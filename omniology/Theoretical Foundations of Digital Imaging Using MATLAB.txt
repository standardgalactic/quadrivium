

TheoreTical
FoundaTions
of
digiTal imaging 
using maTlaB®

Chapman & Hall/CRC
Mathematical and Computational 
Imaging Sciences
Series Editors
Chandrajit Bajaj
Center for Computational Visualization
The University of Texas at Austin
Guillermo Sapiro
Department of Electrical  
and Computer Engineering 
University of Minnesota
Aims and Scope
This series aims to capture new developments and summarize what is 
known over the whole spectrum of mathematical and computational imaging 
sciences. It seeks to encourage the integration of mathematical, statistical and 
computational methods in image acquisition and processing  by publishing a 
broad range of textbooks, reference works and handbooks. The titles included 
in the series are meant to appeal to students, researchers and professionals 
in the mathematical, statistical and computational sciences, application areas, 
as well as interdisciplinary researchers involved in the field. The inclusion of 
concrete examples and applications, and programming code and examples, is 
highly encouraged.
Published Titles
Theoretical Foundations of Digital Imaging Using MATLAB®
by Leonid P. Yaroslavsky 
Rough Fuzzy Image Analysis: Foundations and Methodologies
by Sankar K. Pal and James F. Peters
Proposals for the series should be submitted to the series editors above or directly to:
CRC Press, Taylor & Francis Group
3 Park Square, Milton Park, Abingdon, OX14 4RN, UK

leonid P. Yaroslavsky
TheoreTical
FoundaTions
of
digiTal imaging 
using maTlaB®

MATLAB® is a trademark of The MathWorks, Inc. and is used with permission. The MathWorks does not 
warrant the accuracy of the text or exercises in this book. This book’s use or discussion of MATLAB® soft-
ware or related products does not constitute endorsement or sponsorship by The MathWorks of a particular 
pedagogical approach or particular use of the MATLAB® software.
CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2013 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20121213
International Standard Book Number-13: 978-1-4665-9219-3 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts 
have been made to publish reliable data and information, but the author and publisher cannot assume 
responsibility for the validity of all materials or the consequences of their use. The authors and publishers 
have attempted to trace the copyright holders of all material reproduced in this publication and apologize to 
copyright holders if permission to publish in this form has not been obtained. If any copyright material has 
not been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmit-
ted, or utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, 
including photocopying, microfilming, and recording, or in any information storage or retrieval system, 
without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.
com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood 
Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that provides licenses and 
registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, 
a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used 
only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

To Dima and Yaro on their 25th and 5th birthdays


vii
Contents
Preface......................................................................................................................xv
Author...................................................................................................................xvii
	 1.	 Introduction......................................................................................................1
Imaging Goes Digital.......................................................................................1
Briefly about the Book Structure....................................................................7
References..........................................................................................................8
	 2.	 Mathematical Preliminaries..........................................................................9
Mathematical Models in Imaging..................................................................9
Primary Definitions.....................................................................................9
Linear Signal Space, Basis Functions, and Signal Representation 
as Expansion over a Set of Basis Functions............................................12
Signal Transformations..................................................................................17
Imaging Systems and Integral Transforms.................................................20
Direct Imaging and Convolution Integral..............................................20
Multiresolution Imaging: Wavelet Transforms.....................................22
Imaging in Transform Domain and Diffraction Integrals...................23
Properties of the Integral Fourier Transform.........................................29
Invertibility............................................................................................29
Separability............................................................................................31
Symmetry Properties............................................................................33
Transforms in Sliding Window (Windowed Transforms) and 
Signal Sub-Band Decomposition.............................................................34
Imaging from Projections and Radon Transform.................................37
Statistical Models of Signals and Transformations....................................40
Principles of Statistical Treatment of Signals and Signal 
Transformations and Basic Definitions...................................................40
Models of Signal Random Interferences.................................................45
Additive Signal-Independent Noise Model.......................................45
Multiplicative Noise Model.................................................................47
Poisson Model........................................................................................47
Impulse Noise Model...........................................................................48
Speckle Noise Model............................................................................48
Quantifying Signal-Processing Quality.................................................52
Basics of Optimal Statistical Parameter Estimation..............................53
Appendix.........................................................................................................57
Derivation of Equation 2.32......................................................................57
Derivation of Equation 2.65......................................................................57
Derivations of Equations 2.84 through 2.87...........................................58
Reference..........................................................................................................58

viii
Contents
	 3.	 Image Digitization........................................................................................59
Principles of Signal Digitization...................................................................59
Signal Discretization......................................................................................60
Signal Discretization as Expansion over a Set of Basis
Functions.....................................................................................................60
Typical Basis Functions and Classification............................................ 61
Shift (Convolutional) Basis Functions................................................ 61
Scale (Multiplicative) Basis Functions................................................66
Wavelets..................................................................................................70
Optimality of Bases: Karhunen–Loeve and Related Transform.........73
Image Sampling..............................................................................................78
The Sampling Theorem and Signal Sampling.......................................78
1D Sampling Theorem..........................................................................80
Sampling Two-Dimensional and Multidimensional Signals..........86
Sampling Artifacts: Quantitative Analysis............................................91
Sampling Artifacts: Qualitative Analysis...............................................94
Alternative Methods of Discretization in Imaging Devices.....................96
Signal Scalar Quantization..........................................................................100
Optimal Quantization: Principles.........................................................100
Design of Optimal Quantizers............................................................... 102
Quantization in Digital Holography..................................................... 111
Basics of Image Data Compression............................................................ 113
What Is Image Data Compression and Why Do We Need It?........... 113
Signal Rate Distortion Function, Entropy, and
Statistical Encoding................................................................................. 115
Outline of Image Compression Methods............................................. 117
Appendix.......................................................................................................120
Derivation of Equation 3.31....................................................................120
Derivation of Equation 3.44.................................................................... 121
Derivation of Equation 3.45....................................................................122
Derivation of Equation 3.78....................................................................122
Derivation of Equation 3.98....................................................................123
Derivation of Equation 3.105................................................................... 124
Derivation of Equation 3.136...................................................................127
Basics of Statistical Coding.....................................................................128
Exercises.........................................................................................................130
References......................................................................................................130
	 4.	 Discrete Signal Transformations.............................................................133
Basic Principles of Discrete Representation of Signal 
Transformations............................................................................................133
Discrete Representation of the Convolution Integral.............................. 137
Digital Convolution................................................................................. 137
Treatment of Signal Borders in Digital Convolution.......................... 141

ix
Contents
Discrete Representation of Fourier Integral Transform.......................... 142
Discrete Fourier Transforms.................................................................. 142
2D Discrete Fourier Transforms............................................................ 147
Properties of Discrete Fourier Transforms........................................... 148
Invertibility and sincd-Function....................................................... 149
Energy Preservation Property................................................................150
Cyclicity................................................................................................ 151
Symmetry Properties..........................................................................153
SDFT Spectra of Sinusoidal Signals..................................................154
Mutual Correspondence between Signal Frequencies and 
Indices of Its SDFTs Spectral Coefficients........................................155
DFT Spectra of Sparse Signals and Spectrum Zero Padding.......156
Discrete Cosine and Sine Transforms................................................... 161
Signal Convolution in the DCT Domain.............................................. 166
DFTs and Discrete Frequency Response of Digital Filter.................. 169
Discrete Representation of Fresnel Integral Transform.......................... 171
Canonical Discrete Fresnel Transform and Its Versions.................... 171
Invertibility of Discrete Fresnel Transforms and frincd-Function... 175
Convolutional Discrete Fresnel and Angular Spectrum 
Propagation Transforms.......................................................................... 178
Two-Dimensional Discrete Fresnel Transforms.................................. 182
Discrete Representation of Kirchhoff Integral.........................................184
Hadamard, Walsh, and Wavelet Transforms............................................184
Binary Transforms................................................................................... 185
Hadamard and Walsh Transforms................................................... 185
Haar Transform................................................................................... 186
Discrete Wavelet Transforms and Multiresolution Analysis............ 187
Discrete Sliding Window Transforms and “Time-Frequency” 
Signal Representation................................................................................... 192
Appendix....................................................................................................... 197
Derivation of Equation 4.24.................................................................... 197
Derivation of Equation 4.30.................................................................... 197
Reasonings Regarding Equation 4.31.................................................... 198
Derivation of Equations 4.37 and 4.38................................................... 198
Principle of Fast Fourier Transform Algorithm...................................199
Representation of Scaled DFT as Convolution.....................................200
Derivation of Equation 4.53....................................................................201
Derivation of Equations 4.58 and 4.60...................................................202
Derivation of Equation 4.63....................................................................203
Derivation of Equation 4.65....................................................................204
Derivation of Equation 4.68....................................................................205
Derivation of Equation 4.70....................................................................207
Derivation of Equations 4.72 and 4.74...................................................208
Derivation of Equation 4.75....................................................................209
Derivation of Equation 4.76....................................................................209

x
Contents
Derivation of Equation 4.85.................................................................... 211
Rotated and Scaled DFTs as Digital Convolution............................... 212
Derivation of Equation 4.93.................................................................... 213
Derivation of Equation 4.98.................................................................... 214
Derivation of Equation 4.104................................................................... 214
Derivation of Equation 4.118................................................................... 215
Derivation of Equation 4.124................................................................... 215
Derivation of Equation 4.149................................................................... 216
Derivation of Equation 4.183................................................................... 217
Exercises......................................................................................................... 217
Reference........................................................................................................ 217
	 5.	 Digital Image Formation and Computational Imaging...................... 219
Image Recovery from Sparse or Nonuniformly Sampled Data............. 219
Formulation of the Task.......................................................................... 219
Discrete Sampling Theorem...................................................................220
Algorithms for Signal Recovery from Sparse Sampled Data............223
Analysis of Transforms...........................................................................224
Discrete Fourier Transform...............................................................224
Discrete Cosine Transform................................................................226
Wavelets and Other Bases..................................................................231
Selection of Transform for Image Band-Limited 
Approximation.........................................................................................235
Application Examples..............................................................................236
Image Superresolution from Multiple Differently Sampled 
Video Frames.......................................................................................236
Image Reconstruction from Sparse Projections in Computed 
Tomography.........................................................................................238
Discrete Sampling Theorem and “Compressive Sensing”................238
Digital Image Formation by Means of Numerical Reconstruction 
of Holograms................................................................................................. 241
Introduction.............................................................................................. 241
Principles of Hologram Electronic Recording..................................... 241
Numerical Algorithms for Hologram Reconstruction.......................246
Hologram Pre- and Postprocessing.......................................................249
Point Spread Functions of Numerical Reconstruction of 
Holograms General Formulation...........................................................250
Point Spread Function of Numerical Reconstruction of 
Holograms Recorded in Far Diffraction Zone (Fourier 
Holograms)...........................................................................................254
Point Spread Function of Numerical Reconstruction of 
Holograms Recorded in Near Diffraction Zone (Fresnel 
Holograms)...........................................................................................258
Fourier Reconstruction Algorithm...................................................259
Convolution Reconstruction Algorithm.......................................... 261

xi
Contents
Computer-Generated Display Holography...............................................264
3D Imaging and Computer-Generated Holography...........................264
Recording Computer-Generated Holograms on Optical Media.......266
Optical Reconstruction of Computer-Generated Holograms...........269
Computational Imaging Using Optics-Less Lambertian Sensors.........272
Optics-Less Passive Sensors: Motivation..............................................272
Imaging as a Parameter Estimation Task.............................................273
Optics-Less Passive Imaging Sensors: Possible Designs, 
Expected Performance, Advantages, and Disadvantages..................278
Appendix.......................................................................................................284
Derivation of Equation 5.47....................................................................284
Derivation of Equation 5.63....................................................................285
Derivation of Equation 5.69....................................................................286
Derivation of Equation 5.81....................................................................286
Derivation of Equation 5.88....................................................................289
Derivation of Equation 5.89....................................................................290
Exercises.........................................................................................................290
References......................................................................................................290
	 6.	 Image Resampling and Building Continuous Image Models...........293
Perfect Resampling Filter.............................................................................294
Fast Algorithms for Discrete Sinc Interpolation 
and Their Applications................................................................................298
Signal Subsampling (Zooming-In) by Means of DFT 
or DCT Spectra Zero Padding................................................................298
DFT- and DCT-Based Signal Fractional Shift Algorithms 
and Their Basic Applications..................................................................301
Fast Image Rotation Using the Fractional Shift Algorithms..............306
Image Zooming and Rotation Using “Scaled” and 
Rotated DFTs.............................................................................................308
Discrete Sinc Interpolation versus Other Interpolation Methods: 
Performance Comparison............................................................................ 310
Numerical Differentiation and Integration............................................... 313
Perfect Digital Differentiation and Integration................................... 313
Traditional Numerical Differentiation and Integration 
Algorithms versus DFT/DCT-Based Ones: 
Performance Comparison....................................................................... 317
Local (“Elastic”) Image Resampling: Sliding Window Discrete 
Sinc Interpolation Algorithms....................................................................322
Image Data Resampling for Image Reconstruction
from Projections............................................................................................325
Discrete Radon Transform: An Algorithmic Definition and 
Filtered Back Projection Method for Image Reconstruction..............325
Direct Fourier Method of Image Reconstruction................................327
Image Reconstruction from Fan-Beam Projections............................328

xii
Contents
Appendix.......................................................................................................330
Derivation of Equations 6.6 and 6.7.......................................................330
PSF of Signal Zooming by Means of Zero Padding of Its DCT 
Spectrum...................................................................................................334
Derivation of Equation 6.18.....................................................................338
Derivation of Equation 6.28....................................................................339
Derivation of Equation 6.29....................................................................340
Exercises.........................................................................................................342
References......................................................................................................342
	 7.	 Image Parameter Estimation: Case Study—Localization of 
Objects in Images........................................................................................343
Localization of Target Objects in the Presence of Additive 
Gaussian Noise..............................................................................................343
Optimal Localization Device for Target Localization in 
Noncorrelated Gaussian Noise..............................................................343
Performance of ML-Optimal Estimators: Normal and 
Anomalous Localization Errors.............................................................345
Target Object Localization in the Presence of Nonwhite 
(Correlated) Additive Gaussian Noise..................................................351
Localization Accuracy for the SNR-Optimal Filter.............................354
Optimal Localization in Color and Multicomponent Images...........355
Object Localization in the Presence of Multiple Nonoverlapping 
Nontarget Objects....................................................................................357
Target Localization in Cluttered Images...................................................359
Formulation of the Approach.................................................................359
SCR-Optimal Adaptive Correlator........................................................360
Local Adaptive SCR-Optimal Correlators............................................366
Object Localization in Blurred Images................................................. 370
Object Localization and Edge Detection: Selection of Reference 
Objects for Target Tracking....................................................................372
Appendix.......................................................................................................378
Distribution Density and Variances of Normal Localization 
Errors.........................................................................................................378
Evaluation of the Probability of Anomalous Localization Errors....386
Derivation of Equations 7.49, 7.50, and 7.51......................................389
Exercises.........................................................................................................394
References......................................................................................................394
	 8.	 Image Perfecting..........................................................................................395
Image Perfecting as a Processing Task......................................................395
Possible Approaches to Restoration of Images Distorted by Blur 
and Contaminated by Noise.......................................................................397
MMSE-Optimal Linear Filters for Image Restoration.............................401
Transform Domain MSE-Optimal Scalar Filters.................................401

xiii
Contents
Empirical Wiener Filters for Image Denoising....................................403
Empirical Wiener Filters for Image Deblurring................................... 411
Sliding Window Transform Domain Adaptive Image Restoration.......420
Local Adaptive Filtering.........................................................................420
Sliding Window DCT Transform Domain Filtering...........................422
Hybrid DCT/Wavelet Filtering..............................................................427
Multicomponent Image Restoration and Data Fusion............................429
Filtering Impulse Noise...............................................................................435
Correcting Image Grayscale Nonlinear Distortions................................440
Nonlinear Filters for Image Perfecting......................................................443
Nonlinear Filter Classification Principles.............................................443
Filter Classification Tables and Particular Examples..........................451
Nonlinear Filters for Multicomponent Images....................................458
Display Options for Image Enhancement............................................460
Appendix.......................................................................................................463
Derivation of Equation 8.16.....................................................................463
Empirical Estimation of Variance of Additive Signal-Independent
Broad Band Noise in Images..................................................................464
Derivation of Equation 8.45....................................................................466
Derivation of Equation 8.51....................................................................468
Verification of Equation 8.66...................................................................473
Exercises.........................................................................................................475
References......................................................................................................475


xv
Preface
With the advent and ubiquitous spreading of digital imaging, a new pro-
fession has emerged: imaging engineering. This book is intended as a text-
book for studying the theoretical foundations of digital imaging to master 
this profession. It is based on the experience accumulated by the present 
author for 50 years of working in the field and teaching various courses in 
digital image processing and digital holography in the Russian Academy of 
Sciences, the National Institutes of Health (Bethesda, Maryland, USA), the 
University of Erlangen-Nuremberg (Germany), the Tampere University of 
Technology (Tampere, Finland), Agilent Labs (Palo Alto, California, USA), the 
Autonomous University of Barcelona (Spain), the Institute of Henri Poincare 
(Paris, France), the Kiryu University (Kiryu, Japan), and the University of Tel 
Aviv (Israel).
The book is addressed to young students who opt to pursue a scientific 
and research career in imaging science and engineering. The most out-
standing minds of mankind, such as Galileo Galilei, René Descartes, Isaac 
Newton, James Clerk Maxwell, and many other scientists and engineers con-
tributed to this branch of modern science and technology. At least 12 Nobel 
Prizes have been awarded for contributions directly associated with image 
science and imaging devices, and a majority of others would not be possible 
without one or the other imaging methods. You will be in good company, 
dear reader. Let this book help you to become a master of digital imaging.
A number of MATLAB programs are available at the Download section of 
this book’s web page on the CRC Press website (http://www.crcpress.com/
product/isbn/9781439861400).
MATLAB® and Simulink® are registered trademarks of The MathWorks, Inc. 
For product information, please contact:
The MathWorks, Inc.
3 Apple Hill Drive
Natick, MA 01760-2098 USA
Tel: 508 647 7000
Fax: 508-647-7001
E-mail: info@mathworks.com
Web: www.mathworks.com


xvii
Author
Leonid P. Yaroslavsky is a fellow of the Optical 
Society of America, MS (1961, Faculty of Radio 
Engineering, Kharkov Polytechnic Institute, 
Kharkov, Ukraine), PhD (1968, Institute for 
Information Transmission Problems, Moscow, 
Russia), and Dr. Sc. Habilitatus in Physics 
Mathematics (1982, State Optical Institute, 
Saint Petersburg, Russia). From 1965 to 1983, 
he headed a group for digital image process-
ing and digital holography at the Institute for 
Information Transmission Problems, Russian 
Academy of Sciences, which in particular car-
ried out digital processing of images trans-
mitted from the spacecraft Mars-4, Mars-5, 
Venera-9, and Venera-10 and obtained the first 
color images of the surface of Mars and the first panoramas of the surface of 
Venus. From 1983 to 1995, he headed the Laboratory of Digital Optics at the 
institute. From 1995 to 2008, he was a professor at the Faculty of Engineering, 
Tel Aviv University, where, at present, he is a professor emeritus. He was 
also a visiting professor at the University of Erlangen, Germany; National 
Institutes of Health, Bethesda, Maryland, USA; Institute of Optics, Orsay, 
France; Institute Henri Poincare, Paris, France; International Center for Signal 
Processing, Tampere University of Technology, Tampere, Finland; Agilent 
Laboratories, Palo Alto, California, USA; Gunma University, Kiryu, Japan; 
and the Autonomous University of Barcelona, Spain. He has supervised 20 
PhD candidates and is an author and editor of several books and more than 
100 papers on digital image processing and digital holography.


1
1
Introduction
Imaging Goes Digital
The history of science is, to a considerable extent, the history of invention, 
development, and perfecting imaging methods and devices. Evolution 
of imaging systems can be traced back to rock engravings and to ancient 
­mosaics thousands of years ago (Figure 1.1).
Apparently, the very first “imaging devices” were humans, painters. Great 
artists, such as Leonardo da Vinci, Michelangelo, Albrecht Dürer, and many 
others, not only created outstanding masterpieces of art, but also actually 
­pioneered imaging science and engineering (Figure 1.2).
The first artificial imaging device was, seemingly, camera-obscura 
(“­pinhole camera,” Latin for “dark room”) that dates back to Aristotle (384–
322 bce) and Euclid (365–265 bce). Then, in the thirteenth century, methods 
for polishing lenses were invented and eye glasses were widely used in 
Europe by the mid-fifteenth century. In the first few years of the seventeenth 
century, a decisive breakthrough took place, when Galileo Galilei (1564–1642) 
in October 1609, apparently using his knowledge of laws of light refraction, 
greatly improved the magnification of three-powered “spyglasses” unveiled 
not long before in the Netherlands and built a 20-powered instrument. He 
directed it to the sky and immediately discovered mountains on the Moon, 
four satellites of Jupiter, rings of Saturn, phases of Venus, and nebular patches 
in stars. It was the beginning of the scientific revolution of the seventeenth 
century. Since then, the pace of evolution of imaging science and imaging 
devices has become numbered in decades rather than in centuries.
In the 1630s, René Descartes published the Dioptrique (the Optics) that 
­summarized contemporary knowledge on topics such as the law of ­refraction, 
vision, and the rainbow.
In the late 1660s, Isaac Newton discovered that white light is composed 
of a spectrum of colors and built his first reflecting telescope that allowed 
­avoiding color aberrations and building telescopes with much greater 
­magnification than was possible with refractive Galilean telescopes.
In the 1670s, Robert Hook and Anthony Leeuwenhoek introduced a 
­microscope, invented new methods for grinding and polishing microscope 
lenses, and discovered cells and bacteria.

2
Theoretical Foundations of Digital Imaging Using MATLAB®
The next decisive breakthrough happened in the 1830s through the 1840s, 
when photography was invented, which for the first time solved the prob-
lem of converting images into pictures that can be stored, copied, and sent 
by mail. This invention had a very profound influence on the develop-
ment of our civilization, from people’s everyday life to science and to art. 
Photography has become a branch of industry and a profession that served 
people’s need to memorize the images. After the invention of photography, 
the art of painting became a pure art, which stimulated the birth of new art 
trends such as impressionism. Photographic plates became a major means in 
experimental science, which eventually led to almost all outstanding discov-
eries made in the nineteenth and the twentieth centuries.
FIGURE 1.2
Drawing By Leonardo Da Vinci illustrating treatment of light and shade (a) and a woodcut by 
Albrecht Dürer showing an artist using Dürer’s drawing machine to paint a lute (b).
FIGURE 1.1
​Details from the mosaic floor of the Petra Church.

3
Introduction
In the 1890s, photographic plates enabled discoveries of x-rays by Wilhelm 
Conrad Roentgen (the Nobel Prize laureate, 1901) and radioactivity by 
Antoine Henri Becquerel (the Nobel Prize laureate, 1903) at the end of the 
nineteenth century. These discoveries, in their turn, almost immediately 
gave birth to new imaging techniques, x-ray imaging and radiography.
The 1890s were remarkable years in the history of science. Apart from 
­discoveries of x-rays and radioactivity, these were also the years of the 
­discovery of radio, the major breakthrough in communication and infor-
mation transmission, and of the invention of motion pictures, which solved 
the problem of imaging moving objects. With the invention of motion pic-
tures, the new, for imaging, principal concept of time-sampled images was 
­introduced and realized.
X-rays were discovered by W.C. Roentgen in experiments with cathode 
rays. Cathode rays were discovered in 1859 by the German mathematician 
and physicist Julius Plücker, who used vacuum tubes invented in 1855 by the 
German inventor, Heinrich Geissler. These tubes eventually led to the inven-
tion of the cathode ray tube (CRT) by Karl Braun in 1897 and finally brought 
about the development of electronic television and electron microscopy.
In 1907, the Russian professor Boris Rosing used a CRT in the receiver of a 
television system that, at the camera end, made use of mirror-drum scanning. 
Rosing transmitted crude geometrical patterns onto the television screen 
and was the first inventor to do so using a CRT. Then, in the 1920s through 
the 1940s, Vladimir Zworykin, a former student of Rosing, working first for 
Westinghouse and later for RCA in the United States, and Philo Farnsworth, 
working independently in San Francisco, brought about the birth of purely 
electronic television. Electronic television has finally won in the 30 years of 
competition with electromechanical television based on using, for image 
transmission, the image scanning disk, invented in 1883 by a German stu-
dent, Paul Nipkow. This engineering solution turned to be a dead end in the 
evolution of television, although the idea itself of converting images to time 
signals by means of image row-wise scanning had a principal value and was 
eventually implemented in a much more efficient way as image scanning by 
easily controlled electron beam. There is no need to tell the present genera-
tion the role that television plays in our civilization.
The victory of electronic television heralded the birth of electronic imag-
ing. One more outstanding representative of electronic imaging devices was 
electronic microscope. The first electron microscope was designed in 1931 
by by the German engineer E. Ruska. In 1986, E. Ruska was awarded the 
Nobel Prize in physics “for his ­fundamental work in electron optics, and for 
the design of the first electron microscope.” Electron microscopes depend 
on electrons rather than light to view objects and because of this electron 
microscopes make it possible to view objects with a resolution far beyond the 
resolution of optical microscopes.
Since the 1940s, the pace of evolution of imaging devices has become 
­numbered in years. In 1947, the British (native of Hungary) scientist Dennis 

4
Theoretical Foundations of Digital Imaging Using MATLAB®
Gabor, while working to improve the resolution of electron microscopes, 
invented an optical method for recording and reconstructing amplitudes 
and phases of coherent light radiation. He coined the term holography for 
this method, meaning that it is the method for recording and reproducing 
whole information carried by optical signals. For this invention, he was 
awarded the Nobel Prize in physics in 1971.
In the 1950s, synthetic aperture and side-looking radars were invented, 
which opened ways for creating images of objects in radio frequency band of 
electromagnetic radiation. The principle of synthetic aperture radars is actually 
the same principle of recording of amplitude and phase of radiation wavefronts 
as that of holography, and in 1962, Emmett Leith and Juris Upatnieks of the 
University of Michigan, USA, recognized from their work in side-looking radar 
that holography could be used as a three-dimensional (3D) visual medium. 
They read Gabor’s paper and “simply out of curiosity” decided to duplicate 
Gabor’s technique using the recently invented laser and the “off-axis” technique 
borrowed from their work in the development of side-looking radar. The result 
was the first laser transmission hologram of 3D objects. These transmission 
holograms produced images with clarity and realistic depth but required laser 
light to view the holographic image. Also in 1962, on another side of the globe, 
Yuri N. Denisyuk from the Russian Academy of Sciences combined holography 
with the 1908 Nobel laureate Gabriel Lippmann’s work in natural color photog-
raphy. Denisyuk’s method produced reflection holograms which, for the first 
time, did not need the use of coherent laser light for image reconstruction and 
could be viewed in light from an ordinary incandescent light bulb. Holography 
was the first example of what we can call transform domain imaging.
In 1969, at Bell Labs, USA, George Smith and Willard Boyle invented the first 
CCDs or charge-coupled devices. A CCD is a semiconductor electronic memory 
that can be charged by light. CCDs can hold a charge corresponding to variable 
shades of light, which makes them useful as imaging devices for cameras, scan-
ners, and fax machines. Because of its superior sensitivity, the CCD has revo-
lutionized the field of electronic imaging. In 2009, George Smith and Willard 
Boyle were awarded the Nobel Prize for physics for their work on the CCD.
In 1971–1972, the British engineer Godfrey Hounsfield of EMI Laboratories, 
England, and the South Africa-born physicist Allan Cormack of Tufts 
University, Massachusetts, USA, working independently, invented a new 
imaging method that allowed building images of slices of bodies from sets of 
their x-ray projections taken from different angles. Reconstruction of images 
from their projections required special computer processing of projec-
tions, and the method obtained the name “computer-assisted tomography.” 
Computer tomography (CT) revolutionized medical imaging and in few 
years tens and later hundreds and thousands of CT scanner were installed 
in medical hospitals all over the world. In 1979, Hounsfield and Cormack 
were awarded the Nobel Prize in medicine.
In the 1979s, Gerd Binnig and Heinrich Rohrer, IBM Research Division, 
Zurich Research Laboratory, Switzerland, invented the scanning tunneling 

5
Introduction
microscope that gives 3D images of objects down to the atomic level. Binnig 
and Rohrer were awarded the Nobel Prize in physics in 1986 for this inven-
tion. The powerful scanning tunneling microscope is the strongest micro-
scope to date. With this invention, imaging techniques, which before this 
were based on electromagnetic radiation, conquered the quantum world of 
atomic forces.
But this is not the end of the “evolution of imaging” story. The years after 
the 1970s and the 1980s were the years, when imaging began changing rap-
idly from completely analog to digital. The first swallow in this process 
was CT, in which images of body slices are computed from projection data, 
though its germs one can notice (or find, or trace) in methods of crystallog-
raphy emerged from the discovery of diffraction of x-rays by Max von Laue 
(the Nobel Prize laureate, 1914) in the beginning of the twentieth century. 
Although Von Laue’s motivation was not creating a new imaging technique, 
but rather proving the wave nature of x-rays, photographic records of x-ray 
diffraction on crystals, or lauegrams, had very soon become the main imag-
ing tool in crystallography because using lauegrams, one can numerically 
reconstruct the spatial structure of atoms in crystals. This eventually led 
to one of the greatest discoveries of twentieth century, the discovery, by 
J.  Watson and Fr. Crick, of the Molecular Structure of DNA—the Double 
Helix (the Nobel Prize in Physiology and Medicine, 1962).
Digital imaging was born at the junction of imaging and communication. 
The first reports on digital images date back to the 1920s, when images were 
sent for newspapers by telegraph over submarine cable between London and 
New York. Image transmission was always a big challenge to communica-
tion because it required communication channels of very large capacity. In 
the 1950s, the needs to transmit television over long distances demanded to 
compress TV signals as much as possible. By that time, the first digital com-
puters were available, at least for large companies and research institutions, 
and researchers started using them for investigations in image compression. 
For these purposes, the first image input–output devices for computers were 
developed in the late 1950s through the early 1960s. Satellite communication 
and space research that have been sky rocketing since the first “Sputnik” in 
1957 greatly stimulated works in digital image processing.
In 1964–1971, computers were used at the Jet Propulsion Laboratory 
(Pasadena, California, USA) for improving the quality of the first images 
of the Moon surface transmitted, in digital form, from the US spacecraft 
Ranger-7 and images of Mars transmitted from the US spacecrafts Mariner-4 
(1964), Mariner 7 (1969), and Mariner 9 (1971). In 1973–1976, the first color 
images of the surface of Mars and the first panoramas from the surface of 
Venus were published in USSR Academy of Sciences, which were obtained 
using digital image processing of data transmitted from spacecrafts Mars-
4, Mars-5, Venus 9, and Venus 10 launched in the former USSR. By the late 
1970s, digital image processing had become the main tool in the processing 
of satellite images for space exploration and remote sensing.

6
Theoretical Foundations of Digital Imaging Using MATLAB®
The availability of digital computers by the 1960s and the new ­opportunities 
this offered for information processing could not pass yet another fast-­
growing child of the 1960s, holography. In 1966–1968, a German professor 
Adolf Lohmann, while working in San Diego University, California, USA, 
invented computer-generated holograms and in the late 1960s through the 
early 1970s, the first experiments with numerical reconstruction of optical 
holograms were reported. This was the birth of digital holography.
By the mid-1970s, the first image processing “mini-computer”-based 
­workstations and high-quality gray-scale and color computer displays were 
created. It would be no exaggeration to say that needs for processing, ­storage, 
and displaying images were one of the main, if not the major, impetuses in 
the development of personal computers (PC), which emerged in the early 
1980s and became the main stream in the computer industry. In the late 
1980s through the early 1990s, the industry of dedicated image processing 
boards for minicomputers and PC emerged, and no PC has been sold since 
that time without a “video board.”
The digital revolution affected the industry of image-capturing devices as 
well. In 1972, Texas Instruments patented a filmless electronic camera, the 
first to do so. In August 1981, Sony released the first commercial ­electronic 
camera. Since the mid-1970s, Kodak has invented several solid-state image 
sensors that converted light to digital pictures for professional and home 
consumer use. In 1991, Kodak released the first professional digital cam-
era system (DCS) with a 1.3 megapixel sensor. This has become possible 
not only because megapixel CCDs were developed by this time, but also 
because image compression methods, foundations of which were laid in the 
1950s through the 1960s, have reached a stage, when their implementation 
has become possible, thanks to the emergence of the appropriate computa-
tional hardware. In 1992, the international Joint Photographic Experts Group 
issued the first JPEG standard for compression of still images, and in 1993 
the Motion Picture Expert Group issued the first MPEG standard for com-
pression of video. Nowadays, digital photographic and video cameras and 
JPEG and MPEG standards are overwhelmingly used in all ranges of image-
related activities from space telescopes to mobile phones.
At the beginning of the twenty-first century, the era of photography and 
analog electronic imaging gave way to the era of digital imaging. Digital 
imaging has overpowered the evolution of imaging devices because
• It is much more cheap, productive, and versatile than the analog 
imaging.
• Acquiring and processing of image data is most natural when the 
data are represented, handled, and stored in a digital form. In the 
same way as money is the general equivalent in economy, digital 
signals are the general equivalent in information handling. Thanks 
to its universal nature, digital signals are the ideal means for inte-
grating various informational systems.

7
Introduction
• It enables using digital computers for image processing and analy-
sis. No hardware modifications are necessary anymore for solving 
different tasks. With the same hardware, one can build an arbitrary 
problem solver by simply selecting or designing an appropriate code 
for the computer.
Images are now overwhelmingly created, stored, transmitted, and pro-
cessed in a digital form. The history has completed its spiral cycle from the 
art of making ancient mosaics, as shown in Figure 1.1, which were in fact the 
first digital pictures, to modern digital imaging technology. 
Briefly about the Book Structure
The father of information theory and, generally, of modern communication 
theory Claude Shannon and his coauthor H.W. Bode wrote in their paper 
“A simplified derivation of linear least square smoothing and prediction 
theory” [1]:
In a classical report written for the National Defence Research Council 
[2], Wiener has developed a mathematical theory of smoothing and pre-
diction of considerable importance in communication theory.  A similar 
theory was independently developed by Kolmogoroff [3] at about the 
same time. Unfortunately the work of Kolmogoroff and Wiener involves 
some rather formidable mathematics—Wiener’s yellow-bound report 
soon came to be known among bewildered engineers as “The Yellow 
Peril”—and this has prevented the wide circulation and use that theory 
deserves. In this paper the chief results of the smoothing theory will 
be developed by a new method which, while not as rigorous or gen-
eral as the methods of Wiener and Kolmogoroff, has the advantage of 
greater simplicity, particularly for readers with background of electrical 
circuit theory. The mathematical steps in the present derivation have, for 
the most part, a direct physical interpretation, which enables one to see 
intuitively what mathematics is doing.
This approach was this author’s guideline in writing this book. The book 
concept is to expose the theory of digital imaging in its integrity, from 
image formation to image perfecting, as a specific branch of engineering 
sciences and to present theoretical foundations of digital imaging as com-
prehensively as possible avoiding unnecessarily formidable mathematics 
as much as possible and providing motivations and physical interpreta-
tion to all mathematical entities and derivations. The book is intended to 
be, for imaging engineers, similar to texts on theoretical mechanics are for 
mechanical engineers or texts on communication theory are for communi-
cation engineers.

8
Theoretical Foundations of Digital Imaging Using MATLAB®
Including this introductory chapter, the book consists of eight chapters. 
The book assumes some familiarity with relevant mathematics. The neces-
sary mathematical preliminaries are provided in the second chapter. Chapter 
3 presents the basic contents of the book. It addresses the very first problem 
of digital imaging, the problem of converting images into digital signals that 
can be stored, transmitted, and processed in digital computers. Chapter 4 is 
devoted to the problem of adequate representation of image transformations in 
computers. The main emphasis is made on keeping a correspondence between 
the original analog nature of image transformations and their computer imple-
mentations. In Chapter 5, the concept of computational imaging is illustrated 
by several specific and instructive examples: image reconstruction from sparse 
or nonuniform samples data, digital image formation by means of numerical 
reconstruction of holograms, virtual image formation by means of computer-
generated display holograms, and computational image formation from sen-
sor data obtained without imaging optics. Chapter 6 introduces methods for 
image perfect resampling and building, in computers, continuous image mod-
els. Chapter 7 treats the problem of statistically optimal estimation of image 
numerical parameters. As a typical and representative example, the task of 
optimal localization of targets in images is discussed. In Chapter 8, methods of 
optimal linear and nonlinear filtering for image perfecting and enhancement 
are discussed. All chapters are supplied with short introductory synopses.
In order to illustrate the major results and facilitate their deeper under-
standing, the book offers a number of exercises supported by demo pro-
grams in MATLAB•. Those results and algorithms that are not supported by 
a dedicated demo program can be easily implemented in MATLAB as well.
We tried to keep the book self-containing and to not overload readers by 
the needs to refer to other sources. As a rule, only references to classical 
milestone publications are provided to give credit to their authors. All other 
references, when necessary, can be easily found by Google search using key-
words provided in the text. In order to make reading and understanding of 
the book easier, all formula derivations that require more than two to three 
lines of equations are moved to appendixes and contain all needed details.
References
	
1.	 H.W. Bode, C.E. Shannon, A simplified derivation of linear least square smoothing 
and prediction theory, Proceedings of I.R.E., 38, 4, 417–425, 1950.
	
2.	 N. Wiener, The Interpolation, Extrapolation, and Smoothing of Stationary Time Series, 
National Defence Research Committee; reprinted as a book, J. Wiley and Sons, 
Inc., New York, NY, 1949.
	
3.	 A Kolmogoroff, Interpolation und Extrapolation von Stationären Zufällige  
Folgen, Bull. Acad. Sci. (USSR) Sér. Math. 5, 3–14, 1941.

9
2
Mathematical Preliminaries
In this chapter, we outline the basic notions of signal theory, which will be 
used later throughout the book. In the section “Mathematical Models in 
Imaging,” we introduce notions of signals and signal space. In the section 
“Signal Transformations,” two basic classes of signal transformations are 
introduced: linear and element-wise nonlinear ones. In the section “Imaging 
Systems and Integral Transforms,” major imaging transforms are detailed 
and in the section “Statistical Models of Signals and Transformations,” 
the basics of the statistical approach to treatment of signals and their 
­transformations are reviewed.
Mathematical Models in Imaging
Primary Definitions
In the context of this book, images are signals, or information carriers. The 
main peculiarity of images as signals that distinguish them from other 
­signals is that images are accessible for visual perceptions.
Images are generated by dedicated technical devices, such as microscopes, 
telescopes, photographic and video cameras, tomographic machines, and 
alike, which we call imaging devices. The process of generating images is 
called imaging.
Signals and signal-processing methods are treated through ­mathematical 
models of mathematical functions, which specify relationships between 
physical parameters of imaged objects, such as their capability to reflect or 
absorb radiation used to create images, and parameters of the object physical 
space, such as spatial coordinates and/or of time.
Figure 2.1 represents a classification diagram of signals as ­mathematical func-
tions and associated terminology. In terms of the function values, ­functions 
can be scalar, that is characterized by scalar values, or vectorial, that is, char-
acterized by multiple values treated as value vector ­components. Examples of 
scalar image signals are monochrome gray-scale images. Examples of vectorial 
image signals are two-component signals that ­represent orthogonal compo-
nents of polarized electromagnetic wave fields, pairs of left/right stereoscopic 
images, color images represented by their red, green, and blue components, 
and multispectral images that contain more than three components.

10
Theoretical Foundations of Digital Imaging Using MATLAB®
In terms of function arguments, signals can be one-dimensional (1D) or 
multidimensional functions (2D, 3D, etc.). Examples of 1D signals are audio 
signals, physical measurements as functions of time, rows of image scans, 
and alike. Images are usually modeled as 2D functions of coordinates in 
image plane; video can be regarded as 3D functions of image plane coor-
dinates and time. Volumetric data that represent 3D scenes are functions of 
three spatial coordinates.
In describing physical reality, we conventionally disregard quantum 
effects and use functions that are continuous in both values and arguments; 
hence, the notion of continuous signals, or analog signals, that can take arbi-
trary values and are defined in continuous coordinates. They are regarded 
as a complete analog of physical objects.
The numbers we store and operate within digital computers can be clas-
sified as digital signals. They are produced from continuous signals by a 
procedure, which we call digitization, implemented in special devices, ana-
log-to-digital converters. Signal digitization always, explicitly or implicitly, 
assumes that inverse conversion of the digital signal into the correspond-
ing analog signal is possible using special devices called digital-to-analog 
converters.
There also exist intermediate classes of signals: discrete signals, which 
are ordered sets of numbers that can take arbitrary values, and quantized 
signals, which are continuous functions of their arguments but can assume 
only specific fixed, or quantized, values.
Signals as mathematical functions
Function value
Function arguments
Scalar
(single
component)
signals
Vectorial
(multi-
component)
signals
One-
dimensional
(1D signals)
Multi-
dimensional
(2D, 3D, 4D,
etc. signals)
Discrete
signals
(discrete in
arguments)
Quantized
signals
(quantized in
value)
Continuous
signals
(continuous both in
values and arguments)
Digital
signals
Signal
reconstruction
Signal
digitization
Physical reality
FIGURE 2.1
Classification of signals as mathematical functions.

11
Mathematical Preliminaries
Generally, each digital signal can be regarded as a single number. In 
­practice, digital signals are represented as ordered sets of quantized 
numbers that may be considered as digits of this single number. It is in 
this sense that digital signals can be regarded as being both discrete and 
quantized.
In order to make the signal theory more intuitional, it is very convenient 
to give signals a geometric interpretation by regarding them as points in 
some space, called the signal space (Figure 2.2). In such treatment, each 
point of the signal space corresponds to a certain signal and vice versa. 
Signal space of continuous signals is a continuum, that is, its signals are 
not countable.
Using the notion of the signal space, one can easily portray the relationship 
between continuous and digital signals. Let us split signal space into a set 
of nonoverlapping subspaces, or cells, which together cover the entire space, 
and assign to each cell a numerical index. Each index will correspond to all 
signals within the corresponding cell and, for each signal, one can find an 
index of the cell to which the signal belongs.
Suppose now that all cells are formed in such a way that all signals within 
one cell can be regarded by the signal end user as identical, or indistinguish-
able, for a given specific application. We will call such cells equivalence cells. 
In each equivalence cell, one can select a signal that will serve, in a given 
Signal space
Equivalency cell
Representative signals
FIGURE 2.2
Signal space, equivalency cells, and representative signals (stars).

12
Theoretical Foundations of Digital Imaging Using MATLAB®
particular application, as a representative signal that substitutes all signals 
within this cell. In such a treatment, conversion of a continuous signal into 
a corresponding digital signal (analog-to-digital conversion) is assigning to 
the continuous signal the index of the equivalence cell to which it belongs. 
We will call this process general digitization. The inverse process of convert-
ing digital signal to analog signal (signal reconstruction) is then generating, 
for each number (digital signal), a representative signal of the correspond-
ing equivalence cell. In practice, partition of the signal space into a set of 
equivalence cells is “hard-wired” in analog-to-digital converters and assign-
ing a representative signal to a number is “hard-wired” in digital-to-analog 
converters.
Linear Signal Space, Basis Functions, and Signal Representation 
as Expansion over a Set of Basis Functions
An important feature of physical signals such as image signals is that they 
can be added, subtracted, and amplified or attenuated. Signal space, in which 
operations of signal addition and multiplication by scalars are defined, is 
called linear signal space.
In linear signal space, one can specify a certain number N of fixed signals 
and use them to generate an arbitrary large set of other signals as a weighted 
sum, with certain weight coefficients {αk}, of these signals called basis signals 
(basis functions):
	
a x
x
k
k
k
N
( )
( ).
=
=
−
∑α φ
0
1
	
(2.1)
It is only natural to select the set of basis functions from linearly ­independent 
functions, that is, functions that cannot be represented as a linear combina-
tion of the rest of the functions from the set; otherwise, the set of basis func-
tions will be redundant. The signal space formed of signals generated as a 
linear combination according to Equation 2.1 of N linearly independent basis 
functions is referred to as an N-dimensional linear space.
Each signal a(x) in N-dimensional signal space corresponds to a unique 
linear combination of basis functions {ϕk(x)}, that is, fully defined by a unique 
set of scalar coefficients {αk}. The ordered set of scalar coefficients of decom-
position of a given signal over the given basis function is the signal discrete 
representation with respect to this basis function.
Signal representation as an expansion over a set of basis functions 
(Equation 2.1) is meaningful only as far as, for each signal a(x), its representa-
tion coefficients {αk} for the given set of basis function {ϕk(x)} can be found. To 
this goal, the concepts of scalar product and orthogonality of functions are 
introduced. The scalar product (inner product and dot product) a1(x) ∘ a2(x) 
of two functions a1(x) and a2(x) is a scalar calculated as an integral of their 

13
Mathematical Preliminaries
point-wise product with the second multiplicand taken complex conjugate 
when ­multiplicands are complex valued signals:
	
a x
a x
a x a x
x
X
1
2
1
2
( )
( )
( )
( )
,

=
∗
∫
d
	
(2.2)
where ∗ is the complex conjugacy symbol. This computation method is a 
mathematical model of natural signal transformations that take place in sig-
nal sensors. The scalar product of a signal with itself
	
a x
a x
a x a x
x
a x
x
X
X
( )
( )
( )
( )
( )

=
=
∗
∫
∫
d
d
2
	
(2.3)
is called signal energy, the term adopted from the definition of energy in 
mechanics and electrical engineering. In functional analysis, this integral is 
also called function norm. Functions whose scalar product is zero are called 
mutually orthogonal functions.
Having defined a scalar product, one can use it to establish a simple 
correspondence between signals and their representation coefficients for 
the given basis function. Let {ϕk(x)} be basis functions and {φl(x)} be a set of 
reciprocal functions, which are mutually orthogonal to {ϕk(x)} and normal-
ized such that
	
φ
ϕ
δ
k
l
k l
x
x
k
l
k
l
( )
( )
,
,
,
,

=
=
≠
=



0
1
	
(2.4)
where symbol δk,l is called the Kronecker delta. Then the signal k-th repre-
sentation coefficient αk over basis function {ϕk(x)} can be found as a scalar 
product of the signal and the corresponding k-th reciprocal basis function 
{φk(x)}:
a x
x
x
x
x
x
k
l
l
l
N
k
l
l
k
l
( )
( )
( )
(
( ))
( ( )
( ))



ϕ
α φ
ϕ
α φ
ϕ
=






=
=
=
−
=
∑
0
1
0
1
0
1
N
l
k l
l
N
k
−
=
−
∑
∑
=
α δ
α
,
.
	
(2.5)
One can compose basis function {ϕk(x)} of mutually orthogonal functions 
of a unit norm:
	
φ
φ
δ
k
l
k l
x
s
( )
( )
.
,

=
	
(2.6)
Such basis reciprocal to itself is called orthonormal basis.

14
Theoretical Foundations of Digital Imaging Using MATLAB®
Given representations {αk} and {βk} of signals a(x) and b(x) over an orthonor-
mal basis function {ϕk(x)}, one can calculate signal scalar product and signal 
energy (norm) through these coefficients as
a x
b x
x
x
k
k
k
N
l
l
l
N
k
k
( )
( )
( )
( )
(
(


=











=
=
−
=
−
∑
∑
α φ
β φ
α φ
0
1
0
1
x
x
x
x
l
l
l
N
k
N
k
k
k
N
k
l
k
))
(
( ))
(
( )
( ))


β φ
α β φ
φ
α β
=
−
=
−
∗
=
−
∑
∑
∑
=
=
0
1
0
1
0
1
k
l
N
k
k
k
N
k
N
k l
∗
=
−
∗
=
−
=
−
∑
∑
∑
=
δ
α β
( , )
0
1
0
1
0
1
	
(2.7)
	
a x
x
b x
x
X
k
k
N
X
k
k
N
( )
;
( )
.
2
2
0
1
2
2
0
1
d
d
∫
∑
∫
∑
=
=
=
−
=
−
α
β
	
(2.8)
From Equations 2.7 and 2.8, it follows that representations αk
( )
1
{
}, βk
( )
1
{
}, and 
αk
( )
2
{
}, βk
( )
2
{
} of signals a(x) and b(x) over two orthonormal bases φk
x
( )( )
1
{
} and 
φk
x
( )( )
2
{
} are linked by the relationship
	
α
β
α
β
k
k
k
k
k
N
k
N
( )
( )
( )
( ) .
1
1
2
2
0
1
0
1
(
) =
(
)
∗
∗
=
−
=
−
∑
∑
	
(2.9)
Equations 2.7 through 2.9 are versions of the so-called Parseval’s relationship.
Up to now, it was assumed that signals are continuous. For discrete signals 
defined by their elements (samples), a convenient mathematical model is that 
of vectors. Let {αk} be a set of samples of a discrete signal, k = 0,1,. . .,N − 1. 
They define a vector column a = {
}
ak . Also let 

φ
φ
r
r k
=
{
}
{
}
,
 be a set of linearly 
independent vectors such that
	
λ φ
r
r
r
N

=
−
∑
≠
0
1
0
	
(2.10)
for arbitrary nonzero coefficients {
}
λr ≠0 . One can select this set as a basis 
for representing any signal vector
	
aN
r
r
r
N
=
=
−
∑α φ

0
1
.
	
(2.11)
An ordered set of basis vectors 

φr
{ } can be regarded as a basis matrix
	
TN
k r
= {
}
,
φ
	
(2.12)

15
Mathematical Preliminaries
and signal expansion of Equation 2.11 can be regarded as a matrix product of 
the vector column of coefficients a = {
}
αr  by the basis matrix
	
a
T
N
N
N
=
a .	
(2.13)
In the signal-processing jargon, matrix TN is called transform matrix and 
signal representation defined by Equation 2.12 is called discrete signal trans-
form. If the transform matrix TN has its inverse matrix TN
−1 such that
	
T T
I
N
N
N
−=
1
,	
(2.14)
where I is the identity matrix:
	
IN
k r
=
−
{
},
δ
	
(2.15)
the vector of signal representation coefficients can be found as
	
a N
N
N
=
−
T a
1
.	
(2.16)
Such matrix treatment of discrete signals assumes that signal scalar prod-
uct a ∘ b is defined as a matrix product
	
a
b
a
b

=
⋅
=
∗
∗
=
−
∑
tr
k
k
k
N
a b
0
1
,
	
(2.17)
where the symbol “tr” denotes transposed matrix.
Transforms TN and TN
−1 are mutually orthogonal. The transform matrix 
that is orthogonal to its transpose
	
T
T
I
N
N
tr
N
⋅
=
	
(2.18)
is called the orthogonal matrix. The transform matrix TN orthogonal to its 
complex conjugate and transposed copy TN
tr
∗
(
)
	
T
T
I
N
N
tr
N
⋅(
)
=
∗
	
(2.19)
is called the unitary transform matrix. For unitary transforms, the Parseval’s 
relationships hold:
a
b
a
a




=
=
=
=
=
=
∗
=
−
∗
=
−
=
−
=
∑
∑
∑
a
b
a
a
a b
a
k
k
k
N
r
r
r
N
k
k
N
r
r
0
1
0
1
2
0
1
2
α β
α
;
0
1
N−
∑
.
	
(2.20)

16
Theoretical Foundations of Digital Imaging Using MATLAB®
The discrete representation of continuous signals (Equation 2.1) can be 
extended to their integral representation if one substitutes in Equations 2.1 
basis function index k by a continuous variable, say f, and replaces the sum 
by the integral
	
a x
f
x f
f
( )
( ) ( , )
.
= ∫α
φ
d
F
	
(2.21)
One can also extend this approach to the definition of α(f) by introducing 
reciprocal functions φ(f,x) to obtain an analog of Equation 2.5:
	
α
ϕ
( )
( ) ( , )
.
f
a x
f x
x
= ∫
d 	
(2.22)
Function α(f) is called the integral transform of signal a(x), or its spectrum 
over continuous basis function {φ(f,x)} called the transform kernel. The reci-
procity condition for functions ϕ(x,f) and φ(f,x) or the condition of transform 
invertibility can be obtained by substituting Equation 2.22 into Equation 2.21:
	
a x
a
f
x f
f
a
f
x
( )
( ) ( , )
( , )
( )
( , ) ( ,
=








=
∫
∫
∫
∫
ξ ϕ
ξ
ξ φ
ξ
ξ ϕ
ξ φ
d
d
d
X
F
F
X
f
f
a
x
)
( ) ( , )
,
d
d
= ∫
ξ δ
ξ
ξ
X
	
(2.23)
where
	
δ
ξ
φ
ϕ
ξ
( , )
( , ) ( , )
.
x
x f
f
f
= ∫
d
F
	
(2.24)
Function δ(x,ξ), defined by Equation 2.24, is called the delta-function (Dirac 
delta). Dirac delta is a continuous analog of the Kronecker delta (Equation 
2.4). It symbolizes orthogonality of kernels ϕ(x,f) and φ(f,x), or, in other words, 
invertibility of the integral transforms of Equations 2.21 and 2.22. Equation 
2.23 can also be regarded as a special case of the signal integral representa-
tion with the delta-function as the integral transform kernel.
Considering Equation 2.24 as an analog to Equation 2.6, one can extend the 
concept of the orthogonal basis to continuous functions as well: basis kernels 
that satisfy the relationship
	
φ
φ
δ
ξ
( , )
( , )
( , )
x f
x f
f
x
∗
∫
=
F
d
	
(2.25)

17
Mathematical Preliminaries
are called self-conjugate. For spectra α1(f) and α2(f) of signals a1(x) and a2(x) 
over self-conjugate bases, the following relationship holds:
	
a x a x
x
f
f
f
1
2
1
2
( )
( )
( )
( )
,
∗
∗
∫
∫
=
d
d
X
F
α
α
	
(2.26)
In particular, this means that signal integral transform with self-conjugated 
kernel preserves signal energy:
	
a x
x
x
f
( )
( )
.
2
2
d
d
X
F
∫
∫
=
α
	
(2.27)
Equations 2.26 and 2.27 are a continuous analog to the Parseval’s relation 
for signal discrete representation (Equation 2.9).
Signal Transformations
In sensory and imaging systems, image signals undergo various transfor-
mations, which convert one signal to another. In general, one can math-
ematically treat signal transformations as a mapping in the signal space. 
For digital signals, this mapping, in principle, can be specified in the form 
of a look-up table. However, even for digital signals, this form of the speci-
fication is not practically feasible owing to the enormous volume of the 
digital signal space (a rough evaluation of it can be seen in Chapter 3). For 
discrete and continuous signals, such a specification is all the more not 
constructive.
This is why in practice signal transformations are mathematically 
described and technically implemented as a combination of certain “elemen-
tary” transformations, each of which is specified with the help of a relatively 
small subset of all feasible input–output pairs. The most important of these 
are point-wise transformations and linear transformations.
Point-wise signal transformation is transformation that results in a signal 
whose value in each point of its argument (coordinate) depends only on the 
value of the transformed signal in the same point:
	
b x
TF a x
( )
[ ( )],
=
	
(2.28)
that is, it is specified as a single argument mathematical function of the 
­signal value. This function TF(.) is referred to as the system transfer func-
tion. If the transfer function is the same in all points in signal coordinates, 

18
Theoretical Foundations of Digital Imaging Using MATLAB®
the transformation is called homogeneous transformation. Generally, the 
transformations are inhomogeneous.
A typical example of a point-wise transformation is conversion of energy 
of light radiation into electrical charge or current in cells of photo-electrical 
light sensors. Units performing element-wise signal conversion are widely 
used in models of imaging systems.
Transformation L( )⋅ is a linear transformation if it satisfies the super­
position principle, which states that the result of transformation of a sum of 
several signals can be found by summation of results of the transformation 
of individual signals:
	
L
( )
L(
( )).
α
α
k
k
k
N
k
k
k
N
a x
a x
=
−
=
−
∑
∑





=
0
1
0
1
	
(2.29)
For linear transforms, one can introduce the notion of the sum of linear 
transforms, that is, ∑n
n
L , n = 1, 2, . . . . The physical equivalent of the sum 
of linear transforms is a parallel connection of units realizing the transform 
items as it is shown in the flow diagram in Figure 2.3.
Assuming the possibility of applying linear transformation to signals, 
which are themselves results of a linear transformation, one can also intro-
duce the notion of the product of linear transforms, ∏n
n
L . The physical 
equivalent of the transformation product is a series (cascade) connection of 
units realizing the transform factors (Figure 2.3b). Thanks to the linearity of 
the transforms, their multiplication is distributive with respect to addition:
	
L (L
L )
L L
L L ;
(L
L )L
L L
L L .
1
2
3
1
2
1
3
1
2
3
1
3
2
3
+
=
+
+
=
+
	
(2.30)
If a linear transformation L performs a one-to-one mapping of a signal, 
then there exists an inverse transformation L−1 such that
	
L (L( ))
.
−
=
1
a
a 	
(2.31)
Linear transform 
(a)
(b)
Linear transform 
Linear transform 
Signal
summation
unit 
Input
signal 
Output
signal 
Input
signal 
Linear transform 
Linear transform 
Linear transform 
Output
signal 
FIGURE 2.3
Flow diagrams of sum (a) and product (b) of linear transforms.

19
Mathematical Preliminaries
A linear transformation b
L a
=
( ) of discrete signals is fully characterized 
by a matrix of coefficients Λ = {
}
,
λk n  that links the input a = {
}
αk  and out-
put b = {
}
βk  pairs of the linear transformation coefficients, respectively (see 
Appendix):
	
β
β
λ
α
n
n
k n
k
k
a
=
=
=
=






∑
L( )
.
,
a
Λ
	
(2.32)
Thus, in order to describe a linear transformation of a discrete signal 
of N samples, it suffices to specify a matrix of N2 numbers. Equation 2.32 
implies that, in the general case, linear transforms are not point-wise, and 
that they become so only if the transformation matrix is a diagonal one, that 
is {
}
,
λ
λ δ
k n
k
k n
=
−
.
For continuous signals, integral transforms are mathematical models of 
linear transformations. Let a continuous signal a(x) be specified by means of 
its spectrum α(f) on basis function {ϕ(a)(x,f)} as it is described by Equations 
2.21 and 2.22 and, in a special case of delta-function basis, by Equation 2.23. 
Then the result b
a x
( )
( )
ξ = L
 of applying to this signal a linear transformation 
L is fully specified by the response h
f
x f
a
( , )
(
( , ))
( )
ξ
φ
= L
 of the linear trans-
formation to the transform kernel
b
f
x f
f
f
x f
f
f
a
a
( )
( )
( , )
( )
( , )
(
( )
( )
ξ
α
φ
α
φ
α
=








=


=
∫
∫
L
L
d
d
F
F
) ( , )
.
h
f
f
ξ
d
F∫
	
(2.33)
For the representation of the linear transformation output signal b(ξ) also 
via its spectrum β(f) over some basis functions ϕ(b)(f,ξ)
	
β
ξ φ
ξ
ξ
( )
( )
( , )
( )
f
b
f
b
= ∫
d
Ξ
	
(2.34)
spectra α(f) and β(f) of a signal a(x) and of its linear transformation b(ξ) are 
also related with an integral transform
	
β
α
( )
( )
( , )
.
f
p H f p
p
= ∫
d
F
	
(2.35)
Its kernel H(f,p) is, in its turn, also an integral transform, with kernel 
ϕ(b)(f,ξ), of the linear transformation response h(ξ,f) to basis functions ϕ(a)(f,ξ), 
in which the spectrum of the signal a(x) is specified
	
H f p
h
p
f
b
( , )
( , )
( , )
.
( )
= ∫
ξ
φ
ξ
ξ
d
	
(2.36)

20
Theoretical Foundations of Digital Imaging Using MATLAB®
Signal integral representation (Equation 2.23) via delta-function is of spe-
cial importance for the characterization of the linear transformations. For 
such a representation, the relationship between output signal b(x) and input 
signal a(x) of a linear transformation (Equation 2.34) is reduced to
	
b
a x h x
x
( )
( ) ( , )
,
ξ
ξ
= ∫
d
X
	
(2.37)
where h x
x
( , )
( ( , ))
ξ
δ
ξ
= L
 is a linear transformation response to a delta func-
tion. It is called the impulse response or the point spread function (PSF) of the 
linear system that implements this transformation. The process of linear 
transformation is called linear filtering, and a unit that performs it is called 
linear filter.
Imaging Systems and Integral Transforms
Direct Imaging and Convolution Integral
In describing imaging systems, it is always assumed that there exist a physi-
cal or imaginary object plane and an image plane and that the primary goal 
of imaging systems is reproducing, in image plane, distribution of light 
reflectance, transmittance, or whatever other physical property of the object 
in the object plane.
Many imaging devices, such as optical microscopes and telescopes, x-ray, 
gamma cameras, scanning electron and acoustic microscopes, and scanned 
proximity probe (atomic force, tunnel) microscopes, work on the principle 
of direct imaging of each point in object plane into a corresponding point in 
image plane. Consider the schematic diagram of photographic and TV imag-
ing cameras shown in Figure 2.4.
Imaging optics is a linear system that performs linear signal transformation. 
It is usually characterized by its PSF h(x,y;ξ,η), which links an image b(x,y) in 
the image plane and light intensity distribution a(ξ,η) in the object plane:
	
b x y
a
h x y
( , )
( , ) ( , ; , )
,
= ∫∫
ξ η
ξ η
ξ
η
d d
Y
X
	
(2.38)
where integration is carried out over the object plane (X, Y). In general, the 
image of a point source depends on the source location in the object plane, 
that is, the PSF is space variant.
An important special case is that of space invariant imaging systems, 
in which the image of a point source does not depend on the point source 

21
Mathematical Preliminaries
location. For space invariant systems, PSF is a function of the difference of 
coordinates in object and image planes, and imaging Equation 2.38 for space 
invariant systems takes the form
	
b x y
a
h x
y
( , )
( , ) (
,
)
=
−
−
−∞
∞
−∞
∞
∫∫
ξ η
ξ
η
ξ
η
d d
	
(2.39)
called 2D convolution integral. Correspondingly, 1D convolution integral is 
defined as
	
b x
a
h x
( )
( ) (
)
.
=
−
−∞
∞
∫
ξ
ξ
ξ
d
	
(2.40)
PSF is one of the basic specification characteristics of imaging systems. It is 
used for certification of imaging systems and characterizes the system capa-
bility to resolve objects, that is, imaging system resolving power. Given the 
noise level in the signal sensor, it determines the accuracy of locating objects 
in images. We will discuss this issue in detail in Chapter 7.
The assumption of imaging system space invariance is used in the descrip-
tion and analysis of imaging systems and image restoration most frequently. 
It enables simplifications both in system analysis and in image processing. If 
the system’s PSF is not shift invariant, one can, for simplifying image analy-
sis and processing, convert images from the original coordinate system into a 
transformed one, in which system PSF becomes space invariant. After space 
invariant processing in the transformed coordinate system is completed, 
image should be converted back to the original coordinates. This principle is 
illustrated by a flow diagram in Figure 2.5.
Ray of light
Object a(ξ,η)
Object plane (ξ,η)
Imaging optics
Image
b(x,y)
Image plane (x,y)
Imaging camera
Photosensitive
sensor
FIGURE 2.4
​Schematic diagram of photographic and TV imaging cameras.

22
Theoretical Foundations of Digital Imaging Using MATLAB®
Integral transforms described by Equations 2.38 and 2.39 are, as a rule, not 
invertible: in general, one cannot perfectly restore system input image a(ξ,η) 
from the output image b(x,y). The restoration task is one of the fundamen-
tal tasks of image processing. It belongs to the so-called inverse problems. 
Methods of image restoration will be discussed in Chapter 8.
Multiresolution Imaging: Wavelet Transforms
It is frequently convenient to combine applying convolutional signal trans-
forms to signals a(x) taken at an arbitrary scale and to perform multiresolu-
tion analysis in this way. This leads to integral transforms that was given the 
name of wavelet transforms.
Consider 1D convolution integral for signal a(x) taken in scaled coordinates 
σx:
	
a
x
a
h
x
WL
( ; )
(
)
(
)
,
σ
σξ
ξ
ξ
=
−
−∞
∞
∫
d
	
(2.41)
where σ is a scale parameter. This convolution with PSF hWL(.) depends on 
both scale parameter σ and coordinate x. In Equation 2.41, signal is taken at 
different scales and convolution kernel is kept the same. One can now trans-
late signal scaling into convolution kernel scaling by changing variables 
σξ → ξ and obtain
	
a
x
a
h
x
WL
( ; )
( )
σ
σ
ξ
σ
ξ
σ
ξ
=
−




−∞
∞
∫
1
d
	
(2.42)
or, in scaled coordinates σx → x:
	
a
x
a
h
x
WL
( ; )
( )
.
σ
σ
ξ
ξ
σ
ξ
=
−




−∞
∞
∫
1
d
	
(2.43)
Coordinate
conversion
Space
invariant
processing  
Inverse
coordinate
conversion  
Space variant system
Output
image 
Input
image 
FIGURE 2.5
The principle of space invariant representation of space variant systems.

23
Mathematical Preliminaries
Integral transform defined by Equation 2.43 is called the wavelet transform.
In 1D wavelet transforms, transform domain argument of the kernel func-
tion has two components: coordinate shift ξ and scale σ. There exist many 
wavelet transforms that differ from one another in the selection of the trans-
form kernel hWL( )⋅ called the “mother wavelet.” This selection is the main 
issue in the design of wavelet transforms and is governed by the require-
ment of the invertibility of the transform and by implementation issues. One 
of the simplest examples of the wavelet transforms is Haar transform. The 
kernel of Haar transform (Haar transform mother wavelet) is a bipolar func-
tion shown in Figure 2.6 and is defined as
	
h
x
x
x
WL( ; )
σ
σ
σ
=



−
−




rect
rect
2
2
1
	
(2.44)
where rect(.) is a rect-function:
	
rect
otherwise
( )
,
,
.
x
x
=
≤
<



1
0
1
0
	
(2.45)
Two-dimensional and multidimensional wavelets are usually defined as 
separable functions of coordinates.
Imaging in Transform Domain and Diffraction Integrals
The invention of holography by D. Gabor [1] heralded a new stage in the 
­evolution of imaging methods: imaging in the transform domain. Instead of 
recording an image of an object, D. Gabor suggested recording the amplitude 
and the phase of the wavefront of coherent radiation propagated from the 
object to the recording device. He named the recorded wavefront as hologram.
In order to describe a mathematical model of wave propagation and 
recording holograms, consider the 1D model of free space wave propagation 
shown in Figure 2.7.
1
0.5
1
–1
x
FIGURE 2.6
“Mother wavelet” of Haar transform.

24
Theoretical Foundations of Digital Imaging Using MATLAB®
Let the complex amplitude of the wavefront of a monochromatic ­radiation 
in coordinate x at the object (input) plane be a x
a x
i
x
( ) | ( )|exp(
( ))
=
Φ
, where 
|
|
a x
( )  is the wavefront amplitude equal to the square root of its inten-
sity and Φ(x) is called the wavefront “phase.” Let the “output” (hologram) 
plane, in which the hologram is recorded, also be situated at a distance Z 
from the object plane. The wavefront, which traveled from a point x in the 
object plane to a point with coordinate f in the hologram plane a distance 
Z
x
f
2
2
+
−
(
) , will be attenuated proportionally to this distance, and a 
phase delay 2
2
2
π
λ
Z
x
f
+
−
(
) /  is obtained, where λ is the wavelength of 
the coherent radiation. Then, one can conclude that the PSF of free space 
wave ­propagation is
	
h x f
i
Z
x
f
Z
x
f
( , )
exp(
(
)
)
(
)
.
=
+
−
+
−
2
2
2
2
2
π
λ
	
(2.46)
Accordingly, 2D PSF of free space wave propagation from input plane (x, y) 
to output plane (fx, fy) is
	
h x y f
f
i
Z
x
f
y
f
Z
x
f
y
f
x
y
x
y
x
y
( , ;
,
)
exp(
(
)
(
)
)
(
)
(
)
=
+
−
+
−
+
−
+
−
2
2
2
2
2
2
2
π
λ .
	
(2.47)
The relationship between complex amplitudes a(x,y) and α(fx,fy) of the wave-
front in the input and output planes, respectively, is then the integral transform
   
α
π
λ
(
,
)
( , ) exp(
(
)
(
)
)
(
)
(
f
f
a x y
i
Z
x
f
y
f
Z
x
f
y
f
x
y
x
y
x
y
=
+
−
+
−
+
−
+
−
2
2
2
2
2
2
)
.
2
d d
x
y
−∞
∞
−∞
∞
∫∫
	
(2.48)
Input (object) plane
a(x)
a(x)exp i2π
Z2 + (x–f )2
Z 2 + (x–f )2
λ
x
Ray of radiation
f
Z
Output (hologram) plane
FIGURE 2.7
Free space wave propagation point spread function.

25
Mathematical Preliminaries
This integral transform is called Kirchhoff’s integral.
Assume now that the size of the object and dimensions of the area, over 
which the hologram is recorded, are substantially smaller than the distance 
Z between the input object plane (x, y) and the hologram plane (fx, fy), that is, 
approximated relationships:
	
Z
x
f
y
f
Z
i
Z
x
f
y
f
i
x
y
x
y
2
2
2
2
2
2
2
+
−
+
−
≅
+
−
+
−





=
(
)
(
)
exp
(
)
(
)
exp
π
λ
2
1
2
2
2
2
2
π λ
π
λ
Z
x
f
y
f
Z
i
x
f
y
f
Z
x
y
x
y
+
−
+
−






≅
−
+
−





(
)
(
)
exp
(
)
(
)

	
(2.49)
hold. In this approximation, Kirchhoff’s integral is reduced, after omitting 
an unessential scalar multiplier, to its Fresnel approximation:
	
α
π
λ
(
,
)
( , )exp
(
)
(
)
.
f
f
a x y
i
x
f
y
f
Z
x
y
x
y
x
y
=
−
+
−






−∞
∞
−∞
∞
∫∫
2
2
d d
	
(2.50)
that describes the so-called near zone diffraction. Equation 2.50 can alterna-
tively be written as
	
α
π
λ
π
λ
(
,
)exp
( , )exp
exp
f
f
i
f
f
Z
a x y
i
x
y
Z
x
y
x
y
−
+




=
+




−
2
2
2
2
i
xf
yf
Z
x
y
x
y
2π
λ
+




−∞
∞
−∞
∞
∫∫
d d .
	
(2.51)
If, furthermore, distance Z is so large that one can neglect phase variations 
[ (
)
]
π
λ
f
f
Z
x
y
2
2
+
/
 and [ (
)
]
π
λ
x
y
Z
2
2
+
/
, we arrive at the far zone diffraction, or 
Fraunhofer approximation of Kirchhoff’s integral:
	
α
π
λ
(
,
)
( , )exp
.
f
f
a x y
i
xf
yf
Z
x
y
x
y
x
y
=
−
+




−∞
∞
−∞
∞
∫∫
2
d d
	
(2.52)
Equation 2.52 also describes the relationship between wavefront complex 
amplitudes in front and rear focal planes of lenses. Consider a 1D model of a 
lens shown in Figure 2.8.

26
Theoretical Foundations of Digital Imaging Using MATLAB®
Lens is fully defined by its property to convert light from a point source in 
the lens focal plane into a parallel beam with plain wavefront tilted accord-
ing to the position of the source with respect to lens optical axis. One can use 
this property to determine the PSF of a lens. One can see from the diagram in 
Figure 2.8 that, at point f in the lens rear focal plane, the plane wavefront origi-
nated from a point source of monochromatic light in coordinate (−x) is delayed 
with respect to the point at the lens optical axis by distance ∆=
−
f
x F
sin(
)
/
, 
where F is the lens focal length. In the so-called paraxial approximation, when 
x ≪ F, Δ = −xf/F. This implies that the PSF of optical systems, whose input and 
output planes are front and rear focal planes of a lens, is
	
h x f
i
i
fx
F
( , )
exp(
)
exp
=
=
−




2
2
π
λ
π λ
∆/
	
(2.53)
and complex amplitudes a(x) and α(f) of monochromatic light wavefront in 
frontal and rear focal planes of a lens are, therefore, linked by the relationship
	
a f
a x
i
fx
F
x
X
( )
( )exp
,
=
−




∫
2π λ
d
	
(2.54)
or, in 2D denotation
	
a f
f
a x y
i
f x
f y
F
x
y
x
y
x
y
(
,
)
( , )exp
.
=
−
+




∫∫
2π
λ
d d
Y
X
	
(2.55)
From the schematic diagram in Figure 2.8, it follows that lenses can also 
be considered as spatial light phase modulators that add to the phase of the 
Point
source
F 2 + ξ2
Lens optical axis
F
–x
a(x)
F
Plain
wavefront
Light ray
f
α( f )
ξ
Δ = f
x
F
FIGURE 2.8
​Schematic diagram of wave propagation between focal planes of a lens.

27
Mathematical Preliminaries
incident light a component, which is a quadratic function of the distance 
from the lens optical axis. Indeed, a spherical wave at point ξ in the lens 
plane emanated from a point source at the optical axis in the input plane has 
a phase defined by the distance F2
2
+ ξ  it propagated. Hence, its complex 
amplitude is
	
A
i
F
∝
+






exp
.
2
2
2
π
ξ
λ
	
(2.56)
In the paraxial approximation, when the size of the lens is much smaller 
than its focal distance, wave amplitude is approximately
	
A
A
i
F
∝




0
2
exp
.
π ξ
λ
	
(2.57)
Because this spherical wave is converted by the lens into a plain wavefront, 
complex transparency of the lens is then inverse of the function defined by 
Equation 2.57:
	
T
i
F
=
−




exp
.
π ξ
λ
2
	
(2.58)
One can rewrite Equations 2.50, 2.52, 2.54, 2.56, and 2.57 in dimension-
less coordinates normalized by λZ  or, correspondingly, by λF . In such 
normalized coordinates, obtain, after neglecting inessential constant factors
α
π
λ
λ
λ
λ
(
,
)
( , )
exp
[(
)
(
)]
[(
f
f
a x y
i
Z
z
x
f
y
f
Z
Z
x
f
x
y
x
y
x
=
−
+
−
+
−
{
}
+
−
2
2
2
2
)
(
)]
,
2
2
+
−
−∞
∞
−∞
∞
∫∫
y
f
x
y
y
d d
	
(2.59)
where Z
Z
λ
λ
=
 is a dimensionless distance parameter
	
α
π
(
,
)
( , )exp{
[(
)
(
) ]}
f
f
a x y
i
x
f
y
f
x
y
x
y
x
y
=
−
−
+
−
−∞
∞
−∞
∞
∫∫
2
2
d d
	
(2.60)
and
	
α
π
( )
( )exp(
)
f
a x
i
fx
x
=
−∞
∞
∫
2
d
	
(2.61)

28
Theoretical Foundations of Digital Imaging Using MATLAB®
	
a f
f
a x y
i
f x
f y
x
y
x
y
x
y
(
,
)
( , )exp[
(
)]
.
=
+
−∞
∞
−∞
∞
∫∫
2π
d d
	
(2.62)
We will refer to Equation 2.59 as integral Kirchhoff transform. Integral trans-
form defined by Equation 2.60 is called integral Fresnel transform. Integral 
transforms defined by Equations 2.61 and 2.62 are 1D and 2D integral Fourier 
transforms.
Fresnel transform is very closely connected with Fourier transform and 
can be reduced to it by means of phase modulation of signal and its spectrum 
with chirp-functions chirp( )
exp(
)
x
i x
=
−π
2  and chirp( )
exp(
)
f
i f
=
−π 2 :
	
α
π
π
π
Fr
d
( )
exp(
)
( )exp(
)exp(
)
f
i f
a x
i x
i
fx
x
=
−
−
−∞
∞
∫
2
2
2
	
(2.63)
Fresnel transform can also be regarded as a convolutional transform and, 
as such, it can also be linked with Fourier transform through the convolution 
theorem (see the next section): Fresnel transform αFr(f) of a signal a(x) can be 
found as inverse Fourier transform
	
α
α
π
π
Fr
F
d
( )
( )exp(
)exp(
)
f
p
i p
i
fp
p
=
−
−∞
∞
∫
2
2
	
(2.64)
of a product of the signal Fourier spectrum αF(p) and the Fourier transform 
of the chirp-function which, to the accuracy of an irrelevant constant, is (see 
Appendix) function chirp ( )
exp(
)
∗
=
p
i p
π
2 :
	
exp(
)exp(
)
exp
.
−
∝




−∞
∞
∫
i
x
i
px
x
i
p
πω
π
π ω
2
2
2
2
2
d
	
(2.65)
The transform defined by Equation 2.64 is called angular spectrum propaga-
tion transform.
Integral Kirchhoff transform (Equation 2.59) is also a convolution and can, 
therefore, also be represented, using the convolution theorem, which we 
present in the section “Properties of the Integral Fourier Transform” that fol-
lows, via Fourier transform:
   
α
α
π
K
x
y
x
y
x
y
x
x
y
y
x
y
f
f
p
p K p
p
i
f p
f p
p
p
(
,
)
(
,
) (
,
)exp[
(
)]
=
−
+
−∞
∞
−∫
F
d
d
2
∞
∞
∫
,
	
(2.66)

29
Mathematical Preliminaries
where αF(px,py) is the signal Fourier spectrum and kernel K(px,py) is the 
Fourier transform of the kernel of the Kirchhoff integral transform
	
K p
p
i
d
d
x
f
y
f
d
d
x
f
y
x
y
x
y
x
(
,
)
exp
[(
)
(
)]
[(
)
(
=
−
+
−
+
−
{
}
+
−
+
−
π
λ
λ
λ
λ
2
2
2
2
2
f
i
f p
f p
x
y
y
x
x
y
y
)]
exp[
(
)]
.
2
2
−∞
∞
−∞
∞
∫∫
−
+
π
d d
	
(2.67)
Properties of the Integral Fourier Transform
Integral Fourier transform plays an exceptional role in image processing. 
Apart from its fundamental role in mathematical representation of signal 
transformations in wave propagation and image formation described in 
the previous section, it has, in its discrete representation as discrete Fourier 
transform (DFT, see Chapter 4), a remarkable property of efficient compu-
tation via fast Fourier transform. Integral Fourier transform also represents 
a very convenient tool for linking all linear transforms. In this section, we 
overview the main properties of the integral Fourier transform.
In order to make derivations more compact, we will, when it will be con-
venient, treat 2D coordinates (x, y) and (fx, fy) as two-component vectors 
x = [
]
x
y  and f = [
]
f
f
x
y . In such denotation, the 2D integral Fourier 
transform is written as
	
α
π
( )
( )exp(
)
,
f
x
x f
x
=
−∞
∞
∫a
i
tr
2
d
	
(2.68)
where xtr is transposed vector x. Equation 2.68 can also be generally regarded 
as a multidimensional integral transform assuming that x and f can be, in 
general, more than two component vectors. We call this transform the direct 
integral Fourier transform.
The most important properties of the integral Fourier transform are the 
following.
Invertibility
Integral Fourier transform is invertible. It is proved in the theory of Fourier 
integral that signal a(x) can be found from its Fourier spectrum α(f) as
	
a
i
i
tr
tr
( )
lim
( )exp(
)
( )exp(
)
x
f
f
x
f
f
f
x
f
F
F
=
−
⋅
=
−
⋅
→∞
−∞
∞
∫
∫
α
π
α
π
2
2
d
d .
	
(2.69)

30
Theoretical Foundations of Digital Imaging Using MATLAB®
Integral
	
a
i
tr
( )
( )exp[
]
x
f
f
x
f
=
−
⋅
−∞
∞
∫α
π
2
d
	
(2.70)
is called the inverse integral Fourier transform. Equations 2.69 and 2.70 
imply that the kernel of the integral Fourier transform is self-conjugate and 
delta function, which symbolizes the transform invertibility, is defined as
	
δ
ξ
π
ξ
( , )
lim
exp[
(
)]
.
x
f
x
f
F
F
=
⋅
−
→∞∫
i
tr
2
d
	
(2.71)
In a special case of 1D integral Fourier transform:
	
δ
ξ
π
ξ
π
ξ
(
)
lim
exp[
(
)]
lim{
sinc[
(
)]}
x,
i
f x
f
F
F x
F
F
F
F
=
−
=
−
→∞
−
→∞
∫
2
2
2
d
,,
	
(2.72)
where
	
sinc( )
sin
x
x
x
=
	
(2.73)
is the so-called sinc-function. According to this definition, sinc-function is the 
Fourier transform
	
sinc(
)
rect
exp(
)
2
2
2
π
π
Fx
f
F
F
i
fx
x
=
+




−∞
∞
∫
d
	
(2.74)
of the rect-function (Equation 2.45).
The invertibility of integral Fourier transform is a mathematical idealiza-
tion. In practice, integration in Fourier transform is always implemented in 
finite limits defined by aperture of optical systems, dimensions of lenses, 
and similar factors. These limitations are referred to as bandwidth limita-
tions. Owing to the bandwidth limitations, artifacts known as Gibb’s effects 
may appear in the form of oscillations at signal sharp edges. Figure 2.9 
illustrates the appearance of oscillations caused by signal Fourier spectrum 
band-limitation for a signal in the form of a rectangular wave. As one can 
see, the oscillations do not disappear on widening the signal bandwidth; 
they only become tighter.

31
Mathematical Preliminaries
Separability
It follows from the definition of 2D integral Fourier transform (Equation 2.62) 
that it is separable to two 1D transforms:
	
a f
f
a x y
i
f x
f y
x
y
i
f y
y
x
y
x
y
y
(
,
)
( , )exp[
(
)]
exp(
)
=
+
=
−∞
∞
−∞
∞
∫∫
2
2
π
π
d d
d
a x y
i
f x
x
x
( , )exp(
)
.
2π
d
−∞
∞
−∞
∞
∫
∫
	
(2.75)
Shift Theorem: Absolute value of signal Fourier spectrum is invariant to signal 
shift. Signal shift causes only linear modulation of the phase of the spectrum.
Proof. From Equation 2.61, it follows that
	
a
i
i
tr
tr
(
)
( )exp[
(
)]
[ ( )exp(
)]
x
x
f
f
x
x
f
f
f
x
−
=
−
⋅
−
=
⋅
−∞
∞
∫
0
0
0
2
2
α
π
α
π
d
exp[
]
−
⋅
−∞
∞
∫
i
tr
2πf
x
f
d
	
(2.76)
which implies that if Fourier spectrum of a(x) is α(f), spectrum of a(
)
x
x
−
0  is 
α
π
( )exp(
)
f
f
x
i
tr
2
0
⋅
, and that the absolute value of signal Fourier spectrum is 
invariant to the signal shift.
No band
limitation
Bandwidth
(–F1,F1)
Bandwidth
(–F2,F2)
Bandwidth
(–F3,F3)
F1>F2>F3
FIGURE 2.9
​Illustration of signal oscillation caused by signal band limitation. From top to bottom: signal 
with no band limitation and signals with more and more severe band limitations.

32
Theoretical Foundations of Digital Imaging Using MATLAB®
Rotation Theorem: Signal rotation results in the same rotation of its spectrum.
Proof. In vector-matrix denotation of signal and spectrum coordinates, signal 
rotation by an angle ϑ can be represented as multiplication of coordinate vec-
tor x by a rotation matrix Rot 	
Rotϑ
ϑ
ϑ
ϑ
ϑ
=
−




cos
sin
sin
cos
.
	
(2.77)
Then, from Equations 2.68 and 2.77, we obtain, using matrix identity 
f
Rot
Rot
f
Rot
f
tr
tr
tr
tr
⋅
=
=
−
ϑ
ϑ
ϑ
((
)
)
(
)  that
	
a
i
i
tr
tr
(
)
( )exp(
(
))
( )exp(
(
Rot
x
f
f
Rot
x
f
f
f
ϑ
ϑ
α
π
α
π
⋅
=
−
⋅
⋅
=
−
−∞
∞
∫
2
2
d
⋅
⋅
=
−
⋅
⋅
=
−∞
∞
−∞
∞
∫
∫
Rot
x
f
f
Rot
f
x
f
f
ϑ
ϑ
α
π
α
)
)
( )exp(
((
)
))
( )exp
d
d
i
tr
2
(
((
)
))
.
−
⋅
⋅
−
−∞
∞
∫
i
tr
2π
ϑ
Rot
f
x
f
d
	
(2.78)
Changing variables Rot
f
f
−⋅
→
ϑ
 and using the fact that the Jacobean of 
this coordinate conversion is unity
	
J(
)
cos
sin
Rot−
=
+
=
ϑ
ϑ
ϑ
2
2
1 	
(2.79)
finally obtain
	
a
i
(
)
(
)exp(
)
.
Rot
x
Rot
f
f x
f
ϑ
ϑ
α
π
⋅
=
⋅
−
⋅
−∞
∞
∫



2
d
	
(2.80)
Therefore, if the Fourier spectrum of 2D signal a(x) is α(f), the spectrum of 
rotated signal a(
)
Rot
x
ϑ ⋅
 is α
ϑ
(
)
Rot
f
⋅
.
Scaling Theorem: Scaling signal coordinates σ times causes 1/σ scaling of 
its spectrum magnitude and spectrum coordinates.
Proof. From Equation 2.68, obtain
	
a
i
i
(
)
( )exp[
(
)]
( )exp[
(
)
]
σ
α
π
σ
α
π σ
x
f
f
x
f
f
f
x
f
=
−
⋅
=
−
⋅
=
−∞
∞
−∞
∞
∫
∫
2
2
d
d
1
1
2
σ
α σ
π
f
f x
f




−
⋅
−∞
∞
∫
exp(
)
.
i


d
	
(2.81)

33
Mathematical Preliminaries
Therefore, if the Fourier spectrum of signal a(x) is α(f), the Fourier spec-
trum of scaled signal a(σx) is (1/σ)α((a/σ)f).
Convolution Theorem: The inverse Fourier transform of product α(f)β(f) of 
spectra of two signals a(x) and b(x) is convolution 
a
b
( ) (
)
ξ
ξ
ξ
x −
−∞
∞∫
d  of these 
signals.
Proof.
α
β
π
ξ
π
ξ
ξ
( ) ( )exp(
)
( )exp(
)
f
f
f x
f
f
−
=








−∞
∞
−∞
∞
∫
∫
i
a
i
tr
tr
2
2
d
d
β
π
ξ
β
π
ξ
( )exp(
)
( )
( )exp(
(
))
f
f x
f
f
f
x
f
−
=
−
−


−∞
∞
−∞
∞
∫
∫
i
a
i
tr
tr
2
2
d
d






=
−
−∞
∞
−∞
∞
∫
∫
d
d
ξ
ξ
ξ
ξ
a
b
( ) (
)
.
x
	
(2.82)
Convolution theorem links integral Fourier transform and convolution 
integral. It shows that image convolution can also be treated in terms of mod-
ulation of image Fourier spectra by Fourier transform FR(f) of the convolu-
tion integral kernel, PSF h(x) of the space invariant imaging system:
	
FR
d
( )
( )exp(
)
.
f
x
fx
x
=
−∞
∞
∫h
i2π
	
(2.83)
Function FR(f) is called the system frequency response or modulation transfer 
function.
Symmetry Properties
Signal and their spectra symmetry properties straightforwardly follow from 
the definition of the Fourier transform and are summarized in the following 
equations, in which symbol * means complex conjugation.
For even (odd) signals:
	
a
a
( )
(
)
( )
(
).
x
x
f
f
= ±
−
←
→

= ±
−
Fourier transform
α
α
	
(2.84)
For purely real (imaginary) signals:
	
a
a
( )
( )
( )
(
).
x
x
f
f
= ±
←
→

= ±
−
∗
∗
Fourier transform
α
α
	
(2.85)

34
Theoretical Foundations of Digital Imaging Using MATLAB®
For even purely real (imaginary) signals:
	
a
a
a
( )
(
)
( )
( )
(
)
(
x
x
x
f
f
f
=
−
= ±
←
→

=
−
= ±
−
∗
∗
Fourier transform
α
α
α
). 	
(2.86)
For odd purely real (imaginary) signals:
	
a
a
a
( )
(
)
( )
( )
(
)
(
x
x
x
f
f
= −
−
= ±
←
→

= −
−
= ±
∗
∗
Fourier transform
α
α
α −f).	 (2.87)
Proofs of these relationships are provided in Appendix.
Parseval’s Relationship: The Fourier spectra of signals preserve signal energy
Proof.
a
a
a
a
i
( )
( )
( )
( )
( )exp(
)
x
x
x
x
x
x
f
fx
f
2
2
d
d
d
−∞
∞
∗
−∞
−∞
∫
∫
=
=
−








α
π
∗
−∞
∞
−∞
∞
∗
−∞
−∞
∗
−∞
∞
∫
∫
∫
∫
=
=
=
d
d
d
d
x
f
f
x
fx
x
f
f
f
α
π
α
α
( )
( )exp(
)
( )
( )
a
i2
α( )
.
f
f
2 d
−∞
∞
−∞
∞
∫
∫
	
(2.88)
Transforms in Sliding Window (Windowed Transforms) and Signal 
Sub-Band Decomposition
Up to now, Fourier integral transform as well as other integral transforms 
were defined as “global transforms” of signals over infinite intervals. In real-
ity, however, only finite fractions of the signals selected by the signal sensor 
area are to be or should be analyzed. This can be mathematically modeled by 
signal windowing. In this way, we arrive at windowed transforms:
	
α
ξ
ξ φ
ξ
ξ
( , )
( ) (
) ( , )
,
x f
w
a x
f
=
−
−∞
∞
∫
d
	
(2.89)
where ϕ(f, ξ) is a transform kernel and w(ξ) is a window function such that 
it is close to 1 within a certain vicinity to point ξ = 0 and then more or less 
rapidly decays to zero:
	
w
w
( )
;
lim
( )
.
0
1
0
=
=
→∞
ξ
ξ
	
(2.90)
Windowed transforms of signal a(x) are defined for every point x in signal 
coordinate system and are usually computed in a process of regular signal 
scanning along its coordinate. It is in this sense that they will be referred to 
as sliding window transforms.

35
Mathematical Preliminaries
One of the most important sliding window transforms is sliding window 
Fourier transform (SWFT). It is defined as
	
α
ξ
ξ
π ξ
ξ
( , )
( ) (
)exp(
)
.
x f
w
a x
i
f
=
−
−∞
∞
∫
2
d
	
(2.91)
SWFT of 1D signals is a function of two variables: coordinate x in signal 
domain and frequency f in Fourier domain. At each window position x, it 
represents what one can call signal local spectrum, that is, spectrum of a 
(windowed) signal segment centered at x. This spectrum, being regarded 
as a function of coordinate x that defines window running position and of 
frequency f, is called signal space–frequency representation (time–frequency 
representation, in the communication engineering jargon).
From the inverse Fourier transform of the windowed Fourier transform 
spectrum α(x, f), one can obtain
	
w
a x
x f
i
f
f
( ) (
)
( , )exp(
)
.
ξ
ξ
α
π ξ
−
=
−
−∞
∞
∫
2
d
	
(2.92)
By virtue of Equation 2.90, it follows from Equation 2.92 that
	
a x
x f
f
( )
( , )
.
=
−∞
∞
∫α
d
	
(2.93)
Equation 2.93 can, therefore, be regarded as inverse SWFT.
The window function of SWFT can be an arbitrary function that satisfies 
Equation 2.90. A special case of SWFT with the window function
	
w( )
exp
ξ
ξ
ω
=
−




2
2
2
	
(2.94)
with ω as a window width parameter is known as Gabor transform.
One can give one more and very instructive interpretation to windowed 
Fourier transform. Equation 2.91 represents a convolution integral with 
convolution kernel w
i
f
( )exp(
)
ξ
π ξ
2
. Therefore, according to the convolution 
theorem, Fourier transform of the signal local spectrum α(x, f) at frequency 
f over variable x
	
Α( , )
( , )exp(
)
p f
x f
i
px
x
=
−∞
∞
∫α
π
2
d
	
(2.95)

36
Theoretical Foundations of Digital Imaging Using MATLAB®
is a product
	
Α( , )
( )
( )
p f
p W p
f
= α
	
(2.96)
of the signal “global” Fourier spectrum
	
α
π
( )
( )exp(
)
p
a x
i
px
x
=
−∞
∞
∫
2
d
	
(2.97)
and Fourier transform Wf(p):
	
W p
w
i
f
i
p
w
i
p
f
f ( )
[ ( )exp(
)]exp(
)
( )exp[
(
)]
=
=
+
−∞
∞
∫
ξ
π ξ
π ξ
ξ
ξ
π
ξ
2
2
2
d
d
==
+
−∞
∞
∫
W p
f
(
)
	
(2.98)
of the convolution kernel w
i
f
( )exp(
)
ξ
π ξ
2
, that is, the Fourier spectrum of the 
window function w(ξ) shifted by f. Therefore, signal space–frequency repre-
sentation α(x, f) as a function of x for frequency parameter f can be regarded 
as the signal’s “sub-band” formed by extracting signal frequency compo-
nents around frequency f by means of a spectral window function W(p + f) 
as it is described by Equation 2.96.
This is also true for a general sliding window transformation (Equation 
2.89): sliding window signal transformation results in signal sub-bands 
formed by means of windowing, in the frequency domain, of signal spec-
trum by a function equal to Fourier transform of the corresponding win-
dowed basis functions:
	
W p
w
f
i
p
f ( )
( ) ( , )exp(
)
.
=
−∞
∞
∫
ξ φ
ξ
π ξ
ξ
2
d
	
(2.99)
It is in this sense that we call sliding window signal transformations signal 
sub-band decomposition.
As one can see from the definition of wavelet transform given by Equation 
2.43, wavelet transforms are, for each particular scale, signal convolutions 
as well. Therefore, they can also be treated as signal sub-band decomposi-
tions formed, in the frequency domain, by Fourier transform of the wavelet 
mother function on the corresponding scale:
	
W p
i
p
s( )
exp(
)
.
=




−∞
∞
∫φ ξ
σ
π ξ
ξ
2
d
	
(2.100)

37
Mathematical Preliminaries
This property establishes a link between wavelet and sliding window 
transforms.
Imaging from Projections and Radon Transform
One of the most important relatively recent findings in image science and 
technology is the discovery that image can be formed from its projections. 
This discovery has resulted in various methods of computed tomography 
and manifested the first signs of computational imaging. Image projection 
and reconstruction from projections are described by direct and inverse 
Radon transforms.
Consider an illustrative diagram of object parallel beam projection tomog-
raphy shown in Figure 2.10. According to this figure, the projection of a 2D 
signal a(x, y), specified in a Cartesian coordinate system (x, y), onto an axis ξ 
rotated with respect to the axis x by the angle ϑ is defined as
	
Pr
a x y
x
y
x
y
Y
X
( , )
( , ) (
cos
sin
)
.
ϑ ξ
δ ξ
ϑ
ϑ
=
−
−
∫∫
d d
	
(2.101)
Parallel beam of x-rays
Line array of x-ray
sensitive sensors
ξ
ξ
y
a(x,y)
x
Pr(   ,ξ)
FIGURE 2.10
Parallel beam projection tomography.

38
Theoretical Foundations of Digital Imaging Using MATLAB®
This integral transform that links object signal and its projection is called 
the direct Radon transform. Projection signal Pr( , )
ϑ ξ  is called the sinogram.
Radon transform and Fourier transform of 2D objects are linked with each 
other. To show this, compute 1D Fourier transform, over coordinate ξ, of pro-
jection Pr( , )
ϑ ξ  defined by Equation 2.101:
 
α
ϑ ξ
π ξ
ξ
δ ξ
ϑ
ϑ
ϑ( )
( , )exp(
)
( , ) (
cos
sin
)
f
Pr
i
f
a x y
x
y
x
y
Y
=
=
−
−
−∞
∞
∫
∫
2
d
d d
X
i
f
a x y
i
fx
fy
∫
∫






=
+
−∞
∞
exp(
)
( , )exp[
(
cos
sin
)
2
2
π ξ
ξ
π
ϑ
ϑ
d
]
(
cos
,
sin
),
d d
x
y
f
f
f
f
Y
X
x
y
∫∫
=
=
α
ϑ
ϑ
=
	
(2.102)
where α(fx, fy) is 2D Fourier spectrum of a(x, y). Equation 2.102 is a 
­mathematical formulation of the projection theorem that links Radon and 
Fourier transforms:
1D Fourier transforms αϑ( )f  of object projections Pr( , )
ϑ ξ  is a cross section 
α
ϑ
ϑ
( cos
,
sin
)
f
f
 of 2D object Fourier spectrum α(fx, fy) taken at angle ϑ.
From the projection theorem, it follows that inverse Radon transform can 
be computed as 2D inverse Fourier transform of projections’ spectra αϑ( )f  in 
polar coordinate system ( ,
)
f   :
   
a x y
f
i
f
f
f
f
f
( , )
( )exp[
( cos
sin
)]
( cos
,
si
=
−
+
=
−∞
∞
−∫∫
α
π
ϑ
ϑ
ϑ
α
ϑ
ϑ
π
π
2
d
d
n
)exp[
( cos
sin
)]
.
ϑ
π
ϑ
ϑ
ϑ
π
π
−
+
−∞
∞
−∫∫
i
f
f
f
2
d
d
	
(2.103)
This method of computing inverse Radon transform is called the Fourier 
reconstruction method. Yet another method of inverting Radon transform, 
the filtered back projection method, is also derived from the interrelation 
between Fourier and Radon transforms.
2D function a(x,y) can be found from its 2D Fourier spectrum α(fx, fy) as
	
a x y
f
f
i
f x
f x
f
f
x
y
x
y
x
y
( , )
(
,
)exp[
(
)]
.
=
−
+
−∞
∞
−∞
∞
∫∫
α
π
2
d
d
	
(2.104)

39
Mathematical Preliminaries
In polar coordinate system (f, θ) in the frequency domain (see Figure 2.11)
	
f
f
f
f
f
f
f
f
x
y
x
y
=
=
=
∈
cos ;
sin ;
;
[ , ]
θ
θ
θ
θ
π
d
d
d d
0
	
(2.105)
obtain
	
a x y
f
f
i
f x
y
f
FBproj x
( , )
( , )exp[
( cos
sin )]
( c
=
−
+
=
−∞
∞
∫
∫d
d
θ
α
θ
π
θ
θ
π
2
0
os
sin )
,
θ
θ
θ
π
+
∫
y
d
0
	
(2.106)
where
 
FBproj x
y
f
f
i
f x
y
f
( cos
sin )
( , )exp[
( cos
sin )]
.
θ
θ
α
θ
π
θ
θ
+
=
−
+
−∞
∞
∫
2
d
	
(2.107)
Spectrum α
ϑ
( ,
)
f
 is a cross section of the object’s 2D Fourier spectrum 
along a straight line that goes under angle ϑ, and, according to the projec-
tion theorem, it is 1D Fourier spectrum αϑ( )f  of object projection Pr( , ).
ϑ ξ  
Therefore, Equation 2.107 describes the reconstruction of object sig-
nal a(x, y) by means of accumulating (integration over all angles θ from 
θ = 0 to θ = π) of “back projections” (replication of FBproj x
y
( cos
sin )
θ
θ
+
 
along straight lines x cos θ + y sin θ = ξ for all ξ) of its “filtered projec-
tions” FBproj x
y
( cos
sin )
θ
θ
+
. Filtering of projections defined by Equation 
2.107, using as frequency response of the filter ramp-function f  is called 
ramp-filtering.
fy
f
fx
α(f, ϑ)
f cos ϑ
f cos ϑ
ϑ
FIGURE 2.11
Cartesian and polar coordinate systems in Fourier transform domain.

40
Theoretical Foundations of Digital Imaging Using MATLAB®
Statistical Models of Signals and Transformations
Principles of Statistical Treatment of Signals and Signal Transformations 
and Basic Definitions
The survey of mathematical models of signal transformations will not 
be complete without considering statistical approaches to signals and 
­transformations. The need in statistical treatment of a signal arises because 
any processing is designed to be performed on a certain set of signals rather 
than on a particular signal and the quality of processing is evaluated on 
average over this set. Therefore, for the design and optimization of process-
ing, one has to specify (i) a set of signals, or “signal ensemble,” (ii) a measure 
of processing quality of individual signals, and (iii) a method of averaging 
over the ensemble of the quality measure found for each signal of the ensem-
ble. We will denote signal ensembles as ΩA and operation of averaging of a 
numerical measure V over ensemble ΩA as AV
V
A
Ω( ). For ensembles of digi-
tal signals, the averaging is conventionally performed as weighted summa-
tion and for continuous signals it is performed as weighted integration of the 
measure over the signal ensemble:
	
AV V
W V
AV V
W
V
Ω
Ω
Ω
Ω
( )
,
( )
( ) ( )
,
=
=
∈∑
∫
ω
ω
ω
ω
ω
ω
d
	
(2.108)
where Wω and W(ω) are weight coefficients and, correspondingly, ­weighting 
function, ω is an index of the element of ensemble, and Vω and V(ω) are 
numerical measures to be averaged for the cases of digital and continuous 
­signals, correspondingly.
Image ensembles can be specified in a form of databases, such as ­databases 
of images of human faces, databases of microscopic images of cells, ­databases 
of satellite images of different kinds of terrains and alike, or in the form of 
mathematical models.
Mathematical models of signal ensembles are usually formulated as 
­probabilistic models. Probabilistic models do not specify individual signals 
of an ensemble. Rather, they specify only certain signal statistical character-
istics, that is, averages over the ensemble of certain signal attributes. In this 
averaging, it is most natural to associate the contribution of individual sig-
nals to the ensemble average, which are embodied in weight coefficients and 
weighting function, with the rate of occurrence in realizations of individual 
elements of the ensemble. The mathematical models usually assume that the 
number of realization of signals is infinitely large, and this rate is called prob-
ability, or, in continuous case, probability density.
The most fundamental notion of probabilistic models is that of a random 
variable. Quantized (discrete) random variable V is statistically specified by 

41
Mathematical Preliminaries
probability distribution {Pq} of its values {Vq}, where q is an integer index, 
q = 0,1,. . .,Q − 1 and Q is the total number of possible quantized values. The 
probability distribution {Pq} is a limit, when the number of realizations of the 
variable goes to infinity, of the rates of individual values {Vq} in a finite set 
of realizations. The set of these rates is called the distribution histogram of the 
variable and the rates for particular values of {Vq} are called histogram bins. 
The number of occurrences of individual values {Vq} in a finite set of realiza-
tions is called the cardinality of the set of these values. The sum of histogram 
bins from minimal value V
Vq
0 = min{
} of the variable to a particular value Vq 
is called the cumulative histogram.
Continuous random variables v are specified by the probability 
P V
v
V
( )
(
)
=
<
Probability
 that the variable has a value lower than V. This 
probability as a function of V is called the cumulative distribution function. 
It is defined as a limit of the cumulative histogram, when the number of 
realizations and the number of levels of random variable both go to infin-
ity. Its derivative p v
P V
V
V v
( )
(
( )
)
=
=
d
/d
 is called the probability density. The 
probability density can be regarded as a limit of histogram bins of random 
variable, when the number of its quantized levels reaches infinity.
Random variable mean value
	
V
PV
V
p v v
v
q
q
q
Q
=
=
=
−
−∞
∞
∑
∫
0
1
;
( )
,
d
	
(2.109)
variance
	
V
P V
V
V
p v v
V
v
q
q
q
Q
2
2
0
1
2
2
=
−
=
−
=
−
−∞
∞
∑
∫
(
) ;
( )(
)
,
d
	
(2.110)
and, generally, n-th centered moments
	
V
P V
V
V
p v v
V
v
n
q
q
n
q
Q
n
n
=
−
=
−
=
−
−∞
∞
∑
∫
(
) ;
( )(
)
0
1
d
	
(2.111)
for, correspondingly, quantized and continuous random variables are typical 
examples of ensemble averaging of signal’s attributes, in this case its value, 
and represent statistical characteristics of random variables complementary 
to probability distribution and probability density. The square root of vari-
ance σV
V
=
2  is called the standard deviation of the random variable.
Statistical characteristics of digital signals alternative to histograms and 
their moments are order statistics and their derivatives. Signal order statistics 

42
Theoretical Foundations of Digital Imaging Using MATLAB®
are defined through a notion of the variational row. Variational row VR ak
{
} of 
a digital signal {ak}, k = 0,1,. . .,N − 1 is a sequence of signal samples ordered 
according to their values:
	
VR
a
a
a
a
a
a
a
N
N
k
{
}
( )
( )
(
)
( )
( )
(
)
,
,...,
:
.
= {
}
≤
≤
≤
1
2
1
2

	
(2.112)
If signal samples happen to have the same quantized value, they are placed 
in the variational row one after another in an arbitrary order. Note that coor-
dinate indices {k} of signal samples are ignored in the variational row.
Element a(R) that occupies R-th place in the variational row is called signal 
R-th-order statistics. Index R (R = 1,2,. . .,N) of the order statistics is called its 
rank. The rank shows how many signal samples have value lower or equal to 
that of the element. The very first-order statistics is signal minimum:
	
a
ak
( )
MIN{
}.
1 =
	
(2.113)
The very last-order statistics in the variational row is signal maximum:
	
a
a
N
k
(
)
MAX{
}.
=
	
(2.114)
If the number of signal samples N is odd, (N + 1)/2-th signal order statistics 
that is located exactly in the middle of the variational row is called the signal 
median:
	
a
a
N
k
((
)/ )
MEDN{
}.
+
=
1
2
	
(2.115)
If N is an even number, the median can be defined as
	
(
)/
MEDN{
}.
(
/
)
(
/
)
a
a
a
N
N
k
2 1
2 1
2
−
−
+
=
	
(2.116)
The signal median is an alternative to the signal mean value. As such, it 
is more robust, in a statistical sense, to possible presence, in the sequence of 
signal samples of “outliers” that belong to a statistical ensemble different 
from that of the majority of the signal samples. They may appear due to, 
for instance, spontaneous faults of the signal sensor. Signal median in such 
cases will be close to the mean of the signal without outlier samples. Yet 
another alternative to signal mean robust to the presence of outliers, which 
take extreme values, is the so-called signal alpha-trimmed mean:
	
a
N
a r
r
N
α
α
α
α
=
−
=
−−
∑
1
1
( ),
	
(2.117)
the arithmetic mean of the elements of the variational row, which are mini-
mum α elements apart from its ends.

43
Mathematical Preliminaries
Signal second moment, or its variance, is a parameter that characterizes 
the spread of the signal values. An alternative to it and robust to outliers 
characteristic of signal values spread is signal quasispread defined as a differ-
ence between order statistics, which are certain number r of samples to the 
right and to the left from the median:
	
QSPR ( )
.
r
N
r
N
r
a
a
a
=
−
+ +




+ −




1
2
1
2
	
(2.118)
In image processing, order statistics and ranks can be measured both glob-
ally over the entire given image or set of images and over a sliding window. 
In the latter case, they are called local. Local histograms, ranks, and order 
statistics are the base of nonlinear filters discussed in the section “Correcting 
Image Gray-Scale Nonlinear Distortions” in Chapter 8.
If a random variable represents values of a function, this function is 
called a random process. In order to specify interrelation of values of ran-
dom process at different points, the notions of random processes autocor-
relation and mutual correlation functions are introduced. Autocorrelation 
function CFv(
,
)
x
x
1
2  of a continuous random process v(x) is defined as an 
ensemble average of the product of the process values (v1;v2) at points x1 
and x2:
	
CF x x
AV
v
v
v
V
(
,
)
[ (
) (
)].
1
2
1
2
=
Ω
x
x
	
(2.119)
Correspondingly, correlation functions of discrete and digital random pro-
cesses {Vk} are defined as
	
CF k l
AV
V V
V
k
l
V
( , )
[
].
=
Ω
	
(2.120)
The correlation function as a statistical characteristic of random processes 
is a generalization of the variance as a statistical characteristic of random 
variables. Its value CFv(x,x) (CFV(k,k) for discrete processes) is equal to the 
variance of the process at point x (at k-th sample of the discrete process):
    CF
AV
v
V
CF k k
AV
V
V
v
V
k
k
V
V
( , )
[
( )]
( );
( , )
.
x x
x
x
=
=
=

=
Ω
Ω
2
2
2
2
	
(2.121)
An important special case of random processes is homogeneous random 
­processes, or, in the communication engineering jargon, stationary random pro-
cesses. The correlation function of homogeneous random processes CFv(x1,x2) 
depends only on the difference of coordinates:
	
CF x x
CF x
x
v
v
(
,
)
(
)
1
2
1
2
=
−
	
(2.122)

44
Theoretical Foundations of Digital Imaging Using MATLAB®
and its value CFv(0) is equal to the process variance:
	
CF
V
v( )
,
0
2
=
	
(2.123)
which in this case does not depend on coordinates due to the homogeneity 
(stationarity) of the process.
A measure of interrelation of two random processes is the mutual, or cross-
correlation, function:
	
CF
x x
AV
v
v
v v
V
1 2
1
2
1
1
2
2
(
,
)
[
(
)
(
)].
=
Ω
x
x
	
(2.124)
As we will see in Chapter 7, the cross-correlation function plays an impor-
tant role in optimal target location.
In the same way as the autocorrelation function of a random process 
was introduced as an ensemble average of the product of random process 
realization values in two points, one can consider the ensemble average 
AV
f
f
v
Ω[ (
)
(
)]
v
v
1
2
∗
 of the product of values of Fourier spectra v(f) of realiza-
tions v(x) of random process taken in two frequencies f1 and f2. This “correla-
tion function” of the spectra of realizations of the random process turns out 
to be the Fourier transform of the process correlation function:
	
AV
f
f
AV
v x
i
f x
x
v x
i
v
v
Ω
Ω
[ (
)
(
)]
(
)exp(
)
(
)exp(
v
v
1
2
1
1
1
1
2
2
2
∗
−∞
∞
=
−
∫
π
d
π
π
f x
x
AV
v x v x
i
f x
f x
x
v
2
2
2
1
2
1
1
2
2
2
)
[ (
) (
)]exp
(
)
d
d
−∞
∞
∫








=
−
Ω
1
2
1
2
1
1
2
2
1
2
2
d
d
d
x
CF x x
i
f x
f x
x
x
v
−∞
∞
−∞
∞
−∞
∞
∫∫








=
−
(
,
)exp
(
)
π
∫∫
−∞
∞
.
	
(2.125)
If the random process is stationary
AV
f
f
CF x
x
i
f x
f x
x
x
v
v
Ω[ (
)
(
)]
(
)exp
(
)
v
v
1
2
1
2
1
1
2
2
1
2
2
∗
−∞
∞
−∞
∞
=
−
−
∫
π
d
d
∫
∫∫
=
−
=
−∞
∞
−∞
∞
CF
i
f
i
f
f x
x
CF
v
v
( )exp
(
)exp[
(
)
]
( )e
ξ
π
ξ
π
ξ
ξ
2
2
1
1
2
2
2
d d
xp
(
)
exp[
(
)
]
.
i
f
i
f
f x
x
2
2
1
1
2
2
2
π
ξ
ξ
π
d
d
−
−∞
∞
−∞
∞
∫
∫
	
(2.126)

45
Mathematical Preliminaries
The second integral in Equation 2.125 is, according to Equation 2.72, a Dirac 
delta-function. Therefore, for stationary random processes
AV
f
f
CF
i
f
f
f
v
v
Ω[ (
)
(
)]
( )exp
(
)
(
)
v
v
1
2
1
1
2
2
∗
−∞
∞
=








−
=
∫
ξ
π
ξ
ξ δ
d
SD f
f
f
(
) (
).
1
1
2
δ
−
	
(2.127)
The Fourier transform SD(f1) of the correlation function of a stationary 
random process is called its spectral density (SD) or power spectrum.
By the definition given by Equation 2.127, the spectral density of a station-
ary random process is also an average, over all realizations of the process 
{v(x)}, of squared module of Fourier spectra of the realizations
	
SD f
AV
v x
i
fx
x
v
( )
( )exp(
)
.
=






−∞
∞
∫
Ω
2
2
π
d
	
(2.128)
The random process is called uncorrelated if its correlation function is a 
delta-function, or, respectively, its spectral density is a constant:
	
CF x
x
SD f
n
n
v
( )
( );
( )
.
=
=
σ δ
σ
2
2 	
(2.129)
By the definition (Equation 2.128), the spectral densities of real homoge-
neous random processes are nonnegative even functions:
   
SD f
AV
f
f
AV
f
f
SD
f
v
v
( )
[ ( )
( )]
[
(
) (
)]
(
)
.
=
=
−
−
=
−
≥
∗
•
Ω
Ω
v
v
v
v
0 	
(2.130)
Therefore, autocorrelation functions, being Fourier transforms of even 
spectral density functions, are also even functions:
	
CF x
CF x
v
v
( )
( ).
=
	
(2.131)
Models of Signal Random Interferences
A special case of signal ensembles are those generated by signal random 
interferences due to factors such as signal sensor noise. The most frequently 
used models for describing signal interferences are those of additive, multi-
plicative, Poisson’s noise, impulse, and speckle noise models.
Additive Signal-Independent Noise Model
The additive signal-independent noise model (ASIN-model) implies signal 
distortions described as
	
b x
a x
n x
( )
( )
( ),
=
+
	
(2.132)

46
Theoretical Foundations of Digital Imaging Using MATLAB®
where a(x) is a noiseless signal, n(x) is a random process statistically 
­independent on signal a(x) and referred to as additive noise, and b(x) is a 
signal contaminated with noise. Given signal a(x), additive noise generates 
signal ensemble ΩN that consists of copies of this signal distorted by different 
realizations of noise.
The assumption of statistical independence implies that statistical 
­averaging over the noise ensemble applied to signal b(x) or to results of its 
transformations acts only on the noise component {n(x)}. For instance, for the 
considered ASIN-model:
	
AV
b x
a x
AV
n x
N
N
Ω
Ω
{ ( )}
( )
{ ( )}.
=
+
	
(2.133)
In this model, mean value n
AV
n x
N
=
Ω{ ( )} of noise is usually of no con-
cern and it is natural to assume that n = 0. With this assumption, the mean 
value of the signal corrupted with additive zero mean noise is equal to the 
uncorrupted signal and standard deviation of its fluctuations is equal to the 
standard deviation of noise:
	
AV
b x
a x
N
Ω{ ( )}
( );
=
	
(2.134)
	
AV
b x
AV
b x
AV
b x
a x
AV
n x
N
N
N
N
Ω
Ω
Ω
Ω
( )
{ ( )}
( )
( )
( )
.
−
{
} =
−
{
} =
{
}
2
2
2
	
(2.135)
A typical statistical model of additive noise n(x) is homogeneous zero 
mean Gaussian random process. It is completely statistically determined by 
its probability density called normal distribution
	
p n
n
n
n
( )
exp
,
=
−




1
2
2
2
2
πσ
σ
	
(2.136)
where σn is its standard deviation, and by its correlation function CFn( )
x .
One of the basic results of the probability theory is the central limit theorem, 
which states that distribution density of sum of statistically independent ran-
dom values tends to the normal distribution with the growth of the number 
of those random values. This implies that the normal distribution is a good 
model of the distribution of many types of noise in image sensors, and, in 
particular, of thermal noise caused by random fluctuations of velocities of elec-
trons in electronic signal sensors.
Uncorrelated random process, whose correlation function is a delta-function 
and spectral density is a constant, is conventionally called white noise by 
analogy with “white light” that contains all colors with uniform weights.

47
Mathematical Preliminaries
In a number of applications, highly correlated additive noise should be 
considered. These correlations manifest themselves as concentrated peaks in 
noise power spectrum in certain areas of the frequency domain. If noise power 
spectrum is concentrated only around a few isolated points in the frequency 
domain, this type of additive noise is called periodical noise, or moiré noise.
Multiplicative Noise Model
Multiplicative noise model (MN-model) implies that signal distortions 
appear due to signal multiplication by a random noise process:
	
b x
n x
a x
( )
( )
( ),
=
⋅
	
(2.137)
where n(x) is a signal-independent random process with mean AV
n x
N
Ω{ ( )} 
equal to 1. Similar to mean value of signal corrupted by additive zero mean 
noise, the mean value of a signal corrupted by multiplicative noise is also 
equal to the noncorrupted signal:
	
AV
b x
AV
n x a x
a x
N
N
Ω
Ω
{ ( )}
{ ( )} ( )
( ).
=
=
	
(2.138)
Standard deviation of the corrupted signal is proportional to the standard 
deviation of noise times the signal magnitude:
	
AV
b x
AV
n x
a x
AV
n x
a x
N
N
N
Ω
Ω
Ω
{
( )}
{
( )}
( )
{
( )} ( ) .
2
2
2
2
=
=
	 (2.139)
Therefore, the ratio of corrupted signal standard deviation to its value is 
equal to the standard deviation of the multiplicative noise and does not depend 
on the signal. This is a characteristic property of the multiplicative noise.
Poisson Model
The Poisson model describes quantum fluctuations in interaction of radia-
tion with its sensors, such as photo and x-ray-sensitive sensors. For Poisson’s 
model, random variable values n are nonnegative integer numbers that have 
Poisson probability distribution:
	
P n
n
n
nn
( )
exp(
)
!
,
=
−
	
(2.140)
where n is the mean value of n. It is the property of Poisson’s probability 
distribution that standard deviation of n is equal to its mean n:
	
AV
n
n
n
N
Ω{(
) }
.
−
=
2
	
(2.141)

48
Theoretical Foundations of Digital Imaging Using MATLAB®
When n →∞, the Poisson distribution, according to the Moivre–Laplace 
theorem, tends to normal distribution with standard deviation n :
	
P n
n
n
n
n
( )
exp
(
)
.
=
−
−




1
2
2
2
π
	
(2.142)
An important peculiarity of the Poisson distributions is that the ratio of 
its standard deviation to mean value tends to zero with growth of the mean 
value:
	
lim
( )
lim
,
n
n
AV
n
AV
n
AV
n
n
N
N
N
→∞
→∞
−







=



=
Ω
Ω
Ω
2
0
	
(2.143)
which means that with growth of the mean value n of random variable with 
Poisson’s distribution, its fluctuations from its mean value are becoming rel-
atively less noticeable.
Impulse Noise Model
Impulse noise model (ImpN-model) is defined by the following equation:
	
b x
e x
a x
e x n x
( )
[
( )]
( )
( ) ( ),
=
−
⋅
+
1
	
(2.144)
which implies that random distortions of signal a(x) are caused by two 
­independent random factors: by a binary random process e(x) that assumes 
values 0 and 1, and by a random variable n(x) that assumes values from the 
same value range as that of the noiseless signal a(x). ImpN-model is char-
acteristic for signal transmission and storage systems with random faults. 
The process e(x) describes signal transmission and memory faults and is 
specified by the probability that e(x) = 1 (the probability of error, or the prob-
ability of signal loss). Statistical properties of noise n(x) can be arbitrary; 
most frequently, it is uniformly distributed in the signal dynamic range. If 
random process n(x) assumes only two values equal to the minimum and 
to the maximum of a(x), it produces impulse noise that in image processing 
jargon is called the pepper-and-salt noise because it is seen as contrast black 
and white points.
Speckle Noise Model
The phenomenon of speckle noise is characteristic for imaging systems such as 
holographic ones, synthetic aperture radar, and ultrasound imaging systems 

49
Mathematical Preliminaries
that form images using coherent radiation. Speckle noise originates from the 
property of objects to diffusely scatter radiation and is caused by distortions 
introduced by radiation wavefront sensors. Most frequently, people associate 
it with the finite resolving power of sensors, or, in holographic systems, with 
limitation of the area over which the wavefront is measured by sensors or 
recorded on holograms, though other types of distortions must be consid-
ered as well.
Consider the diagram in Figure 2.12 that illustrates the formation of speckle 
noise caused by the limitation of the sensor’s resolving power.
Let an object with a rough surface be illuminated by a coherent radia-
tion and a
i
( , )exp[ ( , )]
ξ η
θ ξ η  be the complex amplitude of the wavefront on 
the object surface at the point (ξ, η) in the object surface plane. The magni-
tude a(ξ, η) of the wavefront defines the reflected or transmitted radiation 
intensity; its phase θ(ξ, η) describes how object surface changes the phase of 
the illuminating coherent radiation wavefront. For describing the property 
of objects to diffusely scatter radiation, θ(ξ, η) is considered as a random 
process. If θ(ξ, η) is a highly spatially correlated process, object surface is 
specular: it scatters light predominantly in one direction. If process θ(ξ, η) is 
uncorrelated, radiation is scattered uniformly in all directions. In what fol-
lows, we will consider this uniform scattering case.
Assume that the PSF of the coherent imaging system is h(x, y; ξ, η). Then, 
for input object a
i
( , )exp[ ( , )]
ξ η
θ ξ η , output image B(x, y) formed by a sensor 
that is sensitive to squared magnitude of the output wavefront is
     
B x y
b x y
a
i
h x y
( , )
( , )
( , )exp[ ( , )] ( , ; , )
.
=
=
−∞
∞
−∞
∞
∫∫
2
2
ξ η
θ ξ η
ξ η
ξ
η
d d
	
(2.145)
Source of coherent radiation
Photographic
camera
h(x,y;ξ,η)
Speckle image
Object rough surface
a(ξ,η)exp[iθ(ξ,η)]
FIGURE 2.12
Speckle formation model.

50
Theoretical Foundations of Digital Imaging Using MATLAB®
For an object with uniformly painted surface such that a
A
( , )
ξ η =
0
	
B x y
b x y
A
i
h x y
br
( , )
| ( , )|
exp[ ( , )] ( , ; , )
|
=
=
=
−∞
∞
−∞
∞
∫∫
2
0
2
θ ξ η
ξ η
ξ
η
d d
e
im
b
|
|
| ,
2
2
+
	
(2.146)
where
	
b
A
h x y
b
A
h x y
re
im
=
=
−∞
∞
−∞
∞
∫∫
0
0
cos ( , ) ( , ; , )
;
sin ( , ) ( ,
θ ξ η
ξ η
ξ
η
θ ξ η
d d
; , )
ξ η
ξ
η
d d
−∞
∞
−∞
∞
∫∫
	
(2.147)
are real and imaginary components of the complex-valued process b(x, y). 
The assumption that θ(ξ, η) is an uncorrelated random process implies that 
many uncorrelated values of cos ( , )
θ ξ η  and sin ( , )
θ ξ η  are observed within 
the aperture h(x, y; ξ, η) of the imaging system. Therefore, the central limit 
theorem of the probability theory can be used to assert that bre and bim are 
random processes with normal distribution and zero mean values:
	
b
AV b
A
AV
h x y
b
re
re
im
=
=
=
=
−∞
∞
−∞
∞
∫∫
θ
θ
θ ξ η
ξ η
ξ
η
(
)
{cos ( , )} ( , ; , )
;
0
0
d d
AV b
A
AV
h x y
im
θ
θ
θ ξ η
ξ η
ξ
η
(
)
{sin ( , )} ( , ; , )
=
=
−∞
∞
−∞
∞
∫∫
0
0
d d
	
(2.148)
Let us find the correlation function of bre and bim. For bre
CF
AV
b
b
A
AV
b
re
re
re (
,
)
{
(
)[
(
)] }
{cos (
)cos (
x
x
x
x
1
2
1
2
0
2
1
=
=
∗
Ω
Ω
θ
θ
θ ξ
θ ξξ
ξ
ξ
ξ
ξ
ξ ξ
ξ
θ
2
1
1
2
2
1
2
0
2
1
2
1
1
)} (
;
)
(
;
)
(
,
) (
;
)
*
−∞
∞
−∞
∞
∫∫
=
h
h
A
CF
h
x
x
x
d
d
h*(
;
)
,
x2
2
1
2
ξ
ξ
ξ
d
d
−∞
∞
−∞
∞
∫∫
	
(2.149)
where x = (x, y), ξ = (ξ, η), and CFθ(ξ1, ξ2) is the correlation function of cos ( , ).
θ ξ η  
In the above-accepted assumption of applicability of the central limit theo-
rem, CFθ(ξ1, ξ2) is, with respect to integration with h(x, y; ξ, η), a delta-function:
	
CF
AV
θ ξ ξ
θ δ ξ
ξ
δ ξ
ξ
θ
(
,
)
(cos
) (
)
(
).
1
2
2
1
2
1
2
1
2
=
−
=
−
Ω
	
(2.150)

51
Mathematical Preliminaries
Therefore
	
CF
A
h
h
bre (
,
)
(
; )
(
; )
.
*
x
x
x
x
1
2
0
2
1
2
1
2
=
−∞
∞
∫
ξ
ξ
ξ
d
	
(2.151)
In the same way, one can obtain that
	
CF
CF
A
h
h
b
b
im
re
(
,
)
(
,
)
(
; )
(
; )
.
*
x
x
x
x
x
x
1
2
1
2
0
2
1
2
1
2
=
=
−∞
∞
∫
ξ
ξ
ξ
d
	
(2.152)
From Equations 2.151 and 2.152, it follows that variances of orthogonal 
components bre and bim are
	
σ
ξ η
ξ
η
b
re
im
b
b
A
h x y
2
2
2
0
2
2
1
2
=
=
=
−∞
∞
−∞
∞
∫∫
(
)
(
)
| ( , ; , )|
.
d d
	
(2.153)
In general, they are functions of coordinates (x, y) in image plane. For space 
invariant imaging system, for which h x y
h x
y
( , ; , )
(
,
)
ξ η
ξ
η
=
−
−
, variances 
are coordinate independent:
	
σb
A
h x y
x
y
2
0
2
2
1
2
=
−∞
∞
−∞
∞
∫∫
| ( , )| d d
	
(2.154)
Having defined the probability density function of orthogonal compo-
nents bre(x, y) and bim(x, y) of b2(x, y), one can now find the probability density 
of b2(x, y) as the probability density of sum of squared independent variables 
bre and bim with normal distribution. To this end, introduce random variables 
R and ϑ such that
b
R
b
R
B x y
b x y
b
b
R
re
im
re
im
=
=
=
=
+
=
cos
;
sin
;
( , ) | ( , )|
(
)
(
)
.
ϑ
ϑ
2
2
2
2
	 (2.155)
Then, the joint probability that bre and bim take values within a rectangle 
(dbre × dbim) is
	
p b
b
b
b
b
b
R
re
im
b
re
im
b
re
im
(
,
)
exp
(
)
(
)
=
−
+




=
1
2
2
2
2
2
2
2
πσ
σ
θ
π
d
d
d
σ
σ
θ
π
σ
σ
b
b
b
b
R
R
R
R
2
2
2
2
2
2
2
2
2
1
2
2
exp
exp
.
−




=
−




d
d
d
	
(2.156)

52
Theoretical Foundations of Digital Imaging Using MATLAB®
This is the joint probability that variables {
, }
R2    take values in the range 
[
,
]
R
R
R
2
2
2
÷
+
÷
+
d
d
ϑ
ϑ
ϑ . It follows, therefore, that {R2 = B(x, y)} and ϑ are 
statistically independent, ϑ is uniformly distributed in the range {0, 2π} and 
B(x, y) has an exponential distribution density:
	
P b
B
b
b
( )
exp
,
=
−




1
2
2
2
2
σ
σ
	
(2.157)
where σb
2 is defined by Equation 2.154.
From Equations 2.140 and 2.141, one can immediately see that the mean 
value of B(x, y) is
	
B x, y
b
b
A
h x y
x
y
re
im
b
(
)
|
|
|
|
| ( , )|
.
=
+
=
=
−∞
∞
−∞
∞
∫∫
2
2
2
0
2
2
2σ
d d
	
(2.158)
It is the property of the exponential distribution that its standard deviation 
is equal to its mean value
	
σB
B
A
h x y
x
y
= ( )
=
−∞
∞
−∞
∞
∫∫
2 1 2
0
2
2
/
| ( , )|
.
d d
	
(2.159)
Fluctuations of b2(x, y) around its mean value are called speckle noise. It 
is customary to characterize the intensity of speckle noise by the ratio of its 
standard deviation to mean value called “speckle contrast”:
	
SC
B x y
B
=
(
)
σ
,
.
	
(2.160)
It follows from Equations 2.158 and 2.159 that, for objects that scatter radia-
tion almost uniformly in the space, speckle contrast of their image obtained 
in coherent imaging systems of a finite resolving power is unity:
	
SC = 1. 	
(2.161)
Therefore, the speckle noise originated from the limitation of the imag-
ing system resolving power is multiplicative with respect to the image 
signal.
Quantifying Signal-Processing Quality
Consider now the basic notions associated with the evaluation of signal-
processing quality in numerical terms. The measures of processing quality 

53
Mathematical Preliminaries
of individual signals are formulated in the form of loss functions (LF) that 
measure how much an obtained result departs from the desired one. The 
most frequently used loss functions are, for continuous and discrete signals, 
respectively
	




LF a x a x
a x
a x
LF a
a
a
a
p
p
p
k
k
k
k
p
[ ( ); ( )]
| ( )
( )|
(
;
)
|
| ,
=
−
=
−
and
	
(2.162)
where p is a numerical parameter equal to 0, 1, or 2, a(x) is the desired signal, 
and ˆ( )
a x  is its estimate, of which quality is evaluated.
Loss functions defined in this way are functions of signal coordinates 
(index, for discrete signals). In order to characterize the deviations of one 
signal as a whole from another signal by one number, an average value of 
loss functions over the signal extent is used. We will denote this value as 
LOSSp( ; ).
a a  For continuous signals given on interval X and for discrete sig-
nals of N samples, they are defined as, correspondingly,
	




LOSS
LF a x a x
x
a x
a x
x
LOSS
p
p
p
p
( ; )
[ ( ); ( )]
| ( )
( )|
;
(
a a
a
=
=
−
∫
∫
d
d
Χ
Χ
; )
[
;
]
|
| .
a =
=
−
=
−
=
−
∑
∑
LF a
a
a
a
p
k
k
k
N
k
k
p
k
N
0
1
0
1


	
(2.163)
In mathematical jargon, LOSSp( ; )
a a  is called the “Lp-norm” (L0-norm 
for p = 0, L1-norm for p = 1, and L2-norm for p = 2). L2 norm is frequently 
called also the mean square error (MSE), assuming that signal difference 
a
a
k
k
−ˆ  is treated as an “error” in representing signal a through ˆa. Because 
|
|
(
)
a
a
a
a
k
k
k
k
−
=
−
0
δ


, L0-norm computes the rate of nonzero errors, that is, 
probability of errors.
The processing quality for signal ensembles is evaluated as ensemble aver-
age of loss values obtained for individual particular realizations (
,
)
a
a
ω
ω

:
	
LOSS
AV LOSS
W LOSS
LOSS
AV LOSS
Ω
Ω
Ω
Ω
Ω
=
=
=
∈∑
[
( ; )]
(
,
)
[
( ;
a a
a
a
a a
ω
ω
ω
ω


)]
( )
(
,
)
= ∫W
LOSS
ω
ω
ω
ω
a
a
d
Ω


	
(2.164)
for discrete and continuous signals, correspondingly.
Basics of Optimal Statistical Parameter Estimation
The measurement of physical parameters of objects is one of the most fun-
damental tasks in image processing. It is required in many applications. 

54
Theoretical Foundations of Digital Imaging Using MATLAB®
Typical examples are measuring the number of various objects in the field 
of view, their orientations, dimensions and coordinates, outlining objects by 
parameterized curves (so-called “active contours” or “snakes”), and mea-
suring maps of pixel displacement (“motion vectors”) in sequences of video 
frames, to name a few. One of the important special cases is object recogni-
tion, when it is required to determine which object from a list of possible 
objects is observed.
As the measurement devices and algorithms for measuring parameters are 
designed for the use for multitude of images and imaged objects, the most 
appropriate approach to their design is, as we already mentioned, a statisti-
cal approach that assumes that objects and their parameters to be estimated 
are, in any particular observation, selected from corresponding ensembles of 
images and objects and performance of parameter estimation algorithms is 
evaluated on average over these ensembles.
Let a(ρ) be an object signal that depends on a certain parameter ρ, scalar or 
vectorial, which uniquely specifies the signal, and Pℜ(ρ) be a parameter prob-
ability distribution over an ensemble ρ ∈ ℜ of parameter values (probability 
of values if they are discrete or probability density if the parameter values 
are continuous variables). Knowledge of signal a(ρ) allows one to uniquely 
determine the parameter ρ. This signal is sensed by a signal sensor, which, 
in response to it, generates an observed signal that can be used for estimat-
ing the parameter. Let it be signal bω(ρ). Realizations {bω(ρ)} belong to a sta-
tistical ensemble ω ∈ Ω generated by the ensemble of parameter values ℜ 
and by factors that specify the relationship between signals a(ρ) and {bω(ρ)}, 
including factors such as a sensor’s noise. The task of parameter estimation 
is to determine, in the best possible way, the parameter ρ from the observed 
signal bω(ρ).
Within the statistical approach, the best estimation operation is the one 
that minimizes losses, measured as average, over ensembles of observed sig-
nals Ω and of parameter values ℜ, of a certain loss function LF(
, )
ρ
ρ
ω
, which 
characterizes losses due to deviations of the parameter estimates from their 
true values:
	
ˆ
argmin{
[
(ˆ , )]}.
( )
ˆ
ρ
ρ
ρ
ω ρ
ρ
ω
opt
AV AV LF
=
⇒
ℜ
b
Ω
	
(2.165)
Let us initially assume that parameter ρ takes discrete values from a set of 
values {ρq}, numbered by an integer index q. A natural measure of the esti-
mation performance is in this case the probability Perr that estimate ˆρω is not 
equal to the parameter true value ρq (the probability of estimation error). Loss 
function LF
q
(
,
)
ρ
ρ
ω
 is in this case a Kronecker delta: LF
q
(
, )
(
)
ρ
ρ
δ ρ
ρ
ω
ω
=
−


.
For any given realization bω of the observed signal, parameter value ρq 
might be expected with a certain probability P
q
(
)
ρ
ω
b
 called its a posteriori 
probability. It is determined by the a priori probability P(ρq) of the parameter 

55
Mathematical Preliminaries
value ρq and the conditional probability P
q
(
)
bω ρ  that object signal a(ρq) gen-
erates sensor signal bω:
	
P
P
P
P
q
q
q
q
q
(
)
(
) (
)
(
)
.
ρ
ρ
ρ
ρ
ω
ω
ω
b
b
b
=
∑
	
(2.166)
The relationship (Equation 2.166) is called the Bayes rule.
The value 1 −P
q
(
)
ρ
ω
b
 that complements the a posteriori probability to one 
is the probability that parameter takes values other than ρq. Therefore, if the 
parameter estimation device upon observing signal bω makes a decision that 
ˆρ
ρ
=
q, the value 1 −P
q
(
)
ρ
ω
b
 is the conditional probability of error:
	
P Err
P
q
(
)
[
].
b
b
ω
ω
ρ
=
−
1
	
(2.167)
On average over the ensemble Ω of realizations of {bω}, the probability of 
error will be
	
AV
AV
Ω
Ω
Ω
P Err
P
AV P
q
q
(
)
{
(
)}
(
),
b
b
b
ω
ω
ω
ρ
ρ
=
−
=
−
1
1
	
(2.168)
where AVΩ( )⋅ symbolizes the averaging over the ensemble of observed 
signals. Because all values involved in the averaging are nonnegative, the 
probability of parameter estimation error is minimal when, for every par-
ticular bω, a parameter estimate ˆρ is selected that has maximal a posteriori 
probability:
	
ˆ
argmax (
)
argmax
(
) (
)
(
)
{
}
{
}
ρ
ρ
ρ
ρ
ρ
ρ
ω
ρ
ω
ω
MAP
q
q
q
q
q
q
q
P
P
P
P
=
=
∑
b
b
b
	
(2.169)
or, as the denominator does not depend on {ρq},
	
ˆ
argmax (
) (
).
{
}
ρ
ρ
ρ
ρ
ω
MAP
q
q
q
P
P
=
b
	
(2.170)
Such an estimate is called maximum a posteriori probability estimate 
(MAP-estimate) and the described approach to optimization of parameter 
estimation is called the Bayesian approach.
MAP-estimates require knowledge of the conditional probability P
q
{
}
bω ρ , 
which is determined by the relationship between sensor signals {bω} and 

56
Theoretical Foundations of Digital Imaging Using MATLAB®
object signals { (
)}
a ρq
 and of a priori probabilities { (
)}
P
q
ρ
 of parameter values. 
Estimates
	
ˆ
argmax {
}
{
}
ρ
ρ
ρ
ω
ML
q
q
P
=
b
	
(2.171)
that ignore a priori probabilities (or, which is equivalent, assume that a pri-
ori probability distribution is uniform) are called maximum likelihood, or 
ML-estimates.
Equations 2.167 and 2.168 were obtained in the assumption that parameter 
to be estimated is scalar and takes values from a discrete set of values. It is 
quite obvious that they can be in a straightforward way extended to vectorial 
parameters, in which case probabilities involved in the equations are cor-
responding multivariate probabilities, and to parameters with continuum of 
values, in which case probabilities should be replaced by the corresponding 
probability densities.
To conclude this exposure of principles of statistically optimal param-
eter estimation, consider an important and illustrative special case when 
the relationship between object signals and observed signal is determined 
by the above-described model of additive signal-independent uncorrelated 
Gaussian noise (Equation 2.119):
	
b
a
n
ω
ρ
=
+
( )
,
v 	
(2.172)
where nv is a realization of noise from a noise ensemble ΔN. From this equa-
tion, it follows that the conditional probability P
q
{
}
bω ρ  is a probability that 
noise realization nv is equal to the difference b
a
ω
ρ
−( ):
	
P
P
q
{
}
{
( )}.
b
n
b
a
ω
ω
ρ
ρ
=
=
−
v
	
(2.173)
For N-component discrete signals bω = {
}
bk  and a( )
{
( )}
ρ
ρ
= ak
, k = 0,1,. . ., 
N − 1 and Gaussian noise with uncorrelated components, this relationship 
becomes
P
P
b
a
q
k
k
k
n
k
k
n
{
}
{
( )}
exp
[
( )]
,
,
b
n
b
a
ω
ω
ρ
ρ
πσ
ρ
σ
=
=
−
=
−
−





v
1
2
2
2
2





= 



−
−





=
−
=
−
∏
∑
k
N
n
N
n
k
k
k
N
b
a
0
1
2
2
0
1
1
2
1
2
πσ
σ
ρ
exp
[
( )] .
	
(2.174)
Because the exponential function in Equation 2.174 is a monotonic func-
tion of its argument, Equations 2.167 and 2.168 for optimal MAP- and 
ML-estimates of the parameter are reduced to the equations

57
Mathematical Preliminaries
	
ˆ
argmin
[
( )]
ln ( )
(
)
{ }
ρ
ρ
σ
ρ
ρ
MAP
k
k
n
k
N
b
a
P
=
−
−






=
−
∑
2
2
0
1
2
	
(2.175)
	
ˆ
argmin
[
( )] .
(
)
{ }
ρ
ρ
ρ
ML
k
k
k
N
b
a
=
−
=
−
∑
2
0
1
	
(2.176)
The latter equation means that the optimal ML-estimate of the param-
eter minimizes mean squared difference between components of the 
observed signal and object signal, or L2-norm of the signal difference. 
This fundamental result is, in particular, a justification of very frequent 
use in signal processing of L2-norm as a measure of deviation of one sig-
nal from another.
Appendix
Derivation of Equation 2.32
For T( )
( )
{
}
b
n
b
=

φ
 and T( )
( )
{
}
a
k
a
=

φ
 as orthogonal transforms for representation 
of signal vector a and its linear transformation b
L a
=
( ):
	
β
φ
φ
α φ
φ
α
φ
n
b
n
b
n
b
k
k
a
k
n
b
k
=
=
=
=






=
∑
T
b
b
a
( )
( )
( )
( )
( )
L( )
L
L






k
a
n
b
k
k n
k
k
( )
( )
,
,
(
)
(
) =
∑
∑


φ
λ
α
where symbol ∘ represents scalar product and λ
φ
φ
k n
k
a
n
b
,
( )
( )
L
=
(
)
(
)


.
Derivation of Equation 2.65
	
exp(
)exp(
)
exp[ (
)]
ex
−
=
−
−
=
−∞
∞
−∞
∞
∫
∫
i
x
i
px
x
i
x
i
px
x
πω
π
πω
π
2
2
2
2
2
2
d
d
p
exp
exp
−
−
















=
−∞
∞
∫
i
x
i
p
i
p
x
i
p
πω
π
ω
π ω
π ω
2
2
2
2
2
d




−


−∞
∞
∫exp
(
)
i
x
x
πω
2 d

58
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=








=




−∞
∞
∫
exp
exp
exp
i
p
i
x
x
i
p
i
π ω
πω
π ω
π
2
2
2
2
1
2
2
2
2
d
πω
ω
π ω
=




1
2
2
i
i
p
exp
.
Derivations of Equations 2.84 through 2.87
If 
d
a x
f
i
fx
x
( )
( )exp(
)
,
=
−
−∞
∞∫
α
π
2
	
±
−
= ±
−
−
= ±
−
−
−∞
∞
−∞
∞
∫
∫
a
x
f
i
f
x
x
f
i
f x
x
(
)
( )exp[
(
)]
( )exp[
(
) ]
α
π
α
π
2
2
d
d
= ±
−
−
−∞
∞
∫α
π
(
)exp[
]
.
f
i
fx
x
2
d
Therefore, from a
a
( )
(
)
x
x
= ±
−
 it follows that α
α
( )
(
)
f
f
= ±
−. Furthermore
	
±
= ±
= ±
−
−
∗
−∞
∞
∗
−∞
∞
∫
∫
a x
f
i
f
x
f
i
fx
x
*( )
( )exp(
)
(
)exp(
)
.
α
π
α
π
2
2
d
d
Therefore, from a
a
( )
( )
x
x
= ±
∗
, it follows that α
α
( )
(
)
f
f
= ±
−
∗
. Combining 
these relationships, also obtain Equations 2.87 and 2.88.
Reference
	
1.	 D. Gabor, A new microscopic principle, Nature, 161, 777–778, 1948.

59
3
Image Digitization
This chapter addresses the very first problem of digital imaging, the problem 
of converting continuous signals that carry information on natural objects 
into digital signals. We call this conversion “signal digitization.”
Principles of Signal Digitization
As it was stated in the section “Primary Definitions” in Chapter 2, signal 
digitization can be treated in general terms as determination, for each par-
ticular signal, of an index of the equivalency cell to which the signal belongs 
in the signal space, and signal reconstruction can be treated as generating a 
representative signal of the cell with this index. This is, for instance, what we 
do when we describe everything in our life with words in speaking or writ-
ing. In this case, this is our brain that performs the job of subdividing “signal 
space” into the “equivalency cells” of notions and selects the word (cell rep-
resentative signal) that corresponds to what we want to describe.
The volume of our vocabulary is about 105–106 words. The variety of signals 
we have to deal with in imaging is immeasurably larger. One can see that from 
this simple example: the number of digital images of, for instance, TV quality 
(500 × 500 pixels with 256 gray levels in RGB channels) is 2563×500×500. No techni-
cal device will ever be capable of implementing such a huge look-up table.
A solution of this problem of the digitization complexity is found in a 
two-stage digitization procedure. At the first stage, called signal discretiza-
tion, continuous signals are converted into a set of real numbers that form 
signal discrete representation. At the second stage, called scalar (element-wise) 
quantization, this set of numbers is, on a number-by-number basis, converted 
into a set of quantized numbers, which finally results in a digital signal that 
corresponds to the initial continuous one. In the same way, as written speech 
is a sequence of letters selected from an alphabet, digital representation of 
signals is a sequence of samples that can take one of a finite set of quan-
tized values. In terms of the signal space, discretization can be regarded as 
introducing a coordinate system in the signal space and determining signal 
coordinates in this coordinate system. Element-wise quantization is then 
quantization of those coordinates. Equivalence cells of the signal space are 
therefore approximated in this case by hyper-cubes with edges parallel to 

60
Theoretical Foundations of Digital Imaging Using MATLAB®
the coordinate axis. Note that element-wise quantization can also be consid-
ered as an implementation of the general quantization in 1D signal space.
Signal Discretization
Signal Discretization as Expansion over a Set of Basis Functions
In principle, there might be many different ways to convert continuous sig-
nals into discrete ones represented by a set of real numbers. However, the 
entire technological tradition and all technical devices that are used at pres-
ent for such a conversion implement a method that can be mathematically 
modeled as computing coefficients representing signals in their expansion 
over a set of basis functions.
Let ϕk
d x
( )( )
{
} be a set of basis functions used for signal discretization. Then, 
coefficients {αk} of signal discrete representations are computed as
	
α
ϕ
k
k
d
X
a x
x
x
= ∫( )
( )
.
( )
d
	
(3.1)
This equation is a mathematical formulation of operations performed by 
signal sensors. Functions ϕk
d x
( )( )
{
} describe spatial sensitivity of sensors, that 
is, sensor PSF.
Signal discretization with discretization basis function ϕk
d x
( )( )
{
} assumes 
that a reciprocal set of reconstructing basis functions ϕk
r x
( )( )
{
} is defined, 
with which signal can be reconstructed from its discrete representation coef-
ficients {αk} as follows:
	
a x
x
k
k
r
k
N
( )
( ),
( )
≈
=
−
∑α ϕ
0
1
	
(3.2)
where the approximation symbol ≈ in Equation 3.2 indicates that signal 
reconstructed from its discrete representation is, generally, not a precise copy 
of the initial signal, N is the number of representation coefficients needed 
for signal reconstruction with a desired accuracy, and functions ϕk
r x
( )( )
{
} are 
PSFs of signal reconstruction devices (such as, for instance, computer dis-
play), or their reconstruction aperture functions.
For different bases, the signal approximation accuracy for a given num-
ber of basis functions N used for signal reconstruction might be different. 
Naturally, the discretization and reconstruction bases that provide better 
approximation accuracy for a given N are preferable. Therefore, the accu-
racy of the expansion (3.2) is the first issue one should check when selecting 

61
Image Digitization
bases for signal discretization and reconstruction. Approaches to the selec-
tion of bases optimal in this respect are discussed in the section “Optimality 
of Bases: Karhunen–Loeve and Related Transform.”
The second issue to consider when selecting discretization and reconstruc-
tion basis functions is that of complexity of generating and implementing 
basis functions and computing signal representation coefficients.
In principle, discretization and reconstruction basis functions can be hard-
wired in the signal discretization and restoration devices in a form of tem-
plates. However, practically this is rarely feasible because the number N of 
the required template functions is very large (for instance, for images it is of 
the order of magnitude of 105–107). This is why these functions are usually 
produced from a single “mother” function by means of its modification with 
one or another method.
Typical Basis Functions and Classification
Shift (Convolutional) Basis Functions
The simplest method for generating sets of discretization and reconstruction 
basis functions from a “mother” function φM(x) is that of translation (coordi-
nate shift):
	
ϕ
ϕ
ϕ
ϕ
k
s
M
s
k
r
M
r
x
x
k x
x
x
k x
( )
( )
( )
( )
( )
(
);
( )
(
).
=
−
=
−
∆
∆
	
(3.3)
We call functions generated in this way shift basis functions. We call the 
elementary shift interval Δx the discretization or sampling interval, the discreti-
zation using shift basis functions sampling, and the positions {x = kΔx} sam-
pling points. The sampling interval is usually the same for the entire range of 
signal coordinates x, although it need not necessarily be so.
The signal representation coefficients {ak} for sampling basis functions are 
obtained as
	
a
a x
x
k x
k
M
s
X
=
−
∫( )
(
).
( )
ϕ
∆
	
(3.4)
They are called samples. Correspondingly, signal reconstruction is per-
formed as
	
a x
a
x
k x
k
M
r
k
( )
(
).
( )
=
−
∑
ϕ
∆
	
(3.5)
Equation 3.5 can be regarded as convolution conv(.,.) of signals
	
a x
x
k x
k
k
( )
(
)
=
−
∑α δ
∆
	
(3.6)

62
Theoretical Foundations of Digital Imaging Using MATLAB®
with reconstruction basis functions
	
a x
x
k x
k x
x
k
r
k
k
k
N
r
( )
(
)
(
)
(
( )
( )
=
−
=
−∆








∑
∑
∫
=
−
−∞
∞
α ϕ
α δ ξ
ϕ
∆
0
1
0
−
=
−∆
(
)






=
−
∑
ξ
ξ
α δ
ϕ
)
,
( ) .
( )
d
conv
x
k x
x
k
k
N
r
0
1
0
	
(3.7)
This justifies yet another name for shift basis functions, the convolution 
basis functions, and treatment of Equation 3.5 for reconstruction of con-
tinuous signals from their samples as convolution-based interpolation of the 
samples.
The most immediate example of sampling functions are functions built 
from rectangular impulse rect-functions defined by Equation 2.8:
	
ϕk
s x
x rect x
k x
x
( )( )
.
=
−




1
∆
∆
∆
	
(3.8)
For rectangular sampling functions, signal representation coefficients are 
their mean values over sampling intervals:
	
αk
k
x
k
x
X
x
a x rect x
k x
x
x
x
a x
x
=
−




=
−
+
∫
∫
1
1
1 2
1 2
∆
∆
∆
∆
∆
∆
( )
( )
(
)
(
)
d
d
= a k x
(
).
∆
	
(3.9)
By the definition of the rect-function, rectangular sampling functions 
defined by Equation 3.8 are orthogonal. Therefore, the reciprocal signal 
reconstruction basis in this case is composed of functions
	
ϕk
r x
rect x
k x
x
( )( )
.
=
−










∆
∆
	
(3.10)
With this basis, signals are approximated by piece-wise constant functions
	
a x
a x
a k x rect x
k x
x
k
N
( )
( )
(
)
≈
=
−




=
−
∑

∆
∆
∆
0
1
	
(3.11)
as it is illustrated in Figure 3.1.
2D shift basis functions are most frequently implemented as a product of 
1D functions of corresponding coordinates, say, x and y, that is, as separable 
functions. For rectangular sampling functions, these are

63
Image Digitization
	
ϕk l
s x y
x y rect x
k x
x
rect y
l y
y
,
( )( , ) =
−




−








1
∆∆
∆
∆
∆
∆


,
	
(3.12)
	
ϕk l
r x y
rect x
k x
x
rect y
l y
y
,
( )( , )
.
=
−




−










∆
∆
∆
∆
	
(3.13)
Sampling points form in this case a rectangular sampling grid in Cartesian 
coordinates (x, y) (see Figure 3.2) and sampling is performed by measuring 
average signal intensity over rectangular apertures of light-sensitive cells of 
image sensors shown in Figure 3.3. Samples of images are commonly called 
pixels (from picture elements).
Owing to fabrication technology limitations, some gaps must usually be 
left between adjacent light-sensitive cells. Because of this, dimensions dx and 
dy of light-sensitive cells are smaller than corresponding sampling intervals 
FIGURE 3.1
Continuous signal sampled and reconstructed using rectangular impulse sampling and recon-
struction basis functions.
x
y
Δy
Sampling grid
Pixel
positions 
Signal coordinate
axes (x,y) 
Sampling interval Δx 
Sampling interval Δy 
FIGURE 3.2
​2D rectangular sampling grid.

64
Theoretical Foundations of Digital Imaging Using MATLAB®
Δx and Δy. Sampling functions that describe such image sensors with rectan-
gular apertures can be described as
	
ϕk l
s x y
x y rect x
k x
x
rect y
l y
y
,
( )( , )
d
=
−




−








1
d d
d
∆
∆


.
	
(3.14)
The ratios (dx/Δx,dy/Δy) of dimensions of light-sensitive cells to sampling 
intervals are called camera fill factors.
Piece-wise constant image approximation in their reconstruction from 
samples using rectangular reconstruction functions given by Equation 3.13 
produces specific visual effects called image pixilation. They are illustrated 
in Figure 3.4.
Light sensitive
cell’s aperture 
Sampling
interval Δx 
Sampling
interval Δy 
dx
dy
FIGURE 3. 3
Arrangement of light-sensitive elements in image sensor array.
FIGURE 3.4
Effect of “pixilation” in image reconstruction from sampled data using rectangular recon-
struction basis functions: (a) initial image and (b) image reconstructed from sampled initial 
image using rectangular basis functions.

65
Image Digitization
2D sampling functions produced from 1D rect-functions do not necessar-
ily have to be separable functions with rectangular apertures. Frequently 
used options are sampling functions with circular apertures:
	
ϕ
π
k l
s x y
r circ x
k x
r
y
l y
r
,
( )( , )
,
=
−
−










1
2
∆
∆
	
(3.15)
	
ϕk l
r x y
circ x
k x
r
y
l y
r
,
( )( , )
,
,
=
−
−










∆
∆
	
(3.16)
where circ-function circ(x, y) is defined as
	
circ x y
x
y
( , )
,
,
=
+
≤



1
1
0
2
2
otherwise
	
(3.17)
and r is radius of the circular aperture. Rectangular sampling grid with cir-
cular sampling apertures is illustrated in Figure 3.5.
Yet another example of sampling functions is an idealistic mathematical 
model of sinc-function defined by Equation 2.37. For sampling interval Δx, 
sampling basis functions build on sinc-functions are defined as
	
ϕ
π
k x
x
x
k x
x
( )
sinc
=
−




1
∆
∆
∆
	
(3.18)
with sampling performed as
	
α
π
k
x
a x
x
k x
x
x
=
−




−∞
∞
∫
1
∆
∆
∆
( )sinc
.
d
	
(3.19)
As it follows from Equations 2.104, sinc-functions and rect-functions are 
dual: they are Fourier transforms of one another.
Light sensitive
cell’s aperture 
Sampling
interval Δx 
Sampling
interval Δy 
2r
2r
FIGURE 3.5
Rectangular sampling grid with circular sampling apertures.

66
Theoretical Foundations of Digital Imaging Using MATLAB®
Using shift theorem and convolution theorem of the theory of Fourier trans-
form (the section “Imaging Systems and Integral Transforms” in Chapter 2) 
and Equations 2.74 and 2.75, one can see that sampling sinc-functions are 
mutually orthogonal:
	
1
1
∆
∆
∆
∆
∆
∆
x
x
k x
x
x
l x
x
x
x
sinc
(
) sinc
(
)
sinc
π
π
π
−




−




=
−∞
∞
∫
d
x
x
x
k
l
x
x
x
x
i
f k
l
x
∆
∆
∆
∆
∆




−
−




=
−
−
−∞
∞
∫
sinc
(
(
)
)
exp
(
)
π
π
d
2


=
−
[
] =
=
≠



=
−
−∫
d
 
 
f
k
l
k
l
k
l
k
l
x
x
1 2
1 2
1
0
/
/
sinc
(
)
,
,
(
).
∆
∆
π
δ
	
(3.20)
Therefore, reconstruction functions for this basis are functions 
{sinc[π(x − kΔx)/Δx]} and signal reconstruction is performed as
	
a x
a x
x
k x
x
k
k
N
( )
( )
sinc
.
≈
=
−




=
−
∑

α
π
∆
∆
0
1
	
(3.21)
Equation 2.104 also shows that the Fourier spectrum of functions 
{sinc[π(x − kΔx)/Δx]} is zero outside the frequency interval [−1/2Δx,1/2Δx]. 
This implies that signals reconstructed from their samples according to 
Equation 3.21 belong to the class of so-called band-limited functions and that 
coefficients {αk} of discrete representation of band-limited signals a x
( ) are 
equal to their samples taken at equidistant points {x = kΔx}:
	
αk
a k x
= (
).
∆
	
(3.22)
This is where the name “sampling functions” derives from.
Scale (Multiplicative) Basis Functions
Sinusoidal Basis Functions
Yet another method for generating basis functions from one mother function 
φM(x) is scaling the argument of functions:
	
ϕ
ϕ
k
M
x
kx
( )
(
).
=
	
(3.23)

67
Image Digitization
An immediate example of signal expansion over scaling basis functions is 
signal Fourier series expansion over a finite interval:
	
a x
i
kx X
k
k
( )
exp(
),
= ∑α
π
2
/
	
(3.24)
where X is the interval, within which signal is approximated by the Fourier 
series, and coefficients {αk} are complex numbers computed as
	
α
π
k
X
X
X
a x
i
kx X
x
=
−
−∫
1
2
2
2
( )exp(
)
.
/
/
d
/
	
(3.25)
They can be regarded as (1/X)-normalized samples of the signal Fourier 
transform spectrum taken at frequencies {k/X}.
While in reality the number of terms in the expansion (3.24) is always finite, 
classical Fourier series expansion assumes that it is infinite. The limitation 
of the number of terms in Fourier series (3.24) is equivalent to dropping all 
signal components with frequencies higher than (N − 1)/2X, where N is the 
number of terms in the Fourier series expansion. This frequency band-limita-
tion can mathematically be described as multiplying signal Fourier spectrum 
by a rectangular window function rect((f + (N − 1)/2X)/((N − 1)/X)), which is 
equivalent to the signal convolution with the corresponding sinc-function, 
Fourier transform of the rectangular function. As a result, sinc-function-orig-
inated oscillations may appear at signal edges. As it was already mentioned 
in the section “Imaging Systems and Integral Transforms” in Chapter 2, these 
specific distortions in reconstructed signals are called Gibb’s effects.
The fundamental property of Fourier series signal expansion is that, while 
it converges to the signal within interval of expansion X, outside this inter-
val Fourier series it converges, owing to the periodicity of basis functions 
{exp(i2πkx/X)}, to a periodical function with a period X. Periodical signals 
are dual to signals composed from shifted delta-functions introduced in 
Equation 3.6. This duality will be discussed in connection with the sampling 
theorem in the section “Image Sampling.”
Walsh Functions
Generating basis functions by means of scaling their argument can also be 
treated, for the basis of exponential functions {exp(i2πkx/X)}, as generating 
by means of multiplying mother function:
	
exp(
)
exp(
).
i
kx X
i
x X
l
k
2
2
1
π
π
/
/
=
=∏
	
(3.26)
There exists yet another family of orthogonal functions built with the 
same principle, Walsh functions. Walsh functions are binary functions 

68
Theoretical Foundations of Digital Imaging Using MATLAB®
that assume only two values, 1 and −1. Walsh functions are generated by 
multiplication
	
wal x
rad
x X
k
m
k
m
mGC
( )
(
)
=


+
=
∞
∏
1
0
	
(3.27)
of clipped sinusoidal functions called the Rademacher functions:
	
rad
sign
m
m
m
m
( )
sin(
)
,
sin(
)
, sin(
)
ξ
π
ξ
πξ
πξ
=

=
+
>
−
<



2
1
2
0
1
2
0

,
	
(3.28)
where X is interval on which functions are defined and km
GC is the m-th digit 
of the so-called Gray code of index k. Gray code digits are generated from 
digits {km} of ordinary binary representation of the number
	
k
k
k
m
m
m
m
=
=
=
∞
∑
2
0 1
0
;
,
	
(3.29)
according to the following rule:
	
k
k
k
m
GC
m
m
=
⊕
+1, 	
(3.30)
where ⊕ stands for modulo 2 addition, according to which 0 + 0 = 
1 + 1 = 0;  0 + 1 = 1 + 0 = 1.
Formula 3.27 reveals the multiplicative nature of Walsh functions. For the 
purpose of calculating their values in computers, another representation of 
the Walsh functions (see Appendix) is useful:
	
walk
k
m
k
m
mGC
mGC m
m
( )
(
)
(
)
,
ξ
ξ
ξ
=
−


= −
∑
+
+
=
∞
=
∞
∏
1
1
1
1
0
0
	
(3.31)
where
	
ξ
ξ
=
=
−
=
∞
∑
x X
m
m
m
/
2
1
	
(3.32)
with {ξm = 0, 1} as digits of binary representation of the normalized coordi-
nate ξ.

69
Image Digitization
Walsh functions are orthogonal on the interval [0, X]. As one can see from 
Equation 3.31, multiplication of two Walsh functions results in another Walsh 
function with a shifted index or argument:
	
wal
wal
wal
k
l
k
l
( )
( )
( );
ξ
ξ
ξ
=
⊕
	
(3.33)
	
wal
wal
wal
k
k
k
( )
( )
(
).
ξ
ζ
ξ
ζ
=
⊕
	
(3.34)
The shift, called dyadic shift, is determined through the bit-by-bit modulo 2 
addition of functions’ indices or, respectively, arguments.
One can regard the sum ∑
=
∞
+
m
m
GC
m
k
0
1
ξ
 in the definition of Walsh as a scalar 
product of vectors km
GC
{
} and {ξm+1}, composed from binary digits of function’s 
index and argument. It is in this sense that one can treat the basis of Walsh 
functions as a scale basis functions. The multiplicative nature of Walsh func-
tions and exponential ones justifies yet another name for these families of 
bases, multiplicative bases.
Walsh functions are akin to complex exponential functions {exp(i2πkx/X)} 
in one more respect. This can be seen if (−1) in Equation 3.42 is replaced by 
exp(iπ) to obtain
	
wal
i
k
k
m
GC
m
m
( )
exp
ξ
π
ξ
=
∑




+
=
∞
1
0
	
(3.35)
and from comparison of plots of sinusoidal and Walsh functions shown in 
Figure 3.6.
As one can see from the figure, an important parameter that unites both 
families of functions is the number of function zero crossing which coin-
cides, for these functions, with their index k. For sinusoidal functions, this 
parameter is associated with the notion of frequency. For Walsh functions, 
this parameter was termed sequency by Harmuth [1].
Sequency-wise ordering of Walsh functions is not accidental. In principle, 
ordering basis functions can be arbitrary. The only condition one should 
obey is matching between signal representation coefficients {αk} and the cor-
responding discretization and reconstruction basis functions φk
d x
( )( )
{
} and 
φk
r x
( )( )
{
}. However, almost always a certain “natural” ordering of basis func-
tions exists. For instance, shift (convolution) bases are ordered according to 
successive coordinate shifts. Sinusoidal basis functions are naturally ordered 
according to their frequency. Sequence-wise ordering of Walsh functions can 
be regarded natural for the following reason.
One of the most natural orderings of basis functions for signal representa-
tion is ordering, for which signal approximation error for a finite number N 
of terms in signal expansion over the basis decreases with the growth of N. 
For Walsh functions, it happens that, for many analog signals, ­sequency-wise 

70
Theoretical Foundations of Digital Imaging Using MATLAB®
ordering satisfies this requirement much better than other methods of order-
ing. Figure 3.7 illustrates this feature of Walsh function signal spectra.
Graphs on the figure show averaged squared Walsh spectral coefficients 
(power spectra) of image rows as functions of coefficients’ indices for sequence-
wise (Walsh) ordering and for Hadamard ordering. In Hadamard ordering, 
digits {km} of ordinary binary representation of index k Equation 3.43 rather 
than index Gray code digits km
GC
{
} are used for generating the basis functions:
	
walhadk
km m
m
( )
(
)
.
ξ
ξ
= −
∑
+
=
∞
1
1
0
	
(3.36)
Walsh functions are basis functions of the discrete transform called Walsh 
transform, which is discussed in Chapter 4, section “Binary Transforms.” In 
conclusion, note that signal expansion over Walsh function basis approxi-
mates signals with piece-wise constant functions just as it is the case for rect-
angular impulse basis functions.
Wavelets
A distinctive feature of shift (convolution) basis functions is that they 
are concentrated in a vicinity of sampling points and, for them, signal 
FIGURE 3.6
First eight sinusoidal and Walsh functions.

71
Image Digitization
representation coefficients (in this case signal samples) depend mostly on 
signal values in those vicinities; therefore, they carry “local” information 
about signals. In contrast to them, signal discrete representation for scale 
(multiplicative) bases is “global”: signal representation coefficients depend 
Av. Walsh spectrum of image rows
Av. Hadamard spectrum of image rows
(a)
(b)
(c)
10
8
6
4
2
10
8
6
4
2
100
200
300
Sequency index
400
500
100
200
300
Basis function index
400
500
FIGURE 3.7
A test image (a) and averaged power spectra of its rows in Walsh (b) and Hadamard (c) orderings.

72
Theoretical Foundations of Digital Imaging Using MATLAB®
on the entire signal. Sometimes it is useful to have a combination of these 
two features in the signal discrete representation. This is achieved with 
wavelet basis functions built using a combination of shift and scaling of a 
mother function. We have already addressed this feature in the section 
“Multiresolution Imaging: Wavelet Transforms” in Chapter 2 on multires-
olution imaging and indicated that a classic example of such a combina-
tion represents basis functions of Haar transform. Haar functions defined 
on interval X are combinations of shifted rectangular impulse functions 
{rect(x − kΔx/Δx)} and Rademacher functions radk (ξ) = {sign(sin(2kπξ))}:
	
har
rad
rect
k
x X
k
msb
msb
msb
msb
( )
( )
mod
,
,
ξ
ξ
ξ
ξ
=
−[ ]
(
)
=
≤
+
2
2
2
1
1
	
(3.37)
where msb is the index of the most significant nonzero digit (bit) in binary 
representation of k (Equation 3.29) and [k] mod 2msb is a residual from division 
of k by 2msb.
Haar functions are orthogonal on the interval [0, X]. Graphs of the first 
eight Haar functions are shown in Figure 3.8.
The figure clearly reveals the way in which Haar functions are built. One 
can see from the figure that Haar functions form groups according to the 
scale indexed by symbol msb (outlined by boxes in Figure 3.8) and that func-
tions within each group are generated by shift in coordinates by multiple 
of X/2msb. One can also see that signals reconstructed from their discrete 
representation over Haar basis functions belong to the same family of piece-
wise constant functions as signals reconstructed in the base of rectangular 
impulse basis functions and Walsh functions.
X
X
X
X
X
X
X
X
har0(X)
har1(X)
msb = 0
msb = 1
msb = 2
har2(X)
har3(X)
har4(X)
har5(X)
har6(X)
har7(X)
FIGURE 3.8
First eight Haar functions. Boxes unify Haar functions of the same scale.

73
Image Digitization
Numerical values of Haar functions can be found at each point by express-
ing Haar functions, as in the case of Walsh functions, via a binary code of the 
argument (Equations 3.29 and 3.32):
	
har x
k
k
msb
msb
msb
msb
( )
(
)
mod
.
=
−
[ ]
−[ ]
(
)
+
2
1
2
1
ξ
δ
ξ
	
(3.38)
Haar functions are basis functions of the discrete transform called Haar 
transform, which we discuss in Chapter 4, section “Binary Transforms.”
Currently, numerous wavelet bases are known. Interested readers are 
referred to numerous monographs on wavelets. As for each scale wavelets 
are convolutional functions, using wavelets as discretization bases can be 
treated as multiresolution sampling.
Optimality of Bases: Karhunen–Loeve and Related Transform
As it was mentioned, the selection of basis functions for signal discretization 
is governed, in particular, by the accuracy of signal approximation with a 
limited number of terms in their expansion over the bases. In this section, 
we address the issue of optimization of bases in this respect. Because bases 
have to be optimally selected not for individual signals but for certain signal 
ensembles, we will apply statistical treatment of signals outlined in the sec-
tion “Statistical Models of Signals and Transformations” in Chapter 2 and 
assume that signals belong to a certain family (ensemble) of signals and that 
the accuracy of signal representation is evaluated on average over this family.
Let {a(ω) (x)}, ω ∈ ΩA be a set of signals to be represented by their approxima-
tions in the form of a finite expansion:
	
a
x
a
x
x
k
k
N
k
r
( )
( )
( )
( )
( )
( )
( )
ω
ω
ω
α
ϕ
≅
=
=
−
∑

0
1
	
(3.39)
over orthonormal basis discretization and reconstruction basis functions 
ϕ
ϕ
k
d
k
r
x
x
( )
( )
( ) ;
( )
{
} {
} such that
	
ϕ
ϕ
δ
k
d
k
r
X
k l
x
x
x
k l
( )
( )
( )
( )
( , )
,


=
=
∗
−
∫
d
0
	
(3.40)
where * stands for a complex conjugate. Let us also assume that the approxi-
mation accuracy is evaluated in terms of mean square approximation error 
(MSE):
	
ε ω
α
ϕ
ω
ω
ω
ω
( )
( )
( )
( )
( )
( )
( )
( )
( )
( )
2
2
0
1
2
=
−
=
−
∫
∑
=
−
a
x
a
x
x
a
x
x
X
k
k
N
k
r

d
dx
X∫
.
	
(3.41)

74
Theoretical Foundations of Digital Imaging Using MATLAB®
Optimal values of coefficients 
α
ω
ω
k
( )( )
{
} that minimize MSE can be 
found by equating to zero derivatives of ε ω
( )
2 (Equation 3.47) over 
α
ω
α
α
ω
ω
ω
k
k
re
k
im
i
( )
( )
( )
( )
{
} =
+
{
}:
	
∂
∂
−
=
∂
∂
=
−
∑
∫
α
α
ϕ
α
ω
ω
ω
ω
ω
k
re
k
k
N
k
r
X
k
im
a
x
x
x
a
( )
( )
( )
( )
( )
( )
( )
,
( )
0
1
2
0
d
( )
( )
( )
( )
( )
,
ω
ω
α
ϕ
x
x
x
k
k
N
k
r
X
−
=
=
−
∑
∫
0
1
2
0
d
	
(3.42)
which implies that signal transform coefficients should be computed as
	
α
ω
ϕ
ω
ω
k
k
r
X
a
x
x
x
( )
( )
( )
( )
( )
.
=
( )
∗
∫
d
	
(3.43)
As it is shown in Appendix, the minimal MSE is equal in this case to
	
ε ω
ω
α ω
( )
( ,
)
( ) .
min
2
2
2
0
1
=
−
∫
∑
=
−
a x
x
X
k
k
N
d
	
(3.44)
One can further minimize average MSE over the given set Ω of signals 
by an appropriate selection of bases functions ϕk
r x
( )( )
{
} as follows (see 
Appendix):
	
ϕ
α
ϕ
ω
ω
k
opt
x
X
k
k
N
x
AV
a
x
x
k
( )
argmin
( )
( )
( )
( )
{
}
=
−




{
}
=
−
∫
∑
Ω
2
2
0
1
d








=
(
)
{
}
=
−
∫∫
argmax
(
,
)
(
)
( )
*
ϕ
ϕ
ϕ
k x
a
k
k
X
k
N
R x x
x
x
1
2
1
2
0
1
1
2
∑






d
d
x
x
,
	
(3.45)
where AVΩ means averaging over the signal set ΩA. Function Ra (x, y)
	
R x x
AV
a
x a
x
a
A
(
,
)
(
)
(
)
( )
( )
1
2
1
2
=


∗
Ω
ω
ω
	
(3.46)
is an autocorrelation function of signals {a(ω) (x)}. Then, optimal bases func-
tions ϕk
r x
( )( )
{
} are defined by the equation

75
Image Digitization
	
ϕ
ξ ϕ
ξ
ξ ϕ
ϕ
k
r
x
a
k
r
X
k
r
x
R x
k
( )
{
}
{
} =








∫
( )
argmax
( , )
( )
(
( )
( )
*( )
d
xx
x
X
k
N
)
.
d
∫
∑
=
−






0
1
	
(3.47)
From Cauchy–Schwarz–Buniakowsky inequality
	
f x f
x
x
f x
x
f x
x
X
X
X
1
2
1
2
1 2
2
2
1 2
( )
( )
( )
( )
*
/
/
d
d
d
∫
∫
∫
≤












,
	
(3.48)
which becomes equality when f1(x) is proportional to f2(x), it follows that opti-
mal basis functions are eigen functions of the integral equation
	
R x
y
x
a
k
X
k
k
( , )
( )
( )
ξ ϕ ξ
λ ϕ
d
∫
=
	
(3.49)
with kernel defined by the autocorrelation function (Equation 3.46) of signals. 
Scalar coefficients {λk} in this equation are called eigen values of the equation. 
Such bases are called Karhunen–Loeve bases [2,3].
Similar reasoning can be applied to integral representation of signals. Let 
signals a(ω)(x) be approximated by their integral representation over self-­
conjugate basis φ(x, f):
	
a
x
a
x
f
x f
f
F
( )
( )
( )
( )
( )
( ) ( , )
.
ω
ω
ω
α
ϕ
≅
= ∫

d
	
(3.50)
Then mean square approximation error
	
AV
AV
a
x
f
x f
f
F
Ω
Ω
ε ω
α
ϕ
ω
ω
( )
( )
( ) ( , )
( )
( )
2
2
=
−






∫
d
	
(3.51)
will be minimal if signal spectrum α(ω)(f) in this basis is obtained as
	
α
ϕ
ω
ω
( )
( )
( )
( )
( , )
f
a
x
x f
x
X
=
∗
∫
d
	
(3.52)
and basis φ(x, f) satisfies the integral equation
	
R x x
x
f
x
f
x
f
a
X
(
,
) (
, )
( )
(
, ),
1
2
2
2
1
ϕ
λ
ϕ
d
∫
=
∗
	
(3.53)

76
Theoretical Foundations of Digital Imaging Using MATLAB®
where Ra(x1, x2), as before, is the autocorrelation function (Equation 3.46) of 
signals {a(ω) (x)}. Signal transform with transform kernel defined by Equation 
3.53 is called the Karhunen–Loeve transform.
An important, though idealized, special case is that of statistically homo-
geneous (“stationary”) signals, whose correlation functions depend only on 
the difference of its arguments:
	
R
x x
R
x
x
a
a
1
2
1
2
,
.
(
) =
−
(
) 	
(3.54)
In this case, the basis optimality condition of Equation 3.53 takes the form
	
R x
x
x
f
x
f
x
f
a(
) (
, )
( )
(
, )
1
2
2
1
−
=
−∞
∞
∗
∫
ϕ
λ
ϕ
d
2
	
(3.55)
A solution of this equation is an exponential function
	
ϕ
π
( , )
exp(
).
x f
i
fx
=
2
	
(3.56)
Two important conclusions follow from this result:
Integral Fourier transform is an MSE optimal Karhunen–Loeve transform 
for signals with correlation function that depends only on the difference of 
its arguments.
For signals with power spectrum that decays with frequency, the best, in MSE 
sense, their approximation is the approximation with band-limited functions, 
whose Fourier spectrum is equal to zero outside a certain bandwidth [−F,F]:
	
a
x
f
i
fx
f
F
F
(
)
(
)
( ,
)
( )exp(
)
.
ω
ω
ω
α
π
=
−∫
2
d
	
(3.57)
Approximation MSE in this case is minimal and is equal to
	
AV
AV
f
f
AV
f
Ef
A
A
A
F
F
Ω
Ω
Ω
ε ω
α
α
ω
ω
( )
( )
( )
min
(
)
(
)
2
2
2


=
{
}
+
{
}
−∞
−
∞
∫
∫
d
..
	
(3.58)
Karhunen–Loeve transform provides the theoretical lower bound for com-
pact (in terms of the number of terms in signal decomposition) signal dis-
crete representation for MSE criterion of signal approximation.
Consider now a discrete equivalent of the Karhunen–Loeve expansion. Let 
a
ak
ω
ω
= {
}
( ) , k = 0,1,. . .,N − 1, ω ∈ Ω be a discrete signal from an ensemble of 
signals Ω. Find an orthogonal transform TN = {
}
ϕk r,

77
Image Digitization
	
α
α
α
ϕ
ω
ω
ω
ω
=
=
=






=
−
∑
TN
r
k
k r
k
N
a
( )
( )
,
0
1
	
(3.59)
that minimizes, on average over the signal ensemble Ω, mean square error
	
ε ω
ω
ω
( )
( )
( )
2
2
0
1
Ω
Ω
=
−
(
)








=
−
∑
AV
a
a
k
k
k
N

	
(3.60)
between signals ak
ω
{ } and their approximation by truncated expansion
	


α
α
ϕ
ω
ω
=
=






∗
=
−
∑
ak
r
k r
r
N
( )
,
0
1
	
(3.61)
over N
N
≤
 terms. By virtue of the Parseval’s identity, the transform is a 
solution of the equation
	
T =








=
{
}
=
−
{
}
∑
argmax
argmax
,
,
( )
ϕ
ω
ϕ
ω
α
k r
k r
AV
AV
a
r
r
N
k
Ω
Ω
2
0
1

(
)
(
)
.
,
,
,
an
k r
n r
n
N
k
N
r
N
k r
ω
ϕ
ϕ
ϕ
∗
∗
=
−
=
−
=
−
{
}
∑
∑
∑






0
1
0
1
0
1

	 	
	
	
(3.62)
Denote
	
R k n
AV
a
a
a
k
n
( , )
.
(
)
(
)
=
(
)




∗
Ω
ω
ω
	
(3.63)
Then, the transform optimization equation (3.62) becomes
	
T =



{
}
∗
=
−
=
−
=
−
∑
∑
∑
argmax
( , )
(
)
,
,
,
ϕ
ϕ
ϕ
k r
R k n
a
k r
n r
l
N
k
N
r
N
0
1
0
1
0
1





=






{
}
∗
=
−
=
−
∑
∑
argmax
(
)
( , )
,
,
,
ϕ
ϕ
ϕ
k r
n r
a
k r
k
N
n
N
R k n
0
1
0
1
r
N
=
−
∑






0
1

.
	
(3.64)
From the Cauchy–Schwarz–Bunyakowsky inequality
	
a b
a
b
k
k
k
N
k
k
N
k
k
N
=
−
=
−
=
−
∑
∑
∑






≤
⋅
0
1
2
2
0
1
2
0
1
	
(3.65)

78
Theoretical Foundations of Digital Imaging Using MATLAB®
that converts to equality for {ak = λbk}, where λ is an arbitrary constant, it fol-
lows that the transform optimization equation becomes
	
R k n
a
k r
k
N
r
n r
( , )
.
,
,
ϕ
λ ϕ
=
−
∑
=
0
1
	
(3.66)
The transform whose basis functions satisfy Equation 3.66 is called the 
Hottelling transform. The result of applying this transform is called the signal 
principal component decomposition [4].
If no ensemble averaging is required when evaluating the approximation 
error, Equation 3.66 becomes
	
a a
k
n
k r
r
n r
k
N
(
)
.
,
,
∗
=
−
=
∑
ϕ
λ ϕ
0
1
	
(3.67)
The signal decomposition with a transform defined by basis functions that 
are solutions of Equation 3.67 is called singular value decomposition (SVD).
The capability of transforms to concentrate signal energy in few signal 
decomposition coefficients is called energy compaction capability. Theoretically, 
the Karhunen–Loeve transform and the related Hottelling and SVD trans-
forms have the best energy compaction capability among linear trans-
forms. However, in the practice of image processing, they remain, because 
of implementation problems, to serve only as a theoretical benchmark and 
other transforms are used, such as discrete Fourier, discrete cosine, discrete 
Walsh, and discrete Haar transforms that will be introduced in Chapter 4.
Figure 3.9 generated using MATLAB program EnergyCompact_DFT_
DCT_Walsh_Haar_2D_CRC.m provided in Exercises illustrates, for compari-
son, energy compaction capability of these transforms for four test images. 
One can see from the plots that, for these test images, discrete cosine trans-
form (DCT) exhibits the best energy compaction capability. In fact, DCT has 
the edge over other known transforms in most of the image processing appli-
cations. We will discuss the reasons for this later in the section “Discrete 
Cosine and Sine Transforms.”
Image Sampling
The Sampling Theorem and Signal Sampling
Representation of images in the form of arrays of image samples taken, 
usually, in nodes of a uniform rectangular sampling grid is the basic form 
of image discrete representation. Although imaging devices that produce 

79
Image Digitization
Test image 1
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
1
0.95
0.9
0.85
0.8
0.75
0.7
0.9
1
0.98
0.96
0.94
1
0.99
0.98
0.97
0.96
0.95
0.8
0.7
0.6
0.1
0.2
0.3
0.4
Bandwidth (in fraction of the base band)
Test image 1: Fraction of signal energy
Test image 2: Fraction of signal energy
Test image 3: Fraction of signal energy
Test image 4: Fraction of signal energy
DCT
DFT
Walsh
Haar
DCT
DFT
Walsh
Haar
DCT
DFT
Walsh
Haar
DCT
DFT
Walsh
Haar
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
Bandwidth (in fraction of the base band)
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
Bandwidth (in fraction of the base band)
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
Bandwidth (in fraction of the base band)
0.5
0.6
0.7
0.8
0.9
1
Test image 2
Test image 3
Test image 4
FIGURE 3.9
Comparison of energy compaction capability of discrete transforms for four test images. Plots 
on the right of each image show the fraction of image signal energy contained within a fraction 
of image transform coefficients limited by a square in transform domain.

80
Theoretical Foundations of Digital Imaging Using MATLAB®
images may work on different principles, for image displays and image pro-
cessing software, such representation is the standard.
The theoretical foundation of signal sampling is provided by the sampling 
theorem. It was introduced in communication engineering by Vladimir A. 
Kotelnikov [5] and Claude Shannon [6], although, as a mathematical theo-
rem, it was formulated earlier by J. M. Whittaker [7]. Here is how the sam-
pling theorem is formulated in Shannon’s classical paper [6]: “If a function x(t) 
contains no frequencies higher than B hertz, it is completely determined by giving 
its ordinates at a series of points spaced 1/(2B) seconds apart”. It is in this for-
mulation that it is usually known and taught. In reality, however, there are 
no band-limited signals and precise signal reconstruction from its sampled 
representation is never possible. Therefore, if sampling is used for signal dis-
cretization, one needs to know how to minimize signal distortions due to its 
sampling.
In what follows, we introduce an approach to formulation of the sampling 
theorem that directly addresses this problem of minimization of approxima-
tion error in signal reconstruction from its sampled representation.
1D Sampling Theorem
Let φ(r)(x) be the PSF of signal/image reconstruction/display device, φ(s)(x) be 
the PSF of signal sampling device, and Δx be the signal sampling interval. 
Then, discrete representation coefficients {αk} of a signal a(x) are its samples:
	
α
ϕ
k
s
X
a x
x
k x
x
=
−
∫( )
(
)
∆
d
	
(3.68)
and its reconstructed copy is
	
a
x
x
k x
r
k
r
k
( )
( )
( )
(
).
=
−
∑α ϕ
∆
	
(3.69)
Integration over x in Equation 3.68 and summation over k in Equation 
3.69 are performed within signal boundaries. Note that in this formula-
tion, we made a deliberate simplifying assumption that the coordinate of 
the signal sampling point with index k = 0 is x = 0 in both signal sampling 
and reconstruction. In general, there might be arbitrary shifts of the signal 
sampling grid with respect to the sampling and reconstruction devices 
coordinate systems. However, in the analysis of signal sampling, this 
arbitrary shift plays no essential role and can be disregarded. Later, in 
Chapter 4, we will see that these possible shifts must be taken into account 
when describing discrete representations of signal transforms other than 
convolution.

81
Image Digitization
Without violating the generality, one can, in order to simplify further 
mathematical analysis, rewrite the integration in Equation 3.68 and the sum-
mation in Equation 3.69 in infinite limits:
	
α
ϕ
k
s
a x
x
k x
x
=
−
−∞
∞
∫( )
(
)
( )
∆
d
	
(3.70)
	
a
x
x
k x
r
k
r
k
( )
( )
( )
(
)
=
−
=−∞
∞
∑α ϕ
∆
	
(3.71)
assuming that signal a(x) and its samples {αk} are equal to zero outside the 
real intervals of support. Now, modify Equations 3.70 and 3.71 in the follow-
ing way:
	
α
ϕ
ξ ϕ
ξ
ξ δ
k
s
s
a x
x
k x
x
a
x
x
k
=
−
=
−








−
−∞
∞
−∞
∞
∫
∫
( )
(
)
( )
(
)
(
( )
( )
∆
∆
d
d
x
x
a
x
x
k x
x
a
k x
s
s
)
( ) (
)
(
)
( )
( )
d
d
−∞
∞
−∞
∞
∫
∫
=
−
=
δ
∆
∆
	
(3.72)
	
a
x
x
k x
k x
x
r
k
r
k
k
k
r
( )
( )
( )
( )
(
)
(
)
(
=
−
=
−








=−∞
∞
=−∞
∞
∑
∑
α ϕ
α δ ξ
ϕ
∆
∆
−
=
−








−
=
−∞
∞
=−∞
∞
−∞
∞
∫
∑
∫
ξ
ξ
δ ξ
ϕ
ξ
ξ
)
(
) (
)
(
)
( )
( )
d
d
a
k x
k x
x
s
k
r
∆
∆
a
x
s
r
( )
( )(
)
,
( )
d
ξ ϕ
ξ
ξ
−
−∞
∞
∫
	
(3.73)
which introduces “virtual” signals
	
a
x
a
x
s
s
( )
( )
( )
( )
(
)
=
−
−∞
∞
∫
ξ ϕ
ξ
ξ
d
	
(3.74)
and
	
a
x
a
k x
x
k x
s
s
k
( )
( )
( )
(
) (
).
=
−
=−∞
∞
∑
∆
∆
δ
	
(3.75)
Further analysis of signal sampling is much simplified in the Fourier trans-
form domain. Compute the Fourier spectra of virtual signals a(s)(x) and a
x
s( )( ). 

82
Theoretical Foundations of Digital Imaging Using MATLAB®
The spectrum α(s)(f) of signal a(s)(x) (Equation 3.74), whose instantaneous values 
{a(s)(kΔx)} form sampled representation of signal a(x), is, by the convolution theo-
rem, a product
	
α
α
( )
( )
( )
( )
( )
s
s
f
f FR
f
=
	
(3.76)
of spectrum α(f) of the signal a(x) and the frequency response FR(s)(  f) of the 
sampling device, Fourier transform of its PSF φ(s)(x):
	
FR
f
x
i
fx
x
s
s
( )
( )
( )
( )exp(
)
.
=
−∞
∞
∫ϕ
π
2
d
	
(3.77)
Fourier spectrum of the virtual signal a
x
s( )( ) involved in the reconstruction 
of signal a(x) from its sampled representation {a(s) (kΔx)} can be found as (see 
Appendix)
	


α
π
δ
( )
( )
( )
( )
( )exp(
)
(
) (
)
s
s
s
k
f
a
x
i
fx
x
a
k x
x
k x
=
=
−

−∞
∞
=−∞
∞
∫
∑
2
d
∆
∆







=
−
−∞
∞
∫
exp(
)
( )
( )
exp
(
)
( )
i
fx
x
p FR
p
p x
x
i
k x f
p
s
2
1
2
π
α
π
d
d ∆
∆
∆








=−∞
∞
−∞
∞
∑
∫
k
.
	 	
	
	
(3.78)
The sum in the latter expression is a Fourier series expansion on interval 
1/Δx of a function with expansion coefficients, equal to 1, that is, of a Dirac 
delta (Equation 2.24). Therefore, this series converges to a periodical replica-
tion of delta-function with a period 1/Δx. In this way, we arrive at the identity
	
1
2
∆
∆
∆
x
i
k x f
p
f
p
m
x
m
k
exp[
(
)]
π
δ
−
=
−
+




=−∞
∞
=−∞
∞
∑
∑
	
(3.79)
called the Poisson summation formula.
Inserting this formula into Equation 3.77, obtain that the spectrum of the 
virtual signal α( )( )
s
f  is composed of periodical replicas of the spectrum α(x)(f):
	
α
α
α
( )
( )
( )
f
x
f
m
x
x
f
m
x FR
f
m
x
s
m
s
=
+



=
+




+



=−∞
∞
∑
∆
∆
∆
∆
∆
=−∞
∞
∑
m
.
	
(3.80)
This analysis reveals that coefficients {αk} of discrete representation of sig-
nal a(x) over shift basis functions {φ(s)(x − kΔx); φ(r) (x − kΔx)} are instantaneous 
values {as (kΔx)} of a signal a(s)(x) obtained from the signal a(x) by its “prefilter-
ing” in the sampling device (and not those of the signal a(x)).

83
Image Digitization
Signal sampling can be interpreted as converting prefiltered input signal 
a(s)(x) into a virtual signal a
x
s( )( ) (Equation 3.75), whose Fourier spectrum is 
composed of periodically repeated replicas of initial signal spectrum modi-
fied by the frequency response of signal sampling device (Equation 3.80); the 
replication period BB = 1/Δx is defined by the sampling interval and forms; it 
is called the signal baseband.
Signal reconstruction from its sampled representation can be treated as 
a “postfiltering” of the virtual discrete signal a
x
s( )( ) in the reconstruction 
device:
	
a
x
a
x
r
r
( )
( )
( )
( )
(
)
.
=
−
−∞
∞
∫ ξ ϕ
ξ
ξ
d
	
(3.81)
This “postfiltering” can be described in the Fourier transform domain as 
multiplication
	
α
α
( )
( )
( )
( )
( )
( )
r
s
r
f
f FR
f
= 
	
(3.82)
of spectrum α( )( )
s
f  of the virtual signal a x
s( ) by frequency response FRr(f) of 
the signal reconstruction device:
	
FR
f
x
i
fx
x
r
r
( )
( )exp(
)
.
( )
=
−∞
∞
∫ϕ
π
2
d
	
(3.83)
The described interpretation of signal sampling and signal reconstruction 
from its samples is illustrated by flow diagrams in Figures 3.10 and 3.11 and 
by plots in Figure 3.12.
Now, one can easily see that distortions of the reconstructed signal com-
pared to the initial nonsampled signal are due to the following reasons:
• Modifications of the signal spectrum by its prefiltering in the sam-
pling device (Equation 3.76)
• Penetrating tails of the prefiltered signal spectrum periodical repli-
cas inside the signal baseband, which causes spectra aliasing
• Remains of the signal spectrum periodical replicas outside the sig-
nal baseband not perfectly filtered out by the “postfiltering” in the 
reconstruction device
We postpone detailed qualitative and quantitative analysis of sampling 
artifacts till the sections “Sampling Artifacts: Quantitative Analysis” and 
“Sampling Artifacts: Qualitative Analysis” and formulate here the major con-
clusion that, for signals, whose spectral energy does not grow with frequency, 

84
Theoretical Foundations of Digital Imaging Using MATLAB®
“Prefiltering”
∫a(ξ)φ(s)(x − ξ)dx
∞
−∞
Taking signal
instantaneous
samples 
a(x)
Clock x = k∆x
a(s)(x)
{a(s) (k∆x)}
FIGURE 3.10
​Flow diagram of signal sampling.
FR of the ideal prefilter
FR of sampling device
Intial signal spectrum
FR of reconstruction device
M = –2
M = –1
M = 0
M = 1
M = 2
Signal base band
Signal base band
Replica of prefiltered signal spectrum
FR of the ideal postfilter
Prefiltered signal spectrum
f
FIGURE 3.12
Fourier domain representation of signal sampling and reconstruction: upper plot—initial 
signal spectrum, its spectrum after “prefiltering” in the sampling device and frequency 
responses (FR) of the sampling device and of the ideal low-pass filter that defines the signal 
baseband; lower plot—periodical replicas of sampled signal spectrum described by Equation 
3.80 and frequency responses (FR) of the signal reconstruction device and of the ideal low-
pass reconstruction filter.
{a(s)(kΔx)}
“Postfiltering”
∫a~(s)(ξ)ϕ(r)(x−ξ)dξ
a~(s)(x)
a(r)(x)
Forming virtual signal
∑a(s)(k∆x)δ(x − k∆x) 
∞
∞
−∞
=
k=−∞
a~(s)(x)
Clock x = kΔx
FIGURE 3.11
A mathematical model of devices for restoring continuous signals from their samples.

85
Image Digitization
signal distortions due to sampling can be minimized in terms of signal recon-
struction MSE, if signal prefiltering and postfiltering are performed by the 
ideal low-pass filters with frequency response
	
FR
f
rect
f
x
x
LP
(
)( )
(
)
.
=
+


1 2∆
∆
	
(3.84)
PSF of these filters is sinc-function (πx/Δx) introduced in the section 
“Properties of the Integral Fourier Transform” in Chapter 2. Thus, with the 
ideal low-pass pre- and postfilters, signal samples are obtained as
	
α
π
k
s
a
k x
x
a x
x
k x
x
x
=
=
−




−∞
∞
∫
( )(
)
( )sinc
∆
∆
∆
∆
1
d
	
(3.85)
and signal reconstruction from its samples is performed as
	
a
x
a
k x
x
k x
x
r
s
k
( )
( )
( )
(
)sinc
.
=
−




=−∞
∞
∑
∆
∆
∆
π
	
(3.86)
Reconstruction of a continuous signal from its samples according to 
Equation 3.86 is called sinc-interpolation.
Ideal low-pass filters do not distort the signal spectrum within the base-
band and remove all spectral components outside the baseband, thus pre-
venting signal spectrum from aliasing. Signal prefiltering with the ideal 
low-pass filter makes the signal band-limited.
In a special case of band-limited signals, the result of sampling are sam-
ples {a(kΔx)} of signals themselves and signals are perfectly (distortion less) 
reconstructed from the result of sampling:
	
a x
a k x
x
k x
x
k
( )
(
)sinc
.
=
−




=−∞
∞
∑
∆
∆
∆
π
	
(3.87)
The above reasoning can be summarized in the following formulation of 
the sampling theorem:
For signals with power spectrum that does not grow with frequency, the 
MSE of their reconstruction from their sampled representation is minimal 
if sampling and reconstruction are performed using ideal low-pass filters 
for pre- and postfiltering. Band-limited signals with baseband BB = 1/Δx are 
precisely reconstructed by sinc-interpolation of their instantaneous values 
a(kΔx) taken with interval Δx.

86
Theoretical Foundations of Digital Imaging Using MATLAB®
Sampling theorem also allows evaluating the volume of signal discrete 
representation, that is, the number of signal samples N needed to represent 
signals of length X and baseband F:
	
N
X
x
X
F
XF
=
=
=
∆
1
.
	
(3.88)
Signal space-bandwidth product XF is a fundamental parameter that defines 
the number N of signal degrees of freedom.
Sampling Two-Dimensional and Multidimensional Signals
For sampling 2D signals, 2D discretization and reconstruction basis functions 
should be used. The simplest way to generate and to implement in image sam-
pling and display devices 2D sampling and reconstruction basis functions is to 
use separable 2D basis functions that are formed as a product of 1D function:
	
ϕ
ϕ
ϕ
ϕ
1
2
1
2
( )
( )
( )
( )
(
)
(
)
(
)
(
)
s
s
r
r
x
k x
y
k y
x
k x
y
k y
−
−
{
}
−
−
{
}
∆
∆
∆
∆
and
	 (3.89)
With these sampling and reconstruction functions, image sampling and 
reconstruction are carried out successively row-wise/column-wise over a 
rectangular sampling grid in Cartesian coordinates. In the domain of 2D 
Fourier transform, this corresponds to periodical replication of signal spec-
trum in Cartesian coordinates as it is shown in Figure 3.13a and c. For sam-
pling intervals {Δx, Δy} along two coordinates {x, y}, replication periods of 
spectra replicas are {1/Δx, 1/Δy}, respectively. Widening sampling intervals 
in order to reduce the number of signal samples is possible until spectra 
replicas do not overlap too much to cause unacceptable spectra aliasing. 
Therefore, the optimal will be a sampling grid that corresponds to most 
dense possible packing spectra replicas in the spectral domain. The oppor-
tunities for achieving spectra replicas dense packing depend on the shape 
of the figure that encompasses the area of image spectrum, which contains 
image spectral components that must not be sacrificed due to sampling.
If image spectrum is bounded by a rectangle, rectangular sampling grid 
is optimal and the number N of image samples, or the number of image 
degrees of freedom, will be equal to the product of image area Sx, y and spec-
trum area Sf
f
x
y
,
:
	
N
S
S
x y
f
f
x
y
=
,
, .	
(3.90)
However, if the shape of the figure that bounds image spectrum is not a rect-
angle, rectangular sampling grid is not optimal. Consider, for instance, the shape 
of the spectrum shown in Figure 3.13a. If images with such spectrum shape are 
sampled using square sampling grid (Figure 3.13b), sampling will correspond 

87
Image Digitization
FIGURE 3.13
(a) An example of a figure that encompasses image spectrum; (b) square sampling grid; (c) 
and (d) its spectrum periodical replications in rectangular and 45°-tilted coordinate systems, 
correspondingly; (e) 45°-tilted sampling grid; (f) and (g) an example of a natural outdoor scene 
and its spectrum bounded on a certain intensity level; (h) a magazine printout of a gray-scale 
image printed using the 45o-tilted sampling grid.

88
Theoretical Foundations of Digital Imaging Using MATLAB®
to periodical replication of spectra as shown in Figure 3.13c. However, for this 
particular spectrum shape, one can achieve substantially denser packing of 
spectrum replicas, which is shown in Figure 3.13d. To achieve this, image sam-
pling over a square sampling grid in 45°-rotated coordinates should be per-
formed as it is shown in Figure 3.13e. As one can see in Figure 3.13d, the denser 
periodical pattern of spectrum replicas preserves same sampling intervals over 
45°-rotated coordinates as those for the rectangular sampling grid in nonro-
tated coordinates (Figure 3.13b). Therefore, distances between samples in non-
rotated coordinates become larger by 2, which results in twofold saving of the 
number of samples needed to reconstruct images.
This particular example of the image spectrum shape is not occasional. It 
is characteristic for many images of outdoor scenes, such as that shown in 
Figure 3.13f, in which horizontally and vertically oriented objects prevail; in 
their spectra, correspondingly, vertical and horizontal spatial high frequen-
cies have higher intensity than diagonal ones as it is seen in Figure 3.13g. It is 
not surprising that the human visual system evolved to have higher sensitiv-
ity to horizontal and vertical spatial frequencies than to diagonal frequencies.
In viewing printed or displayed images, human eye optics plays the role of 
a postfilter. Selection of a 45o-rotated rectangular sampling grid that fits the 
spectra of natural images and human eye spatial filtering secures invisibility 
of sampling artifacts for less dense sampling grid. The 45°-rotated sampling 
grid became a standard in the print industry for printing gray-scale images. 
An example of a magnified fragment of such a printout, in which rotated 
sampling grid is seen, is shown in Figure 3.13h.
In many applications, images have spectra that decay more or less uniformly 
in all directions such as, for instance, shown in spectrum of Figure 3.14a of 
the image presented in Figure 3.7a. For such images with isotropic spectra 
that can be regarded as bounded by a circle, hexagonal periodical replication 
of spectra is the densest (compare Figures 3.14b and 3.14c). Hence, hexagonal 
sampling grid shown in Figure 3.14d will be optimal in this case. Hexagonal 
sampling grids are frequently used in color displays and print art. Hexagonal 
arrangement of light-sensitive cells can also be found in compound eyes of 
insects and in retinas of eyes of vertebrates (Figures 3.14e and 3.14f).
The described examples of optimization of sampling grids by means 
of rotating and tilting do allow reducing the number of image samples N 
required for image reconstruction, but this number still exceeds the prod-
uct S
S
x y
f
f
x
y
,
,  of image and its spectrum areas as long as gaps remain empty 
in periodic replication of image spectra. This product can be regarded as a 
lower bound for the required number of image samples
	
N
S
S
x y
f
f
x
y
≥
,
, . 	
(3.91)
This lower bound can, at least in principle, be achieved with sub-band decom­
position sampling.

89
Image Digitization
In discretization with sub-band decomposition sampling, image a(x1, x2) is 
decomposed into a sum
	
a x y
a
x y
k
k
K
( , )
( , )
( )
≅
=
−
∑
0
1
	
(3.92)
of certain number K of components {a(k) (x, y)} with rectangular spectra that 
together approximate image spectrum as it is shown in Figure 3.15.
FIGURE 3.14
(a) Bounded on a certain intensity spectrum of the image shown in Figure 3.7; (b) and (c) repli-
cation of circularly bounded image spectrum for Cartesian and hexagonal sampling grids: the 
same number of circular spectra replicas occupy less area, when they are packed in a hexagonal 
coordinate system than in Cartesian coordinates; (d) hexagonal sampling grid; (e) compound 
eye of tsycada; (f) hexagonal arrangement of cones in fovea of human eye retina.

90
Theoretical Foundations of Digital Imaging Using MATLAB®
For each of the components, rectangular sampling grid with sampling 
intervals defined by dimensions of the component spectrum will be opti-
mal. Hence, the required number Nk of samples of the k-th component with 
spectrum Sf
f
k
x
y
,
( )  will be equal to S
S
x y
f
f
k
x
y
,
,
( ) , which, for the entire image, amounts 
to N
N
S
S
k
K
k
x y
k
K
f
f
k
x
y
= ∑
=
∑
=
=
1
1
,
,
( )  samples. As soon as lim
,
( )
,
k
k
K
f
f
k
f
f
S
S
x
y
x
y
→∞
=
∑
=
1
, 
lim
(
,
)
(
,
)
( )
k
k
K
k
a
x x
a x x
→∞
=
∑
=
1
1
2
1
2 , and the lower bound S
S
x y
f
f
x
y
,
,  for N is achieved
	
lim
lim
.
,
,
K
K
k
k
K
x y
f
f
N
N
S
S x
y
→∞
→∞
=
=
=
∑
1
	
(3.93)
Elucidate that the spectra of high-frequency components (components 2, 3, 
4, etc. in Figure 3.15) extracted from the image by means of the correspond-
ing ideal bandpass filters must be, before sampling, shifted to the coordinate 
origin. For this, they must be multiplied (or, in communication engineering 
jargon, modulated) by a sinusoidal signal of spatial frequencies defined by 
coordinates of the symmetry center of the sub-band (for instance, for the 
fourth component in Figure 3.15 it will be cos[
(
)]
( )
( )
2
10
4
20
4
π f
x
f
y
+
). The modu-
lated signal then has to be subjected to a low-pass prefiltering using a filter 
with a flat frequency response within the bandwidth defined by the band-
width of the shifted sub-band. After that the sub-band component extracted 
in this way is ready for sampling over a rectangular sampling grid with 
sampling intervals defined by dimensions of the sub-band. For image recon-
struction, each sampled sub-band component is reconstructed using the 
corresponding 2D low-pass interpolating filter and then, before summation 
f2
f (4) f (4)
10′
20′
–f (4)–f (4)
10′
20′
f1
Sub-band 3
Sub-band 2
Sub-band 2
Sub-band 3
Sub-band 1
4
5
6
4
5
6
FIGURE 3.15
Image spectrum sub-band decomposition. As an example, the spectrum of the image of Figure 
3.7a is shown bounded on a certain intensity level; six sub-bands of this spectrum are pre-
sented to illustrate the sub-band decomposition process that can be extended ad infinitum.

91
Image Digitization
with other components, multiplied by the corresponding “demodulating” 
sinusoidal signal in order to return the component spectrum in its original 
position in the signal spectrum.
Sampling Artifacts: Quantitative Analysis
In this section, we will show how one can numerically evaluate sampling 
artifacts. For the sake of simplicity, a 1D case will be analyzed. Let φ(s) (x) and 
φ(r) (x) be PSFs of sampling and reconstruction devices, Δx be the sampling 
interval, and N be the number of sampled signal samples used for signal 
reconstruction.
Derive a relationship between initial signal a(x) and signal a(r)(x) recon-
structed from its samples that explicitly involves sampling and reconstruc-
tion device parameters. From Equations 3.68 and 3.69, it follows that
	
a
x
x
k x
a
k x
r
k
r
k
N
s
( )
=
−
−∞
∞
=
−
=
−





∑
∫
( )
(
)
( )
(
)
( )
( )
α ϕ
ξ ϕ
ξ
ξ
∆
∆
0
1
d

−
=
−
−
=
−
−∞
∞
=
∑
∫
ϕ
ξ
ξ
ϕ
ξ
ϕ
( )
( )
( )
(
)
( )
(
)
(
)
r
k
N
s
r
k
N
x
k x
a
k x
x
k x
∆
∆
∆
0
1
0
d
−
−∞
∞
∑
∫
=
1
a
h
x
s
r
( )
( , )
,
( & )
ξ
ξ
ξ
d
	
(3.94)
where
	
h
x
k x
x
k x
s
r
s
r
k
N
( & )
( )
( )
( , )
(
)
(
)
ξ
ϕ
ξ
ϕ
=
−
−
=
−
∑
∆
∆
0
1
	
(3.95)
is an overall PSF of the sampling and reconstruction devices.
As we saw in the section “The Sampling Theorem and Signal Sampling,” 
it is easier to analyze those procedures in Fourier domain. Find the Fourier 
spectrum α(r) (f) of the reconstructed signal a(r) (x) in its connection with spec-
trum α(f) of the initial signal:
α
π
ξ
ξ
ξ
( )
( )
( & )
( )
( )exp(
)
( )
( , )
r
r
s
r
f
a
x
i
fx
x
a
h
x
=
=



−∞
∞
−∞
∞
∫
∫
2
d
d



=
−






−∞
∞
−∞
∞
∫
∫
exp(
)
( )exp(
)
( &
i
fx
x
p
i
p
p h s
2
2
π
α
π ξ
d
d
r
s
r
x
i
fx
x
p
p
h
x
i
fx
)
( & )
( , )exp(
)
( )
( , )exp
(
ξ
π
ξ
α
ξ
π
2
2
d d
d
−∞
∞
−∞
∞
∫∫
=
−p
p x
ξ
ξ
)


−∞
∞
−∞
∞
−∞
∞
∫∫
∫
d d d
	

92
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−∞
∞
∫α( )
( , )
,
( & )
p FR
f p
p
s
r
d
	
(3.96)
where FR(s&r)(  f, p) is the overall frequency response of the sampling and 
reconstruction procedures, Fourier transform of their overall PSF:
	
FR
f p
h
x
i
fx
p
x
s
r
s
r
( & )
( & )
( , )
( , )exp
(
)
.
=
−


−∞
∞
∫
ξ
π
ξ
ξ
2
d d
	
(3.97)
Substitute Equation 3.95 into Equation 3.97 and obtain:
	
FR
f p
k x
x
k x
i
fx
p
s
r
s
r
k
N
( & )
( )
( )
( , )
(
)
(
)exp
(
)
=
−
−
−


=
−
∑ϕ
ξ
ϕ
π
ξ
∆
∆
0
1
2

=
−


{
−∞
∞
−∞
∞
∗
∫∫
d d
x
FR
f FR
p
N
N
f
p N x
r
s
ξ
π
( )
( )
( )
( )
sincd
; (
)
exp
∆
×
i
f
p N
x
π(
)(
)
,
−
−

}
1 ∆
	
	
	
	
(3.98)
where FR(s) (·) and FR(r) (·) are frequency responses of signal sampling and 
reconstruction devices, defined by Equations 3.77 and 3.83, and
	
sincd(
; )
sin
sin(
)
N x
x
N
x N
=
	
(3.99)
is the discrete sinc-function, discrete analog of the sinc-function. Note that 
Equation 3.98 is a special case of Equation 4.24 for overall frequency response 
of digital filters.
Because of the finite number of signal samples N used for signal reconstruc-
tion from samples, signal sampling and reconstruction procedures are not 
shift invariant and behave differently on signal borders and on signal parts 
that are far from the borders. Border effects add additional artifacts in the 
reconstructed signal. When the number of signal samples increases, border 
effects diminish and therefore can be neglected for some sufficiently large N.
Consider the asymptotic behavior of FR(s&r)(  f, p) when N → ∞. By Poisson’s 
summation formula (Equation 3.79), obtain from Equation 3.102:
	
lim
( , )
( )
( )
( & )
( )
( )
N
s
r
r
s
m
FR
f p
xFR
f FR
p
f
p
m
x
→∞
∗
=−∞
∞
=
−
+




∑
∆
∆
δ
.
	
(3.100)

93
Image Digitization
Substitution of Equation 3.100 in Equation 3.96 gives
	
lim
( )
( )
( )
( )
( )
( )
N
r
s
r
m
f
p
p
FR
f
f
p
m
x
→∞
∗
=−∞
∞
−∞
∞
=
−
+




∑
α
α
δ
⋅
⋅
FR
∆
∫
∑
=
+




+



=
∗
=−∞
∞
 dp
FR
f
f
m
x FR
f
m
x
FR
f
r
s
m
r
( )
( )
( )
( )
( )
α
∆
∆
FR
f
f
FR
f
f
m
x
f
m
x
s
r
s
s
∗
+
+



+
−






( )
( )
( )
( )
( ) ( )
( )
α
α
α
 
∆
∆


=
∞
∑
m 1
.
	 	
	
	
(3.101)
Equation 3.101 shows that the signal a(r)(x) reconstructed from samples of 
signal a(x) consists of two components. The first component (the first term of 
Equation 3.104) is a copy of signal a(x), modified by its convolution with PSFs 
of the sampling and reconstruction devices. This component does not con-
tain aliasing terms and specifies deviation of reconstructed signal spectrum 
from the initial one:
	
ε
α
sp
r
s
f
FR
f FR
f
f
( )
( )
( )
( ).
( )
( )
=
−


∗
1
	
(3.102)
The second component is an aliasing one. Its spectrum εalsng( f ) consists of 
periodical replicas {
(
)}
( )
α S
f
m
x
±
/∆
 of spectrum α(s)(f) of sampled signal a(s)(x) 
(Equation 3.76):
	
ε
α
α
alsng
r
s
m
f
FR
f
f
m
x FR
f
m
x
f
( )
( )
( )
( )
=
+




+







+
−
=
∞
∑
∆
∆
1
m
x FR
f
m
x
s
∆
∆




−







( )
.
	
(3.103)
A reasonable measure to characterize this component is its energy com-
puted on average over the signal ensemble
	
ε
ε
alsng
alsng
AV
f
f
2
2
=








−∞
∞
∫
Ω
( )
,
d
	
(3.104)
which, as it is shown in Appendix, can be computed as
	
ε
ξ
ξ
alsng
r
a
s
m
FR
f
SD
f
m
FR
f
m
2
2
2
1
2
=
+




+







=
∞
∑
( )
( )
( )
∆
∆




−∞
∞
∫
df
	

94
Theoretical Foundations of Digital Imaging Using MATLAB®
	
+
−




−










=
∞
∑
2
2
2
1
FR
f
SD
f
m
FR
f
m
r
a
s
m
( )
( )
( )
∆
∆
ξ
ξ
df
−∞
∞
∫
.
	
(3.105)
Interpretation of this formula is straightforward from Figure 3.12.
Sampling Artifacts: Qualitative Analysis
Although Equations 3.102 and 3.105 provide certain numerical characteriza-
tion of signal distortions due to sampling, they do not tell much about their 
qualitative features, such as, their visual appearance in images or their influ-
ence on readability of images and performing other image analysis tasks. In 
this section, we will address these issues.
One of the most characteristic and clearly visible sampling artifacts is a 
stroboscopic reduction of frequency of periodical signal components with 
frequencies that exceed the highest frequency 1/2Δx of the signal baseband 
as defined by the sampling interval Δx. If properly prefiltered, such compo-
nents are removed from the signal. Otherwise their replicated copies will 
get inside the baseband and appear with reduced frequencies. Specifically, 
a component with frequency f > 1/2Δx appears in the reconstructed signal 
with frequency (1/Δx − f). Figure 3.16 illustrates this phenomenon, called the 
strobe effect, for 1D signals.
Initial signal spectrum
(a)
f0 = 0.2
f0 = 0.4
f0 = 0.6
f0 = 0.8
–2
–1 –0.5
0
0.5
1
2
f
f
–2
–1 –0.5
0
0.5
1
2
f
–2
–1 –0.5
0
0.5
1
2
f
–2
–1 –0.5
0
0.5
1
2
Sampled signal spectrum
Base band
f = 0.2
f = 0.4
f = 0.6
f = 0.8
(b)
FIGURE 3.16
Strobe effects in sampling periodical signals: (a) from top to bottom, spectra of a sinusoidal 
signals with frequencies 0.2, 0.4, 0.6, and 0.8 (in fraction of the baseband); (b) corresponding 
reconstructed signals.

95
Image Digitization
One can see from the figure that while signals with frequencies 0.2 and 
0.4 fit the baseband and are not affected by sampling, signals with frequen-
cies 0.6 and 0.8 that exceed the baseband border frequency 0.5 are recon-
structed as having reduced frequencies, correspondingly, 1 – 0.6 = 0.4 and 
1 – 0.8 = 0.2. Strobe effects for 2D periodical signals of different frequen-
cies are illustrated in Figure 3.17 generated using MATLAB demo program 
fringe_aliasing_demo_CRC.m provided in Exercises. In video, strobe effects 
are observed on moving objects, and in particular, on rotating objects, such 
as rotating wheels or propellers. On these objects, they cause reducing vis-
ible rotation speed up to even its inversion.
While strobe effects appear due to inappropriate prefiltering prior sam-
pling, signal-inappropriate postfiltering at the reconstruction stage results in 
the appearance of signal ghost high-frequency components from spectrum 
replicas not removed by the reconstruction postfilter. For periodical signals, 
these ghost high-frequency components cause low-frequency “beatings” with 
original high-frequency components as illustrated in Figure 3.18. As beatings 
form moiré patterns, these aliasing effects are called moiré effects. Figure 3.19 
illustrates aliasing artifacts in real-life images that contain periodical patterns.
Appropriate pre- and postfiltering may have a profound positive effect on 
performing image analysis tasks. Figure 3.20, generated using MATLAB pro-
gram IdealVsNonidealSampling_CRC.m provided in Exercises, illustrates 
this on an example of their influence on readability of a printed text.
A remarkable demonstration that appropriate postfiltering can even 
change the visual content of images is given through a painting by Salvador 
FIGURE 3.17
Strobe effect in sampling a 2D periodical signal cos[2πκ(x2 + y2)] ((x, y) are vertical and hori-
zontal coordinates centered in the centers of images): (a) signal with local frequencies that do 
no exceed the sampling rate; (b) signal with a larger value of the parameter κ which results in 
higher local frequencies that exceed the sampling rate.

96
Theoretical Foundations of Digital Imaging Using MATLAB®
Dali “Gala Contemplating the Mediterranean Sea which at Twenty Meters 
becomes a Portrait of Abraham Lincoln” shown in Figure 3.21: pixilated 
image around figure of Gala converts to the portrait of A. Lincoln when 
painting is viewed with low resolution from a distant position, which cor-
responds to low-pass filtering.
Alternative Methods of Discretization in Imaging Devices
In many digital imaging devices, discretization basis functions and restora-
tion basis functions belong to different families of functions. While restora-
tion basis functions implemented in commonly used display and printing 
1
(a)
(b)
f0 = 0.4
0.8
0.6
0.4
0.2
0
–2
–1
–0.5
0
0.5
Initial signal
Sampled signal
Postfilter band
1
2
f
Initial signal
Reconstructed signal
FIGURE 3.18
Moire effects in sampling sinusoidal signals. For sinusoidal signal with frequency 0.4 (in frac-
tion of the signal base band) shown in the upper plot in (b), postfiltering in the band that exceeds 
the base band ([−0.5, 0.5]) does not suppress in the spectrum of sampled signal (a) the replica 
with frequency 0.6, which results in the appearance in the reconstructed signal (bottom plot in 
(b)) of beating between two signals, the original and the ghost.

97
Image Digitization
devices are always shift (convolution) ones, in many modern imaging meth-
ods, discretization basis functions are other than shift ones. Most immediate 
examples are coded aperture imaging, holographic imaging, computed tomography, 
and magnetic resonance imaging (MRI), to name a few. Discrete data collected 
in the discretization process in such devices should be transformed into 
image samples for image display or printing. This process, which is usually 
carried out in computers, is called image reconstruction.
Coded aperture imaging methods were suggested for nonoptical imaging 
such as x-ray, gamma-ray, and other nuclear radiation imaging when no opti-
cal focusing devices are available. They are an alternative to pinhole cameras 
that also build images directly without any need of focusing the radiation. 
FIGURE 3.19
Sampling artifacts in an image that contains periodical patterns: (a) initial image; (b) image 
reconstructed after sampling and reconstruction with an ideal low-pass filter as pre- and post-
filters; (c) image reconstructed after sampling without any pre- and postfiltering with rect-
function as filter PSF; (d) image reconstructed after sampling with pre- and postfiltering using 
filter with rect-function as filter PSF. In all cases, sampling interval is 1/70 of the image height.

98
Theoretical Foundations of Digital Imaging Using MATLAB®
In coded aperture methods, radiation from objects to be imaged is sensed 
through binary (transparent/opaque) masks (“coded apertures”) such as, for 
instance, 2D Walsh function masks shown in Figure 3.22, or by means of 
correspondingly wired arrays of parallel sensors. In our terminology, these 
masks implement discretization basis functions. In such binary masks, half 
of their area is transparent, therefore radiation energy is collected over half 
of the image area. Thus, they provide better ratio of signal-to-quantum noise 
at sensor’s output than pinhole cameras, which collect radiation energy only 
within the area of the pinhole. The gain amounts to the order of N , where 
N is the number of pixels in reconstructed images.
FIGURE 3.20
Influence of sampling artifacts on image readability: (a) initial image; (b) image reconstructed 
after sampling and reconstruction with an ideal low-pass filter as pre- and postfilters; (c) image 
reconstructed after sampling without any pre- and postfiltering with rect-function as filter PSF; 
(d) image reconstructed after sampling with pre- and postfiltering using filter with rect-func-
tion as filter PSF. In all cases, sampling interval is about 1/4 of the lower-case characters’ height.

99
Image Digitization
FIGURE 3.21
A close-up view of the painting by Salvador Dali “Gala Contemplating the Mediterranean Sea 
which at Twenty Meters becomes a Portrait of Abraham Lincoln” (a) and same painting as seen 
with low resolution from a distant point (b), which is equivalent to low-pass filtering.
FIGURE 3.22
8 × 8 array of 2D Walsh basis function for N = 8.

100
Theoretical Foundations of Digital Imaging Using MATLAB®
In numerical reconstruction of holograms, sampled are holograms, that is, 
integral Fourier, Fresnel, or Kirchhoff transforms of objects under study. 
Sampling is performed by photographic cameras in special optical set-
ups, and the results of sampling are used for image reconstruction in the 
computer. We will detail this process in the Section “Computer-Generated 
Display Holography” in Chapter 5.
In computed tomography, slices of bodies are imaged, and 2D discretization is 
separable in a polar coordinate system: linear array of sensors rotates around 
the body to be imaged and, for a discrete set of observation angles, samples 
of projections of body slices, that is, of their Radon transforms described in 
the section “Imaging from Projections and Radon Transform” in Chapter 2 
are collected. The obtained discrete data are then used for the reconstruc-
tion of slice images in computers. In the section “Digital Image Formation 
by Means of Numerical Reconstruction of Holograms” in Chapter 5, we will 
overview corresponding basic algorithms.
In MRI or NMR (nuclear magnetic resonance) imaging, objects to be imaged 
are placed in a strong and spatially nonhomogeneous magnetic field. When 
an electromagnetic excitation signal on a radiofrequency is applied to the 
object, the object reemits the signal but modulates its amplitude and fre-
quency. The intensity of the radiofrequency signal reemitted by different 
elements of the body volume is proportional to the density of protons in 
these volume elements and its frequency is determined by the strength of 
the magnetic field in their coordinates. Because the magnetic field is spatially 
nonhomogeneous, the frequency of the reemitted signal carries information 
about the spatial coordinates of the elements. Therefore, for collecting data 
about distribution of proton density within the body, the reemitted signal is 
sampled in its Fourier domain and, therefore, the discretization bases func-
tions are sinusoidal ones.
Signal Scalar Quantization
Optimal Quantization: Principles
Scalar (element-wise) quantization is the second stage of signal digitiza-
tion. It is applied to coefficients of signal discrete representation obtained 
as the result of signal discretization. Scalar quantization implies that a 
finite interval first has to be specified in the entire range of the signal rep-
resentation coefficient values α by defining their minimum αmin and maxi-
mum αmax and then interval [αmin, αmax] is split into a certain number Q – 2 
of quantization intervals by defining their border values {α(q)}, q = 0, 1, . . ., 
Q − 2, Q being the total number of quantization levels. Quantization intervals 
are indexed by an integer index and for each particular q-th interval, its rep-
resentative value, or quantization level ℵ( )
q , is chosen. In signal reconstruction, 

101
Image Digitization
all values within a particular quantization interval are replaced with its rep-
resentative quantization level. Figure 3.23 illustrates these concepts.
Difference ε
α
( )
( )
q
q
=
−ℵ between true value α and its corresponding quan-
tization level ℵ( )
q  is called quantization error. One should distinguish quanti-
zation errors within the selected dynamic range
	
ε
α
α
α
α
( )
( )
(
)
( )
;
,
,
q
q
q
q
q
Q
=
−ℵ
∈

≤
≤
−
−1
1
2 	
(3.106)
from those outside the boundaries of the dynamic range:
	
ε
α
α
α
(min)
( )
min
;
;
=
−ℵ
<
0
	
(3.107)
	
ε
α
α
α
(max)
(
)
max
;
.
=
−ℵ
>
−
Q 1
	
(3.108)
Quantization errors within the dynamic range are limited in the range 
by the size of the quantization intervals, whereas dynamic range limitation 
errors may, in principle, be unlimited in value.
The arrangement of quantization intervals and selection of quantization lev-
els is governed by requirements to the accuracy of signal-quantized represen-
tation, which are generally formulated in terms of certain constraints imposed 
on the quantization errors. With the most common approach to formulating 
the constraints, losses due to quantization errors are evaluated over all pos-
sible coefficient values on average according to their probability density. To 
this goal, loss functions Dlr(ε(q)), Dl(ε(min)), Dr(ε(max)) are introduced that measure 
losses owing to the quantization errors within and outside the dynamic range 
quantization and precision of signal reconstruction is evaluated, separately for 
quantization errors within and outside the dynamic range, as
	
D
p
D
l
l
=
−∞∫
( )
(
)
,
(min)
min
α
ε
α
α
d
	
(3.109)
Probability density
Quantization levels
Borders of quantization intervals
αmin = α(0)
αmax = α(Q–2)
ℵ(Q–1)
ℵ(q)
ℵ(0)
α(q–1)
α(q)
FIGURE 3.23
Signal values probability density and arrangement of signal quantization intervals and quan-
tization levels.

102
Theoretical Foundations of Digital Imaging Using MATLAB®
	
D
p
D
r
r
=
∞
∫
( )
(
)
,
(max)
max
α
ε
α
α
d
	
(3.110)
and
	
D
p
D
lr
lr
q
q
Q
Q
q
q
=
=
=
−∫
∑
=
−
−
( )
(
)
;
;
( )
( )
min
(
)
ma
(
)
( )
α
ε
α
α
α
α
α
α
α
d
1
1
2
0
2
x,
	
(3.111)
where p(α) is the probability density of the values under quantization.
Equations 3.109 and 3.110 can be used for determining dynamic range 
boundaries {αmin, αmax} and their corresponding quantization levels given the 
constraints to dynamic range limitation error measures Dl and Dr. Equation 
3.111 can be used for determining sets of quantization intervals boundaries 
{α(q)} and quantization levels {
}
( )
ℵq  that minimize the number of quantization 
levels Q given the average quantization error measure Dlr, or minimize the 
average quantization error measure given the number of quantization levels. 
We call quantizers designed in this way optimal scalar quantizers.
Design of Optimal Quantizers
There are two approaches to the design of optimal quantizers, a direct opti-
mization approach and a compressor–expander (compander) approach. Direct 
optimization approach assumes solving the optimization equation
	
α
α
α
α
α
α
opt
q
opt
q
lr
q
q
q
q
p
D
( )
( )
,
( )
,
argmin
( )
( )
( )
(
)
ℵ
{
} =
−ℵ
(
)
ℵ
{
}
−
d
1
α( )
.
q
q
Q
∫
∑
=
−






1
2
	
(3.112)
The optimization is simplified if loss function Dlr (ε(q)) is an even function: 
Dlr(ε) = Dlr(−ε). In this case, from
	
∂
∂
−ℵ
(
)






=
( )
( )
=
−
−
(
)
( )
∫
∑
α
α
α
α
α
α
α
q
lr
q
q
Q
q
p
D
p
q
q
( )
(
( )
d
1
1
2
)
( )
( )
( )
( )
(
)
D
p
D
lr
q
q
q
lr
q
q
α
α
α
−ℵ
(
)
−
(
)
−ℵ
(
) =
−1
0
	
(3.113)
it follows that optimal boundaries of the quantization intervals should be 
placed halfway between the corresponding quantized values:
	
αopt
q
opt
q
opt
q
( )
(
)
( )
.
= ℵ
+ ℵ
(
)
−1
2
/
	
(3.114)

103
Image Digitization
For the quadratic loss function Dlr
q
q
(
)
(
)
( )
( )
ε
ε
=
2, a further simplification of 
the optimization search is possible. From
	
∂
∂ℵ
−ℵ
(
)






=
∂
∂
−∫
∑
=
−
( )
( )
( )
( )
(
)
( )
q
lr
q
q
Q
p
D
p
q
q
α
α
α
α
α
α
d
1
1
2
ℵ
−ℵ
(
)
= −
−ℵ
=
−
−
∫
∫
( )
( )
( )
(
)
( )
(
)
( )
( )(
)
q
q
q
q
q
q
q
p
α
α
α α
α
α
α
α
α
2
1
1
2
0
d
d
	
(3.115)
it follows that in this case optimal quantization levels are centers of mass of 
the probability density within the quantization intervals:
	
ℵ
=
−
−
∫
∫
opt
q
p
p
q
q
q
q
( )
( )
( )
.
(
)
( )
(
)
( )
α
α
α
α
α
α
α
α
α
d
d
1
1
	
(3.116)
Such a solution of the quantization optimization problem for the quadratic 
loss function is called Max–Lloyd quantization.
Compressor–expander quantization is a method suited for hardware imple-
mentation of nonuniform optimal quantization using nonlinear analog signal 
amplifiers and readily available uniform quantizers in which signal dynamic 
range is split into quantization intervals of equal size, and centers of the inter-
vals are used as quantization levels. In order to implement a nonuniform 
quantization with uniform quantizers, signal, before being sent to the uniform 
quantizer, has to be subjected to an appropriate nonlinear point-wise transfor-
mation. Correspondingly, at the signal reconstruction stage, uniformly quan-
tized values have to be subjected to a nonlinear transformation inverse to the 
one used for quantization. Usually, the required nonlinear prequantization 
transformation compresses the signal dynamic range, thus the name “com-
pressor–expander quantization.” Flow diagram of the compressor–expander 
quantization and reconstruction is presented in Figure 3.24.
Optimization of the compressor–expander quantization is achieved by an 
appropriate selection of the compressive nonlinear point-wise transforma-
tion. The optimal transformation transfer function can be found in the fol-
lowing way. Let w(.) be a compression transfer function and Δ(u) be a uniform 
quantization interval. Then, for a particular value α to be quantized, quan-
tization interval Δ(q) that corresponds to uniform quantization of values of 
function w(α) with quantization interval Δ(u) will be equal to
	
∆
∆
( )
(
)
( )
( )
,
.
( )
(
)
q
u
a
a
q
q
w
q
q
=
≤
≤
=
−
−
−
d
/d
α
α
α
α
α
α
1
2
1
	
(3.117)

104
Theoretical Foundations of Digital Imaging Using MATLAB®
This interval determines the quantization error for the Δu-th quantization 
interval. In order to enable analytical solution for optimal selection of w(.), 
modify slightly the quantization error measure incorporated in the optimi-
zation Equation 3.112: introduce a virtual quantization interval
	
∆
∆
∆
α
α
α
α
=
=
≤
≤
u
u
w
w
d
/d
( )
( ) ,
,
(min)
(max)
α
α
α

	
(3.118)
a modified quantization loss function Dlr(
)
∆α  as measure of losses due to 
quantization error in the range of Δα and replace integration of quantization 
loss function over individual quantization intervals and summation over all 
intervals in Equation 3.112 by integration of the modified loss function Dlr(
)
∆α  
over the range of quantized values. With these modifications, the optimiza-
tion Equation 3.112 for optimal transfer function w(α) can be rewritten as
	
w
p
D
w
opt
w
lr
u
( )
argmin
( )
( )
( )
min
max
α
α
α
α
α
α
=









∫


∆
d
α

.
	
(3.119)
This equation can be solved using the Euler–Lagrange equation, which in 
this case takes the form
	
∂
∂










=



w
p
D
w
lr
u
( )
( )
( )
.
α
α
α
∆
const
	
(3.120)
Consider some special cases. We will begin with threshold quantization 
loss functions that assume that quantization error is nil if it does not exceed a 
Input 
Quantization
Restoration
Compressing transformation
Uniform quantizer
Expanding transformation
Restored
signal
Uniformly
quantized values 
Uniformly quantized values
w(α)
w–1(.)
αmin
αmin
αmax
αmax
Δ(q) = Δu/w(α)
Δu
FIGURE 3.24
Schematic diagram of the compressor/expander quantization and restoration.

105
Image Digitization
certain threshold. For threshold loss functions, optimal arrangement of quantiza-
tion intervals does not depend on the probability distribution p(α) because zero 
average losses can be secured if quantization errors are kept under the thresh-
old level. The following two examples represent a particular practical interest.
Example 3.1: Uniform Threshold Criterion for Absolute 
Value of Quantization Error
	
Dlr
thr
(
)
,
,
.
∆
∆
∆
α
α
=
≤



0
1
otherwise 	
(3.121)
From Equations 3.117 and 3.121, it follows that, for monotonic functions 
w(α). Dlr = 0 if
	
w
u
thr
( )
,
α = ∆
∆
/
	
(3.122)
and, therefore, wopt(α) is a linear function
	
w
w
w
w
opt
opt
opt
opt
( )
(
)
(
)
(
)
.
min
max
min
min
max
min
α
α
α
α
α
α
α
α
−
−
=
−
−
	
(3.123)
Therefore, in this case, optimal quantization is the standard uniform 
quantization with quantization interval and the number of quantization 
levels equal to, respectively
	
∆
∆
∆
u
opt
opt
trh
thr
w
w
Q
=
−
−
=
−
(
)
(
)
,
.
max
min
max
min
max
min
α
α
α
α
α
α
	
(3.124)
Example 3.2: Uniform Threshold Criterion of Relative Quantization Error
	
Ddr
thr
thr
(
)
,
,
.
∆
∆
∆
α
α
δ
α
=
≤
=



0
1
otherwise
	
(3.125)
In this case, Dlr = 0 if
	
w
u
thr
( )
,
α
δ
α
= ∆/
	
(3.126)
and, therefore, uniform quantization in a logarithmic scale is optimal:
	
w
w
w
w
opt
opt
opt
opt
( )
(
)
(
)
(
)
ln(
)
ln(
min
max
min
min
max
α
α
α
α
α α
α
−
−
=
/
/αmin)	
(3.127)

106
Theoretical Foundations of Digital Imaging Using MATLAB®
with the number of quantization levels defined as
	
Q
w
w
w
w
w
opt
opt
u
opt
opt
opt
t
=
−
=
−
(
)
(
)
(
)
(
)
( )
max
min
max
min
α
α
α
α
α
α δ
∆

hr
opt
opt
opt
opt
w
w
w
w
=
−
−


(
)
(
)
(
)
(
)
ln(
max
min
max
min
ma
α
α
α
α
α
α
α
x
min
max
min
)
ln(
).
/
/
α
δ
α
α
δ
{
}
=
thr
thr
	
(3.128)
This particular case is of a special interest in image processing. In 
images, artifacts of quantization of image pixel gray levels most fre-
quently exhibit themselves in appearance of what is called “false con-
tours,” visible boundaries between image patches quantized to different 
quantization levels. This phenomenon is illustrated in Figure 3.25.
A natural primary requirement for quantization of image gray levels is to 
secure invisibility of false contours in displayed digital images. The thresh-
old of visibility of patches of constant gray level depends on their contrast 
with respect to their background and of size of patches. Quantitative esti-
mates can be made using the Weber–Fechner’s law: the ratio of brightness 
contrast Δlthr of a stimulus on the threshold of its visibility to background of 
brightness I is constant for a wide range of the brightness:
	
∆I
I
thr
thr
=
=
δ
const.
	
(3.129)
FIGURE 3.25
False contours in image quantization: initial test image (left) and same image quantized uni-
formly to 16 quantization levels (right), in which false patches and their borders become visible.

107
Image Digitization
This law is illustrated in Figure 3.26, which shows the dependence of 
the visibility threshold of stimulus relative contrast on the brightness of 
stimulus background (in a logarithmic scale).
The value of the threshold contrast δthr depends on the stimulus size. 
Its lowest value of 1–3% shown in the figure corresponds to stimuli of 
sufficiently large angular size (of the order of 10 or more angular reso-
lution elements). From the above example and Weber–Fechner’s law, it 
follows that optimal, for digital image display, quantization of image 
samples should be uniform in the logarithmic scale. The number Q of 
required quantization levels for logarithmic quantization can be found 
from Equation 3.121. For good-quality photographic, TV, and computer 
displays, dynamic range αmax/αmin of displayed image brightness is 
about 100. Using this estimation of the dynamic range and taking visual 
sensitivity threshold equal to 2%, obtain from Equation 3.121 that the 
required number of quantization levels Q for which false contours are 
under visibility threshold is of the order of ln 100/0.02 = 2 · 2.43/0.02 = 243. 
Remarkably, similar figures are characteristic also for human audio sen-
sibility. This was the main reason why 256 quantization levels (8 bits) 
were chosen as a standard for gray-scale image, sound, and other analog 
signal representation and why 8 bits (byte) had become a basic unit in 
the computer industry.
Consider now examples of “soft” (nonthreshold) criteria.
Example 3.3: Exponential Criterion of Absolute Quantization Error
	


D
w
lr
G
u
G
(
)
( )
.
∆
∆
∆
α
α
α
=
=
2
2
	
(3.130)
Substituting Equation 3.130 into Equation 3.120 and solving the result-
ing differential equation, obtain in this case
Test object
Background I
Stimulus
relative
contrast
Brightness of the background
Stimulus I + ΔI
ΔI
I
log I
1–3%
FIGURE 3.26
The Weber–Fechner law on the threshold visibility of a stimulus on a uniform background.

108
Theoretical Foundations of Digital Imaging Using MATLAB®
	
w
w
w
w
p
opt
opt
opt
opt
G
( )
(
)
(
)
(
)
( )
min
max
min
/(
)
α
α
α
α
α
α
−
−
=


+
1
2
1 d
α
α
α
α
α
α
α
α
α
α
α
min
/(
)
min
max
min
( )
( )
( )
∫
∫
∫


=



+
p
p
p
G
P
1
2
1 d
d

∫
P dα
α
α
min
max
,
	
(3.131)
where P = 1/(2G + 1). Thus, the required nonlinear prequantization 
transformation depends solely on the probability distribution of the 
quantized values. The meaning of this relationship becomes evident 
from the expression
	
∆
∆
α
α
α
=
∝

−
u
P
w
p
/  ( )
( )
, 	
(3.132)
which implies that the width of quantization intervals for the various 
values of α is inversely proportional to their probability densities raised 
to the corresponding power. For the widely used mean squared quanti-
zation error criterion (G = 1, P = 1/3)
	
w
w
w
w
p
p
( )
(
)
(
)
(
)
( )
( )
min
max
min
/
min
/
α
α
α
α
α
α
α
α
α
−
−
=




∫
1 3
1 3
d
dα
α
α
min
max
.
∫
	
(3.133)
Image modification using transfer function defined by Equation 
3.131 turned out to be very useful for image enhancement. We will dis-
cuss this issue in detail in the section “Filter Classification Tables and 
Particular Examples” in Chapter 8. We call it p-histogram equalization. Its 
special case, when G = 0; P = 1, that is
	
w
w
w
w
p
p
( )
(
)
(
)
(
)
( )
( )
min
max
min
min
min
max
α
α
α
α
α
α
α
α
α
α
α
α
−
−
= ∫
∫
d
d
	
(3.134)
is commonly called histogram equalization because it converts signal prob-
ability density, or, for quantized signals, signal histogram into a uniform 
one. Histogram equalization is a popular image enhancement trans-
formation. For image quantization, this transformation assumes that 
quantization errors are equally important whatever their values are (see 
Equation 3.130) and make quantization intervals inversely proportional 
to the probability density for the level to be quantized (see Equation 3.132).

109
Image Digitization
Sometimes, as in the case of quantizing spectral coefficients of sig-
nals in Fourier, Walsh, and other bases, probability density of quantized 
coefficients of the discrete signal representation is a truncated Gaussian 
probability density distribution:
	
p( )
exp
,
.
min
max
α
α
α
σ
α
α
α
α
∝
−
−
(
)




≤
≤
2
2
2
/
	
(3.135)
Then, for mean square error criterion (G = 1), one can get from Equation 
3.120 that (see Appendix)
	
w
w
w
w
erf
erf
erf
( )
(
)
(
)
(
)
min
max
min
min
max
α
α
α
α
α
σ
α
σ
α
α
α
−
−
=
(
) +
(
)
6
6
6σ
α
σ
α
α
(
) +
(
)
erf
min
,
6
	
(3.136)
where
	
erf x
x
( )
exp(
)
=
−
∫
2
2
0
π
ξ
ξ
d
	
(3.137)
is the error function. This compression function is shown in Figure 3.27 
along with the probability density function.
1
0.9
p(α)
w(α)
α
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0–5
–4
–3
–2
–1
0
1
2
3
4
5
FIGURE 3.27
Optimal compression function as given by Equation 3.136 for quantization variables with nor-
mal probability density.

110
Theoretical Foundations of Digital Imaging Using MATLAB®
Example 3.4: Exponential Criterion of Relative Quantization Error
	


D
w
lr
G
u
G
(
)
( )
.
∆
∆
∆
α
α α
α α
=
= (
)
/
2
2
	
(3.138)
In this case, solution of the Euler–Lagrange equation (3.120) yields
	
w
w
w
w
p
opt
opt
opt
opt
G
G
( )
(
)
(
)
(
)
( )
min
max
min
/(
α
α
α
α
α
α
−
−
=


+
/
2
1
2
1
2
1
2
1
)
min
/(
)
min
max
( )
.
d
/
d
α
α
α
α
α
α
α
α∫
∫

+
p
G
G
	
(3.139)
If quantized values α are distributed uniformly in the dynamic range 
[αmin, αmax], the optimal compression function is
	
w
w
w
w
G
G
( )
(
)
(
)
(
)
min
max
min
/(
)
min
/(
)
max
/(
α
α
α
α
α
α
α
−
−
=
−
+
+
1
2
1
1
2
1
1
2G
G
+
+
−
1
1
2
1
)
min
/(
) .
α
	
(3.140)
We will refer to such type of nonlinear transformations as to “P-th law 
quantization”:
	
w
w
w
w
P
P
P
P
( )
(
)
(
)
(
)
,
min
max
min
min
max
min
α
α
α
α
α
α
α
α
−
−
=
−
−
	
(3.141)
where the exponent P is a transformation parameter. For the mean 
square relative quantization error criterion (Equation 3.130), G = 1, the 
optimal is P = 1/3:
	
w
w
w
w
opt
opt
opt
opt
( )
(
)
(
)
(
)
min
max
min
/
min
/
max
/
α
α
α
α
α
α
α
−
−
=
−
1 3
1 3
1 3
1 3
−αmin
/ .
	
(3.142)
The P-th law compression transformation, thanks to its simple param-
eterization through a single parameter P, proved to be a useful approxi-
mation to optimal compression transformation for quantizing variables 
with normal probability distribution, in particular, for quantizing of 
absolute values of DFT and DCT coefficients of images in transform 
image coding. (We will introduce discrete Fourier and discrete cosine 
transforms in Chapter 4.) Optimal values of the nonlinearity index P, 
for which standard deviation of errors in reconstructed images because 
of quantization of their spectra is minimal, are usually about 0.2–0.3. 
For instance, Figure 3.28 presents an example of a test image and results 
of optimization of P-th law quantization of absolute values of its DCT 
spectral coefficients.

111
Image Digitization
Quantization in Digital Holography
Numerical reconstruction of electronically recorded hologram and ­computer- 
generated holograms, topics united under the name digital holography, will 
be addressed later in Chapter 5. Here, we will discuss some peculiarities of 
signal quantization in digital holography. First of all, as we will see in the 
sections “Digital Image Formation by Means of Numerical Reconstruction 
of Holograms” and “Computer-Generated Display Holography” in Chapter 
5, this is quantization in Fourier or Fresnel transform domains. Therefore, 
in the quantization of holograms, a nonuniform, as, for instance, P-th 
law quantization, is advisable. For numerical reconstruction of images 
from holograms (see the section “Digital Image Formation by Means of 
Test image
Reconstructed image; P = 1
Reconstructed image; P = 0.2
P-th law quantization error stdev; Q = 65
(a)
(c)
(b)
(d)
7
6
5
4
Standard deviation of quantization error
3
2
1
0
0.2
0.4
0.6
Nonlinearity index P
0.8
1
FIGURE 3.28
Optimization of P-th law quantization of image DCT spectrum. (a) Initial test image; (b) and 
(c) images reconstructed from uniformly (P = 1) and P-th (P = 0.2) law quantized spectral coef-
ficients; (d) plot of standard deviation of quantization error as a function on the nonlinearity 
index P for 65 quantization levels, which shows that standard deviation of quantization error 
is minimal for P = 0.2. Note that uniform quantization (P = 1) substantially destroys the image.

112
Theoretical Foundations of Digital Imaging Using MATLAB®
Numerical Reconstruction of Holograms” in Chapter 5), corresponding cor-
recting expanding transformations should be implemented in hologram 
preprocessing. For recording computer-generated holograms (see the sec-
tion “Computer-Generated Display Holography” in Chapter 5), correcting 
expanding transformation should be implemented in hologram encoding for 
recording on an optical medium.
In the synthesis of computer-generated display holograms, yet another 
quantization method, the pseudorandom diffuser method, can be employed. The 
method is aimed at compressing a dynamic range of holograms and makes 
use of the fact that, for display holograms, reproduction of amplitude is only 
required in object wavefront, reconstructed from holograms, because human 
vision senses only the intensity of radiation. For synthesis of the display holo-
gram of an object, object wavefront amplitude and phase should be specified. 
However, the phase component is irrelevant for visualization. Therefore, it can 
be selected so as to minimize hologram quantization artifacts. The pseudoran-
dom diffuser method consists of using, for specifying object wavefront phase 
component, appropriately generated pseudorandom numbers. Note that this 
imitates, in a certain sense, properties of real object to diffusely scatter light.
The method is mathematically described as follows. Let Ak l,
2
{
} be samples, 
with (k, l) as sample indices, of the given object wavefront intensity and {θk,j} 
be an array of pseudorandom numbers taken from the range [0, 2π]. Then 
samples of the object wavefront Ak l,  are defined as:
	
A
A
i
k l
k l
k l
,
,
,
exp(
),
=
θ
	
(3.143)
which preserves wavefront amplitude and assigns to its samples a pseudo-
random phase.
The simplest solution is to use for {θk,j} binary statistically independent 
numbers that assume, with equal probabilities, values 0 and π. Such a pseu-
dorandom phase modulation of the object wavefront redistributes wavefront 
Fourier and Fresnel spectrum energy uniformly (statistically) between all 
spectral coefficients so that all coefficients have the same dynamic range. 
Figure 3.29 illustrates this phenomenon of spectrum “uniformization” by 
means of image pseudorandom phase modulation. Image pseudorandom 
phase modulation eliminates the need of nonuniform quantization and sim-
plifies the hologram encoding for recording on optical media.
In optical reconstruction of images from computer-generated holograms, 
image distortions may appear due to quantization for hologram in hologram 
recording devices. In order to minimize the image reconstruction error, one 
can optimize the pseudorandom object wavefront phase through an iterative 
optimization procedure of assignment of the phase. In this process, at each iter-
ation step, a quantization that would be implemented in hologram encoding in 
applied to the hologram synthesized from the object and iterated object wave-
front is reconstructed. Then the amplitude component of the reconstructed 

113
Image Digitization
wavefront is replaced by the given object wavefront amplitude, while the phase 
component is kept unchanged. The obtained wavefront with this iterated phase 
component is used for the next iteration. Optimization of the pseudorandom 
diffuser is especially required for recording kinoforms, computer-generated holo-
grams, in which hologram amplitude variations are ignored and are replaced by 
a constant (see Section “Recording Computer-Generated Holograms on Optical 
Media” in Chapter 5). Figure 3.30 illustrates that the iterative optimization of 
pseudorandom phase distribution allows achieving quite good image in image 
reconstruction from kinoform in spite of ignoring, in hologram recording, its 
amplitude. In Exercises, a MATLAB program quantization_demo_CRC.m is 
provided that illustrates issues discussed in this section.
Basics of Image Data Compression
What Is Image Data Compression and Why Do We Need It?
As it was mentioned, image representation in the form of arrays of samples 
taken in nodes of uniform sampling grids is standard for image displays. 
This means that any imaging system and image processing should ulti-
mately produce sampled images for displaying.
For sampling, one has to select the sampling interval. For band-limited 
signals, sampling interval is determined according to the sampling theorem, 
by signal bandwidth. However, in reality, there are no band-limited signals 
and sampling interval should be selected on the basis of evaluation of vul-
nerability of images to sampling artifacts: image blurring due to low-pass 
prefiltering, strobe, moiré, and other aliasing effects. A good practical rule is 
to decide how many pixels should be allocated for representing most sharp 
FIGURE 3.29
​Image Fourier spectrum “uniformization” by means of pseudorandom phase modulation: 
(a) test image; (b) Fourier power spectrum of the test image; (c) spectrum of the test image, to 
which a pseudorandom binary (0 and π) phase component is assigned. Note that, for the display 
purposes, spectrum (b) is displayed using P-th law transformation (P = 0.5), otherwise high-
frequency spectral components would be invisible in print.

114
Theoretical Foundations of Digital Imaging Using MATLAB®
image details such as objects’ boundaries, or edges. But such details usually 
occupy a relatively small fraction of image area. Therefore, sampled repre-
sentation of images is as a rule very redundant in terms of the volume of 
data needed to produce images because most pixels belong to not edgy areas 
where image signal is changing much slower and sampling rate selected for 
edges is, for those areas, excessive. This redundancy amounts to tens and, for 
some images, even hundreds of times. The same refers to video data repre-
sented as sets of video frames that are also highly redundant. In addition to 
this, scalar quantization of pixels requires excessive number of quantization 
levels in order to secure invisibility of quantization artifacts, such as false 
contours, to which most vulnerable are those excessive image samples from 
nonedgy image areas.
All this means that for image data storage and transmission, sampled image 
representation can be substantially compressed. The compression is usually a 
supplemental image processing applied to the “primary” sampled image rep-
resentation. Image compression, or image coding, as well as video compression are 
well-established fields covered in many books. In this chapter, we will review 
only their basic principles beginning with basic facts from information theory.
0.25
(a)
(b)
0.2
0.15
0.1
0.05
0
5
15
63
Number of kinoform phase quantization levels Q
255
FIGURE 3.30
Pseudorandom diffuser optimization for computer generated kinoform of the object given in 
Figure 3.29a: (a) reconstructed images for (from left to right) 5, 15, 63, and 255 quantization lev-
els of the hologram phase and (b) corresponding standard deviations of image reconstruction 
normalized error.

115
Image Digitization
Signal Rate Distortion Function, Entropy, and Statistical Encoding
The purpose of the signal coding and data compression is encoding signals 
from a signal ensemble into a stream of binary digits, or bits (binary code) 
of the least possible length as evaluated on average over the signal ensem-
ble. A fundamental result provided by information theory [7] is that there 
is a lower bound for the length of binary code required to specify signals 
from a signal ensemble. This bound is given by the rate distortion function 
Hε of the signal ensemble. In terms of signal space and general digitization 
discussed in the section “Linear Signal Space, Basis Functions and Signal 
Representation as Expansion over a Set of Basis Functions” in Chapter 2, rate 
distortion function is defined as minimal entropy of the set of representative 
signals ˆΩA selected to represent signals from the signal ensemble ΩA with a 
given accuracy:
	
H
P A
P A
A
k
k
A
A
A
ε(
)
min
(
)log (
)
,
Ω
Ω
=
−






⇒Ω
Ω∑




	
(3.144)
where ˆAk  is a representative signal for the k-th equivalency cell of the signal 
space, P Ak
(
)

 is the probability of the subset of signals that belong to this cell 
and minimum is sought over all possible mappings of the signal ensemble 
ΩA onto the set ˆΩA of representative signals provided a given accuracy of the 
representation. This lower bound can, in principle, be achieved through the 
general digitization process.
The upper bound of the number of bits per representative signal is deter-
mined by the amount NΩ of the representative signals: it is equal to log2NΩ, 
which means that the number of bits per a representative signal HA sufficient 
to encode its index lies in the range
	
H
H
N
A
A
ε(
)
log
Ω
Ω
≤
≤
2
	
(3.145)
the upper bound being achieved when representative signals are equally 
probable.
As we mentioned, in reality, signal digitization is performed in two steps 
through discretization and scalar quantization and signals are represented 
by their quantized representation coefficients over discretization basis func-
tions. The entropy of the obtained ensemble of digital signals, which deter-
mines the amount of bits sufficient to specify each of the ensemble signal, 
will be higher than the above lower bound Hε(ΩA) and can be computed as
	
H
p
p
H
A
r
q
r
q
r
A
r
r
A
ε
ε
α
α
ˆ
ˆ
log
ˆ
ˆ
Ω
Ω
Ω
(
) = −
{
}
(
)
{
}
(
) ≥
(
)
∑
∑
2
	
(3.146)

116
Theoretical Foundations of Digital Imaging Using MATLAB®
where r is index of the signal representation coefficients, p
r
qr
({
})
α
 is mutual 
probability of the sets {
}
α r
qr  of quantized values of representation coefficients 
for ensemble ˆΩA of signals reconstructed from their quantized representa-
tion coefficients.
If representation coefficients can be regarded as mutually statistically 
independent
	
p
p
p
r
r
q
r
q
r
N
r
r
ˆ
ˆ
ˆ
,
(
)
(
)
α
α
α
{ }
(
) =
{
}
(
) =
(
)
=
−
∏
0
1
	
(3.147)
where N is the number of representation coefficients, p
r
qr
(
)
(
)
α
 is the probabil-
ity of q-th quantization level of coefficient αr (qr = 0,. . .,Qr − 1), the entropy 
and, therefore, the quantity of bits per signal increase and can be, taking 
into account that {
(
)
}
∑
=
=
−
q
Q
s
q
r
r
r
p
0
1
1
α
, evaluated as
	
H
p
p
A
r
q
r
N
r
q
r
N
r
r
ε
α
α
(
)
....
log
(
)
(
)
Ω
≤−
(
)






(
)
=
−
=
∏



0
1
2
0
−
−
=
−
∏
∑
∑






= −
(
)
−
−
−
1
1
0
1
1
1
0
0
1
q
Q
q
Q
r
q
r
q
N
N
o
N
p
p
α
α


(
)
(
...
)
(
)
log
(
) log
(
)
(
)
= −
−
−−
=
−
=
−
∑
∑
∑
q
Q
r
q
r
N
q
Q
r
q
N
N
r
p
p
1
1
0
0
1
2
0
1
0
1
2
α
α


p
r
q
q
Q
r
N
r
r
(
).
α
=
−
=
−
∑
∑
0
1
0
1
	
(3.148)
Furthermore, if the probability distribution and the number of quantiza-
tion levels of quantized coefficients do not depend on their index r, entropy 
per signal will further increase to entropy Hiid(A) of N identically distributed 
variables
	
H
H
H
N
p
p
A
A
iid
q
q
q
Q
ε
ε
α
α
(
)
(
)
( )
log
.
( )
( )
Ω
Α
≤
Ω
≤
= −
(
)
(
)
=
−
∑



2
0
1
	
(3.149)
The upper limit to the per-signal entropy is given by the entropy H0 = 
N log2Q of uniformly distributed Q level variable:
	
H
H
N
p
p
N
Q
A
A
q
q
q
Q
ε
ε
α
α
(
)
(
)
log
log
.
( )
( )
Ω
≤
Ω
≤−
(
)
(
) ≤
=
−
∑



2
0
1
2
	
(3.150)

117
Image Digitization
In fact, H0 = N log2Q determines the amount of bits per pixel in sampled 
image representation, and it usually very substantially exceeds the lower 
bound. The reason lies in substantial statistical dependence of and nonef-
ficient scalar quantization of pixels. The purpose of image compression is 
to remove this redundancy and to decrease the number of bits per signal to 
make it as much as possible close to its lower bound.
Outline of Image Compression Methods
For more than 60 years since the first works on digital image compression, 
numerous image compression methods have been developed. Figure 3.31 
represents the image compression methods classified into two groups.
The major group of the methods outlined Figure 3.31 by a dashed line con-
sists of methods implemented in three steps:
• Decorrelating image-sampled representation
• Scalar quantization of decorrelated data
• Binary statistical encoding of quantized-decorrelated data
Decorrelating image-sampled representation is a processing that converts 
a set of image or video samples into a set of discrete data that are statistically, 
Coded
compressed
binary stream
Decorrelative linear
transformation 
Predictive
transforms:  
- Recursive (DPCM)
- Multiresolution
(image pyramid
decomposition) 
Orthogonal
transforms 
Framewise:
- DFT 
- DCT
- Walsh
Blockwise: 
- DCT
Scalar quantization:
- Homogeneous
- Zonal
Binary statistical
coding 
- Variable length coding
- Сoding of “rare symbols” 
Combined
decorrelation/quantization: 
- Adaptive sampling
- Vector quantization 
Hybrid
“predictive” and
orthogonal
transforms   
FIGURE 3.31
Classification of digital image compression methods.

118
Theoretical Foundations of Digital Imaging Using MATLAB®
that is, regarded as a statistical ensemble, uncorrelated as much as possible. 
This is achieved by applying to them one or another decorrelating linear 
transformation from two groups of transformation: predictive transforma-
tions and orthogonal transforms.
Predictive transformation computes pixel-wise differences between pixel 
gray level and its predicted estimate found as a weighted sum over pixels 
that surround the given one on the sampling grid. These differences are then 
subjected to scalar quantization. The method in which the prediction and 
computing differences are performed in course of image row-wise/­column-
wise scanning is called differential pulse code modulation (DPCM). In 
DPCM, the difference between the current pixel gray level and the average 
over the nearest to it pixels in its scanning row and in the previous row is 
quantized and then encoded for transmission or storage. It is one of the earli-
est methods of image and signal compression. Nowadays, it is used mostly 
for “interframe” coding of video sequences.
A more efficient decorrelation is achieved when larger and isotro-
pic spatial neighborhood of pixels is involved in the prediction. This is 
implemented in multiresolution image expansion. The multiresolution 
image decomposition methods are outlined in section “Discrete Wavelet 
Transforms and Multiresolution Analysis.” In these methods, decorrelated 
difference signals are obtained, at each resolution (scale) level, by sub-
tracting a low-pass filtered image from its higher-resolution original (see 
Figure 4.16) and then are optimally quantized and statistically encoded. 
Depending on the implementation, this method is known under different 
names: pyramid coding, sub-band decomposition coding, and wavelet coding.
Decorrelation with orthogonal transforms is an alternative to predictive 
decorrelation. Redundancy of the images exhibits itself in this case in concen-
tration of most of image energy in a small number of transform coefficients. 
As it was shown in section “Optimality of Bases: Karhunen-Loeve and Related 
Transforms,” Karhunen–Loeve transform is statistically the best one in terms 
of energy compaction property. However, because of its high computational 
complexity, in practice, other transforms, fast transforms such as DFT, DCT, and 
Walsh transforms that can be computed with so-called fast algorithms are used. 
These discrete transforms are described in details in Chapter 4. Compression 
methods that assume the use of orthogonal transform for image decorrelation 
are united by the name transform image coding. In transform image coding, it is 
the transform coefficients that undergo subsequent scalar quantization.
Two versions of transform coding are known: frame-wise and block-wise 
transform coding. In frame-wise coding, the image frame as a whole is trans-
formed, transform coefficients with very low energy are truncated, and the 
remaining ones are quantized using described methods of optimal scalar 
quantization. In block-wise coding, image is split into nonoverlapping blocks 
of relatively small size and individual blocks are transformed separately. For 
every block, low-energy block transform coefficients are truncated and the 
remaining are optimally quantized.

119
Image Digitization
Applying decorrelative transforms block-wise is well suited to spatial 
image inhomogeneity and transform coefficient quantization can be better 
optimized if it is performed individually for transform spectra of image 
blocks. The size of blocks is determined by the degree of image inhomo-
geneity and, in principle, can vary within an image frame: it should be as 
large as possible provided image remains to be “homogeneous” within the 
block. Block transform coding with variable block size is the most efficient 
implementation of transform image coding. Among block transforms, DCT 
had proved to be the best one and it is put in the base of modern image and 
video compression standards JPEG, H.261, H.262, H.263, and H.320.
Depending on implementation issues, predictive and orthogonal trans-
form can be used in a combination. For instance, in video coding standard 
MPEG, block DCT transform JPEG coding is used for “intraframe” coding 
while predictive transforms are used for DPCM-coding of dc-components of 
blocks, when they are encoded one by one in successive order of image scan-
ning, and also for “interframe” coding as a method for motion compensation.
As it was already mentioned, data obtained after applying to primary 
image-sampled representation of a decorrelating transform are subjected 
to scalar quantization, principles of which were described in the section 
“Signal Scalar Quantization.” The quantization can be homogeneous, that 
is, applied uniformly to all data, or inhomogeneous, that is, different for dif-
ferent groups of data, or, in terms of data indices, different zones of data 
indices. For instance, in block image coding using DCT, indices of spectral 
coefficients of image blocks are split into a number of zones according to 
their spatial frequency, and low-frequency coefficients, which carry most 
of the signal energy, are quantized more precisely than middle-frequency 
coefficients, and the latter are quantized more precisely than high-frequency 
coefficients.
The third step of the three-step compression is statistical (entropy) coding. 
It is applied to the results of quantization and makes use of nonuniformity 
of probabilities of different quantization levels for generating their binary 
codes with the number of bits that are as close as possible to the logarithm 
of the inverse to their probabilities as it is dictated by the information theo-
retical lower bound (Equation 3.149). Two families of the methods of statisti-
cal coding are used: variable-length coding and coding of “rare symbols.” 
The latter are used when one of the symbols to be encoded, such as symbol 
that corresponds to zero-quantized prediction error, has an overwhelmingly 
higher probability than other much more rare symbols. The basics of vari-
able-length coding and coding of “rare symbols” are detailed in Appendix.
The described three-step procedure is called lossy compression to emphasize 
the fact that the original sampled image representation coefficients cannot be 
precisely restored from the compressed binary codes because the procedure 
includes quantization of decorrelated data.
When quantization is avoided, precise image restoration from its binary 
code is possible because decorrelative transforms are reversible. This type 

120
Theoretical Foundations of Digital Imaging Using MATLAB®
of coding is called loss-less coding. Data compression in this case is achieved 
only through statistical (entropy) coding.
An alternative to the three-step procedure represents methods in which 
decorrelation and quantization are not separated from one another. They 
can be considered as attempts to implement general digitization by means of 
splitting signal space into equivalency cells and selection of representative 
signals of the cells. These methods are not as well developed and widely 
used as the methods described above and can be exemplified by adaptive 
sampling and vector quantization methods.
The adaptive sampling method assumes taking samples of images not uni-
formly as in conventional sampling but selectively only in areas of “impor-
tance,” the latter being defined by requirements to the image restoration 
quality. The most known example of adaptive sampling is representing 2D 
surfaces by their “level lines.” Image reconstruction from sets of nonuniform 
samples is discussed in Chapter 5.
The principle of vector quantization is right that of the general quantiza-
tion. But due to the complexity limitation, the idea of the general quantiza-
tion is applied to relatively small image patches or blocks: for each particular 
image patch or block, a representative “typical block” is found from a 
“coded book,” which is supposed to be prepared in advance by a kind of 
learning procedure using image data base and image reconstruction quality 
requirements.
Appendix
Derivation of Equation 3.31
	
rad
sign
sign
m
m
m
n
n
n
( )
sin(
)
sin
ξ
πξ
π
ξ
=

=











−
=−∞∑
2
2
2
1



=














= −
−
=−∞∑
sign
n
m n
n
m
sin
(
)
,
π
ξ
ξ
2
1
1
where {ξn} are binary digits of binary representation of ξ (ξ < 1).
Then
	
wal x
rad
x
k
m
k
m
k
m
k
mGC
mGC m
mGC m
( )
( )
(
)
(
)
=
[
]
=
−
= −
+
=
∞
=
∞
∏
∏
+
+
1
0
0
1
1
1
ξ
ξ
1
0
m=
∞
∑
.

121
Image Digitization
Derivation of Equation 3.44
	
ε ω
ω
ω
ω
α ω ϕ
( )
( ,
)
( ,
)
( ,
)
( )
( )
( )
2
2
0
1
2
=
−
=
−
∫
∑
∫
=
−
a x
a x
x
a x
x
x
X
k
k
N
k
r
X

d
d
=
−
−
∫
∑
∫
∗
=
−
∗
a x
x
a x
x
x
a x
X
k
k
N
k
r
X
k
( ,
)
( ,
)
( )
( )
( ,
)
( )
( )
ω
ω
α ω ϕ
ω
α ω
2
0
1
d
d
k
N
k
r
X
k
k
N
k
r
l
l
N
x
x
x
=
−
∗
=
−
∗
=
−
∑
∫
∑


+
0
1
0
1
0
1
ϕ
α ω ϕ
α ω
( )
( )
( )
( )
( )
( )
d
∑
∫
∫
∑


=
−
∗
=
−
∗
ϕ
ω
α ω
ω ϕ
l
r
X
X
k
k
N
k
r
x
x
a x
x
a x
x
( )
( )
( )
( ,
)
( )
( ,
)
(
d
d
2
0
1
)
( )
( ,
)
( )
( )
d
d
x
a x
x
x
X
k
k
N
k
r
X
∫
∑
∫
−


∗
=
−
∗
α ω
ω
ϕ
0
1
	
+


=
∗
=
−
=
−
∗
∑
∑
∫
α ω α ω
ϕ
ϕ
ω
k
l
l
N
k
N
k
r
l
r
X
x
x
x
a x
( )
( )
( )
( )
( ,
)
( )
( )
0
1
0
1
d
2
0
1
0
dx
k
l
X
k
k
N
k
k
k
k
l
l
∫
∑
−
−
+
−
=
−
∗
∗
∗
=
α ω α ω
α ω α ω
α ω α ω δ
( )
( )
( )
( )
( )
( ) (
)
N
k
N
k
N
X
k
k
N
k
k
a x
x
−
=
−
=
−
=
−
∗
∗
∑
∑
∑
∫
∑
=
−
−
1
0
1
0
1
2
0
1
( ,
)
( )
( )
( )
ω
α ω α ω
α ω α
d
k
k
k
k
N
k
N
X
k
k
N
a x
x
( )
( )
( )
( ,
)
( )
ω
α ω α ω
ω
α ω
+
=
−
∗
=
−
=
−
=
−
∑
∑
∫
∑
0
1
0
1
2
2
0
1
d
	

122
Theoretical Foundations of Digital Imaging Using MATLAB®
Derivation of Equation 3.45
	
ϕ
α
ω
ϕ
ω
ω
k
opt
x
X
k
k
N
x
AV
a
x
x
k
A
( )
argmin
( )
( )
( )
( )
( )
{
}
=
−

{
}
=
−
∫
∑
Ω
2
2
0
1
d











=





−
{
}
∫
argmin
( )
( )
( )
ϕ
ω
k
A
x
X
AV
a
x
x
A
Ω
2 d
V
AV
A
k
A
k
k
N
x
k
Ω
Ω
α
ω
α
ω
ϕ
ω
( )
( )
(
( )
argmax
2
0
1
=
−
{
}
∑












=
)
( )
( )
*(
( )
argmax
ω
ϕ
ω
2
0
1
1
k
N
x
k
A
AV
a
x
a
=
−
{
}
∑












=


Ω
ω
ϕ
ϕ
)
( )
*( )
(
)
(
)
(
)
x
x
x
x
x
k
r
k
r
X
k
N
2
1
2
1
2
0
1











∫∫
∑
=
−
d d




=
{
}
∫∫
argmax
(
,
)
(
)
(
)
( )
( )
*( )
ϕ
ϕ
ϕ
k x
a
k
r
k
r
X
R x x
x
x
x
x
1
2
1
2
1
2
d d
k
N
=
−
∑






0
1
where R x x
AV
a
x
a
x
a
A
(
,
)
(
,
)
(
) .
( )
*( )
1
2
1
2
=


Ω
ω
ω
ω
Derivation of Equation 3.78
	


α
π
δ
( )
( )
( )
( )
( )exp(
)
(
) (
)
s
s
s
k
f
a
x
i
fx
x
a
k x
x
k x
=
=
−

−∞
∞
=−∞
∞
∫
∑
2
d
∆
∆







=
=
−∞
∞
=−∞
∞
∫
∑
exp(
)
(
)exp(
)
( )
( )
i
fx
x
a
k x
i
k xf
p F
s
k
2
2
π
π
α
d
∆
∆
R
p
i
k x f
p
p
p FR
p
p
i
s
k
s
( )
( )
( )exp
(
)
( )
( )
exp
2
2
π
α
∆
−


=
−∞
∞
=−∞
∞
∫
∑
d
d
π
α
π
k x f
p
p FR
p
p x
x
i
k x f
p
k
s
∆
∆
∆
∆
(
)
( )
( )
exp
(
)
( )
−


=
−
=−∞
∞
−∞
∞
∑
∫
d
1
2








=−∞
∞
−∞
∞
∑
∫
k
.

123
Image Digitization
Derivation of Equation 3.98
	
H
f p
k x
x
k x
i
fx
p
s
r
s
r
k
N
( & )
( )
( )
( , )
(
)
(
)exp
(
)
=
−
−
−


=
−
∑ϕ
ξ
ϕ
π
ξ
∆
∆
0
1
2
dd d
d d
x
k x
x
k x
i
fx
p
x
s
r
−∞
∞
−∞
∞
−∞
∫∫
=
−
−
−


ξ
ϕ
ξ
ϕ
π
ξ
( )
( )
(
)
(
)exp
(
)
∆
∆
2
∞
−∞
∞
=
−
−∞
∞
=
−
∫∫
∑
∫
∑
=
−
−
×
ξ
ϕ
ξ
π ξ
ξ
ϕ
k
N
s
k
N
r
k x
i
p
x
0
1
0
1
2
( )
( )
(
)exp(
)
(
∆
d
−
=
−
+


−∞
∞
−∞
∞
∫
∫
k x
i
fx
x
i
p
k x
s
∆
∆
)exp(
)
( )exp
(
)
( )
2
2
π
ϕ
ξ
π
ξ
ξ
d
d



k
N
r x
i
f x
k x
x
i
f
p k x
=
−
−∞
∞
∑
∫
×
+


=
−
0
1
2
2
ϕ
π
π
( )( )exp
(
)
exp
(
)



∆
∆
d


−
×
=
−
−∞
∞
∑
∫
k
N
s
r
i
p
x
i
fx
0
1
2
2
ϕ
ξ
π ξ
ξ
ϕ
π
( )
( )
( )exp(
)
( )exp(





d
)
exp
(
)
exp
(
)
( )
( )
dx
i
f
p N x
i
f
p
x
FR
f
F
r
−∞
∞
∫
=
−

−
−

−
2
1
2
1
π
π
∆
∆
R
p
i
f
p N x
i
f
p N x
i
f
s 



=
−

−
−
−


−
( )
exp
(
)
exp
(
)
exp
(
π
π
π
∆
∆
p
x
i
f
p
x
i
f
p N
x
F
)
exp
(
)
exp
(
)(
)
∆
∆
∆

−
−
−





−
−





π
π
×
1
r
f
FR
p
N
f
p N x
N
f
p
x
r
s
( )
( )
( )
( )
sin
(
)
sin
(
)
exp


=
−


−



π
π
∆
∆
i
f
p N
x
FR
f
FR
p
N
r
s
π(
)(
)
( )
( )
sincd
( )
( )
−
−










=

1 ∆
×
N
f
p N x
i
f
p N
x
FR
f
FR
p
r
s
; (
)
exp
(
)(
)
( )
( )
( )
( )
π
π
−


−
−




×

∆
∆
1



124
Theoretical Foundations of Digital Imaging Using MATLAB®
where FR(s)(·) and FR(r)(·) are frequency responses of signal sampling and 
reconstruction devices, defined by Equations 3.77 and 3.83 and
	
sincd(
; )
sin
sin(
)
N x
x
N
x N
=
Derivation of Equation 3.105
	
ε
α
alsng
r
s
m
FR
f
f
m
x FR
f
m
x
2
1
=




+




+







−∞
∞
=
∫
( )
( )
( )
∆
∆
∞
∑
+
−




−











=
α
α
f
m
x FR
f
m
x
f
AV
FR
f
f
s
r
s
∆
∆
Ω
( )
( )
( )
( )
d
+



+
−
















=
=
∞
−∞
∞
∑
∫
m
x
f
m
x
f
FR
s
m
r
∆
∆
α( )
(
1
2
d
)
( )
( )
( )f
AV
f
m
x
f
m
x
s
s
m
2
1
2
Ω
∆
∆
α
α
+



+
−












=
∞
∑


−∞
∞
∫
df
	
(A3.1)
where we replaced
	
α
α
( )
( )
( )
( )
( )
f FR
f
f
s
s
=
Consider
	
AV
f
m
x
f
m
x
A
s
s
m
Ω
∆
∆
α
α
( )
( )
+



+
−














=
=
∞
∑
1
2
V
f
m
x
f
m
x
s
s
m
n
Ω
∆
∆
α
α
( )
( )
+



+
−















=
∞
=
∞
∑
∑
1
1

×
+



+
−














=
∗
∗
α
α
α
( )
( )
( )
s
s
s
f
n
x
f
n
x
AV
∆
∆
Ω
f
m
x
f
n
x
AV
f
s
m
n
s
+




+











+
∗
=
∞
=
∞
∑
∑
∆
∆
Ω
α
α
( )
( )
1
1
−




+








+
+




∗
∗
m
x
f
n
x
AV
f
m
x
f
s
s
s
∆
∆
∆
Ω
α
α
α
( )
( )
( )
−








+
−




−








∗
n
x
AV
f
m
x
f
n
x
s
s
∆
∆
∆
Ωα
α
( )
( )



	
(A3.2)

125
Image Digitization
Consider now
	
AV
f
m
x
f
n
x
AV
a
x
i
f
s
s
s
Ω
Ω
∆
∆
α
α
π
( )
( )
( )( )exp
+




+








=
∗
2
+








−
+








∗
−∞
∞
m
x x a
i
f
n
x
x
s
∆
∆
( )( )exp
ξ
π
ξ
ξ
2
d d
∫∫
−∞
∞
∗








=
( )


−
+
−

AV
a
x a
i
f x
mx
n
x
s
s
Ω
∆
( )
( )
( )
exp
(
)
ξ
π
ξ
ξ
2







=
−
+
−




−∞
∞
−∞
∞
∫∫
d d
x
CF x
i
f x
mx
n
x
ξ
ξ
π
ξ
ξ
Ω
∆
( , )exp
(
)
2





−∞
∞
−∞
∞
∫∫
d d
x ξ,
		
	
	
(A3.3)
where CFΩ(x, ξ) is correlation function of ensemble of signals {a(s)(x)}. For 
­stationary signals CFΩ(x, ξ) = CFΩ(x − ξ),
	
AV
f
m
x
f
n
x
CF x
i
f x
s
s
Ω
Ω
∆
∆
α
α
ξ
π
( )
( )
(
)exp
(
+




+








=
−
∗
2
−
+
−








=
+
−∞
∞
−∞
∞
∫∫
ξ
ξ
ξ
ξ
π
ξ
ξ
)
( )exp
(
mx
n
x
x
CF
i
f
m
∆
Ω
d d



2
+
−














=
+


−∞
∞
−∞
∞
∫∫
ξ
ξ
ξ ξ
ξ
π
)
( )exp
n
x
CF
i
f
m
x
∆
∆
Ω
d d


2






−




−∞
∞
−∞
∞
∫
∫


ξ
ξ
π
ξ
ξ
d
d
exp i
m
n
x
2
∆
	
(A3.4)
Consider
	
exp
lim
exp
i
m
n
x
X
i
m
n
x
X
X
X
2
1
2
2
π
ξ
ξ
π
ξ
ξ
−




=
−




−∞
∞
→∞
−
∫
∫
∆
∆
d
d
=
−
(
) −
−
−
(
)
−
→∞
lim
exp
(
)
exp
(
)
(
)
X
X
i
m
n
x X
i
m
n
x X
i
m
n
x
1
2
2
2
2
π
π
π
/
/
/
∆
∆
∆
=
−
−
=
−



→∞
→∞
lim sin(
(
) )
(
)
lim sinc
X
X
m
n
x X
m
n
x X
m
n
x
X
2
2
2
π
π
π
/
/
∆
∆
∆
=
−
δ(
),
m
n
	
(A3.5)

126
Theoretical Foundations of Digital Imaging Using MATLAB®
where δ(m − n) is the Kronecker delta defined by Equation 2.4. Therefore
	
AV
f
m
x
f
n
x
CF
i
f
s
s
a s
Ω
∆
∆
α
α
ξ
π
( )
( )
( )( )exp
+




+








=
∗

2
+
















−
=
+




−∞
∞
∫
( )
m
x
m
n
SD
f
m
a s
∆
∆


ξ
ξ δ
ξ
d
(
)
δ(
),
m
n
−
	
(A3.6)
where SD
f
m
x
a s
( )
(
)
+
(
)
/∆
 is spectral density of the signal ensemble {a(s)(x)} on 
frequency (  f + m/Δx).
Substitute the right part of Equation A3.6 into each of the four terms of 
Equation A3.2 with an appropriate replacement of m by −m when needed 
and obtain
	
AV
f
m
x
f
m
x
S
s
s
m
Ω
∆
∆
α
α
( )
( )
+



+
−














=
=
∞
∑
1
2
D
f
m
m
n
SD
f
m
m
n
a
a
m
n
s
s
( )
+




−
+
+




+



=
∞
∑
∆
∆
ξ δ
ξ δ
(
)
(
)
( )
1
=
∞
∑
+
+




+
(
) +
+




−



( )
1
SD
f
m
m
n
SD
f
m
m
n
a
a
s
s
∆
∆
ξ δ
ξ δ
( )
(
)
=
+




−
+
+




=
∞
=
∞
∑
∑
2
2
1
1
SD
f
m
m
n
SD
f
m
m
a
m
n
a
s
s
( )
( )
(
)
(
∆
∆
ξ δ
ξ δ
+
=
+



+
−




=
∞
=
∞
=
∞
∑
∑
∑
n
SD
f
m
SD
f
m
m
n
a
m
a
m
s
s
)
( )
( )
1
1
1
2
2
∆
∆
ξ
ξ
=
∞
∑
1
.
	
	
	
	
(A3.7)
Now, we can use this result to obtain finally
	
ε
α
α
alsng
r
s
s
m
FR
f
AV
f
m
x
f
m
x
2
2
=
+



+
−








( )
( )
( )
( )
Ω
∆
∆
=
∞
−∞
∞
=
∞
∑
∫
∑






=
+



+
1
2
2
1
2
2
df
FR
f
SD
f
m
S
r
a
m
s
( )( )
( )
∆ξ
D
f
m
f
a
m
s
( )
−










=
∞
−∞
∞
∑
∫
∆ξ
1
d
	
(A3.8)

127
Image Digitization
or, with an account for α(  f  )FR(s)(  f  ) = α(s)(  f  )
	
ε
ξ
ξ
alsng
r
a
s
m
FR
f
SD
f
m
FR
f
m
2
2
2
1
2
=
+




+




−∞
∞
=
∞
∫
∑
( )
( )
( )
∆
∆



+
−




−







=
∞
∑SD
f
m
FR
f
m
f
a
s
m
∆
∆
ξ
ξ
( )
2
1
d
	
(A3.9)
Derivation of Equation 3.136
For P = 1 and p( )
exp
α
α
σα
∝
−(
)
2
2
2
, compute
	
p
P
( )
exp(
)
exp(
)
/(
)
min
min
α
α
α
σ
α
α
σ
α
α
α
α
α
α


=
−
=
−
+
∫
∫
1
2
1
2
2
2
2
6
6
d
d
d
d
d
α
α
σ
α
α
α
α
σ
α
α
α
α
σ
α
α
0
2
2
0
2
0
6
2
2
6
6
∫
∫
∫
−
−
=
−
−
−
exp(
)
exp(
)
exp(
min


)
,
min
min
dα
α
σ
α
σ
α
σ
α
α
α
6
0
6
6
∫
=
(
) +
(
)
erf
erf
where
	
erf x
x
( )
exp(
)
=
−
∫
2
2
0
π
ξ
ξ
d
then
	
w
w
w
w
erf
erf
erf
( )
(
)
(
)
(
)
min
max
min
min
max
α
α
α
α
α
σ
α
σ
α
α
α
−
−
=
(
) +
(
)
6
6
6σ
α
σ
α
α
(
) +
(
)
erf
min
6

128
Theoretical Foundations of Digital Imaging Using MATLAB®
Basics of Statistical Coding
Two mutually complement methods of binary statistical coding are known: 
variable-length coding (VL-coding) and coding of rare symbols. In the data cod-
ing jargon, objects of encoding are called symbols. VL-coding is aimed at 
generating, for each symbol to be coded, a binary code word with number of 
bits as close to the logarithm of the inverse to its probability. Originally sug-
gested by Shannon [8] and Fano [9], it was later improved by Huffman [10], 
and the Huffman’s coding procedure had become the preferred implementa-
tion of VL-coding. VL-Huffman coding is an iterative process, in which, at 
each iteration, two symbols with the least probabilities are found in the cur-
rent set of symbols, bits 0 and 1, correspondingly, are assigned to their codes 
and then these symbols are united to form a new auxiliary symbol, whose 
probability is the sum of that of the united symbols. The iteration process is 
repeated with the iterated set of symbols until all symbols are encoded. If 
probabilities of symbols are integer power of 1/2, such a procedure gener-
ates binary codes with number of bits per symbol exactly equal to the binary 
logarithm of the inverse to its probability, and therefore average number of 
bits per symbol is equal to the entropy of the symbol ensemble. An example 
of Huffman-coding is presented in Table A3.1 for eight symbols (A through 
H). As one can see, when probability of one of the symbols of the ensemble 
is much higher than 1/2, Huffman coding is inefficient because it does not 
allow allocating to symbols <1 bit. In such cases, coding of rare symbols is 
applied.
For coding of rare symbols, either of the two methods, run length coding 
and coding coordinates of rare symbols, can be used. In run length coding, the 
encoder generates from the initial sequence of symbols a new sequence, in 
which the runs of the most frequent initial symbol are replaced with new 
auxiliary symbols that designate the run lengths. This new sequence can 
then be subjected to VL-coding if necessary. Run length coding is an essen-
tially 1D procedure. For coding 2D data, it is applied after 2D data are con-
verted into 1D data by means of one or another scanning procedure; in image 
compression, a zigzag scanning (see Figure A3.1) is used.
Coding coordinates of rare symbols is an alternative to the run length 
coding. In this method, positions of rare symbols (others than the most 
frequent one) in the sequence are found. Then a new sequence of symbols 
is generated from the initial one in which all occurrences of the most fre-
quent symbol are removed and at each occurrence of rare symbols an aux-
iliary symbol is added that designates their position in the initial sequence. 
Coding coordinates of rare symbols is less vulnerable to errors in transmit-
ting the binary code than the run length coding. For the former, transmis-
sion errors cause only localized errors in the decoded symbol sequence, 
while in the latter they result in shifts of the entire decoded symbol 
sequence after the erroneous one. This property is of special importance 
in image coding for transmission over noisy channel: in the case of run 

129
Image Digitization
TABLE A3.1
An Example of VL-Huffman Coding of Eight Symbols
Iteration
A
P(A) = 0.49
B
P(B) = 0.27
C
P(C) = 0.12
D
P(D) = 0.065
E
P(E) = 0.031
F
P(F) = 0.014
G
P(G) = 0.006
H
P(H) = 0.004
1st
—
—
—
—
—
—
0
1
P(GH) = 0.01
2nd
—
—
—
—
—
0
1
P(FGH) = 0.024
3rd
—
—
—
—
0
1
P(EFGH) = 0.055
4th
—
—
—
0
1
P(DEFGH) = 0.12
5th
—
—
0
1
P(CDEFGH) = 0.24
6th
—
0
1
P(BCDEFGH) = 0.51
7th
0
1
Binary 
code
0
10
110
1110
11110
111110
1111110
1111111
	
Entropy H = 1.9554.
	
Average number of bits per symbol: 1.959.

130
Theoretical Foundations of Digital Imaging Using MATLAB®
length coding, channel errors may cause substantial deformation of object 
boundaries.
Exercises
EnergyCompact_DFT_DCT_Walsh_Haar_2D_CRC.m fringe_aliasing_demo_
  CRC.m
IdealVsNonidealSampling_CRC.m
quantization_demo_CRC.m
References
	
1.	 H. F. Harmuth, Transmission of Information by Orthogonal Functions, Springer 
Verlag, Berlin, 1970.
	
2.	 H. Karhunen, Über Lineare Methoden in der Wahscheinlichkeitsrechnung, Ann. 
Acad. Sci. Finn., Ser. A.I.37, Helsinki, 1947.
	
3.	 M. Loeve, Fonctions Aleatoires de Seconde Ordre, in: P. Levy, Processes 
Stochastiques et Movement Brownien, Hermann, Paris, France, 1948.
	
4.	 H. Hotelling, Analysis of complex of statistical variables into principal compo-
nents, J. Educ. Psychol., 24: 417, 441, 498–520, 1933.
FIGURE A3.1
The principle of zig-zag scanning 2D data on a rectangular sampling grid.

131
Image Digitization
	
5.	 V. A. Kotelnikov, On the carrying capacity of the ether and wire in telecom-
munications, Material for the First All-Union Conference on Questions of 
Communication, Izd. Red. Upr. Svyazi RKKA, Moscow, 1933 (Russian). (English 
translation: http://ict.open.ac.uk/classics/1.pdf.)
	
6.	 C. E. Shannon, Communication in the presence of noise, Proc. Inst. Radio Eng., 
37(1): 10–21, January 1949. Reprint as classic paper in Proc. IEEE, 86(2), 1998.
	
7.	 J. M. Whittaker, Interpolatory Function Theory, Cambridge University Press, 
Cambridge, England, 1935.
	
8.	 C. Shannon, A mathematical theory of communication, Bell Syst. Tech. J., 27(3): 
379–423; (4): 623–656, 1948.
	
9.	 R. M. Fano, Technical Report No. 75, The Research Laboratory of Electronics, 
MIT, March 17, 1949.
	 10.	 D. A. Huffman, A method for the construction of minimum redundancy codes, 
Proc. IRE, 40(10): 1098–1101, 1952.


133
4
Discrete Signal Transformations
Having established methods for digital representation of analog signals, 
consider how transformations of analog signals must be represented in com-
puters. In the section “Basic Principles of Discrete Representation of Signal 
Transformations,” we formulate the basics principles of discrete represen-
tation of signal transformations and in the subsequent sections “Discrete 
Representation of the Convolution Integral,” “Discrete Representation of 
Fourier Integral Transform,” and “Discrete Representation of Fresnel Integral 
Transform,” we apply them to introduce digital convolution as discrete rep-
resentation of the convolution integral, DFTs as discrete representation of 
the integral Fourier transform and discrete Fresnel transforms as discrete 
representation of the integral Fresnel transform. In the section “Discrete 
Representation of Kirchhoff Integral,” we introduce binary Hadamard and 
Walsh transforms as well as discrete wavelet transforms in their associa-
tion with signal multiresolution analysis. This chapter is concluded with 
an extension of discrete transforms to their application in sliding window, 
which leads to signal “space-frequency” representation.
Basic Principles of Discrete Representation of Signal 
Transformations
Two principles lie in the base of digital representation of analog signal 
transformations:
• Consistency principle with digital representation of signals
• Mutual correspondence principle between continuous and discrete 
transformations
The consistency principle requires that digital representation of signal 
transformations should be parallel to that of signals. The mutual correspon-
dence principle between continuous and digital transformations is said to 
hold if both act to transform identical input signals into identical output 
signals. Thus, digital signal transformations should be treated in terms of 
equivalent analog transformations. This principle is illustrated in Figure 4.1.

134
Theoretical Foundations of Digital Imaging Using MATLAB®
In Chapter 3, we admitted that signal digitization is carried out in two steps: 
discretization and element-wise quantization. Let signal a(x) be represented 
in a digital form by quantized coefficients {αk} of its discrete representation 
over a chosen discretization basis. In the section “Signal Transformations,” 
two classes of signal transformations were specified, point-wise nonlinear 
and linear ones. Digital representation of point-wise transformations is 
based on their definition through transfer functions {Fk(αk)} of the represen-
tation coefficients
	
PWTa = {
(
)}.
Fk
k
α
	
(4.1)
If coefficient values are quantized, functions {Fk(⋅)} can be specified in a 
tabular form. The volume of the table depends upon the number Q of quan-
tization levels. If this number is too large and especially when numbers in 
computers are represented in the floating point format, other methods of 
specifying transformation transfer functions are used. Most commonly, a 
polynomial approximation of functions is used:
	
F
c
k
k
s
k
s
s
S
(
)
,
α
α
=
=
−
∑
0
1
	
(4.2)
where {cs} are polynomial weight coefficients. This settles the problem of 
digital representation of point-wise signal transformations.
Representation of linear transformations in computers is more involved. 
Let {
( )}
( )
φn
d x , {
( )},
( )
φn
r x
 {
( )},
( )
  k
d x
 and {
( )}
( )
  k
r x
 be, respectively, discretization 
and reciprocal reconstruction bases for input a(ξ) and output b(x) signals of a 
linear transformation b = La and let {αk} and {βk} be the corresponding sets of 
signal representation coefficients on these bases:
	
a
a
n
n
r
n
n
n
d
X
( )
( );
( )
( )
;
( )
( )
ξ
α φ
ξ
α
ξ φ
ξ
ξ
=
=
∑
∫
d
	
(4.3)
Signal
digitization
Digital
signal
Analog input signal
Analog output signal
Digital
signal
transformations
Reconstruction
of the continuous
signal
Equivalent continuous transformation
Digital
signal
FIGURE 4.1
​Mutual correspondence principle between continuous and digital signal transformations.

135
Discrete Signal Transformations
	
b x
a
x
b x
x
x
k
k
r
k
k
k
d
X
( )
( )
( );
( )
( )
.
( )
( )
=
=
=
∑
∫
L ξ
β ϕ
β
φ
d
	
(4.4)
Substitute Equation 4.3 into Equation 4.4 to find numerical parameters of 
the linear transformation specified by its PSF h(x, ξ) that are needed to com-
pute the set of representation coefficients {βk} of the linear transformation 
output signal from those {αn} of its input signal:
	
β
φ
ξ ϕ
α φ
ξ ϕ
k
k
d
X
k
d
n
n
r
n
k
d
b x
x
x
a
x
x
x
=
=
=
∫
∫
∑
( )
( )
( )
( )
( )
(
( )
( )
( )
( )
d
d
L
L
X
)
( )
( )
( , )
( )
( )
( )
( )
d
d
d
x
x
x
h x
X
n
n
r
k
d
X
n
n
n
r
∫
∫
∑
∫
=
(
)
=



α
φ
ξ ϕ
α
ξ φ
ξ
ξ
L
Ξ





=
∫
∑
∑
ϕ
α
k
d
X
n
n
k n
n
x
x
h
( )
,
( )
,
d
	
(4.5)
where
	
h
h x
x
x
k n
n
r
k
d
X
,
( )
( )
( , )
( )
( )
.
=














∫
∫
ξ φ
ξ
ξ ϕ
d
d
Ξ
	
(4.6)
Coefficients {hk,n} form the discrete representation of the linear transfor-
mation with PSF h(x, ξ) for discretization basis functions of output signals 
{
( )}
( )
  k
d x
 and reconstructing basis functions {
( )}
( )
φn
r x  of input signals. We will 
refer to the set of coefficients {hk,n} as the discrete point spread function (DPSF) 
or discrete impulse response of the discrete linear transformation defined by 
the right part of Equation 4.5
	
β
α
k
n
k n
n
h
= ∑
,
	
(4.7)
referred to as the digital linear filter.
Equation 4.7 can be rewritten in a compact vector-matrix form as
	
B
HA
=
t, 	
(4.8)
where B = {βk} and is A = {αn} are vector-columns of the representative coeffi-
cients of output and input signals, superscript t denotes the matrix transposi-
tion, and H is the matrix of coefficients {hk,n}.

136
Theoretical Foundations of Digital Imaging Using MATLAB®
In a special case, when bases of the input and output signals are identical, 
orthogonal, and built from the “eigen” functions of the transformation:
	
φ
ϕ
ϕ
η ϕ
k
r
k
r
k
r
k
k
r
( )
( )
( )
( )
( )
( ) ;
( )
( )
⋅=
⋅
{
}
⋅
(
) =
⋅
L
	
(4.9)
filter matrix H degenerates into a diagonal matrix
	
H = {
},
,
η δ
k
k n
	
(4.10)
where δk,n is the Kronecker delta (Equation 2.4). In this case, the relation-
ship of Equation 4.7 between input and output representation coefficients is 
reduced to a simple element-wise multiplication:
	
β
η α
k
k
k
=
. 	
(4.11)
A discrete linear transformation described by a diagonal matrix will be 
referred to as the scalar filter. A general transformation described by Equation 
4.7 will be referred to as the vector filter.
Equation 4.6 provides a way to determine DPSF of a discrete linear 
­transformation that corresponds to a given analog linear transformation 
for chosen bases of its input and output signals. One can also formulate an 
inverse problem: given discrete transformation with DPSF {hk,n}, what will be 
the PSF of the equivalent analog transformation? To answer this question, 
substitute Equations 4.3 and 4.7 into Equation 4.4 and obtain
	
b x
x
h
x
h
a
k
k
r
k
n k
n
n
k
r
k
n k
n
n
d
( )
( )
( )
( )
( )
,
( )
,
( )
=
=




=
∑
∑
∑
∑
β ϕ
α
ϕ
ξ φ
( )
( )
( )
( )
( )
( )
,
( )
( )
ξ
ξ ϕ
ξ
φ
ξ ϕ
d
Ξ∫
∑
∑
∑






=





k
r
k
k n
n
d
k
r
n
k
x
a
h
x



∫
dξ
Ξ
	
(4.12)
from which it follows that PSF heq(x, ξ) of the analog linear transformation 
equivalent to the discrete transformation with DPSF {hk,n} given signal dis-
cretization and reconstruction bases is
	
h
x
h
x
eq
k n
n
n
d
k
r
k
( , )
( )
( ).
,
( )
( )
ξ
φ
ξ ϕ
=
∑
∑
	
(4.13)
In conclusion, note that in digital processing, DPSF coefficients of linear 
transformations are quantized. However, in most cases, they are represented 

137
Discrete Signal Transformations
in the floating point format, that is, the number of quantization levels is very 
high. Because of this, effects of DPSF quantization are usually assumed to be 
negligible and hence disregarded.
As it was stated in the section “The Sampling Theorem and Signal 
Sampling,” the most widely used method of signal discretization is signal 
sampling that uses shifted, or convolution, bases. In what follows, we derive 
discrete representation of the convolution integral and integral Fourier and 
Fresnel transforms for shifted bases.
Discrete Representation of the Convolution Integral
Digital Convolution
1D convolution integral of a signal a(x) with shift invariant kernel h(x) is 
defined as (Equation 2.40)
	
b x
a
h x
( )
( ) (
)
.
=
−
−∞
∞
∫
ξ
ξ
ξ
d
	
(4.14)
In signal sampling and reconstruction, sampling and reconstruction grids 
can, in principle, be arbitrarily shifted with respect to corresponding signal 
coordinate systems. Let signal sampling and reconstruction be performed 
over sampling grids shifted with respect to the signal coordinate axis by arbi-
trary shifts, respectively, ux
s( ) and ux
r( ) (in units of sampling interval Δx) such 
that sample a0 is taken at coordinate x
u
x
x
s
=
( )∆ and placed for ­reconstruction 
in coordinate x
u
x
x
r
=
( )∆ (see Figure 4.2).
Then sampling and reconstruction bases can be written as
	
φ
φ
φ
φ
k
s
s
s
k
r
r
r
x
x
k
x
x
x
k
x
( )
( )
( )
( )
( )
( )
( )
( )
,
=
−
(
)
=
−
(
)


∆
∆
and
	
(4.15)
where k
k
u
s
x
s
( )
( )
=
+
 and k
k
u
r
x
r
( )
( )
=
+
. Substituting Equations 4.14 and 4.15 in 
Equation 4.6, obtain
Signal
Signal samples
x
Δx
a1
a(x)
x = 0
u(s)Δx (u(r)Δx)
a2
a0
FIGURE 4.2
Signal samples in the signal coordinate system.

138
Theoretical Foundations of Digital Imaging Using MATLAB®
h
h x
n
x
x
k
x
k n
r
r
s
s
,
( )
( )
( )
( )
(
)
=
−
−
(
)






−
(
)
−∞
∞
∫
ξ φ
ξ
ξ ϕ


∆
∆
d
dx
h x
k
n
u
u
x
x
x
x
s
x
r
r
s
−∞
∞
−∞
∞
−
∫
∫
=
−
−
−
+
−
(
)


ξ
φ
ξ ϕ
ξ
( )
( )
( )
( )
( )
( )
∆
d d
∞
∞
−
∫
= hk n,
	
(4.16)
and Equation 4.7 takes the form
	
b
a h
k
n
k n
n
=
−
∑
,
	
(4.17)
where the summation is carried out over all signal samples. The definition 
of the convolution integral assumes that analog signal has infinite extent, 
which implies that the number of its samples is also infinitely high, that is, 
that
	
b
a h
k
n
k n
n
=
−
=−∞
∞
∑
.
	
(4.18)
In reality, the number of available signal samples is always finite as is 
the number of samples of the filter DPSF {hk}. Therefore, the summation in 
Equation 4.18 must be truncated. Because the spatial extent of the convolu-
tion kernel h(x) is usually less than that of signals and, consequently, the 
number N(h) of samples {hn} of the filter DPSF is less than that of signals, it is 
convenient to rewrite Equation 4.18 in an alternative form as
	
b
h a
k
n k n
n
=
−
=−∞
∞
∑
	
(4.19)
and then truncate the summation according to the extent of the filter DPSF:
	
b
h a
k
n k n
n
N h
=
−
=
−
∑
0
1
( )
.
	
(4.20)
Equation 4.20 is the basic equation for digital convolution.
For 2D signals, one can, in a similar way, obtain the following discrete 
representation of 2D convolution integral:
	
b
h
a
k l
n m k n l m
m n
h
,
,
,
,
,
=
−
−
∈∑
N
	
(4.21)

139
Discrete Signal Transformations
where (k, l) are sample indices over corresponding 2D coordinates, and N(h) 
is area of nonzero samples hn,m in a rectangular sampling grid. The program 
convolution_demo_CRC.m provided in Exercises illustrates image digital 
convolution.
Now, find the characteristics of an analog filter equivalent to a given digi-
tal one specified by its DPSF {hn} assuming that its analog output signal b(x) 
is reconstructed using certain limited number, say N(b), of output samples of 
the digital filter defined by Equation 4.20. To this end, express b(x) as
b x
b
x
k
x
h a
k
r
r
k
N
n k n
n
N
b
h
( )
( )
( )
( )
( )
=
−
(
) =






=
−
−
=
−
∑
∑
φ
φ

∆
0
1
0
1
( )
( )
( )
( )
( )
( )
( )
r
r
k
N
n
s
r
s
x
k
x
h
a
k
n
x
b
−
(
)
=
−
−
(
)




=
−
∑



∆
∆
0
1
ξ φ
ξ
dξ φ
ξ
φ
−∞
∞
=
−
=
−
∫
∑
∑








−
(
)
=
n
N
r
r
k
N
n
h
b
x
k
x
a
h
0
1
0
1
( )
( )
( )
( )
(
( )

∆
r
r
s
r
s
n
N
k
N
x
k
x
k
n
x
h
b
)
( )
( )
( )
( )
( )
( )
−
(
)
−
−
(
)




=
−
=
−
∑



∆
∆
φ
ξ
0
1
0
1
∑
∫








−∞
∞
dξ,
	
(4.22)
where k
k
u
r
r
( )
( )
=
+
 and n
n
u
s
s
( )
( )
=
+
, as before, are biased sample indices. 
From Equation 4.22, we can conclude that
	
h
x
h
x
n
x
k
n
x
eq
n
r
s
s
r
s
n
N h
( , )
( )
( )
( )
( )
( )
( )
ξ
φ
φ
ξ
=
−
(
)
−
−
(
)




=



∆
∆
0
−
=
−
∑
∑
1
0
1
k
N b
( )
	
(4.23)
is the overall PSF (OPSF) of the continuous filter equivalent to the digital 
filter with DPSF {hn}.
It is more convenient to characterize the equivalent continuous filter by 
its overall frequency response (OFR), Fourier transform of its OPSF. As it is 
shown in Appendix
	
OFR
f, p
h
x
i
fx
p
x
h
i
eq
eq
n
(
)
( , )exp
(
)
exp(
=
−


=
−∞
∞
−∞
∞
∫∫
ξ
π
ξ
ξ
π
2
2
d d
pn x
x
i
fx
x
n
N
r
x
∆)
( )exp(
)
( )
( )
=
−
−∞
∞
∑
∫








×






0
1
2
φ
π
d

−






×
−
(
)
−∞
∞
∫φ
ξ
π ξ
ξ
π
( )
( )
( )exp(
)
exp
(
)
e
s
x
r
i
p
i
f
p u
x
2
2
d
∆
xp
(
)
.
( )
( )
i
f
p k
x
r
k
N b
2
0
1
π
−








=
−
∑

∆
	
(4.24)

140
Theoretical Foundations of Digital Imaging Using MATLAB®
This expression contains four multiplicands. The first multiplicand
	
CFR p
h
i
pn x
n
n
N h
( )
exp(
)
( )
=
=
−
∑
2
0
1
π ∆
	
(4.25)
is a Fourier series expansion of the digital filter DPSF {hn}. It is referred to 
as continuous frequency response of the digital filter. Continuous frequency 
responses of digital filters are periodical functions of frequency with a 
period equal to the signal baseband (1/Δx).
The second and third multiplicands
	
Φ( )
( )
( )
( )exp(
)
r
r
f
x
i
fx
x
=
−∞
∞
∫φ
π
2
d
	
(4.26)
and
	
Φ( )
( )
( )
( )exp(
)
s
s
p
x
i
px
x
=
−∞
∞
∫φ
π
2
d
	
(4.27)
are, respectively, frequency responses of signal reconstruction device and 
complex conjugate of the frequency response of signal sampling device. If 
signal reconstruction and discretization devices are, as required by the sam-
pling theorem, ideal low-pass filters, terms Φ(r) (f) and Φ*(s) (p) are rectangular 
function with support (1/Δx) that remove in OFReq(f, p) all but one period of 
the digital filter continuous frequency response CFR(p).
The fourth term
SV f p
i
f
p u
x
i
f
p k
x
r
r
k
N b
( , )
exp
(
)
exp
(
)
( )
( )
( )
=
−


−


=
2
2
0
π
π
∆
∆

−
∑
=
−

−
−
(
)

−
−
1
2
1
2
1
2
exp
(
)
exp
exp
(
)
( )
i
N
f
p
x
i
f
p
x
i
f
p
b
π
π
π
∆
∆
u
x
N
f
p N
x
N
f
p
x
x
r
b
b
b
( )
( )
( )
( )
sin
(
)
sin
(
)
exp
∆
∆
∆


=
−


−


π
π
i
f
p
u
N
x
x
r
b
2
1
2
π(
)
( )
( )
−
+
−










∆
	
(4.28)
depends only on the number of output signal samples. It reflects the fact 
that the digital filter defined by Equation 4.20 and obtained as a discrete 
representation of the convolution integral is not spatially invariant owing to 

141
Discrete Signal Transformations
the finite number N(b) samples {bk} of the filter output signal involved in the 
reconstruction of analog output signal b(x). When this number increases, the 
contribution of border effects into the reconstructed signal diminishes. In 
the limit, when N(b) → ∞, the filter becomes spatially homogeneous because
	
lim
sin
(
)
sin
(
)
(
).
( )
( )
N
b
b
b
b
N
f
p N
x
N
f
p
x
f
p
( )→∞
−


−


=
−
π
π
δ
∆
∆
	
(4.29)
We already addressed the same issue in the section “Sampling Artifacts: 
Qualitative Analysis” when discussing signal reconstruction from its 
samples.
Note that phase-factor exp[
(
)(
(
))
]
( )
( )
i
f
p u
N
x
x
r
b
2
1 2
π
−
+
−/
∆
 in Equation 
4.28 disappears with a natural selection of the reconstruction shift param-
eter u
N
x
r
b
( )
( )
(
)
= −
−1 2
/ .
Treatment of Signal Borders in Digital Convolution
Equation 4.20 defines the digital convolution filter output signal samples 
{bk} only for k = N(h), N(h) + 1, N(a) − 1, where N(a) is the number of input signal 
samples. Samples for k < N(h) and k > N(a) − 1 are not defined because input 
signal samples {an} for n < 0 and for n > N(a) are not available. Therefore, in 
digital filtering, the number of output signal samples is shrinking away 
unless unavailable input signal samples are additionally defined by one or 
another method of signal extrapolation. If they are, the output signals within 
N(h)/2 samples at its borders are influenced by the extrapolated values of 
the input signal; hence, the extrapolation method must be selected to not 
produce undesirable artifacts. Proper border processing is especially impor-
tant in image processing because of the “curse of dimensionality.” Compare, 
for instance, cases of an audio signal of 106 samples, which corresponds to 
approximately 1 min of phonation, and an image frame of 103 × 103 = 106 pix-
els. Let filter DPSFs have N(h) = 100 for 1D filter and N(h) = 100 × 100 samples, 
that is, the same 1D extent, for 2D filter. Then, for the audio signal, border 
artifacts influence only 10−4-th fraction of samples (6 ms of phonation), while 
for the image signal 10−2-th fraction of pixels is influenced, or one tens on 
each of the image frame dimensions.
In principle, the task of image extrapolating outside the available frame 
of image samples is a special case of the problem of image recovery from 
incomplete set of data. Solving this problem requires formulation of a priori 
knowledge on images or image ensembles and quite sophisticated and com-
putationally expensive methods. Some methods based on the assumption of 
band-limitedness of images will be discussed in Chapter 7. In practice, more 
simple methods are conventionally used.
Very frequently, padding signals outside the signal frame by zeros are 
used. This is, for instance, what is implemented in MATLAB signal and 

142
Theoretical Foundations of Digital Imaging Using MATLAB®
image processing tool boxes. A justification of zero padding may be found 
in an assumption that signals must be extended by their mean value, which 
by default, is assumed to be zero. For many signals such as audio signals, 
the zero mean assumption seems natural. For images, this assumption, as 
a rule, is not relevant, although in some applications, images of objects do 
have an empty (zero) background, which can be extended beyond the image 
frame. Some astronomical images of extraterrestrial objects and tomographic 
images of body slices exemplify these cases.
In numerical and applied mathematics, another assumption, that of signal 
periodicity, is quite popular. It originates from the Fourier series expan-
sion of functions and is very well suited with applications of DFT, which, 
as we will see in the section “Discrete Representation of Fourier Integral 
Transform,” implies, by the definition, that signals are periodical with a 
period equal to the number of signal samples. In image processing, the 
periodical image extension beyond its borders, which makes extreme image 
samples of left and right, or upper and bottom borders immediate neigh-
bors, is definitely not appropriate and frequently results in heavy border 
artifacts.
The major source of border artifacts associated with the use of the above 
two signal extrapolation methods is that they tend to introduce discontinui-
ties in the extrapolated signal at borders of the initial signal. An alternative 
extrapolation method that is completely free of this drawback is signal even 
extension by means of mirror reflection from its borders. These methods and 
the way they work in signal convolution are illustrated in Figure 4.3.
In the section “Signal Convolution in the DCT Domain,” we will show 
that signal even extension by mirror reflection translates DFT into DCT, an 
orthogonal transform with very good energy compaction capability that can 
replace DFT in all its applications, including Fourier analysis, fast convolu-
tion, and signal resampling.
Discrete Representation of Fourier Integral Transform
Discrete Fourier Transforms
In this section, we apply the general approach to discrete representation of 
linear transformations formulated in the section “Basic Principles of Discrete 
Representation of Signal Transformations” to integral Fourier transform. Let 
signal reconstructing and spectrum sampling basis functions be, respec-
tively, {
( )
(
)}
( )
( )
ϕ
ϕ
k
r
r
x
x
k x
=
−∆
 and {
( )
(
)},
( )
( )
ϕ
ϕ
r
s
s
f
f
r f
=
−∆
 where, as before, 
k
k
ux
=
+
 and r
r
v f
=
+
 are biased indices of signal and its spectrum sam-
ples and ux and vf are, respectively, shifts, in fractions of the discretization 

143
Discrete Signal Transformations
intervals Δx and Δf, of signal and its spectrum samples with respect to the 
corresponding coordinate system as illustrated in Figure 4.4.
Then, according to Equation 4.6, a discrete representation of the Fourier 
transform kernel can be obtained as (see Appendix)
Discontinuity at
signal border
Discontinuity at
signal border
Discontinuity at
signal border
Discontinuity at
signal border
No discontinuity
at signal border
No discontinuity
at signal border
Zero-padded signal {a~
k}
Initial signal {ak}
Periodically extended signal  {a~
k}
Evenly extended signal  {a~
k}
Initial signal {ak}
Convolution kernel {hn} in its position for the ﬁrst convolution term
Convolution kernel {hn} in its position for the middle convolution term
Convolution kernel {hn} in its position for the last convolution term
Initial signal {ak}
FIGURE 4.3
​Signal extrapolation by means of zero padding, periodical extension, and even extension by 
means of mirror reflection at signal borders and how do they work in signal convolution.

144
Theoretical Foundations of Digital Imaging Using MATLAB®
	
h
i
fx
x
k
f
r f
x f
i
k
k r
r
s
,
( )
( )
exp(
)
exp
=
−
(
)
−
(
)
=
−∞
∞
−∞
∞
∫∫
2
2
π
φ
φ
π



∆
d d



r x f
f
r f
f
i
fk x
f
r
s
∆∆
Φ
∆
∆
(
)
+
(
)
(
)
−∞
∞
∫
( )
( )( )exp
,
φ
π
2
d
	
(4.30)
where Φ(r)(f) is the frequency response of the signal reconstruction device.
For discrete representation of the Fourier transform, only the term
	


h
i
kr x f
k r,
exp
=
(
)
2π
∆∆
	
(4.31)
is usually used, and the term
	
Φ
∆
∆
( )
( )( )exp
r
s
f
r f
f
i
fk x
f
+
(
)
(
)
−∞
∞
∫


φ
π
2
d
	
(4.32)
is disregarded, though, in principle, it also depends on sample indices k and 
r. Some justification reasonings for this are discussed in Appendix.
Now, let X be an interval occupied by the signal a(x) and N = X/Δx be the 
number of signal samples within this interval. According to the sampling 
theory (see the section “The Sampling Theorem and Signal Sampling” in 
Chapter 3), spectrum sampling interval Δf and extent X of the signal are 
Δf
f
vf
Signal spectrum
α( f )
x
a(x)
ux
Continuous signal
Δx
FIGURE 4.4
​Geometry of dispositions of signal and its Fourier spectrum samples (stems).

145
Discrete Signal Transformations
inverse to each other. Assume, therefore, that Δf = 1/σX, where σ is a scale 
parameter. Then, obtain that
	
∆∆
∆
x f
x
X
N
=
=
σ
σ
1
	
(4.33)
and Equation 4.31 can be rewritten as
	


h
i
kr
N
k r,
exp
.
=




2π σ
	
(4.34)
Then, the basic Equation 4.7 of digital filtering takes, for the representation 
of Fourier transform, the form
   
α
π σ
π
σ
r
u v
k
k
N
k
x
f
a
i
kr
N
a
i
k
u
r
v
( , ; )
exp
exp
(
)(
)
∝



=
+
+
=
−
∑
2
2
0
1

σN
k
N




=
−
∑
0
1
,
	
(4.35)
where superscripts (ux, vf) indicate that signal and its Fourier spectrum sam-
ples are taken with displacements ux and vf with respect to signal and spec-
trum coordinate systems (Figure 4.4).
To complete the derivation, introduce a normalizing multiplier 1/ σN  and 
obtain
	
α
σ
π
σ
σ
r
u v
k
x
f
k
N
N
a
i
k
u
r
v
N
( , ; )
exp
(
)(
) .
=
+
+




=
−
∑
1
2
0
1
	
(4.36)
As it is shown in Appendix, this transform has its inverse
	
a
N
i
k
u
r
v
N
k
u v
r
u v
x
f
r
N
( , ; )
( , ; ) exp
(
)(
) .
σ
σ
σ
σ
α
π
σ
=
−
+
+




=
−
∑
1
2
0
1
	
(4.37)
If σ > 1 and σN is an integer number (σN ∈ Z)
	
a
a
k
N
k
N N
N
k
u v
k
( , ; )
,
, ,...,
,
,
,...,
.
σ
σ
=
=
−
=
+
−



0 1
1
0
1
1 	
(4.38)
Of especial importance is the case of the cardinal sampling, when σ = 1 and, 
hence, ΔxΔf = 1/N. In this case and for signal and its spectrum sample zero 

146
Theoretical Foundations of Digital Imaging Using MATLAB®
shifts (ux = 0; vf = 0) we arrive at the transformations
	
α
π
α
π
r
k
k
k
N
r
r
N
N
a
i
kr
N
a
N
i
kr
N
=




=
−


=
−
=
−
∑
∑
1
2
1
2
0
1
0
1
exp
exp
and



	
(4.39)
are known as direct and inverse DFTs. In order to distinguish the general 
case from this special case, we will refer to transforms defined by Equations 
4.36 and 4.37 as shifted scaled discrete Fourier transforms SScDFT(ux, vf; σ). A ver-
sion of SScDFT(ux, vf; 1) for σ = 1 will be referred to as shifted discrete Fourier 
transforms SDFT(u,v) and a version of SScDFT(0,0;σ) for u = v = 0 will be 
referred to as scaled discrete Fourier transforms ScDFT(σ).
The presence of shift and scale parameters makes the SScDFTs more flex-
ible in simulating integral Fourier transform than the canonical DFT. As we 
will see in Chapter 6, it enables
• Performing continuous spectrum analysis
• Computing convolution and correlation with subpixel resolution
• Perfect and at the same time flexible and computationally efficient 
resampling of discrete signals
In all applications, the DFT is the basic transform because for its 
­computation a very efficient fast Fourier transform (FFT) algorithm exists 
(for the principle of FFT, see Appendix). All the above-introduced general-
izations can be computed in one or another way through DFT. In particular, 
shifted DFTs can be, for any shift parameters, computed through the DFT 
as follows:
	
α
π
π
r
u v
x
k
f
k
N
N
i
ru
N
a
i
kv
N
( , )
exp
exp
e
=












=
−
∑
1
2
2
0
1
xp
;
i
kr
N
2π




	
(4.40)
	
α
π
α
π
k
u v
f
r
x
r
N
N
i
kv
N
i
ru
N
( , )
exp
exp
e
=












=
−
∑
1
2
2
0
1
xp
.
i
kr
N
2π




	
(4.41)
Note that in Equations 4.40 and 4.41, multiplicands exp(±i2πux vf/N), which 
do not depend on sample indices k and r, are omitted as irrelevant and redun-
dant. Equations 4.40 and 4.41 can be used as alternative working definitions 
of shifted DFT.
Scaled DFTs can be represented as convolution, as it is shown in Appendix, 
and therefore, can also be computed through DFT using the discrete convo-
lution theorem presented below in Section “Properties of Discrete Fourier 
Transforms.”

147
Discrete Signal Transformations
2D Discrete Fourier Transforms
In the assumption that 2D signals are defined on a 2D rectangular sampling 
grid of N1 × N2 samples, 1D-shifted scaled DFTs can be straightforwardly 
generalized to 2D-shifted scaled DFTs, SScDFT(u1, v1; u2, v2; σ1, σ2), as
	
α
π σ
r s
u v u
v
k l
l
N
k
N
N N
a
i
kr
N
,
(
,
;
,
)
, exp
1
1
2
2
2
1
1
2
1
2
0
1
0
1
1
1
=
+
=
−
=
−
∑
∑

ls
N
σ2
2












;
	
(4.42)
	
a
N N
i
kr
N
ls
N
k l
r s
u v u
v
,
,
(
,
;
,
) exp
=
−
+





1
2
1
2
1
1
2
2
1
1
2
2
α
π σ
σ









=
−
=
−
∑
∑
s
N
r
N
0
1
0
1
2
1
,
	
(4.43)
where { , }
 
k l  and  
r s,
{
} are biased indices of signal and its spectrum samples:
	



k
k
u k
N
l
l
u l
N
r
r
v
r
f
=
+
=
−
=
+
=
−
=
+
=
1
1
2
2
0
1
0
1
0
1
,
,...,
,
,
,...,
;
,
,...,
,
,
,...,
;
N
s
s
v
s
N
f
1
2
1
0
1
2
−
=
+
=
−

	
(4.44)
{u1, u2} and {
,
}
v
v
f
f
1
2  are corresponding shifts of sampling grids in signal and 
Fourier transform domains, and {σ1, σ2} are scale parameters that define the 
relationships between signal and its spectrum sampling intervals {
,
}
  x
x
1
2  
and {
,
}
  f
f
1
2  and the numbers {N1, N2} of signal and spectrum samples: 
∆
∆
x
f
N
x
1
1
2
1
1
= /σ
; ∆
∆
x
f
N
x
2
2
2
2
1
= /σ
. By the definition, 2D SScDFTs are 
separable over their indices and therefore can be computed in two separate 
passes—row-wise and column-wise:
	
α
π σ
σ
r s
u v
k l
l
N N
a
i
kr
N
ls
N
,
( , )
, exp
=
+












=
1
2
1
2
1
1
2
2


0
1
0
1
1
2
1
1
2
2
1
1
2
2
N
k
N
k l
N N
i
kr
N
a
i
ls
N
−
=
−
∑
∑
=




exp
exp
,
π σ
π σ


2
0
1
0
1
1




=
−
=
−
∑
∑
l
N
k
N
y
.
	
(4.45)
Correspondingly, canonical direct and inverse 2D DFTs are defined as
	
α
π
r s
k l
l
N
k
N
N N
a
i
kr
N
ls
N
,
, exp
;
=
+








=
−
=
−
∑
∑
1
2
1
2
1
2
0
1
0
1
2
1
	
(4.46)
	
a
N N
i
kr
N
ls
N
k l
r s
s
N
r
N
,
, exp
=
−
+








=
−
=
−
∑
∑
1
2
1
2
1
2
0
1
0
1
2
1
α
π
.
	
(4.47)

148
Theoretical Foundations of Digital Imaging Using MATLAB®
A natural generalization of 2D-shifted and -scaled DFTs is 2D affine DFT 
(AffDFT). AffDFT is obtained in the assumption that either signal or its spec-
trum sampling or reconstruction is carried out in affine transformed, with 
respect to signal/spectrum coordinate systems (x1, x2), coordinates (
,
)


x x
1
2 :
	
x
x
A
B
C
D
x
x
1
2
1
2



= 









.
	
(4.48)
where (A, B, C, D) are numerical parameters of the affine transform. 
With 
σA
x
N A x
f
= 1
1
1
1
/
∆
∆

, 
σB = 1/N2BΔx2Δf2, 
σC
x
N C x
f
= 1
1
2
2
/
∆
∆

, 
and 
σD
x
N D x
f
= 1
2
2
2
/
∆
∆

, where   x1,   x2,  fx1, and  fx2  are signal and its Fourier 
transform sampling intervals in image (
,
)


x x
1
2  and Fourier (
,
)
f
f
x
x
1
2  planes, 
AffDTF is defined as
	
α
π σ
σ
σ
σ
r s
k l
A
C
B
D
a
i
rk
N
sk
N
rl
N
sl
N
,
, exp
=
+
+
+






2
1
1
2
2










=
−
=
−
∑
∑
l
N
k
N
0
1
0
1
2
1
.
	
(4.49)
A special case of affine transforms is rotation. For rotation angle θ
	
x
x
x
x
1
2
1
2



=
−








cos
sin
sin
cos
.
θ
θ
θ
θ


	
(4.50)
With N1 = N2 = N, ∆
∆
∆


x
x
x
1
2
=
=
, ∆
∆
∆
f
f
f
x
x
1
2
=
=
, and Δx Δf = 1/N (cardi-
nal sampling), 2D-rotated DFT (RotDFT) is obtained:
α
π
θ
θ
θ
θ
θ
r,s
k l
N
a
i
k
l
N
r
k
l
N
s
=
+
−
−





1
2
, exp
cos
sin
sin
cos













=
−
=
−
∑
∑
l
N
k
N
0
1
0
1
.
	
(4.51)
An obvious generalization of RotDFT is rotated and scaled DFT (RotScDFT):
α
σ
π
θ
θ
σ
θ
θ
σ
θ
r,s
k l
N
a
i
k
l
N
r
k
l
N
s
=
+
−
−



1
2
, exp
cos
sin
sin
cos















=
−
=
−
∑
∑
l
N
k
N
0
1
0
1
	
(4.52)
that assumes 2D signal sampling in θ-rotated and σ-scaled coordinate systems.
Properties of Discrete Fourier Transforms
In this section, we will review basic properties of DFTs. It is instructive to 
compare them with corresponding properties of the integral Fourier trans-
form discussed in Chapter 2. In order to avoid unnecessary complications in 

149
Discrete Signal Transformations
formulae, we will consider here only shifted DFTs. Some useful properties 
and usage of scaled DFTs will be discussed in Chapter 6.
Invertibility and sincd-Function
Let {
}
,
α r
u v  be SDFT(u,v) coefficients of a discrete signal {ak}, k = 0,1,. . .,N − 1. 
Compute the inverse SDFT with shift parameters (px, qf) of a subset of K spec-
tral samples {
}
,
αr
u v .
As it is shown in Appendix, in the result, we obtain
a
N
i
rp
N
i
n
n
u p v q
u v
x
r
K
r
/ ,
, exp
exp
/ =
−












−
=
−
∑
1
2
2
0
1
α
π
π (
)
exp
sincd
(
r
q
N
a
i k K
N
2v
K;N;
k
n
v
k
f
+




=
−+








−
+
π
π
1
u
p
i
K
N
q
n
x
x
k
N
f
−








×
−
−+








=
−
∑
)
exp
ex
0
1
1
2
π
p
(
) ,
i K
N
u
p
x
x
π
−
−




1
	
(4.53)
where
	
sincd( ;
; )
sin( (
) )
sin( (
))
K N x
K N x
N
x N
=
π
π
/
/
	
(4.54)
is the general discrete sinc-function, an extension of the discrete sinc-function 
introduced in Chapter 3 and defined by Equation 3.61; these two functions 
are identical when K = N.
For integer x = k − n and K = N, function sincd(
;
;
)
N N k
n
−
 is identical to 
Kronecker delta-function:
sincd[
;
; (
)]
sin[ (
)]
sin( (
))
(
)
,
,
N N
k
n
k
n
N
k
n N
k
n
k
n
π
π
π
δ
−
=
−
−
=
−
=
=
/
1
0
kk
n
≠



.
	
(4.55)
Therefore, when ux = px, vf = qf, and K = N
   
a
a
N N k
n
a
N k
n
n
u p v q
n
k
N
n
k
N
/ , /
sincd[
;
;(
)]
sincd[
;(
)]
=
−
=
−
=
−
=
−
∑
0
1
0
1
∑
= an,
	
(4.56)
which confirms the invertibility of the SDFT. However, the meaning of 
Equation 4.53 is richer. It shows that the SDFT is invertible in a more gen-
eral sense. Provided vf = qf = −(K − 1/2) and the demodulation of the recon-
structed signal by an exponential multiplier exp[−iπ(K − 1/N) (ux − px)], 

150
Theoretical Foundations of Digital Imaging Using MATLAB®
one, according Equation 4.26, can generate sincd-interpolated signal copies 
shifted with respect to the original signal samples by the (ux − px)-th frac-
tion of the sampling interval. In Chapter 6, we will show that such discrete 
sinc-interpolation is the gold standard for resampling discrete signals.
Discrete sinc-function is a discrete analog of the continuous sinc-func-
tion defined by Equation 2.73. Both functions are plotted for comparison in 
Figure 4.5.
One can see from the figure that continuous and sinc-function and dis-
crete sincd-function are almost identical within the basic interval of N sam-
ples for the discrete sinc-function and its corresponding interval NΔx for the 
­continuous sinc-function; within this interval, the difference between them 
does not exceed 10−2. Outside this interval, they differ dramatically: while 
sinc-function continues decaying, sincd-function is a periodical function 
and the type of its periodicity depends on whether N is odd or even number: 
sincd(N; k + gN) = (−1)g(N−1) sincd(N;k).
Energy Preservation Property
The invertibility of SDFTs implies that SDFTs are orthogonal transforms and, 
as such, they satisfy Parseval’s relationship:
	
ak
u v
k
N
r
u v
r
N
( , )
( , )
.
(
) =
(
)
=
−
=
−
∑
∑
2
0
1
2
0
1
α
	
(4.57)
1
0.8
(a)
(b)
(c)
(d)
Sincd(pi*Nx)
Sinc(pi*x)
Sincd(pi*Nx)
Sinc(pi*x)
Sincd(pi*Nx)
Sinc(pi*x)
Even N
Odd N
Even N
Even N; Sincd-sinc
0.6
0.4
0.2
–0.2
1.0
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1.0
1.0
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
–1
0
–2
–1.5
–1
–0.5
0
x
x
x
0.5
1
1.5
2
–2
–1.5
0.01
0.005
0
–0.005
–0.01
–0.5
0
0.5
–1
–0.5
0
0.5
1.0
1.5
2.0
–2
–1.5
–1.0
–0.5
0
0.5
1.0
1.5
2.0
FIGURE 4.5
Discrete sinc- (dash line) along with continuous sinc- (solid line) functions for odd (a) and even 
(c) number of samples N and differences between sinc- and sincd-functions within the basic 
interval NΔx for odd (b) and even (d) N.

151
Discrete Signal Transformations
Cyclicity
From Equation 4.37, it follows that, for an integer number g, discrete signal 
{
}
,
ak
u v  reconstructed by the inverse SDFT(ux, vy) from SDFT(ux, vy) spectrum of 
signal {ak} is defined outside the index interval (0, N − 1) as (see Appendix)
	
a
a
i
gv
k
gN
u v
k
u v
f
+
=
−
( , )
( , ) exp(
).
2π
	
(4.58)
In particular, when vf = 0, the signal is a periodical function of k:
	
a
a
a
k
gN
u
k
u
k
N
u
+
=
=
( , )
( , )
( )mod
( , )
,
0
0
0
	
(4.59)
where (k) mod N is a residual of k/N. Similar periodicity property holds for 
SDFT(ux, vf) spectra:
	
α
α
π
α
α
α
r
gN
u v
r
u v
x
r
gN
v
r
v
r
N
i
gu
+
+
=
=
=
( , )
( , )
( , )
( , )
( )mod
(
exp(
);
2
0
0
0, )
.
v
	
(4.60)
For the canonical DFT, both signal and its spectrum are periodical func-
tion of indices:
	
a
a
k
k
N
r
r
N
( , )
( )mod
( , )
( , )
( )mod
( , )
;
.
0 0
0 0
0 0
0 0
=
=
α
α
	
(4.61)
Owing to the separability of the DFTs, the same cyclicity feature holds for 
2D and multidimensional DFTs for all indices. The cyclicity feature is the 
main distinction of DTFs from the integral Fourier transform they represent.
Shift Theorem
The shift theorem for the DFTs is completely analogous to that for integral 
Fourier transform: absolute value of signal SDFT(ux, vf) spectrum is invariant 
to the signal shift; signal shift causes only linear modulation of the phase of 
the spectrum.
To prove this, let αr
u v
( , ) be SDFT(ux, vf) of signal {
}.
ak k
+ 0
 Express signal {
}
ak k
+ 0  
as inverse SDFT(ux, vf):
a
N
i
k
k
u
r
v
N
N
k k
r
u v
x
y
r
N
r
u
+
=
−
=
−
+
+
+




=
∑
0
1
2
1
0
0
1
α
π
α
( , )
(
exp
(
)(
)
, ) exp
exp
(
)(
) .
v
y
x
y
r
i
r
v
N
k
i
k
u
r
v
N
−
+








−
+
+




2
2
0
π
π
=
−
∑
0
1
N
	 (4.62)
Equation 4.62 implies that SDFT(ux, vf) spectrum of the shifted signal 
{
}
ak k
+ 0  is α
π
r
u v
y
i
r
v
N
k
( , ) exp −
+










2
0
, which proves the theorem. Similarly, 

152
Theoretical Foundations of Digital Imaging Using MATLAB®
shifted signal spectrum {
}
,
αr r
u v
+ 0  corresponds to phase-modulated signal 
a
i
r k
u
N
k
u v
x
, exp
2
0
π
+



.
Convolution Theorem
The convolution theorem for DFTs is an analog of the convolution theorem 
for integral Fourier transform (see Chapter 2, Equation 2.82): a product of 
SDFT spectra of two signals is the SDFT spectrum of the result of convolu-
tion of these signals. However, in distinction to arithmetic (aperiodic) con-
volution, associated with integral Fourier transform, convolution associated 
with SDFTs is cyclic, by virtue of the cyclicity property of SDFTs.
Let {
}
(
,
)
αr
u v
a
a
 be SDFT (
,
)
u
v
x
a
f
a  of a signal {ak} and {
}
(
,
)
βr
u v
b
b  be SDFT (
,
)
u
v
x
b
f
b  
of a signal {bk}, k,r = 0,1,. . .,N − 1. Compute the inverse SDFT (
,
)
u
v
x
c
f
c  of their 
product and obtain (see Appendix)
c
N
i
k r
N
k
u v
r
u
v
r
u
v
c
c
r
N
c
c
a
a
b
b
(
,
)
(
,
)
(
,
) exp
=
−




=
=
−
∑
1
2
0
1
α
β
π
 
1
2
2
N
i
k
v
v
N
a
i
n
v
v
N
c
f
c
f
b
n
a
f
a
f
b
exp
exp
−
−
(
)






−
(
)





π
π



−
=
−
∑
bk n
n
N
,
0
1
	
(4.63)
where 


k
k
u
k
k
u
k
k
u
a
x
a
b
x
b
c
x
c
=
+
=
+
=
+
;
;
;  r
r
v
r
r
v
r
r
v
a
f
a
b
f
b
c
f
c
=
+
=
+
=
+
;
;
; 
and
	
b
N
i
k
n
u
u
r
v
N
k n
r
u
v
x
c
x
a
f
b
r
N
b
b
−
=
−
=
−
−
+
−
(
)
+
(
)








1
2
0
β
π
(
,
) exp
1
∑
	
(4.64)
is signal reconstructed from spectrum {
}
,
βr
u v
b
b  using inverse SDFT (
,
).
u
u v
x
c
x
a
f
b
−
By virtue of the general invertibility property of SDFTs, when it is selected 
that v
N
f
b = −
−
(
)1 2
/
	
b
b
N
n
m
u
u
u
m
n
x
b
x
c
x
a
n
N
=
−
+
−
+
(
)


=
−
∑
sincd
;π
0
1
	
(4.65)
is a discrete sinc-interpolated copy of signal {bn} shifted by u
u
u
x
b
x
c
n
a
−
+
. The 
derivation of Equation 4.65 is provided in Appendix.
When v
v
v
v
v
f
a
f
b
f
c
f
=
=
=
=
, Equation 4.63 is converted to
c
N
i
k
u
r
v
N
k
u v
r
u
v
r
u
v
x
c
v
r
c
c
a
b
(
,
)
(
, )
, exp
(
)
=
−
+
(
)
+








=
1
2
0
α
β
π
N
n k n
n
N
N
a b
−
−
=
−
∑
∑
=
1
0
1
1

.
	
(4.66)

153
Discrete Signal Transformations
Equation 4.66 represents discrete convolution of signals {ak} and {
}
bk . Being 
computed through SDFTs, it assumes that the signals are extended outside 
the index interval [0, N − 1] according to the cyclicity property of SDFTs 
(Equation 4.60).
In a special case of the DFT (ua = ub = uc = va = vb = vc = 0), it is a cyclic 
convolution:
c
N
i
kr
N
N
a
k
r
r
r
N
n
N
( )
( , )
( , )
( )
mod
mod
exp
=
−



=
=
−
∑
1
2
1
0 0
0 0
0
1
α
β
π
N
N
b k n
n
N
(
)mod ,
−
=
−
∑
0
1
	
(4.67)
which regards signals as being periodical with a period of N samples.
In a similar way, considering inverse SDFT (
,
)
u
v
x
c
f
c  of the product of 
SDFT (
,
)
u
v
x
a
f
a  spectrum αr
u
v
xa
f
a
,
(
) of signal {ak} and complex conjugate to SDFT 
(
,
)
u
v
x
b
f
b  spectrum βr
u
v
xb
f
b
∗(
)
,
 of signal {bk}, k = 0,1,.. .,N − 1, obtain with selection 
v
v
v
N
f
a
f
b
f
c
=
=
= −
−
(
)1 2
/  (see Appendix):
	
c
N
i
k r
N
a
k
u v
r
u
v
r
u
v
c
c
r
N
c
c
a
a
b
b
,
(
,
)
(
,
) exp
=
−



=
∗
=
−
∑
1
2
0
1
α
β
π
 
n n k
n
N
b −
=
−
∑
0
1
,
	
(4.68)
where bn is defined by Equation 4.65.
Equation 4.68 complements Equation 4.66 and describes the correlation of 
signal {ak} with discrete sinc-interpolated copy of signal {bk}. Similar to con-
volution, in a special case of the DFT (ua = ub = uc = va = vb = vc = 0) it is a cyclic 
correlation:
 
c
N
i
kr
N
N
a
k
r
r
r
N
n
N
( )
( , )
( , )
( )
mod
mo
exp
=
−



=
∗
=
−
∑
1
2
1
0 0
0 0
0
1
α
β
π
d
mod
(
)
.
N
N
b n k
n
N
−
=
−
∑
0
1
	
(4.69)
Symmetry Properties
Symmetry properties of general SDFT(ux, vf) are quite intricate. We will 
consider here several most important special cases with which we deal 
in this book. First of all, consider symmetry properties of the canonical 
DFT. As shown in Appendix, for signal {ak} and its DFT spectrum {αr} and 
their index reversed copies {aN−k} and {αN−r}, the following relationships 
hold:
	
{
}
{
};
.
*
*
a
a
N k
N r
k
N r
−
−
−

→

{ } 
→
{
}
DFT
DFT
α
α
	
(4.70)

154
Theoretical Foundations of Digital Imaging Using MATLAB®
From Equations 4.70, it follows that
 
{
}
{
};
;
*
*
a
a
a
a
k
N k
r
N r
k
k
r
N r
= ±

→

= ±
= ±
{
} 
→

= ±
{
}
−
−
−
DFT
DFT
α
α
α
α
α0 =
=
=
= ±
{
} 
→

= ±
−
−
α
α
α
α
α
0
2
2
*
/
*
*
;
,
For even 
, 
/
DFT
N
a
a
a
N
N
k
k
N k
r
N r
*
.
= ±
{
}
−
αN r
	
(4.71)
Reversing signal and its DFT spectrum indices corresponds to revers-
ing sign of signal coordinate and frequency for integral Fourier transform. 
Equations 4.70 and 4.71 show that this analogy is not complete: the signal 
and its DFT spectrum samples with index 0 and, for even N, index N/2 are 
not inversed, and index N/2, which for odd N is virtual, plays a role of the 
symmetry center, as do points x = 0 and f = 0 for integral Fourier transform.
SDFT(1/2,1/2) with both semi-integer shift parameters exhibits more per-
fect symmetry (see Appendix):
	
{
}
;
aN
k
N
r
−−
−−

→
{
}
1
1
SDFT(1/2,1/2)
(1/2,1/2)
α
	
(4.72)
	
{
}
a
a
k
N
k
r
N
r
= ±

→

= ±
−−
−−
1
1
SDFT(1/2,1/2)
(1/2,1/2)
(1/2,1/2
α
α
)
{
} 	
(4.73)
 
a
a
a
k
k
N
k
r
N
r
= ±
= ±
{
} 
→

=
∗
−−
−−
∗
1
1 2 1 2
1 2 1 2
1
1 2 1 2
SDFT(
,
)
(
,
)
(
,
α
α
∓
)
(
,
) .
= ±
{
}
−−
αN
r
1
1 2 1 2
	 (4.74)
For SDFT(u,0) spectra {
}
( , )
αr
u 0
, the following properties are useful:
	
a
i
u
a
a
k
u
N r
u
k
k
u
*
( , )
*( , )
*
( , )
exp(
) ;
{ } 
→
{
}
=
{
}
−
SDFT
SDFT
0
0
0
2
α
π

→

=
{
}
−
α
α
π
r
u
N r
u
i
u
( , )
*( , ) exp(
) .
0
0
2
	
(4.75)
SDFT Spectra of Sinusoidal Signals
SDFT(ux, vf) spectrum of a sinusoidal signal ak = cos(2π(ρk/N) + ϕ) is a combi-
nation of two discrete sinc-functions:
	
α
π ρ
φ
π
r
x
f
k
N
N
k
N
i
k
u
r
v
N
N
=
+




+
+




=
=
−
∑
1
2
2
2
0
1
cos
exp
(
)(
)
exp
sincd[
; (
)]
exp
(
)(
)
i
r
v
N
u
N
r
v
i
N
r
v
f
x
f
f
2
1
π
π
ρ
π
ρ
+




+ +

−
+ +
×
N
r
v
i
N
r
v
N
f
f
+










+
−+
−
−+
−


φ
π
ρ
π
ρ
φ
sincd[ (
)]
exp
(
)(
)
×
1











	
(4.76)

155
Discrete Signal Transformations
shifted in index by the frequency index ρ of the signal. In a special case of 
DFT (ux = 0, vf = 0),
	
α
π ρ
φ
π
π
r
k
N
N
k
N
i
kr
N
N
N
r
=
+








=
+
=
−
∑
1
2
2
2
0
1
cos
exp
sincd[
; (
ρ
π
ρ
φ
π
ρ
π
)]exp
(
)(
)
sincd[ (
)]exp
i
N
r
N
r
i
−
+
+













+
−
1
(
)(
)
.
N
r
N
−
−
−













1
ρ
φ
	
(4.77)
For integer ρ, discrete sinc-functions in Equation 4.77 are reduced to two 
Kronecker deltas:
	
α
π ρ
φ
π
δ
ρ
r
k
N
N
k
N
i
kr
N
N
r
i
=
+








=
+
=
−
∑
1
2
2
2
0
1
cos
exp
{ (
)exp( φ
δ
ρ
φ
)
(
)exp(
)}.
+
−
−
r
i
	
(4.78)
Examples of DFT spectra of sinusoidal signals with integer and noninteger 
frequency parameter ρ are presented in Figure 4.6.
Mutual Correspondence between Signal Frequencies and Indices of Its 
SDFTs Spectral Coefficients
By definition of SDFTs, index r of SDFT spectral coefficients is linked with 
frequency f parameter of signal Fourier spectra by the following relationship:
1
0.8
0.6
0.4
0.2
0
0
32
64
96
Frequency index
abs(DFT(sin(2πρk/256))); ρ = 32
(a)
(b)
abs(DFT(sin(2πρk/256))); ρ = 32.3
Frequency index
128
160
192
224
0
32
64
96
128
160
192
224
1
0.8
0.6
0.4
0.2
0
FIGURE 4.6
DFT spectra of sinusoidal signals with 256 samples and with integer (a) and noninteger (b) 
frequency parameter ρ.

156
Theoretical Foundations of Digital Imaging Using MATLAB®
	
f
r f
r N x
f x
f
r N
=
=
=
=
∆
∆
∆
/
/
;
,

	
(4.79)
where f  is a normalized frequency measured in fractions of the signal base-
band 1/Δx.
DFT spectral coefficient α0
0 0
( , ) plays a role of the zero-frequency component 
of the integral Fourier transform. It is proportional to the signal dc-component:
	
α0
0
1
1
=






=
−
∑
N
N
ak
k
N
.
	
(4.80)
For even N
	
αN
k
k
k
N
N
a
/
(
)
2
0
1
1
1
=
−
=
−
∑
	
(4.81)
represents the highest, f = (N/2)Δf = 1/2Δx, signal frequency component. For 
odd N, coefficients α
α
(
)/
(
)/
*
N
N
−
+
=
1
2
1
2 (for signals with real values) represent 
the highest signal frequency f = (N − 1/2)Δf = (N − 1)/2NΔx.
In order to maintain similarity between DFT spectrum {αr} of discrete 
signal {ak} and Fourier spectrum α(f), f ∈ [−∞, ∞] of the corresponding con-
tinuous signal a(x), it is convenient to cyclically shift sequence {αr} in such 
a way as to place the dc-component coefficient {α0} in the middle of the 
sequence. For even and odd N, shifts are N/2 and (N − 1)/2 correspond-
ingly and spectral coefficients should to be taken, correspondingly, in the 
following order: [αN/2, αN/2+1, . . ., αN−1, α0, α1, . . ., αN/2−1] and [α(N+1)/2, α(N+1)/2+1, 
. . ., αN−1, α0, α1, . . ., α(N−1)/2]. For 2D signals of N1 × N2 samples, these cyclical 
shifts should be taken along the two corresponding indices. In MATLAB, 
this centering shift is performed by the command, fftshift. Figures 4.7 and 
4.8 illustrate the spectral coefficient reordering for DFT spectra of 1D and 
2D sinusoidal signals.
DFT Spectra of Sparse Signals and Spectrum Zero Padding
Let discrete signal {
}
 ak  of LN samples (k
LN
=
−
0 1
1
, ,...,
) be obtained from 
signal {ak} of N samples (k = 0,1, ..., N − 1) by placing between its samples 
(L − 1) zero samples. If index k is represented as a two-component index 
k
kL
l
=
+ , k = 0,1, . . ., N − 1, l = 0,1, . . ., L − 1, such a signal with sparse sam-
ples can be represented as
	
 a
a
l
k
k
=
δ( ), 	
(4.82)

157
Discrete Signal Transformations
where δ(.) is Kronecker’s delta. Compute the DFT of this signal:
	





α
π
δ
π
r
k
k
LN
k
LN
a
i
kr
LN
LN
a
l
i
kL
l
=




=
+
=
−
∑
1
2
1
2
0
1
exp
( )exp
LN
r
LN
a
i
kr
N
L
k
N
l
L
k
k
N






=



=
=
−
=
−
=
−
∑
∑
∑
0
1
0
1
0
1
1
2
1
exp
π
α r
N
( )mod ,
	
(4.83)
where {
}
( )mod
α r
N , r
LN
=
−
0 1
, , . . .,
 is the DFT of signal {ak}. Equation 4.83 shows 
that placing zeros between signal samples results in a periodical replication of 
its DFT spectrum with the number of replicas equal to the number of zeros plus 
one. This property of DFT spectra of sparse signals is illustrated in Figure 4.9a–
d. It is an analog of virtual spectrum replication in sampling continuous signals 
discussed in the section “Sampling Artifacts: Quantitative Analysis.”
Let us now multiply spectrum {
}
αr  by a mask {μr} that zeros all periods but 
one (Figure 4.9e). According to the convolution theorem, multiplying signal 
DFT spectrum by a mask function results in signal cyclic convolution with 
IDFT of the mask. In order to secure that the convolution kernel is a real-
valued function, the mask should maintain spectrum symmetry for real-
valued signals (Equation 4.71). Thus, the definition of the mask depends on 
whether N is an odd or even number. For odd N, the mask should be
	
µ 

r
rect r
N
LN
N
=
−
−
+
(
)
−
−




1
1
2
1
/
,
	
(4.84)
where rect(x) = 1, 0 < x < 1; 0, otherwise (Equation 2.45).
1
0.8
0.6
0.4
0.2
0
128
160
192
224
0
32
64
96
Frequency index
abs(DFT(sin(2πρk/256))); ρ = 32
FIGURE 4.7
​Spectrum of a sinusoidal signal Figure 4.6a reordered by the MATLAB command “fftshift” for 
spectrum centering.

158
Theoretical Foundations of Digital Imaging Using MATLAB®
sin(2*pi*(fx*x/Nx+fy*y/Ny));
fx = 32; Nx = 128; fy = 16; Ny = 128
(a)
(b)
(c)
(d)
(e)
abs(DFT spectrum)
16
32
48
64
80
96
Frequency index
112
112
96
80
64
Frequency index
fftshift(abs(DFT spectrum))
(N/2,N/2)
(N/2–1,N/2)
((N+1)/2,(N+1)/2)
((N+1)/2,0)
((N–1)/2,0)
0
((N–1)/2,(N+1)/2)
(N/2–1),N/2–1)
(0,0)
((N+1)/2,(N–1)/2)
((N–1)/2,(N–1)/2)
(N/2,0)
0.5
0
(0,0)
fx
(N/2-1,0)
0
0.5
–0.5
–0.5
0.5
fx
–0.50.5
0.5
(N/2,N/2–1)
fy
fy
80
96
112
0
16
32
48
80
96 112
Frequency index
0
16
32
48
Frequency index
48
32
16
FIGURE 4.8
​(a–c) A 2D sinusoidal signal and its DFT spectrum represented as an image in the original 
index order (b) and in the shifted index order (c), which corresponds to analog Fourier spec-
trum coordinate system centered at point (fx = 0; fy = 0). Two small dark boxes in images (b) and 
(c) indicate the position of signal spectral components. (d–e) Schematic maps of arrangements 
of N × N “fftshifted” 2D DFT spectral coefficients for even (d) and odd (e) number N in their 
correspondence with frequency (fx, fy) coordinates of integral Fourier transform. Numbers in 
brackets indicate coefficient indices. For real-valued signals, spectral coefficients symmetrical 
with respect to coordinate origin (0, 0) and marked with crosses and stars are mutually com-
plex conjugate and those marked with circle are real valued.

159
Discrete Signal Transformations
Initial signal
(a)
(c)
(d)
(b)
Initial signal spectrum
2
1
0.8
0.6
0.4
0.2
0
1
0
–1
–2
–3
10
20
Sample indices
5× Replicated signal spectrum
5× Sparse signal
2
0
–2
1
0.5
0
20
40
60
80
Frequency indices
100
120
140
160
20
40
60
80
Sample indices
100
120
140
160
30
10
20
Frequency indices
30
FIGURE 4.9
(a) A test signal; (b) its DFT spectrum; (c) sparse signal obtained from signal (a) by placing four 
zeros between its samples; (d) DFT spectrum of the obtained sparse signal; (e) zero-padded 
spectrum of the sparse signal after removing all its periodical components but one; (f) sincd-
interpolated signal reconstructed from the zero-padded spectrum.

160
Theoretical Foundations of Digital Imaging Using MATLAB®
In this case, the inverse DFT of {[1 − rect ((r − (N + 1)/2)/(LN − N − 1))]α(r)mod N} 
produces (see Appendix) a signal
	



a
LN
rect r
N
LN
N
i
kr
LN
k
r
N
=
−
−
+
−
−




−
1
1
1 2
1
2
(
)
exp
( )mod
/
α
π




=
−
(
)




=
−
=
−
∑
∑


r
LN
n
n
N
L
a
N; k
nL
L
0
1
0
1
1
sincd
,
	
(4.85)
or
	
a
L
a
N;k
n
l
L
Lk l
n
n
N
+
=
−
=
+




∑
1
0
1
sincd
−
.
	
(4.86)
This equation shows that nonzero samples of signal ak in signal ak are 
equal to 1/ L -scaled samples of the original signal {ak}
0.6
0.4
0.2
–0.2
–0.4
–0.6
20
40
60
80
Sample indices
Interpolated signal
Sparse signal
Sparse and interpolated signals
100
120
140
160
0
20
1
(e)
(f)
0.5
0
40
60
80
100
120
140
160
Frequency indices
Zero-padded signal spectrum
FIGURE 4.9
Continued.

161
Discrete Signal Transformations
	
a
L
a
Lk
k
=
1
,
	
(4.87)
while its additional zero samples are interpolated with the discrete sinc-
function from the initial nonzero ones (see Figure 4.9f).
For even N, maintaining the spectrum complex-conjugated symmetry 






α µ
α
µ
r
r
LN r
LN r
=
−
−
*
 is possible either with the mask
	
µ 

r
rect r
N
LN
N
( )
,
0
1
2
=
−
−
−
/
	
(4.88)
which zeros N/2-th component of the original spectrum {αr} or with the mask
	
µ 

r
rect r
N
LN
N
( )
,
2
1
2
1
2
=
−
−
−
−
−
/
	
(4.89)
which leaves two copies of this component in the extended spectrum. In 
these two cases one can, similarly to the derivation of Equation 4.86, obtain 
that inverse DFT (IDFT) of the masked-extended spectrum results in signals:
   


a
L
a
N
N k
n
l
L
kL l
r
r
N
n
+
( )
=
{
} =
−
−
+




( )
( )
mod
0
0
1
IDFT
sincd
1;
;
µ α

=
−
∑
n
N
0
1
	
(4.90)
or, correspondingly
   


a
L
a
N
; N k
n
l
L
k
r
r
N
n
n
N
=
{
} =
+
−
+




=
IDFT
sincd
;
µ α
( )
( )mod
2
0
1
1
1
−
∑
1
,
	
(4.91)
where sincd
;
( ;
)
⋅⋅⋅ is general discrete sinc-function, defined by Equation 3.61.
Equations 4.86, 4.90, and 4.91 are discrete analogs of reconstruction of con-
tinuous signals from their samples discussed in the section “The Sampling 
Theorem and Signal Sampling” in Chapter 3. Masking functions {μr} 
(Equations 4.84, 4.88, and 4.89) describe discrete ideal low-pass filters. If N is 
an even number, original signal samples are not retained in the interpolated 
signal because of the special treatment required for the spectral coefficient 
with index N/2. In Chapter 6, we will consider discrete sinc-interpolation in 
detail. The properties of canonican 1D and 2D DFTs are illustrated by the 
MATLAB program dft_demo_CRC.m provided in Exercises.
Discrete Cosine and Sine Transforms
There are a number of special cases of SDFTs worthy of a special discussion. 
All of them are associated with representation of signal and/or spectra that 
exhibit certain symmetry. The most important special case is that of DCT.

162
Theoretical Foundations of Digital Imaging Using MATLAB®
Let, for a signal {ak}, k = 0,1, . . ., N − 1 form an auxiliary signal
	
a
a
k
N
a
k
N
N
k
k
N k
=
=
−
=
−



−−
,
, ,...,
,
,...,
.
0 1
1
2
1
2
1
	
(4.92)
It is shown in Appendix that SDFT(1/2,0) of such a symmetrized signal is
SDFT
/
1 2 0
0
2
1
1
2
2
1 2
2
2
2
/ ,
exp
cos


a
N
a
i
k
N
r
N
a
k
k
k
N
k
{ }=
+



=
=
−
∑
π
π k
N
r
k
N
+




=
−
∑
1 2
0
1
/
.
	
(4.93)
In this way, we arrive at the DCT defined for signal {ak} of N samples as
	
α
π
r
k
k
N
N
a
k
N
r
DCT
/
=
+




=
−
∑
2
2
1 2
0
1
cos
.
	
(4.94)
As one can see directly from Equation 4.94, the DCT signal spectrum is an 
odd (antisymmetric) sequence if regarded outside its base interval [0, N − 1]:
	
α
α
α
r
N r
N
DCT
DCT
= −
=
−
2
0
;
	
(4.95)
while the signal is, by the definition (Equation 4.92), perfectly symmetric 
(even) on interval [0, 2, N – 1]:
	
a
a
k
N
k
=
−−
2
1. 	
(4.96)
From the above derivation of the DCT, it also follows that, for the DCT, 
signals are regarded as periodical with a period 2N:
	
a
a
k
k
N
=
( )mod
.
2
	
(4.97)
The inverse DCT can be found as the inverse SDFT(1/2,0) of spectrum with 
an odd symmetry of Equation 4.95 (see Appendix):
	
a
N
k
N
r
k
r
r
N
=
+
+












=
−
∑
1
2
2
1 2
0
1
1
α
α
π
DCT
DCT
/
cos
.
	
(4.98)
The invertibility of DCT implies that DCT is an orthogonal transform, and, 
therefore, it satisfies Parseval’s relationship:

163
Discrete Signal Transformations
	
ak
k
N
r
r
N
2
0
1
2
0
1
=
−
=
−
∑
∑
=
(
)
αDCT
.
	
(4.99)
Coefficient α0
DCT is, similarly to the case of DFT, proportional to the signal 
dc-component:
	
α0
0
1
2
1
DCT =






=
−
∑
N
N
ak
k
N
.
	
(4.100)
Coefficient
	
α
π
N
k
k
k
N
N
a
k
N
−
=
−
=
−
+




∑
1
0
1
2
2
1
1 2
DCT
/
(
) sin
	
(4.101)
represents the signal’s highest frequency. This equation is similar to that 
for DFT (Equation 4.81) except that signal is multiplied by an “apodization” 
function {sin (π((k + 1/2)/N))}.
The DCT was introduced by Ahmed et al. [1]. It has proved to have a very 
good energy compaction capability and is very frequently considered as an 
approximation to Karhunen–Loeve transform. From the above derivation, 
it becomes clear that the good energy compaction capability of the DCT can 
be attributed to the fact that the DCT is SDFT(1/2, 0) of a signal that is evenly 
extended (Equation 4.92). This way of signal extension eliminates potential 
signal discontinuities at the signal borders and in this way the need in high-
frequency spectral components to reproduce them. Figure 4.10 illustrates a 
better energy compaction capability of DCT spectra with respect to that of 
DFT for a test piece-wise constant image. Plots in Figure 4.10b show energy 
of DFT and DCT spectral coefficients as functions of a fraction (from 0 to 1) 
of the signal base band. One can see from the plots that the same fraction of 
DCT spectral coefficients contains a higher fraction of the total signal energy 
than that of DFT coefficients.
Being a derivative of SDFTs, DCT can, in principle, be computed using FFT 
with the same computational complexity of 1/2,0 operations per each of N 
signal coefficients. There exist dedicated fast transform algorithms of FFT 
type for computing DCT.
The removal of discontinuities at signal borders and computational effi-
ciency make the DCT attractive in many image processing applications such 
as image compression (see the section “Basics of Image Data Compression”), 
image resampling (see Chapter 6), and image perfection and enhancement 
(see Chapter 8) that involve processing in transform domain. DCT is also a 
prefect substitute of DFT for the implementation of signal digital convolution 
with the use of fast transforms. This application will be discussed later in the 
next section.

164
Theoretical Foundations of Digital Imaging Using MATLAB®
The DCT has its complement sine transform, the discrete cosine–sine trans-
form (DcST):
	
α
π
r
k
k
N
N
a
k
N
r
DcST
/
=
+




=
−
∑
2
2
1 2
0
1
sin
.
	
(4.102)
As shown in Appendix, the DcST is an imaginary part of the SDFT(1/2,0) 
of a signal
	
a
a
k
N
a
k
N N
N
k
k
N k
=
=
−
−
=
+
−



−−
,
, ,...,
,
,
,...,
0 1
1
1
2
1
2
1
	
(4.103)
extended to the interval [0, 2N − 1] in an odd (antisymmetric) way:
     
1
2
1 2
2
2
1 2
0
2
1
i
N
a
k
N
r
N
a
k
N
r
k
k
N
k
k
 exp
sin
π
π
+



=
+




=
−
=
∑
/
/
0
1
N−
∑
.
	
(4.104)
From the definition of DcST, it follows that the DcST spectrum exhibits 
even symmetry when being regarded in the interval [0, 2N − 1]:
	
α
α
r
N r
DcST
DcST
=
−
2
	
(4.105)
and that it assumes periodical replication, with a period 2N, of the signal 
complemented with its antisymmetrical copy
	


a
a
k
k
N
=
( )mod
.
2
	
(4.106)
Fraction of signal energy
0.8
0.6
0.4
0.2
0
0.2
0.4
Bandwidth (in fraction of the base band)
0.6
0.8
DFT
DCT
1
(a)
(b)
FIGURE 4.10
A test image (a) and energy of its 2D DFT and DCT spectra as functions of fraction of image 
base band (b).

165
Discrete Signal Transformations
In distinction from the DFT and the DCT, the DcST does not contain a 
signal dc-component:
	
α0
0
DcST =
	
(4.107)
and the inverse DcST
	
a
N
k
N
r
k
N
r
r
N
=
+
+












=
−
∑
1
2
2
1 2
1
1
α
α
π
DcST
DcST
/
sin
	
(4.108)
involves spectral coefficients with indices {1, 2, . . ., N} rather than {0, 1, . . ., 
N − 1} for the DCT.
Direct and inverse DcSTs can be computed through DCT if one changes 
the ordering of the transform coefficient to a reverse one:
	
α
π
π
N r
k
k
N
k
N
a
k
N
r
N
N
a
k
−
=
−
=
+
−




=
+
∑
DcST
/
2
2
1 2
2
2
0
1
sin
(
)(
)
sin[ (
1 2
1 2
1 2
1 2
0
1
/
/
/
/
)]cos
cos[ (
)]sin
π
π
π
k
N
r
k
k
N
r
k
N
+







−
+
+
=
−
∑







=
−
+




=
−
∑
2
2
1
1 2
0
1
N
a
k
N
r
k
k
k
N
(
)
cos π
/
	
(4.109)
	
a
N
k
N
r
N
k
N
N r
r
N
=
+
+
−








−
=
−
∑
1
2
2
1 2
1
1
α
α
π
DcST
DcST
/
sin
(
)(
) 

=
+
−
+








−
=
−
∑
1
2
2
1
1 2
1
1
N
k
N
r
N
k
N r
r
N
α
α
π
DcST
DcST
/
(
)
cos

.
	
(4.110)
2D and multidimensional DCTs and DSTs are defined as separable to 1D 
transforms on each of the indices. For instance, 2D DCT of a signal {ak,l}, k = 0, 
1, . . ., N1 − 1, l = 0, 1, . . ., N2 − 1 is defined as
	
α
π
π
r s
k l
l
N
k
N
N N
a
k
N
r
l
,
, cos
cos
DCT
/
=
+




+
=
−
=
−
∑
∑
2
1 2
1
1
2
1
0
1
0
1
2
1
/2
2
N
s




	
(4.111)
that corresponds to fourfold image symmetry illustrated in Figure 4.11.

166
Theoretical Foundations of Digital Imaging Using MATLAB®
Signal Convolution in the DCT Domain
In this section, we will show that applying DFT convolution theorem to 
­signals extended to double length by means of mirror reflection from their 
borders translates to convolution in the DCT domain.
Let signal {
}
ak  be obtained from signal {ak} of N samples by its extension 
by means of mirror reflection and periodical replication of the result with a 
period of 2N samples:
	
a
a
k
N
a
k
N N
N
k
N
k
N k
( )mod
,
, ...,
,
,
, ...,
2
2
1
0
1
1
2
1
=
=
−
=
+
−



−−
, 1
 
 
	
(4.112)
and let {
}
hn  be a convolution kernel {hn} of N samples (n = 0, 1, . . ., N − 1) zero-
padded to the length 2N.
	
h
n
N
h
n
N
N
N
n
n
N
=
=

−
= 


+
−
−

0
0
2
1
2
2
2
,
,...,
,
,...,
/
/
/
/
1
0
2
2
1
,
,
,...,
N
N
N
/

+
−



	
(4.113)
where ⌊N/2⌋ is an integer part of N/2. Then, the first N samples of cyclic 
convolution
FIGURE 4.11
Fourfold image symmetry.

167
Discrete Signal Transformations
	
b
h a
k
N
n
k n
N
N
n
N
( )mod
(
)mod
2
2
2
0
2
1
=
−+
=
−
∑ 


/
	
(4.114)
can be used for computing digital convolution, in which boundary effects 
characteristic for cyclic convolution are absent, thanks to the signal-mirrored 
extension as it was illustrated in Figure 4.3.
Consider computing the convolution of such signals by means of inverse 
DFT of the product of signal and convolution kernel DFT spectra. The DFT 
spectrum of the extended signal {
}
ak  is
	


α
π
π
r
k
k
N
k
k
N
a
i
kr
N
N
a
k
N
r
=




=
+




=
−
∑
1
2
2
2
2
2
1 2
0
2
1
exp
cos
/
=
−
∑






−




=
−




0
1
2
2
N
r
i
r
N
i
r
N
exp
exp
,
π
α
π
(DCT)
	
(4.115)
where αr
(DCT) is DCT coefficients of the initial signal {ak}. Therefore, the DFT 
spectrum of the signal extended by the “mirror reflection” can be computed 
via DCT using the fast DCT algorithm.
For computing convolution, the signal spectrum defined by Equation 4.115 
should be multiplied by DFT coefficients of the zero-padded convolution 
kernel:
	


η
π
r
n
n
N
N
h
i
nr
N
=




=
−
∑
1
2
2
2
0
2
1
exp
	
(4.116)
and then the inverse DFT of the product should be computed for the first N 
samples:
	
b
N
i
r
N
i
kr
N
k
r
r
r
N
=
−




−




=
=
−
∑
1
2
2
2
2
1
0
2
1
α
π
η
π
(DCT) exp
exp

2
2
1 2
2
0
2
1
N
i
k
N
r
r
r
r
N
α
η
π
(DCT)
/
 exp
.
−
+




=
−
∑
	
(4.117)

168
Theoretical Foundations of Digital Imaging Using MATLAB®
Splitting the sum in Equation 4.117 into two addends and changing 
the index r of summation in the second addend to 2N − r, obtain (see 
Appendix):
	
b
N
i
k
N
r
N
k
r
r
r
N
r
=
−
+




=
(
)
=
−
(
)
∑
1
2
2
1 2
2
1
2
0
2
1
α
η
π
α
η
DCT
DCT
/


exp
r
r
N
N r
N r
i
k
N
r
i
exp
exp
(
)
−
+



−



=
−
−
−
∑
2
1 2
2
2
0
1
2
2
π
α
η
π
/
DCT 
k
N
r
r
N
+




=∑
1 2
2
1
/
.
	
(4.118)
From the properties of DFT and DCT spectra (Equations 4.71 and 4.95), 
it follows that αN
DCT = 0 ; α
α
r
N r
DCT
DCT
= −
−
2
, and {
}


η
η
r
N
r
=
−
∗
2
. Using them in 
Equation 4.118, obtain
	
b
N
i
k
N
r
k
r
r
r
N
r
=
−
+



+



=
−
∑
1
2
2
1 2
2
0
1
α
η
π
α
(DCT)
(DCT)
/


exp
η
π
α
η
α
η
r
r
N
r
r
i
k
N
r
N
∗
=
−
+




=
+
∑
exp
2
1 2
2
1
2
2
1
1
0
0
0
/
(DCT)
(DCT)

 e
r
N
r
r
im
r
N
k
N
r
k
=
−
=
−
∑
∑
+







−
+
1
1
1
1
1 2
2
cos
sin
π
α
η
π
/
(DCT)
1 2
/
N
r







.
	
(4.119)
The first two terms of this expression represent inverse DCT of the 
product {
}
α
η
r
r
re
DCT
(
)
, while the third term is the discrete cosine/sine trans-
form (DcST) of the product {
}
α
η
r
r
im
DCT
(
)
. As shown in the section “Discrete 
Cosine and Sine Transforms” (Equation 4.110), inverse DcST can be con-
verted into DCT by means of changing the summation index r in DcST 
by N − r:
	
α
η
π
α
N r
N r
im
r
N
k
N r
k
N
r
N
−
−
=
−
−
+
−



= −
∑
(DCT)
(D
/

sin
(
)(
)
(
)
1 2
1
1
1
CT)
/
η
π
N r
im
r
N
k
N
r
−
=
−
+




∑
cos
.
1 2
1
1
	
(4.120)
Substitute this expression into Equation 4.119 and obtain the final formula 
for computing, through DCT, digital convolution with substantially reduced 
boundary effects:

169
Discrete Signal Transformations
	
b
N
k
N
r
k
r
r
re
r
N
=
+
+







=
−
∑
1
2
2
1 2
0
0
1
1
α
η
α
η
π
(DCT)
(DCT)
/


cos

−
−
+







−
−
=
−
∑
2
1
1 2
1
1
(
)
cos
.
k
N r
N r
im
r
N
k
N
r
α
η
π
(DCT)
/

	
(4.121)
The MATLAB programs conv_evenextension_demo_CRC and dct_vs_dft_
conv_demo_CRC.m provided in Exercises illustrate the principle of signal 
convolution in the DCT domain and compare border effects in the imple-
mentations of digital convolution in DFT and DCT domains.
DFTs and Discrete Frequency Response of Digital Filter
In this section, we will show that frequency responses of digital filters, which 
are their main characteristic, can be expressed through DFT coefficients of 
their PSFs. Consider the continuous frequency response (Equation 4.25) of a 
digital filter defined by its DPSF {hn}:
	
CFR f
h
i
f x n
u
n
x
s
n
N
( )
exp
.
( )
=
+
(
)


=
−
∑
2
0
1
π ∆
	
(4.122)
Let {
}
( , )
ηr
u 0  be a set of SDFT(u,0) coefficients of the PSF {hn}:
	
h
i
n
u r
N
N
i
u r
n
r
u
x
r
N
r
u
x
=
−
+




=
−
=
−
∑η
π
η
π
( , )
( , )
exp
(
)
exp
0
0
1
0
2
1
2
N
i
nr
N
r
N








−




=
−
∑
exp
.
2
0
1
π
	
(4.123)
Then obtain (see Appendix)
CFR( )
exp
( )
f
N
i
f x
r
N n
f xu
u r
N
r
r
N
x
s
x
=
−




+
−





=
−
∑
1
2
0
1
η
π
∆
∆









∝
−








−
=
−
∑
n
N
r
N
f x
r
N
N
f x
0
1
η
π
π
sin
sin
∆
∆
r
N
i
u
N
f x
r
N
x
s








+
−








−
=
−
∑
0
1
2
1
2
exp
exp
( )
π
∆
×
i
u
N
r
N
x
2
1
2
π
+
−








	
(4.124)

170
Theoretical Foundations of Digital Imaging Using MATLAB®
or, with setting u
u
u
x
x
s
=
=
( )
CFR( )
exp
sincd
;
f
i
u
N
f x
r
N
N f x
r
N
r
=
+
−




−








−
η
π
2
1
2
∆
∆




=
−
∑
r
N
0
1
,
	
(4.125)
where sincd(·;·) is the discrete sinc-function defined by Equation 3.61 and the 
cardinal sampling relationship Δf = 1/NΔx between signal and its Fourier 
spectrum sampling intervals Δx and Δf is assumed.
Equation 4.125 implies that, at points f = r/NΔx = rΔf, r = 0, . . ., N − 1 
within one period of the periodicity of CFR(f), its values are proportional 
to SDFT(u,0) coefficients {ηr} of the filter PSF {hn}. Between these sampling 
points, CFR_DF(f) is interpolated from samples {ηr exp[−i2π(u + (N − 1/2)) 
(r/N)]} with the discrete sinc-interpolation function. The phase multi-
plier exp[−i2π(u + (N − 1/2)) (r/N)] affects only values of CFR(f) between 
its samples. It can be eliminated by the selection of shift parameters 
u
u
u
N
x
x
s
=
=
= −
−
(
)1 2
/ .
In what follows, we will neglect this influence, disregard the phase term 
exp(
)
( )
i
f xux
s
2π ∆
 of CFR(f) associated with the positioning of the signal sam-
pling grid with respect to signal coordinate system, assume using canonical 
DFT for the implementation of digital convolution, and call discrete Fourier 
transform coefficients {ηr} of the filter PSF {hn}
	
η
π
r
n
n
N
r
N
h
i
nr
N
=
=




=
−
∑
DFR( )
exp
1
2
0
1
	
(4.126)
discrete frequency response of the digital filter.
Figure 4.12 illustrates discrete and continuous frequency responses of a dig-
ital filter with PSF [−1, 1] that is frequently used for numerical differentiation. 
abs(DFR(f ))
1
0.8
0.6
0.4
0.2
0–0.5
–0.4
–0.3
–0.2
–0.1
0
f
0.1
0.2
0.3
0.4
FIGURE 4.12
Discrete (stems) and continuous (solid line) frequency responses of a digital filter that is fre-
quently used for numerical evaluation of signal derivatives.

171
Discrete Signal Transformations
The graph in the figure shows absolute value of the frequency response in 
the signal baseband [−1/2Δx ÷ 1/2Δx]; stems on the curve indicate samples 
{ηr} of the continuous frequency response, which represent the filter discrete 
frequency response.
In Chapter 6, we will show how the notion of digital filter discrete fre-
quency response can be used for the design of discrete filters, and, spe-
cifically, of perfect discrete interpolation, differentiation, and integration 
filters.
Discrete Representation of Fresnel Integral Transform
Canonical Discrete Fresnel Transform and Its Versions
In the section “Imaging in Transform Domain and Diffraction Integrals,” we 
introduced a Fresnel approximation to Kirchhoff integral that describes free 
space propagation of waves with wavelength λ over distance Z from plane 
(x, y) to plane (fx, fy) and introduced 2D integral Fresnel transform
     
α
π


 




f
f
a x y
i
x
f
y
f
x
x
y
x
y
,
,
exp
(
) =
(
)
−
−
(
) +
−
(
)






2
2
d dy
−∞
∞
−∞
∞
∫∫
	
(4.127)
as defined in dimensionless coordinates
 




x
x
Z
y
y
Z
f
f
Z
f
f
Z
x
x
y
y
=
=
=
=
λ
λ
λ
λ
,
,
,
.
and
	
(4.128)
Consider its 1D version
	
α
π
( )
( )exp[
(
) ]
.
f
a x
i
x
f
x
=
−
−
−∞
∞
∫
2 d
	
(4.129)
According to Equation 4.6, the discrete representation of the Fresnel trans-
form kernel exp[−iπ(x − f)2] is
h
i
x
f
x
k
u
f
r
v
f
x f
k r
r
x
s
f
,
( )
( )
exp[
(
) ]
[
(
)]
[
(
)
]
=
−
−
−
+
−
+
−∞
∞
−∫
π
φ
φ
2
∆
d d
∞
∞
−∞
∞
∫
∫
=
−
−
+
+
−
+
{
}
φ
π
φ
( )
( )
( )
exp
[
(
)
(
)
]
( )
s
x
f
r
f
f
i
x
f
k
u
x
r
v
f
x
d
d
∆
∆
2
x,
−∞
∞
∫
	
(4.130)

172
Theoretical Foundations of Digital Imaging Using MATLAB®
where, as before, φk
r( )( )⋅ and φr
s( )( )⋅ are signal reconstruction and spectrum 
sampling basis functions, k and r are integer indices of signal and its Fresnel 
spectrum samples, ux and vf are, respectively, shifts, in fractions of sampling 
intervals Δx and Δf, of signal and its spectrum samples with respect to the 
corresponding coordinate system.
Introduce, temporarily, a variable
	
s
k
u
x
r
v
f
kr
x
f
=
+
−
+
(
)
(
)
.
∆
∆
	
(4.131)
Then
 
h
f
f
i
x
f
s
x
x
i s
k r
s
rk
r
r
,
( )
( )
( )
exp[
(
) ]
( )
exp
=
−
−
+
=
−
−∞
∞
−∞
∞
∫
∫φ
π
φ
π
d
d
2
k
s
rk
r
f
i f
i
fs
f
x
i x
2
2
2
2
(
)
−
−
−∞
∞
∫φ
π
π
φ
π
( )exp(
)exp(
)
( )exp(
)ex
( )
d
×
p[
(
)]
exp
( )exp(
)
(
( )
( )
i
x f
s
x
i s
f
i f
f
rk
rk
s
r
2
2
2
π
π
φ
π
−
=
−(
)
−
−∞
∞
∫
d
Φ
−
−∞
∞
∫
s
i
fs
f
rk
rk
)exp(
)
,
2π
d
	
(4.132)
where
	
Φ( )
( )
( )
( )exp(
)exp(
)
r
r
f
x
i x
i
xf
x
=
−
−∞
∞
∫φ
π
π
2
2
d
	
(4.133)
is the Fourier transform of signal reconstruction basis function ϕ(r) (x) modu-
lated by a chirp-function. For ϕ(r) (x) is a function more or less compactly con-
centrated around point x = 0 in an interval of about Δx, exp(−iπx2) ≅ 1 within 
this interval and one can regard Φ( )( )
r
f  as an approximation to frequency 
response of a hypothetical signal reconstruction device assumed in the sig-
nal discrete representation. With similar reservations as those made for dis-
crete representation of Fourier integral, for discrete representation of Fresnel 
integral, only the term
	
h
i s
i
k
u
x
r
v
f
k r
rk
x
f
,
exp
exp
[(
)
(
)
]
=
−(
) =
−
+
−
+
{
}
π
π
2
2
∆
∆
	
(4.134)
of Equation 4.132 is used.

173
Discrete Signal Transformations
To complete the derivation, introduce dimensionless variables
	
µ = (
)
∆
∆
x
f
/
/
1 2
	
(4.135)
and
	
w
u
v
x
f
=
−
µ
µ
/ . 	
(4.136)
At this point, one should choose a relationship between sampling intervals 
Δx and Δf in signal and Fresnel transform domains.
One of the options is to choose the same relationship (Equation 4.33) that 
was used for DFT:
	
∆∆
x f
N
= 1/σ
, 	
(4.137)
where σ is a scale parameter. Another option will be discussed later in the 
section “Convolutional Discrete Fresnel and Angular Spectrum Propagation 
Transforms.” With the choice of Equation 4.137, obtain
	
h
i
k
u
x
r
v
f
i
k
u
x
r
v
k r
x
f
x
f
,
exp{
[(
)
(
)
] }
exp
[(
)
(
)
=
−
+
−
+
=
−
+
−
+
π
π
∆
∆
∆
∆
2
f
N x f
i
k
r
w
N
]
exp
(
)
2
2
σ
π
µ
µ
σ
∆∆






=
−
−
+




/

(4.138)
and the basic Equation 4.5 of digital filtering takes, for the representation of 
Fresnel transform, the form
	
α
π
µ
µ
σ
r
k
k
N
N
a
i
k
r
w
N
=
−
−
+




=
−
∑
1
2
0
1
exp
(
)
,
/
	
(4.139)
where multiplier 1/ N  is introduced, similar to DFTs, for normalization pur-
poses. We will refer to it as shifted scaled discrete Fresnel transform (ShScDFrT).
With an account for coordinate normalization (Equation 4.128) and the car-
dinal sampling relationship Δx = λZ/NΔf, parameter μ of ShScDFrT can be 
expressed as
	
µ
λ
λ
2
2
2
1
1
=
=
=
=
∆
∆
∆∆
∆
∆
x
f
Z
N f
f
Z
N f
N f .
	
(4.140)
This representation reveals the physical meaning of the parameter μ2 as 
the distance parameter in the Fresnel approximation of Kirchhof’s integral 

174
Theoretical Foundations of Digital Imaging Using MATLAB®
(Equation 2.42), given the wavelength λ, the number of wavefront samples N, 
and wavefront sampling interval Δf. Parameter w is a combined shift param-
eter of sampling grid shifts in signal and Fresnel transform domains.
When σ = 1 (the case of the cardinal sampling), we arrive at shifted discrete 
Fresnel transform (SDFrT):
	
α
π
µ
µ
r
k
k
N
N
a
i
k
r
w
N
=
−
−
+




=
−
∑
1
2
0
1
exp
(
)
.
/
	
(4.141)
Its special case for w = 0
	
α
π
µ
µ
r
k
k
N
N
a
i
k
r
N
=
−
−




=
−
∑
1
2
0
1
exp
(
)
/
	
(4.142)
is the canonical discrete Fresnel transform (CDFrT).
SDFrT (μ,w) is quite obviously connected with SDFT(0, −wμ):
	
α
π
µ
π
µ
r
k
k
N
N
a
i
k
N
i
k r
w
N
=
−










−





=
−
∑
1
2
2
2
0
1
exp
exp
(
)





−
−




exp
(
)
i
r
w
N
π
µ
µ
2
2

(4.143)
and can be computed through it as SDFT(0, −wμ) of the chirp-modulated 
signal with subsequent chirp-demodulation of the result. This computing 
method can, in particular, be used for numerical reconstruction of holo-
grams recorded in a near diffraction zone. We will discuss the subject later 
in Chapter 5 (the section “Digital Image Formation by Means of Numerical 
Reconstruction of Holograms”). In this application, it is called the Fourier 
reconstruction algorithm.
From the relationship (Equation 4.143), one can conclude that SDFrT is 
invertible and that inverse SDFrT is defined as
	
a
N
i
k
r
w
N
k
r
w
r
N
=
−
+




=
−
∑
1
2
0
1
α
π
µ
µ
µ
( ,
) exp
(
)
.
/
	
(4.144)
Because shift parameter w is a combination of shifts in signal and spec-
tral domains, shift in the signal domain causes a corresponding shift in the 
transform domain, which, however, depends on the distance parameter μ 
according to Equation 4.136. One can break this interdependence if, in the 
definition of the discrete representation of integral Fresnel transform, a sym-
metry condition is imposed:
	
α
α
r
N
r
=
−	
(4.145)

175
Discrete Signal Transformations
of the transform
	
α
π
µ
r
i
r
w
N
=
−
−




exp
(
)
/
2
	
(4.146)
of a point source δ(k). This symmetry condition is satisfied when
	
w
N
= 2µ 	
(4.147)
and SDFrT for such shift parameter takes the form
	
α
π
µ
µ
r
k
k
N
N
a
i
k
r
N
N
=
−
−
−






=
−
∑
1
2
2
0
1
exp
[
(
)
]
.
/ /
	
(4.148)
The transform defined by Equation 4.148 allows keeping position of objects 
reconstructed from Fresnel holograms invariant to distance. We will call this 
version of the discrete Fresnel transform focal plane invariant discrete Fresnel 
transform (FPIDFrT). We will illustrate the use of FPIDFrT later in the section 
“Numerical Algorithms for Hologram Reconstruction,” when discussing 
algorithms for numerical reconstruction of holograms.
Invertibility of Discrete Fresnel Transforms and frincd-Function
As it was already mentioned, the invertibility of the SDFrT follows immedi-
ately from its connection with SDFT (Equation 4.143). In order to perfectly 
invert SDFrT, one should know focusing and shift parameters μ,w of the 
direct SDFrT. In real applications, such as numerical reconstruction of holo-
grams (see Chapter 5), these parameters are not necessarily exactly known. 
Therefore, it is very instructive to verify what signal will be reconstructed 
from the DFrT spectrum of a signal using inverse DFrT with focusing and shift 
parameters other than those used in direct DFrT (“out-of-focus restoration”).
If, for a discrete signal {ak}, k = 0, 1, . . ., N − 1, one computes its SDFrT 
­spectrum with parameters (μ+, w+) and then inverses SDFrT with parameters 
(μ−, w−) of the result of the direct transform, the following restored signal will 
be obtained (see Appendix):
	
a
N
N
a
i
n
r
w
N
k
w
n
n
N
(
,
)
exp
(
)
µ
π
µ
µ
±
± =
−
−
+









+
+
+
=
−
∑
1
1
2
0
1
/

−
+




=
−
−
−
−
∑
r
N
i
k
r
w
N
0
1
2
× exp
(
)
π
µ
µ
/
	

176
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
+




−
+




−
−
+
+
exp
(
)
exp
(
)
frincd(
; ;
i
k
w
N
a
i
n
w
N
N q k
n
π
µ
π
µ
2
2
−
−
±
=
−
∑
n
w
n
N
),
0
1

(4.149)
where
	
q
w
w
w
=
−
=
−
+
−
±
+
+
−
−
1
1
2
2
µ
µ
µ
µ
;
	
(4.150)
and frincd(N; q; k − n − w±) is a frincd-function defined as
	
frincd(
; ; )
exp
exp
.
N q x
N
i
q
N r
i
xr
N
r
N
=




−




=
−
∑
1
2
2
0
1
π
π
	
(4.151)
Frincd-function is an analog of sincd-function of the DFT and is identical 
to it, to the accuracy of an unessential phase factor, when q = 0:
	
frincd(
; , )
exp
exp(
)
exp
N
x
N
i
xr
N
N
i
x
r
N
0
1
2
1
2
1
0
1
=
−



=
−
−
−
=
−
∑
π
π
i
x
N
x
N
x
N
i
N
N
x
2
1
1
π
π
π
π



−
=




−
−



=
sin(
)
sin
exp
sincd(
;
)exp
.
N
x
i
N
N
x
π
π
−
−




1

(4.152)
Therefore, when q = 0 (μ+ = μ−), and w± = 0 (w+ = w−) from Equation 4.149, 
perfect signal restoration is achieved:
   
a
i
k
w
N
a
i
n
w
N
k
n
n
N
=
−
+




+




=
−
∑
exp
(
)
exp
(
)
sincd[
π
µ
π
µ
2
2
0
1
×
N
k
n
i
N
N
k
n
i
k
w
N
a
i
n
; (
)]exp
(
)
exp
(
)
exp
π
π
π
µ
π
−
−
−




=
−
+




1
2
(
)
(
)
.
n
w
N
k
n
a
n
N
k
µ
δ
+




−
=
=
−
∑
2
0
1
	
(4.153)
From Equation 4.151, one can see that frincd-function is a periodical func-
tion with a period of N samples:
	
frincd(
; , )
frincd(
; ,( )
)
mod
N q x
N q x
N
=
	
(4.154)

177
Discrete Signal Transformations
and that
	
(frincd(
; , ))
frincd(
;
,
).
N q x
N
q N
x
∗=
−
−
	
(4.155)
Figure 4.13 illustrates the behavior of frincd-function for different values of 
the focusing parameter q. As one can see from the plots, the absolute value of 
frincd-function has the shape of a rectangular impulse with oscillations on 
the borders and of width of about qN samples.
Figure 4.14 presents the frincd-function for focusing parameter q in 
the range (0–2) as an image, in which columns are frincd-function values 
shown in gray scale as functions of the sample index r. The image vividly 
abs(frincd(256;q;x))
1.0
0.8
0.6
0.4
0.2
0
25
50
75
100
125
k = x/Δx
150
175
200
225
250
q = 0
q = 0.02
q = 0.08
q = 0.18q = 0.32 q = 0.5
q = 0.72 q = 0.98
FIGURE 4.13
Plots of absolute values of function frincd(N;q;x) for N = 256 and different values of “focus-
ing” parameter q. (The function is shown centered around the middle point of the range of its 
argument.)
50
100
k = x/Δx
150
200
250
0.25
0.5
0.75
1
q
1.25
1.5
2
FIGURE 4.14
Frincd-function frincd(256; q; x/Δx) presented as an image (black is 0, white is 1) for 0 ≤ q ≤ 2.

178
Theoretical Foundations of Digital Imaging Using MATLAB®
demonstrates that beginning q = 1, frincd-function dramatically changes 
its behavior with rise of q. As we will see later in Chapter 5 (the section 
“Numerical Algorithms for Hologram Reconstruction”), this is a manifesta-
tion of appearance of the aliasing phenomenon.
According to the definition (Equation 4.151), frincd-function is the DFT of 
the chirp-function.
DFT is a discrete representation of integral Fourier transform, for which 
the following relationship between chirp-function and its Fourier transform 
holds (see the derivation of Equation 2.57 in Appendix to Chapter 2):
	
exp(
)exp(
)
exp
.
i
f
i
fx
f
i
i
x
πσ
π
σ
π σ
2
2
2
2
2
−
=
−




−∞
∞
∫
d
	
(4.156)
Therefore, one can expect that function frincd(N; q; r) and chirp-functions 
are also linked by an approximative relationship:
	
frincd(
; ; )
exp
exp
N q k
N
i
qr
N
i
rk
N
i
Nq
r
N
=




−



≅
=
−
∑
1
2
2
0
1
π
π
exp −




i
k
qN
π
2

(4.157)
obtained from Equation 4.59 by replacements: f = rΔf; x = kΔx; ΔxΔf = 1/N; 
σ2 = qN. However, taking into account the rectangular shape of the amplitude 
of the frincd-function, this can be true only within the effective width (1 − q)
N/2 ÷ (1 + q)N/2 of the frincd-function, where most of its energy is concen-
trated. Figure 4.15 shows plots of absolute values and the phase of the ratio 
of the left and right parts of Equation 4.60 (ratio of frincd-function and chirp-
function) for different q, which clearly demonstrate that a chirp-­function is 
a reasonable approximation to the frincd-function within the index interval 
[(1 − q)N/2 ÷ (1 + q)N/2], and that even within this approximation interval, 
noticeable distinctions between them remain in the form of oscillations at 
the borders of this interval.
Convolutional Discrete Fresnel and Angular Spectrum Propagation 
Transforms
The cardinal sampling relationship ΔxΔf = 1/N (or ΔxΔf = λZ/N in physical, 
not normalized, units) put in the base of the derivation of the above versions 
of discrete Fresnel transforms is relevant for the far diffraction zone. When 
distance parameter μ2 = Δx/Δf = λZ/NΔf2 is <1, the phase of the chirp-func-
tion exp[−iπ((kμ − r/μ + w)2/N)] involved in the definition of DFrT (Equation 
4.141) is changing, for cardinal sampling, too fast with index r, which causes 
aliasing artifacts. This motivates choosing for μ2 ≤ 1 an alternative sampling 
convention:

179
Discrete Signal Transformations
1.5
1
0.5
0
–0.5
–1
–1.5
0
50
100
150
200
250
300
350
400
450
500
Amplit. error
Approx. interval
Phase error
Approx. interval
Phase(Frincd&Chirp); Boundaries: (1 – q)*(N – 1)/2:(1 + q)*N/2
0
0
1
0.8
Amplit. error
Approx. interval
abs(Frincd&Chirp); Boundaries (1 – q)*N/2:(1 + q)*N/2;q = 0.25; N = 512
(a)
(b)
(c)
0.6
0.4
0.2
50
100
150
200
250
300
350
400
450
500
0
1
0.8
0.6
0.4
0.2
0
50
100
150
200
250
300
350
400
450
500
abs(Frincd&Chirp); Boundaries (1 – q)*N/2:(1 + q)*N/2; q = 0.5; N = 512
1.5
1
0.5
0
–0.5
–1
–1.5
Approx. interval
Phase error
Phase(Frincd&Chirp); Boundaries: (1 – q)*(N – 1)/2:(1 + q)*N/2
0
(d)
50
100
150
200
250
300
350
400
450
500
FIGURE 4.15
Amplitudes (a, c, e, g) and phases (b, d, f, h) of the error of approximation of chirp-function by 
frincd-function for q = 0.25 (a, b); 0.5 (c, d); 0.75 (e, f); 0.99(g, h).

180
Theoretical Foundations of Digital Imaging Using MATLAB®
1.5
1
0.5
0
–0.5
–1
–1.5
Amplit. error
Approx. interval
Approx. interval
Phase error
Phase(Frincd&Chirp); Boundaries: (1 – q)*(N – 1)/2:(1 + q)*N/2
0
1
0.8
abs(Frincd&Chirp); Boundaries (1 – q)*N/2:(1 + q)*N/2; q = 0.75; N = 512
(e)
(f)
0.6
0.4
0.2
0
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
Amplit. error
Approx. interval
Approx. interval
Phase error
Phase(Frincd&Chirp); Boundaries: (1 – q)*(N – 1)/2:(1 + q)*N/2
0
abs(Frincd&Chirp); Boundaries (1 – q)*N/2:(1 + q)*N/2; q = 0.99; N = 512
0
1
0.8
0.6
0.4
0.2
0
1
1.2
(g)
(h)
0.8
0.6
0.4
0.2
50
100
150
200
250
300
350
400
450
500
0
50
100
150
200
250
300
350
400
450
500
FIGURE 4.15
Continued.

181
Discrete Signal Transformations
	
∆
∆
x
f
=
, 	
(4.158)
which obviously must hold on the object plane (Z = 0; μ2 = 0). Then obtain 
for hk r, :
     
h
i
k
u
x
r
v
f
i
k
r
w
f
k r
x
f
,
exp
(
)
(
)
exp
(
)
=
−
+
−
+


{
}
=
−
−
+


π
π
∆
∆
∆
2
2
2
=
−
−
+




exp
(
)
,
i
k
r
w
N
π
µ
2
2
	
(4.159)
where
	
w
u
v
x
f
=
−
. 	
(4.160)
This kernel defines a transform:
	
α
π
µ
r
k
k
N
N
a
i
k
r
w
N
=
−
−
−




=
−
∑
1
2
2
0
1
exp
(
)
,
	
(4.161)
which we call convolutional discrete Fresnel transform (ConvDFrT) since it rep-
resents a digital convolution of signals with a chirp-function.
Yet another modification of the near zone diffraction integral transform 
introduced in the section “Imaging Systems and Integral Transforms” in 
Chapter 2 is the angular spectrum propagation transform (Equation 2.56), 
which in original physical coordinates can be written as
	
α
π
πλ
π
Fr f
a x
i
px
x
i
Zp
i
fp
( )
( )exp(
)
exp(
)exp(
=






−
−∞
∞
∫
2
2
2
d
)
.
dp
−∞
∞
∫
	
(4.162)
In the discretization of this transform, the following assumptions are made:
• The Fourier transform integral over x is replaced by DFT over a set of 
N signal samples {ak} at sampling points 

k x k
k
ux
∆
=
+
(
)
	
a x
i
px
x
a
i
ks
N
k
k
N
( )exp(
)
exp
2
2
0
1
π
π
d
−∞
∞
=
−
∫
∑
⇒





• Chirp-function exp(iπλZp2) is replaced by its samples exp[iπλZ 
(sΔx)2], where {s} are sample indices and Δx is the signal sampling 
interval.

182
Theoretical Foundations of Digital Imaging Using MATLAB®
• λZ is replaced by its expression through parameter μ2 = λZ/NΔf2and 
cardinal relationship Δx = 1/NΔf between sampling intervals in sig-
nal and Fourier transform domains is applied, by virtue of which
	
exp[
(
) ]
exp[
(
) ]
exp
i
Z s x
i
N f
s x
i
s
N
πλ
πµ
π µ
∆
∆
∆
2
2
2
2
2 2
=
=




• Inverse Fourier transform integral over p is replaced by inverse DFT 
over index s.
As a result, the discrete angular spectrum propagation transform (DASPT) is 
obtained:
	
α
π
π µ
r
k
k
N
N
a
i
ks
N
i
s
N
=
















−
=
−
∑
1
2
0
1
2 2
exp
exp
exp

i
rs
N
N
a
i
s
N
i
r
k
w
N
s
s
N
k
2
1
2
0
1
2 2
π
π µ
π





=




−
−
−


=
−
∑
exp
exp










=
−
=
−
∑
∑
s
N
k
N
0
1
0
1
,
	
(4.163)
or
	
α
µ
r
k
k
N
a
N
r
k
w
=
−
−
=
−
∑
frincd(
;
;
),
2
0
1
	
(4.164)
where w = ux − vf and frincd(⋅;⋅;⋅) is the frincd-function defined by Equation 4.151.
DASPT, similar to DFTs and SDFrTs, is an orthogonal transform with 
inverse DASPT defined as
	
a
N
i
k
r
w
N
s
i
s
N
k
r
r
N
=
−
−
+












−




=
−
∑
1
2
0
1
2 2
α
π
π µ
exp
exp

=
−
+
=
−
∗
=
−
∑
∑
s
N
r
r
N
N
k
r
w
0
1
2
0
1
α
µ
frincd (
;
;
).
	
(4.165)
When μ2 = 0 (which means Z = 0) and w = 0, DASPT reduces to the identical 
transform: in this case, the object plane and the transform planes coincide.
Two-Dimensional Discrete Fresnel Transforms
2D and, generally, multidimensional discrete Fresnel transforms are usually 
defined as separable transforms over each of the coordinate indices in the 
assumption of signal and its Fresnel spectrum sampling over rectangular 
sampling grids. Table 4.1 summarizes the 2D discrete Fresnel transforms.

183
Discrete Signal Transformations
TABLE 4.1
2D Discrete Fresnel Transforms
2D canonical DFrT
α
π
µ
µ
r s
k r
k
N
l
N
N N
a
i
k
r
N
,
, exp
e
=
−
−
(
)








=
−
=
−
∑
∑
1
1
2
1
1
2
1
0
1
0
1
1
2
/
xp −
−
(
)








i
l
s
N
π
µ
µ
2
2
2
2
/
2D-shifted and -scaled DFrT
α
π
µ
µ
σ
r s
k l
k
N
l
N
N N
a
i
k
r
w
N
,
, exp
(
)
=
−
−
+




=
−
=
−
∑
1
1
2
1
1
1
2
1
1
0
1
0
1
2
/
1
2
2
2
2
2
2
∑
−
−
+




exp
(
)
i
l
s
w
N
π
µ
µ
σ
/
2D focal plane invariant DFrT
α
π
µ
µ
r s
k l
k
N
l
N N
a
i
k
r
N
N
,
, exp
(
) /
=
−
−
−
[
]






=
−
= ∑
1
2
1
2
1
1
2
0
1
1
/
0
1
2
2
2
2
2
2
N
i
l
s
N
N
−
∑
−
−
−
[
]






exp
(
)
π
µ
µ
/ /
2D convolutional DFrT
α
π
µ
r s
k l
k
N
l
N
N N
a
i
k
r
w
N
,
, exp
(
)
ex
=
−
−
−




=
−
=
−
∑
∑
1
1
2
1
2
1
2
1
0
1
0
1
1
2
p
(
)
−
−
−




i
l
s
w
N
π
µ
2
2
2
2
2
2D DASPT
α
µ
µ
r s
k l
k
N
a
N
k
r
w
N
l
s
w
,
, frincd
;
;
frincd
;
;
=
−
+
(
)
−
+
(
)
=
−
1
1
2
1
2
2
2
2
0
1
1∑
∑
=
−
l
N
0
1
2

184
Theoretical Foundations of Digital Imaging Using MATLAB®
Discrete Representation of Kirchhoff Integral
Using the above-described transform discretization principles and assum-
ing, as in the case of the convolutional Fresnel transform, identical sampling 
intervals Δx and Δf of the signal and its transform, one can obtain the follow-
ing discrete representations of 2D Kirchhoff integral (Equation 2.40):
	
αr s
k l
l
N
k
N
a KRT
k
r l
s
,
,
(
)
;
,
=
−
−
(
)
=
−
=
−
∑
∑
2D
0
1
0
1

 

	
(4.166)
where    
k r l s
, ; ,  are shifted indices (as in Equation 4.44),
	
KRS
/
/
/
2D




z
m n
i
z
m
z
n
z
N
m
,
(
)(
, )
exp
µ
π
µ
=
+
+
(
)
(
)




+
2
1
1
2
2
2
2
2
2
2
2
2
2
/
/


z
n
z
+
;
	
(4.167)
	


z
Z
f
Z
N f
z
N f
=
=
=
/∆
∆
∆
;
.
µ
λ
λ
2
2
	
(4.168)
We refer to this transform as the 2D discrete Kirchhoff transform (DKT). 
When z →0, DKT degenerates into the identical transform. When z →∞, 
DKT reduces to discrete Fresnel transform. In distinction to 2D DFTs and 
DFrTs, 2D DKT is an inseparable transform.
As one can see from Equation 4.166, DKT is a digital convolution. Therefore, 
it can be computed through DFT using FFT as
	
{
}
IFFT FFT[{
}] FFT
,
.
,
,
α
⋅
r =
(
)


{
}
a
n m
k l
z
D
KRS  µ
2
	
(4.169)
From this representation, the inverse DKT can be computed as
	


a
z
D
k
r
n
{ } =








IFFT FFT{
}
FFT
( )
,
,
α
µ
⋅
1
2
KRS
	
(4.170)
where FFT[⋅] is the operator of DFT implemented through FFT and ⋅ is the 
element-wise product of elements of arrays.
Hadamard, Walsh, and Wavelet Transforms
The above-described discrete Fourier and Fresnel transforms originated 
from corresponding imaging integral transforms. In this section, we consider 

185
Discrete Signal Transformations
digital transforms that represent important tools of computational imaging, 
though they do not have direct natural analogs.
Binary Transforms
Basis functions of DFT and DCT transforms are sinusoidal functions that 
assume values in the range [−1 ÷ 1]. Computation of their transform coef-
ficients involves multiplication operations that are usually more time con-
suming than operations of addition. This motivated search for transforms 
with binary basis functions that assume only two values and due to this do 
not require multiplication operations for computing transform coefficients. 
In the section “Sampling Artifacts: Quantitative Analysis,” we already intro-
duced notions of Walsh and Haar transforms, whose basis functions are 
binary functions. Now, we continue the discussion on these transforms and 
provide additional insight into their origin and properties.
Hadamard and Walsh Transforms
Let the number of signal samples N be an integer power n of 2: N = 2n. 
Represent signal and transform domain indices k and r on base 2 through 
their binary digits {km} and {rm}, m = 0, 1, . . ., n − 1:
	
k
k
r
r
m
m
m
n
m
m
m
n
=
=
=
−
=
−
∑
∑
2
2
0
1
0
1
,
	
(4.171)
and consider n-dimensional DFT of a signal {
}
{
}
{
}
a
a
k
km
=
 over binary indices 
{km}. Because binary indices assume only two values, 0 and 1, the number of 
samples in each of the n dimensions is equal to 2, and n-dimensional DFT of 
signal {
}
{
}
{
}
a
a
k
km
=
 will take the form
	
α
α
π
r
r
n
k
k
k
m m
m
n
m
n
n
m
a
i
k r
=
=
∑



−
−
=
=
=
−
∑
∑
{
}
{
}
...
exp
1
2
2
2
2
1
0
1
0
1
0
1

=


=
=
=
∑
∑
∑
−
−
=
−
k
n
k
k
k
k r
n
n
m
m m
m
n
a
i
0
2
1
0
1
0
1
0
1
0
1
1
2
...
exp(
)
{
}
π
∑
=
=
=
∑
=
∑
∑
∑
∑
=
−
−
−
=
−
k
n
k
k
k
k r
k
n
n
m
m m
m
n
a
0
2
1
0
1
0
0
1
0
1
0
1
0
1
1
2
1
...
(
)
.
{
}
	
(4.172)
In this way, we arrive at the transform
	
αr
n
k
k
k
k r
k
n
n
m
m m
m
n
a
=
−
−
−
=
−
=
=
∑
∑
∑
∑
1
2
1
2
1
0
1
0
0
1
0
1
1
...
(
)
{
}
	
(4.173)

186
Theoretical Foundations of Digital Imaging Using MATLAB®
called the Hadamard transform. According to the definition of the Hadamard 
transform, 1D Hadamard transform is an n-dimensional DFT over two sam-
ples in each dimension. From this, it follows that inverse Hadamard trans-
form is identical to the direct one.
The 1D Hadamard transform is, obviously, separable over its n-dimensions:
	
αr
n
k
r
k
r
k
k
k
k r
n
n
n
n
n
n
m
a
=
−
−
−
−
−
−
−
−
=
=
∑
∑
1
2
1
1
1
1
2
2
2
1
0 0
0
1
0
1
(
)
(
)
...
{
}
k0
1
∑
.
	
(4.174)
Owing to this, its computation can be decomposed into n stages with N 
addition/subtraction operates per stage. Thus, the total computational com-
plexity of the transform is Nn = N log2 N operations or log2 N operations 
per transform coefficient. This method of computing Hadamard transform 
is called the fast Hadamard transform algorithm.
The basis functions of Hadamard transform
	
φk
k r
k r
m
n
r
m m
m
n
m m
( )
(
)
(
)
= −
=
−
=
−
∑
=
−
∏
1
1
0
1
0
1
	
(4.175)
are ordered in the same way as exponential basis functions of DFT are: 
according to the natural ascending order of their index. As we already indi-
cated and demonstrated in section “Typical basis functions and classifica-
tion” (Chapter 3), sequency-wise ordering of basis functions of Hadamard 
transform according to their gray code better corresponds to the principle 
of ordering according to transform coefficients’ energy. The transform 
with such ordering of the basis functions, called Walsh transform or Walsh–
Hadamard transform
	
αr
n
k
k
k
k r
k
n
n
m
m mGC
m
n
a
=
−
−
−
=
−
=
=
∑
=
∑
∑
∑
1
2
1
2
1
0
1
0
0
1
0
1
0
1
...
(
)
{
}
	
(4.176)
can also be computed using fast Hadamard transform algorithm, though it 
must be complemented with permutation of transform coefficients according 
to their gray code ordering. Similarly to Hadamard transform, inverse Walsh 
transform is identical to the direct one.
Haar Transform
As it was indicated in the section “Sampling Artifacts: Quantitative Analysis,” 
Haar transform basis functions are generated by windowing periodical 
binary sign-alternating functions (Rademacher functions) taken at dyadic 

187
Discrete Signal Transformations
(integer power of 2) scales with a shifted rectangular impulse function, whose 
extent and dyadic shift intervals are coordinated with the scale. A formal 
definition of discrete Haar basis functions can be derived from Equation 3.95:
	
har r
r
k
k
msb
k
msb
msb
n
msb
( )
(
)
( )mod
,
=
−
−







−−
−
2
1
2
2
1
1
δ
	
(4.177)
with msb as the index of the most significant nonzero digit (bit) in binary 
representation of r (Equation 4.171), (r) mod 2msb being modulo 2msb value 
of r, a residual from division of r by 2msb and ⎣ k/2n−msb⎦ being an integer part 
of k/2n−msb. Table 4.2 provides examples of msb, (r)mod 2msb
, and k/2n−msb for 
k = 0, 1, ..., 7.
Plots of first eight Haar functions are shown in Figure 3.8. From the figure, 
one can see that Haar functions of N = 2n samples form n groups in scale 
(index msb) and that nonzero fragments of functions within each group are 
generated by a coordinate shift with a shift interval specific for each scale. 
Correspondingly, computing Haar transform can be decomposed into n scale 
groups. Computation in the k-th group involves 2n−k addition/subtraction oper-
ations, thus resulting in total ∑
=
∑
=
−
−
=
=
−
−
=
−
−
−
−
k
n
n k
n
k
n
k
n
n
0
1
0
1
1
2
2
2
2
2
1
2
1
((
) (
))
/
 
2
1
(
)
N −
 addition/subtraction operations. Such a method of computing Haar 
transform is called fast Haar transform algorithm. Fast Walsh, fast Hadamard, 
and fast Haar transform algorithms are special cases a large class of fast trans-
form algorithms, to which belong fast Fourier and fast cosine transforms.
Discrete Wavelet Transforms and Multiresolution Analysis
As already mentioned in the section “Sampling Artifacts: Quantitative 
Analysis,” Haar transform is a representative of a large family of transforms 
called wavelet transforms, whose basis functions are built on the principle of 
combining scaling and shifting of a mother function. The design principle 
of discrete wavelet transforms can be explained using a signal flow diagram 
shown in Figure 4.16 for dyadic wavelets, in which scales and shifts change as 
integer powers of 2.
TABLE 4.2
Examples of msb, (r)mod 2msb and k/2n−msb in Binary Representation of Numbers
k
0
1
2
3
4
5
6
7
Binary Code
000
001
010
011
100
101
110
111
msb
0
0
1
2
(r)mod 2msb
–
–
0 
1
00 
01
10
11
k/2n−msb; msb = 1
0
0
0
0
1
1
1
1
k/2n−msb; msb = 2
00
00
01
01
10
10
11
11

188
Theoretical Foundations of Digital Imaging Using MATLAB®
According to this diagram, direct and inverse wavelet transforms consist 
of several scale levels. The maximal number of levels for signals of N = 2n 
samples is n = log2 N. On each scale level s, s = 1,. . .,n of the direct transform 
of a signal {ak}, signal {
}
(
)
ak
s−1 , (k = 0, 1, . . ., 2n−s+1) from the previous level (for 
the very first level {
})
( )
a
a
k
k
0 =
 is subjected to low-pass filtering
	
a
LP a
k
s
n
s
k
n
s
n
Nh
s
( )
( )
(
)
( )
,
=
−
−
=
−
∑
1
0
1
	
(4.178)
where Nh
s( ) is the number of samples of the low-pass filter PSF LPn
s( )
{
}. The 
resulting signal ak
s( ) is downsampled two times to the half the number of 
samples producing a downsampled signal 

a
a
k
s
k
s
( )
( )
=
2 , (k = 0, 1, . . ., 2n−s −1), 
which serves as input for the next level. This downsampled signal ak
s( ) is also 
upsampled (interpolated) back to the full length
	


a
a
k
s
k
n
s
n
s
n
N
s
( )
( )
(
)
=
−
−
=
−
−−
∑INT
2
1
0
2
1
1
	
(4.179)
Direct transform
Scale level 1
Scale level 2
Last scale level
Last scale
level
Scale level 2
Low-pass
filtering
Low-pass
filtering
Low-pass
filtering
Downsampling
Upsampling
(interpolation)
Upsampling
(interpolation)
Upsampling
(interpolation)
Upsampling
(interpolation)
2
2
2
2
2
2
2
2
2
Downsampling
Downsampling
Upsampling
(interpolation)
Upsampling
(interpolation)
Inverse transform
Scale level 1
Input
Input
Input
Input
Output
Output
Output
Output
+
+
+
+
+
+
+
+
+
–
–
FIGURE 4.16
Flow diagrams of direct and inverse discrete wavelet transforms.

189
Discrete Signal Transformations
with an interpolation kernel INTk
s( )
{
} and subtracted from the input signal 
of this level ak
s(
)
−
{
}
1
 to produce the difference signal d
a
a
k
s
k
s
k
s
=
−
{
}
−


(
)
( )
1
 which 
serves, for all levels except for the very last one, as the output signal of the 
level. At the last n-th level, the level output signal is the downsampled sig-
nal ak
n
(
)
−1 . Thus, the result of the transform is a set of n − 1 difference signals 
dk
s
{ }, obtained at scale levels s = 1, 2, . . ., n − 1 and a downsampled signal 
ak
n
(
)
−1  obtained at the last scale level. As a result of the successive downsam-
plings, these signals have different resolutions with respect to the initial sig-
nal, from full resolution, for level s = 1, to lower resolution for higher scales. 
This is why this type of signal decomposition is frequently called multiresolu-
tion analysis and the result of the decomposition is called image pyramid. It is 
illustrated in Figure 4.17.
Although the maximal number of scales is n = log2 N, the described sig-
nal decomposition does not necessarily perform up to this level; it can be 
stopped at any intermediate stage.
The inverse transform shown in the right part of the flow diagram in Figure 
4.16 consists of successive upsampling (interpolation) of the output signals of 
FIGURE 4.17
Image multiresolution decomposition (image pyramid).

190
Theoretical Foundations of Digital Imaging Using MATLAB®
corresponding scale levels beginning from the last one and to the level s = 1 
and adding the results to the output of the previous level. The interpolation 
is performed using the same interpolation kernel INTk
s( )
{
} that is used on the 
corresponding scale level of the direct transform.
Low-pass filtering PSFs LPn
s( )
{
} and interpolation kernels INTk
s( )
{
} deter-
mine the type of the wavelet transform. Many different types of wavelet 
transforms designed and tested for different applications are known at 
present.
Wavelet transforms being linear transforms can be treated in terms of sig-
nal DFT spectra. In these terms, they perform signal “sub-band” decompo-
sition: according to the convolution theorem, signal DFT spectrum, at each 
scale level, is multiplied by the frequency response of the high-pass filter, 
Signal sub-band decomposition; N = 128; scale level 1
1
(a)
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
10
20
30
Scale level 2
40
50
60
10
20
30
Scale level 3
40
50
60
10
20
30
Scale level 4
40
50
60
10
20
30
Scale level 5
40
50
60
10
20
30
Scale level 6
40
50
60
10
20
30
Scale level 7
40
50
60
10
20
30
Frequency index
40
50
60
FIGURE 4.18
An illustrative example of dyadic wavelet sub-band decomposition using a trapezoidal fre-
quency response of the high-pass filter for signals of N = 128 samples (a) and sub-bands that 
correspond to Haar transform (b) for the same number of signal samples.

191
Discrete Signal Transformations
which complements the low-pass filter at this scale and extracts the signal’s 
corresponding sub-band. According to the definition of dyadic wavelets, 
bandwidth of the sub-band of scale s is proportional to N/2s. Figure 4.18a 
illustrates this process for signals with N = 128 using, as an example, high-
pass filters with a trapezoidal frequency response. Figure 4.18b presents 
for comparison sub-bands that correspond to Haar transform for the same 
number of signal samples. Note that for Haar transform, low-pass filtering 
PSF LPn
s( )
{
} and interpolation kernels INTk
s( )
{
} are on each scale rectangular 
impulses of two samples [1,1].
The computational complexity of wavelet transforms can be evaluated as 
follows. At scale level s, low-pass filtered and interpolated are Ns = 2n−s signal 
samples. Let low-pass filtering and interpolation require NLP and NLP multipli-
cation/addition operations per sample, respectively. Then the total number of 
Haar wavelet sub-bands; N = 128; Scale level 1
1
(b)
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
10
20
30
Scale level 2
40
50
60
10
20
30
40
50
60
10
20
30
40
50
60
10
20
30
40
50
60
10
20
30
40
50
60
10
20
30
40
50
60
10
20
30
40
50
60
Scale level 3
Scale level 4
Scale level 5
Scale level 6
Scale level 7
Frequency index
FIGURE 4.18
Continued.

192
Theoretical Foundations of Digital Imaging Using MATLAB®
operations is (
)
(
)(
)
N
N
N
N
N
LP
INT
s
n
n s
LP
INT
+
∑
=
+
−
=
−
−
0
1 2
2
1
 
, which amounts 
to O(NLP + NINT) operations per signal sample no matter how many samples 
the signal contains. Compare this with O(n = log2 N) operations per sample 
of signal of N samples required for transforms, such as DFT and Walsh–
Hadamard transforms that feature “FFT-type” algorithms such as the above-
described fast Hadamard transform.
Discrete Sliding Window Transforms and “Time-Frequency” 
Signal Representation
All the described transforms can be applied “globally” to the entire set of 
available signal samples or “locally” to individual signal fragments. In the 
latter case, the signal is split into nonoverlapping or overlapping fragments, 
and transformation is performed over each fragment individually. When 
transforms are applied to signal fragments within windows that overlap to 
such a degree that their central samples (pixels) are adjacent in the process 
of signal (image) scanning over the sampling grid, “sliding window” transform 
domain processing takes place.
Consider, for the sake of simplicity, the 1D case. Sliding window appli-
cation of transforms to fragment {
}
ak n
Nw
−+

/2
 of signal {ak} centered at the 
signal k-th sample, where ⎣ ⋅ ⎦ is an integer part of the argument, can math-
ematically be described as
	
α
φ
r
k
n
k
n
N
r
n
N
w a
n
w
w
( )
( ),
=
−+

=
−
∑
2
0
1
	
(4.180)
where {wn} are weight coefficients of a window function, which extracts signal 
fragments of Nw samples and weight them, and {ϕr(n)} are the transform basis 
functions. For 1D signals of N samples, a set of local transform coefficients 
αr
k
( )
{
} are 2D arrays of N × Nw samples. When signals are time sequences 
and their local Fourier analysis using DFT or DCT is performed, such signal 
representation is called the time-frequency representation. For 2D signals, slid-
ing window application of 2D DFT or DCT transforms produces their 4D 
space–space frequency representation.
Figures 4.19 and 4.20 illustrate the sliding window DCT domain “time-
frequency” representation of a test signal that consists of eight pieces of 
sinusoids with different frequencies (Figure 4.19) and of a fragment of a real 
speech signal (Figure 4.20).
In Figure 4.19b, one can clearly see bars, which indicate frequencies of the cor-
responding pieces of the signal. In Figure 4.20b, pieces of the signal with low and 
high frequencies and signatures of different sounds are easily distinguishable.

193
Discrete Signal Transformations
1
0.5
–0.5
100
200
300
400
Sample index
Test signal
(a)
(b)
Sample index
Frequency
Test signal: local DCT spectrum, WSZ = 32
500
600
700
800
900
1000
100
200
300
400
500
600
700
800
900
1000
–1
0
1
0
FIGURE 4.19
A test sinusoidal signal with eight fragments of different frequency (a) and its time-frequency 
representation by local DCT spectral analysis in sliding window of 32 samples (b). Intensities 
of spectral components are displayed in gray scale (dark—high intensity, bright—low inten-
sity). Frequencies are shown in the normalized scale from 0 (zero frequency) to 1 (the highest 
frequency of the base band). Note that high-frequency signal fragments are plotted in (a) with 
aliasing due to the limited resolving power of the printer.
Fragment of speech signal
Fragment of speech signal: local DCT spectrum, WSZ = 128
0.4
(a)
(b)
0.2
0
1
1000
2000
3000
4000
Sample index
5000
6000
7000
8000
1000
2000
3000
4000
Sample index
5000
6000
7000
8000
0
–0.2
–0.4
–0.6
Frequency
FIGURE 4.20
A fragment of a speech signal (a) and its time-frequency representation by local DCT spectral 
analysis in sliding window of 128 samples (b). Intensities of spectral components are displayed 
in gray scale (dark—high intensity, bright—low intensity). Frequencies are shown in the nor-
malized scale from 0 (zero frequency) to 1 (the highest frequency of the base band).

194
Theoretical Foundations of Digital Imaging Using MATLAB®
The sliding window transform domain signal representation finds many 
applications in digital image and video processing. Its use for local adaptive 
image and video denoising, deblurring, and enhancement is discussed in 
Chapter 8.
Similar to sliding window transforms of continuous signals treated in 
terms of their Fourier spectra (see the section “Transforms in Sliding Window 
(Windowed Transforms) and Signal Sub-band Decomposition,” in Chapter 2), 
local application of discrete transforms can also be regarded, in terms of sig-
nal DFT spectra, as signal sub-band decomposition. For fixed spectral index 
r, the set of signal local transform coefficients {
( )}
( )
α
φ
r
k
n
N
n k n
N
r
w
w
w a
n
= ∑=
−
−+

0
1
2
 
/
 
of signal {ak} of N samples in the k-th position of window are sequences of N 
samples. Consider their DFTs over index k:
Αs
r
r
k
k
N
n k n
N
r
n
N
i
ks
N
N
w a
n
w
( )
( ) exp
( )
=



=
=
−
−+

∑
1
2
1
0
1
2
α
π
φ
=
−
=
−
∑
∑












0
1
0
1
2
N
k
N
w
i
ks
N
exp
.
π

(4.181)
Let {As} be the DFT spectrum of the entire signal {ak}, such that
	
a
N
i
ks
N
k
s
s
N
=
−




=
−
∑
1
2
0
1
Α exp
.
π
	
(4.182)
Replace {
}
ak n
Nw
−+

/2
 in Equation 4.181 by its expression (Equation 4.182) 
through its DFT spectrum and obtain, as it is shown in Appendix, that
Αs
r
n
k
n
N
r
n
N
N
w a
n
i
ks
N
w
w
( )
( ) exp
=












−+

=
−
∑
1
2
2
0
1
/ φ
π
∝
=
−
∑
k
N
s
r
w s
0
1
Α Φ(
)( ),
	
(4.183)
where
	
Φr
w
w
n
r
n
N
s
N
w
n
i
n
N s
(
)( )
( )exp
=




=
−
∑
1
2
0
1
φ
π
	
(4.184)
is DFT spectrum of the r-th basis function weighted with window weight 
coefficients {wn}.
Equation 4.183 implies that the DFT spectrum, over index k, of the sequence 
of the r-th local spectral coefficients of signal {ak} is the signal DFT spectrum 
masked by the DFT spectrum of weighted r-th basis function, and, there-
fore, the sequence αr
k
( ), in terms of index k, of r-th local transform coefficients 

195
Discrete Signal Transformations
represents an r-th sub-band of the signal. In other words, the local application 
of transforms in a sliding window can be treated as signal sub-band decom-
position by means of band-pass filters with frequency responses defined by 
spectra of transform basis functions weighted by the sliding window weight 
coefficients. In this respect, it is akin to wavelet signal decomposition dis-
cussed in the previous section. The only difference between them is that 
in the sliding window transform domain processing, signal sub-bands are 
(b)
Normalized frequency
Normalized frequency
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
0.5
1
0
1
0.5
0
(a)
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
Walsh-8256; Bands 1–8
DCT-8256; Bands 1–8
FIGURE 4.21
Frequency responses of band-pass filters that correspond to sliding window DCT (a), Walsh 
(b), and Haar (c) (window size 8).

196
Theoretical Foundations of Digital Imaging Using MATLAB®
arranged uniformly over the frequency (transform coefficient index r) axis 
and all have the same “bandwidth,” while for wavelet decomposition signal 
sub-bands are arranged in a logarithmic scale with exponentially growing 
bandwidths.
Figure 4.21 shows, for comparison, frequency responses of band-pass fil-
ters that correspond to sliding window DCT, Walsh and Haar processing 
with uniform weight coefficients ({wn = 1}). Note that the very first band-pass 
filters in all cases are low-pass filters that compute signal local mean in the 
filter window.
Haar-8256; Bands 1–4
(c)
1
0.5
0
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0.2
0.4
Normalized frequency
0.6
0.8
1
1
0.5
0
1
0.5
0
1
0.5
0
FIGURE 4.21
Continued.

197
Discrete Signal Transformations
Appendix
Derivation of Equation 4.24
	
OFR
f, p
h
x
i
fx
p
x
eq
eq
n
N h
(
)
( , )exp
(
)
( )
=
−


=
−∞
∞
−∞
∞
=
−
∫∫
ξ
π
ξ
ξ
2
0
1
d d
∑
∑
∫∫
=
−
−∞
∞
−∞
∞
−
−
−
(
)




k
N
n
r
s
r
s
b
h
x
n x
k
n
x
0
1
φ
φ
ξ
( )
( )
( )
( )
(
)



∆
∆
× exp
(
)
i
fx
p
x
2π
ξ
ξ
−

d d
h
x
i
f x
k
x
p
n
n
N
k
N
s
r
r
h
b
=
−
=
−
∑
∑
+
(
)−
+
0
1
0
1
2
( )
( )
( )
( )
( )
( )
( )exp
ϕ
ξ ϕ
π

∆
ξ(
−
(
)




{
}
=
−∞
∞
−∞
∞
=
∫∫



k
n
x
x
h
i
pn
x
r
s
n
s
n
N
( )
( )
( )
exp(
)
∆
∆
d dξ
π
2
0
( )
exp
(
)
ex
( )
h
b
i
f
p k
x
r
k
N
−
=
−
∑
∑








−








×
1
0
1
2π

∆
p(
)
( )exp(
)
exp(
( )
i
fu
x
x
i
fx
x
i
pu
r
r
2
2
2
π
φ
π
π
∆
( )
−∞
∞
∫






×
−
d
r
s
x
i
p
( )
−∞
∞
−






∫
∆)
( )exp(
)
.
( )
φ
ξ
π ξ
ξ
2
d
Derivation of Equation 4.30
	
h
i
fx
x
k
f
r f
x f
f
k r
r
s
i
s
,
( )
( )
( )
exp(
)
(
)
(
)
( )
=
−
−
=
−∞
∞
−
∞
∫∫
2π
ϕ
ϕ
ϕ

∆
d d
df
i
f
r f
x
k x
x
x
i
kr x
r
exp
(
)(
)
( )
exp(
( )
2
2
π
ϕ
π
+
+
{
}
=
−∞
∞
−∞
∞
∫
∫



∆
∆
∆∆
d
f
f
i
fk x
f
i
f
r f x
x
x
s
s
)
( )exp(
)
exp
(
)
( )
( )
( )
ϕ
π
π
ϕ
2
2


∆
∆
d
d
+


−∞
∞
−
∫
∞
∞
−∞
∞
∫
=
+
exp(
)
(
)
( )exp(
)
( )
( )
i
kr x f
f
r f
f
i
fk x
f
r
s
2
2
π
φ
π



∆∆
Φ
∆
∆
d
∫
.

198
Theoretical Foundations of Digital Imaging Using MATLAB®
Reasonings Regarding Equation 4.31
The spectrum sampling function ϕ(s) (f) is a function compactly concentrated 
in an interval of about Δf around point f = 0. Within this interval, the fre-
quency response of the signal reconstruction device Φ
∆
( )(
)
r
f
r f
+ 
 can be 
approximated by a constant because it is a Fourier transform of the recon-
struction device PSF ϕ(r) (x), which is compactly concentrated around point 
x = 0 in an interval of about Δx. Then Equation 4.30c can be approximated as
	
Φ
∆
∆
∆
( )
( )
( )
(
)
( )exp(
)
( )exp{
r
s
s
f
r f
f
i
fk x
f
f
i
fk x
+
≅
−∞
∞
∫



φ
π
φ
π
2
2
d
}
(
),
( )
df
k x
s
−∞
∞
∫
= Φ
∆

where Φ(s) (•) is the frequency response of the spectrum sampling function 
ϕ(s) (f) that, in its turn and for the same reason of the compactness of ϕ(s) (f), 
can also be approximated by a constant for argument values k x
  .
Derivation of Equations 4.37 and 4.38
Denote k
k
ux
=
+
, n
n
ux
=
+
, and r
r
u f
=
+
. Then, for Equation 4.37, obtain
	
a
N
i
kr
N
N
a
i
nr
N
k
r
r
N
k
σ
σ
σ
α
π σ
σ
π σ
=
−



=



=
−
∑
1
2
1
2
0
1
exp
exp

 









−




=
=
−
=
−
∑
∑
n
N
r
N
k
i
kr
N
N
a
i
0
1
0
1
2
1
2
exp
exp
π σ
σ
π
σ

n
k
N r
N
a
i
n
k
N u
r
N
n
N
k
f
−












=
−

=
−
=
−
∑
∑


σ
σ
π σ
σ
0
1
0
1
1
2
exp


−
−
−
−
=
=
−
∑
exp[
(
)]
exp(
((
)
))
sin
i
n
k
i
n
k
N
N
a
n
N
n
2
1
2
1
1
0
1
π
π
σ
σ
π
/
(
)
sin( ((
)
)) exp
n
k
n
k
N
i
v
N
n
k
N
f
n
N
−


−

−




−




=
π
σ
π
σ
σ
/
1
2
0
−
=
∑
=
−

−




−




1
1
1
2
σ
σ
π
π
σ
σ
N
a
N
n
k
i
v
N
n
k
N
n
f
n
sincd[
; (
)]exp
0
1
0 1
1
0
1
1
N
na
k
N
k
N N
N
−
∑
=
=
−
=
=
−



,
, ,...,
,
,
,...,σ
as sincd[σN; π(n − k)] = δ(n − k) for k = 0,1,. . .,N − 1 and for k = N, N = 1,. . ., 
σ N  − 1, sin[π(n − k)] = 0 and sin π σ
n
k
N
−



≠0.

199
Discrete Signal Transformations
Principle of Fast Fourier Transform Algorithm
FFTs are algorithms for fast computation of the DFT. The principle of the 
FFT can be easily understood if one compares 1D and 2D DFT. Let an
( )
1
{
} and 
ak l,
( )
2
{
} be 1D and 2D arrays with the same number N = N1N2 of samples: n = 0, 
1, . . ., N1N2 − 1; k = 0, 1,.. ., N1 − 1; l = 0, 1, . . ., N2 − 1. Direct computing of the 
1D DFT of array an
( )
1
{
}
	
α
π
r
k
k
N
N
a
i
kr
N
=




=
−
∑
1
2
1
0
1
( ) exp
requires N
N N
2
1
2
2
2
=
 operations with complex numbers while computing the 
2D DFT of array ak l,
( )
2
{
}
	
α
π
r s
k l
l
N
k
N
N
a
i
kr
N
ls
N
,
,
( ) exp
=
+








=
=
−
=
−
∑
∑
1
2
2
1
2
0
1
0
1
2
1
1
2
2
1
2
0
1
0
1
2
1
N
i
kr
N
a
i
ls
N
n
l
N
k
N
exp
exp
π
π








=
−
=
−
∑
∑
requires only N N
N N
N N N
N
1
2
2
1
2
2
1
2
1
2
+
=
+
(
) operations thanks to the sepa-
rability of the 2D DFT to two 1D DFTs. Therefore, one can accelerate comput-
ing the DFT by representing it in a separable multidimensional form. One 
can do this if the size of the array is a composite number. Let, as in the above 
example, N = N1N2. Represent indices k and r of signal and its 1D transform 
samples as 2D ones:
	
k
k N
k
k
N
k
N
r
r N
r
r
=
+
=
−
=
−
=
+
=
2
1
1
1
1
2
2
1
2
2
1
0 1
1
0 1
1
0 1
;
, ,...,
;
, ,...,
;
;
, ,...,
;
, ,...,
.
N
r
N
1
2
2
1
0 1
1
−
=
−
Then, the 1D DFT can be split into two successive 1D DFTs:
	
α
α
π
r
r r
k
k
N
k
k
N
a
i
kr
N
N N
a
i
=
=




=
=
−
∑
1
2
1
2
1
2
1
1
0
1
1
2
1
,
( )
,
( )
exp
exp
2
1
2
2
1
1
1
2
2
2
1
0
1
0
1
1
1
2
2
π
π
(
)(
)
exp
k N
k
r N
r
N N
N
i
k
N
k
N
+
+




=
=
−
=
−
∑
∑
k r
N
i
k r
N N
a
i
k r
N
k
k
1 1
1
1 2
1
2
1
2 2
2
2
2
1
2











exp
exp
,
( )
π
π









=
−
=
−
∑
∑
k
N
k
N
2
2
1
1
0
1
0
1

200
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=




{
}






DFT
exp
DFT
,
( )
N
N
k
k
i
k r
N
a
1
2
1
2
2
1 2
1
π
⋅
over two subsets of N1 and N2 samples, which, as in the above example of 2D 
transform, require only N N
N N
N N N
N
1
2
2
1
2
2
1
2
1
2
+
=
+
(
) operations instead 
of N
N N
2
1
2
2
2
=
.
Obviously, the larger the number of factors of N, the higher is the dimen-
sionality to which 1D DFT can be decomposed in this way, and the higher 
is the computational complexity reduction. For n factors of N = N0 . N1, ..., 
Nn−1, the DFT can be computed with only N.(N0 + N1 + … + Nn−1) operations 
with complex numbers instead of N2 = N(N0 . N1, ..., Nn−1) operations required 
for the direct computation. For N = 2n, the computational complexity of the 
DFT is O(N log2 N). FFTs for signal size that is a power of 2 are called radix-2 
FFT. They are most widespread in the software packages for signal and image 
processing.
FFT algorithms are a special case of a broad class of fast transform algo-
rithms that have similar structure and whose computational complexity is 
O(N log N) or lower.
Representation of Scaled DFT as Convolution
Consider first the inverse scaled DFT defined by Equation 4.37. With denota-
tions k
k
ux
=
+
 and r
r
v f
=
+
, Equation 4.37 can be written as
	
α
σ
π
ν
σ
σ
ν σ
ν σ
N r
u
k
u
f
k
N
N
a
i
N
r
N
k
−
=
−
=
+
−




=
∑
( , ; )
( , ; ) exp
1
2
2
1
0
1
 
N
a
i
N
N
k
i
kr
N
k
u
f
k
N
( , ; ) exp
exp
ν σ
π
ν
σ
π σ
2
2
2
0
1
+




−




=
−
∑


=
−




+




−
exp
exp
exp
( , ; )
i
r
N
N
a
i
N
N
k
i
k
u v
f
2
2
2
2
2
π σ
σ
π
ν
σ
σ


π σ
π
σ



k
N
i
k
r
N
k
N
2
0
1
2
2











−









=
−
∑
exp
(
)



.
The sum in this equation is the digital convolution of the signal spectrum 
α
σ
r
u v
( , ; )
{
} modulated by a chirp-function exp(
(
))
−i
r
N
2
2
π
σ
 /
 and a complex con-
jugate to this function. In a similar way, direct scaled DFT defined by Equation 
4.36 can be, for spectral coefficient, taken in a reverse order, written as

201
Discrete Signal Transformations
α
σ
π
σ
σ
σ
N r
u v
k
u v
f
k
N
N
a
i
N
v
r
N
k
−
=
−
=
+
−




∑
( , ; )
( , ; ) exp
1
2
2
0
1
 
=
+




−




=
−
1
2
2
2
0
σ
π
σ
π σ
σ
N
a
i
N
v
N
k
i
kr
N
k
u v
f
k
N
( , ; ) exp
exp


1
2
2
2
2
∑
−
+




−
× exp(
(
))
exp
exp
( , ; )
i
r
N
N
a
i
N
v
N
k
i
k
u v
f
π
σ
σ
π
σ
σ


/
2
2
2
0
1
2
π σ
π
σ



k
N
i
k
r
N
r
N










−








=
−
∑
× exp
(
)




,
which is also a digital convolution of a modulated signal and a chirp-
function.
Derivation of Equation 4.53
In the derivation, we will use simplified definitions of SDFT as given by 
Equations 4.40 and 4.41.
	
a
N
i
rp
N
i
n
n
u p v q
r
u v
r
K
x
/
/
,
, exp
exp
=
−












−
=
−
∑
1
2
2
0
1
α
π
π (
)
exp
exp
(
)
r
q
N
N
N
a
i
kv
N
i
k
u r
N
v
k
f
k
N
x
+




=




+
=
−
∑
1
1
2
2
0
1
π
π










−




−
+

=
−
∑
r
K
x
f
i
rp
N
i
n r
q
N
0
1
2
2
× exp
exp
(
)
π
π



=
−




−
+
−




=
1
2
2
N
a
i
kv
nq
N
i
k
n
u
p r
N
k
f
f
x
x
r
exp
exp
(
)
π
π
0
1
0
1
1
2
2
K
k
N
k
f
f
x
x
N
a
i
kv
nq
N
i
k
n
u
p K
−
=
−
∑
∑
=
−




−
+
−
exp
exp[
(
)
π
π
/N
i
k
n
u
p
N
N
a
i K k
x
x
k
N
k
k
N
]
exp[
(
)
]
exp{((
[(
−
−
+
−
−
=
+
=
−
=
∑
∑
1
2
1
1
0
1
0
π
π
/
u
n
p
N
i K k
u
n
p
N
i
k
x
x
x
x
)
(
)])
)}
exp{ ((
[(
)
(
)])
)}
exp[
(((
−
+
−
−
+
−
+
/
/
π
π
+
−
+
−
−
+
−
+
×
−
u
n
p
N
i
k
u
n
p
N
i
K
N
k
x
x
x
x
)
(
))
)]
exp[
(((
)
(
))
)]
exp
[(
/
/
π
π
1
+
−
+


−




u
n
p
i
kv
nq
N
x
x
f
f
)
(
)] exp
2π

202
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−
+
−
−
+
−
a
K N
k
n
u
p
N
k
n
u
p
N
k
x
x
x
x
k
sin{ (
)[(
)
(
)]}
sin{ (([(
)
(
)])
)}
π
π
/
/
=∑
×
−
−
+
−




−




=
0
1
2
N
x
x
f
f
k
i
K
k
n
u
p
N
i
kv
nq
N
a
exp
(
)(
) exp
e
π
π
xp
sincd[
(
)]
i k K
N
2v
K;N; k
n
u
p
f
x
x
k
N
π
−
+








−
+
−


=
−
∑
1
0
1




×
−
−
+








−
−




exp
exp
(
)
i
K
N
q
n
i K
N
u
p
f
x
x
π
π
1
2
1
.
Derivation of Equations 4.58 and 4.60
By definition of SDFTs:
	
a
N
i
k
gN
u
r
v
N
N
i
k
gN
r
x
f
r
N
r
+
=
−
=
−
+
+
+




=
−
∑
1
2
1
2
0
1
α
π
α
π
exp
(
)(
)
exp
gN r
v
N
i
k
u
r
v
N
i
f
x
f
r
N
(
) exp
(
)(
)
exp(
+




−
+
+




=
−
=
−
∑
2
2
0
1
π
πgv
N
i
k
u
r
v
N
a
i
gv
f
r
x
f
r
N
k
f
)
exp
(
)(
)
exp(
).
α
π
π
−
+
+




=
−
=
−
∑
2
2
0
1
	
α
π
π
r
gN
k
x
f
k
Nc
k
N
a
i
k
u
r
gN
v
N
N
a
i
g
+
=
−
=
+
+
+




=
∑
1
2
1
2
0
1
exp
(
)(
)
exp
N k
u
N
i
k
u
r
v
N
i
gu
x
x
f
k
N
x
(
) exp
(
)(
)
exp(
+




+
+




=
=
−
∑
2
2
0
1
π
π
)
exp
(
)(
)
exp(
).
N
a
i
k
u
r
v
N
i
gu
k
x
f
k
N
r
x
2
2
0
1
π
α
π
+
+




=
=
−
∑

203
Discrete Signal Transformations
Derivation of Equation 4.63
Denoting 


k
k
u
k
k
u
k
k
u
a
x
a
b
x
b
c
x
c
=
+
=
+
=
+
;
;
; r
r
v
r
r
v r
a
f
a
b
f
b
c
=
+
=
+
=
;
 
r
v f
c
+
, obtain
	
c
N
i
k r
N
N
N
a
k
u v
r
u v
r
u v
c
c
r
N
n
c
c
a
a
b
b
,
=
−




=
=
−
∑
1
2
1
1
0
1
α
β
π
,
,
exp
 
exp
exp
,
i
n r
N
i
k r
N
a
a
n
N
r
u v
c
c
b
b
2
2
0
1
π
β
π
 
 










−
=
−
∑




=
−




=
−
=
∑
r
N
n
r
u v
a
a
c
c
r
N
N
a
N
i
n r
k r
N
b
b
0
1
0
1
1
2
β
π
,
exp
 
 
−
=
−
∑
∑






=


−

1
0
1
1
1
2
n
N
n
r
u v
a
f
a
c
N
a
N
i
n
r
v
k
r
v
b
b
β
π
,
exp


f
c
r
N
n
N
n
r
u v
N
N
a
N
i
b
b














=
=
−
=
−
∑
∑
0
1
0
1
1
1
2
β
π
,
exp


n
r
v
v
v
k
r
v
v
v
N
a
f
b
f
a
f
b
c
f
b
f
c
f
b
r
N


−

−


−











=
−
∑
0
1




=
−


−

−
=
−
∑
n
N
n
r
u v
c
f
b
f
c
f
b
a
N
a
N
i
k
r
v
v
v
n
r
b
b
0
1
1
1
2
β
π
,
exp




−














=
=
−
=
−
∑
∑
v
v
v
N
N
a
N
f
b
f
a
f
b
r
N
n
N
n
r
u
0
1
0
1
1
1
β
b
b
v
c
a
f
b
c
f
c
f
b
a
f
a
f
b
i
k
n
r
v
k
v
v
n
v
v
N
,
exp −
−

 


−

−
−





2π















=
−
−

=
−
=
−
∑
∑
r
N
n
N
n
r
u v
x
c
N
a
N
i
k
n
u
b
b
0
1
0
1
1
1
2
β
π
,
exp
−

 











−
−


=
−
=
−
∑
∑
u
r
v
N
i
k
v
v
x
a
f
b
r
N
n
N
c
f
c
f
b
0
1
0
1
2
 
exp
π

−
−








=
−
−










n
v
v
N
N
i
k
v
v
N
a
a
f
a
f
b
c
f
c
f
b
n
1
2
exp
ex
π
p
,
i
n
v
v
N
b
a
f
a
f
b
k n
n
N
2
0
1
π


−








−
=
−
∑
where
	
b
N
i
k
n
u
u
r
v
N
k n
r
u v
x
c
x
a
f
b
r
N
b
b
−
=
−
=
−
−
+
−
(
)
+
(
)








∑
1
2
0
1
β
π
,
exp
..

204
Theoretical Foundations of Digital Imaging Using MATLAB®
Derivation of Equation 4.65
b
N
i
m
u
u
r
v
N
N
m
r
u v
x
c
n
a
f
b
r
N
b
b
=
−
+
−
(
)
+
(
)








=
=
−
∑
1
2
1
1
0
1
β
π
,
exp
N
b
i
n
u
r
v
N
n
x
b
f
b
n
N
r
N
exp
2
0
1
0
1
π
+
(
)
+
(
)














=
−
=
−
∑
∑
× exp
exp
−
+
−
(
)
+
(
)








=
+
(
)
+
i
m
u
u
r
v
N
b
N
i
n
u
r
v
x
c
n
a
f
b
n
x
b
f
b
2
1
2
π
π
(
)








−
+
−
(
)
+
(
)











=
−
∑
N
i
m
u
u
r
v
N
r
N
x
c
n
a
f
b
0
1
2
exp
π



=
−
+
−
+
(
)
+
(
)








=
−
∑
n
N
n
x
b
x
c
n
a
f
b
r
b
N
i
n
m
u
u
u
N
r
v
0
1
1
2
exp
π
=
−
=
−
∑
∑






=
−
+
−
+
(
)




0
1
0
1
2
N
n
N
n
x
b
x
c
n
a
f
b
b
i
n
m
u
u
u
v
N
exp
π




−
+
−
+
(
)










=
−
=
−
∑
∑
n
N
x
b
x
c
n
a
r
N
N
i
n
m
u
u
u
N
r
0
1
0
1
1
2
×
exp
π




=
−
+
−
+
(
)








=
−
∑b
i
n
m
u
u
u
v
N
N
n
x
b
x
c
n
a
f
b
n
N
exp
ex
2
1
0
1
π
×
p
exp
i
n
m
u
u
u
i
n
m
u
u
u
N r
x
b
x
c
n
a
x
b
x
c
n
a
2
1
2
π
π
−
+
−
+
(
)

−
−
+
−
+
(
)
(
)


/

−






=
−
+
−
+
(
)








=
−
1
2
0
b
i
n
m
u
u
u
v
N
n
x
b
x
c
n
a
f
b
n
N
exp
π
1
1
∑
×
−
+
−
+
(
)

−
−
−
+
−
+
(
)

N
i
n
m
u
u
u
i
n
m
u
u
u
x
b
x
c
n
a
x
b
x
c
n
a
exp
exp
π
π

−
+
−
+
(
)
(
)



−
−
−
+
−
+
(
)
exp
exp
i
n
m
u
u
u
N r
i
n
m
u
u
u
x
b
x
c
n
a
x
b
x
c
n
a
π
π
/
N
r

























205
Discrete Signal Transformations
	
×
−
−
+
−
+
(
)




=
−
+
−
+
(
exp
exp
i
N
N
n
m
u
u
u
b
i
n
m
u
u
u
x
b
x
c
n
a
n
x
b
x
c
n
a
2
1
π
π
)
+
−
(
)








−
+
−
+
(
)


=
−
∑
2
1
0
1
v
N
N
n
m
u
u
u
N
f
b
n
N
x
b
x
c
n
a
×
sin
sin
π
π
π
n
m
u
u
u
N
b
i
n
m
u
u
u
v
N
x
b
x
c
n
a
n
x
b
x
c
n
a
f
b
−
+
−
+
(
)
(
)




=
−
+
−
+
(
)
+
/
exp
2
−
(
)








−
+
−
+
(
)


=
−
∑
1
0
1
N
N
n
m
u
u
u
n
N
x
b
x
c
n
a
× sincd
;
.
π
When v
N
f
b = −
−
(
)1 2
/ ,
	
b
b
N
n
m
u
u
u
m
n
x
b
x
c
n
a
n
N
=
−
+
−
+
(
)


=
−
∑
sincd
;
.
π
0
1
Derivation of Equation 4.68
Denoting 


k
k
u
k
k
u
k
k
u
a
x
a
b
x
b
c
x
c
=
+
=
+
=
+
;
;
;  r
r
v
r
r
v
a
f
a
b
f
b
=
+
=
+
;
;  
r
r
v
c
f
c
=
+
, obtain
	
c
N
i
k r
N
k
u
v
r
u
v
r
u
v
c
c
r
N
c
c
xa
f
a
b
b
,
,
,
exp
=
−




(
)
∗(
)
=
−
∑
1
2
0
1
α
β
π
 
=










−
=
−
∗(
)
∑
1
1
2
0
1
N
N
a
i
n r
N
n
a
a
n
N
r
u v
b
b
exp
exp
,
π
β
 
i
k r
N
N
a
N
i
n r
k
c
c
r
N
n
r
u v
a
a
c
b
b
2
1
1
2
0
1
π
β
π
 
 
 




=
−
=
−
∗(
)
∑
,
exp
r
N
N
a
N
i
k
c
r
N
n
N
n
r
u v
b
b










=
=
−
=
−
(
)
∑
∑
0
1
0
1
1
1
2
β
π
,
exp
c
f
c
a
f
a
r
N
n
N
r
v
n
r
v
N
N
a
	
(
) −
	
(
)












=
=
−
∗
=
−
∑
∑

0
1
0
1
1
n
r
u v
r
N
n
N
N
b
b
1
0
1
0
1
β
,
(
)
=
−
=
−
∑
∑




206
Theoretical Foundations of Digital Imaging Using MATLAB®
	
× exp i
k
r
v
v
v
n
r
v
v
v
N
c
f
b
f
c
f
b
a
f
b
f
a
f
b
2π


+
+
−
(
) −
+
+
−
(
)









∗
(
)
=
−
=
−
=



−
(
)
+
∑
∑
1
1
2
0
1
0
1
N
a
N
i
k
n
r
v
n
r
u
v
r
N
n
N
c
a
f
b
b
b
β
π
,
exp
×

 (
) +
−
(
) −
−
(
)











=
∗


k
v
v
n
v
v
N
N
a
N
c
f
c
f
b
a
f
a
f
b
n
r
u
v
b
b
1
1
β
,
(
)
=
−
=
−
−
+
−
(
)
+
(
)











×
∑
∑
exp i
k
n
u
u
r
v
N
x
c
x
a
f
b
r
N
n
N
2
0
1
0
1
π
exp
exp
i
k
v
v
n
v
v
N
N
i
c
f
c
f
b
a
f
a
f
b
2
1
2
π
π



−
(
) −
−
(
)









=
−
∗
k
v
v
N
a
i
n
v
v
N
b
c
f
c
f
b
n
a
f
a
f
b
n k
n
−
(
)






−
(
)






−
=
exp
2
0
π


N−
∑
1
,
where
	
b
N
i
m
u
u
r
v
N
m
r
u
v
x
c
x
a
f
b
r
N
b
b
=
−
−
+
(
)
+
(
)











=
−
∑
1
2
0
1
β
π
,
exp




=
+
(
)
+
(
)













∗
=
−
∑
; b
N
b
i
n
u
r
v
N
m
n
x
b
f
b
n
N
1
2
0
1
π

−
−
+
(
)
+
(
)














=
=
−
∗
∑
exp
i
m
u
u
r
v
N
N
x
c
x
a
f
b
r
N
2
1
0
1
π
b
i
m
u
u
n
u
r
v
N
n
n
N
x
c
x
a
x
b
f
b
r
N
=
−
=
−
∑
∑
−
+
−
−
(
)
+
(
)








=
0
1
0
1
2
1
exp
π
N
b
i
m
u
u
n
u
N
v
i
m
u
u
m
x
c
x
a
x
b
f
b
m
N
x
c
x
a
exp
exp
2
2
0
1
π
π
−
+
−
−
	
		
	
		
−
+
=
−
∑
	
−
−
	
		
	
		
=
−
∑
n
u
N
r
x
b
r
N
0
1

207
Discrete Signal Transformations
	
=
−
+
−
−




−
+
=
−
∑
1
2
2
0
1
N
b
i
m
u
u
n
u
N
v
i
m
u
u
m
x
c
x
a
x
b
f
b
m
N
x
c
x
exp
exp
π
π
×
a
x
b
x
c
x
a
x
b
m
n
u
i
m
u
u
n
u
N
b
i
m
−
−
(
)

−
−
+
−
−
(
)
(
)
(
)−
=
−
1
2
1
2
exp
exp
π
π
/
u
u
n
u
N
v
m
u
u
n
u
x
c
x
a
x
b
f
b
m
N
x
c
x
a
x
b
+
−
−







−
+
−
−
(
)
=
−
∑
0
1
×
sin π


−
+
−
−
(
)
(
)
(
)
×
−
−
+
−
−
N
m
u
u
n
u
N
i
N
N
m
u
u
n
u
x
c
x
a
x
b
x
c
x
a
x
b
sin
exp
π
π
/
1(
)

	

	
	
	
	
=
−
+
−
−
(
)


−
+
−
−
b
m
u
u
n
u
N
m
u
u
n
u
m
x
c
x
a
x
b
x
c
x
a
sin
sin
π
π
x
b
m
N
x
c
x
a
x
b
f
b
N
i
N
m
u
u
n
u
v
N
(
)
(
)
×
−
(
)
−
+
−
−
(
) +


	
	


	
	
=
−
∑
/
0
1
1
2
exp
π
.
Select v
N
f
b = −
−
(
)1 2
/ , and obtain
	
b
b
m
u
u
n
u
N
m
u
u
n
u
N
n k
m
x
c
x
a
x
b
x
c
x
a
x
b
−
=
−
+
−
−
(
)


−
+
−
−



sin
sin
π
π

=
−
+
−
+
(
)


=
−
=
−
∑
∑
m
N
m
x
c
x
a
x
b
m
N
b
N
n
m
u
u
u
0
1
0
1
sincd
;
.
π
Derivation of Equation 4.70
Given signal {ak} and its DFT spectrum {αr}, k,r = 0,1,. . .,N − 1:
	
a
N
i
kr
N
k
r
r
N
=
−




=
−
∑
1
2
0
1
α
π
exp

208
Theoretical Foundations of Digital Imaging Using MATLAB®
express reversed signal {aN−k} through its DFT spectrum:
	
a
N
i
N
k
N
r
N
i
k
N r
N
k
r
r
N
r
r
N
−
=
−
=
=
−
−



=




∑
1
2
1
2
0
1
0
α
π
α
π
exp
exp
−
−
=
−
−
∑
∑
=
−



=
−




1
0
1
1
2
1
2
N
i
N
r
N
k
N
i
kr
N
N
r
r
N
N
r
α
π
α
π
exp
exp
,
r
N
=
−
∑
0
1
which implies that the DFT spectrum of the reversed signal is the reversed 
spectrum {αN−r} of the initial signal. Furthermore,
	
a
N
i
kr
N
N
i
N
r
N
k
k
r
r
N
N r
r
*
*
*
exp
exp
=



=
−




=
−
−
=
∑
1
2
1
2
0
1
α
π
α
π
0
1
0
1
1
2
N
N r
r
N
N
i
kr
N
−
−
=
−
∑
∑
=
−




α
π
*
exp
,
which implies that signal complex conjugation converts its DFT spectrum 
{αr} into complex conjugated and reversed one αN r
−
{
}
*
.
Derivation of Equations 4.72 and 4.74
Let
	
a
N
i
k
r
N
k
r
r
N
=
−
+
+




(
)
=
−
∑
1
2
1 2
1 2
1 2 1 2
0
1
α
π
/
/
/
/
,
exp
(
)(
) .
Then
	
a
N
i
N
k
r
N
N
k
r
r
N
−−
=
−
=
−
−
−
+
+




1
1 2 1 2
0
1
1
2
1
1 2
1 2
α
π
(
,
) exp
(
)(
)
/
/
/
/
∑
∑
= −
+
+




= −
=
−
−
1
2
1 2
1 2
1
1 2 1 2
0
1
N
i
k
r
N
N
r
r
N
N
α
π
α
(
,
) exp
(
)(
)
/
/
/
/
1
1 2 1 2
0
1
1
2
1 2
1
1 2
1
−
=
−
−
+
−
−
+




=
∑
r
r
N
N
i
k
N
r
N
N
(
,
) exp
(
)(
)
/
/
/
/
π
α
−
=
−
−
+
(
)
+
(
)




∑
r
r
N
i
k
r
N
(
,
) exp
.
1 2 1 2
0
1
2
1 2
1 2
/
/
/
/
π

209
Discrete Signal Transformations
which implies that reversing the order of signal samples reverses the order of 
its SDFT(1/2, 1/2) spectral coefficients.
Accordingly
	
a
N
i
k
r
N
N
k
r
r
N
N
∗
∗
=
−
−
=
+
+




=
∑
1
2
1 2
1 2
1
1 2 1 2
0
1
α
π
α
(
,
) exp
(
)(
)
/
/
/
/
1
1 2 1 2
0
1
2
1 2
1
1 2
1
−
∗
=
−
−
+
−
−
+




=
∑
r
r
N
N
i
k
N
r
N
N
(
,
) exp
(
)(
)
/
/
/
/
π
α
1
1 2 1 2
2
1 2
2
1 2
1 2
−
∗
+
[
]
−
+
+




r
r
i
k
i
k
r
N
(
,
) exp
(
) exp
(
)(
)
/
/
/
/
/
π
π
=
−
−−
∗
∑
=
−(
)
−
+
+




0
1
1
1 2 1 2
1
2
1 2
1 2
N
N
r
N
i
k
r
N
.
exp
(
)(
)
(
,
)
α
π
/
/
/
/
r
N
=
−
∑
0
1
.
Derivation of Equation 4.75
For SDFT(u,0):
	
a
N
i
k
u
N
r
a
N
i
k
u
N
r
k
r
r
N
k
r
=
−
+




=
+




=
−
∑
1
2
1
2
0
1
α
π
α
π
exp
exp
*
*
r
N
N
r
r
N
N
r
N
i
k
u
N
N
r
N
i
=
−
−
=
−
−
∑
∑
=
+
−




=
0
1
0
1
1
2
1
2
α
π
α
*
*
exp
(
)
exp(
π
π
u
i
k
u
N
r
r
N
) exp


−
+




=
−
∑
2
0
1
from which Equation 4.75 follows.
Derivation of Equation 4.76
	
α
π ρ
ϕ
π
r
x
f
k
N
N
k
N
i
k
u
r
v
N
i
=
+




+
+




=
=
−
∑
1
2
2
0
1
cos
exp
(
)(
)
exp
2
2
2
0
1
π
π ρ
φ
π
r
v
N
u
N
k
N
i
r
v
N
k
f
x
f
k
N
+




+




+




=
−
∑cos
exp

210
Theoretical Foundations of Digital Imaging Using MATLAB®
=
+




+



+
−
−



exp
exp
exp
i
r
v
N
u
N
i
k
N
i
i
k
N
i
f
x
2
2
2
2
π
π ρ
φ
π ρ
φ




×
+




=
+




=
−
∑
k
N
f
f
x
i
r
v
N
k
i
r
v
N
u
N
0
1
2
2
2
exp
exp
e
π
π
xp
exp
exp
exp
i
i
k
N
i
r
v
N
k
i
f
k
N
φ
π ρ
π
( )




+







+
−
=
−
∑
2
2
0
1
φ
π ρ
π
π
(
)
−




+







=
=
−
∑exp
exp
exp
i
k
N
i
r
v
N
k
i
r
f
k
N
2
2
2
0
1
+




( )
+
+







+
=
−
∑
v
N
u
N
i
i
r
v
N
k
f
x
f
k
N
2
2
0
1
exp
exp
exp
φ
π
ρ
−(
)
−
+







=
+




=
−
∑
i
i
r
v
N
k
i
r
v
N
u
f
k
N
f
x
φ
π
ρ
π
exp
exp
2
2
0
1
2
2
1
2
1
N
i
i
r
v
N
N
i
r
v
N
f
f
exp
exp
exp
φ
π
ρ
π
ρ
( )
+
+



−
+
+



−






+
−(
)
−
+



−
−
+



−



exp
exp
exp
i
i
r
v
N
N
i
r
v
N
f
f
φ
π
ρ
π
ρ
2
1
2
1




=
+




×
+
+
−
−
+
+
exp
exp[
(
)]
exp[
(
i
r
v
N
u
N
i
r
v
i
r
v
f
x
f
f
2
2
π
π
ρ
π
ρ
)]
exp
exp
exp
(
)
i r
v
N
i r
v
N
i
N
N
r
v
f
f
f
π
ρ
π
ρ
π
ρ
+
+



−
−
+
+




−
+
+
1
+










+
−
+
−
−
−
+
−
i
i
r
v
i
r
v
i r
f
f
φ
π
ρ
π
ρ
π
ρ
exp[
(
)]
exp[
(
)]
exp
+



−
−
−
+




−
−
+
−





v
N
i r
v
N
i
N
N
r
v
i
f
f
f
exp
exp
(
)
π
ρ
π
ρ
φ
1






211
Discrete Signal Transformations
	
=
+




+
+
+
+




exp
sin[ (
)]
sin
exp
i
r
v
N
u
N
r
v
r
v
N
i
f
x
f
f
2
2
π
π
ρ
π
ρ
π N
N
r
v
i
r
v
r
v
N
f
f
f
−
+
+
+










+
−
+
−
+


1(
)
sin[ (
)]
sin
ρ
φ
π
ρ
π
ρ


−
−
+
−










=
+




exp
(
)
exp
i
N
N
r
v
i
N
i
r
v
N
u
f
f
x
π
ρ
φ
π
1
2
2

+
+
{
−
+
+
+










+
sincd[
; (
)]
exp
(
)(
)
si
N
r
v
i
N
r
v
N
f
f
π
ρ
π
ρ
φ

1
ncd[ (
)]exp
(
)(
)
.
π
ρ
π
ρ
φ
r
v
i
N
r
v
N
f
f
−
+
−
−
+
−













1
Derivation of Equation 4.85
	



a
LN
rect r
N
LN
N
i
kr
LN
k
r
N
=
−
−
+
−
−




−
1
1
1 2
1
2
(
)
exp
( )mod
/
α
π




=
−



+




=
−
=
−
∑
∑



r
LN
r
r
N
LN
i
kr
LN
0
1
0
1
2
1
2
α
π
exp
(
)/
α
π
( )mod
(
)/
exp



r
N
r LN
N
LN
i
kr
LN
LN
N
a
−








=
=
−
−
−
∑
2
1
1
1
2
1
n
n
N
r
N
i
nr
N
i
kr
LN
exp
exp
(
2
2
0
1
0
π
π















−




=
−
=
∑
−
=
−
∑
∑



+












−
1
2
0
1
1
2
2
)
exp
exp
/
N
a
i
nr
N
i
k
n
n
N
π
π

r
LN
N L
a
i
k
Ln
LN
r
r LN
N
LN
n







=
−
−


=
−
−


−
∑



1
2
1
1
2
/
exp
π









+
−
−




=
−
=
−
=
∑
∑




r
N
n
N
r
i
k
Ln
LN
r
0
1
2
0
1
2
(
)
exp
/
π
LN
N
LN
−
−
−
∑







(
)
1
2
1
/

212
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−
−
+





−
−
−



−
1
2
1
2
1
2
1
N L
a
i
k
Ln N
LN
i
k
Ln
LN
n
exp
(
)(
)
exp
π
π
















+
−
−





−
−
=
−
∑
n
N
i
LN k
Ln
LN
i
k
0
1
2
2
exp
(
)
exp
(
π
π

 −
−
−
(
)








−
−



−









Ln LN
N
LN
i
k
Ln
LN
)(
)
exp
1
2
2
1
/
π






=
−
−
+





−
−
−
−
1
2
1
2
2
N L
a
i
k
Ln N
LN
i
k
Ln N
n
exp
(
)(
)
exp
(
)(
π
π


1
2
2
1
1
0
1
)
exp
sin
LN
i
k
Ln
LN
L
a
N k
Ln
LN
n
N
n






−
−



−
=
−
=
−
∑
π
π






−






=
−
∑
N
k
Ln
LN
L
a
N; k nL
L
n
N
n
n
sin
sincd
(
)
2
1
0
1
π

-
/
=
−
∑
0
1
N
.
Rotated and Scaled DFTs as Digital Convolution
Equation 4.91 can be rewritten as follows:
	
α
σ
π
θ
θ
σ
θ
θ
σ
θ
r,s
k l
N
a
i
k
l
N
r
k
l
N
s
=
+
−
−



1
2
, exp
cos
sin
sin
cos















=
+
+
=
−
=
−
∑
∑
l
N
k
N
k l
N
a
i
kr
ls
N
l
0
1
0
1
1
2
σ
π
σ
θ
, exp
cos


r
ks
N
l
N
k
N
−












=
−
=
−
∑
∑

σ
θ
sin
.
0
1
0
1
Using in this equation identities
	
2
2
2
2
2
2
2
2












kr
ls
r
k
s
l
r
k
s
l
kr
ls
+
(
) =
+
−
−
−
−
(
) +
+
(
)
+
(
;
)
=
+
−
−
−
−
(
) +
+
(
)








r
k
s
l
r
k
s
l
2
2
2
2
2
2
,

213
Discrete Signal Transformations
obtain
	
α
σ
π
σ
θ
σ
θ
θ
r,s
k l
N
a
i
kr
ls
N
lr
ks
N
=
+
+
−






1
2
, exp
cos
sin










=
+
−
−
−
−
(
)
=
−
=
−
∑
∑
s
N
r
N
a
k l
N
a
i
r
k
s
l
r
k
0
1
0
1
2
2
2
2
1
σ
π
, exp





 2
2
0
1
0
1
2
2
2
+
+
(
)










×
−
−
=
−
=
−
∑
∑




s
l
N
i
kl
r
l
N
k
N
σ
θ
π
cos
exp








s
r
k
s
l
N
i
r
s
r
+
−
(
)
+
(
)








=
−
−
(
)
+
2
2
2
2
σ
θ
π
θ
sin
exp
cos
s
N
N
a
i
k
l
kl
N
k l
sin
exp
cos
sin
,
θ
σ
σ
π
θ
θ
σ








×
−
−
(
)
−







2
2
2















×
+
(
)
−
−
(
)
=
−
=
−
∑
∑
l
N
k
N
i
s
l
r
k
0
1
0
1
2
exp
cos
π
θ



 2
2
cos
sin
,
θ
θ
σ
−
−
(
)
+
(
)

















r
k
s
l
N
which is a 2D chirp-function-modulated 2D convolution, with output coordi-
nates 

r N
s
,
−
, of 2D chirp-function exp
((
)cos
sin )
)
[
/(
]
−
−
−
i
k
l
kl
N
π
θ
θ
σ



2
2
2
 
and 2D chirp-function-modulated signal.
Derivation of Equation 4.93
SDFT1 2 0
0
2
1
1
2
2
1 2
2
1
2
/
/
,
exp



a
N
a
i
k
N
r
N
a
k
k
k
N
k
k
{ } =
+




=
=
−
=
∑
π
0
1
2
1
2
1 2
2
2
1 2
2
N
k
k N
N
i
k
N
r
a
i
k
N
r
−
=
−
∑
∑
+



+
+




exp
exp
π
π
/
/







=
+



+
=
−
−−
=
−
∑
1
2
2
1 2
2
0
1
2
1
2
N
a
i
k
N
r
a
k
k
N
N k
k N
N
exp
π
/
1
2
1 2
2
∑
+










exp i
k
N
r
π
/

214
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
+



+
−
−
=
−
=
−
∑
∑
1
2
2
1 2
2
2
2
1 2
2
0
1
0
1
N
a
i
k
N
r
a
i
N
k
k
k
N
k
k
N
exp
exp
π
π
/
/
N
r
N
a
i
k
N
r
a
k
k
N
k
k










=
+



+
=
−
=
∑
1
2
2
1 2
2
0
1
0
exp
π
/
N
k
i
k
N
r
N
a
k
N
r
−
∑
+










=
+




1
2
1 2
2
2
2
1 2
exp
cos
π
π
/
/
.
k
N
=
−
∑
0
1
Derivation of Equation 4.98
	
a
N
i
k
N
r
N
k
r
r
N
r
=
−
+




=
+
=
−
∑
1
2
2
1 2
2
1
2
0
2
1
0
α
π
α
α
DCT
DCT
DCT
/
exp
exp
exp
−
+







+
−
+




=
−
∑
i
k
N
r
i
k
N
r
r
N
r
2
1 2
2
2
1 2
2
1
1
π
α
π
/
/
DCT

=
+
−
+






=
+
−
=
−
∑
∑
r N
N
r
r
N
N
i
k
N
r
1
2
1
0
1
1
1
2
2
1 2
2
α
α
π
DCT
DCT
/
exp

+
−
+
(
)
−
(
)





=
+
=
−
∑α
π
α
α
r
r
N
r
i
k
N
r
N
N
DCT
DCT
DC
/
exp
2
1 2 2
2
1
2
1
1
0
T
DCT
/
/
exp
exp
−
+







+
−
+


=
−
∑
i
k
N
r
i
k
N
r
r
N
r
2
1 2
2
2
1 2
2
1
1
π
α
π


=
+
+










=
−
=
−
∑
∑
r
N
r
r
N
N
k
N
r
1
1
0
1
1
1
2
2
1 2
α
α
π
DCT
DCT
/
cos
..
Derivation of Equation 4.104
1
2
2
1 2
2
1
2
2
1 2
2
0
2
1
i
N
a
i
k
N
r
i
N
a
i
k
N
r
k
k
N
k


exp
exp
π
π
+




=
+

=
−
∑
/
/


+
+










=
=
−
=
−
∑
∑
k
N
k
k N
N
a
i
k
N
r
i
0
1
2
1
2
1 2
2
1
 exp
π
/
2
2
1 2
2
2
1 2
2
0
1
2
1
N
a
i
k
N
r
a
i
k
N
r
k
k
N
N k
exp
exp
π
π
+



−
+



=
−
−−
∑
/
/







=
−
∑
k N
N
2
1

215
Discrete Signal Transformations
	
=
+



−
−
−



=
−
∑
1
2
2
1 2
2
2
2
1 2
2
0
1
i
N
a
i
k
N
r
a
i
N
k
N
r
k
k
N
k
exp
exp
π
π
/
/







=
+



−
=
−
=
−
∑
∑
k
N
k
k
N
k
i
N
a
i
k
N
r
a
0
1
0
1
1
2
2
1 2
2
exp
e
π
/
xp
sin
−
+










=
+


=
−
∑
i
k
N
r
N
a
k
N
r
k
N
k
2
1 2
2
2
2
1 2
0
1
π
π
/
/


=
−
∑
.
k
N
0
1
Derivation of Equation 4.118
b
N
n
i
k
N
r
N
k
r
r
r
N
r
=
−
+




=
=
−
∑
1
2
2
1 2
2
1
2
0
2
1
α
π
α
η
(
)
(
)
exp
DCT
DCT
/

 r
r
N
r
r
i
k
N
r
i
k
N
r
exp
exp
(
)
−
+



+
−
+


=
−
∑
2
1 2
2
2
1 2
2
0
1
π
α
η
π
/
/
DCT 









=
−
+




=
−
∑
r N
N
r
r
N
i
k
N
r
2
1
1
2
2
1 2
2
α
η
π
(
)
exp
DCT
/

r
N
N r
N r
i
k
N
r
N
=
−
−
−
∑
+



−
+
−




0
1
2
2
2
1 2 2
2
α
η
π
(
)
exp
(
)(
)
DCT
/

r
N
r
r
r
N
N
i
k
N
r
=
=
−
∑
∑



=
−
+







1
0
1
1
2
2
1 2
2
α
η
π
(
)
exp
DCT
/

+
−
+
+




−
−
=
 
/
/
DCT
α
η
π
π
2
2
1
2
1 2
2
1 2
2
N r
N r
r
i
k
i
k
N
r
(
)
exp[
(
)]exp

N
r
r
r
N
N
i
k
N
r
∑
∑



=
−
+



−



=
−
1
2
2
1 2
2
0
1
2
α
η
π
α
(
)
exp
DCT
/

N r
N r
r
N
i
k
N
r
−
−
=
+




∑
(
)
exp
.
DCT
/
η
π
2
1
2
1 2
2
Derivation of Equation 4.124
	
CFR f
N
i
f x
r
N n
f xu
u r
N
r
r
N
x
s
x
( )
exp
( )
=
−




+
−





=
−
∑
1
2
0
1
η
π
∆
∆









=
−








=
−
∑
n
N
r
x
s
x
N
i
f xu
u r
N
0
1
1
2
η
π
exp
( )
∆

−








=
−
=
−
=
−
∑
∑
exp
exp
i
f x
r
N n
N
i
N
f x
r
n
N
r
N
r
2
1
2
0
1
0
1
π
η
π
∆
∆
N
i
f x
r
N
i
f x
r
N







−
−







−
=
−
∑
1
2
1
2
0
1
exp
exp
π
π
∆
∆u
u r
N
x
s
x
( ) −









216
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−








−








=
−
∑
N
N
f x
r
N
N
f x
r
N
r
r
N
η
π
π
sin
sin
e
∆
∆
0
1
xp
(
)
exp
( )
i
N
f x
r
N
i
f xu
u r
N
x
s
x
π
π
−
−








−







1
2
∆
∆
×

=
−








−








=
−
N
N
f x
r
N
N
f x
r
N
r
r
N
η
π
π
sin
sin
∆
∆
0
1
2
1
2
2
1
2
∑

−








−

−





exp
exp
( )
i
u
N
f x
i
u
N
r
N
x
s
x
π
π
∆
×


.
Derivation of Equation 4.149
	
a
N
N
a
i
n
r
w
N
k
w
n
n
N
(
,
)
exp
(
)
µ
π
µ
µ
±
± =
−
−
+









=
−
+
+
+
∑
1
1
0
1
2
/

×
−
+




=
−
+
=
−
−
−
−
+
+
∑
r
N
n
i
k
r
w
N
N
N
a
i
n
w
0
1
2
1
1
exp
(
)
exp
(
)
π
µ
µ
π
µ
/
2
2
2
0
1
0
1
2
+
−
+










×
+
+
+
+
=
−
=
−
∑
∑
r
r n
w
N
n
N
r
N
/
/
µ
µ
µ
(
)
exp i
k
w
r
r k
w
N
N
i
k
w
N
π
µ
µ
µ
µ
π
µ
(
)
(
)
exp
(
)
−
−
−
−
−
−
−
−
+
+
−
+




=
+
2
2
2
2
2
1
/
/




−
+




×
−


+
+
=
−
−
+
∑a
i
n
w
N
i
N
r
n
n
N
exp
(
)
exp
π
µ
π
µ
µ
2
0
1
2
2
2
1
1








−
−
−
+






=
+
+
+
−
−
=
−
−
−
∑
exp
exp
(
)
i
k
n
w
w
N
r
i
k
w
r
N
2
0
1
π
µ
µ
π
µ
2
2
0
1
N
a
i
n
w
N
N q k
n
w
n
n
N




−
+




−
−
+
+
±
=
−
∑
exp
(
)
frincd(
; ;
)
π
µ
.

217
Discrete Signal Transformations
Derivation of Equation 4.183
Αs
r
n
k n
N
r
n
N
N
w a
n
i
ks
N
w
w
( )
( ) exp
=












−+

=
−
∑
1
2
2
0
1
φ
π
k
N
n
r
t
w
t
N
N
w
n
N
i
k
n
N
N
t
=
−
=
−
∑
∑
=
−
−
+ 







0
1
0
1
1
1
2
2
φ
π
( )
exp
Α
/
















=
=
−
=
−
∑
∑
n
N
k
N
n
r
w
i
ks
N
N
w
n
0
1
0
1
2
1
exp
( )
π
φ
Αt
w
t
N
n
i
n
N
N
t
i
kt
N
exp
exp
2
2
2
0
1
π
π
−





−












=
−
∑
/
=
−
=
−
∑
∑










=
−
0
1
0
1
2
1
2
N
k
N
t
n
r
w
i
ks
N
N
w
n
i
n
N
exp
( )
π
φ
π
Α
w
n
N
k
N
N
t
i
t
s
N k
w
/2
2
0
1
0
1






−
−













=
−
=
−
∑
∑exp
π





=
−
−
−
−
−
=
−
∑
t
N
w
t
r
w
N
t
N
i
t
s
i
t
s
0
1
1
2
1
2
Α  (
)( )
exp[
(
)]
exp
π
π N
N
t
t
s
t
N
w
t
r
w
t
N



−












=
−

=
−
=
−
∑
∑
1
0
1
0
1
Α  (
)( ) (
)

ΑΑ 
s
r
w s
(
)( ),
where
	
Φr
w
w
n
r
n
N
w
n
r
t
N
w
n
i
n
N t
N
w
n
i
w
(
)( )
( )exp
( )exp
=



=
=
−
∑
1
2
1
2
0
1
φ
π
φ
π n
N t
n
N




=
−
∑
0
1
Exercises
convolution_demo_CRC.m
conv_evenextension_demo_CRC.m
dft_demo_CRC.m
dct_vs_dft_conv_demo_CRC.m
Reference
	
1.	 N. Ahmed, T. Natarajan, and K. R. Rao, Discrete cosine transform, IEEE Trans. 
Computers, C-23, 90–93, 1974.


219
5
Digital Image Formation and Computational 
Imaging
This chapter is devoted to methods of image formation from numerical 
data, or computational imaging. Apparently, the earliest example of compu-
tational imaging is computed tomography. In computed tomography, dis-
crete numerical data of sampling object slice projections obtained under a 
set of angles are converted into a set of samples of slice image over a regular 
square sampling grid suited to conventional image displays. This conversion 
is mainly a matter of image data resampling supplemented with an appro-
priate transform, DFT, or convolution. We will demonstrate this in Chapter 6. 
In this chapter, we discuss several other examples of computational imaging: 
image recovery from sparse nonuniformly sampled data, digital image for-
mation by means of numerical reconstruction of holograms, hybrid digital 
and analog image formation by means of computer-generated holograms, 
and, in conclusion, will show that in the conventional imaging scheme, 
where images are created by optics that focuses radiation into images, optics 
can, in principle, be replaced by a computer.
Image Recovery from Sparse or Nonuniformly Sampled Data
Formulation of the Task
There are many applications, where, in contrast to the common practice of 
uniform sampling, sampled data are collected in an irregular manner. Here 
are a few typical instances:
• Samples are taken not where the regular sampling grid dictates 
to take them but where it is feasible because of technical or other 
limitations.
• The pattern of sample disposition is dictated by physical principles 
of the work of the measuring device (as, e.g., in interferometry or 
moiré technique, where samples are taken along level lines).
• Sampling device positioning is jittering due to camera or object 
vibrations or due to other irregularities such as in imaging through 
a turbulent medium.

220
Theoretical Foundations of Digital Imaging Using MATLAB®
• Some samples of the regular sampling grid are lost or unavailable 
due to losses in communication channels.
Because image display devices as well as computer software for process-
ing sampling data assume using a regular uniform sampling grid, one 
needs in all these cases to convert irregularly sampled images to regularly 
sampled ones. Generally, the corresponding regular sampling grid may 
contain more samples than available because coordinates of positions of 
available samples might be known with a “subpixel” accuracy, that is, with 
the accuracy (in units of image size) better than 1/K, where K is the num-
ber of available pixels. Therefore, one can regard available K samples as 
being sparsely placed at nodes of a denser sampling grid with total amount 
of nodes N > K determined by the accuracy of specifying positions of the 
available samples.
In this section, we present a general framework for recovery of discrete 
signals from a given set of their arbitrarily taken samples. We treat this prob-
lem as an approximation task in the assumption that continuous signals are 
represented in computers by their K < N samples taken at some of, say, N 
nodes of a regular uniform sampling grid; K < N, and it is believed that if all 
N samples were known, they would be sufficient for representing the con-
tinuous signal. The goal of the processing is generating, out of this incom-
plete set of K samples, a complete set of N signal samples in such a way as 
to secure the most accurate, in terms of MSE, approximation of the discrete 
signal, which would be obtained if the continuous signal it is intended to 
represent were densely sampled at all N positions.
The mathematical foundation of the framework is provided by the discrete 
sampling theorem for “band-limited” discrete signals that have only few 
nonzero coefficients in their representation over a certain orthogonal basis. 
This theorem is introduced in the section “Discrete Sampling Theorem.” In 
the section “Algorithms for Signal Recovery from Sparse Sampled Data,” we 
describe algorithms for signal minimum MSE recovery from such sparse 
sampled data. In the section “Analysis of Transforms,” properties of trans-
forms, which are specifically relevant for signal recovery from sparse data, 
are analyzed. In the section “Application Examples,” we address application 
issues and illustrate the discrete sampling theorem-based methodology of 
discrete signal recovery on examples of image superresolution from multiple 
frames and image recovery from sparse projection data.
Discrete Sampling Theorem
Let AN be a vector of N samples ak
k
N
{ } =
−
0
1
,...,
 of a discrete signal, ΦN be an 
N × N transform matrix,
	
ΦN
r
r
N
k
= {
} =
−
φ ( )
, ,...,
0 1
1 	
(5.1)

221
Digital Image Formation and Computational Imaging
composed of orthonormal basis functions ϕr(k), and ΓN be a vector of signal 
transform coefficients γ r
r
N
{ } =
−
0
1
,...,
 such that
	
AN
N
N
r
r
r
N
k
N
k
=
=






=
−
=
−
∑
Φ Γ
γ φ ( )
.
, ,...,
0
1
0 1
1 	
(5.2)
Assume that available are only K < N signal samples {
}
ak k



∈K, where K is a 
K-size subset of indices {0,1,…, N − 1}. These available K signal samples define 
a system of K equations:
	
a
k
k
r
r
r
N
k




=
( )






=
−
∈
∑γ φ
0
1
K 	
(5.3)
for K signal transform coefficients {γr} of certain K indices r.
Select a subset R of K transform coefficients indices 

r ∈
{
}
R  and define a 
“KofN”-band-limited approximation ˆAN
BL to the signal AN as
	
ˆ
ˆ
( ) .
AN
BL
k
r
r
r R
a
k
=
=






∈∑γ φ




	
(5.4)
Rewrite this equation in a more general form that involves all transform 
coefficients:
	
ˆ
ˆ
( )
AN
BL
k
r
r
r
N
a
k
=
=






=
−
∑γ φ
0
1
	
(5.5)
assuming that all transform coefficients with indices r   R are set to zero:
	


γ
γ
r
r
r
R
=
∈



,
,0
otherwise.	
(5.6)
Then the vector AK of available signal samples {
}
ak  can be expressed in 
terms of the basis functions {ϕr(k)} of transform ΦN as
	








AK
K
k
r
r
r R
a
k
=
⋅
=
=






∈∑
KofN
( ) ,
Φ Γ
γ φ
	
(5.7)

222
Theoretical Foundations of Digital Imaging Using MATLAB®
where K × K subtransform matrix KofNΦ is composed of samples φ 
r k
( ) of 
the basis functions with indices {
}


r ∈R  for signal sample indices 

k ∈K, and 
ΓK is a vector composed of the corresponding subset {
}
γ r  of signal nonzero 
transform coefficients {γr}. This subset of the coefficients can be found by 
means of inverting matrix KofNΦ as
	



Γ
Φ
K
r
K
= { } =
⋅
−
γ
KofN
,
1 A
	
(5.8)
provided matrix KofNΦ
−1 inverse to the matrix KofNΦ exists, which, in gen-
eral, is conditioned, for a specific transform, by positions 

k ∈K of available 
signal samples and by the selection of the subset { }R  of transform basis func-
tions that correspond to nonzero transform coefficients.
By virtue of the Parceval’s relationship for orthonormal transforms, the 
band-limited signal ˆAN
BL approximates the complete signal AN with MSE:
	
MSE
A
A
a
a
N
N
k
k
r
r R
k
N
=
−
=
−
=
∉
=
−
∑
∑
ˆ
ˆ
.
2
2
2
0
1
γ
	
(5.9)
This error can be minimized by an appropriate selection of the K basis 
functions of the subtransform KofNΦ. In order to do so, one must know the 
energy compaction ordering of basis functions of the transform ΦN. If, in 
addition, one knows, for a class of signals, a transform that features the best 
energy compaction in the smallest number of transform coefficients, one can, 
by selecting this transform, secure the best minimum MSE band-limited 
approximation of the signal {ak} for the given subset ak
{ } of its samples.
In this way, we arrive at the discrete sampling theorem that can be formu-
lated in the following two statements:
Statement 1. For any discrete signal of N samples defined by its K ≤ N 
sparse and not necessarily regularly arranged samples, its band-limited, in 
terms of certain transform ΦN, approximation defined by Equation 5.5 can be 
obtained with MSE defined by Equation 5.9 provided positions of the sam-
ples secure the existence of the matrix KofNΦ
−1 inverse to the subtransform 
matrix KofNΦ that corresponds to the band-limitation. The approximation 
error can be minimized by using a transform with the best energy compac-
tion capability.
Statement 2. Any signal of N samples that is known to have only K ≤ N non-
zero transform coefficients for certain transform ΦN (ΦN—transform “band-
limited” signal) can be precisely recovered from exactly K samples provided 
positions of the samples secure the existence of the matrix KofNΦ
−1 inverse 
to the subtransform matrix KofNΦ that corresponds to the band-limitation.

223
Digital Image Formation and Computational Imaging
In this formulation, the discrete sampling theorem is applicable to signals 
of any dimensionality. It also does not require any assumption regarding 
compactness of nonzero signal spectral coefficients in the transform domain. 
The signal dimensionality affects only the formulation of the signal band-
limitedness. For 2D images and transforms such as discrete Fourier, discrete 
cosine, and Walsh transforms, the most simple is compact “low-pass” band-
limitedness by a rectangle or circle sector.
Algorithms for Signal Recovery from Sparse Sampled Data
For optimal signal/image band-limited approximation from sampled data, 
one has to first make a choice of
• The number N of samples to be recovered
• The transform, which promises the best approximation
• The type of band-limitation (e.g., low-pass, band-pass, high-pass, 
the shape of the figure in the transform domain that is supposed to 
­contain nonzero transform coefficients)
The choice of the transform must be made on the basis of the transform 
energy compaction capability. As for the type of band-limitation, it is the 
issue of a priori knowledge on the class of images at hand. If the best, for a 
particular image or set of images, transform and the type of band-limitation 
are not certain, one can select several transforms and types of band-limita-
tions and then, from obtained approximation results, select the one that has 
the highest energy. The number N of samples to be recovered is also a matter 
of a priori belief of how many samples of a regular uniform sampling grid 
would be enough to represent the images to the end user.
Implementation of signal recovery/approximation from sparse nonuni-
formly sampled data according to Equation 5.8 requires matrix inversion, 
which is, generally, a very computationally demanding procedure. In appli-
cations, in which one can be satisfied with signal reconstruction with a cer-
tain limited accuracy, one can apply for the reconstruction a simple iterative 
reconstruction algorithm of the Gerchberg–Papoulis [1,2] type. The flow dia-
gram of the algorithm is shown in Figure 5.1.
In this algorithm, the initial guess is generated from available sparse sig-
nal samples on a dense sampling grid of N samples, supplemented with a 
guess of the rest of the samples, for which, for instance, zeros, signal mean 
value or random numbers can be used. Then, at each iteration, the signal 
is subjected to the selected transform, the obtained transform coefficients 
are zeroed according to the band-limitation assumption and inverse trans-
formed, after which the next iteration of the restored signal is generated by 
means of restoring available signal samples in their known positions.

224
Theoretical Foundations of Digital Imaging Using MATLAB®
Analysis of Transforms
The applicability of a particular transform for band-limited image approxi-
mation depends first of all on whether KofN matrix for this transform is 
invertible, that is, whether available signal samples are compatible with 
band-limitation type selected for this transform. In what follows, we address 
the invertibility conditions most widely used in applications DFT, DCT, 
Walsh, and wavelet transforms.
Discrete Fourier Transform
Consider the K
N
of
DFT
LP -trimmed DFTN matrix:
	
K
N
of
DFT
LP
=










exp i
kr
N
LP
2π

	
(5.10)
that corresponds to DFT KofN-low-pass band-limited signal. Due to complex 
conjugate symmetry of DFT or real signals, K has to be an odd number, and 
the set of frequency domain indices of KofNDFT-low-pass band-limited sig-
nals in Equation 5.10 is defined as
	


r
K
N
K
N
LP
LP
/
/
∈
…
…
R
=
−
−
−
−
{
}
[ , ,
,(
)
,
(
)
,
,
] .
0 1
1 2
1 2
1
	
(5.11)
Signal
transform
Iteration loop
Output estimate after a selected
number of iterations
Inverse
transform
Generating
iterated signal
estimate
through
restoration of
available
signal samples
Initial guess: available signal samples supplemented with a guess
of the rest of the samples, for which zeros, signal mean value or
pseudorandom numbers can be used
Zeroing
transform
coefficients
according to the
band-limitation
assumption
FIGURE 5.1
Flow diagram of the iterative procedure of signal band-limited recovery from sparse samples.

225
Digital Image Formation and Computational Imaging
For such a case, the following theorems hold:
Theorem 5.1 
KofN-low-pass DFT band-limited signals of N samples with only K nonzero 
low-frequency DFT coefficients can be precisely recovered from exactly K of 
their samples taken in arbitrary positions on a regular uniform sampling grid.
Proof.  As it follows from Equations 5.3 through 5.8, the theorem is proven 
if matrix K
N
of
DFT
LP  is invertible. A matrix is invertible if its determinant is 
nonzero. In order to check whether the determinant of the matrix K
N
of
DFT
LP  is 
nonzero, permute the order of columns of the matrix as follows:
	


r
R
N
K
N
K
∈
=
−
−
−
−
{
}
[
(
)
,
,
, , ,
,(
)
]
1 2
1 0 1
1 2
…
…
	
(5.12)
and obtain the matrix
   
K
N
of
/
DFT
DFTsh =












=
−
−
exp
exp
(
)
i
kr
N
i
N
K
N
2
2
1 2
π
π





k
k
r
i
kr
N




−
(
)


















δ
π
×
exp
,
2
	
(5.13)
where
	


r ∈
…
−
R
K
= {[0,
,
1]}.	
(5.14)
The first matrix {exp[
((
(
)
)
) ] (
)}
i
N
K
N k
k
r
2
1 2
π
δ
−
−
−
/ /


  in this product of 
matrices is a diagonal matrix, which is obviously invertible. The second one 
{exp(
)}
i
kr N
2π/
 is a version of Vandermonde matrices, which are also known 
to have nonzero determinant if, as in our case, its ratios for each row are 
distinct [3]. As the permutation of the matrix columns does not change the 
absolute value of its determinant, Equation 5.13 implies that the determinant 
of KofN-trimmed DFTN matrix K
N
of
DFT
LP  of Equation 5.10 is also nonzero for 
an arbitrary set 

K = { }
k  of positions of K available signal samples.
For DFT KofN-high-pass band-limited signals, for which
	
K
N
of
DFT
HP
HP
=










exp
,
i
kr
N
2π

	
(5.15)
where
	


r
R
N
K
N
K
N
K
HP
HP
/
/
/
∈
…
=
−
+
−
+
+
−
{[(
)
,(
)
,
,(
)
]}
1 2
3
2
1 2
	 (5.16)

226
Theoretical Foundations of Digital Imaging Using MATLAB®
a similar theorem holds:
Theorem 5.2
KofN-high-pass DFT band-limited signals of N samples with only K nonzero 
high-frequency DFT coefficients can be precisely recovered from exactly K of 
their arbitrarily taken samples.
Theorems 5.1 and 5.2 can be extended to a more general case of signal DFT 
band-limitation, when indices { }r  of nonzero DFT spectral coefficients form 
arithmetic progressions with common difference other than one such as, for 
instance


r
R
m
m K
N
m K
N
m K
K
mLP
mLP
∈
=
−
−
−
−
−
+
+


0
1
2
1
2
1
2
1
2
,
,
,
(
) ,
(
) ,
,
(
)
(
)
…
…

.
	
(5.17)
Plots in Figure 5.2a and b illustrate examples of exact reconstruction of a 
DFT-”band-limited” signal (solid line) by matrix inversion for two cases: (a) 
all available signal samples are randomly placed within signal support and 
(b) available signal samples form a compact group.
Note that, as experiments show, the convergence of the iterative algorithm 
heavily depends on the realization of sample positions and, for some realiza-
tions of positions of available samples, it might be quite slow.
Discrete Cosine Transform
As it was shown in the section “Properties of Discrete Fourier Transforms” 
in Chapter 4, N-point DCT of a signal is equivalent to 2N-point-shifted dis-
crete Fourier transform (SDFT) with shift parameters (1/2,0) of 2N samples 
signal obtained from the initial one by its mirror reflection. KofN-trimmed 
matrix of SDFT(1/2,0) over 2N samples
	
K
N
of
SDFT
/
=
+










exp
(
)
i
k
r
N
2
1 2
2
π


	
(5.18)
can be represented as a product
	
K
N
of
SDFT =








−









exp
exp
(
)
i
kr
N
i
r
N
k
r
2
2
2
π
π
δ






=




−






K
N
of
DFT exp
(
)
i
r
N
k
r
π
δ

2
	
(5.19)

227
Digital Image Formation and Computational Imaging
1
(a)
(b)
(c)
(d)
0.5
0
–0.5
–1
1
0.5
0
–0.5
–1
1
0.5
0
–0.5
10–10
–1
10
20
30
40
50
60
10
20
30
Samples
Samples
10
20
30
40
50
60
Samples
Iterations
Std Dev of approximation error
1000 2000 3000 4000 5000 6000 7000 8000 9000 10,000
40
50
60
FIGURE 5.2
​Restoration of a DFT low-pass band-limited signal by means of matrix inversion for the cases of 
random (a) and compactly placed signal samples (b) and that by using the iterative algorithm 
(c). Plot (d) shows standard deviation of signal restoration error as a function of the number of 
iterations. The experiment was conducted for test signal length of 64 samples and bandwidth 
of 13 frequency samples (~1/5 of the signal base band). In all plots, the original signal is rep-
resented in solid line obtained, for display purposes, by linear interpolation of its samples; 
available samples are represented by stems and samples reconstructed by matrix inversion are 
represented by dots.

228
Theoretical Foundations of Digital Imaging Using MATLAB®
of a 2N-point DFT matrix and a diagonal matrix {exp(
) (
)}
i r
N
k
r
π
δ
 2
−
. The 
latter one is invertible and the invertibility of KofN-trimmed DFT2N matrix 
KofNDFT can be proved, for the above-described band-limitations, in the 
same way as it has been done above for the DFT case. Therefore, theorems 
similar to those for DFT hold for DCT as well.
These theorems also hold for 2D DFT and DCT transforms provided band-
limitation conditions are separable. The case of nonseparable band-limita-
tion is more involved and requires further study.
We illustrate the above reasoning by some simulation examples. Figures 
5.3 and 5.4 illustrate precise restoration from sparse data of images band-
limited in DCT domain by a square (separable band-limitation) and by a 90° 
circle sector (a pie piece, inseparable band-limitation).
The image presented in Figure 5.3a is a 64×64 pixel test image low-pass 
band-limited in DCT domain by a square of 9×9 samples (Figure 5.3b). It has 
only 9 × 9 = 81 nonzero DCT spectral components out of the 64×64 ones. This 
image was sampled at 82 “random” positions obtained from the standard 
MATLAB pseudorandom number generator. One can see from the figure 
that the iterative algorithm provides quite accurate restoration of the initial 
image, though precise restoration may require quite a large number of itera-
tions. An important peculiarity of the iterative restoration process is that the 
convergence of iteration is very nonuniform within the image area. Usually, 
the restoration error is rapidly becoming very small almost everywhere in 
the image, and only in some parts, where sample density happens to be low, 
restoration errors remain to be substantial and decay quite slowly.
Image band-limitation by a square is separable over image coordinates 
and, as it was shown earlier, it does not impose any limitation on the posi-
tions of sparse samples. It is, however, not isotropic. In the case of the iso-
tropic band-limitation in the DCT domain by a circle sector (a pie piece), 
the situation is quite different. Experiments show that the speed of conver-
gence of the iterative algorithm substantially drops in this case. Many more 
iterations are needed to make the overall standard deviation of the resto­
ration error low enough, though, again, the restoration error remains to be 
substantial only in limited areas of the image. The convergence speed of the 
iterative algorithm in the case of isotropic circle sector band-limitation can 
be substantially improved if the number of available image samples exceeds 
the number of nonzero DCT spectral coefficients, that is, if it is redundant 
from the point of view of the discrete sampling theorem. This is illustrated 
in Figure 5.4.
The image presented in Figure 5.4a is a 64×64 pixels test image low-pass 
band-limited in the DCT domain by a circle sector. It has 73 nonzero DCT 
spectral components out of 64×64, all located within a circle sector shown in 
white in Figure 5.4b. In distinction from the image of Figure 5.3a, this one 
was sampled at 93 “random” positions. The redundancy 93/73 = 1.27 in the 
number of samples with respect to the number of nonzero spectral coeffi-
cients is approximately equal to the ratio of the area of a square to the area of 

229
Digital Image Formation and Computational Imaging
(a)
(b)
(c)
(e)
(d)
BL square; BW = 0.02;
Image map and positions of samples
DCT domain spectral mask; BW = 0.02
Map of abs (Restoration error)
BL square; BW = 0.02; Redund 1
Number of iterations
Reconstr. error Std Dev
100
10–1
10–2
10–3
101
102
103
104
105
FIGURE 5.3
​Recovery of an image band-limited by a square in DCT domain: (a) initial image with 82 “ran-
domly” placed samples in positions shown by white dots; (b) the shape of the image spectrum 
in DCT domain; (c) image restored by the iterative algorithm after 100,000 iterations; (d) itera-
tive algorithm restoration error (white: large errors; black—small errors); (e) restoration error 
standard deviation versus the number of iterations for the iterative algorithm.

230
Theoretical Foundations of Digital Imaging Using MATLAB®
(a)
(b)
(c)
(e)
(d)
BL circle sector; BW = 0.018; Redund 1.27
Image map and positions of samples
DCT domain spectral mask; BW = 0.017822
Map of abs (Restoration error)
Restored map; BL circle sector;
BW = 0.018; Redund 1.27
BL circle sector ; BW = 0.018; Redund 1.2732
Number of iterations
Reconstr. error Std Dev.
100
10–1
100
10–2
10–3
101
102
103
104
105
FIGURE 5.4
​Recovery of an image band-limited in DCT domain by a circle sector: (a) initial image with 
93 “randomly” placed samples in positions shown by white dots; (b) the shape of the image 
spectrum in DCT domain (upper left corner: lowest frequencies; bottom right corner: highest 
frequencies); (c) image restored by the iterative algorithm after 100,000 iterations; (d) restora-
tion error found as a difference between initial test and recovered images (white—large errors; 
black—small errors); (e) restoration error standard deviation versus the number of iterations.

231
Digital Image Formation and Computational Imaging
the circle sector inscribed into this square. As one can see from Figure 5.4e, 
with such a redundancy, iterative restoration converges quite fast and the 
overall restoration error after 100,000 iterations is comparable to that for the 
separable band-limitation by a square illustrated in Figure 5.3. Once again, 
one can see that the convergence of the iterative algorithm is nonuniform 
over the image and relatively large restoration errors occur only in a small 
area of the image where the density of available samples happens to be low.
In some applications, there is a natural and substantial redundancy in the 
number of available image samples with respect to its bandwidth. One of 
such cases is illustrated in Figure 5.5 by an example of image recovery from 
its level lines.
A test 256×256 pixels image, shown in Figure 5.5, is band-limited in the 
DCT domain by a circle sector and contains 302 nonzero spectral coefficients. 
The image was sampled in 6644 samples on a set of its level lines (eight levels), 
which resulted in a 22-fold redundancy with respect to the image spectrum 
2D bandwidth. As one can see from the figure, such a redundancy accelerated 
the convergence of the iterative algorithm very substantially and enabled, 
after a few tens of iterations, restoration with quite low restoration error.
Wavelets and Other Bases
The main peculiarity of wavelet bases is that their basis functions are most 
naturally ordered in terms of two parameters: scale and position within the 
scale. Scale index is analogous to the frequency index for DFT. Position index 
tells only of the shift of the same basis function within the signal extent on 
each scale. Therefore, band-limitation for DFT translates to scale limitation 
for wavelets. Limitation in terms of position is trivial: it simply means that 
some parts of the signal are not relevant. Commonly, discrete wavelets are 
designed for signals whose length is an integer power of 2 (N = 2n). For such 
signals, there are s ≤ n scales and possible “band-limitations.”
The simplest special case of wavelet bases is Haar basis. Signals with N = 2n 
samples and with only K lower index nonzero Haar transform (the transform 
coefficients with indices {K,…, N − 1} are zero) are (
( log
))
s
K
=
−

(
)+ 1
2
1
- 
”band-limited,” where 
x  is an integer part of x. Such signals are piece-wise 
constant within intervals between basis function zero-crossings. The short-
est intervals of the signal constancy contain 2n s
− samples.
As one can see in Figure 5.6, right column plots, where the first eight basis 
functions of Haar transform are presented, for any two samples located on 
the same interval, all Haar basis functions on this and lower scales have the 
same value. Therefore, having more than one sample per constant interval 
will not change the rank of the matrix KofN. The condition for perfect recon-
struction is, therefore, to have at least one sample on each of those intervals.
For other wavelets as well as for other bases, a general necessary, suffi-
cient, and easily verified condition for the invertibility of KofN-trimmed 

232
Theoretical Foundations of Digital Imaging Using MATLAB®
transform submatrix is yet to be found. Standard linear algebra procedures 
for determining matrix rank can be used for testing the invertibility of the 
matrix in each particular case.
For Walsh basis functions, the function index corresponds to the “sequency,” 
or to the number of zero crossings of the basis function. As it was already 
mentioned in the section “Typical Basis Functions and Classification” in 
Chapter 3, the sequency carries a certain analogy to the signal frequency. 
Basis functions ordering according to their sequency, which is a character-
istic for Walsh transform, preserves, for many real-life signals, the property 
(a)
(c)
(b)
Test image and level lines; BW = 0.05
Reconstructed image on 500-th iteration
BW = 0.05; Reconstruction PSNR = 8469.2083
Number of iterations
Reconstruction error Std Dev/255
100
200
300
400
500
10–1
10–2
10–3
100
FIGURE 5.5
​Recovery of an image band-limited in DCT domain by a circle sector from its level lines: (a) ini-
tial image with level lines (shown by white lines); (b) image restored by the iterative algorithm 
after 500 iterations; (c) restoration error standard deviation versus the number of iterations.

233
Digital Image Formation and Computational Imaging
of more or less regular decaying transform coefficients’ energy with their 
index. Therefore, for Walsh transform, the notion of low-pass band-limited 
signal approximation, similar to that described for DFT, can be used. On the 
other hand, as one can see in Figure 5.6, left column plots, Walsh basis func-
tions, similar to Haar basis function, can be characterized by the scale index, 
which specifies the shortest interval of signal constancy. Signals with N = 2n 
samples and band-limitation of K Walsh transform coefficients have shortest 
intervals of signal constancy of 2n s
− samples, where s
K
=
−

+
(
)
log (
)
2
1
1 . 
A necessary condition for perfect reconstruction is to have K signal samples 
taken on different intervals. Unlike the Haar transform case, not all the inter-
vals are needed to be sampled, but only K intervals out of the total number of 
intervals. For a special case of K equal to a power of 2, there are K intervals, 
each of which has to be sampled to secure perfect reconstruction. This is the 
case when the reconstruction condition for the Walsh transform is identical 
to that for the Haar transform.
Figures 5.7 and 5.8 illustrate recovery of a 1D signal and an image “band-
limited” in the Haar transform domain.
Walsh functions
Haar functions
0
1
2
3
4
5
6
7
Scale 0
Scale 1
Scale 2
Scale 3
FIGURE 5.6
​First eight Walsh and Haar basis functions grouped according the scale parameter.

234
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 5.8
Two cases of sparse sampling of an image band-limited in Haar transform: (a) not recoverable 
case; (b) recoverable case. Sample positions are marked with dots; image size is 64 × 64 pixels; 
band-limitation is 8 × 8 samples (scale 3).
Haar: N = 1024; NO = 31; Nit = 2000
Approximation error Std Dev
Sample index
100
200
400
600
800
1000
1200
Iterations
1400
1600
1800
2000
–0.5
10–5
10–10
0
0.5
1
200
300
400
500
600
700
800
900
1000
FIGURE 5.7
​An illustrative example of restoration of Haar transform 1D band-limited signal using the iter-
ative algorithm and plot of approximation error as function of the number of iterations. Initial 
signal is shown by solid line linearly interpolated, for display purposes, from its samples; 
available sparse signal samples are shown by stems, reconstructed samples are shown by light 
points on top of the initial signal line.

235
Digital Image Formation and Computational Imaging
In Figure 5.8, two examples of image recovery are shown: arrangement of 
sparse samples, for which signal recovery is possible (Figure 5.8a) and that for 
which signal is not recoverable from the same number of samples (Figure 5.8b).
An example of the perfect reconstruction of a Walsh transform domain 
“band-limited” signal of N = 512 and of band-limitation K = 5 is illustrated 
in Figure 5.9.
In this example, the resulted KofNWalsh matrix is
	
K
N
of
Walsh K=
=
−
−
−
−
−
−
−
−
−











5
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1





and its rank equals to 5. One should note that, in this particular example, 
perfect reconstruction in the Haar transform domain is not possible since 
one of the shortest intervals of the signal constancy contains no samples.
Selection of Transform for Image Band-Limited Approximation
As it has been already mentioned, the accuracy, in terms of mean square 
approximation error, of signal band-limited approximation is determined 
by the energy compaction capability of the transforms. Theoretically (see 
the section “Optimality of Bases: Karhunen–Loeve and Related Transform” 
Original signal (solid line) and its samples (stems)
Signal reconstructed by direct matrix inversion
100
200
300
400
500
1
0.5
0
1
0.5
0
100
200
300
400
500
FIGURE 5.9
​An example of Walsh band-limited signal recovery by means of matrix inversion.

236
Theoretical Foundations of Digital Imaging Using MATLAB®
in Chapter 3), optimal transforms are Karhunen–Loeve transform and its 
discrete version Hotelling transform. However, the practical value of these 
transforms is quite limited because of high computational complexity of gen-
erating transform basis functions and computing image representation coef-
ficients. In practice, transforms such as DFT, DCT, Walsh, Haar, and wavelet 
transforms that feature fast transform algorithms are preferred for signal 
representation, restoration, and analysis because they combine quite good 
energy compaction capability and low computational complexity. Their effi-
ciency for different classes of signals might, in principle, be different, and 
experimental evaluation of transform energy compaction capability for par-
ticular applications is required. In Figures 5.10 and 5.11, some illustrative 
data for such an evaluation are presented.
Shown in Figure 5.10, images are examples of pseudorandom images band-
limited in domains of DCT, Walsh, and Haar transform by a circle sector 
with radius of 0.1 of the base band size. They are generated by means of 
corresponding domain low-pass filtering of arrays of uncorrelated pseudo-
random numbers.
Images presented in Figure 5.11 illustrate an approximation error of four test 
images approximated by their copies low-pass band-limited by a square of the 
size of 0.3 of the base band. A common characteristic feature of these images is 
that they represent edges of objects in the images, components of crucial impor-
tance for object detection, localization, and recognition (see Chapter 7). One 
can also see in this comparison results that the approximation error standard 
deviation for DCT band-limitation is the lowest  for all of the shown test images.
Application Examples
Image Superresolution from Multiple Differently Sampled Video Frames
One of the potential applications of the above signal recovery technique is 
image superresolution from multiple video frames with chaotic pixel dis-
placements due to atmospheric turbulence, camera instability, or similar 
DCT, Walsh, and Haar transform band-limited images and spectral mask
FIGURE 5.10
​Examples of images with uniform spectra in (left to right) DCT, Walsh, and Haar transforms 
band-limited by a circle sector with radius 0.1 of the base band (the very right image; upper left 
corner: lowest spatial frequencies, lower right corner: highest spatial frequencies).

237
Digital Image Formation and Computational Imaging
DCT_LP image; BW = 0.3; StdErr = 16.3692
DCT_LP image; BW = 0.3; StdErr = 2.9807
Walsh_LP image; BW = 0.3; StdErr = 22.1208
Walsh_LP image; BW = 0.3; StdErr = 4.1801
Haar_LP image; BW = 0.3; StdErr = 22.3649
Haar_LP image; BW = 0.3; StdErr = 4.2585
DCT_LP image; BW = 0.3; StdErr = 1.1226
DCT_LP image; BW = 0.3; StdErr = 1.8348
Walsh_LP image; BW = 0.3; StdErr = 3.3655
Walsh_LP image; BW = 0.3; StdErr = 2.7723
Haar_LP image; BW = 0.3; StdErr = 3.261
Haar_LP image; BW = 0.3; StdErr = 2.6553
FIGURE 5.11
Low-pass band-limited approximations to test images for band-limitation in a form of a 
square of 0.3 of the base band in DCT, Walsh, and Haar transform domains and corresponding 
approximation errors (differences between original and band-limited images; shown to the 
right of each corresponding image). Error standard deviations (StdErr) are indicated in image 
headers in units of image dynamic range [0–255].

238
Theoretical Foundations of Digital Imaging Using MATLAB®
random factors. Here is, in brief, how this can be done. Using methods of 
target location (see Chapter 7), one can, by means of registration of pixel 
neighborhoods in frames of video sequence that contain the same scene, 
determine, for each image frame in sequences of turbulent video frames and 
with a subpixel accuracy, pixel displacements caused by the random acqui-
sition factors. Having obtained these data, a synthetic fused image can be 
generated by placing pixels of the available turbulent video frames in their 
proper positions on the correspondingly denser sampling grid according to 
their found displacements. In this process, some pixel positions on the denser 
sampling grid will remain unoccupied, especially when a limited number of 
image frames is fused. These missing pixels can then be restored using the 
above-described iterative band-limited reconstruction algorithm for image 
recovery from sparse samples. This is illustrated in Figure 5.12 which shows 
one low-resolution frame (a), an image fused from 15 frames (b), and a result 
of iterative interpolation (c) achieved after 50 iterations. Image band-limi-
tation was set in this particular experiment twice of the base band of raw 
low-resolution images.
Image Reconstruction from Sparse Projections in Computed Tomography
The discussed sparse data recovery methods can find application also in 
tomographic imaging, where it frequently happens that a substantial part 
of slices, which surrounds the body slice, is known to be an empty field. 
This means that slice projections (sinograms) are Radon transform band-
limited functions. Therefore, whatever number of projections is available, a 
certain number of additional projections, commensurable, according to the 
discrete sampling theorem, with the relative size of the slice empty zone, can 
be obtained and the corresponding resolution increase in the reconstructed 
images can be achieved using the described iterative band-limited recon-
struction algorithm. Figure 5.13 illustrates such superresolution through 
recovery of missing half of projections achieved using the fact that around 
50% of the image area of the head slice is an empty space.
Discrete Sampling Theorem and “Compressive Sensing”
The described methods for image recovery from sparse samples by means 
of their band-limited approximation in certain transform domain require 
explicit formulation of the desired band-limitation in the selected transform 
domain. While for 1D signal, this formulation is quite simple and requires, 
for most frequently used low-pass band-limitation, specification of only one 
parameter, signal bandwidth, in 2D case formulation of signal band-limita-
tion requires specification of a 2D shape of signal band-limited spectrum. 
The simplest shapes, rectangle and circle sector ones, may not be appropriate 
enough for images at hand. In cases, when the character of spectrum band-
limitation is not known or not certain a priori, image recovery from sparse 

239
Digital Image Formation and Computational Imaging
samples can be achieved using an approach, for which the name “compres-
sive sensing” was coined [4].
The compressive sensing approach also assumes obtaining band-limited, 
in certain selected transform domain, approximation of images but it does 
not require explicit formulation of the signal band-limitation and achieves 
signal recovering from an incomplete set of available samples by means of 
minimization of L1 norm α
α
L
r
N
r
1
0
1
= ∑=
−
 of signal transform coefficients 
{αr} for the selected transform conditioned by preservation in the recovered 
Low-resolution frame
(a)
(b)
(c)
SR frame before interpolation
SR frame after interpolation (50 iterations)
FIGURE 5.12
​Iterative image interpolation in the superresolution process: (a) a low-resolution frame; (b) 
image fused by elastic image registration from 15 frames; (c) a result of iterative interpolation 
of image (b) after 50 iterations. (Adapted from J. W. Goodman and R. W. Lawrence, Applied 
Physics Letters, 11(3), 77–79, 1967.)

240
Theoretical Foundations of Digital Imaging Using MATLAB®
signal of its available samples. The price one should pay for the uncertainty 
regarding band-limitation is that the number of required signal samples M 
must be in this case redundant with respect to the given number K nonzero 
spectral coefficients: according to [4], M/K = O(log N).
Minimization of the L1 norm replaces minimization of L0 norm 
α
α
L
r
N
r
0
0
1
0
= ∑=
−
, which would lead to the minimum number of signal trans-
form nonzero coefficients. Justification of this replacement is that for mini-
mization of L1 norm, standard numerical optimization algorithms, such as 
linear programming, are available, whereas minimization of L0 norm is 
(a)
(b)
(c)
(d)
FIGURE 5.13 
Superresolution in computed tomography: (a) a set of initial projections supplemented with 
the same number of presumably lost projections to double the number of projections; initial 
guesses of the supplemented projections are set to zero (shown in black); (b) image recon-
structed from initially available projections; (c) result of iterative restoration of missing projec-
tions; (d) image reconstructed from the restored double set of projections.

241
Digital Image Formation and Computational Imaging
computationally problematic, and that the two optimizations are practically 
equivalent in many applications.
Digital Image Formation by Means of Numerical 
Reconstruction of Holograms
Introduction
The first experiments in numerical reconstruction of optical holograms date 
back to the 1960s through the 1970s [5–7]. At that time, scanning devices that 
could be used for digitizing holograms had low resolution, which required 
optical magnification of photographic recordings of holograms to fit them 
to the resolution of scanning devices. Figure 5.14 reproduces the results 
reported in [5] and [6].
Then, in the 1990s, with the advent of digital photographic cameras, it had 
become possible to perform direct digitizing optical hologram in the process 
of hologram recording. In first experiments with CCD cameras [8], holograms 
were recorded in the Leith–Upatnieks off-axis scheme [9]. Later, phase-shift-
ing method for recording holograms was suggested [10] that enabled on-axis 
hologram recording scheme more efficient in terms of the use of resolution 
of digital cameras. Since that time, numerous projects in digital recording 
and numerical reconstruction of optical holograms have been initiated and 
implemented, especially in the field of optical holographic microscopy.
Principles of Hologram Electronic Recording
As it was already mentioned, two methods of electronic recording of opti-
cal holograms using digital photographic cameras are known: “off-axis” and 
“on-axis” methods.
The schematic diagram of the “off-axis” method for electronic recording of 
holograms is presented in Figure 5.15.
As it is always in holography, the illumination laser beam is split into two 
beams: object beam, which illuminates the object, and reference beam, which 
is directed to the recording camera to interfere with the light scattered by 
the object. Both beams have presumably a plane wavefront. The interfering 
object and reference wavefronts are sensed and sampled by a photosensor 
array of the camera placed in a plane called the hologram plane. In the off-axis 
recording, a spatial angle between the reference and object beams is intro-
duced that must exceed the angular size of the object, under which it is seen 
from the hologram plane.
Consider a mathematical model of “off-axis” recorded holograms. At each 
point of the hologram plane (fx, fy), photosensitive array of the digital camera 

242
Theoretical Foundations of Digital Imaging Using MATLAB®
measures samples of intensity of the sum of the reference beam R(fx, fy) and 
the object beam αobj (fx, fy) reflected or transmitted by the object:
	
H(
,
)
(
,
)
(
,
)
(
,
)
(
,
)
(
f
f
f
f
R f
f
f
f
R
f
f
x
y
x
y
x
y
x
y
x
y
=
+
=
+
∗
∗
α
α
α
obj
obj
obj
2
f
f
R f
f
f
f
R f
f
x
y
x
y
x
y
x
y
,
) (
,
)
(
,
)
(
,
) ,
+
+
αobj
2
2
	
(5.20)
FIGURE 5.14
​First holograms numerically reconstructed in computers: (a) a test optical Fourier hologram 
electronically recorded using vidicon TV camera to 256 × 256 pixels quantized to 8 gray levels; 
(b) image numerically reconstructed from this hologram on a computer PDP-6; (c) an optical 
photographically recorded Fourier hologram optically magnified with magnification factor 
20 and scanned to 512 × 512 pixels using electromechanical scanner with resolution 0.2 mm 
and quantized to 64 gray levels in a logarithmic scale; (d) two conjugate images reconstructed 
from this hologram on a computer Minsk-22 (http://www.computer-museum.ru/english/
minsk0.htm). (Images (a) and (b) are adapted from J. W. Goodman, R. W. Lawrence, Applied 
Physics Letters, 11(3), 77–79, 1967; images (c) and (d) are adapted from L. P. Yaroslavskii, N. S. 
Merzlyakov, Methods of Digital Holography, Consultance Bureau, NY, 1980. (English translation 
from Russian, In: Methods of Digital Holography, Editors L. P. Yaroslavskii, N. S. Merzlyakov, 
Moscow, Izdatel’stvo Nauka, 1977. 192 p.))

243
Digital Image Formation and Computational Imaging
where asterisk denotes complex conjugation. Numerical reconstruction of 
the hologram consists in applying to samples of the recorded hologram a 
discrete transform that implements wave propagation from the hologram 
plane back to object.
Equation 5.20 can be modified to a form:
H f
f
f
f
R f
f
i
f
f
f
f
x
y
x
y
x
y
x
y
x
y
(
,
)
(
,
)
(
,
) exp
(
(
,
)
(
,
))
=
−

α
θ
θ
obj
obj
Rb

+
−

+
α
θ
θ
α
obj
obj
Rb
(
,
)
(
,
) exp
(
(
,
)
(
,
))
(
f
f
R f
f
i
f
f
f
f
x
y
x
y
x
y
x
y
f
f
R f
f
f
f
R f
f
f
f
f
x
y
x
y
x
y
x
y
x
y
x
,
)
(
,
)
(
,
)
(
,
) cos
(
,
)
(
2
2
2
+
= +
−
α
θ
θ
Obj
Rb
,
) ,
fy



(5.21)
where 
α
α
θ
(
,
)
(
,
) exp
f
f
f
f
i
x
y
x
y
=
(
)
obj  
and 
R f
f
R f
f
i
x
y
x
y
(
,
)
(
,
) exp
=
(
)
θRb  
denote complex amplitudes (amplitudes and phases) of the object and ref-
erence beams, respectively, at point (fx, fy) of the hologram plane. Equation 
5.21 explicitly shows that the recorded hologram signal contains a term with 
amplitude- and phase-modulated spatial carrier (the last term in Equation 
5.21) that carries information on the object beam. In the holograms shown 
in Figure 5.14a and c, one can clearly see periodical patterns formed by this 
spatial carrier. It is also seen in the results of hologram reconstruction shown 
in Figure 5.13b and d that reconstructed images contain a bright spot in the 
center of reconstructed images. This spot, the so-called zero-order diffraction 
term, is generated by the first two terms in Equation 5.21, while the second 
term, the spatial carrier one, produces two reconstructed images, direct 
Laser
Object
Collimator
Collimator
Reference beam
R( fx, fy)
Hologram plane
( fx, fy)
Object beam
α( fx, fy)
Reference
beam angle
Angular size
of the object
Digital
photographic
camera
FIGURE 5.15
Schematic diagram of the “off-axis” method for electronic hologram recording.

244
Theoretical Foundations of Digital Imaging Using MATLAB®
and conjugated ones. The angular distance between centers of these images 
is determined by the reference beam angle, which must exceed the image 
angular size in order to prevent overlapping direct and conjugate images. 
Because of this, the highest spatial frequency of the recorded hologram is at 
least twice as that of the object wavefront. Therefore, the hologram recording 
device must have at least twice as much resolution cells for recording and 
sampling holograms compared to that required for recording of only the 
mathematical hologram (the first term on the right part of Equation 5.20), which 
will reconstruct the object image without the conjugate image.
The schematic diagram of the “on-axis” method for electronic recording of 
holograms is shown in Figure 5.16. In this method, also known as phase-
shifting holography [10], object and reference beams are colinear and several 
exposures of holograms of the object are carried out with shifting, at each 
exposure, the phase of the reference beam plane wavefront. In order to com-
pute from the recording results the mathematical hologram, they are com-
bined in the computer in a certain way, which depends on the number of 
exposures and phase shifts of the reference beam in each exposure.
In what follows, we show that at least three exposures are required in this 
method. Let θRb
( )
k  be a phase shift of the reference beam in the k-th hologram 
exposure, k = 1,. . .,K. Then
 
H
f
f
f
f
R f
f
i
f
f
R f
f
k
x
y
x
y
x
y
k
x
y
x
y
(
,
)
(
,
)
(
,
) exp
(
,
)
(
,
=
+
(
)
=
+
( )
α
θ
α
Rb
2
2
)
(
,
)
(
,
) exp
(
,
)
(
,
) exp
2
+
−(
) +
( )
∗
α
θ
α
θ
f
f
R f
f
i
f
f
R f
f
i
x
y
x
y
k
x
y
x
y
Rb
Rb
k( )
(
) 	
(5.22)
Object
Object
beam
Beam
splitter
Digital
photographic
camera
Reference
beam
Collimator
Collimator
Laser
FIGURE 5.16
Schematic diagram of the “on-axis” method for electronic recording of holograms.

245
Digital Image Formation and Computational Imaging
is a hologram recorded in the k-th exposure. For separating the mathemati-
cal hologram term containing α(fx, fy), K recorded at each exposure holo-
grams {Hk} are summed up with the same phase shifts as those used in their 
recording:
	
H
K
H
i
f
f
R f
f
f
f
R f
f
n
k
k
K
x
y
x
y
x
y
x
y
=
(
) =
+
( )
=
∗
∑
1
1
exp
(
,
)
(
,
)
(
,
)
(
,
)
θ
α
α
Rb
×
(
) +
+




(
)
( )
=
( )
∑exp
(
,
)
(
,
)
exp
i
f
f
R f
f
i
k
k
K
x
y
x
y
k
k
2
1
2
θ
α
θ
Rb
Rb
=∑
1
K
.
	(5.23)
In this equation, the first term is the record of the wavefront propagated 
from the object times intensity of the plane reference beam, which is assumed 
to be a constant; other terms are interfering terms that should be eliminated. 
In order to secure this, phases θRb
( )
k
{
}  must be solutions of equations:
	
exp
exp
.
i
i
n
n
N
n
n
N
θ
θ
Rb,
Rb,
(
) =
(
) =







=
=
∑
∑
1
1
0
2
0
	
(5.24)
It is convenient to use phase shifts {θRb,n} that form an arithmetic progression
	
θ
θ
Rb,
(
)
,
,
,
.
n
k
k
K
=
−
=
1
1
0
…
	
(5.25)
Then Equations 5.24 is converted to equations
	
exp
exp (
)
exp
exp
i
i k
iK
i
k
k
K
k
K
θ
θ
θ
θ
Rb
( )
=
=
(
) =
−
[
] =
(
) −
(
) −
∑
∑
1
0
0
0
1
1
1
1 =
(
) =
−
[
] =
(
) −
(
) −
=∑
0
2
2
1
2
1
2
1
0
0
0
exp
exp
(
)
exp
exp
,
i
i
k
i K
i
n
n
N
θ
θ
θ
θ
Rb
1
0
0
1
=







=
−
∑
k
K
 
	
(5.26)
The solution of Equations 5.26 is θ0 = (2π/K) for any integer N ≥ 3. Note that 
although for K = 2 (θ0 = π) the first equation holds, the second equation does 
not:s
	
exp
exp
exp
exp
exp
exp
i
i
i
i
i
i
2
1
1
2
1
1
2
1
0
0
0
0
0
θ
θ
θ
θ
θ
(
)−
(
)−
(
)+
(
)+
=
(
)−
2
1
2
1
2
1
2
0
0
θ
θ
π
(
)−
(
)+

=
+
=
exp
exp(
)
.
i
i
	
(5.27)

246
Theoretical Foundations of Digital Imaging Using MATLAB®
Consider an example. In four exposures (K = 4, θ0 = (π/2)), we will have 
from Equation 5.22
	
H
R
R
R
H
R
i R
i
R
H
R
R
R
H
1
2
2
2
2
2
3
2
2
4
2
=
+
+
+
=
+
−
+
=
+
−
+
=
∗
∗
∗
∗
∗
∗
α
α
α
α
α
α
α
α
α
α
;
;
;
+
+
−
∗
∗
R
i R
i
R
2
α
α
. 	
(5.28)
Then the mathematical hologram can be computed as
	
αR
H
iH
H
iH
=
+
−
−
(
)
1
2
3
4
4. 	
(5.29)
To this hologram, a discrete transform that implements wave propagation 
from the hologram plane back to object is to be applied for reconstruction the 
object wavefront.
Numerical Algorithms for Hologram Reconstruction
As it is shown in the section “Imaging in Transform Domain and Diffraction 
Integrals,” for holograms recorded in far diffraction zone (Fourier holograms), 
wavefronts in object and hologram planes are linked through integral Fourier 
transform. Therefore, for reconstruction of Fourier holograms, DFT intro-
duced in the section “Discrete Representation of Fourier Integral Transform” 
are used in their FFT algorithmic implementation. Thanks to FFTs, the com-
putational complexity of reconstruction of Fourier hologram of N samples 
is of the order O(log2 N) per sample. Note that in cases of reconstruction of 
holograms of the same object recorded with different wavelength, such as 
in case of color holograms, reconstructed images will be scaled according to 
the wavelength. In order to compensate for the scaling and obtain images of 
the same size for different wavelengths, SDFT (the section “Discrete Fourier 
Transforms”) can be used. Images shown in Figure 5.14b and c are examples 
of reconstruction of holograms recorded in the far diffraction zone.
For holograms recorded in near diffraction zone, wavefronts in object 
and hologram planes are linked through Fresnel integral transform and, 
for especially small distances between the object and the hologram plane, 
by Kirchhoff’s integral (the section “Imaging in Transform Domain and 
Diffraction Integrals”). Correspondingly, for reconstruction of such holo-
grams, discrete Fresnel transforms listed in Table 4.1 and DKT computed via 
FFT (Equations 4.169 and 4.170) should be used depending on the value of 
the focusing parameter µ
λ
λ
2
2
2
=
=
Z N f
ZN SH
∆
, which connects the wave-
length of the object illumination λ, distance between the object and holo-
gram planes Z, the number of hologram samples N, the pitch of the hologram 
recording camera Δf, and the hologram physical size SH = ΔfN (see Section 
“Imaging in Transform Domain and Diffraction Integrals).
Specifically, canonical discrete Fresnel transform (CDFrT) implemented 
through shifted DFT and its versions described in the section “Canonical Discrete 
Fresnel Transform and Its Versions” provide aliasing-free reconstruction for 

247
Digital Image Formation and Computational Imaging
distances that are large enough to secure that μ2 ≥ 1, while the convolutional 
discrete Fresnel transform and discrete angular spectrum propagation trans-
form secure aliasing-free reconstruction for closer distances when μ2 ≤ 1. When 
μ2 = 1, all these transforms produce identical results. These two applicability 
zones are sketched in Figure 5.17.
Figure 5.18 illustrates the reconstruction of an off-axis near zone hologram 
using discrete Fresnel and focal plane invariant discrete Fresnel transforms 
(see also the MATLAB demo program FocPlaneVar_Invar_reconstr_illustr_
CRC.m provided in Exercises). One can see from the figure how focal plane 
invariant discrete Fresnel transform secures a stable position of the recon-
structed image for different object distances.
Figure 5.19 generated by the MATLAB program fourier_vers_conv_demo_
CRC.m provided in Exercises illustrates using canonical DFrT and convolu-
tion DFrT for numerical reconstruction at different distances of an on-axis near 
zone hologram recorded in four exposures by the phase-shifting method. One 
can see the appearance of aliasing artifacts, when canonical DFrT is used for 
image reconstruction out of the zone of its applicability μ2 ≥ 1, and that at dis-
tance, which corresponds to μ2 = 1, both transforms produce identical results.
The central images in each row in the figure are reconstructed using 
canonical DFrT from a hologram cropped to μ2-th fraction of its size. As one 
can see in the figure, this hologram cropping eliminates reconstruction arti-
facts for the canonical DFrT reconstruction.
Hologram
N samples;
camera
pitch Δf
Object plane, μ2 < 1
Fourier
reconstruction
algorithm,
reconstruction with
Object plane, μ2 > 1
Fourier reconstruction
algorithm, reconstruction
with aliasing
Object plane, μ2 < 1
Convolution
reconstruction
algorithm,
reconstruction
without aliasing
Object plane, μ2  = 1
Fourier and
convolution
reconstruction
algorithms:
reconstructions are
identical
Object plane, μ2 > 1
Convolution
reconstruction
algorithm,
reconstruction
with aliasing
Z
NΔf 2
N
N
N
λZ
μ2 =
FIGURE 5.17
Zones of applicability of different versions of discrete Fresnel transform.

248
Theoretical Foundations of Digital Imaging Using MATLAB®
(a)
(b)
Focal plane variant (left) and invariant (right) Fresnel hologram reconstruction; μ2 = 0.44
Object out of focus
Object in focus
Object in focus
Object out of focus
Focal plane variant (left) and invariant (right) Fresnel hologram reconstruction; μ2 = 0.36
(c)
FIGURE 5.18
​Reconstruction of an off-axis optical near zone hologram (a) on two different depth using 
canonical discrete Fresnel transform (left images (b), (c)) and focal plane invariant discrete 
Fresnel transform (right images (b), (c)). One can clearly see that the displacement of the center 
of symmetry of the reconstructed image is observed, when canonical DFrT is used for recon-
struction on different depths, and that the reconstructed image position is kept stable, when the 
focal plane invariant discrete Fresnel transform is used. Bright square spots in the images are 
zero-order diffraction images from dc-component of the hologram. They represent amplitude 
of the discrete frincd-function, 1D cross sections of which are shown in Figures 4.13 and 4.14.

249
Digital Image Formation and Computational Imaging
Hologram Pre- and Postprocessing
In the section “Principles of Hologram Electronic Recording,” we described 
idealized models of hologram recording. In reality, optical set-ups and holo-
gram recording devices always have certain deficiencies, which impair the 
quality of the reconstructed object amplitude and phase. For compensating 
of this impairment, the preprocessing of the hologram before applying to 
them, reconstruction algorithms and postprocessing of the reconstruction 
results are usually required.
Hologram preprocessing is aimed at correcting distortions of hologram in 
the process of recording. One of the major sources of hologram and recon-
structed wavefront distortions is imperfectness of the reference beam. Ideally, 
the reference beam used for recording holograms must have perfectly pla-
nar wavefront, or at least, the shape of the reference wavefront, that is, its 
amplitude and phase as functions of coordinates in the hologram plane must 
be precisely known. In reality, reference beams are never precisely planar 
(b)
(a)
Z = 33 mm; μ2 = 0.2439
Z = 83 mm; μ2 = 0.6618
Z = 136 mm; μ2 = 1
Aliasing artifacts
(c)
mm
z
0
1
2
3
(d)
FIGURE 5.19
​Comparison of reconstruction of near diffraction zone test hologram of an object (a) that consists 
of two hairs and a ruler placed at different distances. (b)–(d) In each row, that show images recon-
structed for different value of the focusing parameter μ2, the left image is reconstructed using 
canonical DFrT, the right image is reconstructed using convolutional DFrT, and the central image 
is reconstructed using canonical DFrT from the hologram cropped to μ2-th fraction of its size.

250
Theoretical Foundations of Digital Imaging Using MATLAB®
due to various technical limitations in constructing and adjustment of opti-
cal set-ups for hologram recording. Not precisely planar reference beams 
cause amplitude and phase modulation of the object wavefront, which results 
in aberrations in the reconstruction of object amplitude and phase profiles. 
These aberrations can be “inverse filtered” (see Chapter 8), if the amplitude 
and phase profiles of the reference beam are known. One method to achieve 
this is recording, in the same optical set-up but without the object, of an addi-
tional reference hologram. The principle of the “inverse filtering” is as follows. 
Having at hand two holograms, one recorded with the object and another one 
recorded, using the same reference beam, without the object, one can back 
propagate to the object plane wavefronts reconstructed from both holograms. 
Back propagation of the result of reconstruction of the initial hologram will 
reconstruct a product αobj(fx, fy)R*(fx, fy) of the object wavefront and reference 
beam wavefront described by the first term in Equation 5.20. Back propaga-
tion of the result of reconstruction of the reference hologram will reconstruct 
wavefront R(fx, fy) of the reference beam at the hologram plane. Dividing the 
former by the complex conjugate to the latter can obtain pure object wavefront 
αobj(fx, fy), which will reconstruct amplitude and phase profiles of the object, 
which will be free from aberration caused by a nonplanar reference beam. 
Of course, this method cannot allow for aberrations caused by mechanical 
vibrations or other instabilities of the optical set-up and additional hologram 
rectification might be required. This issue is currently a subject of intensive 
research, and interested readers are referred to relevant publications.
Yet another example of hologram pre-processing is eliminating zero-order 
diffraction term that is characteristic for reconstruction of off-axis holograms. 
This can be done by means of one or another methods of hologram high-pass 
pre-filtering (see also Chapter 8). One of simple methods is described in [7].
Among other sources of hologram distortion, one can mention imperfec-
tions of hologram recording devices that frequently introduce nonlinear dis-
tortions and random interferences into digitized holograms. Some particular 
examples of preprocessing of holograms for removing periodical noise and 
correcting nonlinear distortions and recording noise in holograms are given 
in the sections “MMSE-Optimal Linear Filters for Image Restoration” and 
“Correcting Image Gray-Scale Nonlinear Distortions” in Chapter 8.
Reconstructed wavefront postprocessing is aimed at further correcting 
distortions of hologram and other distortions, such as speckle noise, that 
may appear in the reconstruction results. The basics of methods for perfect-
ing results of hologram reconstruction are discussed in Chapter 8.
Point Spread Functions of Numerical Reconstruction of Holograms 
General Formulation
In numerical reconstruction of holograms, samples of the object wavefront 
are reconstructed out of samples of its recorded hologram using the discrete 
diffraction transforms. This process can be treated as sampling the object 

251
Digital Image Formation and Computational Imaging
wavefront by a sampling system that consists of the Hologram recording and 
sampling device and a computer, in which the object wavefront samples are 
numerically reconstructed from samples of the hologram.
Signal sampling is a linear transformation. As such, it is fully specified 
by  its PSF, which establishes a link between an object signal a(x) and its 
­samples {ak}:
	
a
a x PSF x k
x
k
X
= ∫( )
( , )
.
d
	
(5.30)
According to the sampling theory (see the section “Image Sampling”), 
for a given sampling interval Δx, the PSF of the ideal sampling device is a 
sinc-function:
	
PSF x k
x
k x
x
x
k x
x
x
k x
x
( , )
sinc
(
)
sin
(
)
(
)
.
=
−

=
−


−
π
π
π
∆
∆
∆
∆
∆
∆
	
(5.31)
In this section, we consider how PSFs of different reconstruction algorithms 
depend on algorithm parameters and on physical parameters of holograms 
and their sampling devices. For the sake of simplicity, we will consider 1D 
holograms and transforms. Corresponding 2D results are straightforward in 
the conventional assumption of the separability of sampling and transforms.
Let, in numerical reconstruction of holograms, samples {ak} of the object 
wavefront be obtained through a transformation
	
a
DRK r k
k
r
r
N
=
=
−
∑α
( , )
0
1
	
(5.32)
of available hologram samples {αr} with a certain discrete reconstruction 
kernel DRK (r, k), which corresponds to the type of the hologram. Also let 
samples {αr} of hologram α(f) that are measured by a hologram recording 
and sampling device be
	
α
α
φ
r
f
s
f
f
r f
f
=
−
−∞
∞
∫
( )
(
)
,
( )
∆
d
	
(5.33)
where φ f
s( )(.)
{
} is a PSF of the hologram sampling device, Δf is a hologram 
sampling interval, r
r
v s
=
+
( ), r is an integer index of hologram samples, and 
v is a shift, in units of the hologram sampling interval, of the hologram sam-
pling grid with respect to the hologram coordinate system; these sampling 

252
Theoretical Foundations of Digital Imaging Using MATLAB®
parameters are analogous to those illustrated, for signal and its Fourier spec-
trum sampling, in Figure 4.4.
The hologram signal α(f) is linked with object wavefront a(x) through a 
diffraction integral
	
α( )
( )
( , )
,
f
a x WPK x f
x
=
−∞
∞
∫
d
	
(5.34)
where WPK (x, f) is a wave propagation kernel. Therefore, one can rewrite 
Equation 5.33 as
	
α
ϕ
r
f
s
a x WPK x f
x
f
r f
f
a x
x
WPK
=








−
(
)
=
−∞
∞
−∞
∞
∫
∫
( )
( , )
( )
( )
d
d
d
∆
( , )
.
( )
x f
f
r f
f
f
s
ϕ
−
(
)
−∞
∞
−∞
∞
∫
∫
∆
d
	
(5.35)
Now insert Equation 5.35 into Equation 5.32 and establish a link between 
the object wavefront a(x) and its samples {ak} reconstructed from the sampled 
hologram:
a
a x
x
WPK x f
f
r f
f DRK r k
k
f
s
r
=
−
(
)








−∞
∞
−∞
∞
=
∫
∫( )
( , )
( , )
( )
d
d
φ
∆
0
1
0
1
N
r
N
f
s
a x
x
WPK x f
f
DRK r k
f
r f
−
−∞
∞
−∞
∞
=
−
∑
∫
∫
∑
=
−
(
( )
( , )
( , )
( )
d
d
φ
∆)








=
−∞
∞
∫a x OPSF x k
x
( )
( , )
.
d
	
(5.36)
where function
	
OPSF x k
WPK x f
f
DRK r k
f
r f
r
N
f
s
( , )
( , )
( , )
( )
=
−
(
)
−∞
∞
=
−
∫
∑
d
0
1
φ
∆
	
(5.37)
can be treated as an overall point spread function (OPSF) of numerical recon-
struction of holograms using discrete reconstruction kernel DRK (r, k). As 
one can see from Equation 5.37, OPSF depends on all factors involved in the 
process of sampling and reconstruction of holograms: wave propagation 

253
Digital Image Formation and Computational Imaging
kernel WPK (., .), discrete reconstruction kernel DRK (., .), PSF of the hologram 
sampling device φ f
s( )(.), and sampling interval Δf.
For further analysis, it is convenient to replace the PSF of the hologram 
sampling device by its Fourier transform, or its frequency response Φ f
s( )(.):
	
φ
ξ
π
ξ
ξ
ξ
f
s
f
s
f
s
f
r f
i
f
r f
( )
( )
( )
(
)
( )exp
(
)
( )exp(
−
=
−
[
]
=
−∞
∞
∫


∆
Φ
∆
Φ
2
d
−
−∞
∞
∫
i
r f
i
f
2
2
π
ξ
π ξ
ξ
∆
)exp(
)
.
d
	
(5.38)
Then obtain
	
αr
f
s
a x WPK x f
x
f
r f
f
a x
x
WPK
=








−
=
−∞
∞
−∞
∞
∫
∫
( )
( , )
(
)
( )
( )
d
d
d
φ
∆
( , )
(
)
.
( )
x f
f
r f
f
f
s
φ
−
−∞
∞
−∞
∞
∫
∫
∆d
	
(5.39)
Introduce function
	
PSF x
k
WPK x f
i
f
f
DRK r k
i
( , ; )
( , )exp(
)
( , )exp(
ξ
π ξ
=








−
−∞
∞
∫
2
2
d
π
ξ
ξ
ξ
r f
WPK x
DRK
k
r
N
∆
)
( , )
( , ),
=
−
∑








=
0
1
⋅
	
(5.40)
where
	
WPK x
WPK x f
i
f
f
( , )
( , )exp(
)
ξ
π ξ
=
−∞
∞
∫
2
d
	
(5.41)
is the Fourier transform of the wave propagation kernel WPK(., .) and
	
DRK
k
DRK r k
i
r f
r
N
( , )
( , )exp(
)
ξ
π
ξ
=
−
=
−
∑
2
0
1
∆
	
(5.42)

254
Theoretical Foundations of Digital Imaging Using MATLAB®
is a Fourier series expansion with samples of the discrete reconstruction ker-
nel DRK(r, k) as expansion coefficients.
The function PSF x
k
( , ; )
ξ
 does not depend on physical parameters of the 
hologram sampling device. It depends solely on wave propagation and dis-
crete reconstruction kernels. We will call this function PSF of sampled hologram 
reconstruction. OPSF of the numerical reconstruction of holograms OPSF(x, k) 
and PSF of sampled hologram reconstruction PSF x
k
( , ; )
ξ
 are linked through 
the integral transform
	
OPSF x k
PSF x
k
f
s
( , )
( )
( , ; )
( )
=
−∞
∞
∫Φ
ξ
ξ
ξ
d
	
(5.43)
with frequency response of the hologram sampling device as a transform 
kernel.
Point Spread Function of Numerical Reconstruction of Holograms Recorded 
in Far Diffraction Zone (Fourier Holograms)
Consider the PSF of numerical reconstruction of Fourier holograms. For 
far diffraction zone, wave propagation kernel is that of the integral Fourier 
transform:
	
WPK x f
i
xf
Z
( , )
exp
,
=
−




2π λ
	
(5.44)
where λ is object illumination wavelength and Z is the distance between object 
and hologram planes. Its Fourier transform WPK x
( , )
ξ  is a delta-function:
 
WPK x
WPK x f
i
f
f
i
f
x
Z
( , )
( , )exp(
)
exp
ξ
π ξ
π
λ
ξ
=
=
−
−








−∞
∞
∫
2
2
d

=
−




−∞
∞
∫
df
x
Z
δ λ
ξ .
	
(5.45)
Assume that shifted DFT with discrete reconstruction kernel
	
DRK r k
i
k
u r
v
N
( , )
exp
(
)(
)
=
+
+




2π
	
(5.46)

255
Digital Image Formation and Computational Imaging
defined in the section “Discrete Fourier Transforms” in Chapter 4 is used for 
the numerical reconstruction of Fourier holograms. As shown in Appendix, 
Fourier series expansion over this discrete reconstruction kernel is
DRK
k
DRK r k
i
r f
i
k
u r
v
N
r
N
ξ
π
ξ
π
,
,
exp
exp
(
)(
)
(
) =
(
)
−(
)
=
[
]
+
+
=
−
∑
2
2
0
1
∆




−
+
(
)


=
−
+
−




=
−
∑
exp
exp
( )
( )
i
r
v
f
i
v
N
s
r
N
s
2
2
1
2
0
1
π
ξ
π
∆





+
+
−










−
+


∆
∆
f
i
k
u
N
v
N
N
f
k
u
N
ξ
π
π
ξ
exp
(
)
sin
2
1
2
×






−
+








sin
.
π
ξ
∆f
k
u
N
	
(5.47)
In order to eliminate pure phase exponential multiplicands in Equation 
5.47, one can choose shift parameters V(s) of sampling and v of the reconstruc-
tion transform as
	
v
v
N
s( )
.
=
= −
−1
2
	
(5.48)
With these shift parameters
DRK
k
f
k
u
N
N
f
k
u
N
ξ
π
ξ
π
ξ
,
sin
sin
(
) =
−
+








−
+








∆
∆
=
−
+








N
N
f
k
u
N
N
sin
;
cd
π
ξ
∆

(5.49)
and
	
PSF x
k
WPK x
DRK
k N
N
f
k
u
N
N
, ;
( , )
( , )
sin
;
ξ
ξ
ξ
π
ξ
δ
(
) =
−
+








cd
∆
x
Z
λ
ξ
−



.
	
(5.50)

256
Theoretical Foundations of Digital Imaging Using MATLAB®
Then obtain finally that the OPSF of numerical reconstruction of Fourier 
hologram is
 
OPSF x k
PSF x
k
N
N
fx
Z
k
u
N
f
s
( , )
( )
( , ; )
sin
;
( )
=
=
−
+



−∞
∞
∫Φ
∆
ξ
ξ
ξ
π
λ
d
cd





−




=
−
+


−∞
∞
∫
N
x
Z
N
N
fx
Z
k
u
N
f
s
Φ
∆
( )( )
sin
;
ξ δ λ
ξ
ξ
π
λ
d
cd











=
−
+
N
x
Z
N
N
x
k
u
x
x
x
f
s
f
s
Φ
∆
∆
Φ
( )
( )
sin
; (
(
)
)
λ
π
cd[
]
/
λZ



,
	
(5.51)
where
	
∆
∆
x
Z N f
Z SH
=
=
λ
λ
	
(5.52)
is an efficient object wavefront sampling interval and
	
S
N f
H =
∆	
(5.53)
is the physical size of the sampled hologram.
Formula 5.51 has a clear physical interpretation illustrated in Figure 5.20.
The figure shows two multiplicands defining OPSFs of numerical recon-
struction of holograms digitally recorded in the far diffraction zone: discrete 
sinc-function (solid line) and frequency responses of the ideal sampling 
device (shown by dots) and of digital cameras (dotted lines) for two different 
camera fill-factors, or the ratio of the size of camera-sensitive elements to the 
interpixel distance (camera pitch).
As it was mentioned, the PSF of the ideal signal sampling device is a sinc-
function and its frequency response is a rect-function. Provided the holo-
gram sampling device is such an ideal sampler with frequency response
	
Φ
∆
∆
∆
∆
f
s
x
Z
x
z
f
f
Z
Z
f
x
Z
f
( )
,
λ
λ
λ
λ
λ



=
+



=
−
≤
≤
rect
/
/
/
/
2
1
2
2
0,
otherwise,



	
(5.54)
the OPSF of numerical reconstruction of the Fourier hologram is a discrete sinc-
function, and object wavefront samples are measured within the spatial inter-
val defined by the spread [−λZ/2Δf ≤ x ≤ λZ/2Δf] of the hologram sampling 

257
Digital Image Formation and Computational Imaging
device frequency response. Therefore, with the ideal hologram sampler, 
numerical reconstruction of Fourier hologram is almost ideal object wavefront 
sampling, as the discrete sinc-function approximates continuous sinc-function 
within the interval −λZ/2Δf ≤ x ≤ λZ/2Δf relatively close, the approximation 
being the closer, the larger is the number of hologram samples N.
In reality, hologram sampling devices are, of course, not ideal samplers, 
and their frequency responses are not rectangular functions. They are rather 
not uniform within the basic object extent interval −λZ/2Δf ≤ x ≤ λZ/2Δf and 
decay not abruptly outside this interval but quite gradually. As a consequence, 
each of the object samples is a combination of the sample, measured by the 
main lobe of the discrete sinc-function within the basic object extend interval 
and samples collected by other lobes of the discrete sinc-function outside the 
basic interval, which may cause aliasing artifacts. It is one source of the mea-
surement errors. In particular, for diffusely reflecting objects, it may result 
in an additional speckle noise in the reconstructed object image. One can 
avoid this distortion if, in the process of making object hologram, the object 
is illuminated strictly only within the basic interval [−λZ/2Δf ≤ x ≤ λZ/2Δf] 
defined by the hologram sampling interval (camera pitch).
1
Frequency
response of the
hologram
sampling device
(Fill factor = 0.9)
Frequency
response of the
hologram ideal
sampling device
Frequency
response of the
hologram
sampling device
(Fill factor = 0.45)
0.8
0.6
0.4
0.2
0
–0.2
–3
–2
–1
0
NΔx = λZ/Δf
1
2
3
FIGURE 5.20
​Components of OPSF of numerical reconstruction of holograms digitally recorded in far dif-
fraction zone. Thin gray solid line represents the discrete sinc-function. Bold dots are samples 
of the continuous sinc-function, the ideal sampling PSF, to compare it with the discrete sinc-
function. Bold rectangle is the frequency response of the hologram ideal sampling device. 
Dotted lines are frequency responses of real hologram sampling devices, digital cameras with 
fill factors 0.9 and 0.45.

258
Theoretical Foundations of Digital Imaging Using MATLAB®
The second source of reconstruction errors is associated with nonunifor-
mity of the hologram sampler frequency response within the basic interval. 
These errors can be compensated by multiplying the reconstruction results 
by a function inverse to the frequency response of the hologram sampler 
Φ f
s x
Z
( )( /
)
λ
.
One can also see from Equations 5.51 and 5.52 that the resolving power 
of numerical reconstruction of Fourier hologram is determined by the 
­distance Δx between zeros of the discrete sinc-function, which is equal to 
λZ/NΔf = λZ/SH. Due to this finite resolving power, one can also expect, for 
diffuse objects, a certain amount of speckle noise in the reconstructed image 
(see the section “Speckle Noise Model”).
Point Spread Function of Numerical Reconstruction of Holograms Recorded 
in Near Diffraction Zone (Fresnel Holograms)
For near diffraction zone, wave propagation kernel is, to the accuracy of an 
irrelevant constant multiplicand
	
WPK x f
i
x
f
Z
( , )
exp
(
)
.
=
−




π
λ
2
	
(5.55)
Its Fourier transform is
	
WPK x
i
x
f
Z
i
f
f
i
x
( , )
exp
(
)
exp(
)
exp(
)
exp
ξ
π
λ
π ξ
π ξ
=
−




=
−∞
∞
∫
2
2
2
d
i
p
Z
i
p
f
π λ
π ξ
2
2




−
−∞
∞
∫
exp(
)d
	
(5.56)
or, with an account of the relationship between chirp-function and its Fourier 
spectrum (Equation 4.156),
	
WPK x
i
x
i
Z
( , )
exp(
)exp(
)
ξ
π ξ
πλ ξ
=
−
2
2
	
(5.57)
again to the accuracy of an irrelevant constant multiplicand omitted. In what 
follows, we will separately consider the PSF for hologram reconstruction 
using two complementing discrete representations of Fresnel integral trans-
form, canonical and convolutional discrete Fresnel transforms described 
in the sections “Canonical Discrete Fresnel Transform and Its Versions” 
and “Convolutional Discrete Fresnel and Angular Spectrum Propagation 

259
Digital Image Formation and Computational Imaging
Transforms.” For simplicity’s sake, zero shifts of sampling grids will be 
assumed in both hologram and object wavefront domains.
Fourier Reconstruction Algorithm
In the Fourier reconstruction algorithm, implemented with canonical DFrT, dis-
crete reconstruction kernel is, with zero shifts of sampling grids in hologram 
and object wavefront domains
	
DRK r k
i
k
N
i
kr
N
i
r
N
( , )
exp
exp
exp
=
−












−
π
µ
π
π µ
2
2
2
2
2



.
	
(5.58)
For this kernel, the Fourier series expansion defined by Equation 5.42 is
	
DRK
k
i
k
N
i
r
N
i
kr
N
( , )
exp
exp
exp
ξ
π
µ
π µ
π
=
−




−








2
2
2
2
2
r
N
s
i
r f
i
k
N
i
r
N
=
−
∑
−(
)
=
−




−




0
1
2
2
2
2
2
exp
exp
exp
( )
π
ξ
π
µ
π µ
∆

−








=
−




=
−
∑
exp
exp
fri
( )
i
r
k
N
f
i
k
N
s
r
N
2
0
1
2
2
π
ξ
π
µ
∆
ncd
;
;
.
N
f
k
N
−
−




1
2
/µ
ξ
∆
	
(5.59)
Then, obtain that the PSF of sampled hologram reconstruction is
	
PSF x
k
WPK x
DRK
k
i
x
i
Z
i
k
( , ; )
( , )
( , )
exp(
)exp(
)exp
ξ
ξ
ξ
π ξ
πλ ξ
π
=
−
−
⋅
∝
2
2
2
2
2
1
µ
µ
ξ
N
N
f
k
N




−
−




frincd
;
;
/
∆

(5.60)
and that the OPSF of numerical reconstruction of Fresnel holograms with 
Fourier reconstruction algorithm is
	
OPSF x k
i
k
N
i
Z
f
s
( , )
exp
( ) exp(
)
( )
=
−




−
−∞
∞
∫
π
µ
ξ
πλ ξ
2
2
2
Φ
 
 
frin
×
cd
d
N
f
k
N
i
x
;
;
exp(
)
.
−
−




1
2
2
/µ
ξ
π ξ
ξ
∆
	
(5.61)

260
Theoretical Foundations of Digital Imaging Using MATLAB®
Equation 5.60 is much more involved for an analytical treatment than the 
corresponding equation for OPSF of numerical reconstruction of Fourier 
holograms and, in general, requires numerical methods for analysis. In order 
to facilitate its interpretation, rewrite Equation 5.60 using Equation 5.58 for 
DRK
k
( , )
ξ
:
OPSF x k
i
x
Z
k
N
f
s
r
N
,
exp
( )
exp
( )
(
) =
−












=
−
∑
π λ
µ
ξ
2
2
2
0
1
 
Φ
−




−








−
−
−∞
∞
∫
i
r
N
i
r
k
N
f
i
x
Z
π µ
π
ξ
π
λ ξ
2
2
2
× exp
exp
(
)
∆
2
2
2
2
2
2
λ
π λ
µ
π µ
Z
i
x
Z
k
N
i
r
N




−












−




exp
exp
e
×
xp
( )exp
(
)
e
( )
i
kr
N
i
x
Z
Z
r
N
f
s
2
0
1
2
π
ξ
π
λ ξ
λ




−
−




×
=
−
−∞
∞
∑
∫Φ
xp(
)
.
−i
r f
2π
ξ
ξ
∆
d
	
(5.62)
Assume now that the frequency response of the hologram sampling device 
Φ f
s( )( )
ξ  is a constant, which is equivalent to the assumption that its PSF is a 
delta-function. Practically, this means that the hologram recording photo-
graphic camera is assumed to have a very small fill-factor. In this simplifying 
assumption, obtain (see Appendix)
 
OPSF x k
i
x
Z
k
N
N
N f
Z
f
,
exp
frincd
;
;
(
) =
−










−
π λ
µ
µ
λ
2
2
2
2
2
1
∆
∆x
Z
k
N
λ
−



.
	
(5.63)
As one can see from this equation, OPSF of numerical reconstruction of 
Fresnel holograms recorded using cameras with very small fill-factor is 
just proportional to the frincd-function defined in the section “Invertibility 
of Discrete Fresnel Transforms and frincd-Function” (Equations 4.154 and 
Figures 4.14 and 4.15). Obviously, the major interest represents a special case 
of  “in focus” reconstruction, when
	
µ
λ
2
2
=
Z
N f
∆
.
	
(5.64)
In this case, numerical reconstruction PSF is the discrete sinc-function

261
Digital Image Formation and Computational Imaging
 
OPSF x k
i
Z
f
f x
Z
k
N
N
f x
,
exp
sincd
;
(
) =
−












λ
λ
π
∆
∆
∆
2
2
2
2
2
2
2
λ
λ
λ
Z
k
N N
i
Z
f
f x
Z
k
N
−








=
−












exp
s
∆
∆
2
2
2
2
2
2
2
incd
; (
)
.
N
x
k x
x
π
−


∆
∆
	
(5.65)
where Δx = λZ/NΔf = λZ/SH. As one can see, “in focus” reconstruction OPSF 
is essentially the same as that for numerical reconstruction of Fourier holo-
grams (Equation 5.51) for the same assumption regarding the hologram 
sampling device. It has the same resolving power and provides aliasing free 
object reconstruction within the interval So = λZ/Δf.
One can establish a link between the size of this interval and the value 
µ
λ
λ
2
2
2
=
=
Z N f
N Z SH
/
/
∆
 of the focusing parameter required for the 
reconstruction:
	
S
Z
f
ZN S
S
o
s
H
H
=
=
=
( )
λ
λ
µ
∆
2
.	
(5.66)
From this relationship, it follows that aliasing free reconstruction of the 
object from a hologram recorded on a distance defined by the focusing param-
eter μ2 is possible if the object size does not exceed the value μ2 SH. Therefore, 
for μ2 < 1, allowed object size should be less than the hologram size, other-
wise the aliasing caused by the periodicity of the discrete sinc-function will 
appear. This is, in particular, what Figures 5.17 and 5.19 illustrate.
Convolution Reconstruction Algorithm
In the convolutional reconstruction algorithm, convolutional discrete Fresnel trans-
form is used for hologram reconstruction, and discrete reconstruction kernel is, 
with zero shifts of sampling grids in hologram and object wavefront domains,
	
DRK r k
N
k
r
N
i
s
N
i
s
N
,
frincd
;
;
exp
exp
(
) =
−
(
) =




−
=
−
∑
µ
π µ
π
2
2 2
0
1
1
2
k
r s
N
−
(
)



.
	
(5.67)
The Fourier series expansion defined by Equation 5.42 for this kernel is
DRK
k
N
i
s
N
i
k
r s
N
i
r f
( , )
exp
exp
(
)
exp(
ξ
π µ
π
π
=




−
−




−
1
2
2
2 2
∆ξ
π µ
π
π
)
exp
exp
exp
s
N
r
N
N
i
s
N
i
ks
N
i
=
−
=
−
∑
∑
=




−




0
1
0
1
2 2
1
2
2 r
s
N
f
r
N
s
N
−








=
−
=
−
∑
∑
∆ξ
0
1
0
1
.
	
(5.68)

262
Theoretical Foundations of Digital Imaging Using MATLAB®
Then, obtain that the PSF of sampled hologram reconstruction is (see 
Appendix)
PSF x
k
WPK x
DRK
k
i
x
i
Z
N
i
( , ; )
( , )
( , )
exp(
)exp(
)
exp
ξ
ξ
ξ
π ξ
πλ ξ
π
=
−
⋅
∝
×
2
2
µ
π
π
ξ
2 2
0
2
2
s
N
i
ks
N
i
r
s
N
f
r
N




−




−








=
−
exp
exp
∆
1
0
1
∑
∑
=
−
s
N
(5.69)
and that OPSF of numerical reconstruction of Fresnel holograms with 
Fourier reconstruction algorithm is
	
OPSF x k
i
Z
i
x
i
s
N
f
s
( , )
( )exp(
)exp(
)
exp
( )
∝
×
Φ
ξ
πλ ξ
π ξ
ξ
π µ
−
−
−∞
∞
∫
2
2 2
2
d




−




−
(
)


=
−
∑
exp
sincd
;
.
i
ks
N
N
s
N f
s
N
2
0
1
π
π
ξ
∆
	
(5.70)
At least one important property can be immediately seen from Equation 
5.70, that of periodicity of the OPSF over object sample index k with a period 
N. As, by the definition of the convolutional Fresnel transform, sampling 
interval Δx in the object plane is identical to the hologram sampling interval 
Δf, this periodicity of the PSF implies that object wavefront is reconstructed 
within the physical interval NΔx = NΔf = SH, where SH is the physical size of 
the hologram. Further detailed analysis is not feasible without bringing in 
numerical methods. Some results of such a numerical analysis are illustrated 
in Figure 5.21.
The top and middle plots in the figure reveal, in particular, that, though 
object sampling interval in the convolution method is set to be equal to 
the hologram sampling interval, the resolving power of the method is still 
defined by the same fundamental value λZ/SH as that of the Fourier recon-
struction algorithm and of the Fourier reconstruction algorithm for Fourier 
holograms. One can clearly see this when one compares the width of the 
main lobe of the PSF in Figure 5.21, the top plot, with the distance between 
vertical ticks, which indicate object sampling positions, and from observ-
ing in the middle plot in Figure 5.21, three times widening of the width of 
the main lobe of PSF that corresponds to the object-to-hologram distance 
parameter μ2 = 0.45 (PSF15) with respect to that for μ2 = 0.15 (PSF5). The bot-
tom plot in Figure 5.21 shows a result of reconstruction of nine point sources 
placed uniformly within the object size. The plot vividly demonstrates that 
the hologram sampling device point function acts very similar to its action 
in the case of the Fourier reconstruction algorithm and of reconstruction of 
Fourier holograms: it modulates the reconstruction result with a function 

263
Digital Image Formation and Computational Imaging
0.8
0.6
0.4
0.2
0
–0.2
1
0.8
0.6
0.4
0.2
0
–0.2
0.8
0.6
0.4
0.2
0
–0.2
0.085
0.095
0.105
0.115
0.125
0.135
0.145
0.155
0.165
0.175
PSF5
PSF15
0.96
0.97
0.98
0.99
1
1.01
1.02
1.03
1.04
0.1
0.3
0.2
0.4
0.5
0.6
0.7
0.8
0.9
1
FIGURE 5.21
​Point spread functions of the convolution algorithm: top—central lobe of OPSF shown along 
with boundaries of object sampling interval indicated by vertical ticks; middle—central lobes 
of OPSF of reconstructions for two distances between object and hologram (PSF5 and PSF15); 
bottom—reconstruction result for 9-point sources placed uniformly within object area.

264
Theoretical Foundations of Digital Imaging Using MATLAB®
close to its Fourier transform, the frequency response of the hologram sam-
pling device.
The finite width of the reconstruction algorithm PSFs not only limits the 
reconstruction resolving power, but also causes speckle noise in the recon-
struction of diffuse objects for the same reason that was mentioned above 
in the discussion of OPSF of reconstruction of Fourier holograms. This phe-
nomenon is illustrated in Figure 5.22, which compares reconstructions of 
intensity of nondiffuse and diffuse objects with intensity profiles in the form 
of a rectangular impulse.
Computer-Generated Display Holography
3D Imaging and Computer-Generated Holography
The inventions in holography by E. Leith and Yu. Denisyuk [10,11] were pri-
marily motivated by the desire to create an efficient means for visualizing 
3D images. Indeed, holographic imaging is an ultimate solution for 3D visu-
alization. This is the only method that is capable of reproducing, in the most 
natural viewing conditions, 3D images that have all the visual properties of 
the original objects.
3D visual communication and display can be achieved through generating, 
at the viewer site, of holograms out of data that contain all relevant informa-
tion regarding the scene to be viewed. Digital computers equipped with ded-
icated devices for fabricating holograms are ideal means for converting data 
on 3D scenes into optical holograms for visual perception. The core of the 3D 
digital holographic visual communication paradigm is the understanding 
80
60
40
20
0.1
0.2
0.3
0.4
0.5
Object coordinate
Nondiffuse object
Diffuse object
Object wavefront intensity
0.6
0.7
0.8
0.9
1
FIGURE 5.22
​Results of computer simulation of reconstruction, by the convolution algorithm, of a Fresnel 
hologram of nondiffuse and diffuse objects with intensity profiles in form of a rectangular 
impulse that demonstrate appearance of heavy speckle noise for the diffuse object.

265
Digital Image Formation and Computational Imaging
that, for generating synthetic holograms at the viewer site, one does not need 
to produce, at the scene site, the hologram of the scene and to transmit it to 
the viewer’s site. Neither does one need to necessarily imitate, at the viewer 
site, the full optical holograms of the scene. What one does need is to collect, 
at the scene site, a set of data that will be sufficient to generate, at the viewer 
site, a synthetic hologram of the scene that fits visual mechanisms for 3D 
perception.
The crucial issues in collecting, storing, and transmitting the data needed 
for the synthesis, at the viewer site, of display holograms are the volume of 
the required data and the computational complexity of the hologram syn-
thesis. The upper bound of the amount of the data needed for the synthesis 
of display hologram’s viewer site is the full volumetric description of the 
scene geometry and optical properties. However, a realistic estimation of the 
amount of data needed for generating a display hologram of the scene is by 
orders of magnitude lower than this upper bound due to the limitations of 
the human visual system. This also has a direct impact on the computational 
complexity of the hologram synthesis.
One of the most promising solutions for the synthesis of computer-
generated display holograms, which are computationally inexpensive 
and at the same time are sufficient for granting 3D visual sensation, is 
generating compound multiple-view holograms. In this method, the scene to 
be viewed is represented by means of multiple-view images taken from 
different directions in the required view angle, and, for each image, its 
corresponding hologram is synthesized with an account of its position in 
the viewing angle (see Figure 5.23).
The mosaic of appropriately arranged elementary holograms forms a com-
pound multiple-view hologram. This hologram, when viewed with two eyes, 
will reconstruct different aspects of scenes from different directions deter-
Object
Compound hologram: a 2D
mosaic of Mx × My
elementary holograms of
Nx × Nv samples
Elementary hologram. Te size of
elementary hologram should be
commensurable with the size of the eye
pupil (3–5 mm in diameter);
N = O (1000) samples
FIGURE 5.23
​Principle of the synthesis of compound multiple-view holograms.

266
Theoretical Foundations of Digital Imaging Using MATLAB®
mined by the position of the viewer. The physical size of each hologram has 
to be, approximately, of the size of the viewer’s eye pupil.
Figure 5.24 illustrates viewing a computer-generated multiple-view com-
pound hologram. The hologram is composed of 900 elementary holograms 
of 256×256 pixels and contains 30×30 views, in spatial angle −90° ÷ 90°, of 
an object in the form of a cube. Being illuminated by a small LED lamp, the 
hologram can be used for viewing the reconstructed scene from different 
angles. Looking through the hologram with two eyes, viewers are able to see 
3D image of a cube (Figure 5.24b) floating in the air.
For computing elementary holograms, discrete Fourier and discrete Fresnel 
transforms, which represent wave propagation integral transforms, can be 
used. The computational complexity of the synthesis of composite holograms 
can be estimated as follows. If individual images have Nx × Ny-pixels, the com-
plexity of the synthesis of elementary holograms with the use of FFTs is of the 
order of Nx Ny log Nx Ny operation. Therefore, the computational complex-
ity of the synthesis of the composite hologram composed of Mx × My elemen-
tary holograms is of the order MxMyNxNy log NxNy operations. Note that the 
computational complexity of generating a single hologram of the same size is 
O(MxMyNxNy log MxMyNxNy), which is 1 + log MxMy/log NxNy times higher.
Recording Computer-Generated Holograms on Optical Media
Apparently, the major problem in computer-generated holography is not the 
computational complexity but rather the problem of converting digital data 
into a physical hologram. To perform this task, computer-controlled spatial 
light modulators (SLM) are needed.
Figure 5.25 illustrates computer-generated hologram recorded on an SLM 
and related definitions. The most important numerical characteristics of SLMs 
are the total number of cells, which can be exposed, sampling intervals, that is, 
FIGURE 5.24
Viewing compound computer-generated hologram (a) and one of the views reconstructed 
from the hologram (b).

267
Digital Image Formation and Computational Imaging
the distances Δξ and Δη between neighboring separately and independently 
exposed resolution cells, and recording aperture, that is, PSF of the recorder.
Computer-generated holograms are arrays of complex number {Γr,s} that rep-
resent hologram samples. For recording holograms, these samples should be 
appropriately encoded for recording according to the type of SLM. SLMs for 
recording computer-generated holograms can be classified into three catego-
ries: amplitude-only SLM, phase-only SLM, and combined amplitude/phase SLM.
Obviously, the most suitable for recording computer-generated holograms 
would be combined SLM that permit independent control of both the inten-
sity and the phase transmittance or reflectance of the resolution cells by, 
correspondingly, amplitudes {|Γr,s|} and phases {θr,s} of hologram samples 
represented as {Γr, s = |Γr, s|exp(iθr, s)}.
In amplitude-only SLMs, the controlled optical parameter is their light 
intensity transmission or reflection factor in each resolution cell. Typical 
examples of amplitude SLMs are the photographic films used in photography 
and optical holography. Photographic media have relatively high resolution 
and dynamic range. However, they have substantial drawbacks: they require 
wet chemical development, and are not reversible. Recently, microlens array 
and micromirror array technology emerged and reports were published on 
using them as amplitude SLM for recording computer-generated holograms.
For recording holograms on amplitude SLMs, samples {Γr,s} can be pre-
sented as an additive combination of numbers with a certain fixed phase. 
Specifically, the following three forms of such representation can be used:
• Orthogonal representation
	
Γ
Γ
Γ
Γ
Γ
r s
r s
r s
r s
r s
i
i
,
,
,
,
, exp(
),
=
+
=
+
re
im
re
im
π 2 	
(5.71)
	
	 where Γr s,
re  and Γr s,
im are real and imaginary parts of Γr,s.
Recorded hologram
Recording
apertures
ξ
Outline of the hologram
window function w(ξ,η)
η
Δη
Δξ
FIGURE 5.25
​Computer-generated hologram recorded on an SLM and related definitions.

268
Theoretical Foundations of Digital Imaging Using MATLAB®
• Biorthogonal representation
Γ
Γ
Γ
Γ
Γ
r s
r s
r s
r s
r s
i
,
,
,
,
, exp(
)
=
+
(
)
+
+
(
)
+
1
2
1
2
2
1
sign
sign
re
im
im
re
π
−
(
)


( ) +
−
(
)


sign
sign
re
re
im
re
Γ
Γ
Γ
Γ
r s
r s
r s
r s
i
,
,
,
,
exp
2
1
2
π
exp(
),
i3
2
π
	
(5.72)
	
where
	
sign( )
,
,
,
.
x
x
x
x
=
>
=
−
<




1
0
0
0
1
0
• Simplex representation
	
Γ
Γ
Γ
Γ
r s
r s
r s
r s
i
i
,
,
( )
,
(
)
,
(
)
exp
exp(
),
=
+
(
) +
−
−
0
120
120
2
3
2
3
π
π
	
(5.73)
	
where Γr s,
( )
0 , Γr s,
(
)
120 , and Γr s,
(
)
−120  are projections of Γr,s treated as a vector 
on a complex plane to vectors exp(i0), exp(i2π/3), and exp(−i2π/3), 
respectively. Note that Γ r s,
( )
0 , Γ r s,
(
)
120 , and Γ r s,
(
)
−120  are nonnegative num-
bers and, for each Γr,s, one of it is equal to zero depending on which 
part of the complex plane bounded by vectors exp(i0), exp(i2π/3), 
and exp(−i2π/3) it belongs.
With these representations through real (Equation 5.71) or three (Equation 
5.73) or four (Equation 5.72) nonnegative numbers, samples Γr,s of holograms 
can be recorded on amplitude SLM using two, three, or four SLM resolution 
cells per each hologram sample.
Phase-only SLMs modulate the phase of optical beams. The most suit-
able for computer-controlled recording holograms are recently emerged 
liquid crystal SLMs. For recording holograms on phase SLM, samples 
Γ
Γ
r s
r s
r s
i
,
,
,
exp
=
(
)
{
}
θ
 can be presented as an additive combination of num-
bers with fixed amplitude and appropriately selected phases:
	
Γr s
r s
q
q
Q
A
i
,
,
( )
exp
.
=
(
)
=∑
0
1
φ
	
(5.74)
Only cases Q = 2 and Q = 3 represent a practical interest. For Q = 2, one can 
obtain

269
Digital Image Formation and Computational Imaging
	
φ
θ
φ
θ
r s
r s
r s
r s
r s
r s
A
A
,
( )
,
,
,
( )
,
,
arccos
;
arccos
.
1
0
2
0
2
2
=
+
(
)
=
−
(
)
Γ
Γ
	 (5.75)
For Q = 3
	
φ
θ
φ
θ
φ
θ
r s
r s
r s
r s
r s
r s
r
,
( )
,
,
,
( )
,
,
( )
arcsin
;
1
2
3
2
3
2
1
3
=
−
−




=
=
Γ
,
,
arcsin
.
s
r s
−
−




2
3
2
1
3
Γ
	
(5.76)
With these representations, hologram samples {Γr,s} can be recorded on 
phase SLMs using two or three of the SLM resolution cells.
An important special case of recording display holograms on phase SLMs 
is the kinoform method. With this method, only phases {θr,s} of hologram sam-
ples are recorded and amplitudes are ignored. The advantage of this method 
is the high diffraction efficiency of the kinoform hologram: they do not 
absorb light used for hologram reconstruction. However, ignoring of ampli-
tudes of hologram samples results in substantial distortions of reconstructed 
image. As we already mentioned in the section “Quantization in Digital 
Holography,” these distortions can be minimized by means of assigning to 
object wavefront a specially optimized pseudorandom phase. Holograms 
shown in Figure 5.24a were recorded by the kinoform method.
A more detailed review of methods for hologram encoding for recording 
can be found in [12].
Optical Reconstruction of Computer-Generated Holograms
At the reconstruction stage, computer-generated holograms synthesized 
with the use of discrete representations of wave propagation transforma-
tions described in Chapter 4 are subjected to analog optical transformations 
in reconstruction optical set-ups such as those shown in Figure 5.26.
The effects of discretization of optical transforms, methods of encod-
ing mathematical holograms into physical holograms and parameters of 
recorded holograms such as the number of hologram samples, hologram 
sampling intervals, and PSF of the hologram recording device influence the 
hologram reconstruction result. In this section, we will demonstrate this 
influence on an example of analysis of optical reconstruction of holograms 
recorded by the kinoform method.
Let
	
Γr s
k l
l
N
A
i
k
u r
p
N
l
v s
q
N
,
, exp
(
)(
)
(
)(
)
=
+
+
+
+
+










=

2
1
2
0
2
π
−
=
−
∑
∑
1
0
1
1
k
N
	
(5.77)

270
Theoretical Foundations of Digital Imaging Using MATLAB®
be samples of the mathematical Fourier phase only hologram generated 
through SDFT(u,v;p,q) from N1 × N2 of object wavefront samples {
}
,
Ak l  modi-
fied, using optimized pseudorandom diffuser described in the section 
“Quantization in Digital Holography,” so as to produce a phase-only holo-
gram. The resulting kinoform hologram recorded, with sampling intervals 
(Δξ, Δη), by a hologram recorder with PSF hrec (ξ, η) on a rectangular sampling 
grid along coordinates (ξ, η) can be, in denotations of Figure 5.25, written as
	
Γ
Γ
∆
∆
ξ η
ξ η
ξ
ξ
ξ η
η
η
,
,
,
,
,
(
) =
(
)
−
−
−
−
(
)
∑
∑
w
h
r
s
r s
s
r
rec
0
0
	
(5.78)
where (ξ0, η0) are shift parameters that depend on the geometry of position-
ing the hologram in the reconstruction set-up, w(ξ, η) is a window function 
that defines the physical size of the recorded hologram: 0 < w (ξ, η) ≤ 1, when 
(ξ, η) belong to the hologram area and w(ξ, η) = 0, otherwise.
At the reconstruction stage, the kinoform is to be subjected to optical 
Fourier transform in a reconstruction optical set-up to reconstruct an image
 
A
x y
i
x
y
Z
w
rcnstr( , )
( , )exp
( ,
=
−
+




=
−∞
∞
−∞
∞
∫∫
Γ ξ η
π ξ
η
λ
ξ η
ξ η
2
d d
)
(
,
)
exp
,
Γ
∆
∆
r s
s
r
h
r
s
i
x
rec ξ
ξ
ξ η
η
η
π
−
−
−
−








−
∑
∑
∫∫
−∞
∞
−∞
∞
0
0
2
×
ξ
η
λ
ξ η
+




y
Z
d d .
	
(5.79)
Reconstructing light beam
(a)
(b)
Reconstructed image
Hologram
Hologram
Observer
Fourier lens
Point source of the 
reconstructing light
FIGURE 5.26
​Set-ups for optical (a) and visual (b) reconstruction of computer-generated Fourier holograms.

271
Digital Image Formation and Computational Imaging
Replace in Equation 5.79 the hologram window function w(ξ, η) by its 
expression
	
w
W
i
Z
( , )
,
exp
ξ η
ξ η
π ξξ
ηη
λ
ξ η
=
(
)
+




−∞
∞
−∞
∞
∫∫
2
d d
	
(5.80)
through its Fourier spectrum W ξ η
,
(
) and obtain (see Appendix)
A
x y
W
i
Z
rcstr( , )
,
exp
 
d d
=
(
)
+




−∞
∞
−∞
∞
−∞
∞
−∞
∞
∫∫∫∫
ξ η
π ξξ
ηη
λ
ξ η
2
×
−
−
−
−
(
)
×
−
+




∑
∑
Γ
∆
∆
r s
s
r
h
r
s
i
x
y
Z
,
,
exp
rec ξ
ξ
ξ η
η
η
π ξ
η
λ
ξ
0
0
2
 d dη
π
v
A
i
k
u
N
p
l
v
N
q
k l
l
N
k
N
=
+
+
+








×
=
−
=
−
∑
∑
, exp
0
1
0
1
1
2
2
1
2
2
H
k
u
N
do
Z
l
v
N
do
Z
x
y
doy
rec
+
+




+
+








=−∞
∞
∑
1
2
λ
ξ
λ
η
∆
∆
,
do
x
y
x
W x
k
u
N
Z
do
Z y
l
v
N
Z
do
Z
=−∞
∞
∑
×
−
+
−
−
+
−




1
2
λ
ξ
λ
ξ
λ
η
λ
η
∆
∆
∆
∆
;
.
	
(5.81)
Selecting SDFT shift parameters p = 0 and q = 0, obtain finally
A
x y
A H
k
u
N
do
Z
l
v
N
do
k l
x
y
rcstr
rec
( , )
,
,
=
+
+




+
+






1
2
λ
ξ
λ
∆
Z
W x
k
u
N
do
do
do
l
N
k
N
x
y
x
∆η




×
−
+
+


=−∞
∞
=−∞
∞
=
−
=
−
∑
∑
∑
∑
0
1
0
1
1
2
1


−
+
+








=
λ
ξ
λ
η
Z y
l
v
N
do
Z
A
x do
y do
y
k l
x
y
oy
∆
∆
;
( ,
; ,
)
,
2

d
=−∞
∞
=−∞
∞
∑
∑
dox
,
	
(5.82)

272
Theoretical Foundations of Digital Imaging Using MATLAB®
where it is denoted
	


A
x do
y do
H
k
u
N
do
Z
l
v
N
do
k l
x
y
x
y
,
,
; ,
,
(
) =
+
−




+
−




rec
1
2
λ
ξ
∆





×
−
+
−
−
=
−
=
−
∑
∑
λ
η
λ
ξ
λ
ξ
Z A
W x
k
u
N
Z
do
Z y
l
k l
l
N
k
N
x
∆
∆
∆

,
;
0
1
0
1
1
2
1
+
−




v
N
Z
do
Z
y
2
λ
η
λ
η
∆
∆
.
	
(5.83)
Equations 5.82 and 5.83 have a clear physical interpretation:
• Object wavefront is reconstructed in a number of diffraction orders 
numbered by indices {dox, doy}.
• In the diffraction order {dox, doy}, the reconstructed wavefront is a 
result of interpolation of samples {
}
,
Ak l ; of the object wavefront mod-
ified for kinoform encoding, with an interpolation kernel W (x; y), 
which is the Fourier transform of the recorded hologram window 
function w(ξ, η), those samples being weighted by samples of the fre-
quency response H
x y
rec( , ) of the hologram recording device taken at 
coordinates
	
x
k
u
N
do
Z y
l
v
N
do
Z
x
y
=
+
+




=
+
+










1
2
λ
ξ
λ
η
∆
∆
,
.
This interpretation is illustrated in Figure 5.27.
Computational Imaging Using Optics-Less Lambertian Sensors
Optics-Less Passive Sensors: Motivation
Conventional optical imaging systems use photosensitive planar arrays 
of detectors coupled with focused optics that form a map of the environ-
ment on the image plane. The optics carries this out at the speed of light, 
but comes with some disadvantages. Because of the law of diffraction, accu-
rate mapping requires large lens sizes and complex optical systems. Also, 
lenses limit the field of view and are only available within a limited range of 
the electromagnetic spectrum. The ever-decreasing cost of computing and 
ever-increasing computer power makes it possible to make imaging devices 
smaller by replacing optical and mechanical components with computation. 
This motivates a search for optics-less computational imaging devices.

273
Digital Image Formation and Computational Imaging
A good example of optics-less computational imaging is electronic record-
ing and numerical reconstruction of optical holograms described in the sec-
tion “Digital Image Formation by Means of Numerical Reconstruction of 
Holograms.” This is a very attractive solution of the problem, but it requires 
active illumination of the imaged object by a coherent radiation and illumina-
tion of sensors by a reference beam coherent with the object beam in order 
to enable recording both amplitude and phase information of the diffracted 
object beam. One can avoid the need to record the phase information if object 
has certain a priori known redundancy, for instance, if it is known to be lim-
ited in space, or by means of recording intensity of diffracted object beam at 
two or more different distances. In these cases, different methods for phase 
retrieval can be used, which, in principle, are similar to iterative methods for 
image reconstruction from sparse nonuniform samples discussed in the sec-
tion “Image Recovery from Sparse or Nonuniformly Sampled Data.” We refer 
the readers to numerous publications on phase retrieval methods. In this sec-
tion, we will show that optics-less incoherent imaging is also possible.
Imaging as a Parameter Estimation Task
One can treat images as sets of data that indicate locations in space and inten-
sities of sources of radiation. These data can be regarded as parameters to be 
FIGURE 5.27
​Left side: computer simulation of optical reconstruction of computer-generated kinoform of 
the image shown at the bottom; numbers indicate diffraction order indices. Right side: recon-
struction masking function for a rectangular hologram recording aperture of size Δξ × Δη.

274
Theoretical Foundations of Digital Imaging Using MATLAB®
estimated from sensor’s signal and the imaging problem can be solved using 
optimal statistical parameter estimation approach outlined in the section 
“Quantifying Signal Processing Quality.” To begin with, consider a simplis-
tic task of determination of intensity and angular direction to a single distant 
radiation source. For determination of these two parameters, two detectors 
illuminated by the source under different angles would be sufficient, pro-
vided the detectors have a certain angular selectivity.
Consider a schematic diagram in Figure 5.28, which depicts a 2D model of 
a sensor consisting of two mutually perpendicular radiation detectors and 
a signal processing unit that computes from its input data estimates ˆI and 
ˆ (
)
θ SRC  of the source intensity I and directional angle θ(SRC).
Assume that outputs s1 and s2 of radiation detectors are proportional to the 
source intensity I and detector’s angular sensitivity function AngSens(θ(SNS)), 
where θ(SNS) is the angle between the direction to the source of radiation and 
the normal to the detector surface, and that they contain mutually indepen-
dent Gaussian random noise components n1 and n2:
	
s
I
n
s
I
n
SNS
SNS
1
1
1
2
2
2
=
(
) +
=
(
) +
AngSens
;
AngSens
.
(
)
(
)
θ
θ
	
(5.84)
Concerning the angular sensitivity of detectors, we opt the simplest 
assumption that the detector’s output is proportional to the radiation energy 
per unit of the detector’s surface projection to the plane perpendicular to the 
Distant  radiation
source (I,θ(SRC))
Direction to the
radiation source
1st detector
2nd detector
Signal processing unit
I,θ
θSRC
θSRC
ˆ ˆ(SRC)
FIGURE 5.28
A two-detector sensor for the determination of directional angle and intensity of a distant 
radiation source.

275
Digital Image Formation and Computational Imaging
direction to the radiation source. This assumption leads to the Lambertian 
cosine law angular sensitivity function of the detectors:
	
AngSens θ
θ
θ
π
θ
π
(
)
(
)
(
)
(
)
cos
,
,
.
SNS
SNS
SNS
SNS
(
) =
<
≥



2
0
2 	
(5.85)
With this assumption, the output detectors depicted in Figure 5.28 will be
	
s
I
n
s
I
n
SRC
SRC
1
1
2
2
=
(
) +
=
(
) +
cos
;
sin
.
(
)
(
)
θ
θ
	
(5.86)
As it was described in the section “Statistical Models of Signals and 
Transformations,” Equation 2.158, for the regarded Gaussian additive signal-
independent noise model, maximum likelihood estimates of parameters ˆI 
and ˆ (
)
θ SRC  will be solutions of equation:
	
ˆ
, ˆ
argmin
cos
si
(
)
,
(
)
(
)
I
s
I
s
I
ML
ML
SRC
I
SRC
SRC
θ
θ
θ
{
} =
−
(
)
(
) +
−
(
)
1
2
1
n
.
(
)
θ SRC
(
)
(
)




2
	
(5.87)
They can be found by equating partial derivatives of the right part of 
Equation 5.87 over the sought variables, which gives the following quite 
obvious solutions (see Appendix):
	
ˆ
arctan
;
ˆ
.
(
)
(
)
θML
SRC
ML
SRC
s
s
I
s
s
=
=
+
2
1
1
2
2
2
	
(5.88)
In order to evaluate the estimation errors of these optimal ML, assume 
that these errors are sufficiently small. Then, estimation errors can be found 
(see Appendix) as increments/decrements d
ML
SRC
ˆ (
)
θ
 and dIML
SRC
ˆ(
) of estimates of 
source directional angle and intensity caused by increments/decrements 
ds1 = n1 and ds2 = n2 of observed signals s1 and s2 due to the noise components:
	
ε
θ
θ
ε
θ
θ
θ =
−
=
+
n
n
I
n
n
s
SRC
SRC
I
SRC
SRC
2
1
1
2
cos
sin
;
cos
sin
.
(
)
(
)
(
)
(
)
	
(5.89)
As one can see, for sufficiently small noise, level estimation errors are pro-
portional to noise in detector signals and, therefore they have normal distri-
bution density. Their mean values are zero:
	
AV
AV
n
AV
n
I
AV
AV
n
A
n
n
n
n
n
I
Ω
Ω
Ω
Ω
Ω
(
)
cos
sin
cos
ε
θ
θ
ε
θ
θ =
(
)
−
(
)
=
=
(
)
+
2
1
1
0
V
n
n
Ω
2
0
(
)
=



sinθ
	
(5.90)

276
Theoretical Foundations of Digital Imaging Using MATLAB®
and variances are proportional to the variance σn
2 of detector noise
 
AV
AV
n
n
I
AV
n
AV
n
n
n
n
n
Ω
Ω
Ω
Ω
ε
θ
θ
θ
θ
2
2
1
2
2
2
2
1
2
( ) =
−




=
(
)
+
cos
sin
cos
(
)
−
(
)
=
=
( ) =
+
sin
cos sin
cos
2
1
2
2
0
2
2
1
2
θ
θ
θ
σ
ε
θ
AV
n n
I
I
AV
AV
n
n
n
n
n
I
Ω
Ω
Ω
n
AV
n
AV
n
AV
n n
n
n
n
2
2
1
2
2
2
2
2
1
2
2
sin
cos
sin
cos si
θ
θ
θ
θ
(
)
=
(
)
+
(
)
+
(
)
Ω
Ω
Ω
n
,
θ
σ
=
n
2
	
(5.91)
where AV
n
Ω is the operator of averaging over ensemble Ωn of realizations of 
noise.
One can extend the above idea of determination of parameters of a single 
radiation source to imaging of a given number of multiple radiation sources 
by means of a radiation sensor that consist of a set of bare radiation detec-
tors with their natural angular selectivity to radiation arranged on a flat or 
curved surface and supplemented with a signal processing unit that collects 
detector outputs and use them to compute optimal statistical estimations of 
sources’ intensities and coordinates. We will refer to this sensor as optics-
less passive sensor (OLP-sensor). The schematic diagram of OLP-sensors is 
depicted in Figure 5.29.
For the case of estimating, by an array of K elementary radiation detec-
tors, of locations and intensities of a known number L of distant point 
radiation sources that can be specified by their directional angle and radia-
tion intensity, a mathematical model of OLP-sensors can be formulated as 
follows.
Let Ik be the intensity of the k-th radiation source, Xk be a vector of spa-
tial coordinates of the k-th source, θl
SNS
(
) be the angle of the surface normal 
of the l-th detector with respect to a sensor’s “optical axis,” and sl be its 
response to the radiation. Also let, for definiteness, assume that detectors’ 
responses are contaminated by additive signal-independent and mutually 
independent noise components {nl} with normal distribution density. Then 
the equation
	
s
I
n
l
k
k
K
k
SRC
l
SNS
l
=
(
)
(
) +
=∑
AngSens
,
(
)
(
)
1
ϑ X
θ
	
(5.92)
models the response of the l-th detector with angular sensitivity AngSens(ϑ) 
as a function of the angle ϑ between the normal to the detector surface and 
the direction to the radiation source.

277
Digital Image Formation and Computational Imaging
The sensor’s signal processor unit operates on output signals {Sn} of all 
N detectors and generates statistically optimal estimate {Îk} and 
{
}
(
)
Xk
SRC  of 
intensities and coordinates of the radiation sources. These might be ML esti-
mates, which require a priori knowledge of only the number of parameters to 
be estimated, or MAP estimates, for which one needs to know a priori prob-
ability densities of the sought parameters, or any other statistical estimates. 
Obviously, changing the type of the estimator requires only the correspond-
ing reprogramming of the sensor signal processing unit and no hardware 
changes.
In particular, the ML estimator defined by Equation 2.171 takes the form
 
ˆ , ˆ
argmin
AngSens
(
)
, ˆ
(
(
)
I
s
I
k
k
SRC
I
n
k
k
K
k
SRC
k
k
SRC
X
X
X
{
} =
−
{
}
=∑
1
ϑ
)
(
)
,
.
θl
SNS
l
L
(
)
(
)














=∑
2
1
	
(5.93)
Of a special importance is the case of estimating intensities of a given 
number of radiation sources in known locations, as, for instance, in nodes 
of a regular spatial grid. In this case, the ML-estimator is defined by the 
equation
	
ˆ
argmin
AngSens
,
(
)
(
)
I
s
I
k
I
n
k
k
K
k
SRC
l
SNS
k
{ } =
−
(
)
(
)





{ }
=∑
1
ϑ X
θ









=∑
2
1
l
L
.
	
(5.94)
We call this mode of operation the “imaging mode.”
A layer of radiation detectors
Signals from detectors
Signal processing unit
Estimates of intensities and
coordinates of the
radiation sources
FIGURE 5.29
​Schematic diagram of OLP-sensors.

278
Theoretical Foundations of Digital Imaging Using MATLAB®
Note that Equation 5.94 can be regarded as a special case of a general imag-
ing equation:
	
ˆ
argmin
( , )
,
I
s
I h k l
k
I
l
k
k
K
l
L
k
{ } =
−












{ }
=
=
∑
∑
1
1
2
	
(5.95)
in which h(k, l) is a PSF of a linear system that defines contribution of radia-
tion from the k-th radiation source to the signal from the l-th detector.
In implementing the outlined parameter estimation approach, various a pri-
ori limitation regarding sought variables can be used. Some of them, such as 
limitations of spatial positions of the sources and nonnegativity of intensity 
estimates, are almost obvious. There might also be useful some additional a 
priori limitations associated with properties of imaged objects. Here are some 
of the most frequently used priors for image intensity signals of real objects:
• Minimum variance VAR I
I
I
k
k
K
k
k
K
( ) =
−



=
=
∑
∑


2
1
2
1
2
• Minimum total variation (average module of gradient) of intensity 
estimates TVAR I
Grad Ik
k
K
( )
(
)
=
=
∑

1
• Minimum bandwidth in a certain selected transform domain
The latter is the base of the compressive sensing approach already men-
tioned in the section “Application Examples.”
OLP-sensors, being decision-making devices, are essentially nonlinear 
devices that cannot be described in terms of PSFs, which is customary for tradi-
tional optics-based imaging devices. The performance of OLP-sensors, and in 
particular, their resolving power is characterized, in the first-order approxima-
tion, by estimation error variances. The statistical theory of parameter estima-
tion shows that, for parameter estimation from data corrupted by sufficiently 
small independent Gaussian additive noise, estimation errors have a normal 
distribution. We illustrated this conclusion above on the example of OLP-
sensor for locating and determination of intensity of a single radiation source.
In general, finding solutions of Equations 5.93 through 5.95 is a very heavy 
computational task: it grows exponentially with the number of sources. Until 
recently, it made the practical use of this approach not feasible. With ever-
growing computer power, this approach becomes more and more promising.
Optics-Less Passive Imaging Sensors: Possible Designs, Expected 
Performance, Advantages, and Disadvantages
There might be several possible designs of OLP-sensors depending on the 
shape of surface on which the sensor’s detectors are installed. In the sen-
sor arrays shown in Figure 5.30a, radiation detectors are placed on the outer 

279
Digital Image Formation and Computational Imaging
surface of a sphere. Such sensors are potentially capable of localizing and 
imaging radiation sources throughout the solid angle.
Figure 5.30b shows an alternative design, an array of detectors on a flat 
surface. Because rays from distant sources are practically parallel and arrive 
at different detectors of the flat array from the same angles, they cannot be 
distinguished as coming from different sources. Therefore, such sensors are 
potentially capable of measuring coordinates and intensities of only sources, 
which are sufficiently close to them so that their rays arrive at different detec-
tors from sufficiently different angles. Any intermediate designs consisting 
of detectors on curved convex or concave surfaces, such as the one shown in 
Figure 5.30c, are also possible.
Figures 5.31 through 5.33 enable obtaining a certain insight into potential 
imaging capabilities of OLP-sensors. Figure 5.31 shows simulation results 
for a model of the OLP convex spherical sensor consisting of 300 elementary 
Radiation detectors on a concave
spherical surface
Radiation source
Radiation detectors on a convex
spherical surface
(a)
(b)
(c)
A ﬂat array of radiation detectors
Radiation
source
FIGURE 5.30
​Examples of possible designs of OLP-sensors: convex spherical (a), flat (b), and concave spheri-
cal sensors (c).

280
Theoretical Foundations of Digital Imaging Using MATLAB®
detectors set to estimate intensities of 304 sources arranged, in known loca-
tions, to form the abbreviation “OLSS.”
Figure 5.32 illustrates the performance of the flat sensor in the “imaging” 
mode and shows the results of reconstruction of the intensities of 8×16 sources 
arranged in a flat array as it is estimated by the flat sensor with 8×16 detectors 
at different distances from the sources. Detector noise standard deviation was 
set to 0.01 in the units of maximal radiation intensity at the sensor. The source 
intensities form an image of characters “SV.” One can conclude from the figure 
that the flat OLS-sensor with a realistic signal-to-noise ratio (SNR) of 100 is 
capable of reasonably good imaging for sources situated in its close proximity, 
though the quality of the estimates rapidly decays with its distance to sources.
Figure 5.33a–d enables quantitative evaluation of the size and shape of the 
flat sensor’s field of view in terms of the standard deviation of estimates 
of X–Y coordinates and intensity of a single source in different positions in 
front of the sensor.
In particular, one can see that within small distances from the sensor, 
accurate estimation of source coordinates and intensity is possible, but at dis-
tances greater than about half of the sensor length, the estimation accuracy 
drops by the order of magnitude. Experiments also revealed that the sen-
sor’s capability to resolve extremely close sources is limited by a value on the 
order of interdetector angular, in the case of the spherical sensor, or linear, 
in the case of the flat sensor, distance, which is intuitively well understood.
Estimation error standard deviation maps illustrated in Figure 5.34a–d are 
similar to those in Figure 5.33 with the difference that the sensor is bent to 
make it convex (a) and (b) or concave (c) and (d).
One can see from the figures that the bending surface of the sensor to a 
convex form widens the field of view of the sensor correspondingly, while 
bending to a concave form narrows it and concentrates it within a sector that 
encompasses the sensor.
FIGURE 5.31
​OLS spherical sensor in the “imaging” mode: original image is an array of sources that form 
characters “OLSS” (left), pattern of individual detectors’ outputs on the surface of the sphere 
shown in gray scale (center, dark—low intensity, bright—high intensity), and estimates of 
source intensities (right). The sensor consisted of 15 × 20 = 300 detectors arranged within 
spatial angles ±π longitude and ±π/2.05 latitude. The array of simulated radiation sources 
consisted of 19 × 16 = 304 sources with known directional angles within spatial angles ±π/2 
longitude and ±π/3 latitude. Each detector had a noise standard deviation of 0.01, and source 
intensities were 0 (dark) or 1 (bright). Standard deviation of estimation errors of source intensi-
ties was found to be 0.0640.

281
Digital Image Formation and Computational Imaging
Detector readings, Z = 1
Detector readings, Z = 2
Estimated source intensities; Z = 1. ErrStDev = 5.68e-04
Estimated source intensities; Z = 2ErrStDev = 0.01
Estimated source intensities; Z = 4; ErrStDev = 0.06
(a)
(b)
(d)
(f)
(c)
(e)
(g)
Detector readings, Z = 4
Detector readings, Z = 8
Estimated source intensities; Z = 8; ErrStDev = 0.12
(f)
FIGURE 5.32
​An illustration of sensing of 8×16 radiation sources arranged on a plane in the form of charac-
ters “SV” by a 3D model of a flat OLP sensor with 8×16 elementary detectors in the “imaging” 
mode for distances of sources from the sensor Z = 1–8 (in units of interdetector distance). SNR 
at detectors was kept, for all distances from sources, constant at 100 by making the source 
amplitude inversely proportional to the distance between the source and sensor planes. 
Detector noise was 0.01.

282
Theoretical Foundations of Digital Imaging Using MATLAB®
y = 20
2–0
2–1
2–2
2–3 2–4
2–5
2–6
2–7
2–8
2–9
2–9
2–8
2–7
2–6
2–5
2–3
2–4
2–2
2–1
20
y = 1
x = –20
x = 20
Line array of 25 detectors
Standard deviations of X-errors
y = 20
2–9
2–8
2–7
2–6
2–5
2–3
2–4
y = 1
x = –20
x = 20
Line array of 25 detectors
Standard deviations of intensity errors
(a)
(c)
(b)
(d)
y = 20
y = 1
x = –20
x = 20
Line array of 25 detectors
Standard deviations of Y-errors
X and Y and IerrStDev along the optical axis
100
10–1
10–2
10–3
5
10
15
20
Distance from the sensor
XerrStd=Dev
YerrStDev
IerrStDev
25
FIGURE 5.33
Maps of standard deviations of estimation errors of X–Y coordinates (a, b) and of intensity (c) of a radiation source as a function of the source position 
with respect to the surface of the flat line array of 25 detectors. Darker areas correspond to larger errors. Plot (d) shows standard deviations of X, Y, and 
intensity estimation errors as function of the distance from the sensor along the sensor “optical axis” (central sections of (a) through (c)).

283
Digital Image Formation and Computational Imaging
The presented data confirm that OLP-sensors with a realistic SNR in its 
detectors are, in principle, capable of reasonably good localization and imag-
ing of radiation sources. This implies that good directional vision without 
optics is possible even using the simplest possible detectors whose angular 
sensitivity is defined solely by the natural surface absorptivity such as the 
Lambertian one. Convex spherical sensors have an unlimited field of view, 
while flat sensors can localize and image radiation sources in their close 
proximity. Sensors on curved surfaces can work in intermediate zones.
As always, there is a trade-off between good and bad features of the OLP-
sensors. The advantages include the following:
• No optics is needed, making this type of sensor applicable to virtu-
ally any type of radiation and to any wavelength.
I errorStDev map; 11 subsensors; radius 100
50 runs; noiseStDev: 0.01
I errorSTD map; 11 subsensors; radius of bending: 5
number of noise realizations: 50; NoiseSTD: 0.01
10
8
6
–6
–4
–2
0
2
4
6
4
2
0
I errorStDev map; 11 subsensors; radius 10
50 runs; noiseStDev: 0.01
(a)
(c)
(d)
(b)
15
10
–10
–5
0
5
10
5
0
Y coordinate
X coordinate
Y coordinate
X coordinate
15
10
–10
–5
0
5
10
5
0
Y coordinate
X coordinate
I errorSTD map; 11 sensors; radius of bending: 10
number of noise realizations: 50; NoiseSTD: 0.01
20
18
16
14
12
10
8
6
2
4
0
–10
–5
0
5
10
X coordinate
Y coordinate
FIGURE 5.34
(a) and (b) Sensors on convex bent surfaces (1D model, 11 detectors, noise standard deviation 
0.01): maps of standard deviations of estimation errors of source intensity as functions of the 
source position with respect to the sensor’s surface for bending radius, in units of interdetector 
distance, 100 (a) and 10 (b). (c) and (d) Sensors on concave bent surfaces (1D model, 11 detec-
tors, noise standard deviation 0.01): maps of standard deviations of estimation errors of source 
intensity as functions of the source position with respect to the sensor’s surface for bending 
radius, in units of inter detector distance, 10 (c) and 5 (d). Darker areas correspond to larger 
errors.

284
Theoretical Foundations of Digital Imaging Using MATLAB®
• The field of view (of convex spherical sensors) is unlimited.
• The design is flexible: the shape of the sensor’s surface can be easily 
changed to fit the required sensor’s field of view.
• Diffraction-related limits are irrelevant to OLS-sensors whose 
resolving power is determined, given the detector’s SNR, solely by 
the detector’s size.
The cost for these advantages is high computational complexity, ­especially 
when good imaging properties for multiple sources are required.
Appendix
Derivation of Equation 5.47
	
DRK
k
DRK r k
i
r f
i
k
u r
v
N
r
N
( , )
( , )exp
exp
(
)(
)
ξ
π
ξ
π
=
−(
)
+
+


=
−
∑
2
2
0
1
∆
×



−
+
(
)


−(
)
=
−
∑
exp
exp
e
( )
( )
( )
( )
i
r
v
f
i
v
f
s
s
r
N
s
s
2
2
0
1
π
ξ
π
ξ
∆
∆
×
xp
(
)
exp
(
)
( )
i
k
u v
N
i
k
u
N
f
r
s
r
N
2
2
0
1
π
π
ξ
+




+
−








=
−
∑
∆
=
−(
)
+




+
−
exp
exp
(
)
exp
(
)
( )
( )
(
i
v
f
i
k
u v
N
i
N
k
u
N
f
s
s
s
2
2
2
π
ξ
π
π
∆
∆
)
( )
exp
(
)
exp
ξ
π
ξ
π







−
+
−







−
=
−
1
2
1
2
i
k
u
N
f
i
s
∆
v
N
f
i
k
u
N
v
N
s( )
exp
(
)
si
+
−








+
+
−




			
			
1
2
2
1
2
∆ξ
π
×
n
sin
π
ξ
π
ξ
N
f
k
u
N
f
k
u
N
∆
∆
−
+








−
+









285
Digital Image Formation and Computational Imaging
Derivation of Equation 5.63
OPSF x k
i
x
Z
k
N
i
r
N
( , )
exp
exp
exp
=
−









×
−




π λ
µ
π µ
2
2
2
2
2
i
kr
N
i
x
Z
Z
i
r f
r
N
2
2
0
1
2
π
π
λ ξ
λ
π




−
−




−
=
−
−∞
∞
∑
∫
×
exp
(
)
exp(
∆ξ
ξ
π λ
µ
π µ
π
)
exp
exp
exp
d ×
i
x
Z
k
N
i
r
N
i
2
2
2
2
2
2
−










×
−




 
kr
N
i
x
Z
Z
i
r f
r
N




−
−




−
−∞
∞
=
−
∫
∑
exp
(
)
exp(
)
π
λ ξ
λ
π
ξ
ξ
2
0
1
2
∆
d
=
−










−






exp
exp
exp
i
x
Z
k
N
i
r
N
i
kr
N
π λ
µ
π µ
π
2
2
2
2
2
2


−




−
−




×
=
−
−∞
∞
∑
∫
r
N
i
Z
i
r f x
Z
0
1
2
2
×
exp
exp
π ξ
λ
π
ξ
λ
ξ


∆
d
exp
exp
exp
i
x
Z
k
N
i
r
N
i
kr
N
π λ
µ
π µ
π
2
2
2
2
2
2
−










−








−




×
−




=
−
∑
exp
exp
exp
i
r f x
Z
i
Z
i
r f
Z
r
N
2
2
0
1
2
π
λ
π ξ
λ
π λ
∆
∆

ξ
ξ
π λ
µ
π µ




−










−



−∞
∞
∫
d
 exp
exp
i
x
Z
k
N
i
r
N
2
2
2
2
2

×
−












×
=
−
∑
r
N
i
k
N
fx
Z
r
i
r
f
Z
0
1
2
2
2
exp
exp
e
π
λ
π λ
∆
∆
xp
exp
i
x
Z
k
N
i
N f
Z
r
N
π λ
µ
π
λ
µ
2
2
2
2
2
2
1
−










−
−










∆


−








=
−




=
−
∑
exp
exp
i
k
N
fx
Z
r
i
x
Z
k
N
r
N
2
0
1
2
2
2
π
λ
π λ
µ
∆







−
−




frincd
;
;
.
N
N f
Z
fx
Z
k
N
1
2
2
µ
λ
λ
∆
∆

286
Theoretical Foundations of Digital Imaging Using MATLAB®
Derivation of Equation 5.69
	
OPSF x k
i
Z
i
x
N
i
s
f
s
( , )
( )exp(
)exp(
)
exp
( )
=
−
×
−∞
∞
∫Φ
ξ
πλ ξ
π ξ
ξ
π µ
2
2 2
2
1
d
N
i
ks
N
i
r
s
N
f
r
N
s




−




−








=
−
=
∑
exp
exp
2
2
0
1
π
π
ξ
∆
0
1
2
2 2
2
N
f
s
i
Z
i
x
i
s
N
−
−∞
∞
∑
∫
=
−
×



Φ( )( )exp(
)exp(
)
exp
ξ
πλ ξ
π ξ
ξ
π µ
d

−




×
−


−

=
−
∑
exp
sin
(
)
sin
(
)
i
ks
N
s
N f
N
N s
N f
s
N
2
0
1
π
π
ξ
π
ξ
∆
∆



−
−





−
exp
(
)
( )exp(
)exp(
( )
i
N
N
s
N f
i
Z
i
x
f
s
π
ξ
ξ
πλ ξ
π
1
2
2
∆
Φ
ξ
ξ
π µ
π
π
)
exp
exp
sincd
; (
d
i
s
N
i
ks
N
N
s
N
2 2
0
1
2




−




×
=
−
−∞
∞
∑
∫
s
N f
−


∆ξ) .
Derivation of Equation 5.81
	
A
x y
W
i
Z
rcstr( , )
,
exp
=
(
)
+




×
−∞
∞
−∞
∞
−∞
∞
−∞
∞
∫∫∫∫
ξ η
π ξξ
ηη
λ
ξ η
2
d d
Γ
∆
∆
r s
s
r
h
r
s
i
x
y
Z
W
,
(
,
)exp
rec ξ
ξ
ξ η
η
η
π ξ
η
λ
ξ η
−
−
−
−
−
+




=
∑
∑
0
0
2
d d
ξ η
ξ η
ξ
ξ
ξ η
η
η
,
(
,
)
,
(
)
×
−
−
−
−
−∞
∞
−∞
∞
=−∞
∞
=−∞
∞
∫∫
∑
∑
d d
Γ
∆
∆
r s
s
r
h
r
s
rec
0
0
exp −
−
(
)
+
−
(
)








−∞
∞
−∞
∞
∫∫
i
x
y
Z
2π
ξ ξ
η η
λ
ξ η
d d

287
Digital Image Formation and Computational Imaging
×
(
)
−
−
(
)
+
+
−
−∞
∞
−∞
∞
=−∞
∞
=−∞
∞
∫∫
∑
∑
W
i
x
r
y
r s
s
r
ξ η
ξ η
π
ξ
ξ
ξ
,
exp
(
)
,
d d
Γ
∆
2
0
η η
η
λ
ξ η
π
ξ ξ
η η
λ
(
)
+








×
−
−
(
) +
−
(
)



(
)
( , )exp
0
2
s
Z
h
i
x
y
Z
∆
 
rec





−∞
∞
−∞
∞
∫∫
d d
ξ η.
Replacing the last multiplicand in this equation by the frequency response, 
in coordinates x
y
−
−
(
)
ξ
η
,
, of the hologram recording device:
	
H
x
y
h
i
x
y
Z
rec
rec
−
−
(
) =
(
)
−
−
(
)
+
−
(
)








−
ξ
η
ξ η
π
ξ ξ
η η
λ
ξ η
,
,
exp
2
d d
∞
∞
−∞
∞
∫∫
obtain:
	
A
x y
W
H
x
y
r s
s
r
rcstr
rec
( , )
,
,
,
=
(
)
−
−
(
)
×
−∞
∞
−∞
∞
=−∞
∞
=−∞
∫∫
∑
ξ η
ξ
η
ξ η
d d
Γ
∞
∑
−
−
(
)
+
+
−
(
)
+








(
)
exp
(
)
(
)
,
i
x
r
y
s
Z
W
H
2
0
0
π
ξ
ξ
ξ
η η
η
λ
ξ η
∆
∆
×
rec x
y
i
x
y
Z
r s
s
−
−
(
)
−
−
(
)
+
−
(
)








×
−∞
∞
−∞
∞
=−
∫∫
ξ
η
π
ξ ξ
η η
λ
,
exp
,
2
0
0
Γ
∞
∞
=−∞
∞
∑
∑
−
−
(
)
+
−
(
)








=
−
−
(
r
i
x
r
y
s
Z
W x
y
exp
,
2π
ξ
ξ
η
η
λ
ξ η
ξ
η
∆
∆
d d
)
(
)
−
+




×
−∞
∞
−∞
∞
=−∞
∞
=−∞
∞
∫∫
∑
∑
H
i
Z
r s
s
r
rec ξ η
π ξξ
ηη
λ
,
exp
,
2
0
0
Γ
exp
.
−
+




i
r
s
Z
2π ξ ξ
η η
λ
ξ η
∆
∆
d d
Denoting
	
H
H
i
Z
rec
rec
(
,
)
,
,
exp
ξ
η
ξ η
ξ η
π ξξ
ηη
λ
0
0
2
0
0
(
) =
(
)
−
+





288
Theoretical Foundations of Digital Imaging Using MATLAB®
and replacing Γr,s by its expression through object wave front samples Ak l,  
(Equation 5.77) results in:
	
A
x y
W x
y
H
A
i
k
u
k l
rcstr
rec
( , )
,
,
exp
(
)(
,
=
−
−
(
)
(
)
×
+
−∞
∞
−∞
∞
∫∫
ξ
η
ξ η
π


2
r
p
N
l
v s
q
N
l
N
k
N
s
r
+
+
+
+










=
−
=
−
=−∞
∞
=−∞
∑
∑
∑
)
(
)(
)
1
2
0
1
0
1
2
1
∞
−∞
∞
−
∑
∫
×
−
+




−
−
(
)
(
)
exp
,
,
i
r
s
Z
W x
y
H
2π ξ ξ
η η
λ
ξ η
ξ
η
ξ η
∆
∆
d d
×
 rec
∞
∞
=
−
=
−
∫
∑
∑
+
+
+








×
A
i
k
u
N
p
l
v
N
q
k l
l
N
k
N
, exp
e
0
1
0
1
1
2
2
1
2π
xp
exp
i
k
u
N
r
l
v
N
s
i
r
s
Z
s
2
2
1
2
π
π ξ ξ
η η
λ
+
+
+








−
+




=−
∆
∆
∞
∞
=−∞
∞
−∞
∞
−∞
∞
=
−
=
∑
∑
∫∫
∑
=
−
−
(
)
(
)
r
k l
l
N
k
W x
y
H
A
d d
ξ η
ξ
η
ξ η
,
,
,


rec
0
1
2
0
1
1
2
2
1
2
2
N
i
k
u
N
p
l
v
N
q
i
Z
k
u
N
−
∑
+
+
+








×
−
−
+

exp
exp
π
π ξ ξ
λ
∆











−
−
+








=−∞
∞
=−∞
∞
∑
∑
r
i
Z
l
v
N
s
s
r
exp
2
2
π η η
λ
∆
d d
ξ η.
The last two multiplicands in this equation can be modified using the 
Poisson summation formula (Equation 3.82). Then obtain:
A
x y
W x
y
H
Ak l
l
N
k
N
rcstr
rec
,
,
,
,
(
)=
−
−
(
)
(
)
−∞
∞
−∞
∞
=
−
=
∫∫
∑
ξ
η
ξ η


0
1
0
2
1−
∑
+
+ +








×
−
+
−




1
1
2
2
2
2
exp i
k
u
N
p
l
v
N
q
Z
k
u
N
dox
π
δ ξ ξ
λ
∆

−+
−




=
−
−
(
)
=−∞
∞
=−∞
∞
∑
∑
δ η η
λ
ξ η
ξ
η
∆
Z
l
v
N
do
W x
y
H
y
do
do
y
x
2
d d
,
 rec ξ η
π
,
exp
,
(
)
+
+ +

−∞
∞
−∞
∞
=
−
=
−
∫∫
∑
∑
A
i
k
u
N
p
l
v
N
q
k l
l
N
k
N
0
1
0
1
1
2
2
1
2
2







×
−
+
−




−+
−




δ ξ ξ
λ
δ η η
λ
∆
∆
Z
k
u
N
do
Z
l
v
N
do
x
y
s
2
2
=−∞
∞
=−∞
∞
∑
∑
r
d d
ξ η

289
Digital Image Formation and Computational Imaging
	
=
+
+
+








×
=
−
=
−
∑
∑


A
i
k
u
N
p
l
v
N
q
H
k l
l
N
k
N
, exp
0
1
0
1
1
2
2
1
2
2
π
 
rec
k
u
N
do
Z
l
v
N
do
Z
x
y
do
d
y
+
+




+
+








=−∞
∞
∑
1
2
λ
ξ
λ
η
∆
∆
,
o
x
y
x
W x
k
u
N
Z
do
Z y
l
v
N
Z
do
Z
=−∞
∞
∑
×
−
+
−
−
+
−




 
1
2
λ
ξ
λ
ξ
λ
η
λ
η
∆
∆
∆
∆
;
.
Derivation of Equation 5.88
	
∂
∂
−
(
)
(
) +
−
(
)
(
)




= −
−
I
s
I
s
I
s
I
SRC
SRC
1
2
1
2
1
2
cos
sin
cos
(
)
(
)
(
θ
θ
θ SRC
SRC
SRC
SRC
s
I
s
)
(
)
(
)
(
)
cos
sin
sin
cos
(
)
(
)
(
) −
−
(
)
(
)
(
)
= −
θ
θ
θ
2
2
2
1
θ
θ
θ
θ
(
)
(
)
(
)
(
)
sin
cos
sin
SRC
SRC
SRC
SRC
s
I
(
) +
(
)

+
(
) +
(
)
(
)
(
2
2
2
2
) =
∂
∂
−
(
)
(
) +
−
(
)
(
)




=
0
2
1
2
1
2
,
cos
sin
(
)
(
)
(
)
θ
θ
θ
SRC
SRC
SRC
s
I
s
I
I s
I
I s
I
SRC
SRC
SRC
SRC
1
2
2
−
(
)
(
)
(
) −
−
(
)
(
)
cos
sin
sin
cos
(
)
(
)
(
)
(
θ
θ
θ
θ
)
(
)
(
)
sin
cos
,
(
)
=
(
) −
(
)
(
) =
2
0
1
2
I s
s
SRC
SRC
θ
θ
which gives
	
I
s
s
s
s
SRC
SRC
SRC
SRC
=
+
=



1
2
1
2
cos
sin
sin
cos
,
(
)
(
)
(
)
(
)
θ
θ
θ
θ
from which it follows:
	
θ
θ
θ
(
)
arctan
sin
sin
SRC
s
s
I
s
s
s
s
s
s
s
s
=
=
+




=
+
=
+
2
1
1
2
2
2
1
2
2
2
2
1
2
2
2
2
2
1
2
2
2
2
2
1
2
2
1
2
1
2
2
2
1
1
s
s
s
s
s
s
s
s
s
s
tan
tan
.
θ
θ
+
=
+
+
=
+

290
Theoretical Foundations of Digital Imaging Using MATLAB®
Derivation of Equation 5.89
	
ε
θ
θ =
=



=
∂
∂
+
∂
∂
d
d
s
s
ds
s
s
s
ds
s
ML
SRC
ˆ
arctan
arctan
a
(
)
2
1
2
2
2
1
1
1
rctan s
s
n
s
s
s
n s
s
s
s
n s
n
2
1
2
1
2
1
2
1 2
1
2
2
1
2
2 1
1
1
1
1
=
+ 



−
+ 



=
−
1 2
1
2
1
2
2
1
2
2
1
s
s
s
n I
n I
I
n
n
SRC
SRC
SRC
+
=
−
=
−
cos
sin
cos
sin
(
)
(
)
(
)
θ
θ
θ
θ(
)
(
)
ˆ
SRC
I
ML
SRC
I
dI
ds
s
s
s
ds
s
s
s
n
s
s
ε =
=
∂
∂
+
+
∂
∂
+
=
1
1
1
2
2
2
2
2
1
2
2
2
1
1
1
2 +
+
+
=
+
=
+
s
n
s
s
s
n I
n I
s
I
n
SRC
SRC
SRC
2
2
2
2
1
2
2
2
1
2
1
cos
sin
cos
(
)
(
)
(
)
θ
θ
θ
n
s
SRC
2 sin
.
(
)
θ
Exercises
FocPlaneVar_Invar_reconstr_illustr.m
References
	
1.	 R. W. Gerchberg, W. O. Saxton, A practical algorithm for the determination of 
phase from image and diffraction plane pictures, Optik, 35, 237–246, 1972.
	
2.	 A. Papoulis, A new algorithm in spectral analysis and band-limited extrapola-
tion, IEEE Transactions on Circuits and Systems, 22(9), 735–742, 1975.
	
3.	 R. A. Horn, C. R. Johnson, Topics in Matrix Analysis, Cambridge University Press, 
Cambridge, UK, 1991.
	
4.	 D. Donoho, Compressed sensing, IEEE Transactions on Information Theory, 52(4), 
1289–1306, 2006.
	
5.	 J. W. Goodman, R. W. Lawrence, Digital image formation from electronically 
detected holograms, Applied Physics Letters, 11(3), 77–79, 1967.
	
6.	 M. A. Kronrod, N. S. Merzlyakov, L. P. Yaroslavsky, Reconstruction of a holo-
gram with a computer, Soviet Physics-Technical Physics, 17(2), 419–420, 1972.
	
7.	 L. P. Yaroslavskii, N. S. Merzlyakov, Methods of Digital Holography, Consultance 
Bureau, N.Y., 1980. (English translation from Russian, In: Methods of Digital 
Holography, Editors L. P. Yaroslavskii, N.S. Merzlyakov, Moscow, Izdatel’stvo 
Nauka, 1977. 192 p.)

291
Digital Image Formation and Computational Imaging
	
8.	 U. Schnars, W. Jüptner, Direct recording of holograms by a CCD target and 
numerical reconstruction, Applied Optics, 33(2), 179–181, 1994.
	
9.	 I. Yamaguchi, T. Zhang, Phase-shifting digital holography, Optics Letters, 22(16), 
1268–1270, 1997.
	 10.	 E. N. Leith, J. Upatnieks, New techniques in wave front reconstruction, JOSA, 
51, 1469–1473, 1961.
	 11.	 Y. N. Denisyuk, Photographic reconstruction of the optical properties of an 
object in its own scattered radiation field, Dokl. Akad. Nauk SSSR, 144, 1275–
1279, 1962.
	 12.	 L. Yaroslavsky, Introduction to digital holography, Bentham E-book Series, In: 
Digital Signal Processing in Experimental Research, vol. 1, Editors L. Yaroslavsky 
and J. Astola, 2009, ISSN: 1879-4432, eISBN: 978-1-60805-079-6.


293
6
Image Resampling and Building Continuous 
Image Models
Accurate and fast image resampling is a key operation in many digital image 
processing applications such as multimodality data fusion, image mosaick-
ing, image reconstruction from projections, image superresolution from 
image sequences, stabilization of video images distorted by atmosphere 
turbulence, target location and tracking with subpixel accuracy, and so on 
to name a few. Image resampling assumes reconstruction of a continuous 
approximation of the original nonsampled image by means of interpolation 
of available image samples to obtain samples “in-between” the available 
ones. Since image samples are obtained using shift (convolutional) discreti-
zation functions (Equation 3.4), continuous image approximation should be 
performed in computer through digital convolution. A number of convolu-
tional interpolation methods are known, beginning from the simplest and 
the least accurate nearest-neighbor and linear (bilinear, for 2D case) interpo-
lations to more accurate cubic (bicubic, for 2D case) and higher-order spline 
methods. How can one evaluate the interpolation accuracy of these methods? 
Is perfect interpolation of sampled data possible, which does not introduce to 
signals any distortions additional to those caused by signal sampling? This 
chapter answers these questions. In the section “Perfect Resampling Filter,” 
we introduce the notion of the perfect resampling filter and show that dis-
crete sinc interpolation as a discrete implementation of the ideal low-pass 
filtering dictated by the sampling theory is the gold standard for resampling 
sampled data. In the section “Fast Algorithms for Discrete Sinc Interpolation 
and Their Applications,” we describe methods for efficient algorithmic imple-
mentation of discrete sinc interpolation for image subsampling, fractional 
shift, and rotation. In the section “Discrete Sinc Interpolation versus Other 
Interpolation Methods: Performance Comparison,” we provide experimen-
tal evidence of the superiority of the discrete sinc interpolation compared 
to other convolutional interpolation methods. In the sections “Numerical 
Differentiation and Integration” and “Local (“Elastic”) Image Resampling: 
Sliding Window Discrete Sinc Interpolation Algorithms,” we illustrate appli-
cations of discrete sinc interpolation principles to accurate signal differentia-
tion and integration and to image reconstruction from projections.

294
Theoretical Foundations of Digital Imaging Using MATLAB®
Perfect Resampling Filter
Consider optimization of signal interpolation by means of linear filtering 
implemented as digital convolution:
	
a
h
a
k
n
k n
n
N
=
−
=
−
∑
(
)
,
intp
0
1
	
(6.1)
where {
}
ak  are samples of a signal obtained as a result of interpolation of ini-
tial signal samples {ak}, hn
(
)
intp
{
} are samples of the interpolation filter PSF, and 
N is the number of available signal samples.
For the purposes of the design of the perfect resampling filter, one can regard 
signal coordinate shift as a general resampling operation. This is justified by 
the fact that samples of the resampled signal for any arbitrary signal resam-
pling grid can be obtained one by one through the corresponding shifts of 
the original signal to the given sample position.
The perfect shifting filter is the filter that generates a shifted copy of the 
input signal with preservation of the original analog signal spectrum in 
its base band defined by the signal sampling rate. In order to further pro-
ceed with derivation of the perfect shifting filter, we will need the following 
characteristics of digital filters and their properties formulated in the sec-
tions “Digital Convolution” and “DFTs and Discrete Frequency Response of 
Digital Filter”:
• The overall frequency response OFR(f) of digital filter is its fre-
quency response with respect to continuous signals that correspond 
to samples of the filter input signals.
• For ideal signal sampling and reconstruction antialiasing low-pass 
filters, overall frequency response OFR(f) of digital filter coincides 
with its continuous frequency response CFR(f) within the signal base 
band [
,
]
−1 2
1 2
∆
∆
x
x  defined by the signal sampling interval Δx.
• Discrete frequency response {ηr} of a digital filter with PSF {hn} 
applied to sampled signals of N samples is DFT of its PSF:
	
η
π
r
n
n
N
N
h
i
nr
N
=




=
−
∑
1
2
0
1
exp
.
	
(6.2)
• Continuous frequency response CFR(f) of digital filter with discrete 
frequency response {ηr} is a function interpolated from {ηr}:
	
CFR f
N
f
r f
f
r
r
N
( )
sincd[
; (
)
],
=
−
=
−
∑η
π
∆
∆
0
1
	
(6.3)

295
Image Resampling and Building Continuous Image Models
	
with the discrete sinc-function
	
sincd(
; )
sin( )
sin(
)
N x
x
N
x N
=
	
(6.4)
	
as an interpolation kernel.
In these formulas, f is the frequency parameter of the integral Fourier 
transform, Δf is spectrum sampling interval; for signal sampling interval Δx 
and cardinal sampling, ∆
∆
f
N x
= 1
.
Coefficients {ηr} of the discrete frequency response of digital filter are sam-
ples of its continuous frequency response CFR(f) taken, with sampling inter-
val Δf, at sampling points {rΔf}: {
(
)}
ηr
CFR
H
f
r f
=
=
∆
.
According to these definitions, overall continuous frequency response 
OFR
f
x
Shift
δ
(
)( ) of the perfect shifting filter for the x-coordinate shift δx must 
be equal, in the signal base band [
,
]
−1 2
1 2
∆
∆
x
x  to the frequency response 
H
f
x
Shift
δ
(
)( ) of the continuous δx-shifting filter. The latter, by virtue of the 
Fourier transform shift theorem, is equal to exp(i2πfδx). Therefore
	
OFR
f
H
f
i
f x
x
Shift
x
Shift
δ
δ
π δ
(
)
(
)
( )
( )
exp(
).
=
=
2
	
(6.5)
From the above-formulated properties of the overall, continuous, and dis-
crete frequency responses of digital filters, it follows that discrete frequency 
response coefficients η
δ
r
Shift
x
(
)(
)
{
} of the perfect δx-shifting filter, for indices 
from r = 0 to r = (N − 1)/2 for odd N and to r = N/2 for even N, which corre-
spond to the lowest and highest frequencies in the signal base band, must be 
samples, in sampling points {
}
r N x
 , of its continuous frequency response. 
The rest of the coefficients should be set according to the symmetry property 
of DFT for real valued data (Equation 4.70). Thus, for odd number of signal 
samples N, coefficients η
δ
r
Shift
x
(
)(
)
{
} must be set to
	
η
δ
π
δ
η
r
Shift
r
Shift
x
i
r x
N x
r
N
(
)
(
)
(
)
exp
,
, ,...,(
)
=




=
−
2
0 1
1 2
∆
(
)
(
),
(
)
,...,
.
(
)
δ
η
δ
x
x
r
N
N
N r
Shift
=
=
+
−
−
∗
1 2
1 	
(6.6)
For even number of signal samples N, from the same requirement 
η
δ
η
δ
r
Shift
N r
Shift
x
x
(
)
(
)
(
)
(
)
=
−
∗
, it follows that the coefficient η
δ
N
Shift
x
2
(
)(
), which cor-
responds to the signal highest frequency in its base band, must be a real 
number. Because of that, for even N this coefficient cannot be taken just as 
a sample of exp(
(
))
i
r x N x
2π δ /
∆
 for r = N/2 and requires a special treatment. 
We select settings:

296
Theoretical Foundations of Digital Imaging Using MATLAB®
	
η
δ
π
δ
π δ
r opt
intp
x
i
r x
N x
r
N
C
x
,
(
)(
)
exp
,
, ,...,
cos
 =




=
−
2
0 1
2
1
∆
∆x
r
N
x
x
r opt
intp
N r opt
intp




=






= (
−
,
(
)
(
)
,
(
)
,
(
)
2
η
δ
η
δ

)
=
+
−
∗,
,...,
,
r
N
N
2
1
1
	
(6.7)
where C is a weight coefficient that defines signal spectrum shaping at its 
highest frequency component. In what follows we will consider, for even N, 
the following three options for C: Case_0: C = 0; Case_1: C = 1; Case_2, C = 2.
Applying to Equations 6.6 and 6.7 inverse discrete Fourier transform, one 
can obtain (see Appendix) that, for odd N, PSF of the perfect shifting filter 
defined by Equation 6.6 is
	
h
x
N
n
x
x
n
Shift
(
)(
)
sincd[
, (
)]
δ
π
δ
=
−
 ∆
	
(6.8)
and for even N, Case 0 and Case 2, perfect shifting filter PSFs are
	
h
x
N
N
n
x
x
n
Shift
(
, )(
)
sincd[
;
; (
)]
0
1
δ
π
δ
=
−
−
∆
	
(6.9)
and
	
h
x
N
N
n
x
x
n
Shift
(
, )(
)
sincd[
;
; (
)],
2
1
δ
π
δ
=
+
−
∆
	
(6.10)
respectively, where sincd( ; ; )
⋅⋅⋅ is the general discrete sinc-function (Equation 
4.54). Case_1 is obviously a combination of Case_0 and Case_2:
h
x
h
x
h
x
n
Shift
n
Shift
n
Shift
(
, )
(
, )
(
, )
(
)
(
)
(
)
sincd
1
0
2
2
δ
δ
δ
=
+


=
[
;
; (
)],
±
−
1 N
n
x
x
π
δ
∆
	 (6.11)
where
	
sincd(
;
; )
[sincd(
;
; )
sincd(
;
; )]
sin[(
)
±
=
−
+
+
=
−
1
1
1
2
1
N x
N N
x
N N
x
N
x
/
N
N
x N
N
x N
x
N
x N
x N
]
sin[(
)
]
sin(
)
sin( )
sin(
) cos(
)
cos
+
+






=
=
1
2
/
(
)sincd(
; ).
x N
N x
/
	
(6.12)

297
Image Resampling and Building Continuous Image Models
Numerical interpolation using discrete sinc-functions (sincd-functions) 
given by Equations 6.8 through 6.11 as the interpolation kernel is called dis-
crete sinc interpolation.
Discrete sinc-function is the point spread function of the ideal digital low-
pass filter, whose discrete frequency response—DFT of its PSF—is a rectan-
gular function and which is a discrete representation of the ideal continuous 
low-pass filter required, according to the sampling theory, for signal resto-
ration from its samples. Figure 6.1 shows absolute value of the continuous 
frequency response of the discrete sinc interpolator (solid line) along with 
absolute values of samples of the discrete frequency response of the ideal 
low-pass digital filter (stems).
Three above versions of sincd-functions for Cases_0–2 are illustrated for 
comparison in Figure 6.2. As one can see from this figure, sincd-function 
for Case 1 converges to zero substantially faster than that for cases 0 and 2, 
thanks to its spectrum shaping: the spectral coefficient ηN 2
1
(int ) corresponding 
to the highest frequency is halved. Due to this property, the Case 1 discrete 
sinc interpolation produces less ringing oscillations in the interpolated sig-
nal, which makes it preferable in practical applications.
From the above reasoning, it follows that discrete sinc interpolation 
secures perfect, for a given finite number of signal samples, resampling of 
discrete signals with preservation of the corresponding continuous signal 
spectra in their sampling points. All resampling filters with PSFs other than 
discrete sinc-function will distort samples of signal spectrum in the signal 
base band and, therefore, introduce interpolation error additional to signal 
distortion due to sampling. It is in this sense that discrete sinc interpola-
tion can be regarded the “gold standard” of discrete signal interpolation. In 
the section “Discrete Sinc Interpolation versus Other Interpolation Methods: 
Performance Comparison,” we will compare discrete sinc interpolation with 
–2
–0.5
0
0.5
1
1.5
–1.5
–1
–0.5
0
Normalized frequency
1
2
0.5
1.5
FIGURE 6.1
Continuous (solid line) and discrete (stems) frequency responses of the discrete sinc interpola-
tor. Frequency indices are normalized so that interval [−0.5 ÷ 0.5] represents signal base band.

298
Theoretical Foundations of Digital Imaging Using MATLAB®
other discrete interpolation methods and provide experimental evidence of 
its perfect performance and superiority.
Fast Algorithms for Discrete Sinc Interpolation 
and Their Applications
Signal Subsampling (Zooming-In) by Means of DFT 
or DCT Spectra Zero Padding
One of the basic image resampling tasks is image subsampling (zooming-in), 
that is, computing, from the given set of samples, a set of in-between samples. 
From properties of signal DFT spectra of sparse signals, discussed in the 
section “Convolutional Discrete Fresnel and Angular Spectrum Propagation 
Transforms” (Equations 4.85, 4.90, and 4.91), it straightforwardly follows that 
discrete sinc interpolated signal subsampling can be achieved by means of 
zero padding its DFT spectrum. Given subsampling (zoom) factor L, this 
algorithm is described by the equation
	
 a
a
k
LN
L
N
k
= IFFT
{DFT_ZP [FFT (
)]}, 	
(6.13)
where {ak}, k = 0,1,. . .,N − 1 are input signal samples,  ak
{ } are output signal sam-
ples, k
NL
=
−
0 1
1
, ,...,
, FFT ( )
N ⋅ and IFFTLN( )⋅ are N-point direct and LN-point 
1
–0.2
0
0.2
0.4
0.6
0.8
1
16
32
48
64
Sample indices
80
96
112
128
Case 0
Discrete sinc-functions: Cases 0,1,2
Case 1
Case 2
FIGURE 6.2
​Comparison of three versions of sincd-functions.

299
Image Resampling and Building Continuous Image Models
inverse fast Fourier transform operators, respectively, and DFT_ZP []
L ⋅ is a 
zero-padding operator, which forms, from N-points sequence of samples, 
an LN-points sequence by padding the former with (L − 1)N zeros. When N 
is an odd number, zeros are placed between (N − 1)/2-th and (N + 1)/2-th 
samples of the N-points sequence. When N is an even number, then
	
i.	(L − 1)N + 1 zeros are placed between N/2 − 1-th and N/2 + 1-th sam-
ples of the N-points sequence and N/2-th sample is discarded, or
	
ii.	(L − 1)N zeros are placed after N/2-th sample and then the sequence 
repeated beginning of its N/2-th sample, or
	 iii.	N/2-th sample of the sequence is halved, (L − 1)N zeros are placed 
after it and then N/2-th through (N − 1)-th samples of the sequence 
are placed at the end, N/2-th sample being also halved.
Cases (i)–(ii) implemented above-described Case_0, Case_2, and Case_1 dis-
crete sinc interpolation, respectively. 2D image subsampling is implemented 
as separable in two consecutive steps over each of the two coordinates.
Although discrete sinc interpolation is perfect in preserving signal spec-
trum, it has one major drawback. As interpolation kernel discrete sinc-
function decays to zero relatively slow, discrete sinc interpolation, being 
implemented through FFT, tends to produce heavy boundary effects that 
may propagate quite far from signal boundaries. It is especially an important 
issue in image processing. With the use of FFT in the resampling algorithm 
(Equation 6.13), images are treated as being periodic in both coordinates. 
Therefore, samples at their left and right and, respectively, upper and bot-
tom borders are, virtually, immediate neighbors in the interpolation process. 
Therefore, any discontinuity between opposite border samples will cause 
heavy oscillations due to tales of the discrete sinc-function that propagate 
far away from the borders.
A simple and very efficient solution of this problem is zero padding in the 
domain of discrete cosine transform (DCT):
	
 a
a
k
LN
L
N
k
= IDCT
{DCT_ZP [DCT (
)]}, 	
(6.14)
where DCT ( )
N ⋅ and IDCT
( )
LN ⋅ are N-points fast direct and LN-points inverse 
discrete cosine transforms and DCT_ZP []
L ⋅ is a DCT spectrum zero-padding 
operator that places (L − 1)N zeros after the last (N − 1)-th DCT spectrum 
sample. Similarly to the Case_1 DFT zero padding, for faster decay of the 
interpolation kernel, it is also advisable to halve the last two spectral samples 
that, for DCT, represent the signal highest frequency component.
Figure 6.3 demonstrates improvement, in terms of boundary effect oscilla-
tions, of image zooming in by means of DCT spectrum zero-padding algo-
rithm compared to DFT spectrum zero padding.

300
Theoretical Foundations of Digital Imaging Using MATLAB®
As it is shown in Appendix, PSF of the DCT spectrum zero padding with 
halving its last two components is defined by the equation




a
LN
N L
a
N
NL nL
k
nL
k
n
n
N
=
+
+
−
(
)




=
−
∑
α
π
π
0
0
1
2
1
1 2
DCT
sin
(
)
sin
/
−
(
)




−
(
)







+
+
+
(
)





k
NL
nL
k
L
N
NL nL
k
2
2
1 2
cos
sin
(
)
π
π
/




+
(
)




+
(
)




+
−
sin
cos
sin
(
)
π
π
π





nL
k
NL
nL
k
L
N
NL n
2
2
1 2
/
L
k
nL
k
NL
N
NL
nL
k
−
(
)




−
(
)




−
−
(
)




+





sin
cos
sin
π
π
2
2
2
π
π
π
(
)
sin
cos
N
NL nL
k
nL
k
NL
N
NL
nL
k
−
+
(
)




+
(
)




−
+
1 2
2
2
2
/






(
)







.
(6.15)
Frequency responses and PSFs of DFT and DCT zero-padding signal 
4×-subsampling are shown for comparison in Figure 6.4. One can see from 
these figures that they are quite close to one another. One can also see from 
Equation 6.15 that DCT zero-padding interpolation is not cyclic shift invari-
ant and is implemented by two pairs of sincd-function interpolation kernels 
1/2-shifted and mirror reflected with respect to each other. Its behavior is 
illustrated in Figure 6.5 for sampling positions at signal left and right bound-
aries and at the middle of the signal extent.
Computation-wise, signal L-times zooming by mean of zero padding its 
DFT or DCT spectra requires, with the use of fast Fourier transform or fast 
DCT algorithms, O
N
(log
) operations per each of signal N samples for direct 
transform and O L
NL
( log
) operation for inverse transform of zero-padded 
FIGURE 6.3
Zooming of an image fragment outlined by white box (a) by means of zero padding its DFT 
spectrum (b) and zero-padding DCT spectrum (c).

301
Image Resampling and Building Continuous Image Models
spectra, which is quite inefficient for large L. Moreover, when conventional 
radix 2 FFT and fast DCT algorithms are used, zooming factor L should 
be selected to be an integer power of 2. These two facts limit to a certain 
degree applicability of the spectra zero-padding algorithms. However, their 
use might be a good practical solution when one works in an appropriate 
software environment, such as, for instance, MATLAB. Image zooming by 
means of DCT spectra zero padding can also be naturally used when images 
are represented in a compressed form such as in JPEG compression. In this 
case, zooming can be carried out without the need to decompress images.
DFT- and DCT-Based Signal Fractional Shift Algorithms 
and Their Basic Applications
In this section, we describe signal resampling algorithms that are based on 
the perfect δx-shifting filter introduced in the section “Perfect Resampling 
Filter.” The filter is designed in DFT domain and, therefore, it can be imple-
mented using fast Fourier transform with computational complexity of 
0
0
0.2
0.4
0.6
0.8
(a)
(b)
1
0
0.2
–0.2
20
40
60
80
100
120
0.4
0.6
0.8
1
0.5
1
1.5
2
Normalized frequency
DFT vs DCT zero-padding frequency responses
DFT-sincd
DCT-sincd
DFT-sincd
DCT-sincd
2.5
3
3.5
4
FIGURE 6.4
Frequency responses (a) and point spread functions (b) of DFT (DFT-sincd) and DCT (DCT-
sincd) zero-padding signal 4×-subsampling (N = 32, L = 4).

302
Theoretical Foundations of Digital Imaging Using MATLAB®
O
N
(log
) operations per output signal sample. The algorithm is described 
by the equation
	
a
x
a
k
N
k
x
N
r
Shift
N
k
(
)
(
)
IFFT
(
)
[FFT (
)] ,
, ,...,
δ
η
δ
=
{
}
{
}
=
−
⋅
0 1
1,
	
(6.16)
where FFT ( )
N ⋅ and IFFT ( )
N ⋅ are direct and inverse N-point fast Fourier trans-
forms, ⋅ symbolizes component-wise product elements of two arrays and 
ηr
Shift u x
(
)(
)
∆
{
} are defined, for odd and even N by the above Equations 6.6 
and 6.7.
This algorithm is suitable for numerous applications. First of all, it allows 
generating arbitrarily shifted discrete sinc interpolated copies of signals. 
0.8
(a)
(b)
(c)
0.6
0.4
0.2
0
–0.2
0.8
0.6
0.4
0.2
0
–0.2
0.8
0.6
0.4
0.2
0
–0.2
20
40
60
80
100
120
20
40
60
80
100
120
20
40
60
80
100
120
FIGURE 6.5
Point spread function of signal 4×-subsampling by means of DCT zero padding for three dif-
ferent sampling positions: at the beginning (a), in the middle (b), and at the end (c) of the signal 
interval.

303
Image Resampling and Building Continuous Image Models
Another application is signal/image zooming-in with an arbitrary integer 
zoom factor. For zoom factor L, signal/image zooming can be implemented 
through generating subsequently computed L − 1 signal/image copies 
shifted by corresponding multiple of 1/L shifts:
	
a
l x
L
a
k
l x
N
r
Shift
N
k
(
)
(
)
IFFT
[FFT (
)]
δ
η
=














∆
⋅

=
−
,
,...,
.
l
L
1
1
	
(6.17)
The work of this algorithm is illustrated by a plot in Figure 6.6 obtained 
using program sincd_interpol_demo.m provided in Exercises.
Mathematically, such image zooming-in method is completely equivalent to 
the above-described DFT spectrum zero padding, but is much more computa-
tionally efficient. Its computational complexity for L-factor zooming is O
N
(log
) 
per output sample rather than O
LN
(log
) for the zero-padding method, and 
this complexity does not depend on whether L is power of two or not.
Obtained in this way, zoomed-in images represent the most perfect 
“continuous” models of images that can be generated for a prescribed sub-
sampling interval. Such models can be used, in particular, for perform-
ing image resampling over an arbitrary sampling grid. In this process, 
required image samples, whose positions do not coincide with one of sam-
pling nodes of the denser sampling grid of the zoomed-in image, can be 
approximated by the nearest available sample of the zoomed-in image as it 
is illustrated in Figure 6.7a. If the selected zoom factor is provided appro-
priately, the nearest-neighbor interpolation in combination with discrete 
sinc interpolated zooming-in will not compromise interpolation accuracy 
substantially. For instance, as one can see from the plot of the frequency 
response of the nearest-neighbor interpolator shown in Figure 6.7b, for 
0
–0.2
–0.1
0
0.1
0.2
1
2
3
4
5
6
7
8
Initial sample indices
Initial and interpolated samples: L = 3
9
10
11
12
13
14
15
Shift 0
Shift 1
Shift 2
FIGURE 6.6
​Initial signal samples (bold) and two sets of its subsamples shifted by 1/3 (shift 1) and 2/3 (shift 
2) of the sampling interval by means of the perfect shifting filter.

304
Theoretical Foundations of Digital Imaging Using MATLAB®
zoom factor 5, decay of the frequency response on the highest spatial fre-
quency of the initial image is only 1.3% and for zoom factor 3, it is 3.5%, 
which can also be frequently tolerated.
One of the important applications, in which “continuous” image models are 
required, is fast location and tracking of moving targets in video sequences. 
In this case, template images of the target with arbitrary orientation and scale 
can be very rapidly computed by means of corresponding resampling of the 
magnified template image of the target obtained with a sufficiently large 
zoom factor. Other application examples are image reconstruction from pro-
jections using the direct Fourier reconstruction algorithm and image recon-
struction from fan-beam projections, which will be discussed below in the 
section “Image Data Resampling for Image Reconstruction from Projections.”
Two more applications worth of special mention are “quasicontinuous” 
Fourier spectrum analysis for detection and localization, with subpixel accuracy, 
of periodical components and image correlation analysis for detection and 
localization, with subpixel accuracy, of position of signal correlation peaks.
1
0.987
0.965
0.932
0.907
0.882
0.857
0.832
0.807
0.782
0.757
0.732
0.707
–0.5
–0.4
–0.25 –0.167–0.1
0
Normalized frequency
(b)
3× zooming-in
5× zooming-in
0.1 0.167
0.25
0.4
0.5
Initial samples
(a)
Subsamples
Required sample
on a new sampling grid
FIGURE 6.7
Nearest-neighbor interpolation in resampling of zoomed-in images (a) and its frequency 
response (b) within zoomed-in image baseband ([−0.5 ÷ 0.5]). Double arrows show base bands 
of initial images before their 5× and 3× zooming-in.

305
Image Resampling and Building Continuous Image Models
The “quasicontinuous” spectrum analysis with subpixel resolution in fre-
quency domain l f L
l LN x
∆
∆
=
 can be performed by means of applying to 
the signal shifted DFT(0,l/L) subsequently L times:
	
α
π
r
l
N
ka
i
kl
LN
l
L
( )
FFT
exp
,
,...,
.
=








=
−
2
1
1
	
(6.18)
As it is shown in Appendix, intermediate spectrum samples obtained in 
this way are discrete-sinc interpolated from samples {αr} of the basic DFT 
spectrum
	
α
α
π
π
r
l
r
s
N
N
s
r
l N
i
N
s
r
l N
N
( )
sincd[
; (
)]exp
(
)(
)
=
−
−
−
−
−




=
−
∑
1
0
1
.
	
(6.19)
Correlation analysis with subpixel resolution of signals {ak} and {bk} can be 
performed using the algorithm that follows from the convolution theorem 
for DFTs (Equation 4.63):
c
l x
L
a
b
k
l x
N
r
Shift
N
k
N
k
(
)
(
)
IFFT
[FFT (
)] [FFT (
δ
η
=








∆
⋅
⋅
)] ,
,...,
.






=
−
l
L
1
1
	
(6.20)
Being a cyclic convolution, the “DFT-based” signal fractional shift algo-
rithm suffers from the same boundary effects as described above in DFT 
zero-padding algorithm. The efficient practical solution of the problem 
is computing convolution in DCT domain instead of DFT domain as it is 
described in the section “Signal Convolution in the DCT Domain.” The DCT-
based signal δx-shifting algorithm is defined by the equation


a
x
k
r
r
Shift
k
N r
=
(
)
{
}−
−(
)
{
}⋅
(
)
{
}
−
(
)
1
2
1
IDCT
Re
IDCT
I
α
η
δ
α
DCT
DCT m
Re



η
δ
α
η
δ
α
η
N r
Shift
Shift
r
x
N
x
−
{
}
(
)
{
}
(
)
(
)
{
}
=
(
)+
1
2
2
0
0
DCT
DCT
r
Shift
r
N
k
N r
x
k
N
r
δ
π
α
(
)
(
)
+







−
−(
)
=
−
−
(
)
∑
1
1
1 2
2
1
cos
/
DCT Im
cos
/
η
δ
π
N r
Shift
r
N
x
k
N
r
−
(
)
=
−
(
)
(
)
+







∑
1
1
1 2
(6.21)
that follows from Equation 4.119. The filter coefficients η
δ
r
Shift
x
(
)(
)
{
} in this 
equation are defined by Equations 4.113 and 4.116, in which discrete sinc-
functions defined by Equations 6.8 through 6.11 should be used as the convo-
lution kernel {hn} of the filter in Equation 4.113. Because of this, the DCT-based 
algorithm is equivalent, in terms of the interpolation accuracy, to the above 
DFT-based perfect fractional shift algorithm.

306
Theoretical Foundations of Digital Imaging Using MATLAB®
In application to signal L times zooming-in, the algorithm can be applied 
repeatedly L − 1 times similar to the DFT-based algorithm:


a
x
k
l x
r
r
Shift
l
k
N r
δ
α
η
δ
α
=
(
)
(
)
{
} −
−(
)
{
}⋅
(
)
{
}
−
1
2
1
IDCT
Re
IDCT
DCT
DCT
DCT
(
)
−
{
}
(
)
(
)
(
)
(
)


=
(
)
Im 

η
δ
α
η
δ
N r
Shift
l
Shift
x
N
x
1
2
0
0
(
) +
(
)
(
)




+


(
)
(
)
=
−
∑
l
r
r
Shift
l
r
N
x
k
N
r
2
1 2
1
1
α
η
δ
π
DCT Re
cos
/







−
−(
)
(
)
(
)




−
(
)
(
)
=
−
 
DCT
2
1
1
1
k
N r
r
Shift
l
r
N
x
α
η
δ
Im

∑
+







=
−
cos
/
,
,
π k
N
r
l
L
1 2
1
1
…
	
(6.22)
using, at l-th step, η
δ
r
Shift
l
x
(
)(
)
(
)  as the filter coefficients.
With respect to boundary effects, DCT-based fractional shift algorithm is 
as efficient as the above-described DCT spectrum zero-padding algorithm. 
It is illustrated in Figure 6.8 on an example of subsampling (magnification) 
of a saw-tooth signal.
As one can see on the figure, oscillations that propagate from signal bor-
ders for DFT-based discrete sinc interpolation almost completely disappear 
when DCT-based discrete sinc interpolation algorithm is used.
Fast Image Rotation Using the Fractional Shift Algorithms
Rotation of a 2D coordinate system by an angle θ as a geometrical transfor-
mation of signal coordinates can be described as a multiplication of signal 
coordinate vector (x,y) by a rotation matrix ROTθ:
1
0.8
0.6
0.4
0.2
0
50
100
DFT-based interpolation
DCT-based interpolation
Original signal samples
150
Sample indices
200
250
FIGURE 6.8
DFT-based versus DCT-based subsampling of a signal shown by dotted stems.

307
Image Resampling and Building Continuous Image Models
	
ROTθ
θ
θ
θ
θ


x
y
x
y



=
−








cos
sin
sin
cos
.
	
(6.23)
In computers, physical coordinates (x,y) are represented, given sampling 
intervals (Δx,Δy), by integer indices of pixels {k,l}:
	
x
y
k x
l y



= 



∆
∆
	
(6.24)
and the rotation matrix is applied to the vector of indices:
	
ROTθ
θ
θ
θ
θ
k
l
k
l



=
−








cos
sin
sin
cos
.
	
(6.25)
Equation 6.25 describes the resampling rule that should be applied to input 
image pixel indices to generate indices of its rotated copy. In order to reduce 
the computational complexity of this transformation, it is advisable to factor-
ize the rotation matrix into a product of three matrices each of which modi-
fies only one coordinate:
 
ROTθ
θ
θ
θ
θ
θ
θ
=
−



=
−







cos
sin
sin
cos
tan(
)
sin
1
2
0
1
1
0
1
/

−




1
2
0
1
tan(
) .
θ/
	
(6.26)
This implementation of image rotation is known as the three-pass rota-
tion algorithm. It carries out, on each of three passes, only shifts along one of 
the coordinates: along rows on the first pass, along columns on the second 
pass, and again along rows on the third pass as it is illustrated in Figure 
6.9. Specifically, in rotation of an image of Nx × Ny pixels (k = 0,1,. . .,Nx − 1, 
l = 0,1,. . .,Ny − 1) around point (0 ≤ k0 ≤ Nx − 1; 0 ≤ l0 ≤ Ny − 1) on the first pass 
k-th row is shifted by δ
θ
x
x
k
k
k ∆
= −
−
tan(
)(
)
/2
0 , on the second pass l-th 
column is shifted by δ
θ
x
x
l
l
k ∆
=
−
sin (
)
0 , and on the third pass again k-th 
row is shifted by δ
θ
x
x
k
k
k ∆
= −
−
tan(
)(
)
/2
0 . The above-described DFT- or 
DCT-based signal fractional shift algorithms are ideally suited for perform-
ing these shifts.
As far as these algorithms implement a cyclic convolution, image rotation 
by this method entails characteristic aliasing artifacts at image borders. They 
are illustrated in Figure 6.9b. One can avoid them by inscribing the image 
into an array of correspondingly larger size, as it is shown in Figure 6.9a or 
by using only the aliasing free image part inside the circle of the diameter 
equal to the image linear size (see Figure 6.9d).

308
Theoretical Foundations of Digital Imaging Using MATLAB®
Image Zooming and Rotation Using “Scaled” and Rotated DFTs
DFT- and DCT-based fractional shift algorithms enable efficient signal/
image discrete sinc interpolated subsampling and zooming-in with an 
integer zoom factor. Direct- and inverse-scaled discrete Fourier transform 
(ScDFT(ux,vf;σ)):
	
α
σ
π
σ
σ
α
σ
r
u v
k
x
f
k
N
k
r
u v
N
a
i
k
u
r
v
N
a
N
, ;
,
exp
(
)(
) ,
=
+
+




=
=
−
∑
1
2
1
0
1
; exp
(
)(
)
σ
π
σ
−
+
+




=
−
∑
i
k
u
r
v
N
x
f
r
N
2
0
1
	
(6.27)
Initial image
First pass
Initial image
First pass
Second pass
Tird pass: rotated image
Second pass
Tird pass: rotated image
(a)
(b)
(c)
(d)
FIGURE 6.9
The principle of the three-pass image rotation algorithm and aliasing artifacts associated with 
implementation of interpolation as cyclic convolution: (a) rotation without aliasing; (b) rota-
tion aliasing artifacts owing to the cyclicity of the convolution; (c) and (d) initial image and 
10 × 36o-rotated image, which shows aliasing artifacts outside the circle of the diameter equal to 
the image linear size.

309
Image Resampling and Building Continuous Image Models
introduced in Chapter 4 (Equations 4.36 and 4.37), when applied with differ-
ent scale parameters enable signal/image discrete sinc interpolated rescaling 
with an arbitrary scale factor. In order to prove this, let scale parameters for 
direct and inverse transforms be σd and σi, and shift parameters be u
v
x
d
f
d
( )
( )
,
, 
and u
v
x
i
f
i
( )
( )
,
, respectively. Then from Equations 6.27, obtain, with selection 
v
v
v
N
f
i
f
d
f
( )
( )
(
)
=
=
= −
−1 2 (see Appendix):
	
a
N
i
k
u
r
v
N
k
i
r
u v
x
i
f
i
i
r
N
d
=
−
+
(
)
+
(
)








=
−
∑
1
2
0
1
σ
α
π
σ
σ
, ;
( )
( )
exp
=
+
−
+










=
−
∑
1
0
1
σ σ
π
σ
σ
i
d
n
x
d
d
x
i
i
n
N
a
N
n
u
k
u
sincd
;
,
( )
( )
	
(6.28)
which means discrete sinc interpolated signal resampling in scaled coordi-
nates. In applications, one can set either of the scale parameters σd or σi to one.
As it is shown in Chapter 4, scaled DFT can be represented as a digital 
convolution, and therefore, by the convolution theorem, can be computed 
using FFT. Comparing with the above-described zooming-in algorithm, this 
method is not as fast, but it allows performing completely arbitrary image 
magnifying–demagnifying. It is especially important for the magnification 
factors in the range 0.5–2, which otherwise can be achieved with a compara-
ble accuracy, using the above-described zooming-in algorithm, only through 
subsampling highly oversampled image.
One can supplement image rescaling with rotation using rotated scaled 
DFT introduced in Chapter 4 (Equation 4.52) with appropriately selected 
scale and rotation angle parameters. Similarly to the above-described signal 
shift or signal rescaling using shifted DFT or scaled DFT, one can use rotated 
DFT for image rescaling and rotation by applying RotDFT with appropriate 
scale and rotation angle parameters to signal SDFT spectrum. It is shown in 
Appendix that image ak l,  obtained through inverse shifted scaled DFT of the 
image spectrum computed using shifted DFT (ux,uy;vf,vp) is a discrete sinc 
interpolated rotated and scaled copy of initial image {am,n}:
	

 

a
N
N
a
i
mr
N
ns
N
k l
m n
n
N
m
N
,
, exp
=
+








=
−
=
−
∑
∑
1
1
2
0
1
0
1
σ
π






×
+
−
=
−
=
−
∑
∑
s
N
r
N
i
k
l
N
r
k
0
1
0
1
2
exp
cos
sin
sin
( )
π
θ
θ
σ
σ




θ
θ
σ
σ
π
θ
σ
−












=
+
+





l
N
s
a
N
m
k
l
m n
cos
sincd
;
cos
s
( )
,
1
in
sincd
;
cos
si
θ
σ
π
θ












×
+
−
=
−
=
−
∑
∑
n
N
m
N
N
n
l
k
0
1
0
1



n
,
θ
σ












	
(6.29)

310
Theoretical Foundations of Digital Imaging Using MATLAB®
where m
m
u
=
+
1, n
n
u
=
+
2, r
r
v f
=
+
1; s
s
v f
=
+

2 ; k
k
u
=
+
1
( )
σ , l
l
u
=
+
2
( )
σ , 
r
r
v f
=
+
1; s
s
v f
( )
( )
σ
σ
=
+
2 , and v
v
v
v
N
f
f
f
f
1
1
2
2
1 2
=
=
=
= −
−
( )
( )
(
)
σ
σ
/
.
To conclude this discussion of discrete sinc-interpolation algorithms men-
tion that, as these algorithms are implemented through processing in DFT 
or DCT domain, one can combine rotation and scaling with adaptive image 
restoration and enhancement through nonlinear modification of its spectrum 
such as soft/hard thresholding, P-th low dynamic range compression and 
alike described in Chapter 8. Figure 6.10 illustrates this option. It shows a 
result of a simultaneous image rotation and scaling along with a result of 
rotation, scaling, denoising, and enhancement by means of thresholding of 
low-energy spectral coefficients combined with rising of absolute values 
of remaining (not zeroed by thresholding) image spectral coefficients to a 
power P < 1 (in this particular case, P = 0.5).
Discrete Sinc Interpolation versus Other Interpolation 
Methods: Performance Comparison
In this section, we provide experimental data of comparison of discrete sinc 
interpolation with other more traditional numerical interpolation methods 
in terms of the interpolation accuracy and signal preservation. Compared 
with discrete sinc interpolation are methods offered by the MATLAB image 
processing toolbox: nearest-neighbor interpolation, linear (bilinear) interpo-
lation and cubic (bicubic) spline interpolation. PSFs and frequency responses 
of the compared interpolation methods are shown in Figure 6.11.
Plots of frequency responses of the methods clearly reveal major drawback 
of the traditional interpolation methods: they tend to substantially attenu-
ate high-frequency signal components within the signal base band (fre-
quency interval [−0.5 ÷ 0.5] in Figure 6.11c) and introduce substantial aliasing 
FIGURE 6.10
​Simultaneous image rescaling, rotation, denoising, sharpening, and enhancement using 
RotScDFT: (a) initial image; (b) 10o-rotated and 1.7 times magnified image; (c) 10o-rotated, 1.7 
times magnified, denoised, sharpened, and enhanced image.

311
Image Resampling and Building Continuous Image Models
frequency components outside this interval (in the case of signal subsam-
pling). In imaging, this tendency results in image blurring that can heavily 
worsen visual image quality and its applicability for further analysis, for 
instance, object recognition, target location, and alike.
In Figures 6.12 through 6.14, results of comparison experiments carried out 
using program RotateComparis_demo_CRC.m (see Exercises) are presented 
that vividly illustrate this phenomenon on examples of multiple rotation of 
test images of a piece of printed text (Figure 6.12a) and of a pseudorandom 
image with uniform spectrum that was low-pass prefiltered to 0.7 of the base 
band in both directions (“Prus” image, Figure 6.12b) to exclude aliasing arti-
facts outside the circle of the radius equal to the highest horizontal and verti-
cal spatial frequency.
With this program, for nearest-neighbor, bilinear, and spline interpolation 
methods, rotations were carried out using MATLAB program imrotate.m 
159
150
PSF_nn
PSF_lin
PSF_spline
PSF_sincd
FR_nn
FR_lin
FR_spl
FR_scincd
140
130
120
110
100
90
80
70
60
50
40
30
20
10
1
1
0.8
(a)
(b)
(c)
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
–0.2
0
1
0.8
0.6
0.4
0.2
0
159
150
140
130
120
110
100
90
80
Frequency responses of interpolators
Normalized frequency
–2.5
–2
–1.5
–1
–0.5
0.5
1
1.5
2
2.5
0
70
60
50
40
30
20
10
1
FIGURE 6.11
Point spread functions (a, b) and frequency responses (c) of nearest-neighbor (nn), linear (lin), 
bicubic spline (spl), and discrete sinc (sincd) interpolators.

312
Theoretical Foundations of Digital Imaging Using MATLAB®
from the image processing toolbox. For discrete sinc interpolated rotation, 
the program contains a code that implements the three-step rotation algo-
rithm through DFT-based fractional shift algorithm described in the previ-
ous section.
Images shown in Figure 6.13 clearly show that, after 60 rotations through 
18° each, standard interpolation methods completely destroy the readability 
of the text, while discrete sinc interpolated rotated image is virtually not 
distinguishable from the original one.
In the analysis of interpolation errors, it is very instructive to compare 
their power spectra to see which spectral components suffered more. For this 
purpose, test image “Prus” is very appropriate. Figure 6.14 presents spectra 
of rotation errors computed as spectra of differences between the initial test 
image “Prus” and the results of its rotation by 1080° carried out in 60 steps 
using bilinear, bicubic, and discrete sinc interpolations. One can see in the 
figure that in the case of discrete sinc interpolation, error spectrum is practi-
cally zero within the base band circle, while for bicubic and for bilinear inter-
polation, error spectrum intensity is low only for low spatial frequencies and 
grows quite substantially to high frequencies.
DFT- and DCT-based image resampling algorithms are advantageous over 
more traditional methods not only in terms of the interpolation accuracy, but 
also in terms of the computational efficiency, which is evidenced, in particu-
lar, by the above-described experiments in image rotation using MATLAB 
implementations of the algorithms: numerical data on computation time 
data presented in the caption to Figure 6.13 show that discrete sinc interpola-
tion works substantially faster than bicubic interpolation.
The computational efficiency of the interpolation error-free discrete sinc 
interpolation algorithms is rooted in the use of fast Fourier and fast DCT 
transforms. Perhaps, the best last concluding remark of this discussion of the 
FIGURE 6.12
​Test images for comparison of interpolation methods: “Text” image (a) and a pseudorandom 
image (b) with uniform spectrum within 0.7 of the base band (“Prus” image).

313
Image Resampling and Building Continuous Image Models
discrete sinc interpolation methods and their applications would be men-
tioning that fast Fourier transform algorithm was invented about 200 years 
ago by Carl Friedrich Gauss for the purpose of facilitating numerical interpo-
lation, in fact by the method which we now call discrete sinc interpolation, of 
sampled data of astronomical observation [1].
Numerical Differentiation and Integration
Perfect Digital Differentiation and Integration
Signal numerical differentiation and integration are operations that require 
measuring infinitesimal increments of signals and their arguments. Therefore, 
FIGURE 6.13
Discrete sinc interpolation versus conventional numerical interpolation methods used for 
60 × 18o rotations of the test image “Text”: (a) nearest-neighbor interpolation, computation time 
(CT) 7.27 time units; (b) bilinear interpolation, C = 11.1 time units; (c) bicubic interpolation, 
CT = 17.7 time units; (d) discrete sinc interpolation, CT = 14.16 time units.

314
Theoretical Foundations of Digital Imaging Using MATLAB®
numerical computing signal derivatives and integrals assume one of another 
method of building “continuous” models of signals specified by their samples 
through explicit or implicit interpolation between available signal samples. 
Because differentiation and integration are shift invariant linear operations, 
methods of computing signal derivatives and integrals from their samples can 
be conveniently designed and compared in the Fourier transform domain.
Let the Fourier transform spectrum of a continuous signal a(x) be α(f):
	
a x
f
i
fx
f
( )
( )exp(
)
.
=
−
−∞
∞
∫α
π
2
d
	
(6.30)
FIGURE 6.14
​Spectrum of test image “Prus” (a) and spectra of rotation error after 60 × 18o rotations of the 
image using bilinear (b), bicubic (c), and discrete sinc interpolation (c). All spectra are shown 
in frequency coordinates (white arrows) centered at spectrum zero frequency (dc-component), 
image lightness being proportional to error spectra intensity; bright points in (d) are spectral 
aliasing components intentionally left at the borders of the image base band to secure, for dis-
play purposes, the same image dynamic range as that of (b) and (c).

315
Image Resampling and Building Continuous Image Models
Then the Fourier spectrum of its derivative
	
a x
x a x
i
f
f
i
fx
f
( )
( )
[(
) ( )]exp(
)
=
=
−
−
−∞
∞
∫
d
d
d
2
2
π α
π
	
(6.31)
will be (−i2πf)α(f) and the Fourier spectrum of its integral
	
a x
a x
x
i
f
f
i
fx
f
( )
( )
( ) exp(
)
=
=
−












−
∫
∫
−∞
∞
d
d
1
2
2
π
α
π
	
(6.32)
will be α(f)/(−i2πf). Therefore, signal differentiation and integration can be 
regarded as signal linear filtering with filter frequency responses, respectively
	
H
f
i
f
diff
(
)( ) = −2π 	
(6.33)
and
	
H
f
i
f
(
)( )
.
intg
=
2π
	
(6.34)
Now, let signal a(x) be represented by its samples {ak}, k = 0,1,. . .,N − 1 and 
let {αr} be a set of DFT coefficients of the discrete signal {ak}:
	
a
N
i
kr
N
k
r
r
N
=
−




=
−
∑
1
2
0
1
α
π
exp
.
	
(6.35)
Then, following the argumentation of the section “Fast Algorithms for 
Discrete Sinc Interpolation and Their Applications” for the optimal resa-
mpling filter and using the relationship of Equation 4.79 that establishes 
mutual correspondence between continuous signal frequency and fre-
quency index of its DFT, one can conclude that samples ηr opt
diff
,
(
)
{
} and ηr opt
,
(
)
intg
{
} 
of continuous frequency response of perfect numerical differentiation and 
integration filters are defined for even N as
	
η
π
π
π
r
diff
i
r N
r
N
r
N
i
N
r
N
r
N
(
)
,
, ,...,
,
(
)
,
=
−
=
−
−
=
−
=
2
0 1
2
1
2
2
2
2
/
/
/
/
/
/ ++
−



1
1
,...,
,
N
	
(6.36)
	
η
π
π
π
r opt
r
iN
r
r
N
r
N
iN
N
r
,
(
)
,
,
,...,
,
(
)
intg =
=
=
−
−
=
−
0
0
2
1
2
1
2
2
2
/
/
/
/
/
,,
,...,
,
r
N
N
=
+
−






/2
1
1 	
(6.37)

316
Theoretical Foundations of Digital Imaging Using MATLAB®
and for odd N as
	
η
π
π
r
diff
i
r N
r
N
i
N
r
N
r
N
(
)
,
, ,...,(
)
(
)
,
(
)
,.
=
−
=
−
−
−
=
+
2
0 1
1 2
1
2
1 2
/
/
/
/
..,
,
N −



1
	
(6.38)
	
η
π
π
r
iN
r
r
N
iN
N
r
r
N
(
)
,
, ,...,(
)
(
),
(
)
,..
intg =
=
−
−
−
=
+
/
/
/
/
2
0 1
1 2
1
2
1 2
.,
.
N −



1
	
(6.39)
One can show that numerical differentiation and integration according to 
Equations 6.36 through 6.39 imply discrete sinc interpolation of signals. Note 
that the coefficients ηN
diff
/
(
)
2  and ηN/
(
)
2
intg  in Equations 6.36 and 6.37 are halved 
that correspond to the above-described Case_1 of discrete sinc interpolation 
(Equation 6.12).
Equations 6.36 through 6.39 imply the following algorithmic implementation 
for computing derivatives and integrals of signals specified by their samples:
	
a
a
k
N
r
diff
k
{ } =
{
}
(
)
IFFT
FFT({
}) ,
(
)
η
⋅
	
(6.40)
	
a
a
k
N
r
k
{ } =
{
}
(
)
IFFT
FFT({
}) ,
(
)
η intg
⋅
	
(6.41)
where FFT( )⋅ and IFFT( )⋅ are direct and inverse fast Fourier transforms and 
⋅ symbolizes element-wise multiplication of vectors. Thanks to the use of 
fast Fourier transform, the computational complexity of the algorithms is 
O
N
(log
) operations per signal sample. Digital filter described by Equation 
6.40 is called the discrete ramp-filter.
Like all DFT-based discrete sinc interpolation algorithms, DFT-based dif-
ferentiation and integration algorithms, being the most accurate in term of 
preserving signal spectral components within the base band, suffer from 
boundary effects. Especially vulnerable in this respect is DFT-based differen-
tiation because of discontinuities at signal borders due to their periodical rep-
lication in processing in the DFT domain. This drawback can be sufficiently 
alleviated by means of extension of the signals to double length through of 
mirror reflection at their boundaries before applying the above-described 
DFT-based algorithms. For such extended signals, DFT-based differentiation 
and integration are reduced to using fast DCT algorithms instead of FFT:
	
a
N
N
r
N
N
N
r
k
N r
k
N r
{ } = −
−
(
)
{
}
=
−(
)
−
(
)
−
(
)
−
(
)
2
2
2
2
1
π
α
π
α
IDCT
co
DCT
DCT
s π k
N
r
r
N
+




=
−
∑
1 2
1
1
/
	
(6.42)

317
Image Resampling and Building Continuous Image Models
a
N
N
r
N
k
N r
k
N r
{ } =
−










=
−(
)
−
(
)
−
2
2
2
2
1
π
α
π
α
IDCT
DCT
DCT
(
)
=
−
−
+




∑N
r
k
N
r
r
N
cos π
1 2
1
1
/
	
(6.43)
where αr
(
)
DCT
{
} are DCT transform coefficients of the signal. These formu-
las can be obtained as special cases of fast digital convolution algorithms 
described in the section “Signal Convolution in the DCT Domain” if one 
substitutes into Equation 4.121 frequency responses of differentiation and 
integration filters given by Equations 6.36 through 6.39. We will refer to the 
filters defined by Equations 6.42 and 6.43 as DCT-based differentiation ramp-
filter and DCT-based integration filter, respectively.
Traditional Numerical Differentiation and Integration Algorithms 
versus DFT/DCT-Based Ones: Performance Comparison
In numerical mathematics, alternative methods of numerical computing 
signal derivatives and integrals are commonly used that are implemented 
through signal discrete convolution in the signal domain:
	
a
h
a
k
n
diff
k n
n
Nh
=
−
=
−
∑
(
)
,
0
1
	
(6.44)
	
a
h
a
k
n
k n
n
Nh
=
−
=
−
∑
intg
0
1
	
(6.45)
The following simplest differentiating kernels of two and five samples are 
recommended in manuals on numerical methods [2]:
	
hn
diff ( )
[
. ,
,
. ]
1
0 5 0 0 5
= −
	
(6.46)
and
	
hn
diff ( )
[
,
, ,
,
].
2
1 12 8 12 0
8 12 1 12
= −
−
/
/
/
/
	
(6.47)
Both are based on an assumption that, on intersample distances, signals 
can be expanded into Taylor series. We will refer to them as D1 and D2 dif-
ferentiation methods.
Most known numerical integration methods are the Newton–Cotes quadra-
ture rules [2]. The first three rules are the trapezoidal, the Simpson, and 
the 3/8-Simpson rules. In all the methods, the value of the integral in the 

318
Theoretical Foundations of Digital Imaging Using MATLAB®
first point is not defined because it affects only the result’s constant bias 
and should be arbitrarily chosen. When it is chosen to be equal to zero, the 
trapezoidal, Simpson, and 3/8-Simpson numerical integration methods are 
defined, for k as a running sample index, by equations, respectively:
	
a
a
a
a
a
T
k
T
k
T
k
k
1
1
1
0
1
2
( )
( )
( )
,
(
),
=
=
+
+
−
−
	
(6.48)
	
a
a
a
a
a
a
S
k
S
k
S
k
k
k
1
2
2
1
0
1
3
4
( )
( )
( )
,
(
),
=
=
+
+
+
−
−
−
	
(6.49)
	
a
a
a
a
a
a
a
S
k
S
k
S
k
k
k
k
0
3 8
3 8
3
3 8
3
2
1
0
3
8
3
3
( /
)
( /
)
( /
)
,
(
).
=
=
+
+
+
+
−
−
−
−
	
(6.50)
As it was mentioned in the section “DFTs and Discrete Frequency Response 
of Digital Filter,” continuous and overall frequency responses of digital fil-
ters are determined by their discrete frequency responses (DFT of their PSF). 
Applying N-point discrete Fourier transform to Equations 6.48 through 6.50, 
obtain for discrete frequency responses ηr
diff ( )
1 , ηr
diff ( )
2 , ηr
T
int, , ηr
S
int, , ηr
,
S
(
)
int 3 8  of 
the above-described numerical differentiation and integration methods, 
respectively:
	
η
π
r
diff
r N
r
N
( )
sin(
);
, ,...,
1
2
0 1
1
∝
=
−
/
	
(6.51)
	
η
π
π
r
diff
r N
r N
r
N
( )
sin(
)
sin(
) ;
, ,...,
2
8
2
4
12
0 1
1
∝
−
=
−
/
/
	
(6.52)
	
η
α
α
π
π
r
T
r
Tr
r
r
r N
i
r N
r
N
(
, )
(
)
,
,
cos(
)
sin(
) ,
,...,
int
=
=
=
−
=
−
0
0
2
1
1
/
/



	
(6.53)
	
η
α
α
π
π
r
S
r
S
r
r
r N
i
r N
r
N
(
, )
( )
,
cos(
)
sin(
) ,
,...,
int
=
=
=
−
+
=
0
0
2
2
3
2
1
/
/
−



1
	
(6.54)
   
η
α
α
π
π
π
r
,
S
r
S
r
r
r N
r N
i
r N
(
)
(
)
,
cos(
)
cos(
)
sin(
int 3 8
3
0
0
3
3
3
=
=
=
−
+
/
/
/
)
,
,...,
r
N
=
−



1
1
	
(6.55)

319
Image Resampling and Building Continuous Image Models
These frequency responses along with frequency responses of DFT-based 
differentiation and integration filters (Equations 6.51 through 6.55) are 
shown, for comparison, in Figures 6.15 and 6.16, respectively.
One can see from these figures that standard numerical differentiation 
and integration methods entail certain and sometimes very substantial dis-
tortions of signal spectral contents on high frequencies. All these methods 
attenuate signal high frequencies, and Simpson and 3/8-Simpson integration 
methods, being slightly more accurate than the trapezoidal method in the 
middle of the signal base band, even tend to generate substantial artifacts if 
signals contain higher frequencies. Frequency response of the 3/8-Simpson 
rule tends to infinity for 2/3 of the maximum frequency, and the frequency 
response of the Simpson rule has almost the same tendency for the maximal 
0.8
0.6
0.4
0.2
00
0.2
0.4
0.6
Ramp
D2
D1
Normalized frequency
Frequency response
0.8
FIGURE 6.15
​Absolute values of frequency responses of differentiation filters described by Equation 6.51 
(curve D1), Equation 6.52 (curve D2), and Equations 6.40 and 6.42 (“Ramp”-filter).
0
10–4
10–3
10–2
Frequency response
10–1
100
0.1
0.2
0.3
0.4
0.5
Trapezoidal
Cub spline
3/8-Simpson
Simpson
DFT
Normalized frequency
0.6
0.7
0.8
0.9
1
FIGURE 6.16
​Absolute values of frequency responses of numerical integration filters described by Equations 
6.53 through 6.55 and that of the DFT-based method (Equations 6.41 and 6.43).

320
Theoretical Foundations of Digital Imaging Using MATLAB®
frequency in the base band. This means, in particular, that noise that might 
be present in input data and round off computation errors will be overampli-
fied by Simpson and 3/8-Simpson in these frequencies.
Quantitative evaluation of performance of the considered differentiation 
methods can be carried out using a simulation program differentiator_com-
parison_CRC.m provided in Exercises. The program implements statistical 
simulation of differentiation by the considered methods of realizations of 
pseudorandom signals with uniform spectrum in the range from 1/16 of 
the base band to the entire base band. Figures 6.17 and 6.18 present results 
of such an experimental evaluation. In the simulation, 16 series of statisti-
cal experiments with 100 experiments in each run were carried out. In the 
runs, realizations of pseudorandom signals of 32,704 samples with uniform 
Fourier spectrum were generated in order to imitate, by means of 32-fold 
10–3
10–2
ErrSrtDev/DerivativeStdDev
10–1
100
10–4
10–5
10–3
10–2
ErrSrtDev/DerivativeStdDev
10–1
100
D1-0.25
DFT-0.25
DFT-0.5 DFT-0.75
DFT-1
D2-1
D2-0.75
D2-0.5
D2-0.25
D1-0.5
DFT-0.25
DCT-0.25 DCT-0.5
DCT-0.75
DCT-1
50
100
150
200
250
Sample index
Differentiation error, 100 realizations; No ApodMask
Differentiation error, 100 realizations; No ApodMask
(a)
(b)
300
350
400
450
500
50
100
150
200
250
Sample index
300
350
400
450
500
DFT-0.5 DFT-0.75
DFT-1
D1-0.75
D1-1
D2-1
D2-0.75
D2-0.5 D2-0.25
FIGURE 6.17
​Experimental data on signal sample-wise normalized standard deviation of the differentiation 
error for D1, D2, and DFT-based differentiation methods (a) and for D2, DFT-, and DCT-based 
methods. (b) Numbers at curves indicate fraction (from one quarter to one) of test signal band-
width with respect to the base bandwidth as defined by the sampling rate.

321
Image Resampling and Building Continuous Image Models
oversampling, continuous signals. In each run, generated pseudorandom 
signals were low-pass filtered to 1/32 of its base-band using the ideal low-
pass filter implemented in DFT domain. The filtered signal was then used as 
a model of a continuous signal and its derivative was computed using DFT 
domain ramp-filter and used as an estimate of the signal ideal derivative. 
Then the central half of this signal, which encompasses 16,352 samples taken 
8196 samples apart from the signal borders, was subsampled with rate 32 to 
generate 511 signal samples that were used in the differentiation by the four 
methods: D1 method (Equation 6.46), D2 method (Equation 6.47), DFT-based 
method (Equation 6.40), and DCT-based method (Equation 6.42). The cor-
responding central part of the ideal derivative signal was also subsampled 
with rate 32 and was used as a reference to evaluate the differentiation error 
for tested methods. The differentiation error was computed as a difference 
between the “ideal” derivative and the results of applying tested differen-
tiation methods divided by the standard deviation of the “ideal” derivative 
over all samples, thus producing estimations normalized to the derivative 
signal energy. Finally, the standard deviation of the normalized error over 
100 realizations was found for each signal sample. The obtained results are 
plotted sample-wise in Figure 6.17a for methods D1, D2, and DFT and in 
Figure 6.17b for methods D2, DFT, and DCT.
In Figure 6.17a, one can see that, indeed, the simplest method D1 performs 
very poorly, while method D2 outperforms the DFT method for signals with 
bandwidth <0.5 of the base band because of the boundary effects for the lat-
ter. It can also be seen that the accuracy of the DFT differentiation method 
substantially improves with the distance from signal boundaries. However, 
even for samples that are far away from signal boundaries, boundary effects 
0.2
10–5
10–4
ErrorStDev/DerivativeStDev
10–3
10–2
10–1
0.4
0.6
Signal bandwidth
DCT
D2
DFT
D1
0.8
1
FIGURE 6.18
Normalized standard deviation of the differentiation error averaged over 100 samples in the 
middle of the signal (samples from 200-th to 300-th) for D1, D2, DFT, and DCT differentiation 
methods as a function of test signal bandwidth (in fractions of the base band defined by the 
signal sampling rate).

322
Theoretical Foundations of Digital Imaging Using MATLAB®
badly deteriorate its differentiation accuracy. Data presented in Figure 6.17b 
evidence that the DCT-based differentiation method does successfully over-
come the boundary effect problem and substantially outperforms both D1 
and D2 methods even for narrow band signals.
In order to exclude boundary effects in evaluating and comparing dif-
ferentiation errors, Figure 6.18 presents plots of normalized error standard 
deviation computed on average over the central 100 samples (from 200th to 
300th) of the test signals with different bandwidth.
These plots convincingly evidence that method D2 provides better accu-
racy only for signals with bandwidth <0.05 of the base band, and even for 
such signals, normalized error standard deviation for the DCT method is 
anyway <10−5. For signals with broader bandwidth, the accuracy of the DCT 
differentiation method is better than for other methods by at least two orders 
of magnitude. One can also find, using this simulation program, that mask-
ing signal with a window (“apodization”) function, which gradually nulls 
signal samples in the vicinity of its border, substantially improves the dif-
ferentiation accuracy of both DFT and DCT methods even further.
Also note that, as it follows from the above results, traditional numerical 
methods maintain a good differentiation accuracy if signals are very sub-
stantially oversampled, which actually undermines their only advantage, 
their low computational complexity.
One more way to evaluating accuracy of numerical differentiation and 
integration is iterative application to a test signal successive differentiation 
and integration and comparison of restored signals with the initial signal. 
Plots in Figure 6.19 obtained using program diffrentiat_integrat_error_
CRC.m (Exercises) illustrate results performed in this way comparison of 
DCT-based differentiation and integration and of conventional D2 method of 
differentiation and trapezoidal method of integration. One can clearly see on 
these plots that conventional methods of differentiation and integration tend 
to very substantially blur signals. Using this program, one can also see that 
DCT-based differentiation/integration procedures have two to three orders 
of magnitude lower standard deviation of the signal restoration error.
Local (“Elastic”) Image Resampling: Sliding Window Discrete 
Sinc Interpolation Algorithms
The above-described perfect DFT- and DCT-based fractional shift algorithms 
are computationally very efficient for performing regular shifts of all image 
pixels. For image resampling in arbitrary sampling grids, they can be used 
as it was described above for generating highly oversampled “quasicontin-
uous” image models, which require additional large memory buffers. An 

323
Image Resampling and Building Continuous Image Models
alternative solution is implementation of discrete sinc interpolation in slid-
ing window processing.
In signal interpolation in sliding window, the perfect shifting filter is gen-
erated and applied, in each window position, only for pixels within the win-
dow, and only interpolated signal samples that correspond to the window 
central sample have to be computed in each window position from signal 
samples within the window. The interpolation function in this case is a dis-
crete sinc-function, whose extent is equal to the window size rather than 
to the whole image size required for the perfect discrete sinc interpolation. 
Therefore, sliding window discrete sinc interpolation cannot provide the 
perfect interpolation, which the above-described global discrete sinc inter-
polation does. Figure 6.20 illustrates 1D frequency responses of sliding win-
dow, for window size of 15 pixels, and of global (full image size) discrete sinc 
interpolations for image 3× zooming.
50
0
0.2
0.4
0.6
0.8
(a)
(b)
1
0
0.2
0.4
0.6
0.8
1
100
150
Sample index
DCT diff/integr: 100 iterations
D2/trap differ/integr: 100 iterations
Initial signal
Iterated diff-integr signal
Initial signal
Iterated diff-integr signal
200
50
100
150
Sample index
200
FIGURE 6.19
​Comparison signal restoration after iterative successive 100 differentiations and integrations 
applied to a rectangular test signal for DCT-based differentiation and integration methods (a) 
and for D2 differentiator and trapezoidal rule integrator (b).

324
Theoretical Foundations of Digital Imaging Using MATLAB®
Such an implementation of the discrete sinc interpolation can be regarded 
as a special case of signal domain convolution interpolation methods. As 
it follows from the above theory, it, in principle, has the highest interpola-
tion accuracy among all convolution interpolation methods with the same 
interpolation kernel support. Additionally, being implemented in the DFT 
or DCT domains, it offers an option of image resampling with simultaneous 
restoration and enhancement by means of methods of local adaptive filtering 
described in Chapter 8.
In local adaptive filtering carried out in sliding window, in each posi-
tion of the window transform, coefficients of window samples are com-
puted and then nonlinearly modified to obtain transform coefficients of 
the output signal samples in the window. These coefficients are then used 
to generate an estimate of the window central pixel by inverse transform 
computed for the window central pixel. Such a filtering can be imple-
mented in the domain of any transform. Therefore, one can, in a straight-
forward way, combine the sliding window DFT or DCT domain discrete 
sinc interpolation signal resampling and filtering for signal restoration 
and enhancement.
Figure 6.21 illustrates the application of such a combined filtering/interpo-
lation for image irregular-to-regular resampling combined with denoising.
In this example, the left image is distorted by known displacements of 
pixels with respect to regular equidistant positions and by an additive noise. 
In the right image, these displacements are compensated and noise is sub-
stantially reduced with the above-described sliding window resampling/
denoising algorithm.
–0.5
0
0.2
0.4
0.6
0.8
1
–0.4
–0.3
–0.2
–0.1
0
Normalized frequency
0.1
0.2
Frequency responses of sliding window and global 3×-zoom discrete sinc interpolators
0.3
Slid. window-15 sincd-interpol
Global sincd-interpol
0.4
0.5
FIGURE 6.20
​Frequency responses of sliding window of 15 samples (dotted line) and of the perfect (global) 
discrete sinc interpolations (solid line) for signal 3×-zooming.

325
Image Resampling and Building Continuous Image Models
Image Data Resampling for Image Reconstruction 
from Projections
Discrete Radon Transform: An Algorithmic Definition and Filtered 
Back Projection Method for Image Reconstruction
Precise data resampling is a crucial issue in image reconstruction from projec-
tions. As it was shown in the section “Imaging from Projections and Radon 
Transform” of Chapter 2, image reconstruction from projections is based on 
properties of integral Radon transform. The main problem in discrete repre-
sentation of the integral Radon transform is definition, for computing image 
projections, of line integral under arbitrary angle over an image sampling grid.
Any definition of the discrete line integral should assume one or another 
method of image interpolation for finding image values along the projection 
line in its points that do not coincide with nodes of image sampling grid. For 
a rectangular sampling grid, only column-wise, row-wise, and 45° diagonal-
wise integrations do not require any interpolation. One possible solution of 
this problem is line integration over a “continuous” image model, obtained 
by means of the above-described method of image zooming-in with discrete 
sinc interpolation. Another, and a more computationally efficient, solution is 
the following algorithmic definition of the discrete Radon transform:
	
Pr
k
a
r
l
k l
r
(
, )
SUM ROT ({
}) ,
,
θ
θ
=
[
] 	
(6.56)
where {Pr(θr,k)} are samples of the r-th projection, taken under angle θr, of the 
image defined by its samples {ak,l} over a square sampling grid {k,l}; ROT ( )
θr ⋅ 
is an operator of image rotation by the angle θr around the center of the sam-
pling grid and SUM []
l ⋅ is the operator of summation of samples of the rotated 
image over index l.
FIGURE 6.21
An example of image resampling from irregular to regular sampling grid and denoising: (a) noisy 
and irregularly sampled image; (b) resampled (rectified) and simultaneously denoised image.

326
Theoretical Foundations of Digital Imaging Using MATLAB®
With this definition, the required image interpolation is carried out in the 
process of image rotation. In order to secure the least possible interpolation 
error, image rotation should be performed with discrete sinc interpolation. 
We will assume that for the implementation of the rotation operator, the 
above-described fast three-step rotation algorithm is used, which preserves 
the number of image samples, although the above-described image rotation 
algorithm in scaled coordinates can, in principle, be used as well.
The filtered back projection algorithm for image reconstruction from pro-
jections is defined by Equation 2.107. According to the above definition of 
the discrete Radon transform, this algorithm can be implemented as the 
following:
	
a
Pr
k
k l
r
l
r
r
,
SUM
ROT
{BckP {RAMPF{
(
, )}}} ,
=
{
}
−θ
θ
	
(6.57)
where {Pr(θr,k)} are samples of the image r-th projection, taken under angle 
θr, RAMPF{}⋅ is an operator of ramp-filtering for differentiation described in 
the section “Numerical Differentiation and Integration,” BckP {}
l ⋅ is a “back 
projection” operator implemented as replication of the operand over index l 
and SUM {}
r ⋅ is a summation operator that sums up replicated filtered projec-
tions over the entire set of projection angles {θr}.
Figure 6.22 generated using program radon_invradon_demo_CRC.m 
provided for exercises (Exercises) illustrates discrete Radon transform and 
image reconstruction using the filtered back projection method.
FIGURE 6.22
​Test image (a), a set of its projections with projection angle as the vertical coordinate (b), an 
example of filtered projection projected backward along the horizontal projected line (c), and 
reconstructed image (d).

327
Image Resampling and Building Continuous Image Models
Direct Fourier Method of Image Reconstruction
According to the direct Fourier method of image reconstruction from their 
parallel projections (see the section “Imaging from Projections and Radon 
Transform”), 1D Fourier spectra of projections should be placed under their 
corresponding angles in a polar coordinate system in frequency domain to 
form a 2D image spectrum, which then can be used for image reconstruction 
by inverse Fourier transform. As one can see from Figure 6.23 that shows a 
polar coordinate system of spectral samples in a Cartesian coordinate system, 
spectral samples are nonuniformly spaced in Cartesian coordinates and are 
very sparse, especially high-frequency ones. In principle, one can attempt to 
apply, for reconstruction of spectral samples on a uniform dense grid, itera-
tive algorithms for image recovery from sparse nonuniform samples consid-
ered in Chapter 5 using a priori redundancy of images associated with empty 
area around body slice, which is always present. However, this method also 
does not seem feasible because of very high sparsity of spectral samples on 
high frequencies, which is not compensated by the image redundancy.
Another option is computing 2D inverse Fourier transform using shifted 
DFTs with shift parameters in frequency domain specific for each particular 
spectrum sample according to its position in 2D Cartesian coordinate sys-
tem, in which SDFT is defined. However, in this case, fast Fourier transform, 
FIGURE 6.23
Spectral samples (small circles) in a Cartesian sampling grid (crosses).

328
Theoretical Foundations of Digital Imaging Using MATLAB®
which exists only for uniform sampling grids, is not applicable. That makes 
such solution impractical by virtue of its high computational complexity.
A feasible practical option for solving this problem is polar-to-Cartesian 
coordinate conversion of spectra of projections to 2D image spectrum by 
means of resampling, in Cartesian coordinates, of a “continuous” model 
of the projection spectra in polar coordinate system formed through sepa-
rable (radial frequencies-wise and angle index-wise) zooming-in projection 
spectra using discrete sinc interpolation. Figure 6.24 presents an illustrative 
example of image reconstruction from projections achieved through inverse 
DFT of image 2D spectrum obtained by resampling of image spectrum in 
polar coordinate system.
Image Reconstruction from Fan-Beam Projections
Described above methods of image reconstruction from projections assume 
image projection in parallel x-ray beams. This is the original classical image 
Test image
Projection spectra
Angle
Radial frequencies
Reconstructed image
5 × Angle (grades)
5 times subsampled projection spectra
5 × Radial frequency index
(a)
(b1)
(b2)
(c)
FIGURE 6.24
​An illustrative example of image restoration from projections using the direct Fourier reconstruc-
tion method: (a) test image; (b1) projection spectra; (b2) projection spectra five times subsampled 
in both coordinates for polar-to-Cartesian coordinate conversion (only half of the spectral coeffi-
cients that correspond to frequencies from zero to the highest one in the base band are displayed; 
the others that are complex conjugate to them are not shown); (c) image reconstructed by means 
of inverse DFT applied to 2D spectrum obtained by resampling zoomed-in projection spectra.

329
Image Resampling and Building Continuous Image Models
reconstruction method, for which well-developed reconstruction algorithms 
are available. In practice, in commercial CT scanners fan-beam projection 
rather than parallel-beam one is used because fan-beam projections can be 
obtained with a point source of x-ray, which is much easier for fabrication 
than collimated parallel beam sources.
The geometry of fan projection is sketched in Figure 6.25. Point source of 
radiation makes full 360° revolution around the object and integrals of absorp-
tion of radiation by the object over projection lines form, for each position 
angle α of the point source, projections Pr(α, β) as a function of the ray angles 
β. All sets of projections for −π ≤ α ≤ π is then used for image reconstruction.
In principle, for inverting Radon transform in fan-beam projection geom-
etry, dedicated reconstruction algorithms are required. There is however an 
alternative and attractive option of converting, by an appropriate resampling, 
the set of fan projections to a set of parallel projections and to enable in this 
way image reconstruction using algorithms for image reconstruction from 
parallel projections. For the resampling, one can use the above-described 
algorithms for resampling by means of image zooming-in using global or 
local discrete sinc interpolation. The latter can be, if required, combined 
with denoising as it was discussed in the section “Local (“Elastic”) Image 
Resampling: Sliding Window Discrete Sinc Interpolation Algorithms.” This 
process of converting one type of projections into another type is called data 
rebinning. Figure 6.26 illustrates this method of image reconstruction.
Radiation point source
Projection lines
–π ≤ α ≤ π
–π/2 ≤ β ≤ π/2
Pr (α, β)
x
y
β
α
FIGURE 6.25
​Geometry of image fan projections.

330
Theoretical Foundations of Digital Imaging Using MATLAB®
Appendix
Derivation of Equations 6.6 and 6.7
From Equation 6.2, for odd number of signal samples N, we have
	
h
x
N
x
i
nr
N
N
n
Shift
r
Shift
r
N
r
(
)
(
)
(
(
)
(
)exp
δ
η
δ
π
η
=
−




=
=
−
∑
1
2
1
0
1
Shift
r
N
r
Shift
x
i
nr
N
x
)
(
)/
(
)
(
)exp
(
)e
δ
π
η
δ
−







+
=
−
∑
2
0
1
2
xp
(
)exp
(
)/
(
)
−







=
−
=
+
−
∑
i
nr
N
N
x
i
n
r
N
N
r
Shift
2
1
2
1
2
1
π
η
δ
π
r
N
x
i
n
N N
r
r
N
N r
Shift
  







+
−
−

=
−
−
∑
0
1
2
2
(
)/
(
)(
)exp
(
)
η
δ
π








=
−
∑
r
N
1
1
2
(
)/
FIGURE 6.26
​Image reconstruction from fan projections: (a) initial test image; (b) its fan-beam projections; 
(c) parallel projections converted from the fan-beam projections; (d) image reconstructed from 
converted parallel projections.

331
Image Resampling and Building Continuous Image Models
	
=
−







+
=
−
−
∑
1
2
0
1
2
N
i
nr
N r
r
Shift
r
N
N r
Shift
η
π
η
(
)
(
)/
(
exp
  
)
(
)/
(
)
exp
(
)exp
i
nr
N
N
x
i
nr
r
N
r
Shift
2
1
2
1
1
2
π
η
δ
π







=
−
=
−
∑
  
N
x
i
nr
N
r
N
r
Shift
r
N



+




=
−
=
−
∑
0
1
2
1
1
2
(
)/
*(
)
(
(
)exp
η
δ
π
)/
(
exp
exp
2
0
1
2
2
∑






=




−




=
N
i
x
N x r
i
nr
N
r
π δ
π

  
N
r
N
i
x
N x
i
nr
N
−
=
−
∑
∑



+
−








1
2
1
1
2
2
2
)/
(
)/
exp
exp
π δ
π




=
−
−



+
−
=
−
∑
1
2
2
0
1
2
N
i
n
x
x
N
r
i
n
x
x
N
r
r
N
exp
exp
(
)/
π
δ
π
δ


  










=
−
∑
r
N
1
1
2
(
)/
.
Denote temporarily
	
n
n
x
x
=
−δ
∆.
Then obtain
	
h
x
N
i
n
N N
i
n
N
n
Shift
(
)(
)
exp
(
)
exp
δ
π
π
=
−
+



−
−




1
1
1
2


  
  
−






+
+



−






1
1
2
2
exp
(
)
exp
exp
i
n
N N
i
n
N
i
n
N
π
π
π


 
−






=
−
−




−



1
1
N
i n
i
n
N
i
n
N
exp(
)
exp
exp
π
π
π



  
  
−










+
−




exp
exp(
)
exp
exp
i
n
N
i n
i
n
N
i
π
π
π
π




  
n
N
i
n
N
N
i n
i
n
N



−
−










=
−
−
+

exp
exp(
)
exp
π
π
π



1
  


+
−







−
−


exp(
)
exp
exp
exp
i n
i
n
N
i
n
N
i
n
N
π
π
π
π



 

=




=
−
1
N
n
n
N
N
n
x
x
sin(
)
sin
sincd[
, (
)].
π
π
π
δ




332
Theoretical Foundations of Digital Imaging Using MATLAB®
For even number of signal samples N, we have from Equation 6.2
	
h
x
N
x
i
nr
N
N
n
intp
r
Shift
r
N
r
S
(
)
(
)
(
(
)
(
)exp
δ
η
δ
π
η
=
−




=
=
−
∑
1
2
1
0
1
hift
r
N
r
Shift
x
i
nr
N
x
i
n
)
/
(
)
(
)exp
(
)exp
δ
π
η
δ
π
−



+
−
=
−
∑
2
2
0
2 1
 
r
N
N
x
i
nr
N
r N
N
r
Shift










=
−



=
−
∑
/
(
)(
)exp
2
1
1
2
η
δ
π
+
−
−







=
−
−
=
∑
∑
r
N
N r
Shift
r
N
i
n
N N
r
0
2 1
1
2
2
/
(
)
/
exp
(
)
 
η
π


=
−



+
=
−
−
∑
1
2
0
2 1
N
i
nr
N
x
r
Shift
r
N
N r
Shift
η
π
η
δ
(
)
/
(
)
exp
(
 
)exp
(
)exp
/
(
)
i
nr
N
N
x
i
n
r
N
r
Shift
2
1
2
1
2
π
η
δ
π










=
−
=∑
r
N
x
i
nr
N r
r
N
r
Shift
r
N



+




=
−
=
∑
0
1
2
1
2
2
(
)/
*(
)
/
(
)exp
 
η
δ
π
∑






=




−




=
−
1
2
2
0
2 1
N
i
x
N x r
i
nr
N
r
N
exp
exp
/
π δ
π


∑
∑



+
−







+
=
−
exp
exp
/
/
(
i
x
N x r
i
nr
N
r
N
N
2
2
1
2 1
2
π δ
π
η


Shift
r
x
i N n
N
N
i
n
x
x
N
r
)(
)exp
exp
δ
π
π
δ







=
−
−




1
2
 
  
=
−
=
−
∑
∑



+
−




+
0
2 1
1
2 1
2
2
N
r
N
N
Shift
i
n
x
x
N
r
/
/
/
(
exp
 
 
π
δ
η
 
)
/
(
)exp(
)
exp
exp
δ
π
π
π
x
i n
N
i
nr
N
i
r
N



=
−



+
=
−
∑
1
2
2
0
2 1
    


n
N r
x
i
x
x
r
N
N
Shift







+



=
−
∑
1
1
2
2
(
)/
/
(
)(
)exp
 η
δ
π δ
 
=
−
−
−
−
+
−
−
exp(
)
exp(
)
exp(
(
))
exp(
)
i n
N
i n
i
n N
i n
π
π
π
π




1
1
2
1
/
 
 
exp(
(
) )
exp(
(
))
(
/
(
)
i
n N r
i
n N
x
N
Shift
2
2
1
2
π
π
η
δ


/
/
 
−






+
)exp
exp(
)
i
x
x
i n
π δ
π












333
Image Resampling and Building Continuous Image Models
=
−
−
−
−
−
1
1
N
i
N
N n
i
n N
i
n N
i
n
exp(
(
) )
exp(
(
))
exp(
(
))
exp(
(
π
π
π
π
/
/
/



/
/
/
/
N
i
N
N n
i
n N r
i
n N
i
))
exp(
(
) )
exp(
(
) )
exp(
(
))
exp(
+
−
−
−
−
π
π
π
π
1



(
))
exp
exp(
)
e
/
(
)



n N
i
x
x
i n
N
N
Shift
/
 



+







=
η
π δ
π
2
1
∆
xp(
(
) )
exp(
(
) )
exp(
(
/
) )
exp(
(
i
N
N n
i
n N r
i
N
N n
i
π
π
π
π
−
−
−
−
−
+
1
1
/
/



n N
i
n N
i
n N
x
N
Shift
/
/
/
))
exp(
(
))
exp(
(
))
(
)exp
/
(
)
π
π
η
δ


−
−



+
2
i
x
x
i n
N
i
N
N n
i
N
π δ
π
π
π



∆







=
−
−
−
−
exp(
)
exp(
(
) )
exp(
(
1
1
1
/
/N n
i
n N
i
n N
i
x
x
N
Shift
) )
exp(
(
))
exp(
(
))
exp
/
(
)




π
π
η
π δ
/
/
−
−
+


2
∆









=
−
+
exp(
)
sin( (
) )
sin( ( /
))
/
i n
N
N
N n
n
N
N
π
π
π
η



1
1/
2
(
)(
)exp(
(
))exp(
) .
Shift
x
i
x
x
i n
δ
π δ
π


/∆






Case_0: ηN
opt
intp
/ ,
(
)
;
2
0
=
	
h
x
N N
n
x
x
n
intp
(
)(
)
sincd[
;
; (
)].
0
1
δ
π
δ


=
−
−
∆
Case_2: η
π δ
N
Shift
x
x
/
(
)
cos( (
));
2
2
=
/∆
	
h
x
N N
n
x
x
n
intp
(
)(
)
sincd[
;
; (
)],
0
1
δ
π
δ


=
+
−
∆
where
	
sincd{
;
; }
sin(
)
sin(
) .
N M x
N
Mx N
x N
= 1
/
/
Proof for Case_2. Find ηN
Shift
/
(
)
2
2  that satisfies the condition:
	
sin( (
) )
sin( (
))
exp
ex
/
(
)
π
π
η
π δ
N
N n
n N
i
x
x
N
Shift
−
+




1
2
2
/
/



∆
p(
)
sin( (
) )
sin( (
))
.
i n
N
N n
n N
π
π
π



=
+ 1/
/
From the above equation,
	
η
π
π
π
N
Shift
N
N n
N
N n
n N
/
(
)
sin( (
) )
sin( (
) )
sin( (
))
exp
2
1
1
=
+
−
−
/
/
/



(
)exp
−
−




i n
i
x
x
π
π δ


∆

334
Theoretical Foundations of Digital Imaging Using MATLAB®
=
−
−



=
−
=
2
2
2
cos(
)exp(
)exp
cos(
)exp(
)
π
π
π δ
π
π




n
i n
i
x
x
n
i n
∆
cos
(
)
cos(
)(
) cos
π
δ
π
π δ
n
x
x
n
x
x
n
n
−







−
=
−






∆
∆
1
2
1
=




2cos
.
π δx
x
∆
PSF of Signal Zooming by Means of Zero Padding of Its DCT Spectrum
Consider analytical expressions that describe signal zooming by means of 
zero padding its DCT spectrum. Let αr
DCT be DCT spectrum of signal {ak},
	
α
π
π
r
k
k
N
k
N
a
k
r
N
N
a
i
k
r
DCT
/
/
=
+



=
+
=
−
∑
2
1 2
1
2
2
1 2
2
0
1
cos
(
)
exp
(
)

N
k
N




=
−
∑
0
2
1
,
where k = 0,. . .,N − 1 and
	
a
a
k
N
a
k
N
LN
k
k
N
k
=
=
−
=
−



−−
,
,...,
,
,...,
.
0
1
1
2
1
Form a zero pad spectrum:
	
α
α
r
L
r
r
N
r
N
LN
DCT
DCT
,
,
,...,
,
,...,
.
=
=
−
=
−



0
1
0
1
Being a DCT spectrum, this spectrum has an odd-symmetry property 
(Equation 4.95):
	



α
α
α
r
L
LN r
L
LN
L
DCT
DCT
DCT
,
,
,
;
.
= −
=
−
2
0
Compute inverse DCT of the zero pad spectrum, using representation of 
DCT through SDFT(1/2,0) and this symmetry property (4.95):
	


a
LN
i
k
r
N
LN
k
r
L
r
N
r
=
−
+




=
=
−
∑
1
2
2
1 2
2
1
2
0
2
1
α
π
α
DCT
DCT
/
, exp
(
)
exp
(
)
exp
(
)
−
+







+
−
+
=
−
∑
i
k
LN
r
i
k
r
N
r
2
1 2
2
2
1 2
0
1
π
α
π
/
/
DCT

2
2
1
2
1
LN
r
r
LN N
LN







=
−
+
−
∑

335
Image Resampling and Building Continuous Image Models
=
−
+







+
=
−
−
∑
1
2
2
1 2
2
0
1
2
LN
i
k
LN
r
r
r
N
LN r
α
π
α
DCT
DCT
/
 
exp
(
)

exp
(
) (
)
−
+
−







=
−
∑
i
k
LN
LN
r
r
N
2
1 2
2
2
1
1
π
/
	
=
+
−
+







−
=
−
∑
1
2
2
1 2
2
0
1
1
LN
i
k
LN
r
r
r
N
r
α
α
π
α
DCT
DCT
DC
/
 
exp
(
)
T
DCT
D
/
exp
(
) (
)
−
+
−







=
+
=
−
∑
i
k
LN
LN
r
LN
r
N
r
2
1 2
2
2
1
2
1
1
0
π
α
α
CT
DCT
/
 
/
exp
(
)
exp
(
−
+







+
+
=
−
∑
i
k
LN
r
i
k
r
N
r
2
1 2
2
2
1 2
0
1
π
α
π
)
.
2
0
1
LN
r
r
N







=
−
∑
Replace in this formula αr
DCT with its expressions through SDFT(1/2,0) in 
the right part of Equation 4.93 and obtain


a
LN
N
a
i
n
r
N
i
k
n
n
N
=
+
+




−
=
−
∑
1
2
1
2
2
1 2
2
2
0
0
2
1
α
π
π
DCT
/
exp
(
)
exp
(
)
exp
(
)
k
LN
r
N
a
i
n
r
N
r
N
n
+







+
+




=
−
∑
1 2
2
1
2
2
1 2
2
1
1
/
/

π

+







=
+
=
−
=
−
∑
∑
n
N
r
N
r
i
k
LN
r
LN
L
0
2
1
1
1
2
1 2
2
2
1
2
exp
(
)
π
α
/
DCT
N
N
a
i
n
k
L
r N
n
n
N
r
N
1
2
1 2
1 2
0
2
1
1
1

exp
π
+
−
+











=
−
=
−
∑
/
/
∑
+
+
+
+











exp
.
i
n
k
L
r N
π
1 2
1 2
/
/
Denote n
n
=
+ 1 2
/  and k
k
=
+ 1 2
/ . Then obtain





a
LN
LN
N
a
i
n
k
L r
N
i
k
r
n
=
+
−












+
α
π
π
DCT
2
1
2
1
2
exp
exp
n
k
L r
N
n
N
r
N
+


















=
−
=
−
∑
∑

0
2
1
1
1

336
Theoretical Foundations of Digital Imaging Using MATLAB®
=
+
−












+
+
α
π
π
0
2
1
2
1
2
DCT
LN
LN
N
a
i
n
k
L r N
i
n
k
n




exp
exp
L r N
a
i
n
n
N
r
N
n






















+
=
−
=
−
∑
∑
0
1
1
1
 


exp π
−












+
+





















k
L r N
i
n
k
L r N
exp π

=
+
−












+
=
−
∑
n N
N
n
LN
LN
N
a
i
n
k
L r N
2
1
0
2
1
2
1
2
α
π
DCT



exp
exp i
n
k
L r N
n
N
r
N
π 


+






















+
=
−
=
−
∑
∑
0
1
1
1
a
i
N
n
k
L r N
i
N
n
k
L
N
n
2
1
2
2
−−
−
−












+
−
+




exp
exp
π
π























=
+
=
−
∑
r N
LN
LN
N
a
i
n
N
n
0
1
0
2
1
2
1
2
α
π
DCT
exp
n
k
L r N
i
n
k
L r N
−












+
+




















exp π





+
−
+











=
−
=
−
−−
∑
∑
n
N
r
N
N
n
a
i
n
k
L r N
0
1
1
1
2
1
 



exp
π

+
−
−






















=
=
−
∑
exp
i
n
k
L r N
n
N
π
α


0
1
0
DCT
2
1
2
1
1
LN
N L
a
i
n
k
L r N
i
n
k
L
n
r
N
+
−












+
+

=
−
∑exp
exp
π
π


















+
−
+





=
−
=
−
∑
∑
r N
i
n
k
L r N
r
N
n
N
1
1
0
1
 
exp
π 








+
−
−















=
=
−
=
−
∑
∑
r
N
r
N
i
n
k
L r N
1
1
1
1
exp
π
α


0
2
1
2
DCT
LN
N L
a
i
nL
k
L
i
nL
k
LN
i
n
+
−





−
−






exp
exp
exp
π
π
π










nL
k
LN
nL
k
L
i
nL
n
N
−





−



+
+





−
+
=
−
∑
1
0
1
 
exp
exp π
k
LN
nL
k
LN
nL
k
L
n






+





−
+
−
+





−
−
exp
exp
exp
π
π
π





1
 
L
k
LN
nL
k
LN
i
nL
k
L
+






−
+





−
+
−
−





−





exp
exp
ex
π
π
1
 
p
exp
−
−






−
−





−



=
+
i
nL
k
LN
i
nL
k
LN
LN
π
π
α




1
2
1
2
0
DCT
N L
a
N
NL nL
k
nL
k
NL
n
n
N
=
−
∑
+
−






−






0
1
1
2
2
sin
sin
exp
π
π




i
nL
k
L
π 

−












2

337
Image Resampling and Building Continuous Image Models
	
+
+
+




+
+
sin
(
)
sin[ (
)
]
exp[
(
)
π
π
π
N
NL
nL
k
nL
k
NL
i
nL
k
L
1
2
2
2






]
sin
(
)
sin[ (
)
]
exp[
(
+
+
+




+
−
+
π
π
π
N
NL
nL
k
nL
k
NL
i
nL
k
1
2
2





)
]
sin
(
)
sin[ (
)
]
exp[
(
2
1
2
2
L
N
NL
nL
k
nL
k
NL
i
nL
+
+
−




−
−
π
π
π





−






k
L
)
] .
/2
From this, we finally obtain:
	




a
LN
N L
a
N
NL
nL
k
n
k
n
n
N
=
+
+
−




=
−
∑
α
π
π
0
0
1
2
1
1
2
DCT
sin
(
)
sin[ ( L
k
NL
nL
k
L
N
NL
nL
k
−
−



+
+
+









)
]
cos[ (
)
]
sin
(
)
si
2
2
1
2
π
π
n[ (
)
]
cos[ (
)
] .
π
π




nL
k
NL
nL
k
L
+
+



2
2
By analogy with DFT zero padding, one can improve the speed of conver-
gence of DCT zero-padding PSF by halving DCT spectral coefficients that 
correspond to the highest frequency. For signals of N samples, these are coef-
ficients with indices N − 2 and N − 1. To find an analytical expression for this 
case, we first compute, using above two equations, L-zoomed signal for the 
case when those coefficients are zeroed:
	



a
LN
N L
a
i
n
k
L r
N
k
r
n
r
N
=
+
−















=
−
∑
α
π
DCT
2
1
2
1
3
exp

+
+












+
−
+

=
−
=
−
∑
∑
n
N
r
N
i
n
k
L r
N
i
n
k
L
0
1
1
3
exp
exp
π
π















+
−
−












=
−
=
−
∑
r
N
i
n
k
L r
N
r
N
r
N
1
3
1
3
exp
π 

∑
	
	
	

338
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
+
−
−












−
=
−
∑
α
π
π
0
0
1
2
1
1
2
DCT
LN
N L
a
N
N
n
k
L
n
n
n
N
sin
sin






k
L
N
N
N
n
k
L












−
−



















+
2
2
2
cos
s
π
in
sin
cos
π
π
N
N
n
k
L
n
k
L
N
−
+












+












1
2
2




π N
N
n
k
L
−
+












	
	


	


2
2


.
Then L-zoomed signal obtained by zero-padding signal DCT spectrum 
and halving its highest frequency components is defined by the equation
	




a
LN
N L
a
N
NL nL
k
nL
k
n
n
N
=
+
+
−
=
−
∑
α
π
π
0
0
1
2
1
1 2
DCT
/
sin[ (
)(
)]
sin[ (
−
−







+
+
+





k
NL
nL
k
L
N
NL nL
k
)
]
cos
sin[ (
)(
)]
si
2
2
1 2
π
π
/
n[ (
)
]
cos
sin[ (
)(
)]
π
π
π






nL
k
NL
nL
k
L
N
NL nL
k
+
+




+
−
−
2
2
1 2
/
sin[ (
)
]
cos
(
)
sin[ (
)(
π
π
π




nL
k
NL
N
NL
nL
k
N
NL
−
−
−




+
−
2
2
2
1 2
/






nL
k
nL
k
NL
N
NL
nL
k
+
+
−
+




	
	
	
)]
sin[ (
)
]
cos
(
)
.
π
π
2
2
2
Derivation of Equation 6.18
	
α
π
π
r
l
N
k
k
a
i
kl
LN
N
a
i
kl
LN
( )
FFT
exp
exp
exp
=







=




2
1
2
i
kr
N
k
N
2
0
1
π




=
−
∑
.
Replace in this equation {ak} with its expression through its DFT spectrum, 
{αr} and obtain
α
α
π
π
π
r
l
r
s
N
N
i
ks
N
i
kl
LN
i
kr
N
( )
exp
exp
exp
=
−








=
−
∑
1
2
2
2
0
1




=
−
−
−



=
=
−
=
−
=
−
∑
∑
∑
k
N
r
k
N
s
N
N
i
s
r
l N
N
k
N
0
1
0
1
0
1
1
2
1
α
π
α
exp
r
s
N
i
s
r
l N
i
s
r
l N
N
exp[
(
)]
exp[
(
)
]
−
−
−
−
−
−
−
−
=
−
∑
2
1
2
1
0
1
π
π

339
Image Resampling and Building Continuous Image Models
	
=
−
−
−
−
−
−
−
−
−
1
N
i
s
r
l N
i
s
r
l N
i
s
r
l N
N
r
α
π
π
π
exp[
(
)]
exp[
(
)]
exp[
((
)
)]
e
/
xp[
((
)
)]
exp
(
)(
)
si
−
−
−
−
−
−




=
=
−
∑
i
s
r
l N
N
i
N
s
r
l N
N
s
N
r
π
π
α
/
0
1
1
×
n[ (
)]
sin[ ((
)
)] exp
(
)(
)
π
π
π
s
r
l N
N
s
r
l N
N
i
N
s
r
l N
N
s
−
−
−
−
−
−
−




/
1
=
−
=
−
∑
=
−
−
−
−
−




0
1
0
1
N
r
s
N
N
s
r
l N
i
N
s
r
l N
N
α
π
π
sincd[
; (
)]exp
(
)(
)
1
∑
.
Derivation of Equation 6.28
	
a
N
i
k
u
r
v
N
k
i
r
u v
x
i
f
i
i
r
N
d
=
−
+
(
)
+
(
)








=
−
∑
1
2
0
1
σ
α
π
σ
σ
, ;
( )
( )
exp
=
+
(
)
+
(
)











=
−
∑
1
1
2
0
1
σ
σ
π
σ
i
d
n
x
d
f
d
d
n
N
N
N
a
i
n
u
r
v
N
exp
( )
( )




−
+
(
)
+
(
)








=
=
−
∑
k
N
x
i
f
i
i
i
i
k
u
r
v
N
N
0
1
2
1
1
× exp
( )
( )
π
σ
σ
σd
n
d
d
d
n
N
i
N
a
i
n
r
N
i
k
exp
exp
( ) ( )
(
2
2
0
1
π σ
π













−
=
−
∑
) ( )
r
N
i
i
k
N
σ




=
−
∑
0
1
	
=
−












=
1
2
0
σ σ
π
σ
σ
i
d
n
d
d
d
i
i
i
r
N
a
i N
n
r
k
r
exp
( )
( )
( )
( )




N
n
N
i
d
n
d
d
d
d
f
d
N
a
i N
n
r
n
v
−
=
−
(
∑
∑






=
+
1
0
1
1
2
σ σ
π
σ
σ
exp
( )
( )


)
=
−
=
−
−


















∑


k
r
k
v
i
i
i
i
f
i
r
N
n
( )
( )
( )
σ
σ
0
1
0
N
i
d
n
d
d
f
d
i
i
f
i
N
a
i N
n
v
k
v
−
∑
=
−










1
1
2
σ σ
π
σ
σ
exp
( )
( )
( )
( )




−














=
−
=
−
∑
∑
n
N
d
d
i
i
r
N
i N
n
k
r
0
1
0
1
2

exp
( )
( )
π
σ
σ







340
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−












1
2
σ σ
π
σ
σ
i
d
n
d
d
f
d
i
i
f
i
N
a
i N
n
v
k
v
exp
exp
( )
( )
( )
( )


[
(
)]
exp
(
)
( )
( )
( )
( )
i
n
k
i N n
k
d
d
i
i
d
d
i
i
n
2
1
2
1
π
σ
σ
π
σ
σ




−
−
−



−
=
−
∑
=
−








0
1
1
2
N
i
d
n
d
d
f
d
i
i
f
i
N
a
i N
n
v
k
v
σ σ
π
σ
σ
exp
( )
( )
( )
( )






×
−
−
=
−
∑
n
N
d
d
i
i
d
d
i
i
n
k
n
k
0
1
sin[ (
)]
sin[ (
)
( )
( )
( )
( )
π
σ
σ
π
σ
σ




N
i
N
N
n
k
d
d
i
i
]
exp
.
( )
( )
π
σ
σ
−
−












1


With selection v
v
N
f
d
f
d
( )
( )
(
)
=
= −
−1 2
/
 obtain
a
N
a
i N
n
k
v
k
i
d
n
d
d
i
i
f
n
N
=
−












×
=
−
∑
1
2
0
1
σ σ
π
σ
σ
exp
s
( )
( )


in[ (
)]
sin[ (
)
]
exp
( )
( )
( )
( )
π
σ
σ
π
σ
σ
π





n
k
n
k
N
i
N
N
d
d
i
d
d
i
−
−
−
1
1
1
×
n
k
N
a
i N
n
k
d
d
i
i
i
d
n
d
d
i
( )
( )
( )
( )
exp
σ
σ
σ σ
π
σ
−












=
−



1
2
σ
π
σ
σ
π
i
f
d
d
i
i
v
N
n
k





−












−
1
2
sin[ (
)]
sin[
( )
( )


(
)
]
sin[ (
)]
( )
( )
( )
( )




n
k
N
a
n
k
d
d
i
i
n
N
i
d
n
d
d
i
i
σ
σ
σ σ
π
σ
σ
−
=
−
=
−
∑
0
1
1
N
n
k
N
a
N
n
d
d
i
i
n
N
i
d
n
d
d
sin[ (
)
]
sincd[
; (
( )
( )
( )
π
σ
σ
σ σ
π
σ



−
=
=
−
∑
0
1
1
−
=

−





=
−
∑
k
a
N
n
u
k
u
i
i
n
N
i
d
n
x
d
d
x
i
i
( )
( )
( )
)]
sincd
;
σ
σ σ
π
σ
σ
0
1
1







=
−
∑
n
N
0
1
.
Derivation of Equation 6.29
Let
	
α
π
r s
m n
n
N
m
N
N
a
i
mr
N
ns
N
,
, exp
=
+












=
−
=
−
∑
1
2
0
1
0
 

1
∑
,

341
Image Resampling and Building Continuous Image Models
where m
m
ux
=
+
, n
n
uy
=
+
, r
r
v f
=
+
, s
s
vp
=
+
, be SDFT of an image 
represented by its samples {am,n}. Apply to this spectrum-rotated DFT defined 
by Equation 4.91 and obtain
	

 

a
N
N
a
i
mr
N
ns
N
k l
m n
n
N
m
,
, exp
=
+












=
−
∑
1
1
2
0
1
σ
π
=
−
=
−
=
−
∑
∑
∑






×
+
−
0
1
0
1
0
1
2
N
s
N
r
N
i
k
l
N
r
k
exp
cos
sin
π
θ
θ
σ



sin
cos
exp
( cos
,
θ
θ
σ
σ
π
θ
−












=
×
+




l
N
s
N
a
i
m
k
m n
1
2
2
 
+








+
−
=
−
=
−
=
−
=
−
∑
∑
∑
∑



l
N
r
n
s
N
r
N
n
N
m
N
sin )
(
θ σ
0
1
0
1
0
1
0
1
k
l
N
s
i
mv
k
l
r
sin
cos )
exp
( cos
sin
( )
θ
θ σ
π
θ
θ
−








×
+
+




2
0
)
( sin
cos )
( )
( )
( )
v
N
nv
k
l
v
N
r
s
s
σ
σ
σ
θ
θ
σ
σ
+
+
−












=



0
1
N
a
m
k
l
m
k
l
m n
2
, sin{ [
( cos
sin )
]}
sin
( cos
sin )
π
θ
θ σ
π
θ
θ






+
+
+
+
σ
π
θ
θ σ
π
θ
N
n
l
k
n
l
k








+
−
+
−
sin{ [
( cos
sin )
]}
sin
( cos
s





 in )
exp
(
( )
θ σ
π
N
i
m v
N
n
N
m
N
r








×
+
−



+
=
−
=
−
∑
∑
0
1
0
1
0
2
1
2

k
l
v
N
N
i
n v
r
s
cos
sin )
exp
( )
(
θ
θ
σ
π
σ
+
+
−
















×


1
2
2
0
)
( )
( sin
cos )
+
−



+
−
+
−















N
k
l
v
N
N
s
1
2
1
2


θ
θ
σ
σ

.
Natural settings of shift parameters that cancel phase shift factors will be
	
v
v
v
v
N
r
r
s
s
0
0
1
2
( )
( )
( )
( )
.
=
=
=
= −
−
σ
σ

342
Theoretical Foundations of Digital Imaging Using MATLAB®
Then, obtain finally
	




a
a
N
m
k
l
k l
m n
n
N
,
, sincd
;
cos
sin
=
+
+












=
1
0
σ
π
θ
θ
σ
−
=
−
∑
∑
+
−












1
0
1
m
N
N
n
l
k
× sincd
;
cos
sin
.
π
θ
θ
σ



Exercises
sincd_interpol_demo_CRC.m
RotateComparis_demo_CRC.m
differentiator_comparison_CRC.m
diffrentiat_integrat_error_CRC.m
radon_invradon_demo_CRC.m
References
	
1.	 C. F. Gauss, Nachclass: Theoria interpolationis methodo nova tractata, Werke, 
Band 3, 265–327, Königlishe Gesellshaft der Wissenshaften, Göttingen, 1866 
(cited after M.T. Heideman, D.H. Johnson, and C.S. Burrus, Gauss and the his-
tory of the fast Fourier transform, IEEE ASSP Magazine, 1(4), 14–81, 1984).
	
2.	 W. H. Press, B. P. Flannery, S. A. Teukolsky, W. T. Vetterling. Numerical Recipes. 
The Art of Scientific Computing. Cambridge University Press, Cambridge, 1987.

343
7
Image Parameter Estimation: Case Study—
Localization of Objects in Images
The evaluation of numerical parameters of objects from image data is 
required in many applications. Typical examples are measuring the number 
of objects, object orientations, dimensions and coordinates, and object track-
ing in video sequences. As special cases of this problem, one can also regard 
object recognition, when it is required to determine object index in the list 
of possible objects, image segmentation, when one needs to determine pixel 
belonging to one of several classes, fitting parameterized 2D curves (so-
called “snakes” and “active contours” models) and 3D geometrical models.
As a rule, algorithms for parameter measurement are to be designed for the 
use for an arbitrary image from multitude of images generated by an imag-
ing system. Therefore, the most appropriate approach to solve this problem 
is a statistical optimization one.
In this chapter, we address the problem of estimation of image numerical 
parameter using as a typical task, the task of target localization, or measurement 
of coordinates of a target object in images. Being of great practical importance by 
itself, this task has a fundamental value for developing and understanding meth-
ods for solving other tasks of image parameter estimation and can be regarded 
as a guiding example both in terms of the design of parameter estimation algo-
rithms and in terms of evaluating their potential performance. We consider the 
task of target localization in two formulations: target localization on empty back-
ground in the presence of additive Gaussian noise (the section “Localization of 
Target Objects in the Presence of Additive Gaussian Noise”) and target localiza-
tion in cluttered images that contain many nontarget objects that camouflage the 
target one (the section “Target Localization in Cluttered Images”).
Localization of Target Objects in the Presence of Additive 
Gaussian Noise
Optimal Localization Device for Target Localization in Noncorrelated 
Gaussian Noise
Let the target object located at coordinates {x0, y0} of an image plane {x, y} be 
specified by its Nx × Ny samples {ak,l(x0, y0)}, k = 0,1,. . .,Nx − 1, l = 0,1,. . .,Ny − 1. 

344
Theoretical Foundations of Digital Imaging Using MATLAB®
Consider a discrete model, in which samples {bk,l} of an observed input image 
that contains a target object can be regarded as a sum of samples of the target 
object signal and samples {nk,l} of a random process that represents imaging 
system sensor noise:
	
b
a
x
y
n
k l
k l
k l
,
,
,
(
,
)
=
+
0
0
	
(7.1)
and assume that noise samples {nk} are statistically independent on the 
­signal {ak,l(x0,y0)}, are uncorrelated, and have a Gaussian probability distribu-
tion density with zero mean and variance σn
2. We discussed this classical 
ASIN-model in the sections “Models of Random Interferences” in Chapter 2. 
Although the model is quite simplistic, it is a good start model because, first, 
it enables solving the problem of statistically optimal localization analyti-
cally and, second, reveals some fundamental properties of statistically opti-
mal localization. Moreover, there are a number of practical tasks to which 
this model is well adequate, such as the tasks of localization of constella-
tions in stellar navigation and tracing target objects observed on a uniform 
background.
For the model of Equation 7.1, we obtained in the section “Basics of 
Optimal Statistical Parameter Estimation” in Chapter 2 (Equation 2.175) 
that the optimal MAP-estimates of object coordinates are solutions of 
equation
   
ˆ , ˆ
argmin
(
,
)
ln
(
,
)
,
,
x
y
b
a
x
y
x
y
k k
k l
l
N
n
y
0
0
0
0
2
0
1
2
0
0
2
{
}
=
−
−
=
−
∑
MAP
σ
P x
y
k
Nx
(
,
) ,
0
0
0
1
=
−
∑





	
(7.2)
where P(x0, y0) is a priori probability distribution function of the 
object ­coordinates. The term ∑
∑
=
−
=
−
k
Nx
l
N
k l
y
b
0
1
0
1
2
|
|
,
 of this equation does 
not depend on  the coordinates (x0, y0). We can assume that the term 
∑
∑
=
−
=
−
k
N
l
N
k
x
y
a x
y
0
1
0
1
0
0
2
| (
,
)|  does not depend on the coordinates (x0, y0) either, 
because it refers to the same object in different coordinates. Therefore, 
Equation 7.2 is reduced to
	
ˆ , ˆ
argmax
(
,
)
ln (
(
,
)
,
,
x
y
b a
x
y
P x
MAP
x
y
k l
k l
l
N
n
y
0
0
0
0
0
1
2
0
0
{
}
=
+
=
−
∑
σ
0
0
0
1
,
)
y
k
Nx
=
−
∑





	
(7.3)
Correspondingly, the ML-estimate of target coordinates can be obtained as
	
ˆ , ˆ
argmax
(
,
)
(
,
)
,
,
x
y
b a
x
y
ML
x
y
k l
k l
l
N
k
N
y
x
0
0
0
0
0
1
0
1
0
0
{
}
=


=
−
=
−
∑
∑




	
(7.4)

345
Image Parameter Estimation
Equation 7.4 implies that the device for obtaining optimal ML-estimates of 
the target object should contain two units: correlator unit, which computes 
mutual correlation function ∑
∑
=
−
=
−
k
N
l
N
k l
k l
x
y
b a
x
y
0
1
0
1
0
0
,
, (
,
)  of the observed signal 
{bk,l} and the target object signal {ak,l(x0, y0)}, or template, in all possible ranges 
of its coordinates, and a unit for locating the position of the highest signal 
peak at the correlator output (Figure 7.1).
Optimal MAP-estimator also consists of a correlator and a decision-­
making device locating the maximum in the correlation pattern. The only 
difference between ML- and MAP-estimators is that, in the MAP-estimator, 
the correlation pattern is biased by the appropriately normalized logarithm 
of the object coordinates’ a priori probability distribution.
As it was described in the section “2D Discrete Fourier Transforms” in 
Chapter 4, digital correlation can be in a computationally efficient way 
implemented in the DFT domain by means of multiplication of input signal 
DFT spectrum by the complex conjugate of the target object DFT spectrum. 
Such an implementation is called matched filtering. Correspondingly, the filter 
that implements this operation is called matched filter.
Performance of ML-Optimal Estimators: Normal and Anomalous 
Localization Errors
Due to the random noise present in the signal, any localization device will 
always estimate object coordinates with a certain error. The estimation accu-
racy can be generally characterized by the probability density p(εx, εy) of the 
estimation errors:
	
ε
ε
x
y
x
x
y
y
=
−
=
−
0
0
0
0
ˆ ,
ˆ . 	
(7.5)
For evaluation of p(εx, εy), one should analyze the distribution density of 
the coordinates of the highest peak of the output signal of the correlator 
within the area of all possible positions of the target object. This signal is a 
sum of the target object signal autocorrelation function and of a correlated 
Gaussian noise resulted from filtering the input white noise by the matched 
Device for
locating position
of the highest
signal peak
{ak,l}
{xˆ0, yˆ0}
{bk,l}
Correlator
FIGURE 7.1
Flow diagram of the ML-optimal localization device.

346
Theoretical Foundations of Digital Imaging Using MATLAB®
filter. This mixture is a nonstationary random process. This fact complicates 
the ­analysis very substantially. An approximate analytical solution of the 
problem can be obtained through the following reasoning.
Consider Figure 7.2. The two upper plots in Figure 7.2 represent a target sig-
nal with realizations of noise of two different levels, and the bottom plots show 
the corresponding correlator outputs. One can see that for the lower noise level 
(bottom left plot), the maximum of the correlator output signal is located in a 
close vicinity of the target location, while for the higher noise level, the maxi-
mum of the correlation is located far away from the target location.
Therefore, two essentially different types of possible localization errors 
have to be distinguished. One type of the errors occurs when noise intensity 
is relatively low with respect to that of the target object signal. In such cases, 
correlator output maxima are located in a close vicinity of the target location, 
and, therefore, localization errors are relatively small. The second type of the 
errors is represented by large errors, which occur when correlator output 
maxima are found very far away from the actual position of the target object. 
Small localization errors are caused by distortion of the target autocorrela-
tion peak shape by the noise. Large errors are a result of prominent large 
noise outbursts occurring outside the area occupied by the object. We call 
the first type of error normal errors because, as we shall see, their probability 
distribution density can be approximated by a Gaussian (normal) distribu-
tion. The errors of the second type called anomalous errors. One can say that 
normal errors characterize the accuracy of coordinate measurements and 
anomalous errors characterize the measurement reliability. The program 
localization_demo_CRC.m provided in Exercises illustrates the phenom-
enon of anomalous errors in localization of objects in images.
Test signal (bold) and test signal + noise
Target
Target
Correlator output
Correlator output
Target location
Target location
Target autocorrelation
Target autocorrelation
Correlation maximum
Correlation maximum
Test signal (bold) and test signal + noise
FIGURE 7.2
Normal (left column) and anomalous (right column) localization errors. Upper plots show the 
target signal with and without noise; bottom plots show the corresponding correlator outputs.

347
Image Parameter Estimation
Figure 7.3 shows an example of the empirical distribution density of 
errors of localization of an impulse in its mixture with uncorrelated addi-
tive Gaussian noise, obtained using the demo program loclzerr_CRC.m (see 
Exercises). As one can see, the localization error distribution density contains 
a peak around zero, which can be associated with normal errors, and almost 
uniform tales, which can be associated with anomalous errors. The uniform 
distribution density of anomalous errors has quite an obvious explanation. 
Outside the area occupied by the object, only the noise component is pres-
ent. Because noise is a spatially homogeneous random process, extremely 
arge noise outbursts, which cause anomalous localization errors, are equally 
probable everywhere in this area.
The detailed treatment of numerical characteristics of normal and anoma-
lous errors is brought out in Appendix. In “Distribution Density and Variances 
of Normal Localization Errors” in Appendix, it is shown that normal errors 
are zero mean random variables with Gaussian distribution density and vari-
ances defined, in the units of sampling intervals, by the relationships
1
0.5
0
–0.5
0.07
0.06
0.05
0.04
0.03
Localization error 
distribution density
0.02
0.01
0 –60
–40
–20
Localization error
0
20
40
60
–1
–60
–40
–20
0
NSR = 0.6
Signal (bold line) and realization of signal + noise; NSR = 0.6
(a)
(b)
20
40
60
FIGURE 7.3
​(a) A test target impulse (bold line) and a realization of uncorrelated Gaussian noise. 
(b) ­Empirical probability density of the localization error obtained through statistical simula-
tion of localization of this impulse in uncorrelated Gaussian noise.

348
Theoretical Foundations of Digital Imaging Using MATLAB®
	
ε
π
σ
ε
π
∆
∆
∆
∆
∆
∆
∆
∆
x
y
x
y
xy
n
a
y
x
x
f
f
f
f
E
f
f
2
2
2
2
2
2
2
2
2
2
2
2
1
4
1
4
=
(
)(
) −(
)
=
(
;
)(
) −(
)
=
−(
)
f
f
E
f
f
f
f
y
xy
n
a
xy
xy
x
y
xy
n
∆
∆
∆
∆
∆
∆
∆
2
2
2
2
2
2
2
2
2
2
2
2
1
4
σ
ε
π
σ
;
Ea
.
	
(7.6)
The parameters of these equations are defined through DFT spectrum {αr,s}:
	
α
π
r s
x
y
k l
x
y
l
N
k
N
N N
a
i
kr
N
ls
N
y
x
,
, exp
=
+












=
−
=
−
∑
1
2
0
1
0
1
∑
	
(7.7)
of the target object signal {ak,l} as follows:
	
E
a
f
N
r
a
k
r
s
N
r
N
l
N
k
N
x
x
r s
y
x
y
x
=
=
=
=
−
=
−
=
−
=
−
∑
∑
∑
∑
2
2
0
1
0
1
0
1
0
1
2
2
2
1
α
α
;
,
∆
2
2
2
2
2
2
2
2
1
1
s
r
r s
s
r
y
y
r s
r
s
r s
s
r
xy
x
y
f
N
s
f
N N
r
∑
∑
∑
∑
∑
∑
∑
∑
=
=
α
α
α
,
,
,
;
;
∆
∆
s
r s
s
r
r s
s
r
α
α
,
,
,
2
2
∑
∑
∑
∑
	
(7.8)
where summation is carried out over indices r,s of spatial frequencies 
from the lowest frequencies (r = 1, ε = 1) to the highest ones (Nx/2, Ny/2) 
or ((Nx − 1)/2, (Ny − 1)/2) depending on whether Nx and Ny are even or odd 
numbers.
On plots in Figure 7.4, one can compare these theoretical estimates of 
­normal noise standard deviation of localization errors with experimental 
data obtained using MATLAB program loclzerr_CRC.m (see Exercises) for 
the test signal shown in the upper plot of Figure 7.3. The plots clearly show 

349
Image Parameter Estimation
that for sufficiently low noise-to-signal ratios theoretical estimates fit experi-
mental data very well. However, with the growth of the noise-to-signal 
ratio, the error standard deviation starts growing faster and faster, which 
­evidences the appearance of anomalous errors.
As it was already mentioned, anomalous errors have uniform distribution 
density over the area of search. Therefore, their sufficient numerical statisti-
cal characteristics are their probability PAe, that is, the area of the uniform 
tails of the error probability density. In “Evaluation of the Probability of 
Anomalous Localization Errors” in Appendix, it is shown that the probabil-
ity of anomalous errors can be evaluated by the integral
	
P
n
E
n
a
n
Q
Ae =
−




−
+

















−∞
∞
−
∫
1
2
2
1
2
2
1
π
σ
exp
Φ


dn,
	
(7.9)
where Q is the number of positions the target object can occupy, without 
overlapping, in the area of search and
	
Φ( )
exp
x
n
n
x
=
−




−∞∫
1
2
2
2
π
d
	
(7.10)
is the “error integral.”
20
ErrorStDev
NormalErrStDev
18
16
14
12
Std_err/Δx
10
8
6
4
2
0
0
0.05
0.1
0.15
0.2
sqrt(σ2
n/Ea)
0.25
0.3
0.35
0.4
0.45
FIGURE 7.4
Theoretical (solid line) and experimental (dot line) curves of standard deviation of localization 
error as functions of noise-to-signal ratio.

350
Theoretical Foundations of Digital Imaging Using MATLAB®
In “Evaluation of the Probability of Anomalous Localization Errors” 
in Appendix, it is also shown that the probability of anomalous localiza-
tion errors PAe as a function of SNR Ea
n
σ2  for large Q features a threshold 
behavior:
	
lim
exp
Q→∞
−∞
∞
−
=
−




−
+













∫
P
n
E
n
a
n
Q
Ae
1
2
2
1
2
2
1
π
σ
Φ





=
>
≤



d
if
/
if
/
n
E
Q
E
Q
a
n
a
n
0
2
1
2
2
2
,
ln
,
ln
.
σ
σ
	
(7.11)
This feature implies that if the area of search is large enough with respect 
to the size of the object, the probability of anomalous errors may become 
enormously high when input SNR Ea
n
/σ2 is lower than the fundamental 
threshold defined by Equation 7.11. This also means that, when the area of 
search of a given target increases, the SNR must also be increased in order to 
keep the probability of anomalous errors low. Moreover, for any given inten-
sity of noise, there exists a trade-off between localization accuracy defined 
by the variance of normal errors and localization reliability described by the 
probability of anomalous errors. Increasing the accuracy achieved by means 
of increasing parameters f x
 2 , f y
 2 , f x y
   2
 in Equation 7.8 through widening the 
object signal spectrum results, with signal energy fixed, in increasing the 
probability of anomalous errors, because widening signal spectrum width is 
equivalent to narrowing the target object, and, consequently, to increasing of 
the ratio Q of the area of search to the object signal area.
Figure 7.5 shows results of numerical verification of the above relation-
ships by computer simulation of the optimal localization device. The data 
plotted in the figure were obtained by computer simulation of localization 
of uniformly painted square of 8×8 pixels in noisy images of different size 
(program localization_demo_CRC.m).
In conclusion, it should be noted that the relationships of Equation 7.6 for 
variances of normal errors and the threshold relationship of Equation 7.11 
for probability of anomalous errors have a very general fundamental value. 
Variances of normal errors determine, in a special case of a point source 
target object, the variance of error in measuring the coordinates of the point 
source. That has a direct relation to such an important characteristics of 
imaging system as their resolving power, that is, their capability to resolve 
two closely located point sources. In the case of point sources, target object 
signal is the system PSF and imaging system resolving power is convention-
ally evaluated using the Rayleigh’s criterion: two point sources are considered 
resolved if the minimum between two corresponding PSF peaks does not 
exceed 80% of the peak maxima. The above analysis of the accuracy of target 
localization reveals that the Rayleigh’s criterion does not take into account 

351
Image Parameter Estimation
imaging system noise, which is yet another factor that, along with the system 
PSF, determines system resolving power. It shows, in particular, that system 
resolving power might be arbitrarily high if noise level is sufficiently low 
and, vice versa, it can be very low if noise level is high even if system PSF is 
sharp enough to satisfy Rayleigh’s criterion.
As for the probability of anomalous errors, which characterizes localiza-
tion reliability, note that ln Q = ln 2 × log2 Q, and log2 Q can be regarded as 
the entropy, in bits, of the results of determining in which position of Q dif-
ferent object positions the target object is located, or, generally, which of Q 
possible values the parameter under measurement has. Therefore, Equation 
7.11 gives the absolute lower bound for the object signal energy per bit of 
measurement information required for reliable parameter estimation in the 
presence of white Gaussian noise with variance σn
2:
	
E
Q
a
n
/log
ln .
2
2
2
2
>
σ
	
(7.12)
Target Object Localization in the Presence of Nonwhite (Correlated) 
Additive Gaussian Noise
In this section, we extend the above results obtained for the additive uncor-
related noise model to the case of nonwhite, or correlated, noise. Let the noise 
1
0.9
0.8
0.7
0.6
PAe
0.5
0.4
0.3
0.2
0.1
00
0.5
1
1.5
2
2.5
3
3.5
4
4.5
Q = 64
Q = 254
Q =1024
Q = 4096
(2σ2
nIn(Q)/Ea)1/2
FIGURE 7.5
Experimental data for the probability of anomalous errors as a function of noise-to-signal ratio 
2
2
σn
a
Q E
ln
/
 for different values of Q. The theoretical threshold value 2
1
2
σn
a
Q E
ln
/
= .

352
Theoretical Foundations of Digital Imaging Using MATLAB®
DFT power spectrum be σn
r s
n
H
2
2
|
|
,
( ) , where |
|
,
( )
Hr s
n
2 is a normalized spectrum 
shaping function such that
	
Hr s
n
s
N
r
N
y
x
,
.
( )
=
−
=
−
∑
∑
=
2
0
1
0
1
1
	
(7.13)
Pass the observed signal plus noise mixture through a filter with frequency 
response
	
ηr s
r s
n
H
,
,
|
|
.
wht
(
)
( )
=
1
	
(7.14)
We will refer to this filter as to the whitening filter. At the output of the whit-
ening filter, noise power spectrum becomes uniform with spectral density 
σn
2, while the target object signal spectrum is modified to αr s
r s
n
H
,
,
( )
|
|
/
, that is, 
the above-discussed model of additive uncorrelated noise for the modified 
target signal is applicable to the signal at the output of the whitening filter. 
Therefore, one can conclude that for the case of additive correlated noise, 
an ML-optimal localization device should consist of the whitening filter 
followed by a filter matched to the modified target object signal and by a 
device for localizing the signal maximum. In this way, we arrive at the opti-
mal localization device shown in a flow diagram of Figure 7.6 that provides 
ML-estimation of the target object coordinates.
The whitening filters and the filter matched to the modified target object 
can be combined into one filter with discrete frequency response
	
η
α
r s
r s
r s
n
H
,
,
,
|
|
=
∗
( ) 2 .
	
(7.15)
Input
image
Whitening
filter
Whitening
filter
SNR-Optimal
filter
Correlator
(matched
filter)
Device for
localization of
signal maximum
Object
coordinates
Target object signal
FIGURE 7.6
Flow diagram of the ML-optimal localization device for the case of correlated Gaussian noise.

353
Image Parameter Estimation
The above reasoning also implies that, for a target signal observed in 
a ­mixture with additive correlated Gaussian noise, the filter defined by 
Equation 7.15 generates a signal that is monotonically related with a posteriori 
probability of target coordinates.
The filter defined by Equation 7.15 has yet another important feature. It 
provides the highest possible, for all linear filters, ratio of its response to 
the target object signal to standard deviation of noise at its output (SNR). In 
order to prove this, consider the response of an arbitrary filter with a dis-
crete frequency response ηr,s to the target signal ak,l located at coordinates 
(
;
)


x
x
x y
y
y
0
0
0
0
=
=
/
/
∆
∆
 and noise nk,l with spectral density σn
r s
n
H
2
2
|
|
,
( ) . The 
filter output to the target signal at the point (
,
)


x
y
0
0  is equal to
   
b
N
N
i
k
x
N
r
l
y
N
l
k l
x
y
r s
r s
x
y
,
,
,
,
exp
=
−
−
+
−









1
2
0
0
α
η
π






=
=
−
=
−
=
=
=
−
=
∑
∑
∑
s
N
r
N
k x
l
y
x
y
r s
r s
s
N
r
y
x
y
N
N
0
1
0
1
0
1
0
0
0
1




,
,
,
α
η
Nx −
∑
1
.
	
(7.16)
The standard deviation of noise at the filter output can be found as
	
σ
σ
η
n
n
r s
r s
n
s
N
r
N
H
y
x
=






( )
=
−
=
−
∑
∑
,
,
.
2
2
0
1
0
1
1 2
	
(7.17)
Their ratio, or the SNR, is then equal to
	
SNR
b
N
N
H
x
y
n
x
y
r s
r s
s
N
r
N
n
r s
r s
n
y
x
=
=
=
−
=
−
∑
∑



0
0
1
0
1
0
1
2
,
,
,
,
,
,
σ
α
η
σ
η
( )
=
−
=
−
∑
∑






2
0
1
0
1
1 2
s
N
r
N
y
x
.
	
(7.18)
By virtue of the Cauchy–Bunyakovsky–Schwarz inequality
	
a b
a
b
n n
n
n
n
n
n
∗
∑
∑
∑
≤












2
1 2
2
1 2
,
	
(7.19)

354
Theoretical Foundations of Digital Imaging Using MATLAB®
the following inequality holds for this ratio:
	
SNR
N
N
H
H
x
y
r s
r s
n
r s
r s
n
s
N
r
N
y
x
=





(
)
=
−
=
−
∑
∑
1
0
1
0
1
,
,
,
( )
,
,
( )
α
η
σ
η
σ
α
n
r s
r s
n
s
N
r
N
n
x
y
r s
r
H
N N
H
y
x
,
,
( )
,
,
2
2
0
1
0
1
1 2
2
1
=
−
=
−
∑
∑






≤
s
n
s
N
r
N
y
x
( )
,
=
−
=
−
∑
∑






0
1
0
1
1 2
	
(7.20)
which reaches its upper bound for ηr,s that satisfies Equation 7.15. We will 
refer to this filter as to the SNR-optimal filter.
	
η
α
η
r s
r s
r s
n
H
SNR
r s
,
(
)
,
,
( )
argmax(
).
,
opt =
=
∗
2
	
(7.21)
Localization Accuracy for the SNR-Optimal Filter
Because the SNR-optimal filter is the matched filter for the target object sig-
nal modified by the whitening operation, the potential localization accuracy 
of the optimal filter can be derived from Equations 7.6 and 7.8 for localization 
accuracy in the presence of white noise in which target object DFT spectrum 
{αr,s} is replaced by its whitened spectrum αr s
r s
n
H
,
,
( )
|
|
/
.
It is very instructive to compare the potential localization accuracy in the 
cases of white and nonwhite noise for the same input noise variance. For the 
sake of simplicity, we consider a 1D case. In this case, we have from Equation 
7.6 for nonwhite noise that
	
ε
π
σ
π
σ
∆
∆
∆
∆
x
x
n
a
x
n
a
x
a
f
E
f
E
f E
(
)
(
)
(
)
(
)
(
nwn
nwn
nwn
(
) =
=
2
2
2
2
2
2
2
2
1
4
1
4
f
E
G
x
a
x
∆
∆
(
)
(
)
)
,
nwn
nwn
2
2
= ε
	
(7.22)
where
	
E
H
f
N
r
H
H
a
r
r
r
N
x
x
r
r
n
r
r
x
(
)
( )
(
)
( )
;
nwn
nwn
=
(
) =
=
−
∑
∑
α
α
α
2
2
0
1
2
2
2
2
2
2
1
∆
r
n
r
( ) 2
∑
	
(7.23)

355
Image Parameter Estimation
and
	
G
f E
f
E
r
r
H
x
x
x
a
x
a
nwn
r
r
r
r
n
= (
)
(
)
= ∑
ε
ε
α
α
∆
∆
∆
∆
(
)
(
)
(
)
(
nwn
nwn
2
2
2
2
2
2
2
2
) 2
r∑
	
(7.24)
is the ratio of localization error variances for nonwhite and white noise of 
the same intensity. As, by the definition (Equation 7.13), ∑
=
=
−
r
N
r
n
x
H
0
1
2
1
|
|
( )
, all 
|
|
( )
Hr
n
2 do not exceed one. This implies that r
H
r
r
r
n
r
2
2
2
2
2
| | |
|
| |
( )
α
α
/
≥
 and, there-
fore G ≤ 1, which means that the potential localization accuracy in the pres-
ence of nonwhite noise is always better than that for white noise with the 
same variance.
This conclusion is well intuitively understood. Consider, for instance, a 
trivial special case, when noise is band-limited and its bandwidth is less than 
that of the signal. SNR-optimal filter is in this case a band pass filter, which 
lets through all input signal frequencies, where noise spectrum vanishes to 
zero and blocks all other frequencies, where noise spectrum is nonzero. The 
resulting signal is therefore noise-free and the potential localization error 
variance is equal to zero.
Optimal Localization in Color and Multicomponent Images
The above-presented results for optimal localization in monochrome images 
can be straightforwardly extended to localization in color, or, generally, 
­multicomponent images, observed, in each component, in the presence of 
additive Gaussian noise.
Let {
(
,
)}
,
(
)
a
x
y
k l
m
0
0 , k = 0,1,...,Nx − 1, l = 0,1,...,Ny − 1 be the m-th component of 
the target object image m = 1,2,...,M (for color images M = 3) located in coor-
dinates (x0, y0) with coordinate probability density P(x0, y0). Also let {
}
,
(
)
bk l
m  and 
{
}
,
(
)
nk l
m  be samples of the corresponding components of the observed image, in 
which the target is to be localized, and of the additive Gaussian noise such that
	
b
a
x
y
n
k l
m
k l
m
k l
m
,
(
)
,
(
)
,
(
)
(
,
)
.
=
+
0
0
	
(7.25)
In the assumption that components of the additive noise as well as samples 
of noise within each component are all mutually uncorrelated, obtain that a 
posteriori probability of observing signal {
}
,
(
)
bk l
m  provided the target object is 
located at coordinates (x0, y0) is
P n
b
a
x
y
b
a
k l
m
k l
m
k l
m
m
k l
m
k l
,
(
)
,
(
)
,
(
)
(
)
,
(
)
,
(
,
)
exp
=
−
{
} ∝
−
−
0
0
2
1
2σn
(
)(
,
)
,
m
k
N
m
M
x
y
0
0
2
0
1
1




=
−
= ∏
∏
	
(7.26)

356
Theoretical Foundations of Digital Imaging Using MATLAB®
where σn
(
)
m 2 denotes the variance of the m-th noise component. Therefore, 
optimal MAP- and ML-localization devices are defined, respectively, by 
equations
ˆ , ˆ
argmax
(
,
)
(
,
)
(
)
,
(
)
,
(
)
x
y
b
a
x
y
x
y
m
k l
m
k l
m
l
Ny
0
0
2
0
0
0
1
0
0
1
{
} =
=
−
σn
∑
∑
∑
∑
=
−
=
=








−






k
N
m
M
m
M
x
P x
y
0
1
0
0
1
1
ln (
,
)
	
(7.27)
and
	
ˆ , ˆ
argmax
(ˆ , ˆ )
(
,
)
(
)
,
(
)
,
(
)
x
y
b
a
x
y
x
y
m
k l
m
k l
m
l
Ny
0
0
2
0
0
0
0
0
1
{
} =
=
σn
−
=
−
=
∑
∑
∑






1
0
1
1
k
N
m
M
x
,
	
(7.28)
which implies that multicomponent optimal localization device should con-
sist of M parallel component-wise correlators, or matched filters, of an adder 
for weighted summation of correlators’ outputs and of a unit for determin-
ing coordinates of the signal maximum at the adder’s output. Its schematic 
diagram is shown in Figure 7.7.
Variances of normal localization errors, which characterize the accuracy 
of optimal localization, and probability of anomalous errors in multicom-
ponent images can be found with just the same technique as it was done for 
single-component images. For details, readers may refer to Ref. [1].
As in the case of single-component images, for localization in multicompo-
nent images with correlated noise components, input image and target object 
image prewhitening can be used in order to reduce the problem to the case of 
Matched filter
(1st component)
Matched filter
(2nd component)
Input
image
components
Matched filter
(3rd component)
Adder
Device for
localization of
signal
maximum
Object’s coordinates
Matched filter
(mth component)
σn
(2)2
σn
(3)2
σn
(m)2
σn
(1)2
1
1
1
1
FIGURE 7.7
Schematic flow diagram of the optimal device for localization of a target object in multicom-
ponent images.

357
Image Parameter Estimation
uncorrelated noise. The optimal localization device of Figure 7.7 should then 
be modified as it is shown in Figure 7.8.
SNR-optimal filters in this device are filters with discrete frequency 
responses {
}
,
(
,
)
ηr s
m opt  defined by the equation
	
η
α
r s
m
r s
m
r s
m
H
,
(
,
)
,
(
)
,
(
)
,
opt =
∗
2
	
(7.29)
in which αr s
m
,
(
)∗ is a complex conjugate DFT spectrum of the target object m-th 
component image and |
|
,
(
)
Hr s
m
2 is the DFT spectral density of the m-th noise 
component normalized according to Equation 7.13.
Object Localization in the Presence of Multiple Nonoverlapping 
Nontarget Objects
In this section, we discuss an extended image model, in which observed 
image signal contains, along with the target object signal and additive non-
correlated Gaussian sensor noise, some number Q of nontarget objects that 
do not overlap one another and the target object. A good example of the situ-
ation, in which such a model is appropriate, would be the task of locating a 
specific character in a printed text.
Inasmuch as nontarget objects do not overlap the target object, the only 
obstacle for locating target object in the close vicinity of its actual location is 
additive sensor noise. Therefore, the design of the filter for the highest local-
ization accuracy, that is, the lowest variance of normal errors, is governed 
by the same reasoning as that for the above-described additive noise model 
SNR-optimal filter
(1st component)
SNR-optimal filter
(2nd component)
SNR-optimal filter
(3rd component)
SNR-optimal filter
(mth component)
Adder
Device for
localization of
signal
maximum
Object’s coordinates
Input
image
components
σn
(2)2
σn
(3)2
σn
(m)2
σn
(1)2
1
1
1
1
FIGURE 7.8
​Schematic flow diagram of ML-optimal device for localization of target objects in multicompo-
nent images with correlated component noise.

358
Theoretical Foundations of Digital Imaging Using MATLAB®
with no nontarget objects. The optimal filter in this case will also be the 
matched filter and the variance of normal errors will be defined by the same 
formulas as those in the cases of the absence of nontarget objects (Equation 
7.6). The presence of nontarget objects affects only the probability of anoma-
lous errors.
In order to estimate the probability of anomalous errors of target local-
ization in the presence of multiple nontarget objects, consider first a simple 
special case, when the area of search contains certain number Q of identical 
nontarget objects. Let the maximal value of their cross-correlation function 
with the target object be Ra,q. Then, by analogy with Equation 7.9, the prob-
ability of anomalous localization errors (probability of false detection) for the 
matched filter localization device can be evaluated as follows:
	
P
n
E
R
E
n
a
a q
a
n
Q
Ae =
−




−
−
+
















−∞
∞
∫
1
2
2
1
2
2
π
σ
exp
,
Φ





dn.
	
(7.30)
As one can see, the presence of nontarget objects very substantially 
increases the probability of anomalous errors compared to that for the case 
of target localization on empty background, because Ea − Ra,q < Ea and this 
difference can even be negative, if cross-correlation of target object with non-
target object is higher than target object autocorrelation.
In a more general case, when in the area of search there might be some 
random number Q of nontarget objects, which belong to one of C classes 
according to the maximal values Ra q
c
,
( )  of their cross-correlation function with 
the target object, it is shown in Ref. [1] that the probability of anomalous 
localization (false detection) errors can be found as
P
P Q
n
P c
E
R
E
n
a
a
a q
c
a
n
c
C
=
−




−
−
+






=∑
( )
exp
( )
,
( )
1
2
2
1
2
2
1
π
σ
Φ




















−∞
∞
∫
∑
Q
Q
n
d
,
	
(7.31)
where P(Q) is the probability of total number Q of nontarget objects and P(c) 
is the probability of nontarget objects of c-th class (c = 1,2,. . .,C).
Figure 7.9 illustrates the phenomenon of false identification of a target 
object with nontarget objects on an example of character recognition. It can 
also be observed using MATLAB program localization_demo_CRC.m pro-
vided in Exercises.
In order to decrease the probability of anomalous errors in the presence 
of nontarget objects, it is necessary to suppress cross-correlation peaks 
for nontarget objects with respect to the autocorrelation peak of the tar-
get object. This requires an appropriate modification of the matched filter. 
Therefore, for localization of a target in the presence of nontarget objects, 

359
Image Parameter Estimation
it is not possible to simultaneously secure the minimum of normal error 
variance and the minimum of the probability of anomalous errors with the 
same estimator, and optimal localization must be carried out in two steps. 
The first step is target detection with minimal probability of anomalous 
errors. A coarse but reliable estimate of the object coordinates is obtained at 
this stage. For the accurate estimation of target coordinates, the second step 
is needed, in which localization with minimal variance of normal errors is 
obtained in a reduced area of search in the vicinity of the location found 
at the first step. The optimal localization device for the second step is the 
matched filter. The problem of the design of optimal device for reliable 
detection of targets on the background of a clutter of nontarget objects is 
addressed in the next section.
Target Localization in Cluttered Images
Formulation of the Approach
Consider now the most general problem of locating targets in images that 
contain a target object and a clutter of nontarget objects that obscure the tar-
get object. There are many image processing tasks, in which the localization 
of a target object in a clutter of nontarget objects is required. Here are some 
of them, to name a few:
• Navigation using terrain maps
• Detection, localization and tracking of various formations in medical
• Detection and localization of defects in nondestructive testing 
images
FIGURE 7.9
​Detection, using matched filtering, of a character “o” in a printer text. Left image: noisy image 
of a printed text with standard deviation of additive noise 15 (within signal range 0–255). Right 
image: results of detection of character “o”; one can see quite a number of false detections.

360
Theoretical Foundations of Digital Imaging Using MATLAB®
• Detection and localization of specific patterns in fingerprints
• Detection and localization of specific objects in surveillance images, 
for instance, face detection
As it follows from the discussion in the section “Localization of Target 
Objects in the Presence of Additive Gaussian Noise,” those background non-
target objects represent the main obstacle for reliable localization of target 
objects. Our purpose therefore is to find out how can one minimize the dan-
ger of false identification of the target object with one of many nontarget 
objects.
In practical tasks of target localization, it is required, as a rule, to secure the 
most reliable target localization in a particular observed image rather than 
on average over a hypothetic ensemble of images, which rarely can be speci-
fied. Therefore, optimization and adaptation of the localization algorithm for 
individual images are desired.
This requirement of adaptivity will be imperative in our approach. The 
second imperative requirement will be that of low computational complexity 
of localization algorithms. Bearing this in mind, we shall restrict the discus-
sion with the same type of localization devices as those described in the 
section “Localization of Target Objects in the Presence of Additive Gaussian 
Noise,” that is, the devices that consist of a linear filter followed by a unit for 
locating signal maximum at the filter output (Figure 7.10).
Owing to the existence of fast and recursive algorithms of digital linear 
filtering, such devices have low computational complexity in their computer 
implementation. They also have promising optical and electro-optical imple-
mentations [2]. In such type of devices, it is the linear filter that has to be 
optimized and is the subject for adaptation.
SCR-Optimal Adaptive Correlator
Consider first the task, illustrated in Figure 7.11, of locating a precisely 
defined target object on a given image.
Let {bk,l}, k = 0,. . .,Nx − 1; l = 0,1,. . .,Ny − 1, be samples of an input image that 
contains, in coordinates (x0, y0), a target image defined by its samples {ak,l(x0, 
y0)}. The position of the target object has to be found as a position of the 
highest signal peak at the output of the linear filter of the localization device 
defined in Figure 7.10. Also let {ηr,s} be the discrete frequency response of the 
Object’s
coordinates
Device for
locating
signal maximum
Linear filter
Input
image
bk,l
bk,l
FIGURE 7.10
Schematic diagram of the localization device.

361
Image Parameter Estimation
linear filter, and {αr,s} and {βr,s} be the DFT spectral coefficients of the target 
object and of the input image, respectively (r = 0,. . .,Nx − 1; s = 0,1,. . .,Ny − 1).
Then filter output at the location of the target object is
	
a
N N
i
x r
N
y s
N
i
kr
N
x
y
x
y
r s
x
y
0
0
1
2
2
0
0
,
, exp
exp
=
+












−
α
π
π
x
y
s
N
r
N
k x
l y
x
y
r s
r
ls
N
N N
y
x
+












=
=
−
=
−
=
=
∑
∑
0
1
0
1
0
0
1
α
η
,
,s
s
N
r
N
y
x
=
−
=
−
∑
∑
0
1
0
1
,
	
(7.32)
and filter response to the entire input image is
	
b
N N
i
kr
N
ls
N
k l
x
y
r s
r s
x
y
s
N
r
y
,
,
, exp
=
−
+












=
−
∑
1
2
0
1
β
η
π
=
−
∑
0
1
Nx
.
	
(7.33)
The rate of target object false detections is determined by the number of 
possible target positions within filter output image bk l, , in which 

b
a
k l
x
y
,
, .
≥
0
0  
One can try to minimize this number by an appropriate selection of the filter 
frequency response {ηr,s}. No analytical solution of this minimization prob-
lem is feasible, because there is no analytical relationship between the fre-
quency response of the filter and the probability density of its output signal. 
The only statistical parameters of the filter output signal that can be deter-
mined given the filter frequency response are signal mean value
	
b
N N
k l
x
y
s
N
r
N
y
x
,
,
,
=
=
−
=
−
∑
∑
1
0 0
0 0
0
1
0
1
β
η
	
(7.34)
FIGURE 7.11
Input image (left) and target object (right image, highlighted).

362
Theoretical Foundations of Digital Imaging Using MATLAB®
and variance
	
b
N N
x
y
r s
r s
s
N
r
N
y
x
2
2
2
0
1
0
1
1
=
=
−
=
−
∑
∑
β
η
,
,
.
	
(7.35)
The latter follows from Parseval’s relationship. Therefore, for optimization of 
the localization device filter, we will rely upon the Tchebyshev’s inequality, which 
establishes a relationship between probability that a random variable x exceeds 
some threshold xthr and the variable’s mean value x and standard deviation σ.
	
Probability
/
thr
thr
2
x
x
x
x
−
≥
(
) ≤
σ2. 	
(7.36)
Filter output signal mean value does not affect localization of the output 
sig­nal global maximum. Therefore, in order to simplify further analysis, we 
will assume it set to be zero by selecting η0,0 = 0. Then, using the Tchebyshev’s 
inequality (Equation 7.36), we obtain for the probability of false identifica-
tion of the target object located in coordinates (x0, y0) with one of nontarget 
(background) objects:
 
P
x
y
b
b
a
k l
x
y
x
y
x
y
Ae
bg
bg
Probability
(
,
)
,
(
,
,
)
,
,
,
0
0
0
0
0
0
0
0
=
−
≥


(
)


≤


b
a
x
y
x
y
(
,
,
)
,
,
bg
0
0 2
0
0
2
	
(7.37)
where {
}
,
(
,
,
)
bk l
x
y
bg
0
0  are filter output values at points outside the target location, 
bx
y
x
y
0
0
0
0
2
,
(
,
,
)
bg
 is their variance, and ax
y
0
0
,  is the filter output value, defined by Equation 
7.32, at the target location. The optimal design of the filter requires minimization 
of PAe(x0, y0) on average over all ranges of possible target object coordinates:
	
η
η
r s
x
y
r s
AV
P
x
y
,
(
)
,
argmin
(
,
) .
,
opt =


0
0
0
0
Ae
	
(7.38)
According to Equation 7.37, this is equivalent to
	
η
η
r s
x
y
bg x
y
x
y
r s
AV
b
a
,
(
)
,
(
,
,
)
,
argmin
a
,
opt =







=
0
0
0
0 2
0
0
2


rgmax
.
,
,
,
(
,
,
)
ηr s
a
AV
b
x
y
x
y
x
y


0
0
0
0
0
0 2
2
bg



	
(7.39)
assuming that the filter response to the target object in its location does not 
depend on the location. We call the ratio
	
SCR
a
AV
b
x
y
x
y
x
y
=






0
0
0
0
0
0 2
2
,
,
(
,
,
)
bg
	
(7.40)
signal-to-clutter ratio (SCR).

363
Image Parameter Estimation
Equation 7.39 implies that, for minimizing PAe, one should maximize SCR. 
If the DFT power spectrum |
|
,
(
,
,
)
βr s
x
y
bg
0
0
2 of the input image background com-
ponent is known, b
x
y
(
,
,
)
bg
0
0 2 can be found using Parseval’s relationship:
	
b
N N
x
y
x
y
r s
x
y
r s
s
N
r
N
y
x
(
,
,
)
,
(
,
,
)
,
bg
bg
0
0
0
0
2
2
2
0
1
0
1
1
=
=
−
=
−
∑
∑
β
η
	
(7.41)
and therefore
	
AV
b
N N
AV
x
y
x
y
x
y
x
y
r s
x
y
r s
s
0
0
0
0
0
0
0
0
2
2
2
1
,
(
,
,
)
,
,
(
,
,
)
,
 bg
(
) =
(
)
β
η
bg
=
−
=
−
∑
∑
0
1
0
1 N
r
N
y
x
.
	
(7.42)
Substitute this equation and Equation 7.32 in Equation 7.40 and obtain:
	
SCR
AV
r s
r s
s
N
r
N
x
y
r s
x
y
y
x
=






=
−
=
−
∑
∑
α
η
β
,
,
,
,
(
,
,
)
0
1
0
1
2
0
0
0
0
bg
2
2
0
1
0
1
(
)
=
−
=
−
∑
∑
ηr s
s
N
r
N
y
x
,
.
	
(7.43)
By virtue of Cauchy–Bunyakovsky–Schwarz inequality (Equation 7.19), the 
SCR defined by this equation has an upper bound:
SCR
AV
r s
r s
s
N
r
N
x
y
r s
x
y
y
x
=






=
−
=
−
∑
∑
α
η
β
,
,
,
,
(
,
,
)
0
1
0
1
2
0
0
0
0
bg
2
2
0
1
0
1
0
1
(
)
=



(
)
=
−
=
−
=
−
=
∑
∑
∑
η
α
β
η
β
r s
s
N
r
N
r s
r s
s
N
r
y
x
y
AV
AV
,
,
,
0
1
2
2
2
0
1
0
1
2
2
0
1
N
r s
s
N
r
N
r s
s
N
x
y
x
y
AV
AV
−
=
−
=
−
=
−
∑
∑
∑






≤
β
η
α
β
,
,
∑
∑
∑
∑
∑
=
−
=
−
=
−
=
−
=
−
r
N
r s
s
N
r
N
r s
s
N
r
N
x
y
x
y
x
AV
AV
0
1
2
2
0
1
0
1
2
2
0
1
0
η
β
β
η
,
,
1
2
2
0
1
0
1
2
2
0
0
0
0
∑
∑
∑
=
=
(
=
−
=
−
α
β
α
β
r s
s
N
r
N
r s
x
y
r s
x
y
AV
AV
y
x
,
,
,
,
(
,
,
)
bg
)
=
−
=
−
∑
∑
s
N
r
N
y
x
0
1
0
1
	
(7.44)

364
Theoretical Foundations of Digital Imaging Using MATLAB®
that is reached when
	
η
η
α
β
η
r s
r s
r s
x
y
r s
x
y
r s
SCR
AV
,
,
(
)
,
,
,
(
,
,
)
argmax(
)
,
=
=
=
∗
opt
bg
0
0
0
0
2
(
)
,
	
(7.45)
where * denotes complex conjugation.
One can see that the filter defined by Equation 7.45 is analogous to the 
SNR-optimal filter (Equation 7.21) introduced in the section “Localization 
of Target Objects in the Presence of Additive Gaussian Noise” for object 
localization in the presence of correlated Gaussian noise. The numerator 
of its frequency response is the frequency response of the filter matched 
to the target object, just as in the SNR-optimal filter for target locating on 
the background of additive white Gaussian noise. The denominator of its 
frequency response is image background component power spectrum 
AVx
y
r s
x
y
0
0
0
0
2
,
,
(
,
,
)
(|
| )
β bg
 averaged over all possible positions of the target object. 
It replaces the additive Gaussian noise power spectrum in the filter of 
Equation 7.21. This makes optimal filter defined by Equation 7.45 to be adap-
tive to the input image. We will call this filter SCR-optimal adaptive correlator.
In order to implement the SCR-optimal adaptive correlator, one needs 
knowledge of the averaged power spectrum AVx
y
r s
x
y
0
0
0
0
2
,
,
(
,
,
)
(|
| )
β bg
 of the back-
ground component of the image. It has to be estimated from the power spec-
trum of the input image. For this, one has to specify in which way target and 
background components are combined in the input image.
Consider the following two models for this relationship: additive model 
and implant model. For the additive model, target image and background 
components are summed up to form the input image:
	
b
a
x
y
b
k l
k l
k l
x
y
,
,
,
(
,
,
)
(
,
)
.
=
+
0
0
0
0
bg
	
(7.46)
The additive model seems to be adequate to the cases of “transmissive” 
imaging, such as x-ray imaging.
For the implant model, target object and background image component 
complement each other and the latter is a part of the input image
	
b
w
b
k l
x
y
k l
x
y
k l
,
(
,
,
)
,
(
,
,
)
,
bg
tg
0
0
0
0
1
=
−
(
)
	
(7.47)
selected by a certain target window function 0
1
0
0
≤
≤
wk l
x
y
,
(
,
,
)
tg
, which is non-
zero  in points that belong to the target object and to zero in nontarget object 
points. The implant model is more adequate to “reflective” imaging, such as, 
for instance, conventional photography.
For the additive model, the spectrum of the background image component 
can be found as

365
Image Parameter Estimation
	
β
β
α
π
r s
x
y
r s
r s
x
y
i
rx
N
sy
N
,
(
,
,
)
,
, exp
.
bg
0
0
2
0
0
=
−
+











	
(7.48)
It is shown in Appendix (Equation 7A.47) that in this case its averaged 
power spectrum can be evaluated as
	
AVx
y
r s
x
y
r s
r s
0
0
0
0
2
2
2
,
,
(
,
,
)
,
,
.
β
β
α
bg
(
) =
+
	
(7.49)
For the implant model (Equation 7.47), it is shown in Appendix that
	
AV
N N
x
y
r s
x
y
r s
x
y
r s
0
0
0
0
2
0 0
2
1
2
,
,
(
,
,
)
,
(
, , )
,
Re
β
ω
β
bg
tgt
(
) =
−




+
=
−
=
−
−
−
∑∑
1
0
1
0
1
2
0 0 2
Nx
r
N
s
N
r s
r r s s
x
y


 


β
ω
,
,
(
, , ) ,
tgt
	
(7.50)
where {
}
,
,0,0
ωr s
(
)
tgt
 are DFT spectral coefficients of the target object window 
function wk l,
, ,
tgt 0 0 for target located in the origin of coordinates:
	
ω
π
r s
x
y
k l
s
N
x
y
N N
w
i
kr
N
ls
N
y
,
(
, , )
,
(
, , ) exp
tgt
tgt
0 0
0 0
0
1
1
2
=
−
∑
+










=
−
∑
.
k
Nx
0
1
	
(7.51)
In a special case when the target window function is a rectangle of (2K + 1)
(2L + 1) pixels averaged over unknown target object coordinates, the power 
spectrum of the background image component can be, for the implant model, 
evaluated as (see Appendix, Equation 7A.60)
AVx
y
r s
x
y
0
0
0
0
2
,
,
,
,
β
bg
1
2 (2
+ 1)(
+ 1) sincd(
+ 1
(
)




=
−
K
L
N N
2K
x
y
2
; 
) sincd(2 + 1; 
; )
N
r
L
N
s
K
x
y
r,s
; 
2




+
+




+
β
2
1
2
1
2
N
L
N
x
y
r
N
x
s
N
x
y
r s
K
N
r
r




+
−
×
=
−
=
−
∑∑
2
0
1
2
2
0
1
2
1


 

β ,
(
;
;
)
sincd
sincd(
;
;
) .
2
1
2
L
s
s
y
+
−
N

	 (7.52)

366
Theoretical Foundations of Digital Imaging Using MATLAB®
As target objects usually occupy only a relatively small part of the input 
image area (the largest relative area of the target is about 1/9 for the case, 
when there are 3×3 possible positions of the target), the contribution of the 
target object into power spectrum of the input image is relatively small. In 
view of this, both additive and implant models imply that one can use, as 
a zero-order approximation to the averaged power spectrum of the image 
background component, either power spectrum of the input image:
	
AVx
y
r s
x
y
r s
0
0
0
0
2
2
,
,
(
,
,
)
,
|
|
|
|
β
β
bg
(
) ≈
	
(7.53)
or input image power spectrum |
|
,
βr s
2 smoothed by a certain smoothing 
­window function ωr s,
smth:
     
AVx
y
r s
x
y
r s
s
N
r
N
r r
y
x
0
0
0
0
2
0
1
0
1
,
,
(
,
,
)
,
β
ω
β
bg
smth
(
) ≈
=
−
=
−
−
∑
∑
 


,
,
;
.
s s
r s
s
N
r
N
y
x
−
=
−
=
−
∑
∑
=

 


2
0
1
0
1
1
ωsmth
	
(7.54)
This smoothing corresponds to windowing input image by an “apodiza-
tion” function, which is equal to unity in the center of the image and gradu-
ally decays to zero to the image borders. Such a windowing, known in optics 
as apodization, is a useful method for reducing border effects in evaluating 
image DFT spectra, caused by cyclicity of DFT (see the section “2D Discrete 
Fourier Transforms” in Chapter 4).
In the conclusion of this section, we will illustrate, using MATLAB pro-
gram corr_comparison_CRC.m provided in Exercises, advantages, in terms 
of the localization reliability, of the described SCR-optimal adaptive correla-
tor over the matched filter correlator, which is optimal for target location in 
Gaussian noise in the absence of nontarget objects and clutter.
Figure 7.12 enables comparison of the performance of the matched filter 
and SCR-optimal adaptive correlators in the localization of correspond-
ing image fragments in stereoscopic images. This comparison shows that 
the matched filter correlator is practically incapable of reliable localization 
of small image fragments of one of the stereoscopic images in the second 
image, while the SCR-optimal adaptive correlator successfully does the job. 
It suppresses the background image component substantially and therefore 
secures much better discrimination capability of the localization device.
Local Adaptive SCR-Optimal Correlators
The described SCR-optimal adaptive correlator minimizes the probability of 
anomalous errors of target localization in images by means of adaptation of 
its filter frequency response to the power spectrum of the background image 
component. This approach is justified if images are spatially homogeneous in 
terms of their spectra, that is, power spectra of arbitrary image fragments do 
not differ much from the power spectrum of the entire image. While this is 

367
Image Parameter Estimation
Correlator outputs (Y-cross-sect. through
position of maximum); SCR_oac = 6.3 
1
0.8
0.6
0.4
0.2
0
–0.2
–0.4
–0.6
–0.8
50
100
Y
150
200
250
Input image and target image (highlighted)
OAC
MF
MF (left) and OAC (right) localization results
MF (left) and OAC (right) outputs
(a)
(b)
(c)
(d)
FIGURE 7.12
Comparison of discrimination capability of matched filter and SCR-optimal adaptive corre-
lators in localization of a fragment of one of two stereoscopic images on the second image. 
(a) Left and right stereoscopic images; target fragment is highlighted by a target window func-
tion (circle of 31 pixels in diameter). (b) Results (marked by a cross) of localization of the ­target 
fragment by the matched filter correlator (left image: false detection) and by SCR-optimal 
adaptive correlator (right image: correct detection). (c) Output images of the matched filter 
(left) and of the SCR-optimal adaptive correlator (right): note a bright spot in the location of 
the target fragment. (d) Rows of outputs of the matched filter (dash-dotted line) and of SCR-
optimal adaptive correlator drawn through the corresponding highest peak; note a target peak 
at location of the target fragment, which is substantially higher than responses of the filter to 
the background clutter (signal-to-clutter ratio is 6.32).

368
Theoretical Foundations of Digital Imaging Using MATLAB®
true for many images, which belong to the class of so-called texture images, 
such as those shown in Figure 7.13a–c, this spectral ­homogeneity is an exemp-
tion rather than a rule. Generally, images are nonhomogeneous and their local 
power spectra may vary substantially (see, e.g., image in Figure 7.13d).
A natural extension of the above-developed SCR-optimal adaptive correla-
tors to nonhomogeneous images is designing and applying the correlator 
filter locally in sliding window of the size commensurable with size of image 
fragments that can be regarded as being homogeneous in terms of their power 
spectra. In such an implementation, in each position {k,l} (k = 1,...,Nx; l = 1,...,Ny) 
of the window SCR-adaptive filter is applied to the image within the window 
and SCR is computed as ratio of the squared filter output signal ˆ
,
bk lto the vari-
ance ˆ
,
bk l
2  of the filter output signal within the window (local variance):
	
SCR
b
b
k l
k l
k l
,
,
,
.
=
2
2

	
(7.55)
Estimate of the target coordinates is then found as a position of the global 
maximum over the SCRk,l map. We will refer to sliding window SCR-optimal 
adaptive correlators with frequency response
FIGURE 7.13
Examples of texture (a,b,c) and nontexture (d) images.

369
Image Parameter Estimation
	
η
α
β
r s
k l
r s
r s
k l
,
( , ,
)
,
,
(
, , )
..........................
opt
bg
=
∗
2
.. ,
	
(7.56)
where |
|
,
(
, , )
........................
βr s
k l
bg
2 is an estimate (obtained as it is described in the previous sec-
tion) of the image background component within the window in its (k,l)-th 
position, as to SCR-optimal local adaptive correlators.
SCR-optimal local adaptive correlators do substantially outperform 
global optimal adaptive correlators in terms of SCR they provide in real-life 
images. Figure 7.14 generated using MATLAB program lcoptcorr_CRC.m 
provided in Exercises illustrates comparison of the SCR-optimal global and 
Local SCR-opt. adapt. correlator: localization result (marked by cross); SCR = 7.3
Global SCR-opt. adapt. correlator: localization result (marked by cross)
Global (left) and local (right; WSz = 29×29; Rtrgt = 7) correlations
False detection
Correct detection
(a)
(b)
(c)
FIGURE 7.14
Comparison of SCR-optimal local and global adaptive correlators. (a) Result (marked by cross) 
of correct localization by the local adaptive correlator in sliding window of 29×29 pixels, on left 
image of a fragment of right image (highlighted; diameter of the target object circular window 
function 15 pixels). (b) Images: result of false detection (marked by a bold cross on the left 
image) of the same target by the global correlator. (c) Corresponding output images of global 
(left) and local (right) correlators.

370
Theoretical Foundations of Digital Imaging Using MATLAB®
local adaptive correlators in the localization of a small fragment of one of 
the stereoscopic images in the second image. As one can see, the same filter, 
which in the example shown in Figure 7.12, properly detected a target of 31 
pixels in diameter, fails, when applied globally rather than locally, to prop-
erly localize a smaller target of 15 pixels in diameter, while this small target 
is successfully localized by the SCR-optimal local adaptive correlator.
Object Localization in Blurred Images
Images produced by imaging systems are frequently not sharp enough due 
to the weakening of their high-frequency components by optics or due to 
other technical reasons of low resolution of the imaging system. They also 
are distorted by the presence of a certain level of random noise, produced by 
image sensors. These image distortions and their correction are treated in 
the next chapter. In this section, we will discuss how they affect the perfor-
mance of SCR-optimal adaptive correlators in target localization in images.
Let the discrete frequency response of the imaging system be {
}
,
(
)
ηr s
ims
 and 
let the noise be an additive random process with uniform power spectrum 
νn
2 . Then, the original target object spectrum αr,s will be modified at the 
output of the imaging system to α
η
r s
r s
,
,
(
)
ims . The image background compo-
nent power spectrum |
|
,
(
)
βr s
bg
2 will also be modified by the imaging system 
to |
||
|
,
(
)
,
(
)
β
η
r s
r s
n
bg
ims
2
2
2
+ ν . With an account of these factors, SCR-optimal adaptive 
correlators should then have the following frequency response:
	
H
f
f
x
y
r s
r s
r s
bg
opt
bl
ims
(
)
,
,
(
)
,
(
)
..................
(
,
) =
∗
∗
α
η
β
2
..
,
(
)
,
η
ν
r s
n
ims 2
2
+
	
(7.57)
where |
|
,
(
)
....................
βr s
bg
2 is an estimate of the undistorted image background compo-
nent power spectrum averaged over all possible positions of the target object.
Modify Equation 7.57 in the following way:
	
η
α
β
η
r s
r s
r s
r s
,
(
)
,
,
(
)
....................
,
(
)
blr,opt
bg
ims
=
∗
∗
2
β
β
r s
r s
,
(
)
....................
,
(
)
...................
bg
bg
2
2
.
,
(
)
,
,
(
)
,
(
)
.................
η
ν
α
η
β
r s
n
r s
r s
r s
ims
ims
bg
2
2
2
+
=
∗
∗
...
,
(
)
,
(
)
....................
,
(
)
,
(
1
2
2
η
β
η
β
r s
r s
r s
r s
ims
bg
ims
bg
ims
)
....................
,
(
)
.
2
2
2
η
ν
r s
n
+











	
(7.58)
Equation 7.58 can be treated as a frequency response of two filters in 
­cascade: SCR-optimal adaptive filter with frequency response designed for 
undistorted image
	
η
α
β
r s
r s
r s
,
(
)
,
,
(
)
.................... ,
opt
bg
=
∗
2
	
(7.59)

371
Image Parameter Estimation
which is preceded by the filter with frequency response
	
η
η
β
η
r s
r s
r s
r s
,
(
)
,
(
)
,
(
)
....................
,
(
dblr
ims
bg
ims
=
1
2
)
,
(
)
....................
,
(
)
,
(
)
2
2
2
2
1
β
η
ν
η
r s
r s
n
r s
S
bg
ims
ims
+
=
NR
SNR
r s
r s
,
,
,
+ 1
	
(7.60)
where
	
SNRr s
r s
r s
n
,
,
(
)
....................
,
(
)
=
β
η
ν
bg
ims
2
2
2
	
(7.61)
is SNR in the distorted image on spatial frequency with indices (r,s). This filter 
has an inverse filter component (term 1/
ims
ηr s,
(
)), which, when applied to the input 
image distorted by the imaging system frequency response ηr s,
(
)
ims , will reverse 
this distortion, and a component with frequency response SNRr,s/(SNRr,s + 1), 
which depends on the component-wise SNR in the system. This second com-
ponent “regularizes” the inverse filtering component by means of suppress-
ing spectral components with low SNR. In Chapter 8, we will show that this 
filter component is an empirical Wiener filter for image deblurring. Thus, SCR-
adaptive filtering by the filter of Equation 7.57 can be interpreted as a two-stage 
procedure: image deblurring and subsequent SCR-optimal adaptive filtering 
of the deblurred image carried out in one stage. This means that target local-
ization on blurred images does not, in principle, require preliminary image 
deblurring correction, because this job is automatically performed by the SCR-
optimal adaptive correlator designed with an account for image blur.
Evaluate how much image blur deteriorates performance of SCR-optimal 
adaptive correlators in target localization. From Equation 7.44, it follows that 
in the presence of image blur and noise, SCR attained by the SCR-optimal 
correlator is
	
SCR
r s
r s
r s
s
N
r
y
(
)
,
,
(
)
....................
,
blr
bg
=
+
=
−
∑
α
β
ν
2
2
2
0
1
=
−
∑
=
0
1
2
2
2
N
r s
r s
r s
x
α
β
β
,
,
(
)
....................
,
(
)
......
bg
bg
..............
,
(
)
....................
,
β
ν
r s
r s
s
Ny
bg 2
2
0
1
+
=
−
∑
r
N
r s
r s
r s
r s
x
SNR
SNR
=
−
∑
=
+
0
1
2
2
1
α
β
,
,
(
)
....................
,
,
bg
s
N
r
N
r s
r s
s
N
y
x
y
=
−
=
−
=
−
∑
∑
≤
0
1
0
1
2
2
0
α
β
,
,
(
)
....................
bg
1
0
1
∑
∑
=
−
r
Nx
.
	
(7.62)
The right part of this inequality is SCR that can be attained if there were 
no signal blur and noise.

372
Theoretical Foundations of Digital Imaging Using MATLAB®
The ratio SNRr,s/(SNRr,s + 1) is a measure of deterioration of SCR on each 
particular signal frequency component. In particular, it tells that while 
{SNRr,s} are sufficiently high, image blur may have a marginal effect on the 
localization reliability of the SCR-optimal adaptive correlator.
Object Localization and Edge Detection: Selection of Reference 
Objects for Target Tracking
It is widely believed in the image processing community that the informa-
tion conveyed by images is contained mostly in image high-frequency com-
ponents and in edges and image analysis should start from edge detection or 
enhancement. The theory of the SCR-optimal adaptive correlator provides a 
rational explanation for this belief. Represent Equation 7.44 for the optimal 
adaptive correlator in the following way:
	
η
α
β
α
β
r s
r s
r s
r s
r s
,
(
)
,
,
(
)
....................
,
,
(
)
opt
bg
bg
=
=
∗
∗
2
2
1 2
2
1
....................
,
(
)
................






βr s
bg
....
.






1 2
	
(7.63)
In this representation, the SCR-optimal adaptive correlator is regarded as 
consisting of two filters in cascade. The filter represented by the right-hand 
factor in Equation 7.63
	
η
β
r s
r s
,
(
)
,
(
)
....................
whtng
bg
=






1
2
1 2
	
(7.64)
is an analog of the whitening filter introduced in the section “Target 
Localization in Cluttered Images” (Equation 7.14) for SNR-optimal target 
localization in correlated Gaussian noise. This filter, being applied to the 
input image, makes the image background component spectrum almost 
uniform. The filter represented by the left-hand factor in Equation 7.63 is a 
matched filter for the target object, modified by the same whitening operator.
This representation implies two conclusions. First of all, as power spectra 
of images usually (though not always) tend to decay on high frequencies, 
spectrum whitening usually results in emphasizing high-frequency image 
components with respect to its low-frequency components. It is in this sense 
that one can say that high-frequency image components are more important 
for image object recognition than low-frequency components. Second, if one 
visually compares image before and after whitening such as, for instance, 
images shown in Figure 7.15, one can see that image whitening results in 
what is visually interpreted as edge enhancement.

373
Image Parameter Estimation
In general, the whitening tends to suppress those image frequency com-
ponents that have high energy and that are, therefore, responsible for fea-
tures common to the majority of objects represented in image. Low-energy 
frequency components, which are responsible for “uncommon,” or rare 
objects and object features, are, on the contrary, emphasized. In a sense, 
one can say that whitening is an operation that automatically enhances 
dissimilarities and suppresses similarities of objects in images. This is 
well illustrated by a result of whitening of a test image of geometrical fig-
ures and printed characters shown in Figure 7.16. One can see in the figure 
that the whitening does enhance edges (object borders), but the enhance-
ment is quite selective. Vertical and horizontal edges that are common to 
all figures and characters are enhanced much less than circumferences, 
slanted edges, and corners in geometrical figures and characters and those 
are also enhanced very selectively according to their rate of occurrences 
in the image.
It is very instructive to also consider PSFs of whitening filters for different 
images. Table 7.1 shows the central 5×5 samples of PSFs of whitening opera-
tors (inverse 2D DFTs of frequency responses, Equation 7.64) for test images 
shown in Figures 7.14a and 7.16a.
One can see that those PSFs for considered two substantially different 
images are quite similar. Their most remarkable common feature is that the 
central peak of PSFs is surrounded by negative closest neighbors (shown 
nonbold in Table 7.1). In this respect, these two particular whitening filter 
FIGURE 7.15
​Test image (a), whitened test image (b), and its local variances in the window of 15×15 pixels (c).

374
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 7.16
Test image of geometrical figures (a), whitened image and its magnified fragments (b), and its 
local variances in the window of 7×7 pixels (c).
TABLE 7.1
PSFs of the Whitening Operators
PSF of the Whitening Operator for Image of 
Figure 7.14a
0.002
0.023
0.043
0.037
0.029
0.003
−0.006
−0.294
−0.035
−0.005
0.047
−0.249
1.000
−0.249
0.047
−0.005
−0.035
−0.294
−0.006
0.003
0.029
0.037
0.043
0.023
0.002
PSF of the Whitening Operator for Image of 
Figure 7.16a
0.012
0.003
−0.024
0.0221
−0.03
0.014
−0.019
−0.2
−0.023
0.042
0.03
−0.243
1.000
−0.243
0.03
0.042
−0.023
−0.2
−0.019
0.014
−0.03
0.022
−0.024
0.003
0.012

375
Image Parameter Estimation
PSFs resemble very much the PSF of filters for computing image spatial 
Laplacian, two most common ­versions of which are as follows:
	
L
L
1
2
0
0 25
0
0 25
1
0 25
0
0 25
0
0 125
0 125
0 1
=
−
−
−
−










=
−
−
−
.
.
.
.
,
.
.
. 25
0 125
1
0 125
0 125
0 125
0 125
−
−
−
−
−










.
.
.
.
.
.
	
(7.65)
This observation suggests a rational explanation for the common belief in 
the importance of the Laplacian operator in image processing: the Laplacian 
operator can be considered as an empirical approximation to adaptive whit-
ening operators.
The remarkable fact is also that visual systems of humans and 
­vertebrates feature similar capacity of neurons to reduce the activity of 
its  spatially nearest neighbors. This action known as lateral inhibition is 
actually what whitening and Laplacian operators perform, thanks to neg-
ative weights of the samples of the filter PSF that surround the ­central 
peak.  This feature exhibits itself as the so-called Mach effect: visual 
impression of edge enhancement in images. Figure 7.17 illustrates this 
phenomenon.
FIGURE 7.17
Mach effect: image visually appears darker at dark sides of edges and brighter on bright sides.

376
Theoretical Foundations of Digital Imaging Using MATLAB®
The importance of whitened edge-contained image component for object 
recognition can also be illustrated by an experiment with exchanging power 
spectra of images (Figure 7.18), in which the power spectrum of one image 
is replaced by the power spectrum of another, while phase spectra retain 
the original. Both images after this exchange remain very well recognizable, 
though one can notice that Mona Lisa’s smile charm evaporated.
This means that low-frequency image components also do carry important 
information. In Figure 7.19 shown are image of “Mona Lisa” low-pass filtered 
to quarter of the image base band (left image) and its complement high-fre-
quency component (right image). As one can see, Mona Lisa’s famous smile 
is retained in the low-frequency component, while in the high-frequency 
component, it volatilized.
Consider now the issue of selecting target objects in cases when target 
objects have to be selected from image fragments for, for example, object 
FIGURE 7.18
​Illustration of importance of whitened spectra for object recognition: images in the bottom 
row are obtained by means of exchange power spectra of images of the upper row retaining 
image-whitened spectra. Note that images are still well recognizable, though Mona Lisa’s 
smile charm evaporated.

377
Image Parameter Estimation
tracking in videos, in image registration and matching with a map, in stereo 
image analysis, in robot vision navigation, and in multimodal medical imag-
ing. In such applications, the question is how to make the choice of the target 
objects to the best advantage.
A natural figure of merit of target objects that determines potential reli-
ability of their localization is the SCR that can be attained for these objects 
in SCR-optimal adaptive correlators. One can obtain from Equation 7.62 that 
maximal attained SCR for the SCR-optimal adaptive correlator is equal to 
the energy of the whitened spectrum of the target object:
	
SCR
r s
r s
s
N
r
N
y
x
=
=
−
=
−
∑
∑
α
β
,
,
(
)
......................
2
2
0
1
0
1
bg
	
(7.66)
Therefore, the higher the energy of the whitened spectrum, the higher is 
the SCR that one can expect at the SCR-optimal adaptive correlator output 
for this object. This implies that the best candidates for target objects will 
be image fragments that have maximal energy of their “whitened” power 
spectrum, that is, image fragments with intensive high-frequency compo-
nents, which are visually interpreted as containing the most intensive edges 
or texture.
This conclusion is illustrated in Figures 7.15 and 7.16, where the “good-
ness” of the fragments of 15×15 pixels (Figure 7.15c) and 7×7 pixels (Figure 
7.16c) in terms of the SCR-factor is represented by the pixel gray levels for 
test images of Figures 7.15a and 7.16a. One can see from these images that 
edge-rich areas are indeed the most appropriate potential candidates for 
FIGURE 7.19
An illustration of importance of low-frequency image components. The left image is a compo-
nent of the “Mona Lisa” image low-pass filtered to quarter of the image base band. It perfectly 
reproduces Mona Lisa’s smile charm. The right image is its high-frequency complement. The 
charm volatilized.

378
Theoretical Foundations of Digital Imaging Using MATLAB®
reference object. One can also make a remarkable observation that, for 
rectangles in the image of geometrical figures, corners have much higher 
“goodness.” This result is intuitively very well understandable: edges in 
all rectangles are similar and cannot be regarded as their specific features, 
while corners are more specific.
Appendix
Distribution Density and Variances of Normal Localization Errors
Although we consider working with images in their sampled representation, 
target localization can be performed, with appropriate signal subsampling, 
with subpixel accuracy and localization errors computed in units of sam-
pling intervals may have arbitrary noninteger values. Therefore, it would 
be appropriate to use continuous image models for the analysis of statistical 
characteristics of localization errors.
Let a(x, y) and b(x, y) be, respectively, continuous models of the target object 
(template) image and of the observed image, in which it should be local-
ized. For the considered case of additive signal-independent noise model, 
b(x, y) = a(x, y) + n(x, y), where n(x, y) stands for realizations of noise. Then, 
the optimal ML-estimate of target object coordinates is a solution of the fol-
lowing continuous analog of Equation 7.4:
 
ˆ , ˆ
argmin
( , ) (
,
)
(
,
)
x
y
b x y a x
x
y
y
x y
x
y
0
0
0
0
0
0
{
}
=
−
−


−∞
∞
−∞
∞
∫∫
ML
d d




=
+


−
−
−∞
∞
argmin
( , )
( , )
(
,
)
(
,
)
x
y
a x y
n x y
a x
x
y
y
x y
0
0
0
0 d d
∫∫
−∞
∞






,
	
(7A.1)
that is, it is a position of the maximum correlation between the observed 
image b(x, y) and the template image a(x, y) taken in all possible range of its 
coordinates {x0, y0}.
Consider the correlator output signal
	
R
x
y
a x y
n x y
a x
x
y
y
x y
R x
ab
a
(
,
)
( , )
( , )
(
,
)
(
0
0
0
0
=
+


−
−
=
−
−∞
∞
−∞
∞
∫∫
d d
x
y
y
n x, y
0
0
,
)
(
),
−
+ 
	
(7A.2)

379
Image Parameter Estimation
where
	
R x
y  =  
a x, y  a x  x , y  y  x y
a(
,
)
(
) (
)
0
0
0
0
−
−
−∞
∞
−∞
∞
∫∫
d d
	
(7A.3)
is an autocorrelation function of the target object signal, and
	
n x
y
n x y a x
x
y
y
x y
(
,
)
( , ) (
,
)
0
0
0
0
=
−
−
−∞
∞
−∞
∞
∫∫
d d
	
(7A.4)
is a correlated Gaussian random process resulting from filtering input 
Gaussian noise by the matched filter. Its correlation function can be found as
	
R
n x, y
n x, y  
=  
n x, y n x, y  a x  x
n
N
N



=
⋅


{
}
−
AV
AV
Ω
Ω
(
)
(
)
(
) (
)
(
0, y  y  a x  x , y  y  x y x y
 
n
−
−
−
=
−∞
∞
−∞
∞
−∞
∞
−∞
∞
∫∫∫∫
0
0
0
2
) (
)d d d d
(
σ δ x  x, y  y  a x  x , y  y  a x  x , y  y  x y x y
−
−
−
−
−
−
−∞
)
d d d d
(
) (
)
0
0
0
0
∞
−∞
∞
−∞
∞
−∞
∞
∫∫∫∫
=
−
−
−
−
σn
a x  x , y  y  a x  x , y  y  x y 
2
0
0
0
0
(
) (
)d d
−∞
∞
−∞
∞
∫∫
=
−
−
σn
a
 R  x
x , y
y
2
0
0
0
0
(
),
	
(7A.5)
where AV
N
Ω( )⋅ denotes statistical averaging over the noise ensemble ΩN, 
AVΩN n x, y n x, y
x  x, y  y
n
{ (
) (
)} =
−
−
σ δ
2 (
) is the correlation function of uncorre-
lated noise and σn
2 is noise variance.
In the case of small (normal) errors, signal maxima at the output of the 
correlator are located in a close vicinity of the point (x0, y0), the position of 
maximum of Ra(x, y). Then the following system of equations determines the 
coordinates (
)
x , y
0
0


 of the maximum of R(x, y):
	
∂
∂
= ∂
∂
−
−
+ ∂
∂
=
∂
∂
= ∂
∂
−
x R x, y
x R x
x , y
y
x n x, y
y R x, y
y R x
x
a
0
0
a
(
)
(
)
(
)
(
)
(

0
0
0
, y
y
y n x, y
−
+ ∂
∂
=






)
(
)

0
 .
	
(7A.6)

380
Theoretical Foundations of Digital Imaging Using MATLAB®
Let the solution of this system be ˆ
; ˆ
x
x
y
y
x
y
0
0
0
0
=
+
=
+
ε
ε  and localiza-
tion errors εx and εy are small enough to permit the first-order Taylor expan-
sion of R(x, y) around point {x0, y0}. Then, we have
     
∂
∂
−
−
= ∂
∂
−
−
+
=
+
=
+
=
=
x R x
x , y
y
x R x
x , y
y
a
x x
y y
a
x x
y y
x
x
y
(
)
(
)
0
0
0
0
0
0
0
0
ε
ε
ε
∂
∂
−
−
+
∂
∂∂
−
−
=
=
=
=
=
2
2
a
y
2
a
x R x
x , y
y
x y R x
x , y
y
x
x
y
y
x
x
y
y
(
)
(
)
0
0
0
0
0
0
0
0
ε
∂
∂
−
−
+
+
= −∂
∂
=
=
=
=
x R x
x , y
y
D
D
x n x, y
a
x x
y y
x
x
xy
y
x
x
y
y
(
)
(
)
.
0
0
0
0
0
0
ε
ε

	
(7A.7)
Similarly, one can obtain
     
∂
∂
−
−
+
+
= −∂
∂
=
=
=
+
=
x R x
x , y
y
D
D
y n x, y
a
x x
y y
xy
x
y
y
x x
n
y y
0
x
0
(
)
(
)
0
0
0
0
ε
ε

+ny
,
	
(7A.8)
where
   
D
x R x
x , y
y
D
y R x
x , y
y
x
2
2
a
x x
y y
y
2
2
a
x x
y y
= ∂
∂
−
−
= ∂
∂
−
−
=
=
=
=
(
)
;
(
)
0
0
0
0
0
0
0
0
0
0
0
0
;
(
)
.
D
x y R x
x , y
y
xy
2
a
x x
y y
=
∂
∂∂
−
−
=
=
	
(7A.9)
In the point (x0, y0) of the target location, the autocorrelation function 
Ra(x − x0, y − y0) has a maximum. Therefore
 
∂
∂
−
−
=
∂
∂
−
−
=
=
=
=
=
x R x
x , y
y
y R x
x , y
y
a
x x
y y
a
x x
y y
(
)
(
)
.
0
0
0
0
0
0
0
0
0
0
and
	
(7A.10)
Substitute these equalities in Equations 7A.7 and 7A.8 and obtain the 
­following system of equations:

381
Image Parameter Estimation
	
D
D
x n x, y
D
D
y n x, y
x
x
xy
y
xy
x
y
y
x x
n
x
x
y
y
ε
ε
ε
ε
+
= −∂
∂
+
= −∂
∂
=
=
=
+


(
)
(
)
0
0
0
x
y
y y
n
=
+






0
	
(7A.11)
from which the following relationships for errors εx and εy in x and y direc-
tions follow:
	
ε
ν
ν
ε
ν
x
y
x
y
xy
x
xy
x
y
xy
y
y
x
x
y
xy
y
xy
x
y
D
D D
D
D
D D
D
D
D D
D
D
D D
D
=
−
−
−
=
−
−
−
2
2
2
;
xy
x
2 ν ,
	
(7A.12)
where
	
ν
ν
ε
ε
ε
ε
x
x x
y y
y
x x
y y
x n x, y
y n x, y
x
y
x
y
= −∂
∂
= −∂
∂
=
+
=
+
=
+
=
+


(
)
(
)
0
0
0
0
;

.


 	
(7A.13)
Derivatives νx and νy of the random Gaussian process n x, y
(
) are Gaussian 
random variables. Therefore, from Equation 7A.12, it follows that small 
ML-coordinate estimation errors {εx, εy} have a Gaussian distribution with 
zero mean and variances:
	
ε
ε
ν
x
x
y
x
y
xy
x
xy
x
y
xy
D
D D
D
D
D D
D
2
2
2
2
2
2
=
(
) =
−




(
) +
−



AV
AV
N
N
Ω
Ω

(
)
−
−
Ω
2
2
2
AV
D D
D D
D
AV
N
y
xy
x
y
xy
y
Ω
ν
ν ν
y
(
)
(
);
2
2
N
x
	
(7A.14)
	
ε
ε
ν
y
y
x
x
y
xy
y
xy
x
y
xy
D
D D
D
D
D D
D
2
2
2
2
2
2
=
=
−




(
) +
−



AV
AV
N
N
Ω
Ω
(
)

(
)
−
−
2
2
2
2
2
AV
AV
N
N
Ω
Ω
ν
ν ν
x
x
xy
x
y
xy
x
y
D D
D D
D
(
)
(
)
	
(7A.15)
   
ε
ε ε
ν ν
xy
x
y
x
y
xy
x
y
xy
x
y
y
xy
x
D D
D
D D
D
D D
D
2
2
2
2
=
=
−
−
−
AV
AV
N
N
Ω
Ω
(
)
(
)
(
)
(
)
(
D
D
D D
D D
D
y
xy
x
x
xy
x
y
xy
x
−
(
)+
−
(
)
2
2
2
2
2
2
)
(
)
.
AV
AV
N
N
Ω
Ω
ν
ν
	
(7A.16)

382
Theoretical Foundations of Digital Imaging Using MATLAB®
The parameters involved in Equations 7.45 through 7.47 can be found using 
the relationship between signal correlation functions and power spectra 
(Equation 2.127) and properties of the Fourier transform:
D
x R
x
x
y
y
x
a
=
∂
∂
−
−
(
)
=
∂
∂
−
−
=
=
2
2
x x
y y
2
2
x
y
x
,
x
a f , f
i2p f
x
x
0
0
0
0
0
(
)
(
2 exp
)
(
)
(
,
)
+
−


{
}
= −
−∞
∞
−∞
∞
=
=
∫∫
f
y
y
f
f
f
f
f
f
y
x
y
x x
y y
x
x
y
0
0
0
d d
d
4
2
2
2
π
α
x
y
x
a
f
f E
d
−∞
∞
−∞
∞
∫∫
= −4
2
2
π
,
	
(7A.17)
where α( fx, fy) is a Fourier spectrum of the target object image
	
α
π
(
)
(
) d d
f
f
a x y
i
f x
f y
f
f
x
y
y
y
x
y
,
( , )exp
=
+


−∞
∞
−∞
∞
∫∫
2
	
(7A.18)
Ea is its energy
	
E
f
f
f
f
a
x
y
x
y
=
−∞
∞
−∞
∞
∫∫
α(
) d d
,
2
	
(7A.19)
and fx
2 is energy of template image derivative along the axis fx relative to the 
signal energy:
	
f
f
f
f
f
f
f
f
f
f
x
x
x
y
x
y
x
y
x
y
2
2
2
2
=
−∞
∞
−∞
∞
−∞
∞
−∞
∞∫∫
∫∫
α
α
(
) d d
(
) d d
,
,
.
	
(7A.20)
Similarly
	
D
f
f
f
f
f
f E
y
y
x
y
x
y
y
a
= −
= −
−∞
∞
−∞
∞
∫∫
4
4
2
2
2
2
2
π
α
π
(
) d d
,
	
(7A.21)

383
Image Parameter Estimation
and
	
D
f f
f
f
f
f
f E
xy
x
y
x
y
x
y
xy
a
= −
= −
−∞
∞
−∞
∞
∫∫
4
4
2
2
2
2
π
α
π
(
) d d
,
,
	
(7A.22)
where
	
f
f
f
f
f
f
f
f
f
f
y
y
x
y
x
y
x
y
x
y
2
2
2
2
=
−∞
∞
−∞
∞
−∞
∞
−∞
∞∫∫
∫∫
α
α
(
) d d
(
) d d
,
,
	
(7A.23)
and
	
f
f f
f
f
f
f
f
f
f
f
xy
x
y
x
y
x
y
x
y
x
y
2
2
2
=
−∞
∞
−∞
∞
−∞
∞
−∞
∞∫∫
∫∫
α
α
(
) d d
(
) d d
,
,
.
	
(7A.24)
The second moments AV
N
Ω(| | )
νx
2 , AVΩN
y
(| | )
ν
2 , and AVΩN
x
y
(
)
ν ν
 of the 
noise component in the formulas (7A.14 through 7A.16) can also be found 
in the spectral domain. For instance, the spectrum of νx, being a spectrum 
of derivative, is equal to 4
2
2
π fx  times power spectrum of Rn(x, y), which, by 
virtue of Equation 7A.5, is equal to σ
α
n
x
y
f
f
2
2
| (
,
)| . Therefore
	
AVΩN
x
n
x
x
y
x
y
x
n
a
f
f
f
f
f
f
E
(
)
,
.
ν
π σ
α
π
σ
2
2
2
2
2
2
2
2
4
4
=
=
−∞
∞
−∞
∞
∫∫
(
) d d
	
(7A.25)
In a similar way, one can obtain
	
AVΩN
y
n
y
x
y
x
y
n
a
y
f
f
f
f
f
E f
(
)
,
ν
π σ
α
π σ
2
2
2
2
2
2
2
2
4
4
=
=
−∞
∞
−∞
∞
∫∫
(
) d d
	
(7A.26)
and
	
AVΩN
x
y
n
x
y
x
y
x
y
n
a
xy
f f
f
f
f
f
E f
(
)
,
.
ν ν
π σ
α
π σ
=
=
−∞
∞
−∞
∞
∫∫
4
4
2
2
2
2
2
2
(
) d d
	
(7A.27)

384
Theoretical Foundations of Digital Imaging Using MATLAB®
After substituting these parameters into Equations 7A.14 through 7A.16, we 
finally arrive, for the optimal ML-estimator, at the following relationships 
for variances of normal errors in object coordinate estimation in the presence 
of additive white zero mean Gaussian noise:
	
ε
π
σ
ε
π
σ
x
y
x
y
xy
n
a
y
x
x
y
x y
f
f f
f
E
f
f f
f
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
4
=
−(
)
=
−(
)
;
,
1
4
2
n
a
xy
xy
x
y
xy
n
a
E
f
f f
f
E
2
2
2
2
2
2
2
2
2
1
4
;
.
ε
π
σ
=
−(
)
	
(7A.28)
The power spectra |
,
|
α(
)
f
f
x
y
2of real-valued signals feature the property 
of central symmetry: |
,
|
|
,
|
α
α
(
)
(
)
f
f
f
f
x
y
x
y
2
2
=
−
−
. If the object signal power 
spectrum is symmetrical with respect to the coordinate axes as well: 
|
,
|
|
,
|
|
,
|
α
α
α
(
)
(
)
(
)
f
f
f
f
f
f
x
y
x
y
x
y
2
2
2
=
−
=
−
, Equation 7A.28 takes the following 
simpler form:
	
ε
σ
π
ε
σ
π
ε
x
x
n
a
y
y
n
a
xy
f
E
f
E
2
2
2
2
2
2
2
2
2
1
4
1
4
0
=
=
=
;
;
.
	
(7A.29)
The last equation implies that, if the signal power spectrum is axes-
symmetrical, normal localization errors along coordinates x and y are 
uncorrelated. This situation takes place if the object spectrum α(fx, fy), and, 
correspondingly, the target object signal a(x,y) are separable functions of the 
coordinates. Equation 7A.29 is applicable to 1D signals.
Equation 7A.28 shows that variances of normal localization errors are fully 
determined by the SNR σn
a
E
2/
 and the energy of derivatives of the target 
object signal. These are the only characteristics of the object shape that affect 
the potential accuracy of its localization.
In digital processing, it is natural to evaluate error variances in units of 
signal sampling intervals Δx,Δy. Denote
	
ε
ε
ε
ε
ε
ε
∆
∆
∆
∆
∆
∆∆
x
x
y
y
xy
xy
x
y
x y
2
2
2
2
2
2
2
2
=
=
=
/
/
/
;
;
.	
(7A.30)
Then, from Equation 7.59, obtain
	
ε
π
σ
π
∆
∆
∆
∆
∆
x
y
x
y
xy
n
a
y
x
f
f
x
f
f
x
E
f
y
f
x
f
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
4
1
4
=
(
)( ) −
=
(
)
y
xy
n
a
y
x
y
xy
n
y
f
x y
E
f
f
f
f
2
2
2
2
2
2
2
2
2
2
2
2
1
4
∆
∆∆
∆
∆
∆
∆
(
) −(
)
=
(
)(
) −(
)
σ
π
σ
Ea
;
	

385
Image Parameter Estimation
	
ε
π
σ
ε
π
∆
∆
∆
∆
∆
∆
∆
∆
y
x
x
y
xy
n
a
xy
xy
x
f
f
f
f
E
f
f
2
2
2
2
2
2
2
2
2
2
2
1
4
1
4
=
(
)(
) −(
)
=
;
2
2
2
2
2
f
f
E
y
xy
n
a
∆
∆
−(
)
σ ,
	
(7A.31)
where
	
f
f
x
f
x
f
f
y
f
y
f
f
x y
f
x
x
x
y
y
y
xy
xy
∆
∆
∆
∆
∆
∆
∆
∆∆
2
2
2
2
2
2
2
2
2
2
2
2
1
1
=
=
=
=
=
=
/
/
;
;
xy
x
y
2
1
1
(
)(
).
/
/
∆
∆
	
(7A.32)
For separable 2D template signals, obtain correspondingly
	
ε
π
σ
ε
π
σ
σ
∆
∆
∆
∆
∆
x
x
n
a
y
y
n
a
xy
f
E
f
E
2
2
2
2
2
2
2
2
2
1
4
1
4
0
=
=
=
;
;
.
	
(7A.33)
These equations are also valid for 1D signals.
The above formulas for variances of localization errors are expressed 
through parameters of continuous signals. In order to express them 
in terms of parameters of corresponding sampled signals, one has to 
apply relationships between sampled signals and reconstruct from 
them continuous signals given by the sampling theory (see Chapter 3), 
characterizations of digital filters in terms of equivalent continuous fil-
ters outlined in the section “DFTs and Discrete Frequency Response of 
Digital Filter” in  Chapter 4 and Parseval’s relationships (2.7 through 
2.9). In this treatment,  we will assume ideal sampling and reconstruc-
tion, which imply band-limited signals with X–Y base bands (−1/2 
Δx ÷ 1/2Δx; −1/2Δy ÷ 1/2Δy).
According to the Parseval’s relationship (Equation 2.8), the relationship of 
Equation 4.79 between continuous signal frequency and frequency index of 
its DFT and Equations 6.36 and 6.38 for frequency responses of signal dif-
ferentiators, obtain for sampled images of Nx × Ny pixels:
	
E
f
f
f
f
a
a
x
y
x
y
k
l
N
k
N
y
x
=
=
−∞
∞
−∞
∞
=
−
=
−
∫∫
∑
∑
α(
,
)
2
2
0
1
0
1
d d
	
(7A.34)

386
Theoretical Foundations of Digital Imaging Using MATLAB®
	
f
f
x
f
f
f
f
f
f
x
x
x
y
y
y
x
x
x
y
x
y
∆
∆
∆
∆
∆
∆
2
2
2
2
1 2
1 2
1 2
1 2
=
−
−
∫
∫
α
α
(
) d d
(
)
,
,
/
/
/
/
2
1 2
1 2
1 2
1 2
2
2
2
2
−
−
∫
∫
∑
∑
=




/
/
/
/
,
,
∆
∆
∆
∆
y
y
x
x
x
y
x
r s
s
r
r s
f
f
r
N
d d
α
α
2
2
2
2
2
1
s
r
x
r
r s
s
r s
s
r
N
r
∑
∑
∑∑
∑
∑
=
α
α
,
,
;
	
(7A.35)
	
f
f
y
f
f
f
f
f
f
y
y
x
y
y
y
x
x
x
y
x
y
∆
∆
∆
∆
∆
∆
2
2
2
2
1 2
1 2
1 2
1 2
=
−
−
∫
∫
α
α
(
) d d
(
)
,
,
/
/
/
/
2
1 2
1 2
1 2
1 2
2
2
2
2
1
−
−
∫
∫
∑
∑
∑
∑
=
/
/
/
/
,
,
;
∆
∆
∆
∆
y
y
x
x
x
y
y
r s
r
s
r s
s
r
f
f
N
s
d d
α
α
	
(7A.36)
f
f f
x y
f
f
f
f
f
xy
x
y
x
y
y
y
x
x
x
y
x
∆
∆
∆
∆
∆
∆∆
2
2
2
1 2
1 2
1 2
1 2
=
−
−
∫
∫
α
α
(
) d d
(
,
/
/
/
/
,
/
/
/
/
,
,
f
f
f
N N
rs
y
y
y
x
x
x
y
x
y
r s
s
r
r s
) d d
2
1 2
1 2
1 2
1 2
2
2
1
−
−
∫
∫
∑
∑
=
∆
∆
∆
∆
α
α
s
r ∑
∑
,
	
(7A.37)
where
	
α
π
r s
x
y
k l
x
y
l
N
k
N
N N
i
kr
N
ls
N
y
x
,
, exp
=
+












=
−
=
−
∑
1
2
0
1
0
1
a
∑
	
(7A.38)
is the DFT of sampled version {ak,l} of the target object signal. Summations in 
Equations 7A.35 through 7A.37 are carried out over indices r,s of spatial fre-
quencies from the lowest frequencies (r = 1, s = 1) to the highest ones ((Nx/2, 
Ny/2) or (Nx − 1)/2, (Ny − 1)/2) depending on whether Nx and Ny are even or 
odd numbers.
Evaluation of the Probability of Anomalous Localization Errors
We defined anomalous errors as those that occur when the localization 
device wrongly locates the target object at output of the matched filter out-
side the area it occupies, that is, in the area that contains only the noise com-
ponent of the image. Because noise at the matched filter output results from 
filtering the input white Gaussian noise, it is spatially homogeneous in this 

387
Image Parameter Estimation
area. Therefore, large noise outbursts may be found with equal probability 
everywhere in an area outside the target object in its actual location. This 
implies that the tales of the localization error distribution density are uni-
form and one can characterize anomalous errors by simply their total prob-
ability determined by the area under the distribution density tales.
Analytical evaluation of the probability of anomalous errors by methods 
of the theory of random processes requires cumbersome computation and 
cannot be carried out without certain simplifying assumptions. Its reason-
ably good estimation can be obtained by the following simple reasoning.
The output of the matched filter outside the area occupied by the object 
is a correlated Gaussian random process n x, y
(
) with correlation function 
defined by Equation 7A.5:
	
R x y
R x y
n
n
a
( , )
( , ).
= σ2
	
(7A.39)
Let ΔS be its correlation interval, that is, a minimal distance at which corre-
lation between process values can be regarded as negligibly small. Because 
the correlation function of noise at the matched filter output is, accord-
ing to Equation 7A.39, proportional to that of the object signal, ΔS has an 
order of magnitude of the area occupied by the signal at the matched fil-
ter output. Therefore, in the area of the search S there are approximately 
Q = S/ΔS uncorrelated samples of Gaussian random process with variance 
σ
σ
σ
n
n
n
a
n
a
R
R
E
2
2
2
0 0
0 0
=
=
=
( , )
( , )
.
Let us take one of this samples, the one at the point of the actual loca-
tion of the target object. According to Equation 7A.2, its value is equal to 
Ra(0,0) + Rn = Ea + Rn, where Ra is a Gaussian zero mean random value with 
variance σn
2. One can then find the probability of anomalous errors PAe as a 
value complementary to the probability that none of the rest of (Q − 1) uncorre-
lated samples of Gaussian noise outside the object location exceeds this value:
P
n
n
t
n
n
n
n
Ae
d
=
−
−




−


−∞
∞
∫
1
1
2
2
1
2
2
2
2
2
2
2
2
πσ
σ
πσ
σ






exp
exp










=
−




−
+

−∞
+
−
−∞
∞
∫
∫
dt
n
E
n
E
n
Q
a
n
a


1
2
1
2
2
1
π
σ
exp
Φ












=
−




−
−
−∞
∞
∫
Q 1
2
2
1
2
2
1
dn
n
E
E
a
a
n
π
σ
exp
Φ
+




















=
−




−
−
−∞
∞
∫
n
n
n
E
Q
a
1
2
1
2
2
1
d
π
exp
Φ
σn
Q
n
n
2
1
+


















−
d ,
	
(7A.40)

388
Theoretical Foundations of Digital Imaging Using MATLAB®
where
	
Φ( )
exp
x
n
n
x
=
−




−∞∫
1
2
2
2
π
d
	
(7A.41)
is the “error integral.”
Formula 7A.40 is known in communication theory as the one that deter-
mines the probability of errors in communication channels with Q orthogonal 
signals and additive white Gaussian noise. The remarkable feature of this 
integral is its threshold behavior for large Q. Consider
	
lim ln
lim
ln
ln
Q
a
n
Q
Q
E
n
Q
Q
→∞
−
→∞
+




















=
(
)
Φ
Φ
σ
µ
2
1




(
) =










→∞
lim
ln
(
ln
)
,
Q
Q
Q
Φ µ
1
where µ
σ
=
E
Q
a
n
2 ln
. Because lim
(
log
)
,
Q
Q
n
→∞
+
=
Φ µ
1  and, therefore, 
lim ln[ (
log
)]
,
Q
Q
n
→∞
+
=
Φ µ
0  the above limit is an indeterminate form 0/0. 
Then by L’Hospital’s rule, we have
	
lim ln
lim
ln
ln
Q
a
n
Q
Q
E
n
Q
Q
→∞
−
→∞
+




















=
Φ
Φ
σ
µ
2
1
d
d
(
)














=
(
)




(
) −
→∞
d
d
/
d
d
/
Q
Q
Q
Q
Q
Q
Q
(
)
lim
ln
ln
1
1
2
Φ
Φ
µ
µ
(
)










=
−
−




(
)




=
→∞
lim
exp
ln
ln
lim
Q
Q
Q
Q
Q
2
2
2
µ
µ
d
d
Q
Q
Q
Q
Q
Q
Q
→∞
−
→∞
−
−










=
−










=
−
µ
µ
µ
µ
2
2
2
2
1
2
2
2
ln
lim
ln
∞
	
	
	
	
		
	
	
	
,
,
.
µ
µ
2
2
2
1
0
2
1
	
(7A.42)
Therefore
	
lim
,
ln
,
ln
Q
a
n
a
n
a
n
E
n
E
Q
E
Q
→∞
−
+












=
<
≥


Φ
σ
σ
σ
2
1
2
2
0
2
1
2
Q



389
Image Parameter Estimation
and
	
lim
exp
Q
a
n
Q
P
n
E
n
→∞
−∞
∞
−
=
−




−
+













∫
Ae
1
2
2
1
2
2
1
π
σ
Φ





=
>
≤



d
if
/
if
/
n
E
Q
E
Q
a
n
a
n
0
2
1
2
2
2
,
ln
,
ln
.
σ
σ
	
(7A.43)
Derivation of Equations 7.49, 7.50, and 7.51
For the additive model:
AV
AV
i
rx
N
s
x
y
r s
x
y
x
y
r s
r s
x
0
0
0
0
0
0
2
0
2
,
,
,
,
,
,
, exp
β
β
α
π
bg
(
)




=
−
+ y
N
i
rx
N
sy
N
y
r s
r s
x
y
0
0
0
2


















−
−
+
∗
∗
β
α
π
,
, exp


















=
+
−
∗
β
α
α β
r s
r s
r s
r s
x
y
AV
i
,
,
,
,
,
exp
2
2
0
0
2
0
0
0
0
π
α β
rx
N
sy
N
AV
x
y
r s
r s
x
y
+


















−
∗
,
,
,
exp −
+


















i
rx
N
sy
N
x
y
2
0
0
π
.
	
(7A.44)
In the assumption that target coordinates have uniform distribution den-
sity over the input image
   
AV
i
rx
N
sy
N
N N
x
y
x
y
x
y
0
0
2
1
0
0
,
exp
exp
±
+


















=
π
±




±




=
−
−
∫
∫
i
rx
N
x
i
sy
N
y
x
N
N
x
N
N
x
x
y
y
2
2
1
0
0
2
2
0
0
2
2
π
π
d
d
exp
N N N
i r
i r
i
r
N
i s
i s
i
s
x
y
x
y
exp(
)
exp(
)
exp(
)
exp(
)
±
−
±
±
±
−
±
±
=
π
π
π
π
π
π
2
2
sin(
) sin(
)
.
π
π
π
π
δ
δ
r
r
s
s
r
s
=
( ) ( )
	
(7A.45)

390
Theoretical Foundations of Digital Imaging Using MATLAB®
Then
AVx
y
r s
x
y
r s
r s
r s
r s
r s
r s
0
0
0
0
2
2
2
,
,
(
,
,
)
,
,
,
,
,
,
(
)
β
β
α
α β
α β
bg
(
) =
+
−
+
∗
∗
δ
δ
β
α
α
β
δ
δ
β
α
α
β
( ) ( )
( ) ( )
r
s
r
s
r s
r s
=
+
−
=
+
−
,
,
,
,
,
,
,
2
2
0 0
0 0
0 0
2
0 0
2
0 0
2
2
0 0
2
2
0
1
1
1
1
,
,
,
,
,
,
,
,
,
,
,
.
r s
r
N
s
N
r s
r s
x
y
=
+
=
−
=
−


β
α
…
…
	
(7A.46)
Spectral coefficients with indices  r,s = 0 are responsible for the signal 
dc-component, which is irrelevant for localization of signal maximum. 
Therefore, one can, for evaluation of AVx
y
r s
x
y
0
0
0
0
2
,
,
(
,
,
)
(|
| )
β bg
, use the relationship
	
AVx
y
r s
x
y
r s
r s
0
0
0
0
2
2
2
,
,
(
,
,
)
,
,
.
β
β
α
bg
(
) =
+
	
(7A.47)
For the implant model, consider, for the sake of simplicity, a 1D case:
	
b
w
b
b
w
b
k
k
x
k
k
k
x
k
(
)
(
,
)
(
,
)
.
bg
tgt
tgt
=
−
(
)
=
−
1
0
0
	
(7A.48)
Then, for the DFT spectrum of the background component, we, using the 
DFT convolution theorem (the section “Discrete Representation of Fourier 
Integral Transform” in Chapter 4), have
 
β
β
β
ω
β
β
β
ω
r
x
r
x
r
r
x
r
x
r
x
r
r
x
N
N
(
)
(
,
)
(
,
)
(
,
)
bg,
bg
bg
tgt
0
0
0
0
1
1
2
=
−
=
−








−






=
+
−
∗
∗
∗
β
β
ω
β
β
ω
β
r
x
r
r
x
r
r
r
x
x
N
N
1
0
0
2
2


(
,
)
(
,
)
tgt
tgt
r
r
r
x
r
r
r
x
x
N
β
ω
β β
ω
∗
∗
∗
(
) +
(
)


tgt
tgt
,
(
,
)
,
0
0
	
(7A.49)
where {βr} is DFT spectrum of the input image and symbol ° denotes cyclic 
convolution. Find the averaged power spectrum of the background compo-
nent in assumption of uniform distribution density of the target coordinate x0:
	
AV
AV
N
x
r
x
x
r
r
r
x
x
r
r
r
0
0
0
0
2
2
2
β
β
β
ω
β
β
ω
bg
tgt
tgt
,
,
(
)
(
)
∗
∗




=
+
−


,
,
x
r
r
r
x
x
N
0
0
(
) +
(
)










∗
(
)
β
β
ω

tgt
	

391
Image Parameter Estimation
	
=
+




−
(
)

+
∗
β
β
ω
β
β
ω
r
r
r
x
x
r
r
r
x
N
2
2
0
0
0
AV
AV
x
x


(
,
)
*(
,
)
tgt
tgt
0
β
β
ω
r
r
r
x
x
N
*
(
,
)
.
 AVx 0
tgt
0
(
)


	
(7A.50)
For AVx
r
x
0
0
(
)
(
,
)
ω tgt
 and AVx
r
x
0
0
(
)
(
,
)
ω∗tgt
, we have
	
AV
AV
i
rx
N
x
r
r
x
x
r
0
0
0
0
2
ω
ω
π
ω
(
)
(
, )
(
exp
tgt,x
tgt
0
(
) =
−







=
tgt
tgt
d
, )
,
exp
exp(
0
0
0
2
2
0
1
2
1
N
i
rx
N
x
N
i
x
x
N
N
r
x
x
x
−




=
−
−
(
)
∫
π
ω
π
π
π
ω
π
π
ω
δ
r
i r
i
r
N
r
r
r
x
r
r
) exp(
)
(
)/
sin(
)
(
, )
(
, )
−
−
=
=
2
0
0
tgt
tgt
( )
	
(7A.51)
	
AV
r
x
r
x
r
0
0
0
ω
ω
δ
∗
∗
(
) =
(
,
)
(
, )
,
tgt
tgt
( ) 	
(7A.52)
where ωr
x
(
,
)
tgt
0  and ωr
∗(
, )
tgt 0  are the DFT spectra of the target window function 
and its complex conjugates in the target position in the origin of coordinate. 
Then
	
β
ω
β ω
δ
β ω
r
x
r
x
r
r r
r
r
o
r
r
r





AV 0
0
0
(
,
)
(
, )
(
, )
(
)
,
tgt
tgt
tgt
(
) =
−
=
−
=0
1
Nx −
∑
	
(7A.53)
	
β
ω
β ω
δ
β ω
r
x
r
x
r
r r
r
r
r
r
*
*(
,
)
*
*(
, )
*
*(
,
(
)




AV 0
0
0
tgt
tgt
tgt
(
) =
−
=
−
o
r
Nx
).
=
−
∑
0
1
	
(7A.54)
For AVx
r
r
x
0
0
2
|
| ,
(
,
)
β
ω

tgt

 we have
	
AV
AV
x
r
r
x
x
r
r r
x
r
N
r
x
0
0
0
0
2
0
1
β
ω
β ω
β ω





(
,
)
(
,
)
*
tgt
tgt

=
−
=
−
∑
≈
r r
x
r
N
r
N
r
r
r r
x
x
−
=
−
=
−
−
≈
≈
≈
≈
∑
∑








=




*(
,
)
*
*(
tgt
t
0
0
1
0
1
β β ω
gt
tgt
, )
(
, )
exp
0
0
0
0
0
2
ω
π
r r
x
x
r
N
AV
i
r
r
N
x
x
−
≈
=
−
−












≈


1
0
1
0
1
0
0
∑
∑∑
=
=
−
=
−
−
−
≈
≈
≈





r
N
r
N
r
r
r r
r r
x
x
β β ω
ω

*
*(
, )
(
, ) (
tgt
tgt
r
r
r
N
r
N
r
r r
x
x
≈
=
−
=
−
−
−
=∑∑
≈
≈



)
(
, )
0
1
0
1
2
0 2
β
ω tgt
	
(7A.55)

392
Theoretical Foundations of Digital Imaging Using MATLAB®
Substitute Equations 7A.51 through 7A.55 into Equation 7A.50 to finally 
obtain
 
AV
N
x
r
x
r
r
r r
r
N
x
r
r
r
x
0
0
2
2
2
0 2
0
1
β
β
β
ω
β β ω
(
,
)
(
, )
*
*
bg
tgt
(
) =
+
−
−
=
−
∑



(
, )
*
(
, )
(
, )
tgt
tgt
tgt
0
0
2
2
0 2
0
1
+
=
+
−
−
=
−
∑
β β ω
β
β
ω
β
r
r
r
x
r
r
r r
r
N
N
x



r
r
r
r
x
r
x
r
N
N
2
0
0
0
2
1
2
1
ω
ω
ω
β
β
(
, )
*(
, )
(
, )
Re
tgt
tgt
tgt
+
(
)
=
−




+

2
0 2
0
1
ωr r
r
Nx
−
=
−
∑


(
, ) .
tgt
	
(7A.56)
Let, for instance, wk
(
, )
tgt 0  is a rectangular window function
	
w
k
K
k
K
K
N
K
k
N
K N
k
N
k
(
, )
,
, ,
,
,
,
,
,
,
,
,
,
tgt 0
1
0 1
0
1
2
1
1
1
=
=
=
+
+
−
−
=
−
−
+
−
…
…
…
1
.



	
(7A.57)
Then
	
ω
π
π
r
x
k
x
k
N
x
N
w
i
kr
N
N
i
kr
x
(
, )
(
, ) exp
exp
tgt
tgt
0
0
0
1
1
2
1
2
=




=
=
−
∑
N
i
kr
N
N
i
x
k
K
x
k N K
N
x
x



+












=
=
=
−
−
∑
∑
0
1
2
1
2
exp
exp
π
π
π
π
π
K
N
r
i
r
N
i
N r
N
i
x
x
x
x
+



−



−
+



−
1
1
2
1
2
2
exp
exp
exp
N
K
N
r
i
r
N
N
i
K
N
x
x
x
x
x
−







−












=
+
exp
exp
2
1
1
2
1
π
π
r
i
K
N r
i
r
N
x
x



−
+
−
−







−











1
1
2
2
1
exp
exp
π
π

	

393
Image Parameter Estimation
	
=
+



−
+
−
−
+




1
2
1 2
1
1
2
1 2
N
i
K
N
r
i
K
N
r
i
r
N
x
x
x
x
exp
exp
exp
π
π
π
/
/



−
−
















=
+




exp
sin
si
i
r
N
N
K
N
r
x
x
x
π
π
1
2
1
n
sincd
;
;
,
π r
N
K
N
K
N
r
x
x
x




=
+
+
(
)
2
1
2
1
	
(7A.58)
where sincd(.;.;.)  is discrete sinc-function defined by Equation 4.54. Substi­
tute Equation 7A.58 into Equation 7A.50 and obtain the following estimate of 
the averaged background image component spectrum:
	
AV
K
N
K
N
r
K
N
x
r
x
x
x
r
x
0
0
2
2
1
2 2
1
2
1
2
1
β
β
(
,
)
(
;
; )
bg
sincd
(
) =
−
+
+




+
+




+
=
−
∑β

r
x
r
N
K
N
r
x
2
0
1
2
1
sincd (
;
;
	
(7A.59)
Equations 7A.56 and 7A.59 can be extended to the 2D case as follows:
AV
N N
x y
r s
x
y
r s
x
y
r s
0 0
0
0
2
0 0
2
1
2
β
ω
β
,
(
,
,
)
,
(
, , )
,
Re
bg
tgt
(
) =
−




+ 1
2
0 0 2
0
1
0
1
Nx
r s
r r s s
s
N
r
N
y
x
β
ω
 




,
,
(
, , )
−
−
=
−
=
−
∑
∑
tgt
	
(7A.60)
AV
K
L
N N
K
x
y
r s
x
y
x
y
0
0
0
0
2
1 2 2
1 2
1
2
1
,
,
,
,
(
)(
)
(
β
bg
sincd
(
)




=
−
+
+
+ ;
; )
,
N
r
K
N
L
N
x
r s
x
y
sincd(2 + 1; 
; )
L
N
s
y




+
+




+


β
2
2
2
1
2
1



×
+
−
+
−
=
2
2
2
2
2
1
2
1
β 



r s
x
y
s
K
N
r
r
L
N
s
s
,
(
;
;
)
(
;
;
) ,
sincd
sincd
0
1
0
1 N
r
N
y
x
−
=
−
∑
∑

	
(7A.61)
where (2K + 1) and (2L + 1) are dimensions of a rectangular target window 
function wk l,
(
, , )
tgt 0 0 .

394
Theoretical Foundations of Digital Imaging Using MATLAB®
Exercises
localization_demo_CRC.m
loclzerr_CRC.m
corr_comparison_CRC.m
lcoptcorr_CRC.m
References
	
1.	 L. P. Yaroslavsky, The theory of optimal methods for localization of objects 
in pictures, In: Progress in Optics, Editor, E. Wolf, Vol. XXXII, Elsevier Science 
Publishers, Amsterdam, 1993.
	
2.	 L. P. Yaroslavsky, Digital Holography and Digital Image Processing: Principles, 
Methods, Algorithms, Kluwer Academic Publishers, Boston, 2004.

395
8
Image Perfecting
This chapter is an introduction to methods for perfecting visual and/or 
metrological image quality. We begin, in the section “Image Perfecting as a 
Processing Task,” with the formulation of the image perfecting task. Then, 
in the sections “Possible Approaches to Restoration of Image Distorted by 
Blur and Contaminated by Noise” and “MMSE-Optimal Linear Filters for 
Image Restoration,” we present possible approaches to correction of image 
blur and cleaning images from additive noise, and introduce MMSE-optimal 
linear filters that perform this processing and are implemented, for the sake 
of simplification of their design and minimization of their computational 
complexity, in a domain of certain orthogonal transform, which features fast 
transform algorithm. In the section “Sliding Window Transform Domain 
Adaptive Image Restoration,” we extend MMSE-optimal linear filters for 
working in sliding window, which makes them local adaptive. In the section 
“Multicomponent Image Restoration and Data Fusion,” we further extend 
these filters to multi­component image restoration and consider the issue of 
fusing image data from different sources. In the section “Filtering Impulse 
Noise,” we discuss nonlinear filtering methods for cleaning impulse noise in 
images. In the section “Correcting Image Grayscale Nonlinear Distortions,” 
methods for correcting image grayscale distortions are addressed, and finally, 
in the section “Nonlinear Filters for Image Perfecting,” we provide a survey 
and classification of nonlinear filters for image denoising and enhancement.
Image Perfecting as a Processing Task
Image perfecting as an image processing task has two stages: image resto-
ration and image enhancement. Image restoration is a processing aimed at 
correcting signal distortions that may occur in imaging systems due to tech-
nical limitations in their design, implementation, and working conditions. 
Typical examples of image distortions are image blur and noisiness. These 
distortions much affect the suitability of images for visual analysis and, as it 
was shown in Chapter 7, determine image potentials for localization and rec-
ognition of objects. Two more examples of image distortions are geometrical 
distortions and point-wise nonlinear grayscale distortions.
The methods for distortion correction are based on the canonical model of 
imaging systems shown in Figure 8.1.

396
Theoretical Foundations of Digital Imaging Using MATLAB®
The model assumes the existence of a “true” image a(x,y), which the sys-
tem would produce if there were no signal distortions in it, and represents 
the system output image b x y
( , )
   as a result of transformations of the “true” 
image by a combination of geometrical transformation, linear transforma-
tions, point-wise nonlinear transformations, and stochastic transformations.
Geometrical transformations are transformations of image coordinates. 
They are specified by relationships ( , )
( , )
x y
x y
    between the initial image 
coordinate system (x,y) and the transformed one ( , )
 
x y .
Linear transformations are specified through the system PSF or frequency 
response (see the section “Signal Transformations” in Chapter 2). Frequency 
response of the ideal imaging system is assumed to be uniform for all fre-
quencies in the image base band defined by the sampling rate. Frequency 
responses of real imaging systems are not uniform. Usually they decay, more 
or less rapidly, on high frequencies, which results in image blur.
Point-wise transformations are specified through the system transfer func-
tion (Equation 2.28). Ideally, the system transfer function is a linear function. 
Deviations of system transfer functions from linear ones cause distortions of 
the gray-level scale (nonlinear distortions).
Stochastic transformations model random interferences, or noise, in 
images. They are specified by statistical noise models such as those described 
in the section “Models of Signal Random Interferences” (Chapter 2).
The goal of image restoration is estimating, with a certain required accu-
racy, the “true” signal a(x,y), given distorted signal b x y
( , )
   produced by the 
imaging system. This problem is frequently referred to as the inverse problem.
If the system does not introduce any random distortions and system’s 
parameters such as PSF and transfer function are known, the inverse prob-
lem has a trivial solution: in order to restore signal a(x,y) from signal b x y
( , ),
 
the latter should be subjected, in the order inverse to that distortion factors 
have in the model, to transformations inverse to those introduced by the 
system. This is what, in practice, people do for correcting geometrical distor-
tions and nonlinear distortions.
However, this does not work well for correcting distortions caused by lin-
ear transformations. Applying inverse transformation for correcting linear 
distortions frequently results in overamplification of random disturbances 
that are unavoidably present in images on the output of imaging systems. 
This frequently makes images “corrected” by the inverse filtering even 
worse for visual perception than noncorrected images; hence, image restora-
tion methods smarter than simple inverse filtering are required.
Geometrical
transformation
Linear
transformation
Point-wise nonlinear
transformation
Stochastic
transformation
a(x, y)
b(x , y)
FIGURE 8.1
A canonical model of imaging systems.

397
Image Perfecting
The goal of image enhancement is producing, out of raw or corrected 
(“restored”) images, enhanced images, which better fit the needs and capa-
bilities of human operators in image analysis and decision making. The 
human visual system has certain limitations in its capability to perceive 
information carried by images. For instance, in grayscale images, the human 
visual system cannot detect gray-level contrasts that are lower than a cer-
tain contrast sensitivity threshold. It is also incapable of apprehending image 
attributes other than variations of its intensity, which might be decisive for 
image analysis. From the other side, human vision perceives colors, has 3D 
capability through stereo vision, and is capable of very efficient detection 
of image variations in time. Therefore, converting images into a form that 
makes use of capabilities of human visual system to perceive information to 
the highest possible degree is required in addition to image restoration.
Possible Approaches to Restoration of Images Distorted 
by Blur and Contaminated by Noise
Let {bk,l}, (k = 0,1,. . .,Nx – 1, l = 0,1,. . .,Ny – 1), be samples of a distorted image, 
which are in a certain way, defined by the imaging system model, deter-
mined by samples {ak,l} of the “true” image to be restored from {bk,l}, and let 
ˆ ,
ak l
{
} be samples of the restored image. Consider an imaging system model 
that describes image blur and contamination by additive signal-independent 
zero mean Gaussian noise. For such a model
	
b
h
a
n
k l
k l
k l
,
,
,
(
)
,
=
+

	
(8.1)
where {nk,l} are samples of noise, (
) ,
h
a k l

 are samples of digital convolution of 
samples {ak,l} of the “true” image with imaging system PSF {hk,l}, which speci-
fies the linear transformation responsible for image blur. Our goal is to find 
an optimal, in a certain sense that we are going to specify, image restoration 
algorithm, that is, mapping {
}
{
}
,
,
bk l
k l
 â
.
An immediate option for solving this problem is to consider the task of 
image restoration as a parameter estimation task, that is, a task of estimat-
ing the set of image samples {ak,l} from the observed set of samples {bk,l} of 
the input image as we did in the sections “Computational Imaging Using 
Optics-Less Lambertian Sensors” in Chapter 5 and “Target Localization in 
Cluttered Images” in Chapter 7. As shown in the section “Statistical Models 
of Signals and Transformations” in Chapter 2, the statistically optimal esti-
mates ˆ ,
ak l
{
} of {ak,l} are ML- and MAP-estimates:
	
ˆ
argmin
(
)
;
,
(
)
,
,
,
a
b
h
a
k l
ML
a
k l
k l
l
N
k
N
k l
y
x
{
}
=
−
[
]
=
−
=
−
∑
∑

2
0
1
0
1
	
(8.2)

398
Theoretical Foundations of Digital Imaging Using MATLAB®
	
ˆ
argmin
(
)
ln ({
,
(
)
,
,
,
a
b
h
a
P a
k l
MAP
a
k l
k l
l
N
n
k l
y
{
}
=
−
[
] −
=
−
∑

2
0
1
2
2σ
k l
k
Nx
, }) ,
=
−
∑






0
1
	
(8.3)
where σn
2 is noise variance and P
ak l
ˆ ,
{
}
(
) is a priori probability of the set ˆ ,
ak l
{
} 
of image samples.
We showed in the section “Computational Imaging Using Optics-Less 
Lambertian Sensors” (Chapter 5) that this approach, in principle, works. The 
main problem with it is the extremely high, even for moderate image sizes 
Nx × Ny, dimensionality of the minimization task, which leads to prohibi-
tively high computational expenses. It is especially true for ML-estimation. 
In MAP-estimation, the volume of the signal space, in which global mini-
mum is searched, can, in principle, be narrowed by a priori probabilities. The 
problem is, however, how one can specify those probabilities. During several 
decades of trying to develop meaningful probabilistic mathematical models 
for images, a number of models have been suggested, beginning from the 
simplest Gaussian random process model, to more sophisticated Gibbs and 
2D Markov random process models, to name a few. Being mathematically 
more elegant than the other, those models, however, failed to produce results 
of practical rather than only of pure academic value.
In order to ease the solution of the problem of narrowing the search 
space, one can replace a priori probability distribution of input images (term 
[
ln ({
})]
,
−2
2
σn
k l
P a
) in Equation 8.3) by another functional ℜ({
})
,
ak l  of images 
that characterizes the “desirability” of the solution ˆ ,
ak l
{
} (the more desirable 
the solution, the smaller ℜ({
})
,
ak l  must be). Considering that mean squared 
deviation of (
) ,
h
a k l

 from {bk,l} in Equation 8.3 normalized by Nx × Ny is, for 
large Nx × Ny, a statistically good estimate for variance σn
2 of additive noise, 
one can reformulate Equation 8.3 in terms of constrained optimization:
ˆ
argmin
({
})
(
)
,
(
)
,
,
,
a
a
N N
b
h
a
k l
Opt
a
k l
x
y
k l
k
k l
{
}
=
ℜ
−
subject to
1

,l
l
N
k
N
n
y
x
[
] =
=
−
=
−
∑
∑
2
0
1
0
1
2
σ
	
(8.4)
or, using Lagrange multiplier λ
	
ˆ
argmin
({
})
(
)
,
(
)
,
,
,
,
a
a
b
h
a
k l
Opt
a
k l
k l
k l
l
N
k l
y
{
}
=
ℜ
+
−
[
]
=
−
∑
λ

2
0
1
k
Nx
=
−
∑






0
1
.
	
(8.5)
This approach to solving inverse problem is called regularization.
A classic example of the regularization functional ℜ({
})
,
ak l  is L2 norm of 
the sought solution:

399
Image Perfecting
	
ℜ
=
=
−
=
−
∑
∑
({
})
,
,
,
a
a
k l
k l
l
N
k
N
y
x
2
0
1
0
1
	
(8.6)
which links the desirability of the solution to its variance. This prior is known 
to be related to the so-called Tikhonov regularization and to Wiener filtering. We 
will detail the Wiener filtering approach in the next section.
L2 norm forces the solution to not deviate much from its mean value by 
means of punishing its deviations from the mean, large deviations being 
punished substantially stronger than small ones. This does enable noise 
reduction and produces “smooth” image estimates but at the expense of sub-
stantial loss of image sharpness, which, as we saw in Chapter 7, is of crucial 
importance for image analysis.
As a better measure of image “goodness,” L2 norm the image Laplacian 
was suggested:
	
ℜ
=
=
−
=
−
∑
∑
({
})
{
}
,
,
a
Laplacian a
k l
k l
l
N
k
N
y
x
2
0
1
0
1
	
(8.7)
(for the definition of Laplacian operator and its usefulness, see the section 
“Object Localization and Edge Detection: Selection of Reference Objects for 
Target Tracking” (Chapter 7)). The rationale behind this measure is the fact 
that most of the image energy is contained in a low-frequency component 
of image spectra, whereas most of the white noise energy is contained in its 
high-frequency components, hence the higher differential measure, such as 
Laplacian, that is, image second spatial derivative, the more probable it is due 
to the noise. However, punishing large values of image Laplacian also con-
tradicts with desirable properties of images: as we saw in the section “Object 
Localization and Edge Detection: Selection of Reference Objects for Target 
Tracking” (Chapter 7), the energy of object Laplacian is a good measure of 
their potential detectability in a clutter of other objects.
In order to soften the punishment, the L1 norm can be used instead of the 
L2 norm. An example of such a softened differential measure is using image 
total variation as a regularizing functional:
	
ℜ
=
=
−
=
−
∑
∑
({
})
{
},
,
,
a
Gradient a
k l
k l
l
N
k
N
y
x
0
1
0
1
	
(8.8)
where the Gradient operator computes sums of absolute values of image spa-
tial derivatives.
Considerable progress in the search of an appropriate regularizing func-
tional was achieved recently, when it was suggested to formulate functional 

400
Theoretical Foundations of Digital Imaging Using MATLAB®
ℜ({
})
,
ak l  in terms of sparsity of transform coefficients of the solution, or, in 
other words, to search solutions among band-limited, in a certain transform, 
approximations to {ak,l}. This approach was inspired by advances in trans-
form image compression methods, such as JPEG or wavelet image coding 
(see the section “Basics of Image Data Compression” in Chapter 3). The mea-
sure of transform coefficient sparsity is their L0 norm:
	
ℜ
=
=
−
=
−
∑
∑
({
})
{
}
,
,
,
,
a
T a
k l
k l
r s
s
N
r
N
y
x
0
0
1
0
1
	
(8.9)
which computes the number of transform T{.} nonzero coefficients. It turned 
out, however, that such a norm is not well suited for numerical optimization 
algorithms and can be replaced by the L1 norm:
	
ℜ
=
=
−
=
−
∑
∑
({
})
{
}
.
,
,
,
a
T a
k l
k l
r s
s
N
r
N
y
x
0
1
0
1
	
(8.10)
This transform domain “sparsity” approach is being actively pursued at 
present, and interested readers are referred to numerous publications under 
key words “compressive sensing” and “sparse representations.” Being, 
however, still based on numerical optimization, this approach does solve 
the problem of the computational complexity of the optimization. Aside 
from that, it shares the important drawback common to all the above-listed 
approaches: all of them disregard image spatial inhomogeneity. We already 
demonstrated the importance of taking image spatial inhomogeneity into 
account in the section “Local Adaptive SCR-Optimal Correlators” (Chapter 
7), where we introduced local adaptive SCR-optimal correlators for target 
location. Later in this chapter, we introduce local adaptive filtering methods 
that explicitly account for image spatial inhomogeneity.
A constructive and computationally efficient alternative to the above-out-
lined parameter estimation approach is a “waveform estimation” approach 
that can be traced back to classical works by the fathers of information theory 
N. Wiener [1], A. Kolmogorov [2], C. E. Shannon [3], and V. A. Kotelnikov [4]. 
In this approach, the inaccuracy of restoration of signals is evaluated by L2 
norm of the restoration error, that is, by the mean-squared difference between 
the “true” and restored signals, and restoration is supposed to be performed 
by linear filtering of the distorted signals, which is designed to minimize this 
mean-squared restoration error. We will refer to this approach as minimum 
mean squared error (MMSE) approach. Linear filtering that minimizes MSE res-
toration error is also called Wiener filtering. In terms of the general parameter 
estimation approach, the MMSE approach is aimed at minimization of the 
second moment of the a posteriori probability of the estimate.

401
Image Perfecting
MMSE approach-based linear filtering is motivated by the following reason-
ing. In the absence of noise, linear distortions introduced by linear filtering of 
image signal in imaging systems can, in principle, be corrected by the inverse 
linear filtering. One can expect that, in the presence of small noise, linear fil-
tering will still be sufficient, except that a certain “small” modification of the 
inverse filter will be required to keep the restoration inaccuracy small.
In what follows, we outline the MMSE approach in detail, discuss its poten-
tials and limitations, and demonstrate that its application in sliding win-
dow, similar to that described in the section “Local Adaptive SCR-Optimal 
Correlators” (Chapter 7), is a promising solution of the problem of restoration 
of noisy, and blurred images both in terms of restoration accuracy and in 
terms of computational efficiency.
MMSE-Optimal Linear Filters for Image Restoration
Transform Domain MSE-Optimal Scalar Filters
Consider designing a linear filter that generates, from a copy {bk,l} of a “true” 
signal {ak,l} distorted in the imaging system by linear filtering and by additive 
noise, its estimate ˆ ,
ak l
{
} with minimal mean squared error:
	
ˆ
argmin
ˆ
R{
}
ˆ
,
,
a
a
a
k
b
a
k l
k l
l
N
k
N
k
k
y
x
{ } =
−
={ }
=
−
=
−
∑
∑
AV
AV
A
N
Ω
Ω
2
0
1
0
1











	
(8.11)
evaluated on average (averaging operators AV
A
Ω and AV
N
Ω) over image ΩA 
and noise ΩN ensembles.
In order to simplify further formula derivations, we will use 1D notation 
unless otherwise indicated.
In general, linear filtering of a discrete signal can be conveniently described 
as multiplication of a vector of input signal samples B = {bk} by a filter matrix 
H (see Chapter 4, Equation 4.8):
	
ˆ
,
A
H B
=
⋅
	
(8.12)
where ˆ
ˆ
A = { }
ak  is a vector of filter output signal samples. For signals of N 
samples, a general filter matrix H has dimensions N × N. The specification of 
such a filter requires determining N2 filter coefficients, and the filtering itself 
requires performing N operations per signal sample. In image processing, 
the computational complexity of both determination of filter coefficients and 
the filtering might become too high because of high dimensionality of image 
arrays. Fast transform algorithms, with which transform coefficients can be 

402
Theoretical Foundations of Digital Imaging Using MATLAB®
computed for O(N log N) operations, allow to dramatically ease the filter 
design, and decrease its computational complexity. This motivates consider-
ing only “scalar” filtering, specified by diagonal matrices, assuming that it is 
implemented in a domain of orthogonal transforms that can be computed 
with fast algorithms. Scalar filtering is described by the equation
	
ˆ
,
A
T
H
T B
d
=
⋅
⋅
⋅
−1
	
(8.13)
where T and T−1 are, respectively, direct and inverse orthogonal transforms, 
and H = diag{ηr}, (r = 0,1,. . .,N − 1) is a diagonal filter matrix. Such a scalar 
filtering implies the following relationship between transform coefficients 
ˆ
ˆ
αr
{
} =
⋅
T A and {βr} = T ⋅ B of filter output and input signal samples:
	
ˆ
.
α
η β
r
r
r
=
	
(8.14)
In the assumption of orthogonality of the transform T, one can, by virtue 
of Parseval’s relationship (Equation 2.20), reformulate the filter optimality 
condition defined by Equation 8.20 in terms of signal transform coefficients:
	
ˆ
argmin
ˆ
arg
{
}
α
α
α
η
r
r
r
r
N
r
{
} =
−












=
=
−
∑
AV
AV
A
N
Ω
Ω
2
0
1
min
.
{
}
η
α
η β
r
r
r
r
r
N
AV
AV
A
N
Ω
Ω
−












=
−
∑
2
0
1
	
(8.15)
Through computing derivatives over the sought variables and equaling 
them to zero, one can obtain from Equation 8.15 (see Appendix) that MSE-
optimal scalar filter coefficients {ηr} are normalized cross-correlation coef-
ficients between spectral coefficients βr and αr of the filter input and “true” 
signals:
	
η
α β
β
r
opt
r
r
r
(
)
.
=
(
)
(
)
∗
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
2
	
(8.16)
Equation 8.16 implies that, in order to implement the optimal scalar Wiener 
filter, one should know cross-correlation AV
AV
A
N
Ω
Ω
α β
r
r
∗
(
)
{
} between spec-
tral coefficients of filter input signal and “true” signal and power spectrum 
AV
AV
A
N
Ω
Ω
βr
2
(
)
{
} of the input signal in the selected transform domain. We 
will refer to filters defined by Equation 8.16 as scalar Wiener filters.

403
Image Perfecting
Empirical Wiener Filters for Image Denoising
Consider the additive signal-independent noise model (Section “Models 
of Signal Random Interferences” in Chapter 2), in which filter input signal 
samples {bk} are a sum of “true” signal samples {ak} and samples {nk} of signal-
independent zero mean random noise:
	
b
a
n
k
k
k
=
+
.	
(8.17)
In the spectral domain of the transform Τ, the same relationship holds for 
signal and noise spectral coefficients {βr}, {αr}, and {νr}:
	
β
α
ν
r
r
r
=
+
.	
(8.18)
For this model, one can obtain that
	
AV
AV
AV
AV
AV
A
N
N
A
Ω
Ω
Ω
Ω
Ω
α β
α
α
ν
α
r
r
r
r
r
r
A
∗
∗
∗
(
) =
+
(
)

=
(
)
2
	
(8.19)
and
	
AV
AV
AV
AV
AV
A
N
A
Ω
Ω
Ω
Ω
Ω
Ω
A
N
A
r
r
r
r
r
r
A
β
α
ν
α
ν
α
ν
2
2
(
) =
+
+
(
)


=
(
) +
∗
∗
(
)
V
r
2
(
)
	
(8.20)
because for zero mean noise AV
AV
N
N
Ω
Ω
(
)
(
)
ν
ν
r
r
∗=
= 0 . Therefore, coeffi-
cients ηr
WF
(
)
{
} of scalar Wiener filter for suppressing additive signal-indepen-
dent noise are defined as
	
η
α
α
ν
r
WF
r
r
r
r
r
SNR
SNR
(
) =
(
)
(
) +
(
)
=
+
AV
AV
AV
A
A
N
Ω
Ω
Ω
2
2
2
1
	
(8.21)
or, in 2D notations, as
	
η
α
α
ν
r
WF
r s
r s
r s
r s
r s
SNR
SNR
(
)
,
,
,
,
,
,
=
(
)
(
) +
(
)
=
+
AV
AV
AV
A
A
N
Ω
Ω
Ω
2
2
2
1
	
(8.22)
where
	
SNRr s
r s
r s
,
,
,
=
(
)
(
)
AV
AV
A
N
Ω
Ω
α
ν
2
2
	
(8.23)

404
Theoretical Foundations of Digital Imaging Using MATLAB®
is SNR on the (r,s)-th image spectral component. Thus, scalar Wiener filter 
weight coefficients are defined, for each image spectral coefficient, by the 
SNRr,s for this coefficient. The lower the SNR for a particular signal spectral 
component, the lower will be the contribution of this component to the filter 
output signal.
Equation 8.22 can be given yet another interpretation that links Wiener 
filtering with SCR-optimal filtering for target location that we discussed in 
Chapter 7. Suppose that the image contains a single object with spectrum 
{αr}. For such an object, Equation 8.22 for scalar Wiener filter takes the form
	
η
α
α
ν
α
α
α
ν
r
WF
r s
r s
r s
r s
r s
r s
r
(
)
,
,
,
,
,
,
,
=
(
)
(
) +
(
)
=
(
) +
∗
2
2
2
2
AV
AV
N
N
Ω
Ω
s
2
(
)
.
	
(8.24)
Equation 8.24 represents this filter as consisting of two filters in a cascade. 
The first filter
	
α
α
ν
r s
r s
r s
,
,
,
∗
(
) +
(
)






2
2
AV
N
Ω
	
is similar to target location filters considered in Chapter 7. It produces at its 
output a peak at the location of the object. If this peak were a delta-function, 
it would draw, after applying to it the second filter {αr,s}, the object in the 
detected location, as if the filter recognizes the object. Because the peak is 
not a delta-function, Wiener filter draws at the object location the object in a 
certain way blurred by the peak.
In order to implement the scalar Wiener filter, one has to know power spec-
tra AV
A
Ω
αr s,
2
(
) and AV
N
Ω
νr s,
2
(
) of the “true” image and of noise in the 
selected transform domain. Noise power spectrum AV
N
Ω
νr s,
2
(
) might be 
known from the specification certificate of the imaging device. Otherwise, it 
can be measured empirically directly in noisy input images using methods 
described in Appendix. Denote noise power spectrum estimate by νr s,
2 .
As for the “true” image power spectrum AV
A
Ω
αr s,
2
(
), it is almost never 
known. However, one can attempt to estimate it using Equation 8.20 and 
an estimate βr s,
2  of the power spectrum AV
AV
A
N
Ω
Ω
βr s,
2
(
) of the input noisy 
image, which can be obtained by means of one or another method of aver-
aging of the image spectrum βr s,
2 (for instance, as we will see later in an 
illustrative example of Figure 8.2, 1D row-wise image power spectrum can 
be estimated by means of averaging of power spectra of image rows). With 

405
Image Perfecting
Estimate of the true image spectrum
18
16
14
12
10
8
6
50
100
Frequency index
(c)
(d)
(b)
(a)
150
200
25
Initial image spectrum
FIGURE 8.2
Filtering moiré interferences in an image: (a) input image; (b) plots of averaged DFT power 
spectra of the input image rows (solid line) and of an estimate of true image spectrum (dotted 
line) used for detecting moire noise spectral components; (c) output image cleaned from moire 
noise by means of rejecting filtering; (d) difference between input and output: eliminated noise 
pattern.

406
Theoretical Foundations of Digital Imaging Using MATLAB®
such empirical estimates βr s,
2  and νr s,
2 , an estimate αr s,
2  of the true image 
power spectrum AV
A
Ω
αr s,
2
(
) can be obtained as
	
α
β
ν
r s
r s
r s
,
,
,
.
2
2
2
=
−
	
(8.25)
Because empirical estimates of image and noise spectra may deviate from 
accurate statistical ones, for which AN infinitely large number of noise real-
izations are required, Equation 8.25 might give negative values for some 
estimates of αr s,
2 , which contradicts the property of power spectra to be 
nonnegative. In order to prevent this, the following modified spectrum esti-
mation can be used:
	
α
β
ν
r s
r s
r s
,
,
,
max
;
.
2
2
2
0
=
−



	
(8.26)
With these estimates for image and noise power spectra, we arrive at the 
following empirical substitute for the scalar Wiener filter:
	
η
β
ν
β
r s
EWF
r s
r s
r s
,
(
)
,
,
,
max
;
.
=
−








2
2
2
0
	
(8.27)
We will refer to this filter as the empirical Wiener filter.
If the imaging system noise is known to be uncorrelated with variance σn
2, 
the empirical Wiener filter takes the form
	
η
β
σ
β
r s
EWF
r s
n
r s
,
(
)
,
,
max
;
.
=
−








2
2
2
0
	
(8.28)
As one can see from Equations 8.27 and 8.28, the weight coefficients of sca-
lar Wiener filters assume values in the range between zero and one. A ver-
sion of the empirical Wiener filter of Equation 8.28 with binary coefficients
	
η
β
r s
rjct
r s
Thr
,
(
)
,
,
,
,
=
≥



1
0
2
if
otherwise
	
(8.29)
where Thr is a rejecting threshold called the rejecting filter. As it follows from 
Equation 8.28, the rejecting threshold Thr has a value of the order of mag-
nitude of the noise variance σn
2. Rejecting filters eliminate from the input 

407
Image Perfecting
images spectra all components whose intensity is lower than the rejecting 
threshold Thr ≅σn
2; all other image spectral components are preserved by 
rejecting filters. Therefore, rejecting filters replace signals with their band-
limited approximations and, by virtue of the Parseval’s relationship for 
orthonormal transforms, they are exact solutions of the optimization equa-
tion (8.4), in which transform coefficient sparsity defined by Equation 8.9 is 
used as a regularization functional ℜ({
})
,
ak l . In image processing applica-
tions, this feature might be an advantage of rejecting filters before empirical 
Wiener filters that minimize restoration MSE by the expense of distorting 
all image components, distortions being heavier the lower the SNR for those 
components.
From Equation 8.27, it follows that, having used for the filter design esti-
mates of true signal power spectrum given by Equation 8.26, empirical Wiener 
filters produce signals with power spectrum [(| |) | | /(| |)
]
;
α
β
β
r
r
r
2 2
2
2 2
0 , 
which deviates from those estimates. Using image power spectrum preser-
vation as a criterion for signal restoration (instead of MMSE-criterion), one 
can arrive at scalar filters with coefficients
	
η
β
σ
β
r s
SPF
r s
n
r s
,
(
)
,
,
max
;
.
=
−








2
2
2
1 2
0
	
(8.30)
We call them spectrum preservation filters. Modifications of input image 
spectra carried out by rejecting and spectrum preservation filters are some-
times called hard thresholding and soft thresholding, respectively.
The described filters proved to be very efficient in image denoising if 
signal and/or noise spectra are well separated in the transform domain. A 
typical example of such a situation is filtering of narrow band noise, whose 
spectrum has only a few components in the transform domain. Figures 8.2 
through 8.4 provide examples of filtering such a narrow band noise.
Figure 8.2 demonstrates filtering “moiré” noise patterns in an image. Such 
interferences frequently appear, in particular, in images digitized by optical 
scanners. The image in Figure 8.2a is an example of an image contaminated 
with “moiré” noise, and the plot in Figure 8.2b (solid line) shows an averaged 
DFT power spectrum of input image rows. One can clearly see anomalous 
peaks of the noise spectrum in the input image power spectrum. These peaks 
can be quite easily detected in the averaged power spectrum, for example, 
by means of checking local violations of spectrum monotonic decay with 
higher frequencies, as it is implemented in the program demoire1_CRC.m 
(see Exercises) used to generate this figure. Obtained in this way, the loca-
tions of detected peaks are used for zeroing values of the spectral coefficients 
in those points. The obtained rejecting filter applied row-wise to spectra of 
noisy image rows generates output-filtered image shown in Figure 8.2c. The 
difference between input and output images shown in Figure 8.2d presents 

408
Theoretical Foundations of Digital Imaging Using MATLAB®
the noise component eliminated in the output image. Note that this type of 
interference can also be successfully filtered out in DCT and Walsh trans-
form domains as well.
Figure 8.3 illustrates prefiltering of the off-axis hologram of Figure 5.18a. 
The DFT spectrum of the hologram (Figure 8.3b) indicates that the hologram 
contains a periodical noise component, which exhibits itself in horizontal 
and vertical stripes, and an intensive parasitic zero-order diffraction compo-
nent (bright central spot in the spectrum). The periodical noise can be attrib-
uted to imperfect analog-to-digital conversion in the digital camera used 
for hologram recording; dc and parasitic low-frequency components result 
from recording intensities of object and reference beams (last two terms in 
Equation 5.1). Both periodical and zero-order diffraction terms, which impair 
image reconstructed from the hologram, as one can see in Figure 8.3e, can 
be substantially weakened by rejecting filtering the hologram by a filter with 
frequency response shown in Figure 8.3c. As a result, a noticeable improve-
ment of quality of the reconstructed image shown in Figure 8.3f is achieved.
Figure 8.4 illustrates a cleaning image from banding noise. This type of 
noise is a frequent distortion in imaging systems that use mechanical scan-
ning for generating images. Banding noise exhibits itself in chaotic behav-
ior of mean values of image signal in the direction of scan, that is, in the 
direction of image rows. Figure 8.4a shows an example of an image distorted 
by banging noise. Row-wise image mean values shown as a function of the 
row number in Figure 8.4b are image Radon transform coefficients in this 
direction. Normally, row-wise mean values are quite smooth functions of 
the row index. One can estimate the smooth component of this function, that 
is, “true” values of Radon transform spectral coefficients, by means of one 
or another smoothing operation, for instance, by means of computing spec-
trum local mean or local median in sliding window (for details of local mean 
and local median, see the section “Filter Classification Tables and Particular 
Examples”). A result of such a smoothing is shown by a bold line in Figure 
8.4b. The difference between the initial and smoothed curves shown in 
Figure 8.4d gives estimates of banding noise interferences for each image 
row. Subtracting these differences from all pixels in the corresponding row 
eliminates the noise as one can see in Figure 8.4c.
In terms of the discussed filters, this can be treated as image Radon spec-
trum preservation filtering. Program filtering_stripes_CRC.m provided in 
Exercises implements the described filtering.
The denoising capability of Wiener filtering of uncorrelated (white) noise is 
much lower. When filtering white noise, Wiener filter tends to weaken low-
energy image spectral components. In the case of filtering in DFT or in DCT 
domains, these are usually image high-frequency coefficients, which are, 
as we saw in section “Object Localization and Edge Detection: Selection of 
Reference Objects for Target Tracking” (Chapter 7), very important for object 
detection and recognition. In addition, Wiener filtering converts input white 
noise into a residual output correlated noise although with a lower variance. 

409
Image Perfecting
FIGURE 8.3
​Cleaning periodic interferences and zero-order diffraction in Fresnel holograms before their 
numerical reconstruction: (a) a digitized hologram; (b) DFT spectrum of the hologram centered 
at x–y zero frequencies and enhanced for display purposes; spectrum reveals the presence of 
quasiperiodic interferences (horizontal and vertical stripes) and substantial zero-order diffrac-
tion term (bright spot at zero frequencies); (c) pattern of 2D rejecting filter discrete frequency 
response coefficients (black for 1 and white for 0) used for hologram prefiltering; (d) differ-
ence between initial hologram and filtered one demonstrating noise pattern removed by the 
filtering (image is enhanced for display purposes); (e) image reconstructed from the initial 
hologram; (f) image reconstructed from the filtered hologram, which shows removal of inter-
ferences and zero-order diffraction term seen in figure (e).

410
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.4
Filtering banding noise: (a) initial noisy image; (b) plots of row-wise image mean values (solid 
line) and of a result of their smoothing by local averaging in sliding window (bold line); (c) fil-
tered image cleaned from noise; (d) removed noise component (enhanced for display purposes).

411
Image Perfecting
It is well known that human vision is much more sensitive to correlated noise 
than to white noise of the same intensity. Therefore, Wiener filtering for image 
denoising may even worsen image visual quality rather than improving it.
A good method for evaluating image restoration capability of filtering 
is its computer simulation. In the simulation, one can implement the ideal 
Wiener filter because both signal and noise spectra are known. In this way, 
one can determine potentials of the Wiener filtering and its real capability in 
its implementation as an empirical Wiener filter.
Figures 8.5 through 8.7 show the results of computer simulation of Wiener 
filtering of two test images with additive white noise using the program 
WienerFilter_CRC.m for two noise levels (PSNR = 3 and PSNR = 2), respec-
tively. The empirical Wiener filter was implemented in this example according 
to Equation 8.27. As one can see from the figures, ideal Wiener filtering does 
improve image quality, when noise level is not too high. For the empirical 
Wiener filter, improvement is much less appreciable. In particular, the empiri-
cal Wiener filter is incapable of restoring the readability of text for PSNR = 2 
(noise standard deviation is 128 in the range 0–255). The difference images 
between initial noisy images and the results of the Wiener filtering (restora-
tion error) clearly reveals that the filtering tends to destroy image edges.
As we have seen, the noise-suppressing capability of scalar empirical 
Wiener filters depends on appropriate selection of transform domain, where 
image and noise spectra would be separated to the highest possible degree. 
For highly correlated noise, a transform in which noise spectrum is concen-
trated in a few components should be selected. For uncorrelated (white) noise, 
this separation is much less possible as the spectrum of uncorrelated noise 
in any transform remains to be uniform, and certain separation signal and 
noise are only possible due to the energy compaction property of the trans-
form with respect to image signals. As we mentioned, DCT transform is one 
of the most promising in this respect. Another option is using wavelet trans-
forms, some of which also exhibit good energy compaction property. A ver-
sion of the rejecting and spectrum preservation filters that are implemented 
with wavelet transform image decomposition is known as wavelet shrinkage 
filtering by hard and soft thresholding, respectively. Figure 8.8 shows a flow 
diagram of signal denoising by means of the wavelet shrinkage.
Empirical Wiener Filters for Image Deblurring
Consider now an imaging system model in which the following relationship 
holds for transform domain spectra {βr,s}, {αr,s}, and {νr,s} of input signal, ideal 
signal, and noise:
	
β
λ
α
ν
r s
r s
r s
r s
,
,
,
, ,
=
+
	
(8.31)
where {λr} is a set of coefficients that specify the imaging systems in the trans-
form domain. For DFT, coefficients {λr} are samples of the imaging system 

412
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.5
​Denoising of a test image (a) with PSNR = 3 (noise standard deviation 84.7 in the range 0–255) 
by the ideal (b) and empirical (d) Wiener filters; (c) and (e) are corresponding restoration errors.

413
Image Perfecting
FIGURE 8.6
​Denoising of a test image (a) with PSNR = 2 (noise standard deviation 128 in the range 0–255) 
by the ideal (b) and empirical (d) Wiener filters; (c) and (e) are corresponding restoration errors.

414
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.7
Denoising of a test noisy image (b) with PSNR = 3 (noise standard deviation 84.7 in the range 
0–255) by the ideal (c) and empirical (e) Wiener filters. Noiseless image is shown for comparison 
in (a); (d) and (f) are corresponding restoration errors.

415
Image Perfecting
frequency response. In ideal imaging systems, they should all be equal 
to unity. In reality, they usually decay with the frequency index r, which 
results, in particular, in image blur. Processing aimed at correcting this type 
of distortion is frequently referred to as image deblurring.
For this model, terms involved in the general Equation 8.16 for MMSE-
optimal scalar Wiener filters are
	
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
α β
α
λ α
ν
λ
r s
r s
r s
r s
r s
r s
r
,
,
,
,
,
,
,
∗
∗
∗
∗
(
) =
+
(
)

=
s
r s
∗
(
)
AV
A
Ω
α ,
2
	
(8.32)
and
	
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
β
λ α
ν
λ α
ν
r s
r s
r s
r s
r s
r s
r s
,
,
,
,
,
,
,
2
(
) =
+
(
)
+
(
)

∗
∗
∗


=
(
) +
(
)
λ
α
ν
r s
r s
r s
,
,
,
2
2
2
AV
AV
A
A
Ω
Ω
	
(8.33)
because for zero mean noise, AV
AV
N
N
Ω
Ω
(
)
(
)
ν
ν
r
r
∗=
= 0. Therefore, coef-
ficients ηr
WF
(
)
{
} of scalar Wiener filter for restoration of blurred and noisy 
image are defined as
Input
Soft/hard
thresholding
Soft/hard
thresholding
Output
Interpolation
Interpolation
Interpolation
Interpolation
Interpolation
+
+
+
+
+
+
–
–
+
+
Low-pass
filtering and
downsampling
Low-pass
filtering and
downsampling
Low-pass
filtering and
downsampling
FIGURE 8.8
Wavelet shrinkage: signal denoising in wavelet transform domain. Units “soft/hard” thresh-
olding implement signal spectrum preservation and rejecting filters of Equations 8.30 and 8.29, 
respectively.

416
Theoretical Foundations of Digital Imaging Using MATLAB®
	
η
λ
α
λ
α
ν
λ
r
WF
r s
r
r s
r
r
r s
r s
SNR
(
)
,
,
,
,
=
(
)
(
) +
(
)
=
∗AV
AV
AV
A
A
N
Ω
Ω
Ω
2
2
2
2
1
1 + SNRr s,
,
	
(8.34)
where SNR is the signal-to-noise ratio at the output of the linear filter unit of 
the imaging system model:
	
SNRr s
r s
r s
r s
,
,
,
,
.
=
(
)
(
)
λ
α
ν
2
2
2
AV
AV
A
N
Ω
Ω
	
(8.35)
Correspondingly, the general deblurring empirical Wiener filter, deblur-
ring empirical Wiener filter, and the rejecting filter for the case of white noise 
will be defined as follows:
	
η
λ
β
ν
β
r
r s
r s
r s
r s
=
−
(
)










max
;
,
,
,
,
,
1
0
2
2
2
AV
A
Ω
	
(8.36)
	
η
λ
β
σ
β
r
r s
r s
n
r s
=
−








max
;
,
,
,
,
1
0
2
2
2
	
(8.37)
and
	
η
λ
β
r
r s
r s
Thr
=
≥



1
0
2
,
,
,
,
.
if
otherwise
	
(8.38)
All these filters can be treated as two filters in a cascade: the filter with 
coefficients
	
η
λ
r
inv
r
= 1
	
(8.39)
called the inverse filter and signal denoising filters described by Equations 
8.27 through 8.29. Inverse filter compensates for the distortions of signal 
frequency components in the imaging system while the denoising filter 
prevents from excessive amplification of noise and performs a sort of regular-
ization of the inverse filter.

417
Image Perfecting
Figure 8.9a–h illustrates the image deblurring capability of the described 
scalar Wiener restoration filters.
The figure shows blurred test images with different noise levels (noise stan-
dard deviations 6.4, 25.6, and 85.3 in units of image grayscale range 0–255) 
and results of their deblurring using ideal Wiener filters, which characterize 
potentials of Wiener filtering, and empirical Wiener filters, which demonstrate 
the real deblurring capability of Wiener filtering. One can see from the figures 
that when the noise level in blurred images is relatively small, Wiener filters 
are capable of restoring text readability, and when the noise level increases, the 
deblurring capability of Wiener filtering deteriorates down to full incapability.
One of the most immediate applications of Wiener filtering is correcting 
distortions caused by the finite size of apertures of image sensors, image 
sampling devices, and image displays. We will refer to this processing as 
aperture correction.
Let an image sensor and sampling device be an array of light-sensitive 
elements with a square aperture of size dx = dy = d(s) (Figure 3.3) arranged 
over a square sampling grid with sampling interval Δx. Then, the frequency 
response of the individual sensor elements is
	
H f
f
i
f x
x
i
f y
x
x
y
x
d
d
y
d
d
s
s
s
(
,
)
exp(
)
exp(
)
( )
( )
( )
(
/
/
/
=
−
−
∫
2
2
2
2
2
π
π
d
d
s
f d
f d
f d
f d
f
x
s
x
s
y
s
y
s
x
)/
( )
( )
( )
( )
sin(
/ )
/
sin(
)
sinc(
2
2
2
∫
=
=
π
π
π
π
π dd
f d
s
x
s
( )
( )
)sinc(
)
π
	
(8.40)
or
	
H f
f
f
xd
f
xd
x
y
x
s
x
s
(
,
)
sinc
sinc
,
( )
( )
=
(
)
(
)
π
π
∆
∆
	
(8.41)
where d
d
x
s
s
( )
( )/
=
∆ is the sensor’s fill factor. The discrete frequency response 
{λr,s} of the sensor can be obtained as samples of H(fx, fy) taken in frequency-
domain sampling points {fx = rΔf, fy = sΔf} with sampling interval Δf:
	
λ
λ λ
π
π
r s
r
s
s
s
d
r N
d
s N
,
( )
( )
sinc
/
sinc
/
,
=
=
(
) ⋅
(
) 	
(8.42)
where N = 1/ΔxΔf is the number of samples in both coordinates (assuming 
the cardinal sampling).
If the image display device also has a square aperture of size d(r) × d(r), the 
entire imaging system discrete frequency response is
	 λ
λ λ
π
π
π
r s
r
s
s
x
r
x
s
y
d
r
N
d
r
N
d
s
N
,
( )
( )
( )
sinc
/
sinc
/
sinc
/
si
=
=
(
)⋅
(
)
(
) nc
/
.
( )
πd
s
N
r
y
(
) 	
(8.43)

418
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.9
Image deblurring using scalar Wiener filtering for different noise levels: (a), (d), (g) blurred 
images with additive white noise of standard deviation 6.4, 25.6, and 85.3, respectively (in units 
of image gray level range 0–255); (b), (e), (h) images restored by ideal Wiener filters; and (c), (f), 
(i) corresponding images restored by empirical Wiener filters.

419
Image Perfecting
Parameters d s( ), d(r), and Δx are imaging system design parameters that are 
usually specified in imaging system certificates. They can be used for aper-
ture correction images in the computer before their display.
Figure 8.10 illustrates such an image aperture correction of a test air 
photograph. The middle image in this figure is obtained by applying to 
the left image an inverse filter for the system’s frequency response defined 
by Equation 8.42 with d
d
s
r
( )
( )
=
= 1 and the right image shows the correc-
tion term: the difference between initial and aperture-corrected images. 
The images were generated using the program invapert_CRC.m provided 
in Exercises.
FIGURE 8.9
Continued.

420
Theoretical Foundations of Digital Imaging Using MATLAB®
Sliding Window Transform Domain Adaptive Image 
Restoration
Local Adaptive Filtering
For implementing image restoration using Wiener filtering, one should 
select a fashion in which images are to be processed. Given an image to be 
processed, filtering can be designed and carried out either over the entire 
available image frame or fragment-wise. We will refer to the former as global 
filtering and to the latter as local filtering.
The applicability of global and local filtering depends on whether images 
belong to classes of spatial homogeneous or spatial inhomogeneous 
images, which we mentioned in the section “Local Adaptive SCR-Optimal 
Correlators.” As far as the design of empirical Wiener filters is concerned, 
spatial inhomogeneity of images in terms of their spectra is the issue. In the 
spatial homogeneous image, the local spectra do not vary substantially; oth-
erwise, images are inhomogeneous. Figure 8.11 illustrates this, in addition to 
Figure 7.13.
Global filtering is suited for spatial homogeneous images. For spatial inho-
mogeneous filtering, local filtering is required.
The importance of local processing is also confirmed by the evolution 
of vision, which has resulted in an image analysis mechanism that works 
locally with relatively small fragments of the field of view. Human visual 
acuity is very uneven over the field of view. The field of view of the human 
vision is about 30°. The maximal resolving power of the vision is about one 
angular minute. However, such a relatively high resolving power is concen-
trated only within a small fraction of the field of view that has an angular 
size of about 2°. When viewing the image, the eye optical axis permanently 
jumps, apparently under the control of peripheral vision, over the field of 
view, which directs the high-resolution part of its light-sensitive retina called 
fovea to different places in the scene. Therefore, the brain analyzes visual 
scenes locally within the area of acute vision, which is about 1/15 the field of 
FIGURE 8.10
​Initial (left), aperture corrected (middle) images, and their difference (right).

421
Image Perfecting
view (for images of 512 × 512 pixels, this means a window of roughly 33 × 33 
pixels).
The theoretical framework for local filtering is provided by the local crite-
ria of processing quality that evaluate the processing quality individually 
over image fragments centered at each pixel. In particular, for optimal local 
MMSE scalar filters acting in a rectangular window centered at pixel {k,l}, 
filter coefficients ηr
k l
( , )
{
} are, according to the local criteria, defined by the fol-
lowing modification of Equation 8.15:
	
ˆ
argmin
( )
{
}
,
( , )
,
( , )
,
( , )
,
α
α
η
β
η
r
k
r s
k l
r s
k l
r s
k l
s
r s
=
−
=
AV
AV
A
N
Ω
Ω
2
0
1
0
1W
r
W
y
x
−
=
−
∑
∑












,
	
(8.44)
where Wx and Wy are dimensions of the area, over which filtering performance 
is evaluated, and, respectively, of the filter window, βr s
k l
,
( , )
{
} are spectral coeffi-
cients of the input image samples within the window, and αr s
k l
,
( , )
{
} are spectral 
coefficients of filter window samples of a hypothetical true image. Solutions 
obtained in the sections “Empirical Wiener Filters for Image Denoising” and 
“Empirical Wiener Filters for Image Deblurring” for empirical Wiener filters 
for image restoration can be straightforwardly extended to local filtering by 
replacing in Equations 8.37 through 8.30 and 8.34 through 8.38 signal spectra 
with corresponding spectra of the image window samples. Local empirical 
Wiener filtering is local adaptive because filter coefficients depend on local 
power spectra of image fragments.
The most straightforward way to implement local filtering is to perform 
it in a “hopping” window. Hopping window processing being very attractive 
FIGURE 8.11
​An example of spatial inhomogeneous image of 256 × 256 pixels (a) separated in fragments of 
16 × 16 pixels and DCT spectra of the corresponding fragments (b).

422
Theoretical Foundations of Digital Imaging Using MATLAB®
from the computational complexity point of view suffers, however, from 
blocking effects, artifacts in a form of discontinuities at the edges of the hop-
ping window. Obviously, the ultimate solution of the “blocking effects” 
problem would be sliding window processing.
In the sliding window filtering, one should, for each position of the filter 
window, compute transform coefficients of the signal within the window, 
determine on this base the filter coefficients, modify the image transform 
coefficients accordingly, and then compute the inverse transform. With slid-
ing window, inverse transform need not, in principle, be computed for all 
pixels within the window since only the central sample of the window has 
to be determined in order to form the output image in the process of image 
scanning with the filter window. Figure 8.12 shows the schematic flow dia-
gram of this process.
Sliding Window DCT Transform Domain Filtering
The selection of orthogonal transforms for the implementation of the filters 
is governed by
• The required accuracy of approximation of general linear filtering 
with scalar filtering
• The availability of a priori knowledge regarding image spectra in the 
chosen base
• The accuracy of the empirical spectrum estimation from the 
observed data required for the adaptive filter design
• The computational complexity of the filter implementation
Transform
Point-wise
multiplication
by the ﬁlter mask
Window
scanning
direction
Filter
formation
Inverse
transform
Output
pixel
Output
image
Modiﬁed spectrum
Filter mask
Image spectrum
Input image
FIGURE 8.12
The principle of local adaptive filtering in a sliding window.

423
Image Perfecting
Among all known transforms, DCT proved to be one of the most appropri-
ate ones for sliding window transform domain filtering. DCT exhibits good 
energy compaction capability, which is a key feature for the efficiency of fil-
ters. Being advantageous to DFT in terms of energy compaction capability, 
DCT can also be regarded as a good substitute for DFT in signal/image res-
toration tasks with imaging system specification in terms of their frequency 
responses. DCT is suitable for multicomponent signal/image processing as 
well. The use of DCT in sliding window has low computational complexity 
owing to the existence of recursive algorithms for computing DCT in slid-
ing windows. In addition, note that, if the window size is an odd number 
(2Nw + 1), the inverse DCT transform of local spectrum βr
k
( )
{
} for computing 
window central pixel ak involves only signal spectrum coefficients β2s
k
( )
{
} with 
even indices (see Appendix)
	
a
N
k
w
k
s
k
s
N
s
w
=
+
+
−








=∑
1
2
1
2
1
0
2
1
β
β
( )
( )(
)
.
	
(8.45)
Therefore, only those spectral coefficients have to be computed, and the 
computational complexity of sliding window filtering in DCT domain is 
O(Nw + 1) operations for 1D filtering in a window of 2Nw + 1 samples and 
O[(Nw1 + 1)(Nw2 + 1)] operations for 2D filtering in a rectangular window of 
(2Nw1 + 1) × (2Nw2 + 1) pixels.
Figure 8.13, generated using the program demo_lcdct2_CRC.m provided in 
Exercises, illustrates local adaptive rejecting filtering for denoising a piece-
wise constant test image. Image (a) is the test image contaminated by addi-
tive noise with standard deviation of 25 gray levels. Image (b) is the output 
image filtered with filter window of 7×7 pixels. Image (c) shows difference 
between input noisy and output images. It is the input image component that 
was filtered out. Its standard deviation is approximately equal to the noise 
standard deviation. Image (d) presents a map of the rejecting filters “trans-
parence,” for each window position; that is, the ratio of the number of ones 
in the array of the filter coefficients to the window size. Note that the latter 
is also the sparsity of output image local spectra. On average, the sparsity of 
output image local spectra for this particular test image and noise intensity 
turned out to be 0.157, that is, on an average, only 12–13 of 49 spectral coef-
ficients of 7×7 pixel image fragments are left after the rejecting filtering.
One can see from this image that when the filter window seats inside 
of an image patch, where the image gray values are constant, the filter is 
almost completely opaque and preserves only local dc (local mean) image 
component. On the contrary, on the boundaries of the patches, the filter is 
almost completely transparent, thus preserving the edges of the patches at 
the expense of lower noise suppression. This feature of the local adaptive fil-
ters can be even better appreciated from magnified fragments of images (a), 

424
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.13
Local and global empirical Wiener filtering: (a) noisy test image; (b) result of local filtering in 
window 7 × 7 pixels; (c) difference between input noisy (a) and filtered (b) images; (d) map of 
local filter “transparentness”; (e) result of global filtering; (f) difference between input noisy 
(a) and filtered (e) images. Note image blur and residual noise correlation after global filtering.

425
Image Perfecting
(b), and (d) shown in Figure 8.14 and from results of global filtering shown in 
Figure 8.13e and f. The edge-preserving capability is an important advantage 
of local adaptive filtering compared to global filtering.
An example of the local adaptive DCT domain denoising of a real MRI 
image is shown in Figure 8.15. The left image in this figure is the initial 
image; the central image is the result of the filtering; and the right image 
is a difference image between initial and filtered ones. From the difference 
image, one can see that it looks almost chaotic and does not contain any vis-
ible details of the initial image.
Local adaptive filtering is also very well suited for denoising images with 
signal-dependent noise such as speckle noise. The characteristic feature of 
the speckle noise is that its standard deviation is proportional to the signal 
(see the section “Speckle Noise Model” in Chapter 2). For filtering speckle 
noise using local adaptive filters, one should set parameters σn and Thr of 
the filters of Equations 8.27 through 8.29 be proportional to the image local 
dc component β0
( , )
k l . Figure 8.16 shows an example of such a denoising of an 
ultrasound image.
Although the above discussion was limited to 2D filters, their extension 
to the 3D case of RGB images or video sequences is straightforward: 2D 
indices in all equations in the sections “Optimal Linear Filters for Image 
Restoration” and “Sliding Window Transform Domain Adaptive Image 
FIGURE 8.14
​Magnified fragments of images of Figure 8.13a, b, and d respectively.
FIGURE 8.15
Denoising of a real MRI image by means of local adaptive filtering in DCT domain. Left to 
right: initial noisy image, filtered image, and difference between initial and filtered images.

426
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.16
​Local adaptive denoising of a speckled US image: left—initial image; middle—filtered image; 
right—difference between initial and filtered images. Image size is 256 × 256; filter window 
size is 25 × 25 pixels.
FIGURE 8.17
2D and 3D local adaptive filtering of a simulated video sequence: (a) one of the noisy frames of 
a test video sequence (image size 256 × 256 pixels); (b) a result of 2D local adaptive empirical 
Wiener filtering (filter window 5 × 5 pixels); (c) a result of 3D local adaptive empirical Wiener 
filtering (filter window 5 × 5 pixels × 5 frames).

427
Image Perfecting
Restoration” should be replaced by 3D ones (two for special coordinates and 
the third for channel index for RGB color images or frame index for video 
sequences) and 2D transforms should be replaced by the corresponding 3D 
transform. Figures 8.17 and 8.18 demonstrate the efficiency of 3D local adap-
tive empirical Wiener filtering in restoration (denoising and deblurring) of 
video sequences.
Hybrid DCT/Wavelet Filtering
An important practical issue in using local adaptive filters is selecting the 
filter window size. This selection is governed by the typical size of image 
details that should be preserved in the filtering. In general, optimal win-
dow size depends on the image and may vary even within the image. This 
requires filtering in multiple windows with an appropriate combination of 
the filtering results at each window position (for methods of combining, see 
the section “Multicomponent Image Restoration and Data Fusion”).
One can avoid filtering in multiple windows by making use of the multi-
resolution property of the wavelet image decomposition in the hybrid filtering 
method. In the hybrid filtering, hard or soft thresholding in each scale level 
of the wavelet filtering shown in a flow diagram of Figure 8.8 is replaced 
by the above-described local adaptive filtering with a fixed window size. 
Owing to wavelet transform multiscale image representation, this replace-
ment imitates parallel local adaptive filtering of the input image with a set 
of windows of different sizes accordingly to the scales selected. The flow 
diagram of the hybrid filtering is shown in Figure 8.19.
As we mentioned, DCT transform is almost always the most appropri-
ate for local adaptive filtering. For high-resolution images, DCT filtering in 
FIGURE 8.18
3D local adaptive empirical Wiener filtering for denoising and deblurring of a real thermal 
video sequence: (a) a frame of initial video sequence; (b) a frame of restored video sequence. 
Filter window is 5 × 5 pixel × 5 frames; image size 512 × 512 pixels.

428
Theoretical Foundations of Digital Imaging Using MATLAB®
sliding window requires a window size of the smallest size of 3 × 3 pixels; 
otherwise, filtering may result in loss of tiny image details. This require-
ment limits the noise suppression capability of the local adaptive filtering 
that increases with window size. In the hybrid filtering, when the window 
3 × 3 in the first scale is used, in scale 2, the effective window size is 6 × 6 
pixels, in scale 3, it is 12 × 12, and so on.
In DCT filtering in the window of 3 × 3 pixels, only the following four basis 
functions of the DCT transform are involved:
	
φ
φ
0 0
0 2
1
1
1
1
1
1
1
1
1
2
2
1
1
1
2
2
2
1
1
,
(
)
,
(
)
;
DCT
DCT
=










=
−
−
−
+
+
+
−
−
−










=
−
+
−
−
+
−
−
+
−










1
2
2
1
2
1
1
2
1
1
2
1
2 0
2
;
;
,
(
)
φ
φ
DCT
 
,
(
)
.
2
1
2
1
2
1
2
4
2
1
2
1
DCT =
−
−
−
−
+
−
−
−
−









	
(8.46)
The second and the third functions represent what is called vertical and 
horizontal Laplacian operators. The last function can be decomposed into a 
sum of diagonal Laplacians:
Input
Sliding window
local adaptive
filtering
Sliding window
local adaptive
filtering
Output
Interpolation
Interpolation
Interpolation
Interpolation
Interpolation
+
+
+
+
+
+
+
+
Low-pass
filtering and
downsampling
Low-pass
filtering and
downsampling
Low-pass
filtering and
downsampling
FIGURE 8.19
Flow diagram of the image hybrid denoising with wavelet decomposition and local adaptive 
of the decomposition components.

429
Image Perfecting
φ2 2
1
2
1
2
1
2
4
2
1
2
1
1
2
2
1
1
1
2
1
1
1
2
, =
−
−
−
−
+
−
−
−
−










=
+
−
−
−
+
−
−
−
+










+
−
−
+
−
+
−
+
−
−
















1
1
2
1
2
1
2
1
1
.
	
(8.47)
Therefore, DCT filtering in the 3 × 3 window can be replaced by filtering in the 
domain of four directional Laplacians (not counting the basis function φ0 0,
(
),
DCT  
which is responsible for image local dc component (local mean)). Experimental 
experience proves that, for high-resolution images, such an implementation is 
advantageous to simple DCT since it produces less filtering artifacts. Its use in 
hybrid filtering promises additional advantages because it is equivalent to a 
corresponding increase in the number of effective basis functions.
In conclusion, note that, as we mentioned it in the section “Transforms 
in Sliding Window (Windowed Transforms) and Signal Subband 
Decomposition” in Chapter 2, local adaptive filters, wavelet shrinkage, and 
hybrid filtering methods can be treated as hard or soft thresholding of image 
subbands. The local adaptive filtering in the transform domain is filtering 
in subbands uniformly distributed in the base band with the number of the 
subbands equal to, in 1D case, (Window Size + 1)/2. Wavelet shrinkage is fil-
tering in subbands arranged in the base band in a logarithmic scale with the 
number of subbands equal to the number of the resolution scales. Hybrid 
filtering combines logarithmic arrangement of subbands of wavelets with 
uniform arrangement of sub-subbands within wavelet subbands. It is inter-
esting to note that this “logarithmic coarse-uniform fine” band arrange-
ment resembles very much, from one hand, floating point representation 
of numbers in computers (logarithmic for order and uniform for mantissa) 
and, from the other hand, arrangement of tones and semitones in music (in 
Bach’s equal-tempered scale, octaves are arranged in a logarithmic scale and 
12 semitones are equally spaced within octaves).
Multicomponent Image Restoration and Data Fusion
The above theory of MSE-optimal scalar filtering can be extended to the res-
toration of multicomponent images such as color and multispectral images, 
video sequences, images of same objects generated by different imaging 
devices (multimodality imaging). Such a processing is called data fusion.
As an illustrative mathematical model, consider an M-channel imaging 
system, in which each of the M-component images can be described in the 
DFT domain by the model of Equation 8.31:
	
β
λ
α
ν
r
m
r
m
r
m
r
m
(
)
(
)
(
)
(
) ,
=
+
{
} 	
(8.48)

430
Theoretical Foundations of Digital Imaging Using MATLAB®
where m is component index, m = 1,2,. . .,M, βr
m
(
)
{
} and αr
m
(
)
{
} are spectral coef-
ficients of the observed and perfect image components, λr
m
(
)
{
} are discrete 
frequency response coefficients of the system’s m-th channel, and νr
m
(
)
{
} are 
spectral coefficients of additive signal-independent zero mean uncorrelated 
(white) noise with variance σn
m
2(
) in the m-th channel, uncorrelated with noise 
components in other channels.
Suppose that image components are restored in the DFT domain by a lin-
ear combination of scalar filtered input image components:
	
ˆ
,
(
)
(
, )
( )
α
η
β
r
m
r
m p
r
p
p
M
=






=∑
1
	
(8.49)
where βr
p
( )
{
} and ˆ (
)
αr
m
{
} are DFT spectral coefficients of input and restored 
images in the p-th and m-th channel, correspondingly, and ηr
m l
(
, )
{
} are coeffi-
cients of frequency response of a restoration scalar linear filter that generates 
a contribution to the m-th channel output image from the p-th channel.
From the MSE criterion
	
ˆ
argmin
(
)
(
)
(
, )
( )
(
, )
α
α
η
β
η
r
m
r
m
r
m p
r
p
p
M
r
N
r
m p
=
−
{
}
=
=
∑
AV
AV
A
N
Ω
Ω
1
2
0
−
∑














1
,
	
(8.50)
one can obtain the following system of M2 equations for M2 MMSE-optimal 
restoration multichannel filter coefficients ηr
m l
(
, )
{
} (see Appendix):
	
η
β β
β
r
m p
r
p
r
l
p
M
r
m
r
l
(
, )
( )
( )
(
)
( ) .
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
∗
=
∗
(
) =
(
)
∑
1
α
	
(8.51)
Cross-correlations AV
AV
A
N
Ω
Ω
β β
r
p
r
l
( )
( )
∗
(
) and AV
AV
A
N
Ω
Ω
α
β
r
m
r
l
(
)
( )
∗
(
) are, accord-
ing to Equation 8.48 (see Appendix),
	
AV
AV
AV
A
N
A
Ω
Ω
Ω
β β
λ
λ
α
α
σ
δ
r
p
r
l
r
p
r
l
r
p
r
l
n
p
( )
( )
( )
( )
( )
( )
( )
∗
∗
∗
(
) =
(
) +
2
(
)
l
p
−
	
(8.52)
	
AV
AV
AV
A
N
A
Ω
Ω
Ω


α
β
λ
α
α
r
m
r
l
r
l
r
m
r
l
(
)
( )
( )
(
)
( )
∗
∗
∗
(
) =
(
)	
(8.53)
because channel noises are assumed to be zero mean and noncorrelated. 
Inserting Equations 8.52 and 8.53 into Equation 8.51, the following system of 
M2 equations for multichannel filter coefficients ηr
m l
(
, )
{
} is finally obtained:

431
Image Perfecting
	
η
α
α
η
σ
λ
α
r
m p
p
M
r
p
r
l
r
m l
n
l
r
m
(
, )
( )
*( )
(
, )
( )
(
)
AV
AV
A
A
Ω
Ω
=∑
(
) +
=
1
2
1


 r
m
r
l
(
)
*( )
,
α
(
)





	
(8.54)
where
	
α
λ α
r
r
r
( )
( )
( ) .
⋅
⋅
⋅
=
{
} 	
(8.55)
In order to ease the analysis and interpretation of the solution and get an 
insight into how interchannel correlations and noise level determine chan-
nel contributions to the result of fusion, consider a special case of fusion 
of two channels (l = 1,2) into one (m = 1,2). In this case, we have a system 
of two pairs of equations for channel weight coefficients η
η
r
r
( , )
( , )
,
1 1
1 2
{
} and 
η
η
r
r
( , )
( , )
,
2 1
2 2
{
}:
AV
AV
A
A
Ω
Ω



α
η
α
α
η
σ
η
r
r
r
r
r
n
r
( )
( , )
( )
*( )
( , )
( )
(
1 2
1 1
2
1
1 2
2 1
1
(
)
+
(
)
+
, )
( )
( )
*( )
( )
*( )
( , )
1
1
1
1
1
2
1 1
1
=
(
)
(
)
+
λ
α α
α α
η
r
r
r
r
r
r
AV
AV
A
A
A
Ω
Ω




V
AV
A
A
Ω
Ω



α
η
σ
η
λ
α α
r
r
n
r
r
r
r
( )
( , )
( )
( , )
( )
( )
*( )
2 2
1 2
2 2
1 2
1
1
2
1
(
)
+
=
(
)






(
)
+
(
)
+
AV
AV
A
A
Ω
Ω



α
η
α
α
η
r
r
r
r
r
( )
( , )
( )
*( )
( , )
1 2
2 1
2
1
2 2
σ
η
λ
α
α
α α
n
r
r
r
r
r
r
2 1
2 1
2
2
1
1
2
1
( )
( , )
( )
( )
*( )
( )
*( )
=
(
)
(
AV
AV
A
A
Ω
Ω




)
+
(
)
+
=
η
α
η
σ
η
λ
α
r
r
r
n
r
r
r
( , )
( )
( , )
( )
( , )
( )
2 1
2 2
2 2
2 2
2 2
2
1
AV
AV
A
A
Ω
Ω

 ( )
*( ) .
2
2
αr
(
)






	
(8.56)
Consider in detail the first pair that can be rewritten as
	




α
σ
η
α
α
η
λ
α
r
n
r
r
r
r
r
r
( )
( )
( , )
( )
( )
( , )
( )
1 2
2 1
1 1
2
1
1 2
1
1
+




+
=
∗
( )
( )
( )
( , )
( )
( )
( , )
(
1 2
1
2
1 1
2 2
2 2
1 2
1



α α
η
α
σ
η
λ
r
r
r
r
n
r
r
∗
+
+




=
1
1
2
)
( )
( )
,


α α
r
r
∗
	
(8.57)
where A
A
V
( )
Ω
⋅⋅ is, for the sake of brevity, replaced by ( )⋅⋅.
Solutions of these equations are (see Appendix)
	
η
λ
κ
κ
r
r
r
r
r
r
r
SNR
SNR
SNR
( , )
( )
( )
( , )
( , )
( )
1 1
1
1
1 2
2 1
2
1
1
1
1
=
+
−
(
)


+
( )
( )
( , )
( , )
( )
( )
( , )
(
1
2
1 2
2 1
1
2
1 2
2
1
1
+
+
−
(
)
=
SNR
SNR SNR
r
r
r
r
r
r
r
κ
κ
η
λ
)
( , )
( )
( )
( )
( , )
( , )
(
κ
κ
κ
r
r
r
r
r
r
r
SNR
SNR
SNR
SNR
2 1
2
1
2
1 2
2 1
1
1
1
+
+
+
−
(
)
)
( ) ,
SNRr
2
	
(8.58)

432
Theoretical Foundations of Digital Imaging Using MATLAB®
where κr
( , )
1 2  and κr
( , )
2 1  are true signal interchannel cross-correlation coefficients
	
κ
α α
α
κ
α α
α
r
r
r
r
r
r
r
r
( , )
( )
( )
( )
( , )
( )
( )
( )
,
1 2
1
2
1 2
2 1
1
2
2 2
= (
)
= (
)
∗
∗

	
(8.59)
and
	
SNR
AV
AV
r
m
r
m
r
m
r
m
r
m
r
m
A
A
(
)
(
)
(
)
(
)
(
)
(
)
=
(
)
=
(
)






Ω
Ω
α
σ
λ
α
σ
2
2
2
2
2




=
m
1 2
,
	
(8.60)
are channel signal-to-noise ratios in image spectral components.
Equation 8.58 is an analog of Equation 8.34 for one-component image res-
toration and, similar to that, implies that each channel contributes to the 
fused output signal its inverse filtered signal weighted by a “regularization” 
factor that monotonically grows with the channel signal-to-noise ratio.
Two immediate important special cases of the described multicompo-
nent image restoration are denoising of multiple images of the same object 
obtained with different sensors and superresolution from video.
If two input images are images of the same object that might be displaced 
with respect to each other, true signal interchannel cross-correlation coef-
ficients are
	
κ
κ
π
κ
κ
r
r
r
r
i
k
r
( , )
( , )
( , )
( , )
( , )
exp(
),
,
1 2
2 1
1 2
1 2
2 1
2
1
=
=
=
∗
∗
and
	
(8.61)
where, according to the shift theorem for DFT, k(1,2) is spatial displacement 
between images in channels 1 and 2. Then the channel weight coefficients 
are
η
λ
η
λ
κ
r
r
r
r
r
r
r
r
SNR
SNR
SNR
( , )
( )
( )
( )
( )
( , )
( )
( ,
;
1 1
1
1
1
2
1 2
2
2
1
1
1
=
+
+
=
1
2
1
2
1
)
( )
( )
( ) .
SNR
SNR
SNR
r
r
r
+
+
	
(8.62)
In general, Equation 8.54 is converted in this case to
	
λ
λ
κ
η
α
η
σ
λ
r
l
r
p
r
p l
p
M
r
m p
r
r
m l
n
l
r
*( )
( )
( , )
(
, )
(
, )
( )
=∑








+
=
1
2
2
*( )
(
, )
l
r
m l
r
κ
α
2





	
(8.63)
or
	
exp(
)
exp(
( , )
(
, )
(
, )
( )
(
, )
p
M
p l
r
m p
r
m l
r
l
m l
i
k
r
SNR
i
k
=∑
+
=
1
2
2
π
η
η
π


r) ,





	
(8.64)

433
Image Perfecting
where it is denoted
	
η
λ η
r
m
r
r
m
(
, )
( )
(
, ).
⋅
⋅
⋅
=
	
(8.65)
As one can verify, the solution of these equations is
	
η
π
r
m l
l m
r
l
r
s
s
M
i
k
r SNR
SNR
(
, )
( ,
)
( )
( )
exp(
)
=
+
=∑
2
1
1
	
(8.66)
or
	
η
π
λ
r
m l
l m
r
l
r
l
r
s
M
i
k
r
SNR
SNR
(
, )
( ,
)
( )
( )
( )
exp(
)
.
=
+
=∑
2
1
1
s
	
(8.67)
Equation 8.67 implies that in this case multichannel image fusion consists 
of mutual alignment (factor exp(i2πk(l,m)r)) and inverse filtering (factor 1 λr
l( )) 
of channel images and summing up the results with weights proportional 
to channel SNRs.
When mutual displacements of images are known, images can be aligned 
through their resampling with an appropriate interpolation using methods 
discussed in Chapter 6. In particular, if displacements k m l
0
(
, )
{
} are known with 
a subpixel accuracy, in the averaging, samples of images will be interlaced 
according to the mutual shifts of the images. Therefore, the resulting image 
will have accordingly higher sampling rate than that of the original image 
set and, hence, will have higher resolving power. This resolution increase is 
referred to as superresolution from multiple images. An example of superreso-
lution that can be achieved in processing of turbulent videos is described in 
the section “Application Examples” in Chapter 5.
Mutual image lateral displacement is just a special case of general image 
affine geometric transformations, including scaling or rotation. Obviously, 
image alignment before fusing should allow for all those transformations.
When mutual image displacements or corresponding parameters are not 
known, they have to be determined. The estimation of image displacements 
or other geometrical parameters can be performed using methods of image 
parameter estimation discussed in Chapter 7. In particular, it is shown in 
Chapter 7 that, for the model of additive uncorrelated Gaussian noise in 
image components, mutual image lateral displacements can be determined 
by means of locating positions of image cross-correlation peaks. Image aver-
aging with such an image correlational alignment is called correlational aver-
aging or correlational accumulation. The correlation accumulation has found 

434
Theoretical Foundations of Digital Imaging Using MATLAB®
many practical applications, especially in high-resolution electrocardiogra-
phy and similar biomedical signal processing and for processing electron 
micrographs of virus particles in which very many of the identical particles 
are simultaneously observed.
As it was shown in Chapter 7, in estimating lateral displacements of noisy 
images, two types of localization errors occur: normal errors and anomalous 
ones. Normal errors are small errors. In image correlational accumulation, 
they result in certain blur of the resulting fused image due to nonperfect 
alignment of component images. Anomalous localization errors appear, 
when the target image is erroneously identified with a realization of noise. In 
Correlational accumulation, SNR = 0.5; Nit = 10,000.
One of noisy images (left) and accumulated image (right)
(a)
(b)
Correlational accumulation, SNR = 0.1; Nit = 10,000.
One of noisy images (left) and accumulated image (right)
Plot of the middle rows of template and of accumulated image
1
0.8
0.6
0.4
0.2
2
1.5
1
0.5
0
–0.5
0
3
13
23
33
43
53
63
73
63
93
103
113
Accumulated image
Template
Accumulated image
Template
123
3
13
23
33
43
53
63
73
83
93
103
113
123
Plot of the middle rows of template and of accumulated image
FIGURE 8.20
​Correlational accumulation of 10,000 realizations of a circular template image mixed with 
additive noise for signal-to-noise ratios 0.5 (a) and 0.1 (b). Overshoots at the edges of the accu-
mulated image seen on plots of image middle row for SNR = 0.1 are artifacts caused by anoma-
lous errors in image alignments for the accumulation.

435
Image Perfecting
image fusing through correlational averaging, this means that some image 
components involved in the fusion will be not object images but just pieces 
of realizations of noise, which results in artifacts that are visually perceived 
as image edge emphasizing.
Figure 8.20 illustrates this phenomenon on simulation results of denoising, 
by means of correlational averaging, of noisy images containing a circular 
template in random position in the field of view for two values of signal-to-
noise ratio 0.5 (a) and 0.1 (b).
One can see on the figure that for SNR = 0.1, template image is restored 
with substantial artifacts in the form of overshoots at the edges, while for 
SNR = 0.5, these artifacts are practically not noticeable, although certain blur 
of the template edges can be indicated.
Filtering Impulse Noise
Image distortions in the form of impulse noise or “pepper-and-salt” noise 
usually occur in image transmission via noisy digital communication chan-
nels and in the storage of digital imagery. Signal transmission errors result in 
losses, with certain probability, of individual image samples and in replacing 
their values by random values. Impulse noise may also appear as a resid-
ual noise after applying denoising filtering to noisy images with additive 
or speckle noise. In this case, impulse noise originates from large outbursts 
of additive or speckle noise that the filtering failed to remove. “Pepper-and-
salt” noise usually occurs due to memory cell faults in digital image storage. 
The possibility of successful filtering of impulse and “pepper-and-salt” noise 
allows one to lower requirements to transmitter power or, given the trans-
mitter power, to raise the transmission distance and to lower requirements 
to the reliability of digital storage.
As a factor that affects image perception, impulse noise is more destructive 
than additive normal noise of the same intensity. One can convince him(her)
self in this by comparing, in Figure 8.21, the readability of a test image of 
printed text distorted by both types of noise of the same intensity, in terms 
of mean square deviation from the noise-free image.
Impulse noise is described by the ImpN-model introduced in the section 
“Models of Signal Random Interferences” in Chapter 2 (Equation 2.131):
	
b
e
a
e n
k l
k l
k l
k l
k l
,
,
,
,
,
(
)
,
=
−
⋅
+
1
	
(8.68)
where {bk,l} are samples of image contaminated by impulse noise, {ak,l} are 
the perfect image samples, {ek,l} are samples of a binary random sequence 
that determines the presence (ek,l = 1) or the absence (ek,l = 0) of impulse noise 
in the (k,l)-th sample, and {nk,l} are samples of yet another random sequence 
that replaces signal samples in cases when impulse interference takes place.

436
Theoretical Foundations of Digital Imaging Using MATLAB®
From this model, it follows that filtering impulse noise assumes two stages:
• Detection stage: detecting signal samples that have been lost due to 
the noise
• Correction stage: estimating values of those lost samples
In the case of image transmission over noisy digital channels using error 
detection codes, the positions of distorted pixels might be known, and no 
detection is required. Obviously, no special detection is required for “pepper-
and-salt” noise either because distorted pixels are those that take extreme 
values in the image dynamic range.
If positions of error pixels are known, image restoration can, in principle, 
be achieved by means of, for instance, using the discrete sampling theorem-
based iterative algorithm for band-limited approximation of images with 
omissions described in the section “Algorithms for Signal Recovery from 
Sparse Sampled Data.” However, in practice, using much more simple algo-
rithms is frequently sufficient, which replace error pixels by a certain aver-
aging of those of 8 pixels in their 3×3 pixel neighborhood in the rectangular 
sampling grid (the closest three pixels in the row above from the given pixel, 
two pixels to the left and to the right from the given pixel in its row, and the 
closest three pixels in the row below it), which are known to be nondistorted. 
Examples of images restored using these two methods from the distorted 
image shown in Figure 8.22a are shown in Figure 8.22b and c, respectively.
When the positions of distorted pixels are not known, their detection rep-
resents the main problem. This task can be treated as a special case of the task 
of object localization in clutter images treated in Chapter 7. For localization 
of impulse noise samples, individual pixels replaced by noise are the local-
ization targets. Hence, the target spectrum in Equation 7.45 that determines 
that the SCR-optimal adaptive correlator is uniform, and the correlator filter 
FIGURE 8.21
Test image with additive normal noise (left) and impulse noise (right) with mean squared devi-
ation from noise free image equal to 50 (in the image range 0–255).

437
Image Perfecting
FIGURE 8.22
​Filtering impulse noise: (a) noisy image with probability of error 0.3; (b) image denoised by the 
iterative band-limited reconstruction algorithm for known positions of error pixels; (c) image 
denoised by means of replacement of error pixels with mean over nondistorted pixels in the 
3 × 3 neighborhood for known positions of error pixels; (d) image denoised by the iterative 
filtering algorithm for unknown positions of error pixels; (e) image denoised by the recursive 
filtering algorithm for unknown positions of error pixels.

438
Theoretical Foundations of Digital Imaging Using MATLAB®
frequency response will be in this case determined solely by an estimate 
βr s
bg x
y
,
(
,
,
)
0
0
2  of the power spectrum of the image background component:
	
η
β
β
β
r s
opt
r s
bg x
y
r s
bg x
y
r s
b
,
(
)
,
(
,
,
)
,
(
,
,
)
,
(
=
=




1
1
1
0
0
0
0
2
2
1 2
g x
y
,
,
)
.
0
0
2
1 2




	
(8.69)
Equation 8.69 implies that image filtering using this filter is double whiten-
ing. As it is shown in the section “Object Localization and Edge Detection: 
Selection of Reference Objects for Target Tracking” (Chapter 7), double whit-
ening can be approximated by two convolution of the image with Laplacian 
(the double Laplacian). Detection of impulse noise samples can then be imple-
mented by comparing the output of such a filter in every pixel with a cer-
tain threshold. As the threshold, standard deviation of the filter output signal 
multiplied by a certain constant can be taken, the constant been selected so 
as to maximize the probability of correct detection, given the probability of 
false alarms that may occur due to small contrast details and object edges in 
the image. At the correction stage, image samples that have been detected 
as distorted can be replaced by “predicted” values found by one or another 
smoothing operation over those samples in their vicinity that are not marked 
as distorted. As the smoothing operation, arithmetic mean or its robust 
nonlinear versions discussed in the section “Nonlinear Filter Classification 
Principles” can be used. This algorithm can be mathematically formalized as
	
ˆ
,
,
,
,
,
,
,
,
a
b
dL
D
b
k l
k l
k l
dL
k l
k l
=
≤



if
otherwise
σ
	
(8.70)
where ˆ ,
ak l
{
} are filtered image samples, {bk,l} are samples of the initial dis-
torted image, {dLk,l} are samples of the result of applying to image {bk,l} the 
double Laplacian operator, D is a detection threshold constant multiplier to 
the standard deviation σdLk l,  of {dLk,l}, and bk l,
{
} are the “predicted” values. 
D is a free parameter of the algorithm, which depends on the probability of 
pixel distortion: the larger the probability, the lower must be D.
In case when the probability of pixel distortion is sufficiently large, many 
clusters of two of more adjacent distorted pixels may occur, which hampers 
detection of individual distorted pixels by the filter aimed at the detection of 
individual distorted pixels. The reliability of the detection of distorted pixels 
can be increased if denoising is implemented in an iterative manner, using 
as input image, at each iteration, the image obtained on the previous iteration 
and with decreasing, from iteration to iteration, of the impulse noise detec-
tion threshold in order to remove and correct at earlier stages of iterations the 
most intensive impulse noise outbursts. This algorithm can be mathemati-
cally formulated by the equation

439
Image Perfecting
	
ˆ
,
ˆ
,
(
)
,
(
)
(
)
,
(
)
,
(
)
a
d
D
a
k l
t
k l
t
t
d
k l
t
k l
t
−
−
−
−
≤
−
1
1
1
1
1
if  
otherwis
σ
e



,
	
(8.71)
where ˆ ,
( )
ak l
t
{
} are filtered image samples at the (t-1)-th iteration ( ˆ ,
( )
,
a
b
k l
k l
0 =
{
}),
dLk l
t
,
(
)
−
{
}
1  are samples of the result of applying to image ˆ ,
(
)
ak l
t−
{
}
1  at the (t–1)-th 
iteration the double Laplacian operator, D(t−1) is the detection threshold con-
stant multiplier to the standard deviation σdk l
t
,
(
)
−1  of dk l
t
,
(
)
−
{
}
1 , and ˆ ,
(
)
ak l
t−
{
}
1  are the 
pixel “predicted” values found at (t − 1)-th iteration.
An even more simple and fast modification of this denoising filtering is 
recursive filtering in a sliding window, in which detection and estimation 
for each pixel are carried out in the process of image row-wise/column-
wise scanning using, for detection, comparison of prediction error, found 
in the same way as in DPCM-coding (see the section “Outline of Image 
Compression Methods” in Chapter 3), with a certain detection threshold:
	
ˆ
,
,
,
,
,
,
,
,
a
b
a
b
DetThr
b
k l
k l
k l
k l
k l
=
−
≤



if
otherwise
	
(8.72)
where “predicted” values bk l,  of the (k,l)-th pixel for image scanning in the 
direction of index l are computed, in the same way as in DPCM coding, by 
weighted summation of pixels ˆ
, ˆ
, ˆ
, ˆ
,
,
,
,
a
a
a
a
k
l
k
l
k
l
k l
−
−
−
−
+
−
{
}
1
1
1
1
1
1  on the preceding 
and the given row, which have already been processed, and DetThr is a detec-
tion threshold. In order to lower the probability of missing distorted pixels, 
DetThr should be lower, which increases the probability of false detection. 
This may result in blurring of image edges. In order to reduce the damage, it 
was found useful to modify the filter in the following way:
	
ˆ
,
ˆ
,
,
,
,
,
,
,
,
a
b
a
b
DetThr
a
sign a
b
C
k l
k l
k l
k l
k l
k l
k l
=
−
≤
+
−
(
)
if
otherwise



,
	
(8.73)
where C is a certain correcting constant, which is smaller than the visual 
detection threshold for small targets of the size of one pixel and larger than 
visual detection threshold for large targets. The practical values of C are 
roughly in the range of 10–20 gray levels (in the 0–255 scale). Images (d) and 
(e) in Figure 8.22 illustrate filtering impulse noise with the probability 0.3 by 
the described iterative and recursive filters. They were generated using the 
MATLAB program impulse_noise_filtering_demo_CRC.m (see Exercises).
The described impulse noise filtering algorithms belong to the family of 
nonlinear filters because they contain detection components, which are sub-
stantially nonlinear. In the section “Nonlinear Filters for Image Perfecting,” 

440
Theoretical Foundations of Digital Imaging Using MATLAB®
we introduce a general framework for a family of nonlinear filters for image 
perfection, of which the described filters represent a special case.
Correcting Image Grayscale Nonlinear Distortions
Image grayscale reproduction is characterized by the imaging system trans-
fer function. Normally it should be a linear function in the image intensity 
dynamic range from its minimum to its maximum. Deviations from linear-
ity cause image grayscale distortions that need to be corrected. Imaging sys-
tems intended for image display are usually equipped for this purpose with 
special means for manual correction using buttons “brightness,” “contrast,” 
and “gamma-correction,” the “gamma” being a slope of the system transfer 
function plotted in a logarithmic scale. This is usually perfectly enough as 
far as visual image quality is concerned. When images are intended for met-
rological purposes, automatic and accurate correcting methods are needed.
Correcting grayscale distortions is obviously a special case of inverse 
problems. When system transfer function TF(⋅) is known, it can be corrected 
by means of applying to distorted images a correcting function CF(⋅) = TF−1(⋅) 
inverse to TF(⋅), provided noise and signal quantization effects are negligible.
Nonlinear correcting of quantized signals may result in conglutination of 
quantization levels as illustrated in Figure 8.23.
Therefore, quantization artifacts that were regarded negligible before 
nonlinear transformation may become intolerable and, generally, the 
FIGURE 8.23
​Nonlinear signal transformation and conglutination of quantization levels. Thin lines in the 
figure are bounds of 16 uniform quantization intervals. The curve shows transfer function of a 
nonlinear transformation. Bold lines indicate nine quantization levels left after the nonlinear 
transformation of 16 quantization levels of input values.

441
Image Perfecting
­optimization of the correcting function over the image database or ensem-
ble ΩA is required:
	
CF
LOSS a
CF Q TF a
CF
k l
k l
l
N
k
N
A
y
x
( )
argmin
(
)
,
,
⋅=
−
[
]
{
}
⋅( )
=
−
= ∑
AVΩ
0
1
0
−
∑












1
,
	
(8.74)
where Q(⋅) is the image scalar quantization transfer function and LOSS|⋅| is a 
loss function, for instance, quadratic one, that evaluates losses due to devia-
tions of the image signal from its nondistorted original.
In applications, it very frequently happens that the imaging system trans-
fer function that has to be corrected is not known. In some cases, it can be 
determined directly from an analysis of distorted images or calibrated using 
as a reference a certain standard image. This task is akin to the task of noise 
diagnostics discussed in Appendix.
Nonlinear point-wise distortion transfer function can be, for quantized 
signals, parameterized as a look-up table with the number of parameters 
(look-up table entries) equal to the number of signal quantization levels. It 
affects all pixels in the same way. Therefore, having enough pixels, one can, 
in principle, estimate those parameters from statistical characteristics of 
distorted images quite well. Specifically, distribution histograms of images, 
which are directly affected by the point-wise transformation, can be used for 
this purpose if normal histogram is known for the type of images, to which 
the image to be corrected belongs.
A typical example to illustrate such an opportunity is correcting nonlin-
ear distortions in recording optical interferograms. Perfect interferogram is 
a phase-modulated sinusoidal signal. If the interferogram to be corrected 
contains many periods of a sinusoidal signal, the distribution function of its 
phase can be regarded to be uniform in the range [–π,π]. The probability dis-
tribution function of sinusoidal signals with a uniformly distributed phase is 
known. Therefore, the correcting nonlinear transformation can be found as 
a transformation that converts the histogram of the distorted interferogram 
into the histogram defined by the known probability distribution function 
of sinusoidal signals with uniformly distributed phase. Generally, correcting 
nonlinear transformation is the one that converts the histogram of the dis-
torted image into a normal histogram for the given type of images. We will 
refer to such a transformation as histogram matching. Figure 8.24 illustrates 
the histogram matching for correcting nonlinear distortions of an interfero-
gram using, as a reference, histogram of a simulated ideal interferogram. 
The MATLAB program Histo_standardization_CRC.m used for generating 
images in these figure is provided in Exercises.
Yet another example of an application, in which the histogram matching 
can be used for correcting unknown nonlinear image distortion, is creating 
image mosaics or panoramic images from sets of individually taken images.

442
Theoretical Foundations of Digital Imaging Using MATLAB®
0.03
Inp. image histogram
Input and reference image histograms
Ref. image histogram
0.015
0.005
50
100
150
200
250
0.01
0.02
0.025
(a)
(b)
(c)
(d)
FIGURE 8.24
Histogram matching for correcting nonlinear distortions in imaging systems: (a) distorted 
interferogram; (b) reference interferogram; (c) histograms of the distorted and reference inter-
ferograms; (d) corrected interferogram.

443
Image Perfecting
Algorithmically, the histogram matching can be implemented through the 
histogram equalization, a nonlinear transformation that converts image histo-
grams to uniform histograms. For the histogram matching, it is sufficient to 
find histogram equalization transformation for the image to be transformed 
and that for the image with the reference histogram. The required histo-
gram matching transformation can then be obtained by combining histo-
gram equalization transformation for the image to be transformed and the 
transformation inverse to the histogram equalization transformation for the 
reference histogram.
Histogram equalization is a special case of a large class of nonlinear filter-
ing algorithms, which we discuss in the next section.
Nonlinear Filters for Image Perfecting
Digital linear filters for image perfecting introduced in the sections 
“Optimal Linear Filters for Image Restoration” and “Sliding Window 
Transform Domain Adaptive Image Restoration” are called linear because 
they are defined by Equation 4.7 of weighted summation of signal discrete 
representation coefficients (samples, when sampling is used for signal dis-
cretization), which is an equation of a straight line in the multidimensional 
signal space. Obviously, that, generally, filter input–output relationship 
might be nonlinear; hence, generally, nonlinear filters must considered. 
Since J.W. Tukey [5] introduced the median filter, a vast variety of nonlinear 
filters for image processing has been suggested. In order to ease navigating 
in this ocean of filters, we will provide in this chapter a classification of the 
nonlinear filters originated from the median filter and describe some most 
useful filters for image denoising and enhancement. Throughout almost the 
entire chapter, we will assume that images are single-component grayscale 
sampled images with quantized gray levels. Possible approaches to nonlin-
ear filtering of multicomponent images will be briefly discussed in a sepa-
rate section.
Nonlinear Filter Classification Principles
Equation 4.7 for linear filters can be considered as a special case of a general non-
linear relationship between filter output pixel ˆ ,
ak l and its input pixels am n
k l
,
( , )
:
{
}
	
ˆ
{
(
)},
,
,
a
NBH a
k l
k l
= ESTM
	
(8.75)
where {k,l} and {m,n} are integer indices of image pixels, NBH(ak,l) is a subset 
of image pixels am n
k l
,
( , )
{
}, which we will call the pixel neighborhood of the pixel 

444
Theoretical Foundations of Digital Imaging Using MATLAB®
ak,l that corresponds, in the input image, to the filter output sample ˆ ,
ak l, and 
ESTM{⋅} is an estimation operation that produces the filter output.
Pixel neighborhoods and estimation operation are key words in our clas-
sification of nonlinear filters. Such an approach enables unified treatment 
and comparison of nonlinear filters and their structuring that can be directly 
translated into algorithmic implementations of the filters.
The pixel neighborhood is formed on the base of attributes of pixels involved in 
the filtering. Obviously, primary pixel attributes that determine filtering opera-
tions are pixel gray values and their coordinates (indices). It turns out, however, 
that a number of attributes other than only these primary ones are essential for 
nonlinear filtering. Table 8.1 presents a sample list of pixel attributes that are 
involved in the design of nonlinear filters known from the literature.
Attributes rank and cardinality describe statistical properties of pixels 
in neighborhoods. They are interrelated and may actually be regarded as 
two faces of the same quality. While rank is associated, as it is described 
in the section “Principles of Statistical Treatment of Signals and Signal 
Transformations and Basic Definitions” in Chapter 2, with the variational 
row, that is, ordered in ascending order sequence of neighborhood pixel 
values, cardinality is associated with the histogram over the neighborhood. 
“Geometrical” attributes gradient and Laplacian describe properties of images 
as surfaces in 3D spaces, respectively.
TABLE 8.1
​Sample List of Pixel Attributes
Attribute Gray Level
Denotation a
Definition Pixel Gray Level
Coordinates
COORDWnbh(ak,l)
Pixel coordinates (indices) in the filter window 
(window-neighborhood)
Cardinality
HISTNBH (a)
The number of neighborhood pixels with the 
same gray level as that of element a:
HIST
a
a
a
NBH
k l
k l NBH
( )
(
)
,
,
=
−
∈∑δ
Rank
RANKNBH(a)
Number of neighborhood elements with values 
lower than a, or position of gray level a in the 
variational row
RANK
a
HIST
v
NBH
NBH
v a
a
( )
( )
min
=
=∑
Gradient
GRDTNBH(k,l)
Image gradient in position (k,l):
GRDT
k l
a
a
a
a
NBH
k l
k
l
k l
k l
( , )
,
,
,
,
=
−
(
) +
−
(
)
−
−
1
2
1
2
Laplacian
LPLCNBH(k,l)
Image Laplacian in position (k,l) (absolute value 
of convolution of the image with one of the 
kernels defined by Equation 7.65):
  LPLC
k l
L
a k l
NBH( , )
{ }( , )
=


445
Image Perfecting
Pixel neighborhoods are formed as subsets of filter window pixels selected 
according to their certain attributes. The formation of pixel neighborhoods 
can be interpreted as segmentation of image fragment within the filter win-
dow for separating pixels that will be involved in generating filter output 
from those that are irrelevant for this. The primary neighborhood is the set 
of all pixels of the filter window. We will call this neighborhood the window-
neighborhood Wnbh(k,l), where (k,l) are indices of the window central pixel 
that specify the window position. Other neighborhoods are subsets of Wnbh. 
In their denotations, we will indicate the attribute, upon which the neighbor-
hood is formed, and its numerical parameters: NBH (Attribute, Parameters).
The process of neighborhood formation can be multistage using as an 
attribute, at each stage, a certain estimate over the neighborhood formed at 
the previous stage. One can distinguish the following groups of neighbor-
hoods in terms of pixel attributes, upon which they are formed:
• C-neighborhoods built according to pixel coordinates within the fil-
ter window.
• V-neighborhoods built according to pixel gray levels.
• R-neighborhoods built according to pixel ranks, that is, pixel posi-
tions in variational row.
• H-neighborhoods built according to pixel cardinalities.
• G-neighborhoods built according to pixel “geometrical” attributes, 
such as gradient or Laplacian, that are associated with properties of 
images regarded as 2D surfaces.
Table 8.2 presents a list of types of pixel neighborhoods most relevant for 
the design of nonlinear filters.
The selection of the neighborhood for the design of a particular filter 
is governed by a priori assumption regarding properties of objects in the 
image: their size and shape (C-neighborhoods), the spread of their gray lev-
els (EV-neighborhoods), the size and gray-level spread (KNV-neighborhood), 
and its counterparts (R-neighborhoods). Figure 8.25 illustrates forming 
EV-neighborhood for a fragment of an image of angiogram. It was gen-
erated using the MATLAB program neighborhoods_CRC.m provided in 
Exercises.
CL-neighborhood is an option that can be used when no a priori knowledge 
concerning spread of objects gray level is available and, from the other side, 
it is known that objects gray level may form “clusters,” that is, more or less 
well-distinguished hills, in image histograms as illustrated in Figure 8.26. 
Note that for better distinguishability of histogram clusters, it is frequently 
advisable to smooth window histograms using one or another data smooth-
ing filters, such as those described below in the section “Filter Classification 
Tables and Particular Examples.” This figure was also generated using the 
MATLAB program neighborhoods_CRC.m.

446
Theoretical Foundations of Digital Imaging Using MATLAB®
TABLE 8.2
Types of Neighborhoods Used in Nonlinear Filtering Algorithms
C-Neighborhoods: Pixel Coordinates as Attributes
Window-neighborhood: Wnbh
The primary neighborhood composed of all 
pixels of the filter window
KSN-neighborhood: KSNnbh(ak,l;K) 
Neighborhood composed of a given number 
K of pixels spatially closest to the given one
Shape-neighborhoods: SHnbh(ak,l,S)
Spatial neighborhood of a certain spatial 
shape and size of S pixels
Weighted C-neighborhoods
WKSNnbh(ak,l;{wm,n}) 
WSHnbh(ak,l;{wm,n}) 
RpKSNnbh(ak,l;{wm,n}) 
RpKSNnbh(ak,l;{wm,n})
KSN- and shape-neighborhoods with weight 
coefficients {wm,n} assigned to their pixels 
according to certain pixel attributes. If 
weight coefficients {wm,n} are noninteger 
numbers, pixels gray levels are multiplied 
by those coefficients (WKSNnbh). If weight 
coefficients {wm,n} are integer numbers, pixel 
gray levels are replicated accordingly thus 
producing correspondingly enlarged set of 
pixels (RpKSNnbh)
V-Neighborhoods: Pixel Gray Level as Attributes
Epsilon-V-Neighborhood of pixel ak:
EVnbh ak l
v
v
(
;
;
)
, ε
ε
+
−
A subset of filter window pixels with values 
{a} that satisfy the inequality:
a
a
a
k l
v
k l
v
,
,
.
−
≤
≤
+
−
+
ε
ε
Weighted V- (WV-) neighborhood: 
WVnbh(ak,l;w(v–ak,l))
Filter window pixels with weights {w(v–ak,l)} 
assigned according to their gray levels
Range-neighborhood: RNGnbh(k,l;Vmin,Vmax)
A subset of filter window pixels with gray 
levels am,nwithin a specified range 
[Vmin ≤ am,n ≤ Vmax]
“K nearest-by-value”-neighborhood of pixel ak,l:
KNVnbh(ak,l,K)
A subset of K filter window pixels with gray 
levels closest to that of pixel ak,l
R-Neighborhoods: Pixel Ranks as Attributes
“Epsilon-R”-neighborhood: ERnbh ak l
R
R
(
;
;
)
, ε
ε
+
−
A subset of filter window pixels with ranks 
{R(am,n)} that satisfy inequality:
R a
R a
R a
k l
R
m n
k l
R
(
)
(
)
(
)
,
,
,
−
≤
≤
+
−
+
ε
ε
Quantil-neighborhood: Qnbh(NBH,Rleft,Rright)
Filter window order statistics {
}
(
)
a Rn , whose 
ranks {Rn} satisfy inequality Rleft < Rn < Rright
H-Neighborhoods: Pixel Cardinalities as Attributes
“Cluster” neighborhood of pixel ak,l:
CLnbh(NBH;ak)
Neighborhood elements that belong to the 
same cluster of the histogram over the 
neighborhood as that of element ak,l.
G-Neighborhoods: Geometrical Attributes
“Flat”-neighborhoods: 
FLnbhL(ak,l,Thr) FLnbhG(ak,l,Thr)
Filter window pixels with values of absolute 
value of Laplacian (or module of gradient) 
lower than a certain threshold

447
Image Perfecting
G-neighborhoods such as “Flat”-neighborhood can be used to unify pixels that 
belong to more or less “flat” portions of images regarded as 2D surfaces.
Typical estimation operations used in known nonlinear filters are listed 
in Table 8.3. They are split into two groups: data smoothing operations and 
operations that evaluate data spread in the neighborhood.
In the filter design, the selection of estimation operation is, in general, gov-
erned by requirements of statistical or other optimality of the estimate at the 
filter output. For instance, if data are observations of a single value distorted 
by an additive uncorrelated Gaussian random noise, arithmetic MEAN over 
the data is an optimal MAP of this value. It is also an estimate that mini-
mizes mean squared deviation of the estimate from the data. PROD is an 
Input image and selected fragment
40
30
20
10
050
100
150
Gray level
EV-neighborhood; EV+= 10; EV–= 20
Filter window 39 × 39
Filter window histogram
and EV-nbh borders
FIGURE 8.25
​An illustrative example of EV-neighborhood for a fragment (upper right image) of an image of 
angiogram (upper left image with the fragment highlighted). The bottom left graph shows image 
fragment histogram with EV-neighborhood borders (dotted line with triangle markers) and win-
dow central pixel gray level indicated by dotted lines without marker. The bottom right image 
represents the selected EV-neighborhood; pixels that do not belong to it are shown dark black.

448
Theoretical Foundations of Digital Imaging Using MATLAB®
operation homomorphic to the addition involved in MEAN operation: the 
sum of logarithms of a set of values is the logarithm of their product.
ROS operations might be optimal MAP-estimations for models other than 
additive Gaussian noise models. For instance, if neighborhood elements are 
observations of a single value distorted by the addition of independent ran-
dom values with exponential distribution density, MEDN over the data is 
known to be optimal MAP-estimation of this value. It is also an estimate 
that provides the minimum to average of absolute values of its deviation 
Input image and selected fragment
Smoothed window histogram
and cluster borders
40
35
30
25
20
15
10
5
0
50
100
150
Gray level
200
CI-neighborhood, Vleft = 20; Vright = 101
Filter window 39 × 39
FIGURE 8.26
​An illustrative example of CL-neighborhood for a fragment (upper right image) of a micro-
scopic image (upper left image with the fragment highlighted). The bottom left plot presents 
image fragment histogram smoothed for better distinguishability of histograms clutters. 
Dotted lines with triangle markers show left and right borders of the histogram clutter that 
corresponds to dark particles in the image. Dotted lines without marker indicate gray level 
of the fragment central pixel outlined in the upper right image by the white square. The bot-
tom right image represents the selected CL-neighborhood; pixels that do not belong to it are 
shown dark black.

449
Image Perfecting
from the data. If additive noise distribution is one sided, MIN or MAX might 
be optimal estimations. MODE can be regarded an operation of obtaining 
MAP-estimation if the distribution histogram is considered to be a posteriori 
distribution of signal gray levels.
RAND is a “stochastic” estimation operation. It generates an estimate 
that, statistically, is equivalent to all the above “deterministic” estimates: 
it has the same mean, standard deviation, and all other distribution 
moments. Images presented in Figure 8.27 clearly show that the replace-
ment of image samples with pseudorandom numbers by RAND-operation 
may provide a reasonably good estimate of pixel gray levels from pixel 
neighborhoods.
It is especially true for higher-order neighborhoods. For instance, one can 
hardly distinguish image visually (a) and image (c) obtained from pseudorandom 
TABLE 8.3
​Estimation Operations
Operation
Denotation
Definition
SMTH (NBH): Data Smoothing Operations
Arithmetic and geometric 
mean 
MEAN(NBH)
Arithmetic mean of samples of the 
neighborhood
GMEAN(NBH)
Product of samples of the neighborhood
Order statistics
K_ROS(NBH)
Value that occupies the K-th place (has 
rank K) in the variational row over the 
neighborhood. Special cases:
MIN(NBH)
Minimum over the neighborhood (the 
first term of the variational row)
MEDN(NBH)
Central element (median) of the 
variational row
MAX(NBH)
Maximum over the neighborhood (the 
last term of the variational row)
Histogram mode
MODE(NBH)
Value of the neighborhood element with 
the highest cardinality:
MODE(NBH) = arga max(HISTNBH(a))
Random number over 
neighborhood
RAND(NBH)
A pseudorandom number taken from an 
ensemble with the same gray level 
distribution histogram as that of 
elements of the neighborhood
SPRD(NBH): Operations that Evaluate the Spread of Data within the Neighborhood
Standard deviation 
STDEV(NBH)
Pixel gray level standard deviation over 
the neighborhood
Interquantil distance 
(quasispread)
IQDIST(NBH)
R_ROS(NBH) – L_ROS(NBH), where 
1 ≤ L < R ≤ SIZE(NBH)
Range 
RNG(NBH)
MAX(NBH) - MIN(NBH)
Neighborhood size
SIZE(NBH)
Number of elements of the 
neighborhood

450
Theoretical Foundations of Digital Imaging Using MATLAB®
numbers that have the same local histograms over EV-neighborhood for 
ε
ε
v
v
+
−
=
= 10 gray levels as the image (a). The difference (d) between these two 
images looks almost chaotic, which means that no substantially important 
visual information is lost in the image (c).
All the above-mentioned operations belong to a class of data smoothing 
operations. We will use a common denotation SMTH estimation opera-
tion for them. The rest of the operations generate numerical measures of 
neighborhood data spread. We will use a common denotation SPRD opera-
tion for them. Their two modifications, “interquantil distance” IQDIST and 
“range” RNG, are recommended as a replacement for standard deviation for 
the evaluation of spread of data. The SIZE operation computes the number 
of samples in the neighborhood, when it does not directly follow from the 
neighborhood definition.
FIGURE 8.27
​Illustration of RAND(NBH) operation: (a) initial test image with 256 quantization levels; (b) 
result of applying operation to the initial image RAND(KSN) in the filter window of 7 × 7 pix-
els; (c) result of applying to the initial image operation RAND(EV-nbh) in the filter window of 
7 × 7 pixels and ε
ε
v
v
+
−
=
= 10; (d) difference between images (a) and (c); standard deviation of 
the difference is 5.6 (in units of the image range 0–255).

451
Image Perfecting
Filter Classification Tables and Particular Examples
Tables 8.4 and 8.5 list the most known nonlinear filters. Filters presented 
in Table 8.4 are intended for cleaning images from noise and other foreign 
contaminations. The simplest local mean filter, MSE-optimal and local adap-
tive linear filters described in the sections “Optimal Linear Filters for Image 
Restoration” and “Sliding Window Transform Domain Adaptive Image 
Restoration” can be regarded in such a classification as special cases of gen-
eral nonlinear filters. Other C-neighborhood data smoothing filters: “percentile” 
filters and adaptive mode quantization filter are robust to outliers alternatives to 
the local mean filter. The most popular from them are median filter and mor-
phological filters. The most representative from V-neighborhood data smoothing 
filters are KNV-mean and EV-mean, or the sigma filter. The so-called bilateral 
filter is a kind of a “softened” modification of the “sigma” filter, in which 
uniform weights in the range a
a
a
k l
v
k l
v
,
,
−
≤
≤
+


−
+
ε
ε
 are replaced by “soft” 
weights w v
a
v
a
k l
k l
v
v
(
)
exp (
)
,
,
−
=
−


2
2
2
2
σ
πσ .
Examples of robust to outliers data smoothing filters, which reject outliers 
on the basis of pixel ranks, are R-neighborhood filters: alpha-trimmed mean 
and alpha-trimmed median filters.
In principle, the specification of filter parameters requires knowledge of 
true pixels gray levels, which is, of course, unavailable as far as images are 
contaminated with noise that should be cleaned out by the filtering. Escape 
out of this vicious circle lies in iterative filtering:
	
ˆ
(
),
( )
(
)
a
NBH
k
t
t
=
−
ESTM
1
	
(8.76)
where subscript t is an iteration index. With infinitely large number of iter-
ations, filter outputs may arrive at the so-called filter “fixed” points. Filter-
fixed point is an image, which the filter does not change. It is a kind of an 
“eigen” function of the filter. Trivial fixed points of all described smooth-
ing filters are, obviously, constants. Nontrivial fixed points of many of the 
smoothing filters are piece-wise constant images, as it is illustrated for filter 
MODE(Wnbh) in Figure 8.28.
Filter MODE(Wnbh) is a very hard smoother. Its natural application is image 
segmentation. Other smoothing filters listed in Table 8.4 are softer and can 
be used for edge-preserving noise cleaning. The simplest of them and very 
popular median filter, as well as other “percentile” filters, apparently do not 
have a nontrivial fixed point. They can be used for noise cleaning in a non-
iterative manner. In particular, median filter is especially efficient as robust 
substitutes for local mean filters in cleaning images from additive noise with 
outliers and for the detection of outliers in images by means of comparing 
with a threshold of difference between images and their smoothed copies.
Figure 8.29 illustrates the application of the median filter for removing 
banding noise in an image that contains contrast fiducial marks that must be 

452
Theoretical Foundations of Digital Imaging Using MATLAB®
TABLE 8.4
​Image Smoothing Filters
C-Neighborhood Filters
Moving average 
(local mean) 
filter
ˆa
Wnbh
k = MEAN(
)
MSE-optimal and 
local adaptive 
linear filters
ˆ
MEAN
a
WKSNnbh
k =
(
)  
weight coefficients of WKSN-neighborhood are determined by 
correlation functions (or power spectra) of images and noise as it is 
described in the sections “Optimal Linear Filters for Image 
Restoration” and “Sliding Window Transform Domain Adaptive 
Image Restoration”
“Percentile” 
filters
ˆ
_
a
KSNnbh
k = K
ROS(
)
Median filter 
ˆa
Wnbh
k = MEDN(
)
MAX filter 
ˆa
Wnbh
k = MAX(
)
MIN filter
ˆa
Wnbh
k = MIN(
)
Weighted ROS- (median, 
min, max, .. .) filters
ˆ
_
a
RpKSNnbh
k = K
ROS(
)
“Morphological”  Erosion 
filters 
ˆa
SHnbh
k = MAX(
)
Dilation
ˆ
MIN
a
SHnbh
k =
(
)
Adaptive mode 
quantization 
filter 
ˆ
MODE
a
Wnbh
k =
(
)
V-Neighborhood Filters
KNV-mean filter
ˆ
MEAN(
(
;
));
a
KNV a
K
k
k
=
  K is a filter parameter
EV-mean filter 
(the “Sigma” 
filter)
ˆ
MEAN(
(
;
;
;
));
a
EVnbh Wnbh a
k
k
V
V
=
+
−
ε
ε
   ε
ε
V
V
+
−
;
 are filter parameters
C-Neighborhood Filters
“Bilateral” filter
ˆ
MEAN(
(
;
;
(
)))
,
,
a
WVnbh Wnbh a
w v
a
k
k l
k l
=
−
; 
w v
a
v
a
k l
k l
v
v
(
)
exp (
)
,
,
−
=
−


2
2
2
2
σ
πσ ;  σν is a filter parameter
“Modified” 
trimmed mean 
filter 
ˆ
MEAN(EV(MEDN(
);
;
)))
a
Wnbh
k
V
V
=
+
−
ε
ε
;  ε
ε
V
V
+
−
;
 are filter 
parameters
R-Neighborhood Filters
“Alpha”-trimmed 
mean, median
ˆ
MEAN(
(
,
,
))
a
Qnbh Wnbh R
R
k
left
right
=
;
ˆ
MEDN(
(
,
,
))
a
Qnbh Wnbh R
R
k
left
right
=
 
, Rleft,Rright are filter parameters

453
Image Perfecting
preserved. The filtering algorithm is similar to that illustrated in Figure 8.4, 
except the row-wise mean is replaced by the local median in row-wise- and 
column-wise-oriented rectangular windows.
More efficient image noise cleaners are V-neighborhood filters, especially 
the “sigma” filter. One can compare the noise-cleaning capability of iterative 
median and sigma filters in Figure 8.30.
The fixed points of the “sigma” filter are piece-wise images, provided 
appropriately selected filter parameters (filter window and borders of 
EV-interval). Therefore, “sigma” filters, when applied as noise cleaners, tend 
to generate piece-wise constant images. Another limitation of the applica-
bility of “sigma” filters as noise cleaners is that they are incapable of clean-
ing impulse noise, because EV-neighborhood for pixels distorted by impulse 
noise may not contain any pixel except the given one if noise outburst con-
trast exceeds the EV interval of the filter.
The described algorithms are most suitable for smoothing image contami-
nations that can be regarded as being additive. In cases when a model of 
impulse noise is more appropriate for noise contaminations, noise clean-
ing filters should be built as two stages: (i) contamination detection and (ii) 
smoothing.
TABLE 8.5
​Image Enhancement Filters
Local Contrast Enhancement Filter
“Unsharp masking”
ˆ
(
)
SMTH(
,
)
,
,
,
,
a
g a
g a
NBH a
k l
k l
k l
k l
=
−
+
−


1
; g is user 
defined local contrast amplification parameter
Local histogram equalization
ˆ
SIZE(
) RANK(
)
,
max
min
min
a
a
a
NBH
NBH
a
k l =
−
+
Weighted local histogram 
equalization
ˆ
(
) RANK(
)
,
max
min
min
a
a
a
RpKSNnbh
RpKSNnbh
a
k l =
−
+
SIZE
Local p-histogram equalization
ˆ
pRANK(
)
,
,
max
min
min
a
a
a
pK
NBH
a
k l =
−
+
 where 
pRANK(
)
( );
( );
min
min
max
NBH
HIST
a
pK
HIST
a
NBH
p
v a
a
p
v a
a
=
=
=
=
∑
∑
 
 
p is a user-defined enhancement parameter (0 ≤ p ≤ 1)
Edge Extraction Filters
Local variance filter
ˆ
STDEV
a
Wnbh
k =
(
)
Quasirange filter; Max-min filter
ˆ
QSRNG
,
a
NBH
k l =
=
(
)
 R_ROS(Wnbh) - L_ROS(Wnbh)
ˆ
MAX
MIN
a
NBH
NBH
k =
(
)
(
−
Size-EV filter
ˆ
SIZE(
(
;
;
;
))
,
,
a
EVnbh Wnbh a
k l
k l
V
V
=
+
−
ε
ε
Local cardinality filter
ˆ
HIST
,
a
Wnbh a
k
k
=
(
)

454
Theoretical Foundations of Digital Imaging Using MATLAB®
This principle is described by the equations
	
ˆ
(
) SMTH
(
(
)),
,
,
est
,
a
sw a
sw
NBH a
k l
k l
k l
=
⋅
+
−
⋅
1
	
(8.77)
where sw is a binary switch variable
	
sw
a
NBH
a
k l
k l
=
∈



1
0
,
(SMTH
(
))
,
,
,
det
,
otherwise
	
(8.78)
Mode(Wnbh): initial (left) and iterated (right) images; 50-th iteration
(a)
(b)
ModeI(Wnbh): StDev(INPIMG-OUTIMG)
17.5
17
16.5
16
15.5
15
14.5
14
13.5
12.5
0
5
10
Iterations
15
20
25
13
FIGURE 8.28
​Piece-wise constant image (a) (right) obtained after 25 iteration of filter MODE(Wnbh) for filter 
window of 3 × 3 pixels applied to an initial image (a) (left) and plot of standard deviation of 
the difference between initial and iterated images (b) as a function of the number of iterations, 
which proves the filter convergence to a fixed point.

455
Image Perfecting
where SMTHest(⋅) and SMTHdet(⋅) are, respectively, estimation and detection 
smoothing operations, for which one of the smoothing filters from Table 8.4 
can be used, and NBHdet(SMTHdet(ak,l)) is a “detection” neighborhood formed 
around the (k,l)-th pixel smoothed by the detection smoothing operation.
Typical image enhancement nonlinear filters are listed in Table 8.5. The fil-
ters are classified into two groups: local contrast enhancement filters and edge 
extraction filters. Local contrast enhancement filters are intended to make vis-
ible objects that might not be visible in the initial images because their contrast 
with respect to their background is lower than the contrast sensitivity of vision. 
There are at least two ways to achieve this goal. The first one is “unsharp” mask-
ing. With unsharp masking, the difference is amplified between initial images 
and their smoothed copies, which are used as estimates of objects’ background. 
For the smoothing, one of the smoothing filters described in Table 8.4 can be 
used. Images in Figure 8.31 illustrate this method.
The second group of methods for local contrast enhancement form meth-
ods in which image gray levels are subjected to a point-wise transformation 
with a transfer function, whose slope, for a given gray level, is determined by 
the image histogram: the greater the gray level rate in the image the greater 
is the amplification of local gray level contrasts for these gray levels. The 
most important representative of this group is p-histogram equalization, in 
which the transfer function slope is proportional to p-th certain power of the 
image histogram. It can be applied both globally to the entire image frame 
and locally in sliding window. In the latter case, we call them local p-histo-
gram equalization. The term “equalization” stems from the fact that when p = 1 
such transformation converts images with an arbitrary histogram to images 
with the uniform histogram (in fact, almost but not exactly uniform due to 
effects of quantization). This particular transformation of image gray levels 
FIGURE 8.29
​Fiducial marks (dark crosses) robust filtering banding noise in an image of Mars surface 
returned from the Soviet space probe Mars-4: left—initial distorted image; middle—image 
after removal vertical bands by subtracting from the initial image its local median in the win-
dow of 170 × 3 pixels; right—image after subsequent removal of horizontal bands by subtract-
ing from the previous image its local median in the window of 3 × 257 pixels (image size is 
512 × 512 pixels).

456
Theoretical Foundations of Digital Imaging Using MATLAB®
FIGURE 8.30
​(a) Comparison of noise-cleaning capabilities of iterative application of median and sigma fil-
ters. First (from top to bottom) row: a test image (left) and its copy with additive uniformly 
distributed in the range (0–20) noise (right). Second row: iterated median-filtered image after 
75 iterations (left) with filter window 3 × 3 pixels and its difference from the initial noisy image 
(right); note the difference in image bright points from corners of patches, which were removed 
from the image. Third row: iterated median-filtered image after 75 iterations with filter win-
dow 5 × 5 pixels (left) and its difference from the initial noisy image (right); note further losses 
in patch corners and corresponding image blur. Fourth and fifths rows: iterated sigma-filtered 
images after 75 iterations with ε
ε
V
V
+
−
=
= 12 gray levels and filter window 3 × 3 and 5 × 5 pix-
els, respectively (left) and their corresponding differences from the initial noisy image (right); 
note the preservation of edges of patches that have sufficient contrast. (b) Plot of the difference 
between initial noisy and iterated sigma-filtered image for 3 × 3 filter window that demon-
strates that after 75 iteration filtering has reached the filter-fixed point.

457
Image Perfecting
is called histogram equalization. One of the immediate applications of histo-
gram equalization is image dynamic range blind calibration, which we men-
tioned in the section “Correcting Image Grayscale Nonlinear Distortions.”
In the case p = 0, the transformation stretches linearly the dynamic range 
of the image to the entire dynamic range available for image display:
	
ˆ
(
)
,
,
max
min
,
min
a
a
a
MAX
MIN a
MIN
a
k l
k l
=
−
−
−
+
	
(8.79)
FIGURE 8.31
​Local contrast enhancement of a test image of 256 × 256 pixels (left) by means of unsharp mask-
ing using local mean (middle) and local median (right) in the window 7 × 7 pixels with param-
eter g set to 1.
Mean EV iter: Stdev(INPIMG-OUTIMG)
(b)
10
9
8
Standard deviation
7
6
5
4
10
20
30
Iteration
40
50
60
70
FIGURE 8.30
Continued.

458
Theoretical Foundations of Digital Imaging Using MATLAB®
where (amax,amin) are maximal and minimal gray levels for image display 
(usually 0 and 255) and (MAX,MIN) are maximal and minimal gray lev-
els of the input image, or, respectively, image fragment in the filter window 
if the filter is applied locally in a sliding window. Intermediate values of 
p enable flexible, using only one parameter, control of image local contrast 
enhancement.
The histogram equalization can be treated as converting image gray-level 
contrasts into contrast in terms of pixel ranks. As we indicated in section 
“Design of Optimal Quantizers” (Chapter 3), histogram p-equalization and, 
in particular, histogram equalization can also be interpreted in terms of sig-
nal optimal quantization.
We illustrate image local contrast enhancement by means of global and 
local p-histogram equalization in windows of different sizes in Figure 8.32. 
Figure 8.32 shows how image local histogram equalization can make vis-
ible invisible low-contrast texture in a test image and how processing with 
differently oriented windows reproduces differently oriented contrast 
patches.
Figure 8.33 demonstrates the effects of applying global and local histo-
gram p-equalization for improving the visibility of blood vessels and other 
low-contrast details in a real x-ray image of a woman’s breast (mammogram).
Edge extraction nonlinear filters are exemplified by filters that measure the 
local spread of data: the local variance filter and its robust to outliers substitute 
local quasispread filter, the max-min filter, which is a special case of the quasis-
pread filter, the size-EV filter and the local cardinality filter, which, in its turn, 
can be regarded as a special case of the size-EV filter, when its EV-interval is 
set to zero. Figure 8.34 illustrates the performance of these filters on an exam-
ple of detection of edges in a microscopic image of a crystalline structure.
Images for Figures 8.32 through 8.34 were generated using the MATLAB 
program enhancement_demo_CRC.m provided in Exercises.
Nonlinear Filters for Multicomponent Images
The above-described classes of nonlinear filters are intended for working 
with single-component grayscale images. An immediate and trivial option 
for their usage for multicomponent images is separable, that is, component-
wise, filtering. For nonseparable applications, notions of pixel attributes, 
neighborhood, and estimation operation must be revisited. Some of them 
are equally relevant to both single-component and multicomponent images. 
These are attributes “coordinates” and “cardinality,” C-neighborhoods (“win-
dow-”, KSN-, and “cluster”-neighborhoods), arithmetic mean MEAN(NBH), 
histogram mode MODE(NBH), and RAND(NBH). The design of correspond-
ing unseparable nonlinear filters based on these pixel attributes, neighbor-
hoods, and estimation operations is straightforward. Most of the others pixel 
attributes, neighborhoods, and estimation operations need to be defined, an 
introduction of certain scalar measures over image components that would 

459
Image Perfecting
numerically evaluate variations of vector of components. These measures are 
essentially determined by the specificity of image components. No general 
approach seems feasible to their definitions and each particular case must be 
treated ad hoc.
FIGURE 8.32
Amplification of local contrasts by means of local histogram equalization in windows of 
approximately same size and different shape: (a) test image that contains an invisible low-
contrast periodical texture with maximal amplitude 5 gray levels (out of 256); (b)–(f) results 
of local histogram equalization in different windows: square of 15 × 15, a rectangle of 71 × 3 
pixels rotated by 45°, a horizontal rectangle of 3 × 71 pixels, a rectangle of 71 × 3 pixels rotated 
by −45° and vertical rectangle of 71 × 3 pixels, respectively.

460
Theoretical Foundations of Digital Imaging Using MATLAB®
Display Options for Image Enhancement
The way, in which images are displayed, is a very important aspect of image 
enhancement. As it was mentioned, in image enhancement, all capabilities 
of human visual system must be employed: the capability to distinguish 
colors, the capability of 3D perception through stereo vision, and the capa-
bility to sense temporal changes. These capabilities open up to five channels 
to the human brain: three RGB (red–green–blue) channels, two stereoscopic 
channels through two eyes, and one temporal channel. When displaying 
grayscale images for visual analysis, one can employ these channels to con-
vey information to the visual cortex of the brain. This can be achieved using 
the following methods of such a multichannel displaying grayscale images:
• Pseudocolor display
• Image colorization
• Image stereo-visualization
• Image animation
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
00
50
100
Gray level
Histogram
Transformation
look-up table
150
200
250
(a)
(b)
FIGURE 8.33
Enhancement of local contrasts of a mammogram (a, upper left image). (a) Global (upper right 
image) and local p-histogram equalization in windows 91 × 91 and 31 × 31 pixels (accordingly, 
bottom left and right images); (b) image histogram and transformation transfer function (look-
up table), both normalized to one. P = 0.5, image size 892 × 470 pixels.

461
Image Perfecting
In pseudocolor display method, grayscale images are reproduced as artifi-
cial RGB color images by means of encoding image gray levels within their 
dynamic range, say 0–255, by a certain color, that is, by one of 256 appropri-
ately selected combinations of gray levels of the artificial RGB components. 
Thanks to the high sensitivity of human visual system to color variations, this 
method helps to visually distinguish grayscale image variations otherwise not 
visible by virtue of limited grayscale contrast sensitivity of vision. Figure 8.35 
illustrates how the pseudocolor representation of the test image from Figure 
8.32a makes visible an invisible low-contrast periodic texture of the test image.
Image colorization is a method of simultaneous displaying in one synthetic 
color image up to three versions of image enhancement results by means of 
assigning each version to one of three RGB components of the synthetic color 
image. This way of displaying enables parallel analysis of different versions 
of image enhancement that may represent different features of images useful 
for visual image analysis. Figure 8.36 illustrates this method on an example 
of displaying different versions of enhancement of the mammogram shown 
in Figure 8.33.
Stereo-visualization is a method of simultaneous representation of two ver-
sions of enhancement or feature extraction of an image. For this, from initial 
two image versions, an artificial stereoscopic pair is generated, in which the 
intensity of images is defined by the first input image version and parallax, or 
mutual displacement between of corresponding points of images of the pair, 
is defined by the second input image version treated as an image depth map.
FIGURE 8.34
​Edge extraction on an example of a microscopic image of a crystalline structure: (a) initial 
image; (b) max-min filter; (c) size-EV filter; (d) local cardinality filter. In all cases, filter window 
size 3 × 3 pixels; borders of EV-neighborhood for the size-EV are (+7, − 7) gray levels.

462
Theoretical Foundations of Digital Imaging Using MATLAB®
Image animation enables visual analysis of many versions of image 
enhancement, for instance, local histogram p-equalization in windows of 
different sizes, by means of representing different image versions as frames 
of an artificial video sequence.
Obviously, these visualization methods can be used in combination. 
Methodologically, these methods can be treated as representatives of a class 
of nonlinear filters, which change the number of image components.
FIGURE 8.36
(See color insert.) Colorization of enhanced versions of mammogram shown in Figure 8.33: the 
lower right version is shown in red, the upper right version is shown in green, and the initial 
image (upper left) is shown in blue.
FIGURE 8.35
​(See color insert.) Pseudocolor representation of the test image of Figure 8.32a, which contains 
an invisible low-contrast periodical texture. Color bar to the right shows color coding table for 
image gray levels.

463
Image Perfecting
Appendix
Derivation of Equation 8.16
   
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
α
η β
α
η β
α
η β
r
r
r
r
N
r
r
r
r
r
r
−






=
−
−
=
−
∗
∗
∗
∑
2
0
1
(
)(
)
r
N
r
r
r
r
r
r
r
r
r
r
=
−
∗
∗
∗
=
∑








=
−
−
+
(
)
0
1
2
2
2
0
AV
AV
A
N
Ω
Ω
α
η α β
η α β
η
β
N
r
r
re
r
im
r
r
r
re
i
i
−
∗
∑






=
−
+
(
)
−
−
1
2
AV
AV
A
N
Ω
Ω
α
η
η
α β
η
(
)
(
)
(
)
η
α β
η
η
β
r
im
r
r
r
N
r
re
r
im
r
(
)
(
)
(
)
(
)
(







+
+
(
)
)





∗
=
−
∑
0
1
2
2
2


.
	
(A8.1)
Compute partial derivatives of this expression over real ηr
re
(
) and imagi-
nary ηr
im
(
) parts of ηr and equal those to zero to obtain ηr
opt
(
)
{
} that minimize 
it:
	
∂
∂
−






=
−
−
=
−
∗
∗
∑
η
α
η β
α β
α β
r
re
r
r
r
r
N
r
r
r
r
(
) AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
2
0
1
+
(
)
=
−
+


=
∗
2
2
2
2
2
2
η
β
α β
η
β
η
r
re
r
r
r
r
re
r
r
re
(
)
(
)
(
)
Re(
)
AV
AV
A
A
N
Ω
Ω
V
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
β
α β
r
r
r
2
2
0
(
) −

=
∗
Re
(
)
	
(A8.2)
from which it follows that
	
η
α β
β
r
re opt
r
r
r
(
,
)
Re
(
)
.
=


(
)
∗
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
2
	
(A8.3)

464
Theoretical Foundations of Digital Imaging Using MATLAB®
Similarly, one can obtain
	
η
α β
β
r
im opt
r
r
r
(
,
)
Im
(
)
.
=


(
)
∗
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
2
	
(A8.4)
Therefore
	
η
α β
β
r
opt
r
r
r
(
)
(
).
=
(
)
∗
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
2
	
(A8.5)
Empirical Estimation of Variance of Additive Signal-Independent 
Broad Band Noise in Images
Additive signal-independent zero mean noise with normal distribution is 
fully specified by its standard deviation and autocorrelation function. If the 
noise is uncorrelated or weakly correlated (broad band), as is often the case, 
then its variance and correlation function can be found by means of the fol-
lowing simple algorithm based on detecting and measuring abnormalities in 
the covariance function of the observed image.
By the definition (Equation 2.110), the correlation function of signal {bk} 
obtained as an additive mixture
	
b
a
n
k
k
k
=
+
	
(A8.6)
of an “ideal” signal {ak} and signal-independent noise zero mean noise {nk} is
R
N
b a
N
a a
b
k
k
k
N
k
k
( )
κ
κ
κ
=














=
+
∗
=
−
+
∗
∑
AV
AV
AV
A
N
A
Ω
Ω
Ω
1
1
0
1
k
N
k
k
k
N
k
N
n n
N
a
n
=
−
+
∗
=
−
∑
∑





+






+
0
1
0
1
1
1
AV
AV
AV
N
A
N
Ω
Ω
Ω
κ
(
)
(
k
k
N
k
k r
k
N
a
n
N
a
n
R
R
+
∗
=
−
∗
+
=
−
∑
∑
+
=
+
κ
κ
κ
)
(
)
(
)
( )
( ),
0
1
0
1
1
AV
AV
A
N
Ω
Ω
	
(A8.7)
where AV
AV
Ω
Ω
N
N
n
n
k
k
(
)
(
)
+
+
∗
=
=
κ
κ
0 as mean values of zero mean noise, Ra(κ) 
is the correlation function of the noiseless signal, and Rn(κ) is the correlation 
function of the noise.

465
Image Perfecting
Consider the uncorrelated (white) noise case when
	
Rn
n
n
( )
( )
,
,
,
λ
σ δ κ
σ
κ
κ
=
=
=
>



2
2
0
0
0
	
(A8.8)
where σn
2 is the noise variance. In this case, the correlation function Rb(κ) of 
the observed image deviates from the correlation function Ra(κ) of the noise-
less image in the coordinate origin only:
	
R
R
R
b
a
n
a
( )
( )
,
( ),
.
κ
κ
σ
κ
κ
κ
=
+
=
>



2
0
0 	
(A8.9)
Therefore, one can estimate the value Ra(0) for k = 0 by means of extrapolat-
ing values of Rb(κ) = Ra(κ) for κ > 0 and then use the extrapolated value ˆ ( )
Ra 0  
to compute an estimate ˆσn
2 of noise variance as
	
ˆ
( )
ˆ ( ).
σn
b
a
R
R
2
0
0
=
−
	
(A8.10)
This is well illustrated in Figure A8.1 generated using the program 
NoiseVar_CRC.m (Exercises). Correlation functions of images are normally 
quite smooth functions in the vicinity of the coordinate origin (κ = 0). This 
property enables obtaining sufficiently accurate estimates of the noise vari-
ance using, for extrapolation, a few samples of Rb(κ). For instance, the data 
presented in Figure 8.2 for noisy images were obtained by means of evalu-
ating 1D correlation functions of images through inverse DFT of the mean 
of power spectra of image rows, which implements image ensemble aver-
aging AV
A
Ω
Σ
(
)
1
0
1
/
(
)
=
−
+
∗
N
a a
k
N
k
k κ , and subsequent extrapolation of Rb(0) from 
Rb(1) and Rb(2) using a parabolic approximation of Rb(κ) in the vicinity of 
point κ = 0:
	
ˆ ( )
( )
( ).
R
R
R
a
b
b
0
4
3
1
1
3
2
=
−
	
(A8.11)
A similar approach can be used for the estimation of the correla-
tion  function of a weakly correlated (broad band) noise, that is, a 
noise  whose ­correlation function Rn(κ) is known to be concentrated 
in only a few first  samples of Rn(κ). Estimates of these samples can be 
obtained as ­differences between image empirical correlation function 
Rb(κ) in those samples and their values extrapolated from the rest of the 

466
Theoretical Foundations of Digital Imaging Using MATLAB®
samples of Rb(κ), in which noise correlation function values are known to 
be negligible.
Derivation of Equation 8.45
The DCT spectra coefficients of signal samples {ak} in the sliding window of 
(2Nw + 1) samples centered at the k-th sample are defined as
	
β
π
r
k
w
k N
n
w
n
N
N
a
n
N
r
w
w
( )
cos
.
=
+
+
+




−
+
=∑
1
2
1
1 2
2
1
0
2
Noiseless image
1D correlation function
6000
7000
5000
4000
3000
2000
1000
0
5
10
15
Displacement
Input image. Noise stand. dev. = 39.8731
1D correlation function. Estimated noise stand. dev. = 39.9679
9000
8000
7000
9000
5000
4000
3000
2000
1000
0
2
4
6
8
Displacement
10
12
14
16
(a)
(b)
(c)
(d)
FIGURE A8.1
​Noiseless and noisy images (left column) and their row-wise 1D correlation functions (right 
column); for the noisy image, empirical estimate of standard deviation of noise is indicated 
in the image title.

467
Image Perfecting
By the definition of inverse DCT:
	
a
N
n
N
r
k N
n
w
k
r
k
w
r
N
w
w
−
+
=
=
+
+
+
+









∑
1
2
1
2
1 2
2
1
0
1
2
β
β
π
( )
( ) cos



.
Therefore, the window central pixel ak can be found as
	
a
N
N
N
r
k
w
k
r
k
w
w
r
Nw
=
+
+
+
+












=∑
1
2
1
2
1
2
2
1
0
1
2
β
β
π
( )
( ) cos
/
=
+
+












=
+
=∑
1
2
1
2
2
1
2
1
0
1
2
0
N
r
N
w
k
r
k
r
N
w
k
w
β
β
π
β
( )
( )
(
cos
)
( )(
)
+
−








=∑
2
1
2
1
β s
k
s
N
s
w
	.
1D correlation function
Input image
(e)
(f)
(g)
(h)
900
800
700
600
500
400
300
200
100
0
1800
1600
1400
1200
1000
800
600
400
200
0
2
4
6
8
Displacement
10
12
14
16
2
4
6
8
Displacement
1D correlation function. Estimated noise stand. dev. = 31.3423
Input image. Noise stand. dev. = 30.0675
10
12
14
16
FIGURE A8.1
Continued.

468
Theoretical Foundations of Digital Imaging Using MATLAB®
Derivation of Equation 8.51
Find the partial derivatives of functional
 	
AV
AV
A
N
Ω
Ω
α
η
β
 r
m
r
m n
r
n
n
M
r
N
(
)
(
, )
( )
−














=
=
−
∑
∑
1
2
0
1
	
over real and imaginary parts of thought weight coefficients ηr
m n
(
, )
{
} and 
equal them to zero:
	
∂
∂
−






−
=
∗
∑
η
α
η
β
α
η
r
re m l
r
m
r
m p
r
p
p
M
r
m
(
, )
(
)
(
, )
( )
(
)
AV
AV
A
N
Ω
Ω
1
r
m p
r
p
p
M
r
N
∗
∗
=
=
−
∑
∑




















(
, )
( )
β
1
0
1
	
=
∂
∂
−
−
=
η
α
η
β
η
β
r
re m l
r
m
r
re m p
r
p
r
im m p
r
p
p
i
(
, )
(
)
(
, )
( )
(
, )
( )
AV
AV
A
N
Ω
Ω
1
1
0
1
M
p
M
r
N
r
m
r
re m p
r
p
i
∑
∑
∑
=
=
−
∗
∗













×
−
+
α
η
β
(
)
(
, )
( )
η
β
r
im m p
r
p
p
M
p
M
(
, )
( )
∗
=
=
∑
∑













1
1
	
=
−
−
+
∗
∗
∗
=
AV
AV
A
N
Ω
Ω
β
α
η
β
η
β
r
l
r
m
r
re m p
r
p
r
im m p
r
p
p
M
i
( )
(
)
(
, )
( )
(
, )
( )
1∑
∑
=
∗










−
−
−
p
M
r
l
r
m
r
re m p
r
p
r
im m p
i
1
β
α
η
β
η
β
( )
(
)
(
, )
( )
(
, )
r
p
p
M
p
M
( )
=
=
∑
∑










1
1
	
= −
+
(
)
+
∗
∗
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
α
β
α
β
η
β
r
m
r
l
r
m
r
l
r
re m p
r
l
(
)
( )
(
)
( )
(
, )
( )β
β
β
r
p
r
l
r
p
p
M
∗
∗
=
+
(
)
∑
( )
( )
( )
1
	
−
−
(
)
=∑
i
r
im m p
p
M
r
l
r
p
r
l
r
p
η
β β
β
β
(
, )
( )
*( )
*( )
( ) .
1
AV
AV
A
N
Ω
Ω
	
(A8.12)
From this equation, it follows that
	
η
β
β
η
r
re m p
r
p
r
l
p
M
r
im m p
(
, )
( )
( )
(
, )
Re
I
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
∗
=
(
)
(
) +
∑
1
m
Re
( )
( )
(
)
( )
β
β
α
β
r
p
r
l
p
M
r
m
r
l
∗
=
∗
(
)
(
)
=
(
)
(
)
∑
1
AV
AV
A
N
Ω
Ω

	
(A8.13)

469
Image Perfecting
∂
∂
−






−
=
∗
∑
η
α
η
β
α
η
r
im m l
r
m
r
m p
r
p
p
M
r
m
(
, )
(
)
(
, )
( )
(
)
AV
AV
A
N
Ω
Ω
1
r
m p
r
p
p
M
r
N
r
i
∗
∗
=
=
−
∑
∑




















=
∂
∂
(
, )
( )
β
η
1
0
1
m m l
r
m
r
re m p
r
p
r
im m p
r
p
p
M
p
i
(
, )
(
)
(
, )
( )
(
, )
( )
AV
AV
A
N
Ω
Ω
α
η
β
η
β
−
−
=
=
∑
1
1
0
1
M
r
N
r
m
r
re m p
r
p
r
im
i
∑
∑














−

=
−
∗
∗
α
η
β
η
(
)
(
, )
( )
(m p
r
p
p
M
p
M
r
l
r
i
, )
( )
( )
(
β
β
α
∗
=
=
∗
∑
∑













=
−
1
1
AV
AV
A
N
Ω
Ω
m
r
re m p
r
p
r
im m p
r
p
p
M
p
M
i
)
(
, )
( )
(
, )
( )
−











∗
∗
=
=
∑
∑η
β
η
β
1
1

−
−



∗
=
=
∑
∑
i
i
r
l
r
m
r
re m p
r
p
r
im m p
r
p
p
M
p
M
β
α
η
β
η
β
( )
(
)
(
, )
( )
(
, )
( )
1
1








= −
−



∗
∗
 i
i
r
m
r
l
r
m
r
l
r
re m p
AV
AV
A
N
Ω
Ω
α
β
α
β
η
(
)
( )
(
)
( )
(
, )AV
AV
AV
A
N
A
Ω
Ω
Ω
β β
β
β
η
r
l
r
p
r
l
r
p
p
M
r
im m p
p
M
( )
( )
( )
( )
(
, )
∗
∗
=
=
−



∑
∑
1
1
AV
AV
AV
N
A
N
Ω
Ω
Ω
β β
β
β
α
β
r
l
r
p
r
l
r
p
r
m
r
l
i
i
( )
*( )
*( )
( )
(
)
( )
Im



= −

∗
 
2








∗
=∑
i
i
r
re m p
r
l
r
p
p
M
r
im m p
p
η
β β
η
(
, )
( )
( )
(
, )
Im
AV
AV
A
N
Ω
Ω
2
1
=
∗
∑




=




1
2
2
M
r
t
r
p
r
m
r
l
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
Re
Im
( )
*( )
(
)
( )
β β
α
β
−





∗
=
=
∑
∑
2
2
1
1
η
β β
η
r
re m p
r
l
r
p
p
M
r
im m p
p
M
(
, )
( )
( )
(
, )
Im
AV
AV
A
N
Ω
Ω
AV
AV
A
N
Ω
Ω
Re
( )
*( )
β β
r
l
r
p



 = 0
	
(A8.14)

470
Theoretical Foundations of Digital Imaging Using MATLAB®
from which it follows that
	
η
β β
η
r
re m p
p
M
r
l
r
p
r
im m p
p
M
(
, )
( )
*( )
(
, )
Im
=
=
∑
∑
(
)
(
) −
1
1
AV
AV
AV
A
N
A
Ω
Ω
ΩAV
AV
AV
N
A
N
Ω
Ω
Ω
Re
Im
.
( )
*( )
*(
)
( )
β β
α
β
r
l
r
p
r
m
r
l
(
)
(
)
=
(
)
(
)
	
(A8.15)
Multiplying this equation by (−i) and combining this with Equation A8.13, 
obtain
	
η
β
β
β
β
η
r
re m p
r
p
r
l
r
p
r
l
p
M
r
i
i
(
, )
( )
( )
( )
( )
Re
AV
AV
A
N
Ω
Ω
∗
∗
=
(
) −(
)
(
)
+
∑
1
m m p
p
M
r
l
r
p
r
p
r
l
i
(
, )
( )
*( )
*( )
( )
Re
Im
=∑
(
(
) +
(
))
=
1
AV
AV
AV
A
N
Ω
Ω
Ω
β β
β
β
A
N
AVΩ
Re
Im
(
)
( )
(
)
( )
α
β
α
β
r
m
r
l
r
m
r
l
i
∗
∗
(
) −
(
)
(
)
or
	
η
β β
η
r
re m p
p
M
r
p
r
l
r
im m p
p
M
i
(
, )
( )
*( )
(
, )
=
=
∑
∑
(
) +
1
1
AV
AV
AV
AV
A
N
A
Ω
Ω
Ω
ΩN
A
N
AV
AV
β β
α
β
r
p
r
l
r
m
r
l
( )
*( )
(
)
*( )
(
)
=
(
)
Ω
Ω
and finally
	
η
β β
α
β
r
m p
r
p
r
l
p
M
r
m
r
l
(
, )
( )
( )
(
)
( ) .
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
∗
=
∗
(
) =
(
)
∑
1
	
(A8.16)
Cross-correlations 
AV
AV
A
N
Ω
Ω
β β
r
p
r
l
( )
( )
∗
(
) and AV
AV
A
N
Ω
Ω
α
β
r
m
r
l
(
)
( )
∗
(
) are, 
according to Equation 8.57
 
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
β β
λ
α
ν
λ
α
r
p
r
l
r
p
r
p
r
p
r
l
r
( )
( )
( )
( )
( )
( )
(
∗
∗
∗
(
)
=
+
(
)
l
r
l
r
p
r
l
r
p
r
l
r
l
r
p
)
( )
( )
( )
( )
( )
( )
( )
+
(
)
(
)
=
+
∗
∗
∗
∗
ν
λ
λ
α
α
λ
ν α
AV
AV
A
N
Ω
Ω
r
l
r
p
r
l
r
p
r
p
r
l
r
p
r
l
r
p
∗
∗
∗
∗
+
+
(
)
=
( )
( )
( )
( )
( )
( )
( )
( )
( )
λ
ν
α
ν
ν
λ
λ
α
AV
A
Ω
α
λ
α
ν
λ
α
r
l
r
l
r
l
r
p
r
p
r
p
∗
∗
∗
(
) +
(
)
(
)
+
(
)
( )
( )
( )
( )
( )
( )
AV
AV
AV
AV
A
N
A
Ω
Ω
Ω
ΩΩ
Ω
Ω
N
N
A
AV
AV
ν
ν
ν
λ
λ
α
α
r
l
r
p
r
l
r
p
r
l
r
p
r
l
∗
∗
∗
∗
(
) +
(
)
=
(
)
( )
( )
( )
( )
( )
( )
( ) +



n
p
l
p
2( ) (
)
	(A8.17)

471
Image Perfecting
	
AV
AV
AV
AV
A
N
A
N
Ω
Ω
Ω
Ω
(
)
(
)
( )
(
)
( )
( )
( )
α
β
α
λ
α
ν
r
m
r
l
r
m
r
l
r
l
r
l
∗
∗
∗
∗
=
+
(
)


=
(
)
∗
∗
λ
α
α
r
l
r
m
r
l
( )
(
)
( )
AV
A
Ω
	
(A8.18)
because noise is assumed to be zero mean and noncorrelated. Inserting 
Equations A8.17 and A8.18 into Equation A8.16, obtain
η
λ
λ
α
α
σ
δ
r
m p
r
p
r
l
r
p
r
l
n
p
p
M
l
p
(
, )
( )
( )
( )
( )
( ) (
)
∗
∗
=
(
) +
−

=
∑
AV
A
Ω
2
1
λ
α
α
r
l
r
m
r
l
∗
∗
(
)






( )
(
)
( )
AV
A
Ω
	
(A8.19)
or
	
η
α
α
η
σ
λ
α
r
m p
p
M
r
p
r
l
r
m l
n
l
r
m
(
, )
( )
*( )
(
, )
( )
(
)
=∑
(
) +
=
1
2
1
AV
AV
A
A
Ω
Ω


 r
m
r
l
(
)
*( )
,
α
(
)





	
(A8.20)
where α
λ
α
r
p
r
p
r
p
( )
( )
( )
=
 and α
λ α
r
l
r
l
r
l
( )
( )
( )
=
 denote spectral coefficients of images 
in corresponding channels after their linear distortions. For every l, this is a 
system of M equation for finding MMSE-optimal weight coefficients {
}.
(
, )
ηr
m l
In order to ease the analysis and interpretation of the solution and get an 
insight into how interchannel correlations and noise level determine chan-
nel contributions to the result of fusion, consider a special case of fusion. For 
the case of two channels (l = 1,2) into one (m = 1,2), we have
	
AV
AV
A
A
Ω
Ω



α
η
α
α
η
σ
η
r
r
r
r
r
n
r
( )
( , )
( )
*( )
( , )
( )
(
1 2
1 1
2
1
1 2
2 1
1
(
)
+
(
)
+
, )
( )
( )
*( )
( )
*( )
( , )
1
1
1
1
1
2
1 1
1
=
(
)
(
)
+
λ
α α
α α
η
r
r
r
r
r
r
AV
AV
A
A
A
Ω
Ω




V
AV
A
A
Ω
Ω



α
η
σ
η
λ
α α
r
r
n
r
r
r
r
( )
( , )
( )
( , )
( )
( )
*( )
2 2
1 2
2 2
1 2
1
1
2
1
(
)
+
=
(
)






(
)
+
+
AV
AV
A
A
Ω
Ω



α
η
α
α
η
r
r
r
r
r
( )
( , )
( )
*( )
( , )
(
)
1 2
2 1
2
1
2 2
σ
η
λ
α
α
η
α
n
r
r
r
r
r
r
2 1
2 1
2
2
1
2 1
1
1
( )
( , )
( )
( )
*( )
( , )
( )
=
(
)
AV
AV
A
A
Ω
Ω



α
η
α
σ
η
λ
α
r
r
r
n
r
r
*( )
( , )
( )
( )
( , )
( )
2
2 2
2 2
2 2
2 2
2
1
(
) +
+
(
) +
=
AV
AV
A
A
Ω
Ω

 r
( )
.
2 2
(
)






	
(A8.21)
Consider in detail the first pair of equations that can be rewritten as
	




α
σ
η
α
α
η
λ
α
r
n
r
r
r
r
r
r
( )
( )
( , )
( )
( )
( , )
( )
1 2
2 1
1 1
2
1
1 2
1
1
+




+
=
∗
( )
( )
( )
( , )
( )
( )
( , )
(
1 2
1
2
1 1
2 2
2 2
1 2
1



α α
η
α
σ
η
λ
r
r
r
r
n
r
r
∗
+
+




=
1
1
2
)
( )
( ),


α α
r
r
∗
	
(A8.22)
where AV
A
Ω( )⋅⋅ is, for the sake of brevity, replaced by ( )
⋅⋅.

472
Theoretical Foundations of Digital Imaging Using MATLAB®
The solutions of these equations are
	
η
λ
α
α
σ
α α
r
r
r
r
n
r
r
( , )
( )
( )
( )
( )
( )
( )
1 1
1
1 2
2 2
2 2
1
2
2
1
=
+



−(
)
∗








α
σ
α
σ
α α
r
n
r
n
r
r
( )
( )
( )
( )
( )
( )
1 2
2 1
2 2
2 2
1
2
2
+




+



−(
)
∗
=
−(
)



+
∗
1
1
1 2
2 2
1
2
2
2 2
1
λ
α
α
α α
σ
α
r
r
r
r
r
n
r
( )
( )
( )
( )
( )
( )
( )





2
1 2
2 2
1
2
2
2 1
2 2
2





α
α
α α
σ
α
σ
r
r
r
r
n
r
n
( )
( )
( )
( )
( )
( )
(
−(
)



+
+
∗
2
1 2
2 1
2 1
1
1
2
2
1 2
1
1
)
( )
( )
( )
( )
( )
( )
( )





α
σ
σ
λ
α α
α
α
r
n
n
r
r
r
r
r
+
=
−(
)
∗
( )
( )
( )
( )
( )
( )
(
2 2
2 2
2 2
1
2
2
1 2
1










+
−(
)
∗
σ
α
α α
α
α
n
r
r
r
r
r




 2 2
2 1
1 2
2 2
2 2
2 1
1 2
)
( )
( )
( )
( )
( )
( )










+
+
+
σ
α
σ
α
σ
α
σ
n
r
n
r
n
r
n



2 2
2 2
1
1 2
2 1
2
1 2
1
1
1
1
( )
( )
( )
( , )
( , )
( )
( , )
(
α
λ




r
r
r
r
r
r
r
SNR
=
−
(
) +
−
2 1
1
2
1
2
1
1
1
1
1
1
1
1
, )
( )
( )
( )
( )
( )
( )
(
) +
+
+
=
+
SNR
SNR
SNR SNR
SNR
r
r
r
r
r
r
λ
−
(
)


+
−
(
)




r
r
r
r
r
r
SNR
SNR SN
( , )
( , )
( )
( , )
( , )
( )
1 2
2 1
2
1 2
2 1
1
1
1
R
SNR
SNR
r
r
r
( )
( )
( )
2
2
1
+
+
	
(A8.23)
and
η
λ
α α
α
σ
α
r
r
r
r
r
n
r
( , )
( )
( )
( )
( )
( )
( )
1 2
1
1
2
1 2
2 1
1 2
1
=
(
)
+



−
∗




α α
α
σ
α
σ
α
r
r
r
n
r
n
( )
( )
( )
( )
( )
( )
1
2
1 2
2 1
2 2
2 2




∗
(
)
+




+



−
r
r
r
r
r
n
r
n
( )
( )
( )
( )
( )
( )
( )
( )
1
2
2
1
1
2
2 1
1 2
2 1
1




α
λ
α α
σ
α
σ
∗
∗
(
)
=
(
)
+




+



−(
)
=
∗





α
σ
α α
λ
α α
r
n
r
r
r
r
( )
( )
( )
( )
( )
( )
2 2
2 2
1
2
2
1
1
1
r
n
n
n
r
r
r
r
SNR
SNR
∗
(
)
+
(
)
+
(
) −
( )
( )
( )
( )
( )
( )
( )
2
2 1
2 1
2 2
1
2
1
1
1
σ
σ
σ
α α

 ∗
(
)
( )
2
2

473
Image Perfecting
=
(
)
+
(
)
+
∗
1
1
1
1
1
2
2 1
2 1
2 2
1
λ
α α
σ
σ
σ
r
r
r
n
n
n
r
r
SNR
SNR
( )
( )
( )
( )
( )
( )
( )
(


2
1 2
2 2
1
2
2
1 2
2 2
1
1
)
( )
( )
( )
( )
( )
( )
( )
(
) −
(
)
=
∗






α
α
α α
α
α
λ
r
r
r
r
r
r
r
SNR
SNR
SNR
SNR
r
r
r
r
r
r
r
( )
( )
( )
( )
( )
( )
(
2
1
2
2 2
1
2
1
1
1



α α
α
∗
(
)
+
(
)
+
(
) −
)
( )
( )
( )
( )
( )
( )
( )
( )
SNR
SNR
r
r
r
r
r
r
r
r
2
1
2
2
1 2
2 2
2
2
1
1




α α
α
α
λ
α
∗
(
)
=
α
α
α
r
r
r
r
r
r
r
SNR
SNR
SNR SNR
∗
(
)
+
(
)
+
(
) −
( )
( )
( )
( )
( )
( )
( )
2
2 2
1
2
1
2
1
1
1




α
α
α
λ
κ
r
r
r
r
r
r
r
SNR
SNR
∗
(
)
=
+
(
)
( )
( )
( )
( )
( , )
( )
( )
2
2
1 2
2 2
2
2 1
2
1
1
1
1 +
(
) −
=
SNR
SNR SNR
SNR
r
r
r
r
r
r
r
r
( )
( , )
( , )
( )
( )
( )
( , )
2
1 2
2 1
1
2
2
2 1
1
κ
κ
λ
κ
( )
( )
( )
( , )
( , )
( )
( ) ,
2
1
2
1 2
2 1
1
2
1
1
+
+
+
−
(
)
SNR
SNR
SNR SNR
r
r
r
r
r
r
κ
κ
	
(A8.24)
where
	
κ
α α
α
κ
α α
α
r
r
r
r
r
r
r
r
( , )
( )
( )
( )
( , )
( )
( )
( )
;
1 2
1
2
1 2
2 1
1
2
2 2
= (
)
= (
)
∗
∗
	
(A8.25)
and
	
SNR
m
r
m
r
m
r
m
r
m
A
n
(
)
(
)
(
)
(
)
AV
AV
,
,
=
(
)
(
)










=
λ
α
ν
2
2
2
Ω
Ω
1 2. 	
(A8.26)
Verification of Equation 8.66
Prove that the solution defined by Equation 8.66 satisfies Equation 8.64. First, 
find 
exp(
)
( , )
(
, )
p
M
p
r
m p
i
k
r
=∑
1
1
2π
η
 for ηr
m p
(
, ) defined by Equation 8.66:
	
exp(
)
exp(
) exp(
( , )
(
, )
( , )
(
i
k
r
i
k
r
i
k
p
p
M
r
m p
p
p
M
2
2
2
1
1
1
1
π
η
π
π
=
=
∑
∑
=

m p
r
p
r
s
s
M
r SNR
SNR
, )
( )
( )
)
1
1
+
=∑

474
Theoretical Foundations of Digital Imaging Using MATLAB®
	
=
−
+
=
=
=
∑
∑
exp(
[
] )
exp(
( , )
( ,
)
( )
( )
i
k
k
r
SNR
SNR
i
p l
p m
p
M
r
p
r
s
s
M
2
1
2
1
1
π
π
π
k
r
SNR
SNR
i
k
r
SNR
m l
r
p
r
s
p
M
p
M
l m
r
p
(
, )
( )
( )
( ,
)
(
)
exp
1
2
1
1
+
=
(
)
=
=
∑
∑
)
( )
p
M
r
s
s
M
SNR
=
=
∑
∑
+
1
1
1
because k(p,l) – k(p,m) = k(l,m). Inserting this in Equation 8.64, we arrive at the 
identity
	
exp(
)
exp(
)
( ,
)
( )
( )
( ,
)
i
k
r
SNR
SNR
i
k
r S
l m
r
p
p
M
r
s
s
M
l m
2
1
2
1
1
π
π
=
=
∑
∑
+
+
NR
SNR
SNR
i
k
r
SNR
r
l
r
s
s
M
r
l
l m
r
p
p
M
( )
( )
( )
( ,
)
( )
exp(
)
1
2
1
1
1
+
=
+
=
=
∑
∑
π
SNR
i
k
r
SNR
i
k
r
s
s
M
l m
r
s
s
M
l m
( )
( ,
)
( )
( ,
)
exp(
)
exp(
=
=
∑
∑
+
+
=
1
1
2
1
1
2
π
π
r
SNR
SNR
i
k
r
r
p
p
M
r
s
s
M
l m
)
exp(
),
( )
( )
( ,
)
1
1
2
1
1
+
+
=
=
=
∑
∑
π
which completes the proof.

475
Image Perfecting
Exercises
demoire1_CRC.m
WienerFilter_CRC.m
filtering_stripes_CRC.m
demo_lcdct2_CRC.m
impulse_noise_filtering_demo_CRC.m
histo_standardization_CRC.m
neighborhoods_CRC.m
enhancement_demo_CRC.m
noiseVar_CRC.m
References
	
1.	 N. Wiener, The Interpolation, Extrapolation and Smoothing of Stationary Times Series, 
Wiley, New York, 1949.
	
2.	 A. N. Kolmogorov, Sur l’interpolation de suits stationaires, C. R. Acad. Sci., 
(Paris) 208, 2043–2045, 1939.
	
3.	 C. E. Shannon, Communication in the presence of noise, Proc. IRE, 1, 10–21, 
1949.
	
4.	 V. A. Kotelnikov, The Theory of Optimum Noise Immunity (Translated from 
Russian), McGraw Hill, New York, 1959.
	
5.	 J. W. Tukey, Exploratory Data Analysis, Addison Wesley, Boston, Massachusetts, 
1971.


FIGURE 8.35
​Pseudocolor representation of the test image of Figure 8.32a, which contains an invisible 
­low-contrast periodical texture. Color bar to the right shows color coding table for image gray 
levels.

FIGURE 8.36
Colorization of enhanced versions of mammogram shown in Figure 8.33: the lower right ver-
sion is shown in red, the upper right version is shown in green, and the initial image (upper 
left) is shown in blue.

TheoreTical FoundaTions 
of digiTal imaging  using maTlaB®
With the ubiquitous use of digital imaging, a new profession 
has emerged: imaging engineering. Designed for newcomers 
to imaging science and engineering, Theoretical Foundations 
of Digital Imaging Using MATLAB® treats the theory of digital 
imaging as a specific branch of science. It covers the subject in 
its entirety, from image formation to image perfecting. 
Based on the author’s 50 years of working and teaching in 
the field, the text first addresses the problem of converting 
images into digital signals that can be stored, transmitted, 
and processed on digital computers. It then explains how to 
adequately represent image transformations on computers. 
After presenting several examples of computational imaging, 
including numerical reconstruction of holograms and virtual 
image 
formation 
through 
computer-generated 
display 
holograms, the author introduces methods for image perfect 
resampling and building continuous image models. He also 
examines the fundamental problem of the optimal estimation 
of image parameters, such as how to localize targets in images. 
The book concludes with a comprehensive discussion of 
linear and nonlinear filtering methods for image perfecting and 
enhancement.
Helping you master digital imaging, this book presents a unified 
theoretical basis for understanding and designing methods 
of imaging and image processing. To facilitate a deeper 
understanding of the major results, it offers a number of exercises 
supported by MATLAB programs, with the code available at 
http://www.crcpress.com/product/isbn/9781439861400.
ISBN: 978-1-4398-6140-0
9 781439 861400
90000
K12836
 Digital Imaging

