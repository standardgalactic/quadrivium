l 
•.• 
M I • 
' 
J.. 
ALAN V. OPPENHEIM 
ALAN S. WILLSKV 
WITH S. HAMID NAWAB 
•
PRENTICE HALL SIGNAL PROCESSING SERIES 
. 
ALAN V. OPPENHEIM, SERIES EDITOR ~ 
~ 

SECOND EDITION 
SIGNALS 
& 
SYSTEMS 
ALAN v. OPPENHEIM 
ALAN s. w ILLSKY 
MAssACHUSETTS INsTITUTE OF TEcHNOLOGY 
WITH 
S.IIAMIDNAWAB 
BosToN UNIVERSITY 
PRENTICE-HALL INTERNATIONAL, INC. 

PREFACE 
XVII 
AcKNOWLEDGMENTS 
xxv 
FoREWORD 
xxvii 
CoNTENTS 
1 SIGNALS AND SYSTEMS 1 
1.0 . Introduction 1 
1.1 
Continuous-Time and Discrete-Time Signals 1 
1.1.1 
Examples and Mathematical Representation 1 
1.1.2 Signal Energy and Power 5 
1.2 Transformations of the Independent Variable 7 
1.2.1 
Examples of Transformations of the Independent Variable 8 
1.2.2 Periodic Signals 
11 
1.2.3 Even and Odd Signals 
13 
1.3 Exponential and Sinusoidal Signals 14 
1.3.1 Continuous-Time Complex Exponential and Sinusoidal Signals 
15 
1.3.2 Discrete-Time Complex Exponential and Sinusoidal Signals 21 · 
1.3.3 Periodicity Properties of Discrete-Time Complex Exponentials 25 
1.4 The Unit Impulse and Unit Step Functions 30 
1.4.1 
The Discrete-Time Unit Impulse and Unit Step Sequences 30 
1.4.2 The Continuous-Time Unit Step and Unit Impulse Functions 32 
1.5 Continuous-Time and Discrete-Time Systems 38 
1.5.1 
Simple Examples of Systems 39 
1.5.2 Interconnections of Systems 41 
1.6 Basic System Properties 44 
1.6.1 
Systems with and without Memory 44 
1.6.2 Invertibility and Inverse Systems 45 
1.6.3 
Causality 46 
1.6.4 Stability 48 
1.6.5 Time Invariance 50 
1.6.6 Linearity 53 
1.7 Summary 56 
Problems 57 
2 LINEAR TIME-INVARIANT SYSTEMS 74 
2.0 Introduction 74 
2.1 
Discrete-Time LTI Systems: The Convolution Sum 75 
vii 

viii 
2.1.1 . The Representation of Discrete-Time Signals in Terms 
of Impulses 75 
2.1.2 The Discrete-Time Unit Impulse Response and the Convolution-Sum 
Representation of LTI Systems 77 
2.2 
Continuous-Time LTI Systems: The Convolution Integral 90 
2.2.1 
The Representation of Continuous-Time Signals in Terms 
of Impulses 90 
2.2.2 The Continuous-Time Unit Impulse Response and the Convolution 
Integral Representation of LTI Systems 94 
2.3 Properties of Linear Time-Invariant Systems 103 
2.3.1 
The Commutative Property 104 
2.3.2 The Distributive Property 
104 
2.3.3 
The Associative Property 
107 
2.3.4 LTI Systems with and without Memory 
108 
2.3.5 
Invertibility of LTI Systems 109 
2.3.6 Causality for LTI Systems 
112 
2.3.7 
Stability for LTI Systems 113 
2.3.8 • The Unit Step Response of an LTI System 115 
2.4 Causal LTI Systems Described by Differential and Difference 
· Equations 116 
2.4.1 
Linear Constant -Coefficient Differential Equations 
117 
2.4.2 Linear Constant-Coefficient Difference Equations 
121 
2.4.3 
Block Diagram Representations of First-Order Systems Described 
by Differential and Difference Equations 124 
2.5 Singularity Functions 127 
2.5.1 
The Unit Impulse as an Idealized Short Pulse 128 
2.5.2 Defining the Unit Impulse through Convolution 
131 
2.5.3 
Unit Doublets and Other Singularity Functions 
132 
2.6 Summary 137 
Problems 137 
3 FoURIER SERIES REPRESENTATION OF 
PERIODIC SIGNALS 177 
3.0 Introduction 177 
3.1 A Historical Perspective 178 
3.2 The Response of LTI Systems to Complex Exponentials 182 
3.3 Fourier Series Representation of Continuous-Time 
Periodic Signals 186 
3.3.1 
Linear Combinations of Harmonically Related Complex 
Exponentials 
186 
3.3.2 Determination of the Fourier Series Representation 
of a Continuous-Time Periodic Signal 190 
3.4 Convergence of the Fourier Series 195 
Contents 

Contents 
3.5 Properties of Continuous-Time Fourier Series 202 
3.5.1 
Linearity 202 
3.5.2 Time Shifting 202 
3.5.3 
Time Reversal 203 
3.5.4 Time Scaling 204 
3.5.5 Multiplication 204 
3.5.6 Conjugation and Conjugate Symmetry 204 
3.5.7 Parseval's Relation for Continuous-Time Periodic Signals 205 
3.5.8 Summary of Properties of the Continuous-Time Fourier Series 205 
3.5.9 Examples 205 
3.6 Fourier Series Representation of Discrete-Time 
Periodic Signals 211 
3.6.1 Linear Combinations of Harmonically Related Complex 
Exponentials 211 
3.6.2 Determination of the Fourier Series Representation of a · 
Periodic Signal 212 
3.7 Properties of Discrete-Time Fourier Series 221 
3.7.1 Multiplication 222 
3.7.2 First Difference 222 
3.7.3 Parseval's Relation for Discrete-Time Periodic Signals 223 
3.7.4 Examples 223 
3.8 Fourier Series and LTI Systems 226 
3.9 Filtering 231 
3.9.1 Frequency-Shaping Filters 232 
3.9.2 Frequency-Selective Filters 236 
3.10 Examples of Continuous-Time Filters Described by 
Differential Equations 239 
3.10.1 
A Simple RC Lowpass Filter 239 
3.10.2 A Simple RC Highpass Filter 241 
3.11 Examples of Discrete-Time Filters Described by 
Difference Equations 244 
3.11.1 
First-Order Recursive Discrete-Time Filters 244 
3.11.2 Nonrecursive Discrete-Time Filters 245 
3.12 Summary 249 
Problems 250 
4 ThE CONTINUOUS-TIME FOURIER TRANSFORM 284 
4.0 Introduction 284 
4.1 Representation of Aperiodic Signals: The Continuous-Time 
Fourier Transform 285 
4.1.1 
Development of the Fourier Transform Representation 
of an Aperiodic Signal 285 
4.1.2 Convergence of Fourier Transforms 289 
4.1.3 Examples of Continuous-Time Fourier Transforms 290 
ix 

X 
4.2 The Fourier Transform for Periodic Signals 296 
4.3 Properties of the Continuous-Time Fourier Transform 300 
4.3.1 
Linearity 301 
4.3.2 Time Shifting 301 
4.3.3 
Conjugation and Conjugate Symmetry 303 
4.3.4 Differentiation and Integration 306 
4.3.5 Time and Frequency Scaling 308 
4.3.6 Duality 309 
4.3.7 
Parseval's Relation 312 
4.4 The Convolution Property 314 
4.4.1 
Examples 317 
4.5 The Multiplication Property 322 
4.5.1 
Frequency-Selective Filtering with Variable Center Frequency 325 
4.6 Tables of Fourier Properties and of Basic Fourier 
Transform Pairs 328 
· 
4.7 Systems Characterized by Linear Constant-Coefficient 
Differential Equations 330 
4.8 Summary 333 
Problems 334 
5 ThE DISCRETE-TIME FOURIER TRANSFORM 358 
5.0 Introduction 358 
5.1 
Representation of Aperiodic Signals: The Discrete-Time 
Fourier Transform 359 
5.1.1 Development of the Discrete-~ime Fourier Transform 359 
5.1.2 Examples of Discrete-Time Fourier Transforms 362 
5 .1.3 
Convergence Issues Associated with the Discrete-Time Fourier 
Transform 366 
5.2 The Fourier Transform for Periodic Signals 367 
5.3 Properties of the Discrete-Time Fourier Transform 372 
5.3.1 . Periodicity of the Discrete-Time Fourier Transform 373 
5.3.2 Linearity of the Fourier Transform 373 
5.3.3 Time Shifting and Frequency Shifting 373 
5.3.4 Conjugation and Conjugate Symmetry 375 
5.3.5 
Differencing and Accumulation 375 
5.3.6 Time Reversal 376 
5.3.7 Time Expansion 377 
5.3.8 Differentiation in Frequency 380 
5.3.9 Parseval's Relation 380 
5.4 The Convolution Property 382 
5.4.1 
Examples 383 
5.5 The Multiplication Property 388 
5.6 Tables of Fourier Transform Properties and Basic Fourier 
Transform Pairs 390 
Contents 

Contents 
5. 7 Duality 390 
5.7.1 
Duality in the Discrete-Time Fourier Series 391 
5.7.2 Duality between the Discrete-Time Fourier Transform and the 
Continuous-Time Fourier Series 395 
5.8 Systems Characterized by Linear Constant-Coefficient 
Difference Equations 396 
5.9 Summary 399 
Problems 400 
6 TIME AND FREQUENCY CHARACTERIZATION 
OF SIGNALS AND SYSTEMS 423 
6.0 Introduction 423 
6.1 
The Magnitude-Phase 'Representation of. the Fourier 
Transform 423 
6.2 The Magnitude-Phase Representation of the Frequency Response 
of LTI Systems 427 
6.2.1 Linear and Nonlinear Phase 428 
6.2.2 Group Delay 430 
6.2.3 Log-Magnitude and Bode Plots 436 
6.3 Time-Domain Properties of Ideal Frequency-Selective 
Filters 439 
6.4 Time-Domain and Frequency-Domain Aspects of Nonideal 
Filters 444 
6.5 First-Order and Second-Order Continuous-Time Systems 448 
6.5 .1 
First -Order Continuous-Time Systems 448 
6.5 .2 Second-Order Continuous-Time Systems 451 
6.5.3 
Bode Plots for Rational Frequency Responses 456 
6.6 First-Order and Second-Order Discrete-Time Systems 461 
6.6.1 
First-Order Discrete-Time Systems 461 
6.6.2 Second-Order Discrete-Time Systems 465 
6.7 Examples of Time- and Frequency-Domain Analysis 
of Systems 472 
6.7.1 
Analysis of an Automobile Suspension System 473 
6.7.2 Examples of Discrete-Time Nonrecursive Filters 476 
6.8 Summary 482 
Problems 483 
7 SAMPLING 514 
7.0 Introduction 514 
7.1 
Representation of a Continuous-Time Signal by Its Samples: 
The Sampling Theorem 515 
7.1.1 
Impulse-Train Sampling 516 
7 .1.2 Sampling with a Zero-Order Hold 520 
xi 

xii 
7.2 Reconstruction of a Signal from Its Samples Using 
Interpolation 522 
7.3 The Effect of Undersampling: Aliasing 527 
7.4 Discrete-Time Processing of Continuous-Time Signals 534 
7.4.1 
Digital Differentiator 541 
7.4.2 Half-Sample Delay 543 
7.5 Sampling of Discrete-Time Signals 545 
7.5.1 Impulse-Train Sampling 545 
7.5 .2 Discrete-Time Decimation and Interpolation 549 
7.6 Summary 555 
Problems 556 
8 CoMMUNICATION SYSTEMS 582 
. 
8.0 Introduction 582 
8.1 
Complex Exponential and Sinusoidal Amplitude Modulation 583 
8.1.1 
Amplitude Modulation with a Complex Exponential Carrier 583 
8.1.2 Amplitude Modulation with a Sinusoidal Carrier 585 
8.2 Demodulation for Sinusoidal AM 587 
8.2.1 Synchronous Demodulation 587 
8.2.2 Asynchronous Demodulation 590 
8.3 Frequency-Division Multiplexing 594 
8.4 Single-Sideband Sinusoidal Amplitude Modulation 597 
8.5 Amplitude Modulation with a Pulse-Train Carrier 601 
8.5.1 
Modulation of a Pulse-Train Carrier 601 
8.5.2 Time-Division Multiplexing 604 
8.6 Pulse-Amplitude Modulation 604 
8.6.1 
Pulse-Amplitude Modulated Signals 604 
8.6.2 Intersymbol Interference in PAM Systems 607 
8.6.3 
Digit~l Pulse-Amplitude and Pulse-Code Modulation 610 
8.7 Sinusoidal Frequency Modulation 611 
8.7.1 
Narrowband Frequency Modulation 613 
8.7.2 Wideband Frequency Modulation 615 
8.7.3 
Periodic Square-Wave Modulating Signal 617 
8.8 Discrete-Time Modulation 619 
8.8.1 
Discrete-Time Sinusoidal Amplitude Modulation 619 
8.8.2 Discrete-Time Transmodulation 623 
8.9 Summary 623 
Problems 625 
9 THE LAPLACE TRANSFORM 654 
9.0 Introduction 654 
9.1 
The Laplace Transform 655 
9.2 The Region of Convergence for Laplace Transforms 662 
Contents 

Contents 
9.3 The Inverse Laplace Transfonn 670 
9.4 Geometric Evaluation of the Fourier Transfonn from the 
Pole-Zero Plot 674 
9.4.1 . First-Order Systems 676 
9.4.2 Second-Order Systems 677 
9.4.3 All-Pass Systems 681 
9.5 Properties of the Laplace Transfonn 682 
9.5.1 
Linearity of the Laplace Transform 683 
9.5.2 
Time Shifting 684 
9.5.3 
Shifting in the s-Domain 685 
9.5 .4 
Time Scal1ng 685 
9.5.5 
Conjugation 687 
9.5.6 
Convolution Property 687 
9.5.7 
Differentiation in the Time Domain 688 
9.5.8 
Differentiation in the s-Domain 688 
9.5.9 
Integration in the Time Domain 690 
9.5.10 The Initial- and Final-Value Theorems 690 
9.5.11 
Table of Properties 6?1 
9.6 Some Laplace Transfonn Pairs 692 
9.7 Analysis and Characterization of LTI Systems Using the 
Laplace Transfonn 693 
9. 7.1 
Causality 693 
9.7.2 Stability 695 
9.7.3 
LTI Systems Characterized by Linear Constant-Coefficient 
Differential Equations 698 
9.7.4 Examples Relating System Behavior to the System Function 701 
9.7.5 
Butterworth Filters 703 
9.8 System Function Algebra and Block Diagram 
Representations 706 
9.8.1 
System Functions for Interconnections of LTI Systems 707 
9.8.2 Block Diagram Representations for Causal LTI Systems Described 
by Differential Equations and Rational System Functions 708 
9.9 The Unilateral Laplace Transfonn 714 
9.9.1 
Examples of Unilateral Laplace Transforms 714 
9.9.2 Properties of the Unilateral Laplace Transform 716 
9.9.3 
Solving Differential Equations Using the Unilateral Laplace 
Transform 719 
9.10 Summary 720 
Problems 721 
10 THE Z-TRANSFORM 741 
10.0 Introduction 741 
10.1 The z-Transfonn 741 
10.2 The Region of Convergence for the z-Transfonn. 748 
xiii 

xiv 
10.3 The Inverse z-Transform 757 
10.4 Geometric Evaluation of the Fourier Transform from the 
Pole-Zero Plot 763 
10.4.1 First-Order Systems 763 
10.4.2 Second-Order Systems 765 
10.5 Properties of the z-Transform 767 
10.5.1 
Linearity 767 
10.5.2 
Time Shifting 767 
10.5.3 
Scaling in the z-Domain 768 
10.5.4 
Time Reversal 769 
10.5.5 
Time Expansion 769 
10.5.6 
Conjugation 770 
10.5.7 
The Convolution Property 770 
10.5.8 
Differentiation in the z-Domain 772 
10.5.9 
The Initial-Value Theorem 773 
10.5.10 Summary of Properties 774 
10.6 Some Common z-Transform Pairs 774 
10.7 Analysis and Characterization of LTI Systems Using 
z-Transforms 774 
10.7.1 Causality 776 
10.7.2 Stability 777 
10.7.3 LTI Systems Characterized by Linear Constant-Coefficient 
Difference Equations 779 
10.7.4 Examples Relating System Behavior to the System Function 781 
10.8 System Function Algebra and Block Diagram 
Representations 783 
10.8.1 System Functions for Interconnections of LTI Systems 784 
10.8.2 Block Diagram Representations for Causal LTI Systems Described 
by Difference Equations and Rational System Functions 784 
10.9 The Unilateral z-Transform 789 
10.9.1 
Examples of Unilateral z-Transforms and Inverse Transforms 790 
10.9.2 Properties of the Unilateral z-Transform 792 
10.9.3 
Solving Difference Equations Using the Unilateral 
z-Transform 795 
10.10 Summary 796 
Problems 797 
11 UNEAR FEEDBACK SYSTEMS 816 
11.0 Introduction 816 
11.1 Linear Feedback Systems 819 
11.2 Some Applications and Consequences of Feedback 820 
11.2.1 Inverse System Design 820 
11.2.2 Compensation for Nonideal Elements 821 
11.2.3 
Stabilization of Unstable Systems 823 
Contents 

PREFACE 
This book is the second edition of a text designed for undergraduate courses in signals and 
systems. While such courses are frequently found in electrical engineering curricula, the 
concepts and techniques that form the core of the subject are of fundamental importance 
in all engineering disciplines. In fact, the scope of potential and actual applications of the 
methods of signal and system analysis continues to expand as engineers are confronted 
with ne~ challenges involving the synthesis or analysis of complex processes. For these 
reasons we feel that a course· in signals and systems not only is an essential element in 
an engineering program but also can be one of the most rewarding, exciting, and useful 
courses that engineering students take during their undergraduate education. 
Our treatment of the subject of signals and systems in this second edition maintains 
the same general philosophy as in the first edition but with significant rewriting, restructur-
ing, and additions. These changes are designed to help both the instructor in presenting the 
subject material and the student in mastering it. In the preface to the first edition we stated 
that our overall approach to signals and systems had been guided by the continuing devel-
opments in technologies for signal and system design and implementation, which made it 
increasingly important for a student to have equal familiarity with techniques suitable for 
analyzing and synthesizing both continuous-time and discrete-time systems. As we write 
the preface to this second edition, that observation and guiding principle are even more 
true than before. Thus, while students studying signals and systems should certainly have 
a solid foundation in disciplines based on the laws of physics, they must also have a firm 
grounding in the use of computers for the analysis of phenomena and the implementation 
of systems and algorithms. As a consequence, engin~ering curricula now reflect a blend of 
subjects, some involving continuous-time models and others focusing on the use of com-
puters and discrete representations. For these reasons, signals and systems courses that 
bring discrete-time and continuous-time concepts together in a unified way play an in-
creasingly important role in the education of engineering students and in their preparation 
for current and future developments in their chosen fields. 
It is with these goals in mind that we have structured this book to develop in parallel 
the methods of analysis for continuous-time and discrete-time signals and systems. This 
approach also offers a distinct and extremely iin.portant pedagogical advantage. Specifi-
cally, we are able to draw on the similarities between continuous- and discrete-time meth-
ods in order to share insights and intuition developed in each domain. Similarly, we can 
exploit the differences between them to sharpen an understanding of the distinc~ properties 
of each. 
In organizing the material both originally and now in the second edition, we have 
also considered it essential to introduce the student to some of the important uses of the 
basic methods that are developed in the book. Not only does this provide the student 
with an appreciation for the range of applications of the techniques being learned and for 
directions for further study, but it also helps to deepen understanding of the subject. To 
achieve this goal we include introductory treatments on the subjects of filtering, commu-
xvii 

xviii 
Preface 
nications, sampling, discrete-time processing of continuous-time signals, and feedback. In 
fact, in one of the major changes in this second edition, we have introduced the concept 
of frequency-domain filtering very early in our treatment of Fourier analysis in order to 
provide both motivation for and insight into this very important topic. In addition, we 
have again included an up-to-date bibliography at the end of the book in order to assist the 
student who is interested in pursuing additional and more advanced studies of the methods 
and applications of signal and system analysis. 
The organization of the book reflects our conviction that full mastery of a subject 
of this nature cannot be accomplished without a significant amount of practice in using 
and applying the tools that are developed. Consequently, in the second edition we have 
significantly increased the number of worked examples within each chapter. We have also 
enhanced one of the key assets of the first edition, namely the end-of-chapter homework 
problems. As in the first edition, we have included a substantial number of problems, 
totaling more than 600 in number. A majority of the problems included here are new and 
thus provide additional flexibility for the instructor in preparing homework assignments. 
In addition, in order to enhance the utility of the problems for both the student and the 
instructor we have made a number of other changes to the organization and presentation of 
the problems. In particular, we have organized the problems in each chapter under several 
specific headings, each of which spans the material ip the entire chapter but with a different 
objective. The first two sections of problems in each chapter emphasize the mechanics of 
using the basic concepts and methods presented in the chapter. For the first of these two 
sections, which has the heading Basic Problems with Answers, we have also provided 
answers (but not solutions) at the end of the book. These answers provide a simple and 
immediate way for the student to check his or her understanding of the material. The 
problems in this first section are generally appropriate for inclusion in homework sets. 
Also, in order to give the instructor additional flexibility in assigning homework problems, 
we have provided a second section of Basic Problems for which answers have not been 
included. 
A third section of problems in each chapter, organized under the heading of Ad-
vanced Problems, is oriented toward exploring and elaborating upon the foundations and 
practical implications of the material in the text. These problems often involve mathe-
matical derivations and more sophisticated use of the concepts and methods presented in 
the chapter. Some chapters also include' a section of Extension Problems which involve 
extensions of material presented in the chapter and/or involve the use of knowledge from 
applications that are outside the scope of the main text (such as advanced circuits or me-
chanical systems). The overall variety and quantity of problems in each chapter will hope-
fully provide students with the means to develop their understanding of the material and 
instructors with considerable flexibility in putting together homework sets that are tailored 
to the specific needs of their students. A solutions manual is also available to instructors 
through the publisher. 
Another significant additional enhancement to this second edition is the availability 
of the companion book Explorations in Signals and Systems Using MATIAB by Buck, 
Daniel, and Singer. This book contains MATLAB@-based computer exercises for each 
topic in the text, and should be of great assistance to both instructor and student. 
Students using this book are assumed to have a basic background in calculus as well 
as some experience in manipulating complex numbers and some exposure to differential 

Preface 
XIX 
equations. With this background, the book is self-contained. In particular, no prior expe-
rience with system analysis, convolution, Fourier analysis, or Laplace and z-transforms is 
assumed. Prior to learning the subject of signals and systems most students will have had 
a course such as basic circuit theory for electrical engineers or fundamentals of dynamics 
for mechanical engineers. Such subjects touch on some of the basic ideas that are devel-
oped more fully in this text. This background can clearly be of great value to students in 
providing additional perspective as they proceed through the book 
The Foreword, which follows this preface, is written to offer the reader motivation 
and perspective for the subject of signals and systems in general and our treatment of it 
in particular. We begin Chapter 1 by introducing some of the elementary ideas related to 
the mathematical representation of signals and systems. In particular we discuss trans-
formations (such as time shifts and scaling) of the independent variable-of a signal. We 
also introduce some of the most important and basic continuous-time and discrete-time 
signals, namely real and complex exponentials and the continuous-time and discrete-time 
unit step and unit impulse. Chapter 1 also introduces block diagram representations of in-
terconnections of systems and discusses several basic system properties such as causality, 
linearity and time-invariance. In Chapter 2 we build on these last two properties, together 
with the sifting property of unit impulses to develop the convolution -sum representation 
for discrete-time linear, time-invariant (LTI) systems and the convolution integral repre-
sentation for continuous-time LTI systems. In this treatment we use the intuition gained 
from our development of the discrete-time case as an aid in deriving and understanding its 
continuous-time counterpart. We then turn to a discussion of causal, LTI systems charac-
terized by linear constant-coefficient differential and difference equations. In this introduc-
, tory discussion we review the basic ideas involved in solving linear differential equations 
(to which most students will have had some previous exposure) and we also provide a dis-
cussion of analogous methods for linear difference equations. However, the primary focus 
of our development in Chapter 2 is not on methods of solution, since more convenient ap-
proaches are developed later using transform methods. Instead, in this first look, our intent 
is to provide the student with some appreciation for these extremely important classes of 
systems, which will be encountered often in subsequent chapters. Finally, Chapter 2 con-
eludes with a brief discussion of singularity functions-steps, impulses, doublets, and so 
forth-in the context of their role in the description and analysis of continuous-time LTI 
systems. In particular, we stress the interpretation of these signals in terms of how they 
are defined under convolution-
that is, in terms of the responses of LTI systems to these 
idealized signals. 
Chapters 3 through 6 present a thorough and self-contained development of the · 
methods of Fourier analysis in both continuous and discrete time and together represent 
the most significant reorganization and revision in the second edition. In particular, as we 
indicated previously, we have introduced the concept of frequency-domain filtering at a 
much earlier point in the development in order to provide motivation for and a concrete 
application of the Fourier methods being developed. As in the first edition, we begin the 
discussions in Chapter 3 by emphasizing and illustrating the two fundamental reasons 
for the important role Fourier analysis plays in the study of signals and systems in both 
continuous and discrete time: (1) extremely broad classes of signals can be represented 
as weighted sums or integrals of complex exponentials; and (2) the response of an LTI 
system to a complex exponential input is the same exponential multiplied by a complex-

XX 
Preface 
number characteristic of the system. However, in contrast to the first edition, the focus of 
attention in Chapter 3 is on Fourier series representations for periodic signals in both con-
tinuous time and discrete time. In this way we not only introduce and examine many of the 
properties of Fourier .representations without the additional mathematical generalization 
required to obtain the Fourier transform for aperiodic signals, but we also can introduce 
the application to filtering at a very early stage in the development. In particular, tak-
ing advantage of the fact that complex exponentials are eigenfunctions of LTI systems, 
we introduce the frequency response of an LTI system and use it to discuss the concept 
of frequency-selective filtering, to introduce ideal filters, and to give several examples of 
nonideal filters described by differential and difference equations. In this way, with a min-
imum of mathematical preliminaries, we provide the student with a deeper appreciation 
for what a Fourier representation means and why it is such a useful construct. 
· Chapters 4 and 5 then build on the foundation provided by Chapter 3 as we develop 
first the continuous-time Fourier transform in Chapter 4 and, in a parallel fashion, the 
discrete-time Fourier transform in Chapter 5. In both chapters we derive the Fourier trans-
form representation of an aperiodic signal as the limit of the Fourier series for a signal 
whose period becomes arbitrarily large. This perspective emphasizes the close relationship 
between Fourier series and transforms, which we develop further in subsequent sections 
and which allows us to transfer the intuition developed for Fourier series in Chapter 3 to the 
more general context of Fourier transforms. In both chapters we have included a discus-
sion of the many important properties of Fourier transforms, with special emphasis placed 
on the convolution and multiplication properties. In particular, the convolution property 
allows us to take a second look at the topic of frequency-selective filtering, while the 
multiplication property serves as the starting point for our treatment of sampling and mod-
ulation in !ater chapters. Finally, in the last sections in Chapters 4 and 5 we use transform 
methods to determine the frequency responses ofLTI systems described by differential and 
difference equations and to provide several examples illustrating how Fourier transforms 
can be used to compute the responses for such systems. To supplement these discussions 
(and later treatments of Laplace and z-transforms) we have again included an Appendix at 
the end of the book that contains a description of the method of partial fraction expansion. 
Our treatment of Fourier analysis in these two chapters is characteristic of the par-
allel treatment we have developed. Specifically, in our discussion in Chapter 5, we are 
able to build on much of the insight developed in Chapter 4 for the continuous-time case, 
and toward the end of Chapter 5 we emphasize the complete duality in continuous-time 
and discrete-time Fourier representations. In addition, we bring the special nature of each 
domain into sharper focus by contrasting the differences between continuous- and discrete-
time Fourier analysis. 
As those familiar with the first edition will note, the lengths and scopes of Chapters 
4 and 5 in the second edition are considerably smaller than their first edition counterparts. 
This is due not only to the fact that Fourier series are now dealt with in a separate chapter 
but also to our moving several topics into Chapter 6. The result, we believe, has several 
significant benefits. First, the presentation in three shorter chapters of the basic concepts 
and results of Fourier analysis, together with the introduction of the concept of frequency-
selective filtering, should help the student in organizing his or her understanding of this 
material and in developing some intuition about the frequency domain and appreciation 
for its potential applications. Then, with Chapters 3-5 as a foundation, we can engage in 

"Preface 
xxi 
a more detailed look at a number of important topics and applications. In Chapter 6 we 
take a deeper look at both the time- and frequency-domain characteristics of LTI systems. 
For example, we introduce magnitude-phase and Bode plot representations for frequency 
responses and discuss the effect of frequency response phase on the time domain charac-
teristics of the output of an LTI system. In addition, we examine the time- and frequency-
domain behavior of ideal and nonideal filters and the tradeoffs between these that must be 
addressed in practice. We also take a careful look at first- and second-order systems and 
their roles as basic building blocks for more complex system synthesis and analysis in both 
continuous and discrete time. Finally, we discuss several other more complex examples 
of filters in both continuous and discrete time. These examples together with the numer-
ous other aspects of filtering explored in the problems at the end of the chapter provide 
the student with some appreciation for the richness and flavor of this important subject. 
While each of the topics in Chapter 6 was present in the first edition, we believe that by 
reorganizing and collecting them in a separate chapter following the basic development 
of Fourier analysis, we have both simplified the introduction of this important topic in 
Chapters 3-5 and presented in Chapter 6 a considerably more cohesive picture of time-
and frequency-domain issues. 
In response to suggestions and preferences expressed by many users of the first edi-
tion we have modified notation in the discussion of Fourier transforms to be more con-
sistent with notation most typically used for continuous-time and discrete-time Fourier 
transforms. Specifically, beginning with Chapter 3 we now denote the continuous-time 
Fourier transform as X(jw) and the discrete-time Fourier transform as X(ejw). As with all 
options with notation, there is not a unique best choice for the notation for Fourier trans-
forms. However, it is our feeling, and that of many of our colleagues, that the notation used 
in this edition represents the preferable choice. 
Our treatment of sampling in Chapter 7 is concerned primarily with the sampling 
theorem and its implications. However, to place this subject in perspective we begin by dis-
cussing the general concepts of representing a continuous-time signal in terms of its sam-
ples and the reconstruction of signals using interpolation. After using frequency-domain 
methods to derive the sampling theorem, we consider both the frequency and time do-
mains to provide intuition concerning the phenomenon of aliasing resulting from under-
sampling. One of the very important uses of sampling 'is in the discrete-time processing of 
continuous-time signals, a topic that we explore at some length in this chapter. Following 
this, we tum to the sampling of discrete-time signals. The basic result underlying discrete-
time sampling is developed in a manner that parallels that used in continuous time, and 
the applications of this result to problems of decimation and interpolation are described. 
Again a variety of other applications, in both continuous and discrete time, are addressed 
in the problems. 
Once again the reader acquainted with our first edition will note a change, in this case 
involving the reversal in the order of the presentation of sampling and communications. We 
have chosen to place sampling before communications in the second edition both because 
we can call on simple intuition to motivate and describe the processes of sampling and 
reconstruction from samples and also because this order of presentation then allows us 
in Chapter 8 to talk more easily about forms of communication systems that are closely 
related to sampling or rely fundamentally on using a sampled version of the signal to be 
transmitted. 

Jodi 
Preface 
Our treatment of communications in Chapter 8 includes an in -depth discussion of 
continuous-time sinusoidal amplitude modulation (AM), which begins with the straight-
forward application of the multiplication property to describe the effect of sinusoidal AM 
in the frequency domain and to suggest how the original modulating signal can be recov-
ered. Following this, we develop a number of additional issues and applications related 
to sinusoidal modulation, including frequency-division multiplexing and single-sideband 
modulation. Many other examples and applications are described in the problems. Several 
additional topics are covered in Chapter 8. The first of these is amplitude modulation of 
a pulse train and time-division multiplexing, which has a close connection to the,topic of 
sampling in Chapter 7. Indeed we make this tie even more explicit and provide a look into 
the important field ·of digital communications by introducing and briefly describing the 
topics of pulse-amplitude modulation (PAM) and intersymbol interference. Finally, our 
discussion of frequency modulation (FM) provides the reader with a look at a nonlinear 
modulation problem. Although the analysis of FM systems is not as straightforward as for 
the AM case, our introductory treatment indicates how frequency-domain methods can 
be used to gain a significant amount of insight into the characteristics of FM signals and 
systems. Through these discussions and the many other aspects of modulation and com-
munications explored in the problems in this chapter we believe that the student can gain 
an appreciation both for the richness of the field of communications and for the central 
role that the tools of signals and systems analysis play in it. 
Chapters 9 and 10 treat the Laplace and z-transforms, respectively. For the most part, 
we focus on the bilateral versions of these transforms, although in the last section of each 
chapter we discuss unilateral transforms and their use in solving differential and differ-
ence equations with nonzero initial conditions. Both chapters include discussions on: the 
close relationship between these transforms and Fourier transforms; the class of rational 
transforms and their representation in terms of poles and zeros; the region of convergence 
of a Laplace or z-transform and its relationship to properties of the signal with which it is 
associated; inverse transforms using partial fraction expansion; the geometric evaluation 
of system functions and frequency responses from pole-zero plots; and basic transform 
properties. In addition, in each chapter we examine the properties and uses of system 
functions for LTI systems. Included in these discussions are the determination of system 
functions for systems characterized by differential and difference equations; the use of sys-
tem function algebra for interconnections of LTI systems; and the construction of cascade, 
parallel- and direct-form block-diagram representations for systems with rational system 
functions. 
The tools of Laplace and z-transforms form the basis for our examination of linear 
feedback systems in Chapter 11. We begin this chapter by describing a number of the 
important uses and properties of feedback systems, including stabilizing unstable systems, 
designing tracking systems, and reducing system sensitivity. In subsequent sections we use 
the tools that we have developed in previous chapters to examine three topics that are of 
importance for both continuous-time and discrete-time feedback systems. These are root 
locus analysis, Nyquist plots and the Nyquist criterion, and log-magnitude/phase plots and 
the concepts of phase and gain margins for stable feedback systems. 
The subject of signals and systems is an extraordinarily rich one, and a variety of 
approaches can be taken in designing an introductory course. It was our intention with 
the first edition and again with this second edition to provide instructors with a great deal of 

Preface 
xxlli 
; 
flexibility in structuring their presentations of the subject. To obtain this flexibility and to 
maximize the usefulness of this book for instructors, we have chosen to present thorough, 
in-depth treatments of a cohesive set of topics that forms the core of most introductory 
courses on signals and systems. In achieving this depth we have of necessity omitted in-
troductions to topics such as descriptions of random signals and state space models that are 
sometimes included in first courses on signals and systems. Traditionally, at many schools, 
such topics are not included in introductory courses but rather are developed in more depth 
in follow-on undergraduate courses or in courses explicitly devoted to their investigation. 
Although we have not included an introduction to state space in the book, instructors-of 
introductory courses can easily incorporate it into the treatments of differential and dif-
ference equations that can be found throughout the book. In particular, the discussions 
in Chapters 9 and 10 on block diagram representations for systems with rational system 
functions and on unilateral transforms and their use in solving differential and difference 
equations with initial conditions form natural points of departure for the discussions of 
state-space representations. 
A typical one-semester course at the sophomore-junior level using this book would 
cover Chapters 1-5 in reasonable depth (although various topics in each chapter are easily 
omitted at the discretion of the instructor) with selected topics chosen from the remaining 
chapters. For example, one possibility is to present several of the basic topics in Chapters 
6-8 together with a treatment of Laplace and z-transforms and perhaps a brief introduction 
to the use of system function concepts to analyze feedback systems. A variety of alternate 
formats are possible, including one that incorporates an introduction to state space or one 
in which more focus is placed on continuous-time systems by de-emphasizing Chapters 5 
and 10 and the discrete-time topics in Chapters 3, 7, 8, and 11. 
In addition to these course formats this book can be used as the basic text for a 
thorough, two-semester sequence on linear systems. Alternatively, the portions of the book 
not used in a first course on signals and ~ystems can, together with other sources, form the 
basis for a subsequent course. For example, much of the material in this book forms a direct 
bridge to subjects such as state space analysis, control systems, digital signal processing, 
communications and statistical signal processing: Consequently, a follow-on course can be 
constructed that uses some of the topics in this book together with supplementary material 
in order to provide an introduction to one or more of these advanced subjects. In fact, a 
new course following this model has been developed at MIT and has proven not only to 
be a popular course among our students but also a crucial component of our signals and 
systems curriculum. 
As it was with the first edition, in the process of writing this book we have been for-
tunate to have received assistance, suggestions, and support from numerous colleagues, 
students and friends. The ideas and perspectives that form the heart of this book have 
continued to evolve as a result of our own experiences in teaching signals and systems 
and the influences of the many colleagues and students with whom we have worked. We 
would like to thank Professor Ian T. Young for his contributions to the first edition of this 
book and to thank and welcome Professor Hamid Nawab for the significant role he played 
in the development and complete restructuring of the examples and problems for this sec-
ond edition. We also express our appreciation to John Buck, Michael Daniel and Andrew 
Singer for writing the MATLAB companion to the text. In addition, we would like to 
thank Jason Oppenheim for the use of one of his original photographs and Vivian Berman 

' 
xxiv 
Preface 
for her ideas and help in arriving at a cover design. Also, as indicated on the acknowl-
edgment page that follows, we are deeply grateful to the many students and colleagues 
who devoted a significant number of hours to a variety of aspects of the preparation of this 
second edition. 
We would also like to express our sincere thanks to Mr. Ray Stata and Analog De-
vices, Inc. for their generous and continued support of signal processing and this text 
through funding of the Distinguished Professor Chair in Electrical Engineering. We also 
thank M.I.T. for providing support and an invigorating environment in which to develop 
our ideas. 
The encouragement, patience, technical support, and enthusiasm provided by 
Prentice-Hall, and in particular by Marcia Horton, Tom Robbins, Don Powley, and their 
predecessors and by Ralph Pescatore of TKM ProduCtions and the production staff at 
Prentice-Hall, have been crucial in making this second edition a reality. 
Alan V. Oppenheim 
Alan S. Will sky 
Cambridge, Massachusetts 

FoREWORD 
The concepts of signals and systems arise in a wide variety of fields, and the ideas and 
techniques associated with these concepts play an important role in such diverse areas of 
science and technology as communications, aeronautics and astronautics, circuit design, 
acoustics, seismology, biomedical engineering, energy generation and distribution sys-
tems, chemical process control, and speech processing. Although the physical nature of 
the signals and systems that arise in these various disciplines may be drastically different, 
they all have two very basic features in common. The signals, which are functions of one 
or more independent variables, contain information about the behavior or nature of some 
phenomenon, whereas the systems respond to particular signals by producing other sig-
nals or some desired behavior. Voltages and currents as a function of time in an electrical 
circuit are examples of signals, and a circuit is itself an example of a system, which in this 
case responds to applied voltages and currents. As another example, when an automobile 
driver depresses the accelerator pedal, the automobile responds by increasing the speed 
of the vehicle. In this case, the system is the automobile, the pressure on the accelerator 
pedal the input to the system, and the automobile speed the response. A computer program 
for the automated diagnosis of electrocardiograms can be viewed as a system which has as 
its input a digitized electrocardiogram and which produces estimates of parameters such 
as heart rate as outputs. A camera is a system that receives light from different sources 
and reflected from objects and produces a photograph. A robot arm is a system whose 
movements are the response to control inputs. 
In the many contexts in which signals and systems arise, there are a variety of prob-
lems and questions that are of importance. In some cases, we are presented with a specific 
system and are interested in characterizing it in detail to understand how it will respond to 
various inputs. Examples include the analysis of a circuit in order to quantify its response 
to different voltage and current sources and the determination of an aircraft's response 
characteristics both to pilot commands and to wind gusts. 
In other problems of signal and system analysis, rather than analyzing existing sys-
tems, our interest may be focused on designing systems to process signals in particular 
ways. One very common context in which such problems arise is in the design of systems 
to enhance or restore signals that have been degraded in some way. For example, when 
a pilot is communicating with an air traffic control tower, the communication can be de-
graded by the high level of background noise in the cockpit. In this and many similar cases, 
it is possible to design systems that will retain the desired signal, in this case the pilot's 
voice, and reject (at least approximately) the unwanted signal, i.e., the noise. A similar 
set of objectives can also be found in the general area of image restoration and image 
enhancement. For example, images from deep space probes or earth-observing satellites 
typically represent degraded versions of the scenes being imaged because of limitations of 
the imaging equipment, atmospheric effects, and errors in signal transmission in returning 
the images to earth. Consequently, images returned from space are routinely processed 
by systems to compensate for some of these degradations. In addition, such images are usu-
xxYii 

xxviii 
Foreword 
ally processed to enhance certain features, such as lines (corresponding, for example, to 
river beds or faults) or regional boundaries in which there are sharp contrasts in color or 
darkness. 
In addition to enhancement and restoration, in many applications there is a need to 
design systems to extract specific pieces of information from signals. The estimation of 
heart rate from an electrocardiogram is one example. Another arises in economic forecast-
ing. We may, for example, wish to analyze the history of an economic time series, such as 
a set of stock market averages, in order to estimate trends and other characteristics such 
as seasonal variations that may be of use in making predictions about future behavior. In 
other applications, the focus may be on the design of signals with particular properties. 
Specifically, in communications applications considerable attention is paid to designing 
signals to meet the constraints and requirements for successful transmission. For exam-
ple, long distance communication through the atmosphere requires the use of signals with 
frequencies in a particular part of the electromagnetic spectrum. The design of communi-
cation signals must also take into account the need for reliable reception in the presence 
of both distortion due to transmission through the atmosphere and interference from other 
signals being transmitted simultaneously by other users. 
Another very important class of applications in which the concepts and techniques 
of signal and system analysis arise are those in which we wish to modify or control the 
·characteristics of a given system, perhaps through the choice of specific input signals or 
by combining the system with other systems. lllustrative of this kind of application is the 
design of control systems to regulate chemical processing plants. Plants of this type are 
equipped with a variety of sensors that measure physical signals such as temperature, hu-
midity, and chemical composition. The control system in such a plant responds to these 
sensor signals by adjusting quantities such as flow rates and temperature in order to regu-
late the ongoing chemical process. The design of aircraft autopilots and computer control 
systems represents another example. In this case, signals measuring aircraft speed, alti-
tude, and heading are used by the aircraft's control system in order to adjust variables such 
as throttle setting and the position of the rudder and ailerons. These adjustments are made 
to ensure that the aircraft follows a specified course, to smooth out the aircraft's ride, and 
to enhance its responsiveness to pilot commands. In both this case and in the previous ex-
ample of chemical process control, an important concept, referred to as feedback, plays a 
major role, llS measured signals are fed back and used to adjust the response characteristics 
of a system. 
The examples in the preceding paragraphs represent only a few of an extraordinarily 
wide variety of applications for the concepts of signals and systems. The importance of 
these concepts stems not only from the diversity of phenomena and processes in which 
they arise, but also from the collection of ideas, analytical techniques, and methodologies 
that have been and are being developed and used to solve problems involving signals and 
systems. The history of this development extends back over many centuries, and although 
most of this work was motivated by specific applications, many of these ideas have proven 
to be of central importance to problems in a far larger variety of contexts. than those for 
which they were originally intended; For example, the tools of Fourier analysis, which 
form the basis for the frequency-domain analysis of signals and systems, and which we 
will develop in some detail in this book, can be traced from problems of astronomy studied 
by the ancient Babylonians to the development of mathematical physics in the eighteenth 
and nineteenth centuries. 

Foreword 
xxix 
In some of the examples that we have mentioned, the signals vary continuously in 
time, whereas in others, their evolution is described only at discrete points in time. For 
example, in the analysis of electrical circuits and mechanical systems we are concerned 
with signals that vary continuously. On the other hand, . the daily closing stock market 
average is by its very nature a signal that evolves at discrete points in time (i.e., at the 
close of each day). Rather than a curve as a function of a continuous variable, then, the 
closing stock market average is a sequence of numbers associated with the discrete time 
instants at which it is specified. This distinction in the basic description of the evolution of 
signals and of the systems that respond to or process these signals leads naturally to two 
parallel frameworks for signal and system analysis, one for phenomena and processes that 
are described in continuous time and one for those that are described in discrete time. 
The concepts and techniques associated both with continuous-time signals and sys-
tems and with discrete-time signals and systems have a rich history and are conceptually 
closely related. Historically, however, because their applications have in the past been suf-
ficiently different, they have for the most part been studied and developed somewhat sepa-
rately. Continuous-time signals and systems have very strong roots in problems associated 
with physics and, in the more recent past, with electrical circuits and communications. 
The techniques of discrete-time signals and systems haye strong roots in numerical analy-
sis, statistics, and time-series analysis associated with such applications as the analysis of 
economic and demographic data. Over the past several decades, however, the disciplines 
of continuous-time and discrete-time signals and systems have become increasingly en-
twined and the applications have become highly interrelated. The major impetus for this 
has come from the dramatic advances in technology for the implementation of systems 
and for the generation of signals. Specifically, the continuing development of high-speed 
digital computers, integrated circuits, and sophisticated high-density device fabrication 
techniques has made it increasingly advantageous to consider processing continuous-time 
signals by representing them by time samples (i.e., by converting them to discrete-time 
signals). As one example, the computer control system for a modern high-performance 
aircraft digitizes sensor outputs such as vehicle speed in order to produce a sequence of 
sampled measurements which are then processed by the control system. 
Because of the growing interrelationship between continuous-time signals and sys-
tems and discrete-time signals and systems and because of the close relationship among 
the concepts and techniques associated with each, we have chosen in this text to develop 
the concepts of continuous-time and discrete-time signals and systems in parallel. Since 
many of the concepts are similar (but not identical), by treating them in parallel, insight 
and intuition can be shared and both the simjlarities and differences between them become 
better focused. In addition, as will be evident as we proceed through the material, there 
are some concepts that are inherently easier to understand in one framework than the other 
and, once understood, the insight is easily transferable. Furthermore, this parallel treatment 
greatly facilitates our understanding of the very important practical context in which con-
tinuous and discrete time are brought together, namely the sampling of continuous-time 
signals and the processing of continuous-time signals using discrete-time systems. 
As we have so far described them, the notions of signals and systems are extremely 
general concepts. At this level of generality, however, only the most sweeping statements 
can be made about the nature of signals and systems, and their properties can be discussed 
only in the most elementary terms. On the other hand, an important and fundamental notion 
in dealing with signals and systems is that by carefully choosing subclasses of each with 

XXX 
Foreword 
particular properties that can then be exploited, we can analyze and characterize these 
signals and systems in great depth. The principal focus in this book is on the particular 
class of linear time-invariant systems. The properties of linearity and time invariance that 
define this class lead to a remarkable set of concepts and techniques which are not only of 
major practical importance but also analytically tractable and intelleCtually satisfying. 
As we have emphasized in this foreword, signal and system analysis has a long his-
tory out of which have emerged some basic techniques and fundamental principles which 
have extremely broad areas of application. Indeed, signal and system analysis is constantly 
evolving and developing in response to new problems, techniques, and opportunities. We 
fully expect this development to accelerate in pace as improved technology makes possi-
ble the implementation of increasingly complex systems and signal processing techniques. 
In the future we will see signals and systems tools and concepts applied to an expanding 
scope of applications. For these reasons, we feel that the topic of signal and system analy-
sis represents a body of knowledge that is of essential concern to the scientist and engineer. 
We have chosen the set of topics presented in this book, the organization of the presen-
tation, and the problems in each chapter in a way that we feel will most help the reader 
to obtain a solid foundation in the fundamentals of signal and system analysis; to gain an 
understanding of some of the very important and basic applications of these fundamentals 
to problems in filtering, sampling, communications, and feedback system analysis; and to 
develop some appreciation for an extremely powerful and broadly applicable approach to 
formulating and solving complex problems. 

1 
SIGNALS AND SYSTEMS 
1.0 INTRODUCTION 
As described in the Foreword, the intuitive notions of signals and systems arise in a rich va-
riety of contexts. Moreover, as we will see in this book, there is an analytical framework-
that is, a language for describing signals and systems and an extremely powerful set of tools 
for analyzing them-that applies equally well to problems in many fields. In this chapter, 
we begin our development of the analytical framework for signals and systems by intro-
ducing their mathematical description and representations. In the chapters that follow, we 
· build on this foundation in order to develop and describe additional concepts and methods 
that add considerably both to our understanding· of signals and systems and to our ability 
to analyze and solve problems involving signals and systems that arise in a broad array of 
applications. 
1.1 CONTINUOUS-TIME AND DISCRETE-TIME SIGNALS 
1 . 1 . 1 Examples and Mathematical Representation 
Signals may describe a wide variety of physical phenomena. Although signals can be rep-
resented in many ways, in all cases the information in a signal is contained in a pattern of 
variations of some form. For example, consider the simple circuit in Figure 1.1. In this case, 
the patterns of variation over time in the source and capacitor voltages, Vs and vc, are exam-
ples of signals. Similarly, as depicted in Figure 1.2, the variations over time of the applied 
force f and the resulting automobile velocity v are signals. As another example, consider 
the human vocal mechanism, which produces speech by creating fluctuations in acous-
tic pressure. Figure 1.3 is an illustration of a recording of such a speech signal, obtained by 
1 

2 
Signals and Systems 
Chap. 1 
A 
c 
~----~ 
-pv 
Figure 1. 1 
A simple RC circuit with source 
voltage Vs and capacitor voltage Vc. 
Figure 1.2 
An automobile responding to an 
applied force f from the engine and to a re-
tarding frictional force pv proportional to the 
automobile's velocity v. 
I 
I 
~ --
--! _ _ _ _ j _____ ~ _ _ _ _ 2 ____ ______ l ____ _ ~ __ __ J 
1 
sh 
1 
oul 
1 
d 
1 
r--- -
- , - -- --
I -- --~-- -- -,-----~-
--
-
-
, -
- --
- T - --- - , 
I 
I 
I 
I 
I 
I 
... - - - - -'- - - - - ~ - - - - ..! - - - - - '- - ---! - - - - -'-- -- - ~ - - - - -' 
w 
I 
e 
r - - - - -,- - - - - I - - - - I - - - - - ,- - - - - I - - - - -,- - - - - T - - - - -, 
I 
I 
I 
I 
I 
I 
I 
I 
I 
.. - - - - -'- - - - ..... ~ - - - - .!. - - - - - '- - - - - ..!. - - - - ..:.'_ - - - -
.!.. - - - - -' 
ch 
a 
· ,- - - - - I---- - , -- ---~- - - - -,-----,- - -- - I-- .:_ - -,- - - - - .. 
:......,_~LA...~: 
I 
~'fl 
,.;---., 
I 
I 
-
~ 
; 
~ 
1 
I 
I 
I 
I 
I 
I 
I 
I 
~ - -- -! __ __ j _ _ ___ ~ --- - ~-----~ - -- -~---- - ~~ - - - J 
a 
1 
se 
Figure 1.3 
Example of a record-
ing of speech. [Adapted from Ap-
plications of Digital Signal Process-
ing, A.V. Oppenheim, ed. (Englewood 
Cliffs, N.J.: Prentice-Hall, Inc., 1978), 
p. 121 .] The signal represents acous-
tic pressure variations as a function 
of time for the spoken words "should 
we chase." The top line of the figure 
corresponds to the word "should," 
the second line to the word "we," 
and the last two lines to the word 
"chase." (We have indicated the ap-
proximate beginnings and endings 
of each successive sound in each 
word.) 
using a microphone to sense variations in acoustic pressure, which are then converted into 
an electrical signal. As can be seen in the figure, different sounds correspond to different 
patterns in the variations of acoustic pressure, and the human vocal system produces intel-
ligible speech by generating particular sequences of these patterns. Alternatively, for the 
monochromatic picture, shown in Figure .1.4, it is the pattern of variations in brightness 
across the image that is important. 

Sec. 1.1 
Continuous-Time and Discrete-Time Signals 
Figure 1 .4 
A monochromatic 
picture. 
3 
Signals are represented mathematically as functions of one or more independent 
variables. For example, a speech signal can be represented mathematically by acoustic 
pressure as a function of time, and a picture can be represented by brightness as a func-
tion of two spatial variables. In this book, we focus our attention on signals involving a 
single independent variable. For convenience, we will generally refer to the independent 
variable as time, although it may not in fact represent time in specific applications. For 
example, in geophysics, signals representing variations with depth of physical quantities 
such as density, porosity, and electrical resistivity are used to study the structure of the 
earth. Also, knowledge of the variations of air pressure, temperature, and wind speed with 
altitude are extremely important in meteorological investigations. Figure 1.5 depicts a typ-
ical example of annual average vertical wind profile as a function of height. The measured 
variations of wind speed with height are used in examining weather patterns, as well as 
wind conditions that may affect an aircraft during final approach and landing. 
Throughout this book we will be considering two basic types of signals: continuous-
time signals and discrete-time signals. In the case of continuous-time signals the inde-
pendent variable is continuous, and thus these signals are defined for a continuum of values 
26 
24 
22 
20 
18 
~16 
0 g 14 
~ 12 
l'i 10 
(/) 
8 
6 
4 
2 
0 
200 
400 
600 
800 1 ,000 1 ,200 1 ,400 . 1 ,600 
Height (feet) 
Figure 1.s 
Typical annual vertical 
wind profile. (Adapted from Crawford 
and Hudson, National Severe Storms 
Laboratory Report, ESSA ERLTM-NSSL 
48, August 1970.) 

4 
Signals and Systems 
Chap. 1 
400 
350 
300 
250 
200 
150 
100 
50 
ot 
Jan. 5,1929 
Jan. 4,1930 
Figure 1.6 
An example of a discrete-time signal: The weekly Dow-Jones 
stock market index from January 5, 1929, to January 4, 1930. 
of the independent variable. On the other hand, discrete-time signals are defined only at 
discrete times, and consequently, for these signals, the independent variable takes on only 
a discrete set of values. A speech signal as a function of time and atmospheric pressure 
as a function of altitude are examples of continuous-time signals. The weekly Dow-Jones 
stock market index, as illustrated in Figure 1.6, is an example of a discrete-time signal. 
Other examples of discrete-time signals can be found in demographic studies in which 
various attributes, such as average budget, crime rate, or pounds of fish caught, are tab-
ulated against such discrete variables as family size, total population, or type of fishing 
vessel, respectively. 
To distinguish between continuous-time and discrete-time signals, we will use the 
symbol t to denote the continuous-time independent variable and n to denote the discrete-
time independent variable. In addition, for continuous-time signals we will enclose the 
independent variable in parentheses ( · ), whereas for discrete-time signals we will use 
brackets [ · ] to enclose the independent variable. We will also have frequent occasions 
when it will be useful to represent signals graphically. Illustrations of a continuous-time 
signal x(t) and a discrete-time signal x[n] are shown in Figure 1. 7. It is important to note 
that the discrete-time signal x[n] is defined only.for integer values of the independent 
variable. Our choice of graphical representation for x[n] emphasizes this fact, and for 
further emphasis we will on occasion refer to x[n] as a discrete-time sequence. 
A discrete-time signal x[n] may represent a phenomenon for which the independent 
variable is inherently discrete. Signals such as demographic data are examples of this. On 
the other hand, a very important class of discrete-time signals arises from the sampling of 
continuous-time signals. In this case, the discrete-time signal x[n] represents successive 
samples of an underlying phenomenon for which the independent variable is continuous. 
Because of their speed, computational power, and flexibility, modem digital processors are 
used to implement many practical systems, ranging from digital autopilots to digital audio 
systems. Such systems require the use of discrete-time sequences representing sampled 
versions of continuous-time signals-e.g., aircraft position, velocity, and heading for an 

Sec. 1.1 
Continuous-Time and Discrete-Time Signals 
x(t) 
0 
(a) 
x[n] 
x[O] 
n 
Figure 1.7 
Graphical representations of (a) continuous-time and (b) discrete-
time signals. 
5 
autopilot or speech and music for an audio system. Also, pictures in newspapers--or in this 
book, for that matter- actually consist of a very fine grid of points, and each of these points 
represents a sample of the brightness of the corresponding point in the original image. No 
matter what the source of the data, however, the si~nal x[n] is defined only for integer 
values of n. It makes no more sense to refer to the 32th sample of a digital speech signal 
than it does to refer to the average budget for a family with 2~ family members. 
Throughout most of this book we will treat discrete-time signals and continuous-time 
signals separately but in parallel, so that we can draw on insights developed in one setting 
to aid our understanding of another. In Chapter 7 we will return to the question of sampling, 
and in that context we will bring continuous-time and discrete-time concepts together in 
order to ex<imine the relationship between a continuous-time signal and a discrete-time 
signal obtained from it by sampling. 
1. 1 .2 Signal Energy and Power 
From the range of examples provided so far, we see that signals may represent a broad 
variety of phenomena. In many, but not all, applications, the signals we consider are di-
rectly related to physical quantities capturing power and energy in a physical system. For 
example, if v(t) and i(t) are, respectively, the voltage and current across a resistor with 
resistance R, then the instantaneous power is 
"p(t) = v(t)i(t) = ~v2 (t). 
(1.1) 

6 
Signals and Systems 
Chap. 1 
The total energy expended over the time interval t 1 s t s t2 is 
f
12 
p(t)dt = f'
2 
.!.v2(t)dt, 
,, 
,, R 
(1.2) 
and the average power over this time interval is 
-
-
p(1)d1 = -
-
- v2(1)dt. 
1 ftz 
1 f'2 1 
12 -
t1 
11 
t2 - ft 
11 R 
(1.3) 
Similarly, for the automobile depicted in Figure 1.2, the instantaneous power dissipated 
through friction is p(t) = bv2(t), and we can then define the total energy and average 
power over a time interval in the same way as in eqs. (1.2) and (1.3). 
With simple physical examples such as these as motivation, it is a common and 
worthwhile convention to use similar terminology for power and energy for any continuous-
time signal x(t) or any discrete-time signal x[n]. Moreover, as we will see shortly, we will 
frequently find it convenient to consider signals that take on complex values. In this case, 
the total energy over the time interval 11 s 1 s 12 in a continuous-time signal x(1) is 
defined as 
(1.4) 
where Jxl denotes the magnitude of the (possibly complex) number x. The time-averaged 
power is obtained by dividing eq. (1.4) by the length, t2 - t1, of the time interval. Simi-
larly, the total energy in a discrete-time signal x[n] over the time interval n, s n s n2 is 
defined as 
(1.5) 
and dividing by the number of points in the interval, n2 - n 1 + 1, yields the average power 
over the interval. It is important to remember that the terms "power" and "energy" are used 
here independently of whether the quantities in eqs. ( 1.4) and ( 1.5) actually are related to 
physical energy. 1 Nevertheless, we will find it convenient to use these terms in a general 
fashion. 
Furthermore, in many systems we will be interested in examining power and energy 
in signals over an infinite time interval, i.e., for - oo < 1 < + oo or for -oo < n < + oo. In 
these cases, we define the total energy as limits of eqs. (1.4) and (1.5) as the time interval 
increases without bound. That is, in continuous time, 
I
T 
J+"' 
Eoo ~ }~ - T Jx(1)J2 dt = 
-oo Jx(t)J2 dt, 
(1.6) 
and in discrete time, 
+N 
+co 
Eoo ~ lim L Jx[n]J2 = L Jx[n]J2. 
N -+"' n= - N 
n= - 00 
(1.7) 
1 Even if such a relationship does exist, eqs. (1.4) and (1.5) may have the wrong dimensions and scalings. 
For example, comparing eqs. (1.2) and (1.4), we see that if x(t) represents the voltage across a resistor, then 
eq. (1 .4) must be divided by the resistance (measured, for example, in ohms) to obtain units of physical energy. 

Sec. 1.2 
Transformations of the Independent Variable 
7 
Note that for some signals the integral in eq. (1.6) or sum in eq. (1.7) might not converge-
e.g., if x(t) or x[n] equals a nonzero constant value for all time. Such signals have infinite 
energy, while signals with E"' < oo have finite energy. 
In an analogous fashion, we can define the time-averaged power over an infinite 
interval as 
/:; 
1 IT 
P"' = lim 2T 
jx(t)/2 dt 
r~ oo 
- T 
(1.8) 
and 
(1.9) 
in continuous time and discrete time, respectively. With these definitions, we can identify 
three important classes of signals. The first of these is the class of signals with finite total 
energy, i.e., those signals for which E"' < oo. Such a signal must have zero average power, 
since in the continuous time case, for example, we see from eq. ( 1.8) that 
P"' = lim E"' = 0. 
(1.10) 
r ~oo 2T 
An example of a finite-energy signal is a signal that takes on the value 1 for 0 :s; t :s; 1 
and 0 otherwise. In this case, E"' = 1 and Poo = 0. 
A second class of signals are those with finite average power Poo. From what we 
have just seen, if P"' > 0, then, of necessity, E"' = oo. This, of course, makes sense, since 
if there is a nonzero average energy per unit time (i.e., nonzero power), then integrating 
or summing this over an infinite time interval yields an infinite amount of energy. For 
example, the constant signal x[n] = 4 has infinite energy, but average power Poo = 16. 
There are also signals for which neither P"' nor Eoo are finite. A simple example is the 
signal x(t) = t. We will encounter other examples of signals in each of these classes in 
the remainder of this and the following chapters. 
1 .2 TRANSFORMATIONS OF: THE INDEPENDENT VARIABLE 
A central concept in signal and system analysis is that of the transformation of a signal. 
For example, in an aircraft control system, signals corresponding to the actions of the pilot 
are transformed by electrical and mechanical systems into changes in aircraft thrust or 
the positions of aircraft control surfaces such as the rudder or ailerons, which in tum are 
transformed through the dynamics and kinematics of the vehicle into changes in aircraft 
velocity and heading. Also, in a high-fidelity audio system, an input signal representing 
music as recorded on a cassette or compact disc is modified in order to enhance desirable 
characteristics, to remove recording noise, or to balance the several components of the 
signal (e.g., treble and bass). In this section, we focus on a very limited but important class 
of elementary signal transformations that involve simple modification of the independent 
variable, i.e., the time axis. As we will see in this and subsequent sections of this chapter, 
these elementary transformations allow us to introduce several basic properties of signals 
and systems. In later chapters, we will find that they also play an important role in defining 
and characte!izing far richer and important classes of systems. 

8 
Signals and Systems 
Chap. 1 
1.2.1 Examples of Transformations of the Independent Variable 
A simple and very important example of transforming the independent variable of a signal 
is a time shift. A time shift in discrete time is illustrated in Figure 1.8, in which we have 
two signals x[n] and x[n - no] that are identical in shape, but that are displaced or shifted 
relative to each other. We will also encounter time shifts in continuous time, as illustrated 
in Figure 1.9, in which x(t - to) represents a delayed (if to is positive) or advanced (if to 
is negative) version of x(t). Signals that are related in this fashion arise in applications 
such as radar, sonar, and seismic signal processing, in which several receivers at different 
locations observe a signal being transmitted through a medium (water, rock, air, etc.). In 
this case, the difference in propagation time from the point of origin of the transmitted 
signal to any two receivers results in a time shift between the signals at the two receivers. 
A second basic transformation of the time axis is that of time reversal. For example, 
as illustrated in Figure 1.1 0, the signal x[-n] is obtained from the signal x[ n] by a reflec-
tion about n = 0 (i.e., by reversing the signal). Similarly, as depicted in Figure 1.11, the 
signal x(-t) is obtained from the signal x(t) by a reflection about t = 0. Thus, if x(t) rep-
resents an audio tape recording, then x( -t) is the same tape recording played backward. 
Another transformation is that of time scaling. In Figure 1.12 we have illustrated three 
signals, x(t), x(2t), and x(t/2), that are related by linear scale changes in the independent 
variable. If we again think of the example of x(t) as a tape recording, then x(2t) is that 
recording played at twice the speed, and x(t/2) is the recording played at half-speed. 
It is often of interest to determine the effect of transforming the independent variable 
of a given signal x(t) to obtain a signal of the form x(at + /3), where a and f3 are given 
numbers. Such a transformation of the independent variable preserves the shape of x(t), 
except that the resulting signal may be linearly stretched if Ia I < 1, linearly compressed 
if Ia I > 1, reversed in time if a < 0, and shifted in time if f3 is nonzero. This is illustrated 
in the following set of examples. 
x[n] 
x[n- no] 
0 
n 
Figure 1 .8 
Discrete-time signals 
related by a time shift. In this figure 
no > 0, so that x[n - no] is a delayed 
n 
verson of x[n] (i.e., each point in x[n] 
occurs later in x[n- n0]). 

Sec. 1.2 
Transformations of the Independent Variable 
x[n] 
n 
(a) 
x[- n] 
n 
(b) 
Figure 1.9 
Continuous-time signals related 
by a time shift. In this figure ~ < 0, so that 
x(t -
~) is an advanced version of x(t) (i.e., 
each point in x( t) occurs at an earlier time in 
x(t -
~)) . 
Figure 1.10 
(a) A discrete-time signal x[n]; (b) its reflec-
tion x[- n] about n = 0. 
x(t) 
(a) 
x(- t) 
(b) 
Figure 1.11 
(a) A continuous-time signal x(t); (b) its 
reflection x( - t) about t = 0. 
x(t) 
~ 
x(2t) & 
x(t/2) 
~ 
Figure 1. 12 
Continuous-time signals 
related by time scaling. 
9 

10 
Signals and Systems 
Chap. 1 
Example 1.1 
Given the signal x(t) shown in Figure 1.13(a), the signal x(t + 1) corresponds to an 
advance (shift to the left) by one unit along the t axis as illustrated in Figure 1.13(b). 
Specifically, we note that the value of x(t) at t = to occurs in x(t + 1) at t = to - 1. For 
- 1 
-1 
'I <(t) 
0 
1 
2 
(a) 
0 
1 
0 
(b) 
1 
(c) 
0 
2/3 
4/3 
(d) 
- 2/3 
0 
2/3 
(e) 
2 
Figure 1.13 
(a) The continuous-time signal x(t) used in Examples 1.1-1.3 
to illustrate transformations of the independent variable; (b) the time-shifted 
signal x(t + 1); (c) the signal x(- t + 1) obtained by a time shift and a time 
reversal; (d) the time-scaled signal x(~t); and (e) the signal x(~t+ 1) obtained 
by time-shifting and scaling. 

Sec. 1.2 
Transformations of the Independent Variable 
11 
example, the value of x(t) at t = 1 is found in x(t + 1)at t = 1 - 1 = 0. Also, since 
x(t) is zero fort < 0, we have x(t + 1) zero for t < - 1. Similarly, since x(t) is zero for 
t > 2, x(t + 1) is zero fort > 1. 
Let us also consider the signal x( - t + 1), which may be obtained by replacing t 
with - tin x(t + 1). That is, x( - t + 1) is the time reversed version of x(t + 1). Thus, 
x( -t + 1) may be obtained graphically by reflecting x(t + 1) about the taxis as shown 
in Figure 1.13(c). 
Example 1.2 
Given the signal x(t), shown in Figure 1.13(a), the signal x(~t) corresponds to a linear 
compression of x(t) by a factor of~ as illustrated in Figure 1.13(d). Specifically we note 
that .the value of x(t) at t = to occurs in x(~t) at t = 
~t0 • For example, the value of 
x(t) at t = 1 is found in x(~t) at t = 
~ (1) = ~ -Also, since x(t) is zero fort < 0, we 
have x( ~ t) zero fort < 0. Similarly, since x(t) is zero fort > 2, x(~t) is zero fort> ~-
Example 1.3 
Suppose that we would like to determine the effect of transforming the independent vari-
able of a given signal, x(t), to obtain a signal of the form x(at + {3), where a and f3 are 
given numbers. A systematic approach to doing this is to first delay or advance x(t) in 
accordance with the value of f3 , and then to perform time scaling and/or time reversal on 
the resulting signal in accordance with the value of a. The delayed or advanced signal is 
linearlystretchedifjaj < 1,linearlycompressedifjaj > 1,andreversedintimeifa < 0. 
To illustrate this approach, let us show how x( ~t + 1) may be determined for the 
signal x(t) shown in Figure 1.13(a). Since f3 = 1, we first advance (shift to the left) x(t) 
by 1 as shown in Figure 1.13(b) .. Since jaj = ~.we may linearly compress the shifted 
signal of Figure 1.13(b) by a factor of ~ to obtain the signal shown in Figure 1.13( e). 
In addition to their use in representing physical pheQomena such as the time shift 
in a sonar signal and the speeding up or reversal of an audiotape, transformations of the 
independent variable are extremely useful in signal and system analysis. In Section 1.6 
and in Chapter 2, we will use transformations of the independent variable to introduce and 
analyze the properties of systems. These transformations are also important in defining 
and examining some important properties of signals. 
1 .2.2 Periodic Signals 
An important class of signals that we will encounter frequently throughout this book is 
the class of periodic signals. A periodic continuous-time signal x(t) has the property that 
there is a positive value of T for which 
x(t) = x(t + T) 
(1.11) 
for all values oft. In other words, a periodic signal has the property that it is unchanged by a 
time shift ofT. In this case, we say that x(t) is periodic with period T. Periodic continuous-
time signals arise in a variety of contexts. For example, as illustrated in Problem 2.61, 
the natural response of systems in which energy is conserved, such as ideal LC circuits 
without resistive energy dissipation and ideal mechanical systems without frictional losses, 
are periodic and, in fact, are composed of some of the basic periodic signals that we will 
introduce in Section 1.3. 

12 
Signals and Systems 
Chap. 1 
x(t) 
... ~A&A~··· 
Figure 1 . 14 A continuous-time 
periodic signal. 
-2T 
- T 
0 
T 
2T 
An example of a periodic continuous-time signal is given in Figure 1.14. From the 
figure or from eq. (1.11), we can readily deduce that if x(t) is periodic with period T, then 
x(t) = x(t + mT) for all t and for any integer m. Thus, x(t) is also periodic with period 
2T, 3T, 4T, .... The fundamental period To of x(t) is the smallest positive value ofT for 
which eq. (1.11) holds. This definition of the fundamental period works, except if x(t) is 
a constant. In this case the fundamental period is undefined, since x(t) is periodic for any 
choice ofT (so there is no smallest positive value). A signal x(t) that is not periodic will 
be referred to as an aperiodic signal. 
Periodic signals are defined analogously in discrete time. Specifically, a discrete-
time signal x[n] is periodic with period N, where N is a positive integer, if it is unchanged 
by a time shift of N, i.e., if 
x[n] = x[n + N] 
(1.12) 
for all values of n. If eq. (1.12) holds, then x[n] is also periodic with period 2N, 3N, . ... 
The fundamental period No is the smallest positive value of N for which eq. (1.12) holds. 
An example of a discrete-time periodic signal with fundamental period No = 3 is shown 
in Figure 1.15. 
x[n) 
Example 1.4 
Figure 1 . 1 5 
A discrete-time pe-
n 
riodic signal with fundamental period 
No= 3. 
Let us illustrate the type of problem solving that may be required in determining whether 
or not a given signal is periodic. The signal whose periodicity we wish to check is given 
by 
( ) = { cos(t) 
if t < 0 
X t 
. () 'f 
0. 
smt 
It~ 
(1.13) 
From trigonometry, we know that cos(t + 27T) = cos(t) and sin(t + 27T) = sin(t). Thus, 
considering t > 0 and t < 0 separately, we see that x(t) does repeat itself over every 
interval oflength 27T. However, as illustrated in Figure 1.16, x(t) also has a discontinuity 
at the time origin that does not recur at any other time. Since every feature in the shape of 
a periodic signal must recur periodically, we conclude that the signal x(t) is not periodic. 

Sec. 1.2 
Transformations of the Independent Variable 
13 
x(t) 
Figure 1.16 
The signal x(t) considered in Example 1.4. 
1.2.3 Even and Odd Signals 
Another set of useful properties of signals relates to their symmetry under time reversal. 
A signal x(t) or x[n] is referred to as an even signal if it is identical to its time-reversed 
counterpart, i.e., with its reflection about the origin. In continuous time a signal is even if 
x( - t) = x(t), 
while a discrete-time signal is even if 
A signal is referred to as odd if 
x[ - n] = x[n]. 
x(-t) = -x(t), 
x[ -n] = - x[n]. 
(1.14) 
(1.15) 
(1.16) 
(1.17) 
An odd signal must necessarily be 0 at t = 0 or n = 0, since eqs. (1.16) and (1.17) require 
that x(O) = - x(O) and x[O] = - x[O]. Examples of even and odd continuous-time signals 
are shown in Figure 1.17. 
x(t) 
(a) 
x(t) 
Figure 1 .17 
(a) An even con-
tinuous-time signal; (b) an odd 
continuous-time signal. 

14 
x[n) = { 1, n ~ 0 
0, n < 0 
.. .'1111 
- 3 - 2 - 1 0 1 2 3 
l
t. n < 0 
Sv{x[nJ} = 
~,n = O 
2. n > 0 
·· · Ill }ttl··· 
-3-2 - 1 0 1 2 3 
1 
- 3 - 2-'-1 
2I r r 
Signals and Systems 
Chap. 1 
n 
n 
n 
Figure 1 . 18 
Example of the even-
odd decomposition of a discrete-time 
signal. 
An important fact is that any signal can be broken into a sum of two signals, one of 
which is even and one of which is odd. To see this, consider the signal 
1 
Sv{ x(t)} = 2[x(t)+x(-t)], 
(1.18) 
which is referred to as the even part of x(t). Similarly, the odd part of x(t) is given by 
1 
0d{x(t)} = 2[x(t)- x( -t)]. 
(1.19) 
It is a simple exercise to check that the even part is in fact even, that the odd part is odd, 
and that x(t) is the sum of the two. Exactly analogous definitions hold in the discrete-
time case. An example of the even-odd decomposition of a discrete-time signal is given 
in Figure 1.18. 
1 .3 EXPONENTIAL AND SINUSOIDAL SIGNALS 
In this section and the next, we introduce several basic continuous-time and discrete-time 
signals. Not only do these signals occur frequently, but they also serve as basic building 
blocks from which we can construct many other signals. 

Sec. 1.3 
Exponential and Sinusoidal Signals 
1.3.1 Continuous-Time Complex Exponential 
and Sinusoidal Signals 
The continuous-time complex exponential signal is of the form 
x(t) = Ce0 1
, 
15 
(1.20) 
where C and a are, in general, complex numbers. Depending upon the values of these 
parameters, the complex exponential can exhibit several different characteristics. 
RealExponentialSignah 
As illustrated in Figure 1.19, if C and a are real [in which case x(t) is called a real 
exponential], there are basically two types of behavior. If a is positive, then as t in-
creases x(t) is a growing exponential, a form that is used in describing many different 
physical processes, including chain reactions in atomic explosions and complex chemical 
reactions. If a is negative, then x(t) is a decaying exponential, a signal that is also used 
to describe a wide variety of phenomena, including the process of radioactive decay and 
the responses of RC circuits and damped mechanical systems. In particular, as shown 
in Problems 2.61 and 2.62, the natural responses of the circuit in Figure 1.1 and the 
automobile in Figure 1.2 are decaying exponentials. Also, we note that for a = 0, x(t) 
is constant. 
x(t) 
(a) 
x(t) 
(b) 
Figure 1 . 19 
Continuous,time real 
exponential x(t) = Ce"1: (a) a > 0; 
(b) a< 0. 

16 
Signals and Systems 
Chap. 1 
Periodic Complex Exponential and Sinusoidal Signals 
A second important class of complex exponentials is obtained by constraining a to be 
purely imaginary. Specifically, consider 
(1.21) 
An important property of this signal is that it is periodic. To verify this, we recall from 
eq. (1.11) that x(t) will be periodic with period T if 
(1.22) 
Or, since 
it follows that for periodicity, we must have 
(1.23) 
If w0 = 0, then x(t) = 1, which is periodic for any value ofT. If wo # 0, then the fun-
damental period To of x(t)-
that is, the smallest positive value ofT for which eq. (1.23) 
holds-is 
27T 
To = lwol" 
(1.24) 
Thus, the signals eiwot and e- Jwot have the same fundamental period. 
A signal closely related to the periodic complex exponential is the sinusoidal signal 
x(t) = A cos(wot + cp), 
(1.25) 
as illustrated in Figure 1.20. With seconds as the units oft, the units of cf> and w0 are radians 
and radians per second, respectively. It is also common to write w 0 = 27T fo, where fo has 
the units of cycles per second, or hertz (Hz). Like the complex exponential signal, the si-
nusoidal signal is periodic with fundamental period To given by eq. (1.24). Sinusoidal and 
x(t) = A cos (w0t + <J>) 
Figure 1 .20 
Continuous-time sinu-
soidal signal. 

Sec. 1.3 
Exponential and Sinusoidal Signals 
17 
complex exponential signals are also used to describe the characteristics of many physical 
processes-in particular, physical systems in which energy is conserved. For example, as 
shown in Problem 2.61, the natural response of an LC circuit is sinusoidal, as is the simple 
harmonic motion of a mechanical system consisting of a mass connected by a spring to a 
stationary support. The acoustic pressure variations corresponding to a single musical tone 
are also sinusoidal. 
By using Euler's relation,2 the complex exponential in eq. (1.21) can be written in 
terms of sinusoidal signals with the same fundamental period: 
ejwot = cos wot + j sin wot. 
(1.26) 
Similarly, the sinusoidal signal of eq. (1.25) can be written in terms of periodic complex 
exponentials, again with the same fundamental period: 
(1.27) 
Note that the two exponentials in eq. (1.27) have complex amplitudes. Alternatively, we 
can express a sinusoid in terms of a complex exponential signal as 
A cos(wot + lf>) = A(Jl.e{ej(wot+<f>>}, 
(1.28) 
where, if cis a complex number, CR.-e{c} denotes its real part. We will also use the notation 
dm{c} for the imaginary part of c, so that, for example, 
A sin(wot + l/>) = Adm{ej(wot+<f>>}. 
(1.29) 
From eq. (1.24), we see that the fundamental period To of a continuous-time sinu-
soidal signal or a periodic complex exponential is inversely proportional to lwol. which 
we will refer to as the fundamental frequency. From Figure 1.21, we see graphically what 
this. means. If we decrease the magnitude of w 0, we slow down the rate of oscillation and 
therefore increase the period. Exactly the opposite effects occur if we increase the mag-
nitude of w 0 . Consider now the case w 0 = 0. In this case, as we mentioned earlier, x(t) 
is constant and therefore is periodic with period T for any positive value ofT. Thus, the 
fundamental period of a constant signal is undefined. On the other hand, there is no am-
biguity in defining the fundamental frequency of a constant signal to be zero. That is, a 
constant signal has a zero rate of oscillation. 
Periodic signals-and in particular, the complex periodic exponential signal in 
eq. (1.21) and the sinusoidal signal in eq. (1.25)-provide important examples of signals 
with infinite total energy but finite average power. For example, consider the periodic ex-
ponential signal of eq. (1.21), and suppose that we calculate the total energy and average 
power in this signal over one period: 
Eperiod = foTo iejworl2 dt 
(To 
= Jo 
1 · dt = T0, 
(1.30) 
2Euler's relation and other basic ideas related to the manipulation of complex numbers and exponentials 
are considered in the mathematical review section of the problems at the end of the chapter. . 

18 
(a) 
(b) 
(c) 
Signals and Systems 
Chap. 1 
Figure 1.21 
Relationship between 
the fundamental frequency and period 
for continuous-time sinusoidal signals; 
here, wt > w:1 > WJ, which implies 
that 71 < T2 < Ta. 
1 
P period = T 
0 
Eperiod = 1. 
(1.31) 
Since there are an infinite number of periods as t ranges from -oo to +oo, the total energy 
integrated over all time is infinite. However, each period of the signal looks exactly the 
same. Since the average power of the signal equals 1 over each period, averaging over 
multiple periods always yields an average power of 1. That is, the complex periodic ex-

Sec. 1.3 
Exponential and Sinusoidal Signals 
19 
ponential signal has finite average power equal to 
' 
1 IT . 
2 
P, = lim -
ieJwotl dt = 1. 
T---> "" 2T - T 
(1.32) 
Problem 1.3 provides additional examples of energy and power calculations for periodic 
and aperiodic signals. · 
· 
Periodic complex exponentials will play a central role in much of our treatment of 
signals and systems, in part because they serve as extremely useful building blocks for 
many other signals. We will often find it useful to consider sets of harmonically related 
complex exponentials-that is, sets of periodic exponentials, all of which are periodic with 
a common period T0• Specifically, a necessary condition for a complex exponential ejwt to 
be periodic with period To is that 
ejwTo = 1, 
(1.33) 
which implies that wT0 is a multiple of 21T, i.e., 
wTo = 
21Tk, 
k = 0, ±1, ±2, . ... 
(1.34) 
Thus, if we define 
(1.35) 
we see that, to satisfy eq. (1.34), w must be an integer multiple of wo. That is, a harmoni-
cally related set of complex exponentials is a set of periodic exponentials with fundamental 
frequencies that are all multiples of a single positive frequency w0: 
k = 0, ±1, ±2, .... 
(1.36) 
Fork = 0, cPk(t) is a constant, while for any other value of k, cPk(t) is periodic with fun -
damental frequency I klwo and fundamental period 
21T 
_ To 
iklwo - Tkf" 
(1.37) 
The kth harmonic cPk(t) is still periodic with period To as well, as it goes through exactly 
ikl of its fundamental periods during any time interval oflength T0• 
Our use of the term "harmonic" is consistent with its use in music, where it refers 
to tones resulting from variations in acoustic pressure at frequencies that are integer mul-
tiples of a fundamental frequency. For example, the pattern of vibrations of a string on an 
·instrument such as a violin can be described as a superposition-i.e., a weighted sum--of 
harmonically related periodic exponentials. In Chapter 3, we will see that we can build a 
very rich class of periodic signals using the harmonically related signals of eq. (1.36) as 
the building blocks. 
Example 1.5 
It is sometimes desirable to express the sum of two complex exponentials as the product 
of a single complex exponential and a single sinusoid. For example, suppose we wish to 

20 
Signals and Systems 
Chap. 1 
plot the magnitude of the signal 
(1.38) 
To do this, we first factor out a complex exponential from the right side of eq. (1.38), 
where the frequency of this exponential factor is taken as the average of the frequencies 
of the two exponentials in the sum. Doing this, we obtain 
(1.39) 
which, because of Euler's relation, can be rewritten as 
x(t) = 2ei2-51 cos(O.St). 
(1.40) 
From this, we can directly obtain an expression for the magnitude of x(t): 
lx(t)l = 21 cos(O.St)l. 
(1.41) 
Here, we have used the fact that the magnitude of the complex exponential ei25 1 is always 
unity. Thus, lx(t)l is what is commonly referred to as a full-wave rectified sinusoid, as 
shown in Figure 1.22. 
Figure 1 .22 
The full-wave rectified sinusoid of Example 1.5. 
General Complex Exponential Signals 
The most general case of a complex exponential can be expressed and interpreted in terms 
of the two cases we have examined so far: the real exponential and the periodic complex 
exponential. Specifically, consider a complex exponential C eat, where C is expressed in 
polar form and a in rectangular form. That is, 
and 
a = r + jwo. 
Then 
(1.42) 
Using Euler's relation, we can expand this further as 
ceat = ICiert cos(wot + (}) + jiCiert sin(wot + (}). 
(1.43) 

Sec. 1.3 
Exponential and Sinusoidal Signals 
21 
Thus, for r = 0, the real and imaginary parts of a complex exponential are sinusoidal. For 
r > 0 they correspond to sinusoidal signals multiplied by a growing exponential, and for 
r < 0 they correspond to sinusoidal signals multiplied by a decaying exponential. These 
two cases are shown in Figure 1.23. The dashed lines in the figure correspond to the func-
tions ±!Clerc. From eq. (1.42), we see that !Clerc is the magnitude of the complex expo-
nential: Thus, the dashed curves act as an envelope for the oscillatory curve in the figure 
in that the peaks of the oscillations just reach these curves, and in this way the envelope 
provides us with a convenient way to visualize the general trend in the amplitude of the 
oscillations. 
x(t) 
(a) 
x(t) 
(b) 
Figure 1.23 
(a) Growing sinusoidal 
signal x(t) = Cert cos (wot + 8), 
r > 0; (b) decaying sinusoid x(t) = 
cert cos (wot + 8), r < o. 
Sinusoidal signals multiplied by decaying exponentials are commonly referred to as 
damped sinusoids. Examples of damped sinusoids arise in the response of RLC circuits 
and in mechanical systems containing both damping and restoring forces, such as automo-
tive suspension systems. These kinds of systems have mechanisms that dissipate energy 
(resistors, damping forces such as friction) with oscillations that decay in time. Examples 
illustrating such systems and their damped sinusoidal natural responses can be found in 
Problems 2.61 and 2.62. 
1.3.2 Discrete-Time Complex Exponential and Sinusoidal Signals 
As in continuous time, an important signal in discrete time is the complex e;xponential 
signal or sequence, defined by 
(1.44) 

22 
Signals and Systems 
Chap. 1 
where C and a are, in general, complex numbers. This could alternatively be expressed 
in the form 
x[n] = cef3n, 
(1.45) 
where 
a = ef3. 
Although the form of the discrete-time complex exponential sequence given in eq. ( 1.45) is 
more analogous to the form of the continuous-time exponential, it is often more convenient 
to express the discrete-time complex exponential sequence in the form of eq. (1.44). 
Real Exponential Signals 
If C and a are real, we can have one of several types of behavior, as illustrated in Fig-
ure 1.24.Iflal > 1 themagnitudeofthesignalgrowsexponentiallywithn, whileiflal < 1 
we have a decaying exponential. Furthermore, if a is positive, all the values of Ca" are of 
the same sign, but if a is negative then the sign of x[n] alternates. Note also that if a = 1 
then x[n] is a constant, whereas if a = - 1, x[n] alternates in value between +C and - C. 
Real-valued discrete-time exponentials are often used to describe population growth as 
a function of generation and total return on investment as a function of day, month, or 
quarter. 
Sinusoidal Signals 
Another important complex exponential is obtained by using the form given in eq. (1.45) 
and by constraining f3 to be purely imaginary (so that lal = 1). Specifically, consider 
(1.46) 
As in the continuous-time case, this signal is closely related to the sinusoidal signal 
x[n] = Acos(won + cp). 
. (1.47) 
If we taken to be dimensionless, then both w 0 and cp have units of radians. Three examples 
of sinusoidal sequences are shown in Figure 1.25. 
As before, Euler's relation allows us to relate complex exponentials and sinusoids: · 
ejwon = cos won+ j sin won 
(1.48) 
and 
(1.49) 
The signals in eqs. (1.46) and (1.47) are examples of discrete-time signals with infinite 
total energy but finite average power. For example, since lejwo"l2 = 1, every sample of 
the signal in eq. (1.46) contributes 1 to the signal's energy. Thus, the total energy for 
-oo < n < oo is infinite, while the average power per time point is obviously equal to 1. 
Other examples of energy and power calculations for discrete-time signals are given in 
Problem 1.3. 

Sec. 1.3 
Exponential and Sinusoidal Signals 
n 
(a) 
n 
(b) 
n 
(c) 
n 
(d) 
Figure 1 .24 
The real exponential 
signal x[n] = Ca": 
(a) a > 1; (b) 0 < a < 1; 
(c) -1 < a < 0; (d) a < - 1. 
23 

24 
Signals and Systems 
Chap. 1 
x[n] =cos (21Tn/12) 
n 
(a) 
x[n] =cos (81Tn/31) 
n 
(b) 
x[n] = cos (n/6) 
n 
(c) 
Figure 1 .25 
Discrete-time sinusoidal signals. 
General Complex Exponential Signals 
The general discrete-time complex exponential can be written and interpreted in terms of 
'real exponentials and sinusoidal signals. Specifically, if we write C and a in polar form, 

Sec. 1.3 
Exponential and Sinusoidal Signals 
25 
viz., 
and 
then 
(1 .50) 
Thus, for lal = 1, the real and imaginary parts of a complex exponential sequence are 
sinusoidal. For Ia I < 1 they correspond to sinusoidal sequences multiplied by a decaying 
exponential, while for lal > 1 they correspond to sinusoidal sequences multiplied by a 
growing exponential. Examples of these signals are depicted in Figure 1.26. 
' ' 
/ 
/ 
(a) 
(b) 
' 
/ 
/ 
/ 
' ' ' 
Figure 1.26 
(a) Growing discrete-time sinusoidal signals; (b) decaying 
discrete-time sinusoid. 
n 
n 
1.3.3 Periodicity Properties of Discrete-Time Complex Exponentials 
While there are many similarities between contim,1ous-time and discrete-time signals, 
there are also a number of important differences. One of these concerns the discrete-time 
exponential signal ejwon. In Section 1.3.1, we identified the following two properties of its 

26 
Signals and Systems 
Chap. 1 
continuous-time counterpart ejwot: (1) the larger the magnitude of w 0, the higher is the rate 
of oscillation in the signal; and (2) ej wot is periodic for any value of w 0 • In this section we 
d~scribe the discrete-time versions of both of these properties, and as we will see, there 
are definite differences between each of these and its continuous-time counterpart. 
The fact that the first of these properties is different in discrete time is a direct conse-
quence of another extremely important distinction between discrete-time and continuous-
time complex exponentials. Specifically, consider the discrete-time complex exponential 
with frequency wo + 21T: 
(1.51) 
From eq. (1.51), we see that the exponential at frequency w 0 + 21T is the same as that 
at frequency w0 . Thus, we have a very different situation from the continuous-time case, 
in which the signals ejwot are all distinct for distinct values of w0. In discrete time, these 
signals are not distinct, as the signal with frequency w0 is identical to the signals with 
frequencies w 0 ± 21T, w 0 ± 41T, and so on. Therefore, in considering discrete-time com-
plex exponentials, we need only consider a frequency interval of length 21T in which to 
choose w0 . Although, according to eq. (1.51), any interval of length 21T will do, on most 
occasions we will use the interval 0 ::5 w0 < 21T or the interval -
1T ::5 w0 < 1T. 
Because of the periodicity implied by eq. (1.51), the signal ejwon does not have a 
continually increasing rate of oscillation as w0 is increased in magnitude. Rather, as il-
lustrated in Figure 1.27, as we increase w0 from 0, we obtain signals that oscillate more 
and more rapidly until we reach w 0 = 1T. As we continue to increase w 0, we decrease the 
rate of oscillation until we reach wo = 21T, which produces the same constant sequence as 
w0 = 0. Therefore, the low-frequency (that is, slowly varying) discrete-time exponentials 
have values of wo near 0, 21T, and any other even multiple of 1T, while the high frequen-
cies (corresponding to rapid variations) are located near wo = ± 1T and other odd multiples 
of 1T. Note in particular that for w 0 = 1T or any other odd multiple of 1T, 
(1.52) 
so that this signal oscillates rapidly, changing sign at each point in time [as illustrated in 
Figure 1.27(e)]. 
The second property we wish to consider concerns the periodicity of the discrete-
time complex exponential. In order for the signal ejwon to be periodic with period N > 0, 
we must have 
(1.53) 
or equivalently, 
(1.54) 
For eq. (1.54) to hold, w0N must be a multiple of 21T. That is, there must be an integer m 
such that 
or equivalently, 
woN= 21Tm, 
m 
N" 
(1.55) 
(1.56) 

N 
..... 
· · -!IIIII IIIifi@illfiJ I I III 1111· · · 
x[n] = cos ('ITn/8) 
x[n] = cos ('!Tn/4) 
n 
n 
(a) 
(b) 
(c) 
x[n] = cos ('ITn/2) 
x[n] = cos'!Tn 
x[n] = cos (3'1Tn/2) 
n 
n 
n 
...... 
(d) 
(e) 
(f) 
x[n] = cos (7'1Tn/4) 
. x[n] = cos (15'1Tn/8) 
..................................... IIIIIIIIIIIIifififffiiiiiiiiiii ... 
n 
n 
(i) 
~ 
-
~ 
Figure 1.27 
Discrete-time sinusoidal sequences for several different frequencies. 

28 
Signals and Systems 
Chap. 1 
According to eq. (1.56), the signal eiwon is periodic if woi2TT is a rational number and is 
not periodic otherwise. These same observations also hold for discrete-time sinusoids. For 
example, the signals depicted in Figure 1.25(a) and (b) are periodic, while the signal in 
Figure 1.25(c) is not. 
Using the calculations that we have just made, we can also determine the funda-
mental period and frequency of discrete-time complex exponential"s, where we define the 
fundamental frequency of a discrete-time periodic signal as we did in continuous time. 
That is, if x[n] is periodic with fundamental periodN, its fundamental frequency is 2TTIN. 
Consider, then, a periodic complex exponential x[n] = eiwon with w 0 =/:- 0. As we have 
just seen, w0 must satisfy eq. (1.56) for some pair of integers m and N, with N > 0. In 
Problem 1.35, it is shown that if w 0 =/:- 0 and if Nand m have no factors in common, then 
the fundamental period of x[n] is N. Using this fact together with eq. (1.56), we find that 
the fundamental frequency of the periodic signal eiwon is 
2TT 
wo 
---
N 
m 
(1.57) 
Note that the fundamental period can also be written as 
(1.58) 
These last two expressions again differ from their continuous-time counterparts. In 
Table 1.1, we have summarized some of the differences between the continuous-time sig-
nal eiwot and the discrete-time signal eiwon. Note that, as in the continuous-time case, the 
constant discrete-time signal resulting from setting wo = 0 has a fundamental frequency 
of zero, and its fundamental period is undefined. 
TABLE 1.1 
Comparison of the signals eiwot and eiwo". 
Distinct signals for distinct values of w0 
Periodic for any choice of w0 
Fundamental frequency wo 
Fundamental period 
wo = 0: undefined 
wo Y"O:~ 
wo 
Identical signals for values of w0 
separated by multiples of 27T 
Periodic only if w0 = 27Tm/N for some integers N > 0 and m. 
Fundamental frequency' w0/m 
Fundamental period' 
wo = 0: undefined 
wo Y" O:m(~) 
• Assumes that m and N do not have any factors in common. 
To gain some additional insight into these properties, let us examine again the signals 
depicted in Figure 1.25. First, consider the sequence x[n] = cos(27Tn/12), depicted in 
Figure 1.25(a), which we can think of as the set of samples of the continuous-time sinusoid 
x(t) = cos(27rtl12) at integer time points. In this case, x(t) is periodic with fundamental 
period 12 and x[n] is also periodic with fundamental period 12. That is, the values of x[n] 
repeat every 12 points, exactly in step with the fundamental period of x(t). 

Sec. 1.3 
Exponential and Sinusoidal Signals 
29 
In contrast, consider the signal x[n] = cos(87Tn/31), depicted in Figure 1.25(b), 
which we can view as the set of samples of x(t) = cos (87Tt/31) at integer points in time. 
In this case, x(t) is periodic with fundamental period 3114. On the other hand, x[n] is pe-
riodic with fundamental period 31. The reason for this difference is that the discrete-time 
signal is defined only for integer values of the independent variable. Thus, there is no 
sample at timet = 3114, when x(t) completes one period (starting from t = 0). Similarly, 
there is no sample at t = 2 · 3114 or t = 3 · 31/4, when x(t) has completed two or three 
periods, but there is a sample at t = 4 · 3114 = 31, when x(t) has completed four periods. 
This can be seen in Figure 1.25(b), where the pattern of x[n] values does not repeat with 
each single cycle of positive and negative values. Rather, the pattern repeats after four 
such cycles, namely, every 31 points. 
Similarly, the signal x[n] = cos(n/6) can be viewed as the set of samples of the 
signal x(t) = cos(t/6) at integer time points. In this case, the values of x(t) at integer 
sample points never repeat, as these sample points never span an interval that is an exact 
multiple of the period, 127T, of x(t). Thus, x[n] is not periodic, although the eye visually 
interpolates between the sample points, suggesting the envelope x(t), which is periodic. 
The use of the concept of sampling to gain insight into the periodicity of discrete-time 
sinusoidal sequences is explored further in Problem 1.36. 
Example 1.6 
Suppose that we wish to determine the fundamental period of the discrete-time signal 
x[n] = ej(27Ti3)n + ej(37TI4)n. 
(1.59) 
The first exponential on the right-hand side of eq. (1.59) has a fundamental period of 3. 
While this can be verified from eq. ( 1.58), there is a simpler way to obtain that answer. In 
particular, note that the angle (27r/3)n of the first term must be incremented by a multiple 
of 27r for the values of this exponential to begin repeating. We then immediately see that 
if n is incremented by 3, the angle will be incremented by a single multiple of 27r. With 
regard to the second term, we see that incrementing the angle (37r/4)n by 27r would 
require n to be incremented by 8/3, which is impossible, since n is restricted to being an 
integer. Similarly, incrementing the angle by 47r would require a noninteger increment 
of 16/3 ton. However, incrementing the angle by 67r requires an increment of 8 ton, 
and thus the fundamental period of the second term is 8. 
Now, for the entire signal x[n] to repeat, each of the terms in eq. (1.59) must go 
through an integer number of its own fundamental period. The smallest increment of n 
that accomplishes this is 24. That is, over an interval of 24 points, the first term on the 
right-hand side of eq. (1.59) will have gone through eight of its fundamental periods, the 
second term through three of its fundamental periods, and the overall signal x[n] through 
exactly one of its fundamental periods. 
As in continuous time, it is also of considerable value in discrete-time signal and 
system analysis to consider sets of harmonically related periodic exponentials-that is, 
periodic exponentials with a common period N. From eq. (1.56), we know that these are 
precisely the signals which are at frequencies which are multiples of 27TIN. That is, 
k = 0, ±1, .... 
(1.60) 

30 
Signals and Systems 
Chap. 1 
In the continuous-time case, all of the harmonically related complex exponentials ej k(ZTTIT)r, 
k = 0, :±:: 1, :±::2, ... , are distinct. However, because of eq. (1.51), this is not the case in 
discrete time. Specifically, 
<f>k+N[n] = ej(k+N)(2TTIN)n 
(1.61) 
This implies that there are only N distinct periodic exponentials in the set given in 
eq. (1.60). For example, 
(1.62) 
are all distinct, and any other <f>k[n] is identical to one of these (e.g., </>N[n] = <f>o[n] and 
<1>- t[n] = </>N- t[n]). 
-
1 .4 THE UNIT IMPULSE AND UNIT STEP FUNCTIONS 
In this section, we introduce several other basic signals-specifically, the unit impulse and 
step functions in continuous and discrete time-
that are also of considerable importance in 
signal and system analysis. In Chapter 2, we will see how we can use unit impulse signals 
as basic building blocks for the construction and representation of other signals. We begin 
with the discrete-time case. 
1.4.1- The Discrete-Time Unit Impulse and Unit Step Sequences 
One of the simplest discrete-time signals is the unit impulse (or unit sample), which is 
defined as 
8[n] = { ~: 
n;60 
n = O 
. (1.63) 
and which is shown in Figure 1.28. Throughout the book, we will refer to 8 [n] interchange-
ably as the unit impulse or unit sample. 
8[n] 
........ 'I ....... . 
Figure 1 .. 28 
Discrete-time unit im-
n 
pulse (sample). 
A second basic discrete-time signal is the discrete-time unit step, denoted by u[n] 
and defined by 
· 
u[n] = { ~: 
The unit step sequence is shown in Figure 1.29. 
n<O 
n:::::: 0 · 
(1.64) 

Sec. 1.4 
The Unit Impulse and Unit Step Functions 
31 
• • • • • • • • • • 
Interval of summation 
I 
u[n] 
. .lii I II I 
0 
8[m] 
n 
Figure 1.29 
Discrete-time unit step 
sequence. 
• • • • • • • • • • . I . . .. . • • • 
n 
m 
(a) 
Interval of summation 
- -- -B"1ffif-- -- - -
I 
• • • • • • • • • . . I . . . 
• • • • • • 
n 
(b) 
m 
Figure 1.30 
Running sum of 
eq. (1 .66): (a) n < 0; (b) n > 0. 
There is a close relationship between the discrete-time unit impulse and unit step. In 
particular, the discrete-time unit impulse is the first difference of the discrete-time step 
o[n] = u[n] - u[n- 1]. 
(1.65) 
Conversely, the discrete-time unit step is the running sum of the unit sample. That is, 
n 
u[n] = 2::: o[m]. 
(1.66) 
m=-oo 
Equation (1.66) is illustrated graphically in Figure 1.30. Since the only nonzero value of 
the unit sample is at the point at which its argument is zero, we see from the figure that the 
running sum in eq. (1.66) is 0 for n < 0 and 1 for n 2::: 0. Furthermore, by changing the 
variable of summation from m to k = n - m in eq. (1.66), we find that the discrete-time 
unit step can also be written in terms of the unit sample as 
or equivalently, 
0 
u[n] = 2::: o[n- k], 
k =co 
u[n] = 2::: o[n - k]. 
k =O 
(1.67) 

32 
B[n - k] 
• • • 0 I. 0 
0 
n 
Interval of summation 
~-
-
- --------
I • • • • • • • • • • 
0 
(a) 
Interval of summation 
' ----- 8[n ~ k)- ---
I 
I 
• • • • • • • • • • • • • 0 I. 00 0 
Signals and Systems 
Chap. 1 
k 
0 
n 
k 
Figure 1 .31 
Relationship given in 
(b) 
eq. (1.67): (a) n < 0; (b) n > 0. 
Equation (1.67) is illustrated in Figure 1.31. In this case the nonzero value of 8[n- k] is 
at the value of k equal ton, so that again we see that the summation in eq. (1.67) is 0 for 
n < 0 and 1 for n 2:: 0. 
An interpretation of eq. (1.67) is as a superposition of delayed impulses; i.e., we can 
view the equation as the sum of a unit impulse 8[n] at n = 0, a unit impulse 8[n - 1] at 
n = 1, another, 8[n- 2], at n = 2, etc. We will make explicit use of this interpretation in 
Chapter2. 
The unit impulse sequence can be used to sample the value of a signal at n = 0. In 
particular, since o[n] is nonzero (and equal to 1) only for n = 0, it follows that 
x[n]o[n] = x[O]o[n]. 
(1.68) 
More generally, if we consider a unit impulse o [ n - n0] at n = n0 , then 
x[n]o[n- no] = x[no]o[n - n0 ]. 
(1.69) 
This sampling property of the unit impulse will play an important role in Chapters 2 
and 7. 
1.4.2 The Continuous-Time Unit Step 
and Unit Impulse Functions 
The continuous-time unit step function u(t) is defined in a manner similar to its discrete-
time counterpart. Specifically, 
u(t) = { O, I, 
t < O 
t > 0' 
(1.70) 
as is shown in Figure 1.32. Note that the unit step is discontinuous at t = 0. The 
continuous-time unit impulse function o(t) is related to the unit step in a manner analogous 

Sec. 1.4 
The Unit Impulse and Unit Step Functions 
u(t) 
0 
33 
Figure 1.32 
Continuous-time unit 
step function. 
to the relationship between the discrete-time unit impulse and step functions. In particular, 
the continuous-time unit step is the running integral of the unit impulse 
U(t) = r oo i)( T) dT. 
(1.71) 
This also suggests a relationship between l>(t) and u(t) analogous to the expression for 
l>[n] in eq. (1.65). In particular, it follows from eq. (1.71) that the continuous-time unit 
impulse can be thought of as the first derivative of the continuous-time unit step: 
i>(t) = d~;t). 
(1.72) 
In contrast to the discrete-time case, there is some formal difficulty with this equa-
tion as a representation of the unit impulse function, since u(t) is discontinuous at t = 0 
and consequently is formally not differentiable. We can, however, interpret eq. (1.72) by 
considering an approximation to the unit step Ut..(t), as illustrated in Figure 1.33, which 
rises from the value 0 to the value 1 in a short time interval of length ~. The unit step, 
of course, changes values instantaneously and thus can be thought of as an idealization of 
Ut..(t) for~ so short that its duration doesn't matter for any practical purpose. Formally, 
u(t) is the limit of Ut..(t) as~ ~ 0. Let us now consider the derivative 
as shown in Figure 1.34. 
u<l(t) 
.., ( ) _ dut..(t) 
UtJ. t -
-
-dt ' 
Figure 1 .33 
Continuous approximation to 
the unit step, u<l{t). 
0 .l 
Figure 1 .34 
Derivative of 
u<l(t). 
(1.73) 

34 
0 
Figure 1.35 
Continuous-
time unit impulse. 
Signals and Systems 
k8(t) 
·t 
0 
Figure 1.36 
Scaled im~ 
pulse. 
Chap. 1 
Note that lh.(t) is a short pulse, of duration~ and with unit area for any value of~. 
As~ ~ 0, 8a (t) becomes narrower and higher, maintaining its unit area. Its limiting form, 
8(t) = lim 86,(!), 
6.-->0 
(1.74) 
can then be thought of as an idealization of the short pulse lh (t) as the duration~ becomes 
insignificant. Since 8(t) has, in effect, no duration but unit area, we adopt the graphical 
notation for it shown in Figure 1.35, where the arrow at t = 0 indicates that the area of the 
pulse is concentrated at t = 0 and the height of the arrow and the "1" next to the arrow 
are used to represent the area of the impulse. More generally, a scaled impulse k8(t) will 
have an area k, and thus, 
r oo k8( T) dT = ku(t). 
A scaled impulse with area k is shown in Figure 1.36, where the height of the arrow used 
to depict the scaled impulse is chosen to be proportional to the area of the impulse. 
As with discrete time, we can provide a simple graphical interpretation of the running 
integral of eq. (1.71); this is shown in Figure 1.37. Since the area of the continuous-time 
unit impulse 8( T) is concentrated at T = 0, we see that the running integral is 0 for t < 0 
and 1 fort > 0. Also, we note that the relationship in eq. (1.71) between the continuous-
time unit step and impulse can be rewritten in a different form, analogous to the discrete-
time form in eq. (1.67), by changing the variable of integration from T to (J' = t- T: 
t 
. 
0 
u(t) = Loo 8( T) dT = L 
8(t - (J')( -d(J'), 
or equivalently, 
u(t) = fooo 8(t - (J') d(J'. 
(1.75) 
The graphical interpretation of this form of the relationship between u(t) and S(t) is 
given in Figure 1.38. Since in this case the area of 8(t - (J') is concentrated at the point 
(J' = t, we again see that the integral in eq. (1.75) is 0 fort< 0 and 1 fort> 0. This type 
of graphical interpretation of the behavior of the unit impulse under integration will be 
extremely useful in Chapter 2. 

Sec. 1.4 
The Unit Impulse and Unit Step Functions 
Interval of integration 
B(T) 
0 
(a) 
Interval of integration 
--------------r----. 
B(T) 
: 
I 
I 
. 
I 
I 
0 
(b) 
Figure 1.37 
Running integral given in eq. (1.71 ): 
(a) t < 0; (b) t > 0. 
'T 
'T 
Interval of integration 
B(t- 0') 
0 
(a) 
Interval of integration 
B(t- 0') 
0 
(b) 
Figure 1.38 
Relationship given in eq. (1 .75): 
(a) t < 0; (b) t > 0. 
35 
As with the discrete-time impulse, the continuous-time impulse has a very important 
sampling property. In particular, for a number of reasons it will be important to consider 
the product of an impulse and more well-behaved continuous-time functions x(t). The in-
terpretation of this quantity is most readily developed using the definition of 8(t) according 
to eq. (1.74). Specifically, consider 
XJ(t) = x(t)8t.(t). 
In Figure 1.39(a) we have depicted the two time functions x(t) and 8t.(t), and in Fig-
ure 1.39(b) we see an enlarged view of the nonzero portion of their product. By construc-
tion, x1 (t) is zero outside the interval 0 :s t :s .:1. For .:1 sufficiently small so that x(t) is 
approximately constant over this interval, 
x(t)8t,.(t) = x(0)8t,.(t). 
Since 8(t) is the limit as .:1 ~ 0 of 8t,.(t), it follows that 
x(t)8(t) = x(0)8(t). 
(1.76) 
By the same argument, we have an analogous expression for an impulse concentrated at 
an arbitrary point, say, t0 . That is, 
x(t)8 (t - to) = x(to)8(t - to). 

36 
O!:J. 
(a) 
x(O)-
0 
(b) 
Signals and Systems 
Chap. 1 
Figure 1.39 
The product x(t)S,i{t): 
(a) graphs of both functions; (b) en-
larged view of the nonzero portion of 
their product. 
Although our discussion of the unit impulse in this section has been somewhat in-
formal, it does provide us with some important intuition about this signal that will be 
useful throughout the book. As we have stated, the unit impulse should be viewed as an 
idealization. As we illustrate and discuss in more detail in Section 2.5, any real physi-
cal system has some inertia associated with it and thus does not respond instantaneously 
to inputs. Consequently, if a pulse of sufficiently short duration is applied to such a sys-
tem, the system response will not be noticeably influenced by the pulse's duration or by 
the details of the shape of the pulse, for that matter. Instead, the primary characteristic 
of the pulse that will matter is the net, integrated effect of the pulse-i.e., its area. For 
systems that respond much more quickly than others, the pulse will have to be of much 
shorter duration before the details of the pulse shape or its duration no longer matter. Nev-
ertheless, for any physical system, we can always find a pulse that is "short enough." 
The unit impulse then is an idealization of this concept-the pulse that is short enough 
for any system. As we will see in Chapter 2, the response of a system to this idealized 
pulse plays a crucial role in signal and system analysis, and in the process of devel-
oping and understanding this role, we will develop additional insight into the idealized 
signal.3 
3The unit impulse and other related functions (which are often collectively referred to as singularity 
functions) have been thoroughly studied in the field of mathematics under the alternative names of general-
ized functions and the theory of distributions. For more detailed discussions of this subject, see Distribution 
Theory and Transfonn Analysis, by A. H. Zemanian (New York: McGraw-Hill Book Company, 1965), Gen-
eralised Functions, by R.F. Hoskins (New York: Halsted Press, 1979), or the more advanced text, Fourier 
Analysis and Generalized Functions, by M. J. Lighthill (New York: Cambridge University Press, 1958). 
Our discussion of singularity functions in Section 2.5 is closely related in spirit to the mathematical theory 
described in these texts and thus provides an informal introduction to concepts that underlie this topic in 
mathematics. 

Sec. 1.4 
The Unit Impulse and Unit Step Functions 
37 
Example 1.7 
Consider the discontinuous signal x(t) depicted in Figure 1.40(a). Because of the rela-
tionship between the continuous-time unit impulse and unit step, we can readily calculate 
and graph the derivative of this signal. Specifically, the derivative of x(t) is clearly 0, 
except at the discontinuities. In the case of the unit step, we have seen [eq. (1.72)] that 
differentiation gives rise to a unit impulse located at the point of discontinuity. Further-
more, by multiplying both sides of eq. (1.72) by any number k, we see that the derivative 
of a unit step with a discontinuity of size k gives rise to an impulse of area k at the point 
of discontinuity. This rule also holds for any other signal with a jump discontinuity, such 
as x(t) in Figure 1.40(a). Consequently, we can sketch its derivative .X(t), as in Fig-
ure 1.40(b), where an impulse is placed at each discontinuity of x(t), with area equal to 
the size of the discontinuity. Note, for example, that the discontinuity in x(t) at t = 2 
has a value of -3, so that an impulse scaled by -3 is located at t = 2 in the signal .X(t). 
x(t) 
2-
r--
-
-1 -
x<tl 
2-
1 -
--1 -
-2 -
- 3-
2 
3 
4 
2 3 
4 
- - .6Ginterval of integration 
1 -: 
2 
3 
4 
-1 -
-2-
-3-
(a) 
(b) 
(c) 
T 
Figure 1.40 
(a) The discontinuous signal x(t) analyzed in Example 1.7; 
(b) its derivative x(t); (c) depiction of the recovery of x(t) as the running inte-
gral of x(t), illustrated for a value of t between 0 and 1. 

38 
Signals and Systems 
Chap. 1 
As a check of our result, we can verify that we can recover x(t) from x(t). Specif-
ically, since x(t) and x(t) are both zero for t :5 0, we need only check that for t > 0, 
x(t) = J: x(T)dT. 
(1.77) 
As illustrated in Figure 1.40(c), fort< 1, the integral on the right-hand side of eq. (1.77) 
is zero, since none of the impulses that constitute x(t) are within the interval of integra-
tion. For 1 < t < 2, the first impulse (located at t = 1) is the only one within the inte-
gration interval, and thus the integral in eq. ( 1. 77) equals 2, the area of this impulse. For 
2 < t < 4, the first two impulses are within the interval of integration, and the integral 
accumulates the sum of both of their areas, namely, 2 - 3 = -1. Finally, for t > 4, all 
three impulses are within the integration interval, so that the integral equals the sum of 
all three areas-that is, 2 - 3 + 2 = + 1. The result is exactly the signal x(t) depicted 
in Figure 1.40(a). 
1.5 CONTINUOUS-TIME AND DISCRETE-TIME SYSTEMS 
Physical systems in the broadest sense are an interconnection of components, devices, 
or subsystems. In contexts ranging from signal processing and communications to elec-
tromechanical motors, automotive vehicles, and chemical-processing plants, a system can 
be viewed as a process in which input signals are transformed by the system or cause the 
system to respond in some way, resulting in other signals as outputs. For example, a high-
fidelity system takes a recorded audio signal and generates a reproduction of that signal. 
If the hi-fi system has tone controls, we can change the tonal quality of the reproduced sig-
nal. Similarly, the circuit in Figure 1.1 can be viewed as a system with input voltage Vs(t) 
and output voltage Vc(t), while the automobile in Figure 1.2 can be thought of as a system 
with input equal to the force f(t) and output equal to the velocity v(t) of the vehicle. An 
image-enhancement system transforms an input image into an output image that has some 
desired properties, such as improved contrast. 
Acontinuous-time system is a system in which continuous-time input signals are 
applied and result in continuous-time output signals. Such a system will be represented 
pictorially as in Figure 1.4l(a), where x(t) is the input and y(t) is the output. Alterna-
tively, we will often represent the input-output relation of a continuous-time system by the 
notation 
x(t) ~ y(t). 
x(t) __ 
..,..1 Continuous-time 1--+- y(t) 
system 
x[n]----t~ 
(a) 
Discrete-time 
system 
(b) 
1--___,~ y[n 1 
(1.78) 
Figure 1 .41 
(a) Continuous-time 
system; (b) discrete-time system. 

Sec. 1.5 
Continuous-Time and Discrete-Time Systems 
39 
Similarly, a discrete-time system-that is, a system that transforms discrete-time inputs 
into discrete-time outputs-will be depicted as in Figure 1.4l(b) and will sometimes be 
represented symbolically as 
x[n] ~ y[n]. 
(1.79) 
In most of this book, we will· treat discrete-time systems and continuous-time systems 
separately but in parallel. In Chapter 7, we will bring continuous-time and discrete-time 
systems together through the concept of sampling, and we will develop some insights 
into the use of discrete-time systems to process continuous-time signals that have been 
sampled. 
1.5.1 Simple Examples of Systems 
One of the most important motivations for the development of general tools for analyzing 
and designing systems is that systems from many different applications have very similar 
mathematical descriptions. To illustrate this, we begin with a few simple examples. 
Example 1.8 
Consider the RC circuit depicted in Figure 1.1. If we regard vs(t) as the input signal and 
vc(t) as the output signal, then we can use simple circuit analysis to derive an equation 
describing the relationship between the input and output. Specifically, from Ohm's law, 
the current i(t) tl}rough the resistor is proportional (with proportionality constant 11 R) to 
the voltage drop across the resistor; i.e., 
'( ) _ Vs(t) - Vc(t) 
z t -
R 
. 
(1.80) 
Similarly, using the defining constitutive relation for a capacitor, we can relate i(t) to the 
rate of change with time of the voltage across the capacitor: 
(1.81) 
Equating the right-hand sides of eqs. (1.80) and (1.81), we obtain a differential equation 
describing the relationship between the input Vs(t) and the output Vc(t): 
(1.82) 
Example 1.9 
Consider Figure 1.2, in which we regard the force f(t) as the input and the velocity v(t) 
as the output. If we let m denote the mass of the automobile and mpv the resistance due 
to friction, then equating acceleration-i.e., the time derivative of velocity-with net 
force divided by mass, we obtain 
d~~t) = ~ [f(t) - pv(t)], 
(1.83) 

40 
Signals and Systems 
Chap. 1 
i.e., 
dv(t) 
p 
1 
-
+ - v(t) = - f(t). 
dt 
m 
m 
(1.84) 
Examining and comparing eqs. (1.82) and (1.84) in the above examples, we see that 
the input-output relationships captured in these two equations for these two very different 
physical systems are basically the same. In particular, they are both examples of first-order 
linear differential equations of the form 
dy(t) 
Cit + ay(t) = bx(t), 
(1 .85) 
where x(t) is the input, y(t) is the output, and a and bare constants. This is one very simple 
example of the fact that, by developing methods for analyzing general classes of systems 
such as that represented by eq. (1.85), we will be able to use them in a wide variety of 
applications. 
Example 1 . 1 0 
As a simple example of a discrete-time system, consider a simple model for the balance 
in a bank account from month to month. Specifically, let y[n) denote the balance at the 
end of the nth month, and suppose that y[n] evolves from month to month according to 
the equation 
y[n] = 1.01y[n- 1] + x[n], 
(1.86) 
or equivalently, 
y[n] - 1.01y[n- 1] = x [n], 
(1.87) 
where x[n] represents the net deposit (i.e., deposits minus withdrawals) during the nth 
month and the term 1.01y[n - 1] models the fact that we accrue 1% interest each month. 
Example 1 . 11 
As a second example, consider a simple digital simulation of the differential equation in 
eq. ( 1.84) in which we resolve time into discrete intervals of length 11 and approximate 
dv(t)ldt at t = nl1 by the first backward difference, i.e., 
v(nl1) - v((n - 1)A) 
11 
In this case, if we let v[n] = v(nl1) and f[n] = f(nl1), we obtain the following discrete-
time model relating the sampled signals f[n] and v[n]: 
m 
11 
v[n] -
(m + pl1) v[n- 1] = (m + pl1/[n]. 
(1.88) 
Comparing eqs. (1.87) and (1.88), we see that they are both examples of the same 
general first-order linear difference equation, namely, 
y[n] + ay[n- 1] = bx [n]. 
(1.89) 

Sec. 1.5 
Continuous-nme and Discrete-Time Systems 
41 
As the preceding examples suggest, the mathematical descriptions of systems from 
a wide variety of applications frequently have a great deal in common, and it is this fact 
that provides considerable motivation for the development of broadly applicable tools for 
signal and system analysis. The key to doing this successfully is identifying classes of 
systems that have two important characteristics: (1) The systems in this class have prop-
erties and structures that we can exploit to gain insight into their behavior and to develop 
effective tools for their analysis; and (2) many systems of practical importance can be 
accurately modeled using systems in this class. It is on the first of these characteristics 
that most of this book focuses, as we develop tools for a particular class of systems re-
ferred to as linear, time-invariant systems. In the next section, we will introduce the prop-
erties that characterize this class, as well as a number of other very important basic system 
properties. 
The second characteristic mentioned in the preceding paragraph is of obvious impor-
tance for any system analysis technique to be of value in practice. It is a well-established 
fact that a wide range of physical systems (including those in Examples 1.8- 1.10) can 
be well modeled within the class of systems on which we focus in this book. However, 
a critical point is that any model used in describing or analyzing a physical system rep-
resents an idealization of that system, and thus, any resulting analysis is only as good 
as the model itself. For example, the simple linear model of a resistor in eq. (1.80) 
and that of a capacitor in eq. (1.81) are idealizations. However, these idealizations are 
quite accurate for real resistors and capacitors in many applications, and thus, analy-
ses employing such idealizations provide useful results and conclusions, as long as the 
voltages and currents remain within the operating conditions under which these simple 
linear models are valid. Similarly, the use of a linear retarding force to represent fric-
tional effects in eq. (1.83) is an approximation with a range of validity. Consequently, 
although we will not address this issue in the book, it is important to remember that 
an essential component of engineering practice in using the methods we develop here 
consists of identifying the range of validity of the assumptions that have gone into a 
model and ensuring that any analysis or design based on that model does not violate those 
assumptions. 
1.5.2 Interconnections of Systems 
An important idea that we will use throughout this book is the concept of the interconnec-
tion of systems. Many real systems are built as interconnections of several subsystems. 
One exampleis an audio system, which involves the interconnection of a radio receiver, 
compact disc player, or tape deck with an amplifier and one or more speakers. Another is 
a digitally controlled aircraft, which is an interconnection of the aircraft, described by its 
equations of motion and the aerodynamic forces affecting it; the sensors, which measure 
various aircraft variables such as accelerations, rotation rates, and heading; a digital au-
topilot, which responds to the measured variables and to command inputs from the pilot 
(e.g., the desired course, altitude, and speed); and the aircraft's actuators, which respond 
to inputs provided by the autopilot in order to use the aircraft control surfaces (rudder, 
tail, ailerons) to change the aerodynamic forces on the aircraft. By viewing such a system 
as an interconnection of its components, we can use our understanding of the component 

42 
Input 
Signals and Systems 
Input 
(a) 
Input 
Output 
(b) 
System 3 
(c) 
Figure 1.42 
Interconnection of two systems: (a) series (cascade) intercon-
nection; (b) parallel interconnection; (c) series-parallel interconnection. 
Chap. 1 
Output 
systems and of how they are interconnected in order to analyze the operation and behavior 
of the overall system. In addition, by describing a system in terms of an interconnection of 
simpler subsystems, we may in fact be able to define useful ways in which to synthesize 
complex systems out of simpler, basic building blocks. 
While one can construct a variety of system interconnections, there are several basic 
ones that are frequently encountered. A series or cascade interconnection of two systems 
is illustrated in Figure 1.42(a). Diagrams such as this are referred to as block diagrams. 
Here, the output of System 1 is the input to' System 2, and the overall system transforms 
an input by processing it first by System 1 and then by System 2. An example of a series 
interconnection is a radio receiver followed by an amplifier. Similarly, one can define a 
series interconnection of three or more systems. 
A parallel interconnection of two systems is illustrated in Figure 1.42(b ). Here, the 
same input signal is applied to Systems 1 and 2. The symbol "$" in the figure denotes 
addition, so that the output of the parallel interconnection is the sum of the outputs of 
Systems 1 and 2. An example of a parallel interconnection is a simple audio system with 
several microphones feeding into a single amplifier and speaker system. In addition to the 
simple parallel interconnection in Figure 1.42(b ), we can define parallel interconnections 
of more than two systems, and we can combine both cascade and parallel interconnections 

Input 
Sec. 1.5 
Continuous-Time and Discrete-Time Systems 
+ 
System 1 
Output 
System 2 
43 
Figure 1.43 
Feedback interconnec-
tion. 
to obtain more complicated interconnections. An example of such an interconnection is 
given in Figure 1.42(c).4 
Another important type of system interconnection is a feedback interconnection, an 
example of which is illustrated in Figure 1.43. Here, the output of System 1 is the input to 
System 2, while the output of System 2 is fed back and added to the external input to pro-
duce the actual input to System 1. Feedback systems arise in a wide variety of applications. 
For example, a cruise control system on an automobile senses the vehicle's velocity and 
adjusts the fuel flow in order to keep the speed at the desired level. Similarly, a digitally 
controlled aircraft is most naturally thought of as a feedback system in which differences 
between actual and desired speed, heading, or altitude are fed back through the autopilot 
in order to correct these discrepancies. Also, electrical circuits are often usefully viewed 
as containing feedback interconnections. As an example, consider the circuit depicted in 
Figure 1.44(a). As indicated in Figure 1.44(b), this system can be viewed as the feedback 
interconnection of the two circuit elements. 
i(t) 
+ 
___.. + 
i1 (t) ! 
i2 (t) ! 
t i(t) 
. ;;; i'" C 
~ 
R 
i1 (t) 
Capacitor 
V(t) = ~~-~i1 (T)dT 
-
i2 (t) 
Resistor 
. (t) _ v(t) 
12 
- A 
+ 
v(t) 
v(t) 
Figure 1.44 
(a) Simple electrical 
circuit; (b) block diagram in which the 
circuit is depicted as the feedback inter-
connection of two circuit elements. 
40n occasion, we will also use the symbol ® in our pictorial representation of systems to denote the 
operation of multiplying two signals (see, for example, Figure 4.26). 

44 
Signals and Systems 
Chap. 1 
1 .6 BASIC SYSTEM PROPERTIES 
In this section we introduce and discuss a number of basic properties of continuous-time 
and discrete-time systems. These properties have important physical interpretations and 
relatively simple mathematical descriptions using the signals and systems language that 
we have begun to develop. 
1.6. 1 Systems with and without Memory 
A system is said to be memoryless if its output for each value of the independent variable 
at a given time is dependent on the input at only that same time. For example, the 
system specified by the relationship 
· 
(1.90) 
is memoryless, as the value ofy[n] at any particular time n0 depends only on the value of 
x[n] at that time. Similarly, a resistor is a memory less system; with the input x(t) taken as 
the current and with the voltage taken as the output y(t), the input-output relationship of a 
resistor is 
y(t) = Rx(t), 
(1.91) 
where R is the resistance. One particularly simple memoryless system is the identity sys-
tem, whose output is identical to its input. That is, the ihput-output relationship for the 
continuous-time identity system is 
y(t) = x(t), 
and the corresponding relationship in discrete time is 
y[n] = x[n]. 
An example of a discrete-time system with memory is an accumulator or summer 
n 
y[n] = L x[k], 
(1.92) 
k= -oo 
and a second example is a delay 
y[n] = x[n- 1]. 
(1.93) 
A capacitor is an example of a continuous-time system with memory, since if the input is 
taken to be the current and the output is the voltage, then 
1 fl 
y(t) = C - oo x(r)dT, 
(1.94) 
where C is the capacitance. 
Roughly speaking, the concept ofmemory in a system corresponds to the presence 
of a mechanism in the system that retains or stores information about input values at times 

Sec. 1.6 
Basic System Properties 
45 
other than the current time. For example, the delay in eq. (1.93) must retain or store the 
preceding value of the input. Similarly, the accumulator in eq. (1.92) must "remember" or 
store information about past inputs. In particular, the accumulator computes the running 
sum of all inputs up to the current time, and thus, at each instant of time, the accumulator 
must add the current input value to the preceding value of the running sum. In other words, 
the relationship between the input and output of an accumulator can be described as 
n-1 
y[n] = L x[k] + x[n], 
(1.95) 
k = -co 
or equivalently, 
y[n] = y[n - 1] + x[n]. 
(1.96) 
Represented in the latter way, to obtain the output at the current time n, the accumulator 
must remember the running sum of previous input values, which is exactly the preceding 
value of the accumulator output. 
In many physical systems, memory is directly associated with the storage of energy. 
For example, the capacitor in eq. (1.94) stores energy by accumulating electrical charge, 
represented as the integral of the current. Thus, the simple RC circuit in Example 1 .. 8 
and Figure 1.1 has memory physically stored in the capacitor. Similarly, the automobile in 
Figure 1.2 has memory stored in its kinetic energy. In discrete-time systems implemented · 
with computers or digital microprocessors, memory is typically directly associated with 
storage registers that retain values between clock pulses. 
While the concept of memory in a system would typically suggest storing past input 
and output values, our formal definition also leads to our referring to a system as having 
memory if the current output is dependent on future values of the input and output. While 
·systems having this dependence on future values m1ght at first seem unnatural, they in fact 
form an important class of systems, as we discuss further in Section 1.6.3. 
1.6.2 lnvertibility and Inverse Systems 
A system is said to be invertible if distinct inputs lead to distinct outputs. As illustrated in 
Figure 1.45(a) for the discrete-time case, if a system is invertible, then an inverse system 
exists that, when cascaded with the original system, yields an output w[n] equal to the 
input x[n] to the first system. Thus, the series interconp.ection in Figure 1.45(a) has an 
overall input-output relationship which is the same as that for the identity system. 
An example of an invertible continuous-time system is 
y(t) = 2x(t), 
(1.97) 
for which the inverse system is 
1 
w(t) = 2y(t). 
(1.98) 
This example is illustrated in Figure 1.45(b). Another example of an invertible system 
is the accumulator of eq. (1.92). For this system, the difference between two successive 

46 
Signals and Systems 
Chap. 1 
x[n] ---+-
System 
y[nJ 
Inverse 
system 
w[n] = x[n] . 
(a) 
x(t) 
y(t) 
y(t) = 2x(t) .,_.;.._~ 
1--~ w[t] = x(t) 
(b) 
x[n] ~L.-y-[n_J_=_k =-~-"'-x_[k_l_
· __. 
y(n] •I w[n] = y[n] - y[n - 1] ~ 
w[n] = x[n] 
(c) 
Figure 1 .45 
Concept of an inverse system for: (a) a general invertible sys-
tem; (b) the invertible system described by eq. (1 .97); (c) the invertible system 
defined in eq. (1 .92). 
values of the output is precisely the last input value. Therefore, in this case, the inverse 
system is 
w[n] = y[n] - y[n - 1], 
(1.99) 
as illustrated in Figure 1.45(c). Examples of noninvertible systems are 
y[n] = 0, 
(1.100) 
that is, the system that produces the zero output sequence for any input sequence, and 
(1.101) 
in which case we cannot determine the sign of the input from knowledge of the output. 
The concept of invertibility is important in many contexts. One example arises in 
systems for encoding used in a wide variety of communications applications. In such a 
system, a signal that we wish to transmit is first applied as the input to a system known 
as an encoder. There are many reasons for doing this, ranging from the desire to encrypt 
the original message for secure or private communication to the objective of providing 
some redundancy in the signal (for example, by adding what are known as parity bits) 
so that any errors that occur in transmission can be detected and, possibly, corrected. For 
loss less coding, the input to the encoder must be exactly recoverable from the output; i.e., 
the encoder must be invertible. 
1.6.3 Causality 
A system is causal if the output at any time depends on values of the input at only the 
present and past times. Such a system is often referred to as being nonanticipative, as 

Sec. 1.6 
Basic System Properties 
47 
the system output does not anticipate future values of the input. Consequently, if two inputs 
to a causal system are identical up to some point in time to or n0 , the corresponding outputs 
must also be equal up to this same time. The RC circuit of Figure 1.1 is causal, since 
the capacitor voltage responds only to the present and past values of the source voltage. 
Similarly, the motion of an automobile is causal, since it does not anticipate future actions 
of the driver. The systems described in eqs. (1.92)- (1.94) are also causal, but the systems 
defined by 
y[n] = x[n] - x[n + 1] 
(1.102) 
and 
(1.103) 
are not. All memory less systems are causal, since the output responds only to the current 
value of the input. 
Although causal systems are of great importance, they do not by any means constitute 
the only systems that are of practical significance. For example, causality is not often an 
essential constraint in applications in which the independent variable is not time, such as in 
image processing. Furthermore, in processing data that have been recorded previously, as 
often happens with speech, geophysical, or meteorological signals, to name a few, we are 
by no means constrained to causal processing. As another example, in many applications, 
including historical stock market analysis and demographic studies, we may be interested 
in determining a slowly varying trend in data that also contain high-frequency fluctuations 
about that trend. In this case, a commonly used approach is to average data over an interval 
in order to smooth out the fluctuations and keep only the trend. An example of a noncausal 
averaging system is 
1 
+M 
y[n] = 2M + 1 L x[n- k]. 
k = - M 
(1.104) 
Example 1 . 1 2 
When checking the causality of a system, it is important to look carefully at the input-
output relation. To illustrate some of the issues involved in doing this, we will check the 
causality of two particular systems. 
The first system is defined by 
y[n] = x[ - n]. 
(1.105) 
Note that the output y[n0] at a positive time no depends only on the value of the input 
signal x[- n0] at time (- n0), which is negative and therefore in the past of n0 . We may 
be tempted to conclude at this point that the given system is causal. However, we should 
always be careful to check the input-output relation for all times. In particular, for n < 0, 
e.g. n = - 4, we see that y[ -4] = x[4], so that the output at this time depends on a future 
value of the input. Hence, the system is not causal. 
It is also important to distinguish carefully the effects of the input from those of 
any other functions used in the definition of the system. For example, consider the system 
y(t) = x(t) cos(t + 1). 
(1.106) 

48 
Signals and Systems 
Chap. 1 
In this system, the output at any time t equals the input at that same time multiplied by 
a number that varies with time. Specifically, we can rewrite eq. (1.106) as 
y(t) = x(t)g(t), 
where g(t) is a time-varying function, namely g(t) = cos(t + 1). Thus, only the current 
value of the input x(t) influences the current value of th~ output y(t), and we conclude 
that this system is causal (and, in fact, memory less). 
1.6.4 Stability 
Stability is another important system property. Informally, a stable system is one in which 
small inputs lead to responses that do not diverge. For example, consider the pendulum in 
Figure 1.46(a), in which the input is the applied force x(t) and the output is the angular 
deviation y(t) from the vertical. In this case, gravity applies a restqring force that tends 
to return the pendulum to the vertical position, and frictional losses due to drag tend to 
slow it down. Consequently, if a small force x(t) is applied, the resulting deflection from 
vertical will also be small. In contrast, for the inverted pendulum in Figure 1.46(b ), the 
effect of gravity is to apply a force that tends to increase the deviation from vertical. Thus, 
a small applied force leads to a large vertical deflection causing the pendulum to topple 
over, despite any retarding forces due to friction. 
The system in Figure 1.46(a) is an example of a stable system, while that in Fig-
ure 1.46(b) is unstable. Models for chairi reactions or for population growth with unlim-
ited food supplies and no predators are examples of unstable systems, since the system 
response grows without bound in response to small inputs. Another example of an unsta-
ble system is the model for a bank account balance in eq. (1.86), since if an initial deposit 
is made (i.e., x[O] = a positive amount} and there are no subsequent withdrawals, then 
that deposit will grow each month without bound, because of the compounding effect of 
interest payments. 
x(t) 
x(t) 
(b) 
Figure 1.46 
(a) A stable pendulum; 
(b) an unstable inverted pendulum. 

Sec. 1.6 
Basic System Properties 
49 
There are also numerous examples of stable systems. Stability of physical systems 
generally results from the presence of mechanisms that dissipate energy. For example, 
assuming positive component values in the simple RC circuit of Example 1.8, the resistor 
dissipates energy and this circuit is a stable system. The system in Example 1.9 is also 
stable because of the dissipation of energy through friction. 
The preceding examples provide us with an intuitive understanding of the concept 
of stability. More formally, if the input to a stable system is bounded (i.e., if its magnitude 
does not grow without bound), then the output must also be bounded and therefore cannot 
diverge. This is the definition of stability that we will use throughout this book. For exam-
ple, consider applying a constant force f(t) = F to the automobile in Figure 1.2, with the 
vehicle initially at rest. In this case the velocity of the car will increase, but not without 
bound, since the retarding frictional force also increases with velocity. In fact, the velocity 
will continue to increase until the frictional force exactly balances the applied force; so, 
from eq. (1.84), we see that this terminal velocity value V must satisfy 
p 
1 
-V = -F, 
(1.107) 
m 
m 
i.e., 
F 
v = - . 
(1.108) 
p 
As another example, consider the discrete-time system defined by eq. (1.104), and 
suppose that the input x[n] is bounded in magnitude by some number, say, B, for all values 
of n. Then the largest possible magnitude for y[n] is also B, because y[n] is the average 
of a finite set of values of the input. Therefore, y[n] is bounded and the system is stable. 
On the other hand, c~msider the accumulator described by eq. (1.92). Unlike the system 
in eq. (1.104), this system sums all of the past values of the input rather than just a finite 
set of values, and the system is unstable, since the sum can grow continually even if x[n] 
is bounded. For example, if the input to the accumulator is a unit step u[n], the output 
will be 
n 
y[n] = L u[k] = (n + 1)u[n]. 
k = - oo 
That is, y[O] = 1, y(1] = 2, y[2] = 3, and so on, and y[n] grows without bound. 
Example 1 . 1 3 
If we suspect that a system is unstable, then a useful strategy to verify this is to look for 
a specific bounded input that leads to an unbounded output. Finding one such example 
enables us to conclude that the given system is unstable. If such an example does not 
exist or is difficult to find, we must check for stability by using a method that does not 
utilize specific examples of input signals. To illustrate this approach, let us check the 
stability of two systems, 
sl : y(t) = tx(t) 
(1.109) 

50 
Signals and· Systems 
Chap. 1 
and 
(1.110) 
In seeking a specific counterexample in order to disprove stability, we might try simple 
bounded inputs such as a constant or a unit step. For system S1 in eq. (1.109), a constant 
input x(t) = 1 yields y(t) = t, which is unbounded, since no matter what finite con-
stant we pick, jy(t)\ will exceed that constant for some t. We conclude that system S1 is 
unstable. 
For system S2, which happens to be stable, we would be unable to find a bounded 
input that results in an unbounded output. So we proceed to verify that all bounded inputs 
result in bounded outputs. Specifically, let B be an arbitrary positive number, and let x(t) 
be an arbitrary signal bounded by B; that is, we are making no assumption about x(t), 
except that 
\x(t)\ < B, 
(1.111) 
or 
-B < x(t) < B, 
(1.112) 
for all t. Using the definition of S2 in eq. (1.110), we then see that if x(t) satisfies 
eq. (1.111), then y(t) must satisfy 
(1.113) 
We conclude that if any input to S2 is bounded by an arbitrary positive number B, the 
corresponding ·output is guaranteed to be bounded by e8 • Thus, S2 is stable. 
The system properties and concepts that we have introduced so far in this section 
are of great importance, .and we will examine some of these in more detail later in the 
book. There remain, however, two additional properties-time invariance and linearity-
that play a particularly central role in the subsequent chapters of the book, and in the 
remainder of this section we introduce and provide initial discussions of these two very 
important concepts. 
1.6.5 Time lnvariance 
Conceptually, a system is time invariant if the behavior and characteristics of the system 
are fixed over time. For example, the RC circuit of Figure 1.1 is time invariant if the 
resistance and capacitance values R and C are constant over time: We would expect to 
get the same results from an experiment with this circuit today as we would if we ran the 
identical experiment tomorrow. On the other hand, if the values of R and C are changed 
or fluctuate over time, then we would expect the results of our experiment to depend on 
the time at which we run it. Similarly, if the frictional coefficient b and mass m of the 
automobile in Figure 1.2 are constant, we would expect the vehicle to respond identically 
independently of when we drive it. On the other hand, if we load the auto's trunk with 
heavy suitcases one day, thus increasing m, we would expect the car to behave differently 
than at other times when it is not so heavily loaded. 
The property of time in variance can be described very simply in terms of the signals 
and systems language that we have introduced. Specifically, a system is time invariant if 

Sec. 1.6 
Basic System Properties 
51 
a time shift in the input signal results in an identical time shift in the output signal. That 
is, if y[n] is the output of a discrete-time, time-invariant system when x[n] is the input, 
then y [n- no] is the output when x [n- no] is applied. In continuous time with y(t) the 
output corresponding to the input x(t), a time-invariant system will have y (t - to) as the 
output when x (t - to) is the input. 
To see how to determine whether a system is time invariant or not, and to gain some 
insight into this property, consider the following examples: 
Example 1 . 1 4 
Consider the continuous-time system defined by 
y(t) = sin [ x(t) ]. 
(1.114) 
To check that this system is time invariant, we must determine whether the time-
invariance property holds for any input and any time shift t0. Thus, let x 1 (t) be an 
arbitrary input to this system, and let 
YI(t) = sin[x1(t)] 
(1.115) 
be the corresponding output. Then consider a second input obtained by shifting x1 (t) in 
time: 
X2(t) = X[ (t - to) . 
(1.116) 
The output corresponding to this input is 
Y2(t) = sin [ x2(t)] = sin [XI (t- to)] . 
(1.117) 
Similarly, from eq. (1.115), 
Yl (t - to) = sin [XI (t - to)] . 
(1.118) 
Comparing eqs. (1.117) and (1.118), we see that y2(t) = y 1 (t - t0) , and therefore, this 
system is time invariant. 
Example 1 . 1 5 
As a second example, consider the discrete-time system 
y[n] = nx[n]. 
(1.119) 
This is a time-varying system, a fact that can be verified using the same formal procedure 
as that used in the preceding example (see Problem 1.28). However, when a system is 
suspected of being time varying, an approach to showing this that is often very useful 
is to seek a counterexample-i.e., to use our intuition to find an input signal for which 
the condition of time invariance is violated. In particular, the system in this example 
represents a system with a time-varying gain. For example, if we know that the current 
input value is 1, we cannot determine the current output value without knowing the 
current time. 
Consequently, consider the input signal x 1 [n] = S[n], which yields an output 
y 1[n]thatisidentically0(sincenc5[n] = O). However, theinput x2[n) = S[n-1]yields 
the output y2[n] = nS[n -1] = S[n - 1]. Thus, while x2[n] is a shifted version of x1 [n], 
Y2[n] is not a shifted version of Yl [n]. 

52 
Signals and Systems 
Chap. 1 
While the system in the preceding example has a time-varying gain and as a result 
is a time-varying system, the system in eq. (1.97) has a constant g~n and, in fact, is time 
invariant. Other examples of time-invariant systems are given by eqs. ( 1.91)- ( 1.104 ). The 
following example illustrates a time-varying system. 
Example 1 . 1 6 
j Consider the system 
y(t) = · x(2t). 
(1.120) 
This system represents a time scaling. That is, y(t) is a time-compressed (by a factor of 
2) version of x(t). Intuitively, then, any time shift in the input will also be compressed 
by a factor of 2, and it is for this reason that the system is not time invariant. To demon-
strate this by counterexample, consider the input x 1(t) shown in Figure 1.47(a) and the 
resulting output y1 (t) depicted in Figure 1.47(b). If we then shift the input by 2- i.e., 
consider x2(t) = x 1 (t- 2), as shown in Figure 1.47(c)-we obtain the resulting output 
(a) 
0 
(c) 
(e) 
Figure 1.47 
(a) The input x1 (t) to the system in Example 1.16; (b) the 
output y1 (t) corresponding to x1 (t); (c) the shifted input x2(t) = X1 (t - 2); 
(d) the output y2(t) corresponding to x2(t); (e) the shifted signal y1(t- 2). 
Note that y2(t) ,= y1 (t - 2), showing that the system is not time invariant. 

Sec. 1.6 
Basic System Properties 
53 
y2(t) = x2(2t) shown in Figure 1.47(d). Comparing Figures 1.47(d) and (e), we see that 
yz(t) ~ y 1 (t- 2), so that the system is not time invariant. (In fact, y2(t) = y 1 (t - 1), so 
that the output time shift is only half as big as it should be for time in variance, due to the 
time compression imparted by the system.) 
1 .6.6 Linearity 
A linear system, in continuous time or discrete time, is a system that possesses the impor-
tant property of superposition: If an input consists of the weighted sum of several signals, 
then the output is the sup~rposition-that is, the weighted sum-of the responses of the 
system to each of those signals. More precisely, let y1 (t) be the response of a continuous-
time system to an input x1 (t), and let y2(t) be the output corresponding to the input x 2(t). 
Then the system is linear if: 
1. Th~ response to x, (t) + x2(t) is YI (t) + y2(t). 
2. The response to ax1 (t) is ay1 (t), where a is any complex constant. 
The first of these two properties is known as the additivity property; the second is known 
as the scaling or homogeneity property. Although we have written this description using 
continuous-time signals, the same definition holds in discrete time. The systems specified 
by eqs. (1.91)-(1.100), (1.102)-(1.104), and (1.119) are linear, while those defined by 
eqs. (1.101) and (1.114) are nonlinear. Note that a system can be linear without being 
tiine invariant, as in eq. (1.119), and it can be time invariant without being linear, as in 
eqs. (1.101) and (1.114). 
The two properties defining a linear system can be combined into a single statement: 
continuous time: ax, (t) + bx2(t) ~ ay1 (t) + by2(t), 
discrete time: ax1 [n] + bx2[n] ~ ay1 [n] + by2[n]. 
(1.121) 
(1.122) 
Here, a and b are any complex constants. Furthermore, it is straightforward to show from 
the definition of linearity that if xk[n], k = 1, 2, 3, .. . , are a set of inputs to a discrete-
time linear system with corresponding outputs ydn], k = 1, 2, 3, ... , then the response to 
a linear combination of these inputs given by 
is 
x[n] = L akxk[n] ~ a,x,[n] + a2x2[n] + a3x3[n] +... 
(1.123) 
k 
y[n] = L akyk[n] = a,y,[n] + a2y2[n] + a3y3[n] + .... 
k 
(1.124) 
This very important fact is known as the superposition property, which holds for linear 
systems in both continuous and discrete time. 
A direct consequence of the superposition property is that, for linear systems, an 
input which is zero for all time results in an output which is zero for all time. For example, 
if x[n] ~ 
y[n], then the homogeneity property tells us that . 
0 = 0 · x[n] ~ 0 · y[n] = 0. 
(1.125) 

54 
Signals and Systems 
Chap. 1 
In the following examples we illustrate how the linearity of a given system can be 
checked by directly applying the definition of linearity. 
Example 1 . 1 7 
Consider a systemS whose input x(t) and output y(t) are related by 
y(t) = tx(t) 
To determine whether or not Sis linear, we consider two arbitrary inputs x 1 (t) and x2(t). 
Xt (t) ~ Yt (t) = IXt (t) 
X2(t) ~ Y2(t) = tx2(t) 
Let x3(t) be a linear combination of x 1(t) and x2(t). That is, 
x3(t) = ax, (t) + bx2(t) 
where a and b are arbitrary scalars. If x3(t) is the input to S, then the corresponding 
output may be expressed as 
y3(t) = tx3(t) 
= t(ax 1 (t) + bx2(t)) 
= atx1(t) + btx2(t) 
= ay, (t) + by2(t) 
We conclude that the system S is linear. 
Example 1 . 1 8 
Let us apply the linearity-checking procedure of the previous example to another system 
S whose input x(t) and output y(t) are related by 
y(t) = x2(t) 
Defining x 1 (t), x2(t), and x3(t) as in the previous example, we have 
Xt (t) ~ Yt (t) = XT(I) 
and 
x2(t) ~ Y2(t) = xi(t) 
X3(t) ~ y3(t) = x~(t) 
= (ax, (t) + bx2(t))2 
= a 2 xi(t) + b2 xi(t) + 2abx, (t)x2(t) 
= a2y 1 (t) + b2y2(t) + 2abx, (t)x2(t) 
Clearly, we can specify x 1 (t), x2(t), a, and b such that y3(t) is not the same as ay1 (t) + 
by2(t). For example, ifx1 (t) = 1, x2(t) = 0, a = 2, and b = 0, then y3(t) = (2x 1 (1))2 = 
4, but 2y1 (t) = 2(x1 (1))2, = 2. We conclude that th~ systemS is not linear. 
Example 1 . 1 9 
In checking the linearity of a system, it is important to remember that the system must 
satisfy both the additivity and homogeneity properties and that the signals, as well as 
any scaling constants, are allowed to be complex. To emphasize the importance of these 

Sec. 1.6 
Basic System Properties 
55 
points, consider the system specified by 
y[n] = <Jl..e{x[n]}. 
(1.126) 
As shown in Problem 1.29, this system is additive; however, it does not satisfy the ho-
mogeneity property, as we now demonstrate. Let 
x 1 [n] = r[n] + js[n] 
(1.127) 
be an arbitrary complex input with real and imaginary parts r[n] and s[n], respectively, 
so that the corresponding output is 
Y1 [n] = r[n]. 
(1.128) 
Now, consider scaling x 1 [n] by a complex number, for example, a = j; i.e., consider 
the input 
x2[n] = jx1[n] = j(r[n] + js[n]) 
= -s[n] + jr[n]. 
The output corresponding to x2[n] is 
Y2[n] = CRe{x2[n]} = -s[n], 
which is not equal to the scaled version of y 1 [n], 
ay1 [n] = jr[n]. 
(1.129) 
(1.130) 
(1.131) 
We conclude that the system violates the homogeneity property and hence is not linear. 
Example 1 .20 
Consider the system 
y[n] = 2x[n] + 3. 
(1.132) 
This system is not linear, as can be verified in several ways. For example, the system 
violates the additivity property: If x 1 [n] = 2 and x2[n] = 3, then 
x1[n] ~ Yl[n] = 2xl[n] + 3 = 7, 
x2[n] ~ Y2[n] = 2x2[n] + 3 = 9. 
However, the response to x3[n] = x 1 [n] + x2[n] is 
y3[n] = 2[xl [n] + x2[n]] + 3 = 13, 
(1.133) 
(1.134) 
(1.135) 
which does not equal y 1 [n] + y2[n] = 16. Alternatively, since y[n] = 3 if x[n] = 0, we 
see that the system violates the "zero-in/zero-out" property of linear systems given in 
eq. (1.125). 
It may seem surprising that the system in the above example is nonlinear, since 
eq. (1.132) is a linear equation. On the other hand, as depicted in Figure 1.48, the output 
of this system can be represented as the sum.of the output of a linear system and another 
signal equal to the zero-input response of the system. For the system in eq. (1.132), the 
linear system is 
x[n] ~ 2x[n], 
and the zero-input response is 
Yo[n] = 3. 

56 
1.7 SUMMARY 
Linear 
x(t) --•1 system 
Signals and Systems 
Yo(t) 
1--... + l----1~ y(t) 
Chap. 1 
Figure 1.48 
Structure of an incrementally linear system. Here, y0[n] is the 
zero-input response of the system. 
There are, in fact, large classes of systems in both continuous and discrete time that 
can be represented as in Figure 1.48-i.e., for which the overall system output consists 
of the superposition of the response of a linear system with a zero-input response. As 
shown in Problem 1.47, such systems correspond to the class of incrementally linear 
systems- i.e., systems in continuous or discrete time that respond linearly to changes in 
the input. In other words, the difference between the responses to any two inputs to an 
incrementally linear system is a linear (i.e., additive and homogeneous) function of the 
difference between.the two inputs. For example, if x 1 [n] and x2[n] are two inputs to the 
system specified by eq. (1.132), and if y1 [n] and y2[n] are the corresponding outputs, 
then 
Y1 [n] - Y2[n] = 2x, [n] + 3 - {2x2[n] + 3} = 2 {XI [n] - x2[n1} . 
(1.136) 
In this chapter, we have developed a number of basic concepts related to continuous-time 
and discrete-time signals and systems. We have presented both an intuitive picture of what 
signals and systems are through several examples and a mathematical representation for 
signals and systems that we will use throughout the book. Specifically, we introduced 
graphical and mathematical representations of signals and used these representations in 
performing transformations of the independent variable. We also defined and examined 
several basic signals, both in continuous time and in discrete time. These included com-
plex exponential signals, sinusoidal signals, and unit impulse and step functions. In ad-
dition, we investigated the concept of periodicity for continuous-time and discrete-time 
signals. 
In developing some of the elementary ideas related to systems, we introduced block 
diagrams to facilitate our discussions concerning the interconnection of systems, and we 
defined a number of important properties of systems, including causality, stability, time 
invariance, and linearity. 
The primary focus in most of this book will be on the class of linear, time-invariant 
(LTI) systems, both in continuous time and in discrete time. These systems play a par-
ticularly important role in system analysis and design, in part due to the fact that many 
systems encountered in nature can be successfully modeled as linear and time invariant. 
Furthermore, as we shall see in the following chapters, the properties of linearity and time 
invariance allow us to analyze in detail the behavior of LTI systems. 

Chap. 1 Problems 
57 
Chapter 1 Problems 
Basic problems emphasize the mechanics of using concepts and methods in a man-
ner similar to that illustrated in the examples that are solved in the text. 
Advanced problems explore and elaborate upon the foundations and practical im-
plications of the textual material. 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The next two sections contain problems belonging to the 
· basic and advanced categories, respectively. A final section, Mathematical Review, pro-
vides practice problems on the fundamental ideas of complex arithmetic and algebra. 
BASIC PROBLEMS WITH ANSWERS 
1.1. Express each of the following complex numbers in Cartesian form (x + jy): !ej7T' 
!e- j1r ej1rl2 e- j1r!2 ej57TI2 - f2ej7TI4 
f2ej97TI4 
f2e- j97T!4 
f2e - j7T!4 
2 
, 
, 
, 
,VL.. 
, ....;.t.. 
,.yL 
,.yL. 
. 
1.2. Express each of the following complex numbers in polar form (rej8, with -7r < 
() $ 
7T): 5, -2, -3j, 4- Jf , 1 + j, (1- j)2, j(l- j), (1 + j)/(1 - j), (}2 + j}2)1 
(1 + j}3). 
1.3. Determine the values of P,., and Eoo for each of the following signals: 
(a) x 1(t) = e- 21u(t) 
(b) x2(t) = ej(Zt+ 7TI4) 
(c) x3(t) = cos(t) 
(d) x, [n] = <!)nu[n] 
(e) xz [n] = ej(7T!Zn+7TIS) 
(f) X3[n] =cos( in) 
1.4. Let x[n] be a signal with x[n] = 0 for n < -2 and n > 4. For each signal given 
below, determine the values of n for which it is guaranteed to be zero. 
(a) x[n- 3] 
(b) x[n + 4] 
(c) x[ -n] 
(d) x[-n + 2] 
(e) x[ - n- 2] 
1.5. Let x(t) be a signal with x(t) = 0 fort < 3. For each signal given below, determine 
the values oft for which it is guaranteed to be zero. 
(a) x(l - t) 
(b) x(1 - t) + x(2- t) 
(c) x(l - t)x(2- t) 
(d) x(3t) 
(e) x(t/3) 
1.6. Determine whether or not each of the following signals is periodic: 
(a) x 1 (t) = 2ej(t+7TI4>u(t) 
(b) x 2[n] = u[n] + u[ - n] 
(c) x3 [n] = :z;= 
- x{S[n - 4k]- S[n- 1 - 4k]} 
1.7. For each signal given below, determine all the values of the independent variable at 
which the even part of the signal is guaranteed to be zero. 
· 
(a) x, [n] = u[n] - u[n - 4] 
(b) x2(t) = sindt) 
(c) x 3[n] = <!)"u[n - 3] 
(d) x4(t) = e- st;(t + 2) 
1.8. Express the real part of each of the following signals in the form A e- m cos(wt + cj>), 
where A, a, w, and 4> are real numbers with A > 0 and - 7r < 4> s 1r: 
(a) x 1 (t) = - 2 
(b) x2(t) = fie Jrr/4 cos(3t + 27T) 
(c) x3(t) = e- 1 sin(3t + 7T) 
(d) x4(t) = j e( - 2-,. J IOOJt 
1.9. Determine whether or not each of the following signals is periodic. If a signal is 
periodic, specify its fundamental period. 
(a) x 1 (t) = j ej !Ot 
~ . 
(b) x2 (t) = eH 
~jlt 
1 
(c) x, [n] = eJ?m; 
(d) x4[n] = 3eJ37T\,,_,. 11- >15 
(e) x5[n] = 3eJ ,,5,n T 1/_J 

58 -
Signals and Systems 
Chap. 1 
1.10. Determine the fundamental period of the signal x(t) = 2cos(10t + 1) - ,sin(4t- 1). 
1.11. Determine the fundamental period of the signal x[ n] = 1 + ej47rnn -
ejZ7rnl5. 
1.12. Consider the discrete-time signal 
00 
x[n] = 1 - ~ 
8[n - 1 - k]. 
k =3 
Determine the values of the integers M and no so that x[n] may be expressed as 
x[n] = u[Mn - no]. 
1.13. Consider the continuous-time signal 
x(t) = 8(t + 2) - 8(t - 2). 
Calculate the value of E oo for the signal 
y(t) = f oo x( r)dr. 
1.14. Consider a periodic signal 
x(t) = { 1, 
0 :5 t ::;; 1 
-2, 
1 < t < 2 
with period T = 2. The derivative of this signal is related to the "impulse train" 
00 
' g(t) = ~ 
8(t - 2k) 
k = -oo 
with period T = 2; It can be shown that 
dx(t) 
(if = Atg(t - ft) + Azg(t- tz). 
Determine the values of At, t1, Az, and tz. 
1.15. Consider a systemS with input x[n] and output y[n]. This system is obtained through 
a series interconnection of a system S1 followed by a system S2. The input-output 
relationships for S 1 and Sz are 
Yt [n] = 2xt [n] + 4xt [n - 1], 
1 
yz[n] = xz[n- 2] + 2xz[n- 3], 
where x 1 [n] and x2[n] denote input signals. 
(a) Determine the input-output relationship for system S. 
(b) Does the input -output relationship of system S change if the order in which S 1 
and Sz are connected in series is reversed (i.e., if S2 follows S1)? 
1.16. Consider a discrete-time system with input x[n] and output y[n]. The input-output 
relationship for this system is 
y[n] = x[n]x[n - 2]. 

Chap. 1 Problems 
59 
(a) Is the system memoryless? 
(b) Determine the output of the system when the input is A5[n], where A is any 
real or complex number. 
(c) Is the system invertible? 
1.17. Consider a continuous-time system with input x(t) and output y(t) related by 
(a) Is this system causal? 
(b) Is this system linear? 
y(t) = x(sin(t)). 
1.18. Consider a discrete-time system with input x[n] and output y[n] related by 
n+no 
y[n] = 
~ x[k], 
where no is a finite positive integer. 
(a) Is this system linear? 
(a) Is this system time-invariant? 
k =n- n0 
(c) If x[n] is known to be bounded by a finite integer B (i.e., lx[nJI < B for all n), it 
can be shown that y[n] is bounded by a finite number C. We conclude that the 
given system is stable. Express C in terms of B and no. 
1.19. For each of the following input-output relationships, determine whether the corre-
sponding system is linear, time invariant or both. 
(a) y(t) = t2 x(t- 1) 
(b) y[n] = x2[n- 2] 
(c) y[n] = x[n + 1] - x[n- 1] 
(d) y[n] = Od{x(t)} 
1.20. A continuous-time linear systemS with input x(t) and output y(t) yields the follow-
ing input-output pairs: 
x(t) = ej21 ~ y(t) = ej31, 
x(t) = e- j 21 ~ y(t) = e- j 31. 
(a) If x1 (t) = cos(2t), determine the corresponding output y 1 (t) for systemS. 
(b) If x2(t) = cos(2(t - 1)), determine the corresponding output y2(t) for sys-
temS. 
BASIC PROBLEMS 
1.21. A continuous-time signal x(t) is shown in Figure Pl.21. Sketch and label carefully 
each of the following signals: 
(a) x(t- 1) 
(b) x(2- t) 
(d) x(4-
~) · 
(e) [x(t) + x( - t)]u(t) 
(c) x(2t + 1) 
(f) x(t)[5(t + ~) - 5(t- ~)] 
1.22. A discrete-time signal is shown in Figure Pl.22. Sketch and label carefully each of 
the following signals: 
(a) x[n - 4] 
(d) x[3n + 1] 
(g) !x[n] + !< -l)n x[n] 
(b) x[3 - n] 
(e) x[n]u[3 - n] 
(h) x[(n - 1?J 
(c) x[3n] 
(f) x[n - 2]5[n - 2] 

-2 
60 
2r-----. 
0 
2 
- 1 
-4 
-1 
Figure P1.21 
-3 
- 1 
2 
Signals and Systems 
1 1 
2 
1 2 
Chap. 1 
- 1 0 
1 
2 
3 
4 
5 
n 
Figure P1.22 
1.23. Determine and sketch the even and odd parts of the signals depicted in Figure P1.23. 
Label your sketches carefully. 
(a) 
x(t) 
1 
2 
~ 
-2 
- 1 
1 
(b) 
The line 
.......__The line 
x(t) = - 2t fort < 0 
x(t) = tfor t > 0 
(c) 
Figure P1.23 
1.24. Determine and sketch the even and odd parts of the signals depicted in Figure Pl.24. 
Label your sketches carefully. 

Chap. 1 Problems 
61 
.. ·lllllll ~1
1 2 3 
n 
(a) 
3 
2 
n 
2 
- 4 
n 
(c) 
Figure P1.24 
1.25. Determine whether or not each of the following continuous-time signals is periodic. 
If the signal is periodic, determine its fundamental period. 
(a) x(t) = 3cos(4t+ j) 
(b) x(t) = ej(1rr- J) 
(c) x(t) = [cos(2t- j)]2 
(d) x(t) = &t{cos(47Tt)u(t)} 
00 
(e) x(t) = &tt{sin(47Tt)u(t)} 
(f) x(t) = L e-<2r- n) u(2t - n) 
n= - oo 
1.26. Determine whether or not each of the following discrete-time signals is periodic. If 
the signal is periodic, determine its fundamental period. 
(a) x[n] = sin( 6; n + 1) 
(b) x[n] = cos(~ - 7T) 
(c) x[n] = cos(in2) 
(d) x[n] = cos(~n)cos(*n) 
(e) x[n] = 2cos(*n) +sin( in)- 2cos(~n + i) 
1.27. In this chapter, we introduced a number of general properties of systems. In partic-
ular, a system may or may not be 
(1) Memoryless 
(2) Time invariant 
(3) Linear 
(4) Causal 
(5) Stable 
Determine which of these properties hold and which do not hold for each of the 
following continuous-time systems. Justify your answers. In each example, y(t) de-
notes the system output and x(t) is the system input. 

62 
(a) y(t) = x(t - 2) + x(2 - t) 
(c) y(t) = f !~ x( T)dT 
{ 
0 
x(t) < 0 
(e) y(t) = 
;(t) + x(t - 2), 
x(t) ~ 0 
(g) y(t) = d~~t) 
Signals and Systems 
Chap. 1 
(b) y(t) = [cos(3t)]x(t) 
{ 
0 
t < 0 
(d) y(t) = 
;(t) + x(t - 2), 
t ~ 0 
(f) y(t) = x(t/3) 
1.28. Determine which of the properties listed in Problem 1.27 hold and which do not 
hold for each of the following discrete-time systems. Justify your answers. In each 
example, y[n] denotes the system output and x[n] is the system input. 
(a) y[n] = x[ -n] 
(b) y[n] = x[n- 2] - 2x[n- 8] 
(c) y[n] = nx[n] 
(d) y[n] = 8v{x[n - I]} 
{ 
x[n], 
n ~ 1 
{ x[n], 
n ~ 1 
(e) y[n] = 
0, 
n = 0 
(f) y[n] = 
0, 
n = 0 
x[n + 1], 
n ~ -1 
x[n], 
n ~ - 1 
(g) y[n] = x[4n + 1] 
1.29. (a) Show that the discrete-time system whose input x[n] and output y[n] are related 
by y[n] = ffi-e{x[n]} is additive. Does this system remain additive if its input-
output relationship is changed to y[n] = ffi-e{ej7Tnf4x[n]}? (Do not assume that 
x[n] is real in this problem.) 
(b) In the text, we discussed the fact that the property of linearity for a system is 
equivalent to the system possessing both the additivity property and homogene-
ity property. Determine whether each of the systems defined below is additive 
and/or homogeneous. Justify your answers by providing a proof for each prop-
erty if it holds or a counterexample if it does not. 
(i) y(t) = _!_ [dx(t) f 
(ii) y[n] = 
x[n-1] ' 
{ 
x[n]x[n- 2] 
x[n _ 1] ,= 0 
x(t) 
dt 
0, 
x[n - I] = 0 
1.30. Determine if each of the following systems is invertible. If it is, construct the inverse 
system. If it is not, find two input signals to the system that have the same output. 
(a) y(t) = x(t - 4) 
(b) y(t) = cos[x(t)] 
(c) y[n] = nx[n] 
(d) y(t) = Coo X(T)dT 
{ 
x[n - 1], 
n ~ 1 
(e) y[n] = 
0, 
n = 0 
(f) y[n] = x[n]x[n - 1] 
x[n], 
n ~ - 1 
(g) y[n] = x[l - n] 
(i) y[n] = L~ = - oo(~y-kx [k] 
(h) y(t) = Coo e-(1- T) x( T)dT 
(j) y(t) = d~~t) 
(k) 
[n] = { x[n + 1], 
n ~ 0 
y 
x[n], 
n ~ - 1 
(m) y[n] = x[2n] 
(I) y(t) = x(2t) 
(n) y[n] = { x[n/2], 
. 
0, 
neven 
n odd 
1.31. In this problem, we illustrate one of the most important consequences of the prop-
erties of linearity and time invariance. Specifically, once we know the response 
of a linear system or a linear time-invariant (LTI) system to a single input or the 
responses to several inputs, we can directly compute the responses to many other 

Chap. 1 Problems 
63 
x, (t) 
input sigl}als. Much of the remainder of this book deals with a thorough exploitation 
of this fact in order to develop results and techniques for analyzing and synthesizing 
LTI systems. 
(a) Consider an LTI system whose response to the signal x 1 (t) in Figure Pl.3l(a) is 
the signal Yl (t) illustrated in Figure P1.31 (b). Determine and sketch carefully 
the response of the system to the input x2(t) depicted in Figure Pl.31(c). 
(b) Determine and sketch the response of the system considered in part (a) to the 
input x3(t) shown in Figure Pl.3l(d). 
y, (t) 
. 1r----,l, 
:~ 
0 
1 
2 
(a) 
0 
1 
2 
(b) 
I 
I 
- 1 
0 
2 
-1 1-
(c) 
(d) 
Figure P1.31 
ADVANCED PROBLEMS 
1.32. Let x(t) be a continuous-time signal, and let 
Yl (t) = x(2t) and Y2(t) = x(t/2). 
The signal y1 (t) represents a speeded up version of x(t) in the sense that the duration 
of the signal is cut in half. Similarly, y2(t) represents a slowed down version of 
x(t) in the sense that the duration of the signal is doubled. Consider .the following 
statements: 
(1) If x(t) is periodic, then y1(t) is periodic. 
(2) If Yl (t) is periodic, then x(t) is periodic. 
(3) If x(t) is periodic, then y2(t) is periodic. 
(4) If y2(t) is periodic, then x(t) is periodic. 
For each of these statements, determine whether it is true, and if ,so, determine the 
relationship between the fundamental periods of the two signals considered in the 
statement. If the statement is not true, produc~ a counterexample to it. 
1.33. Let x[n] be a discrete-time signal, and let 
{ 
x[n/2] 
y1 [n] = x[2n] and Y2[n] = 
O, 
' 
neven 
nodd · 

64 
Signals and Systems 
Chap. 1 
The signals YI [n] and y2[n] respectively represent in some sense the speeded up and 
slowed down versions of x[n]. However, it should be noted that the discrete-time 
notions of speeded up and slowed down have subtle differences with respect to their 
continuous-time counterparts. Consider the following statements: 
(1) If x[n] is periodic, then Yt [n] is periodic. 
(2) If Yl [n] is periodic, then x[n] is periodic. 
(3) If x [n] is periodic, then y2[n] is periodic. 
(4) If Y2[n] is periodic, then x [n] is periodic. 
For each of these statements, determine whether it is true, and if so, determine the 
relationship between the fundamental periods of the two signals considered in the 
statement. If the statement is not true, produce a counterexample to it. 
1.34. In this problem, we explore several of the properties of even and odd signals. 
(a) Show that if x[n] is an odd signal, then 
+eo L x[n] = 0. 
n= - oo 
(b) Show that if x 1 [n] is an odd signal and x2[n] is an even signal, then x 1 [n]x2[n] 
is an odd signal. 
(c) Let x[n] be an arbitrary signal with even and odd parts denoted by 
xe[n] = 8v{x[n]} 
and 
x 0 [n] = 0d{x[n]}. 
Show that 
+eo 
+eo 
+eo 
L x2[n] = L x;[n] + L x; [n]. 
n= -oo 
n= -oo 
n= - oo 
(d) Although parts (a)-( c) have been stated in terms of discrete-time signals, the 
analogous properties are also valid in continuous time. To demonstrate this, 
show that 
L+: x2(t)dt = J_+eoeo x;(t)dt + J_+eoeo x; (t)dt, 
where Xe(t) and x 0 (t) are, respectively, the even and odd parts of x(t). 
1.35. Consider the periodic discrete-time exponential time signal 
x[n] = eim(27TIN)n. 
Show that the fundamental period of this' signal is 
No = N/gcd(m, N), 
where gcd(m, N) is the greatest common divisor of m and N-that is, the largest 
integer that divides both m and Nan integral number of times. For example, 
gcd(2, 3) = 1, gcd(2, 4) = 2, gcd(8, 12) = 4. 
Note that No = N if m and N have no factors in common. 

Chap. 1 Problems 
1.36. Let x(t) be the continuous-time complex exponential signal 
x(t) = e jwot 
65 
with fundamental frequency w0 and fundamental period To = 21Tiwo. Consider the 
discrete-time signal obtained by taking equally spaced samples of x(t)-that is, 
x[n] = x(nT) = ejwonT. 
(~) Show that x[n] is periodic if and only if T!T0 is a rational number-
that is, if 
and only if some multiple of the sampling interval exactly equals a multiple of 
the period of x(t). 
(b) Suppose that x[n] is periodic-
that is, that 
T -
p 
-- - , 
To 
q 
(Pl.36-l) 
where p and q are integers. What are the fundamental period and fundamental 
frequency of x[n]? Express the fundamental frequency as a fraction of w0T. 
(c) Again assuming that T!To satisfies eq. (Pl.36- l), determine precisely how 
many periods of x(t) are needed to obtain the samples that form a single period 
of x[n]. 
1.37. An important concept in many communications applications is the correlation be-
tween two signals. In the problems at the end of Chapter 2, we will have more to 
say about this topic and will proyide some indication of how it is used in practice. 
For now, we content ourselves with a brief introduction to correlation functions and 
some of their properties. 
Let x(t) and y(t) be two signals; then the correlation function is defined as 
c/>xy(t) = [ , x(t + r)y( r)dr. 
The function cf> xAt) is usually referred to as the autocorrelation function of the signal 
x(t),while c/>xy(t) is often called a cross-correlation function. 
(a) What is the relationship between cf>xy(t) and c/>yx(t)? 
(b) Compute the odd part of cf>xAt). 
(c) Suppose that y(t) = x(t + T). Express cf>xy(t) and c/>yy(t) in terms of cf>xAt). 
1.38. In this problem, we examine a few of the properties of the unit impulse function. 
(a) Show that 
1 
o(2t) = 2s(t). 
Hint: Examine Sa(t). (See Figure 1.34.) 
(b) In Section 1.4, we defined the continuous-time unit impulse as the limit of the 
signal Sa(t). More precisely, we defined several of the properties of S(t) by 
examining the corresponding properties of Sa(t). For example, since the signal 
ua(t) = [ , oa(r)dr 

66 
--A 
converges to the unit step 
u(t) = lim u~(t), 
a ..... o 
we could interpret 8(t) through the equation 
u(t) = L, 
8(T)dT 
' 
Signals and Systems 
or by viewing 8(t) as the formal derivative of u(t). 
Chap. 1 
(P1.38-l) 
This type of discussion is important, as we are in effect trying to define 
8(t) through its properties rather than by specifying its value for each t, which 
is not possible. In Chapter 2, we provide a very simple characterization of the 
behavior of the unit impulse that is extremely useful in the study of linear time-
invariant systems. For the present, however, we concentrate on demonstrating 
that the important concept in using the unit impulse is to understand how it 
behaves. To do this, consider the six signals depicted in Figure P1.38. Show 
rl(t) 
ri(t) 
im 
ij D 
a. 
a. 
2 
2 
(a) 
r~ (t) 
(c) 
r~ (t) 
2 
:1 
(e) 
A 2A 
(b) 
r1 (t) 
(d) 
- A 
A 
(f) 
Figure P1.38 

Chap. 1 Problems 
that each "behaves like an impulse" as Ll ~ 0 in that, if we let 
u~(t) = [ ., r~(T)dT, 
then 
lim u~ (t) = u(t). 
~ -- o 
In each case, sketch and label carefully the signal u~ (t). Note that 
ri (0) = r1 (0) = 0 for all Ll. 
67 
Therefore, it is not enough to define or to think of 5(t) as being zero for t ""' 0 
and infinite fort = 0. Rather, it is properties such as eq. (Pl.38-1) that define 
the impulse. In Section 2.5 we will define a whole class of signals known as 
singularity functions, which are related to the unit impulse and which are also 
defined in terms of their properties rather than their values. 
1.39. The role played by u(t), S(t), and other singularity functions in the study of linear 
time-invariant systems is that of an idealization of a physical phenomenon, and, as 
we will see, the use of these idealizations allow us to obtain an exceedingly impor-
tant and very simple representation of such systems. In using singularity functions, 
we need, however, to be careful. In particular, we must remember that they are ideal-
izations, and thus, whenever we perform a calculation using them, we are implicitly 
assuming that this calculation represents an accurate description of the behavior of 
the signals that they are intended to idealize. To illustrate, consider the equation 
x(t)5(t) = x(0)5(t). 
(Pl.39-1) 
This equation is based on the observation that 
x(t)5~(t) = x(O)S~(t). 
(Pl.39- 2) 
Taking the limit of this relationship then yields the idealized one given by eq. 
(Pl.39-1). However, a more careful examination of our derivation of eq. (Pl.39-2) 
shows that that equation really makes sense only if x(t) is continuous at t = 0. If it 
is not, then we will not have x(t) = x(O) for t small. 
To make this point clearer, consider the unit step signal u(t). Recall from eq. 
(1.70) that u(t) = 0 fort < 0 and u(t) = l fort > 0, but that its value at t = 0 is 
not defined. [Note, for example, that u~(O) = 0 for all Ll, while ui(O) = ~ (from 
Problem 1.38(b)).] The fact that u(O) is not defined is not particularly bothersome, 
as long as the calculations we perform using u(t) do not rely on a specific choice for 
u(O). For example, if f(t) is a signal that is continuous at t = 0, then the value of 
[
"'"" f(a)u(a')da 
does not depend upon a choice for u(O). On the other hand, the fact that u(O) is 
undefined is significant in that it means that certain calculations involving singular-
ity functions are undefined. Consider trying to define a value for the product u(t)5(t). 

68 
Signals and Systems 
Chap. 1 
To see that this cannot be defined, show that 
lim [ua(t)8(t)] = 0, 
.:l->0 
but 
lim [ua(t)8a(t)] = -2
18(t) . 
.:l-+0 
In general, we can define the product of two signals without any difficulty, 
as long as the signals do not contain singularities (discontinuities, impulses, or the 
other singularities introduced in Section 2.5) whose locations coincide. When the 
locations do coincide, the product is undefined. As an example, show that the signal 
I
+oo 
g(t) = _"' u(T)S(t- r)dr 
is identical to u(t); that is, it is 0 for t < 0, it equals 1 for t > 0, and it is undefined 
fort = 0. 
1.40. (a) Show that if a system is either additive or homogeneous, it has the property 
that if the input is identically zero, then the output is also identically zero. 
(b) Determine a system (either in continuous or discrete time) that is neither ad-
ditive nor homogeneous but which has a zero output if the input is identically 
zero. 
(c) From part (a), can you conclude that if the input to a linear system is zero be-
tween times t1 and t2 in continuous time or between times n1 and n2 in discrete 
time, then its output must also be zero between these same times? Explain your 
answer. 
1.41. Consider a systemS with input x[n] and output y[n] related by 
y[n] = x[n]{g[n] + g[n- 1]}. 
(a) If g[n] = 1 for all n, show that Sis time invariant. 
(b) If g[n] = n, show that Sis not time invariant. 
(c) If g[n] =· 1 + ( - l)n, show that Sis time invariant. 
1.42. (a) Is the following statement true or false? 
The series interconnection of twq linear time-invariant systems is itself a linear, 
time-invariant system. 
Justify your answer. 
(b) Is the following statement true or false? 
The series interconnection of two nonlinear systems is itself nonlinear. 
Justify your answer. 
(c) Consider three systems with the following input-output relationships: 
System 1: 
y[n] = { x[n/2], 
0, 
neven 
n odd ' 

Chap. 1 Problems 
69 
System 2: 
1 
1 
y[n] = x[n] + 2x[n- 1] + 4x[n - 2], 
System 3: 
y[n] = x[2n]. 
Suppose that these systems are connected in series as depicted in Figure P1.42. 
Find the input-output relationship for the overall interconnected system. Is this 
system linear? Is it time invariant? 
· 
y[n] 
Figure P1.42 
1.43. (a) Consider a time-invariant system with input x(t) and output y(t). Show that if 
x(t) is periodic with period T, then so is y(t). Show that the analogous result 
also holds in discrete time. 
(b) Give an example of a time-invariant system and a nonperiodic input signal x(t) 
such that the corresponding output y(t) is periodic. 
1.44. (a) Show that causality for a continuous-time linear system is equivalent to the 
following statement: 
For any time to and any input x(t) such that x(t) = 0 fort < t0 , the correspond-
ing output y(t) must also be zero fort < t0 . 
The analogous statement can be made for a discrete-time linear system. 
(b) Find a nonlinear system that satisfies the foregoing condition but is not causal. 
(c) Find a nonlinear system that is causal but does not satisfy the condition. 
(d) Show that invertibility for a discrete-time linear system is equivalent to the 
following statement: 
The only input that produces y[n] = 0 for all n is x[n] = 0 for all n. 
The analogous statement is also true for a continuous-time linear system. 
(e) Find a nonlinear system that satisfies the condition of part (d) but is not invert-
ible. 
1.45. In Problem 1.37, we introduced the concept of correlation functions. It is often im-
portant in practice to compute the correlation function cPhAt), where h(t) is a fixed 
given signal, but where x(t) may be any of a wide variety of signals. In this case, 
what is done is to design a system S with input x(t) and output </Jhx(t). 
(a) IsS linear? IsS time invariant? IsS causal? Explain your answers. 
(b) Do any of your answers to part (a) change if we take as the output cPxh(t) rather 
than cPhAt)? 
1.46. Consider the feedback system of Figure Pl.46. Assume that y[n] = 0 for n < 0. 
+~ e[n] .. l 
x[n] ---toll~ l 
... _____ .. _:_y-[n_]_=_\e-[n---1]-~~~~~~..--.....,.~ y[n] 
Figure P1.46 

70 
1.47. 
(a) Sketch the output when x[n] = 8[n]. 
(b) Sketch the output when x[n] = u[n]. 
Signals and Systems 
Chap. 1 
(a) LetS denote an incrementally linear system, and let x 1 [n] be an arbitrary input 
signal to S with corresponding output y1 [n]. Consider the system illustrated in 
Figure Pl.47(a). Show that this system is linear and that, in fact, the overall 
input-output relationship between x [n] and y[n] does not depend on the partic-
ular choice of x 1 [n]. 
(b) Use the result of part (a) to show that Scan be represented in the form shown 
in Figure 1.48. 
(c) Which of the following systems are incrementally linear? Justify your answers, 
and if a system is incrementally linear, identify the linear system Land the zero-
input response Yo[n] or y0(t) for the representation of the system as shown in 
Figure 1.48. 
(i) 
y[n] = n + x[n] + 2x[n + 4] 
{ 
n/2, 
(ii) 
[ ] 
(n- 1)/2 
Y n = (n- 1)/2 + k~oo x[k], 
n odd 
n even 
x[n] 
:~ ·I 
s 
:~ 
• 
y[n] 
(a) 
x1[n] 
Y1[n] 
t 
X (t) 
.~ w (t) • I 
y(t) = d~:t) 
• 
y (t) 
(b) 
COS('lTn) 
v [n] 
z [n] = VL[n] 
z[n] 
x [n] 
Y [n] 
w [n] = x2 [n] 
w[n] 
(c) 
Figure P1.47 

Chap. 1 Problems 
("') 
[ ] 
{ x[n] - x[n - 1] + 3, 
if x[O] ~ 0 
m Y n = 
x[n] - x[n - 1] - 3, if x[O] < 0 
(iv) The system depicted in Figure Pl.47(b). 
(v) The system depicted in Figure Pl.47(c). · 
71 
(d) Suppose that a particular incrementally linear system: has a representation as 
in Figure 1.48, with L denoting the linear system and Yo[n] the zero-input re-
sponse. Show that Sis time invariant if and only if Lis a time-invariant system 
and yo[n] is constant. 
MATHEMATICAL REVIEW 
The complex number z can be expressed in several ways. The Cartesian or rectangular 
form for z is 
Z =X+ jy, 
where j = J=1 and x andy are real numbers referred to respectively as the real part and 
the imaginary part of z. As we indicated earlier, we will often use the notation 
x = CR.e{z}, y = t1m{z}. 
The complex number z can also be represented in polar form as 
where r > 0 is the magnitude of z and () is the angle or phase of z. These quantities will 
often be written as 
r = lzl. () = 1::z. 
The relationship between these two representations of complex numbers can be de-
termined either from Eulers relation, 
ej6 = cos() + j sin(), 
or by plotting z in the complex plane, as shown in Figure Pl.48, in which the coordinate 
axes are CR.e{z} along the horizontal axis and t1m{z} along the vertical axis. With respect to 
this graphical representation, x and y are the Cartesian coordinates of z, and r and () are its 
polar coordinates. 
dm 
y 
X 
(R.e 
Figure P1.48 

72 
Signals and Systems 
Chap. 1 
1.48. Let zo be a complex number with polar coordinates (ro, Oo) and Cartesian coordi-
nates (xo, yo). Determine expressions for the Cartesian coordinates of the following 
complex numbers in terms of xo and Yo· Plot the points zo, ZJ, 22, ZJ, u, and zs in 
the complex plane when r0 = 2 and Oo = '1TI4 and when ro = 2 and 00 = 'TT/2. 
"Indicate on your plots the real and imaginary parts of each point. 
(a) ZJ = roe- iBo 
(b) 22 = ro 
(c) Z3 = roei<Bo+-rr) 
(d) Z4 = roeiC- Bo +-rr) 
(e) zs = roeiCBo+ 27T) 
1.49. Express each of the following complex numbers in polar form, and plot them in the 
complex plane, indicating the magnitude and angle of each number: 
(a) 1 + jj3 
(b) -5 
(c) - 5- 5j 
(d) 3 + 4j 
(e) (1- j/3)3 
(f) (1 + j)5 
(g) ( J3 + j3)(1 _ j) 
(h) 2- }(61./3) 
(i) I+ jfj 
2+ j(61 fj) 
J3+ j 
(j) j(l + j)e}1rl6 
(k) ( J3 + j)2)2e- }"11"14 
(I) ei"
1L I 
l +JJ3 
1.50. (a) Using Euler's relationship or Figure Pl.48, determine expressions for x andy 
in terms of r and (}. 
(b) Determine expressions for rand(} in terms of x andy. 
(c) If we are given only r and tan(}, can we uniquely determine x and y? Explain 
your answer. 
1.51. Using Euler's relation, derive the following relationships: 
(a) cosO= i<eiB+e- 18) 
(b) sinO= iJ<ei8 -e- i8) 
(c) cos2 (} = 40 +cos 20) 
(d) (sinO)(sin<f>) = 4 cos(O - cj>)- 4 cos((}+ c/>) 
(e) sin((} + 4>) = sin(} cos 4> + cos(} sin 4> 
1.52. Let z denote a complex variable; that is, 
z = x + j y = rei8. 
The complex conjugate of z is 
z* = x- jy = re- 18. 
Derive each of the following relations, where z, z1, and 22 are arbitrary complex 
numbers: 
(a) zz* = ? 
(b) f. = ei28 
(c) z + z* = 2ffi-e{z} 
(d) z - z* = 2jdm{z} 
(e) (ZI + 22)* = z7 + z2 
(f) (az1 22)* ~ az7 z;, where a is any real number 
(g) (~ )* = 4 
22 
z2 
(h) ffi-e{~} = .!_[ Z1Zi+:;z2] 
Z2 
2 
Z2Z2 
1.53. Derive the following relations, where z, z1, and z2 are arbitrary complex numbers: 
(a) (e 2)* = ez" 
(b) ZJZ2 + zjz2 ,;, 2ffi-e{zlz2} = 2ffi-e{zjz2} 

Chap. 1 Problems 
(c) lzl = lz*l 
(d) lz1z21 = lzdiZ21 
(e) cR.e{z} ~ lzl. fJm{z} $ lzl 
(f) lz, zi + z~ z2l $ 21z1 z2l 
(g) <lzd - IZ21>2 
$ lz1 + z2l2 ~ <lzd + IZ21)2 
73 
1.54. The relations considered in this problem are used on many occasions throughout the 
book. 
(a) Prove the validity of the following expression: 
N-1 
{ N 
2:an = 
1-'-aN 
n=O 
1-a' 
a= I 
for any complex number a ¥- 1 · 
This is often referred to as the finite sum formula. 
(b) Show that if Ia I < 1, then 
' 
. 
This is often referred to as the infinite sum formula. 
(c) Show also if Ia I < 1, then 
00 2: na" = ..,...,--a----,--;;-
n= O 
(1- a)2' 
(d) Evaluate 
00 
2:a", 
n= k 
assuming that Ia I < 1. 
1.55. Using the results from Problem 1.54, evaluate each of the following sums and ex-
press your answer in Cartesian (rectangular) form: 
(a) 2:~=0ej1Tnl2 
(b) 2:~=-2ej1Tn/2 
(c) 2::=o(~)nej1rnl2 
(d) .2::= 2 (~)nej1T11I2 
(e) .2:~=0 cos(¥n) 
(f) .2::= 0(~)
11 cos(}n) 
1.56. Evaluate each of the following integrals, and express your answer in Cartesian (rect-
angular) form: 
· 
(a) /0
4 ejm12dt 
(b) /0
6 ejm12dt 
(c) /2
8 ejm12dt 
(d) /0
00 e -<I+ j)tdt 
(e) fooo e- 1 cos(t)dt 
(f) /0
00 e- 21 sin(3t)dt 

2 
LINEAR TIME-INVARIANT SYSTEMS 
2.0 INTRODUCTION 
74 
In Section 1.6 we introduced and discussed a number of basic system properties. Two of 
these, linearity and time in variance, play a fundamental role in signal and system analysis 
for two major reasons. First, many physical processes possess these properties and thus 
can be modeled as linear time-invariant (LTI) systems. In addition, LTI systems can be 
analyzed in considerable detail, providing both insight into their properties and a set of 
powerful tools that form the core of signal and system analysis. 
A principal objective of this book is to develop an understanding of these proper-
ties and tools and to provide an introduction to several ofthe very important applications 
in which the tools are used. Io. this chapter, we begin the development by deriving and 
examining a fundamental and extremely useful representation for LTI systems and by in-
troducing an important class of these systems. 
One of the primary reasons LTI systems are amenable to · analysis is that any such 
system possesses the superposition property described in Section 1.6,6. As a consequence, 
if we can represent the input to an LTI system in terms of a linear combination of a set of 
basic signals, we can then use superposition to compute the output of the system in terms 
of its responses to these basic signals. 
As we will see in the following sections, one of the important characteristics of the 
unit impulse, both in discrete time and in continuous time, is that very general signals 
can be represented as linear combinations of delayed impulses. This fact, together with 
the properties of superposition and time invariance, will allow us to develop a complete 
characterization of any LTI system in terms of its response to a unit impulse. Such a 
representation, referred to as the convolution sum in the discrete-time case and the convo-
lution integral in continuous time, provides considerable analytical convenience in dealing 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
75 
with LTI systems. Following our development of the convolution sum and the convolution 
integral we use these characterizations to examine some of the other properties of LTI sys-
tems. We then consider the class of continuous-time systems described by linear constant-
coefficient differential equations and its discrete-time counterpart, the class of systems 
described by linear constant-coefficient difference equations. We will return to examine 
these two very important classes of systems on a number of occasions in subsequent chap-
ters. Finally, we will take another look at the continuous-time· unit impulse function and 
a number of other signals that are closely related to it in order to provide some additional 
insight into these idealized signals and, in particular, to their use and interpretation in the 
context of analyzing LTI systems. 
2.1 DISCRETE-TIME LTI SYSTEMS: THE CONVOLUTION SUM 
2.1.1 The· Representation of Discrete-Time Signals in Terms 
of Impulses 
The key idea in visualizing how the discrete-time unit impulse can be used to construct 
any discrete-time signal is to think of a discrete-time signal as a sequence of individual im-
pulses. To see how this intuitive picture can be turned into a mathematical representation, 
consider the signal x[n] depicted in Figure 2.1(a). In the remaining parts of this figure, 
we have depicted five time-shifted, scaled unit impulse sequences, where the scaling on 
each impulse equals the value of x[n] at the particular instant the unit sample occurs. For 
example, 
x[ - 1]5[n + 1] = { x[ - 1], 
0, 
x[O]S[n] = { x[O], 
0, 
x[1]5[n - 1] = { x[l], 
0, 
n = -1 
n ~ -1' 
n = O 
n ~ 0' 
n = 1 
n ~ 1 · 
Therefore, the sum of the five-sequences in the figure equals x[ n] for - 2 :s n :s 2. More 
generally, by including additional shifted, scaled impulses, we can write 
x[n] = ... + x[ -3]5[n + 3] + x[ - 2]5[n + 2] + x[ -1]5[n + 1] + x[O]S[n] 
+ x[1]5[n- 1] + x[2]5[n- 2] + x[3]5[n- 3] + .... 
(2.1) 
For any value of n, only one of the terms on the right -hand side of eq. (2.1) is nonzero, and 
the scaling associated with that term is precisely x[n]. Writing this summation in a more 
compact form, we have 
+oo 
x[n] = L, x[k]S[n - k]. 
(2.2) 
k = - 00 
This corresponds to the representation of an arbitrary sequence as a linear combination of 
shifted unit impulses S[n - k], where the weights in this linear combination are x[k]. As 
an example, consider x[n] = u[n], the unit step. In this case, since u[k] = 0 for k < 0 

76 
Linear Time-Invariant Systems 
Chap. 2 
x[n) 
n 
(a) 
I 
x[- 2) 8[n + 2) 
... • • 
• • • • • • 
- 4 - 3 - 2 - 1 0 1 2 3 4 
n 
(b) 
x[- 1) 8(n + 1) 
- 1 
• • • I 
• • • • • 
- 4- 3 - 2 
0 1 2 3 4 
n 
(c) 
I 
x[O) Il[n] 
• • • • 
• • • • 
-4-3 - 2 - 1 0 1 2 3 4 
n 
(d) 
x[1) 8[n- 1] 
• • • • • I • • • 
-4-3 - 2-1 0 1 2 3 4 
n 
(e) 
x[2) 8(n- 2) 
2 
• • • • • • I 
• • 
- 4 - 3 - 2 - 1 0 1 
3 4 
n 
Figure 2. I 
Decomposition of a. 
(f) 
discrete-time signal into a weighted 
sum of shifted impulses. 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
17 
and u[k] = 1 fork ~ 0, eq. (2.2) becomes 
+oo 
u[n] = L o[n -
k], 
k=O 
which is identical to the expression we derived in Section 1.4. [See eq. (1.67).] 
Equation (2.2) is called the sifting property of the discrete-time unit impulse. Be-
cause the sequence o[n- k] is nonzero only when k = n, the summation on the right-
hand side of eq. (2.2) "sifts" through the sequence of values x[k] and preserves only the 
value corresponding to k = n. In the next subsection, we will exploit this representa-
tion of discrete-time signals in order to develop the convolution -sum representation for a 
discrete-time LTI system. 
2.1.2 The Discrete-Time Unit Impulse Response and the Convolution-
Sum Representation of LTI Systems 
The importance of the sifting property of eqs. (2.1) and (2.2) lies in the fact that it repre-
sents x[ n] as a superposition of scaled versions of a very simple set of elementary functions, 
namely, shifted unit impulses o[n- k], each of which is nonzero (with value 1) at a single 
point in time specified by the corresponding value of k. The response of a linear system 
to x[n] will be the superposition of the. scaled responses of the system to each of these 
shifted impulses. Moreover, the property of time in variance tells us that the responses of a 
time-invariant system to the time-shifted unit impulses are simply time-shifted versions of 
one another. The convolution -sum representation for discrete-time systems that are both 
linear and time invariant results from putting these two basic facts together. 
More specifically, consider the response of alinear (but possibly time-varying) sys-
tem to an arbitrary input x[n]. We can represent the input through eq. (2.2) as a linear 
combination of shifted unit impulses. Let hk[n] denote the response of the linear system 
to the shifted unit impulse o [ n - k]. Then, from the superposition property for a linear 
system [eqs. (1.123) and (1.124)], the response y[n] of the linear system to the input x[n] 
in eq. (2.2) is simply the weighted linear combination of these basic responses. That is, 
with the input x[n] to a linear system expressed in the form ofeq. (2.2), the output y[n] 
can be expressed as 
+ oo 
y[n] = L x[k]hk[n]. 
(2.3) 
k= -00 
Thus, according to eq. (2.3), if we know the response of a linear system to the set of 
shifted unit impulses, we can construct the response to an arbitrary input. An interpreta-
tion of eq. (2.3) is illustrated in Figure 2.2. The signal x[n] is applied as the input to a 
linear system whose responses h- t[n], ho[n], and ht[n] to the signals o[n + 1], o[n], and 
o[n - 1], respectively, are depicted in Figure 2.2(b). Since x[n] can be written as a linear 
combination of o[n + 1], o[n], and o[n - 1], superposition allows us to write the response 
to x[n] as a linear combination of the responses to the individual shifted impulses. The 
individual shifted and scaled impulses that constitute x[n] are illustrated on the left-hand 
side of Figure 2.2( c), while the responses to these component signals are pictured on the · 
right-hand side. In Figure 2.2(d) we have depicted the actual input x[n], which is the sum 
of the components on the left side of Figure 2.2(c) and the actual output y[n], which, by 

78 
Linear Time-Invariant Systems 
x[n] 
- 1 
n 
(a) 
h0 [n] 
n 
n 
(b) 
Figure 2.2 
Graphical interpretation of the response of a discrete-time linear 
system as expressed in eq. (2.3). 
Chap.2 
n 
superposition, is the sum of the components on the right side of Figure 2.2(c). Thus, the 
response at time n of a linear system is simply the superposition of the responses due to 
the input value at each point in time. 
In general, of course, the responses hk[n] need not be related to each other for differ-
ent values of k. However, if the linear system is also time invariant, then these responses 
to time-shifted unit impulses are all time-shifted versions of each other. Specifically, since 
5[n- k] is a time-shifted version of 5[n], the response hk[n] is a time-shifted version of 
ho[n]; i.e., 
hk[n] = ho[n -
k]. 
(2.4) 
For notational convenience, we will drop the subscript on ho[n] and define the unit impulse 
(sample) response 
h[n] = ho[n]. 
(2.5) 
That is, h[ n] is the output of the LTI system when 5 [ n] is the input. Then for an LTI system, 
eq. (2.3) becomes 
+oo 
y[n] = 2, x[k]h[n- k]. 
(2.6) 
k = -
00 
This result is referred to as the convolution sum or superposition sum, and the oper-
ation on the right-hand side of eq. (2.6) is known as the convolution of the sequences x[n] 
and h[n]. We will represent the operation of convolution symbolically as 
y[n] = x[n] * h[n]. 
(2.7) 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
79 
x[-1)8[n +1) 
n 
n 
x[O)Il[n] 
x[O) h0[n) 
... t. ... 
.. tT,T,, 
lo 
0 
n 
n 
x[1)8[n-1] 
x[1) h1[n] 
.. .II... 
0 
x[n) 
n 
n 
(c) 
y[n] 
T 
n 
0 
n 
(d) 
Figure 2.2 Continued 
Note that eq. (2.6) expresses the response of an LTI system to an arbitrary input in 
terms of the system's response to the unit impulse. From this, we see that an LTI system 
is completely characterized by its response to a single signal, namely, its response to the 
unit impulse. 
The interpretation of eq. (2.6) is similar to the one we gave for eq. (2.3), where, in the 
case of an LTI system, the response due to the input x[k] applied at time k is x[k]h[n- k]; 
i.e., it is a shifted and scaled version (an "echo") of h[n]. As before, the actual output is 
the superposition of all these responses. 

80 
Linear Time-Invariant Systems 
Chap. 2 
Example 2.1 
Consider an LTI system with impulse response h[n] and input x[n], as illustrated in 
Figure 2.3(a). For this case, since only x[O] and x[l] are nonzero, eq. (2.6) simplifies to 
the expression 
y[n] = x[O]h[n - 0] + x[l]h[n - 1] = O:Sh[n] + 2h[n - 1]. 
(2.8) 
The sequences 0.5h[n] and 2h[n - 1] are the two echoes of the impulse response needed 
for the superposition involved in generating y[n]. These echoes are displayed in Fig-
ure 2.3(b). By summing the two echoes for each value of n, we obtain y[n], which is 
shown in Figure 2.3(c). 
h[n] 
• • 
11 J J • • 
0 
2 
n 
'J 
x[n] 
0.5 
• • T 
• • • 
0 
n 
(a) 
0.5 
0.5h[n] 
• • T T T • • 
0 
2 
n 
'I I I 
2h[n- 1) 
• • • 
• 
0 
2 
3 
n 
(b) 
,,I I r 
y[n] 
• 
o.5t 
• 
• 
0 
2 
3 
n 
(c) 
Figure 2.3 
(a) The impulse response h[n] of an LTI system and an input 
x[n] to the system; (b) the responses or "echoes," 0.5h[n] and 2h[n - 1], to 
the nonzero values of the input, namely, x[O] = 0.5 and x[1] = 2; (c) the 
overall response y[n] , which is the sum of the echos in (b). 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
81 
By considering the effect of the superposition sum on each individual output sample, 
we obtain another very useful way to visualize the calculation of y[ n] using the convolution 
sum. In particular, consider the evaluation of the output value at some specific time n. A 
particularly convenient way of displaying this calculation graphically begins with the two 
signals x[k] and h[n - k] viewed as functions of k. Multiplying these two functions, we 
obtain a sequence g[k] = x[k]h[n - k], which, at each time k, is seen to represent the 
contribution of x[k] to the output at time n. We conclude that summing all the samples 
in the sequence of g[k] yields the output value at the selected time n. Thus, to calculate 
y[n] for all values of n requires repeating this procedure for each value of n. Fortunately, 
changing the value of n has a very simple graphical interpretation for the two signals x[k] 
and h[n - k], viewed as functions of k. The following examples illustrate this and the use 
of the aforementioned viewpoint in evaluating convolution sums. 
Example 2.2 
Let us consider again the convolution problem encountered in Example 2.1. The se-
quence x[k] is shown in Figure 2.4(a), while the sequence h[n - k], for n fixed and 
viewed as a function of k, is shown in Figure 2.4(b) for several different values of n. In 
sketching these sequences, we have used the fact that h[n - k] (viewedas a function of 
k with n fixed) is a time-reversed and shifted version of the impulse response h[k]. In 
particular, as k increases, the argument n- k decreases, explaining the need to perform a 
time reversal of h[k]. Knowing this, then in order to sketch the signal h[n- k], we need 
only determine its value for some particular value of k. For example, the argument n - k 
will equal 0 at the value k = n. Thus, if we sketch the signal h[- k], we can obtain the 
signal h[n - k] simply by shifting to the right (by n) if n is positive or to the left if n is 
negative. The result for our example for values of n < 0, n = 0, 1, 2, 3, and n > 3 are 
shown in Figure 2.4(b). 
Having sketched x[k] and h[n - k] for any particular value of n, we multiply 
these two signals and sum over all values of k. For our example, for n < 0, we see from 
Figure 2.4 that x[k]h[n- k] = 0 for all k, since the nonzero values of x[k] and h[n- k] 
do not overlap. Consequently, y[n] = 0 for n < 0. For n = 0, since the product of the 
sequence x[k] with the sequence h[O - k] has only one nonzero sample with the value 
0.5, we conclude that 
"' 
y[O] = L x[k]h[O - k] = 0.5. 
(2.9) 
k= - 0> 
The product of the sequence x[k] with the sequence h[1 - k] has two nonzero samples, 
which may be summed to obtain 
"' 
y[1] = L x[k]h[1 - k] = 0.5 + 2.0 = 2.5. 
(2.10) 
k= - 0> 
Similarly, 
"' 
y[2] = L x[k]h[2 - k] = 0.5 + 2.0 = 2.5, 
(2.11) 
k= - 0> 
and 

82 
Linear Time-Invariant Systems 
Chap. 2 
J J f 
n- 2 n-1 
n 
• 
0.5, . -
0 
21 
• • 
(a) 
• • • • 
0 
J J • • • 
- 2 - 1 
0 
• • 
- 1 
0 
• 
• 
0 
2 
• • 
0 
2 
3 
• • • • 
0 
(b) 
x[k] 
• 
k 
h[n-k], n< O 
k 
h(O-k] 
k 
h[1-k] 
k 
h[2- k] 
k 
h[3- k] 
k 
h[n-k], n> 3 
I I I 
n- 2 n-1 
n 
k 
Figure 2.4 
Interpretation of eq. (2.6) for the signals h[n) and x[n) in Fig-
ure 2.3; (a) the signal x[k) and (b) the signal h[n - k) (as a function of k 
with n fixed) for several values of n (n < 0; n = 0, 1, 2, 3; n > 3). Each 
of these signals is obtained by reflection and shifting of the unit impulse re-
sponse h[k). The response y[n) for each value of n is obtained by multiplying 
the signals x[k] and h[n - k) in (a) and (b) and then summing the products 
over all values of k. The calculation for this example is carried out in detail in 
Example 2.2. 
y[3] = I 
x[k)h[3 - k] = 2.0. 
k = _, 
(2.12) 
Finally, fot n > 3, the product x[k)h[n- k] is zero for all k, from which we conclude 
that y[n] = 0 for n > 3. The resulting output values agree with those obtained in Exam-
; __ j pie 2.1. 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
83 
Example 2.3 
Consider an input x[n] and a unit impulse response h[n] given by 
x[n] = a
11 u[n], 
h[n] = u[n], 
with 0 < a < 1. These signals are illustrated in Figure 2.5. Also, to help us in visualizing 
and calculating the convolution of the signals, in Figure 2.6 we have depicted the signal 
x [k] followed by h[- k], h[ -1- k], and h[1- k] (that is, h[n - k] for n = 0, - 1, and+ 1) 
and, finally, h[n - k] for an arbitrary positive value of n and an arbitrary negative value 
of n. From this figure, we note that for n < 0, there is no overlap between the nonzero 
points in x[k] and h[n -
k]. Thus, for n < 0, x [k]h[n -
k] = 0 for all values of k, and 
hence, from eq. (2.6), we see that y[n] = 0, n < 0. For n 2: 0, 
x[k]h[n- k] = { a k, 
0 s k .s n. 
0, 
otherwtse 
>1•1 = •"•1•1 t 
........... _IIIIIIIIIttrrrrrrr 
0 
(a) 
0 
(b) 
Figure 2.5 
The signals x[n] and h[n] in Example 2.3. 
Thus, for n 2: 0, 
II 
y[n] = ~a k, 
k=O 
and using the result of Problem 1.54 we can write this as 
II 
1 -a"+ I 
y[n] = ~ 
a k = ---:---
k=O 
1 -
Cl' 
for n 2: 0. 
Thus, for all n, 
(
l 
a"+
1
) 
y [n] = 
1 _a 
u[n]. 
The signal y [n] is sketched in Figure 2.7. 
n 
n 
(2.13) 

84 
Linear Time-Invariant Systems 
Chap. 2 
t 
x[k] = <lu[k] 
. 
........... JIIIIIItrrnrrurr 
000 
0 
k 
(a) 
. t 
h[-k] 
.. 
0 IIIIIIIIIIL ................... 
0 
0 
k 
(b) , 
j 
h[- 1- k] 
.. 
0 III III III II .. .. .. .. . .. . .. .. .. .. 
0 
-1 0 
k 
(c) 
t 
h[1 - k] 
OoO IIliiiiiiiLI ................. OoO 
0 1 
k 
(d) 
.. 
0 III II III III liii II[~·~ ...... ::" .. 
0 
• 
0 
n 
k 
(e) 
j 
h[n - k] 
0 
.. III lii..... . ............... :~" .. 
0 
· 
n 
0 
k 
(f) 
Figure 2.6 
Graphical interpretation of the calculation of the convolution 
sum for Example 2.3. 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
85 
y[n) = (1 -u" + 1) u[n] 
1-u 
1- u 
0 
n 
Figure 2.7 
Output for Example 2.3. 
The operation of convolution is sometimes described in terms of "sliding" the se-
quence h[n - k] past x[k]. For example, suppose we have evaluated y[n] for some partic-
ular value of n, say, n = no. That is, we have sketched the signal h[n0 - k], multiplied it 
by the signal x[k], and summed the result over all values of k. To evaluate y[n] at the next 
value of n-i.e., n = n0 + 1-we need to sketch the signal h[(no + 1) - k]. However, we 
can do this simply by taking the signal h[n0 -
k] and shifting it to the right by one point. 
For each successive value of n, we continue this process of shifting h[n- k] to the right 
by one point, multiplying by x[k], and summing the result over k. 
Example 2.4 
As a further example, consider the two sequences 
[ ] 
{ 
1, 
0 :5 n :5 4 
x n = 
0, 
otherwise 
and 
h[n] = { o:", , 0 :5 n. :5 6. 
, 0, 
otherwise 
These signals are depicted in Figure 2.8 for a positive value of a > 1. In order to calculate 
the convolution of the two signals, it is convenient to consider five separate intervals for 
n. This is illustrated in Figure 2.9. 
Interval I. For n < 0, there is no overlap between the nonzero portions of x[k] and 
h[n- k], and consequently, y[n] = 0. 
Interval 2. For 0 :5 n :5 4, 
x[k]h[n- k] = { o:"- k, 
0, 
O:Sk :S n 
otherwise 

86 
Linear Time-Invariant Systems 
- 2 - 1 
- 2 - 1 
012345 
(a) 
01234567 
(b) 
Figure 2.8 
The signals to be convolved in Example 2.4. 
Thus, in this interval, 
II 
y[n] = 2.:: a"- k. 
k=O 
x[n] 
n 
h[n] 
n 
Chap. 2 
(2.14) 
We can evaluate this sum using the finite sum formula, eq. (2.13). Specifically, changing 
the variable of summation in eq. (2.14) from k tor = n- k, we obtain 
" 
1- a"+l 
y[n] = 2.:: ar = ---,----
r=O 
1 - a 
Interval3. For n > 4 but n - 6 ~ 0 (i.e., 4 < n ~ 6), 
x [k]h[n - k] = { a"- k, 
0 ~ k.~ 4. 
0, 
otherwise 
Thus, in this interval, 
4 
y[n] = 2.:: a"- k. 
k=O 
(2.15) 
Once again, we can use the geometric sum formula in eq. (2.13) to evaluate eq. (2.15). 
Specifically, factoring out the constant factor of a" from the summation in eq. (2.15) 
yields 
4 
1 
( - 1)5 
11- 4 
11+1 
[ ] 
"2.::( - I )k 
11 
-
a 
a 
- a 
yn =a 
a 
=a 
= 
1- a - 1 
1 - a 
k=O 
Interval4. 
For n > 6 but n - 6 ~ 4 (i.e., for 6 < n ~ 10), 
x [k]h[n - k] = { a"-k, 
(n - 6). ~ k ~ 4 ' 
0, 
otherwise 
(2.16) 

. rl 
.......... 1111 ............. . 
0 
4 
k 
(a) 
l 
1 
h[n- k) 
n < 
0 
• llltrr •• ••••••••.••••••••. 
n 
0 
k 
n- 6 
(b) 
~ h]o- k] 
...... flit tr •••••••••••••••• 
0 
n 
k 
n- 6 
(c) 
t 
h[n- k) 
r 
4 < n ~ 6 
.........Irrrr ............ . 
f 0 
n 
k 
n- 6 
(d) 
1 
h[n- k] 
I 
6 < n ~ 10 
••••••••••. flltrr ••••.••••• 
~ 
0 
n 
k 
n- 6 
(e) 
1
h[n- k) I 
n> 10 
••••••••.••.••.•. llttrr •••• 
0 
n-6 
n 
k 
(f) 
Figure 2. 9 
Graphical interpretation of the convolution performed in 
Example 2.4. 
87 

88 
so that 
y[n] = 
4 
:2: 
Linear Time-Invariant Systems 
n- k 
a 
. 
k=n- 6 
Chap.2 
We can again use eq. (2.13) to evaluate this summation. Letting r = k- n + 6, we obtain 
Interval 5. For n - 6 > 4, or equivalently, n > 10, there is no overlap between the 
nonzero portions of x[k] and h[n- k], and hence, 
Summarizing, then, we obtain 
y[n] = 
which is pictured in Figure 2.10. 
y[n] = 0. 
0, 
1- a"+ 1 
1- a 
' 
n<O 
a"-4- an+l 
--:----, 4 < n ::56 , 
1-a 
a"- 4 -a7 
1- a 
' 
0, 
0 
6<n::510 
10 < n 
10 
y[n] 
n 
Figure 2.1 o Result of performing the convolution in Example 2.4. 
Example 2.5 
Consider an LTI system with input x[n] and unit impulse response h[n] specified as 
follows: 
x[n] = 2"u[ -n], 
h[n] = u[n]. 
(2.17) 
(2.18) 

Sec. 2.1 
Discrete-Time LTI Systems: The Convolution Sum 
89 
1 
1 I 
x[k) = 2ku[-k) 
1 
2 
1 
1 
4 I 
16 
8 
• I 
t 
• • • • 
-2 - 1 
0 
k 
I I r I I I 
h[n-k) 
• • • 
n 
k 
(a) 
2 
y[n) 
1 
1 
2 
1 
1 
l 
16 8 
4 
... t 
t ' 
- 3 - 2 - 1 
0 
2 
3 
n 
(b) 
Figure 2.11 
(a) The sequences x[k] and h[n- k] for the convolution prob-
lem considered in Example 2.5; (b) the resulting output signal y[n]. 
The sequences x[k] and h[n - k] are plotted as functions of kin Figure 2.11(a). Note that 
x[k] is zero fork > 0 and h[n - k] is zero fork > n. We also observe that, regardless of 
the value of n, the sequence x[k]h[n - k] always has nonzero samples along the k-axis. 
When n ~ 0, x [k]h[n - k] has nonzero samples in the interval k :5 0. It follows that, 
for n ~ 0, 
0 
0 
y [n] = L, x[k]h[n - k] = L, 2k. 
(2.19) 
k = - CO 
k = - 00 
To evaluate the infinite sum in eq. (2.19), we may use the infinite sum formula, 
(2.20) 
Changing the variable of summation in eq. (2.19) from k to r = - k, we obtain 
1 
1 - (1/2) = 2· 
(2.21) 
Thus, y[n] takes on a constant value of 2 for n ~ 0. 

90 
' 
Linear Time-Invariant Systems 
Chap. 2 
When n < 0, x[k]h[n -
k] has nonzero samples for k ::::; n. It follows that, for 
n < 0, 
n 
n 
y[n] = L x[k]h[n- k] = L 2k. 
(2.22) 
k =-00 
k= -00 
By performing a change of variable l = - k and then m = l + n, we can again make 
use of the infinite sum formula, eq. (2.20), to evaluate the sum in eq. (2.22). The result 
is the following for n < 0: 
-
00 (1)1 -
00 (1)"'-"- (1)-n 
00 (1)m 
y[n] - .2.: 2 - .2.: 2 
- 2 .2.: 2 
= 2". 2 = 2"+'. 
l = - n 
m =O 
m=O 
(2.23) 
The complete sequence of y[n] is sketched in Figure 2.ll(b). 
These examples illustrate the usefulness of visualizing the calculation of the con-
volution sum graphically. Moreover, in addition to providing a useful way in which to 
calculate the response of an LTI system, the convolution sum also provides an extremely 
useful representation for LTI systems that allows us to examine their properties in great 
detail. In particular, in Section 2.3 we will describe some of the properties of convolution 
and will also examine some of the system properties introduced in the previous chapter in 
order to see how these properties can be characterized for LTI systems. 
2.2 CONTINUOUS-TIME LTI SYSTEMS: THE CONVOLUTION INTEGRAL 
In analogy with the results derived and discussed in the preceding section, the goal of this 
section is to obtain a complete characterization of a continuous-time LTI system in terms 
of its unit impulse response. In discrete time, the key to our developing the convolution 
sum was the sifting property of the discrete-time unit impulse-
that is, the mathematical 
representation of a signal as the superposition of scaled and shifted unit impulse functions. 
Intuitively, then, we can think of the discrete-time system as responding to a sequence of 
individual impulses. In continuous time, of course, we do not have a discrete sequence of 
input values. Nevertheless, as we discussed in Section 1.4.2, if we think of the unit im-
pulse as the idealization of a pulse which is so short that its duration is inconsequential for 
any real, physical system, we can develop a representation for arbitrary continuous-time 
signals in terms of these idealized pulses with vanishingly small duration, or equivalently, 
impulses. This representation is developed in the next subsection, and, following that, we 
will proceed very much as in Section 2.1 to develop the convolution integral representation 
for continuous-time LTI systems. 
2.2.1 The Representation of Continuous-Time Signals in Terms 
of Impulses 
To develop the continuous-time counterpart of the discrete-time sifting property in 
eq. (2.2), we begin by considering a pulse or "staircase" approximation, x(t), to a 
continuous-time signal x(t), as illustrated in Figure 2.12(a). In a manner similar to that 

Sec. 2.2 
Continuous-Time LTI Systems: The Convolution Integral 
91 
x(t) 
-~ 0 ~ 2~ 
(a) 
x(-2~)8d(t + 2~)~ 
<HAlo j 
- 21l - ll 
(b) 
x( - ~)8d(t + ~)~ 
<(-A)d 
-~ 0 
(c) 
x(0)8d(t)~ 
0'(0) 
0 ~ 
(d) 
x(~)8 d (t - ~)~ 
x(~) 
(e) 
k~ 
Figure 2.12 
Staircase approxima-
tion to a continuous-time signal. 

92 
Linear Time-Invariant Systems 
Chap. 2 
employed in the discrete-time case, this approximation can be expressed as a linear com-
bination of delayed pulses, as illustrated in Figure 2.12(a)-(e). If we define 
(h(t) = ( ~, o ::s r < a, 
0, 
otherwise 
then, since /l51l(t) has unit amplitude, we have the expression 
00 
x<r) = L x<ka)sll<r - ka)a. 
k = -00 
(2.24) 
(2.25) 
From Figure 2.12, we see that, as in the discrete-tim~ ·case [eq. (2.2)], for any value oft, 
only one term in the summation on the right-hand side of eq. (2.25) is nonzero. 
As we let ll approach 0, the approximation .X(t) becomes better and better, and in the 
limit equals x(t). Therefore, 
+oo 
x(t) = lim L x(kll)51l(t- kll)ll. 
ll --->0 k = -oo 
(2.26) 
Also, as ll -
0, the summation in eq. (2.26) approaches an integral. This can be seen by 
considering the graphical interpretation of the equation, illustrated in Figure 2.13. Here, 
we have illustrated the signals x(T), 51l(t- T), and their product. We have also indicated 
a shaded region whose area approaches the area under x(T)51l(t- T) as ll -
0. Note that 
the shaded region has an area equal to x(mll) where t - ll < mil < t. Furthermore, for 
this value oft, only the term with k = m is nonzero in the summation in eq. (2.26), and 
thus, the right-hand side of this equation also equals x(m/l). Consequently, it follows from 
eq. (2.126) and from the preceding argument that x(t) equals the limit as ll -
0 of the area 
under x(T)51l(t- T). Moreover, from eq. (1.74), we know that the limit as ll -
0 of 51l(t) 
is the unit impulse function 5(t). Consequently, 
I 
+oo 
X(t) = - oo X(T)5(t - T)dT. 
(2.27) 
As in discrete time, we refer to eq. (2.27) as the sifting property of the continuous-time 
impulse. We note that, for the specific example of x(t) = u(t), eq. (2.27) becomes 
I 
+oo 
J oo 
U(t) = 
U(T)5(t- T)dT = 
, 5(t - T)dT, 
- oo 
0 
(2.28) 
since u( T) = 0 forT < 0 and u( T) = 1 for T > 0. Equation (2.28) is identical to eq. ( 1. 7 5), 
derived in Section 1.4.2. 
Once again, eq. (2.27) should be viewed as an idealization in the sense that, for 
ll "small enough," the approximation of x(t) in eq. (2.25) is essentially exact for any 
practical purpose. Equation (2.27) then simply represents an idealization of eq. (2.25) by 
taking ll to be vanishingly small. Note also that we could have derived eq. (2.27) directly 
by using several of the basic properties of the unit impulse that we derived in Section 1.4.2. 

Sec. 2.2 
Continuous-Time LTI Systems: The Convolution Integral 
93 
X('T) 
(a) 
&A(t- T) 
m~ 
t -
~ 
. (b) 
t- ~ 
1-~-1 
(c) 
1 
X 
'T 
'T 
. 1 
~ 
'T 
Figure 2.13 
Graphical interpreta-
tion of eq. (2.26). 
Specifically, as illustrated in Figure 2.14(b), the signal o(t- r) (viewed as a function of 
T with t fixed) is a unit impulse located at T = t. Thus, as shown in Figure 2.14(c), the 
signal x(r)o(t- r) (once again viewed as a function of r) equals x(t)o(t - r) [i.e., it is a 
scaled impulse at T = t with an area equal to the value of x(t)]. Consequently, the integral 
of this signal from T = -co to T = + co equals x(t); that is, 
I 
+ co 
I 
+ co 
I 
+ co 
-co X(T)O(t- T)dT = 
- co x(t)o(t- T)dT = x(t) -co O(t - T)dT = x(t). 
Although this derivation follows directly from Section 1.4.2, we have included the deriva- . 
tion given in eqs. (2.24)-(2.27) to stress the similarities with the discrete-time case and, 
in particular, to emphasize the interpretation of eq. (2.27) as representing the signal x(t) 
as a "sum" (more precisely, an integral) of weighted, shifted impulses. 

94 
x(-r) 
(a) 
8(t- -r) 
(b) 
x(-r)8(t--r) = x(t)8(t--r) 
(c) 
x(t) 
T 
Linear Time-Invariant Systems 
Chap.2 
Figure 2.14 
(a) Arbitrary signal 
x(T); (b) impulse S(t - T) as a function 
-r 
of T with t fixed; (c) product of these 
two signals. 
2.2.2 The Continuous-Time Unit Impulse Response and the 
Convolution Integral Representation of LTI Systems 
As in the discrete-time case, the representation developed in the preceding section provides 
us with a way in which to view an arbitrary continuous-time signal as the superposition of 
scaled and shifted pulses. In particular, the approximate representation in eq. (2.25) repre-
sents the signal.X(t) as a sum of scaled and shifted versions of the basic pulse signal oa(t). 
Consequently, the response y(t) of a linear system to this signal will be the superposition 
of the responses to the scaled and shifted versions of oa(t). Specifically, let us define hktl(t) 
as the response of an LTI system to the input Sa(t- kll). Then, from eq. (2.25) and the 
superposition property, for continuous-time linear systems, we see that 
+ oo 
y(t) = L x(kll)hktl(t)ll. 
(2.29) 
k = - oo 
The interpretation of eq. (2.29) is similar to that for eq. (2.3) in discrete time. In 
particular, consider Figure 2.15, which is the continuous-time counterpart of Figure 2.2. In 

Sec. 2.2 
x(O) 
08 
x(8) 
x(k8) 
k8 
Q(t) 
0 
x(t) 
0 
Continuous-Time LTI Systems: The Convolution Integral 
95 
08 
(a) 
(b) 
(c) 
(d) 
0 
(e) 
0 
(f) 
1\ 
x(O)h0(t)8 
1\ 
x(k8)hkll(t)8 
(V-
y(t) 
y(t) 
Figure 2.15 
Graphical interpreta-
tion of the response of a continuous-
time linear system as expressed in 
eqs. (2.29) and (2.30). 

96 
Linear Time-Invariant Systems 
Chap. 2 
Figure 2.15(a) we have depicted the input x(t) and its approximation x(t), while in Figure 
2.15(b )- (d), we have shown the responses of the system to three of the weighted pulses in 
the expression for x(t). Then the output y(t) corresponding to x(t) is the superposition of 
all of these responses, as indicated in Figure 2.15(e). 
What remains, then, is to consider what happens as a becomes vanishingly small-
i.e., as a ~ 0. In particular, with x(t) as expressed in eq. (2.26), x(t) becomes an increas-
ingly good approximation to x(t), and in fact, the two coincide as a ~ 0. Consequently, 
the response to x(t), namely, y(t) in eq. (2.29), must converge to y(t), the response to 
the actual input x(t), as illustrated in Figure 2.15(f). Furthermore, as we have said, for a 
"small enough," the duration of the pulse Sj,(l - ka) is of no significance, in that, as far as 
the system is concerned, the response to this pulse is essentially the same as the response 
to a unit impulse at the same point in time. That is, since the pulse 8t:,.(t- ka) corresponds 
to a shifted unit impulse as a ~ 0, the response hu.(t) to this input pulse becomes the 
response to an impulse in the limit. Therefore, if we let h1'(t) denote the response at time t 
to a unit impulse S(t - T) located at timeT, then 
(2.30) 
As a ~ 0, the summation on the right-hand side becomes an integral, as can be seen 
graphically in Figure 2.16. Specifically, in Figure 2.16 the shaded rectangle represents one 
term in the summation on the right-hand side of eq. (2.30) and as a ~ 0 the summation 
approaches the area under x(T)h1'(t) viewed as a function ofT. Therefore, 
(2.31) 
The interpretation of eq. (2.31) is analogous to the one for eq. (2.29). As we showed 
in Section 2.2.1, any input x(t) can be represented as 
Shaded area = x(k!l.)hk.l(t)A 
k!l. 
(k+ 1)a 
Figure 2.16 
Graphical illustration 
of eqs. (2.30) and (2.31 ). 

Sec. 2.2 
Continuous-Time LTI Systems: The Convolution Integral 
97 
That is, we can intuitively think of x(t) as a "sum" of weighted shifted impulses, where 
the weight on the impulse o(t- r) is x( r)dr. With this interpretation, eq. (2.31) represents 
the superposition of the responses to each of these inputs, and by linearity, the weight 
on the response h1'(t) to the shifted impulse o(t- r) is also x(r)dr. · 
Equation (2.31) represents the general form of the response of a linear system in 
continuous time. If, in addition to being linear, the system is also time invariant, then 
h1'(t) = h0(t- r); i.e., the response of an LTI system to the unit impulse o(t - r), which 
is shifted by r seconds from the origin, is a similarly shifted version of the response to the 
unit impulse function o(t). Again, for notational convenience, we will drop the subscript 
and define the unit impulse response h(t) as 
h(t) = h0(t); 
(2.32) 
i.e., h(t) is the response to o(t). In this case, eq. (2.31)becomes 
I 
+oo 
y(t) = 
-oo x(r)h(t- r)dr. 
(2.33) 
Equation (2.33), referred to as the convolution integral or the superposition integral, 
is the continuous-time counterpart of the convolution sum of eq. (2.6) and corresponds 
to the representation of a continuous-time LTI system in terms of its response to a unit 
impulse. The convolution of two signals x(t) and h(t) will be represented symbolically as 
y(t) = x(t) * h(t). 
(2.34) 
While we have chosen to use the same symbol * to denote both discrete-time and 
continuous-time convolution, the context will generally be sufficient to distinguish the 
two cases. 
As in discrete time, we see that a continuous-time LTI system is completely char-
acterized by its impulse response-i.e., by its response to a.single elementary signal, the 
unit impulse o(t). In the next section, we explore the implications of this as we examine 
a number of the properties of convolution and of LTI systems in both continuous time and 
discrete time. 
The procedure for evaluating the convolution integral is quite similar to that for its 
discrete-time counterpart, the convolution sum. Specifically, in eq. (2.33) we see that, for 
any value of t, the output y(t) is a weighted integral of the input, where the weight on 
x( r) is h(t - r). To evaluate this integral for a specific value oft, we first obtain the signal 
h(t- r) (regarded as a function of r with t fixed) from h( r) by a reflection about the origin 
and a shift to the right by tift > 0 or a shift to the left by ltl for t < 0. We next multiply 
together the signals x(r) and h(t - r), and y(t) is obtained by integrating the resulting 
product from r = - oo to r = +oo. To illustrate the evaluation of the convolution integral, 
let us consider several examples. 

98 
Linear Time-Invariant Systems 
Chap. 2 
Example 2.6 
Let x(t) be the input to an LTI system with unit impulse response h(t), where 
x(t) = e-at u(t), 
a > 0 
and 
h(t) = u(t). 
In Figure 2.17, we have depicted the functions h(r), x(r), and h(t - r) for a negative 
value oft and for a positive value oft. From this figure, we see that fort < 0, the product 
of x(r) and h(t - r) is zero, and consequently, y(t) is zero. Fort > 0, 
{ 
e - aT, 
0 < T < t 
x(r)h(t- r) = 
0 
h 
. 
. 
, 
ot erw1se 
h(T) 
0 
'I' 
x(T) 'I'--
0 
'I' 
h(t- T) 
I 'I 
t < O 
0 
'I' 
h(t- T) 
I 
t > O 
0 
'I' 
Figure 2.17 
Calculation of the convolution integral for Example 2.6. 

Sec. 2.2 
Continuous-Time LTI Systems: The Convolution Integral 
From this expression, we can compute y(t) for t > 0: 
Thus, for all t, y(t) is 
y(t) = !o - e- a1)u(t), 
a 
which is shown in Figure 2.18. 
y(t) = 1 (1- e- 81 )u(t) 
a 
1 a --- ----- -- ---- --- ----
0 
Figure 2. 18 
Response of the system in Example 2.6 with impulse re-
sponse h(t) = u(t) to the input x(t) = e- at u(t). 
99 
Example 2.7 
Consider the convolution of the following two signals: 
x(t) = { ~: 
h(t) = { t, 0, 
0 < t< T 
otherwise ' 
0 < t < 2T 
otherwise 
· 
As in Example 2.4 for discrete-time convolution, it is convenient to consider the evalu-
ation of y(t) in separate intervals. In Figure 2.19, we have sketched x('r) and have illus-
tratedh(t- T)ineachoftheintervalsofinterest.Fort < Oandfort > 3T, x(T)h(t-T) = 
0 for all values ofT, and consequently, y(t) = 0. 'For the other intervals, the product 
x( T)h(t- T) is as indicated in Figure 2.20. Thus, for these three intervals, the integration 
can be carried out graphically, with the result that 
!
0, 
!t2 
2 
' 
'y(t) = 
Tt -
~ T2, 
-~t
2 + Tt + ~T
2
, 
2T < t < 3T 
0, 
t<O 
0 < t < T 
T < t < 2T , 
3T < t 
which is depicted in Figure 2.21. 

x('r) 1h 
0 
T 
'T 
h(t-T) 
~t 
t < O 
I 
t 0 
t- 2T 
h(t- -r) 
N: 
0< t < T 
I 
0 t 
T 
t- 2T 
h(t-T) 
rK 
T < t < 2T 
I o 
t 
t- 2T 
h(t- 'T) 
2TJ~ 
2T < t < 3T 
0 \ 
'T 
t- 2T 
h(t- 'T) 
2Ti ~ 
t > 3T 
0 
I 
'T 
t - 2T 
Figure 2.19 
Signals x( T) and h(t- T) for different values of t for 
Example 2.7. 
100 

Sec. 2.2 
Continuous-Time LTI Systems: The Convolution Integral 
O< t < T 
0 
t 
(a) 
T < t < 2T 
0 
T 
'T 
(b) 
2T < t < 3T 
t T 
'T 
t-2T 
(c) 
Figure 2.20 
Product x( r)h(t- r) for Example 2.7 for the three ranges of 
values of t for which this product is not identically zero. (See Figure 2.19.) 
y(t) 
0 
T 
2T 
3T 
Figure 2.21 
Signal y(t) = x(t) * h(t) for Example 2.7. 
101 
Example 2.8 
Let y(t) denote the convolution of the following two signals: 
x(t) = e2' u( -t), 
h(t) = u(t - 3). 
(2.35) 
(2.36) 
The signals x(r) and h(t - r) are plotted as functions of r in Figure 2.22(a). We first 
observe that these two signals have regions of nonzero overlap, regardless of the value 

102 
Linear Time-Invariant Systems 
Chap.2 
0 
'T 
h(t- 7) 
t- 3 
0 
(a) 
y(t) 
0 
3 
(b) 
Figure 2.22 
The convolution problem considered in Example 2.8. 
oft. When t- 3 :s:. 0, the product of x(T) and h(t- T) is nonzero for -oo < T < t- 3, 
and the convolution integral becomes 
y(t) = 
e2T dT = - e2(t- 3l. 
f
t- 3 
1 
_., 
2 
(2.37) 
Fort- 3 ;?: 0, the product x( T)h(t - T) is nonzero for -oo < T < 0, so that the convolution 
integral is 
(2.38) 
The resulting signal y(t) is plotted in Figure 2.22(b). 
As these examples and those presented in Section 2.1 illustrate, the graphical in-
terpretation of continuous-time and discrete-time convolution is of considerable value in 
visualizing the evaluation of convolution integrals and sums. 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
103 
2.3 PROPERTIES OF LINEAR TIME-INVARIANT SYSTEMS 
In the preceding two sections, we developed the extremely important representations 
of continuous-time and discrete-time LTI systems in terms of their unit impulse re-
sponses. In discrete time the representation takes the form of the convolution sum, while 
its continuous-time counterpart is the convolution integral, both of which we repeat here 
for convenience: 
+oo 
y[n] = L x[k]h[n - k] = x[n] * h[n] 
(2.39) 
k = -oo 
I 
+oo 
y(t) = 
-oo x( T)h(t - T)dT = x(t) * h(t) 
(2.40) 
As we have pointed out, one consequence of these representations is that the charac-
teristics of an LTI system are completely determined by its impulse response. It is impor-
tant to emphasize that this property holds in general only for LTI systems. In particular, as 
illustrated in the following example, the unit impulse response of a nonlinear system does 
not completely characterize the behavior of the system. 
Example 2.9 
Consider a discrete-time system with unit impulse response 
h[ ] _ { 1, 
n = 0, 1 
n -
0, 
otherwise · 
(2.41) 
If the system is LTI, then eq. (2.41) completely determines its input-output behavior. In 
particular, by substituting eq. (2.41) into the convolution sum, eq. (2.39), we find the 
following explicit equation· describing how the input and output of this LTI system are 
related: 
y[n] = x[n] + x[n - 1]. 
(2.42) 
On the other hand, there are many nonlinear systems with the same response-i.e., that 
given in eq. (2.41)-to the input o[n]. For example, both of the following systems have 
this property: 
y[n] = (x[n] + x[n - 1])2, 
y[n] = max(x[n], x[n - 1]). 
Consequently, if the system is nonlinear it is not completely characterized by the impulse 
response in eq. (2.41). 
The preceding example illustrates the fact that LTI systems have a number of prop-
erties not possessed by other systems, beginning with the very special representations that 
they have in terms of convolution sums and integrals. In the remainder of this section, we 
explore some of the most basic and important of these properties. 

104 
Linear Time-Invariant Systems 
Chap.2 
2.3.1 The Commutative Property 
A basic property of convolution in both continuous and discrete time is that it is a commu-
tative operation. That is, in discrete time 
+ oo 
x[n] * h[n] = h[n] * x[n] = L, h[k]x[n -
k], 
(2.43) 
k = -
00 
and in continuous time 
J 
+ oo 
x(t) * h(t) = h(t) * x(t) = 
-oo h( T)x(t - T)dT. 
(2.44) 
These expressions can be verified in a straightforward manner by means of a substitution 
of variables in eqs. (2.39) and (2.40). For example, in the discrete-time case, if we let 
r = n - k or, equivalently, k = n - r, eq. (2.39) becomes 
+oo 
+oo 
x[n] * h[n] = L, x[k]h[n- k] = L, x[n- r]h[r] = h[n] * x[n]. 
(2.45) 
k = - oo 
r= -oo 
With this substitution of variables, the roles of x[n] and h[n] are interchanged. According 
to eq. (2.45), the output of an LTI system with input x[n] and unit impulse response h[n] 
is identical to the output of an LTI system with input h[n] and unit impulse response x[n]. 
For example, we could have calculated the convolution in Example 2.4 by first reflecting 
and shifting x[k], then multiplying the signals x[n- k] and h[k], and finally summing the 
products for all values of k. 
Similarly, eq. (2.44) can be verified by a change of variables, and the implications of 
this result in continuous time are the same: The output of an LTI system with input x(t) and 
unit impulse response h(t) is identical to the output of an LTI system with input h(t) and 
unit impulse response x(t). Thus, we could have calculated the convolution in Example 2. 7 
by reflecting and shifting x(t), multiplying the signals x(t - T) and h(T), and integrating 
over - oo < T < + oo. In specific cases, one of the two forms for computing convolutions 
[i.e., eq. (2.39) or (2.43) in discrete time and eq. (2.40) or (2.44) in continuous time] may 
be easier to visualize, but both forms always result in the same answer. 
2.3.2 The Distributive Property 
Another basic property of convolution is the distributive property. Specifically, convolution 
distributes over addition, so that in discrete time 
x[n] * (h1 [n] + hz[n]) = x[n] * h1 [n] + x[n] * hz[n], 
(2.46) 
and in continuous time 
x(t) * [h1 (t) + hz(t)] = x(t) * h1 (t) + x(t) * hz(t). 
(2.47) 
This property can be verified in a straightforward manner. 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
h,(t) 
y,(t) 
x(t) 
~y(t) 
h2(t) 
Y2(t) 
(a) 
x(t) -
-_.. 
1----lll~ y(t) 
(b) 
105 
Figure 2.23 
Interpretation of the 
distributive property of convolution 
for a parallel interconnection of LTI 
systems. 
The distributive property has a useful interpretation in terms of system interconnec-
tions. Consider two continuous-time LTI systems in parallel, as indicated in Figure 2.23(a). 
The systems shown in the block diagram are LTI systems with the indicated unit impulse 
responses. This pictorial representation is a particularly convenient way in which to denote 
LTI systems in block diagrams, and it also reemphasizes the fact that the impulse response 
of an LTI system completely characterizes its behavior. 
The two systems, with impulse responses h1 (t) and h2(t), have identical inputs, and 
their outputs are added. Since 
and 
Y2(t) = x(t) * h2(t), 
the system of Figure 2.23(a) has output 
y(t) = x(t) * h1 (t) + x(t) * h2(t), 
(2.48) 
corresponding to the right-hand side of eq. (2.47). The system of Figure 2.23(b) has output 
y(t) = x(t) * [h, (t) + h2(t)], 
(2.49) 
corresponding to the left-hand side of eq. (2.47). Applying eq. (2.47) to eq. (2.49) and 
comparing the result with eq. (2.48), we see that the systems in Figures 2.23(a) and (b) 
are identical. 
There is an identical interpretation in discrete time, in which each of the signals 
in Figure 2.23 is replaced by a discrete-time counterpart (i.e., x(t), h 1(t), h2(t), y 1(t), 
Y2(t), and y(t) are replaced by x[n], h 1 [n], h2[n], y 1 [n], Y2 [n], and y[n], respectively). In 
summary, then, by virtue of the distributive property of convolution, a parallel combina-
tion of LTI systems can be replaced by a single LTI system whose unit impulse response 
is the sum of the individual unit impulse responses in the parallel combination. 

106 
Linear Time-Invariant Systems 
Chap.2 
Also, as a consequence of both the commutative and distributive properties, we have 
[x, [n] + x2[n]] * h[n] = XI [n] * h[n] + x2[n] * h[n] 
(2.50) 
and 
(XI (t) + X2(t)] * h(t) = XI (t) * h(t) + X2(t) * h(t), 
(2.51) 
which simply state that the response of an LTI system to the sum of two inputs must equal 
the sum of the responses to these signals individually. 
As illustrated in the next example, the distributive property of convolution can also 
be exploited to break a complicated convolution into several simpler ones. 
Example 2. 1 0 
Let y[n] denote the convolution of the following two sequences: 
x[n] = (~ ru[n] + 2"u[ -n], 
h[n] = u[n]. 
(2.52) 
(2.53) 
Note that the sequence x[n] is nonzero along the entire time axis. Direct evaluation of 
such a convolution is somewhat tedious. Instead, we may use the distributive property to 
express y[n] as the sum of the results of two simpler convolution problems. In particular, 
ifwelet x,[n] = (l/2)"u[n]andx2[n] = 2"u[-n],itfollowsthat 
y[n] = (x1 [n] + x2[n]) * h[n]. 
(2.54) 
Using the distributive property of convolution, we may rewrite eq. (2.54) as 
y[n] = y, [n] + y2[n], 
(2.55) 
where 
Yl [n] = x, [n] * h[n] 
(2.56) 
and 
y2[n] = x2[n] * h[n]. 
(2.51) 
The convolution in eq. (2.56) for y 1 [n] can be obtained from Example 2.3 (with a = 
112), while y2[n] was evaluated in Example 2.5. Their sum is y[n], which is shown in 
Figure 2.24. 
1 
1 2 
... ~ f 
y[n] 
4 - - -- -- - -- --- - - ---
3 
-3-2 -1 
0 1 2 3 4 5 6 7 
n 
Figure 2.24 
The signal y[n] = x[n] * h[n] for Example 2.10. 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
107 
2.3.3 The Associative Property 
Another important and useful property of convolution is that it is associative. That is, in 
discrete time 
(2.58) 
and in continuous time 
x(t) * [ht (t) * h2(t)] ,; [x(t) * ht (t)] * h2(t). 
(2.59) 
This property is proven by straightforward manipulations of the summations and integrals 
involved. Examples verifying it are given in Problem 2.43. 
As a consequence of the associative property, the expressions 
y[n] = x[n] * ht[n] * h2[n] 
(2.60) 
and 
y(t) = x(t) * ht (t) * h2(t) 
(2.61) 
are unambiguous. That is, according to eqs. (2.58) and (2.59), it does not matter in which 
order we convolve these signals. 
An interpretation of the associative property is illustrated for discrete-time systems 
in Figures 2.25(a) and (b). In Figure 2.25(a), 
y[n] = w[n] * h2[n] 
= (x[n] * ht [n]) * h2[n]. 
In Figure 2.25(b), 
y[n] = x[n] * h[n] 
= x[n] * (ht [n] * h2[n]). 
According to the associative property, the series interconnection of the two systems in 
Figure 2.25(a) is equivalent to the single system in Figure 2.25(b). This can be generalized 
to an arbitrary number of LTI systems in cascade, and the analogous interpretation and 
conclusion also hold in continuous time. 
By using the commutative property together with the associative property, we find 
another very important property of LTI systems. Specifically, from Figures 2.25(a) and 
(b), we can conclude that the impulse response of the cascade of two LTI systems is the 
convolution of their individual impulse responses. Since convolution is commutative, we 
can compute this convolution of h1 [n] and h2[n] in either order. Thus, Figures 2.25(b) and 
(c) are equivalent, and from the associative property, these are in tum equivalent to the 
system of Figure 2.25(d), which we note is a cascade combination of two systems as in 
Figure 2.25(a), but with the order of the cascade reversed. Consequently, the unit impulse 
response of a cascade of two LTI systems does not depend on the order in which they are 
cascaded. In fact, this holds for an arbitrary number of LTI systems in cascade: The order 
in which they are cascaded does not matter as far as the overall system impulse response 
is concerned. The same conclusions hold in continuous time as well. 

108 
x[n] 
I 
h,[,] 
w[n] I 
~ h2[n] 
(a) 
x[n] 
·I 
h[n] = h1[n]• h2[n] 
(b) 
x[n] 
·I 
h[n] = h2[n] • h1 [n] 
(c) 
l---1~~1 h,[,] 
(d) 
Linear Time-Invariant Systems 
Chap. 2 
~ y[n] 
~ y[n] 
~ y[n] 
1---1~~ y(n] 
Figure 2.25 
Associative property of 
convolution and the implication of this 
and the commutative property for the 
series interconnection of LTI systems. 
It is important to emphasize that the behavior of LTI systems in cascade-and, in 
particular, the fact that the overall system response does not depend upon the order of the 
systems in the cascade-is very special to such systems. In contrast, the order in which 
nonlinear systems are cascaded cannot be changed, in general, without changing the over-
all response. For instance, if we have two memory less systems, one being multiplication 
by 2 and the other squaring the input, then if we multiply first and square second, we obtain 
y[n] = 4x2[n]. 
However, if we multiply by 2 after squaring, we have 
y[n] = 2x2[n]. 
Thus, being able to interchange the order of systems in a cascade is a characteristic par-
ticular to LTI systems. In fact, as shown in Problem 2.51, we need both linearity and time 
invariance in order for this property to be true in general. 
2.3.4 LTI Systems w ith and without Memory 
As specified in Section 1.6.1, a system is memoryless if its output at any time depends 
only on the value of the input at that same time. From eq. (2.39), we see that the only 
way thatthis can be true for a discrete-time LTI system is if h[n] = 0 for n "# 0. In this case 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
109 
the impulse response has the form 
h[n] = K8[n], 
(2.62) 
where K = h[O] is a constant, and the convolution sum reduces to the relation 
y[n] = Kx[n]. 
(2.63) 
If a discrete-time LTI system has an impulse response h[n] that is not identically zero for 
n ~ 0, then the system has memory. An example of an LTI system with memory is the 
system given by eq. (2.42). The impulse response for this system, given in eq. (2.41), is 
nonzero for n = 1. 
From eq. (2.40), we can deduce similar properties for continuous-time LTI systems 
with and without memory. In particular, a continuous-time LTI system is memoryless if 
h(t) = 0 for t ~ 0, and such a memoryless LTI system has the form 
y(t) = Kx(t) 
(2.64) 
for some constant K and has the impulse response 
h(t) = K8(t). 
(2.65) 
Note that if K = 1 in eqs. (2.62) and (2.65), then these systems become identity 
systems, with output equal to the input and with unit impulse response equal to the unit 
impulse. In this case, the convolution sum and integral formulas imply that 
x[n] = x[n] * 8[n] 
and 
x(t) = x(t) * 8(t), 
which reduce to the sifting properties of the discrete-time and continuous-time unit im-
pulses: 
+oo 
x[n] = L x[k]8[n- k] 
k= - oo 
J 
+oo 
x(t) = 
-oo x( r)8(t - r)dr. 
2.3.5 lnvertibility of LTI Systems 
Consider a continuous-time LTI system with impulse response h(t). Based on the discus-
sion in Section 1.6.2, this system is invertible only if an inverse system exists that, when 
connected in series with the original system, produces an output equal to the input to the 
first system. Furthermore, if an LTI system is invertible, then it has an LTI inverse. (See 
Problem 2.50.) Therefore, we have the picture shown in Figure 2.26. We are given a sys-
tem with impulse response h(t). The inverse system, with impulse response h1 (t), results 
in w(t) = x(t)- such that the series interconnection in Figure 2.26(a) is identical to the 

110 
Linear Time-Invariant Systems 
Chap. 2 
~Q_____ 
x(t)----..~~ 
w(t) = x(t) 
(a) 
(b) 
Figure 2.26 
Concept of an inverse 
system for continuous-time LTI sys-
tems. The system with impulse re-
sponse hd t) is the inverse of the 
system with impulse response h(t) if 
h(t) * h1 (t) = ll(t). 
identity system in Figure 2.26(b). Since the overall impulse response in Figure 2.26(a) is 
h(t) * h1 (t), we have the condition that h1 (t) must satisfy for it to be the impulse response 
of the inverse system, namely, 
h(t) * h1 (t) = o(t). 
(2.66) 
Similarly, in discrete time, the impulse response h1[n] of the inverse system for an LTI 
system with impulse response h[n] must satisfy 
h[n] * h![n] = o[n]. 
(2.67) 
The following two examples illustrate invertibility and the construction of an inverse 
system. 
Example 2.11 
Consider the LTI system consisting of a pure time shift 
y(t) = x(t - to). 
(2.68) 
Such a system is a delay if to > 0 and an advance if to < 0. For example, if to > 0, then 
the output at time t equals the value of the input at the. earlier time t - t0. If to = 0, the 
system in eq. (2.68) is the identity system and thus is memory less. For any other value 
of t0 , this system has memory, as it responds to the value of the input at a time other than 
the current time. 
The impulse response for the system can be obtained from eq. (2.68) by taking the 
input equal to l>(t), i.e., 
h(t) = l>(t - t0). 
(2.69) 
Therefore, 
x(t - to) = x(t) * l>(t - to). 
(2.70) 
That is, the convolution-of a signal with a shifted impulse simply shifts the signal. 
To recover the input from the output, i.e., to invert the system, all that is required is 
to shift the output back. The system with this compensating time shift is then the inverse 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
111 
system. That is, if we take 
h1(t) = l>(t +to), 
then 
h(t) * h1 (t) = l>(t - t0) * i>(t + to) = i>(t). 
Similarly, a pure time shift in discrete time has the unit impulse response 5 [ n- n0], 
so that convolving a signal with a shifted impulse is the same as shifting the signal. 
Furthermore, the inverse of the LTI system with impulse response l>[n- n0 ] is the LTI 
system that shifts the signal in the opposite direction by the same amount-i.e., the LTI 
system with impulse response l>[n + n0]. 
Example 2. 1 2 
Consider an LTI system with impulse response 
h[n] = u[n]. 
(2.71) 
Using the convolution sum, we can calculate the response of this system to an arbitrary 
input: 
+oo 
y[n] = L x[k]u[n -
k]. 
(2.72) 
. 
k = - oo 
Since u[n -
k] is 0 for n- k < 0 and 1 for n- k ~ 0, eq. (2.72) becomes 
n 
y[n] = L x[k]. 
(2.73) 
k= - 00 
That is, this system, which we first encountered in Sectiori 1.6.1 [see eq. (1.92)], is a 
summer or accumulator that computes the running sum of all the values of the input 
up to the present time. As we saw in Section 1.6.2, such a system is invertible, and its 
inverse, as given by eq. (1.99), is 
y[n] = x[n] - x[n- 1], 
(2.74) 
which is simply a first difference operation. Choosing x[n] = l>[n], we find that the 
impulse response of the inverse system is 
h1 [n] = l>[n] - l>[n - 1]. 
(2.75) 
As a check that h[n] in eq. (2.71) and h1 [n] in eq. (2.75) are indeed the impulse re-
sponses of LTI systems that are inverses of each other, we can verify eq. (2.67) by direct 
calculation: 
h[n] * h1 [n] = u[n] * {l>[n] - l>[n - 1]} 
= u[n] * 8[n] - u[n] * 8[n- 1] 
= u[n] - u[n - 1] 
= 8[n]. 
(2.76) 

112 
Linear Time-Invariant Systems 
Chap. 2 
2.3.6 Causality for LTI Systems 
In Section 1.6.3, we introduced the property of causality: The output of a causal system 
depends only on the present and past values of the input to the system. By using the con-
volution sum and integral, we can relate this property to a corresponding property of the 
impulse response of an LTI system. Specifically, in order for a discrete-time LTI system to 
be causal, y[n] must not depend on x[k] fork > n. From eq. (2.39), we see that for this to 
be true, all of the coefficients h[n- k] that multiply values of x[k] fork > n must be zero. 
This then requires that the impulse response of a causal discrete-time LTI system satisfy 
the condition 
h[n] = 0 
for n < 0. 
(2.77) 
According to eq. (2.77), the impulse response of a causal LTI system must be zero before 
the impulse occurs, which is consistent with the intuitive concept of causality. More gener-
ally, as shown in Problem 1.44, causality for a linear system is equivalent to the condition 
of initial rest; i.e., if the input to a causal system is 0 up to some point in time, then the 
output must also be 0 up to that time. It is important to emphasize that the equivalence 
of causality and the condition of initial rest applies only to linear systems. For example, 
as discussed in Section 1.6.6, the system y[n] = 2x[n] + 3 is not linear. However, it is 
causal and, in fact, memoryless. On the other hand, if x[n] = 0, y[n] = 3 ¥- 0, so it does 
not satisfy the condition of initial rest. 
For a causal discrete-time LTI system, the condition in eq. (2.77) implies that the 
convolution sum representation in eq. (2.39) becomes 
n 
y[n] = 2:: x[k]h[n - k], 
k= -oo 
and the alternative equivalent form, eq. (2.43), becomes 
00 
y[n] = 2:: h[k]x[n - k]. 
k=O 
Similarly, a continuous-time LTI system is causal if 
h(t) = 0 
fort < 0, 
and in this case the convolution integral is given by 
y(t) = I 
1 
x( r)h(t - r)dr = ( oo h( r)x(t - r)dr. 
-
00 
Jo 
(2.78) 
(2.79) 
(2.80) 
(2.81) 
Both the accumulator (h[n] = u[n]) and its inverse (h[n] = B[n] - B[n - 1]), de-
scribed in Example 2.12, satisfy eq. (2.77) and therefore are causal. The pure time shift 
with impulse response h(t) = B(t- to) is causal for to ?:: 0 (when the time shift is a delay), 
but is noncausal for to < 0 (in which case the time shift is an advance, so that the output 
anticipates future val,ues of the input). 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
113 
Finally, while causality is a property of systems, it is common terminology to refer to 
a signal as being causal if it is zero for n < 0 or t < 0. The motivation for this terminology 
comes from eqs. (2.77) and (2.80): Causality of an LTI system is equivalent to its impulse 
response being a causal signal. 
2.3.7 Stability for LTI Systems 
Recall from Section 1.6.4 that a system is stable if every bounded input produces a 
bounded output. In order to determine conditions under which LTI systems are stable, 
consider an input x[n] that is bounded in magnitude: 
lx[nll < B 
for all n. 
(2.82) 
Suppose that we apply this input to an LTI system with unit impulse response h[n]. Then, 
using the convolution sum, we obtain an expression for the magnitude of the output: 
(2.83) 
Since the magnitude of the sum of a set of numbers is no larger than the sum of the mag-
nitudes of the numbers, it follows from eq. (2.83) that 
+oo 
iy[nJI :'5 L lh[kJIIx[n - k]l. 
(2.84) 
k = -
00 
From eq. (2.82), lx[n - kll < B for all values of k and n. Together with eq. (2.84), this 
implies that 
+oo 
iy[nll :'5 B L lh[kll 
for all n. 
(2.85) 
k = -
00 
From eq. (2.85), we can conclude that if the impulse response is absolutely summable, 
that is, if 
+oo L ih[kJI < 00, 
(2.86) 
k = -oo 
then y[n] is bounded in magnitude, and hence, the system is stable. Therefore, eq. (2.86) is 
a sufficient condition to guarantee the stability of a discrete-time LTI system. In fact, this 
condition is also a necessary condition, since, as shown in Problem 2.49, if eq. (2.86) is 
not satisfied, there are bounded inputs that result in unbounded outputs. Thus, the stability 
of a discrete-time LTI system is completely equivalent to eq. (2.86). 
In continuous time, we obtain an analogous characterization of stability in terms of 
the impulse response of an LTI system. Specifically, if lx(t)l < B for all t, then, in analogy 
with eqs. (2.83)-(2.85), it follows that 

114 
Linear Time-Invariant Systems 
Chap.2 
jy(t)l = If."'. h(r)x(t - r)dr 
I 
+ oo 
:5 
- oo jh(r)jjx(t- r)jdr 
I 
+oo 
:5 B - oo jh(r)jdr. 
Therefore, the system is stable if the impulse response is absolutely integrable, i.e., if 
I 
+oo 
- oo jh(r)jdr < oo. 
(2.87) 
As in discrete time, if eq. (2.87) is not satisfied, there are bounded inputs that produce 
unbounded outputs; therefore, the stability of a continuous-time LTI system is equivalent 
to eq. (2.87). The use of eqs (2.86) and (2.87) to test for stability is illustrated in the next 
two examples. 
Example 2.13 
Consider a system that is a pure time shift in either continuous time or discrete time. 
Then, in discrete time 
+oo 
+oo 
L !h[n]! = L !S[n - no]! = 1, 
(2.88) 
n= - oo 
n= - oo 
while in continuous time 
f
+oo 
f +oo 
_., !h('r)!dT = _., !5(7- to)!dT = 1, 
(2.89) 
and we conclude that both of these systems are stable. This should not be surprising, 
since if a signal is bounded in magnitude, so is any time-shifted version of that signal. 
Now consider the accumulator described in Example 2.12. As we discussed in 
Section 1.6.4, this is an unstable system, since, if we apply a constant input to an accu-
mulator, the output grows without bound. That this system is unstable can also be seen 
from the fact that its impulse response u[n] is not absolutely summable: 
00 
00 
L !u[n]! = L u[n] = oo. 
n= - oo 
n= O 
Similarly, consider the integrator, the continuous-time counterpart of the accumu-
lator: 
y(t) = L., x(T)dr. 
(2.90) 
This is an unstable system for precisely the same reason as that given for the accumula-
tor; i.e., a constant input gives rise to an output that grows without bound. The impulse 

Sec. 2.3 
Properties of Linear Time-Invariant Systems 
response for the integrator can be found by letting x(t) = li(t), in which case 
h(t) = L. 
5('r)dT = u(t) 
and 
f
+oo 
i +oo 
ju( T)jdT = 
d'T = oo. 
- oo 
0 
Since the impulse response is not absolutely integrable, the system is not stable. 
2.3.8 The Unit Step Response of an LTI System 
115 
Up to now, we have seen that the representation of an LTI system in terms of its unit 
impulse response allows us to obtain very explicit characterizations of system properties. 
Specifically, since h[n] or h(t) completely determines the behavior of an LTI system, we 
have been able to relate system properties such as stability and causality to properties of 
the impulse response. 
There is another signal that is also used quite often in describing the behavior of 
LTI systems: the unit step response, s[n] or s(t), corresponding to the output when x[n] = 
u[n] or x(t) = u(t). We will find it useful on occasion to refer to the step response, and 
therefore, it is worthwhile relating it to the impulse response. From the convolution -sum 
representation, the step response of a discrete-time LTI system is the convolution of the 
unit step with the impulse response; that is, 
s[n] = u[n] * h[n]. 
However, by the commutative property of convolution, s[n] = h[n] * u[n], and therefore, 
s[n] can be viewed as the response to the input h[n] of a discrete-time LTI system with 
unit impulse response u[n]. As we have seen in Example 2.12, u[n] is the unit impulse 
response of the accumulator. Therefore, 
n 
s[n] = L h[k]. 
(2.91) 
k = -oo 
From this equation and from Example 2.12, it is clear that h[n] can be recovered from s[n] 
using the relation 
h[n] = s[n] - s[n - 1]. 
(2.92) 
That is, the step response of a discrete-time LTI system is the running sum of its impulse 
response [eq. (2.91)]. Conversely, the impulse response of a discrete-time LTI system is 
the first difference of its step response [eq. (2.92)]. 
Similarly, in continuous time, the step response of an LTI system with impulse re-
sponse h(t) is given by s(t) = u(t) * h(t), which also equals the response of an integra-
tor [with impulse response u(t)] to the input h(t). That is, the unit step response of a 
continuous-time LTI system is the running integral of its impulse response, or 
S(t) = t oo h( T)d'T, 
(2.93) 

116 
Linear Time-Invariant Systems 
Chap.2 
and from eq. (2.93), the unit impulse response is the first derivative of the unit step re-
sponse,1 or 
h( ) _ ds(t) _ 
'( ) 
t-dt - st. 
(2.94) 
Therefore, in both continuous arid discrete time, the unit step response can also be used to 
characterize an LTI systeJll, since we can calculate the unit impulse response from it. In 
Problem 2.45, expressions analogous to the convolution sum imd convolution integral are 
derived for the representations of an LTI system in terms of its unit step response. 
2.4 CAUSAL LTI SYSTEMS DESCRIBED BY DIFFERENTIAL 
AND DIFFERENCE EQUATIONS 
An extremely important class of continuous-time systems is that for which the input and 
output are related through a linear constant-coefficient differential equation. Equations of 
this type arise in the description of a wide variety of systems and physical phenomena. For 
example, as we illustrated in Chapter 1, the response of the RC circuit in Figure 1.1 and 
the motion of a vehicle subject to acceleration inputs and frictional forces, as depicted in 
Figure 1.2, can both be described through linear constant-coefficient differential equations. 
Similar differential equations arise in the description of mechanical systems containing 
restoring and damping forces, in the kinetics of chemical reactions, and in many other 
contexts as well. 
Correspondingly, an important class of discrete-time systems is that for which the in~ 
put and output are related through a linear constant-coefficient difference equation. Equa-
tions of this type are used to describe the sequential behavior of many different processes. 
For instance, in Example 1.10 we saw how difference equations arise in describing the 
accumulation of savings in a bank account, and in Example 1.11 we saw how they can 
be used to describe a digital simulation of a continuous-time system described by a dif-
ferential equation. Difference equations also arise quite frequently in the specification of 
discrete-time systems designed to perform particular operations on the input signal. For 
example, the system that calculates the difference between successive input values, as in 
eq. (1.99), and the system described by eq. (1.104) that computes the average value of the 
input over an interval are described by difference equations. 
Throughout this book, there will be many occasions in which we will consider and 
examine systems described by linear constant-coefficient differential and difference equa-
tions. In this section we take a first look at these systems to introduce some of the basic 
ideas involved in solving differential and difference equations and to uncover and explore 
some of the properties of systems described by such equations. In subsequent chapters, we 
develop additional tools for the analysis of signals and systems that will add considerably 
both to our ability to analyze systems described by such equations and to our understanding 
of their characteristics and behavior. 
'Throughout this book, we will use both the notations indicated in eq. (2.94) to denote fiist derivatives. 
Analogous notation will also be used for higher derivatives. 

Sec. 2.4 
Causal LTI Systems Described by Differential and Difference Equations 
117 
2.4.1 Linear Constant-Coefficient Differential Equations 
To introduce some of the important ideas concerning systems specified by linear constant-
coefficient differential equations, let us consider a first-order differential equation as in eq. 
(1.85), viz., 
dy(t) 
dt + 2y(t) = x(t), 
(2.95) 
where y(t) denotes the output of the system and x(t) is the input. For example, comparing 
eq. (2.95) to the differential equation (1.84) for the velocity of a vehicle subject to applied 
and frictional forces, we see that eq. (2.95) would correspond exactly to this system if 
y(t) were identified with the vehicle's velocity v(t), if x(t) were taken as the applied force 
f(t), and if the parameters in eq. (1.84) were normalized in units such that blm = 2 and 
lim= 1. 
A very important point about differential equations such -as eq. (2.95) is that they 
provide an implicit specification of the system. That is, they describe a relationship be-
tween the input and the output, rather than an explicit expression for the system output 
as a function of the input. In order to obtain an explicit expression, we must solve the 
differential equation. To find a solution, we need more information than that provided by 
the differential equation alone. For example, to determine the speed of an automobile at 
the end of a 10-second interval when it has been subjected to a constant acceleration of 
1 m/sec2 for 10 seconds, we would also need to know how fast the vehicle was moving at 
the start of the interval. Similarly, if we are told that a constant source voltage of 1 volt is . 
applied to the RC circuit in Figure 1.1 for 10 seconds, we cannot determine what the ca-
pacitor voltage is at the end of that interval without also knowing what the initial capacitor 
voltage is. 
More generally, to solve a differential equation, we must specify one or more auxil-
iary conditions, and once these are specified, we can then, in principle, obtain an -explicit 
expression for the output in terms of the input. In other words, a differential equation such 
as eq. (2.95) describes a constraint between the input and the output of a system, but to 
characterize the system completely, we must also specify auxiliary conditions. Different 
choices for these auxiliary conditions then lead to different relationships between the in-
put and the output. For the most part, in this book we will focus on the use of differential 
equations to describe causal LTI systems, and for such systems the auxiliary conditions 
take a particular, simple form. To illustrate this and to uncover some of the basic properties 
of the solutions to differential equations, let us take a look at the solution of eq. (2.95) for 
a specific input signal x(t).2 
20ur discussion of the solution of linear constant-coefficient differential equations is brief, since we as-
sume that the reader has some familiarity with this material. For review, we recommend a text on the solution of 
ordinary differential equations, such as Ordinary Differential Equations (3rd ed.), by G. Birkhoff and G.-C. Rota 
(New York: John Wiley and Sons, 1978), or Elementary Differential Equations (3rd ed.), by W.E. Boyce and 
R.C. DiPrima (New York: John Wiley and Sons, 1977). There are also numerous texts that discuss differential 
equations in the context of circuit theory. See, for example, Basic Circuit Theory, by L.O. Chua, C.A. Desoer, 
and E.S. Kuh (New York: McGraw-Hill Book Company, 1987). As mentioned in the text, in the following 
chapters we present other very useful methods for solving linear differential equations that will be sufficient for 
our purposes. In addition, a number of exercises involving the solution of differential equations are included in 
the problems at the end of the chapter. 

118 
/ 
Linear Time-Invariant Syst~ms 
~xample 2. 14 
Consider the soluti_on of eq. (2.95) when the input signal is 
x(t) = Ke31 u(t), 
where K is a real number. 
Chap.2 
(2.96) 
The complete solution to eq. (2.96) consists of the sum of a particular solution, 
yp(t), and a homogeneous solution, y11(t), i.e., 
y(t) = Yp(t) + Yh(t), 
(2.97) 
where the particular solution satisfies eq. (2.95) and y11(t) is a solution of the homoge-
neous differential equation 
dy(t) 
2 () - 0 
----;]t + y t -
. 
(2.98) 
A common method for finding the particular solution for an exponential input signal as 
in eq. (2.96) is to look for a so-called forced response- i.e., a signal of the same form 
as theinput. With regard to eq. (2.95), since x(t) = Ke 31 fort > 0, we hypothesize a 
solution for t > 0 of the form 
(2.99) 
where Y is a number that we must determine. Substituting eqs. (2.96) and (2.99) into 
. eq. (2.95) fort > 0 yields 
Canceling the factor e31 from both sides of eq. (2.100), we obtain 
or 
3Y + 2Y = K, 
K 
y = 5' 
so that 
In order to determine y11(t), we hypothesize a solution of the form 
Yh(t) = Aes1• 
Substituting this into eq. (2.98) gives 
Asesr + 2Aesr = Aes1(s + 2) = 0. 
(2.100) 
(2.101) 
(2.102) 
(2.103) 
(2.104) 
(2.105) 
From this equation, we see that we must takes = -2 and that Ae- 21 is a solution to eq. 
(2.98) for any choice of A. Utilizing this fact and eq. (2.103) in eq. (2.97), we find that 
the solution of the differential equation for t > 0 is 
y(t) = Ae- 21 + ~e
31
, 
t > 0. 
(2.106) 

Sec. 2.4 
Causal LTI Systems Described by Differential and Difference Equations 
119 
As noted earlier, the differential equation (2.95) by itself does not specify uniquely the 
response y(t) to the input x(t) in eq. (2.96). In particular, the constant A in eq. (2.106) 
has not yet been determined. In order for the value of A to be determined, we need to 
specify an auxiliary condition in addition to the differential equation (2.95). As explored 
in Problem 2.34, different choices for this auxiliary condition lead to different solutions 
y(t) and, consequently, to different relationships between the input and the output. As 
we have indicated, for the most part in this book we focus on differential and difference 
equations used to describe systems that are LTI and causal, and in this case the auxiliary 
condition takes the form of the condition of initial rest. That is, as shown in Problem 1.44, 
for a causal LTI system, if x(t) = 0 fort < t0, then y(t) must also equal 0 fort < t0• From 
eq. (2.96), we see thatforourexample x(t) = Ofor t < 0, and thus, the condition of initial 
rest implies that y(t) = 0 fort < 0. Evaluating eq. (2.106) at t = 0 and setting y(O) = 0 
yields 
or 
Thus, for t > 0, 
K 
O=A+-5 ' 
K 
A =- -5' 
(2.107) 
while fort < 0, y(t) = 0, because of the condition of initial rest. Combining these two 
cases, we obtain the full solution 
(2.108) 
Example 2.14 illustrates several very important points concerning linear constant-
coefficient differential equations and the systems they represent. First, the response to 
an input x(t) will generally consist of the sum of a particular solution to the differential 
equation and a homogeneous solution-i.e., a solution to the differential equation with the 
input set to zero. The homogeneous solution is often referred to as the natural response 
of the system. The natural responses of simple electrical circuits and mechanical systems 
are explored in Problems 2.61 and 2.62. 
In Example 2.14 we also saw that, in order to determine completely the relation-
ship between the input and the output of a system described by a differential equation 
such as eq. (2.95), we must specify auxiliary conditions. An implication of this fact, 
. which is illustrated in Problem 2.34, is that different choices of auxiliary conditions lead 
to different relationships between the input and the output. As we illustrated in the ex-
ample, for the most part we will use the condition of initial rest for systems described 
by differential equations. In the example, since the input was 0 for t < 0, the condition 
of initial rest implied the initial condition y(O) = 0. As we have stated, and as illustrated in 

120 
Linear Time-Invariant Systems 
Chap.2 
Problem 2.33, under the condition of initial rest the system described by eq. (2.95) is LTI 
and causal.3 For example, if we multiply the input in eq. (2.96) by 2, the resulting output 
would be twice the output in eq. (2.108). 
It is important to emphasize that the condition of initial rest does not specify a zero 
initial condition at a fixed point in time, but rather adjusts this point in time so that the 
response is zero until the input becomes nonzero. Thus, if x(t) = 0 for t ::s to for the 
causal LTI system described by eq. (2.95), then y(t) = 0 for t ::s to, and we would use 
the initial condition y(to) = 0 to solve for the output for t > to. As a physical example, 
consider again the circuit in Figure 1.1, also discussed in Example 1.8. Initial rest for this 
example corresponds to the statement that, until we connect a nonzero voltage source to the 
circuit, the capacitor voltage is zero. Thus, if we begin to use the circuit at noon today, the 
initial capacitor voltage as we connect the voltage source at noon today is zero. Similarly, 
if we begin to use the circuit at noon tomorrow instead, the initial capacitor voltage as we 
connect the voltage source at noon tomorrow is zero. 
This example also provides us with some intuition as to why the condition of initial 
rest makes a system described by a linear constant-coefficient differential equation time 
invariant. For example, if we perform an experiment on the circuit, starting from initial 
rest, then, assuming that the coefficients Rand C don't change over time, we would expect 
to get the same results whether we ran the experiment today or tomorrow. That is, if we 
perform identical experiments on the two days, where the circuit starts from initial rest at 
noon on each day, then we would expect to see identical responses- i.e., responses that 
are simply time-shifted by one day with respect to each other. 
While we have used the first-order differential equation (2.95) as the vehicle for the 
discussion of these issues, the same ideas extend directly to systems described by higher 
order differential equations. A general Nth-order linear constant-coefficient differential 
equation is given by 
(2.109) 
The order refers to the highest derivative of the output y(t) appearing in the equation. In 
the case when N = 0, eq. (2.109) reduces to 
() _ 1 ~b dkx(t) 
y t -
-
L., k--k- . 
ao k=O 
dt 
(2.110) 
In this case, y(t) is an explicit function of the input x(t) and its derivatives. For N ;::: 1, 
eq. (2.109) specifies the output implicitly in terms of the input. In this case, the analysis 
of the equation proceeds just as in our discussion of the first-order differential equation in 
Example 2.14. The solution y(t) consists of two parts-a particular solution to eq. (2.109) 
3In fact, as is also shown in Problem 2.34, if the initial condition for eq. (2.95) is nonzero, the resulting 
system is incrementally linear. That is, the overall response can be viewed, much as in Figure 1.48, as the 
superposition of the response to the initial conditions alone (with input set to 0) and the response to the input 
with an initial condition of 0 (i.e:, the response of the causal LTI system described by eq. (2.95)). 

Sec. 2.4 
Causal LTI Systems Described by Differential and Difference Equations 
plus a solution to the homogeneous differential equation 
..f!:, 
dky(t) - 0 
L.....,ak- d k 
-
. 
k=O 
t 
121 
(2.111) 
The solutions to this equation are referred to as the natural responses of the system. 
As in the first-order case, the differential equation (2.109) does not completely spec-
ify the output in terms of the input, and we need to identify auxiliary conditions to deter-
mine completely the input-output relationship for the system. Once again, different choices 
for these auxiliary conditions result in different input-output relationships, but for the most 
part, in this book we will use the condition of initial rest when dealing with systems de-
scribed by differential equations. That is, if x(t) = 0 for t :5 t0, we assume that y(t) = 0 
for t :5 t0, and therefore, the response for t > to can be calculated from the differential 
equation (2.109) with the initial conditions 
( ) _ dy(to) _ 
_ dN- 1y(to) _ 0 
Y to - ~- . .. -
dtN- 1 
-
. 
(2.112) 
Under the condition of initial rest, the system described by eq. (2.109) is causal and LTI. 
Given the initial conditions in eq. (2.112), the output y(t) can, in principle, be determined 
by solving the differential equation in the manner used in Example 2.14 and further illus-
trated in several problems at the end of the chapter. However, in Chapters 4 and 9 we will 
develop some tools for the analysis of continuous-time LTI systems that greatly facilitate 
the solution of differential equations and, in particular, provide us with powerful methods 
for analyzing and characterizing the properties of systems described by such equations. 
2.4.2 Unear Constant-Coefficient Difference Equations 
The discrete-time counterpart of eq. (2.109) is the Nth-order linear constant-coefficient 
difference equation 
N 
M 
L aky[n- k] = L bkx[n- k]. 
(2.113) 
k=O 
k=O 
An equation of this type can be solved in a manner exactly analogous to that for differential 
equations. (See Problem 2.32.)4 Specifically, the solution y[n] can be written as the sum 
of a particular solution to eq. (2.113) and a solution to the homogeneous equation 
N 
Laky[n- k] = 0. 
k=O 
(2.114) 
4For a detailed treatment of the methods for solving linear constant-coefficient difference equations, 
see Finite Difference Equations, by H. Levy and F. Lessman (New York: Macmillan, Inc., 1961), or Finite 
Difference Equations and Simulations (Englewood Cliffs, NJ: Prentice-Hall, 1968) by F. B. Hildebrand. In 
Chapter 6, we present another method for solving difference equations that greatly facilitates the analysis of 
linear time-invariant systems that are so described. In addition, we refer the reader to the problems at the end 
of this chapter that deal with the solution of difference equations. 

122 
Linear Time-Invariant Systems 
Chap. 2 
The solutions to this homogeneous equation are often referred to as the natural responses 
of the system described by eq. (2.113). 
As in the continuous-time case, eq. (2.113) does not completely specify the output 
in terms of the input. To do this, we must also specify some auxiliary conditions. While 
there are many possible choices for auxiliary conditions, leading to different input-output 
relationships, we will focus for the most part on the condition of initial rest-i.e., if x[n] = 
0 for n < no, then y[n] = 0 for n < no as well. With initial rest, the system described by 
eq. (2.113) is LTI and causal. 
Although all of these properties can be developed following an approach that di-
rectly parallels our discussion for differential equations, the discrete-time case offers an 
alternative path. This stems from the observation that eq. (2.113) can be rearranged in the 
form 
1 [ M 
N 
) 
y[n] = a- Lbkx[n - k]- Laky[n- k] . 
0 
k = O 
k = 1 
(2.115) 
Equation (2.115) directly expresses the output at time n in terms of previous values of the 
input and output. From this, we can immediately see the need for auxiliary conditions. In 
order to calculate y[n], we need to know y[n- 1], . . . , y[n- N]. Therefore, if we are given 
the input for all nand a set of auxiliary conditions such as y[- N], y[-N + 1], .. . , y[ - 1], 
eq. (2.115) can be solved for successive values of y[n]. 
An equation of the form of eq. (2.113) or eq. (2.115) is called a recursive equation, 
since it specifies a recursive procedure for determining the output in terms of the input and 
previous outputs. In the special case when N = 0, eq. (2.115) reduces to 
y[n] = i (bk ) x[n- k]. 
k = O ao 
(2.116) 
This is the discrete-time counterpart of the continuous-time system given in eq. (2.110). 
Here, y[n] is an explicit function of the present and previous values of the input. For this 
reason, eq. (2.116) is often called a nonrecursive equation, since we do not recursively 
use previously computed values of the output to compute the present value of the output. 
Therefore, just as in the case of the system given in eq. (2.11 0), we do not need auxiliary 
conditions in order to determine y[n]. Furthermore, eq. (2.116) describes an LTI system, 
and by direct computation, the impulse response of this system is found to be 
{ 
b, 
h[n] = 
ao' 
0, 
0-5n-5M 
otherwise 
(2.117) 
That is, eq. (2.116) is nothing more than the convolution sum. Note that the impulse re-
sponse for it has finite duration; that is, it is nonzero only over a finite time interval. Because 
of this property, the system specified by eq. (2.116) is often called afinite impulse response 
(FIR) system. 
Although we do not require auxiliary conditions for the case of N = 0, such condi-
tions are needed for the recursive case when N <::: 1. To illustrate the solution of such an 
equation, and to gain some insight into the behavior and properties of recursive difference 
equations, let us examine the following simple example: 

Sec. 2.4 
Causal LTI Systems Described by Differential and Difference Equations 
123 
Example 2. 1 5 
Consider the difference equation 
1 
y[n]- 2y[n - 1] = x[n]. 
(2.118) 
Eq. (2.118) can also be expressed in the form 
1 
y[n] = x[n] + 2y[n - 1], 
(2.119) 
highlighting the fact that we need the previous value of the output, y[n- 1], to calculate 
the current value. Thus, to begin the recursion, we need an initial condition. 
For example, suppose that we impose the condition of initial rest and consider the 
input 
x[n] = KB[n]. 
(2.120) 
In this case, since x[ n] = 0 for n :5: - 1, the condition of initial rest implies that y[ n] = 
0 for n :5: - 1, so that we have as an initial condition y[ -1] = 0. Starting from this 
initial condition, we can solve for successive values' of y[n] for n 2: 0 as follows: 
1 
y[O] = x[O] + 2y[ -1] = K, 
(2.121) 
1 
1 
y[1] = x[1] + 2y[O] = 2K, 
(2.122) 
1 
(1 )
2 
y[2] = x[2] + 2y[1] = 2 K, 
(2.123) 
1 
(1 )n 
y[n] = x[n] + 2y[n- 1] = 2 K. 
(2.124) 
Since the system specified by eq. (2.118) and the condition of initial rest is LTI, its input-
output behavior is completely characterized by its impulse response. Setting K = 1, we 
see that the impulse response for the system considered in this example is 
h~n] = G)' u[n]. 
(2.125) 
Note that the causal LTI system in Example 2.15 has an impulse response of infinite 
duration. In fact, if N 2: 1 in eq. (2.113), so that the difference equation is recursive, it 
is usually the case that the LTI system corresponding to this equation together with the 
condition of initial rest will have an impulse response of infinite duration. Such systems 
are commonly referred to as infinite impulse response (IIR) systems. 
As we have indicated, for the most part we will use recursive difference equations in 
the context of describing and analyzing systems that are linear, time-invariant, and causal, 
and consequently, we will usually make the assumption of initial rest. In Chapters 5 
and 10 we will develop tools for the analysis of discrete-time systems that will provide us 

124 
Linear Time-Invariant Systems 
Chap. 2 
with very useful and efficient methods for solving linear constant-coefficient difference 
equations and for analyzing the properties of the systems that they describe. 
2.4.3 Block Diagram Representations of First-Order Systems 
Described by Differential and Difference Equations 
An important property of systems described by linear constant-coefficient difference and 
differential equations is that they can be represented in very simple and natural ways 
in terms of block diagram interconnections of elementary operations. This is significant 
for a number of reasons. One is that it provides a pictorial representation which can add 
to our understanding of the behavior and properties of these systems. In addition, such 
representations can be of considerable value for the simulation or implementation of the 
systems. For example, the block diagram representation to be introduced in this section 
for continuous-time systems is the basis for early analog computer simulations of systems 
described by differential equations, and it can also be directly translated into a program 
for the simulation of such a system on a digital computer. In addition, the corresponding 
representation for discrete-time difference equations suggests simple and efficient ways 
in which the systems that the equations describe can be implemented in digital hardware. 
In this section, we illustrate the basic ideas behind these block diagram representations 
by constructing them for the causal first-order systems introduced in Examples 1.8-1.11. 
In Problems 2.57-2.60 and Chapters 9 and 10, we consider block diagrams for systems 
described by other, more complex differential and difference equations. 
We begin with the discrete-time case and, in particular, the causal system described 
by the first-order difference equation 
y[n] + ay[n - 1] = bx[n]. 
(2.126) 
To develop a block diagram representation · of this system, note that the evaluation of 
eq. (2.126) requires three basic operations: addition, multiplication by a coefficient, and 
delay (to capture the relationship between y[n] and y[n - 1]). Thus, let us define three 
basic network elements, as indicated in Figure 2.27. To see how these basic elements can 
be used to represent the causal system described by eq. (2.126), we rewrite this equation 
in the form that directly suggests a recursive algorithm for computing successive values 
of the output y[n]: 
y[n] = -ay[n - 1] + bx[n]. 
(2.127) 
This algorithm is represented pictorially in Figure 2.28, which is an example of a feedback 
system, since the output is fed back through a delay and a multiplication by a coefficient 
and is then added to bx[n]. The presence of feedback is a direct consequence of the recur-
sive nature of eq. (2.127). 
The block diagram in Figure 2.28 makes clear the required memory in this system 
and the consequent need for initial conditions. In particular, a delay corresponds to a mem-
ory element, as the element must retain the previous value of its input. Thus, the initial 
value of this memory element serves as a necessary initial condition for the recursive cal-
culation specified pictorially in Figure 2.28 and mathematically in eq. (2.127). Ofcourse, 
if the system described by eq. (2.126) is initially at rest, the initial value stored in the 
memory element is zero. 

I 
Sec. 2.4 
Causal LTI Systems Described by Differential and Difference Equations 
125 
x2[n] 
x1[n] 
.~ 
(a) 
a 
x[n] ----+----- ax[n] 
(b) 
b 
x[n]......,..._.~ 
D 
- a 
.....__....,. _ ___. y[n- 1] 
Figure 2.27 
Basic elements for 
the block diagram representation 
of the causal system described by 
eq. (2.126): (a) an adder; (b) multi-
plication by a coefficient; (c) a unit 
delay. 
Figure 2.28 
Block diagram repre-
sentation for the causal discrete-time 
system described by eq. (2.126). 
Consider next the causal continuous-time system described by a first -order differen-
tial equation: 
dy(t) 
dt + ay(t) = bx(t). 
(2.128) 
As a first attempt at defining a block diagram representation for this system, let us rewrite 
it as 
y(t) = -! dy(t) + ~ x(t). 
a dt 
a 
(2.129) 
The right-hand side of this equation involves three basic operations: addition, multiplica-
tion by a coefficient, and differentiation. Therefore, if we define the three basic network 
elements indicated in Figure 2.29, we can consider representing eq. (2.129) as an inter-
connection of these basic elements in a manner analogous to that used for the discrete-time 
system described previously, resulting in the block diagram of Figure 2.30. 
While the latter figure is a valid representation of the causal system described by 
eq. (2.128), it is not the representation that is most frequently used or the representation 
that leads directly to practical implementations, since differentiators are both difficult to 
implement and extremely sensitive to errors and noise. An alternative implementation that 

126 
x2(t) 
~ 
x1(t) 
·8 
(a) 
/ 
a 
x(t) 
(b) 
(c) 
b/a 
x(t) _,.--!lo-l 
• x1 (t) + x2(t) 
ax(t) 
Linear Time-Invariant Systems 
Chap.2 
Figure 2.29 
One possible set of 
basic elements for the block diagram 
representation of the continuous-time 
system described by eq. (2.128): 
(a) an adder; (b) multiplication by a 
coefficient; (c) a differentiator. 
Figure 2.30 
Block diagram 
representation for the system in 
eqs. (2.128) and (2.129), using adders, 
multiplications by coefficients, and 
differentiators. 
is much more widely used can be obtained by first rewriting eq. (2.128) as 
dy(t) 
(if = bx(t) - ay(t) 
(2.130) 
and then integrating from -oo to t. Specifically, if we assume that in the system described 
by eq. (2.130) the value of y( - oo) is zero, then the integral of dy(t)ldt from -oo tot is 
precisely y(t). Consequently, we obtain the equation 
y(t) = LY. rbx(T)- ay(r)] dT. 
(2.131) 
In this form. our system can be implemented using the adder and coefficient multiplier 
indicated in Figure 2.29, together with an integrator, as defined in Figure 2.31. Figure 2.32 
is a block diagram representation for this system using these elements. 

Sec. 2.5 
Singularity Functions 
b 
x(t)--t--{ 
- a 
t---"""T--t~ y(t) 
127 
Figure 2.31 
Pictorial representation 
of an integrator. 
Figure 2.32 · Block diagram rep-
resentation for the system in eqs. 
(2.128) and (2.131 ), using adders, 
multiplications by coefficients, and in-
tegrators. 
Since integrators can be readily implemented using operational amplifiers, repre-
sentations such as that in Figure 2.32 lead directly to analog implementations, and indeed, 
this is the basis for both early analog computers and modern analog computation systems. 
Note that in the continuous-time case it is the integrator that represents the memory stor-
age element of the system. This is perhaps more readily seen if we consider integrating 
eq. (2.130) from a finite point in time to, resulting in the expression 
y(t) = y(to) + r [bx(T)- ay(r)] dT. 
Jro 
(2.132) 
Equation (2.132) makes clear the fact that the specification of y(t) requires an initial con-
dition, namely, the value of y (t0). It is precisely this value that the integrator stores at 
time to. 
While we have illustrated block diagram constructions only for the simplest first-
order differential and difference equations, such block diagrams can also be developed for 
higher order systems, providing both valuable intuition for and possible implementations 
of these systems. Examples of block diagrams for higher order systems can be found in 
Problems 2.58 and 2.60. 
2. 5 SINGULARITY FUNCTIONS 
In this section, we take another look at the continuous-time unit impulse function in order 
to gain additional intuitions about this important idealized signal and to introduce a set of 
related signals known collectively as singularity functions. In particular, in Section 1.4.2 
we suggested that a continuous-time unit impulse could be viewed as the idealization of a 
pulse that is "short enough" so that its shape and duration is of no practical consequence-
i.e., so that as far as the response of any particular LTI system is concerned, all of the area 
under the pulse can be thought of as having been applied instantaneously. In this section, 
we would first like to provide a concrete example of what this means and then use the 
interpretation embodied within the example to show that the key to the use of unit impulses 
and other singularity functions is in the specification of how LTI systems respond to these 
idealized signals; i.e., the signals are in essence defined in terms of how they behave under 
convolution with other signals. 

128 
Linear Time-Invariant Systems 
Chap.2 
2.5.1 The Unit Impulse as an Idealized Short Pulse 
From the sifting property, eq. (2.27), the unit impulse o(t) is the impulse response of the 
identity system. That is, 
x(t) = x(t) * o(t) 
for any signal x(t). Therefore, if we take x(t) = o(t), we have 
o(t) = o(t) * o(t). 
(2.133) 
(2.134) 
Equation (2.134) is a basic property of the unit impulse, and it also has a significant im-
plication for our interpretation of the unit impulse as an idealized pulse. For example, as 
in Section 1.4.2, suppose that we think of o(t) as the limiting form of a rectangular pulse. 
Specifically, let DD.(t) correspond to the rectangular pulse defined in Figure 1.34, and let 
rD.(t) = BD.(t) * BD.(t). 
(2.135) 
Then rD.(t) is as sketched in Figure 2.33. If we wish to interpreto(t) as the limit as Ll --7 0 of 
DD.(t), then, by virtue of eq. (2.134), the limit as Ll --7 0 for rD.(t) must also be a unit impulse. 
In a similar manner, we can argue that the limits as Ll --7 0 of rD.(t) * rD.(t) or rD.(t) * Ofl(t) 
must be unit impulses, and so on. Thus, we see that for consistency, if we define the unit 
impulse as the limiting form of some signal, then in fact, there is an unlimited number of 
very dissimilar-looking signals, all of which behave like an impulse in the limit. 
The key words in the preceding paragraph are "behave like an impulse," where, as 
we have indicated, what we mean by this is that the response of an LTI system to all of 
these signals is essentially identical, as long as the pulse is "short enough," i.e., Ll is "small 
enough." The following example illustrates this idea: 
1 
fl 
Example 2. 1 6 
r .1(t) 
Figure 2.33 
The signal r,1(t) 
defined in eq. (2.135). 
Consider the LTI system described by the first-order differential equation 
d~;t) + 2y(t) = x(t), 
(2.136) 
together with the condition of initial rest. Figure 2.34 depicts the response of this system 
to 8fl.(t), rfl.(t), rfl.(t) * 8fl.(t), and rfl.(t) * rfl.(t) for several values of ll. For lllarge enough, 
the responses to these input signals differ noticeably. However, for ll sufficiently small, 
the responses are essentially indistinguishable, so that all of the input signals "behave" 
in the same way. Furthermore, as suggested by the figure, the limiting form of all of these 
responses is precisely e- 21 u(t). Since the limit of each of these signals as ll ~ 0 is the 
unit impulse, we conclude that e- 21 u(t) is the impulse response for this system.5 
5In Chapters 4 and 9, we will describe much simpler ways to determine the impulse response of causal 
LTI systems described by linear constant-coefficient differential equations. 

Sec. 2.5 
Singularity Functions 
0.5 
d =0.0025 
1 
Responses to x(t) = 8 d (!) 
(a) 
Responses to x(t) = &d(t)•rd(t) 
(c) 
2 
2 
(e) 
1 
Responses to x(t) = r d (t) 
(b) 
1 
Responses to x(t) = r d (!)or d (t) 
(d) 
2 
Figure 2.34 
Interpretation of a unit impulse as the idealization of a pulse 
whose duration is "short enough" so that, as far as the response of an LTI 
system to this pulse is concerned, the pulse can be thought of as having 
been applied instantaneously: (a) responses of the causal LTI system de-
scribed by eq. (2.136) to the input oA (t) for .l = 0.25, 0.1, and 0.0025; 
2 
2 
(b) responses of the same system to rA(t) for the same values of .l; (c) re-
sponses to oA(t) * rA(t); (d) responses to rA(t) * rA(t); (e) the impulse response 
h( t) = e-21 u( t) for the system. Note that, for .l = G.25, there are noticeable 
differences among the responses to these different signals; however, as .l 
becomes smaller, the differences diminish, and all of the responses converge 
to the impulse response shown in (e). 
129 

130 
Linear Time-Invariant Systems 
Chap.2 
One important point to be emphasized is that what we mean by "A small enough" 
depends on the particular LTI system to which the preceding pulses are applied. For 
example, in Figure 2.35, we have illustrated the responses to these pulses for different 
0.1 
Responses to x(t) = SA (t) 
(a) 
11.=0.00025 
Responses to x(t) = SA (t)• r A (t) 
(c) 
0.2 
0.5 
11.= 0.00025 
0.1 
Responses to x(t) = r A (t) 
(b) 
0.2 
0.1 
Responses to x(t) = r A(t)• r A(t) 
(d) 
(e) 
Figure 2.35 
Finding a value of a that is "small enough" depends upon 
0.2 
0.2 
the system to which we are applying inputs: {a) responses of the causal LTI 
system described by eq. {2.137) to the input Bt. {t) for a = 0.025, 0.01, and 
0.00025; {b) responses to rt.{t); {c) responses to Bt.{t)*ft.{t); {d) responses to 
rt.{t) * rt.{t); {e) the impulse response h{t) = e- 201 u{t) for the system. Com-
paring these responses to those in Figure 2.34, we see that we need to use a 
smaller value of a in this case before the duration and shape of the pulse are 
of no consequence. 

Sec. 2.5 
Singularity Functions 
131 
values of A for the causal LTI system described by the first-order differential equation · 
d~;t) + 20y(t) = x(t). 
(2.137) 
As seen in the figure, we need a smaller value of A in this case in order for the responses 
to be indistinguishable from each other and from the impulse response h(t) = e- 201 u(t) 
for the system. Thus, while what we mean by "A small enough" is different for these 
two systems, we can find values of A small enough for both. The unit impulse is then 
the idealization of a short pulse whose duration is short enough for all systems. 
2.5.2 Defining the Unit Impulse through Convolution 
As the preceding example illustrates, ford small enough, the signals S~(t), r~(t), r~(t) * 
S~(t), and r~(t) * r~(t) all act like impulses when applied to an LTI system. In fact, there 
are many other signals for which this is true as well. What it suggests is that we should 
think of a unit impulse in terms of how an LTI system responds to it. While usually a 
function or signal is defined by what it is at each value of the independent variable, the 
primary importance of the unit impulse is not what it is at each value oft, but rather what 
it does under convolution. Thus, from the point of view of linear syste~s analysis, we may 
alternatively define the unit impulse as that signal which, when applied to an LTI system, 
yields the impulse response. That is, we define S(t) as the signal for which 
x(t) = x(t) * S(t) 
(2.138) 
for any x(t). In this sense, signals, such as S~(t), r~(t), etc., which correspond to short 
pulses with vanishingly small duration as d ~ 0, all behave like a unit impulse in the 
limit because, if we replace S(t) by any of these signals, then eq. (2.138) is satisfied in the 
limit. 
All the properties of the unit impulse that we need can be obtained from the opera-
tional definition given by eq. (2.138). For example, if we let x(t) = 1 for all t, then 
I 
+oo 
1 = x(t) = x(t) * S(t) = S(t) * x(t) = 
- oo S( r)x(t - r) dr 
I 
+ oo 
= 
- oo S(r)dr, 
so that the unit impulse has unit area. 
It is sometimes useful to use another completely equivalent operational definition of 
S(t). To obtain this alternative form, consider taking an arbitrary signal g(t), reversing it 
in time to obtain g( -t), and then convolving this with S(t). Using eq. (2.138), we obtain 
I 
+ oo 
g(- t) = g(-t)*S(t) = 
-oo g(r-t)S(r)dr, 
which, for t = 0, yields 
I 
+oo 
g(O) = 
- oo g(r)S(r)dr. 
(2.139) 

132 
Linear Time-Invariant Systems 
Chap. 2 
Therefore, the operational definition of 5(t) given by eq. (2.138) implies eq. (2.139). On 
the other hand, eq. (2.139) implies eq. (2.138). To see this, let x(t) be a given signal, fix a 
time t, and define 
g(T) = x(t - T). 
Then, using eq. (2.139), we have 
f
+oo 
f+ oo 
x(t) = g(O) = 
- oo g(T)l>(T)dT = 
- oo x(t- T)l>(T)dT, 
which is precisely eq. (2.138). Therefore, eq. (2.139) is an equivalent operational definition 
of the unit impulse. That is, the unit impulse is the signal which, when multiplied by a 
signal g(t) and then integrated from -oo to +oo, produces the value g(O). 
Since we will be concerned principally with LTI systems, and thus with convolution, 
the characterization of 5(t) given in eq. (2.138) will be the one to which we will refer most 
often. However, eq. (2.139) is useful in determining some of the other properties of the 
unit impulse. For example, consider the signal f ( t) 5 ( t), where f ( t) is another signal. Then, 
from eq. (2.139), 
(2.140) 
On the other hand, if we consider the signal f(O) 5(t), we see that 
L+
00
00 
g(T)/(0)5(T)dT = g(O)J(O). 
(2.141) 
Comparing eqs. (2.140) and (2.141), we find that the two signals f(t) 5(t) and f(O) 5(t) be-
have identically when they are multiplied by any signal g(t) and then integrated from - oo 
to +oo. Consequently, using this form of the operational definition of signals, we conclude 
that 
f(t) 5(t) = /(0) 5(t), 
(2.142) 
which is a property that we derived by alternative means in Section 1.4.2. [See eq. (1.76).] 
2.5.3 Unit Doublets and Other Singularity Functions 
The unit impulse is one of a class of signals known as singularity functions, each of which 
can be defined operationally in terms of its behavior under convolution. Consider the LTI 
system for which the output is the derivative of the input, i.e., 
' • 
y(t) = dx(t) 
dt 
(2.143) 
The unit impulse response of this system is the derivative of the unit impulse, which is 
called the unit doublet u1 (t). From the convolution representation for LTI systems, we 
have 

Sec. 2.5 
Singularity Functions 
dx(t) 
-
- = x(t) * u1 (t) 
dt 
133 
(2.144) 
for any signal x(t). Just as eq. (2.138) serves as the operational definition of 8(t), we will 
take eq. (2.144) as the operational definition of u1(t). Similarly, we can define u2(t), the 
second derivative of 8(t), as the impulse response of an LTI system that takes the second 
derivative of the input, i.e., 
d 2x(t) 
~ 
= x(t) * u2(t). 
(2.145) 
From eq. (2.144), we see that 
-- = - --
= x(t) * Ut(t) * UJ(t) 
d
2x(t) 
d (dx(t)) 
dt2 
dt 
dt 
' 
(2.146) 
and therefore, 
U2(t) = Ut (t) * UJ (t). 
(2.147) 
In general, uk(t), k > 0, is the kth derivative of 8(t) and thus is the impulse response of a 
system that takes the kth derivative of the input. Since this system can be obtained as the 
cascade of k differentiators, we have 
Uk(t) = UJ(t) * ''' * Ut(t). 
k times 
(2.148) 
As with the unit impulse, each of these singularity functions has properties that can 
be derived from its operational definition. For example, if we consider the constant signal 
x(t) = 1, we find that 
dx(t) 
f 
+ oo 
0 = - d 
= x(t) * u1(t) = 
UJ(T)x(t- r)dr 
t 
-
00 
f
+oo 
= 
- oo UJ(T)d'T, 
so that the unit doublet has zero area. Moreover, if we convolve the signal g( - t) with u1 (t), 
we obtain 
f 
+ oo 
dg( -t) 
1 
g(T- t)Ut(T)d'T = g(- t) * UJ(t) = -
-
= - g (-t), 
- oo 
dt 
which, for t = 0, yields 
f 
+ oo 
-g'(O) = 
- oo g(T)Ut(T)dr. 
(2.149) 

134 
Linear Time-Invariant Systems 
Chap.2 
In an analogous manner, we can derive related properties of u1 (t) and higher order singu-
larity functions, and several of these properties are considered in Problem 2.69. 
As with the unit impulse, each of these singularity functions can be informally re-
lated to short pulses. For example, since the unit doublet is formally the derivative of the 
unit impulse, we can think of the doublet as the idealization of the derivative of a short 
pulse with unit area. For instance, consider the short pulse l>tJ. (t) in Figure 1.34. This pulse 
behaves like an impulse as a ~ 0. Consequently, we would expect its derivative to be-
have like a doublet as a ~ 0. As verified in Problem 2.72, dl>tJ.(t)ldt is as depicted in 
Figure 2.36: It consists of a unit impulse at t = 0 with area + va, followed by a unit 
impulse of area -1/a at t = a, i.e., 
dl>;t<t) = ±[5(t) - l>(t- a)J. 
(2.150) 
Consequently, using the fact that x(t) * l>(t - to) = x(t - to) [see eq. (2.70)], we find that 
x(t) * dl>tJ.(t) = x(t)- x(t- M = dx(t) 
dt 
a 
dt • 
(2.151) 
where the approximation becomes increasingly accurate as a ~ 0. Comparing eq. (2.151) 
with eq. (2.144), we see that dl>tJ.(t)/dt does indeed behave like a unit doublet as a ~ 0. 
In addition to singularity functions that are derivatives of different orders of the unit 
impulse, we can also define signals that represent successive integrals of the unit im-
pulse function. As we saw in Example 2.13, the unit step is the impulse response of an 
integrator: 
Therefore, 
y(t) = [ ,, X(T)dT. 
dS11(t) 
dt 
1 
- Li 
(2.152) 
Figure 2.36 
The derivative 
d811 ( t)/ dt of the short rectangular 
pulse 811 (t) of Figure 1.34. 

Sec. 2.5 
Singularity Functions 
135 
and we also have the following operational definition of u(t): 
x(t) * u(t) = Lx, x(T)dT. 
(2.153) 
Similarly, we can define the system that consists of a cascade of two integrators. Its 
impulse response is denoted by u_2(t), which is simply the convolution of u(t), the impulse 
response of one integrator, with itself: 
U- 2(t) = u(t) * u(t) = r oo U( T) dT. 
(2.154) 
Since u(t) equals 0 for t < 0 and equals 1 for t > 0, it follows that 
U-2U) = tu(t). 
(2.155) 
This signal, which is referred to as the unit ramp function, is shown in Figure 2.37. Also, 
we can obtain an operational definition for the behavior of u_2(t) under convolution from 
eqs. (2.153) and (2.154): 
x(t) * U- 2(t) = x(t) * it(t) * u(t) 
= ~ 
~oo x(a') d(}' )* u(t) 
(2.156) 
=roo u~oo X((}')d(}') dT. 
In an analogous fashion, we can define higher order integrals of 5(t) as the impulse 
responses of cascades of integrators: 
U- k(t) = u(t)* · · · *u(t) = Jt U- (k- l)(T)dT. 
~ 
-
00 
(2.157) 
k times 
The convolution of x(t) with U-3(t), U- 4(t), .. . generate correspondingly higher order 
integrals of x(t). Also, note that the integrals in eq. (2.157) can be evaluated directly (see 
Figure 2.37 
Unit ramp function. 

136 
Linear Time-Invariant Systems 
Chap.2 
Problem 2.73), as was done in eq. (2.155), to obtain 
tk- l 
u_k(t) = (k _ 1)! u(t). 
(2.158) 
Thus, unlike the derivatives of l>(t), the successive integrals of the unit impulse are func-
tions that can be defined for each value oft [eq. (2.158)], as well as by their behavior under 
convolution. 
At times it will be worthwhile to use an alternative notation for l>(t) and u(t), namely, 
l>(t) = uo(t), 
u(t) = U-t (t). 
(2.159) 
(2.160) 
With this notation, uk(t) for k > 0 denotes the impulse response of a cascade of k differ-
entiators, u0(t) is the impulse response of the identity system, and, fork< 0, uk(t) is the 
impulse response of a cascade of lkl integrators. Furthermore, since a differentiator is the 
inverse system of an integrator, 
u(t) * Ut (t) = l>(t), 
or, in our alternative notation, 
U- t (t) * Ut (t) = uo(t). 
(2.161) 
More generally, from eqs. (2.148), (2.157), and (2.161), we see that for any integers k 
and r, 
(2.162) 
If k and rare both positive, eq. (2.162) states that a cascade of k differentiators followed by 
r more differentiators yields an output that is the ( k + r )th derivative of the input. Similarly, 
if k is negative and r is negative, we have a cascade of lkl integrators followed by another 
lrl integrators. Also, if k is negative and r is positive, we have a cascade of I~ integrators 
followed by r differentiators, and the overall system is equivalent to a cascade of lk + rl 
integrators if k + r < 0, a cascade of k + r differentiators if k + r > 0, or the identity system 
if k + r = 0. Therefore, by defining singularity functions in terms of their behavior under 
convolution, we obtain a characterization that allows us to manipulate them with relative 
ease and to interpret them directly in terms of their significance for LTI systems. Since 
this is our primary concern in the book, the operational definition for singularity functions 
that we have given in this section will suffice for our purposes.6 
6 As mentioned in Chapter 1, singularity functions have been heavily studied in the field of mathematics 
under the alternative names of generalized functions and distribution theory. The approach we have taken in 
this section is actually closely allied in spirit with the rigorous approach taken in the references given in footnote 
3 of Section 1.4. 

Chap.2 
Problems 
137 
2.6 SUMMARY 
In this chapter, we have developed important representations for LTI systems, both in dis-
crete time and in continuous time. In discrete time we derived a representation of signals 
as weighted sums of shifted unit impulses·, and we then used this to derive the convolution-
sum representation for the response of a discrete-time LTI system. In continuous time we 
.derived an analogous representation of continuous-time signals as weighted integrals of 
shifted unit impulses, and we used this to derive the convolution integral representation 
for continuous-time LTI systems. These representations are extremely important, as they 
allow us to compute the response of an LTI system to an arbitrary input in terms of the sys-
tem's response to a unit impulse. Moreover, in Section 2.3 the convolution sum and integral 
provided us with a means of analyzing the properties of LTI systems and, in particular, of 
relating LTI system properties, including causality and stability, to corresponding proper-
ties of the unit impulse response. Also, in Section 2.5 we developed an interpretation of 
the continuous-time unit impulse and other related singularity functions in terms of their 
behavior under convolution. This interpretation is particularly useful in the analysis of LTI 
systems. 
An important class of continuous-time systems consists of those described by linear 
constant-coefficient differential equations. Similarly, in discrete time, linear constant-
coefficient difference equations play an equally important role. In Section 2.4, we exam-
ined simple examples of differential and difference equations and discussed some of the 
properties of systems described by these types of equations. In particular, systems de-
scribed by linear constant-coefficient differential and difference equations together with 
the condition of initial rest are causal and LTI. In subsequent chapters, we will develop 
additional tools that greatly facilitate our ability to analyze such systems. 
Chapter 2 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
Extension problems introduce applications, concepts, or methods beyond those pre-
sented in the text. 
BASIC PROBLEMS WITH ANSWERS 
2.1. Let 
x[n] = S[n] + 2S[n- 1] - S[n - 3] 
and 
h[n] = 2S[n + 1] + 2S[n - 1]. 
Compute and plot each of the following convolutions: 
(a) Yt [n] = x[n] * h[n] 
(b) Y2[n] = x[n + 2] * h[n] 
(c) y3[n] = x[n] * h[n + 2] 

138 
Linear Time-Invariant Systems 
Chap. 2 
2.2. Consider the signal 
( 
)
n-1 
h[n] = ~ 
{u[n + 3] - u[n - 10]}. 
Express A and B in terms of n so that the following equation holds: 
h[n -
k] = 
2 
' 
-
-
. 
{ 
( !)n-k-1 
A < k < B 
0, 
elsewhere 
2.3. Consider an input x[n] and a unit impulse response h[n] given by 
x[n] = G J-
2 
u[n - 2], 
h[n] = u[n + 2]. 
Determine and plot the output y[n] = x[n] * h[n]. 
2.4. Compute and plot y[n] = x[n] * h[n], where 
2.5. Let 
x[n] = { 6: 
h[n] = { 1• 
0, 
3:sn:s8 
otherwise 
' 
4 :s n :s 15 
otherwise 
xn= 
an 
n= 
[ ] 
{ 
1, 
0 :s n :s 9 
d 
h[ ] 
{ 1, 
0 :s n :s N 
0, 
elsewhere 
0, 
elsewhere 
' 
where N :s 9 is an integer. Determine the value of N, given that y[n] = x[n] * h[n] 
and 
y[4] = 5, y[14] = 0. 
2.6. Compute and plot the convolution y[n] = x[n] * h[n], where 
(
1 )-n 
x[n] = 3 
u[ -n - 1] 
and 
h[n] = u[n- 1]. 
2.7. A linear systemS has the relationship 
00 
y[n] = ~ 
x[k]g[n - 2k] 
k = -oo 
between its input x[n] and its output y[n], where g[n] = u[n] - u[n - 4]. 

Chap. 2 
Problems 
(a) Determine y[n] when x[n] = 8[n - 1]. 
(b) Determine y[n] when x[n] = 8[n- 2]. 
(c) Is SLTI? 
(d) Determine y[n] when x[n] = u[n]. 
2.8. Determine and sketch the convolution of the following two signals: 
2.9. Let 
{ 
t + 1, 0 ~ t ~ 1 
x(t) = 
2 - t, 
1 < t ~ 2 , 
0, 
elsewhere 
h(t) = 8(t + 2) + 28(t + 1). 
h(t) = e21u(-t + 4) + e- 21u(t- 5). 
Determine A and B such that 
2.10. Suppose that 
{ 
- 2(t-r) 
e 
, 
h(t- T) = 
0, 
e2(t-r) , 
T<A 
A<T<B. 
B<T 
x(t) = { 6: 
0 ~ t ~ 1 
elsewhere 
and h(t) = x(tla), where 0 <a ~ 1. 
(a) Determine and sketch y(t) = x(t) * h(t). 
(b) If dy(t)/dt contains only three discontinuities, what is the value of a? 
2.11. Let 
x(t) = u(t - 3) - u(t - 5) 
and 
h(t) = e- 31 u(t). 
(a) Compute y(t) = x(t) * h(t). 
(b) Compute g(t) = (dx(t)/dt) * h(t). 
(c) How is g(t) related to y(t)? 
2.12. Let 
00 
y(t) = e- 1u(t) * L 8(t- 3k). 
k = - oo 
Show that y(t) = Ae- 1 for 0 ~ t < 3, and determine the value of A. 
139 

140 
Linear Time-Invariant Systems 
Chap.2 
2.13. Consider a discrete-time system S 1 with impulse response 
h[n] = G J 
u[n]. 
(a) Find the integer A such that h[n] - Ah[n- 1] = 5[n]. 
(b) Using the result from part (a), determine the impulse response g[n] of an LTI 
system S2 which is the inverse system of S I· 
2.14. Which of the following impulse responses correspond(s) to stable LTI systems? 
(a) h1(t) = e-<l - 2j)ru(t) 
(b) h2(t) = e- r cos(2t)u(t) 
2.15. Which of the following impulse responses correspond(s) to stable LTI systems? 
(a) h1[n] = ncos(-~n)u[n] 
(b) h2[n] = 3nu[-n + 10] 
2.16. For each of the following statements, determine whether it is true or false: 
(a) If x[n] = 0 for n < N1 and h[n] = 0 for n < N2, then x[n] * h[n] = 0 for 
n <N1 +N2. 
(b) If y[n] = x[n] * h[n], then y[n -
1] = x[n- 1] * h[n- 1]. 
(c) If y(t) = x(t) * h(t), then y( -t) = x( -t) * h( -t). 
(d) If x(t) = 0 for t > T1 and h(t) = 0 for t > T2, then x(t) * h(t) = 0 for t > 
T1 + T2. 
2.17. Consider an LTI system whose input x(t) and output y(t) are related by the differ-
ential equation 
d 
dty(t) + 4y(t) = x(t). 
The system also satisfies the condition of initial rest. 
(a) If x(t) = e<-l+3j)tu(t), what is y(t)? 
(P2.17- 1) 
(b) Note that <Re{x(t)} will satisfy eq. (P2.17-1) with (}le{y(t)}. Determine the out-
put y(t) of the LTI system if · 
x(t) = e- r cos(3t)u(t). 
2.18. Consider a causal LTI system whose input x[n] and output y[n] are related by the 
difference equation 
1 
y[n] = 4y[n- 1] + x[n]. 
Determine y[n] if x[n] = 5[n - 1]. 
2.19. Consider the cascade of the following two systems S 1 and S2, as depicted in Figure 
P2.19: 
w[nJ.,I 
s2 
1----t•~ y[n) 
Figure P2. 1 9 

Chap.2 
Problems 
S 1 : causal LTI, 
1 
w[n] = 2w[n - 1] + x[n]; 
S2 : causal LTI, 
y[n] = ay[n- 1] + {3w[n]. 
The difference equation relating x[n] and y[n] is: 
1 
3 
y[n] = - 8y[n- 2] + 4y[n- 1] + x[n]. 
(a) Determine a and {3. 
(b) Show the impulse response ofthe cascade connection of S1 and S2. 
2.20. Evaluate the following integrals: 
(a) f .:0"" uo(t) cos(t) dt 
(b) Jr? sin(27rt)8(t + 3)dt 
(C) e5 UJ (1 - T) COS(27TT) dT 
BASIC PROBLEMS 
2.21. Compute the convolution y[n] = x[n] * h[n] of the following pairs of signals: 
(a) x[n] = a
11
u[n], ) a ""' {3 
h[n] = {3
11u[n], 
(b) x[n] = h[n] = a
11u[n] 
(c) x[n] = (- ! )
11u[n- 4] 
h[n] = 4"u[2 -
n] 
(d) x[n] and h[n] are as in Figure P2.21. 
x[n] 
h[n) 
141 
•••• 
1I I I I I ••••• 
• ••• 
1I I I I I I ••• I I I I I I •••• 
- 1 0 1 2 3 4 5 
n 
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 
n 
Figure P2.21 
2.22. For each of the following pairs of waveforms, use the convolution integral to find the 
response y(t) of the LTI system with impulse response h(t) to the input x(t). Sketch 
your results. 
(a) x(t) = e-ar u(t)} (Do this both when a ""' {3 and when a = {3.) 
h(t) = e- f3ru(t) 

142 
(b) x(t) = u(t) - 2u(t - 2) + u(t - 5) 
h(t) = e21 u(l - t) 
(c) x(t) and h(t) are as in Figure P2.22(a). 
(d) x(t) and h(t) are as in Figure P2.22(b). 
(e) x(t) and h(t) are as in Figure P2.22(c). 
x(t) 
h(t) 
2 
One period of sin 'ITt 
2 
(a) 
x(t) 
(b) 
x(t) 
- 1 
(c) 
Linear Time-Invariant Systems 
Chap. 2 
h(t) 
4 
3 
h(t) 
- 1 
3 
2 
Figure P2.22 
2.23. Let h(t) be the triangular pulse shown in Figure P2.23(a), and let x(t) be the impulse 
train depicted in Figure P2.23(b). That is, 
+ oo 
x(t) = L B(t - kT). 
k= - oo 
Determine and sketch y(t) = .x(t) * h(t) for the following values ofT: 
(a) T = 4 
(b) T = 2 
(c) T = 3/2 
(d) T = 1 

Chap.2 
Problems 
143 
h(t) 
(a) 
···t t t t :r t t t t t t··· 
- 2T -T 
0 
T 
2T 
3T 
t 
(b) 
Figure P2.23 
2.24. Consider the cascade interconnection of three causal LTI systems, illustrated in Fig-
ure P2.24(a). The impulse response h2[n] is 
hz[n] = u[n] - u[n - 2], 
and the overall impulse response is as shown in Figure P2.24(b). 
x[n] 
h1[n] 
y[n] 
(a) 
- 1 0 1 2 3 4 5 6 7 
n 
(b) 
Figure P2.24 
(a) Find the impulse response h1 [n] . 
(b) Find the response of the overall system to the input 
x [n] = 5[n] - 5[n- 1]. 

144 
Linear Time-Invariant Systems 
Chap.2 
2.25. Let the signal 
y[n] = x[n] * h[n], 
where 
x[n] = 3
11u[ -n- 1] + G r 
u[n] 
and 
h[n] = (~ r 
u[n + 3]. 
(a) Determine y[n] without utilizing the distributive property of convolution. 
(b) Determine y[n] utilizing the distributive property of convolution. 
2.26. Consider the evaluation of 
y[n] = x, [n] * xz[n] * x3[n], 
where x, [n] = (0.5)11u[n], Xz[n] = u[n + 3], and x3[n] = 5[n] - 5[n - 1]. 
(a) Evaluate the convolution x1[n] * xz[n]. 
(b) Convolve the result of part (a) with x3[n] in order to evaluate y[n]. 
(c) Evaluate the convolution x2[n] * x3[n]. 
(d) Convolve the result of part (c) with x1 [h] in order to evaluate y[n]. 
2.27. We define the area under a continuous-time signal v(t) as 
Av = L+: v(t) dt. 
Show that if y(t) = x(t) * h(t), then 
Ay = AxAh. 
2.28. The following are the impulse responses of discrete-time LTI systems. Determine 
whether each system is causal and/or stable. Justify your answers. 
(a) h[n] = (~)
11 u[n] 
(b) h[n] = (0.8)"u[n + 2] 
(c) h[n] = <!)
11u[ - n] 
(d) h[n] = (5)
11u[3 - n] 
(e) h[n] = (-!)11u[n] + (1.01)
11u[n- 1] 
(f) h[n] = (- !)11u[n] + (l.Ol)11u[l - n] 
(g) h[n] = n(~)
11 u[n- 1] 
2.29. The following are the impulse responses of continuous-time LTI systems. Determine 
whether each system is causal and/or stable. Justify your answers. 
(a) h(t) = e-41 u(t - 2) 
(b) h(t) = e-61u(3- t) 
(c) h(t) = e- 21u(t +50) 
(d) h(t) = e21u( -1- t) 

Chap.2 
Problems 
145 
(e) h(t) = e- 6ltl 
(f) h(t) = te- 1 u(t) 
(g) h(t) = (2e-t -
e<r- IOO)/JOO)u(t) 
2.30. Consider the first-order difference equation 
y[n] + 2y[n - 1] = x[n]. 
Assuming the condition of initial rest (i.e., if x[n] = 0 for n < no, then y[n] = 0 for 
n < n0), find the impulse response of a system whose input and output are related by 
this difference equation. You may solve the problem by rearranging the difference 
equation so as to express y[ n] in terms of y[ n- 1] and x[ n] and generating the values 
of y[O], y[ + 1], y[ +2], .. . in that order. 
2.31. Consider the LTI system initially at rest and described by the difference equation 
y[n] + 2y[n - 1] = x[n] + 2x[n - 2]. 
Find the response of this system to the input depicted in Figure P2.31 by solving the 
difference equation recursively. 
x[n] 
..... 'r'fl I J',,_ •••• 
- 2- 1 0 1 2 3 4 
n 
Figure P2.31 
2.32. Consider the difference equation 
1 
y[n]- zy[n - 1] = x[n], 
(P2.32- 1) 
and suppose that 
x[n] = (~ J 
u[n]. 
(P2.32-2) 
Assume that the solution y[n] consists of the sum of a particular solution Yp[n] to 
eq. (P2.32-1) and a homogeneous solution Yh[n] satisfying the equation 
1 
Yh[n] -
zYh[n - 1] = 0. 
(a) Verify that the homogeneous solution is given by 
Yh[n] = AGJ 
(b) Let us consider obtaining a particular solution Yp[n] such that 
1 
(1 )n 
Yp[n]- zYp[n - 1] = 3' 
u[n]. 

' 146 
Linear Time-Invariant Systems 
Chap.2 
By assuming that Yp[n] is of the form B( ~ )n for n 2: 0, and substituting this in 
the above difference equation, determine the value of B. 
(c) Suppose that the LTI system described by eq. (P2.32-1) and initially at rest has 
as its input the signal specified by eq. (P2.32-2). Since x[n] = 0 for n < 0, we 
have that y[n] = 0 for n < 0. Also, from parts (a) and (b) we have that y[n] 
has the form 
for n :::: 0. Iri order to solve for the unknown constant A, we must specify a value 
for y[n] for some n :::: 0. Use the condition of initial rest and eqs. (P2.32-1) 
and (P2.32-2) to determine y[O]. From this value determine the constant A. The 
result of this calculation yields the solution to the difference equation (P2.32- 1) 
under the condition of initial rest, when the input is given by eq. (P2.32-2). 
2.33. Consider a system whose input x(t) and output y(t) satisfy the first-order differential 
equation 
dy(t) 
dt + 2y(t) = x(t). 
(P2.33- 1) 
The system also satisfies the condition of initial rest. 
(a) (i) 
Determine the system output y 1 (t) when the input is x 1 (t) = e31 u(t). 
(ii) Determine the system output y2(t) when the input is x2(t) = e21 u(t). 
(iii) Determine the system output y3(t) when the input is x3(t) = ae31u(t) + 
{3 e21 u(t), where a and {3 are real numbers. Show that y3(t) = ay1 (t) + 
{3 Y2(t). 
(iv) Now let x1 (t) and x2(t) be arbitrary signals such that 
xi(t) = 0, fort< t1, 
x2(t) = 0, fort < t2. 
Letting y1 (t) be the system output for input x 1 (t), Y2(t) be the system output 
for input x2(t), and y3(t) be the system output for x3(t) = ax1 (t) + f3x2(t), 
show that 
We may therefore conclude that the system under consideration is linear. 
(b) (i) ' Determine the system output y1 (t) when the input is x 1 (t) = K e21 u(t). 
(ii) Determine the system output y2(t) when the input is x2(t) = Ke2<t-T) 
u(t ..:.. T). Show that Y2(t) = Yt (t - T). 
(iii) Now let x 1 (t) be an arbitrary signal such that Xi (t) = 0 fort < t0. Letting 
Yi (t) be the system output for input Xi (t) and Y2(t) be the system output 
for x2(t) = Xi (t - T), show that 
Yz(t) = Y1 (t - T). 

Chap.2 
Problems 
147 
We may therefore conclude that the system under consideration is time 
invariant. In conjunction with the result derived in part (a), we conclude 
that the given system is LTI. Since this system satisfies the condition of 
initial rest, it is causal as well. 
2.34. The initial rest assumption corresponds to a zero-valued auxiliary condition being 
imposed at a time determined in accordance with the input signal. In this problem 
we show that if the auxiliary condition used is nonzero or if it is always applied at a 
fixed time (regardless of the input signal) the corresponding system cannot be LTI. 
Consider a system whose input x(t) and output y(t) satisfy the first-order differential 
equation (P2.33-1). 
(a) Given the auxiliary condition y(l) = 1, use a counterexample to show that the 
system is not linear. 
(b) Given the auxiliary condition y(l) = 1, use a counterexample to show that the 
system is not time invariant. 
(c) Given the auxiliary condition y(l) = 1, show that the system is incrementally 
linear. 
(d) Given the auxiliary condition y(1) = 0, show that the system is linear but not 
time invariant. 
(e) Given the auxiliary condition y(O) + y(4) = 0, show that the system is linear 
but not time invariant. 
2.35. In the previous problem we saw that application of an auxiliary condition at a fixed 
time (regardless of the input signal) leads to the corresponding system being not 
time-invariant. In this problem, we explore the effect of fixed auxiliary conditions on 
the causality of a system. Consider a system whose input x(t) and output y(t) satisfy 
the first-order differential equation (P2.33-1). Assume that the auxiliary condition 
associated with the differential equation is y(O) = 0. Determine the output of the 
system for each of the following two inputs: 
(a) x1 (t) = 0, for all t 
(b) X2(t) = { 01,, 
t < - 1 
t > - 1 
Observe that if y1 (t) is the output for input x1 (t) and y2(t) is the output for input 
x2(t), then Yt (t) and Y2(t) are not identical fort< -1, even though x1 (t) and x2(t) 
are identical fort < - 1. Use this observation as the basis of an argument to conclude 
that the given system is not causal. 
2.36. Consider a discrete-time system whose input x[n] and output y[n] are related by 
y[n] = G 
)y[n - 1] + x[n]. 
(a) Show that if this system satisfies the condition of initial rest (i.e., if x[n] = 0 
for n < n0, then y[n] = 0 for n < n0), then it is linear and time invariant. 
(b) Show that if this system does not satisfy the condition of initial rest, but instead 
uses the auxiliary condition y[O] = 0, it is not causal. [Hint: Use an approach 
similar to that used in Problem 2.35.] 

148 
Linear Time-Invariant Systems 
Chap. 2 
2.37. Consider a system whose input and output are related by the first-order differential 
equation (P2.33-1). Assume that the system satisfies the condition of final rest [i.e., 
if x(t) = 0 fort > to, then y(t) = 0 fort > to] . Show that this system is not causal. 
[Hint: Consider two inputs to the system, x1 (t) = 0 and x2(t) = e1(it(t)- u(t- 1)), 
which result in outputs YI (t) and Y2(t), respectively. Then show that y1 (t) .:P y2(t) 
fort< 0.] 
2.38. Draw block diagram representations for causal LTI systems described by the fol-
lowing difference equations: 
(a) y[n] = 1y[n- 1] + !x[n] 
(b) y[n] = 1y[n- 1] + x[n- 1] 
2.39. Draw block diagram representations for causal LTI systems described by the fol-
lowing differential equations: 
(a) y(t) = -(!)dy(t)ldt + 4x(t) 
(b) dy(t)ldt + 3y(t) = x(t) 
ADVANCED PROBLEMS 
2.40. (a) Consider an LTI system with input and output related through the equation 
y(t) = L"' e-<r- -r)x(T- 2)dr. 
What is the impulse response h(t) for this system? 
(b) Determine the response of the system when the input x(t) is as shown in Figure 
P2.40. 
x(t) 
, I 
- 1 
2 
2.41. Consider the signal 
x[n] = anu[n]. 
(a) Sketch the signal g[n] = x[n] - ax[n - 1]. 
Figure P2.40 
(b) Use the result of part (a) in conjunction with properties of convolution in order 
to determine a sequence h[n] such that 
x[n] * h[n] = G J 
{u[n + 2] - u[n - 2]}. 
2.42. Suppose that the signal 
x(t) = u(t + 0.5) - u(t - 0.5) 

Chap. 2 
Problems 
149 
is convolved with the signal 
(a) Determine a value of w0 which ensures t:Qat 
y(O) = 0, 
where y(t) = x(t) * h(t). 
(b) Is your answer to the previous part unique? 
2.43. One of the important properties of convolution, in both continuous and discrete time, 
is the associativity property. In this problem, we will check and illustrate this prop-
erty. 
(a) Prove the equality 
[x(t) * h(t)] * g(t) = x(t) * [h(t) * g(t)] 
by showing that both sides of eq. (P2.43- 1) equal 
f 
+ oo f 
+ oo 
- oo 
-oo x( r)h(u)g(t -
T - u) dr du. 
(P2.43- l) 
(b) Consider two LTI systems with the unit sample responses h1 [n] and h2[n] 
shown in Figure P2.43(a). These two systems are cascaded as shown in Figure 
P2.43(b). Let x[n] = u[n]. 
1 
4 
3 
2 
0 1 2 3 4 
(a) 
n 
n 
x[n] 
(b) 
Figure P2.43 

150 
Linear Time-Invariant Systems 
Chap. 2 
(i) 
Compute y[n] by first computing w[n] = x[n] * h 1 [n] and then computing 
y[n] = w[n] * h2[n]; that is, y[n] = [x[n] * ht[n]] * h2[n]. 
(ii) Now find y[n] by first convolving h1[n] and h2[n] to obtain g[n] 
h 1 [n] * h2[n] and then convolving x[n] with g[n] to obtain y[n] 
x[n] * [ht [n] * h2[n]]. 
The answers to (i) and (ii) should be identical, illustrating the associativity prop-
erty of discrete-time convolution. 
(c) Consider the cascade of two LTI systems as in Figure P2.43(b), where in this 
case 
ht [n] = sin 8n 
and 
h2[n] = a
11u[n], 
Jal < 1, 
and where the input is 
x[n] = 5[n] - a5[n- 1]. 
Determine the output y[n]. (Hint: The use of the associative and commutative 
properties of convolution should greatly facilitate the solution.) 
2.44. (a) If 
x(t) = 0, ltl > T1, 
and 
h(t) = 0, ltl > T2, 
then 
x(t) * h(t) = 0, ltl > T3 
for some positive number T3 . Express T3 in terms of T1 and T2. 
(b) A discrete-time LTI system has input x[n], impulse response h[n], and output 
y[n] . If h[n] is known to be zero everywhere outside the interval No ~ n ~ 
N1 and x[n] is known to be zero everywhere outside the interval N2 ~ n ~ 
N3 , then the output y[n] is constrained to be zero everywhere, except on some 
interval N4 ~ n ~ Ns. 
(i) 
Determine N4 and Ns in terms of No, Nt. N2, and N3. 
(ii) If the interval No ~ n ~ N1 is of length Mh, N2 ~ n ~ N3 is of length 
Mx, and N4 ~ n ~ N5 is of length My. express My in terms of Mh 
andMx. 
(c) Consider a discrete-time LTI system with the property that if the input x[n] = 0 
for all n 2:: 10, then the output y[n] = 0 for all n 2:: 15. What condition must 
h[n], the impulse response of the system, satisfy for this to be true? 
(d) Consider an LTI system with impulse response in Figure P2.44. Over what in-
terval must we know x(t) in order to determine y(O)? 

Chap. 2 
Problems 
151 
h(t) 
-2 - 1 
6 
Figure P2.44 
2.45. (a) Show that if the response of an LTI system to x(t) is the output y(t), then the 
response of the system to 
x'(t) = dx(t) 
dt 
is y'(t). Do this problem in three different ways: 
(i) Directly from the properties of linearity and time invariance and the fact 
that 
'( ) _ 1. 
x(t) - x(t- h) 
x t-1m 
h 
. 
h->0 
(ii) By differentiating the convolution integral. 
(iii) By examining the system in Figure P2.45. 
x(t) 
y'(t) 
Figure P2.45 
(b) Demonstrate the validity of the following relationships: 
(i) y'(t) = x(t) * h'(t) 
(ii) y(t) = (J~ ""x(r)dr) * h'(t) = C oo[x'(r) * h(T)]dT = x'(t) * (J~ 00h(r)dr) 
[Hint: These are easily done using block diagrams as in (iii) of part (a) and the 
fact that u1 (t) * u_ 1 (t) = c5(t).] 
(c) An LTI system has the response y(t) = sinw0t to input x(t) = e-51u(t). Use 
the result of part (a) to aid in determining the impulse response of this system. 
(d) Let s(t) be the unit step response of a continuous-time LTI system. Use part (b) 
to deduce that the response y(t) to the input x(t) is 
+oo 
y(t) = J 
x'(r)s(t-r)dr . 
- oo 
(P2.45-1) 
Show also that 
f 
+oo 
x(t) = 
-co x'(r)u(t - r)dT. 
(P2.45-2) 

152 
Linear Time-Invariant Systems 
Chap. 2 
(e) Use eq. (P2.45-1) to determine the response of an LTI system with step response 
s(t) = (e- 31 - 2e-21 + l)u(t) 
to the input x(t) = e1 u(t). 
(f) Let s[n] be the unit step response of a discrete-time LTI system. What are the 
discrete-time counterparts of eqs. (P2.45-1) and (P2.45-2)? 
2.46. Consider an LTI systemS and a signal x(t) = 2e- 31u(t- 1). If 
x(t)-- y(t) 
and 
dx(t) 
---;[(-- - 3y(t) + e-21u(t), 
determine the impulse response h(t) of S: 
2.47. We are given a certain linear time-invariant system with impulse response h0(t). We 
are told that when the input is x0(t) the output is y0(t), which is sketched in Figure 
P2.47. We are then given the following set of inputs to linear time-invariant systems 
with the indicated impulse responses: 
Input x(t) 
(a) x(t) = 2xo(t) 
(b) x(t) = xo(t) - xo(t- 2) 
(c) x(t) = xo(t - 2) 
(d) x(t) = xo( -t) 
(e) x(t) = xo( -t) 
(f) x(t) = x0(t) 
Impulse response h(t) 
h(t) = h0(t) 
h(t) = h0(t) 
h(t) = h0(t + 1) 
h(t) = h0(t) 
h(t) = h0( -t) 
h(t) = hb(t) 
[Here x0(t) and h0(t) denote the first derivatives of x0(t) and h0(t), respectively.] 
Yo(t) 
lz..,.._: --
0 
2 
Figure P2.47 
In each of these cases, determine whether or not we have enough information 
to determine the output y(t) when the input is x(t) and the system has impulse re-
sponse h(t). If it is possible to determine y(t), provide an accurate sketch of it with 
numerical values clearly indicated on the graph. 

Chap.2 
Problems 
153 
2.48. Determine whether each of the following statements concerning LTI systems is true 
or false. Justify your answers. 
(a) If h(t) is the impulse response of an LTI system and h(t) is periodic and nonzero, 
the system is unstable. 
(b) The inverse of a causal LTI system is always causal. 
(c) If lh[nll :5 K for each n, where K is a given number, then the LTI system with 
h[n] as its impulse response is stable. 
(d) If a discrete-time LTI system has an impulse response h[n] of finite duration, 
the system is stable. 
(e) If an LTI system is causal, it is stable. 
(t) The cascade of a noncausal LTI system with a causal one is necessarily non-
causal. 
(g) A continuous-time LTI system is stable if and only if its step response s(t) is 
absolutely integrable-
that is, if and only if 
I 
+ oo 
- oo ls(t)l dt < oo. 
(h) A discrete-time LTI system is causal if and only if its step response s[n] is zero 
for n < 0. 
2.49. In the text, we showed that if h[n] is absolutely summable, i.e., if 
+ oo 
2:: lh[kll < oo, 
k = - oo 
then the LTI system with impulse response h[n] is stable. This means that absolute 
summability is a sufficient condition for stability. In this problem, we shall show 
that it is also a necessary condition. Consider an LTI system with impulse response 
h[n] that is not absolutely summable; that is, 
+ oo 
2:: lh[kll = 00• 
k = - oo 
(a) Suppose that the input to this system is 
{ 
0, 
x[n] = 
h[- n] 
Jh[- n]J' 
ifh[- n]=O 
ifh[-n]#O' 
Does this input signal represent a bounded input? If so, what is the smallest 
number B such that 
lx[nll :5 B for all n? 

154 
Linear Time-Invariant Systems 
Chap.2 
(b) Calculate the output at n = 0 for this particular choice of input. Does the re-
sult prove the contention that absolute summability is a necessary condition for 
stability? 
(c) In a similar fashion, show that a continuous-time LTI system is stable if and 
only if its impulse response is absolutely integrable. 
2.50. Consider the cascade of two systems shown in Figure P2.50. The first system, A, is 
known to be LTI. The second system, B, is known to be the inverse of system A. Let 
Yt (t) denote the response of system A to x 1 (t), and let y2(t) denote the response of 
systemA to x2(t). 
>(t) -l s,'fm I y(t) •I Sy~m t-1----,~•~ x(t) 
Figure P2.50 
(a) What is the response of system B to the input ay1 (t) + by2(t), where a and bare 
constants? 
(b) What is the response of system B to the input y 1 ( t - T)? 
2.51. In the text, we saw that the overall input-output relationship of the cascade of two 
LTI systems does not depend on the order in which they are cascaded. This fact, 
known as the commutativity property, depends on both the linearity and the time 
in variance of both systems. In this problem, we illustrate the point. 
(a) Consider two discrete-time systems A and B, where system A is an LTI system 
with unit sample response h[n] = (l/2)nu[n]. System B, on the other hand, is 
linear but time varying. Specifically, if the input to system B is w[n], its output 
is 
x[n] 
z[n] = nw[n]. 
Show that the commutativity property does not hold for these two systems 
by computing the impulse responses of the cascade combinations in Figures 
P2.51(a) and P2.51(b), respectively. 
1-----t~ System 
8 
(a) 
y[n] 
x[n) 
Figure P2. 51 
1-----t~ System 
A 
(b) 
y[n] 
(b) Suppose that we replace system B in each of the interconnected systems of 
Figure P2.51 by the system with the following relationship between its input 
w[n] and output z[n]: 
z[n] = w[n] + 2. 
Repeat the calculations of part (a) in this case. 

Chap.2 
Problems 
2.52. Consider a discrete-time LTI system with unit sample response 
h[n] = (n + 1)a
11u[n], 
where Ia I < 1. Show that the step response of this system is 
s[n] = [(a ~ 1)2 - (a ~ 1)2 an + (a~ 1) (n + l)an] u[n]. 
(Hint: Note that 
2.53. (a) Consider the homogeneous differential equation 
~ dky(t) - 0 
Lak-dk -
. 
k =O 
t 
Show that if so is a solution of the equation 
N 
p(s) = L aksk = 0, 
k =O 
155 
(P2.53-1) 
(P2.53-2) 
then Aesot is a solution of eq. (P2.53- l), where A is an arbitrary complex con-
stant. 
(b) The polynomial p(s) in eq. (P2.53- 2) can be factored ih terms of its roots 
SJ, . .• , Sr as 
where the si are the distinct solutions of eq. (P2.53-2) and the (J'i are their 
multiplicities-that is, the number of times each root appears as a solution of 
the equation. Note that 
(]' ! + (]'2 + · · · + (J'r = N. 
In general, if (J'i > 1, then not only is Aes;t a solution of eq. (P2.53- l), 
but so is Atj es;t, as long as j is an integer greater than or equal to zero and less 
than or equal to (J'i -
1. To illustrate this, show that if (J'i = 2, then Ates;t is a 
solution of eq. (P2.53-l). [Hint: Show that if sis an arbitrary complex number, 
then 

156 
Linear Time-Invariant Systems 
Chap. 2 
Thus, the most general solution of eq. (P2.53-1) is 
r u; - l 
~ 
~ 
Aijfj es;t, 
i=l j =O 
where the Aij are arbitrary complex constants. 
(c) Solve the following homogeneous differential equations with the specified aux-
iliary conditions: 
(i) d~wl + 3d~~tl + 2y(t) = 0, y(O) = 0, y'(O) = 2 
(ii) d~wl + 3d~~tl + 2y(t) = 0, y(O) = 1, y'(O) = -1 
(iii) d~~tl + 3d~~tl + 2y(t) = 0, y(O) = 0, y'(O) = 0 
(iv) d:~tl + 2d~~tl + y(t) = 0, y(O) = 1, y'(O) = 1 
(v) d~7irl + d:7~rl -
d~~tl - y(t) = 0, y(O) = 1, y'(O) = 1, y"(O) = -2 
(vi) d:~tl + 2d~~tl + Sy(t) = 0, y(O) = 1, y'(O) = 1 
2.54. (a) Consider the homogeneous difference equation 
N 
~aky[n- k] = 0, 
k=O 
Show that if Zo is a solution of the equation 
N 
~akz-k = 0, 
k=O 
(P2.54-1) 
(P2.54-2) 
then Az0 is a solution of eq. (P2.54-1 ), where A is an arbitrary constant. 
(b) As it is more convenient for the moment to work with polynomials that have 
only nonnegative powers of z, consider the equation obtained by multiplying 
both sides of eq. (P2.54-2) by zN: 
N 
p(z) = ~ 
ak~-k = 0. 
k=O 
The polynomial p(z) can be factored as 
p(z) = ao(z -
Zl )u1 ••• (z -
Zr )u', 
where the z1, ••• , Zr are the distinct roots of p(z). 
Show that if y[n] = nzn-l, then 
± 
aky[n- k] = dp(z) zn- N + (n- N)p(z)zn-N-l . 
k=O 
dz 
(P2.54-3) 
Use this fact to show that if ui = 2, then both Az? and Bnz?- 1 are solutions of 
eq. (P2.54-1), where A and Bare arbitrary complex constants. More generally, 
one can use this same procedure to show that if ui > 1, then 

Chap. 2 
Problems 
157 
A 
n! 
zn-r 
r!(n- r)! 
is a solution of eq. (P2.54-1) for r = 0, 1, ... , u; - 1.7 
(c) Solve the following homogeneous difference equations with the specified aux-
iliary conditions: 
(i) y[n] + ~y[n - 1] + iy[n- 2] = 0; y[O] = 1, y[ - 1] = - 6 
(ii) y[n] - 2y[n - 1] + y[n - 2] = 0; y[O] = 1, y[l] = 0 
(iii) y[n] - 2y[n- 1] + y[n- 2] = 0; y[O] = 1, y[lO] = 21 
(iv) y[n] -fy[n- 1] + ~y[n - 2] = 0; y[O] = 0, y[ -1] = 1 
2.55. In the text we described one method for solving linear constant-coefficient difference 
equations, and another method for doing this was illustrated in Problem 2.30. If the 
assumption of initial rest is made so that the system described by the difference 
equation is LTI and causal, then, in principle, we can determine the unit impulse 
response h[n] using either of these procedures. In Chapter 5, we describe another 
method that allows us to determine h[n] in a more elegant way. In this problem we 
describe yet another approach, which basically shows that h[n] can be determined 
by solving the homogeneous equation with appropriate initial conditions . 
. (a) Consider the system initially at rest and described by the equation 
1 
y[n]- 2y[n- 1] = x[n]. 
(P2.55-1) 
Assuming that x[n] = S[n], what is y[O]? What equation does h[n] satisfy 
for n 2': 1, and with what auxiliary condition? Solve this equation to obtain 
a closed-form expression for h[n]. 
(b) Consider next the LTI system initially at rest and described by the difference 
equation 
1 
y[n] - 2y[n - 1] = x[n] + 2x[n - 1]. 
(P2.55- 2) 
This system is depicted in Figure P2.55( a) as a cascade of two LTI systems that 
are initially at rest. Because of the properties of LTI systems, we can reverse 
the order of the systems in the cascade to obtain an alternative representation 
of the same overall system, as illustrated in Figure P2.55(b). From this fact, 
use the result of part (a) to determine the impulse response for the system de-
scribed by eq. (P2.55-2). 
(c) Consider again the system of part (a), with h[n] denoting its impulse response. 
Show, by verifying that eq. (P2.55-3) satisfies the difference equation(P2.55-
1), that the response y[n] to an arbitrary input x[n] is in fact given by the con-
volution sum 
+co 
y[n] = 2.:: h[n - m]x[m]. 
(P2.55-3) 
m= -oo 
7Here, we are using factorial notation-that is, k! = k( k - 1 )( k - 2) . . . (2)(1 ), where 0! is defined to be l. 

158 
Linear Time-Invariant Systems 
Chap.2 
x[n] ...... 
z[n] 
z[n] = x[n] + 2x[n - 1] 
y[n]- ~y[n - 1] = z[n] 
~ 
y[n] 
(a) 
x[n] 
w[n]- ~w[n-1] = x[n] 
w[n] 
...... 
y[n] = w[n] + 2w[n- 1] ~ 
y[n] 
(b) 
Figure P2.55 
(d) Consider the LTI system initially at rest and described by the difference equa-
tion 
N .2: aky[n - k] = x[n]. 
k=O 
(P2.55-4) 
Assuming that ao ¥= 0, what is y[O] if x[n] = o[n]? Using this result, specify 
the homogeneous equation and initial conditions that the impulse response of 
the system must satisfy. 
Consider next the causal LTI system described by the difference equation 
N 
M 
.2: aky[n - k] = .2: bkx[n - k]. 
(P2.55-5) 
k=O 
k=O 
Express the impulse response of this system in terms of that for the LTI system 
described by eq. (P2.55- 4). 
(e) There is an alternative method for determining the impulse response of the LTI 
system described by eq. (P2.55-5). Specifically, given the condition of initial 
rest, i.e., in this case, y[ - N] = y[ -N + 1] = .. . = y[ -1] = 0, solve eq. 
(P2.55- 5) recursively when x[n] = o[n] in order to determine y[O], .. . , y[M]. 
What equation does h[n] satisfy for n ~ M? What are the appropriate initial 
conditions for this equation? 
(f) Using either of the methods outlined in parts (d) and (e), find the impulse re-
sponses of the causal LTI systems described by the following equations: 
(i) y[n] - y[n - 2] = x[n] 
(ii) y[n] - y[n - 2] = x[n] + 2x[n -
1] 
(iii) y[n] - y[n - 2] = 2x[n] - 3x[n - 4] 
(iv) y[n]- (J312)y[n- 1] + ky[n- 2] = x[n] 
2.56. In this problem, we consider a procedure that is the continuous-time counterpart of 
the technique developed in Problem 2.55. Again, we will see that the problem of 
determining the impulse response h(t) for t > 0 for an LTI system initially at rest 
and described by a linear constant-coefficient differential equation reduces to the 
problem of solving the homogeneous equation with appropriate initial conditions. 

Chap. 2 
Problems 
159 
(a) Consider the LTI system initially at rest and described by the differential equa-
tion 
dy(t) 
-----;[( + 2y(t) = x(t). 
(P2.56-1) 
Suppose that x(t) = 5(t). In order to determine the value of y(t) immediately 
after the application of the unit impulse, consider integrating eq. (P2.56-l) from 
t = o- to t = o+ (i.e., from "just before" to ''just after" the application of the 
impulse). This yields 
(o+ 
(o+ 
y(O+)- y(O- ) + 2 Jo- y(T)dT = Jo- 5(T)dT = 1. 
(P2.56-2) 
Since the system is initially at rest and x(t) = 0 fort < 0, y(O- ) = 0. To satisfy 
eq. (P2.56-2) we must have y(O+) = 1. Thus, since x(t) = 0 fort> 0, the 
impulse response of our system is the solution of the homogeneous differential 
equation 
with initial condition 
dy(t) 
2 () - 0 
- -+ yt-
dt 
Solve this differential equation to obtain the impulse response h(t) for the sys-
tem. Check your result by showing that 
I 
+ co 
y(t) = 
-co h(t- T)X(T)dT 
satisfies eq. (P2.56-l) for any input x(t). 
(b) To generalize the preceding argument, consider an LTI system initially at rest 
and described by the differential equation 
N 
dky(t) 
.2:ak-k- = x(t) 
k =O 
dt 
(P2.56-3) 
with x(t) = 5(t). Assume the condition of initial rest, which, since x(t) = 0 for 
t < 0, implies that 
-
dy 
-
dN- ly -
y(O ) = d/0 ) = ... = dtN- 1 (0 ) = 0. 
(P2.56-4) 
Integrate both sides of eq. (P2.56-3) once from t = o- to t = o+, and use 
eq. (P2.56-4) and an argument similar to that used in part (a) to show that the 

160 
x(t) 
Linear Time-Invariant Systems 
Chap. 2 
resulting equation is satisfied with 
0
+ 
dy 
+ 
dN- 2y 
+ 
y( 
) = dt (0 ) = ... = dtN- 2 (0 ) = 0 
(P2.56-5a) 
and 
dN- I)' 
1 
dtN - l (0 +) = aN' 
(P2.56-5b) 
Consequently, the system's impulse response fort > 0 can be obtained by solv-
ing the homogeneous equation 
..f!:, 
dky(t) - 0 
Lak-
-
-
k=O 
dtk 
with initial conditions given by eqs. (P2.56-5)! 
(c) Consider now the causal LTI system described by the differential equation 
N 
dk y(t) 
M 
dk X(t) 
Lak - d k = Lbk-d 
k . 
(P2.56-6) 
k=O 
t 
k=O 
t 
Express the impulse response of this system in terms of that for the system of 
part (b). (Hint: Examine Figure P2.56.) 
N 
d'W(t) 
~ ak -k- = x(t) 
k = 0 
dt 
w(t) 
M 
d'W(t) 
1---to~ y(t) = 
~ bk -k-
k = 0 
dt 
y(t) 
Figure P2.56 
(d) Apply the procedures outlined in parts (b) and (c) to find the impulse responses 
for the LTI systems initially at rest and described by the following differential 
equations: 
(i) d~~~r) + 3 d~~r) + 2y(t) = x(t) 
(ii) d~~r) + 2d~~t) + 2y(t) = x(t) 
(e) Use the results of parts (b) and (c) to deduce that if M ;:;: N in eq. (P2.56-6), 
then the impulse response h(t) will contain singularity terms concentrated at 
t = 0. In particular, h(t) will contain a term of the form 
M- N 
L a,u,(t), 
r=O 
where the a, are constants and the u,(t) are the singularity functions defined in 
Section 2.5. 
(0 Find the impulse responses of the causal LTI systems described by the following 
differential equations: 
(i) 
d~~r) + 2y(t) = 3 d~~r) + x(t) 
(ii) d2yit) + 5dy(t) + 6y(t) = d3x(t) + 2d2x(t) + 4dx(t) + 3x(t) 
d t 
d t 
"""Ji3 
(jJ2 
d t 

Chap. 2 
Problems 
161 
2.57. Consider a causalLTI systemS whose input x[n] and output y[n] are related by the 
difference equation 
y[n] = -ay[n - 1] + box[n] + b1x[n - 1]. 
(a) Verify that S may be considered a cascade connection of two causal LTI systems 
sl and s2 with the following input-output relationship: 
S, : Yl [n] = box! [n] + b, x, [n - 1], 
S2 : Y2[n] = - ay2[n - 1] + x2[n]. 
(b) Draw a block diagram representation of S 1. 
(c) Draw a block diagram representation of S2• 
(d) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S 1 followed by the block diagram representation 
of S2. 
(e) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S2 followed by the block diagram representation 
ofS1. 
(f) Show that the two unit-delay elements in the block diagram representation of S 
obtained in part (e) may be collapsed into one unit-delay element. The result-
ing block diagram is referred to as a Direct Form II realization of S, while the 
block diagrams obtained in parts (d) and (e) are referred to as Direct Form I 
realizations of S. 
2.58. Consider a causal LTI systemS whose input x[n] and output y[n] are related by the 
difference equation 
2y[n] - y[n - 1] + y[n - 3] = x[n] - Sx[n - 4]. 
(a) Verify that S may be considered a cascade connection of two causal LTI systems 
sl and s2 with the following input-output relationship: 
S1 : 2yl [n] = x, [n] - Sx, [n - 4], 
1 
1 
s2: Y2[n] = 2Y2[n - 1]- 2Y2[n- 3] + X2[n]. 
(b) Draw a block diagram representation of S 1• 
(c) Draw a block diagram representation of S2. 
(d) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S 1 followed by the block diagram representation 
of s2. 
(e) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S2 followed by the block diagram representation 
of S1• 
(f) Show that the four delay elements in the block diagram representation of S 
obtained in part (e) may be collapsed to three. The resulting block diagram 
is referred to as a Direct Form II realization of S, while the block diagrams 
obtained in parts (d) and (e) are referred to as Direct Form I realizations of S. 

162 
Linear Time-Invariant Systems 
Chap. 2. 
2.59. Consider a causal LTI system S whose input x(t) and output y(t) are related by the 
differential equation 
dy(t) 
dx(t) 
a1 ----;[( + aoy(t) = box(t) + b1 ----;[(' 
(a) Show that 
y(t) = A t
00y(r)dT + Bx(t) + C t oo x(r)dT, 
and express the constants A, B, and C in terms of the constants a0, a1, b0, 
andb1. 
(b) Show that S may be considered a cascade connection of the following two causal 
LTI systems: 
sl: YI(t) = Bxl(t) + ctoox(r)dT, 
s2 : Y2(t) = A f ooY2( T) dr + X2(t). 
(c) Draw a block diagram representation of S1• 
(d) Draw a block diagram representation of S2. 
(e) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S1 followed by the block diagram representation 
of s2. 
(t) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S2 followed by the block diagram of representa-
tions(. 
(g) Show that the two integrators in your answer to part (f) may be collapsed into 
one. The resulting block diagram is referred to as a Direct Form II realization 
of S, while the block diagrams obtained in parts (e) and (f) are referred to as 
Direct Form I realizations of S. 
2.60. Consider a causal LTI system S whose input x(t) and output y(t) are related by the 
differential equation 
(a) Show that 
y(t) = At
00y(r)dr+Bt oo U~
00y(o-)do-)dT 
+ Cx(t) + Dtoo x(r)dT + E t oo u~oo x(o-)dO') dT, 

Chap.2 
Problems 
163 
and express the constants A, B, C, D, and E in terms of the constants ao, a1, a2, 
bo, b,, and b2. 
(b) Show that S may be considered a cascade connection of the following two causal 
LTI systems: 
S1 :y1(t) = Cx 1 (t)+D( oox,(r)dr+Et oo U~ooXJ((J')d(J')dr, 
s2 : Y2(t) = A t ooY2( r) dr + B t oo (fooY2((J') d(J') dr + Xz(t). 
(c) Draw a block diagram representation of S1• 
(d) Draw a block diagram representation of S2. 
(e) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of S 1 followed by the block diagram representation 
of s2. 
(f) Draw a block diagram representation of S as a cascade connection of the block 
diagram representation of s2 followed by the block diagram representation 
of S1. 
(g) Show that the four integrators in your answer to part (f) may be collapsed into 
two. The resulting block diagram is referred to as a Direct Form II realization 
of S, while the block diagrams obtained in parts (e) and (f) are referred to as 
Direct Form I realizations of S. 
EXTENSION PROBLEMS 
2.61. (a) In the circuit shown in Figure P2.61(a), x(t) is the input voltage. The voltage 
y(t) across the capacitor is considered to be the system output. 
L=1H 
C = 1F 
(a) 
Figure P2.61a 
(i) Determine the differential equation relating x(t) and y(t). 
(ii) Show that the homogeneous solution of the differential equation from part 
(i) has the form K1ejw,t + K2ejw21• Specify the values of w, and w2. 
(iii) Show that, since the voltage and current are restricted to be real, the natUral 
response of the system is sinusoidal. 

164 
Linear Time-Invariant Systems 
Chap.2 
(b) In the circuit shown in Figure P2.6l(b), x(t) is the input voltage. The voltage 
y(t) across the capacitor is considered to be the system output. 
R = 10 
x(t) 
+ 
C =1F 
x(t) 
+ 
(b) 
Figure P2.61b 
(i) Determine the differential equation relating x(t) and y(t). 
(ii) Show that the natural response of this system has the form K e-at, and spec-
ify the value of a. 
(c) In the circuit shown in Figure P2.61(c), x(t) is the input voltage. The voltage 
y(t) across the capacitor is considered to be the system output. 
R = 20 
L = 1H 
y(t) 
(c) 
Figure P2.61c 
(i) Determine the differential equation relating x(t) and y(t). 
(ii) Show that the homogeneous solution of the differential equation from part 
(i) has the form e- at{K1 e121 + K2e-12'}, and specify the value of a. 
(iii) Show that, since the voltage and current are restricted to be real, the natural 
response of the system is a decaying sinusoid. 
2.62. (a) In the mechanical system shown in Figure P2.62(a), the force x(t) applied to 
the mass represents the input, while the displacement y(t) of the mass repre-
sents the output. Determine the differential equation relating x(t) and y(t). Show 
that the natural response of this system is periodic. 
(b) Consider Figure P2.62(b), in which the force x(t) is the input and the velocity 
y(t) is the output. The mass of the car ism, while the coefficient of kinetic fric-
tion is p. Show that the natural response of this system decays with increasing 
time. 
(c) In the mechanical system shown in Figure P2.62(c), the force x(t) applied to the 
mass represents the input, while the displacement y(t) of the mass represents 
the output. 

Chap.2 
Problems 
x(t) 
(a) 
(c) 
! x(t) 
K = Spring constant = 2 N/m 
m =Mass= 1 Kg 
(b) 
b = Damping constant = 2 N-s/m 
Figure P2.62 
(i) Determine the differential equation relating x(t) and y(t). 
165 
m = 1,000 Kg 
p = 0.1 N-s/m 
(ii) Show that the homogeneous solution of the differential equation from part 
(i) has the form e-a1{K1 ejt + K2e- jt}, and specify the value of a. 
(iii) Show that, since the force and displacement are restricted to be real, the 
natural response of the system is a decaying sinusoid. 

166 
Linear Time-Invariant Systems 
Chap.2 
2.63. A $100,000 mortgage is to be retired by equal monthly payments of D dollars. In-
terest, compounded monthly, is charged at the rate of 12% per annum on the unpaid 
balance; for example, after the first month, the total debt equals 
$100,000 + (
0
~~
2 )$100,000 = $101,000. 
The problem is to determine D such that after a specified time the mortgage is paid 
in full, leaving a net balance of zero. 
(a) To set up the problem, let y[n] denote the unpaid balance after the nth monthly 
payment. Assume that the principal is borrowed in month 0 and monthly pay-
ments begin in month 1. Show that y[n] satisfies the difference equation 
y[n] - yy[n - 1] = - D 
n :::::: 1 
(P2.63-1) 
with initial condition 
y[O] = $100,000, 
where y is a constant. Determine y. 
(b) Solve the difference equation of part (a) to determine 
y[n] 
for n :::::: 0. 
(Hint: The particular solution of eq. (P2.63-1) is a constant Y. Find the value 
of Y, and express y[n] for n :::::: 1 as the sum of particular and homogeneous 
solutions. Determine the unknown constant in the homogeneous solution by 
directly calculating y[1] from eq. (P2.63-1) and comparing it to your solution.) 
(c) If the mortgage is to be retired in 30 years after 360 monthly payments of D 
dollars, determine the appropriate value of D. 
(d) What is the total payment to the bank over the 30-year period? 
(e) Why do banks make loans? 
2.64. One important use of inverse systems is in situations in which one wishes to remove 
distortions of some type. A good example of this is the problem of removing echoes 
from acoustic signals. For example, if an auditorium has a perceptible echo, then 
an initial acoustic impulse will be followed by attenuated versions of the sound at 
regularly spaced intervals. Consequently, an often -used model for this phenomenon 
is an LTI system with an impulse response consisting of a train of impulses, i.e., 
h(t) = L hks<r - kT). 
k=O 
(P2.64-1) 
Here the echoes occur T seconds apart, and hk represents the gain factor on the kth 
echo resulting from an initial acoustic impulse. 
(a) Suppose that x(t) represents the original acoustic signal (the music produced 
by an orchestra, for example) and that y(t) = x(t) * h(t) is the actual signal that 
is heard if no processing is done to remove the echoes. In order to remove the 
distortion introduced by the echoes, assume that a microphone is used to sense 
y(t) and that the resulting signal is transduced into an electrical signal. We will 

Chap.2 
Problems 
167 
also use y(t) to denote this signal, as it represents the electrical equivalent of 
the acoustic signal, and we can go from one to the other via acoustic-electrical 
conversion systems. 
The important point to note is that the system with impulse response given 
by eq. (P2.64-1) is invertible. Therefore, we can find an LTI system with im-
pulse response g(t) such that 
y(t) * g(t) = x(t), 
and thus, by processing the electrical signal y(t) in this fashion and then con-
verting back to an acoustic signal, we can remove the troublesome echoes. 
The required impulse response g(t) is also an impulse train: 
g(t) = L gk5(t - kT). 
k=O 
Determine the algebraic equations that the successive g k must satisfy, and solve 
these equations for go, g 1, and g2 in terms of hk. 
(b) Suppose that h0 = 1, h 1 = 112, and h; = 0 for all i ;::: 2. What is g(t) in this 
case? 
(c) A good model for the generation of echoes is illustrated in Figure P2.64. Hence, 
each successive echo represents a fed-back version of y(t), delayed by T sec-
onds and scaled by a . Typically, 0 < a < 1, as successive echoes are attenu-
ated. 
x(t) 
+ 
y(t) 
ex 
Delay 
T 
Figure P2.64 
(i) What is the impulse response of this system? (Assume initial rest, i.e., 
y(t) = 0 fort < 0 if x(t) = 0 fort < 0.) 
(ii) Show that the system is stable if 0 < a < 1 and unstable if a > 1. 
(iii) · What is g(t) in this case? Construct a realization of the inverse system 
using adders, coefficient multipliers, and T-second delay elements. 
(d) Although we have phrased the preceding discussion in terms of continuous-time 
systems because of the application we have been considering, the same general 
ideas hold in discrete time. That is, the LTI system with impulse response 
00 
h[n] = L hk5[n - kN] 
k=O 
is invertible and has as its inverse an LTI system with impulse response 
g[n] = L gk5[n- kN]. 
k=O 

168 
Linear Time-Invariant Systems 
Chap.2 
It is not difficult to check that the gk satisfy the same algebraic equations as in 
part (a). 
Consider now the discrete-time LTI system with impulse response 
00 
h[n] = L 8[n - kN]. 
k = - oo 
This system is not invertible. Find two inputs that produce the same output. 
2.65. In Problem 1.45, we introduced and examined some of the basic properties of cor-
relation functions for continuous-time signals. The discrete-time counterpart of the 
correlation function has essentially the same properties as those in continuous time, 
and both are extremely important in numerous applications (as is discussed in Prob-
lems 2.66 and 2.67). In this problem, we introduce the discrete-time correlation 
function and examine several more of its properties. 
Let x[n] and y[n] be two real-valued discrete-time signals. The autocorrela-
tion functions <f>xx[n] and <f>yy[n] of x[n] and y[n], respectively, are defined by the 
expressions 
+oo 
<f>xAn] = L x[m + n]x[m] 
m=-oo 
and 
+oo 
<f>yy[n] = L y[m + n]y[m], 
m= - oo 
and the cross-correlation functions are given by 
+oo 
<f>xy[n] = L x[m + n]y[m] 
m= - oo 
and 
+ oo 
<f>yx[n] = L y[m + n]x[m]. 
m= -oo 
As in continuous time, these functions possess certain symmetry properties. Specif-
ically, <f>xAn] and <f>yy[n] are even functions, while <f>xy[n] = <f>yx[- n]. 
(a) Compute the autocorrelation sequences for the signals x1 [n], x2[n], x3[n], and 
x4 [n] depicted in Figure P2.65. 
(b) Compute the cross-correlation sequences 
cf>x;xi [n], i =F j, i, j = 1, 2, 3, 4, 
for x;[n], i = 1, 2, 3, 4, as shown in Figure P2.65. 
(c) Let x[n] be the input to anLTI system with unit sample response h[n], and let the 
corresponding output be y[n]. Find expressions for <f>xy[n] and <f>yy[n] in terms 
of <f>xAn] and h[n]. Show how <f>xy[n] and <f>yy[n] can be viewed as the output 

Chap.2 
Problems 
169 
• • • 
• • • • 
0 1 2 3 
n 
n 
.'I I'r. 
x3 [n] 
• • 
•••• 
-1 0 1 
n 
Figure P2.65 
of LTI systems with cPxAn] as the input. (Do this by explicitly specifying the 
impulse response of each of the two systems.) 
(d) Let h[n] = x 1 [n] in Figure P2.65, and let y[n] be the output of the LTI system 
with impulse response h[n] when the input x[n] also equals x 1 [n]. Calculate 
cPxy[n] and cPyy[n] using the results of part (c). 
2.66. Let h1 (t), h2(t), and h3(t), as sketched in Figure P2.66, be the impulse responses 
of three LTI systems. These three signals are known as Walsh functions and are of 
considerable practical importance because they can be easily generated by digital 
logic circuitry and because multiplication by each of them can be implemented in a 
simple fashion by a polarity-reversing switch. 
I 
I 
1 2 
- 1-
Figure P2.66 
(a) Determine and sketch a choice for x1 (t), a continuous-time signal with the fol-
lowing properties: 
(i) x 1 (t) is real. 
(ii) x 1(t) = 0 fort< 0. 
(iii) lx1 (t)l :::; 1 for t ~ 0. 
(iv) Y1 (t) = Xt (t) * h(t) is as large as possible at t = 4. 
(b) Repeat part (a) for x2(t) and x3(t) by making y2(t) = x2(t) * h2(t) and y3(t) = 
x3(t) * h3(t) each as large as possible at t = 4. 
(c) What is the value of 
YiJ(t) = Xi(t) * h j(t), i ¥- j 
at timet = 4 fori, j = 1, 2, 3? 

170 
Linear Time-Invariant Systems 
Chap. 2 
The system with impulse response hi(t) is known as the matched filter 
for the signal xi(t) because the impulse response is tuned to Xi(t) in order to 
produce the maximum output signal. In the next problem, we relate the concept 
of a matched filter to that of the correlation function for continuous-time signals. 
2.67. The cross-correlation function between two continuous-time real signals x(t) and 
y(t) is 
x1(t) 
x0(t) 
I 
- h -
f 
+oo 
cPxy(t) = 
- oo X(t + T)y( T) dT. 
(P2.67- 1) 
The autocorrelation function of a signal x(t) is obtained by setting y(t) = x(t) in 
eq. (P2.67- 1): 
f 
+ oo 
cPxx(t) = - oo X(t + T)X(T)dT. 
(a) Compute the autocorrelation function for each of the two signals x1 (t) and x2(t) 
depicted in Figure P2.67(a). 
-1 
(a) 
x1(t) 
I 
' t 
4 
- 1 
(b) 
Figure P2.67 
(b) Let x(t) be a given signal, and assume that x(t) is of finite duration-i.e., that 
x(t) = 0 fort< 0 and t > T. Find the impulse response of an LTI system so 
that <Pxx(t - T) is the output if x(t) is the input. 
(c) The system determined in part (b) is a matched filter for the signal x(t). That 
this definition of a matched filter is identical to the one introduced in Problem 
2.66 can be seen from the following: 
r 

Chap.2 
Problems 
171 
Let x(t) be as in part (b), and let y(t) denote the response to x(t) of an 
LTI system with real impulse response h(t). Assume that h(t) = 0 for t < 0 
and fort > T . Show that the choice for h(t) that maximizes y(T), subject to the 
constraint that 
for h2(t)dt = M, a fixed positive number, 
(P2.67-2) 
is. a scalar multiple of the impulse response determined in part (b). [Hint: 
Schwartz's inequality states that 
[ 
b 
]112 [ b 
]'12 
r 
u(t)v(t)dt ::5 L 
u2(t)dt L 
v2(t)dt 
for any two signals u(t) and v(t). Use this to obtain a bound on y(T).] 
(d) The constraint given by eq. (P2.67-2) simply provides a scaling to the impulse 
response, as increasing M merely changes the scalar multiplier mentioned in 
part (c). Thus, we see that the particular choice for h(t) in parts (b) and (c) is 
matched to the signal x(t) to produce maximum output. This is an extremely 
important property in a number of applications, as we will now indicate. 
In communication problems, one often wishes to transmit one of a small 
number of possible pieces of information. For example, if a complex message 
is encoded into a sequence of binary digits, we can imagine a system that trans-
mits the information bit by bit. Each bit can then be transmitted by sending one 
signal, say, x0(t) , if the bit is a 0, or a different signal x 1 (t) if a 1 is to be com-
municated. In this case, the receiving system for these signals must be capable 
of recognizing whether x0(t) or x 1 (t) has been received. Intuitively, what makes 
sense is to have two systems in the receiver, one tuned to xo(t) and one tuned 
to x 1 (t), where, by "tuned," we mean that the system gives a large output after 
the signal to which it is tuned is received. The property of producing a large 
output when a particular signal is received is exactly what the matched filter 
possesses. 
In practice, there is always distortion and interference in the transmission 
and reception processes. Consequently, we want to maximize the difference be-
tween the response of a matched filter to the input to which it is matched and 
the response of the filter to one of the other signals that can be transmitted. To 
illustrate this point, consider the two signals x0(t) and x 1 (t) depicted in Fig-
ure P2.67(b). Let Lo denote the matched filter for x0(t), and let L 1 denote the 
matched filter for x 1 (t). 
(i) Sketch the responses of Lo to x0(t) and x 1 (t). Do the same for L 1• 
(ii) Compare the values of these responses at t = 4. How might you modify 
x0(t) so that the receiver would have an even easier job of distinguishing 
between x0(t) and x 1 (t) in that the response of Lo to x 1 (t) and L 1 to x0(t) 
would both be zero at t = 4? 
2.68. · Another application in which matched filters and correlation functions play an im-
portant role is radar systems. The underlying principle of radar is that an electro-

172 
Linear Time-Invariant Systems 
Chap.2 
magnetic pulse transmitted at a target will be reflected by the target and will subse-
quently return to the sender with a delay proportional to the distance to the target. 
Ideally, the received signal will simply be a shifted and possibly scaled version of 
the original transmitted signal. 
Let p(t) be the original pulse that is sent out. Show that 
c/>pp(O) = max c/>pp(t). 
t 
That is, c/>pp(O) is the largest value taken by c/>pp(t). Use this equation to deduce that, 
if the waveform that comes back to the sender is 
x(t) = a p(t - to), 
where a is a positive constant, then 
c/>xp(to) = max c/>xp(t). 
t 
(Hint: Use Schwartz's inequality.) 
Thus, the way in which simple radar ranging systems work is based on using a 
matched filter for the transmitted waveform p(t) and noting the time at which the 
output of this system reaches its maximum value. 
2.69. In Section 2.5, we characterized the unit doublet through the equation 
f 
+ oo 
x(t) * u,(t) = 
-oo x(t- r)u 1(r)dr = x'(t) 
(P2.69- 1) 
for any signal x(t). From this equation, we derived the relationship 
f 
+ oo 
- oo g(r)u,(r)dr = - g'(O). 
(P2.69-2) 
(a) Show that eq. (P2.69-2) is an equivalent characterization of u1 (t) by showing 
that eq. (P2.69-2) implies eq. (P2.69- l). [Hint: Fix t, and define the signal 
g(r) = x(t - r).] 
Thus, we have seen that characterizing the unit impulse or unit doublet 
by how it behaves under convolution is equivalent to characterizing how it be-
haves under integration when multiplied by an arbitrary signal g(t). In fact, as 
indicated in Section 2.5, the equivalence of these operational definitions holds 
for all signals and, in particular, for all singularity functions. 
(b) Let f(t) be a given signal. Show that 
f(t)u, (t) = f(O)u, (t)- f'(O)o(t) 
by showing that both functions have the same operational definitions. 
(c) What is the value of 
Find an expression for j(t)u2(t) analogous to that in part (b) for f(t)u 1 (t). 

Chap. 2 
Problems 
173 
2.70. In analogy with continuous-time singularity functions, we can define a set of 
discrete-time signals. Specifically, let 
and 
and define 
and 
Note that 
and 
(a) What is 
(b) Show that 
u_1 [n] = u[n], 
uo[n] = 8[n], 
u1 [n] = 8[n] - 8[n - 1], 
uk[n] = fi[n] * UJ[n] * · · · * UJ[n!, k > 0 
v 
k times 
uk[n] = U-J[n] * U- J[n] * · · · * U- t[n], k < 0. 
lkl times 
x[n] * 8[n] = x[n], 
"' 
x[n] * u[n] = ~ x[m], 
m= -oo 
x[n] * Ut[n] = x[n] - x[n - 1], 
m= oo 
· x[n]u1 [n] = x[O]u1 [n] - [x[1] - x[0]]8[n - 1] 
= x[1]u1 [n] - [x[l] - x[0]]8[n]. 
(c) Sketch the signals uz[n] and u3[n]. 
(d) Sketch U- z[n] and U-3[n]. 
(e) Show that, in general, fork> 0, 
(-l)nk! 
uk[n] = 
'(k _ )I [u[n] - u[n - k- 1]]. 
n. 
n. 
(P2.70-1) 
(Hint: Use induction. From part (c), it is evident that uk[n] satisfies eq. 
(P2.70-1) for k = 2 and 3. Then, assuming that eq. (P2.70-1) satisfies uk[n], 
write uk+ 1 [n] in terms of uk[n], and show that the equation also satisfies 
. Uk+I[n].) 
. 

174 
Linear Time-Invariant Systems 
Chap. 2 
(t) Show that, in general, for k > 0, 
(n + k- 1)! 
. 
U- k[n] = 
n!(k _ 1)! u[n]. 
(P2.70-2) 
(Hint: Again, use induction. Note that 
(P2.70-3) 
Then, assuming that eq. (P2.70-2) is valid for u_k[n], use eq. (P2.70-3) to show 
that eq. (P2.70-2) is valid for U-(k+t)[n] as well.) 
2.71. In this chapter, we have used several properties and ideas that greatly facilitate the 
analysis of LTI systems. Among these are two that we wish to examine a bit more 
closely. As we will see, in certain very special cases one must be careful in using 
these properties, which otherwise hold without qualification. 
(a) One of the basic and most important properties of convolution (in both con tin-
uous and discrete time) is associativity. That is, if x(t), h(t), and g(t) are three 
signals, then 
x(t) * [g(t) * h(t)] = [x(t) * g(t)] * h(t) = [x(t) * h(t)] * g(t). 
(P2.71- 1) 
This relationship holds as long as all three expressions are well defined and 
finite. As that is usually the case in practice, we will in general use the asso-
ciativity property without comments or assumptions. However, there are some 
cases in which it does not hold. For example, consider the system depicted in 
Figure P2.71, with h(t) = u1 (t) and g(t) = u(t). Compute the response ofthis 
system to the input 
x(t) = 1 for all t. 
<~)-~y(t) 
Figure P2.71 
Do this in the three different ways suggested by eq. (P2. 71-1) and by the figure: 
(i) By first convolving the two impulse responses and then convolving the result 
with x(t). 
(ii) By first convolving x(t) with u1 (t) and then convolving the result with u(t). 
(iii) By first convolving x(t) with u(t) and then convolving the result with u1 (t). 

Chap. 2 
Problems 
(b) Repeat part (a) for 
and 
(c) Do the same for 
x(t) = e- 1 
h(t) = e -r u(t), 
g(t) = u1 (t) + o(t). 
x[n] = GJ. 
h[n] = G J 
u[n], 
1 
g[n] = o[n] - 2o[n- 1]. 
175 
Thus, in general, the associativity property of convolution holds if and 
only if the three expressions in eq. (P2.71- 1) make sense (i.e., if and only if 
their interpretations in terms of LTI systems are meaningful). For example, in 
part (a) differentiating a constant and then integrating makes sense, but the 
process of integrating the constant from t = - oo and then differentiating does 
not, and it is only in such cases that associativity breaks down. 
Closely related to the foregoing discussion is an issue involving inverse 
systems. Consider the LTI system with impulse response h(t) = u(t). As we 
saw in part (a), there are inputs-specifically, x(t) = nonzero constant- for 
which the output of this system is infinite, and thus, it is meaningless to consider 
the question of inverting such outputs to recover the input. However, if we limit 
ourselves to inputs that do yield finite outputs, that is, inputs which satisfy 
(P2.71-2) 
then the system is invertible, and the LTI system with impulse response u1 (t) 
is its inverse. 
(d) Show that the LTI system with impulse response u1 (t) is not invertible. (Hint: 
Find two different inputs that both yield zero output for all time.) However, 
show that the system is invertible if we limit ourselves to inputs that satisfy eq. 
(P2.71-2). [Hint: In Problem 1.44, we showed that an LTI system is invertible 
if no input other than x(t) = 0 yields an output that is zero for all time; are 
there two inputs x(t) that satisfy eq. (P2.71- 2) and that yield identically zero 
responses when convolved with u1 (t)?] 
What we have illustrated in this problem is the following: 
(1) If x(t), h(t), and g(t) are three signals, and if x(t) * g(t), x(t) * h(t), and 
h(t) * g(t) are all well defined and finite, then the associativity property, eq. 
(P2.71-1), holds. 

176 
Linear Time-Invariant Systems 
Chap.2 
(2) Let h(t) be the impulse response of an LTI system, and suppose that the 
impulse response g(t) of a second system has the property 
h(t) * g(t) = o(t). 
(P2.71- 3) 
Then, from (l),for all inputs x(t) for which x(t) * h(t) and x(t) * g(t) are 
both well defined and finite, the two cascades of systems depicted in Fig-
ure P2. 71 act as the identity system, and thus, the two LTI systems can 
. be regarded as inverses of one another. For example, if h(t) = u(t) and 
g(t) = u1 (t), then, as long as we restrict ourselves to inputs satisfying eq. 
(P2.71- 2), we can regard these two systems as inverses. 
Therefore, we see that the associativity property of eq. (P2.71- 1) and the definition 
ofLTI inverses as given in eq. (P2.71-3) are valid, as long as all convolutions that are 
involved are finite. As this is certainly the case in any realistic problem, we will in 
general use these properties without comment or qualification. Note that, although 
we have phrased most of our discussion in terms of continuous-time signals and 
systems, the same points can also be made in discrete time [as should be evident 
from part (c)]. 
2.72. Let 8.:l(t) denote the rectangular pulse of height ± 
for 0 < t ~ .l. Verify that 
d 
1 
dt o.:l(t) = "Ll [o(t) - o(t- .l)J. 
2.73. Show by induction that 
tk- l 
U- k(t) = (k _ 1)! u(t) fork = 1, 2, 3 ... 

3.0 INTRODUCTION 
3 
FouRIER SERIES 
REPRESENTATION OF 
PERIODIC SIGNALS 
The representation and analysis of LTI systems through the convolution sum as developed 
in Chapter 2 is based on representing signals as linear combinations of shifted impulses. 
In this and the following two chapters, we explore an alternative representation for signals 
and LTI systems. As in Chapter 2, the starting point for our discussion is.the development 
of a representation of signals as linear combinations of a set of basic signals. For this 
alternative representation we use complex exponentials. The resulting representations are 
known as the continuous-time and discrete-time Fourier series and transform. As we will 
see, these can be used to construct broad and useful classes of signals. 
We then proceed as we did in Chapter 2. That is, because of the superposition prop-
erty, the response of an LTI system to any input consisting of a linear combination of basic 
signals is the same linear combination of the individual responses to each of the basic sig-
nals. In Chapter 2, these responses were all shifted versions of the unit impulse response, 
leading to the convolution sum or integral. As we will find in the current chapter, the re-
sponse of an LTI system to a complex exponential also has a particularly simple form, 
which then provides us with another convenient representation for LTI systems and with 
another way in which to analyze these systems and gain insight into their properties. 
In this chapter, we focus on the representation of continuous-time and discrete-time 
periodic signals referred to as the Fourier series. In Chapters 4 and 5, we extend the anal-
ysis to the Fourier transform representation of broad classes of aperiodic, finite energy 
signals. Together, these representations provide one of the most powerful and important 
sets of tools and insights for analyzing, designing, and understanding signals and LTI sys-
tems, and we devote considerable attention in this and subsequent chapters to exploring 
the uses of Fourier methods. 
177 

178 
Fourier Series Representation of Periodic Signals 
Chap.3 
We begin in the next section with a brief historical perspective in order to provide 
some insight into the concepts and issues that we develop in more detail in the sections 
and chapters that follow. 
3. 1 A HISTORICAL PERSPECTIVE 
The development of Fourier analysis has a long history involving a great many individ-
uals and the investigation of many different physical phenomena. 1 The concept of using 
"trigonometric sums"-that is, sums of harmonically related sines and cosines or periodic 
complex exponentials-to describe periodic phenomena goes back at least as far as the 
Babylonians, who used ideas of this type in order to predict astronomical events.2 The 
modern history of the subject begins in 1748 with L. Euler, who examined the motion of 
a vibrating string. In Figure 3.1, we have indicated the first few of what are known as 
the "normal modes" of such a string. If we consider the vertical deflection f(t, x) of the 
string at time t and at a distance x along the string, then for any fixed instant of time, the 
normal modes are harmonically related sinusoidal functions of x. What Euler noted was 
that if the configuration of a vibrating string at some point in time is a linear combination 
of these normal modes, so is the configuration at any subsequent time. Furthermore, Euler 
showed that one could calculate the coefficients for the linear combination at the later time 
in a very straightforward manner from the coefficients at the earlier time. In doing this, 
Euler performed the same type of calculation as we will in the next section in deriving 
one of the properties of trigonometric sums that make them so useful for the analysis of 
LTI systems. Specifically, we will see that if the input to an LTI system is expressed as a 
linear combination of periodic complex exponentials or sinusoids, the output can also be 
expressed in this form, with coefficients that are related in a straightforward way to those 
of the input. 
The property described in the preceding paragraph would not be particularly useful, 
unless it were true that a large class of interesting functions could be represented by linear 
combinations of complex exponentials. In the middle of the 18th century, this point was the 
subject of heated debate. In 1753, D. Bernoulli argued on physical grounds that all physi-
cal motions of a string could be represented by linear combinations of normal modes, but 
he did not pursue this mathematically, and his ideas were not widely accepted. In fact, Eu-
ler himself discarded trigonometric series, and in 1759 l L. Lagrange strongly criticized 
the use of trigonometric series in the examination of vibrating strings. His criticism was 
based on his own belief that it was impossible to represent signals with corners (i.e., with 
discontinuous slopes) using trigonometric series. Since such a configuration arises from 
1 The historical material in this chapter was taken from the following references: I. Grattan-Guiness, 
Joseph Fourier, 17.68- 1830 (Cambridge, MA: The MIT Press, 1972); G. F. Simmons, Differential Equations: 
With Applications and Historical Notes (New York: McGraw-Hill Book Company, 1972); C. Lanczos, Dis- r 
course on Fourier Series (London: Oliver and Boyd, 1966); R. E. Edwards, Fourier Series: A Modem Intro-
duction (New York: Springer-Verlag, 2nd ed., 1970); and A. D. Aleksandrov, A. N. Kolmogorov, and M.A. 
Lavrent' ev, Mathematics: Its Content, Methods, and Meaning, trans. S. H. Gould, Vol. II; trans. K. Hirsch, Vol. 
m (Cambridge, MA: The MIT Press, 1969). Ofthese, Grattan -Guiness' work offers the most complete account 
of Fourier's life and contributions. Other references are cited in several places in the chapter. 
2 H. Dym and H. P. McKean, Fourier Series and Integrals (New York: Academic Press, 1972). This 
text and the book of Simmons cited in footnote 1 also contain discussions of the vibrating-string problem and 
its role in the development of Fourier analysis. 

Vertical deflection t 
f(t,x) 
Sec. 3.1 
A Historical Perspective 
1---------
---x-Position along 
0 
the string 
---........ ........ ........ ........ 
Figure 3. 1 
Normal modes of a vi-
brating string. (Solid lines indicate the 
configuration of each of these modes 
at some fixed instant of time, t.) 
179 
the plucking of a string (i.e., pulling it taut and then releasing it), Lagrange argued that 
trigonometric series were of very limited use. 
It was in this somewhat hostile and skeptical environment that Jean Baptiste Joseph 
Fourier (Figure 3.2) presented his ideas half a century later. Fourier was born on March 
Figure 3.2 
Jean Baptiste Joseph 
Fourier [picture from J. B. J. Fourier, 
Oeuvres de Fourier, Vol. II (Paris: 
Gauthier-Villars et Fils, 1980)]. 

180 
Fourier Series Representation of Periodic Signals 
Chap. 3 
21, 1768, in Auxerre, France, and by the time of his entrance into the controversy con-
cerning trigonometric series, he had already had a lifetime of experiences. His many 
contributions- in particular, those concerned with the series and transform that carry his 
name- are made even more impressive by the circumstances under which he worked. 
His revolutionary discoveries, although not completely appreciated during his own life-
time, have had a major impact on the development of mathematics and have been and still 
are of great importance in an extremely wide range of scientific and engineering disci-
plines. 
In addition to his studies in mathematics, Fourier led an active political life. In fact, 
during the years that followed the French Revolution, his activities almost led to his down-
fall, as he narrowly avoided the guillotine on two separate occasions. Subsequently, Fourier 
became an associate of Napoleon Bonaparte, accompanied him on his expeditions to Egypt 
(during which time Fourier collected the information he would use later as the basis for 
his treatises on Egyptology), and in 1802 was appointed by Bonaparte to the position of 
prefect of a region of France centered in Grenoble. It was there, while serving as prefect, 
that Fourier developed his ideas on trigonometric series. 
The physical motivation for Fourier's work was the phenomenon of heat propaga-
tion and diffusion. This in itself was a significant step in that most previous research in 
mathematical physics had dealt with rational and celestial mechanics. By 1807, Fourier 
had completed a work, Fourier had found series of harmonically related sinusoids to be 
useful in representing the temperature distribution through a body. In addition, he claimed 
that "any" periodic signal could be represented by such a series. While his treatment of 
this topic was significant, many of the basic ideas behind it had been discovered by oth-
ers. Also, Fourier's mathematical arguments were still imprecise, and it remained for P. L. 
Dirichlet in 1829 to provide precise conditions under which a periodic signal could be rep-
resented by a Fourier series. 3 Thus, Fourier did not actually contribute to the mathematical 
theory of Fourier series. However, he did have the clear insight to see the potential for this 
series representation, and it was to a great extent his work and his claims that spurred much 
of the subsequent work on Fourier series. In addition, Fourier took this type of representa-
tion one very large step farther than any of his predecessors: He obtained a representation 
for aperiodic signals-not as weighted sums of harmonically related sinusoids-but as 
weighted integrals of sinusoids that are not all harmonically related. It is this extension 
from Fourier series to the Fourier integral or transform that is the focus of Chapters 4 and 5. 
Like the Fourier series, the Fourier transform remains one of the most powerful tools for 
the analysis of LTI systems. 
Four distinguished mathematicians and scientists were appointed to examine the 
1807 paper of Fourier. Three of the four-S. F. Lacroix, G. Monge, and P. S. de Laplace-
were in favor of publication of the paper, but the fourth, J. L. Lagrange, remained adamant 
in rejecting trigonometric series, as he had done 50 years earlier. Because of Lagrange's 
vehement objections, Fourier's paper never appeared. After several other attempts to have 
his work accepted and published by the Institut de France, Fourier undertook the writing of 
another version of his work, which appeared as the text Theorie analytique de Ia chaleur.4 
3Both S.D. Poisson and A. L. Cauchy had obtained results about the convergence of Fourier series before 
1829, but Dirichlet's work represented such a significant extension of their results that he is usually credited 
with being the first to consider Fourier series convergence in a rigorous fashion. 
4See J. B. J. Fourier, The Analytical Theory of Heat, trans. A. Freeman (New York: Dover, 1955). 

Sec. 3.1 
A Historical Perspective 
181 
This book was published in 1822, 15 years after Fourit!r had first presented his results to 
the Institut. 
Toward the end of his life Fourier received some of the recognition he deserved, 
but the most significant tribute to him has been the enormous impact of his work on so 
many disciplines within the fields of mathematics, science, and engineering. The theory 
of integration, point-set topology, and eigenfunction expansions are just a few examples 
of topics in mathematics that have their roots in the analysis of Fourier series and inte-
grals.5 Furthermore, in addition to the original studies of vibration and heat diffusion, there 
are numerous other problems in science and engineering in which sinusoidal signals, and 
therefore Fourier series and transforms, play an important role. For example, sinusoidal 
signals arise naturally in describing the motion of the planets and the periodic behavior of 
the earth's climate. Alternating-current sources generate sinusoidal voltages and currents, 
and, as we will see, the tools of Fourier analysis enable us to analyze the response of an 
LTI system, such as a circuit, to such sinusoidal inputs. Also, as illustrated in Figure 3.3, 
waves in the ocean consist of the linear combination of sinusoidal waves with different 
spatial periods or wavelengths. Signals transmitted by radio and television stations are si-
nusoidal in nature as well, and as a quick perusal of any text on Fourier analysis will show, 
the range of applications in which sinusoidal signals arise and in which the tools of Fourier 
analysis are useful extends far beyond these few examples. 
-
Wavelength 150ft 
---- Wavelenght 500ft 
- • -
• -Wavelength 800 ft 
Figure 3.3 
Ship encountering the superposition of three wave trains, each with a 
different spatial period. When these waves reinforce one another, a very large wave 
can result. In more severe seas, a giant wave indicated by the dotted line could result. 
Whether such a reinforcement occurs at any location depends upon the relative phases 
of the components that are superposed. [Adapted from an illustration by P. Mion in 
"Nightmare Waves Are All Too Real to Deepwater Sailors," by P. Britton, Smithsonian 
8 (February 1978), pp. 64-65]. 
While many of the applications in the preceding paragraph, as well as the original 
work of Fourier and his contemporaries on problems of mathematical physics, focus on 
phenomena in continuous time, the tools of Fourier analysis for discrete-time signals and 
systems have their own distinct historical roots and equally rich set of applications. In par-
ticular, discrete-time concepts and methods are fundamental to the discipline of numerical 
analysis. Formulas for the processing of discrete sets of data points to produce numerical 
approximations for interpolation, integration, and differentiation were being investigated 
as early as the time of Newton in the 1600s. In addition, the problem of predicting 
the motion of a heavenly body, given a sequence of observations of the body, spurred the 
5For more on the impact of Fourier's work on mathematics, see W. A. Coppel, "J. B. Fourier-on the 
occasion of His Two Hundredth Birthday," American Mathematical Monthly, 76 (1969), 468- 83. 

182 
Fourier Series Representation of Periodic Signals 
Chap.3 
investigation of harmonic time series in the 18th and 19th centuries by eminent scientists 
and mathematicians, including Gauss, and thus provided a second setting in which much 
of the initial work was done on discrete-time signals and systems. 
In the rnid-1960s an algorithm, now known as the fast Fourier transform, or FFf, was 
introduced. This algorithm, which was independently discovered by Cooley and Tukey in 
1965, also has a considerable history and can, in fact, be found in Gauss' notebooks.6 
What made its modern discovery so important was the fact that the FFf proved to be 
perfectly suited for efficient digital implementation, and it reduced the time required to 
compute transforms by orders of magnitude. With this tool, many interesting but previ-
ously impractical ideas utilizing the discrete-time Fourier series and transform suddenly 
became practical, and the development of discrete-time signal and system analysis tech-
niques moved forward at an accelerated pace. 
What has emerged out of this long history is a powerful and cohesive framework for 
the analysis of continuous-time and discrete-time signals and systems and an extraordinar-
ily broad array of existing and potential applications. In this and the following chapters, 
we will develop the basic tools of that framework and examine some of its important im-
plications. 
3.2 THE RESPONSE OF LTI SYSTEMS TO COMPLEX EXPONENTIALS 
As we indicated in Section 3.0, it is advantageous in the study of LTI systems to represent 
signals as linear combinations of basic signals that possess the following two properties: · 
1. The set of basic signals can be used to construct a broad and useful class of signals. 
2. The response of an LTI system to each signal should be simple enough in structure 
to provide us with a convenient representation for the response of the system to 
any signal constructed as a linear combination of the basic signals. 
Much of the importance of Fourier analysis results from the fact that both of these prop-
erties are provided by the set of complex exponential signals in continuous and discrete 
time-i.e., signals of the form est in continuous time and zn in discrete time, where s and 
z are complex numbers. Iri subsequent sections of this and the following two chapters, 
we will examine the first property in some detail. In this section, we focus on the second 
property and, in this way, provide motivation for the use of Fourier series and transforms 
in the analysis of LTI systems. 
The importance of complex exponentials in the study of LTI systems stems from the 
fact that the response of an LTI system to a complex exponential input is the same complex 
exponential with only a change in amplitude; that is, 
continuous time: est ~ 
H(s)es1, 
discrete time: zn ~ 
H(z)zn, 
(3.1) 
(3.2) 
where the complex amplitude factor H(s) or H(z) will in general be a function of the 
complex variable s or z. A signal for which the system output is a (possibly complex) 
6M. T. Heideman, D. H. Johnson, and C. S. Burrus, "Gauss and the History of the Fast Fourier Trans-
form," The IEEE ASSP Magazine I (1984), pp. 14-21. 

Sec. 3.2 
The Response of LTI Systems to Complex Exponentials 
183 
constant times the input is referred to as an eigenfunction of the system, and the amplitude 
factor is referred to as the system's eigenvalue. 
To show that complex exponentials are indeed eigenfunctions of LTI systems, let us 
consider a continuous-time LTI system with impulse response h(t). For an input x(t), we 
can determine the output through the use of the convolution integral, so that with x(t) = est 
I 
+oo 
y(t) = 
- oo h( T)X(t - T) dT 
(3.3) 
I 
+ oo 
= 
-oo h( T)es(t- r) dT. 
Expressing es<t- r) as est e- sr, and noting that est can be moved outside the integral, we see 
that eq. (3.3) becomes 
I 
+ oo 
y(t) = est - oo h(T)e- sr dT. 
(3.4) 
Assuming that the integral on the right-hand side of eq. (3.4) converges, the response to 
est is of the form 
y(t) = H(s)est, 
(3.5) 
where Jl(s) is a complex constant whose value depends on sand which is related to the 
system impulse response by 
I 
+oo 
H(s) = 
- oo h(T)e- sr dT. 
(3.6) 
Hence, we have shown that complex exponentials are eigenfunctions of LTI systems. The 
constant H(s) for a specific value of sis then the eigenvalue associated with the eigen-
function est. 
In an_exactly parallel manner, we can show that complex exponential sequences are 
eigenfunctions of discrete-time LTI systems. That is, suppose that an LTI system with 
impulse response h[n] has as its input the sequence 
(3.7) 
where z is a complex number. Then the output of the system can be detennined from the 
convolution sum as 
+ oo 
y[n] = L h[k]x [n -
k] 
k = -
00 
(3.8) 
+ oo 
+oo 
= L h[k]zn- k = Z
11 L h[k]z- k. 
k = -oo 
k = - oo 
From this expression, we see that if the input x[n] is the complex exponential given by 
eq. (3.7), then, assuming that the summation on the right-hand side of eq. (3.8) converges, 
the output is the same complex exponential multiplied by a constant that depends on the 

184 
Fourier Series Representation of Periodic Signals 
Chap.3 
value of z. That is, 
y[n] = H(z)zn, 
(3.9) 
where 
+oo 
H(z) = L h[k]z- k. 
(3.10) 
k =-oo 
Consequently, as in the continuous-time case, complex exponentials are eigenfunctions of 
discrete-time LTI systems. The constant H(z) for a specified value of z is the eigenvalue 
associated with the eigenfunction zn. 
For the analysis of LTI systems, the usefulness of decomposing more general signals 
in terms of eigenfunctions can be seen from an example. Let x(t) correspond to a linear 
combination of three complex exponentials; that is, 
From the eigenfunction property, the response to each separately is 
a1e511 ~ 
aiH(si)e5 11, 
a2e521 ~ 
a2H(s2)e521, 
a3e531 ~ 
a3H(s3)e531, 
(3.11) 
and from the superposition property the response to the sum is the sum of the responses, 
so that 
(3.12) 
More generally, in continuous time, eq. (3.5), together with the superposition property, 
implies that the representation of signals as a linear combination of complex exponentials 
leads to a convenient expression for the response of an LTI system. Specifically, if the 
input to a continuous-time LTI system is represented as a linear combination of complex 
exponentials, that is, if 
then the output will be 
y(t) = L akH(sk)e5k1• 
k 
(3.13) 
(3.14) 
In an exactly analogous manner, if the input to a discrete-time LTI system is represented 
as a linear combination of complex exponentials, that is, if 
then the output will be 
y[n] = L akH(zk)z'k. 
k 
(3.15) 
(3.16) 

Sec. 3.2 
The Response of LTI Systems to Complex Exponentials 
185 
In other words, for both continuous time and discrete time, if the input to an LTI 
system is represented as a linear combination of complex exponentials, then the output 
can also be represented as a linear combination of the same complex exponential signals. 
Each coefficient in this representation of the output is obtained as the product of the corre-
sponding coefficient ak of the input and the system's eigenvalue H(s k) or H(zk) associated 
with the eigenfunction es*r or z'fc, respectively. It was precisely this fact that Euler discov-
ered for the problem of the vibrating string, that Gauss and others used in the analysis 
of time series, and that motivated Fourier and others after him to consider the question 
of how broad a class of signals could be represented as a linear combination of complex 
exponentials. In the next few sections we examine this question for periodic signals, first 
in continuous time and then in discrete time, and in Chapters 4 and 5 we consider the 
extension of these representations to aperiodic signals. Although in general, the variables 
sand z in eqs. (3.1)- (3.16) may be arbitrary complex numbers, Fourier analysis involves 
restricting our attention to particular forms for these variables. In particular, in continuous 
time we focus on purely imaginary values of s-i.e., s = jw-and thus, we consider only 
complex exponentials of the form ejwr. Similarly, in discrete time we restrict the range 
of values of z to those of unit magnitude- i.e., z = ejw_ so that we focus on complex 
exponentials of the form ejwn. 
Example 3.1 
As an illustration of eqs. (3.5) and (3.6), consider an LTI system for which the input x(t) 
and output y(t) are related by a time shift of 3, i.e., 
y(t) = x(t - 3). 
(3.17) 
If the input to this system is the complex exponential signal x(t) = ej 21 , then, from 
eq. (3.17), 
(3.18) 
Equation (3.18) is in the form of eq. (3.5), as we would expect, since ej21 is an eigen-
function. The associated eigenvalue is H(j2) = e- j6 • It is straightforward to confirm 
eq. (3.6) for this example. Specifically, from eq. (3.17), the impulse response of the sys-
tem is h(t) = c5(t - 3). Substituting into eq. (3.6), we obtain 
sothatH(j2) = e- j6 . 
As a second example, in this case illustrating eqs. (3.11) and (3.12), consider the 
input signal x(t) = cos(4t) + cos(7t). From eq. (3.17), y(t) will of course be 
y(t) = cos(4(t - 3)) + cos(7(t - 3)). 
(3.19) 
To see that this will also result from eq. (3.12), we first expand x(t) using Euler's relation: 
x(t) = .!.ej4t + .!.e- j4t + .!.ej?t +.!. e -j ?t 
2 
2 
2 
2 
. 
(3.20) 
From eqs. (3.11) and (3.12), 

186 
Fourier Series Representation of Periodic Signals 
Chap.3 
or 
Y(t) = .!.ej4(t- 3) + .!.e- j 4(t- 3) + .!.ej?(t- 3) + .!. e - j7(1- 3) 
2 
2 
2 
2 
= cos(4(t- 3)) + cos(7(t - 3)). 
For this simple example, multiplication of each periodic exponential component of 
x(t)-for example, ~ej
41-by the corresponding eigenvalue-e.g., H(j4) = e - j 12-
effectively causes the input component to shift in time by 3. Obviously, in this case 
we can determine y(t) in eq. (3.19) by inspection rather than by employing eqs. (3.11) 
and (3.12). However, as we will see, the general property embodied in eqs. (3.11) 
and (3.12) not only allows us to calculate the responses of more complex LTI systems, 
but also provides the basis for the frequency domain representation and analysis of LTI 
systems. 
3.3 FOURIER SERIES REPRESENTATION OF CONTINUOUS-TIME 
PERIODIC SIGNALS 
3.3.1 Linear Combinations of Harmonically Related 
Complex Exponentials 
As defined in Chapter 1, a signal is periodic if, for some positive value ofT, 
x(t) = x(t + T) 
for all t. 
(3.21) 
The fundamental period of x(t) is the minimum positive, nonzero value of T for which 
eq. (3.21) is satisfied, and the value w0 = 2nlT is referred to as the fundamental fre-
quency. 
In Chapter 1 we also introduced two basic periodic signals, the sinusoidal signal 
x(t) = cos wot 
(3.22) 
and the periodic complex exponential 
(3.23) 
Both of these signals are periodic with fundamental frequency w0 and fundamental period 
T = 2nlwo. Associated with the signal in eq. (3.23) is the set of harmonically related 
complex exponentials 
cf>k(t) = ejkw0t = ejk(27TIT)t, 
k = 0, :± 1, :±2, .... 
(3.24) 
Each of these signals has a fundamental frequency that is a multiple of w0, and therefore, 
each is periodic with period T (although for lkl ;::::: 2, the fundamental period of cf>k(t) is a 
fraction of T). Thus, a linear combination of harmonically related complex exponentials 
of the form 
+oo 
x(t) = L akejkwot = 
(3.25) 
k = - 00 
k = -00 

Sec. 3.3 
Fourier Series Representation of Continuous-Time Periodic Signals 
187 
is also periodic with period T. In eq. (3.25), the term fork = 0 is a constant. The terms for 
k = + 1 and k = -1 both have fundamental frequency equal to w0 and are collectively 
referred to as the fundamental components or the first harmonic components. The two 
terms for k = + 2 and k = -2 are periodic with half the period (or, equivalently, twice 
the frequency) of the fundamental components and are referred to as the second harmonic 
components. More generally, the components for k = + N and k = - N are referred to as 
the Nth harmonic components. 
The representation of a periodic signal in the form of eq. (3.25) is referred to as the 
Fourier series representation. Before developing the properties of this representation, let 
us consider an example. 
Example 3.2 
Consider a periodic signal x(t), with fundamental frequency 27T, that is expressed in the 
form of eq. (3.25) as 
where 
+3 
x(t) = L akejk2m, 
k=-3 
ao = 1, 
1 
al = a- 1 = 4' 
(3.26) 
Rewriting eq. (3.26) and collecting each of the harmonic components which have the 
same fundamental frequency, we obtain 
1·z 
·z 
1.4 
·4 
x(t) = 1 + -(e1 1rt + e- 1 1rt) + - (e1 1rt + e- J 1rt) 
4 
2 
(3.27) 
1 
"6 
"6 
+ 3(el 1Tt + e- J 1Tt). 
Equivalently, using Euler's relation, we can write x(t) in the form 
1 
2 
x(t) = 1 + 2: cos 27Tt + cos 47Tt + 3 cos 67Tt. 
(3.28) 
In Figure 3.4, we illustrate graphically how the signal x(t) is built up from its harmonic 
components. 

188 
Fourier Series Representation of Periodic Signals 
Chap. 3 
x0(t) = 1 
x1(t) = t cos 2'1Tt 
x0(t) + X 1 (t) 
1\1\l/\1\ 
7\JV\TV\! ~ 
x(t) = x0(t) + x1(t) +x2(t) + x3(t) 
Figure 3.4 
Construction of the signal x(t) in Example 3.2 as a linear com-
bination of harmonically related sinusoidal signals. 
t 
Equation (3.28) is an example of an alternative form for the Fourier series of real 
periodic signals. Specifically, suppose that x(t) is real and can be represented in the form 
of eq. (3.25). Then, since x*(t) = x(t), we obtain 
+ oo 
x(t) = L ake- jkwot. 
k = - 00 

Sec. 3.3 
Fourier Series Representation of Continuous-Time Periodic Signals 
189 
Replacing k by - k in the summation, we have 
+ co 
x(t) = L 
a*_kejkwot, 
k= - co 
which, by comparison with eq. (3.25), requires that ak = a*_k, or equivalently, that 
(3.29) 
Note that this is the case in Example 3.2, where the ak's are in fact real and ak = a-k· 
To derive the alternative forms of the Fourier series, we first rearrange the summation 
in eq. (3.25) as 
co 
x(t) = ao + L[akejkwot + a _ke- jkwot]. 
k=l 
Substituting a:k for a_k from eq. (3.29), we obtain 
co 
x(t) = ao + L[akejkwot + a:ke- jkwo1]. 
k= l 
Since the two terms inside the summation are complex conjugates of each other, this can 
be expressed as 
co 
x(t) = ao + 2.: 2ffi.e{akejkwot}. 
k=l 
If ak is expressed in polar form as 
then eq. (3.30) becomes 
That is, 
co 
x(t) = ao + L 
2ffi-e{Akej(kwot+8kl}. 
k= l 
co 
x(t) = ao + 2 L 
Ak cos(kwot + fh). 
k=l 
(3.30) 
(3.31) 
Equation (3.31) is one commonly encountered form for the Fourier series of real periodic 
signals in continuous time. Another form is obtained by writing akin· rectangular form as 
ak = Bk + jCb 
where Bk and Ck are both real. With this expression for ak. eq. (3.30) takes the form 
co 
x(t) = ao + 2 L 
[Bk cos kwot -
Ck sin kwot]. 
k=l 
(3.32) 
In Example 3.2 the ak's are all real, so that ak = Ak = Bk. and therefore, both represen-
tations, eqs. (3.31) and (3.32), reduce to the same form, eq. (3.28). 

190 
Fourier Series Representation of Periodic Signals 
Chap. 3 
Thus, for real periodic functions, the Fourier series in terms of complex exponentials, 
as given in eq. (3.25), is mathematically equivalent to either of the two forms in eqs. (3.31) 
and (3.32) that use trigonometric functions. Although the latter two are common forms for 
Fourier series,? the complex exponential form of eq. (3.25) is particularly convenient for 
our purposes, so we will use that form almost exclusively. 
Equation (3.29) illustrates one of many properties associated with Fourier series. 
These properties are often quite useful in gaining insight and for computational purposes, 
and in Section 3.5 we collect together the most important of them. The derivation of several 
of them is considered in problems at the end of the chapter. In Section 4.3, we also will 
develop the majority of the properties within the broader context of the Fourier transform. 
3.3.2 Determination of the Fourier Series Representation 
of a Continuous-time Periodic Signal 
Assuming that a given periodic signal can be represented with the series of eq. (3.25), we 
need a procedure for determining the coefficients ak. Multiplying both sides of eq. (3.25) 
bye- jnwot' we obtain 
+oo 
x(t)e- jnw0t 
L akejkwote-Jnwot. 
(3.33) 
k = -00 
Integrating both sides from 0 to T = 27Tiwo, we have 
Here, Tis the fundamental period of x(t), and consequently, we are integrating over one 
period. Interchanging the order of integration and summation yields 
{T x(t)e- Jnwotdt = f ak[{T ei(k- n)wotdt]. 
(3.34) 
Jo 
k = - oo 
Jo 
The evaluation of the bracketed integral is straightforward. Rewriting this integral using 
Euler's formula, we obtain 
LT ei<k- n)wot dt = foT cos(k - n)wot dt + j I: sin(k - n)wot dt. 
(3.35) 
Fork¥- n, cos(k- n)w0t and sin(k- n)w0t are periodic sinusoids with fundamental period 
(T!Ik - nl). Therefore, in eq. (3.35), we are integrating over an interval (oflength T) that 
is an integral number of periods of these signals. Since the integral may be viewed as 
measuring the total area under the functions over the interval, we see that for k ¥- n, both 
of the integrals on the right-hand side of eq. (3.35) are zero. For k = n, the integrand on 
the left-hand side of eq. (3.35) equals 1, and thus, the integral equals T. In sum, we then 
have 
( T ei(k- n)wot dt = { T, 
Jo 
0, 
k = n 
k ¥- n ' 
7ln fact, in his original work, Fourier used the sine-cosine form of the Fourier series given in eq. (3.32). 

Sec. 3.3 
Fourier Series Representation of Continuous-Time Periodic Signals 
191 
and consequently, the right-hand side of eq. (3.34) reduces to Tan. Therefore, 
an = ~faT x(t)e- jflh>ot dt, 
(3.36) 
which provides the equation for determining the coefficients. Furthermore, note that in 
evaluating eq. (3.35), the only fact that we used concerning the interval of integration 
was that we were integrating over an interval of length T, which is an integral number of 
periods of cos( k- n )w0t and sin( k- n )w0t. Therefore, we will obtain the same result if we 
integrate over any interval of length T. That is, if we denote integration over any interval 
oflength T by fT' we have 
and consequently, 
f 
ej(k-n)w0t dt = { T, 
T 
0, 
k=n 
k# n' 
an = ~ t x(t)e-jnwot dt . . 
(3.37) 
To summarize, if x(t) has a Fourier series representation [i.e., if it can be expressed 
as a linear combination of harmonically related complex exponentials in the form of eq. 
(3.25)], then the coefficients are given by eq. (3.37). This pair of equations, then, defines 
the Fourier series of a periodic continuous-time signal: 
+oo 
+oo 
x(t) = L akejkwot = L akejk(27TIT)t, 
(3.38) 
k = - oo 
k =-oo 
(3.39) 
Here, we have written equivalent expressions for the Fourier series in terms of the fun-
damental frequency w0 and the fundamental period T. Equation (3.38) is referred to as 
the synthesis equation and eq. (3.39) as the analysis equation. The set of coefficients {ak} 
are often called the Fourier series coefficients or the spectral coefficients of x(t).8 These 
complex coefficients measure the portion of the signal x(t) that is at each harmonic of the 
fundamental component. The coefficient ao is the de or constant component of x(t) and is 
given by eq. (3.39) with k = 0. That is, 
ao = ~ JT x(t)dt, 
(3.40) 
which is simply the average value of x(t) over one period. 
Equations (3.38) and (3.39) were known to both Euler and Lagrange in the mid-
dle of the 18th century. However, they discarded this line of analysis without having 
8The term "spectral coefficient" is derived from problems such as the spectroscopic decomposition of 
light into spectral lines (i.e., into its elementary components at different frequencies). The intensity of any line in 
such a decomposition is a direct measure of the fraction of the total light energy at the frequency corresponding 
to the line. 

192 
Fourier Series Representation of Periodic Signals 
Chap.3 
examined the question of how large a class of periodic signals could, in fact, be represented 
in such a fashion. Before we tum to this question in the next section, let us illustrate the 
continuous-time Fourier series by means of a few examples. 
Example 3.3 
Consider the signal 
x(t) = sinw0t, 
whose fundamental frequency is w0 • One approach to determining the Fourier series 
coefficients for this signal is to apply eq. (3.39). For this simple case, however, it is 
easier to expand the sinusoidal signal as a linear combination of complex exponentials 
and identify the Fourier series coefficients by inspection. Specifically, we can express 
sinw0t as 
1 
° 
1 
° 
sinw t = -
e'wot - -e- Jwot 
0 
2j 
2j 
0 
Comparing the ri~ht-hand sides of this equation and eq. (3.38), we obtain 
Example 3.4 
Let 
1 
a1 = 2j' 
ak = 0, 
1 
a - 1 = - 2j' 
k ¥- + 1 or - 1. 
x(t) = 1 + sinw0t + 2coswat +cos (2wot + ~). 
which has fundamental frequency w0 • As with Example 3.3, we can again expand x(t) 
directly in terms of complex exponentials, so that 
x(t) = 1 + ~[ejwot _ e- jw0t] + [ejwot + e- jw0t] + ![ej(2w0t+1Ti4) + e-j(2wot+1TI4)]. 
~ 
. 
2 
Collecting terms, we obtain 
x(t) = 1 + (1 + 21j )ejwot + (1 - ;j )e- jwot + nej(?T/4) )ej2wot + (~e- j(?T/4) )e- j2wot. 
Thus, the Fourier S!!ries coefficients for this example are 
a0 = 1, 
a1 = (1 + _!_) = 1 - !1· 
2j 
2 ' 
= (1 - _!_) = 1 + !]· 
2j 
2 ' 

Sec. 3.3 
Fourier Series Representation of Continuous-Time Periodic Signals 
-
1 - j(7T/4) -
J2(1 -
") 
a-2- 2e 
- 4 
1 , 
ak = 0, lkl > 2. 
i In Figure 3.5, we show a bar graph of the magnitude and phase of ak. 
- 3 - 2 - 1 
0 
1 
2 
3 
k 
<): ak 
- 2 I 
• • • • 
• 
• 
• • 
-3 1-1 0 
2 3 
k 
Figure 3.5 
Plots of the magnitude and phase of the Fourier coefficients of 
the signal considered in Example 3.4. 
193 
Example 3.5 
The periodic square wave, sketched in Figure 3.6 and defined over one period as 
x(t) = { ~: 
ltl < TI 
TI < ltl < T/2 ' 
(3.41) 
is a signal that we will encounter a number of times throughout this book. This signal is 
periodic with fundamental period T and fundamental frequency w0 = 2-rr/T. 
To determine the Fourier series coefficients for x(t), we use eq. (3.39). Because 
of the symmetry of x(t) about t = 0, it is convenient to choose - T 12 ~ t < T /2 as the 
x(t) 
... J rJ 
rJ 
I ~ I n rJ 
[ ... 
-2T 
- T 
_.I -T1 T1 .I 
T 
2T 
2 
2 
Figure 3.6 
Periodic square wave. 

194 
Fourier Series Representation of Periodic Signals 
Chap.3 
interval over which the integration is performed, although any interval of length T is 
equally valid and thus will lead to the same result. Using these limits of integration and 
substituting from eq. (3.41), we have first, fork = 0, 
ao = .!..JTI dt = 2Tt. 
T 
- TI 
T 
(3.42) 
As mentioned previously, a0 is interpreted to be the average value of x(t), which in this 
case equals the fraction of each period during which x(t) = 1. For k -,.6 0, we obtain 
which we may rewrite as 
(3.43) 
Noting that the term in brackets is sin kw0T1, we can express the coefficients ak as 
sin(kwoTt) 
hr 
where we have used the fact that w0T = 27T. 
k"" 0, 
(3.44) 
Figure 3.7 is a bar graph of the Fourier series coefficients for this example. In 
particular, the coefficients are plotted for a fixed value of T1 and several values ofT. 
For this specific example, the Fourier coefficients are real, and consequently, they can 
be depicted graphically with only a single graph. More generally, of course, the Fourier 
coefficients are complex, so that two graphs, corresponding to the real and imaginary 
parts, or magnitude and phase, of each coefficient, would be required. ForT= 4T1, x(t) 
is a square wave that is unity for half the period and zero for half the period. In this case, 
woT1 = 7T/2, and from eq. (3.44), 
ak = sin( 7Tk/2) 
k7T 
k"" 0, 
(3.45) 
while 
ao = 2" 
(3.46) 
From eq. (3.45), ak = 0 fork even and nonzero. Also, sin(7Tk/2) alternates between ±1 
for successive odd values of k. Therefore, 
1 
a3 = a-3 = - 37T, 
1 
as = 
a- s = 57T' 

Sec. 3.4 
Convergence of the Fourier Series 
195 
k 
-I 
. ".. . "'. .1111111. . "'. . " .. 
I 
• 
I I I 
I 11-4 
0 
41 II 
I I I 
• I 
k 
(b) 
e 
I 
e 
I 
l'~~~~~~~~~~~~ .. l 
I 
I 'Ill' ~s 
o 
sl' Ill' I 
e 
I 
1 
(c) 
Figure 3.7 
Plots of the scaled Fourier series coefficients Tak for the pe-
riodic square wave with 7; fixed and for several values of T: (a) T = 4 7;; 
(b) T = 87;; (c) T = 167;. The coefficients are regularly spaced samples of 
the envelope (2sinw7;)/w, where the spacing between samples, 2TT!T, de-
creases as T increases. 
3.4 CONVERGENCE OF THE FOURIER SERIES 
k 
Although Euler and Lagrange would have been happy with the results of Examples 3.3 
and 3.4, they would have objected to Example 3.5, since x(t) is discontinuous while each 
of its harmonic components is continuous. Fourier, on the other hand, considered the same 
example and maintained that the Fourier series representation of the square wave is valid. 
In fact, Fourier maintained that any periodic signal could be represented by a Fourier 
series. Although this is not quite true, it is true that Fourier series can be used to represent an 
extremely large class of periodic signals, including the square wave and all other periodic 
signals with which we will be concerned in this book and which are of interest in practice. 
To gain an understanding of the square-wave example and, more generally, of the 
question of the validity of Fourier series representations, let us examine the problem of 
approximating a given periodic signal x(t) by a linear combination of a finite number of 
harmonically related complex exponentials-that is, by a finite series of the form 

196 
Fourier Series Representation of Periodic Signals 
N 
XN(t) = L akejkwot 
k=-N 
Chap.3 
(3.47) 
Let eN(t) denote the approximation error; that is, 
+N 
eN(t) = x(t) - XN(t) = x(t) - L akejkwor. 
k=- N 
(3.48) 
In order to determine how good any particular approximation is, we need to specify a 
quantitative measure of the size of the approximation error. The criterion that we will use 
is the energy in the error over one period: 
(3.49) 
As shown in Problem 3.66, the particular choice for the coefficients in eq. (3.47) that 
minimize the energy in the error is 
(3.50) 
Comparing eqs. (3.50) and (3.39), we see that eq. (3.50) is identical to the expression used 
to determine the Fourier series coefficients. Thus, if x(t) has a Fourier series representa-
tion, the best approximation using only a finite number of harmonically related complex 
exponentials is obtained by truncating the Fourier series to the desired number of terms. 
As N increases, new terms are added and EN decreases. If, in fact, x(t) has a Fourier series 
representation, then the limit of EN as N ~ oo is zero. 
Let us tum now to the question of when a periodic signal x(t) does in fact have a 
Fourier series representation. Of course, for any signal, we can attempt to obtain a set of 
Fourier coefficients through the use of eq. (3.39). However, in some cases, the integral 
in eq. (3.39) may diverge; that is, the value obtained for some of the ak may be infinite. 
Moreover, even if all of the coefficients obtained from eq. (3.39) are finite, when these 
coefficients are substituted into the synthesis equation (3.38), the resulting infinite series 
may not converge to the original signal x(t). 
Fortunately, there are no convergence difficulties for large classes of periodic signals. 
For example, every continuous periodic signal has a Fourier series representation for which 
the energy EN in the approximation error approaches 0 as N goes to oo. This is also true 
for many discontinuous signals. Since we will find it very useful to include discontinuous 
signals such as square waves in our discussions, it is worthwhile to investigate the issue 
of convergence in a bit more detail. Specifically, there are two somewhat different classes 
of conditions that a periodic signal can satisfy to guarantee that it can be represented by a 
Fourier series. In discussing these, we will not attempt to provide a complete mathematical 
justification; more rigorous treatments can be found in many texts on Fourier analysis. 9 
9See, for example, R. V. Churchill, Fourier Series and Boundary Value Problems, 3rd ed. (New York: 
McGraw-Hill Book Company, 1978); W. Kaplan, Operational Methods for Linear Systems (Reading, MA: 
Addison-Wesley Publishing Company, 1962); and the book by Dym and McKean referenced in footnote 2 of 
this chapter. 

Sec. 3.4 
Convergence of the Fourier Series 
197 
One class of periodic signals that are representable through the Fourier series is those 
signals which have finite energy over a single period, i.e., signals for which 
t Jx(t)J2 dt < oo. 
(3.51) 
When this condition is satisfied, we are guaranteed that the coefficients ak obtained from 
eq. (3.39) are finite. Furthermore, let XN(t) be the approximation to x(t) obtained by using 
these coefficients for lkl ::5 N: 
+N 
XN(t) = L akejkwor. 
k= - N 
(3.52) 
Then we are guaranteed that the energy EN in the approximation error, as defined in 
eq. (3.49), converges to 0 as we add more and more terms, i.e., as N ~ oo. That is, if 
we define 
+ oo 
e(t) = x(t) - L akeJkwot, 
(3.53) 
k= - oo 
then 
IT Je(t)l2 dt = 0. 
(3.54) 
As we will see in an example at the end of this section, eq. (3.54) does not imply that the 
signal x(t) and its Fourier series representation 
+ oo L akeJkwot 
(3.55) 
k= - oo 
are equal at every value oft. What it does say is that there is no energy in their difference. 
The type of convergence guaranteed when x(t) has finite energy over a single pe-
riod is quite useful. In this case eq. (3.54) states that the difference between x(t) and its 
Fourier series representation has zero energy. Since physical systems respond to signal en-
ergy, from this perspective x(t) and its Fourier series representation are indistinguishable. 
Because most of the periodic signals that we consider do have finite energy over a single 
period, they have Fourier series representations. Moreover, an alternative set of conditions, 
developed by P. L. Dirichlet and also satisfied by essentially all of the signals with which 
we will be concerned, guarantees that x(t) equals its Fourier series representation, except 
at isolated values oft for which x(t) is discontinuous. At these values, the infinite series 
of eq. (3.55) converges to the average of the values on either side of the discontinuity. 
The Dirichlet conditions are as follows: 
Condition 1. 
Over any period, x(t) must be absolutely integrable; that is, 
Ir Jx(t)l dt < oo. 
(3.56) 

198 
Fourier Series Representation of Periodic Signals 
Chap. 3 
As with square integrability, this guarantees that each coefficient ak will be finite, since 
iaki ::s _!_ f jx(t)e- jkwotl dt = _!_ f jx(t)j dt. 
T T 
T 
T 
So if 
fr jx(t)j dt < oo, 
then 
iaki < 00• 
A periodic signal that violates the first Dirichlet condition is 
1 
x(t) = (' 
0 < t ::s 1; 
that is, x(t) is periodic with period 1. This signal is illustrated in Figure 3.8(a). 
Condition 2. 
In any finite interval of time, · x(t) is of bounded variation; that is, there 
are no more than a finite number of maxima and minima during any single period of the 
signal. 
An example of a function that meets Condition 1 but not Condition 2 is 
x(t) = sin (2;). 0 < t ::s 1, 
as illustrated in Figure 3.8(b). For this function, which is periodic with T = 1, 
L
1 
jx(t)j dt < 1. 
(3.57) 
The function has, however, an infinite number of maxima and minima in the interval. 
Condition 3. In any finite interval of time, there are only a finite number of discontinu-
ities. Furthermore, each of these discontinuities is finite. 
An example of a function that violates Condition 3 is illustrated in Figure 3.8(c). The 
signal, of period T = 8, is composed of an infinite number of sections, each of which is 
half the height and half the width of the previous section. Thus, the area under one period of 
the function is clearly less than 8. However, there are an infinite number of discontinuities 
in each period, thereby violating Condition 3. 
As can be seen from the examples given in Figure 3.8, signals that do not satisfy 
the Dirichlet conditions are generally pathological in nature and consequently do not 
typically arise in practical contexts. For this reason, the question of the convergence of 
Fourier series will not play a particularly significant role in the remainder of the book. For 
a periodic signal that has no discontinuities, the Fourier series representation converges 
and equals the original signal at every value oft. For a periodic signal with a finite number 
of discontinuities in each period, the Fourier series representation equals the signal every-

~ 
I 
I 
-1 
Sec. 3.4 
Convergence of the Fourier Series 
x(t) 
(a) 
x(t) 
(b) 
x(t) 
(c) 
Figure 3.8 
Signals that violate the 
Dirichlet conditions: (a) the signal 
x(t) = 1/t for 0 < t ~ 1, a peri-
odic signal with period 1 (this signal 
violates the first Dirichlet condition); 
(b) the periodic signal of eq. (3.57), 
which violates the second Dirichlet 
condition; (c) a signal periodic with 
period 8 that violates the third Dirichlet 
condition [for 0 ~ t < 81 the value of 
x( t) decreases by a factor of 2 when-
ever the distance from t to 8 
decreases by a factor of 2; that is, 
x(t) = 1, 0 ~ t < 4, x(t) = 1/2, 
4 ~ t < 6, x(t) = 1/4, 6 ~ t < 7, 
x(t) = 1/8, 7 ~ t < 7.5, etc.]. 
199 
where except at the isolated points of discontinuity, at which the series converges to the 
average value of the signal on either side of the discontinuity. In this case the difference 
between the original signal and its Fourier series representation contains no energy, and 
consequently, the two signals can be thought of as being the same for all practical pur-

200 
Fourier Series Representation of Periodic Signals 
Chap.3 
poses. Specifically, since the signals differ only at isolated points, the integrals of both 
signals over any interval are identical. For this reason, the two signals behave identically 
under convolution and consequently are identical from the standpoint of the analysis of 
LTI systems. 
To gain some additional understanding of how the Fourier series converges for a 
periodic signal with discontinuities, let us return to the example of a square wave. In 
particular, in 1898, 10 an American physicist, Albert Michelson, constructed a harmonic 
analyzer, a device that, for any periodic signal x(t), would compute the truncated Fourier 
series approximation of eq. (3.52) for values of N up to 80. Michelson tested his device on 
many functions, with the expected result that XN(t) looked very much like x(t). However, 
when he tried the square wave, he obtained an important and, to him, very surprising re-
sult. Michelson was concerned about the behavior he observed and thought that his device 
might have had a defect. He wrote about the problem to the famous mathematical physicist 
Josiah Gibbs, who investigated it and reported his explanation in 1899. 
What Michelson had observed is illustrated in Figure 3.9, where we have shown 
XN(t) for several values of N for x(t), a symmetric square wave (T = 4T1 ). In each case, 
the partial sum is superimposed on the original square wave. Since the square wave satis-
fies the Dirichlet conditions, the limit as N ~ oo of XN(t) at the discontinuities should be 
the average value of the discontinuity. We see from the figure that this is in fact the case, 
since for any N, XN(t) has exactly that value at the discontinuities. Furthermore, for any 
other value oft, say, t = t 1, we are guaranteed that 
lim xN(tJ) = x(tJ). 
N ->oo 
Therefore, the squared error in the Fourier series representation of the square wave has 
zero area, as in eqs. (3.53) and (3.54). 
For this example, the interesting effect that Michelson observed is that the behavior 
of the partial sum in the vicinity of the discontinuity exhibits ripples and that the peak am-
plitude of these ripples does not seem to decrease with increasing N. Gibbs,showed that 
these are in fact the case. Specifically, for a discontinuity of unity height, the -partial sum 
exhibits a maximum value of 1.09 (i.e., an overshoot of 9% of the height of the discon-
tinuity), no matter how large N becomes. One must be careful to interpret this c~ectly, 
however. As stated before, for any fixed value oft, say, t = 
t~o the partial sums will con-
verge to the correct value, and at the discontinuity they will converge to one-half the sum 
of the values of the signal on either side of the discontinuity. However, the closer t1 is cho-
sen to the point of discontinuity, the larger N must be in order to reduce the error below a 
specified amount. Thus, as N increases, the ripples in the partial sums become compressed 
toward the discontinuity, but for any finite value of N, the peak amplitude of the ripples 
remains constant. This behavior has come to be known as the Gibbs phenomenon. The im-
plication is that the truncated Fourier series approximation XN(t) of a discontinuous signal 
x(t) will in general exhibit high-frequency ripples and overshoot x(t) near the disconti-
nuities. If such an approximation is used in practice, a large enough value of N should 
be chosen so as to guarantee that the total energy in these ripples is insignificant. In the 
limit, of course, we know that the energy in the approximation error vanishes and that the 
Fourier series representation of a discontinuous signal such as the square wave converges. 
10The historical information used in this example is taken from the book by Lanczos referenced in foot-
note 1 of this chapter. 

Sec. 3.4 
Convergence of the Fourier Series 
0 
(e) 
XN(t) 
t\~ 
II 
rvv ........
........ ..,v 
N= 79 
0 
(d) 
Figure 3.9 
Convergence of the Fourier series representation of a square 
wave: an illustration of the Gibbs phenomenon. Here, we have depicted the 
finite series approximation xN{t) = 2.:=-N akeikwot tor several values of N. 
201 
N=19 

202 
Fourier Series Representation of Periodic Signals 
Chap.3 
3.5 PROPERTIES OF CONTINUOUS-TIME FOURIER SERIES 
As mentioned earlier, Fourier series representations possess a number of important prop-
erties that are useful for developing conceptual insights into such representations, and they 
can also help to reduce the complexity of the evaluation of the Fourier series of many sig-
nals. In Table 3.1 we have summarized these properties, several of which are considered 
in the problems at the end of this chapter. In Chapter 4, in which we develop the Fourier 
transform, we will see that most of these properties can be deduced from corresponding 
properties of the continuous-time Fourier transform. Consequently we limit ourselves here 
to the discussion of several of these properties to illustrate how they may be derived, in-
terpreted, and used. 
Throughout the following discussion of selected properties from Table 3.1, we will 
find it convenient to use a shorthand notation to indicate the relationship between a peri-
odic signal and its Fourier series coefficients. Specifically, suppose that x(t) is a periodic 
signal with period T and fundamental frequency wo = 2TTIT. Then if the Fourier series 
coefficients of x(t) are denoted by ako we will use the notation 
~s 
x(t) ~ 
ak 
to signify the pairing of a periodic signal with its Fourier series coefficients. 
3.5.1 Linearity 
Let x(t) and y(t) denote two periodic signals with period T and which have Fourier series 
coefficients denoted by ak and bb respectively. That is, 
H 
x(t) ~ 
ak> 
~s 
y(t) ~ 
bk. 
Since x(t) and y(t) have the same period T, it easily follows that any linear combination 
of the two signals will also be periodic with period T. Furthermore, the Fourier series 
coefficients ck of the linear combination of x(t) and y(t), z(t) = Ax(t) + By(t), are given 
by the same linear combination of the Fourier series coefficients for x(t) and y(t). That is, 
~s 
z(t) = Ax(t) + By(t) ~ 
ck = Aak + Bbk. 
(3.58) 
The proof of this follows directly from the application of eq. (3.39). We also note that 
the linearity property is easily extended to a linear combination of an arbitrary number of 
signals with period T. 
3.5.2 Time Shifting 
When a time shift is applied to a periodic signal x(t), the period Tofthe signal is preserved. 
The Fourier series coefficients bk of the resulting signal y(t) = x(t- to) may be expressed 
as 
1 I 
. . 
bk = T T x(t- to)e- Jkwotdt. 
(3.59) 

Sec. 3.5 
Properties of Continuous-Time Fourier Series 
203 
Letting 7 = t - to in the integral, and noting that the new variable 7 will also range over 
an interval of duration T, we obtain 
where ak is the kth Fourier series coefficient of x(t). That is, if 
~s 
x(t) ~ 
ah 
then 
(3.60) 
One consequence of this property is that, when a periodic signal is shifted in time, the 
magnitudes of its Fourier series coefficients remain unaltered. That is, lbkl = iakl· 
3.5.3 Time Reversal 
The period T of a periodic signal x(t) also remains unchanged when the signal undergoes 
time reversal. To determine the Fourier series coefficients of y(t) = x( - t), let us consider 
the effect of time reversal on the synthesis equation (3.38): 
x( -t) = L ake- Jk27ft1T. 
(3.61) 
k= -
00 
Making the substitution k = - m, we obtain 
00 
y(t) = x( - t) = L a-meJm2miT. 
(3.62) 
m= - oo 
We observe that the right-hand side of this equation has the form of a Fourier series syn-
thesis equation for x( - t), where the Fourier series coefficients bk are 
(3.63) 
That is, if 
then 
~s 
x( - t) ~ 
a- k· 
In other words time reversal applied to a continuous-time signal results in a time reversal 
of the corresponding sequence of Fourier series coefficients. An interesting consequence 
of the time-reversal property is that if x(t) is even-that is, if x( -t) = x(t)-then its 
Fourier series coefficients are also even-i.e., a _k = ak. Similarly, if x(t) is odd, so that 
x( - t) = - x(t), then so are its Fourier series coefficients-i.e., a _k = -ak. 

204 
Fourier Series Representation of Periodic Signals 
Chap.3 
3.5.4 Time Scaling 
Time scaling is an operation that in general changes the period of the underlying signal. 
Specifically, if x(t) is periodic with period T and fundamental frequency w 0 = 27T/T, 
then x(at), where a is a positive real number, is periodic with period Tla and fundamen-
tal frequency aw0. Since the time-scaling operation applies directly to each of the har-
monic components of x(t), we may easily conclude that the Fourier coefficients for each 
of those components remain the same. That is, if x(t) has the Fourier series representation 
in eq. (3.38), then 
+oo 
x(at) = L akejk(awo)t 
k = - 00 
is the Fourier series representation of x(at). We emphasize that, while the Fourier coef-
ficients have not changed, the Fourier series representation has changed because of the 
change in the fundamental frequency. 
3.5.5 Multiplication 
Suppose that x(t) and y(t) are both periodic with period T and that 
5'5 
x(t) ~ 
ah 
5'5 
y(t) ~ 
bk. 
Since the product x(t)y(t) is also periodic with period T, we can expand it in a Fourier 
series with Fourier series coefficients hk expressed in terms of those for x(t) and y(t). The 
result is 
5'5 
00 
x(t)y(t) ~ 
hk = 2, albk- 1· 
(3.64) 
1= -00 
One way to derive this relationship (see Problem 3.46) is to multiply the Fourier series 
representations of x(t) and y(t) and to note that the kth harmonic component in the product 
will have a coefficient which is the sum of terms of the form a1bk- l· Observe that the sum 
on the right-hand side of eq. (3.64) may be interpreted as the discrete-time convolution of 
the sequence representing the Fourier coefficients of x(t) and the sequence representing 
the Fourier coefficients of y(t). 
3.5.6 Conjugation and Conjugate Symmetry 
Taking the complex conjugate of a periodic signal x(t) has the effect of complex conjuga-
tion and time reversal on the corresponding Fourier series coefficients. That is, if 
5'5 
x(t) ~ 
ah 
then 
(3.65) 

Sec. 3.5 
Properties of Continuous-Time Fourier Series 
205 
, 
I 
This property is easily proved by applying complex conjugation to both sides of eq. (3.38) 
and replacing the summation variable k by its-negative. 
Some interesting consequences of this property may be derived for x(t) real-that 
is, when x(t) = x*(t). In particular, in this case, we see from eq. (3.65) that the Fourier 
series coefficients will be conjugate symmetric, i.e., 
(3.66) 
as we previously saw in eq. (3.29). This in tum implies various symmetry properties (listed 
in Table 3.1) for the magnitudes, phases, real parts, and imaginary parts of the Fourier 
series coefficients of real signals. For example, from eq. (3.66), we see that if x(t) is real, 
then a0 is real and 
iakl = ia- ki· 
Also, if x(t) is real and even, then, from Section 3.5.3, ak = a- k· However, from eq. (3.66) 
we see that ak = a_ko so that ak = ak. That is, if x(t) is real and even, then so are its 
Fourier series coefficients. Similarly, it can be shown that if x(t) is real and odd, then its 
Fourier series coefficients are purely imaginary and odd. Thus, for example, a0 = 0 if x(t) 
is real and odd. This and the other symmetry properties of the Fourier series are examined 
further in Problem 3.42. 
3.5.7 Parseval's Relation for Continuous-Time Periodic Signals -
As shown in Problem 3.46, Parseval's relation for continuous-time periodic signals is 
(3.67) 
where the ak are the Fourier series coefficients of x(t) and Tis the period of the signal. 
Note that the left-hand side of eq. (3.67) is the average power (i.e., energy per unit 
time) in one period ofthe periodic signal x(t). Also, 
~ t lakejkwof dt = ~IT iaki2dt = lakl2, 
(3.68) 
so that lakl2 is the average power in the kth harmonic component of x(t). Thus, what Par-
seval's relation states is that the total average power in a periodic signal equals the sum of 
the average powers in all of its harmonic components. 
3.5.8 Summary of Properties of the Continuous-Time 
Fourier Series 
In Table 3.1, we summarize these and other important properties of continuous-time 
Fourier series. 
3.5.9 Examples 
Fourier series properties, such as those listed in Table 3.1, may be used to circumvent some 
of the algebra involved in determining the Fourier coefficients of a given signal. In the next 

206 
Fourier Series Representation of Periodic Signals 
Chap.3 
TABLE 3.1 
PROPERTIES OF CONTINUOUS-TIME FOURIER SERIES 
Property 
Linearity 
Time Shifting 
Frequency Shifting 
Conjugation 
Time Reversal 
Time Scaling 
Periodic Convolution 
Multiplication 
Differentiation 
Integration 
Conjugate Symmetry for 
Real Signals 
Real and Even Signals 
Real and Odd Signals 
Even-Odd Decomposition 
of Real Signals 
Section 
3.5.1 
3.5.2 
3.5.6 
3.5.3 
3.5.4 
3.5.5 
3.5.6 
3.5.6 
3.5.6 
Periodic Signal 
x(t)} Periodic with period T and 
y(t) 
fundamental frequency w0 = 27r/T 
Ax(t) + By(t) 
x(t - to) 
eJMw0t x(t) = eiM(27rfT)t x(t) 
x·(r) 
x(-t) 
x(at), a > 0 (periodic with period Tla) 
t 
X(T)y(t - T)dT 
x(t)y(t) 
dx(t) 
dt 
I' ( d (finite valued and 
X t) t 
-ro 
periodic only if a0 = 0) 
x(t) real 
x(t) real and even 
x( t) real and odd 
{ 
x,(t) = &t-{x(t)} 
X 0 (t) = 0d{x(t)} 
[x(t) real] 
[x(t) real] 
Parseval's Relation for Periodic Signals 
Fourier Series Coefficients 
Aak + Bbk 
ake- Jkwoto = ake- Jk(27rtTJto 
ak- M 
a:_" 
a _k 
ak 
"k 
"k27r 
J woak = J yak 
C~o )ak = ck(2~/T) )ak 
l
~~~k~~~ <R~{a_k} 
dm{ak} = -dm{a- k} 
lad= ia-ki 
<r.ak = -<r.a- k 
ak real and even 
ak purely imaginary and odd 
<R~{ad 
jdm{ad 
three examples, we illustrate this. The last example in this section then demonstrates how 
properties of a signal can be used to characterize the signal in great detail. 
Example 3.6 
Consider the signal g(t) with a fundamental period of 4, shown in Figure 3.10. We 
could determine the Fourier series representation of g(t) directly from the analysis equa-
tion (3.39). Instead, we will use the relationship of g(t) to the symmetric periodic square 
wave x(t) in Example 3.5. Referring to that example, we see that, with T = 4 and 
T 1 = 1, 
g(t) = x(t - 1) - 1/2. 
(3.69) 

Sec. 3.5 
Properties of Continuous-Time Fourier Series 
207 
g(t) 
1 
2 
- 2 
- 1 
1 
2 
_ _1 
2 
Figure 3. 1 o Periodic signal for Example 3.6. 
The time-shift property in Table 3.1 indicates that, if the Fourier Series coefficients of 
x(t) are denoted by ak> the Fourier coefficients of x(t - 1) may be expressed as 
(3.70) 
The Fourier coefficients of the de offset in g(t)-i.e., the term - 112 on the right-hand 
side of eq. (3.69)- are given by , 
_ { 0, 
for k ¥- 0 
Ck -
I 
& 
k 
0. 
- 2, 
10f 
= 
(3.71) 
Applying the linearity property in Table 3.1, we conclude that the coefficients for g(t) 
may be expressed as 
where each a k may now be replaced by the corresponding expression from eqs. (3.45) 
and (3.46), yielding 
dk = 
k1T 
• 
• 
{ 
sin(1rk/2) e- j k1rl2 
for k ¥- 0 
0, 
fork= 0 
(3.72) 
Example 3.7 
Consider the triangular wave signal x(t) with period T = 4 and fundamental frequency 
w0 = 7T/2 shown in Figure 3.11. The derivative of this signal is the signal g(t) in Exam-
x(t) 
- 2 
2 
Figure 3.11 
Triangular wave signal in Example 3.7. 

208 
Fourier Series Representation of Periodic Signals 
Chap.3 
pie 3.6. Denoting the Fourier coefficients of g(t) by dk and those of x(t) by eb we see 
that the differentiation property in Table 3.1 indicates that 
(3.73) 
This equation can be used to express ek in terms of db except when k = 0. Specifically, 
from eq. (3.72), 
_ 2dk _ 2sin(-7Tk/2) -jkTr/2 
ek -
j k7r -
j(hr-)2 
e 
, 
k ,= 0. 
(3.74) 
Fork = 0, e0 can be determined by finding the area under one period of x(t) and dividing 
by the length of the period: 
Example 3.8 
1 
eo= 2· 
Let us examine some properties of the Fourier series representation of a periodic train of 
impulses, or impulse train. This signal and its representation in terms of complex expo-
nentials will play an important role when we discuss the topic of sampling in Chapter 7. 
The impulse train with period T may be expressed as 
"' 
x(t) = L B(t - kT); 
(3.75) 
k =-00 
it is illustrated in Figure 3.12(a). To determine the Fourier series coefficients ak, we use 
eq. (3.39) and select the interval of integration to be - T/2 ~ t ~ T/2, avoiding the 
placement of impulses at the integration limits. Within this interval, x(t) is the same as 
B(t), ~it follows.that 
1JT/2 
. 
1 
ak = -
B(t)e- Jk211"tiT dt = -. 
T - T/2 
T 
(3.76) 
In other words, all the Fourier series coefficients of the impulse train are identical. These 
coefficients are also real valued and even (with respect to the index k). This is to be 
expected, since, according to Table 3.1, any real and even signal (such as our impulse 
train) should have real and even Fourier coefficients. 
The impulse train also has a straightforward relationship to square-wave signals 
such as g(t) in Figure 3.6, which we repeat in Figure 3.12(b). The derivative of g(t) is 
the signal q(t) illustrated in Figure 3.12(c). We may interpret q(t) as the difference of 
two shifted versions of the impulse train x(t). That is, 
q(t) = x(t + T1) -
x(t - T1 ). 
(3.77) 
Using the properties of Fourier series, we can now compute the Fourier series coeffi-
cients of q(t) and g(t) without any further direct evaluation of the Fourier series analysis 
equation. First, from the time-shifting and linearity properties, we see from eq. (3.77) 
that the Fourier series coefficients bk of q(t) may be expressed in terms of the Fourier 
series coefficients ak of x(t); that is, 

Sec. 3.5 
Properties of Continuous-Time Fourier Series 
x(t) 
- T 
T 
(a) 
g(t) 
- T/2 
T/2 
(b) 
q(t) 
- T/2 
T/2 
- 1 
(c) 
Figure 3.12 
(a) Periodic train of impulses; (b) periodic square wave; 
(c) derivative of the periodic square wave in (b). 
where w0 = 21T!T. Using eq. (3.76), we then have 
b 
1 [ 1·kw r 
_1·kw T ] 
2j sin(kwoT1 ) 
k =y; e 
O l -e 
O l 
= 
T 
. 
209 
Finally, since q(t) is the derivative of g(t), we can use the differentiation property in 
Table 3.1 to write 
(3.78) 
where the ck are the Fourier series coefficients of g(t) .. Thus, 
bk 
2j sin(kw0TI) 
c k = -- = -=---:-:-~=--::..:_ 
jkwo 
jkwoT 
k ¥- 0, 
(3.79) 

210 
Fourier Series Representation of Periodic Signals 
Chap.3 
where we have used the fact that w0T = 27T. Note that eq. (3.79) is valid fork~ 0, 
since we cannot solve for c0 from eq. (3.78) with k = 0. However, since c0 is just the 
average value of g(t) over one period, we can determine it by inspection from Figure 
3.12(b): 
(3.80) 
Eqs. (3.80) and (3.79)are identical to eqs. (3.42) and (3.44), respectively, for the Fourier 
series coefficients of the square wave derived in Example 3.5. 
The next example is chosen to illustrate the use of many of the properties in 
Table 3.1. 
Example 3.9 
Suppose we are given the following facts about a signal x(t): 
1. x(t) is a real signal. 
2. x(t) is periodic with period T = 4, and it has Fourier series coefficients ak. 
3. ak = 0 for lkl > 1. 
4. The signal with Fourier coefficients bk = e- j"'kl2a- k is odd. 
5. i f4 ix(t)l2dt = 1/2. 
Let us show that this information is sufficient to determine the signal x(t) to within a 
sign factor. According to Fact 3, x(t) has at most three nonzero Fourier series coefficients 
ak: a0, at, and a- t· Then, since x(t) has fundamental frequency w 0 = 27T/4 = 7T/2, it 
follows that 
Since x(t) is real (Fact 1), we can use the symmetry properties in Table 3.1 to conclude 
that a0 is real and at = a*- t· Consequently, 
(3.81) 
Let us now determine the signal corresponding to the Fourier coefficients bk given 
in Fact 4. Using the time-reversal property from Table 3.1, we note that a- k corresponds 
to the signal x(-t). Also, the time-shift property in the table indicates that multiplication 
of the kth Fourier coefficient by e - j k"'12 = e - j kwo corresponds to the underlying signal. 
being shifted by 1 to the right (i.e., having t replaced by t - 1). We conclude that the 
coefficients bk correspond to the signal x(-(t- 1)) = x( - t + 1), which, according to 
Fact 4, must be odd. Since x(t) is real, x( - t + 1) must also be real. From Table 3.1, 
it then follows that the Fourier coefficients of x( - t + 1) must be purely imaginary and 
odd. Thus, b0 = 0 and h- t = -bt . Since time-reversal and time-shift operations cannot 
change the average power per period, Fact 5 holds even if x(t) is replaced by x( -t + 1). 
That is, 
(3.82) 

Sec. 3.6 
Fourier Series Representation of Discrete-Time Periodic Signals 
211 
We can now use Parseval's relation to conclude that 
(3.83) 
Substituting b1 = -b- 1 in this equation, we obtain lbd = 1/2. Since b1 is also known 
to be purely imaginary, it must be either j/2 or - j/2. 
Now we can translate these conditions on b0 and b1 into equivalent statements on 
a0 and a 1. First, since b0 = 0, Fact 4 implies that a0 = 0. With k = 1, this condition 
implies that a 1 = e - j1T12b_1 = - jb_, = jb 1• Thus, if we take b1 = j/2, then a 1 = 
-1/2, and therefore, from eq. (3.81), x(t) = -cos( 1Tt/2). Alternatively, if we take b 1 = 
- j/2, then a 1 = 112, and therefore, x(t) = cos(7Tt/2). 
3.6 FOURIER SERIES REPRESENTATION OF DISCRETE-TIME 
PERIODIC SIGNALS 
In this section, we consider the Fourier series representation of discrete-time periodic sig-
nals. While the discussion closely parallels that of Section 3.3, there are some important 
differences. In particular, the Fourier series representation of a discrete-time periodic sig-
nal is a finite series, as opposed to the infinite series representation required for continuous-
time periodic signals. As a consequence, there are no mathematical issues of convergence 
such as those discussed in Section 3.4. 
3.6.1 Linear Combinations of Harmonically Related Complex 
Exponentials 
As defined in Chapter 1, a discrete-time signal x[n] is periodic with period N if 
x[n] = x[n + N]. 
(3.84) 
The fundamental period is the smallest positive integer N for which eq. (3.84) holds, and 
wo = 27T/ N is the fundamental frequency. For example, the complex exponential ei<2Tr1 N )n 
is periodic with period N. Furthermore, the set of all discrete-time complex exponential 
signals that are periodic with period N is given by 
.,1.. [n) = ejkw0n = ejk(2TriN)n k = Q + 1 +2 
'f'k 
' 
' -
J 
-
' •••• 
(3.85) 
All of these signals have fundamental frequencies that are multiples of 27T/ N and thus are 
harmonically related. 
As mentioned in Section 1.3.3, there are only N distinct signals in the set given 
by eq. (3.85). This is a consequence of the fact that discrete-time complex exponen-
tials which differ in frequency by a multiple of 27T are identical. Specifically, c/Jo[n] = 
cPN[n], cP1 [n] = cPN+ 1 [n], and, in general, 
(3.86) 
That is, when k is changed by any integer multiple of N, the identical sequence is gener-
ated. This differs from the situation in continuous time in which the signals cPk(t) defined 
in eq. (3.24) are all different from one another. 

212 
Fourier Series Representation of Periodic Signals 
Chap.3 
We now wish to consider the representation of more general periodic sequences in 
terms of linear combinations of the sequences cPk[n] in eq. (3.85). Such a linear combina-
tion has the form 
x[n] = .2:= akcPk[n] = .2:= akejkwon = .2:= akejk(2TriN)n. 
(3.87) 
k 
k 
k 
Since the sequences cPk[n] are distinct only over a range of N successive values of k, the 
summation in eq. (3.87) need only include terms over this range. Thus, the summation is 
on k, as k varies over a range of N successive integers, beginning with any value of k. We 
indicate this by expressing the limits of the summation as k = (N). That is, 
x[n] = .2:= akcPk[n] = .2:= akejkwon = .2:= akejk(2TriN)n. 
(3.88) 
k= (N) 
k= (N) 
k=(N) 
For example, k could take on the values k = 0, 1, ... , N - 1, or k = 3, 4, . . . , N + 2. In 
either case, by virtue of eq. (3.86), exactly the same set of complex exponential sequences 
appears in the summation on the right-hand side of eq. (3.88). Equation (3.88) is referred 
to as the discrete-time Fourier series and the coefficients ak as the Fourier series coeffi-
cients. 
3.6.2 Determination of the Fourier Series Representation 
of a Periodic Signal 
Suppose now that we are given a sequence x[n] that is periodic with fundamental period 
N. We would like to determine whether a representation of x[n] in the form of eq. (3.88) 
exists and, if so, what the values of the coefficients ak are. This question can be phrased in 
terms of finding a solution to a set of linear equations. Specifically, if we evaluate eq. (3.88) 
for N successive values of n corresponding to one period of x[n], we obtain 
x[O] = .2:= ak, 
k= (N) 
x[l] = .2:= akej2TrkiN, 
k=(N) 
x[N- 1) = .2:= akejhk(N- I)IN. 
k= (N) 
(3.89) 
Thus, eq. (3.89) represents a set of N linear equations for theN unknown coefficients ak 
as k ranges over a set of N successive integers. It can be shown that this set of equations 
is linearly independent and consequently can be solved to obtain the coefficients ak in 
terms of the given values of x[n]. In Problem 3.32, we consider an example in which the 
Fourier series coefficients are obtained by explicitly solving the set of N equations given 
in eq. (3.89). However, by following steps parallel to those used in continuous time, it is 
possible to obtain a closed-form expression for the coefficients ak in terms of the values 
of the sequence x [n]. 

Sec. 3.6 
Fourier Series Representation of Discrete-Time Periodic Signals 
The basis for this result is the fact, shown in Problem 3.54, that 
L ei k(27rl N)n = { N, 
n= (N) 
O, 
k = 0, ±N, ±2N, . .. 
otherwise 
213 
(3.90) 
Equation (3.90) states that the sum over one period of the values of a periodic complex 
exponential is zero, unless that complex exponential is a constant. 
Now consider the Fourier series representation of eq. (3.88). Multiplying both sides 
bye- Jr(Z'TI'IN)n and summing over N terms, we obtain 
L x[n]e - jr(2'TI'IN)n = L L akej (k-r)(2'TI'IN)n. 
(3.91) 
n=(N) 
n= (N) k= (N) 
Interchanging the order of summation on the right-hand side, we have 
L x[n]e- jr(2'T1'/N)n = L ak L ei<k-r)(27r!N)n. 
(3.92) 
n= (N) 
k= (N) 
n=(N) 
From the identity in eq. (3.90), the innermost sum on non the right-hand side of eq. (3.92) 
is zero, unless k- r is zero or an integer multiple of N. Therefore, if we choose values for 
r over the same range as that over which k varies in the outer summation, the innermost 
sum on the right-hand side of eq. (3.92) equals N if k = rand 0 if k "# r. The right-hand 
side of eq. (3.92) then reduces to Nan and we have 
ar = ~ L x[n]e - j r(2'TI'IN)n. 
n=(N) 
(3.93) 
This provides a closed-form expression for obtaining the Fourier series coefficients, 
and we have the discrete-time Fourier series pair: 
x[n] = 
L akejkwon = L akejk(2'TI'IN)n, 
(3.94) 
k= (N) 
k= (N) 
ak = ~ L x[n]e - jkwon = ~ L x[n]e - Jk(2'T1'/N)n. 
n=(N) 
n=(N) 
(3.95) 
These equations play the same role for discrete-time periodic signals that eqs. (3.38) and 
(3.39) play for continuous-time periodic signals, with eq. (3.94) the synthesis equation and 
eq. (3.95) the analysis equation. As in continuous time, the discrete-time Fourier series 
coefficients ak are often referred to as the spectral coefficients of x[n]. These coefficients 
specify a decomposition of x[n] into a sum of N hamionically related complex exponen-
tials. 
Referring to eq. (3.88), we see that if we take kin the range from 0 toN - 1, we 
have 
(3.96) 

214 
Fourier Series Representation of Periodic Signals 
Chap.3 
Similarly, if k ranges from 1 toN, we obtain 
(3.97) 
From eq. (3.86), </>o[n] = <f>N[n], and therefore, upon comparing eqs. (3.96) and (3.97), 
we conclude that ao = aN. Similarly, by letting k range over any set of N consecutive 
integers and using eq. (3.86), we can conclude that 
(3.98) 
That is, if we consider more than N sequential values of k, the values ak repeat periodically 
with period N. It is important that this fact be interpreted carefully. In particular, since there 
are only N distinct complex exponentials that are periodic with period N, the djscrete-
time Fourier series representation is a finite series with N terms. Therefore, if we fix the 
N consecutive values of k over which we define the Fourier series in eq. (3.94), we will 
obtain a set of exactly N Fourier coefficients from eq. (3.95). On the other hand, at times 
it will be convenient to use different sets of N values of k, and consequently, it is useful 
to regard eq. (3.94) as a sum over any arbitrary set of N successive values of k. For 
this reason, it is sometimes convenient to think of ak as a sequence defined for all values 
of k, 'but where only N successive elements in the sequence will be used in the Fourier 
series representation. Furthermore, since the <f>k[n] repeat periodically with period N as 
we vary k [eq. (3.86)], so must the ak [eq. (3.98)]. This viewpoint is illustrated in the next 
example. 
Example 3. 1 0 
Consider the signal 
x[n] = sinwon, 
(3.99) 
which is the discrete-time counterpart of the signal x(t) = sin w0t of Example 3.3. x[n] 
is periodic only if 27rlw0 is an integer or a ratio of integers. For the case when 27r/w0 is 
an integer N, that is, when 
27T' 
wo = N' 
x[n] is periodic with fundamental period N, and we obtain a result that is exactly analo-
gous to the continuous-time case. Expanding the signal as a sum of two complex expo-
nentials, we get 
(3.100) 
Comparing eq. (3.100) with eq. (3.94), we see by inspection that 
(3.101) 

Sec. 3.6 
Fourier Series Representation of Discrete-Time Periodic Signals 
215 
and the remaining coefficients over the interval of summation are zero. As described 
previously, these coefficients repeat with period N; thus, aN+l is also equal to (l/2j) and 
aN- I equals ( -l/2j). The Fourier series coefficients for this example with N = 5 are 
illustrated in Figure 3.13. The fact that they repeat periodically is indicated. However, 
only one period is utilized in the synthesis equation (3.94). 
1 
2] 
-8-7 
k 
Figure 3.13 
Fourier coefficients for x[n] = sin(27T/5)n. 
Consider now the case when 27T/w0 is a ratio of integers-that is, when 
Assuming thatM andN do not have any common factors, x[n] has a fundamental period 
of N. Again expanding x[n] as a sum of two complex exponentials, we have 
x[n] = I_ejM(27riN)n _ I_e - jM(27riN)n 
2j 
2j 
' 
from which we can determine by inspection that aM = (l/2j), a - M = ( -112j), and the 
remaining coefficients over one period of length N are zero. The Fourier coefficients 
for this example with M = 3 and N = 5 are depicted in Figure 3.14. Again, we have 
indicated the periodicity of the coefficients. For example, for N = 5, a2 = a- 3 , which 
in our example equals ( -112j). Note, however, that over any period of length 5 there are 
only two nonzero Fourier coefficients, and therefore there are only two nonzero terms in 
the synthesis equation. 
_1_ 
2j 
1 
2] 
Figure 3.14 
Fourier coefficients for x[n] = sin 3(27T/5)n. 
k 

Sec. 3.6 
Fourier Series Representation of Discrete-Time Periodic Signals 
.... 111 ....... 111 ....... 1iL .... 111 ....... l1l .... 
- 2N 
- N 
0 
N 
2N 
k 
dm(aJ 
(a) 
k 
-rr/2 
k 
- -rr/2 
(b) 
Figure 3.15 
(a) Real and imaginary parts of the Fourier series coefficients 
in Example 3.11; (b) magnitude and phase of the same coefficients. 
217 

218 
Fourier Series Representation of Periodic Signals 
Chap.3 
Example 3.12 
In this example, we consider the discrete-time periodic square wave shown in Fig-
ure 3.16. We can evaluate the Fourier series for this signal using eq. (3.95). Because 
x[n] = 1 for -N1 :-=;; n :-=;; Nh it is particularly convenient to choose the length-N 
interval of summation in eq. (3.95) so that it includes the range - N 1 :-=;; n :-=;; N 1• In this 
case, we can express eq. (3.95) as 
(3.102) 
.IIIII ..... ~IIIII ...... IIIII .. ··· 
-N 
-N1 0 N1 
N 
n 
Figure 3. 16 
Discrete-time periodic square wave. 
Letting m = n + N 1, we observe that eq. (3.102) becomes 
(3.103) 
1 2N, 
. 
ak = N .2: e-jk(27r!N)(m- N1) 
m=O 
1 
2N, 
= Nejk(27r!N)N1 .2: e- jk(27r!N)m. 
m=O 
The summation in eq. (3 .1 03) consists of the sum of the first 2N 1 + 1 terms in a geometric 
series, which can be evaluated using the result of Problem 1.54. This yields 
a 
= -ejk(27rtN)N1 
1 
(1 _ e- jk27r(2N1 + 1)/N) 
k 
N 
1 -
e jk(27r!N) 
_ 1 e- jk(27ri2N)[ejk27r(N 1 + 1/2)/N _ e - jk27r(N1 + 1/2)/N) 
(3.104) 
-
N 
e- jk(27ri2N>[ejk(27ri2N) _ e- jk(27rt2N)] 
_ 1 sin[27Tk(N1 + 1/2)/N] 
- N 
sin(7Tk/N) 
k ~ 0, ±N, ±2N, ... 
and 
k = 0, ±N, ±2N, .... 
(3.105) 
The coefficients ak for 2N1 + 1 = 5 are sketched for N = 10, 20, and 40 in Figures 
3.17(a), (b), and (c), respectively. 
In discussing the convergence of the continuous-time Fourier series in Section 3.4, 
we considered the example of a symmetric square wave and observed how the finite sum in 
eq. (3.52) converged to the square wave as the number of terms approached infinity. In par-

Sec. 3.6 
Fourier Series Representation of Discrete-Time Periodic Signals 
219 
(a) 
(b) 
1.!11111111111 .. 1 
I"'" I 
1.!111111111111.1 
I"'" I 
I.!IIIIIIIIIIIJ.I . 
I' 
• •n• " 
"••n...:8 _ 4 0 
4 
8 .. 1 n• • 
• 1111 .. 
• r k 
(c) 
Figure 3. 1 7 
Fourier series coefficients for the periodic square wave of Ex-
ample 3.12; plots of Nak for 2M + 1 = 5 and (a) N = 10; (b) N = 20; and 
(c) N = 40. 
ticular, we observed the Gibbs phenomenon at the discontinuity, whereby, as the number 
of terms increased, the ripples in the partial sum (Figure 3.9) became compressed toward 
the discontinuity, with the peak amplitude of the ripples remaining constant independently 
of the number of terms in the partial sum. Let us consider the analogous sequence of partial 
sums for the discrete-time square wave, where, for convenience, we will assume that the 
period N is odd. In Figure 3.18, we have depicted the signals 
M 
x[n] = L, akejk(2TriN)n 
(3.106) 
k = - M 
for the example of Figure 3.16 with N = 9, 2N1 + 1 = 5, and for several values of M. 
ForM = 4, the partial sum exactly equals x[n]. We see in particular that in contrast to the 
continuous-time case, there are no convergence issues and there is no Gibbs phenomenon. 
In fact, there are no convergence issues with the discrete-time Fourier series in general. 
The reason for this stems from the fact that any discrete-time periodic sequence x[n] is 
completely specified by a finite number N of parameters, namely, the values of the se-
quence over one period. The Fourier series analysis equation (3.95) simply transforms this 
set of N parameters into an equivalent set-the values of theN Fourier coefficients- and 

220 
Fourier Series Representation of Periodic Signals 
Chap. 3 
M= 1 
riiii, .. ,IIIII, .. ,IIIII, .. ,IIIII, .. ,IIIII 
-18 
- 9 
0 
9 
18 
n 
(a) 
M= 2 
JJJJJ,,,,Illllr,,rlllllr,,rlllllr,,rlllli 
-18 
- 9 
0 
· 
9 
18 
n 
(b) 
M= 3 
IIIII .... IIIII .... IIIII .... IIIII .... IIIII 
-18 
- 9 
0 
9 
18 
n 
(c) 
M= 4 
IIIII .... IIIII .... IIIII .... IIIII .... IIIII 
- 18 
- 9 
0 
9 
18 
n 
(d) 
Figure 3.18 
Partial sums of eqs. 
(3.1 06) and (3.1 07) for the periodic 
square wave of Figure 3.16 with 
N = 9 and 2N1 + 1 = 5: (a) M = 1; 
(b) M = 2; (c) M = 3; (d) M = 4. 
the synthesis equation (3.94) tells us how to recover the values of the original sequence in 
terms of afinite series. Thus, if N is odd and we take M = (N- 1)/2 in eq. (3.106), the 
sum includes exactly N terms, and consequently, from the synthesis equations, we have 
x[n] = x[n]. Similarly, if N is even and we let 
M 
x[n] = 
~ akejk(21r/N)n, 
(3.107) 
k = - M+l 
then with M = N/2, this sum consists of N terms, and again, we can conclude from 
eq. (3.94) that x[n] = x[n]. 
In contrast, a continuous-time periodic signal takes on a cqntinuum of values over 
a single period, and an infinite number of Fourier coefficients are required to represent it. 

Sec. 3.7 
Properties of Discrete-Time Fourier Series 
221 
Thus, in general, none of the finite partial sums in eq. (3.52) yield the exact values of x(t), 
and convergence issues, such as those considered in Section 3.4, arise as we consider the 
problem of evaluating the limit as the number of terms approaches infinity. 
3.7 PROPERTIES OF DISCRETE-TIME FOURIER SERIES 
There are strong similarities between the properties of discrete-time and continuous-time 
Fourier series. This can be readily seen by comparing the discrete-time Fourier series 
properties summarized in Table 3.2 with their continuous-time counterparts in Table 3.1. 
TABLE 3.2 
PROPERTIES OF DISCRETE-TIME FOURIER SERIES 
Property 
Linearity 
Time Shifting 
Frequency Shifting 
Conjugation 
Time Reversal 
Time Scaling 
Periodic Convolution 
Multiplication 
First Difference 
Running Sum 
Conjugate Symmetry for 
Real Signals 
Real and Even Signals 
Real and Odd Signals 
Even-Odd Decomposition 
of Real Signals 
Periodic Signal 
x[n] } Periodic with period Nand 
y[n] 
fundamental frequency wo = 27TIN 
Ax[n] + By[n] 
x[n- no] 
ejM(2'1TIN)n x[n] 
x"[n] 
x[-n] 
{ 
x[nlm], 
if n is a multiple of m 
X(m)[n] = 
. 
. 
. 
0, 
1f n IS not a multiple of m 
(periodic with period mN) 
L x[r]y[n - r] 
r- (N ) 
x[n]y[n] 
x[n] - x[n - 1] 
f x[k] (~nite valued and periodic only) 
k - - oo 
\If ao = 0 
x[n] real 
x[n] real and even 
x[n] real and odd 
{ 
x,[n] = &tt{x[n]} 
X 0 [n] = Od{x[n]} 
[x[n] real] 
[x[n] real] 
Parseval's Relation for Periodic Signals 
1 N L lx[nJI
2 = L lakl
2 
n-(N) 
k- (N) 
Fourier Series Coefficients 
ak } Periodic with 
bk 
period N 
Aak + Bbk 
ake- jk(2'1TIN)no 
ak- M 
a"_k 
a- k 
1 
(viewed as periodic) 
- ak 
m 
with period mN 
L a1bk- l 
1- (N) 
(1 - e- jk(2'1TtN))ak 
( (1 _ e-
1
jk(Z'1TtN) ) )ak 
!
~~~k~._~ <Ri?{a . .} 
dm{a.} = - dm{a . .} 
lakl = la- kl 
1:ak = -1:a- k 
a, real and even 
a, purely imaginary and odd 
<Ri?{a,} 
jdm{ak} 

222 
Fourier Series Representation of Periodic Signals 
Chap. 3 
The derivations of many of these properties are very similar to those of the corresponding 
properties for continuous-time Fourier series, and several such derivations are considered 
in the problems at the end of the chapter. In addition, in Chapter 5 we will see that most of 
the properties can be inferred from corresponding properties of the discrete-time Fourier 
transform. Consequently, we limit the discussion in the following subsections to only a few 
of these properties, including several that have important differences relative to those for 
continuous time. We also provide examples illustrating the usefulness of various discrete-
time Fourier series properties for developing conceptual insights and helping to reduce the 
complexity of the evaluation of the Fourier series of many periodic sequences. 
As with continuous time, it is often convenient to use a shorthand notation to indicate 
the relationship between a periodic signal and its Fourier series coefficients. Specifically, 
if x[n] is a periodic signal with period Nand with Fourier series coefficients denoted by 
at. then we will write 
3. 7. 1 Multiplication 
The multiplication property of the Fourier series representation is one example of a prop-
erty that reflects the difference between continuous time and discrete time. From Table 3.1, 
the product of two continuous-time signals of period T results in a periodic signal with pe-
riod T whose sequence of Fourier series coefficients is the convolution of the sequences 
of Fourier series coefficients of the two signals being multiplied. In discrete time, suppose 
that 
and 
~s 
y[n]-- bk 
are both periodic with period N. Then the product x[n]y[n] is also periodic with period N, 
and, as shown in Problem 3.57, its Fourier coefficients, dt. are given by 
~s 
x[n]y[n] -- dk = L atbk- 1· 
i =(N) 
(3.108) 
Equation (3.108) is analogous to the definition of convolution, except that the summation 
variable is now restricted to an interval of N consecutive samples. As shown in Problem 
3.57, the summation can be taken over any set of N consecutive values of l. We refer to this 
type of operation as a periodic convolution between the two periodic sequences of Fourier 
coefficients. The usual form of the convolution slim (where the summation variable ranges 
from - oo to oo) is sometimes referred to as aperiodic convolution, to distinguish it from 
periodic convolution. 
3. 7. 2 First Difference 
The discrete-time parallel to the differentiation property of the continuous-time Fourier 
series involves the use of the first-difference operation, which is defined as x[n]- x[n - 1]. 

Sec. 3.7 
Properties of Discrete-Time Fourier Series 
223 
If x[n] is periodic with period N, then so is y[n], since shifting x[n] or linearly combining 
x[n] with another periodic signal whose period is N always results in a periodic signal 
with period N. Also, if 
then the Fourier coefficients corresponding to the first difference of x[n] may be expressed 
as 
!!S 
. 
. 
x[n] - x[n- 1] ~ 
(1 - e-Jk(27rtN>)ab 
(3.109) 
which is easily obtained by applying the time-shifting and linearity properties in Table 3.2. 
A common use of this property is in situations where evaluation of the Fourier series co-
efficients is easier for the first difference than for the original sequence. (See Problem 
3.31.) 
3.7.3 Parseval's Relation for Discrete-Time Periodic Signals 
As shown in Problem 3.57, Parseval's relation for discrete-time periodic signals is given 
by 
(3.110) 
where the ak are the Fourier series coefficients of x[n] and N is the period. As in the 
continuous-time case, the left-hand side of Parseval's relation is the average power in one 
period for the periodic signal x[n]. Similarly,lakl2 is the average power in the kth harmonic 
component of x[n]. Thus, once again, Parseval's relation states that the average power in 
a periodic signal equals the sum of the average powers in all of its harmonic components. 
In discrete time, of course, there are only N distinct harmonic components, and since the 
ak are periodic with period N, the sum on the right-hand side of eq. (3.110) can be taken 
over any N consecutive values of k. 
3.7.4 Examples 
In this subsection, we present several examples illustrating how properties of the discrete-
time Fourier series can be used to characterize discrete-time periodic signals and to com-
pute their Fourier series representations. Specifically, Fourier series properties, such as 
those listed in Table 3.2, may be used to simplify the process of determining the Fourier 
series coefficients of a given signal. This involves first expressing the given signal in terms 
of other signals whose Fourier series coefficients are already known or are simpler to com-
pute. Then, using Table 3.2, we can express the Fourier series coefficients of the given 
signal in terms of the Fourier series coefficients of the other signals. This is illustrated in 
Example 3.13. Example 3.14 then illustrates the determination of a sequence from some 
partial information. In Example 3.15 we illustrate the use of the periodic convolution prop-
erty in Table 3.2. 
· 
I 

224 
Fourier Series Representation of Periodic Signals 
Chapo3 
Example 3.13 
Let us consider the problem of finding the Fourier series coefficients ak of the sequence 
x[n] shown in Figure 3o19(a)o This sequence has a fundamental period of 50 We observe 
that x[n] may be viewed as the sum of the square wave x 1 [n] in Figure 3o19(b) and the 
de sequence x2[n] in Figure 3o19(c)o Denoting the Fourier series coefficients of x 1 [n] by 
bk and those of x2 [n] by ck. we use the linearity property of Table 302 to conclude that 
I I 
• • 
ak = bk + Cko 
(30111) 
I I I I (I I I 
- 5 
I I I • • 
0 
(a) 
I I I 
0 
(b) 
I I I I I 
x[n] 
5 
n 
• • I I I • • n 
I I I I I I I I I I I I I I I I 
0 
(c) 
n 
Figure 3.19 
(a) Periodic sequence x[n] for Example 3013 and its represen-
tation as a sum of (b) the square wave x1 [n] and (c) the de sequence x2[n] o 
From Example 3012 (with N 1 = 1 and N = 5), the Fourier series coefficients bk corre-
sponding to x1 [n] can be expressed as 
{ 
1 sin(37Tk/5) 
bk = 
~ sin( 7Tk/5) , fork <F 0, :±:5, :±: 10, 0 0 0 
5, 
fork= 0, :±:5, :±:10, 00 0 
(30112) 
The sequence x2[n] has only a de value, which is captured by its zeroth Fourier 
series coefficient: 
1 4 
co = 5 L xz[n] = 1. 
n=O 
(30113) 
Since the discrete-time Fourier series coefficients are periodic, it follows that ck = 1 
whenver k is an integer multiple of 50 The remaining coefficients of x2 [n] must be zero, 
because x2 [n] contains only a de component. We can now substitute the expressions for 
bk and ck into eqo (30111) to obtain 
{ 
bk 
= ! sin(37Tk/5) 
_ 
5 sin( 1rk/5) , fork <F 0, :±:5, :±: 10, 0 0 0 
ak-
8 5' 
fork= 0, :±:5, :±:10, 00 0 
(30114) 

Sec. 3.7 
Properties of Discrete-Time Fourier Series 
225 
Example 3. 1 4 
Suppose we are given the following facts about a sequence x[n]: 
1. x[n] is periodic with period N = 6. 
2. L~=O x[n] = 2. 
3. L ;,=2(-l)nx[n] = 1. 
4. x[ n] has the minimum power per period among the set of signals satisfying the 
preceding three conditions. 
Let us determine the sequence x[n]. We denote the Fourier series coefficients of x[n] by 
ak. From Fact 2, we conclude that a0 = 1/3. Noting that ( -l)n . = e- j7Tn = e- j(2" 16l3n, 
we see from Fact 3 that a3 = 116. From Parseval's relation (see Table 3.2), the average 
power in x[n] is 
(3.115) 
Since each nonzero coefficient contributes a positive amount to P, and since the values 
of ao and a3 are prespecified, the value of P is minimized by choosing a 1 = a2 = a4 = 
a5 = 0. It then follows that 
x[n] = ao + a3ej"n = (113) + (1/6)( -lt, 
which is sketched in Figure 3.20. 
x[n] 
... ~ I i I 1 I I 
-2 -1 
0 
2 
3 
(3.116) 
n 
Figure 3.20 
Sequence x[n] that is consistent with the properties specified 
in Example 3.14. 
Example 3.15 
In this example we determine and sketch a periodic sequence, given an algebraic expres-
sion for its Fourier series coefficients. In the process, we will also exploit the periodic 
convolution property (see Table 3.2) of the discrete-time Fourier series. Specifically, as 
stated in the table and as shown in Problem 3.58, if x[n] and y[n] are periodic with period 
N, then the signal 
w[n] = L x[r]y[n - r] 
r =(N) 
is also periodic with period N. Here, the summation may be taken over any set of N 
consecutive values of r. Furthermore, the Fourier series coefficients of w[n] are equal to 
Nakbk> where ak and bk are the Fourier coefficients of x[n] and y[n], respectively. 

226 
Fourier Series Representation of Periodic Signals 
Chap.3 
Suppose now that we are told that a signal w[n] is periodic with a fundamental 
period of N = 7 and with Fourier series coefficients 
sin2(37Tk/7) 
Ck = 
. 
7 sin2( "7T k/7) 
(3.117) 
We observe that ck = 7d~ , where dk denotes the sequence of Fourier series coefficients 
of a square wave x [n], as in Example 3.12, with N1 = 1 and N = 7. Using the periodic 
convolution property, we see that 
3 
w[n] = L x[r]x[n- r] = L x[r] x [n - r], 
(3.118) 
r ~ (7) 
r ~ -3 
where, in the last equality, we have chosen to sum over the interval -3 :::; r :::; 3. Except 
for the fact that the sum is limited to a finite interval, the product-and-sum method for 
evaluating convolution is applicable here. In fact, we can convert eq. (3.118) to an ordi-
nary convolution by defining a signal x[n] that equals x[n] for- 3 :::; n :::; 3 and is zero 
otherwise. Then, from eq. (3.118), 
3 
+ oo 
w[n] = L, x[r]x[n- r] = L, x[r] x [n - r]. 
r ~- 3 
r = -oo 
That is, w[n] is the aperiodic convolution of the sequences x[n] and x [n]. 
The sequences x [r], x [r] , and x [n - r] are sketched in Figure 3.21 (a)-( c). From the 
figure we can immediately calculate w[n] . In particular we see that w[O] = 3; w[ -1] = 
w[1] = 2; w[-2] = w[2] = 1; and w[-3] = w[3] = 0. Since w[n] is periodic with 
period 7, we can then sketch w[n] as shown in Figure 3.21(d). 
3.8 FOURIER SERIES AND LTI SYSTEMS 
In the preceding few sections, we have seen that the Fourier series representation can 
be used to construct any periodic signal in discrete time and essentially all periodic 
continuous-time signals of practical importance. In addition, in Section 3.2 we saw that 
the response of an LTI system to a linear combination of complex exponentials takes a 
particularly simple form. Specifically, in continuous time, if x(t) = est is the input to 
a continuous-time LTI system, then the output is given by y(t) = H(s)es1, where, from 
eq. (3.6), 
I 
+ oo 
H(s) = 
- oo h(r)e - s'~"dr, 
(3.119) 
in which h(t) is the impulse response of the LTI system. 
Similarly, if x[n] = zn is the input to a discrete-time LTI system, then the output is 
given by y[n] = H(z)zn, where, from eq. (3.10), 
+ oo 
H(z) = L, h[k]z- k, 
(3.120) 
k= -
00 
in which h[n] is the impulse response of the LTI system. 

Sec. 3.8 
Fourier Series and LTI Systems 
xlr] 
• I I I • • • • I I r 
• • • • I I I • 
- 3 - 2 - 1 
0 
2 
3 
(a) 
Q[r] 
• • • • • • • • I I r 
• • • • • • • • 
- 1 
0 
(b) 
x[n- r] 
• • • I I I • • • • I I r. • • • I I 
n- 7 
n- 1 n n+1 
(c) 
3 
w[n] 
2 
- 7 
- 3 - 2 - 1 
0 
2 
3 
7 
(d) 
Figure 3.21 
(a) The square-wave sequence x[r] in Example 3.15; (b) the 
sequence x[r] equal to x[r] for - 3 s r s 3 and zero otherwise; (c) the 
sequence x[n- r]; (d) the sequence w[n] equal to the periodic convolution of 
x(n] with itself and to the aperiodic convolution of x(n] ~ith x[n]. 
227 
' 
' 
' 
n 
When s or z are general complex numbers, H(s) and H(z) are referred to as the 
system functions of the corresponding systems. For continuous-time signals and systems 
in this and the following chapter, we focus on the specific case in which CRe{s} = 0, so that 
s = jw, and consequently, est is ofthe form ej"'1• This input is a complex exponential at 
frequency w. The system function of the form s = jw-i.e., H (jw) viewed as a function 
of w-is referred to as the frequency response of the system and is given by 
I 
+ oo 
H(jw) = 
-oo h(t)e- j"''dt. 
(3.121) 

228 
Fourier Series Representation of Periodic Signals 
Chap.3 
Similarly, for discrete-time signals and systems, we focus in this chapter and in 
Chapter 5 on values of z for which lzl = 1, so that z = ei<» and z" is of the form eiwn. 
Then the system function H(z) for z restricted to the form z = ei<» is referred to as the 
frequency response of the system and is given by 
+co 
H(eiw) = L h[n]e- jwn. 
(3.122) 
n= - oo 
The response of an LTI system to a complex exponential signal of the form eJwt (in 
continuous time) or eJwn (in discrete time) is particularly simple to express in terms of the 
frequency response of the system. Furthermore, as a result of the superposition property 
for LTI systems, we can express the response of an L TI system to a linear combination 
of complex exponentials with equal ease. In Chapters 4 and 5, we will see how we can 
use these ideas together with continuous-time and discrete-time Fourier transforms to an-
alyze the response of LTI systems to aperiodic signals. In the remainder of this chapter, 
as a first look at this important set of concepts and results, we focus on interpreting and 
understanding this notion in the context of periodic signals. 
Consider first the continuous-time case, and let x(t) be a periodic signal with a 
Fourier series representation given by 
+co 
x(t) = L akeJkwot. 
(3.123) 
k= - CO 
Suppose that we apply this signal as the input to an LTI system with impulse response 
h(t). Then, since each of the complex exponentials in eq. (3.123) is-an eigenfunction of 
the system, as in eq. (3.13) with sk = j kwo, it follows that the outout is 
+oc 
y(t) = .I akH(jkw0)ejkwot. 
(3.124) 
k= -oc 
Thus, y(t) is also periodic with the same fundamental frequency as x(t). Furthermore, if 
{ak} is the set of Fourier series coefficients for the input x(t), then {akH(jkwo)} is the 
set of coefficients for the output y(t). That is, the effect of the LTI system is to modify 
individually each of the Fourier coefficients of the input through multiplication by the 
value of the frequency response at the corresponding frequency. 
Example 3.16 
Suppos~ that the periodic signal x(t) discussed in Example 3.2 is the input signal to an 
LTI system with impulse response 

Sec. 3.8 
Fourier Series and LTI Systems 
229 
To calculate the Fourier series coefficients of the output y(t), we first compute the fre-
quency response: 
1 
. I"' 
= -1 + jw e- Te- JwT o 
(3.125) 
1 
-
1 + jw· 
Therefore, using eqs. (3.124) and (3.125), together with the fact that w 0 = 27T in this 
example, we obtain 
+3 
y(t) = L bkejk2m, 
k = - 3 
bo = 1, 
bl = 4! (1 + 1j27T). 
b- 1 = _41 (1 
1"2 ). 
- J 7T 
bz = 4 ( 1 + 1j47T). 
b3 = ~ c 
/j67T). 
h-z = 4 
(1 -1j47T). 
(3.126) 
(3.127) 
Note that y(t) must be a real-valued signal, since it is the convolution of x(t) and h(t), 
which are both real. This can be verified by examining eq. (3.127) and observing that 
b~ = b- k· Therefore, y(t) can also be expressed in either of the forms given in eqs. (3.31) 
and (3.32); that is, 
or 
where 
3 
y(t) = 1 + 2 L Dk cos (27Tkt + lh), 
k = l 
3 
y(t) = 1 + 2 L [Ek cos 27Tkt- Fk sin 27Tkt], 
k = l 
bk = Dkej8k = Ek + jFk> 
k = 1, 2, 3. 
These coefficients can be evaluated directly from eq. (3.127). For example, 
(3.128) 
(3.129) 
(3.130) 

230 
Fourier Series Representation of Periodic Signals 
Chap. 3 
In discrete time, the relationship between the Fourier series coefficients of the input 
and output of an LTI system exactly parallels eqs. (3.123) and (3.124). Specifically, let 
x[n] be a periodic signal with Fourier series representation given by 
x[n] = 2.: akejk(27TIN)n. 
k= (N) 
If we apply this signal as the input to an LTI system with impulse response h[n], then, as 
in eq. (3.16) with Zk = ejk(21TIN), the output is 
y[n] = 2.: akH(ej27Tk!N)ejk(27TIN)n. 
k= (N) 
(3.131) 
Thus, y[n] is also periodic with the same period as x[n], and the kth Fourier coefficient of 
y[ n] is the product of the kth Fourier coefficient of the input and the value of the frequency 
response of the LTI system, H(ej27Tk!N), at the corresponding frequency. 
Example 3. 17 
Consider an LTI system with impulse response h[n] = a"u[n], -1 <a < 1, and with 
the input 
(27rn) 
x[n] =cos N 
. 
(3.132) 
As in Example 3.10, x[n] can be written in Fourier series form as 
x[n] = 
~ei(27TIN)n + ~e - J(27TIN)n. 
Also, from eq. (3.122), 
H(eiw) = ia"e- Jwn = i(ae- Jw)". 
n=O 
n=O 
(3.133) 
This geometric series can be evaluated using the result of Problem 1.54, yielding 
(3.134) 
Using eq. (3.131), we then obtain the Fourier series for the output: 
(3.135) 

Sec. 3.9 
Filtering 
231 
If we write 
then eq. (3.135) reduces to 
y[n] = rcos(~ n + 8). 
(3.136) 
For example, if N = 4, 
1 
-:----
----;;-;--;-;- = -- = 
1 - ae- jZ1rl4 
1 + aj 
and thus, 
We note that for expressions such as eqs. (3.124) and (3.131) to make sense, the 
frequency responses H(jw) and H(ejw) in eqs. (3.121) and (3.122) must be well defined 
and finite. As we will see in Chapters 4 and 5, this will be the case if the LTI systems 
under consideration are stable. For example, the LTI system in Example 3.16, with impulse 
response h(t) = e- 1u(t), is stable and has a well-defined frequency response given by 
eq. (3.125). On the other hand, an LTI system with impulse response h(t) = e1u(t) is 
unstable, and it is easy to check that the integral in eq. (3.121) for H(jw) diverges for 
any value of w. Similarly, the LTI system in Example 3.17, with impulse response h[n] = 
anu[n], is stable for lal < 1 and has frequency response given by eq. (3.134). However, 
if Ia I > 1, the system is unstable, and then the summation in eq. (3.133) diverges: 
3.9 FILTERING 
In a variety of applications, it is of interest to change the relative amplitudes of the fre-
quency components in a signal or perhaps eliminate some frequency components entirely, 
a process referred to as filtering. Linear time-invariant systems that change the shape of the 
spectrum are often referred to as frequency-shaping filters. Systems that are designed to 
pass some frequencies essentially undistorted and significantly attenuate or eliminate oth-
ers are referred to asfrequency-selectivefilters. As indicated by eqs. (3.124) and (3.131), 
the Fourier series coefficients of the output of an LTI system are those of the input multi-
plied by the frequency response of the system. Consequently, filtering can be conveniently 
accomplished through the use of LTI systems with an appropriately chosen frequency re-
sponse, and frequency-domain methods provide us with the ideal tools to examine this 
very important class of applications. In this and the following two sections, we take a first 
look at filtering through a few examples. 

232 
Fourier Series Representation of Periodic Signals 
Chap. 3 
3.9.1 Frequency-Shaping Filters 
One application in which frequency-shaping filters are often encountered is audio sys-
tems. For example, LTI filters are typically included in such systems to permit the listener 
to modify the relative amounts of low-frequency energy (bass) and high-frequency en-
ergy (treble). These filters correspond to LTI systems whose frequency responses can be 
changed by manipulating the tone controls. Also, in high-fidelity audio systems, a so-called 
equalizing filter is often included in the preamplifier to compensate for the frequency-
response characteristics of the speakers. Overall, these cascaded filtering stages are fre-
quently referred to as the equalizing or equalizer circuits for the audio system. Figure 3.22 
illustrates the three stages of the equalizer circuits for one particular series of audio speak-
ers. In this figure, the magnitude of the frequency response for each of these stages is shown 
on a log-log plot. Specifically, the magnitude is in units of 20 log10 jH(jw )j, referred to as 
decibels or dB. The frequency axis is labeled in Hz (i.e., w/27T) along a logarithmic scale. 
As will be discussed in more detail in Section 6.2.3, a logarithmic display of the magnitude 
of the frequency response in this form is common and useful. 
Taken together, the equalizing circuits in Figure 3.22 are designed to compensate for 
the frequency response of the speakers and the room in which they are located and to allow 
the listener to control the overall frequency response. In particular, since the three systems 
are connected in cascade, and since each system modifies a complex exponential input 
K eiwt by multiplying it by the system frequency response at that frequency, it follows that 
the overall frequency response of the cascade of the three systems is the product of the three 
frequency responses. The first two filters, indicated in Figures 3.22(a) and (b), together 
make up the control stage of the system, as the frequency behavior of these filters can be 
adjusted by the listener. The third filter, illustrated in Figure 3.22(c), is the equalizer stage, 
which has the fixed frequency response indicated. The filter in Figure 3.22(a) is a low-
frequency filter controlled by a two-position switch, to provide one of the two frequency 
responses indicated. The second filter in the control stage has two continuously adjustable 
slider switches to vary the frequency response within the limits indicated in Figure 3.22(b ). 
Another class of frequency-shaping filters often encountered is that for which the 
filter output is the derivative of the filter input, i.e., y(t) = dx(t)ldt. With x(t) of the form 
x(t) = eiwt, y(t) will be y(t) = jweiwt, from which it follows that the frequency response 
is 
H(jw) = jw. 
(3.137) 
The frequency response characteristics of a differentiating filter are shown in Figure 3.23. 
Since H(jw) is complex in general, and in this example in particular, H(jw) is frequently 
displayed (as in the figure) as separate plots of jH(jw )J and <}:..H(jw ). The shape of this fre-
quency response implies that a complex exponential input eiwt will receive greater ampli-
fication for larger values of w. Consequently, differentiating filters are useful in enhancing 
rapid variations or transitions in a signal. 
One purpose for which differentiating filters are often used is to enhance edges in 
picture processing. A black-and-white picture can be thought of as a two-dimensional 
"continuous-time" signal x(t1, t2), where t1 and t2 are the horizontal and vertical coordi-
nates, respectively, and x(t1, t2) is the brightness of the image. If the image is repeated 
periodically in the horizontal and vertical directions, then it can be represented by a two-
dimensional Fourier series (see Problem 3.70) consisting of sums of products of complex 

+25 r--r-r--~~----~--~--.--,----~-r-r--r-rT----, 
+20 
+15 
m +1o r---------~~~~----------------------------~ 
:g. 
3l 
+5 t------
c: 
8. 
0 
rtJ 
(I) 
a: 
- 5 
- 10 
Switch position 2 
- 15 ~~~--~~----~--~--~~----~~~--~~--~ 
20Hz 30 40 
60 
100 
200 
400 600 1kHz 
Frequency 
(a) 
2 
3 4 
6 8 10 
20 
+25 r--r-r--~~----~--~--.--,----~-r-r--r-rT----, 
+20 
+15 
m +1o ._____~ 
:g. 
3l 
+5 
c: 
8. 
0 
rtJ 
(I) 
a: 
- 5 
- 10 
- 15 ~~~--~~----~--~--~~----~~~--~~~~ 
20Hz 30 40 60 
100 
200 
400 600 1kHz 
Frequency 
(b) 
2 
3 4 
6 8 10 
20 
+25 r--r-r--~~----~--~--.--,----~-r-r--r-ro----, 
+20 
+15 
m +1o 
:g. 
3l 
+5 
c: 
8. 
0 
gJ 
a: 
-5 
- 10 
- 15 L-~~--L-~----~--~--L-~----~~-L--L-~--~ 
20Hz30 40 
60 100 
200 
400 600 1kHz 
Frequency 
(c) 
2 
3 4 
6 8 10 
Figure 3.22 
Magnitudes of the frequency responses of the equalizer 
circuits for one particular series of audio speakers, shown on a scale of 
20 log10 jH(jw )I. which is referred to as a decibel (or dB) scale. (a) Low-
frequency filter controlled by a two-position switch; (b) upper and lower 
frequency limits on a continuously adjustable shaping filter; (c) fixed 
frequency response of the equalizer stage. 
20 
233 

234 
Fourier Series Representation of Periodic Signals 
Chap. 3 
I HOwl I 
~ 
1:Hijw) 
~r------
:rr 2 
w 
w 
Figure 3.23 
Characteristics of the 
frequency response of a filter for which 
the output is the derivative of the in-
put. 
exponentials, ejw 111 and ejwztz, that oscillate at possibly different frequencies in each of 
the two coordinate directions. Slow variations in brightness in a particular direction are 
represented by the lower harmonics in that direction. For example, consider an edge cor-
responding to a sharp transition in brightness that runs vertically in an image. Since the 
brightness is constant or slowly varying along the edge, the frequency content of the edge 
in the vertical direction is concentrated at low frequencies. In contrast, since there is an 
abrupt variation in brightness across the edge, the frequency content of t.he edge in the 
horizontal direction is concentrated at higher frequencies. Figure 3.24 illustrates the effect 
on an image of the two-dimensional equivalent of a differentiating filter. 11 Figure 3.24(a) 
shows two original images and Figure 3.24(b) the result of processing those images with 
the filter. Since the derivative at the edges of a picture is greater than in regions where the 
brightness varies slowly with distance, the effect of the filter is to enhance the edges. 
Discrete-time LTI filters also find a broad array of applications. Many of these in-
volve the use of discrete-time systems, implemented using general- or special-purpose 
digital processors, to process continuous-time signals, a topic we discuss at some length in 
Chapter 7. In addition, the analysis of time series information, including demographic data 
and economic data sequences such as the stock market a,verage, commonly involves the 
use of discrete-time filters. Often the long-term variations (which correspond to low fre-
quencies) have a different significance than the short-term variations (which correspond to 
high frequencies), and it is useful to analyze these components separately. Reshaping the 
relative weighting ofthe components is typically accomplished using discrete-time filters. 
As one example of a simple discrete-time filter, consider an LTI system that succes-
sively takes a two-point average of the input values: 
1 
y[n] = 2(x[n] + x[n - 1]). 
(3.138) 
11 Specifically each image in Figure 3.24(b) is the magnitude of the two-dimensional gradient of its 
counterpart image in Figure 3.24(a) where the magnitude of the gradient off (x, y) is 
w~~ y) )
2 
+ (af~~ y) Jr 

(a) 
(b) 
Sec. 3.9 
Filtering 
Figure 3.24 
Effect of a differentiating filter on an image: (a) two original images; 
(b) the result of processing the original images with a differentiating filter. 
235 
In this case h[n] = 
~(o[n] + o[n - 1]), and from eq. (3.122), we see that the frequency 
response of the system is 
H(ejw) = ~[1 + e- jw] = e-jw12 cos(w/2). 
(3.139) 
The magnitude of H(ejw) is plotted in Figure 3.25(a), and <r..H(ejw) is shown in Figure 
3.25(b). As discussed in Section 1.3.3, low frequencies for discrete-time complex expo-
nentialsoccurnearw = 0, ±27T, ±47T, ... , andhighfrequenciesneru:w = :::!::7T, ±37T, .... 
This is a result of the fact that ej(w + 27T)n = ejwn, so that in discrete time we need only con-
~ider a 27T interval of values of w in order to cover a complete range of distinct discrete-
time frequencies. As a consequence, any discrete-time frequency responses H(ejw) must 
be periodic with period 27T, a fact that can also be deduced directly from eq. (3.122). 
For the specific filter defined in eqs. (3.138) and (3.139), we see from Figure 3.25(a) 
that jH(ejw)i is large for frequencies near w = 0 and decreases as we increase lwl toward 
7T, indicating that higher frequencies are attentuated more than lower ones. For exam-
ple, if the input to this system is constant-i.e., a zero-frequency complex exponential 

236 
(a) 
(b) 
Fourier Series Representation of Periodic Signals 
Chap. 3 
Figure 3.25 
(a) Magnitude and 
(b) phase for the frequency response 
of the discrete-time LTI system 
y(n] = 1/2(x[n] + x[n- 1]). 
x[n] = KejO·n = K-then the output will be 
y[n] = H(ej·O)KejwO·n = K = x[n]. 
On the other hand, if the input is the high-frequency signal x[n] = K ej7rn = K( - 1)", 
then the output will be 
y[n] = H(ej7T)Kej7r·n = 0. 
Thus, this system separates out the long-term constant value of a signal from its high-
frequency fluctuations and, consequently, represents a first example of frequency-selective 
filtering, a topic we look at more carefully in the next subsection. 
3. 9. 2 Frequency-Selective Filters 
Frequency-selective filters are a class of filters specifically intended to accurately or 
approximately select some bands of frequencies and reject others. The use of frequency-
selective filters arises in a variety of situations. For example, if noise in an audio recording 
is in a higher frequency band than the music or voice on the recording is, it can be 
removed by frequency-selective filtering. Another important application of frequency-
selective filters is in communication systems. As we discuss in detail in Chapter 8, the 
basis for amplitude modulation (AM) systems is the transmission of information from 
many different sources simultaneously by putting the information from each channel into 
a separate frequency band and extracting the individual channels or bands at the receiver 
using frequency-selective filters. Frequency-selective filters for separating the individual 

Sec. 3.9 Filtering 
237 
channels and frequency-shaping filters (such as the equalizer illustrated in Figure 3.22) 
for adjusting the quality of the tone form a major part of any home radio and television 
receiver. 
While frequency selectivity is not the only issue of concern in applications, its broad 
importance has led to a widely accepted set of terms describing the characteristics of 
frequency-selective filters. In particular, while the nature of the frequencies to be passed 
by a frequency-selective filter varies considerably from application to application, several 
basic types of filter are widely used and have been given names indicative of their func-
tion. For example, a lowpass filter is a filter that passes low frequencies- i.e., frequencies 
around w = 0--and attenuates or rejects higher frequencies. A highpass filter is a filter 
that passes high frequencies and attentuates or rejects low ones, and a bandpass filter is a 
filter that passes a band of frequencies and attenuates frequencies both higher and lower 
than those in the band that is passed. In each case, the cutoff frequencies are the frequen-
cies defining the boundaries between frequencies that are passed and frequencies that are 
rejected-i.e., the frequencies in the passband and stopband. 
Numerous questions arise in defining and assessing the quality of a frequency-
selective filter. How effective is the filter at passing frequencies in the passband? How 
effective is it at attentuating frequencies in the stopband? How sharp is the transition 
near the cutoff frequency-i.e., from nearly free of distortion in the passband to highly 
attenuated in the stopband? Each of these questions involves a comparison of the charac-
teristics of an actual frequency-selective filter with those of a filter with idealized behavior. 
Specifically, an ideal frequency-selective filter is a filter that exactly passes complex ex-
ponentials at one set of frequencies without any distortion and completely rejects signals 
at all other frequencies. For example, a continuous-time ideal lowpass filter with cutoff 
frequency W e is an LTI system that passes complex exponentials ejwt for values of win the 
range -we :5 w :5 W e and rejects signals at all other frequencies. That is, the frequency 
response of a continuous-time ideallowpass filter is 
as shown in Figure 3.26. 
H(jw) 
'I 
H(jw) = { 1• 
0, 
-we 
0 
We 
w 
-stopband-j-Passband-j--stopband-
(3.140) 
Figure 3.26 
Frequency response of 
an ideal lowpass filter. 
Figure 3.27(a) depicts the frequency response of an ideal continuous-time highpass 
filter with cutoff frequency w e. and Figure 3.27(b) illustrates an ideal continuous-time 
bandpass filter with lower cutoff frequency W et and upper cutoff frequency W e2· Note that 
each of these filters is symmetric about w = 0, and thus, there appear to be two passbands 
for the highpass and bandpass filters. This is a consequence of our having adopted the 

238 
H(jw) 
·t 
- we 
(a) 
H(jw) 
·t 
-we2 
- wel 
(b) 
We 
Wel 
Fourier Series Representation of Periodic Signals 
Chap. 3 
(I) 
(I) 
Figure 3.27 
(a) Frequency re-
sponse of an ideal highpass filter; 
(b) frequency response of an ideal 
bandpass filter. 
use of the complex exponential signal eJwr, rather than the sinusoidal signals sin w t and 
coswt,atfrequencyw.SinceeJwt = coswt+ jsinwtande- Jwt = coswt- jsinwt,both 
of these complex exponentials are composed of sinusoidal signals at the same frequency w. 
For this reason, we usually define ideal filters so that they have the symmetric frequency 
response behavior seen in Figures 3.26 and 3.27. 
In a similar fashion, we can define the corresponding set of ideal discrete-time 
frequency-selective filters, the frequency responses for which are depicted in Figure 3.28. 
H(ei"') 
I~ 
·I 
-
'lT 
- we 
0 
(a) 
H(ei"') 
I 
-'lT 
(b) 
H(ei"') 
Ill 
-'lT 
(c) 
We 
'lT 
'lT 
'lT 
(I) 
(I) 
w 
.Figure 3.28 
Discrete-time ideal 
frequency-selective filters: (a) lowpass; 
(b) highpass; (c) bandpass. 

Sec. 3.10 
Examples of Continuous-Time Filters Described by Differential Equations 
239 
In particular, Figure -3.28(a) depicts an ideal discrete-time lowpass filter, Figure 3.28(b) 
is an ideal highpass filter, and Figure 3.28(c) is an ideal bandpass filter. Note that, as 
discussed in the preceding section, the characteristics of the continuous-time and discrete-
time ideal filters differ by virtue of the fact that, for discrete-time filters, the frequency 
response H(ejw) must be periodic with period 27T, with low frequencies riear even multi-
ples of 7T and high frequencies near odd multiples of 'TT. 
As we will see on numerous occasions, ideal filters are quite useful in describing ide-
alized system configurations for a variety of applications. However, they are not realizable 
in practice and must be approximated. Furthermore, even if they could be realized, some of 
the characteristics of ideal filters might make them undesirable for particular applications, 
and a nonideal filter might in fact be preferable. 
In detail, the topic of filtering encompasses many issues, including design and imple-
mentation. While we will not delve deeply into the details of filter design methodologies, 
in the remainder of this chapter and the following chapters we will see a number of other 
examples of both continuous-time and discrete-time filters and will develop the concepts 
and techniques that form the basis of this very important engineering discipline. 
3. 1 0 EXAMPLES OF CONTINUOUS-TIME FILTERS DESCRIBED 
BY DIFFERENTIAL EQUATIONS 
In many applications, frequency-selective filtering is accomplished through the use ofLTI 
systems described by linear constant-coefficient differential or difference equations. The 
reasons· for this are numerous. For example, many physical systems that can be inter-
preted as performing filtering operations are characterized by differential or difference 
equations. A good example of this that we will examine in Chapter 6 is an automobile 
suspension system, which in part is designed to filter out high-frequency bumps and ir-
regularities in road surfaces. A second reason for the use of filters described by differen-
tial or difference equations is that they are conveniently implemented using either analog 
or digital hardware. Furthermore, systems described by differential or difference equa-
tions offer an extremely broad and flexible range of designs, allowing one, for example, 
to produce filters that are close to ideal or that possess other desirable characteristics. In 
this and the next section, we consider several examples that illustrate the implementation 
of continuous-time and discrete-time frequency-selective filters through the use of dif-
ferential and difference equations. In Chapters 4-6, we will see other examples of these 
classes of filters and will gain additional insights into the properties that make them so use-
ful. 
3.1 0.1 A Simple RC Lowpass Filter 
Electrical circuits are widely used to implement continuous-time filtering operations. One 
of the simplest examples of such a circuit is the first-order RC circuit depicted in Fig-
ure 3.29, where the source voltage v5(t) is the system input. This circuit can be used to 
perform either a lowpass or highpass filtering operation, depending upon what we take 
as the output signal. In particular, suppose that we take the capacitor voltage vc(t) as the 
output. In this case, the output voltage is related to the input voltage through the linear 

240 
Fourier Series Representation of Periodic Signals 
Chap. 3 
+ v,(t) -
A 
+ 
c 
Figure 3.29 
First-order RC filter. 
constant -coefficient differential equation 
dvc(t) 
RC dt + Vc(t) = v.,(t). 
(3.141) 
Assuming initial rest, the system described by eq. (3 .141) is LTI. In order to determine 
its frequency response H (jw ), we note that, by definition, with input voltage vs(t) = ejwt, 
we must have the output voltage vc(t) = H(jw )ejwr. If we substitute these expressions into 
eq. (3.141), we obtain 
d 
. 
. 
. 
RC-[H(jw)eJwt] + H(jw)eJwt = eJwt 
dt 
' 
or 
RCjwH(jw)ejwt + H(jw)ejwt = ejwt, 
from which it follows directly that 
H(j"w)ejwt = 
1 
jwt 
1+RCjwe 
' 
or 
H(jw) = 1 + RCjw. 
(3.142) 
(3.143) 
(3.144) 
(3.145) 
The magnitude and phase of the frequency response H(jw) for this example are 
shown in Figure 3.30. Note that for frequencies near w = 0, IH(jw )I = 1, while for larger 
values of w (positive or negative), IH(jw )I is considerably smaller and in fact steadily 
decreases as lwl increases. Thus, this simple RC filter (with vc(t) as output) is a nonideal 
lowpass filter. 
To provide a first glimpse at the trade-offs involved in filter design, let us briefly 
consider the time-domain behavior of the circuit. In particular, the impulse response of the 
system described by eq. (3.141) is 
1 -
h(t) = RCe t!RC u(t), 
(3.146) 

Sec. 3.10 
Examples of Continuous-Time Filters Described by Differential Equations 
IH(jw)l 
-1/RC 
0 
(a) 
<i:H(jw) 
7T/2 
(b) 
1/RC 
Figure 3.30 
(a) Magnitude and (b) phase plots for the frequency response 
for the RC circuit of Figure 3.29 with output Vc(t). 
and the step response is 
s(t) = [1 -
e- t/RC]u(t), 
241 
w 
w 
(3.147) 
both of which are plotted in Figure 3.31 (where T = RC). Comparing Figures 3.30 and 
3.31, we see a fundamental trade-off. Specifically, suppose that we would like our filter 
to pass only very low frequencies. From Figure 3.30(a), this implies that l!RC must be 
small, or equivalently, that RC is large, so that frequencies other than the low ones of 
interest will be attentuated sufficiently. However, looking at Figure 3.31(b), we see that 
if RC is large, then the step response will take a considerable amount of time to reach its 
long-term value of 1. That is, the system responds sluggishly to the step input. Conversely, 
if we wish to have a faster step response, we need a smaller value of RC, which in tum 
implies that the filter will pass higher frequencies. This type of trade-off between behavior 
in the frequency domain and in the time domain is typical of the issues arising in the design 
and analysis of LTI systems and filters and is a subject we will look at more carefully in 
Chapter 6. 
3. 1 0.2 A Simple RC Highpass Filter 
As an altemativy to choosing the capacitor voltage as the output in our RC circuit, we can 
choose the voltage across the resistor. In this case, the differential equation relating input 

242 
h(t) 
1 
T 
T 
s(t) 
1-.1. 
e 
T 
and output is 
(a) 
(b) 
Fourier Series Representation of Periodic Signals 
Chap.3 
Figure 3.31 
(a) Impulse response 
of the first-order RC lowpass filter with 
-r = RC; (b) step response of RC low-
pass filter with -r = RC. 
Rc dv,(t) 
( ) = RCdvs(t) 
dt + Vr t 
dt . 
(3.148) 
We can find the frequency response G(jw) of this system in exactly the same way we did 
in the previous case: Ifvs(t) = eiwt, then we must have vr(t) = G(jw)eiwt; substituting 
these expressions into eq. (3.148) and performing a bit of algebra, we find that 
. 
jwRC 
G(Jw) = 1 + jwRc· 
(3.149) 
The magnitude and phase of this frequency response are shown in Figure 3.32. From the 
figure, we see that the system attenuates lower frequencies and passes higher frequencies-
i.e., those for which lwl >> 1/RC-with minimal attenuation. That is, this system acts as 
a nonideal highpass filter. 
As with the lowpass filter, the parameters of the circuit control both the frequency 
response of the highpass filter and its time response characteristics. For example, consider 
the step response for the filter. From Figure 3.29, we see that v,(t) = vs(t) - vc(t). Thus, 
if Vs(t) = u(t), Vc(t) must be given by eq. (3.147). Consequently, the step response of the 
highpass filter is 
(3.150) 
which is depicted in Figure 3.33. Consequently, as RC is increased, the response becomes 
more sluggish-i.e., the step response takes a longer time to reach its long-term value 

v,(t) 
Sec. 3.10 
Examples of Continuous-Time Filters Described by Differential Equations 
IGOwll 
-- 1/RC 
0 
1/RC 
(a) 
1:G(jw) 
(b) 
Figure 3.32 
(a) Magnitude and (b) phase plots for the frequency response 
of the RC circuit of Figure 3.29 with output v,(t). 
243 
w 
w 
RC 
Figure 3.33 
Step response of the 
first-order RC highpass filter with 
T = RC. 
of 0. From Figure 3.32, we see that increasing RC (or equivalently, decreasing 1/RC) 
also affects the frequency response, specifically, it extends the passband down to lower 
frequencies. 
We observe from the two examples in this section that a simple RC circuit can serve 
as a rough approximation to a highpass or a lowpass filter, depending upon the choice of the 
physical output variable. As illustrated in Problem 3.71, a simple mechanical system using 
a mass and a mechanical damper can also serve as a lowpass or high pass filter described by 

244 
Fourier Series Representation of Periodic Signals 
Chap.3 
analogous first -order differential equations. Because of their simplicity, these examples of 
electrical and mechanical filters do not have a sharp transition from passband to stopband 
and, in fact, have only a single parameter (namely, RC in the electrical case) that con-
trols both the frequency response and time response behavior of the system. By designing 
more complex filters, implemented using more energy storage elements (capacitances and 
inductances in electrical filters and springs and damping devices in mechanical filters), 
we obtain filters described by higher order differential equations. Such filters offer con-
siderably more flexibility in terms of their characteristics, allowing, for example, sharper 
passband-stopband transition or more control over the trade-offs between time response 
and frequency response. 
3.11 EXAMPLES OF DISCRETE-TIME FILTERS DESCRIBED 
BY DIFFERENCE EQUATIONS 
As with their continuous-time counterparts, discrete-time filters described by linear 
constant-coefficient difference equations are of considerable importance in practice. In-
deed, since they can be efficiently implemented in special- or general-purpose digital 
systems, filters described by difference equations are widely used in practice. As in al-
most all aspects of signal and system analysis, when we examine discrete-time filters 
described by difference equations, we find both strong similarities and important differ-
ences with the continuous-time case. In particular, discrete-time LTI systems described 
by difference equations can either be recursive and have impulse responses of infinite 
length (IlR systems) or be nonrecursive and have finite-length impulse responses (FIR 
systems). The former are the direct counterparts of continuous-time systems described 
by differential equations illustrated in the previous section, while the latter are also of 
considerable practical importance in digital systems. These two classes have distinct sets 
of advantages and disadvantages in terms of ease of implementation and in terms of the 
order of filter or the complexity required to achieve particular design objectives. In this 
section we limit ourselves to a few simple examples of recursive and nonrecursive filters, 
while in Chapters 5 and 6 we develop additional tools and insights that allow us to analyze 
and understand the properties of these systems in more detail. 
3.11.1 First-Order Recursive Discrete-Time Filters 
The discrete-time counterpart of each of the first-order filters considered in Section 3.10 
is the LTI system described by the first-order difference equation 
y[n] - ay[n - 1] = x[n]. 
(3.151) 
From the eigenfunction property of complex exponential signals, we know that if x[n] = 
eiwn, then y[n] = H(eiw)eJwn, where H(eiw) is the frequency response of the system. 
Substituting into eq. (3.151), we obtain 
(3.152) 
or 
(3.153) 

Sec.3.11 
Examples of Discrete-Time Filters Described by Difference Equations 
245 
so that 
(3.154) 
The magnitude and phase of H(ejw) are shown in Figure 3.34(a) for a = 0.6 and in Figure 
3.34(b) for a = -0.6. We observe that, for the positive value of a, the difference equation 
(3.151) behaves like a lowpass filter with minimal attenuation of low frequencies near 
w = 0 and increasing attenuation as we increase w toward w = 7T. For the negative value 
of a, the system is a highpass filter, passing frequencies near w = 7T and attenuating lower 
frequencies. In fact, for any positive value of a < 1, the system approximates a lowpass 
filter, and for any negative value of a > - 1, the system approximates a high pass filter, 
where Ia I controls the size of the filter passband, with broader pass bands as Ia I is decreased. 
As with the continuous-time examples, we again have a trade-off between time do-
main and frequency domain characteristics. In particular, the impulse response of the sys-
tem described by eq. (3.151) is 
h[n] = a"u[n]. 
(3.] 55) 
The step response s[n] = u[n] * h[n] is 
1 - a" + I 
s[n] = 
1 
__ a u[n]. 
(3.156) 
From these expressions, we see that lal also controls the speed with which the impulse and 
step responses approach their long-term values, with faster responses for smaller values 
of lal, and hence, for filters with smaller passbands. Just as with differential equations, 
higher order recursive difference equations can be used to provide sharper filter charac-
teristics and to provide more flexibility in balancing time-domain and frequency-domain 
constraints. 
Finally, note from eq. (3.155) that the system described by eq. (3.151) is unstable 
if lal :::::: 1 and thus does not have a finite response to complex exponential inputs. As we 
stated previously, Fourier-based methods and frequency domain analysis focus on systems 
with finite responses to complex exponentials; hence, for examples such as eq. (3. 1 51), we 
restrict ourselves to stable systems. 
3.11.2 Nonrecursive Discrete-Time Filters 
The general form of an FIR nonrecursive difference equation is 
M 
y[n] = L bkx[n - k]. 
k=- N 
(3.157) 
That is, the output y[n] is a weighted average of the (N + M + 1) values of x[n] from 
x[n - M] through x[n + N], with the weights given by the coefficients bk. Systems of 
this form can be used to meet a broad array of filtering objectives, including frequency-
selective filtering. 
One frequently used example of such a filter is a moving-average filter, where the 
output y[n] for any n- say, n0-is an average of values of x[n] in the vicinity of n0. The 

(a) 
"' 2 
(b) 
246 
"' 2 
w 
(J) 
(J) 
Figure 3.34 
Frequency response 
of the first-order recursive discrete-
time filter of eq. (3.151 ): (a) a = 0.6; 
(b) a= -0.6. 

Sec. 3.11 
Examples of Discrete-Time Filters Described by Difference Equations 
247 
basic idea is that by averaging values locally, rapid high-frequency components of the in-
put will be averaged out and lower frequency variations will be retained, corresponding to 
smoothing or lowpass filtering the original sequence. A simple two-point moving-average 
filter was briefly introduced in Section 3.9 [eq. (3.138)]. An only slightly more complex 
example is the three-point moving-average filter, which is of the form 
1 
y[n] = 3(x[n - 1] + x[n] + x[n + 1]), 
(3.158) 
so that each output y[n] is the average of three consecutive input values. In this case, 
1 
h[n] = 3[8[n + 1] + B[n] + B[n- 1]], 
and thus, from eq. (3.122), the corresponding frequency response is 
. 
1 
. 
. 
1 
H(elw) = 3
[elw + 1 + e- lw] = 3o + 2cosw). 
(3.159) 
The magnitude of H(ejw) is sketched in Figure 3.35. We observe that the filter has the 
general characteristics of a lowpass filter, although, as with the first-order recursive filter, 
it does not have a sharp transition from passband to stopband. 
Figure 3.35 
Magnitude of the fre-
0 
1I 
'IT 
2 
2'1T 
w 
quency response of a three-point 
moving-average lowpass filter. 
The three-point moving-average filter in eq. (3.158) has no parameters that can 
be changed to adjust the effective cutoff frequency. As a generalization of this moving-
average filter, we can consider averaging over N + M + 1 neighboring points-that is, 
using a difference equation of the form 
1 
M 
Y[n] -
""'""' x[n - k]. 
- N+M+1 L 
k=-N 
(3.160) 
The corresponding impulse response is a rectangular pulse (i.e., h[n] = li(N + M + 1) 
for -N :s: n :s: M, and h[n] = 0 otherwise). The filter's frequency response is 
. 
1 
~ . k 
H(elw) = 
L 
e - JW • 
N + M + 1 k=-N 
(3.161) 

248 
Fourier Series Representation of Periodic Signals 
Chap.3 
The summation in eq. (3.161) can be evaluated by performing calculations similar to those 
in Example 3 .12, yielding 
H( jw) = 
1 
jw[(N - M )/2] sin[w(M + N + 1)/2] 
e 
N + M + 1 e 
sin(w/2) 
· 
(3.162) 
By adjusting the size, N + M + 1, of the averaging window we can vary the cutoff fre-
quency. For example, the magnitude of H(ejw) is shown in Figure 3.36for M +N + 1 = 33 
and M + N + 1 = 65. 
- 'lT/2 
IH(ei"')l 
0 
(a) 
0 
(b) 
'lT/2 
Figure 3.36 
Magnitude of the frequency response for the lowpass moving-
average filter of eq. (3.162): (a) M = N = 16; (b) M = N = 32. 
'lT 
w 
'lT 
w 
Nonrecursive filters can also be used to perform highpass filtering operations. To 
illustrate this, again with a simple example, consider the difference equation 
[ ] _ x[n] - x[n - 1] 
y n -
2 
. 
(3.163) 
For input signals that are approximately constant, the value of y[n] is close to zero. For 
input signals that vary greatly from sample to sample, the values of y[n] can be ex-

Sec. 3.12 
Summary 
249 
pected to have larger amplitude. Thus, the system described by eq. (3.163) approximates 
a highpass filtering operation, attenuating slowly varying low-frequency components and 
passing rapidly varying higher frequency components with little attenuation. To see this 
more precisely we need to look at the system's frequency response. In this case, h[n] = 
H8[n]- cS[n- 11}, so that direct application of eq. (3.122) yields 
H(ejw) = ~[1 - e- jw] = jejw/2 sin(w/2). 
(3.164) 
In Figure 3.37 we have plotted the magnitude of H(ejw), showing that this simple 
system approximates a highpass filter, albeit one with a very gradual transition from pass-
band to stopband. By considering more general nonrecursive filters, we can achieve far 
sharper transitions in lowpass, highpass, and other frequency-selective filters. 
w 
'IT 
Figure 3.37 
Frequency response of 
a simple highpass filter. 
Note that, since the impulse response of any FIR system is of finite length (i.e., 
from eq. (3.157), h[n] = bn for -N :s n :s M and 0 otherwise), it is always absolutely 
summable for any choices of the bn. Hence, all such filters are stable. Also, if N > 0 
in eq. (3.157), the system is noncausal, since y[n] then depends on future values of the 
input. In some applications, such as those involving the processing of previously recorded 
signals, causality is not a necessary constraint, and thus, we are free to use filters with 
N > 0. In others, such as many involving real-time processing, causality is essential, and 
in such cases we must takeN :s 0. 
3.12 SUMMARY 
In this chapter, we have introduced and developed Fourier series representations for both 
continuous-time and discrete-time systems and have used these representations to take a 
first look at one of the very important applications of the methods of signal and system 
analysis, namely, filtering. In particular, as we discussed in Section 3.2, one of the primary 
motivations for the use of Fourier series is the fact that complex exponential signals are 
eigenfunctions ofLTI systems. We have also seen, in Sections 3.3-3.7, that any periodic 
signal of practical interest can be represented in a Fourier series- i.e., as a weighted sum 

250 
Fourier Series Representation of Periodic Signals 
Chap. 3 
of harmonically related complex exponentials that share a common period with the signal 
being represented. In addition, we have seen that the Fourier series representation has a 
number of important properties which describe how different characteristics of signals are 
reflected in their Fourier series coefficients. 
One of the most important properties of Fourier series is a direct consequence of the 
eigenfunction property of complex exponentials. Specifically, if a periodic signal is ap-
plied to an LTI system, then the output will be periodic with the same period, and each 
of the Fourier coefficients of the output is the corresponding Fourier coefficient of the 
input multiplied by a complex number whose value is a function of the frequency corre-
sponding to that Fourier coefficient. This function of frequency is characteristic of the LTI 
system and is referred to as the frequency response of the system. By examining the fre-
quency response, we were led directly to the idea of filtering of signals using LTI systems, 
a concept that has numerous applications, including several that we have described. One 
important class of applications involves the notion of frequency-selective filtering-i.e., 
the idea of using an LTI system to pass certain specified bands of frequencies and stop 
or significantly attentuate others. We introduced the concept of ideal frequency-selective 
filters and also gave several examples of frequency-selective filters described by linear 
constant-coefficient differential or difference equations. 
The purpose of this chapter has been to begin the process of developing both the 
tools of Fourier analysis and an appreciation for the utility of these tools in applications. In 
the chapters that follow, we continue with this agenda by developing the Fourier transform 
representations for aperiodic signals in continuous and discrete time and by taking a deeper 
look not only at filtering, but also at other important applications of Fourier methods. 
Chapter 3 Problems 
The first section of problems belongs to the basic category and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
3.1. A continuous-time periodic signal x(t) is real valued and has a fundamental period 
T = 8. The nonzero Fourier series coefficients for x(t) are 
Express x(t) in the form 
a1 = a - 1 = 2,a3 = a :_3 = 4j. 
co 
x(t) = L,Akcos(wkt+<fJk). 
k=O 
3.2. A discrete-time periodic signal x[n] is real valued and has a fundamental period 
N = 5. The nonzero Fourier series coefficients for x[n] are 
ao = 1, a2 = a:_2 = ej'TI'/4, a4 = a:_4 = 2ejTrl3. 

Chap.3 
Problems 
Express x[n] in the form 
00 
x[n] = Ao + L Ak sin(wkn + c/>k). 
k = l 
3.3. For the continuous-time periodic signal 
(21T ) 
. (51T ) 
x(t) = 2 +cos 3 t + 4sm 3 t , 
251 
determine the fundamental frequency w0 and the Fourier series coefficients ak such 
that 
00 
x(t) = L akejkwot. 
k = - oo 
3.4. Use the Fourier series analysis equation (3.39) to calculate the coefficients ak for 
the continuous-time periodic signal 
x(t) = { 1.5, 
-1.5, 
with fundamental frequency w0 = 1T. 
0::5t<l 
l::5t < 2 
3.5. Let x1 (t) be a continuous-time periodic signal with fundamental frequency w 1 and 
Fourier coefficients ak. Given that 
x2(t) = x,(l- t) + x,(t- 1), 
how is the fundamental frequency w 2 of x2(t) related to WJ? Also, find a relationship 
between the Fourier series coefficients bk of x2(t) and the coefficients ak. You may 
use the properties listed in Table 3.1. 
3.6. Consider three continuous-time periodic signals whose Fourier series representa-
tions are as follows: 
Use Fourier series properties to help answer the following questions: 
(a) Which of the three signals is/are real valued? 
(b) Which of the three signals is/are even? 
3.7. Suppose the periodic signal x(t) has fundamental period T and Fourier coefficients 
ak. In a variety of situations, it is easier to calculate the Fourier series coefficients 

252 
Fourier Series Representation of Periodic Signals 
bk for g(t) = dx(t)ldt, as opposed to calculating ak directly. Given that 
J:T x(t) dt = 2, 
Chap.3 
find an expression for ak in terms of bk and T. You may use any of the properties 
listed in Table 3.1 to help find the expression. 
3.8. Suppose we are given the following information about a signal x(t): 
1. x(t) is real and odd. 
2. x(t) is periodic with period T = 2 and has Fourier coefficients ak. 
3. ak = Ofor lkl > 1. 
4. 4J0
2Ix(t)l2 dt = 1. 
Specify two different signals that satisfy these conditions. 
3.9. Use the analysis equation (3.95) to evaluate the numerical values of one period of 
the Fourier series coefficients of the periodic signal 
00 
x[n] = L {4o[n- 4m] + 8o[n- 1 - 4m]}. 
m= - oo 
3.10. Let x[n] be a real and odd periodic signal with period N = 7 and Fourier coefficients 
ak. Given that 
a1s = j, a16 = 2j, a17 = 3j, 
determine the values of ao, a-t. a - 2. and a-3· 
3.11. Suppose we are given the following information about a signal x[n]: 
1. x[n] is a real and even signal. 
2. x[n] has period N = 10 and Fourier coefficients ak. 
3. au = 5. 
I 
9 
4. w L lx[n]i2 =50. 
n=O 
, Show that x[n] = A cos(Bn +C), and specify numerical values for the constants A, 
B, and C. 
3.12. Each of the two sequences x1 [n] and x2[n] has a period N = 4, and the correspond-
ing Fourier series coefficients are specified as 
~~ [n] ~ 
ah 
x2[n] ~ 
bh 
where 
1 
1 
ao = a3 = 2a1 = 2 a2 = 1 and 
bo = b1 = b2 = b3 = 1. 
Using the multiplication property in Table 3.1, determine the Fourier series coeffi-
cients ck for the signal g[n] = x1 [n]x2[n]. 

Chapo3 
Problems 
3.13. Consider a continuous-time LTI system whose frequency response is 
H(jw) = [ , h(t)e~Jwtdt = sin~w) 
If the input to this system is a periodic signal 
x(t) = { 1, 
0 ::5 t < 4 
- 1, 4 ::5 t < 8 
with period T = 8, determine the corresponding system output y(t)o 
3.14. When the impulse train 
00 
x[n] = .2: o[n- 4k] 
k = -
00 
253 
is the input to a particular LTI system with frequency response H(eiw), the output 
of the system is found to be 
(
57T 
7T) 
y[n] = cos 2 n + '4 
o 
Determine the values of H(eikr.IZ) fork = 0, 1, 2, and 30 
3.15. Consider a continuous-time ideallowpass filterS whose frequency response is 
H(jw) = { 1, 
lwl ::5 100 
0, 
lwl > 100 ° 
When the input to this filter is a signal x(t) with fundamental period T = 7T/6 and 
Fourier series coefficients a k. it is found that 
s 
x(t) ~ 
y(t) = x(t)o 
For what values of k is it guaranteed that ak = 0? 
3.16. Determine the output of the filter shown in Figure P3 016 for the following periodic 
inputs: 
(a) XJ [n] = ( - l)n 
(b) x2[n] = 1 + sin(3; n + i) 
(c) x3[n] = 2:~= - oomn-
4ku[n- 4k] 
'1T 
5'1T 
3 
12 
-2'1T - ~ _um 
3 
12 
_5'1T _:n: 
12 
3 
'1T 
Figure P3. 16 

254 
Fourier Series Representation of Periodic Signals 
Chap.3 
3.17. Consider three continuous-time systems s I' s2. and s3 whose responses t\) a complex 
exponential input ei51 are specified as 
sl : ei5t ___,. tei5t, 
s2 : ei5t ___,. ei5(t- l), 
s3 : ejSt ___,. cos(5t). 
For each system, determine whether the given information is sufficient to conclude 
that the system is definitely not LTI. 
3.18. Consider three discrete-time systems S1, S2, and S3 whose respective responses to 
a complex exponential input ei'rrn/2 are specified as 
sl : ej1Till2 ___,. ej1Tnl2u[n], 
s2 : ej1Tnl2 ___,. eJ3mzl2' 
s3 : ej1Tn12 ___,. 2ej51Tfz12. 
For each system, determine whether the given information is sufficient to conclude 
that the system is definitely not LTI. 
3.19. Consider a causal LTI system implemented as the RLcircuit shown in Figure P3.19. 
A current source produces an input current x(t), and the system output is considered 
to be the current y(t) flowing through the inductor. 
1!1 
Figure P3. 19 
(a) Find the differential equation relating x(t) and y(t). 
(b) Determine the frequency response of this system by considering the output of 
the system to inputs of the form x(t) = eiwt. 
(c) Determine the output y(t) if x(t) = cos(t). 
3.20. Consider a causal LTI system implemented as the RLC circuit shown in Figure 
P3.20. In this circuit, x(t) is the input voltage. The voltage y(t) across the capac-
itor is considered the system output. 
+ 
x(t) 
R=10 
L= 1H 
C= 1F 
y(t) 
Figure P3.20 

Chap. 3 
Problems 
255 
(a) Find the differential equation relating x(t) and y(t). 
(b) Determine the frequency response of this system by considering the output of 
the system to inputs of the form x(t) = ejwt. 
(c) Determine the output y(t) if x(t) = sin(t). 
BASIC PROBLEMS 
3.21. A continuous-time periodic signal x(t) is real valued and has a fundamental period 
T = 8. The nonzero Fourier series coefficients for x(t) are specified as 
Express x(t) in the form 
a1 = a:.. 1 = j, as = a- s = 2. 
x(t) = L Ak cos(wkt + 4>k)· 
k=O 
3.22. Determine the Fourier series representations for the following signals: 
(a) Each x(t) illustrated in Figure P3.22(a)-(f). 
(b) x(t) periodic with period 2 and 
x(t) = e - t 
for 
- 1 < t < 1 
x(t) 
x(t) 
~ 
I / 'I ~ I / 
-5 
- 4 
- 3 
-2 
-1 
1 
2 
3 
4 
5 
(b) 
x(t) 
~ 
(c) 
Figure P3.22 

256 
Fourier Series Representation of Periodic Signals 
Chap.3 
x(t) 
t - 3 
t - 1 r 
1 
t 
3 
t 
5 L 
-4 l -2 l 
l-2 2 l 
4 l 
6 
(d) 
x(t) 
l 
I 
0 1~ 
I n I lJ 
- 7 - 6 
3 4 
5 
6 
lJ -~ -2 
- 1- 1 lJ 
(e) 
x(t) 
JJ _[}J ~~ f!-1 ~ 
(f) 
Figure P3.22 
Continued 
(c) x(t) periodic with period 4 and 
x(t) = { sin 'ITt, 
0 ::5 t ::5 2 
0, 
2 < t ::5 4 
3.23. In each of the following, we specify the Fourier series coefficients of a continuous-
time signal that is periodic with period 4. Determine the signal x(t) in each case. 
{ 
0, 
k = 0 
. (a) ak = 
(j)k sin;;'\ otherwise 
(b) a = (- l)k sin br/8 
-
..!_ 
k 
2k7r ' 
ao -
16 
( ) 
-
{ j k, 
lkl < 3 
c ak -
0, 
otherwise 
{ 
1 
k even 
(d) a k = 2: 
k odd 
3.24. Let 
x(t) = { t, 
0 ::5 t ::5 1 
2 - t, 
1 ::5 t ::5 2 
be a periodic signal with fundamental period T = 2 and Fourier coefficients ak. 
(a) Determine the value of ao. 
(b) Determine the Fourier series representation of dx(t)/dt. 
(c) Use the result of part (b) and the differentiation property of the continuous-time 
Fourier series to help determine the Fourier series coefficients of x(t). 

Chap.3 
Problems 
257 
3.25. Consider the following three continuous-time signals with a fundamental period of 
T = 112: 
x(t) = cos(47Tt), 
y(t) = sin(47Tt), 
z(t) = x(t)y(t). 
(a) Determine the Fourier series coefficients of x(t). 
(b) Determine the Fourier series coefficients of y(t). 
(c) Use the results of parts (a) and (b), along with the multiplication property of the 
continuous-time Fourier series, to determine the Fourier series coefficients of 
z(t) = x(t)y(t). 
{d) Determine the Fourier series coefficients of z(t) through direct expansion of z(t) 
in trigonometric form, and compare your result with that of part (c). 
3.26. Let x(t) be a periodic signal whose Fourier series coefficients are 
Use Fourier series properties to answer the following questions: 
(a) Is x(t) real? 
(b) Is x(t) even? 
(c) Is dx(t)/dt even? 
3.27. A discrete-time periodic signal x[n] is real valued and has a fundamental period 
N = 5. The nonzero Fourier series coefficients for x[n] are 
- 2 
-
• 
- 2 j'TT'/6 
ao -
, az -
a _2 -
e 
, 
Express x[n] in the form 
00 
x[n] = Ao + .2:, Ak sin(wkn + c/>k). 
k = l 
3.28. Determine the Fourier series coefficients for each of the following discrete-time 
periodic signals. Plot the magnitude and phase of each set of coefficients ak. 
(a) Each x[n] depicted in Figure P3.28(a)-(c) 
(b) x[n] = sin(27Tn/3)cos(7Tn/2) 
(c) x[n] periodic with period 4 and 
1 
. 7Tn 
x[n] = 
- sm 4 
for 0 :5 n :5 3 
(d) x[n] periodic with period 12 and 
x[n] = 1 - sin ~n for 0 :5 n :5 11 

258 
Fourier Series ·Representation of Periodic Signals 
Chap.3 
x[n] 
III .. IIIII .. IIIII.:Itlll .. lllll .. lllll .. ll 
-14 
-7 
0 
7 
14 
21 n 
(a) 
x[n] 
.IIII .. IIII .. IIII.~IIII .. IIII .. IIII .. IIII. 
-18 
-12 
- 6 
2 
0 
(b) 
x[n] 
(c) 
Figure P3.28 
6 
12 
18 
n 
3.29. In each of the following, we specify the Fourier series coefficients of a signal that 
is periodic with period 8. Determine the signal x[n] in each case. 
(a) ak = cos(k;)+ sine~1T) 
(b) ak = { ~~n(k;), ~:~:56 
(c) ak as in Figure P3.29(a) 
(d) ak as in Figure P3.29(b) 
.111.111.111.111.
1
111.111.111.11 
- 8 
0 
8 
16 
k 
(a) 
ak 
2 
lo,olllllo,olllill.,lllllo,olll 
- 8 
0 
8 
16 
k 
(b) 
Figure P3.29 
3.30. Consider the following three discrete-time signals with a fundamental period of 6: 
(27T ) 
0 (27T 
7T) 
x[n] = 1 +cos 6 n , 
y[n] = sm 6 n + 4 , 
z[n] = x[n]y[nJ 

Chap.3 
Problems 
(a) Determine the Fourier series coefficients of x[n]. 
(b) Determine the Fourier series coefficients of y[n]. 
259 
(c) Use the results of parts (a) and (b), along with the multiplication property of 
the discrete-time Fourier series, to determine the Fourier series coefficients of 
z[n] = x[n]y[n]. 
(d) Determine the Fourier series coefficients of z[n] through direct evaluation, and 
compare your result with that of part (c). 
3.31. Let 
x[n] = { 1, 
0 :5 n :5 7 
0, 
8 :5 n :5 9 
be a periodic signal with fundamental period N = 10 and Fourier serj.es coefficients 
ak. Also, let 
g[n] = x[n] - x[n - 1]. 
(a) Show that g[n] has a fundamental period of 10. 
(b) Determine the Fourier series coefficients of g[n]. 
(c) Using the Fourier series coefficients of g[n] and the First-Difference property 
in Table 3.2, determine ak for k # 0. 
3.32. Consider the signal x[n] depicted in Figure P3.32. This signal is periodic with period 
N = 4. The signal can be expressed in terms of a discrete-time Fourier series as 
3 
x[n] = 2.:: akeJk(27rl4)n. 
(P3.32-1) 
k=O 
x[n] 
Figure P3.32 
As mentioned in the text, one way to determine the Fourier series coefficients is 
to treat eq. (P3.32-1) as a set of four linear equations (for n = 0, 1, 2, 3) in four 
unknowns (ao, a1, a2, and a3). 
(a) Write out these four equations explicitly, and solve them directly using any stan-
dard technique for solving four equations in four unknowns. (Be sure first to 
reduce the foregoing complex exponentials to the simplest form.) 
(b) Check your answer by calculating the ak directly, using the discrete-time 
Fourier series analysis equation 
1 3 
. 
ak = 4 2.:: x[n]e- Jk(27rl4)n. 
n=O 

260 
Fourier SE_lries Representation of Periodic Signals 
Chap.3 
3.33. Consider a causal continuous-time LTI system whose input x(t) and Otltput y(t) are 
related by the following differential equation: 
d 
dty(t) + 4y(t) = x(t). 
Find the Fourier series representation of the output y(t) for each of the following 
inputs: 
(a) x(t) = cos 27Tt 
(b) x(t) = sin47Tt + cos(67Tt + TT/4) 
3.34. Consider a continuous-time LTI system with impulse response 
h(t) = e- 4ltl. 
Find the Fourier series representation of the output y(t) for each of the following 
inputs: 
(a) x(t) = L:::_"'o(t- n) 
(b) x(t) = 2:::: _
00 ( -l)no(t - n) 
(c) x(t) is the periodic wave depicted in Figure P3.34. 
1 " 
~ 
···l D D D 
DODD 
- 3 
- 2 
-1 
0 
1 
2 
3 
4 
Figure P3.34 
3.35. Consider a continuous-time LTI system S whose frequency response is 
H( ·w) = { 1, 
lwl <== ~50. 
1 
0, 
otherwise 
When the input to this system is a signal x(t) with fundamental period T = 7rl7 and 
Fourier series coefficients ak> it is found that the output y(t) is identical to x(t). 
For what values of k is it guaranteed that ak = 0? 
-
3.36. Consider a causal discrete-time LTI system whose input x[n] and output y[n] are 
related by the following difference equation: 
1 
y[n] - 4y[n- 1] = x[n] 
Find the Fourier series representation of the output y[n] for each of the following 
inputs: 
(a) x[n] = sine
17 n) 
(b) x[n] = cos(in) + 2cos(¥n) 
3.37. Consider a discrete-time LTI system with impulse response 
(
1 ~nl 
h[n] = 2,} 

Chap.3 
Problems 
261 
Find the Fourier series representation of the output y[n] for each of the following 
inputs: 
(a) x[n] = L:;=_008[n- 4k] 
(b) x[n] is periodic with period 6 and 
x[n] = { 01,, 
n = 0, ::!:: 1 
n = ::!::2, ::!::3 
3.38. Consider a discrete-time LTI system with impulse response 
{ 
1, 
0 :::; n :::; 2 
h[n] = 
-1, 
- 2 :::; n :::; - 1 . 
0, 
otherwise 
Given that the input to this system is 
+ oo 
x[n] = L, B[n - 4k], 
k = - oo 
determine the Fourier series coefficients of the output y[n]. 
3.39. Consider a discrete-time LTI systemS whose frequency response is 
. 
( 1, 
H(elw) = 
0, 
lwl:::; ~ 
~ < lwl < 7T • 
Show that if the input x[n] to this system has a period N = 3, the output y[n] has 
only one nonzero Fourier series coefficient per period. 
ADVANCED PROBLEMS 
3.40. Let x(t) be a periodic signal with fundamental period T and Fourier series coeffi-
cients ak. Derive the Fourier series coefficients of each of the following signals in 
terms of ak: 
(a) x(t - to) + x(t + to) 
(b) 8t~{x(t)} 
(c) CRe{x(t)} 
(d) d2 x(t) 
dt2 
(e) x(3t - 1) [for this part, first determine the period of x(3t - 1)] 
3.41. Suppose we are given the following information about a continuous-time periodic 
signal with period 3 and Fourier coefficients ak: 
1. ak = ak+2 · 
2. ak = a - k· 
3. J ~;;5 x(t)dt = 1. 
4. fx(t)dt = 2. 
Determine x(t). 

262 
Fourier Series Representation of Periodic Signals 
Chap. 3 
3.42. Let x(t) be a real-valued signal with fundamental period T and Fourier series coef-
ficients ak. 
(a) Show that ak = a*_k and ao must be real. 
(b) Show that if x(t) is even, then its Fourier series coefficients must be real and 
even. 
(c) Show that if x(t) is odd, then its Fourier series coefficients are imaginary and 
odd and ao = 0. 
(d) Show that the Fourier coefficients of the even part of x(t) are equal to <Re{ad. 
(e) Show that the Fourier coefficients of the odd part of x(t) are equal to jtl'm{ak}. 
3.43. (a) A continuous-time periodic signal x(t) with period Tis said to be odd harmonic 
if, in its Fourier series representation 
+co 
x(t) = L akejk(27TIT)r, 
k = - CO 
ak = 0 for every non-zero even integer k. 
(i) Show that if x(t) is odd harmonic, then 
x(t) = - x(t+ ~). 
(ii) Show that if x(t) satisfies eq. (P3.43-2), then it is odd harmonic. 
(P3.43-1) 
(P3.43-2) 
(b) Suppose that x(t) is an odd-harmonic periodic signal with period 2 such that 
x(t) = t 
for 0 < t < 1. 
Sketch x(t) and find its Fourier series coefficients. 
(c) Analogously, to an odd-harmonic signal, we could define an even-harmonic 
signal as a signal for which ak = 0 fork odd in the representation in eq. (P3.43-
l). Could T be the fundamental period for such a signal? Explain your answer. 
(d) More generally, show that Tis the fundamental period of x(t) in eq. (P3.43-1) 
if one of two things happens: 
(1) Either a1 or a - 1 is nonzero; 
or 
(2) There are two integers k and l that have no common factors and are such 
that both ak and a 1 are nonzero. 
3.44. Suppose we are given the following information about a signal x(t): 
1. x(t) is a real signal. 
2. x(t) is periodic with period T = 6 and has Fourier coefficients ak. 
3. ak = 0 for k = 0 and k > 2. 
4. x(t) = - x(t - 3). 
5. i/!3lx(t)l2 dt = ~ · 
6. a 1 is a positive real number. 
Show that x(t) = A cos(Bt + C), and determine the values of the constants A, B, 
and C. 

Chap.3 
Problems 
263 
3.45. Let x(t) be a real periodic signal with Fourier series representation given in the 
sine-cosine form of eq. (3.32); i.e., 
\ 
- 5 
-
-6 
x(t) = ao + 2 _2)Bk cos kw0t- Ck sin kw0t]. 
k = l 
(P3.45-1) 
(a) Find the exponential Fourier series representation of the even and odd parts of 
x(t); that is, find the coefficients ak and f3k in terms of the coefficients in eq. 
(P3.45- 1) so that 
+oo 
Sv{x(t)} = L akeJkwot, 
k = -00 
+oo 
0d{x(t)} = L f3keJ kwot. 
k = - oo 
(b) What is the relationship betweenak and a _k in part (a)? What is the relationship 
- 4 
between f3 k and f3- k? 
. 
(c) Suppose that the signals x(t) and z(t) shown in Figure P3.45 have the sine-cosine 
series representations 
~[ 
(27Tkt) 
. (27Tkt)~ 
x(t) = a0 + 2 t:J Bkcos - 3-
- Cksm - 3- l 
~[ 
(27Tkt) 
. (27Tkt)~ 
z(t) = do + 2 t:J Ek cos - 3-
- Fk sm - 3-l 
x(t) 
'l 
-3 - 2 
0 
1 
3 
4 
6 
7 
9 
z(t) 
-
2-
-
-
~ 
-3 
- 1 
1 
2 
3 4 
5 
6 7 
8 
9 
t 
...._ 
~ 
- 2 
~ 
-
~ 
Figure P3.45 

264 
Fourier Series Representation of Periodic Signals 
Chap. 3 
Sketch the signal 
y(t) ~ 4(ao +do)+ 2 t,{[ B, + 
~E1 ]cos (Z~kt )+ F, sine~kt )}· 
3.46 In this problem, we derive two important properties of the continuous-time Fourier 
series: the multiplication property and Parseval's relation. Let x(t) and y(t) both be 
continuous-time periodic signals having period To and with Fourier series represen-
tations given by 
+ co 
+co 
x(t) = L 
a kejkw0t, 
y(t) = L 
bkejkwot. 
(P3.46-1) 
k = -co 
k = - CO 
x1(t) 
20'1Tt 
(a) 
x2(t) 
z(t) cos 20'1Tt, 
where z(t) is as in Figure P3.22(f) 
(b) 
e - I 1 I cos 20'1Tt 
- 3 
- 1 
(c) 
Figure P3.46 

Chap.3 
Problems 
265 
(a) Show that the Fourier series coefficients of the signal 
+oo 
z(t) = x(t)y(t) = L ckejkwot 
k= -00 
are given by the discrete convolution 
+oo 
Ck = L anbk-n· 
n= -co 
(b) Use the result of part (a) to compute the Fourier series coefficients of the signals 
x1(t), x2(t), and x3(t) depicted in Figure P3.46. 
(c) Suppose that y(t) in eq. (P3.46-1) equals x*(t). Express the bk in the equation in 
terms of ab and use the result of part (a) to prove Parseval's relation for periodic 
signals-that is, 
3.47 Consider the signal 
x(t) = cos 2Trt. 
Since x(t) is periodic with a fundamental period of 1, it is also periodic with a period 
of N, where N is any positive integer. What are the Fourier series coefficients of x(t) 
if we regard it as a periodic signal with period 3? 
3.48. Let x[n] be a periodic sequence with period Nand Fourier series representation 
x[n] = L 
akejk(27riN)n. 
k=<N> 
(P3.48-1) 
The Fourier series coefficients for each of the following signals can be expressed in 
terms of akin eq. (P3.48- l). Derive the expressions. 
(a) x[n- no] 
(b) x[n] - x[n- 1] 
(c) x[n] - x[n -
~] (assume that N is even) 
(d) x[n] + x[n + ~] (assume that N is even; note that this signal is periodic with 
period N/2) 
(e) x*[ -n] 
(f) ( -l)nx[n] (assume that N is even) 
(g) ( -l)n x[n] (assume that N is odd; note that this signal is periodic with period 
2N) 
(h) y[n] = { x[n], 
n even 
0, 
n odd 
3.49. Let x[n] be a periodic sequence with period Nand Fourier series representation 
x[n] = L 
akejk(27riN)n. 
k=<N> 
(P3.49- 1) 

266 
Fourier Series Representation of Periodic Signals 
(a) Suppose that N is even and that x[n] in eq. (P3.49-1) satisfies 
x[n] = -x[n+ ~] foralln. 
Show that ak = 0 for all even integers k. 
(b) Suppose that N is divisible by 4. Sh~w that if 
x[n] = -x[n +~]for all n, 
then ak = 0 for every value of k that is a multiple of 4. 
Chap.3 
(c) More generally, suppose that N is divisible by an integer M. Show that if 
(N/M) - 1 
[ 
N] 
2o · 
x n + r M 
= 0 for all n, 
then ak = 0 for every value of k that is a multiple of M . 
3.50. SJ1ppose we are given the following information about a periodic signal x[n] with 
period 8 and Fourier coefficients ak: 
1. ak = - ak- 4· 
2. x[2n + 1] = (-1)n. 
Sketch one period of x[n]. 
3.51. Let x[n] be a periodic signal with period N = 8 and Fourier series coefficients 
ak = -ak- 4. A signal 
[ ] 
(
1 + ( -l)n) [ 
1) 
yn= 
2 
xn-
with period N = 8 is generated. Denoting the Fourier series coefficients of y[n] by 
bk, find a function f[k] such that 
3.52. x[n] is a real periodic signal with period Nand complex Fourier series coefficients 
ak· Let the Cartesian form for ak be denoted by 
where bk and ck are both real. 
(a) Show that a _k = ak". What is the relation between bk and h - k? What is the 
relation between ck and c _k? 
(b) Suppose that N is even. Show that aNn is real. 

Chap.3 
Problems 
267 
(c) Show that x[n] can also be expressed as a trigonometric Fourier series of the 
form 
(N - I)/
2 
(2 k ) 
(2 k ) 
x[n] = ao + 2 ~ bk cos 
: 
n - ck sin 
: 
n 
if N is odd or as 
(N-
2
l
12 
(2 k ) 
(2 k ) 
x[n] = (ao +aNd -1)
11
) + 2 ~ bk cos 
: 
n - ck sin 
: 
n 
if N is even. 
(d) Show that if the polar form of ak is Akei0k, then the Fourier series representation 
for x[n] can also be written as 
(N-1)12 
(2 k 
) 
x[n] = ao + 2 ~ Ak cos 
: 
n + (h 
if N is odd or as 
(N/2)- 1 
( 2 k 
) 
x[n] = (ao + aNd-1)") + 2 L Akcos 
: 
n + fh 
k = l 
if N is even. 
(e) Suppose that x[n] and z[n], as depicted in Figure P3.52, have the sine-cosine 
series representations 
3 
2 
1 
x[n] 
z[n) 
3 
2 
Figure P3.52 
n 
n 

268 
Fourier Series Representation of Periodic Signals 
Chap.3 
~~ 
(27Tkn) 
. (27Tkn)j 
x[n] = a0 + 2 tJ bkcos - 7-
- cksm - 7-
, 
~~ 
(27Tkn) 
. (27Tkn)j 
z[n] =do+ 2 tJ dkcos - 7-
- fksm - 7-
. 
Sketch the signal 
~~ 
(27Tkn) 
. (27Tkn)j 
y[n] = ao- do+ 2 tJ dkcos - 7-
+ (fk- ck)sm - 7-
. 
3.53. Let x[n] be a real periodic signal with period Nand Fourier coefficients ak. 
(a) Show that if N is even, at least two of the Fourier coefficients within one period 
of ak are real. 
(b) Show that if N is odd, at least one of the Fourier coefficients within one period 
of ak is real. 
3.54. Consider the function 
N-1 
a[k] = L ei(27r!N)kn. 
n=O 
(a) Show that a[k] = N fork = 0, ±N, ±2N, ±3N, .. .. 
(b) Show that a[k] = 0 whenever k is not an integer multiple of N. (Hint: Use the 
finite sum formula.) 
(c) Repeat parts (a) and (b) if 
a[k] = L 
ei(2TTIN)kn. 
n=<N> 
3.55. Let x[n] be a periodic signal with fundamental period Nand Fourier series coeffi-
cients ak. In this problem, we derive the time-scaling property 
[ ] _ { x[ E.], 
n = 0, ±m, ±2m,··· 
X(m) n -
m 
0, 
elsewhere 
listed in Table 3.2. 
(a) Show that X(m)[n] has period of mN. 
(b) Show that if 
x[n] = v[n] + w[n], 
then 

Chap.3 
Problems 
269 
(c) Assuming that x[n] = ei2'1rkon!N for some integer k0, verify that 
l m- 1 
X(m)[n] = - L ej2'1r(ko+IN)nl(mN)_ 
m 1= 0 
That is, one complex exponential in x[n] becomes a linear combination of m 
complex exponentials in X(m)[n]. 
(d) Using the results of parts (a), (b), and (c), show that if x[n] has the Fourier 
coefficients ak, then X(m)[n] must have the Fourier coefficients ~ak. 
3.56. Let x[n] be a periodic signal with period Nand Fourier coefficients ak. 
(a) Express the Fourier coefficients bk of lx[nJI2 in terms of ak. 
(b) If the coefficients ak are real, is it guaranteed that the coefficients bk are also 
real? 
· 
3.57. (a) Let 
N - 1 
x[n] = L akejk(27r!N)n 
(P3.57-1) 
k=O 
and 
N - 1 
y[n] = L bkejk(27r!N)n 
k= O 
be periodic signals. Show that 
N - 1 
x[n]y[n] = L ckejk(27r!N)n, 
k= O 
where 
N-1 
N - 1 
ck = L, albk-1 = L ak- lbl. 
1= 0 
1= 0 
(b) Generalize the result of part (a) by showing that 
Ck = L 
albk- 1 = L 
ak- lbl. 
I =<N> 
I =<N> 
(c) Use the result of part (b) to find the Fourier series representation of the following 
signals, where x[n] is given by eq. (P3.57- l). 
(i) 
x[n] cos ( 
6~n) 
(ii) x[n]L:::_ 005[n- rN] 
(iii) x[n] (2:::::_"'5 [ 
n -
'~])(assume thatNis divisible by 3) 
(d) Find the Fourier series representation for the signal x[n]y[n], where 
x[n] = cos( 7Tn/3) 

270 
Fourier Series Representation of Periodic Signals 
Chap. 3 
and 
{ 
1 
lnl :s 3 
y [n] = o: 
4 :s lnl :s 6 · 
is periodic with period 12. 
(e) Use the result of part (b) to show that 
L 
x [n] y [n] = N L atb- f, 
n=<N> 
l=<N> 
and from this expression, derive Parseval's relation for discrete-time periodic 
signals. 
3.58. Let x[n] and y[n] be periodic signals with common period N, and let 
z[n] = L 
x [r] y [n - r] 
r=<N> 
be their periodic convolution. 
(a) Show that z[n] is also periodic with period N. 
(b) Verify that if ak, bk> and ck are the Fourier coefficients of x [n] , y[n], and z[n], 
respectively, then 
(c) Let 
x [n] = sin c:n) 
and 
[n] = { 1, 
0 :s n :s 3 
y 
0, 
4 :s n :s 7 
be two signals that are periodic with period 8. Find the Fourier series represen-
tation for the periodic convolution of these signals. 
(d) Repeat part (c) for the following two periodic signals that also have period 8: 
x[n] = 
sm 4 
' 
-
n -
, 
[ 
. (31Tn) 
0 < 
< 3 
0, 
4 :s n :s 7 
y[n] = G r 
o :s n :s 7. 
3.59. (a) Suppose x[n] is a periodic signal with period N. Show that the Fourier series 
coefficients of the periodic signal 
00 
g(t) = L x[k] 5(t - kT) 
k = -
00 
are periodic with period N. 

Chap.3 
Problems 
271 
(b) Suppose that x(t) is a periodic signal with period T and Fourier series coeffi-
cients ak with period N. Show that there must exist a periodic sequence g[n] 
such that 
00 
x(t) = L g[k] 8(t- kTIN). 
k = - oo 
(c) Can a continuous periodic signal have periodic Fourier coefficients? 
3.60. Consider the following pairs of signals x[n] and y[n]. For each pair, determine 
whether there is a discrete-time LTI system for which y[n] is the output when the 
corresponding x[n] is the input. If such a system exists, determine whether the sys-
tem is unique (i.e., whether there is more than one LTI system with the given input-
output pair). Also, determine the frequency response of an LTI system with the 
desired behavior. If no such LTI system exists for a given x[n], y[n] pair, explain 
why. 
' 
I n 
In 
(a) x[n] = (2 ), y[n] = (4 ) 
(b) x[n] = (tn)u[n], y[n] = (~)nu[n] 
(c) x[n] = (t n)u[n], y[n] = 4nu[ -n] 
(d) x[n] = ejn!S, y[n] = 2ejnts 
(e) x[n] = ejnl8u[n], y[n] = 2ejn18u[n] 
(t) x[n] = r. y[n] = 2r(l- j) 
(g) x[n] = cos(1Tnl3),y[n] = cos(1Tnl3) + J3 siri(7Tn/3) 
(h) x[n] and y1 [n] as in Figure P3.60 
(i) x[n] and Y2[n] as in Figure P3.60 
x[n] · 
••• ttt •••••••• ~ttt ••••••••• ttt ••••••••• ttl 
-12 
0 
12 
24 n 
tlt ••• tll ••• llt ••• III ••• lll ••• lll ••• lll ••• 
-15 
-9 
-3 
0 
3 
9 
15 
21 
n 
Y2!n] 
•••••• ttt •••••• ttt •••••• ttt •••••• ttt •••••• 
- 9 
0 
9 
18 
n 
Figure P3.60 
3.61. As we have seen, the techniques of Fourier analysis are of value in examining 
continuous-time LTI systems because periodic complex exponentials are eigenfunc-
tions for LTI systems. In this problem, we wish to substantiate the following state-
ment: Although some LTI systems may have additional eigenfunctions, the complex 
exponentials are the only signals that are eigenfunctions of every LTI system. 

272 
Fourier Series Representation of Periodic Signals 
Chap. 3 
(a) What are the eigenfunctions of the LTI system with unit impulse response 
h(t) = B(t)? What are the associated eigenvalues? 
(b) Consider the LTI system with unit impulse response h(t) = B(t - T). Find a 
signal that is not of the form e51, but that is an eigenfunction of the system with 
eigenvalue 1. Similarly, find the eigenfunctions with eigenvalues 112 and 2 that 
are not complex exponentials. (Hint: You can find impulse trains that meet these 
requirements.) 
(c) Consider a stable LTI system with impulse response h(t) that is real and even. 
Show that cos wt and sin wt are eigenfunctions of this system. 
(d) Consider the LTI system with impulse response h(t) = u(t). Suppose that <f>(t) is 
an eigenfunction of this system with eigenvalue A. Find the differential equation 
that <f>(t) must satisfy, and solve the equation. This result, together with those 
of parts (a) through (c), should prove the validity of the statement made at the 
beginning of the problem. 
3.62. One technique for building a de power supply is to take an ac signal and full-wave 
rectify it. That is, we put the ac signal x(t) through a system that produces y(t) = 
lx(t)l as its output. 
(a) Sketch the input and output waveforms if x(t) = cost. What are the fundamen-
tal periods of the input and output? 
(b) If x(t) = cost, determine the coefficients of the Fourier series for the output 
y(t). 
(c) What is the amplitude of the de component of the input signal? What is the 
amplitude of the de component of the output signal? 
3.63. Suppose that a continuous-time periodic signal is the input to an LTI system. The 
signal has a Fourier series representation 
00 
x(t) = ~ 
a1kleik(7TI4)t, 
k = -oo 
where a is a real number between 0 and 1, and the frequency response of the system 
is 
H(jw) = { l , 
0, 
lwl :5 W 
lwi >W . 
How large must W be in order for the output of the system to have at least 90% of 
the average energy per period of x(t)? 
3.64. As we have seen in this chapter, the concept of an eigenfunction is an extremely 
important tool in the study ofLTI systems. The same can be said for linear, but time-
varying, systems. Specifically, consider such a system with input x(t) and output 
y(t). We say that a signal <f>(t) is an eigenfunction of the system if 
<f>(t) ~ 
A<f>(t). 
That is, if x(t) = <f>(t), then y(t) = A<f>(t), where the complex constant A is called 
the eigenvalue associated with <f>(t). 

Chap. 3 
Problems 
273 
(a) Suppose that we can represent the input x(t) to our system as a linear combina-
tion of eigenfunctions c/Jit), each of which has a corresponding eigenvalue Ak; 
that is, 
00 
x(t) = 2: ckcfJk(t). 
k = -oo 
Express the output y(t) of the system in terms of {cd, {c/Jk(t)}, and {Ak}. 
(b) Consider the system characterized by the differential equation 
( ) 
_ 
2 d 2 x(t) 
dx(t) 
y t -
t di2 + tdt. 
Is this system linear? Is it time invariant? 
(c) Show that the functions 
cpk(t) = tk 
are eigenfunctions of the system in part (b). For each cfJk(t), determine the cor-
responding eigenvalue Ak. 
(d) Determine the output of the system if 
x(t) = 10r 10 + 3t + ~t
4 + 1r. 
EXTENSION PROBLEMS 
3.65. Two functions u(t) and v(t) are said to be orthogonalover the interval (a,b) if 
r 
u(t)v*(t) dt = 0. 
(P3.65-1) 
If, in addition, 
r 
iu(t)l2 dt = 1 = r 
lv(t)l2 dt, 
the functions are said to be normalized and hence are called orthonormal. A set of 
functions {c/Jk(t)} is called an orthogonal (orthonormal) set if each pair of functions 
in the set is orthogonal (orthonormal). 
(a) Consider the pairs of signals u(t) and v(t) depicted in Figure P3.65. Determine 
whether each pair is orthogonal over the interval (0, 4). 
(b) Are the functions sin mw0t and sin nw0t orthogonal over the interval (0, T), 
where T = 21r!w0? Are they also orthonormal? 
(c) Repeat part (b) for the functions c/Jm(t) and cp11(t), where 
cfJk(t) = )r[cos kwot +sin kwot]. 

274 
u(t) 
- 1 
u(t) 
- 1 
u(t) 
2 3 
4 
Exponentials with 
time constant = 1 
sin ('ll't/2) 
'li'P------. 
2 
3 
4 
Fourier Series Representation of Periodic Signals 
Chap.3 
v(t) 
1 2 
- 1 
(a) 
Exponentials with 
time constant = 1 
4 
(b) 
v(t) 
(c) 
v(t) 
11' 
2 
3 
4 
(d) 
Figure P3.65 
(d) Show that the functions <f>k(t) = ejkwor are orthogonal over any interval of 
length T = 27T/w0. Are they orthonormal? 
(e) Let x(t) be an arbitrary signal, and let x 0 (t) and Xe(t) be, respectively, the odd 
and even parts of x(t). Show that x 0 (t) and Xe(t) are orthogonal over the interval 
( -T, T) for any T. 

Chap.3 
Problems 
275 
(t) Show that if {</Jk(t)} is a set of orthogonal signals over the interval (a, b), then 
the set {(11 Jf4")</Jk(t)}, where 
Ak = r 
I</Jk(t)l2 dt. 
is orthonormal. 
(g) Let {</J;(t)} be a set of orthonormal signals on the interval (a, b), and consider a 
signal of the form 
x(t) = L a;</J;(t), 
i 
where the a; are complex constants. Show that 
f lx(t)l2 dt = L lad2. 
I 
\ 
(h) Suppose that </J1 (t), ... , <fJN(t) are nonzero only in the time interval 0 ::5 t 
::5 T and that they are orthonormal over this time interval. Let L; denote the 
LTI system with impulse response 
h;(t) = </J;(T - t). 
(P3.65-2) 
Show that if <P j(t) is applied to this system, then the output at time T is 1 if 
i = j and 0 if i ~ j. The system with impulse response given by eq. (P3.65- 2) 
was referred to in Problems 2.66 and 2.67 as the matched filter for the signal 
</J;(t). 
3.66. The purpose of this problem is to show that the representation of an arbitrary pe-
riodic signal by a Fourier series or, more generally, as a linear combination of any 
set of orthogonal functions is computationally efficient and in fact very useful for 
obtaining good approximations of signals.12 
Specifically, let {</J;(t)}, i = 0, :±: 1, :±:2, ... be a set of orthonormal functions 
on the interval a ::5 t ::5 b, and let. x(t) be a given signal. Consider the follow-
ing approximation of x(t) over the interval a ::5 t ::5 b: 
+N 
Xn(t) = L a;</J;(t). 
(P3.66- l) 
i =- N 
Here, the a; are (in general, complex) constants. To measure the deviation between 
x(t) and the series approximation XN(t), we consider the error eN(t) defined as 
(P3.66-2) 
A reasonable and widely used criterion for measuring the quality of the approxima-
tion is the energy in the error signal over the interval of interest-that is, the integral 
12See Problem 3.65 for the definitions of orthogonal and orthonormal functions. 

276 
Fourier Series Representation of Periodic Signals 
Chap. 3 
of the square of the magnitude of the error over the interval a ~ t ~ b: 
(P3.66-3) 
(a) Show that E is minimized by choosing 
a; = r 
x(t)<f>7(t) dt. 
(P3.66-4) 
[Hint: Use eqs. (P3.66-1)-(P3.66-3) to express E in terms of a;, <{>;(t), and x(t). 
Then express a; in rectangular coordinates as a; = b; + jc;, and show that the 
equations 
aE 
aE 
. 
- b = 0 
and 
-
= 0, 1 = 0, ± 1, ±2, ... , N 
a ; 
Be; 
are satisfied by the a; as given by eq. (P3.66- 4).] 
(b) How does the result of part (a) change if 
A; = r 
l<f>;(t)l2 dt 
and the {<{>;(t)} are orthogonal but not orthonormal? 
(c) Let <f>n(t) = ejnwor, and choose any interval of length To = 2nlwo. Show that 
the a; that minimize E are as given in eq. (3.50). 
(d) The set of Walsh functions is an often-used set of orthonormal functions. (See 
Problem 2.66.) The set of five Walsh functions, <f>o(t), 4> 1 (t), ... , <{>4(t), is illus-
trated in Figure P3.66, where we have scaled time so that the <{>;(t) are nonzero 
and orthonormal over the interval 0 ~ t ~ 1. Let x(t) = sin 'TT't. Find the ap-
proximation of x(t) of the form 
4 
x(t) = L a;<f>;(t) 
i = O 
such that 
L 
lx(t) - .X(t)l2 dt 
is minimized. 
(e) Show that XN(t) in eq. (P3.66-1) and eN(t) in eq. (P3.66-2) are orthogonal if 
the a; are chosen as in eq. (P3.66-4). 
The results of parts (a) and (b) are extremely important in that they show 
that each coefficient a; is independent of all the other a/ s, i ¥- j . Thus, if 
we add more terms to the approximation [e.g., if we compute the approxi-
mation .XN+ 1 (t)], the coefficients of <{>;(t), i = 1, ... , N , that were previously 
determined will not change. In contrast to this, consider another type of se-

Chap.3 
Problems 
4>o(t) 
- 1 
-1 
-1 
- 1 
1 4 
1 2 
(a) 
(b) 
(c) 
(d) 
(e) 
277 
Figure P3.66 
ries expansion, the polynomial Taylor series. The infinite Taylor series for e1 
is e1 = 1 + t + t2/2! + ... , but as we shall show, when we consider a finite 
polynomial series and the error criterion of eq. (P3.66-3), we get a very different 
result. 
Specifically, let </>o(t) = 1, </> 1(t) = t, <f>2(t) = t2, and so on . 
. (f) Are the </>i(t) orthogonal over the interval 0 ::s t ::s 1? 

278 
Fourier Series Representation of Periodic Signals 
Chap. 3 
(g) Consider an approximation of x(t) = e1 over the interval 0 =5 t =5 1 of the form 
xo(t) = aocf>o(t). 
Find the value of ao that minimizes the energy in the error signal over the in-
terval. 
(h) We now wish to approximate e1 by a Taylor series using two terms-i.e., 
x 1 (t) = ao + a 1 t. Find the optimum values for a0 and a1• [Hint: Compute E in 
terms of a0 and a1, and then solve the simultaneous equations 
aE 
aE __ o. 
-
= 0 
and . 
aao 
aai 
Note that your answer for a0 has changed from its value in part (g), where there 
was only one term in the series. Further, as you increase the number of terms in 
the series, that coefficient and all others will continue to change. We can thus 
see the ~dvantage to be gained in expanding a function using orthogonal terms.] 
3.67 As we discussed in the text, the origins of Fourier analysis can be found in problems 
of mathematical physics. In particular, the work of Fourier was motivated by his 
investigation of heat diffusion. In this problem, we illustrate how the Fourier series 
enter into the investigation. 13 
Consider the problem of determining the temperature at a given depth beneath 
the surface of the earth as a function of time, where we assume that the temperature 
at the surface is a given function of time T(t) that is periodic with period 1. (The 
unit of time is one year.) Let T(x, t) denote the temperature at a depth x below the 
surface at time t. This function obeys the heat diffusion equation 
with auxiliary condition 
aT(x, t) 
at 
T(O, t) = T(t). 
(P3.67-1) 
(P3.67-2) 
Here, k is the heat diffusion constant for the earth (k > 0). Suppose that we expand 
T(t) in a Fourier series: 
+ co 
T(t) = L anejn2m. 
(P3.67-3) 
n= - oo 
Similarly, let us expand T(x, t) at any given depth x in a Fourier series in t. We 
obtain 
+ co 
T(x, t) = L bn(x)ejnZm, 
(P3.67-4) 
n = - oo 
where the Fourier coefficients bn(x) depend upon the depth x. 
13The problem has been adapted from A. Sommerfeld, Partial Differential Equations in Physics (New 
York: Academic Press, 1949), pp 68-71. 

Chap.3 
Problems 
279 
(a) Use eqs. (P3.67-1)-(P3.67-4) to show that bn(x) satisfies the differential equa-
tion 
(P3.67-5a) 
with auxiliary condition 
(P3.67- 5b) 
Since eq. (P3.67-5a) is a second-order equation, we need a second auxiliary 
condition. We argue on physical grounds that, far below the earth's surface, the 
variations in temperature due to surface fluctuations should disappear. That is, 
lim T(x, t) = a constant. 
X-->"' 
(b) Show that the solution of eqs. (P3.67-5) is 
bn(X) = (an exp[ - J 27Tinl(l + j)xlk], 
an exp[ - J 27Tinl(l - j)xlk], 
n:=:::O 
n ::5 0 
(P3.67- 5c) 
(c) Thus, the temperature oscillations at depth x are damped and phase-shifted ver-
sions of the temperature oscillations at the surface. To see this more clearly, 
let 
T(t) = ao + a1 sin27Tt 
(so that a0 represents the mean yearly temperature). Sketch T(t) and T(x, t) over 
a one-year period for 
X= k E 
vi· 
a0 = 2, and a 1 = 1. Note that at this depth not only are the temperature os-
cillations significantly damped, but the phase shift is such that it is warmest in 
winter and coldest in summer. This is exactly the reason why vegetable cellars 
are constructed! 
3.68. Consider the closed contour shown in Figure P3.68. As illustrated, we can view this 
curve as being traced out by the tip of a rotating vector of varying length. Let r(O) 
denote the length of the vector as a function of the angle(}. Then r(O) is periodic in 
(} with period 27T and thus has a Fourier series representation. Let {ak} denote the 
Fourier coefficients of r(O). 
(a) Consider now the projection x(O) of the vector r(O) onto the x-axis, as indicated 
in the figure. Determine the Fourier coefficients for x(O) in terms of the ak 's. 
(b) Consider the sequence of coefficients 
bk = akejk7r14. 
Sketch the figure in the plane that corresponds to this set of coefficients. 

280 
Fourier Series Representation of Periodic Signals 
Chap.3 
- 1 
-1 
Figure P3.68 
(c) Repeat part (b) with 
(d) Sketch figures in the plane such that r(O) is not constant, but does have each of 
the following properties: 
(i) 
r(O) is even. 
(ii) The fundamental period of r(O) is TT. 
(iii) The fundamental period of r(O) is Tr/2. 
3.69. In this problem, we consider the discrete-time counterpart of the concepts introduced 
in Problems 3.65 and 3.66. In analogy with the continuous-time case, two discrete-
time signals <Pk[n] and <Pm[n] are said to be orthogonal over the interval (N1, N2) 
if 
k = m 
k~m · 
(P3.69-1) 
If the value of the constants Ak and Am are both 1, then the signals are said to be 
orthonormal. 
(a) Consider the signals 
<Pk[n] = 5[n - k], k = 0, ± 1, ±2, . . . , ±N. 
Show that these signals are orthonormal over the interval (-N, N). 
(b) Show that the signals 
<Pk[n] = ejk(27r!N)n, k = 0, 1, ... , N - 1, 
are orthogonal over any interval of length N. 
(c) Show that if 
' 
M 
x[n] = L a;<P;[n], 
i=l 

Chap.3 
Problems 
281 
where the <f>;[n] are orthogonal over the interval (N,1, N2), then 
N2 
M 
L ix[nJI2 = L iad2 A;. 
n = N1 
i = l 
(d) Let <f>;[n], i = 0, 1, . . . , M, be a set of orthogonal functions over the interval 
(N1, N2), and let x[n] be a given signal. Suppose that we wish to approximate 
x[n] as a linear combination of the <f>;[n]; that is, 
M 
x[n] = L a;<f>;[n], 
i = O 
where the a; are constant coefficients. Let 
e[n] = x[n] - x[n], 
and show that if we wish to minimize 
N2 
E = L je[n]j2, 
n = N1 
then the a; are given by 
(P3.69- 2) 
[Hint: As in Problem 3.66, express E in terms of a;, <f>;[n], A;, and x[n], write 
a; = b; + jc;, and show that the equations 
aE 
aE 
-
= 0 
and 
-
= 0 
ab; 
ac; 
are satisfied by the a; given by eq. (P3.69-2). Note that applying this result 
when the <f>;[n] are as in part (b) yields eq. (3.95) for ak.] 
(e) Apply the result of part (d) when the <f>;[n] are as in part (a) to determine the 
coefficients a; in terms of x[n]. 
3.70. (a) In this problem, we consider the definition of the two-dimensional Fourier se-
ries for periodic signals with two independent variables. Specifically, consider 
a signal x(t1, t2) that satisfies the equation 
x(tJ, t2) = x(t1 + TJ, t2 + T2), for all tJ, t2. 
This signal is periodic with period T1 in the t1 direction and with period T2 in 
the t2 direction. Such a signal has a series representation of the form 
+oo 
+oo 
X(tj, t2) = L L amnej(mwlll +nw2t2>, 
n= -oo nz = - oo 

282 
Fourier Series Representation of Periodic Signals 
where 
Wt = 2TT!Tt, 
W2 = 2TTIT2. 
Find an expression for am11 in terms of x(tt, t2). 
(b) Determine the Fourier series coefficients am11 for the following signals: 
(i) cos(27rtt + 2t2) 
(ii) the signal illustrated in Figure P3.70 
x(t1,t2) = 1 in shaded areas and 
0 elsewhere 
D 
D 
D 
Figure P3.70 
Chap. 3 
3.71. Consider the mechanical system shown in Figure P3.71. The differential equation 
relating velocity v(t) and the input force f(t) is given by 
f(t) 
v(t) 
~ 
B 
Bv(t) + K I 
v(t) dt = f(t). 
Figure P3.71 

Chap. 3 
Problems 
283 
(a) Assuming that the output is fs(t) , the compressive force acting on the spring, 
write the differential equation relating fs(t) and f(t) . Obtain the frequency re-
sponse of the system, and argue that it approximates that of a lowpass filter. 
(b) Assuming that the output is /d(t), the compressive force acting on the dash-
pot, write the differential equation relating /d(t) and f(t). Obtain the frequency 
response of the system, and argue that it approximates that of a high pass filter. 

4 
THE CONTINUOUS-TIME FOURIER 
TRANSFORM 
4.0 INTRODUCTION 
284 
In Chapter 3, we developed a representation of periodic signals as linear combinations of 
complex exponentials. We also saw how this representation can be used in describing the 
effect of LTI systems on signals. 
In this and the following chapter, we extend these concepts to apply to signals that are 
not periodic. As we will see, a rather large class of signals, including all signals with finite 
energy, can also be represented through .a linear combination of complex exponentials. 
Whereas for periodic signals the complex exponential building blocks are harmonically 
related, for aperiodic signals they are infinitesimally close in frequency, and the represen-
tation in terms of a linear combination takes the form of an integral rather than a sum. The 
resulting spectrum of coefficients in this representation is called the Fourier transform, and 
the synthesis integral itself, which uses these coefficients to represent the signal as a linear 
combination of complex exponentials, is called the inverse Fourier transform. 
The development of this representation for aperiodic signals in continuous time is 
one of Fourier's most important contributions, and our development of the Fourier trans-
form follows very closely the approach he used in his original work. In particular, Fourier 
reasoned that an aperiodic signal can be viewed as a periodic signal with an infinite pe-
riod. More precisely, in the Fourier series representation of a periodic signal, as the period 
increases the fundamental frequency decreases and the harmonically related components 
become closer in frequency. As the period becomes infinite, the frequency components 
form a continuum and the Fourier series sum becomes an integral. In the next section 
we develop the Fourier series representation for continuous-time periodic signals, and 
in the sections that follow we build on this foundation as we explore many of the important 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
285 
properties of the continuous-time Fourier transform that form the foundation of frequency-
domain methods for continuous-time signals and systems. In Chapter 5, we parallel this 
development for discrete-time signals. 
4. 1 REPRESENTATION OF APERIODIC SIGNALS: 
THE CONTINUOUS-TIME FOURIER TRANSFORM 
4.1.1 Development of the Fourier Transform Representation 
of an Aperiodic Signal 
To gain some insight into the nature of the Fourier transform representation, we begin by 
revisiting the Fourier series representation for the continuous-time periodic square wave 
examined in Example 3.5. Specifically, over one period, 
{ 
1 
JtJ < Tt 
x(t) = o: 
T t < JtJ < T/2 
and periodically repeats with period T, as shown in Figure 4.1. 
As determined in Example 3.5, the Fourier series coefficients ak for this square wave 
are 
[eq. (3.44)] 
(4. i) 
where w0 = 2'1TIT. In Figure 3.7, bar graphs ofthese coefficients were shown for a fixed 
value of T 1 and several different values ofT. 
An alternative way of interpreting eq. (4.1) is as samples of an envelope function, 
specifically, 
T 
_ 2sinwTt I 
ak-
. 
W 
w=kw0 
(4.2) 
That is, with w thought of as a continuous variable, the function (2 sin w T1 )lw represents 
the envelope of T ak, and the coefficients ak are simply equally spaced samples of this 
envelope. Also, for fixed Tt. the envelope of Tak is independent ofT. In Figure 4.2, we 
again show the Fourier series coefficients for the periodic square wave, but this time as 
samples of the envelope of Tat, as specified in eq. (4.2). From the figure, we see that as 
x(t) 
... J fJ 
fJ 
I ~ I fJ 
fJ 
[ ... 
-2T 
- T 
_I_ - T1 
T1 
T 
T 
2T 
2 
2 
Figure 4. 1 
A continuous-time periodic square wave. 

286 
(a) 
(b) 
The Continuous-Time Fourier Transform 
Chap.4 
Figure 4.2 
The Fourier series co-
efficients and their envelope for the 
periodic square wave in Figure 4.1 for 
several values of T (with 7; fixed): 
(a) T = 47;; (b) T = 87; ; (c) T = 
167;. 
T increases, or equivalently, as the fundamental frequency w0 = 27TIT decreases, the 
envelope is sampled with a closer and closer spacing. As T becomes arbitrarily large, 
the original periodic square wave approaches a rectangular pulse (i.e., all that remains in 
the time domain is an aperiodic signal corresponding to one period of the square wave). 
Also, the Fourier series coefficients, multiplied by T, become more and more closely 
spaced samples of the envelope, so that in some sense (which we will specify shortly) 
the set of Fourier series coefficients approaches the envelope function as T ~ oo. 
This example illustrates the basic idea behind Fourier's development of a represen-
tation for aperiodic signals. Specifically, we think of an aperiodic signal as the limit of a 
periodic signal as the period becomes arbitrarily large, and we exarninf the limiting be-
havior of the Fourier series representation for this signal. In particular, consider a signal 
x(t) that is of finite duration. That is, for some number T 1, x(t) = 0 if ltl > T 1, as illus-
trated in Figure 4.3(a). From this aperiodic signal, we can construct a periodic signal i(t) 
for which x(t) is one period, as indicated in Figure 4.3(b). As we choose the period T to 
be larger, i(t) is identical to x(t) over a longer interval, and as T ~ oo, i(t) is equal to 
x(t) for any finite value oft. 
Let us now examine the effect of this on the Fourier series representation of i(t). 
Rewriting eqs. (3.38) and (3.39) here for convenience, with the integral in eq. (3.39) 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
x(t) 
06 
(a) 
- 2T 
- T 
T 
2T 
Figure 4.3 
(a) Aperiodic signal x(t); (b) periodic signal x(t), constructed 
to be equal to x(t) over one period. 
carried out over the interval - T 12 :s: t :s: T 12, we have 
+ oo 
i(t) = ~ 
akejkwot, 
k = - oo 
ak = -
i(t)e- Jkwotdt, 
1 I 
T/2 
. 
T 
- T/2 
287 
(4.3) 
(4.4) 
where wo = 27T'/T. Since i(t) = x(t) for ltl < T/2, and also, since x(t) = 0 outside this 
interval, eq. (4.4) can be rewritten as 
ak = -
x(t)e- Jkwotdt = -
x(t)e- Jkwotdt. 
1 I 
T/2 
. 
1 I 
+ oo 
. 
T 
- T/2 
T 
-oo 
Therefore, defining the envelope X(jw) of Tak as 
X(jw) = L+oooo x(t)e- jwtdt, 
(4.5) 
we have, for the coefficients ab 
ak = ~X(jkwo). 
(4.6) 
Combining eqs. (4.6) and (4.3), we can express i(t) in terms of X(jw) as 
+oo 
1 
. 
i(t) = ~ y;X(Jkwo)elkwot, 
k = - oo 
or equivalently, since 2TTIT = w 0 , 
1 
+ oo 
. 
i(t) = 2
'TT ~ X(jkwo)e1kwotwo. 
k = -
00 
(4.7) 

288 
The Continuous-Time Fourier Transform 
Chap.4 
As T ~ oo, i(t) approaches x(t), and consequently, in the limit eq. (4.7) becomes a rep-
resentation of x(t). Furthermore, w 0 ~ 0 as T ~ oo, and the right-hand side of eq. (4.7) 
passes to an integral. This can be seen by considering the graphical interpretation of the 
equation, illustrated in Figure 4.4. Each term in the summation on the right-hand side is 
the area of a rectangle ofheightX(j kw0)ejkwot and width w0. (Here, tis regarded as fixed.) 
As wo ~ 0, the summation converges to the integral of X(jw)ejwr. Therefore, using 
the fact that i(t) ~ x(t) ·as T ~ oo, we see that eqs. ( 4. 7) and ( 4.5) respectively become 
and 
X(jw)eiwt 
1 I 
+ oo 
. 
x(t) = -
X(jw)e1w1dw 
2'TT 
- oo 
' (4.8) 
I 
+ oo 
X(jw) = 
-oo x(t)e- jwtdt. 
(4.9) 
(k + 1)w0 
w 
Figure 4.4 
Graphical interpretation 
of eq. (4.7). 
Equations (4.8) and (4.9) are referred to as the Fourier transfonnpair, with the func-
tion X(jw) referred to as the Fourier Transfonn or Fourier integral of x(t) and eq. (4.8) 
as the inverse Fourier transfonn equation. The synthesis equation (4.8) plays a role for 
aperiodic signals similar to that of eq. (3.38) for periodic signals, since both represent a 
signal as a linear combination of complex exponentials. For periodic signals, these com-
plex exponentials have amplitudes {ak}. as given by eq. (3.39), and occur at a discrete set 
of harmonically related frequencies kw0, k = 0, ± 1, ±2, . . .. For aperiodic signals, the 
complex exponentials occur at a continuum of frequencies and, according to the synthesis 
equation (4.8), have "amplitude" X(jw )(dwi2'TT). In analogy with the terminology used 
for the Fourier series coefficients of a periodic signal, the transform X(jw) of an aperiodic 
signal x(t) is commonly referred to as the spectrum of x(t), as it provides us with the in-
formation needed for describing x(t) as a linear combination (specifically, an integral) of 
sinusoidal signals at different frequencies. 
Based on the above development, or equivalently on a comparison of eq. (4.9) and 
eq. (3.39), we also note that the Fourier coefficients ak of a periodic signal i(t) can be 
expressed in terms of equally spaced samples of the Fourier transform of one period of i(t). 
Specifically, suppose that i(t) is a periodic signal with period T and Fourier coefficients 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
289 
ak. Let x(t) be a finite-duration signal that is equal to i(t) over exactly one period-say, 
for s ::::; t ::::; s + T for some value of s- and that is zero otherwise. Then, since eq. (3.39) 
allows us to compute the Fourier coefficients of i(t) by integrating over any period, 
we can write 
Since x(t) is zero outside the range s ::::; t ::::; s + T we can equivalently write 
Comparing with eq. (4.9) we conclude that 
ak = ~X(jw)l 
, 
w = kwo 
(4.10) 
where X(jw) is the Fourier transform of x(t). Equation 4.10 states that the Fourier coef-
ficients of i(t) are proportional to samples of the Fourier transform of one period of i(t). 
This fact, which is often of use in practice, is examined further in Problem 4.37. 
4.1.2 Convergence of Fourier Transforms 
Although the argument we used in deriving the Fourier transform pair assumed that x(t) 
was of arbitrary but finite duration, eqs. (4.8) and (4.9) remain valid for an extremely broad 
class of signals of infinite duration. In fact, our derivation of the Fourier transform suggests 
that a set of conditions like those required for the convergence of Fourier series should also 
apply here, and indeed, that can be shown to be the case. 1 Specifically, consider X(jw) 
evaluated according to eq. (4.9), and let x(t) denote the signal obtained by using X(jw) in 
the right-hand side of eq. (4.8). That is, 
1 f 
+oo 
. 
x(t) = -
X(jw)e1w1dw. 
27T' 
-00 
What we would like to know is when eq. (4.8) is valid [i.e., when is x(t) a valid represen-
tation of the original signal x(t)?]. If x(t) has finite energy, i.e., if it is square integrable, 
so that 
(4.11) 
then we are guaranteed that X(jw) is finite [i.e., eq. (4.9) converges] and that, with e(t) 
denoting the error between x(t) and x(t) [i.e., e(t) = x(t) - x(t)], 
1 For a mathematically rigorous discussion of the Fourier transform and its properties and applications, 
seeR. Bracewell, The Fourier Transform and Its Applications, 2nd ed. (New York: McGraw-Hill Book Com-
pany, 1986); A. Papoulis, The Fourier Integral and Its Applications (New York: McGraw-Hill Book Company, 
1987); E. C. Titchmarsh, Introduction to the Theory of Fourier Integrals (Oxford: Clarendon Press, 1948); and 
the book by Dym and McKean referenced in footnote 2 of Chapter 3. 

290 
The Continuous-Time Fourier Transform 
Chap.4 
I 
+ oo 
-oo je(t)j2dt = 0. 
(4.12) 
Equations (4.11) and (4.12) are the aperiodic counterparts of eqs. (3.51) and (3.54) for 
periodic signals. Thus, in a manner similar to that for periodic signals, if x(t) has finite 
energy, then, although x(t) and its Fourier representation .X(t) may differ significantly at 
individual values oft, there i~ no energy in their difference. 
Just as with periodic signals, there is an alternative set of conditions which are suffi-
cient to ensure that i(t) is equal to x(t) for any t except at a discontinuity, where it is equal 
to the average of the values on either side of the discontinuity. These conditions, again 
referred to as the Dirichlet conditions, require that: 
1. x(t) be absolutely integrable; that is, 
I 
+ oo 
- oo jx(t)jdt < oo. 
(4.13) 
2. x(t) have a finite number of maxima and minima within any finite interval. 
3. x(t) have a finite number of discontinuities within any finite interval. Futhermore, 
each of these discontinuities must be finite. 
Therefore, absolutely integrable signals that are continuous or that have a finite number of 
discontinuities have Fourier transforms. 
Although the two alternative sets of conditions that we have given are sufficient to 
guarantee that a signal has a Fourier transform," we will see in the next section that peri-
odic signals, which are neither absolutely integrable nor square integrable over an infinite 
interval, can be considered to have Fourier transforms if impulse functions are permitted 
in the transform. This has the advantage that the Fourier series and Fourier transform can 
be incorporated into a common framework, which we will find to be very convenient in 
subsequent chapters. Before examining the point further in Section 4.2, however, let us 
consider several examples of the Fourier transform. 
4.1.3 Examples of Continuous-Time Fourier Transforms 
Example 4.1 
Consider the signal 
x(t) = e- at u(t) 
a > 0. 
From eq. (4.9), 
X(jw) = 
{ "' e- ate- jwtdt = - -~-.- e-<a+jw)tl "' · 
Jo 
a+ JW 
o 
That is, 
X(jw) = -
1-.- , 
a > 0. 
a+ JW 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
291 
Since this Fourier transform is complex valued, to plot it as a function of w, we express 
X(jw) in terms of its magnitude and phase: 
· 
IX(jw)l = J 
1 
, 
4:-X(jw) = - tan- 1 (~a)· 
a 2 + w2 
Each of these components is sketched in Figure 4.5. 
Note that if a is complex rather than real, then x(t) is absolutely integrable as long 
as <Re{a} > 0, and in this case the preceding calculation yields the same form for X(jw ). 
That is, 
X(jw) = -
1- .-, (Re{a} > 0. 
a+ JW 
IX(jw)l 
1/a 
- a 
a 
(a) 
<l::X(jw) 
(b) 
w 
Figure 4.5 
Fourier transform of the signal x(t) = e- at u(t), a> 0, consid-
ered in Example 4.1. 
Example 4.2 
Let 
x(t) = e - altl, 
a> 0. 

292 
The Continuous-Time Fourier Transform 
This signal is sketched in Figure 4.6. The Fourier transform of the signal is 
1 
1 
= - - - + ---
a - jw 
a + jw 
2a 
-
a2 + w2. 
In this case X(jw) is real, and it is illustrated in Figure 4.7. 
x(t) 
Figure 4.6 
Signal x(t) = e- ~ t l of Example 4.2. 
-a 
X Ow) 
2/a 
a 
w 
Figure 4.7 
Fourier transform of the signal considered in Example 4.2 and 
depicted in Figure 4.6. 
Example 4.3 
Now let us determine the Fourier transform of the unit impulse 
x(t) = 8(t). 
Substituting into eq. (4.9) yields 
f
+"" 
X(jw) = 
_, 8(t)e- Jwtdt = 1. 
Chap.4 
(4.14) 
(4.15) 
That is, the unit impulse has a Fourier transform consisting of equal contributions at all 
frequencies. 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
Example 4.4 
Consider the rectangular pulse signal 
{ 
1 ltl < T1 
x(t) = o: ltl > T1 ' 
293 
(4.16) 
as shown in Figure 4.8(a). Applying eq. (4.9), we find that tlie Fourier transform of this 
signal is 
X( . ) -
- Jwt d - 2 sm w 
1 
I
T, 
. 
T 
JW -
e 
t -
-
-
- , 
- T 1 
W 
as sketched in Figure 4.8(b ). 
x(t) 
Ill 
- T1 
T 1 
(a) 
X(jw) 
Figure 4.8 
(a) The rectangular pulse signal of Example 4.4 and (b) its 
Fourier transform. 
(4.17) 
As we discussed at the beginning of this section, the signal given by eq. (4.16) can be 
thought of as the limiting form of a periodic square wave as the period becomes arbitrarily 
large. Therefore, we might expect that the convergence of the synthesis equation for this 
signal would behave in a manner similar to that observed in Example 3.5 for the square 
wave. This is, in fact, the case. Specifically, consider the inverse Fourier transform for the 
rectangular pulse signal: 
A()_ 1 f +oo 2sinwT, jwtd 
x t -
-
e 
w. 
27T' 
-
00 
w 
Then, since x(t) is square integrable, 

294 
The Continuous-Time Fourier Transform 
Chap.4 
I 
+oo 
- co lx(t) - .X(t)l2 dt = 0. 
Furthermore, because x(t) satisfies the Dirichlet conditions, .X(t) = x(t), except at the 
points of discontinuity, t = ±T1, where x(t) converges to 112, which is the average of 
the values of x(t) on both sides of the discontinuity. In addition, the convergence of x(t) 
to x(t) exhibits the Gibbs phenomenon, much as was illustrated for the periodic square 
wave in Figure 3.9. Specifically, in analogy with the finite Fourier series approximation, 
eq. (3.47), consider the following integral over a finite-length interval of frequencies: 
_1_ Iw 2sinwT, eiwt dw. 
27T - w 
w 
As W ~ oo, this signal converges to x(t) everywhere, except at the discontinuities. More-
over, the signal exhibits ripples near the discontinuities. The peak amplitude of these rip-
ples does not decrease as W increases, although the ripples do become compressed toward 
the discontinuity, and the energy in the ripples converges to zero. 
Example 4.5 
Consider the signal x(t) whose Fourier transform is 
X( 'w) = { 1, 
lwl < W. 
1 
0, 
lwl > W 
(4.18) 
This transform is illustrated in Figure 4.9(a). Using the synthesis equation (4.8), we can 
X(jw) 
1'i1 
-w 
w 
w 
(a) 
x(t) 
--rr/W 
-rr/W 
(b) 
Figure 4.9 
Fourier transform pair of Example 4.5: (a) Fourier transform for 
Example 4.5 and (b) the corresponding time function. 

Sec. 4.1 
Representation of Aperiodic Signals: The Continuous-Time Fourier Transform 
295 
then determine 
( ) _ 
1 f w jwtd 
_ sin W t 
xt --
e 
w---
27T - w 
7Tt 
' 
(4.19) 
which is depicted in Figure 4.9(b). 
Comparing Figures 4.8 and 4.9 or, equivalently, eqs. (4.16) and (4.17) with eqs. 
(4.18) and (4.19), we see an interesting relationship. In each case, the Fourier transform 
pair consists of a function of the form (sin aO)fb() and a rectangular pulse. However, in 
Example 4.4, it is the signal x(t) that is a pulse, while in Example 4.5, it is the transfonn 
X(jw ). The special relationship that is apparent here is a direct consequence of the duality 
property for Fourier transforms, which we discuss in detail in Section 4.3.6. 
Functions of the form given in eqs. ( 4.17) and ( 4.19) arise frequently in Fourier 
analysis and in the study of LTI systems and are referred to as sine functions. A commonly 
used precise form for the sine function is 
. (()) 
sin 7TO 
smc 
= --;:o· 
(4.20) 
The sine function is plotted in Figure 4.10. Both of the signals in eqs. (4.17) and (4.19) 
can be expressed in terms of the sine function: 
2sinwTt 
2T 
. 
(wTt) 
---
= 
tSinC --
W 
7T 
sin Wt = W 
sine (Wt)· 
7Tt 
7T 
7T 
sinc(e) 
Figure 4. 1 o The sine function. 
Finally, we can gain insight into one other property of the Fourier transform by 
examining Figure 4.9, which we have redrawn as Figure 4.11 for several different values 
of W. From this figure, we see that as W increases, X(jw) becomes broader, while the 
main peak of x(t) at t = 0 becomes higher and the width of the first lobe of this sig-
nal (i.e., the part of the signal for Jtl < 7TIW) becomes narrower. In fact, in the limit as 
W ~ oo, X(jw) = 1 for all w, and consequently, from Example 4.3, we see that x(t) in 
eq. (4.19) converges to an impulse as W ~ oo. The behavior depicted in Figure 4.11 is 
an example of the inverse relationship that exists between the time and frequency domains, 

296 
The Continuous-Time Fourier Transform 
Chap.4 
X1(jw) 
X2(jw) 
'I 
I 'I I 
-w, 
w, 
w 
-w2 
w2 
w 
(a) 
(b) 
X3(jw) 
rn 
-w3 
w3 
w 
(c) 
Figure 4. 11 
Fourier transform pair of Figure 4.9 for several different values of W. 
and we can see a similar effect in Figure 4.8, where an increase in T1 broadens x(t) but 
makes X(jw) narrower. In Section 4.3.5, we provide an explanation of this behavior in the 
context of the scaling property of the Fourier transform. 
4.2 THE FOURIER TRANSFORM FOR PERIODIC SIGNALS 
In the preceding section, we introduced the Fourier transform representation and gave 
several examples. While our attention in that section was focused on aperiodic signals, we 
can also develop Fourier transform representations for periodic signals, thus allowing us to 

Sec. 4.2 
The Fourier Transform for Periodic Signals 
297 
consider both periodic and aperiodic signals within a unified context. In fact, as we will see, 
we can construct the Fourier transform of a periodic signal directly from its Fourier series 
representation. The resulting transform consists of a train of impulses in the frequency 
domain, with the areas of the impulses proportional to the Fourier series coefficients. This 
will tum out to be a very useful representation. 
To suggest the general result, let us consider a signal x(t) with Fourier transform 
X(jw) that is a single impulse of area 27T at w = w 0 ; that is, 
X(jw) = 27To(w - wo). 
(4.21) 
To determine the signal x(t) for which this is the Fourier transform, we can apply the 
inverse transform relation, eq. (4.8), to obtain 
1 I 
+ oo 
x(t) = -2 
27To(w - w 0)ejwr dw 
7T 
-oo 
More generally, if X(jw) is of the form of a linear combination of impulses equally spaced 
in frequency, that is, 
+ oo 
X(jw) = 2 27Tako(w -
kwo), 
(4.22) 
k = - oo 
then the application of eq. (4.8) yields 
+ oo 
x(t) = ~ 
akejkwor. 
(4.23) 
k = - oo 
We see that eq. ( 4.23) corresponds exactly to the Fourier series representation of aperiodic 
signal, as specified by eq. (3.38). Thus, the Fourier transform of a periodic signal with 
Fourier series coefficients {ak} can be interpreted as a train of impulses occurring at the 
harmonically related frequencies and for which the area of the impulse at the kth harmonic 
frequency kwo is 27T times the kth Fourier series coefficient ak. 
Example 4.6 
Consider again the square wave illustrated in Figure 4.1. The Fourier series coefficients 
' · for this signal are 
and the Fourier transform of the signal is 
X(jw) = f 2 sin ~woTl S(w - kwo), 
k = - 00 

298 
The Continuous-Time Fourier Transform 
Chap. 4 
which is sketched in Figure 4.12 forT = 4T1• In comparison with Figure 3.7(a), the 
only differences are a proportionality factor of 271" and the use of impulses rather than a 
bar graph. 
I 
/ 
XQw) 
'' 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
2 I 
I 2 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
,' - wo 
I 
\ 
\ 
' 
Figure 4.12 
Fourier-transform of a symmetric periodic square wave. 
Example 4.7 
Let 
x(t) = sin w 0t. 
The Fourier series coefficients for this signal are 
2j' 
k ~ 1 
or 
-1. 
Thus, the Fourier transform is as shown in Figure 4.13(a). Similarly, for 
x(t) = cos w0t, 
the Fourier series coefficients are 
k ~ 1 or 
-1. 
The Fourier transform of this signal is depicted in Figure 4.13(b ). These two transforms 
will be of considerable importance when we analyze sinusoidal modulation systems in 
Chapter 8. 

Sec. 4.2 
The Fourier Transform for Periodic Signals 
299 
X Owl 
'IT/j 
0 
w 
(a) 
X Ow) 
t 
I 
'IT 
'IT 
t 
0 
w 
(b) 
Figure 4.13 
Fourier transforms of (a) x(t) = sin wot; (b) x(t) = cos wot. 
Example 4.8 
A signal that we will find extremely useful in our analysis of sampling systems in Chap-
ter 7 is the impulse train 
+ oo 
x(t) = L ll(t- kT), 
k =-00 
which is periodic with period T, as indicated in Figure 4.14(a). The Fourier series coef-
ficients for this signal were computed in Example 3.8 and are given by 
1 I 
+T/2 
. 
1 
ak = -
B(t)e- 1""'o' dt = -. 
T - rn 
T 
That is, every Fourier coefficient of the periodic impulse train has the same value, liT. 
Substituting this value for akin eq. (4.22) yields 
X(jw) = 2; k~oo ll(w- 2;k). 
Thus, the Fourier transform of a periodic impulse train in the time domain with pe-
riod Tis a periodic impulse train in the frequency domain with period 21TIT, as sketched 
in Figure 4.14(b ). Here again, we see an illustration of the inverse relationship between 
the time and the frequency domains. As the spacing between the impulses in the time 
domain (i.e., the period) gets longer, the spacing between the impulses in the frequency 
domain (namely, the fundamental frequency) gets smaller. 

300 
The Continuous-Time Fourier Transform 
Chap.4 
x(t) 
... 1 1 'i 1 1 
-2T 
-T 
0 
T 
2T 
(a) 
X(jw) 
... 1 1 
'T t 
1 1 
4'1T 
2'1T 
0 
2'1T 
4'1T 
w 
- T 
- T 
T 
T 
(b) 
Figure 4.14 
(a) Periodic impulse train; (b) its Fourier transform. 
4.3 PROPERTIES OF THE CONTINUOUS-TIME FOURIER TRANSFORM 
In this and the following two sections, we consider a number of properties of the Fourier 
transform. A detailed listing of these properties is given in Table 4.1 in Section 4.6. As was 
the case for the Fourier series representation of periodic signals, these properties provide 
us with a significant amount of insight into the transform and into the relationship between 
the time-domain and frequency-domain descriptions of a signal. In addition, many of the 
properties are often useful in reducing the complexity of the evaluation of Fourier trans-
forms or inverse transforms. Furthermore, as described in the preceding section, there is 
a close relationship between the Fourier series and Fourier transform representations of a 
periodic signal, and using this relationship, we can translate many of the Fourier transform 
properties into corresponding Fourier series properties, which we discussed independently 
in Chapter 3. (See, in particular, Section 3.5 and Table 3.1.) 
Throughout the discussion in this section, we will be referring frequently to functions 
of time and their Fourier transforms, and we will find it convenient to use a shorthand 
notation to indicate the pairing of a signal and its transform. As developed in Section 4.1, 
a signal x(t) and its Fourier transform X(jw) are related by the Fourier transform synthesis 
and analysis equations, 
[eq. (4.8)] 
1 I 
+ co 
. 
x(t) = -2 
X(jw)e1"' 1dw 
7T 
- co 
(4.24) 
and 
[eq. (4.9)] 
I 
+ oo 
X(jw) = 
-co x(t)e- Jwtdt. 
(4.25) 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
301 
We will sometimes find it convenient to refer to X(jw) with the notation 5{x(t)} and 
to x(t) with the notation 5 - 1{X(jw )}. We will also refer to x(t) and X(jw) as a Fourier 
transform pair with the notation 
g: 
x(t) ~ 
X(jw ). 
Thus, with reference to Example 4.1, 
and 
4.3. 1 Linearity 
If 
and 
then 
1 
---,---- = 5{e-ar u(t)}, 
a+ jw 
e- aru(t) = 5- t { -
1-.-}, 
a+ JW 
g: 
1 
e-aru(t) ~ --.- . 
a+ JW 
g: 
x(t) ~ 
X(jw) 
g: 
y(t) ~ 
Y(jw), 
g: 
ax(t) + by(t) ~ 
aX(jw) + bY(jw). 
(4.26) 
The proof of eq. (4.26) follows directly by application of the analysis eq. (4.25) to ax(t) + 
by(t). The linearity property is easily extended to a linear combination of an arbitrary 
number of signals. 
4.3.2 Time Shifting 
If 
then 
g: 
x(t) ~ 
X(jw ), 
(4.27) 

302 
The Continuous-Time Fourier Transform 
Chap.4 
To establish this property, consider eq. (4.24): 
x(t) = -
X(jw)e1w1dw. 
1 f oo 
. 
27T 
- oo 
Replacing t by t - to in this equation, we obtain 
Recognizing this as the synthesis equation for x(t - t0), we conclude that 
~{x(t- to)}= e-jw10X(jw). 
One consequence of the time-shift property is that a signal which is shifted in time 
does not have the magnitude of its Fourier transform altered. That is, if we express X(jw) 
in polar form as 
~{x(t)} = X(jw) = jX(jw )jej<l':X(jw), 
then 
~{x(t- to)}= e- jw 10X(jw) = jX(jw)jekl:X(}w)- wtol. 
Thus, the effect of a time shift on a signal is to introduce into its transform a phase shift, 
namely, -wt0 , which is a linear function of w. 
Example 4.9 
To illustrate the usefulness of the Fourier transform linearity and time-shift proper-
ties, let us consider the evaluation of the Fourier transform of the signal x(t) showri in 
, Figure 4.15(a). 
First, we observe that x(t) can be expressed as the linear combination 
1 
x(t) = 2 
XJ (t - 2.5) + x2(t - 2.5), 
where the signals x 1 (t) and x2(t) are the rectangular pulse signals shown in Figure 
4.15(b) and (c). Then, using the result from Example 4.4, we obtain 
X ( . ) _ 2sin(w/2) 
d X ( . ) _ 2sin(3w/2) 
I )W -
an 
2 }W -
. 
w 
w 
Finally, using the linearity and time-shift properties of the Fourier transform yields 
X(jw) = e- jSw/2 { sin(w/2) +~sin(3w/2)}. 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
2 
3 
4 
(a) 
x1(t) m 
_, 
1 
2 
2 
(b) 
1 x2(t) 
I 
I I 
-1. 
3 
2 
2 
(c) 
Figure 4. 15 
Decomposing a signal into the linear combination of two sim-
pler signals. (a) The signal x(t) for Example 4.9; (b) and (c) the two compo-
nent signals used to represent x(t). 
4.3.3 Conjugation and Conjugate Symmetry 
The conjugation property states that if 
~ 
x(t) ~ 
X(jw ), 
then 
~ 
303 
x*(t) ~X*(- jw). 
(4.28) 
This property follows from the evaluation of the complex conjugate of eq. (4.25): 
X'(jw) ~ [[ x(t)e-j•< dtJ 
f 
+ co 
= 
- co x*(t)ejwt dt. 
Replacing w by -w, we see that 
f 
+ co 
X*(- jw) = 
- co x*(t)e- jwt dt. 
(4.29) 

304 
The Continuous-Time Fourier Transform 
Chap.4 
Recognizing that the right-hand side of eq. ( 4.29) is the Fourier transform analysis equation 
for x*(t), we obtain the relation given in eq. (4.28). 
The conjugation property allows us to show that if x(t) is real, then X(jw) has con-
jugate symmetry; that is, 
I X(- jw) = X*(jw) 
[x(t) re~]. I 
Specifically, if x(t) is real so that x*(t) = x(t), we have, from eq. (4.29), 
I 
+ oo 
X*(- jw) = 
- oo x(t)ejwt dt = X(jw ), 
and eq. (4.30) follows by replacing w with -w. 
and 
From Example 4.1, with x(t) = e- a1u(t), 
X(jw) = 
1 . 
a+ JW 
1 
X(- jw) = 
= X*(jw). 
a- jw 
(4.30) 
As one consequence of eq. (4.30), if we express X(jw) in rectangular form as 
X(jw) = (Jl.e{X(jw )} + jdm{X(jw )}, 
then if x(t) is real, 
<Re{X(jw )} = <R.e{X(- jw )} 
and 
dm{X(jw )} = -dm{X(- jw )}. 
That is, the real part of the Fourier transform is an even function of frequency, and the 
imaginary part is an odd function of frequency. Similarly, if we express X(jw) in polar 
form as 
X(jw) = jX(jw )jej<l:X(jw), 
then it follows from eq. (4.30) that jX(jw )j is an even function of w and <tX(jw) is an 
odd function of w. Thus, when computing or displaying the Fourier transform ·of a real-
valued signal, the real and imaginirry parts or magnitude and phase of the transform need 
only be specified for positive frequencies, as the values for negative frequencies can be 
determined directly from the values for w > 0 using the relationships just derived. 
As a further consequence of eq. (4.30), if x(t) is both real and even, then X(jw) will 
also be real and even. To see this, we write 
I 
+ oo 
X(- jw) = 
- oo x(t)ejwt dt, 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
305 
or, with the substitution T = -t, 
I 
+ oo 
X( - jw) = 
- oo x(-r)e - jwTdr. 
Since x(-r) = x(r), we have 
I 
+oo 
X(- jw) = 
- oo x(r)e- jwtdT 
= X(jw). 
Thus, X(jw) is an even function. This, together with eq. (4.30), also requires that 
X*(jw) = X(jw) [i.e., that X(jw) is real]. Example 4.2 illustrates this property for the 
real, even signal e- altl . In a similar manner, it can be shown that if x(t) is a real and odd 
function oftime, so that x(t) = - x(- t), then X(jw) is purely imaginary and odd. 
Finally, as was discussed in Chapter 1, a real function x(t) can always be expressed 
in terms of the sum of an even function Xe(t) = Sv{x(t)} and an odd function x 0 (t) = 
0d{x(t)}; that is, 
x(t) = Xe(t) + X0 (t). 
From the linearity of the Fourier transform, 
~{x(t)} = ~{xe (t)} + ~{x0 (t)}, 
and from the preceding discussion, ~{x e (t)} is a real function and ~{x0 (t)} is purely imag-
inary. Thus, we can conclude that, with x(t) real, 
g: 
x(t) ~ 
X(jw ), 
g: 
Sv{x(t)} ~ 
CRe{X(jw )}, 
g: 
0d{x(t)} ~ 
jffm{X(jw )}. 
One use of these symmetry properties is illustrated in the following example. 
Example 4. 1 0 
Consider again the Fourier transform evaluation of Example 4.2 for the signal x(t) = 
e - alrl, where a > 0. This time we will utilize the symmetry properties of the Fourier 
transform to aid the evaluation process. 
From Example 4.1, we have 
g: 
1 
e - aru(t) ~ 
-
- .-. 
a+ JW 
Note that for t > 0, x(t) equals e - ar u(t), while for t < 0, x(t) takes on mirror image 
values. That is, 

306 
The Continuous-Time Fourier Transform 
x(t) = e - altl = e- at u(t) + eat u(- t) 
= 2 [e - at u(t) ~ eat u(- t)] 
= 28v{e-at u(t)}. 
Chap.4 
Since e- at u(t) is real valued, the symmetry properties of the Fourier transform lead us 
to conclude that 
It follows that 
8v{e- atu(t)} ~ 
<Re{ - 1-.-}. 
a+ JW 
X(jw) = 2<Re{ - 1-.-} = ~. 
a+ JW 
a2 + w2 
which is the same as the answer found in Example 4.2. 
4.3.4 Differentiation and Integration 
Let x(t) be a signal with Fourier transform X(jw ). Then, by differentiating both sides of 
the Fourier transform synthesis equation ( 4.24 ), we obtain 
Therefore, 
dx(t) 
1 f +"' . X( . ) J'wtd 
-
-
= -
)W 
)W e 
W. 
dt 
21T 
- oo 
dx(t) 
~ 
. X( . ) 
----;]'! ~ 
JW 
JW . 
(4.31) 
This is a particularly important property, as it replaces the operation of differentiation in 
the time domain with that of multiplication by jw in the frequency domain. We will find 
the substitution to be extremely useful in our discussion in Section 4.7 on the use of Fourier 
transforms for the analysis of LTI systems described by differential equations. 
Since differentiation in the time domain corresponds to multiplication by jw in the 
frequency domain, one might conclude that integration should involve division by jw in 
the frequency domain. This is indeed the case, but it is only one part of the picture. The 
precise relationship is 
I
t 
~ 
1 
x(r)dr ~ 
-. X(jw) + 1rX(O)o(w). 
- oo 
JW 
(4.32) 
The impulse term on the right-hand side of eq. (4.32) reflects the de or average value that 
can result from integration. 
The use of eqs. (4.31) and (4.32) is illustrated in the next two examples. 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
307 
Example 4.11 
Let us detennine the Fourier transform X(jw) of the unit step x(t) = u(t), making use 
of eq. (4.32) and the knowledge that 
~ 
g(t) = 8(t) ~ 
G(jw) = 1. 
Noting that 
x(t) = r oo g(-r)d'T 
and taking the Fourier transform of both sides, we obtain 
X(jw) = G(_Jw) + 7TG(0)8(w ), 
JW 
where we have used the integration property listed in Table 4.1. Since G(jw) = 1, we 
conclude that 
X(jw) = _;.__ + 1T8(w ). 
)W 
(4.33) 
Observe that we can apply the differentiation property of eq. (4.31) to recover the 
transform of the impulse. That is, 
du(t) 
~ 
. [ 1 
] 
8(t) = -- ~ 
;w -:- + 1r8(w) 
= 1, 
dt 
JW 
where the last equality follows from the fact that w8(w) = 0. 
Example 4. 1 2 
Suppose that we wish to calculate the Fourier transform X(jw) for the signal x(t) dis-
played in Figure 4.16(a). Rather than applying the Fourier integral directly to x(t), we 
instead consider the signal 
d 
g(t) = dt x(t). 
x(t) 
-1 1f A 
t 
~ 
(a) 
g(t) = 
d~~t) 
(b) 
- 1 
-1 
Figure 4. 16 
(a) A signal x(t) for which the Fourier transform is to be eval-
uated; (b) representation of the derivative of x( t) as the sum of two components. 

308 
The Continuous-Time Fourier Transform 
Chap.4 
As illustrated in Figure 4.16(b), g(t) is the sum of a rectangular pulse and two impulses. 
The Fourier transforms of each of these component signals may be determined from 
Table4.2: 
G( . ) 
(2 sinw) 
1·w 
_ 1·w 
JW 
= -- -e -e 
. 
w 
Note that G(O) = 0. Using the integration property, we obtain 
. 
G(jw) 
X(Jw) = -. 
-
+ 7TG(0)8(w ). 
JW 
With G(O) = 0 this becomes 
X( . ) = 2sinw _ 2cosw 
)W 
. 
2 
. 
• 
JW 
JW 
The expression for X(jw) is purely imaginary and odd, which is consistent with the fact 
that x(t) is real and odd. 
4.3.5 Time and Frequency Scaling 
If 
~ 
x(t) ~ 
X(jw ), 
then 
~ 
1 (jw) 
x(at) ~ 
]QIX --;; , 
(4.34) 
where a is a nonzero real number. This property follows directly from the definition of 
the Fourier transform-specifically, 
I
+oo 
5"{x(at)} = 
-oo x(at)e-jwtdt. 
Using the substitution T = at, we obtain 
{ 
1 I 
+oo 
. 
-
x(r)e- J(wla)rdT, 
IT-"{x(at)} = 
a 
- oo 
1 I 
+ oo 
. 
--
x(r)e- J(wla)rdT, 
a 
-oo 
a>O 
a<O 
which corresponds to eq. (4.34). Thus, aside from the amplitude factor 1/jaj, a linear scal-
ing in time by a factor of a corresponds to a linear scaling in frequency by a factor of lla, 
and vice versa. Also, letting a = -1, we see from eq. (4.34) that 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
309 
I x( -t) ;!_._, X(- jw ).1 
(4.35) 
That is, reversing a signal in time also reverses its Fourier transform. 
A common illustration of eq. (4.34) is the effect on frequency content that results 
when an audiotape is recorded at one speed and played back at a different speed. If the 
playback speed is higher than the recording speed, corresponding to compression in time 
(i.e., a> 1), then the spectrum is expanded in frequency (i.e., the audible effect is that the 
playback frequencies are higher). Conversely, the signal played back will be scaled down 
in frequency if the playback speed is slower than the recording speed (0 < a < 1). For 
example, if a recording of the sound of a small bell ringing is played back at a reduced 
speed, the result will sound like the chiming of a larger and deeper sounding bell. 
The scaling property is another example of the inverse relationship between time 
and frequency that we have already encountered on several occasions. For example, we 
have seen that as we increase the period of a sinusoidal signal, we decrease its frequency. 
Also, as we saw in Example 4.5 (see Figure 4.11), if we consider the transform 
X(jw) = { 1, 
0, !w!<W 
!w!>W' 
then as we increase W, the inverse transform of X(jw) becomes narrower and taller and 
approaches an impulse as W ~ oo. Finally, in Example 4.8, we saw that the spacing in the 
frequency domain between impulses in the Fourier transform of a periodic impulse train 
is inversely proportional to the spacing in the time domain. 
The inverse relationship between the time and frequency domains is of great im-
portance in a variety of signal and systems contexts, including filtering and filter design, 
and we will encounter its consequences on numerous occasions in the remainder of the 
book. In addition, the reader may very well come across the implications of this property 
in studying a wide variety of other topics in science and engineering. One example is the 
uncertainty principle in physics; another is illustrated in Problem 4.49. 
4.3.6 Duality 
By comparing the transform and inverse transform relations given in eqs. ( 4.24) and ( 4.25), 
we observe that these equations are similar, but not quite identical, in form. This symmetry 
leads to a property of the Fourier transform referred to as duality. In Example 4.5, we 
alluded to duality when we noted the relationship that exists between the Fourier transform 
pairs of Examples 4.4 and 4.5. In the former example we derived the Fourier transform 
pair 
XJ(t) = { ~: 
while in the latter we considered the pair 
sin Wt 
~ 
. 
{ 1, 
x2(t) = -- ~ 
X2(jw) = 
0 
~t 
' 
!w!<W 
!w!>W' 
(4.36) 
(4.37) 

310 
The Continuous-Time Fourier Transform 
Chap.4 
x1(t) 
X1(jw) 
~ 
~ 
-T1 
T1 
x2(t) 
X2(jw) 
I 
1 
I 
-w 
w 
w 
Figure 4.17 
Relationship between the Fourier transform pairs of eqs. (4.36) 
and (4.37). 
The two Fourier transform pairs and the relationship between them are depicted in 
Figure 4.17. 
The symmetry exhibited by these two examples extends to Fourier transforms in 
general. Specifically, because of the symmetry between eqs. (4.24) and (4.25), for any 
transform pair, there is a dual pair with the time and frequency variables interchanged. 
This is best illustrated through an example. 
Example 4. 1 3 
Let us consider using duality to find the Fourier transform G(jw) of the signal 
2 
g(t) = 1 + t2 0 
In Example 4.2 we encountered a Fourier transform pair in which the Fourier transform, 
as a function of w, had a form similar to that of the signal x(t). Specifically, suppose we 
consider a signal x(t) whose Fourier transform is 
X(jw) = -1 
2 2' 
+w 
Then, from Example 4.2, 
x(t) = e-ltl ~ 
X(jw) = 1 } w2 • 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
311 
The synthesis equation for this Fourier transform pair is 
e-lrl = -
--z eJw'dw. 
1 J"' ( 2 
) . 
27T 
-00 1 + w 
Multiplying this equation by 27T and replacing t by -t, we obtain 
Now, interchanging the names of the variables t and w, we find that 
(4.38) 
The right-hand side of eq. ( 4.38) is the Fourier transform analysis equation for 2/(1 + t2), 
and thus, we conclude that 
The duality property can also be used to determine or to suggest other properties of 
Fourier transforms. Specifically, if there are characteristics of a function of time that have 
implications with regard to the Fourier transform, then the same characteristics associated 
with a function of frequency will have dual implications in the time domain. For example, 
in Section 4.3.4, we saw that differentiation in the time domain corresponds to multiplica-
tion by jw in the frequency domain. From the preceding discussion, we might then suspect 
that multiplication by jt in the time domain corresponds roughly to differentiation in the 
frequency domain. To determine the precise form of this dual property, we can proceed 
in a fashion exactly analogous to that used in Section 4.3.4. Thus, if we differentiate the 
analysis equation (4.25) with respect tow, we obtain 
dX(jw) I 
+ co 
dw 
= 
- co - jtx(t)e- jwtdt. 
(4.39) 
That is, 
. () 
:!' 
dX(jw) 
- JfX t ~ dw 
. 
(4.40) 
Similarly, we can derive the dual properties of eqs. (4.27) and (4.32): 
. 
:!' 
elwot x(t) ~ 
X(j(w - wo)) 
(4.41) 
and 
1 
:!' 
Jw 
--:-x(t) + 7TX(0)o(t) ~ X(7])d7]. 
]f 
-co 
(4.42) 

312 
The Continuous-Time Fourier Transform 
Chap.4 
4.3.7 Parseval's Relation 
If x(t) and X(jw) are a Fourier transform pair, then 
(4.43) 
This expression, referred to as Parseval's relation, follows from direct application of the 
Fourier transform. Specifically, 
f 
+oo 
f 
+oo 
- oo lx(t)l2dt = 
- oo x(t)x*(t)dt 
f 
+
00 
[ 1 f +
00 
• l 
= 
-oo x(t) 2
'TT 
- oo X*(jw)e-1w
1dw dt. 
Reversing the order of integration gives 
f 
+ oo 
1 f 
+ oo 
[J +oo 
. l 
-oo lx(t)l2dt = 2'TT 
- oo X*(jw) 
- oo x(t)e- ]WI dt dw. 
The bracketed term is simply the Fourier transform of x(t); thus, 
The term on the left-hand side of eq. (4.43) is the total energy in the signal x(t). 
Parseval's relation says that this total energy may be determined either by computing the 
energy per unit time (lx(t)i2) and integrating over all time or by computing the energy per 
unit frequency (IX(Jw )I2/2TT) and integrating over all frequencies. For this reason, IX(jw )12 
is often referred to as the energy-density spectrum of the signal x(t). (See also Problem 
4.45.) Note that .Parseval's relation for finite-energy signals is the direct counterpart of 
Parseval's relation for periodic signals (eq. 3.67), which states that the average power of 
a periodic signal equals the sum of the average powers of its individual harmonic compo-
nents, which in tum are equal to the squared magnitudes of the Fourier series coefficients. 
Parseval's relation and other Fourier transform properties are often useful in deter-
mining some time domain characteristics of a signal directly from the Fourier transform. 
The next example is a simple illustration of this. 
Example 4. 14 
For each of the Fourier transforms shown in Figure 4.18, we wish to evaluate the follow-
ing time-domain expressions: 
E = f_", ix(t)l2dt 
D = !!.._x(t)l 
dt 
t=O 

Sec. 4.3 
Properties of the Continuous-Time Fourier Transform 
313 
X(jw) 
- 1 
-0.5 
0 
0.5 
w 
(a) 
X(jw) 
jfiT 
- 1 
0 
w 
.__ ___ -f-j fiT 
(b) 
Figure 4. 18 
The Fourier transforms considered in Example 4.14. 
To evaluate E in the frequency domain, we may use Parseval's relation. That is, 
(4.44) 
which evaluates to ~ for Figure 4.18(a) and to 1 for Figure 4.18(b). 
To evaluate D in the frequency domain, we first use the differentiation property to 
observe that 
g(t) = :t x(t) ~ 
jwX(jw) = G(jw ). 
Noting that 
If" 
D = g(O) = -
G(jw)dw 
27T -" 
we conclude: 
D = r oo jwX(jw) dw 
which evaluates to zero for figure 4.18(a) and to 
- ~ for Figure 4.18(b). 
(2 .. rrr) 
(4.45) 
(4.46) 
There are many other properties of the Fourier transform in addition to those we have 
already discussed. In the next two sections, we present two specific properties that play 

314 
The Continuous-Time Fourier Transform 
Chap. 4 
particularly central roles in the study of LTI systems and their applications. The first of 
these, discussed in Section 4.4, is referred to as the convolution property, which is central 
to many signals and systems applications, including filtering. The second, discussed in 
Section 4.5, is referred to as the multiplication property, and it provides the foundation 
for our discussion of sampling in Chapter 7 and amplitude modulation in Chapter 8. In 
Section 4.6, we summarize the properties of the Fourier transform. 
4.4 THE CONVOLUTION PROPERTY 
As we saw in Chapter 3, if a periodic signal is represented in a Fourier series-i.e., as 
a linear combination of harmonically related complex exponentials, as in eq. (3.38)-
then the response of an LTI system to this input can also be represented by a Fourier 
series. Because complex exponentials are eigenfunctions ofLTI systems, the Fourier series 
coefficients of the output are those of the input multiplied by the frequency response of 
the system evaluated at the corresponding harmonic frequencies. 
In this section, we extend this result to the situation in which the signals are aperiodic. 
We first derive the property somewhat informally, to build on the intuition we developed for 
periodic signals in Chapter 3, and then provide a brief, formal derivation starting directly 
from the convolution integral. 
Recall our interpretation of the Fourier transform synthesis equation as an expression 
for x(t) as a linear combination of complex exponentials. Specifically, referring back to 
eq. (4.7), x(t) is expressed as the limit of a sum; that is, 
1 f 
+oo 
. 
1 
+oo 
. 
x(t) = -
X(jw)e 1w1dw = lim -
L X(jkwo)e1kwotwo. 
27T 
-oo 
wo--+0 27T k= _00 
(4.47) 
As developed in Sections 3.2 and 3.8, the response of a linear system with impulse response 
h(t) to a complex exponential ejkwot is H(j kw0)ejkwot, where 
f 
+oo 
H(jkwo) = - oo h(t)e-jkw01dt. 
(4.48) 
We can recognize the frequency response H(jw ), as defined in eq. (3.121), as the Fourier 
transform of the system impulse response. In other words, the Fourier transform of the 
impulse response (evaluated at w = kw0) is the complex scaling factor that the LTI system 
applies to the eigenfunction ejkwor. From superposition [see eq. (3.124)], we then have 
1 
+oo 
. 
1 
+ oo 
. 
27T L X(jkwo)eJkwotCJ'o ~ 
27T L X(jkwo)H(jkwo)eJkwotwo, 
k=- oo 
k=- oo 
and thus, from eq. (4.47), the response of the linear system to x(t) is 
y(t) = lim -2
1 f X(jkwo)H(jkwo)ejkwo1wo 
wo--+0 
7T k= -oo 
1 f 
+oo 
. 
= -
X(jw)H(jw)elw 1dw. 
27T 
-
00 
(4.49) 

Sec. 4.4 
The Convolution Property 
315 
Since y(t) and its Fourier transform Y(jw) are related by 
} f 
+ co 
. 
y(t) = -
Y(jw )e1wr dw, 
27T 
-co 
(4.50) 
we can identify Y(jw) from eq. (4.49), yielding 
Y(jw) = X(jw)H(jw). 
(4.51) 
As a more formal derivation, we consider the convolution integral 
f 
+co 
y(t) = 
-co x(r)h(t- r)dT. 
(4.52) 
We desire Y(jw ), which is 
Y(jw) = g:{y(t)} = L+: [L+ooco x(r)h(t-r)dr]e- Jwtdt. 
(4.53) 
Interchanging the order of integration and noting that x( T) does not depend on t, we have 
(4.54) 
By the time-shift property, eq. (4.27), the bracketed term is e-Jwr H(jw ). Substituting this 
into eq. (4.54) yields 
f 
+co 
f 
+co 
Y(jw) = 
-oo x(r)e- JwrH(jw)dT = H(jw) -oo x(r)e-JwrdT. 
(4.55) 
The integral is X(jw ), and hence, 
Y(jw) = H(jw)X(jw). 
That is, 
~ 
y(t) = h(t) * x(t) ~ 
Y(jw) = H(jw )X(jw ). 
(4.56) 
Equation ( 4.56) is of major importance in signal and system analysis. As expressed 
in this equation, the Fourier transform maps the convolution of two signals into the product 
of their Fourier transforms. H(jw ), the Fourier transform of the impulse response, is the 
frequency response as defined in eq. (3.121) and captures the change in complex amplitude 
of the Fourier transform of the input at each frequency w. For example, in frequency-
selective filtering we may want to have H(jw) = 1 over one range of frequencies, so that 
the frequency components in this band experience little or no attenuation or change due to 
the system, while over another range of frequencies we may want to have H(jw) = 0, so 
that components in this range are eliminated or significantly attenuated. 

316 
The Continuous-Time Fourier Transform 
Chap.4 
The frequency response H (jw) plays as important a role in the analysis of LTI sys-
tems as does its inverse transform, the unit impulse response. For one thing, since h(t) 
completely characterizes an LTI system, then so must H(jw). In addition, many of the 
properties of LTI systems can be conveniently interpreted in terms of H (jw ). For exam-
ple, in Section 2.3, we saw that the impulse response of the cascade of two LTI systems 
is the convolution of the impulse responses of the individual systems and that the over-
all impulse response does not depend on the order in which the systems are cascaded. 
Using eq. (4.56), we can rephrase this in terms of frequency responses. As illustrated in 
Figure 4.19, since the impulse response of the cascade of two LTI systems is the con-
volution of the individual impulse responses, the convolution property then implies that 
the overall frequency response of the cascade of two systems is simply the product of 
the individual frequency responses. From this observation, it is then clear that the overall 
frequency response does not depend on the order of the cascade. 
x(t) 
H1(jw) 
(a) 
x(t) 
~ IH1(jw)H2(jw)l 
(b) 
x(t) 
(c) 
y(t) 
~ y(t) 
y(t) 
Figure 4. 19 Three equivalent LTI 
systems. Here, each block represents 
an LTI system with the indicated 
frequency response. 
As discussed in Section 4.1.2, convergence of the Fourier transform is guaranteed 
only under certain conditions, and consequently, the frequency response cannot be defined 
for every LTI system. If, however, an LTI system is stable, then, as we saw in Section 2.3.7 
and Problem 2.49, its impulse response is absolutely integrable; that is, 
I 
+ oo 
- oo ih(t)idt < oo. 
(4.57) 
Equation (4.57) is one of the three Dirichlet conditions that together guarantee the exis-
tence of the Fourier transform H(jw) of h(t). Thus, assuming that h(t) satisfies the other 
two conditions, as essentially all signals of physical or practical significance do, we see 
that a stable LTI system has a frequency response H(jw ). 
In using Fourier analysis to study LTI systems, we will be restricting ourselves 
to systems whose impulse responses possess Fourier transforms. In order to use trans-
form techniques to examine unstable LTI systems we will develop a generalization of 

Sec. 4.4 
The Convolution Property 
317 
the continuous-time Fourier transform, the Laplace transform. We defer this discussion to 
Chapter 9, and until then we will consider the many problems and practical applications 
that we can analyze using the Fourier transform. 
4.4. 1 Examples 
To illustrate the convolution property and its applications further, let us consider several 
examples. 
Example 4. 1 5 
Consider a continuous-time LTI system with impulse response 
h(t) = B(t - t0). 
(4.58) 
The frequency response of this system is the Fourier transform of h(t) and is given by 
H(jw) = e- jwto. 
(4.59) 
Thus, for any input x(t) with Fourier transform X(jw ), the Fourier transform of the output 
is 
Y(jw) = H(jw)X(jw) 
= e- jwtoX(jw). 
(4.60) 
This result, in fact, is consistent with the time-shift property of Section 4.3.2. Specifi-
cally, a system for which the impulse response is B(t- to) applies a time shift of to to the 
input-that is, 
y(t) = x(t - to). 
Thus, the shifting property given in eq. (4.27) also yields eq. (4.60). Note that, either from 
our discussion in Section 4.3.2 or directly from eq. (4.59), the frequency response of a 
system that is a pure time shift has unity magnitude at all frequencies (i.e., ie- jwtol = 1) 
and has a phase characteristic - wt0 that is a linear function of w. 
Example 4. 16 
,_ As a second example, let us examine a differentiator-that is, an LTI system for which 
the input x(t) and the output y(t) are related by 
y(t) = d~;t). 
From the differentiation property of Section 4.3.4, 
Y(jw) = jwX(jw ). 
(4.61) 
Consequently, from eq. (4.56), it follows that the frequency response of a differentiator 
is 
H(jw) = jw. 
(4.62) 

318 
The Continuous-Time Fourier Transform 
Example 4. 1 7 
Consider an integrator-that is, an LTI system specified by the equation 
y(t) = L, 
x(r)dr. 
Chap.4 
The impulse response for this system is the unit step u(t), and therefore, from Exam-
ple 4.11 and eq. ( 4.33), the frequency response of the system is 
H(jw) = _;.,_ + 7TB(w ). 
JW 
Then using eq. (4.56), we have 
Y(jw) = H(jw)X(jw) 
= _;,_X(jw) + 7TX(jw)B(w) 
JW 
= _;_X(jw) + 7TX(O)B(w), 
JW 
which is consistent with the integration property of eq. (4.32). 
I 
Example 4. 18 
As we discussed in Section 3.9.2, frequency-selective filtering is accomplished with an 
LTI system whose frequency response H (jw) passes the desired range of frequencies and 
significantly attenuates frequencies outside that range. For example, consider the ideal 
lowpass filter introduced in Section 3.9.2, which has the frequency reponse illustrated in 
Figure 4.20 and given by 
H(jw) = { 1 lwl < we. 
0 lwl > W e 
(4.63) 
Now that we have developed the Fourier transform representation, we know that the 
impulse response h(t) of this ideal filter is the inverse transform of eq. (4.63). Using the 
result in Example 4.5, we then have 
h(t) = si~~ e t, 
(4.64) 
i which is plotted in Figure 4.21. 
H(jw) 
'I 
0 
-stopband--\- Passband ---t--stopband-
Figure 4.20 
Frequency response of an ideal lowpass filter. 

Sec. 4.4 
The Convolution Property 
319 
h(t) 
Figure 4.21 
Impulse response of an ideal lowpass filter. 
From Example 4.18, we can begin to see some of the issues that arise in filter design 
that involve looking in both the time and frequency domains. In particular, while the ideal 
lowpass filter does have perfect frequency selectivity, its impulse response has some char-
acteristics that may not be desirable. First, note that h(t) is not zero fort < 0. Consequently, 
the ideallowpass filter is not causal, and thus, in applications requiring causal systems, 
the ideal filter is not an option. Moreover, as we discuss in Chapter 6, even if causality 
is not an essential constraint, the ideal filter is not easy to approximate closely, and non-
ideal filters that are more easily implemented are typically preferred. Furthermore, in some 
applications (such as the automobile suspension system discussed in Section 6.7.1), oscil-
latory behavior in the impulse response of a lowpass filter may be undesirable. In such 
applications the time domain characteristics of the ideallowpass filter, as shown in Fig-
ure 4.21, may be unacceptable, implying that we may need to trade off frequency-domain 
characteristics such as ideal frequency selectivity with time-domain properties. 
For example, consider the LTI system with impulse response 
h(t) = e - r u(t). 
( 4.65) 
The frequency response of this system is 
H(jw) = -.- 1-
JW + 1 
(4.66) 
Comparing eqs. (3.145) and (4.66), we see that this system can be implemented with 
the simple RC circuit discussed in Section 3.10. The impulse response and the magnitude 
of the frequency response are shown in Figure 4.22. While the system does not have the 
strong frequency selectivity of the ideal lowpass filter, it is causal and has an impulse 
response that decays monotonically, i.e., without oscillations. This filter or somewhat more 
complex ones corresponding to higher order differential equations are quite frequently 
preferred to ideal filters because of their causality, ease of implementation, and flexibility 
in allowing trade-offs, among other design considerations such as frequency selectivity 
and oscillatory behavior in the time domain. Many of these issues will be discussed in 
more detail in Chapter 6. 
The convolution property is often useful in evaluating the convolution integral- i.e., 
in computing the response of LTI systems. This is illustrated in the next example. 

320 
The Continuous-Time Fourier Transform 
h(t) 
e 
(a) 
IH(iw)l 
- 1 
(b) 
Figure 4.22 
(a) Impulse response of the LTI system in eq. (4.65); 
(b) magnitude of the frequency response of the system. 
Example 4. 19 
Consider the response of an LTI system with impulse response 
h(t) = e- at u(t), 
a > 0, 
to the input signal 
x(t) = e- bt u(t), 
b > 0. 
Chap.4 
w 
Rather than computing y(t) = x(t) * h(t) directly, let us transform the problem into the 
frequency domain. From Example 4.1, the Fourier transforms of x(t) and h(t) are 
and 
Therefore, 
X(jw) = -
1- .-
b + JW 
H(jw) = -
1- .- . 
a+ JW 
(4.67) 
To determine the output y(t), we wish to obtain the inverse transform of Y(jw ). 
This is most simply done by expanding Y(jw) in a partial-fraction expansion. Such 
expansions are extremely useful in evaluating inverse transforms, and the general 
method for performing a partial-fraction expansion is developed in the appendix. For this 

Sec. 4.4 
The Convolution Property 
321 
example, assuming that b # a, the partial fraction expansion for Y(jw) takes the form 
Y(jw) = ~- + _B 
__ - , 
a+ JW 
b + JW 
(4.68) 
where A and B are constants to be determined. One way to find A and B is to equate the 
right-hand sides of eqs. (4.67) and ( 4.68), multiply both sides by (a + jw )(b + jw ), and 
solve for A and B. Alternatively, in the appendix we present a more general and efficient 
method for computing the coefficients in partial-fraction expansions such as eq. (4.68). 
Using either of these approaches, we find that 
and therefore, 
1 
A=--. = -B, 
b - a 
Y(jw) = _1_ [-1- __ 1_] 
b - a a + jw 
b + jw · 
(4.69) 
The inverse transform for each of the two terms in eq. (4.69) can be recognized 
by inspection. Using the linearity property of Section 4.3.1, we have 
1 
y(t) = --[e- a1u(t) - e- btu(t)]. 
b-a 
When b = a, the partial fraction expansion of eq. ( 4.69) is not valid. However, with 
b = a, eq. (4.67) becomes 
Recognizing this as 
Y(jw) = ( 
1
. )2" 
a+ JW 
. d [ 
1 
] 
(a + jw )2 = 1 dw a + jw ' 
1 
we can use the dual of the differentiation property, as given in eq. (4.40). Thus, 
:J 
1 
e- atu(t) ~ --.-
a+ JW 
- at ( ) 
:J 
. d [ 
1 
] 
te 
u t ~ 
J- --.-
= ..,-----,---,-;;-
dw a+ JW 
(a+ jw)2' 
and consequently, 
y(t) = te- at u(t). 
Example 4.20 
As another illustration of the usefulness of the convolution property, let us consider the 
problem of determining the response of an ideallowpass filter to an input signal x(t) that 
has the form of a sine function. That is, 
() 
sinw;t 
xt = --. 
7Tt 
Of course, the impulse response of the ideallowpass filter is of a similar form, namely, 

322 
The Continuous-Time Fourier Transform 
h(t) = sinwet. 
7Tt 
Chap.4 
The filter output y(t) will therefore be the convolution of two sine functions, which, as we 
now show, also turns out to be a sine function. A particularly convenient way of deriving 
this result is to first observe that 
where 
and 
Therefore, 
Y(jw) = X(jw)H(jw), 
X(jw) = { 01 
lwl ::s w; 
elsewhere 
H(jw) = { 01 
lwl ::s w;, 
elsewhere 
Y(jw) = { 1 lwl ::s wo , 
0 elsewhere 
where w0 is the smaller of the two numbers w; and W e. Finally, the inverse Fourier trans-
form of Y(jw) is given by 
{ 
sinwet 
"f 
--
1 We :S W; 
y(t) = 
. 7Tt 
smw;t 
.f 
-
-
1 W; :S W e 
7Tt 
That is, depending upon which of W e and w; is smaller, the output is equal to either x(t) 
or h(t). 
4.5 THE MULTIPLICATION PROPERTY 
The convolution property states that convolution in the time domain corresponds to mul-
tiplication in the frequency domain. Because of duality between the time and frequency 
domains, we would expect a dual property also to hold (i.e., that multiplication in the time 
domain corresponds to convolution in the frequency domain). Specifically, 
I f+x 
r(t) = s(t)p(t) ~ 
R(jw) = -
S(jO)P(j(w- O))dO 
. 
27T -X 
(4.70) 
This can be shown by exploiting duality as discussed in Section 4.3.6, together with the 
convolution property, or by directly using the Fourier transform relations in a manner anal-
ogous to the procedure used in deriving the convolution property. 
Multiplication of one signal by another can be thought of as using one signal to scale 
or modulate the amplitude of the other, and consequently, the multiplication of two sig-
nals is often referred to as amplitude modulation. For this reason, eq. (4.70) is sometimes 

Sec. 4.5 
The Multiplication Property 
323 
referred to as the modulation property. As we shall see in Chapters 7 and 8, this property 
has several very important applications. To illustrate eq. (4.70), and to suggest one of the 
applications that we will discuss in subsequent chapters, let us consider several examples. 
Example 4.21 
Let s(t) be a signal whose spectrum S(jw) is depicted in Figure 4.23(a). Also, consider 
the signal 
p(t) = cos wot. 
Then 
P(jw) = 7r5(w - w0 ) + 7r5(w + wo), 
as sketched in Figure 4.23(b), and the spectrum R(jw) of r(t) = s(t)p(t) is obtained by 
w 
(a) 
'IT 
PGw) 
1 
I 
1 
w 
(b) 
r0.tRfjw)=.:r·PO·IA . 
(-w0 - w1) 
(- w0 + w1) 
(w0 -
w1) 
(w0 + w1) 
(c) 
Figure 4.23 
Use of the multiplication property in Example 4.21: {a) the 
Fourier transform of a signal s{t); {b) the Fourier transform of p(t) = cos wot; 
{c) the Fourier transform of r(t) = s{t)p{t). 

324 
The Continuous-Time Fourier Transform 
Chap.4 
an application of eq. (4.70), yielding 
R(jw) = 2~ r 
.. ~(jO)P(j(w - O))dO 
= ~S(j(w - wo)) + ~S(j(w + wo)), 
(4.71) 
which is sketched in Figure 4.23(c). Here we have assumed that w0 > w1, so that the 
two nonzero portions of R(jw) do not overlap. Clearly, the spectrum of r(t) consists of 
the sum of two shifted and scaled versions of S(jw ). 
From eq. (4.71) and from Figure 4.23, we see that all of the information in the 
signal s(t) is preserved when we multiply this signal by a sinusoidal signal, although the 
information has been shifted to higher frequencies. This fact forms the basis for sinu-
soidal amplitude modulation systems for communications. In the next example, we learn 
how we can recover the original signal s(t) from the amplitude-modulated signal r(t). 
Example 4.22 
Let us now consider r(t) as obtained in Example 4.21, and let 
g(t) = r(t) p(t), 
where, again, p(t) = cosw0t. Then, R(jw), P(jw), and G(jw) are as shown in 
Figure 4.24. 
From Figure 4.24(c) and the linearity of the Fourier transform, we see that g(t) 
is the sum of(l/2)s(t) and a signal with a spectrum that is nonzero only at higherfrequen-
R(jw) 
& 
tN2 & 
- wo 
(a) 
wo 
w 
'IT 
P(jw) 
'IT 
1 
I 
1 
-wo 
(b) 
wo 
w 
G(jw) j( 
A/4 
~ 
A/4 
~ 
-2w0 
-w1 
w1 
(c) 
Figure 4.24 
Spectra of signals considered in Example 4.22: (a) R{jw ); 
(b) P(jw ); (c) G(jw ). 
w 

Sec. 4.5 
The Multiplication Property 
325 
cies (centered around ±2w0). Suppose then that we apply the signal g(t) as the input to 
a frequency-selective lowpass filter with frequency response H (jw) that is constant at 
low frequencies (say, for jwj < w 1) and zero at high frequencies (for jwj > w 1). Then 
the output of this system will have as its spectrum H (jw )G(jw ), which, because of the 
particular choice of H (jw ), will be a scaled replica of S(jw ). Therefore, the output itself 
will be a scaled version of s(t). In Chapter 8, we expand significantly on this idea as we 
develop in detail the fundamentals of amplitude modulation. 
Example 4.23 
Another illustration of the usefulness of the Fourier transform multiplication property is 
provided by the problem of determining the Fourier transform of the signal 
x(t) = sin(t) sin(t/2) 
7Tt2 
The key here is to recognize x(t) as the product of two sine functions: 
x(t) = 7T (sin(t) )(sin(t/2) ) · 
7Tt 
' 7Tt 
Applying the multiplication property of the Fourier transform, we obtain 
X(jw) = ~g: { sin(t) } * g: { sin(t/2)} . 
2 
7Tt 
7Tt 
Noting that the Fourier transform of each sine function is a rectangular pulse, we can 
proceed to convolve those pulses to obtain the function X(jw) displayed in Figure 4.25. 
vL, f•l ~ 
- 3 
- 1 
1 
3 
(I) 
2 
2 
2 
2 
Figure 4.25 
The Fourier transform of x(t) in Example 4.23. 
4.5.1 Frequency-Selective Filtering with Variable Center Frequency 
As suggested in Examples 4.21 and 4.22 and developed more fully in Chapter 8, one of the 
important applications of the multiplication property is amplitude modulation in commu-
nication systems. Another important application is in the implementation of frequency-
selective bandpass filters with tunable center frequencies that can be adjusted by the 
simple tum of a dial. In a frequency-selective bandpass filter built with elements such 
as resistors, operational amplifiers, and capacitors, the center frequency depends on a 
number of element values, all of which must be varied simultaneously in the correct way 
if the center frequency is to be adjusted directly. This is generally difficult and cumber-
some in comparison with building a filter whose characteristics are fixed. An alternative 
to directly varying the filter characteristics is to use a fixed frequency-selective filter and 

326 
The Continuous-Time Fourier Transform 
Chap. 4 
shift the spectrum of the signal appropriately, using the principles of sinusoidal amplitude 
modulation. 
For example, consider the system shown in Figure 4.26. Here, an input signal 
x(t) is multiplied by the complex exponential signal eiwct. The resulting signal is then 
passed through a lowpass filter with cutoff frequency w0 , and the output is multiplied by 
e- Jwct. The spectra of the signals x(t), y(t), w(t), and /(t) are illustrated in Figure 4.27. 
eiwct 
I 
y(t) 
x(t) --.... 11~0)----.... ll~l 
Ideal lowpass 
filter 
H(jw) 
'I 
w(t) 
...,_ __ 
~
X ~-~f(t) 
Figure 4.26 
Implementation of a bandpass filter using amplitude modula-
tion with a complex exponential carrier. 
X(jw) 
~ 
Y(jw) 
Frequency response of 
1--
ideal lowpass filter ~ 
I 
I 
W(jw) 
M 
F(jw) 
(I) 
(I) 
(I) 
w 
Figure 4.27 
Spectra of the signals 
in the system of Figure 4.26. 

Sec. 4.5 
The Multiplication Property 
327 
Specifically, from either the multiplication property or the frequency-shifting property it 
follows that the Fourier transform of y(t) = e jwct x(t) is 
J
+ oc 
Y(jw) = _,. 8(9 - wc)X(w -
(J)d(J 
' 
so that Y(jw) equals X(jw) shifted to the right by w e and frequencies in X(jw) near 
w = We have been shifted into the passband of the lowpass filter. Similarly, the Fourier 
transform ofj(t) = e- jw,rw(t) is 
F(jw) = W(j(w+ we)), 
so that the Fourier transform ofF (jw) is W (jw) shifted to the left by We· From Figure 4.27, 
we observe that the overall system of Figure 4.26 is equivalent to an ideal bandpass fil-
ter with center frequency - we and bandwidth 2w0, as illustrated in Figure 4.28. As the 
frequency We of the complex exponential oscillator is varied, the center frequency of the 
bandpass filter varies. 
I I I T 
w 
Figure 4.28 
Bandpass filter equiva-
lent of Figure 4.26. 
In the system of Figure 4.26 with x(t) real, the signals y(t), w(t), and f(t) are all 
complex. If we retain only the real part of f(t), the resulting spectrum is that shown in 
Figure 4.29, and the equivalent bandpass filter passes bands of frequencies centered 
around We and -we. as indicated in Figure 4.30. Under certain conditions, it is also possi-
ble to use sinusoidal rather than complex exponential modulation to implement the system 
of the latter figure. This is explored further in Problem 4.46. 
w 
H(jw) 
I I tt I I I 
w 
Figure 4.29 
Spectrum of (Jl.e{f(t)} 
associated with Figure 4.26. 
Figure 4.30 
Equivalent bandpass 
filter for ffi-e{f{t)} in Figure 4.29. 

328 
The Continuous-Time Fourier Transform 
Chap.4 
4.6 TABLES OF FOURIER PROPERTIES AND OF BASIC FOURIER TRANSFORM PAIRS 
In the preceding sections and in the problems at the end of the chapter, we have consid-
ered some of the important properties of the Fourier transform. These are summarized in 
Table 4.1, in which we have also indicated the section of this chapter in which each prop-
erty has been discussed. 
In Table 4.2, we have assembled a list of many of the basic and important Fourier 
transform pairs. We will encounter many of these repeatedly as we apply the tools of 
TABLE 4. 1 
PROPERTIES OF THE FOURIER TRANSFORM 
Section 
Property 
x(t) 
y(t) 
Aperiodic signal 
X(jw) 
Y(jw) 
Fourier transform 
---- ------ - -- -------- --- ------- --- ---------- ----- ------ --- -
4.3.1 
Linearity 
ax(t) + by(t) 
aX(jw) + bY(jw) 
4.3.2 
Time Shifting 
x(t- to) 
e - jwto X(jw) 
4.3.6 
Frequency Shifting 
ei"'o' x(t) 
X(j(w - wo)) 
4.3.3 
Conjugation 
x' (t) 
X'(- jw) 
4.3.5 
Time Reversal 
x(-t) 
X(- jw) 
4.3.5 
Time and Frequency 
x(at) 
_!_xfw) 
Scaling 
JaJ 
a 
4.4 
Convolution 
x(t) * y(t) 
X(jw2XJjwl_ 
4.5 
Multiplication 
x(t)y(t) 
trr J 
+~X(jfJ)Y(j(w- 8))d8 
d 
-~ 
4.3.4 
Differentiation in Time 
dix(t) 
jwX(jw) 
4.3.4 
Integration 
L 
x(t)dt 
~X(jw) + ?TX(0)8(w) 
JW 
4.3.6 
Differentiation in 
tx(t) 
j :wX(jw) 
Frequency 
r(jw) " X'(-jw) 
<R-e{X(jw)} = <Roe{ X(- jw )} 
4.3.3 
Conjugate Symmetry 
x(t) real 
dm{X(jw)} = - dm{X(- jw)} 
for Real Signals 
jX(jw)J = jX(- jw)J 
<tX(jw) = - <tX(- jw) 
4.3.3 
Symmetry for Real and 
x(t) real and even 
X(jw) real and even 
Even Signals 
4.3.3 
Symmetry for Real and 
x(t) real and odd 
X(jw) purely imaginary and odd 
Odd Signals 
4.3.3 
Even-Odd Decompo-
x,(t) = &v{x(t)} 
[x(t) real] 
<Roe{ X (jw)} 
sition for Real Sig-
x 0 (t) = 0d{x(t)} 
[x(t) real] 
jdm{X(jw)} 
nals 
4.3.7 
Parseval's Relation for Aperiodic Signals 
f 
+ ~ 
I f 
+ ~ 
-~ Jx(t)j2dt = 21T 
-~ jX(jw)j
2dw 

Sec. 4.6 
Tables of Fourier Properties and of Basic Fourier Transform Pairs 
329 
TABLE 4.2 
BASIC FOURIER TRANSFORM PAIRS 
Signal 
+~ 
2.: akejkwol 
k - - oo 
COSWof 
sinwot 
x(t) = 1 
Periodic square wave · 
{ 
1, 
ltl < T1 
x(t) = 
0, 
T1 < ltl ~ I 
and 
x(t + T) = x(t) 
+ ~ 
2.: 8(t - nT) 
n= - oo 
x(t) { 1, ltl < T1 
0, 
ltl > T1 
sinWt 
'TI"t 
8(t) 
u(t) 
8(t- to) 
e-at u(t), <R.e{a} > 0 
te-•' u(t), <R.e{a} > 0 
Fourier transform 
+ ~ 
271" 2.: ak8(w - kwo) 
k= - <Xl 
7r[8(w - wo) + 8(w + wo)] 
~[8(w- w0 ) - 8(w + wo)] 
J 
27r8(w) 
a1 = 1 
Fourier series coefficients 
(if periodic) 
a* = 0, 
otherwise 
a1 = a - 1 = 
~ 
ak = 0, 
otherwise 
I 
al = - a - 1 = 2j 
ak = 0, 
otherwise 
ao = 1, 
ak = 0, k 'I' 0 
(this is the Fourier series representation for) 
\any choice of T > 0 
~ 2 sin kwoT1 "( 
k 
) 
woT1 
. 
(kwoT1 ) _ sin kwoT1 
L.... 
u w -
w0 . 
-
-
smc -
-
-
k~ 
k - -~ 
k 
71" 
71" 
.. 
2sinwTI 
w 
X(jw) = { 1. 
lwl < W 
0, lwi > W 
1 
-:- + 7r8(w) 
JW 
a+ jw 
(a+ jw)2 
1 
ak = T for all k 

330 
The Continuous-Time Fourier Transform 
Chap. 4 
Fourier analysis in our examination of signals and systems. All of the transform pairs, 
except for the last one in the table, have been considered in examples in the preceding 
sections. The last pair is considered in Problem 4.40. In addition, note that several of 
the signals in Table 4.2 are periodic, and for these we have also listed the corresponding 
Fourier series coefficients. 
4. 7 SYSTEMS CHARACTERIZED BY LINEAR CONSTANT -COEFFICIENT 
DIFFERENTIAL EQUATIONS 
As we have discussed on several occasions, a particularly important and useful class 
of continuous-time LTI systems is those for which the input and output satisfy a linear 
constant-coefficient differential equation of the form 
..f!:, 
dky(t) _ ~ 
b dkx(t) 
~ak -----
d k 
- ~ k-----d 
k . 
k=O 
t 
k=O 
t 
(4.72) 
In this section, we consider the question of determining the frequency response of 
such an LTI system. Throughout the discussion we will always assume that the 
frequency response of the system exists, i.e., that eq. (3.121) converges. 
There are two closely related ways in which to determine the frequency response 
H(jw) for an LTI system described by the differential equation (4.72). The first of these, 
which relies on the fact that complex exponential signals are eigenfunctions of LTI 
systems, was used in Section 3.10 in our analysis of several simple, nonideal filters. 
Specifically, if x(t) = ejwr, then the output must be y(t) = H (jw )ejwr . Substituting these 
expressions into the differential equation (4.72) and performing some algebra, we can 
then solve for H(jw ). In this section we use an alternative approach to arrive at the same 
answer, making use of the differentiation property, eq. ( 4.31 ), of Fourier transforms. 
Consider an LTI system characterized by eq. (4.72). From the convolution property, 
Y(jw) = H(jw)X(jw), 
or equivalently, 
. 
Y(jw) 
H(jw) = X(jw)' 
(4.73) 
where X(jw ), Y(jw ), and H(jw) are the Fourier transforms of the input x(t), output y(t), 
and impulse response h(t), respectively. Next, consider applying the Fourier transform to 
both sides of eq. (4.72) to obtain 
(4.74) 
From the linearity property, eq. (4.26), this becomes 
..f!:, g:[ dky(t)j = ~ 
b g:[ dkx(t)j 
~ 
ak 
dtk 
~ k 
dtk 
' 
k=O 
k=O 
(4.75) 

Sec. 4.7 
Systems Characterized by Linear Constant-Coefficient Differential Equations 
331 
and from the differentiation property, eq. (4.31), 
N 
M 
2:_ ak(jw)kY(jw) = 2:_ bk(jw)kX(jw), 
k=O 
k=O 
or equivalently, 
Thus, from eq. (4.73), 
(4.76) 
Observe that H (jw) is thus a rational function; that is, it is a ratio of polynomials 
in (jw ). The coefficients of the numerator polynomial are the same coefficients as those 
that appear on the right-hand side of eq. (4.72), and the coefficients of the denominator 
polynomial are the same coefficients as appear on the left side of eq. (4.72). Hence, the 
frequency response given in eq. (4.76) for the LTI system characterized by eq. (4.72) can 
be written down directly by inspection. 
The differential equation (4.72) is commonly referred to as an Nth-order differen-
tial equation, as the equation involves derivatives of the output y(t) up through the Nth 
derivative. Also, the denominator of H(jw) in eq. (4.76) is an Nth-order polynomial in 
(jw). 
Example 4.24 
Consider a stable LTI system characterized by the differential equation 
dy(t) 
dt + ay(t) = x(t), 
with a·> 0. From eq. (4.76), the frequency response is 
H(jw) = -. - 1-. 
. ;w +a 
(4.77) 
(4.78) 
Comparing this with the result of Example 4.1, we see that eq. (4.78) is the Fourier 
transform of e - at u(t). The impulse response of the system is then recognized as 
h(t) = e- 01u(t). 
Example 4.25 
Consider a stable LTI system that is characterized by the differential equation 

332 
The Continuous-Time Fourier Transform 
Chap. 4 
From eq. (4.76), the frequency response is 
. 
(jw) + 2 
H(;w) = (jw)2 + 4(jw) + 3 · 
(4.79) 
To determine the corresponding impulse response, we require the inverse Fourier trans-
form of H(jw ). This can be found using the technique of partial-fraction expansion em-
ployed in Example 4.19 and discussed in detail in the appendix. (In particular, see Ex-
' ample A.1, in which the details of the calculations for the partial-fraction expansion of 
eq. (4.79) are worked out.) As a first step, we factor the denominator of the right-hand 
side of eq. (4.79) into a product of lower order terms: 
. 
jw +2 
H(;w) = (jw + 1)(jw + 3) 
(4.80) 
Then, using the method of partial-fraction expansion, we find that 
I 
I 
H(jw) = jw2+ 1 + jw2+3. 
The inverse transform of each term can be recognized from Example 4.24, with the result 
that 
The procedure used in Example 4.25 to obtain the inverse Fourier transform is gen-
erally useful in inverting transforms that are ratios of polynomials in jw. In particular, 
we can use eq. (4.76) to determine the frequency response of any LTI system described 
by a linear constant-coefficient differential equation and then can calculate the impulse 
response by performing a partial-fraction expansion that puts the frequency response into 
a form in which the inverse transform of each term can be recognized by inspection. In 
addition, if the Fourier transform X(jw) of the input to such a system is also a ratio of 
polynomials in jw, then so is Y(jw) = H(jw )X(jw ). In this case we can use the same 
technique to solve the differential equation-
that is, to find the response y(t) to the input 
x(t). This is illustrated in the next example. 
Example 4.26 
Consider the system of Example 4.25, and suppose that the input is 
x(t) = e-1 u(t). 
Then, using eq. (4.80), we have 
Y(jw) = H(jw)X(jw) = [(jw l~)~~ + 3)][jw 1+ 1] 
jw + 2 
(jw + 1)2(jw + 3) · 
(4.81) 

Sec. 4.8 
Summary 
333 
As discussed in the appendix, in this case the partial-fraction expansion takes the form 
. 
All 
A12 
A21 
Y(Jw) = jw + 1 + (jw + 1)2 + jw + 3' 
(4.82) 
where A 11 , A 12, and A21 are constants to be determined. In Example A.2 in the appendix, 
the technique of partial-fraction expansion is used to determine these constants. The 
values obtained are 
so that 
1 
All = 4, 
1 
AI2 = 2' 
1 
4' 
I 
I 
I 
Y( · ) 
4 
2 
4 
JW 
= jw + 1 + (jw + 1)2 -
jw + 3 · 
(4.83) 
Again, the inverse Fourier: transform for each term in eq. (4.83) can be obtained by in-
spection. The first and third terms are of the same type that we have encountered in the 
preceding two examples, while the inverse transform of the second term can be obtained 
from Table 4.2 or, as was done in Example 4.19, by applying the dual of the differenti-
ation property, as given in eq. (4.40), to ll(jw + 1). The inverse transform of eq. (4.83) 
is then found to be 
[
1 -
1 -
1 -
] 
y(t) = 4e I + 2te I - 4e 31 u(t). 
From the preceding examples, we see how the techniques of Fourier analysis allow 
us to reduce problems concerning LTI systems characterized by differential equations to 
straightforward algebraic problems. This important fact is illustrated further in a number 
of the problems at the end of the chapter. In addition (see Chapter 6), the algebraic structure 
of the rational transforms encountered in dealing with LTI systems described by differen-
tial eqpations greatly facilitate the analysis of their frequency-domain properties and the 
development of insights into both the time-domain and frequency-domain characteristics 
of this important class of systems. 
4.8 SUMMARY 
In this chapter, we have developed the Fourier·transform representation for continous-time 
signals and have examined many of the properties that make this transform so useful. In 
particular, by viewing an aperiodic signal as the limit of a periodic signal as the period 
becomes arbitrarily large, we derived the Fourier transform representation for aperiodic 
signals from the Fourier series representation for periodic signals developed in Chapter 3. 
In addition, periodic signals themselves can be represented using Fourier transforms con-
sisting of trains of impulses located at the harmonic frequencies of the periodic signal and 
with areas proportional to the corresponding Fourier series coefficients. 
The Fourier transform possesses a wide variety of important properties that de-
scribe how different characteristics of signals are reflected in their transforms, and in 

334 
The Continuous-Time Fourier Transform 
Chap.4 
this chapter we have derived and examined many of these properties. Among them are 
two that have particular significance for our study of signals and systems. The first is the 
convolution property, which is a direct consequence of the eigenfunction property of com-
plex exponential signals and which leads to the description of an LTI system in terms 
of its frequency response. This description plays a fundamental role in the frequency-
domain approach to the analysis of LTI systems, which we will continue to explore in 
subsequent chapters. The second property of the Fourier transform that has extremely 
important implications is the multiplication property, which provides the basis for the 
frequency-domain analysis of sampling and modulation systems. We examine these sys-
tems further in Chapters 7 and 8. 
We have also seen that the tools of Fourier analysis are particularly well suited to 
the examination of LTI systems characterized by linear constant-coefficient differential 
equations. Specifically, we have found that the frequency response for such a system can 
be determined by inspection and that the technique of partial-fraction expansion can then 
be used to facilitate the calculation of the impulse response of the system. In subsequent 
chapters, we will find that the convenient algebraic structure of the frequency responses 
of these systems allows us to gain considerable insight into their characteristics in both the 
time and frequency domains. 
Chapter 4 Problems 
The first section of problems belongs to the basic category and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
4.1. Use the Fourier transform analysis equation (4.9) to calculate the Fourier transforms 
of: 
(a) e-2(t-Ilu(t- 1) 
(b) e- 2lt- II 
Sketch and label the magnitude of each Fourier transform. 
4.2. Use the Fourier transform analysis equation (4.9) to calculate the Fourier transforms 
of: 
(a) 5(t + 1) + 5(t - 1) 
(b) fr{u( - 2 - t) + u(t- 2)} 
Sketch and label the magnitude of each Fourier transform. 
4.3. Determine the Fourier transform of each of the following periodic signals: 
(a) sin(2'7Tt + ~) 
(b) 1 + cos(61rt + ~) 
4.4. Use the Fourier transform synthesis equation (4.8) to determine the inverse Fourier 
transforms of: 
(a) X1 (jw) = 21T 5(w) + 1T 5(w - 41T) + 1T 5(w + 41T) 

Chap. 4 Problems 
{ 
2, 
O:sw:s2 
(b) X2(jw) = 
-2, 
- 2 :5 w < 0 
0, 
lwl > 2 
335 
4.5. Use the Fourier transform synthesis equation (4.8) to determine the inverse Fourier 
transform of X(jw) = JX(jw)Jej<l:X(jw), where 
JX(jw )J = 2{u(w + 3) - u(w - 3)}, 
<r..X(jw) = -~w + 7T. 
Use your answer to determine the values oft for which x(t) = 0. 
4.6. Given that x(t) has the Fourier transform X(jw ), express the Fourier transforms of 
the signals listed below in terms of X(jw ). You may find useful the Fourier transform 
properties listed in Table 4.1. 
(a) x1(t) = x(1- t) + x(-1- t) 
(b) x2(t) = x(3t- 6) 
(c) x3(t) = ;r~ x(t - 1) 
4. 7. For each of the following Fourier transforms, use Fourier transform properties (Table 
4.1) to determine whether the corresponding time-domain signal is (i) real, imaginary, 
or neither and (ii) even, odd, or neither. Do this without evaluating the inverse of any 
of the given transforms. 
(a) X1(jw) = u(w)- u(w- 2) 
(b) X2(jw) = cos(2w) sin( I) 
(c) X3(jw) = A(w)ejB(w), where A(w) = (sin2w)/w and B(w) = 2w +I 
(d) X(jw) = :z:::;=-oo(!)lk\ o(w - 7) 
4.8. Consider the signal 
{
0, 
x(t) = 
t + !, 
1, 
t < -! 
2 
-! < t < ! 
2-
-
2' 
t >! 
2 
(a) Use the differentiation and integration properties in Table 4.1 and the Fourier 
transform pair for the rectangular pulse in Table 4.2 to find a closed-form ex-
pression for X(jw ). 
(b) What is the Fourier transform of g(t) = x(t)- ! ? 
4.9. Consider the signal 
- { 0, 
ltl > 1 
x(t) -
(t + 1)/2, 
-1 :5 t :5 1' 
(a) With the help of Tables 4.1 and 4.2, determine the closed-form expression for 
X(jw). 
(b) Take the real part of your answer to part (a), and verify that it is the Fourier 
transform of the even part of x(t). 
(c) What is the Fourier transform of the odd part of x(t)? 

336 
The Continuous-Time Fourier Transform 
Chap.4 
4.10. (a) Use Tables 4.1 and 4.2 to help determine the Fourier transform of the following 
signal: 
(
sint)
2 
x(t) = t 
7Tt 
(b) Use Parseval's relation and the result of the previous part to determine the nu-
merical value of 
I
+"' 
( . 
)4 
A = 
t2 smt dt 
- oo 
7T( 
4.11. Given the relationships 
y(t) = x(t) * h(t) 
and 
g(t) = x(3t) * h(3t), 
and given that x(t) has Fourier transform X(jw) and h(t) has Fourier transform 
H(jw ), use Fourier transform properties to show that g(t) has the form 
g(t) = Ay(Bt). 
Determine the values of A and B. 
4.12. Consider the Fourier transform pair 
-ltl 
n: 
2 
e 
~ 
1 +w2 ' 
(a) Use the appropriate Fourier transform properties to find the Fourier transform 
of te- 111. 
(b) Use the result from part (a), along with the duality property, to determine the 
Fourier transform of 
4t 
Hint: See Example 4.13. 
4.13. Let x(t) be a signal whose Fourier transform is 
X(jw) = i>(w) + i>(w -
7T) + i>(w - 5), 
and let 
h(t) = u(t) - u(t - 2). 
(a) Is x(t) periodic? 
(b) Is x(t) * h(t) periodic? 
(c) Can the convolution of two aperiodic signals be periodic? 

Chap. 4 Problems 
337 
4.14. Consider a signal x(t) with Fourier transform X(jw ). Suppose we are given the 
following facts: 
1. x(t) is real and nonnegative. 
2. rr:- 1{(1 + jw )X(jw )} = Ae- 21 u(t), where A is independent oft. 
3. f:JX(jw )12 dw = 27T. 
Determine a closed-form expression for x(t). 
4.15. Let x(t) be a signal with Fourier transform X(jw ). Suppose we are given the fol-
lowing facts: 
1. x(t) is real. 
2. x(t) = 0 for t :s 0. 
3. 2~ f _:'oo CRe{X(jw )}eiwt dw = ltle-111. 
Determine a closed-form expression for x(t). 
4.16. Consider the signal 
oo 
sin(k.!!:) 
7T 
x(t) = ~ (k.!!:) 8(t - k4 ). 
k = - 00 
4 
(a) Determine g(t) such that 
(
sint) 
x(t) = 
7Tt 
g(t). 
(b) Use the multiplication property of the Fourier transform to argue that X(jw) is 
periodic. Specify X(jw) over one period. 
4.17. Determine whether each of the following statements is true or false. Justify y9ur 
answers. 
(a) An odd and imaginary signal always has an odd and imaginary Fourier trans-
form. 
(b) The convolution of an odd Fourier transform with an even Fourier transform is 
always odd. 
4.18. Find the impulse response of a system with the frequency response 
JJ(jw) = (sin
2(3w))cosw 
w2 
4.19. Consider a causal LTI system with frequency response 
H(jw) = ~3
. 
JW + 
For a particular input x(t) this system is observed to produce the output 
y(t) = e-3tu(t) - e- 4tu(t). 
Determine x(t). 
4.20. Find the impulse response of the causal LTI system represented by the RLC circuit 
considered in Problem 3.20. Do this by taking the inverse Fourier transform of the 
circuit's frequency response. You may use Tables 4.1 and 4.2 to help evaluate the 
· inverse Fourier transform. 

338 
The Continuous-Time Fourier Transform 
Chap.4 
BASIC PROBLEMS 
4.21. Compute the Fourier transform of each of the following signals: 
(a) [e-ar cosw0t]u(t), a> 0 
(b) e- 3ltl sin2t 
(c) x(t) = { I +cos 7Tt, 
ltl :s; l 
(d) .2::;= 0 ak o(t- kT), Ia I < 1 
0, 
ltl > 1 
(e) [te- 21 sin4t]u(t) 
(f) [ sin 1Tt] [ sin 27T(t-l)] 
1Tt 
1T(t- l) 
(g) x(t) as shown in Figure P4.2l(a) 
(i) x(t) = { 1 - t
2
, 
0 < t ~ · 1 
0, 
otherwtse 
(h) x(t) as shown in Figure P4.21(b) 
X (t) 
X (t) 
... t t t t t t t' t' t t t t t t t··· 
-6 - 5 -4 -3 -2 - 1 
0 
1 
2 
3 
4 
5 
6 
7 
8 
t 
(a) 
(b) 
Figure P4.21 
4.22. Determine the continuous-time signal corresponding to each of the following 
transforms. 
..J:: XOw) 
IXOw)l 
w 
(a) 
[7_1 
1 
2 
3 
w 
(b) 
Figure P4.22 

Chap. 4 Problems 
(a) X(jw) = 2sin[3(w - 2?T)] 
(w - 2'1T) 
(b) X(jw) = cos(4w + Tr/3) 
(c) X(jw) as given by the magnitude and phase plots of Figure P4.22(a) 
(d) X(jw) = 2[S(w- 1) -l>(w + 1)] + 3[S(w- 2Tr) + l>(w + 27r)] 
(e) X(jw) as l.n Figure P4.22(b) 
4.23. Consider the signal 
x (t) = 
e ' 
-
-
{ 
-/ 
0 < t < 1 
0 
0, 
elsewhere · 
339 
Determine the Fourier transform of each of the signals shown in Figure P4.23. You 
should be able to do this by explicitly evaluating only the transform of x0(t) and 
then using properties of the Fourier transform. 
x0(t) 
- 1 
0 
1 
(a) 
(b) 
-1 
0 
1 
0 
1 
(c) 
(d) 
Figure P4.23 
4.24. (a) Determine which, if any, of the real signals depicted in Figure P4.24 have 
Fourier transforms that satisfy each of the following conditions: 
(1) CR£{X(jw )} = 0 
(2) dm{X(jw )} = 0 
(3) There exists a real a such that eiaw X(jw) is real 
(4) f:oo X(jw)dw = 0 
(5) f:oo wX(jw)dw = 0 
(6) X(jw) is periodic 
(b) Construct a signal that has properties (1), (4), and (5) and does not have the 
others. 

340 
X (t) 
(a) 
(b) 
X (t) 
I 
(c) 
X t) 
(d) 
x(t) = e - t2t2 
(e) 
(f) 
The Continuous-Time Fourier Transform 
Chap.4 
""""""8 
Figure P4.24 

Chap. 4 Problems 
341 
4.25. Let X(jw) denote the Fourier transform of the signal x(t) depicted in Figure P4.25. 
(a) X(jw) can be expressed as A(jw)eje(jw), where A(jw) and 8(jw) 
are both real-values. Find 8(jw). 
(b) Find X(jO). 
(c) Find f.:'oo X.(jw)dw . 
(d) Evaluate f.:'co X(jw) 28!:"' ej2w dw . 
(e) Evaluate Ceo IX(jw )J2 dw. 
(f) Sketch the inverse Fourier transform of ffi..e{X(jw )}. 
Note: You should perform all these calculations without explicitly evaluating X(jw ). 
X (t) 
- 1 
0 
2 
3 
Figure P4.25 
4.26. (a) Compute the convolution of each of the following pairs of signals x(t) and h(t) 
by calculating X(jw) and H(jw ), using the convolution property, and inverse 
transforming. 
(i) x(t) = te- 21 u(t), h(t) = e- 41 u(t) 
(ii) x(t) = te- 21 u(t), h(t) = te- 41 u(t) 
(iii) x(t) = e- 1u(t), h(t) = e1u(- t) 
(b) Suppose that x(t) = e- (t- 2>u(t - 2) and h(t) is as depicted in Figure P4.26. Ver-
ify the convolution property for this pair of signals by showing that the Fourier 
transform of y(t) = x(t) * h(t) equals H(jw )X(jw ). 
- 1 
3 
Figure P4.26 
4.27. Consider the signals 
x(t) = u(t - 1) - 2u(t - 2) + u(t - 3) 
and 
co 
x(t) = L x(t - kT), 
k = -co 

342 
The Continuous-Time Fourier Transform 
Chap.4 
where T > 0. Let ak denote the Fourier series coefficients of x(t), and let X(jw) 
denote"the Fourier transform of x(t). 
(a) Determine a closed-form expression for X(jw ). 
(b) Determine an expression for the Fourier coefficients ak and verify that ak = 
~x(i2;k). 
4.28. (a) Let x(t) have the Fourier transform X(jw ), and let p(t) be periodic with funda-
mental frequency w0 and Fourier series representation 
+ oo 
p(t) = 2::: anejnwot. 
n= -oo 
Determine an expression for the Fourier transform of 
y(t) = x(t)p(t). 
(P4.28-1) 
(b) Suppose that X(jw) is as depicted in Figure P4.28(a). Sketch the spectrum of 
y(t) in eq. (P4.28-l) for each of the following choices of p(t): 
(i) p(t) = cos(t/2) 
(ii) p(t) = cost 
(iii) p(t) = cos 2t 
(iv) p(t) = (sin t)(sin 2t) 
(v) p(t) = cos 2t - cost 
(vi) p(t) = .L:;:_
00 8(t- 1rn) 
(vii) p(t) = 2::;: _
00 8(t - 27Tn) 
(viii) p(t) = 2::;: - oo 8(t - 47Tn) 
(ix) p(t) = .L:;:_"' 8(t- 27Tn)- 4 .L:;:_"' 8(t- 1rn) 
(x) p(t) = the periodic square wave shown in Figure P4.28(b). 
X Ow) 
--
(!) 
(a) 
p (t) 
J D D D rn D D D D D··· 
'll' 
(b) 
Figure P4.28 

Chap. 4 Problems 
343 
4.29. A real-valued continuous-time function x(t) has a Fourier transform X(jw) whose 
magnitude and phase are as illustrated in Figure P4.29(a). 
The functions Xa(t), Xb(t), Xc(t), and xd(t) have Fourier transforms whose 
magnitudes are identical to X(jw ), but whose phase functions differ, as shown in 
Figures P4.29(b)-(e). The phase functions <r..Xa(jw) and <r..Xb(jw) are formed by 
adding a linear phase to <J:.X(jw ). The function <r..Xc(jw) is formed by reflecting 
<J:.X(jw) about w = 0, and <r..Xd(jw) is obtained by a combination of a reflection 
and an addition of a linear phase. Using the properties of Fourier transforms, deter-
mine the expressions for Xa(t), xb(t), Xc(t), and xd(t) in terms of x(t). 
IXfjw)l 
4: X Ow) . 
- ----------------
2 
- ~ -------- ---------
(a) 
------.................................... 
w 
...._Slope =-a 
(b) 
Figure P4.29 

344 
The Continuous-Time Fourier Transform 
Chap.4 
____ ........................ 
Slope = b 
............ 
.................. 
(c) 
w 
------- - - --
- -rr/2 
(d) 
---Slope =d 
----------
w 
--
(e) 
Figure P4.29 
Continued 
4.30. Suppose g(t) = x(t) cost and the Fourier transform of the g(t) is 
(a) Determine x(t). 
G( . ) _ { 1, 
lwl s 2 
JW 
--:-
0, 
otherwise· 
(b) Specify the Fourier J;ransform X1 (jw) of a signal x 1 (t) such that 

Chap. 4 Problems 
345 
4.31. (a) Show that the three LTI systems with impulse responses 
h1 (t) = u(t), 
hz(t) = -2o(t) + 5e- 21u(t), 
and 
all have the same response to x(t) = cost. 
(b) Find the impulse response of another LTI system with the same response to 
cost. 
This problem illustrates the fact that the response to cos t cannot be used to 
specify an LTI system uniquely. 
4.32. Consider an LTI system S with impulse response 
h(t) = sin(4(t- 1)). 
1T(t - 1) 
Determine the output of S for each of the following inputs: 
(a) x 1 (t) = cos(6t + ~) 
(b) xz(t) = 2: ;= 0 (~)k sin(3kt) 
(c) X (t) = sin(4(t+ I)) 
3 
1T(I+ I) 
(d) X4(t) = cin2t)2 
1TI 
4.33. The input and the output of a stable and causal LTI system are related by the dif-
ferential equation 
d2y(t) 
6dy(t) 
8 () - 2 ( ) 
--+ --+ yt-
xt 
dt2 
dt 
(a) Find the impulse response of this system. 
(b) What is the response of this system if x(t) = te- 21u(t)? 
(c) Repeat part (a) for the stable and causal LTI system described by the equation 
d2y(t) 
~2 dy(t) 
( ) = 2 d2 x(t) _ 2 ( ) 
dt2 + V L. dt + y t 
dt2 
X t 
4.34. A causal and stable LTI system S has the frequency response 
. 
jw +4 
H(jw) = 6 
2 
5 . . 
-w + JW 

346 
The Continuous-Time Fourier Transform 
Chap. 4 
(a) Determine a differential equation relating the input x(t) and output y(t) of S. 
(b) Determine the impulse response h(t) of S. 
(c) What is the output of S when the input is 
x(t) = e- 41u(t)- te-41u(t)? 
4.35. In this problem, we provide examples of the effects of nonlinear changes in phase. 
(a) Consider the continuous-time LTI system with frequency response 
H( . ) = a- jw 
JW 
. ' 
a+ JW 
where a > 0. What is the magnitude of H(jw )? What is <r..H(jw )? What is the 
impulse response of this system? 
(b) Determine the output of the system of part (a) with a = 1 when the input is 
cos(tl }3) + cost + cos J3r. 
Roughly sketch both the input and the output. 
4.36. Consider an LTI system whose response to the input 
x(t) = [e- 1 + e- 31]u(t) 
is 
y(t) = [2e- 1 - 2e- 41]u(t). 
(a) Find the frequency response of this system. 
(b) Determine the system's impulse response. 
(c) Find the differential equation relating the input and the output of this system. 
ADVANCED PROBLEMS 
4.37. Consider the signal x(t) in Figure P4.37. 
(a) Find the Fourier transform X(jw) of x(t). 
(b) Sketch the signal 
00 
i(t) = x(t) * 2.: 8(t - 4k). 
k = - oo 
(c) Find another signal g(t) such that g(t) is not the same as x(t) and 
00 
i(t) = g(t) * 2.: 8(t - 4k). 
k= -00 

Chap. 4 Problems 
347 
(d) Argue that, although G(jw) is different from X(jw), G(j';k) = X(j';k) for all 
integers k. You should not explicitly evaluate G(jw) to answer this question. 
X (t) 
Figure P4.37 
4.38. Let x(t) be any signal with Fourier transform X(jw ). The frequency-shift property 
of the Fourier transform may be stated as 
. 
~ 
eJwot x(t) ~ 
X(j(w - wo)). 
(a) Prove the frequency-shift property by applying the frequency shift to the anal-
ysis equation 
X(jw) = [
"' x(t)e- jwtdt. 
(b) Prove the frequency-shift property by utilizing the Fourier transform of ejwot in 
conjunction with the multiplication property of the Fourier transform. 
4.39. Suppose that a signal x(t) has Fourier transform X(jw ). Now consider another signal 
g(t) whose shape is the same as the shape of X(jw ); that is, 
g(t) = X(jt). 
(a) Show that the Fourier transform G(jw) of g(t) has the same shape as 21Tx( - t); 
that is, show that 
G(jw) = 21Tx(- w). 
(b) Using the fact that 
5'{S(t + B)} = ejBw 
in conjunction with the result from part (a), show that 
5'{ej81 } = 21T S(w -B). 
4.40. Use properties of the Fourier transform to show by induction that the Fourier trans-
form of 
tn- l 
x(t) = (n _ l)! e- at u(t), a > 0, 

348 
The Continuous-Time Fourier Transform 
Chap.4 
is 
1 
(a+jw)"' 
4.41. In this problem, we derive the multiplication property of the continuous-time Fourier 
transform. Let x(t) and y(t) be two continuous-time signals with Fourier transforms 
X(jw) and Y(jw ), respectively. Also, let g(t) denote the inverse Fourier transform 
of 2~ {X(jw) * Y(jw )}. 
(a) Show that 
1 J 
+oo 
[ 1 J 
+oo 
. l 
g(t) = 27T - oo X(j()) 27T -oo Y(j(w - ()))el"'l dw d(). 
(b) Show that 
-
Y(j(w - ()))elwt dw = el81y(t). 
1 J 
+oo 
. 
. 
27T 
-00 
(c) Combine the results of parts (a) and (b) to conclude that 
g(t) = x(t)y(t). 
4.42. Let 
g1 (t) = {[cos(wot)]x(t)} * h(t) 
and 
g2(t) = {[sin(wot)]x(t)} * h(t), 
where 
00 
x(t) = L a kejklOOt 
k = -00 
is a real-valued periodic signal and h(t) is the impulse response of a stable LTI 
system. 
1 
(a) Specify a value for w0 and any necessary constraints on H(jw) to ensure that 
g1 (t) = (Re{as} 
and 
(b) Give an example of h(t) such that H(jw) satisfies the constraints you specified 
in part (a). 
4.43. Let 
2 
sint 
g(t) = x(t) cos t * -. 
1Tt 
Assuming that x( t) is real and X (j w) = 0 for jw I ;;;;:: 1, show that there exists an 
LTI system S such that 
s 
x(t) ~ 
g(t). 

Chap. 4 Problems 
349 
4.44. The output y(t) of a causal LTI system is related to the input x(t) by the equation 
dy(t) 
f + oo 
- d 
+ lOy(t) = 
x(T)z(t - T)dT- x(t), 
t 
-00 
where z(t) = e- 1 u(t) + 3 l>(t). 
(a) Find the frequency response H(jw) = Y(jw )IX(jw) of this system. 
(b) Determine the impulse response of the system. 
4.45. In the discussion in Section 4.3.7 of Parseval's relation for continuous-time signals, 
we saw that 
--llll-
0 
f 
+
00 
1 f 
+
00 
-oo lx(t)l
2 dt = 21T 
- oo IX(jw )1
2 dw. 
This says that the total energy of the signal can be obtained by integrating IX(Jw )12 
over all frequencies. Now consider a real-valued signal x(t) processed by the ideal 
bandpass filter H(jw) shown in Figure P4.45. Express the energy in the output sig-
nal y(t) as an integration over frequency of IX(Jw )jZ. For A sufficiently small so that 
IX(Jw )I is approximately constant over a frequency interval of width A, show that 
the energy in the output y(t) of the bandpass filter is approximately proportional to 
AIX(Jwo)l2 . 
On the basis of the foregoing result, AIX(Jw0)12 is proportional to the energy 
in the signal in a bandwidth A around the frequency w0• For this reason, IX(Jw )12 is 
often referred to as the energy-density spectrum of the signal x(t). 
Figure P4.45 
4.46. In Section 4.5.1, we discussed the use of amplitude modulation with a complex 
exponential carrier to implement a bandpass filter. The specific system was shown 
in Figure 4.26, and if only the real part of f(t) is retained, the equivalent bandpass 
filter is that shown in Figure 4.30. 
In Figure P4.46, we indicate an implementation of a bandpass filter using 
sinusoidal modl!!ation and lowpass filters. Show that the output y(t) of the sys-
tem is identical totnat which would be obtained by retaining only CRe{f(t)} in Fig-
ure 4.26. 

\ 
350 
The Continuous-Time Fourier Transform 
Chap.4 
x(t) 
y(t) 
w 
Figure P4.46 
4.47. An important property of the frequency response H(jw) of a continuous-time LTI 
system with a real, causal impulse response h(t) is that H(jw) is completely spec-
ified by its real part, ffi-e{H(jw )}. The current problem is concerned with deriving 
and examining some of the implications of this property, which is generally referred 
to as real-part sufficiency. 
(a) Prove the property of real-part sufficiency by examining the signal he(t), which 
is the even part of h(t). What is the Fourier transform of he(t)? Indicate how 
h(t) can be recovered from he(t). 
(b) If the real part of the frequency response of a causal system is 
ffi-e{H(jw)} = cosw, 
what is h(t)? 
(c) Show that h(t) can be recovered from h0 (t), the odd part of h(t), for every 
value of t except t = 0. Note that if h(t) does not contain any singularities 
[5(t), u1 (t), u2(t), etc.] at t = 0, then the frequency response 
I 
+ oo 
H(jw) = 
- oo h(t)e- jwt dt 
will not change if h(t) is set to some arbitrary finite value at the single point 
t = 0. Thus, in this case, show that H(jw) is also completely specified by its 
imaginary part. 

Chap. 4 Problems 
351 
EXTENSION PROBLEMS 
4.48. Let us consider a system with a real and causal impulse response h(t) that does not 
have any singularities at t = 0. In Problem 4.47, we saw that either the real or the 
imaginary part of H(jw) completely determines H(jw ). In this problem we derive 
an explicit relationship between HR(jw) and H1(jw ), the real and imaginary parts 
of H(jw). 
(a) To begin, note that since h(t) is causal, 
h(t) = h(t)u(t), 
(P4.48-1) 
except perhaps at t = 0. Now, since h(t) contains no singularities at t = 0, the 
Fourier transforms of both sides of eq. (P4.48- 1) must be identical. Use this 
fact, together with the multiplication property, to show that 
H( . ) -
1 I 
+ oo H(j'q)d 
JW -
-.- . 
-
-
11· 
}Tr 
-00 w- 11 
(P4.48-2) 
Use eq. (P4.48-2) to determine an expression for HR(jw) in terms of H1(jw) 
and one for fh(jw) in terms of HR(jw ). 
(b) The operation 
1 I +oo X(T) 
y(t) =
-
-
dT 
7r 
- oo t- T 
(P4.48-3) 
is called the Hilbert transform. We have just seen that the real and imaginary 
parts of the transform of a real, causal impulse response h(t) can be determined 
from one another using the Hilbert transform. 
Now consider eq. (P4.48-3), And regard y(t) as the output of an LTI system 
with input x(t). Show that the frequency response of this system is 
\ 
H( . ) = { - j, 
w > 0 
JW 
. 
<0. 
], 
w 
(c) What is the Hilbert transform of the signal x(t) = cos 3t? 
4.49. Let H(jw) be the frequency response of a continuous-time LTI system, and suppose 
that H(jw) is real, even, and positive. Also, assume that 
max{H(jw )} = H(O). 
w 
(a) Show that: 
(i) The impulse response, h(t), is real. 
(ii) max{jh(t)j} = h(O). 
Hint: If f (t, w) is a complex function of two variables, then 
I 
+ oo 
I 
+oo 
- oo f(t, W) dw :S 
-oo if(t, W )j dw. 

352 
The Continuous-Time Fourier Transform 
Chap. 4 
(b) One important concept in system analysis is the bandwidth of an LTI system. 
There are many different mathematical ways in which to define bandwidth, 
but they are related to the qualitative and intuitive idea that a system with fre-
quency response G(jw) essentially "stops" signals of the form ejwt for values of 
w where G(jw) vanishes or is small and "passes" those complex exponentials 
in the band of frequency where G(jw) is not small. The width of this band is the 
bandwidth. These ideas will be made much clearer in Chapter 6, but for now we 
will consider a special definition of bandwidth for those systems with frequency 
responses that have the properties specified previously for H(jw ). Specifically, 
one definition of the bandwidth Bw of such a system is the width of the rect-
angle of height H(jO) that has an area equal to the area under H(jw ). This is 
illustrated in Figure P4.49(a). Note that since H(jO) = maxw H(jw ), the fre-
quencies within the band indicated in the figure are those for which H(jw) is 
largest. The exact choice of the width in the figure is, of course, a bit arbitrary, 
but we have chosen one definition that allows us to compare different systems 
and to make precise a very important relationship between time and frequency. 
What is the bandwidth of the system with frequency response 
H(jw) 
H(O) 
H(jw) = { l, 
0, 
JwJ<W? 
JwJ>w· 
---I 
Area of rectangle = 
• 
,-
area under H(jw) 
w 
Figure P4.49a 
(c) Find an expression for the bandwidth Bw in terms of H(jw ). 
(d) Let s(t) denote the step response of the system set out in part (a). An important 
measure of the speed of response of a system is the rise time, which, like the 
bandwidth, has a qualitative definition, leading to many possible mathematical 
definitions, one of which we will use. Intuitively, the rise time of a system is a 
measure of how fast the step response rises from zero to its final value, 
s(oo) = lim s(t). 
f ---> 00 
Thus, the smaller the rise time, the faster is the response of the system. For the 
system under consideration in this problem, we will define the rise time as 
s(oo) 
t, = h(O) 

Chap. 4 Problems 
353 
Since 
s'(t) = h(t), 
and also because of the property that h(O) = max1 h(t), tr is the time it would 
take to go from zero to s( oo) while maintaining the maximum rate of change of 
s(t). This is illustrated in Figure P4.49(b). 
Find an expression for tr in terms of H(jw ). 
(b) 
Figure P4.49b 
(e) Combine the results of parts (c) and (d) to show that 
Bwtr = 21T. 
(P4.49-1) 
Thus, we cannot independently specify both the rise time and the bandwidth of 
our system. For example, eq. (P4.49-1) implies that, if we want a fast system (tr 
small), the system must have a large bandwidth. This is a fundamental trade-off 
that is of central importance in many problems of system design. 
4.50. In Problems 1.45 and 2.67, we defined and examined several of the properties and 
uses of correlation functions. In the current problem, we examine the properties of 
such functions in the frequency domain. Let x(t) and y(t) be two real signals. Then 
the cross-correlation function of x(t) and y(t) is defined as 
f
+oo 
</Jxy(t) = 
-oo X(t + T)y( T) dT. 
Sirnilarh, we can define </Jyx(t), <PxxCt), and </Jyy(t). [The last two of these are called 
the autbcorrelation functions of the signals x( t) and y( t), respectively.] Let <f_) xy (j w ), 
<f_)yx(jw ), <f_) xxUw ), and <f_)yy(jw) denote the Fourier transforms of <Pxy(t), </Jyx(t), 
<PxxCt), and </Jyy(t), respectively. 
(a) What is the relationship between <f_)xy(jw) and <f_)yx(jw )? 
(b) Find an expression for <f_)xy(jw) in terms of X(jw) and Y(jw ). 
(c) Show that <f_)xxUw) is real and nonnegative for every w. 
(d) Suppose now that x(t) is the input to an LTI system with a real-valued impulse 
response and with frequency response H(jw) and that y(t) is the output. Find 
expressions for <f_)xy(jw) and <f_)yy(jw) in terms of <f_)xxUw) and H(jw ). 

354 
The Continuous-Time Fourier Transform 
Chap.4 
(e) Let x(t) be as is illustrated in Figure P4.50, and let the LTI system impulse 
response be h(t) = e-at u(t), a> 0. Compute <PxxUw ), <Pxy(jw ), and <Pyy(jw) 
using the results of parts (a)-(d). 
(f) Suppose that we are given the following Fourier transform of a function cf>(t): 
. 
w 2 + 100 
<l>(jw) = w 2 + 25 · 
Find the impulse responses of two causal, stable LTI systems that have autocor-
relation functions equal to cf>(t). Which one of these has a causal, stable inverse? 
x(t) 
0 
Figure P4.50 
4.51. (a) Consider two LTl systems with impulse responses h(t) and g(t), respectively, 
and suppose that these systems are inverses of one another. Suppose also that the 
systems have frequency responses denoted by H(jw) and G(jw }, respectively. 
What is the relationship between H(jw) and G(jw )? 
(b) Consider the continuous-time LTI system with frequency response 
H( 'w) = { 1, 
2 < lw! < 3. 
1 
0, 
otherwise 
(i) Is it possible to find an input x(t) to this system such that the output is as 
depicted in Figure P4.50? If so, find x(t). If not, explain why not. 
. (ii) Is this system invertible? Explain your answer. 
(c) Consider an auditorium with an echo problem. As discussed in Problem 2.64, 
we can model the acoustics of the auditorium as an LTI system with an im-
pulse response consisting of an impulse train, with the kth impulse in the train 
corresponding to the kth echo. Suppose that in this particular case the impulse 
response is 
"' 
h(t) = 2: e - kT 8(t- kT), 
k=O 
where the factor e-kT represents the attenuation of the kth echo. 
In order to make a high-quality recording from the stage, the effect of the 
echoes must be removed by performing some processing of the sounds sensed 
by the recording equipment. In Problem 2.64, we used convolutional techniques 
to consider one example of the design of such a processor (for a different acous-
tic model). In the current problem, we will use frequency-domain techniques. 
Specifically, let G(jw) denote the frequency response of the LTI system to be 

Chap. 4 Problems 
355 
used to process the sensed acoustic signal. Choose G(jw) so that the echoes are 
completely removed and the resulting signal is a faithful reproduction of the 
original stage sounds. 
(d) Find the differential equation for the inverse of the system with impulse re-
sponse 
h(t) = 2 S(t) + U] (t). 
(e) Consider the LTI system initially at rest and described by the differential equa-
tion 
d2y(t) 
6dy(t) 
9 ( ) _ d 2 x(t) 
3 d x(t) 
2 ( ) 
df'l + --;{t + y t 
- df'l + --;{t + X t . 
The inverse of this system is also initially at rest and described by a differen-
tial equation. Find the differential equation describing the inverse, and find the 
impulse responses h(t) and g(t) of the original system and its inverse. 
4.52. Inverse systems frequently find application in problems involving imperfect mea-
suring devices. For example, consider a device for measuring the temperature of a 
liquid. It is often reasonable to model such a device as an LTI system that, because 
ofthe response characteristics of the measuring element (e.g., the mercury in ather-
mometer), does not respond instantaneously to temperature changes. In particular, 
assume that the response of this device to a unit step in temperature is 
s(t) = (1 - e-112)u(t). 
(P4.52-1) 
(a) Design a compensatory system that, when provided with the output of the mea-
suring device, produces an output equal to the instantaneous temperature of the 
liquid. 
(b) One of the problems that often arises in using inverse systems as compensators 
for measuring devices is that gross inaccuracies in the indicated temperature 
may occur if the actual output of the measuring device produces errors due to 
small, erratic phenomena in the device. Since there always are such sources 
of error in real systems, one must take them into account. To illustrate this, 
consider a measuring device whose overall output can be modeled as the sum 
of the response of the measuring device characterized by eq. (P4.52-1) and 
an interfering "noise" signal n(t). Such a model is depicted in Figure P4.52(a), 
where we have also included the inverse system of part (a), which now has as its 
input the overall output of the measuring device. Suppose that n(t) = sin wt. 
What is the contribution of n(t) to the output of the inverse system, and how 
does this output change as w is increased? 
(c) The issue raised in part (b) is an important one in many applications of LTI 
system analysis. Specifically, we are confronted with the fundamental trade-
off between the speed of response of the system and the ability of the system 
to attenuate high-frequency interference. In part (b) we saw that this trade-
off implied that, by attempting to speed up the response of a measuring device 
(by means of an inverse system), we produced a system that would also amplify 

356 
The Continuous-Time Fourier Transform 
~ ---- ------ -- - - - - ----1 
I 
() 
I 
I 
I 
I 
I 
Actual measuring device 
n t 
I 
..... 
I 
I 
L 
I 
I 
LTI model of 
I 
measuring device 
+ 
s(t) = (1 - e - t/2) u (t) 
I 
I 
__ ____ __ _______ __ __ ! 
(a) 
r----------- - - -------1 
I 
n(t) 
I 
Inverse system 
to LTI model 
of measuring 
device 
I 
Perfect measuring 
I 
~ 
device 
)---i--+-l Compensating _____.. 
J 
s(t) = u(t) 
I 
system 
L ____ ______________ _ J 
(b) 
Figure P4.52 
Chap. 4 
corrupting sinusoidal signals. To illustrate this concept further, consider a mea-
suring device that responds instantaneously to changes in temperature, but that 
also is corrupted by noise. The response of such a system can be modeled, as 
depicted in Figure P4.52(b ), as the sum of the response of a perfect measuring 
device and a corrupting signal n(t). Suppose that we wish to design a compen-
satory system that will slow down the response to actual temperature variations, 
but also will attenuate the noise n(t). Let the impulse response of this system 
be 
h(t) = ae -at u(t). 
Choose a so that the overall system of Figure P4.52(b) responds as quickly 
as possible to a step change in temperature, subject to the constraint that the 
amplitude of the portion of the output due to the noise n(t) = sin 6t is no larger 
than 1/4. 
4.53. As mentioned in the text, the techniques of Fourier analysis can be extended to 
signals having two independent variables. As their one-dimensional counterparts do 
in some applications, these techniques play an important role in other applications, 
such as image processing. In this problem, we introduce some of the elementary 
ideas of two-dimensional Fourier analysis. 
Let x(t1, t2) be a signal that depends upon two independent variables t1 and 
tz. The two-dimensional Fourier transform of x(t1, tz) is defined as 
X(jw1,jwz) = J_+"'"' J_+"'"' x(tJ , tz)e- j(w 111 +w212ldtldtz. 
(a) Show that this double integral can be performed as two successive one-
dimensional Fourier transforms, first in t1 with t2 regarded as fixed and then 
in tz. 

Chap. 4 Problems 
357 
(b) Use the result of part (a) to determine the inverse transform-
that is, an expres-
sion for x(t,, tz) in terms of X(jw,, }wz). 
(c) Determine the two-dimensional Fourier transforms of the following signals: 
(i) x(t,, tz) = e-c, +212 u(t, - 1)u(2 - tz) 
•• 
{ e- lttl- ltzl, 
if -1 < t 1 :5 1 and -1 :5 tz :5 1 
(n) x(t,, tz) = 
O, 
otherwise 
..• 
_ { e-lctl- ltzl, 
if 0 ::;; t 1 ::;; 1 or 0 ::;; t2 ::;; 1 (or both) 
(m) x(t,, tz) -
0 
h 
. 
, 
ot erwtse 
(iv) x(t1, tz) as depicted in Figure P4.53. 
(v) e- lc, +t2Hr, - rzl 
-1 
-1 
x (t1, t:J = 1 in shaded area 
and 0 outside 
Figure P4.53 
(d) Determine the signal x(t1, t2) whose two-dimensional Fourier transform is 
X(jw,, }wz) = 4 
2~ o(wz - 2w,). 
+)WI 
(e) Let x(t1, t2) and h(t1, t2) be two signals with two-dimensional Fourier trans-
forms X(jw 1, jw2) and H(jw 1, jw2), respectively. Determine the transforms 
of the following signals in terms of X(jw 1, jw2) and H(jw 1, }wz): 
(i) x(t, - T,, tz - Tz) 
(ii) x(at,, btz) 
(iii) y(t,, tz) = C,,"" C,"" x( 'TJ, Tz)h(t, -
'TJ, tz - Tz) dr, d 'Tz 

5 
THE DISCRETE-TIME FOURIER 
TRANSFORM 
5.0 INTRODUCTION 
358 
In Chapter 4, we introduced the continuous-time Fourier transform and developed the 
many characteristics of that transform which make the methods of Fourier analysis of 
such great value in analyzing and understanding the properties of continuous-time signals 
and systems. In the current chapter, we complete our development of the basic tools of 
Fourier analysis by introducing and examining the discrete-time Fourier transform. 
In our discussion of Fourier series in Chapter 3, we saw that there are many similari-
ties and strong parallels in analyzing continuous-time and discrete-time signals. However, 
there are also important differences. For example, as we saw in Section 3.6, the Fourier 
series representation of a discrete-time periodic signal is a finite series, as opposed to the 
infinite series representation required for continuous-time periodic signals. As we will see 
in this chapter, there are corresponding differences between continuous-time and discrete-
time Fourier transforms. 
In the remainder of the chapter, we take advantage of the similarities between 
continuous-time and discrete-time Fourier analysis by following a strategy essentially 
identical to that used in Chapter 4. In particular, we begin by extending the Fourier se-
ries description of periodic signals in order to develop a Fourier transform representation 
for discrete-time aperiodic signals, and we follow with an analysis of the properties and 
characteristics of the discrete-time Fourier transform that parallels that given in Chap-
ter 4. By doing this, we not only will enhance our understanding of the basic concepts of 
Fourier analysis that are common to both continuous and discrete time, but also will con-
trast their differences in order to deepen our understanding of the distinct characteristics 
of each. 

Sec. 5.1 
Representation of Aperiodic Signals: The Discrete-Time Fourier Transform 
359 
5. 1 REPRESENTATION OF APERIODIC SIGNALS: 
THE DISCRETE-TIME FOURIER TRANSFORM 
5.1.1 Development of the Discrete-Time Fourier Transform 
In Section 4.1 [eq. (4.2) and Figure 4.2], we saw that the Fourier series coefficients for a 
continuous-time periodic square wave can be viewed as samples of an envelope function 
and that, as the period of the square wave increases, these samples become more and 
more finely spaced. This property suggested representing an aperiodic signal x(t) by first 
constructing a periodic signal x(t) that equaled x(t) over one period. Then, as this period 
approached infinity, x(t) was equal to x(t) over larger and larger intervals of time, and the 
Fourier series representation for x(t) converged to the Fourier transform representation for 
x(t). In this section, we apply an analogous procedure to discrete-time signals in order to 
develop the Fourier transform representation for discrete-time aperiodic sequences. 
Consider a general sequence x[ n] that is of finite duration. That is, for some integers 
N 1 and N2, x[n] = 0 outside the range -N1 :5 n :5 N2. A signal of this type is illustrated 
in Figure 5.1(a). From this aperiodic signal, we can construct a periodic sequence x[n] for 
which x[n] is one period, as illustrated in Figure 5.1(b). As we choose the period N to be 
larger, x[n] is identical to x[n] over a longer in}erval, and as N ~ oo, x[n] = x[n] for any 
finite value of n. 
Let us now examine the Fourier series representation of x[n]. Specifically, from eqs. 
(3.94) and (3.95), we have 
x[n] = L akejk(2'1TIN)n, 
k = (N) 
x[n] 
......... riiirtiriifiir ........ . 
0 
(a) 
x[n] 
... riiirttriiliir ...... riiirt!riiliir ...... riiiitrriillrr. .. . 
-N 
0 
N 
(b) 
Figure 5.1 
(a) Finite-duration signal x[n]; (b) periodic signal x[n] con-
structed to be equal to x[n] over one period. 
(5.1) 
n 
n 

360 
The Discrete-Time Fourier Transform 
ak =. ~ L i[n]e- jk(2'TTIN)n. 
n=(N) 
Chap.5 
(5.2) 
Since x[n] = i[n] over a period that includes the interval - N 1 :::; n :::; N2, it is 
convenient to choose the interval of summation in eq. (5.2) to include this interval, so that 
i[n] can be replaced by x[n] in the summation. Therefore, 
1 
Nz 
. 
1 
+oo 
. 
ak = N L x[n]e- Jk(2'TT!N)n = N L x[n]e- Jk(2'TT!N)n, 
(5.3) 
n= - N1 
n= -oo 
where in the second equality in eq. (5.3) we have used the fact that x[n] is zero outside 
the interval -Nl :::; n :::; N2. Defining the function 
+oo 
X(ejw) = L x[n]e- jwn, 
(5.4) 
n = - oo 
we see that the coefficients ak are proportional to samples of X(ejw), i.e., 
1 
"k 
ak = NX(el wo), 
(5.5) 
where w0 = 27r/N is the spacing of the samples in the frequency domain. Combining eqs. 
(5.1) and (5.5) yields 
Since w0 = 27r/N, or equivalently, liN = w0!27r, eq. (5.6) can be rewritten as 
i[n] = _1_ L X(ejkwo)ejkwonwo. 
27r k=(N) 
(5.6) 
(5.7) 
As with eq. (4.7), as N increases w 0 decreases, and as N ~ oo eq. (5.7) passes to 
an integral. To see this more clearly, consider X(ejw)ejwn as sketched in Figure 5.2. From 
Figure 5.2 
Graphical interpretation 
of eq. (5.7). 

Sec. 5.1 
Representation of Aperiodic Signals: The Discrete-Time Fourier Transform 
361 
eq. (5.4), X(ejw) is seen to be periodic inw with period 27T, and so is ejwn. Thus, the product 
X(ejw)ejwn will also be periodic. As depicted in the figure, each term in the summation 
in eq. (5.7) represents the area of a rectangle of height X(ejkwo)ejwon and width w0 . As 
wo ~ 0, the summation becomes an integral. Furthermore, since the summation is carried 
out over N consecutive intervals of width w0 = 27T/N, the total interval of integration will 
always have a width of 21T. Therefore, as N ~ oo, i[n] = x[n], and eq. (5.7) becomes 
x[n] = -
X(elw)e1wn dw, 
1 f . . 
21T 2-rr 
where, since X(ejw)ejwn is periodic with period 27T, the interval of integration can be taken 
as any interval of length 27T. Thus, we have the following pair of equations: 
x[n] = -
X(e1w)e;wn dw, 
1 f . . 
21T 
2-rr 
(5.8) 
+oo 
X(ejw) = L x[n]e- jwn. 
(5.9) 
n= - co 
Equations (5.8) and (5.9) are the discrete-time counterparts of eqs. (4.8) and (4.9). 
The function X(ejw) is referred to as the discrete-time Fourier transform and the pair of 
equations as the discrete-time Fourier transform pair. Equation (5.8) is the synthesis equa-
tion, eq. (5.9) the analysis equation. Our derivation of these equations indicates how an 
aperiodic sequence can be thought of as a linear combination of complex exponentials. 
In particular, the synthesis equation is in effect a representation of x[n] as a linear com-
bination of complex exponentials infinitesimally close in frequency and with amplitudes 
X(ejw)(dwi21T). For this reason, as in continuous time, the Fourier transform X(ejw) will 
often be referred to as the spectrum of x[n], because it provides us with the information 
on how x[n] is composed of complex exponentials at different frequencies. 
Note also that, as in continuous time, our derivation of the discrete-time Fourier 
transform provides us with an important relationship between discrete-time Fourier series 
and transforms. In particular, the Fourier coefficients ak of a periodic signal i[n] can be 
expressed in terms of equally spaced samples of the Fourier transform of a finite-duration, 
aperiodic signal x[n] that is equal to i[n] over one period and is zero otherwise. This fact 
is of considerable importance in practical signal processing and Fourier analysis, and we 
look at it further in Problem 5.41. 
As our derivation indicates, the discrete-time Fourier transform shares many sim-
ilarities with the continuous-time case. The major differences between the two are the 
periodicity of the discrete-time transform X(ejw) and the finite interval of integration in 
the synthesis equation. Both of these stem from a fact that we have noted several times be-
fore: Discrete-time complex exponentials that differ in frequency by a multiple of 21T are 
identical. In Section 3.6 we saw that, for periodic discrete-time signals, the implications 
of this statement are that the Fourier series coefficients are periodic and that the Fourier 
series representation is a finite sum. For aperiodic signals, the analogous implications are 
that X(ejw) is periodic (with period 27T) and that the synthesis equation involves an inte-. 
gration only over a frequency interval that produces distinct complex exponentials (i.e., 
any interval of length 27T). In Section 1.3.3, we noted one further consequence of the pe-

362 
The Discrete-Time Fourier Transform 
Chap. 5 
riodicity of ejwn as a function of w: w = 0 and w = 27T yield the same signal. Signals 
·at frequencies near these values or any other even multiple of 7T are slowly varying and 
therefore are all appropriately thought of as low-frequency signals. Similarly, the high 
frequencies in discrete time are the values of w near odd multiples of 7T. Thus, the signal 
x1 [n] shown in Figure 5.3(a) with Fourier transform depicted in Figure 5.3(b) varies more 
slowly than the signal x2[n] in Figure 5.3(c) whose transform is shown in Figure 5.3(d). 
X1(ei"') 
x1[n] 
I\ I L \ 
I I 
I I dJ 
I 
0 
n 
- 2'1T 
-
'IT 
0 
'IT 
2'1T 
(a) 
(b) 
I 
I ' 
I 
I I 
I 
n 
(c) 
(d) 
Figure 5.3 
(a) Discrete-time signal x1 [n]. (b) Fourier transform of x1 [n]. 
Note that X1(ei"') is concentrated near w = 0, ± 21T, ±41T, .. .. (c) Discrete-
time signal x2[n]. (d) Fourier transform of x2[n]. Note that X2(ei"') is concen-
trated near w = ±1r, ±31T, ... . 
5.1.2 Examples of Discrete-Time Fourier Transforms 
To illustrate the discrete-time Fourier transform, let us consider several examples. 
Example 5.1 
· · Consider the signal 
x[n] = a"u[n], 
lal < 1. 
' 
w 
w 

Sec. 5.1 
Representation of Aperiodic Signals: The Discrete-Time Fourier Transform 
363 
In this case, 
+<» 
X(ej"') = L anu[n]e- jwn 
n =-oo 
The magnitude and phase of X(ej"') are shown in Figure 5.4(a) for a > 0 and in Fig-
ure 5.4(b) for a < 0. Note that all of these functions are periodic in w with period 27T. 
w 
(a) 
IX(eiil 
~ 
1 - a 
- 21T 
0 
<l: X(eij 
tan - l (lalf/1 - a2)........._ 
1T 
21T 
w 
Figure 5.4 
Magnitude and phase of the Fourier transform of Example 5.1 
for (a) a> 0 and (b) a< 0. 

364 
Example 5.2 
Let 
The Discrete-Time Fourier Transform 
x[n] = al"l, 
lal < 1. 
Chap.5 
This signal is sketched for 0 <a < 1 in Figure 5.5(a). Its Fourier transform is obtained 
from eq. (5.9): 
+oo 
X(ejw) = L al"le- jwn 
n = - oo 
00 
- 1 
= 2:a"e- jwn + 2:: a-"e-jwn. 
n=O 
n=- oo 
x[n] 
X(ei"') 
(1 +a)/(1 - a) 
(b) 
n 
Figure 5.5 
(a) Signal x[n] = aJnl of Example 5.2 and (b) its Fourier trans-
form (0 < a < 1 ). 

Sec. 5.1 
Representation of Aperiodic Signals: The Discrete-Time Fourier Transform 
365 
Making the substitution of variables m = - n in the second summation, we obtain 
00 
00 
X(ejw) = _2)ae- jwy• + 2.)aejw)m. 
n=O 
m = l 
Both of these summations are infinite geometric series that we can evaluate in closed 
form, yielding 
1 
aejw 
.,.--------,.,.- + 
. 
1 - ae ;w 
1 - aeJw 
1 - a2 
1 - 2a cos w + a2 • 
In this case, X(ejw) is real and is illustrated in Figure 5.5(b), again for 0 < a < 1. 
Example 5.3 
Consider the rectangular pulse 
x[n] = { ~: 
which is illustrated in Figure 5.6(a) for N 1 = 2. In this case, 
Nl 
X(ejw) = L, e- jwn. 
n = - N 1 
x[n] 
.................. IIiii ................. . 
- N1 0 N1 
n 
(a) 
(b) 
Figure 5.6 
(a) Rectangular pulse signal of Example 5.3 for N1 = 2 and 
(b) its Fourier transform. 
(5.10) 
(5.11) 

366 
The Discrete-Time Fourier Transform 
Chap. 5 
Using calculations similar to those employed in obtaining eq. (3.104) in Example 3.12, 
we can write 
. 
sinw (N, + ~) 
X(elw ) = 
sin(w/2) 
. 
(5.12) 
This Fourier transform is sketched in Figure 5.6(b) for N 1 = 2. The function in eq. (5.12) 
is the discrete-time counterpart of the sine function, which appears in the Fourier trans-
form of the continuous-time rectangular pulse (see Example 4.4). An important differ-
ence between these two functions is that the function in eq. (5.12) is periodic with period 
27T, whereas the sine function is aperiodic. 
5.1.3 Convergence Issues Associated 
with the Discrete-Time Fourier; Transform 
Although the argument we used to derive the discrete-time Fourier transform in Sec-
tion 5.1.1 was constructed assuming that x[n] was of arbitrary but finite duration, eqs. 
(5.8) and (5.9) remain valid for an extremely broad class of signals with infinite duration 
(such as the signals in Examples 5.1 and 5.2). In this case, however, we again must con-
sider the question of convergence of the infinite summation in the analysis equation (5.9). 
The conditions on x[n] that guarantee the convergence of this sum are direct counterparts 
of the convergence conditions for the continuous-time Fourier transform. 1 Specifically, 
eq. (5.9) will converge either if x[n] is absolutely summable, that is, 
+ oo L lx[n]l < oo, 
(5.13) 
n= -oo 
or if the sequence has finite energy, that is, 
+oo L lx[n]il < oo. 
(5.14) 
n= - oo 
In contrast to the situation for the analysis equation (5.9), there are generally no 
convergence issues associated with the synthesis equation (5.8), since the integral in this 
equation is over a finite interval of integration. This is very much the same situation as 
for the discrete-time Fourier series synthesis equation (3.94), which involves a finite sum 
and consequently has no issues of convergence associated with it either. In particular, 
if we approximate an aperiodic signal x[n] by an integral of complex exponentials with 
frequencies taken over the intervallwl ::; W, i.e., 
1 Jw 
. . 
x[n] = -
X(e1w)eJWn dw, 
27T - w 
(5.15) 
1 For discussions of the vmvergence issues associated with the discrete-time Fourier transform, see A. V. 
Oppenheim and R. W. Schafer, Discrete-Time Signal Processing (Englewood Cliffs, NJ: Prentice-Hall, Inc., 
1989), and L. R. Rabiner and B. Gold, Theory and Application of Digital Signal Processing (Englewood Cliffs, 
NJ: Prentice-Hall, Inc., 1975). 

Sec. 5.2 
The Fourier Transform for Periodic Signals 
367 
then x[n] = x[n] for W = 7T. Thus, much as in Figure 3.18, we would expect not to see 
any behavior like the Gibbs phenomenon in evaluating the discrete-time Fourier transform 
synthesis equation. This is illustrated in the following example. 
Example 5.4 
Let x[n] be the unit impulse; that is, 
x[n] = ll[n]. 
In this case the analysis equation (5.9) is easily evaluated, yielding 
In other words, just as in continuous time, the unit impulse has a Fourier transform repre-
sentation consisting of equal contributions at all frequencies. If we then apply eq. (5.15) 
to this example, we obtain 
A[ ] _ 
1 f w 
jwll d 
_ sin W n 
xn--
e 
w -
-
-
. 
21T - w 
1Tn 
(5.16) 
This is plotted in Figure 5.7 for several values of W. As can be seen, the frequency of the 
oscillations in the approximation increases as W is increased, which is similar to what we 
observed in the continuous-time case. On the other hand, in contrast to the continuous-
time case, the amplitude of these oscillations decreases relative to the magnitude of x[O] 
as W is increased, and the oscillations disappear entirely for W = 1T. 
5.2 THE FOURIER TRANSFORM FOR PERIODIC SIGNALS 
As in the continuous-time case, discrete-time periodic signals can be incorporated within 
the framework of the discrete-time Fourier transform by interpreting the transform of a 
periodic signal as an impulse train in the frequency domain. To derive the form of this 
representation, consider the signal 
(5.17) 
In continuous time, we saw that the Fourier transform of eiwot can be interpreted as an 
impulse at w = w0 . Therefore, we might expect the same type of transform to result for 
the discrete-time signal of eq. (5.17). However, the discrete-time Fourier transform must 
be periodic in w with period 27T. This then suggests that the Fourier transform of x[n] in 
eq. (5.17) should have impulses at w 0, w 0 ± 27T, w 0 ± 47T, and so on. In fact, the Fourier 
transform of x[n] is the impulse train 
+oo 
X(eiw) = .2: 27T8(w- wo - 27Tl), 
(5.18) 
I= - oo 

w 
c-eo 
x[n] 
w = 'IT/4 
4--......... 
1 j 
•..• .•..• ..rJ Jr.. • ..•.••••..•. 
• 
••• 
••• 
0 
••• 
n 
(a) 
x[n] 
I 
1 2 
(c) 
x[n] 
7 8 
(e) 
w = 'IT/2 
w = 7'IT/8 
n 
x[n] 
w = 37r/8 
. .. rfirr .................. " 
• •••• •••• •••• .,. 0 
' 
(b) 
x[n] 
w = 37r/4 
3 
4 
(d) 
x[n] 
0 
(f) 
W='IT 
Figure s. 7 
Approximation to the unit sample obtained as in eq. (5.16) using complex 
exponentials with frequencies lwl ::; W: (a) W = 7T/4; (b) W = 37T/8; (c) W = 7T/2; 
(d) W = 37T/4; (e) W = 7 7T/8; (f) W = 7T. Note that for W = 'IT, x[n] = 8[n]. 
n 
n 

Sec. 5.2 
The Fourier Transform for Periodic Signals 
369 
which is illustrated in Figure 5.8. In order to check the validity of this expression, we must 
evaluate its inverse transform. Substituting eq. (5.18) into the synthesis equation (5.8), we 
find that 
1f 
0 
0 
1f
~ 
0 
-
X(e1w)e1wn dw = -
L..., 27T 8(w - wo - 27Tl)e1wn dw. 
27T 27T 
27T 27Tf = - oo 
. 
211' 
w 
Figure 5.8 
Fourier transform of 
x(n] = eiwon. 
Note that any interval of length 27T includes exactly one impulse in the summation given 
in eq. (5.18). Therefore, if the interval of integration chosen includes the impulse located 
at wo + 27Tr, then 
Now consider a periodic sequence x[n] with period Nand with the Fourier series 
representation 
x[n] = L akejk(27TIN)n. 
k = (N ) 
In this case, the Fourier transform is 
(5.19) 
(5.20) 
so that the Fourier transform of a periodic signal can be directly constructed from its 
Fourier coefficients. 
To verify that eq. (5.20) is in fact correct, note that x[n] in eq. (5.19) is a linear 
combination of signals of the form in eq. (5.17), and thus the Fourier transform of x[n] 
must be a linear combination of transforms of the form of eq. (5.18). In particular, suppose 
that we choose the interval of summation in eq. (5.19) ask = 0, 1, . . . , N- 1, so that 
x[n] = ao + alej(27TIN)n + a 2e j 2(27TIN)n 
+ ... + aN- lej(N- 1)(27TIN)n. 
(5.21) 

370 
The Discrete-Time Fourier Transform 
Chap.5 
Thus, x[n] is a linear combination of signals, as in eq. (5.17), with w0. = 0, 21TIN, 
41TIN, ... , (N - 1)27T/N. The resulting Fourier transform is illustrated in Figure 5.9. 
In Figure 5.9(a), we have depicted the Fourier transform of the first term on the right-hand 
side of eq. (5.21): The Fourier transform of the constant signal a0 = a0ejO·n is a periodic 
impulse train, as in eq. (5.18), with wo = 0 and a scaling of21Tao on each of the impulses. 
Moreover, from Chapter 4 we know that the Fourier series coefficients ak are periodic 
with period N, so that 21Tao = 21TaN = 21Ta- N. In Figure 5.9(b) we have illustrated the 
Fourier transform of the second term in eq. (5.21), where we have again used eq. (5.18), 
2'1T8o = 2'1Ta_N 
2'1Ta0 
2'1T8o = 2'1TaN 
1 
1 
1 
2'1T 
0 
2'1T 
(a) 
2'1Ta1 = 2'1Ta_N + 1 
2'1Ta1 
2'1Ta1 = 2'1TaN + 1 
t 
t 
t 
( (- N + 1) 2r:) 
( 2r:) 
((N + 1) 2r:) 
(b) 
( (-N - 1) 2r: ) 
(-
2r:) 
( (N- 1) 2r:) 
+ 
+ 
+ 
2'1TaN_1 = 2'1Ta_N- 1 
2'1TaN_1 = 2'1Ta_1 
2'1TaN - 1 
(c) 
2'1Ta_N 
2'1Ta0 
2'1TaN 
2'1Ta_N+1 
2'1Ta1 
2'1TaN+1 
(d) 
Figure 5.9 
Fourier transform of a discrete-time periodic signal: (a) Fourier transform 
of the first term on the right-hand side of eq. (5.21 ); (b) Fourier transform of the sec-
ond term in ~q. (5.21 ); (c) Fourier transform of the last term in eq. (5.21 ); (d) Fourier 
transform of x(n] in eq (5.21 ). 
w 
w 
w 
w 

Sec. 5.2 
The Fourier Transform for Periodic 'Signals 
371 
in this case for a 1ej(27TIN}n, and the fact that 21ra 1 = 21raN+l = 2'1ra - N + l · Similarly, 
Figure 5.9(c) depicts the final term. Finally, Figure 5.9(d) depicts the entire expression 
for X(ejw). Note that because of the periodicity of the ak, X(ejw) can be interpreted as 
a train of impulses occurring at multiples of the fundamental frequency 2TTIN, with the 
area of the impulse located at w = 27Tk/N being 27Tab which is exactly what is stated in 
eq. (5.20). 
Example 5.5 
Consider the periodic signal 
From eq. (5.18), we can immediately write 
That is, 
27T 
with 
Wo = s · 
- 1T :S w < 1T, 
and X(ejw ) repeats periodically with a period of 27T, as illustrated in Figure 5.10. 
X(eiw) 
I 
'IT 
1 I 1 
1 1 
1 I 1 
t 
- 2'11' t 
- wo 
0 
wo 
t 
2'11' t 
(- 2'11'- wo) (- 2'1T+wo) 
(2'11'- w0) 
(2'1T+ wo) 
Figure 5.1 o Discrete-time Fourier transform of x[n] = cos won. 
Example 5.6 
(5.22) 
(5.23) 
(5.24) 
w 
The discrete-time counterpart of the periodic impulse train of Example 4.8 is the se-
quence 
+oo 
x [n] = L, 8[n - kN], 
(5.25) 
k = -
00 
as sketched in Figure 5.1l(a). The Fourier series coefficients for this signal can be cal-
culated directly from eq. (3.95): 
ak = ~ L x [n]e- jk(21TIN)". 
11 =(N) 

372 
The Discrete-Time Fourier Transform 
Chap. 5 
Choosing the interval of summation as 0 :s n :s N - 1, we have 
(5.26) 
Using eqs. (5.26) and (5.20), we can then represent the Fourier transform of the signal 
as 
(5.27) 
which is illustrated in Figure 5.11(b). 
x[n] 
... l 
11 
l 
l 
... 
•••• ••••••••• ••••••••• ••••••••• ••••••• 
- N 
0 
N 
2N 
n 
(a) 
X(ei"') 
21r1N 
w 
(b) 
Figure 5.11 
(a) Discrete-time periodic impulse train; (b) its Fourier 
transform. 
5.3 PROPERTIES OF THE DISCRETE-TIME FOURIER TRANSFORM 
As with the continuous-time Fourier transform, a variety of properties of the discrete-time 
Fourier transform provide further insight into the transform and, in addition, are often 
useful in reducing the complexity in the evaluation of transforms and inverse transforms. 
In this and the following two sections we consider these properties, and in Table 5.1 we 
present a concise summary of them. By comparing this table with Table 4.1, we can 
get a clear picture of some of the similarities and differences between continuous-time 
and discrete-time Fourier transform properties. When the derivation or interpretation of 
a discrete-time Fourier transform property is essentially identical to its continuous-time 
counterpart, we will simply state the property. Also, because of the close relationship 
between the Fourier series and the Fourier transform, many of the transform properties 

Sec. 5.3 
Properties of the Discrete-Time Fourier Transform 
313 
translate directly into corresponding properties for the discrete-time Fourier series, which 
we summarized in Table 3.2 and briefly discussed in Section 3.7. 
In the following discussions, it will be convenient to adopt notation similar to that 
used in Section 4.3 to indicate the pairing of a signal and its transform. That is, 
X(eiw) = ~{x[n]}, 
x[n] = ~ -
1 {X(eiw)}, 
~ 
. 
x[n] ~ 
X(e1w). 
5.3.1 Periodicity of the Discrete-Time Fourier Transform 
As we discussed in Section 5.1, the discrete-time Fourier transform is always periodic in 
w with period 27T; i.e., 
(5.28) 
This is in contrast to the continuous-time Fourier transform, which in general is not peri-
odic. 
5.3.2 Linearity of the Fourier Transform 
If 
and 
then 
5.3.3 Time Shifting and Frequency Shifting 
If 
~ 
. 
x[n] ~ 
X(elw), 
then 
(5.29) 
(5.30) 

374 
The Discrete-Time Fourier Transform 
Chap.S 
and 
(5.31) 
Equation (5.30) can be obtained by direct substitution of x[n - n0] into the analysis equa-
tion (5.9), while eq. (5.31) is derived by substituting X(ej(w- wol) into the synthesis equa-
tion (5.8). 
As a consequence of the periodicity and frequency-shifting properties of the discrete-
time Fourier transform, there exists a special relationship between ideallowpass and ideal 
highpass discrete-time filters. This is illustrated in the next example. 
Example 5.7 
In Figure 5.12(a) we have depicted the frequency response H1p(ejw) of a lowpass filter 
with cutoff frequency We, while in Figure 5.12(b) we have displayed H1p(ej(w- 11"))-that 
is, the frequency response H1p(ejw) shifted by one-half period, i.e., by 11". Since high 
frequencies in discrete time are concentrated near 1r (and other odd multiples of 1r), the 
filter in Figure 5.12(b) is an ideal highpass filter with cutoff frequency 1r- we. That is, 
(5.32) 
As we can see from eq. (3.122), and as we will discuss again ih Section 5.4, the 
frequency response of an LTI system is the Fourier transform of the impulse response 
of the system. Thus, if h1p[n] and hhp[n] respectively denote the impulse responses of 
0 
I 
d; H,,(.,.., 
0 
- 21T 
-"IT 
-we 
We 
1T 
21T 
w 
(a) 
Hlp(ei(w- ")) 
I 
q 
+1 p 
I 
-21T 
-"IT 
\ 
21T 
w 
-("IT-we) 
("IT-we) 
(b) 
Figure 5.12 
(a) Frequency response of a lowpass filter; (b) frequency re-
sponse of a highpass filter obtained by shifting the frequency response in (a) 
by w = 1r corresponding to one-half period. 

Sec. 5.3 
Properties of the Discrete-Time Fourier Transform 
The lowpass and highpass filters in Figure 5.12, then eq. (5.32) 
and the frequency-shifting property imply that 
hhp[n] = eJ1Tnhlp[n] 
= (- l)"hlp[n]. 
5.3.4 Conjugation and Conjugate Symmetry 
If 
then 
Also, if x[n] is real valued, its transform X(ejw) is conjugate symmetric. That is, 
I X(ejw) = X*(e - jw) 
[x[n]real]. I 
375 
(5.33) 
(5.34) 
(5.35) 
(5.36) 
From this, it follows that ffie{X(ejw)} is an even function of w and dm{X(ejw)} is an odd 
function of w. Similarly, the magnitude of X(ejw) is an even function and the phase angle 
is an odd function. Furthermore, 
n: 
. 
8v{x[n]} ~ 
ffie{X(elw )} 
and 
n: 
. 
0d{x[n]} ~ 
jdm{X(elw)}, 
where 8v and 0d denote the even and odd parts, respectively, of x[n]. For example, if x[n] 
is real and even, its Fourier transform is ah real and even. Example 5.2 illustrates this 
symmetry for x[n] = alnl. 
5.3.5 Differencing and Accumulation 
In this subsection, we consider the discrete-time counterpart of integration-that is, 
accumulation-and its inverse, first differencing. Let x[n] be a signal with Fourier trans-
form X(ejw). Then, from the linearity and time-shifting properties, the Fourier transform 
pair for the first-difference signal x[n] - x[n - 1] is given by 
n: 
. 
. 
x[n] - x[n - 1] ~ 
(1 - e-;w)X(elw). 
(5.37) 

376 
The Discrete-Time Fourier Transform 
Chap.5 
Next, consider the signal 
n 
y[n] = .2:: x[m]. 
(5.38) 
m = - oo 
Since y[n] - y[n - 1] = x[n], we might conclude that the transform of y[n] should be 
related to the transform of x[n] by division by (1 - e- jw). This is partly correct, but as 
with the continuous-time integration property given by eq. (4.32), there is more involved. 
The precise relationship is 
n 
:y 
1 
+oo 
""' x[m] ~ 
1 
_ . X(ejw) + 7TX(ej0) ""' 8(w- 27Tk). 
L 
-e 1w 
L 
m =-oo 
k = - oo 
(5.39) 
The impulse train on the right-hand side of eq. (5.39) reflects the de or average value that 
can result from summation. 
Example 5.8 
Let us derive the Fourier transform X(ejw) of the unit step x[n] = u[n] by making use 
of the accumulation property and the knowledge that 
no 
. 
g[n] = 8[n] ~ 
G(e'w) = 1. 
From Section 1.4.1 we know that the unit step is the running sum of the unit impulse. 
That is, 
n 
x[n] = L g[m]. 
nr = - oo 
Taking the Fourier transform of both sides and using accumulation yields 
X(ejw) = 
1 . G(ejw) + 1rG(ej0 ) i 8(w - 21Tk) 
(1- e- 'w) 
k = - oo 
1 
00 ' 
= 1- rjw + 1T k~oo 8(w - 21Tk). 
5.3.6 Time Reversal 
Let x[n] be a signal with spectrum X(ejw), and consider the transform Y(ejw) of y[n] = 
x[ - n]. From eq. (5.9), 
+ oo 
+oo 
Y(ejw) = .2:: y[n]e- jwn = .2:: x[ - n]e- jwn. 
(5.40) 
n= -oo 
n = - oo 
Substituting m = -n into eq. (5.40), we obtain 
+ oo 
Y(ejw) = .2:: x[m]e- j(- w)m = X(e- jw). 
(5.41) 
m = - oo 

Sec. 5.3 
Properties of the Discrete-Time Fourier Transform 
377 
That is, 
(5.42) 
5.3.7 Time Expansion 
Because of the discrete nature of the time index for discrete-time signals, the relation be-
tween time and frequency scaling in discrete time takes on a somewhat different form from 
its continuous-time counterpart. Specifically, in Section 4.3.5 we derived the continuous-
time property 
a= 
1 (jw) 
x(at) ~ 
~X --;; . 
(5.43) 
However, if we try to define the signal x[an] , we run into difficulties if a is not an integer. 
Therefore, we cannot slow down the signal by choosing a < 1. On the other hand, if we 
let a be an integer other than ± 1- for example, if we consider x[2n ]-we do not merely 
speed up the original signal. That is, since n can take on only integer values, the signal 
x[2n] consists of the even samples of x[n] alone. 
There is a result that does closely parallel eq. (5.43), however. Let k be a positive 
integer, and define the signal 
[ ] _ { x[nlk], 
if n is a multiple of k 
X(k) n -
0 , 
if n is not a multiple of k. 
(5.44) 
As illustrated in Figure 5.13 fork = 3, X(k)[n] is obtained from x [n] by placing k- 1 zeros 
between successive values of the original signal. Intuitively, we can think of x(k)[n] as a 
slowed-down version of x[n]. Since X(k) [n] equals 0 unless n is a multiple of k, i.e., unless 
n = rk, we see that the Fourier transform of xck)[n] is given by 
+ oo 
+ oo 
x (k)(ejw) = L X(k)[n]e- jwn = L X(k)[rk]e- jwrk. 
n= -oo 
x[n] 
Ill!lll!Ili 
-1 
1 
I I 
x(3l[n] I 
.l .. _ 
.. l .. t •• I .... I .. t .. I .... 1. 
- 6 
- 3 
0 
3 
6 
n 
r = -oo 
Figure 5.13 
The signal x(3J[n] ob-
tained from x[n] by inserting two zeros 
between successive values of the 
n 
original signal. 

378 
The Discrete-Time Fourier Transform 
Chap.5 
Furthermore, since X(k)[rk] = x[r], we find that 
+oo 
x (k)(eiw) = L x[r]e- j(kw)r = X(eikw). 
r = - oo 
That is, 
(5.45) 
Note that as the signal is spread out and slowed down in time by taking k > 1, 
its Fourier transform is compressed. For example, since X(eiw) is periodic with period 
2TT, X(eikw) is periodic with period 2TTI k. This property is illustrated in Figure 5.14 for a 
rectangular pulse. 
x[n] 
X(ei"') 
n 
0 
n 
-
'11' 
_ JL 
JL 
'11' 
2 
2 
0 
n 
Figure 5.14 
Inverse relationship between the time and frequency domains: As k in-
creases, x(k)[n) spreads out while its transform is compressed. 
w 
w 

Sec. 5.3 
Properties of the Discrete-Time Fourier Transform 
379 
Example 5.9 
As an illustration of the usefulness of the time-expansion property in determining 
Fourier transforms, let us consider the sequence x[n] displayed in Figure 5.15(a). This 
sequence can be related to the simpler sequence y[n] depicted in Figure 5.15(b). In 
particular 
x[n] = Y(2)[n] + 2y(2)[n- 1], 
where 
[ ] _ { y[n/2], 
if n is even 
Y(2) n -
0 
· ·f 
· 
dd 
, 
· tniSO 
and Y(2)[n - 1] represents Y<2>[n] shifted one unit to the right. The signals y(2)[n] and 
2y(2)[n- 1] are depicted in Figures 5.15(c) and (d), respectively. 
Next, note that y[n] = g[n - 2], where g[n] is a rectangular pulse as considered 
in Example 5.3 (with N 1 = 2) and as depicted in Figure 5.6(a). Consequently, from 
Example 5.3 and the time-shifting property, we see that 
• 'I 'I 
0 
• 
11 I 
0 
• 
11 • 
0 
1 
• • 'I 
0 
Y( jw) = 
_ j2w sin(5w/2) 
e 
e 
sin(w/2) · 
I I I I I I I 
2 
3 
4 
5 
6 
7 
8 
(a) 
I I I • • 
y[n) 
• • 
2 
3 
4 
5 
6 
7 
8 
(b) 
I • I • I • I 
2 
3 
4 
5 
6 
7 
8 
(c) 
• I • I • I • 
2 
3 
4 
5 
6 
7 
8 
(d) 
I 
x[n) 
• • 
9 
n 
• • • 
9 
n 
Y(2)[n) 
• • • 
9 
n 
2y(2)[n - 1) 
I • • 
9 
n 
Figure 5.15 
(a) The signal x[n] in Example 5.9; (b) the signal y[n]; (c) 
the signal y(2)[n] obtained by inserting one zero between successive values of 
y[n]; and (d) the signal 2Y(2)[n- 1]. 

380 
The Discrete-Time Fourier Transform 
Using the time-expansion property, we then obtain 
!J' 
_ j4w sin(5w) 
Y(2) [n] ~ 
e 
- .-(-) , 
smw 
and using the linearity and time-shifting properties, we get 
2 
[ 
l] 
!J' 
2 - jSwsin(5w) 
Y(2) n-
~ 
e 
sin(w). 
i Combining these two results, we have 
X(ejw) = e- j4w(l + 2e- jw)(s~(5w))· 
sm(w) 
5.3.8 Differentiation in Frequency 
Again, let 
Chap.5 
If we use the definition of X(ej"') in the analysis equation (5.9) and differentiate both sides, 
we obtain 
+oo L - jnx[n]e- jwn. 
n= -oo 
The right-hand side of this equation is the Fourier transform of - jnx[n]. Therefore, mul-
tiplying both sides by j, we see that 
~ 
dX(ej"') 
nx[n] ~ 
j 
dw 
. 
(5.46) 
The usefulness of this property will be illustrated in Example 5.13 in Section 5.4. 
5.3. 9 Parseval's Relation 
If x[n] and X(ej"') are a Fourier transform pair, then 
(5.47) 
We note that this is similar to eq. (4.43), and the derivation proceeds in a similar man-
ner. The quantity on the left-hand side of eq. (5.47) is the total energy in the signal x[n], and 

Sec. 5.3 
Properties of the Discrete-Time Fourier Transform 
381 
Parseval's relation states that this energy can also be determined by integrating the energy 
per unit frequency, jX(eiw)j2!21T, over a full21T interval of distinct discrete-time frequen-
cies. In analogy with the continuous-time case, jX( eiw)j2 is referred to as the energy-density 
spectrum of the signal x[n]. Note also that eq. (5.47) is the counterpart for aperiodic sig-
nals of Parseval's relation, eq. (3.110), for periodic signals, which equates the average 
power in a periodic signal with the sum of the average powers of its individual harmonic 
components. 
Given the Fourier transform of a sequence, it is possible to use Fourier transform 
properties to determine whether a particular sequence has a number of different properties. 
To illustrate this idea, we present the following example. 
Example 5. 1 0 
Consider the sequence x[n] whose Fourier transform X(ejw) is depicted for -TT ::s 
w ::s 1r in Figure 5.16. We wish to determine whether or not, in the time domain, x[n] 
is periodic, real, even, and/or of finite energy. 
IX(ei'")l 
~L---'-----:1 ~~ . 
(a) 
(b) 
:n:. 
2 
'lT 
Figure s. 16 
Magnitude and phase of the Fourier transform for Exam-
ple 5.10. 

382 
The Discrete-Time Fourier Transform 
Chap. 5 
Accordingly, we note first that periodicity in the time domain implies that the 
Fourier transform is zero, except possibly for impulses located at various integer multi-
ples of the fundamental frequency. This is not true for X(ejw). We conclude, then, that 
x[n] is not periodic. 
Next, from the symmetry properties for Fourier transforms, we know that a real-
valued sequence must have a Fourier transform of even magnitude and a phase function 
that is odd. This is true for the given IX(ejw)l and <J::X(ejw). We thus conclude that x[n] 
is real. 
Third, if x[n] is an even function, then, by the symmetry properties for real signals, 
X(ejw) must be real and even. However, since X(ejw) = IX(ejw)ie- jZw, X(ejw) is not a 
real-valued function. Consequently, x[n] is not even. 
Finally, to test for the finite-energy property, we may use Parseval's relation, 
It is clear from Figure 5.16 that integrating IX(ejw)IZ from -7r to 7T will yield a finite 
quantity. We conclude that x[n] has finite energy. 
In the next few sections, we consider several additional properties. The first two of these 
are the convolution and multiplication properties, similar to those discussed in Sections 
4.4 and 4.5. The third is the property of duality, which is examined in Section 5.7, where 
we consider .not only duality in the discrete-time domain, but also the duality that exists 
between the continuous-time and discrete-time domains. 
5.4 THE CONVOLUTION PROPERTY 
In Section 4.4, we discussed the importance of the continuous-time Fourier transform with 
regard to its effect on the operation of convolution and its use in dealing with continuous-
time LTI systems. An identical relation applies in discrete time, and this is one of the 
principal reasons that the discrete-time Fourier transform is of such great value in repre-
senting and analyzing discrete-time LTI systems. Specifically, if x[n], h[n], and y[n] are 
the input, impulse response, and output, respectively, of an LTI system, so that 
y[n] = x[n] * h[n], 
then 
(5.48) 
where X(eiw), H(eiw), and Y(eiw) are the Fourier transforms of x[n], h[n], and y[n], re-
spectively. Furthermore, comparing eqs. (3.122) and (5.9), we see that the frequency re-
sponse of a discrete-time LTI system, as first defined in Section 3.8, is the Fourier transform 
of the impulse response of the system. 
The derivation of eq. (5.48) exactly parallels that carried out in Section 4.4. In par-
ticular, as in continuous time, the Fourier synthesis equation (5.8) for x[n] can be inter-

Sec. 5.4 
The Convolution Property 
383 
preted as a decomposition of x[n] into a linear combination of complex exponentials with 
infinitesimal amplitudes proportional to X(ejw). Each of these exponentials is an eigen-
function of the system. In Chapter 3, we used this fact to show that the Fourier series 
coefficients of the response of an LTI system to a periodic input are simply the Fourier 
coefficients of the input multiplied by the system's frequency response evaluated at the 
corresponding harmonic frequencies. The convolution property (5.48) represents the ex-
tension of this result to aperiodic inputs and outputs by using the Fourier transform rather 
than the Fourier series. 
As in continuous time, eq. (5.48) maps the convolution of two signals to the simple 
algebraic operation of multiplying their Fourier transforms, a fact that both facilitates the 
analysis of signals and systems and adds significantly to our understanding of the way in 
which an LTI system responds to the input signals that are applied to it. In particular, from 
eq. (5.48), we see that the frequency response H(ejw) captures the change in complex 
amplitude of the Fourier transform of the input at each frequency w. Thus, in frequency-
selective filtering, for example, we want H(ejw) = 1 over the range of frequencies cor-
responding to the desired passband and H(ejw) = 0 over the band of frequencies to be 
eliminated or significantly attenuated. 
5.4. 1 Examples 
To illustrate the convolution property, along with a number of other properties, we consider 
several examples in this section. 
Example 5.11 
Consider an LTI system with impulse response 
h[n] = 8[n - no]. 
The frequency response is 
+oo 
H(ejw) = L 8[n - n0]e- jwll = e- jw"o. 
n = ~ oo 
Thus, for any input x[n] with Fourier transform X(ejw), the Fourier transform of the 
output is 
(5.49) 
We note that, for this example, y[n] = x[n -
n0 ] and eq. (5.49) is consistent with the 
time-shifting property. Note also that the frequency response H(ejw) = e- jw"o of a pure 
time shift has unity magnitude at all frequencies and a phase characteristic -wn0 that is 
linear with frequency. 
Example 5.12 
Consider the discrete-time ideal lowpass filter introduced in Section 3.9.2. This sys-
tem has the frequency response H(ejw) illustrated in Figure 5.17(a). Since the impulse 

384 
The Discrete-Time Fourier Transform 
Chap.5 
response and frequency response of an LTI system are a Fourier transform pair, we can 
determine the impulse response of the ideallowpass filter from the frequency response 
using the Fourier transform synthesis equation (5.8). In particular, using - 7r :s w :s 7T 
as the interval of integration in that equation, we see from Figure 5.17(a) that 
which is shown in Figure 5.17(b). 
H(Eh 
~ 
, I 
I, 
- 2'lT 
-'IT 
-we 
0 
we 
'IT 
2'lT 
w 
(a) 
h[n] 
................ ,,,rir,,, ................ , 
(b) 
Figure s. 17 
(a) Frequency response of a discrete-time ideal lowpass filter; 
(b) impulse response of the ideallowpass filter. 
(5.50) 
In Figure 5.17, we come across many of the same issues that surfaced with the 
continuous-time idea1lowpass filter in Example 4.18. First, since h[n] is not zero for 
n < 0, the ideallowpass filter is not causal. Second, even if causality is not an important is-
sue, there are other reasons, including ease of implementation and preferable time domain 
characteristics, that nonideal filters are generally used to perform frequency-selective fil-
tering. In particular, the impulse response of the ideallowpass filter in Figure 5.17 (b) is 
oscillatory, a characteristic that is undesirable in some applications. In such cases, a trade-
off between frequency-domain objectives such as frequency selectivity and time-domain 
properties such as nonoscillatory behavior must be made. In Chapter 6, we will discuss 
these and related ideas in more detail. 
As the following example illustrates, the convolution property can also be of value 
in facilitating the calculation of convolution sums. 

Sec. 5.4 
The Convolution Property 
385 
Example 5. 1 3 
Consider an LTI system with impulse response 
h[n] = a" u[n], 
with Ia I < 1, and suppose that the input to this system is 
x[n] = Wu[n], 
with I,B I < 1. Evaluating the Fourier transforms of h[n] and x[n], we have 
and 
so that 
(5.51) 
(5.52) 
(5.53) 
As with Example 4.19, determining the inverse transform of Y(ejw) is most easily 
done by expanding Y(ejw) by the method of partial fractions. Specifically, Y(ejw) is a 
ratio of polynomials in powers of e- jw, and we would like to express this as a sum of 
simpler terms of this type so that we can find the inverse transform of each term by 
inspection (together, perhaps, with the use of the frequency differentiation property of 
Section 5.3.8). The general algebraic procedure for rational transforms is described in 
the appendix. For this example, if a ¥= ,8, the partial fraction expansion of Y(ejw) is of 
the form 
A 
B 
Y(ejw) = 
. + ~--::o-----,,.... 
1 - a e JW 
1 - ,Be Jw 
Equating the right-hand sides of eqs (5.53) and (5.54), we find that 
A= - a-
a - ,8' 
B = __ 
,8_ 
a- ,8" 
(5.54) 
Therefore, from Example 5.1 and the linearity property, we can obtain the inverse trans-
form of eq. (5.54) by inspection: 
y[n] = _a_a"u[n]- _,B_,B"u[n] 
a-,8 
a-,8 
1 
= -
-[a"+ 1u[n]- W +1u[n]]. 
a-,8 
(5.55) 
For a = ,8, the partial-fraction expansion in eq. (5.54) is not valid. However, in this 
case, 

386 . 
The Discrete-Time Fourier Transform 
Chap. 5 
which can be expressed as 
(5.56) 
As in Example 4.19, we can use the frequency differentiation property, eq. (5.46), 
together with the Fourier transform pair 
to conclude that 
"[] :f .d( 1 ) 
na u n 
+----'> Jd-
1 
_ . 
. 
w 
- ae ;w 
To account for the factor ejw, we use the time-shifting property to obtain 
(n + 1)a"+ u[n + 1] +----'> je;w-
. , 
I 
:f 
· d ( 
1 
) 
dw 1- ae- ;w 
and finally, accounting for the factor 1/a:, in eq. (5.56), we obtain 
y[n] ~ (n + 1)a"u[n + 1]. 
(5.57) 
It is worth noting that, although the right-hand side is multiplied by a step that begins 
at n = -1, the sequence (n + 1)a"u[n + 1] is still zero prior ton = 0, since the factor 
n + 1 is zero at n = - 1. Thus, we can alternatively express y[n] as 
y[n] = (n + 1)a"u[n]. 
(5.58) 
As illustrated in the next example, the convolution property, along with other Fourier 
transform properties, is often useful in analy.zing system interconnections. 
Example 5. 14 
Consid~r the system shown in Figure 5.18(a) with input x[n] and output y[n]. The LTI 
systems with frequency response H 1 p( ejw) are ideallowpass filters with cutoff frequency 
7T/4 and unity gain in the passband. 
Let us first consider the top path in Figure 5.18(a). The Fourier transform of the 
signal w 1 [n] can be obtained by noting that ( - 1)" = ejrrn so that w 1 [n] = ejrrn x[n]. 
Using the frequency-shifting property, we then obtain 
WI (ejw) = X(ej(w- rr)). 
The convolution property yields 
Wz(ejw) = HLp(ejw)X(ej(w- rr)). 
Since w3[n] = ejrr"w2[n], we can again apply the frequency-shifting property to obtain 
W3(ejw) = Wz(ej(w - rr)) 
= HLp(ej(w- rr))X(ej(w- 2rr)). 

Sec. 5.4 
The Convolution Property 
(- 1)" 
(-1)" 
x[n] 
y(n] 
(a) 
H(Eh 
I I I I I' I I I 
- 1T _ ;m 
_:!!_ 
1T 
.an. 
1T 
w 
4 
4 
4 
4 
(b) 
Figure 5.18 
(a) System interconnection for Example 5.14; (b) the overall 
frequency response for this system. 
Since discrete-time Fourier transforms are always periodic with period 27T, 
W3(ejw) = Htp(ej(w-7T))X(ejw). 
Applying the convolution property to the lower path, we get 
W4(ejw) = Htp(ejw)X(ejw). 
From the linearity property of the Fourier transform, we obtain 
Y(ejw) = W3(ejw) + W4(ejw) 
= [Htp(ej(w-7T)) + Htp(ejw)]X(ejw). 
Consequently, the overall system in Figure 5.18(a) has the frequency response 
H(ejw) = [Htp(ej(w - ")) + Htp(ejw)] 
which is shown in Figure 5.18(b). 
387 
As we saw in Example 5.7, H1p(ej<w- 7T)) is the frequency response of an ideal 
highpass filter. Thus, the overall system passes both low and high frequencies and stops 
frequencies between these two passbands. That is, the filter has what is often referred to 
as an ideal bandstop characteristic, where the stopband is the region 7T/4 < lwl < 37T/4. 
It is important to note that, as in continuous time, not every discrete-time LTI system 
has a frequency response. For example, the LTI system with impulse response h[n]. = 
2nu[n] does not have a finite response to sinusoidal inputs, which is reflected in the fact 

388 
The Discrete-Time Fourier Transform 
Chap. 5 
that the Fourier transform analysis equation for h[n] diverges. However, if an LTI system 
is stable, then, from Section 2.3.7, its impulse response is absolutely summable; that is, 
+oo 
L, lh[nll < oo. 
(5.59) 
n= - co 
Therefore, the frequency response always converges for stable systems. In using Fourier 
methods, we will be restricting ourselves to systems with impulse responses that have well-
defined Fourier transforms. In Chapter 10, we will introduce an extension of the Fourier 
transform referred to as the z-transform that will allow us to use transform techniques for 
LTI systems for which the frequency response does not converge. 
5.5 THE MULTIPLICATION PROPERTY 
In Section 4.5, we introduced the multiplication property for continuous-time signals and 
indicated some of its applications through several examples. An analogous property exists 
for discrete-time signals and plays a similar role in applications. In this section, we derive 
this result directly and give an example of its use. In Chapters 7 and 8, we will use the 
multiplication property in the context of our discussions of sampling and communications. 
Consider y[n] equal to the product of x1 [n] and x2[n], with Y(eiw), X1 (eiw), and 
X2(eiw) denoting the corresponding Fourier transforms. Then 
+oo 
+oo 
Y(eiw) = L y[n]e- Jwn = L XJ [n]xz[n]e- jwn, 
n= -oo 
n= - oo 
or since 
(5.60) 
it follows that 
(5.61) 
Interchanging the order of summation and integration, we obtain 
Y(eiw) = 2~ L1T XJ(eill)[n~oo Xz[n]e-J<w - ll)n]de. 
(5.62) 
The bracketed summation is X2(ei<w - O)), and consequently, eq. (5.62) becomes 
(5.63) 

Sec. 5.5 
The Multiplication Property 
389 
Equation (5.63) corresponds to a periodic convolution of X 1(eiw) and X2(eiw), and the 
integral in this equation can be evaluated over any interval of length 27T. The usual form 
of convolution (in which the integral ranges from - oo to + oo) is often referred to as ape-
riodic convolution to distinguish it from periodic convolution. The mechanics of periodic 
convolution are most easily illustrated through an example. 
Example 5. 15 
Consider the problem of finding the Fourier transform X(ejw) of a signal x[n] which is 
the product of two other signals; that is, 
where 
and 
[ ] 
sin(37Tn/4) 
XI n = --'---
-
7Tn 
x
2 [n] = sin(7Tn/2). 
7Tn 
From the multiplication property given in eq. (5.63), we know that X(ejw) is the periodic 
convolution of X1 (ejw) and X2(ejw), where the integral in eq. (5.63) can be taken over 
any interval of length 27T. Choosing the interval -'IT < 8:5 7T, we obtain 
(5.64) 
Equation (5.64) resembles aperiodic convolution, except for the fact that the inte-
gration is limited to the interval -
'IT < 8 :5 7T. However, we can convert the equation 
' into an ordinary convolution by defining 
for -
'IT < w :5 7T 
otherwise 
: Then, replacing X1 (ej8 ) in eq. (5.64) by X1 (ej8 ), and using the fact that X1 (ej8 ) is zero 
' for I 8 I > 7T, we see that 
X(ejw) = - 1 J 
7T X1 (ej8)X2(ej(w- O))d8 
27T 
- 7T 
= - 1- J"' X1(ej8 )X2(ej(w- O))d8. 
27T _., 
Thus, X(ejw) is l/27T times the aperiodic convolution of the rectangular pulse X1 (ejw) 
and the periodic square wave X2(ejw), both of which are shown in Figure 5.19. The result 
of this convolution is the Fourier transform X(ejw) shown in Figure 5.20. 

390 
I 
- 2'1T 
·I 
'II 
-
'lT - 2 
1-'lT 
I 
3n 
- 4 
The Discrete-Time Fourier Transform 
Chap.5 
x, (ei"') 
11 
'II 
2 
'lT 
w 
X2 (eii 
11 
I 'lT 
3n 
4 
w 
Figure 5.19 
X1 (ei"') representing one period of X1 (ei"'), and X2(ei"'). The 
linear convolution of X,(ei"') and X2(ei"') corresponds to the periodic convolu-
tion of X1 (ei"') and X2(ei"'). 
- n 
.31!_ _1I. 
_1I. 
- 4 
2 
4 
1I. 
1I. 
.31!_ 
1T 
4 
2 
4 
w 
Figure 5.20 
Result of the periodic convolution in Example 5.15. 
5.6 TABLES OF FOURIER TRANSFORM PROPERTIES 
AND BASIC FOURIER TRANSFORM PAIRS 
5.7 DUALITY 
In Table 5.1, we summarize a number of important properties of the discrete-time Fourier 
transform and indicate the section of the text in which each is discussed. In Table 5.2, we 
summarize some of the basic and most important discrete-time Fourier transform pairs. 
Many of these have been derived in examples in the chapter. 
In considering the continuous-time Fourier transform, we observed a symmetry or duality 
between the analysis equation (4.9) and the synthesis equation (4.8). No corresponding 
duality exists between the analysis equation (5.9) and the synthesis equation (5.8) for the 
discrete-time Fourier transform. However, there is a duality in the discrete-time Fourier 
series equations (3.94) and (3.95), which we develop in Section 5.7.1. In addition, there is 

Sec. 5.7 
Duality 
391 
TABLE 5.1 
PROPERTIES OF THE DISCRETE-TIME FOURIER TRANSFORM 
Section 
5.3.2 
5.3.3 
5.3.3 
5.3.4 
5.3.6 
5.3.7 
5.4 
5.5 
5.3.5 
5.3.5 
5.3.8 
5.3.4 
5.3.4 
5.3.4 
5.3.4 
5.3.9 
Property 
Aperiodic Signal 
Fourier Transform 
x[n] 
X(ei"' )} periodic with 
y[n] 
Y(ei"') period 21T 
Linearity 
ax[n] + by[n] 
aX(ei"') + bY(ei"') 
Time Shifting 
x[n -
no] 
e- Jwno X(ei"' ) 
Frequency Shifting 
e1"'•"x[n] 
X(ei<w - wo)) 
Conjugation 
x' [n] 
X'(e - i"') 
Time Reversal 
x[-n] 
X(e - 1"') 
Time Expansion 
{ x[nlk], 
if n = multiple of k 
X(e1*"') 
X(k)[n] = 0, 
if n ¥- multiple of k 
Convolution 
x[n] * y [n] 
X(ei"' )Y(ei"') 
Multiplication 
x [n]y [n] 
_!__ J X(ei9)Y(ei<w - 9))d(J 
21T 
21T 
Differencing in Time 
x[n] - x [n - 1] 
(1 - e- i"' )X(ei"') 
II 
__ 
1_ . X(ei"') 
Accumulation 
2, x[k] 
k ~-~ 
1 - e- Jw 
+ ~ 
+1TX(ei0) L o(w - 21Tk) 
k~ -~ 
Differentiation in Frequency 
nx[n] 
.dX(ei"') 
} -
-
-
dw 
r(e'") • X'(e· '") 
Conjugate Symmetry for 
(Jl.e{X(el"')} = (Jl.e{X(e-1"')} 
x[n] real 
dm{X(el"')} = - dm{X(e- 1"')} 
Real Signals 
IX(e1"')1 = IX(e-1"')1 
1:X(ei"' ) = -1:X(e - iw) 
Symmetry for Real, Even 
x[n] real an even 
X(ei"') real and even 
Signals 
Symmetry for Real, Odd 
x [n] real and odd 
X(ei"') purely imaginary and 
Signals 
odd 
Even -odd Decomposition 
Xe[n] = 8t~{x[n)} 
[x[n] real] 
<Jle{X ( ei"')} 
of Real Signals 
X0 [n] = 19d{x[n)} 
[x[n] real] 
jdm{X(ei"')} 
Parseval's Relation for Aperiodic Signals 
+~ 
1 J 
,J;~ lx[nJIZ = 21T 
2
" IX(e1"')i2dw 
a duality relationship between the discrete-time Fourier transform and the continuous-time 
Fourier series. This relation is discussed in Section 5.7.2. 
5.7.1 Duality in the Discrete-Time Fourier Series 
Since the Fourier series coefficients ak of a periodic signal x[n] are themselves a periodic 
sequence, we can expand the sequence ak in a Fourier series. The duality property for 
discrete-time Fourier series implies that the Fourier series coefficients for the periodic se-
quence ak are the values of (1/N)x[ -n] (i.e., are proportional to the values of the original 

TABLE 5.2 
BASIC DISCRETE-TIME FOURIER TRANSFORM PAIRS 
Signal 
Fourier Transform 
Fourier Series Coefficients (if periodic) 
L akejk(2n/N)n 
+~ 
( 
2 k) 
21T .~~ ako (J) -
~ 
a* 
k=(N) 
(a) 
wo 
= 2;:11 
+ ~ 
= { I, 
k = m, m:!:N,m:t2N, .. . 
eiwon 
21T L o(w - Wo - 21Tl) 
ak 
1 =-~ 
0, 
otherwise 
(b) 
~ irrational ::? 
The signal is aperiodic 
(a) 
wo 
= 2;;11 
+~ 
= U: 
k = :!: m, :!:m:!: N, :!:m:!: 2N, . . 
COS£Uon 
1T L {S(w - wo - 2TTI) + o(w + wo - 2TTI)) 
a* 
1 =-~ 
otherwise 
(b) 
!!!l1. 
irrational ::? 
The signal is aperiodic 
27T 
(a) 
wo 
= 2zr 
~ f {o(w - wo - 2TTI) - o(w + wo - 2TTI)) 
{ h 
k = r, r :!: N,r:!:2N, ... 
sin won 
ak 
= 
_J.. 
k = - r, - r:!: N, -r:!: 2N, . .. 
J 1 = - ~ 
2j' 
0, 
otherwise 
(b) 
~ irrational ::? The signal is aperiodic 
+ ~ 
{ I, 
k = 0, :tN, :!:2N, . . 
x[n) =I 
21r 2.:: o<w - 21rl) 
ak = 
otherwise 
1 = - ~ 
0, 
Periodic square wave 
{ l, 
/n/ ,;; N 1 
sin[(21Tk/N)(N1 + ~)) , k ¥ 0, :!:N, :!:2N, .. . 
x[n) = 
+~ 
( 
2 k) 
ak = 
N sin[21Tk/2N] 
0, 
N 1 < /n/ ,;; N/2 
21T .~~ ako (J) -
~ 
and 
2N1 +I 
ak = -
N-
k = 0, :!:N, :!:2N, .. . 
x[n + N] = x[n) 
+ ~ 
Z: •~~ s(w - 2~k) 
I 
L o[n - kNI 
ak = N for all k 
k = - ~ 
a"u[n), 
/a/ < I 
l 
I - ae jw 
-
{ I, 
/n/ ,;; N 1 
sin[w(N1 + ~)) 
x[n)= 
sin(w/2) 
-
0, 
/n/ > N 1 
sinWn = .!f.sinc(W") 
{ l, 0 ,;; /w/ ,;; W 
X(w) = 
1TII 
'TT 
1T 
0, 
W < /w/ ,;; 1T 
-
O< W < TT 
X(w) periodic with period 2TT 
o[n) 
I 
-
I 
+~ 
u[n) 
-1 --
. + L 1r0(w - 21Tk) 
-
- e-Jw 
k= - 00 
o[n - n0) 
e- jwno 
-
(n + 1 )a" u[n], 
/a/< I 
1 
(I - ae Jw)2 
-
(n + r- I)! " [ l 
/a / < I 
l 
n!(r - I)! a u n' 
(1 - ae Jwy 
-
392 

Sec. 5.7 
Duality 
393 
signal, reversed in time). To see this in more detail, consider two periodic sequences with 
period N, related through the summation 
f[m] = ~ L g[r]e- jr(27TIN)m. 
r=(N) 
If we let m = k and r = n, eq. (5.65) becomes 
f[k] = ~ L g[n]e- jk(27TIN)n. 
n=(N) 
(5.65) 
Comparing this with eq. (3.95), we see that the sequence f[k] corresponds to the Fourier 
series coefficients of the signal g[n]. That is, if we adopt the notation 
introduced in Chapter 3 for a periodic discrete-time signal and its set of Fourier coeffi-
cients, the two periodic sequences related through eq. (5.65) satisfy 
:J'S 
g[n] ~ 
f[k]. 
Alternatively, if we let m = nand r = - k, eq. (5.65) becomes 
f[n] = L ..!_ g[- k]ejk(27TIN)n. 
k=(N)N 
(5.66) 
Comparing this with eq. (3.94), we find that (1/N)g[ -k] corresponds to the sequence of 
Fourier series coefficients of f[n]. That is, 
. 
~s 
1 
f[n] ~ 
Ng[ -k]. 
(5.67) 
As in continuous time, this duality implies that every property of the discrete-time 
Fourier series has a dual. For example, referring to Table 3.2, we see that the pair of prop-
erties 
(5.68) 
and 
ejm(27r!N)n x[n) ~ 
ak- m 
(5.69) 
are dual. Similarly, from the same table, we can extract another pair of dual properties: 
~s 
L x[r]y[n - r] ~ 
Nakbk 
(5.70) 
r= (N) 
and 
~s 
x[n]y[n] ~ L atbk- t· 
(5.71) 
l =(N) 

394 
The Discrete-Time Fourier Transform 
Chap. 5 
In addition to its consequences for the properties of discrete-time Fourier series, du-
ality can often be useful in reducing the complexity of the calculations involved in deter-
mining Fourier series representations. This is illustrated in the following example. 
Example 5. 16 
Consider the following periodic signal with a period of N = 9: 
x[n] = 
9 sin(7Tn/9), n # multtpleof9 
{ 
1 sin(57Tn/9) 
. 
. 
~· 
n = multiple of9 
(5.72) 
In Chapter 3, we found that a rectangular square wave has Fourier coefficients in a form 
much as in eq. (5.72). Duality, then, suggests that the coefficients for x[n] must be in the 
form of a rectangular square wave. To see this more precisely, let g[n] be a rectangular 
square wave with period N = 9 such that 
{ 
1, 
lnl :5 2 
g[n] = 
0, 
2 < lnl :5 4. 
The Fourier series coefficients bk for g[n] can be determined from Example 3.12 as 
{ 
~ sin(57rk/9) 
bk = 
9 sin(7Tk/9) ' 
5 
9' 
k # multiple of 9 
k = multiple of 9 
The Fourier series analysis equation (3.95) for g[n] can now be written as 
bk = ~ ± 
(l)e - j27Tnki9. 
n = - 2 
Interchanging the names of the variables k and nand noting that x[n] = b,, we find that 
Letting k' = - k in the sum on the right side, we obtain 
2 
x[n] = ~ L e +j2mtk'l9_ 
k' = - 2 
Finally, moving the factor l/9 inside the summation, we see that the right side of this 
equation has the form of the synthesis equation (3.94) for x[n]. We thus conclude that 
the Fourier coefficients of x[n] are given by 
{ 
l/9, 
lkl ::; 2 
ak = 
0, 
2 < lkl ::; 4, 
and, of course, are periodic with period N = 9. 

Sec. 5.7 
Duality 
395 
5. 7.2 Duality between the Discrete-Time Fourier Transform 
and the Continuous-Time Fourier Series 
In addition to the duality for the discrete Fourier series, there is a duality between the 
discrete-time Fourier transform and the continuous-time Fourier series. Specifically, let us 
compare the continuous-time Fourier series equations (3.38) and (3.39) with the discrete-
time Fourier transform equations (5.8) and (5.9). We repeat these equations here for con-
venience: 
[eq. (5.8)] 
x[n] = -
X(e1w)eJwndw, 
1 f . . 
2Tr 21T 
(5.73) 
+oo 
[eq. (5.9)] 
X(ejw) = L x[n]e- jwn, 
(5.74) 
n= - co 
+oo 
[eq. (3.38)] 
x(t) = L akejkwot, 
(5.75) 
k= - oo 
[eq. (3.39)] 
ak = ~ t x(t)e- jkwotdt. 
(5.76) 
Note that eqs. (5.73) and (5.76) are very similar, as are eqs. (5.74) and (5.75), and 
in fact, we can interpret eqs. (5.73) and (5.74) as a Fourier series representation of the 
periodic frequency response X(ejw). In particular, since X(ejw) is a periodic function of w 
with period 2Tr, it has a Fourier series representation as a weighted sum of harmonically 
related periodic exponential functions of w, all of which have the common period of 2Tr. 
That is, X(ejw) can be represented in a Fourier series as a weighted sum of the signals 
ejwn, n = 0, ± 1, ±2, .. . . From eq. (5.74), we see that the nth Fourier coefficient in this 
expansion- i.e., the coefficient multiplying ejwn_is x[- n]. Furthermore, since the period 
of X(ejw) is 2Tr, eq. (5.73) can be interpreted as the Fourier series analysis equation for the 
Fourier series coefficient x[n]-
i.e., for the coefficient multiplying e- jwn in the expression 
for X(ejw) in eq. (5.74). The use of this duality relationship is best illustrated with an 
example. 
Example 5.17 
The duality between the discrete-time Fourier transform synthesis equation and the 
continuous-time Fourier series analysis equation may be exploited to determine the 
discrete-time Fourier transform of the sequence 
x[n] = sin(7Tnl2)_ 
7Tn 
To use duality, we first must identify a continuous-time signal g(t) with period T = 27T 
and Fourier coefficients ak = x[k]. From Example 3.5, we know that if g(t) is a periodic 
square wave with period 27T (or, equivalently, with fundamental frequency wo = 1) and 
with 
. (t) _ { 1, 
ltl ~ T1 
g 
-
0, 
T1 < ltl ~ 1r ' 
then the Fourier series coefficients of g(t) are 

396 
The Discrete-Time Fourier Transform 
Chap.5 
Consequently, if we take T1 = 7T/2, we will have a k = x[k]. In this case the analysis 
equation for g(t) is 
sin(7Tk/2) 
1 J1r 
. 
1 J1rl2 
. 
= -
g(t)e- 1k1dt = -
(1 )e- 1k1dt. 
7Tk 
27T - 11' 
27T 
- 11'12 
Renaming k as n and t as w, we have 
(5.77) 
Replacing n by-non both sides of eq. (5.77) and noting that the sine function is even, 
we obtain 
The right-hand side of this equation has the form of the Fourier transform synthesis 
equation for x[n], where 
. 
{ 1 
X(e'w) = 
0 lwl s 7T/2 
7T/2 < lwl s 7T · 
In Table 5.3, we present a compact summary of the Fourier series and Fourier trans-
form expressions for both continuous-time and discrete-time signals, and we also indicate 
the duality relationships that apply in each case. 
TABLE 5.3 
SUMMARY OF FOURIER SERIES AND TRANSFORM EXPRESSIONS 
Continuous time 
Discrete time 
Time domain 
Frequency domain 
Time domain 
Frequency domain 
I 
I 
x(t) = 
I 
ak = 
x [n] = 
I 
ak = 
'l:t: - oo a ke j kwot 
I 
to fro x(t)e- jkwot 
L k=(N) akejk(2TTIN)n 
I 
~ Lk =(N) x [n]e- jk(2TT/N)n 
I 
I 
Fourier 
I 
I 
Series 
continuous time 
I 
discrete frequency 
~ 
discrete time ~ 
discrete frequency 
I 
periodic in time 
I 
aperiodic in frequency 
~~. 
periodic in time 
periodic in frequency 
I 
I 
I 
~ 
I 
x(t) = 
I 
X(j(J)) = 
x[n) = 
I 
X(eiw) = 
f,; f-+~~ X(jw )eiw'dw 
I 
J_+e~ x(tk- jwrdt 
___!__ J,_ X(ei•' )ei··" dw 
I 
L.:: -oo x [n]e-jwn 
I 
I 
Fourier 
I 
27r _ .. 
I 
Transform continuous time ~ 
continuousf~uency 
discrete time 
I 
continuous frequency 
I 
aperiodic in time 
. 
aperiodic in ~uency 
aperiodic in time 
I 
periodic in frequency 
5.8 SYSTEMS CHARACTERIZED BY LINEAR CONSTANT-COEFFICIENT 
DIFFERENCE EQUATIONS 
A general linear constant -coefficient difference equation for an LTI system with input x[ n] 
and output y[n] is ofthe form 

Sec. 5.8 
Systems Characterized by Linear Constant-Coefficient Difference Equations 
397 
N 
M 
.2: aky[n - k] = .2: bkx[n - k]. 
(5.78) 
k=O 
k=O 
The class of systems described by such difference equations is quite an important and 
useful one. In this section, we take advantage of several of the properties of the discrete-
time Fourier transform to determine the frequency response H(ejw) for an LTI system 
described by such an equation. The approach we follow closely parallels the discussion 
in Section 4.7 for continuous-time LTI systems described by linear constant-coefficient 
differential equations. 
There are two related ways in which to determine H(ejw). The first of these, which 
we illustrated in Section 3.11 for several simple difference equations, explicitly uses the 
fact that complex exponentials are eigenfunctions ofLTI systems. Specifically, if x[n] = 
ejwn is the input to an LTI system, then the output must be of the form H(ejw)ejwn . Substi-
tuting these expressions into eq. (5.78) and performing some algebra allows us to solve for 
H(ejw). In this section, we follow a second approach making use of the convolution, linear-
ity, and time-shifting properties of the discrete-time Fourier transform. Let X ( ejw ), Y ( ejw ), 
and H(ejw) denote the Fourier transforms of the input x[n], output y[n], and impulse re-
sponse h[n], respectively. The convolution property, eq. (5.48), of the discrete-time Fourier 
transform then implies that 
H(ejw) = Y(ejw). 
X(eJw) 
(5.79) 
Applying the Fourier transform to both sides of eq. (5.78) and using the linearity and 
time-shifting properties, we obtain the expression 
N 
M 
.2: ake- jkwY(ejw) = .2: bke- jkwX(ejw), 
k=O 
k=O 
or equivalently, 
Y( jw) 
'"M 
b 
- jkw 
H(ejw) = _e 
_ _ -
= L...k=O ke 
. 
X(eJW) 
L~= O ake- jkw 
(5.80) 
Comparing eq. (5.80) with eq. (4.76), we see that, as in the case of continuous time, H(ejw) 
is a ratio of polynomials, but in discrete time the polynomials are in the variable e- jw. 
The coefficients of the numerator polynomial are the same coefficients as appear on the 
right side of eq. (5.78), and the coefficients of the denominator polynomial are the same 
as appear on the left side of that equation. Therefore, the frequency response of the LTI 
system specified by eq. (5.78) can be written down by inspection. 
The difference equation (5.78) is generally referred to as an Nth-order difference 
equation, as it involves delays in the output y[n] of uptoN time steps. Also, the denomi-
nator of H(ejw) in eq. (5.80) is an Nth-order polynomial in e- jw. 
Example 5. 18 
Consider the causal LTI system that is characterized by the difference equation 
y[n] - ay[n- 1] = x[n], 
(5.81) 

398 
The Discrete-Time Fourier Transform 
with Ia! < 1. From eq. (5.80), the frequency response of this system is 
1 
H(e1w) = ..,--------,--
1- ae- 1w 
Chap.5 
(5.82) 
Comparing this with Example 5.1, we recognize it as the Fourier transform of these-
' quence a"u[n]. Thus, the impulse response of the system is 
(5.83) 
Example 5. 19 
Consider a causal LTI system that is characterized by the difference equation 
3 
1 
y[n] - 4y[n - 1] + gy[n- 2] = 2x[n]. 
(5.84) 
From eq. (5.80), the frequency response is 
. 
2 
H(e1w) = 
. 
1- "i e- jw + !rj"lb> 
4 
8 
(5.85) 
As a first step in obtaining the impulse response, we factor the denominator of eq. (5.85): 
. 
2 
H(elw) = 
. 
(1 -
~r jw)(1 -
~r jw) 
(5.86) 
H(ejw) can be expanded by the method of partial fractions, as in Example A.3 in the 
appendix. The result of this expansion is 
(5.87) 
The inverse transform of each term can be recognized by inspection, with the result that 
(1)" 
(1)" 
h[n] = 4 2 u[n] - 2 4 u[n]. 
(5.88) 
The procedure followed in Example 5.19 is identical in style to that used in contin-
uous time. Specifically, after expanding H(ejw) by the method of partial fractions, we can 
find the inverse transform of each term by inspection. The same approach can be applied 
to the frequency response of any LTI system described by a linear constant-coefficient dif-
ference equation in order to determine the system impulse response. Also, as illustrated in 
the next example, if the Fourier transform X(ejw) of the input to such a system is a ratio of 
polynomials in e- jw, then Y(ejw) is as well. In this case, we can use the same technique 
to find the response y[n] to the input x[n]. 
Example 5.20 
Consider the LTI system of Example 5.19, and let the input to this system be 
( 1 )" 
x[n] = 4 u[n]. 

Sec. 5.9 
5.9 SUMMARY 
Summary 
399 
Then, using eq. (5.80) and Example 5.1 or 5.18, we obtain 
(5.89) 
(1- !e- jw)(l - i e-•w)2' 
As described in the appendix, the form of the partial-fraction expansion in this case is 
Y(ejw) = 
Bu 
+ 
~1 2 . 
+ 
~2 1 
. , 
1- i e- jw 
(1 - 4e- ;w)2 
1 - 'i e- ;w 
(5.90) 
where the constants B 11 , B12, and B21 can be determined using the techniques described 
in the appendix. This particular expansion is worked out in detail in Example A.4, and 
the values obtained are 
B11 = - 4, 
B12 = - 2, 
Bz1 = 8, 
so that 
Y(e jw ) = _ 
4 
_ 
2 
+ 
8 
. 
1 - ! e-jw 
(1 - !e- jw )Z 
1- ! e- jw 
4 
4 
2 
(5.91) 
The first and third terms are of the same type as those encountered in Example 5.19, 
while the second term is of the same form as one seen in Example 5.13. Either from 
these examples or from Table 5.2, we can invert each of the terms in eq. (5.91) to obtain 
the inverse transform 
y[n] = { -4 (~ J -2(n + 1) (~ )" + 8 (~ n 
u[n]. 
(5.92) 
In this chapter, we have paralleled Chapter 4 as we developed the Fourier transform for , 
discrete-time signals and examined many of its important properties. Throughout the chap-
ter, we have seen a great many similarities between continuous-time and discrete-time 
Fourier analysis, and we have also seen some important differences. For example, the re-
lationship between Fourier series and Fourier transforms in discrete time is exactly anal-
ogous to that in continuous time. In particular, our derivation of the discrete-time Fourier 
transform for aperiodic signals from the discrete-time Fourier series representations is 
very much the same as the corresponding continuous-time derivation. Furthermore, many 
of the properties of continuous-time transforms have exact discrete-time counterparts. On 
the other hand, in contrast to the continuous-time case, the discrete-time Fourier transform 
of an aperiodic signal is always periodic with period 2'7T. In addition to similarities and 
differences such as these, we have described 'the duality relationships among the Fourier 
representations of continuous-time and discrete-time signals. 
The most important similiarities between continuous- and discrete-time Fourier anal-
ysis are in their uses in analyzing and representing signals and LTI systems. Specifically, 
the convolution property provides us with the basis for the frequency-domain analysis of 
LTI systems. We have already seen some of the utility of this approach in our discussion of 

400 
The Discrete-Time Fourier Transform 
Chap.5 
filtering in Chapters 3-5 and in our examination of systems described by linear constant-
coefficient differential or difference equations, and we will gain a further appreciation for 
its utility in Chapter 6, in which we examine filtering and time-versus-frequency issues in 
more detail. In addition, the multiplication properties in continuous and discrete time are 
essential to our development of sampling in Chapter 7 and communications in Chapter 8. 
Chapter 5 Problems 
The first section of problems belongs to the basic category and the answers are provided 
in the back of the book. The remaining three sections contain problems belonging to the 
basic, advanced, and extension categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
5.1. Use the Fourier transform analysis equation (5.9) to calculate the Fourier transforms 
of: 
(a) (4)11- 1u[n- 1] 
(b) (4)1n- ll 
Sketch and label one period of the magnitude of each Fourier transform. 
5.2. Use the Fourier transform analysis equation (5.9) to calculate the Fourier transforms 
of: 
(a) o[n - 1] + o[n + 1] 
(b) o[n + 2] - o[n - 2] 
Sketch and label one period of the magnitude of each Fourier transform. 
5. 3. Determine the Fourier transform for -7r :5 w < 7T in the case of each of the fol-
lowing periodic signals: 
(a) sin(~n + i) 
(b) 2 + cos(-~n + ~) 
5.4. Use the Fourier transform synthesis equation (5.8) to determine the inverse Fourier 
transforms of: 
(a) X,(ejw) = 2.:;=-oo{27TO(w - 27Tk) + 7TO(w- ¥- 27Tk) + 7TO(w + ¥- 27Tk)} 
(b) X2(ejw) = { 2}, . 
0 < w :5 7T 
-2], 
-7T < w :5 0 
5.5. Use the Fourier transform synthesis equation (5.8) to determine the inverse Fourier 
transform of X(e jw ) = iX(ejw)iej <l:X(eiw), where 
Use your answer to determine the values of n for which x[n] = 0. 
5.6. Given that x[n] has Fourier transform X(ejw), express the Fourier transforms of the 
following signals in terms of X(ejw). You may use the Fourier transform properties 
listed in Table 5.1. 
(a) Xt [n] = x[1 - n] + x[ -1 - n] 
(b) X2[n] = x' [-nJ+x[n) 
(c) x3[n] = (n- 1)2x[n] 

Chap. 5 Problems 
401 
5. 7. For each of the following Fourier transforms, use Fourier transform properties (Table 
5.1) to determine whether the corresponding time-domain signal is (i) real, imagi-
nary, or neither and (ii) even, odd, or neither. Do this without evaluating the inverse 
of any of the given transforms. 
(a) X1(ejw) = e - jwLk~
1 (sinkw) 
(b) X2(ejw) = j sin(w) cos(5w) 
(c) X3(ejw) = A(w) + ejB(w) where 
A(w) = { l, 
0, 
0 :S lwl :S ¥ 
¥ < lwl :S 7T 
and B(w) = -
3; + 7T. 
5.8. Use Tables 5.1 and 5.2 to help determine x[n] when its Fourier transform is 
. 
1 
sm 2w 
( 
. 
3 
) 
X(e1w) = 1 
_ . 
- . - w-
+ 57T8(w), 
- e JW 
sm 2 
5.9. The following four facts are given about a real signal x[n] with Fourier transform 
X(ejw): 
1. x[n] = 0 for n > 0. 
2. x[O] > 0. 
3. 9'm{X(ejw)} = sinw- sin2w. 
4. 2~ J:'1T IX(ejw)l2 dw = 3. 
Determine x[n]. 
5.10. Use Tables 5.1 and 5.2 in conjunction with the fact that 
n =-:N 
to detennine the numerical value of 
00 
(1 )II 
A = ::~:> 2 
n=O 
' 5.11. Consider a signal g[n] with Fourier transform G(ejw). Suppose 
g[n] = X(2)[n], 
where the signal x[n] has a Fourier transform X(e jw). Determine a real number a 
such that 0 < a < 27T and G(ejw) = G(ej(w - al). 
5.12. Let 
(
sin *n)
2 
(sin wen) 
y[n] = --
* 
' 
7Tn 
7Tn 
where * denotes convolution and lwei :S 7T. Determine a stricter constraint on W e 

402 
The Discrete-Time Fourier Transform 
Chap.5 
which ensures that 
sm-n 
(
. 
1T )2 
y[n] = 
1T~ 
. 
5.13. An LTI system with impulse response h1[n] = (~)nu[n] is connected in parallel 
with another causal LTI system with impulse response h2[n]. The resulting parallel 
interconnection has the frequency response 
Determine h2[n]. 
· 
- 12 + 5e- jw 
H(e1w) = -=-=------=~-:-------:;:;-
12 - 7 e- jw + e- j2w · 
5.14. Suppose we are given the following facts about an LTI system S with impulse re-
sponse h[n] and frequency response H(ejw): 
1. (~)nu[n] ~ 
g[n], where g[n] = 0 for n 2: 2 and n < 0. 
2. H(ej1r!2) = 1. 
3. H(ejw) = H(ej(w - TTl). 
Determine h[n]. 
5.15. Let the inverse Fourier transform of Y(ejw) be 
y[n] = (si::en )
2
, 
where 0 <We< 1T. Determine the value of We which ensures that 
. 
1 
Y(el1T) = z· 
5.16. The Fourier transform of a particular signal is 
X(ejw) = ~ 
(112)k 
. 
L 
1 _ !e-j(w-TTI2k) 
k=O 
4 
It can be shown that 
x[n] = g[n]q[n]; 
where g[n] is of the form anu[n] and q[n] is a periodic signal with period N. 
(a) Determine the value of a. 
(b) Determine the value of N. 
(c) Is x[n] real? 
5.17. The signal x[n] = ( -l)n has a fundamental period of 2 and corresponding Fourier 
series coefficients ak. Use duality to determine the Fourier series coefficients bk of 
the signal g[ n] = an with a fundamental period of 2. 
5.18. Given the fact that 
lnl 
~ 
1 -
02 
JaJ < 1, 
a ~ 
1 - 2a cos w + a2 ' 

Chap. 5 Problems 
403 
use duality to determine the Fourier series coefficients of the following continuous-
time signal with period T = 1: 
1 
x( t) = -=-----:--=--:-
5 - 4 cos(27Tt) 
5.19. Consider a causal and stable LTI systemS whose input x[n] and output y[n] are 
related through the second-order difference equation 
1 
1 
y[n]- 6y[n- 1] -
6 y[n- 2] = x[n]. 
(a) Determine the frequency response H(ejw) for the systemS. 
(b) Determine the impulse response h[n] for the systemS. 
5.20. A causal and stable LTI system S has the property that 
(~ J 
u[n] ~ 
n (~ J 
u[n]. 
(a) Determine the frequency response H(ejw) for the systemS. 
(b) Determine a difference equation relating any input x[n] and the corresponding 
output y[n]. 
BASIC PROBLEMS 
5.21. Compute the Fourier transform of each of the following signals: 
(a) x[n] = u[n - 2] - u[n - 6] 
(b) x[n] = <4)-
11u[ -n- 1] 
(c) x[n] = <Vnlu[ -n- 2] 
(d) x[n] = 2
11 sinGn)u[ - n] 
(e) x[n] = <4)1nl cos(i(n- 1)) 
{ 
n, 
- 3 ~ n ~ 3 
(f) x[n] = 
0, 
otherwise 
(g) x[n] = sin(~n) + cos(n) 
(h) x[n] = sin( 5; n) + cose; n) 
(i) x[n] = x[n - 6], and x[n] = u[n] - u[n - 5] for 0 ~ n ~ 5 
(j) x[n] = (n- l)(Vnl 
(k) x[n] = cin(;:'5)) cose; n) 
5.22. The following are the Fourier transforms of discrete-time signals. Determine the 
signal corresponding to each transform. 
· 
( 1, 
~4 ~lwl ~ 
3
4~ 
(a) X(e1w) --
o 
3~ < I I < 
o < I I < ~ 
' 
4 
-
w -
'TT, 
-
w 
4 
(b) X(ejw) = 1 + 3e- jw + 2e- j2w -
4e- j 3w + e- jlOw 
(c) X(ejw) = e-jw/2 for -'TT ~ w ~ '1T 
(d) X(ejw) = cos2 w + sin2 3w 

404 
(e) X(eiw) = L:;= - oo(- 1)k5(w - fk) 
- jw 
l 
(f) X(eiw) = e 1 ~ ~ 
J- 5e Jw 
J- le- jw 
(g) X ( e jw) = ..,....--,----="----.----::-:-
1-ie jw_ke 2jw 
I ( 1)6 - j6w 
(h) X(eiw) = - -
e . 
J-te Jw 
The Discrete-Time Fourier Transform 
Chap.S 
5.23. Let X(eiw) denote the Fourier transform of the signal x[n] depicted in Figure P5.23. 
Perform the following calculations without explicitly evaluating X(eiw): 
(a) Evaluate X(ei0). 
(b) Find <r..X(eiw). 
(c) Evaluate f ~1TX(eiw)dw. 
(d) Find X(el'IT). 
(e) Determine and sketch the signal whose Fourier transform is ffi-e{x(w )}. 
(f) Evaluate: 
(i) J ~1TIX(eiw)l
2dw 
(ii) J ~'IT I 
dXd~w) 12 dw 
x[n] 
2 
Fig P5.23 
n 
5.24. Determine which, if any, of the following signals have Fourier transforms that sat-
isfy each of the following conditions: 
1. ffi-e{X(eiw)} = 0. 
2. dm{X(eiw)} = 0. 
3. There exists an integer a such that eJaw X( eiw) is real. 
4. J ~1TX(eiw)dw = 0. 
5. X(eiw) periodic. 
6. X(ei0) = 0. 
(a) x[n] as in Figure P5.24(a) 
(b) x[n] as in Figure P5.24(b) 
(c) x[n] = (~)nu[n] 
(d) x[n] = (~)lnl 
(e) x[n] = 5[n - 1] + 5[n + 2] 
(f) x[n] = 5[n - 1] + 5[n + 3] 
(g) x[n] as in Figure P5.24(c) 
(h) x[n] as in Figure P5.24(d) 
(i) x[n] = 5[n- 1] - 5[n + 1] 

Chap. 5 Problems 
405 
x[n] 
• • • • .~I 1(1 I I I • • • • • • 
- 1 0 1 2 3 4 5 6 
n 
(a) 
x[n] 
. I . I . I . . 1 I . 1 • I . I . I . I . I . 
I-2-1 ~J 2 
I n 
(b) 
x[n] 
2 
n 
(c) 
x[n] 
2 
n 
(d) 
Fig P5.24 
5.25. Consider the signal depicted in Figure P5 .25. Let the Fourier transform of this signal 
be written in rectangular form as 
X(ei"') = A(w) + jB(w). 
Sketch the function of time corresponding to the transform 

406 
2 
The Discrete-Time Fourier Transform 
x[n] 
3 
- 2 
2 3 4 5 
- 1 
Fig P5.25 
Chap. 5 
n 
5.26. Let x 1 [n] be the discrete-time signal whose Fourier transform X1 (ejw) is depicted 
in Figure P5.26(a). 
(a) Consider the signal x2[n] with Fourier transform X2(ejw), as illustrated in Fig-
ure P5.26(b). Express x2[n] in terms of x 1[n]. [Hint: First express X2(ejw) in 
terms of X 1 ( ejw ), and then use properties of the Fourier transform.] 
(b) Repeat part (a) for x3[n] with Fourier transform X3(ejw), as shown in Figure 
P5.26(c). 
(c) Let 
n= - oo 
a='-'------
co 
~ 
XJ[n] 
n= - oo 
This quantity, which is the center of gravity of the signal x 1 [n], is usually re-
ferred to as the delay time of x 1 [n]. Find a. (You can do this without first deter-
mining x 1 [n] explicitly.) 
'IT 3 
'IT 
w 
'IT 
w 
(a) 
Fig P5.26a 

Chap. 5 Problems 
-'IT 
'IT 
'IT 
'IT 
w 
-3 
3 
(b) 
X3 (ei"') 
1 
w 
(c) 
(d) Consider the signal x4[n] = x1 [n] * h[n], where 
h[n] = sin( 7Tn/6) . 
7Tn 
Sketch X4(ejw). 
407 
Fig P5.26b,c 
5.27. (a) Let x[n] be a discrete-time signal with Fourier transform X(ejw), which is il-
lustrated in Figure P5.27. Sketch the Fourier transform of 
w[n] = x[n]p[n] 
for each of the following signals p[n]: 
(i) 
p[n] = cos 7Tn 
(ii) p[n] = cos( 7Tn/2) 
(iii) p[n] = sin( 7Tn/2) 
00 
ov> p[n] = L, o[n- 2k] 
k= - oo 
00 
) 
<v> p[n] = L, o[n- 4k] 
k = -
00 
X(ei"') 
'IT 
'IT 
2 
4'1T 
w 
Fig P5.27 

408 
The Discrete-Time Fourier Transform 
Chap.5 
(b) Suppose that the signal w[n] of part (a) is applied as the input to an LTI system 
with unit sample response 
h[n] = sin(1Tn/2). 
1Tn 
Determine the output y[n] for each of the choices of p[n] in part (a). 
5.28. The signals x[n] and g[n] are known to have Fourier transforms X(ejw) and G(ejw), 
respectively. Furthermore, X(ejw) and G(ejw) are related as follows: 
-1 J+1T X(ej0)G(ej(w- e))d() = 1 + e- jw 
(P5.28- 1) 
21T -1T 
(a) If x[n] = ( -1Y, determine a sequence g[n] such that its Fourier transform 
G(ejw) satisfies eq. (P5.28-1). Are there other possible solutions for g[n]? 
(b) Repeat the previous part for x[n] = <4Y'u[n]. 
5.29. (a) Consider a discrete-time LTI system with impulse response 
h[n] = G J 
u[n]. 
Use Fourier transforms to determine the response to each of the following input 
signals: 
(i) 
x[n] = (~)''u[n] 
(ii) x[n] = (n + l)(~Yu[n] 
(iii) x[n] = ( -l)n 
(b) Suppose that 
h[n] = [ G J 
cos ( ~n )] u[n]. 
Use Fourier transforms to determine the response to each of the following in-
puts: 
(i) 
x[n] = (4)nu[n] 
(ii) x[n] = cos( 1Tn/2) 
(c) Let x[n] and h[n] be signals with the following Fourier transforms: 
X(ejw) = 3ejw + 1 - e-jw + 2e-j3w, 
H(ejw) = - ejw + 2e- Zjw + ej4w. 
Determine y[n] = x[n] * h[n]. 
5.30. In Chapter 4, we indicated that the continuous-time LTI system with impulse re-
sponse 
h(t) = -smc -
= --
W . 
(Wt) 
sin Wt 
1T 
1T 
1Tt 
plays a very important role in LTI system analysis. The same is true of the discrete-
time LTI system with impulse response 
W : 
(Wn) 
sin Wn 
h[n] = -
smc -
= --. 
1T 
1T 
1Tn 

Chap. 5 Problems 
409 
(a) Determine and sketch the frequency response for the system with impulse re-
sponse h[n]. 
(b) Consider the signal 
. (7Tn) 
(7Tn) 
x[n] = sm T 
- 2cos 4. 
Suppose that this signal is the input to LTI systems with the following impulse 
responses. Determine the output in each case. 
(i) 
h[n] = sin(1rn/6) 
1Tn 
(ii) h[n] = sin(1rn/6) + sin(?Tn/2) 
1rn 
1rn 
(iii) h[n] = sin(1Tn/!s~~(1Tn/3) 
(iv) h[n] = sin(?Tn/6)sin(?Tn/3) 
1Tn 
(c) Consider an LTI system with unit sample response 
h[n] = sin( 7Tn/3). 
7Tn 
Determine the output for each of the following inputs: 
(i) 
x[n] = the square wave depicted in Figure P5.30 
00 
(ii) x[n] = 2:: S[n - 8k] 
k= -00 
(iii) x[n] = ( - l)n times the square wave depicted in Figure P5.30 
(iv) x[n] = S[n + 1] + S[n- 1] 
x[n) 
III ... IIIII .. ~IIIII ... IIIII ... IIIII ... II 
- 8 
0 
8 
16 
n 
Fig P5.30 
5.31. An LTI systemS with impulse response h[n] and frequency response H(eiw) is 
known to have the property that, when - 7r :5 w0 :5 7T, 
(a) Determine H(eiw). 
(b) Determine h[n]. 
cos won ~ 
wo cos won• 
5.32. Let h 1 [n] and h2[n] be the impulse responses of causal LTI systems, and let H 1 (eiw) 
and H2(eiw) be the corresponding frequency responses. Under these conditions, is 
the following equation true in general or not? Justify your answer. 

410 
The Discrete-Time Fourier Transform 
Chap.5 
5.33. Consider a causal LTI system described by the difference equation 
1 
y[n] + ly[n- 1] = x[n]. 
(a) Determine the frequency response H(ejw) of this system. 
(b) What is the response of the system to the following inputs? 
(i) 
x[n] = (~)nu[n] 
(ii) x[n] = (- ~)nu[n] 
(iii) x[n] = o[n] + ~o[n - 1] 
(iv) x[n] = 5[n] -
~5[n - 1] 
(c) Find the response to the inputs with the following Fourier transforms: 
(i} 
X(ejw) = 1-~e - iw 
l+ie- Jw 
("") X( jw) = 1+ -'e- iw 
II 
e 
1-le- iw 
4 
(iii) X(ejw) = 
1 
(I -
~e -iw)(l + ie- iw) 
(iv) X(ejw) = 1 + 2e-3jw 
5.34. Consider a system consisting of the cascade of two LTI systems with frequency 
responses 
and 
(a) Find the difference equation describing the overall system. 
(b) Determine the impulse response of the overall system. 
5.35. A causal LTI system is described by the difference equation 
y[n] - ay[n - 1] = bx[n] + x[n - 1], 
where a is real and less than 1 in magnitude. 
(a) Find a value of b such that the frequency response of the system satisfies 
IH(ejw)l = 1, for all w. 
This kind of system is called an all-pass system, as it does not attenuate the 
input ejwn for any value of w. Use the value of b that you have found in the rest 
of the problem. 
(b) Roughly sketch <J:.H(ejw), 0 :5 w :5 11', when a = ~-
(c) Roughly sketch <J:.H(ejw), 0 :5 w :5 11', when a = -~. 

Chap. 5 Problems 
411 
(d) Find and plot the output of this system with a = -4 when the input is 
x[n] = G 
)n u[n] . . 
From this example, we see that a nonlinear change in phase can have a signif-
icantly different effect on a signal than the time shift that results from a linear 
phase. 
5.36. (a) Let h[n] and g[n] be the impulse responses of two stable discrete-time LTI sys-
tems that are inverses of each other. What is the relationship between the fre-
quency responses of these two systems? 
(b) Consider causal LTI systems described by the following difference equations. 
In each case, determine the impulse response of the inverse system and the 
difference equation that characterizes the inverse. 
(i) 
y[n] = x[n] -
~x[n - 1] 
(ii) y[n] + 4y£n - 1] = x[n] 
(iii) y[n] + 4y£n- 1] = x[n] -
~x[n - 1] 
(iv) y[n] + iy£n- 1] - ky[n - 2] = x[n] -
~x[n - 1]- kx£n - 2] 
(v) y[n] + iy£n - 1] - ky[n- 2] = x[n] - 4x[n - 1] 
(vi) y[n] + iy[n- 1]- ky[n- 2] = x[n] 
(c) Consider the causal, discrete-time LTI system described by the difference equa-
tion 
1 
1 
y[n] + y[n - 1] + 4y[n- 2] = x[n- 1]- 2x[n- 2]. 
(P5.36-1) 
What is the inverse of this system? Show that the inverse is not causal. Find an-
other causal LTI system that is an "inverse with delay" of the system described 
by eq. (P5.36-1). Specifically, find a causal LTI system such that the output 
w[n] in Figure P5.36 equals x[n - 1]. 
x[n] 
LTI system 
y[n) 
Causal 
described by 
LTI 
w[n) 
eq. (P5.36-1) 
system 
Fig P5.36 
ADVANCED PROBLEMS 
5.37. Let X(eiw) be the Fourier transform of x[n]. Derive expressions in terms of X(eiw) 
for the Fourier transforms of the following signals. (Do not assume that x[n] is real.) 
(a) ffi.e{x[n]} 
(b) x*[ - n] 
(c) 8v{x[n]} 

412 
The Discrete-Time Fourier Transform 
Chap.5 
5.38. Let X(eiw) be the Fourier transform of a real signal x[n]. Show that x[n] can be 
written as 
x[n] = J
0
7T{B(w)cosw + C(w)sinw}dw 
by finding expressions for B(w) and C(w) in terms of X(eiw). 
5.39. Derive the convolution property 
5' 
. 
. 
x[n] * h[n] ~ 
X(elw)H(elw). 
5.40. Let x[n] and h[n] be two signals, and let y[n] = x[n] * h[n]. Write two expressions 
for y[O], one (using the convolution sum directly) in terms of x[n] and h[n], and 
one (using the convolution property of Fourier transforms) in terms of X(eiw) and 
H(eiw). Then, by a judicious choice of h[n], use these two expressions to derive 
Parseval's relation-that is, 
In a similar fashion, derive the following generalization of Parseval's relation: 
+ oo 
1 J 
7T 
• 
• 
~ 
x[n]z*[n] = 2
1T 
_ X(elw)Z*(elw)dw. 
n- oo 
~ 
5.41 Let i[n] be a periodic signal with period N. A finite-duration signal x[n] is related 
to i[n] through 
x[n] = { i[n], 
0, 
no :5 n :5 no+N-1 
otherwise 
for some integer n0 . That is, x[n] is equal to i[n] over one period and zero elsewhere. 
(a) If i[n] has Fourier series coefficients ak and x[n] has Fourier transformX(eiw), 
show that 
regardless of the value of n0 . 
(b) Consider the following two signals: 
x[n] = u[n] - u[n - 5] 
00 
i[n] = ~ 
x[n - kN] 
k= - oo 
where N is a positive integer. Let ak denote the Fourier coefficients of i[n] and 
let X(eiw) denote the Fourier transform of x[n]. 
(i) 
Determine a closed-form expression for X(eiw). 

Chap. 5 Problems 
413 
(ii) Using the result of part (i), determine an expression for the Fourier coeffi-
cients ak. 
5.42. In this problem, we derive the frequency-shift property of the discrete-time fourier 
transform as a special case of the multiplication property. Let x[n] be any discrete-
time signal with Fourier transform X(ejw), and let 
g[n] = ejwon x[n]. 
(a) Determine and sketch the Fourier transform of 
p[n] = ejwon. 
(b) The multiplication property of the Fourier transform tells us that, since 
g[n] = p[n]x[n], 
Evaluate this integral to show that 
G(ejw) = X(ej(w -wol). 
5.43. Let x[n] be a signal with Fourier transform X(ejw), and let 
g[n] = x[2n] 
be a signal whose Fourier transform is G(ejw). In this problem, we derive the rela-
. tionship between G(ejw) and X(ejw). 
(a) Let 
[ ] 
_ (e- j1rn x[n]) + x[n] 
v n -
2 
. 
Express the Fourier transform V(ejw) ofv[n] in terms of X(ejw). 
(b) Noting that v[n] = 0 for n odd, show that the Fourier transform ofv[2n] is equal 
to V(eFr ). 
(c) Show that 
x[2n] = v[2n]. 
It follows that 
G(ejw) = V(ejw/2). 
Now use the result of part (a) to express G(ejw) in terms of X(ejw). 
5.44. (a) Let 
(7Tn) . (7Tn) 
x 1 [n] = cos 3 
+ sm T 

414 
The Discrete-Time Fourier Transform 
Chap.S 
be a signal, and let Xt (ejw) denote the Fourier transform of x 1 [n]. Sketch x 1 [n], 
together with the signals with the following Fourier transforms: 
(i) 
X2(ejw) = Xt(ejw)ejw, lwl < 1T 
(ii) X3(ejw) = Xt(ejw)e- jJw/2, lwl < 1T 
(b) Let 
(7T"t) 
. (1Tt) 
w(t) = cos 3T + sm 2T 
be a continuous-time signal. Note that x 1 [n] can be regarded as a sequence of 
evenly spaced samples of w(t); that is, 
Xt [n] = w(nT). 
Show that 
x2[n] = w(nT -a) ·· 
and 
x3[n] = w(nT - {3) 
and specify the values of a and {3. From this result we can conclude that x2[n] 
and x3[n] are also evenly spaced samples of w(t). 
5.45. Consider a discrete-time signal x[n] with Fourier transform as illustrated in Figure 
P5.45. Provide dimensioned sketches of the following continuous-time signals: 
(a) Xt (t) = L:= - cx,x[n]ej(21TI10)nt 
(b) X2(t) = L:=-cx,x[ -n]ej(21T!IO)nt 
w 
~m{ X(eij} 
Fig P5.45 

Chap. 5 Problems 
(c) x3(t) = .L:= - oo0d{x[n]}ei<21T/8)nt 
(d) x4(t) = .L:=-ooffi-e{x[n]}ei(27T/6)nt 
5.46. In Example 5.1, we showed that for Ia I < 1, 
n 
~ 
1 
a u[n] ~ 
1 
_ . . 
- ae JW 
(a) Use properties of the Fourier transform to show that 
. 
~ 
1 
(n + 1)anu[n] ~ 
(1 
_. )2 . 
- ae JW 
(b) Show by induction that the inverse Fourier transform of 
is 
(n + r- 1)! 
n 
x[n] = 
I( _ 1)1 a u[n]. 
n. r 
. 
415 
5.47. Determine whether each of the following statements is true or false. Justify your 
answers. In each statement, the Fourier transform of x[n] is denoted by X(eiw). 
(a) If X(eiw) = X(eJ<w - t>), then x[n] = 0 for lnl > 0. 
(b) If X(eiw) = X(ei<w - 1T)), then x[n] = 0 for lnl > 0. 
(c) If X(eiw) = X(eiw12), then x[n] = 0 for lnl > 0. 
(d) If X(eiw) = X(ei2w), then x[n] = 0 for lnl > 0. 
5.48. We are given a discrete-time, linear, time-invariant, causal system with input de-
noted by x[n] and output denoted by y[n]. This system is specified by the following 
pair of difference equations, involving an intermediate signal w[n] : 
1 
1 
2 
y [n] + 4y[n - 1] + w[n] + 2w[n - 1] = 3x[n], 
5 
5 
y[n]- 4y [n - 1] + 2w[n]- 2w[n -
1] = - 3
x[n]. 
(a) Find the frequency response and unit sample response of the system. 
(b) Find a single difference equation relating x (n] and y[n] for the system. 
5.49. (a) A particular discrete-time system has input x[n] and output y[n]. The Fourier 
transforms of these signals are related by the equation 
Y(eiw) = 2X(eiw) + e-JwX(eiw)- dXd~w). 
(i) 
Is the system linear? Clearly justify your answer. 
(ii) Is the system time invariant? Clearly justify your answer. 
(iii) What is y[n] if x[n] = 8[n]? 

416 
The Discrete-Time Fourier Transform 
Chap.5 
(b) Consider a discrete-time system for which the transform Y(el"') of the output 
is related to the transform bf the input through the relation 
Find an expression for y[n] in terms of x[n]. 
5.50. (a) Suppose we want to design a discrete-time LTI system which has the property 
that if the input is 
(
1 )n 
1 (1 )n-1 
x[n] = 2 
u[n] - 4 2 
u[n -
1], 
then the output is 
y[n] = (~ J 
u[n]. 
(i) 
Find the impulse response and frequency response of a discrete-time LTI 
system that has the foregoing property. 
(ii) Find a difference equation relating x[n] and y[n] that characterizes the 
system. 
(b) Suppose that a system has the response (114)nu[n] to the input (n+2)(112)nu[n]. 
If the output of this system is 5[n] - ( -112)nu[n], what is the input? 
5.51. (a) Consider a discrete-time system wrth unit sample response 
( 1 )n 
1 (1 )n 
h[n] = 2 u[n] + 2 4 u[n]. 
Determine a linear constant-coefficient difference equation relating the input 
and output of the system. 
(b) Figure P5.51 depicts a block diagram implementation of a causal LTI system. 
(i) 
Find a difference equation relating x[n] and y[n] for this system. 
(ii) What is the frequency response of the system? 
(iii) Determine the system's irr..pulse response. 
Fig P5.51 

Chap. 5 Problems 
417 
5.52. (a) Let h[n] be the impulse response of a real, causal, discrete-time LTI system. 
Show that the system is completely specified by the real part of its frequency 
response. (Hint: Show how h[n] can be recovered from 8v{h[n]}. What is the 
Fourier transform of 8v{ h[ n]} ?) This is the discrete-time counterpart of the real-
part sufficiency property of causal LTI systems considered in Problem 4.47 for 
continuous-time systems. 
(b) Let h[n] be real and causal. If 
CR-e{H(eiw)} = 1 + a cos 2w(a real), 
determine h[n] and H(eiw). 
(c) Show that h[n] can be completely recovered from knowledge of dm{H(eiw)} 
and h[O]. 
(d) ·Find two real, causal LTI systems whose frequency responses have imaginary 
parts equal to sin w. 
EXTENSION PROBLEMS 
5.53. One of the reasons for the tremendous growth in the use of discrete-time methods for 
the analysis and synthesis of signals and systems was the development of exceed-
ingly efficient tools for performing Fourier analysis of discrete-time sequences. At 
the heart of these methods is a technique that is very closely allied with discrete-time 
Fourier analysis and that is ideally suited for use on a digital computer or for im-
. plementation in digital hardware. This technique is the discrete Fourier transform 
(DFT) for finite-duration signals. 
Let x[n] be a signal of finite duration; that is, there is an integer N 1 so that 
x[n] = 0, 
outside the interval 0 s; n s; N1 - 1 
Furthermore, let X(eiw) denote the Fourier transform of x[n]. We can construct a 
periodic signal x[n] that is equal to x[n] over one period. Specifically, let N 2::: N 1 
be a given integer, and let x[n] be periodic with period Nand such that 
x[n] = x[n], 
The Fourier series coefficients for x[n] are given by 
ak = _!_ L x[n]e- jk(27TIN)n 
N (N) 
Choosing the interval of summation to be that over which x[n] = x[n], we obtain 
1 N-1 
. 
ak = N L x[n]e- Jk(27TIN)n 
n=O 
(P5.53-1) 
The set of coefficients defined by eq. (P5.53-1) comprise the DFT of x[n]. Specifi-
cally, the DFT of x[n] is usually denoted by X[k], and is defined as 

418 
The Discrete-Time Fourier Transform 
Chap.5 
1 N - 1 
X[k] = ak = N L x[n]e- Jk(2TriN)n, 
n=O 
k = 0, 1, ... , N - 1 
(P5.53- 2) 
The importance of the DFT stems from several facts. First note that the original 
finite duration signal can be recovered from its DFT. Specifically, we have 
N - 1 
x[n] = L X[k]eik(2TriN)n, 
n = 0, 1, ... , N - 1 
(P5.53- 3) 
k=O 
Thus, the finite-duration signal can either be thought of as being specified by the 
finite set of nonzero values it assumes or by the finite set of values of X[k] in its DFT. 
A second important feature of the DFT is that there is an extremely fast algorithm, 
called the fast Fourier transform (FFT), for its calculation (see Problem 5.54 for 
an introduction to this extremely important technique). Also, because of its close 
relationship to the discrete-time Fourier series and transform, the DFT inherits some 
of their important properties. 
(a) Assume that N ~ N1• Show that 
where X[k] is the DFT of x[n]. That is, the DFT corresponds to samples of 
X(ei"') taken every 2nlN. Equation (P5.53-3) leads us to conclude that x[n] 
can be uniquely represented by these samples of X(ei"'). 
(b) Let us consider samples of X(ei"') taken every 27T/M, where M < N1• These 
samples correspond to more than one sequence of duration N1. To illustrate this, 
consider the two signals x1 [n] and x2[n] depicted in Figure P5.53. Show that if 
we choose M = 4, we have 
XI (ei(27rk/4)) = Xz (ei(27rkl4)) 
for all values of k. 
x1 [n] 
x2 [n] 
...... ~r
1
.I: ..... . 
0 
2 3 
n . ... ;• 
.iri:~I ... 
_111112341 
7 
n 
- 1 
Fig P5.53 
5.54. As indicated in Problem 5.53, there are many problems of practical importance in 
which one wishes to calculate the discrete Fourier transform (DFf) of discrete-time 
signals. Often, these signals are of quite long duration, and in such cases it is very 

Chap. 5 Problems 
419 
important to' use computationally efficient procedures. One of the reasons for the 
significant increase in the use of computerized techniques for the analysis of signals 
was the development of a very efficient technique known as the fast Fourier trans-
form (FFI') algorithm for the calculation of the DFf of finite-duration sequences. 
In this problem, we develop the principle on which the FFI' is based. 
Let x[n] be a signal that is 0 outside the interval 0 :s n :s N1 -
1. For N :::::: 
N 1, theN-point DFf of x[n] is given by 
X[k] = _!_ ~ 
x[n]e- /k(27TIN)n, 
k = 0, 1, ... , N - 1. 
N k=O 
It is convenient to write eq. (P5.54-1) as 
where 
1 N- 1 
X[k] = N L x[n]WN"· 
k=O 
(P5.54-1) 
(P5.54-2) 
(a) One method for calculating X[k] is by direct evaluation of eq. (P5.54-2). A 
useful measure of the complexity of such a computation is the total number of 
complex multiplications required. Show that the number of complex multipli-
cations required to evaluate eq. (P5.54-2) directly, fork = 0, 1, . . . , N - 1, is 
N2. Assume that x[n] is complex and that the required values of WN" have been 
precomputed and stored in a table. For simplicity, do not exploit the fact that, 
for certain values of n and k, WN" is equal to :±: 1 or :±: j and hence does not, 
strictly speaking, require a full complex multiplication. 
(b) Suppose that N is even. Let f[n] = x[2n] represent the even-indexed samples 
of x[n], and let g[n] = x[2n + 1] represent the odd-indexed samples. 
(i) 
Show that f[n] and g[n] are zero outside the interval 0 :s n :s (N/2)- 1. 
(ii) Show that theN-point DFf X[k] of x[n] can be expressed as 
1 
(N/2)- 1 
1 
(N/2) - 1 
X[k] = N L f[n]WN12 + N w~ L 
g[n]WN~ 
n=O 
n=O 
1 -
1 
k -
= 2F[k] + 2 w NG[k], k = 0, 1, . . . ' N - 1, (P5.54-3) 
where 
2 
(N/2)- 1 
F[k] = N L 
f[n]WN12• 
n=O 
2 
(N/2)- 1 
-
""" 
k 
G[k] = N L 
g[n]WNn· 
n=O 

420 
The Discrete-Time Fourier Transform 
Chap.5 
(iii) Show that, for all k, 
-[ N] 
-
F k + 2 
= F[k], 
-[ N] 
-
G k + 2 
= G[k]. 
Note that F[k], k = 0, 1, . . . , (N/2) - 1, and G[k], k = 0, 1, ... , (N/2) -
1, are the (N/2)-point DFfs of f[n] and g[n], respectively. Thus, eq. 
(P5.54-3) indicates that the length-N DFf of x[n] can be calculated in 
terms of two DFfs of length N /2. 
(iv) Determine the number of complex multiplications required to compute 
X[k], k = 0, 1, 2, . .. , N - 1, from eq. (P5.54-3) by first computing F[k] 
and G[k]. [Make the same assumptions about multiplications as in part (a), 
and ignore the multiplications by the quantity 112 in eq. (P5.54-3).] 
(c) If, likeN, N/2 is even, then f[n] and g[n] can each be decomposed into se-
quences of even- and oddcindexed samples, and therefore, their DFfs can be 
computed using the same process as in eq. (P5.54-3). Furthermore, if N is an 
integer power of 2, we can continue to iterate the process, thus achieving sig-
nificant savings in computation time. With this procedure, approximately how 
many complex multiplications are required for N = 32, 256, 1 ,024, and 4,096? 
Compare this to the direct method of calculation in part (a). 
5.55. In this problem we introduce the concept of windowing, which is of great importance 
both in the design of LTI systems and in the spectral analysis of signals. Windowing 
is the operation of taking a signal x[ n] and multiplying it by a finite-duration window 
signal w[n]. That is, 
p[n] = x[n]w[n]. 
Note that p[n] is also of finite duration. 
The importance of windowing in spectral analysis stems from the fact that in 
numerous applications one wishes to compute the Fourier transform of a signal that 
has been measured. Since in practice we can measure a signal x[n] only over a finite 
time interval (the time window), the actual signal available for spectral analysis is 
[n] = { x[n], 
-M :s_ n ::; M, 
P 
0, 
otherwise 
· 
where - M ::; n ::; M is the time window. Thus, 
p[n] = x[n]w[n], 
where w[n] is the rectangular window; that is, 
{ 
1, 
- M ::; n ::; M 
w[n] = 
0, 
otherwise 
· 
(PS.SS-1) 
Windowing also plays a role in LTI system design. Specifically, for a variety of 
reasons (such as the potential utility of the FFf algorithm; see Problem P5.54), it is 

Chap. 5 Problems 
421 
often advantageous to design a system that has an impulse response of finite duration 
to achieve some desired signal-processing objective. That is, we often begin with 
a desired frequency response H(eiw) whose inverse transform h[n] is an impulse 
response of infinite (or at least excessively long) duration. What l.s required then 
is the construction of an impulse response g[n] of finite duration whose transform 
G(eiw) adequately approximates H(eiw). One general approach to choosing g[n] is 
to find a window function w[n] such that the transform of h[n]w[n] meets the desired 
specifications for G(eiw). 
Clearly, the windowing of a signal has an effect on the resulting spectrum. In 
this problem, we illustrate that effect. 
(a) To gain some understanding of the effect of windowing, consider windowing 
the signal 
00 
x[n] = L, 5[n - k] 
k = - oo 
using the rectangular window signal given in eq. (P5.55- 1). 
(i) 
What is X(eiw)? 
(ii) Sketch the transform of p[n] = x[n]w[n] when M = 1. 
(iii) Do the same forM = 10. 
(b) Next, consider a signal x[n] whose Fourier transform is specified by 
lwl < TT/4 
7T/4 < lwl s 7T · 
Let p[n] = x[n]w[n], where w[n] is the rectangular window of eq. 
(P5.55-1). Roughly sketch P(eiw) forM = 4, 8, and 16. 
(c) One of the problems with the use of a rectangular window is that it introduces 
ripples in the transform P(eiw). (This is in fact directly related to the Gibbs 
phenomenon.) For that reason, a variety of other window signals have been 
developed. These signals are tapered; that is, they go from 0 to 1 more gradually 
than the abrupt transition of the rectangular window. The result is a reduction in 
the amplitude of the ripples in P( eiw) at the expense of adding a bit of distortion 
in terms of further smoothing of X(eiw). 
To illustrate the points just made, consider the signal x[ n] described in part 
(b), and let p[n] = x[n]w[n], where w[n] is the triangular or Bartlett window; 
that is, 
w[n] = 
M+ l' 
- . 
-
. 
{ 1 - A 
-M < n < M 
0, 
otherwtse 
Roughly sketch the Fourier transform of p[n] = x[n]w[n] forM = 4, 8, and 
16. [Hint: Note that the triangular signal can be obtained as a convolution of 
a rectangular signal with itself. This fact leads to a convenient expression for 
W(eiw).] 

422 
The Discrete-Time Fourier Transform 
Chap.5 
(d) Let p[n] = x[n]w[n], where w[n] is a raised cosine signal known as the Han-
ning window; i.e., 
w[n] = { iD + cos(1rn/M)], 
- M :5. n :5 M. 
0, 
otherwise 
Roughly sketch P(eiw) forM = 4, 8, and 16. 
5.56. Let x[m, n] be a signal that is a function of the two independent, discrete variables 
m and n. In analogy with one dimension and with the continuous-time case treated 
in Problem 4.53, we can define the two-dimensional Fourier transform of x[m, n] as 
00 
00 
X(eiw1, eiwz) = L L x[m, n]e- J<wlm+wznl. 
(P5.56-l) 
n= - oo m= - oo 
(a) Show that eq. (P5.56-1) can be calculated as two successive one-dimensional 
Fourier transforms, first in m, with n regarded as fixed, and then inn. Use this 
result to determine an expression for x[m, n] in terms of X(eiw1, eiwz). 
(b) Suppose that 
x[m, n] = a[m]b[n], 
where a[m] and b[n] are each functions of only one independent variable. Let 
A(eiw) and B(eiw) denote the Fourier transforms of a[m] and b[n], respectively. 
Express X(eiw1, eiwz) in terms of A(eiw) and B(eiw). 
(c) Determine the two-dimensional Fourier transforms of the following signals: 
(i) 
x[m, n] = 5[m- 1]5[n + 4] 
(ii) x[m, n] = <i)n- mu[n- 2]u[ -m] 
(iii) x[m, n] = <i)n cos(21Tml3)u[n] 
(' ) 
[ 
] _ { 1, 
-2 < m < 2 and -4 < n < 4 
IV x m, n -
0, 
otherwise 
(v) 
{ 1 
-2 + n < m < 2 + nand - 4 < n < 4 
x[m, n] = 
o: 
otherwise 
(vi) x[m,n] = sin(;n + 
2~m) 
(d) Determine the signal x[m, n] whose Fourier transform is 
X( jw 1 
jw2 ) = { 1, 
0 < lw 1 I :5 7T/4 and 0 < lw2l :5 7T/2 
e 
'e 
0, 
1T/4 < lw1 I < 1T or 1TI2 < lw2l < 1T 
· 
(e) Let x[m, n] and h[m, n] be two signals whose two-dimensional Fourier trans-
forms are denoted by X(eiw1, eiwz) and H(eiw1, eiwz), respectively. Deter-
mine the transforms of the following signals in terms of X ( eiw 1, eiwz) and 
H(eiwl, eJw2): 
(i) 
x[m, n]eiW1meJWzn 
("") 
[ 
] 
{ x[k, r], 
if m = 2k and n = 2r 
11 
Y m, n = 
O, 
if m is not a multiple of 2 or n is not a multiple of 3 
(iii) y[m, n] = x[m, n]h[m, n] 

6 
TIMEANDFREQUENCY 
CHARACTERIZATION 
OFSIGNALSANDSYSTEMS 
6.0 INTRODUCTION 
The frequency-domain characterization of an LTI system in terms of its frequency re-
sponse represents an alternative to the time-domain characterization through convolution. 
In analyzing LTI systems, it is often particularly convenient to utilize the frequency do-
main because differential and difference equations and convolution operations in the time 
domain become algebraic operations in the frequency domain. Moreover, concepts such as 
frequency-selective filtering are readily and simply visualized in the frequency domain. 
However, in system design, there are typically both time-domain and frequency-domain 
considerations. For example, as we briefly discussed in Examples 4.18 and 5.12, and as we 
will illustrate in more detail in this chapter, significant oscillatory behavior in the impulse 
response of a frequency-selective filter may be undesirable, and consequently, we may 
wish to sacrifice the level of frequency selectivity in a filter in order to meet the required 
tolerances on impulse response behavior. Situations such as this are the rule rather than 
the exception in practice, as in most applications we would like to specify or constrain 
certain characteristics of a system in both the time domain and the frequency domain, 
frequently resulting in conflicting requirements. Hence, in system design and analysis, it 
is important to relate time-domain and frequency-domain characteristics and trade-offs. 
Introducing these issues and relationships is the primary focus of the chapter. 
6.1 THE MAGNITUDE-PHASE REPRESENTATION OF THE FOURIER TRANSFORM 
The Fourier transform is in general complex valued and, as we discussed, can be repre-
sented in terms of its real and imaginary components or in terms of magnitude and phase. 
423 

424 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
The magnitude-phase representation of the continuous-time Fourier transform X(jw) is 
X(jw) = JX(jw)Jej<U(Jw)_ 
(6.1) 
Similarly the magnitude-phase representation of the discrete-time Fourier transform 
X(ejw) is 
(6.2) 
In the following discussion, we concentrate for the most part on the continuous-time case 
in describing and illustrating several points related to magnitude-phase representations. 
The essential points apply equally to the discrete-time case. 
From the Fourier transform synthesis equation ( 4.8), we can think of X(jw) as pro-
viding us with a decomposition of the signal x(t) into a "sum" of complex exponentials at 
different frequencies. In fact, as discussed in Section 4.3.7, JX(jw)J2 may be interpreted 
as the energy-density spectrum of x(t). That is, JX(jw )J2dwi21T can be thought of as the 
amount of energy in the signal x(t) that lies in the infinitesimal frequency band between 
wand w + dw. Thus, the magnitude JX(jw)J describes the basic frequency content of a 
signal- i.e., IX(jw )I provides us with the information about the relative magnitudes of the 
complex exponentials that make up x(t). For example, if IX(jw )I = 0 outside of a small 
band of frequencies centered at zero, then x(t) will display only relatively low-frequency 
oscillations. 
The phase angle <r..X(jw ), on the other hand, does not affect the amplitudes of the 
individual frequency components, but instead provides us with information concerning the 
relative phases of these exponentials. The phase relationships captured by <r..X(jw) have 
a significant effect on the nature of the signal x(t) and thus typically contain a substan-
tial amount of information about the signal. In particular, depending upon what this phase 
function is, we can obtain very different-looking signals, even if the magnitude function 
remains unchanged. For example, consider again the example illustrated in Figure 3.3. In 
this case, a ship encounters the superposition of three wave trains, each of which can be 
modeled as a sinusoidal signal. With fixed magnitudes for these sinusoids, the amplitude 
of their sum may be quite small or very large, depending on the relative phases. The im-
plications of phase for the ship, therefore, are quite significant. As another illustration of 
the effect of phase, consider the signal 
1 
2 
x(t) = 1 + 2 cos(21Tt + <f>t) + cos(41Tt + </>2) + 3 cos(61Tt + 4>3). 
(6.3) 
In Figure 3.4, we depicted x(t) for the case when <f>t = </>2 = </>3 = 0. In Figure 6.1, we 
illustrate x(t) for this case also and for several other choices for the phase of the individual 
components. As this figure demonstrates, the resulting signals can differ significantly for 
different relative phases. 
In general, changes in the phase function of X(jw) lead to changes in the time-
domain characteristics of the signal x(t). In some instances phase distortion may be 
important, whereas in others it is not. For example, a well-known property of the auditory 
system is a relative insensitivity to phase. Specifically, if the Fourier transform of a spoken 
sound (e.g., a vowel) is subjected to a distortion such that the phase is changed but the 
magnitude is unchanged, the effect can be perceptually negligible, although the waveform 
in the time domain may look considerably different. While mild phase distortions such as 
those affecting individual sounds do not lead to a loss of intelligibility, more severe phase 

Sec. 6.1 
The Magnitude-Phase Representation of The Fourier Transform 
425 
(a) 
(b) 
~. 
(c) 
(d) 
Figure 6.1 
The signal x(t) given in 
eq. (6.3) for several different choices 
of the phase angles 4>1 , 4>2, and cfl3: 
(a) </>1 = 4>2 = cfJ3 = 0; (b) 
4>1 = 4 rad, 4>2 = 8 rad, cfJ3 = 12 rad; 
(c) 4>1 = 6 rad, 4>2 = -2.7 rad, cfJ3 = 
0.93 rad; (d) 4>1 = 1.2 rad, 4>2 = 4.1 
rad, cfJ3 = - 7.02 rad. 
distortions of speech certainly do. As an extreme illustration, if x(t) is a tape recording of a 
sentence, then the signal x( -t) represents the sentence played backward. From Table 4.1, 
assuming x(t) is real valued, the corresponding effect in the frequency domain is to replace 
the Fourier transform phase by its negative: 
5'{x(- t)} =X(- jw) = IX(jw)le- J<l:X(Jw)_ 
That is, the spectrum of a sentence played in reverse has the same magnitude function as 
the spectrum of the original sentence and differs only in phase. Clearly, this phase change 
has a significant impact on the intelligibility of the recording. 
A second example illustrating the effect and importance of phase is found in exarnin-
ing images. As we briefly discussed in Chapter 3, a black-and-white picture can be thought 
of as a signal x(t1, t2), with t1 denoting the horizontal coordinate of a point on the picture, 
tz the vertical coordinate, and x(t1, tz) the brightness of the image at the point (t1, tz). The 
Fourier transform X(jw 1, jw 2) of the image represents a decomposition of the image into 
complex exponential components of the· form eiw 111 eiw212 that capture the spatial varia-
tions of x(t1, t2) at different frequencies in each of the two coordinate directions. Several 
elementary aspects of two-dimensional Fourier analysis are addressed in Problems 4.53 
and 5.56. 
In viewing a picture, some of the most important visual information is contained in 
the edges and regions of high contrast. Intuitively, regions of maximum and minimum 

426 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
(a) 
(b) 
(c) 
(d) 
intensity in a picture are places at which complex exponentials at different frequencies are 
in phase. Therefore, it seems plausible to expect the phase of the Fourier transform of a 
picture to contain much of the information in the picture, and in particular, the phase should 
capture the information about the edges. To substantiate this expectation, in Figure 6.2(a) 
we have repeated the picture shown in Figure 1.4. In Figure 6.2(b) we have depicted the 
magnitude of the two-dimensional Fourier transform of the image in Figure 6.2(a), where 
in this image the horizontal axis is w 1, the vertical is w2, and the brightness of the image 
at the point (w 1, w 2) is proportional to the magnitude of the transform X(jw I> jw2) of the 
image in Figure 6.2(a). Similarly, the phase of this transform is depicted in Figure 6.2(c). 
Figure 6.2(d) is the result of setting the phase [Figure 6.2(c)] of X(jw 1, jw2) to zero (with-
out changing its magnitude) and inverse transforming. In Figure 6.2(e) the magnitude of 
X(jw 1, jw2) was set equal to 1, but the phase was kept unchanged from what it was in 
Figure 6.2(c). Finally, in Figure 6.2(f) we have depicted the image obtained by inverse 
transforming the function obtained by using the phase in Figure 6.2( c) and the magnitude 
of the transform of a completely different image-
the picture shown in Figure 6.2(g)! 
These figures clearly illustrate the importance of phase in representing images. 

Sec. 6.2 
The Magnitude-Phase Representation of the Frequency Response of LTI Systems 
(e) 
(g) 
(f) 
Figure 6.2 
(a) The image shown in Figure 1.4; 
(b) magnitude of the two-dimensional Fourier 
transform of (a); (c) phase of the Fourier trans-
form of (a); (d) picture whose Fourier transform 
has magnitude as in (b) and phase equal to zero; 
(e) picture whose Fourier transform has magnitude 
equal to 1 and phase as in (c); (f) picture whose 
Fourier transform has phase as in (c) and magni-
tude equal to that of the transform of the picture 
shown in (g). 
6.2 THE MAGNITUDE-PHASE REPRESENTATION 
OF THE FREQUENCY RESPONSE OF LTI SYSTEMS 
427 
From the convolution property for continuous-time Fourier transforms, the transform 
Y(jw) of the output of an LTI system is related to the transform X(jw) of the input to the 
system by the equation 
Y(jw) = H(jw)X(jw), 
where H(jw) is the frequency response of the system-i.e., the Fourier transform of the 
system's impulse response. Similarly, in discrete time, the Fourier transforms of the input 
X(ejw) and ouput Y(ejw) of an LTI system with frequency response H(ejw) are related by 
Y(ejw) = H(ejw)X(ejw). 
(6.4) 
Thus, the effect that an LTI system has on the input is to change the complex ampli-
tude of each of the frequency components of the signal. By looking at this effect in terms 
of the magnitude-phase representation, we can understand the nature of the effect in more 

428 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
detail. Specifically, in continuous time, 
IYUw )I = IHUw )IIXUw )I 
(6.5) 
and 
<r.Y(jw) = <r.H(jw) + <r.X(jw), 
(6.6) 
and exactly analogous relationships hold in the discrete-time case. From eq. (6.5), we see 
that the effect an LTI system has on the magnitude of the Fourier transform of the sig-
nal is to scale it by the magnitude of the frequency response. For this reason, IH(jw )I (or 
IH(ejw)l) is commonly referred to as the gain of the system. Also, from eq. (6.6), we see 
that the phase of the input <r.X(jw) is modified by the LTI system by adding the phase 
<r.H(jw) to it, and <r.H(jw) is typically referred to as the phase shift of the system. The 
phase shift of the system can change the relative phase relationships among the compo-
nents of the input, possibly resulting in significant modifications to the time domain char-
acteristics of the input even when the gain of the system is constant for all frequencies. 
The changes in the magnitude and phase that result from the application of an input to 
an LTI system may be either desirable, if the input signal is modified in a useful way, or 
undesirable, if the input is changed in an unwanted m~ner. In the latter case, the effects 
in eqs. (6.5) and (6.6) are commonly referred to as maghitude and phase distortions. In 
the following sections, we describe several concepts and tools that allow us to understand 
these effects a bit more thoroughly. 
6.2.1 Linear and Nonlinear Phase 
When the phase shift at the frequency w is a linear function of w, there is a particularly 
straightforward interpretation of the effect in the time domain. Consider the continuous-
time LTI system with frequency response 
H(jw) = e-jwro, 
so that the system has unit gain and linear phase-i.e., 
IH(jw )I = 1, <r.H(jw) = - wto. 
(6.7) 
(6.8) 
As shown in Example 4.15, the system with this frequency response characteristic pro-
duces an output that is simply a time shift of the input-i.e., 
y(t) = x(t - to). 
(6.9) 
In the discrete-time case, the effect oflinear phase is similar to that in the continuous-
time case when the slope of the linear phase is an integer. Specifically, from Example 5.11, 
we know that the LTI system with frequency response e- jwno with linearphase function 
- wn0 produces an ouput that is a simple shift ofthe input-i.e., y[n] = x[n- n0]. Thus, a 
linear phase shift with an integer slope corresponds to a shift of"x[n] by an integer number 
of samples. When the phase slope is not an integer, the effect in the time domain is some-
what more complex and is discussed in Chapter 7, Section 7.5. Informally, the effect is a 
time shift of the envelope of the sequence values, but the values themselves may change. 
While linear phase shifts lead to very simple and easily understood and visualized 
changes in a signal, if an input signal is subjected to a phase shift that is a nonlin-
ear function of w, then the complex exponential components of the input at different 
frequencies will be shifted in a manner that results in a change in their relative phases. 
When these exponentials are superimposed, we obtain a signal that may look considerably 
different from the input signal. This is illustrated in Figure 6.3 in the continuous-time case. 

~ 
N -o 
(a) 
0 
(c) 
0 
10 
(b) 
0 
(d) 
Figure 6.3 
(a) Continuous-time signal that is applied as the input to several systems 
for which the frequency response has unity magnitude; (b) response for a system with 
linear phase; (c) response for a system with nonlinear phase; and (d) response for a 
system with phase equal to the nonlinear phase of the system in part (c) plus a linear 
phase term. 

430 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
In Figure 6.3(a), we depict a signal that is applied as the input to three different systems. 
Figure 6.3(b) shows the output when the signal is applied as input to a system with fre-
quency response H 1 (jw) = e- jwto, resulting in an output that equals the input delayed by 
to seconds. In Figure 6.3(c), we display the output when the signal is applied to a system 
with unity gain and nonlinear phase function-i.e., 
(6.10) 
where <r..H2(jw) is a nonlinear function of w. Figure 6.3(d) shows the output from another 
system with nonlinear phase. In this case, the corresponding frequency response has a 
phase shift that is obtained by adding a linear phase term to <r..H2(jw )-i.e., 
(6.11) 
Thus, the output in Figure 6.3(d) can be thought of as the response to a cascade of the 
system H2(jw) followed by a time shift, so that the waveforms in Figures 6.3(c) and (d) 
are related through a simple time shift. 
In Figure 6.4, we illustrate the effect of both linear and nonlinear phase in the 
discrete-time case. Once again, the signal in Figure 6.4(a) is applied as the input to three 
different LTI systems, all with unity gain (i.e., jH(ejw)j = 1). The signals in the subse-
quent parts of Figure 6.4 depict the corresponding outputs. In the case of Figure 6.4(b ), 
the system has linear phase characteristics with integer slope of -5, so that the output 
equals the input delayed by 5. The phase shifts for the systems associated with Figures 
6.4(c) and (d) are nonlinear, but the difference between these two phase functions is linear 
with integer slope so that the signals in Figures 6.4(c) and (d) are related by a time shift. 
Note that all the systems considered in the examples illustrated in Figures 6.3 and 6.4 
have unity gain, so that the magnitude of the Fourier transform of the input to any of 
these systems is passed through unchanged by the system. For this reason, such systems 
are commonly referred to as all-pass systems. The characteristics of an all-pass system 
are completely determined by its phase-shift characteristics. A more general LTI system 
H(jw) or H(ejw), of course, imparts both magnitude shaping through the gain jH(jw )j or 
jH(ejw)j and phase shift that may or may not be linear. 
6.2.2 Group Delay 
As discussed in Section 6.2.1, systems with linear phase characteristics have the particu-
larly simple interpretation as time shifts. In fact, from eqs. (6.8) and (6.9), the phase slope 
tells us the size of the time shift. That is, in continuous time, if <r..H(jw) = -wt0, then 
the system imparts a time shift of -t0 or, equivalently, a delay of t0• Similarly, in discrete 
time, <r..H(ejw) = -wn0 corresponds to a delay of no. 
The concept of delay can be very naturally and simply extended to include nonlin-
ear phase characteristics. Suppose that we wish to examine the effects of the phase of a 
continuous-time LTI system on a narrowband input-i.e., an input x(t) whose Fourier 
transform is zero or negligibly small outside a small band of frequencies centered at 
w = w0 . By taking the band to be very small, we can accurately approximate the phase 
of this system in the band .with the linear approximation 
<r..H(jw) = -cp - wa, 
(6.12) 

Sec. 6.2 
0 
0 
0 
The Magnitude-Phase Representation of the Frequency Response of LTI Systems 
431 
(a) 
5 
(b) 
(c) 
(d) 
n 
n 
n 
Figure 6.4 
{a) Discrete-time signal 
that is applied as input to several sys-
tems for which the frequency response 
has unity magnitude; {b) response for 
a system with linear phase with slope 
of - 5; {c) respon~e for a system with 
nonlinear phase; and {d) response for 
a system whose phase characteristic 
is that of part {c) plus a linear phase 
term with integer slope. 

432 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
so that 
(6.13) 
Thus, the approximate effect of the system on the Fourier transform of this narrowband 
input consists of the magnitude shaping corresponding to IH(jw )I, multiplication by an 
overall constant complex factor e- icf> and multiplication by a linear phase term e- Jwa 
corresponding to a time delay of a seconds. This time delay is referred to as the group 
delay at w = wo, as it is the effective common delay experienced by the small band or 
group of frequencies centered at w = wo. 
The group delay at each frequency equals the negative of the slope of the phase at 
that frequency; i.e., the group delay is defined as 
r(w) = - d~ {<t.H(jw)}. 
(6.14) 
The concept of group delay applies directly to discrete-time systems as well. In the next 
example we illustrate the effect of nonconstant group delay on a signal. 
Example 6.1 
Consider the impulse response of an all-pass system with a group delay that varies with 
frequency. The frequency response H (jw) for our example is the product of three factors; 
i.e., 
where 
3 
H(jw) = fl H;(jw), 
i = l 
. 
1 + (}w!w;)
2 
- 2jl; (wlw;) 
H;(Jw) = 
2 
, 
1 + (iw!w;) + 2jl; (wlw;) 
{ 
w 1 = 315 rad/sec and ' 1 = 0.066, 
w 2 = 943 rad/sec and ' 2 = 0.033, 
w 3 = 1888 rad/sec and ' 3 = 0.058. 
(6.15) 
It is often useful to express the frequencies w; measured in radians per second in terms 
of frequencies /; measured in Hertz, where 
In this case, 
W ; = 27T j;. 
f 1 =50Hz 
h =150Hz 
!3 =300Hz. 
Since the numerator of each of the factors H;(jw) is the complex conjugate of 
the corresponding denominator, it follows that IH;(jw )I = 1. Consequently, we may also 

Sec. 6.2 
The Magnitude-Phase Representation of the Frequency Response of LTI Systems 
433 
conclude that 
jH(jw)l = 1. 
The phase for each H;(jw) can be determined from eq. (6.15): 
<J:H;(jw) = -2arctan 
1 
1
2 
, 
[ 
2{(wlw ·) l 
1- (wlw;) 
and 
3 
<J:H(jw) = L <l:H;(jw). 
i ~
l 
If the values of <J:H(jw) are restricted to lie between -7r and 7T, we obtain the principal-
phase function (i.e., the phase modulo 27T), as shown in Figure 6.5(a) where we have 
plotted the phase versus frequency measured in Hertz. Note that this function con-
tains discontinuities of size 27T at various frequencies, making the phase function non-
differentiable at those points. However, the addition or subtraction of any integer multiple 
of 27T to the value of the phase at any frequency leaves the original frequency response 
unchanged. Thus, by appropriately adding or subtracting such integer multiples of 27T 
from various portions of the principal phase, we obtain the unwrapped phase in Fig-
ure 6.5(b). The group delay as a function of frequency may now be computed as 
T(w) = - d~ {<J:[H(jw)]}, 
where <J:[H(jw)] represents the unwrapped-phase function corresponding to H(jw). A 
plot of T(w) is shown in Figure 6.5(c). Observe that frequencies in the close vicinity of 
50 Hz experience greater delay than frequencies in the vicinity of 150Hz or 300Hz. The 
effect of such nonconstant group delay can also be qualitatively observed in the impulse 
response (see Figure 6.5(d)) of the LTI system. Recall that ff{li(t)} = 1. The frequency 
components of the impulse are all aligned in time in such a way that they combine to 
form the impulse, which is, of course, highly localized in time. Since the all-pass system 
has nonconstant group delay, different frequencies in the input are delayed by different 
amounts. This phenomenon is referred to as dispersion. In the current example, the group 
delay is highest at 50 Hz. Consequently, we would expect the latter parts of the impulse 
response to oscillate at lower frequencies near 50 Hz. This clearly evident in Figure 
6.5(d). 
Example 6.2 
Nonconstant group delay is among the factors considered important for assessing the 
transmission performance of switched telecommunications networks. In a survey1 in-
volving locations all across the continental United States, AT&T/Bell System reported 
group delay characteristics for various categories of toll calls. Figure 6.6 displays some 
of the results of this study for two such classes. In particular, what is plotted in each 
curve in Figure 6.6(a) is the nonconstant portion of the group delay for a specific cate-
gory of toll calls. That is, for each category, a common constant delay corresponding to 
1 "Analog Transmission Performance on the Switched Telecommunications Network," by F. P: Duffy 
and T. W. Thatcher, Jr., in the Bell System Technical Journal, vol. 50, no. 4, April, 1971. 

434 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
- 2 
-4L-~--~------~----~------~----_J------~------L---~~ 
0 
50 
100 
150 
200 
Frequency (Hz) 
250 
300 
350 
400 
(a) 
0~--~--------~----~------,------,------~------r-----~ 
- 5 
0.08 
I 
,., 0.06 
.!ll 
' ., 
" c g. 0.04 
e 
(!) 
0.02 
50 
100 
50 
100 
150 
200 
250 
300 
Frequency (Hz) 
150 
200 
250 
300 
Frequency (Hz) 
350 
350 
400 
(b) 
400 
(c) 
600r----,----~-----r----~----.-----~----~---,----~----~ 
400 
200 
0 
- 200 
- 400 
- 600L_ __ _J ____ ~ 
____ _L ____ _L ____ ~----~----L---_J----~----~ 
0 
0.02 
0.04 
0.06 
0.08 
0.1 
0.12 
0.14 
0.16 
0.18 
0.2 
Time (sec) 
(d) 
Figure 6.5 
Phase, group delay, and impulse response for the all-pass sys-
tem of Example 6.1: (a) principal phase; (b) unwrapped phase; (c) group delay; 
(d) impulse response. Each of these quantities is plotted versus frequency 
measured in Hertz. 

7,000 
6,000 
'g 
~ 5,000 
e 
0 
14,000 
~ 
~ 
c. e 
3,000 
(!) 
c 
~ 
5 2,000 
0 <: 
0 z 
1,000 
0 
0 
Sec. 6.2 
Medium 
\ 
\\ 
Short\ ~ 
~ 
The Magnitude-Phase Representation of the Frequency Response of LTI Systems 
I 
Modi"m I 
I 
J v; 
k?l 
Short 
~ 
0 
- 5 
3 
- 10 
::::> 
J: 
0 ,;; 
.Q 
~ - 15 
- 20 
- 25 
- 30 
Sho~ ~ 
r.......... " 
\ 
Medium 
Medium 
435 
Short 
600 
1 ,200 
1 ,800 
2,400 
3,000 
3,800 
0 
600 
1 ,200 
1 ,BOO 
2,400 
3,000 
3,600 
Frequency in (Hz) 
Frequency in (Hz) 
(a) 
(b) 
Figure 6.6 
(a) Non-constant portion of the group delay; and (b) frequency re-
sponse magnitude as functions of frequency for short- and medium-distance toll calls 
in switched telecommunications networks [after Duffy and Thatcher]. Each of these 
quantities is plotted versus frequency measured in Hertz. Also, as is commonly done 
in practice, the magnitudes of the frequency responses are plotted using a logarithmic 
scale in units of decibels. That is, what is plotted in (b) is 20 log10 !H(jw )I for the fre-
quency responses corresponding to short- and medium-distance toll calls. The use of 
this logarithmic scale for the frequency-response magnitudes is discussed in detail in 
Section 6.2.3. 
r· · the minimum of the group delay over all frequencies has been subtracted from the group 
delay, and the resulting difference is plotted in Figure 6.6(a). Consequently, each curve 
in Figure 6.6(a) represents the additional delay (beyond this common constant delay) 
experienced by the different frequency components of toll calls within each category. 
The curves labeled SHORT and MEDIUM respectively represent the results for short-
distance (0-180 airline miles) and medium-distance (180-725 airline miles) toll calls. 
The group delay as a function of frequency is seen to be lowest at 1, 700Hz and increases 
monotonically as we move away from that figure in either direction. 
When the group delay characteristics illustrated in Figure 6.6(a) are combined 
with the characteristics of the magnitude of the frequency response reported in the same 
AT &T/Bell System survey and shown in Figure 6.6(b ), we obtain impulse reponses of the 
type shown in Figure 6.7. The impulse response in Figure 6.7(a) corresponds to the short-
distance category. The very low- and very high-frequency components of the response 
occur later than the components in the mid-frequency range. This is compatible with 

0.6 
0.4 
0.2 
0 
- 0.2 
- 0.4 
0 
0.6 
0.4 
0.2 
0 
-0.2 
-0.4 
0 
436 
Time and Frequency Characterization of Signals and Systems 
2 
3 
4 
4 
5 
Time (msec) 
(a) 
5 
Time(msec) 
(b) 
6 
7 
8 
6 
7 
8 
Figure 6.7 
Impulse responses associated with the group delay and magnitude char-
acteristics in Figure 6.6: (a) impulse response corresponding to the short-distance cate-
gory of toll calls; (b) impulse response for the medium-distance category. 
9 
9 
Chap.6 
10 
10 
-, the corresponding group delay characteristics in Figure 6.6(a), Similarly, Figure 6.7(b) 
• illustrates the same phenomenon for the impulse response corresponding to medium-
distance toll calls. 
6.2.3 Log-Magnitude and Phase Plots 
In graphically displaying continuous-tune or discrete-time Fourier transforms and system 
frequency responses in polar form, it is often convenient to use a logarithmic scale for the 
magnitude of the Fourier transform. One of the principal reasons for doing this can be seen 

Sec. 6.2 
The Magnitude-Phase Representation of the Frequency Response of LTI Systems 
437 
from eqs. (6.5) and (6.6), which relate the magnitude and phase of the output of an LTI 
system to those of the input and frequency response. Note that the phase relationship is 
additive, while the magnitude relationship involves the product of JH(jw )j and JX(jw )J. 
Thus, if the magnitudes of the Fourier transform are displayed on a logarithmic amplitude 
scale, eq. (6.5) takes the form of an additive relationship, namely, 
logJY(jw)J = logJH(jw)J + logJX(jw)J, 
(6.16) 
with an exactly analogous expression in discrete time. 
Consequently, if we have a graph of the log magnitude and phase of the Fourier 
transform of the input and the frequency response of an LTI system, the Fourier transform 
of the output is obtained by adding the log-magnitude plots and by adding the phase plots. 
In a similar fashion, since the frequency response of the cascade of LTI systems is the 
product of the individual frequency responses, we can obtain plots of the log magnitude and 
phase of the overall frequency response of cascaded systems by adding the corresponding 
plots for each of the component systems. In addition, plotting the magnitude of the Fourier 
transform on a logarithmic scale allows detail to be displayed over a wider dynamic range. 
For example, on a linear scale, the detailed magnitude characteristics in the stopband of 
a frequency-selective filter with high attenuation are typically not evident, whereas they 
are on a logarithmic scale. 
Typically, the specific logarithmic amplitude scale used is in units of 20 log 10, re-
ferred to as decibels2 (abbreviated dB). Thus, 0 dB corresponds to a frequency response 
with magnitude equal to 1, 20 dB is equivalent to a gain of 10, - 20 dB corresponds to an 
attenuation of 0. 1, and so on. Also, it is useful to note that 6 dB approximately corresponds 
to a gain of 2. 
For continuous-time systems, it is also common and useful to use a logarithmic 
frequency scale. Plots of 20log10 jH(jw)J and <r..H(jw) versus log10(w) are referred to 
as Bode plots. A typical Bode plot is illustrated in Figure 6.8. Note that, as discussed 
in Section 4.3.3, if h(t) is real, then jH(jw )J is an even function of w and <r..H(jw) is 
an odd function of w. Because of this, the plots for negative w are superfluous and can 
be obtained immediately from the plots for positive w. This, of course, makes it pos-
sible to plot frequency response characteristics versus log 10(w) for w > 0, as in the 
figure. 
The use of a logarithmic frequency scale offers a number of advantages in continu-
ous time. For example, it often allows a much wider range of frequencies to be displayed 
than does a linear frequency scale. In addition, on a logarithmic frequency scale, the shape 
2The origin of this particular choice of units and the term decibels can be traced to the definition of 
power ratios in systems. Specifically, since the square of the magnitude of the Fourier transform of a signal can 
be interpreted as the energy per unit frequency, or power, in a signal, the square of the magnitude, IH (jw )12 or 
iH(ejw )i2 , of the frequency response of a system can be thought of as the power ratio between the input and 
the output of an LTI system. In honor of Alexander Graham Bell, the inventor of the telephone, the term bel 
was introduced to indicate a factor of 10 in a power ratio, and decibel was used to denote one-tenth of this 
factor on a logarithmic scale (so that the cascade of 10 systems with 1-dB power ratios each would result in 
1 bel of power amplification). Thus, 10log10 IH(jw)l2 is the number of decibels of power amplification for the 
frequency response H(jw ), and this in tum equals 20 log 10 iH(jw )I in magnitude amplification. 

438 
Time and Frequency Characterization of Signals and Systems 
20 
-
10 
S OdB~----~ 
I -;; - 10 
i -20 
~ - 30 
-40 
-50 
0 t-------
3 
'IT 
::;::: 
2 
I 
"' 
- 'lT 
10 
100 
1.000 
Figure 6.8 
A typical Bode plot. (Note that w is plotted using a logarithmic 
scale.) 
Chap.6 
of a particular response curve doesn't change if the frequency is scaled. (See Problem 
6.30.) Furthermore for continuous-time LTI systems described by differential equations, 
an approximate sketch of the log magnitude vs. log frequency can often be easily obtained 
through the use of asymptotes. In Section 6.5, we will illustrate this by developing sim-
ple piecewise-linear approximate Bode plots for first- and second-order continuous-time 
systems. 
In discrete time, the magnitudes of Fourier transforms and frequency responses are 
often displayed in dB for the same reasons that they are in continuous time. However, 
in discrete time a logarithmic frequency scale is not typically used, since the range of 
frequencies to be considered is always limited and the advantage found for differential 
equations (i.e., linear asymptotes) does not apply to difference equations. Typical graphi-
cal representations of the magnitude and phase of a discrete-time frequency response are 
shown in Figure 6.9. Here, we have plotted 4:H(ejw) in radians and IH(ejw)l in decibels 
[i.e., 20 log 10 IH(ejw)IJ as functions of w. Note that for h[n] real, we actually need plot 
H(ejw) only for 0 s w s 7T, because in this case the symmetry property of the Fourier 
transform implies that we can then calculate H(ejw) for -7r s w s 0 using the relations 
IH(ejw)l = IH(e-jw)l and 4:H(e- jw) = -4:H(ejw). Furthermore, we need not consider . 
values of lwl greater than 7T, because of the periodicity of H(ejw). 

Sec. 6.3 
Time-Domain Properties of Ideal Frequency-Selective Filters 
24dB 
20 
16 
12 
- 12 
1T 
2 
1T 
2 
Figure 6. 9 
Typical graphical representations of the magnitude and phase of 
a discrete-time frequency response H(eiw). 
439 
As emphasized in this section, a logarithmic amplitude scale is often useful and 
important. However, there are many situations in which it is convenient to use a linear 
amplitude scale. For example, in discussing ideal filters for which the magnitude of the 
frequency response is a nonzero constant over some frequency bands and zero over others, 
a linear amplitude scale is more appropriate. Thus, we have introduced both linear and 
logarithmic graphical representations for the magnitude of the Fourier transform and will 
use each as appropriate. 
6.3 TIME-DOMAIN PROPERTIES OF IDEAL FREQUENCY-SELECTIVE FILTERS 
In Chapter 3, we introduced the class of frequency-selective filters, i.e., LTI systems with 
frequency responses chosen so as to pass one or several bands of frequencies with little or 
no attenuation and to stop or significantly attenuate frequencies outside those bands. As 
we discussed in Chapters 3, 4, and 5, there are a number of issues of importance that arise 

440 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
in frequency-selective filtering applications and that relate directly to the characteristics 
of frequency-selective filters. In this section, we take another look at such filters and their 
properties. We focus our attention here on lowpass filters, although very similar concepts 
and results hold for other types of frequency-selective filters such as highpass or bandpass 
filters. (See Problems 6.5, 6.6, 6.26, and 6.38.) 
As introduced in Chapter 3, a continuous-time ideallowpass filter has a frequency 
response of the form 
H(jw) = { 1 lwl ~We
. 
0 lwl >We 
(6.17) 
This is illustrated in Figure 6.10(a). Similarly, a discrete-time ideallowpass filter has a 
frequency response 
H(jw) 
(a) 
(b) 
Figure 6.1 o (a) The frequency response of a continuous-time ideal low-
pass filter; (b) the frequency response of a discrete-time ideal lowpass filter. 
(6.18) 
w 
and is periodic in w, as depicted in Figure 6.10(b). As can be seen from eqs. (6.17) 
and (6.18) or from Figure 6.10, ideallowpass filters have perfect frequency selectivity. 
That is, they pass without attenuation all frequencies at or lower than the cutoff frequency 
w e and completely stop all frequencies in the stopband (i.e., higher than We). Moreover, 
these filters have zero phase characteristics, so they introduce no phase distortion. 
As we have seen in Section 6.2, nonlinear phase characteristics can lead to signifi-
cant changes in the time-domain characteristics of a signal even when the magnitude of its 

Sec. 6.3 
Time-Domain Properties of Ideal Frequency-Selective Filters 
441 
spectrum is not changed by the system, and thus, a filter with a magnitude characteristic as 
in eq. (6.17) or eq. (6.18), but with nonlinear phase, might produce undesirable effects in 
some applications. On the other hand, an ideal filter with linear phase over the passband, 
as illustrated in Figure 6.11, introduces only a simple time shift relative to the response of 
the ideallowpass filter with zero phase characteristic. 
IH(iw)l 
11 
-we 
0 
4: H(jw)= - aw 
we 
w 
Figure 6.11 
Continuous-time ideal 
lowpass filter with linear phase charac-
teristic. 
In Examples 4.18 and 5.12, we computed the impulse responses of ideallowpass 
filters. In particular, the impulse response corresponding to the filter in eq. (6.17) is 
h(t) = sin7T~e t' 
(6.19) 
which is shown in Figure 6.12(a). Similarly, the impulse response of the discrete-time 
ideal filter in eq. (6.18) is 
h[n] = sin Wen, 
7Tn 
(6.20) 
which is depicted in Figure 6.12(b )for we = . 7T/4. If either of the ideal frequency responses 
of eqs. (6.17) and (6.18) is augmented with a linear phase characteristic, the impulse 
response is simply delayed by an amount equal to the negative of the slope of this phase 
function, as is illustrated in Figure 6.13 for the continuous-time impulse response. Note 
that in both continuous and discrete time, the width of the filter passband is proportional 
to We, while the width of the main lobe of the impulse is proportional to llwe. As the 
bandwidth of the filter increases, the impulse response becomes narrower, and vice versa, 
consistent with the inverse relationship between time and frequency discussed in Chapters 
4 and 5. 

442 
h(t) 
(a) 
h[n] 
(b) 
Figure 6.12 
(a) The impulse response of the continuous-time Ideal lowpass filter 
of Figure 6.10(a); (b) the impulse response of the discrete-time ideallowpass filter of 
Figure 6.10(b) with we = 7T/4. 
h(t-a) 
Figure 6.13 
Impulse response of an ideal lowpass filter with magnitude 
and phase shown in Figure 6.11. 
n 

Sec. 6.3 
Time-Domain Properties of Ideal Frequency-Selective Filters 
443 
The step responses s(t) and s[n] of the ideallowpass filters in continuous time and 
discrete time are displayed in Figure 6.14. In both cases, we note that the step responses 
exhibit several characteristics that may not be desirable. In particular, for these filters, 
the step responses overshoot their long-term final values and exhibit oscillatory behavior, 
frequently referred to as ringing. Also, recall that the step response is the running integral 
or sum of the impulse response-i.e., 
s(t) = r oo h(T)dT, 
II 
s[n] = 2: h[m]. 
m ==-o:J 
s(t) 
(a) 
s[n] 
(b) 
Figure 6. 14 
(a) Step response of a continuous-time ideal lowpass filter; 
(b) step response of a discrete-time ideal lowpass filter. 
n 

444 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
Since the impulse responses for the ideal filters have main lobes extending from - 'TI'Iwc 
to +'TI'Iwc. the step responses undergo their most significant change in value over this 
time interval. That is, the so-called rise time of the step response, a rough measure of the 
response time of the filter, is also inversely related to the bandwidth of the filter. 
6.4 TIME-DOMAIN AND FREQUENCY-DOMAIN ASPECTS 
OF NONIDEAL FILTERS 
The characteristics of ideal filters are not always desirable in practice. For example, in 
many filtering contexts, the signals to be separated do not always lie in totally disjoint 
frequency bands. A typical situation might be that depicted in Figure 6.15, where the 
spectra of two signals overlap slightly. In such a case, we may wish to trade off the fi-
delity with which the filter preserves one of these signals-say, x1 (f)-against the level 
to which frequency components of the second signal x2(t) are attenuated. A filter with 
a gradual transition from passband to stopband is generally preferable when filtering the 
superposition of signals with overlapping spectra. 
X(jw) 
Figure 6. 1 s 
Two spectra that are 
w 
slightly overlapping. 
Another consideration is suggested by examining the step responses of ideallowpass 
filters, shown in Figure 6.14. For both continuous time and discrete time, the step response 
asymptotically approaches a constant equal to the value of the step. In the vicinity of the 
discontinuity, however, it overshoots this value and exhibits ringing. In some situations, 
this time-domain behavior may be undesirable. 
Moreover, even in cases where the ideal frequency-selective characteristics are de-
sirable, they may not be attainable. For example, from eqs. (6.18) and (6.19) and Fig-
ure 6.12, it is evident that the ideallowpass filter is noncausal. When filtering is to be 
carried out in real time, however, causality is a necessary constraint, and thus, a causal 
approximation to the ideal characteristics would be required. A further consideration that 
motivates providing some flexibility in the filter characteristics is ease of implementation. 
In general, the more precisely we try to approximate or implement an ideal frequency-
selective filter, the more complicated or costly the implementation becomes, whether in 
terms of components such as resistors, capacitors, and operational amplifiers in continu-
ous time or in terms of memory registers, multipliers, and adders in discrete time. In many 
contexts, a precise filter characteristic may not be essential and a simple filter will suffice. 
For all of these reasons, nonideal filters are of of considerable practical importance, 
and the characteristics of such filters are frequently specified or quantified in terms of 
several parameters in both the frequency and time domain. First, because the magnitude 
characteristics of the ideal frequency-selective filter may be unachievable or undesirable, 

Sec. 6.4 
Time-Domain and Frequency-Domain Aspects of Nonideal Filters 
445 
it is preferable to allow some flexibility in the behavior of the filter in the passband and 
in the stopband, as well as to permit a more gradual transition between the passband and 
stopband, as opposed to the abrupt transition characteristic of ideal filters. For example, 
in the case of lowpass filters, the specifications may allow some deviation from unity gain 
in the passband and from zero gain in the stopband, as well as including both a passband 
edge and stopband edge with a transition band between them. Thus, specifications for a 
continuous-time lowpass filter are often stated to require the magnitude of the frequency 
response of the filter to be restricted to the nonshaded area indicated in Figure 6.16. In 
this figure, a deviation from unity of plus and minus 81 is allowed in the passband, and a 
deviation of 82 from zero is allowed in the stopband. The amount by which the frequency 
response differs from unity in the passband is referred to as the passband ripple, and the 
amount by which it deviates from zero in the stopband is referred to as the stopband ripple. 
The frequency Wp is refetTed to as the passband edge and Ws as the stopband edge. The 
frequency range from w P to W s is provided for the transition from passband to stopband 
and is referred to as the transition band. Similar definitions apply to discrete-time lowpass 
filters, as well as to other continuous- and discrete-time frequency-selective filters. 
IH(jw)l 
\ 1\ 
I 
\ 
I 
\ 
I 
, \ 
I 
Passband : Tran·sjtion : 
\ 
I 
\ 
I 
\ 
I 
' r·· 
Stopband 
Figure 6.16 
Tolerances for the 
magnitude characteristic of a lowpass 
filter. The allowable passband ripple 
is 81 and stopband ripple is ~ . The 
dashed curve illustrates one possible 
frequency response that stays within 
the tolerable limits. 
In addition to the specification of magnitude characteristics in the frequency domain, 
in some cases the specification of phase characteristics is also important. In particular, a 
linear or nearly linear phase characteristic over the passband of the filter is frequently 
desirable. 
To control the time-domain behavior, specifications are frequently imposed on the 
step response of a filter. As illustrated in Figure 6.17, one quantity often of interest is the 
rise time tr of the step response-i.e., the interval over which the step response rises toward 
its final value. In addition, the presence or absence of oscillatory behavior, or ringing, in the 
step response is often of importance. If such ringing is present, then there are three other 
quantities that are often used to characterize the nature of these oscillations: the overshoot 
a Of the final value Of the Step response, the ringing frequency Wr, and the settling time 
t5-i.e., the time required for the step response to settle to within a specified tolerance of 
its final value. 
For nonideallowpass filters, a trade-off may be observed between the width of the 
transition band (a frequency-domain characteristic) and the settling time of the step re-
sponse (a time-domain characteristic). The following example illustrates this trade-off. 

446 
Time and Frequency Characterization of Signals and Systems 
s(t) 
t, 
Figure 6. 1 1 
Step response of a continuous-time lowpass filter, indicating 
the rise time t,, overshoot 11, ringing frequency w,, and settling time t5-i.e., 
the time at which the step response settles to within ±.S of its final value. 
Example 6.3 
Chap.6 
Let us consider two specific lowpass filters designed to have a cutoff frequency of 500 
Hz. Each filter has a fifth-order rational frequency response and a real-valued impulse 
response. The two filters are of specific types, one referred to as Butterworth filters 
and the other as elliptic filters. Both of these classes of filters are frequently used in 
practice. 
The magnitudes of the frequency responses of the two filters are plotted (versus 
frequency measured in Hertz) in Figure 6.18(a). We take <the transition band of each 
filter as the region around the cutoff frequency (500 Hz) where the frequency response 
magnitude is neither within .05 of unity magnitude (the passband ripple) nor within .05 
of zero magnitude (the stopband ripple). From Figure 6.18(a), it can be seen that the 
transition band of the Butterworth filter is wider than the transition band of the elliptic 
filter. 
The price paid for the narrower transition band of the elliptic filter may be observed 
in Figure 6.18(b ), in which the step responses of both filters are displayed. We see that 
the ringing in the elliptic filter's step response is more prominent than for the Butterworth 
step response. In particular, the settling time for the step response is longer in the case 
of the elliptic filter. 
The consideration of the trade-offs between time-domain and frequency-domain 
characteristics and of other issues such as the complexity and cost of filters forms the 
core of the important field of filter design. In the next few sections, and in several of the 
problems at the end of the chapter, we provide additional examples of LTI systems and 
filters and their time- and frequency-domain characteristics. 

Sec. 6.4 
Time-Domain and Frequency-Domain Aspects of Nonideal Filters 
447 
5l 
c 
8. 
rJl 
~ 
>. 
0 c 
Cll 
::l 
0" 
~ 
0 
Q) 
"0 
.;! ·c: 
Cl 
"' 
:I! 
-~~~ -- - - - - -- ---- --- - - - -- - --- --- - - ------ --- - - -
' 
0.9 
0.8 
0.7 
0.6 
0.5 
0.4 
0.3 
0.2 
0.1 
\ --Elliptic filter 
\ 
\ ' ' ' 
I 
I 
I 
I ' ' ' ' ' \ 
\ __.-- Butterworth filter 
' ' ' ' ' " .. , .. 
--- - -- --- -- - - -- ~-~
~·~~~
-----.-__ ------------~-w-~-~
- -
- ---~ 
0 
200 
400 
600 
800 
1 ,000 1 ,200 
1 ,400 
1 ,600 1 ,800 2,000 
Frequency (Hz) 
1.2 
' ' ' ' ' 
0.8 
I 
I 
I 
' ' 
0.6 
I ' ' ' ' ' 
0.4 
' ' ' ' 
I 
I 
0.2 
I 
' ' ' 
I 
I 
I 
0 
2 
4 
6 
8 
10 
12 
14 
16 
18 
Time(msec) 
Figure 6.18 
Example of a fifth-order Butterworth filter and a fifth-order 
elliptic filter designed to have the same passband and stopband ripple and 
the same cutoff frequency: (a) magnitudes of the frequency responses plotted 
versus frequency measured in Hertz; (b) step responses. 
20 

448 
Time and Frequency Characterization' of Signals and Systems 
Chap.6 
6.5 FIRST-ORDER AND SECOND-ORDER CONTINUOUS-TIME SYSTEMS 
LTI systems described by linear constant-coefficient differential equations are of great 
practical importance, because many physical systems can be modeled by such equations 
and because systems of this type can often be conveniently implemented. For a variety 
of practical reasons, high-order systems are frequently implemented or represented by 
combining first-order and second-order systems in cascade or parallel arrangements. Con-
sequently, the properties of first- and second-order systems play an important role in an-
alyzing, designing, and understanding the time-domain and frequency-domain behavior 
of higher order systems. In this section, we discuss these low-order systems in detail for 
continuous time. In Section 6.6, we examine their discrete-time counterparts. 
6.5.1 First-Order Continuous-Time Systems 
The differential equation for a first-order system is often expressed in the form 
dy(t) 
T---;[t + y(t) = x(t), 
(6.21) 
where the coefficient -r is a positive number whose significance will be made clear 
shortly. The corresponding frequency response for the first-order system is 
and the impulse response is 
H(jw) = 
. 1 I' 
JWT+ 
which is sketched in Figure 6.19(a). The step response ofthe system is 
s(t) = h(t) * u(t) = [1 - e- 117]u(t). 
(6.22) 
(6.23) 
(6.24) 
This is sketched in Figure 6.19(b ). The parameter r is the time constant of the system, and 
it controls the rate at which the first-order system responds. For example, as illustrated in 
Figure 6.19, at t = r the impulse response has reached lie times its value at t = 0, and 
the step response is within 11 e of its final value. Therefore, as r is decreased, the impulse 
response decays more sharply, and the rise time of the step response becomes shorter- i.e., 
it rises more sharply toward its final value. Note also that the step response of a first-order 
system does not exhibit any ringing. 
Figure 6.20 depicts the Bode plot of the frequency response of eq. (6.22). In this 
figure we illustrate one of the advantages of using a logarithmic frequency scale: We can, 
without too much difficulty, obtain a useful approximate Bode plot for a continuous-time 
first-order system. To see this, let us first examine the plot of the log magnitude of the 
frequency response. Specifically, from eq. (6.22), we obtain 
20 log10 IH(jw )I = -10 log10[(wr)2 + 1]. 
(6.25) 
From this, we see that for wr << 1, the log magnitude is approximately zero, while for 
wr » 1, the log magnitude is approximately a linear function of log10(w ). That is, 
20log10 IH(jw)l = 0 
for 
w « 1/r, 
(6.26) 

h(t) 
,. 
(a) 
s(t) 
---- - - -- -- - --- -- - -·-=..- -::,;;-.---=-----
,. 
Figure 6.19 
Continuous-time first-
(b) 
order system: (a) impulse response; 
(b) step response. 
20 
3dB 
3 OdB 
__ _j , , 
Asymptotic 
~ 
~approx imation 
0 
Oi 
- 20 
.2 
0 
C\1 
- 40 
- 60 
0.1/T 
1/T 
10/T 
100/T 
w 
11"14 
0 
3 
::::> 
J: 
"1-
- 11"/4 
- 11"/2 
- 311"/4 
0.1;,. 
1/T 
1 0/T 
1 00/T 
Figure 6.20 
Bode plot for a 
w 
continuous-time first-order system. 
449 

450 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
and 
20 log10 IH(jw )I = -20 log10(wT) 
= -20log10(w)- 20log10(T) for 
w »liT. 
(6.27) 
In other words, for the first-order system, the low- and high-frequency asymptotes of the 
log magnitude are straight lines. The low-frequency asymptote [given by eq. (6.26)] is just 
the 0-dB line, while the high-frequency asymptote [specified by eq. (6.27)] corresponds to 
a decrease of 20 dB in IH (jw )I for every decade (i.e., factor of 10) in w. This is sometimes 
referred to as a "20-dB-per-decade" asymptote. 
Note that the two asymptotic approximations given in eqs. (6.26) and (6.27) are equal 
at the point log10(w) = -log10(T), or equivalently, w = liT. Interpreted graphically, this 
means that the two straight-line asymptotes meet at w = liT, which suggests a straight-
line approximation to the magnitude plot. That is, our approximation to 20 log10 IH(jw )I 
equals 0 for w :5 liT and is given by eq. (6.27) for w ;::::: 1/T. This approximation is also 
sketched (as a dashed line) in Figure 6.20. The point at which the slope of the approxima-
tion changes is precisely w = liT, which, for this reason, is often referred to as the break 
frequency. Also, note that at w = liT the two terms [(wT)2 and 1] in the argument of the 
logarithm in eq. (6.25) are equal. Thus, at this point, the actual value ofthe magnitude is 
20log10 IH (j~ )I = -10log10(2) = - 3 dB. 
(6.28) 
Because of this, the point w = liT is sometimes called the 3-dB point. From the figure, 
we see that only near the break frequency is there any significant error in the straight-line 
approximate Bode plot. Thus, if we wish to obtain a more accurate sketch of the Bode plot, 
we need only modify the approximation near the break frequency. 
It is also possible to obtain a useful straight-line approximation to 1:.H(jw ): 
1:.H(jw) = - tan- 1(wT) 
{ 
0, 
W :5 O.ll T 
= 
-('7T/4)[log10(wT) + 1], 
O.liT :5 w :5 lOfT. 
-7T/2, 
W 
;::::: lOfT 
(6.29) 
Note that this approximation decreases linearly (from 0 to -7T/2) as a function of log 10(w) 
in the range 
0.1 
10 
:5 w :5 -
, 
T 
T 
i.e., in the range from one decade below the break frequency to one decade above the break 
frequency. Also, zero is the correct asymptotic value of 1:.H(jw) for w << liT, and - 7T/2 
is the correct asymptotic value of 1:.H(jw) for w » liT. Furthermore, the approximation 
agrees with the actual value of 1:.H(jw) at the break frequency w = liT, at which point 
<t.H(j~) = -~. 
(6.30) 
This asymptotic approximation is also plotted in Figure 6.20, and from it we can see how, 
if desired, we can modify the straight-line approximation to obtain a more accurate sketch 
of 1:.H(jw ). 

Sec. 6.5 
First-Order and Second-Order Continuous-Time Systems 
451 
From this first-order system, we can again see the inverse relationship between time 
and frequency. As we make T smaller, we speed up the time response of the system [i.e., 
h(t) becomes more compressed toward the origin, and the rise time of the step response 
is reduced] and we s~multaneously make the break frequency large [i.e., H(jw) becomes 
broader, since IH(jw)l = 1 for a larger range of frequencies]. This can also be seen by 
multiplying the impulse response by T and observing the relationship between Th(t) and 
H(jw): 
Th(t) = e - tiT u(t), 
1 
H(jw) = jwT+ 1· 
Thus, Th(t) is a function of tiT and H(jw) is a function of wT, and from this we see that 
changing T is essentially equivalent to a scaling in time and frequency. 
6.5.2 Second-Order Continuous-Time Systems 
The linear constant-coefficient differential equation for a second-order system is 
d2y(t) 
dy(t) 
2 
2 
~ 
+ 2{;wn"d( + wny(t) = WnX(t). 
(6.31) 
Equations of this type arise in many physical systems, including RLC circuits and me-
chanical systems, such as the one illustrated in Figure 6.21, composed of a spring, a mass, 
and a viscous damper or dashpot. In the figure, the input is the applied force x(t) and the 
output is the displacement of the mass y(t) from some equilibrium position at which the 
spring exerts no restoring force. The equation of motion for this system is 
m d2y(t) = x(t)- ky(t) - b dy(t) 
dt2 
dt ' 
or 
d2y(t) + (!?__)dy(t) + (!:_)y(t) = _!_x(t). 
dt2 
m 
dt 
m 
m 
Comparing this to eq. ( 6.31 ), we see that if we identify 
and 
Wn =If 
b 
(= -2Jk;t' 
~ 
y(t) (displacement) 
(6.32) 
x(t) (applied force) 
Figure 6.21 
Second-order system 
consisting of a spring and dashpot 
attached to a moveable mass and a 
fixed support. 

452 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
then [except for a scale factor of k on x(t)] the equation of motion for the system of Figure 
6.21 reduces to eq. (6.31). 
The frequency response for the second-order system of eq. (6.31) is 
2 
H(jw) = (jw )2 + 2~::(jw) + w~ · 
The denominator of H(jw) can be factored to yield 
where 
CJ = -~wn + Wn~• 
c2 = -~wn - Wn~· 
(6.33) 
(6.34) 
For ~ """ 1, c1 and c2 are unequal, and we can perform a partial-fraction expansion of the 
form 
where 
M 
H(jw) = ---
jw- CJ 
Wn 
M= - === 
2~· 
M 
From eq. (6.35), the corresponding impulse response for the system is 
h(t) = M[ec 11 -
ec21]u(t). 
If~ = 1, then CJ = c2 = - wn, and 
w~ 
H(jw) = (jw + Wn)2" 
From Table 4.2, we find that in this case the impulse response is 
h(t) = w~te - wnt u(t). 
(6.35) 
(6.36) 
(6.37) 
(6.38) 
(6.39) 
Note from eqs. (6.37) and (6.39), that h(t)lwn is a function of Wnt. Furthermore, 
eq. (6.33) can be rewritten as 
H(jw) = 
2 
1 
' 
{jw!wn} + 2~ (jwlwn) + 1 
from which we see that the frequency response is a function of wlwn. Thus, changing Wn 
is essentially identical to a time and frequency scaling. 
The parameter ~ is referred to as the damping ratio and the parameter w n as the 
undamped natural frequency. The motivation for this terminology becomes clear when 

s(t) 
2 
Sec. 6.5 
First-Order and Second-Order Continuous-Time Systems 
453 
we take a more detailed look at the impulse response and the step response of a second-
order system. First, from eq. (6.35), we see that for 0 < ( < 1, c 1 and c 2 are complex, and 
we can rewrite the impulse response in eq. (6.37) in the form 
w e - ~w n t 
h(t) = 
p,{exp[j(w 11 ~)t] - exp[- j(wn~)t]}u(t) 
2j 1- ( 2 
(6.40) 
Thus, for 0 < ( < 1, the second-order system has an impulse response that has 
damped oscillatory behavior, and in this case the system is referred to as being under-
damped. If ( > 1, both Ct and c2 are real and negative, and the impulse response is the 
difference between two decaying exponentials. In this case, the system is overdamped. The 
case of ( = 1, when c1 = c2, is called the critically damped case. The impulse responses 
(multiplied by llw 11 ) for second-order systems with different values of ( are plotted in 
Figure 6.22(a). 
(a) 
(b) 
Figure 6.22 
Response of continu-
ous-time second-order systems with 
different values of the damping 
ratio (: (a) impulse response; 
(b) step response. 

454 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
The step response of a second-order system can be calculated from eq. (6.37) for 
~ =F 1. This yields the expression 
{ 
[
ecJt 
ec2t ]} 
s(t) = h(t) * u(t) = 
1 + M ~ 
- Cz 
u(t). 
(6.41) 
For~ = 1, we can use eq. (6.39) to obtain 
s(t) = [1 - e- w.t - w 11te- w" 1]u(t). 
(6.42) 
The step response of a second-order system is plotted in Figure 6.22(b) for several values 
of (. From this figure, we see that in the underdamped case, the step response exhibits 
both overshoot (i.e., the step response exceeds its final value) and ringing (i.e., oscillatory 
behavior). For~ = 1, the step response has the fastest response (i.e., the shortest rise time) 
that is possible without overshoot and thus has the shortest settling time. As ~ increases 
beyond 1, the response becomes slower. This can be seen from eqs. (6.34) and (6.41). As~ 
increases, c1 becomes smaller in magnitude, while c2 increases in magnitude. Therefore, 
although the time constant (lljc2J) associated with ec21 decreases, the time constant (llic11) 
associated with ec 11 increases. Consequently the term involving ec1t in eq. (6.41) takes a 
longer time to decay to zero, and thus it is the time constant associated with this term that 
determines the settling time of the step response. As a result the step response takes longer 
to settle for large values of~. In terms of our spring-dashpot example, as we increase the 
magnitude of the damping coefficient b beyond the critical value at which~ in eq. (6.33) 
equals 1, the motion of the mass becomes increasingly sluggish. 
Finally, note that, as we have said, the value of w 11 essentially controls the time scale 
of the responses h(t) and s(t). For example, in the underdamped case, the larger W 11 is, the 
more compressed is the impulse response as a function oft, and the higher is the frequency 
of the oscillations or ringing in both h(t) and s(t). In fact, from eq. (6.40), we see that 
the frequency of the oscillations in h(t) and s(t) is w 11~, 
which does increase with 
increasing w 11 • Note, however, that this frequency depends explicitly on the damping ratio 
and does not equal (and is in fact smaller than) w 11 , except in the undamped case,~ = 0. 
(It is for this reason that the parameter w n is traditionally referred to as the undamped 
natural frequency.) For the spring-dashpot example, we therefore conclude that the rate of 
oscillation of the mass equals w 11 when no dash pot is present, and the oscillation frequency 
decreases when we include the dashpot. 
In Figure 6.23, we have depicted the Bode plot of the frequency response given in 
eq. (6.33) for several values of~· As in the first-order case, the logarithmic frequency scale 
leads to linear high- and low-frequency asymptotes for the log magnitude. Specifically, 
from eq. (6.33), 
From this expression, it follows that 
20log10 IH(jw)i = { ~401 
+ 401 
og10 w 
og10 W 11, 
forw << Wn 
forw >> Wn · 
(6.43) 
(6.44) 

Sec. 6.5 
First-Order and Second-Order Continuous-Time Systems 
8 
Asymptotic 
= -20 
approximation 
::c 
0 
Oi 
.Q 
- 40 
0 
C\J 
-60 
- 80 
0.1wn 
Wn 
10wn 
w 
0 
-TI/4 
3 i' -TI/2 
Asymptotic 
approximation 
v 
- 3'IT/4 
w 
Figure 6.23 
Bode plots for second-order systems with several different 
values of damping ratio ( . 
455 
Therefore, the low-frequency asymptote of the log magnitude is the 0-dB line, while the 
high-frequency asymptote [given by eq. (6.44)] has a slope of - 40 dB per decade; i.e., 
IH(jw )I decreases by 40 dB for every increase in w of a factor of 10. Also, note that the 
two straight-line asymptotes meet at the point w = W 11 • Thus, we obtain a straight-line 
approximation to the log magnitude by using the approximation given in eq. (6.44) for 
w :::.;; w 11 • For this reason, w 11 is referred to as the break frequency of the second-order 
system. This approximation is also plotted (as a dashed line) in Figure 6.23. 
We can, in addition, obtain a straight-line approximation to <r..H(jw ), whose exact 
expression can be obtained from eq. (6.33): 
xH(. ) = _ 
- I ( 
2~(w lwn) ) 
'~--
JW 
tan 
1 - (wlwn)2 . 
(6.45) 

456 
The approximation is 
Time and Frequency Characterization of Signals and Systems 
w :.:; O.lwn 
O.lwn :.:; W :.:; 10W 11, 
w;::::: lOwn 
Chap. 6 
(6.46) 
which is also plotted in Figure 6.23. Note that the approximation and the actual value again 
are equal at the break frequency w = w ," where 
It is important to observe that the asymptotic approximations, eqs. (6.44) and (6.46), 
we have obtained for a second-order system do not depend on~. while the actual plots of 
IH(jw )I and <r..H(jw) certainly do, and thus, to obtain an accurate sketch, especially near 
the break frequency w = Wn, we must take this into account by modifying the approxi-
mations to conform more closely to the actual plots. The discrepancy is most pronounced 
for small values of(. In particular, note that in this case the actual log magnitude has a 
peak around w = W 11 • In fact, straightforward calculations using eq. (6.43) show that, for 
( < ./it2 = 0.707, IH(jw)l has a maximum value at 
Wmax = WnJl- 2(2, 
and the value at this maximum point is 
(6.47) 
(6.48) 
For ( > 0.707, however, H(jw) decreases monotonically as w increases from zero. The 
fact that H(jw) can have a peak is extremely important in the design offrequency-selective 
filters and amplifiers. In some applications, one may want to design such a circuit so 
that it has a sharp peak in the magnitude of its frequency response at some specified 
frequency, thereby providing large frequency-selective amplification for sinusoids at fre-
quencies within a narrow band. The quality Q of such a circuit is defined to be a measure 
of the sharpness of the peak. For a second-order circuit described by an equation of the 
form of eq. (6.31), the quality is usually taken to be 
1 
Q = 2f 
and from Figure 6.23 and eq. (6.48), we see that this definition has the proper behavior: 
The less damping there is in the system, the sharper is the peak in IH(jw )1. 
6.5.3 Bode Plots for Rational Frequency Responses 
At the start of this section, we indicated that first- and second-order systems can be used 
as basic building blocks for more complex LTI systems with rational frequency responses. 
One consequence of this is that the Bode plots presented here essentially provide us with 

Sec. 6.5 
First-Order and Second-Order Continuous-Time Systems 
457 
all of the information we need to construct Bode plots for arbitrary rational frequ~ncy 
responses. Specifically, we have described the Bode plots for the frequency responses 
given by eqs. (6.22) and (6.33). In addition, we can readily obtain the Bode plots for 
frequency responses of the forms 
H(jw) = 1 + jwT 
(6.49) 
and 
H(jw) = 1 + 
2{(~:)+ (~:r 
(6.50) 
The Bode plots for eqs. (6.49) aad (6.50) follow directly from Figures 6.20 and 6.23 and 
from the fact that 
20 log10 IH(jw)l = - 20 log10 I H(~w) I 
and 
<r.(H(jw )) = - <): (H(~w)} 
Also, consider a system function that is a constant gain 
H(jw) = K. 
Since K = IKiej·O if K > 0 and K = 1Kiej1T if K < 0, we see that 
20log10 IE(jw)l = 20log10 IKI 
<r.H( . ) = { 0, 
if K > 0 
JW 
'Tr, 
if K < 0 
Since a rational frequency response can be factored into the product of a construit gain and 
first- and second-order terms, its Bode plot can be obtained by summing the plots for each 
of the terms. We illustrate further the construction of Bode plots in the next two examples. 
Example 6.4 
Let us obtain the Bode plot for the frequency response 
2 X 104 
H(jw) = (jw)2 + IOOjw + 104' 
i First, we note that 
H(jw) = 2H(jw), 
where H(jw) has the same fortn as the standard second-order frequency response spec-
ified by eq. (6.33). It follows that 
20 log10 IH(jw )I = 20 log10 2 + 20 log IH(Jw )1. 

458 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
By comparing H(jw) with the frequency response in eq. (6.33), we conclude that w 11 = 
100 and~ = 112 for H(jw). Using eq. (6.44), we may now specify the asymptotes for 
20log10 IH(jw)l: 
20log10 IH(jw)l = 0 forw « 100, 
and 
20log10 IH(jw)l = -40log10 w + 80 forw » 100. 
It follows that 20 log 10 IH (jw )I will have the same asymptotes, except for a constant 
offset at all frequencies due to the addition of the 20 log10 2 term (which approxi-
mately equals 6 dB). The dashed lines in Figure 6.24(a) represent these asymptotes. 
OdB 
- 20 
1 
f 
- 40 
0 
r£ 
.Q -60 
0 
(\j 
-80 
- 100~0----------~-1----------~2~--------~~3--------~104 
10 
10 
10 
10 
w 
' ' 
(a) 
3 -7r/2 
= 
I 
>.:1 
w 
(b) 
Figure 6.24 
Bode plot for system function in Example 6.4: (a) magnitude; 
(b) phase. 

Sec. 6.5 
First-Order and Second-Order Continuous-Time Systems 
459 
The solid curve in the same figure represents the actual computer-generated Bode 
plot for 20log10 IH(Jw)l. Since the value of~ for H(jw) is less than :.;2!2, the actual 
Bode plot has a slight peak near w = 100. 
To obtain a plot of <tH(jw ), we note that 
<J:.H(jw) = <J:.H(jw) 
and that <J:.H(jw) has its asymptotes specified in accordance with eq. (6.46); that is, 
{
0, 
<J:.H(jw) = 
=~/2)[log 10 (w/100) + 1], 
ws10 
10 :::;; w :::;; 1,000. 
w ~ 1,000. 
The asymptotes and the actual values for <J:.H (jw) are plotted with dashed and solid 
lines, respectively, in Figure 6.24(b). 
Example 6.5 
Consider the frequency response 
. 
100(1+jw) 
H(;w) = (10 + jw)(100 + jw) 
To obtain the Bode plot for H(jw ), we rewrite it in the following factored form: 
H(jw) = Uo)(1 + Jwno)(1 + j~noo)0 + jw). 
Here, the first factor is a constant, the next two factors have the standard form for a first-
order frequency response as specified in eq. (6.22), and the fourth factor is the reciprocal 
of the same first-order standard form. The Bode plot for 20 log 10 IH(jw )I is therefore the 
sum of the Bode plots corresponding to each of the factors. Furthermore, the asymptotes 
corresponding to each factor may be summed to obtain the asymptotes for the overall 
Bode plot. These asymptotes and the actual values of 20 log 10 IH (jw )I are displayed in 
Figure 6.25(a). Note that the constant factor of 1110 accounts for an offset of - 20 dB at 
each frequency. The break frequency at w = 1 corresponds to the (1 + jw) factor, which 
produces the 20 dB/decade rise that starts at w = 1 and is canceled by the 20 dB/decade 
decay that starts at the break frequency at w = 10 and is due to the 11(1 + jw/10) factor. 
Finally, the 1/(1 + jw/100) factor contributes another break frequency at w = 100 and 
a subsequent decay at the rate of 20 dB/decade. 
Similarly we can construct the asymptotic approximation for4:.H {jro) from the in-
dividual asymptotes for each factor, as illustrated, together with a plot of the exact value 
of the phase, in Figure 6.25(b). In particular, the constant factor 1110 contributes 0 to 
the phase, while the factor (1 + jw) contributes an asymptotic approximation that is 0 
for w < 0.1, and rises linearly as a function oflog10(w) from a value of zero at w = 0.1 
to a value of n/2 radians at w = 10. However, this rise is canceled at w = 1 by the 
asymptotic approximation for the angle of 1/(1 + jw/10) which contributes a linear de-
crease in angle of n/2 radians over the range of frequencies from w = 1 tow = 100. 
Finally, the asymptotic approximation for the angle of 1/(1 + jw/100) contributes an-
other linear decrease in angle of n/2 radians over the range of frequencies from w = 10 
tow = 1000. 

460 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
- 40 
0.1 
10 
100 
1000 
w 
(a) 
rr/2 
rr/4 
0 
- rr/4 
-rr/2 
0.1 
10 
100 
1000 
w 
(b) 
Figure 6.25 
Bode plot for system function in Example 6.5: (a) magnitude; 
(b) phase. 
In our discussion of first-order systems in this section, we restricted our atten-
tion to values of T > 0. In fact, it is not difficult to check that if T < 0, then the 
causal first-order system described by eq. (6.21) has an impulse response that is not 
absolutely integrable, and consequently, the system is unstable. Similarly, in analyzing 
the second-order causal system in eq. (6.31), we required that both { and w~ be pos-
itive numbers. If either of these is not positive, the resulting impulse response is not 
absolutely integrable. Thus, in this section we have restricted attention to those causal 
first- and second-order systems that are stable and for which we can define frequency 
responses. 

Sec. 6.6 
First-Order and Second-Order Discrete-Time Systems 
461 
6.6 FIRST-ORDER AND SECOND-ORDER DISCRETE-TIME SYSTEMS 
In this section, we examine the properties of first- and second-order discrete-time LTI 
systems, paralleling the development in the preceding section. As in continuous time, any 
system with a frequency response that is a ratio of polynomials in e- Jw - i.e., any discrete-
time LTI system described by a linear constant-coefficient difference equation-can be 
written as a product or sum of first- and second-order systems, implying that these ba-
sic systems are of considerable value in both implementing and analyzing more complex 
systems. (See, for example, Problem 6.45.) 
6.6.1 First-Order Discrete-Time Systems 
Consider the first-order causal LTI system described by the difference equation 
y[n] - ay[n - 1] = x[n], 
(6.51) 
with Ia I < 1. From Example 5 .18, the frequency response of this system is 
. 
1 
H(elw) = 
. , 
1 - ae- Jw 
(6.52) 
and its impulse response is 
(6.53) 
which is illustrated in Figure 6.26 for several values of a. Also, the step response of the 
system is 
1 -an+! 
s[n] = h[n] * u[n] = 
1 _ a u[n], 
(6.54) 
which is illustrated in Figure 6.27. 
The magnitude of the parameter a plays a role similar to that of the time constant 
-r in the continuous-time first-order system. Specifically, ial determines the rate at which 
the first-order system responds. For example, from eqs. (6.53) and (6.54) and Figures 6.26 
and 6.27, we see that h[n] and s[n] converge to their final value at the rate at which lal" 
converges to zero. Therefore, the impulse response decays sharply and the step response 
settles quickly for lal small. For ial nearer to 1, these responses are slower. Note that unlike 
its continuous-time counterpart, the first-order system described by eq. (6.51) can display 
oscillatory behavior. This occurs when a < 0, in which case the step response exhibits 
both overshoot of its final value and ringing. 
The magnitude and phase of the frequency response of the first-order system in 
eq. (6.51) are, respectively, 
iH(eiw)i = ------=-1,----~ 
(1 + a2 - 2acosw) ll2 
(6.55) 

.j:lo 
o-
N 
h[n] 
h[n] 
1t 
1 
1t 
1 
a=+-
a=+-
•••••••••• r •••••••••••••••••••• :... 
• ••••••••• Jr •..•........••..... : __ _ 
0 
h[n] 
n 
0 
·-------------------
h[n] 
n 
1 t 
1 
a -
-
.......... . ................. ~~: .. . 
ol 
n 
(a) 
0 
(c) 
3 
a= - 4 
n 
n 
0 
(b) 
h[n] 
0 
(d) 
Figure 6.26 
Impulse response h[n] = anu[n] of a first-order system: (a) a = ±1/4; 
(b) a = ±1/2; (c) a = ±3/4; (d) a = ±7/8. 
1 
a=-2 
7 
a=-a 
n 
n 
n 

Sec. 6.6 
First-Order and Second-Order Discrete-Time Systems 
2 
4 
:f' . 
. .. 
1 
•••••••••~ JJJJJJJJJJJJJJJJJJJJJJJJJn 
2 
4 
:[In] 
a=-l 
••••••••• ~ rtttttttttlllltttlllltltln 
(a) 
s[n] 
a = + ~ 
5 
4 
4 
3 
2 
n 
3 
4 
'[' 
·--· 
......... : 
,,,,,,,,,,,,,,,,,,,,,,,,," 
(c) 
:f' 
... 
1 
....... ,.:_llllllllllllllllllllliiii" 
2 
2 
:l(n] 
a=- l 
••••••••• : rtttlllllllltlltttTTTTTTT" 
(b) 
s(n] 
8 
7 
a=+s 
7 
6 
5 
4 
3 
2 
n 
3 
. 
8 
•rl 
, __ I 
,,,,,,,,.: ,J,J,TtTtTtltltttttttttttn 
(d) 
Figure 6.27 
Step response s[n] of a first-order system: (a) a = ±1/4; (b) a = 
±1/2; (c) a = ±3/4; (d) a = ± 7/8. 
and 
463 
<r.H ( ejw) = _ tan_ 1 [ 
a sin w 
] . 
1 - acosw 
(6.56) 
In Figure 6.28(a), we have plotted the log magnitude and the phase of the frequency 
response in eq. (6.52) for several values of a > 0. The case of a < 0 is illustrated in 

464 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
Figure 6.28(b). From these figures, we see that for a > 0, the system attenuates high 
frequencies [i.e., !H(ejw)! is smaller for w near ±7T than it is for w near 0], while when 
a < 0, the system amplifies high frequencies and attenuates low frequencies. Note also 
that for lal small, the maximum and minimum values, 11(1 +a) and 11(1- a), of !H(ejw)! 
are close together in value, and the graph of !H(ejw)! is relatively flat. On the other hand, for 
!a! near 1, these quantities differ significantly, and consequently !H(ejw)! is more sharply 
peaked, providing filtering and amplification that is more selective over a narrow band of 
frequencies. 
7 
a= 8 
20 log10 IH(eiw)l 
20dB 
-8 
'IT 2 
(a) 
a= Z 
3 8 
a= -
1 4 
a=-2 
a=1 
4 
Figure 6.28 
Magnitude and phase of the frequency response of eq. (6.52) 
for a first-order system: (a) plots for several values of a > 0; (b) plots for 
several values of a < 0. 
w 
w 

Sec. 6.6 
First-Order and Second-Order Discrete-Time Systems 
- 21T 
a= - ~ 
a = - ~ 
a= - 14 
a= - 12 
4 
20 log10 IH(ei"')i 
20dB 
- 8 
1T 2 
(b) 
Figure 6.28 
Continued 
6.6.2 Second-Order Discrete-Time Systems 
Consider next the second-order causal LTI system described by 
y[n] - 2r cos Oy[n - 1] + ?y[n - 2] = x [n], 
with 0 < r < 1 and 0 ::s 0 ::s 7T. The frequency response for this system is 
. 
1 
H(elw) = 
. 
. 
. 
1- 2rcosoe- Jw + r 2e-J2w 
The denominator of H(ejw ) can be factored to obtain 
H(ejw) = 
·o 
. 1 
·o 
. . 
[1 - (reJ )e- JW][1 - (re- 1 )r JW] 
465 
w 
w 
(6.57) 
(6.58) 
(6.59) 

466 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
For() ¥ 0 or 'TT', the two factors in the denominator of H(elw) are different, and a partial-
fraction expansion yields 
where 
eiO 
A= 2} sin()' 
In this case, the impulse response of the system is 
h[n] = [A(rej(') 11 + B(re- jO)n]u[n] 
_ 
11 sin[(n + 1)()] [ ] 
-
r 
·e 
un. 
sm 
(6.60) 
(6.61) 
(6.62) 
For() = 0 or 'TT', the two factors in the denominator of eq. (6.58) are the same. When() = 0, 
. 
1 
. 
H(e1w) = 
(6 63) 
(1 - re- Jw)2 
. 
and 
h[n] = (n + l)r
11 u[n]. 
(6.64) 
When() = 'TT', 
(6.65) 
and 
h[n] = (n+ 1)(-r)"u[n]. 
(6.66) 
The impulse responses for second-order systems are plotted in Figure 6.29 for a range 
of values of rand(). From this figure and from eq. (6.62), we see that the rate of decay of 
h[n] is controlled by r-i.e., the closer r is to 1, the slower is the decay in h[n]. Similarly, 
the value of () determines the frequency of oscillation. For example, with () = 0 there is 
no oscillation in h[n], while for () = 
7T' the oscillations are rapid. The effect of different 
values of rand() can also be seen by examining the step response of eq. (6.57). For() ¥ 0 
or 'TT', 
[ (1 - (rel6)"+ 1 ) 
(1 - (re- JOy+ 1 \l 
s[n] = h[n] * u[n] = A 
1 _ reiO 
. + B 
1 _ rr 16 
}J u[n]. 
(6.67) 
Also, using the result of Problem 2.52, we find that for () = 0, 
[ ] 
[ 
1 
r 
11 
r 
"] [ ] 
s n = (r _ 1)2 - (r _ 1)2 r + r _ 1 (n + 1)r u n , 
(6.68) 
while for() = 'TT', 
s[n] = [(r:1)2 + (r:l)2(-r)"+ r~ · 1(n+l)(-r)"]u[n]. 
(6.69) 
The step response is plotted in Figure 6.30, again for a range of values of rand (). 

6= 0 
6=! 
6=¥ 
6 _ 3'11' 
- 4 
6='!1' 
Sec. 6.6 
r=l 
0 
1 
~ 
0 
1 I 
• 
0 
First-Order and Second-Order Discrete-Time Systems 
r = ~ 
9= 0 
1 
r= 4 
6 = ~ 
1 
r=4 
6 = ~ 
r = ~ 
a- 21! 
u - 4 
r = ~ 
6='11' 
n 
n 
n 
n 
n 
0 
1 ~I 
• 
0 
1 1. 
ol 
1 1~. 
of 
1
11, .. 
or 
r = ~ 
1 
r=2 
6=0 
1 
r=2 
6=i 
1 
r= 2 
6 = ~ 
1 
r= 2 
6- 21! 
- 4 
1 
r= 2 
6= '11' 
n 
n 
n 
n 
n 
r= ~ 
0 
3 
r= 4 
1 ~ 
6=i 
d! ... 
0 ll1 
3 
r= 4 
1 " 
I' 
9=~ 
oj l • 
3 
r= 4 
1
11 I •. 
6=21! 
4 
orJP 
3 
r= 4 
1 
6='11' 
I"" 
0 
I p··· 
Figure 6.29 
Impulse response of the second-order system of eq. (6.57) for a range 
of values of r and o. 
467 
n 
n 
n 
n 
n 
The second-order system given by eq. (6.57) is the counterpart of the underdamped 
second-order system in continuous time, while the special case of () = 0 is the critically 
damped case. That is, for any value of() other than zero, the impulse response has a damped 

6 = 0 
6= ¥ 
6=¥ 
6 _ 3'lT 
-
4 
6= '1T 
468 
r = ~ 
r = ~ 
r=i 
s[n) 
1 
1 
4 
r=4 
r= 2 
6=i 
e=i 
3 
s[n] 
1 
4 
1 
4 
r=4 
r=2 
3 
e = ~ 
3 
e = ~ 
3 
2 
2 
2 
0 
n 
n 
s[n) 
s[n] 
1 
4 
1 
4 
r=4 
r=2 
e -~ 
- 4 
3 
e -~ 
- 4 
3 
2 
2 
0 
n 
s[n] 
s[n] 
1 
4 
1 
4 
r=4 
r=2 
6= 7T 
3 
6=7T 
3 
2 
2 
n 
* Note: The plot for r= ~ , 6=0 has a different scale from the others. 
Figure 6.30 
Step response of the second-order system of eq. (6.57) for a range of 
values of rand o. 
3 
r=4 
e=i 
3 
r=4 
e = ~ 
n 
3 
r=4 
e = ~ 
n 
3 
r=4 
9=7T 
n 

Sec. 6.6 
First-Order and Second-Order Discrete-Time Systems 
469 
oscillatory behavior, and the step response exhibits ringing and overshoot. The frequency 
response of this system is depicted in Figure 6.31 for a number of values of rand () . From 
Figure 6.31, we see that a band of frequencies is amplified , and r determines how sharply 
peaked the frequency response is within this band. 
As we have just seen, the second-order system described in eq. (6.59) has factors 
with complex coefficients (unless() = 0 or 1T). It is also possible to consider second-order 
systems having factors with real coefficients. Specifically, consider 
(6.70) 
where d1 and dz are both real numbers with jd1j, ldzl < 1. Equation (6.70) is the frequency 
response for the difference equation 
-12 
8=0 
{a) 
Figure 6.31 
Magnitude and phase of the frequency response of the 
second-order system of eq. (6.57): (a) fJ = 0; (b) fJ = n/4; (c) fJ = n/2; 
(d) fJ = 3n/4; (e) fJ = n. Each plot contains curves corresponding to 
r = 1/4, 1/2, and 3/4. 
w 

470 
In this case, 
where 
Thus, 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
r= ~ 
(b) 
24dB 
20 
-12 
1T 2 
r = ~ 
1 
4 
r = -2 
r = 1 
4 
Figure 6.31 
Continued 
y[n]- (dt + dz)y[n- 1] + dtdzy[n - 2] = x[n]. 
B = 
dz 
dz -d, 
h[n] = [Ad! + Bd2]u[n], 
w 
w 
(6.71) 
(6.72) 
(6.73) 
(6.74) 

Sec. 6.6 
First-Order and Second-Order Discrete-Time Systems 
9 = :!! 2 
(c) 
24dB 
20 
16 
-8 
- 12 
Figure 6.31 
Continued 
which is the sum of two decaying real exponentials. Also, 
s[n] = [A(\--d~~~ )+ 
B(\--d~:
1 )]u[n]. 
471 
w 
(6.75) 
The system with frequency response given by eq. (6.70) corresponds to the cascade 
of two first-order systems. Therefore, we can deduce most of its properties from our un-
derstanding of the first-order case. For example, the log-magnitude and phase plots for eq. 
(6.70) can be obtained by adding together the plots for each of the two first-order terms. 
Also, as we saw for first -order systems, the response of the system is fast if jd 11 and ld2l 
are small, but the system has a long settling time if either of these magnitudes is near 1. 
Furthermore, if d 1 and d2 are negative, the response is oscillatory. The case when both d 1 
and d2 are positive is the counterpart of the overdamped case in continuous time, with the 
impulse and step responses settling without oscillation. 

472 
() _ 3'1T 
- 4 
Time and Frequency Characterization of Signals and Systems 
20 log10 JH(eiw)J 
24d8 
20 
-12 
(d) 
Figure 6.31 
Continued 
Chap.6 
w 
w 
In this section, we have restricted attention to those causal first- and second-order 
systems that are stable and for which the frequency response can be defined. In particular, 
the causal system described by eq. (6.51) is unstable for I a I :2: 1. Also, the causal system 
described by eq. (6.56) is unstable if r :2: 1, and that described by eq. (6.71) is unstable 
if either I d 1 I or I d2 I exceeds 1. 
6. 7 EXAMPLES OF TIME- AND FREQUENCY-DOMAIN ANALYSIS OF SYSTEMS 
Throughout this chapter, we have illustrated the importance of viewing sy$tems in both the 
time domain and the frequency domain and the importance of being aware of trade-offs in 
the behavior between the two domains. In this section, we illustrate some of these issues 
further. In Section 6.7.1, we discuss these trade-offs for continuous time in the context 
of an automobile suspension system. In Section 6. 7 .2, we discuss an important class of 
discrete-time filters referred to as moving-average or nonrecursive systems. 

Sec. 6.7 
Examples of Time- and Frequency-Domain Analysis of Systems 
473 
w 
- 12 
0 = 1T 
w 
(e) 
Figure 6.31 
Continued 
6. 7. 1 Analysis of an Automobile Suspension System 
A number of the points that we have made concerning the characteristics and trade-offs 
in continuous-time systems can be illustrated in the interpretation of an automobile sus-
pension system as a lowpass filter. Figure 6.32 shows a diagrammatic representation of a 
simple suspension system comprised of a spring and dashpot (shock absorber). The road 
surface can be thought of as a superposition of rapid small-amplitude changes in elevation 
(high frequencies), representing the roughness of the road surface, and gradual changes 
in elevation (low frequencies) due to the general topography. The automobile suspension 
system is generally intended to filter out rapid variations in the ride caused by the road 
surface (i.e., the system acts as a lowpass filter). 
The basic purpose of the suspension system is to provide a smooth ride, and there is 
no sharp, natural division between the frequencies to be passed and those to be rejected. 
Thus, it is reasonable to accept and, in fact, prefer a lowpass filter that has a gradual 

474 
Time and Frequency Characterization of Signals and Systems 
Reference 
elevation 
Figure 6.32 
Diagrammatic representation of an automotive suspension 
system. Here, y0 represents the distance between the chassis and the road 
surface when the automobile is at rest, y(t) + y0 the position of the chassis 
above the reference elevation, and x(t) the elevation of the road above the 
reference elevation. 
Chap.6 
transition from passband to stopband. Furthermore, the time-domain characteristics of the 
system are important. If the impulse response or step response of the suspension system 
exhibits tinging, then a large bump in the road (modeled as an impulse input) or a curb 
(modeled as a step input) will result in an uncomfortable oscillatory response. In fact, a 
common test for a suspension system is to introduce an excitation by depressing and then 
releasing the chassis. If the response exhibits ringing, it is an indication that the shock 
absorbers need to be replaced. 
Cost and ease of implementation also play an important role in the design of au-
tomobile suspension systems. Many studies have been carried out to determine the most 
desirable frequency-response characteristics for suspension systems from the point of view 
of passenger comfort. In situations where the cost may be warranted, such as for passenger 
railway cars, intricate and costly suspension systems ar~ used. For the automotive indus-
try, cost is an important factor, and simple, less costly suspension systems are generally 
used. A typical automotive suspension system consists simply of the chassis connected to 
the wheels through a spring and a dashpot. 
In the diagrammatic representation in Figure 6.32, y0 represents the distance be-
tween the chassis and the road surface when the automobile is at rest,"y(t) +Yo the position 
of the chassis above the reference elevation, and x(t) the elevation of the road above the 
reference elevation. The differential equation governing the motion of the chassis is then 
Md
2y(t) 
b dy(t) 
k () -
kx(t) + b dx(t) 
(6.76) 
----;]!2 + -:it + y t -
dt ' 
where M is the mass of the chassis and k and b are the spring and shock absorber constants, 
respectively. The frequency response of the system is 
or 
H(. 
_ 
k + bjw 
JW)- (jw)2M + b(jw) + k' 
w~ + 2~w 11 (jw) 
H(jw) = (jw)2 + 2~w 11 (jw) + w~' 
(6.77) 

Sec. 6.7 
Examples of Time- and Frequency-Domain Analysis of Systems 
475 
where 
Wn = .}it and 2(w 11 = !· 
As in Section 6.5.2, the parameter Wn is referred to as the undamped natural frequency and 
( as the damping ratio. A Bode plot of the log magnitude of the frequency response in eq. 
(6.77) can be constructed by using first-order and second-order Bode plots. The Bode plot 
for eq. (6.77) is sketched in Figure 6.33 for several different values of the damping ratio. 
Figure 6.34 illustrates the step response for several different values of the damping ratio. 
As we saw in Section 6.5.2, the filter cutoff frequency is controlled primarily through 
w 11 , or equivalently for a chassis with a fixed mass, by an appropriate choice of spring 
constantk. For a given w11 , the damping ratio is then adjusted through the damping factor b 
associated with the shock asorbers. As the natural frequency w11 is decreased, the suspen-
sion will tend to filter out slower road variations, thus providing a smoother ride. On the 
other hand, we see from Figure 6.34 that the rise time of the system increases, and thus the 
system will feel more sluggish. On the one hand, it would be desirable to keep w n small to 
improve the lowpass filtering; on the other hand, it would be desirable to have w n large for 
a rapid time response. These, of course, are conflicting requirements and illustrate the need 
for a trade-off between time-domain and frequency-domain characteristics. Typically, a 
suspension system with a low value of w 11 , so that the rise time is long, is characterized 
as "soft" and one with a high value of w 11 , so that the rise time is short, is characterized as 
"hard." From Figures 6.33 and 6.34,we observe also that, as the damping ratio decreases, 
the frequency response of the system cuts off more sharply, but the overshoot and ring-
ing in the step response tend to increase, another trade-off between the time and frequency 
3 
I 
0 
Oi 
.Q 
0 
C\J 
OdB 
-20 
Frequency 
Figure 6.33 
Bode plot for the magnitude of the frequency response of the 
automobile suspension system for several values of the damping ratio. 

476 
Time and Frequency Characterization of Signals and Systems 
s(t) 
Figure 6.34 
Step response of the automotive suspension system for vari-
ous values of the damping ratio (( = 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 
1.0, 1.2, 1.5, 2.0, 5.0). 
Chap.6 
domains. Generally, the shock absorber damping is chosen to have a rapid rise time and 
yet avoid overshoot and ringing. This choice corresponds to the critically damped case, 
with{; = 1.0, considered in Section 6.5.2. 
6.7.2 Examples of Discrete-Time Nonrecursive Filters 
In Section 3.11, we introduced the two basic classes of LTI filters described by difference 
equations, namely, recursive or infinite impulse response (IIR) filters and nonrecursive or 
finite impulse response (FIR) filters. Both of these classes of filters are of considerable 
importance in practice and have their own advantages and disadvantages. For example, 
recursive filters implemented as interconnections of the first- and second-order systems 
described in Section 6.6 provide a flexible class of filters that can be easily and efficiently 
implemented and whose characteristics can be adjusted by varying the number and the 
parameters of each of the component first- and second-order subsystems. On the other 
hand, as shown in Problem 6.64, it is not possible to design a causal, recursive filter with 
exactly linear phase, a property that we have seen is often desirable since, in that case, the 
effect of the phase on the output signal is a simple time delay. In contrast, as we show in this 
section, nonrecursive filters can have exactly linear phase. However, it is generally true that 
the same filter specifications require a higher order equation and hence more coefficients 
and delays when implemented with a nonrecursive equation, compared with a recursive 
difference equation. Consequently, for FIR filters, one of the principal trade-offs between 
the time and frequency domains is that increasing the flexibility in specifying the frequency 
domain characteristics of the filter, including, for example, achieving a higher degree of 
frequency selectivity, requires an FIR filter with an impulse response of longer duration. 
One of the most basic nonrecursive filters, introduced in Section 3.11.2, is the 
moving-average filter. For this class of filters, the output is the average of the values of 
the input over a finite window: 
1 
M 
y[n] = N 
M 
1 ~ x[n- k]. 
(6.78) 
+ 
+ 
k = - N 

Sec. 6.7 
Examples of Time- and Frequency-Domain Analysis of Systems 
477 
The corresponding impulse response is a rectangular pulse, and the frequency response is 
H( jw) = 
1 
jw[(N- M )/2) sin[w(M + N + 1)12] 
e 
N + M + 1 e 
sin(w/2) 
· 
(6.79) 
In Figure 6.35, we show the log magnitude forM+ N + 1 = 33 and M + N + 1 = 65. The 
main, center lobe of each of these frequency responses corresponds to the effective pass-
band of the corresponding filter. Note that, as the impulse response increases in length, the 
width of the main lobe of the magnitude of the frequency response decreases. This provides 
another example of the trade-off between the time and frequency domains. Specifically, 
in order to have a narrower passband, the filter in eqs. (6.78) and (6.79) must have a 
longer impulse response. Since the length of the impulse response of an FIR filter has a 
direct impact on the complexity of its implementation, this implies a trade-off between 
frequency selectivity and the complexity of the filter, a topic of central concern in filter 
design. 
Moving-average filters are commonly applied in economic analysis in order to at-
tenuate the short-term fluctuations in a variety of economic indicators iri relation to longer 
term trends. In Figure 6.36, we illustrate the use of a moving-average filter of the form of 
eq. (6.78) on the weekly Dow Jones stock market index for a 10-year period. The weekly 
Dow Jones index is shown in Figure 6.36(a). Figure 6.36(b) is a 51-day moving aver-
age (i.e., N = M = 25) applied to that index, and Figure 6.36( c) is a 201-day moving 
average (i.e., N = M = 100) applied to the index. Both moving averages are considered 
useful, with the 51-day average tracking cyclical (i.e., periodic) trends that occur during 
the course of the year and the 20 1-day average primarily emphasizing trends over a longer 
time frame. 
The more general form of a discrete-time nonrecursive filter is 
M 
y[n] = L bkx[n - k], 
k = - N 
(6.80) 
so that the output of this filter can be thought of as a weighted average of N + M + 1 
neighboring points. The simple moving-average filter in eq. (6.78) then corresponds to 
setting all of these weights to the same value, namely, 1/(N + M + 1). However, by choosing 
these coefficients in other ways, we have considerable flexibility in adjusting the filter's 
frequency response. 
There are, in fact, a variety of techniques available for choosing the coefficients in 
eq. (6.80) so as to meet certain specifications on the filter, such as sharpening the transition 
band as much as possible for a filter of a given length (i.e., for N+M+ 1 fixed). These pro-
cedures are discussed in detail in a number of texts, 3 and although we do not discuss the 
procedures here, it is worth emphasizing that they rely heavily on the basic concepts and 
tools developed in this book. To illustrate how adjustment of the coefficients can influence 
3See, for example, R. W. Hamming, Digital Filters, 3rd ed. (Englewood Cliffs, NJ: Prentice-Hall, Inc., 
1989); A. V. Oppenheim and R. W. Schafer, Discrete-Time Signal Processing (Englewood Cliffs, NJ: Prentice-
Hall, Inc., 1989); and L. R. Rabiner and B. Gold, Theory and Application of Digital Signal Processing (Engle-
wood Cliffs, NJ: Prentice-Hall, Inc., 1975). 

478 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
OdB 
3 
-40 
·~ 
J: 
0 
i 
0 
- 80 
1;'1 
• 
- 120 
OdB 
3 
- 40 
~ 
:I: 
0 o; 
..Q 
~ - 80 
-120 
-'TT/2 
0 
'TT/2 
0 
'TT/2 
w 
Figure 6.35 
Log-magnitude plots for the moving-average filter of eqs. 
(6.78) and (6.79) for (a) M + N + 1 = .33 and (b) M + N + 1 = 65. 
(a) 
(b) 
theresponseofthefilter, letusconsiderafilteroftheformofeq. (6.80), withN = M = 16 
and the filter coefficients chosen to be 
{ 
sin(27Tk/33) 
bk = 
7Tk 
' 
0, 
\k\ :5 32 
\k\ > 32 
(6.81) 

Sec. 6.7 
Examples of Time- and Frequency-Domain Analysis of Systems 
479 
400 
350 
lA 
300 
bl\ 
1 
A 
J'1 r 
n 
v 
IV 
"I\ 
,/ 
\. 
//' 
r\ ll 
~ 
[W" 
,... 
250 
200 
150 
100 
50 
0 
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ 
1927 
1928 
1929 
1930 
1931 
1932 
1933 
1934 
1935 
1936 
1937 
(a) 
400 
350 
111 
300 
~ 
I 
1\ 
If' 
h 
250 
200 v 
'\ 
/ 
1\ 
,/ 
150 
100 
50 
1\ I' ~ 
0 
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ 
1927 
1928 
1929 
1930 
1931 
1932 
1933 
1934 
1935 
1936 
1937 
(b) 
400 
350 
1/ 1\ 
I 
\ "- · 
300 
250 
[...1 
1\ 
,./ v 
' 
/ 
200 
150 
100 
1\ 
v 
50 
1\. -v 
0 
~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ 
1927 
1928 
1929 
1930 
1931 
1932 
1933 
1934 
1935 
1936 
1937 
(c) 
Figure 6.36 
Effect of lowpass fil-
tering on the Dow Jones weekly stock 
market index over a 1 0-year period 
using moving-average filters: (a) weekly 
index; (b) 51-day moving average ap-
plied to (a); (c) 201-day moving 
average applied to (a). The weekly 
stock market index and the two moving 
averages are discrete-time sequences. 
For clarity in the graphical display, 
the three sequences are shown here 
with their individual values connected 
by straight lines to form a continuous 
curve. 

480 
Time and Frequency Characterization of Signals and Systems 
The impulse response of the filter is 
{ 
sin(21Tn/33) 
h[n] = 
1Tn 
' 
0, 
lnl :5 32 
lnl > 32 
Chap.6 
(6.82) 
Comparing this impulse response with eq. (6.20), we see that eq. (6.82)-corresponds to 
truncating, for lnl > 32, the impulse response for the ideallowpass filter with cutoff fre-
quency W e = 21T/33. 
In general, the coefficients bk can be adjusted so that the cutoff is at a desired fre-
quency. For the example shown in Figure 6.37, the cutoff frequency was chosen to match 
approximately the cutoff frequency of Figure 6.35 for N = M = 16. Figure 6.37(a) shows 
the impulse response of the filter, and Figure 6.37 (b) shows the log magnitude of the fre-
quency response in dB. Comparing this frequency response to Figure 6.35, we observe 
that the passband of the filter has approximately the same width, but that the transition to 
0 
~ 
0 
C\j 
h[n) 
_g_ 
33 
(a) 
n 
20,-----,----,,----.-----.-----.-----.-----.-----, 
-80 
1T 
31T 
1T 
1T 
0 
1T 
1T 
31T 
- 4 
-T6 
- 8 
- T6 
T6 
8 
T6 
w 
(b) 
Figure 6.37 
(a) Impulse response for the nonrecursive filter of eq. (6.82); 
(b) log magnitude of the frequen~y response of the filter. 
1T 4 

Sec. 6.7 
Examples of Time- and Frequency-Domain Analysis of Systems 
481 
the stopband is sharper. In Figures 6.38(a) and (b), the magnitudes (on a linear amplitude 
scale) of the two filters are shown for comparison. It should be clear from the compari-
son of the two examples that, by the intelligent choice of the weighting coefficients, the 
transition band can be sharpened. An example of a higher order lowpass filter (N = M = 
125), with the coefficients determined through a numerical algorithm referred to as the 
Parks-McClellan algorithm,4 is shown in Figure 6.39. This again illustrates the trade-off 
between the time and frequency domains: If we increase the length N + M + 1 of a filter, 
then, by a judicious choice of the filter coefficients in eq. (6.80), we can achieve sharper 
transition band behavior and a greater degree of frequency selectivity. 
An important property of the examples we have given is that they all have zero or lin-
ear phase characteristics. For example, the phase of the moving-average filter of eq. (6.79) 
is w[(N - M)/2].Also, since the impulse response in eq. (6.82) is real and even, the im-
pulse response of the filter described by that equation is real and even, and thus has zero 
phase. From the symmetry properties of the Fourier transform of real signals, we know 
that any nonrecursive filter with an impulse response that is real and even will have a 
frequency response H(ejw) that is real and even and, consequently, has zero phase. Such a 
filter, of course, is noncausal, since its impulse response h[n] has nonzero values for n < b. 
However, if a causal filter is required, then a simple change in the impulse response can 
achieve this, resulting in a system with linear phase. Specifically, since h[n] is the impulse 
response of an FIR filter, it is identically zero outside a range of values centered at the origin 
w 
w 
(b) 
Figure 6.38 
Comparison, on a 
linear amplitude scale, of the frequency 
responses of (a) Figure 6.37 and 
(b) Figure 6.35. 
4 A. V. Oppenheim and R. W. Schafer, Discrete-Time Signal Processing (Englewood Cliffs, NJ: Prentice-
Hall, Inc., 1989), Chap. 7. 

0 
-20 
- 40 
s 
-60 
~ 
:I: 
- 80 
0 i - 100 
0 
C'J 
-120 
- 140 
-160 
482 
Time and Frequency Characterization of Signals and Systems 
m 
:E. 00110. 
"C-
.a 0.065 
·~ 0.020 
~ 0.025 
"C 0.070 
@ 
~ 
0 
0.05 0.10 
«< 
II II 
II Ill 
c.. 
w 
Figure 6.39 
Lowpass nonrecursive filter with 251 coefficients designed to obtain the 
sharpest possible cutoff. 
II 
Chap. 6 
1T 
(i.e., h[n] = 0 for alllnl > N). If we now define the nonrecursive LTI system resulting 
from a simple N-step delay of h[n], i.e., 
ht [n] = h[n - N], 
(6.83) 
then ht [n] = 0 for all n < 0, so that this LTI system is causal. Furthermore, from the time-
shift property for discrete-time Fourier transforms, we see that the frequency response of 
the system is 
Ht(ejw) = H(ejw)e-jwN. 
(6.84) 
Since H(ejw) has zero phase, H 1 (ejw) does indeed have linear phase. 
6.8 SUMMARY 
In this chapter, we have built on the foundation of Fourier analysis of signals and systems 
developed in Chapters 3-5 in order to examine in more detail the characteristics of LTI 
systems and the effects they have on signals. In particular, we have taken a careful look at 
the magnitude and phase characteristics of signals and systems, and we have introduced 
log-magnitude and Bode plots for LTI systems. We have also discussed the impact of 
phase and phase distortion on signals and systems. This examination led us to understand 
the special role played by linear phase characteristics, which impart a constant delay at all 
frequencies and which, in tum, led to the concept of nonconstant group delay and disper-
sion associated with systems having nonlinear phase characteristics. Using these tools and 
insights, we took another look at frequency-selective filters and the time-frequency trade-
offs involved. We examined the properties of both ideal and non-ideal frequency-selective 
filters and saw that time-frequency considerations, causality constraints, and implemen-
tation issues frequently make non-ideal filters, with transition bands and tolerance limits 
in the passbands and stopbands, the preferred choice. 

Chap. 6 Problems 
483 
We also examined in detail the time-frequency characteristics of first- and second-
order systems in both continuous and discrete time. We noted in particular the trade-off 
between the response time of these systems and the frequency-domain bandwidth. Since 
first- and second-order systems are the building blocks for more complex, higher order LTI 
systems, the insights developed for those basic systems are of considerable use in practice. 
Finally, we presented several examples of LTI systems in order to illustrate many of 
the points developed in the chapter. In particular, we examined a simple model of an auto-
mobile suspension system to provide a concrete example of the time-response-frequency-
response concerns that drive system design in practice. We also considered several 
examples of discrete-time nonrecursive filters, ranging from simple moving-average 
filters to higher order FIR filters designed to have enhanced frequency selectivity. We 
saw, in addition, that FIR filters can be designed so as to have exactly linear phase. These 
examples, the development of the tools of Fourier analysis that preceded them, and the 
insights those tools provide illustrate the considerable value of the methods of Fourier 
analysis in analyzing and designing LTI systems. 
Chapter 6 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining two sections contain problems belonging to · 
the basic and advanced categories, respectively. 
BASIC PROBLEMS WITH ANS"f'ERS 
6.1. Consider a continuous-time LTI system with frequency response H(jw) = 
iHUw)i ej<t.H(jw) and real impulse response h(t). Suppose that we apply an input 
x(t) = cos(wot + cf>o) to this system. The resulting output can be shown to be of the 
form 
y(t) = Ax(t - to), 
where A is a nonnegative real number representing an amplitude-scaling factor and 
to is a time delay. 
(a) Express A in terms of /H(Jw0 )/. 
(b) Express to in terms of <'J:.H(jw0 ). 
6.2. Consider a discrete-time LTI system with frequency response H(eiw) 
/H(eiw)jeJ <l:H(eiw) and real impulse response h[n]. Suppose that we apply the input 
x[n] = sin(won + cf>o) to this system. The resulting output can be shown to be of 
the form 
y[n] = /H(eiwo)jx[n - no], 
provided that <'J:.H(eiwo) and w0 are related in a particular way. Determine this rela-
tionship. 
6.3. Consider the following frequency response for a causal and stable LTI system: 
H( . ) _ 1- jw 
JW -
- --
1 + jw' 

484 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
(a) Show that IH(jw )I = A, and determine the value of A . 
(b) Determine which of the following statements is true about r( w ), the group delay 
of the system. (Note: r(w) = -d( <r.H(jw ))ldw, where <r.H(jw) is expressed 
in a form that does not contain any discontinuities.) 
1. r(w) = Oforw > 0 
2. r(w) > Oforw > 0 
3. r(w) < Oforw > 0 
· 6.4. Consider a linear-phase discrete-time LTI system with frequency response H(eiw) 
and real impulse response h[n]. The group delay function for such a system is 
defined as 
d 
. 
r(w) = - dw <r.H(elw), 
where <r.H(eiw) has no discontinuities. Suppose that, for this system, 
IH(ei'1712)1 = 2, <r.H(ei0) = 0, and T (I) = 2. 
Determine the output of the system for each of the following inputs: 
(a) cos<In) 
(b) sinC; n + *) 
6.5. Consider a continuous-time ideal bandpass filter whose frequency response is 
H( :w) = { 1, 
W e :5 lwl :5 3wc . 
1 
0, 
elsewhere 
(a) If h(t) is the impulse response of this filter, determine a function g(t) such that 
h(t) = ( si:~et )g(t). 
(b) As we is increased, does the impulse response of the filter get more concentrated 
or less concentrated about the origin? 
6.6. Consider a discrete-time ideal highpass filter whose frequency response is specified 
as 
H(efw) = { 1, 
7T- We :5 lwl :5 7T 
0, 
lwl < 7T -We 
(a) If h[n] is the impulse response of this filter, determine a function g[n] such that 
h[n] = ei::en )g[n]. 
(b) As we is increased, does the impulse response of the filter get more concentrated 
or less concentrated about the origin? 
6.7. A continuous-time lowpass filter has been designed with a passband frequency of 
1,000 Hz, a stopband frequency of 1,200 Hz, passband ripple of 0.1, and stopband 
ripple of0.05. Let the impulse response of this lowpass filter be denoted by h(t). We 
wish to convert the filter into a bandpass filter with impulse response 
g(t) = 2h(t) cos(4,0007Tt). 

Chap. 6 Problems 
485 
Assuming that IH(}w)l is negligible for lwl > 4,0007T, answer the following ques-
tions: 
(a) If the passband ripple for the bandpass filter is constrained to be 0.1, what are 
the two passband frequencies associated with the bandpass filter? 
(b) If the stopband ripple for the bandpass filter is constrained to be 0. 05, what are 
the two stopband frequencies associated with the bandpass filter? 
6.8. A causal, nonideallowpass filter is designed with frequency response H(ejw) . The 
difference equation relating the input x[n] and output y[n] for this filter is specified 
as 
N 
M 
y[n] = L aky[n - k] + L bkx[n- k]. 
k=l 
k=O 
The filter also satisfies the following specifications for the magnitude of its fre-
quency response: 
passband frequency = w P• 
passband tolerance = 8P, 
stopband frequency = w s. 
stopband tolerance = 8s. 
Now consider a causal LTI system whose input and output are related by the differ-
ence equation 
N 
M 
y[n] = 2:<-llaky[n - k] + 2:<-Ilbkx[n- k]. 
k= I 
k=O 
Show that this filter has a passband with a tolerance of 8p, and specify the corre-
sponding location of the passband. 
6.9. Consider a continuous-time causal and stable LTI system whose input x(t) and out-
put y(t) are related by the differential equation 
dy(t) 
(it + Sy(t) = 2x(t). 
What is the final value s(oo) of the step response s(t) of this filter? Also, determine 
the value of to for which 
s(to) = s(oo) [ 1 - : 2 J. 
6.10. For each first-order system whose frequency response is as follows, specify the 
straight-line approximation of the Bode magnitude plot: 
(a) 40(j~+O.l) 
(b) 0.04(jw+SO) 
JW +40 
JW +0.2 
6.11. For each second-order system whose frequency response is as follows, specify the 
straight-line approximation of the Bode magnitude plot: 
(a) 
250 
(b) O 02 
jw +50 
(jw) 2+50.5jw+25 
· 
(jw)2 +0.2jw + l 

486 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
6.12. A continuous-time LTI systemS with frequency response H(jw) is constructed by 
cascading two continuous-time LTI systems with frequency responses H 1 (jw) and 
Hz(jw ), respectively. Figures P6.12(a) and P6.12(b) show the straight-line approx-
imations of the Bode magnitude plots of H 1 (jw) and H(jw ), respectively. Specify 
Hz(Jw). 
24dB 
- 20 dB/decade 
8 1 0 
40 
1 00 
w (rad/sec) 
(a) 
20 log10 I H(jw)l 
- 20dB~----------~ 
8 10 
(b) 
- 40 dB/decade 
100 
w (rad/sec) 
Figure P6. 12 
6.13. The straight-line approximation of the Bode magnitude plot of a second-order 
continuous-time LTI system S is shown in Figure P6.13. S may be constructed by 
20 log1o I H(jw)l 
6 dB 1------------,. ..... .f -20 dB/decad~ 
I 
-~dB---------,---
~ --- --
2 
10 
I 
{ 
- 40 dB/decade 
80 1 00 
w (rad/sec) 
Figure P6. 13 

Chap. 6 Problems 
487 
either connecting two first-order systems S1 and S2 in cascade or two first-order 
systems S3 and S4 in parallel. Determine which, if any, of the following statements 
are true or false. Justify your answers. 
(a) The frequency responses of S1 and S2 may be determined uniquely. 
(b) The frequency responses of S3 and S4 may be determined uniquely. 
6.14. The straight-line approximation of the Bode magnitude plot of a causal and stable 
continuous-time LTI systemS is shown in Figure P6.14. Specify the frequency re-
sponse of a system that is the inverse of S. 
20 log10 I H(jw)l 
94dB 
~ 
0 dB/decade 
80dB 
12dBI----~ 
0.1 
0.2 
10 
50 100 
w (rad/sec) 
Figure P6. 1 4 
6.15. For each of the following second-order differential equations for causal and sta-
ble LTI systems, determine whether the corresponding impulse response is under-
damped, overdamped, or critically damped: 
(a) d:~tl + 4 d~~r) + 4y(t) = x(t) 
(b) sd:7~r) + 4d~~r) + Sy(t) = 7x(t) 
(c) d:7~t) + 20d~~r) + y(t) = x(t) 
(d) sd:~l) + 4d~~t) + 5y(t) = 7x(t) + ~d~;t) 
6.16. A particular first-order causal and stable discrete-time LTI system has a step re-
sponse whose maximum overshoot is 50% of its final value. If the final value is 1, 
determine a difference equation relating the input x[ n] and output y[ n] of this filter. 
6.17. For each of the following second-order difference equations for causal and stable LTI 
systems, determine whether or not the step response of the system is oscillatory: 
(a) y[n] + y[n -
1] + ~y[n- 2] = x[n] 
(b) y[n] - y[n- 1] + ~y[n- 2] = x[n] 
6.18. Consider the continuous-time LTI system implemented as the RC circuit shown in 
Figure P6.18. The voltage source x(t) is considered the input to this system. The 
voltage y(t) across the capacitor is considered the system output. Is it possible for 
the step response of the system to have an oscillatory behavior? 

488 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
R 
x(t) 
+ 
y(t) 
c 
Figure P6. 18 
6.19. Consider the continuous-time LTI system implemented as the RLC circuit shown 
in Figure P6.19. The voltage source x(t) is considered the input to this system. The 
voltage y(t) across the capacitor is considered the system output. How should R, L, 
and C be related so that there is no oscillation in the step response? 
6.20. Consider a nonrecursive filter with the impulse response shown in Figure P6.20. 
What is the group delay as a function of frequency for this filter? 
3 
2 
2 
0 
2 
3 
4 
n 
Figure P6.20 
BASIC PROBLEMS 
6.21. A causal LTI filter has the frequency response H(jw) shown in Figure P6.21. For 
each of the input signals given below, determine the filtered output signal y(t). 
(a) x(t) = ej1 
(b) x(t) = (sinwot)u(t) 
(c) X(jw) = (jw)(~+ jw) 
(d) X(jw) = 2+
1
jw 

Chap. 6 Problems 
489 
H(jw) 
w 
Figure P6.21 
6.22. Shown in Figure P6.22(a) is the frequency response H(jw) of a continuous-time 
filter referred to as a lowpass differentiator. For each of the input signals x(t) below, 
determine the filtered output signal y(t). 
(a) x(t) = cos(27Tt + 0) 
(b) x(t) = cos(47Tt + 0) 
(c) x(t) is a half-wave rectified sine wave of period, as sketched in Figure P6.22(b). 
x(t) = [ sin27Tt, 
m :5 t :5 (m + ~) 
0, 
. 
(m + !) :5 t :5 m for any integer m 
IH (jw)l 
<t H (jw) 
- 3~ 
3~ w 
(a) 
x(t) 
0 
t 
(b) 
Figure P6.22 
6.23. Shown in Figure P6.23 is jH(jw)j for a lowpass filter. Determine and sketch the 
impulse response of the filter for each of the following phase characteristics: 
(a) <r.H(jw) = 0 
(b) <r.H(jw) = wT, where Tis a constant 

490 
Time and Frequency Characterization of Signals and Systems , 
Chap. 6 
I H(jw) I 
'I 
I 
(c) 1:H(jw) = ( I~ 
2 ' 
(J) > 0 
(J) < 0 
w 
Figure P6.23 
6.24. Consider a continuous-time lowpass filter whose impulse response h(t) is known to 
be real and whose frequency response magnitude is given as: 
IH( "w)l = { 1, 
lwl :5 ~0071". 
1 
0, 
otherwise 
(a) Determine and sketch the real-valued impulse response h(t) for this filter when 
the corresponding group delay function is specified as: 
(i) 'T( (J)) = 5 
(ii) 'T( (J)) = ~ 
(iii) 'T( (J)) = - ~ 
(b) If the impulse response h(t) had not been specified to be real, would knowl-
edge of IH(Jw )I and T(w) be sufficient to determine h(t) uniquely? Justify your 
answer. 
6.25. By computing the group delay at two selected frequencies, verify that each of the 
following frequency responses has nonlinear phase. · 
(a) H(jw) = jw
1+ 1 
(b) H(jw) = (jw~l); 
(c) H(jw) = (jw+l)l(jw+2) 
6.26. Consider an ideal highpass filter whose frequency response is specified as 
H( ·w) = { 1, 
lwl > ~ c . 
1 
0, 
otherwise 
(a) Determine the impulse response h(t) for this filter. 
(b) As we is increased, does h(t) get more or less concentrated about the origin? 
(c) Determine s(O) and s(oo), where s(t) is the step response of the filter. 
6.27. The output y(t) of a causal LTI system is related to the input x(t) by the differential 
equation 
dyd(t) + 2y(t) = x(t). 
t 
. 
(a) Determine the frequency response 
H(. ) = Y(jw) 
JW 
X(jw) 
of the system, and sketch its Bode plot. 
(b) Specify, as a function of frequency, the group delay associated with this system. 
(c) If x(t) = e- t u(t), determine Y(jw ), the Fourier transform of the output. 

Chap. 6 Problems 
491 
(d) Using the technique of partial-fraction expansion, determine the output y(t) for 
the input x(t) in part (c). 
(e) Repeat parts (c) and (d), first if the input has as its Fourier transform 
6.28. (a) 
(b) 
(') X( · ) _ l + jw 
I 
)W 
-
2+ j w ' 
then if 
(ii) X( . ) 
2+ jw 
JW = l + jw ' 
and finally, if 
(iii) X(jw) = (2 + jw)l(l + jw) 
Sketch the Bode plots for the following frequency responses: 
(i) 
1 + (jw/10) 
(ii) 
1 - (jw/10) 
(iii) 
_ 1_
6 _ 
(iv) 
1- (jw/10) 
(jw +2)4 
1 + jw 
(v) 
(jw/10)- 1 
(vi) 
1 + (j~/10) 
l +;w 
I+Jw 
(vii) 
1- (jw/10) 
(viii) l0+5jw +10(jw)2 
(jw)2+(jw)+ 1 
1+(jwll0) 
(ix) 
(xi) 
1 + jw + (jw)2 
(x) 
1 - jw + (jw)2 
(jw + 10)(10jw + I) 
[(jw/100+ l)][((jw)2 + jw+ I)] 
Determine and sketch the impulse response and the step response for the sys-
tem with frequency response (iv). Do the same for the system with frequency 
response (vi). 
The system given in (iv) is often referred to as a non-minimum-phase 
system, while the system specified in (vi) is referred to as being a minimum 
phase. The corresponding impulse responses of (iv) and (vi) are referred to as 
a non -minimum-phase signal and a minimum-phase signal, respectively. By 
comparing the Bode plots of these two frequency responses, we can see that 
they have identical magnitudes; however, the magnitude of the phase of the 
system of (iv) is larger than for the system of (vi). 
We can also note differences in the time-domain behavior of the two sys-
tems. For example, the impulse response of the minimum-phase system has 
more of its energy concentrated near t = 0 than does the impulse response of 
the non-minimum-phase system. In addition, the step response of (iv) initially 
has the opposite sign from its asymptotic value as t ~ oo, while this is not the 
case for the system of (vi). 
The important concept of minimum- and non-minimum-phase systems 
can be extended to more general LTI systems than the simple first-order systems 
we have treated here, and the distinguishing characteristics of these systems can 
be described far more thoroughly than we have done. 
6.29. An LTI system is said to have phase lead at a particular frequency w = wo if 
<J..H(jw0) > 0. The terminology stems from the fact that if e jwot is the input to 
this system, then the phase of the output will exceed, or lead, the phase of the input. 
Similarly, if <J:H(jw 0) < 0, the system is said to have phase lag at this frequency. 
Note that the system with frequency response 
1 
1 + jwr 

492 
Time and Frequency Characterization of Signals and Systems 
has phase lag for all w > 0, while the system with frequency response 
1 + jwT 
has phase lead for all w > 0. 
Chap.6 
(a) Construct the Bode plots for the following two systems. Which has phase lead 
and which phase lag? Also, which one amplifies signals at certain frequencies? 
(i) 
I + (jw/10) 
(ii) 
I+ IOjw 
1+ 10jw 
1+ (jwll0) 
(b) Repeat part (a) for the following three frequency responses: 
(i) 
(1 +( iw/10))2 
(ii) 
1 + ;wllO 
(iii) 
I + lOjw 
(I + 10jw)3 
IOO(jw)~+ IOjw+ I 
0.01(jw)2+0.2jw+ I 
6.30. Let h(t) have the Bode plot depicted in Figure P6.30. The dashed lines in the figure 
represent straight-line approximations. Sketch the Bode plots for lOh(lOt). 
OdBI---.;;..;:_-
:1 -20 
I' - 40 
0 
Oi - 60 
.Q 
?;l -80 
- 100 
0.1 
10 
0.1 
100 
1000 
w 
1000 
w 
Figure P6.30 
6.31. An integrator has as its frequency response 
I 
1 
H(jw) = -. + 7TS(w), 
JW 
where the impulse at w = 0 is a result of the fact that the integration of a constant 
input from t = -oo results in an infinite output. Thus, if we avoid inputs that are 

Chap. 6 Problems 
493 
40 
20 
3 
~ OdB 
0 o; 
.Q 
- 20 
0 
C\1 
- 40 
-60 
1 
0 
I' 
¥ 
_, 
2 
-
'IT 
constant, or equivalently, only examine H (jw) for w > 0, we see that 
20log IH(jw)l = - 20log(w), 
- 7T 
<J:.H(jw) = 2 . 
In other words, the Bode plot for an integrator, as illustrated in Figure P6.31, consists 
of two straight-line plots. These plots reflect the principal characteristics of an inte-
grator: a phase shift of - 90° at all positive values of frequency and the amplification 
of low frequencies. 
(a) A useful, simple model of an electric motor is an LTI system with input equal to 
the applied voltage and output given by the motor shaft angle. This system can 
be visualized as the cascade of a stable LTI system (with the voltage as input 
and shaft angular velocity as output) and an integrator (representing the integra-
tion of the angular velocity). Often, a model of first-order system is used for the 
first prut of the cascade. Assuming, for example, that this first-order system has 
a time constant of 0.1 second, we obtain an overall motor frequency response of 
0.01 
0.1 
10 
100 
1000 
w 
1-
1-
I 
I 
I 
I 
I 
l 
0.01 
0.1 
10 
100 
1000 
w 
Figure P6.31 

494 
Time and Frequency Characterization of Signals and Systems 
the form 
1 
H(jw) = jw(l + jw/10) + 7TO(w). 
Sketch the Bode plot for the system for w > 0.001. 
(b) Sketch the Bode plot for a differentiator. 
(c) Do the same for systems with the following frequency responses: 
(i) H(jw) = 1 + }:;1100 
(ii) H(jw) = (1 +(jw)!ld:(jw)2t100) 
Chap.6 
6.32. Consider the system depicted in Figure P6.32. This "compensator" box is a continu-
ous-time LTI system. 
(a) Suppose that it is desired to choose the frequency response of the compensator so 
that the overall frequency response H(jw) of the cascade satisfies the following 
two conditions: 
1. The log magnitude of H(jw) has a slope of - 40 dB/decade beyond w = 
1,000. 
2. For 0 < w < 1,000, the log magnitude of H(jw) should be between 
- 10 dB and 10 dB. 
. 
Design a suitable compensator (that is, determine a frequency response for a 
compensator that meets the preceding requirements), and draw the Bode plot 
for the resulting H(jw ). 
(b) Repeat (a) ifthe specifications on the log magnitude of H (jw) are as follows: 
1. It should have a slope of + 20 dB/decade for 0 < w < 10. 
2. It should be between+ 10 and +30 dB for 10 < w < 100. 
3. It should have a slope of -20 dB/decade for 100 < w < 1,000. 
4. It should have a slope of -40 dB/decade for w > 1,000. 
x(t)---+-1 Compensator I •I jw ~ 50 f 
• 
y(t) 
Figure P6.32 
6.33. Figure P6.33 shows a system commonly used to obtain a highpass filter from a 
lowpass filter and vice versa. 
(a) Show that, if H(jw) is a lowpass filter with cutoff frequency w1P, the overall 
system corresponds to an ideal highpass filter. Determine the system's cutoff 
frequency and sketch its impulse response. 
(b) Show that, if H(jw) is an ideal highpass filter with cutoff frequency whp• the 
overall system corresponds to an ideallowpass filter, and determine the cutoff 
frequency of the system. 
(c) If the interconnection of Figure P6.33 is applied to an ideal discrete-time low-
pass filter, will the resulting system be an ideal discrete-time highpass filter? 
x(t) -~~~---~·~BI----l;~C!>-- ~t) 
Figure P6.33 

Chap. 6 Problems 
495 
6.34. In Problem 6.33, we considered a system commonly used to obtain a highpass filter 
from a lowpass filter and vice versa. In this problem, we explore the system further 
and, in particular, consider a potential difficulty if the phase of H(jw) is not properly 
chosen. 
(a) Referring to Figure P6.3J, let us assume that H(jw) is real and as shown in 
Figure P6.34. Then 
1-51 <H(jw) < 1 +51, 0 :s w :s WJ, 
- 52 < H(jw) < +52, w2 < w. 
Determine and sketch the resulting frequency response of the overall system of 
Figure P6.33. Does the resulting system correspond to an approximation to a 
highpass filter? 
(b) Now let H(jw) in Figure P6.33 be of the form 
(P6.34- 1) 
where H 1 (jw) is identical to Figure P6.34 and O(w) is an unspecified phase 
characteristic. With H(jw) in this more general form, does it still correspond to 
an approximation to a lowpass filter? 
(c) Without making any assumptions about O(w ), determine and sketch the toler-
ance limits on the magnitude of the frequency response of the overall system of 
Figure P6.33. 
(d) If H(jw) in Figure P6.33 is an approximation to a lowpass filter with unspec-
ified phase characteristics, will the overall system in that figure necessarily 
correspond to an approximation to a highpass filter? 
H(jw) 
1 +&, ~---....---..~ 
1 - &, 1--'""-----'""---'"1. 
Figure P6.34 
6.35. Shown in Figure P6.35 is the frequency response H(ejw) of a discrete-time differ-
entiator. Determine the output signal y[n] as a function of w 0 if the inputx[n] is 
x[n] = cos[w0n + 0]. 

496 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
-
~ ~-----..., 
1T 
w 
..._ __ --1 - ~ 
...__ 
Figure P6.35 
6.36. Consider a discrete-time lowpass filter whose impulse response h[n] is known to be 
real and whose frequency response magnitude in the region - Tr ::::; w ::::; 7r is given 
as: 
lwl ::::; i 
otherwise · 
Determine and sketch the real-valued impulse response h[n] for this filter when the 
corresponding group delay function is specified as: 
(a) T(w) = 5 
(b) T(w) = ~ 
(c) r(w) = - ~ 
6.37. Consider a causal LTI system whose frequency response is given as: 
. 
. 1- !ejw 
H(e'w) = e- 'w 
2 
.
. 
1- ! e- Jw 
2 
(a) Show that IH(ejw)l is unity at all frequencies. 
(b) Show that 
<r..H(e1w) = - w - 2tan- 1 
2 
1 
. 
. 
( 
! sinw 
) 
1 - 2 cosw 
(c) Show that the group delay for this filter is given by 
3 
'T(W) = 
5 
4 
. 
4 - cosw . 
Sketch T(w ). 
(d) What is the output of this filter when the input is cos(-~n)? 
6.38. Consider an ideal bandpass filter whose frequency response in the region -7r ::::; 
w ::::; 7r is specified as 
. 
{ 1 
H(e1w) = 
' 
0, 
11'-
<I I< 11' + 
2 
W e
-
W 
-
2 
W e 
otherwise 

Chap. 6 Problems 
497 
Determine and sketch the impulse response h[n] for this filter when 
(a) W e = ~ 
(b) W e = i 
(c) W e = ~ 
As W e is increased, does h[n] get more or less concentrated about the origin? 
6.39. Sketch the log magnitude and phase of each of the following frequency responses. 
(a) 1 + ~e - Jw 
(b) 1 + 2e-Jw 
(c) 1 - 2e- Jw 
(d) 1 + 2e- Jilu 
I 
l +ie- Jw 
(e) (l+ !e-Jw)3 
(f) 
1 - ~e-Jw 
I +2e- Jw 
1- 2e- Jw 
(g) l+!e-Jw 
(h) 
I +~e - Jw 
(i) 
(k) 
(I - ~r Jw)(l- ~e - 1"') 
I +2e- 2Jw 
(l- ~ e - Jw)2 
(j) 
I 
(I -
~e - 1"')( 1 + ~e - Jw) 
6.40. Consider an ideal discrete-time lowpass filter with impulse response h[n] and for 
which the frequency response H(ei"' ) is that shown in Figure P6.40. Let us consider 
obtaining a new filter with impulse response h 1 [n] and frequency response H 1 (ei"') 
as follows: 
h, [n] = { h[n/2], 
0, 
n even 
n odd 
This corresponds to inserting a sequence value of zero between each sequence value 
of h[n]. Determine and sketch H 1 (ei"') and state the class of ideal filters to which it 
belongs (e.g., lowpass, highpass, bandpass, multiband, etc.) . 
I H(ei"') I 
.J:: H(ei"')=O 
~ 
I 
~ 
- 2'11" 
-
'IT 
- we 
We 
'IT 
2'11" 
w 
Figure P6.40 
6.41. A particular causal LTI system is described by the difference equation 
J2 
1 
y[n]- Ty[n - 1] + 4 y[n - 2] = x[n]- x[n - 1]. 
(a) Find the impulse response of this system. 
(b) Sketch the log magnitude and the phase of the frequency response of the system. 
6.42. (a) Consider two LTI systems with the following frequency responses: 

498 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
Show that both of these frequency responses have the same magnitude function 
[Le.,jH1 (ejw)j = IH2(ejw)IJ, but the group delay of H2(ejw) is greater than the 
group delay of H 1 (ejw) for w > 0. 
(b) Determine.and sketch the impulse and step responses of the two systems. 
(c) Show that 
H2(ejw) = G(ejw)Ht(ejw), 
where G(ejw) is an all-pass system [i.e.,jG(ejw)j = 1 for all w]. 
6.43. When designing filters with highpass or bandpass characteristics, it is often conve-
nient first to design a lowpass filter with the desired passband and stopband specifi-
cations and then to transform this prototype filter to the desired highpass or bandpass 
filter. Such transformations are called lowpass-to-highpass or highpass-to-lowpass 
transformations. Designing filters in this manner is convenient because it requires 
us only to formulate our filter design algorithms for the class of filters with low-
pass characteristics. As one example of such a procedure, consider a discrete-time 
lowpass filter with impulse response h1p[n] and frequency response H1p(ejw), as 
sketched in Figure P6.43. Suppose the impulse response is modulated with these-
quence ( - 1)
11 to obtain hhp[n] = ( - 1)" h1p[n]. 
(a) Determine and sketch Hhp(ejw) in terms of H1p(ejw). Show in particular that, for 
H 1p(ejw) as shown in Figure P6.43, Hhp(ejw) corresponds to a highpass filter. 
(b) Show that modulation of the impulse response of a discrete-time high pass filter 
by (- I)" will transform it to a lowpass filter. 
HIP (eiw) 
--'-----
:\~___,c__ffi__..._
1 
. -----......._____,c_L__..__ w 
1T 
Figure P6.43 
6.44. A discrete-time system is implemented as shown in Figure P6.44. The system S 
shown in the figure is an LTI system with impulse response h1p[n]. 
x[n] 
(a) Show that the overall system is time invariant. 
(b) If h1p[n] is a lowpass filter, what type of filter does the system of the figure 
implement? 
·0 ·I 
s 
·cp---Yi"i 
t 
h1p[n] 
(- 1)n 
(-1)n 
Figure P6.44 

Chap. 6 Problems 
499 
6.45. Consider the following three frequency responses for causal and stable third-order 
LTI systems. By utilizing the properties of first- and second-order systems dis-
cussed in Section 6.6, determine whether or not the impulse response of each of the 
third-order systems is oscillatory. (Note: You should be able to answer this ques-
tion without taking the inverse Fourier transforms of the frequency responses of the 
third-order systems.) 
Ht (ejw) = -
- .-------:-1- ---.,...---
(1 - ir 
jw)(l -
~e -jw)(l - ie- jw)' 
1 
H2(ejw) = - ---,--- ---,------,--
(1 + ir 
jw)(1 -
~e-jw)(l - ie- jw)' 
1 
H3(ejw) = --.---- --....,----;;----
(1 -
~e -jw)(1 -
~e - jw + -fte- j2w) · 
6.46. Consider a causal, nonrecursive (FIR) filter whose real-valued impulse response 
h[n] is zero for n ~ N. 
(a) Assuming that N is odd, show that if h[n] is symmetric about (N- 1)/2 (i.e., if 
h[(N - 1)/2 + n] = h[(N - 1)/2 - n]), then 
H(ejw) = A(w)e- j[(N- 1)12Jw, 
where A(w) is a real-valued function of w. We conclude that the filter has linear 
phase. 
(b) Give an example of the impulse response h[n] of a causal, linear-phase FIR 
filter such that h[n] = 0 for n ~ 5 and h[n] ¥- 0 for 0 ~ n ~ - 4. 
(c) Assuming that N is even, show that if h[n] is symmetric about (N- 1)/2 (i.e., 
if h[(N/2) + n] = h[N/2 - n- 1]), then 
H(ejw) = A(w)e- j[(N-1)12lw, 
where A(w) is a real-valued function of w . 
(d) Give an example of the impulse response h[n] of a causal, linear-phase FIR 
filter such that h[n] = 0 for n ~ 4 and h[n] ¥- 0 for 0 ~ n ~ 3. 
6.47. A three-point symmetric moving average, referred to as a weighted moving average, 
is of the form 
y[n] = b{ax[n - 1] + x[n] + ax[n + 1]}. 
(P6.47-1) 
(a) Determine, as a function of a and b, the frequency response H(ejw) of the three-
point moving average in eq. (P6.47- 1). 
(b) Determine the scaling factor b such that H ( ejw) has unity gain at zero frequency. 
(c) In many time-series analysis problems, a common choice for the coefficient a 
in the weighted moving average in eq. (P6.47-1) is a = 1/2. Determine and 
sketch the frequency response of the resulting filter. _ 
6.48. Consider a four-point, moving-average, discrete-time filter for which the difference 
equation is 
y[n] = box[n] + btx[n- 1] + b2x[n- 2] + b3x[n- 2]. 

Chap. 6 Problems 
501 
s(t) 
Figure P6.49 
involving the analysis of complex systems having a few dominant time con-
stants and other very small time constants. In order to reduce the complexity 
of the model of the system to be analyzed, one often can simplify the fast parts 
of the system. That is, suppose we regard a complex system as a parallel in-
terconnection of first- and second-order systems. Suppose also that one of these 
subsystems, with impulse response h(t) and step response s(t), is fast-that is, 
thats(t) settles to its final value s(oo) very quickly. Then we can approximate this 
subsystem by the subsystem that settles to the same final value instantaneously. 
That is, if s(t) is the step response to our approximation, then 
s(t) = s(oo)u(t). 
This is illustrated in Figure P6.49. Note that the impulse response of the ap-
proximate system is then 
h(t) = s(oo)o(t), 
which indicates that the approximate system is memoryless. 
Consider again the causal LTI system described by eq. (P6.49-1) and, in 
particular, the representation of it as a parallel interconnection of two first-order 
systems, as described in part (b). Use the method just outlined to replace the 
faster of the two subsystems by a memory less system. What is the differential 
equation that then describes the resulting overall system? What is the frequency 
response of this system? Sketch IH(jw )I (not log IH(jw )I) and <r..H(jw) for both 
the original and approximate systeins. Over what range of frequencies are these 
frequency responses nearly equal? Sketch the step responses for both systems. 
Over what range of time are the step responses nearly equal? From your plots, 
you will see some of the similarities and differences between the original sys-
tem and its approximation. The utility of an approximation such as this de-
pends upon the specific application. In particular, one must take into account 
both how widely separated the different time constants are and also the nature 
of the inputs to be considered. As you will see from your answers in this part of 
the problem, the frequency response of the approximate system is essentially 
the same as the frequency response of the original system at low frequencies. 
That is, when the fast parts of the system are sufficiently fast compared to the 
rate of fluctuation of the input, the approximation becomes useful. 

502 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
6.50. The concepts associated with frequency-selective filtering are often used to sepa-
rate two signals that have been added together. If the spectra of the two signals do 
not overlap, ideal frequency-selective filters are desirable. However, if the spectra 
overlap, it is often preferable to design the filter to have a gradual transition between 
passband and stopband. In this problem, we explore one approach for determining 
the frequency response of a filter to be used for separating signals with overlapping 
spectra. Let x(t) denote a composite continuous-time signal consisting of the sum 
oftwo signals s(t) + w(t). As indicated in Figure P6.50(a), we would like to design 
an LTI filter to recover s(t) from x(t). The filter's frequency response H(jw) is to 
be chosen so that, in some sense, y(t) is a "good" approximation to s(t). 
Let us define a measure of the error between y(t) and s(t) at each frequency 
was 
where S(jw) and Y(jw) are the Fourier transforms of s(t) and y(t), respectively. 
(a) Express €(w) in terms of S(jw), H(jw), and W(jw), where W(jw) is the 
Fourier transform of w(t). 
(b) Let us restrictH(jw) to be real, so thatH(jw) = H*(jw ). By setting the deriva-
tive of €(w) with respect to H(jw) to be zero, determine the H(jw) required to 
minimize the error € ( w). 
(c) Show that ifthe spectra of S(jw) and W(jw) are non-overlapping, the result in 
part (b) reduces to an ideal frequency-selective filter. 
(d) From your result in part (b), determine and sketch H(jw) if S(jw) and W(jw) 
are as shown in Figure P6.50(b). 
x(t) = s(t) + w(t)~ 
y(t) 
(a) 
S(jw) 
'I 
- 2 
2 
(1) 
W(jw) 
dl 
- 1 
(1) 
(b) 
Figure P6.50 

Chap. 6 Problems 
503 
6.51. An ideal bandpass filter is a bandpass filter that passes only a range of frequencies, 
without any change in amplitude or phase. As shown in Figure P6.51(a), let the 
passband be 
w 
w 
wo - -
::5 lwl ::5 wo + -. 
2 
2 
(a) What is the impulse response h(t) of this filter? 
(b) We can approximate an ideal bandpass filter by cascading a first-order lowpass 
and a first-order highpass filter, as shown in Figure P6.51(b). Sketch the Bode 
diagrams for each of the two filters H 1 (jw) and H 2(jw ). 
(c) Determine the Bode diagram for the overall bandpass filter in terms of your 
results from part (b). 
I I 
(a) 
(b) 
H2(jw) = ~ 
100+jw 
w 
Figure P6.51 
6.52. In Figure P6.52(a), we show the magnitude of the frequency response for an ideal 
continuous-time differentiator. A nonideal differentiator would have a frequency 
response that is some approximation to the frequency response in the figure. 
(a) Consider a nonideal differentiator with frequency response G(jw) for which 
IG(Jw )! is constrained to be within ± 10% of the magnitude of the frequency 
response of the ideal differentiator at all frequencies; that is, 
-O.I!H(jw)i ::s: [!G(jw)! - !H(jw)IJ ::s: O.I!H(jw)!. 
Sketch the region in a plot of G(jw) vs. w where !G(Jw )! must be confined to 
meet this specification. 

504 
Time and Frequency Characterization of Signals and Systems 
(a) 
Ideal delay 
L...__T_s_ec_. __J x(t-T) 
(b) 
Figure P6.52 
w 
Multiplication 
by 1/T 
y(t) =tw(t) 
Chap.6 
(b) The system in Figure P6.52(b ), incorporating an ideal delay of T seconds, is 
sometimes used to approximate a continuous-time differentiator. ForT = w-2 
second, determine the frequency range over which the magnitude of the fre-
quency response of the system in the figure is within ± 10% of that for an ideal 
differentiator. 
6.53. In many filtering applications, it is often undesirable for the step response of a filter 
to overshoot its final value. In processing pictures, for example, the overshoot in the 
step response of a linear filter may produce flare-that is, an increase in intensity-
at sharp boundaries. It is possible, however, to elirnipate overshoot by requiring that 
the impulse response of the filter be positive for all time. 
Show that if h(t), the impulse response of a continuous-time LTI filter, is al-
ways greater than or equal to zero, the step response of the filter is a monotonically 
nondecreasing function and therefore will not have overshoot. 
· 
6.54. By means of a specific filter design procedure, a nonideal continuous-time lowpass 
filter with frequency response H0(jw ), impulse response ho(t), and step response 
s0(t) has been designed. The cutoff frequency of the filter is at w = 21T X 102 
rad/sec, and the step response rise time, defined as the time required for the step · 
response to go from 10% of its final value to 90% of its final value, is Tr = 10- 2 
second. From this design, we can obtain a new filter with an arbitrary cutoff fre-
quency we by the use of frequency scaling. The frequency response of the resulting 
filter is then of the form 
Hip(jw) = Ho(jaw), 
where a is an appropriate scale factor. 
(a) Determine the scale factor a such that H1p(jw) has a cutoff frequency of We. 

Chap. 6 Problems 
505 
(b) Determine the impulse response h1p(t) of the new filter in terms of we and ho(t). 
(c) Determine the step response s1p(t) of the new filter in terms of W e and s0(t). 
(d) Determine and sketch the rise time of the new filter as a function of its cutoff 
frequency W e . 
This is one illustration of the trade-off between time-domain and 
frequency-domain characteristics. In particular, as the cutoff frequency de-
creases, the rise time tends to increase. 
6.55. The square of the magnitude of the frequency response of a class of continuous-time 
lowpass filters, known as Butterworth filters, is 
Let us define the passband edge frequency w P as the frequency below which 
jB(jw )j2 is greater than one-half of its value at w = 0; that is, 
Now let us define the stopband edge frequency W s as the frequency above which 
jB(jw )j2 is less than 10- 2 of its value at w = 0; that is, 
jB(jw)j2 ::5 w- 2jB(jO)j2, lwl > W s. 
The transition band is then the frequency range between w i> and W s· The ratio wslw P 
is referred to as the transition ratio. 
For fixed w P• and making reasonable approximations, determine and sketch 
the transition ratio as a function of N for the class of Butterworth filters. 
6.56. In this problem, we explore some of the filtering issues involved in the commercial 
version of a typical system that is used in most modern cassette tape decks to reduce 
noise. The primary source of noise is the high-frequency hiss in the tape playback 
, 
I 
process, which, in some part, is due to the friction between the tape and the playback 
head. Let us assume that the noise hiss that is added to the signal upon playback has 
the spectrum of Figure P6.56(a) when measured in decibels, with 0 dB equal to the 
signal level at 100 Hz. The spectrum S(jw) of the signal has the shape shown in 
Figure P6.56(b). 
The system that we analyze has a filter H 1 (jw) which conditions the signal 
s(t) before it is recorded. Upon playback, the hiss n(t) is added to the signal. The 
system is represented schematically in Figure P6.56(c). 
Suppose we would like our overall system to have a signal-to-noise ratio of 40 
dB over the frequency range 50 Hz < w/27T < 20 kHz. 
(a) Determine the transfer characteristic of the filter H 1 (jw ). Sketch the Bode plot 
of H 1(jw). 
(b) If we were to listen to the signal p(t), assuming that the playback process does 
nothing more than add hiss to the signal, how do you think it would sound? 
(c) What should the Bode plot and transfer characteristic of the filter H2(jw) be in 
order for the signal s(t) to sound similar to s(t)? 

506 
Time and Frequency Characterization of Signals and Systems 
20 log1o I N(jw) I 
- 28dB ~ 
- 40 dB 1-t---~
1 
I 
5kHz 
10kHz 
20kHz 
(a) 
20 log1o I S(jw) I 
w 
f = 21T 
_: ::~ 
"'----"--~ __.__...________,_____,_,\_ 
50 
s(t) 
r(t) 
100 
(b) 
(c) 
1kHz 
10kHz 
20kHz 
n(t) 
p(t) 
Figure P6.56 
Chap.6 
s(t) 
6.57. Show that if h[n], the impulse response of a discrete-time LTI filter, is always greater 
than or equal to zero, the step response of the filter is a monotonically nondecreasing 
function and therefore will not have overshoot. 
6.58. In the design of either analog or digital filters, we often approximate a specified 
magnitude characteristic without particular regard to the phase. For example, stan-
dard design techniques for lowpass and bandpass filters are typically derived from 
a consideration of the magnitude characteristics only. 
In many filtering problems, one would ideally like the phase characteristics to 
be zero or linear. For causal filters, it is impossible to have zero phase. However, for 
many digital.filtering applications, it is not necessary that the unit sample response 
of the filter be zero for n < 0 if the processing is not to be carried out in real time. 
One technique commonly used in digital filtering when the data to be filtered 
are of finite dliration and stored, for example, on a disc or magnetic tape is to process 
the data forward and then backward through the same filter. 
Let h[n] be the unit sample response of a causal filter with an arbitrary phase 
characteristic. Assume that h[n] is real, and denote its Fourier transform by H(ejw). 
Let x[n] be the data that we want to filter. The filtering operation is performed as 
follows: 

Chap. 6 Problems 
x[n]-----,1~~ g(n] 
g[-n]-----,1~~ r[n] 
s[n] = r[- n] 
(a) 
x[n] 
~g[n] 
x[- n] 
~r[n] 
(b) 
H (eiw) 
ll I 
1!: 
3'11' 
'IT w 
4 
4 
,......,.-,:rr w 
(c) 
Figure P6.58 
(a) Method A: Process x[n] to get s[n], as indicated in Figure P6.58(a). 
.507 
1. Determine the overall unit sample response h1 [n] that relates x[n] and s[n], 
and show that it has zero phase characteristic. 
2. Determine IH1 (ej"')l and express it in terms of IH(ej"')l and -1:.H(ej"'). 
(b) Method B: Process x[n] through the filter h[n] to get g[n] [Figure P6.58(b)]. 
Also, process x[n] backward through h[n] to get r[n]. The output y[n] is taken 
to be the sum of g[n] and rt -n]. The composite set of operations can be repre-
sented by a filter with input x[n], output y[n], and unit sample response h2[n]. 
1. Show that the composite filter h2[n] has zero phase characteristic. 
2. Determine IH2(ej"')l, and express it in terms of IH(ej"')l and -1:.H(ej"'). 
(c) Suppose that we are given a sequence of finite duration on which we would 
like to perform bandpass, zero-phase filtering. Furthermore, assume that we 

508 
Time and Frequency Characterization of Signals and Systems 
Chap. 6 
are given the bandpass filter h[n] with frequency response as specified in Fig-
ure P6.58( c) and with magnitude characteristic that we desire, but with linear 
phase. To achieve zero phase, we could use either of the preceding methods, A 
or B. Determine and sketch jH1(eiw)j and jH2(eiw)j. From these results, which 
method would you use to achieve the desired bandpass filtering operation? Ex-
plain why. More generally, if h[n] has the desired magnitude, but a nonlinear 
' phase characteristic, which method is preferable to achieve a zero phase char-
acteristic? 
6.59. Let hd[n] denote the unit sample response of a desired ideal system with frequency 
response Hd(eiw), and let h[n] denote the unit sample response for an FIR system 
of length Nand with frequency response H(eiw). In this problem, we show that a 
rectangular window of length N samples applied to he~ [ n] will produce a unit sample 
response h[n] such that the mean square error 
is minimized. 
(a) The error function E(eiw) = Hd(eiw ) - H(eiw) can. be expressed as the power 
series 
E(ejw) = ~ 
e[n]e-jwn. 
n= - oo 
Find the coefficients e[n] in terms of hc~[n] and h[n]. 
(b) Using Parsevafs relation, express the mean square error E2 in terms of the co-
efficients e[n]. 
(c) Show that for a unit sample response h[n] of length N samples, E2 is minimized 
when 
h[n] = { hd[n], 
0, 
O:sn:sN - 1 
otherwise 
That is, simple truncation gives the best mean square approximation to a desired 
frequency response for a fixed value of N. 
6.60. In Problem 6.50, we considered one specific criterion for determining the frequency 
response of a continuous-time filter that would recover a signal from the sum of 
two signals when their spectra overlapped in frequency. For the discrete-time case, 
develop the result corresponding to that obtained in part (b) of Problem 6.50. 
6.61. In many situations we have available an analog or digital filter module, such as a 
basic hardware element or computer subroutine. By using the module repetitively 
or by combining identical modules, it is possible to implement a new filter with 
improved passband or stopband characteristics. In this and the next problem, we 
consider two procedures for doing just that. Although the discussion is phrased in 
terms of discrete-time filters, much of it applies directly to continuous-time filters 
as well. 

Chap. 6 Problems 
509 
w 
Figure P6.61 
Consider a lowpass filter with frequency response H(eiw) for which JH(eiw)J 
falls within the tolerance limits shown in Figure P6.61; that is, 
1- OJ $ 
JH(eiw)J $ 1 + OJ, 0 $ w $ 
WJ, 
0 $ 
JH(e1w)J $ 02, w2 $ w $ 
7T. 
A new filter with frequency response G(eiw) is formed by cascading two identical 
filters, both with frequency response H(eiw). 
(a) Determine the tolerance limits on JG(eiw)J. 
(b) Assuming that H ( eiw) is a good approximation to a lowpass filter, so that o 
1 < < 
1 and 52 < < 1, determine whether the passband ripple for G( eiw) is larger or 
smaller than the passband ripple for H(eiw). Also, determine whether the stop-
band ripple for G(eiw) is larger or smaller than the stopband ripple for H(ei w). 
(c) If N identical filters with frequency response H(eiw) are cascaded to obtain a 
new frequency response G( eiw ), then, again assuming that o 
1 < < 1 and 52 < < 
1, determine the approximate tolerance limits on JG(eiw)J. 
6.62. In Problem 6.61, we considered one method for using a basic filter module repeti-
tively to implement a new filter with improved characteristics. Let us now consider 
an alternative approach, proposed by J. W. Tukey in the book, Exploratory Data 
Analysis (Reading, MA: Addison-Wesley Publishing Co., Inc., 1976). The proce-
dure is shown in block diagram form in Figure P6.62(a). 
(a) Suppose that H(eiw) is real and has a passband ripple of ±5 1 and a stopband 
ripple of ±52 (i.e., H(eiw) falls within the tolerance limits indicated in Fig-
ure P6.62(b)). The frequency response G(eiw) of the overall system in Figure 
P6.62(a) falls within the tolerance limits indicated in Figure P6.62(c). Deter-
mine A, B, C, and Din terms of Dt and 02. 
(b) If o 
1 < < l .and 52 < < 1, what is the approximate passband ripple and stopband 
ripple associated with G(eiw)? Indicate in particular whether the passband rip-
ple for G(eiw) is larger or smaller than the passband ripple for H(eiw). Also, 
indicate whether the stopband ripple for G(eiw) is larger or smaller than the 
stopband ripple for H(eiw). 
(c) In parts (a) and (b), we assumed that H(eiw) is real. Now consider H(eiw) to 
have the more general form 
H(ejw) = H, (ejw)ejO(w), 
whereHt (eiw) is real andO(w) is an unspecified phase characteristic. IfJH(eiw)J 

510 
Time and Frequency Characterization of Signals and Systems 
g[n] 
I 
I 
Chap. 6 
x[n]-....;...--1----1~1 H(ei"') 
y[n] -
)---!~~ 
w[n] 
I 
I 
I_------------------------ - - - -- _I 
(a) 
1 +81 ~-----i 
(b) 
A :s G (ei"') :s B 
0 :s w :s wP 
C :s G (ei"') :s D 
w8 :s w :s 'IT 
""""'----- 'I 
(c) 
Figure P6.62 
is a reasonable approximation to an ideallowpass filter, will!G( elw)l necessarily 
be a reasonable approximation to an ideallowpass filter? 
(d) Now assume that H(elw) is an FIR linear-phase lowpass filter, so that 
H(elw) = HI(elw)ejMw, 

Chap. 6 Problems 
511 
where H 1 (efw) is real and M is an integer. Show how to modify the system in 
Figure P6.62(a) so that the overall system will approximate a lowpass filter. 
6.63. In the design of digital filters, we often choose a filter with a specified magnitude 
characteristic that has the shortest duration. That is, the impulse response, which 
is the inverse Fourier transform of the complex frequency spectrum, should be as 
narrow as possible. Assuming that h[n] is real, we wish to show that if the phase 
O(w) associated with the frequency response H(eiw) is zero, the duration of the 
impulse response is minimal. Let the frequency response be expressed as 
and let us consider the quantity 
00 
00 
D = L n2h2[n] = L (nh[n])2 
n = - oo 
n= - oo 
to be a measure of the duration of the associated impulse response h[n]. 
(a) Using the derivative property of the Fourier transform and Parseval's relation, 
express Din terms of H(eiw). 
(b) By expressing H(eiw) in terms of its magnitude IH(ejw)l and phase O(w ), use 
your result from part (a) to show that Dis minimized when O(w) = 0. 
6.64. For a discrete-time filter to be causal and to have exactly linear phase, its impulse 
response must be of finite length and consequenUy the difference equation must be 
nonrecursive. To focus on the insight behind this statement, we consider a particular 
case, that of a linear phase characteristic for which the slope of the phase is an 
integer. Thus, the frequency response is assumed to be of the form 
(P6.64-1) 
where H,(eiw) is real and even. 
Let h[n] denote the impulse response of the filter with frequency response 
H(ejw) and let h,[n] denote the impulse response of the filter with frequency re-
sponse H,(ejw). 
(a) By using the appropriate properties in Table 5.1, show that: 
1. h,[n] = h,[ -n] (i.e., h,[n] is symmetric about n = 0). 
2. h[n] = h,[n - M]. 
(b) Using your result in part (a), show that with H(ejw) of the form shown in eq. 
(P6.64-l), h[n] is symmetric about n = M, that is, 
h[M + n] = h[M - n]. 
(P6.64-2) 
(c) According to the result in part (b), the linear phase characteristic in eq. 
(P6.64- 1) imposes a symmetry in the impulse response. Show that if h[n] 
is causal and has the symmetry in eq. (P6.64-2), then 
h[n] = 0, 
n < Oandn >2M 
(i.e., it must be of finite length). 

512 
Time and Frequency Characterization of Signals and Systems 
Chap.6 
6.65. For a class of discrete-time lowpass filters, known as Butterworth filters, the squared 
magnitude of the frequency response is given by 
where w e is the cutoff frequency (which we shall take to be n/2) and N is the order 
of the filter (which we shall consider to beN = 1). Thus, we have 
I 
j(J) 12 -
1 
B(e 
) 
-
1 + tan2(w/2) · 
(a) Using trigonometric identities, show that IB(e1w)l2 = cos2(w/2). 
(b) Let B(ejw) ::;::; acos(w/2). For what complex values of a is IB(eiw )l2 the same 
as in part (a)? 
(c) Show that B(eiw) from part (b) is the transfer function corresponding to a dif-
ference equation of the form 
y[n] = a x[n] + fh[n - ')']. 
Determine a, /3, and 'Y· 
6.66. In Figure P6.66(a) we show a discrete-time system consisting of a parallel combi-
nation of N LTI filters with impulse response hk[n], k = 0, 1, · · ·, N- 1. For any k, 
hk[n] is related to h0[n] by the expression 
x[n) 
hk[n] = ei(27rnk/N) ho[n]. 
(a) If ho[n] is an ideal discrete-time lowpass filter with frequency response Ho(e1w) 
as shown in Figure P6.66(b), sketch the Fourier transforms of h1 [n] and hN- I [n] 
for win the range -n < w :5 +1r. 
h0[n) 
Yo(n] 
'-----' YN - ,(n) 
N - 1 
y[n] = I 
ydn] 
k=O 
Figure P6.66a 

Chap. 6 Problems 
513 
1T 
w 
Figure P6.66b 
(b) Determine the value of the cutoff frequency W e in Figure P6.66(b) in terms of 
N (0 < we :i 1r) such that the system of Figure P6.66(a) is an identity system; 
that is, y[n] = x[n] for all nand any input x[n]. 
(c) Suppose that h[n] is no longer restricted to be an ideallowpass filter. If h[n] 
denotes the impulse response of the entire system in Figure P6.66(a) with input 
x[n] and output y[n], then h[n] can be expressed in the form 
h[n] = r[n]ho[n]. 
Determine and sketch r[n]. 
(d) From your result of part (c), determine a necessary and sufficient condition on 
h0[n] to ensure that the overall system will be an identity system (i.e., such that 
for any input x[n], the output y[n] will be identical to x[n]). Your answer should 
not contain any sums. 

7 
SAMPLING 
7.0 INTRODUCTION 
514 
Under certain conditions, a continuous-time signal can be completely represented by and 
recoverable from knowledge of its values, or samples, at points equally spaced in time. 
This somewhat surprising property follows from a basic result that is referred to as the 
sampling theorem. This theorem is extremely important and useful. It is exploited, for 
example, in moving pictures, which consist of a sequence of individual frames, each of 
which represents an instantaneous view (i.e., a sample in time) of a continuously changing 
scene. When these samples are viewed in sequence at a sufficiently fast rate, we perceive 
an accurate representation of the original continuously moving scene. As another example, 
printed pictures typically consist of a very fine grid of points, each corresponding to a 
sample of the spatially continuous scene represented in the picture. If the samples are 
sufficiently close together, the picture appears to be spatially continuous, although under 
a magnifying glass its representation in terms of samples becomes evident. 
Much of the importance of the sampling theorem also lies in its role as a bridge 
between continuous-time signals and discrete-time signals. As we will see in this chapter, 
the fact that under certain conditions a continuous-time sig~al can be completely recovered 
from a sequence of its samples provides a mechanism for representing a continuous-time 
signal by a discrete-time signal. In many contexts, processing discrete-time signals is more 
flexible and is often preferable to processing continuous-time signals. This is due in large 
part to the dramatic development of digital technology over the past few decades, result-
ing in the availability of inexpensive, lightweight, programmable, and easily reproducible 
discrete-time systems. The concept of sampling, then, suggests an extremely attractive 
and widely employed method for using discrete-time system technology to implement 
continuous-time systems and process continuous-time signals: We exploit sampling to 

Sec. 7.1 
Representation of a Continuous-Time Signal by Its Samples: The Sampling Theorem 51 s 
convert a continuous-time signal to a discrete-time signal, process the discrete-time signal 
using a discrete-time system, and then convert back to continuous time. 
In the following discussion, we introduce and develop the concept of sampling and 
the process of reconstructing a continuous-time signal from its samples. In this discus-
sion, we both identify the conditions under which a continuous-time signal can be exactly 
reconstructed from its samples and examine the consequences when these conditions are 
not satisfied. Following this, we explore the processing of continuous-time signals that 
have been converted to discrete-time signals through sampling. Finally, we examine the 
sampling of discrete-time signals and the related concepts of decimation and interpola-
tion. 
7. I REPRESENTATION OF A CONTINUOUS-TIME SIGNAL BY ITS SAMPLES: 
THE SAMPLING THEOREM 
In general, in the absence of any additional conditions or information, we would not expect 
that a signal could be uniquely specified by a sequence of equally spaced samples. For 
example, inFigure 7.1 we illustrate three different continuous-time signals, all of which 
have identical values at integer multiples of T; that is, 
Clearly, an infinite number of signals can generate a given set of samples. As we 
will see, however, if a signal is band limited-i.e., if its Fourier transform is zero outside 
a finite band of frequencies-and if the samples are taken sufficiently close together in 
relation to the highest frequency present in the signal, then the samples uniquely specify 
the signal, and we can reconstruct it perfectly. This result, known as the sampling theorem, 
is of profound importance in the practical application of the methods of signal and system 
analysis. 
Figure 7. 1 
Three continuous-time signals with identical values at integer 
multiples of T. 

516 
Sampling 
Chap. 7 
7. 1 . 1 Impulse-Train Sampling 
In order to develop the sampling theorem, we need a convenient way in which to represent 
the sampling of a continuous-time signal at regular intervals. A useful way to do this is 
through the use of a periodic impulse train multiplied by the continuous-time signal x(t) 
that we wish to sample. This mechanism, known as impulse-train sampling, is depicted 
in Figure 7.2. The periodic impulse train p(t) is referred to as the sampling function, the 
period T as the sampling period, and the fundamental frequency of p(t), Ws = 2Tr!T, as 
the sampling frequency. In the time domain, 
Xp(t) = x(t)p(t), 
(7.1) 
where 
+oo 
p(t) = L, 8(t - nT). 
(7.2) 
n= - oo 
Because of the sampling property of the unit impulse discussed in Section 1.4.2, we 
know that multiplying x(t) by a unit impulse samples the value of the signal at the point at 
which the impulse is located; i.e., x(t)8(t - t0 ) = x(to)8(t- to). Applying this to eq. (7.1), 
we see, as illustrated in Figure 7.2, that xp(t) is an impulse train with the amplitudes of 
/ 
/ 
p(t) 
x(t) 
• ~~-------;·~ Xp(t) 
1-T-l 
p(t) 
t t 't t t t t 
0 
', 1-T:J x(O) 
x(l) 
',I / 
_/ 
Figure 7.2 
Impulse-train sampling. 

t 
- 2w8 
Sec. 7.1 
Representation of a Continuous-Time Signal by Its Samples: The Sampling Theorem 517 
the impulses equal to the samples of x(t) at intervals spaced by T; that is, 
+oo 
Xp(t) = L x(nT)8(t- nT). 
(7.3) 
n= - oo 
From the multiplication property (Section 4.5), we know that 
} J+x 
X/Jw) = 2
1T _ "' X(j8)P(j(w -
8))d8. 
(7.4) 
and from Example 4.8, 
2 
+oo 
P(jw) = ; L S(w - kw5 ). 
k = - o> 
(7.5) 
Since convolution with an impulse simply shifts a signal [i.e., X(jw) * S(w - wo) = 
X(j(w - w0))], it follows that 
1 +"' 
Xp(jw) = T L X(j(w - kw5 )). 
k = -
00 
(7.6) 
That is, Xp(jw) is a periodic function of w consisting of a superposition of shifted replicas 
of X(jw), scaled by liT, as illustrated iri Figure 7.3. In Figure 7.3(c), WM < (ws -
WM), 
or equivalently, W s > 2wM, and thus there is no overlap between the shifted replicas of 
X(jw ), whereas in Figure 7.3(d), with W s < 2wM, there is overlap. For the case illustrated 
in Figure 7.3(c), X(jw) is faithfully reproduced at integer multiples of the sampling fre-
quency. Consequently, if W s > 2wM, x(t) can be recovered exactly from xp(t) by means of 
XGw) 1 
-wM 
WM 
(a) 
POw) 
t ';t 
- ws 
0 
(b) 
w 
t 
Ws 
t 
2w8 
t ... 
Figure 7.3 
Effect in the frequency 
domain of sampling in the time do-
main: (a) spectrum of original signal; 
(b) spectrum of sampling function; 

518 
XPOw) 
1\!\Jh/\1\!\ 
- wM 
Q WM t Ws 
W 
(c) 
(w8 -
wM) 
(J) 
Sampling 
Chap. 7 
Figure 1.3 
Continued (c) spectrum 
of sampled signal with ws > 2wM; 
(d) spectrum of sampled signal with 
w5 < 2wM. 
a lowpass filter with gain T and a cutoff frequency greater than w M and less than w s - w M, 
as indicated in Figure 7.4. This basic result, referred to as the sampling theorem, can be 
stated as follows: 1 
Sampling Theorem: 
Let x(t) be a band-limited signal with X(jw) = 0 for lwl > WM . Then x(t) is uniquely 
determined by its samples x(nT), n = 0, ::!:: 1, ::!::2, . . . , if 
where 
W s = 
Given these samples, we can reconstruct x(t) by generating a periodic impulse train in 
which successive impulses have amplitudes that are successive sample values. This 
impulse train is then processed through an ideallowpass filter with gain T and cutoff 
frequency greater than w M and less than w s - w M. The resulting output signal will 
exactly equal x(t). 
1 The important and elegant sampling theorem was available for many years in a variety of forms in 
the mathematics literature. See, for example, J. M. Whittaker, "Interpolatory Function Theory," (New York: 
Stecher-Hafner Service Agency, 1964), chap. 4. It did not appear explicitly in the literature of communication 
theory until the publication in 1949 of the classic paper by Shannon entitled "Communication in the Presence of 
Noise" (Proceedings of the IRE, January 1949, pp. 10-21). However, H. Nyquist in 1928 and D. Gabor in 1946 
had pointed out, based on the use of the Fourier Series, that 21W numbers are sufficient to represent a function 
of duration T and highest frequency W. [H. Nyquist, "Certain Topics in Telegraph Transmission Theory," AlEE 
Transactions, 1928, p. 617; D. Gabor, "Theory of Communication,"Joumal of lEE 93, no. 26 (1946), p. 429.] 

Sec. 7.1 
Representation of a Continuous-Time Signal by Its Samples: The Sampling Theorem 519 
+oo 
p(t) = ! 8(t - nT) 
n = - oo 
h 
!X 
Xp(t) D 
x(t)---1·~01-· -----IIII~Ljl------lll~x,(t) 
(a) 
X(jw) A 
(b) 
Xp(iw) 
~~L(WM 
- ws 
- wM 
WM 
Ws 
(J) 
(c) 
H(jw) 
T 
I 
WM < we < (ws - wM) 
(d) 
X,(jw) 
~ 
(e) 
Figure 7.4 
Exact recovery of a 
continuous-time signal from its sam-
ples using an ideal lowpass filter: 
(a) system for sampling and recon-
struction; (b) representative spectrum 
for x(t); (c) corresponding spectrum 
for Xp(t); (d) ideallowpass filter to re-
cover X(jw) from Xp(jw); (e) spectrum 
of x,(t). 
The frequency 2w M, which, under the sampling theorem, must be exceeded by the sam-
pling frequency, is commonly referred to as the Nyquist rate. 2 
As discussed in Chapter 6, ideal filters are generally not used in practice for a va-
riety of reasons. In any practical application, the ideallowpass filter in Figure 7.4 would be 
2The frequency WM corresponding to one-half the Nyquist rate is often referred to as the Nyquist fre-
quency. 

520 
Sampling 
Chap. 7 
replaced by a nonideal filter H(jw) that approximated the desired frequency character-
istic accurately enough for the problem of interest (i.e., H(jw) = 1 for lwl < WM, and 
H(jw) = 0 for lwl > ws - WM ). Obviously, any such approximation in the lowpass filter-
ing stage will lead to some discrepancy between x(t) and xr(t) in Figure 7.4 or, equiva-
lently, between X(jw) and Xr(jw ). The particular choice of nonideal filter is then dictated 
by the acceptable level of distortion for the application under consideration. For conve-
nience and to emphasize basic principles such as the sampling theorem, we will regularly 
assume the availability and use of ideal filters throughout this and the next chapter, with the 
understanding that in practice such a filter must be replaced by a nonideal filter designed 
to approximate the ideal characteristics accurately enough for the problem at hand. 
7. 1.2 Sampling with a Zero-Order Hold 
The sampling theorem, which is most easily explained in terms of impulse-train sampling, 
establishes the fact that a band-limited signal is uniquely represented by its samples. In 
practice, however, narrow, large-amplitude pulses, which approximate impulses, are also 
relatively difficult to generate and transmit, and it is often more convenient to generate the 
sampled signal in a form referred to as a zero-order hold. Such a system samples x(t) at 
a given instant and holds that value until the next instant at which a sample is taken, as 
illustrated in Figure 7.5. The reconstruction of x(t) from the output of a zero-order hold 
can again be carried out by lowpass filtering. However, in this case, the required filter 
no longer has constant gain in the passband. To develop the required filter characteristic, 
we first note that the output x0(t) of the zero-order hold can in principle be generated by 
impulse-train sampling followed by an LTI system with a rectangular impulse response, as 
depicted in Figure 7 .6. To reconstruct x(t) from xo(t), we consider processing xo(t) with an 
LTI system with impulse response hr(t) and frequency response Hr(Jw ). The cascade of 
this system with the system of Figure 7.6 is shown in Figure 7.7, where we wish to specify 
Hr(jw) so that r(t) = x(t). Comparing the system in Figure 7.7 with that in Figure 7.4, 
we see that r(t) = x(t) if the cascade combination of ho(t) and hr(t) is the ideallowpass 
filter H(jw) used in Figure 7.4. Since, from Example 4.4 and the time-shifting property 
in Section 4.3.2, 
u( · ) 
- jwTtz [2sin(wT/2)] 
no JW 
= e 
, 
w 
(7.7) 
this requires that 
. 
eJwTI2H(jw) 
Hr(Jw) = 2sin(wT/2) · 
(7.8) 
w 
x(t) 
Zero-order 
Xo (t) 
_..;..;...~ 
hold 
Figure 7.5 
Sampling utilizing a zero-order hold. 

Sec. 7.1 
Representation of a Continuous-Time Signal by Its Samples: The Sampling Theorem 519 
+«> 
p(t) = I 8(t - nT) 
n = - oo 
• l x 
xp(t) Q 
x(t) --... -~@1-· _.:.;._,...~~1------•~ x,(t) 
(a) 
X(jw) 
~ 
(J) 
(b) 
Xp(jw) 
~)hL(w" 
-ws 
- wM 
WM 
Ws 
(J) 
(c) 
H(jw) 
T 
I 
WM < we < (ws -wM) 
(J) 
(d) 
X,(jw) 
~ 
(J) 
(e) 
Figure 7.4 
Exact recovery of a 
continuous-time signal from its sam-
ples using an ideal lowpass filter: 
(a) system for sampling and recon-
struction; (b) representative spectrum 
for x(t); (c) corresponding spectrum 
for Xp(t); (d) ideallowpass filter to re-
cover X(jw) fromXp(jw); (e) spectrum 
of x,(t). 
The frequency 2w M , which, under the sampling theorem, must be exceeded by the sam-
pling frequency, is commonly referred to as the Nyquist rate. 2 
· 
As discussed in Chapter 6, ideal filters are generally not used in practice for a va-
riety of reasons. In any practical application, the ideallowpass filter in Figure 7.4 would be 
2The frequency WM corresponding to one-half the Nyquist rate is often referred to as the Nyquist fre-
quency. 

520 
Sampling 
Chap. 7 
replaced by a nonideal filter H(jw) that approximated the desired frequency character-
istic accurately enough for the problem of interest (i.e., H(jw) = 1 for lwl < WM, and 
H(jw) = 0 for lwl > w5 - wM ). Obviously, any such approximation in the lowpass filter-
ing stage will lead to some discrepancy between x(t) and x,.(t) in Figure 7.4 or, equiva-
lently, between X(jw) and X,.(jw ). The particular choice of nonideal filter is then dictated 
by the acceptable level of distortion for the application under consideration. For conve-
nience and to emphasize basic principles such as the sampling theorem, we will regularly 
assume the availability and use of ideal filters throughout this and the next chapter, with the 
understanding that in practice such a filter must be replaced by a nonideal filter designed 
to approximate the ideal characteristics accurately enough for the problem at hand. 
7. 1 .2 Sampling with a Zer~Order Hold 
The sampling theorem, which is most easily explained in terms of impulse-train sampling, 
establishes the fact that a band-limited signal is uniquely represented by its samples. In 
practice, however, narrow, large-amplitude pulses, which approximate impulses, are also 
relatively difficult to generate and transmit, and it is often more convenient to generate the 
sampled signal in a form referred to as a zero-order hold. Such a system samples x(t) at 
a given instant and holds that value until the next instant at which a sample is taken, as 
illustrated in Figure 7.5. The reconstruction of x(t) from the output of a zero-order hold 
can again be carried out by lowpass filtering. However, in this case, the required filter 
no longer has constant gain in the passband. To develop the required filter characteristic, 
we first note that the output x0(t) of the zero-order hold can in principle be generated by 
impulse-train sampling followed by an LTI system with a rectangular impulse response, as 
depicted in Figure 7 .6. To reconstruct x(t) from x0(t), we consider processing xo(t) with an 
LTI system with impulse response h,.(t) and frequency response H,.(jw ). The cascade of 
this system with the system of Figure 7.6 is shown in Figure 7.7, where we wish to specify 
H,.(jw) so that r(t) = x(t). Comparing the system in Figure 7. 7 with that in Figure 7 .4, 
we see that r(t) = x(t) if the cascade combination of h0(t) and h,.(t) is the ideallowpass 
filter H(jw) used in Figure 7.4. Since, from Example 4.4 and the time-shifting property 
in Section 4.3.2, 
H( . ) 
-jwTtz [2sin(wT/2)] 
o JW = e 
, 
w 
(7.7) 
this requires that 
. 
ejwTI2H(jw) 
H,.(Jw) = 2sin(wT/2) · 
(7.8) 
w 
_x..;.(t;...) -.J Zero-order 
Xo (t) 
hold 
Figure 7.5 
Sampling utilizing a zero-order hold. 

Sec. 7.1 
x(t)--.~ 
I 
I 
p(t) 
/ 
/ 
/ 
x(t) 
Representation of a Continuous-Time Signal by Its Samples: The Sampling Theorem 521 
Xp (t) 
p(t) 
X 
h0 (t) 1b_ l---.-x0 (t) 
0 
T 
t 
x(t) 
H(jw) 
Figure 1.6 
Zero-order hold as 
impulse-train sampling followed by an 
LTI system with a rectangular impulse 
response. 
r--------------------------------1 
I 
I 
I 
I 
I 
h0 (t) 
I 
I 
I 
Xp (t)l 1b 
x0 (t) 
h,(t) 
I 
I 
H,(jw) 
I 
I 
I 
I 
0 
Tt 
I 
r(t) 
I 
I 
I 
I 
L ___ _________________ ___ _______ _ J 
Figure 7.7 
Cascade of the representation of a zero-order hold (Figure 7.6) 
with a reconstruction filter. 

522 
IH,(jw)l 
Ws 
- 2 
<l: H,Qw) 
1r 
~ 
w. 
- 2 
., 
- 2 
Ws 
(J) 
2 
Ws 
(J) 
2 
Sampling 
Chap. 7 
Figure 7.8 
Magnitude and phase 
for the reconstruction filter for a zero-
order hold. 
For example, with the cutoff frequency of H(jw) equal to ws/2, the ideal magnitude and 
phase for the reconstruction filter following a zero-order hold is that shown in Figure 7.8. 
Once again, in practice the frequency response in eq. (7.8) cannot be exactly realized, 
and thus an adequate approximation to it must be designed. In fact, in many situations, the 
output of the zero-order hold is considered an adequate approximation to the original signal 
by itself, without any additionallowpass filtering, and in essence represents a possible, al-
though admittedly very coarse, interpolation between the sample values. Alternatively, in 
some applications, we may wish to perform some smoother interpolation between sample 
values. In the next section, we explore in more detail the general concept of interpreting 
the reconstruction of a signal from its samples as a process of interpolation. 
7.2 RECONSTRUCTION OF A SIGNAL FROM ITS SAMPLES 
USING INTERPOLATION 
Interpolation, that is, the fitting of a continuous signal to a set of sample values, is a 
commonly used procedure for reconstructing a function, either approximately or exactly, 
from samples. One simple interpolation procedure is the zero-order hold discussed in 
Section 7.1. Another useful form of interpolation is linear interpolation, whereby adja-
cent sample points are connected by a straight line, as illustrated in Figure 7.9. In more 
Figure 1. 9 
Linear interpolation be-
tween sample points. The dashed curve 
represents the original signal and the 
solid curve the linear interpolation. 

Sec. 7.2 
Reconstruction of a Signal from Its Samples Using Interpolation 
523 
complicated interpolation formulas, sample points may be connected by higher order poly-
nomials or other mathematical functions. 
As we have seen in Section 7.1, for a band-limited signal, if the sampling instants 
are sufficiently close, then the signal can be reconstructed exactly; i.e., through the use 
of a lowpass filter, exact interpolation can be carried out between the sample points. The 
interpretation of the reconstruction of x(t) as a process of interpolation becomes evident 
when we consider the effect in the time domain of the lowpass filter in Figure 7.4. In 
particular, the output is 
x,(t) = Xp(t) * h(t) 
or, with xp(t) given by eq. (7.3), 
+ oo 
x,(t) = L x(nT)h(t- nT). 
(7.9) 
n= - oo 
Equation (7 .9) describes how to fit a continuous curve between the sample points 
x(nT) and consequently represents an interpolation formula. For the ideallowpass filter 
H(jw) in Figure 7.4, 
(7.10) 
so that 
( ) = ~ ( T)weT sin(we(t- nT)) 
Xr t 
L 
X n 
( 
T) 
. 
n= - oo 
1T 
W e t - n 
(7.11) 
The reconstruction according to eq. (7.11) with W e = ws/2 is illustrated in Figure 7.10. 
Figure 7.10(a) represents the original band-limited signal x(t), and Figure 7.10(b) rep-
resents xp(t), the impulse train of samples. In Figure 7.10(c), the superposition of the 
individual terms in eq. (7.11) is illustrated. 
Interpolation using the impulse response of an ideallowpass filter as in eq. (7.11) 
is commonly referred to as band-limited interpolation, since it implements exact re-
construction if x(t) is band limited and the sampling frequency satisfies the condi-
tions of the sampling theorem. As we have indicated, in many cases it is preferable 
to use a less accurate, but simpler, filter or, equivalently, a simpler interpolating func-
. tion than the function in eq. (7.10). For example, the zero-order hold can be viewed 
as a form of interpolation between sample values in which the interpolating function 
h(t) is the impulse response ho(t) depicted in Figure 7.6. In that sense, with xo(t) 
in the figure corresponding to the approximation to x(t), the system h0(t) represents 
an approximation to the ideal lowpass filter required for the exact interpolation. Fig-
ure 7.11 shows the magnitude of the transfer function of the zero-order-hold interpo-
lating filter, superimposed on the desired transfer function of the exact interpolating 
filter. 
Both from Figure 7.11 and from Figure 7 .6, we see that the zero-order hold is a very 
rough approximation, although in some cases it is sufficient. For example, if additional 

524 
~>(t) 
I 
I 
I 
I 
I 
IH,(jw)l 
(a) 
(b) 
(c) 
~ 
Ideal interpolating 
filter 
Sampling 
Chap. 7 
Figure 1. 1 o Ideal band-limited in-
terpolation using the sine function: 
(a) band-limited signal x(t); (b) im-
pulse train of samples of x(t); (c) ideal 
band-limited interpolation in which the 
impulse train is replaced by a superpo-
sition of sine functions [eq. (7.11)]. 
Zero-order ___ , 
hold 
0 
Figure 1. 11 
Transfer function for 
the zero-order hold and for the ideal 
interpolating filter. 
lowpass filtering is naturally applied in a given application, it will tend to improve 
the overall interpolation. This is illustrated in the case of pictures in Figure 7.12. Fig-
ure 7.12(a) shows pictures with impulse sampling (i.e., sampling with spatially nar-
row pulses). Figure 7.12(b) is the result of applying a two-dimensional zero-order 
hold to Figure 7.12(a), with a resulting mosaic effect. However, the human visual 
system inherently imposes lowpass filtering, and consequently, when viewed at a dis-
tance, the discontinuities in the mosaic are smoothed. For example, in Figure 7.12(c) a 

(a) 
(b) 
(c) 
Figure 7. 1 2 
(a) The original pictures of Figures 6.2(a) and (g) with impulse sam-
pling; (b) zero-order hold applied to the pictures in (a). The visual system naturally 
introduces lowpass filtering with a cutoff frequency that decreases with distance. 
Thus, when viewed at a distance, the discontinuities in the mosaic in Figure 7.12(b) 
are smoothed; (c) result of applying a zero-order hold after impulse sampling with 
one-fourth the horizontal and vertical spacing used in (a) and (b). 
525 

526 
Sampling 
Chap. 7 
zero-order hold is again used, but here the sample spacing in each direction is one-fourth 
that in Figure 7.12(a). With normal viewing, considerable lowpass filtering is naturally 
applied, although the mosaic effect is still evident. 
If the crude interpolation provided by the zero-order hold is insufficient, we can use 
a variety of smoother interpolation strategies, some of which are known collectively as 
higher order holds. In particular, the zero-order hold produces an output signal, as in Fig-
ure 7.5, that is discontinuous. In contrast, linear interpolation, as illustrated in Figure 7.9, 
yields reconstructions that are continuous, although with discontinous derivatives due to 
the changes in slope at the sample points. Linear interpolation, which is sometimes referred 
to as a first-order hold •. can also be viewed as interpolation in the form of Figure 7.4 and 
eq. (7.9) with h(t) triangular, as illustrated in Figure 7.13. The associated transfer function 
is also shown in the figure and is 
H(. ) = .!_ [sin(wT/2)]
2 
JW 
T 
w/2 
(7.12) 
The transfer function of the first-order hold is shown superimposed on the transfer function 
for the ideal interpolating filter. Figure 7.14 corresponds to the same pictures as those in 
Figure 7 .12(b ), but with a first-order hold applied to the sampled picture. In an analogous 
fashion, we can define second- and higher order holds that produce reconstructions with a 
higher degree of smoothness. For example, the output of a second-order hold provides an 
interpolation of the sample values that is continuous and has a continuous first derivative 
and discontinuous second derivative. 
x(t) 
p(t) 
~ 
X 
Xp(t) 
(a) 
Xp(t) 
(b) 
h(t) 
h(t) 
H(jw) 
T 
2T 
~ 
-T 
(c) 
T 
x,(t) 
.... -- ... , 
' ' 
Figure 7.13 
Linear interpolation 
(first-order hold) as impulse-train sam-
pling followed by convolution with a 
triangular impulse response: (a) sys-
tem for sampling and reconstruction; 
(b) impulse train of samples; (c) im-
pulse response representing a first-
order hold; 

Sec. 7.3 
The Effect of Undersampling: Aliasing 
x,(t) 
~ 
'''' '~ ',,' ' ' ~: ' 
' <'' ' ''_.,-
,, ''' 
: >,' ' ~ ,",': '''' 
, 
' 
; 
" 
.. 
.. 
.. 
.. , 
\ 
. 
' 
- ~ 
2 
(d) 
H(jw) 
T 
0 
(e) 
~ 
2 
Ideal interpolating 
filter 
7.3 THE EFFECT OF UNDERSAMPLING: ALIASING 
527 
Figure 7.13 
Continued (d) first-
order hold applied to the sampled sig-
nal; (e) comparison of transfer function 
of ideal interpolating filter and first-
order hold. 
In previous sections in this chapter, it was assumed that the sampling frequency was 
sufficiently high that the conditions of the sampling theorem were met. As illustrated in 
Figure 7.3, with W s > 2wM, the spectrum of the sampled signal consists of scaled repli-
cations of the spectrum of x(t), and this forms the basis for the sampling theorem. When 
(a) 
(b) 
Figure 7. 14 
Result of applying a first-order hold rather than a zero-order hold af-
ter impulse sampling with one-third the horizontal and vertical spacing used in Fig-
ures 7.12(a) and (b). 

528 
Sampling 
Chap. 7 
Ws < 2wM, X(jw), the spectrum of x(t), is no longer replicated in Xp(jw) and thus is 
no longer recoverable by lowpass filtering. This effect, in which the individual terms in 
eq. (7.6) overlap, is referred to as aliasing, and in this section we explore its effect and 
consequences. 
Clearly, if the system of Figure 7.4 is applied to a signal with Ws < 2wM, the 
reconstructed signal xr(t) will no longer be equal to x(t). However, as explored in 
Problem 7.25, the original signal and the signal xr(t) that is reconstructed using band-
limited interpolation will always be equal at the sampling instants; that is, for any choice 
ofws, 
Xr(nT) = x(nT), 
n = 0, ±1, ±2, . . .. 
(7.13) 
Some insight into the relationship between x(t) and Xr(t) when Ws < 2wM is pro-
vided by considering in more detail the comparatively simple case of a sinusoidal signal. 
Thus, let 
x(t) = cos wot, 
(7.14) 
with Fourier transform X(jw) as indicated in Figure 7.15(a). In this figure, we have 
graphically distinguished the impulse at w0 from that at - w0 for convenience. Let us 
consider Xp()w ), the spectrum of the sampled signal, and focus in particular on the 
effect of a change in the frequency w0 with the sampling frequency Ws fixed. In Fig-
ures 7.15(b)-(e), we illustrate Xp(jw) for several values of w 0 . Also indicated by a 
dashed line is the passband of the lowpass filter of Figure 7.4 with w e = wsf2. Note 
that no aliasing occurs in (b) and (c), since w 0 < w s/2, whereas aliasing does occur 
in (d) and (e). For each of the four cases, the lowpass filtered output Xr(t) is given as 
follows: 
Xr(t) = cos wot = x(t) 
Xr(t) = cos wot = x(t) 
Xr(t) = cos(ws - wo)t # x(t) 
Xr(t) = cos(ws - wo)t # x(t). 
When aliasing occurs, the original frequency w0 takes on the identity of a lower fre-
quency, Ws -wo. Forws/2 < wo < Ws, as wo increases relative toWs, the output frequency 
Ws - wo decreases. When Ws = wo, for example, the reconstructed signal is a constant. 
This is consistent with the fact that, when sampling once per cycle, the samples are all 
equal and would be identical to those obtained by sampling a constant signal (wo = 0). 
In Figure 7.16, we have depicted, for each of the four cases in Figure 7.15, the signal x(t), 
its samples, and the reconstructed signal Xr(t). From the figure, we can see how the lowpass 

Sec. 7.3 
The Effect of Undersampling: Aliasing 
529 
.'lT 
I 
I 
- wo 
• 
- ws 
• 
I 
- ws 
Aliasing 
Aliasing 
X(jw) 
(a) 
Xp(jw) 
(b) 
XPUw) 
(c) 
XP(jw) 
(ws- wo) 
(e) 
t'lT 
wo 
w 
wo= ~ 
6 
w 
(ws- wo) 
wo= 2ws 
6 
w 
4w 
wo= =r 
w 
wo =~ 
6 
w 
Figure 7. 15 
Effect in the frequency 
domain of oversampling and under-
sampling: (a) spectrum of original si-
nusoidal signal; (b), (c) spectrum of 
sampled signal with w5 > 2W(); (d), 
(e) spectrum of sampled signal with 
ws < 2wo. As we increase wo in mov-
ing from (b) through (d), the impulses 
drawn with solid lines move to the 
right, while the impulses drawn with 
dashed lines move to the left. In (d) 
and (e), these impulses have moved 
sufficiently that there is a change in the 
ones falling within the passband of the 
ideal lowpass filter. 
filter interpolates between the samples, in particular always fitting a sinusoid of frequency 
less than w sl2 to the samples of x(t). 
As a variation on the preceding examples, consider the signal 
x(t) = cos(wot + c/J). 
(7.15) 

U1 
w 
0 
' \ 
\ 
\ 
' ' 
\ 
\ 
\ 
\ 
\ 
\ 
I 
'- "'. 
I 
I 
I 
I 
I 
' 
I 
' \ 
' 
' 
\ 
\ 
\ 
\ ' , 
/ 
Original signal 
_ ~ / 
Reconstructed signal 
(a) 
't' 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
' 
I 
(b) 
' i 
' 
' 
' 
' 
' 
___ .... 
I 
I 
I 
I 
I 
\ 
\ 
\ 
\ 
\ 
\ 
' 
\ 
\ 
' 
I 
I l ' 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
I 
\ 
Figure 7. 16 
Effect of aliasing on a sinusoidal signal. For each of four values of 
~. the original sinusoidal signal (solid curve), its samples, and the reconstructed sig-
nal (dashed curve) are illustrated: (a) ~ = w5/6; (b) ~ = 2w5/6; (c) ~ = 4w5/6; 
(d) ~ = 5w5/6. In (a) and (b) no aliasing occurs, whereas in (c) and (d) there is 
aliasing. 
I 
I 
' 
I 
' ' 
I 
I 
wo=~ 
6 
2W5 
wo=s 

,ijco 
i'!co 
II 
II 
0 
0 
3 
3 
I 
/ 
' ' I 
/ 
/ 
I 
\ 
\ 
\ 
\ 
' ' I 
/ 
/ 
~ -: 
' ' \ 
/ 
I 
\ 
I 
~ 
Q) 
I 
::::. 
/ 
~ 
/ 
c:: 
' 
8 
I 
/ 
/ 
..0 
:§: 
~ ...; 
/ 
/ 
~ 
I 
:J 
01 
\ 
u: 
\ 
' \ 
J 
/ 
/ 
' \ 
\ 
\ 
I 
\ 
' ' 
' \ 
J 
/ 
/ 
/ 
/ 
/ 
/ 
I 
531 

532 
Sampling 
Chap. 7 
In this case, the Fourier transform of x(t) is essentially the same as Figure 7.15(a), ex-
cept that the impulse indicated with a solid line now has amplitude 'TT'ei<f>, while the 
impulse indicated with a dashed line has amplitude with the opposite phase, namely, 
'TT'e- i<f>. If we now consider the same set of choices for w0 as in Figure 7.15, there-
sulting spectra for the sampled versions of cos(w0t + </>) are exactly as in the figure, 
with all solid impulses having amplitude 'TT'ei<f> and all dashed ones having amplitude 
'TT'e- i<f>. Again, in cases (b) and (c) the condition of the sampling theorem is met, so 
that x,(t) = cos(w0t + </>) = x(t), while in (d) and (e) we again have aliasing. How-
ever, we n~w see tl].at there has been a reversal in the solid and dashed impulses ap-
pearing in the passband of the lowpass filter. As a result, we find that in these cases, 
x,(t) = cos[(ws - w0)t- <f>], where we have a change in the sign of the phase </J, i.e., a phase 
reversal. 
It is important to note that the sampling theorem explicity requires that the sampling 
frequency be greater than twice the highest frequency in the signal, rather than greater 
than or equal to twice the highest frequency. The next example illustrates that sampling a 
sinusoidal signal at exactly twice its frequency (i.e., exactly two samples per cycle) is not 
sufficient. 
Example 7.1 
Consider the sinusoidal signal 
x(t) = cos(~· t + ~). 
and suppose that this signal is sampled, using impulse sampling, at exactly twice the 
frequency of the sinusoid, i.e., at sampling frequ.!ncy w •. As shown in Problem.7.39, if 
this impulse-sampled signal is applied as the input to an ideallowpass filter with cutoff 
frequency w./2, the resulting output is 
x,(t) =(cos~) cos(~· r). 
As a consequence, we see that perfect reconstruction of x(t) occurs only in the case in 
which the phase~ is zero (or an integer multiple of 27T'). Otherwise, the signal x,(t) does 
not equal x(t). 
As an extreme example, consider the case in which~ = -'TT'/2, so that 
This signal is sketched in Figure 7.17. We observe that the values of the signal at integer 
multiples of the sampling period 2Trlws are zero. Consequently, sampling at this rate 
produces a signal that is identically zero, and when this zero input is applied to the ideal 
lowpass filter, the resulting output x,(t) is also identically zero. 

Sec. 7.3 
The Effect of Undersampling: Aliasing 
533 
Figure 7.17 
Sinusoidal signal for Example 7.1. 
The effect of undersampling, whereby higher frequencies are reflected into lower 
frequencies, is the principle on which the stroboscopic effect is based. Consider, for exam-
ple, the situation depicted in Figure 7 .18, in which we have a disc rotating at a constant rate 
with a single radial line marked on the disc. The flashing strobe acts as a sampling system, 
since it illuminates the disc for extremely brief time intervals at a periodic rate. When the 
strobe frequency is much higher than the rotational speed of the disc, the speed of rotation 
of the disc is perceived correctly. When the strobe frequency becomes less than twice the 
rotational frequency of the disc, the rotation appears to be at a lower frequency than is actu-
ally the case. Furthermore, because of phase reversal, the disc will appear to be rotating in 
the wrong direction! Roughly speaking, if we track the position of a fixed line on the disc 
at successive samples, then when wo < W s < 2w0, so that we sample somewhat more fre-
quently than once per revolution, samples of the disc will show the fixed line in positions 
that are successively displaced in a counterclockwise direction, opposite to the clockwise 
rotation of the disc itself. At one flash per revolution, corresponding tows = w0, the radial 
line appears stationary (i.e., the rotational frequency of the disc and its harmonics have 
been aliased to zero frequency). A similar effect is commonly observed in Western movies, 
Strobe 
Figure 7. 1 8 
Strobe effect. 

Sec. 7.4 
Discrete-Time Processing of Continuous-Time Signals 
535 
The transformation of Xc(t) to xd [n] corresponding to the first system in Figure 7.19 will 
be referred to as continuous-to-discrete-time conversion and will be abbreviated C/D. The 
reverse operation corresponding to the third system in Figure 7.19 will be abbreviated D/C, 
representing discrete-time to continuous-time conversion. The D/C operation performs an 
interpolation between the sample values provided to it as input. That is, the D/C operation 
produces a continuous-time signal Yc(t) which is related to the discrete-time signal Yd[n] 
by 
Yd[n] = Yc(nT). 
This notation is made explicit in Figure 7.20. In systems such as digital computers and 
digital systems for which the discrete-time signal is represented in digital form, the device 
commonly used to implement the C/D conversion is referred to as an analog-to-digital (A-
to-D) converter, and the device used to implement the D/C conversion is referred to as a 
digital-to-analog (D-to-A) converter. 
Xc (t) 
T 
T 
Figure 7.20 
Notation for continuous-to-discrete-time conversion and 
discrete-to-continuous-time conversion. T represents the sampling period. 
Yc (t) 
To understand further the relationship between the continuous-time signal xc(t) and 
its discrete-time representation xd [ n ], it is helpful to represent C/D as a process of periodic 
sampling followed by a mapping of the impulse train to a sequence. These two steps are 
illustrated in Figure 7.21. In the first step, representing the sampling process, the impulse 
train Xp(t) corresponds to a sequence of impulses with amplitudes corresponding to the 
samples of Xc(t) and with a time spacing equal to the sampling period T. In the conver-
sion from the impulse train to the discrete-time sequence, we obtain xd[n], corresponding 
to the same sequence of samples of Xc(t), but with unity spacing in terms of the new in-
dependent variable n. Thus, in effect, the conversion from the impulse train sequence of 
samples to the discrete-time sequence of samples can be thought of as a normalization in 
time. This normalization in converting xp(t) to xd[n] is evident in Figures 7.21(b) and (c), 
in which xp(t) and xd[n] are respectively illustrated for sampling rates of T = T1 and 
T = 2T1• 
It is also instructive to examine the processing stages in Figure 7.19 in the frequency 
domain. Since we will be dealing . with Fourier transforms in both continuous and dis-
crete time, in this section only we distinguish the continuous-time and discrete-time fre-
quency variables by using w in continuous time and fl in discrete time. For example, the 
continuous-time Fourier transforms of Xc(t) and Yc(t) are Xc(jw) and Yc(Jw ), respectively, 
while the discrete-time Fourier transforms of xd[n] and Yd[n] are Xd(ei0 ) and Yd(ei0 ), 
respectively. 

536 
-
/ 
C/D conversion 
------ ---- ----- - , 
I 
I 
p(t) 
: ~ 
Conversion of 
x (t) __:... x 
Xp (t) 
impulse train 
c 
1 
to discrete-time 
- - ' 
sequence 
1 
I 
I ________________ I 
/ 
/ 
/ -
-T---
0 T 2T 
(a) 
= 
, 
(b) 
/ , -
/ 
rrniinr 
Sampling 
Xp (t) 
___ ,... 
0 
T 
2T t 
-4-3-2 - 1 0 
1 2 3 4 
n 
-4 -3 -2 -1 0 
1 
2 
3 
4 
n 
(c) 
Figure 7.21 
Sampling with a periodic impulse train followed by conversion 
to a discrete-time sequence: (a) overall system; (b) xp{t) for two sampling 
rates. The dashed envelope represents Xc{t); (c) the output sequence for the 
two different sampling rates. 
Chap. 7 
To begin let us express Xp(jw ), the continuous-time Fourier transform of xp(t), 
in terms of the sample values of Xc(t) by applying the Fourier transform to eq. (7.3). 
Since 
+oo 
xp(t) = :2=. Xc(nT)o(t - nT), 
(7.17) 
n= -oo 
and since the transform of o(t- nT) is e- JwnT, it follows that 
+oo 
Xp(jw) = :2=. Xc(nT)e- jwnT 
(7 .18) 
n= -oo 

Sec. 7.4 
Discrete-Time Processing of Continuous-Time Signals 
537 
Now consider the discrete-time Fourier transform of xd[n], that is, 
+oo 
Xd(ej0 ) = L xd[n]e- j!ln, 
(7.19) 
11 = - oo 
or, using eq. (7.16), 
+oo 
Xd(ej0 ) = L Xc(nT)e- j!ln. 
(7.20) 
n = - oo 
Comparing eqs. (7.18) and (7.20), we see that Xd(ej0 ) and Xp(jw) are related through 
Xd(ej0 ) = Xp(Jfl/T). 
(7.21) 
Also, recall that, as developed in eq. (7.6) and illustrated in Figure 7.3, 
1 
+oo 
Xp(jw) = T L Xc(j(w -
kws)). 
k = -oo 
(7.22) 
Consequently, 
. 
1 
+oo 
Xd(e10 ) = T L Xc(}(fl - 27Tk)/T). 
k = - oo 
(7.23) 
The relationship among Xc(jw), Xp(jw), and Xd(ej0 ) is illustrated in Figure 7.22 
for two different sampling rates. Here, Xd(ej0 ) is a frequency-scaled version of Xp(jw) 
Xc (jw) 
Xc(iw) 
i 
i 
w 
0 
!l 
Figure 7.22 
Relationship between XcUw ), Xp(jw ), and Xd( ein) for two dif-
ferent sampling rates. 
w 
n 

538 
Sampling 
Chap. 7 
and, in particular, is periodic inn with period 27T. This periodicity is, of course, charac-
teristic of any discrete-time Fourier transform. The spectrum of xd[n] is related to that of 
Xc(t) through periodic replication, represented by eq. (7.22), followed by linear frequency 
scaling, represented by eq. (7.21). The periodic replication is a consequence of the first 
step in the conversion process in Figure 7.21, namely, the impulse-train sampling. The 
linear frequency scaling in eq. (7.21) can be thought of informally as a consequence of 
the normalization in time introduced by converting from the impulse train xp(t) to the 
discrete-time sequence xd[n]. From the time-scaling property of the Fourier transform in 
Section 4.3.5, scaling of the time axis by liT will introduce a scaling of the frequency 
axis by T. Thus, the relationship 11 = w T is consistent with the notion that, in converting 
from xp(t) to xd[n], the time axis is scaled by liT. 
In the overall system of Figure 7.19, after processing with a discrete-time system, 
the resulting sequence is converted back to a continuous-time signal. This process is the 
reverse of the steps in Figure 7.21. Specifically, from the sequence Yd[n], a continuous-
time impulse train yp(t) can be generated. Recovery of the continuous-time signal Yc(t) 
from this impulse train is then accomplished by means of lowpass filtering, as illustrated 
in Figure 7.23. 
D/C conversion 
~ -- ---------------- ------- -----
1 
I 
I 
I 
I 
Conversion of 
Yp (t) 
IT 
discrete-time 
I 
I 
sequence to 
w w 
Yd[n]~ 
Yc (t) 
I 
I 
I 
I 
I 
impulse train 
Ws 
-2 
s 
2 
Figure 7.23 
Conversion of a 
discrete-time sequence to a continuous-
time signal. 
Now let us consider the overall system of Figure 7.19, represented as shown in Fig-
ure 7.24. Clearly, if the discrete-time system is an identity system (i.e., xd[n] = Yd[n]), 
then, assuming that the conditions of the sampling theorem are met, the overall system 
will be an identity system. The characteristics of the overall system with a more general 
frequency response Hd(ejfl.) are perhaps best understood by examining the representative 
example depicted in Figure 7.25. On the left-hand side of the figure are the representative 
~ -- ------------- --------- ----------------- ----- ----------- ----
1 
: 
p(t) 
I 
I 
I 
I 
Xc (t) --j-.-
X 
I 
I 
I 
I 
I 
I 
I 
Conversion of xd [n] 
impulse train 1---.~ 
to sequence 
Yd [n] 
Conversion of Yp (t) 
1---.~ sequence to 
impulse train 
2 
2 
•-------------------------------------------------------------
Figure 7.24 
Overall system for filtering a continuous-time signal using a discrete-
time filter. 
Yc (t) 

Ill 
w 
..0 
Xe (jw) 
Hd (ein), Xd (ein) 
It\ 
- wM 
0 
WM 
w 
- wM T -fie 
fie wMT 
(a) 
(d) 
Xp(jw) 
Hp (jw), Xp (jw) 
!\~!\ 
AAA 
- ws 
-wM 
0 
WM 
(b) 
Xd (ein) 
Ws 
w 
- w. 
fie 0 fie wM 
-wM -T 
T 
(e) 
He (jw), Xe (jw) 
~ 
__ L 
He (jw) 
- w8T 
- wMT 
0 
wMT 
w8T = 2'1T 
fi 
- wM 
WM 
(c) 
(f) 
Figure 7.25 
Frequency-domain illustration of the system of Figure 7.24: (a) continuous-
time spectrum Xc(iw ); (b) spectrum after impulse-train sampling; (c) spectrum of 
discrete-time sequence xd[n]; (d) Hd(ei0 ) and Xd(eifi ) that are multiplied to form 
Yd(eifi ); (e) spectra that are multiplied to form Yp(jw); (f) spectra that are multiplied 
to form Yc(iw). 
Ws 
2'1T 
fi 
w 
w 

540 
Sampling 
Chap. 7 
spectra Xc(jw ), Xp(jw ), and Xd(ejfl), where we assume that WM < Ws/2, so that there is 
no aliasing. The spectrum Y d( ejfl) corresponding to the output of the discrete-time filter is 
the product of Xd(ejfl) and Hd(ejfl), and this is depicted in Figure 7.25(d) by overlaying 
Hd(ejfl) and Xd(ejfl). The transformation to Yc(jw) then corresponds to applying a fre-
quency scaling and lowpass filtering, resulting in the spectra indicated in Figure 7.25(e) 
and (f). Since Yd(ejfl) is the product of the two overlaid spectra in Figure 7.25(d), the 
frequency scaling and lowpass filtering are applied to both. In comparing Figures 7.25(a) 
and (f), we see that 
(7.24) 
Consequently, for inputs that are sufficiently band limited, so that the sampling theorem is 
satisfied, the overall system of Figure 7.24 is, in fact, equivalent to a continuous-time LTI 
system with frequency response H c(jw) which is related to the discrete-time frequency 
response Hd(ejfl) through 
lwl < wsf2 
lwl > wsf2 · 
(7.25) 
The equivalent frequency response for this continuous-time filter is one period of the 
frequency response of the discrete-time filter with a linear scale change applied to the 
frequency axis. This relationship between the discrete-time frequency response and 
the equivalent continuous-time frequency response is illustrated in Figure 7 .26. 
The equivalence of the overall system of Figure 7.24 to an LTI system is somewhat 
surprising in view of the fact that multiplication by an impulse train is not a time-invariant 
operation. In fact, the overall system of F;igure 7.24 is not time invariant for arbitrary in-
puts. For example, if Xc(t) was a narrow rectangular pulse of duration less than T, then a 
time shift of Xc(t) could generate a sequence x[n] that either had all zero values or had 
one nonzero value, depending on the alignment of the rectangular pulse relative to the 
2'1T 
n 
Figure 7.26 
Discrete-time fre-
quency response and the equivalent 
w 
continuous-time frequency response 
for the system of Figure 7.24. 

Sec. 7.4 
Discrete-Time Processing of Continuous-Time Signals 
541 
sampling impulse train. However, as suggested by the spectra of Figure 7.25, for band-
limited input signals with a sampling rate sufficiently high so as to avoid aliasing, the 
system of Figure 7.24 is equivalent to a continuous-time LTI system. For such inputs, 
Figure 7.24 and eq. (7.25) provide the conceptual basis for continuous-time processing 
using discrete-time filters. This is now explored further in the context of some examples. 
7 .4. 1 Digital Differentiator 
Consider the discrete-time implementation of a continuous-time band-limited differenti-
ating filter. As discussed in Section 3.9.1, the frequency response of a continuous-time 
differentiating filter is 
He(jw) = jw, 
(7.26) 
and that of a band-limited differentiator with cutoff frequency W e is 
He(jw) = { jw, 
0, 
lwl <we 
lwl >we' 
(7.27) 
as sketched in Figure 7.27. Using eq. (7.25) with a sampling frequency Ws = 2we, we see 
that the corresponding discrete-time transfer function is 
(7.28) 
as sketched in Figure 7.28. With this discrete-time transfer function, Ye(t) in Figure 7.24 
will be the derivative of Xe(t), assuming that there is no aliasing in sampling Xe(t). 
I He (jw) I 
1T 1------. 
2 
1T 
2 
w 
w 
Figure 7.27 
Frequency response 
of a continuous-time ideal band-limited 
differentiator HcUw) = jw, lwl < we. 

542 
1T 2 
1T 2 
Example 7.2 
n 
Sampling 
Chap. 7 
Figure 7.28 
Frequency response 
of discrete-time filter used to imple-
ment a continuous-time band-limited 
differentiator. 
By considering the output of the digital differentiator for a continuous-time sine input, 
we may conveniently determine the impulse response hd [n] of the discrete-time filter in 
the implementation of the digital differentiator. With reference to Figure 7 .24, let 
( ) _ sin( 'Trt/T) 
Xc t -
, 
'Trt 
where Tis the sampling period. Then 
lwl < 7r/T 
otherwise ' 
(7.29) 
which is sufficiently band limited to ensure that sampling Xc(t) at frequency W s = 27r/T 
does not give rise to any aliasing. It follows that the output of the digital differentiator is 
( ) _ d 
( ) _ cos( 7rt/T) _ sin( 7rt/T) 
Yc t -
-d Xc t -
T 
2 
t 
t 
'Trt 
(7.30) 
For Xc(t) as given by eq. (7.29), the corresponding signal XJ [n] in Figure 7.24 may 
be expressed as 
1 
XJ [n] = Xc(nT) = T8[n]. 
That is, for n 'i' 0, Xc(nT) = 0, while 
(7.31) 
which can be verified by l'Hopital's rule. We can similarly evaluate Yd[n] in Figure 7.24 
corresponding to YcU) in eq. (7.30). Specifically 
{ 
( - 1)" 
Yd[n] = Yc(nT) = 
OnT2 ' 
n'i'O 
n=O 
(7.32) 

Sec. 7.4 
Discrete-Time Processing of Continuous-Time Signals 
543 
which can be verified for n -,.6 0 by direct substitution into eq. (7.30) and for n = 0 by 
application of l'H6pital's rule. 
Thus when the input to the discrete-time filter given by eq. (7.28) is the scaled 
unit impulse in eq. (7.31), the resulting output is given by eq. (7.32). We then conclude 
that the impulse response of this filter is given by 
{ 
(-l)n 
hd[n] = ~ · 
n -,.6 0 
0, 
n = 0 
7 .4.2 Half-Sample Delay 
In this section, we consider the implementation of a time shift (delay) of a continuous-time 
signal through the use of a system in the form of Figure 7.19. Thus, we require that the 
input and output of the overall system be related by 
Yc(t) = Xc(t- Ll) 
(7.33) 
when the input Xc(t) is band limited and the sampling rate is high enough to avoid alias-
ing and where Ll represents the delay time. From the time-shifting property derived in 
Section 4.3.2 
Ye(Jw) = e- jwi:!.Xe(Jw). 
From eq. (7.25), the equivalent continuous-time system to be implemented must be band 
limited. Therefore, we take 
He(Jw) = 
e 
' 
{ 
- jwl:!. 
0, 
lwl < we 
otherwise' 
(7.34) 
where we is the cutofffrequency of the continuous-time filter. That is, He(Jw) corresponds 
to a time shift as in eq. (7.33) for band-limited signals and rejects all frequencies greater 
than We . The magnitude and phase of the frequency response are shown in Figure 7.29(a). 
With the sampling frequency W s taken as W s = 2wc, the corresponding discrete-time 
I Hc(jw) I 
Hd(ei!l) 
'I 
-we 
We 
w 
I 
, I 
I 
- 'lT 
'lT 
n 
<l: Hc(iw) 
<l: Hd(ei!l) 
w 
~ 
............. 
............... 
"'l~ 'i 
(a) 
(b) 
Figure 7.29 
(a) Magnitude and phase of the frequency response for a 
continuous-time delay; (b) magnitude and phase of the frequency response 
for the corresponding discrete-time delay. 

544 
Sampling 
Chap. 7 
frequency response is 
(7.35) 
and is shown in Figure 7.29(b). 
For appropriately band-limited inputs, the output of the system of Figure 7.24 with 
Hd(ej0 ) as in eq. (7.35) is a delayed replica of the input. For !1fT an integer, the sequence 
Yd[n] is a delayed replica of xd[n]; that is, 
Yd[n] = Xd [ n- ~]. 
(7.36) 
For !1fT not an integer, eq. (7 .36), as written, has no meaning, since sequences are defined 
only at integer values of the index. However, we can interpret the relationship between 
xd[n] and Yd[n] in these cases in terms of band-limited interpolation. The signals Xc(t) 
and xd[n] are related through sampling and band-limited interpolation, as are Yc(t) and 
Yd[n]. With Hd(ej0 ) in eq. (7.35), Yd[n] is equal to samples of a shifted version of the 
band-limited interpolation of the sequence xd[n]. This is illustrated in Figure 7.30 with 
d!T = 112, which is sometimes referred to as a half-sample delay. 
0 
T 
2T 
(a) 
0 
T 
2T 
(b) 
Example 7.3 
Figure 7.30 
(a) Sequence of sam-
ples of a continuous-time signal Xc{t); 
(b) sequence in (a) with a half-sample 
delay. 
The approach in Example 7.2 is also applicable to determining the impulse response 
hd[n] of the discrete-time filter in the half-sample delay system. With reference to Fig-
ure 7.24, let 
( ) _ sin( 'TTt/T) 
Xc t -
. 
'TTt 
It follows from Example 7.2 that 
1 
xd[n] = Xc(nT) = T8[n]. 
(7.37) 

Sec. 7.5 
Sampling of Discrete-Time Signals 
545 
Also, since there is no aliasing for the band-limited input in eq. (7.37), the output of the 
half-sample delay system is 
() = 
( _ T/2) = sin(7T(t- T/2)/T) 
Ye t 
Xc t 
7T(t-T/2)
, 
and the sequence Yd[n] in Figure 7.24 is 
We conclude that 
sin( 7T(n -
~ )) 
Yd[n] = Yc(nT) = ---
7'-
T7T(n -
~) · 
sin( 7T(n -
~ )) 
h[n] = -
-
--,.-"--
7T(n- ~) . 
7.5 SAMPLING OF DISCRETE-TIME SIGNALS 
Thus far in this chapter, we have considered the sampling of continuous-time signals, and 
in addition to developing the analysis necessary to understand continuous-time sampling, 
we have introduced a number of its applications. As we will see in this section, a very sim-
ilar set of properties and results with a number of important applications can be developed 
for sampling of discrete-time signals. 
7.5.1 Impulse-Train Sampling 
In analogy with continuous-time sampling as carried out using the system of Figure 7 .2, 
sampling of a discrete-time signal can be represented as shown in Figure 7.31. Here, the 
new sequence xp[n] resulting from the sampling process is equal to the original sequence 
x[n] at integer multiples of the sampling period Nand is zero at the intermediate samples; 
that is, 
[ ] _ { x[n], 
Xp n -
0, 
if n = an integer multiple of N 
otherwise 
(7.38) 
As with continuous-time sampling in Section 7.1, the effect in the frequency do-
main of discrete-time sampling is seen by using the multiplication property developed in 
Section 5.5. Thus, with 
+co 
Xp[n] = x[n]p[n] = L x[kN]S[n- kN], 
(7.39) 
k= - oo 
we have, in the frequency domain, 
(7.40) 

546 
Sampling 
Chap. 7 
x[n]--.-{ X ,__.,._ xp[n] 
+oo 
p[n) = ~ 1l [n - kN) 
k= - 00 
riiiiirrriiiiiiiiir 
x[n] 
n 
.. I .. I I I .. I I I 
p[n: 
• • • • 
• • 
• • • • 
• • 
n 
I I I I I.. I I . 
xp[n] 
• • 
• • • • • • 
• • 
Figure 7.31 
Discrete-time 
n 
sampling. 
As in Example 5.6, the Fourier transform of the sampling sequence p[n] is 
2 
+co 
. 
11'"" 
P(e1w) = N L 
l>(w - kws), 
k = - 00 
(7.41) 
where W s , the sampling frequency, equals 211'/N. Combining eqs. (7.40) and (7.41), we 
have 
(7.42) 
Equation (7.42) is the counterpart for discrete-time sampling of eq. (7.6) for 
continuous-time sampling and is illustrated in Figure 7.32. In Figure 7.32(c), with 
Ws - WM > WM, or equivalently, W s > 2wM, there is no aliasing [i.e., the nonzero portions 
of the replicas of X(ejw) do not overlap], whereas with Ws < 2wM, as in Figure 7.32(d), 
frequency-domain aliasing results. In the absence of aliasing, X(ejw) is faithfully repro-
duced around w = 0 and integer multiples of 211'. Consequently, x[n] can be recovered 
from xp[n] by means of a lowpass filter with gain Nand a cutoff frequency greater than 

Sec. 7.5 
Sampling of Discrete-Time Signals 
X(eij ;l 
- 2'lr 
-wM 
0 
WM 
(a) 
P(eij 
t 
t 
t 'd 
t 
t 
t 
w. 
(b) 
Xp(eiw) 
~ /\. /\. Yhu6, /\. L 
- wM 
WM ""W5 
2'lr 
W 
(c) 
(w.-wM) 
(d) 
Figure 1.32 
Effect in the frequency domain of impulse-train sampling of a 
discrete-time signal: (a) spectrum of original signal; (b) spectrum of sampling 
sequence; (c) spectrum of sampled signal with w5 > 2wM; (d) spectrum of 
sampled signal with ws < 2wM. Note that aliasing occurs. 
547 
WM and less than Ws -
WM, as illustrated in Figure 7.33, where we have specified the 
cutoff frequency of the lowpass filter as w 5/2. If the overall system of Figure 7 .33( a) is ap-
plied to a sequence for which Ws < 2wM, so that aliasing results, Xr[n] will nolonger 
be equal to x[n]. However, as with continuous-time sampling, the two sequences will 
be equal at multiples of the sampling period; that is, corresponding to eq. (7.13), we 
have 
Xr[kN] = x[kN], 
k = 0, ± 1, ± 2, .. . , 
(7.43) 
independently of whether aliasing occurs. (See Problem 7.46.) 

548 
Sampling 
p[n] 
x[n] 
.~ P 
• 
H(jw) 
x,[n] 
x[n]~ 
(a) 
X(jw) 
~ 
;k 
~ 
- 2'TT 
-wM 
WM 
2'TT 
w 
Xp(jw) 
(0.A/\}±\(>~~ 
X(jw) 
"I 
- 2'TT 
2'TT 
w 
X,(jw) 
zl 
- 2'TT 
(b) 
Figure 7.33 
Exact recovery of a discrete-time signal from its samples us-
ing an ideal lowpass filter: (a) block diagram for sampling and reconstruction 
of a band-limited signal from its samples; (b) spectrum of the signal x[n]; 
(c) spectrum of Xp[n]; (d) frequency response of an ideallowpass filter with 
cutoff frequency w5/2; (e) spectrum of the reconstructed signal x,[ n ]. For the 
example depicted here w5 > 2wM so that no aliasing occurs and consequently 
x,[n] = x[n]. 
Example 7.4 
Consider a sequence x[n] whose Fourier transform X(ejw) has the property that 
X(ejw) = 0 
for 
2rr/9 ~ lwl ~ 'TT. 
Chap. 7 

Sec. 7.5 
Sampling of Discrete-Time Signals 
549 
To determine the lowest rate at which x[n] may be sampled without the possibility of 
aliasing, we must find the largest N such that 
We conclude that Nmax = 4, and the corresponding sampling frequency is 27T/4 = 7T/2. 
The reconstruction of x[n] through the use of a lowpass filter applied to xp[n] can be 
interpreted in the time domain as an interpolation formula similar to eq. (7.11). With h[n] 
denoting the impulse response of the lowpass filter, we have 
h[n] = Nwc sinwcn 
(7.44) 
The reconstructed sequence is then 
x,.[n] = Xp[n] * h[n], 
(7.45) 
or equivalently, 
[ ] = ~ [kN]Nwc sinwc(n- kN) 
x,. n 
L 
x 
( - kN) . 
k = - oo 
7r 
W e n 
(7.46) 
Equation (7.46) represents ideal band-limited interpolation and requires the implemen-
tation of an ideal lowpass filter. In typical applications a suitable approximation for the 
lowpass filter in Figure 7.33 is used, in which case the equivalent interpolation formula is 
of the form 
+oo 
x,.[n] = L x[kN]h,.[n - kN], 
(7.47) 
k = - oo 
where h,.[ n] is the impulse response of the interpolating filter. Some specific examples, in-
eluding the discrete-time counterparts of the zero-order hold and first-order hold discussed 
in Section 7.2 for continuous-time interpolation, are considered in Problem 7.50. 
7.5.2 Discrete-Time Decimation and Interpolation 
There are a variety of important applications of the principles of discrete-time sampling, 
such as in filter design and implementation or in communication applications. In many 
of these applications it is inefficient to represent, transmit, or store the sampled sequence 
Xp[n] directly in the form depicted in Figure 7.31, since, in between the sampling instants, 
Xp[n] is known to be zero. Thus, the sampled sequence is typically replaced by a new 
sequence xb[n], which is simply every Nth value of Xp[n]; that is, 
(7.48) 
Also, equivalently, 
xb[n] = x[nN], 
(7.49) 

550 
Sampling 
Chap. 7 
since Xp[n] and x[n] are equal at integer multiples of N. The operation of extracting every 
Nth sample is commonly referred to as decimation. 3 The relationship between x[n], xp[n], 
and Xb[n] is illustrated in Figure 7.34. 
To determine the effect in the frequency domain of decimation, we wish to determine 
the relationship between Xb(eiw)-
the Fourier transform of xb[n]-
and X(eiw). To this 
end, we note that 
+co 
Xb(eiw) = L Xb[k]e - jwk, 
k= - co 
or, using eq. (7.48), 
+ co 
Xb(eiw) = L Xp[kN]e-jwk. 
k = - co 
If we let n = kN, or equivalently k = n/N, we can write 
n = integer 
multiple of N 
and since xp[n] = 0 when n is not an integer multiple of N, we can also write 
+co 
Xb(eiw) = L Xp[n]e - JwniN. 
n= - oo 
ti IIIrrrrriiiiiii It 
x[n] 
0 
n 
. ' . .1. • J • I r 
xp[n] 
. I . . . . . . I .. 
0 
n 
(7.50) 
(7.51) 
(7.52) 
rln!Ir 
0 
n 
Figure 7.34 
Relationship between 
Xp[n] corresponding to sampling and 
xb[n] corresponding to decimation. 
3Technically, decimation would correspond to extracting every tenth sample. However, it has become 
common terminology to refer to the operation as decimation even when N is not equal to I 0. 

Sec. 7.5 
Sampling of Discrete-Time Signals 
551 
Furthermore, we recognize the right-hand side of eq. (7.52) as the Fourier transform of 
Xp[n]; that is, 
· 
+o:: L Xp[n]e - jwn!N = Xp(eiw!N ). 
n = - o::: 
Thus, from eqs. (7.52) and (7.53), we conclude that 
Xb(eiw) = Xp(eiw!N ). 
(7.53) 
(7.54) 
This relationship is illustrated in Figure 7.35, and from it, we observe that the spectra for 
the sampled sequence and the decimated sequence differ only in a frequency scaling or 
normalization. If the original spectrum X(ei w) is appropriately band limited, so that there 
is no aliasing present in Xp(ei w), then, as shown in the figure, the effect of decimation is to 
spread the spectrum of the original sequence over a larger portion of the frequency band. 
X(eiw) 
~ 
A 
I 
A 
-wM 
WM 
71' 
271' 
w 
i 
71' 
271' 
w 
Figure 7.35 
Frequency-domain illustration of the relationship between 
sampling and decimation. 
If the original sequence x[n] is obtained by sampling a continuous-time signal, the 
process of decimation can be viewed as reducing the sampling rate on the signal by a factor 
of N. To avoid aliasing, X ( eiw) cannot occupy the full frequency band. In other words, if 
the signal can be decimated without introducing aliasing, then the original continuous-
time signal was oversampled, and thus, the sampling rate can be reduced without aliasing. 
With the interpretation of the sequence x[n] as samples of a continuous-time signal, the 
process of decimation is often referred to as downsampling. 

552 
C/1:> 
xd[n] 
Discrete time 
conversion 
lowpass filter 
Hd(ei"') 
Xe(iw) 
Lh 
-wM 
WM 
~(eij 
~ 
- 2'!l" 
w 
'IT 
2'!l" 
Hd(ei"') 
D 'rh 
D 
-2'!l"2 
- we 
We 
21T 
Yd(eij 
(J 
cb 
(J 
- 2'!l" 
- we 
We 
2'!l" 
w 
w 
w 
w 
Sampling 
Chap. 7 
Figure 7.36 
Continuous-time sig-
nal that was originally sampled at the 
Nyquist rate. After discrete-time fil-
tering, the resulting sequence can be 
further downsampled. Here Xc(iw) 
is the continuous-time Fourier trans-
form of Xc(t), Xd(eiw) and Yd(eiw) are 
the discrete-time Fourier transforms 
of xd[n] and Yd[n] respectively, and 
Hd( eJw) is the frequency response of 
the discrete-time lowpass filter de-
picted in the block diagram. 
In some applications in which a sequence is obtained by sampling a continuous-
time signal, the original sampling rate may be as low as possible without introducing 
aliasing, but after additional processing and filtering, the bandwidth of the sequence 
may be reduced. An example of such a situation is shown in Figure 7.36. Since the 
output of the discrete-time filter is band limited, downsampling or decimation can be 
applied. 
Just as in some applications it is useful to downsample, there are situations in which 
it is useful to convert a sequence to a higher equivalent sampling rate, a process referred 
to as upsampling or interpolation. Upsampling is basically the reverse of decimation or 
downsampling. As illustrated in Figures 7.34 and 7.35, in decimation we first sample and 
then retain only the sequence values at the sampling instants. To upsample, we reverse 
the process. For example, referring to Figure 7.34, we consider upsampling the sequence 
xb[n] to obtain x[n]. From xb[n], we form the sequence xp[n] by inserting N - 1 points 
with zero amplitude between each of the values in xb[n]. The interpolated sequence x[n] 
is then obtained from Xp[n] by lowpass filtering. The overall procedure is summarized in 
Figure 7.37. 

Ul 
Ul 
w 
xb[n] 
Conversion of 
-
decimated sequence 
Ideal lowpass 
to sampled 
filter 
----+ 
sequence 
H(eiw) 
x[n] 
(a) 
xb[n] 
Xb(eiw) 
)_, A 
L 
n 
-Z'lT 
2'1T 
w 
xp[n] 
n 
-2'1T 
-'lT 
1T 
1T 
'lT 
2'1T w 
2 
2 
x[n] 
X(eiw) 
71\ 
\ . 
. I 
n 
-~'lT 
'lT 
2'1T 
w 
Figure 7.37 Upsampling: (a) overall system; (b) associated sequences and spectra 
for upsampling by a factor of 2. 

554 
Sampling 
Chap. 7 
Example 7.5 
In this example, we illustrate how a combination of interpolation and decimation may be 
used to further downsample a sequence without incurring aliasing. It should be noted that 
maximum possible downsampling is achieved once the non-zero portion of one period 
of the discrete-time spectrum has expanded to fill the entire band from - 'IT to 7T. 
Consider the sequence x[ n] whose Fourier transform X ( ejw) is illustrated in Figure 
7.38(a). As discussed in Example 7.4, the lowest rate at which impulse-train sampling 
may be used on this sequence without incurring aliasing is 27T/4. This corresponds to 
'IT 
w 
(a) 
-2'1T 
10'1T -'IT 8'1T 
0 
8'1T ,/I> 
--g 
--g 
9 
(b) 
-2'1T 17'1T 
'IT 
--g 
Figure 7.38 
Spectra associated with Example 7.5. (a) Spectrum of x[n]; 
(b) spectrum after downsampling by 4; (c) spectrum after upsampling x[n] by 
a factor of 2; (d) spectrum after upsampling x[n] by 2 and then downsampling 
by 9. 
w 
w 

Sec. 7.6 
7.6 SUMMARY 
Summary 
555 
sampling every 4th value of x[ n]. If the result of such sampling is decimated by a factor 
of 4, we obtain a sequence xb[n] whose spectrum is shown in Figure 7.38(b). Clearly, 
there is still no aliasing of the original spectrum. However, this spectrum is zero for 
87T/9 s lwl s 7T, which suggests there is room for further downsampling. 
Specifically, examining Figure 7.38(a) we see that if we could scale frequency 
by a factor of 9/2, the resulting spectrum would have nonzero values over the entire 
frequency interval from - 7r to 7T. However, since 9/2 is not an integer, we can't achieve 
this purely by downsampling. Rather we must first upsample x[n] by a factor of 2 and 
then downsample by a factor of9. In particular, the spectrum of the signal xu[n] obtained 
when x[n] is upsampled by a factor of 2, is displayed in Figure 7.38(c). When X11 [n] is 
then downsampled by a factor of 9, the spectrum of the resulting sequence X 11b[n] is as 
shown in Figure 7 .38( d). This combined result effectively corresponds to downsampling 
x[n] by a noninteger amount, 9/2. Assuming that x[n] represents unaliased samples of 
a continuous-time signal Xc(t), our interpolated and decimated sequence represents the 
maximum possible (aliasing-free) downsampling of Xc(t). 
In this chapter we have developed the concept of sampling, whereby a continuous-time 
or discrete-time signal is represented by a sequence of equally spaced samples. The con-
ditions under which the signal is exactly recoverable from the samples is embodied in 
the sampling theorem. For exact reconstruction, this theorem requires that the signal to be 
sampled be band limited and that the sampling frequency be greater than twice the high-
est frequency in the signal to be sampled. Under these conditions, exact reconstruction of 
the original signal is carried out by means of ideal lowpass filtering. The time-domain 
interpretation of this ideal reconstruction procedure is often referred to as ideal band-
limited interpolation. In practical implementations, the lowpass filter is approximated and 
the interpolation in the time domain is no longer exact. In some instances, simple inter-
polation procedures such as a zero-order hold or linear interpolation (a first-order hold) 
suffice. 
If a signal is undersampled (i.e., if the sampling frequency is less than that required 
by the sampling theorem), then the signal reconstructed by ideal band-limited interpolation 
will be related to the original signal through a form of distortion referred to as aliasing. 
In many instances, it is important to choose the sampling rate so as to avoid aliasing. 
However, there are a variety of important examples, such as the stroboscope, in which 
aliasing is exploited. 
Sampling has a number of important applications. One particularly significant set 
of applications relates to using sampling to process continuous-time signals with discrete-
time systems, by means of minicomputers, microprocessors, or any of a variety of devices 
specifically oriented toward discrete-time signal processing. 
The basic theory of sampling is similar for both continuous-time and discrete-
time signals. In the discrete-time case there is the closely related concept of decimation, 
whereby the decimated sequence is obtained by extracting values of the original sequence 
at equally spaced intervals. The difference between sampling and decimation lies in the 
fact that, for the sampled sequence, values of zero lie in between the sample values, 
whereas in the decimated sequence these zero values are discarded, thereby compressing 
the sequence in time. The inverse of decimation is interpolation. The ideas of decima-

556 
Sampling 
Chap. 7 
tion and interpolation arise in a variety of important practical applications of signals and 
systems, including communication systems, digital audio, high-definition television, and 
many other applications. 
Chapter 7 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining two sections contain problems belonging to 
the basic and advanced categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
7.1. A real-valued signal x(t) is known to be uniquely determined by its samples when 
the sampling frequency is w s = 10, 0001r. For what values of w is X (jw) guaranteed 
to be zero? 
7.2. A continuous-time signal x(t) is obtained at the output of an ideallowpass filter 
with cutoff frequency w c = 1, 0001r. If impulse-train sampling is performed on x(t), 
which of the following sampling periods would guarantee that x(t) can be recovered 
from its sampled version using an appropriate lowpass filter? 
(a) T = 0.5 X 10- 3 
(b) T = 2 X 10- 3 
(c) T = 10- 4 
7.3. The frequency which, under the sampling theorem, must be exceeded by the sam-
pling frequency is called the Nyquist rate. Determine the Nyquist rate corresponding 
to each of the following signals: 
(a) x(t) = 1 + cos(2,0001Tt) + sin(4,0001Tt) 
(b) x(t) = sin(4,000m) 
7TI 
(c) x(t) = ( sin(4,~07TI) t 
7.4. Let x(t) be a signal with Nyquist rate w0 . Determine the Nyquist rate for each of the 
following signals: 
(a) x(t) + x(t - 1) 
(b) d~~l) 
(c) x2(t) 
(d) x(t)coswot 
7.5. Let x(t) be a signal with Nyquist rate w0 . Also, let 
y(t) = x(t)p(t - 1), 

Chap. 7 
Problems 
557 
where 
00 
2 
p(t) = L o(t- nT), and T < ..!!.. 
n= - oo 
Wo 
Specify the constraints on the magnitude and phase of the frequency response of a 
filter that gives x(t) as its output when y(t) is the input. 
7.6. In the system shown in Figure P7.6, two functions of time, xi (t) and x2(t), are mul-
tiplied together, and the product w(t) is sampled by a periodic impulse train. xi (t) 
is band limited to wi, and x2(t) is band limited to w2 ; that is, 
Xi(jw) = 0, lwl ;::: Wi, 
X2(jw) = 0, lwl ;::: w2. 
Determine the ltUlXimum sampling interval T such that w(t) is recoverable 
from wp(t) through the use of an ideallowpass filter. 
x1(t)--:....,p 
x2(t) 
-
• X1(jw) rn 
p(t) = ~ B(t - nT) 
w~) • ~" --• • w, ~I 
Figure P7.6 
7.7. A signal x(t) undergoes a zero-order 'hold operation with an effective sampling pe-
riod T to produce a signal x0(t). Let xi (t) denote the result of a first-order hold 
operation on the samples of x(t); i.e., 
00 
xi (t) = L x(nT)hi (t - nT), 
n= - oo 
where hi (t) is the function shown in Figure P7 .7. Specify the frequency response of 
a filter that produces Xi (t) as its output when xo(t) is the input. 

558 
Sampling 
Chap. 7 
Figure P7.7 
7.8. Consider a real, odd, and periodic signal x(t) whose Fourier series representation 
may be expressed as 
5 (1 )k 
x(t) = L 2 sin(k'TT't). 
k=O 
Let x(t) represent the signal obtained by performing impulse-train sampling on x(t) 
using a sampling period ofT = 0.2. 
(a) Does aliasing occur when this impulse-train sampling is performed on x(t)? 
(b) If x(t) is passed through an ideallowpass filter with cutoff frequency 'TTIT and 
passband gain T, determine the Fourier series representation of the output signal 
g(t). 
7.9. Consider the signal 
which we wish to sample with a sampling frequency of Ws = 1507T to obtain a 
signal g(t) with Fourier transform G(jw ). Determine the maximum value of wo for 
which it is guaranteed that 
G(jw) = 75X(jw) for lwl :s; wo, 
where X(jw) is the Fourier transform of x(t). 
7.10. Determine whether each ofthe following statements is true or false: 
(a) The signal x(t) = u(t + To) - u(t - T0 ) can undergo impulse-train sampling 
without aliasing, provided that the sampling period T < 2T0 . 
(b) The signal x(t) with Fourier transform X(jw) = u(w + wo) -
u(w - wo) can 
undergo impulse-train sampling without aliasing, provided that the sampling 
period T < 'TT!wo. 
(c) The signal x(t) withFouriertransformX(jw) = u(w)- u(w -w0) can undergo 
impulse-train sampling without aliasing, provided that the sampling period T < 
2'TT!w0 . 
7.11. Let Xc(t) be a continuous-time signal whose Fourier transform has the property that 
Xc(Jw) = 0 for lwl ~ 2,0007T. A discrete-time signal 

Chap. 7 
Problems 
559 
is obtained. For each of the following constraints on the Fourier transform Xd(eiw) 
of xd[n], determine the corresponding constraint on Xc(jw ): 
(a) Xd(eiw) is real. 
(b) The maximum value of Xd(eiw) over all w is 1. 
(c) Xd(eiw) = 0 for 3; 
:5 lwl :5 'IT. 
(d) Xd(eiw) = Xd(ei<w - 71")). 
7.12. A discrete-time signal xd[n] has a Fourier transform Xd(eiw) with the property that 
Xd(eiw) = 0 for 37T/4 ::; lwl ::; 'IT. The signal is converted into a continuous-time 
signal · 
where T = 10- 3. Determine the values of w for which the Fourier transform Xc(jw) 
of Xc(t) is guaranteed to be zero. 
7.13. With reference to the filtering approach illustrated in Figure 7.24, assume that the 
sampling period used is T and the input Xc(t) is band limited, so that Xc(jw) = 0 for 
lwl ;:: 'IT IT. If the overall system has the property that Yc(t) = Xc(t-2T), determine 
the impulse response h[n] of the discrete-time filter in Figure 7 .24. 
7.14. Repeat the previous problem, except this time assume that 
7.15. Impulse-train sampling of x[n] is used to obtain 
00 
g[n] = L x[n]5[n- kN]. 
k =-00 
If X(eiw) = 0 for 37T/7 ::; lwl :s 'IT, determine the largest value for the sampling 
interval N which ensures that no aliasing takes place while sampling x[n]. 
7.16. ,The following facts are given about the signal x[n] and its Fourier transform: 
1. x[n] is real. 
2. X(eiw) # OforO < w <'IT. 
3. x[n]L~=-oo5[n- 2k] = 5[n]. 
Determine x[n]. You may find it useful to note that the signal (sin 2fn)/(7Tn) satisfies 
two of these conditions. 

x[n) 
560 
Sampling 
Chap. 7 
7.17. Consider an ideal discrete-time bandstop filter with impulse response h[ n] for which 
the frequency response in the interval - 7r ::;; w ::;; 7T is 
lwl :5 * 
and !wl 2: 
3.7 . 
elsewhere 
Determine the frequency response of the filter whose impulse response is h[2n]. 
7 .18. Suppose the impulse response of an ideal discrete-time lowpass filter with cutoff fre-
quency 7T/2 is interpolated (in accordance with Figure 7 .37) to obtain an upsampling 
by a factor of 2. What is the frequency response corresponding to this upsampled 
impulse response? 
7.19. Consider the system shown in Figure P7.19, with input x[n] and the correspond-
ing output y[n]. The zero-insertion system inserts two points with zero amplitude 
between each of the sequence values in x[ n]. The decimation is defined by 
y[n] = w[Sn], 
where w[n] is the input sequence for the decimation system. If the input is of the 
form 
sinw1n 
x[n] = _ __:._ 
7Tn 
determine the output y[ n] for the following values of w 1 : 
(a) w 1 ::;; 3; 
(b) Wt > 3; 
H(eiw) 
,..... 1-1 
w[n] 
Zero insertion 
Decimation 
- 7T 
-7T/5 
7T/5 
7T 
Figure P7. 19 
y[n] 
7.20. Two discrete-time systems S1 and S2 are proposed for implementing an ideal low-
pass filter with cutoff frequency 7T/4. System S1 is depicted in Figure P7.20(a). 
System S2 is depicted in Figure P7.20(b). In these figures, SA corresponds to a zero-
insertion system that inserts one zero after every input sample, while S 8 corresponds 
to a decimation system that extracts every second sample of its input. 
(a) Does the proposed system S1 correspond to the desired ideallowpass filter? 
(b) Does the proposed system S2 correspond to the desired ideallowpass filter? 

Chap. 7 
Problems 
561 
-x[n-1--~:l _ _ 
sA __ I 
~ ill 
Ss 
y[n] 
- 1T/8 0 1T/8 
(a) 
m 
Jh 
I 
' 
SA 
y[n] 
-x[n-]--•""'il.____ss _ _ 
- 1T/2 0 1r/2 
- 1T/2 0 1T/2 
(b) 
Figure P7.20 
BASIC PROBLEMS 
7.21. A signal x(t) with Fourier transform X(jw) undergoes impulse-train sampling to 
generate 
00 
xp(t) = :L, x(nT)o(t - nT) 
n= - oo 
where T = w-4 . For each of the following sets of constraints on x(t) and/or X(jw ), 
does the sampling theorem (see Section 7.1.1) guarantee that x(t) can be recovered 
exactly from Xp(t)? 
(a) X(jw) = 0 for lwl > 50001T 
(b) X(jw) = 0 for lwl > 150001T 
(c) CR.e{X(jw)} = 0 for lwl > 50001T 
(d) x(t) real and X(jw) = 0 for w > 50001T 
(e) x(t) real and X(jw) = 0 for w < -150001T 
(f) X(jw) * X(jw) = 0 for lwl > 150001T 
(g) IX(Jw )I = 0 for w > 50001T 
7.22. The signal y(t) is generated by convolving a band-limited signal x 1 (t) with another 
band-limited signal x2(t), that is, 
where 
y(t) = Xi (t) * X2(t) 
X,(jw) = 0 
X2(}w) = 0 
for lw I > 1 0001T 
for lw I > 20001T. 
Impulse-train sampling is performed on y(t) to obtain 

562 
Sampling 
Chap. 7 
+oo 
Yp(t) = L y(nT)5(t- nT). 
n= -oo 
Specify the range of values for the sampling period T which ensures that y(t) is 
recoverable from Yp(t). 
7.23. Shown in Figure P7.23 is a system in which the sampling signal is an impulse train 
with alternating sign. The Fourier transform of the input signal is as indicated in the 
figure. 
(a) For ~ < Trl(2w M ), sketch the Fourier transform of x p(t) and y(t). 
(b) For~ < Trl(2wM ), determine a system that will recover x(t) from Xp(t). 
(c) For~ < Tr!(2wM ), determine a system that will recover x(t) from y(t). 
(d) What is the maximum value of~ in relation to WM for which x(t) can be recov-
ered from either xp(t) or y(t)? 
p(t) 
x(t)--~ ,__x:;...P (_t)~ H(jw) ,...._......_ y(t) 
... t 
t 
l _J 
2~ 
X(jw) 
& 
H(jw) 
D 'i D 
31T w 
T 
Figure P7.23 
7.24. Shown in Figure P7.24 is a system in which the input signal is multiplied by a 
periodic square wave. The period of s(t) is T. The input signal is band limited with 
IX(jw)l = Oforlwl::::: WM. 

Chap. 7 
Problems 
563 
(a) For a = T/3, determine, in terms of WM, the maximum value ofT for which 
there is no aliasing among the replicas of X(jw) in W(jw ). 
(b) For a = T 14, determine, in terms of w M, the maximum value of T for which 
· there is no aliasing among the replicas of X(jw) in W(jw ). 
x(t) ----.{ x )---~ w(t) 
s(t) 
s(t) 
·Hr 
'l~n r 
U~UTU 
I 
Figure P7.24 
7 .25. In Figure P7 .25 is a sampler, followed by an ideallowpass filter, for reconstruction of 
x(t) from its samples Xp(t). From the sampling theorem, we know thatifws = 27T/T 
is greater than twice the highest frequency present in x(t) and we = ws/2, then the 
reconstructed signal xr(t) will exactly equal x(t). If this condition on the bandwidth 
of x(t) is violated, then Xr(t) will not equal x(t). We seek to show in this problem 
that if We = w 5/2, then for any choice ofT, Xr(t) and x(t) will always be equal at 
the sampling instants; that is, 
Xr(kT) = x(kT), k = 0, ± 1, ±2, .... 
p(t) = l 
8(t - nT) 
n = - oo 
x(t) ----l•~~ '' (t) 
H(jw) ill 
)------l~ x, (t) 
Figure P7 .25 
To obtain this result, consider eq. (7.11), which expresses Xr(t) in terms of the 
samples of x(t): 
( ) = ~ ( T)TWe sin[we(t - nT)] 
Xr t 
L 
X n 
( 
T) 
. 
n=-co 
7T 
Wet-n 
With We = w 5/2, this becomes 
"' 
sin [ f(t-nT)] 
Xr(t) = L x(nT) 
7T 
• 
n= - co 
-(t-nT) 
T 
(P7.25-1) 

564 
Sampling 
Chap. 7 
By considering the values of a for which [sin(a)]/a = 0, show from eq. 
(P7.25- 1) that, without any restrictions on x(t), x,.(kT) = x(kT) for any integer 
value of k. 
7.26. The sampling theorem, as we have derived it, states that a signal x(t) must be sam-
pled at a rate greater than its bandwidth (or equivalently, a rate greater than twice its 
highest frequency). This implies that if x(t) has a spectrum as indicated in Figure 
P7.26(a) then x(t) must be sampled at a rate greater than 2w2. However, since the 
signal has most of its energy concentrated in a narrow band, it would seem reason-
.able to expect that a sampling rate lower than twice the highest frequency could be 
used. A signal whose energy is concentrated in a frequency band is often referred to 
as a bandpass signal. There are a variety of techniques for sampling such signals, 
generally referred to as bandpass-sampling techniques. 
X(jw) 
'i 
w 
(a) 
+ oo 
p(t) =};&(t- nT) 
x(t) ---1•~J" '~ (t) 
• B--'• (t) 
p(t) 
t t 
1 1 t t 
T 
H(jw) 
·t 
(b) 
Figure P7 .26 

Chap. 7 
Problems 
565 
To examine the possibility of sampling a bandpass signal as a rate less than 
the total bandwidth, consider the system shown in Figure P7 .26(b ). Assuming that 
w1 > w2 -
WJ. find the maximum value ofT and the values of the constants A, Wa, 
and wb such that Xr(t) = x(t). 
7.27. In Problem 7.26, we considered one procedure for bandpass sampling and recon-
struction. Another procedure, used when x(t) is real, consists of multiplying x(t) by a 
complex-exponential and then sampling the product. The sampling system is shown 
in Figure P7.27(a). With x(t) real and with X(jw) nonzero only for w 1 < lwl < w2, 
the frequency is chosen to be w0 = (1/2)(w 1 + w2), and the lowpass filter H 1 (jw) 
has cutoff frequency (1/2)(w2 -
wJ). 
x(t) 
(a) For X(jw) as shown in Figure P7.27(b), sketch Xp(jw ). 
(b) Determine the maximum sampling period T such that x(t) is recoverable from 
Xp(t). 
(c) Determine a system to recover x(t) from xp(t). 
X 
H(jw) 
1--~ 
X 
Xp(t) 
t 
t 
e - iwot 
p(t) = I &(t-nT) 
(a) 
n = - oo 
X(jw) 
;1 'i 
- w2 -w1 
(b) 
Figure P7.27 
7.28. Figure P7.28(a) shows a system that converts a continuous-time signal to a discrete-
time signal. The input x(t) is periodic with a period of 0.1 second. The Fourier series 
coefficients of x(t) are 
(
1 ~kl 
ak = 2} , - oo < k < +oo. 
The lowpass filter H(jw) has the frequency response shown in Figurt: P7.28(b). The 
sampling period T = 5 x w-3 second. 
(a) Show that x[n] is a periodic sequence, and determine its period. 
(b) Determine the Fourier series coefficients of x[n]. 

Xc (t) 
X 
566 
Sampling 
Chap. 7 
Conversion 
x(t) 
Lowpass 
Xc(t) 
of an 
filter 
X 
impulse train 
x[n] = Xc (nT) 
H(jw) 
to a 
sequence 
p(t) = ~ 8(t - nT) 
n = - oo 
(a) 
H(jw) 
11 
I 
- 2057T 
2057T 
w 
(b) 
Figure P7 .28 
7 .29. Figure P7 .29( a) shows the overall system for filtering a continuous-time signal using 
a discrete-time filter. If Xc(jw) and H(ejw) are as shown in Figure P7.29(b), with 
liT = 20kHz, sketch Xp(jw ), X(ejw), Y(ejw), Yp(jw ), and Yc(jw ). 
H(jw) 
Xp (t) 
Conversion x[n] = Xc (nT) 
h [n] 
y[n] = Yc (nT) 
Conversion 
Yp (t) til ~ 
to a 
H(eiw) 
to an 
sequence 
impuise train 
- '!TIT 
'IT IT 
p(t) = ~ 8(t - nT) 
n = - oo 
(a) 
Xc(jw) 
H(eiw) 
;h 
1 
I 
I 
-'IT X104 
'IT X104 
w 
- :!!: 
1T 
4 
4 
w 
(b) 
Figure P7 .29 

Chap. 7 
Problems 
567 
7 .30. Figure P7 .30 shows a system consisting of a continuous-time LTI system followed 
by a sampler, conversion to a sequence, and an LTI discrete-time system. The 
continuous-time LTI system is causal and satisfies the linear, constant-coefficient 
differential equation 
dyc(t) 
~ 
+ Yc(t) = Xc(t). 
The input Xc(t) is a unit impulse O(t). 
(a) Determine Yc(t). 
(b) Determine the frequency response H(eiw) and the impulse response h[n] such 
that w[n] = o[n]. 
Xc(t)--~ 
(t) 
Conversion of 
[ I 
Yc 
t::\.___,__ impulse train 
Y n 
~----·~~ 
l 
...:~.~ 
LTI 
p(t) = L S(t-nT) 
n = - oc 
Figure P7.30 
LTI 
H(ei"') 
w[n] 
7.31. Shown in Figure P7.31 is a system that processes continuous-time signals using a 
digital filter h[n] that is linear and causal with difference equation 
1 
y[n] = 2 y[n - 1] + x[n]. 
For input signals that are band limited such that Xc(jw) = 0 for lw I > TTIT, the 
system in the figure is equivalent to a continuous-time LTI system. 
Determine the frequency response Hc(jw) of the equivalent overall system 
with input Xc(t) and output Yc(t). 
x (t) 
Conversion of 
x[n) 
x (t) ____..,P impulse train 
c 
to a 
sequence 
p(t) = L S(t-nT) 
n = - oo 
y[n) 
h[n) 
Figure P7.31 
Conversion of 
sequence 
to a 
impulse train 
y(t) 
Ideal lowpass 
filter cutoff 
frenquency 
'TTIT 
7.32. A signal x[n] has a Fourier transform X(eiw) that is zero for (7T/4) :s lwl :s 7T. 
Another signal 

568 
Sampling 
Chap. 7 
00 
g[n] = x[n] .L o[n- 1 - 4k] 
k= -oo 
is generated. Specify the frequency response H ( eiw) of a lowpass filter that produces 
x[n] as output when g[n] is the input. 
7.33. A signal x[n] with Fourier transform X(eiw) has the property that 
(x[n] ktoo o[n- 3k] )* ei~!n) = x[n]. 
For what values of w is it guaranteed that X(eiw) = 0? 
7.34. A real-valued discrete-time signal x[n] has a Fourier transform X(eiw) that is zero 
for 37T/14 :5 lwl :5 71'. The nonzero portion of the Fourier transform of one period 
of X(eiw) can be made to occupy the region lwl < 7T by first performing upsampling 
by a factor of L and then performing downsampling by a factor of M . Specify the 
values of L and M. 
7.35. Consider a discrete-time sequence x[n] from which we form two new sequences, 
xp[n] and xd[n], where xp[n] corresponds to sampling x[n] with a sampling period 
of 2 and xd [ n] corresponds to decimating x[ n] by a factor of 2, so that 
[ ] _ { x[n], 
n = 0, :±:2, :±:4, . .. 
Xp n -
0, 
n = :±:1, ±3, ... 
and 
xd[n] = x[2n]. 
(a) If x[n] is as illustrated in Figure P7.35(a), sketch the sequences Xp[n] and xd[n]. 
(b) If X(eiw) is as shown in Figure P7.35(b), sketch Xp(eiw) and Xd(eiw). 
I I I I I I I I I I 
x[n] 
• • ' I I 
I ' . 
0 
n 
(a) 
X(ei"') 
' ~ 
~ 
~ 
0 
3'!T 
5'!T 
4 
4 
2'1T 
(b) 
Figure P7.35 
ADVANCED PROBLEMS 
7.36 Let x(t) be a band-limited signal such that X(jw) = 0 for lwl ;::::: ¥. 
11 'IT 
4 
(a) If x(t) is sampled using a sampling period T, determine an interpolating function 

Chap. 7 
Problems 
569 
g(t) such that 
dx(t) = "' x(nT)g(t - nT). 
dt 
L 
n= - oo 
(b) Is the function g(t) unique? 
7.37. A signal limited in bandwidth to lwl < W can be recovered from nonuniformly 
spaced samples as long as the average sample density is 2(W/27T) samples per sec-
ond. This problem illustrates a particular example of nonuniform sampling. Assume 
that in Figure P7.37(a): 
1. x(t) is band limited; X(jw) = 0, !wl > W. 
2. p(t) is a nonuniformly spaced periodic pulse train, as shown in Figure P7.37(b). 
3. f(t) is a periodic waveform with period T = 271"/W. Since f(t) multiplies an 
impulse train, only its values f(O) = a and f(!l) = batt = 0 and t = .:l, re-
spectively, are significant. 
4. H 1 (jw) is a 90° phase shifter; that is, 
Sampled 
x(t) 
x(t) --~ 
x 1--..;..;--t 
t 
p(t) 
t t 
Ht(jW) = { j, . 
- ], 
f(t) 
l ~~ 
w > 0 
w <0" 
Y1(t) ~ 
lY2(t) 
0----1 
H2(jw) 
Y3 (t) 
(a) 
p(t) 
t~ 
1 
1 
~--~-~ 
t t 
t 
0 
(b) 
Figure P7.37 
t----;•~ z(t) 

570 
5. H2(jw) is an ideallowpass filter; that is, 
{
K, 
Hz(jw) = 
K *, 
0, 
where K is a (possibly complex) constant. 
O< w<W 
-W < w<O, 
lwi > W 
(a) Find the Fourier transforms of p(t), y, (t), yz(t), and y3(t). 
Sampling 
Chap. 7 
(b) Specify the values of a, b, and K as functions of .:l such that z(t) = x(t) for any 
band-limited x(t) and any .:l such that 0 < .:l < 1riW. 
7 .38. It is frequently necessary to display on an oscilloscope screen waveforms having 
very short time structures- for example, on the scale of thousandths of a nanosec-
ond. Since the rise time of the fastest oscilloscope is longer than this, such displays 
cannot be achieved directly. If however, the waveform is periodic, the desired result 
can be obtained indirectly by using an instrument called a sampling oscilloscope. 
The idea, as shown in Figure P7 .38(a), is to sample the fast waveform x(t) once 
each period, but at successively later points in successive periods. The increment 
.:l should be an appropriately chosen sampling interval in relation to the bandwidth 
of x(t). If the resulting impulse train is then passed through an appropriate interpolat-
x(t) 
MMJV\1\;, 
I 
I 
f+-i-T-
1 
I 
I 
I 
I 
1 
I 
p(t) 
I 
I 
I 
t t bm-( i i t 
I 
I 
1 
I 
I 
I 
I 
t 
I 
I 
I 
I 
I 
I 
I 
I 
~y(t) 
:1 
:1 
:1 
~ 
L_I 
t-'--d:::::;Y, 
(a) 
x(t) ---~~ x )------;~ 
Periodic with 
period T; 
I x Ow) I = o 
for I w I > Wx 
"' 
p(t) = l &[t- n(T +A)] 
H(jw) 
)-----~·~ y(t) 
1 
H(jw) = 
2(T + A) 
{
1.lwl< --
0, elsewhere 
(b) 
Figure P7 .38 

Chap. 7 
Problems 
571 
ing lowpass filter, the output y(t) will be proportional to the original fast waveform 
slowed down or stretched out in time [i.e., y(t) is proportional to x(at), where a < 1]. 
For x(t) = A + B cos[(27TIT)t + 0], find a range of values of~ such that y(t) 
in Figure P7.38(b) is proportional to x(at) with a < 1. Also, determine the value of 
a in terms ofT and~-
7.39 A signal Xp(t) is obtained through impule-train sampling of a sinusoidal signal x(t) 
whose frequency is equal to half the sampling frequency w s. 
x(t) = cos(~' t + <P) 
and 
+co 
xp(t) = ~ 
x(nT)8(t- nT) 
n= -co 
where T = 27TIWs. 
(a) Find g(t) such that 
x(t) = cos(</J)cos(~s t)+ g(t). 
(b) Show that 
g(nT) = 0 
for n = 0, ± 1, ±2, · · · 
(c) Using the results of the previous two parts, show that if xp(t) is applied as the 
input to an ideallowpass filter with cutoff frequency ws/2, the resulting output 
is 
y(t) = cos(</J)cos(~s t). 
7.40. Consider a disc on which four cycles of a sinusoid are painted. The disc is rotated at 
approximately 15 revolutions per second, so that the sinusoid, when viewed through 
a narrow slit, has a frequency of 60 Hz. 
The arrangement is indicated in Figure P7.40. Let v(t) denote the position of 
the line seen through the slit. Then 
v(t) = A cos(wot + <P ), wo = 1207T. 
Position of line varies sinusoidally 
at 60 cycles per second 
...----...,.._,~ ............. ----, 
/
---
......_ 
/ 
/ 
, 
....._ 
Disk rotating at 
/ 
/ 
\ 
"'\ 
15 rps 
//--\ 
J.-- .... , \ 
I 
\ 
\ 
I 
\ 
I 
\ 
, 
_
_ 
A 
, _
_ 
/ 
I 
\ 
( 
) 
I 
\ 
\ 
I 
/ 
" -...... , __ 
/ 
/ 
....._ 
___ __.... 
Figure P7.40 

572 
Sampling 
Chap. 7 
For notational convenience, we will normalize v(t) so that A = 1. At 60Hz, the eye 
is not able to follow v(t), and we will assume that this effect can be explained by 
modeling the eye as an ideallowpass filter with cutoff frequency 20 Hz. 
Sampling of the sinusoid can be accomplished by illuminating the disc with a 
strobe light. Thus, the illumination can be represented by an impulse train; that is, 
+ oo 
i(t) = ~ 
l>(t - kT), 
k= - oo 
where liT is the strobe frequency in hertz. The resulting sampled signal is the prod-
uct r(t) = v(t)i(t). Let R(jw ), V(jw ), and /(jw) denote the Fourier transforms of 
r(t), v(t), and i(t), respectively. 
· 
(a) Sketch V(jw ), indicating clearly the effect of the parameters cp and wo. 
(b) Sketch /(jw), indicating the effect ofT. 
(c) According to the sampling theorem, there is a maximum value forT in terms 
of wo such that v(t) can be recovered from r(t) using a lowpass filter. Determine 
this value ofT and the cutoff frequency of the lowpass filter. Sketch R(jw) when 
T is slightly less than the maximum value. 
If the sampling period Tis made greater than the value determined in part 
(c), aliasing of the spectrum occurs. As a result of this aliasing, we perceive a 
lower frequency sinusoid. 
(d) Suppose that 27T'IT = wo + 207T'. Sketch R(jw) for lwl < 407T'. Denote by Va(t) 
the apparent position of the line as we perceive it. Assuming that the eye be-
haves as an ideallowpass filter with 20-Hz cutoff and unity gain, express va(t) 
in the form 
Va(t) = Aa cos(wa + c/Ja), 
where Aa is the apparent amplitude, Wa the apparent frequency, and c/Ja the 
apparent phase of va(t). 
(e) Repeat part (d) for 27T'IT = w0 - 207T'. 
7 .41. In many practical situations a signal is recorded in the presence of an echo, which we 
would like to remove by appropriate processing. For example, in Figure P7.41(a), 
we illustrate a system in which a receiver simultaneously receives a signal x(t) and 
an echo represented by an attenuated delayed replication of x(t). Thus, the receiver 
output is s(t) = x(t) + ax(t- T0 ), where Ia I < 1. This output is to be processed to 
recover x(t) by first converting to a sequence and then using an appropriate digital 
filter h[n], as indicated in Figure P7.4l(b). 
Assume that x(t) is band limited [i.e., X(jw) = 0 for lwl > WM] and that 
ial < 1. 
(a) If To < 'TT'IwM, and the sampling period is taken to be equal to To (i.e., T = To), 
determine the difference equation for the digital filter h[n] such that Yc(t) is 
proportional to x(t). 
(b) With the assumptions of part (a), specify the gain A of the ideallowpass filter 
such that Yc(t) = x(t). 
(c) Now suppose that 'TT'IwM < To< 27T'IWM . Determine a choice for the sampling 
period T, the lowpass filter gain A, and the frequency response for the digital 
filter h[n] such that Yc(t) is proportional to x(t). 

Chap. 7 
Problems 
573 
M////////////// 
~~t-T0) 
(a) ~ 
Receiver output 
s(t) = x(t) + a x(t-T0) 
Ideal lowpass 
filter 
Sc(t) = x(t) +ax(t- T0) r-----, 
---L X 
Sp(t) 
Conversion of 
impulse train 
to a 
sequence 
s[n] 
h[n] 
y[n] 
Conversion of 
sequence 
Yp(t) 
to 
impulse train 
p(t) =I S(t - kT) 
k = - co 
(b) 
Figure P7 .41 
7 .42. Consider a band-limited signal Xc(t) that is sampled at a rate higher than the Nyquist 
rate. The samples, spaced T seconds apart, are then c.onverted to a sequence x[n], 
as indicated in Figure P7.42. 
p(t) = I &(t - nT) 
n = - oo 
xp(t) 
Conversion of 
xc(t) -----1 x )---__,~ impulse train )-----!~ x[n] = Xc (nD 
to sequence 
Figure P7 .42 
Determine the relation between the energy Ed of the sequence, the energy Ec 
of the original signal, and the sampling interval T. The energy of a sequence x[ n] is 
defined as 
n=-oo 
and the energy in a continuous-time function Xc(t) is defined as 
J 
+oo 
Ec = 
- oo lxc(tW dt. 

574 
Sampling 
Chap. 7 
7.43. Figure P7.43(a) depicts a system for which the input and output are discrete-time 
signals. The discrete-time input x[n] is converted to a continuous-time impulse train 
xp(t). The continuous-time signal Xp(t) is then filtered by an LTI system to produce 
the output Yc(t), which is then converted to the discrete-time signal y[n]. The LTI 
system with input Xc(t) and output Yc(t) is causal and is characterized by the linear 
constant -coefficient differential equation 
d 2yc(t) 
4 dyc(t) 
3 ( ) _ 
( ) 
~ 
+ dt + Yc t -
Xc t . 
The overall system is equivalent to a causal discrete-time LTI system, as indicated 
in Figure P7 .43(b ). 
Determine the frequency response H(ejw) and the unit sample response h[n] 
of the equivalent LTI system. 
~ S(t-'nT) 
· n = - co 
HGw) 
x[n] 
Conversion 
xp(t) Ih 
h(t) 
Conversion 
to a 
sequence 
y[n] 
~ 
toan 
impulse train 
- '!1'/T 
'!1'/T 
+ - oo 
xp(t) = ~ x[n] S(t - nT) 
n =-co 
+oo 
Yp(t) = Yc(t) ~ S(t - nT) 
n =- oo 
(a) 
y[n] = Yc(nT) 
h[n]; H(ei"') 
x[n] 
equivalent 
y[n] 
LTI system 
(b) 
Figure P7.43 
7 .44. Suppose we wish to design a continuous-time generator that is capable of producing 
sinusoidal signals at any frequency satisfying 
where w 1 and w 2 are given positive numbers. 
Our design is to take the following form: We have stored a discrete-time cosine 
wave of period N; that is, we have stored x[O], . . . , x[N - 1], where 

x[O] 
• 
• 
• 
x[N - 1] 
Chap. 7 
Problems 
575 
• 
(27Tk) 
x[k] = cos N . 
Every T seconds we output an impulse weighted by a value of x[k], where we pro-
ceed through the values of k = 0, 1, ... , N - 1 in a cyclic fashion. That is, 
· 
yp<kT) = x(k modulo N), 
or equivalently, 
(27Tk) 
Yp(kT) = cos N 
' 
and 
+ oo 
(2 k) 
yp(t) = k~oo COS ~ 8(t - kT). 
(a) Show that by adjusting T, we can adjust the frequency of the cosine signal being 
sampled. That is, show that 
+ oo 
yp(t) = (coswot) L 8(t- kT), 
k = - oo 
where w0 = 27T/ NT. Determine a range of values for T such that yp<t) can rep-
resent samples of a cosine signal with a frequency that is variable over the full 
range 
(b) Sketch Yp(Jw). 
The overall system for generating a continuous-time sinusoid is depicted 
in Figure P7.44(a). H(jw) is an ideallowpass filter with unity gain in its pass-
band; that is, 
H( 'w) = { 1, 
lwl < ~ c • 
1 
0, 
otherwtse 
~I 
H(jw) 
• 
y(t) 
y(t) 
·I 
G(jw) 
1---~• cos wt 
(a) 
(b) 
Figure P7 .44 

+oo 
576 
Sampling 
Chap. 7 
The parameter W e is to be determined so that y(t) is a continuous-time cosine 
signal in the desired frequency band. 
(c) Consider any value of Tin the range determined in part (a). Determine the 
minimum value of Nand some value for W e such that y(t) is a cosine signal in 
the range w, ::5 w ::5 w2. 
(d) The amplitude of y(t) will vary, depending upon the value of w chosen between 
w 1 and w 2. Thus, we must design a system G(jw) that normalizes the signal as 
shown in Figure P7.44(b). Find such a G(jw). 
7 .45. In the system shown in Figure P7 .45, the input Xe(t) is band limited with Xe(jw) = 
0, jwj > 21T X 104 . The digital filter h[n] is described by the input-output relation 
HOw) 
to a 
J±L 
h[n) 
y[n] 
Conversion 
Yp(t) 
to an 
impulse train 
Yc(t) 
Conversion 
x[n) = xc(nl) 
sequence 
_ 1!, 
11' 
T 
T 
p(t) = l8(t-nT) 
n = - oo 
Figure P7.45 
n 
y[n] = T L x[k]. 
(P7.45-1) 
k = -00 
(a) What is the maximum value of T allowed if aliasing is to be avoided in the 
transformation from Xe(t) to Xp(t). 
(b) With the discrete-time LTI system specified through eq. (P7.45-1), determine 
its impulse response h[n]. 
(c) Determine whether there is any value ofT for which 
lim y[n] = limJ
1 
Xe(T)dT. 
n ~ oo 
t-+oo 
_ 00 
(P7.45-2) 
If so, determine the maximum value. If not, explain and specify how T would 
be chosen so that the equality in eq. (P7.45-2) is best approximated. (Think 
carefully about thi~ part; it is easy to jump to the wrong conclusion!) 
7.46 A signal x[n] is sampled in discrete time as shown in Figure P7.46. hr[n] is an ideal 
lowpass filter with frequency response 
lwl < N 
N < lwl < 1T 
From eqs. (7.46) and (7.47), the filter output is expressible as 
x,[n] = k:t;oo x[kN]h,[n - kN] = k:t;oo x[kN]N:e si:~~(~ ~~~) 

Chap. 7 
-Problems 
577 
x[n] 
h,[n] 
x,[n] 
+oo 
p[n] = l8(n-kN) 
k = - oo 
Figure P7 .46 
where w e = 27T/N. Show that independent of whether the sequence x[n] is sam-
pled above or below the Nyquist rate, x,.[mN] = x[mN], where m is any positive or 
negative integer. 
7.47. Suppose x[n] has a Fourier transform that is zero for 7T/3 ~ lwl ~ 7T. Show that 
_ 
oo 
(sin(J(n - 3k))) 
x[n] - k~oo x[3k] 
J(n - 3k) 
. 
7.48. If x[n] = cos(~n. +cf>o) withO ~ cf>o < 27T andg[n] = x[n].L ~= - ooo[n-4k], what 
additional constraints must be imposed on cf>o to ensure that 
(
sin '!!.n) 
g[n] * 
~~ 
= x[n]? 
7.49. As discussed in Section 7.5 and illustrated in Figure 7.37, the procedure for interpo-
lation or upsampling by an integer factor N can be thought of as the cascade of two 
operations. The first operation, involving system A, corresponds to inserting N - 1 
zero-sequence values between each sequence value of x[n], so that 
n = 0, ±N, ±2N, ... 
otherwise 
For exact band-limited interpolation, H(eiw) is an ideallowpass filter. 
(a) Determine whether or not system A is linear. 
(b) Determine whether or not system A is time invariant. 
(c) For Xd(eiw) as sketched in Figure P7.49 and with N = 3, sketch Xp(eiw). 
(d) For N = 3, Xd(eiw) as in Figure P7.49, and H(eiw) appropriately chosen for 
exact band-limited interpolation, sketch X(eiw). 
w 
Figure P7 .49 

578 
Sampling 
Chap. 7 
7 .50. In this problem, we consider the discrete-time counterparts of the zero-order hold and 
first -order hold, which were discussed for continuous time in Sections 7 .1.2 and 7 .2. 
Let x[n] be a sequence to which discrete-time sampling, as illustrated in Fig-
ure 7.31, has been applied. Suppose the conditions of the discrete-time sampling 
theorem are satisfied; that is, Ws > 2wM, where Ws is the sampling frequency and 
X(ejw) = 0, WM < lwl :::;; 7T. The original signal x[n] is then exactly recoverable 
from xp[n] by ideal lowpass filtering, which, as discussed in Section 7.5, corre-
sponds to band-limited interpolation. 
The zero-order hold represents an approximate interpolation whereby every 
sample value is repeated (or held) N - 1' successive times, as illustrated in Figure 
P7.50(a) for the case of N = 3. The first-order hold represents a linear interpolation 
between samples, as illustrated in the same figure. 
I I I I I I I I I I I I I I I I I I I 
x[n] 
n 
I . . I . . I . . I . . I . . I . . I 
n 
rn-fiJ}rrnrUJUU-:·'"~
0
" 
rf1Thnn11111Iln 
(a) 
n 
xdn] 
FOH 
n 
ZOH 
xp[n)~x0[n) 
(b) 
x0[n]~x[n) 
(c) 
FOH 
xp[n]~x1 [n] 
(d) 
Figure P7.50 

Chap. 7 
Problems 
579 
(a) The zero-order hold can be represented as an interpolation in the form of eq. 
(7.47) or, equivalently, the system in Figure P7.50(b). Determine and sketch 
ho[n] for the general case of a sampling period N. 
(b) x[n] can be exactly recovered from the zero-order-hold sequence x0 [n] using an 
appropriate LTI filter H(eiw), as indicated in Figure P7.50(c). Determine and 
sketch H(eiw). 
(c) The first-order-hold (linear interpolation) can be represented as an interpolation 
in the form of eq. (7.47) or, equivalently, the system in Figure P7.50(d). Deter-
mine and sketch h1 [n] for the general case of a sampling period N. 
(d) x[n] can be exactly recovered from the first-order-hold sequence x 1 [n] using an 
appropriate LTI filter with frequency response H(eiw). Determine and sketch 
H(eiw). 
7.51. As shown in Figure 7.37 and discussed in Section 7.5.2, the procedure for inter-
polation or upsampling by an integer factor N can be thought of as a cascade of 
two operations. For exact band-limited interpolation, the filter H(eiw) in Figure 
7.37 is an ideallowpass filter. In any specific application, it would be necessary 
to implement an approximate lowpass filter. In this problem, we explore some use-
ful constraints that are often imposed on the design of these approximate lowpass 
filters. 
(a) Suppose that H(eiw) is approximated by a zero-phase FIR filter. The filter is 
to be designed with the constraint that the original sequence values xd[n] get 
reproduced exactly; that is, 
x[n] = Xd [i]. n = 0, ±L, ±2L, .... 
(P7.51-l) 
This guarantees that, even though the interpolation between the original se-
quence values may not be exact, the original values are reproduced exactly in 
the interpolation. Determine the constraint on the impulse response h[n] of the 
lowpass filter which guarantees that eq. (P7.51-1) will hold exactly for any se-
quence xd[n]. 
(b) Now suppose that the interpolation is to be carried out with a linear-phase, 
causal, symmetric FIR filter of length N; that is . 
h[n] = 0, n < 0, n > N - 1, 
(P7.51-2) 
(P7.51- 3) 
where HR(eiw) is real. The filter is to be designed with the constraint that the 
original sequence values xd [ n] get reproduced exactly, but with an integer delay 
a, where a is the negative of the slope of the phase of H(eiw); that is, 
[n- a] 
x[n] = xd -L- , n- a = 0, ±L, ±2L, ... 
(P7.51-4) 
Determine whether this imposes any constraint on whether the filter length N 
is odd or even. 

580 
Sampling 
Chap. 7 
(c) Again, suppose that the interpolation is to be carried out with a linear-phase, 
causal, symmetric FIR filter, so that 
H(ejw) = HR(ejw)e- jf3w, 
where HR(ejw) is real. The filter is to be designed with the constraint that the 
original sequence values xd[n] get reproduced exactly, but with a delay M that 
is not necessarily equal to the slope of the phase; that is, 
[ n- a] 
x[n] = xd - L-
, n - M = 0, ±L, ± 2L, .... 
Determine whether this imposes any constraint on whether the filter length N is 
odd or even. 
7.52 In this problem we develop the dual to the time-domain sampling theorem, whereby 
a time-limited signal can be reconstructed from frequency-domain samples. To de-
velop this result, consider the frequency-domain sampling operation in Figure P7 .52. 
-
+oo 
X(jw) --~ 
X )--__,~ X(jw) = X(jw)P(jw) = ~ XOkwo) l>(w- kwo) 
k = -oo 
+oo 
P(jw) = ~ 8(w-kw0) 
k =-co 
X(jw) 
~ 
w 
P(jw) 
t t t t t t t t t 
0 
w0 
2w0 
w 
w 
Figure P7 .52 

Chap. 7 
Problems 
581 
(a) Show that 
i(t) = x(t) * p(t) 
where i(t), x(t), and p(t) are the inverse Fourier transforms of X(jw ), X(jw ), 
and P(jw ), respectively. 
(b) Assuming that x(t) is time-limited so that x(t) = 0 for ltl ;:;:: ..!!... , show that x(t) 
W o 
can be obtained from i(t) through a "low-time windowing" operation. That is, 
x(t) = i(t)w(t) 
where 
( 
wo, 
w(t) = 
O, 
jtj :5 ..!!... 
wo 
ltl > -
..!!... 
wo 
(c) Show that x(t) is not recoverable from i(t) if x(t) is not constrained to be zero 
for jtj ;:;:: ..!!... . 
wo 

8 
CoMMUNICATION SYSTEMS 
8.0 INTRODUCTION 
582 
Communication systems play a key role in our modem world in transmitting information 
between people, systems, and computers. In general terms, in all communication systems 
the information at the source is first processed by a transmitter or modulator to change it 
into a form suitable for transmission over the communication channel. At the receiver, the 
signal is then recovered through appropriate processing. This processing is required for a 
variety of reasons. In particular, quite typically, any specific communication channel has 
associated with it a frequency range over which it is best suited for transmitting a signal 
and outside of which communication is severely degraded or impossible. For example, 
the atmosphere will rapidly attenuate signals in the audible frequency range (1 0 Hz to 20 
kHz), whereas it will propagate signals at a higher frequency range over longer distances. 
Thus, in transmitting audio signals such as speech or music over a communication channel 
that relies on propagation through the atmosphere, the transmitter first embeds the signal 
through an appropriate process into another, higher frequency signal. 
Many of the concepts and techniques we have developed in the earlier chapters of 
this text play a central role in the analysis and design of communication systems. As with 
any concept that is closely tied to a wide variety of important applications, there are a large 
number of detailed issues to be considered, and, as indicated in the bibliography, there are 
many excellent texts on the subject. While a full and detailed analysis of communication 
systems is well beyond the scope of our discussions here, with the background of the 
previous chapters we are now in a position to introduce some of the basic principles and 
issues encountered in the design and analysis of these systems. 
The general process of embedding an information -bearing signal into a second 
signal is typically referred to as modulation. Extracting the information -bearing signal 

Sec. 8.1 
Complex Exponential and Sinusoidal Amplitude Modulation 
583 
is known as demodulation. As we will see, modulation techniques not only allow us to 
embed information into signals that can be transmitted effectively, but also make possible 
the simultaneous transmission of more than one signal with overlapping spectra over the 
same channel, through a concept referred to as multiplexing. · 
There are a wide variety of modulation methods used in practice, and in this chapter 
we examine several of the most important of these. One large class of modulation meth-
ods relies on the concept of amplitude modulation or AM in which the signal we wish to 
transmit is used to modulate the amplitude of another signal. A very common form of am-
plitude modulation is sinusoidal amplitude modulation, which we explore in some detail 
in Sections 8.1-8.4 together with the related concepts of frequency-division multiplexing. 
Another important class of AM systems involves the modulation of the amplitude of a 
pulsed signal, and in Sections 8.5 and 8.6 we examine this form of modulation as well as 
the concept of time-division multiplexing. In Section 8. 7 we then examine a different form 
of modulation, namely sinusoidal frequency modulation in which the information -bearing 
signal is used to vary the frequency of a sinusoidal signal. 
· 
All of the discussion up through Section 8.7 focuses attention on continuous-time 
signals, since most transmission media, such as the atmosphere, are best thought of as 
continuous-time phenomena. Nevertheless, not only is it possible to develop analogous 
techniques for discrete-time signals, but it is of considerable practical importance to con-
sider modulation concepts involving such signals, and in Section 8.8 we examine some of 
the basic ideas behind the communication of discrete-time signals. 
8. 1 COMPLEX EXPONENTIAL AND SINUSOIDAL AMPLITUDE MODULATION 
Many communication systems rely on the concept of sinusoidal amplitude modulation, in 
which a complex exponential or sinusoidal signal c(t) has its amplitude multiplied (mod-
ulated) by the information-bearing signal x(t). The signal x(t) is typically referred to as 
the modulating signal and the signal c(t) as the carrier signal. The modulated signal y(t) 
is then the product of these two signals: 
y(t) = x(t)c(t) 
As we discussed in Section 8.0, an important objective in modulation is to produce a 
signal whose frequency range is suitable for transmission over the communication channel 
to be used. In telephone transmission systems, for example, long-distance transmission is 
often accomplished over microwave or satellite links. The individual voice signals are 
in the frequency range 200 Hz to 4 kHz, whereas a microwave link requires signals in 
the range 300 megahertz (MHz) to 300 gigahertz (GHz), and communication satellite 
links operate in the frequency range from a few hundred MHz to over 40 GHz. Thus, 
for transmission over these channels, the information in a voice signal must be shifted 
into these higher ranges of frequency. As we will see in this section, sinusoidal amplitude 
modulation achieves such a shift in frequency in a very simple manner. 
8. 1. 1 Amplitude Modulation with a Complex Exponential Carrier 
There are two common forms of sinusoidal amplitude modulation, one in which the carrier 
signal is a complex exponential of the form 
(8.1) 

584 
Communication Systems 
Chap. 8 
and the second in which the carrier signal is sinusoidal and of the form 
c(t) = cos(wet + Oe). 
(8.2) 
In both cases, the frequency We is referred to as the carrier frequency. Let us consider first 
the case of a complex exponential carrier, and for convenience, let us choose (J e = 0, so 
that the modulated signal is 
(8.3) 
From the multiplication property (Section 4.5), and with X(jw ), Y(jw ), and C(jw) 
denoting the Fourier transforms of x(t), y(t), and c(t), respectively, 
} f+ x 
Y(jw) = 2
7T _, X(j8)C(j(w- 8))d8. 
(8.4) 
For c(t) a complex exponential as given in eq. (8.1), 
C(jw) = 27TS(w- We), 
(8.5) 
and hence, 
Y(jw) = X(jw - jwe). 
(8.6) 
Thus, the spectrum of the modulated output y(t) is simply that of the input, shifted in 
frequency by an amount equal to the carrier frequency We. For example, with X(jw) band 
limited with highest frequency WM (and bandwidth 2wM), as depicted in Figure 8.l(a), 
the output spectrum Y(jw) is that shown in Figure 8.l(c). 
X(jw) 
~ 
-wM 
WM 
(a) 
C(jw) 
I 
(b) 
(c) 
2'll" 
t 
We 
w 
w 
Figure 8. 1 
Effect in the frequency 
domain of amplitude modulation with a 
complex exponential carrier: (a} spec-
trum of modulating signal x(t}; (b) 
spectrum of carrier c(t} = eiwct; (c) 
spectrum of amplitude-modulated sig-
nal y(t} = x(t)eiwct. 

Sec. 8.1 
Complex Exponential and Sinusoidal Amplitude Modulation 
585 
From eq. (8.3), it is clear that x(t) can be recovered from the modulated signal y(t) 
by multiplying by the complex exponential e- Jwct; that is, 
(8.7) 
In the frequency domain, this has the effect of shifting the spectrum of the modulated signal 
back to its original position on the frequency axis. The process of recovering the original 
signal from the modulated signal is referred to as demodulation, a topic we discuss at more 
length in Section 8.2. 
Since eiwct is a complex signal, eq. (8.3) can be rewritten as 
y(t) = x(t) cos Wet + j x(t) sin Wet. 
(8.8) 
Implementation of eq. (8.7) or (8.8) with x(t) real utilizes two separate multipliers and two 
· sinusoidal carrier signals that have a phase difference of 11"12, as depicted in Figure 8.2 for 
c(t) given by eq. (8.1). In Section 8.4 we give an example of one of the applications in 
which there are particular advantages to using a system, such as in Figure 8.2, employing 
two sinusoidal carriers with a phase difference of 11"12. 
)-----1~ CR.e (y(t)) 
x(t) 
........ ........oj~ X )-----1~ 9m(y(t)) 
Figure 8.2 
Implementation of am-
plitude modulation with a complex ex-
ponential carrier c( t) = ei(wct+9c). 
8. 1 .2 Amplitude Modulation with a Sinusoidal Carrier 
In many situations, using a sinusoidal carrier of the form of eq. (8.2) is often simpler than 
and equally as effective as using a complex exponential carrier. In effect, using a sinusoidal 
carrier corresponds to retaining only the real or imaginary part of the output of Figure 8.2. 
A system that uses a sinusoidal carrier is depicted in Figure 8.3. 
Figure 8.3 
Amplitude modulation 
with a sinusoidal carrier. 
The effect of amplitude modulation with a sinusoidal carrier in the form of eq. (8.2) 
can be analyzed in a manner identical to that in the preceding subsection. Again, for 

586 
Communication Systems 
Chap. 8 
convenience we choose () c = 0. In this case, the spectrum of the carrier signal is 
C(jw) = 7T[D(w - W e) + o(w + We)], 
(8.9) 
and thus, from eq. (8.4), 
Y(jw) = ~[X(jw- jwc) + X(jw + jwc)]. 
(8.10) 
With X(jw) as depicted in Figure 8.4(a), the spectrum of y(t) is that shown in Figure 8.4(c). 
Note that there is now a replication of the spectrum of the original signal, centered around 
both +we and - we. As a consequence, x(t) is recoverable from y(t) only if wc>wM, since 
otherwise the two replications will overlap in frequency. This is in contrast to the case of a 
complex exponential carrier, for which a replication of the spectrum of the original signal is 
centered only around We. Specifically, as we saw in Section 8.1.1, in the case of amplitude 
modulation with a complex exponential carrier, x(t) can always be recovered from y(t) 
for any choice of We by shifting the spectrum back to its original location by multiplying 
by e- jwct, as in eq. (8.7). With a sinusoidal carrier, on the other hand, as we see from 
Figure 8.4, if We < WM , then there will be an overlap between the two replications of 
X(jw) . For example, Figure 8.5 depicts Y(jw) for W e = wM/2. Clearly, the spectrum of 
x(t) is no longer replicated in Y(jw ), and thus, it may no longer be possible to recover x(t) 
from y(t). 
X(jw) 
& 
-wM 
WM 
(a) 
C(jw) 
f 
I 
- we 
(b) 
Y(jw) 
~ 
'! 
(c) 
f 
We 
w 
w 
w 
Figure 8.4 
Effect in the frequency 
domain of amplitude modulation with a 
sinusoidal carrier: (a) spectrum of 
modulating signal x(t); (b) spectrum 
of carrier c(t) = cos wet; (c) spectrum 
of amplitude-modulated signal. 

Sec. 8.2 
Demodulation for Sinusoidal AM 
X(jw) LL 
(a) 
(b) 
8.2 DEMODULATION FOR SINUSOIDAL AM 
w 
w 
587 
Figure 8.5 
Sinusoidal amplitude 
modulation with carrier cos wet for 
which we = wM/2: (a) spectrum of 
modulating signal: (b) spectrum of 
modulated signal. 
At the receiver in a communication system, the information -bearing signal x(t) is recov-
ered through demodulation. In this section, we examine the process of demodulation for 
sinusoidal amplitude modulation, as introduced in the previous section. There are two com-
monly used methods for demodulation, each with its own advantages and disadvantages. 
In Section 8.2.1 we discuss the first of these, a process referred to as synchronous demod-
ulation, in which the transmitter and receiver are synchronized in phase. In Section 8.2.2, 
we describe an alternative method referred to as asynchronous demodulation. 
8.2.1 Synchronous Demodulation 
Assuming that we > WM, demodulation of a signal that was modulated with a sinusoidal 
carrier is relatively straightforward. Specifically, consider the signal 
y(t) = x(t) cos Wet. 
(8.11) 
As was suggested in Example 4.21, the original signal can be recovered by modulating 
y(t) with the same sinusoidal carrier and applying a lowpass filter to the result. To see this, 
consider 
w(t) = y(t) COS Wet. 
(8.12) 
Figure 8.6 shows the spectra of y(t) and w(t), and we observe that x(t) can be recovered 
from w(t) by applying an ideallowpass filter with a gain of 2 and a cutoff frequency that 
is greater than w M and less than 2w c - w M. The frequency response of the lowpass filter 
is indicated by the dashed line in Figure 8.6(c). 
The basis for using eq. (8.12) and a lowpass filter to demodulate y(t) can also be 
seen algebraically. From eqs. (8.11) and (8.12), it follows that 
· w(t) = x(t) cos2 Wet, 

588 
Communication Systems 
Y(jw) 
~ 
I Y', 
- we 
(we- wM) 
We (we+ wM) 
(a) 
C(jw) 
1T 
I 
1T 
1 
1 
- we 
(b) 
We 
W(jw) 
__ zt\ 
____ 
-----, 
I 
1 
1 
1 
2 
1 
I 
I 
I 
I 
I 
I 
(c) 
Figure 8.6 
Demodulation of an amplitude-modulated signal with a sinu-
soidal carrier: (a) spectrum of modulated signal; (b) spectrum of carrier signal; 
(c) spectrum of modulated signal multiplied by the carrier. The dashed line 
indicates the frequency response of a lowpass filter used to extract the de-
modulated signal. 
or, using the trigonometric identity 
we can rewrite w(t) as 
1 
1 
w(t) = 2 x(t) + 2 x(t) cos 2wct. 
Chap.8 
w 
w 
(8.13) 
Thus, w(t) consists of the sum of two terms, namely one-half the original signal and one-
half the original signal modulated with a sinusoidal carrier at twice the original carrier 
frequency we. Both of these terms are apparent in the spectrum shown in Figure 8.6(c). 
Applying the lowpass filter to w(t) corresponds to retaining the first term on the right-hand 
side of eq. (8.13) and eliminating the second term. 
The overall system for amplitude modulation and demodulation using a complex 
exponential carrier is depicted in Figure 8.7, and the overall system for modulation and 
demodulation using a sinusoidal carrier is depicted in Figure 8.8. In these figures, we 
have indicated the more general case in which, for both the complex exponential and the 
sinusoidal carrier, a carrier phase () c is included. The modification of the preceding analysis 
so as to include ()c is straightforward and is considered in Problem 8.21. 

Sec. 8.2 
Demodulation for Sinusoidal AM 
589 
x(t) ---+{ X 1-----.. y(t) 
x(t)--~0---.. y(t) 
l 
eHwot + Uo) 
(a) 
(a) 
y(t) 
()-------- w(t) 
l 
y(t) 
8 - J(w, t + oo) 
(b) 
f.::\ 
w(t) 
----~~------~~~~ 
l 
cos (wet + ec) 
1--...,.. x(t) 
Lowpass ftlter 
Figure 8.7 
System for ampli-
tude modulation and demodulation 
using a complex exponential car-
rier: (a) modulation; (b) demodula-
tion. 
(b) 
Figure 8.8 
Amplitude modulation and demodulation with a sinusoidal car-
rier: (a) modulation system; (b) demodulation system. The lowpass filter cut-
off frequency Wco is greater than wM and less than 2wc -
wM. 
In the systems of Figures 8. 7 and . 8.8, the demodulating signal is assumed to be 
synchronized in phase with the modulating signal, and consequently the process is referred 
to as synchronous demodulation. Suppose, however, that the modulator and demodulator 
are not synchronized in phase. For the case of the complex exponential carrier, with () c 
denoting the phase of the modulating carrier and c/Jc the phase of the demodulating carrier, 
and consequently, 
y(t) = e j(wct+Oc) x(t), 
w(t) = e - j(wct+</>cl y(t), 
(8.14) 
(8.15) 
(8.16) 
Thus, if () c ¥- cp0 w(t) will have a complex amplitude factor. For the particular case in 
which x(t) is positive, x(t) = lw(t)l, and thus x(t) can be recovered by taking the magni-
tude of the demodulated signal. 
For the sinusoidal carrier, again let() c and c/Jc denote the phases of the modulating and 
demodulating carriers, respectively, as indicated in Figure 8.9. The input to the lowpass 
filter is now 
(8.17) 
or, using the trigonometric identity 
1 
1 
cos( w et + ()c) cos( w et + c/Jc) = 2 cos(() c -
c/Jc) + 2 cos(2wct + () c + c/Jc), 
(8.18) 

590 
Communication Systems 
x(t) --~ 
x }--~ y(t) 
(a) 
H(jw) 
0 
w(t) 
y(t) ---JJ;~ X 1-----JI~I 
21 
we have 
l 
- Woo 
Wco 
W 
(b) 
Figure 8. 9 
Sinusoidal amplitude modulation and demodulation system for 
which the carrier signals and the modulator and demodulator are not synchro-
nized: (a) modulator; (b) demodulator. 
1 
1 
w(t) = 2 cos(Oc- 4Jc)x(t) + 2x(t)cos(2wct + Oc + 4>c), 
Chap. a 
(8.19) 
and the output of the lowpass filter is then x(t) multiplied by the amplitude factor cos(Oc -
4Jc). If the oscillators in the modulator and demodulator are in phase, Oc = 4Jc, and the 
output of the lowpass filter is x(t). On the other hand, if these oscillators have a phase 
difference of 7r/2, the output will be zero. In general, for a maximum output signal, the os-
cillators should be in phase. Of even more importance, the phase relation between the two 
oscillators must be maintained over time, so that the amplitude factor cos(Oc- 4>c) does 
not vary. This requires careful synchronization between the modulator and the demodu-
lator, which is often difficult, particularly when they are geographically separated, as is 
typical in a communication system. The corresponding effects of, and the need for, syn-
chronization not only between the phase of the modulator and demodulator, but between 
the frequencies ofthe carrier signals used in both, are explored in detail in Problem 8.23. 
8.2.2 Asynchronous Demodulation 
In many systems that employ sinusoidal amplitude modulation, an alternative demod-
ulation procedure referred to as asynchronous demodulation is commonly used. Asyn-
chronous demodulation avoids the need for synchronization between the modulator and 
demodulator. In particular, suppose that x(t) is always positive and that the carrier fre-
quency w c is much higher than w M, the highest frequency in the modulating signal. 
The modulated signal y(t) will then have the general form illustrated in Figure 8.10. 

--
~ 
~ 
Sec. 8.2 
Demodulation for Sinusoidal AM 
591 
In particular, the envelope of y(t)-that is, a smooth curve connecting the peaks in y(t)-
would appear to be a reasonable approximation to x(t). Thus, x(t) could be approximately 
recovered through the use of a system that tracks these peaks to extract the envelope. Such 
a system is referred to as an envelope detector. One example of a simple circuit that acts 
as an envelope detector is shown in Figure 8.11(a). This circuit is generally followed by a 
lowpass filter to reduce the variations at the carrier frequency, which are evident in Figure 
8.11 (b) and which will generally be present in the output of an envelope detector of the 
type indicated in Figure 8.11(a). 
The two basic assumptions required for asynchronous demodulation are that x(t) 
be positive and that x(t) vary slowly compared to we. so that the envelope is easily 
tracked. The second condition is satisfied, for example, in audio transmission over a radio-
frequency (RF) channel, where the higP.est frequency present in x(t) is typically 15 to 20 
kHz and wei2'1T is in the range 500kHz to 2 MHz. The first condition, that x(t) be positive, 
can be satisfied by simply adding an appropriate constant value to x(t) or, equivalently, 
by a simple change in the modulator, as shown in Figure 8.12. The output of the envelope 
detector then approximates x(t) + A, from which x(t) is easily obtained. 
To use the envelope detector for demodulation, we require that A be sufficiently 
large so that x(t) + A is positive. Let K denote the maximum amplitude of x(t); that is, 
lx(t)l :::; K. For x(t) +A to be positive, we require that A > K. The ratio KIA is commonly ·· 
referred to as the modulation index m. Expressed in percent, it is referred to as the percent 
modulation. An illustration of the output of the modulator of Figure 8.12 for x(t) sinu-
soidal and form = 0.5 (50% modulation) and m = 1.0 (100% modulation), is shown in 
Figure 8.13. 
In Figure 8.14, we show a comparison of the spectra associated with the modulated 
signal when synchronous demodulation and when asynchronous demodulation are used. 
We note in particular that the output of the modulator for the asynchronous system in 
Figure 8.12 has an additional component A cos wet that is neither present nor necessary in 
the synchronous system. This is represented in the spectrum of Figure 8.14( c) by the pres-
ence of impulses at +we and -we. For a fixed maximum amplitude K of the modulating 
signal, as A is decreased the relative amount of carrier present in the modulated output 
decreases. Since the carrier component in the output contains no information, its presence 
y(t) 
' ' 
J( Envelope 
------" Envelope 
Figure 8. 1 o Amplitude-modulated 
signal for which the modulating signal 
is positive. The dashed curve repre-
sents the envelope of the modulated 
signal. 

592 
x(t)--+-t 
Communication Systems 
+ 
y(t) 
c 
R 
w(t) 
(a) 
{b) 
Figure 8. 11 
Demodulation by envelope detection: (a) circuit for envelope 
detection using half-wave rectification; (b) waveforms associated with the en-
velope detector in (a): r(t) is the half-wave rectified signal, x(t) is the true 
envelope, and w(t) is the envelope obtained from the circuit in (a). The rela-
tionship between x(t) and w(t) has been exaggerated in (b) for purposes of 
illustration. In a practical asynchronous demodulation system, w(t) would typi-
cally be a much closer approximation to x(t) than depicted here. 
J---~ y(t) = {A+ x(t)) coswct 
A 
Chap. 8 
Figure 8. 1 2 
Modulator for an 
asynchronous modulation-demodulation 
system. 
represents an inefficiency- for example, in the amount of power required to transmit 
the modulated signal-and thus, in one sense it is desirable to make the ratio KIA- i.e., 
the modulation index m- as large as possible. On the other hand, the ability of a simple 
envelope detector such as that in Figure 8.11 to follow the envelope and thus extract x(t) 
improves as the modulation index decreases. Hence, there is a trade-off between the effi-

Sec. 8.2 
Demodulation for Sinusoidal AM 
' ' 
X(jw) 
(a) 
(b) 
& 
- wM 
WM 
(a) 
6 
~t 6 
- w e 
W e 
(b) 
(c) 
w 
w 
w 
593 
Figure 8. 1 3 
Output of the am-
plitude modulation system of Figure 
8.12: (a) modulation index m = 0.5; 
(b) modulation index m = 1.0. 
Figure 8.14 
Comparison of spec-
tra for synchronous and asynchronous 
sinusoidal amplitude modulation sys-
tems: (a) spectrum of modulating 
signal; (b) spectrum of x(t) cos wet 
representing modulated signal in a 
synchronous system; (c) spectrum of 
[x(t) + A] cos wet representing modu-
lated signal in an asynchronous 
system. 

594 
Communication Systems 
Chap. 8 
ciency of the system in terms of the power in the output of the modulator and the quality 
of the demodulated signal. 
There are a number of advantages and disadvantages to the asynchronous modulation-
demodulation system of Figures 8.11 and 8.12, compared with the synchronous system of 
Figure 8.8. The synchronous system requires a more sophisticated demodulator because 
the oscillator in the demodulator must be synchronized with the oscillator in the modu-
lator, both in phase and in frequency. On the other hand, the asynchronous modulator in 
general requires transmitting more power than the synchronous modulator, since, for the 
envelope detector to operate properly, the envelope must be positive, or equivalently, there 
must be a carrier component present in the transmitted signal. This is often preferable in 
cases such as that associated with public radio broadcasting, in which it is desirable to 
mass-produce large numbers of receivers (demodulators) at moderate cost. The additional 
cost in transmitted power is then offset by the savings in cost for the receiver. On the 
other hand, in situations in which transmitter power requirements are at a premium, as 
in satellite communication, the cost of implementing a more sophisticated synchronous 
receiver is warranted. 
8.3 FREQUENCY-DIVISION MULTIPLEXING 
Many systems used for transmitting signals provide more bandwidth than is required for 
any one signal. For example, a typical microwave link has a total bandwidth of several 
gigahertz, which is considerably greater than the bandwidth required for one voice chan-
nel. If the individual voice signals, which are overlapping in frequency, have their fre-
quency content shifted by means of sinusoidal amplitude modulation so that the spectra 
of the modulated signals no longer overlap, they can be transmitted simultaneously over a 
single wideband channel. The resulting concept is referred to as frequency-division multi-
plexing (FDM). Frequency-division multiplexing using a sinusoidal carrier is illustrated in 
Figure 8.15. The individual signals to be transmitted are assumed to be band limited and 
coswat 
x.(t)--~ 
Ya(t) 
coswbt 
~ 
xb(t) 
X 
Yb(t) 
w(t) 
Figure 8. 1 5 
Frequency-division 
multiplexing using sinusoidal amplitude 
modulation. 

X8 (jw) 
Sec. 8.3 
Frequency-Division Multiplexing 
595 
are modulated with different carrier frequencies. The modulated signals are then summed 
and transmitted simultaneously over the same communication channel. The spectra of the 
individual subchannels and the composite multiplexed signal are illustrated in Figure 8.16. 
Through this multiplexing process, the individual input signals. are allocated distinct seg-
ments of the frequency band. To recover the individual channels in the demultiplexing 
process requires two basic steps: bandpass filtering to extract the modulated signal corre-
sponding to a specific channel, followed by demodulation to recover the original signal. 
Thi!i is illustrated in Figure 8.17 to recover channel a, where, for purposes of illustration, 
synchronous demodulation is assumed. 
Xb(jw) 
Xe(jw) 
~ 
__rh_ ~ 
- wM 
WM 
w 
- wM 
WM 
w 
- wM 
WM 
w 
Y8 (jw) 
(') 
I (') 
-wa 
- wa 
Yb(jw) 
1.1 
I 
1.1 
- wb 
- wb 
w 
Ye(jw) 
1\ 
I 
1\ 
-we 
We 
W 
W(jw) 
/\(.1(') 
I (')(.II\ 
Figure 8.16 
Spectra associated 
with the frequency-division multiplexing 
- we 
-wb 
- wa 
Wa 
wb 
We 
w 
system of Figure 8.15. 

\ 
596 
Communication Systems 
Chap. a 
1-- ---Demultiplexing -----+1-<-------- Demodulation-----~ 
w(t) 
Bandpass 
Lowpass 
filter 
coswat 
filter 
t 
H1(jw) 
H2(jw) 
~t·~ 
Ya(t) 
I' 
X 
I I 
-wa 
Wa 
w 
- wM 
WM 
w 
Figure 8.17 
Demultiplexing and demodulation for a frequency-division multiplexed 
signal. 
Telephone communication is one important application of frequency-division multi-
plexing. Another is the transmission of signals through the atmosphere in the RF band. 
In the United States, the use of radio frequencies for transmitting signals over the range 
10 kHz to 275 GHz is controlled by the Federal Communications Commission, and 
different portions of the range are allocated for different purposes. The current allo-
cation of frequencies is shown in Figure 8.18. As indicated, the frequency range in 
the neighborhood of 1 MHz is assigned to the AM broadcast band, where AM refers 
specifically to the use of sinusoidal amplitude modulation. Individual AM radio sta-
tions are assigned specific frequencies within the AM band, and thus, many stations 
can broadcast simultaneously through this use of frequency-division multiplexing. In 
principle, at the receiver, an individual radio station can be selected by demultiplex-
ing and demodulating, as illustrated in Figure 8.17. The tuning dial on the receiver 
would then control both the center frequency of the bandpass filter and the frequency of 
the demodulating oscillator. In fact, for public broadcasting, asynchronous modulation 
and demodulation are used to simplify the receiver and reduce its cost. Furthermore, 
the demultiplexing in Figure 8.17 requires a sharp cutoff bandpass filter with variable 
center frequency. Variable frequency-selective filters are difficult to implement, and 
consequently, a fixed filter is implemented instead, and an intermediate stage of mod-
ulation and filtering [referred to in a radio receiver as the intermediate-frequency (IF) 
stage] is used. The use of modulation to slide the spectrum of the signal past a fixed 
bandpass filter replaces the use of a variable bandpass filter in a manner similar to the 
procedure discussed in Section 4.5.1. This basic procedure is incorporated into typical 
home AM radio receivers. Some of the more detailed issues involved are considered in 
Problem 8.36. 
As illustrated in Figure 8.16, in the frequency-division multiplexing system of Fig-
ure 8.15 the spectrum of each individual signal is replicated at both positive and negativ~ 
frequencies, and thus the modulated signal occupies twice the bandwidth of the original. 
This represents an inefficient use of bandwidth. In the next section we consider an al-
ternative form of sinusoidal amplitude modulation, which leads to more efficient use of 
bandwidth at the cost of a more complicated modulation system. 

Frequency 
range 
30--300 Hz 
0.3-3 kHz 
3-30kHz 
30--300 kHz 
0.3- 3 MHz 
3-30MHz 
30--300 MHz 
0.3-3 GHz 
3-300Hz 
30--300 GHz 
103-107 GHz 
Sec. 8.4 
Single-Sideband Sinusoidal Amplitude Modulation 
597 
Designation 
ELF 
(extremely 
low frequency) 
VF 
(voice frequency) 
VLF 
(very low fre-
quency) 
LF 
(low frequency) 
MF 
(medium frequency) 
HF 
(high frequency) 
VHF 
(very high 
frequency) 
UHF 
(ultra high 
frequency) 
SHF 
(super high 
frequency) 
EHF 
(extremely high. 
frequency) 
Infrared, visible light, 
ultraviolet 
Typical uses 
Macrowave, submarine com-
munication 
Data terminals, telephony 
Navigation, telephone, tele-
graph, frequency and timing 
standards 
Industrial (power line) com-
munication, aeronautical 
and maritime long-range 
navigation, radio beacons 
Mobile, AM broadcasting, 
amateur, public safety 
Military communication, aero-
nautical mobile, intema-
tiona! fixed, amateur and 
citizen's band, industrial 
FM and TV broadcast, land 
transportation (taxis, buses, 
railroad) 
UHF TV, space telemetry, 
radar, military 
Satellite and space commu-
nication, common carrier 
(CC), microwave 
Experimental, government, 
radio astronomy 
Optical communications 
Propagation 
method 
Megametric waves 
Copper wire 
Surface ducting 
(ground wave) 
Mostly surface ducting 
Ducting and ionospheric 
reflection (sky wave) 
Ionospheric reflecting sky 
wave, 50--400 km layer 
altitudes 
Sky wave (ionospheric and 
tropospheric scatter) 
Transhorizon tropospheric 
scatter and line-of-sight 
relaying 
Line-of-sight ionosphere 
penetration 
Line of sight 
Line of sight 
Channel 
features 
Penetration of conducting 
earth and seawater 
Low attenuation, little fading, 
extremely stable phase and 
frequency, large antennas 
Slight fading, high atmo-
spheric pulse 
Increased fading, but reliable 
Intermittent and frequency-
selective fading, multipath 
Fading, scattering, and multi-
path 
Ionospheric penetration, 
extraterrestrial noise, 
high directly 
Water vapor and oxygen 
absorption 
Figure 8. 18 
Allocation of frequencies in the RF spectrum. 
8.4 SINGLE-SIDEBAND SINUSOIDAL AMPLITUDE MODULATION 
For the sinusoidal amplitude modulation systems discussed in Section 8.1, the total 
bandwidth of the original signal x(t) is 2wM, including both positive and negative 
frequencies, where WM is the highest frequency present in x(t). With the use of a 
complex exponential carrier, the spectrum is translated to We, and the total width of 
the frequency band over which there is energy from the signal is still 2w M, although the 
modulated signal is now complex. With a sinusoidal carrier, on the other hand, the spec-
trum of the signal is shifted to +we and -we, and thus, twice the bandwidth is required. 
This suggests that there is a basic redundancy in the modulated signal with a sinusoidal 
carrier. Using a technique referred to as single-sideband modulation, we can remove the 
redundancy. 
The spectrum of x(t) is illustrated in Figure 8.19(a), in which we have shaded the 
positive and negative frequency components differently to distinguish them. The spectrum 

598 
Communication Systems 
Chap. 8 
in Figure 8.19(b) results from modulation with a sinusoidal carrier, where we identify an 
upper and lower sideband for the portion of the spectrum centered at +w c and that centered 
at -we. Comparing Figures 8.19(a) and (b), we see that X(jw) can be recovered if only 
the upper sidebands at positive and negative frequencies are retained, or alternatively, if 
only the lower sidebands at positive and negative frequencies are retained. The resulting 
spectrum if only the upper sidebands are retained is shown in Figure 8.19(c), and the 
resulting spectrum if only the lower sidebands are retained is shown in Figure 8.19(d). 
The conversion of x(t) to the form corresponding to Figure 8.19(c) or (d) is referred to as 
single-sideband modulation (SSB), in contrast to the double-sideband modulation (DSB) 
of Figure 8.19(b ), in which both sidebands are retained. 
There are several methods by which the single-sideband signal can be obtained. 
One is to apply a sharp cutoff bandpass or highpass filter to the double-sideband signal of 
Figure 8.19(b), as illustrated in Figure 8.20, to remove the unwanted sideband. Another 
is to use a procedure that utilizes phase shifting. Figure 8.21 depicts a system designed 
X(jw) 
~ 
- wM 
WM 
w 
(a) 
Y(jw) 
FA t 6 
w 
sideband sideband 
(b) 
sideband sideband 
Yu(jw) 
~ ·t 
~ 
- we 
We 
w 
(c) 
'lj(jw) ·t 
Figure 8. 19 
Double- and single-
~ 
~ 
sideband modulation: {a) spectrum of 
modulating signal; {b) spectrum af-
ter modulation with a sinusoidal car-
rier; {c) spectrum with only the upper 
- we 
We 
w 
sidebands; {d) spectrum with only the 
(d) 
lower sidebands. 

Sec. 8.4 
Single-Sideband Sinusoidal Amplitude Modulation 
599 
Y(t) 
·I 
H(jw) 
• 
Yu(t) 
Y(jw) 
A 
'i A 
- we 
We 
w 
H(jw) 
't 
- we 
We 
w 
Yu(jw) 
~ 
'1 
~ 
Figure 8.20 
System for retaining 
the upper sidebands using ideal high-
- we 
We 
w 
pass filtering. 
to retain the lower sidebands. The system H (jw) in the figure is referred to as a "90° 
phase-shift network," for which the frequency response is of the form 
H(jw) = { --: j, 
], 
w > 0 
w < 0" 
(8.20) 
The spectra of x(t), YJ(t) = x(t)coswct, Y2(t) = Xp(t)sinwct, and y(t) are illustrated in 
Figure 8.22. As is examined in Problem 8.28, to retain the upper sidebands instead of the 
lower sidebands, the phase characteristic of H(jw) is reversed so that 
H(jw) = { j, . 
- ], 
w > O 
w < 0" 
(8.21) 
As is explored in Problem 8.29. synchronous demodulation of single-sideband systems can 
be accomplished in a manner id~ ntical to synchronous demodulation of double-sideband 
systems. The price paid forth~ increased efficiency of single-sideband systems is added 
complexity in the modulator. 

600 
x(t)--• 
{ 
- j w> O Xp(t) 
L--__.~H(jw)= + j w< O 1--•l 
H(jw) 
Communication Systems 
+ 1----1~ y(t) 
<l: H(jw) 
± 
----l¥ 
w 
w 
-¥1---
Figure 8.21 
System for single-sideband amplitude modulation, using a 90° 
phase-shift network, in which only the lower sidebands are retained. 
Chap. 8 
In surrilliary, in Sections 8.1 through 8.4 we have seen a number of variations of 
complex exponential and sinusoidal amplitude modulation. With asynchronous demod-
ulation, discussed in Section 8.2.2, a constant must be added to the modulating signal 
so that it is positive. This results in the presence of the carrier signal as a component in 
the modulated output, requiring more power for transmission, but resulting in a simpler 
demodulator than is required in a synchronous system. Alternatively, only the upper or 
lower sidebands in the modulated output may be retained, which makes more efficient use 
of bandwidth and transiihtter power, but requires a more sophisticated modulator. Sinu-
soidal amplitude modulation with both sidebands and the presence of a carrier is typically 
abbreviated as AM-DSB/WC (amplitude modulation, double sideband/with carrier) and, 
when the carrier is suppressed or absent, as AM-DSB/SC (amplitude modulation, double-
sideband/suppressed carrier). The corresponding single-sideband systems are abbreviated 
AM-SSB/WC and AM-SSB/SC. 
Sections 8.1 through 8.4 are intended to provide an introduction to many of the basic 
concepts associated with sinusoidal amplitude modulation. There are many variations in 
details and implementation, and the reader is referred to the bibliography for an indication 
of the numerous excellent books that explore this topic further. 

Sec. 8.5 
Amplitude Modulation with a Pulse-Train Carrier 
X(jw) 
w 
v,(jw) 
~ 
't ~ 
- we 
We 
w 
Y2(jw) 
1 
2 
w 
Y(jw) 
't 
w 
601 
Figure 8.22 
Spectra associated 
with the single-sideband system of 
Figure 8.21. 
8.5 AMPUTUDE MODULATION WITH A PULSE-TRAIN CARRIER 
8.5.1 Modulation of a Pulse-Train Carrier 
In previous sections, we examined amplitude modulation with a sinusoidal carrier. Another 
important class of amplitude modulation techniques corresponds to the use of a carrier 
signal that is a pulse train, as illustrated in Figure 8.23; amplitude modulation of this type 
effectively corresponds to transmitting equally spaced time slices of x(t). In general, we 
would not expect that an arbitrary signal could be recovered from such a set of time slices. 
However, our examination of the concept of sampling in Chapter 7 suggests that this should 
be possible if x(t) is band limited and the pulse repetition frequency is high enough. 
From Figure 8.23, 
y(t) = x(t)c(t); 
(8.22) 
i.e., the modulated signal y(t) is the product of x(t) and the carrier c(t). With Y(jw ), X(jw ), 
and C(jw) representing the Fourier transforms of each of these signals, it follows from 

602 
c(t) 
! 
x(t) 
~ 
y(t) 
x(t) ~ 
0 
t 
c(t) 
dJ 
l:t1·l r-1 
D D D 
0 
y(t) 
~ b D d 
0 
the multiplication property that 
Communication Systems 
Chap. 8 
Figure 8.23 
Amplitude modulation 
of a pulse train. 
1 J+x 
Y(jw) = -
X(jO)C(j(w -
O))dO. 
21J' -X 
(8.23) 
Since c(t) is periodic with period T, C(jw) consists of impulses in frequency spaced by 
271'/T; that is, · 
-oo 
C(jw) = 271' 2.= ako(w -
kwc), 
(8.24) 
k = -00 
where W e = 211'/T and the coefficients ak are the Fourier series coefficients of c(t), which,' 
from Example 3.5, are 
(8.25) 

Sec. 8.5 
Amplitude Modulation With a Pulse Train-Carrier 
603 
The spectrum of c(t) is shown in Figure 8.24(b). With the spectrum of x(t) as illustrated 
in Figure 8.24(a), the resulting spectrum of the modulated signal y(t) is shown in Fig-
ure 8.24(c). From eqs. (8.23) and (8.24), Y(jw) is a sum of scaled and shifted replicas of 
X(jw): 
+oo 
Y(jw) = L akX(j(w - kwc)). 
k = -
00 
X(jw) 
(a) 
C(jw) 
-271'~ / T 
(b) 
Y(jw) 
(c) 
' ' 
' ' ' ' ' 
Figure 8.24 
Spectra associated with amplitude modulation of a pulse train: 
(a) spectrum of a bandlimited-signal x(t); (b) spectrum of the pulse carrier 
signal c(t) in Figure 8.23; (c) spectrum of the modulated pulse train y(t). 
(8.26) 
w 
w 

604 
Communication Systems 
Chap.8 
Comparing eq. (8.26) with eq. (7.6) and Figure 8.24 with Figure 7.3(c), we see that 
the spectrum of y(t) is very similar in form to the spectrum resulting from sampling with 
a periodic impulse train, the only difference being the values of the Fourier coefficients 
of the pulse train. For the periodic impulse train used in Chapter 7, all of the Fourier 
coefficients are equal to liT in value, while for the pulse train c(t) in Figure 8.23, the 
Fourier coefficients are given by eq. (8.25). Consequently, the replicas of X(jw) do not 
overlap as long as W e > 2wM, which corresponds to the condition ofthe Nyquist sampling 
theorem. If this constraint is satisfied, then, as with impulse-train sampling, x(t) can be 
recovered from y(t) through the use of a lowpass filter with cutoff frequency greater than 
WM and less than W e -
WM . 
Note that the same conclusion holds for a wide variety of other pulselike carrier 
waveforms: If c(t) is any periodic signal with Fourier transform as in eq. (8.24) for some 
set of Fourier coefficients ak. then Y(jw) is given by eq. (8.26). Then, as long as we = 
2nlT > 2w M, the replicas of X(jw) do not overlap, allowing us to recover x(t) by lowpass 
filtering, provided that the DC Fourier coefficient a0 is nonzero. As shown in Problem 
8.11, if ao is zero or unacceptably small, then, by using a bandpass filter to select one of 
the shifted replicas of X(jw) with a larger value of ak> we obtain a sinusoidal AM signal 
with a scaled version of x(t) as the modulating signal. Using the demodulation methods 
described in Section 8.2, we can then recover x(t). 
8.5.2 Time-Division Multiplexing 
Amplitude modulation with a pulse-train carrier is often used to transmit several signals 
over a single channel. As indicated in Figure 8.23, the modulated output signal y(t) is 
nonzero only when the carrier signal c(t) is on (i.e., is nonzero). During the intervals in 
which c(t) is off, other similarly modulated signals can be transmitted. Two equivalent 
representations of this process are shown in Figure 8.25. In this technique for transmitting 
several signals over a single channel, each signal is in effect assigned a set of time slots 
of duration a that repeat every T seconds and that do not overlap with the slots assigned 
to other signals. The smaller the ratio MT, the larger the number of signals that can be 
transmitted over the channel. This procedure is referred to as time-division multiplexing 
(TDM). Whereas frequency-division multiplexing, as discussed in Section 8.3, assigns 
different .frequency intervals to individual signals, time-division multiplexing assigns dif-
ferent time intervals to individual signals. Demultiplexing the individual signals from the 
composite signal in Figure 8.25 is accomplished by time gating, to select the particular 
time slots associated with each individual signal. 
8.6 PULSE-AMPLITUDE MODULATION 
8.6. 1 Pulse-Amplitude Modulated Signals 
In Section 8.5 we described a modulation system in which a continuous-time signal x(t) 
modulates a periodic pulse train, corresponding to transmitting time slices of x(t) of dura-
tion a seconds every T seconds. As we saw both in that discussion and in our investigation 
of sampling in Chapter 7, our ability to recover x(t) from these time slices depends not on 
their duration a, but rather on their frequency 27TIT, which must exceed the Nyquist rate 

Sec. 8.6 
Pulse-Amplitude Modulation 
.... ----
/ 
' 
x2(t) 
.rf . , 
' 
-------·~~ 
\ 
• y(t) 
x3(t) 
, 
~ 
~--.....-------
(a) 
Figure 8.25 
Time-division 
multiplexing. 
605 
in order to ensure an alias-free reconstruction of x(t). That is, in principle, we need only 
transmit the samples x(nT) of the signal x(t). 
In fact, in modem communication systems, sampled values of the information-
bearing signal x(t), rather than time slices are more typically transmitted. For practical 
reasons, there are limitations on the maximum amplitude that can be transmitted over 
a communication channel, so that transmitting impulse-sampled versions of x(t) is not 
practical. Instead, the samples x(nT) are used to modulate the amplitude of a sequence of 
pulses, resulting in what is referred to as a pulse-amplitude modulation (PAM) system. 

606 
Communication Systems 
Chap. B 
The use of rectangular pulses corresponds to a sample-and-hold strategy in which 
pulses of duration .6. and amplitude proportional to the instantaneous sample values of x(t) 
are transmitted. The resulting waveform for a single PAM channel of this type is illus-
trated in Figure 8.26. In the figure, the dotted curve represents the signal x(t). As with 
the modulation scheme in Section 8.5, PAM signals can be time multiplexed. This is illus-
trated in Figure 8.27, which depicts the transmitted waveform with three time-multiplexed 
channels. The pulses associated with each channel are distinguished by shading, as well 
as by the channel number above each pulse. For a given pulse-repetition period T, as the 
pulse width decreases, more time-multiplexed channels can be transmitted over the same 
communication channel or medium. However, as the pulse width decreases, it is typically 
necessary to increase the amplitude of the transmitted pulses so that a reasonable amount 
of energy is transmitted in each pulse. 
In addition to energy considerations, a number of other issues must be addressed 
in designing a PAM signal. In particular, as long as the sampling frequency exceeds the 
Nyquist rate, we know that x(t) can be reconstructed exactly from its samples, and con-
/ 
/ 
/ 
/ 
/ 
/ 
/ 
' ' ' 
' ~ 
' 
' ' 
'~ 
_____ .... 
Figure 8.26 
Transmitted waveform for a single PAM channel. The dotted 
curve represents the signal x(t). 
Figure 8.27 
Transmitted waveform with three time-multiplexed PAM channels. The 
pulses associated with each channel are distinguished by shading, as well as by .the 
channel number above each pulse. Here, the intersymbol spacing is 7; = T/3. 
y(t) 

sec. 8.6 
Pulse-Amplitude Modulation 
607 
sequently we can use these samples to modulate the amplitude of a sequence of pulses of 
any shape. The choice of pulse shape is dictated by considerations such as the frequency 
selectivity of the communication medium being used and the problem of intersymbol in-
terference, which we discuss next. 
8.6.2 lntersymbollnterference in PAM Systems 
In the TDM pulse-amplitude modulation system just described, the receiver can, in prin-
ciple, separate the channels by sampling the time-multiplexed waveform at appropriate 
times. For example, consider the time-multiplexed signal in Figure 8.27, which consists 
of pulse-amplitude-modulated versions of three signals Xt (t), x2(t), and x3(t). If we sam-
ple y(t) at appropriate times, corresponding, for example, to .the midpoints of each pulse, 
we can separate the samples of the three signals. That is, 
y(t) = Axt(t), 
t = 0, ±3Tt, ±6Tt, .. . , 
y(t) = Ax2(t), 
t = Tt, Tt ± 3Tt, Tt ± 6Tt. ... , 
(8.27) 
y(t) = Ax3(t), 
t = 2Tt. 2Tt ± 3Tt, Tt ± 6Tt. ... , 
where T1 is the intersymbol spacing, here equal to T/3, and where A is the appropriate 
proportionality constant. In other words, samples of x 1 (t), x2(t), and x3(t) can be obtained 
by appropriate sampling of the received time-multiplexed PAM signal. 
The strategy indicated in the preceding paragraph assumes that the transmitted 
pulses remain distinct as they propagate over the communication channel. In transmis-
sion through any realistic channel, however, the pulses can be expected to be distorted 
through effects such as additive noise and filtering. Additive noise in the channel will, 
of course, introduce amplitude errors at the sampling times. Filtering due to the nonideal 
frequency response of a channel causes a smearing of the individual pulses that can cause 
the received pulses to overlap in time. This interference is illustrated in Figure 8.28 and 
is referred to as intersymbol inteiference. 
Sampling time 
for channel 1 
t 
intersymbol 
interference 
Sampling time 
for channel2 
I 
~ 
Sampling time 
for channel 3 
Figure 8.28 
lntersymbol interference. 
t 

608 
Communication Systems 
Chap. 8 
The smearing over time of the idealized pulses in Figure 8.27 can result from the 
bandwidth constraints of the channel or from phase dispersion caused by nonconstant 
group delay, as was discussed in Section 6.2.2. (See in particular, Example 6.1.) If the 
intersymbol interference is due only to the limited bandwidth of the channel, an approach 
is to use a pulse shape p(t) that is itself band limited and therefore not affected (or only 
minimally affected) by the restricted bandwidth of the channel. In particular, if the chan-
nel has a frequency response H(jw) that has no distortion over a specified frequency band 
(e.g., if H(jw) = 1 for lwl < W), then if the pulse that is used is band limited (i.e., if 
P(jw) = 0 for lw I ~ W), each PAM signal will be received without distortion. On the 
other hand, by using such a pulse, we no longer have pulses without overlap as in Fig-
ure 8.27. Nevertheless, intersymbol interference can be avoided in the time domain, even 
with a band-limited pulse, if the pulse shape is constrained to have zero-crossings at the 
other sampling times [so that eq. (8.27) continues to hold]. For example, consider the sine 
pulse 
( ) 
T1 sin( 7Tt/T1) 
pt = 
7Tt 
and its corresponding spectrum displayed in Figure 8.29. Since the pulse is zero at integer 
multiples of the symbol spacing T 1, as indicated in Figure 8.30, there will be no intersym-
bol interference at these instants. That is, if we sample the received signal at t = kT 1, then 
the contributions to this sampled value from all of the other pulses, i.e., from p(t - mT1) 
form ¥< k, will be identically zero. Of course, avoiding interference from adjacent symbols 
p(t) 
P(jw) 
------L-----~----~-----
w 
'IT 
'IT 
T1 
T1 
Figure 8.29 A sine pulse and its corresponding spectrum. 

Sec. 8.6 
Pulse-Amplitude Modulation 
Sampling 
time for 
channel1 
Sampling 
time for 
channel2 
Pulse used to transmit 
sample of channel 2 
Pulse used to transmit 
sample of channel 3 
Sampling 
time for 
channel3 
Figure ·a.3o 
Absence of intersymbol interference when sine pulses with 
correctly chosen zero-crossings are used. 
609 
requires high accuracy in the sampling times, so that sampling occurs at the zero-crossings 
of the adjacent symbols. 
The sine pulse is only one of many band-limited pulses with time-domain zero-
crossings at ±T1, ±2T1, etc. More generally, consider a pulse p(t) with spectrum of the 
form 
{
l+P,(jw), 
P(jw) = 
P1(jw), 
0, 
lwl :5 ~· 
T
7TI < lwl :5 27T 
T; 
otherwise 
and with P,(jw) having odd symmetry around Tr!T1, so that 
P, (- jw + j ~) = - P, (jw + j ~ ) 
0 :5 w s 
'Tr 
T,' 
(8.28) 
(8.29) 
as illustrated in Figure 8.31. If P1(jw) = 0, p(t) is the sine pulse itself. More generally, 
as explored in Problem 8.42, for any P(jw) satisfying the conditions in eqs. (8.28) and 
(8.29), p(t) will have zero-crossing at ±T1, ±2T1, .••• 
While signals satisfying eqs. (8.28) and (8.29) allow us to overcome the problem 
of limited channel bandwidth, other channel distortions may occur that require a differ-
ent choice of pulse waveform or some additional processing of the received signal prior 
to the separation of the different TDM signals. In particular, if IH(jw )I is not constant 
over the passband, there may be a need to perform channel equalization-i.e., filtering of 

610 
Communication Systems 
Chap. 8 
P(jw) 
Figure 8.31 
Odd symmetry around w/T1 as defined in eq. (8.29). 
the received signal to correct for the nonconstant channel gain. Also, if the channel has 
nonlinear phase, distortion can result that leads to intersymbol interference, unless com-
pensating signal processing is performed. Problems 8.43 and 8.44 provide illustrations of 
these effects. 
8.6.3 Digital Pulse-Amplitude and Pulse-Code Modulation 
The PAM system described in the preceding subsections involves the use of a discrete set 
of samples to modulate a sequence of pulses. This set of samples can be thought of as a 
discrete-time signal x[n], and in many applications x[n] is in fact stored in or generated by 
a digital system. In such cases, the limited word length of a digital system implies that x[n] 
can take on only a finite, quantized set of values, resulting in only a finite set of possible 
amplitudes for the modulated pulses. 
In fact, in many cases this quantized form of digital PAM is reduced to a system 
using only a few-typically, only two-amplitude values. In particular, if each sample of 
x[n] is represented as a binary number (i.e., a finite string of O's and 1 's), then a pulse 
with one of two possible values (one value corresponding to a 0 and one value to a 1) can 
be set for each binary digit, or bit, in the string. More generally, in order to protect against 
transmission errors or provide secure communication, the sequence of binary digits rep-
resenting x[n] might first be transformed or encoded into another sequence of O'.s and 1 's 
before transmission. For example, a very simple error detection mechanism is to transmit 
one additional modulated pulse for each sample of x[n], representing a parity check. That 
is, this additional bit would be set to 1 if the binary representation of x[n] has an odd num-
ber of 1 'sin it and to 0 if there is an even number of 1 's. The receiver can then check the 
received parity bit against the other received bits in order to detect inconsistencies. More 
complex coding and error correction schemes can certainly be employed, and the design 
of codes with particular desirable properties is an important component of communication 
system design. For obvious reasons, a PAM system modulated by an encoded sequence of 
O's and 1 's is referred to as a pulse-code modulation (PCM) system. 

Sec. 8.7 
Sinusoidal Frequency Modulation 
611 
8. 7 SINUSOIDAL FREQUENCY MODULATION 
In the preceding sections, we discussed a number of specific amplitude modulation sys-
tems in which the modulating signal was used to vary the amplitude of a sinusoidal or 
a pulse carrier. As we have seen, such systems are amenable to detailed analysis using 
the frequency-domain techniques we developed in preceding chapters. In another very 
important class of modulation techniques referred to as frequency modulation ( FM), the 
modulating signal is used to control the frequency of a sinusoidal carrier. Modulation sys-
tems of this type have a number of advantages over amplitude modulation systems. As 
suggested by Figure 8.10, with sinusoidal amplitude modulation the peak amplitude of 
the envelope of the carrier is directly dependent on the amplitude of the modulating signal 
x(t), which can have a large dynamic range-i.e., can vary significantly. With frequency 
modulation, the envelope of the carrier is constant. Consequently, an FM transmitter can 
always operate at peak power. In addition, in FM systems, amplitude variations introduced 
over a transmission channel due to additive disturbances or fading can, to a large extent, 
be eliminated at the receiver. For this reason, in public broadcasting and a variety of other 
contexts, FM reception is typically better than AM reception. On the other hand, as we 
will see, frequency modulation generally requires greater bandwidth than does sinusoidal 
amplitude modulation. 
Frequency modulation systems are highly nonlinear and, consequently, are not as 
straightforward to analyze as are the amplitude modulation systems discussed in the pre-
ceding sections. However, the methods we have developed in earlier chapters do allow us 
to gain some understanding of the nature and operation of these systems. 
We begin by introducing the general notion of angle modulation. Consider a sinu-
soidal carrier expressed in the form 
c(t) = Acos(wct+Oc) = Acos()(t), 
(8.30) 
where O(t) = Wct+Oc and where We is the frequency and Oc the phase of the carrier. Angle 
modulation, in general, corresponds to using the modulating signal to change or vary the 
angle O(t). One form that this sometimes takes is to use the modulating signal x(t) to vary 
the phase () c so that the modulated signal takes the form 
y(t) = A cos[ w et+ Oc(t)], 
(8.31) 
where () c is now a function of time, specifically of the form 
Oc(t) = Oo + kpx(t). 
(8.32) 
If x(t) is, for example, constant, the phase of y(t) will be constant and proportional to 
the amplitude of x(t). Angle modulation of the form of eq. (8.31) is referred to as phase 
modulation. Another form of angle modulation corresponds to varying the derivative of 
the angle proportionally with the modulating signal; that is, 
y(t) = A cos O(t), 
(8.33) 
where 
d()(t) 
dt = We+ ktx(t). 
(8.34) 

612 
Communication Systems 
Chap. a 
For x(t) constant, y(t) is sinusoidal with a frequency that is offset from the carrier fre-
quency W e by an amount proportional to the amplitude of x(t). For that reason, angle 
modulation of the form of eqs. (8.33) and (8.34) is commonly referred to as frequency 
modulation. 
Although phase modulation and frequency modulation are different forms of angle 
modulation, they can be easily related. From eqs. (8.31) and (8.32), for phase modulation, 
x(t) 
d()(t) _ 
k dx(t) 
df- W e + Pd(• 
(8.35) 
x(t) 
L/ 
L/ 
y(t) 
y(t) 
t . 
(a) 
(b) 
x(t) 
I 
y(t) 
" 
(\ 
~ 
v v \) 
(c) 
Figure 8.32 
Phase modulation, frequency modulation, and their relationship: (a) 
phase modulation with a ramp as the modulating signal; (b) frequency modulation with 
a ramp as the modulating signal; (c) frequency modulation with a step (the derivative of 
a ramp) as the modulating signal. 

Sec. 8.7 
Sinusoidal Frequency Modulation 
613 
and thus, comparing eqs. (8.34) and (8.35), we see that phase modulating with x(t) is iden-
tical to frequency modulating with the derivative of x(t). Likewise, frequency modulating 
with x(t) is identical to phase modulating with the integral of x(t). An illustration of phase 
modulation and frequency modulation is shown in Figures 8.32(a) and (b). In both cases, 
the modulating signal is x(t) = tu(t) (i.e., a ramp signal increasing linearly with time 
fort > 0). In Figure 8.32(c), an example of frequency modulation is shown with a step 
(the derivative of a ramp) as the modulating signal [i.e., x(t) = u(t)]. The correspondence 
between Figures 8.32(a) and (c) should be evident. 
Frequency modulation with a step corresponds to the frequency of the sinusoidal 
carrier changing instantaneously from one value to another when x(t) changes value at t = 
0, much as the frequency of a sinusoidal oscillator changes when the frequency setting is 
switched instantaneously. When the frequency modulation is a ramp, as in Figure 8.32(b ), 
the frequency changes linearly with time. This notion of a time-varying frequency is often 
best expressed in terms of the concept of instantaneous frequency. For 
y(t) = A cos O(t), 
the instantaneous frequency of the sinusoid is defined as 
·( ) -
d()(t) 
WI t -
---;[(• 
(8.36) 
(8.37) 
Thus, for y(t) truly sinusoidal [i.e., O(t) = (wet + 00)], the instantaneous frequency is 
We. as we would expect. For phase modulation as expressed in eqs. (8.31) and (8.32), the 
instantaneous frequency is We+ kp(dx(t)ldt), and for frequency modulation as expressed 
in eqs. (8.33) and (8.34), the instantaneous frequency is We + k f x(t). 
Since frequency modulation and phase modulation are easily related, we will phrase 
the remaining discussion in terms of frequency modulation alone. To gain some insight 
into how the spectrum of the frequency-modulated signal is affected by the modulating 
signal x(t), it is useful to consider two cases in which the modulating signal is sufficiently 
simple so that some of the essential properties of frequency modulation become evident. 
8. 7. 1 Narrowband Frequency Modulation 
Consider the case of frequency modulation with 
x(t) = A cos Wmt. 
From eqs. (8.34) and (8.37), the instantaneous frequency is 
w;(t) = We + kJACOSWmt, 
which varies sinusoidally between We+ k1A and We- k1A. With 
we have 
(8.38) 
(8.39) 

614 
Communication Systems 
Chap. 8 
and 
y(t) = cos[ wet + J x(t)dt] 
= cos (wet+ ~: sinwmt + Oo). 
(8.40) 
where 00 is a constant of integration. For convenience we will choose 00 = 0, so that 
y(t) = cos [wet+ ~: sinwmt]. 
(8.41) 
The factor !1wlwm, which we denote by m, is defined as the modulation index for 
frequency modulation. The properties of FM systems tend to be different, depending on 
whether the modulation index m is small or large. The case in which m is small is referred 
to as narrowband FM. In general, we can rewrite eq. (8.41) as 
y(t) = cos( wet+ m sinwmt) 
or 
y(t) = coswetcos(msinwmt)- sinwetsin(msinwmt). 
When m is sufficiently small ( << TT/2), we can make the approximations 
cos(msinwmt) = 1, 
sin(msinwmt) = msinwmt, 
so that eq. (8.42) becomes 
y(t) =cos wet- m(sinwmt)(sinwct). 
(8.42) 
(8.43) 
(8.44) 
(8.45) 
(8.46) 
The spectrum of y(t) based on this approximation is shown in Figure 8.33. We note 
that it has a similarity to AM-DSB/WC in that the carrier frequency is present in the 
spectrum and there are sidebands representing the spectrum of the modulating signal in 
eq. (8.38). However, in AM-DSB/WC the additional carrier injected is in phase with the 
modulated carrier, whereas, as we see in eq. (8.46) for the case of the narrowband FM, 
the carrier signal has a phase difference of TTI2 in relation to the amplitude-modulated 
carrier. The waveforms corresponding to AM-DSB/WC and FM are also very different. 
Figure 8.34(a) illustrates the narrowband FM waveform corresponding to eq. (8.46). For 
comparison, Figure 8.34(b) shows the AM-DSB/WC signal 
yz(t) = coswet + m(coswmt)(coswct). 
(8.47) 
For the narrowband FM signal of eq. (8.46), the bandwidth of the sidebands is equal 
to 'the bandwidth of the modulating signal, and in particular, although the approximation 
in the equation is based on assuming that m << TT/2, the bandwidth of the sidebands is 
otherwise independent of the modulation index m (i.e., it depends only on the bandwidth 
of the modulating signal, not on its amplitude). A similar statement applies for narrowband 
FM with a more general modulating signal. 

Sec. 8.7 
Sinusoidal Frequency Modulation 
Y(jw) 
1T 
ffi1T 
ffi1T 
2 
2 
w 
(a) 
(b) 
8. 7.2 Wideband Frequency Modulation 
615 
Figure 8.33 
Approximate spectrum 
for narrowband FM. 
Figure 8.34 
Comparison of 
narrowband FM and AM-DSB/WC: 
(a) narrowband FM; (b) AM-DSB/WC. 
When m is large, the approximation leading to eq. (8.46) no longer applies, and the spec-
trum of y(t) depends on both the amplitude and the spectrum of the modulating signal 
x(t). With y(t) expressed in the form of eq. (8.43), we note that the terms cos[m sin wmt] 
and sin[m sinwmt] are periodic signals with fundamental frequency Wm. Thus, the Fourier 
transform of each of these signals is an impulse train with impulses at integer multiples 
of Wm and amplitudes proportional to the Fourier series coefficients. The coefficients for 
these two periodic signals involve a class of functions referred to as Bessel functions of 
the first kind. The first term in eq. (8.43) corresponds to a sinusoidal carrier of the form 
coswct amplitude modulated by the periodic signal cos[msinwmt] and the second term 
to a sinusoidal carrier sin wet amplitude modulated by the periodic signal sin[m sin wmt]. 
Multiplication by the carrier signals has the effect in the frequency domain of translating 
the spectrum of eq. (8.43) to the carrier frequency, so that it is centered at plus and minus 

616 
Communication Systems 
Chap. B 
we. In Figures 8.35(a) and (b) we illustrate, for w > 0, the the magnitude of the spectra of 
the two individual terms in eq. (8.43), and in Figure 8.35(c) the magnitude of the combined 
spectrum representing the modulated signal y(t). The spectrum of y(t) consists of impulses 
at frequencies ±we + nwm, n = 0, ± 1, ±2, .. . , and is not, strictly speaking, band limited 
around ±we. However, the behavior of the Fourier series coefficients of cos[m sin wmt] 
and sin[msinwmt] are such that the amplitude of the nth harmonic for lnl > m can be 
considered negligible, and thus, the total bandwidth B of each sideband centered around 
+we and - we is effectively limited to 2mwm. That is, 
(8.48) 
or, since m = ktAiwm = IJ.wlwm. 
B = 2ktA = 2/J.w. 
(8.49) 
Comparing eqs. (8.39) and (8.49), we note that the effective bandwidth of each 
sideband is equal to the total excursion of the instantaneous frequency around the carrier 
(a) 
(b) 
(c) 
Figure 8.35 
Magnitude of spec-
trum of wideband frequency modula-
tion with m = 12: {a) magnitude of 
spectrum of coswctcos[msinwmt]; 
{b) magnitude of spectrum of 
sin wctsin[msin wmt]; 
{c) combined spectral magnitude of 
cos[ wet+ msin wmt]. 

Sec. 8.7 
Sinusoidal Frequency Modulation 
617 
frequency. Therefore, for wideband FM, since we assume that m is large, the bandwidth 
of the modulated signal is much larger than the bandwidth of the modulating signal, and 
in contrast to the narrowband case, the bandwidth of the transmitted signal in wideband 
FM is directly proportional to amplitude A of the modulating signal and the gain factor k1. 
8. 7.3 Periodic Square-Wave Modulating Signal 
Another example that lends insight into the properties of frequency modulation is that of a 
modulating signal which is a periodic square wave. Referring to eq. (8.39), let kJ = 1 so 
that llw = A, and let x(t) be given by Figure 8.36. The modulated signal y(t) is illustrated 
in Figure 8.37. The instantaneous frequency is W e + llw when x(t) is positive and W e - llw 
when x(t) is negative. Thus, y(t) can also be written as 
y(t) = r(t) cos[(wc + llw )t] + r ~ - ~ )cos[(wc - llw )t], 
(8.50) 
y(t) 
x(t) 
A 
' 
T 
T 
T 
T 
T 
t 
- 2 
- 4 
4 
2 
-A r-
Figure 8.36 
Symmetric periodic square wave. 
Figure 8.37 
Frequency modulation 
with a periodic square-wave modulat-
ing signal. 

618 
Communication Systems 
Chap. 8 
where r(t) is the symmetric square wave shown in Figure 8.38. Thus, for this particular 
modulating signal, we are able to recast the problem of determining the spectrum of the 
FM signal y(t) as the determination of the spectrum of the sum of the two AM signals in 
eq. (8.50). Specifically, 
Y(jw) = ~[R(jw +}we + jtl.w) + R(jw- }we - jtl.w)] 
+ ~[Rr(Jw +}we - jtl.w) + Rr(jw- }we + jtl.w)], 
(8.51) 
where R(jw) is the Fourier transform of the periodic square wave r(t) in Figure 8.38 and 
Rr(Jw) is the Fourier transform of r(t- T/2). From Example 4.6, with T = 4Tt. 
{8.52) 
and 
Rr(Jw) = R(jw)e- JwT12. 
(8.53) 
The magnitude of the spectrum of Y(jw) is illustrated in Figure 8.39. As with wideband 
· FM, the spectrum has the general appearance oftwo sidebands, centered around we ::!: tl.w, 
that decay for w <We - tl.w and w >We + tl.w. 
r(t) 
.. ] 
I 
I' 
I 
I 
3T 
T 
T 
0 
T 
T 
3T 
T 
- 4 
- 2 
- 4 
4 
2 
4 
Figure 8.38 
Symmetric square wave r(t) in eq. (8.50). 
Y(jw) 
1
~lr-~I~II~II~I~!I~I!~I~~~~~~~~~I!~IJ~I~II~II~II~I~II~II~I~II~II~I~II~II~I~II~II~II~I~II~I~~~~~~~IJ~I~II~II~I~II __ __ 
(wc -'- ~w) 
We 
(wc+~w) 
Figure 8.39 
Magnitude of the spectrum for w > 0 corresponding to fre-
quency modulation with a periodic square-wave modulating signal. Each of the 
vertical lines in the figure represents an impulse of area proportional to the 
height of the line. 
w 

Sec. 8.8 
Discrete-Time Modulation 
619 
Systems for the demodulation of FM signals typically are of two types. One type of 
demodulation system corresponds to converting the FM signal to an AM signal through 
differentiation, while demodulation systems of the second type directly track the phase or 
frequency of the modulated signal. The foregoing discussion provides only a brief intro-
duction to the characteristics of frequency modulation, and we have again seen how the 
basic techniques developed in the earlier chapters can be exploited to analyze and gain an 
insight into an important class of systems. 
8.8 DISCRETE-TIME MODULATION 
8.8.1 Discrete-Time Sinusoidal Amplitude Modulation 
A discrete-time amplitude modulation system is depicted in Figure 8.40, in which c[n] 
is the carrier and x[n] the modulating signal. The basis for our analysis of continuous-
time amplitude modulation was the multiplication property for Fourier transforms-
specifically, the fact that multiplication in the time domain corresponds to convolution in 
the frequency domain. As we discussed in Section 5.5, there is a corresponding property 
for discrete-time signals which we can use to analyze discrete-time amplitude modulation. 
Specifically, consider 
y[n] = x[n]c[n]. 
With X(eiw), Y(eiw), and C(eiw) denoting the Fourier transforms of x[n], y[n], and c[n], 
respectively, Y(eiw) is proportional to the periodic convolution of X(eiw) and C(eiw); that 
is, 
(8.54) 
Since X(eiw) and C(eiw) are periodic with a period of2'7T, the integration can be performed 
over any frequency interval oflength 2'7T. 
Let us first consider sinusoidal amplitude modulation with a complex exponential 
carrier, so that 
(8.55) 
As we saw in Section 5.2, the Fourier transform of c[n] is a periodic impulse train; that is, 
+oo 
C(eiw) = L 21TO(w -
W e + k21T), 
(8.56) 
k =-00 
c[n) 
l 
x[n) --~ ·~ 
y[n] 
Figure 8.40 
Discrete-time ampli-
tude modulation. 

620 
Communication Systems 
Chap.8 
which is sketched in Figure 8.41(b). With X(ejw) as illustrated in Figure 8.41(a), the spec-
trum of the modulated signal is that shown in Figure 8.41(c). In particular, we note that 
Y(ejw) = X(ej<w- wcl). This is the discrete-time counterpart to Figure 8.1, and here again, 
with x[n] real, the modulated signal will be complex. Demodulation is accomplished by 
multiplying by e- jwc'1 to translate the spectrum back to its original location on the fre-
quency axis, so that 
x[n] = y[n]e- jw,n. 
(8.57) 
As explored in Problem 6.43, if we = Tr so that c[n] = ( - 1)
11 , the result of modula-
tion in the time domain is to change the algebraic sign of x[n] for odd values of n, while in 
the frequency domain the consequence is the interchanging of high and low frequencies. 
Problem 6.44 explores the use of this type of modulation in utilizing a lowpass filter to 
achieve highpass filtering and vice versa. 
As an alternative to a complex exponential carrier, we can use a sinusoidal carrier, 
in which case, with x[n] real, the modulated signal y[n] will also be real. With c[n] = 
cos wen. the spectrum of the carrier consists of periodically repeated pairs of impulses at 
- 2'11' 
-wM 
r 
-2'11' 
- 2'TI'+Wc 
1 
0 
WM 
(a) 
C(ei"') 
I '·I 
0 
We 
(b) 
Y(ei"') 
(wc-wM) We (wc+wM) 
(c) 
2'11' 
,. I 
2'11' 
2'11'+Wc 
2'11' 
Figure 8.41 
(a) Spectrum of x[n]; (b) spectrum of c[n] = eiwrn; (c) spec-
trum of y[n] = x[n]c[n]. 
w 
w 
w 

Sec. 8.8 
Discrete-Time Modulation 
621 
w· = :±:we+ k2'TT, as illustrated in Figure 8.42(b). With X(ejw) as shown in Figure 8.42(a), 
the resulting spectrum for the modulated signal is shown in Figure 8.42(c) and corresponds 
to replicating X(ejw) at the frequencies w = :±:we + k2'TT. In order that the individual 
replications of X(ejw) do not overlap, we require that 
(8.58) 
and 
or, equivalently, 
(8.59) 
The first condition is identical to that in Section 8.2 for continous-time sinusoidal ampli-
tude modulation, while the second results from the inherent periodicity of discrete-time 
X(el"') 
1\ 
i 
1\ 
- 27T 
- wM 0 WM 
27T 
w 
(a) 
C(ei"') 
I r r I r r I r 
- 27T 
-27T+We 
- we 
0 
We 
27T- We 
27T 
27T+We 
w 
(b) 
Y(ei"') 
i 
(27T-we- wM) 
... 1\ 1\ 
1\ \1\ 
/\··· 
I 
- 27T 
- 27T + We 
- we 
0 
f We \ 
27T-We 
27T 
27T+Wc 
w 
Wc- WM 
We+WM 
(c) 
Figure 8.42 
Spectra associated with discrete-time modulation using a 
sinusoidal carrier: (a) spectrum of a bandlimited-signal x[n]; (b) spectrum of a 
sinusoidal carrier signal c[n] = cos wen: (c) spectrum of the modulated signal 
y(n] = x[n]c(n]. 

622 
Communication Systems 
Chap. 8 
spectra. Combining eqs. (8.58) and (8.59), we see that for amplitude modulation with a 
sinusoidal carrier, we must restrict w c so that 
(8.60) 
Demodulation can be accomplished in a manner similar to that employed in con-
tinuous time. As illustrated in Figure 8.43, multiplication of y[n] with the same carrier 
used in the modulator results in several replications of the spectrum of the original signal, 
one of which is centered about w = 0. By lowpass filtering to eliminate the unwanted 
replications of X(ejw), the demodulated signal is obtained. 
As should be evident from the foregoing discussion, analysis of discrete-time am-
plitude modulation proceeds in a manner similar to that of continuous-time amplitude 
modulation, with only slight differences. For example, as explored in Problem 8.47, in 
the synchronous modulation and demodulation system, the effect of a phase difference or 
a frequency difference between the sinusoidal carriers in the modulator and demodulator 
is identical in both discrete and continuous time. In addition, just as in continuous time, 
we can use discrete-time sinusoidal AM as the basis for frequency-division multiplexing in 
cos wen 
l 
y(n] 
w[n) 
X 
... ~ 
- 2'1T 
Lowpass filter 
H(ei"') 
rb_ 
-Wco 
Wco w 
1----1~ x[n] 
2'1T 
w 
Figure 8.43 
System and associated 
spectra for discrete-time synchronous 
demodulation. 

Sec. 8.9 
Summary 
623 
discrete time. Furthermore, as explored in Problem 8.48, we can also consider using 
a discrete-time signal to modulate a pulse train, leading to time-division multiplexing 
of discrete-time signals. 
The implementation of discrete-time multiplexing systems provides an excellent ex-
ample of the flexibility of discrete-time processing in general and the importance of the 
operation of upsampling (see Section 7.5.2) in particular. Consider a discrete-time FDM 
system with M sequences that we wish to frequency-division multiplex. With M channels, 
it is required that the spectral energy for each input channel x;[n] be band limited; that is, 
7T 
M < lwl < 7T. 
(8.61) 
If the sequences originally occupied the entire frequency band corresponding, for example, 
to having sampled a set of continuous-time signals at the Nyquist rate, then they would first 
have to be converted to a higher sampling rate (i.e., upsampled) before frequency-division 
multiplexing. This idea is explored further in Problem 8.33. 
8.8.2 Discrete-Time Transmodulation 
One context in which discrete-time modulation is widely used, together with the oper-
ations of decimation, upsampling, and interpolation introduced in Chapter 7, is digital 
communication systems. Typically, in such systems continuous-time signals are trans-
mitted over communication channels in the form of discrete-time signals, obtained by 
sampling. The continous-time signals are often in the form of time-division -multiplexed 
(TDM) or frequency-division-multiplexed (FDM) signals. The signals are then converted 
to discrete-time sequences whose values are represented digitally, for storage or long-
distance transmission. In some systems, because of different constraints or requirements 
at the transmitting end and the receiving end; or because sets of signals that have been in-
dividually multiplexed by different methods are then multiplexed together, there is often 
the requirement for converting from sequences representing TDM signals to sequences 
representing FDM signals or vice versa. This conversion from one modulation or multi-
plexing scheme to another is referred to as transmodulation or transmultiplexing. In the 
context of digital communication systems, one obvious way of implementing transmulti-
plexing is to convert back to continuous-time signals, demultiplex and demodulate, and 
then modulate and multiplex as required. However, if the new signal is then to be con-
verted back to a discrete-time signal, it is clearly more efficient for the entire process to 
be carried out directly in the discrete-time domain. Figure 8.44 shows, in block diagram 
form, the steps involved in converting a discrete-time TDM signal to a discrete-time FDM 
signal. Note that, after demultiplexing the TDM signal, each channel must be upsampled 
in preparation for frequency-division multiplexing. 
8.9 SUMMARY 
In this chapter, we have examined a number of the basic concepts associated with com-
munication systems. In particular, we have examined the concept of modulation, in which 
a signal we wish to communicate is used to modulate a second signal referred to as the 

Oo 
N .,. 
ll 
TOM signal 
i I I I y I I I 1 I 0 
Demultiplex 
(N channels) 
l 
x1[n] 
Y I 9 ? Y 9 ? 
x2[n] 
I I I l I ~ I I 
l 
x3[n] 
r r ? r r f 9 
l -x4[n] 
- I I I I I I I 
cos 
cos 
cos 
Figure 8.44 
Block diagram for TDM-to-FDM transmultiplexing. 
(~)n 
(~ )n 
(1f)n 

Sec. 8.9 
Summary 
625 
carrier, and we have looked in detail at the concept of amplitude modulation. The proper-
ties of amplitude modulation are most easily interpreted in the frequency domain through 
the multiplication property of the Fourier transform. Amplitude modulation with a com-
plex exponential or sinusoidal carrier is typically used to shift the spectrum of a sig-
nal in frequency and is applied, for example, in communication systems to place the 
spectrum in a frequency range suitable for transmission and to permit frequency-division 
multiplexing. Variations of sinusoidal amplitude modulation, such as the insertion of a 
carrier signal for asynchronous systems and single- and double-sideband systems, were 
discussed. 
We also examined several other forms of modulation -based communication. 
In this regard, we briefly introduced the concepts of frequency and phase modula-
tion. Although these forms of modulation are more difficult to analyze in detail, it 
is possible to gain significant insight into their characteristics through the frequency 
.domain. 
We further examined in some detail amplitude modulation of a pulsed signal, 
.which led us to the concepts of time-division multiplexing and pulse-amplitude 
modulation, in which successive samples of a discrete-time signal are used to mod-
ulate the amplitude of a sequence of pulses. This led in tum to an examination of 
discrete-time modulation and digital communication, in which the flexibility of discrete-
time processing facilitates the design and implementation of more sophisticated 
communication systems involving concepts such as pulse-code modulation and 
transmodulation. 
Chapter 8 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining two sections contain problems belonging to 
the basic and advanced categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
8.1. Let x(t) be a signal for which X(jw) = 0 when lwl > WM. Another signal y(t) is 
specified as having the Fourier transform Y(jw) = 2X(j(w -we)). Determine a 
signal m(t) such that 
x(t) = y(t)m(t). 
8.2. Let x(t) be a real-valued signal for which X(jw) = 0 when lwl > 1,0007T. Suppos-
ing that y(t) = ejwct x(t), answer the following questions: 
(a) What constraint should be placed on W e to ensure that x(t) is recoverable from 
y(t)? 
(b) What constraint should be placed on W e to ensure that x(t) is recoverable from 
ffi-e{y(t)}? 
. 

626 
Communication Systems 
Chap. 8 
8.3. Let x(t) be a real-valued signal for which X(jw) = 0 when lwl > 2,00017'. Ampli-
tude modulation is performed to produce the signal 
g(t) = x(t) sin(2,0007Tt). 
A proposed demodulation technique is illustrated in Figure P8.3 where g(t) is the 
input, y(t) is the output, and the ideallowpass filter has cutoff frequency 2,00017' 
and passband gain of 2. Determine y(t). 
Ideal 
g(t) 
1----~ lowpass 1----~ y(t) 
filter 
cos(2000'iTt) 
Figure P8.3 
8.4. Suppose 
x(t) = sin 2007Tt + 2 sin 4007Tt 
and 
g(t) = x(t) sin 4001Tt. 
If the product g(t)(sin 4001Tt) is passed through an ideallowpass filter with cutoff 
frequency 40017' and passband gain of 2, determine the signal obtained at the output 
of the lowpass filter. 
8.5. Suppose we wish to transmit the signal 
( ) 
sin 1, 0007Tt 
xt = - ---
1Tt 
using a modulator that creates the signal 
w(t) = (x(t) + A) cos(10,0007Tt). 
Determine the largest permissible value of the modulation index m that would allow 
asynchronous demodulation to be used to recover x(t) from w(t). For this problem, 
you should assume that the maximum magnitude taken on by a side lobe of a sine 
function occurs at the instant of time that is exactly halfway between the two zero-
crossings enclosing the side lobe. 
8.6. Assume that x(t) is a signal whose Fourier transform X(jw) is zero for lwl > WM . 
The signal g(t) may be expressed in terms of x(t) as 
[ 
(sinwct)j 
g(t) = x(t)coswct-
x(t)coswct * ----;;( , 
where * denotes convolution and w c > w M . Determine the value of the constant A 
such that 

Chap. 8 Problems 
627 
AsinwMt 
x(t) = (g(t) cos Wet)* 
. 
'TTt 
8.7. An AM-SSB/SC system is applied to a signal x(t) whose Fourier transform X(jw) is 
zero for lw I > w M. The carrier frequency w e used in the system is greater than w M. 
Let g(t) denote the output of the system, assuming that only the upper sidebands 
are retained. Let q(t) denote the output of the system, assuming that only the lower 
sidebands are retained. The system in Figure P8.7 is proposed for converting g(t) 
into q(t). How should the parameter wo in the figure be related to We? What should 
be the value of passband gain A? 
g(t) 
coswot 
Figure P8.7 
8.8. Consider the modulation system shown in Figure P8.8. The input signal x(t) has a 
FouriertransformX(jw) that is zero for lwl > WM. Assuming that we> WM, answer 
the following questions: 
x(t) 
(a) Is y(t) guaranteed to be real if x(t) is real? 
(b) Can x(t) be recovered from y(t)? 
HOw)= 
. ' 
{
-J· w>O 
J ,w<O 
y(t) 
Figure P8.8 
8.9. Two signals x 1(t) and x2(t), each with a Fourier transform that is zero for lwl > 
We, are to be combined using frequency-division multiplexing. The AM-SSB/SC 
technique of Figure 8.21 is applied to each signal in a manner that retains the lower 
sidebands. The carrier frequencies used for x1 (t) and x2(t) are We and 2we, respec-
tively. The two modulated signals are then summed together to obtain the FDM 
signal y(t). 
, 

628 
Communication Systems 
(a) For what values of w is Y(jw) guaranteed to be zero? 
(b) Specify the values of A and w0 so that 
[{ 
sinwot} 
] 
A sin wet 
x1 (t) = 
y(t) * -------;:( cos w0t * 
7Tt 
, 
where * denotes convolution. 
Chap. 8 
8.10. A signal x(t) is multiplied by the rectangular pulse train c(t) shown in Figure P8.10. 
(a) What constraint should be placed on X(jw) to ensure that x(t) can be recovered 
from the product x(t)c(t) by using an ideallowpass filter? 
(b) Specify the cutoff frequency We and the passband gain A of the ideallowpass 
filter needed to recover x(t) from x(t)c(t). [Assume that X(jw) satisfies the 
constraint determined in part (a).] 
c(t) 
r: 0 25X10- 3sec 
~ 
-
1r--1-
r--
-
... 
0 
t(sec) 
Figure PS. 1 0 
8.11. Let 
00 
c(t) = ~ 
akejkwct, 
k = - oo 
where a0 = 0 and a1 ¥- 0, be a real-valued periodic signal. Also, let x(t) be a signal 
with X(jw) = 0 for lwl ;::: wc/2. The signal x(t) is used to modulate the carrier c(t) 
to obtain 
y(t) = x(t)c(t). 
(a) Specify the passband and the passband gain of an ideal bandpass filter so that, 
with input y(t), the output of the filter is 
g(t) = (alejwct + aie- jwct)x(t). 
(b) If a1 = ladej<l:a 1, show that 
g(t) = Acos(wct + cf>)x(t), 
and express A and cf> in terms of Ia 1l and ~a 1. 
8.12. Consider a set of 10 signals xi(t), i = 1, 2, 3, ... , 10. Assume that each Xi(t) has 
Fourier transform such that Xi(jw) = 0 for lwl ;::: 2,0007T. AlllO signals are to be 
time-division multiplexed after each is multiplied by a carrier c(t) shown in Figure 
P8.12. If the period T of c(t) is chosen to have the maximum allowable value, what 
is the largest value of~ such that all 10 signals can be time-division multiplexed? 

Chap. 8 Problems 
629 
r---
r---
-
r---
... 
- T 
0 
T 
2T 
Figure P8. 1 2 
8.13. A class of popularly used pulses in PAM are those which have a raised cosine fre-
quency response. The frequency response of one of the members of this class is 
P(jw) = [ t(t +cos~), 0 s \w\ s ~~, 
0, 
elsewhere 
where T1 is the intersymbol spacing. 
(a) Determine p(O). 
(b) Determine p(kTt), where k = ± 1, ±2, .... 
8.14. Consider the frequency-modulated signal 
y(t) = cos( wet + m cos Wmt), 
where We>> Wm and m << TT/2. Specify an approximation to Y(jw) for w > 0. 
8.15. For what values of w0 in the range -TT < w0 s 
'TT is amplitude modulation with 
carrier eiwon equivalent to amplitude modulation with carrier cos won? 
8.16. Suppose x[n] is a real-valued discrete-time signal whose Fourier transform X(eiw) 
has the property that 
. 
'TT 
X(elw) = 0 for S s w :s 'TT. 
We use x[n] to modulate a sinusoidal carrier c[n] = sin(57r/2)n to produce 
y[n] = x[n]c[n]. 
Determine the values of win the range 0 s w :s 'TT for which Y(eiw) is guaranteed 
to be zero. 
8.17. Consider an arbitrary finite-duration signal x[n] with Fourier transform X(eiw). We 
generate a signal g[n] through insertion of zero-valued samples: 
[ ] 
[ ] 
{ 
x[n/4], 
n = 0, ±4, ±8, ±12, ... 
g n = X(4) n = 
0, 
otherwise 
The signal g[n] is passed through an ideallowpass filter with cutoff frequency TTI4 
and passband gain of unity to produce a signal q[n]. Finally, we obtain 
y[n] = q[n] cos c: n). 
For what values of w is Y(eiw) guaranteed to be zero? 

630 
Communication Systems 
Chap. 8 
8.18. Let x[n] be a real-valued discrete-time signal whose Fourier transform X(ejw) is 
zero for w ~ 71'14. We wish to obtain a signal y[n] whose Fourier transform has the 
property that, in the interval - 71' < w ~ 71', 
x[n] 
. 
{ X(ej(w- fl), I< w ~ 3; 
Y(e'w) = 
X(ej(w+fl), -3: < W ~ -I. 
0, 
otherwise 
The system in Figure P8.18 is proposed for obtaining y[n] from x[n]. Determine 
constraints that the frequency response H(ejw) of the filter in the figure must satisfy 
for the proposed system to work. 
y[n] 
Figure PS. 18 
8.19. Consider 10 arbitrary real-valued signals x;[n], i = 1, 2, ... , 10. Suppose each x;[n] 
is upsampled by a factor of N, and then sinusoidal amplitude modulation is applied 
to it with carrier frequency w; = i7T/10. Determine the value of N which would 
guarantee that alllO modulated signals can be summed together to yield an FDM 
signal y[n] from which each x;[n] can be recovered. 
8.20. Let v1 [n] and v2[n] be two discrete-time signals obtained through the sampling 
(without aliasing) of continuous-time signals. Let 
y[n] = v,[n] + vz[n - 1] 
be a TOM signal, where, fori = 1, 2, 
n = 0, ±2, ±4, ±6, ... 
otherwise 
The signal y[n] is processed by the systemS depicted in Figure P8.20 to obtain a 
signal g[n]. For the two filters used inS, 
lwl ~I 
I<w~71'· 

Chap. 8 Problems 
631 
y[n] 
Determine the signal p[n] used in S such that g[n] represents frequency-division 
multiplexing of v1 [n] and v2[n]. 
p(n] 
+ 
g[n] 
+ 
p[n-1] 
Figure P8.20 
BASIC PROBLEMS 
8.21. In Sections 8.1 and 8.2, we analyzed the sinusoidal amplitude modulation and de-
modulation system of Figure 8.8, assuming that the phase (} c of the carrier signal 
was zero. 
(a) For the more general case of arbitrary phase(} c in the figure, show that the signal 
in the demodulation system can be expressed as 
1 
1 
w(t) = 2x(t) + 2x(t)cos(2wct + 20c). 
(b) If x(t) has a spectrum that is zero for lwl ;:::: WM, determine the relationships 
required among w co [the cutoff frequency of the ideallowpass filter in Figure 
8.8(b)], we (the carrier frequency), and WM so that the output of the lowpass 
filter is proportional to x(t). Does your answer depend on the carrier phase Oc? 
8.22. In Figure P8.22(a), a system is shown with input signal x(t) and output signal y(t). 
The input signal has the Fourier transform X(jw) shown in Figure P8.22(b). Deter-
mine and sketch Y(jw ), the spectrum of y(t). 
T -
- --'-5p__._
_ 3w-l-
1
l,_.__p_._5w-w 
1---...... y(t) 
-3w 
3w 
w 
cos(5wt) 
cos(3wt) 
(a) 
Figure P8.22 

632 
Communication Systems 
Chap.8 
X(jw) 
& 
w 
-2w 
2w 
(b) 
Figure PS.22 
Continued 
8.23. In Section 8.2, we discussed the effect of a loss of synchronization in phase between 
the carrier signals in the modulator and demodulator in sinusoidal amplitude modu-
lation. We showed that the output of the demodulation is attenuated by the cosine of 
the phase difference, and in particular, when the modulator and demodulator have 
a phase difference of 'TT/2, the demodulator output is zero. As we demonstrate in 
this problem, it is also important to have frequency synchronization between the 
modulator and demodulator. 
Consider the amplitude modulation and demodulation systems in Figure 8.8 
with () c = 0 and with a change in the frequency of the demodulator carrier so that 
w(t) = y(t) cos wat, 
where 
y(t) = x(t)coswct. 
Let us denote the difference in frequency between the modulator and demodulator 
as !iw (i.e., wa - We = !iw ). Also, assume that x(t) is band limited with X(jw) = 0 
for lw I <:: w M, and assume that the cutoff frequency w co of the lowpass filter in the 
demodulator satisfies the inequality 
(a) Show that the output of the lowpass filter in the demodulator is proportional to 
x(t) cos(!iwt). 
(b) If the spectrum of x( t) is that shown in Figure P8 .23, sketch the spectrum of the 
output of the demodulator. 
X(jw) 
& 
wM 
w 
Figure PS.23 
8.24. Figure P8.24 shows a system to be used for sinusoidal amplitude modulation, where 
x(t) is band limited with maximum frequency WM, so that X(jw) = 0, lwl > WM. 

Chap. 8 Problems 
633 
As indicated, the signal s(t) is a periodic impulse train with period T and with an 
offset from t = 0 of Ll. The system H (jw) is a bandpass filter. 
(a) With Ll = 0, WM = 7T/2T, w 1 = 7T!T, and wh = 37T/T, show that y(t) is pro-
portional to x(t)coswct, where w e= 27TIT. 
(b) If WM, W[, and wh are the same as given in part (a), but Ll is not necessarily 
zero, show that y(t) is proportional to x(t)cos(wct + 8c), and determine w e and 
8 c as a function of T and Ll. 
(c) Determine the maximum allowable value of WM relative toT such that y(t) is 
proportional to x(t) cos( w et + 8 c). 
x(t) 
H(jw) 
y(t) 
s(t) 
s(t) 
1-T-1 
t t I f t t 
o a 
(T+a) (2T+a) 
HOw) 
At 
- wh 
- wl 
wl 
wh 
w 
Figure P8.24 
8.25. A commonly used system to maintain privacy in voice communication is a speech 
scrambler. As illustrated in Figure P8.25(a), the input to the system is a normal 
speech signal x(t) and the output is the scrambled version y(t). The signal y(t) is 
transmitted and then unscrambled at the receiver. 
We assume that all inputs to the scrambler are real and band limited to the 
frequency wM; that is, X(jw) = 0 for lwl > WM. Given any such input, our pro-
posed scrambler permutes different bands of the spectrum of the input signal. In 
addition, the output signal is real and band limited to the same frequency band; that 
is, Y(jw) = 0 for lwl > WM. The specific algorithm for the scrambler is 
Y(jw) = X(j(w- WM)), 
Y(jw) = X(j(w + WM)), 
w >0, 
w <0. 
(a) If X(jw) is given by the spectrum shown in Figure P8.25(b), sketch the spec-
trum of the scrambled signal y(t). 
(b) Using amplifiers, multipliers, adders, oscillators, and whatever ideal filters you 
find necessary, draw the block diagram for such an ideal scrambler. 
(c) Again using amplifiers, multipliers, adders, oscillators, and ideal filters, draw a 
block diagram for the associated unscrambler. 

634 
x(t)----.. 
(Normal 
speech) 
Communication Systems 
(a) 
X(jw) 
& 
(b) 
Figure P8.25 
Chap.8 
x(t) 
8.26. In Section 8.2.2, we discussed the use of an envelope detector for asynchronous 
demodulation of an AM signal of the form y(t) = [x(t) + A] cos( wet + Oe). An 
alternative demodulation system, which also does not require phase synchroniza-
tion, but does require frequency synchronization, is shown in block diagram form 
in Figure P8.26. The lowpass filters both have a cutoff frequency of W e . The signal 
y(t) = [x(t) +A] cos( wet+ Oe). with Oe constant but unknown. The signal x(t) is 
band limited with X(jw) = 0, lwl > WM, and with WM <We. As we required for 
the use of the envelope detector, x(t) +A > 0 for all t. 
Show that the system in Figure P8.26 can be used to recover x(t) from y(t) 
without knowledge of the modulator phase (} e. 
)----1~ Lowpass 1-----J~ 
filter 
y(t) 
}----1~ Lowpass 1-----J~I 
filter 
Figure P8.26 
Square 
root 
r(t) 
8.27. As discussed in Section 8.2.2, asynchronous modulation-demodulation requires the 
injection of the carrier signal so that the modulated signal is of the form 

Chap. 8 Problems 
635 
y(t) = [A + x(t)] cos( wet+ Oe), 
(P8.27-1) 
where A+ x(t) > 0 for all t. The presence of the carrier means that more transmitter 
power is required, representing an inefficiency. 
(a) Let x(t) = cos WMt with WM <we and A+ x(t) > 0. For a periodic signal y(t) 
with period T, the average power over time is defined as P y = (liT) J T y2(t) dt. 
Determine and sketch Py for y(t) in eq. (P8.27-1). Express your answer as a 
function of the modulation index m, defined as the maximum absolute value of 
x(t) divided by A. 
(b) The efficiency of transmission of an amplitude-modulated signal is defined to 
be the ratio of the power in the sidebands of the signal to the total power in the 
signal. With x(t) = coswMt, and with WM <We and A+ x(t) > 0, determine 
and sketch the efficiency of the modulated signal as a function of the modulation 
index m. 
8.28. In Section 8.4 we discussed the implementation of single-sideband modulation using 
90° phase-shift networks, and in Figures 8.21 and 8.22 we specifically illustrated 
the system and associated spectra required to retain the lower sidebands. 
Figure P8.28(a) shows the corresponding system required to retain the upper 
sidebands. 
x(t)~ 
y(t) 
{
+j ,w>O 
H(jw)= 
. 
0 
-J ,W< 
(a) 
X(jw) 
w 
(b) 
Figure P8.28 

636 
Communication Systems 
Chap. 8 
(a) With the same X(jw) illustrated in Figure 8.22, sketch Y1(jw), Y2(jw), and 
Y(jw) for the system in Figure P8.28(a), and demonstrate that only the upper 
sidebands are retained. 
(b) For X(jw) imaginary, as illustrated in Figure P8.28(b), sketch Y1 (jw ), Y2(jw ), 
and Y(jw) for the system in Figure P8.28(a), and demonstrate that, for this case 
also, only the upper sidebands are retained. 
8.29. Single-sideband modulation is commonly used in point-to-point voice communica-
tion. It offers many advantages, including effective use of available power, con-
servation of bandwidth, and insensitivity to some forms of random fading in the 
channel. In double-sideband suppressed carrier (DSB/SC) systems the spectrum 
of the modulating signal appears in its entirety in two places in the transmitted 
spectrum. Single-sideband modulation eliminates this redundancy, thus conserving 
bandwidth and increasing the signal-to-noise ratio within the remaining portion of 
the spectrum that is transmitted. 
In Figure P8.29(a), two systems for generating an amplitude-modulated 
single-sideband signal are shown. The system on the top can be used to generate a 
single-sideband signal for which the lower sideband is retained, and the system on 
the bottom can produce a single-sideband signal for which the upper sideband is 
retained. 
(a) For X(jw) as shown in Figure P8.29(b), determine and sketch S(jw), the 
Fourier transform of the lower sideband modulated signal, and R(jw ), the 
Fourier transform of the upper sideband modulated signal. Assume that 
We> W3. 
The upper sideband modulation scheme is particularly useful with voice 
communication, as any real filter has a finite transition region for the cutoff 
(i.e., near we). This region can be accommodated with negligible distortion, 
since the voice signal does not have any significant energy near w = 0 (i.e., for 
lwl < WJ = 27T X 40Hz). 
(b) Another procedure for generating a single-sideband signal is termed the phase-
shift method and is illustrated in Figure P8.29(c). Show that the single-
sideband signal generated is proportional to that generated by the lower 
sideband modulation scheme of Figure P8.29(a) [i.e., p(t) is proportional 
to s(t)]. 
(c) All three AM-SSB signals can be demodulated using the scheme shown on 
the right-hand side of Figure P8.29(a). Show that, whether the received sig-
nal is s(t), r(t), or p(t), as long as the oscillator at the receiver is in phase 
with oscillators at the transmitter, and w = we. the output of the demodulator 
is x(t). 
The distortion that results when the oscillator is not in phase with the trans-
mitter, called quadrature distortion, can be particularly troublesome in data 
communication. 
8.30. Amplitude modulation with a pulse-train carrier may be modeled as in Figure 
P8.30(a). The output of the system is q(t). 
(a) Let x(t) be a band-limited signal [i.e., X(jw) = 0, lwl ;;:::: 7T/T], as shown in 
Figure P8.30(b). Determine and sketch R(jw) and Q(jw). 

x(t) 
- w 
w 
w 
x(t) 
(a) 
X(jw) 
(I) 
(b) 
x(t) 
p(t) 
H~
' w) +j 
(I) 
- j 
(c) 
Figure P8.29 
637 

x(t) 
638 
Communication Systems 
Chap.8 
(b) Find the maximum value of a such that w(t) = x(t) with an appropriate filter 
M(jw). 
(c) Determine and sketch the compensating filter M(jw) such that w(t) = x(t). 
PAM system 
r(t) 
h(t) 
_Ih_ 1---i-q-(t_,) ~~ 
- tJ./2 tJ./2 
p(t)= ~ 8(t - nT) 
n=-co 
(a) 
XOw) 
cb 
w 
1!: 
T 
(b) 
Figure P8.30 
8.31. Let x[ n] be a discrete-time signal with spectrum X ( eiw ), and let p( t) be a continuous-
time pulse function with spectrum P(jw ). We form the signal 
+oo 
y(t) = .2: x[n]p(t - n). 
n = - oo 
(a) Determine the spectrum Y(jw) in terms of X(eiw) and P(jw ). 
(b) If 
p(t) = { cos 8'7Tt, 
0, 
determine P(jw) and Y(jw ). 
O:st:sl 
elsewhere ' 
8.32. Consider a discrete-time signal x [n] with Fourier transform shown in Figure 
P8.32(a). The signal is amplitude modulated by a sinusoidal sequence, as indi-
cated in Figure P8.32(b). 

Chap. 8 Problems 
639 
(a) Determine and sketch Y(ejw), the Fourier transform of y[n]. 
(b) A proposed demodulation system is shown in Figure P8.32(c). For what value 
of Oc, Wtp. and Gwill x[n] = x[n]? Are any restrictions on we andw1p necessary 
to guarantee that x[n] is recoverable from y[n]? 
X(ei"') 
I it\ 
I 
'IT 
wo 
wo 
'IT 
(a) 
x[n]-...... T'i"i 
cosw 0n 
(b) 
H(ei"') 
Iil 
1-----l~ x[n] 
-w.IP 
(t}_fp 
Figure P8.32 
8.33. Let us consider the frequency-division multiplexing of discrete-time signals x;[n], 
i = 0, 1, 2, 3. Furthermore, each x;[n] potentially occupies the entire frequency 
band ( -7r < w < 7r). The sinusoidal modulation of upsampled versions of each 
of these signals may be carried out by using either double-sideband techniques or 
single-sideband techniques. 
(a) Suppose each signal x;[n] is appropriately upsampled and then modulated with 
cos[i(7r/4)n]. What is the minimum amount ofupsampling that must be carried 
out on each x;[n] in order to ensure that the spectrum of the FDM signal does 
not have any aliasing? 
(b) If the upsampling of each x;[n] is restricted to be by a factor of 4, how would 
you use single-sideband techniques to ensure that the FDM signal does not have 
any aliasing? Hint: See Problem 8.17. 

640 
Communication Systems 
Chap. 8 
ADVANCED PROBLEMS 
8.34. In discussing amplitude modulation systems, modulation and demodulation were 
carried out through the use of a multiplier. Since multipliers are often difficult to 
implement, many practical systems use a nonlinear element. In this problem, we 
illustrate the basic concept. 
In Figure P8.34, we show one such nonlinear system for amplitude modu-
lation. The system consists of squaring the sum of the modulating signal and the 
carrier and then bandpass filtering to obtain the amplitude-modulated signal. 
Assume that x(t) is band limited, so that X(jw) = 0, lwl > WM.' Deter-
mine the bandpass filter parameters A, w1, and wh such that y(t) is an amplitude-
modulated version of x(t) [i.e., such that y(t) = x(t) cos Wet] . Specify the necessary 
constraints, if any, on We and WM. 
y(t) 
Figure P8.34 
8.35. The modulation-demodulation scheme proposed in this problem is similar to sinu-
soidal amplitude modulation, except that the demodulation is done with a square 
wave with the same zero-crossings as cos wet. The system is shown in Figure 
P8.35(a); the relation between cos w et and p(t) is shown in Figure P8.35(b). Let the 
input signal x(t) be a band-limited signal with maximum frequency WM <We, as 
shown in Figure P8.35(c). 
(a) Sketch and dimension the real and imaginary parts of Z(jw ), P(jw ), and Y(jw ), 
the Fourier transforms of z(t), p(t), and y(t), respectively. 
(b) Sketch and dimension a filter H(jw) so that v(t) = x(t). 
Modulation 
Demodulation 
--------., 
--------------- --- -- -., 
I 
I 
I 
x(t) ~0-.....__z(_tl _ _..-t•~@l--y-(t)___,•~~: v(t) 
it 
t 
~ 
: coswct 
I 
(a) 
p(t) 
I 
I 
------------ ----- ----1 
Figure P8.35 

Chap. 8 Problems 
I 
I 
~Rill r-
(b) 
<R-e {X(jw)} 
,;h, 
(c) 
. t 
w 
Figure P8.35 
Continued 
641 
dm{X(jw)} 
w 
8.36. The accurate demultiplexing-demodulation of radio and television signals is gener-
ally performed using a system called the superheterodyne receiver, which is equiv-
alent to a tunable filter. The basic system is shown in Figure P8.36(a). 
(a) The input signal y(t) consists of the superposition of many amplitude-modulated 
signals that have been multiplexed using frequency-division multiplexing, so 
that each signal occupies a different frequency channel. Let us consider one such 
channel that contains the amplitude-modulated signal y1 (t) = XI (t) cos w et, 
with spectrum Y1 (jw) as depicted at the top of Figure P8.36(b). We want to de-
multiplex and demodulate YI (t) to recover the modulating signal XJ (t), using the 
system of Figure P8.36(a). The coarse tunable filter has the spectrum H 1 (jw) 
shown at the bottom of Figure P8.36(b). Determine the spectrum Z(jw) of the in-
put signal to the fixed selective filter H2(jw ). Sketch and label Z(jw) for 
w > 0. 
(b) The fixed frequency-selective filter is a bandpass type centered around the fixed 
frequency w 1, as shown in Figure P8.36(c). We would like the output of the 
filter with spectrumHz(jw) to be r(t) = XJ(t)cosw 1t. In terms of We and WM, 
what constraint must WT satisfy to guarantee that an undistorted spectrum of 
x 1 (t) is centered around w = w f ? 
(c) What must G, a, and {3 be in Figure P8.36(c) so that r(t) = x1(t)cosw 1t? 
8.37. The following scheme has been proposed to perform amplitude modulation: The in-
put signal x(t) is added to the carrier signal cos Wet and then put through a nonlinear 

642 
We 
W e 
Coarse 
tunable 
filter 
H1(jw) 
Y(jw) 
H1(jw) 
K 
we- w-r 
H2(jw) 
Gl 
I 
a 
w, 
~ 
(c) 
Communication Systems 
Oscilator 
w 
cos(we + w1)t 
z(t) 
X 
(a) 
Y1(jw) 
(we- wM) We(we+wM) 
Input signal 
we-wM We We+wM 
Coarse tunable filter 
(b) 
Figure P8.36 
Fixed 
selective 
r(t) 
filter 
H2(jw) 
W
· 
We+w-r w 
Chap.S 
To 
demodulator 

Chap. 8 Problems 
device, so that the output z(t) is related to the input by 
z(t) = eY(t) -
1, 
y(t) = x(t) +COS Wet. 
643 
This is illustrated in Figure P8.37(a). Such a nonlinear relation can be implemented 
through the current-voltage characteristics of a diode, where, with i(t) and v(t) the 
diode and current and voltage, respectively, 
i(t) = Ioeav(t) - 1 (a real). 
To study the 'effects of nonlinearity, we can examine the spectrum of z(t) and how 
it relates to X(jw) and We. To accomplish this, we use the power series for eY, 
which is 
1 
1 
eY = 1 + y + 2 yz + 6l + ... . 
(a) If the spectrum of x(t) is given by Figure P8.37(b), and if We = 100w1, sketch 
and label Z(jw ), the spectrum of z(t), using the first four terms in the power 
series for eY. 
(b) The bandpass filter has parameters as shown in Figure P8.37(c). Determine the 
range of a and the range of {3 such that r(t) is an amplitude-modulated version 
of x(t). 
~ 
'it)-- l 
, ~ .•-t 
cos wet 
(a) 
X(jw) 
z(t) 
BPF 
H(jw) 
-w 1 
w 1 
w 
(b) 
H(jw) 
D 
D 
-13 -a 
a 
13 
w 
(c) 
r(t) 
Figure P8.37 
8.38. In Figure P8.38(a), a communication system is shown that transmits a band-limited 
signal x(t) as periodic bursts of high-frequency energy. Assume that X(jw) = 0 for 
lwl > WM. Two possible choices, m1 (t) and m2(t), are considered for the modulating 
signal m(t). m 1 (t) is a periodic train of sinusoidal pulses, each of duration D, as 
shown in Figure P8.38(b). That is, 

644 
Communication Systems 
Chap. 8 
00 
m1 (t) = 2: p(t - kT), 
k = - oo 
Where 
(t) = { cos Wet, 
ltl < (D/2) 
p 
0, 
ltl > (D/2) . 
m2(t) is cos Wet periodically blanked or gated; that is, m2(t) = g(t) cos wet, where 
g(t) is as shown in Figure P8.38(b). 
m(t) 
>(!)-~ 
p(t) 
:o-1-rY· 
- D/22 - _v~D/2 
m1(t) 
:-f'l-1-"-, 
_ 012 r__v __ v:J:D/2 
g(t) 
I 
- D/2 
D/2 
m2(t) 
:-o-1-"-, 
(b) 
I 
Figure P8.38 
:T\_[S_T\_' 
2 __ v_::v:JJ 
T 
----+- r(t) 

Chap. 8 Problems 
645 
The following relationships between the parameters T, D, we, and WM are 
assumed: 
D<T, 
27T 
We>> D' 
27T 
T >2wM. 
Also, assume that [sin(x)]/x is negligible for x >> 1. 
Determine whether, for some choice of Wip• either m1 (t) or m2(t) will result in 
a demodulated signal x(t). For each case in which your answer is yes, determine an 
acceptable range for w 1p. 
8.39. Suppose we wish to communicate one of two possible messages: message m0 or 
message m1• To do so, we will send a burst of one of two frequencies over a time 
interval of ltmgth T. Note that T is independent of which message is being trans-
mitted. For message mo we will send coswot, and for message m1 we will send 
cos w 1 t. Thus, a burst b(t) will look as shown in Figure P8.39(a). Such a communi-
m0(t) 
'rv'\/\/\ 
m1(t) 
fu'V'v"v"v'V'T 
(a) 
cosw0t 
b(t) 
(b) 
Line "m0 " 
Line "m1" 
Figure P8.39 
Choose 
maximum 
of the 
absolute 
values 

646 
Communication Systems 
Chap.B 
cation system is called frequency shift keying (FSK). When the burst of frequency 
b(t) is received, we wish to determine whether it represents message mo or message 
m1• To accomplish this, we do as illustrated in Figure P8.39(b). 
(a) Show that the maximum difference between the absolute values of the two lines 
in Figure P8.39(b) occurs when cos wot and cos w 1 t have the relationship 
JoT coswotcosw 1tdt = 0. 
(b) Is it possible to choose w0 and w 1 such that there is no interval of length T for 
which 
foT coswotcosw 1tdt = 0? 
8.40. In Section 8.3, we discussed the use of sinusoidal modulation for frequency-
division multiplexing whereby several signals are shifted into different frequency 
bands and then summed for simultaneous transmission. In the current problem, we 
explore another multiplexing concept referred to as quadrature multiplexing. In this 
multiplexing procedure, two signals can be transmitted simultaneously in the same 
frequency band if the two carrier signals are 90° out of phase. The multiplexing sys-
) tern is shown in Figure P8.40(a) and the demultiplexing system in Figure P8.40(b). 
x1 (t) and x2(t) are both assumed to be band limited with maximum frequency w M, 
so that X 1 (jw) = X2 (jw) = 0 for lw I > w M. The carrier frequency w c is assumed 
to be greater than w M. Show that Yl (t) = x1 (t) and Y2(t) = x2(t). 
x1(t) __ 
....,..-{ 
r(t) =multiplexed signal 
(a) 
Figure P8.40 
8.41. In Problem 8.40, we introduced the concept of quadrature multiplexing, whereby 
two signals are summed after each has been modulated with carrier signals of iden-
tical frequency, but with a phase difference of 90°. The corresponding discrete-time 
multiplexer and demultiplexer are shown in Figure P8.41. The signals x1 [n] and 
x2[n] are both assumed to be band limited with maximum frequency WM, so that 

(b) 
Figure P8.41 

648 
Communication Systems 
Chap. 8 
(a) Determine the range of values for W e so that x1 [n] and x2[n] can be recovered 
from r[n]. 
(b) With We satisfying the conditions in part (a), determine H(ejw) so that YI [n] = 
XI[n] and Y2[n] = x2[n]. 
8.42. In order to avoid intersymbol interference, pulses used in PAM systems are designed 
to be zero at integer multiples of the symbol spacing T 1 • In this problem, we develop 
a class of pulses which are zero at t = kTI, k = ± 1, ::!::2, ± 3, .... 
Consider a pulse PI (t) that is real and even and that has a Fourier transform 
PI (jw ). Also, assume that 
P 1 (- jw + j ~) = - P1 (jw + j ~ ). 0 :.,; w :.,; 
(a) Define a periodic sequence fh (t) with Fourier transform 
P1 (jw) = m~oo pi (jw - jm ~~). 
and show that 
(b) Use the result of the previous part to show that for some T 
ih (t) = 0, t = kT, k = 0, ::!::2, ::!::4, .... 
(c) Use the result of the previous part to show that 
PI(kTJ) = 0, k = ::!:: 1, ::!::2, ::!::3, .... 
(d) Show that a pulse p(t) with Fourier transform 
{ 
1 + PI(jw), 
P(jw) = 
P 1(jw), 
0, 
also has the property that 
lwl:.,; ~ 
~ :.,; lwl:.,; ~7 
otherwise 
p(kT1) = 0, 
k = ::!:: 1, ::!::2, ::!::3, .... 
8.43. The impulse response of a channel used for PAM communication is specified by 
h(t) = 
10,000~ - I.ooor u(t). 
It is assumed that the phase response of the channel is approximately linear in the 
bandwidth of the channel. A pulse that is received after passing through the channel 
is processed using an LTI systemS with impulse response g(t) in order to compen-
sate for the nonuniform gain over the channel bandwidth. 

Chap. 8 Problems 
649 
(a) Verify that if g(t) has the Fourier transform 
G(jw) = A+ jBw, 
where A and B are real constants, then g(t) can compensate for the nonuniform 
gain over the channel bandwidth. Determine the values of A and B. 
(b) It is proposed that S be implemented with the system shown in Figure P8.43. 
Determine the values of the gain factors a ar-d {3 in this system. 
x(t) 
~ 
x(t) 
(Received signal 
before compensation) 
~y(t) 
(Received signal 
after compensation) 
Figure P8.43 
8.44. In this problem, we explore an equalization method used to avoid intersymbol in-
terference caused in PAM systems by the channel having nonlinear phase over its 
bandwidth. 
When a PAM pulse with zero-crossings at integer multiples of the symbol 
spacing T1 is passed through a channel with nonlinear phase, the received pulse may 
no longer have zero-crossings at times that are integer multiples of T 1• Therefore, in 
order to avoid intersymbol interference, the received pulse is passed through a zero-
forcing equalizer, which forces the pulse to have zero-crossings at integer multiples 
ofT 1 • This equalizer generates a new pulse y(t) by summing up weighted and shifted 
versions of the received pulse x(t). The pulse y(t) is given by 
N 
y(t) = L a1x(t - lTt ), 
l = - N 
where the a1 are all real and are chosen such that 
y(kTt) = { ~: 
k = 0 
k = ±1, ±2, ±3, ... , ±N . 
(P8.44-1) 
(a) Show that the equalizer is a filter and determine its impulse response. 
(b) To illustrate the selection of the weights a1, let us consider an example. If 
x(OTt) = 0.0, x(- Tt) = 0.2, x(Tt) = -0.2, and x(kTt) = 0 for ikl > 1, de-
termine the values of ao, a1, and a- 1 such that y(±Tt) = 0. 

650 
Communication Systems 
Chap. 8 
8.45. A band-limited signal x(t) is to be transmitted using narrowband FM techniques. 
That is, the modulation index m, as defined in Section 8.7, is much less than n/2. 
Before x(t) is transmitted to the modulator, it is processed so that X(jw )lw = O = 0 
and I x( t) I < 1. This normalized x( t) is now used to angle-modulate a carrier to form 
the FM signal 
(a) Determine the instantaneous frequency w;. 
(b) Using eqs. (8.44) and (8.45), the narrowband assumption (m << n/2), and the 
preceding normalization conditions, show that 
y(t) =COS Wet- (m [ , X(T)dT) sinwct. 
(c) What is the relationship among the bandwidth of y(t), the bandw!dth of x(t), 
and the carrier frequency w c? 
8.46. Consider the complex exponential function of time, 
s(t) = eiO(tl, 
(P8.46-1) 
where O(t) = w 0t 212. 
Since the instantaneous frequency w; = dO/dt is also a function of time, the 
signal s(t) may be regarded as an FM signal. In particular, since the signal sweeps 
linearly through the frequency spectrum with time, it is often called a frequency 
"chirp" or "chirp signal." 
(a) Determine the instantaneous frequency. 
(b) Determine and sketch the magnitude and phase of the Fourier transform of the 
"chirp signal." To evaluate the Fourier transform integral, you may find it help-
ful to complete the square in the exponent in the integrand and to use the relation 
J
+oo 
1.:: 
• 2 
{ 'TT 
eJz dz = 
.i - (1 + j). 
- co 
\ 
2 
LTI 
x(t) _ ___,~@-----+1 h(t)=s(t) 1-1-....,•~@-----+ y(t) 
t 
t 
s*(t) 
s*(t) 
Figure P8.46 

Chap. 8 Problems 
651 
(c) Consider the system in Figure P8.46, in which s(t) is the "chirp signal" in 
eq. (P8.46-1). Show that y(t) = X(jw 0t), where X(jw) is the Fourier trans-
form of x(t). 
(Note: The system in Figure P8.46 is referred to as the "chirp " transform algo-
rithm and is often used in practice to obtain the Fourier transform of a signal.) 
8.47. In Section 8.8 we considered synchronous discrete-time modulation and demod-
ulation with a sinusoidal carrier. In this problem we want to consider the effect of 
a loss in synchronization in phase and/or frequency. The modulation and demod-
ulation systems are shown in Figure P8.47(a), where both a phase and frequency 
difference between the modulator and demodulator carriers is indicated. Let the 
frequency difference wd- We be denoted as !1w and the phase difference (}d- (}c 
as /1(}. 
(a) If the spectrum of x[n] is that shown in Figure P8.47(b), sketch the spectrum 
of w[n], assuming !1w = 0. 
(b) If !1w = 0, show that w can be chosen so that the output r[n] is r[n] = 
x [n] cos !1(}. In particular, what is r[n] if /1(} = 'TT/2? 
(c) For /1(} = 0, and w = WM + !1w , show that the output r[n] = x[n] cos[l1wn] 
(assume that !1w is small). 
l 
x[n) --.....~ y[n) 
1-----. r[n) 
- w 
w w 
(a) 
(b) 
Figure P8.47 
8.48. In this problem, we consider the analysis of discrete-time amplitude modulation of 
a pulse-train carrier. The system to be considered is shown in Figure P8.48(a). 

652 
Communication Systems 
Chap.8 
(a) Determine and sketch the discrete-time Fourier transform of the periodic 
square-wave signal p[n] in Figure P8.48(a). 
(b) Assumethatx[n]hasthespectrumshowninFigureP8.48(b). With wM = 7T/2N 
and with M = 1 in Figure P8.48(a), sketch Y(ejw), the Fourier transform of 
y[n]. 
(c) Now assume thatX(ejw) is known to be band limited with X(ejcJ ) = 0, WM .< 
w < 27T - WM , but is otherwise unspecified. For the system of Figure P8.48(a), 
determine, as a function of N, the maximum allowable value of w M that will 
permit x[n] to be recovered from y[n]. Indicate whether your result depends 
onM. 
(d) With w M and N satisfying the condition determined in part (c), state or show in 
block diagram form how to recover x[n] from y[n]. 
x[n)~~y[n) 
t 
p[n] 
p[n] 
IIIIII ........... IIIIII ........... IIIIII ........... I 
01• • •M 
N (N+M) 
n 
(a) 
'IT 
w 
(b) 
Figure P8.48 
8.49. In practice it is often very difficult to build an amplifier at very low frequencies. 
Consequently, low-frequency amplifiers typically exploit the principles of ampli-
tude modulation to shift the signal into a higher-frequency band. Such an amplifier 
is referred to as a chopper amplifier and is illustrated in the block-diagram form in 
Figure P8.49. 
>(1)--y--8 
y(t) 
s(t) 
s(t) 
Figure P8.49 

Chap. B Problems 
653 
s(t) 
Cl 1ch Cl 
, - T 
0 T T 
T 
42 
H1(jw) 
Ai 
-~ 
_:rr 
:rr 
31r 
w 
T 
T 
T 
T 
H2(jw) 
11 
I 
_:rr 
:rr 
w 
T 
T 
Figure P8.49 
Continued 
(a) Determine in terms ofT the highest allowable frequency present in x(t), if y(t) 
is to be proportional to x(t) (i.e., if the overall system is to be equivalent to an 
amplifier). 
(b) With x(t) bandlimited as specified in part (a), determine the gain of the overall 
system in Figure P8.49 in terms of A and T. 

9 
THE LAPLACE TRANSFORM 
9.0 INTRODUCTION 
654 
In the preceding chapters, we have seen that the tools of Fourier analysis are extremely 
useful in the study of many problems of practical importance involving signals and LTI 
systems. This is due in large part to the fact that broad classes of signals can be represented 
as linear combinations of periodic complex exponentials and that complex exponentials are 
eigenfunctions of LTI systems. The continuous-time Fourier transform provides us with 
a representation for signals as linear combinations of complex exponentials of the form 
esr with s = jw. However the eigenfunction property introduced in Section 3.2 and many 
of its consequences apply as well for arbitrary values of s and not only those values that 
are purely imaginary. This observation leads to a generalization of the continuous-time 
Fourier transform, known as the Laplace transform, which we develop in this chapter. In 
the next chapter we develop the corresponding discrete-time generalization known as the 
z-transform. 
As we will see, the Laplace and z-transforms have many of the properties that make 
Fourier analysis so useful. Moreover, not only do these transforms provide additional tools 
and insights for signals and systems that can be analyzed using the Fourier transform, 
but they also can be applied in some very important contexts in which Fourier transforms 
cannot. For example Laplace and z-transforms can be applied to the analysis of many un-
stable systems and consequently play an important role in the investigation of the stability 
or instability of systems. This fact, combined with the algebraic properties that Laplace 
and z-transforms share with Fourier transforms, leads to a very important set of tools for 
system analysis and in particular for the analysis of feedback systems, which we develop 
in Chapter 11. 

Sec. 9.1 
The Laplace Transform 
655 
9. 1 THE lAPlACE TRANSFORM 
In Chapter 3, we saw that the response of a linear time-invariant system with impulse 
response h(t) to a complex exponential input of the form est is 
y(t) = H(s)es1, 
(9.1) 
where 
H(s) = I:"" h(t)e- st dt. 
(9.2) 
For s imaginary (i.e., s = jw ), the integral in eq. (9.2) corresponds to the Fourier trans-
form of h(t). For general values of the complex variable s, it is referred to as the Laplace 
transform of the impulse response h(t). 
The Laplace transform of a general signal x(t) is defined as1 
I
+oo 
X(s) g 
- oo x(t)e- st dt, 
(9.3) 
and we note in particular that it is a function of the independent variable s corresponding 
to the complex variable in the exponent of e-st. The complex variables can be written as 
s = a- + jw, with a- and w the real and imaginary parts, respectively. For convenience, 
we will sometimes denote the Laplace transform in operator form as .C{x(t)} and denote 
the transform relationship between x(t) and X(s) as 
.£ 
x(t) ~ 
X(s). 
When s = jw, eq. (9.3) becomes 
I 
+ oo 
X(jw) = 
-oo x(t)e- Jwt dt, 
which corresponds to the Fourier transform of x(t); that is, 
X(s)ls= jw = rr:{x(t)}. 
(9.4) 
(9.5) 
(9.6) 
The Laplace transform also bears a straightforward relationship to the Fourier trans-
form when the complex variables is not purely imaginary. To see this relationship, consider 
X(s) as specified in eq. (9.3) with s expressed ass = a- + jw, so that 
I 
+ oo 
X(a- + jw) = 
-oo x(t)e-(u+jw)t dt, 
(9.7) 
1The transform defined by eq. (9.3) is often called the bilateral Laplace transform, to distinguish it from 
the unilateral Laplace transform, which we discuss in Section 9.9. The bilateral transform in eq. (9.3) involves 
an integration from - oo to + oo, while the unilateral transform has a form similar to that in eq. (9.3), but with 
limits of integration from 0 to +oo. As we are primarily concerned with the bilateral transform, we will omit the 
word "bilateral," except where it is needed in Section 9.9 to avoid ambiguity. 

656 
The Laplace Transform 
Chap. 9 
or 
f 
+ oo 
X(u + jw) = 
-oo [x(t)e-u1]e- Jwl dt. 
(9.8) 
We recognize the right-hand side of eq. (9.8) as the Fourier transform of x(t)e- u1; that 
is, the Laplace transform of x(t) can be interpreted as the Fourier transform of x(t) after 
multiplication by a real exponential signal. The real exponential e- ul may be decaying or 
growing in time, depending on whether u is positive or negative. 
To illustrate the Laplace transform and its relationship to the Fourier transform, let 
us consider the following example: 
Example 9.1 
Let the signal x(t) = e- a'u(t). From Example 4.1, the Fourier transform X(jw) con-
verges for a > 0 and is given by 
a > 0. 
(9.9) 
From eq. (9.3), the Laplace transform is 
X(s) = J" e-aru(t)e-"dt = ( " e-<s + a)tdt, 
-~ 
Jo 
(9.10) 
or, withs = u + jw, 
(9.11) 
By comparison with eq. (9.9) we recognize eq. (9.11) as the Fourier transform of 
e - <u+a)t u(t), and thus, 
X(u+jw) = (u+a)+jw' 
u+a > O, 
or equivalently, since s = u + jw and u = (Re{s}, 
That is, 
1 
X(s) = --, 
ffi.-e{s} > - a. 
s+a 
(9.12) 
(9.13) 
(9.14) 
For example, for a 
ffi.-e{s} > 0. 
0, x(t) is the unit step with Laplace transform X(s) = 1/s,' 
We note, in particular, that just as the Fourier transform does not converge for all 
signals, the Laplace transform may converge for some values of<R-e{s} and not for others. 
In eq. (9.13), the Laplace transform converges only for u = <R-e{s} > -a. If a is positive, 

Sec. 9.1 
The Laplace Transform 
then X(s) can be evaluated at CF = 0 to obtain 
1 
X(O+ jw) = --
jw +a· 
657 
(9.15) 
As indicated in eq. (9.6), for CF = 0 the Laplace transform is equal to the Fourier transform, 
as is evident in the preceding example by comparing eqs. (9.9) and (9.15). If a is negative 
or zero, the Laplace transform still exists, but the Fourier transform does not. 
Example 9.2 
For comparison with Example 9.1, let us consider as a second example the signal 
·Then 
or 
x(t) = -e- atu(- t). 
X(s) = - f_'"., e- ate- s1u(- t)dt 
= - r., e- (s+a)t dt, 
1 
X(s) = --. 
s+a 
(9.16) 
(9.17) 
(9.18) 
For convergence in this example, we require that <Re{s +a} < 0, or <Re{s} < - a; that is, 
<Re{s} < -a. 
(9.19) 
Comparing eqs. (9.14) and (9.19), we see that the algebraic expression for the 
Laplace transform is identical for both of the signals considered in Examples 9.1 and 9 .2. 
However, from the same equations, we also see that the set of values of s for which the 
expression is valid is very different in the two examples. This serves to illustrate the fact 
that, in specifying the Laplace transform of a signal, both the algebraic expression and 
the range of values of s for which this expression is valid are required. In general, the 
range of values of s for which the integral in eq.(9.3) converges is referred to as the region 
of convergence (which we abbreviate as ROC) of the Laplace transform. That is, the 
ROC consists of those values of s = CF + jw for which the Fourier transform of x(t)e- 171 
converges. We will have more to say about the ROC as we develop some insight into the 
properties of the Laplace transform. 
A convenient way to display the ROC is shown in Figure 9.1. The variables is a 
complex number, and in the figure we display the complex plane, generally referred to as 
the s-plane, associated with this complex variable. The coordinate axes are <Re{s} along 
the horizontal axis and dm{s} along the vertical axis. The horizontal and vertical axes are 
sometimes referred to as the CF-axis and the jw-axis, respectively. The shaded region in 
Figure 9.1(a) represents the set of points in the s-plane corresponding to the region of 
convergence for Example 9.1. The shaded region in Figure 9.1(b) indicates the region of 
convergence for Example 9.2. 

658 
The Laplace Transform 
s-plane 
s-plane 
- a 
CR.e 
j-a 
CR.e 
I 
I 
' 
I 
I 
I 
(a) 
(b) 
Figure 9.1 
(a) ROC for Example 9.1; (b) ROC for Example 9.2. 
Example 9.3 
In this example, we consider a signal that is the sum of two real exponentials: 
x(t) = 3e- 21u(t)- 2e- 1u(t). 
The algebraic expression for the Laplace transform is then 
X(s) = f_"'j3e- 21u(t)-2e- 1u(t)]e-s1 dt 
= 3 J:, e-
21e-
51u(t)dt- 2 J:, e-
1e-
51U(t)dt. 
Chap.9 
(9.20) 
(9.21) 
Each of the integrals in eq. (9.21) is of the same form as the integral in eq. (9.10), and 
consequently, we can use the result in Example 9.1 to obtain 
3 
2 
X(s) = -- -
-
-. 
s +2 
s +1 
(9.22) 
To determine the ROC we note that x(t) is a sum of two real exponentials, and 
from eq. (9.21) we see that X(s) is the sum of the Laplace transforms of each of the 
individual terms. The first term is the Laplace transform of 3e- 21 u(t) and the second 
term the Laplace transform of -2e- 1 u(t). From Example 9.1, we know that 
£ 
1 
e- 1 u(t) +---+ -
-1, 
s + 
£ 
1 
e- 21 u(t) +---+ --
s + 2' 
CR.e{s} > - 1, 
CR.e{s} > - 2. 
The set of values of CR.e{s} for which the Laplace transforms of both terms converge is 
CR-e{s} > - 1, and thus, combining the two terms on the right-hand side of eq. (9.22), we 
obtain 
£ 
s -1 
3e- 21u(t)-2e- 1u(t)+---+ 
2 
3 
2, 
CR-e{s} > -1. 
s + s + 
(9.23) 

Sec. 9.1 
The Laplace Transform 
659 
Example. 9.4 
In this example, we consider a signal that is the sum of a real and a complex exponential: 
x(t) = e- 21 u(t) + e- 1(cos 3t)u(t). 
Using Euler's relation, we can write 
and the Laplace transform of x(t) then can be expressed as 
+-
e- (! - 3j)1u(t)e-s1 dt 
1 J"" 
2 _., 
+! J"" e- <1+3j)lu(t)e- st dt. 
2 
- oo 
(9.24) 
(9.25) 
Each of the integrals in eq. (9.25) represents a Laplace transform of the type en-
countered in Example 9.1. It follows that 
.c 
1 
e- 21u(t) ~ 
8 + 2, 
(fl.e{s} > - 2, 
(9.26) 
e-0 - 3jl1u(t) ~ 
1 
(fl.e{s} > - 1, 
s + (1 - 3j)' 
(9.27) 
e - (l+3jl1u(t) ~ 
1 
(fl.e{s} > - 1. 
s + (1 + 3j)' 
(9.28) 
For all three Laplace transforms to converge simultaneously, we must have ffi.e{s} > - 1. 
Consequently, the Laplace transform of x(t) is 
1 
1( 
1 
) 
1( 
1 
) 
s + 2 + 2 s + (1 - 3 j) + 2 s + (1 + 3 j) ' 
ffi.e{s} > -1, 
. (9.29) 
or, with terms combined over a common denominator, 
- 21 
- 1 
.c 
2s2 + 5s + 12 
e 
u(t) + e 
(cos 3t)u(t) ~ 
(s2 + 2s + 10)(s + 2), 
ffi.e{s} > -1. 
(9.30) 
In each of the four preceding examples, the Laplace transform is rational, i.e., it is a 
ratio of polynomials in the complex variable s, so that 
X()= N(s) 
s 
D(s)' 
(9.31) 
where N(s) and D(s) are the numerator polynomial and denominator polynomial, respec-
tively. As suggested by Examples 9.3 and 9.4, X(s) will be rational whenever x(t) is a 
linear combination of real or complex exponentials. As we will see in Section 9. 7, rational 

660 
The Laplace Transform 
Chap.9 
transforms also arise when we consider LTI systems specified in terms of linear constant-
coefficient differential equations. Except for a scale factor, the numerator and denominator 
polynomials in a rational Laplace transform can be specified by their roots; thus, mark-
ing the locations of the roots of N(s) and D(s) in the s-plane and indicating the ROC 
provides a convenient pictorial way of describing the Laplace transform. For example, in 
Figure 9.2(a) we show the s-plane representation of the Laplace transform of Example 9.3, 
with the location of each root of the denominator polynomial in eq. (9.23) indicated with 
"X" and the locatio'l of the root of the numerator polynomial in eq. (9.23) indicated with 
"o." The corresponding plot of the roots of the numerator and denominator polynomials for 
the Laplace transform in Example 9.4 is given in Figure 9.2(b). The region of convergence 
for each of these examples is shaded in the corresponding plot. 
I 
I 
I 
I 
I 
I 
I 
)( ¥ 
- 2 - 11 
I 
I 
I 
I 
I 
I ' . 
* 
ol I 
I 
I 
I 
I 
-2 - 11 
I 
I 
01 
I 
"' 
I 
!Jm 
(a) 
!Jm 
(b) 
s-plane 
(R,e 
s-plane 
Figure 9.2 
s-plane representation 
ffi-e 
of the Laplace transforms for (a) Ex-
ample 9.3 and (b) Example 9.4. Each 
x in these figures marks the location 
of a pole of the corresponding Laplace 
transform-i.e., a root of the denomi-
nator. Similarly, each o marks a zero-
i.e., a root of the the numerator. The 
shaded regionsindicate the ROCs. 
For rational Laplace transforms, the roots of the numerator polynomial are com-
monly referred to as the zeros of X(s), since, for those values of s, X(s) = 0. The roots 
of the denominator polynomial are referred to as the poles of X(s), and for those values 
of s, X(s) is infinite. The poles and zeros of X(s) in the finite s-plane completely char-
acterize the algebraic expression for X(s) to within a scale factor. The representation of 
X(s) through its poles and zeros in the s-plane is referred to as the pole-zero plot of X(s). 

Sec. 9.1 
The Laplace Transform 
661 
However, as we saw in Examples 9.1 and 9.2, knowledge of the algebraic form of X(s) does 
not by itself identify the ROC for the Laplace transform. That is, a complete specification, 
to within a scale factor, of a rational Laplace transform consists of the pole-zero plot of 
the transform, together with its ROC (which is commonly shown as a shaded region in the 
s-plane, as in Figures 9.1 and 9.2). 
Also, while they are not needed to specify the algebraic form of a rational transform 
X(s), it is sometimes convenient to refer to poles or zeros of X(s) at infinity. Specifically, 
if the order of the denominator polynomial is greater than the order of the numerator poly-
nomial, then X (s) will become zero as s approaches infinity. Conversely, if the order of the 
numerator polynomial is greater than the order of the denominator, then X(s) will become 
unbounded as s approaches infinity. This behavior can be interpreted as zeros or poles at 
infinity. For example, the Laplace transform in eq. (9.23) has a denominator of order 2 and 
a numerator of order only 1, so in this case X(s) has one zero at infinity. The same is true 
for the transform in eq. (9.30), in which the numerator is of order 2 and the denominator is 
of order 3. In general, if the order of the denominator exceeds the order of the numerator 
by k, X(s) will have k zeros at infinity. Similarly, if the order of the numerator exceeds the 
order of the denominator by k, X(s) will have k poles at infinity. 
Example 9.5 
Let 
4 -
1 
x(t) = 5(t) - 3e 1 u(t) + 3e21 u(t). 
(9.32) 
The Laplace transform of the second and third terms on the right-hand side of eq. (9.32) 
can be evaluated from Example 9 .1. The Laplace transform of the unit impulse can be 
evaluated directly as 
I
+<» 
.C{5(t)} = 
- <» 5(t)e- "
1 dt = 1, 
(9.33) 
which is valid for any value of s. That is, the ROC of .C{5(t)} is the entire s-plane. Using 
this result, together with the Laplace transforms of the other two terms in eq. (9.32), we 
obtain 
4 1 
1 1 
X(s) = 1 - 3 s + 1 + 3 s - 2' 
(Jl.e{s} > 2, 
(9.34) 
or 
(s- 1)2 
X(s) = (s + 1)(s _ 2), 
(Jl.e{s} > 2, 
(9.35) 
where the ROC is the set of values of s for which the Laplace transforms of all three terms 
in x(t) converge. The pole-zero plot for this example is shown in Figure 9.3, together with 
the ROC. Also, since the degrees of the numerator and denominator of X(s) are equal, 
X(s) has neither poles nor zeros at infinity. 

662 
i 
I 
I 
I 
I 
I 
I 
I 
I 
The Laplace Transform 
s-plane 
----------X--~K»-X------~---
-1 
+1 +2 ' 
I 
I 
I 
I 
I 
I 
I 
I 
Figure 9.3 
Pole-zero plot and ROC for Example 9.5. 
Chap.9 
Recall from eq. (9.6) that, for s = jw, the Laplace transform corresponds to the 
Fourier transform. However, if the ROC of the Laplace transform does not include the 
jw-axis, (i.e., if ffi-e{s} = 0), then the Fourier transform does not converge. As we see 
from Figure 9.3, this, in fact, is the case for Example 9.5, which is consistent with the 
fact that the term (113)e21 u(t) in x(t) does not have a Fourier transform. Note also in this 
example that the two zeros in eq. (9.35) occur at the same value of s. In general, we will 
refer to the order of a pole or zero as the number of times it is repeated at a given location. 
In Example 9.5 there is a second-order zero at s = 1 and two first-order poles, one at 
s = - 1, the other at s = 2. In this example the ROC lies to the right of the rightmost 
pole. In general, for rational Laplace transforms, there is a close relationship between the 
locations of the poles and the possible ROCs that can be associated with a given pole-zero 
plot. Specific constraints on the ROC are closely associated with time-domain properties 
of x(t). In the next section, we explore some of these constraints and properties. 
9.2 THE REGION OF CONVERGENCE FOR LAPLACE TRANSFORMS 
In the preceding section, we saw that a complete specification of the Laplace transform re-
quires not only the algebraic expression for X(s), but also the associated region of conver-
gence. As evidenced by Examples 9.1 and 9 .2, two very different signals can have identical 
algebraic expressions for X(s), so that their Laplace transforms are distinguishable only by 
the region of convergence. In this section, we explore some specific constraints on the ROC 
for various classes of signals. As we will see, an understanding of these constraints often 
permits us to specify implicitly or to reconstruct the ROC from knowledge of only the al-
gebraic expression for X(s) and certain general charactelistics of x(t) in the time domain. 
Property 1: 
The ROC of X(s) consists of strips parallel to the jw-axis in the s-plane. 
The validity of this property stems from the fact that the ROC of X(s) consists of 
those values of s = (T + jw for which the Fourier transform of x(t)e- ar converges. That 

Sec. 9.2 
The Region of Convergence for Laplace Transforms 
663 
is, the ROC of the Laplace transform of x(t) consists of those values of s for which x(t)e- m 
is absolutely integrable:2 
L +oooo ix(t)le-at dt < oo. 
(9.36) 
Property 1 then follows, since this condition depends only on a-, the real part of s. 
Property 2: 
For rational Laplace transforms, the ROC does not contain any poles. 
Property 2 is easily observed in all the examples studied thus far. Since X (s) is infinite 
at a pole, the integral in eq. (9.3) clearly does not converge at a pole, and thus the ROC 
cannot contain values of s that are poles. 
Property 3: If x(t) is of finite duration and is absolutely integrable, then the ROC is 
the entire s-plane. 
The intuition behind this result is suggested in Figures 9.4 and 9.5. Specifically, a 
finite-duration signal has the property that it is zero outside an interval of finite duration, 
as illustrated in Figure 9.4. In Figure 9.5(a), we have shown x(t) of Figure 9.4 multiplied 
by a decaying exponential, and in Figure 9.5(b) the same signal multiplied by a growing 
Figure 9.4 
Finite-duration signal. 
' ,/Decaying exponential 
',~ 
Growing exponential 
(a) 
(b) 
Figure 9.5 
(a) Finite-duration signal of Figure 9.4 multiplied by a decaying exponen-
tial; (b) finite-duration signal of Figure 9.4 multiplied by a growing exponential. 
/ 
2For a more thorough and formal treatment of Laplace transforms and their mathematical properties, 
including convergence, see E. D. Rainville, The Laplace Transform: An Introduction (New York: Macmil-
lan, 1963), and R. V. Churchill and J. W. Brown, Complex Variables and Applications (5th ed.) (New York: 
McGraw-Hill, 1990). Note that the condition of absolute integrability is one of the Dirichlet conditions intro-
duced in Section 4.1 in the context of our discussion of the convergence of Fourier transforms. 

664 
The Laplace Transform 
Chap.9 
exponential. Since the interval over which x(t) is nonzero is finite, the exponential weight-
ing is never unbounded, and consequently, it is reasonable that the integrability of x(t) not 
be destroyed by this exponential weighting. 
A more formal verification of Property 3 is as follows: Suppose that x(t) is absolutely 
integrable, so that 
I
T2 
lx(t)l dt < oo. 
T1 
(9.37) 
For s = u + jw to be in the ROC, we require that x(t)e-ut be absolutely integrable, i.e., 
I
T2 
lx(t)le- ut dt < oo. 
T1 
(9.38) 
Eq. (9.37) verifies that sis in the ROC when CRe{s} = u = 0. For u > 0, the maximum 
value of e- ut over the interval on which x(t) is nonzero is e-uT1, and thus we can write 
(9.39) 
Since the right-hand side of eq.(9.39) is bounded, so is the left-hand side; therefore, the 
· s-plane for CR.e{s} > 0 must also be in the ROC. By a similar argument, if u < 0, then 
(9.40) 
and again, x(t)e-ut is absolutely integrable. Thus, the ROC includes the entire s-plane. 
Example 9.6 
Let 
x(t) = { e - at, 
0 < t < T 
0, 
otherwise 
(9.41) 
Then 
X(s) = 
e - at e-st dt = -
- [1 -
e - (s+a)T]. 
J
T 
1 
o 
s +a 
(9.42) 
Since in this example x(t) is of finite length, it follows from Property 3 that the ROC is 
the entire s-plane. In the form of eq. (9.42), X(s) would appear to have a pole at s = -a, 
which, from Property 2, would be inconsistent with an ROC that consists of the entir~ 
s-plane. In fact, however, in the algebraic expression in eq. (9.42), both numerator and 
denominator are zero at s = -a, and thus, to determine X(s) at s = - a, we can use 
L'h6pital's rule to obtain 
[ 
~(1 _ e - (s+a)T) ] 
lim X(s) = lim 
ds 
= lim Te - aT e - sT, 
s~-a 
s-+ -a 
!L(s +a) 
s--+ -a 
ds 
so that 
X(-a) = T. 
(9.43) 

Sec. 9.2 
The Region of Convergence for Laplace Transforms 
665 
It is important to recognize that, to ensure that the exponential weighting is bounded 
over the interval in which x(t) is nonzero, the preceding discussion relies heavily on the 
fact that x(t) is of finite duration. In the next two properties, we consider modifications of 
the result in Property 3 when x(t) is of finite extent in only the positive-time or negative-
time direction. 
Property 4: If x(t) is right sided, and if the line (Jl..,e{s} = cr0 is in the ROC, then all 
values of s for which CRe{s} > cr0 will also be in the ROC. 
A right-sided signal is a signal for which x(t) = 0 prior to some finite time T1, as 
illustrated in Figure 9 .6. It is possible that, for such a signal, there is no value of s for which 
the Laplace transform will converge. One example is the signal x(t) = e
12 u(t). However, 
suppose that the Laplace transform converges for some value of cr, which we denote by 
cro. Then 
f 
+oo 
- oo ix(t)ie - uot dt < oo, 
(9.44) 
or equivalently, since x(t) is right sided, 
(9.45) 
x(t) ~ 
T, 
Figure 9.6 
Right-sided signal. 
Then if cr 1 > cr0, it must also be true that x(t)e-u 11 is absolutely integrable, since e- u 11 
decays· faster than e-uot as t ~ 
+oo, as illustrated in Figure 9.7. Formally, we can say 
that with cr1 > cro, 
f 
oo ix(t)ie - ul t dt = f 
oo ix(t)ie -uot e - (ul - uo)t dt 
T1 
T1 
(9.46) 
:5 e - (ul-uo)Tl f 
oo ix(t)ie -uot dt. 
T1 
Since T1 is finite, it follows from eq. (9.45) that the right side of the inequality in eq. (9.46) 
is finite, and hence, x(t)e- u 11 is absolutely integrable. 
Note that in the preceding argument we explicitly rely on the fact that x(t) is right 
sided, so that, although with cr 1 > cr0, e-u11 diverges faster than e- uot as t ~ -oo, 
x(t)e- u 11 cannot grow without bound in the negative-time direction, since x(t) = 0 for 

666 
The Laplace Transform 
Chap. 9 
Figure 9. 7 
If x(t) is right sided 
and x(t)e- uot is absolutely integrable, 
then x(t)e-u,t; CT1 > CT0, will also be 
absolutely integrable. 
t < T 1• Also, in this case, if a points is in the ROC, then all the points to the right of s, 
i.e., all points with larger real parts, are in the ROC. For this reason, the ROC in this case 
is commonly referred to as a right-half plane. 
Property 5: If x(t) is left sided, and if the line ffi.e{s} = CTo is in the ROC, then all 
values of s for which ffi.e{s} < CTo will also be in the ROC. 
A left-sided signal is a signal for which x(t) = 0 after some finite time T2, as illus-
trated in Figure 9.8. The argument and intuition behind this property are exactly analogous 
to the argument and intuition behind Property 4. Also, for a left-sided signal, the ROC is 
commonly referred to as a left-half plane, as if a point s is in the ROC, then all points to 
the left of s are in the ROC. 
T2 
Figure 9.8 
Left-sided signal. 
Property 6: If x(t) is two sided, and if the line ffi.e{s} = CTo is in the ROC, then the 
ROC will consist of a strip in the s-plane that includes the line ffi.e{s} = CT0 . 
A two-sided signal is a signal that is of infinite extent for both t > 0 and t < 0, as 
illustrated in Figure 9.9(a). For such a signal, the ROC can be examined by choosing an 
arbitrary time T0 and dividing x(t) into the sum of a right-sided signal XR(t) and a left-
sided signal XL(t), as indicated in Figures 9.9(b) and 9.9(c). The Laplace transform of x(t) 
converges for values of s for which the transforms of both XR(t) and XL(t) converge. From 
Property 4, the ROC of .C{xR(t)} consists of a half-plane ffi.e{s} > CTR for some value CTR, 
and from Property 5, the ROC of .C{xL(t)} consists of a half-plane ffi.e{s} < CTL for some 
value O"L. The ROC of .C{x(t)} is then the overlap of these two half-planes, as indicated in 
Figure 9.10. This assumes, of course, that CTR < CTL, so that there is some overlap. If this 
is not the case, then even if the Laplace transforms of xR(t) and xL(t) individually exist, 
the Laplace transform of x(t) does not. 
· 

Sec. 9.2 
The Region of Convergence for Laplace Transforms 
x(t) 
---d 
"'----
(a) 
""-----
J 
(b) 
(c) 
Figure 9.9 · Two-sided signal divided into the sum of a right-sided and left-sided sig-
nal: (a) two-sided signal x(t); (b) the right-sided signal equal to x(t) for t > To and 
equal to 0 for t < T0; (c) the left-sided signal equal to x(t) for t < T0 and equal to 0 for 
t > T0 . 
(b) 
-· ... , 
O'R i 
I 
I 
I 
I 
I 
I 
I 
l s-plane 
I 
I 
I 
I 
I 
I O'L 
i 
I 
I 
I 
I 
I 
.. I 
(a) 
O'R I 
I 
I 
I 
I 
I I 
I 
s-plane 
(c) 
Figure 9.10 
(a) ROC for xR(t) in Figure 9.9; (b) ROC for xL(t) in Figure 
9.9; (c) the ROC for x(t) = xR(t) + xL(t), assuming that the ROCs in (a) and 
(b) overlap. 
667 

668 
The Laplace Transform 
Chap. 9 
~xample 9.7 
Let 
(9.47) 
as illustrated in Figure 9.11 for both b > 0 and b < 0. Sirice this is a two-sided signal, 
let us divide it into the sum of a right-sided and left-sided signal; that is, 
Figure 9.11 
Signal x(t) = e- bltl for both b > 0 and b < 0. 
From Example 9.1, 
and from Example 9.2, 
.c 
-1 
e+b1u(-t) ~ 
--, (Re{s} <+b. 
s - b 
(9.48) 
(9.49) 
(9.50) 
Although the Laplace transforms of each of the individual terms in eq. (9.48) have a 
region of convergence, there is no common region of convergence if b s 0, and thus, 
for those values of b, x(t) has no Laplace transform. If b > 0, the Laplace transform of 
x(t) is 
- bltl 
.c 
1 
1 
-2b 
e 
~ 
s + b - s _ b = s2 _ b2 ' 
-b < (Re{s} < +b. 
(9.51) 
The corresponding pole-zero plot is shown in Figure 9.12, with the shading indicating 
the ROC. 

Sec. 9.2 
The Region of Convergence for Laplace Transforms 
669 
~-- 1~-~ 
I 
I 
I 
I s-plane 
t 
I 
i 
I 
I 
I 
----*~~~--¥~---
-b: -: 
jb 
CR.e 
I 
I 
I 
I 
i.. . 
I 
I 
I 
t, ____ ,_ 
{.~ I 
Figure 9.12 
Pole-zero plot and ROC for Example 9.7. 
A signal either does not have a Laplace transform or falls into one of the four cate-
gories covered by Properties 3 through 6. Thus, for any signal with a Laplace transform, 
the ROC must be the entire s-plane (for finite-length signals), a left-half plane (for left-
sided signals), a right-half plane (for right-sided signals), or a single strip (for two-sided 
signals). In all the examples that we have considered, the ROC has the additional property 
that in each direction (i.e., <R.e{s} increasing and <R.e{s} decreasing) it is bounded by poles 
or extends to infinity. In fact, this is always true for rational Laplace transforms: 
Property 7: If the Laplace transformX(s) of x(t) is rational, then its ROC is bounded 
by poles or extends to infinity. In addition, no poles of X(s) are contained in the ROC. 
A formal argument establishing this property is somewhat involved, but its validity 
is essentially a consequence of the facts that a signal with a rational Laplace transform 
consists of a linear combination of exponentials and, from Examples 9.1 and 9.2, that 
the ROC for the transform of individual terms in this linear combination must have the 
property. As a consequence of Property 7, together with Properties 4 and 5, we have 
Property 8: If the Laplace transformX(s) of x(t) is rational, then if x(t) is right sided, 
the ROC is the region in the s-plane to the right of the rightmost pole. If x(t) is left sided, 
the ROC is the region in the s-plane to the left of the leftmost pole. 
To illustrate how different ROCs can be associated with the same pole-zero pattern, 
let us consider the following example: 
Example 9.8 
Let 
1 
X(s) = (s + l)(s + 2)' 
(9.52) 
with the associated pole-zero pattern in Figure 9.13(a). As indicated in Figures 9.13(b)-
(d), there are three possible ROCs that can be associated with this algebraic expression, 
corresponding to three distinct signals. The signal associated with the pole-zero pat-
tern in Figure 9.13(b) is right sided. Since the ROC includes the jw-axis, the Fourier 

670 
s-plane 
--X-X-+--
---,ffi=-.e-
-·-·= ··~' ~ 
.. . 
I 
I 
. . · ... ~··· .l 
(a) 
s-plane 
s-x-x-+--
-
-
. 
i 
ffi.e 
I 
I 
I 
I 
(c) 
The Laplace Transform 
1 t I 
I 
I 
9m 
·s-plane 
--x-1 ~
·
· ~~~~~ffi~.e 
I . 
i 
I 
I~ I 
i I 
1 I 
I I 
I : .j 
(b) 
s-plane 
-X-X-1---=10-.n 
i _ I 
l]l., 
I 
I 
I 
I 
I I 
. I 
(d) 
Chap. 9 
Figure 9.13 
(a) Pole-zero pattern for Example 9.8; (b) ROC corresponding 
to a right-sided sequence; (c) ROC corresponding to a left-sided sequence; 
(d) ROC corresponding to a two-sided sequence. 
transform of this signal converges. Figure 9 .13( c) corresponds to a left -sided signal and 
Figure 9 .13( d) to a two-sided signal. Neither of these two signals have Fourier trans-
forms, since their ROCs do not include the jw-axis. 
9.3 THE INVERSE LAPLACE TRANSFORM 
In Section 9.1 we discussed the interpretation of the Laplace transform of a signal as the 
Fourier transform of an exponentially weighted version of the signal; that is, with sex-
pressed ass = cr + jw, the Laplace transform of a signal x(t) is 
(9.53) 
for values of s = cr + jw in the ROC. We can invert this relationship using the inverse 
Fourier transform as given in eq. (4.9). We have 
x(t)e- ut = g:- 1{X(cr + jw)} =-
X(cr + jw)e1w 1 dw, 
1 I 
+oo 
. 
27T 
- oo 
(9.54) 
or, multiplying both sides by eut, we obtain 
x(t) = -
X(cr + jw )e(u+ Jw)t dw. 
1 I 
+oo 
. 
27T 
- oo 
(9.55) 

Sec. 9.3 
The Inverse Laplace Transform 
671 
That is, we can recover x(t) from its Laplace transform evaluated for a set of values of 
s = cr + jw in the ROC, with cr fixed and w varying from -oo to +oo. We can highlight 
this and gain additional insight into recovering x(t) from X(s) by changing the variable of 
integration in eq. (9.55) from w to sand using the fact thatcr is constant, so thatds = j dw . 
The result is the basic inverse Laplace transform equation: 
1 f<T+ j"' 
x(t) = -2 
. 
X(s)es1 ds. 
7T" 1 u - j"' 
(9.56) 
This equation states that x(t) can be represented as a weighted integral of complex 
exponentials. The contour of integration in eq. (9.56) is the straight line in the s-plane 
corresponding to all points s satisfying (Re{s} = cr. This line is parallel to the jw-axis. 
Furthermore, we can choose any such line in the ROC-i.e., we can choose any value 
of cr such that X(cr + jw) converges. The formal evaluation of the" integral for a general 
X(s) requires the use of contour integration in the complex plane, a topic that we will not 
consider here. However, for the class of rational transforms, the inverse Laplace transform 
can be determined without directly evaluating eq. (9.56) by using the technique of partial-
fraction expansion in a manner similar to that used in Chapter 4 to determine the inverse 
Fourier transform. Basically, the procedure consists of expanding the rational algebraic 
expression into a linear combination of lower order terms. 
For example, assuming no multiple-order poles, and assuming that the order of the 
denominator polynomial is greater than the order of the numerator polynomial, we can 
expand X(s) in the form 
m 
A· 
X(s) = L-' 
·. 
i = l s + ai 
(9.57) 
From the ROC of X(s), the ROC of each of the individual terms in eq. (9.57) can be 
inferred, and then, from Examples 9.1 and 9.2, the inverse Laplace transform of each of 
these terms can be determined. There are two possible choices for the inverse transform 
of each term A/(s + ai) in the equation. If the ROC is to the right of the pole at s = -ai, 
then the inverse transform of this term is Aie-a;t u(t), a right-sided signal. If the ROC is to 
the left of the pole at s = -ai, then the inverse transform of the term is - Aie- a;1u( -t), 
a left-sided signal. Addirig the inverse transforms of the individual terms in eq. (9.57) 
then yields the inverse transform of X(s). The details of this procedure are best presented 
through a number of examples. 
Example 9.9 
Let 
1 
X(s) = (s + l)(s + 2)' 
(Jle{s} > - 1. 
(9.58) 
To obtain the inverse Laplace transform, we first perform a partial-fraction expansion to 
obtain 
. 
1 
A 
B 
X(s) = (s + 1)(s + 2) = s + 1 + s + 2· 
(9.59) 

672 
The Laplace Transform 
Chap.9 
As discussed in· the appendix, we can evaluate the coefficients A and B by multiplying 
both sides of eq. (9.59) by (s + 1)(s + 2) and then equating coefficients of equal powers 
of s on both sides. Alternatively, we can use the relation 
A = [(s + 1)X(s)Jis= - 1 = 1, 
B = [(s + 2)X(s)Jis=-2 = - 1. 
Thus, the partial-fraction expansion for X(s) is 
1 
1 
X(s) = -- - --. 
s+1 
s+2 
(9.60) 
(9.61) 
(9.62) 
From Examples 9.1 and 9.2, we know that there are two possible inverse trans-
forms for a transform of the form 1/(s + a), depending on whether the ROC is to the 
left or the right of the pole. Consequently, we need to determine which ROC to associate 
with each of the individual first-order terms in eq. (9.62). This is done by reference to the 
properties of the ROC developed in Section 9.2. Since the ROC for X(s) is <Jl..e{s} > - 1, 
the ROC for the individual terms in the partial-fraction expansion of eq. (9.62) includes 
(Jl..e{s} > - 1. The ROC for each term can then be extended to the left or right (or both) to 
be bounded by a pole or infinity. This is illustrated in Figure 9.14. Figure 9.14(a) shows 
the pole-zero plot and ROC for X(s), as specified in eq. (9.58). Figure 9.14(b) and 9.14(c) 
represent the individual terms in the partial-fraction expansion in eq. (9.62). The ROC 
for the sum is indicated with lighter shading. For the term represented by Figure 9 .14( c), 
the ROC for the sum can be extended to the left as shown, so that it is bounded by a pole. 
!1m 
, c:--~~ 
I 
s-plane 
I 
I 
! 
I 
I 
- X- :>!(___,t---,--t--
I 
I 
! 
I 
i 
!1m 
-2 
-~ I 
I 
I I-. 
(a) 
s-plane 
--~--+-----:r-
-~ 
i 
I 
I 
(b) 
1'~-·-- 1··=,_.., 
i i I 
s-plane 
~l~--~----+-ffi-~-
1 
I 
I 
(c) 
Figure 9.14 
Construction of the ROCs for the individual terms in the 
partial-fraction expansion of X(s) in Example 9.8: (a) pole-zero plot and ROC 
for X(s); (b) pole at s = -1 and its ROC; (c) pole at s = - 2 and its ROC. 

Sec. 9.3 
The Inverse Laplace Transform 
673 
Since the ROC is to the right of both poles, the same is true for each of the indi-
vidual terms, as can be seen in Figures 9.14(b) and (c). Consequently, from Property 8 
in the preceding section, we know that each of these terms corresponds to a right-sided 
signal. The inverse transform of the individual terms in eq. (9.62) can then be obtained 
by reference to Example 9.1: 
We thus obtain 
.£ 
1 
e- 1u(t) <-------7 --1, 
s+ 
e- 2r u(t) ~ 
_ 1_ 
s + 2' 
ffi-e{s} > - 1, 
ffi-e{s} > - 2. 
[ - ( 
- 21] ( ) 
.c 
1 
e 
- e 
u t 
<-------? (s + 1)(s + 2)' 
ffi-e{s} > - 1. 
(9.63) 
(9.64) 
(9.65) 
Example 9. 1 0 
Let us now suppose that the algebraic expression for X(s) is again given by eq. (9.58), 
but that the ROC is now the left-half plane ffi-e{s} < - 2. The partial-fraction expansion 
for X(s) relates only to the algebraic expression, so eq. (9.62) is still valid. With this new 
ROC, however, the ROC is to the left of both poles and thus, the same must be true for 
each of the two terms in the equation. That is, the ROC for the term corresponding to 
the pole at s = - 1 is ffi-e{s} < -1, while the ROC for the term with pole at s = -2 is 
ffi-e{s} < -2. Then, from Example 9.2, 
-e- 1u( - t) ~ 
s ~ 1, 
ffi-e{s} < - 1, 
(9.66) 
.£ 
1 
-e- 21u(-t) <-------? s + 2, 
ffi-e{s} < -2, 
(9.67) 
so that 
( ) 
[ 
- t 
- 21] ( 
) 
.£ 
1 
x t = -e + e 
u -t <-------? (s + 1)(s + 2), 
ffi-e{s} < - 2. 
(9.68) 
Example 9. 11 
Finally, suppose that the ROC of X(s) in eq. (9.58) is -2 < ffi-e{s} < - 1. In this case, 
the ROC is to the left of the pole at s = -1 so that this term corresponds to the left-sided 
signal in eq. (9.66), while the ROC is to the right of the pole at s = -2 so that this term 
corresponds to the right-sided signal in eq. (9.64). Combining these, we find that 
( ) 
- r ( 
) 
- 21 ( ) 
.C 
1 
x t = -e u -t - e 
u t 
<-------? (s + 1)(s + 2)' 
- 2 < ffi-e{s} < -1. 
(9.69) 
As discussed in the appendix, when X(s) has multiple-order poles, or when the de-
nominator is not of higher degree than the numerator, the partial-fraction expansion of X(s) 
will include other terms in addition to the first-order terms considered in Examples 9.9-
9 .11. In Section 9 .5, after discussing properties of the Laplace transform, we develop some 
other Laplace transform pairs that, in conjunction with the properties, allow us to extend 
the inverse transform method outlined in Example 9.9 to arbitrary rational transforms. 

674 
The Laplace Transform 
Chap.9 
9.4 GEOMETRIC EVALUATION OF THE FOURIER TRANSFORM 
FROM THE POLE-ZERO PLOT 
As we saw in Section 9.1, the Fourier transform of a signal is the Laplace transform evalu-
ated on the jw-axis. In this section we discuss a procedure for geometrically evaluating the 
Fourier transform and, more generally, the Laplace transform at any set of values ·from the 
pole-zero pattern associated with a rational Laplace transform. To develop the procedure, 
let us first consider a Laplace transform with a single zero [i.e., X(s) = s-a], which we 
evaluate at a specific value of s, say, s = SJ. The algebraic expression s1 - a is the sum 
of two complex numbers, s1 and -a, each of which can be represented as a vector in the 
complex plane, as illustrated in Figure 9.15. The vector representing the complex number 
s1 - a is then the vector sum of s1 and - a, which we see in the figure to be a vector from 
the zero at s = a to the point s1• The value of X(s1) then has a magnitude that is the length 
of this vector and an angle that is the angle of the vector relative to the real axis. If X(s) 
instead has a single pole at s = a [i.e., X(s) = ll(s - a)], then the denominator would be 
represented by the same vector sum of s 1 and -a, and the value of X(s1) would have a 
magnitude that is the reciprocal of the length of the vector from the pole to s = s1 and an 
angle that is the negative of the angle of the vector with the real axis. 
9m 
s-plane 
s, 
a 
<Re 
Figure 9.15 
Complex plane rep-
resentation of the vectors s1, a, and 
s1 - a representing the complex num-
bers s1, a, and St - a, respectively. 
A more general rational Laplace transform consists of a product of pole and zero 
terms of the form discussed in the preceding paragraph; that is, it can be factored into the 
form 
(9.70) 
To evaluate X(s) at s = s1, each term in the product is represented by a vector from the 
zero or pole to the point s1• The magnitude of X(sJ) is then the magnitude of the scale 
factor M, times the product of the lengths of the zero vectors (i.e., the vectors from the 
zeros to s1) divided by the product of the lengths of the pole vectors (i.e., the vectors from 
the poles to s1 ) . The angle of the complex number X(s 1) is the sum of the angles of the zero 
vectors minus the sum of the angles of the pole vectors. If the scale factor Min eq. (9.70) 
is negative, an additional angle of 7T would be included. If X(s) has a multiple pole or zero 

Sec. 9.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
675 
(or both), corresponding to some of the a /s being equal to each other or some of the /3;'s 
being equal to each other (or both), the lengths and angles of the vectors from each of these 
poles or zeros must be included a number of times equal to the order of the pole or zero. 
Example 9. 1 2 
Let 
1 
X(s) = -
- , 
s+.!. 
2 
(9.71) 
The Fourier transform is X(s)ls~ jw · For this example, then, the Fourier transform is 
X(jw) = jw! 112 
(9.72) 
' 
The pole-zero plot for X(s) is shown in Figure 9.16. To determine the Fourier transform 
graphically, we construct the pole vector as indicated. The magnitude of the Fourier 
transform at frequency w is the reciprocal of the length of the vector from the pole to the 
point jw on the imaginary axis. The phase of the Fourier transform is the negative of the 
angle of the vector. Geometrically, from Figure 9.16, we can write 
and 
1:X(jw) = - tan- 1 2w. 
_1. 
2 
w 
s-plane 
(Jl..e 
(9.73) 
(9.74) 
Figure 9. 16 
Pole-zero plot for Example 9.12. !X(jw) I is the reciprocal of 
the length of the vector shown, and <r.X(jw) is the negative of the angle of the 
vector. 
Often, part of the value of the geometric determination of the Fourier transform lies 
in its usefulness in obtaining an approximate view of the overall characteristics of the 
transform. For example, in Figure 9.16, it is readily evident that the length of the pole 
vector monotonically increases with increasing w, and thus, the magnitude of the Fourier 

676 
The Laplace Transform 
Chap. 9 
transform will monotonically decrease with increasing w. The ability to draw general con-
elusions about the behavior of the Fourier transform from the pole-zero plot is further il-
lustrated by a consideration of general first- and second-order systems. 
9.4.1 First-Order Systems 
As a generalization of Example 9 .12, let us consider the class of first -order systems that 
was discussed in some detail in Section 6.5.1. The impulse response for such a system is 
and its Laplace transform is 
1 
H(s) = -
-
, 
ST + 1 
(9.75) 
(9.76) 
The pole-zero plot is shown in Figure 9.17. Note from the figure that the length of the pole 
vector is minimal for w = 0 and increases monotonically as w increases. Also, the angle 
of the pole increases monotonically from 0 to TT/2 as w increases from 0 to oo. 
w 
_.1 ,. 
s-plane 
Figure 9.17 
Pole-zero plot for first-
order system of eq. (9.76). 
From the behavior of the pole vector as w varies, it is clear that the magnitude of 
the frequency response H(jw) monotonically decreases as w increases, while -t.H(jw) 
monotonically decreases from 0 to -TT/2, as shown in the Bode plots for this system in 
Figure 9.18. Note also that when w = liT, the real and imaginary parts of the pole vector 
are equal, yielding a value of the magnitude of the frequency response that is reduced by 
a factor of ji, or approximately 3 dB, from its maximum at w = 0 and a value of 7T/4 for 
the angle of the frequency response. This is consistent with our examination of first-order 
systems in Section 6.5.1, where we noted that w = liT is often referred to as the 3-dB 
point or the break frequency-i.e., the frequency at which the straight-line approximation 
of the Bode plot of IH(jw )I has a break in its slope. As we also saw in Section 6.5.1, the 
time constant T controls the speed of response of first-order systems, and we now see that 

20 
OdB 
1 
J: 
0 
- 20 
i 
0 
C\1 
-40 
-60 
'IT/4 
0 
~ -'IT/4 
J: 
'<I 
- 'IT/2 
- 3'IT/4 
Sec. 9.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
677 
3 dB 
J , 
Asymptotic 
...---approximation 
0.1/T 
1fT 
10fT 
100fT 
(t) 
0.1/T 
1fT 
1 0/T 
100fT 
Figure 9.18 
Frequency response 
(t) 
for a first-order system. 
the pole of such a system at s = - 1/r is on the negative real axis, at a distance to the 
origin that is the reciprocal of the time constant. 
From our graphical interpretation, we can also see how changing the time constant 
or, equivalently, the position of the pole of H(s) changes the characteristics of a first-order 
system. In particular, as the pole moves farther into the left -half plane, the break frequency 
and, hence, the effective cutoff frequency of the system increases. Also, from eq. (9.75) 
and from Figure 6.19, we see that this same movement of the pole to the left corresponds 
to a decrease in the time constant r, resulting in a faster decay of the impulse response 
and a correspondingly faster rise time in the step response. This relationship between the 
real part of the pole locations and the speed of the system response holds more generally; 
that is, poles farther away from the jw-axis are associated with faster response terms in 
the impulse response. 
9.4.2 Second-Order Systems 
Let us next consider the class of second-order systems, which was discussed in some detail 
in Section 6.5.2. The impulse response and frequency response for the system, originally 

678 
The Laplace Transform 
given in eqs. (6.37) and (6~33), respectively, are 
where 
and 
h(t) = M[ec11 -
eC11]u(t), 
Ct = - {wn + Wn~• 
c2 = -{wn- Wn~• 
M = 
Wn 
2~· 
2 
H(jw) = 
w11 
• 
(jw)2 + 2{w 11(jw) + w~ 
The Laplace transform of the impulse response is 
Chap. 9 
(9.77) 
(9.78) 
(9.79) 
For ( > 1, c1 and c2 are real and thus both poles lie on the real axis, as indicated 
in Figure 9.19(a). The case of ( > 1 is essentially a product of two first-order terms, as 
in Section 9.4.1. Consequently, in this case IH(jw)l decreases monotonically as lwl in-
creases, while <r.H(jw) varies from 0 at w = 0 to -TT as w -7 oo. This can be verified 
from Figure 9 .19( a) by observing that the length of the vector from each of the two poles 
to the points = jw increases monotonically as w increases from 0, and the angle of each 
of these vectors increases from 0 to TT/2 as w increases from 0 to oo. Note also that as ( 
increases, one pole moves closer to the jw-axis, indicative of a term in the impulse re-
sponse that decays more slowly, and the other pole moves farther into the left-half plane, 
indicative of a term in the impulse response that decays more rapidly. Thus, for large val-
ues of(, it is the pole close to the jw-axis that dominates the system response for large 
time. Similarly, from a consideration of the pole vectors for ( >> 1, as indicated in Fig-
ure 9.19(b), for low frequencies the length and angle of the vector for the pole close to 
the jw-axis are much more sensitive to changes in w than the length and angle of the 
vector for the pole far from the jw-axis. Hence, we see that for low frequencies, the char-
acteristics of the frequency response are influenced principally by the pole close to the 
jw-axis. 
For 0 < ( < 1, c1 and c2 are complex, so that the pole-zero plot is that shown in 
Figure 9.19(c). Correspondingly, the impulse response and step response have oscilla-
tory parts. We note that the two poles occur in complex conjugate locations. In fact, as 
we discuss in Section 9.5.5, the complex poles (and zeros) for a real-valued signal al~ 
ways occur in complex conjugate pairs. From the figure-partJularly when ( is small, 
so that the poles are close to the jw-axis- as w approaches w 11 
1 - {2, the behavior of 
the frequency response is dominated by the pole vector in the second quadrant, and in 

Sec. 9.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
s-plane 
s-plane 
(Jl.e 
(a) 
(b) 
!lm 
s-plane 
:E+--t--~~- -~j-~'Wn 
'w" 
--------- -
cos6=' 
(Jl.e 
X 
(c) 
(d) 
Figure 9.19 
(a) Pole-zero plot for a second-order system with ( > 1; (b) pole vec-
tors for ( » 1; (c) pole-zero plot for a.second-order system with 0 < ( < 1; (d) pole 
vectors for 0 < ( < 1 and for w = wn~ 
and w = wn~ 
± ( wn. 
679 

680 
The Laplace Transform 
Chap. 9 
" 
particular, the length of that pole vector has a minimum at w = w n J 1 :.... ( 2 • Thus, qual-
itatively, we would expect the magnitude of the frequency response to exhibit a peak 
in the vicinity of that frequency. Because of the presence of the other pole, the peak 
will occur not exactly at w = wnJ1 - ( 2, but at a frequency slightly less than this. A 
careful sketch of the magnitude of the frequency response is shown in Figure 9.20(a) 
for Wn = 1 and several values of ( where the expected behavior in the vicinity of the 
poles is clearly evident. This is consistent with our analysis of second-order systems in 
Section 6.5.2. 
IHUwll 
(a) 
-l:HUwl 
( b) 
Figure 9.20 
(a) Magnitude and (b) phase of the frequency response for a 
second-order system with 0 < ( < 1. 

Sec. 9.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
681 
Thus, for 0 < ( < 1, the second-order system is a nonideal bandpass filter, with the 
parameter ( controlling the sharpness and width of the peak in the frequency response. In 
particular, from the geometry in Figure 9.19(d), we see that the length of the pole vector 
from the second-quadrant pole increases by a factor of J2 from its minimum at w = 
Wn~ 
when w increases or decreases from this value by (w 11 • Consequently, for small 
(,and neglecting the effect of the distant third-quadrant pole, jH(jw )j is within a factor of 
J2 of its peak value over the frequency range 
If we define the relative bandwidth B as the length of this frequency interval divided by 
the undamped natural frequency w n, we see that 
B = 2(. 
Thus, the closer ( is to zero, the sharper and narrower the peak in the frequency response 
is. Note also that B is the reciprocal of the quality measure Q for second-order systems 
defined in Section 6.5.2. Thus, as the quality increases, the relative bandwidth decreases 
and the filter becomes increasingly frequency selective. 
An analogous picture can be developed for <r..H ( w ), which is plotted in Figure 9 .20(b) 
for Wn = 1 and several values of(. As can be seen from Figure 9.19(d), the angle of 
the second-quadrant pole vector changes from - .'TT'/4 to 0 to 'TT'/4 as w changes from 
Wn~- (w" tow"~ 
to W 11~ 
+ (w 11 • For small values of(, the angle 
for the third-quadrant pole changes very little over this frequency interval, resulting in 
a rapid change in <r..H (jw) of approximately 'TT'/2 over the interval, as captured in the 
figure. 
Varying Wn with ( fixed only changes the frequency scale in the preceding 
discussion-i.e., i!f(w)i and <r..H(w) depend only on wlw 11 • From Figure 9.19(c), we 
also can readily determine how the poles and system characteristics change as we vary 
(, keeping Wn constant. Since cos (J = (, the poles move along a semicircle with fixed 
radius w 11 • For ( = 0, the two poles are on the imaginary axis. Correspondingly, in the 
time domain, the impulse response is sinusoidal with no damping. As ( increases from 
0 to 1, the two poles remain complex and move into the left-half plane, and the vectors 
from the origin to the poles maintain a constant overall magnitude w 11 • As the real part of 
the poles becomes more negative, the associated time response will decay more quickly 
as t ~ oo. Also, as we have seen, as (increases from 0 toward 1, the relative bandwidth 
of the frequency response increases, and the frequency response becomes less sharp and 
less frequency selective. 
9.4.3 All-Pass Systems 
As a final illustration of the geometric evaluation of the frequency response, let us con-
sider a system for which the Laplace transform of the impulse response has the pole-zero 
plot shown in Figure 9.21(a). From this figure, it is evident that for any point along the 
jw-axis, the pole and zero vectors have equal length, and consequently, the magnitude of 
the frequency response is constant and independent of frequency. Such a system is com-

682 
The Laplace Transform 
s-plane 
w 
-a 
a 
(Jl..e 
(a) 
-t H(jw) 
IH(jw)l 
w 
(b) 
Figure 9.21 
(a) Pole-zero plot for an all-pass system; (b) magnitude and 
phase of an all-pass frequency response. 
Chap.9 
w 
monly referred to as an all-pass system, since it passes all frequencies with equal gain (or 
attenuation). The phase of the frequency response is 0 1 - 02 , or, since 0 1 = 7T - 02 , 
<i:.H(jw) = 7r-202. 
(9.80) 
From Figure 9.2l(a), 02 = tan- 1(w/a), and thus, 
<i:.H(jw) = 7T- 2tan- 1 (~). 
(9.81) 
The magnitude and phase of H(jw) are illustrated in Figure 9.2l(b). 
9.5 PROPERTIES OF THE LAPLACE TRANSFORM 
In exploiting the Fourier transform, we relied heavily on the set of properties developed 
in Section 4.3. In the current section, we consider the corresponding set of properties for 

Sec. 9.5 
Properties of the Laplace Transform 
683 
the Laplace transform. The derivations of many of these results are analogous to those 
of the corresponding properties for the Fourier transform. Consequently, we will not 
present the derivations in detail, some of which are left as exercises at the end of the 
chapter. (See Problems 9.52- 9.54.) 
' 
9.5.1 Linearity of the Laplace Transform 
If 
and 
then 
x, (t) ~ 
x, (s) 
with a region of convergence that 
will be denoted as Rt 
xz(t) ~ 
Xz(s) 
with a region of convergence that 
will be denoted as Rz, 
..c 
ax1 (t) + bxz(t) ~ 
aX, (s) + bXz(s), with ROC 
containing R 1 n R2. 
(9.82) 
As indicated, the region of convergence of X(s) is at least the intersection of R1 and R2, 
which could be empty, in which case X(s) has no region of convergence-i.e., x(t) has 
no Laplace transform. For example, for x(t) as in eq. (9.47) of Example 9.7, with b > 0 
the ROC for X(s) is the intersection of the ROCs for the two terms in the sum. If b < 0, 
there are no common points in R1 and R2; that is, the intersection is empty; and thus, x(t) 
has no Laplace transform. The ROC can also be larger than the intersection. As a simple 
example, for x 1 (t) = x2(t) and a = -bin eq. (9.82), x(t) = 0, and thus, X(s) = 0. The 
ROC of X(s) is then the entire s-plane. 
The ROC associated with a linear combination of terms can always be constructed 
by using the properties of the ROC developed in Section 9 .2. Specifically, from the inter-
section of the ROCs for the individual terms (assuming that it is not empty), we can find a 
line or strip that is in the ROC of the linear combination. We then extend this to the right 
(CR.e{s} increasing) and to the left (CR.e{s} decreasing) to the nearest poles (which may be 
at infinity). 
Example 9. 1 3 
In this example, we illustrate the fact that the ROC for the Laplace transform of a linear 
combination of signals can sometimes extend beyond the intersection of the ROCs for 
the individual terms. Consider 
x(t) = x 1 (t) - x2(t), 
(9.83) 

684 
The Laplace Transform 
Chap. 9 
where the Laplace transforms of x 1(t) and x2(t) are, respectively, 
CR..e{s} > - 1, 
(9.84) 
and 
1 
X2(s) = (s + l)(s + 2)' 
CR..e{s} > - 1. 
(9.85) 
· .c .... The pole-zero plot, including the ROCs for X1 (s) and X2(s), is shown in Figures 9.22(a) 
and (b). From eq. (9.82), 
s +I 
1 
(s+ l)(s+2) - s+2' 
1 
1 
X(s) = s + 1 -
(s + 1)(s + 2) 
(9.86) 
Thus, in the linear combination of x1 (t) and x2(t), the pole at s = -1 is canceled by a 
zero at s = - 1. The pole-zero plot for X(s) = X1 (s) - X2(s) is shown in Figure 9.22(c). 
The intersection of the ROCs for X1 (s) and X2(s) is (R_.e{s} > -1. However, since the 
ROC is always bounded by a pole or infinity, for this example the ROC for X(s) can be 
extended to the left to be bounded by the pole at s = -2, as a result of the pole-zero 
cancellation at s = - 1. 
r 
r-.,.----~,1.......---... 
I 
s-plane 
l 
I s-plane 
I 
I 
l 
ffi£ 
I 
I 
-~2"1-4~---+--ffi-£ 
---~--~----~--ffi-£ 
I 
l 
I 
I 
I 
l.oc.,.. -~~.-• .- _,...,,,._.,._,.,,_. , 
(a) 
(b) 
(c) 
Figure 9.22 
Pole-zero plots and ROCs for Example 9.13: (a) X1(s); 
(b) X2(s); (c) X1 (s) - X2(s). The ROC for X1 (s) - X2(s) includes the inter-
section of R1 and R2, which can then be eXtended to be bounded by the pole 
at s = - 2. 
9.5.2 Time Shifting 
If 
then 
.c 
x(t) ~ 
X(s), 
.c 
x(t - to) ~ 
withROC = R, 
with ROC = R. ·I 
(9.87) 

Sec. 9.5 
Properties of the Laplace Transform 
9.5.3 Shifting in the s-Domain 
If 
.,c 
x(t) -+-+ X(s), 
then 
withROC = R, 
I e sot x(t) ~ 
X(s - so), 
with ROC = R + (Re{s0}. 
685 
(9.88) 
That is, the ROC associated with X(s - so) is that of X(s), shifted by ffi.e{s0}. Thus, for any 
values that is in R, the values+ ffi.e{s0} will be in R1. This is illustrated in Figure 9.23. 
Note that if X(s) has a pole or zero ats = a, thenX(s - s0) has a pole or zero ats-s0 = a-
i.e., s = a + so. 
An important special case of eq. (9.88) is when s0 = jw0-i.e., when a signal x(t) 
is used to modulate a periodic complex exponential ejwot. In this case, eq. (9.88) becomes 
0 
£ 
eJwot x(t) -+-+ X(s - Jwo), 
with ROC = R. 
(9.89) 
The right-hand side of eq. (9.89) can be interpreted as a shift in the s-plane parallel to 
the jw-axis. That is, if the Laplace transform of x(t) has a pole or zero at s = a, then the 
Laplace transform of ejwot x(t) has a pole or zero at s = a + jw0. 
9.5.4 Time Scaling 
If 
£ 
x(t) -+-+ X(s), 
with ROC = R, 
r2 1 
I 
I 
I 
I 
I 
! 
I 
i s-plane 
I 
I 
I 
I 
1 r1 
I 
I 
I 
I 
I 
-! 
(a) 
I 
I 
r2 + CR.e (s0) I 
I 
I 
I 
I 
(b) 
--- - 1 
I s-plane 
I 
I 
I 
I 
Figure 9.23 
Effect on the ROC of shifting in the s-domain: (a) the ROC of 
X(s); (b) the ROC of X(s- So). 

' 
r2 i I. 
I 
I 
I 
686 
The Laplace Transform 
Chap.9 
then 
.c 
1 · (s) 
x(at) ~ 
lalx Q 1 
with ROC R1 = aR. 
(9.90) 
That is, for 'any values in R [which is illustrated in Figure 9.24(a)], the value as will 
be in R1, as illustrated in Figure 9.24(b) for a positive value of a < I. Note that, for 
0 <a< 1, there is a compression in the size of the ROC of X(s) by a factor of a, as depicted 
in Figure 9.24(b), while for a> 1, the RO·c is expanded by a factor of a. Also, 
eq. (9.90) implies that if a is negative, the ROC undergoes a reversal plus a scaling. In 
particular, as depicted in Figure 9.24(c), the ROC of lliaiX(sla) for 0 >a> -1 involves 
Sm 
I 
1: t 
I 
I 
I 
I 
ffi.e 
ar2 1 
I 
I 
I 
I 
I 
I 
(a) 
g,. 
s-plane 
(c) 
g,. 
l 
·1 s-plane 
.j 
l 
I 
i I 
1ar1 
I 
I 
I I 
.I 
(b) 
ffi.e 
Figure 9.24 
Effect on the ROC of 
time scaling: (a) ROC of X(s); (b) ROC 
of (1/lai)X(s/a) for 0 <a< 1; (c) ROC of 
(1/jai)X(s/a) for 0 >a> -1. 

Sec. 9.5 
Properties of the Laplace Transform 
687 
a reversal about the jw-axis, together with a change in the size of the ROC by a factor of 
lal. Thus, time reversal of x(t) results in a reversal of the ROC. That is, 
9.5.5 Conjugation 
If 
then 
Therefore, 
.c 
x( - t) ~ 
X( -s), 
with ROC = - R. 
(9.91) 
.c 
x(t) ~ 
X(s), 
with ROC = R, 
(9.92) 
x*(t) ~ 
r(s*), 
with ROC = R. 
(9.93) 
X(s) = r(s*) when x(t) is real. 
(9.94) 
Consequently, if x(t) is real and if X(s) has a pole or zero at s = s0 (i.e., if X(s) is un-
bounded or zero at s = s0), then X(s) also has a pole or zero at the complex conjugate 
points = s~. For example, the transform X(s) for the real signal x(t) in Example 9.4 has 
poles at s = 1 ± 3j and zeros at s = ( -5 ± jfii)/2. 
9.5.6 Convolution Property 
If 
and 
then 
.c 
with ROC = Rt. 
with ROC = R2. 
x 1 (t) * x2(t) ~ 
X1 (s)X2(s), 
with ROC containing R1 n R2• 
(9.95) 
In a manner similar to the linearity property set forth in Section 9.5.1, the ROC of 
X1 (s)X2(s) includes the intersection of the ROCs of X1 (s) and X2(s) and may be larger if 
pole-zero cancellation occurs in the product. For example, if 
s+1 
Xt(S) = s + 2' 
<Re{s} > -2, 
(9.96) 

688 
The Laplace Transform 
Chap.9 
and 
(Re{s} > - 1, 
(9.97) 
then X1 (s)X2(s) = 1, and its ROC is the entire s-plane. 
As we saw in Chapter 4, the convolution property in the context of the Fourier 
transform plays an important role in the analysis of linear time-invariant systems. In Sec-
tions 9.7 and 9.8 we will exploit in some detail the convolution property for Laplace trans-
forms for the analysis of LTI systems in general and, more specifically, for the class of 
systems represented by linear constant-coefficient differential equations. 
9.5.7 Differentiation in the Time Domain 
If 
.c 
x(t) ~ 
X(s), 
withROC = R, 
then 
dx(t) 
.c 
dt 
~ 
sX(s), 
with ROC containing R. 
(9.98) 
This property follows by differentiating both sides of the inverse Laplace transform as 
expressed in equation (9.56). Specifically, let 
1 f<T+ 
j oo 
x(t) = -2 
. 
X(s)e51ds. 
7T 1 u - j oo 
Then 
dx(t) -
1 fu+ 
j oo X( ) std 
-- - --. 
s 
s e 
s. 
dt 
27T 1 u - j oo 
(9.99) 
Consequently, dx(t)ldt is the inverse Laplace transform of sX(s). The ROC of sX(s) in-
cludes the ROC of X(s) and may be larger if X(s) has a first-order pole at s = 0 that is 
canceled by the multiplication by s. For example, if x(t) = u(t), then X(s) = lis, with an 
ROC that is (Re{s} > 0. The derivative of x(t) is an impulse with an associated Laplace 
transform that is unity and an ROC that is the entire s-plane. 
9.5.8 Differentiation in the s-Domain 
Differentiating both sides of the Laplace transform equation (9.3), i.e., 
X(s) = L +oooo x(t)e- 51dt, 
we obtain 
dX(s) I 
+ oo( 
) ( ) - srd 
- -
= 
-txt e 
t. 
ds 
- oo 

Sec. 9.5 
Properties of the Laplace Transform 
Consequently, if 
then 
.,c 
x(t) ~ 
X(s), 
.,c 
- tx(t) ~ 
dX(s) 
(iS' 
withROC = R, 
withROC = R. 
The next two examples illustrate the use of this property. 
Example 9. 1 4 
Let us find the Laplace transform of 
x(t) = te- a'u(t). 
Since 
<R.e{s} > - a, 
it follows from eq. (9.100) that 
te-a'u(t) ~ 
_!!_ [- 1- ] = -
1-
ds s+a 
(s+a)2 ' 
<R.e{s} > -a. 
In fact, by repeated application of eq. (9.100), we obtain 
£ 
l 
~--­
(s + a)3 ' 
<R.e{s} > -a, 
and, more generally, 
<R.e{s} > -a. 
689 
(9.100) 
(9.101) 
(9.102) 
(9.103) 
(9.104) 
As the next example illustrates, this specific Laplace transform pair is particularly use-
ful when applying partial-fraction expansion to the determination of the inverse Laplace 
transform of a rational function with multiple-order poles. 
Example 9. 1 5 
Consider the Laplace transform 
2s2 + 5s + 5 
X(s) = (s + 1)2(s + 2)' 
<R.e{s} > - 1. 
Applying the partial-fraction expansion method descril:>ed in the appendix, we can write 
2 
1 
3 
X(s) = (s + 1)2 - (s + 1) + s + 2' 
<R.e{s} > -1. 
(9.105) 

690 
The Laplace Transform 
Chap.9 
Since the ROC is to the right of the poles at s = - 1 and -2, the inverse transform of 
each of the terms is a right-sided signal, and, applying eqs. (9.14) and (9.104), we obtain 
the inverse transform 
9.5.9 Integration in the Time Domain 
If 
.c 
x(t) ~ 
X(s), 
withROC = R, 
then 
t oo X(T)dT 
!x(s), with ROC containing 
s 
R n {<R.e{s} > 0}. 
(9.106) 
This property is the itwerse of the differentiation property set forth in Section 9.5.7. It can 
be derived using the convolution property presented in Section 9.5.6. Specifically, 
[
,, x(r)dr = u(t) * x(t). 
(9.107) 
From Example 9.1, with a = 0, 
u(t) 
.c 
1 
~­s' 
and thus, from the convolution property, 
<R.e{s} > 0, 
.c 
1 
u(t) * x(t) ~ 
-X(s), 
s 
(9.108) 
(9.109) 
with an ROC that contains the intersection ofthe ROC of X(s) and the ROC of the Laplace 
transform of u(t) in eq. (9.108), which results in the ROC given in eq. (9.106). 
9.5.1 0 The Initial- and Final-Value Theorems 
Under the specific constraints that x(t) = 0 fort < 0 and that x(t) contains no impulses 
or higher order singularities at the origin, one can directly calculate, from the Laplace 
transform, the initial value x(O+)-i.e., x(t) as t approaches zero from positive values of 
t. Specifically the initial-value theorem states that 
x(O+) = lim sX(s), 
(9.110) 
s->oo 
Also, if x(t) = 0 for t < 0 and, in addition, x(t) has a finite limit as t ~ x, then the final-
value theorem says that 
lim x(t) = limsX(s). 
(9.111) 
t-+ oo 
s-+0 
The derivation of these results is considered in Problem 9.53. 

Sec. 9.5 
Properties of the Laplace Transform 
691 
Example 9. 1 6 
• The initial- and final-value theorems can be useful in checking the correctness of the 
Laplace transform calculations for a signal. For example, consider the signal x(t) in 
Example 9.4. From eq. (9.24), we see that x(O+) = 2. Also, using eq. (9.29), we find 
that 
. 
. 
2s3 + 5s2 + 12s 
hmsX(s) .= hm 3 
4 2 
14 
20 = 2, 
s-+oo 
s- oo S + S + 
S + 
which is consistent with the initial-value theorem in eq. (9.110). 
9.5.11 Table of Properties 
In Table 9.1, we summarize the properties developed in this section. In Section 9. 7, 
many of these properties are used in applying the Laplace transform to the analysis and 
characterization of linear time-invariant systems. As we have illustrated in several exam-
ples, the various properties of Laplace transforms and their ROCs can provide us with 
TABLE 9.1 
PROPERTIES OF THE LAPLACE TRANSFORM 
Laplace 
Section 
Property 
Signal 
Transform 
ROC 
x(t) 
X(s) 
R 
X1 (t) 
X1 (s) 
R1 
x2(t) 
X2(s) 
R2 
--------------- -------- - - -- ---- --- --
- - - -- -- - - ---- - - ---
9.5.1 
Linearity 
ax1 (t) + bx2(t) 
aX1(s) + bX2(s) 
At least R1 n R2 
9.5.2 
Time shifting 
x(t - to) 
e-"• X(s) 
R 
9.5.3 
Shifting in the s-Domain 
esor x(t) 
X(s- so) 
Shifted version of R (i.e., s is 
in the ROC if s - s0 is in R) 
x(at) 
I x(s) 
Scaled ROC (i.e., s isin the 
Ia! a 
ROC if s/a is in R) 
9.5.4 
Time scaling 
9.5.5 
Conjugation 
x"(t) 
X"(s") 
R 
9.5.6 
Convolution 
Xi (t) * X2(t) 
X1 (s)X2(s) 
At least R1 n R2 
d 
sX(s) 
At least R 
di x(t) 
9.5.7 
Differentiation in the 
Time Domain 
- tx(t) 
d 
R 
dsX(s) 
9.5.8 
Differentiation in the 
s-Domain 
L 
x(r)d(r) 
I 
At least R n {ffi-e{s} > 0} 
- X(s) 
s 
9.5.9 
Integration in the Time 
Domain 
-------- -- ---- -
Initial- and Final-Value Theorems 
9.5.10 
If x(t) = 0 fort< 0 and x(t) contains no impulses or higher-order singularities at t = 0, then 
x(O+) = lim sX(s) 
s ~oo 
If x(t) = 0 for t < 0 and x(t) has a finite limit as t--? oc, then 
lim x(t) = lim sX(s) 
t-+oo 
s- o 

692 
The Laplace Transform 
Chap.9 
considerable information about a signal and its transform that can be useful either in char-
acterizing the signal or" in checking a calculation. In Sections 9.7 and 9.8 and in some of 
the problems at the end of this chapter, we give several other examples of the uses of these 
properties. 
9.6 SOME LAPLACE TRANSFORM PAIRS 
As we indicated in Section 9.3, the inverse Laplace transform can often be easily evaluated 
by decomposing X(s) into a linear combination of simpler terms, the inverse transform 
of each of which can be recognized. Listed in Table 9.2 are a number of useful-Laplace 
TABLE 9.2 
LAPLACE TRANSFORMS OF ELEMENTARY FUNCTIONS 
Transfonn 
pait 
Signal 
Transfonn 
ROC 
1 
o(t) 
1 
Ails 
2 
u(t) 
1 
ffi-e{s} > 0 
-s 
3 
- u( -t) 
1 
ffi-e{s} < 0 
-s 
4 
rn- 1 
1 
ffi-e{s} > 0 
(n - 1)! u(t) 
-s" 
5 
til- l 
1 
ffi-e{s} < 0 
- (n - 1)! u(-t) 
-s" 
6 
e-at u(t) 
1 
ffi-e{s} > - a 
--
s+a 
7 
- e-at u( - t) 
1 
ffi-e{s} < -a 
--
s+a 
8 
t''- 1 
1 
ffi-e{s} > -a 
(n- 1)! e-at u(t) 
--
(s +a)" 
9 
tn- 1 
1 
ffi-e{s} < - a 
- (n- 1)!e-atu(-t) 
--
(s +a)" 
10 
o(t - T) 
e - sT 
All s 
11 
[cos w 0t]u(t) 
s 
ffi-e{s} > 0 
s2 + w5 
12 
[sinw0t]u(t) 
Wo 
ffi-e{s} > 0 
s2 + w5 
13 
[e-at coswot]u(t) 
s+a 
CR-e{s} > - a 
(s + a)2 + w5 
14 
[e-at sin wot]u(t) 
Wo 
ffi-e{s} > -a 
(s + a)2 + w5 
15 
u (t) = d"o(t) 
11 
dt" 
s" 
All s 
16 
u_,(t) = u(t) * · · · * u(t) 
1 
ffi-e{s} > 0 
-
'-y---1 
s" 
n times 

Sec. 9.7 
Analysis And Characterization of LTI Systems Using the Laplace Transform 
693 
transform pairs. Transform pair 1 follows directly from eq. (9.3). Transform pairs 2 and 
6 follow directly from Example 9.1 with a = 0 and a = a, respectively. Transform pair 
4 was developed in Example 9.14 using the differentiation property. Transform pair 8 
follows from transform pair 4 using the property set forth in Section 9.5.3. Transform pairs 
3, 5, 7, and 9 are based on transform pairs 2, 4, 6 and 8, respectively, together with the time-
scaling property of section 9.5.4 with a = -1. Similarly, transform pairs 10 through 16 
can all be obtained from earlier ones in the table using appropriate properties in Table 9.1 
(see Problem 9.55). 
9. 7 ANALYSIS AND CHARACTERIZATION OF LTI SYSTEMS USING 
THE LAPLACE TRANSFORM 
One of the important applications of the Laplace transform is in the analysis and character-
ization of LTI systems. Its role for this class of systems stems directly from the convolution 
property (Section 9.5 .6). Specifically, the Laplace transforms of the input and output of an 
LTI system are related through multiplication by the Laplace transform of the impulse 
response of the system. Thus, 
Y(s) = H(s)X(s). 
(9.112) 
where X(s), Y(s), and H(s) are the Laplace transforms of the input, output, and 
impulse response of the system, respectively. Equation (9.112) is the counterpart, in 
the context of Laplace transforms, of eq. (4.56) for Fourier transform. Also, from our 
discussion in Section 3.2 on the response of LTI systems to complex exponentials, if the 
input to an LTI system is x(t) = e5t, with sin the ROC of H(s), then the output will be 
H(s)e
5t; i.e., est is an eigenfunction of the system with eigenvalue equal to the Laplace 
transform of the impulse response. 
If the ROC of H(s) includes the imaginary axis, then for s = jw, H(s) is the 
frequency response of the LTI system. In the broader context of the Laplace 
transform, H(s) is commonly referred to as the system function or, alternatively, the 
transfer function. Many properties of LTI systems can be closely associated with the 
characteristics of the system function in the s-plane. We . illustrate this next by 
examining several important properties and classes of systems. 
9. 7. 1 Causality 
For a causal LTI system, the impulse response is zero for t < 0 and thus is right sided. 
Consequently, from the discussion in Section 9.2, we see that 
The ROC associated with the system function for a 
causal system is a right-half plane. 
It should be stressed, however, that the converse of this statement is not necessarily 
true. That is, as illustrated in Example 9.19 to follow, an ROC to the right of the rightmost 

694 
The Laplace Transform 
Chap.9 
pole does not guarantee that a system is causal; rather, it guarantees only that the impulse 
response is right sided. However, if H (s) is rational, then, as illustrated in Examples 9.17 
and 9.18 to follow, we can determine whether the system is causal simply by checking to 
see if its ROC is a right-half plane. Specifically, 
For a system with a rational system function, causality 
of the system is equivalent to the ROC being the 
right-half plane to the right of the rightmost pole. 
Example 9. 1 7 
Consider a system with impulse response 
(9.113) 
Since h(t) = 0 fort < 0, this system is causal. Also, the system function can be obtained 
from Example 9.1: 
1 
H(s) = --
s + 1' 
<R.e{s} > - 1. 
(9.114) 
In this case, the system function is rational and the ROC in eq. (9.114) is to the right of 
the rightmost pole, consistent with our statement that causality for systems with rational 
system functions is equivalent to the ROC being to the right of the rightmost pole. 
Example 9. 1 8 
Consider a system with impulse response 
Since h(t) ¥- 0 fort< 0, this system is not causal. Also, from Example 9.7, the system 
function is 
-2 
H(s) = s2 _ 1, 
- 1<<R.e{s}<+l. 
Thus, H(s) is rational and has an ROC that is not to the right of the the rightmost pole, 
consistent with the fact that the system is not causal. 
Example 9. 1 9 
Consider the system function 
es 
H(s) = s + 1' 
<R.e{s} > - 1. 
(9.115) 
For this system, the ROC is to the right of the rightmost pole. Therefore, the impulse 
response must be right sided. To determine the impulse response, we first use the result 

Sec. 9.7 
Analysis And Characte,rization of LTI Systems Using the Laplace Transform 
695 
of Example 9.1: 
<R.e{s} > - 1. 
(9.116) 
Next, from the time-shifting property of Section 9.5.2 [eq. (9.87)], the factor e" in eq. 
(9.115) can be accounted for by a shift in the time function in eq. (9.116). Then 
.c 
es 
e-<t+llu(t + 1) ~ --
s + 1' 
<R.e{s} > -1, 
so that the impulse response associated with the system is 
h(t) = e-<t+l)u(t + 1), 
(9.117) 
(9.118) 
which is nonzero for -1 < t < 0. Hence, the system is not causal. This example serves 
as a reminder that causality implies that the ROC is to the right of the rightmost pole, 
but the converse is not in general true, unless the system function is rational. 
In an exactly analogous manner, we can deal with the concept of anticausality. A 
system is anticausal if its impulse response h(t) = 0 for t > 0. Since in that case h(t) 
would be left sided, we know from Section 9.2 that the ROC of the system function H(s) 
would have to be a left-half plane. Again, in general, the converse is not true. That is, if 
the ROC of H(s) is a left-half plane, all we know is that h(t) is left sided. However, if H(s) 
is rational, then having an ROC to the left of the leftmost pole is equivalent to the system 
being anticausal. 
9. 7. 2 Stability 
The ROC of H(s) can also be related to the stability of a system. As mentioned in Sec-
tion 2.3.7, the stability of an LTI system is equivalent to its impulse response being abso-
lutely integrable, in which case (Section 4.4) the Fourier transform of the impulse response 
converges. Since the Fourier transform of a signal equals the Laplace transform evaluated 
along the jw-axis, we have the following: 
An LTI system is stable if and only if the ROC 
of its system function H(s) includes the entire 
jw-axis [i.e., ffi-e(s) = 0]. 
Example 9.20 
Let us consider an LTI system with system function 
s - 1 
H(s) = (s + l)(s - 2) 
(9.119) 
Since the ROC has not been specified, we know from our discussion in Section 9.2 that 
there are several different ROCs and, consequently, several different system impulse re-
sponses that can be associated with the algebraic expression for H(s) given in eq. (9.119). 

696 
The Laplace Transform 
Chap.9 
If, however, we have information about the causality or stability of the system, the ap-
propriate ROC can be identified. For example, if the system is known to be causal, the 
ROC will be that indicated in Figure 9.25(a), with impulse response 
h(t) = (~ e-
1 + ~ e
21 )u(t). 
(9.120) 
Note that this particular choice of ROC does not include the jw-axis, and consequently, 
the corresponding system is unstable (as can be checked by observing that h(t) is not 
absolutely integrable). On the other hand, if the system is known to be stable, the ROC 
is that given in Figure 9.25(b), and the corresponding impulse response is 
2 
1 
h(t) = 3e- 1u(t)- 3e21u(-t), 
which is absolutely integrable. Finally, for the ROC in Figure 9.25(c), the system is 
anticausal and unstable, with 
dm 
1 
1 s-plane 
I 
I 
I 
! 
I 
I 
J, 
~ 
------~:-+-e~~~---------
-1 
1 
~ 
I
I_ 
! 
I 
<Re 
l 
I 
(a) 
(b) 
dm 
'1 
I i 
s-plane 
I 
I 
I * 
X 
-;11 
'1 2 
I I 
I 
• .1 
(c) 
Figure 9.25 
Possible ROCs for the system function of Example 9.20 with 
poles at s = -1 and s = 2 and a zero at s = 1: (a) causal, unstable system; 
(b) noncausal, stable system; (c) anticausal, unstable system. 
<Re 

Sec. 9.7 
Analysis And Characterization of LTI Systems Using the Laplace Transform 
697 
It is perfectly possible, of course, for a system to be stable (or unstable) and have 
a system function that is not rational. For example, the system function in eq. (9.115) is 
not rational, and its impulse response in eq. (9.118) is absolutely integrable, indicating 
that the system is stable. However, for systems with rational system functions, stability is 
easily interpreted in terms of the poles of the system. For example, for the pole-zero plot in 
Figure 9.25, stability corresponds to the choice of an ROC that is between the two poles, 
so that the jw-axis is contained in the ROC. 
For one particular and very important class of systems, stability can be characterized 
very simply in terms of the locations of the poles. Specifically, consider a causal LTI system 
with a rational system function H(s). Since the system is causal, the ROC is to the right of 
the rightmost pole. Consequently, for this system to be stable (i.e., for the ROC to include 
the jw-axis), the rightmost pole of H(s) must be to the left of the jw-axis. That is, 
A causal system with rational system function H(s) 
is stable if and only if all of the poles of H(s) lie in 
the left-half of the s-plane- i.e., all of the poles have 
negative real parts. 
Example 9.21 
Consider again the causal system in Example 9.17. The impulse response in eq. (9.113) 
is absolutely integrable, and thus the system is stable. Consistent with this, we see that 
the pole of H(s) in eq. (9.114) is at s = - 1, which is in the left-half of the s-plane. In 
contrast, the causal system with impulse response 
h(t) = e21 u(t) 
is unstable, since h(t) is not absolutely integrable. Also, in this case 
1 
H(s) = s - 2' 
<Re{s} > 2, 
so the system has a pole at s = 2 in the right half of the s-plane. 
Example 9.22 
Let us consider the class of causal second-order systems previously discussed in Sec-
tions 9.4.2 and 6.5.2. The impulse response and system function are, respectively, 
and 
where 
h(t) = M[e'-' 11 -
ec21]u(t) 
(9.121) 
w 2 
H(s) = 
2 
n 
2 
s + 2(w,s + w, 
c1 = -(w, + w,~. 
c2 = - (w,- w,~. 
M = 
w, 
2~· 
(9.122) 
(9.123) 
(9.124) 
(9.125) 

698 
! I 
I I 
~
-
I ' i 
f 
I I 
i 
The Laplace Transform 
Figure 9.26 
Pole locations and ROC for a causal second-order system 
with ( < 0. 
Chap. 9 
In Figure 9.19, we illustrated the pole locations for ( > 0. In Figure 9.26, we illustrate 
the pole locations for ( < 0. As is evident from the latter figure and from eqs. (9.124) 
and (9.125), for ( < 0 both poles have positive real parts. Consequently, for ( < 0, the 
causal second-order system cannot be stable. This is also evident in eq. (9.121), since, 
with CRe{cJ} > 0 and (Jl.e{c2} > 0, each term grows exponentially as t increases, and thus 
h(t) cannot be absolutely integrable. 
9:1.3 LTI Systems Characterized by Linear Constant-Coefficient 
Differential Equations 
In Section 4.7, we discussed the use of the Fourier transform to obtain the frequency re-
sponse of an LTI system characterizeg by a linear constant-coefficient differential equation· 
without first obtaining the impulse response or time-domain solution. In an exactly anal-
ogous manner, the properties of the Laplace transform can be exploited to directly obtain 
the system function for an LTI system characterized by a linear constant-coefficient dif-
ferential equation. We illustrate this procedure in the next example. 
Example 9.23 
Consider an LTI system for which the input x(t) and output y(t) satisfy the linear 
constant -coefficient differential equation 
dy(t) 
----cit + 3y(t) = x(t). 
(9.126) 

Sec. 9.7 
Analysis and Characterization of LTI Systems Using the Laplace Transform 
699 
Applying the Laplace transform to both sides of eq. (9.126), and using the linearity and 
differentiation properties set forth in Sections 9.5.1 and 9.5.7, respectively [(eqs. (9.82) 
and (9.98)], we obtain the algebraic equation 
sY(s) + 3Y(s) = X(s). 
Since, from eq. (9.112), the system function is 
Y(s) 
H(s) = X(s)' 
we obtain, for this system, 
1 
H(s) = -
-
. 
s+3 
(9.127) 
(9.128) 
This, then, provides the algebraic expression for the system function, but not the 
region of convergence. In fact, as we discussed in Section 2.4, the differential equation 
itself is not a complete specification of the LTI system, and there are, in general, differ-
ent impulse responses, all consistent with the differential equation. If, in addition to the 
differential equation, we know that the system is causal, then the ROC can be inferred 
to be to the right of the rightmost pole, which in this case corresponds to <R-e{s} > -3. If 
the system were known to be anticausal, then the ROC associated with H(s) would be 
1 (ft.e{s} < -3. The corresponding impulse response in the causal case is 
h(t) = e- 3' u(t), 
(9.129) 
whereas in the anticausal case it is 
h(t) = -e-3'u( - t). 
(9.130) 
The same procedure used to obtain H(s) from the differential equation in Exam-
ple 9.23 can be applied more generally. Consider a general linear constant-coefficient dif-
ferential equation of the form 
(9.131) 
Applying the Laplace transform to both sides and using the linearity and differenti-
ation properties repeatedly, we obtain 
(9.132) 
or 
H(s) = 
(9.133) 

700 
The Laplace Transform 
Chap.9 
Thus, the system function for a system specified by a differential equation is always ratio-
nal, with zeros at the solutions of 
(9.134) 
and poles at the solutions of 
(9.135) 
Consistently with our previous discussion, eq. (9.133) does not include a specification of 
the region of convergence of H(s), since the linear constant-coefficient differential equa-
tion by itself does not constrain the region of convergence. However, with additional in-
formation, such as knowledge about the stability or causality of the system, the region of 
convergence can be inferred. For example, if we impose the condition of initial rest on the 
system, so that it is causal, the ROC will be to the right of the rightmost pole. 
Example 9.24 
An RLC circuit whose capacitor voltage and inductor current are initially zero constitutes 
an LTI system describable by a linear constant-coefficient differential equation. Consider 
the series RLC circuit in Figure 9.27. Let the voltage across the voltage source be the 
input signal x(t), and let the voltage measured across the capacitor be the output signal 
y(t). Equating the sum of the voltages across the resistor, inductor, and capacitor with 
the source voltage, we obtain 
Rcdy(t) 
LCdzy(t) 
() = 
() 
dt + 
dt2 + y t 
X t . 
Applying eq. (9.133), we obtain 
l!LC 
H(s), = s2 + (RIL)s + (1/LC)" 
(9.136) 
(9.137) 
As shown in Problem 9.64, if the values of R, L, and C are all positive, the poles of 
this system function will have negative real parts, and consequently, the system will be 
stable. 
R 
L 
y(t) 
Figure 9.27 
A series RLC circuit. 

Sec. 9.7 
Analysis and Characterization of LTI Systems Using the Laplace Transform 
701 
9. 7.4 Examples Relating System Behavior to the System Function 
As we have seen, system properties such as causality and stability can be directly related 
to the system function and its characteristics. In fact, each of the properties of Laplace 
transforms that we have described can be used in this way to relate the behavior of the 
system to the system function. In this section, we give several examples illustrating this. 
Example 9.25 
Suppose we know that if the input to an LTI system is 
x(t) = e- 3' u(t), 
then the output is 
As we now show, from this knowledge we can determine the system function for this 
system and from this can immediately deduce a number of other properties of the system. 
and 
Taking Laplace transforms of x(t) and y(t), we get 
1 
X(s) = s + 3' 
1 . 
Y(s) = (s + 1)(s + 2)' 
ffi.e{s} > - 3, 
ffi.e{s} > -1. 
From eq. (9.112), we can then conclude that 
H( ) 
Y(s) 
s + 3 
s = X(s) = (s + l)(s + 2) 
s+3 
s2 + 3s + 2' 
Furthermore, we can also determine the ROC for this system. In particular, we 
know from the convolution property set forth in Section 9.5.6 that the ROC of Y(s) must 
include at least the intersections of the ROCs of X(s) and H(s). Examining the three 
possible choices for the ROC of H(s) (i.e., to the left of the pole at s = -2, between the 
poles at -2 and -1, and to the right of the pole at s = - 1 ), we see that the only choice 
that is consistent with the ROCs of X(s) and Y(s) is ffi.e{s} > - 1. Since this is to the 
right of the rightmost pole of H(s), we conclude that H(s) is causal, and since both poles 
of H(s) have negative real parts, it follows that the system is stable. Moreover, from the 
relationship between eqs. (9.131) and (9.133), we can specify the differential equation 
that, together with the condition of initial rest, characterizes the system: 
Example 9.26 
d 2y(t) 
3dy(t) 
2 () _ dx(t) 
3 () 
di2+ dt+ yt -dt+ xt . 
Suppose that we are given the following information about an LTI system: 
1. The system is causal. 
2. The system function is rational and has only two poles, at s = -2 and s = 4. 

702 
The Laplace Transform 
Chap.9 
3. If x(t) = 1, then y(t) = 0. 
4. The value of the impulse response at t = o+ is 4. 
From this information we would like to determine the system function of the system. 
From the first two facts, we know that the system is unstable (since it is causal and 
has a pole at s = 4 with positive real part) and that the system function is of the form 
p(s) 
H(s) = (s + 2)(s - 4) 
p(s) 
s2 -2s-8' 
where p(s)is a polynomial ins. Because the response y(t) to the input x(t) = 1 = e0·r 
must equal H(O) · e0'1 = H(O), we conclude, from fact 3, that p(O) = 0-i.e., that p(s) 
must have a root at s = 0 and thus is of the form 
p(s) = sq(s), 
where q(s) is another polynomial ins. 
Finally, from fact 4 and the initial-value theorem in Section 9.5.10, we see that 
I. 
H( ) 
I' 
s2q(s) 
4 
s~s s = s~ s2 - 2s - 8 = 
. 
(9.138) 
As s ~ oo, the terms of highest power in s in both the numerator and the denominator 
of sH(s) dominate and thus are the only ones of importance in evaluating eq. (9.138). 
Furthermore, if the numerator has higher degree than the denominator, the limit will 
diverge. Consequently, we can obtain a finite nonzero value for the limit only if the 
degree of the numerator of sH(s) is the same as the degree of the denominator. Since the 
degree of the denominator is 2, we conclude that, for eq. {9.138) to hold, q(s) must be a 
constant- i.e., q(s) = K. We can evaluate this constant by evaluating 
I. 
Ks2 
• 
Ks2 
s~ s2 - 2s - 8 = !~ SZ = K. 
Equating eqs. (9.138) and (9.139), we see that K = 4, and thus, 
4s 
H(s) = (s + 2)(s- 4) 
Example 9.27 
(9.139) 
Consider a stable and causal system with impulse response h(t) and system function 
H(s). Suppose H(s) is rational, contains a pole at s = - 2, and does not have a zero at 
the origin. The location of all other poles and zeros is unknown. For each of the following 
statements let us determine whether we can definitely say that it is true, whether we can 
definitely say that it is false, or whether there is insufficient information to ascertain the 
statement's truth: 
(a) :f { h(t)e31 } converges. 
(b) e00
00 h(f)df = 0. 
(c) th(t) is the impulse response of a causal and stable system. 

Sec. 9.7 
Analysis and Characterization of LTI Systems Using the Laplace Transform 
(d) dh(t)ldt contains at least one pole in its Laplace transform. 
(e) h(t) has finite duration. 
(t) H (s) = H( -s). 
(g) lim ..... "' H(s) = 2. 
703 
Statement (a) is false, since ~ {h(t)e
31 } corresponds to the value of the Laplace 
transform of h(t) at s = -3. If this converges, it implies that s = -3 is in the ROC. 
A causal and stable system must always have its ROC to the right of all of its poles. 
However, s = - 3 is not to the right of the pole at s = - 2. 
Statement (b) is false, because it is equivalent to stating that H(O) = 0. This con-
tradicts the fact that H(s) does not have a zero at the origin. 
Statement (c) is true. According to Table 9.1, the property set forth in Section 9.5.8, 
the Laplace transform of th(t) has the same ROC as that of H(s). This ROC includes 
the jw-axis, and therefore, the corresponding system is stable. Also, h(t) = 0 fort < 0 
implies that th(t) = 0 fort < 0. Thus, th(t) represents the impulse response of a causal 
system. 
Statement (d) is true. According to Table 9.1, dh(t)ldt has the Laplace transform 
sH(s). The multiplication by s does not eliminate the pole at s = - 2. 
Statement (e) is false. If h(t) is of finite duration, then if its Laplace transform 
has any points in its ROC, the ROC must be the entire s-plane. However, this is not 
consistent with H(s) having a pole at s = - 2. 
Statement (f) is false. If it were true, then, since H(s) has a pole at s = - 2, it 
must also have a pole at s = 2. This is inconsistent with the fact that all the poles of a 
causal and stable system must be in the left half of the s-plane. 
The truth of statement (g) cannot be ascertained with the information given. The 
statement requires that the degree of the numerator and denominator of H(s) be equal, 
and we have insufficient information about H(s) to determine whether this is the case. 
9. 7. 5 Butterworth Filters 
In Example 6.3 we briefly introduced the widely-used class of LTI systems known as 
Butterworth filters. The filters in this class have a number of properties, including the 
characteristics of the magnitude of the frequency response of each of these filters in the 
passband, that make them attractive for practical implementation. As a further illustration 
of the usefulness of Laplace transforms, in this section we use Laplace transform tech-
niques to determine the system function of a Butterworth filter from the specification of 
its frequency response magnitude. 
An Nth-order lowpass Butterworth filter has a frequency response the square of 
whose magnitude is given by 
(9.140) 
where N is the order of the filter. From eq. (9.140), we would like to determine the system 
function B(s) that giv~s rise to IB(jw )j2. We first note that, by definition, 
IB(jw)l2 = B(jw)B*(jw). 
(9.141) 

704 
The Laplace Transform 
Chap.9 
If we restrict the impulse response of the Butterworth filter to be real, then from the prop-
erty of conjugate symmetry for Fourier transforms, 
B*(jw) = B(- jw), 
(9.142) 
so that 
1 
B(jw )B(- jw) = 1 + (jw/ jwc)2N . 
(9.143) 
Next, we note that B(s)is= jw = B(jw), and consequently, from eq. (9.143), 
1 
B(s)B( - s) = 1 +(sf jwc)2N" 
(9.144) 
The roots of the denominator polynomial corresponding to the combined poles of 
B(s)B( - s) are at 
s = ( -
1)1/2N (jwc). 
Equation (9.145) is satisfied for any values = Sp for which 
ispl = We 
and 
7T(2k + 1) 
'1T 
<r..sp = 
2N 
+ 2' . 
k an integer; 
that is, 
( . ['TT(2k + 1) 
]) 
Sp = wcexp J 
2N 
+ 'TT/2 · 
(9.145) 
(9.146) 
(9.147) 
(9.148) 
In Figure 9.28 we illustrate the positions of the poles of B(s)B( -s) for N = 
1, 2, 3, and 6. In general, the following observations can be made about these poles: 
1. There are 2N poles equally spaced in angle on a circle of radius w c in the s-plane. 
2. A pole never lies on the jw-axis and occurs on the <T-axis for N odd, but not for 
N even. 
3. The angular spacing between the poles of B(s)B( -s) is 'TTIN radians. 
To determine the poles of B(s) given the poles of B(s)B( - s), we observe that the 
poles of B(s)B( -s) occur in pairs, so that if there is a pole at s = sp. then there is also 
a pole at s = -sp. Consequently, to construct B(s), we choose one pole from each pair. 
If we restrict the system to be stable and causal, then the poles that we associate with 
B(s) are the poles along the semicircle in the left-half plane. The pole locations specify 
B(s) only to within a scale factor. However, from eq. (9.144), we see that B2(s)is=O = 1, or 
equivalently, from eq. (9 .140), the scale factor is chosen so that the square of the magnitude 
ofthe frequency response has unity gain at w = 0. 
To illustrate the determination of B(s), let us consider the cases N = 1, N = 2, and 
N = 3. In Figure 9.28 we showed the poles of B(s)B(- s), as obtained from eq. (9.148). 

Sec. 9.7 
Analysis and Characterization of LTI Systems Using the Laplace Transform 
. 705 
N=1 
N=2 
.... 
.... 
,. 
' 
I 
\ 
I 
\ 
----X . 
X------
\ 
I (J) 
\ 
I 
c 
' 
,.' 
.... _ .... 
N=6 
Figure 9.28 
Position of the poles of B(s)B( - s) for N = 1, 2, 3, and 6. 
In Figure 9.29 we show the poles assoCiated with B(s) for each of these'values of N. The 
corresponding transfer functions are: 
N = 1: 
N = 2: 
N = 3: 
B(s) = ~; 
S +We 
s2 + /iwcs + w; ' 
w3 
B(s) = 
c 
(s + wc)(s + wcei< '11'13))(s + wee -j( '11'!3)) 
w3 c 
(s + wc)(s2 + wcs + w~) 
w3 c 
s3 + 2w s2 + 2w2s + w3' 
c 
c 
c 
(9.149) 
(9.150) 
(9.151) 
Based on the discussion in Section 9.7 .3, from B(s) we can determine the associated 
linear constant -coefficient differential equation. Specifically, for the foregoing three values 

706 
The Laplace Transform 
I 
I 
~-­
/ 
!Jm 
N=1 
~c\----r--------ffi--~ 
' " ... 
I 
x-
iwc 
/ 
----*----~---------
- we\ 
ffi~ 
\ 
'x~ 
Figure 9.29 
Position of the poles of B(s) for N = 1, 2, and 3. 
of N, the corresponding differential equations are: 
N = 1: 
dy(t) 
- d 
+ Wcy(t) = WcX(t); 
t 
. 
N = 2: 
d 2y(t) 
~ dy(t) 
2 
-
2 
. 
(jj2 + v2wc(jf + wcy(t) - wcx(t), 
N = 3: 
N=2 
9.8 SYSTEM FUNCTION ALGEBRA AND BLOCK DIAGRAM REPRESENTATIONS 
Chap. 9 
(9.152) 
(9.153) 
The use of the Laplace transform allows us to replace time-domain operations such as 
differentiation, convolution, time shifting, and so on, with algebraic operations. We have 
already seen many of the benefits of this in terms of analyzing LTI systems, and in this 
section we take a look at another important use of system function algebra, namely, in 
analyzing interconnections of LTI systems and synthesizing systems as interconnections 
of elementary system building blocks. 

Sec. 9.8 
System Function Algebra and Block Diagram Representations 
707 
9.8.1 System Functions for Interconnections of LTI Systems 
Consider the parallel interconnection of two systems, as shown in Figure 9.30(a). The 
impulse response of the overall system is 
h(t) = hl (t) + h2(t), 
(9.155) 
and from the linearity of the Laplace transform, 
H(s) = H1 (s) + H2(s). 
(9.156) 
Similarly, the impulse response of the series interconnection in Figure 9.30(b) is 
h(t) = hl {t) * h2(t), 
and the associated system function is 
H(s) = H1(s)H2(s). 
(a) 
x(t) 
(b) 
(9.157) 
(9.158) 
Figure 9.30 
(a) Parallel intercon-
nection of two LTI systems; (b) series 
combination of two LTI systems. 
The utility of the Laplace transform in representing combinations of linear systems 
through algebraic operations extends to far more complex interconnections than the simple 
parallel and series combinations in Figure 9.30. To illustrate this, consider the feedback 
interconnection of two systems, as indicated in Figure 9.31. The design, applications, and 
analysis of such interconnections are treated in detail in Chapter 11. While analysis of the 
system in the time domain is not particularly simple, determining the overall system func-
tion from input x(t) to output y(t) is a straightforward algebraic manipulation. Specifically, 
from Figure 9.31, 
Y(s) = H1 (s)E(s), 
E(s) = X(s) - Z(s), 
(9.159) 
(9.160) 

708 
The Laplace Transform 
Chap. 9 
+ 
x(t)--~ 
1----....... --~ 
y(t) 
z(t) 
and 
Z(s) = H2(s)Y(s), 
Figure 9.31 
Feedback interconnec-
tion of two LTI systems. 
(9.161) 
from which we obtain the relation 
Y(s) = H1 (s)[X(s) - H2(s)Y(s)], 
(9.162) 
or 
(9.163) 
9.8.2 Block Diagram Representations for Causal LTI Systems 
Described by Differential Equations and Rational 
System Functions 
In Section 2.4.3, we illustrated the block diagram representation of an LTI system de-
scribed by a first-order differential equation using the basic operations of addition, multi-
plication by a coefficient, and integration. These same three operations can also be used 
to build block diagrams for higher order systems, and in this section we illustrate this in 
several examples. 
Example 9.28 
Consider the causal LTI system with system function 
1 
H(s) = -. 
s+3 
From Section 9.7.3, we know that this system can also be described by the differential 
equation 
d~;t) + 3y(t) = x(t), 
together with the condition of initial rest. In Section 2.4.3 we constructed a block diagram 
J · representation, shown in Figure 2.32, for a first-order. system such as this. An equiva-
lent block diagram (corresponding to Figure 2.32 with a = 3 and b = 1) is shown in 

Sec. 9.8 
System Function Algebra and Block Diagram Representations 
x(t) 
1-----....... -~ 
y(t) 
(a) 
x(t) + 
1----..---~ y(t) 
(b) 
Figure 9.32 
(a) Block diagram representation of the causal LTI system in 
Example 9.28; (b) equivalent block diagram representation. 
709 
Figure 9.32(a). Here, lis is the system function of a system with impulse response u(t), 
i.e., it is the system function of an integrator. Also, the system function -3 in the feed-
back path in Figure 9.32(a) corresponds to multiplication by the coefficient - 3. The 
block diagram in the figure involves a feedback loop much as we considered in the pre-
vious subsection and as pictured in Figure 9.31, the sole difference being that the two 
, signals that are the inputs to the adder in Figure 9.32(a) are added, rather than sub-
tracted as in Figure 9.31. However, as illustrated in Figure 9.32(b), by changing the sign 
of the coefficient in the multiplication in the feedback path, we obtain a block diagram 
representation of exactly the same form as Figure 9.31. Consequently, we can apply 
eq. (9.163) to verify that 
lis 
1 
H(s) = 1 + 3/s = s + 3 · 
Example 9.29 
Consider now the causal LTI system with system function 
H(s) = -
- = -
-
(s + 2). 
s+2 
( 1 ) 
s+3 
s+3 
(9.164) 
As suggested by eq. (9.164), this system can be thought of as a cascade of a system 
with system function ll(s + 3) followed by a system with system function s + 2, and 

710 
The Laplace Transform 
Chap.9 
we have illustrated this in Figure 9.33(a), in which we have used the block diagram in 
Figure 9.32(a) to represent 1/(s + 3). 
It is also possible to obtain an alternative block diagram representation for the 
system in eq. (9.164). Using the linearity and differentiation properties of the Laplace 
transform, we know that y(t) and z(t) in Figure 9.33 (a) are related by 
dz(t) 
y(t) = dt + 2z(t). 
However, the input e(t) to the integrator is exactly the derivative of the output z(t), so 
that 
y(t) = e(t) + 2z(t), 
which leads directly to the alternative block diagram representation shown in Fig-
ure 9.33(b). Note that the block diagram in Figure 9.33(a) requires the differentiation of 
z(t), since 
dz(t) 
y(t) = dt + 2z(r) 
In contrast, the block diagram in Figure 9.33(b) does not involve the explicit differenti-
ation of any signal. 
r-- - - --- - - -- - ----- - ---------------------1 
I 
1 
I 
I 
x(t) 
: 
+ }--..;.:e(~t)_-+1 
1 
z(t) 
I 
I 
I 
I 
' 
I 
I 
I 
I 
I 
I 
I 
I 
I 
I 
L --- --- - ----- ------ ---- - - ---- --- - - -- - - - ~ 
(a) 
x(t) 
e(t) 
-....:..:..--'1~ + >-~--~---+~ 
(b) 
)----. y(t) 
Figure 9.33 
(a) Block diagram representations for the system in Exam-
ple 9.29; (b) equivalent block diagram representation. 
y(t) 

Sec. 9.8 
System Function Algebra and Block Diagram Representations 
711 
Example 9.30 
Consider next a causal second-order system with system function 
1 
H(s) = (s + 1)(s + 2) 
s2 + 3s + 2 · 
(9.165) 
The input x(t) and output y(t) for this system satisfy the differential equation 
dJr~t) + 3 d~;t) + 2y(t) = x(t). 
(9.166) 
By employing similar ideas to those used in the preceding examples, we obtain the block 
diagram representation for this system shown in Figure 9.34(a). Specifically, since the 
e(t) 
(a) 
x(t) l ·~ ·cr ·~ 
(b) 
X t 
(c) 
Figure 9.34 
Block diagram representations for the system in Exam-
ple 9.30: (a) direct form; (b) cascade form; (c) parallel form. 
• y(t) 
y(t) 

712 
The Laplace Transform 
Chap.9 
input to an integrator is the derivative of the output of the integrator, the signals in the 
block diagram are related by 
f(t) = d~;t)' 
e(t) = df(t) = d
2y(t). 
dt 
. 
dt 
Also, eq. (9.166) can be rewritten as 
d
2y(t) = -3dy(t) - 2 () 
() 
d 2 
d 
yt +xt, 
t 
t 
. 
or 
e(t) = -3 f(t) - 2y(t) + x(t), 
which is exactly what is represented in Figure 9.34(a). 
The block diagram in this figure is sometimes referred to as a direct-form repre-
sentation, since the coefficients appearing in the diagram can be directly identified with 
the coefficients appearing in the system function or, equivalently, the differential equa-
tion. Other block diagram representations of practical importance also can be obtained 
after a modest amount of system function algebra. Specifically, H(s) in eq. (9.165) can 
be rewritten as 
H(s) = (-1 )(-1 )· 
s+1 s+2 
which suggests that this system can be represented as the cascade of two first-order sys-
tems. The cascade-form representation corresponding to H(s) is shown in Figure 9 .34(b ). 
Alternatively, by performing a partial-fraction expansion of H(s), we obtain 
1 
1 
H(s) = -
-
- --, 
s+1 
s+2 
which leads to the parallel-form representation depicted in Figure 9.34(c). 
Example 9.31 
As a final example, consider the system function 
H(s) = 2s
2 +4s - 6. 
s2 + 3s + 2 
(9.167) 
Once again, using system function algebra, we can write H (s) in several different forms, 
each of which suggests a block diagram representation. In particular, we can write 
H(s) = (s2 + ~s + 2 )(2s
2 + 4s- 6), 
! which suggests the representation of H (s) as the cascade of the system depicted in Fig-
ure 9.34(a) and the system with system function 2s2 + 4s - 6. However, exactly as we 

Sec. 9.8 
System Function Algebra and Block Diagram Representations 
713 
did in Example 9.29, we can extract the derivatives required for this second system by 
"tapping" the signals appearing as the inputs to the integrators in the first system. The 
details of this construction are examined in Problem 9.36, and the result is the direct-
form block diagram shown in Figure 9.35. Once again, in the direct-form representation 
the coefficients appearing in the block diagram can be determined by inspection from 
the coefficients in the system function in eq. (9.167). 
or 
Figure 9.35 
Direct-form representation for the system in Example 9.31 . 
Alternatively, we can write H(s) in the form 
H(s) = (2(s- 1))(~) 
s+2 
s+1 
6 
8 
H(s) = 2+ -
-
- -
- . 
s+2 
s+l 
y(t) 
(9.168) 
~9.169) 
The first of these suggests a cascade-form representation, while the second leads to a 
parallel-form block diagram. These are also considered in Problem 9.36. 
The methods for constructing block diagram representations for causal LTI systems 
described by differential equations and rational system functions can be applied equally 
well to higher order systems. In addition, there is often considerable flexibility in how this 
is done. For example, by reversing the numerators in eq. (9.168), we can write 
H(s) = (~)(2(s - 1)). 
s+2 
s+2 
which suggests a different cascade form. Also, as illustrated in Problem 9 .38, a fourth-
order system function can be written as the product of two second-order system functions, 
each of which can be represented in a number of ways (e.g., direct form, cascade, or par-
allel), and it can also be written as the sum of lower order terms, each of which has sev-
eral different representations. In this way, simple low-order systems can serve as building 
blocks for the implementation of more complex, higher order systems. 

714 
The Laplace Transform 
Chap. 9 
9.9 THE UNILATERAL LAPLACE TRANSFORM 
In the preceding sections of this chapter, we have dealt with what is commonly called 
the bilateral Laplace transform. In this section, we introduce and examine a somewhat 
different transform, the unilateral Laplace transform, which is of considerable value in 
analyzing causal systems and, particularly, systems specified by linear constant-coefficient 
differential equations with nonzero initial conditions (i.e., systems that are not initially at 
rest). 
The unilateral Laplace transform of a continuous-time signal x(t) is defined as 
X(s) ~ ("" x(t)e-sr dt, 
Jo-
(9.170) 
where the lower limit of integration, o-, signifies that we include in the interval of 
integration any impulses or higher order singularity functions concentrated at t = 0. 
Once again we adopt a convenient shorthand notation for a signal and its unilateral 
Laplace transform: 
'l.J.£ 
x(t) ~ 
X(s) = 'U.C{ x(t)}. 
(9.171) 
Comparing eqs. (9.170) and (9.3), we see that the difference in the definitions of 
the unilateral and bilateral Laplace transform lies in the lower limit on the integral. The 
bilateral transform depends on the entire signal from t = - oo tot = +oo, whereas the uni-
lateral transform depends only on the signal from t = o- to oo. Consequently, two signals 
that differ for t < 0, but that are identical for t 2: 0, will have different bilateral Laplace 
transforms, but identical unilateral transforms. Similarly, any signal that is identically zero 
fort< 0 has identical bilateral and unilateral transforms. 
Since the unilateral transform of x(t) is identical to the bilateral transform of the 
signal obtained from x(t) by setting its value to 0 for all t < 0, many of the insights, 
concepts, and results pertaining to bilateral transforms can be directly adapted to the 
unilateral case. For example, using Property 4 in Section 9.2 for right-sided signals, 
we see that the ROC for eq. (9.170) is always a right-half plane. The evaluation of 
the inverse unilateral Laplace transforms is also the same as for bilateral transforms, 
with the constraint that the ROC for a unilateral transform must always be a right-half 
plane. 
9. 9. 1 Examples of Unilateral Laplace Transforms 
To illustrate the unilateral Laplace transform, let us consider the following examples: 
Example 9.32 
Consider the signal 
(9.172) 

Sec. 9.9 
The Unilateral Laplace Transform 
715 
Since x(t) = 0 fort < 0, the unilateral and bilateral transforms are identical. Thus, from 
Table 9.2, 
1 
£C(s) = -( 
)n ' 
s+a 
CR-e{s} > -a. 
(9.173) 
Example 9.33 
Consider next 
x(t) = e- a(r+l)u(t + 1). 
(9.174) 
The bilateral transform X(s) for this example can be obtained from Example 9.1 and the 
time-shifting property (Section 9.5.2): 
e' 
X(s) = --, 
s+a 
By contrast, the unilateral transform is 
CR.e{s} > - a. 
£C(s) = f"' e- a(r+l)u(t + 1)e-st dt 
Jo-
= ["' e- ae- r(s+a) dt 
Jo-
-
1 
= e a _
_ 
s +a' 
CR.e{s} > - a. 
(9.175) 
(9.176) 
Thus, in this example, the unilateral and bilateral Laplace transforms are clearly dif-
ferent. In fact, we should recognize £C(s) as the bilateral transform not of x(t), but of 
x(t)u(t), consistent with our earlier comment that the unilateral transform is the bilateral 
transform of a signal whose values for t < o- have been set to zero. 
Example 9.34 
Consider the signal 
x(t) = 8(t) + 2u1 (t) + e1 u(t). 
(9.177) 
Since x(t) = 0 fort< 0, and since singularities at the origin are included in the interval 
of integration, the unilateral transform for x(t) is the same as the bilateral transform. 
Specifically, using the fact (transform pair 15 in Table 9.2) that the bilateral transform 
of Un(t) is sn, we have 
1 
s(2s- 1) 
£C(s) = X(s) = 1 + 2s + -- = 
, 
s-1 
s-1 
CR.e{s} > 1. 
(9.178) 
Example 9.35 
Consider the unilateral Laplace transform 
1 
£C(s) = (s + 1)(s + 2) 
(9.179) 

716 
The Laplace Transform 
Chap. 9 
In Example 9.9, we considered the inverse transform for a bilateral Laplace transform of 
the exact form as that in eq. (9.179) and for several ROCs. For the unilateral transform, 
the ROC must be the right-half plane to the right of the rightmost pole of X(s); i.e., in 
this case, the ROC consists of all points s with <Jl.~{s} > - 1. We can then invert this 
unilateral transform exactly as in Example 9.9 to obtain 
x(t) = [e - 1 -
e- 21]u(t) 
for 
t > o-' 
(9.180) 
where we have emphasized the fact that unilateral Laplace transforms provide us with 
information about signals only for t > o-. 
Example 9.36 
Consider the unilateral transform 
s2 - 3 
X(s) = -
-
. 
s+2 
(9.181) 
Since the degree of the numerator of X(s) is not strictly less than the degree of the de-
nominator, we expand X(s) as 
c 
X(s) = A + Bs + -
-2. 
s+ 
Equating eqs. (9.181) and (9.182), and clearing denominators, we obtain 
s2 - 3 = (A+ Bs)(s + 2) + C, 
and equating coefficients for each power of s yields 
1 
X(s) = -2 + s + -
-2, 
s+ 
with an ROC of <Jl.~{s} > -2. Taking inverse transforms of each term results in 
X(t) = - 2o(t) + Ut (t) + e - 21 u(t) for 
t > 0- . 
(9.182) 
(9.183) 
(9.184) 
(9.185) 
9.9.2 Properties of the Unilateral Laplace Transform 
As with the bilateral Laplace transform, the unilateral Laplace transform has a number of 
important properties, many of which are the same as their bilateral counterparts and sev-
eral of which differ in significant ways. Table 9.3 summarizes these properties. Note that 
we have not included a column explicitly identifying the ROC for the unilateral Laplace 
transform for each signal, since the ROC of any unilateral Laplace transform is always a 
right-half plane. For example the ROC for a rational unilateral Laplace transform is always 
to the right of the rightmost pole. 
Contrasting Table 9.3 with Table 9.1 for the bilateral transform, we see that, with 
the caveat that ROCs for unilateral Laplace transforms are always right-half planes, the 
linearity, s-domain shifting, time-scaling, conjugation and differentiation in the s-domain 

Sec. 9.9 
The Unilateral Laplace Transform 
717 
TABLE 9.3 
PROPERTIES OF THE UNILATERAL LAPLACE TRANSFORM 
Property 
Signal 
Unilateral Laplace Transform 
x(t) 
~(s) 
x,(t) 
~,(s) 
x2(t) 
~2 (s) 
------ -- - -------
__ _ _ .,. ___ ___ ------- - -- ------ --
Linearity 
ax, (t) + bx2(t) 
a~,(s) + b~2(s) 
Shifting in the s-domain 
e'o' x(t) 
~(s- so) 
Time scaling 
x(at), 
a > O 
~~(~) 
Conjugation 
X* (t) 
x * (s) 
Convolution (assuming 
x1 (I) * Xz(l) 
~,(s)~2 Cs) 
that x1 (t) and x2(t) 
are identically zero for 
t < 0) 
Differentiation in the time 
d 
s~(s) ~ x(O- ) 
dix(t) 
domain 
Differentiation in the 
- tx(t) 
d 
ds ~(s) 
s-domain 
L 
x(T)dT 
1 
Integration in the time 
-
~(s) 
domain 
' 
s 
-- --- ----- --- - - -
- -- - ------ -
-- ---- - -- --- - - ----
Initial- arid Final-Value Theorems 
If x(t) contains no impulses or higher-order singularities at t = 0, then 
x(O+) = lims~(s) 
s ~ oo 
limx(t) = lims~(s) 
t-+ oo 
s-+0 
properties are identical to their bilateral counterparts. Similarly, the initial- and final-value 
theorems stated in Section 9.5 .1 0 also hold for unilateral Laplace transforms. 3 The deriva-
tion of each of these properties is identical to that of its bilateral counterpart. 
The convolution property for unilateral transforms also is quite similar to the corre-
sponding property for bilateral transforms. This property states that if 
x 1 (t) = x2(t) = 0 
for all 
t < 0, 
(9.186) 
3In fact, the initial- and final-value theorems are basically unilateral transform properties, as they apply 
only to signals x(t) that are identically 0 for t < 0. 

718 
The Laplace Transform 
Chap. 9 
then 
(9.187) 
Equation (9 .187) follows immediately from the bilateral convolution property, since, under 
the conditions of .eq. (9 .186), the unilateral and bilateral transforms are identical for each 
of the signals x 1 (t) and x2(t) . Thus, the system analysis tools and system function algebra 
developed and used in this chapter apply without change to unilateral transforms, as long 
as we deal with causal LTI systems (for which the system function is both the bilateral 
and the unilateral transform of the impulse response) with inputs that are identically zero 
fort < 0. An example of this is the integration property in Table 9.3: If:x(t) = 0 fort < 0, 
then 
x(r)d-r = x(t) * u(t) ~ 
X(s)'U(s) = -X(s) 
i
t 
'11.£ 
-
1 
o-
s 
As a second case in point, consider the following example: 
Example 9.37 
Suppose a causal LTI system is described by the differential equation 
d2y(t) 
3dy(t) 
2 () -
() 
(:ii2 + ---;It + y t -xt , 
(9.188) 
(9.189) 
together with the condition of initial rest. Using eq, (9.133), we find that the system 
function for this system is 
1 
Jf(s) = 
2 
3 
2' 
s + s + 
(9.190) 
Let the input to this system be x(t) = au(t). In this case, the unilateral (and bilateral) 
Laplace transform of the output y(t) is 
'Y(s) = Jf(s)ff(s) = s(s + 1~(s + 2) 
a/2 
a 
a/2 
= -
---+-- . 
s 
s+1 
s+2 
Applying Example 9.32 to each term of eq. (9.191) yields 
[ 1 
-
1 -
] 
y(t) = a 2 - e 1 + 2e 21 u(t). 
(9.191) 
(9.192) 
It is important to note that the convolution property for unilateral Laplace transforms 
applies only if the signals x 1 (t) and x2(t) in eq. (9.187) are both zero for t < 0. That is, 
while we have seen that thebilateral Laplace transform of x1 (t) * x2(t) always equals the 
product of the bilateral transforms of x1 (t) and x2(t), the unilateral transform of Xt (t)*x2(t) 
in general does not equal the product of the unilateral transforms if either x 1 (t) or x2(t) is 
nonzero fort < 0. (See, for example, Problem 9.39). 

Sec. 9.9 
The Unilateral Laplace Transform 
719 
A particularly important difference between the properties of the unilateral and bi-
lateral transforms is the differentiation property. Consider a signal x(t) with unilateral 
Laplace transform ~(s). Then, integrating by parts, we find that the unilateral transform 
of dx(t)ldt is given by 
roo dx(t) e- st dt = x(t)e-51 1
00 
+ s ("' x(t)e- st dt 
Jo-
dt 
o-
Jo-
(9.193) 
= sa:(s) - x(O- ). 
Similarly, a second application of this would yield the unilateral Laplace transform of 
d2 x(t)ldt2' i.e., 
(9.194) 
where x'(O- ) denotes the derivative of x(t) evaluated at t = o-. Clearly, we can continue 
the procedure to obtain the unilateral transform of higher derivatives. 
9.9.3 Solving Differential Equations Using the Unilateral 
Laplace Transform 
A primary use of the unilateral Laplace transform is in obtaining the solution of linear 
constant-coefficient differential equations with nonzero initial conditions. We illustrate 
this in the following example: 
Example 9.38 
Consider the system characterized by the differential equation (9.189) with initial con-
. ditions 
(9.195) 
Let x(t) = au(t). Then, applying the unilateral transform to both sides of eq. (9.189), 
we obtain 
or 
s2'Y(s) - {3s - y + 3s'Y(s) - 3{3 + 2'Y(s) = ~. 
s 
,11 
{3(s + 3) 
y 
a 
.:~(s) = 
+ 
+ -
- --= 
(s + 1)(s + 2) 
(s + 1)(s + 2) 
s(s + 1)(s + 2)' 
where 'Y(s) is the unilateral Laplace transform of y(t). 
(9.196) 
(9.197) 
Referring to Example 9.37 and, in particular, to eq. (9.191), we see that the last 
term on the right-hand side of eq. (9.197) is precisely the unilateral Laplace transform 
of the response of the system when the initial conditions in eq. (9.195) are both zero 
({3 = y = 0). That is, the last term represents the response of the causal LTI system 
described by eq. (9.189) and the condition of initial rest. This response is often referred 

720 
9.10 SUMMARY 
The Laplace Transform 
Chap.9 
to as the zero-state response- i.e., the response when the initial state (the set of initial 
conditions in eq. (9.195)) is zero. 
· An analogous interpretation applies to the first two terms on the right-hand side of 
eq. (9 .197). These terms represent the unilateral transform of the response of the system 
when the input is zero (a = 0). This response is commonly referred to as the zero-
input response. Note that the zero-input response is a linear function of the values of 
the initial conditions (e.g., doubling the values of both f3 andy doubles the zero-input 
response). Furthermore, eq. (9.197) illustrates an important fact about the solution of 
linear constant-coefficient differential equations with nonzero initial conditions, namely, 
that the overall response is simply the superposition of the zero-state and the zero-input 
responses. The zero-state response is the response obtained by setting the initial condi-
tions to zero-i.e., it is the response of an LTI system defined by the differential equa-
tion and the condition of initial rest. The zero-input response is the response to the initial 
conditions with the input set to zero. Other examples illustrating this can be found in 
Problems 9.20, 9.40, and 9.66. 
Finally, for any values of a, f3, andy, we can, of course, expand 'Y(s) in eq. (9.197) 
in a partial-fraction expansion and invert to obtain y(t). For example, if a = 2, f3 = 3, 
andy = - 5, then performing a partial-fraction expansion for eq. (9.197) we find that 
1 
1 
3 
'Y(s) = -
-
-
+ - -. 
s 
s+1 
s+2 
Applying Example 9.32 to each term then yields 
y(t) = [1 - e- 1 + 3e- 21]u(t) 
for 
t > 0. 
(9.198) 
(9.199) 
In this chapter, we have developed and studied the Laplace transform, which can be viewed 
as a generalization of the Fourier transform. It is particularly useful as an analytical tool in 
the analysis and study ofLTI systems. Because of the properties of Laplace transforms, LTI 
systems, including those represented by linear constant-coefficient differential equations, 
can be characterized and analyzed in the transform domain by algebraic manipulations. In 
addition, system function algebra provides a convenient tool both for analyzing intercon-
nections of LTI systems and for constructing block diagram representations of LTI systems 
described by differential equations. 
For signals and systems with rational Laplace transforms, the transform is often con-
veniently represented in the complex plane (s-plane) by marking the locations of the poles 
and zeros and indicating the region of convergence. From the pole-zero plot, the Fourier 
transform can be geometrically obtained, within a scaling factor. Causality, stability, and 
other characteristics are also easily identified from knowledge of the pole locations and 
the region of convergence. 
In this chapter, we have been concerned primarily with the bilateral Laplace trans-
form. However, we also introduced a somewhat different form of the Laplace transform 
known as the unilateral Laplace transform. The unilateral transform can be interpreted as 
the bilateral transform of a signal whose values prior to t = o- have been set to zero. 
This form of the Laplace transform is especially useful for analyzing systems described 
by linear constant-coefficient differential equations with nonzero initial conditions. 

Chap. 9 
Problems 
721 
Chapter 9 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
· 
BASIC PROBLEMS WITH ANSWERS 
9.1. For each of the following integrals, specify the values of the real parameter (J' which 
ensure that the integral converges: 
(a) Io"' e- 5r e- <u+ jw)r dt 
(b) I ~"' e-5t e-(u+ jw)t dt 
(c) ese- st e- <u+ jw)r dt 
(d) C"'e-51 e- <u+ jw)r dt 
(e) I :"'e- 5ltle - (u+ Jw)r dt . 
(f) I ~"'e- 5ltle - <u + }w)r dt 
9.2. Consider the signal 
x(t) = e- 51u(t-1), 
and denote its Laplace transform by X(s). 
(a) Using eq. (9.3), evaluate X(s) and specify its region of convergence. 
(b) Determine the values of the finite numbers A and to such that the Laplace traris-
form G(s) of 
g(t) = Ae- 51u(-t- to) 
has the same algebraic form as X(s). What is the region of convergence corre-
sponding to G(s)? 
9.3. Consider the signal 
x(t) = e- St u(t) + e-f3t u(t), 
and denote its Laplace transform by X(s). What are the constraints placed on the 
real and imaginary parts of {3 if the region of convergence of X(s) is (Re{s} > - 3? 
9.4. For the Laplace transform of 
x(t) = { e
1 sin 2t, 
0, 
t :5 0 
t>O' 
indicate the location of its poles and its region of convergence. 
9.5. For each of the following algebraic expressions for the Laplace transform of a signal, 
determine the number of zeros located in the finite s-plane and the number of zeros 
located at infinity: 
1 
1 
(a) s + 1 + s + 3 
s + 1 
(b) -
-
s2 - 1 
s3 -
1 
(c) s2 + s + 1 

722 
The Laplace Transform 
Chap.9 
9.6. An absolutely integrable signal x(t) is known to have a pole at s = 2. Answer the 
following questions: 
(a) Could x(t) be of finite duration? 
{b) Could x(t) be left sided? 
{c) Could x(t) be right sided? 
{d) Could x(t) be two sided? 
9.7. How many signals have a Laplace transform that may be expressed as 
(s -
1) 
(s + 2)(s + 3)(s2 + s + 1) 
in its region of convergence? 
9.8. Let x(t) be a signal that has a rational Laplace transform with exactly two poles, 
located at s = - 1 and s = - 3. If g(t) ,:, e21 x(t) and G(jw) [the Fourier transform 
of g(t)] converges, determine whether x(t) is left sided, right sided, or two sided. 
9.9. Given that 
.,c 
1 
e- 01u(t) ~ 
--, 
s+a 
(ft.e{s} > Cft.e{ - a}, 
determine the inverse Laplace transform of 
X(s) = 
2(s + 2) 
s2+7s+12' 
Cft.e{s} > -3. 
9.10. Using geometric evaluation of the magnitude of the Fourier transfoirn from the cor-
responding pole-zero plot, determine, for each of the following Laplace transforms, 
whether the magnitude of the corresponding Fourier transform is approximately 
lowpass, highpass, or bandpass: 
1 
{a) H1 (s) = (s + 1)(s + 3), 
(ft.e{s} > -1 
(b) H2(s) = 2 s 
1, 
ffi.e{s}> -~ 
s + s + 
s2 . 
(c) H3(s) = s2 + 2s + 1, 
ffi.e{s} > -1 
9.11. Use geometric evaluation from the pole-zero plot to determine the magnitude of the 
Fourier transform of the signal whose Laplace transform is specified as 
X(s) = s2- s + 1 
ffi.e{s} > _ _ 
21. 
s2 +s+1' 
9.12. Suppose we are given the following three facts about the signal x(t): 
1. x(t) = 0 for t < 0. 
2. x(k/80) = 0 f6r k = 1, 2, 3, ... . 
3. x(l/160) = e- 120. 
Let X(s) denote the Laplace transform of x(t), and determine which of the following 
statements is consistent with the given information about x(t): 
(a) X(s) has only one pole in the finites-plane. 
(b) X(s) has only two poles in the finites-plane. 
{c) X(s) has more than two poles in the finites-plane. 

Chap. 9 
Problems 
9.13. Let 
g(t) = x(t) +ax( -t), 
where 
x(t) = /3 e - r u(t) 
and the Laplace transform of g(t) is 
s 
G(s) = s2 - 1' 
-1 < <R.e{s} < 1. 
Determine the values of the constants a and f3 . 
723 
9.14. Suppose the following facts are given about the signal x(t) with Laplace transform 
X(s): 
1. x(t) is real and even. 
2. X(s) has four poles and no zeros in the finites-plane. 
3. X(s) has a pole at s = (112)ej1T14. 
4. C ,,x(t) dt = 4. 
Determine X(s) and its ROC. 
9.15. Consider two right-sided signals x(t) and y(t) related through the differential equa-
tions 
dx(t) 
· 
--;[! = - 2y(t) + 5(t) 
and 
d~;t) = 2x(t). 
Determine Y(s) and X(s), along with their regions of convergence. 
9.16. A causal LTI systemS with impulse response h(t) has its input x(t) and output y(t) 
related through a linear constant-coefficient differential equation of the form 
d 3y(t) 
d2y(t) 
dy(t) 
2 
---;R3 + (1 + a)---;[j'2 + a(a + 1)---;[t +a y(t) = x(t). 
(a) If 
dh(t) 
g(t) = --;[! + h(t), 
how many poles does G(s) have? 
(b) For what real values of the parameter a is S guaranteed to be stable? 
9.17. A causal LTI system S has the block diagram representation shown in Figure P9 .17. 
Determine a differential equation relating the input x(t) to the output y(t) of this 
system. 

724 
The Laplace Transform 
Chap.9 
Figure P9.17 . 
9.18. Consider the causal LTI system represented by the RLC circuit examined in Prob-
lem 3.20. 
(a) Determine H(s) and specify its region of convergence. Your answer should be 
consistent with the fact that the system is causal and stable. 
(b) Using the pole-zero plot of H(s) and geometric evaluation of the magnitude of 
the Fourier transform, determine whether the magnitude of the corresponding 
Fourier transform has an approximately lowpass, highpass, or bandpass char-
acteristic. 
(c) If the value of R is now changed to w-3 fl, determine H(s) and specify its 
region of convergence. 
(d) Using the pole-zero plot of H(s) obtained in part (c) and geometric evaluation 
of the magnitude of the Fourier transform, determine whether the magnitude of 
the corresponding Fourier transform has an approximately lowpass, highpass, 
or bandpass characteristic. 
9.19. Determine the unilateral Laplace transform of each of the following signals, and 
specify the corresponding regions of convergence: 
(a) x(t) = e- zr u(t + 1) 
(b) x(t) = S(t + 1) + S(t) + e- Z(t+3lu(t + 1) 
(c) x(t) = e- 21u(t) + e- 41u(t) 
9.20. Consider the RL circuit of Problem 3.19. 
(a) Determine the zero-state response of this circuit when the input current is 
x(t) = e- zr u(t). 
(b) Determine the zero-input response of the circuit fort> o-, given that 
y(O- ) = 1. 
(c) Determine the output of the circuit when the input current is x(t) = e- zr u(t) 
and the initial condition is the same as the one specified in part (b). 
BASIC PROBLEMS 
9.21. Determine the Laplace transform and the associated region of convergence and pole-
zero plot for each of the following functions of time: 
(a) x(t) = e- 21u(t) + e- 31u(t) 
(b) x(t) = e- 41u(t) + e- 51(sin5t)u(t) 
(c) x(t) = e21u(- t) + e31u(- t) 
(d) x(t) = te-Zitl 

Chap. 9 
Problems 
725 
(e) x(t) = lfie-2
11
1 
(t) x(t) = ltie21u(-t) 
() () 
{
1, 
O ::;=; t ::;:;1 
g x t = 
0, 
elsewhere 
(h) x(t) = { t, 
0 ::;:; t ::;:; 1 
2 - t, 
1 :-;;;; t :-;;;; 2 
(i) x(t) = 5(t) + u(t) 
G) x(t) = 5(3t) + u(3t) 
9.22. Determine the function of time, x(t), for each of the following Laplace transforms 
and their associated regions of convergence: 
(a) 
s2~9
• 
ffi.e{s} > 0 
(b) s2:9, 
<R.e{s} < 0 
( ) 
s+ 1 
tD { } 
1 
c 
(s+ l)2+9' 
Vl€ s < -
(d) 
s+2 
-4 < <R.e{s} < -3 
s2+?s+ 12' 
(e) s<;:+6, 
- 3 < <R.e{s} < -2 
(t) ~ 
s2-s+l' 
( ) s2- s+l 
g 
(s+J)2 ' 
<R.e{s} > 4 
<R.e{s} > -1 
9.23, For each of the following statements about x(t), and for each of the four pole-zero 
plots in Figure P9.23, determine the corresponding constraint on the ROC: 
1. x(t)e- 31 is absolutely integrable. 
2. x(t) * (e- 1u(t)) is absolutely integrable. 
3. x(t) = 0, t > 1. 
4. x(t) = 0, t < - 1. 
dm 
9m 
X 
2j 
X 
X 
2j 
0 
- 2 
2 (Jl.e 
-2 
2 (Jl.e 
X 
- 2j 
X 
X 
-2j 
0 
dm 
9m 
0 
2j 
X 
0 
2j 
0 
-2 
2 ffie 
-2 
0 
- 2j 
X 
0 
-2j 
0 
Figure P9.23 

726 
The Laplace Transform 
Chap.9 
9.24. Throughout this problem, we will consider the region of convergence of the Laplace 
transforms always to include the jw-axis. 
(a) Consider a signal x(t) with Fourier transform X(jw) and Laplace transform 
X(s) = s + 1/2. Draw the pole-zero plot for X(s). Also, draw the vector whose 
length represents IX(jw )I and whose angle with respect to the real axis repre-
sents ~X(jw) for a given w. 
(b) By examining the pole-zero plot and vector diagram in part (a), determine a 
different Laplace transform X1 (s) corresponding to the function of time, x 1 (t), 
so that 
but 
x 1 (t) ¥- x(t). 
Show the pole-zero plot and associated vectors that represent X1 (jw ). 
(c) For your answer in part (b), determine, again by examining the related vector 
diagrams, the relationship between ~X(jw) and ~X 1 (jw ). 
(d) Determine a Laplace transform X2(s) such that 
but x2(t) is not proportional to x(t). Show the pole-zero plot for X2(s) and the 
associated vectors that represent Xz(jw ). 
(e) For your answer in part (d), determine the relationship between IXz(jw )I and 
IX(jw)l. 
(f) Consider a signal x(t) with Laplace transform X(s) for which the pole-zero plot 
is shown in Figure P9.24. Determine X1(s) such that IX(jw)l = IX1(jw)l and 
all poles and zeros of X1 (s) are in the !eft-half of the s-plane [i.e., ffi-e{s} < 0]. 
Also, determine X2(s) such that ~X(jw) = ~X2 (jw) and all poles and zeros 
of X2(s) are in the left-half of the s-plane. 
-x-~o---+--o>--- x -----
- 2 
- 1 
1. 
1 
<Re 
2 
Figure P9.24 
9.25. By considering the geometric determination of the Fourier transform, as developed 
in Section 9 .4, sketch, for each of the pole-zero plots in Figure P9 .25, the magnitude 
of the associated Fourier transform. 

Chap. 9 
Problems 
!1m 
!1m 
----x --~~---------
0 
- iwo 
X - iwo 
(a) 
(b) 
!1m 
--x--~o-+-----------
----X--X-+~~o------
- b -a 
a 
b 
(c) 
(d) 
!1m 
0 
iwo 
---- x --~~--o------
0 
- jw0 
(e) 
(f) 
Figure P9.25 
9.26. Consider a signal y(t) which is related to two signals x 1 (t) and x2(t) by 
y(t) = XJ(t- 2) * X2( - t + 3) 
where 
and 
x2(t) = e- 31 u(t). 
727 

728 
Given that 
The Laplace Transform 
.c 
1 
e-atu(t) -
--, 
(Re{s} > -·a, 
s+a 
Chap.9 
use prope1iies of the Laplace transform to determine the Laplace transform Y(s) of 
y(t). 
9.27. We are given the following five facts about a real signal x(t) with Laplace transform 
X(s): 
1. X(s) has exactly two poles. 
2. X(s) has no zeros in the finites-plane. 
3. X(s) has a pole at s = -1 + j . 
4. e21 x(t) is not absolutely integrable. 
5. X(O) = 8. 
Determine X(s) and specify its region of convergence. 
9.28. Consider an LTI system for which the system function H(s) has the pole-zero pattern 
shown in Figure P9.28. 
--x---x--~----x~ 
- 2 
- 1 
+ 1 
+ 2 
eR-e 
Figure P9 .28 
(a) Indicate all possible ROCs that can be associated with this pole-zero pattern. 
(b) For each ROC identified in part (a), specify whether the associated system is 
stable and/or causal. 
9.29. Consider an LTI system with input x(t) = e- 1u(t) and impulse response h(t) = 
e-21 u(t). 
(a) Determine the Laplace transforms of x(t) and h(t). 
(b) Using the convolution property, determine the Laplace transform Y(s) of the 
output y(t). 
(c) From the Laplace transform of y(t) as obtained in part (b), determine y(t). 
(d) Verify your result in part (c) by explicitly convolving x(t) and h(t). 
9.30. A pressure gauge that can be modeled as an LTI system has a time response to a 
unit step input given by (1 - e- 1 - te- 1)u(t). For a certain input x(t), the output is 
observed to be (2 - 3e-1 + e-31)u(t). 
For this observed measurement, determine the true pressure input to the gauge 
as a function of time. 

Chap.9 
Problems 
729 
9.31. Consider a continuous-time LTI system for which the input x(t) and output y(t) are 
related by the differential equation 
d 2y(t) - dy(t) - 2y(t) = x(t). 
dt2 
dt 
Let X(s) and Y(s) denote Laplace transforms of x(t) and y(t), respectively, and let 
H(s) denote the Laplace transform ofh(t), the system impulse response. 
(a) Determine H(s) as a ratio of two polynomials ins. Sketch the pole-zero pattern 
of H(s). 
(b) Determine h(t) for each of the following cases: 
1. The system is stable. 
2. The system is causal. 
3. The system is neither stable nor causal. 
9.32. A causal LTI system with impulse response h(t) has the following properties: 
1. When the input to the system is x(t) = e21 for all t, the output is y(t) = (l/6)e21 
for all t. 
2. The impulse response h(t) satisfies the differential equation 
d~;t) +' 2h(t) = (e- 41)u(t) + bu~t), 
where b is an unknown constant. 
Determine the system function H(s) of the system, consistent with the information 
above. There should be no unknown constants in your answer; that is, the constant 
b should not appear in the answer. 
9.33. The system function of a causal LTI system is 
. 
s + 1 
H(s) = 2 
2 
2' 
s + s + 
Determine and sketch the response y(t) when the input is 
x(t) = e- ltl, 
-oo < t < oo, 
9.34. Suppose we are given the following information about a causal and stable LTI sys-
temS with impulse response h(t) and a rational system function H(s): 
1. H(l) = 0.2. 
2. When the input is u(t), the output is absolutely integrable. 
3. When the input is tu(t), the output is not absolutely integrable. 
4. The signal d 2h(t)/dt2 + 2 dh(t)ldt +. 2h(t) is of finite duration. 
5. H(s) has exactly one zero at infinity. 
Determine H(s) and its region of convergence. 
9.35. The input x(t) and output y(t) of a causal LTI system are related through the block-
diagram representation shown in Figure P9.35. 
(a) Determine a differential equation relating y(t) and x(t). 
(b) Is this system stable? 

730 
The Laplace Transform 
Chap.9 
---..; + }-----.-~-----{ + >------
x(t) 
y(t) 
Figure P9.35 
9.36. In this problem, we consider the construction of various types of block diagram 
representations for a causal LTI system S with input x(t), output y(t), and system 
function 
H(s) = 2s
2 + 4s - 6. 
s2 + 3s + 2 
To derive the direct-form block diagram representation of S, we first consider a 
causal LTI system S1 that has the same input x(t) asS, but whose system function 
is 
1 
Ht(S) = 
2 
3 
2" 
s + s + 
With the output of St denoted by y1 (t), the direct-form block diagram representation 
of St is shown in Figure P9.36. The signals e(t) and f(t) indicated in the figure 
represent respective inputs into the two integrators. 
(a) Express y(t) (the output of S) as a linear combination of y1 (t), dy1 (t)/dt, and 
d 2yt(t)/dt2. 
. 
(b) How is dy1 (t)ldt related to f(t)? 
(c) How is d 2y 1 (t)/dt2 related to e(t)? 
(d) Express y(t) as a linear combination of e(t), f(t), and Yt (t). 
f(t) 
x(t) 
Figure P9.36 
Y1(t) 

Chap.9 
Problems 
731 
(e) Use the result from the previous part to extend the direct-form block diagram 
representation of S1 and create a block diagram representation of S. 
(f) Observing that 
H(s) = (2(s- 1))(~). 
s+2 
s+l 
draw a block diagram representation for S as a cascade combination of two 
subsystems. 
(g) Observing that 
6 
8 
H(s) = 2 + -- - -
-
s+2 
s+l' 
draw a block-diagram representation for S as a parallel combination of three 
subsystems. 
· 
9.31. Draw a direct"form representation for the causal LTI systems with the following 
system functions: 
s+I 
(b) H ( ) 
s2-5s+6 
s 
(a) HJ(S) = s2+5s+6 
2 s = s2+7s+IO 
(c) H3(s) = (s+2)2 
9.38. Consider a fourth-order causal LTI system S whose system function is specified as 
1 
H(s) = (s2 - s + l)(s2 + 2s + 1)" 
(a) Show that a block diagram representation for S consisting of a cascade of 
four first-order sections will contain multiplications by coefficients that are not 
purely real. 
(b) Draw a block diagram representation for S as a cascade interconnection of two 
second-order systems, each of which is represented in direct form. There should 
be no multiplications by nonreal coefficients in the resulting block diagram. 
(c) Draw a block diagram representation for S as a parallel interconnection of two 
second-order systems, each of which is represented in direct form. There should 
be no multiplications by nonreal coefficients in the resulting block diagram. 
9.39. Let 
x1(t) = e-21u(t) 
and 
x2(t) = e-3(r+I)u(t + 1). 
(a) Determine the unilateral Laplace transform ~ 1 (s) and the bilateral Laplace 
transform X1 (s) for the signal XI (t). 
(b) Determine the unilateral Laplace transform ~2(s) and the bilateral Laplace 
transform X2(s) for the signal x2(t). 
(c) Take the inverse bilateral Laplace transform of the product X1 (s)Xz(s) to deter-
mine the signal g(t) = x1 (t) * x2(t). 
(d) Show that the inverse unilateral Laplace transform of the product~~ (s)~z(s) 
is not the same as g(t) fort > o-. 
9.40. Consider the system S characterized by the differential equation 
d3y(t) 
6d2y(t) 
11 dy(t) 
6 () = ( ) 
dt3 + 
dt2 + 
dt + y t 
X t . 

732 
The Laplace Transform 
Chap.9 
(a) Determine the zero-state response of this system for the input x(t) = e- 41 u(t). 
(b) Determine the zero-input response of the system fort> o-, given that 
dy(t) I 
= -1. 
dt 
t=O-
. 
d2y(t) I 
= 1 
dt2 
. 
t=o-
(c) Determine the output of S when the input is x(t) = e- 41u(t) and the initial con-
ditions are the same as those specified in part (b). 
ADVANCED PROBLEMS 
9.41. (a) Show that, if x(t) is an even function, so that x(t) = x( -t), then X(s) = X( -s). 
(b) Show that, if x(t) is an odd function, so that x(t) = -x(-t), then X(s) = 
-X(-s). 
(c) Determine which, if any, of the pole-zero plots in Figure P9.41 could correspond 
to an even function of time. For those that could, indicate the required ROC. 
----x--~~--x-----
- 1 
1 
<R.e 
(a) 
(b) 
-- X __ __,f----X-----
-- X __ __,r------o------
- 1 
1 
<R.e 
-1 
<R.e 
-j 
(c) 
(d) 
Figure P9 .41 

Chap. 9 
Problems 
733 
9.42. Determine whether each of the following statements is true or false. If a statement 
is true, construct a convincing argument for it. If it is false, give a counterexample. 
(a) The Laplace transform of Pu(t) does not converge anywhere on the s-plane. 
(b) The Laplace transform of e
12 u(t) does not converge anywhere on the s-plane. 
(c) The Laplace transform of ejwot does not converge anywhere on the s-plane. 
(d) The Laplace transform of ejwot u(t) does not converge anywhere on the s-plane. 
(e) The Laplace transform of ltl does not converge anywhere on the s-plane. 
9.43. Let h(t) be the impulse response of a causal and stable LTI system with a rational 
system function. 
(a) Is the system with impulse response dh(t)ldt guaranteed to be causal and stable? 
(b) Is the system with impulse response C., h( T) d T guaranteed to be causal and 
unstable? 
9.44. Let x(t) be the sampled signal specified as 
eo 
x(t) = 2: e - nT 8(t- nT), 
11 = 0 
where T > 0. 
(a) Determine X(s), including its region of convergence. 
(b) Sketch the pole-zero plot for X(s). 
(c) Use geometric interpretation of the pole-zero plot to argue that X(jw) is peri-
odic. 
9.45. Consider the LTI system shown in Figure P9.45(a) for which we are given the fol-
lowing information: 
and 
X(s)=s+2, 
s-2 
x(t) = 0, 
t > 0, 
[See Figure P9.45(b).] 
(a) Determine H(s) and its region of convergence. 
(b) Determine h(t). 
(a) 
Figure P9.45 
y(t) 
(b) 

734 
The Laplace Transform 
Chap.9 
(c) Using the system function H(s) found in part (a), determine the output y(t) if 
the input is 
- oo < t < + oo. 
9.46. Let H(s) represent the system function for a causal, stable system. The input to 
the system consists of the sum of three terms, one of which is an impulse 8(t) and 
another a complex exponential of the form e sot, where so is a complex constant. The 
output is 
y(t) = -6e-r u(t) + 3: e41 cos 3t + !! e41 sin 3t + 8(t). 
Determine H(s), consistently with this information. 
9.47. The signal 
y(t) = e- 21 u(t) 
is the output of a causal all-pass system for which the system function is 
s - 1 
H(s) = s + 1" 
(a) Find and sketch at least two possible inputs x(t) that could produce y(t). 
(b) What is the input x(t) if it is known that 
I:"' lx(t)l dt < oo? 
(c) What is the input x(t) if it is known that a stable (but not necessarily causal) 
system exists that will have x(t) as an output if y(t) is the input? Find the im-
pulse response h(t) of this filter, and show by direct convolution that it has the 
property claimed [i.e., that y(t) * h(t) = x(t)]. 
9.48. The inverse of an LTI system H(s) is defined as a system that, when cascaded with 
H(s), results in an overall transfer function of unity or, equivalently, an overall im-
pulse response that is an impulse; 
(a) If H 1 (s) denotes the transfer function of an inverse system for H(s), determine 
the general algebraic relationship between H(s) and H1 (s). 
(b) Shown in Figure P9.48 is the pole-zero plot for a stable, causal system H(s). 
Determine the pole-zero plot for the associated inverse system. 
-------x----~~---------
- 1 
1 2 
<Re 
Figure P9.48 

Chap. 9 
Problems 
735 
9.49. A class of systems, referred to as minimum-delay or minimum-phase systems, is 
sometimes defined through the statement that these systems are causal and stable 
and that the inverse systems are also causal and stable. 
Based on the preceding definition, develop an argument to demonstrate that 
all poles and zeros of the transfer function of a minimum-delay system must be in 
the left half of the s-plane [i.e., <Re{s} < 0]. 
9.50. Determine whether or not each of the following statements about LTI systems is 
true. If a statement is true, construct a convincing argument for it. If it is false, give 
a counterexample. 
(a) A stable continuous-time system must have all its poles in the left half of the 
s-plane [i.e., (Jl.e{s} < 0]. 
(b) If a system function has more poles than zeros, and the system is causal, the 
step response will be continuous at t = 0. 
(c) If a system function has more poles than zeros, and the system is not restricted 
to be causal, the step response can be discontinuous at t = 0. 
(d) A stable, causal system must have all its poles and zeros in the left half of the 
s-plane. 
9.51. Consider a stable and causal system with a real impulse response h(t) and system 
function H(s). It is known that H(s) is rational, one of its poles is at -1 + j , one 
of its zeros is at 3 + j, and it has exactly two zeros at infinity. For each of the 
following statements, determine whether it is true, whether it is false, or whether 
there is insufficient information to determine the statement's truth. 
(a) h(t)e- 31 is absolutely integrable. 
(b) The ROC for H(s) is (Re{s} > - 1. 
(c) The differential equation relating inputs x(t) and outputs y(t) for S may be writ-
ten in a form having only real coefficients. 
(d) lim5 __,ooH(s) = 1. 
(e) H(s) does not have fewer than four poles. 
(f) H(jw) = 0 for at least one finite value of w. 
(g) If the input to Sis e31 sin t, the output is e31 cost. 
9.52. As indicated in Section 9.5, many of the properties of the Laplace transform and 
their derivation are analogous to corresponding properties of the Fourier transform 
and their derivation, as developed in Chapter 4. In this problem, you are asked to 
outline the derivation of a number of the Laplace transform properties. 
Observing the derivation for the corresponding property in Chapter 4 for the 
Fourier transform, derive each of the following Laplace transform properties. Your 
derivation must include a consideration of the region of convergence. 
(a) Time shifting (Section 9.5.2) 
(b) Shifting in the s-domain (Section 9.5.3) 
(c) Time scaling (Section 9.5.4) 
(d) Convolution property (Section 9.5.6) 
9.53. As presented in Section 9.5.10, the initial-value theorem states that, for a signal x(t) 
with Laplace transform X(s) and for which x(t) = 0 fort < 0, the initial value of 
x(t) [i.e., x(O+ )] can be obtained from X(s) through the relation 
x(O+) = lim sX(s). 
[eq. (9.110)] 
S --+ 00 

736 
The Laplace Transform 
Chap. 9 
First, we note that, since x(t) = 0 fort< 0, x(t) = x(t)u(t). Next, expanding x(t) 
as a Taylor series at t = 0+, we obtain 
x(t) = [ x(O+) + x<I)(O+ )t + · · · + x<nl(O+) :~ + 
0 
• 
0
] u(t), 
(P9.53-l) 
where x<n)(O+ ) denotes the nth derivative of x(t) evaluated at t = 0+. 
(a) Determine the Laplace transform of an arbitrary term x<nl(O+ )(t11/n!)u(t) on the 
right-hand side of eq. (P9.53-l). (You may find it helpful to review Example 
9.14.) 
(b) From your result in part (a) and the expansion in eq. (P9.53-l), show that X(s) 
can be expressed as 
"' 
1 
X(s) = "'C"' x<n)(O+ )-o 
L... 
sn+ l 
n=O 
(c) Demonstrate that eqo (9.110) follows from the result of part (b). 
(d) By first determining x(t), verify the initial-value theorem for each of the fol-
lowing examples: 
(1) X(s) = s~2 
(2) X(s) = (s+;~~ + 3 ) 
(e) A more general form of the initial-value theorem states that if x<
11>(0+) = 0 for 
n < N, then x<Nl(O+) = lims ..... "'sN+ 1 X(s). Demonstrate that this more general 
statement also follows from the result in part (b). 
9.54. Consider a real-valued signal x(t) with Laplace transform X(s). 
(a) By applying complex conjugation to both sides of eq. (9.56), show that X(s) = 
X*(s*). 
(b) From your result in (a)', show that if X(s) has a pole (zero) at s = so, it must 
also have a pole (zero) at s = s0; i.e., for x(t) real, the poles and zeros of X(s) 
that are not on the real axis must occur in complex conjugate pairs. 
9.55. In Section 9.6, Table 9.2, we listed a number of Laplace transform pairs, and we 
indicated specifically how transform pairs 1 through 9 follow from Examples 9.1 
and 9.14, together with various properties from Table 9.1. 
By exploiting properties from Table 9.1, show how transform pairs 10 through 
16 follow from transform pairs 1 through 9 in Table 9.20 
9.56. The Laplace transform is said to exist for a specific complex s if the magnitude of 
the transform is finite-that is, if IX(s)l < co. 
Show that a sufficient condition for the existence of the transform X(s) at s = 
so = cro + jwo is that 

Chap. 9 
Problems 
737 
In other words, show that x(t) exponentially weighted by e - uot is absolutely inte-
grable. You will need to use the result that, for a complex function f(t), 
1r f(t)dtl :::;; r lf(t)l dt. 
(P9.56-l) 
Without rigorously proving eq. (P9.56-1), argue its plausibility. 
9.57. The Laplace transform X(s) of a signal x(t) has four poles and an unknown number 
of zeros. The signal x(t) is known to have an impulse at t = 0. Determine what 
information, if any, this provides about the number of zeros and their locations. 
9.58. Let h(t) be the impulse response of a causal and stable LTI system with rational 
system function H(s). Show that g(t) = CRe{h(t)} is also the impulse response of a 
causal and stable system. 
9.59. If~(s) denotes the unilateral Laplace transform of x(t), determine, in terms of~(s), 
the unilateral Laplace transform of: 
(a) x(t - 1) 
(b) x(t + 1) 
(c) J:,x( T) dT 
(d) d~~~r) 
EXTENSION PROBLEMS 
9.60. In long-distance telephone communication, an echo is sometimes encountered due 
to the transmitted signal being reflected at the receiver, sent back down the line, re-
flected again at the transmitter, and returned to the receiver. The impulse response 
for a system that models this effect is shown in Figure P9.60, where we have as-
sumed that only one echo is received. The parameter T corresponds to the one-way 
travel time along the communication channel, and the parameter a represents the 
attenuation in amplitude between transmitter and receiver. 
h(t) 
I 
a 
t 
t 
0 
T 
3T 
Figure P9.60 
(a) Determine the system function H(s) and associated region of convergence for 
the system. 
(b) From your result in part (a), you should observe that H(s) does not consist of a 
ratio of polynomials. Nevertheless, it is useful to represent it in terms of poles 
and zeros, where, as usual, the zeros are the values of s for which H(s) = 0 

738 
The Laplace Transform 
Chap.9 
and the poles are the values of s for which 1/H(s) = 0. For the system function 
found in part (a), determine the zeros and demonstrate that there are no poles. 
(c) From your result in part (b), sketch the pole-zero plot for H(s). 
(d) By considering the appropriate vectors in the s-plane, sketch the magnitude of 
the frequency response of the system. 
9.61. The autocorrelation function of a signal x(t) is defined as 
cfl:u:(T) = J:oo x(t)x(t + T)dt. 
(a) Determine, in terms of x(t), the impulse response h(t) of an LTI system for 
which, when the input is x(t), the output is cflxx(t) [Figure P9.61(a)]. 
(b) From your answer in part (a), determine «Pxx(s), the Laplace transform of cflxx( T) 
in terms of X(s). Also, express «Pxx(jw), the Fourier transform of cflxx(T), in 
terms of X(jw ). 
(c) If X(s) has the pole-zero pattern and ROC shown in Figure P9.61(b), sketch the 
pole-zero pattern and indicate the ROC for «Pxx(s). 
9m 
[ 
-x~*~--~+--
- 3 -2 - ~ 
CR.e 
x(t)~<l>xx(t) 
(a) 
Figure P9.6-l 
I 
Ll ----...1 
(b) 
9.62. In a number of applications in signal design and analysis, the class of signals 
cfln(t) = e - t/2 Ln(t)u(t), 
n = 0, 1, 2, .. . , 
(P9.62-1) 
where 
(P9.62- 2) 
is encountered. 
(a) The functions Ln(t) are referred to as Laguerre polynomials. To verify that they 
in fact have the form of polynomials, determine Lo(t), L 1 (t), and L].(t) explicitly. 
(b) Using the properties of the Laplace transform in Table 9.1 and Laplace trans-
form pairs in Table 9.2, determine the Laplace transform «Pn(s) of cfln(t). 
(c) The set of signals cfln(t) can be generated by exciting a network of the form in 
Figure P9.62 with an impulse. From your result in part (b), determine Ht(s) 
and H2(s) so that the impulse responses along the cascade chain are the signals 
c/Jn(t) as indicated. 

Chap.9 
Problems 
739 
8(t) 
Figure P9.62 
9.63. In filter design, it is often possible and convenient to transform a lowpass filter to 
a highpass filter and vice versa. With H(s) denoting the transfer function of the 
original filter and G(s) that of the transformed filter, one such commonly used trans-
formation consists of replacing s by 1/s; that is, 
G(s) = HG). 
(a) For H(s) = ll(s + 112), sketch IH(jw)l and IG(jw)l. 
(b) Determine the linear constant-coefficient differential equation associated with 
H(s) and with G(s). 
(c) Now consider a more general case in which H(s) is the transfer function asso-
ciated with the linear constant-coefficient differential equation in the general 
form 
..f!::. a dky(t) = ..f!::. b dk x(t) 
~ k d~ 
~ k d~ . 
k=O 
k=O 
(P9.63-1) 
Without any loss of generality, we have assumed that the number of derivatives 
N is the same on both sides of the equation, although in any particular case, 
some of the coefficients may be zero. Determine H(s) and G(s). 
(d) From your result in part (c), determine, in terms of the coefficients in 
eq. (P9.63-l), the linear constant-coefficient differential equation associated 
with G(s). 
9.64. Consider the RLC circuit shown in Figure 9.27 with input x(t) and output y(t). 
(a) Show that if R, L, and Care all positive, then this LTI system is stable. 
(b) How should R, L, and C be related to each other so that the system represents a 
second-order Butterworth filter? 
9.65. (a) Determine the differential equation relating v;(t) and v0(t) for the RLC circuit 
of Figure P9.65. 
30 
1h 
v0(0+) = 1 
dvo(t)l = 2 
dt 
t = 0+ 
Figure P9.65 

740 
The Laplace Transform 
Chap. 9 
(b) Suppose that v;(t) = e-31u(t). Using the unilateral Laplace transform, deter-
mine V0 (t) fort> 0. 
9.66. Consider the RL circuit shown in Figure P9.66. Assume that the current i(t) has 
reached a steady state with the switch at position A. At time t = 0, the switch is 
moved from position A to position B. 
i(t) 
L=1H 
Figure P9.66 
(a) Find the differential equation relating i(t) and v2 for t > o-. Specify the initial 
condition (i.e., the value of i(O- )) for this differential equation in terms of v1• 
(b) Using the properties of the unilateral Laplace transform in Table 9.3, determine 
and plot the current i(t) for each of the following values of v1 and v2 : 
(i) v, = 0 V, v 2 = 2 V 
(ii) 
V] = 4 V, V2 = 0 v 
(iii) Vt = 4 V, V2 = 2 V 
Using your answers for (i), (ii), and (iii), argue that the current i(t) may be 
expressed as a sum of the circuit's zero-state response and zero-input response. 

10 
THE Z-TRANSFORM 
10.0 INTRODUCTION 
In Chapter 9, we developed the Laplace transform as an extension of the continuous-time 
Fourier transform. This extension was motivated in part by the fact that it can be applied 
to a broader class of signals than the Fourier transform can, since there are many sig-
nals for which the Fourier transform does not converge but the Laplace transform does. 
The Laplace transform allowed us, for example, to perform transform analysis of unstable 
systems and to develop additional insights and tools for LTI system analysis. 
In this chapter, we use the same approach for discrete time as we develop the z-
transform, which is the discrete-time counterpart of the Laplace transform. As we will 
see, the motivations for and properties of the z-transform closely parallel those of the 
Laplace transform. Just as with the relationship between continuous-time and discrete-
time Fourier transforms, however, we will encounter some important distinctions between 
the z-transform and the Laplace transform that arise from the fundamental differences 
between continuous-time and discrete-time signals and systems. 
1 0. 1 THE z-TRANSFORM 
As we saw in Section 3.2, for a discrete-time linear time-invariant system with impulse 
response h[n], the response y[n] of the system to a complex exponential input of the form 
zn is 
y[n] = H(z)zn, 
(10.1) 
741 

742 
The z-Transform 
Chap. 10 
where 
+co 
H(z) = L h[n]z- n. 
(10.2) 
n= - co 
For z = eiw with w real (i.e., with lzl = 1), the summation in eq. (10.2) corresponds to 
the discrete-time Fourier transform of h[n]. More generally, when lzl is not restricted to 
unity, the summation is referred to as the z-transform of h[n]. 
The z-transform of a general discrete-time signal x[n] is defined as 1 
+co 
X(z) ~ L x[n]z- n, 
(10.3) 
n= - oo 
where z is a complex variable. For convenience, the z-transform of x[n] will sometimes 
be denoted as Z{x[n]} and the relationship between x[n] and its z-transform indicated as 
z 
x[n] ~ 
X(z). 
(10.4) 
In Chapter 9, we considered a number of important relationships between the 
Laplace transform and the Fourier transform for continuous-time signals. In a similar, but 
not identical, way, there are a number of important relationships between the z-transform 
and the discrete-time Fourier transform. To explore these relationships, we express the 
complex variable z in polar form as 
z = reiw, 
(10.5) 
with r as the magnitude of z and was the angle of z. In terms of rand w, eq. (10.3) becomes 
+ co 
X(reiw) = L x[n](reiw)- n, 
n= - oo 
or equivalently, 
+co 
X(reiw) = L {x[n]r- n}e- Jwn. 
(10.6) 
n= - oo 
From eq. (10.6), we see that X(reiw) is the Fourier transform of the sequence x[n] 
multiplied by a real exponential r-n; that is, 
X(reiw) = :!{x[n]r- n}. 
(10.7) 
The exponential weighting r - n may be decaying or growing with increasing n, depending 
on whether r is greater than or less than unity. We note in particular that, for r = 1, or 
1The z-transform defined in eq. (10.3) is often referred to as the bilateral z-transform, to distinguish 
it from the unilateral z-transform, which we develop in Section 10.9. The bilateral z-transform involves a 
summation from - oo to + oo, while the unilateral transform has a form similar to eq. (10.3), but with summation 
limits from 0 to +oo. Since we are mostly concerned with the bilateral z-transform, we will refer to X(z) as 
defined in eq. (10.3) simply as the z-transform, except in Section 10.9, in which we use the words "unilateral" 
and "bilateral" to avoid ambiguity. 

Sec. 10.1 
The z-Transform 
743 
equivalently, /z/ = 1, eq. (10.3) reduces to the Fourier transform; that is, 
X(z)l z=ejw = X(ejw) = ~{x[n]}. 
(10.8) 
The relationship between the z-transform and Fourier transform for discrete-time 
signals parallels closely the corresponding discussion in Section 9.1 for continuous-time 
signals, but with some important differences. In the continuous-time case, the Laplace 
transform reduces to the Fourier transform when the real part of the transform variable is 
zero. Interpreted in terms of the s-plane, this means that the Laplace transform reduces to 
the Fourier transform on the imaginary axis (i.e., for s = jw ). In contrast, the z-transform 
reduces 'to the Fourier transform when the magnitude of the transform variable z is unity 
(i.e, for z = ejw). Thus, the z-transform reduces to the Fourier transform on the contour 
in the complex z-plane corresponding to a circle with a radius of unity, as indicated in 
Figure 10.1. This circle in the z-plane is referred to as the unit circle and plays a role in 
the discussion of the z-transform similar to the role of the imaginary axis in the s-plane for 
the Laplace transform. 
!1m 
z-plane 
Figure 1 o. 1 
Complex z-plane. The 
z-transform reduces to the Fourier 
transform for values of z on the unit 
circle. 
From eq. (10.7), we see that, for convergence of the z-transform, we require that the 
Fourier transform of x[n]r- n converge. For any specific sequence x[n], we would expect 
this convergence for some values of r and not for others. In general, the z-transform of a 
sequence has associated with it a range of values of z for which X(z) converges. As with 
the Laplace transform, this range of values is referred to as the region of convergence 
(ROC). If the ROC includes the unit circle, then the Fourier transform also converges. To 
illustrate the z-transform and the associated region of convergence, let us consider several 
examples. 
Example 1 0. 1 
Consider the signal x[n] = a"u[n]. Then, from eq. (10.3), 
+ oo 
oo 
X(z) = L a"u[n]z- " = L(az- 1)". 
n = - oo 
n=O 
For convergence of X(z), we require that :L:~= o laz- 11" < oo. Consequently, the region 
of convergence is the range of values of z for which laz- 11 < I, or equivalently, lzl > Ia!. 

744 
Then 
X(z) = 2 )az- ')" = -:-1-- -a-z_-.,., 
n=O 
The z-Transform 
z 
z - a' 
lzl > lal. 
Chap. 10 
(10.9) 
Thus, the z-transform for this signal is well-defined for any value of a, with an ROC 
determined by the magnitude of a according to eq. (10.9). For example, for a = 1, x[n] 
is the unit step sequence with z-transform 
1 
X(z) = -1 
- T' 
- z 
lzl > 1. 
,, 
We see that the z-transform in eq. (10.9) is a rational function. Consequently, just 
as with rational Laplace transforms, the z-transform can be characterized by its zeros (the 
roots of the numerator polynomial) and its poles (the roots of the denominator polyno-
mial). For this example, there is one zero, at z = 0, and one pole, at z = a. The pole-zero 
plot and the region of convergence for Example 10.1 are shown in Figure 10.2 for a value 
of a between 0 and 1. For lal > 1, the ROC does not include the unit circle, consistent 
with the fact that, for these values of a, the Fourier transform of a"u[n] does not converge. 
Unit Circle 
(fl..e 
Figure 1 0.2 
Pole-zero plot and region of convergence for Example 10.1 for 
0 <a< 1. 
Example 1 0.2 
Now let x[n] = - a"u[ - n - 1]. Then 
+oo 
- 1 
X(z) = - L a"u[- n - 1]z-n = - L a"z- n 
n = - oc 
n = - oo 
00 
00 
- 2:a-"z" = 1 - 2:ca-1z)". 
n = 1 
n = O 
If la- 1 zl < 1, or equivalently, lzl < lal, the sum in eq. (10.10) converges and 
1 
X(z) = l - ..,---,-
1- a- 1z 
1 - az- 1 
z 
z - a' 
lzl < lal. 
(10.10) 
(10.11) 
The pole-zero plot and region of convergence for this example are shown in Fig-
ure 10.3 for a value of a between 0 and 1. 

Sec. 10.1 
The z-Transform 
Figure 1 0.3 
Pole-zero plot and region of convergence for Example 10.2 for 
0 < a< 1. 
745 
Comparing eqs. (10.9) and (10.11), and Figures 10.2 and 10.3, we see that the al-
gebraic expression for X(z) and the corresponding pole-zero plot are identical in Exam-
ples 10.1 and 10.2, and the z-transforms differ only in their regions of convergence. Thus, 
as with the Laplace transform, specification of the z-transform requires both the algebraic 
expression and the region of convergence. Also, in both examples, the sequences were 
exponentials and the resulting z-transforms were rational. In fact, as further suggested by 
the following examples, X(z) will be rational whenever x[n] is a linear combination of real 
or complex exponentials: 
Example 1 0.3 
Let us consider a signal that is the sum of two real exponentials: 
(1)" 
(1)" 
x[n] = 7 3 u[n] - 6 2 u[n]. 
(10.12) 
The z-transform is then 
+"' { (1)" 
(1)
11 
} 
X(z) = n~"' 7 3 u[n] - 6 2 u[n] z- n 
(10.13) 
7 
6 
1 - .! z- 1 
1 -
.! z-I 
3 
2 
(10.14) 
z(z -
~) 
(10.15) 
For convergence of X(z), both sums in eq. (10.13) must converge, which requires 
that both J(113)z- 1J < 1 and J(ll2)z- 1J < 1, or equivalently, Jzl > 113 and lzl > 112. Thus, 
the region of convergence is JzJ > 112. 

746 
The z-Transform 
Chap. 10 
The z-transform for this example can also be obtained using the results of Exam-
ple 10.1. Specifically, from the definition of the z-transform in eq. (10.3), we see that the 
z-transform is linear; that is, if x[n] is the sum of two terms, then X(z) will be the sum 
of the z-transforms of the individual terms and will converge when both z-transforms 
converge. From Example 10.1, 
and 
( 1 )" 
z 
3 u[n] +---+ 1 
1 _ 1, 
lzl > ~ 
-
jZ 
( 1 )" 
z 
1 
-2 
u[n] ~ 
-
----.---------,-
1 - !.z- 1' 
2 
lzl > ~. 
(10.16) 
(10.17) 
and consequently, 
(1)" 
(1)" 
z 
7 3 u[n] - 6 z u[n] ~ 
(10.18) 
7 
6 
-
----;-, -
1 
, lzl > ~. 
1 - - z- 1 
1 - - z- 1 
3 
. 
2 
as we determined before. The pole-zero plot and ROC for the z-transform of each of the 
individual terms and for the combined signal are shown in Figure 10.4. 
9m 
9m 
(a) 
(b) 
(c) 
Figure 1 0.4 
Pole-zero plot and region of convergence for the individual terms 
and the sum in Example 10.3: (a)1/(1 -
~z-
1 ), lzl > ~; (b)1/(1 - ;z-1), lzl > ;; 
(c)?/(1 -
~z-
1
) - 6/(1 - ;z-1), lzl > ; . 

Sec. 10.1 
The z-Transform 
747 
Example 1 0.4 
Let us consider the signal 
x[n] = (~)'' sinGn)u[n] 
The z-transform of this signal is 
(10.19) 
or equivalently, 
(10.20) 
For convergence of X(z), both sums in eq. (10,19) must converge, which requires 
that j(l/3)eirr/4z- 11 < 1 and j(l/3)e- j1T14z-'l < 1, or equivalently, lzl > 113. The pole-
zero plot and ROC for this example are shown in Figure 10.5. 
Figure 10.5 
Pole-zero plot and ROC for the z-transform in Example 1 OA. 
In each of the preceding four examples, we expressed the z-transform both as a 
ratio of polynomials in z and as a ratio of polynomials in z- 1• From the definition of 
the z-transform as given in eq. (10.3), we see that, for sequences which are zero for 
n < 0, X(z) involves only negative powers of z. Thus, for this class of signals, it is partic-
ularly convenient for X(z) to be expressed in terms of polynomials in z- 1 rather than z, and 

748 
The z-Transform 
Chap. 10 
when appropriate, we will use that form in our discussion. However, reference to the poles 
and zeros is always in terms of the roots of the numerator and denominator expressed as 
polynomials in z. Also, it is sometimes convenient to refer to X(z), written as a ratio of 
polynomials in z, as having poles at infinity if the degree of the numerator exceeds the 
degree of the denominator or zeros at infinity if the numerator is of smaller degree than 
the denominator. 
1 0.2 THE REGION OF CONVERGENCE FOR THE z-TRANSFORM 
In Chapter 9, we saw that there were specific properties of the region of convergence 
of the Laplace transform for different classes of signals and that understanding these 
properties led to further insights about the transform. In a similar manner, we explore 
a number of properties of the region of convergence for the z-transform. Each of the 
following properties and its justification closely parallel the corresponding property in 
Section 9.2. 
Property 1: 
The ROC of X(z) consists of a ring in the z-plane centered about the 
origin. 
This property is illustrated in Figure 10.6 and follows from the fact that the ROC 
consists of those values of z c= rej<JJ for which x[n]r-n has a Fourier transform that con-
verges. That is, the ROC of the z-transform of x[n] consists of the values of z for which 
x[n]r- n is absolutely summable:2 
I 
I 
/ ' 
/ 
\ 
' 
/ 
n= - oo 
-
- ··-., .... 
' ' \ 
I 
I 
' ', z-plane 
\ 
I 
(10.21) 
Figure 1 0.6 
ROC as a ring in the 
z-plane. In some cases, the inner 
boundary can extend inward to the ori-
gin, in which case the ROC becomes a 
disc. In other cases, the outer bound-
ary can extend outward to infinity. 
2For a thorough treatment of the mathematical properties of z-transforms, see R.V. Churchill and J.W. 
Brown, Complex Variables and Applications (5th ed.) (New York: McGraw-Hill, 1990), and E. I. Jury, Theory 
and Application of the z-Transform Method (Malabar, FL: R. E. Krieger Pub. Co., 1982). 

Sec. 10.2 
The Region of Convergence for the z-Transform 
749 
Thus, convergence is dependent only on r = lzl and not on w. Consequently, if a 
specific value of z is in the ROC, then all values of z on the same circle (i.e., with the 
same magnitude) will be in the ROC. This by itself guarantees that the ROC will con-
sist of concentric rings. As we will see when we discuss Property 6, the ROC must in 
fact consist of only a single ring. In some cases the inner boundary of the ROC may ex-
tend inward to the origin, and in some cases the outer boundary may extend outward to 
infinity. 
Property 2: 
The ROC does not contain any poles. 
As with the Laplace transform, this property is simply a consequence of the fact that 
at a pole X(z) is infinite and therefore, by definition, does not converge. 
Property 3: 
If x[n] is of finite duration, then the ROC is the entire z-plane, except 
possibly z = 0 and/or z = oo. 
A finite-duration sequence has only a finite number of nonzero values, extending, 
say, from n = N1 ton = N2, where N1 and N2 are finite. Thus, the z-transform is the sum 
of a finite number of terms; that is, 
N2 
X(z) = 2: x[n]z- ". 
(10.22) 
n = N 1 
For z not equal to zero or infinity, each term in the sum will be finite, and conse-
quently, X(z) will converge. If N 1 is negative and N2 positive, so that x[n] has nonzero 
values both for n < 0 and n > 0, then the summation includes terms with both positive 
powers of z and negative powers of z. As lzl ~ 0, terms involving negative powers of 
z become unbounded, and as lzl ~ oo, terms involving positive powers of z become un-
bounded. Consequently, for N 1 negative and N2 positive, the ROC does not include z = 0 
or z = oo. If N 1 is zero or positive, there are only negative powers of z in eq. (10.22), and 
consequently, the ROC includes z = oo. If N2 is zero or negative, there are only positive 
powers of z in eq. (10.22), and consequently, the ROC includes z = 0. 
Example 10.5 
Consider the unit impulse signal i>[n]. Its z-transform is given by 
Z 
+ oo 
i>[n] ~ L 8[n]C' = 1, 
(10.23) 
n= - co 
with an ROC consisting of the entire z-plane, including z = 0 and z = oo. On the other 
hand, consider the delayed unit impulse 8[n - 1], for which 
(10.24) 
n= - co 

.. 
750 
The z-Transform 
Chap. 10 
This z-transform is well defined except at z = 0, where there is a pole. Thus, the ROC 
consists of the entire z-plane, including z = co but excluding z = 0. Similarly, consider 
an impulse advanced in time, namely, 8[n + 1]. In this case, 
Z 
+oo 
8[n + 1] ~ L 8[n + l]z- " = z. 
(10.25) 
n = - o:. 
which is well defined for all finite values of z. Thus, the ROC consists of the entire finite 
z-plane (including z = 0), but there is a pole at infinity . 
Property 4: If x[ n] is a right -sided sequence, and if the circle !zl = r0 is in the ROC, 
then all finite values of z for which !zl > ro will also be in the ROC. 
The justification for this property follows in a manner identical to that of Property 4 
in Section 9.2. A right-sided sequence is zero prior to some value of n, say, N 1• If the 
circle lzl = ro is in the ROC, then x[n]r0n is absolutely summable. Now consider lzl = r1 
with r 1 > ro, so that r1n decays more quickly than r0" for increasing n. As illustrated 
in Figure 10.7, this more rapid exponential decay will further attenuate sequence values 
x[n] 
N, 
n 
IIIIIIIIIIIIIIIIIIIIIIIIIIIIII ~· 
n 
r n n 
,, .. ,,,, 
JJJJJTtttttttt,,,,,,,,,,, ... 
n 
Figure 10.7 
With r1 > r0,x[n]r,- n 
decays faster with increasing n than 
does x[n]r0- n. Since x[n] = O,n < N1, 
this implies that if x[n]cn is abso-
lutely summable, then x[n]r,- n will be 
also. 

Sec. 10.2 
The Region of Convergence for the z-Transform 
751 
for positive values of n and cannot cause sequence values for negative values of n to be-
come unbounded, since x[n] is right sided and, in particular, x[n]z- n = 0 for n < N 1• 
Consequently, x[n]r!n is absolutely summable. 
For right-sided sequences in general, eq. (10.3) takes the form 
00 
X(z) = L x[n]z- n, · 
(10.26) 
n = N1 
where N 1 is finite and may be positive or negative. If N1 is negative, then the summation 
in eq. (10.26) includes terms with positive powers of z, which become unbounded as lzl --.,) 
oo. Consequently, for right-sided sequences in general, the ROC will not include infinity. 
However, for the particular class of causal sequences, i.e., sequences that are zero for 
n < 0, N1 will be nonnegative, and consequently, the ROC will include z = oo. 
Property 5: 
If x[n] is a left-sided sequence, and if the circle lzl = ro is in the ROC, 
then all values of z for which 0 < lzl < ro will also be in the ROC. 
Again, this property closely parallels the corresponding property for Laplace trans-
forms, and the proof of it and its basis in intuition are similar to the proof and intuition 
for Property 4. In general, for left-sided sequences, from eq. (10.3), the summation for the 
z-transform will be of the form 
N2 
X(z) = 2: x[n]z- n, 
(10.27) 
n= - oo 
where N2 may be positive or negative. If N2 is positive, then eq. (10.27) includes negative 
powers of z, which become unbounded as lzl --.,) 0. Consequently, for left-sided sequences, 
the ROC will not in general include z = 0. However, if N2 ::s 0 (so that x[n] = 0 for all 
n > 0), the ROC will include z = 0. 
Property 6: If x[n] is two sided, and if the circle lzl = ro is in the ROC, then the 
ROC will consist of a ring in the z-plane that includes the circle lzl = r0 • 
As with Property 6 in Section 9.2, the ROC for a two-sided signal can be examined 
by expressing x[n] as the sum of a right-sided and a left-sided signal. The ROC for the 
right-sided component is a region bounded on the inside by a circle and extending outward 
to (and possibly including) infinity. The ROC for the left-sided component is a region 
bounded on the outside by a circle and extending inward to, and possibly including, the 
origin. The ROC for the composite signal includes the intersection of the ROCs of the 
components. As illustrated in Figure 10.8, the overlap (assuming that there is one) is a 
ring in the z-plane. 
We illustrate the foregoing properties with examples that closely parallel Exam-
ples 9.6 and 9.7. 

752 
The z-Transform 
z-plane 
(a) 
(b) 
' ,, 
' \ 
\ 
\ 
z-plane 
' 
(c) 
Figure 10.8 
(a) ROC for right-sided sequence; (b) ROC for left-sided sequence; 
(c) intersection of the ROCs in (a) and (b), representing the ROC for a two-sided se-
quence that is the sum of the right-sided and the left-sided sequence. 
Example 1 0.6 
Consider the signal 
Then 
{
a" 
x[n] = 
O,' 
N - 1 
0 :s n :s N - 1, a > 0 
otherwise 
X(z) = L a"z- n 
n=O 
1-(az- ')N 
1 zN - aN 
1 - az- 1 
-
zN- 1 z - a · 
z-plane 
Chap. 10 
(10.28) 

Sec. 10.2 
The Region of Convergence for the z-Transform 
753 
Since x[ n] is of finite length, it follows from Property 3 that the ROC includes the entire z-
plane except possibly the origin and/or infinity. In fact, from our discussion of Property 3, 
since x [n] is zero for n < 0, the ROC will extend to infinity. However, since x[n] is 
nonzero for some positive values of n, the ROC will not include the origin. This is evident 
from eq. (10.28), from which we see that there is a pole of order N - 1 at z = 0. TheN 
roots of the numerator polynomial are at 
Zk = aei(2rrk/Nl, 
k = 0, 1, . .. , N - l. 
(10.29) 
The root fork = 0 cancels the pole at z = a. Consequently, there are no poles other than 
at the origin. The remaining zeros are at 
Zk = aei(2rrk/Nl, 
k = 1, ... 'N - l. 
The pole-zero pattern is shown in Figure 10.9. 
(N-1 )st order pole 
z-plane 
Unit circle 
a 
Figure 1 o. 9 
Pole-zero pattern for Example 10.6 with N = 16 and 
0 < a < 1. The region of convergence for this example consists of all 
values of z except z = 0. 
(10.30) 
Example 10.7 
Let 
x[n] = bl"l, 
b > 0. 
(10.31) 
This two-sided sequence is illustrated in Figure 10.10, for both b < 1 and b > 1. The 
z-transform for the sequence can be obtained by expressing it as the sum of a right-sided 
and a left-sided sequence. We have 
From Example 10.1, 
and from Example 10.2, 
x[n] = b"u [n] + b- "u[ - n - 1]. 
z 
b"u[n] ~ 
lzl > b, 
1- bz 1' 
1 
lzl <b. 
(10.32) 
(10.33) 
(10.34) 

754 
The z-Transform 
Chap. 10 
O< b<1 
n 
(a) 
b > 1 
n 
(b) 
Figure 1 0.1 0 
Sequence x(n] = bini for 0 < b < 1 and for b > 1: (a) b = 
0.95; (b) b = 1.05. 
In Figures 10.11(a)- (d) we show the pole-zero pattern and ROC for eqs. (10.33) 
and (10.34), for values of b > 1 and 0 < b < 1. Forb> 1, there is no common ROC, 
and thus the sequence in eq. (10.31) will not have a z-transform, even though the right-
sided and left-sided components do individually. Forb< 1, the ROCs in eqs. (10.33) 
and (10.34) overlap, and thus the z-transform for the composite sequence is 
or equivalently, 
1 
X(z) = 1 - bz 
1 
1 - b I z I' 
b < lzl < b' 
b2 - 1 
z 
X(z) = -b- (z - b)(z- b- 1)' 
1 
b < lzl < b" 
The corresponding pole-zero pattern and ROC are shown in Figure 10.11(e). 
(10.35) 
(10.36) 

Sec. 10.2 
The Region of Convergence for the z-Transform 
755 
~m 
(a) 
(b) 
~m 
~m 
Unit circle 
Unit circle 
i z-plane 
z-plane 
(c) 
~m 
(e) 
I 
\ 
Unit circle 
(d) 
Figure 1 0. 11 
Pole-zero plots and ROCs for Example 10.7: (a) eq. (1 0.33) for 
b > 1; (b)eq. (10.34)for b > 1; (c) eq. (10.33)for0 < b < 1; (d)eq. (10.34)for 
0 < b < 1; (e) pole-zero plot and ROC for eq. (1 0.36) with 0 < b < 1. Forb > 1, 
the z-transform of x[n] in eq. (10.31) does not converge for any value of z. 

756 
The z-Transform 
Chap. 10 
In discussing the Laplace transform in Chapter 9, we remarked that for a rational 
Laplace transform, the ROC is always bounded by poles or infinity. We observe that in 
the foregoing examples a similar statement applies to the z-transform, and in fact, this is 
always true: 
Property 7: If the z-transform X(z) of x[n] is rational, then its ROC is bounded by 
poles or extends to infinity. 
Combining Property 7 with Properties 4 and 5, we have 
Property 8: If the z-transforrn X(z) of x[n] is rational, and if x[n] is tight sided, then 
the ROC is the region in the z-plane outside the outermost pole- i.e., outside the circle 
of radius equal to the largest magnitude of the poles of X(z). Furthermore, if x[n] is 
causal (i.e., if it is tight sided and equal to 0 for n < 0), then the ROC also includes 
z = 00, 
Thus, for right-sided sequences with rational transforms, the poles are all closer to 
the origin than is any point in the ROC. 
Property 9: 
If the z-transforrn X(z) of x[n] is rational, and if x[n] is left sided, then 
the ROC is the region in the z-plane inside the innermost nonzero pole-i.e., inside the 
circle of radius equal to the smallest magnitude of the poles of X(z) other than any at 
z = 0 and extending inward to and possibly including z = 0. In particular, if x[n] is 
anticausal (i.e., if it is left sided and equal to 0 for n > 0), then the ROC also includes 
z = 0. 
Thus, for left-sided sequences, the poles of X(z) other than any at z = 0 are farther 
from the origin than is any point in the ROC. 
For a given pole-zero pattern, or equivalently, a given rational algebraic. expression 
X(z), there are a limited number of different ROCs that are consistent with the preceding 
properties. To illustrate how different ROCs can be associated with the same pole-zero 
pattern, we present the following example, which closely parallels Example 9.8. 
Example 1 0.8 
Let us consider all of the possible ROCs that can be connected with the function 
1 
X(~ = 
. 
(1- ~z -
1 )(1- 2z- 1) 
(10.37) 
The associated pole-zero pattern is shown in Figure 10.12(a). Based on our discussion 
in this section, there are three possible ROCs that can be associated with this algebraic 
expression for the z-transforrn. These ROCs are indicated in Figure 10.12(b)- (d). Each 
corresponds to a different sequence. Figure 10.12(b) is associated with a right-sided 
sequence, Figure 10.12(c) with a left-sided sequence, and Figure 10.12(d) with a two-
sided sequence. Since Figure 10.12(d) is the only one for which the ROC includes the 
unit circle, the sequence corresponding to this choice of ROC is the only one of the three 
for which the Fourier transform converges. 

Sec. 10.3 
The Inverse z-Transform 
I'Jm 
I'Jm 
(a) 
(b) 
Unit circle 
' 
_ ' , z-plane 
ffi-e 
ffi-e 
(c) 
(d) 
Figure 1 o. 12 
The three possible ROCs that can be connected with the 
expression for the z-transform in Example 10.8: (a) pole-zero pattern for X(z); 
(b) pole-zero pattern and ROC if x[n) is right sided; (c) pole-zero pattern and 
ROC if x[n) is left sided; (d) pole-zero pattern and ROC if x[n] is two sided. In 
each case, the zero at the origin is a second-order zero. 
1 0.3 THE INVERSE z-TRANSFORM 
757 
In this section, we consider several procedures for determining a sequence when its z-
transform is known. To begin, let us consider the formal relation expressing a sequence in 
terms of its z-transform. This expression can be obtained on the basis of the interpretation, 
developed in Section 10.1, of the z-transform as the Fourier transform of an exponentially 
weighted sequence. Specifically, as expressed in eq. (10.7), 
(10.38) 
for any value of r so that z = rejw is inside the ROC. Applying the inverse Fourier trans-
form to both sides of eq. (10.38) yields 
x[n]r- n = g:- 1{X(rejw)}, 

758 
The z-Transform 
Chap. 10 
or 
x[n] = rn~ - l [X(reiw)]. 
(10.39) 
Using the inverse Fourier transform expression in eq. (5.8), we have 
or, moving the exponential factor rn inside the integral and combining it with the term 
eiwn, 
x[n] = -1- J X(reiw)(reiwtdw. 
21T 
27r 
(10.40) 
That is, we can recover x[n] from its z-transform evaluated along a contour z = reiw in 
the ROC, with r fixed and w varying over a 21T interval. Let us now change the variable 
of integration from w to z. With z = reiw and r fixed, dz = jreiwdw = jzdw, or dw = 
(11 j)z- 1 dz. The integration in eq. (10.40) is over a 21T interval in w, which, in terms of 
z, corresponds to one traversal around the circle lzl = r. Consequently, in terms of an 
integration in the z-plane, eq. (10.40) can be rewritten as 
1 ~ 
-
x[n] = 21T j J X(z)zn 1 dz, 
(10.41) 
where the symbol 0 denotes integration around a counterclockwise closed circular contour 
centered at the origin and with radius r. The value of r can be chosen as any value for 
which X(z) converges- i.e., any value such that the circular contour of integration lzl = r 
is in the ROC. Equation (10.41) is the formal expression for the inverse z-transform and 
is the discrete-time counterpart of eq. (9.56) for the inverse Laplace transform. As with 
eq. (9.56), formal evaluation of the inverse transform equation (10.41) requires the use 
of contour integration in the complex plane. There are, however, a number of alternative 
procedures for obtaining a sequence from its z-transform. As with Laplace transforms, one 
particularly useful procedure for rational z-transforms consists of expanding the algebraic 
expression into a partial-fraction expansion and recognizing the sequences associated with 
the individual terms. In the following examples, we illustrate the procedure. 
Example 10.9 
Consider the z-transform 
3 -
~z -
1 
X(z) = 
1 
6 
1 
, 
lzl > ~· 
(1- 4z- 1)(1 - 3z- 1) 
(10.42) 
There are two poles, one at z = 113 and one at z = 114, and the ROC lies outside the 
outermost pole. That is, the ROC consists of all points with magnitude greater than that 
of the pole with the larger magnitude, namely the pole at z = 1/3. From Property 4 in 
Section 10.2, we then know that the inverse transform is a right-sided sequence. As 
described in the appendix, X(z) can be expanded by the method of partial fractions. For 

Sec. 10.3 
The Inverse z-Transform 
759 
this example, the partial-fraction expansion, expressed in polynomials in z- 1, is 
1 
2 
X(z) = 1 
I 
- 1 + 
I 
. 
-4z 
1- 3z- l 
(10.43) 
Thus, x[n] is the sum of two terms, one with z-transform 11[1 - (l/4)z- 1] and the 
other with z-transform 2/[1 - (113)z- 1]. In order to determine the inverse z-transform of 
each of these individual terms, we must specify the ROC associated with each. Since 
the ROC for X(z) is outside the outermost pole, the ROC for ~ach individual term in 
eq. (10.43) must also be outside the pole associated with that term. That is, the ROC 
for each term consists of all points with magnitude greater than the magnitude of the 
corresponding pole. Thus, 
x[n] = x 1 [n] + x2[n], 
(10.44) 
where 
z 
lzl > i· 
x1[n] ~ 
1- .l.z- 1' 
4 
(10.45) 
z 
2 
lzl > ~· 
x2[n] ~ 
1 -
.l. z- 1' 
3 
(10.46) 
From Example 10.1, we can identify by inspection that 
(10.47) 
and 
( 1 )" 
x2[n] = 2 3 u[n], 
(10.48) 
and thus, 
(1)" 
(1)" 
x[n] = 4 u[n] + 2 3 u[n]. 
(10.49) 
Example 10.10 
Now let us consider the same algebraic expression for X(z) as in eq. (10.42), but with 
the ROC for X(z) as 114 < lzl < 113. Equation (10.43) is still a valid partial-fraction ex-
pansion of the algebraic expression for X(z), but the ROC associated with the individual 
terms will change. In particular, since the ROC for X(z) is outside the pole at z = 114, 
the ROC corresponding to this term in eq. (10.43) is also outside the pole and consists of 
all points with magnitude greater than 114, as it did in the previous example. However, 
since in this example the ROC for X(z) is inside the pole at z = 113, that is, since the 
points in the ROC all have magnitude less than 113, the ROC corresponding to this term 
must also lie inside this pole. Thus, the z-transform pairs for the individual components 
in eq. (10.44) are 
lzl > i· 
(10.50) 

760 
and 
z 
2 
xz[n] ~ 
-
----,--
1- .!z- I' 
3 
The z-Transform 
Chap. 10 
lzl < ~· 
(10.51) 
The signal XI [n] remains as in eq. (10.47), while from Example 10.2, we can identify 
(
1 )II 
x2[n] = - 2 3 u[ -n - 1], 
(10.52) 
so that 
(1)
11 
(1)
11 
x[n] = 4 u[n]- 2 3 u[ - n - 1]. 
(10.53) 
Example 10.11 
Finally, consider X(z) as in eq. (10.42), but now with the ROC lzl < 1/4. In this case the 
ROC is inside both poles, i.e., the points in the ROC all have magnitude smaller than 
either of the poles at z = 1/3 or z = 114. Consequently the ROC for each term in the 
partial-fraction expansion in eq. (10.43) must also lie inside the corresponding pole. As 
a result, the z-transform pair for XI [n] is given by 
1 
lzl < 4' 
(10.54) 
while the z-transform pair for x2[n] is given by eq. (10.51). Applying the result of Ex-
ample 10.2 to eq. (10.54), we find that 
(
1 )II 
XI[n]= ,- 4 u[-n-1], 
so that 
(1)
11 
(1)
11 
x[n] = -
4 u[ - n - 1] - 2 3 u[ -n- 1]. 
The foregoing examples illustrate the basic procedure of using partial-fraction ex-
pansions to determine inverse z-transforms. As with the corresponding method for the 
Laplace transform, the procedure relies on expressing the z-transform as a linear com-
bination of simpler terms. The inverse transform of each term can then be obtained by 
inspection. In particular, suppose that the partial-fraction expansion of X(z) is of the form 
m 
Ai 
X(z) = ~ 1-
. - I, 
i = I 
a,z 
(10.55) 
so that the inverse transform of X(z) equals the sum of the inverse transforms of the individ-
ual terms in the equation. If the ROC of X(z) is outside the pole at z = ai, the inverse trans-
form of the corresponding term in eq. (10.55) is Aiaju[n]. On the other hand, ifthe ROC 
of X(z) is inside the pole at z = ai, the inverse transform of this term is -Aiaju[ -n- 1]. 
In general, the partial-fraction expansion of a rational transform may include terms in 

Sec. 10.3 
The Inverse z-Transform 
761 
addition to the first-order terms in eq. (10.55). In Section 10.6, we list a number of other 
z-transform pairs that can be used in conjunction with the z-transform properties to be 
developed in Section 10.5 to extend the inverse transform method outlined in the preceding 
example to arbitrary rational z-transforms. 
Another very useful procedure for determining the inverse z-transform relies on a 
power-series expansion of X(z). This procedure is.motivated by the observation that the 
definition of the z-transform given in eq. (10.3) can be interpreted as a power series in-
volving both positive and negative powers of z. The coefficients in this power series are, 
in fact, the sequence values x[n]. To illustrate how a power-series expansion can be used 
to obtain the inverse z-transform, let us consider three examples. 
Example 1 0. 1 2 
Consider the z-transform 
X(z) = 4z2 + 2 + 3z- 1, 0 < lzl < oo. 
(10.56) 
From the power-series definition of the z-transform in eq. (10.3), we can determine the 
inverse transform of X(z) by inspection: 
{
4, 
n = - 2 
[] -
2, 
n=O 
x n -
3, 
n = 1 
0, 
otherwise 
That is, 
x[n] = 4B[n + 2] + 2B[n] + 3B[n - 1]. 
(10.57) 
Comparing eqs. (10.56) and (10.57), we see that different powers of z serve as placehold-
ers for sequence values at different points in time; i.e., if we simply use the transform 
pair 
z 
B[n +no] ~ 
z"0, 
we can immediately pass from eq. (10.56) to (10.57) and vice versa. 
Example 1 0. 1 3 
Consider 
X(z) = 1 _ az 1, 
lzl > Ia!. 
This expression can be expanded in a power series by long division: 
1+az- 1 + a2z- 2 + ··· 
1 - az- 1 1 
1 - az- 1 
az 1 
az- 1 - a2z- 2 
a2z- 2 

762 
The z-Transform 
Chap. 10 
-or 
(10.58) 
The series expansion of eq. (10.58) converges, since lzl > lal, or equivalently, laz- '1 < 1. 
Comparing this equation with the definition ofthe z-transform in equation (10.3), we see, 
by matching terms in powers of z, that x[n] = 0, n < 0; x[O] = 1; x[1] = a; x[2] = a2 ; 
and in general, x[n] = a"u[n], which is consistent with Example 10.1. 
If, instead, the ROC of X(z) is specified as lzl < lal or, equivalently, laz- '1 > 1, 
then the power-series expansion for 11(1 - az- 1) in eq. (10.58) does not converge. How-
ever, we can obtain a convergent power series by long division again: 
- az- 1 + 1 
or 
(10.59) 
In this case, then, x[n] = 0, n 2: 0; and x[ -1] = -a- 1, x[ -2] = - a- 2, .•. ; that is, 
x[n] = -a"u[ -n - 1]. This is consistent with Example 10.2. 
The power-series expansion method for obtaining the inverse z-transform is particu-
larly useful for nonrational z-transforms, which we illustrate with the following example: 
Example 1 0. 14 
Consider the z-transform 
X(z) = log(l + az- 1 ), 
lzl > lal. 
(10.60) 
With lzl > lal, or, equivalently, laz- 11 < 1, eq. (10.60) can be expanded in a power series 
using the Taylor's series expansion 
oo 
( 
1)"+' v" 
log(l + v) = L -
, lvl < 1. 
n = l 
n 
Applying this to eq. (10.60), we have 
from which we can identify 
oo (-1)"+ 1a"z- " 
X(z) = L 
, 
n = l 
n 
{ 
a" 
_ 
n+l 
x[n] = 
( 1) 
-;· 
0, 
n 2: 1 
n~O 
(10.61) 
(10.62) 
(10.63) 

Sec. 10.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
or equivalently, 
- (- a)" 
x [n] = -
-
u[n - 1]. 
n 
763 
In Problem 10.63 we consider a related example with region of convergence lzl < Ia I. 
1 0.4 GEOMETRIC EVALUATION OF THE FOURIER TRANSFORM 
FROM THE POLE-ZERO PLOT 
In Section 10.1 we noted that the z-transform reduces to the Fourier transform for lzl = 1 
(i.e., for the contour in the z-plane corresponding to the unit circle), provided that the 
ROC of the z-transform includes the unit circle, so that the Fourier transform converges. 
In a similar manner, we saw in Chapter 9 that, for continuous-time signals, the Laplace 
transform reduces to the Fourier transform on the jw-axis in the s-plane. In Section 9.4, 
we also discussed the geometric evaluation of the continuous-time Fourier transform from 
the pole-zero plot. In the discrete-time case, the Fourier transform can again be evaluated 
geometrically by considering the pole and zero vectors in the z-plane. However, since in 
this case the rational function is to be evaluated on the contour lzl = 1, we consider the 
vectors from the poles and zeros to the unit circle rather than to the imaginary axis. To 
illustrate the procedure, let us consider first-order and second-order systems, as discussed 
in Section 6.6. 
1 0.4. 1 First-Order Systems 
The impulse response of a first-order causal discrete-time system is of the general form 
h[n] = a
11u[n], 
and from Example 10.1, its z-transform is 
1 
H(z) = 1 
- I 
- az 
z 
z - a' 
(10.64) 
lzl > lal. 
(10.65) 
For lal < 1, the ROC includes the unit circle, and consequently, the Fourier transform of 
h[n] converges and is equal to H(z) for z = ejw . Thus, the frequency response for the 
first-order system is 
(10.66) 
Figure 10.13(a) depicts the pole-zero plot for H(z) in eq. (10.65), including the 
vectors from the pole (at z = a) and zero (at z = 0) to the unit circle. With this plot, the 
geometric evaluation of H(z) can be carried out using the same procedure as described in 
Section 9.4. In particular, if we wish to evaluate the frequency response in eq. (10.65), 
we perform the evaluation for values of z of the form z = · ejw. The magnitude of the 
frequency response at frequency w is the ratio of the length of the vector v 1 to the length 
of the vector v2 shown in Figure 10.13(a). The phase of the frequency response is the an-
gle of v 1 with respect to the real axis minus the angle of v2. Furthermore, the vector v 1 from 

764 
!Jm 
z-plane 
CR-e 
-'IT 
(a) 
<J::H(eiw) 
(I) 
(c) 
The z-Transform 
Chap. 10 
20 
10 
a= 0.5 
0 
'IT 
(b) 
(I) 
Figure 1 0.13 
(a) Pole and zero 
vectors for the geometric determina-
tion of the frequency response for a 
first-order system for a value of a be-
tween 0 and 1; (b) magnitude of the 
frequency response for a = 0.95 and 
a = 0.5; (c) phase of the frequency 
response for a = 0.95 and a = 0.5. 
the zero at the origin to the unit circle has a constant length of unity and thus has no 
effect on the magnitude of H(eiw). The phase contributed to H(eiw) by the zero is the 
angle of the zero vector with respect to the real axis, which we see is equal to w . For 
0 < a < 1, the pole vector has minimum length at w = 0 and monotonically increases in 
length as w increases from zero to 7T. Thus, the magnitude of the frequency response will be 

Sec. 10.4 
Geometric Evaluation of the Fourier Transform from the Pole-Zero Plot 
765 
maximum at w = 0 and will decrease monotonically as w increases from 0 to 7T'. The angle 
of the pole vector begins at zero and increases monotonically as w increases from zero to 
'TT'. The resulting magnitude and phase of H(eiw) are shown in Figures 10.13(b) and (c), 
respectively, for two values of a. 
. 
The magnitude of the parameter a in the discrete-time first-order system plays a 
role similar to that of the time constant r for the continuous-time first-order system of 
Section 9.4.1. Note first that, as illustrated in Figure 10.13, the magnitude of the peak 
of H(eiw) at w = 0 decreases as lal decreases toward 0. Also, as was discussed in Sec-
tion 6.6.1 and illustrated in Figures 6.26 and 6.27, as lal decreases, the impulse response 
decays more sharply and the step response settles more quickly. With multiple poles, the 
speed of response associated with each pole is related to its distance from the origin, with 
those closest to the origin contributing the most rapidly decaying terms in the impulse re-
sponse. This is further illustrated in the case of second-order systems, which we consider 
next. 
1 0.4.2 Second-Order Systems 
Next, let us consider the class of second-order systems as discussed in Section 6.6.2, with 
impulse response and frequency response given in eqs. (6.64) and (6.60), which were-
spectively repeat here as 
h[ ] = 
nsin(n + 1)() [ ] 
n 
r 
. () 
un 
sm 
(10.67) 
and 
(10.68) 
where 0 < r < 1 and 0 ::5 () ::5 7T'. Since H(eiw) = H(z)lz=ejw, we can infer from 
eq. (10.68) that the system function, corresponding to the z-transform of the system 
impulse response, is 
1 
H(z) = 1- (2rcos())z- 1 + r2z-2' 
(10.69) 
The poles of H(z) are located at 
(10.70) 
and there is a double zero at z = 0. The pole-zero plot and the pole and zero vectors with 
0 < () < 'TT'/2 are illustrated in Figure 10.14(a). In this case, the magnitude of the frequency 
response equals the square of the magnitude ofV1 (since there is a double zero at the origin) 
divided by the product of the magnitudes ofv2 and v3• Because the length of the vector v1 
from the zero at the origin is 1 for all values of w, the magnitude of the frequency response 
equals the reciprocal of the product of the lengths of the two pole vectors v2 and V3. Also, 
the phase of the frequency response equals twice the angle of v1 with respect to the real 
axis minus the sums of the angles of v2 and V3 . In Figure 10.14(b) we show the magnitude 
ofthe frequency responsefor r = 0.95 and r = 0. 75, while in Figure 10.14(c) we display 
the phase of H(eiw) for the same two values of r. We note in particular that, as we move 

766 
Unit circle 
z-plane 
(a) 
(c) 
10 
0 
(b) 
The z-Transform 
r = 0.95 
r = 0.75 
Chap. 10 
w 
w 
Figure 10.14 
(a) Zerovectorv1 and pole 
vectors v2 and v3 used in the geometric cal-
culation of the frequency responses for 
a second-order system; (b) magnitude 
of the frequency response correspond-
ing to the reciprocal of the product 
of the lengths of the pole vectors for 
r = 0.95 and r = 0.75; (c) phase of 
the frequency response for r = 0.95 
and r = 0.75. 
along the unit circle from w = 0 toward w = 1T, the length of the vector v2 first decreases 
and then increases, with a minimum length in the vicinity of the pole location, at w = (). 
This is consistent with the fact that the magnitude of the frequency response peaks for w 
near() when the length of the vector v2 is small. Based on the behavior of the pole vectors, 
it is also evident that as r increases toward unity, the minimum length of the pole vectors 
will decrease, causing the frequency response to peak more sharply with increasing r. 
Also, for r near unity, the angle of the vector v2 changes sharply for w in the vicinity of 
(). Furthermore, from the form of the impulse response [ eq. (1 0.67) and Figure 6.29] or the 

Sec. 10.5 
Properties of the z-Transform 
767 
step response [eq. (6.67) and Figure 6.30], we see, as we did with the first-order system, 
that as the poles move closer to the origin, corresponding to r decreasing, the impulse 
response decays more rapidly and the step response settles more quickly. 
10.5 PROPERTIES OF THE z-TRANSFORM 
As with the other transforms we have developed, the z-transform possesses a number of 
properties that make it an extremely valuable tool in the study of discrete-time signals and 
systems. In this section, we summarize many of these properties. Their derivations are 
analogous to the derivations of properties for the other transforms, and thus, many are left 
as exercises at the end of the chapter. (See Problems 10.43 and 10.51-10.54.) 
1 0.5.1 Linearity 
If 
and 
then 
z 
z 
Xt[n] ~ 
Xt(Z), 
with ROC= Rt, 
ax1 [n] + bxz[n] ~ 
aX1 (z) + bXz(z), 
with ROC containing Rt n Rz. 
(10.71) 
As indicated, the ROC of the linear combination is at least the intersection of R1 
and R2 . For sequences with rational z-transforms, if the poles of aX1 (z) + bXz(z) consist 
of all of the poles of X1 (z) and X2(z) (i.e., if there is no pole-zero cancellation), then the 
region of convergence will be exactly equal to the overlap of the individual regions of 
convergence. If the linear combination is such that some zeros are introduced that cancel 
poles, then the region of convergence may be larger. A simple example of this occurs 
when x1 [n] and x2[n] are both of infinite duration, but the linear combination is of finite 
duration. In this case the region of convergence of the linear combination is the entire 
z-plane, with the posl?ible exception of zero and/or infinity. For example, the sequences 
a"u[n] and a"u[n -
1] both have a region of convergence defined by lzl > lal, but the 
sequence corresponding to the difference (a"u[n]- a"u[n -
1]) = S[n] has a region of 
convergence that is the entire z-plane. 
1 0.5.2 Time Shifting 
If 
z 
x[n] ~ 
X(z), 
with ROC = R, 

768 
then 
The z-Transform 
z 
x[n - no] ~ 
z- no X(z), 
with ROC = R, except for 
the possible addition or dele-
tion of the origin or infinity. 
Chap. 10 
(10.72) 
Because of the multiplication by Z- 110 , for no > 0 poles will be introduced at z = 0, 
which may cancel corresponding zeros of X(z) at z = 0. Consequently, z = 0 may be a 
pole of z- no X(z) while it may not be a pole of X(z). In this case the ROC for z-no X(z) equals 
the ROC of X(z) but with the origin deleted. Similarly, if n0 < 0, zeros will be introduced 
at z = 0, which may cancel corresponding poles of X(z) at z = 0. Consequently, z = 0 
may be a zero of z-nox(z) while it may not be a pole of X(z). In this case z = oo is a pole 
of z- nox(z), and thus the ROC for z- nox(z) equals the ROC of X(z) but with the z = oo 
deleted. 
1 0.5.3 Scaling in the z-Domain 
If 
z 
x[n] ~ 
X(z), 
with ROC = R, 
then 
z ( z) . 
z0x[n] ~ 
X zo , w1th ROC = lzoiR, 
(10.73) 
where lzoiR is the scaled version of R. That is, if z is a point in the ROC of X(z), then the 
point lzolz is in the ROC of X(z/zo). Also, if X(z) has a pole (or zero) at z = a, then X(zlzo) 
has a pole (or zero) at z = zoa. 
· 
An important special case of eq. (10.73) is when zo = eiwo. In this case, lzoiR = R 
and 
(10.74) 
The left-hand side of eq. (10.74) corresponds to multiplication by a complex exponential 
sequence. The right-hand side can be interpreted as a rotation in the z-plane; that is, all 
pole-zero locations rotate in the z-plane by an angle of wo, as illustrated in Figure 10.15. 
This can be seen by noting that if X ( z) has a factor of the form 1 - az- 1 , then X ( e- Jwo z) 
will have a factor 1- aeiwo z- 1, and thus, a pole or zero at z = a in X(z) will become a pole 
or zero at z = aeiwo in X(e- Jwo z). The behavior of the z-transform on the unit circle will 
then also shift by an angle of w0 . This is consistent with the frequency-shifting property 
set forth in Section 5.3.3, where multiplication with a complex exponential in the time 
domain was shown to correspond to a shift in frequency of the Fourier transform. Also, 
in the more general case when zo = r0eiwo in eq. (10.73), the pole and zero locations are 
rotated by w 0 and scaled in magnitude by a factor of ro. 

Sec. 10.5 
Properties of the z-Transform 
9m 
z-plane 
(a) 
(b) 
Figure 1 o. 15 
Effect on the pole-zero plot of time-domain multiplica-
tion by a complex exponential sequence eiwon: (a) pole-zero pattern for the 
z-transform for a signal x[n]; (b) pole-zero pattern for the z-transform of 
x[ n]eiwon. 
1 0.5.4 Time Reversal 
If 
z 
x[n] ~ 
X(z), 
with ROC = R, 
then 
z 
x[- n] ~X(±), with ROC=~ · 
That is, if zo is in the ROC for x[n], then 1/zo is in the ROC for x[ - n]. 
1 0.5.5 Time Expansion 
769 
(10.75) 
As we discussed in Section 5.3.7, the continuous-time concept of time scaling does not 
directly extend to discrete time, since the discrete-time index is defined only for integer 
values. However, the discrete-time concept of time expansion-i.e., of inserting a number 
of zeros between successive values of a discrete-time sequence x[n]--can be defined and 
does play an important role in discrete-time signal and system analysis. Specifically, the 
sequence X(k)[n], introduced in Section 5.3.7 and defined as 
[ ] _ { x[n/k], 
X(k) n . -
0 
' 
if n is a multiple of k 
if n is not a multiple of k 
(10.76) 
has k - 1 zeros inserted between successive values of the original signal. In this case, if 
z 
x[n] ~ 
X(z), 
with ROC = R, 

770 
The z-Transform 
Chap. 10 
then 
z 
k 
X(k) [n] -
X(z ), 
with ROC = R 11k. 
(10.77) 
That is, if z is in the ROC of X(z), then the point z11k is in the ROC of X(zk). Also, if X(z) 
has a pole (or zero) at z = a, then X(zk) has a pole (or zero) at z = a11k. 
The interpretation of this result follows from the power-series form of the z-
transform, from which we see that the coefficient of the term z-n equals the value of 
the signal at time n. That is, with 
+oo 
X(z) = .L, x[n]z- n, 
n= - oo 
it follows that 
+oo 
+oo 
X(l ) = L x [n](l )- n = .L, x [n]z- kn. 
(10.78) 
n = - oo 
n= - oo 
Examining the right-hand side of eq. (10.78), we see that the only terms that appear are of 
the form z- kn. In other words, the coefficient of the term z-m in this power series equals 
0 if m is not a multiple of k and equals x[mlk] if m is a multiple of k. Thus, the inverse 
transform of eq. (10.78) is X(k)[n]. 
1 0.5.6 Conjugation 
If 
then 
z 
x[n] -
X(z), 
with ROC = R, 
* 
z 
* * 
x [n]- X (z ), 
with ROC= R. 
Consequently, if x[n] is real, we can conclude from eq. (10.80) that 
X(z) = X*(z*). 
(10.79) 
(10.80) 
Thus, if X(z) has a pole (or zero) at z = z0 , it must also have a pole (or zero) at the com-
plex conjugate point z = z0. For example, the transform X(z) for the real signal x[n] in 
Example 10.4 has poles at z = (113)e:t j7TI4. 
1 0.5.7 The Convolution Property 
If 
z 
x1[n]- Xt(z), 
with ROC= Rt, 

Sec. 10.5 
Properties of the z-Transform 
771 
and 
then 
(10.81) 
Just as with the convolution property for the Laplace transform, the ROC of 
X1 (z)X2(z) includes the intersection of R1 and R2 and may be larger if pole-zero can-
cellation occurs in the product. The convolution property for the z-transform can be 
derived in a variety of different ways. A formal derivation is developed in Problem 10.56. 
A derivation can also be carried out analogous to that used for the convolution property for 
the continuous-time Fourier transform in Section 4.4, which relied on the interpretation 
of the Fourier transform as the change in amplitude of a complex exponential through an 
LTI system. 
For the z-transform, there is another often useful interpretation of the convolution 
property. From the definition in eq. (10.3), we recognize the z-transform as a series in 
z- 1 where the coefficient of z-n is the sequence value x[n]. In essence, the convolution 
property equation (10.81) states that when two polynomials or power series X1 (z) and 
X2(z) are multiplied, the coefficients in the polynomial representing the product are the 
convolution of the coefficients in the polynomials X1 (z) and X2(z). (See Problem 10.57). 
Example 1 0. 1 5 
Consider an LTI system for which 
y[n] = h[n] * x[n], 
(10.82) 
where 
h[n] = cS[n] - cS[n - 1]. 
' Note that 
z 
cS[n]- cS[n - 1] ~ 
1- z- 1, 
(10.83) 
with ROC equal to the entire z-plane except the origin. Also, the z-transform in 
eq. (10.83) has a zero at z = 1. From eq. (10.81), we see that if 
z 
x[n] ~ 
X(z), 
with ROC = R, 
then 
z 
y[n] ~ 
(1- z- 1)X(z), 
(10.84) 
with ROC equal to R, with the possible deletion of z = 0 and/or addition of z = 1. 
Note that for this system 
y[n] = [cS[n] - cS[n - 1]] * x[n] = x[n] - x[n- 1]. 

772 
The z-Transfotm 
Chap. 10 
That is, y[n] is the first difference of the sequence x[n]. Since the first-difference opera-
tion is commonly thought of as a discrete-time counterpart to differentiation, eq. (10.83) 
can be thought of as the z-transform counterpart of the Laplace transform differentiation 
property presented in Section 9.5.7. 
Example 1 0. 1 6 
Suppose we now consider the inverse of first differencing, namely, accumulation or sum-
mation. Specifically, let w[n] be the running sum of x[n]: 
n 
w[n] = L x[k] "" u[n] * x[n]. 
(10.85) 
k=- oo 
Then, using eq. (10.81) together with the z-transform of the unit step in Example 10.1, 
we see that 
n 
Z 
1 
w[n] = L x[k] ~ 
1 _ z_1 X(z), 
k = - 00 
(10.86) 
with ROC including at least the intersection of R with lzl > 1. Eq. (10.86) is the discrete-
time z-transform counterpart of the integration property in Section 9.5.9. 
1 0.5.8 Differentiation in the z-Domain 
If 
z 
x[n] ~ 
X(z), 
with ROC = R, 
then 
z 
nx[n] ~ 
- zdX(z) 
with ROC = R. 
dz ' 
(10.87) 
This property follows in a straightforward manner by differentiating both sides of the 
expression for the z-transform given in eq. (10.3). As an example of the use of this property, 
let us apply it to determining the inverse z-transform considered in Example 10.14. 
Example 1 0. 17 
If 
then 
X(z) = log(l + az- 1), 
lzl > lal, 
(10.88) 
z 
dX(z) 
az- 1 
nx[n] ~ 
- z-- = 
lzl > lal. 
dz 
1+az- 1' 
(10.89) 
By differentiating, we have converted the z-transform to a rational expression. The 
inverse z-transform of the right-hand side of eq. (10.89) can be obtained by using Exam-
ple 10.1 together with the time-shifting property, eq. (10.72), set forth in Section 10.5.2. 

J 
Sec. 10.5 
Properties of the z-Transform 
Specifically, from Example 10.1 and the linearity property, 
z 
a 
a(- a)"u[n] ~ 
1 
1 , lzl > lal. 
+ az 
Combining this with the time-shifting property yields 
Consequently, 
z 
az- 1 
a(-ar 1u[n - l] ~ 
1 
_1 , lzl > lal. 
+ az 
- (- a)" 
x[n] = -
-
u[n- 1]. 
n 
Example 1 0. 18 
773 
(10.90) 
(10.91) 
As another example of the use of the differentiation property, consider determining the 
inverse z-transform for 
az- 1 
X(z) = (1 _ az- l )2 , lzl > Ia I. 
From Example 10.1, 
z 
a"u[n] ~ 
lzl > lal, 
1- az- 1 ' 
and hence, 
z 
d ( 
1 
) 
az-
1 
na" u[n] ~ 
- zdz 1- az 1 
= (1 - az 1)2' 
1 0.5.9 The Initial-Value Theorem 
If x [n] = 0, n < 0, then 
x[O] = lim X(z). 
z-+ oo 
(10.92) 
(10.93) 
lzl > lal. 
(10.94) 
(10.95) 
This property follows by considering the limit of each term individually in the ex-
pression for the z-transform, with x[n] zero for n < 0. With this constraint, 
X(z) = L x [n] z- n. 
n=O 
As z ~ oo, z-n ~ 0 for n > 0, whereas for n = 0, z-n = 1. Thus, eq. (10.95) follows. 
As one consequence of the initial-value theorem, for a causal sequence, if x[O] is 
finite, then limz....,oo X(z) is finite. Consequently, with X(z) expressed as a ratio of polyno-
mials in z, the order of the numerator polynomial cannot be greater than the order of the 
denominator polynomial; or, equivalently, the number of finite zeros of X(z) cannot be 
greater than the number of finite poles. 

'-
774 
The z-Transform 
Chap. 10 
Example 1 0. 19 
00 The initial-value theorem can also be useful in checking the correctness of the z-
transform calculation for a signal. For example, consider the signal x[n] in Example 10.3. 
From eq. (10.12), we see that x[O] = l. Also, from eq. (10.14), 
which is consistent with the initial-value theorem. 
1 0.5.1 0 Summary of Properties 
In Table 10.1, we summarize the properties of the z-transform. 
1 0.6 SOME COMMON z-TRANSFORM PAIRS 
As with the inverse Laplace transform, the inverse z-transform can often be easily evalu-
ated by expressing X(z) as a linear combination of simpler terms, the inverse transforms of 
which are recognizable. In Table 1 0.2, we have listed a number of useful z-transform pairs. 
Each of these can be developed from previous examples in combination with the proper-
ties of the z-transform listed in Table 10.1. For example, transform pairs 2 and 5 follow 
directly from Example 10.1, and transform pair 7 is developed in Example 10.18. These, 
together with the time-reversal and time-shifting properties set forth in Sections 10.5.4 
and 10.5.2, respectively, then lead to transform pairs 3, 6, and 8. Transform pairs 9 and 10 
can be developed using transform pair 2 together with the linearity and scaling properties 
developed in Sections 10.5.1 and 10.5.3, respectively. 
10.7 ANALYSIS AND CHARACTERIZATION OF LTI SYSTEMS 
USING z-TRANSFORMS 
The z-transform plays a particularly important role in the analysis and representation of 
discrete-time LTI systems. From the convolution property presented in Section 10.5.7, 
Y(z) = H(z)X(z), 
(10.96) 
where X(z), Y(z), and H(z) are the z-transforms of the system input, output, and impulse 
response, respectively. H(z) is referred to as the system function or transfer function of the 
system. For z evaluated on the unit circle (i.e., for z = eiw), H(z) reduces to the frequency 
response of the system, provided that the unit circle is in the ROC for H(z). Also, from 
our discussion in Section 3.2, we know that if the input to an LTI system is the complex 
exponential signal x[n] = zn, then the output will be H(z)zn. That is, zn is an eigenfunction 
of the system with eigenvalue given by H(z), the z-transform of the impulse response. 
Many properties of a system can be tied directly to characteristics of the poles, zeros, 
and region of convergence of the system function, and in this section we illustrate some 
of these relationships by examining several important system properties and an important 
class of systems. 

'I 
'I 
U1 
TABLE 10.1 
PROPERTIES OF THE z-TRANSFORM 
Section 
10.5.1 
10.5.2 
10.5.3 
10.5.4 
10.5.5 
10.5.6 
10.5.7 
10.5.7 
10.5.7 
10.5.8 
10.5.9 
Property 
Linearity 
Time shifting 
Scaling in the z-domain 
Time reversal 
Time expansion 
Conjugation 
Convolution 
First difference 
Accumulation 
Differentiation 
in the z-domain 
x[n] 
x 1[n] 
Xz[n] 
ax1 [n] + bxz[n] 
x[n- no] 
eiwon x [n] 
z0x[n] 
a"x[n] 
x[-n] 
X(kl[n] = { x [r], 
0, 
x' [n] 
X1 [n] * Xz [n] 
x[n] - x[n - 1] 
2::~= -x x [k] 
nx[n] 
Signal 
z-Transform 
X(z) 
XJ(Z) 
Xz(Z) 
aX1 (z) + bXz(z) 
z-"0X(z) 
X(e- Jwo z) 
x (~) 
X(a- 1 z) 
X(z- 1) 
n = rk for some integer r 
n # rk 
X(zk) 
X' (z' ) 
X1 (z)Xz(z) 
(1 - z- 1)X(z) 
_l_X(z) 
1 - z-1 
dX(z) 
-z----;JZ 
Initial Value Theorem 
If x[n] = 0 for n < 0, then 
x[O] = limX(z) 
z-x 
R 
R1 
Rz 
ROC 
At least the intersection of R1 and Rz 
R, except for the possible addition or 
deletion of the origin 
R 
ZoR 
Scaled version of R {i.e., laiR = the 
set of points {lalz} for z in R) 
Inverted R (i.e., R- 1 = the set of 
points z- 1, where z is in R) 
R 11k (i.e., the set of points zllk, where 
z is inR) 
R 
At least the intersection of R 1 and R2 
At least the intersection of R and 
lzl > 0 
At least the intersection of R and 
lzl > 1 
R 

776 
The z-Transform 
TABLE 10.2 
SOME COMMON z-TRANSFORM PAIRS 
Signal 
l. .S[n] 
2. u[n] 
3. -u[-n-1] 
4 . .S[n- m] 
5. a"u[n] 
6. -a"u[ - n - 1] 
7. na"u[n] 
8. -na"u[ -n- 1] 
9. [coswon]u[n] 
10. [sinwon]u[n] 
11. [r" coswon]u[n] 
12. [r'' sinw0n]u[n] 
1 0.7.1 Causality 
1 - z- 1 
1 
1 - z- 1 
Transform 
1- az 1 
(l - az 1)2 
az- 1 
(1 - az 1)2 
1 - [coswo]z- 1 
1 - [2coswolz 1 + z 2 
[sinwolz- 1 
1- [2coswolz 1 + z 2 
1 - [rcoswol z- 1 
1 - [2rcosw0]z 1 + r2z-2 
[r sin wo]z- 1 
1 - [2rcosw0]z- 1 + r2 z ~ 2 
ROC 
All z 
lzl > I 
lzl < 1 
All z, except 
0 (if m > 0) or 
oo (if m < 0) 
lzl > lal 
lzl < faf 
lzl > fal 
lzl < fal 
lzl > 1 
lzl > 1 
lzl > r 
lzl > r 
Chap. 10 
A causal LTI system has an impulse response h[n] that is zero for n < 0, and therefore is 
right-sided. From Property 4 in Section 10.2 we then know that the ROC of H(z) is the 
exteriorofacircleinthez-plane.Forsomesystems,e.g.,ifh[n] = 5[n],sothatH(z) = 1, 
the ROC can extend all the way in to and possibly include the origin. Also, in general, for 
a right-sided impulse response, the ROC may or may not include infinity. For example, 
if h[n] = 5[n + 1], then H(z) = z, which has a pole at infinity. However, as we saw in 
Property 8 in Section 10.2, for a causal system the power series 
00 
H(z) = L h[n]z- n 
n=O 
does not include any positive powers of z. Consequently, the ROC includes infinity. Sum-
marizing, we have the follow principle: 
A discrete-time LTI system is causal if and only if the ROC of its system function is 
the exterior of a circle, including infinity. 

Sec. 10.7 
Analysis and Characterization of LTI z-Transforms 
777 
H H(z) is rational, then, from Property 8 in Section 10.2, for the system to be causal, 
the ROC must be outside the outermost pole and infinity must be in the ROC. Equivalently, 
the limit of H(z) as z ~ 
oo must be finite. As we discussed in Section 10.5.9, this is 
equivalent to the numerator of H(z) having degree no larger than the denominator when 
both are expressed as polynomials in z. That is: 
A discrete-time LTI system with rational system function H(z) is causal if and only if: 
(a) the ROC is the exterior of a circle outside the outermost pole; and (b) with H(z) 
expressed as a ratio of polynomials in z, the order of the numerator cannot be greater 
than the order of the denominator. 
Example 1 0.20 
Consider a system with system function whose algebraic expression is 
z3 - 2z2 + z 
H(z) = 
1 
1. 
z2 + 4z + 8 
Without even knowing the ROC for this system, we can conclude that the system is not 
causal, because the numerator of H (z) is of higher order than the denominator. 
Example 1 0.21 
Consider a system with system function 
1 
1 
H(z) = 1 - lz- 1 + 1- 2z- 1, 
lzl > 2 
2 
(10.97) 
Since the ROC for this system function is the exterior of a circle outside the outermost 
pole, we know that the impulse response is right-sided. To determine if the system is 
causal, we then need only check the other condition required for causali~y, namely that 
H(z), when expressed as a ratio of polynomials in z, has numerator degree no larger than 
the denominator. For this example, 
z2 -
~z + 1' 
2 
(10.98) 
so that the numerator and denominator of H(z) are both of degree two, and consequently 
we can conclude that the system is causal. This can also be verified by calculating the 
inverse transform of H(z). In particular, using transform pair 5 in Table 10.2, we find 
that the impulse response of this system is 
(10.99) 
Since h[n] = 0 for n < 0, we can confirm that the system is causal. 
10.7.2 Stability 
As we discussed in Section 2.3. 7, the stability of a discrete-time LTI system is equivalent to 
its impulse response being absolutely summable. In this case the Fourier transform of h[n] 

778 
The z-Transform 
Chap. 10 
converges, and consequently, the ROC of H(z) must include the unit circle. Summarizing, 
we obtain the following result: 
An LTI system is stable if and only if the ROC of its system function H(z) includes 
the unit circle, lzl = 1. 
Example 1 0.22 
Consider again the system function in eq. (10.97). Since the associated ROC is the region 
lzl > 2, which does not include the unit circle, the system is not stable. This can also be 
seen by noting that the impulse response in eq. (10.99) is not absolutely summable. If, 
however, we consider a system whose system function has the same algebraic expression 
as in eq. (10.97) but whose ROC is the region 1/2 < lzl < 2, then the ROC does contain 
the unit circle,. so that the corresponding system is noncausal but stable. In this case, 
using transform pairs 5 and 6 from Table 10.2, we find that the corresponding impulse 
response is 
( 1 )" 
h[n] = z u[n]- 2"u[ - n - 1], 
(10.100) 
which is absolutely summable. 
Also, for the third possible choice of ROC associated with the algebraic expression 
for H(z) in eq. (10.97), namely, lzl < 1/2, the corresponding system is neither causal 
(since the ROC is not outside the outermost pole) nor stable (since the ROC does not 
include the unit circle). This can also be seen from the impulse response, which (using 
transform pair 6 in Table 10.2) is 
h[n] = -[GJ +2"]u[-n - 1]. 
As Example 10.22 illustrates, it is perfectly possible for a system to be stable but 
not causal. However, if we focus on causal systems, stability can easily be checked by 
examining the locations of the poles. Specifically, for a causal system with rational system 
function, the ROC is outside the outermost pole. For this ROC to include the unit circle, 
lzl = 1, all of the poles of the system must be inside the unit circle. That is: 
A causal LTI system with rational system function H(z) is stable if and only if all of 
the poles of H(z) lie inside the unit circle-i.e., they must all have magnitude smaller 
than 1. 
Example 1 0.23 
Consider a causal system with system function 
1 
H(z) = 1 
I' 
- az 
which has a pole at z = a. For this system to be stable, its pole must be inside the unit 
circle, i.e., we must have lal < 1. This is consistent with the condition for the absolute 
summability of the corresponding impulse response h[ n] = a" u [ n]. 

Sec. 10.7 
Analysis and Characterization of LTI z-Transforms 
779 
Example 1 0.24 
The system function for a second-order system with complex poles was given in 
eq. (10.69), specifically, 
H (z) = ~---c-----,---------,---=----=-
1 -:- (2rcosll)z- l + r2z-2' 
(10.101) 
with poles located at z1 = rej8 and z2 = re- je. Assuming causality, we see that the 
ROC is outside the outermost pole (i.e., lzl > lrf). The pole-zero plot and ROC for this 
system are shown in Figure 10.16 for r < 1 and r > 1. For r < 1, the poles are inside 
the unit circle, the ROC includes the unit circle, and therefore, the system is stable. For 
r > 1, the poles are outside the unit circle, the ROC does not include the unit circle, and 
the system is unstable. 
Unit circle 
z-plane 
(fl.e 
(a) 
(b) 
Figure 1 o. 16 
Pole-zero plot for a second-order system with complex poles: 
(a) r < 1; (b) r > 1. 
1 0.7.3 LTI Systems Characterized by linear Constant-Coefficient 
Difference Equations 
For systems characterized by linear constant-coefficient difference equations, the proper-
ties of the z-transform provide a particularly convenient procedure for obtaining the system 
function, frequency response, or time-domain response of the system. Let us illustrate this 
with an example. 
Example 10.25 
Consider an LTI system for which the input x[n] and output y[n] satisfy the linear 
constant-coefficient difference equation 
1 
1 
y[n]- 2y[n - 1] = x[n] + 3x[n - 1]. 
(10.102) 

780 
The z-Transform 
Chap. 10 
Applying the z-transform to both sides of eq. (10.102), and using the linearity property 
set forth in Section 10.5.1 and the time-shifting property presented in Section 10.5.2, we 
obtain 
or 
Y(z) = X(z) 
i _ . 
[
1 + !z-'] 
1- 2z I 
(10.103) 
From eq. (10.96), then, 
(10.104) 
This provides the algebraic expression for H (z), but not the region of convergence. 
In fact, there are two distinct impulse responses that are consistent with the difference 
equation (10.102), one right sided and the other left sided. Correspondingly, there are 
two different choices for the ROC associated with the algebraic expression (10.104). 
One, lzl > 112, is associated with the assumption that h[n] is right sided, and the other, 
lzl < 1/2, is associated with the assumption that h[n] is left sided. 
Consider first the choice of ROC equal to lzl > 1. Writing 
( 
1 -1) 
1 
H(z) = 1 + 3z 
1 _ , 
1 - 2z I 
we can use transform pair 5 in Table 10.2, together with the linearity and time-shifting 
properties, to find the corresponding impulse response 
(
1 )
11 
1 (1 )n-1 
h[n] = 2 u[n] + 3 2 
u[n- 1]. 
For the other choice of ROC, namely, lzl < 1, we can use transform pair 6 in 
Table 10.2 and the linearity and time-shifting properties, yielding 
(
1 )n 
1 (1 )n-1 
h[n] = -
2 u[ - n- 1] - 3 2 
u[ -n]. 
In this case, the system is anticausal (h[n] = 0 for n > 0) and unstable. 
For the more general case of an Nth-order difference equation, we proceed in a man-
ner similar to that in Example 1 0.25, applying the z-transform to both sides of the equation 
and using the linearity and time-shifting properties. In particular, consider an LTI system 
for which the input and output satisfy a linear constant-coefficient difference equation of 
the form 
N 
M 
L aky[n - k] = L bkx[n- k]. 
(10.105) 
k=O 
k=O 

Sec. 10.7 
Analysis and Characterization of LTI z-Transforms 
781 
Then taking z-transforms of both sides of eq. (10.105) and using the linearity and time-
shifting properties, we obtain 
N 
M 
2:>kz- kY(z) = L bkz- kX(z), 
k=O 
k=O 
or 
N 
M 
Y(z) L akz- k = X(z) L bkz- k, 
k=O 
k=O 
so that 
H( ) = Y(z) 
z 
X(z) 
(10.106) 
We note in particular that the system function for a system satisfying a linear constant-
coefficient difference equation is always rational. Consistent with our previous example 
and with the related discussion for the Laplace transform, the differenct< equation by itself 
does not provide information about which ROC to associate with the algebraic expression 
H(z). An additional constraint, such as the causality or stability of the system, however, 
serves to specify the region of convergence. For example, if we know in addition that the 
system is causal, the ROC will be outside the outermost pole. If the system is stable, the 
ROC must include the unit circle. 
1 0. 7.4 Examples Relating System Behavior to the System Function 
As the previous subsections illustrate, many properties of discrete-time LTI systems can 
be directly related to the system function and its characteristics. In this section, we give 
several additional examples to show how z-transform properties can be used in analyzing 
systems. 
Example 1 0.26 
Suppose that we are given the following information about an LTI system: 
1. If the input to the system is x 1 [n] = (1/6r u[n], then the output is 
where a is a real number. 
2. If x2[n] = ( -1)", then the output is y2[n] = ~( -1)". As we now show, from 
these two pieces of information, we can determine the system function H(z) for this 
system, including the value of the number a, and can also immediately deduce a number 
of other properties of the system. 
The z-transforms of the signals specified in the first piece of information are 

782 
The z-Transform 
Chap. 10 
1 
1 
X1(z) = 1 - !z- 1' 
lzl > 6' 
(10.107) 
6 
Y1(z) = 
a 
10 
1 - !z- 1 + 1 - lz-1 
2 
3 
(10.108) 
(a+ 10) - (5 + ~)z -
1 
1 
(1 -
~z-1)(1 - t z- 1), 
lzl > z· 
From eq. (10.96), it follows that the algebraic expression for the system function is 
Y1(z) 
[(a' + 10)- (5 + ~)z-
1 ][1- ~z-
1 ] 
H(z) = -
= 
(10.109) 
X1(z) 
(1- ~z-
1 )(1- iz- 1) 
Furthermore, we know that the response to x2[n] = ( - 1)" must equal ( -1)" multiplied 
by the system function H(z) evaluated at z = -1. Thus from the second piece of infor-
mation given, we see that 
7 
[(a+ 10) + 5 + j][~] 
- H(- 1) -
----.,--.----"--~ 
4 -
-
(~)(~) 
(10.110) 
Solving eq. (10.110), we find that a = - 9, so that 
(1- 2z-1)(1 - !z- 1) 
H(z) -
6 
- (1- ~z- 1 )(1- iz- 1)' 
(10.111) 
or 
1 
13 -1 + I - 2 
H(z) = 
- 6z 
3z 
1 -
~z - 1 + !z-2, 
6 
6 
(10.112) 
or, finally, 
z2 -
.!1z + ! 
H(z) = 
6 
3 
z2 -
~ z +! · 
6 
6 
(10.113) 
Also, from the convolution property, we know that the ROC of Y1 (z) must include 
at least the intersections of the ROCs of X1 (z) and H(z). Examining the three possible 
ROCs for H(z) (namely, lzl < 113, 113 < lzl < 1/2, and lzl > 112), we find that the only 
choice that is consistent with the ROCs of X1 (z) and Y1 (z) is lzl > 112. 
Since the ROC for the system includes the unit circle, we know that the system 
is stable. Furthermore, from eq. (10.113) with H(z) viewed as a ratio of polynomials in 
z, the order of the numerator does not exceed that of the denominator, and thus we can 
conclude that the LTI system is causal. Also, using eqs. (10.112) and (10.106), we can 
write the difference equation that, together with the condition of initial rest, characterizes 
the system: 
5 
1 
13 
1 
y[n] - 6y[n - 1] + 6y[n- 2] = x[n] - 6 x[n- 1] + 3x[n - 2]. 
Example 1 0.27 
Consider a stable and causal system with impulse response h[n] and rational system 
function H(z). Suppose it is known that H(z) contains a pole at z = 112 and a zero 
somewhere on the unit circle. The precise number and locations of all of the other poles 

Sec. 10.8 
System Function Algebra and Block Diagram Representations 
783 
and zeros are unknown. For each of the following statements, let us determine whether 
we can definitely say that it is true, whether we can definitely say that it is false, or 
whether there is insufficient information given to determine if it is true or not: 
(a) ~ (C1/2)"h[nl} converges. 
(b) H(ejw) = 0 for some w. 
(c) h[n] has finite duration. 
(d) h[n] is real. 
(e) g[n] = n[h[n] * h[n]] is the impulse response of a stable system. 
Statement (a) is true.~ { (1/2)" h[nl} corresponds to the value of the z-transform of 
h[n] at z = 2. Thus, its convergence is equivalent to the point z = 2 being in the ROC. 
Since the system is stable and causal, all of the poles of H(z) are inside the unit circle, 
and the ROC includes all the points outside the unit circle, including z = 2. 
Statement (b) is true because there is a zero on the unit circle. 
Statement (c) is false because a finite-duration sequence must have an ROC that 
includes the entire z-plane, except possibly z = 0 and/or z = oo. This is not consistent 
with having a pole at z = 1/2. 
Statement (d) requires that H(z) = H *(z*). Tlus in turn implies that if there is 
a pole (zero) at a nonreallocation z = z0 , there must also be a pole (zero) at z = z(j. 
Insufficient information is given to validate such a conclusion. 
Statement (e) is true. Since the system is causal, h[n] = 0 for n < 0. Conse-
quently, h[n] * h[n] = 0 for n < 0; i.e., the system with h[n] * h[n] as its impulse re-
sponse is causal. The same is then true for g[n] = n[h[n] * h[n]]. Furthermore, by the 
convolution property set forth in Section 10.5.7, the system function corresponding to 
the impulse response h[n] * h[n] is H 2(z), and by the differentiation property presented 
in Section 10.5.8, the system function corresponding to g[n] is 
(10.114) 
From eq. (10.114), we can conclude that the poles of G(z) are at the same locations as 
those of H(z), with the possible exception of the origin. Therefore, since H(z) has all its 
poles inside the unit circle, so must G(z). It follows that g[n] is the impulse response of 
a causal and stable system. 
1 0.8 SYSTEM FUNCTION ALGEBRA AND BLOCK DIAGRAM 
REPRESENTATIONS 
Just as with the Laplace transform in continuous time, the z-transform in discrete time 
allows us to replace time-domain operations such as convolution and time shifting with 
algebraic operations. This was exploited in Section 10.7.3, where we were able to replace 
the difference-equation description of an LTI system with an algebraic description. The 
use of the z-transform to convert system descriptions to algebraic equations is also helpful 
in analyzing interconnections of LTI systems and in representing and synthesizing systems 
as interconnections of basic system building blocks. 

x[n] 
784 
The z-Transform 
Chap. 10 
1 0.8. 1 System Functions for Interconnections of LTI Systems 
The system function algebra for analyzing discrete-time block diagrams such as series, 
parallel, and feedback interconnections is exactly the same as that for the corresponding 
continuous-time systems in Section 9 .8.1. For example, the system function for the cascade 
of two discrete-time LTI systems is the product of the system func.tions for the individual 
systems in the cascade. Also, consider the feedback interconnection of two systems, as 
shown in Figure 10.17. It is relatively involved to determine the difference equation or im-
pulse response for the overall system working directly in the time domain. However, with 
the systems and sequences expressed in terms of their z-transforms, the analysis involves 
only algebraic equations. The specific equations for the interconnection of Figure 10.17 
exactly parallel eqs. (9.159)- (9.163), with the final result that the overall system function 
for the feedback system of Figure 10.17 is 
+ 
e[n] 
+ 
-
Y(z) = H(z) = 
HI (z) 
(10.115) 
X(z) 
1 + H1 (z)Hz(z) · 
H1(z) 
h1[n] 
H2(z) 
h2[n] 
y[n] 
Figure 1 o. 17 
Feedback intercon-
nection of two systems. 
1 0.8.2 Block Diagram Representations for Causal LTISystems 
Described by Difference Equations and Rational 
System Functions 
As in Section 9 .8.2, we can represent causal LTI systems described by difference equations 
using block diagrams involving three basic operations-in this case, addition, multiplica-
tion by a coefficient, and a unit delay. In Section 2.4.3, we described such a block diagram 
for a first-order difference equation. We first revisit that example, this time using system 
function algebra, and then consider several slightly more complex examples to illustrate 
the basic ideas in constructing block diagram representations. 
Example 1 0.28 
Consider the causal LTI system with system function 
1 
H(z) = 
1 
• 
1- 4z- I 
(10.116) 
Using the results in Section 10.7.3, we find that this system can also be described by the 
difference equation 
1 
y[n] - 4 y[n - 1] = x[n], 

Sec. 10.8 
System Function Algebra and Block Diagram Representations 
785 
together with the condition of initial rest. In Section 2.4.3 we constructed a block diagram 
representation for a first-order system of this form, and an equivalent block diagram 
(corresponding to Figure 2.28 with a = - 1/4 and b = 1) is shown in Figure 10.18(a). 
Here, z- 1 is the system function of a unit delay. That is, from the time-shifting property, 
the input and output of this system are related by 
w[n] = y[n - -1]. 
The block diagram in Figure 10.18(a) contains a feedback loop much as for the sys-
tem considered in the previous subsection and pictured in Figure 10.17. In fact, with 
some minor modifications, we can obtain the equivalent block diagram shown in Fig-
ure 10.18(b), which is exactly in the form shown in Figure 10.17, with H 1(z) = 1 and 
H2(z) = - 114z- 1• Then, applying eq. (10.115), we can verify that the system function 
of the system in Figure 10.18 is given by eq. (10.116). 
• y[n] 
(a) 
+ 
x[n] ---+-1 + )-------...,.--..- y[n] 
(b) 
Figure 1 o. 18 
(a) Block diagram representations of the causal LTI system 
in Example 1 0.28; (b) equivalent block diagram representation. 
Example 1 0.29 
Suppose we now consider the causal LTI system with system function 
1 - 2z-
1 
( 
1 
) 
H(z) = 
= 
-
-
-
(1 - 2z- 1). 
1 - ! z- 1 
1 - ! z- 1 
4 
4 
(10.117) 
As eq. (10.117) suggests, we can think of this system as the cascade of a system with 
system function 11[1 - (114)z- 1] and one with system function 1 - 2z- 1• We have il-
lustrated the cascade in Figure 10.19(a), in which we have used the block diagram in 
Figure 10.18(a) to represent 11[1 - (1/4)z- 1]. We have also represented 1- 2z- 1 using 
a unit delay, an adder, and a coefficient multiplier. Using the time-shifting property, we 
then see that the input v[n] and output y[n] of the system with system function 1 - 2z- 1 

786 
The z-Transform 
Chap. 10 
are related by 
y[n] = v[n] - 2v[n- 1]. 
While the block diagram in Figure 10.19(a) is certainly a valid representation of 
the system in eq. (10.117), it has an inefficiency whose elimination leads to an alternative 
block-diagram representation. To see this, note that the input to both unit delay elements 
in Figure 10.19(a) is v[n], so that the outputs of these elements are identical; i.e., 
w[n] = s[n] = v[n- 1]. 
Consequently, we need not keep both of these delay elements, and we can simply use 
the output of one of them as the signal to be fed to both coefficient multipliers. The result 
is the block diagram representation in Figure 10.19(b). Since each unit delay element 
requires a memory register to store the preceding value of its input, the representation in 
Figure 10.19(b) requires less memory than that in Figure 10.19(a). 
---- - ------ - - ----1 
l-i--~y(n] 
(a) 
x[n] --~1 + )--------..--------~( + l----!~ y(n] 
(b) 
Figure 1 o. 19 
{a) Block-diagram representations for the system in Exam-
ple 10.29; {b) equivalent block-diagram representation using only one unit de-
lay element. 
Example 1 0.30 
Next, consider the second-order system function 
1 
H(z) = --·---,--
(1 + ~:. - 1)(1- ~z- 1) 
1 
(10.118) 
which is also described by the difference equation 
i 
1 
y[n] + 4y[n - 1] - gy[n- 2] = x[n]. 
(10.119) 

Sec. 10.8 
System Function Algebra and Block Diagram Representations 
787 
Using the same ideas as in Example 10.28, we obtain the block-diagram representation 
for this system shown in Figure 10.20(a). Specifically, since the two system function 
blocks in this figure with system function z- 1 are unit delays, we have 
f[n] = y[n - 1], 
e[n] = f[n - 1] = y[n - 2], 
so that eq. (10.119) can be rewritten as 
1 
1 
y[n] = - 4y[n- 1] + gy[n- 2] + x[n], 
x[nJ---~ 
(a) 
x[n] 
(b) 
x[n] 
Figure 1 0.20 
Block-diagram representations for the system in Exam-
ple 10.30: (a) direct form; (b) cascade form; (c) parallel form. 
y[n) 

788 
The z-Transform 
Chap. 10 
or 
1 
. 1 
y[n] = -4f[n] + se[n] + x[n], 
which is exactly what the figure represents. 
The block diagram in Figure 10.20(a) is commonly referred to as a direct-form 
representation, since the coefficients appearing in the diagram can be determined by 
inspection from the coefficients appearing in the difference equation or, equivalently, 
the system function. Alternatively, as in continuous time, we can obtain both cascade-
form and parallel-form block diagrams with the aid of a bit of system function algebra. 
Specifically, we can rewrite eq. (10.118) as 
(10.120) 
which suggests the cascade-form representation depicted in Figure 10.20(b) in which 
the system is represented as the cascade of two systems corresponding to the two factors 
in eq. (10.120). 
Also, by performing a partial-fraction expansion, we obtain 
2 
I 
H(z) = 
3 
+ 
31 
, 
1 + 4z-1 
1 - 4z-1 
which leads to the parallel-form representation depicted in Figure 10.20(c). 
Example 10.31 
Finally, consider the system function 
(10.121) 
Writing 
( 
1 
)( 
7 -1 1 -2) 
H(z) = 
1 + ~z- 1- kz-2 1- 4z 
- 2z 
(10.122) 
suggests representing the system as the cascade of the system in Figure 10.20(a) and the 
system with system function 1- ~z -
1 - 4z-2• However, as in Example 10.29, the unit 
delay elements needed to implement the first term in eq. (10.122) also produce the de-
layed signals needed in computing the output of the second system. The result is the 
direct-form block diagram shown in Figure 10.21, the details ofthe construction of which 
are examined in Problem 10.38. The coefficients in the direct-form representation can 
be determined by inspection from the coefficients in the system function of eq. (10.121). 
We can also write H(z) in the forms 
(1 + .!.z-
1 )(1 - 2z-') 
H(z) = 
4 
1 + .!. z- 1 1 - .!. z- 1 
2 
4 
(10.123) 

Sec. 10.9 
The Unilateral z-Transform 
789 
y[n] 
Figure 1 0.21 
Direct-form representation for the system in Example 1 0.31. 
and 
H(z) = 4 + 
513 
1 + !z- 1 
2 
14/3 
1 - !z- 1 • 
4 
(10.124) 
Eq. (10.123) suggests a cascade-form representation, while eq. (10.124) leads to a 
parallel-form block diagram. These are also considered in Problem 10.38. 
The concepts used in constructing block-diagram representations in the preceding 
examples can be applied directly to higher order systems, and several examples are con-
sidered in Problem 10.39. As in continuous time, there is typically considerable flexibility 
in doing this-e.g., in how numerator and denominator factors are paired in a product rep-
resentation as in eq. (10.123), in the way in which each factor is implemented, and in the 
order in which the factors are cascaded. While all of these variations lead to representa-
tions of the same system, in practice there are differences in the behavior of the different 
block diagrams. Specifically, each block-diagram representation of a system can be trans-
lated directly into a computer algorithm for the implementation of the system. However, 
because the finite word length of a computer necessitates quantizing the coefficients in the. 
block diagram and because there is numerical roundoff as the algorithm operates, each of 
these representations will lead to an algorithm that only approximates the behavior of the 
original system. Moreover, the errors in each of these approximations will be somewhat 
different. Because of these differences, considerable effort has been put into examining 
the relative merits of the various block -diagram representations in terms of their accuracy 
and sensitivity to quantization effects. For discussions of this subject, the reader may tum 
to the references on digital signal processing in the bibliography at the end of the book. 
10.9 THE UNilATERAL z-TRANSFORM 
The form of the z-transform considered thus far in this chapter is often referred to as the 
bilateral z-transform. As was the case with the Laplace transform, there is an alterna-
tive form, referred to as the unilateral z-transform, that is particularly useful in analyzing 
causal systems specifiyd by linear constant-coefficient difference equations with nonzero 
initial conditions (i.e., systems that are not initially at rest). In this section, we introduce 
the unilateral z-transform and illustrate some of its properties and uses, paralleling our 
discussion of the unilateral Laplace transform in Section 9.9. 

790 
The z-Transform 
Chap. 10 
The unilateral z-transform of a sequence x[n] is defined as 
X(z) = ~ 
x[n]z- n. 
(10.125) 
n=O 
As in previous chapters, we adopt a convenient shorthand notation for a signal and its 
unilateral z-transform: 
'UZ 
x[n] ~ 
X(z) = 'UZ{ x[nJ}. 
(10.126) 
The unilateral z-transform differs from the bilateral transform in that the summation is 
carried out only over nonnegative values of n, whether or not x[n] is zero for n < 0. Thus 
the unilateral z-transform of x[n] can be thought of as the bilateral transform of x[n]u[n] 
(i.e., x[n] multiplied by a unit step). In particular, then, for any sequence that is zero for 
n < 0, the unilateral and bilateral z-transforms will be identical. Referring to the discussion 
of regions of convergence in Section 10.2, we also see that, since x[n]u[n] is always a 
right-sided sequence, the region of convergence of X(z) is always the exterior of a circle. 
Because of the close connection between bilateral and unilateral z-transforms, the 
calculation of unilateral transforms proceeds much as for bilateral transforms, with the 
caveat that we must take care to limit the range of summation in the transform to n :::::: 0. 
Similarly, the calculation of inverse unilateral transforms is basically the same as for bilat-
eral transforms, once we take into account the fact that the ROC for a unilateral transform 
is always the exterior of a circle. 
1 0. 9. 1 Examples of Unilateral z-Transforms and Inverse Transforms 
Example 1 0.32 
Consider the signal 
x[n] = a"u[n]. 
(10.127) 
Since x[ n] = 0, n < 0, the unilateral and bilateral transforms are equal for this example, 
and thus, in particular, 
X(z) = 1 - ~z- I , 
lzl > lal. 
(10.128) 
Example 1 0.33 
Let 
x[n] = a"+ 1u[n + 1]. 
(10.129) 
In this case the unilateral and bilateral transforms are not equal, since x[ - 1] = 1 ¥- 0. 
The bilateral transform is obtained from Example 10.1 and the time-shifting property set 
forth in Section 10.5.2. Specifically, 
z 
X(z) = 1 
I, 
- az 
lzl > lal. 
(10.130) 

Sec. 10.9 
The Unilateral z-Transform 
In contrast, the unilateral transform is 
or 
00 
~(z) = L, x[n]z-
11 
11 = 0 
00 
= L,a"+1z- ", 
11 = 0 
~(z) = 
a 
1- az 1' 
791 
lzl > lal. 
(10.131) 
Example 1 0.34 
Consider the unilateral z-transform 
(10.132) 
In Example 10.9, we considered the inverse transform for a bilateral z-transform X(z) 
of the same form as in eq. (10.132) and for several different ROCs. In the case of the 
unilateral transform, the ROC must be the exterior of the circle of radius equal to the 
largest magnitude of the poles of ~(z)-in this instance, all points z with lzl > 113. We 
can then invert the unilateral transform exactly as in Example 10.9, yielding 
x[n] = (~} u[n] + 2G} u[n] 
for 
n 2: 0. 
(10.133) 
In eq. (10.133), we have emphasized the fact that inverse unilateral z-transforms provide 
us with information about x[n] only for n 2: 0. 
Another approach to inverse transforms introduced in Section 10.3, namely, iden-
tifying the inverse transforms from the coefficients in the power-series expansion of the 
z-transform, also can be used for unilateral transforms. However, in the unilateral case, a 
constraint which must be satisfied is that, as a consequence of eq. (10.125), the power-
series expansion for the transform cannot contain terms with positive powers of z. For 
instance, in Example 10.13 we performed long division on the bilateral transform 
1 
X(z) = 1 
- t 
- az 
(10.134) 
in two ways, corresponding to the two possible ROCs for X(z). Only one of these choices, 
namely, that corresponding to the ROC lzl > lal, led to a series expansion without positive 
powers of z, i.e., 
1 
(10.135) 
1 - az- t 

792 
The z-Transform 
Chap. 10 
and this is the only choice for the expansion if eq. (10.134) represents a unilateral trans-
form. 
Note that the requirement that ~(z) have a power-series expansion with no terms 
with positive powers of z implies that not every function of z can be a unilateral z-transform. 
In particular, if we consider a rational function of z written as a ratio of polynomials in z 
(not in z- 1 ), i.e., 
p(z) 
q(z)' 
(10.136) 
then for this to be a unilateral transform (with the appropriately chosen ROC as the ex-
terior of a circle), the degree of the numerator must be no bigger than the degree of the 
denominator. 
Example 1 0.35 
A simple example illustrating the preceding point is given by the rational function in 
eq. (10.130), which we can write as a ratio of polynomials in z: 
z2 
z-a 
(10.137) 
There are two possible bilateral transforms that can be associated with this function, 
namely those corresponding to the two possible ROCs, lzl < lal and lzl > Ia!. The choice 
lzl > Ia I corresponds to a right-sided sequence, but not to a signal that is zero for all n < 0, 
since its inverse transform, which is given by eq. (10.129), is nonzero for n = -1. 
More generally, if we associate eq. (10.136) with the bilateral transform with the 
ROC that is the exterior of the circle with radius given by the magnitude of the largest 
root of q(z), then the inverse transform will certainly be right sided. However, for it to 
be zero for all n < 0, it must also be the case that degree(p(z)) :::;; degree(q(z)). 
1 0.9.2 Properties of the Unilateral z-Transform 
The unilateral z-transform has many important properties, some of which are identical to 
their bilateral counterparts and several of which differ in significant ways. Table 10.3 sum-
marizes these properties. Note that we have not included a column explicitly identifying 
the ROC for the unilateral z-transform for each signal, since the ROC of any unilateral z-
transform is always the exterior of a circle. For example, the ROC for a rational unilateral 
z-transform is always outside the outermost pole. 
By contrasting this table with the corresponding Table 10.1 for bilateral z-transforms, 
we can gain considerable insight into the nature of the unilateral transform. In particular, 
several properties-namely, linearity, scaling in the z-domain, time expansion, conjuga-
tion, and differentiation in the z-domain-are identical to their bilateral counterparts, as 
is the initial-vaJ.ue theorem stated in Section 10.5.9, which is fundamentally a unilateral 
transform property, since it requires x[n] = 0 for n < 0. One bilateral property, namely, 
the time-reversal property set forth in Section 10.5.4, obviously has no meaningful coun-
terpart for the unilateral transform, while the remaining properties differ in important ways 
between the bilateral and unilateral cases. 

Sec. 10.9 
The Unilateral z-Transform 
TABLE 10.3 
PROPERTIES OF THE UNILATERAL z-TRANSFORM 
Property 
Linearity 
Time delay 
Time advance 
Scaling in the z-domain 
Time expansion 
Conjugation 
Convolution (assuming 
that x1 [n] and x2[n] 
are identically zero for 
n < 0) 
First difference 
Accumulation 
Differentiation in the 
z-domain 
ax1 [n] + bx2[n] 
x[n - l] 
x[n + l] 
ei"'o" x[n] 
z0x[n] 
a"x[n] 
x , [n] = { x[m], 
0, 
x'[n] 
x1 [n] * x2[n] 
x[n] - x[n - 1] 
II 
_Lx[k] 
k-0 
nx[n] 
Signal 
n = mk 
n ¥< mk for any m 
Initial Value Theorem 
x[O] = limft:(z) 
z-oo 
793 
Unilateral z-Transfonn 
aft:I(Z) + bft:2(z) 
z- 1SC(z) + x[ -1] 
zfe(z) - zx[O] 
ft:(e- j wo z) 
ft:(z!Zo) 
ft:(a- 1 z) 
fe(zk) 
ft:' (z') 
f( 1 (z) ft:2(z) 
(1 - z- 1)ft:(z)- x[ -1] 
1 
1 - z- 1 ft:(z) 
dfe(z) 
-z-----;rz 
Let us examine the difference in the convolution property first. Table 10.3 states that 
if x 1 [n] = xz[n] = 0 for all n < 0, then 
(10.138) 
Since in this case the unilateral and bilateral transforms are identical for each of these 
signals, eq. (10.138) follows from the bilateral convolution property. Thus, the system 
analysis and system function algebra developed and used in this chapter apply without 
change to unilateral transforms, as long as we are considering causal LTI systems (for 
which the system function is both the bilateral and the unilateral transform of the impulse 
response) with inputs that are identically zero for n < 0. An example of such application 
is to the accumulation or summation property in Table 10.3. Specifically, if x[n] = 0 for 
n < 0, then 
n 
'UZ 
1 
L x[k] = x[n] * u[n] ~ 
X(z)'U(z) = X(z) 1 __ 1• 
k=O 
z 
(10.139) 
As a second example, consider the following: 

794 
The z-Transform 
Example 1 0.36 
Consider the causal LTI system described by the difference equation 
y[n] + 3y[n- 1] = x[n], 
Chap. 10 
(10.140) 
together with the condition of initial rest. The system function for this system is 
1 
J{ (z) = 1 + 3z 1 • 
(10.141) 
·Suppose that the input to the system is x[n] = au[n], where a is a given constant. In 
this case, the unilateral (and bilateral) z-transform of the output y[n] is 
'Y(z) = J{(z)fr(z) = (1 + 3c~(l- z- ') 
= 
(3/4)a + (1/4)a . 
1+3z- 1 
1-z- 1 
Applying Example 10.32 to each term of eq. (10.142) yields 
y[n] = a[~ + (~ )<-3f ]u[n]. 
(10.142) 
(10.143) 
An important point to note here is that the convolution property for unilateral z-
transforms applies only if the signals Xi [n] and x2[n] in eq. (10.138) are both identically 
zero for n < 0. While it is generally true that the bilateral transform of Xi [n] * x 2[n] equals 
the product of the bilateral transforms of Xi [n] and x2[n], the unilateral transform of x1[n]* 
x2[n] in general does not equal the product of the unilateral transforms if Xi [n] or x2[n] is 
nonzero for n < 0. This point is explored further in Problem 10.41. 
Much of the importance of the unilateral z-transform lies in its application to analyz-
ing causal systems and, in particular, systems characterized by linear constant-coefficient 
difference equations with possibly nonzero initial conditions. In Section 10.7 we saw 
how the bilateral transform-particularly the shifting property for bilateral z-transforms-
could be used to analyze and compute solutions for LTI systems characterized by such 
difference equations, together with the assumption of initial rest. As we will now see, 
the shifting property for unilateral transforms, which differs from its bilateral counterpart, 
· plays an analogous role for initialized systems. 
To develop the shifting property for the unilateral transform, consider the signal 
y[n] = x[n - 1]. 
(10.144) 
Then 
00 
'Y(z) = L x[n- l]z- n 
n=O 
= x[ -1] + L x[n - 1]z-n 
n=i 
00 
= x[ -1] + L x[n]z- (n+l), 
n=O 

Sec. 10.9 
The Unilateral z-Transform 
795 
or 
"' 
'Y(z) = x[ -1] + z- 1 L x[n]z- n, 
(10.145) 
n=O 
so that 
'Y(z) = x[ - 1] + z- 1X(z). 
(10.146) 
By repeated application of eq. (10.146), the unilateral transform of 
w[n] = y[n - 1] = x[n - 2] 
(10.147) 
is 
'W(z) = x[ -2] + x[ - 1]z-1 + z- 2X(z). 
(10.148) 
Continuing this iterative procedure, we can also determine the unilateral transform of x[n-
m] for any positive value of m. 
Eq. (10.146) is sometimes referred to as the time delay property, since y[n] in 
eq. (10.144) is a delayed version of x[n]. There is also a time advance property for 
unilateral transforms that relates the transform of an advanced version of x[n] to X(z). 
Specifically, as shown in Problem 10.60, 
'UZ 
x[n + 1] ~ 
zX(z)- zx[O]. 
(10.149) 
1 0.9.3 Solving Difference Equations Using the Unilateral 
z-Transform 
The following example illustrates the use of unilateral z-transforms and the time delay 
property to solve linear constant-coefficient difference equations with nonzero initial con-
ditions: 
Example 1 0.37 
Consider again the difference equation (10.140) with x[n] = au[n] and with the initial 
condition 
y[-1] = {3. 
(10.150) 
Applying the unilateral transform to both sides of eq. (10.140) and using the linearity 
and time delay properties, we obtain 
(10.151) 
Solving for 'Y(z) yields 
'Y(z) = - 1 }~z 1 + (1 + 3z ~(1 - z 1 )" 
(10.152) 

796 
1 0. 1 0 SUMMARY 
The z-Transform 
Chap. 10 
Referring to Example 10.36 and, in particular, eq. (10.142), we see that the second 
term on the right-hand side of eq. (10.152) equals the unilateral z-transform of there-
sponse of the system when the initial condition in eq. (10.150) is zero ({3 = 0). That is, 
this term represents the response of the causal LTI system described by eq. (10.140), to-
gether with the condition of initial rest. As in continuous-time, this response is frequently 
referred to as the zero-state response, i.e., the response when the initial condition or state 
is zero. 
The first term on the right-hand side of eq. (10.152) is interpreted as the unilateral 
transform of the zero-input response- i.e., the response of the system when the input 
is zero (a = 0). The zero-input response is a linear function of the value f3 of the ini-
tial condition. Moreover, eq. (10.152) illustrates the fact that the solution of a linear 
constant-coefficient difference equation with nonzero initial state is the superposition of 
the zero-state and zero-input responses. The ,zero-state response, obtained by setting the 
initial condition to zero, corresponds to the response of the causal LTI system defined by 
the difference equation and the condition of initial rest. The zero-input response is there-
sponse to the initial condition alone with the input set to zero. Problems 10.20 and 10.42 
provide other examples illustrating the use of unilateral transforms to solve difference 
equations with nonzero initial conditions. 
Finally, for any values of a and {3, we can expand 'Y(z) in eq. (10.152) by the 
method of partial fractions and invert the result to obtain y[n]. For example, if a = 8 
and f3 = 1, 
3 
2 
'Y(z) = 1 + 3z- 1 + 1 - z- 1 ' 
(10.153) 
and applying the unilateral transform pair in Example 10.32 to each term yields 
y[n] = [3(- 3t + 2]u[n], 
for n ~ 0. 
(10.154) 
' 
In this chapter, we have developed the z-transform for discrete-time signals and systems. 
The discussion and development closely paralleled the corresponding treatment of the 
Laplace transform for continuous-time signals, but with some important differences. For 
example, in the complex s-plane the Laplace transform reduces to the Fourier transform on 
the imaginary axis, whereas in the complex z-plane the z-trapsform reduces to the Fourier 
transform on the unit circle. For the Laplace transform the ROC consists of a strip or 
half-plane (i.e., a strip extending to infinity in one direction), whereas for the z-transform 
the ROC is a ring, perhaps extending outward to infinity or inward to include the origin. 
As with the Laplace transform, time-domain characteristics such as the right-sided, left-
sided, or two-sided nature of a sequence and the causality or stability of an LTI system 
can be associated with properties of the region of convergence. In particular, for rational 
z-transforms, these time-domain characteristics can be associated with the pole locations 
in relation to the region of convergence. 
Because of the properties of z-transforms, LTI systems, including those described 
by linear constant-coefficient difference equations, can be analyzed in the transform do-
main by algebraic manipulations. System function algebra also is a very useful tool for 
the analysis of interconnections of LTI systems and for the construction of block diagram 
representations of LTI systems described by difference equations. 

Chap. 10 
Problems 
797 
For the most part in this chapter, we have focused on bilateral z-transforms. However, 
as with the Laplace transform, we have also introduced a second form of the z-transform 
known as the unilateral z-transform. The unilateral transform, which can be viewed as the 
bilateral transform of a signal whose values for n < 0 have been set to zero, is particularly 
useful for analyzing systems described by linear constant-coefficient difference equations 
with nonzero initial conditions. 
Chapter 1 0 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
10.1. Determine the constraint on r = lzl for each of the following sums to converge: 
(a) ~ 
(~)n + l Z-n 
(b) ~(~) - n + l zn 
n= - 1 
n= l 
00 
00 
(c) ~{l+(~ l)" }z - n 
(d) ~ 
(~)lnl cos(in)z- n 
n=O 
n= -co 
10.2. Consider the signal 
x[n] = G r 
u[n - 3]. 
Use eq. (10.3) to evaluate the z-transform of this signal, and specify the corre-
sponding region of convergence. 
10.3. Let 
x[n] = (- Itu[n] + a"u[-n- no]. 
Determine the constraints on the complex number a and the integer no, given that 
the ROC of X(z) is 
' 
10.4. Consider the signal 
1 < lzl < 2. 
x[n] = { (~)" cos(~n), 
0, 
Determine the poles and ROC for X(z). 
n ::5 0 
n > O 
10.5. For each of the following algebraic expressions for the z-transform of a signal, 
determine the number of zeros in the finite z-plane and the number of zeros at 
infinity. 

798 
z- 1(1 -
.!.z- 1) 
(a) 
2 
(1 _ ~ z - 1)(1 _ ~ z- 1) 
(1 - z- 1)(1 - 2z- 1) 
(b) (1- 3z-1)(1- 4c 1) 
z- 2(1- z- 1) 
(c) 
(1 -
~z- 1)(1 + ~z - 1) 
The z-Transform 
Chap. 10 
10.6. Let x[n] be an absolutely summable signal with rational z-transform X(z). If X(z) 
is known to have a pole at z = 1/2, could x[n] be 
(a) a finite-duration signal? 
(b) a left-sided signal? 
(c) a right-sided signal? 
(d) a two-sided signal? 
10.7. Suppose that the algebraic expression for the z-transform of x[n] is 
1- !z- 2 
X(z) = 
4 
• 
(1 + ~ z- 2)(1 + ~ z- 1 + ~ z- 2) 
How many different regions of convergence could correspond to X(z)? 
10.8. Let x[n] be a signal whose rational z-transform X(z) contains a pole at z = 1/2. 
Given that 
x1 [n] = (~ J 
x[n] 
is absolutely stimmable and 
x2[n] = (~ J 
x[n] 
is not absolutely summable, determine whether x[n] is left sided, right sided, or 
two sided. 
10.9. Using partial-fraction expansion and the fact that 
anu[n] ~ 
1 
1 _1, lzl > ial, 
- az 
find the inverse z-transform of 
1 - !z- 1 · 
X(z) = (1 - z-1)Zl + 2z-l)' lzl > 2. 
10.10. Consider the following algebraic expression for the z-transform X(z) of a signal 
x[n]: 
1 + z- 1 
X(z) = 1 + .!.z- 1. 
3 

Chap. 10 Problems 
799 
(a) Assuming the ROC to be lzl > 113, use long division to determine the values 
of x[O], x[1], and x[2]. 
(b) Assuming the ROC to be lzl < 1/3, use long division to determine the values 
of x[O], x[ -1], and x[ -2]. 
10.11. Find the inverse z-transform of 
1 
[1,024 - z-
10
] 
X(z) = 1,024 
1 -
~z-1 
, lzl > 0. 
10.12. By considering the geometric interpretation of the magnitude of the Fourier trans-
form from the pole-zero plot, determine, for each of the following z-transforms, 
whether the corresponding signal has an approximately lowpass, bandpass, or 
highpass characteristic: 
- I 
(a) X(z) = 
1 z 8 _ 1 , lzl > ~ 
+ §Z 
1 + ~z -
1 
(b) X(z) = 1 _ ~z-~ + ~z_ 2 , lzl > ~ 
9 
81 
(c) X(z) = 1 
~ _2 , lzl > ~ 
+ SfZ 
10.13. Consider the rectangular signal 
x[n] = { ~: 
Let 
Os;ns;5 
otherwise 
· 
g[n] = x[n] - x[n - 1]. 
(a) Find the signal g[n] and directly evaluate its z-transform. 
(b) Noting that 
n 
x[n] = L g[k], 
k= - oo 
use Table 10.1 to determine the z-transform of x[n]. 
10.14. Consider the triangular signal 
g[n] = { 73--\ 
0, 
2s;ns;? 
8 s; n s; 12. 
otherwise 
(a) Determine the value of no such that 
g[n] = x[n] * x[n - no], 
where x[n] is the rectangular signal considered in Problem 10.13. 
(b) Use the convolution and shift properties in conjunction with X(z) found in 
Problem 10.13 to determine G(z). Verify that your answer satisfies the initial-
value theorem. 

800 
The z-Transform 
Chap. 10 
10.15. Let 
y[n] = G r 
u[n]. 
Determine two distinct signals such that each has a z-transform X (z) which satisfies 
both of the following conditions: 
1. [X(z) + X(- z)]/2 = Y(z2). 
2. X(z) has only one pole and only one zero in the z-plane. 
10.16. Consider the following system functions for stable LTI systems. Without utilizing 
the inverse z-transform, determine in each case whether or not the corresponding 
system is causal. 
1- :!z- 1 + !z- 2 
(a) 
3 
2 
z-1(1 _ ~z-1)(1 _ ~z - 1) 
(b) 
(c) 
z- ! 2 
z2 + !z- l 
2 
16 
z+l 
z +:!- !z-2 -
~z-3 
3 
2 
3 
10.17. Suppose we are given the following five facts about a particular LTI systemS with 
impulse response h[n] and z-transform H(z): 
1. h[n] is real. 
2. h[n] is right sided. 
3. limH(z) = 1. 
z---.oo 
4. H(z) has two zeros. 
5. H(z) has one of its poles at a nonreallocation on the circle defined by lzl = 3/4. 
Answer the following two questions: 
(a) IsS causal? 
(b) IsS stable? 
10.18. Consider a causal LTI system whose input x[n] and output y[n] are related through 
the block diagram representation shown in Figure P10.18. 
y[n] 
Figure Pl 0. 18 
(a) Determine a difference equation relating y[n] and x[n]. 
(b) Is this system stable? 
10.19. Determine the unilateral z-transform of each of the following signals, and specify 
the corresponding regions of convergence: 

Chap. 10 Problems 
(a) x, [n] = Ci)"u[n + 5] 
(b) X2[n] = o[n + 3] + o[n] + 2nu[ - n] 
(c) x3[n] = <V"I 
10.20. Consider a system whose input x[n] and output y[n] are related by 
y[n- 1] + 2y[n] = x[n]. 
(a) Determine the zero-input response of this system if y[ -1] = 2. 
801 
(b) Determine the zero-state response of the system to the input x[ n] = ( 114 )" u[ n ]. 
(c) Determine the output of the system for n ~ 0 when x[n] = (114Yu[n] and 
y[ -1] = 2. 
BASIC PROBLEMS 
10.21. Determine the z-transform for each of the following sequences. Sketch the pole-
zero plot and indicate the region of convergence. Indicate whether or not the Fourier 
transform of the sequence exists. 
(a) o[n + 5] 
(b) o[n- 5] 
(c) (-l)"u[n] 
(d) (~)n+Iu[n + 3] 
(e) (-
~ )nu[ - n - 2] 
(f) Ci)nu[3 - n] 
(g) 2"u[ -n] + Ci)nu[n- 1] 
(h) (~)"-
2 u[n - 2] 
10.22. Determine the z-transform for the following sequences. Express all sums in closed 
form. Sketch the pole-zero plot and indicate the region of convergence. Indicate 
whether the Fourier transform of the sequence exists. 
(a) (~)n{u[n + 4] - u[n - 5]} 
(b) n(V"I 
(c) 
l nl(~)lnl 
(d) 4"cos[ 2;n + iJu[- n- 1] 
10.23. Following are several z-transforms. For each one, determine the inverse z-transform 
using both the method based on the partial-fraction expansion and the Taylor's se-
ries method based on the use of long division . . 
X(z) = 1- z- 1 
1 
1 
I - 2' lzl > 2" 
- 4z 
1 - z- 1 
1 
X(z) = 1- l.z-2' lzl < 2" 
4 
z-' - l. 
1 
X(z) = 
2 
lzl > 2· 
1 - l.z- 1' 
2 
z- ' - l. 
1 
X(z) = 
2 
lzl < 2· 
1 - l.z-I' 
2 
X(z) = 
z- 1 -
l. 
1 
(1- ~z-~)2' lzl > 2" 
X(z) = 
z- 1 -! 
1 
(1- ~z-~)2' lzl < 2" 

802 
The z-Transform 
Chap. 10 
10.24. Using the method indicated, determine the sequence that goes with each of the 
following z-transforms: 
(a) Partial fractions: 
X(z) = 1 + h_1 + z_2, and x[n] is absolutely summable. 
(b) Long division: 
1- .!.z- 1 
X(z) = 
2 
and x[n] is right sided. 
1 + .!.z- 1' 
2 
(c) Partial fractions: 
X(z) = 
1 
3 
1 _ , and x[n] is absolutely summable. 
z -- - -z 1 
4 
8 
10.25. Consider a right-sided sequence x[n] with z-transform 
X(z) = 
· 
1 
. 
. 
(1 _ ~ z- I )(I _ z- I) 
(P10.25-l) 
(a) Carry out a partial-fraction expansion of eq. (P10.25- 1) expressed as a ratio 
ot polynomials in z- 1, and from this expansion, determine x[n] . 
(b) Rewrite eq. (Pl0.25-1) as a ratio of polynomials in z, and carry out a partial-
fraction expansion of X(z) expressed in terms of polynomials in z. From this 
expansion, determine x[n], and demonstrate that the sequence obtained is 
identical to that obtained in part (a). 
10.26. Consider a left-sided sequence x[n] with z-transform 
1 
X(z) = 
. 
(1 -
~z - 1)(1- z- 1) 
(a) Write X(z) as a ratio of polynomials in z instead of z- 1• 
(b) Using a partial-fraction expression, express X(z) as a sum of terms, where each 
term represents a pole from your answer in part (a). 
(c) Determine x[n]. 
10.27. A right-sided sequence x[n] has z-transform 
Determine x[n] for n < 0. 
10.28. (a) Determine the z-transform of the sequence 
x[n] = 5[n] - 0.95 5[n- 6]. 
(b) Sketch the pole-zero pattern for tht> sequence in part (a). 
(c) By considering the behavior of the pole and zero vectors as the unit circle 
is traversed, develop an approximate sketch of the magnitude of the Fourier 
transform of x[n]. 
10.29. By considering the geometric determination of the frequency response as discussed 
in Section 10.4, sketch, for each of the pole-zero plots in Figure Pl0.29, the mag-
nitude of the associated Fourier transform. 

Chap. 10 
Problems 
!Jm 
Unit circle 
(a) 
!Jm 
(c) 
Unit circle 
<Re 
(b) 
!Jm 
Unit circle 
!Jm 
(e) 
Figure Pl 0.29 
(d) 
Circle of radius 0.9 
803 

804 
The z-Transform 
Chap. 10 
10.30. Consider a signal y[n] which is related to two signals XI [n] and x2[n] by 
y[n] = XJ [n + 3] * x2[ - n + 1] 
where 
X) [n] = G r 
u[n] and 
X2[n] = G)' u[n]. 
Given that 
use properties of the z-transform to determine the z-transform Y(z) of y[n]. 
10.31. We are given the following five facts about a discrete-time signal x[n] with z-
transform X(z): 
1. x[n] is real and right-sided. 
2. X(z) has exactly two poles. 
3. X(z) has two zeros at the origin. 
4. X(z) has a pole at z = 4efrrl3. 
5. X(1) = ~· 
Determine X(z) and specify its region of convergence. 
10.32. Consider an LTI system with impulse response 
and input 
h[n] = { ~~' 
n 2: 0 
n<O 
[ ] = { 1, 
0 ::5 n ::5 N - 1 
xn 
0 
th 
. 
. 
, 
o erwtse 
(a) Determine the output y[n] by explicitly evaluating the discrete convolution of 
x[n] and h[n]. 
(b) Determine the output y[n] by computing the inverse z-transform of the product 
of the z-transforms of the input and the unit sample response. 
10.33. (a) Determine the system function for the causal LTI system with difference equa-
tion 
1 
1 
y[n] -
2'y[n - 1] + 4y[n- 2] = x[n]. 
(b) Using z-transforms, determine y[n] if 
x[n] = (~ )' u[n]. 

Chap. 10 Problems 
805 
10.34. A causal LTI system is described by the difference equation 
y[n] = y[n - 1] + y[n - 2] + x[n- 1} 
(a) Find the system function H(z) = Y(z)/X(z) for this system. Plot the poles and 
zeros of H(z) and indicate the region of convergence. 
(b) Find the unit sample response of the system. 
(c) You should have found the system to be unstable. Find a stable (noncausal) 
unit sample response that satisfies the difference equation. 
10.35. Consider an LTI system with input x[n] and output y[n] for which 
5 
y[n- 1] - ly[n] + y[n + 1] = x[n]. 
The system may or may not be stable or causal. 
By considering the pole-zero pattern associated with the preceding differ-
ence equation, determine three possible choices for the unit sample response of 
the system. Show that each choice satisfies the difference equation. 
10.36. Consider the linear, discrete-time, shift -invariant system with input x[ n] and output 
y[n] for which 
10 
y[n- 1] - 3 y[n] + y[n + 1] = x[n]. 
The system is stable. Determine the unit sample response. 
, 
10.37. The input x[n] and output y[n] of a causal LTI system are related through the 
block-diagram representation shown in Figure P10.37. 
x[n] 
y[n] 
Figure PI 0.37 
(a) Determine a difference equation relating y[n] and x[n]. 
(b) Is this system stable? 
10.38. Consider a causal LTI systemS with input x[n] and a system function specified as 
H(z) = Ht (z)Hz(z), 
where 

x[n] 
.806 
The z-Transform 
Chap. 10 
and 
H ( ) 
1 
7 - 1 
1 - 2 
2 z = - 4z - 2z . 
A block diagram corresponding to H(z) may be obtained as a cascade connection 
of a block diagram for HI (z) followed by a block diagram for H2(z). The result is 
shown in Figure P10.38, in which we have also labeled the intermediate signals 
e1 [n], e2[n], !I [n], and fz[n]. 
(a) How is e1 [n] related to !I [n]? 
(b) How is e2[n] related to fz[n]? 
y[n] 
Figure P1 0.38 
(c) Using your answers to the previous two parts as a guide, construct a direct-
form block diagram for S that contains only two delay elements. 
(d) Draw a cascade-form block diagram representation for S based on the obser-
vation that 
(
1 + !z- I )(1 - 2z-I) 
H(~ = 
4 
. 
1 + !z-I 1- !z-I 
2 
4 
(e) Draw a parallel-form block diagram representation for S based on the obser-
vation that 
H(z) = 4 + 
513 
1 + !z-I 
2 
14/3 
1- !z- I. 
4 
10.39. Consider the following three system functions corresponding to causal LTI sys-
tems: 
1 
H1 (z) = -
-----,-----;;------:--
(1 -
z- I + i z-2)(1 -
~z- I + bz-2)' 
1 
H2(z) = -------,.---...,------
(1 _ z- 1 + ~z-2)(1 _ ~ z- I + z- 2)' 
1 
H3(z) = -
-
----,--------=---
(1- z-1 + ~z - 2)(1 - z- 1 + tz- 2). 

Chap. 10 Problems 
807 
(a) For each system function, draw a direct-form block diagram. 
(b) For each system function, draw a block diagram that corresponds to the cas-
cade connection of two second-order block diagrams. Each second-order block 
diagram should be in direct form. 
(c) For each system function, determine whether there exists a block diagram rep-
resentation which is the cascade of four first-order block diagrams with the 
constraint that all the coefficient multipliers must be real. 
10.40. Determine the unilateral z-transform for each of the sequences in Problem 10.21. 
10.41. Consider the following two signals: 
(
1 )n+l 
x1 [n] = 2' 
u[n + 1], 
x2[n] = (~ J 
u[n]. 
Let X 1 (z) and X 1 (z) respectively be the unilateral and bilateral z-transforms of 
x1 [n], and let X2(z) and X2(z) respectively be the unilateral and bilateral z-
transforms of x2[n]. 
(a) Take the inverse bilateral z-transform of X1 (z)X2(z) to determine g[n] = 
x1 [n] * x2[n]. 
(b) Take the inverse unilateral z-transform of X 1 (z)X2 (z) to obtain a signal q[ n] 
for n ;::: 0. Observe that q[n] and g[n] are not identical for n ;::: 0. 
10.42. For each of the following difference equations and associated input and initial con-
ditions, determine the zero-input and zero-state responses by using the unilateral 
z-transform: 
(a) y[n] + 3y[n- 1] = x[n], 
x[n] = G J 
u[n], 
y[ - 1] = 1. 
1 
1 
(b) y[n]- ly[n- 1] = x[n]- 2x[n- 1], 
x[n] = u[n], 
y[ -1] = 0. 
1 
1 
(c) y[n]- ly[n- 1] = x[n]- 2x[n- 1], 
x[n] = u[n], 
y[ -1] = 1. 
ADVANCED PROBLEMS 
10.43. Consider an even sequence x[n] (i.e., x[n] = x[ -n]) with rational z-transform 
X(z). 

808 
The z-Transform 
Chap. 10 
(a) From the definition of the z-transform, show that 
(b) From yourresults in part (a), show that if a pole (zero) of X(z) occursat z = z0, 
then a pole (zero) must also occur at z = l/z0. 
(c) Verify the result in part (b) for each of the following sequences: 
(1) cS[n + 1] + cS[n- 1] 
(2) cS[n + 1] -
~cS[n] + cS[n - 1] 
10.44. Let x[n] be a discrete-time signal with z-transform X(z). For each of the following 
signals, determine the z-transform in terms of X(z): 
(a) Ax[n], where A is the first-difference operator defined by 
(b) XI [n] = { x[n/2], 
0, 
(c) x1 [n] = x [2n] 
Ax[n] = x [n] - x[n -
1] 
n even 
n odd 
10.45. Determine which of the following z-transforms could be the transfer function of 
a discrete-time linear system that is not necessarily stable, but for which the unit 
sample response is zero for n < 0. State your reasons clearly. 
(1- z- 1)2 
(z - 1)2 
(a) 
(b) 
1 - ! z-1 
2 
(z -
~)5 
(c) (z- ~ )6 
(d) 
10.46. A sequence x[n] is the output of an LTI system whose input is s[n]. The system is 
described by the difference equation 
x[n] = s[n]- e8as[n- 8], 
where 0 < a < 1. 
(a) Find the system function 
X(z) 
HI (z) = S(z), 
, 
and plot its poles and zeros in the z-plane. Indicate the region of convergence. 
(b) We wish to recover s[n] from x[n] with an LTI system. Find the system func-
tion 

Chap. 10 Problems 
809 
such that y[n] = s[n]. Find all possible regions of convergence for H2(z), and 
for each, tell whether or not the system is causal or stable. 
(c) Find all possible choices for the unit impulse response h2[n] such that 
y[n] = hz[n] * x[n] = s[n]. 
10.47. The following is known about a discrete-time LTI system with input x[n] and out-
put y[n]: 
1. If x[n] = (- 2)n for all n, then y[n] = 0 for all n. 
2. If x[n] = (112)nu[n] for all~· then y[n] for all n is of the form 
y[n] = 8[n] + a(~ J 
u[n], 
where a is a constant. 
(a) Determine the value of the constant a. 
(b) Determine the response y[n] if the input x[n] is 
x[n] = 1, for all n. 
10.48. Suppose a second-order causal LTI system has been designed with a real impulse 
response h1 [n] and a rational system function H1 (z). The pole-zero plot for H1 (z) 
is shown in Figure P10.48(a). Now consider another causal second-order system 
with impulse response hz[n] and rational system function H2(z). The pole-zero plot 
for Hz(z) is shown in Figure P10.48(b). Determine a sequence g[n] such that the 
following three conditions hold: 
(1) hz[n] = g[n]h1 [n] 
(2) g[n] = 0 for n < 0 
"' 
(3) L)g[kJ! = 3 
k=O 
!Jm 
!Jm 
1 
eRe 
(a) 
(b) 
Figure Pl 0.48 

810 
The z-Transform 
Chap. 10 
10.49. In Property 4 of Section 10.2, it was stated that if x[n] is a right-sided sequence and 
if the circle lzl = ro is in the ROC, then all finite values of z for which 1z1 > r0 will 
also be in the ROC. In this discussion an intuitive explanation was given. A more 
formal argument parallels closely that used for Property 4 of Section 9.2, relating 
to the Laplace transform. Specifically, consider a right-sided sequence 
x[n] = 0, n < N1, 
and for which 
"' 
"' 
L lx[n]lr0n = L lx[n]ir0n < oo. 
n= - oo 
Then if ro ::::: r1, 
"' 
"' 
L lx[n]irln ::::: A L lx[nllron, 
(P10.49- 1) 
where A is a positive constant. 
(a) Show that eq. (P10.49-1) is true, and determine the constant A in terms of r0, 
r1, andN1• 
· 
(b) From your result in part (a), show that Property 4 of Section 10.2 follows. 
(c) Develop an argument similar to the foregoing one to demonstrate the validity 
of Property 5 of Section 10.2. 
10.50. A discrete-time system with the pole-zero pattern shown in Figure P10.50(a) is 
referred to as a first-order all-pass system, since the magnitude of the frequency 
response is constant regardless of frequency. 
(a) Demonstrate algebraically that IH(ejw)l is constant. 
\ 
To demonstrate the same property geometrically, consider the vector dia-
gram in Figure PlO.SO(b). We wish to show that the length ofv2 is proportional 
to the length of v1 independently of the frequency w. 
Unit circle 
ROC: lzl>a 
(a) 
Figure PI O.SOa 

Chap. 10 
Problems 
811 
(b) 
Figure P1 O.SOb 
(b) Express the length ofv1 using the law of cosines and the fact that v1 is one leg 
of a triangle for which the other two legs are the unit vector and a vector of 
length a. 
(c) In a manner similar to that in part (b), determine the length of v2 and show 
that it is proportional in length to v1 independently of w. 
10.51. Consider a real-valued sequence x[n] with rational z-transform X(z). 
(a) From the definition of the z-transform, show that 
X(z) = X*(z*). 
(b) From your result in part (a), show that if a pole (zero) of X(z) occurs at z = zo, 
then a pole (zero) must also occur at z = z0. 
(c) Verify the result in part (b) for each of the following sequences: 
(1) x[n] = <!)nu[n] 
(2) x[n] = 8[n] - !8[n- 1] + ~8[n- 2] 
(d) By combining your results in part (b) with the result of Problem 1 0.43(b ), show 
that for a real, even sequence, if there is a pole (zero) of H(z) at z = pei8 , then 
thereisalsoapole(zero)ofH(z)atz = (llp)ei8 andatz = (llp)e-i8 . 
10.52. Consider a sequence x1 [n] with z-transform X1 (z) a~d a sequence x2[n] with z-
transform Xz(z), where 
xz[n] = x 1 [- n]. 
Show that X2(z) = X1(1/z), and from this, show that if X1(z) has a pole (or zero) 
at z = zo, then Xz(z) has a pole (or zero) at z = llzo. 
10.53. (a) Carry out the proof for each of the following properties in Table 10.1: 
(1) Property set forth in Section 10.5.2 
(2) Property set forth in Section 10.5.3 
(3) Property set forth in Section 10.5.4 

812 
The z-Transform 
Chap. 10 
(b) With X (z) denoting the z-transform of x[ n] and Rx the ROC of X (z), determine, 
in terms of X(z) and Rx, the z-transform and associated ROC for each of the 
following sequences: 
(1) x* [n] 
(2) z0x[n], where zo is a complex number 
10.54. In Section 10.5.9, we stated and proved the initial-value theorem for causal se-
quences. 
(a) State and prove the corresponding theorem if x[n] is anticausal (i.e., if x[n] = 
0, n > 0). 
(b) Show that if x[n] = 0, n < 0, then 
x[l] = lim z(X(z) - x[O]). 
z - HlO 
10.55. Let x[n] denote a causal sequence (i.e., if x[n] = 0, n < 0) for which x[O] is 
nonzero and finite. 
(a) Using the initial-value theorem, show that there are no poles or zeros of X(z) 
at z = oo. 
(b) Show that, as a consequence of your result in part (a}, the number of poles 
of X(z) in the finite z-plane equals the number of zeros of X(z) in the finite 
z-plane. (The finite z-plane excludes z = oo.) 
10.56. In Section 10.5.7, we stated the convolution property for the z-transform. To show 
that this property holds, we begin with the convolution sum expressed as 
00 
x3 [n] = x, [n] * x2[n] = L x, [k]x2[n - k]. 
(P10.56-1) 
k = - oo 
(a) By taking the z-transform of eq. (P10.56-1) and using eq. (10.3), show that 
00 
X3(Z) = L XJ [k]X2(Z), 
k = - oo 
where X2(z) is the transform of x2[n - k]. 
(b) Using your result in part (a) and property 10.5.2 in Table 10.1, show that 
00 
X3(z) = X2(z) L x1 [k] z- k. 
(c) From part (b), show that 
as stated in eq. (10.81). 
10.57. Let 
k = -oo 
X1 (z) = x 1 [0] + x 1 [1]z- 1 + · · · + x1 [NI] z- N1, 
Xi(z) = X2[0] + X2[1]z- I + · · · + x2[N2]z- N2 • 
Define 

Chap. 10 Problems 
and let 
M 
Y(z) = 2: y[k]z- k. 
k=O 
(a) Express Min terms of N1 and N2. 
(b) Use polynomial multiplication to determine y[O], y[l], and y[2]. 
(c) Use polynomial multiplication to show that, for 0 ::::::; k ::::::; M, 
00 
y[k] = ~ 
x1 [m]x2[k- m]. 
m= - oo 
813 
10.58. A minimum-phase system is a system that is causal and stable and for which the 
inverse system is also causal and stable. Determine the necessary constraints on the 
location in the z-plane of the poles and zeros of the system function of a minimum-
phase system. 
10.59. Consider the digital filter structure shown in Figure P10.59. 
_ Js_ 
3 
_Js_ 
4 
Figure P1 0.59 
(a) Find H(z) for this causal filter. Plot the pole-zero pattern and indicate there-
gion of convergence. 
(b) For what values of the k is the system stable? 
(c) Determine y[n] if k = 1 and x[n] = (2/3)n for all n. 
10.60. Consider a signal x[n] whose unilateral z-transform is X(z). Show that the unilat-
eral z-transform of y[n]. = x[n + 1] may be specified as 
'Y(z) = zX(z) - zx[O]. 
10.61. IfX(z) denotes the unilateral z-transform of x[n], determine, in terms ofX(z), the 
unilateral z-transform of: 
(a) x[n + 3] 
(b) x[n - 3] 
(c) L~ =-oo x[k] 
EXTENSION PROBLEMS 
10.62. The autocorrelation sequence of a sequence x[n] is defined as 
00 
c/JxAn] = ~ 
x[k]x[n + k]. 
k= -00 
Determine the z-transform of c/JxAn] in terms of the z-transform of x[n]. 

814 
The z-Transform 
Chap. 10 
10.63. By using the power-series expansion 
oo 
wi 
log(l - w) = - L --:-, JwJ < 1, 
i= I 
l 
determine the inverse of each of the following two z-transforms: 
(a) X(z) = log(l - 2z), lzl < ~ 
(b) X(z) = log(l- ~z-
1 ), lzl > ~ 
10.64. By first differentiating X(z) and using the appropriate properties of the z-transform, 
determine the sequence for which the z-transform is each of the following: 
(a) X(z) = log(l - 2z), lzl < ~ 
(b) X(z) = log(l- ~z-
1
), lzl > ~ 
Compare your results for (a) and (b) with the results obtained in Problem 10.63, in 
which the power-series expansion was used. 
10.65. The bilinear transformation is a mapping for obtaining a rational z-transform Hd(Z) 
from a rational Laplace transform Hc(s). This mapping has. two important proper-
ties: 
1. If Hc(s) is the Laplace transform of a causal and stable LTI system, then Hd(Z) 
is the z-transform of a causal and stable LTI system. 
2. Certain important characteristics of IHc(jw )J are preserved in JHd(ejw)J. 
In this problem, we illustrate the second of these properties for the case of all-pass 
filters. 
(a) Let 
a - s 
Hc(s) = - -, 
s+a 
where a is real and positive. Show that 
JHc(jw)J = 1. 
(b) Let us now apply the bilinear transformation to Hc(s) in order to obtain Hd(Z). 
· That is, 
Show that Hd(Z) has one pole (which is inside the unit circle) and one zero 
(which is outside the unit circle). 
(c) For the system function Hd(Z) derived in part (b), show that IHd(ejw)J = 1. 
10.66. The bilinear transformation, introduced in the previous problem, may also be used 
to obtain a discrete-time filter, the magnitude of whose frequency response is sim-
ilar to the magnitude of the frequency response of a given continuous-time low-
pass filter. In this problem, we illustrate the similarity through the example of a 
continuous-time second-order Butterworth filter with system function Hc(s). 

Chap. 10 Problems 
815 
(a) Let 
Hc~(z) = Hc(s)is= ,_,_,. 
l +z- 1 
Show that 
(b) Given that 
and that the corresponding filter is causal, verify that Hc(O) = 1, that IHc(jw )I 
decreases monotonically with increasing positive values of w, that IHc(J)I2 = 
1/2 (i.e., that W e = 1 is the half-power frequency), and that Hc(oo) = 0. 
(c) Show that if the bilinear transformation is applied to Hc(s) of part (b) in order 
to obtain Hc~(z), then the following may be asserted about Hc~(z) and Hc~(ejw): 
1. 
Hc~(z) has only two poles, both of which are inside the unit circle. 
2. 
Hc~(ej0 ) = 1. 
3. 
IHc~(ejw)l decreases monotonically as w goes from 0 to 'TT'. 
4. The half-power frequency of Hc~(ejw) is 1r12. 

11 
lJNEARFEEDBACKSYSTEMS 
11 .0 INTRODUCTION 
816 
It has long been recognized that in many situations there are particular advantages to be 
gained by using feedback-that is, by using the output of a system to control or modify 
the input. For example, it is common in electromechanical systems, such as a motor whose 
shaft position is to be maintained at a constant angle, to measure the error between the 
desired and the true position and to use this error in the form of a ~ignal to tum the shaft 
in the appropriate direction. This is illustrated in Figure 11.1, where we have depicted 
the use of a de motor for the accurate pointing of a telescope. In Figure 11.1(a) we have ' 
indicated pictorially what such a system would look like, where v(t) is the input voltage 
to the motor and O(t) is .the angular position of the telescope platform. The block diagram 
for the motor-driven pointing system is shown in Figure 11.1(b). A feedback system for 
controlling the position of the telescope is illustrated in Figure 11.1 (c), and a block diagram 
equivalent to this system is shown in Figure 11.1(d). The external, or reference, input to 
this feedback system is the desired shaft angle e D· A potentiometer is used to convert the 
angle into a voltage Kl e D proportional toeD· Similarly, a second potentiometer produces a 
voltage K1 O(t) proportional to the actual platform angle. These two voltages are compared, 
producing an error voltage K1 (e v - O(t)), which is amplified and then used to drive the 
electric motor. 
Figure 11.1 suggests two different methods for pointing the telescope. One of these 
is the feedback system of Figures 11.1(c) and (d). Here, the input that we must provide 
is the desired reference angle e D· Alternatively, if the initial angle, the desired angle, and 
the detailed electrical and mechanical characteristics of the motor-shaft assembly were 
known exactly, we could specify the precise history of the input voltage v(t) that would 
first accelerate and then decelerate the shaft, bringing the platf{)rm to a stop at the desired 

v(t) 
...__ ______ ___. Cl:) 9(t) 
90 -
Potentiometer 
v(t)---.,._ 
Input 
voltage 
(a) 
Motor 
(b) 
(c) 
··~ 
K H 
(d) 
I 
I 
1------!·~ 9(t) 
Platform 
angular 
position 
Amplifier 
(gain K2) 
Motor I 
Potentiometer 
• 
9(t) 
Figure 11 .1 
Use of feedback to control the angular position of a telescope: (a) de 
motor-driven telescope platform; (b) block diagram of the system in (a); (c) feedback 
system for pointing the telescope; (d) block diagram of the system in (c) (here, K = 
K1K2). 
817 

818 
Linear Feedback Systems 
Chap. 11 
position without the use of feedback, as in Figures 11.1 (a) and (b). A system operating in 
accordance with Figures 1l.l(a) and (b) is typically referred to as an open-loop system, 
in contrast to the closed-loop system of Figures 11.1(c) and (d). In a practical environ-
ment, there are clear advantages to controlling the motor-shaft angle with the closed-loop 
system rather than with the open-loop system. For example, in the closed-loop system, 
when the shaft has been rotated to the correct position, any disturbance from this position 
will be sensed, and the resulting error will be used to provide a correction. In the open-
loop system, there is no mechanism for providing a correction. As another advantage of 
the closed-loop system, consider the effect of errors in modeling the characteristics of the 
motor-shaft assembly. In the open -loop system, a precise characterization of the system is 
required to design the correct input. In the closed-loop system, the input is simply the de-
sired shaft angle and does not require precise knowledge of the system. This insensitivity 
of the closed-loop system to disturbances and to imprecise knowledge of the system are 
two important advantages of feedback. 
The control of an electric motor is just one of a great many examples in which feed-
back plays an important role. Similar uses of feedback can be found in a wide variety of 
applications, such as chemical process control, automotive fuel systems, household heating 
systems, and aerospace systems, to name just a few. In addition, feedback is also present 
in many biological processes and in the control of human motion. For example, when a 
person reaches for an object, it is usual during the reaching process to monitor visually the 
distance between the hand and the object so that the velocity of the hand can be smoothly 
decreased as the distance (i.e., the error) between the hand and the object decreases. The 
effectiveness of using the system output (hand position) to control the input is clearly 
demonstrated by alternatively reaching with and without the use of visual feedback. 
In addition to its use in providing an error-correcting mechanism that can reduce sen-
sitivity to disturbances and to errors in the modeling of the system that is to be controlled, 
another important characteristic of feedback is its potential for stabilizing a system that is 
inherently unstable. Consider the problem of trying to balance a broomstick in the palm 
of the hand. If the hand is held stationary, small disturbances (such as a slight breeze or 
inadvertent motion Of the hand) will cause the broom to fall over. Of course, if one knows 
exactly what disturbances will occur, and if one can control the motion of the hand per-
fectly, it is possible to determine in advance how to move the hand to balance the broom. 
This is clearly unrealistic; however, by always moving the hand in the direction in which 
the broom is falling, the broom can be balanced. This, of course, requires feedback in 
order to sense the direction in which the broom is falling. A second example that is closely 
related to the balancing of a broom is the problem of controlling a so-called inverted pen-
dulum, which is illustrated in Figure 11.2. As shown, an inverted pendulum consists of a 
thin rod with a weight at the top. The bottom of the rod is mounted on a cart that can move 
in either direction along a track. Again, if the cart is kept stationary, the inverted pendulum 
Figure 11.2 
An inverted pendulum. 

Sec. 11.1 
Linear Feedback Systems 
819 
will topple over. The problem of stabilizing the pendulum is one of designing a feedback 
system that will move the cart to keep the pendulum vertical. This example is examined 
in Problem 11.56. A third example, which again bears some similarity to the balancing of 
a broom, is the problem of ,controlling t},le trajectory of a rocket. In this case, much as the 
movement of the hand is used to compensate for disturbances in the position of the broom, 
the direction of the thrust of the rocket is used to correct for changes in aerodynamic forces 
and wind disturbances that would otherwise cause the rocket to deviate from its course. 
Again, feedback is important, because these forces and disturbances are never precisely 
known in advance. 
The preceding examples provide some indication of why feedback may be useful. 
In the next two sections we introduce the basic block diagrams and equations for linear 
feedback systems and discuss in more detail a number of applications of feedback and 
control, both in continuous time and in discrete time. We also point out how feedback can 
have harmful as well as useful effects. These examples of the uses and effects of feedback 
will give us some insight into how changes in the parameters in a feedback control system 
lead to changes in the behavior of the system. Understanding this relationship is essential in 
designing feedback systems that have certain desirable characteristics. With this material 
as background, we will then develop, in the remaining sections of the chapter, several 
specific techniques that are of significant value in the analysis and design of continuous-
time and discrete-time feedback systems. 
11 . 1 LINEAR FEEDBACK SYSTEMS 
The general configuration of a continuous-time LTI feedback system is shown in Fig-
ure 11.3(a) and that of a discrete-time LTI feedback system in Figure 11.3(b). Because of 
~~ 
x(t) ----..--~ 
e(t) 
+ 
r(t) 
x[n]~ 
e[n] 
+ 
r[n] 
H(s) 
G(s) 
(a) 
H(z) 
G(z) 
(b) 
y(t) 
y[n] 
Figure 11 .3 
Basic feedback system 
configurations in (a) continuous time 
and (b) discrete time. 

820 
Linear Feedback Systems 
Chap. 11 
the typical applications in which feedback is utilized, it is natural to restrict the systems in 
these figures to be causal. This will be our assumption throughout the chapter. In that case, 
the system functions in Figure 11.3 can be interpreted either as unilateral or as bilateral 
transforms, and, as a consequence of causality, the ROC's associated with them will always 
be to the right of the rightmost pole for Laplace transforms and outside the outermost pole 
for z-transforms. 
It should also be noted that the convention used in Figure 11.3(a) is that r(t), the 
signal fed back, is subtracted from the input x(t) to form e(t). The identical convention 
is adopted in discrete time. Historically, this ·convention arose in tracking-system applica-
tions, where x(t) represented a desired command and e(t) represented the error between 
the command and the actual response r(t). This was the case, for example, in our discus-
sion of the pointing of a telescope. In more general feedback systems, e(t) and e[n], the 
discrete-time counterpart of e(t), may not correspond to or be directly interpretable as error 
signals. 
' 
The system function H(s) in Figure 11.3(a) or H(z) in Figure 11.3(b) is referred to 
as the system function of the forward path and G(s) or G(z) as the system function of the 
feedback path. The system function of the overall system of Figure 11.3(a) or (b) is referred 
to as the closed-loop system function and will be denoted by Q(s) or Q(z). In Sections 9.8.1 
and 10.8.1, we derived expressions for the system functions of feedback interconnections 
of LTI systems. Applying these results to the feedback systems of Figure 11.3, we obtain 
Y(s) 
H(s) 
Q(s) = X(s) = 1 + G(s)H(s)' 
(11.1) 
Y(z) 
H(z) 
Q(z) = X(z) = 1 + G(z)H(z) 
(11.2) 
Equations (11.1) and (11.2) represent the fundamental equations for the study of LTI feed-
back systems. In the following sections, we use these equations as the basis for gaining 
insight into the properties of feedback systems and for developing several tools for their 
analysis. 
11.2 SOME APPLICATIONS AND CONSEQUENCES OF FEEDBACK 
In the introduction, we provided a brief, intuitive look at some of the properties and uses 
of feedback systems. In this section, we examine a number of the characteristics and ap-
plications of feedback in somewhat more quantitative terms, using the basic feedback 
equations (11.1) and (11.2) as a starting point. Our purpose is to provide an introduction 
to and an appreciation for the applications of feedback, rather than to develop any of these 
applications in detail. In the sections that follow, we focus in more depth on several specific 
techniques for analyzing feedback systems that are useful in a wide range of problems, 
including many of the applications that we are about to describe. 
11.2.1 Inverse System Design 
In some applications, one would like to synthesize the inverse of a given continuous-time 
system. Suppose that this system has system function P(s), and consider the feedback 
system shown in Figure 11.4. Applying equation (11.1) with H(s) = K and G(s) = P(s), 

Sec. 11 .2 
Some Applications and Consequences of Feedback 
821 
x(t)___;G) 
+ 
K 
y(t) 
P(s) 
we find that the closed-loop system function is 
K 
Q(s) = 1 + KP(s) 
Figure 11 .4 
Form of a feedback 
system used in implementing the in-
verse of the system with system func-
tion P(s). 
(11.3) 
If the gain K is sufficiently large so that K P(s) » 1, then 
1 
Q(s) = P(s)' 
(11.4) 
in which case the feedba,ck system approximates the inverse of the system with system 
function P(s). 
It is important to note that the result in eq. (11.4) requires that the gain K be suffi-
ciently high, but is otherwise not dependent on the precise value of the gain. Operational 
amplifiers are one class of devices that provide this kind of gain and are widely used in 
feedback systems. One common application ofthe inversion inherent in eq. (11.4) is in the 
implementation of integrators. A capacitor has the property that its current is proportional 
to the derivative of the voltage. By inserting a capacitor in the feedback path around an 
operational amplifier, the differentiation property of the capacitor is inverted to provide 
integration. This specific application is explored in more detail in Problems 11.50-11.52. 
Although our discussion is for the most part restricted to linear systems, it is worth 
pointing out that this same basic approach is commonly used in inverting a nonlinearity. 
For example, systems for which the output is the logarithm of the input are commonly im-
plemented by utilizing the exponential current-voltage characteristics of a diode as feed-
back around an operational amplifier. This is explored in more detail in Problem 11.53. 
11.2.2 Compensation for Nonideal Elements 
Another common use of feedback is to correct for some of the nonideal properties of the 
open-loop system. For example, feedback is often used in the design of amplifiers to pro-
vide constant-gain amplification in a given frequency band, and in fact, it is this applica-
tion, pioneered by H. S. Black at Bell Telephone Laboratories in the 1920s, that is generally 
considered to have been the catalyst for the development of feedback control as a practical 
and useful system design methodology. 
· 
Specifically, consider an open -loop frequency response H (jw) which provides am-
plification over the specified frequency band, but which is not constant over that range. 
For example, operational amplifiers or the vacuum tube amplifierE of concern to Black and 
his colleagues typically provide considerable, but not precisely controlled, amplification. 

822 
Linear Feedback Systems 
Chap. 11 
While such devices can provide raw amplification levels of several orders of magnitude, 
the price one pays for this includes uncertain levels of amplification that can fluctuate 
with frequency, time, temperature, etc., and that can also introduce unwanted phase and 
nonlinear distortions. What Black proposed was placing such a powerful, but uncertain and 
erratic, amplifier in a feedback loop as in Figure 11.3(a) with G(s) chosen to be constant, 
i.e., G(s) = K. In this case, assuming the closed-loop system is stable, its frequency response is 
H(jw) 
Q(jw) = 1 + KH(jw)" 
If, over the specified frequency range, 
jKH(jw)j » 1, 
then 
Q(jw) = ~· 
(11.5) 
(11.6) 
(11.7) 
That is, the closed-loop frequency response is constant, as desired. This of course assumes 
that the system in the feedback path can be designed so that its frequency response G(jw) 
has a constant gain Kover the desired frequency band, which is precisely what we assumed 
we could not ensure for H (jw ). The difference between the requirement on H (jw) and that 
on G(jw), however, is that H(jw) must provide amplification, whereas, from eq. (11.7), 
we see that forthe overall closed-loop system to provide a gain greater than unity, K must 
be less than 1. That is, G(jw) must be an attenuator over the specified range of frequencies. 
In general, an attenuator with approximately flat frequency characteristics is considerably 
easier to realize than an amplifier with approximately flat frequency response (since an 
attenuator can be constructed from passive elements). 
The use of feedback to flatten the frequen::y response incurs some cost, however, 
and it is this fact that led to the considerable skepticism with which Black's idea was met. 
In particular, from eqs. (11.6) and (11.7), we see that 
jH(jw)j » ~ = Q(jw), 
(11.8) 
so that the closed-loop gain 11 K will be substantially less than the open -loop gain iH(}w )!. 
This apparently significant loss of gain, attributable to what Black referred to as degen-
erative or negative feedback, was initially viewed as a serious weakness in his negative-
feedback amplifier. Indeed, the effect had been known for many years and had led to 
the conviction that negative feedback was not a particularly useful mechanism. However, 
Black pointed out that what one gave up in overall gain was often more than offset by the 
reduced sensitivity of the overall closed-loop amplifier: The closed-loop system function 
is essentially equal to eq. (11.7), independently of variations in H(jw ), as long as jH(jw )j 
is large enough. Thus, if the open-loop amplifier is initially designed with considerably 
more gain than is actually needed, the closed-loop amplifier will provide the desired lev-
els of amplification with greatly reduced sensitivity. This concept and its application to 
extending the bandwidth of an amplifier are explored in Problem 11.49. 

Sec. 11.2 
Some Applications and Consequences of Feedback 
823 
11.2.3 Stabilization of Unstable Systems 
As mentioned in the introduction, one use of feedback systems is to stabilize systems that, 
without feedback, are unstable. Examples of this kind of application include the control of 
the trajectory of a rocket, the regulation of nuclear reactions in a nuclear power plant, the 
stabilization of an aircraft, and the natural and regulatory control of animal populations. 
To illustrate how feedback can be used to stabilize an unstable system, let us consider 
a simple first-order continuous-time system with 
b 
H(s) = --. 
s - a 
(11.9) 
With a > 0, the system is unstable. Choosing the system function G(s) to be a constant 
gain K, we see that the closed-loop system function in eq. (11.1) becomes 
H(s) 
Q(s) = 1 + KH(s) 
b 
s-a+Kb' 
(11.10) 
The closed-loop system will be stable if the pole is moved into the left half of the s-plane. 
This will be the case if 
Kb>a. 
(11.11) 
Thus, we can stabilize the system with a constant gain in the feedback loop if that gain is 
chosen to satisfy eq. (11.11). This type offeedback system is referred to as a proportional 
feedback system, since the signal that is fed back is proportional to the output of the system. 
As another example, consider the second-order system 
b 
H(s) = -
- . 
s2 +a 
(11.12) 
If a > 0, the system is an oscillator (i.e., H(s) has its poles on the jw-axis), and the impulse 
response of the system is sinusoidal. If a < 0, H(s) has one pole in the left-half plane 
and one in the right-half plane. Thus, in either case, the system is unstable. In fact, as 
considered in Problem 11.56, the system function given in eq. (11.12) with a< 0 can be 
used to model the dynamics of the inverted pendulum described in the introduction. 
Let us first consider the use of proportional feedback for this second-order system; 
that is, we take 
G(s) = K. 
(11.13) 
Substituting into eq. (11.1), we obtain 
b 
Q(s) = s2 +(a+ Kb)' 
(11.14) 

824 
Linear Feedback Systems 
Chap. 11 
In our discussion of second-order systems in Chapter 6, we considered a transfer function 
of the form 
s2 + 2(wns + w~· 
(11.15) 
For such a system to be stable, Wn must be real and positive (i.e., w~ > 0), and ( must 
be positive (corresponding to positive damping). From eqs. (11.14) and (11.15), it follows 
that with proportional feedback we can only influence the value of w~, and consequently, 
we cannot stabilize the system because we cannot introduce any damping. To suggest a 
type of feedback that can be used to stabilize this system, recall the mass-spring-dashpot 
mechanical system described in our examination of second-order systems in Section 6.5.2. 
We saw that damping in that system was the result of the inclusion of a dashpot, which 
provided a restoring force proportional to the velocity of the mass. This suggests that we 
consider proportional-plus-derivative feedback, that is, a G(s) of the form 
(11.16) 
which yields 
b 
Q(s) = s2 + bK2s +(a+ K1b)" 
(11.17) 
The closed-loop poles will be in the left-half plane, and hence, the closed-loop system will 
be stable as long as we choose K1 and K 2 to guarantee that 
(11.18) 
The preceding discussion illustrates how feedback can be used to stabilize contin-
uous-time systems. The stabilization of unstable systems is an important application of 
feedback for discrete-time systems .as well. Examples of discrete-time systems that are 
unstable in the absence of feedback are models of population growth. To illustrate how 
feedback can prevent the unimpeded growth of populations, let us consider a simple model 
for the evolution of the population of a single species of animal. Let y[ n] denote the number 
of animals in the nth generation, and assume that without the presence of any impeding 
influences, the birthrate is such that the population would.double each generation. In this 
case, the basic equation for the population dynamics of the species is 
y[n] = 2y[n - 1] + e[n], 
(11.19) 
where e[n] represents any additions to or deletions from the population that are caused by 
external influences. 
This population model is obviously unstable, with an impulse response that grows 
exponentially. However, in any ecological system, there are a number of factors that will 
inhibit the growth of a population. For example, limits on the food supply for the species 
will manifest themselves through a reduction in population growth when the number of 
animals becomes large. Similarly, if the species has natural enemies, it is often reasonable 
to assume that the population of the predators will grow when the population of the prey 
increases and, consequently, that the presence of natural enemies will· retard population 
growth. In addition to natural influences such as these, there may be effects introduced by 

x[n] 
+ + 
Sec. 11.2 
Some Applications and Consequences of Feedback 
825 
humans that are aimed at population control. For example, the food supply or the predator 
population may fall under human regulation. In addition, stocking lakes with fish or im-
porting animals from other areas can be used to promote growth, and the control of hunting 
or fishing can also provide a regulative effect. Because all of these influences depend on 
the size of the population (either naturally or by design), they represent feedback effects. 
Based on the preceding discussion, we can separate e[n] into two parts by means of 
the equation 
e[n] = x[n] - r[n], 
(11.20) 
where r[n] represents the effect of the regulative influences described in the previous para-
graph and x[n] incorporates any other external effects, such as the migration of animals 
or natural disasters or disease. Note that we have included a minus sign in eq. (11.20). 
This is consistent with our convention of using negative feedback, and here it also has the 
physical interpretation that, since the uninhibited growth of the population is unstable, the 
feedback term plays the role of a retarding influence. To see how the population can be 
controlled by the presence of this feedback term, suppose that the regulative influences ac-
. count for the depletion of a fixed proportion f3 of the population in each generation. Since, 
according to our model, the surviving fraction of each generation will double in size, it 
follows that 
y[n] = 2(1 - f3)y[n- 1] + x[n]. 
Comparing eq. (11.21) with eqs. (11.19) and (11.20), we see that 
r[n] = 2{3 y[n - 1]. 
(11.21) 
(11.22) 
The factor of 2 here represents the fact that the depletion of the present population de-
creases the number of births in the next generation. 
This example of the use of feedback is illustrated in'Figure 11.5. Here, the system 
function of the forward path is obtained from eq. (11.19) as 
-
1 
H(z) = 1 - 2z- l ' 
while from eq. (11.22) the system function of the feedback path is 
G(z) = 2{3z- 1• 
e[n] 
1 
- -
1- 2z - 1 
y[n] 
(11.23) 
(11.24) 
213y[n -1] 
213z - 1 
Figure 1 1.5 
Block diagram of a 
simple feedback model of population 
dynamics. 

826 
Consequently, the closed-loop system function is 
H(z) 
Q(z) = 1 + G(z)H(z) 
Linear Feedback Systems 
Chap. 11 
1 
(11.25) 
1- 2(1- 13)z- 1• 
If 13 < 112, the closed-loop system is still unstable, whereas it is stable 1 if 112 < f3. < 3/2. 
Clearly, this example of population growth and control is extremely simplified. For 
instance, the feedback model of eq. (11.22) does not account for the fact that the part of 
r[n] which is due to the presence of natural enemies depends upon the population of the 
predators, which in tum has its own growth dynamics. Such effects can be incorporated 
by making the feedback model more complex to reflect the presence of other dynamics 
in an ecological system, and the resulting models for the evolution of interacting species 
are extremely important in ecological studies. However, even without the incorporation 
of these effects, the simple model that we have described here does illustrate the basic 
ideas of how feedback can prevent both the unlimited proliferation of a species and its 
extinction. In particular, we can see at an elementary level how human -induced factors 
can be used. For example, if a natural disaster or an increase in the population of natural 
enemies causes a drastic decrease in the population of a species, a tightening of limits 
on hunting or fishing and accelerated efforts to increase the population can be used to 
decrease 13 in order to destabilize the system to allow for rapid growth, until a normal-size 
population is again attained. 
Note also that for this type of problem, it is not usually the case that one wants 
strict stability. If the reguiating influences are such that 13 = 112, and if all other external 
influences are zero (i.e., if x[n] = 0), then y[n] = y[n - 1]. Therefore, as long as x[n] is 
small and averages to zero over several generations, a value of 13 = 112 will result in an 
essentially constant population. However, for this value of 13 the system is unstable, since 
eq. (11.21) then reduces to 
y[n] = y[n- 1] + x [n]. 
(11.26) 
That is, the system is equivalent to an accumulator. Thus, if x[n] is a unit step, the output 
grows without bound. Consequently, if a steady trend is expected in x[n], caused, for 
example, by a migration of animals into a region, a value of 13 > 112 would need to be 
used to stabilize the system and thus to keep the population within bounds and maintain 
an ecological balance. 
11.2.4 Sampled-Data Feedback Systems 
In addition to dealing with problems such as the one just described, discrete-time feedback 
techniques are of great importance in a wide variety of applications involving continuous-
time systems. The flexibility of digital systems has made the implementation of sampled-
data feedback systems an extremely attractive option. In such a system, the output of a 
continuous-time system is sampled, some processing is done on the resulting sequence 
of samples, and a discrete sequence of feedback commands is generated. This sequence 
1 Although, in the context of our population example, {3 could never exceed unity, since {3 > 1 corre-
sponds to removing more than 100% of the population. 

Sec. 11.2 
Some Applications and Consequences of Feedback 
827 
is then converted to a continuous-time signal that is fed back to and subtracted from the 
external input to produce the actual input to the continuous-time system. 
Clearly, the constraint of causality on feedback systems imposes a restriction on the 
process of converting the discrete-time feedback signal to a continuous-time signal (e.g., 
ideal lowpass filtering or any noncausal approximation of it is not allowed). One of the 
most widely used conversion systems is the zero-order hold (introduced in Section 7 .1.2). 
The structure of a sampled-data feedback system involving a zero-order hold is depicted in 
Figure 11.6(a). In the figure, we have a continuous-time LTI system with system function 
H(s) that is sampled to produce a discrete-time sequence 
p[n] = y(nT). 
(11.27) 
The sequence p[n] is then processed by a discrete-time LTI system with system 
function G(z), and the resulting output is put through a zero-order hold to produce the 
continuous-time signal 
z(t) = d[n] 
for 
nT ::5 t < (li + l)T. 
(11.28) 
This signal is subtracted from the external input x(t) to produce e(t). 
x(t) 
+ 
e(t) 
+ 
H(s) 
,t 
y(t) 
Zero-order 
Ideal C/D 
hold 
~ p[n] 
G(z) 
(a) 
F(z) 
l-e..;.(n..;.J...,: ~ 
Zero-order 
hold 
Ideal C/D 
1--+------,~~ p[n] 
I 
1-- - ----- ------- --- -------------- - J 

828 
Linear Feedback Systems 
Chap. 11 
Suppose also that x(t) is constant over intervals of length T. That is, 
x(t) = r[n] 
for 
nT :5 t < (n + 1)T, 
(11.29) 
where r[n] is a discrete-time sequence. This is an approximation that is usually valid in 
practice, as the sampling rate is typically fast enough so that x(t) does not change appre-
ciably over intervals of length T. Furthermore, in many applications, the external input is 
itself actually generated by applying a zero-order hold operation to a discrete sequence. 
For example, in systems such as advanced aircraft, the external inputs represent human 
operator commands that are themselves first processed digitally and then converted back 
to continuous-time input signals. Because the zero-order hold is a linear operation, the 
feedback system of Figure 11.6(a) when x(t) is given by eq. (11.29) is equivalent to the 
system of Figure 11.6(b). 
As shown in Problem 11.60, the discrete-time system with input e[n] and output 
p[n] is an LTI system with system function F(z) that is related to the continuous-time 
system function H(s) by means of a step-invariant transformation. That is, if s(t) is the 
step response of the continuous-time system, then the step response q[n] of the discrete-
time system consists of equally spaced samples of s(t). Mathematically, 
q[n] = s(nT) 
for all n. 
(11.30) 
Once we have determined F(z), we have a completely discrete-time feedback system 
model (Figure 11.6(b)) exactly capturing the behavior of the continuous-time feedback 
system (Figure 11.6(a)) at the sampling instants t = nT, and we can then consider de-
signing the feedback system function G(z) to achieve our desired objectives. An example 
of designing such a sampled-data feedback system to stabilize an unstable continuous-time 
system is examined in detail in Problem 11.60. 
11.2.5 Tracking Systems 
As mentioned in Section 11.0, one of the important applications of feedback is in the 
design of systems in which the objective is to have the output track or follow the input. 
There is a broad range of problems in which tracking is an important component. For 
example, the telescope-pointing problem discussed in Section 11.0 is a tracking problem: 
The feedback system of Figures 11.1 (c) and (d) has as its input the desired pointing angle, 
and the purpose of the feedback loop is to provide a mechanism for driving the telescope 
to follow the input. In airplane autopilots the input is the desired flight path of the vehicle, 
and the autopilot feedback system uses the aircraft control surfaces (rudder, ailerons, and 
elevator) and thrust control in order to keep the aircraft on the prescribed course. 
To illustrate some of the issues that arise in the design of tracking systems, con-
sider the discrete-time feedback system depicted in Figure 11.7(a). The examination of 
discrete-time tracking systems of this form often arises in analyzing the characteristics of 
sampled-data tracking systems for continuous-time applications. One example of such a 
system is a digital autopilot. In Figure 11.7(a), Hp(Z) denotes the system function of the 
system whose output is to be controlled. This system is often referred to as the plant, a term 
that can be traced to applications such as the control of power plants, heating systems, and 
chemical-processing plants. The system function Hc(z) represents a compensator, which 
is the element to be designed. Here, the input to the compensator is the tracking error-

x[n] 
x[n) 
Sec. 11.2 
Some Applications and Consequences of Feedback 
829 
(a) 
(b) 
1---~,_._......,.._y(n] 
Figure 11.7 
(a) Discrete-time 
tracking system; (b) tracking sys-
d[n] 
tern of (a) with a disturbance d[n] in 
the feedback path accounting for the 
presence of measurement errors. 
that is, the difference e[n] between the input x[n] and the output y[n]. The output of the 
compensator is the input to the plant (for example, the actual voltage applied to the motor 
in the feedback system of Figures 11.1 (c) and (d) or the actual physical input to the drive 
system of the rudder of an aircraft). 
To simplify notation, let H(z) = H c(z)H p(z). In this case, the application of eq. (11.2) 
yields the relationship 
H(z) 
Y(z) = 1 + H(z) X(z). 
(11.31) 
Also, since Y(z) = H(z)E(z), it follows that 
1 
E(z) = 1 + H(z)X(z), 
(11.32) 
or, specializing to z = ejw, we obtain 
E(ejw) = 1 + ~(ejw)X(ejw). 
(11.33) 
Equation (11.33) provides us with some insight into the design of tracking systems. Specif-
ically, for good tracking performance, we would like e[n] or, equivalently, E(ejw) to be 
small. That is, 
1 
X( jw)- 0 
1 + H(ejw) 
e 
-
· 
(11.34) 
Consequently, for that range of frequencies for which X(ejw) is nonzero, we would like 
IH(ejw)l to be large. Thus, we have one of the fundamental principles of feedback system 
design: Good tracking performance requires a large gain. This desire for a large gain, 
however, must typically be tempered, for several reasons. One reason is that if the gain 
is too large, the closed-loop system may have undesirable characteristics (such as too little 

830 
Linear Feedback Systems 
Chap. 11 
damping) or might in fact become unstable. This possibility is discussed in the next section 
and is also addressed by the methods developed in subsequent sections. 
In addition to the issue of stability, there are other reasons for wanting to limit the gain 
in a tracking system. For example, in implementing such a system, we must measure the 
output y[n] in order to compare it to the command input x[n], and any measuring device 
used will have inaccuracies and error sources (such as thermal noise in the electronics 
of the device). In Figure 11.7(b), we have included these error sources in the form of a 
disturbance input d[n] in the feedback loop. Some simple system function algebra yields 
the following relationship between Y(z) and the transforms X(z) and D(z) of x[n] and d[n]: 
[ 
H(z) 
J [ H(z) 
J 
Y(z) = 
1 + H(z) X(z) -
1 + H(z) D(z) . 
(11.35) 
From this expression, we see that in order to minimize the influence of d[n] on y[n], we 
would like H(z) to be small so that the second term on the right-hand side of eq. (11.35) 
is small. 
From the preceding development, we see that the goals of tracking and of minimiz-
ing the effect of measurement errors are conflicting, and one must take this into account in 
coming up with an acceptable system design. In general, the design depends on more de-
tailed information concerning the characteristics ofthe input x[n] and the disturbance d[n]. 
For example, in many applications x[ n] has a significant amount of its energy concentrated 
at low frequencies, while measurement error sources such as thermal noise have a great 
deal of energy at high frequencies. Consequently, one usually designs the compensator 
Hc(z) so that IH(e jw )l is large at low frequencies and is small for w near ±7T. 
There are a variety of other issues that one must consider in designing tracking sys-
tems, such as the presence of disturbances at other points in the feedback loop. (For exam-
ple, the effect of wind on the motion of an aircraft must be taken into account in designing 
an autopilot.) The methods of feedback system analysis introduced in this chapter provide 
the necessary tools for examining each of these issues. In Problem 11.57, we use some 
of these tools to investigate several other aspects of the problem of designing tracking 
systems. 
11.2.6 Destabilization Caused by Feedback 
As well as having many applications, feedback can have undesirable effects and can in 
fact cause instability. For example, consider the telescope-pointing system illustrated in 
Figure 11.1. From the discussion in the preceding section, we know that it would be de-
sirable to have a large amplifier gain in order to achieve good performance in tracking the 
desired pointing angle. On the other hand, as we increase the gain, we are likely to obtain 
faster tracking response at the expense of a reduction in system damping, resulting in sig-
nificant overshoot and ringing in response to changes in the desired angle. Furthermore, 
instability can result if the gain is increased too much. 
Another common example of the possible destabilizing effect of feedback is feed-
back in audio systems. Consider the situation depicted in Figure 11.8(a). Here, a loud-
speaker produces an audio signal that is an amplified version of the sounds picked up by a 
microphone. Note that in addition to other audio inputs, the sound coming from the speaker 
itself may be sensed by the microphone. How strong this particular signal is depends upon 

Amplifier 
External 
audio 
inputs 
Sec. 11.2 
Some Applications and Consequences of Feedback 
Total audio 
input to the 
(a) 
Speaker 
Microphone 
}--m_i_cr_o;...ph_o_n_e--1 
1-----.-...... ~ Speaker 
K1 
output 
+ 
(b) 
831 
External1 
~ 
audro 
+ .f---------1 K1 1----.-....,.ll~ Speaker 
inputs 
r-
O"tP"' 
~--------II - K2e-sr 1 ..... •~-----~ 
Figure 11 .8 
(a) Pictorial repre-
sentation of the phenomenon of audio 
feedback; (b) block diagram represen-
tation of (a); (c) block diagram in (b) 
redrawn as a negative feedback sys-
tem. (Note: e- sr is the system function 
of a T-second time delay.) 
(c) 
the distance between the speaker and the microphone. Specifically, because of the attenu-
ating properties of air, the strength of the signal reaching the microphone from the speaker 
decreases as the distance between the speaker and the microphone increases. In addition, 
due to the finite speed of propagation of sound waves, there is time delay between the 
signal produced by the speaker and that sensed by the microphone. 
This audio feedback system is represented in block diagram form in Figure 11.8(b ). 
Here, the constant K2 in the feedback path represents the attenuation, and Tis the prop-
agation delay. The constant K1 is the amplifier gain. Also, note that the output from the 
feedback path is added to the external input. This is an example of positive feedback. As 
discussed at the beginning of the section, the use of a negative sign in the definition of 
the basic feedback system of Figure 11.3 is purely conventional, and positive and nega-
tive feedback systems can be analyzed using the same tools. For example, as illustrated in 
Figure 11. 8( c), the feedback system of Figure 11.8(b) can be written as a negative feedback 

832 
Linear Feedback Systems 
Chap. 11 
system by adding a minus sign to the feedback-path system function. From this figure and 
from eq. (11.1), we can determine the closed-loop system function: 
Q(s) = 
K1 
. 
1 - K1K2e- sT 
(11.36) 
Later we will return to this example, and, .using a technique that we will develop in 
Section 11.3, we will show that the system of Figure 11.8 is unstable if 
(11.37) 
Since the attenuation due to the propagation of sound through the air decreases (i.e., K2 
increases) as the distance between the speaker and the microphone decreases, if the mi-
crophone is placed too close to the speaker, so that eq. (11.37) is satisfied, the system will 
be unstable. The result of this instability is an excessive amplification and distortion of 
audio signals. 
It is interesting to note that positive, or what Black referred to as regenerative, feed-
back had also been known for some time before he invented his negative feedback am-
plifier and, ironically, had been viewed as a very useful mechanism (in contrast to the 
skeptical view of negative feedback). Indeed, positive feedback can be useful. For exam-
ple, it was already known in the 1920s that the destabilizing influence of positive feedback 
could be used to generate oscillating signals. This use of positive feedback is illustrated in 
Problem 11.54. 
In this section, we have described a number of the applications of feedback. These 
and others, such as the use of feedback in the implementation of recursive discrete-time 
filters (see Problem 11.55), are considered in more detail in the problems at the end of the 
chapter. From our examination of the uses of feedback and the possible stabilizing and 
destabilizing effects that it can have, it is clear that some care must be taken in designing 
and analyzing feedback systems to ensure that the closed-loop system behaves in a desir-
able fashion. Specifically, in Sections 11.2.3 and 11.2.6, we have seen several examples 
of feedback systems in which the characteristics of the closed-loop system can be signif-
icantly altered by changing the values of one or two parameters in the feedback system. 
In the remaining sections of this chapter, we develop several techniques for analyzing the 
effect of changes in such parameters on the closed-loop system and for designing systems 
to meet desired objectives such as stability, adequate damping, etc. 
11 .3 ROOT-LOCUS ANALYSIS OF LINEAR FEEDBACK SYSTEMS 
As we have seen in a number of the examples and applications we have discussed, a 
useful type of feedback system is that in which the system has an adjustable gain K as-
sociated with it. As this gain is varied, it is of interest to examine how the poles of the 
closed-loop system change, since the locations of these poles tell us a great deal about the 
behavior of the system. For example, in stabilizing an unstable system, the adjustable gain 
is used to move the poles into the left-half plane for a continuous-time system or inside 
the unit circle for a discrete-time system. In addition, in Problem 11.49, we show that 
feedback can be used to broaden the bandwidth of a first-order system by moving the pole 
so as to decrease the time constant of the system. Furthermore, just as feedback can be used 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
833 
to relocate the poles to improve system performance, as we saw in Section 11.2.6, there 
is the potential danger that with an improper choice of feedback a stable system can be 
destabilized, which is usually undesirable. 
In this section, we discuss a particular method for examining the locus (i.e., the path) 
in the complex plane of the poles of the closed-loop system as an adjustable gain is varied. 
The procedure, referred to as the root-locus method, is a graphical technique for plotting 
the closed-loop poles of a rational system function Q(s) or Q(z) as a function of the value 
of the gain. The technique works in an identical manner for both continuous-time and 
discrete-time systems. 
11 .3. 1 An Introductory Example 
To illustrate the basic nature of the root-locus method for analyzing a feedback system, let 
us reexamine the discrete-time example considered in the preceding section and specified 
by the system functions 
[eq. (11.23)] 
and 
[eq. (11.24)] 
z 
1 
H(z) = 1- 2z-I - --
z - 2 
G(z) = 2{3z- 1 = 213 , 
z 
(11.38) 
(11.39) 
where {3 now is viewed as an adjustable gain. Then, as we noted earlier, the closed-loop 
system function is 
[eq. (11.25)] 
1 
Q(z) = 1- 2(1- {3)z- 1 
z 
(11.40) 
z - 2(1 - {3)' 
In this example, it is straightforward to identify the closed-loop pole as being located at 
z = 2(1- {3). In Figure 11.9(a), we have plotted the locus of the pole for the system as {3 
varies from 0 to + oo. In part (b) of the figure, we have plotted the locus as {3 varies from 0 
to -oo. In each plot, we have indicated the point z = 2, which is the open-loop pole [i.e., 
it is the pole of Q(z) for {3 = 0]. As {3 increases from 0, the pole moves to the left of the 
point z = 2 along the real axis, and we have indicated this by including an arrow on the 
thick line to show how the pole changes as {3 is increased. Similarly, for {3 < 0, the pole of 
Q(z) moves to the right of z = 2, and the direction of the arrow in Figure 11.9(b) indicates 
how the pole changes as the magnitude of {3 increases. For 112 < {3 < 3/2, the pole lies 
inside the unit circle, and thus, the system is stable. 
As a second example, consider a continuous-time feedback system with 
and 
s 
H(s) = -
-
s-2 
2{3 
G(s) = -, 
s 
(11.41) 
(11.42) 
where {3 again represents the adjustable gain. Since H(s) and G(s) in this example are 
algebraically identical to H(z) and G(z), respectively, in the preceding example, the same 

834 
J3>0 
Unit circle 
'- -,/ 
/ 
I 
,' 
I 
I 
' 
(a) 
2 
Unit circle 
'
- -,/ 
/ 
' 
1/ 
I 
' 
(b) 
I 
/ 
2 
will be true for the closed-loop system function 
Linear Feedback Systems 
Chap. 11 
Figure 11 . 9 
Root locus for the 
closed-loop system of eq. (11.40) as 
the value of {3 is varied: (a) {3 > 0; 
(b) {3 < 0. Note that we have marked 
the point z = 2 that corresponds to 
the pole location when {3 = 0. 
s 
Q(s) = s - 2(1 - {3) 
(11.43) 
vis-a-vis Q(z), and the locus of the pole as a function of {3 will be identical to the locus in 
that example. 
The relationship between these two examples stresses the fact that the locus of 
the poles is determined by the algebraic expressions for the system functions of the for-
ward and feedback paths and is not inherently associated with whether the system is a 
continuous-time or discrete-time system. However, the interpretation of the result is inti-
mately connected with its continuous-time or discrete-time context. In the discrete-time 
case it is the location of the poles in relation to the unit circle that is important, whereas 
in the continuous-time case it is their location in relation to the imaginary axis. Thus, 
as we have seen for the discrete-time example in eq. (11.40), the system is stable for 
112 < {3 < 3/2, while the continuous-time system of eq. (11.43) is stable for {3 > 1. 
11.3.2 Equation for the Closed-Loop Poles 
In the simple example considered in the previous section the root locus was easy to plot, 
since we could first explicitly determine the closed-loop pole as a function of the gain 
parameter and then plot the location of the pole as we changed the gain. For more complex 

x(t) 
Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
835 
systems, one cannot expect to find such simple closed-form expressions for the closed-loop 
poles. However, it is still possible to sketch accurately the locus of the poles as the value 
of the gain parameter is varied from -oo to +oo, without actually solving for the location of 
the poles for any specific value of the gain. This technique for determining the root locus is 
extremely useful in gaining insight into the characteristics of a feedback system. Also, as 
we develop the method, we will see that once we have determined the root locus, there is a 
relatively straightforward procedure for determining the value of the gain parameter that 
produces a closed-loop pole at any specified location along the root locus. We will phrase 
our discussion in terms of the Laplace transform variables, with the understanding that it 
applies equally well to the discrete-time case. 
Consider a modification of the basic feedback system of Figure 11.3( a), where either 
G(s) or H(s) is cascaded with an adjustable gainK. This is illustrated in Figure 11.10. In ei-
ther of these cases, the denominator of the closed-loop system function is 1 + KG(s)H(s).2 
Therefore, the equation for the poles of the closed-loop system are the solutions of the 
equation 
1 + KG(s)H(s) = 0. 
(11.44) 
+ 
f--+-
+ 
K 
H(s) 
y(t) 
-
G(s) 
_ 
KH(s) 
Q(s) - 1 + KH(s)G(s) 
(a) 
x(t) --..,:~8 
+ 
• H(s) 
y(t) 
-
K f+-
G(s) 
_ 
H(s) 
Q(s)- 1 + KH(s)G(s) 
(b) 
~ 
Figure 11 . 1 o Feedback systems 
containing an adjustable gain: (a) sys-
tem in which the gain is located in the 
forward path; (b) system with the gain 
in the feedback path. 
2In the following discussion, we assume for simplicity that there is no pole-zero cancellation in the 
product G(s)H(s). The presence of such pole-zero cancellations does not cause any real difficulties, and the 
procedure we will outline here is easily extended to that case (Problem 11.32). In fact, the simple example at 
the start of this section [eqs. (ll.41) and (11.42)] does involve a pole-zero cancellation, at s = 0. 

836 
Linear Feedback Systems 
Chap. 11 
Rewriting eq. (11.44), we obtain the basic equation determining the closed-loop poles: 
1 
G(s)H(s) = - K' 
(11.45) 
The technique for plotting the root locus is based on the properties of this equation and its 
solutions. In the remainder of this section, we will discuss some of these properties and 
indicate how they can be exploited in determining the root locus. 
11.3.3 The End Points of the Root Locus: The Closed-Loop 
Poles for-K = 0 and IKI = +ao 
Perhaps the most immediate observation that one can make about the root locus is that 
obtained by examining eq. (11.45) forK = 0 and IKI = oo. ForK = 0, the solution of 
this equation must yield the poles of G(s)H(s), since 1/K = oo. To illustrate, recall the 
example given by eqs. (11.41) and (11.42). If we let f3 play the role of K, we see that 
eq. (11.45) becomes 
2 
s - 2 
1 
f3' 
(11.46) 
Therefore, for f3 = 0, the pole of the system will be located at the pole of 2/(s- 2) (i.e., 
at s = 2), which agrees with what we depicted in Figure 11.9. 
Suppose now that IKI = oo. Then 1/K = 0, so that the solutions of eq. (11.45) must 
approach the zeros of G(s)H(s). If the order of the numerator of G(s)H(s) is smaller than 
that of the denominator, then some of these zeros, equal in number to the difference in 
order between the denominator and numerator, will be at infinity. 
Referring again to eq. (11.46), since the order of the denominator of 2/(s - 2) is 1, 
while the order of the numerator is zero, we conclude that in this example there is one 
zero at infinity and no zeros in the finite s-plane. Thus, as l/31 __.,. oo, the closed-loop pole 
approaches infinity. Again, this agrees with Figure 11.9, in which the magnitude· of the 
pole increases without bound as l/31 __.,. oo for either f3 > 0 or f3 < 0. 
-While the foregoing observations provide us with basic information as to the closed-
loop pole locations for the extreme values of K, the following result is the key to our being 
able to plot the root locus without actually solving for the closed-loop poles as explicit 
functions of the gain. 
11 .3.4 The Angle Criterion 
Consider again eq. (11.45). Since the right-hand side of this equation is real, a point s0 
can be a closed-loop pole only if the left-hand side of the equation, i.e., G(so)H(so), is also 
real. Writing 
G(so)H(so) = JG(so)H(so)J ef1:G(so)H(so), 
we see that, for G(so)H(so) to be real, it must be true that 
ef1:G(so)H(so) = ± 1. 
(11.47) 
(11.48) 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
837 
That is, for so to be a closed-loop pole, we must have 
<r..G (so) H (so) = integer multiple of 7T. 
(11.49) 
Returning to eq. (11.46), we see immediately that in order for 2/(so- 2) to be real, 
it is necessary that so be real. For more complex system functions, it is not as easy to 
determine the values of so for which G (so) H (so) is real. However, as we will see, the use 
of the angle criterion given by eq. (11.49), together with the geometric method described 
in Chapter 9 for evaluating <r..G (so) H (so), greatly facilitates the determination of the 
root locus. 
The angle criterion given by eq. (11.49) provides us with a direct method for deter-
mining whether a point so could be a closed-loop pole for some value of the gain K. A 
further examination of eq. (11.45) gives us a way in which to calculate the value of the 
gain corresponding to any point on the root locus. Specifically, suppose that s0 satisfies 
<r..G (so) H (so) = odd multiple of 7T. 
(11.50) 
Then ei -t.G(so)H(so) = .-1, and from eq. (11.47) we see that 
G (so) H (so) = - IG (so) H (so)j . 
(11.51) 
Substituting eq. (11.51) into eq. (11.45), we find that if 
K = 
1 
IG(so)H (so)j' 
(11.52) 
then so is a solution of the equation and hence a closed-loop pole. 
Similarly, if so satisfies the condition 
<r..G (so) H (so) = even multiple of 7T, 
(11.53) 
then 
G (so) H (so) = jG (so) H (so) I. 
(11.54) 
Thus, if 
K = - .----1-----. 
IG (so) H (so)l' 
(11.55) 
then so is a solution of eq. (11.45) and hence a closed-loop pole. 
For the example given in eq. (11.46), if so is on the real line and so < 2, then 
4:,(-2 )= -TT, 
so - 2 
and from eq. (11.52), the value of f3 for which so is the closed-loop pole is 
1 
= 2- so 
f3 = -
2 -
2 
ls0-21 
(11.56) 
(11.57) 

838 
Linear Feedback Systems 
Chap. 11 
That is, 
so = 2(1 - {3), 
(11.58) 
which agrees with eq. (11.43). 
Summarizing the last two observations that we have made, we see that the root locus 
for the closed-loop system, that is, the set of points in the complex s-plane that are closed-
loop poles for some value of K asK varies from - oo to +oo, are precisely those points that 
satisfy the angle condition of eq. (11.49). Furthermore: 
1. A point so for which 
1:G (so) H (so) = odd multiple of 7T 
(11.59) 
is on the root locus and is a closed-loop pole for some value of K > 0. The value of 
the gain that makes s0 a closed-loop pole is given by eq. (11.52). 
2. A point so for which 
1:G (so) H (so) = even multiple of 7T 
(11.60) 
is on the root locus and is a closed-loop pole for some value of K < 0. The value of 
the gain that makes so a closed-loop pole is given by eq. (11.55). 
Therefore, we have now reduced the problem of determining the root locus to that of 
searching for points that satisfy the angle requirements given by eqs. (11.59) and (11.60). 
These equations can be refined further to a set of properties that aid in sketching the root 
locus. Before discussing these properties, however, let us consider a simple example. 
Example 11 . 1 
Let 
1 
H(s) = --
s + 1' 
1 
G(s) = --. 
s+2 
(11.61) 
Recall that in Section 9.4 we discussed the geometric evaluation of Laplace transforms. 
In that section, we saw that the angle of the rational Laplace transform 
k = l 
(11.62) 
II 
Il<s-ak) 
k = l 
evaluated at some point s0 in the complex plane equals the sum of the angles of the 
vectors from each of the zeros to s0 minus the sum of the angles from each of the poles 
to s0• Applying this to the product of G(s)H(s), where G(s) and H(s) are as given in 
eq. (11.61), we can determine geometrically those points in the s-plane that satisfy the 
angle criteria, eqs. (11.59) and (11.60), and therefore can sketch the root locus. 
In Figure 11.11, we have plotted the poles of G(s)H(s) and have denoted by() and 
<P the angles from each of the poles to the point s0 . Let us first test the angle criterion 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
839 
Figure 11.11 
Geometric procedure for evaluating angle criterion in Exam-
ple 11.1. 
for points s0 on the real axis. To begin with, the angle contribution from both poles is 
zero when s0 is on the real axis to the right of - 1. Thus, 
<J.G (so) H (so) = 0 = 0 · 1T, 
s0 real and greater than -1, 
(11.63) 
and by eq. (11.60), these points are on the root locus forK < 0. For points between the 
two poles, the pole at -1 contributes an angle of - 7T, and the pole at - 2 contributes 0. 
Thus, 
<J.G (so) H (so) = -1T, 
so real, - 2 < so < - 1. 
(11.64) 
These points are on the locus for K > 0. Finally, each pole contributes an angle of - 7r 
wl;len s0 is real and less than - 2, so that 
<J.G (so) H (so) = -27T, 
s0 real and less than -2. 
Therefore, these points are on the locus for K < 0. 
Let us now examine points in the upper half of the s-plane. (Since the impulse 
responses are real-valued, the complex poles occur in conjugate pairs. Therefore, we 
can immediately determine the poles in the lower half-plane after we have examined the 
upper half.) From Figure 11.11, the angle of G (so) H (so) at the point so is 
<J.G(so)H(so) = 
-(0+~). 
(11.65) 
Also, it is clear that as s0 ranges over the upper half-plane (but not the real axis), we have 
o < o < 1T, 
0 < ~ < 1T. 
(11.66) 
Thus, 
-27T < <J.G(s)H(s) < 0, 
(11.67) 
Therefore, we see immediately that no point in the upper half-plane can be on the locus 
forK < 0 [since <J.G(s)H(s) never equals an even multiple of 7T]. In addition, if s0 is to 
be on the locus for K > 0, we must have 
<J.G(so)H(so) = -(0+~) = -
1T, 
(11.68) 

840 
Linear Feedback Systems 
Chap. 11 
or 
(J = 71" -
,P. 
(11.69) 
Examining the geometry of Figure 11.11, we see that this occurs only for those points 
located on the straight line that is parallel to the imaginary axis and that bisects the line 
joining the poles at -1 and - 2. We have now examined the entire s-plane and have 
determined all those points on the root locus. In addition, we know that for K = 0, the 
closed-loop poles equal the poles of G(s)H(s), and as IKI -+ oo, the closed-loop poles 
go to the zeros of G(s)H(s), which in this case are both at infinity. Putting these results 
together, we can draw the entire root locus, depicted in Figure 11.12, in which we have 
indicated the direction of increasing IKI, both for K > 0 and for K < 0. 
-2 
- 1 
CR.e 
(a) 
!1m 
- 2 
- 1 
(b) 
Figure 11.12 
Root locus for Example 11 .1: (a) K > 0; (b) K < 0. The 
poles of G(s)H(s); which are located at s = - 1 and s = - 2, are indicated. 
Note from the figure that for K > 0 there are two branches of the root locus and 
that the same is true for K < 0. The reason for the existence of two branches is that 
in this example the closed-loop system is a second-order system and consequently has 
two poles for any specified value of K. Therefore, the root locus has two branches, each 
of which traces the location of one of the closed-loop poles as K is varied, and for any 
, particular value of K, there is one closed-loop pole on each branch. Again, if we wish to 
calculate the value of K for which a specific point s0 on the locus is a closed-loop pole, 
we can use eqs. (11.52) and (11.55). 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
841 
11.3.5 Properties of the Root Locus 
The procedure outlined in the preceding subsection provides us, in principle, with a method 
for determining the root locus for any continuous-time or discrete-time LTI feedback sys-
tem. That is, we simply determine, graphically or otherwise, all those points that satisfy 
eq. (11.59) or eq. (11.60). Fortunately, there are a number of other geometric properties 
concerning root loci that make the sketching of a locus far less tedious. To begin our dis-
cussion of these properties, let us assume that we have placed G(s)H(s) in the standard 
form 
Sill+ bill-Ism- I + · · · + bo 
G(s)H(s) = ----.,-----
sn + an- lsn-l + . .. + ao 
m n (s - f3k) 
k=l 
(11.70) 
where the f3k's denote the zeros and the ak's denote the poles. In general, these may be 
complex. Also, from eq. (11.70), we see that we are assuming that the leading coeffi-
cient in both the numerator and the denominator of G(s)H(s) is + 1. This can always be 
achieved by dividing the numerator and denominator by the denominator coefficient of sn 
and absorbing the resulting numerator coefficient of sill into the gain K. For example, 
2s + 1 
~s + ! 
(2) 
s + ! 
K 
= K 
3 
3 
=- K 
2 
3s2 +5s+2 
s2+~s+~ 
3 
s2+~s+~' 
3 
3 
3 
3 
(11.71) 
and the quantity (2/3)K is then regarded as the overall gain that is varied in determining 
the root locus. 
We assume, in addition, that 
m :5 n, 
(11.72) 
which is the case that is usually encountered in practice. (Problem 11.33 considers the case 
m > n.) The following are some properties that include earlier observations and that aid 
in sketching the root locus. 
Property 1: 
ForK = 0, the solutions of eq. (11.45) are the poles of G(s)H(s). Since 
we are assuming n poles, the root locus has n branches, each one starting (for K = 0) 
at a pole of G(s)H(s). 
Property 1 includes the general version of a fact which we noted in Example 11.1: that 
there is one branch of the root locus for each closed-loop pole. The next property is also 
simply a restatement of one of our earlier observations. 
Property 2: 
As IKI ~ oo, each branch of the root locus approaches a zero of 
G(s)H(s). Since we are assuming that m :5 n, n - m of these zeros are at infinity. 

842 
Linear Feedback Systems 
Chap. 11 
Property 3: Parts of the real s-axis that lie to the left of an odd number of real poles 
and zeros of G(s)H(s) are on the root locus forK > 0. Parts of the real s-axis that lie 
to the left of an even number (possibly zero) of poles and zeros of G(s)H(s) are on the 
root locus forK < 0. 
We can show that Property 3 is true as follows: From our discussion in Example 11.1 
and from Figure 11.13(a), we see that if a point on the real s-axis is to the right of a real 
pole or zero of G(s)H(s), that pole or zero contributes zero to 4:-G(so)H(so). On the other 
hand, if so is to the left of a zero, that zero contributes +7T, whereas if s0 is to the left of 
a pole, we get a contribution of -?T (since we subtract the pole angles). Hence, if so is to 
the left of an odd number of real poles and zeros, the total contribution of these poles and 
zeros is an odd multiple of 7T, whereas if so is to the left of an even number of real poles 
and zeros, the total contribution is an even multiple of 7T. From eqs. (11.59) and (11.60), 
we will have the result stated in Property 3 if we can show that the total contribution 
from all poles and zeros with nonzero imaginary parts is an even multiple of 1r: The key 
here is that such poles and zeros occur in complex-conjugate pairs, and we can consider 
the contribution from each such pair, as illustrated in Figure 11.13(b). The symmetry in 
the picture clearly indicates that the sum of the angles from this pair to any point so on the 
real axis is precisely 27T. Summing over all conjugate zero pairs and subtracting the sum 
over all conjugate pole pairs, we get the desired result. Thus, any segment of the real line 
Angle of zero radians 
! 
(a) 
(b) 
Angle of 'lT radians 
<Re 
<Re 
Figure 11 .13 
(a) Angle contribu-
tion from real poles and zeros to a 
point on the real axis; (b) total angle 
contribution from a complex-conjugate 
pole pair to a point on the real axis. 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
843 
between real poles or zeros is on the root locus either for K > 0 or for K < 0, depending 
on whether it lies to the left of an odd or an even number of poles and zeros of G(s )H (s). 
As one consequence of Properties 1 through 3, consider a segment of the real axis 
between two poles of G(s)H(s), with no zeros between these poles. From Property 1 the 
root locus begins at the poles, and from Property 3 the entire portion of the real axis between 
the two poles will lie on the root locus for a positive or negative range of values of K. 
Therefore, as IKI increases from zero, the two branches of the root locus that begin at these 
poles move toward each other along the segment of the real axis between the poles. From 
Property 2, as IKI increases toward infinity, each branch of the root locus must approach 
a zero. Since there are no zeros along that portion of the real axis, the only way that this 
can happen is if the branches break off into the complex plane for IKI sufficiently large. 
This is illustrated in Figure 11.12, in which the locus for K > 0 has a portion between 
two real poles. As K is increased, the root locus eventually leaves the real axis, forming 
two complex-conjugate branches. Summarizing this discussion, we have the following 
property of the root locus: 
Property 4: 
Branches of the root locus between two real poles must break off into 
the complex plane for IKilarge enough. 
Properties 1-4 serve to illustrate how characteristics of the root locus can be de-
duced from eqs. (11.45), (11.59), and (11.60). In many cases, plotting the poles and zeros 
of G(s)H(s) and then using these four properties suffices to provide a reasonably accurate 
sketch of the root locus. (See Examples 11.2 and 11.3.) In addition to these properties, 
however, there are numerous other characteristics of the root locus that allow one to ob-
tain sketches of increasing accuracy. For example, from Property 2, we know that n - m 
branches of the root locus approach infinity. In fact, these branches approach infinity at 
specific angles that can be calculated, and therefore, the branches are asymptotically par-
allel to lines at the~e angles. Moreover, it is possible to draw in the asymptotes and then 
determine the point at which they intersect. These two properties and several others are 
illustrated in Problems 11.34-11.36 and 11.41- 11.42. A more detailed development of 
the root-locus method can be found in more advanced texts such as those listed in the 
bibliography at the end of the book. 
In the remainder of this section we present two examples, one in continuous time 
and one in discrete time, that illustrate how the four properties that we have just described 
allow us to sketch the root locus and to deduce the stability characteristics of a feedback 
system as the gain K is varied. 
Example 11 .2 
Let 
s- 1 
G(s)H(s) = (s + 1)(s + 2) 
(11.73) 
From Properties 1 and 2, the root locus for either K positive or K negative starts at the 
points s = -1 and s = -:-2. One branch tenninates at the zero at s = 1 and the other at 
infinity. 
Let us first consider K > 0. The root locus in this case is illustrated in Fig-
ure 11.14(a). From Property 3, we can identify the regions of the real axis that are on 

844 
-2 
-1 
(a) 
dm 
(b) 
Linear Feedback Systems 
Chap. 11 
CR.e 
Figure 11.14 
Root locus for Example 11.2: (a) K > 0; (b) K < 0. The 
poles of G(s)H(s) at s = - 1 and s = -2 and the zero of G(s)H(s) at s = 1 
are indicated in the figure. 
the root locus forK> 0--specifically,<R-.e{s} < -2 and -1 < <R-.e{s} < 1. Therefore, one 
branch of the root locus forK > 0 originates at s = -1 and approaches s = 1 asK ~ oo. 
The other begins at s = -2 and extends to the left toward <R-.e{s} = -oo asK ~ +oo. 
Thus, we see that for K > 0, if K is sufficiently large, the system will become 
unstable, as one of the closed-loop poles moves into the right-half plane. The procedure 
that we have used for sketching the root locus does not, of course, indicate the value 
of K for which this instability develops. However, for this particular example, we see 
that the value of K for which the instability occurs corresponds to the root locus passing 
through s = 0. Consequently, from eq. (11.52), the corresponding value of K is 
1 
K = IG(O)H(O)I = 2" 
(11.74) 
Thus, the system is stable for 0 ::::; K < 2, but is unstable for K <::: 2. 
ForK < 0, the portions of the real axis lying on the root locus are <R-.e{s} > 1 and 
- 2 < <R-.e{s} < - 1. Thus, the root locus again starts at the points s = -2 and s = -1, 
moving into the region -2 < <R-.e{s} < -1. At some point, it breaks off into the complex 
plane and follows a trajectory such that it returns to the real axis for s > 1. Upon the root 
locus' return to the real axis, one branch moves to the left toward the zero at s = 1 and 
the other to the right toward s = oo, as indicated in Figure 11.14(b ), in which we have 
displayed an accurate plot of the root locus for K < 0. 

Sec. 11.3 
Root-Locus Analysis of Linear Feedback Systems 
845 
Rules can also be developed to indicate the locations at which the root locus leaves 
and enters the real axis. Even without that precise a description, however, we can sketch 
the general shape of the root locus in Figure 11.14(b) and can therefore deduce that for 
K < 0, the system also becomes unstable for IKI sufficiently large. 
Example 11 .3 
Consider the discrete-time feedback system illustrated in Figure 11.15. In this case, 
z- 1 
z 
G(z)H(z) = 
= 
. 
(1 - kz-1)(1- ±z-t) 
(z - 4)(z- ±) 
(11.75) 
x[n] 
y[n] 
+~ 
K 
(1 -
~z-
1 ) 
-
z-1 
(1- h - 1) 
Figure 11.1 5 
Discrete-time feedback system of Example 11.3. 
As discussed at the beginning of this section, the techniques for sketching the root locus 
of a discrete-time feedback system are identical to those used in the continuous-time 
case. Therefore, in a manner exactly analogous to that of the preceding example, we 
can deduce the basic form of the root locus for this example, which is illustrated in 
Figure 11.16. In this case the portion of the real axis between the two poles of G(z)H(z) 
(at z = 114 and z = 1/2) is on the root locus for K > 0, and as K increases the locus 
breaks off into the complex plane and returns to the axis at some point in the left-half 
plane. From there, one branch approaches the zero of G(z)H(z) at z = 0, and the other 
approaches infinity as K ~ oo. The form of the root locus for K < 0 consists of two 
branches on the real axis, one approaching 0 and the other infinity. 
As we remarked earlier, while the form of the root locus does not depend on 
whether the system is a continuous-time or discrete-time system, any conclusion re-
garding stability based on examining the locus certainly does. For this example, we can 
conclude that for IKI sufficiently large the system is unstable, since one of the two poles 
has magnitude greater than 1. In particular, from the K > 0 root locus in Figure 11.16(a), 
we see that the transition from stability to instability occurs when one of the closed-loop 
poles is at z = -1. From eq. (11.52), the corresponding value of K is 
K = 
1 
= 15 
jG(-l)H(-l)j 
8. 
(11 .76) 
Similarly, from Figure 11.16(b), the stability-instability transition occurs when one of 
the closed-loop poles is at z = 1, and from eq. (11.55), the corresponding value of K is 
1 
3 
K =-
= --
jG(l)H(l)j 
8. 
(11.77) 
Putting this together, we see that the closed-loop system in Figure 11.16 is stable if 

846 
I 
I 
I 
\ 
\ 
I 
I 
I 
I 
I 
I 
I 
I 
I 
' ' 
(a) 
Linear Feedback Systems 
I 
I 
' \ 
\ 
\ 
-
----- ' ,,/Unit circle 
' 
1 
1 
4 
2 
(b) 
\ 
\ 
\ 
I 
I 
Chap. 11 
Figure 11.16 
Root locus for Example 11.3: (a) K > 0; (b) K < 0. The 
poles of G(z)H(z) at z = 1/4 and z = 1/2 and the zero of G(z)H(z) at z = 0 
are indicated in the figure. 
3 
15 
- - < K < -
8 
8 
(11.78) 
and is unstable for K outside this range. 
11.4 THE NYQUIST STABILITY CRITERION 
As developed in Section 11.3, the root -locus technique provides detailed information con-
cerning the location of closed-loop poles as the system gain is varied. From root-locus 
plots, one can determine the damping and the stability characteristics of the system as K 
is varied. Determination of the root locus requires the analytic description of the system 

Sec. 11.4 
The Nyquist Stability Criterion 
847 
functions of the forward and feedback paths and is applicable only when these transforms 
are rational. For example, it cannot be directly applied in situations in which our knowledge 
of the system functions is obtained purely from experimentation. 
In this section, we introduce another method for the determination of the stability of 
feedback systems as a function of an adjustable gain parameter. This technique, referred to 
as the Nyquist criterion, differs from the root-locus method in two basic ways. Unlike the 
root-locus method, the Nyquist criterion does not provide detailed information concerning 
the location of the closed-loop poles as a function of K, but rather, simply determines 
whether or not the system is stable for any specified value of K. On the other hand, the 
Nyquist criterion can be applied to nonrational system functions and in situations in which 
no analytic description of the forward and feedback path system functions is available. 
Our objective in this section is to outline the basic ideas behind the Nyquist criterion 
for both continuous-time and discrete-time systems. As we will see, both the discrete-
time and continuous-time Nyquist tests are the result of the same fundamental concept, 
although, as with the root-locus method, the actual criteria for stability differ because of 
the differences between continuous and discrete time. More detailed developments of the 
ideas behind the Nyquist criterion and its use in the design of feedback systems can be 
found in texts on the analysis and synthesis of feedback systems and automatic control 
systems, including those listed in the bibliography at the end of the book. 
To introduce the method, let us recall that the poles of the closed-loop systems of 
Figure 11.10 and their discrete-time counterparts are the solutions of the equations 
1 + KG(s)H(s) = 0 
(continuous time) 
(11.79) 
and 
1 + KG(z)H(z) = 0 
(discrete time). 
(11.80) 
For discrete-time systems, we want to determine whether any of the solutions of eq. (11.80) 
lie outside the unit circle, and for continuous-time systems whether any of the solutions of 
eq. (11.79) lie in the right half of the s-plane. The Nyquist criterion fixes this by examina-
tion of the values of G(s)H(s) along the jw-axis and the values of G(z)H(z) along the unit 
circle. The basis for this is the encirclement property, which we develop in the following 
subsection. 
11.4.1 The Encirclement Property 
Consider a general rational function W(p), where pis a complex variable,3 and suppose 
that we plot W (p) for values of p along a closed contour in the p-plane, which we traverse 
in a clockwise direction. This is illustrated in Figure 11.17 for a function W(p) that has 
two zeros and no poles. In Figure 11.17 (a) we show a closed contour C in the p-plane, and 
in Figure 11.17 (b) we plot the closed contour of the values of W (p) asp varies around C. 
3Because we will use the property we are about to develop for both continuous-time and discrete-time 
feedback systems, we have chosen to describe it in terms of a general complex variable p. In the next subsection 
we use this property to analyze continuous-time feedback systems, where the complex variable iss. Following 
this, in Section 11.4.3 we use the encirclement property for discrete-time feedback systems, in which context 
the complex variable is z. 

848 
(a) 
(b) 
p-plane 
W-plane 
Linear Feedback Systems 
Chap. 11 
Figure 11. 17 
Basic encirclement 
property. The closed curve in (b) rep-
resents a plot of the values of W(p) 
(Re 
for values of p along the curve C 
in (a). Here, the arrow on the curve C 
in (a) indicates the direction in which 
C is traversed, and the arrow in (b) 
indicates the corresponding direction 
along the contour of values of W(p). 
In this example, there is one zero of W(p) inside the contour and one zero of W(p) outside 
the contour. At any point p on C, the angle of W (p) is the sum of the angles of the two 
vectors v1 and v2 to the point p. As we traverse the contour once, the angle 4>1 of the 
vector from the zero inside the contour encounters a net change of -27T radians, whereas 
the angle 4>2 of the vector from the zero outside the contour encounters no net change. 
Thus, on the plot of W(p), there is a net change in angle of -27T. Said another Wdy, the 
plot of W (p) in Figure 11.17 (b) encircles the origin once in the clockwise direction. More 
generally, for an arbitrary rational W(p), as we traverse a closed contour in the clock-
wise direction, any poles and zeros of W (p) outside the contour will contribute no net 
change to the angle of W(p), whereas each zero inside the contour will contribute a net 
change of -27T and each pole inside will contribute a net change of +27T. Since each 
net change of -2 7T in W (p) corresponds to one clockwise encirclement of the origin in the 
plot of W(p), we can state the following basic encirclement property: 
Encirclement Property: 
As a closed contour C in the p-plane is traversed once in the 
clockwise direction, the corresponding plot of W(p) for values of p along the contour 
encircles the origin in the clockwise direction a net number of times equal to the number 
of zeros minus the number of poles contained within the contour. 
In applying this statement, a counterclockwise encirclement is interpreted as the neg-
ative of one clockwise encirclement. For example, if there is one pole and no zeros inside 
the contour, there will be one counterclockwise, or equivalently, minus-one clockwise, 
encirclement. 

Sec. 11.4 
The Nyquist Stability Criterion 
849 
Example 11 .4 
Consider the function 
p - 1 
W(p) = (p + 1)(p2 + p + 1). 
(11.81) 
9m 
9m 
c,Ox 
p-plane 
<Re 
X 
(a) 
9m 
p-plane 
W-plane 
X 
(b) 
9m 
9m 
p-plane 
W-plane 
(c) 
Figure 11. 18 
Basic encirclement property for Example 11.4: (a) the con-
tour encircles no poles or zeros and consequently W(p) has no encirclements 
of the origin; (b) the contour encircles one pole and therefore W(p) has one 
encirclement of the origin; (c) the contour encircles three poles and therefore 
W(p) has three encirclements of the origin; 

850 
Linear Feedback Systems 
Chap. 11 
tim 
g,. 
p-plane 
W-plane 
X 
<R.e 
<R.e 
X 
(d) 
g,. 
g,. 
p-plane 
W-plane 
<R.e 
<R.e 
(e) 
Figure 11.18 
Continued (d) the contour encircles one pole and one zero 
and therefore W(p) has no encirclements of the origin; (e) the contour encir-
cles three poles and one zero. W(p) has two encirclements of the origin. 
In Figure 11.18, we depict several closed contours in the complex p-plane and the corre-
sponding plots of W(p) along each of these contours. In Figure 11.18(a), the contour C1 
does not encircle any of the poles or zeros of W(p), and consequently, the plot of W(p) 
has no net encirclements of zero. In Figure 11.18(b ), only the pole at p = -1 is contained 
within the contour C2, and the plot of W(p) encircles the origin once in the counterclock-
wise direction (minus-one clockwise encirclements). In Figure 11.18(c), C3 encircles all 
three poles, and the plot of W(p) encircles the origin three times in a counterclockwise 
direction. In Figure 11.18(d), C4 encircles one pole and one zero, and therefore, the plot 
of W(p) has no net encirclements of the origin. Finally, in Figure 11.18(e), all of the 
poles and the one zero of W(p) are contained within C5, and thus, the plot of W(p) along 
this contour has two net counterclockwise encirclements of the origin. 
11.4.2 The Nyquist Criterion for Continuous-Time 
LTI Feedback Systems 
In this section, we exploit the encirclement property in examining the stability of the 
continuous-time feedback system of Figure 11.10. Stability of this system requires that 

Sec. 11.4 
The Nyquist Stability Criterion 
851 
no zeros of 1 + K G(s )H (s ), or equivalently, of the function 
1 
R(s) = K + G(s)H(s) 
(11.82) 
lie in the right half of the s-plane. Thus, in applying the general result developed in the 
preceding subsection, we can consider the contour indicated in Figure 11.19. From the 
plot of R(s), as s traverses the contour C we can obtain a count of the number of zeros 
minus the number of poles of R(s) contained within the contour by counting the number 
of clockwise encirclements of the origin. As M increases to infinity, this then corresponds 
to the number of zeros minus the number of poles of R(s) in the right half of the s-plane. 
jM 
Figure 11. 19 
Closed contour con-
taining a portion of the right-half plane; 
as M ~ oo, the contour encloses the 
entire right-half plane. 
Let us examine the evaluation of R(s) along the contour in Figure 11.19 as Min-
creases to infinity. Along the semicircular portion of the contour extending into the right-
half plane, we must ensure that R(s) remains bounded as M increases. Accordingly, we 
will assume that R(s) has at least as many poles as zeros. In that case, 
and 
R(s) = bnS
11 + bn- 1S
11
- 1 + · · · + bo 
anS11 + an- 1S11 - 1 + ... + ao 
lim R(s) = bn = constant. 
lsi-->CO 
an 
(11.83) 
(11.84) 
Therefore, as M increases to infinity, the value of R(s) does not change as we traverse the 
semicircular part of the contour, and consequently, the constant value along this part is 
equal to the value of R(s) at the end points [i.e., R(jw) at w = ± oo]. 
Therefore, the plot of R(s) along the contour of Figure 11.19 can be obtained by 
plotting R(s) along the part of the contour that coincides with the imaginary axis-that is, 
the plot of R(jw) as w varies from - oo to + oo. Since R(jw) equals l!K + G(jw)H(jw), 
R(s) along the contour can be drawn from knowledge of G(jw) and H(jw ). If both 
the forward- and feedback-path systems are stable, G(jw) and H(jw) are simply the 
frequency-response functions of these systems. However, the encirclement property 
for the general function W(p) is simply a property of complex functions; it has nothing to 

852 
Linear Feedback Systems 
Chap. 11 
do with whether W(p) arose as the Laplace or z-transform of any signal and, conse-
quently, has nothing to do with regions of convergence. Thus, even if the forward- and 
feedback-path systems are unstable, if we examine the plot of the function R(jw) = 
11K + G(jw)H(jw) for - oo < w < oo, we know that the net number of clockwise en-
circlements of the origin will equal the number of zeros minus the number of poles of R(s) 
that lie in the right-half plane. 
Furthermore, from eq. (11.&2), we see that the poles of R(s) are simply the poles 
of G(s)H(s), while the zeros of R(s) are the closed-loop poles. In addition, since 
G(jw)H(jw) = R(jw) -
11K, it follows that the plot of G(jw)H(jw) encircles the 
point - 11 K exactly as many times as R(jw) encircles the origin. The plot of G(jw )H (jw) 
as w varies from - oo to + oo is called the Nyquist plot. From the encirclement property, we 
then see that 
The number of clockwise 
encirclements of the point 
- 1/ K by the Nyquist plot 
The number of right-half 
plane closed-loop poles 
minus the number of right-
half plane poles of G(s)H(s) . . 
(11.85) 
While the open -loop system G(s )H (s) may have unstable poles, for the closed-loop system 
to be stable we require no right-half plane closed-loop poles. This yields the continuous-
time Nyquist stability criterion: 
Continuous-Time Nyquist Stability Criterion: 
For the closed-loop system to be 
stable, the net number of clockwise encirclements of the point - 11 K by the Nyquist plot 
of G(jw )H(jw) must equal minus the number of right-half-plane poles of G(s)H(s). 
Equivalently, the net number of counterclockwise encirclements of the point - 11 K by 
the Nyquist plot of G(jw )H(jw) must equal the number of right-half-plane poles of 
G(s)H(s). 
For example, if the forward- and feedback-path systems are stable, then the Nyquist 
plot is simply the plot of the frequency response of the cascade of these two systems. In 
this case, since there are no poles of G(s)H(s) in the right-half plane, the Nyquist criterion 
requires that, for stability, the net number of encirclements of the point -11 K must be 
zero. 
Example 1 1 . 5 
Let 
1 
G(s) =
-s + 1' 
1 
H(s) = -
-. 
.!.s + 1 
2 
(11.86) 
The Bode plot for G(jw )H(jw) is shown in Figure 11.20. The Nyquist plot depicted 
in Figure 11.21 is constructed directly from the plots of the log magnitude and phase 
of G(jw )H(jw ). That is, each point on the Nyquist plot has polar coordinates con-
sisting of the magnitude IG(jw)H(jw)l and angle <tG(jw)H(jw) for some value 
of w. The coordinates of G(jw )H (jw) for w < 0 are obtained from the values for 
w > 0 through the use of the conjugate . symmetry property of G(jw )H(jw ). This 
property manifests itself geometrically in a very simple way, which facilitates the 
sketching of the Nyquist plot for any feedback system composed of systems with 

Sec. 11.4 
The Nyquist Stability Criterion 
20 
OdB 
3 
~ 
::c 
:5 
(!) 
0 
Ol 
- 80 
.Q 
0 
C\1 
- 120 
0.01 
10 
100 
w 
0 
3 
~ 
::c 
3 
(!) 
v-
w 
Figure 11.20 
Bode plot for G(jw )H(jw) in Example 11 .5. 
!fm{G(jw)H(jw)} 
w=O 
<Re{G(jw)H(jw)} 
Figure 11.21 
Nyquist plot of G(jw )H(jw) for Example 11.5. The arrow on 
the curve indicates the direction of increasing w. 
853 

854 
Linear Feedback Systems 
Chap. 11 
real impulse responses. Specifically, since I G(- jw )H (- jw) I = I G(jw )H (jw) I and 
1:G(- jw)H( - jw) = - 1:G(jw)H(jw), the Nyquist plot of G(jw)H(jw) for w :S 0 
is a reflection about the real axis of the plot for w 2: 0. Note also that we have included 
an arrow on the Nyquist plot in Figure 11.21. This arrow indicates the direction of in-
creasing w. That is, it indicates the direction in which the Nyquist plot is traversed (as 
w varies from - oo to +oo) for the counting of encirclements in the application of the 
Nyquist criterion. 
In this example there are no right-half-plane open-loop poles, and consequently, 
the Nyquist criterion requires that, for stability, there be no net encirclements of the 
point -11 K. Thus, by inspection of Figure 11.21, we see that the closed-loop system 
will be stable if the point - 1/ K falls outside the Nyquist contour-that is, if 
which is equivalent to 
1 
-
-
:S 0 
K 
K 2: 0 
or 
or 
1 
- -
> 1 
K 
, 
O> K > -1. 
(11.87) 
(11.88) 
Combining these two conditions, we obtain the result that the closed-loop system will be 
stable for any choice of K greater than -1. 
Example 11.6 
Consider now 
G(s)H(s) = 
s + 1 
(s-
1)(~s + 1). 
(11.89) 
The Nyquist plot for this system is indicated in Figure 11.22. For this example, G(s)H(s) 
has one right-half-plane pole. Thus, for stability we require one counterclockwise encir-
clement of the point - 11 K, which in tum requires that the point - 11 K fall inside the 
contour. Hence, we will have stability if and only if - 1 < - 11 K < 0, that is, if K > 1. 
dm{G(jw)H(jw)} 
- 1 
/ 
<R.e{G(jw)H(jw)} 
w=O 
Figure 11 .22 
Nyquist plot for Example 11.6. The arrow on the curve indi-
cates the direction of increasing w. 
In the foregoing discussion, we have introduced and illustrated a form for the Nyquist 
stability criterion that applies to an extremely large class of feedback systems. In addition, 

Sec. 11.4 
The Nyquist Stability Criterion 
855 
there are a number of refinements and extensions of the criterion that allow it to be used for 
many other feedback systems as well. For example, as we have developed it, the Nyquist 
plot can be drawn without any difficulties for stable or unstable G(s)H(s), as long as there 
are no poles of G(s)H(s) exactly on the jw-axis. When such poles do occur, the value 
of G(jw )H(jw) is infinite at those points. However, as considered in Problem 11.44, the 
Nyquist criterion can be modified to allow for poles of G(s)H(s) on the jw-axis. In ad-
dition, as mentioned at the beginning of this section, the Nyquist criterion can also be 
extended to the case in which G(s) and H(s) are not rational. For example, it can be shown 
that if the forward- and feedback-path systems are both stable, the Nyquist criterion is 
the same when the system functions are nonrational as it is when they are rational. That 
is, the closed-loop system is stable if there are no net encirclements of the point -1/K. 
To illustrate the application of the Nyquist criterion for nonrational system functions, we 
present the following example: 
Example 11 . 7 
Consider the acoustic feedback example discussed in Section 11.2.6. Referring to Fig-
ure 11.8(b), let K = K 1K 2 and 
G(s)H(s) = -e- sT = e - (sT+j1r), 
where we have used the fact that e-i" = - 1. In this case, 
G(jw)H(jw) = e - j(wT+"l, 
(11.90) 
(11.91) 
and as w varies from - oo to oo, G(jw )H(jw) traces out a circle of radius 1 in the clock-
wise direction, with one full revolution for every change of 27r/T in w. This is illus-
trated in Figure 11.23. Since the forivard- and feedback-path systems are stable [the 
cascade G(s)H(s) is simply a time delay], the Nyquist stability criterion indicates that 
the closed-loop system will be stable if and only if - 1/K does not fall inside the unit 
circle. Equivalently, we require for stability that 
IKI < 1. 
(11.92) 
9'm{G(jw)H(jw)} 
Figure 11.23 
Nyquist plot for Example 11.7. 
Since K1 and K2 represent an acoustic gain and attenuation, respectively, they are both 
positive, which yields the stability criterion 
(11.93) 

856 
Linear Feedback Systems 
Chap. 11 
11.4.3 The Nyquist Criterion for Discrete-Time LTI 
Feedback Systems . 
As in the continuous-time case, the Nyquist stability criterion for discrete-time systems 
is based on the fact that the difference in the number of poles and zeros inside a contour, 
for a rational function, can be determined by examining a plot of the value of the function 
along the contour. The difference between the continuous-time and discrete-'time cases is 
the choice of the contour. For the discrete-time case, stability of the closed-loop feedback 
system requires that no zeros of 
1 
R(z) = K + G(z)H(z) 
(11.94) 
lie outside the unit circle. 
Recall that the encirclement property relates to poles and zeros inside any specified 
contour. On the other hand, in examining the stability of a discrete-time system, we are 
concerned with the zeros of R(z) outside the unit circle. Therefore, in order to make use of 
the encirclement property, we first make a simple modification. Let us consider the rational 
function 
R(z) = RG) 
(11.95) 
obtained by replacing z by its reciprocal. As seen in Problem 10.43, if zo is a zero (pole) 
of R(z), then 1/zo is a zero (pole) of R(z). Since 11 lzol is less than 1 if lzol > 1, any zero 
or pole of R(z) outside the unit circle corresponds to a zero or pole of R(z) inside the unit 
circle. 
From the basic encirclement property, we know that as z traverses the unit circle in 
a clockwise direction, the net number of clockwise encirclements of the origin by R(z) 
equals the difference between the number of it1'> zeros and poles inside the unit circle. 
However, from the previous paragraph, this equals the difference between the number of 
. zeros and poles of R(z) outside the unit circle. Furthermore, on the unit circle, z = ejw 
and 11 z = e- jw. Therefore, 
(11.96) 
From this, we see that evaluating R(z) as z traverses the unit circle in the clockwise di-
rection is identical to evaluating R(z) as z traverses the unit circle in the counterclockwise 
direction. In sum, then, 
The number of clockwise 
encirclements of the origin 
by the plot of R(ejw) as the 
unit circle is traversed in the 
counterclockwise direction 
(e.g., as w increases from 0 
to 2'7T) 
The number of zeros of R(z) 
outside the unit circle minus 
the number of poles of R(z) 
outside the unit circle. 
(11.97) 
Much as in the continuous-time case, counting the encirclements of the origin by 
R(ejw) is equivalent to counting the number of encirclements of the point - 11K by the 

Sec. 11.4 
The Nyquist Stability Criterion 
857 
plot of G(eiw)H(eiw), again referred to as the Nyquist plot, which is graphed as w varies 
from 0 to 27T. Also, the poles of R(z) are precisely the poles of G(z)H(z), and the zeros of 
R(z) are the closed-loop poles. Therefore, the encirclement property stated in the preceding 
paragraph implies that the net number of clockwise encirclements by the Nyquist plot of 
the point - 11 K equals the number of closed-loop poles outside the unit circle minus the 
number of poles of G(z)H (z) outside the unit circle. In order that the closed-loop system be 
stable, we require no closed-loop poles outside the unit circle. This yields the discrete-time 
Nyquist stability criterion: 
Discrete-Time Nyquist Stability Criterion: For the closed-loop system to be sta-
ble, the net number of clockwise encirclements of the point -11 K by the Nyquist plot 
of G(eiw)H(eiw) as w varies from 0 to 27T must equal minus the number of poles of 
G(z)H(z) that lie outside the unit circle. Equivalently, the net number of counterclock-
wise encirclements ofthe point -1/K by the Nyquist plot of G(eiw)H(eiw) as w varies 
from 0 to 27T must equal the number of poles of G(z)H(z) outside the unit circle. 
Example 11 .8 
Let 
z - 2 
G(z)H(z) = -
-;---
1 + ! z-1 
2 
1 
(11.98) 
The Nyquist plot of this curve is shown in Figure 11.24. Since G(z)H (z) has no poles 
outside the unit circle, for the stability of the closed-loop system there must be no encir-
clements of the point -1/K. From the figure, we see that this will be the case either if 
-1/K < - 1 or if -1/K > 2. Thus, the system is stable for -112 < K < 1. 
5m {G(eiw)H(eiw)} 
Figure 11 .24 
Nyquist plot for Example 11.8. The arrow on the curve in-
dicates the direction in which the curve is traversed as w increases from 0 
to 21r. 
Just as in continuous time, if the forward and feedback paths are stable, then the 
Nyquist plot can be obtained from the frequency responses H(eiw) and G(eiw) of these 

858 
Linear Feedback Systems 
Chap. 11 
systems. If the forward and feedback paths are unstable, then the frequency responses are 
not defined. Nevertheless, the function G(z)H(z) can still be evaluated on the unit circle, 
and the Nyquist stability criterion can be applied. 
As we have seen in this section, the Nyquist stability criterion provides a useful 
method for determining the range of values of the gain K for which a continuous-time 
or discrete-time feedback is stable (or unstable). This criterion and the root-locus method 
are extremely important tools in the design and implementation of feedback systems, and 
each has its own uses and limitations. For example, the Nyquist criterion can be applied to 
nonrational system functions, whereas the root-locus method cannot. On the other hand, 
root-locus plots allow us to examine not only stability, but also other charac~eristics of the 
closed-loop system response, such as damping, oscillation frequency, and so on, which are 
readily identifiable from the location of the poles of the closed-loop system. In the next 
section, we introduce an additional tool for the analysis of feedback systems that highlights 
another important characteristic of closed-loop system behavior. 
11.5 GAIN AND PHASE MARGINS 
In this section, we introduce and examine the concept of the margin of stability in a feed-
back system. It is often of interest not only to know whether a feedback system is stable, 
but also to determine how much the gain in the system can be perturbed and how much 
additional phase shift can be added to the system before it becomes unstable. Information 
such as this is important because in many applications the forward and feedback system 
functions are known only approximately or may change slightly during operation because 
of wear, the effect of high temperatures on components, or similar influences. 
As an example, consider the telescope-pointing system described in Section 11.0 
and illustrated in Figures 11.1 (c) and (d). This system consists of a motor, a potentiometer 
converting the shaft angle to a voltage, and an amplifier that is used to amplify the voltage 
representing the difference between the desired and the actual shaft angles. Assuming that 
we have obtained approximate descriptions of each of these components, we can set the 
amplifier gain so that the system will be stable if these descriptions are accurate. However, 
the amplifier gain and the constant of proportionality that describes the angle-voltage char-
acteristic of the potentiometer are never known exactly, and therefore, the actual gain in 
the feedback system may differ from the nominal value assumed in designing the system. 
Furthermore, the damping characteristics of the motor cannot be determined with absolute 
precision, and thus, the actual time constant of the motor response may differ from the ap-
proximate value in the specification of the system. For example, if the actual motor time 
constant is larger than the nominal value used in the design, the motor will respond more 
sluggishly than anticipated, thereby producing an effective time delay in the feedback 
system. As we have discussed in earlier chapters, and as we will again in Example 11.11, 
time delays have the effect of increasing the negative phase in the frequency response of a 
system, and this phase shift can have a destabilizing influence on the system. Because of 
the possible presence of gain and phase errors such as those we have just described, it is 
clearly desirable to set the amplifier gain so that there is some margin for error-that is, so 
that the actual system will remain stable even if it differs somewhat from the approximate 
model used in the design process. 

x(t) 
Sec. 11 .5 
Gain and Phase Margins 
859 
In this section, we introduce one method for quantifying the margin of stability in a 
feedback system. To do this, we consider a closed-loop system, depicted in Figure 11.25, 
that has been designed to be stable based on nominal values for the forward- and feedback-
path system functions. For our discussion here, we let H (s) and G(s) denote these nominal 
values. Also, since the basic concepts are identical for both continuous-time and discrete-
time systems, we will again focus our development on the continuous-time case, and at the 
end of the section we illustrate the application of these ideas to a discrete-time example. 
+ 
H(s) 
G(s) 
y(t) 
Figure 11.25 
Typical feedback 
system designed to be stable, as-
suming nominal descriptions for H(s) 
and G(s). 
To assess the margin of stability in our feedback system, suppose that the actual 
system is as depicted in Figure 11.26, where we have allowed for the possibility of a gain 
K and phase shift <Pin the feedback path. In the nominal system K is unity and <Pis zero, but 
in the actual system either or both may have a different value. Therefore, it is of interest to 
know how much variation can be tolerated in these quantities without losing closed-loop 
system stability. In particular, the gain margin of the feedback system is defined as the 
minimum amount of additional gain K, with <P = 0, that is required so that the closed-
loop system becomes unstable. Similarly, the phase margin is the additional amount of 
phase shift, with K = 1, that is required for the system to be unstable. By convention, the 
phase margin is expressed as a positive quantity; that is, it equals the magnitude of the 
additional negative phase shift at which the feedback system becomes unstable. 
)II 
H(s) 
G(•)~-
K ~ 
+ 
>(t)~ 
y(t) 
Figure 11 .26 
Feedback system containing possible gain and phase devia-
tions from the nominal description depicted in Figure 11.25. 
Since the closed-loop system of Figure 11.25 is stable, the system of Figure 11.26 
can become unstable if, asK and <Pare varied, at least one pole of the closed-loop system 
crosses the jw-axis. If a pole of the closed-loop system is on the jw-axis at, say, w = w0, 
then at this frequency 
1 +Ke- NG(jwo)H(jwo) = 0, 
(11.99) 

860 
Linear Feedback Systems 
Chap. 11 
or 
(11.100) 
Note that with K = 1 and cf> = 0, by our assumption of stability for the nominal feedback 
system of Figure 11.25, there is no value of wo for which eq. (11.100) is satisfied. The 
gain margin of this system is the minimum value of K > 1 for which eq. (11.100) has a 
solution for some w0 with cf> = 0. That is, the gain margin is the smallest value of K for 
which the equation 
KG(jwo)H(jwo) = -1 
(11.101) 
has a solution w0 . Similarly, the phase margin is the minimum value of cf> for which 
eq. (11.100) has a solution for some w0 when K = 1. In other words, the phase margin is 
the smallest value of cf> > 0 for which the equation 
(11.102) 
has a solution. 
To illustrate the calculation and graphical interpretation of gain and phase margins, 
we consider the following example. 
Example 11 . 9 
Let 
4(1 + .!.s) 
G(s)H(s) = 
2 
• 
s(l + 2s)(1 + 0.05s + (0.125d) 
(11.103) 
The Bode plot for this example is shown in Figure 11.27. Note that, as discussed in 
Problem 6.31, the factor of 11 jw in G(jw )H (jw) contributes -90° ( -TT/2 radians) of 
phase shift and a 20-dB-per-decade increase in IG(jw )H(jw )I. To determine the gain 
margin, we observe that, with 4J = 0, the only frequency at which eq. (11.101) can be 
satisfied is that for which <t:.G(jw0)H(jw0) = -TT. At this frequency, the gain mar-
gin in decibels can be identified by inspection of Figure 11.27. We first examine Fig-
ure 11.27(b) to determine the frequency w 1 at which the angle curve crosses the line 
- TT radians. Locating the point at this same frequency in Figure 11.27(a) provides us 
with the value of IG(jw 1 )H(jw 1)1. For eq. (11.101) to be satisfied for w0 = w 1, K must 
equal1/IG(jw 1 )H(jw 1 )I. This value is the gain margin. As illustrated in Figure 11.27(a), 
the gain margin expressed in decibels can be identified as the amount the log-magnitude 
curve would have to be shifted up so that the curve intersects the 0-dB line at the fre-
quency w 1 • 
In a similar fashion, we can determine the phase margin. Note first that the only 
frequency at which eq. (11.102) can be satisfied is that for which IGUwo)H(jwo)l = 1, 
or equivalently, 20 log10 IG(jw0)H(jwo)l = 0. To determine the phase margin, we first 
find the frequency w2 in Figure 11.27(a) at which the log-magnitude curve crosses the 
0-dB line. Locating the point at this same frequency in Figure 11.27(b) then provides 
us with QJ.e value of <r:.G (jw2)H (jw2). For eq. (11.102) to be satisfied for wo = w 2, the 
angle of the left-hand side of this equation must be -TT. The value of 4J for which this 
is true is the phase margin. As illustrated in Figure 11.27(b), the phase margin can be 
identified as the amount the angle curve would have to be lowered so that the curve 
intersects the line - 7r at the frequency w 2• 

Sec. 11.5 
Gain and Phase Margins 
40 
3 
20 
J: 
3 OdB 
:=:> 
CJ 
0 
- 20 
c; 
..Q 
0 
(\j -40 
(1)2 w\i 
- 60 
0.1 
: 1.0 
10.0 
w 
'IT 2 
~ 
0 
J: 
3 
'IT 
:=:> -2 
CJ 
"f 
- 'IT 
371' 
- 2 
0.1 
1.0 
10.0 
w 
Figure 11 .27 
Use of Bode plots to calculate gain and phase margins for 
the system of Example 11.9. 
861 
In determining gain and phase margins, it is not always of interest to identify ex-
plicitly the frequency at which the poles will cross the jw-axis. As an alternative, we can 
identify the gain and phase margins from a log magnitude-phase diagram. For example, 
the log magnitude-phase diagram for the system of Figure 11.27 is shown in Figure 11.28. 
In this figure, we plot 20 log 10 jG(jw)H(jw)j versus <r.G(jw)H(jw) as w varies from 0 
to +oo. Therefore, because of the conjugate symmetry of G(jw )H(jw ), the plot contains 
the same information as the Nyquist plot, in which <Re{G(jw )H(jw )} is plotted versus 
gm{G(jw )H(jw )} for - oo < w < oo. As we have indicated, the phase margin can be read 
off by locating the intersection of the log magnitude-phase plot with the 0-dB line. That 
is, the phase margin is the amount of additional negative phase shift required to shift the 
log magnitude-phase curve so that it intersects the 0-dB line with exactly 180° (7T ra-
dians) of phase shift. Similarly, the gain margin is directly obtained from the intersec-
tion of the log magnitude-phase curve with the line -7r radians, and this represents the 
amount of additional gain needed so that the curve crosses the line -7r with a magnitude 
ofO dB. 
The following examples provide several other elementary illustrations of log mag-
nitude-phase diagrams: 

862 
40 
20 
3 
::::: 
OdB 
I 
3 
::::: " 
0 
- 20 
Oi 
..Q 
0 
C\J 
- 40 
- 60 - 2'1T 
3'1T 
- 2 
<t G(jw)H(jw) 
Linear Feedback Systems 
Chap. 11 
Figure 11 .28 
Log magnitude-
phase plot for the system of Exam-
ple 11.9. 
Example 11 . 1 0 
Let 
G(s)H(s) = r s + l , 
7 > 0. 
(11.104) 
40 
20 
3 
Phase margin 
I 
OdB 
3 
::::: " 
0 
- 20 
Oi 
- - ------ -- ---- -- -- :- -- -- - ---~ 
-
..Q 
0 
C\J 
- 40 
-
- 60 L--------L-
1
-------~
1
-------i------~ 
-2'1T 
3'1T 
- 'IT 
0 
- 2 
1:G(jw)H(jw) 
Figure 11 .29 
Log magnitude-phase plot for the first-order system of Ex-
ample 11.10. 

Sec. 11.5 
Gain and Phase Margins 
863 
In this case, we obtain the log magnitude-phase plot depicted in Figure 11.29. This has 
a phase margin of 7T, and since the curve does not intersect the line -7T, the system 
has infinite gain margin (i.e., we can increase the gain as much as we like and maintain 
stability). This is consistent with the conclusion that we can draw by examining the 
system illustrated in Figure 11.30(a). In Figure 11.30(b ), we have depicted the root locus 
for this system with <P = 0 and K > 0. From the figure, it is evident that the system is 
stable for any positive value of K. In addition, if K = 1 and <P = 7T, so that eN = -1, 
the closed-loop system function for the system of Figure 11 .30(a) is l!Ts, which has a 
pole at s = 0, so that the system is unstable. 
+ 
x(t)~ + 
-
K 
(b) 
1 
TS+1 
~ 
(a) 
CRe 
Figure 11 .30 
{a) First-order feedback system with possible gain and 
phase variations in the feedback path; {b) root locus for this system with 
<P = 0, K > 0. 
y(t) 
Example 11 . 11 
Suppose we now consider the second-order system 
1 
H(s) = 
2 
1' 
s + s + 
G(s) =. 1. 
(11.105) 
The system H (s) has an undamped natural frequency of 1 and a damping ratio of 0.5. The 
log magnitude-phase plot for this system is illustrated in Figure 11.31. Again we have in-
finite gain margin, but a phase margin of only 7T/2, since it can be shown by a straightfor-
ward calculation that IH(jw )I = 1 for w = 1, and at this frequency <r:.H(jw) = - 7T/2. 
We can now illustrate the type of problem that can be solved using the concepts 
of gain and phase margins. Suppose that the feedback system specified by eq. (11.105) 
cannot be realized. Rather, some unavoidable time delay is introduced into the feedback 

864 
Linear Feedback Systems 
Chap. 11 
path. That is, 
(11.106) 
where r is the time delay. What we would like to know is how small this delay must be 
to ensure the stability of the closed-loop system. 
40 .--------,--------,--------,--------. 
20 
3 
~ OdB 
3 
C) 
0 
-20 
~ 
0 
C\1 
- 40 
---- --------- --- --,-------
1 
I 
I 
-60 '----------1.---------'----------'----------' 
-2'11' 
0 
<l:G(jw)H(jw) 
Figure 11 .31 
Log magnitude-phase plot for the second-order system of 
Example 11.11. 
The first point to note is that 
(11.107) 
so the delay does not change the magnitude of H (jw )G(jw ). On the other hand, 
<r.e- jwT = -wrradians. 
(11.108) 
Thus, every point on the curve in Figure 11.31 is shifted to the left. The amount of the 
shift is proportional to the value of w for each point on the log magnitude-phase curve. 
From this discussion, we see that instability will occur once the phase margin is 
reduced to zero, and this will happen when the phase shift introduced by the delay is 
equal to - 1r12 at w = 1. That is, the critical value r * of the time delay satisfies 
or (assuming that the units of w are radians/second) 
r * "" 1.57 seconds. 
Thus, for any time delay T < r *, the system remains stable. 
Example 11 . 1 2 
(11.109) 
(11.110) 
Consider again the acoustic feedback system discussed in Section 11.2.6 and Exam-
ple 11.7. Here, we assume that the system of Figure 11.8 has been designed with K 1 K2 < 
1, so that the closed-loop system is stable. In this case, the log magnitude-phase plot for 

Sec. 11.5 
Gain and Phase Margins 
40r------.-------,------,-------r------. 
! 
20 
3 
I 
3 
OdB 
Gain margin 
I 
I 
I 
I 
I 
I 
I 
I 
-
--------------i------------- -i-------
~ 20 log10 (K1K2)-f-------+-:----------; 
t 
:"w=O 
0 
§ 
0 
N 
- 20 
-
I 
I 
I 
- 40~----~------~------~------~----~ 
865 
- 4TI 
-3TI 
-2TI 
-TI 
0 
1:G(jw)H(jw) 
Figure 11 .32 
Log magnitude-phase plot for Example 11 .12. 
G(s)H(s) = K 1K2e -(sT+ j7T) is illustrated in Figure 11.32. From the figure, we see that the 
system has infinite phase margin arid a gain margin in decibels of - 20 log 10 (K1 K2) (i.e., 
this is precisely the gain factor that, when multiplied by K1K2, equals 1). 
As indicated at the start of the section, the definitions of the gain and phase margin 
are the same for discrete-time feedback systems as for continuous-time systems. Specifi-
cally, if we have a stable discrete-time feedback system, the gain margin is the minimum 
amount of additional gain required in the feedback system such that the closed-loop sys-
tem becomes unstable. Similarly, the phase margin is the minimum amount of additional 
negative phase shift required for the feedback system to be unstable. The following ex-
ample illustrates the graphical calculation of phase and gain margins for a discrete-time 
feedback system; the procedure is essentially the same as for continuous-time systems. 
Example 1 1 . 1 3 
In this example, we illustrate the concept of gain and phase margin for the discrete-time 
feedback system shown in Figure 11.33. Here, 
7./i - 1 
--z 
G(z)H(z) = 
4 
, 
(11.111) 
1- 7./iz- ' + ~ z-2 
8 
64 
and by direct calculation we can check that the feedback system is stable for K = 1 
and 4> = 0. In Figure 11.34, we have displayed the log magnitude-phase diagram for 
+ 
1 
x[n] __..... 
y[n] 
+ 
1_ 7v'2 z- 1 + 49 z- 2 
8 
64 
7v'2 - 1 
az -t:J-
K -
Figure 11 .33 
Discrete-time feedback system of Example 11 .13. 

866 
s 
~ 
:X: s 
-~ 
(!) 
0 
Ci 
.Q 
0 
C\1 
Linear Feedback Systems 
Chap. 11 
40.-----------.-----------.-----------r----------, 
20 
OdB 
Phase margin = 0.0685 rad 
rj- --------- ----- ------
Gain margin = 1.68dB 
-20~--------~~----------~----------~--------~ 
-271" 
371" 
- 2 
Figure 1·1 .34 
Log magnitude-phase diagram for the discrete-time feedback 
system of Example 11.13. 
0 
the system; that is, we have plotted 20 log10 IG(ejw)H(ejw)l versus <t.G(ejw)H(ejw) as 
w varies from 0 to 27T. The system has a gain margin of 1.68 dB and a phase margin of 
0.0685 radians (3.93°). 
In concluding this section, it should be stressed that the gain margin is the minimum 
value of gain that moves one or more of the closed-loop poles onto the jw-axis in continu-
ous time or the unit circle in discrete time and, consequently, causes the system to become 
unstable. It is important to note, however, that this does not imply that the system is un-
stable for all values of gain above the value specified by the gain margin. For example, 
as illustrated in Problem 11.47, asK increases, the root locus may move from the left-half 
plane into the right-half plane and then cross back into the left-half plane. The gain margin 
provides us with the information about how much the gain can be increased until the poles 
first reach the jw-axis, but it tells us nothing about the possibility that the system may 
again be stable for even larger values of the gain. To obtain such information, we must 
either refer to the root locus or use the Nyquist stability criterion. (See Problem 11.47.).4 
11 .6 SUMMARY 
In this chapter, we have examined a number of the applications and several techniques for 
the analysis of feedback systems. We have seen how the use of Laplace and z-transforms 
allows us to analyze these systems algebraically and graphically. In Section 11.2 we in-
dicated several of the applications of feedback, including the design of inverse systems, 
4For detailed discussions of this point and also of gain and phase margins and log magnitude-phase 
diagrams in general, see the texts on feedback listed in the bibliography at the end of the book. 

Chap. 11 
Problems 
867 
the stabilization of unstable systems, and the design of tracking systems. We also saw that 
feedback can destabilize, as well as stabilize, a system. 
In Section 11.3, we described the root-locus method for plotting the poles of the 
closed-loop system as a function of a gain parameter. Here, we found that the geometric 
evaluation of the phase of a rational Laplace transform or z-transform allowed us to gain 
a significant amount of insight into the properties of the root locus. These properties of-
ten permit us to obtain a reasonably accurate sketch of the root locus without performing 
complex calculations. 
In contrast to the root-locus method, the Nyquist criterion of Section 11.4 is a tech-
nique for determining the stability of a feedback system, again as a function of a variable 
gain, without obtaining a detailed description of the location of the closed-loop poles. The 
Nyquist criterion is applicable to nonrational system functions and thus can be used when 
all that is available are experimentally determined frequency responses. The same is true of 
the gain and phase margins described in Section 11.5. These quantities provide a measure 
of the margin of stability in a feedback system and therefore are of importance to design-
ers in that they allow them to determine how robust a feedback system is to discrepancies 
between estimates of the forward- and feedback-path system functions and their actual 
values. 
Chapter 11 Problems 
The first section of problems belongs to the basic category, and the answers are pro-
vided in the back of the book. The remaining three sections contain problems belonging 
to the basic, advanced, and extension categories, respectively. 
BASIC PROBLEMS WITH ANSWERS 
11.1. Consider the interconnection of discrete-time LTI systems shown in Figure P11.1. 
Express the overall system function for this interconnection in terms of Ho(z), 
H1 (z), and G(z). 
+ 
·I H1(z) 
+ 
+ 
+ 
-
y[n] 
x[n] 
G(z) 
Figure P11.1 

868 
Linear Feedback Systems 
Chap. 11 
11.2. Consider the interconnection of continuous-time LTI systems shown in Figure 
Pll.2. Express the overall system function for this interconnection in terms of 
H 1(s), H 2(s), G1(s), and G2(s). 
+ 
+ 
x(t) 
+ 
H2(s) 
+ 
H1(s) 
-
-
G1(s) 
G2(s) 
Figure P11.2 
11.3. Consider the continuous-time feedback system depicted in Figure 11.3(a) with 
1 
H(s) = --
s - 1 
and 
G(s) = s- b. 
For what real values of b is the feedback system stable? 
y(t) 
11.4. A causal LTI system S with input x(t) and output y(t) is represented by the differ-
ential equation 
d 2y(t) 
dy(t) 
( ) _ dx(t) 
(ii2 + dt + y t - d(' 
Sis to be implemented using the feedback configuration of Figure 11.3(a) with 
H(s) = ll(s + 1). Determine G(s). 
11.5. Consider the discrete-time feedback system depicted in Figure 11.3(b) with 
1 
H(z) = 1- !z-t 
2 
and 
G(z) = 1- bz- 1• 
For what real values of b is the feedback system stable? 
11.6. Consider the discrete-time feedback system depicted in Figure 11.3(b) with 
H(z) = 1- z- N 
and 
z-t 
G(z) = 1- z-N' 
Is this system IIR or FIR? 
11.7. Suppose the closed-loop poles of a feedback system satisfy 
1 
(s+2)(s+3) 
K' 
Use the root-locus method to determine the values of K for which the feedback 
system is guaranteed to be stable. 

Chap. 11 
Problems 
869 
11.8. Suppose the closed-loop poles of a feedback system satisfy 
s- 1 
1 
(s + 1)(s + 2) 
K. 
Use the root-locus method to determine the negative values of K for which the 
feedback system is guaranteed to be stable. 
11.9. Suppose the closed-loop poles of a feedback system satisfy 
(s + 1)(s + 3) 
1 
(s + 2)(s + 4) 
K. 
Use the root-locus method to determine whether there are any values of the ad-
justable gain K for which the system's impulse response has an oscillatory compo-
nent of the form e - at cos(wot + cf>), where wo ~ 0. 
11.10. The root locus corresponding to G(s)H(s) = -1/K is illustrated in Figure P11.10. 
In this figure, the start (K = 0) and end of each branch of the root locus are marked 
by a 'e' symbol. Specify the poles and zeros of G(s)H(s). 
K>O 
-1 
- j 
K<O 
-1 
Figure P11.10 

870 
Linear Feedback Systems 
Chap. 11 
11.11. Suppose the closed~ loop poles of a discrete-time feedback system satisfy 
z-2 
1 
(1 _ ~z- 1)(1 + ~z- 1) 
- K' 
Using the root-locus method, determine the positive values of K for which this 
system is stable. 
11.12. Each of the four locations z = 112, z = 114, z = 0, and z = - 112 is a single-order 
pole or zero of G(z)H(z). Furthermore, G(z)H(z) is known to have only two poles. 
What information can you deduce about the poles and zeros of G(z)H(z) from the 
fact that for all K, the root locus corresponding to 
G(z)H(z) = 
is on the real axis. 
1 
K 
11.13. Consider the block diagram of Figure Pl1.13 for a discrete-time system. Use the 
root-locus method to determine the values of K for which the system is guaranteed 
to be stable. 
x[n] 
1---.....,.--""T'"---• y[n] 
D 
+~--.---+--~ 
D 
4 
K 
Figure P11.13 
11.14. Let C be a closed path that lies on the unit circle in the p-plane and that is traversed 
in the clockwise direction in order to evaluate W(p). For each of the following 
expressions for W (p ), determine the net number of times the plot of W (p) encircles 
the origin in a clockwise direction: 
(a) W(p) = (1-!p- 1) 
(1-!p- 1) 
(b) W( ) 
(l-2p- ll 
p = -( 1-- -,-i p-_--"'1 );;_(l-=-.L2p-_"-cl -+ 4_p __ 2::-) 

Chap. 11 
Problems 
871 
11.15. Consider a continuous-time feedback system whose closed-loop poles satisfy 
1 
1 
G(s)H(s) = (s + l) = - K" 
Use the Nyquist plot and the Nyquist stability criterion to determine the range 
of values of K for which the closed-loop system is stable. Hint: In sketching the 
Nyquist plot, you may find it useful to sketch the corresponding Bode plot first. It 
also is helpful to determine the values of w for which G(jw )H (jw) is real. 
11.16. Consider a continuous-time feedback system whose closed-loop poles satisfy 
1 
1 
G(s)H(s) = (s + l)(s/10 + 1) = - K" 
Use the Nyquist plot and the Nyquist stability criterion to determine the range of 
values of K for which the closed-loop system is stable. 
11.17. Consider a continuous-time feedback system whose closed-loop poles satisfy 
1 
1 
G(s)H(s) = (s + 1)4 
K" 
Use the Nyquist plot and the Nyquist stability criterion to determine the range of 
values of K for which the closed-loop system is stable. 
11.18. Consider a discrete-time feedback system whose closed-loop poles satisfy 
G(z)H(z) = z- 3 = - ~-
Use the Nyquist plot and the Nyquist stability criterion to determine the range of 
values-of K for which the closed-loop system is stable. 
11.19. Consider a feedback system, either in continuous-time or discrete-time, and sup-
pose that the Nyquist plot for the system passes through the point -1/K. Is the 
feedback system stable or unstable for this value of the gain? Explain your answer. 
11.20. Consider the basic continuous-time feedback system of Figure 11.3(a). Determine 
the phase and gain margin for the following specification of H(s) and G(s): 
s+l 
H(s) = 
2 
1, 
G(s) = 1. 
s + s + 
BASIC PROBLEMS 
11.21. Consider the feedback system of Figure P11.21. Find the closed-loop poles and 
zeros of this system for the following values of K: 
(i) 
K = 0.1 
(ii) K = 1 
(iii) K = 10 
(iv) K = 100 

872 
Linear Feedback Systems 
Chap. 11 
+ 
x(t) -----t~ 
1----..--.... y(t) 
s+1 
s+100 
Figure P11.21 
11.22. Consider the basic feedback system of Figure 11.3(a). Determine the closed-loop 
system impulse response for each of the following specifications of the system 
functions in the forward and feedback paths: 
(a) H(s) = (s+l;(s+3)' G(s) = 1 
(b) H(s) = si3 , G(s) = sii 
(c) H(s) = ~. G(s) = e - s/3 
11.23. Consider the basic feedback systems of Figure ll.3(b). Determine the closed-loop 
system impulse response for each of the following specifications of the system 
functions in the forward and feedback paths: 
( ) H( ) _ 
z- 1 
G( ) _ 2 _ 
I - 1 
a 
z -
1- ! z-1, 
z -
3 
6z 
2 
(b) H(z) = ~- ~z-
1
, G(z) = 
1_zl:-1 
2 
11.24. Sketch the root loci for K > 0 and K < 0 for each of the following: 
(a) G(s)H(s) = si 1 
(b) G(s)H(s) = (s-l)l(s +3) 
(c) G(s)H(s) = s2 +~+l 
(d) G(s)H(s) = ~ 
s 
(e) G(s)H(s) = (s:3
1)
2 
(f) G(s)H(s) = s
2 +2s+ 2 
s2(s- l) 
(g) G(s)H(s) = (s+l)(s- 1) 
s(s2 +2s+2) 
(h) G(s)H(s) = (sJ~)(;l3 ) 
11.25. Sketch the root loci for K > 0 and K < 0 for each of the following: 
(a) G(z)H(z) = z;-=_
1
~_ 
4 
(b) G(z)H(z) = z2 ~! 
4 
(c) G(z)H(z) = z-
1<1tz-
1
) 
l - 4z 2 
(d) G(z)H(z) = z- 1 - z-2 
(e) G(z)H(z) is the system function of the causal LTI system described by the 
difference equation 
y[n] - 2y[n - 1] = x[n - 1] - x[n - 2]. 

Chap. 11 
Problems 
873 
11.26. Consider a feedback system with 
G(s)H(s) = (s- a)(s- b) 
s(s + 3)(s + 6) 
Sketch the root locus for K > 0 and K < 0 for the following values of a and b: 
(a) a = 1, 
b = 2 
(b) a = - 2, 
b = 2 
(c) a = -4, 
b = 2 
(d)a=-7, b=2 
(e) a= - 1, 
b=-2 
(t) a=-4, b=-2 
(g) a = -7, 
b = -2 
(h) a = - 5, 
b = -4 
(i) a = -7, 
b = - 4 
(j) a = -7, 
b = -8 
11.27. Consider a feedback system with 
s+2 
H(s) = 
2 
2 
4, 
G(s) = K. 
s + s + 
(a) Sketch the root locus for K > 0. 
(b) Sketch the root locus forK < 0. 
(c) Find the smallest positive value of K for which the closed-loop impulse re-
sponse does not exhibit any oscillatory behavior. 
11.28. Sketch the Nyquist plot for each of the following specifications of G(s)H(s), and 
use the continuous-time Nyquist criterion to determine the range of values of K (if 
any such range exists) for which the closed-loop system is stable. Note: In sketch-
ing the Nyquist plots, you may find it useful to sketch the corresponding Bode plots 
first. It also is helpful to determine the values of w for which G(jw )H(jw) is real. 
(a) G(s)H(s) = s~l 
(b) G(s)H(s) = s2 ~ 1 
(c) G(s)H(s) = (s+'l)2 
(d) G(s)H(s) = (s1\
3 
(e) G(s)H(s) = (};tl2 
(t) G(s)H(s) = 
(:~/l2 
(g) G(s)H(s) = ~:2":_~ 
(h) G(s)H(s). = s2+~+ 2 
(i) G(s)H(s) = s2 ~;s
1
+ 2 
(j) G(s)H(s) = (s+l~~ls - l)2 
s2 
(k) G(s)H(s) = (s+l)3 
11.29. Consider the basic continuous-time feedback system of Figure 11.3(a). Sketch the 
log magnitude-phase diagram, and roughly determine the phase and gain margin, 
for each of the following choices of G(s) and H(s). You may find it useful to use 
the straight-line approximations to the Bode plots developed in Chapter 6 to aid 
you in sketching the log magnitude-phase diagrams. Be careful, however, to take 
into account how the actual frequency response deviates from its approximation 
near break frequencies when there are underdamped second-order terms present. 
(See Section 6.5.2.) 
(a) H(s) = lOs+ 1 G(s) = 1 
s2+s+ l' 
(b) H(s) = silO+ 1 G(s) = 1 
s2+s+ I' 
(c) H(s) = (s+l)2~s+IO)' G(s) = 100 
(d) H(s) = (s+' l)3 , G(s) = s~ 1 
(e) H(s) = (s+ 1\(s: tO), G(s) = 1 

874 
(f) H(s) = 1- s/100 G(s) = IOs+ l 
(s+'i')i"'' 
s/ I 0+ I 
(g) H(s) = 
s(s~ I)' G(s) = 
s~ I 
Linear Feedback Systems 
Chap. 11 
Note: Your sketch for part (g) should reflect the fact that for this feedback 
system IG(jw )H(jw )I ~ oo as w ~ 0; what is the phase of G(jw )H(jw) for 
w = o+' i.e., for w an infinitesimal amount larger than 0? 
11.30. Sketch the Nyquist plot for each of the following specifications of G(z)H(z), and 
use the discrete-time Nyquist criterion to determine the range of values of K (if any 
such range exists) for which the closed-loop system is stable. [Note: In sketch-
ing the Nyquist plots, you may find it useful to first sketch the magnitude and 
phase plots as a function of frequency or at least calculate IG(ejw)H(ejw)l and 
<r.G(ejw)H(ejw) at several points. Also, it is helpful to determine the values of w 
for which G(ejw)H(ejw) is real.] 
(a) G(z)H(z) = ~ 
(b) G(z)H(z) = 
z~2 
2 
(c) G(z)H(z) = z- 1 
(d) G(z)H(z) = z- 2 
(e) G(z)H(z) = (z+1)1(z-il 
(f) G(z)H(z) = 
z(zz;;f~) 
(g) G(z)H(z) = zL~+l 
(h) G(z)H(z) = z~z~A) 
3 
(i) G(z)H(z) = ~ 
z 
11.31. Consider the basic discrete-time system in Figure 11.3(b ). Sketch the log magnitude-
phase diagram, and roughly determine the phase and gain margin, for each of the 
following choices of G(z) and H(z). You may find it useful to determine the values 
of w for which either IG(ejw)H(ejw)l = 1 or <r.G(ejw) = -7T. 
(a) H(z) = z- 1, G(z) = i 
- 1 
I 
(b) H(z) = 
1 _\- ~, G(z) = 2 
2 
(c) H(z) = (l - }z- 1l
1
(1+1c 1l, G(z) = z- 2 
(d) H(z) = z_:2 , G(z) = 1 
(e) H(z) = ~. G(z) = -:-4 
z+ 2 
z- 2 
(f) H(z) = ~. G(z) = 1- ~z-
1 
z+ 2 
I 
(g) H(z) = zL~+l, G(z) = 1 
3 
(h) H(z) = 
z~l, G(z) = ~z-
1 
(Note: Your sketch for part (h) should reflect the fact that, for this feedback system, 
G(z)H(z) has a pole at z = 1; what are the values of <r.G(ejw)H(ejw) for ejw just 
on either side of the point z = 1 ?) 
ADVANCED PROBLEMS 
11.32. (a) Consider the feedback system of Figure 11.10(b) with 
H( ) = N1(s) 
s 
D1(s)' 
(P11.32-1) 

Chap. 11 
Problems 
875 
Assume that there is no pole-zero cancellation in the product G(s)H(s). Show 
that the zeros of the closed-loop system fl.mction consist of the zeros of H(s) 
and the poles of G(s). 
(b) Use the result of part (a) together with the appropriate property of the root 
locus to confirm that, with K = 0, the closed-loop system zeros are the zeros 
of H(s) and the closed-loop poles are the poles of H(s). 
(c) While it is usual for H(s) and G(s) in eq. (Pll.32-1) to be in reduced form 
[i.e., the polynomials N 1 (s) and D 1 (s) have no common factors, and the same 
is true of N2(s) and D2(s)], it may happen that N 1 (s) and D2(s) have common 
factors or N2(s) and D 1 (s) have common factors. To see what occurs when 
such common factors are present, let p(s) denote the greatest common factor 
of N1(s) and D 2(s). That is, 
N 1(s) 
p(s) 
and 
are both polynomials and have no common factors. Similarly, 
and 
D 1(s) 
q(s) 
are polynomials and have no common factors. Show that the closed-loop sys-
tem function can be written as 
where 
and 
(s) = p(s) [ 
H(s) l 
Q 
q(s) 1 + KG(s)H(s) ' 
H(s) = N 1(s)lp(s) 
D 1 (s)lq(s) 
G(s) = N2(s)/q(s). 
D2(s)/p(s) 
(P11.32-2) 
Therefore, from eq. (P11.32-2) and part (a), we see that the zeros of Q(s) are 
the zeros of p(s), the zeros of H(s), and the poles of G(s), while the poles of 
Q(s) are the zeros of q(s) and the solutions of 
1 + KG(s)H(s) = 0. 
(Pll.32-3) 
By construction, there is no pole-zero cancellation in the product G(s)H(s), and 
thus, we can apply the root-locus method described in Section 11.3 to sketch 
the locations of the solutions of eq. (Pll.32-3) asK is varied . . 
(d) Use the procedure outlined in part (c) to determine the closed-loop zeros, any 
closed-loop poles whose locations are independent of K, and the locus of the 
remaining closed-loop poles for K > 0 when 
s + 1 
H(s) = (s + 4)(s + 2)' 
G(s) = s + 21' 
s+ 

876 
(e) Repeat part (d) for 
(t) Let 
1 + z- 1 
H(z) = ---,-----
1- ! z- 1' 
2 
Linear Feedback Systems 
z- 1 
G(z) = 1 + z-1 . 
z2 
H(z) = (z- 2)(z + 2)' 
1 
G(z) = 2 . 
z 
(i) 
Sketch the root locus for K > 0 and for K < 0. 
(ii) Find all the values of K for which the overall system is stable. 
Chap. 11 
(iii) Find the impulse response of the closed-loop system when K = 4. 
11.33. Consider the feedback system of Figure 11.10(a), and suppose that 
Ill n (s- f3.k) 
G(s)H(s) = .:.:...,
k :,-:1---
n<s- ak) 
k = l 
where m > n.5 In this case G(s)H(s) has m- n poles at infinity (see Chapter 9), 
and we can adapt the root-locus rules given in the text by noting that (1) there are 
m branches of the root locus and (2) forK = 0, all branches of the root locus begin 
at poles of G(s)H(s), m- n of which are at infinity. Furthermore, as IKI ~ oo, these 
branches converge to them zeros of G(s)H(s), namely, {31, {32, ••• , {3111 • Use these 
facts to assist you in sketching the root locus (for K > 0 and for K < 0) for each 
of the following: 
(a) G(s)H(s) = s - 1 
(b) G(s)H(s) = (s + 1)(s + 2) 
(c) G(s)H(s) = 
(s +;~~+Z) 
11.34. In Section 11.3, we derived a number of properties that can be of value in deter-
mining the root locus for a feedback system. In this problem, we develop several 
additional properties. We derive these properties in terms of continuous-time sys-
tems, but, as with all root-locus properties, they hold as well for discrete-time root 
loci. For our discussion of these properties, we refer to the basic equation satisfied 
by the closed-loop poles, namely, 
G(s)H(s) = 
K' 
(P11.34-1) 
5Note that for a continuous-time system, the condition m > n implies that the system with system func-
tion G(s)H(s) involves differentiation of the input. [In fact, the inverse transform of G(s)H(s) includes singu-
larity functions up to the order m - n.] In discrete time, if G(z)H(z), written as a ratio of polynomials in z, has 
m > n, it is necessarily the system function of a noncausal system. [In fact, the inverse transform of G(z)H(z) 
has a nonzero value at time n - m < 0.] Thus, the case considered in this problem is actually of interest only 
for continuous-time systems. 

Chap. 11 
Problems 
where 
m 
[1<s- f3k) 
G(s)H(s) = _k~-
1 
1---
[1<s- ak) 
k=1 
s 
Throughout this problem, we assume that m s; n. 
877 
(Pl1.34-2) 
Figure P11.34 
(a) From Property·2, we know that n- m branches of the root locus go to ze-
ros of G(s)H(s) located at infinity. In this first part, we demonstrate that it is 
straightforward to determine the angles at which these branches approach in-
finity. Specifically, consider searching the remote part of the s-plane [i.e., the 
region where lsi is extremely large and far from any of the poles and zeros of 
G(s)H(s)]. This region is illustrated in Figure P11.34. Use the geometry of the 
picture, together with the angle criterion for K > 0 and for K < 0, to deduce 
that: 
• For K > 0, the n - m branches of the root locus that approach infinity do so 
at the angles 
(2k + 1)7T 
k = 0, 1, ... , n - m - 1. 
n-m 

878 
Linear Feedback Systems 
Chap. 11 
• For K < 0, the n - m branches of the root locus that approach infinity do so 
at the angles 
2k7r 
k = 0, 1, . .. , n - m - 1. 
n-m' 
Thus, the branches of the root locus that approach infinity do so at specified angles 
that are arranged symmetrically. For example, for n - m = 3 and K ::> 0, we see 
thatthe asymptotic angles are 7r/3, 71", and 57r/3. The result of part (a), together with 
one additional fact, allows us to draw in the asymptotes for the branches of the root 
locus that approach infinity. Specifically, all of the n - m asymptotes intersect at a 
single point on the real axis. This is derived in the next part of the problem. 
(b) (i) 
As a first step, consider a general polynomial equation 
sr+fr- !Sr- l +···+fo = (s-t",)(s - b)···(s - t"r) = 0. 
Show that 
r 
fr- 1 =
- Lt"i· 
i = l 
(ii) Perform long division on 1/G(s)H(s) to write 
1 
n- m 
n-m-1 
(Pll 34-3) 
G(s)H(s) = S 
+ 'Yn- m- IS 
+ · · · · 
· 
Show that 
m 
n 
'Yn- m- 1 = an- I -
bm- 1 = L f3k- L ak. 
k=l 
k = l 
[See eq. (Pll.34-2).] 
(iii) Argue that the solution of eq. (Pll.34-1) for large sis an approximate 
solution of the equation 
sn- m + 'Yn- m- JSn - m- 1 + 'Yn - m- 2Sn- m- 2 + . .. +'Yo+ K = 0. 
(iv) Use the results.of (i)-(iii) to deduce that the sum of then- m closed-loop 
poles that approach infinity is asymptotically equal to 
Thus, the center of gravity of these n - m poles is 
bm-1 -an- I 
n - m 
which does not depend on K. Consequently, we haven- m closed-loop 
poles that approach lsi = oo at evenly spaced angles and that have a center 
of gravity that is independent of K. From this, we can deduce that: 

Chap. 11 
Problems 
879 
The asymptotes of the n- m branches of the root locus that approach 
infinity intersect at the point 
n 
m 
2.:>~k - "2.!3k 
k= J 
k=J 
n-m 
This point of intersection of the asymptotes is the same for K > 0 and 
K<O. 
(c) Suppose that 
1 
G(s)H(s) = (s + l)(s + 3)(s + 5) 
(i) 
What are the asymptotic angles for the closed-loop poles that approach 
infinity for K > 0 and for K < 0? 
(ii) What is the point of intersection of the asymptotes? 
(iii) Draw in the asymptotes, and use them to help you sketch the root locus 
for K > 0 and for K < 0. 
(d) Repeat part (c) for each of the following: 
(i) 
G(s)H(s) = s(s:2~(~+4) 
(ii) 
G(s)H(s) = ~ 
(iii) G(s)H(s) = ....,....,...,..,..,.-'
1~"":"A' 
s(s+ l)(s+5)(s+6) 
(iv) G(s)H(s) = (s+2)2
1(s- l)2 
( v) 
G ( s )H ( s) = -;-(s .,...+ 1;'7lc"':;c..::~-;;-2s-:-+=
2) 
(vi) G(s)H(s) = .,...(s-,+2"")2.=7(s..;,i.:..,~2"""s-+2=) 
(vii) G(s)H(s) = (s+IOO~;~J)(s-2) 
(e) Use the result of part (a) to explain why the following statement is true: For 
any continuous-time feedback system, with G(s)H(s) given by eq. (Pll.34--
2), if n - m ;:::: 3, we can make the closed-loop system unstable by choosing 
jKjlarge enough. 
(f) Repeat part (c) for the discrete-time feedback system specified by 
z-3 
G(z)H(z) = 
. 
(1- z-')(1 + 4z- ') 
(g) Explain why the following statement is true: For any discrete-time feedback 
system with 
if n > m, we can make the closed-loop system unstable by choosing jKjlarge 
enough. 
11.35. (a) Consider again the feedback system of Example 11.2: 
s-1 
G(s)H(s) = (s + 1)(s + 2) 

880 
Linear Feedback Systems 
Chap. 11 
The root locus forK< 0 is plotted in Figure 11.14(b). For some value of K, 
the closed-loop poles are on the jw-axis. Determine this value of K and the 
corresponding locations of the closed-loop poles by examining the real and 
imaginary parts of the equation 
G(jw)H(jw) = - ~' 
which must be satisfied if the point s = jw is on the root locus for any given 
values of K. Use this result plus the analysis in Example 11.2 to find the full 
range of values of K (positive and negative) for which the closed-loop system 
is stable. 
(b) Note that the feedback system is unstable for IKI sufficiently large. Explain 
why this is true in general for continuous-time feedback systems for which 
G(s)H(s) has a zero in the right-half plane and for discrete-time feedback sys-
tems for which G(z)H(z) has a zero outside the unit circle. 
11.36. Consider a continuous-time feedback system with 
1 
G(s)H(s) = s(s + 1)(s + 2) 
(P11.36-l) 
(a) Sketch the root locus for K > 0 and forK < 0. (Hint: The results of Problem 
11.34 are useful here.) 
(b) If you have sketched the locus correctly, you will see that for K > 0, two 
branches of the root locus cross the jw-axis, passing from the left-half plane 
into the right-half plane. Consequently, we can conclude that the closed-loop 
system is stable for 0 < K < K0, where K0 is the value of the gain for which 
the two branches of the root locus intersect the jw-axis. Note that the sketch 
of the root locus does not by itself tell us what the value of Ko is or the exact 
point on the jw-axis where the branches cross. As in Problem 11.35, deter-
mine K0 by solving the pair of equations obtained as the real and imaginary 
parts of 
G(jw)H(jw) = - ~
0
• 
(P11.36-2) 
Determine the corresponding two values of w (which are the negatives of each 
other, since poles occur in complex-conjugate pairs). 
From your root-locus sketches in part (a), note that there is a segment 
of the real axis between two poles which is on the root locus for K > 0, and 
a different segment is on the locus for K < 0. In both cases, the root locus 
breaks off from the real axis at some point. In the next part of this problem, we 
illustrate how one can calculate these breakaway points. 
(<:) Consider the equation denoting the closed-loop poles: 
G(s)H(s) = 
1 
K' 
(P11.36-3) 

Chap. 11 
Problems 
881 
s 
IC2S==t', 
I 
' 
I 
(b) 
' 
s 
Figure P11.36 
Using eq. (P11.36-1), show that an equivalent equation for the closed loop 
poles is 
p(s) = s3 + 3s2 + 2s = - K. 
(P11.36-4) 
Consider the segment of the real axis between 0 and - 1. This segment is on 
the root locus for K 2: 0. For K = 0, two branches of the locus begin at 0 and 
- 1 and approach each other as K is increased. 
(i) 
Use the facts stated, together with eq. (P11.36-4), to explain why the 
function p(s) has the form shown in Figure P11.36(a) for -1 :s s :s 0 
and why the points+ where the minimum occurs is the breakaway point 
(i.e., it is the point where the two branches of the K > 0 locus break from 
the segment of the real axis between -1 and 0). 
Similarly, consider the root locus forK < 0 and, more specifically, 
the segment ofthe real axis between -1 and -2 that is part of this locus. 
ForK = 0, two branches of the root locus begin at -1 and -2, and asK 
is decreased, these poles approach each other. 
(ii) In an analogous fashion to that used in part (i), explain why the function 
p(s) has the form shown in Figure P11.36(b) and why the points- where 
the maximum occurs is the breakaway point for K < 0. 
Thus, the breakaway points correspond to the the maxima and min-
ima of p(s) ass ranges over the negative real line. 
(iii) The points at which p(s) has a maximum or minimum are the solutions 
of the equation 
dp(s) = 0 
ds 
· 
Use this fact to find the breakaway points s+ and s- , and then use eq. 
(P11.36-4) to find the gains at which these points are closed-loop poles. 
In addition to the method illustrated in part (c), there are other, partially 
analytical, partially graphical methods for determining breakaway points. It is also 
possible to use a procedure similar to the one just illustrated in part (c) to find the 

882 
Linear Feedback Systems 
Chap. 11 
"break-in" points, where two branches of the root locus merge onto the real axis. 
These methods plus the one illustrated are described in advanced texts such as 
those listed in the bibliography at the end of the book. 
11.37. One issue that must always be taken into account by the system designer is the 
possible effect of unmodeled aspects of the system one is attempting to stabilize or 
modify through feedback. In this problem, we provide an illustration of why this 
is the case. Consider a continuous-time feedback system, and suppose that 
1 
H(s) = (s + lO)(s- 2) 
(P11.37- 1) 
and 
G(s) = K. 
(P11.37-2) 
(a) Use root-locus techniques to show that the closed-loop system will be stable if 
K is chosen large enough. 
(b) Suppose that the system we are trying to stabilize by feedback actually has a 
system function 
1 
H(s) = 
· 
(s + 10)(s - 2)(10- 3s + 1) 
\Pl1.37- 3) 
The added factor can be thought of as representing a first-order system in cas-
cade with the system of eq. (P11.37- 1). Note that the time constant of the 
added first order system is extremely small and thus will appear to have a step 
response that is almost instantaneous. For this reason, one often neglects such 
factors in order to obtain simpler and more tractable models that capture all of 
the important characteristics of the system. However, one must still keep these 
neglected dynamics in mind in obtaining a useful feedback design. To see why 
this is the case, show that if G(s) is given by eq. (P11.37-2) and H(s) is as in 
eq. (P11.37-3), then the closed-loop system will be unstable if K is chosen too 
large. Hint: See Problem 11.34. 
(c) Use root-locus techniques to show that if 
G(s) = K(s + 100), 
then the feedback system will be stable for all values of K sufficiently large if 
H(s) is given by eq. (P11.37- 1) or eq. (P11.37- 3). 
11.38. Consider the feedback system of Figure 11.3(b) with 
Kz- 1 
H(z) = 1 - z-1 
and 
G(z) = 1- az- 1• 
(a) Sketch the root locus for K > 0 and K < 0 when a = 112. 
(b) Repeat part (a) when a = -112. 

Chap. 11 
Problems 
883 
(c) With a = - 1/2, find a value of K for which the closed-loop impulse response 
is of the form 
(A+ Bn)a
11 
for some values of the constants A, B, and a, with Ia! < 1. (Hint: What must 
the denominator of the closed-loop system function look like in this case?) 
11.39. Consider the feedback system of Figure P11.39 with 
1 
H(z) = 1 _ .!.z- I, 
G(z) = K. 
2 
(P11.39-1) 
x[n] ~ 
e[n] 
H(z) 
y[n) 
-
G(z) 
Figure P11.39 
(a) Plot the root locus forK > 0. 
(b) Plot the root locus forK < 0. (Note: Be careful with this root locus. By ap-
plying the angle criterion on the real axis, you will find that as K is decreased 
from zero, the closed loop approaches z = +oo along the positive real axis and 
then returns along the negative real axis from z = - oo. Check that this is in 
fact the case by explicitly solving for the closed-loop pole as a function of K . 
At what value of K is the pole at lzl = oo?) 
(c) Find the full range of values of K for which the closed-loop system is stable. 
(d) The phenomenon observed in part (b) is a direct consequence of the fact that 
in this example the numerator and denominator of G(z)H(z) have the same 
degree. When this occurs in a discrete-time feedback system, it means that 
there is a delay-free loop in the system. That is, the output at a given point in 
time is being fed back into the system and in tum affects its own value at the 
same point in time. To see that this is the case in the system we are considering 
here, write the difference equation relating y[n] and e[n]. Then write e[n] in 
terms of the input and output for the feedback system. Contrast this result with 
that of the feedback system with 
1 
H(z) = 
1 
1 _
1
, 
G(z) = Kz- 1• 
- 2z 
(P11.39- 2) 
The primary consequence of having delay-free loops is that such feed-
back systems cannot be implemented in the form depicted. For example, 
for the system of eq. (P11.39-1), we cannot first calculate e[n] and then y[n], 

x[n] 
884 
Linear Feedback Systems 
Chap. 11 
because e[n] depends on y[n] . Note that we can perform this type of calcula-
tion for the system of eq. (P11.39-2), since e[n] depends on y[n- 1]. 
(e) Show that the feedback system of eq. (P11.39- 1) represents a causal system, 
except for the value of K for which the closed-loop pole is at lzl = oo. 
11.40. Consider the discrete-time feedback system depicted in Figure P11.40. The system 
in the forward path is not very well damped, and we would like to choose the 
feedback system function so as to improve the overall damping. By using the root-
locus method, show that this can be done with 
G(z) = 1 -
~ z-
1
• 
1 
+ 
K(z - 4) 
--+ 
z2- 7v'2 z + 49 
y[n] 
-
8 
64 
G(z) 
Figure P11.40 
Specifically, sketch the root locus for K > 0, and specify the value of the gain K 
for which a significant improvement in damping is obtained. 
11.41. (a) Consider a feedback system with 
H(z) = 
z + 1 
, 
z2 + z +! 
4 
K 
G(z) = -. 
z - 1 
(i) 
Write the closed-loop system function explicitly as a ratio of two polyno-
mials. (The denominator polynomial will have coefficients that depend 
onK.) 
(ii) Show that the sum of the closed-loop poles is independent of K . 
(b) More generally, consider a feedback system with system function 
Show that if m :5 n - 2, the sum of the closed-loop poles is independent of K. 
11.42. Consider again the discrete-time feedback system of Example 11.3: 
z 
G(z)H(z) = 
1 
1 . 
(z -
2)(z- 4) 
The root loci forK > 0 and K < 0 are depicted in Figure 11.16. 

Chap. 11 
Problems 
885 
(a) Consider the root locus for K > 0. In this case, the system becomes unstable 
when one of the closed-loop poles is less than or equal to -1. Find the value 
of K for which z = -1 is a closed-loop pole. 
(b) Consider the root locus forK < 0. In this case, the system becomes unstable 
when one of the closed-loop poles is greater than or equal to 1. Find the value 
of K for which z = 1 is a closed-loop pole. 
(c) What is the full range of values of Kfor which the closed-loop system is stable? 
11.43. Consider a discrete-time feedback system with 
1 
G(z)H(z) = z(z _ 1) 
(a) Sketch the root locus forK> 0 and forK< 0. 
(b) If you have sketched the root locus correctly forK > 0, you will see that the 
two branches of the root locus cross and exit from the unit circle. Consequently, 
we can conclude that the closed-loop system is stable for 0 < K < K0, where 
Ko is the value of the gain for which the two branches intersect the unit circle. 
At what points on the unit circle do the branches exit from it? What is the value 
of Ko? 
11.44. As mentioned in Section 11.4, the continuous-time Nyquist criterion can be ex-
tended to allow for poles of G(s)H(s) on the jw-axis. In this problem, we will 
illustrate the general technique for doing this by means of several examples. Con-
sider a continuous-time feedback system with 
1 
G(s)H(s) = s(s + 1) 
(P11.44-l) 
When G(s)H(s) has a pole at s = 0, we modify the contour of Figure 11.19 by 
avoiding the origin. To do this, we indent the contour by adding a semicircle of 
infinitesimal radius € into the right-half plane. [See Figure P11.44(a).] Thus, only 
a small part of the right-half plane is not enclosed by the modified contour, and 
its area goes to zero as we let € ~ 0. Consequently, as M ~ oo, the contour will 
enclose the entire right -half plane. As in the text, G(s )H (s) is a constant (in this case 
zero) along the circle of infinite radius. Thus, to plot G(s)H(s) along the contour, 
we need only plot it for the portion of the contour consisting of the jw-axis and the 
infinitesimal circle. 
(a) Show that 
7T 
2 
and 
where s = jO- is the point where the infinitesimal semicircle meets the jw-
axis just below the origin and s = jO+ is the corresponding point just above 
the origin. 
(b) Use the result of part (a) together with eq. (P11.44-1) to verify that Figure 
P11.44(b) is an accurate sketch of G(s)H(s) along the portions of the contour 

(a) 
t w = o-
w = :!: oo 
~ w=O+ 
(b) 
Figure P11.44 
886 

Chap. 11 
Problems 
887 
from- joo to jO- and jO+ to joo. In particular, check that <'J.G(jw )H(jw) and 
IG(jw )H (jw )I behave in the manner depicted in the figure. 
(c) All that remains to be done is to determine the plot of G(s)H(s) along the 
small semicircle about s = 0. Note that as e ---'» 0, the magnitude of G(s)H(s) 
along this contour goes to infinity. Show that as € ---'» 0, the contribution of the 
pole at s = -1 to <'J.G(s)H(s) along the semicircle is zero. Then show that as 
E
---'» 0, 
<tG(s)H(s) = -0, 
where(} is as defined in Figure P1 1.44(a). Thus, since 0 varies from - TT/2 at 
s = jO- to +TT/2 at s = }0- in the counterclockwise direction, <'J.G(s)H(s) 
must go from + TT/2 at s = }0+ to - 7T/2 at s = jO+ in the clockwise direction. 
The result is the complete Nyquist plot depicted in Figure Pll.44(c). 
(c) 
Figure P11.44 
Continued 

888 
Linear Feedback Systems 
Chap. 11 
(d) Using the Nyquist plot of Figure P11.44(c), find the range of values of K 
for which the closed-loop feedback system is stable. (Note: As presented in 
the text, the continuous-time Nyquist criterion states that, for closed-loop sys-
tem stability, the net number of clockwise encirclements of the point - 11 K 
must equal minus the net number of right-half plane poles of G(s)H(s). In the 
present example, note that the pole of G(s)H(s) at s = 0 is outside the modi-
fied contour. Consequently, it is not included in counting the poles of G(s)H(s) 
in the right-half plane [i.e., only poles of G(s)H(s) strictly inside the right-half 
plane are counted in applying the Nyquist criterion]. Thus, in this case, since 
G(s)H(s) has no poles strictly inside the right-half plane, we must have no 
encirclements of the points = - 11 K for closed-loop system stability.) 
(e) Follow the steps outlined in parts (a)- ( c) to sketch the Nyquist plots for each 
of the following: 
(i) 
G(s)H(s) = (silO)+ 1 
s(s+ I) 
(ii) G(s)H(s) = s(s~ 112 
(iii) G(s)H(s) = ~ [be careful in calculating 4:G(s)H(s) along the infinites-
imal semicircle] 
(iv) G(s)H(s) = s(t_1s) [be careful in calculating <J:.G(jw )H(jw) as w is var-
ied; make sure to take the minus sign in the denominator into account] 
(v) G(s)H(s) = s~ t [same remark as for (iii)] 
s 
In each case, use the Nyquist criterion to determine the range of values of K 
(if any such range exists) for which the closed-loop system is stable. Also, use 
another method (root locus or direct calculation of the closed-loop poles as a 
function of K) to provide a partial check of the correctness of your Nyquist 
plot. [Note: In sketching the Nyquist plots, you may find it useful to sketch the 
Bode plots of G(s)H(s) first. It may also be helpful to determine the values of 
w for which G(jw)H(jw) is real.] 
(f) Repeat part (e) for: 
(i) 
G(s)H(s) = s2 ~ 1 
(ii) G(s)H(s) = :z:\ 
Note: In these cases there are two poles on the imaginary axis; accordingly, 
you will need to modify the contour of Figure 11.19 to avoid each of them. 
Use infinitesimal semicircles, as in Figure P11.44(a). 
11.45. Consider a system with system function 
H(s) = (s + l)
1
(s _ 2) 
(Pll.45-l) 
Because this system is unstable, we would like to devise some method for its sta-
bilization. 
(a) Consider first a series compensation scheme as illustrated in Figure Pll.45(a). 
Show that the overall system of this figure is stable if the system function 
s-2 
C(s) = s + 3' 
In practice, this is not considered to be a particularly useful way to attempt to 
stabilize a system. Explain why. 

Chap. 11 
Problems 
889 
x(t) ---.•~1 C(s) 1---!•~ 1 
H(s) 1---!·~ y(t) 
(a) 
--~+ f":"'\ 
+ 
x(t) 
V 
C(s) 
H(s) 
y(t) 
-
(b) 
Figure P11.45 
(b) Suppose that instead we use a feedback system, as depicted in Figure P11.45(b ). 
Is it possible to stabilize this system using a constant gain, that is, 
C(s) = K, 
for the stabilizing element? Justify your answer using Nyquist techniques. 
(c) Show that the system of Figure Pl1.45(b) can be stabilized if C(s) is a propor-
tional plus derivative system-
that is, if 
C(s) = K(s + a). 
Consider both the case 0 < a < 1 and the case a > 1. 
(d) Suppose that 
C(s) = K(s + 2). 
Choose the value of K such that the closed-loop system has a pair of complex 
poles with a damping ratio ~ = 1/2. (Hint: In this case, the denominator of the 
closed-loop system must have the form 
2 
2 
S + W 11S + W 11 
for some value of Wn > 0.) 
(e) Pure derivative compensation is both impossible to obtain and undesirable in 
practice. This is because the required amplification of arbitrarily high frequen-
cies neither can be obtained nor is advisable, as all real systems are subject to 
some level of high-frequency disturbances. Thus, suppose that we consider a 
compensator of the form 
C(s) = KG : :} a, b > 0. 
(Pl1.45-2) 

890 
Linear Feedback Systems 
Chap. 11 
If b < a, this is a lag network: <r.C(jw) < 0 for all w > 0, so that the phase 
of the output of the system lags the phase of the input. If b > a, <r.C(jw) > 0 
for all w > 0, and the system is then called a lead network. 
(i) 
Show that it is possible to stabilize the system with the lead compensator 
if K is chosen large enough. 
s +.! 
C(s) = K--2 
s+2 
(P11.45-3) 
(ii) Show that it is not possible to stabilize the feedback system of Figure 
P11.45(b) using the lag network 
C(s) = K
5 + 3. 
s+2 
Hint: Use the results of Problem 11.34 in sketching the root locus. Then 
determine the points on the jw-axis that are on the root locus and the 
values of K for which each of these points is a closed-loop pole. Use this 
information to prove that for no value of K are all of the closed-loop poles 
in the left-half plane. 
11.46. Consider the continuous-time feedback system depicted in Figure Pl1.46(a). 
x(t) ----t•+~G) 
+ 
.. 
s+10 
(s+1)2' 
y(t) 
-
10 
(s/100+1)2 
(a) 
x(t) ----t•+~8 
+ 
.. 
(s+10)e- s' 
(s+1)2 
y(t) 
-
10 
(s/100+1)2 
(b) 
Figure P11.46 

Chap. 11 
Problems 
891 
(a) Use the straight-line approximations to Bode plots developed in Chapter 6 to 
obtain a sketch of the log magnitude-phase plot of this system. Estimate the 
phase and gain margins from your plot. 
(b) Suppose that there is an unknown delay within the feedback system, so that 
the actual feedback system is as shown in Figure P11.46(b). Approximately 
what is the largest delay T that can be tolerated before the feedback system 
becomes unstable? Use your results from part (a) for this calculation. 
(c) Calculate more precise values of the phase and gain margins, and compare 
these to your results in part (a). This should give you some idea of the size of 
the errors that are incurred in using the approximate Bode plots. 
11.47. As mentioned at the end of Section 11.5, the phase and gain margins may provide 
sufficient conditions to ensure that a stable feedback system remains stable. For 
example, we showed that a stable feedback system will remain stable as the gain 
is increased, until we reach a limit specified by the gain margin. This does not 
imply (a) that the feedback system cannot be made unstable by decreasing the 
gain or (b) that the system will be unstable for all values of gain greater than the 
gain margin limit. In this problem, we illustrate these two points. 
(a) Consider a continuous-time feedback system with 
1 
G(s)H(s) = (s- l)(s + 2)(s + 3) 
Sketch the root locus for this system for K > 0. Use the properties of the root 
locus described in the text and in Problem 11.34 to help you draw the locus 
accurately. Once you do so, you should see that for small values of the gain 
K the system is unstable, for larger values of K the system is stable, while 
for still larger values of K the system again becomes unstable. Find the range 
of values of K for which the system is stable. Hint: Use the same method as 
is employed in Example 11.2 and Problem 11.35 to determine the values of 
K at which branches of the root locus pass through the origin and cross the 
jw-axis. 
If we set our gain somewhere within the stable range that you have just 
found, we can increase the gain somewhat and maintain stability, but a large 
enough increase in gain causes the system to become unstable. This maximum 
amount of increase in gain at which the closed-loop system just becomes un-
stable is the gain margin. Note that if we decrease the gain too much, we can 
also cause instability. 
(b) Consider the feedback system of part (a) with the gain K set at a value of 7. 
Show that the closed-loop system is stable. Sketch the log magnitude-phase 
plot of this system, and show that there are two nonnegative values of w 
for which 4:-G(jw)H(jw) = -Tr. Further, show that, for one of these values 
7IG(Jw)H(jw)l < 1, and for the other 7IG(jw)H(jw)l > 1. The first value 
provides us with the usual gain margin-that is, the factor 11I7G(jw)H(jw)l 
by which we can increase the gain and cause instability. The second provides 
us with the factor 11I7G(jw )H(jw )I by which we can decrease the gain and 
just cause instability. 

892 
Linear Feedback Systems 
Chap. 11 
(c) Consider a feedback system with 
G( )H( ) = (s/100 + 1? 
s 
s 
(s + 1)3 
Sketch the root locus forK > 0. Show that two branches of the root locus begin 
in the left-half plane and, asK is increased, move into the right-half plane and 
then back into the left-half plane. Do this by examining the equation 
G(jw)H(jw) = - ~· 
Specifically, by equating the real and imaginary parts of this equation, show 
that there are two values of K :::::: 0 for which the closed-loop poles lie on the 
jw-axis. 
Thus, if we set the gain at a small enough value so that the system is sta-
ble, then we can increase the gain up until the point at which the two branches 
of the root locus intersect the jw-axis. For a range of values of gain beyond this 
point, the closed-loop system is unstable. However, if we continue to increase 
the gain, the system will again become stable for K large enough. 
(d) Sketch the Nyquist plot for the system of part (c), and confirm the conclusions 
reached in part (c) by applying the Nyquist criterion. (Make sure to count the 
net number of encirclements of - 1/K.) 
Systems such as that considered in parts (c) and (d) of this problem are 
often referred to as being conditionally stable systems, because their stability 
properties may change several times as the gain is varied. 
11.48. In this problem, we illustrate the discrete-time counterpart of the technique de-
scribed in Problem 11.44. Specifically, the discrete-time Nyquist criterion can be 
extended to allow for poles of G(z)H(z) on the unit circle. 
Consider a discrete-time feedback system with 
1 
z-2 
G(z)H(z) = 1 _ z-I 
z(z -
1) · 
(P11.48-1) 
In this case, we modify the contour on which we evaluate G(z)H(z), as illustrated 
in Figure P11.48(a). 
(a) Show that 
and 
<r..G(ej21T- )H(e.j21T- ) = I' 
where z = ej21r- is the point below the real axis at which the small semicircle 
intersects the unit circle and z = ejo+ is the corresponding point above the real 
axis. 
(b) Use the results of part (a) together with eq. (P11.48-1) to verify that Fig-
ure P11.48(b) is an accurate sketch of G(z)H(z) along the portion of the 

Chap. 11 
Problems 
893 
(a) 
tw=2'7T 
! w=O+ 
(b) 
Figure P11.48 

894 
Linear Feedback Systems 
Chap. 11 
contour z = eiw as w varies from o+ to 27T- in a counterclockwise direc-
tion. In particular, verify that the angular variation of G(eiw)H(eiw) is as 
indicated. 
(c) Find the value of w for which1:G(eiw)H(eiw) = - 7T, and verify that 
jG(eiw)H(eiw)j = 1 
at this point. [Hint: Use the geometrical method for evaluating 1: G( eiw)H ( eiw) 
together with some elementary geometry to determine the value of w.] 
(d) Consider next the plot of G(z)H(z) along the small semicircle about z = 1. 
Note that as € ~ 0, the magnitude of G(z)H(z) along this contour goes to in-
finity. Show that as € ~ 0, the contribution of the pole at z = 0 to 1: G(z)H (z) 
along the semicircle is zero. Then show that as € ~ 0, 
1:G(z)H(z) = -0, 
where() is as defined in Figure Pll.48(a). 
Thus, since() varies from -7T/2 to +7T/2 in the counterclockwise direc-
tion, 1:G(z)H(z) varies from +7T/2 to -7T/2 in the clockwise direction. The 
result is the complete Nyquist plot of Figure P11.48( c). 
(e) Using the Nyquist plot, find the range of values of K for which the closed-
loop feedback system is stable. [Note: Since the pole of G(z)H(z) at z = 1 is 
(c) 
Figure P11.48 
Continued 

Chap. 11 
Problems 
895 
inside the modified contour, it is not included in counting the poles of G(z)H(z) 
outside the unit circle. That is, only poles strictly outside the unit circle are 
counted in applying the Nyquist criterion. Thus, in this case, since G(z)H(z) 
has no poles strictly outside the unit circle, we must have no encirclements of 
the point z = -II K for closed-loop stability.] 
(f) Follow the steps outlined in parts (a), (b), and (d) to sketch the Nyquist plots 
for each of the following: 
(i) 
z+ ~ +li 
z- l 
(ii) 
I 
(z- l)(z+ ~ +>/% 
(iii) 
;:+ 1 
z(z- I) 
(iv) ~~~'// [be careful in calculating <r.G(z)H(z) along the infinitesimal semi-
circle] 
For each of the preceding, use the Nyquist criterion to determine the range 
of values of K (if any such range exists) for which the closed-loop system is 
stable. Also, use another method (root locus or direct calculation of the closed-
loop poles as a function of K) to provide a partial check of the correctness of 
your Nyquist plot. Note: In sketching the Nyquist plots, you may find it useful 
to first sketch the magnitude and phase plots as a function of frequency or at 
least calculate /G(eiw)H(eiw)/ and <r.G(eiw)H(eiw) at several points. Also, it 
is helpful to determine the values of w for which G(eiw)H(eiw) is real. 
(g) Repeat part (f) for 
1 
G(z)H(z) = zZ _ 1. 
In this case there are two poles on the unit circle, and thus, you must modify 
the contour around each of these by including an infinitesimal semicircle that 
extends outside the unit circle, thereby placing the pole inside the contour. 
EXTENSION PROBLEMS 
11.49. In this problem, we provide an illustration of how feedback can be used to increase 
the bandwidth of an amplifier. Consider an amplifier whose gain falls off at high 
frequencies. That is, suppose the system function of this amplifier is 
Ga 
H(s) = --. 
s+a 
. (a) What is the de gain of the amplifier (i.e., the magnitude of its frequency re-
sponse at 0 frequency)? 
(b) What is the system time constant? 
(c) Suppose we define the bandwidth of the system as the frequency at which the 
magnitude of the amplifier frequency response is 11 ji times its magnitude at 
de. What is the bandwidth of the amplifier? 

896 
Linear Feedback Systems 
Chap. 11 
(d) Suppose we place the amplifier in a feedback loop as depicted in Figure 
Pll.49. What is the de gain of the closed-loop system? What are the time 
constant and the bandwidth of the closed-loop system? 
(e) Find the value of K that leads to a closed-loop bandwidth that is exactly double 
the bandwidth of the open -loop amplifier. What are the corresponding closed-
loop system time constant and de gain? 
x(t)--....,.+~1 
1------.,._-~ y(t) 
Figure P11.49 
11.50. As mentioned in the text, an important class of devices used in the implementation 
of feedback systems is the class of operational amplifiers. A model for such an 
amplifier is depicted in Figure Pll.50(a). The amplifier's input is the difference 
>---o+ 
v0(t) 
+ 
r 
v1(t) 
Figure P11.50a 
between two voltages v2(t) and v1 (t), and the output voltage is an amplified version 
of the input; that is, 
(Pll.S0-1) 
Consider an operational amplifier connection shown in Figure Pll.50(b). In 
this figure, Z1 (s) and Z2(s) are impedances. (That is, each is the system function of 
an LTI system whose input is the current flowing through the impedance element 
and whose output is the voltage across the element.) Making the approximation 
that the input impedance of the operational amplifier is infinite and that its output 
impedance is zero, we obtain the following relationship between V1 (s), V;(s), and 
V 0 (s), the Laplace transforms of v1 (t), v;(t), and v0 (t), respectively: 
VI = [zl(s~~s~2 (s) J V;(s) + [zl(s~~s~2(s) J Vo(s). 
(Pll.S0- 2) 

Chap. 11 
V;(t) 
Problems 
Z2(s) 
Z1(s) 
+ 
+ 
v0 (t) 
v1 (t) 
r-
-
Figure P11.50b 
Also, from eq. (P11.50-1) and Figure Pll.50(b), we see that 
V0 (s) = - KVJ(s). 
(a) Show that the system function 
H(s) = Vo(s) 
V;(s) 
897 
(Pl1.50-3) 
for the interconnection of Figure Pll.SO(b) is identical to the overall closed-
loop system function for the system of Figure Pl1.50(c). 
V;(t) ____,.. 
Z2(s) 
+ + 
- K 
Z1(s) + Z2(s) 
+ 
Z1(s) 
Z1(s) + Z2(s) 
Figure P11.50c 
(b) Show that if K > > 1, then 
H( ) = _ Zz(s) 
s 
Z1(s)' 
11.51. (a) Suppose that in Figure P11.50(b) Z 1(s) and Zz(s) are both pure resistances, 
say, R1 and Rz, respectively. A typical value for R21R1 is in the range 1 to 
103, while a typical value forK is 106. Using the results of Problem 11.50(a), 
calculate the actual system function for this value of K and for R21 R 1 equal to 
1 and then to 103, and compare each resulting value to - R21 R 1. This should 
give you some idea of how good the approximation of Problem 11.50(b) 
typically is. 

898 
Linear Feedback Systems 
Chap. 11 
(b) One of the important uses of feedback is in the reduction of system sensitivity 
to variations in parameters. This is particularly important for circuits involv-
ing operational amplifiers, which have high gains that may be known only 
approximately. 
(i) 
Consider the circuit discussed in part (a), with R2/R 1 = 102• What is 
the percentage change in the closed-loop gain of the system if K changes 
from 106 to 5 x 105? 
(ii) How large must K be so that a 50% reduction in its value results in only 
a 1% reduction in the closed-loop gain? Again, take R2/R1 = 102 • 
11.52. Consider the circuit of Figure P 11.52. This circuit is obtained by using 
1 
Z2(s) = CS 
in Figure Pll.50(b ). Using the results from Problem 11.50, show that the system 
behaves approximately like an integrator. In what frequency range (expressed in 
terms of K, R, and C) does this approximation break down? 
c 
>-----1..._--o + 
r 
v0 (t) 
Figure P11.52 
11.53. Consider the circuit depicted in Figure P 11.53( a), which is obtained from the circuit 
of Figure Pll.50(b) by using Z1 (s) = Rand by replacing Z2(s) with a diode that 
has an exponential current-voltage relationship. Assume that this relationship is of 
the form 
(P11.53-1) 
where M is a constant that depends upon the construction of the diode, q is the 
charge of an electron, k is Boltzmann's constant, and Tis absolute temperature. 
Note that the idealized relationship of eq. (P11.53-1) assumes that there is no pos-
sibility of a negative diode current. Usually, there is some small maximum negative 
value of diode current, but we will neglect this possibility in our analysis. 
(a) Assuming that the input impedance of the operational amplifier is infinite and 
that its output impedance is zero, show that the following relations hold: 
(P11.53-2) 
(P11.53-3) 

Chap. 11 
V;(t) 
V;(t) 
Problems 
899 
Figure P11.53a 
(b) Show that forK large, the relationship between v0 (t) and vi(t) is essentially 
the same as in the feedback system of Figure P11.53(b), in which the system 
in the feedback path is a nonlinear memoryless system with input v0 (t) and 
output 
(c) Show that forK large, 
+ 
Vo(t) = kT ln (- Vi(t) )· 
q 
RM 
(P11.53-4) 
+ 
- K 
+ 
w(t) 
: w(t) = RMeqvo(t)/kT~ 
Figure P11.53b 
Note that eq. (P11.53- 4) makes sense only for a negative vi(t), which is con-
sistent with the requirement that the diode current cannot be negative. If a 
positive v;(t) is applied, the current id(t) cannot balance the current through 
the resistor. Thus, a nonnegligible current is fed into the amplifier, causing it 
to saturate. 
11.54. In this problem, we explore the use of positive feedback for generating oscillating 
signals. 
(a) Consider the system illustrated in Figure Pl1.54(a). Show that x 1(t) = xi(t) if 
G(s)H(s) = -1. 
(Pll.54-1) 
Suppose that we connect terminals 1 and 2 in Figure Pll.54(a) and make 
xi(t) = 0. Then the output of the system should remain unchanged if we 

900 
X;(t) = O 
Linear Feedback Systems 
Chap. 11 
H(s) 
y(t) 
3 
-1 
Gs 
(a) 
+ 
+ 
H(s) 
y(t) 
+ 
......___ -1 
~ 
G(s) 
(b) 
Figure P11.54 
satisfy eq. (Pll.54-l). The system now produces an output without any input. 
Therefore, the system shown in Figure Pll.54(b) is an oscillator, provided that 
eq. (Pll.54-l) is satisfied. 
(b) A commonly used oscillator in practice is the sinusoidal oscillator. For such an 
oscillator, we may rewrite the condition of eq. (Pll.54-1) as 
G(jwo)H(Jwo) = - 1. 
(Pll.54-2) 
What is the value of the closed-loop gain for the system shown in Figure 
Pll.54(b) at w0 when eq. (Pll.54-2) is satisfied? 
(c) A sinusoidal oscillator may be constructed on the basis of the principle out-
lined above by using the circuit shown in Figure Pll.54( c). The input to the 
Figure P11.54c 

Chap. 11 
Problems 
901 
amplifier is the difference between the voltages v1 (t) and v2(t). In this circuit, 
the amplifier has a gain of A and an output resistance of R0 . Z1 (s), Z2(s), and 
Z3(s) are impedances. (That is, each is the system function of an LTI system 
whose input is the current flowing through the impedance element and whose 
output is the voltage across the element.) It can be shown that, for this circuit, 
where 
Also, we can show that 
(i) 
Show that 
-AZL(s) 
H(s) = ZL(s) + Ro' 
G(s) = 
- Z1 (s) 
z, (s) + Z3(s) 
G(s)H(s) = 
AZ,(s)Z2(s) 
Ro(ZJ (s) + Z2(s) + Z3(s)) + Z2(s)(Z, (s) + Z3(s)) 
(ii) If Z1 (s), Z2(s), and Z3(s) are pure reactances (i.e., inductances or ca-
pacitances), we can write Z,(jw) = jX,(jw), Z2(jw) = }X2(jw), and 
Z3(jw) = }X3(jw ), where X;(jw ), i = 1, 2, 3, are all real. Using there-
sults of parts (b) and (i), show that a necessary condition for the circuit to 
produce oscillations is 
X, (jw) + Xz(jw) + X3(jw) = 0. 
(iii) Show also that, in addition to the constraint of part (ii), the constraint 
AX1 (jw) = X2(jw) has to be satisfied for the circuit to produce os-
cillations. [Since X;(}w) is positive for inductances and negative for 
capacitances, the latter constraint requires that Z1 (s) and Z2(s) be reac-
tances of the same type (i.e., both should be inductances or both should 
be capacitances).] 
(iv) Let us assume that Z1 (s) and Z2(s) are both inductances such that 
X,(jw) = Xz(}w) = wL. 
Let us also assume that 
X3(jw) = - 1/(wC) 
is a capacitance. Use the condition derived in (ii) to determine the fre-
quency (in terms of L and C) at which the circuit oscillates. 
ll.SS. (a) Consider the nonrecursive discrete-time LTI filter depicted in Figure Pll.55(a). 
Through the use of feedback around this nonrecursive system, a recursive 
filter can be implemented. To do so, consider the configuration shown in 
Figure P11.55(b), in which H(z) is the system function of the nonrecursive 
LTI system of Figure Pll.55(a). Determine the overall system function of this 

902 
x(n] 
Linear Feedback Systems 
Chap. 11 
feedback system, and find the difference equation relating the input to the 
output of the overall system. 
D 
D 
D 
••• _._ 
D 
....._ ___ 
+{ + )---....... ~ + 1----
y(n] 
(a) 
+ 
K 
y(n] 
-
H(z) 
(b) 
Figure P11.55 
(b) Now suppose that H(z) in Figure Pll.SS(b) is the system function of a recur-
sive LTI system. Specifically, suppose that 
N 
2:Ciz-i 
H(z) = _i;_t __ 
~diz-i 
i= l 
Show how one can find values of the coefficients K, Ct, ... , CN, and do, ... , dN, 
such that the closed-loop system function is 
N 
~bi Z - i 
Q(z) = _i;_o _ _ 
~ai z-i 
i=O 
where the ai and bi are specified coefficients. 

Chap. 11 
Problems 
903 
In this problem, we have seen that the use of feedback provides us with alterna-
tive implementations of LTI systems specified by linear constant-coefficient dif-
ference equations. The implementation in part (a), consisting of feedback around 
a nonrecursive system, is particularly interesting, as some technologies are ide-
ally suited to implementing tapped delay-line structures (i.e., systems consisting 
of chains of delays with taps at each delay whose outputs are weighted and then 
summed). 
11.56. Consider an inverted pendulum mounted on a movable cart, as depicted in Figure 
P11.56. Here, we have modeled the pendulum as consisting of a massless rod of 
length L with a mass m attached at the end. The variable O(t) denotes tlie pendu-
lum's angular deflection from the vertical, g is gravitational acceleration, s(t) is 
the position of the cart with respect to some reference point, a(t) is the acceler-
ation of the cart, and x(t) represents the angular acceleration resulting from any 
disturbances, such as gusts of wind. 
s(t) 
I 
I 
I 
a(t) 
Figure P11.56 
Our goal in this problem is to analyze the dynamics of the inverted pendulum 
and, more specifically, to investigate the problem of balancing the pendulum by 
a judicious choice of the acceleration a(t) of the cart. The differential equation 
relating O(t), a(t), and x(t) is 
d 20(t) 
. 
L----;[i'l = g sm[O(t)] - a(t) cos[O(t)] + Lx(t). 
(Pll.56-1) 
This relation merely equates the actual acceleration of the mass along a direction 
perpendicular to the rod to the applied accelerations [gravity, the disturbance ac-
celeration due to x(t), and the cart's acceleration] along this direction. 
Note that eq. (Pll.56-1) is a nonlinear differential equation. The detailed, 
exact analysis of the behavior of the pendulum requires that we examine this equa-
tion; however, we can obtain a great deal of insight into the dynamics of the pendu-
lum by performing a linearized analysis. Specifically, let us examine the dynamics 
of the pendulum when it is nearly vertical [i.e., when O(t) is small]. In this case, we 

904 
Linear Feedback Systems 
Chap. 11 
can make the approximations 
sin[O(t)] = O(t), cos[O(t)] = 1. 
(P11.56-2) 
(a) Suppose that the cart is stationary [i.e., a(t) = 0], and consider the causal LTI 
system with input x(t) and output O(t) described by eq. (P11.56-1), together 
with the approximations given in eq. (Pll.56-2). Find the system function for 
this system, and show that it has a pole in the right-half of the plane, implying 
that the system is unstable. 
(b) The result of part (a) indicates that if the cart is stationary, any .. _minor angular 
disturbance caused by x(t) will lead to growing angular deviations from the 
vertical. Clearly, at some point, these deviations will become sufficiently large 
so that the approximations of eq. (Pll.56-2) will no longer be valid. At this 
point the linearized analysis is no longer accurate, but the fact that it is ac-
curate for small angular displacements allows us to conclude that the vertical 
equilibrium position is unstable, since small angular displacements will grow 
rather than diminish. 
We now wish to consider the problem of stabilizing the vertical position 
of the pendulum by moving the cart in an appropriate fashion. Suppose we try 
proportional feedback-that is, 
a(t) = KO(t). 
Assume that O(t) is small, so that the approximations in eq. (Pll.56-2) are 
valid. Draw a block diagram of the linearized system with O(t) as the output, 
x(t) as the external input, and a(t) as the signal that is fed back. Show that 
the resulting closed-loop system is unstable. Find a value of K such that if 
x(t) = 8(t), the pendulum will sway back and forth in an undamped oscillatory 
fashion. 
(c) Consider using the proportional-plus-derivative (PD) feedback, 
d()(t) 
a(t) = K1 O(t) + K2 (if· 
Show that one can find values of K1 and K2 that stabilize the pendulum. In 
fact, using 
g = 9. 8 m/sec2 
and 
(Pll.56- 3) 
L = 0.5 m, 
choose values of K1 and K2 so that the damping ratio of the closed loop system 
is 1 and the natural frequency is 3 rad/sec. 
11.57. In this problem, we consider several examples of the design of tracking systems. 
Consider the system depicted in Figure Pll.S7. Here, Hp(s) is the system whose 
output is to be controlled, and Hc(s) is the compensator to be designed. Our objec-
tive in choosing Hc(s) is that we would like the output y(t) to follow the inp.ut x(t). 
In particular, in addition to stabilizing the system, we would also like to design the 
system so that the error e(t) decays to zero for certain specified inputs. 

Chap. 11 
Problems 
x(t) 
+ 
e(t) 
+ 
-
(a) Suppose that 
H0 (s) 
d(t) 
Hp(s) 
Figure P11.57 
a 
Hp(s) = -
- , 
a r= 0. 
s+a 
905 
y(t) 
(P11.57-1) 
Show that if Hc(s) = K (which is known as proportional or P control), we 
can choose K so as to stabilize the system and so that e(t) -
0 if x(t) = 5(t). 
Show that we cannot get e(t) -
0 if x(t) = u(t). 
(b) Again let Hp(s) be as in eq. (P11.57-1), and suppose that we use proportional-
plus-integral (PI) control-that is, 
Show that we can choose K 1 and K2 so as to stabilize the system, and we can 
also get e(t) -
0 if x(t) = u(t). Thus, the system can track a step. In fact, this 
illustrates a basic and important principle in feedback system design: To track 
a step [X(s) = lis], we need an integrator (lis) in the feedback system. An 
extension of this principle is considered in the next problem. 
(c) Suppose that 
Show that we cannot stabilize this system with a PI controller, but that we cart 
stabilize it and have it track a step if we use proportional-plus-integral-plus-
differential (PID) control, i.e., 
11.58. In Problem 11.57, we discussed how the presence of an integrator in a feedback 
system can make it possible for the system to track a step input with zero error 
in the steady state. In this problem, we extend the idea. Consider the feedback 
system depicted in Figure P11.58, and suppose that the overall closed-loop system 
is stable. Suppose also that 
H(s) = __.:.:.k_= .:....l ---
n- 1 
s1[l (s- ak) 
k = l 

906 
Linear Feedback Systems 
Chap. 11 
x(t) ____;~ H(s) 1---...... -~y(t) 
Figure P11.58 
where the ak and f3k are given nonzero numbers and lis a positive integer. The 
feedback system of Figure Pll.58 is often referred to as a Type l feedback system. 
(a) Use the final-value theorem (Section 9.5.10) to show that a Type 1 feedback 
system can track a step-that is, that 
e(t) ~ 0 
if 
x(t) = u(t). 
(b) Similarly, show that a Type 1 system cannot track a ramp, but rather, that 
e(t) ~ a finite constant if 
x(t) = U- 2(t). 
(c) Show that, for a Type 1 system, unbounded results ensue if 
x(t) = U- k(t) 
with k > 2. 
(d) More generally, show that, for a Type l system: 
(i) 
e(t) ~ 0 if x(t) = U- k(t) with k :$ l 
(ii) e(t) ~ a finite constant if x(t) = U(- l+l)(t) 
(iii) e(t) ~ oo if x(t) = U- k(t) with k > l + 1 
11.59. (a) Consider the discrete-time feedback system of Figure Pll.59. Suppose that 
1 
H(z) = 
. 
(z-l)(z+~) 
+~ 
x[n] ____..~ H(z) 1---..... -~y[n] 
Figure P11.59 
Show that this system can track a unit step in the sense that if x[n] = u[n], 
then 
lim e[n] = 0. 
(Pll.59- 1) 
n-'>oo 
(b) More generally, consider the feedback system of Figure Pll.59, and assume 
that the closed-loop system is stable. Suppose that H(z) has a pole at z = 1. 

Chap. 11 
Problems 
907 
Show that the system can track a unit step. [Hint: Express the transform E(z) 
of e[n] in terms of H(z) and the transform of u[n]; explain why all the poles 
of E(z) are inside the unit circle.] 
(c) The results of parts (a) and (b) are discrete-time counterparts of the results for 
continuous-time systems discussed in Problems 11.57 and 11.58. In discrete 
time, we can also consider the design of the systems that track specified inputs 
perfectly after a finite number of steps. Such systems are known as deadbeat 
feedback systems. 
Consider the discrete-time system of Figure Pll.59 with 
z-' 
H(z) = 1 - c '. 
Show that the overall closed-loop system is a deadbeat feedback system with 
the property that it tracks a step input exactly after one step: that is, if x[n] = 
u[n], then e[n] = 0, n ;:;:; 1. 
(d) Show that the feedback system of Figure P 11.59 with 
is a deadbeat system with the property that the output tracks a unit step per-
fectly after a finite number of steps. At what time step does the error e[n] first 
settle to zero? 
(e) More generally, for the feedback system of Figure P11.59, find H(z) so that 
y[n] perfectly tracks a unit step for n 2: Nand, in fact, so that 
N - 1 
e[n] = .2:: akC>[n- k], 
k=O 
(P11.59- 2) 
where the ak are specified constants: Hint: Use the relationship between H(z) 
and E(z) when the input is a unit step and e[n] is given by eq. (Pll.59-2). 
(f) Consider the system of Figure P11.59 with 
Show that this system tracks a ramp x[n] = (n + 1)u[n] exactly after two time 
steps. 
11.60. In this problem, we investigate some of the properties of sampled-data feedback 
systems and illustrate the use of such systems. Recall from Section 11.2.4 that 
in a sampled-data feedback system the output of a continuous-time system is sam-
pled. The resulting sequence of samples is processed by a discrete-time system, the 
output of which is converted to a continuous-time signal that in turn is fed back and 
subtracted from the external input to produce the actual input to the continuous-
time system. 

908 
Linear Feedback Systems 
Chap. 11 
(a) Consider the system within dashed lines in Figure 11.6(b). This is a discrete-
time system with input e[n] and output p[n]. Show that it is an LTI system. As 
we have indicated in the figure, we will let F(z) denote the system function of 
this system. 
(b) Show that in Figure 11.6(b) the discrete-time system with system function 
F(z) is related to the continuous-time system with system function H(s) by 
means of a step-invariant transfonnation. That is, if s(t) is the step response of 
the continuous-time system and q[n] is the step response of the discrete-time 
system, then 
(c) Suppose that 
Show that 
q[n] = s(nT) 
for all n. 
1 
H(s) = --1, CR.e{s} > 1. 
s -
F(z) = (eT - l)z- 1' 
lzl > er. 
1 - eTz- 1 
(d) Suppose that H(s) is as in part (c) and that G(z) = K. Find the range of values 
of K for which the closed-loop discrete-time system of Figure 11.6(b) is stable. 
(e) Suppose that 
K 
G(z) = -1-+---=-! z---1 • 
2 
Under what conditions on T can we find a value of K that stabilizes the overall 
system? Find a particular pair of values forK and T that yield a stable closed-
loop system. Hint: Examine the root locus, and find the values for which the 
poles enter or leave the unit circle. 

APPENDIX 
PARTIAL-FRACTION EXPANSION 
A. 1 INTRODUCTION 
The purpose of this appendix is to describe the technique of partial-fraction expansion. 
This tool is of great value in the study of signals and systems; in particular, it is very 
useful in inverting Fourier, Laplace, or z-transforms and in analyzing LTI systems de-
scribed by linear constant-coefficient differential or difference equations. The method of 
partial-fraction expansion consists of taking a function that is the ratio of polynomials and 
expanding it as a linear combination of simpler terms of the same type. The determination 
of the coefficients in the linear combination is the basic problem to be solved in obtaining 
the expansion. As we will see, this is a relatively straightforward problem in algebra that 
can be solved very efficiently with a bit of "bookkeeping." 
To illustrate the basic idea behind and role of partial-fraction expansion, consider 
the analysis developed in Section 6.5.2 for a second-order continuous-time LTI system 
specified by the differential equation 
d 2y(t) 
dy(t) 
2 
2 
df2 + 2(wn ---;[t + wny(t) = wnx(t). 
The frequency response of this system is 
2 
H(jw) = (. )2 
2t" ( . ) 
2' 
JW 
+ 
Wn JW + Wn 
or, if we factor the denominator, 
where 
2 
H(jw) = (. 
~('-
)' 
JW -
Cj JW -
C2 
C] = - (wn + WnJ(2 -
1, 
C2 = - (wn -
Wn~· 
(A.1) 
(A.2) 
(A.3) 
(A.4) 
Having H(jw ), we are in a position to answer a variety of questions related to the 
system. For example, to determine the impulse response of the system, recall that for any 
number a with ffi-e{s} < 0, the Fourier transform of 
is 
1 
X](jW) = ---
jw - a' 
(A.5) 
(A.6) 
909 

910 
Appendix 
while if 
(A.7) 
then 
X2(jw)=( . 
1 
)2 . 
JW - a 
(A.8) 
Therefore, if we can expand H(jw) as a sum of terms of the form of eq. (A.6) or 
(A.8), we can determine the inverse transform of H(jw) by inspection. For example, in 
Section 6.5.2 we noted that when c1 oF c2, H(jw) in eq. (A.3) could be rewritten in the 
form 
H( . ) -
( 
(I)~ 
) 
1 
( 
(I)~ 
) 
1 
JW -
. 
+ 
. 
. 
C] -
C2 
}W -
CJ 
C2 -
CJ 
)W -
C2 
(A.9) 
In this case, the Fourier transform pair of eqs. (A.S) and (A.6) allows us to write down 
immediately the inverse transform of H(jw) as 
(A.lO) 
While we have phrased the preceding discussion in terms of continuous-time Fourier 
transforms, similar concepts also arise in discrete-time Fourier analysis and in the use of 
Laplace and z-transforms. In all of these cases, we encounter the important class of rational 
transforms- that is, transforms that are ratios of polynomials in some variable. Also, in 
each of these contexts, we find reasons for expanding these transforms as sums of simpler 
terms such as in eq. (A.9). In this section, in order to develop a general procedure for 
calculating the expansions, we consider rational functions of a general variable v; that is, 
we examine functions of the form 
H(v) = f3mvm + f3m- JVm- I + ... + f3Iv + f3o. 
a 11V11 + a 11- JV 11- I + ... + a1v + ao 
(A.ll) 
For continuous-time Fourier analysis (jw) plays the role of v, while for Laplace 
transforms that role is played by the complex variables. In discrete-time Fourier analysis, 
vis usually taken to be e-Jw, while for z-transforms, we can use either z- 1 or z. After we 
have developed the basic techniques of partial-fraction expansion, we will illustrate their 
application to the analysis of both continuous-time and discrete-time LTI systems. 
A.2 PARTIAL-FRACTION EXPANSION AND CONTINOUS-TIME SIGNALS 
AND SYSTEMS 
For our purposes, it is convenient to consider rational functions in one of two standard 
forms. The second of these, which is often useful in the analysis of discrete-time signals 
and systems, will be discussed shortly. The first of the standard forms is 
G(v) = bn- tV
11- I + h11- 2V
11
- 2 + ... + b1v + bo 
V 11 + a11- tvn- l + ... + a1v + ao 
(A.l2) 

Appendix 
911 
In this form the coefficient of the highest order term in the denominator is 1, and the order 
of the numerator is at least one less than the order of the denominator. (The order of the 
numerator will be less than n- 1 if bn- l = 0.) 
If we are given H(v) in the form of eq. (A.ll), we can obtain a rational function of 
the form of eq. (A.12) by performing two straightforward calculations. First, we divide 
both the numerator and the denominator of H(v) by an. This yields 
(A.13) 
where 
= 
f3m 
'Ym- 1 = f3m- l 
'Ym 
an 
an 
= an- I 
= an- 2 
an- I 
an-2 
an 
an 
If m < n, H ( v) is called a strictly proper rational function, and in this case, letting 
bo = 'Yo, b, = 'YJ, . . . , bm = 'Ym. and setting any remaining b's equal to zero, we see that 
H(v) in eq. (A.13) is already of the form of eq. (A.12). In most of the discussions in this 
book in which rational functions are considered, we are concerned primarily with strictly 
proper rational functions. However, if H(v) is not proper (i.e., if m 2:: n), we can perform 
a preliminary calculation that allows us to write H(v) as the sum of a polynomial in v and 
a strictly proper rational function. That is, 
H(v) = Cm- nVm-n + Cm-n-IVm- n- I + . . . + CJV +Co 
+ bn- JVn- l + bn- 2Vn-2 + . . . + b,v + bo 
vn + an- Ivn 1 + ... + a,v + ao 
(A.14) 
The coefficients co, c,, . . . , Cm- n and bo, b,, ... , bn- I can be obtained by equating eqs. 
(A.13) and (A.l4) and then multiplying through by the denominator. This yields 
m 
- b 
n- I 
b 
b 
')lmV + · · · + ')IJV +'YO -
n- IV 
+ · · · + 
JV + 
0 
(A.15) 
+ (Cm-nVm- n + . . . + Co)(vn + an- IVn- I + ... + ao). 
By equating the coefficients of equal powers of v on both sides of eq. (A.15), we can 
determine the c's and b's in terms of the a's andy's. For example, if m = 2 and n = 1, 
so that 
1'2v2 + 'YtV +'Yo 
bo 
H(v) = 
= c,v +co+--, 
v +a, 
v +a, 
then eq. (A.15) becomes 
y zv 2 + 'YIV +'Yo = bo + (c,v + co)(v + aJ) 
= bo + c,v2 +(co+ a,cJ)v +a, co. 
Equating the coefficients of equal powers of v, we obtain the equations 
1'2 = c,, 
1'1 = co+ a,c,, 
'Yo = bo + a 1co. 
(A.16) 

912 
Appendix 
The first equation yields the value of c 1, which can then be used in the second to solve for 
c0 , which in tum can be used in the third to solve for b0. The result is 
c, = 'Y2· 
co = 'YI - aj'yz, 
bo = 'Yo - a,('YI - a1'Y2). 
The general case of eq. (A.15) can be solved in an analogous fashion. 
Our goal now is to focus on the proper rational function G(v) in eq. (A.l2) and to 
expand it into a sum of simpler proper rational functions. To see how this can be done, 
consider the case of n = 3, so that eq. (A.12) reduces to 
G(v) = 
bzv
2 + b,v + bo 
. 
(A.l?) 
v3 + a2v2 + a 1 v + ao 
As a first step, we factor the denominator of G( v) in order to write it in the form 
G(v) = 
b2v2 + b,v + bo 
(A.lS) 
(v- pi)(v- P2)(v- P3) 
Assuming for the moment that the roots p1, p2, and p3 of the denominator are all distinct, 
we would like to expand G( v) into a sum of the form 
A, 
Az 
A3 
G(v) = - -
+ -- + --. 
(A.19) 
v - PI 
v - P2 
v - P3 
The problem, then, is to determine the constants A1, A2, and A3. One approach is to equate 
eqs. (A.18) and (A.19) and to multiply through the denominator. In this case, we obtain 
the equation 
bzv2 + b,v + bo = A,(v- pz)(v - P3) 
+ Az(v- pi)(v - P3) 
+ A3(v- p,)(v- pz). 
(A.20) 
By expanding the right-hand side of eq. (A.20) and then equating coefficients of equal 
powers of v, we obtain a set of linear equations that can be solved for A 1, A2, and A3. 
Although this approach always works, there is a much easier method. Consider 
eq. (A.19), and suppose that we would like to calculate A 1• Then, multiplying through 
by v - PI , we obtain 
(v _ pi)G(v) =A,+ A2(v- p,) + A3(v - p,). 
v - pz 
v-p3 
(A.21) 
Since p1, p2, and p3 are distinct, the last two terms on the right-hand side of eq. (A.21) 
are zero for v = p1. Therefore, 
or, using eq. (A.18), 
A, = [(v- pi)G(v)Jiv=pp 
bzpf + b,p, + bo 
(p, - pz)(p, - P3) · 
(A.22) 
(A.23) 

Appendix 
Similarly, 
_ 
. 
_ 
b2 p~ + b1 P2 + bo 
A2 -
[(v - fJ2)G(v)Jiu =p2 -
( 
)( 
)' 
P2 -
PI P2 -
P3 
_ 
_ 
_ 
b2p~ + b1 P3 + bo 
A3 - [(v 
P3)G(v)llu=p3 -
( 
)( 
)' 
P3 - PI 
P3 - P2 
Suppose now that Pt = P3 =/c. p2; that is, 
G(v) = b2v2 + btv + bo. 
(v - Pt)2(v - P2) 
In this case, we look for an expansion of the form 
913 
(A.24) 
(A.25) 
(A.26) 
G(v) = ~ 
+ 
A 12 
+ ~ 
(A.27) 
v - pl 
(v-pt)2 
v -
p2 
Here, we need the 11( v- p1 )2 term in order to obtain the correct denominator in eq. (A.26) 
when we collect terms over a least common denominator. We also need to include the 
ll(v - p1) term in general. To see why this is so, consider equating eqs. (A.26) and (A.27) 
and multiplying them through by the denominator of eq. (A.26): 
b2v2 + b1v + bo = A11(v- Pt)(v- P2) 
+ A!2(v- P2) + A21(v - P1f 
(A.28) 
Again, if we equate coefficients of equal powers of v, we obtain three equations (for 
the coefficients of the v 0 , v 1, and v2 terms). If we omit the A11 term in eq. (A.27), we will 
then have three equations in two unknowns, which in general will not have a solution. By 
including this term, we can always find a solution. In this case also, however, there is a 
much simpler method. Consider eq. (A.27) and multiply through by (v - p1 f: 
2 
A21(v- Pl)2 
(v - PI) G(v) = A11(v - PI)+ A12 + 
(A.29) 
v - P2 
From the preceding example, we see immediately how to determine A12: 
A 
= [( _ 
)2G( )]! 
= b2Pi + htPt + bo 
12 
V 
Pl 
V 
u = p1 
• 
PI- P2 
(A.30) 
As for A11 , suppose that we differentiate eq. (A.29) with respect to v: 
d 
2 
[2(v - p 1) 
(v-pJ)
2
] 
-d [(v -
pJ) G(v)] = A11 + A21 
-
( 
)2 . 
v 
v -
p2 
v-p2 
(A.31) 
It is then apparent that the final term in eq. (A.31) is zero for v = Pt. and therefore, 
A11 = [:v(v- Pt)
2
G(v)Jiv =p, 
(A.32) 
Zb2P1 + bt 
b2Pi + b1P1 + bo 
PI - P2 
(Pt - P2)2 

914 
Appendix 
Finally, by multiplying eq. (A.27) by v - p2, we find that 
A 
= [( _ 
)G( )JI 
_ b2p~ + b1P2 + bo 
21 
v 
P2 
v 
V=fJ2 -
( 
)2 
P2 - PI 
(A.33) 
This example illustrates all of the basic ideas behind partial-fraction expansion in the 
general case. Specifically, suppose that the denominator of G(v) in eq. (A.12) has distinct 
roots p1, ... , Pr with multiplicities 0'[, . .. , O'r; that is, 
G(v) = 
bn- [Vn- 1 + ... + blv + bo 
(v - Pl)u'(V - P2)u2 ••• (v - Pr)ur 
(A.34) 
In this case, G(v) has a partial-fraction expansion of the form 
G( ) _ 
All 
A12 
A1u, 
v
- - -
+ 
2 + ... + -----'-----
v -
pl 
(v-p1) 
(v-p1)u, 
+~+ 
... + 
A2uz 
v - P2 
(v - P2)uz 
Art 
Aru, 
+ .. . + - -+ ... + ... +( 
) 
V -
Pr 
V- Pr u, 
(A.35) 
r 
u ; 
A;k 
= LL <v _ p ·)k' 
i=l k = I 
1 
where the Aik are computed from the equation 1 
(A.36) 
This result can be checked much as in the example: Multiply both sides of eq. (A.35) 
by (v - Pi)u; and differentiate repeatedly, until A;k is no longer multiplied by a power of 
v - p;. Then set v = Pi· 
ExampleA.1 
In Example 4.25, we examine an LTI system described by the differential equation 
d
2y(t) 
4 dy(t) 
3 ( ) _ dx(t) 
2 ( ) 
(A.3?) 
----;[j2 + --;[( + y t -
--;[( + X t . 
The frequency response of this system is 
. 
jw +2 
H(jw) = (jw)2 + 4jw + 3' 
(A.38) 
To determine the impulse response for this system, we expand H(jw) into a sum 
of simpler terms whose inverse transforms can be obtained by inspection. Making the 
subsitution of v for jw, we obtain the function 
1 Here, we use the factorial notation r! for the product r(r - l)(r - 2) ... 2 · 1. The quantity 0! is defined 
to be equal to 1. 

Appendix 
v+2 
G(v) = 
2 
4 
3 
v + v+ 
v+2 
(v + 1)(v + 3)" 
The partial-fraction expansion for G(v) is then 
where 
Thus, 
G( ) _ 
A11 
Az1 
v- --+--
v + 1 
v + 3' 
- 1 + 2 
1 
Au = [(v + 1)G(v)] lv =- 1 = _ 1 + 3 = 2' 
- 3 + 2 
1 
A21 = [(v + 3)G(v)] lv=-3= _ 3 + 1 = 2· 
I 
I 
H(jw) = jw 2+ 1 + jw 2+ 3' 
and the impulse response of the system, obtained by inverting eq. (A.43), is 
1 -
1 -
h(t) = 2e 1u(t) + 2e 
31 u(t). 
915 
(A.39) 
(A.40) 
(A.41) 
(A.42) 
(A.43) 
(A.44) 
The system described by eq. (A.37) can also be analyzed using the techniques 
of Laplace transform analysis, as developed in Chapter 9. The system function for this 
system is 
s+2 
H(s) = 
2 
4 
3' 
s + s + 
(A.45) 
and if we substitute v for s, we obtain the same G(v) given in eq. (A.39). Thus, the 
partial-fraction expansion proceeds exactly as in eqs. (A.40)-(A.42), with the result that 
I 
I 
H(s) = _l_ + _l_. 
s+1 
s+3 
(A.46) 
Inverting this transform, we again obtain the impulse response, as given in eq. (A.44). 
ExampleA.2 
We now illustrate the method of partial-fraction expansion when there are repeated fac-
tors in the denominator. In Example 4.26, we considered the response of the system 
described in eq. (A.37) when the input was 
x(t) = e-1u(t). 
From eq. 4.81, the Fourier transform of the output of the system is 
. 
jw + 2 
Y(JW) = (jw + 1)2(jw + 3)" 
Substituting v for jw, we obtain the rational function 
v+2 
G(v) = (v + 1)2(v + 3) · 
(A.47) 
(A.48) 
(A.49) 

Appendix 
917 
The B;k can be calculated in a manner similar to that used earlier: 
B 
1 
( 
)u·- k [ d" ;-k [(1 
- 1 )u·G( )]JI 
ik = (u;-k)! - p; 
I 
dv"; - k 
- P; V 
I 
V 
-
. . 
v - p~ 
(A.59) 
As before, the validity of eq. (A.59) can be determined by multiplying both sides of 
eq. (A. 58) by (1 - pj 1v)u;, then differentiating repeatedly with respect to v, until B ;k 
is no longer multiplied by a power of 1 - pj 1v, and finally, setting v = p;. 
ExampleA.3 
Consider the causal LTI system in Example 5.19 characterized by the difference equation 
3 
1 
y[n] - 4y[n - 1] + Sy[n- 2] = 2x[n]. 
(A.60) 
The frequency response of the system is 
(A.61) 
For discrete-time transforms such as this, it is most convenient to substitute v for e- jw. 
Making this substitution, we obtain the rational function 
2 
G( v) = -1---_"3 v- +--'1 v"C'z 
4 
8 
2 
I 
I 
' 
(1 -
2v)(1 - 4v) 
Using the partial-fraction expansion specified by eqs. (A.57)-(A.59), we obtain 
Thus, 
G( ) _ 
B11 
Bz1 
v -
--~- + --~-, 
1 - 2v 
1 - 4v 
B 11 
[ (1- ~v )a(v)]'v~z = 1 = 4 
= 4, 
B21 
[ (1 - ~v )a(v) Jlv~
4 = 1 = 
2 = -2. 
2 
(A.62) 
(A.63) 
(A.64) 
(A.65) 
(A.66) 
and taking the inverse transform of eq. (A.66), we obtain the unit impulse response: 
(1)" 
(1)" 
h[n] = 4 2 u[n] - 2 4 u[n]. 
<Aim 
In Section 10.7, we developed the tools of z-transform analysis for the exami-
nation of discrete-time LTI systems specified by linear constant-coefficient difference 

918 
Appendix 
equations. Applying those techniques to this example, we find that the system function 
can be determined by inspection from eq. (A.60) and is 
2 
H(~ = 
. 
1 - 1z- 1 + !z-2 
4 
8 
(A.68) 
Then, substituting v for z- 1, we obtain G(v) as in eq. (A.62). Thus, using the partial-
fraction expansion calculations in eqs. (A.63)-(A.65), we find that 
4 
2 
H(z) = 
-
, 
1 - !z- 1 
1 - !z- 1 
2 
4 
which, when inverted, again yields the unit impulse response of eq. (A.67). 
ExampleA.4 
Suppose that the input to the system considered in Example A.3 is 
(1 )" 
x[n] = 4 u[n]. 
Then from Example 5.20, the Fourier transform of the output is 
Substituting v fore- jw yields 
2 
G(v) = 
. 
(1 - !v)(1 ~ ±v)2 
Thus, using eqs. (A.58) and (A.59), we obtain the partial-fraction expansion 
and find 
Therefore, 
G( ) 
Bu 
. 
B12 
B21 
v = - -+ 
+--
1 - !v 
(1 - !v)2 
1 - !v 
4 
4 
2 
B11 = (-4) [ :v (1 -~v )
2 
G(v)l=
4 
= -4, 
B12 = ((1- ~v r 
G(v)Jiv=
4 
= -2, 
B21 = ((1- ~v)G(v)l =
2 
= 8. 
(A.69) 
(A.70) 
(A.71) 
(A.72) 
(A.73) 
(A.74) 
(A.75) 
(A.76) 
(A.77) 

Appendix 
919 
which can be inverted by inspection as follows, using the Fourier transform pairs in 
Table4.2: 
{ (1)" 
(1)" 
(1)"} 
y[n] = 
- 4 4 - 2(n + 1) 4 + 8 2: 
u[n]. 
(A.78) 
ExampleA.S 
Improper rational functions are often encountered in the analysis of discrete-time sys-
tems. To illustrate this, and also to show how they can be analyzed using the techniques 
developed here, consider the causal LTI system characterized by the difference equation 
5 
1 
11 
1 
y[n] + 6y[n - 1] + 6y[n - 2] = x[n] + 3x[n- 1] + 6 x[n- 2] + 3x[n- 3]. 
The frequency response of this system is 
1 + 3e- Jw + !!e- J2w + !e- J3w 
H(elw) = 
6 
3 
1 + le-JW + ! e-J2W 
6 
6 
Substituting v for e- jw, we obtain 
1 + 3v + !!v2 + !v3 
G(v) = -----;;--'6"-----.......-:-"-3-
1 + lv + !v2 
6 
6 
(A.79) 
(A.80) 
This rational function can be written as the sum of a polynomial and a proper 
rational function: 
btv + bo 
G(v) = co+ CtV + -----.---..,--
1 + lv + !v2 • 
6 
6 
Equating eqs. (A.80) and (A.81), and multiplying by 1 + ~v + iv2 , we obtain 
11 
2 1 
3 
(5 
) 
1 + 3v + 6 v + 3v 
= (co + bo) + 6 co + Ct + bt v 
Equating coefficients, we see that 
1 
1 
6C[ = 3 ~ Ct = 2, 
1 
5 
11 
6Co + 6 cl = (f ~ Co = 1, 
5 
1 
6 co + Ct + bt = 3 ~ bt 
6, 
co + bo = 1 ~ bo = 0. 
Thus, 
(A.81) 
(A.82) 
(A.83) 
(A.84) 

920 
Appendix 
Also, we can use the method developed here to expand the proper rational function 
in eq. (A.81): 
!v 
6 
1 + ?.v + !v2 
6 
6 
The coefficients are 
Therefore, we find that 
B11 
B 21 
(1 + ~v) + (1 + ~v) · 
(1 + ~v)(1 + ~v) 
B 11 = (__l;--)1 
= 1, 
1 + 2v 
v =-3 
B21 = (__l;--)1 
= - 1. 
1 + 3V 
v= - 2 
and by inspection, we can determine the impulse response of this system: 
h[n] = «S[n] + 2«S[n- 1] + [ (-n· -(- ~ r 
]u[n]. 
(A.85) 
(A.86) 
(A.87) 

ANswERS 
931 

932 
Answers 
Chapter 1 Answers 
1.1. -0.5, - 0.5, j , - j, j , 1 + j , 1 + j, 1 - j, 1 - j 
1.2. 5ei0, 2ei7T, 3e- i7T12, e- j7TI3, .fiei7T14, 2e- j7TI2, .fiei7T14, ei7T12, e- jTTII Z. 
1.3. (a) Poo = 0, Eoo = ~ 
(b) Poo = 1, Eoo = oo 
(c) Poo = ~' ~oo = 00 
(d) Poo = O, Eoo = t 
(e) Poo = 1, Eoo = 00 
(t) Poo = t , Eoo = 00 
1.4. (a) n < 1 and n > 7 
(b) n < - 6 and n > 0 
(c) n < -4 and n > 2 
(d) n < - 2 and n > 4 
(e) n < - 6 and n > 0 
1.5. (a) t > - 2 
(b) t > -1 
(c) t > - 2 
(d) t < 1 
(e) t < 9 
1.6. (a) No 
(b) No 
(c) Yes 
1.7. (a) lnl > 3 
(b) all t 
(c) lnl < 3, lnl -
00 
(d) ltl -
00 
1.8. (a) A = 2, a = 0, w = 0, cf> = 7T 
(b) A = 1, a = 0, w = 3, cf> = 0 
(c) A = 1, a = 1, w = 3, cf> = I 
(d) A = 1, a = 2, w = 100, cf> = I 
1.9. (a) T = ~ 
(b) Not periodic 
(c) N = 2 
(d) N = 10 
(e) Not periodic 
1.10. 7T 
1.11. 35 
1.12. M = - 1, no = - 3 
1.13. 4 
1.14. A 1 = 3,tJ = O, Az = -3,tz = 1 
1.15. (a) y[n] = 2x[n- 2] + 5x[n- 3] + 2x[n- 4] 
(b) No 
1.16. (a) No 
(b) 0 
(c) No 
1.17. (a) No; e.g.,y( -7r) = x(O) 
(b) Yes 
1.18. (a) Yes 
(b) Yes 
(c) C ::::; (2no + l)B 
1.19. (a) Linear, not time invariant 
(c) Linear, time invariant 
1.20. (a) cos(3t) 
(b) cos(3t- 1) 
Chapter 2 Answers 
(b) Not linear, time invariant 
(d) Linear, not time invariant 
2.1. (a) YI [n] = 25[n + 1] + 45[n] + 25[n - 1] + 25[n - 2] - 25[n - 4] 
'(b) Yz[n] = Y1 [n + 2] 
(c) y3[n] = yz[n] 
2.2. A = n - 9, B = n + 3 
1n+l 
2.3. 2[1 - 2 
]u[n] 
{ 
n - 6, 
7 ::::; n :5 11 
2 4 
[ ] 
6, 
12 ::::; n ::::; 18 
• • Y n = 
24 - n, 
19 :5 n :5 23 
0, 
otherwise 

Answers 
933 
2.5. N = 4 
[ 
3" 
n<O 
2.6. y[n] = r 
2 , 
n ~ 0 
2.7. (a) u[n- 2] - u[n- 6] 
(b) u[n- 4] - u[n- 8] 
(c) No 
(d) y[n] = 2u[n] - 8[n] - 8[n -
1] 
{ 
t + 3, 
- 2 < t :5 - 1 
t+4 
-l<t:50 
2•8• y(t) = 
2 - it, 
0 < t :5 1 
0, 
elsewhere 
2.9. A = t - 5, B{ t~ t - 4 
2.10. (a) y(t) = 
a1' + a-t, 
0, 
· 
1-e- 3(1- 3) 
2.11. (a) y(t) = 
3 
' 
0 :5 t:5a 
a:5t:51 
l:5t:51+a 
otherwise 
-00 < t :5 3 
3<t :5 5 
' 
{0, 
(l - e - 6)e - 3(!- 5) 
3 
, 
5<t:5oo 
(b) g(t) = e-3(t - 3>u(t- 3) - e-3(t-S>u(t - 5) 
2.12. A = 
1 _~ _ 3 
2.13. (a) A = ~ 
(b) g[n] = 8[n] -
~8[n - 1] 
2.14 . . hi (t), h2(t) 
(b) a = 1 
(c) g(t) = dy(t) 
dt 
2.16. (a) True 
(b) False 
(c) True 
(d) True 
2.17. (a) y(t) = I~j[e< - I+ 3j)
1 - e- 41]u(t) 
(b) y(t) = ~ [e- 1(cos 3t + sin 3t) - e- 41]u(t) 
2.18. (1/4)n-l u[n- 1] 
2.19. (a) a = ~. ,8 = 1 
2.20. (a) 1 
(b) 0 
(b) [2(4)n -
(~)n]u[n] 
(c) 0 
Chapter 3 Answers 
3.1. x(t) = 4cos(*t)- 8cose; t + I) 
3.2. x[n] = 1 + 2sin( 4; n + 3;) + 4sin( 8; n + 5;) 
3.3. wo = J• ao = 2, a2 = a-2 = 4, as = a:_5 = - 2} 
[ 
0, 
k = 0 
3.4. ak = 
e - jk7rf23si~~¥->, 
k -=F 0 

934 
3.5. w2 = w I· bk = e- Jkw 1 [a-k +ad 
3.6. (a) X2(t), X3(t) 
(b) X2(t) 
3.7. ak = { j;~k 
~: ~ 
J¥k' 
3.8. x1(t) = J2sin(7Tt), x2(t) = -J2sin(1Tt) 
3.9. ao = 3, a1 = 1 - 2j, a2 = -1, a3 = 1 + 2j 
3.10. ao = O, a - 1 = - j , a-2 = -2j, a- 3 = -3j 
3.11. A = 10, B = ~ , C = 0 
3.12. ck = 6 for all k 
3.13. y(t) = 0 
3.14. H(ei'Tr12) = H *(ei37r12) = 2ei'Tr14, H(ei0) = H(ei'Tr) = 0 
3.15. lkl > 8 
3.16. (a) 0 
(b) sine; n + ~) 
(c) 0 
3.17. S1 and S3 are not LTI. 
3.18. S 1 and S2 are not LTI. 
Answers 
3.19. (a) d~;t) + y(t) = x(t) 
(b) H(jw) = (1+1Jw) 
(c) y(t) = Jzcos(t- ~) 
3.20. (a) d~W) + d~;r) + y(t) = x(t) 
(b) H(jw) = ( 1 + J~ -w2) 
(c) -cost 
Chapter 4 Answers 
4 1 ( ) 
e- jw 
(b) 4e - jw 
.. a 
2+jw 
4+w2 
4.2. (a) 2cosw 
(b) -2jsin2w 
4.3. (a) ~[ef7rl4 5(w - 21T)- e- J7rl45(w + 21T)] 
J 
(b) 21T5(w) + 1T[ef7r!S5(w - 61r) + e-J7r!S5(w + 61r)] 
4.4. (a) 1 + cos 41Tt 
(b) 
4 5 x(t) = - 2 sin(3(r- 312)) t = k'Tr + ~ for nonzero integers k 
• • 
7r(t- 3/2) 
' 
3 
2 
4.6. (a) X1(jw) = 2X(- jw)cosw 
(b) X2(jw) = ~e-J
2wX(j*) 
(c) X3(jw) = - w2e-Jwx(jw) 
4.7. (a) neither, neither 
(b) imaginary, odd 
(c) imaginary, neither 
(d) real, even 
4.8. (a) 
2si~(~/2) + 1Tl>(w) 
(b) 
2sin(~/2) 
JW 
)W 
4.9. (a) ~ 
_ e~jw 
(b) sinw 
(c) sinw _ cosw 
~ 
~ 
w 
~ 
~ 
{ 
j/21T, 
-2 ::s w < 0 
4.10. (a) X(jw) = 
- j/21T, 
0 ::s w < 2 
(b) A = 2~3 
0, 
otherwise 

Answers 
4.11. A = ~ . B = 3 
4.12. (a) -(I !t )2 
(b) -j27Twe- lwl 
4.13. (a) No 
(b) Yes 
(c) Yes 
4.14. x(t) = Jl2[e- 1 -
e- 21 ]u(t) 
4.15. x(t) = 2te- 11iu(t) 
4.16. (a) g(t) = 7T £ S(t- k41r) 
k= - "' 
{ 
4 
lwl ::5 1 
(b) X(jw) = o: 1 < lwl ::5 4 
4.17. (a) False 
(b) True 
{ 
~. 
ltl < 1 
4.18. h(t) = - ~ + &. 
.1 ::5 ltl ::5 5 
-w + ~· 
5 < ltl < 7 
0, 
otherwise 
4.19. x(t) = e- 41 u(t) 
4.20. h(t) = fie-112 sin( f" t)u(t) 
Chapter 5 Answers 
5.1. (a) 
(b) 
0.15e- jw 
1.25-cosw 
5.2. (a) 2 cos w 
(b) 2j sin(2w) 
5.3. (a) j{ej1TI4S(w- i)- e- j1T14S(w + i)} 
(b) 47Tl>(w) + 7T{ej1TI8S(w -
~) + e- j1TI8S(w + ~)} 
5.4. (a) Xt[n] = 1 +cos(fn) 
(b) -4 sin;,~ n) 
s in[ .?!(n -~)] 
5;5. x[n] = 
1T(,._ ~i , and x[n] = 0 for n = :too 
5.6. (a) X1(ejw) = (2cosw)X(e-jw) 
(b) X2(ejw) = CRe{X(ejw)} 
(c) X3(ejw) = - £rX(ejw) - 2j d~X(ejw) + X(ejw) 
5.7. (a) imaginary, neither 
(b) real, odd 
(c) real, neither 
5.8. x[n] = 
n + 3, 
-1 ::5 n ::5 1 
{ 
1, 
n ::5 -2 
4, 
n 2:: 2 
5.9. x[nl = -l>[n + 2] + l>[n + 1] + l>[n] 
5.10. A= 2 
5.11. a = 7T 
5.12. I ::5 lwei ::5 7T 
5.13. h2[n] = -2(i)"u[n] 
5.14. h[n] = ~S[n] -1?S[n - 2] 
935 

936 
5.15. W e = 37T/4 
5.16. (a) a = ~ 
(b) N = 4 
(c) No 
5.17. bk = ~( -1)k 
5.18. ak = ~(~) l kl 
5.19. (a) H(eiw) = (I 
1 
. )1
(1 
1 
. ) 
-2e ;w 
+3 e JW 
(b) h[n] = ~ (~)nu[n] + ~(- ~ )nu[n] 
4 
- j w 
5.20. (a) H(eiw) = ~ 
. 
! - 5e JW 
(b) y[n] -
~y[n - 1] = ~x[n - 1] 
Chapter 6 Answers 
6.1. (a) A = IH(jwo)l 
(b) to = -
1:H (Jwo) 
wo 
6.2. <f.H(eiwo) = -n0(w0) + 27Tk for some integer k. 
6.3. (a) A = 1 
(b) T(w) > 0 for w > 0 
6.4. (a) 2cos(}n - 7T) 
(b) 2sinC;n -
3;) 
6.5. (a) g(t) = 2cos(2wct) 
(b) more concentrated 
6.6. (a) g[n] = ( -l)n 
(b) more concentrated 
6.7. (a) 1,000 Hz and 3,000 Hz 
(b) 800Hz and 3,200 Hz 
6.8. 7T -
(J) p :5 (J) :5 7T 
6.9. Final value = 2/5, to = 2/5 sec 
{ 
- 20 
(J) « 0. 1 
6.10. (a) 20 log10 IH(jw )I = 
20 l~g10(w ), 0.1 « w « 40 
32, 
(J) » 40 
{
20, 
(b) 20log10 IH(jw)l = -20log10(w) + 6, 
-28, 
. 
(J) « 0.2 
0.2 « 
(J) « 50 
(J) »50 
{ 
20, 
(J) « 0.5 
6.11. (a) 20log10 IH(jw)l = - 20log10(w) + 14, 0.5 « w «50 
- 40 log10(w) + 48, 
w »50 
{ 
0, 
(J) « 1 
(b) 20log10 IH(jw)l = 
- 40log10 w, 
1 « w «50 
- 20 log 10 w - 34, 
w » 50 
6 12 H ( . ) _ 
O.OI(jw+40) 
' 
' 
2 JW 
-
(jw + l)(jw+8) 
6.13. (a) not unique 
(b) unique 
· 614 H ( · ) = 0 2 X 10-4 (Jw+SO)(jw+IO) 
• 
• 
I JW 
• 
(jw+0.2)2 
Answers 

Answers 
6.15. (a) critically damped 
(b) underdamped 
(c) overdamped 
(d) underdamped 
6.16. y[n] + ~y[n- 1] = ~x[n] 
6.17. (a) oscillatory 
(b) nonoscillatory 
6.18. No 
6.19. R 
<== 2j€ 
6.20. T(W) = 2 
1 
Chapter 7 Answers 
7.1. lwl > 5,0007T 
7.2. (a) and (c) 
7.3. (a) 8,0007T 
(b) 8,0007T 
(c) 16,0007T 
7.4. (a) wo 
(b) wo 
(c) 2wo 
(d) 3wo 
7 5 IH( . )j _ { T, 
jwj :5 W e 
h 
~ 
< 27T _ wo xH( · ) _ 0 
• • 
JW 
-
0 
th 
. , w ere 2 <We 
y 
2 , '~--
JW 
-
, 
o erwtse 
7 .6. T max = _
+1T 
WJ 
W2 
7.7. H(jw) = 2sin~~T/2) X eJ(wT/2) 
7.8. (a) Yes 
4 
{ O, 
k = 0 
(b) g(t) = L. akeJk1Tt, where ak = 
- j(~)k+l, 1 :5 k :5 4 
k= - 4 
j(~)-k + i , 
-4 :::; k :::; -1 
7.9. wo = 507T 
7.10. (a) False 
(b) True 
(c) True 
7 .11. (a) Xe(jw) is real 
(b) Max{Xe(jw)} = 0.5 X 10-3 
(c) Xe(jw) = 0 for lwl <== 1,5007T 
(d) Xe(jw) = Xe(j(w - 2,0007T)) for 0 :5 w :5 2,0007T 
7.12. lwl <== 7507T 
7.13. h[n] = o[n- 2] 
7 14 h[ ] = _ sin[7T(n - ~)] 
• • 
n 
T1T(n - ! )2 
7.15. N = 2 
7.16. x[n] = 4Cin(7Tnl2))2 
1Tn 
7.17. ldeallowpass filter with cutoff frequency 7T/2 and passband gain of unity 
7.18. Ideallowpass filter with cutoff frequency 7T/4 and passband gain of 2. 
7.19. (a) y[n] = sin(;:~n/
3
) 
(b) y[n] = ~o[n] 
7.20. (a) Yes 
(b) No 
937 

938 
Answers 
Chapter 8 Answers 
8.1. m(t) = ~e - jwct 
8.2. (a) No constraint necessary 
(b) lwei > 1,0001T 
8.3. y(t) = 0 
8.4. y(t) = sin 2001Tt 
8.5. m = 2~ 
8.6. A= 4 
8.7. wo = 2we,A = 2 
8.8. (a) Yes 
(b) Yes, x(t) = {y(t) sin wet}* 
2 si;~<
1 
8.9. (a) lwl > 2we 
(b) wo = We, A = 2 
8.10. (a) X(jw) = 0 for lwl :::::: 1,0001T 
(b) We = 1,0001T, A = 4 
8.11. (a) ~c :::; lwl :::; 
3~c, Gain = 1 
(b) A = 2laJ!, </> = ~a1 
8.12 . .il = o.5 x w-4 
8.13. (a) p(O) = i, 
(b) p(kT1) = 0 
8.14. Y(jw) = 1r8(w - We) -
~j 8(w - We - Wm) ~ ~j 8(w - We + Wm) 
8.15. wo = 0 and wo = 1T 
8.16. 0 :::; w :::; 3; and 5; 
:::; w :::; 1T 
8.17. 0 :::; lwl :::; I 
818 H( jw) _ { j, 
0 < W :::; i 
• • 
e 
-
-. 
-:!!: < 
< 0 
], 
4 -
w 
8.19. N = 20 
00 
8.20. p[n] = 2:: 8[n - 2k] 
k= -oo 
Chapter 9 Answers 
9.1. (a) u > -5 
(b) u < -5 
(c) -oo :::; u :::; oo 
(d) no value of u 
(e) lui < 5 
(f) u < 5 
- (s+5) 
9.2. (a) es+S ,CR.e{s} > -5 
(b) A= -1,to = -1, CR.e{s} < -5 
. 9.3. CR.e{f3} = 3, dm{/3} arbitrary 
9.4. 1 + 2j, 1 - 2j, CR.e{s} < 1 
9.5. (a) 1,1 
(b) 0,1 
(c) 1,0 
9.6. (a) no 
(b) yes 
(c) no 
(d) yes 
9.7. 4 
9.8. two sided 
' 
9.9. x(t) = 4e- 41 u(t) - 2e-31 u(t) 

Answers 
9.10. (a) lowpass 
(b) bandpass 
(c) highpass 
9.11. IX(Jw )j = 1 
9.12. (a) not consistent 
(b) consistent 
(c) consistent 
9.13. a = -1, {3 = & 
9.14. X(s) = 1/[4(s2 - h + i)(s2 + h + i)J,- J} < CR-e{s} < J} 
9.15. X(s) = i:4 ; CR-e{s} > 0, 
Y(s) = s2: 4 ; CR-e{s} > 0 
9.16. (a) 2 
(b) a> 0 
9 17 
d
2 
~I) + 10 d y(t) + 16y(t) = 12x(t) + 3 dx(t) 
• 
• 
dt 
dt 
dt 
9.18. (a) H(s) = s2 +~+ 1 , CR-e{s}> -4 
(b) Lowpass 
(c) H(s) = s2+ 10
1 3s+ 1, CR-e{s} > -0.0005 
(d) Bandpass 
9.19. (a) s!2, CR-e{s} > -2 
- 6 
(b) 1 + ;+2, CR-e{s} > -2 
(c) s!4 + s!2' CR-e{s} > -2 
9.20. (a) e- 1 u(t) - e-21 u(t) 
(b) e- 1u(t) 
(c) 2e- 1u(t)- e- 21u(t) 
Chapter 1 0 Answers 
10.1. (a) lzl > 4 
(b) lzl < 4 
(c) lzl > 1 
(d) 4 < lzl < 2 
I 
- J 
I 
10.2. X(z) = 125 1_z! z-l; lzl > 5 
5 
10.3. ial = 2, no arbitrary 
10.4. poles at z = ~e:tj'7T
14
, ROC: lzl < ~ 
10.5. (a) 1,1 
(b) 2,0 
(c) 1,2 
10.6. (a) No 
(b) No 
(c) Yes 
(d) Yes 
10.7. 3 
10.8. two sided 
10.9. x[n] = ~u[n] + ~(-2)
11 u[n] 
939 
10.10. (a) x[O] = 1, x[l] = ~ · x[2] = - ~ 
(b) x[Ol = 3, x[ -1] = - 6, x[ -2] = 18 
10.11. x[n] = { <4)
11
, 
0 ::;; n.::;; 9 
0, 
otherwise 
10.12. (a) highpass 
(b) lowpass 
(c) bandpass 
10.13. (a) G(z) = 1- z-6; lzl > 0 
(b) X(z) = 
: :::~=~ ; lzl > 0 
10.14. (a) no = 2 
(b) G(z) = (~~~:~
7 
)2 

940 
10.15. <1)nu[n] and (-1)nu[n] 
10.16. (a) Not causal 
(b) Causal 
(c) Not causal 
10.17. (a) Yes 
(b) Yes 
10.18. (a) y[n]- ~y[n- 1] + ~y[n- 2] = x[n] - 6x[n - 1] + 8x[n - 2] 
(b) Yes 
10.19. (a) Xl(z) = 1 _L- ~, lzl > ~ 
4 
(b) xz(z) = 2, All z 
(c) X3(Z) = 1 _ L- ~, lzl > 1 
2 
10.20. (a) - (- 1)nu[n] 
(b) 1<-1)nu[n] + i<~)nu[n] 
(c) -
~( -1)nu[n] + i<~)nu[n] 
Chapter 11 Answers 
111 R ( ) + 
HI(Z) 
• • 
0 z 
I + G(t )H1 (z) 
11 2 
H 1(s)H2(s) 
• • I + H1 (s)G1 (s)+H1 (s)H2(s)G2(s) 
11.3. b < - 1 
11.4. G(s) = .!. s 
11.5. -
~ < b < ~ 
11.6. FIR 
11.7. K > - 6 
11.8. -3 < k < 0 
11.9. No, root locus stays on real axis 
11.10. Double pole at s = -1, double zero at s = 1 
11.11. 0 < k < ~ 
11.12. Pole and zero positions alternate on the real axis 
11.13. Unstable for all K 
11.14. (a) 0 
(b) 1 
11.15. K > -1 
11.16. K > - 1 
11.17. - 1 < K < 4 
11.18. - 1 < K < 1 
11.19. Unstable 
11.20. Gain margin is infinite, phase margin is 2 tan - I j2 
Answers 

INDEX 
Absolutely summable impulse 
response, 113 
Absolutely integrable impulse 
response, 114 
Accumulation property 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 
375-76 
unilateral z transform, 793 
Accumulator, 44 
Acoustic feedback, 830-32, 855 
Adders in block diagrams, 125, 126 
Additivity property, 53 
Aliasing, 527-34 
All-pass systems, 430, 498, 681-82 
AM. See Amplitude modulation (AM) 
Amplifier 
chopper, 652 
operational, 821, 896-97 
Amplitude modulation (AM), 236~37, 
322, 324, 583 
pulse-train carrier, 601-4, 605 
sinusoidal, 583- 87 
complex exponential carrier, 583-85 
demodulation for, 587-94 
discrete-time, 619-23 
frequency-division multiplexing 
(FDM) using, 594-97 
single-sideband, 597-601 
sinusoidal carrier, 585-87 
Amplitude-scaling factor, 483 
Analog-to-digital (A-to-D) 
converter, 535 
Analysis equation 
continuous-time Fourier series, 191 
continuous-time Fourier 
transform, 288 
discrete-time Fourier series, 213 
discrete-time Fourier transform, 
361, 390 
Angle criterion, 836-40 
Angle modulation, 611-13 
Angle (phase) of complex number, 71 
Anticausality, 695 
Aperiodic convolution, 222 
Aperiodic signal, 12, 180 
continuous-time Fourier transform for, 
285- 89 
discrete-time Fourier transform for, 
359-62 
Associative property of LTI systems, 
107-8 
Audio systems 
feedback in, 830-32, 855 
frequency-shaping filters in, 232 
Autpcorrelation functions, 65, 168, 
170-72, 738 
Automobile suspension system, analysis 
of, 473-76 
Average, weighted, 245 
Averaging system, noncausal, 47 
Band-limited input signals, 541 
Band-limited interpolation, 523- 24 
Bandpass filters, 237-38, 326 
Bandpass-sampling techniques, 564-65 
941 

942 
Bandpass signal, 564-65 
Bandwidth of an LTI system, 352-53 
Bartlett (triangular) window, 421 
Bernoulli, D., 178 
Bilateral Laplace transform. See Laplace 
transform 
Bilinear transformation, 814-15 
Bit, 610 
Block diagram(s), 42 
cascade-form, 712, 713, 787-89 
causal LTI systems, 708-13, 
784- 89 
direct-form, 712, 713, 787-89 
first-order systems described by 
differential and difference 
equations, 124-27 
parallel-form, 712, 713, 787- 89 
Bode plots, 436-39 
automobile suspension system, 475 
rational frequency responses, 
456-60 
Breakfrequency,450 
Butterworth filters, 446- 47, 505, 703-6 
Capacitor, 44 
Carrier frequency, 584 
Carrier signal, 583 
Cartesian (rectangular) form for complex 
number, 71 
Cascade-form block diagrams, 712, 713, 
787-89 
Cascade (series) interconnection, 42 
Causal LTI systems, 46-48, 112-13, 
116-27 
block diagram representations for, 
708-13, 784-89 
first-order systems, 124-27 
Laplace transform for, 693-95, 697 
z-transform for, 776-77 
Channel equalization, 609- 10 
"Chirp" transform algorithm, 651 
Chopper amplifier, 652 
Circle, unit, 743 
Circuit, quality of, 456 
Closed-loop system, 818 
Closed-loop poles, 834- 36 
Index 
Closed-loop system function; 820 
Coefficient multiplier, 125, 126 
Coefficients, Fourier series. See Fourier 
series coefficients 
Communications systems, 582-653 
amplitude modulation with pulse-train 
carrier, 601- 4, 605 
discrete-time modulation, 619-23 
pulse-amplitude modulation, 604-10 
digital, 610 
intersymbol interference in, 607- 10 
sinusoidal amplitude modulation, 
583- 87 
with complex exponential carrier, 
583- 85 
demodulation for, 587-94 
discrete-time, 619-23 
frequency-division multiplexing 
(FDM) using, 594- 97 
single-sideband, 597- 601 
sinusoidal carrier, 585-87 
sinusoidal frequency modulation, 583, 
611-19 
narrowband, 613- 15 
periodic square-wave modulating 
signal, 617- 19 
wideband, 615- 17 
Commutative property of LTI systems, 
104 
Compensation for nonideal elements, 
821-22 
Complex conjugate, 72 
Complex exponential(s) 
discrete-time, periodicity properties 
of, 25- 30 
general, 20- 21 
harmonically related, 19 
linear combinations of harmonically 
related. See Fourier series 
LTI system response to, 182-86, 
226-31 
periodic, 186 
sinusoidal amplitude modulation and, 
583-85 
Complex exponential signals, general, 
24-25 

Index 
Complex numbers, 71 
Conditionally stable systems, 892 
Conjugate symmetry, 204- 5, 206, 221, 
303- 6,375 
Conjugation property 
continuous-time Fourier series, 
204-5, 206 
continuous-time Fourier transform, 
303-6 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 375 
Laplace transform, 687 
unilateral, 717 
z-transform, 770 
unilateral, 793 
Constants, time, 448 
dominant, 500-501 
Continuous-time signals 
energy and power of, 5- 7 
examples and mathematical 
representation of, 1- 5 
sampling of, 4 
Continuous-time systems, 448-60 
Bode plots for rational frequency 
responses and, 456- 60 
examples of, 39-41 
first-order, 448-51 
interconnections of, 41-43 
second-order, 451-56 
Continuous-to-discrete-time 
conversion, 535 
Convergence. See also Region of 
convergence 
continuous-time Fourier series, 
195- 201 
continuous-time Fourier transform, 
289- 90 
discrete-time Fourier series, 219- 21 
discrete-time Fourier transform, 
366-67 
Convolution 
aperiodic, 222 
associative property of, 107-8 
commutative property of, 104 
defining continuous-time unit impulse 
function through, 131-32 
distributive property of, 104-6 
operation of, 79, 85 
periodic, 222, 389- 90 
Convolution integral, 90-102 
evaluating, 97- 102 
Convolution property 
943 
continuous-time Fourier series, 206 
continuous-time Fourier transform, 
314-22 
discrete-time Fourier series, 
221,222 
discrete-time Fourier transform, 
382-88 
Laplace transform, 687-88 
unilateral, 717-18 
z-transform, 770-72 
unilateral, 793-94 
Convolution sum, 75-90, 384- 86 
evaluating, 81-84 
Correlation function, 65 
Critically damped systems, 453, 467 
Cross-correlation functions, 65, 
168, 170 
Cutoff frequencies, 237 
Damped sinusoids, 21 
Damping ratio, 452-53 
de offset, 207 
de sequence, 224 
Deadbeat feedback, 907 
Decibels (dB), 232, 233, 437 
Decimation, 549-55 
Degenerative (negative) feedback, 
822, 831-32 
Delay, 44 
group, 430-36 
half-sample, 543-45 
unit, 125 
Delay time, 406 
Demodulation, 585 
defined,583 
sinusoidal amplitude modulation, 
587-94 
asynchronous, 590-94 
discrete-time, 622 
synchronous, 587-90 

944 
Difference· equations 
discrete-time filters described by, 
244- 49 
first-order recursive, 244-45 
nonrecursive, 245-49 
linear constant-coefficient. See Linear 
constant -coefficient difference 
equations 
Differencing property 
discrete-time Fourier series, 222- 23 
discrete-time Fourier transform, 
375-76 
z-transform, 775 
unilateral, 793 
Differential equations 
continuous-time filters described by, 
239-44 
RC highpass filter, 241-44 
RC lowpass filter, 239-41 
linear constant-coefficient. See Linear 
constant -coefficient differential · 
equations 
Differentiating filters 
continuous-time, 232-34, 235 
discrete-time, 541- 43 
Differentiation 
s domain, 688-90, 717 
time-domain, 688, 717 
z domain, 772, 793 
Differentiation property 
continuous-time Fourier series, 206 
continuous-time Fourier transform, 
306- 8 
discrete-time Fourier transform, 380 
Differentiator 
block diagram representation of, 126 
digital, 541-43 
Digital-to-analog (D-to-A) converter, 535 
Direct Form I realization, 161-63 
Direct Form ll realization, 161-63 
Direct-form block diagrams, 712, 713, 
787-89 
Dirichlet, P.L., 180 
Dirichlet conditions, 197- 200, 290, 316 
Discontinuities, 198-200 
Discrete Fourier transform (DFT) for 
finite-duration signals, 417-18 
Index 
Discrete-time Fourier series pair, 213 
Discrete-time LTI filters, 234- 36 
Discrete-time modulation, 619- 23 
Discrete-time nonrecursive filters, 
476-82 
Discrete-time signals, 211 
energy and power of, 5- 7 
examples and mathematical 
representation of, 1- 5 
sampling of, 545- 55 
decimation and interpolation, 
549- 55 
impulse train, 545-49 
Discrete-time systems, 461-72 
first-order, 461- 65 
second-order, 465-72 
Discrete-time to continuous-time 
conversion, 535 
Dispersion, 433 
Distortion 
magnitude and phase, 428 
quadrature, 636 
Distribution theory, 36, 136 
Distributive property of LTI systems, 
104-6 
Dominant time constant, 500-501 
Double-sideband modulation (DSB), 598 
Downsampling, 551 
Duality 
continuous-time Fourier transform, 
295, 309- 11, 322 
discrete-time Fourier transform, 390-96 
between discrete-time Fourier 
transform and continuous-time 
Fourier series, 395- 96 
Echo, 737 
Eigenfunctions, 183- 84, 272 
Eigenvalue, 183, 272 
Elliptic filters, 446-47 
Encirclement property, 847- 50 
Energy-density spectrum, 312, 349, 381 
Energy of signals, 5-7 
Envelope detector, 591, 592 
Envelope function, 285 
Equalization, 649 
channel, 609-10 

Index 
Equalizer, zero-force, 649 
Equalizer circuits, 232, 233 
Euler, L., 178 
Eu1er's relation, 71 
Even signals, 13-14 
continuous-time Fourier series, 206 
discrete-time Fourier series, 221 
Exponentials. See Complex 
exponential(s) 
Exponential signals, 14-30 
continuous-time complex, 15-21 
discrete-time complex, 21-30 
real, 22, 23 
Extension problems, 137 
Fast Fourier transform (FFT), 182, 418 
Feedback. See also Linear feedback 
systems 
applications of, 820-32 
angular position of telescope, 
816-18 
audio, 830-32, 855 
compensation for nonideal 
elements, 821-22 
inverse system design, 820-21 
inverted pendulum, 818- 19 
population dynamics, 824-26 
sampled-data systems, 826-28 
stabilization of unstable systems, 
823- 26 
tracking systems, 828-30 
closed-loop poles, 836-38 
deadbeat, 907 
degenerative (negative), 822, 831- 32 
destabilization caused by, 830-32 
positive (regenerative), 831-32 
proportional, 823 
proportional-plus-derivative, 824 
Typel,906 
Feedback interconnection, 43 
Feedback path, system function of, 820 
Filter(s), 231-50 
Butterworth, 446-47, 505, 703-6 
continuous-time, described by 
differential equations, 239-44 
RC highpass filter, 241- 44 
RC lowpass filter, 239- 41 
continuous-time differentiating, 
232-34,235,541 
945 
discrete-time, described by difference 
equations, 244-49 
first-order recursive, 244-45 
nonrecursive, 245- 49 
elliptic, 446-47 
finite impulse response (FIR), 122 
discrete-time, 476-82 
linear-phase, causal, symmetric, 
579- 80 
frequency-selective, 231, 236- 39, 
318,423 
bandpass, 237-38, 326 
highpass, 237-38, 241-44, 
374-75, 387 
ideal, 237- 39, 439-44 
lowpass, 237, 318, 321-22, 374- 75, 
384,440,442,443 
time-domain properties of ideal, 
439-44 
with variable center frequency, 
325-27 
frequency-shaping, 231, 232- 36 
differentiating filters, 232- 34, 235 
discrete-time LTI filters, 234- 36 
infinite impulse response (IIR), 
123,476 
matched, 170-72, 275 
moving-average, 476-82 
nonideal, 444-47 
Filtering, defined, 231 
Final-value theorem, 690-91 
Finite-duration signals, discrete Fourier 
transform for, 417-18 
Finite impulse response (FIR) filters, 122 
discrete-time, 245-49, 476-82 
linear-phase, causal, symmetric, 
579-80 
Finite sum formula, 73 
First difference, 111. See also 
Differencing property 
First harmonic components, 187 
. First-order continuous-time systems, 
448-51 
First-order discrete-time systems, 
461-65 

946 
First-order recursive discrete-time filters, 
244- 45 
Forced response, 118 
Forward path, system function of, 820 
Fourier, Jean Baptiste Joseph, 179-81 
Fourier series, 177-283. See also 
Filter(s) 
continuous-time, 186-211 
analysis equation of, 191 
conjugation and conjugate 
symmetry of, 204-5 
convergence of, 195-201 
determination of, 190--95 
Dirichlet conditions, 197-200 
duality between discrete-time 
Fourier transform and, 395-96 
examples, 205-11 
Gibbs phenomenon, 200--201, 219 
linear combinations of harmonically 
related complex exponentials, 
186--90 
linearity property of, 202 
multiplication property of, 204 
Parseval's relation for, 205, 206 
square wave, 193-95, 200, 201, 
209,218-19 
synthesis equation of, 191 
table of properties, 206 
time reversal property of, 203 
time scaling property of, 204 
time shifting property of, 202-3 
discrete-time, 211-26 
analysis equation of, 213 
convergence of, 219- 21 
determination of, 212- 21 
first -difference property of, 
222-23 
linear combinations of harmonically 
related complex exponentials, 
211- 12 
multiplication property of, 222 
Parseval's relation for, 223 
square wave, 219-20, 224 
synthesis equation of, 213 
table of properties, 221 
historical perspective, 178- 82 
LTI systems and, 226-31 
Fourier series coefficients 
continuous-time, 191, 286 
convolution property of, 222 
discrete-time, 212, 213 
Index 
real and imaginary parts of, 216, 217 
Fourier series pair, discrete-time, 213 
Fourier transform, 180 
fast (FFT), 182, 418 
geometric evaluation from pole-zero 
plot, 674-82, 763- 67 
all-pass systems, 681-82 
first-order systems, 676-77, 
763-65 
second-order systems, 677-81, 
765-67 
inverse, 284, 288 
magnitude-phase representation of, 
423- 27 
Fourier transform, continuous-time, 
284-357. See also Laplace 
transform 
analysis equations, 300 
for aperiodic signal, 285-89 
convergence of, 289-90 
Dirichlet conditions, 290, 316 
even signals, 304 
examples of, 290--96 
Gibbs phenomenon, 294 
imaginary part of, 304 
impulse train, 299-300 
inverse, 284, 288 
odd signals, 304 
periodic signals, 296- 300 
properties of, 300--330 
conjugation and conjugate 
symmetry, 303- 6 
convolution, 314- 22 
differentiation and integration, 
306-8 
·duality, 295, 309-11, 322 
linearity, 301 
multiplication, 322-27 
Parseval's relation, 312-14 
tables. of, 328-30 
time and frequency scaling, 308- 9 
time shifting, 301-3 
real part of, 304 

Index 
rectangular pulse signal, 293- 94 
sine functions, 295 
symmetric periodic square wave, 
297-98 
synthesis equation for, 288, 300, 314 
two-dimensional, 356-57 
of unit impulse, 292 
Fourier transform, discrete-time, 
358-422 
analysis equation, 361, 390 
convergence issues associated with, 
366-67 
development of, 359-62 
examples of, 362- 66 
finite-duration signals, 417-18 
impulse train, 371- 72, 376 
periodic signals, 367- 72 
properties of, 372-90 
conjugation and conjugation 
symmetry,375 
convolution, 382- 88 
differencing and accumulation, 
375-76 
differentiation in frequency, 380 
duality, 390-96 
linearity, 373 
multiplication, 388- 90 
Parseval's relation, 380-82 
periodicity, 373 
table of, 390, 391 
time expansion, 377-80 
time reversal, 376-77 
time shifting and frequency 
shifting, 373-75 
rectangular pulse, 365-66 
synthesis equation, 361, 390 
unit impulse, 367 
z-transform and, 743 
Fourier transform pairs, 288 
continuous-time, 329 · 
discrete-time, 361, 392 
Frequency( ies) 
carrier, 584 
cutoff, 237 
differentiation in, 380 
fundamental, 17-18 
instantaneous, 613 
Nyquist, 519 
passband, 237 
sampling, 516 
stopband, 237 
947 
Frequency-division multiplexing (FDM), 
594-97 
Frequency-domain characterization. See 
Time-domain and frequency-
domain characterization 
Frequency response, 227-28 
continuous-time delay, 543 
continuous-time ideal band-limited 
differentiator, 541 
discrete-time delay, 543 
discrete-time filter, 542 
first-order system, 677 
highpass filter, 374- 75 
lowpass filter, 374- 75 
discrete-time ideal, 384 
ideal, 318 
LTI systems, 427-39 
LTI systems analysis and, 316 
open-loop, 821 
raised cosine, 629 
rational, Bode plots for, 456-60 
second-order systems, 677- 78, 680 
Frequency scaling of continuous-time 
Fourier transform, 308-9 
Frequency-selective filter, 231, 236-39, 
318,423 
bandpass, 237-38, 326 
highpass, 237- 38, 241-44, 
374-75, 387 
ideal, 237-39 
time-domain properties of, 
439-44 
lowpass, 237 
variable center frequency, 325-27 
Frequency-shaping filters, 231, 
232- 36 
differentiating filters, 232- 34, 235 
discrete-time LTI filters, 234-36 
Frequency shifting property 
continuous-time Fourier series, 206 
continuous-time Fourier transform, 
311, 328 
discrete-time Fourier series, 221 

948 
· discrete-time Fourier transform, 
373-75 
Frequency shift keying (FSK), 646 
Fundamental components, 187 
Fundamental frequency, 17-18 
Fundamental period, 12 
continuous-time periodic signal, 186 
discrete-time periodic signal, 211 
Gain, 428 
linear feedback systems, 835, 858-66 
tracking system, 829- 30 
General complex exponentials, 20-21, 
24-25 
Generalized functions, 36, 136 
Gibbs phenomenon, 200-201, 219, 294 
Group delay, 430-36 
Half-sample delay, 543-45 
Hanning window, 422 
Harmonically related complex 
exponentials, 19 
Harmonic analyzer, 200 
Harmonic components, 187 
Heat propagation and diffusion, 180 
Higher order holds, 526-27 
Highpass filter, 237-38 
frequency response of, 374-75 
ideal bandstop characteristic, 387 
RC, 241-44 
Highpass-to-lowpass 
transformations, 498 
Hilbert transform, 351 
Hold(s) 
higher order, 526-27 
zero-order, 520-22, 523-26 
Homogeneity (scaling) property, 53 
Ideal frequency-selective filter; 237-39 
time-domain properties of, 439-44 
Idealization, 67 
Identity. system, 44 
Image processing 
differentiating filters for, 232-34, 235 
phase representation and, 425-27 
Imaginary part 
complex number, 71 
Index 
Fourier series coefficients, 216, 217 
Impulse response 
absolutely integrable, 114 
absolutely summable, 113 
associated with group delay, 435-36 
causal LTI system, 112 
continuous-time ideal lowpass 
filter, 442 
discrete-time ideallowpass filter, 442 
first-order discrete-time system, 
. 
461-62 
ideallowpass filter, 321-22, 384 
second-order systems, 677-78 
discrete-time systems, 466-68 
Impulse train 
continuous-time Fourier series of, 
208- 10 
continuous-time Fourier transform of, 
299-300 
discrete-time Fourier transform of, 
371-72, 376 
Impulse-train sampling, 516- 20, 545-49 
Incrementally linear systems, 56 
Independent variable, 3-4 
transformation of, 7-14 
Infinite impulse response (IIR) filters, 
123,476 
Infinite sum formula, 73, 89 
Infinite Taylor series, 277 
Initial-value theorem 
Laplace transform, 690-91 
z-transform, 773-74 
Instantaneous frequency, 613 
Integral, convolution, 90-102 
evaluating, 97-102 
Integration, in time-domain, 690, 717 
Integration property 
continuous-time Fourier series, 206 
continuous-time Fourier transform, 
306-8 
Integrator, 126-27 
Interconnection 
convolution property and analysis of, 
386-87 
distributive property of convolution 
and, 105 
feedback, 43 

Index 
LTI systems 
Laplace transform for, 707-8 
system functions for, 707-8 
z-transform for, 784 
parallel, 42-43 
Interference, intersymbol, 607-10 
Intermediate-frequency (IF) stage, 596 
Interpolation, 549-55 
band-limited, 523-24 
linear, 522-23, 526 
reconstruction using, 522-27 
Intersymbol interference (lSI), 607- 10 
Inverse Fourier transform, 284, 288 
Inverse Laplace transform, 670-73 
Inverse LTI system, 734 
Inverse system design, 820-21 
Inverse systems, 45-46 
Inverse z-transform, 757-63 
examples of, 758-763 
Inverted pendulum, 818-19 
Invertibility of LTI systems, 109-11 
Invertible systems, 45-46 
Lacroix, S.F., 180 
Lag,phase,491-92 
Lag network, 890 
Lagrange, J.L., 178-79, 180 
Laguerre polynomials, 738 
Laplace, P.S. de, 180 
Laplace transform, 654-740 
bilateral, 655, 714 
geometric evaluation of, 674-82 
all-pass systems, 681-82 
first-order systems, fl76-77 
second-order systems, 677-81 
inverse, 670-73 
LTI system analysis and 
characterization using, 693-706 
causality, 693-95, 697 
linearity constant-coefficient 
differential equations, 698-700 
stability, 695-98 
poles of, 660 
pole-zero plot of, 660-62, 674-82 
properties of, 682-92 
conjugation, 687 
convolution, 687- 88 
949 
differentiation in s domain, 688-90 
differentiation in time-domain, 688 
initial- and final-value theorems, 
690-91 
integration in time-domain, 690 
linearity, 683-84 
s-domain shifting, 685 
table of, 691-92 
time scaling, 685-87 
time shifting, 684 
region of convergence for, 657-58, 
662-70 
left-sided signal, 666, 669 
rational transform, 669 
right-sided signal, 665-66, 669 
two-sided signal, 666-68 
s-plane representation of, 660, 
663-64 
as system function, 693, 701-13 
block diagram representations, 
708-13 
Butterworth filters, 703-6 
interconnections of LTI systems, 
707-8 · 
transform pairs, 692-93 
unilateral, 714-20 
examples of, 714-16 
properties of, 716-19 
solving differential equations using, 
719-20 
zeros of, 660 
Lead, phase, 491- 92 
Lead network, 890 
Left-half plane, 666 
Left-sided signal, 666 
Linear, time-invariant (LTI) systems, 
41, 56, 74-176. See also Linear 
constant -coefficient difference 
equations; Linear constant-
coefficient differential equations 
bandwidth of, 352-53 
causal, 46-48, 112-13, 116-27 
block diagram representations for, 
124-27, 708-13, 784-89 
described by linear constant-
coefficient difference equations, 
116,121- 24,396-99 

950 
described by linear constant-
coefficient differential equations, 
116, 117-21 
real-part sufficiency property 
of, 417 
continuous-time, 90-102 
convolution -integral representation 
of, 94-102 
described by linear constant~ 
coefficient differential equations, 
330-33 
representation in terms of impulses, 
90-94 
convolution property and, 319-21 
discrete-time, 75- 90 
convolution -sum representation of, 
77- 90 
representation in terms of impulses, 
75- 77 
feedback. See Linear feedback 
systems 
filtering with, 231, 234-36 
Fourier series and, 226-31 
frequency response of, 316 
magnitude-phase representation of, 
427- 39 
interconnection of 
Laplace transform for, 707-8 
z-transform for, 784 
inverse, 109-11, 734 
Laplace transform to analyze and 
characterize, 693-706 
causality, 693-95, 697 
linearity constant -coefficient 
differential equations, 
698-700 
stability, 695-98 
with and without memory, 108- 9 
properties of, 103-8 
associative, 107- 8 
commutative, 104 
distributive, 104-6 
response to complex exponentials, 
182- 86, 226-31 
stability for, 113- 15 
system functions for interconnections 
of, 707-8 
Index 
unit impulse response of cascade of 
two, 107 
unit step response of, 115-16 
windowing in design of, 420-21 
z-transform to analyze and 
characterize, 774-83 
causality, 776-77 
stability, 777-79 
Linear constant-coefficient difference 
equations, 116, 121-24, 396- 99, 
779-81 
finite impulse response (FIR) 
system, 122 
infinite impulse response (IIR) 
system, 123 
natural responses as solutions to, 122 
nonrecursive, 122 
recursive, 122, 123 
unilateral z-transform to solve, 
795- 96 
Linear constant-coefficient differential 
equations, 116, 117-21, 330-33, 
698- 700 
block diagram representation of, 
124- 27 
initial rest condition, 119-20 
natural responses as solutions to, 
119, 121 
particular and homogeneous solutions 
to, 118-19 
unilateral Laplace transform to solve, 
719-20 
Linear feedback systems, 816-908. 
See also Feedback 
closed-loop, 818 
gain and phase margin, 835, 
858-66 
Nyquist stability criterion, 
846-58 
continuous-time, 850-55 
discrete-time, 856-58 
encirclement property, 847-50 
open-loop, 818 
properties and uses of, 819-20 
root-locus analysis of, 832-46 
angle criterion, 836-40 
end points, 836 

Index 
equation for closed-loop poles, 
834- 36 
properties of, 841-46 
sampled-data, 826-28 
Linear interpolation, 522-23, 526 
Linearity, 53- 56 
Linearity property 
continuous-time Fourier series, 
202,206 
continuous-time Fourier 
transform, 301 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 373 
Laplace transform, 683-84 
unilateral, 717 
z-transform, 767 
unilateral, 793 
Log magnitude-phase diagram, 861- 62, 
864-66 
Log-magnitude plots, 436-39 
Lossless coding, 46 
Lowpass filters, 237 
frequency response of, 374-75 
ideal 
continuous-time, 440, 442, 443 
discrete-time, 384, 442, 443 
frequency response of, 318 
impulse responses of, 321-22, 
384,442 
step response of, 443 
RC, 239-41 
Lowpass-to-highpass transformations, 
498 
LTI. See Linear, time-invariant (LTI) 
systems 
Magnitude of complex number, 71 
Magnitude-phase representation 
Fourier transform, 423- 27 
frequency response of LTI systems, 
427-39 
group delay, 430-36 
linear and nonlinear phase, 428- 30 
log-magnitude and Bode plots, 
436- 39 
Mass-spring-dashpot mechanical 
system, 824 
951 
Matched filter, 170-72, 27 5 
Measuring devices, imperfect, 355- 56 
Memory, LTI systems with and without, 
108-9 
Memoryless systems, 44 
Michelson, Albert, 200 
Modulating signal, 583 
Modulation. See also Sinusoidal 
amplitude modulation 
angle, 611-13 
defined, 582 
discrete-time, 619-23 
double-sideband (DSB), 598 
percent, 591 
phase, 611-13 
pulse-amplitude, 604-10 
digital, 610 
intersymbol interference in, 607-10 
pulse-code, 610 
sinusoidal frequency, 583, 611- 19 
narrowband, 613-15 
periodic square-wave modulating 
signal, 617-19 
wideband, 615-17 
Modulation index, 591, 614 
Modulation property, 323. See also 
Multiplication property 
Monge, G., 180 
Moving-average filters, 245-47, 476- 82 
Multiplexing 
defined, 583 
frequency-division (FDM), 594-97 
quadrature, 646 
time-division (TDM), 604, 605 
Multiplication property 
continuous-time Fourier series, 
204,206 
continuous-time Fourier transform, 
322-27 
discrete-time Fourier series, 221, 222 
discrete-time Fourier transform, 
388- 90 
Multiplicities, 155 
Narrowband frequency modulation, 
613- 15 
Natural frequency, undamped, 452- 53 

952 
Natural responses, 119, 121, 122 
Negative (degenerative) feedback, 822, 
831- 32 
Networks, lag and lead, 890 
Nonanticipative system, 46-47 
Noncausal averaging system, 47 
Nonideal filters, time-domain 
and frequency-domain 
characterization of, 444-47 
Nonrecursive filters. See Finite impulse 
response (FIR) filters 
Nonrecursive linear constant-coefficient 
difference equations, 122 
Normalized functions, 273 
Nyquist frequency, 519 
Nyquist plots, 853-58 
Nyquist rate, 519, 556 
Nyquist stability criterion, 846- 58 
continuous-time, 850-55 
discrete-time, 856-58 
encirclement property, 847- 50 
Odd harmonic continuous-time periodic 
signal, 262 
Odd signals, 13-14 
continuous-time Fourier series, 
206 
discrete-time Fourier series, 221 
Open-loop system, 818 
Open-loop frequency response, 821 
Operational amplifiers, 821, 896-97 
Orthogonal functions, 273-75 
Orthogonal signals, 280-81 
Orthonormal functions, 273-75 
Orthonormal signals, 280-81 
Oscilloscope, sampling, 534 
Overdamped system, 453 
Oversampling, 529 
Overshoot, 454 
Parallel-form block diagrams, 712, 713, 
787-89 
Parallel interconnection, 42- 43 
Parity check, 610 
Parseval's relation 
continuous-time Fourier transform, 
312-14 
continuous-time Fourier series, 
205, 206 
discrete-time Fourier transform, 
380-82 
Index 
discrete-time Fourier series, 223 
Partial-fraction expansion, 909- 20 
continuous-time signals and systems 
and, 910-16 
discrete-time signals and systems and, 
916-20 
Passband edge, 445 
Passband frequency, 237 
Passband ripple, 445 
Pendulum, inverted, 818-19 
Percent modulation, 591 
Period, sampling, 516 
Periodic complex exponentials, 
16-20, 186 
Periodic convolution, 222, 389-90 
continuous-time Fourier series, 206 
discrete-time Fourier series, 221 
Periodicity property of discrete-time 
Fourier transform, 373 
Periodic signals, 11-13. See also 
Fourier transform; Fourier series; 
Periodic complex exponentials; 
Sinusoidal signals 
continuous-time, 12 
discrete-time, 12 
power of, 312 
Periodic square wave 
continuous-time, 193- 95, 200-201, 
209, 218-19, 285- 86, 297-98 
discrete-time, 219-20, 224 
Periodic train of impulses 
continuous-time Fourier series of, 
208-10 
continuous-time Fourier transform of, 
299-300 
discrete-time Fourier transform of, 
371-72, 376 
Periodic signal, odd-harmonic, 262 
Phase (angle) of complex number, 71 
Phase lag, 491-92 
Phaselead,491-92 
Phase margin in linear feedback systems, 
858-66 

Index 
Phase modulation, 611-13 
Phase reversal, 532 
Phase shift, 428, 636 
Plant, 828 
Polar form for complex number, 71 
Poles 
closed-loop, 834-36 
Laplace transform, 660 
Pole-zero plot(s) 
all-pass systems, 682 
first-order systems, 676-77, 763-65 
Laplace transforms, 660-62, 674-82 
second-order systems, 678-80, 
765-67 
z-transform, 763-67 
Polynomials, Laguerre, 738 
Population dynamics, feedback model of, 
824-26 
Positive (regenerative) feedback, 
831-32 
-
Power of signals, 5- 7, 312 
Power-series expansion method, 761- 63 
Principal-phase function, 433, 434 
Proportional feedback system, 823-24 
Proportional (P) control, 905 
Proportional-plus-derivative 
feedback, 824 
Proportional-plus-integral (PI) 
control, 905 
Proportional-plus-integral-plus-
differential (PID) control, 905 
Pulse-amplitude modulation, 604-10 
digital, 610 
intersymbol interference in, 607-10 
Pulse-code modulation, 610 
Pulse-train carrier, 601-4, 605 
Quadrature distortion, 636 
Quadrature multiplexing, 646 
Quality of circuit, 456 
Raised cosine frequency response, 629 
Rational frequency responses, Bode plots 
for, 456-60 
RC highpass filter, 241-44 
RC lowpass filter, 239- 41 
Real exponential signals, 15, 22, 23 
953 
Real part 
complex number, 71 
Fourier series coefficients, 216, 217 
Real-part sufficiency, 350, 417 
Rectangular (Cartesian) form for 
complex number, 71 
Rectangular pulse 
continuous-time, 293-94 
discrete-time, 365-66 
Rectangular window, 420 
Recursive (infinite impulse response) 
filters, 123, 476 
Recursive linear constant-coefficient 
difference equations, 122, 123 
Regenerative (positive) feedback, 
831-32 
Region of convergence 
Laplace transform, 657-58, 662-70 
left-sided signal, 666, 669 
rational transform, 669 
right-sided signal, 665-66, 669 
two-sided signal, 666-68 
z-transform, 743-44, 748-57 
bounded by poles or infinity, 756 
centered about origin, 748-49 
finite-duration sequence, 749-50 
left-sided sequence, 751, 752 
right-sided sequence, 750-51, 752 
two-sided sequence, 751-53 
Right-half plane, 666 
Right-sided signal, 665- 66 
Ringing; 443, 454 
Rise time, 352-53, 444 
Root-locus analysis, 832-46 
angle criterion, 836-40 
end points, 836 
equation for closed-loop poles, 834-36 
properties of, 841-46 
Running sum of discrete-time Fourier 
series, 221 
Sampled-data feedback systems, 
826-28 
Sampling, 29, 39, 514-81 
aliasing, 527- 34 
bandpass signal, 564-65 
continuous-time signals, 4 

954 
discrete-time processing of 
continuous-time signals, 
534-45 
digital differentiator, 541- 43 
half-sample delay, 543- 45 
discrete-time signals, 545- 55 
decimation and interpolation, 
549-55 
impulse train, 545-49 
impulse-train, 516-20, 545- 49 
reconstruction using interpolation, 
522-27 
with zero-order hold, 520-22, 523-26 
Sampling frequency, 516 
Sampling function, 516 
Sampling oscilloscope, 534 
Sampling period, 516 
Sampling property of continuous-time 
impulse, 35 
Sampling theorem, 514- 15, 518 
Scaling (homogeneity) property, 53 
·Scaling in z domain, 768-69, 793 
Scrambler, speech, 633-34 
Second harmonic components, 187 
Second-order continuous-time systems, 
451-56 
Second-order discrete-time systems, 
465-72 
Series (cascade) interconnection, 42 
Shifting property 
s-domain, 717 
unilateral z transform, 794-95 
Sifting property 
continuous-time impulse, 90-92 
discrete-time unit impulse, 77 
Signal(s), 1- 38. See also Periodic signals 
continuous-time and discrete-time, 
1- 7 
energy and power of, 5-7 
examples and mathematical 
representation of, 1-5 
sampling of, 4, 545- 55 
exponential and sinusoidal, 
14-30, 186 
continuous-time complex, 15-21 
discrete-time complex, 21-30 
real, 22, 23 
transformation of independent 
variable, 7-14 
examples of, 8-11 
Index 
unit impulse and unit step functions, 
30-38 
continuous-time, 32- 38 
discrete-time, 30- 32 
Sine functions, 295 
Single-sideband sinusoidal amplitude 
modulation, 597-601 
Singularity functions, 36, 67, 127-36. 
See also Unit impulse 
Sinusoidal amplitude modulation, 
583- 87 
complex exponential carrier, 
583- 85 
demodulation for, 587-94 
asynchronous, 590-94 
synchronous, 587-90 
discrete-time, 619-23 
frequency-division multiplexing 
(FDM) using, 594- 97 
single-sideband, 597- 601 
with sinusoidal carrier, 585- 87 
Sinusoidal frequency modulation, 583, 
611-19 
nrurrowband,613-15 
periodic square-wave modulating 
signal, 617-19 
wideband, 615- 17 
Sinusoidal signals, 14- 30, 186 
continuous-time complex, 15-21 
discrete-time, 24 
discrete-time complex, 21-30 
real, 22, 23 
Sinusoids, damped, 21 
Sliding, 85 
Spectral coefficient. See Fourier series 
coefficients 
Spectrum, 288, 361. See also Fourier 
transform 
energy-density, 312, 349, 381 
Speech scrambler, 633-34 
Square wave, periodic 
continuous-time, 193-95, 200-201, 
209, 218~19,285-86, 297-98 
discrete-time, 219-20, 224 

Index 
Stability, 48-50 
feedback systems, 858-66 
LTI systems, 113- 15, 695-98, 
777-79 
Stabilization with feedback, 823-26 
Step-invariant transformation, 828, 908 
Step response, 115- 16 
automotive suspension system, 476 
continuous-time ideal lowpass 
filter, 443 
discrete-time ideallowpass filter, 443 
first-order discrete-time system, 
461, 463 
second-order discrete-time systems, 
466,468 
Stopband edge, 445 
Stopband frequency, 237 
Stopband ripple, 445 
Stroboscopic effect, 533-34 
Sufficiency, real-part, 350, 417 
Summer, 44 
Superposition integral. See Convolution 
integral 
Superposition property, 53 
Superposition sum. See Convolution sum 
Suspension system, analysis of, 473-76 
Symmetry, conjugate, 204-5, 206, 221, 
303-6, 375 
Synthesis equation 
continuous-time Fourier series, 191 
continuous-time Fourier transform, 
288,300,314 
discrete-time Fourier series, 213 
discrete-time Fourier transform, 
361,390 
System function(s), 227 
closed-loop, 820 
feedback path, 820 
forward path, 820 
interconnections of LTI systems, 
707- 8 
Laplace transform as, 693, 701- 13 
block diagram representations, 
708- 13 
Butterworth filters, 703-6 
interconnections of LTI systems, 
707- 8 
z-transform as, 781-89 
block diagram representations, 
784-89 
955 
interconnection of LTI systems, 784 
Systems, 38-56 
continuous-time and discrete-time, 
38-43 
examples of, 39-41 
first-order, 448-51, 461-65 
interconnections of, 41- 43 
second-order, 451-56, 465-72 
properties of, 44-56 
causality, 46-48 
invertible and inverse, 45- 46 
linearity, 53-56 
memory and memoryless, 44-45 
stability, 48-50 
time-invariance, 50-53 
Taylor series, infinite, 277 
Telescope, angular position of, 816- 18 
Time, 3-4 
Time advance property of unilateral 
z-transform, 793 
Time constants, 448 
dominant, 500-501 
Time delay property of unilateral 
z-transform, 793 
Time-division multiplexing (TDM), 
604,605 
Time-domain and frequency-domain 
characterization, 423-513 
continuous-time systems, 448-60 
Bode plots for rational frequency 
responses and, 456-60 
first-order, 448-51 
second-order, 451-56 
discrete-time systems, 461-72 
first-order, 461- 65 
second-order, 465-72 
examples of, 472-82 
automobile suspension system, 
473-76 
discrete-time nonrecursive filter, 
476-82 
magnitude-phase representation 
Fourier transform, 423-27 

956 
frequency response of LTI systems, 
427-39 
nonideal filters, 444-47 
Time expansion property 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 
377-80 
z-transform, 769- 70 
unilateral, 793 
Time invariance, 50--53, 77 
Time reversal property, 8 
continuous-time Fourier series, 
203, 206 
continuous-time Fourier 
transform, 309 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 
376-77 
Laplace transform, 687 
z-transform, 769 
Time scaling property, 8, 9, 10 
continuous-time Fourier series, 
204, 206 
continuous-time Fourier transform, 
308-9 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 
377-80 
Laplace transform, 685- 87 
unilateral, 717 
z-transform, 769-70 
unilateral, 793 
Time shifting property, 8-9, 10 
continuous-time Fourier series, 
202- 3, 206 
continuous-time Fourier transform, 
301-3 
discrete-time Fourier series, 221 
discrete-time Fourier transform, 
373- 75 
Laplace transform, 684 
z-transform, 767-68 
Time window, 420 
Tracking systems, 828-30 
Transfer function. See System 
function(s) 
Transformation 
bilinear, 814-15 
highpass-to-lowpass, 498 
of independent variable, 7-14 
lowpass-to-highpass, 498 
step-invariant, 828, 908 
Index 
Transition band, 445 
Transmodulation (transmultiplexing), 
discrete-time, 623, 624 
Triangular (Bartlett) window, 421 
Trigonometric series, 178-79 
Two-sided signal, 666-68 
Type 1 feedback system, 906 
Undamped natural frequency, 452-53 
Undamped system, 454 
Underdamped systems, 467 
Undersampling, 527-34 
Unilateral Laplace transform, 714-20 
examples of, 714-16 
properties of, 716-19 
solving differential equations using, 
719-20 
Unilateral z-transform, 742, 789-96 
examples of, 779-92 
' 
properties of, 792-95 
solving difference equations using, 
795-96 
Unit circle, 743 
Unit delay, 125 
Unit doublets, 132-36, 172 
Unit impulse, 30-38 
cascade of two LTI systems and, 107 
continuous-time, 32-38, 127-36, 292 
defining through convolution, 
131-32 
as idealized short pulse, 128-31 
sifting property of, 90-92 
discrete-time, 30-32, 367 
. sifting property of, 77 
representation of continuous-time LTI 
systems in terms of, 90-94 
representation of discrete-time LTI 
systems in terms of, 75-77 
Unit impulse response, discrete-time, 
77-90. See also Impulse response 

Index 
Unit ramp function, 135 
Unit step functions, 30-38 
continuous-time, 32- 38 
discrete-time, 30-32 
Unit step response of LTI systems, 
115-16 
Unstable systems, feedback to stabilize, 
823-26 
Unwrapped phase, 433, 434 
Upsampling, 552, 553 
Variable, independent, 3-4 
transformation of, 7-14 
Walsh functions, 170, 276 
, Wave, square. See Periodic square wave 
Wavelengths, 181 
Weighted average, 245 
Wideband frequency modulation, 
615-17 
Windowing, 420-22 
Zero-force equalizer, 649 
Zero-input response, 55- 56, 720 
Zero-order hold, 520-22, 523-26 
Zeros of Laplace transform, 660 
Zero-state response, 720 
z-transform, 741- 815 
bilateral, 742, 789 
defined, 742 
discrete-time Fourier transform 
and, 743 
geometric evaluation of, 763- 67 
first-order systems, 763-65 
second-order systems, 765- 67 
inverse, 757-63 
examples of, 79-92 
957 
LTI systems analysis and 
characterization using, 774-83 
causality, 776- 77 
linear constant -coefficient 
difference equations, 779-81 
stability, 777-79 
pole-zero plot, 763-67 
properties of, 767-74 
conjugation, 770 
convolution, 770-72 
differentiation in z-domain, 772 
initial-value theorem, 773- 74 
linearity, 767 
scaling in z-domain, 768- 69 
table of, 775 
time expansion, 769-70 
time reversal, 769 
time shifting, 767- 68 
region of convergence for, 743-44, 
748-57 
bounded by poles or infinity, 756 
centered about origin, 748-49 
finite-duration sequence, 749- 50 
left-sided sequence, 751, 752 
right-sided sequence, 750-51, 752 
two-sided sequence, 751-53 
system functions, 781-89 
block diagram representations, 
784- 89 
for interconnection of LTI 
systems, 784 
unilateral, 742, 789-96 
examples of, 789-796 
properties of, 792- 95 
solving difference equations using, 
795-96 
z-transform pairs, 774, 776 

