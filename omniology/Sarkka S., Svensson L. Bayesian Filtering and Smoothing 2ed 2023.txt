This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Bayesian Filtering and Smoothing
Second Edition
Simo S¨arkk¨a and Lennart Svensson
Bayesian Filtering and Smoothing has been pub-
lished by Cambridge University Press. It can be
purchased directly from Cambridge University
Press: www.cambridge.org/9781108926645.
Please cite this book as:
Simo S¨arkk¨a and Lennart Svensson (2023).
Bayesian
Filtering
and
Smoothing.
Second
Edition. Cambridge University Press.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Contents
Preface
page xi
Symbols and Abbreviations
xv
1
What Are Bayesian Filtering and Smoothing?
1
1.1
Applications of Bayesian Filtering and Smoothing
1
1.2
Origins of Bayesian Filtering and Smoothing
7
1.3
Optimal Filtering and Smoothing as Bayesian Inference
9
1.4
Algorithms for Bayesian Filtering and Smoothing
12
1.5
Parameter Estimation
14
1.6
Exercises
16
2
Bayesian Inference
17
2.1
Philosophy of Bayesian Inference
17
2.2
Connection to Maximum Likelihood Estimation
17
2.3
The Building Blocks of Bayesian Models
19
2.4
Bayesian Point Estimates
20
2.5
Numerical Methods
22
2.6
Exercises
24
3
Batch and Recursive Bayesian Estimation
27
3.1
Batch Linear Regression
27
3.2
Recursive Linear Regression
30
3.3
Batch versus Recursive Estimation
31
3.4
Drift Model for Linear Regression
34
3.5
State Space Model for Linear Regression with Drift
36
3.6
Toward Bayesian Filtering and Smoothing
39
3.7
Exercises
41
4
Discretization of Continuous-Time Dynamic Models
44
4.1
Discrete-Time and Continuous-Time Dynamic Models
45
4.2
Discretizing Linear Dynamic Models
47
4.3
The Euler–Maruyama Method
52
v

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
vi
Contents
4.4
Discretization via Continuous-Time Linearization
58
4.5
Covariance Approximation via Constant Gradients
65
4.6
Fast Sampling
69
4.7
Exercises
70
5
Modeling with State Space Models
73
5.1
Linear and Non-Linear Gaussian Models
73
5.2
Non-Gaussian Measurement Models
78
5.3
Measurements as Inputs
82
5.4
Linear-in-Parameters Models in State Space Form
83
5.5
Autoregressive Models
86
5.6
Discrete-State Hidden Markov Models (HMMs)
87
5.7
Exercises
89
6
Bayesian Filtering Equations and Exact Solutions
91
6.1
Probabilistic State Space Models
91
6.2
Bayesian Filtering Equations
94
6.3
Kalman Filter
96
6.4
Afﬁne Kalman Filter
102
6.5
Bayesian Filter for Discrete State Space
103
6.6
Exercises
106
7
Extended Kalman Filtering
108
7.1
Taylor Series Approximation of Non-Linear Transform
108
7.2
Extended Kalman Filter
113
7.3
Higher Order Extended Kalman Filters
119
7.4
Iterated Extended Kalman Filter
121
7.5
Levenberg–Marquardt, Line-Search, and Related IEKFs
125
7.6
Automatic Differentiation and EKFs
127
7.7
Exercises
128
8
General Gaussian Filtering
131
8.1
Gaussian Moment Matching
131
8.2
Gaussian Filter
133
8.3
Gauss–Hermite Integration
136
8.4
Gauss–Hermite Kalman Filter
140
8.5
Spherical Cubature Integration
142
8.6
Cubature Kalman Filter
145
8.7
Unscented Transform
149
8.8
Unscented Kalman Filter
155
8.9
Higher Order Cubature/Unscented Kalman Filters
162
8.10
Exercises
166

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Contents
vii
9
Gaussian Filtering by Enabling Approximations
168
9.1
Enabling Linearization
169
9.2
Statistical Linearization
171
9.3
Statistically Linearized Filter
176
9.4
Statistical Linear Regression
178
9.5
Statistical Linear Regression Filters
187
9.6
Practical SLR Filters
192
9.7
Relation to Other Gaussian Filters
200
9.8
Exercises
202
10
Posterior Linearization Filtering
204
10.1
Generalized Statistical Linear Regression
204
10.2
Posterior Linearization
206
10.3
Iterated Posterior Linearization
208
10.4
Iterated Posterior Linearization Filter
212
10.5
Practical Iterated Posterior Linearization Filters
217
10.6
Optimality Properties of Different Linearizations
225
10.7
Exercises
227
11
Particle Filtering
229
11.1
Monte Carlo Approximations in Bayesian Inference
229
11.2
Importance Sampling
231
11.3
Sequential Importance Sampling
234
11.4
Resampling
236
11.5
Particle Filter
239
11.6
Auxiliary Particle Filter
244
11.7
Rao–Blackwellized Particle Filter
247
11.8
Exercises
250
12
Bayesian Smoothing Equations and Exact Solutions
253
12.1
Bayesian Smoothing Equations
253
12.2
Rauch–Tung–Striebel Smoother
255
12.3
Afﬁne Rauch–Tung–Striebel Smoother
259
12.4
Bayesian Smoother for Discrete State Spaces
261
12.5
Viterbi Algorithm
262
12.6
Exercises
266
13
Extended Rauch–Tung–Striebel Smoothing
267
13.1
Extended Rauch–Tung–Striebel Smoother
267
13.2
Higher Order Extended Rauch–Tung–Striebel Smoothers
270
13.3
Iterated Extended Rauch–Tung–Striebel Smoother
271
13.4
Levenberg–Marquardt and Line-Search IERTSSs
276
13.5
Exercises
277

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
viii
Contents
14
General Gaussian Smoothing
278
14.1
General Gaussian Rauch–Tung–Striebel Smoother
278
14.2
Gauss–Hermite Rauch–Tung–Striebel Smoother
280
14.3
Cubature Rauch–Tung–Striebel Smoother
282
14.4
Unscented Rauch–Tung–Striebel Smoother
285
14.5
Higher Order Cubature/Unscented RTS Smoothers
287
14.6
Statistical Linear Regression Smoothers
290
14.7
Posterior Linearization Smoothers
294
14.8
Exercises
305
15
Particle Smoothing
308
15.1
SIR Particle Smoother
308
15.2
Backward-Simulation Particle Smoother
310
15.3
Backward-Simulation with Rejection Sampling
312
15.4
Reweighting Particle Smoother
314
15.5
Rao–Blackwellized Particle Smoothers
316
15.6
Exercises
318
16
Parameter Estimation
319
16.1
Bayesian Estimation of Parameters in State Space Models
319
16.2
Computational Methods for Parameter Estimation
322
16.3
Practical Parameter Estimation in State Space Models
330
16.4
Exercises
348
17
Epilogue
349
17.1
Which Method Should I Choose?
349
17.2
Further Topics
351
Appendix
Additional Material
355
A.1
Properties of Gaussian Distribution
355
A.2
Block Matrix Inverses and Matrix Inversion Formulas
356
A.3
Cholesky Factorization and Its Derivative
357
A.4
Afﬁne Stochastic Differential Equations
359
A.5
Time Derivative of Covariance in Theorem 4.13
362
A.6
Derivation of Mean for Bicycle Model
363
A.7
Mean Discretization for the Polar Coordinated Turn Model
364
A.8
Approximating Qk 1 in the Polar Coordinated Turn Model
365
A.9
Conditional Moments Used in SLR
367
A.10
Parameter Derivatives for the Kalman Filter
371
A.11
Parameter Derivatives for the Gaussian Filter
374

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Contents
ix
References
379
List of Examples
393
List of Theorems, Corollaries, and Algorithms
397
Index
401

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Preface
The aim of this book is to give a concise introduction to non-linear Kalman
ﬁltering and smoothing, particle ﬁltering and smoothing, and to the re-
lated parameter estimation methods. Although the book is intended to be
an introduction, the mathematical ideas behind all the methods are care-
fully explained, and a mathematically inclined reader can get quite a deep
understanding of the methods by reading the book. The book is purposely
kept relatively short for quick reading.
The book is mainly intended for advanced undergraduate and graduate
students in applied mathematics, computer science, and electrical engineer-
ing. However, the book is also suitable for researchers and practitioners
(engineers) who need a concise introduction to the topic on a level that en-
ables them to implement or use the methods. Readers are assumed to have
a background in linear algebra, vector calculus, and Bayesian inference,
and MATLAB or Python programming skills.
As implied by the title, the mathematical treatment of the models and
algorithms in this book is Bayesian, which means that all the results are
treated as being approximations to certain probability distributions or their
parameters. Probability distributions are used both to represent uncertain-
ties in the models and to model the physical randomness. The theories
of non-linear ﬁltering, smoothing, and parameter estimation are formu-
lated in terms of Bayesian inference, and both the classical and recent
algorithms are derived using the same Bayesian notation and formalism.
This Bayesian approach to the topic is far from new and was pioneered by
Stratonovich in the 1950s and 1960s – even before Kalman’s seminal arti-
cle in 1960. Thus the theory of non-linear ﬁltering has been Bayesian from
the beginning (see Jazwinski, 1970).
The main additions to the second edition of the book are the chapters
on how to construct state space models of practical systems along with
coverage of the iterated extended Kalman ﬁlters and smoothers, general-
ized statistical linear regression based ﬁlters and smoothers, and posterior
xi

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xii
Preface
linearization ﬁlters and smoothers. These additions have also resulted in a
slight reordering of the material related to the coverage of Gaussian ﬁlters
and smoothers. Methods for Bayesian estimation in discrete state systems,
including, for example, the Viterbi algorithm, are now also covered.
Chapter 1 is a general introduction to the idea and applications of
Bayesian ﬁltering and smoothing. The purpose of Chapter 2 is to brieﬂy
review the basic concepts of Bayesian inference as well as the basic
numerical methods used in Bayesian computations. Chapter 3 starts
with a step-by-step introduction to recursive Bayesian estimation by
demonstrating how to recursively solve a linear regression problem. The
transition to Bayesian ﬁltering and smoothing theory is explained by
extending and generalizing the problem. The ﬁrst Kalman ﬁlter of the
book is also encountered in this chapter.
Chapters 4 and 5 are concerned with practical modeling with state
space models. In particular, Chapter 4 is concerned with transforming
continuous-time models of tracking models into discrete-time state space
models that are compatible with the discrete-time estimation methods
considered in this book, as well as examples of dynamic models. Chapter 5
proceeds to augment the models with linear, non-linear, Gaussian, and
non-Gaussian measurement models and explains how certain classes of
machine learning and signal processing models can be recast as state space
models.
The Bayesian ﬁltering theory starts in Chapter 6 where we derive
the general Bayesian ﬁltering equations and, as their special case, the
celebrated Kalman ﬁlter, along with discrete state Bayesian ﬁlters. Taylor
series-based non-linear extensions of the Kalman ﬁlter, the extended
Kalman ﬁlter (EKF), and iterated extended Kalman ﬁlter (IEKF) are pre-
sented in Chapter 7. After that, Chapter 8 starts by introducing the moment
matching-based general Gaussian ﬁlter algorithm, and the Gauss–Hermite
Kalman ﬁlter (GHKF), cubature Kalman ﬁlter (CKF), unscented Kalman
ﬁlter (UKF), and higher order cubature/unscented Kalman ﬁlters are then
derived as special cases of it.
Chapter 9 introduces a different perspective and reformulates all the
Gaussian ﬁlters in terms of enabling linearizations. The presentation starts
with statistical linearization and the statistically linearized ﬁlter (SLF), and
proceeds to statistical linear regression (SLR) and the related ﬁlters, which
turn out to recover and extend all the Gaussian ﬁlters covered in the previ-
ous chapters. By further extending the concept of enabling linearizations,
Chapter 10 introduces the posterior linearization ﬁlter (PLF), which gen-
eralizes the concept of iterated Gaussian ﬁltering. Sequential Monte Carlo

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Preface
xiii
(SMC)-based particle ﬁlters (PF) are explained in Chapter 11 by starting
from the basic SIR ﬁlter and ending with Rao–Blackwellized particle ﬁlters
(RBPF).
Chapter 12 starts with a derivation of the general (ﬁxed-interval)
Bayesian smoothing equations and then continues to a derivation of
the Rauch–Tung–Striebel (RTS) smoother as their special case. In that
chapter, we also present methods for smoothing in discrete state systems,
including the Viterbi algorithm. The extended RTS smoother (ERTSS)
and the iterated extended RTS smoother (IERTSS) are presented in
Chapter 13. The general Gaussian smoothing framework is presented in
Chapter 14, and the Gauss–Hermite RTS smoother (GHRTSS), cubature
RTS smoother (CRTSS), unscented RTS smoother (URTSS), and higher
order cubature/unscented RTS smoothers are derived as its special cases.
The chapter then proceeds to the iterated posterior linearization smoother
(IPLS), which generalizes the concept of iterated Gaussian smoothing.
In Chapter 15 we start by showing how the basic SIR particle ﬁlter can
be used to approximate the smoothing solutions with a minor modiﬁcation.
We then introduce the numerically superior backward-simulation particle
smoother and the reweighting (or marginal) particle smoother. Finally, we
discuss the implementation of Rao–Blackwellized particle smoothers.
Chapter 16 is an introduction to parameter estimation in state space
models concentrating on optimization and expectation-maximization
(EM)-based computation of maximum likelihood (ML) and maximum
a posteriori (MAP) estimates, as well as on Markov chain Monte Carlo
(MCMC) methods. We start by presenting the general methods and then
show how Kalman ﬁlters and RTS smoothers, non-linear Gaussian ﬁlters
and RTS smoothers, and ﬁnally particle ﬁlters and smoothers, can be used
to compute or approximate the quantities needed in the implementation
of parameter estimation methods. This leads to, for example, classical
EM algorithms for state space models, as well as to particle EM and
particle MCMC methods. We also discuss how Rao–Blackwellization can
sometimes be used to help parameter estimation.
Chapter 17 is an epilogue where we give general advice on selecting dif-
ferent methods for different purposes. We also discuss and give references
to various technical points and related topics that are important but did not
ﬁt into this book.
Each of the chapters ends with a range of exercises that give the reader
hands-on experience in implementing the methods and selecting the appro-
priate method for a given purpose. The MATLAB and Python source code

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xiv
Preface
needed in the exercises as well as much other material can be found on the
book’s web page.
We are grateful to many people who carefully checked the book and
gave many valuable suggestions for improving the text. It is not possible
to include all of them, but we would like to speciﬁcally mention Arno
Solin, Robert Pich´e, Juha Sarmavuori, Thomas Sch¨on, Pete Bunch, Isambi
S. Mbalawata, Adrien Corenﬂos, Fatemeh Yaghoobi, Hany Abdulsamad,
Jakob Lindqvist, and Lars Hammarstrand. We are also grateful to Jouko
Lampinen, Aki Vehtari, Jouni Hartikainen, Ville V¨a¨an¨anen, Heikki Haario,
Simon Godsill, ´Angel Garc´ıa-Fern´andez, Filip Tronarp, Toni Karvonen,
and various others for research co-operation that led to improvement of
our understanding of the topic as well as to the development of some of the
methods that now are explained in this book. We would also like to thank
the editors of Cambridge University Press for their original suggestion for
the publication of the book. We are also grateful to our families for their
support and patience during the writing of this book.
Simo and Lennart

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
General Notation
a; b; c; x; t; ˛; ˇ Scalars
a; f; s; x; y; ˛; ˇ Vectors
A; F; S; X; Y
Matrices
A; F; S; X; Y
Spaces or sets
Notational Conventions
AT
Transpose of matrix
A 1
Inverse of matrix
A T
Inverse of transpose of matrix
ŒAi
ith column of matrix A
ŒAij
Element at ith row and j th column of matrix A
jaj
Absolute value of scalar a
jAj
Determinant of matrix A
dx=dt
Time derivative of x.t/
@gi.x/
@xj
Partial derivative of gi with respect to xj
.a1; : : : ; an/
Column vector with elements a1; : : : ; an
.a1    an/
Row vector with elements a1; : : : ; an
.a1    an/T
Column vector with elements a1; : : : ; an
@g.x/
@x
Gradient (column vector) of scalar function g
@g.x/
@x
Jacobian matrix of vector-valued function x 7! g.x/
CovŒx
Covariance CovŒx D EŒ.x   EŒx/ .x   EŒx/T of the
random variable x
CovŒx; y
Cross-covariance CovŒx; y D EŒ.x EŒx/ .y EŒy/T
of the random variables x and y
diag.a1; : : : ; an/ Diagonal matrix with diagonal values a1; : : : ; an
xv

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xvi
Symbols and Abbreviations
p
P
Matrix such that P D
p
P
p
P
T
P  1=2
Alternative notation for Œ
p
P 1
EŒx
Expectation of x
EŒx j y
Conditional expectation of x given y
R
f .x/ dx
Integral of f .x/ over the space Rn
R b
a g.t/ dt
Integral of g.t/ over the interval t 2 Œa; b
p.x/
Probability density of continuous random variable x or
probability of discrete random variable x
p.x j y/
Conditional probability density or conditional probabil-
ity of x given y
p.x/ / q.x/
p.x/ is proportional to q.x/, that is, there exists a con-
stant c such that p.x/ D c q.x/ for all values of x
tr A
Trace of matrix A
VarŒx
Variance VarŒx D EŒ.x   EŒx/2 of the scalar random
variable x
x  y
x is much greater than y
xi;k
ith component of vector xk
x  p.x/
Random variable x has the probability density or prob-
ability distribution p.x/
x , y
x is deﬁned to be equal to y
x  y
x is approximately equal to y
x ' y
x is assumed to be approximately equal to y
x0Wk
Set or sequence containing the vectors fx0; : : : ; xkg
Px
Time derivative of x.t/
Symbols
˛
Parameter of the unscented transform or a pendulum angle
˛i
Acceptance probability in an MCMC method
N˛
Target acceptance rate in an adaptive MCMC method
ˇ
Parameter of the unscented transform, or a parameter of a
dynamic model

Step size in line search
./
Gamma function
ı./
Dirac delta function, or steering angle
ıx
Difference of x from the mean ıx D x   m
t
Sampling period
tk
Length of time interval tk D tkC1   tk

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xvii
"k
Measurement error at time step k
"k
Vector of measurement errors at time step k

A parameter or heading angle

Vector of parameters
k
Vector of parameters at time step k
.n/
Vector of parameters at iteration n of the EM-algorithm
.i/
Vector of parameters at iteration i of an MCMC-algorithm

Candidate point in an MCMC-algorithm
OMAP
Maximum a posteriori (MAP) estimate of parameter 

Parameter of the unscented transform or auxiliary variable

Parameter of the unscented transform or the Poisson distribu-
tion, or regularization parameter
0
Parameter of the Poisson distribution
ƒ
Noise covariance in (generalized) statistical linear regression
ƒ.i/
Noise covariance on the ith iteration of posterior linearization
ƒk
Noise covariance in a Gaussian enabling approximation of a
dynamic model

Mean of Student’s t-distribution
C;.i 1/
Predicted mean from iteration i   1
.i/
Predicted measurement model mean at iteration i
 k
Predicted dynamic model mean in a statistical linear regres-
sion ﬁlter
C
k
Predicted measurement model mean in a statistical linear re-
gression ﬁlter
k
Predicted mean of measurement yk at time step k
 k .xk 1/ Conditional mean moment of a dynamic model
k.xk/
Conditional mean moment of a measurement model
 .i/
k
Predicted dynamic model mean for sigma point i at time step
k
C;.i 1/
k
Predicted mean from iteration i   1
.i/
k
Predicted measurement model mean for sigma point i at time
step k or predicted measurement model mean at ith iteration
G
Mean in generalized statistical linear regression approxima-
tion
L
Mean in the linear (Taylor series-based) approximation
M
Mean in the Gaussian moment matching approximation
Q
Mean in the quadratic approximation
R
Mean in the statistical linear regression approximation
R.x/
Conditional mean moment in statistical linear regression

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xviii
Symbols and Abbreviations
S
Mean in the statistical linearization approximation
U
Mean in the unscented approximation

Degrees of freedom in Student’s t-distribution

Unit Gaussian random variable
.i/
ith scalar unit sigma point

Vector of unit Gaussian random variables
.i/
ith unit sigma point vector
.i1;:::;in/
Unit sigma point in the multivariate Gauss–Hermite cubature

Constant  D 3:14159265358979323846 : : :
./
Importance distribution or linearization distribution
f
k.xk/
Linearization distribution of a dynamic model
h
k .xk/
Linearization distribution of a measurement model
…
Transition matrix of a hidden Markov model
…i;j
Element .i; j / of transition matrix …

Probability
2
Variance
2
i
Variance of noise component i
†
Auxiliary matrix needed in the EM-algorithm
†i
Proposal distribution covariance in the Metropolis algorithm

Time
'
Direction angle
'k./
Energy function at time step k
ˆ./
A function returning the lower triangular part of its argument
or cumulative density of the standard Gaussian distribution
ˆ
An auxiliary matrix needed in the EM-algorithm
!
Angular velocity
k
Noise covariance in a Gaussian enabling approximation of a
measurement model
k
Noise covariance at the ith iteration of a posterior lineariza-
tion ﬁlter
a
Action in decision theory or a part of a mean vector
ao
Optimal action
ak
Offset in an afﬁne dynamic model or constant term in a sta-
tistical linear regression approximation
a./
Non-linear drift function in a stochastic differential equation
or acceleration
A
Resampling index
Ai
Resampling index

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xix
A
Dynamic model matrix in a linear time-invariant model, the
lower triangular Cholesky factor of a covariance matrix, the
upper left block of a covariance matrix, a coefﬁcient matrix
in statistical linearization, or an arbitrary matrix
A.i/
Coefﬁcient matrix at the ith iteration of posterior lineariza-
tion
Ak
Dynamic model matrix (i.e., transition matrix) of the jump
from step k to step k C 1, or approximate transition matrix in
a statistical linear regression approximation
Ax
Jacobian matrix of a.x/
bk
Binary value in the Gilbert–Elliot channel model
b
The lower part of a mean vector, the offset term in statistical
linearization, or an arbitrary vector
b.i/
Offset term at the ith iteration of posterior linearization
b.i/
k
Offset term at ith iteration
bk
Dynamic bias vector or offset in an afﬁne measurement model
or constant term in a statistical linear regression approxima-
tion
Be./
Bernoulli distribution
B
Lower right block of a covariance matrix, an auxiliary matrix
needed in the EM-algorithm, or an arbitrary matrix
c
Scalar constant
ck
Clutter (i.e., outlier) indicator
C
Arbitrary scalar constant
C./
Cost or loss function
C
The upper right block of a covariance matrix, an auxiliary
matrix needed in the EM-algorithm, or an arbitrary matrix
Ck
Cross-covariance matrix in a non-linear Kalman ﬁlter
CG
Cross-covariance in the generalized statistical linear regres-
sion approximation
CL
Cross-covariance in the linear (Taylor series-based) approxi-
mation
CM
Cross-covariance in the Gaussian moment matching approx-
imation
CQ
Cross-covariance in the quadratic approximation
CR
Cross-covariance in the statistical linear regression approxi-
mation
CS
Cross-covariance in the statistical linearization approxima-
tion

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xx
Symbols and Abbreviations
CU
Cross-covariance in the unscented approximation
d
Positive integer, usually dimensionality of the parameters
di
Order of a monomial
dt
Differential of time variable t
dx
Differential of vector x
D
Derivative of the Cholesky factor, an auxiliary matrix needed
in the EM-algorithm, or an arbitrary matrix
Dk
Cross-covariance matrix in a non-linear RTS smoother or an
auxiliary matrix used in derivations
ei
Unit vector in the direction of the coordinate axis i
Qe
Noise term in statistical linear regression
Qek
Noise term in an enabling Gaussian approximation of a dy-
namic model at time step k
f./
Dynamic transition function in a state space model
F Œ
An auxiliary functional needed in the derivation of the EM-
algorithm
Fx./
Jacobian matrix of the function x 7! f.x/
F
Feedback matrix of a continuous-time linear state space
model
F .i/
xx./
Hessian matrix of x 7! fi.x/
g
Gravitation acceleration
g./
An arbitrary function
gi./
An arbitrary function
g./
An arbitrary vector-valued function
g.t/
Vector of forces
g 1./
Inverse function of g./
Qg./
Augmented function with elements .x; g.//
Gk
Gain matrix in an RTS smoother
Gx./
Jacobian matrix of the function x 7! g.x/
G.i/
xx./
Hessian matrix of x 7! gi.x/
h./
Measurement model function in a state space model
Hp./
pth order Hermite polynomial
H
Measurement model matrix in a linear Gaussian model, or a
Hessian matrix
Hk
Measurement model matrix at time step k in a linear Gaussian
or afﬁne model, or approximate measurement model matrix
in a statistical linear regression approximation
H.i/
k
Measurement model matrix at the ith iteration of posterior
linearization ﬁlter

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xxi
Hx./
Jacobian matrix of the function x 7! h.x/
H.i/
xx./
Hessian matrix of x 7! hi.x/
i
Integer-valued index variable
Imax
Number of iterations in iterated methods
I
Identity matrix
Ii.; .n// An integral term needed in the EM-algorithm
j
Integer-valued index variable
J./
Jacobian matrix
k
Time step number
K.i/
Gain at iteration i of iterated posterior linearization
Kk
Gain matrix of a Kalman/Gaussian ﬁlter
K.i/
k
Gain matrix at the ith iteration of an iterated ﬁlter at time step
k
L
Positive constant
L./
Negative logarithm of distribution
LGN./
Gauss–Newton objective function
L
Noise coefﬁcient (i.e., dispersion) matrix of a continuous-
time linear state space model
L./
Likelihood function
m
Dimensionality of a measurement, mean of the univariate
Gaussian distribution, a mass, number of sigma points, or
loop counter
m
Mean of a Gaussian distribution
Qm
Mean of an augmented random variable
m.i/
Mean at iteration i of iterated posterior linearization
mk
Mean of a Kalman/Gaussian ﬁlter at the time step k
m.i/
k
Mean at the ith iteration of a posterior linearization ﬁlter,
mean of the Kalman ﬁlter in the particle i of RBPF at time
step k
m.i/
0WT
History of means of the Kalman ﬁlter in the particle i of
RBPF
Qmk
Augmented mean at time step k, an auxiliary variable used in
derivations, or linearization point
m k
Predicted mean of a Kalman/Gaussian ﬁlter at time step k,
just before the measurement yk
m .i/
k
Predicted mean of the Kalman ﬁlter in the particle i of RBPF
at time step k
Qm k
Augmented predicted mean at the time step k

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xxii
Symbols and Abbreviations
ms
k
Mean computed by a Gaussian (RTS) smoother for the time
step k
ms
0WT
Trajectory of the smoother means from a Gaussian (RTS)
smoother
ms;.i/
0WT
Trajectory of means at smoother iteration i or history of
means of the RTS smoother in the particle i of RBPS
m
Expected value of x  .x/
mf
k
Mean of f
k
mh
k
Mean of h
k
M
Constant in rejection sampling
n
Positive integer, usually the dimensionality of the state
n0
Augmented state dimensionality in a non-linear transform
n00
Augmented state dimensionality in a non-linear transform
N
Positive integer, usually the number of Monte Carlo samples
N./
Gaussian distribution (i.e., normal distribution)
Oi;j
Element .i; j / of emission matrix O
O
Emission matrix of a hidden Markov model
p
Order of a Hermite polynomial
p0
State-switching probability in the Gilbert–Elliot channel
model
p1
State-switching probability in the Gilbert–Elliot channel
model
p2
State-switching probability in the Gilbert–Elliot channel
model
p j;k
Predictive distribution for the discrete state xk D j
pj;k
Filtering distribution for the discrete state xk D j
ps
j;k
Smoothing distribution for the discrete state xk D j
P
Variance of the univariate Gaussian distribution
Po./
Poisson distribution
P
Covariance of the Gaussian distribution
QP
Covariance of an augmented random variable
P xy;.i 1/
Predicted cross-covariance from iteration i   1 in iterated
posterior linearization
P y;.i 1/
Predicted covariance from iteration i   1 in iterated posterior
linearization
P .i/
Covariance at iteration i of iterated posterior linearization
Pk
Covariance of a Kalman/Gaussian ﬁlter at time step k

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xxiii
P .i/
k
Covariance at iteration i of iterated posterior linearization ﬁl-
ter, covariance of the Kalman ﬁlter in the particle i of RBPF
at time step k
P .i/
0WT
History of covariances of the Kalman ﬁlter in the particle i of
RBPF
QPk
Augmented covariance at time step k or an auxiliary variable
used in derivations
P  k
Predicted covariance of a Kalman/Gaussian ﬁlter at the time
step k just before the measurement yk
QP  k
Augmented predicted covariance at time step k
P  .i/
k
Predicted covariance of the Kalman ﬁlter in the particle i of
RBPF at time step k
P s
k
Covariance computed by a Gaussian (RTS) smoother for the
time step k
P s
0WT
Trajectory of smoother means from a Gaussian (RTS)
smoother
P s;.i/
0WT
Trajectory of smoother covariances from iteration i of an iter-
ated smoother or history of covariances of the RTS smoother
in the particle i of RBPS
P x
k
Predicted dynamic model covariance in a statistical linear re-
gression ﬁlter
P xx
k
Predicted dynamic model cross-covariance in a statistical lin-
ear regression ﬁlter
P xy
k
Predicted measurement model cross-covariance in a statisti-
cal linear regression ﬁlter
P y
k
Predicted measurement model covariance in a statistical lin-
ear regression ﬁlter
P x
k.xk 1/
Conditional covariance moment for a dynamic model
P y
k.xk/
Conditional covariance moment for a measurement model
P x;.i/
k
Predicted dynamic model covariance in SPCMKF for sigma
point i on time step k
P y;.i/
k
Predicted measurement model covariance in SPCMKF for
sigma point i on time step k
P xy;.i 1/
k
Predicted cross-covariance from iteration i   1 in the iterated
posterior linearization ﬁlter
P y;.i 1/
k
Predicted covariance from iteration i   1 in the iterated pos-
terior linearization ﬁlter
P
Covariance of x  .x/
P f
k
Covariance of f
k

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xxiv
Symbols and Abbreviations
P h
k
Covariance of h
k
q0
Smaller probability of error in the Gilbert–Elliot channel
model
q1
Larger probability of error in the Gilbert–Elliot channel
model
qc
Spectral density of a white noise process
qc
i
Spectral density of component i of a white noise process
q./
Proposal distribution in the MCMC algorithm or an arbitrary
distribution in the derivation of the EM-algorithm
q.n/
Distribution approximation on the nth step of the EM-
algorithm
q
Gaussian random vector
qk
Gaussian process noise
Qqk
Euler–Maruyama approximation-based Gaussian process
noise
Q
Variance of scalar process noise
Q./
k
Sigma point of the process noise qk
Q.; .n// An auxiliary function needed in the EM-algorithm
Q
Covariance of the process noise in a time-invariant model
Qk
Covariance of the process noise at the jump from step k to
k C 1
QQk
Euler–Maruyama approximation-based covariance of the
process noise
Qc
Spectral density matrix of (vector-valued) white noise
r
Distance to the center of rotation
rk
Scalar Gaussian measurement noise
rk
Vector of Gaussian measurement noises
rj./
Residual term in the Gauss–Newton objective function
R
Variance of scalar measurement noise
R./
k
Sigma point of the measurement noise rk
R
Covariance matrix of the measurement in a time-invariant
model or the covariance-related parameter in Student’s t-
distribution
Rk
Covariance matrix of the measurement at the time step k
R
Space of real numbers
Rn
n-dimensional space of real numbers
Rnm
Space of real n  m matrices
s
Speed, generic integration variable, or temporary variable
sk
Regime signal in the Gilbert–Elliot channel model

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xxv
si;x
x-coordinate of radar i
si;y
y-coordinate of radar i
S
Number of backward-simulation draws
St./
Student’s t-distribution
S.i/
Covariance at iteration i of iterated posterior linearization
Sk
Innovation covariance of a Kalman/Gaussian ﬁlter at time
step k
S.i/
k
Innovation covariance at the ith iteration of an iterated ﬁlter
at time step k
SG
Covariance in the generalized statistical linear regression
SL
Covariance in the linear (Taylor series-based) approximation
SM
Covariance in the Gaussian moment matching approximation
SQ
Covariance in the quadratic approximation
SR
Covariance in the statistical linear regression approximation
SR.x/
Conditional covariance moment in statistical linear regression
SS
Covariance in the statistical linearization approximation
SU
Covariance in the unscented approximation
t
Time variable t 2 Œ0; 1/
t0
Another time variable t0 2 Œ0; 1/
t.i/
Cumulative sum in resampling
tk
Time of the step k (usually time of the measurement yk)
T
Index of the last time step or the ﬁnal time of a time interval
Tk
Sufﬁcient statistics
u
Scalar (random) variable
uk
Latent (non-linear) variable in a Rao–Blackwellized particle
ﬁlter or smoother, or deterministic input to a dynamic model
u.i/
k
Latent variable value in particle i
u.i/
0Wk
History of latent variable values in particle i
U./
Utility function
U./
Uniform distribution
v.i/
Random variable
vk
Bernoulli sequence in the Gilbert–Elliot channel model
v.i/
k
Unnormalized weight in a SIR particle ﬁlter-based likelihood
evaluation
vk
Innovation vector of a Kalman/Gaussian ﬁlter at time step k
Qvk
Noise term in an enabling Gaussian approximation of a mea-
surement model on time step k
v .i/
k
Innovation vector at ith iteration of iterated extended Kalman
ﬁlter at time step k

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xxvi
Symbols and Abbreviations
V
Volume of space
Vk.xk/
Value function at time step k of the Viterbi algorithm
V
Region in space (e.g., V D Œ 1; 1)
w.i/
Normalized weight of the particle i in importance sampling
Qw.i/
Weight of the particle i in importance sampling
w.i/
Unnormalized weight of the particle i in importance sam-
pling
w.i/
k
Normalized weight of the particle i at time step k of a particle
ﬁlter
w.i/
kjn
Normalized weight of a particle smoother
wi
Weight i in a regression model
wk
Vector of weights at time step k in a regression model
w.t/
Gaussian white noise process
W
Weight in the cubature or unscented approximation
Wi
ith weight in a sigma point approximation
W .m/
i
Mean weight of the unscented transform
W .c/
i
Covariance weight of the unscented transform
Wi1;:::;in
Weight in multivariate Gauss–Hermite cubature
x
Scalar random variable or state, sometimes regressor vari-
able, or a generic scalar variable
x
Random variable or state
Ox
Estimate of x or nominal x
x.i/
ith Monte Carlo draw from the distribution of x
xk
State at time step k
x
k
Optimal state at time step k
x.i/
k
ith iterate of state estimate for time step k in iterated extended
Kalman ﬁlter or smoother, or ith Monte Carlo sample of state
in MCKF
Ox.i/
k
Predicted ith Monte Carlo sample of the state in MCKF (be-
fore prediction)
x .i/
k
Predicted ith Monte Carlo sample of the state in MCKF (after
prediction)
x.t/
State at (continuous) time t
Qxk
Augmented state at time step k
x0Wk
Set containing the state vectors fx0; : : : ; xkg
x.i/
0Wk
The history of the states in the particle i
x
0WT
Optimal state trajectory

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xxvii
x.i/
0WT
ith iterate of state trajectory estimate in an iterated extended
Kalman smoother
Qx.j/
0WT
State trajectory simulated by a backward-simulation particle
smoother
X
Matrix of regressors
Xk
Matrix of regressors up to the time step k
X ./
Sigma point of x
QX ./
Augmented sigma point of x
X ./
k
Sigma point of the state xk
QX ./
k
Augmented sigma point of the state xk
OX ./
k
Predicted sigma point of the state xk
X  ./
k
Sigma point of the predicted state xk
QX  ./
k
Augmented sigma point of the predicted state xk
X
Set of possible values for a discrete-valued state
y
Scalar variable, random variable, or measurement
y
Random variable or measurement
yk
Measurement at the time step k
y1Wk
Set containing the measurement vectors fy1; : : : ; ykg
y.i/
k
ith Monte Carlo sample of measurement in MCKF
Y./
Sigma point of y
QY./
Augmented sigma point of y
OY./
k
ith predicted sigma point of the measurement yk at step k
Y
Set of possible values for a discrete-valued measurement
z
Scalar variable
z
Augmented random variable
Z
Normalization constant
Zk
Normalization constant at the time step k
Zp
Normalization constant for distribution p
1
Inﬁnity
Abbreviations
2D
Two-dimensional
AD
Automatic differentiation
ADF
Assumed density ﬁlter
AM
Adaptive Metropolis (algorithm)
AMCMC
Adaptive Markov chain Monte Carlo
APF
Auxiliary particle ﬁlter

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xxviii
Symbols and Abbreviations
AR
Autoregressive (model)
ARMA
Autoregressive moving average (model)
ASIR
Auxiliary sequential importance resampling
BS-PS
Backward-simulation particle smoother
CA
Constant acceleration (model)
CDKF
Central differences Kalman ﬁlter
CKF
Cubature Kalman ﬁlter
CLT
Central limit theorem
CPF
Cubature particle ﬁlter
CPU
Central processing unit
CRLB
Cram´er–Rao lower bound
CRTSS
Cubature RTS smoother
CT
Coordinated turn (model)
CV
Constant velocity (model)
DLM
Dynamic linear model
DOT
Diffuse optical tomography
DSP
Digital signal processing
EC
Expectation correction
EEG
Electroencephalography
EKF
Extended Kalman ﬁlter
EM
Expectation-maximization
EP
Expectation propagation
ERTSS
Extended Rauch–Tung–Striebel smoother
FFBS
Forward-ﬁltering backward-sampling (smoother)
FHKF
Fourier–Hermite Kalman ﬁlter
fMRI
Functional magnetic resonance imaging
GHKF
Gauss–Hermite Kalman ﬁlter
GHPF
Gauss–Hermite particle ﬁlter
GHRTSS
Gauss–Hermite Rauch–Tung–Striebel smoother
GNSS
Global navigation satellite system
GPQF
Gaussian process quadrature ﬁlter
GPS
Global positioning system
GPU
Graphics processing unit
GSLR
Generalized statistical linear regression
HMC
Hamiltonian (or hybrid) Monte Carlo
HMM
Hidden Markov model
IEKF
Iterated extended Kalman ﬁlter
IEKS
Iterated extended Kalman smoother
IERTSS
Iterated extended RTS smoother
IKS
Iterated Kalman smoother

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Symbols and Abbreviations
xxix
IMM
Interacting multiple model (algorithm)
INS
Inertial navigation system
IPL
Iterated posterior linearization
IPLF
Iterated posterior linearization ﬁlter
IPLS
Iterated posterior linearization smoother
IS
Importance sampling
IURTSS
Iterated unscented RTS smoother
InI
Inverse imaging
KF
Kalman ﬁlter
LIE
Law of iterated expectations
LLN
Law of large numbers
LMS
Least mean squares
LQG
Linear quadratic Gaussian (regulator)
MA
Moving average (model)
MAP
Maximum a posteriori
MC
Monte Carlo
MCKF
Monte Carlo Kalman ﬁlter
MCMC
Markov chain Monte Carlo
MCRTSS
Monte Carlo RTS smoother
MEG
Magnetoencephalography
MH
Metropolis–Hastings
MKF
Mixture Kalman ﬁlter
ML
Maximum likelihood
MLP
Multi-layer perceptron
MMSE
Minimum mean squared error
MNE
Minimum norm estimate
MSE
Mean squared error
PF
Particle ﬁlter
PL
Posterior linearization
PLF
Posterior linearization ﬁlter
PMCMC
Particle Markov chain Monte Carlo
PMMH
Particle marginal Metropolis–Hastings
QKF
Quadrature Kalman ﬁlter
RAM
Robust adaptive Metropolis (algorithm)
RBPF
Rao–Blackwellized particle ﬁlter
RBPS
Rao–Blackwellized particle smoother
RMSE
Root mean squared error
RTS
Rauch–Tung–Striebel
RTSS
Rauch–Tung–Striebel smoother
RW
Random walk (model)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
xxx
Symbols and Abbreviations
SDE
Stochastic differential equation
SIR
Sequential importance resampling
SIR-PS
Sequential importance resampling particle smoother
SIS
Sequential importance sampling
SL
Statistical linearization
SLAM
Simultaneous localization and mapping
SLDS
Switching linear dynamic system
SLF
Statistically linearized ﬁlter
SLR
Statistical linear regression
SLRF
Statistical linear regression ﬁlter
SLRRTSS Statistical linear regression RTS smoother
SLRTSS
Statistically linearized RTS smoother
SMC
Sequential Monte Carlo
SPCMKF Sigma-point conditional moment Kalman ﬁlter
TV
Time varying
TVAR
Time-varying autoregressive (model)
UKF
Unscented Kalman ﬁlter
UPF
Unscented particle ﬁlter
URTSS
Unscented Rauch–Tung–Striebel smoother
UT
Unscented transform

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1
What Are Bayesian Filtering and Smoothing?
The term optimal ﬁltering traditionally refers to a class of methods that
can be used for estimating the state of a time-varying system that is indi-
rectly observed through noisy measurements. The term optimal in this con-
text refers to statistical optimality. Bayesian ﬁltering refers to the Bayesian
way of formulating optimal ﬁltering. In this book we use these terms inter-
changeably and always mean Bayesian ﬁltering.
In optimal, Bayesian, and Bayesian optimal ﬁltering, the state of the
system refers to the collection of dynamic variables, such as position, ve-
locity, orientation, and angular velocity, which fully describe the system.
The noise in the measurements means that they are uncertain; even if we
knew the true system state, the measurements would not be deterministic
functions of the state but would have a distribution of possible values. The
time evolution of the state is modeled as a dynamic system that is perturbed
by a certain process noise. This noise is used for modeling the uncertainties
in the system dynamics. In most cases the system is not truly stochastic, but
stochasticity is used to represent the model uncertainties.
Bayesian smoothing (or optimal smoothing) is often considered to be
a class of methods within the ﬁeld of Bayesian ﬁltering. While Bayesian
ﬁlters in their basic form only compute estimates of the current state of
the system given the history of measurements, Bayesian smoothers can be
used to reconstruct states that happened before the current time. Although
the term smoothing is sometimes used in a more general sense for methods
that generate a smooth (as opposed to rough) representation of data, in the
context of Bayesian ﬁltering, the term (Bayesian) smoothing has this more
deﬁnite meaning.
1.1 Applications of Bayesian Filtering and Smoothing
Phenomena that can be modeled as time-varying systems of the above type
are very common in engineering applications. This kind of model can be
1

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
2
What Are Bayesian Filtering and Smoothing?
found, for example, in navigation, aerospace engineering, space engineer-
ing, remote surveillance, telecommunications, physics, audio signal pro-
cessing, control engineering, ﬁnance, and many other ﬁelds. Examples of
such applications are the following.
 Global positioning system (GPS) (Kaplan, 1996) is a widely used satel-
lite navigation system, where the GPS receiver unit measures arrival
times of signals from several GPS satellites and computes its position
based on these measurements (see Figure 1.1). The GPS receiver typi-
cally uses an extended Kalman ﬁlter (EKF) or some other optimal ﬁlter-
ing algorithm1 for computing the current position and velocity such that
the measurements and the assumed dynamics (laws of physics) are taken
into account. Also, the ephemeris information, which is the satellite ref-
erence information transmitted from the satellites to the GPS receivers,
is typically generated using optimal ﬁlters.
Figure 1.1 In the GPS system, the measurements are time delays
of satellite signals, and the optimal ﬁlter (e.g., extended Kalman
ﬁlter, EKF) computes the position and the accurate time.
 Target tracking (Bar-Shalom et al., 2001; Crassidis and Junkins, 2004;
Challa et al., 2011) refers to the methodology where a set of sensors,
1 Strictly speaking, the EKF is only an approximate optimal ﬁltering algorithm because it
uses a Taylor series-based Gaussian approximation to the non-Gaussian optimal ﬁltering
solution.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.1 Applications of Bayesian Filtering and Smoothing
3
such as active or passive radars, radio frequency sensors, acoustic ar-
rays, infrared sensors, or other types of sensors, are used for determin-
ing the position and velocity of a remote target (see Figure 1.2). When
this tracking is done continuously in time, the dynamics of the target
and measurements from the different sensors are most naturally com-
bined using an optimal ﬁlter or smoother. The target in this (single) tar-
get tracking case can be, for example, a robot, a satellite, a car, or an
airplane.
Figure 1.2 In target tracking, a sensor (e.g., radar) generates
measurements (e.g., angle and distance measurements) of the
target, and the purpose is to determine the target trajectory.
 Multiple target tracking (Bar-Shalom and Li, 1995; Blackman and
Popoli, 1999; Mahler, 2014; Stone et al., 2014) systems are used for
remote surveillance in cases where there are multiple targets moving
at the same time in the same geographical area (see Figure 1.3). This
introduces the concept of data association (which measurement was
from which target?) and the problem of estimating the number of
targets. Multiple target tracking systems are typically used in remote
surveillance for military purposes, but their civil applications are, for
example, monitoring of car tunnels, automatic alarm systems, and
people tracking in buildings.
 Inertial navigation (Titterton and Weston, 1997; Grewal et al., 2001)
uses inertial sensors, such as accelerometers and gyroscopes, for com-
puting the position and velocity of a device, such as a car, an airplane,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4
What Are Bayesian Filtering and Smoothing?
Figure 1.3 In multiple target tracking, the data association
problem has to be solved because it is impossible to know without
any additional information which target produced which
measurement.
or a missile. When the inaccuracies in sensor measurements are taken
into account, the natural way of computing the estimates is by using an
optimal ﬁlter or smoother. Also, in sensor calibration, which is typically
done in a time-varying environment, optimal ﬁlters and smoothers can
be applied.
 Integrated inertial navigation (Bar-Shalom et al., 2001; Grewal et al.,
2001) combines the good sides of unbiased but inaccurate sensors, such
as altimeters and landmark trackers, and biased but locally accurate in-
ertial sensors. Combination of these different sources of information is
most naturally performed using an optimal ﬁlter, such as the extended
Kalman ﬁlter. This kind of approach was used, for example, in the guid-
ance system of the Apollo 11 lunar module (Eagle), which landed on the
moon in 1969.
 GPS/INS navigation (Bar-Shalom et al., 2001; Grewal et al., 2001) is a
form of integrated inertial navigation where the inertial navigation sys-
tem (INS) is combined with a GPS receiver unit. In a GPS/INS naviga-
tion system, the short-term ﬂuctuations of the GPS can be compensated
by the inertial sensors, and the inertial sensor biases can be compensated
by the GPS receiver. An additional advantage of this approach is that it is
possible to temporarily switch to pure inertial navigation when the GPS

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.1 Applications of Bayesian Filtering and Smoothing
5
receiver is unable to compute its position (i.e., has no ﬁx) for some rea-
son. This happens, for example, indoors, in tunnels, and in other cases
when there is no direct line-of-sight between the GPS receiver and the
satellites.
 Robotics and autonomous systems (Thrun et al., 2005; Barfoot, 2017)
typically use combinations of tracking and inertial navigation methods,
along with sensors that measure the characteristics of the environment in
one way or another. Examples of characteristics of the environment are
radio signals or the locations of obstacles or landmarks detected from
camera images. As the environment of the robot or autonomous system
is typically unknown, the map of the environment also needs to be gener-
ated during the localization process. This concept is called simultaneous
localization and mapping (SLAM), and the methodology for this pur-
pose includes, for example, extended Kalman ﬁlters and particle ﬁlters.
 Brain imaging methods, such as electroencephalography (EEG),
magnetoencephalography (MEG), parallel functional magnetic reso-
nance imaging (fMRI), and diffuse optical tomography (DOT) (see
Figure 1.4), are based on reconstruction of the source ﬁeld in the brain
from noisy sensor data by using the minimum norm estimates (MNE)
technique and its variants (Hauk, 2004; Tarantola, 2004; Kaipio and
Somersalo, 2005; Lin et al., 2006). The minimum norm solution can
also be interpreted in the Bayesian sense as a problem of estimating
the ﬁeld with certain prior structure from Gaussian observations.
With that interpretation, the estimation problem becomes equivalent
to a statistical inversion or generalized Gaussian process regression
problem (Tarantola, 2004; Kaipio and Somersalo, 2005; Rasmussen and
Williams, 2006; S¨arkk¨a, 2011). Including dynamical priors then leads
to a linear or non-linear spatio-temporal estimation problem, which
can be solved with Kalman ﬁlters and smoothers (cf. Hiltunen et al.,
2011; S¨arkk¨a et al., 2012b). The same can be done in inversion-based
approaches to parallel fMRI, such as inverse imaging (InI) (Lin et al.,
2006).
 Spread of infectious diseases (Keeling and Rohani, 2007) can often
be modeled as differential equations for the number of susceptible,
infected, recovered, and dead individuals. When uncertainties are
introduced into the dynamic equations, and when the measurements are
not perfect, the estimation of the spread of the disease can be formulated
as an optimal ﬁltering problem (see, e.g., S¨arkk¨a and Sottinen, 2008).
 Biological processes (Murray, 1993), such as population growth,
predator–prey models, and several other dynamic processes in biology,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6
What Are Bayesian Filtering and Smoothing?
Figure 1.4 Brain imaging methods such as EEG and MEG are
based on estimating the state of the brain from sensor readings. In
the dynamic case, the related inversion problem can be solved
with an optimal ﬁlter or smoother.
can also be modeled as (stochastic) differential equations. Estimation
of the states of these processes from inaccurate measurements can be
formulated as an optimal ﬁltering and smoothing problem.
 Telecommunications is also a ﬁeld where optimal ﬁlters are tradition-
ally used. For example, optimal receivers, signal detectors, and phase
locked loops can be interpreted to contain optimal ﬁlters (Van Trees,
1968, 1971; Proakis, 2001) as components. Also, the celebrated Viterbi
algorithm (Viterbi, 1967) can be seen as a method for computing the
maximum a posteriori (MAP) Bayesian smoothing solution for the un-
derlying hidden Markov model (HMM).
 Audio signal processing applications, such as audio restoration (Godsill
and Rayner, 1998) and audio signal enhancement (Fong et al., 2002),
often use time-varying autoregressive (TVAR) models as the underlying
audio signal models. These kinds of models can be efﬁciently estimated
using optimal ﬁlters and smoothers.
 Stochastic optimal control (Aoki, 1967; Maybeck, 1982a; Stengel, 1994)
considers control of time-varying stochastic systems. Stochastic con-
trollers can typically be found in, for example, airplanes, cars, and rock-
ets. Optimal, in addition to statistical optimality, means that the control

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.2 Origins of Bayesian Filtering and Smoothing
7
signal is constructed to minimize a performance cost, such as the ex-
pected time to reach a predeﬁned state, the amount of fuel consumed, or
the average distance from a desired position trajectory. When the state of
the system is observed through a set of sensors, as it usually is, optimal
ﬁlters are needed for reconstructing the state from them.
 Learning systems or adaptive systems can often be mathematically
formulated in terms of optimal ﬁlters and smoothers (Haykin, 2001),
and they have a close relationship to Bayesian non-parametric model-
ing, machine learning, and neural network modeling (Bishop, 2006).
Methods similar to the data association methods in multiple target
tracking are also applicable to on-line adaptive classiﬁcation (Andrieu
et al., 2002). The connection between Gaussian process regression
(Rasmussen and Williams, 2006) and optimal ﬁltering has also been
discussed, for example, in S¨arkk¨a et al. (2007a), Hartikainen and S¨arkk¨a
(2010), S¨arkk¨a et al. (2013), and S¨arkk¨a and Solin (2019).
 Physical systems that are time-varying and measured through non-ideal
sensors can sometimes be formulated as stochastic state space models,
and the time evolution of the system can be estimated using optimal
ﬁlters (Kaipio and Somersalo, 2005). These kinds of problem are of-
ten called inverse problems (Tarantola, 2004), and optimal ﬁlters and
smoothers can be seen as the Bayesian solutions to time-varying inverse
problems.
1.2 Origins of Bayesian Filtering and Smoothing
The roots of Bayesian analysis of time-dependent behavior are in the ﬁeld
of optimal linear ﬁltering. The idea of constructing mathematically opti-
mal recursive estimators was ﬁrst presented for linear systems due to their
mathematical simplicity, and the most natural optimality criterion from
both the mathematical and modeling points of view was least squares op-
timality. For linear systems, the optimal Bayesian solution (with minimum
mean squared error, MMSE, loss) coincides with the least squares solution,
that is, the optimal least squares solution is exactly the posterior mean.
The history of optimal ﬁltering starts from the Wiener ﬁlter (Wiener,
1950), which is a frequency-domain solution to the problem of least
squares optimal ﬁltering of stationary Gaussian signals. The Wiener ﬁlter
is still important in communication applications (Proakis, 2001), digital
signal processing (Hayes, 1996), and image processing (Gonzalez and
Woods, 2008). The disadvantage of the Wiener ﬁlter is that it can only be
applied to stationary signals.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8
What Are Bayesian Filtering and Smoothing?
The success of optimal linear ﬁltering in engineering applications is
mostly due to the seminal article of Kalman (1960b), which describes the
recursive solution to the optimal discrete-time (sampled) linear ﬁltering
problem. One reason for its success is that the Kalman ﬁlter can be un-
derstood and applied with very much lighter mathematical machinery than
the Wiener ﬁlter. Also, despite its mathematical simplicity and generality,
the Kalman ﬁlter (or actually the Kalman–Bucy ﬁlter (Kalman and Bucy,
1961)) contains the Wiener ﬁlter as its limiting special case.
In the early stages of its history, the Kalman ﬁlter was soon discovered
to belong to the class of Bayesian ﬁlters (Ho and Lee, 1964; Lee, 1964;
Jazwinski, 1966, 1970). The corresponding Bayesian smoothers (Rauch,
1963; Rauch et al., 1965; Leondes et al., 1970) were also developed soon
after the invention of the Kalman ﬁlter. An interesting historical detail is
that while Kalman and Bucy were formulating the linear theory in the
United States, Stratonovich was doing the pioneering work on the prob-
abilistic (Bayesian) approach in Russia (Stratonovich, 1968; Jazwinski,
1970).
As discussed in the book of West and Harrison (1997), in the 1960s,
Kalman ﬁlter-like recursive estimators were also used in the Bayesian com-
munity, and it is not clear whether the theory of Kalman ﬁltering or the
theory of dynamic linear models (DLM) came ﬁrst. Although these theo-
ries were originally derived from slightly different starting points, they are
equivalent. Because of the Kalman ﬁlter’s useful connection to the the-
ory and history of stochastic optimal control, this book approaches the
Bayesian ﬁltering problem from the Kalman ﬁltering point of view.
Although the original derivation of the Kalman ﬁlter was based on the
least squares approach, the same equations can be derived from pure prob-
abilistic Bayesian analysis. The Bayesian analysis of Kalman ﬁltering is
well covered in the classical book of Jazwinski (1970) and a bit more re-
cently in the book of Bar-Shalom et al. (2001). Kalman ﬁltering, mostly
because of its least squares interpretation, has been widely used in stochas-
tic optimal control. A practical reason for this is that the inventor of the
Kalman ﬁlter, Rudolph E. Kalman, has also made several contributions
to the theory of linear quadratic Gaussian (LQG) regulators (Kalman,
1960a), which are fundamental tools of stochastic optimal control (Sten-
gel, 1994; Maybeck, 1982a).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.3 Optimal Filtering and Smoothing as Bayesian Inference
9
hidden:
/ xk 1
/

xk
/

xkC1
/

observed:
yk 1
yk
ykC1
Figure 1.5 In optimal ﬁltering and smoothing problems a
sequence of hidden states xk is indirectly observed through noisy
measurements yk:
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Figure 1.6 An example of a time series, which models a
discrete-time resonator. The actual resonator state (signal) is
hidden and only observed through the noisy measurements.
1.3 Optimal Filtering and Smoothing as Bayesian Inference
In mathematical terms, optimal ﬁltering and smoothing are considered to
be statistical inversion problems, where the unknown quantity is a vector-
valued time series fx0; x1; x2; : : :g that is observed through a set of noisy
measurements fy1; y2; : : :g, as illustrated in Figure 1.5. An example of this
kind of time series is shown in Figure 1.6. The process shown is a noisy
resonator with a known angular velocity. The state xk D .xk Pxk/T is two
dimensional (2D) and consists of the position of the resonator xk and its
time derivative Pxk. The measurements yk are scalar observations of the
resonator position (signal), and they are corrupted by measurement noise.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10
What Are Bayesian Filtering and Smoothing?
The purpose of the statistical inversion at hand is to estimate the hid-
den states x0WT D fx0; : : : ; xT g from the observed measurements y1WT D
fy1; : : : ; yT g, which means that in the Bayesian sense we want to compute
the joint posterior distribution of all the states given all the measurements.
In principle, this can be done by a straightforward application of Bayes’
rule
p.x0WT j y1WT / D p.y1WT j x0WT / p.x0WT /
p.y1WT /
;
(1.1)
where
 p.x0WT / is the prior distribution deﬁned by the dynamic model,
 p.y1WT j x0WT / is the likelihood model for the measurements,
 p.y1WT / is the normalization constant deﬁned as
p.y1WT / D
Z
p.y1WT j x0WT / p.x0WT / dx0WT :
(1.2)
Unfortunately, this full posterior formulation has the serious disadvantage
that each time we obtain a new measurement, the full posterior distribution
would have to be recomputed. This is particularly a problem in dynamic
estimation (which is exactly the problem we are solving here!), where mea-
surements are typically obtained one at a time, and we would want to com-
pute the best possible estimate after each measurement. When the number
of time steps increases, the dimensionality of the full posterior distribu-
tion also increases, which means that the computational complexity of a
single time step increases. Thus eventually the computations will become
intractable, no matter how much computational power is available. With-
out additional information or restrictive approximations, there is no way of
getting over this problem in the full posterior computation.
However, the above problem only arises when we want to compute the
full posterior distribution of the states at each time step. If we are willing to
relax this a bit and be satisﬁed with selected marginal distributions of the
states, the computations become an order of magnitude lighter. To achieve
this, we also need to restrict the class of dynamic models to probabilis-
tic Markov sequences, which is not as restrictive as it may at ﬁrst seem.
The model for the states and measurements will be assumed to be of the
following type.
 An initial distribution speciﬁes the prior probability distribution p.x0/
of the hidden state x0 at the initial time step k D 0.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.3 Optimal Filtering and Smoothing as Bayesian Inference
11
 A dynamic model describes the system dynamics and its uncertainties
as a Markov sequence, deﬁned in terms of the transition probability dis-
tribution p.xk j xk 1/.
 A measurement model describes how the measurement yk depends
on the current state xk. This dependence is modeled by specifying the
conditional probability distribution of the measurement given the state,
which is denoted as p.yk j xk/.
Thus a general probabilistic state space model is usually written in the
following form:
x0  p.x0/;
xk  p.xk j xk 1/;
yk  p.yk j xk/:
(1.3)
Because computing the full joint distribution of the states at all time steps is
computationally very inefﬁcient and unnecessary in real-time applications,
in Bayesian ﬁltering and smoothing the following marginal distributions
are considered instead (see Figure 1.7).
 Filtering distributions computed by the Bayesian ﬁlter are the marginal
distributions of the current state xk given the current and previous mea-
surements y1Wk D fy1; : : : ; ykg:
p.xk j y1Wk/;
k D 1; : : : ; T:
(1.4)
The result of applying the Bayesian ﬁlter to the resonator time series in
Figure 1.6 is shown in Figure 1.8.
 Prediction distributions, which can be computed with the prediction step
of the Bayesian ﬁlter, are the marginal distributions of the future state
xkCn, n steps after the current time step:
p.xkCn j y1Wk/;
k D 1; : : : ; T;
n D 1; 2; : : : :
(1.5)
 Smoothing distributions computed by the Bayesian smoother are the
marginal distributions of the state xk given a certain interval y1WT D
fy1; : : : ; yT g of measurements with T > k:
p.xk j y1WT /;
k D 1; : : : ; T:
(1.6)
The result of applying the Bayesian smoother to the resonator time series
is shown in Figure 1.9.
Computing ﬁltering, prediction, and smoothing distributions require only
a constant number of computations per time step, and thus the problem of
processing arbitrarily long time series is solved.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12
What Are Bayesian Filtering and Smoothing?
Figure 1.7 State estimation problems can be divided into optimal
prediction, ﬁltering, and smoothing, depending on the time span
of the measurements available with respect to the time of the
estimated state.
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Filter Estimate
95% Quantile
Figure 1.8 The result of computing the ﬁltering distributions for
the discrete-time resonator model. The estimates are the means of
the ﬁltering distributions, and the quantiles are the 95% quantiles
of the ﬁltering distributions.
1.4 Algorithms for Bayesian Filtering and Smoothing
There exist a few classes of ﬁltering and smoothing problems that have
closed form solutions.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.4 Algorithms for Bayesian Filtering and Smoothing
13
0
5
10
15
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time step k
Resonator position xk
 
 
Signal
Measurement
Smoother Estimate
95% Quantile
Figure 1.9 The result of computing the smoothing distributions
for the discrete-time resonator model. The estimates are the
means of the smoothing distributions, and the quantiles are the
95% quantiles of the smoothing distributions.
 The Kalman ﬁlter (KF) is a closed form solution to the linear Gaussian
ﬁltering problem. Due to linear Gaussian model assumptions, the poste-
rior distribution is exactly Gaussian, and no numerical approximations
are needed.
 The Rauch–Tung–Striebel smoother (RTSS) is the corresponding closed
form smoother for linear Gaussian state space models.
 Finite-state ﬁlters and smoothers are solutions for hidden Markov mod-
els (HMMs) with ﬁnite state spaces.
But because the Bayesian optimal ﬁltering and smoothing equations are
generally computationally intractable, many kinds of numerical approxi-
mation methods have been developed, for example:
 The extended Kalman ﬁlter (EKF) approximates the non-linear and non-
Gaussian measurement and dynamic models by linearization, that is,
by forming a Taylor series expansion at the nominal (or maximum a
posteriori, MAP) solution. This results in a Gaussian approximation to
the ﬁltering distribution.
 The extended Rauch–Tung–Striebel smoother (ERTSS) is the approxi-
mate non-linear smoothing algorithm corresponding to the EKF.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14
What Are Bayesian Filtering and Smoothing?
 The unscented Kalman ﬁlter (UKF) approximates the propagation
of densities through the non-linearities of measurement and noise
processes using the unscented transform. This also results in a Gaussian
approximation.
 The unscented Rauch–Tung–Striebel smoother (URTSS) is the approxi-
mate non-linear smoothing algorithm corresponding to the UKF.
 Sequential Monte Carlo methods or particle ﬁlters and smoothers repre-
sent the posterior distribution as a weighted set of Monte Carlo samples.
 The unscented particle ﬁlter (UPF) and local linearization-based parti-
cle ﬁltering methods use UKFs and EKFs, respectively, for approximat-
ing the optimal importance distributions in particle ﬁlters.
 Rao–Blackwellized particle ﬁlters and smoothers use closed form inte-
gration (e.g., Kalman ﬁlters and RTS smoothers) for some of the state
variables and Monte Carlo integration for others.
 Grid-based approximation methods approximate the ﬁltering and
smoothing distributions as discrete distributions on a ﬁnite grid.
 Other methods also exist, for example, based on Gaussian mixtures, se-
ries expansions, describing functions, basis function expansions, expo-
nential family of distributions, variational Bayesian methods, and batch
Monte Carlo (e.g., Markov chain Monte Carlo, MCMC, methods).
1.5 Parameter Estimation
In state space models of dynamic systems, there are often unknown or un-
certain parameters , which should be estimated along with the state itself.
For example, in a stochastic resonator model, the frequency of the resonator
might be unknown. Also, the noise variances might be only known approx-
imately, or they can be completely unknown. Although, formally, we can
always augment unknown parameters as part of the state, in practice it is
often useful to consider parameter estimation separately.
In a Bayesian setting, the proper way to estimate the parameters is by
setting a prior distribution on the parameters p./ and treating them as
additional random variables in the model. When unknown parameters are
present, the state space model in Equation (1.3) becomes
  p./;
x0  p.x0 j /;
xk  p.xk j xk 1; /;
yk  p.yk j xk; /:
(1.7)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
1.5 Parameter Estimation
15
The full Bayesian solution to this problem would require the computation
of the full joint posterior distribution of states and parameters p.x0WT ;  j
y1WT /. Unfortunately, computing this joint posterior of the states and pa-
rameters is even harder than computation of the joint distribution of states
alone, and thus this task is intractable.
Fortunately, when run with ﬁxed parameters , the Bayesian ﬁlter al-
gorithm produces the sequence of distributions p.yk j y1Wk 1; / for k D
1; : : : ; T as side products. Once we have these, we can form the marginal
posterior distribution of parameters as follows:
p. j y1WT / / p./
TY
kD1
p.yk j y1Wk 1; /;
(1.8)
where we have denoted p.y1 j y1W0; / , p.y1 j / for notational conve-
nience. When combined with the smoothing distributions, we can form all
the marginal joint distributions of states and parameters as follows:
p.xk;  j y1WT / D p.xk j y1WT ; / p. j y1WT /
(1.9)
for k D 1; : : : ; T , where p.xk j y1WT ; / is the smoothing distribution of
the states with ﬁxed model parameters . However, we cannot compute the
full joint posterior distribution of states and parameters, which is the price
of only using a constant number of computations per time step.
Although here we use the term parameter estimation, it might some-
times be the case that we are not actually interested in the values of the
parameters as such, but we just do not know their values. In that case the
proper Bayesian approach is to integrate out the parameters. For example,
to compute the smoothing distributions in the presence of unknown pa-
rameters we can integrate out the parameters from the joint distribution in
Equation (1.9):
p.xk j y1WT / D
Z
p.xk;  j y1WT / d
D
Z
p.xk j y1WT ; / p. j y1WT / d:
(1.10)
Many of the Bayesian methods for parameter estimation indeed allow this
to be done (approximately). For example, by using the parameter samples
produced by a Markov chain Monte Carlo (MCMC) method, it is possible
to form a Monte Carlo approximation to the above integral.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16
What Are Bayesian Filtering and Smoothing?
1.6 Exercises
1.1
Find the seminal article of Kalman (1960b) from the internet (or from a
library) and investigate the orthogonal projections approach that is taken in
the article. How would you generalize the approach to the non-linear/non-
Gaussian case? Is it possible?
1.2
An alternative to Bayesian estimation would be to formulate the state estima-
tion problem as maximum likelihood (ML) estimation. This would amount
to estimating the state sequence as the ML-estimate
Ox0WT D arg max
x0WT p.y1WT j x0WT /:
(1.11)
Do you see any problem with this approach? Hint: Where is the dynamic
model?
1.3
Assume that in an electronics shop, the salesperson decides to give you a
chance to win a brand new GPS receiver. He lets you choose one of three
packages of which one contains the GPS receiver and two others are empty.
After you have chosen the package, the salesperson opens one of the pack-
ages that you have not chosen – and that package turns out to be empty.
He gives you a chance to switch to the other yet unopened package. Is it
advantageous for you to do that?

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
2
Bayesian Inference
This chapter provides a brief presentation of the philosophical and math-
ematical foundations of Bayesian inference. The connections to classical
statistical inference are also brieﬂy discussed.
2.1 Philosophy of Bayesian Inference
The purpose of Bayesian inference (Bernardo and Smith, 1994; Gelman
et al., 2013) is to provide a mathematical machinery that can be used for
modeling systems, where the uncertainties of the system are taken into
account, and the decisions are made according to rational principles. The
tools of this machinery are probability distributions and the rules of proba-
bility calculus.
If we compare the so-called frequentist philosophy of statistical analy-
sis to Bayesian inference, the difference is that in Bayesian inference, the
probability of an event does not mean the proportion of the event in an
inﬁnite number of trials but the certainty of the event in a single trial. Be-
cause models in Bayesian inference are formulated in terms of probability
distributions, the probability axioms and computation rules of probability
theory (see, e.g., Shiryaev, 1996) also apply in Bayesian inference.
2.2 Connection to Maximum Likelihood Estimation
Consider a situation where we know the conditional distribution p.yk j /
of conditionally independent random variables (measurements) y1WT D
fy1; : : : ; yT g, but the parameter  2 Rd is unknown. The classical statisti-
cal method for estimating the parameter is the maximum likelihood method
(Milton and Arnold, 1995), where we maximize the joint probability of the
17

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
18
Bayesian Inference
measurements, also called the likelihood function,
L./ D
TY
kD1
p.yk j /:
(2.1)
The maximum of the likelihood function with respect to  gives the maxi-
mum likelihood estimate (ML-estimate)
O D arg max

L./:
(2.2)
The difference between Bayesian inference and the maximum likelihood
method is that the starting point of Bayesian inference is to formally con-
sider the parameter  as a random variable. Then the posterior distribution
of the parameter  can be computed by using Bayes’ rule,
p. j y1WT / D p.y1WT j / p./
p.y1WT /
;
(2.3)
where p./ is the prior distribution, which models the prior beliefs on the
parameter before we have seen any data, and p.y1WT / is a normalization
term, which is independent of the parameter . This normalization con-
stant is often left out, and if the measurements y1WT are conditionally inde-
pendent given , the posterior distribution of the parameter can be written
as
p. j y1WT / / p./
TY
kD1
p.yk j /:
(2.4)
Because we are dealing with a distribution, we might now choose the most
probable value of the random variable, the maximum a posteriori (MAP)
estimate, which is given by the maximum of the posterior distribution.
The optimal estimate in the mean squared sense is the posterior mean of
the parameter (MMSE-estimate). There are an inﬁnite number of other
ways of choosing the point estimate from the distribution, and the best
way depends on the assumed loss or cost function (or utility function). The
ML-estimate can be seen as a MAP-estimate with uniform prior p./ / 1
on the parameter .
We can also interpret Bayesian inference as a convenient method for
including regularization terms into maximum likelihood estimation. The
basic ML-framework does not have a self-consistent method for including
regularization terms or prior information into statistical models. However,
this regularization interpretation of Bayesian inference is quite limited be-
cause Bayesian inference is much more than this.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
2.3 The Building Blocks of Bayesian Models
19
2.3 The Building Blocks of Bayesian Models
The basic blocks of a Bayesian model are the prior model containing the
preliminary information on the parameter and the measurement model de-
termining the stochastic mapping from the parameter to the measurements.
Using combination rules, namely Bayes’ rule, it is possible to infer an es-
timate of the parameters from the measurements. The probability distribu-
tion of the parameters, conditional on the observed measurements, is called
the posterior distribution, and it is the distribution representing the state of
knowledge about the parameters when all the information in the observed
measurements and the model is used. The predictive posterior distribution
is the distribution of new (not yet observed) measurements when all the
information in the observed measurements and the model is used.
 Prior model
The prior information consists of subjective experience-based beliefs
about the possible and impossible parameter values and their relative
likelihoods before anything has been observed. The prior distribution is
a mathematical representation of this information:
p./ D information on parameter  before seeing any observations.
(2.5)
The lack of prior information can be expressed by using a non-
informative prior. The non-informative prior distribution can be selected
in various different ways (Gelman et al., 2013).
 Measurement model
Between the true parameters and the measurements, there often is a
causal, but inaccurate or noisy relationship. This relationship is math-
ematically modeled using the measurement model:
p.y j / D distribution of observation y given the parameters .
(2.6)
 Posterior distribution
The posterior distribution is the conditional distribution of the param-
eters given the observations. It represents the information we have af-
ter the measurement y has been obtained. It can be computed by using
Bayes’ rule,
p. j y/ D p.y j / p./
p.y/
/ p.y j / p./;
(2.7)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
20
Bayesian Inference
where the normalization constant is given as
p.y/ D
Z
p.y j / p./ d:
(2.8)
In the case of multiple measurements y1WT , if the measurements are con-
ditionally independent, the joint likelihood of all measurements is the
product of distributions of the individual measurements, and the poste-
rior distribution is
p. j y1WT / / p./
TY
kD1
p.yk j /;
(2.9)
where the normalization term can be computed by integrating the right-
hand side over . If the random variable is discrete, the integration is
replaced by summation.
 Predictive posterior distribution
The predictive posterior distribution is the distribution of new measure-
ments yT C1 given the observed measurements
p.yT C1 j y1WT / D
Z
p.yT C1 j / p. j y1WT / d:
(2.10)
Thus, after obtaining the measurements y1WT , the predictive posterior
distribution can be used to compute the probability distribution for mea-
surement index T C 1, which has not been observed yet.
In the case of tracking, we could imagine that the parameter is the sequence
of dynamic states of a target, where the state contains the position and ve-
locity. The measurements could be, for example, noisy distance and direc-
tion measurements produced by a radar. In this book we will divide the
parameters into two classes: the dynamic state of the system and the static
parameters of the model. But from the Bayesian estimation point of view,
both the states and static parameters are unknown (random) parameters of
the system.
2.4 Bayesian Point Estimates
In many practical applications, distributions alone have no use; we need
ﬁnite dimensional summaries (point estimates). This selection of a point
based on observed values of random variables is a statistical decision, and
therefore this selection procedure is most naturally formulated in terms of
statistical decision theory (Berger, 1985; Bernardo and Smith, 1994; Raiffa
and Schlaifer, 2000).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
2.4 Bayesian Point Estimates
21
Deﬁnition 2.1 (Loss function). A loss function or cost function C.; a/
is a scalar-valued function that determines the loss of taking the action a
when the true parameter value is . The action (or control) is the statistical
decision to be made based on the currently available information.
Instead of loss functions, it is also possible to work with utility functions
U.; a/, which determine the reward from taking the action a with param-
eter values . Loss functions can be converted to utility functions and vice
versa by deﬁning U.; a/ D  C.; a/.
If the value of the parameter  is not known, but the knowledge of the pa-
rameter can be expressed in terms of the posterior distribution p. j y1WT /,
then the natural choice is the action that gives the minimum (maximum) of
the expected loss (utility) (Berger, 1985):
EŒC.; a/ j y1WT  D
Z
C.; a/ p. j y1WT / d:
(2.11)
Commonly used loss functions are the following.
 Quadratic error loss. If the loss function is quadratic,
C.; a/ D .   a/T.   a/;
(2.12)
then the optimal choice ao is the mean of the posterior distribution of ,
ao D
Z
 p. j y1WT / d:
(2.13)
This posterior mean-based estimate is often called the minimum mean
squared error (MMSE) estimate of the parameter . The quadratic loss is
the most commonly used loss function for regression problems because
it is easy to handle mathematically and because in the case of a Gaussian
posterior distribution, the MAP estimate and the median coincide with
the posterior mean.
 Absolute error loss. The loss function of the form
C.; a/ D
X
i
ji   aij
(2.14)
is called an absolute error loss, and in this case the optimal choice is the
median of the distribution (the medians of the marginal distributions in
the multi-dimensional case).
 0–1 loss. If the loss function is of the form
C.; a/ D  ı.a   /;
(2.15)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
22
Bayesian Inference
where ı./ is the Dirac delta function, then the optimal choice is the
maximum (mode) of the posterior distribution, that is, the maximum a
posteriori (MAP) estimate of the parameter. If the random variable  is
discrete, the corresponding loss function can be deﬁned as
C.; a/ D
(
0;
if  D a;
1;
if  ¤ a:
(2.16)
2.5 Numerical Methods
In principle, Bayesian inference provides the equations for computing the
posterior distributions and point estimates for any model once the model
speciﬁcation has been set up. However, the practical difﬁculty is that
computation of the integrals involved in the equations can rarely be per-
formed analytically, and numerical methods are needed. Here we brieﬂy
describe numerical methods that are also applicable in higher-dimensional
problems:
Gaussian
approximations,
multi-dimensional
quadratures,
Monte Carlo methods, and importance sampling.
 Gaussian approximations (Gelman et al., 2013) are very common, and
in them the posterior distribution is approximated by a Gaussian distri-
bution (see Section A.1)
p. j y1WT / ' N. j m; P/:
(2.17)
The mean m and covariance P of the Gaussian approximation can be
computed either by matching the ﬁrst two moments of the posterior
distribution or by using the mode of the distribution as the approximation
of m and by approximating P using the curvature of the posterior at the
mode. Note that above we have introduced the notation ', which here
means that the left-hand side is assumed to be approximately equal to
the right-hand side, even though we know that this will not be true in
most practical situations nor can we control the approximation error in
any practical way.
 Multi-dimensional quadrature or cubature integration methods, such as
Gauss–Hermite quadrature, can also be used if the dimensionality of the
integral is moderate. The idea is to deterministically form a representa-
tive set of sample points f.i/ W i D 1; : : : ; N g (sometimes called sigma

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
2.5 Numerical Methods
23
points) and form the approximation of the integral as the weighted aver-
age
EŒg./ j y1WT  
N
X
iD1
Wi g..i//;
(2.18)
where the numerical values of the weights Wi are determined by the
algorithm. The sample points and weights can be selected, for example,
to give exact answers for polynomials up to certain degree or to account
for the moments up to certain degree. Above we have used the notation
 to mean that the expressions are approximately equal in some suitable
limit (here N ! 1) or in some veriﬁable conditions.
 In direct Monte Carlo methods, a set of N samples from the posterior
distribution is randomly drawn,
.i/  p. j y1WT /;
i D 1; : : : ; N;
(2.19)
and the expectation of any function g./ can be then approximated as the
sample average
EŒg./ j y1WT   1
N
X
i
g..i//:
(2.20)
Another interpretation of this is that Monte Carlo methods form an ap-
proximation of the posterior density of the form
p. j y1WT /  1
N
N
X
iD1
ı.   .i//;
(2.21)
where ı./ is the Dirac delta function. The convergence of Monte Carlo
approximation is guaranteed by the central limit theorem (CLT) (see,
e.g., Liu, 2001), and the error term is, at least in theory, under certain
ideal conditions, independent of the dimensionality of . The rule of
thumb is that the error should decrease as the square root of the number
of samples, regardless of the dimensions.
 Efﬁcient methods for generating Monte Carlo samples are the Markov
chain Monte Carlo (MCMC) methods (see, e.g., Gilks et al., 1996; Liu,
2001; Brooks et al., 2011). In MCMC methods, a Markov chain is con-
structed such that it has the target distribution as its stationary distribu-
tion. By simulating the Markov chain, samples from the target distribu-
tion can be generated.
 Importance sampling (see, e.g., Liu, 2001) is a simple algorithm for
generating weighted samples from the target distribution. The difference

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
24
Bayesian Inference
between this and direct Monte Carlo sampling and MCMC is that each of
the particles has an associated weight, which corrects for the difference
between the actual target distribution and the approximate importance
distribution ./ from which the sample was drawn.
An importance sampling estimate can be formed by drawing N sam-
ples from the importance distribution
.i/  . j y1WT /;
i D 1; : : : ; N:
(2.22)
The importance weights are then computed as
Qw.i/ D 1
N
p..i/ j y1WT /
..i/ j y1WT /;
(2.23)
and the expectation of any function g./ can be then approximated as
EŒg./ j y1WT  
N
X
iD1
Qw.i/ g..i//;
(2.24)
or alternatively as
EŒg./ j y1WT  
PN
iD1 Qw.i/ g..i//
PN
iD1 Qw.i/
:
(2.25)
2.6 Exercises
2.1
Prove that the median of distribution p./ minimizes the expected value of
the absolute error loss function
EŒj   aj D
Z
j   aj p./ d:
(2.26)
2.2
Find the optimal point estimate a that minimizes the expected value of the
loss function
C.; a/ D .   a/T R .   a/;
(2.27)
where R is a positive deﬁnite matrix, and the distribution of the parameter is
  p. j y1WT /.
2.3
Assume that we have obtained T measurement pairs .xk; yk/ from the linear
regression model
yk D 1 xk C 2;
k D 1; 2; : : : ; T:
(2.28)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
25
The purpose is now to derive estimates of the parameters 1 and 2 such that
the following error is minimized (least squares estimate):
E.1; 2/ D
T
X
kD1
.yk   1 xk   2/2:
(2.29)
(a) Deﬁne y D .y1 : : : yT /T and  D .1 2/T. Show that the set of
Equations (2.28) can be written in matrix form as
y D X ;
with a suitably deﬁned matrix X.
(b) Write the error function in Equation (2.29) in matrix form in terms of y,
X, and .
(c) Compute the gradient of the matrix form error function, and solve the
least squares estimate of the parameter  by ﬁnding the point where the
gradient is zero.
2.4
Assume that in the linear regression model above (Equation (2.28)), we set
independent Gaussian priors for the parameters 1 and 2 as follows:
1  N.0; 2/;
2  N.0; 2/;
where the variance 2 is known. The measurements yk are modeled as
yk D 1 xk C 2 C "k;
k D 1; 2; : : : ; T;
where the terms "ks are independent Gaussian errors with mean 0 and vari-
ance 1, that is, "k  N.0; 1/. The values xk are ﬁxed and known. The poste-
rior distribution can be now written as
p. j y1; : : : ; yT /
/ exp
 
 1
2
T
X
kD1
.yk   1 xk   2/2
!
exp

  1
22 2
1

exp

  1
22 2
2

:
The posterior distribution can be seen to be Gaussian, and your task is to
derive its mean and covariance.
(a) Write the exponent of the posterior distribution in matrix form as in
Exercise 2.3 (in terms of y, X, , and 2).
(b) Because a Gaussian distribution is always symmetric, its mean m is at
the maximum of the distribution. Find the posterior mean by computing
the gradient of the exponent and ﬁnding where it vanishes.
(c) Find the covariance of the distribution by computing the second deriva-
tive matrix (Hessian matrix) H of the exponent. The posterior covari-
ance is then P D  H 1 (why?).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
26
Bayesian Inference
(d) What is the resulting posterior distribution? What is the relationship
with the least squares estimate in Exercise 2.3?
2.5
Implement an importance sampling-based approximation for the Bayesian
linear regression problem in the above Exercise 2.4. Use a suitable Gaussian
distribution as the importance distribution for the parameters . Check that
the posterior mean and covariance (approximately) coincide with the exact
values computed in Exercise 2.4.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3
Batch and Recursive Bayesian Estimation
In order to understand the meaning and applicability of Bayesian ﬁltering
and its relationship to recursive estimation, it is useful to go through an
example where we solve a simple and familiar linear regression problem
in a recursive manner. After that we generalize this concept to include a
dynamic model in order to illustrate the differences in dynamic and batch
estimation.
3.1 Batch Linear Regression
Consider the linear regression model
yk D 1 C 2 tk C "k;
(3.1)
where we assume that the measurement noise is a zero mean Gaus-
sian with a given variance "k  N.0; 2/, and the prior distribution
of the parameters 
D .1 2/T is Gaussian with known mean and
covariance   N.m0; P0/. In the classical linear regression problem,
we want to estimate the parameters  from a set of measurement data
D D f.t1; y1/; : : : ; .tT ; yT /g. The measurement data and the true linear
function used in the simulation are illustrated in Figure 3.1.
In compact probabilistic notation, the linear regression model can be
written as
p.yk j / D N.yk j Hk ; 2/;
p./ D N. j m0; P0/;
(3.2)
where we have introduced the row vector Hk D .1 tk/, and N./ denotes
the Gaussian probability density function (see Section A.1). Note that we
denote the row vector Hk in matrix notation because it generally is a matrix
(when the measurements are vector valued), and we want to avoid using
different notations for scalar and vector measurements. The likelihood of
yk is also conditional on the regressors tk (or equivalently Hk), but because
27

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
28
Batch and Recursive Bayesian Estimation
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
 t
 y
 
 
Measurement
True signal
Figure 3.1 The underlying truth and the measurement data in the
simple linear regression problem.
the regressors are assumed to be known, to simplify the notation we will
not denote this dependence explicitly, and from now on this dependence is
assumed to be understood from the context.
The batch solution to the linear regression problem in Equation (3.2) can
be obtained by a straightforward application of Bayes’ rule:
p. j y1WT / / p./
TY
kD1
p.yk j /
D N. j m0; P0/
TY
kD1
N.yk j Hk ; 2/:
In the posterior distribution above, we assume the conditioning on tk and
Hk but will not denote it explicitly. Thus the posterior distribution is de-
noted to be conditional on y1WT , and not on the data set D also containing
the regressor values tk. The reason for this simpliﬁcation is that the simpli-
ﬁed notation will also work in more general ﬁltering problems, where there
is no natural way of deﬁning the associated regressor variables.
Because the prior and likelihood are Gaussian, the posterior distribution
will also be Gaussian:
p. j y1WT / D N. j mT ; PT /:
(3.3)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.1 Batch Linear Regression
29
0
0.2
0.4
0.6
0.8
1
0.5
1
1.5
2
 t
 y
 
 
Measurement
True signal
Estimate
Figure 3.2 The result of simple linear regression with a slight
regularization prior used for the regression parameters. For
simplicity, the variance was assumed to be known.
The mean and covariance can be obtained by completing the quadratic
form in the exponent, which gives:
mT D

P  1
0
C 1
2 HT H
 1  1
2 HT y C P  1
0
m0

;
PT D

P  1
0
C 1
2 HT H
 1
;
(3.4)
where Hk D .1 tk/, and
H D
0
B@
H1
:::
HT
1
CA D
0
B@
1
t1
:::
:::
1
tT
1
CA ;
y D
0
B@
y1
:::
yT
1
CA :
(3.5)
Figure 3.2 shows the result of batch linear regression, where the posterior
mean parameter values are used as the linear regression parameters.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
30
Batch and Recursive Bayesian Estimation
3.2 Recursive Linear Regression
A recursive solution to the regression problem (3.2) can be obtained by
assuming that we have already obtained the posterior distribution condi-
tioned on the previous measurements 1; : : : ; k   1, as follows:
p. j y1Wk 1/ D N. j mk 1; Pk 1/:
Now assume that we have obtained a new measurement yk, and we want to
compute the posterior distribution of  given the old measurements y1Wk 1
and the new measurement yk. According to the model speciﬁcation, the
new measurement has the likelihood
p.yk j / D N.yk j Hk ; 2/:
Using the batch version equations such that we interpret the previous pos-
terior as the prior, we can calculate the distribution
p. j y1Wk/ / p.yk j / p. j y1Wk 1/
/ N. j mk; Pk/;
(3.6)
where the Gaussian distribution parameters are
mk D

P  1
k 1 C 1
2 HT
k Hk
 1  1
 2 HT
k yk C P  1
k 1 mk 1

;
Pk D

P  1
k 1 C 1
2 HT
k Hk
 1
:
(3.7)
By using the matrix inversion lemma (see Corollary A.5), the covariance
calculation can be written as
Pk D Pk 1   Pk 1 HT
k

Hk Pk 1 HT
k C 2 1 Hk Pk 1:
By introducing temporary variables Sk and Kk, the calculation of the mean
and covariance can then be written in the form
Sk D Hk Pk 1 HT
k C 2;
Kk D Pk 1 HT
k S  1
k ;
mk D mk 1 C Kk Œyk   Hk mk 1;
Pk D Pk 1   Kk Sk KT
k:
(3.8)
Note that Sk D Hk Pk 1 HT
k C 2 is scalar because the measurements are
scalar and thus no matrix inversion is required.
The equations above actually are special cases of the Kalman ﬁlter up-
date equations. Only the update part of the equations (as opposed to the

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.3 Batch versus Recursive Estimation
31
0
0.2
0.4
0.6
0.8
1
 t
-1
-0.5
0
0.5
1
1.5
 y
Recursive E[ 1 ]
Batch E[ 
1 ]
Recursive E[ 2 ]
Batch E[ 
2 ]
Figure 3.3 Convergence of the means of recursive linear
regression parameters. The ﬁnal value is exactly the same as that
obtained with batch linear regression.
prediction and update) is required because the estimated parameters are as-
sumed to be constant, that is, there is no stochastic dynamics model for the
parameters . Figures 3.3 and 3.4 illustrate the convergence of the means
and variances of the parameters during the recursive estimation.
3.3 Batch versus Recursive Estimation
In this section we generalize the recursion idea used in the previous section
to general probabilistic models. The underlying idea is simply that at each
measurement, we treat the posterior distribution of the previous time step
as the prior for the current time step. This way we can compute the same
solution in a recursive manner that we would obtain by direct application
of Bayes’ rule to the whole (batch) data set.
The batch Bayesian solution to a statistical estimation problem can be
formulated as follows.
1. Specify the likelihood model of measurements p.yk j / given the pa-
rameter . Typically the measurements yk are assumed to be condition-
ally independent such that
p.y1WT j / D
TY
kD1
p.yk j /:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
32
Batch and Recursive Bayesian Estimation
0
0.2
0.4
0.6
0.8
1
 t
10-4
10-3
10-2
10-1
100
 y
Recursive Var[ 1 ]
Batch Var[ 1 ]
Recursive Var[ 2 ]
Batch Var[ 2 ]
Figure 3.4 Convergence of the variances of linear regression
parameters plotted on logarithmic scale. As can be seen, every
measurement brings more information, and the uncertainty
decreases monotonically. The ﬁnal values are the same as the
variances obtained from the batch solution.
2. The prior information about the parameter  is encoded into the prior
distribution p./.
3. The observed data set is D D f.t1; y1/; : : : ; .tT ; yT /g, or if we drop the
explicit conditioning on tk, the data is D D y1WT .
4. The batch Bayesian solution to the statistical estimation problem can be
computed by applying Bayes’ rule:
p. j y1WT / D 1
Z p./
TY
kD1
p.yk j /;
where Z is the normalization constant
Z D
Z
p./
TY
kD1
p.yk j / d:
For example, the batch solution of the above kind to the linear regression
problem (3.2) was given by Equations (3.3) and (3.4).
The recursive Bayesian solution to the above statistical estimation prob-
lem can be formulated as follows.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.3 Batch versus Recursive Estimation
33
1. The distribution of measurements is again modeled by the likelihood
function p.yk j /, and the measurements are assumed to be condition-
ally independent.
2. In the beginning of estimation (i.e., at step 0), all the information about
the parameter  we have is contained in the prior distribution p./.
3. The measurements are assumed to be obtained one at a time – ﬁrst y1,
then y2, and so on. At each step we use the posterior distribution from
the previous time step as the current prior distribution:
p. j y1/ D 1
Z1
p.y1 j /p./;
p. j y1W2/ D 1
Z2
p.y2 j /p. j y1/;
p. j y1W3/ D 1
Z3
p.y3 j /p. j y1W2/;
:::
p. j y1WT / D
1
ZT
p.yT j /p. j y1WT  1/:
It is easy to show that the posterior distribution at the ﬁnal step above is
exactly the posterior distribution obtained by the batch solution. Also,
reordering of measurements does not change the ﬁnal solution.
For example, Equations (3.6) and (3.7) give the one step update rule for the
linear regression problem in Equation (3.2).
The recursive formulation of Bayesian estimation has many useful prop-
erties.
 The recursive solution can be considered as the on-line learning solution
to the Bayesian learning problem. That is, the information on the param-
eters is updated in an on-line manner using new pieces of information as
they arrive.
 Because each step in the recursive estimation is a full Bayesian update
step, batch Bayesian inference is a special case of recursive Bayesian
inference.
 Due to the sequential nature of estimation, we can also model the ef-
fect of time on the parameters. That is, we can model what happens to
the parameter  between the measurements – this is actually the basis
of ﬁltering theory, where time behavior is modeled by assuming the pa-
rameter to be a time-dependent stochastic process .t/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
34
Batch and Recursive Bayesian Estimation
3.4 Drift Model for Linear Regression
Assume that we have a similar linear regression model as in Equation (3.2),
but the parameter  is allowed to perform a Gaussian random walk be-
tween the measurements:
p.yk j k/ D N.yk j Hk k; 2/;
p.k j k 1/ D N.k j k 1; Q/;
p.0/ D N.0 j m0; P0/;
(3.9)
where Q is the covariance of the random walk. Now, given the distribution
p.k 1 j y1Wk 1/ D N.k 1 j mk 1; Pk 1/;
the joint distribution of k and k 1 is1
p.k; k 1 j y1Wk 1/ D p.k j k 1/ p.k 1 j y1Wk 1/:
The distribution of k given the measurement history up to time step k   1
can be calculated by integrating over k 1:
p.k j y1Wk 1/ D
Z
p.k j k 1/ p.k 1 j y1Wk 1/ dk 1:
This relationship is sometimes called the Chapman–Kolmogorov equation.
Because p.k j k 1/ and p.k 1 j y1Wk 1/ are Gaussian, the result of the
marginalization is Gaussian,
p.k j y1Wk 1/ D N.k j m k ; P  k /;
where
m k D mk 1;
P  k D Pk 1 C Q:
By using this as the prior distribution for the measurement likelihood
p.yk j k/, we get the parameters of the posterior distribution
p.k j y1Wk/ D N.k j mk; Pk/;
1 Note that this formula is correct only for Markovian dynamic models, where
p.k j k 1; y1Wk 1/ D p.k j k 1/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.4 Drift Model for Linear Regression
35
0
0.5
1
1.5
2
 t
-1.5
-1
-0.5
0
0.5
1
1.5
Measurements
True Signal
Estimate
Figure 3.5 Example of tracking a sine signal with a linear model
with drift, where the parameters are allowed to vary according to
the Gaussian random walk model.
which are given by Equations (3.8), when mk 1 and Pk 1 are replaced by
m k and P  k :
Sk D Hk P  k HT
k C 2;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk Œyk   Hk m k ;
Pk D P  k   Kk Sk KT
k:
(3.10)
This recursive computational algorithm for the time-varying linear regres-
sion weights is again a special case of the Kalman ﬁlter algorithm. Fig-
ure 3.5 shows the result of recursive estimation of a sine signal assuming a
small diagonal Gaussian drift model for the parameters.
At this point we change from the regression notation used so far into
state space model notation, which is commonly used in Kalman ﬁlter-
ing and related dynamic estimation literature. Because this notation easily
causes confusion to people who have got used to regression notation, this
point is emphasized.
 In state space notation, x means the unknown state of the system, that is,
the vector of unknown parameters in the system. It is not the regressor,
covariate, or input variable of the system.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
36
Batch and Recursive Bayesian Estimation
 For example, the time-varying linear regression model with drift pre-
sented in this section can be transformed into the more standard state
space model notation by replacing the variable k D .1;k 2;k/T with
the variable xk D .x1;k x2;k/T:
p.yk j xk/ D N.yk j Hk xk; 2/;
p.xk j xk 1/ D N.xk j xk 1; Q/;
p.x0/ D N.x0 j m0; P0/:
(3.11)
From now on, the symbol  is reserved for denoting the static parameters
of the state space model. Although there is no fundamental difference be-
tween states and the static parameters of the model (we can always augment
the parameters as part of the state), it is useful to treat them separately.
3.5 State Space Model for Linear Regression with Drift
The linear regression model with drift in the previous section had the disad-
vantage that the covariates tk occurred explicitly in the model speciﬁcation.
The problem with this is that when we get more and more measurements,
the parameter tk grows without bound. Thus the conditioning of the prob-
lem also gets worse in time. For practical reasons it would also be desirable
to have a time-invariant model, that is, a model that is not dependent on the
absolute time but only on the relative positions of states and measurements
in time.
The alternative state space formulation of the linear regression model
with drift, without using explicit covariates, can be done as follows. Let us
denote the time difference between consecutive times as tk 1 D tk tk 1.
The idea is that if the underlying phenomenon (signal, state, parameter) xk
was exactly linear, the difference between adjacent time points could be
written exactly as
xk   xk 1 D Px tk 1;
(3.12)
where Px is the derivative, which is constant in the exactly linear case. The
divergence from the exactly linear function can be modeled by assuming
that the above equation does not hold exactly, but there is a small noise
term on the right-hand side. The derivative can also be assumed to perform
a small random walk and thus not be exactly constant. This model can be

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.5 State Space Model for Linear Regression with Drift
37
written as follows:
x1;k D x1;k 1 C tk 1x2;k 1 C q1;k 1;
x2;k D x2;k 1 C q2;k 1;
yk D x1;k C rk;
(3.13)
where the signal is the ﬁrst components of the state, x1;k , xk, and the
derivative is the second, x2;k , Pxk. The noises are rk  N.0; 2/ and
.q1;k 1; q2;k 1/  N.0; Q/. The model can also be written in the form
p.yk j xk/ D N.yk j H xk; 2/;
p.xk j xk 1/ D N.xk j Ak 1 xk 1; Q/;
(3.14)
where
Ak 1 D
1
tk 1
0
1

;
H D
 1
0

:
With a suitable Q, this model is actually equivalent to model (3.9), but in
this formulation we explicitly estimate the state of the signal (point on the
regression line) instead of the linear regression parameters.
We could now explicitly derive the recursion equations in the same
manner as we did in the previous sections. However, we can also use the
Kalman ﬁlter, which is a readily derived recursive solution to generic linear
Gaussian models of the form
p.yk j xk/ D N.yk j Hk xk; Rk/;
p.xk j xk 1/ D N.xk j Ak 1 xk 1; Qk 1/:
Our alternative linear regression model in Equation (3.13) can be seen to
be a special case of these models. The Kalman ﬁlter equations are often
expressed as prediction and update steps as follows.
1. Prediction step:
m k D Ak 1 mk 1;
P  k D Ak 1 Pk 1 AT
k 1 C Qk 1:
2. Update step:
Sk D Hk P  k HT
k C Rk;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk Œyk   Hk m k ;
Pk D P  k   Kk Sk KT
k:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
38
Batch and Recursive Bayesian Estimation
0
0.5
1
1.5
2
 t
-1.5
-1
-0.5
0
0.5
1
1.5
Measurements
True Signal
Estimate
Figure 3.6 Example of tracking a sine signal with a Kalman ﬁlter
using the locally linear state space model. The result differs
slightly from the random walk parameter model because of a
slightly different choice of process noise. It could be made
equivalent if desired.
The result of tracking the sine signal with a Kalman ﬁlter is shown in
Figure 3.6. All the mean and covariance calculation equations given in
this book so far have been special cases of the above equations, including
the batch solution to the scalar measurement case (which is a one-step
solution). The Kalman ﬁlter recursively computes the mean and covariance
of the posterior distributions of the form
p.xk j y1Wk/ D N.xk j mk; Pk/:
Note that the estimates of xk derived from this distribution are non-
anticipative in the sense that they are only conditional on the measurements
obtained before and at the time step k. However, after we have obtained the
measurements y1; : : : ; yk, we could compute estimates of xk 1; xk 2; : : :,
which are also conditional to the measurements after the corresponding
state time steps. Because more measurements and more information are
available for the estimator, these estimates can be expected to be more
accurate than the non-anticipative measurements computed by the ﬁlter.
The abovementioned problem of computing estimates of the state
by conditioning not only on previous measurements but also on future
measurements is called Bayesian smoothing, as already mentioned in

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.6 Toward Bayesian Filtering and Smoothing
39
0
0.5
1
1.5
2
 t
-1.5
-1
-0.5
0
0.5
1
1.5
Measurements
True Signal
Estimate
Figure 3.7 Example of tracking a sine signal with the
Rauch–Tung–Striebel (RTS) smoother using the locally linear
state space model. The result is much “smoother” and more
accurate than the result of the Kalman ﬁlter.
Section 1.3. The Bayesian smoothing solution to linear Gaussian state
space models is given by the Rauch–Tung–Striebel (RTS) smoother. The
full Bayesian theory of smoothing will be presented in Chapter 12. The
result of tracking the sine signal with the RTS smoother is shown in
Figure 3.7.
It is also possible to predict the time behavior of the state in the future
that we have not yet measured. This procedure is called optimal prediction.
Because optimal prediction can always be done by iterating the prediction
step of the optimal ﬁlter, no specialized algorithms are needed for this.
The result of prediction of the future values of the sine signal is shown in
Figure 3.8.
3.6 Toward Bayesian Filtering and Smoothing
The models that we have seen in this chapter can be seen as special cases
of probabilistic state models having the following form:
dynamics: xk  p.xk j xk 1/;
measurements: yk  p.yk j xk/;
(3.15)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
40
Batch and Recursive Bayesian Estimation
0
0.5
1
1.5
2
2.5
 t
-1.5
-1
-0.5
0
0.5
1
1.5
Measurements
True Signal
Estimate
Figure 3.8 Example of prediction of a sine signal with an
optimal linear predictor (the Kalman ﬁlter prediction step) using
the locally linear state space model. The prediction is a straight
line extending to inﬁnity, as the model states.
although so far we have only looked at Gaussian examples of dynamic and
measurement models. However, non-linear generalizations of Bayesian
ﬁltering, smoothing, and prediction problems and solutions can be ob-
tained by replacing the Gaussian distributions and linear functions in the
model with non-Gaussian and non-linear ones. The Bayesian ﬁltering
and smoothing theory described in this book can be applied to generic
non-linear ﬁltering models of the above form.
To understand the generality of this model, it is useful to note that if we
dropped the time-dependence from the state, we would get the model
dynamics: x  p.x/;
measurements: yk  p.yk j x/;
(3.16)
which can be seen as a general Bayesian statistical model (Gelman et al.,
2013) where yk contains the observed quantities (data) and x is the vector
of all unknown parameters. Because x can be an arbitrary set of parameters
or hyper-parameters of the system, all static Bayesian models are special
cases of this model. Thus in the dynamic estimation context, we extend the
static models by allowing for a Markov model for the time-behavior of the
(hyper-)parameters.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
3.7 Exercises
41
The Markovianity is also less of a restriction than it sounds because what
we have is a vector-valued Markov process, not a scalar one. Similar to the
fact that differential equations of an arbitrary order can always be trans-
formed into vector-valued differential equations of the ﬁrst order, Markov
processes of an arbitrary order can be transformed into vector-valued ﬁrst-
order Markov processes.
3.7 Exercises
3.1
Recall that the batch solution to the linear regression problem in Equa-
tions (3.2) is given by the mean and covariance in Equations (3.4). The im-
plementation of these equations can be found in the companion codes of the
book2.
(a) Use the matrix inversion lemmas in Corollary A.5 to convert the batch
linear regression solution in Equations (3.4) to a similar form as Equa-
tions (3.8). Hint: R D 2 I.
(b) Check numerically that Equations (3.4) and the equations that you de-
rived give exactly the same mean and covariance.
3.2
Note that the model in Exercise 2.4 can be rewritten as a linear state space
model
wk D wk 1;
yk D Hk wk C "k;
where Hk D .xk 1/, w0  N.0; 2 I/, and "k  N.0; 1/. The state in
the model is now wk D .1 2/T, and the measurements are yk for k D
1; : : : ; T . Assume that the Kalman ﬁlter is used for processing the measure-
ments y1; : : : ; yT . Your task is to prove that at time step T , the mean and
covariance of wT computed by the Kalman ﬁlter are the same as the mean
and covariance of the posterior distribution computed in Exercise 2.4.
The Kalman ﬁlter equations for the above model can be written as:
Sk D Hk Pk 1 HT
k C 1;
Kk D Pk 1 HT
k S 1
k ;
mk D mk 1 C Kk .yk   Hk mk 1/;
Pk D Pk 1   Kk Sk KT
k:
(a) Write formulas for the posterior mean mk 1 and covariance Pk 1 as-
suming that they are the same as those that would be obtained if the pairs
f.xi; yi/ W i D 1; : : : ; k  1g were (batch) processed as in Exercise 2.4.
2 https://github.com/EEA-sensors/Bayesian-Filtering-and-Smoothing

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
42
Batch and Recursive Bayesian Estimation
Write similar equations for the mean mk and covariance Pk. Show that
the posterior means can be expressed in the form
mk 1 D Pk 1 XT
k 1 yk 1;
mk D Pk XT
k yk;
where Xk 1 and yk 1 have been constructed as X and y in Exercise 2.4,
except that only the pairs f.xi; yi/ W i D 1; : : : ; k   1g have been used,
and Xk and yk have been constructed similarly from pairs up to the step
k.
(b) Rewrite the expressions XT
k Xk and XT
k yk in terms of Xk 1, yk 1, Hk
and yk. Substitute these into the expressions of mk and Pk obtained in
(a).
(c) Expand the expression of the covariance Pk D Pk 1   Kk Sk KT
k by
substituting the expressions for Kk and Sk. Convert it to a simpler form
by applying the matrix inversion lemma (see Corollary A.5)
Pk 1 Pk 1 HT
k .Hk Pk 1 HT
kC1/ 1 Hk Pk 1 D .P  1
k 1CHT
k Hk/ 1:
Show that this expression for Pk is equivalent to the expression in (a).
(d) Expand the expression of the mean mk D mk 1CKk .yk Hk mk 1/,
and show that the result is equivalent to the expression obtained in (a).
Hint: The Kalman gain can also be written as Kk D Pk HT
k.
(e) Prove by an induction argument that the mean and covariance computed
by the Kalman ﬁlter at step T is the same as the posterior mean and
covariance obtained in Exercise 2.4.
3.3
Recall that the Gaussian probability density is deﬁned as
N.x j m; P/ D
1
.2 /n=2 jPj1=2 exp

 1
2.x   m/T P  1 .x   m/

:
Derive the following Gaussian identities.
(a) Let x and y have the Gaussian densities
p.x/ D N.x j m; P/;
p.y j x/ D N.y j H x; R/;
then the joint distribution of x and y is
x
y

 N
 m
H m

;
 P
P HT
H P
H P HT C R

and the marginal distribution of y is
y  N.H m; H P HT C R/:
Hint: Use the properties of expectation EŒH xCr D H EŒxCEŒr and
CovŒH x C r D H CovŒx HT C CovŒr (if x and r are independent).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
43
(b) Write down the explicit expression for the joint and marginal probability
densities above:
p.x; y/ D p.y j x/ p.x/ D‹
p.y/ D
Z
p.y j x/ p.x/ dx D‹
(c) If the random variables x and y have the joint Gaussian probability
density
x
y

 N
a
b

;
 A
C
CT
B

;
then the conditional density of x given y is
x j y  N.a C C B 1 .y   b/; A   C B 1CT/:
Hints:
 Denote inverse covariance as D D
D11
D12
DT
12
D22

, and expand the
quadratic form in the Gaussian exponent.
 Compute the derivative with respect to x and set it to zero. Conclude
that due to symmetry, the point where the derivative vanishes is the
mean.
 From the block matrix inverse formulas given in Theorem A.4, we
get that the inverse of D11 is
D 1
11 D A   C B 1 CT
and that D12 can be then written as
D12 D  D11 C B 1:
 Find the simpliﬁed expression for the mean by applying the identities
above.
 Find the second derivative of the negative Gaussian exponent with
respect to x. Conclude that it must be the inverse conditional covari-
ance of x.
 Use the Schur complement expression above for computing the con-
ditional covariance.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4
Discretization of Continuous-Time Dynamic
Models
A probabilistic state space model requires both a dynamic model and a
measurement model. The measurement model relates states to measure-
ments via the conditional distribution p.yk j xk/ and enables us to use
measurements to learn about states. The dynamic model instead uses the
transition distribution p.xk j xk 1/ to describe how the state evolves over
time, and therefore indirectly enables us to make use of measurements col-
lected at other time steps to learn about xk at the current time step k. This
chapter aims to describe how to construct dynamic models for tracking.
We will complete these state space models with measurement models in
the next chapter. Although the focus is on tracking, the same ideas also
work for building models of, for example, electromechanical systems or
biological systems.
Dynamic models that arise from target tracking can often be described in
terms of differential equations, or their random counterparts stochastic dif-
ferential equations (SDEs), which evolve continuously in time (as opposed
to jumping from one time step to another). Therefore, in this chapter, we
ﬁrst construct models in continuous time and then discretize them to obtain
models that operate in discrete time steps. This conversion to discrete time
is needed because our ﬁlters and smoothers in the next chapters all operate
in discrete time. For more details on the mathematics behind continuous-
time models, and in particular SDEs, the reader is referred to S¨arkk¨a and
Solin (2019).
It is worth noting that in this chapter (and book), we have purposely
chosen the approach of ﬁrst forming a continuous-time white-noise-driven
model and then discretizing it. This approach has the advantage of having
an inherent mathematical connection with the theory of SDEs. Another
approach to form the model would be to drive the stochastic differential
equation with a piecewise constant or impulse noise. The relationships and
differences between these modeling approaches are discussed, for example,
in Bar-Shalom et al. (2001).
44

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.1 Discrete-Time and Continuous-Time Dynamic Models
45
Time t
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
Signal x(t)
x1
t1
x2
t2
x3
t3
x4
t4
t1
t2
t3
Figure 4.1 A scalar continuous time signal x.t/ sampled at four
different times: x1 D x.t1/; x2 D x.t2/; x3 D x.t3/, and
x4 D x.t4/.
4.1 Discrete-Time and Continuous-Time Dynamic Models
A discrete-time dynamic model refers to a model of xk given xk 1, where
k is an integer-valued time step index. We can often express this model as
a functional relationship
xk D fk 1.xk 1/ C qk 1;
(4.1)
where qk 1  N.0; Qk 1/ is a Gaussian process noise. This can also be
expressed as a conditional distribution,
p.xk j xk 1/ D N.xk j fk 1.xk 1/; Qk 1/:
(4.2)
By accurately modeling the dynamics of the state, we can better predict the
distribution of future states and thereby obtain better prediction, ﬁltering,
and smoothing performance.
In many cases, we can view the discrete-time state sequence xk, where
k D 1; 2; 3; : : :, as samples from a continuous-time function x.t/ where
t 2 Œ0; 1/ such that xk D x.tk/. We use tk to denote the time of the
discrete time step k, which is usually the time when we observe the mea-
surement yk, and tk 1 D tk   tk 1 to denote the sampling period. This is
illustrated in Figure 4.1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
46
Discretization of Continuous-Time Dynamic Models
The connection to the continous-time function x.t/ is useful because
instead of directly modeling the discrete-time dynamics of xk, it is often
easier to formulate a model for the continuous-time state sequence, for in-
stance, by using underlying laws of physics to describe how objects move.
The continuous-time analog of the discrete-time model in Equation (4.1) is
the stochastic differential equation (SDE)
dx.t/
dt
D a.x.t// C L w.t/;
(4.3)
where a./ is a known function, L is a known matrix, and w.t/ is a
continuous-time Gaussian process noise. The process noise w.t/ is
assumed to be a zero mean white noise process, which means that the
process has the following mean and covariance functions:
E Œw.t/ D 0;
Cov Œw.1/; w.2/ D ı.1   2/ Qc:
(4.4)
Here ı./ is the Dirac delta function, and Qc is referred to as the spectral
density matrix of the white noise, which can be seen as a continuous-time
analog of a covariance matrix. Furthermore, the white noise enters the SDE
causally in the sense that w.t0/ and x.t/ are uncorrelated whenever t0  t.
Considering that the noise is also white, see Equation (4.4), this implies that
x.t/ is Markovian. In engineering literature, it is common to express the
models in terms of white noise like this because that enables us to develop
the models without introducing new mathematical concepts – rigorous for-
mulations of SDEs often rely on Itˆo calculus (see, e.g., S¨arkk¨a and Solin,
2019); this requires a redeﬁnition of the concept of an integral, which adds
mathematical complexity.
In the following sections, we explain how to construct a dynamic model
for xk. Speciﬁcally, we describe general techniques to express the time
behaviour of x.t/ as an SDE of the form of Equation (4.3). The discrete-
time dynamic model such as Equation (4.1) is then obtained as a model
for the transition from xk 1 D x.tk 1/ to xk D x.tk/. The process of
obtaining a discrete-time model from the continuous-time counterpart is
referred to as discretization. Importantly, since x.t/ is Markovian, so is the
discrete-time sequence xk. It also turns out that it is always possible to ﬁnd
a transition density p.xk j xk 1/ D p.x.tk/ j x.tk 1// that is an exact
probabilistic description of the transition from xk 1 to xk (S¨arkk¨a and
Solin, 2019), but unfortunately, this density is often intractable and cannot
be written in a simple form as Equation (4.1). Therefore, for non-linear
models, we need to use approximate discretization methods.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.2 Discretizing Linear Dynamic Models
47
g1.t/
g2.t/
Figure 4.2 Illustration of car’s dynamic model in Example 4.1.
In the dynamic model, the unknown forces g1.t/ and g2.t/ are
modeled as white noise processes.
4.2 Discretizing Linear Dynamic Models
Let us start with a time-invariant continuous-time linear model, expressed
as an SDE,
dx.t/
dt
D F x.t/ C L w.t/;
(4.5)
where w.t/ is white Gaussian noise with moments (i.e., mean and covari-
ance) as given in Equation (4.4). The key feature in this model is that the
right-hand side is a linear function of x.t/. This kind of model is very use-
ful in practical applications because simple physics-based dynamic models
often have this form, as seen from the following example.
Example 4.1 (Dynamic model of a car). Let us consider a car moving in
2D as shown in Figure 4.2. We can model the car as a point mass located at
its center point .x1; x2/. A simple way to model its movement is to assume
that it is pushed around by certain unknown, time-dependent forces g1.t/
and g2.t/, which are related to the dynamical behavior by Newton’s second
law
g.t/ D m a.t/;
(4.6)
which thus relates the vector of (unknown) forces g D .g1; g2/ to the
accelerations a D .d2x1
ı
dt2 ; d2x2
ı
dt2 / and the mass of the car m.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
48
Discretization of Continuous-Time Dynamic Models
Because the function g.t/ is unknown, a sensible (Bayesian) way to model
it is to replace it with a random process. Let us thus model g.t/=m as a
vector of two independent white noise processes, reducing Newton’s law to
d2x1.t/
dt2
D w1.t/;
d2x2.t/
dt2
D w2.t/:
(4.7)
If we deﬁne x3 D dx1= dt, x4 D dx2= dt, then the model can be written as
a ﬁrst order system of differential equations:
d
dt
0
BB@
x1
x2
x3
x4
1
CCA D
0
BB@
0
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0
1
CCA
„
ƒ‚
…
F
0
BB@
x1
x2
x3
x4
1
CCA C
0
BB@
0
0
0
0
1
0
0
1
1
CCA
„ ƒ‚ …
L
w1
w2

:
(4.8)
In shorter matrix form, this can be written as a continuous-time linear
dynamic model of the form
dx
dt D F x C L w;
where the spectral density of white noise w.t/ has the form Qc
D
diag.qc
1; qc
2/, where qc
1 and qc
2 are the spectral densities of w1.t/ and
w2.t/, respectively.
The model obtained above is a special case of the continuous-time con-
stant velocity models, also called Wiener velocity models. More generally,
we have the following class of models.
Example
4.2
(Continuous-time
constant
velocity
model).
A
d-
dimensional continuous-time constant velocity (CV) model, also called the
Wiener velocity model, can be written as
dx.t/
dt
D
0
I
0
0

x.t/ C
0
I

w.t/;
(4.9)
where the ﬁrst d elements in x are the position of an object (or the value of
a variable), and the remaining d elements represent the velocity. The model
speciﬁes that the time derivative of the position is the velocity, whereas the
time derivative of the velocity is the process noise w.t/.
The solution x.t/ to the linear SDE in Equation (4.5) is Gaussian be-
cause it is produced by a linear system driven by Gaussian noise. This also

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.2 Discretizing Linear Dynamic Models
49
implies that the transition density p.x.tk/ j x.tk 1//, and thus the cor-
responding discrete-time model, is a discrete-time linear Gaussian model.
The following theorem provides a closed-form expression for computing
the transition density and hence the closed-form discretization of a time-
invariant linear SDE.
Theorem 4.3 (Discretization of linear dynamic models). The transition
density for the linear time-invariant SDE in Equation (4.5), where the white
noise process w.t/ has the spectral density Qc, is given as
p.x.tk/ j x.tk 1// D N.x.tk/ j exp.F tk 1/ x.tk 1/; Qk 1/;
(4.10)
where tk 1 D tk   tk 1 and
Qk 1 D
Z tk 1
0
exp .F s/ L Qc LT exp .F s/T ds:
(4.11)
Please note that above, exp./ is the matrix exponential function, not an
element-wise exponential. Consequently, discretization gives a linear and
Gaussian model
xk D Ak 1 xk 1 C qk 1;
(4.12)
where Ak 1 D exp.F tk 1/ and qk 1  N.0; Qk 1/.
Proof
This theorem follows from Lemma A.9, by setting b D 0 and
 D tk 1 in the lemma.
Example 4.4 (Discretization of the Wiener process). Let us then consider a
d-dimensional Wiener process, which can be considered as a time-integral
of a d-dimensional white noise process and hence has the representation
dx.t/
dt
D w.t/;
(4.13)
for which F D 0. Assume that the spectral density of the white noise is Qc.
Because exp.0/ D I, it follows from Theorem 4.3 that
p.x.tk/ j x.tk 1// D N.x.tk/ j x.tk 1/; Qk 1/;
(4.14)
where Qk 1 D
R tk 1
0
Qc ds D Qc tk 1. The discretized version of the
Wiener process is thus a random walk
xk D xk 1 C qk 1;
(4.15)
where qk 1  N.0; Qk 1/ and Qk 1 D Qc tk 1. See Figure 4.3 for an
illustration.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
50
Discretization of Continuous-Time Dynamic Models
0.5
1
1.5
2
2.5
3
3.5
Time t
-1
0
1
2
x(t)
(a)
-1
0
1
2
xk
0
1
2
3
4
5
6
7
Time step k
(b)
Figure 4.3 (a) One realization of a scalar Wiener process x.t/
with Qc D 2. (b) A random walk, obtained by sampling x.t/ with
sampling period t D 0:5, which means that we have Qk D 1
for all k D 0; 1; 2; : : : .
Example 4.5 (Discrete-time constant/Wiener velocity model). We can use
Theorem 4.3 to discretize the constant/Wiener velocity model in Exam-
ple 4.2. From Equation (4.9), we conclude that
F D
0
I
0
0

;
L D
0
I

:
(4.16)
It follows from Theorem 4.3, and the deﬁnition of the matrix exponential,
that
Ak 1 D exp.F tk 1/ D
1
X
nD0
.F tk 1/n
nŠ
D
I
0
0
I

C F tk 1 D
I
I tk 1
0
I

;
(4.17)
becase F n D 0 except for n D 0 and n D 1, that is, F is a nilpotent matrix
with index 2. Ignoring the process noise, this transition matrix says that the
velocity is constant, whereas the new position is the previous position plus
tk 1 times the velocity.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.2 Discretizing Linear Dynamic Models
51
If we assume that the spectral density of the white noise is Qc, then the
discrete-time covariance matrix is
Qk 1 D
Z tk 1
0
exp.F s/ L Qc LT exp.F s/T ds
D
Z tk 1
0
I
s I
0
I
 0
I

Qc  0
I
  I
0
s I
I

ds
D
Z tk 1
0
s2 Qc
s Qc
s Qc
Qc

ds
D
 
t3
k 1
3
Qc
t2
k 1
2
Qc
t2
k 1
2
Qc
tk 1 Qc
!
;
(4.18)
where we used (4.17) to rewrite exp.F s/. If tk 1  1, the overall pro-
cess noise is small and dominated by the noise on the velocity state. If
tk 1  1, the process noise is large and dominated by the noise on the
position state.
Example 4.6 (Discretized dynamic model of a car). Using the result in
Example 4.5 with Qc D diag.qc
1; qc
2/, we can discretize the dynamic model
of the car in Example 4.1 with discretization step t to get
0
BB@
x1;k
x2;k
x3;k
x4;k
1
CCA D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
„
ƒ‚
…
A
0
BB@
x1;k 1
x2;k 1
x3;k 1
x4;k 1
1
CCA C qk 1;
(4.19)
where qk 1 is a discrete-time Gaussian noise process with zero mean and
covariance:
Q D
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
:
(4.20)
This can be seen to be a (discrete-time) linear dynamic model of the form
xk D A xk 1 C qk 1;
where xk D x.tk/, and A is the transition matrix given in Equation (4.19).
For models where the integral expression for the covariance in Equa-
tion (4.11) does not have a convenient analytical expression, it can still be

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
52
Discretization of Continuous-Time Dynamic Models
numerically evaluated efﬁciently using matrix fraction decomposition (see,
e.g., Axelsson and Gustafsson, 2015; S¨arkk¨a and Solin, 2019).
4.3 The Euler–Maruyama Method
In Example 4.1 we derived a dynamic model of a car, and the model had
a closed-form discretization given in Example 4.6 because the model was
linear. However, often the dynamics need to be modeled with non-linear
(stochastic) differential equations, in which case the discretization cannot
be done in closed form. One method to approximately discretize a non-
linear SDE model is the Euler–Maruyama method (see, e.g., S¨arkk¨a and
Solin, 2019).
Let us now assume that we can formulate the dynamics of our modeled
phenomenon as a non-linear SDE of the form
dx.t/
dt
D a.x.t// C L w.t/;
(4.21)
where L is a known matrix and w.t/ is a white noise process with spectral
density Qc as before, but now a.x/ is some non-linear function. In this
case, the transition density p.x.tk/ j x.tk 1// is no longer Gaussian in
general and generally lacks a closed form expression. In spite of this, we
generally approximate it as Gaussian and seek a non-linear model with
additive Gaussian noise
xk D fk 1.xk 1/ C qk 1;
qk 1  N.0; Qk 1/:
(4.22)
An example of a non-linear model is given in the following.
Example 4.7 (Noisy pendulum model). The differential equation for a
simple pendulum (see Figure 4.4) with unit length and mass can be written
as
d2˛
dt2 D  g sin.˛/ C w.t/;
(4.23)
where ˛ is the angle, g is the gravitational acceleration, and w.t/ is a white
noise process with a spectral density qc modeling random forces acting on
the pendulum. This model can be converted into the following state space
model:
d
dt
x1
x2

D

x2
 g sin.x1/

C
0
1

w.t/;
(4.24)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.3 The Euler–Maruyama Method
53
g
w.t/
˛
Figure 4.4 Illustration of pendulum example. In addition to the
gravitation g, there is an additional unknown force component
w.t/, which is modeled as white noise.
where x1 D ˛ and x2 D d˛= dt. This can be seen as a particular case of a
continuous-time non-linear dynamic model of the form
dx
dt D a.x/ C L w;
(4.25)
where a.x/ is a non-linear function.
The Euler–Maruyama method (see, e.g., S¨arkk¨a and Solin, 2019) is an
extension of the Euler method to SDEs. The method corresponds to the
approximation
dx.t/
dt
 a.x.tk 1// C L w.t/;
8t 2 Œtk 1; tk/;
(4.26)
that is, it uses the approximation a.x.t//  a.x.tk 1// on a short interval
Œtk 1; tk/ to simplify the solution.
Theorem 4.8 (The Euler–Maruyama method). For
dx.t/
dt
D a.x.t// C L w.t/;
(4.27)
the Euler–Maruyama method leads to the discrete-time model
xk D fk 1.xk 1/ C qk 1;
qk 1  N.0; Qk 1/;
(4.28)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
54
Discretization of Continuous-Time Dynamic Models
where
fk 1.xk 1/ D xk 1 C a.xk 1/ tk 1;
Qk 1 D L Qc LT tk 1;
(4.29)
and tk 1 D tk   tk 1. It is often more convenient to write the discretiza-
tion of the form
xk D fk 1.xk 1/ C L Qqk 1;
Qqk 1  N.0; QQk 1/
(4.30)
where
QQk 1 D Qc tk 1
(4.31)
because QQk 1 is usually strictly positive deﬁnite even though Qk 1 is not.
Proof
The Euler–Maruyama method corresponds to the approximate
model
dx.t/
dt
 a.x.tk 1// C L w.t/:
(4.32)
By integrating both sides from tk 1 to tk, we get
x.tk/   x.tk 1/ D a.x.tk 1// tk 1 C L
Z tk
tk 1
w.t/ dt:
(4.33)
We know from Example 4.4 that
Z tk
tk 1
w.t/ dt  N.0; Qc tk 1/;
(4.34)
and hence L
R tk
tk 1 w.t/ dt  N.0; L Qc LT tk 1/, which gives the results
by rearranging the terms.
Let us now apply the Euler–Maruyama method to the noisy pendulum
model that we introduced above.
Example 4.9 (Euler–Maruyama discretization of pendulum model). In the
case of the noisy pendulum model in Example 4.7, we have
a.x/ D

x2
 g sin.x1/

;
L D
0
1

:
(4.35)
If the spectral density of the white noise process w.t/ is qc, then the ﬁrst
version of the Euler–Maruyama method in Equation (4.28) gives
x1;k
x2;k

D
x1;k 1
x2;k 1

C

x2;k 1
 g sin.x1;k 1/

tk 1 C
q1;k 1
q2;k 1

;
(4.36)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.3 The Euler–Maruyama Method
55
which implies that the discrete-time dynamic model function is
fk 1.xk 1/ D

x1;k 1 C x2;k 1 tk 1
x2;k 1   g sin.x1;k 1/ tk 1

;
(4.37)
and the joint covariance of qk 1 D .q1;k 1; q2;k 1/T is
Qk 1 D L qc LT tk 1 D
0
0
0
qc tk 1

;
(4.38)
which is a singular matrix. The second version of the Euler–Maruyama
method in Equation (4.30) gives
x1;k
x2;k

D
x1;k 1
x2;k 1

C

x2;k 1
 g sin.x1;k 1/

tk 1 C
0
1

Qqk 1;
(4.39)
where Qqk 1  N.0; qc tk 1/. This discretization has the same fk 1.xk 1/
deﬁned in Equation (4.37), but now the noise is non-singular and only
enters into the second component of the state.
The challenge with the Euler–Maruyama discretization in the example
above is that the overall process noise qk 1 is singular in the sense that
its covariance matrix L qc LT tk 1 is singular. Although this problem can
sometimes be avoided by using the second form of the discretization, it
does not resolve the general issue that the transition density approximation
implied by the Euler–Maruyama method is singular whenever L Qc LT is
not invertible. This singularity is not a problem for most of the ﬁltering
methods that we see later in this book, but in iterated ﬁlters and smoothers
this singularity causes numerical problems.
Let us now look at a more complicated example of a coordinated turn
model, which is useful in target tracking applications.
Example 4.10 (The polar coordinated turn (CT) model). Consider the
problem of modeling the motion of a car as shown in Figure 4.5. Instead
of assuming random forces pushing the car as in Example 4.1, let us as-
sume that the car has a direction '.t/, which deﬁnes the front-direction of
the car as the counterclockwise angle from the east direction. If we assume
that the car moves forward, then the velocity of the car is given as
dx1.t/
dt
D s.t/ cos.'.t//;
dx2.t/
dt
D s.t/ sin.'.t//;
(4.40)
where x1; x2 are the position coordinates, and s.t/ is the speed of the car.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
56
Discretization of Continuous-Time Dynamic Models
'.t/
Figure 4.5 Illustration of polar coordinated turn (CT) model in
Example 4.10. The car moves to a direction deﬁned by the angle
'.t/, and the speed and angular velocity are perturbed by white
noises.
Furthermore, let us assume that the car is turning with an angular ve-
locity !.t/, which thus gives the following differential equation for the di-
rection:
d'.t/
dt
D !.t/:
(4.41)
We can now form a stochastic model by assuming that s.t/ and !.t/ are
perturbed by white noises via the differential equations
ds.t/
dt
D w1.t/;
d!.t/
dt
D w2.t/:
(4.42)
We can then write the resulting model in the form
d
dt
0
BBBB@
x1.t/
x2.t/
s.t/
'.t/
!.t/
1
CCCCA
D
0
BBBB@
s.t/ cos.'.t//
s.t/ sin.'.t//
0
!.t/
0
1
CCCCA
C
0
BBBB@
0
0
0
0
1
0
0
0
0
1
1
CCCCA
w1.t/
w2.t/

;
(4.43)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.3 The Euler–Maruyama Method
57
which is a model of the form
dx
dt D a.x/ C L w;
(4.44)
with the state x.t/ D
 x1.t/; x2.t/; s.t/; '.t/; !.t/

.
We can now apply the Euler–Maruyama method to the model above.
Example 4.11 (Euler–Maruyama discretization of polar CT model). If we
use the Euler–Maruyama method to discretize the polar CT model in Ex-
ample 4.10, we get (by the second form of discretization)
xk D xk 1 C
0
BBBB@
sk 1 cos.'k 1/
sk 1 sin.'k 1/
0
!k 1
0
1
CCCCA
tk 1 C
0
BBBB@
0
0
0
0
1
0
0
0
0
1
1
CCCCA
Qqk 1;
(4.45)
where Qqk 1 D .Qq1;k 1; Qq2;k 1/T with
Qqk 1  N.0; QQk 1/;
QQk 1 D
qc
1
0
0
qc
2

tk 1;
(4.46)
and where qc
1 and qc
2 are the spectral densities of the white noise processes
w1.t/ and w2.t/. Thus the discretized model has the dynamic model func-
tion
fk 1.xk 1/ D
0
BBBB@
x1;k 1 C sk 1 cos.'k 1/ tk 1
x2;k 1 C sk 1 sin.'k 1/ tk 1
sk 1
'k 1 C !k 1 tk 1
!k 1
1
CCCCA
;
(4.47)
with the state x D
 x1; x2; s; '; !
T. However, p.xk j xk 1/ D N.xk j
f.xk 1/; Qk 1/ is not a proper density since Qk 1 D L Qc LT tk 1 is
not invertible.
Originally, the Euler–Maruyama method was developed to simulate so-
lutions of SDEs (see, e.g., Kloeden and Platen, 1999; S¨arkk¨a and Solin,
2019) instead of forming discretizations of dynamic models for ﬁltering
and smoothing problems as we do here. To simulate a solution of the
SDE in Equation (4.21) between tk 1 and tk by using the Euler–Maruyama
method, we can do the following.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
58
Discretization of Continuous-Time Dynamic Models
Algorithm 4.12 (Simulating SDE solution with Euler–Maruyama). Split
interval Œtk 1; tk into n steps of length  D .tk   tk 1/=n; then do the
following:
 Start simulation from the state Ox0 D x.tk 1/.
 For j D 1; : : : ; n, simulate solution using Euler–Maruyama:
Oxj D Oxj  1 C a.Oxj  1/  C L Oqj 1;
(4.48)
where Oqj  1 is a random draw from N.0; Qc /.
 The approximation of the trajectory x.tk 1/ ! x.tk/ is then given by
the piece-wise constant trajectory consisting of the points fOx0; : : : ; Oxng.
It can be shown (Kloeden and Platen, 1999) that the trajectories simu-
lated using the Euler–Maruyama method above converge to true trajectory
samples of the SDE when  ! 0. When using multiple steps in the
Euler–Maryuama method, we also avoid the variance singularity problem
arising in the method. As discussed in Section 4.6, this can be used to cre-
ate multi-step discretizations on the basis of simple approximations such
as Euler–Maruyama. Furthermore, in Monte Carlo-based particle ﬁltering
methods, Euler–Maruyama simulation can be used as such to implement
the prediction step (or actually the importance sampling step) as it only
needs us to be able to simulate trajectories from the SDE. Simulating so-
lutions of SDEs is also useful in generating simulated data from dynamic
models, such as the pendulum model and coordinate turn model that we
have seen in this section. Because we are using more than one step in the
simulation, the singularity of the single step vanishes as the effective multi-
step transition density is no longer singular.
There are a wide range of other simulation methods for SDEs (see Kloe-
den and Platen, 1999; S¨arkk¨a and Solin, 2019), which can often also be
used as a basis for discretization of continuous-time models in the sense
that we do here. However, simulation often requires slightly different ap-
proximations than discretization. For example, linearization, which we dis-
cuss in the next sections, and which is very useful in discretization of dy-
namic models, is not as useful in simulation as the rate of convergence, in
a theoretical sense, is no better than that of Euler–Maruyama.
4.4 Discretization via Continuous-Time Linearization
The Euler–Maruyama method, which uses a zeroth order approximation
of a.x/, is a general and simple discretization method, but it often yields
rough approximations when the sampling period is long. Another problem

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.4 Discretization via Continuous-Time Linearization
59
with the Euler–Maruyama method is that it often leads to singular process
noise covariances. One way to cope with these problems is to use a ﬁrst
order Taylor series approximation
a.x.t//  a.Nx.t// C Ax.Nx.t// .x.t/   Nx.t// ;
(4.49)
where Nx.t/ is some nominal or linearization trajectory. Above, Ax.Nx.t//
denotes the Jacobian of a.x/ evaluated at Nx.t/, whose ith row is the gradi-
ent of ai.x/.
There are different ways to form the nominal trajectory. One way is
to use the expected value m.t/ D EŒx.t/ of the continuous-time model
solution as the linearization trajectory:
a.x.t//  a.m.t// C Ax.m.t// .x.t/   m.t//:
(4.50)
It may seem counterintuitive to use an unknown quantity m.t/ to approx-
imate a.x.t//, but this approximation actually helps us ﬁnd m.t/ and to
form the discretized model. The same approximation is also used in the
continuous-discrete time extended Kalman ﬁlter (e.g., S¨arkk¨a and Solin,
2019) to approximate a non-linear dynamic model with an afﬁne one.
Theorem 4.13 (Linearized continuous-time dynamic model). Suppose that
we approximate the SDE as
dx.t/
dt
 a.m.t// C Ax.m.t// .x.t/   m.t// C L w.t/:
(4.51)
Given x.tk 1/ D xk 1, x.t/ is then Gaussian for t  tk 1 with moments
that satisfy
dm.t/
dt
D a.m.t//;
(4.52)
dP.t/
dt
D Ax.m.t// P.t/ C P.t/ AT
x.m.t// C L Qc LT;
(4.53)
where m.tk 1/ D xk 1 and P.tk 1/ D 0.
Proof
Taking expectations of both sides of Equation (4.51) and using
E ŒAx.m.t//.x.t/   m.t// D 0 and E ŒL w.t/ D 0 gives Equation (4.52).
The derivation of (4.53) is more involved and is given in Appendix A.5.
The above approximation has the useful feature that the solution to the
equation dm.t/=dt D a.m.t//, with initial condition m.tk 1/ D xk 1,
is just the solution to the deterministic dynamic equation without noise.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
60
Discretization of Continuous-Time Dynamic Models
It turns out that this equation can be solved in closed form in several im-
portant examples. However, the expression for P.t/ is known as the Lya-
punov differential equation and generally lacks an analytical solution un-
less Ax.m.t// is constant. In any case, it is possible to solve the equation
for P.t/, or both of the equations, using differential equation solvers such
as Runge–Kutta methods (Hairer et al., 2008). Regardless of the solution
method, we get the following conceptual discretization method.
Algorithm 4.14 (Discretization by mean linearization). Let us denote the
solution to Equation (4.52) at time tk as fk 1.xk 1/ D m.tk/ and the
corresponding solution to Equation (4.53) as Qk 1.xk 1/ D P.tk/. Note
that the dependence on xk 1 comes from the initial condition m.tk 1/ D
xk 1. Then we can form a discretization of the continuous-time model
dx.t/
dt
D a.x.t// C L w.t/;
(4.54)
as
xk D fk 1.xk 1/ C qk 1;
qk 1  N.0; Qk 1.xk 1//:
(4.55)
The covariance Qk 1.xk 1/ in the above discretization is, in general,
a function of xk 1 and has a more complicated form than the additive
noise discretization that we obtained from the Euler–Maruyama method.
Because of this, and due to the difﬁculty of solving the Lyapunov equation,
the covariance expression is often further approximated, as we will see in
the next section. However, before that, let us take a look at an example.
Example 4.15 (Analytical mean for the polar CT model). The determinis-
tic part of the polar CT model considered in Example 4.10 has the form
d
dt
0
BBBB@
x1.t/
x2.t/
s.t/
'.t/
!.t/
1
CCCCA
D
0
BBBB@
s.t/ cos.'.t//
s.t/ sin.'.t//
0
!.t/
0
1
CCCCA
;
(4.56)
which is thus also the differential equation for the mean. To determine
the equation for fk 1.xk 1/ for the discretization with Algorithm 4.14,
we need to solve this differential equation, with initial condition

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.4 Discretization via Continuous-Time Linearization
61
xk 1 D
 x1;k 1; x2;k 1; sk 1; 'k 1; !k 1
T, which can be done analyti-
cally. As shown in Appendix A.7, this gives
fk 1.xk 1/ D
0
BBBB@
x1;k 1 C 2sk 1
!k 1 sin. tk 1 !k 1
2
/ cos.'k 1 C tk 1 !k 1
2
/
x2;k 1 C 2sk 1
!k 1 sin. tk 1 !k 1
2
/ sin.'k 1 C tk 1 !k 1
2
/
sk 1
'k 1 C !k 1 tk 1
!k 1
1
CCCCA
:
(4.57)
Note that when the angular rate is !k 1  0, we get the approximation
2sk 1
!k 1 sin. tk 1 !k 1
2
/  sk 1tk 1 and the relations
f1.xk 1/  x1;k 1 C sk 1 tk 1 cos.'k 1/;
f2.xk 1/  x2;k 1 C sk 1 tk 1 sin.'k 1/;
(4.58)
which can be used as numerically stable approximations when !k 1 is
small.
Unfortunately, the solution to the covariance differential equation (4.53)
for the polar CT model is intractable. It is possible to approximate the co-
variance of qk 1 using, for example, the Euler–Maruyama approximation
given in Example 4.11; however, unfortunately this is singular and thus un-
suited for many cases. We will come back to approximating the covariance
in the next section, but before that, let us take a look at another example.
Example 4.16 (Analytical mean for the Cartesian CT model). It is also
possible to express the polar coordinated turn (CT) model in Example 4.10
in Cartesian coordinates such that the angle and speed are replaced by
a velocity vector. If we take time derivatives of Equation (4.40) and use
Equations (4.41) and (4.42), we get
d2x1.t/
dt 2
D ds.t/
dt
cos.'.t//   s.t/ d'.t/
dt
sin.'.t//
D w1.t/ cos.'.t//   !.t/ dx2.t/
dt
;
d2x2.t/
dt 2
D ds.t/
dt
sin.'.t// C s.t/ d'.t/
dt
cos.'.t//
D w1.t/ sin.'.t// C !.t/ dx1.t/
dt
:
(4.59)
Note that the derivation is somewhat heuristic and that a more rigorous
derivation would involve the Itˆo formula (S¨arkk¨a and Solin, 2019). If we

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
62
Discretization of Continuous-Time Dynamic Models
now rename the angular velocity noise to w3.t/ and approximate the
noise terms above with independent noises w1.t/ ! w1.t/ cos.'.t//
and w2.t/ ! w1.t/ sin.'.t//, we end up with the following Cartesian
coordinated turn (CT) model:
d
dt
0
BBBB@
x1.t/
x2.t/
Px1.t/
Px2.t/
!.t/
1
CCCCA
D
0
BBBB@
Px1.t/
Px2.t/
 !.t/ Px2.t/
!.t/ Px1.t/
0
1
CCCCA
C
0
BBBB@
0
0
0
0
0
0
1
0
0
0
1
0
0
0
1
1
CCCCA
0
@
w1.t/
w2.t/
w3.t/
1
A ;
(4.60)
where . Px1; Px2/ is the velocity vector. Although this model is conceptually
simpler than the polar CT model, the disadvantage is that we no longer
have a noise process that directly affects the tangential (speed) direction,
and we are instead limited to additive noise to the velocity vector.
The analytical solution to the deterministic part of the aforementioned
model now results in
fk 1.xk 1/
D
0
BBBBB@
x1;k 1 C Px1;k 1
!k 1 sin.tk 1 !k 1/   Px2;k 1
!k 1 .1   cos.tk 1 !k 1//
x2;k 1 C Px1;k 1
!k 1 .1   cos.tk 1 !k 1// C Px2;k 1
!k 1 sin.tk 1 !k 1/
Px1;k 1 cos.tk 1 !k 1/   Px2;k 1 sin.tk 1 !k 1/
Px1;k 1 sin.tk 1 !k 1/ C Px2;k 1 cos.tk 1 !k 1/
!k 1
1
CCCCCA
D
0
BBBBB@
1
0
sin.tk 1 !k 1/
!k 1
  .1 cos.tk 1 !k 1//
!k 1
0
0
1
.1 cos.tk 1 !k 1//
!k 1
sin.tk 1 !k 1/
!k 1
0
0
0
cos.tk 1 !k 1/
  sin.tk 1 !k 1/
0
0
0
sin.tk 1 !k 1/
cos.tk 1 !k 1/
0
0
0
0
0
1
1
CCCCCA
0
BBBB@
x1;k 1
x2;k 1
Px1;k 1
Px2;k 1
!k 1
1
CCCCA
;
(4.61)
as we will see in Exercise 4.5. When !k 1  0, for numerical stability, it is
useful to replace this expression with its ﬁrst order limit when !k 1 ! 0,
which can be written as
lim
!k 1!0 fk 1.xk 1/ D
0
BBBB@
1
0
tk 1
0
0
0
1
0
tk 1
0
0
0
1
0
0
0
0
0
1
0
0
0
0
0
1
1
CCCCA
0
BBBB@
x1;k 1
x2;k 1
Px1;k 1
Px2;k 1
!k 1
1
CCCCA
:
(4.62)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.4 Discretization via Continuous-Time Linearization
63
r

ı
L
Figure 4.6 An illustration of the parameters in the bicycle model
described in Example 4.17.
The solution to the covariance is again intractable, but we come back to
ﬁnding suitable approximations for the covariance in the next sections.
Another model, which is useful for modeling vehicle dynamics, is the
bicycle model. Like the above CT models, the bicycle model also yields
closed-form solutions to the predicted mean in Equation (4.52).
Example 4.17 (Bicycle model). The bicycle model is a simple model for
cars and vehicles, which models the vehicle as having the shape of a bicy-
cle, or an electric scooter, as shown in Figure 4.6.
Let .x1.t/; x2.t// refer to the position of the rear wheel, .t/ the head-
ing, s.t/ the speed, ı.t/ the steering angle for the front wheel, and let
L be the length of the wheelbase. Apart from the state variables x.t/ D
.x1.t/; x2.t/; s.t/; .t/; ı.t//, we use r.t/ to denote the (signed) distance
to the current center of rotation.
From Figure 4.6 we conclude that tan.ı.t// D L=r.t/. We can now
describe the turn rate as
d.t/
dt
D s.t/
r.t/ D s.t/ tan.ı.t//
L
:
(4.63)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
64
Discretization of Continuous-Time Dynamic Models
If we assume that the speed and steering angle are driven by independent
white noises, then the complete model becomes
d
dt
0
BBBB@
x1.t/
x2.t/
s.t/
.t/
ı.t/
1
CCCCA
D
0
BBBB@
s.t/ cos..t//
s.t/ sin..t//
0
s.t/=r.t/
0
1
CCCCA
C L w.t/;
(4.64)
with
L D
0
BBBB@
0
0
0
0
1
0
0
0
0
1
1
CCCCA
;
Qc D
qc
s
0
0
qc
ı

:
(4.65)
The mean in Equation (4.52) again has a closed-form solution and, as
shown in Appendix A.6, this leads to the discretization
f.xk 1/ D
0
BBBB@
x1;k 1 C rk 1 .sin.k 1 C ˇk 1/   sin.k 1//
x2;k 1 C rk 1 .cos.k 1/   cos.k 1 C ˇk 1//
sk 1
k 1 C ˇk 1
ık 1
1
CCCCA
; (4.66)
where rk 1 D L= tan.ık 1/ and ˇk 1 D tk 1sk 1=rk 1. Similarly to
the CT model, the solution to the covariance using Equation (4.53) is in-
tractable, and we can either resort to the Euler–Maryuama approximation
for it or use the approximations discussed in the next section.
As discussed at the beginning of this section, we have many different
choices for the linearization trajectory Nx.t/. The linearization with respect
to the mean m.t/, which we have discussed so far, is useful when we can
solve the deterministic dynamic model analytically or otherwise quickly.
However, if that is not the case, then another possible approximation is to
linearize with respect to the initial point, that is,
a.x.t//  a.x.tk 1// C Ax.x.tk 1// .x.t/   x.tk 1//:
(4.67)
This leads to the following kind of approximation.
Theorem 4.18 (Linearization with respect to initial condition). Suppose
that we approximate
dx.t/
dt
D a.x.t// C L w.t/
(4.68)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.5 Covariance Approximation via Constant Gradients
65
as
dx.t/
dt
 a.x.tk 1// C Ax.x.tk 1// .x.t/   x.tk 1// C Lw.t/:
(4.69)
The discretized model is then
xk D xk 1 C
 Z tk 1
0
exp.Ax.xk 1/ s/ ds
!
a.xk 1/ C qk 1
D xk 1 C
 1
X
iD1
t i
k 1 Ax.xk 1/i 1
iŠ
!
a.xk 1/
„
ƒ‚
…
fk 1.xk 1/
Cqk 1;
(4.70)
where qk 1  N.0; Qk 1.xk 1// and
Qk 1.xk 1/ D
Z tk 1
0
exp.Ax.xk 1/ s/ L Qc LT exp.Ax.xk 1/ s/T ds:
(4.71)
Proof
See Exercise 4.7.
As a sanity check, we note that Theorem 4.18 yields the same discretized
model as Theorem 4.3 when a.x.tk 1// D F x.tk 1/, since that implies
that Ax.xk 1/ D F, for which the deterministic part of the discretization
simpliﬁes to
xk 1 C
 1
X
iD1
ti
k 1Ax.xk 1/i 1
iŠ
!
a.xk 1/ D exp.F tk 1/ xk 1:
(4.72)
The method above has the advantage that it provides a tractable approxima-
tion for the covariance as well. However, the approximation of the deter-
ministic part can be quite rough as it is based on linearization at the initial
point only. It can also be cumbersome to compute. Now a promising idea
is to combine the approximations, which is discussed in the next section.
4.5 Covariance Approximation via Constant Gradients
Recall that we are aiming at ﬁnding discretizations of the form
xk D fk 1.xk 1/ C qk 1;
qk 1  N.0; Qk 1/;
(4.73)
where both the deterministic part fk 1.xk 1/ and the noise covariance
Qk 1 should be as accurate as possible. The covariance should preferably

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
66
Discretization of Continuous-Time Dynamic Models
also be non-singular and independent of xk 1. In the previous section we
saw that by using a continuous-time linearization with respect to the mean,
a.x.t//  a.m.t// C Ax.m.t// .x.t/   m.t// ;
(4.74)
we can often obtain good approximations to the deterministic part
fk 1.xk 1/ by solving the mean differential equation in closed form. On
the other hand, by linearizing with respect to the initial point,
a.x.t//  a.xk 1/ C Ax.xk 1/ .x.t/   xk 1/ ;
(4.75)
we obtained a slightly inferior approximation for the deterministic part but
with the advantage that the covariance approximation was tractable. To get
the beneﬁts of both of the approaches, it is possible to use a linearization
of the form
a.x.t//  a.m.t// C Ax.xk 1/ .x.t/   m.t//;
(4.76)
where Ax.xk 1/ is now a constant matrix. This linearization yields the
same expression for m.t/ as the linearization with respect to the mean, and
thus fk 1./, as the linearization in (4.50).
Theorem 4.19 (Discretization with a constant gradient). Suppose that we
approximate the dynamic model SDE by
dx.t/
dt
 a.m.t// C Ax.xk 1/ .x.t/   m.t// C L w.t/;
(4.77)
with the initial condition x.tk 1/ D xk 1. The mean m.t/ is still the
solution to
dm.t/
dt
D a.m.t//
(4.78)
with m.tk 1/ D xk 1, and the covariance is given by
P.tk/ D
Z tk 1
0
exp.Ax.xk 1/ s/ L Qc LT exp.Ax.xk 1/ s/T ds:
(4.79)
The discretization can then be formed by putting fk 1.xk 1/ D m.tk/ and
Qk 1.xk 1/ D P.tk/.
Proof
See Exercise 4.9.
Although the above theorem provides approximations for the mean
and covariance in a form that can be easily numerically approximated,
one practical challenge is that the covariance expressions explicitly

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.5 Covariance Approximation via Constant Gradients
67
depend on the value of xk 1. That is, the dynamic model takes the form
p.xk j xk 1/ D N.xk j fk 1.xk 1/; Qk 1.xk 1//. Some of the ﬁlters
(and smoothers) presented later can easily handle models of this type, such
as Gaussian ﬁlters that use the conditional moments formulation (see, e.g.,
Algorithm 9.22) and the particle ﬁlters (see, e.g., Algorithm 11.8). Still,
to obtain simpler ﬁlters and smoothers, we would prefer the covariance
not to depend on the state. One simple solution is to introduce additional
approximations and evaluate the Jacobian Ax./ at some ﬁxed point, other
than xk 1.
In fact, the aforementioned procedure can be combined with an Euler–
Maruyama approximation for fk 1.xk 1/. Thus we get the following pro-
cedure.
Algorithm 4.20 (Additive noise approximation). An additive noise ap-
proximation to the SDE in Equation (4.21) can be obtained by ﬁrst forming,
for example, the Euler–Maruyama approximation or continuous-time lin-
earization approximation for fk 1.xk 1/. Then the noise can be approxi-
mated by linearizing the model at some ﬁxed point Ox and by approximating
the covariance by the covariance of
dx.t/
dt
D Ax.Ox/ x.t/ C L w.t/;
(4.80)
which leads to the approximation
Qk 1 
Z tk 1
0
exp.Ax.Ox/ s/ L Qc LT exp.Ax.Ox/ s/T ds:
(4.81)
The covariance resulting from the above is usually non-singular even in
the case when the Euler–Maruyama method gives a singular covariance.
Furthermore, it is independent of xk 1 since we use a ﬁxed linearization
point Ox. We are free to select any linearization point, for example, the
origin. However, in practice, it is often desirable to linearize a.xk/ close to
the true value of the state, and it may therefore be better to use, for instance,
the posterior mean computed by a ﬁlter as linearization point, Ox D mk.
The approximation in Algorithm 4.20 can often be made even simpler by
only linearizing with respect to some variables and leaving others constant.
This is illustrated in the following example.
Example 4.21 (Additive noise approximation for pendulum model). The
noisy pendulum model in Example 4.7 can be linearized around Ox D
 0; 0


This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
68
Discretization of Continuous-Time Dynamic Models
to give
a.x/ D

x2
 g sin.x1/


 0
1
 g
0

„
ƒ‚
…
Ax.Ox/
x1
x2

;
(4.82)
for which the approximate process noise given by Equation (4.81) is con-
stant. Another way is just to linearize with respect to x2 and leave x1 ﬁxed
to the origin, which gives an even simpler approximation:
a.x/ D

x2
 g sin.x1/


0
1
0
0
 x1
x2

:
(4.83)
With this approximation, we get a closed form covariance approximation
via Equation (4.18):
Qk 1 D qc
 
t3
k 1
3
t2
k 1
2
t2
k 1
2
tk 1
!
:
(4.84)
Sometimes it is not possible to form a simple approximation by lin-
earization at a single point. In that case it is sometimes possible to ﬁrst
form an approximation via linearization at xk 1 and then approximating it.
This is demonstrated in the following example.
Example 4.22 (Constant gradient covariance for polar CT model). The
expression for the covariance for the polar coordinated turn model in Ex-
ample 4.10, by a constant gradient approximation at xk 1, is given in Ap-
pendix A.8. By setting the speed to zero, approximating the cross-terms in-
volving sines and cosines to zero, and by dominating squares of sines and
cosines by 1, we obtain the following approximation to the covariance:
Qk 1 D
0
BBBBBB@
qc
s
t3
k 1
3
0
0
0
0
0
qc
s
t3
k 1
3
0
0
0
0
0
qc
s tk 1
0
0
0
0
0
qc
!
t3
k 1
3
qc
!
t2
k 1
2
0
0
0
qc
!
t2
k 1
2
qc
! tk 1
1
CCCCCCA
;
(4.85)
where qc
s and qc
! are the spectral densities of the white noises driving the
speed and angular velocity, respectively.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
4.6 Fast Sampling
69
Figure 4.7 The ﬁgure illustrates a possible relation between the
sequences .t0; t1; : : : / and .0; 1; : : : / when n1 D n2 D 3. We
normally collect measurements at 0 D t0, 3 D t1 and 6 D t2,
but not at the intermediate times 1; 2; 4, and 5.
4.6 Fast Sampling
As long as the sampling period tk 1 is small, even the Euler–Maruyama
method in Theorem 4.8 yields an accurate discrete-time dynamic model.
We have presented several techniques that aim to also perform accurate
discretization for larger sampling periods. However, we limited our discus-
sion to models that approximate p.x.tk/ j x.tk 1// as Gaussian in a single
step, which may be a poor approximation for large sampling periods. One
way to improve the discretization is to use high order SDE approximations,
such as Itˆo–Taylor expansions (see Kloeden and Platen, 1999; S¨arkk¨a and
Solin, 2019), which unfortunately often leads to overly complicated solu-
tions. An alternative strategy is to reformulate the problem such that we
sample the continuous-time state sequence more frequently, to reduce the
sampling period. We here refer to this as a fast sampling approach. In this
formulation, it is easy to obtain an accurate (Gaussian) dynamic model, but
the reduced sampling period may instead result in increased complexity for
the discrete-time ﬁltering and smoothing algorithms.
One way to formalize this strategy is by introducing additional nk  1 sampling times i between tk 1 and tk such that i D tk when i D
Pk
j D1 nk and deﬁning the discrete time sequence as xk D x.k/. This is
illustrated in Figure 4.7. This approach yields a different state sequence
because we sample the continuous time state sequence more frequently.
Since we are still only collecting measurements at t1; t2; : : : , fast sampling
means that there are nk discrete time steps between every measurement that
we collect. In spite of this, the ﬁlters, predictors, and smoothers presented
in this book can still be applied directly, with the minor difference that we
skip the update step when we do not have a measurement. By computing
the posterior distribution of x0 D x.0/; x1 D x.1/; : : : , we also obtain
the posterior distribution at the original sampling times x.t0/; x.t1/; : : :

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
70
Discretization of Continuous-Time Dynamic Models
since we have merely introduced new sampling times between the original
ones.
Fast sampling is closely related to the numerical solution of the SDE in
Algorithm 4.12 since we again split the time interval Œtk 1; tk into subin-
tervals and approximate a.x.t// differently in each interval. If we use the
Euler–Maruyama method with the faster sampling rate, we implicitly as-
sume that
a.x.t//  a.x.k 1//;
t 2 Œk 1; k/;
(4.86)
but we now only use this approximation in a time interval of length
k 1 D k   k 1. An important special case is when the sampling
time is constant, tk D t, and we further split tk into n equally
long subintervals such that also k D  is the same for all k and
 D t=n. By sampling faster, the Euler–Maruyama method uses (4.86)
in an interval that is 1=n of the original sampling period, which leads to
more accurate approximations.
4.7 Exercises
4.1
Use Algorithm 4.12 to sample from a scalar Wiener process
dx.t/
dt
D w.t/;
(4.87)
where w.t/ has the spectral density qc D 1. Use  D 0:01 to generate and
illustrate N D 3 samples in the interval t 2 Œ0; 4 when x.0/ D 0.
4.2
In continuous time, a d-dimensional constant acceleration (CA) model can
be described as
dx.t/
dt
D
0
@
0
I
0
0
0
I
0
0
0
1
A x.t/ C
0
@
0
0
I
1
A w.t/;
(4.88)
where the ﬁrst d elements in x.t/ represent the position of an object, the
next d elements represent the velocity, and the ﬁnal d elements are the
acceleration. Use Theorem 4.3 to obtain the discrete-time CA model. For
simplicity, you can assume that the spectral density of the noise is Qc D
2I.
4.3
Discretize the CA model in Exercise 4.2 using the Euler–Maruyama method
in Theorem 4.8, and compare the result to the exact discretization obtained
in Exercise 4.2.
4.4
In order to build intuition for when different models are useful, it is helpful
to observe sequences sampled from candidate models. Generate sequences

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
71
from the scalar random walk (RW) model given in Equation (4.15), the con-
stant velocity (CV) model described in Example 4.5, and the CA model de-
scribed in Exercise 4.2. Plot the positions for sequences generated using the
RW and CV models, and the velocities for sequences generated using the
CV and CA models. To facilitate the comparison, adjust the parameters such
that the sequences that you plot jointly take values in similar ranges. Com-
pare and comment on the roughness of the different sequences.
4.5
Derive the expressions for fk 1.xk 1/ for the Cartesian coordinated turn
model given in Example 4.16. Note that fk 1.xk 1/ D m.tk/, where m.tk/
is the solution to the dynamic equation without noise.
4.6
Derive the limit for fk 1.xk 1/ when !k 1 ! 0 for the Cartesian coordi-
nated turn model given in Example 4.16.
4.7
Prove Theorem 4.18. Hint: You can obtain the discrete-time model using
Lemma A.9 and simplify the expression by recalling the deﬁnition of the
matrix exponential.
4.8
An interesting special case of Theorem 4.13 is when a.x/ D F x, which
implies that Ax.x/ D F. It then holds that a.m.t// D Ax.m.t// m.t/, and
(4.51) then simpliﬁes to (4.5). For such linear and time-invariant systems,
Theorem 4.3 speciﬁes that
m.t/ D exp.F.t   tk 1// x.tk 1/;
P.t/ D
Z t tk 1
0
exp .F s/ L Qc LT exp .F s/T ds:
(4.89)
Verify that the moments in Equation (4.89) satisfy the description in Theo-
rem 4.13 when we have a scalar state variable x.t/. Note that P.t/ in (4.89)
has a simple closed form solution when all variables are scalar.
4.9
Prove Theorem 4.19.
4.10
Write down the expression for the process noise covariance Qk 1.xk 1/
resulting from the method in Theorem 4.19 for the bicycle model considered
in Example 4.17. Also use the discretized model to simulate trajectories from
the dynamics.
4.11
Show that using the additive noise approximation in Algorithm 4.20 on the
Cartesian coordinated turn model in Equation (4.60) at origin leads to the
following process noise covariance:
Qk 1 D
0
BBBBBBB@
qc
1
t3
k 1
3
0
qc
1
t2
k 1
2
0
0
0
qc
2
t3
k 1
3
0
qc
2
t2
k 1
2
0
qc
1
t2
k 1
2
0
qc
1 tk 1
00
0
qc
2
t2
k 1
2
0
qc
2 tk 1
0
0
0
0
0
qc
3 tk 1
1
CCCCCCCA
;
(4.90)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
72
Discretization of Continuous-Time Dynamic Models
where the spectral densities of white noises w1.t/, w2.t/, and w3.t/ are qc
1,
qc
2, and qc
3, respectively.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5
Modeling with State Space Models
In the previous chapter, we discussed the discretization of continuous-time
dynamic models as a strategy to construct discrete-time dynamic models
that describe the transition density, p.xk j xk 1/, for a probabilistic state
space model. However, a probabilistic state space model also requires a
measurement model, p.yk j xk/, which describes the conditional distribu-
tion of a measurement yk given a state xk at time step k. In this chapter,
we discuss the construction of measurement models in general and provide
speciﬁc examples of models that we can combine with the dynamic mod-
els introduced in the previous chapter. Finally, we present two more model
families that we can represent as state space models.
5.1 Linear and Non-Linear Gaussian Models
In Chapter 4 we presented various ways to construct dynamic models of
the form
xk D f.xk 1/ C qk 1;
(5.1)
where qk 1  N.0; Qk 1/ is Gaussian process noise. In general, the dy-
namic function f./ may depend on the time step k   1, and the covariance
Qk 1 may depend on the state xk 1, but here we omit both of these depen-
dencies from our notation.
The model in Equation (5.1) thus corresponds to a conditional distribu-
tion model
p.xk j xk 1/ D N.xk j f.xk 1/; Qk 1/:
(5.2)
In reality, we often cannot observe the states xk directly, but we only get
some indirect, noisy observations yk of them. The aim is then to estimate
the states from the measurements, which is a task that can be accom-
plished by using Bayesian ﬁlters and smoothers (such as Kalman ﬁlters
73

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
74
Modeling with State Space Models
and Rauch–Tung–Striebel smoothers), which we will encounter in the sub-
sequent chapters.
We can often express the measurement model as a functional relation
yk D h.xk/ C rk;
rk  N.0; Rk/;
(5.3)
which implies that we have
p.yk j xk/ D N.yk j h.xk/; Rk/:
(5.4)
Even more generally, we may have yk D h.xk; rk/, and the noise rk
may also be non-Gaussian, but the special case in Equation (5.3) is more
common in the literature. We will, however, come back to these extensions
in the next section.
There is a wide range of sensors, including radars, speedometers,
gyroscopes, global navigation satellite systems (GNSSs), radars, ac-
celerometers, thermometers, and barometers. The functional form of h./,
and whether the function is linear or non-linear, depend on what the
sensor measures and how the measurement is related to the chosen state
representation. Linear models are common when the measurements are
noisy observations of some state variables. Non-linear models may appear,
for example, if the state variables need to be converted into a different
coordinate system to enable a simple relation to the measurements.
Let us start with a linear measurement model for a car.
Example 5.1 (Position measurement model for a car). Recall that in Ex-
ample 4.6 we derived a discrete-time linear dynamic model for a car of the
form xk D A xk 1 C qk 1, where the state x D
 x1; x2; x3; x4

contains
the position variables .x1; x2/ and the velocity vector .x3; x4/. Assume that
the position of the car .x1; x2/ is measured and that the measurements are
corrupted by independent Gaussian measurement noises r1;k  N.0; 2
1/
and r2;k  N.0; 2
2/ (see Figure 5.1):
y1;k D x1;k C r1;k;
y2;k D x2;k C r2;k:
(5.5)
The measurement model can now be written as
yk D H xk C rk;
H D
1
0
0
0
0
1
0
0

:
(5.6)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.1 Linear and Non-Linear Gaussian Models
75
.y1; y2/
Figure 5.1 Illustration of car’s measurement model. The
measurements .y1; y2/ are modeled as noise-corrupted
observations of the car’s position.
The dynamic and measurement models of the car now form a linear Gaus-
sian state space model
xk D A xk 1 C qk 1;
yk D H xk C rk;
where qk 1  N.0; Q/ and rk  N.0; R/ with R D diag.2
1; 2
2/. Because
this model is linear and Gaussian, the state of the car can be estimated from
the noisy measurements using the Kalman ﬁlter.
Suppose that we instead use the non-linear polar coordinated turn model
in Example 4.10 as the dynamic model, whose discrete-time versions were
considered in Examples 4.11 and 4.15. We would then get a measurement
model
yk D
1
0
0
0
0
0
1
0
0
0

xk C rk;
(5.7)
as the state in that model is deﬁned as x D
 x1; x2; s; '; !

, where .x1; x2/
is the position, s is the speed, ' is the direction, and ! is the angular
velocity. This then leads to a model that has non-linear dynamics but a
linear measurement model:
xk D f.xk 1/ C qk 1;
yk D H xk C rk;

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
76
Modeling with State Space Models
where it is common to assume that qk 1 and rk are again Gaussian. In this
case, the estimation of the state could be implemented using, for example,
the extended Kalman ﬁlter (EKF), the unscented Kalman ﬁlter (UKF), or a
particle ﬁlter.
Non-linear measurement models arise when we do not directly measure
state variables, but the measurement is a non-linear function of state com-
ponents, as illustrated in the following pendulum example.
Example 5.2 (Measurement model for noisy pendulum). In Example 4.9
we formed a discrete-time non-linear dynamic model for a pendulum with
the state x D
 x1; x2

, where x1 D ˛ is the angular position of the
pendulum, and x2 D d˛= dt is the angular velocity. We could then, for
example, consider measuring the angular position of the pendulum, which
leads to the linear Gaussian measurement model
yk D ˛.tk/ C noise:
(5.8)
However, if we measure only the horizontal position of the pendulum, we
get a non-linear measurement model
yk D sin.˛.tk// C rk;
(5.9)
where rk is the measurement noise, which we can model, for example, as
a Gaussian rk  N.0; Rk/. If we combine the dynamic and measurement
models together, we get a model of the general form
xk D f.xk 1/ C qk 1;
yk D h.xk/ C rk;
(5.10)
where yk is the vector of measurements, qk 1  N.0; Qk 1/, and rk 
N.0; Rk/. Estimation of the pendulum state can be now implemented using,
for example, the extended Kalman ﬁlter (EKF), unscented Kalman ﬁlter
(UKF), or particle ﬁlter.
Non-linear measurement models also arise, for example, when we mea-
sure range and bearing, which is a type of measurement that a radar pro-
duces. This is illustrated in the following example.
Example 5.3 (Radar measurements). Let yk be an observation from a
radar sensor, which provides a noisy observation of the range (distance)
and bearing (angle) to the position of an object in 2D. The sensor is lo-
cated at the origin, and we model the state dynamics using a coordinated
turn model in Example 4.10 (with discretizations in Examples 4.11 and
4.15) such that the state is represented by x D
 x1; x2; s; '; !

, where

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.1 Linear and Non-Linear Gaussian Models
77
.x1; x2/ is the position, s is the speed, ' is the direction, and ! is the angu-
lar velocity. To model the measurement, we can express range and bearing
as a function of xk plus noise as follows:
yk D
0
@
q
x2
1;k C x2
2;k
arctan

x2;k
x1;k

1
A
„
ƒ‚
…
h.xk/
C
r1;k
r2;k

„ ƒ‚ …
rk
:
(5.11)
The measurement model above would be identical if we modeled the dy-
namics using the constant velocity model in Example 4.6.
In target tracking scenarios, we often have multiple sensors (such as
radars) instead of a single one. In this case, the measurements from the
multiple sensors can be simply stacked into a larger-dimensional measure-
ment vector as illustrated in the following.
Example 5.4 (Multiple range measurements). Let us assume that we have
four radars located in positions .s1;x; s1;y/, . . . , .s4;x; s4;y/, and they mea-
sure range to the target whose position coordinates are given by the ﬁrst
two elements .x1; x2/ of the state x. Then the measurement model can be
written as
yk D
0
BB@
p
.x1;k   s1;x/2 C .x2;k   s1;y/2
p
.x1;k   s2;x/2 C .x2;k   s2;y/2
p
.x1;k   s3;x/2 C .x2;k   s3;y/2
p
.x1;k   s4;x/2 C .x2;k   s4;y/2
1
CCA
„
ƒ‚
…
h.xk/
C
0
BB@
r1;k
r2;k
r3;k
r4;k
1
CCA
„ ƒ‚ …
rk
:
(5.12)
Similarly we could stack a combination of range and bearings measure-
ments into a single measurement vector.
When the radar measurement model in Example 5.3 or range measure-
ment model in Example 5.4 is combined with a dynamic model, this leads
to a model of the form
xk D f.xk 1/ C qk 1;
yk D h.xk/ C rk;
(5.13)
where we can process the measurements yk to obtain estimates of the state
by using, for example, the extended Kalman ﬁlter (EKF) or one of the other
non-linear ﬁlters or smoothers that we encounter later in this book.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
78
Modeling with State Space Models
5.2 Non-Gaussian Measurement Models
In the previous section we discussed models of the form
p.yk j xk/ D N.yk j h.xk/; Rk/;
(5.14)
which can also be expressed as yk D h.xk/ C rk where rk  N.0; Rk/. In
other words, we have a possibly non-linear measurement function h.xk/
that describes the conditional mean EŒyk j xk, and we have additive Gaus-
sian noise rk. Even though this is a commonly used model, there are many
situations where the noise cannot be accurately modeled as Gaussian.
One distribution that is often used to model the noise is the Student’s
t-distribution. The n-dimensional Student’s t-distribution with  degrees of
freedom has the form (Kotz and Nadarajah, 2004; Roth, 2012)
St.y j ; R; /
D
.. C n/=2/
.=2/ n=2 n=2 jRj1=2

1 C 1
 .y   /T R 1 .y   /
 .Cn/=2
;
(5.15)
where .z/ D
R 1
0 xz 1 exp. x/ dx is the gamma function. The Student’s
t-distribution has heavier tails than the Gaussian distribution, that is, more
of its probability is far away from the mean (see Figure 5.2). Due to the
heavy tails, the model expects some measurements with larger errors than
the typical ones; such measurements are often referred to as outliers, and
the model is therefore more robust to outliers than a Gaussian model.
Using this distribution for the additive noise, we can now form a more
robust measurement model as
p.yk j xk/ D St.yk j h.xk/; R; /;
(5.16)
which thus sets the mean to be equal to the sensor model h.xk/. The other
parameters R and  control the covariance and heaviness of the tails of the
distribution. For example, the covariance is given as

 2 R, which is only
ﬁnite when  > 2.
Example 5.5 (Robust measurement model for a car). A more robust mea-
surement model for the car considered in Example 5.1 can be constructed
by replacing the Gaussian noise model with a Student’s t-distribution
model:
p.yk j xk/ D St.yk j H xk; R; /:
(5.17)
In this case the Kalman ﬁlter is no longer applicable, though it is possible
to use Student’s t extensions of the Kalman ﬁlter on it (see, e.g., Roth et al.,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.2 Non-Gaussian Measurement Models
79
-10
-5
0
5
10
 y
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Density
Gaussian
Student's t, =1
Student's t, =4
Figure 5.2 An illustration of three scalar densities with mean
 D 1 and parameter R D 1: one Gaussian density N.y j ; R/
and two Student’s t-distributions, St.y j ; R; /, with  D 1 and
 D 4, respectively.
2013), and both the generalized Gaussian ﬁlters discussed in Chapters 9
and 10, and the particle ﬁlters presented in Chapter 11, are also applicable
to this kind of model.
The Student’s t-distribution is also closely related to Gaussian distribu-
tions, because if we have
u  Ga.=2; =2/;
y  N.; R=u/;
(5.18)
where Ga.; / is the gamma distribution, then the marginal distribution
of y is St.; R; / (see, e.g., Roth, 2012). Thus in this sense a Student’s
t-distribution can be seen as a Gaussian distribution with uncertainty in
the noise covariance modeled by scaling R ! R=u with an unobserved
gamma-distributed random variable u. This in turn makes it closely con-
nected with Kalman ﬁltering with unknown variance (see, e.g., S¨arkk¨a and
Nummenmaa, 2009).
Another way to model outliers is to state that we obtain a regular mea-
surement with some probability  2 Œ0; 1 and an outlier with probability
1   . We can then obtain a measurement model by introducing a sepa-
rate model for the outliers. That model could be a Gaussian density with a

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
80
Modeling with State Space Models
-10
-5
0
5
10
 y
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Density
Gaussian
Uniform
Mixture
Figure 5.3 Here we show a Gaussian density with mean  D 1
and covariance R D 1, a uniform density U.y j V/ where
V D Œ 7; 9, and a mixture of densities, as in Equation 5.21, with
 D 0:9.
larger covariance, or it could be a uniform density over some region V:
U.yk j V/ D
(
1
V ;
if yk 2 V;
0;
otherwise,
(5.19)
where V is the volume of V. The complete measurement model then takes
the form
p.yk j xk/ D
(
N.yk j h.xk/; Rk/;
with probability ;
U.yk j V/;
with probability 1   ;
(5.20)
where  2 Œ0; 1 is the detection probability. The density in Equation 5.20
can also be expressed as a mixture model
p.yk j xk/ D .1   / U.yk j V/ C  N.yk j h.xk/; Rk/:
(5.21)
We illustrate this density in Figure 5.3 in a scalar setting that resembles the
example shown in Figure 5.2.
Alternatively, this mixture model can be seen as a model with a
Bernoulli-distributed binary indicator variable ck  Be./ taking value 1
with probability  and value 0 with probability 1    (see Equation (5.26)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.2 Non-Gaussian Measurement Models
81
below). In this formulation, the model takes the form
p.ck/ D Be.ck j /;
p.yk j xk; ck/ D
(
N.yk j h.xk/; Rk/;
if ck D 1;
U.yk j V/;
if ck D 0;
(5.22)
where ck is unobserved.
Example 5.6 (Clutter model for pendulum). In Example 5.2 we con-
structed a non-linear Gaussian measurement model for a pendulum. We
can now allow for outlier measurements in the model by replacing it with
p.yk j xk/ D
(
N.yk j sin.˛k/; Rk/;
with probability ;
U.yk j Œ L; L/;
with probability 1   
(5.23)
for some suitable constant L. The state estimation problem in this kind of
model can no longer be done with a method based on an extended Kalman
ﬁlter, but we can still use a general Gaussian ﬁlter or a particle ﬁlter.
Yet another useful model is a Poisson distribution
Po.y j / D exp. / y
yŠ ;
(5.24)
which can be used to model counts of events y D 0; 1; 2; : : : . Because
the Poisson parameter  must be positive, we typically form the model via
exp-transformation as  D 0 exp.u/, where u is a variable that can take
positive and negative values, and 0 is a constant. This leads to measure-
ment models of the form
p.yk j xk/ D Po.yk j 0 exp.h.xk///;
(5.25)
where h.xk/ is the sensor model that maps the state to the log-intensity
relative to 0. State-estimation problems with this kind of measurement
model can be tackled with either particle ﬁlters or generalized Gaussian
ﬁlters.
In classiﬁcation problems arising in machine learning (see, e.g., Ras-
mussen and Williams, 2006; Bishop, 2006), the Bernoulli distribution can
be used as a measurement model:
Be.y j / D y .1   /1 y D
(
;
if y D 1;
1   ;
if y D 0;
(5.26)
where y 2 f0; 1g. Because we need to have  2 Œ0; 1, the model is typi-
cally expressed in terms of a transformation, such as a standard cumulative

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
82
Modeling with State Space Models
distribution function or a standard logistic transformation, of a real-valued
variable:
p.yk D 1 j xk/ D ˆ.h.xk//; or
p.yk D 1 j xk/ D
1
1 C exp. h.xk//;
(5.27)
where ˆ.z/ D
R z
 1 N.x j 0; 1/ dx. The corresponding state-estimation
problem can then be approached by using particle ﬁlters or generalized
Gaussian ﬁlters (cf. Garc´ıa-Fern´andez et al., 2019).
5.3 Measurements as Inputs
For practical reasons, it is sometimes useful to view some of the observa-
tions as inputs to the dynamic model. The objective is generally to sim-
plify the problem and to reduce the number of state variables, and, when
applicable, this technique often yields good performance as long as the
measurement noise is small. For notation, we write the dynamic model as
xk D f.xk 1; uk 1/ C qk 1;
(5.28)
where uk 1 is a measured signal that we describe as a known input to the
system.
Example 5.7 (Gyroscope measurement as input). Let us recall the dynamic
model function corresponding to the polar coordinated turn model that we
considered in Example 4.15:
f.xk 1/ D
0
BBBB@
x1;k 1 C 2sk 1
!k 1 sin. tk 1 !k 1
2
/ cos.'k 1 C tk 1 !k 1
2
/
x2;k 1 C 2sk 1
!k 1 sin. tk 1 !k 1
2
/ sin.'k 1 C tk 1 !k 1
2
/
sk 1
'k 1 C !k 1 tk 1
!k 1
1
CCCCA
;
(5.29)
where the state is xk 1 D
 x1;k 1; x2;k 1; sk 1; 'k 1; !k 1

. If we now
have a gyroscope sensor available, then it gives a direct measurement !gyro
k
of the angular velocity !k. It is possible to model this as a noisy measure-
ment of !k:
!gyro
k
D !k C rk D
 0
0
0
0
1

xk C rk;
(5.30)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.4 Linear-in-Parameters Models in State Space Form
83
where rk is measurement noise. However, we can also put uk 1 D !gyro
k 1
and redeﬁne the dynamic model function as
f.xk 1; uk 1/ D
0
BB@
x1;k 1C 2sk 1
uk 1 sin. tk 1uk 1
2
/ cos.'k 1C tk 1uk 1
2
/
x2;k 1C 2sk 1
uk 1 sin. tk 1uk 1
2
/ sin.'k 1C tk 1uk 1
2
/
sk 1
'k 1 C uk 1 tk 1
1
CCA ;
(5.31)
where the state is now xk 1 D
 x1;k 1; x2;k 1; sk 1; 'k 1

, and !gyro
k 1 is
fed in as the input signal uk 1.
Viewing the measurements as input can be used in many contexts and
for many sensors. For instance, for the above polar coordinated turn model,
we could also view measurements from a speedometer as inputs instead of
including sk as part of the state (see Exercise 5.4). However, it should be
noted that the simpliﬁcations that this gives rise to may come at the price
of reduced performance.
5.4 Linear-in-Parameters Models in State Space Form
In Chapter 3 we saw that a simple one-dimensional linear regression prob-
lem can be converted into a state space model that can be solved using
the Kalman ﬁlter. In an similar manner, more general linear-in-parameters
models can be converted into state space models. This is demonstrated in
the following example.
Example 5.8 (Linear-in-parameters regression model I). Consider the fol-
lowing parametric model:
yk D w0 C w1 g1.tk/ C    C wd gd.tk/ C "k;
(5.32)
where g1.tk/; : : : ; gd.tk/ are some given functions of time tk, and "k is
Gaussian measurement noise. The problem of determining the weights
w0; : : : ; wd from a set of measurements f.t1; y1/; : : : ; .tT ; yT /g can be
converted into a Kalman ﬁltering problem as follows.
Introducing the variables Hk D .1 g1.tk/    gd.tk// and xk D x D
.w0; w1; : : : ; wd/, we can rewrite the model as a linear Gaussian state
space model:
xk D xk 1;
yk D Hk xk C "k:
(5.33)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
84
Modeling with State Space Models
Because the model is a linear Gaussian state space model, we can now use
a linear Kalman ﬁlter to estimate the parameters.
The presented strategy is not limited to functions g1; : : : ; gd that are
explicit functions of time. Instead, they can be functions of arbitrary re-
gressors, as illustrated in the following example.
Example 5.9 (Linear-in-parameters regression model II). Consider the fol-
lowing parametric model:
yk D w0 C w1 g1.sk/ C    C wd gd.sk/ C "k;
(5.34)
where g1.s/; : : : ; gd.s/ are some given functions of a the variable s 2 Rn,
and where the weights w0; : : : ; wd are to be estimated from a sequence of
measurements ..s1; y1/; : : : ; .sT ; yT //. Similarly to the previous example,
we can convert the problem into a linear Gaussian state space model by
deﬁning Hk D .1 g1.sk/    gd.sk// and xk D x D .w0; w1; : : : ; wd/,
and then solve for xk using a Kalman ﬁlter.
Linearity of the state space models in the above examples resulted from
the property that the models are linear in their parameters. Generalized
linear models involving non-linear link functions will lead to non-linear
state space models, as is illustrated in the following example.
Example 5.10 (Generalized linear model). An example of a generalized
linear model is
yk D g.w0 C wT sk/ C "k;
(5.35)
where g./ is some given non-linear link function, and sk is a vector of
regressors. If we deﬁne the state as x D .w0; w/ and hk.x/ , g.w0 C
wT sk/, we get the following non-linear Gaussian state space model:
xk D xk 1;
yk D hk.xk/ C "k:
(5.36)
Because the state space model is non-linear, instead of the linear Kalman
ﬁlter, we need to use non-linear Kalman ﬁlters, such as the extended
Kalman ﬁlter (EKF) or the unscented Kalman ﬁlter (UKF), to cope with
the non-linearity.
One general class of non-linear regression models, which can be con-
verted into state space models using an analogous approach to the above,
is the multi-layer perceptron (MLP) (see, e.g., Bishop, 2006), also known
as a neural network. Using a non-linear Kalman ﬁlter is indeed one way

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.4 Linear-in-Parameters Models in State Space Form
85
to train (to estimate the parameters of) such models (Haykin, 2001), even
though it remains an unconventional technique to train neural networks.
However, non-linear regression models of this kind arise in various others
contexts as well.
Many sensors have an unknown offset b, also known as a bias, such that
we observe, say,
yk D h.xk/ C b C rk;
rk  N.0; Rk/;
(5.37)
instead of yk D hk.xk/ C rk. One way to handle an unknown bias is to
include it in the state vector. That is, we can introduce a new state vector
Qxk D .xk; bk/ where the original state is augmented with the bias bk D
bk 1. The model then becomes a standard state estimation problem with
the redeﬁned measurement model function
Qh.Qxk/ D h.xk/ C bk:
(5.38)
Instead of the singular dynamics, bk D bk 1, we can include a small noise
in the dynamics of the bias bk D bk 1 C qb
k 1 to allow for slow drifting of
the bias.
Example 5.11 (Including bias in state vector). Consider a constant ve-
locity model (see Example 4.5) with xk D
 x1;k; x2;k

, where x1;k is the
position and x2;k is the velocity. Suppose that we observe
y1;k
y2;k

D
x1;k
x2;k

C
 0
bk

C
r1;k
r2;k

;
(5.39)
where bk is a bias in the velocity measurement that drifts slowly with time.
We can then redeﬁne Qxk D
 x1;k; x2;k; bk

as a state for which (5.39) is a
measurement model without any unknown parameters (see Exercise 5.6).
We can then introduce the dynamic model
0
@
x1;k
x2;k
bk
1
A D
0
@
1
tk 1
0
0
1
0
0
0
1
1
A
0
@
x1;k 1
x2;k 1
bk 1
1
A C
0
@
q1;k 1
q2;k 1
q3;k 1
1
A ;
(5.40)
where qk 1 D
 q1;k 1; q2;k 1; q3;k 1

 N.0; Qk 1/, which leads to a
complete probabilistic state space model that enables us to estimate bk
jointly with x1;k and x2;k. We note that (5.40) is a constant velocity model
for .x1;k; x2;k/ and a random walk model for bk, and we can use Exam-
ples 4.4 and 4.5 to ﬁnd a suitable structure for Qk 1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
86
Modeling with State Space Models
5.5 Autoregressive Models
In digital signal processing (DSP), an important class of models is linear
signal models, such as autoregressive (AR) models, moving average (MA)
models, autoregressive moving average models (ARMA), and their gener-
alizations (see, e.g., Hayes, 1996). In those models one is often interested
in performing adaptive ﬁltering, which refers to the methodology where
the parameters of the signal model are estimated from data. These kinds of
adaptive ﬁltering problems can often be formulated using a linear Gaussian
state space model (and solved using a Kalman ﬁlter), as illustrated in the
following example.
Example 5.12 (Autoregressive (AR) model). An autoregressive (AR)
model of order d has the form
yk D w1 yk 1 C    C wd yk d C "k;
(5.41)
where "k is a white Gaussian noise process. The problem of adaptive ﬁl-
tering is to estimate the weights w1; : : : ; wd given the observed signal
y1; y2; y3; : : : . If we let Hk D .yk 1    yk d/ and deﬁne the state as
xk D .w1; : : : ; wd/, we get a linear Gaussian state space model
xk D xk 1;
yk D Hk xk C "k:
(5.42)
Thus the adaptive ﬁltering problem can be solved with a linear Kalman
ﬁlter.
The classical algorithm for adaptive ﬁltering is called the least mean
squares (LMS) algorithm, and it can be interpreted as an approximate ver-
sion of the above Kalman ﬁlter. However, in LMS algorithms it is common
to allow the model to change over time, which in the state space context
corresponds to setting up a dynamic model for the model parameters. This
kind of model is illustrated in the next example.
Example 5.13 (Time-varying autoregressive (TVAR) model). In a time-
varying autoregressive (TVAR) model, the weights are assumed to depend
on the time step k as
yk D w1;k yk 1 C    C wd;k yk d C "k:
(5.43)
A typical model for the time dependence of weights is the random walk
model
wi;k D wi;k 1 C qi;k 1;
qi;k 1  N.0; Qi/;
i D 1; : : : ; d:
(5.44)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.6 Discrete-State Hidden Markov Models (HMMs)
87
If we deﬁne the state as xk D .w1;k; : : : ; wd;k/, this model can be writ-
ten as a linear Gaussian state space model with process noise qk 1 D
.q1;k 1; : : : ; qd;k 1/:
xk D xk 1 C qk 1;
yk D Hk xk C "k:
(5.45)
More general (TV)ARMA models can be handled similarly.
5.6 Discrete-State Hidden Markov Models (HMMs)
One useful class of probabilistic state space models that is often used in
speech processing and telecommunications applications is that of ﬁnite-
state hidden Markov models (HMMs, Rabiner, 1989). In these models,
the state is assumed to take values in some ﬁnite set of possible values
xk 2 X. Often (but not always), the measurements can also be assumed to
take values in another ﬁnite set yk 2 Y.
When the sets X and Y are both ﬁnite, we can without a loss of gen-
erality assume scalar states xk and measurements yk taking values in sets
X D f1; 2; : : : ; Xg and Y D f1; 2; : : : ; Y g, respectively. The states xk now
form a Markov chain whose transition probabilities can be conveniently
collected into a state transition matrix … with elements
…i;j D p.xk D j j xk 1 D i/:
(5.46)
The element …i;j thus gives the probability of jumping from the state
xk 1 D i to the state xk D j . In general, this matrix can also depend
on the time step k.
The measurements can be conveniently described in terms of an emis-
sion matrix O, which can also generally depend on the time step k and has
the elements
Oi;j D p.yk D j j xk D i/;
(5.47)
that is, the element Oi;j is the probability of observing the measurement
yk D j given that we are on the state xk D i.
Example 5.14 (Gilbert–Elliot channel model). In this example we consider
the Gilbert–Elliot model (see, e.g., Capp´e et al. (2005), Sec. 1.3.1), which
is an example of a ﬁnite-state hidden Markov model (HMM). The model
consists of a binary input sequence fbk W k D 1; : : : ; T g to be transmitted
and a binary channel regime signal fsk
W
k D 1; : : : ; T g. The binary
measurements are given as bk ˚ vk, where vk is a Bernoulli sequence,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
88
Modeling with State Space Models
0
50
100
Time step k
1
2
3
4
State xk
(a)
0
50
100
Time step k
1
2
Measurement yk
(b)
Figure 5.4 Simulated state (a) and measurement (b) sequences
from Gilbert–Elliot channel model in Example 5.14.
and ˚ denotes the exclusive or (i.e., xor) operation. These measurements
can be encoded as values yk D 1 for bk ˚ vk D 0 and yk D 2 when
bk ˚ vk D 1.
The regime signal sk deﬁnes the probability of an error (i.e., p.vk D 1/)
such that when sk D 0, then the probability of error has a small value
q0 and when sk D 1, the probability of error has a larger value q1. The
sequence fsk W k D 1; : : : ; T g is modeled as a ﬁrst order Markov chain,
and the probability of moving to state sk D 1 from state sk 1 D 0 is given
by p0 and the probability of moving to state sk D 0 from state sk 1 D 1 is
p1. We model the input signal fbk W k D 1; : : : ; T g as a ﬁrst order Markov
chain with state-switching probability p2. The joint model for the state
.bk; sk/ is a four-state Markov chain for the pair consisting of the states
f.0; 0/; .0; 1/; .1; 0/; .1; 1/g which are encoded as states xk 2 f1; : : : ; 4g in
the Markov chain, respectively.
The state transition and emission matrices are given as
… D
0
B@
.1   p0/ .1   p2/
p0 .1   p2/
.1   p0/ p2
p0 p2
p1 .1   p2/
.1   p1/ .1   p2/
p1 p2
.1   p1/ p2
.1   p0/ p2
p0 p2
.1   p0/ .1   p2/
p0 .1   p2/
p1 p2
.1   p1/ p2
p1 .1   p2/
.1   p1/ .1   p2/
1
CA ;
O D
0
B@
.1   q0/
q0
.1   q1/
q1
q0
.1   q0/
q1
.1   q1/
1
CA :
Figure 5.4 shows examples of simulated state and measurement trajecto-
ries from this model.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
5.7 Exercises
89
HMMs can also be often used as part of conventional continuous-state
tracking models to model the dynamics of indicator variables, as is illus-
trated in Exercise 5.8.
5.7 Exercises
5.1
Modify Example 5.4 to correspond to bearings (i.e., direction measurements)
from the four radars located at positions .s1;x; s1;y/, . . . , .s4;x; s4;y/.
5.2
Show that Student’s t-distribution in (5.15) converges to a Gaussian as the
degrees of freedom  ! 1.
5.3
Suppose we have a constant velocity model in 2D and that a speedometer
observes the speed in additive Gaussian noise. Write down the measurement
model in the functional relation form (see Equation (5.3)) and in conditional
density form (see Equation (5.4)).
5.4
Modify the gyroscope measurement and input models in Example 5.7 to cor-
respond to modeling speedometer readings instead. How would you combine
the two types of measurements (gyroscope and speedometer) in the same
model?
5.5
Consider the regression problem
yk D a1 sk C a2 sin.sk/ C b C "k;
k D 1; : : : ; T;
"k  N.0; R/;
a1  N.0; 2
1 /;
a2  N.0; 2
2 /;
b  N.0; 2
b /;
(5.48)
where sk 2 R are the known regressor values, R; 2
1 ; 2
2 ; 2
b are given pos-
itive constants, yk 2 R are the observed output variables, and "k are in-
dependent Gaussian measurement errors. The scalars a1, a2, and b are the
unknown parameters to be estimated. Formulate the estimation problem as a
linear Gaussian state space model.
5.6
Determine a matrix H such that the biased measurement model in Equa-
tion (5.39) can be rewritten in linear form yk D H Qxk C rk, where Qxk D
 x1;k; x2;k; bk

.
5.7
Consider the model
xk D
d
X
iD1
ai xk i C qk 1;
yk D xk C "k;
(5.49)
where the values fykg are observed, qk 1 and "k are independent Gaussian
noises, and the weights a1; : : : ; ad are known. The aim is to estimate the

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
90
Modeling with State Space Models
sequence fxkg. Rewrite the problem as an estimation problem in a linear
Gaussian state space model.
5.8
Let us now consider the clutter measurement model from Equation (5.22)
formulated for the car model.
(a) Write down the dynamic and measurement models with a clutter model
of the form of Equation (5.22) for the linear Gaussian car model consid-
ered in Example 5.1. You can assume that the clutter measurements are
uniformly distributed in a box Œ L; L  Œ L; L.
(b) Instead of assuming that each measurement is independently clutter or
non-clutter, write down a Markov model (in terms of the state-transition
matrix) for the clutter indicator ck that assigns a probability of ˛ for hav-
ing another non-clutter measurement after a non-clutter measurement,
and ˇ for having another clutter measurement after a clutter measure-
ment.
(c) Formulate a joint probabilistic state space model for the car and the
clutter state by using the augmented state Qxk D .xk; ck/, where xk
contains the linear dynamics, and ck is the clutter indicator.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6
Bayesian Filtering Equations and Exact
Solutions
In this chapter, we derive the Bayesian ﬁltering equations, which are the
general equations for computing Bayesian ﬁltering solutions to both lin-
ear Gaussian and non-linear/non-Gaussian state space models. We also de-
rive the Kalman ﬁltering equations that give the closed-form solution to
the linear Gaussian Bayesian ﬁltering problem. Additionally, we specialize
the Bayesian ﬁltering equations to discrete-state hidden Markov models
(HMMs).
6.1 Probabilistic State Space Models
Bayesian ﬁltering is considered with state estimation in general probabilis-
tic state space models, which have the following form.
Deﬁnition 6.1 (Probabilistic state space model). A probabilistic state space
model or non-linear ﬁltering model consists of a sequence of conditional
probability distributions:
xk  p.xk j xk 1/;
yk  p.yk j xk/
(6.1)
for k D 1; 2; : : : , where
 xk 2 Rn is the state of the system at time step k,
 yk 2 Rm is the measurement at time step k,
 p.xk j xk 1/ is the dynamic model that describes the stochastic dy-
namics of the system. The dynamic model can be a probability density, a
counting measure, or a combination of these, depending on whether the
state xk is continuous, discrete, or hybrid.
 p.yk j xk/ is the measurement model, which is the distribution of mea-
surements given the state.
91

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
92
Bayesian Filtering Equations and Exact Solutions
The model is assumed to be Markovian, which means that it has the
following two properties.
Property 6.2 (Markov property of states).
The states fxk W k D 0; 1; 2; : : :g form a Markov sequence (or Markov
chain if the state is discrete). This Markov property means that xk (and
actually the whole future xkC1; xkC2; : : :) given xk 1 is independent of
anything that has happened before the time step k   1:
p.xk j x0Wk 1; y1Wk 1/ D p.xk j xk 1/:
(6.2)
Also, the past is independent of the future given the present:
p.xk 1 j xkWT ; ykWT / D p.xk 1 j xk/:
(6.3)
Property 6.3 (Conditional independence of measurements).
The current measurement yk given the current state xk is conditionally
independent of the measurement and state histories:
p.yk j x0Wk; y1Wk 1/ D p.yk j xk/:
(6.4)
A simple example of a Markovian sequence is the Gaussian random
walk. When this is combined with noisy measurements, we obtain the fol-
lowing example of a probabilistic state space model.
Example 6.4 (Gaussian random walk). A Gaussian random walk model
can be written as
xk D xk 1 C qk 1;
qk 1  N.0; Q/;
yk D xk C rk;
rk  N.0; R/;
(6.5)
where xk is the hidden state (or signal), and yk is the measurement. In
terms of probability densities, the model can be written as
p.xk j xk 1/ D N.xk j xk 1; Q/
D
1
p2Q exp

  1
2Q.xk   xk 1/2

;
p.yk j xk/ D N.yk j xk; R/
D
1
p
2R
exp

  1
2R.yk   xk/2

;
(6.6)
which is a probabilistic state space model. Example realizations of the
signal xk and measurements yk are shown in Figure 6.1. The parameter
values in the simulation were Q D R D 1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.1 Probabilistic State Space Models
93
0
20
40
60
80
100
Time step k
-10
-8
-6
-4
-2
0
2
4
6
 xk
Signal
Measurement
Figure 6.1 Simulated signal and measurements from the
Gaussian random walk model in Example 6.4.
With the Markovian assumption and the ﬁltering model (6.1) the joint
prior distribution of the states x0WT D fx0; : : : ; xT g, and the joint likeli-
hood of the measurements y1WT D fy1; : : : ; yT g are, respectively,
p.x0WT / D p.x0/
TY
kD1
p.xk j xk 1/;
(6.7)
p.y1WT j x0WT / D
TY
kD1
p.yk j xk/:
(6.8)
In principle, for a given T we could simply compute the posterior distribu-
tion of the states by Bayes’ rule:
p.x0WT j y1WT / D p.y1WT j x0WT / p.x0WT /
p.y1WT /
/ p.y1WT j x0WT / p.x0WT /:
(6.9)
However, this kind of explicit usage of the full Bayes’ rule is not feasible in
real-time applications, because the number of computations per time step
increases as new observations arrive. Thus, this way we could only work
with small data sets, because if the amount of data is unbounded (as in real-
time sensing applications), then at some point of time the computations
will become intractable. To cope with real-time data, we need to have an
algorithm that performs a constant number of computations per time step.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
94
Bayesian Filtering Equations and Exact Solutions
As discussed in Section 1.3, ﬁltering distributions, prediction distribu-
tions, and smoothing distributions can be computed recursively such that
only a constant number of computations is done on each time step. For
this reason we shall not consider the full posterior computation at all, but
concentrate on the abovementioned distributions instead. In this and the
next few chapters, we consider computation of the ﬁltering and prediction
distributions; algorithms for computing the smoothing distributions will be
considered in later chapters.
6.2 Bayesian Filtering Equations
The purpose of Bayesian ﬁltering is to compute the marginal posterior
distribution or ﬁltering distribution of the state xk at each time step k given
the history of the measurements up to the time step k:
p.xk j y1Wk/:
(6.10)
The fundamental equations of Bayesian ﬁltering theory are given by the
following theorem.
Theorem 6.5 (Bayesian ﬁltering equations). The recursive equations (the
Bayesian ﬁlter) for computing the predicted distribution p.xk j y1Wk 1/
and the ﬁltering distribution p.xk j y1Wk/ at time step k are given by the
following Bayesian ﬁltering equations.
 Initialization. The recursion starts from the prior distribution p.x0/.
 Prediction step. The predictive distribution of the state xk at time
step k, given the dynamic model, can be computed by the Chapman–
Kolmogorov equation
p.xk j y1Wk 1/ D
Z
p.xk j xk 1/ p.xk 1 j y1Wk 1/ dxk 1:
(6.11)
 Update step. Given the measurement yk at time step k, the posterior
distribution of the state xk can be computed by Bayes’ rule
p.xk j y1Wk/ D 1
Zk
p.yk j xk/ p.xk j y1Wk 1/;
(6.12)
where the normalization constant Zk is given as
Zk D
Z
p.yk j xk/ p.xk j y1Wk 1/ dxk:
(6.13)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.2 Bayesian Filtering Equations
95
If some of the components of the state are discrete, the corresponding inte-
grals are replaced with summations. This is discussed more in Section 6.5.
The prediction and update steps are illustrated in Figures 6.2 and 6.3, re-
spectively.
Figure 6.2 Visualization of the prediction step: Prediction
propagates the state distribution of the previous measurement step
through the dynamic model such that the uncertainties
(stochastics) in the dynamic model are taken into account.
(a)
(b)
Figure 6.3 Visualization of the update step: (a) prior distribution
from prediction and the likelihood of measurement just before the
update step; (b) the posterior distribution after combining the
prior and likelihood by Bayes’ rule.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
96
Bayesian Filtering Equations and Exact Solutions
Proof
The joint distribution of xk and xk 1 given y1Wk 1 can be computed
as
p.xk; xk 1 j y1Wk 1/ D p.xk j xk 1; y1Wk 1/ p.xk 1 j y1Wk 1/
D p.xk j xk 1/ p.xk 1 j y1Wk 1/;
(6.14)
where the disappearance of the measurement history y1Wk 1 is due to the
Markov property of the sequence fxk W k D 1; 2; : : :g. The marginal dis-
tribution of xk given y1Wk 1 can be obtained by integrating the distribution
(6.14) over xk 1, which gives the Chapman–Kolmogorov equation
p.xk j y1Wk 1/ D
Z
p.xk j xk 1/ p.xk 1 j y1Wk 1/ dxk 1:
(6.15)
If xk 1 is discrete, then the above integral is replaced with summation over
xk 1. The distribution of xk given yk and y1Wk 1, that is, given y1Wk, can be
computed by Bayes’ rule
p.xk j y1Wk/ D 1
Zk
p.yk j xk; y1Wk 1/ p.xk j y1Wk 1/
D 1
Zk
p.yk j xk/ p.xk j y1Wk 1/;
(6.16)
where the normalization constant is given by Equation (6.13). The disap-
pearance of the measurement history y1Wk 1 in Equation (6.16) is due to the
conditional independence of yk of the measurement history, given xk.
6.3 Kalman Filter
The Kalman ﬁlter (Kalman, 1960b) is the closed form solution to the
Bayesian ﬁltering equations for the ﬁltering model, where the dynamic
and measurement models are linear Gaussian:
xk D Ak 1 xk 1 C qk 1;
yk D Hk xk C rk;
(6.17)
where xk 2 Rn is the state, yk 2 Rm is the measurement, qk 1 
N.0; Qk 1/ is the process noise, rk  N.0; Rk/ is the measurement noise,
and the prior distribution is Gaussian x0  N.m0; P0/. The matrix Ak 1
is the transition matrix of the dynamic model, and Hk is the measurement
model matrix. In probabilistic terms the model is
p.xk j xk 1/ D N.xk j Ak 1 xk 1; Qk 1/;
p.yk j xk/ D N.yk j Hk xk; Rk/:
(6.18)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.3 Kalman Filter
97
Theorem 6.6 (Kalman ﬁlter). The Bayesian ﬁltering equations for the lin-
ear ﬁltering model (6.17) can be evaluated in closed form, and the resulting
distributions are Gaussian:
p.xk j y1Wk 1/ D N.xk j m k ; P  k /;
p.xk j y1Wk/ D N.xk j mk; Pk/;
p.yk j y1Wk 1/ D N.yk j Hk m k ; Sk/:
(6.19)
The parameters of the distributions above can be computed with the fol-
lowing Kalman ﬁlter prediction and update steps.
 The prediction step is
m k D Ak 1 mk 1;
P  k D Ak 1 Pk 1 AT
k 1 C Qk 1:
(6.20)
 The update step is
vk D yk   Hk m k ;
Sk D Hk P  k HT
k C Rk;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk vk;
Pk D P  k   Kk Sk KT
k:
(6.21)
The recursion is started from the prior mean m0 and covariance P0.
Proof
The Kalman ﬁlter equations can be derived as follows.
1. By Lemma A.2, the joint distribution of xk and xk 1 given y1Wk 1 is
p.xk 1; xk j y1Wk 1/
D p.xk j xk 1/ p.xk 1 j y1Wk 1/
D N.xk j Ak 1 xk 1; Qk 1/ N.xk 1 j mk 1; Pk 1/
D N
xk 1
xk
 ˇˇˇ m0; P 0

;
(6.22)
where
m0 D

mk 1
Ak 1 mk 1

;
P 0 D

Pk 1
Pk 1 AT
k 1
Ak 1 Pk 1
Ak 1 Pk 1 AT
k 1 C Qk 1

;
(6.23)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
98
Bayesian Filtering Equations and Exact Solutions
and the marginal distribution of xk is by Lemma A.3
p.xk j y1Wk 1/ D N.xk j m k ; P  k /;
(6.24)
where
m k D Ak 1 mk 1;
P  k D Ak 1 Pk 1 AT
k 1 C Qk 1:
(6.25)
2. By Lemma A.2, the joint distribution of yk and xk is
p.xk; yk j y1Wk 1/ D p.yk j xk/ p.xk j y1Wk 1/
D N.yk j Hk xk; Rk/ N.xk j m k ; P  k /
D N
xk
yk
 ˇˇˇ m00; P 00

;
(6.26)
where
m00 D
 m k
Hk m k

;
P 00 D
 P  k
P  k HT
k
Hk P  k
Hk P  k HT
k C Rk

: (6.27)
3. By Lemma A.3, the conditional distribution of xk is
p.xk j yk; y1Wk 1/ D p.xk j y1Wk/
D N.xk j mk; Pk/;
(6.28)
where
mk D m k C P  k HT
k.Hk P  k HT
k C Rk/ 1Œyk   Hk m k ;
Pk D P  k   P  k HT
k .Hk P  k HT
k C Rk/ 1 Hk P  k ;
(6.29)
which can be also written in the form (6.21).
The functional form of the Kalman ﬁlter equations given here is not
the only possible one. From a numerical stability point of view it would
be better to work with matrix square roots of covariances instead of plain
covariance matrices. The theory and details of implementation of this kind
of method is well covered, for example, in the book of Grewal and Andrews
(2015).
Example 6.7 (Kalman ﬁlter for a Gaussian random walk). Assume that we
are observing measurements yk of the Gaussian random walk model given
in Example 6.4, and we want to estimate the state xk at each time step.
The information obtained up to time step k is summarized by the Gaussian
ﬁltering density
p.xk j y1Wk/ D N.xk j mk; Pk/:
(6.30)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.3 Kalman Filter
99
0
20
40
60
80
100
Time step k
-10
-8
-6
-4
-2
0
2
4
6
 xk
Signal
Measurement
Filter estimate
95% quantiles
Figure 6.4 Signal, measurements, and result of Kalman ﬁltering
of the Gaussian random walk in Example 6.7.
The Kalman ﬁlter prediction and update equations are now given as
m k D mk 1;
P  k D Pk 1 C Q;
mk D m k C
P  k
P  k C R .yk   m k /;
Pk D P  k   .P  k /2
P  k C R:
(6.31)
The result of applying this Kalman ﬁlter to the data in Figure 6.1 is shown
in Figure 6.4.
Example 6.8 (Kalman ﬁlter for car tracking). By discretizing the state
space model for the car in Example 4.6 and by forming a position mea-
surement model for it in Example 5.1, we got the following linear state
space model:
xk D A xk 1 C qk 1;
qk 1  N.0; Q/;
(6.32)
yk D H xk C rk;
rk  N.0; R/;
(6.33)
where the state is four dimensional, x D .x1; x2; x3; x4/, such that the
position of the car is .x1; x2/ and the corresponding velocities are .x3; x4/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
100
Bayesian Filtering Equations and Exact Solutions
The matrices in the dynamic model are
A D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA ;
Q D
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
;
where qc
1 and qc
2 are the spectral densities (continuous time variances)
of the process noises in each direction. The matrices in the measurement
model are
H D
1
0
0
0
0
1
0
0

;
R D
2
1
0
0
 2
2

;
where 2
1 and 2
2 are the measurement noise variances in each position
coordinate.
 The Kalman ﬁlter prediction step now becomes the following:
m k D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA mk 1;
P  k D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA Pk 1
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
C
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.3 Kalman Filter
101
-5
0
5
10
 x1
-12
-10
-8
-6
-4
-2
0
2
 x2
True trajectory
Measurements
Filter estimate
Figure 6.5 Simulated trajectory, measurements, and result of the
Kalman ﬁlter-based car tracking in Example 6.8. The starting
point is at the top of the trajectory. The RMSE position error
based on the measurements only is 0:77, whereas the position
RMSE of the Kalman ﬁlter estimate is 0:43.
 The corresponding Kalman ﬁlter update step is
Sk D
1
0
0
0
0
1
0
0

P  k
1
0
0
0
0
1
0
0
T
C
2
1
0
0
2
2

;
Kk D P  k
1
0
0
0
0
1
0
0
T
S 1
k ;
mk D m k C Kk

yk  1
0
0
0
0
1
0
0

m k

;
Pk D P  k   Kk Sk KT
k:
The result of applying this ﬁlter to simulated data is shown in Figure 6.5.
The parameter values used in the simulation were 1 D 2 D 1=2, qc
1 D
qc
2 D 1, and t D 1=10.
Although the Kalman ﬁlter can be seen as the closed form Bayesian
solution to the linear Gaussian ﬁltering problem, the original derivation of
Kalman (1960b) is based on a different principle. In his seminal article,
Kalman (1960b) derived the ﬁlter by considering orthogonal projections
on the linear manifold spanned by the measurements. A similar approach
is also employed in many other works concentrating on estimation in linear

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
102
Bayesian Filtering Equations and Exact Solutions
systems, such as in the book of Kailath et al. (2000). The advantage of
the approach is that it avoids explicit Gaussian assumptions in the noise
processes, as the Kalman ﬁlter can be seen as a more general best linear
unbiased estimator of the state. The disadvantage is that the route to non-
linear models is much less straightforward than in the present Bayesian
approach.
When the model is time invariant, that is, when the model matrices
in Equation (6.17) do not explicitly depend on the time step k, then as
k ! 1, the Kalman ﬁlter approaches a time-invariant ﬁlter called the sta-
tionary Kalman ﬁlter or steady-state Kalman ﬁlter (Anderson and Moore,
1979; Kailath et al., 2000). What happens in the Kalman ﬁlter is that the
prediction step variance and the update step covariance approach steady-
state values Pk ! P and P  k ! P   when k ! 1. Then the gain also
becomes constant K, and the Kalman ﬁlter becomes a time-invariant linear
ﬁlter.
6.4 Afﬁne Kalman Filter
An often needed simple extension of the Kalman ﬁlter is the afﬁne Kalman
ﬁlter, which provides the closed-form ﬁltering solution to models of the
afﬁne form
xk D Ak 1 xk 1 C ak 1 C qk 1;
yk D Hk xk C bk C rk;
(6.34)
where the difference to the linear Gaussian model in Equation (6.17) is that
we have additional (known and deterministic) offsets ak 1 and bk in the
dynamic and measurement models.
Theorem 6.9 (Afﬁne Kalman ﬁlter). The Bayesian ﬁltering equations for
the afﬁne ﬁltering model in Equation (6.34) can be evaluated in closed
form, and the resulting distributions are Gaussian:
p.xk j y1Wk 1/ D N.xk j m k ; P  k /;
p.xk j y1Wk/ D N.xk j mk; Pk/;
p.yk j y1Wk 1/ D N.yk j Hk m k C bk; Sk/:
(6.35)
The parameters of these distributions can be computed recursively with the
following afﬁne Kalman ﬁlter prediction and update steps.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.5 Bayesian Filter for Discrete State Space
103
 The prediction step is
m k D Ak 1 mk 1 C ak 1;
P  k D Ak 1 Pk 1 AT
k 1 C Qk 1:
(6.36)
 The update step is
vk D yk   Hk m k   bk;
Sk D Hk P  k HT
k C Rk;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk vk;
Pk D P  k   Kk Sk KT
k:
(6.37)
The recursion is started from the prior mean m0 and covariance P0.
Proof
The derivation is analogous to the derivation of the Kalman ﬁlter
in Theorem 6.6.
Note that the expressions for the distributions in Equation (6.35) are
identical to Equation (6.19) when bk D 0. Similarly, the prediction and
update steps in Equations (6.36) and (6.37) are identical to the original
Kalman ﬁlter, except for a minor adjustment in the expressions for m k
and vk.
6.5 Bayesian Filter for Discrete State Space
In Section 6.2, the Bayesian ﬁltering equations were formulated for the
case of continuous states xk 2 Rn, but it turns out that the equations also
work for discrete state spaces xk 2 X, where X is some discrete space
such as X D f1; 2; 3; : : :g. The only difference is that the integrals in Equa-
tions (6.11) and (6.13) are replaced with summations. Discrete models are
common in applications such as speech recognition and telecommunica-
tions, and they are often referred to as hidden Markov models (HMMs,
Rabiner, 1989).
Corollary 6.10 (Bayesian ﬁltering equations for discrete state spaces).
When xk takes values in a discrete state-space X, the Bayesian ﬁlter
equations in Theorem 6.5 take the following form.
 Initialization. The recursion starts from the prior distribution p.x0/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
104
Bayesian Filtering Equations and Exact Solutions
 Prediction step. The predictive distribution of the state xk can be com-
puted by a discrete version of the Chapman–Kolmogorov equation:
p.xk j y1Wk 1/ D
X
xk 12X
p.xk j xk 1/ p.xk 1 j y1Wk 1/:
(6.38)
 Update step. The update step takes the form
p.xk j y1Wk/ D 1
Zk
p.yk j xk/ p.xk j y1Wk 1/;
(6.39)
where
Zk D
X
xk2X
p.yk j xk/ p.xk j y1Wk 1/:
(6.40)
As discussed in Section 5.6, when the sets of possible states and mea-
surements are ﬁnite, and of the form xk 2 X with X D f1; 2; : : : ; Xg and
yk 2 Y with Y D f1; 2; : : : ; Y g, then it is convenient to deﬁne a state
transition matrix … and an emission matrix O, which have elements
…i;j D p.xk D j j xk 1 D i/;
Oi;j D p.yk D j j xk D i/:
(6.41)
These matrices can also depend on the time step k, but the dependence is
omitted for notational convenience. If we further denote
p j;k D p.xk D j j y1Wk 1/;
pj;k D p.xk D j j y1Wk/;
(6.42)
then the Bayesian ﬁlter for the resulting hidden Markov model (HMM) can
be written as follows.
Corollary 6.11 (Bayesian ﬁltering equations for discrete HMMs). The
Bayesian ﬁltering equations for hidden Markov models (HMMs) with ﬁ-
nite state and measurement spaces can be written as
p j;k D
X
i
…i;j pi;k 1;
pi;k D
Oi;yk p i;k
P
j Oj;yk p j;k
;
(6.43)
where the dynamic and measurement model matrices (i.e., transition and
emission matrices) are deﬁned in Equations (6.41), and the predictive and
posterior probabilities p j;k and pj;k in Equations (6.42).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
6.5 Bayesian Filter for Discrete State Space
105
20
40
60
80
100
Time step k
1
2
3
4
State xk
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
True states
Filter estimates
Figure 6.6 Filtering result for the Gilbert–Elliot channel model
in Example 6.12. The probabilities of the states are denoted by
shades of gray, and the ﬁlter estimates are the most probable
states computed as maxima of the ﬁltering distributions. The error
rate of the ﬁlter when the most probable state is guessed is 11%,
whereas guessing by no errors, that is, vk D 1, gives an error rate
of 14%.
The above algorithm is closely related to the forward portion of the
forward-backward algorithm for HMMs (see, e.g., Rabiner, 1989). The
smoother version of the above algorithm along with the Viterbi algorithm
that targets the MAP estimation of the trajectory are presented in Sec-
tions 12.4 and 12.5, respectively.
Example 6.12 (Gilbert–Elliot channel ﬁlter). In this example we con-
sider the ﬁltering problem on the Gilbert–Elliot model considered in
Example 5.14. The aim is to estimate the hidden state sequence on the
left in Figure 5.4 from the measurements shown on the right in the same
ﬁgure. Figure 6.6 shows the result of applying the Bayesian ﬁlter in
Corollary 6.11 to the measurements shown in Figure 5.4.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
106
Bayesian Filtering Equations and Exact Solutions
6.6 Exercises
6.1
Derive the Kalman ﬁlter equations for the following linear-Gaussian ﬁltering
model with non-zero-mean noises:
xk D A xk 1 C qk 1;
yk D H xk C rk;
(6.44)
where qk 1  N.mq; Q/ and rk  N.mr; R/.
6.2
Implement the Kalman ﬁlter in Example 6.7 for the Gaussian random walk
model with Matlab or Python. Draw realizations of state and measurement
sequences and apply the ﬁlter to it. Plot the evolution of the ﬁltering distri-
bution.
6.3
Derive the stationary Kalman ﬁlter for the Gaussian random walk model.
That is, compute the limiting Kalman ﬁlter gain when k ! 1, and write
down the mean equation of the resulting constant-gain Kalman ﬁlter. Plot the
frequency response of the resulting time-invariant ﬁlter. What type of digital
ﬁlter is it?
6.4
Consider the following dynamic model:
xk D
 
cos.!/
sin.!/
!
 ! sin.!/
cos.!/
!
xk 1 C qk 1;
yk D
 1
0

xk C rk;
where xk 2 R2 is the state, yk is the measurement, rk  N.0; 0:1/ is a white
Gaussian measurement noise, and qk  N.0; Q/, where
Q D
 qc ! qc cos.!/ sin.!/
2!3
qc sin2.!/
2!2
qc sin2.!/
2!2
qc !Cqc cos.!/ sin.!/
2!
!
:
(6.45)
The angular velocity is ! D 1=2 and the spectral density is qc D 0:01.
The model is a discretized version of the noisy resonator model with a given
angular velocity !.
In the ﬁle exercise6_4.m (MATLAB) or Exercise6_4.ipynb
(Python) of the book’s companion code repository1 there is simulation of the
dynamic model together with a baseline solution, where the measurement
is directly used as the estimate of the state component x1, and the second
component x2 is computed as a weighted average of the measurement
differences. Implement the Kalman ﬁlter for the model and compare its
performance (in RMSE sense) to the baseline solution. Plot ﬁgures of the
solutions.
6.5
Let us consider a binary HMM with two states xk 2 f1; 2g where the prob-
ability of jumping from state xk 1 D 1 to xk D 2 is given by 1;2 D 0:2,
1 https://github.com/EEA-sensors/Bayesian-Filtering-and-Smoothing

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
107
and the probability of jumping from xk 1 D 2 to xk D 1 is 2;1 D 0:1. Fur-
thermore, assume that yk 2 f1; 2g as well and that the probability of getting
yk D xk as the measurement is 0:3 for both of the states.
(a) Verify that the state transition and emission matrices are given by
… D
0:8
0:2
0:1
0:9

;
O D
0:7
0:3
0:3
0:7

:
(6.46)
(b) Starting from prior p0 D .0:5; 0:5/, simulate 100 steps of states and
measurements, and compute the error of using yk as the guess of xk.
What error rate would you expect?
(c) Implement an HMM ﬁlter for the problem, and compute estimates of
the state by taking the higher probability state at each step based on the
ﬁlter distribution. Simulate 100 independent realizations of the problem,
and check that on average we get a lower error rate than by just guessing
yk as in (b).
6.6
It is also possible to approximate the ﬁltering distributions on a grid and use
the HMM ﬁlter to solve the resulting ﬁnite-state problem. Select a ﬁnite in-
terval in the state space, say x 2 Œ 10; 10, and discretize it evenly to N
subintervals (e.g., N D 1000). Using a suitable numerical approximation
to the integrals in the Bayesian ﬁltering equations, implement a ﬁnite grid
approximation to the Bayesian ﬁlter for the Gaussian random walk in Exam-
ple 6.4. Verify that the result is practically the same as that of the Kalman
ﬁlter in Exercise 6.2.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7
Extended Kalman Filtering
It often happens in practical applications that the dynamic and measure-
ment models are not linear, and the Kalman ﬁlter is not appropriate. How-
ever, often the ﬁltering distributions of this kind of model can be approx-
imated by Gaussian distributions. In this chapter, we investigate methods
that use Taylor series expansions to perform approximate Bayesian ﬁltering
using such Gaussian approximations. The ﬁrst method is the (ﬁrst order)
extended Kalman ﬁlter (EKF), which is the classical and probably the most
widely used non-linear ﬁlter. We then proceed to discuss higher order EKFs
and then present the iterated EKF, which aims to improve the Taylor series
approximation by using iteration.
7.1 Taylor Series Approximation of Non-Linear Transform
Consider the following transformation of a Gaussian random variable x
into another random variable y:
x  N.m; P/;
y D g.x/;
(7.1)
where x 2 Rn, y 2 Rm, and g W Rn ! Rm is a general non-linear function.
Formally, the probability density of the random variable y is1 (see, e.g.,
Gelman et al., 2013)
p.y/ D jJ.y/j N.g 1.y/ j m; P/;
(7.2)
where jJ.y/j is the determinant of the Jacobian matrix of the inverse trans-
form g 1.y/. However, it is not generally possible to handle this distribu-
tion directly, because it is non-Gaussian for all but linear g.
1 This actually only applies to invertible g./, but it can be easily generalized to the
non-invertible case.
108

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.1 Taylor Series Approximation of Non-Linear Transform
109
A ﬁrst order Taylor series-based Gaussian approximation to the distri-
bution of y can now be formed as follows. If we let x D m C ıx, where
ıx  N.0; P/, we can form the Taylor series expansion of the function g./
as follows (provided that the function is sufﬁciently differentiable):
g.x/ D g.mCıx/  g.m/CGx.m/ ıxC
X
i
1
2ıxT G.i/
xx.m/ ıx ei C   ;
(7.3)
where Gx.m/ is the Jacobian matrix of g with elements
ŒGx.m/j;j 0 D @gj.x/
@xj 0
ˇˇˇˇˇ
xDm
;
(7.4)
and G.i/
xx.m/ is the Hessian matrix of gi./ evaluated at m:
h
G.i/
xx.m/
i
j;j 0 D @2gi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
:
(7.5)
Furthermore, ei D .0    0 1 0    0/T is a vector with 1 at position i and
all other elements zero, that is, it is the unit vector in the direction of the
coordinate axis i.
The linear approximation can be obtained by approximating the function
by the ﬁrst two terms in the Taylor series:
g.x/ ' g.m/ C Gx.m/ ıx:
(7.6)
Computing the expected value with respect to x gives:
EŒg.x/ ' EŒg.m/ C Gx.m/ ıx
D g.m/ C Gx.m/ EŒıx
D g.m/:
(7.7)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
110
Extended Kalman Filtering
The covariance can then be approximated as
E
h
.g.x/   EŒg.x// .g.x/   EŒg.x//Ti
' E
h
.g.x/   g.m// .g.x/   g.m//Ti
' E
h
.g.m/ C Gx.m/ ıx   g.m// .g.m/ C Gx.m/ ıx   g.m//Ti
D E
h
.Gx.m/ ıx/ .Gx.m/ ıx/Ti
D Gx.m/ E

ıx ıxT
GT
x.m/
D Gx.m/ P GT
x.m/:
(7.8)
We often are also interested in the the joint covariance between the vari-
ables x and y. Approximation of the joint covariance can be achieved by
considering the augmented transformation
Qg.x/ D
 x
g.x/

:
(7.9)
The resulting mean and covariance are
EŒQg.x/ '
 m
g.m/

;
CovŒQg.x/ '

I
Gx.m/

P

I
Gx.m/
T
D

P
P GT
x.m/
Gx.m/ P
Gx.m/ P GT
x.m/

:
(7.10)
In the derivation of the extended Kalman ﬁlter equations, we need a slightly
more general transformation of the form
x  N.m; P/;
q  N.0; Q/;
y D g.x/ C q;
(7.11)
where q is independent of x. The joint distribution of x and y, as deﬁned
above, is now the same as in Equations (7.10) except that the covariance Q
is added to the lower right block of the covariance matrix of Qg./. Thus we
get the following algorithm.
Algorithm 7.1 (Linear approximation of an additive transform). The linear
approximation-based Gaussian approximation to the joint distribution of x

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.1 Taylor Series Approximation of Non-Linear Transform
111
and the transformed random variable y D g.x/ C q, where x  N.m; P/
and q  N.0; Q/ is given by
x
y

 N
 m
L

;
 P
CL
CT
L
SL

;
(7.12)
where
L D g.m/;
SL D Gx.m/ P GT
x.m/ C Q;
CL D P GT
x.m/;
(7.13)
and Gx.m/ is the Jacobian matrix of g with respect to x, evaluated at
x D m, with elements
ŒGx.m/j;j 0 D @gj.x/
@xj 0
ˇˇˇˇˇ
xDm
:
(7.14)
In ﬁltering models where the process noise is not additive, we often need
to approximate transformations of the form
x  N.m; P/;
q  N.0; Q/;
y D g.x; q/;
(7.15)
where x and q are independent random variables. The mean and covariance
can now be computed by substituting the augmented vector .x; q/ for the
vector x in Equation (7.10). The joint Jacobian matrix can then be written
as Gx;q D .Gx Gq/. Here Gq is the Jacobian matrix of g./ with respect
to q, and both Jacobian matrices are evaluated at x D m, q D 0. The
approximations to the mean and covariance of the augmented transform as
in Equation (7.10) are then given as
EŒQg.x; q/ ' g.m; 0/;
CovŒQg.x; q/ '

I
0
Gx.m/
Gq.m/
 P
0
0
Q
 
I
0
Gx.m/
Gq.m/
T
D

P
P GT
x.m/
Gx.m/ P
Gx.m/ P GT
x.m/ C Gq.m/ Q GT
q.m/

:
(7.16)
The approximation above can be formulated as the following algorithm.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
112
Extended Kalman Filtering
Algorithm 7.2 (Linear approximation of a non-additive transform). The
linear approximation-based Gaussian approximation to the joint distribu-
tion of x and the transformed random variable y D g.x; q/ when x 
N.m; P/ and q  N.0; Q/ is given by
x
y

 N
 m
L

;
 P
CL
CT
L
SL

;
(7.17)
where
L D g.m; 0/;
SL D Gx.m/ P GT
x.m/ C Gq.m/ Q GT
q.m/;
CL D P GT
x.m/;
(7.18)
Gx.m/ is the Jacobian matrix of g with respect to x, evaluated at x D
m; q D 0, with elements
ŒGx.m/j;j 0 D @gj.x; q/
@xj 0
ˇˇˇˇˇ
xDm; qD0
;
(7.19)
and Gq.m/ is the corresponding Jacobian matrix with respect to q:

Gq.m/

j;j 0 D @gj.x; q/
@qj 0
ˇˇˇˇˇ
xDm; qD0
:
(7.20)
In quadratic approximations, in addition to the ﬁrst order terms, the sec-
ond order terms in the Taylor series expansion of the non-linear function
are also retained.
Algorithm 7.3 (Quadratic approximation of an additive non-linear trans-
form). The second order approximation is of the form
x
y

 N
 m
Q

;
 P
CQ
CT
Q
SQ

;
(7.21)
where the parameters are
Q D g.m/ C 1
2
X
i
ei tr
n
G.i/
xx.m/ P
o
;
SQ D Gx.m/ P GT
x.m/ C 1
2
X
i;i0
ei eT
i0 tr
n
G.i/
xx.m/ P G.i0/
xx .m/ P
o
C Q;
CQ D P GT
x.m/;
(7.22)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.2 Extended Kalman Filter
113
Gx.m/ is the Jacobian matrix (7.14), and G.i/
xx.m/ is the Hessian matrix
of gi./ evaluated at m:
h
G.i/
xx.m/
i
j;j 0 D @2gi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
;
(7.23)
where ei D .0    0 1 0    0/T is a vector with 1 at position i and other
elements zero, that is, it is the unit vector in the direction of the coordinate
axis i.
7.2 Extended Kalman Filter
The extended Kalman ﬁlter (EKF) (see, e.g., Jazwinski, 1970; Maybeck,
1982b; Bar-Shalom et al., 2001; Grewal and Andrews, 2015) is an exten-
sion of the Kalman ﬁlter to non-linear ﬁltering problems. If the process and
measurement noises can be assumed to be additive, the state space model
can be written as
xk D f.xk 1/ C qk 1;
yk D h.xk/ C rk;
(7.24)
where xk 2 Rn is the state, yk 2 Rm is the measurement, qk 1 
N.0; Qk 1/ is the Gaussian process noise, rk  N.0; Rk/ is the Gaussian
measurement noise, f./ is the dynamic model function, and h./ is the
measurement model function. The functions f and h can also depend on
the step number k, but for notational convenience, this dependence has not
been explicitly denoted.
The idea of the extended Kalman ﬁlter is to use (or assume) Gaussian
approximations
p.xk j y1Wk/ ' N.xk j mk; Pk/
(7.25)
to the ﬁltering densities. In the EKF, these approximations are formed by
utilizing Taylor series approximations to the non-linearities, and the result
is the following algorithm.
Algorithm 7.4 (Extended Kalman ﬁlter I). The prediction and update steps
of the ﬁrst order additive noise extended Kalman ﬁlter (EKF) are:
 Prediction:
m k D f.mk 1/;
P  k D Fx.mk 1/ Pk 1 F T
x.mk 1/ C Qk 1;
(7.26)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
114
Extended Kalman Filtering
 Update:
vk D yk   h.m k /;
Sk D Hx.m k / P  k HT
x.m k / C Rk;
Kk D P  k HT
x.m k / S 1
k ;
mk D m k C Kk vk;
Pk D P  k   Kk Sk KT
k:
(7.27)
Above, Fx.m/ and Hx.m/ denote the Jacobian matrices of functions f./
and h./, respectively, with elements
ŒFx.m/j;j 0 D @fj.x/
@xj 0
ˇˇˇˇˇ
xDm
;
(7.28)
ŒHx.m/j;j 0 D @hj.x/
@xj 0
ˇˇˇˇˇ
xDm
:
(7.29)
Derivation
These ﬁltering equations can be derived by repeating the
same steps as in the derivation of the Kalman ﬁlter in Section 6.3 and by
applying Taylor series approximations on the appropriate steps.
1. The joint distribution of xk and xk 1 is non-Gaussian, but we can form
a Gaussian approximation to it by applying the approximation Algo-
rithm 7.1 to the function
f.xk 1/ C qk 1;
(7.30)
which results in the Gaussian approximation
p.xk 1; xk j y1Wk 1/ ' N
xk 1
xk
 ˇˇˇ m0; P 0

;
(7.31)
where
m0 D
 mk 1
f.mk 1/

;
P 0 D
 Pk 1
Pk 1 F T
x
Fx Pk 1
Fx Pk 1 F T
x C Qk 1

;
(7.32)
and the Jacobian matrix Fx of f.x/ is evaluated at x D mk 1. The
approximations of the marginal mean and covariance of xk are thus
m k D f.mk 1/;
P  k D Fx Pk 1 F T
x C Qk 1:
(7.33)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.2 Extended Kalman Filter
115
2. The joint distribution of yk and xk is also non-Gaussian, but we can
again approximate it by applying Algorithm 7.1 to the function
h.xk/ C rk:
(7.34)
We get the approximation
p.xk; yk j y1Wk 1/ ' N
xk
yk
 ˇˇˇ m00; P 00

;
(7.35)
where
m00 D
 m k
h.m k /

;
P 00 D
 P  k
P  k HT
x
Hx P  k
Hx P  k HT
x C Rk

; (7.36)
and the Jacobian matrix Hx of h.x/ is evaluated at x D m k .
3. By Lemma A.3, the conditional distribution of xk is approximately
p.xk j yk; y1Wk 1/ ' N.xk j mk; Pk/;
(7.37)
where
mk D m k C P  k HT
x .Hx P  k HT
x C Rk/ 1 Œyk   h.m k /;
Pk D P  k   P  k HT
x .Hx P  k HT
x C Rk/ 1 Hx P  k :
(7.38)
A more general state space model, with non-additive noise, can be writ-
ten as
xk D f.xk 1; qk 1/;
yk D h.xk; rk/;
(7.39)
where qk 1  N.0; Qk 1/ and rk  N.0; Rk/ are the Gaussian process
and measurement noises, respectively. Again, the functions f and h can
also depend on the step number k. The EKF algorithm for the above model
is the following.
Algorithm 7.5 (Extended Kalman ﬁlter II). The prediction and update
steps of the (ﬁrst order) extended Kalman ﬁlter (EKF) in the non-additive
noise case are:
 Prediction:
m k D f.mk 1; 0/;
P  k D Fx.mk 1/ Pk 1 F T
x.mk 1/ C Fq.mk 1/ Qk 1 FT
q.mk 1/;
(7.40)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
116
Extended Kalman Filtering
 Update:
vk D yk   h.m k ; 0/;
Sk D Hx.m k / P  k HT
x.m k / C Hr.m k / Rk HT
r.m k /;
Kk D P  k HT
x.m k / S 1
k ;
mk D m k C Kk vk;
Pk D P  k   Kk Sk KT
k;
(7.41)
where the matrices Fx.m/, Fq.m/, Hx.m/, and Hr.m/ are the Jacobian
matrices of f and h with respect to state and noise, with elements
ŒFx.m/j;j 0 D @fj.x; q/
@xj 0
ˇˇˇˇˇ
xDm; qD0
;
(7.42)

Fq.m/

j;j 0 D @fj.x; q/
@qj 0
ˇˇˇˇˇ
xDm; qD0
;
(7.43)
ŒHx.m/j;j 0 D @hj.x; r/
@xj 0
ˇˇˇˇˇ
xDm; rD0
;
(7.44)
ŒHr.m/j;j 0 D @hj.x; r/
@rj 0
ˇˇˇˇˇ
xDm; rD0
:
(7.45)
Derivation
These ﬁltering equations can be derived by repeating the
same steps as in the derivation of the extended Kalman ﬁlter above, but
instead of using Algorithm 7.1, we use Algorithm 7.2 for computing the
approximations.
The advantage of the EKF over other non-linear ﬁltering methods is its
relative simplicity compared to its performance. Linearization is a very
common engineering way of constructing approximations to non-linear
systems, and thus it is very easy to understand and apply. A disadvan-
tage is that because it is based on a local linear approximation, it will not
work in problems with considerable non-linearities. The ﬁltering model is
also restricted in the sense that only Gaussian noise processes are allowed,
and thus the model cannot contain, for example, discrete-valued random
variables. The Gaussian restriction also prevents the handling of hierarchi-
cal models or other models where signiﬁcantly non-Gaussian distribution
models would be needed.
The EKF also requires the measurement model and the dynamic
model functions to be differentiable, which is a restriction. In some cases

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.2 Extended Kalman Filter
117
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
EKF estimate
Figure 7.1 Simulated pendulum data and the result of tracking
the pendulum angle and angular rate with the EKF in Example
7.6. The resulting RMSE was 0:17.
it might also be simply impossible to compute the required Jacobian
matrices, which renders the use of the EKF impossible. Even when the
Jacobian matrices exist and could be computed, the actual computation
and programming of Jacobian matrices can be quite error prone and hard
to debug. However, the manual computation of Jacobians can sometimes
be avoided by using automatic differentiation (Griewank and Walther,
2008), which we discuss more in Section 7.6.
Example 7.6 (Pendulum tracking with EKF). The Euler–Maruyama dis-
cretization of the pendulum model given in Example 4.9 in combination
with the measurement model given in Example 5.2 leads to the following
model:
x1;k
x2;k

„ ƒ‚ …
xk
D

x1;k 1 C x2;k 1 t
x2;k 1   g sin.x1;k 1/ t

„
ƒ‚
…
f.xk 1/
Cqk 1;
yk D sin.x1;k/
„ ƒ‚ …
h.xk/
Crk;
(7.46)
where rk  N.0; R/. In order to avoid the singularity of the noise re-
sulting from the Euler–Maruyama discretization, we use the additive noise

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
118
Extended Kalman Filtering
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
EKF estimate
Sensors
Figure 7.2 The result of applying EKF to simulated data from
the (polar) coordinated turn model in Example 7.7. The positions
of the radar sensors that measure the range to the target are
depicted by triangles. The resulting position RMSE was 0:031.
approximation given in Example 4.21, which puts qk 1  N.0; Q/ with
Q D
 
qc t3
3
qc t2
2
qc t2
2
qc t
!
;
(7.47)
where qc is the spectral density of the continuous-time process noise. The
required Jacobian matrices of f.x/ and h.x/ for the ﬁrst order EKF are:
Fx.x/ D

1
t
 g cos.x1/ t
1

;
Hx.x/ D
 cos.x1/
0

: (7.48)
An example result of applying the EKF to simulated data from the pendu-
lum model is shown in Figure 7.1. The prior mean and covariance were
selected to be m0 D .0; 0/ and P0 D I. After an initial transient, the
EKF is indeed able to track the pendulum angle quite well despite the non-
linearity of the model. The RMSE in the angle is 0:17, which is much lower
than the standard deviation of the measurement noise, which was 0:32.
Example 7.7 (Coordinated turn model with EKF). As a more complicated
example, we consider a polar coordinated turn model, which has a dynamic
model of the form
xk D f.xk 1/ C qk 1;
(7.49)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.3 Higher Order Extended Kalman Filters
119
with state consisting of 2D-position, speed, direction, and angular velocity:
xk D
 x1;k; x2;k; sk; 'k; !k

. As the dynamic model function we use the
analytical mean discretization given in Example 4.15:
f.xk 1/ D
0
BBBB@
x1;k 1 C 2sk 1
!k 1 sin. t !k 1
2
/ cos.'k 1 C t !k 1
2
/
x2;k 1 C 2sk 1
!k 1 sin. t !k 1
2
/ sin.'k 1 C t !k 1
2
/
sk 1
'k 1 C !k 1 t
!k 1
1
CCCCA
: (7.50)
As the process noise covariance Qk 1 for qk 1  N.0; Qk 1/ we use
the additive noise approximation provided in Example 4.22. The measure-
ments are range measurements from four radars positioned in locations
.s1;x; s1;y/, . . . , .s4;x; s4;y/ as described by the model given in Example 5.4:
yk D
0
BB@
p
.x1;k   s1;x/2 C .x2;k   s1;y/2
p
.x1;k   s2;x/2 C .x2;k   s2;y/2
p
.x1;k   s3;x/2 C .x2;k   s3;y/2
p
.x1;k   s4;x/2 C .x2;k   s4;y/2
1
CCA
„
ƒ‚
…
h.xk/
C
0
BB@
r1;k
r2;k
r3;k
r4;k
1
CCA
„ ƒ‚ …
rk
:
(7.51)
In this case the required Jacobians of f./ and h./ are more complicated
than in the pendulum example above, but they can still be easily derived.
Figure 7.2 shows the result of applying EKF to simulated measurements
from the model. Note that instead of using the approximate additive noise
model in the simulation, the trajectory was simulated using 100 steps of
Euler–Maruyama between each measurement. The EKF can be seen to
recover the trajectory quite well, resulting in a position RMSE of 0.031.
7.3 Higher Order Extended Kalman Filters
In the so-called second order EKF (see, e.g., Gelb, 1974), the non-linearity
is approximated by retaining the second order terms in the Taylor series
expansion as in Algorithm 7.3. The resulting algorithm is the following.
Algorithm 7.8 (Second order extended Kalman ﬁlter). The prediction and
update steps of the second order extended Kalman ﬁlter (in the additive
noise case) are:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
120
Extended Kalman Filtering
 Prediction:
m k D f.mk 1/ C 1
2
X
i
ei tr
n
F .i/
xx.mk 1/ Pk 1
o
;
P  k D Fx.mk 1/ Pk 1 F T
x.mk 1/
C 1
2
X
i;i0
ei eT
i0 tr
n
F.i/
xx.mk 1/ Pk 1 F.i0/
xx .mk 1/ Pk 1
o
C Qk 1;
(7.52)
 Update:
vk D yk   h.m k /   1
2
X
i
ei tr
n
H.i/
xx.m k / P  k
o
;
Sk D Hx.m k / P  k HT
x.m k /
C 1
2
X
i;i0
ei eT
i0 tr
n
H.i/
xx.m k / P  k H.i0/
xx .m k / P  k
o
C Rk;
Kk D P  k HT
x.m k / S 1
k ;
mk D m k C Kk vk;
Pk D P  k   Kk Sk KT
k;
(7.53)
where the matrices Fx.m/ and Hx.m/ are given by Equations (7.28) and
(7.29). The matrices F.i/
xx.m/ and H.i/
xx.m/ are the Hessian matrices of fi
and hi respectively:
h
F .i/
xx.m/
i
j;j 0 D @2fi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
;
(7.54)
h
H.i/
xx.m/
i
j;j 0 D @2hi.x/
@xj @xj 0
ˇˇˇˇˇ
xDm
:
(7.55)
The non-additive version can be derived in an analogous manner, but
due to its complicated appearance, it is not presented here.
It would also be possible to attempt to use even higher order Taylor
series expansions for the dynamic and measurement models in order to
get higher order EKFs. However, the computational complexity of these
methods increases rapidly with the Taylor series order, and the inclusion
of higher order terms can lead to numerically unstable ﬁlters. Therefore a
better idea is to use iteration as described in the next section.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.4 Iterated Extended Kalman Filter
121
7.4 Iterated Extended Kalman Filter
The iterated extended Kalman ﬁlter (IEKF, Gelb, 1974) is an iterated ver-
sion of the EKF where the idea is that after performing the EKF update
using a linearization at the predicted mean, we have improved our knowl-
edge about the state xk and can linearize again at the updated mean. We
can then perform another update using the resulting (presumably better)
linearization to obtain a new approximation to the posterior mean, using
which we can perform another linearization. This iterative procedure is the
update step in the IEKF algorihm.
It turns out that the above iterative procedure can be interpreted as a
Gauss–Newton method for ﬁnding the maximum a posteriori (MAP) esti-
mate of the state at each update step (Bell and Cathey, 1993), which also
guarantees the convergence of this procedure in well-deﬁned conditions.
Even though the above description may be enough to formulate the al-
gorithm, we now derive the IEKF measurement update for additive noise
models from the perspective of a MAP estimator, to provide additional in-
sights.
The prediction step of an IEKF is identical to an EKF and yields a
Gaussian approximation:
p.xk j y1Wk 1/ ' N.xk j m k ; P  k /:
(7.56)
The likelihood corresponding to the additive noise measurement model in
Equation (7.24) is
p.yk j xk/ D N.yk j h.xk/; Rk/:
(7.57)
By using Bayes’ rule, we can then write the posterior distribution of xk as
p.xk j y1Wk/ D
p.yk j xk/ p.xk j y1Wk 1/
R
p.yk j xk/ p.xk j y1Wk 1/ dxk
/ p.yk j xk/ p.xk j y1Wk 1/:
(7.58)
The maximum a posteriori (MAP) estimate of the state xk can now be
obtained as
xMAP
k
D arg max
xk p.xk j y1Wk/
D arg max
xk p.yk j xk/ p.xk j y1Wk 1/:
(7.59)
However, it is more convenient to work with the negative logarithms of
distributions instead and deﬁne
L.xk/ D   log Œp.yk j xk/ p.xk j y1Wk 1/ ;
(7.60)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
122
Extended Kalman Filtering
which, with Equation (7.56) as the prior and Equation (7.57) as the likeli-
hood, gives
L.xk/ '   log

N.yk j h.xk/; Rk/ N.xk j m k ; P  k /

D C C 1
2.yk   h.xk//T R 1
k .yk   h.xk//
C 1
2.xk   m k /T ŒP  k  1 .xk   m k /;
(7.61)
where C is a constant independent of xk. We can thus solve for the MAP
estimate xMAP
k
from the minimization problem
xMAP
k
D arg min
xk L.xk/
' arg min
xk

C C 1
2.yk   h.xk//T R 1
k .yk   h.xk//
C 1
2.xk   m k /T ŒP  k  1 .xk   m k /

:
(7.62)
We now describe how to solve for the MAP estimate in Equation (7.62)
using the Gauss–Newton method. The Gauss–Newton method (see, e.g.,
Nocedal and Wright, 2006) is an optimization method that assumes that
the objective function can be expressed as a sum of quadratic forms,
LGN.xk/ D 1
2
N
X
j D1
rT
j .xk/ rj.xk/;
(7.63)
and then iterates the following steps until convergence:
1. Perform a ﬁrst order Taylor expansion of r1; : : : ; rN about the current
estimate of the optimum xk.
2. Analytically ﬁnd the optimum xk of the approximate model obtained
by replacing r1; : : : ; rN with their Taylor expansions.
One way to express the approximation to L.xk/ in Equation (7.61) as in
Equation (7.63) is to select N D 3 and
r1.xk/ D
p
2C;
r2.xk/ D R 1=2
k
.yk   h.xk//;
r3.xk/ D ŒP  k  1=2 .xk   m k /:
(7.64)
We note that a ﬁrst order Taylor expansion of r1.xk/, r2.xk/, and r3.xk/
would represent r1.xk/ and r3.xk/ exactly and only introduce an approxi-
mation to r2.xk/ due to the linearization of the non-linear function h.xk/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.4 Iterated Extended Kalman Filter
123
The iterations of Gauss–Newton are started from some initial guess x.0/
k .
Then let us assume that the current estimate at iteration i   1 is x.i 1/
k
. We
can then linearize h.xk/ by forming a ﬁrst order Taylor series expansion at
the current estimate as follows:
h.xk/ ' h.x.i 1/
k
/ C Hx.x.i 1/
k
/ .xk   x.i 1/
k
/:
(7.65)
Plugging this back into Equation (7.63) gives the approximation
LGN.xk/ ' C C 1
2.yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .xk   x.i 1/
k
//T R 1
k
 .yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .xk   x.i 1/
k
//
C 1
2.xk   m k /T ŒP  k  1 .xk   m k /:
(7.66)
Because the above expression is quadratic in xk, we can compute its mini-
mum by setting its gradient to zero. The Gauss–Newton method then pro-
ceeds to use this minimum as the next iterate x.i/
k . However, instead of
explicitly setting the gradient to zero, let us derive the solution in a slightly
different way to clarify the connection to our ﬁlters.
The approximation on the right-hand side of Equation (7.66) can be seen
as the negative log-posterior for a model with the measurement model
Qp.yk j xk/ D N.yk j h.x.i 1/
k
/ C Hx.x.i 1/
k
/ .xk   x.i 1/
k
/; Rk/; (7.67)
which has the form of an afﬁne model with Gaussian noise. As both
the prior and likelihood are linear and Gaussian, the minimum of Equa-
tion (7.66) will exactly correspond to the posterior mean of xk with
this measurement model and the prior given in Equation (7.56). We
can obtain it by using, for example, the afﬁne Kalman ﬁlter update in
Theorem 6.9 with the measurement model matrix Hk D Hx.x.i 1/
k
/ and
offset bk D h.x.i 1/
k
/   Hx.x.i 1/
k
/ x.i 1/
k
, which results in
K.i/
k D P  k HT
x.x.i 1/
k
/
h
Hx.x.i 1/
k
/ P  k HT
x.x.i 1/
k
/ C Rk
i 1
;
x.i/
k D m k C K.i/
k
h
yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .m k   x.i 1/
k
/
i
:
(7.68)
The above iteration can then be repeated until it reaches a stationary point
x./
k
' xMAP
k
, which we can use as the updated mean estimate mk '

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
124
Extended Kalman Filtering
x./
k . The updated covariance can be approximated by the covariance cor-
responding to the linearized model in Equation (7.67) when evaluated at
the mean mk. The resulting algorithm is the following.
Algorithm 7.9 (Iterated Extended Kalman Filter). The prediction and up-
date steps of the iterated extended Kalman ﬁlter (IEKF) are:
 Prediction:
m k D f.mk 1/;
P  k D Fx.mk 1/ Pk 1 FT
x.mk 1/ C Qk 1:
(7.69)
 Update:
– Start from an initial guess, for example, x.0/
k
D m k .
– Then for i D 1; 2; : : : ; Imax, compute:
v .i/
k
D yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .m k   x.i 1/
k
/;
S.i/
k D Hx.x.i 1/
k
/ P  k HT
x.x.i 1/
k
/ C Rk;
K.i/
k D P  k HT
x.x.i 1/
k
/
h
S.i/
k
i 1
;
x.i/
k D m k C K.i/
k v .i/
k ;
(7.70)
and put mk D x.Imax/
k
.
– Compute the covariance estimate as follows:
Pk D P  k   K.Imax/
k
S.Imax/
k
h
K.Imax/
k
iT
:
(7.71)
Above, Fx.m/ and Hx.m/ are the Jacobian matrices of functions f./ and
h./ deﬁned in Equations (7.28) and (7.29), respectively.
It is worth noting that the iteration in the IEKF is only done to per-
form the update step, and it is a very local improvement in the sense that
it ignores estimates at other time steps. The iterations can still help, in par-
ticular in situations where the measurement likelihood is informative com-
pared to the predicted density (Morelande and Garc´ıa-Fern´andez, 2013).
Later, in Chapters 13 and 14, we discuss iterated extended smoothing al-
gorithms that perform global iteration by iteratively improving the whole
trajectory estimate instead of just improving the ﬁlter update step.
Example 7.10 (Pendulum tracking with IEKF). The result of applying
IEKF to the pendulum model introduced in Example 7.6 is shown in Fig-
ure 7.3. The performance of IEKF in this model is very similar to EKF, and
the RMSE is 0:17, which is the same as for EKF.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.5 Levenberg–Marquardt, Line-Search, and Related IEKFs
125
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
IEKF estimate
Figure 7.3 Simulated pendulum data and the result of tracking
the pendulum angle and angular rate with the IEKF in Example
7.10. The resulting RMSE was 0:17.
Example 7.11 (Coordinated turn model with IEKF). If we apply the IEKF
to the coordinated turn simulation that we considered in Example 7.7, we
get basically the same result as for EKF. This is because in that simulation,
the dynamic model is quite accurate, and the initial guess is also relatively
accurate. However, if we modify the simulation such that the initial guess
is further away from the actual position (and increase the prior covariance
appropriately), then the EKF and IEKF results do differ. Figure 7.4 illus-
trates the difference, which is that EKF takes much longer to converge to
the true trajectory than IEKF in the beginning of tracking. After the initial
transient, both of the methods produce practically the same result.
7.5 Levenberg–Marquardt, Line-Search, and Related IEKFs
As discussed in Section 7.4 above, the iterated extended Kalman ﬁlter
(IEKF) can be seen as a Gauss–Newton method for optimization of cost
functions of the form
L.xk/ ' C C 1
2.yk   h.xk//T R 1
k .yk   h.xk//
C 1
2.xk   m k /T ŒP  k  1 .xk   m k /
(7.72)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
126
Extended Kalman Filtering
-1.2
-1
-0.8
-0.6
-0.4
-0.2
0
 x1
-1.1
-1
-0.9
-0.8
-0.7
-0.6
-0.5
 x2
True trajectory
EKF estimate
IEKF estimate
Figure 7.4 The result of applying EKF and IEKF to simulated
data from the (polar) coordinated turn model in Example 7.11
when using an inaccurate initial guess. The ﬁgure only shows the
initial part of the trajectory as the result of the remaining
trajectory is identical for EKF and IEKF. The resulting RMSE for
EKF was 0:038, while for IEKF it was 0:031, and it can be seen
that EKF takes much longer to converge to the trajectory than
IEKF.
with respect to xk. However, there are many other optimization methods
that often have better performance than the plain Gauss-Newton method
(Nocedal and Wright, 2006). Different kinds of extensions have been dis-
cussed in Fatemi et al. (2012) and Skoglund et al. (2015), including:
 The Levenberg–Marquardt method corresponds to adding a regulariza-
tion term to the minimization of the quadratic approximation in Equa-
tion (7.66):
LGN.xk/ ' C C 1
2.yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .xk   x.i 1/
k
//T R 1
k
 .yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .xk   x.i 1/
k
//
C 1
2.xk   m k /T ŒP  k  1 .xk   m k /
C 1
2 .xk   x.i 1/
k
/T .xk   x.i 1/
k
/;
(7.73)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
7.6 Automatic Differentiation and EKFs
127
which can be implemented within the IEKF update iteration, for exam-
ple, as an extra measurement at x.i 1/
k
with noise covariance I= (cf.
S¨arkk¨a and Svensson, 2020).
 A line search can be implemented by modifying the computation of x.i/
k
in Equation (7.70) to
x.i/
k D x.i 1/
k
C  .x.i/
k
  x.i 1/
k
/;
(7.74)
where x.i/
k
D m k C K.i/
k v.i/
k , and the step size parameter  is selected
to approximately minimize L.x.i 1/
k
C  .x.i/
k
  x.i 1/
k
//.
 Quasi-Newton methods (Skoglund et al., 2015) can be implemented by
including an additional correction matrix to the minimization problem,
which leads to a similar extension as Levenberg–Marquardt.
7.6 Automatic Differentiation and EKFs
The implementation of EKFs presumes the availability of the Jacobian ma-
trices Fx./ and Hx./ of the model functions f./ and h./ as deﬁned in
Equations (7.28) and (7.29). To implement the second order EKFs, we fur-
ther need the Hessians of the model functions deﬁned in Equations (7.54)
and (7.55). Although for simple model functions the manual derivation of
the Jacobians and Hessian is easy, it can be tedious when the models are,
for example, derived as a numerical solutions to partial differential equa-
tions or when they are otherwise complicated to handle.
To help with the aforementioned issue, many programming languages
and environments, such as MATLAB, Python, and Julia, have support for
automatic differentiation (AD, Griewank and Walther, 2008). The idea of
AD is to automatically transform the function to be evaluated into a se-
quence of operations that automatically computes its (exact) derivative
along with its value. This is different from numerical differentiation where
the derivatives are approximated, for example, by using ﬁnite differences,
because the derivatives computed with AD are exact.
An obvious use for automatic differentiation (AD) in EKFs is the com-
putation of the Jacobians and Hessians of f./ and h./. This avoids errors
in manual derivation of these quantities, and AD-computed derivatives can
also be used to numerically validate the manually computed derivatives.
However, a disadvantage of AD is that evaluation of derivatives using it
can be computationally slower than using manually implemented deriva-
tives. In the context of parameter estimation (see Chapter 16), AD can be

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
128
Extended Kalman Filtering
used to compute derivatives of the marginal log-likelihood in order to avoid
manual implementation of the parameter gradient recursions.
7.7 Exercises
7.1
Consider the following non-linear state space model:
xk D xk 1   0:01 sin.xk 1/ C qk 1;
yk D 0:5 sin.2 xk/ C rk;
(7.75)
where qk 1 has a variance of 0:012 and rk has a variance of 0:02. Derive
the required derivatives for an EKF and implement the EKF for the model.
Simulate trajectories from the model, compute the RMSE values, and plot
the result.
7.2
In this exercise we consider a classical bearings-only target tracking prob-
lem that frequently arises in the context of passive sensor tracking. In this
problem there is single target in the scene, and two angular sensors are used
for tracking it. The scenario is illustrated in Figure 7.5.
Figure 7.5 In the bearings-only target tracking problem, the
sensors generate angle measurements of the target, and the
purpose is to determine the target trajectory.
The state of the target at time step k consists of the position .xk; yk/ and the
velocity . Pxk; Pyk/. The dynamics of the state vector xk D .xk yk Pxk Pyk/T
are modeled with the discretized Wiener velocity model:
0
BB@
xk
yk
Pxk
Pyk
1
CCA D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
0
BB@
xk 1
yk 1
Pxk 1
Pyk 1
1
CCA C qk 1;

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
129
where qk is a zero mean Gaussian process noise with covariance
Q D
0
BB@
qc
1 t3=3
0
qc
1 t2=2
0
0
qc
2 t3=3
0
qc
2 t2=2
qc
1 t2=2
0
qc
1 t
0
0
qc
2 t2=2
0
qc
2 t
1
CCA :
In this scenario the diffusion coefﬁcients are qc
1 D qc
2 D 0:1, and the sam-
pling period is t D 0:1. The measurement model for sensor i 2 f1; 2g
is:
i
k D tan 1
 
yk   si
y
xk   six
!
C ri
k;
(7.76)
where .si
x; si
y/ is the position of the sensor i, and ri
k  N.0; 2/ is a Gaus-
sian measurement noise with a standard deviation of  D 0:05 radians. At
each sampling time, which occurs 10 times per second (i.e., t D 0:1), both
of the two sensors produce a measurement.
In the ﬁle exercise7_2.m (MATLAB) or Exercise7_2.ipynb
(Python) of the book’s companion code repository there is a baseline
solution, which computes estimates of the position from the crossing of the
measurements and estimates the velocity to be always zero. Your task is to
implement an EKF for the problem and compare the results graphically and
in the RMSE sense.
(a) Implement an EKF for the bearings-only target tracking problem, which
uses the non-linear measurement model (7.76) as its measurement
model function (not the crossings). Hints:
 Use the function atan2 in the measurement model instead of atan
to directly get an answer in the range Œ ; .
 The two measurements at each measurement time can be processed
one at a time, that is, you can simply perform two scalar updates
instead of a single two-dimensional measurement update.
 Start by computing the Jacobian matrix of the measurement model
function with respect to the state components. Before implementing
the ﬁlter, check by ﬁnite differences or automatic differentiation that
the Jacobian matrix is correct.
(b) Compute the RMSE values, and plot ﬁgures of the estimates.
7.3
Implement the second order EKF for the model in Exercise 7.1.
7.4
Show that the IEKF with a single iteration is equivalent to the ﬁrst order
EKF.
7.5
Fill in the details of deriving the IEKF update by using the afﬁne Kalman
ﬁlter update.
7.6
Derive the IEKF update by setting gradient to zero in Equation (7.66) and
by using matrix inversion formulas in Corollary A.5.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
130
Extended Kalman Filtering
7.7
Implement IEKF for the model in Exercise 7.1.
7.8
Implement EKF for the Cartesian coordinated turn model in Equations (4.61)
and (4.90) with a linear position measurement model. Why would IEKF not
make sense for this model?
7.9
Implement IEKF for the bearings-only model in Exercise 7.2.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8
General Gaussian Filtering
In Chapter 7 we used Taylor series expansions to approximate a non-linear
state space model as a linear (or afﬁne) state space model. The ﬁltering
problem on the linearized model was then essentially solved by using a
Kalman ﬁlter, which led to extended Kalman ﬁlters (EKFs). Furthermore,
an iterated use of linearization then led to the iterated extended Kalman
ﬁlter (IEKF), which can be seen as a special case of the Gauss–Newton
optimization method.
In this chapter we present a philosophically different way of forming
Gaussian approximations to ﬁlter solutions that is based on using moment
matching. The idea is to postulate (or assume) the distributional form of the
ﬁltering density and then match the moments (in this case mean and covari-
ance) of the approximating density to the true ﬁltering density – at least ap-
proximately. This leads to so-called Gaussian ﬁlters (Ito and Xiong, 2000),
where the non-linear ﬁltering problem is solved using Gaussian assumed
density approximations. The generalized framework also enables the use
of various powerful Gaussian quadrature and cubature integration methods
(Wu et al., 2006; Arasaratnam and Haykin, 2009), including the unscented
transform which leads to the unscented Kalman ﬁlter (UKF, Julier and
Uhlmann, 1995; Julier et al., 2000). The EKF-based ﬁlters presented in the
previous chapter can be seen as approximations to the general Gaussian
ﬁlter. In this section we present the Gaussian ﬁltering framework and show
how the Gauss–Hermite Kalman ﬁlter (GHKF) and the cubature Kalman
ﬁlter (CKF) can be derived as its approximations. We also show how the
UKF can be seen as a generalization of the CKF.
8.1 Gaussian Moment Matching
Recall that in Chapter 7 we derived the EKF in terms of a linear approx-
imation to the non-linear transformation of random variables (e.g., Algo-
rithm 7.1), which is concerned with computing a Gaussian approximation
131

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
132
General Gaussian Filtering
to a pair of random variables .x; y/ deﬁned via
x  N.m; P/;
q  N.0; Q/;
y D g.x/ C q:
(8.1)
Instead of resorting to linearization, another approach is now to ﬁrst com-
pute the mean and covariance of .x; y/ and then form the Gaussian ap-
proximation as having these mean and covariance, that is, by using mo-
ment matching. We cannot, however, compute the mean and covariance in
closed form, but we can indeed write them in terms of integrals over Gaus-
sian distributions. For example, the mean and covariance of y are given
as
EŒy D
Z
g.x/ N.x j m; P/ dx;
CovŒy D
Z
.g.x/   EŒy/ .g.x/   EŒy/T N.x j m; P/ dx C Q:
(8.2)
One way to unify various Gaussian approximations to non-linear trans-
forms is to reduce them to approximate computations of Gaussian integrals
of the general form
Z
g.x/ N.x j m; P/ dx
for suitably selected g./. If we can compute these, a straightforward way
to form the Gaussian approximation for .x; y/ is to simply match the mo-
ments of the distributions, which gives the following algorithm.
Algorithm 8.1 (Gaussian moment matching of an additive transform). The
moment matching-based Gaussian approximation to the joint distribution
of x and the transformed random variable y D g.x/ C q, where x 
N.m; P/ and q  N.0; Q/, is given by
x
y

 N
 m
M

;
 P
CM
CT
M
SM

;
(8.3)
where
M D
Z
g.x/ N.x j m; P/ dx;
SM D
Z
.g.x/   M/ .g.x/   M/T N.x j m; P/ dx C Q;
CM D
Z
.x   m/ .g.x/   M/T N.x j m; P/ dx:
(8.4)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.2 Gaussian Filter
133
It is now easy to check by substituting the linear approximation g.x/ '
g.m/ C Gx.m/ .x   m/ into the above expression that the integrals reduce
to the linear approximations in Algorithm 7.1.
The non-additive version of the transform is the following.
Algorithm 8.2 (Gaussian moment matching of a non-additive transform).
The moment matching-based Gaussian approximation to the joint distri-
bution of x and the transformed random variable y D g.x; q/, where
x  N.m; P/ and q  N.0; Q/ is given by
x
y

 N
 m
M

;
 P
CM
CT
M
SM

;
(8.5)
where
M D
Z
g.x; q/ N.x j m; P/ N.q j 0; Q/ dx dq;
SM D
Z
.g.x; q/   M/ .g.x; q/   M/T
 N.x j m; P/ N.q j 0; Q/ dx dq;
CM D
Z
.x   m/ .g.x; q/   M/T N.x j m; P/ N.q j 0; Q/ dx dq:
(8.6)
8.2 Gaussian Filter
If we use the moment matching approximations for constructing a ﬁltering
algorithm, we get the following Gaussian assumed density ﬁlter (ADF),
which is also called the Gaussian ﬁlter (Maybeck, 1982b; Ito and Xiong,
2000; Wu et al., 2006). The key idea is to assume that the ﬁltering distribu-
tion is indeed Gaussian,
p.xk j y1Wk/ ' N.xk j mk; Pk/;
(8.7)
and approximate its mean mk and covariance Pk via moment matching.
The Gaussian ﬁlter can be used for approximating the ﬁltering distributions
of models having the same form as with the EKF, that is, models of the form
(7.24) or (7.39).
Algorithm 8.3 (Gaussian ﬁlter I). The prediction and update steps of the
additive noise Gaussian (Kalman) ﬁlter for models of the form (7.24) are:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
134
General Gaussian Filtering
 Prediction:
m k D
Z
f.xk 1/ N.xk 1 j mk 1; Pk 1/ dxk 1;
P  k D
Z
.f.xk 1/   m k / .f.xk 1/   m k /T
 N.xk 1 j mk 1; Pk 1/ dxk 1 C Qk 1:
(8.8)
 Update:
k D
Z
h.xk/ N.xk j m k ; P  k / dxk;
Sk D
Z
.h.xk/   k/ .h.xk/   k/T N.xk j m k ; P  k / dxk C Rk;
Ck D
Z
.xk   m k / .h.xk/   k/T N.xk j m k ; P  k / dxk;
Kk D Ck S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(8.9)
Derivation
Let us now follow a similar derivation as we did for the EKF
in Section 7.2.
1. If we apply the moment matching in Algorithm 8.1 to xk D f.xk 1/ C
qk 1 with xk 1  N.mk 1; Pk 1/, we get
p.xk 1; xk j y1Wk 1/ ' N
xk 1
xk
 ˇˇˇ
mk 1
m k

;
Pk 1
Dk
DT
k
P  k

;
(8.10)
where m k and P  k are as deﬁned in Equation (8.8), and
Dk D
Z
.xk 1   mk 1/
 f.xk 1/   m k
T
 N.xk 1 j mk 1; Pk 1/ dxk 1:
(8.11)
By Lemma A.3, the marginal distribution for xk then has mean m k and
covariance P  k , which gives the prediction equations.
2. Similarly we can apply the moment matching to yk D h.xk/ C rk,
giving
p.xk; yk j y1Wk 1/ ' N
xk
yk
 ˇˇˇ
m k
k

;
P  k
Ck
CT
k
Sk

;
(8.12)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.2 Gaussian Filter
135
where k, Ck, and Sk are as deﬁned in Equations (8.9). Using the
Gaussian conditioning in Lemma A.3 then gives a Gaussian distribution
with the following mean and covariance:
mk D m k C Ck S 1
k .yk   k/;
Pk D P  k   Ck S 1
k CT
k;
(8.13)
which can be further rewritten to give Equations (8.9).
The advantage of the moment matching formulation is that it enables the
use of many well-known numerical integration methods, such as Gauss–
Hermite quadratures and cubature rules (McNamee and Stenger, 1967;
Julier and Uhlmann, 1995; Ito and Xiong, 2000; Julier et al., 2000; Wu
et al., 2006; Arasaratnam and Haykin, 2009). It is also possible to use
other methods, such as the Bayes–Hermite/Gaussian-process quadrature
(O’Hagan, 1991; Deisenroth et al., 2009; S¨arkk¨a et al., 2016; Karvonen
et al., 2019; Pr¨uher et al., 2021) or Monte Carlo integration for approxi-
mating the integrals.
The Gaussian ﬁlter can be extended to non-additive noise models as
follows.
Algorithm 8.4 (Gaussian ﬁlter II). The prediction and update steps of the
non-additive noise Gaussian (Kalman) ﬁlter for models of the form (7.39)
are:
 Prediction:
m k D
Z
f.xk 1; qk 1/
 N.xk 1 j mk 1; Pk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1;
P  k D
Z
.f.xk 1; qk 1/   m k / .f.xk 1; qk 1/   m k /T
 N.xk 1 j mk 1; Pk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1:
(8.14)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
136
General Gaussian Filtering
 Update:
k D
Z
h.xk; rk/
 N.xk j m k ; P  k / N.rk j 0; Rk/ dxk drk;
Sk D
Z
.h.xk; rk/   k/ .h.xk; rk/   k/T
 N.xk j m k ; P  k / N.rk j 0; Rk/ dxk drk;
Ck D
Z
.xk   m k / .h.xk; rk/   k/T
 N.xk j m k ; P  k / N.rk j 0; Rk/ dxk drk;
Kk D Ck S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(8.15)
The above general Gaussian ﬁlters are theoretical constructions rather
than practical ﬁltering algorithms. However, there exist many models for
which the required integrals can indeed be computed in closed form. But
a more practical approach is to compute them numerically. These kinds of
methods will be discussed in the next sections.
8.3 Gauss–Hermite Integration
In the Gaussian ﬁlter (and later in the smoother), we are interested in ap-
proximating Gaussian integrals of the form
Z
g.x/ N.x j m; P/ dx
D
1
.2 /n=2 jPj1=2
Z
g.x/ exp

 1
2.x   m/T P  1 .x   m/

dx;
(8.16)
where g.x/ is an arbitrary function. In this section, we derive a Gauss–
Hermite-based numerical cubature1
algorithm for computing such
integrals. The algorithm is based on direct generalization of the one-
dimensional Gauss–Hermite rule into multiple dimensions by taking the
Cartesian product of one-dimensional quadratures. The disadvantage of
1 As one-dimensional integrals are quadratures, multi-dimensional integrals have been
traditionally called cubatures.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.3 Gauss–Hermite Integration
137
the method is that the required number of evaluation points is exponential
with respect to the number of dimensions.
In its basic form, one-dimensional Gauss–Hermite quadrature integra-
tion refers to the special case of Gaussian quadratures with unit Gaussian
weight function w.x/ D N.x j 0; 1/, that is, to approximations of the form
Z 1
 1
g.x/ N.x j 0; 1/ dx 
X
i
Wi g.x.i//;
(8.17)
where Wi; i D 1; : : : ; p are the weights and x.i/ are the evaluation points or
abscissas – which in the present context are often called sigma points. Note
that the quadrature is sometimes deﬁned in terms of the weight function
exp. x2/, but here we use the “probabilists’ deﬁnition” above. The two
versions of the quadrature are related by simple scaling of variables.
Obviously, there are an inﬁnite number of possible ways to select the
weights and evaluation points. In Gauss–Hermite integration, as in all
Gaussian quadratures, the weights and sigma points are chosen such that
with a polynomial integrand the approximation becomes exact. It turns
out that the polynomial order with a given number of points is maximized
if we choose the sigma points to be roots of Hermite polynomials. When
using the pth order Hermite polynomial Hp.x/, the rule will be exact for
polynomials up to order 2p   1. The required weights can be computed in
closed form (see below).
The Hermite polynomial of order p is deﬁned as (these are the so-called
“probabilists’ Hermite polynomials”):
Hp.x/ D . 1/p exp.x2=2/ dp
dxp exp. x2=2/:
(8.18)
The ﬁrst few Hermite polynomials are:
H0.x/ D 1;
H1.x/ D x;
H2.x/ D x2   1;
H3.x/ D x3   3x;
H4.x/ D x4   6 x2 C 3;
(8.19)
and further polynomials can be found from the recursion
HpC1.x/ D x Hp.x/   p Hp 1.x/:
(8.20)
Using the same weights and sigma points, integrals over non-unit Gaussian
weights functions N.x j m; P / can be evaluated using a simple change of

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
138
General Gaussian Filtering
integration variable:
Z 1
 1
g.x/ N.x j m; P / dx D
Z 1
 1
g.P 1=2 Cm/ N. j 0; 1/ d: (8.21)
Gauss–Hermite integration can be written as the following algorithm.
Algorithm 8.5 (Gauss–Hermite quadrature). The pth order Gauss–
Hermite approximation to the one-dimensional integral
Z 1
 1
g.x/ N.x j m; P / dx
(8.22)
can be computed as follows:
1. Compute the unit sigma points as the roots .i/; i D 1; : : : ; p of the
Hermite polynomial Hp.x/. Note that we do not need to form the poly-
nomial and then compute its roots, but instead it is numerically more
stable to compute the roots as eigenvalues of a suitable tridiagonal ma-
trix (Golub and Welsch, 1969).
2. Compute the weights as
Wi D
pŠ
p2 ŒHp 1..i//2 :
(8.23)
3. Approximate the integral as
Z 1
 1
g.x/ N.x j m; P / dx 
p
X
iD1
Wi g.P 1=2 .i/ C m/:
(8.24)
By generalizing the change of variables idea, we can form approxi-
mations to multi-dimensional integrals of the form (8.16). First let P D
p
P
p
P
T, where
p
P is the Cholesky factor of the covariance matrix P or
some other similar square root of the covariance matrix. If we deﬁne new
integration variables  by
x D m C
p
P ;
(8.25)
we get
Z
g.x/ N.x j m; P/ dx D
Z
g.m C
p
P / N. j 0; I/ d:
(8.26)
The integration over the multi-dimensional unit Gaussian distribution can
be written as an iterated integral over one-dimensional Gaussian distribu-
tions, and each of the one-dimensional integrals can be approximated with

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.3 Gauss–Hermite Integration
139
Gauss–Hermite quadrature:
Z
g.m C
p
P / N. j 0; I/ d
D
Z
  
Z
g.m C
p
P / N.1 j 0; 1/ d1      N.n j 0; 1/ dn

X
i1;:::;in
Wi1      Wing.m C
p
P .i1;:::;in//:
(8.27)
The weights Wik; k
D
1; : : : ; n are simply the corresponding one-
dimensional Gauss–Hermite weights, and .i1;:::;in/ is an n-dimensional
vector with one-dimensional unit sigma point .ik/ at element k. The
algorithm can now be written as follows.
Algorithm 8.6 (Gauss–Hermite cubature). The pth order Gauss–Hermite
approximation to the multi-dimensional integral
Z
g.x/ N.x j m; P/ dx
(8.28)
can be computed as follows.
1. Compute the one-dimensional weights Wi; i D 1; : : : ; p and unit sigma
points .i/ as in the one-dimensional Gauss–Hermite quadrature Algo-
rithm 8.5.
2. Form multi-dimensional weights as the products of one-dimensional
weights:
Wi1;:::;in D Wi1      Win
D
pŠ
p2 ŒHp 1..i1//2     
pŠ
p2 ŒHp 1..in//2 ;
(8.29)
where each ik takes values 1; : : : ; p.
3. Form multi-dimensional unit sigma points as Cartesian products of the
one-dimensional unit sigma points:
.i1;:::;in/ D
0
B@
.i1/
:::
.in/
1
CA :
(8.30)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
140
General Gaussian Filtering
4. Approximate the integral as
Z
g.x/ N.x j m; P/ dx 
X
i1;:::;in
Wi1;:::;ing.m C
p
P .i1;:::;in//;
(8.31)
where
p
P is a matrix square root deﬁned by P D
p
P
p
P
T.
The pth order multi-dimensional Gauss–Hermite integration is exact for
monomials of the form xd1
1 xd2
2    xdn
n , and their arbitrary linear combina-
tions, where each of the orders di  2p   1. The pth order integration
rule for an n-dimensional integral requires pn sigma points, which quickly
becomes infeasible when the number of dimensions grows.
8.4 Gauss–Hermite Kalman Filter
The additive form multi-dimensional Gauss–Hermite cubature-based
Gauss–Hermite (Kalman) ﬁlter (GHKF) (Ito and Xiong, 2000), which is
also called the quadrature Kalman ﬁlter (QKF) (Arasaratnam et al., 2007),
can be derived by replacing the Gaussian integrals in the Gaussian ﬁlter
Algorithm 8.3 with the Gauss–Hermite approximations in Algorithm 8.6.
Algorithm 8.7 (Gauss–Hermite Kalman ﬁlter). The additive form Gauss–
Hermite Kalman ﬁlter (GHKF) algorithm is the following.
 Prediction:
1. Form the sigma points as:
X .i1;:::;in/
k 1
D mk 1 C
p
Pk 1 .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p;
(8.32)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (8.30).
2. Propagate the sigma points through the dynamic model:
OX .i1;:::;in/
k
D f.X .i1;:::;in/
k 1
/;
i1; : : : ; in D 1; : : : ; p:
(8.33)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
X
i1;:::;in
Wi1;:::;in OX .i1;:::;in/
k
;
P  k D
X
i1;:::;in
Wi1;:::;in. OX .i1;:::;in/
k
  m k / . OX .i1;:::;in/
k
  m k /T C Qk 1;
(8.34)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.4 Gauss–Hermite Kalman Filter
141
where the weights Wi1;:::;in were deﬁned in Equation (8.29).
 Update:
1. Form the sigma points:
X  .i1;:::;in/
k
D m k C
q
P  k .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p;
(8.35)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (8.30).
2. Propagate the sigma points through the measurement model:
OY.i1;:::;in/
k
D h.X  .i1;:::;in/
k
/;
i1; : : : ; in D 1; : : : ; p:
(8.36)
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
X
i1;:::;in
Wi1;:::;in OY.i1;:::;in/
k
;
Sk D
X
i1;:::;in
Wi1;:::;in. OY.i1;:::;in/
k
  k/ . OY.i1;:::;in/
k
  k/T C Rk;
Ck D
X
i1;:::;in
Wi1;:::;in.X  .i1;:::;in/
k
  m k / . OY.i1;:::;in/
k
  k/T;
(8.37)
where the weights Wi1;:::;in were deﬁned in Equation (8.29).
4. Compute the ﬁlter gain Kk, the ﬁltered state mean mk, and the co-
variance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.38)
The non-additive version can be obtained by applying the Gauss–
Hermite quadrature to the non-additive Gaussian ﬁlter Algorithm 8.4 in
a similar manner. However, due to the rapid growth of computational
requirements in state dimension, the augmented form is computationally
quite heavy, because it requires roughly double the dimensionality of the
integration variable.
Example 8.8 (Pendulum tracking with GHKF). The result of applying the
GHKF to the pendulum model in Example 7.6 is shown in Figure 8.1.
Unlike in the EKF, we do not need to derive analytical derivatives or use

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
142
General Gaussian Filtering
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
GHKF estimate
Figure 8.1 Simulated pendulum data and the result of tracking
the pendulum with the GHKF (Example 8.8). The resulting
RMSE was 0:10, which is lower than the RMSEs of EKF and
IEKF (= 0:17).
automatic differentiation for implementing the GHKF. The resulting RMSE
is 0:10 which is lower than the RMSEs of the EKF and IEKF which both
were 0:17.
Example 8.9 (Coordinated turn model with GHKF). We also applied the
GHKF to the coordinated turn model in Example 7.7 and the resulting
position RMSE was 0:030, which is slightly lower than that of the EKF but
still practically the same. The result is shown in Figure 8.2.
8.5 Spherical Cubature Integration
In this section, we derive the third order spherical cubature rule, which was
popularized by Arasaratnam and Haykin (2009). However, this method can
in hindsight be seen as a special case of the unscented transform, which we
discuss in Section 8.7. Instead of using the derivation of Arasaratnam and
Haykin (2009), we use the derivation presented by Wu et al. (2006), due to
its simplicity. Although the derivation that we present here is far simpler
than the alternative, it is completely equivalent. Furthermore, the derivation
presented here can be more easily extended to more complicated spherical

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.5 Spherical Cubature Integration
143
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
EKF estimate
GHKF estimate
Sensors
Figure 8.2 The result of applying GHKF to the coordinated turn
model in Example 7.7. The resulting RMSE was 0:030, which is
almost the same as that of EKF.
cubatures, and it indeed turns out that this was already done a while ago by
McNamee and Stenger (1967).
Recall from Section 8.3 that the expectation of a non-linear function over
an arbitrary Gaussian distribution N.x j m; P/ can always be transformed
into an expectation over the unit Gaussian distribution N. j 0; I/. Thus,
we can start by considering the multi-dimensional unit Gaussian integral
Z
g./ N. j 0; I/ d:
(8.39)
We now wish to form a 2n-point approximation of the form
Z
g./ N. j 0; I/ d  W
X
i
g.c u.i//;
(8.40)
where the points u.i/ belong to the symmetric set Œ1 with generator
.1; 0; : : : ; 0/ (see, e.g., Wu et al., 2006; Arasaratnam and Haykin, 2009):
Œ1 D
8
ˆˆˆˆˆ<
ˆˆˆˆˆ:
0
BBBBB@
1
0
0
:::
0
1
CCCCCA
;
0
BBBBB@
0
1
0
:::
0
1
CCCCCA
;   
0
BBBBB@
 1
0
0
:::
0
1
CCCCCA
;
0
BBBBB@
0
 1
0
:::
0
1
CCCCCA
;   
9
>>>>>=
>>>>>;
;
(8.41)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
144
General Gaussian Filtering
and W is a weight and c is a parameter yet to be determined.
Because the point set is symmetric, the rule is exact for all monomials
of the form xd1
1 xd2
2    xdn
n , if at least one of the exponents di is odd. Thus
we can construct a rule that is exact up to third degree by determining the
coefﬁcients W and c such that it is exact for selections gj./ D 1 and
gj./ D 2
j . Because the true values of the integrals are
Z
N. j 0; I/ d D 1;
Z
2
j N. j 0; I/ d D 1;
(8.42)
we get the equations
W
X
i
1 D W 2n D 1;
W
X
i
Œc u.i/
j 2 D W 2c2 D 1;
(8.43)
which have the solutions
W D 1
2n;
c D pn:
(8.44)
That is, we get the following simple rule, which is exact for monomials up
to third degree:
Z
g./ N. j 0; I/ d  1
2n
X
i
g.pn u.i//:
(8.45)
We can now easily extend the method to arbitrary mean and covariance by
using the change of variables in Equations (8.25) and (8.26), and the result
is the following algorithm.
Algorithm 8.10 (Spherical cubature integration). The third order spherical
cubature approximation to the multi-dimensional integral
Z
g.x/ N.x j m; P/ dx
(8.46)
can be computed as follows.
1. Compute the unit sigma points as
.i/ D
(pn ei;
i D 1; : : : ; n;
 pn ei n;
i D n C 1; : : : ; 2n;
(8.47)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.6 Cubature Kalman Filter
145
where ei denotes a unit vector in the direction of the coordinate axis i.
2. Approximate the integral as
Z
g.x/ N.x j m; P/ dx  1
2n
2n
X
iD1
g.m C
p
P .i//;
(8.48)
where
p
P is a matrix square root deﬁned by P D
p
P
p
P
T.
The derivation presented by Arasaratnam and Haykin (2009) is some-
what more complicated than the derivation of Wu et al. (2006) presented
above, as it is based on converting the Gaussian integral into spherical coor-
dinates and then considering the even order monomials. However, Wu et al.
(2006) actually did not present the most useful special case given in Algo-
rithm 8.10 but instead presented the method for more general generators
Œu. The method in the above Algorithm 8.10 has the useful property that
its weights are always positive, which is not always true for more general
methods (Wu et al., 2006).
Note that “third order” here means a different thing than in the Gauss–
Hermite Kalman ﬁlter – the pth order Gauss–Hermite ﬁlter is exact for
monomials up to order 2p   1, which means that the third order GHKF is
exact for monomials up to ﬁfth order. The third order spherical cubature
rule is exact only for monomials up to third order. It is also possible to
derive symmetric rules that are exact for monomials higher than third order.
However, this is no longer possible with a number of sigma points that
is linear O.n/ in the state dimension (Wu et al., 2006; Arasaratnam and
Haykin, 2009). We discuss one such rule, the ﬁfth order rule, in Section 8.9.
In that rule, the required number of sigma points is proportional to n2, the
state dimension squared.
As in the case of the unscented transform, being exact up to order three
only ensures that the estimate of the mean of g./ is exact for polynomials
of order three. The covariance will be exact only for polynomials up to
order one (linear functions). In this sense the third order spherical cubature
rule is actually a ﬁrst order spherical cubature rule for the covariance.
8.6 Cubature Kalman Filter
When we apply the third order spherical cubature integration rule in Al-
gorithm 8.10 to the Gaussian ﬁlter equations in Algorithm 8.3, we get the
cubature Kalman ﬁlter (CKF) of Arasaratnam and Haykin (2009).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
146
General Gaussian Filtering
Algorithm 8.11 (Cubature Kalman ﬁlter I). The additive form of the cu-
bature Kalman ﬁlter (CKF) algorithm is the following.
 Prediction:
1. Form the sigma points as
X .i/
k 1 D mk 1 C
p
Pk 1 .i/;
i D 1; : : : ; 2n;
(8.49)
where the unit sigma points are deﬁned as
.i/ D
(pn ei;
i D 1; : : : ; n;
 pn ei n;
i D n C 1; : : : ; 2n:
(8.50)
2. Propagate the sigma points through the dynamic model:
OX .i/
k
D f.X .i/
k 1/;
i D 1; : : : ; 2n:
(8.51)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D 1
2n
2n
X
iD1
OX .i/
k ;
P  k D 1
2n
2n
X
iD1
. OX .i/
k
  m k / . OX .i/
k
  m k /T C Qk 1:
(8.52)
 Update:
1. Form the sigma points:
X  .i/
k
D m k C
q
P  k .i/;
i D 1; : : : ; 2n;
(8.53)
where the unit sigma points are deﬁned as in Equation (8.50).
2. Propagate sigma points through the measurement model:
OY.i/
k
D h.X  .i/
k
/;
i D 1 : : : 2n:
(8.54)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.6 Cubature Kalman Filter
147
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D 1
2n
2n
X
iD1
OY.i/
k ;
Sk D 1
2n
2n
X
iD1
. OY.i/
k   k/ . OY.i/
k   k/T C Rk;
Ck D 1
2n
2n
X
iD1
.X  .i/
k
  m k / . OY.i/
k   k/T:
(8.55)
4. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.56)
By applying the cubature rule to the non-additive Gaussian ﬁlter in Al-
gorithm 8.4, we get the following augmented form of the cubature Kalman
ﬁlter (CKF).
Algorithm 8.12 (Cubature Kalman ﬁlter II). The augmented non-additive
form of the cubature Kalman ﬁlter (CKF) algorithm is the following.
 Prediction:
1. Form the matrix of sigma points for the augmented random variable
.xk 1; qk 1/:
QX .i/
k 1 D Qmk 1 C
q
QPk 1 .i/0;
i D 1; : : : ; 2n0;
(8.57)
where
Qmk 1 D
mk 1
0

;
QPk 1 D
Pk 1
0
0
Qk 1

:
Here n0 D n C nq, where n is the dimensionality of the state xk 1,
and nq is the dimensionality of the noise qk 1. The unit sigma points
are deﬁned as
.i/0 D
(p
n0 ei;
i D 1; : : : ; n0;
 p
n0 ei n0;
i D n0 C 1; : : : ; 2n0:
(8.58)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
148
General Gaussian Filtering
2. Propagate the sigma points through the dynamic model:
OX .i/
k
D f. QX .i/;x
k 1 ; QX .i/;q
k 1 /;
i D 1; : : : ; 2n0;
(8.59)
where QX .i/;x
k 1 denotes the ﬁrst n components in QX .i/
k 1, and QX .i/;q
k 1 de-
notes the last nq components.
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
1
2n0
2n0
X
iD1
OX .i/
k ;
P  k D
1
2n0
2n0
X
iD1
. OX .i/
k
  m k / . OX .i/
k
  m k /T:
(8.60)
 Update:
1. Let n00 D n C nr, where n is the dimensionality of the state, and nr is
the dimensionality of the measurement noise. Form the sigma points
for the augmented vector .xk; rk/ as follows:
QX  .i/
k
D Qm k C
q
QP  k .i/00;
i D 1; : : : ; 2n00;
(8.61)
where
Qm k D
m k
0

;
QP  k D
P  k
0
0
Rk

:
The unit sigma points .i/00 are deﬁned as in Equation (8.58), but with
n0 replaced by n00.
2. Propagate the sigma points through the measurement model:
OY.i/
k
D h. QX  .i/;x
k
; QX  .i/;r
k
/;
i D 1; : : : ; 2n00;
(8.62)
where QX  .i/;x
k
denotes the ﬁrst n components in QX  .i/
k
, and QX  .i/;r
k
denotes the last nr components.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.7 Unscented Transform
149
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
1
2n00
2n00
X
iD1
OY.i/
k ;
Sk D
1
2n00
2n00
X
iD1
. OY.i/
k   k/ . OY.i/
k   k/T;
Ck D
1
2n00
2n00
X
iD1
.X  .i/;x
k
  m k / . OY.i/
k   k/T:
(8.63)
4. Compute the ﬁlter gain Kk, the ﬁltered state mean mk, and the co-
variance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.64)
Although in the cubature Kalman ﬁlter (CKF) literature, the “third or-
der” characteristic of the cubature integration rule is often emphasized (see
Arasaratnam and Haykin, 2009), it is important to remember that in the
covariance computation, the rule is only exact for ﬁrst order polynomials.
Thus in that sense CKF is a ﬁrst order method.
Example 8.13 (Pendulum tracking with CKF). The result of the CKF in
the pendulum model (Example 7.6) is shown in Figure 8.3. The RMSE was
0:11, which is between the error of the GHKF, which was 0:10, and the
EKF, which was 0:17. However, the result is practically the same as that of
the GHKF.
Example 8.14 (Coordinated turn model with CKF). The result of applying
the CKF to the coordinated turn model considered in Example 7.7 is shown
in Figure 8.4. The RMSE was 0:30, which is the same as the RMSE of the
GHKF.
8.7 Unscented Transform
Although in this chapter we have started by presenting the GHKF and CKF
as instances of numerical integration approximations to the general Gaus-
sian ﬁlter, historically, the unscented Kalman ﬁlter (UKF, Julier et al.,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
150
General Gaussian Filtering
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
CKF estimate
Figure 8.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the CKF
(Example 8.13). The resulting RMSE was 0:11, which is slightly
higher than the error of GHKF (= 0:10) but still lower than EKF
(= 0:17).
1995; Wan and Van der Merwe, 2001; Julier and Uhlmann, 2004) was the
ﬁrst general ﬁltering framework that used this approach in non-linear ﬁl-
tering. The UKF can be seen to be based on the unscented transform (UT
Julier and Uhlmann, 1995; Julier et al., 2000; Julier, 2002), which in fact
is a numerical integration-based approximation to the moment matching
transform in Algorithm 8.1. The aims of this and the next section are to ex-
plain how the UT and UKF ﬁt into the numerical integration-based Gaus-
sian ﬁltering framework.
In order to arrive at the UT, we notice that we can generalize the numer-
ical integration approach in Section 8.5 by using a 2n C 1 point approxi-
mation, where the origin is also included:
Z
g./ N. j 0; I/ d  W0 g.0/ C W
X
i
g.c u.i//:
(8.65)
We can now solve for the parameters W0, W , and c such that we get the
exact result with selections gj./ D 1 and gj./ D 2
j . The solution can

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.7 Unscented Transform
151
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
EKF estimate
CKF estimate
Sensors
Figure 8.4 The result of applying CKF to the coordinated turn
model (see Example 8.14). The resulting RMSE was 0:30, which
matches that of GHKF.
be written in the form
W0 D

n C  ;
W D
1
2.n C /;
c D
p
n C ;
(8.66)
where  is a free parameter. This gives an integration rule that can be
written asZ
g.x/ N.x j m; P/ dx


n C  g.m/ C
1
2.n C /
2n
X
iD1
g.m C
p
P .i//;
(8.67)
where
.i/ D
(pn C  ei;
i D 1; : : : ; n;
 pn C  ei n;
i D n C 1; : : : ; 2n:
(8.68)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
152
General Gaussian Filtering
However, we in fact have
p
P ei D Œ
p
Pi, where Œ
p
Pi denotes the ith
column of the matrix
p
P. Therefore, we can rewrite the integration rule as
Z
g.x/ N.x j m; P/ dx 

n C  g.X .0// C
1
2.n C /
2n
X
iD1
g.X .i//;
(8.69)
where we have deﬁned sigma (i.e., evaluation) points
X .0/ D m;
X .i/ D m C
p
n C 
hp
P
i
i ;
i D 1; : : : ; n;
X .iCn/ D m  p
n C 
hp
P
i
i ;
i D 1; : : : ; n:
(8.70)
This rule already appears in the original article on the unscented transform
(Julier and Uhlmann, 1995), and it is equivalent to the cubature rule in
Algorithm 8.10 when  D 0. We can equivalently interpret the integration
rule such that we ﬁrst compute transformed sigma points by propagating
them though the function Y.i/ D g.X .i// for i D 0; : : : ; 2n, and then use
Z
g.x/ N.x j m; P/ dx 

n C  Y.0/ C
1
2.n C /
2n
X
iD1
Y.i/:
(8.71)
In the so-called scaled unscented transform (Julier, 2002), this rule is
modiﬁed by evaluating the integrand in the following sigma-points instead
of the original ones:
X .i/0 D X .0/ C ˛

X .i/   X .0/
;
(8.72)
where ˛ > 0 is an additional parameter. This corresponds to replacing
pn C  in the sigma-point computation with ˛pn C . To ﬁnd the corre-
sponding weights that still lead to a method that is exact to third order, we
need to ﬁnd a modiﬁed , which we denote as , such that
˛
p
n C  D
p
n C ;
(8.73)
which gives
 D ˛2 .n C /   n:
(8.74)
Furthermore, we can observe that there is no inherent need to use the same
weights for the mean and covariance computation. In this regard, Julier
(2002) suggest the introduction of an additional parameter ˇ > 0, which
only appears in the covariance computation, to account for high order mo-
ments of the distribution. In particular, the choice of ˇ D 2 is in a certain

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.7 Unscented Transform
153
sense optimal for a Gaussian distribution. With this addition we get differ-
ent weights for the mean (m) and covariance (c) computation:
W .m/
0
D

n C ;
W .c/
0
D

n C  C .1   ˛2 C ˇ/;
W .m/
i
D
1
2.n C /;
i D 1; : : : ; 2n;
W .c/
i
D
1
2.n C /;
i D 1; : : : ; 2n:
(8.75)
If we apply the resulting integration rule to the moment matching transform
in Algorithm 8.1, we get the following unscented transform.
Algorithm 8.15 (Unscented approximation of an additive transform). The
unscented transform-based Gaussian approximation to the joint distribu-
tion of x and the transformed random variable y D g.x/ C q, where
x  N.m; P/ and q  N.0; Q/ is given by
x
y

 N
 m
U

;
 P
CU
CT
U
SU

;
(8.76)
where the submatrices can be computed as follows.
1. Form the set of 2n C 1 sigma points as follows:
X .0/ D m;
X .i/ D m C
p
n C 
hp
P
i
i ;
X .iCn/ D m  p
n C 
hp
P
i
i ;
i D 1; : : : ; n;
(8.77)
where the parameter  is deﬁned in Equation (8.74).
2. Propagate the sigma points through the non-linear function g./:
Y.i/ D g.X .i//;
i D 0; : : : ; 2n:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
154
General Gaussian Filtering
3. The submatrices are then given as:
U D
2n
X
iD0
W .m/
i
Y.i/;
SU D
2n
X
iD0
W .c/
i
.Y.i/   U/ .Y.i/   U/T C Q;
CU D
2n
X
iD0
W .c/
i
.X .i/   m/ .Y.i/   U/T;
(8.78)
where the constant weights W .m/
i
and W .c/
i
were deﬁned in the Equa-
tion (8.75).
The unscented transform approximation to a transformation of the form
y D g.x; q/ can be derived by considering the augmented random variable
Qx D .x; q/ as the random variable in the transform, which corresponds to
using the numerical integration scheme above in the non-additive moment
matching transform in Algorithm 8.2. The resulting algorithm is the fol-
lowing.
Algorithm 8.16 (Unscented approximation of a non-additive transform).
The (augmented) unscented transform-based Gaussian approximation
to the joint distribution of x and the transformed random variable
y D g.x; q/ when x  N.m; P/ and q  N.0; Q/ is given by
x
y

 N
 m
U

;
 P
CU
CT
U
SU

;
(8.79)
where the sub-matrices can be computed as follows. Let the dimensionali-
ties of x and q be n and nq, respectively, and let n0 D n C nq.
1. Form the sigma points for the augmented random variable Qx D .x; q/:
QX .0/ D Qm;
QX .i/ D Qm C
p
n0 C 0
hp
QP
i
i ;
QX .iCn0/ D Qm  p
n0 C 0
hp
QP
i
i ;
i D 1; : : : ; n0;
(8.80)
where the parameter 0 is deﬁned as in Equation (8.74), but with n
replaced by n0, and the augmented mean and covariance are deﬁned by
Qm D
m
0

;
QP D
P
0
0
Q

:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.8 Unscented Kalman Filter
155
2. Propagate the sigma points through the function:
QY.i/ D g. QX .i/;x; QX .i/;q/;
i D 0; : : : ; 2n0;
where QX .i/;x and QX .i/;q denote the parts of the augmented sigma point
i that correspond to x and q, respectively.
3. Compute the predicted mean U, the predicted covariance SU, and the
cross-covariance CU:
U D
2n0
X
iD0
W .m/0
i
QY.i/;
SU D
2n0
X
iD0
W .c/0
i
. QY.i/   U/ . QY.i/   U/T;
CU D
2n0
X
iD0
W .c/0
i
. QX .i/;x   m/ . QY.i/   U/T;
where the deﬁnitions of the weights W .m/0
i
and W .c/0
i
are the same as in
Equation (8.75), but with n replaced by n0 and  replaced by 0.
The unscented transform is also a third order method in the sense that
the estimate of the mean of g./ is exact for polynomials up to order three.
That is, if g./ is indeed a multi-variate polynomial of order three, the
mean is exact. However, the covariance approximation is exact only for
ﬁrst order polynomials, because the square of a second order polynomial is
already a polynomial of order four, and the unscented transform (UT) does
not compute the exact result for fourth order polynomials. In this sense
the UT is only a ﬁrst order method. With suitable selection of parameters
( D 3   n), it is possible to get some, but not all, of the fourth order
terms appearing in the covariance computation correct also for quadratic
functions.
8.8 Unscented Kalman Filter
The unscented Kalman ﬁlter (UKF) (Julier et al., 1995; Wan and Van
der Merwe, 2001; Julier and Uhlmann, 2004) is an approximate ﬁltering
framework that utilizes the unscented transform to approximate the
general Gaussian ﬁlters in Algorithms 8.3 and 8.4, and it can thus be
applied to models of the form (7.24) or (7.39). The UKF forms a Gaussian
approximation to the ﬁltering distribution:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
(8.81)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
156
General Gaussian Filtering
where mk and Pk are the mean and covariance computed by the algorithm.
Algorithm 8.17 (Unscented Kalman ﬁlter I). In the additive form of the
unscented Kalman ﬁlter (UKF) algorithm, which can be applied to additive
models of the form (7.24), the following operations are performed at each
measurement step k D 1; 2; 3; : : :
 Prediction:
1. Form the sigma points:
X .0/
k 1 D mk 1;
X .i/
k 1 D mk 1 C
p
n C 
hp
Pk 1
i
i ;
X .iCn/
k 1
D mk 1  p
n C 
hp
Pk 1
i
i ;
i D 1; : : : ; n;
(8.82)
where the parameter  is deﬁned in Equation (8.74).
2. Propagate the sigma points through the dynamic model:
OX .i/
k
D f.X .i/
k 1/;
i D 0; : : : ; 2n:
(8.83)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
2n
X
iD0
W .m/
i
OX .i/
k ;
P  k D
2n
X
iD0
W .c/
i
. OX .i/
k
  m k / . OX .i/
k
  m k /T C Qk 1;
(8.84)
where the weights W .m/
i
and W .c/
i
were deﬁned in Equation (8.75).
 Update:
1. Form the sigma points:
X  .0/
k
D m k ;
X  .i/
k
D m k C
p
n C 
hq
P  k
i
i ;
X  .iCn/
k
D m k  p
n C 
hq
P  k
i
i ;
i D 1; : : : ; n:
(8.85)
2. Propagate sigma points through the measurement model:
OY.i/
k
D h.X  .i/
k
/;
i D 0; : : : ; 2n:
(8.86)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.8 Unscented Kalman Filter
157
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
2n
X
iD0
W .m/
i
OY.i/
k ;
Sk D
2n
X
iD0
W .c/
i
. OY.i/
k   k/ . OY.i/
k   k/T C Rk;
Ck D
2n
X
iD0
W .c/
i
.X  .i/
k
  m k / . OY.i/
k   k/T:
(8.87)
4. Compute the ﬁlter gain Kk, the ﬁltered state mean mk, and the co-
variance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.88)
The ﬁltering equations above can be derived in an analogous manner to
the EKF or Gaussian ﬁlter equations, but the unscented transform-based
approximations are used instead of the linear approximations or moment
matching.
The non-additive form of the UKF (Julier and Uhlmann, 2004) can be
derived by augmenting the process and measurement noises to the state
vector and then using the UT approximation for performing prediction and
update steps simultaneously. Alternatively, we can ﬁrst augment the state
vector with process noise, then approximate the prediction step, and after
that do the same with measurement noise on the update step. This latter
form corresponds to the moment matching-based Gaussian ﬁlter, whereas
the former is different (though it would be possible to derive a general
Gaussian ﬁlter using that kind of moment matching as well). The different
algorithms and ways of doing this in practice are analyzed in the article
by Wu et al. (2005). However, if we directly apply the non-additive UT in
Algorithm 8.16 separately to the prediction and update steps, we get the
following algorithm.
Algorithm 8.18 (Unscented Kalman ﬁlter II). In the augmented form of
the unscented Kalman ﬁlter (UKF) algorithm, which can be applied to non-
additive models of the form (7.39), the following operations are performed
at each measurement step k D 1; 2; 3; : : :

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
158
General Gaussian Filtering
 Prediction:
1. Form the sigma points for the augmented random variable
.xk 1; qk 1/:
QX .0/
k 1 D Qmk 1;
QX .i/
k 1 D Qmk 1 C
p
n0 C 0
q
QPk 1

i
;
QX .iCn0/
k 1
D Qmk 1  p
n0 C 0
q
QPk 1

i
;
i D 1; : : : ; n0;
(8.89)
where
Qmk 1 D
mk 1
0

;
QPk 1 D
Pk 1
0
0
Qk 1

:
Here n0 D n C nq, where n is the dimensionality of the state xk 1,
and nq is the dimensionality of the noise qk 1. The parameter 0 is
deﬁned as in Equation (8.74), but with n replaced by n0.
2. Propagate the sigma points through the dynamic model:
OX .i/
k
D f. QX .i/;x
k 1 ; QX .i/;q
k 1 /;
i D 0; : : : ; 2n0;
(8.90)
where QX .i/;x
k 1 denotes the ﬁrst n components in QX .i/
k 1, and QX .i/;q
k 1 de-
notes the last nq components.
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
2n0
X
iD0
W .m/0
i
OX .i/
k ;
P  k D
2n0
X
iD0
W .c/0
i
. OX .i/
k
  m k / . OX .i/
k
  m k /T;
(8.91)
where the weights W .m/0
i
and W .c/0
i
are the same as in Equation (8.75),
but with n replaced by n0 and  by 0.
 Update:
1. Form the sigma points for the augmented random variable .xk; rk/:
QX  .0/
k
D Qm k ;
QX  .i/
k
D Qm k C
p
n00 C 00
q
QP  k

i
;
QX  .iCn00/
k
D Qm k  p
n00 C 00
q
QP  k

i
;
i D 1; : : : ; n00;
(8.92)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.8 Unscented Kalman Filter
159
where
Qm k D
m k
0

;
QP  k D
P  k
0
0
Rk

:
Here we have deﬁned n00 D n C nr, where n is the dimensionality
of the state xk, and nr is the dimensionality of the noise rk. The
parameter 00 is deﬁned as in Equation (8.74), but with n replaced
by n00.
2. Propagate the sigma points through the measurement model:
OY.i/
k
D h. QX  .i/;x
k
; QX  .i/;r
k
/;
i D 0; : : : ; 2n00;
(8.93)
where QX  .i/;x
k
denotes the ﬁrst n components in QX  .i/
k
, and QX  .i/;r
k
denotes the last nr components.
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
2n00
X
iD0
W .m/00
i
OY.i/
k ;
Sk D
2n00
X
iD0
W .c/00
i 1 . OY.i/
k   k/ . OY.i/
k   k/T;
Ck D
2n00
X
iD0
W .c/00
i
.X  .i/;x
k
  m k / . OY.i/
k   k/T;
(8.94)
where the weights W .m/00
i
and W .c/00
i
are the same as in Equa-
tion (8.75), but with n replaced by n00 and  by 00.
4. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional to the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.95)
The UKF was originally proposed as an improvement to the EKF (Julier
et al., 1995). In that regard, the advantage of the UKF over the EKF is that
the UKF is not based on a linear approximation at a single point but uses
further points in approximating the non-linearity. As discussed in Julier and

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
160
General Gaussian Filtering
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
UKF estimate
Figure 8.5 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the UKF
(Example 8.19). The resulting RMSE was 0:10, which is
practically the same as with the GHKF (Figure 8.1).
Uhlmann (2004), the unscented transform is able to capture the higher or-
der moments caused by the non-linear transform better than Taylor series-
based approximations. However, as already pointed out in the previous sec-
tion, although the mean estimate of the UKF is exact for polynomials up
to order three, the covariance computation is only exact for polynomials
up to ﬁrst order. In the UKF, the dynamic and model functions are also not
required to be formally differentiable nor do their Jacobian matrices need
to be computed. The disadvantage over the EKF is that the UKF often re-
quires slightly more computational operations than the EKF.
Example 8.19 (Pendulum tracking with UKF). The result of applying the
UKF to the pendulum model and simulated data in Example 7.6 is shown
in Figure 8.5. The resulting RMSE was 0:10, which is the same as with
GHKF while better than the EKF (= 0:17) and CKF (= 0:11).
Example 8.20 (Coordinated turn model with UKF). Figure 8.6 shows the
result of applying the UKF to the coordinated turn model in Example 7.7.
The resulting RMSE was 0:30, which is the same as with the CKF and
GHKF.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.8 Unscented Kalman Filter
161
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
EKF estimate
UKF estimate
Sensors
Figure 8.6 The result of applying UKF to the coordinated turn
model (see Example 8.20). The resulting RMSE is the same as
that of CKF and GHKF.
It is worth noting that although the unscented Kalman ﬁlters (UKFs) in
the forms that we have described them in this section appear to differ from
the other numerical integration ﬁlters, such as the Gauss–Hermite Kalman
ﬁlter in Algorithm 8.7 and the cubature Kalman ﬁlter in Algorithm 8.11, in
the sigma-point forming step, the difference is only superﬁcial. The use of
columns of the Chokesly factors of the covariances in forming the sigma
points in Algorithm 8.17, for example, is in fact equivalent to using the
following unit sigma points:
.i/ D
(p
n C  ei;
i D 1; : : : ; n;
 p
n C  ei n;
i D n C 1; : : : ; 2n;
(8.96)
because
p
P .c ei/ D c Œ
p
Pi. Furthermore, the UKF uses different sets of
numerical integration weights W .m/
i
and W .c/
i
for the mean and covariance.
This is in reality is not a unique feature of the UKF either, because in
any numerical integration-based ﬁlter we could use different numerical
integration rules for the mean and covariance – or in fact for all the integrals
appearing in the equations. However, to simplify the story, we have not
discussed this explicitly in the case of other ﬁlters.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
162
General Gaussian Filtering
8.9 Higher Order Cubature/Unscented Kalman Filters
We can also generalize the spherical cubature/unscented integration rules
discussed in Section 8.5 and 8.7 to higher than third order (McNamee and
Stenger, 1967; Wu et al., 2006). This can be done by using symmetric sets
of higher order. We have already seen two kinds of symmetric sets:
 Set Œ0 D f.0; : : : ; 0/g, which only contains the origin.
 Set Œu D f.u; 0; : : : ; 0/; . u; 0; : : : ; 0/; .0; u; : : : :; 0/; : : :g, whose spe-
cial case was given in (8.41) with u D 1.
With these deﬁnitions, the unscented rule in (8.67) can be written in the
form Z
g./ N. j 0; I/ d  W0
X
2Œ0
g./ C W
X
2Œc
g./;
(8.97)
where W0, W , and c are given by Equation (8.66). The cubature rule in
Equation (8.45) is a special case of this of the form
Z
g./ N. j 0; I/ d  W
X
2Œc
g./;
(8.98)
which is obtained by setting  D 0.
It turns out that a ﬁfth order symmetric cubature rule can now be con-
structed in the form
Z
g./ N. j 0; I/ d
 W0
X
2Œ0
g./ C W .1/ X
2Œu
g./ C W .2/
X
2Œu;u
g./;
(8.99)
where we have introduced the additional symmetric set Œu; u, which con-
tains all vectors that have only two non-zero elements having values u or
 u. As an example, in three dimensions we have
Œ1; 1 D
8
<
:
0
@
1
1
0
1
A ;
0
@
 1
 1
0
1
A ;
0
@
1
 1
0
1
A ;
0
@
 1
1
0
1
A ;
0
@
1
0
1
1
A ;
0
@
 1
0
 1
1
A ;
0
@
1
0
 1
1
A ;
0
@
 1
0
1
1
A ;
0
@
0
1
1
1
A ;
0
@
0
 1
 1
1
A ;
0
@
0
1
 1
1
A ;
0
@
0
 1
1
1
A
9
=
; :
(8.100)
As shown in McNamee and Stenger (1967) and Wu et al. (2006), this rule
can integrate monomials up to ﬁfth order provided that we select u D
p
3,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.9 Higher Order Cubature/Unscented Kalman Filters
163
W0 D 1 C .n2   7n/=18, W1 D .4   n/=18, and W2 D 1=36. This leads to
the following integration method.
Algorithm 8.21 (Fifth order cubature/unscented integration). The ﬁfth or-
der spherical cubature/unscented approximation to the multi-dimensional
integral
Z
g.x/ N.x j m; P/ dx
(8.101)
can be computed as follows.
1. Compute the unit sigma points as
.0/ D 0;
.i/ D i’th vector in symmetric set Œ
p
3;
.iC2n/ D i’th vector in symmetric set Œ
p
3;
p
3:
(8.102)
2. Compute the weights as
W0 D 1 C .n2   7n/=18;
Wi D .4   n/=18;
i D 1; : : : ; 2n;
WiC2n D 1=36;
i D 1; 2; : : : :
(8.103)
3. Approximate the integral as
Z
g.x/ N.x j m; P/ dx 
X
i
Wi g.m C
p
P .i//;
(8.104)
where
p
P is a matrix square root deﬁned by P D
p
P
p
P
T.
A disadvantage of this rule is that it leads to negative weights when
n  5. This is a typical challenge with higher order symmetric rules and
can lead to non-positive deﬁnite covariance matrices and hence unstable
ﬁlters.
If we use this rule in the Gaussian ﬁlter (Algorithm 8.3), we obtain the
following ﬁfth order cubature/unscented Kalman ﬁlter for additive noise
models. The non-additive version could be derived similarly, as we did for
the CKF.
Algorithm 8.22 (Fifth order cubature/unscented Kalman ﬁlter). The addi-
tive form of the ﬁfth order cubature/unscented Kalman ﬁlter (UKF5) algo-
rithm is the following.
 Prediction:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
164
General Gaussian Filtering
1. Form the sigma points as:
X .i/
k 1 D mk 1 C
p
Pk 1 .i/;
i D 0; 1; 2; : : : ;
(8.105)
where the unit sigma points are deﬁned by Equation (8.102).
2. Propagate the sigma points through the dynamic model:
OX .i/
k
D f.X .i/
k 1/;
i D 0; 1; 2; : : : :
(8.106)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
X
i
Wi OX .i/
k ;
P  k D
X
i
Wi . OX .i/
k
  m k / . OX .i/
k
  m k /T C Qk 1;
(8.107)
where the weights Wi are given by Equation (8.103).
 Update:
1. Form the sigma points:
X  .i/
k
D m k C
q
P  k .i/;
i D 0; 1; 2; : : : ;
(8.108)
where the unit sigma points are deﬁned as in Equation (8.102).
2. Propagate sigma points through the measurement model:
OY.i/
k
D h.X  .i/
k
/;
i D 0; 1; 2; : : : :
(8.109)
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
X
i
Wi OY.i/
k ;
Sk D
X
i
Wi . OY.i/
k   k/ . OY.i/
k   k/T C Rk;
Ck D
X
i
Wi .X  .i/
k
  m k / . OY.i/
k   k/T;
(8.110)
where the weights Wi are deﬁned as in (8.103).
4. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(8.111)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
8.9 Higher Order Cubature/Unscented Kalman Filters
165
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
UKF5 estimate
Figure 8.7 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the UKF5
(Example 8.23). The resulting RMSE was 0:10 which is the same
as that of GHKF and UKF.
It would also be possible to derive higher order ﬁlters in this class by
applying the higher order rules given in McNamee and Stenger (1967). In
fact, by simply changing the weights and unit sigma points in the above
algorithm, it can serve as a prototype of implementing ﬁlters using an arbi-
trary integration rule having this form (e.g., McNamee and Stenger, 1967;
Ito and Xiong, 2000; Julier et al., 2000; Wu et al., 2006; Arasaratnam and
Haykin, 2009; S¨arkk¨a et al., 2016; Karvonen et al., 2019).
Example 8.23 (Pendulum tracking with UKF5). The result of applying the
UKF5 to the pendulum model and simulated data in Example 7.6 is shown
in Figure 8.7. The resulting RMSE of 0:10 is practically the same as for the
GHKF and UKF.
Example 8.24 (Coordinated turn model with UKF5). Figure 8.8 shows the
result of applying ﬁfth order cubature/unscented Kalman ﬁlter (UKF5) to
the coordinated turn model introduced in Example 7.7. The result is similar
to the results of the GHKF, CKF, and UKF with RMSE of 0:30.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
166
General Gaussian Filtering
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
EKF estimate
UKF5 estimate
Sensors
Figure 8.8 The result of applying the ﬁfth order
cubature/unscented Kalman ﬁlter to the coordinated turn model.
The result is practically the same as with the other numerical
integration ﬁlters.
8.10 Exercises
8.1
Show that the selection  D 3   n in Equation (8.67) causes fourth order
terms 4
i to be integrated exactly when m D 0 and P D I. What happens to
the weights if n > 3?
8.2
Show that when the function is linear, both the unscented transform and the
spherical cubature integration rule give the exact result.
8.3
Show that one-dimensional Hermite polynomials are orthogonal with re-
spect to the inner product
hf; gi D
Z
f .x/ g.x/ N.x j 0; 1/ dx:
(8.112)
8.4
Show that multivariate Hermite polynomials deﬁned as
Hi1;:::;in.x/ D Hi1.x1/      Hin.xn/
(8.113)
are orthogonal with respect to the inner product
hf; gi D
Z
f .x/ g.x/ N.x j 0; I/ dx:
(8.114)
8.5
Implement a GHKF for the model in Exercise 7.1. Plot the results and com-
pare the RMSE values with the EKF.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
167
8.6
Write down the cubature transform, that is, the moment transformation re-
sulting from approximating the integrals in Algorithm 8.1 with spherical
cubature integration in Algorithm 8.10.
8.7
Implement a CKF and UKF for the model in Exercise 7.1. Plot the results and
compare the RMSE values with the EKF and GHKF. Can you ﬁnd parameter
values for the methods that cause the UKF, GHKF, and CKF methods to
become identical?
8.8
Implement a CKF for the bearings-only target tracking problem in Exer-
cise 7.2. Compare the performance with the EKF.
8.9
Implement a UKF for the Cartesian coordinated turn model in Equa-
tions (4.61) and (4.90) with a linear position measurement model. Also
compare its performance with the EKF in Exercise 7.8.
8.10
Check numerically, by comparing to the closed form expressions for inte-
grals of polynomials, that the integration rules introduced in Sections 8.5
and 8.7 are exact (only) up to third order and the rule in Section 8.9 up to
ﬁfth order.
8.11
Implement the ﬁfth order ﬁlter in Algorithm 8.22 to the model in Exer-
cise 7.1. Compare its performance with the other ﬁlters.
8.12
Write down the ﬁfth order unscented transform, that is, the moment trans-
formation resulting from approximating the integrals in Algorithm 8.1 with
the ﬁfth order integration rule in Algorithm 8.21.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9
Gaussian Filtering by Enabling
Approximations
We have already seen several Gaussian ﬁlters for ﬁltering in non-linear sys-
tems, with different premises and motivations. In Chapter 7 we encountered
extended Kalman ﬁlters (EKFs), which ﬁrst linearize the dynamic and mea-
surement models and then apply a Kalman ﬁlter to the linearized model. In
Chapter 8 we looked into moment matching-based Gaussian ﬁlters, which
compute the integrals needed in the moment matching using numerical in-
tegration. It turns out that the moment matching-based Gaussian ﬁlters can
also be viewed as different strategies to linearize measurement and dy-
namic models (Lefebvre et al., 2002; Arasaratnam et al., 2007; Tronarp
et al., 2018). We refer to these linearizations as enabling approximations
since they enable us to use the closed-form Kalman ﬁlter prediction and
update equations. In fact, most ﬁlters that recursively approximate the pos-
terior as Gaussian share this property, which means that they combine two
steps:
1. Approximate measurement and dynamic models as linear (or afﬁne)
with additive Gaussian noise.
2. Use the Kalman ﬁlter equations to perform prediction and update.
Perhaps the simplest example is the EKF, which performs a ﬁrst order Tay-
lor expansion of both models. In this chapter, we elaborate on this per-
spective and explain why all the Gaussian ﬁlters presented earlier arguably
contain the above two steps (sometimes implicitly). Considering that the
second step is identical for all ﬁlters, the main difference between different
ﬁlters is how the models are linearized. Understanding the Gaussian ﬁlters
in terms of these enabling approximations provides a unifying perspective,
sheds new light on the family of Gaussian ﬁlters, and enables us to de-
velop new ﬁlters, such as posterior linearization ﬁlters which we discuss in
Chapter 10.
168

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.1 Enabling Linearization
169
9.1 Enabling Linearization
Let us again take a look at ﬁltering in non-linear Gaussian models of the
form
xk D f.xk 1/ C qk 1;
qk 1  N.0; Qk 1/;
yk D h.xk/ C rk;
rk  N.0; Rk/;
(9.1)
which we already considered in Chapters 7 and 8. Let us now assume for
a while that we have some way to approximate this state space model as
afﬁne1 and Gaussian:
xk ' Ak 1 xk 1 C ak 1 C Qek 1;
yk ' Hk xk C bk C Qvk;
(9.2)
where Qek 1  N.0; ƒk 1/ and Qvk  N.0; k/, whereas Ak 1 and Hk
are constant matrices, and ak 1 and bk are constant vectors. If the noise
covariances ƒk 1 and k are full rank, we can also express Equation (9.2)
in terms of conditional probability density functions
p.xk j xk 1/ ' N.xk j Ak 1 xk 1 C ak 1; ƒk 1/;
p.yk j xk/ ' N.yk j Hk xk C bk; k/:
(9.3)
Once we have introduced the approximations in Equation (9.2), the pre-
diction and update steps have simple, closed-form expressions given by the
afﬁne Kalman ﬁlter in Theorem 6.9.
Algorithm 9.1 (Gaussian ﬁltering with enabling linearizations). The pre-
diction and update steps of a Gaussian ﬁlter for computing the ﬁltering
means mk and covariances Pk that makes use of enabling linearizations
are:
 Prediction: Find Ak 1, ak 1, and ƒk 1 such that
xk ' Ak 1 xk 1 C ak 1 C Qek 1;
(9.4)
where Qek 1  N.0; ƒk 1/. Compute the predicted moments
m k D Ak 1 mk 1 C ak 1;
P  k D Ak 1 Pk 1 AT
k 1 C ƒk 1:
(9.5)
 Update: Find Hk, bk, and k such that
yk ' Hk xk C bk C Qvk;
(9.6)
1 Recall that A x C a is an afﬁne function in x for all values of a but that it is only linear
if a D 0.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
170
Gaussian Filtering by Enabling Approximations
where Qvk  N.0; k/. Compute the updated moments
k D Hk m k C bk;
Sk D Hk P  k HT
k C k;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(9.7)
It is easy to verify that both the EKF and the IEKF are examples of Algo-
rithm 9.1 for models with additive and non-additive noise. Let us verify this
in the additive noise case, that is, when the state space model takes the form
of Equation (9.1). The prediction step is identical in the EKF and the IEKF,
and they both use Ak 1 D Fx.mk 1/, ak 1 D f.mk 1/ Fx.mk 1/ mk 1
and ƒk 1 D Qk 1. This corresponds to a ﬁrst order Taylor expansion of
fk 1.xk 1/ at xk 1 D mk 1:
f.xk 1/ ' f.mk 1/ C Fx.mk 1/ .xk 1   mk 1/:
(9.8)
In the update step, both ﬁlters rely on a ﬁrst order Taylor expansion of
h.xk/. Introducing Nmk as the linearization point, both ﬁlters use Hk D
Hx. Nmk/, bk D h. Nmk/   Hx. Nmk/ Nmk and k D Rk. The difference is
that the EKF linearizes h.xk/ at the predicted mean Nmk D m k , whereas
the IEKF seeks to set Nmk to the maximum a posteriori estimate of xk.
Taylor expansions such as Equation (9.8) are commonly used in the
literature, but the enabling approximations of the form of Equation (9.2)
are more ﬂexible than that. To start with, we may want to approximate
f.xk 1/ and h.xk/ accurately for a range of values, which means that the
Taylor expansion may not be optimal. Also, even though these functions
are deterministic, we are free to select the noise covariances ƒk 1 and k
larger than the original noise covariances Qk 1 and Rk to acknowledge
errors introduced when linearizing f.xk 1/ and h.xk/.
In this chapter, we consider three families of probabilistic state space
models. Apart from the additive noise models as in Equation (9.1), we also
study models with non-additive Gaussian noise:
xk D f.xk 1; qk 1/;
qk 1  N.0; Qk 1/;
yk D h.xk; rk/;
rk  N.0; Rk/:
(9.9)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.2 Statistical Linearization
171
We also consider a third formulation where the model is expressed in terms
of conditional probability distributions:
xk  p.xk j xk 1/;
yk  p.yk j xk/:
(9.10)
This general formulation enables us to handle models that are inconvenient
to express using Equations (9.1) or (9.9).
In this chapter (and the next), we describe principles for selecting the
enabling approximations in Equation (9.2) and explain how they can be
applied to each of the above families of models. As we will see, some of
these principles give rise to ﬁlters that are identical to the general Gaussian
ﬁlters in Chapter 8, whereas other principles give rise to new ﬁlters.
9.2 Statistical Linearization
Statistical linearization (SL, see, e.g., Gelb, 1974) is a type of linearization
that can be used in Algorithm 9.1 for models with additive or non-additive
noise, where the relation between two random variables x and y is approx-
imated as afﬁne and noise free, y ' A x C b.
Deﬁnition 9.2 (Statistical linearization). If x and y are two random vari-
ables, y ' A x C b is called a statistical linearization if A and b are
selected to minimize the mean squared error (MSE)
MSE.A; b/ D E

.y   A x   b/T.y   A x   b/

;
(9.11)
where the matrix A and the vector b are deterministic variables.
Theorem 9.3 (Statistical linearization I). Suppose x and y are two random
variables and that m D EŒx, P D CovŒx, S D EŒy, and CS D
CovŒx; y. The approximation y ' A x C b minimizes the mean squared
error (MSE)
MSE.A; b/ D E

.y   A x   b/T .y   A x   b/

(9.12)
when
A D CT
S P  1;
b D S   A m:
(9.13)
Proof
The result follows from setting the derivatives of MSE.A; b/ with
respect to A and b to zero.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
172
Gaussian Filtering by Enabling Approximations
Corollary 9.4 (Gaussian approximation from statistical linearization).
When x  N.m; P/, S D EŒy, and CS D CovŒx; y, the statistical
linearization y ' A x C b gives rise to a Gaussian approximation
x
y

 N
m
S

;
 P
CS
CT
S
SS

;
(9.14)
where SS D A P AT.
Proof
We obtain this result from Theorem 9.3 by combining the expres-
sions for A and b with y ' A x C b. We get, for instance, CovŒx; A x C
b D CovŒx; x AT D CS.
To make statistical linearization somewhat more concrete, let us deﬁne
the random variable y as follows:
x  N.m; P/;
y D g.x/;
(9.15)
which corresponds the transformation problem ﬁrst considered in
Section 7.1 and later in Chapter 8. The statistical linearization for
Equation (9.15) is given in Corollary 9.5.
Corollary 9.5 (Statistical linearization II). The approximation g.x/ '
A x C b, with x and g.x/ deﬁned in Equation (9.15), minimizes the mean
squared error
MSE.A; b/ D E

.g.x/   A x   b/T .g.x/   A x   b/

(9.16)
when
A D EŒ.x   m/ g.x/TT P  1;
b D EŒg.x/   A m;
(9.17)
where all expected values are taken with respect to x  N.m; P/.
Proof
The result is a special case of Theorem 9.3. Speciﬁcally, for y D
g.x/ the expressions in (9.17) follow from (9.13) since S D EŒy D
EŒg.x/ and
CS D EŒ.x   m/ .g.x/   EŒg.x//T
D EŒ.x   m/ g.x/T C EŒ.x   m/
„
ƒ‚
…
D0
EŒg.x/T D EŒ.x   m/ g.x/T:
(9.18)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.2 Statistical Linearization
173
Note that EŒ.x   m/ g.x/TT D EŒg.x/ .x   m/T, which is used to
simplify and rewrite several of the expressions below.
We can now form an approximation to an additive transform analogously
to the previous chapters but now by using the statistical linearization ap-
proximation.
Corollary 9.6 (Statistical linearization of an additive transform). When
x  N.m; P/ and y D g.x/Cq with q  N.0; Q/, statistical linearization
gives rise to a Gaussian approximation
x
y

 N
m
S

;
 P
CS
CT
S
SS

;
(9.19)
where
S D EŒg.x/;
SS D EŒg.x/ .x   m/T P  1 EŒ.x   m/ g.x/T C Q;
CS D EŒ.x   m/ g.x/T;
(9.20)
with the expectations taken with respect to x  N.m; P/.
Proof
This results directly from Corollary 9.4.
It is now useful to compare the approximation above to the moment
matching approximation in Algorithm 8.1. We can rewrite the above ex-
plicitly in terms of integrals as follows:
S D
Z
g.x/ N.x j m; P/ dx;
SS D
Z
.g.x/   S/ .x   m/T N.x j m; P/ dx

P  1

Z
.x   m/ .g.x/   S/T N.x j m; P/ dx

C Q;
CS D
Z
.x   m/ .g.x/   S/T N.x j m; P/ dx:
(9.21)
By comparing to Equation (8.4) we see that we indeed have S D M
and CS D CM, but SS ¤ SM. In fact, we always have SS  SM, that
is, the approximation to the covariance of y produced by SL is generally
smaller than the approximation produced by moment matching, and thus it
is likely to underestimate the uncertainty in y. This is a problem caused the
deterministic approximation used by SL, and we come back to a solution
to this problem in Section 9.4 by introducing statistical linear regression
(SLR), which can be seen as stochastic version of SL.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
174
Gaussian Filtering by Enabling Approximations
Statistical linearization for additive noise models is closely related to a
ﬁrst order Taylor expansion. If the function g.x/ is differentiable, we can
use the following well-known property of Gaussian random variables to
highlight the similarities:
E

g.x/ .x   m/T
D E ŒGx.x/ P;
(9.22)
where EŒ denotes the expected value with respect to x  N.m; P/, and
Gx.x/ is the Jacobian matrix of g.x/. Given this result, the matrix in the
SL simpliﬁes to
A D EŒg.x/ .x   m/T P  1 D E ŒGx.x/ :
(9.23)
Using this expression, the similarities between a ﬁrst order Taylor expan-
sion
g.x/ ' Gx.m/ .x   m/ C g.m/
(9.24)
and an SL
g.x/ ' EŒGx.x/ .x   m/ C EŒg.x/
(9.25)
become even more evident. That is, the Taylor expansion uses the Jacobian
Gx.EŒx/ whereas SL uses EŒGx.x/, and where the Taylor expansion uses
g.EŒx/, SL uses EŒg.x/.
Example 9.7 (Statistical linearization). Let us compare a ﬁrst order Taylor
expansion about x D 1 with two different statistical linearizations (SLs)
of a scalar function g.x/ D x3. In this example, the SLs assume that
x  N.m; P / where m D 1, but the ﬁrst SL uses P D 0:1 whereas the
second uses P D 1. We can obtain the SLs by computing the integrals
A D EŒGx.x/
D
Z
3x2 N.x j m; P / dx;
 D
Z
x3 N.x j m; P / dx
(9.26)
and then setting g.x/ ' A .x   m/ C .
The involved functions are illustrated in Figure 9.1. As can be seen, the
SL with P D 0:1 is similar to the Taylor expansion, and they are both
accurate near x D m D 1. The SLs are optimal on average (in the MSE
sense) when x is distributed as N.m; P /, and the SL with P D 1 seeks
to approximate g.x/ D x3 for a larger range of x values. We note that

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.2 Statistical Linearization
175
-1
0
1
2
3
4
x
-20
0
20
40
60
80
g(x)
1st order Taylor
SL, P = 0.1
SL, P = 1
(a)
-1
0
1
2
3
4
x
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
m = 1, P = 0.1
m = 1, P = 1
(b)
Figure 9.1 (a) The function g.x/ D x3 and the three statistical
linearizations in Example 9.7. (b) The two prior densities.
all three linearizations are different even though they are all performed
around x D 1.
We can also use SL as an enabling approximation for the non-additive
models in (9.9), that is, to approximate f.xk 1; qk 1/ and h.xk; rk/. To
describe the method, suppose x  N.m; P/ and q  N.0; Q/ are indepen-
dent random variables and that we would like to approximate g.x; q/. It is
possible to directly use SL and Theorem 9.3 to ﬁnd g.x; q/ ' A x C b. In
this case, the noise q may inﬂuence how we select A and b, but A x C b is
still a deterministic function, and it is generally undesirable to approximate
the dynamic or measurement models as noise free.
A more suitable approach is to introduce
z D
x
q

(9.27)
and to ﬁnd an SL
y ' Az z C b
D
 A
Aq x
q

C b
D A x C Aq q C b;
(9.28)
where Az D
 A
Aq
. Here Aq q represents the additive noise which
means that the approximation in (9.28) is not noise free. For instance, with

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
176
Gaussian Filtering by Enabling Approximations
this approach, SL of the dynamic model yields an approximation
f.xk 1; qk 1/ ' A xk 1 C Aq qk 1 C ak 1:
(9.29)
Setting Qek 1 D Aq qk 1  N.0; Aq Qk 1 .Aq/T/ implies that ƒk 1 D
Aq Qk 1 .Aq/T.
The approximation g.x; q/ ' A x C Aq q C b is called a statistical lin-
earization if A, Aq, and b are selected to minimize the MSE, as described
in Corollary 9.8.
Corollary
9.8
(Statistical
linearization
III).
The
approximation
y D g.x; q/ ' A x C Aq q C b minimizes the MSE
MSE.A; Aq; b/ D E

.g.x; q/   A x   Aq q   b/T
 .g.x; q/   A x   Aq q   b/

(9.30)
when
A D CovŒy; x P  1 D EŒg.x; q/ .x   m/T P  1;
Aq D CovŒy; q Q 1 D EŒg.x; q/ qT Q 1;
b D EŒg.x; q/   A m;
(9.31)
where all expected values are taken with respect to x  N.m; P/, and
q  N.0; Q/.
Proof
The corollary follows from Theorem 9.3, see Exercise 9.10 for
details.
Statistical linearization of g.x/ can also be seen as the ﬁrst order
Fourier–Hermite series expansion of the function (Sarmavuori and S¨arkk¨a,
2012) with respect to the Gaussian distribution x  N.m; P/. This point
of view enables the extension of statistical linearization to quadratic
approximations and beyond, but these approximations are not discussed
here in detail.
9.3 Statistically Linearized Filter
A ﬁlter that uses statistical linearization as an enabling approximation is
called a statistically linearized ﬁlter (SLF). An SLF (Gelb, 1974), or quasi-
linear ﬁlter (Stengel, 1994), is similar to the EKF, except that statistical
linearizations are used instead of the Taylor series approximations.
If we use the SL in Corollary 9.5 for the additive noise model in Equa-
tion (9.1) and combine it with Algorithm 9.1, we obtain the following al-
gorithm.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.3 Statistically Linearized Filter
177
Algorithm 9.9 (Statistically linearized ﬁlter I). The prediction and update
steps of the additive noise statistically linearized (Kalman) ﬁlter for the
model in Equation (9.1) are:
 Prediction:
m k D EŒf.xk 1/;
P  k D EŒf.xk 1/ ıxT
k 1 P  1
k 1 EŒf.xk 1/ ıxT
k 1T C Qk 1;
(9.32)
where ıxk 1 D xk 1 mk 1 and the expectations are taken with respect
to the variable xk 1  N.mk 1; Pk 1/.
 Update:
k D EŒh.xk/;
Sk D EŒh.xk/ ıQxT
k .P  k / 1 EŒh.xk/ ıQxT
kT C Rk;
Kk D EŒh.xk/ ıQxT
kT S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k;
(9.33)
where ıQxk D xk   m k and the expectations are taken with respect to
the variable xk  N.m k ; P  k /.
We can also combine Corollary 9.8 with Algorithm 9.1 to obtain the
statistically linearized ﬁlter for the non-additive noise models in (9.9).
Algorithm 9.10 (Statistically linearized ﬁlter II). The prediction and up-
date steps of the non-additive-noise statistically linearized (Kalman) ﬁlter
for the model in Equation (9.9) are:
 Prediction:
m k D EŒf.xk 1; qk 1/;
P  k D EŒf.xk 1; qk 1/ ıxT
k 1 P  1
k 1 EŒf.xk 1; qk 1/ ıxT
k 1T
C EŒf.xk 1; qk 1/ qT
k 1 Q 1
k 1 EŒf.xk 1; qk 1/ qT
k 1T;
(9.34)
where ıxk 1 D xk 1 mk 1 and the expectations are taken with respect
to the variables xk 1  N.mk 1; Pk 1/ and qk 1  N.0; Qk 1/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
178
Gaussian Filtering by Enabling Approximations
 Update:
k D EŒh.xk; rk/;
Sk D EŒh.xk; rk/ ıQxT
k .P  k / 1 EŒh.xk; rk/ ıQxT
kT
C EŒh.xk; rk/ rT
k R 1
k
EŒh.xk; rk/ rT
kT;
Kk D EŒh.xk; rk/ ıQxT
kT S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k;
(9.35)
where ıQxk D xk   m k and the expectations are taken with respect to
the variables xk  N.m k ; P  k / and rk  N.0; Rk/.
The advantage of the SLF over the EKF is that it is a more global ap-
proximation than the EKF, because the linearization is not only based on
the local region around the mean but on a whole range of function values
(see (9.24) and (9.25) for a comparison between a Taylor expansion and
SL in the additive noise case). In addition, the non-linearities do not have
to be differentiable since the expressions in our ﬁlters do not involve Ja-
cobians. However, if the non-linearities are differentiable, then we can use
the Gaussian random variable property in (9.22) to rewrite the equations in
an EKF-like form, as indicated by (9.23).
An important disadvantage with the SLF described above is that the ex-
pected values of the non-linear functions have to be computed in closed
form. Naturally, this is not possible for all functions. Fortunately, the ex-
pected values involved are of such a type that one is likely to ﬁnd many of
them tabulated in older physics and control engineering books (see, e.g.,
Gelb and Vander Velde, 1968). Also, when the expected values do not have
closed-form expressions, we can instead use a Gaussian quadrature tech-
nique, such as those presented in Chapter 8, see Exercise 9.3 for an exam-
ple. However, if we are willing to compute the expectations numerically
anyway, it is better to use statistical linear regression instead, which we
discuss next.
9.4 Statistical Linear Regression
Statistical linearization (SL) provides a deterministic approximation to the
relation between two random variables x and y. However, even if y D
g.x/, such that the true relation between x and y is deterministic, it can still
be valuable to approximate the relation as an afﬁne function with Gaussian
noise, to reﬂect the fact that we have introduced errors when approximating

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.4 Statistical Linear Regression
179
the function as afﬁne. Additionally, in Section 9.2 from Equations (9.21)
we also saw that the deterministic approximation produced by SL failed to
match the moment matching approximation for stochastic transformation
of the form y D g.x/ C q for the covariance of y, which is sometimes a
problem.
In this section, we describe statistical linear regression (SLR), which is
an enabling approximation that includes a strategy for selecting the noise
covariance (Arasaratnam et al., 2007) accounting for the approximation
error. The fact that SLR does not yield a deterministic approximation
makes it suitable for combination with all the considered model families
(see Equations (9.1), (9.9), and (9.10)). It also resolves the aforementioned
problem of approximating the covariance of y properly.
In SLR, the afﬁne approximation is selected as in a statistical lineariza-
tion, and the noise covariance is the covariance of the approximation error.
Deﬁnition 9.11 (Statistical linear regression). If x and y are two random
variables, y ' A x C b C Qe, Qe  N.0; ƒ/ is called a statistical linear
regression if A and b are selected to minimize the mean squared error
MSE.A; b/ D E

.y   A x   b/T .y   A x   b/

;
(9.36)
where A and b are deterministic variables, whereas the noise covariance
is selected as
ƒ D E

.y   A x   b/ .y   A x   b/T
:
(9.37)
Theorem 9.12 (Statistical linear regression I). Suppose x and y are two
random variables, and let m D EŒx, P D CovŒx, R D EŒy, SR D
CovŒy, and CR D CovŒx; y. In the statistical linear regression (SLR),
y ' A x C b C Qe, Qe  N.0; ƒ/, we then have
A D CT
R P  1;
b D R   A m;
ƒ D SR   A P AT:
(9.38)
Proof
The expressions for A and b follow from Theorem 9.3. The ex-
pression for ƒ follows from its deﬁnition
ƒ D CovŒy   A x   b
D E

.y   R   A .x   m// .y   R   A .x   m//T
D CovŒy C A P AT   A CR   CT
R AT
D SR   A P AT;
(9.39)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
180
Gaussian Filtering by Enabling Approximations
where R D EŒy, and the last equality follows from CR D P AT.
To understand why the SLR selects the noise covariance using (9.37),
we note that this preserves the ﬁrst two moments of the joint distribution
of x and y:
Corollary 9.13 (Gaussian approximation from SLR). When x  N.m; P/,
R D EŒy, CR D CovŒx; y, and SR D CovŒy, the statistical lineariza-
tion y ' A xCbC Qe, Qe  N.0; ƒ/ gives rise to a Gaussian approximation
x
y

 N
 m
R

;
 P
CR
CT
R
SR

:
(9.40)
Proof
We know that y ' A x C b C Qe is Gaussian when x and Qe are
Gaussian, and it follows from Theorem 9.12 that
E

x
A x C b C Qe

D

m
A m C b

D
 m
R

;
Cov

x
Ax C b C Qe

D
 P
P AT
A P
A P AT C ƒ

D
 P
CR
CT
R
SR

:
(9.41)
Importantly, when x  N.m; P/, the SLR approximates the joint dis-
tribution of x and y as Gaussian where the ﬁrst two moments match the
original joint distribution. When applied to a transformation of the form
y D g.x/ C q, q  N.0; Q/, the SLR approximation exactly reproduces
the moment matching approximation in Algorithm 8.1 as can be seen from
the following.
Corollary 9.14 (SLR of an additive transform). Suppose y D g.x/ C q,
where x  N.m; P/ and q  N.0; Q/. The SLR forms the approximation
y ' A x C b C Qe, Qe  N.0; ƒ/, where, as in Equation (9.38), we have
A D CT
R P  1;
b D R   A m;
ƒ D SR   A P AT;
(9.42)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.4 Statistical Linear Regression
181
where
R D
Z
g.x/ N.x j m; P/ dx;
CR D
Z
.x   m/ .g.x/   R/T N.x j m; P/ dx;
SR D
Z
.g.x/   R/ .g.x/   R/T N.x j m; P/ dx C Q:
(9.43)
Furthermore, the corresponding joint Gaussian approximation for .x; y/
is given by
x
y

 N
 m
R

;
 P
CR
CT
R
SR

:
(9.44)
As we can see, the expressions for R, CR, and SR in Equation (9.43)
are identical to the expressions for M, CM, and SM in Equation (8.4).
SLR therefore provides the same approximation to .x; y/ as the Gaussian
moment matching approach used in Chapter 8 with R D M, CR D CM,
and SR D SM. This also implies that all the numerical integration methods
such as Gauss–Hermite and spherically symmetric cubature methods can
be used to numerically compute the integrals in Equations (9.43) in the
same way as we did in Chapter 8.
To compare the SLR approximation y ' A xCbC Qe, Qe  N.0; ƒ/ with
the SL approximation y ' A x C b, we note that A and b are identical in
both approximations. The difference is that the SLR includes the additional
noise Qe, which represents the errors introduced when approximating y as an
afﬁne function of x. In terms of the Gaussian approximations of .x; y/ that
SL and SLR provide (see Corollaries 9.4 and 9.13), it holds that R D S
and CR D CS. Considering that SS D A P AT and SR D A P AT C ƒ, it
follows that SR  SS, because the error covariance ƒ is always positive
semi-deﬁnite. That is, compared to SL, SLR introduces an additional noise
to ensure that the approximation of .x; y/ matches the original moments.
When we construct an enabling approximation of y D g.x/ C q using
SL, we ﬁrst obtain A and b by performing SL on g.x/, and we then select
ƒSL D Q. Note that SL is only used to approximate g.x/ and that the noise
is simply added to the SL approximation. Using SLR we directly linearize
y D g.x/ C q ' A x C b C Qe, Qe  N.0; ƒ/. We obtain the same A and b
as the SL, but the noise covariance is different, ƒ ¤ ƒSL. Since q has zero
mean and x and q are independent, it follows that
ƒ D EŒ.g.x/ C q   A x   b/ .g.x/ C q   A x   b/T
D EŒ.g.x/   A x   b/ .g.x/   A x   b/T C Q:
(9.45)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
182
Gaussian Filtering by Enabling Approximations
Since ƒSL D Q, we conclude that SLR adds the matrix EŒ.g.x/   A x  b/ .g.x/   A x   b/T to the noise covariance used by SL. Note that this
additional term represents the errors introduced when approximating g.x/
as afﬁne.
Although SLR yields the same Gaussian approximation to .x; y/ as the
moment matching approach in Chapter 8, it is still useful in its own right.
First, we obtain a uniﬁed description of all our Gaussian ﬁlters as different
types of linearizations of state space models. Second, the SLR perspective
provides insights that can be used to develop further linearizations and
ﬁlters as we see in Chapter 10.
To illustrate the differences between SLR and SL, we can consider an
example without additional noise.
Example 9.15 (Statistical linear regression). Let us return to the functions
and random variables in Example 9.7. If we wish to perform SLR on the
same random variables, and ﬁnd y D g.x/ D x3 ' A x C b C e, e 
N.0; ƒ/, we would obtain the functions A x C b illustrated in Figure 9.1,
since A and b are identical in SL and SLR.
In contrast to SL, SLR also contains a noise term e  N.0; ƒ/. In this
particular example, the noise term has the standard deviation
p
ƒ  4:86
when P D 1 and
p
ƒ  0:43 when P D 0:1. We note that the error is
smaller when P is smaller. The reason for this is that ƒ is the variance of
g.x/   A x   b when x  N.m; P /, and that error is generally smaller
closer to m. In fact, as P ! 0, both the SL and the SLR converge to the
noise-free ﬁrst order Taylor expansion y  g.m/ C Gx.m/ .x   m/.
We can also use SLR for models with non-additive noise (9.9) and with
conditional distributions (9.10). For these models, we can formulate ex-
pressions for R, CR, and SR directly from their deﬁnitions, but we also
use conditional moments (Tronarp et al., 2018) to ﬁnd alternative expres-
sions for them; for additive noise models both versions are identical.
Let us now assume that instead of a functional relationship such as y D
g.x/ C q, we have only been given a conditional distribution p.y j x/.
Although this distribution can be arbitrarily complicated and non-Gaussian
(cf. Chapter 5), we can still often compute its conditional moments
R.x/ D EŒy j x D
Z
y p.y j x/ dy;
SR.x/ D CovŒy j x D
Z
.y   R.x// .y   R.x//T p.y j x/ dy:
(9.46)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.4 Statistical Linear Regression
183
For example, when y D g.x/ C q with q  N.0; Q/, we have R.x/ D
g.x/ and SR.x/ D Q. SLR can be reformulated in terms of the conditional
moments as follows.
Theorem 9.16 (Conditional moments form of SLR joint moments). In the
statistical linear regression (SLR), see Theorem 9.12, the moments R, CR,
and SR can be expressed as functions of the conditional moments R.x/ D
EŒy j x and SR.x/ D CovŒy j x as follows:
R D EŒR.x/;
CR D EŒ.x   m/ .R.x/   R/T;
SR D CovŒR.x/ C EŒSR.x/:
(9.47)
Proof
The relation R D EŒR.x/ is a direct consequence of the law of
iterated expectations (LIE): EŒy D EŒEŒy j x. Combining LIE with the
deﬁnition of CR gives
CR D EŒEŒ.x   m/ .y   R/T j x
D EŒ.x   m/ .R.x/   R/T:
(9.48)
Finally, we can use LIE to derive the expression for SR as follows:
SR D EŒEŒ.y   R/ .y   R/T j x
D EŒEŒ.y   R.x/ C R.x/   R/ .y   R.x/ C R.x/   R/T j x
D EŒEŒ.y   R.x// .y   R.x//T j x
C EŒEŒ.R.x/   R/ .R.x/   R/T j x
D EŒSR.x/ C CovŒR.x/:
(9.49)
To obtain enabling approximations for the non-additive noise models in
(9.9), we show how to perform SLR on y  g.x; q/, q  N.0; Q/.
Corollary 9.17 (Non-additive transform in conditional moment form). Let
y D g.x; q/, where x  N.m; P/ and q  N.0; Q/ are independent
random variables. The SLR, y ' A x C b C Qe, Qe  N.0; ƒ/, is given by
(9.38) where R, CR, and SR can be expressed in two different forms. First,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
184
Gaussian Filtering by Enabling Approximations
their deﬁnitions give
R D
Z
g.x; q/ N.x j m; P/ N.q j 0; Q/ dx dq;
CR D
Z
.x   m/ .g.x; q/   R/T N.x j m; P/ N.q j 0; Q/ dx dq;
SR D
Z
.g.x; q/   R/ .g.x; q/   R/T N.x j m; P/ N.q j 0; Q/ dx dq:
(9.50)
Second, from (9.47) it follows that using the conditional moments
R.x/ D
Z
g.x; q/ N.q j 0; Q/ dq;
SR.x/ D
Z
.g.x; q/   R.x// .g.x; q/   R.x//T N.q j 0; Q/ dq;
(9.51)
we get
R D
Z
R.x/ N.x j m; P/ dx;
CR D
Z
.x   m/ .R.x/   R/T N.x j m; P/ dx;
SR D
Z 
.R.x/   R/ .R.x/   R/T N.x j m; P/
C SR.x/ N.x j m; P/

dx:
(9.52)
The expressions in Corollary 9.17 can be used to develop Gaussian ﬁlters
by approximating the integrals in (9.50) or (9.51) and (9.52) using, for
instance, a sigma point method. A potential disadvantage with using (9.51)
and (9.52) is that the integrals are nested and that (9.51) should be evaluated
for every x in (9.52). In comparison, (9.50) jointly integrates over both x
and q.
Finally, the SLR can also used for the conditional distribution models
in (9.10). To this end, we describe the expressions for the variables in
Theorem 9.12 for models with conditional distributions.
Corollary 9.18 (Conditional moments of conditional distributions). Let
x  N.m; P/ and y  p.y j x/. In the SLR, y ' A xCbCQe, Qe  N.0; ƒ/,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.4 Statistical Linear Regression
185
we have A, b, and ƒ as in (9.38), where
R D
Z
y p.y j x/ N.x j m; P/ dy dx;
CR D
Z
.x   m/ .y   R/T p.y j x/ N.x j m; P/ dy dx;
SR D
Z
.y   R/ .y   R/T p.y j x/ N.x j m; P/ dy dx:
(9.53)
We can also express these moments using (9.52), where the conditional
moments are given by
R.x/ D
Z
y p.y j x/ dy;
SR.x/ D
Z
.y   R.x// .y   R.x//T p.y j x/ dy:
(9.54)
It should be noted that the random variable y may also be discrete val-
ued. In that case, the integrals with respect to y in Corollary 9.18 should
be replaced by summations. Also, the integrals with respect to x can be
approximated using Gaussian quadrature methods (such as a sigma point
method), whereas the integrals with respect to y may require other approx-
imations unless p.y j x/ is also Gaussian.
Interestingly, the expressions in (9.52) are valid for all three model fam-
ilies. The difference is that the expressions for the conditional moments
vary. For the additive noise case, we have R.x/ D g.x/ and SR.x/ D Q
(and (9.52) then simpliﬁes to (9.43)); for the non-additive models, these
functions are described in (9.51) and for conditional distributions in (9.54).
The expressions in (9.52) are particularly useful when the conditional mo-
ments have closed form solutions, such as in the following example.
Example 9.19 (SLR with Poisson observations). Let the state x be dis-
tributed as N.m; P /, and suppose exp.x/ represents the size of a popula-
tion. For population models, it is common to assume Poisson-distributed
observations
y  Po.˛ exp.x//:
(9.55)
Recall from Chapter 5 that the probability density (or mass) function of a
Poisson-distributed random variable with parameter .x/ is
Po.y j .x// D exp. .x// .x/y
yŠ
;
(9.56)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
186
Gaussian Filtering by Enabling Approximations
8
9
10
11
12
x
-2500
0
2500
5000
7500
y
Expected value
Quantiles
Figure 9.2 The ﬁgure illustrates y ' A x C b C e in
Example 9.19. The solid line shows A x C b, whereas the dashed
lines show A x C b ˙
p
ƒ, where A x C b is the expected value
of y j x, whereas the quantiles A x C b ˙
p
ƒ represent values
one standard deviation above and below the mean.
and both its mean and variance are .x/. That is, for this model the con-
ditional moments in (9.54) have closed form solutions, and it holds that
.x/ D EŒy j x and Py.x/ are both .x/ D ˛ exp.x/.
Consequently, to perform SLR we can use (9.52) to identify the involved
moments
 D
Z
˛ exp.x/ N.x j m; P / dx;
Pxy D
Z
.x   m/ .˛ exp.x/   / N.x j m; P / dx;
Py D
Z  ˛ exp.x/ C .˛ exp.x/   /2
N.x j m; P / dx:
(9.57)
The above expected values can be approximated numerically or solved
analytically, see Exercise 9.5. From the obtained values, we compute the
linearization parameters A D Pxy=P , b D    A m and ƒ D Py  A2 P . The resulting linearization when m D 10 and P D 0:3 is shown in
Figure 9.2.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.5 Statistical Linear Regression Filters
187
9.5 Statistical Linear Regression Filters
Shortly after the introduction of the unscented Kalman ﬁlter (Julier et al.,
2000), the ﬁlter was re-derived using statistical linear regression (SLR)
(Lefebvre et al., 2002). SLR was later used to re-derive the Gauss–Hermite
Kalman ﬁlter (Arasaratnam et al., 2007). More recently, SLR has also been
used to develop ﬁlters and smoothers for state space models expressed
using conditional moments (Tronarp et al., 2018).
Let us ﬁrst present a naive version of the statistical linear regression
ﬁlter (SLRF) for additive noise models, where we combine Corollary 9.14
with Algorithm 9.1 without any simpliﬁcations. This algorithm will help
us understand and explain several of the upcoming algorithms.
Algorithm 9.20 (Statistical linear regression ﬁlter I). The prediction and
update steps of an additive noise statistical linear regression (Kalman)
ﬁlter for the model in Equation (9.1) are:
 Prediction:
Ak 1 D .P xx
k /T P  1
k 1;
ak 1 D  k   Ak 1 mk 1;
ƒk 1 D P x
k   Ak 1 Pk 1 AT
k 1;
(9.58)
where
 k D
Z
f.x/ N.x j mk 1; Pk 1/ dx;
P xx
k D
Z
.x   mk 1/ .f.x/    k /T N.x j mk 1; Pk 1/ dx;
P x
k D
Z
.f.x/    k / .f.x/    k /T N.x j mk 1; Pk 1/ dx C Qk 1:
(9.59)
Compute the predicted moments
m k D Ak 1 mk 1 C ak 1;
P  k D Ak 1 Pk 1 AT
k 1 C ƒk 1:
(9.60)
 Update:
Hk D .P xy
k /T .P  k / 1;
bk D C
k   Hk m k ;
k D P y
k   Hk P  k HT
k;
(9.61)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
188
Gaussian Filtering by Enabling Approximations
where
C
k D
Z
hk.x/ N.x j m k ; P  k / dx;
P xy
k D
Z
.x   m k / .hk.x/   C
k /T N.x j m k ; P  k / dx;
P y
k D
Z
.h.x/   C
k / .h.x/   C
k /T N.x j m k ; P  k / dx C Rk:
(9.62)
Compute the updated moments
k D Hk m k C bk;
Sk D Hk P  k HT
k C k;
Kk D P  k HT
k S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(9.63)
If we analyse the equations in Algorithm 9.20, we notice that some of
the calculations are redundant. Speciﬁcally, we can show that m k D  k
and P  k D P x
k in the prediction step, and that k D C
k and Sk D P y
k
in the update step. If we also introduce Ck D P xy
k , the algorithm can be
simpliﬁed to the following ﬁlter.
Algorithm 9.21 (Statistical linear regression ﬁlter II). The prediction and
update steps of an additive noise statistical linear regression (Kalman)
ﬁlter for the model in Equation (9.1) are:
 Prediction:
m k D
Z
f.x/ N.x j mk 1; Pk 1/ dx;
P  k D
Z
.f.x/   m k / .f.x/   m k /T N.x j mk 1; Pk 1/ dx C Qk 1:
(9.64)
 Update:
k D
Z
hk.x/ N.x j m k ; P  k / dx;
Ck D
Z
.x   m k / .hk.x/   k/T N.x j m k ; P  k / dx;
Sk D
Z
.h.x/   k/ .h.x/   k/T N.x j m k ; P  k / dx C Rk:
(9.65)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.5 Statistical Linear Regression Filters
189
Compute the updated moments
Kk D Ck S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(9.66)
Importantly, Algorithm 9.21 is identical to Algorithm 8.3, and we have
therefore demonstrated that the general Gaussian ﬁlters derived from Al-
gorithm 8.3 can be viewed as a combination of SLR and Algorithm 9.1.
That is, the general Gaussian ﬁlters for additive noise models presented
in Chapter 8 (e.g., UKF, CKF, GHKF) implicitly use SLR as an enabling
approximation.
We can also use SLR to develop ﬁlters for the non-additive noise mod-
els in Equation (9.9) and for the general conditional distribution models
in Equation (9.10). To modify Algorithm 9.20 to work for non-additive
or conditional models, only the expressions for the moments in Equa-
tions (9.59) and (9.62) change, and the rest of the algorithm remains iden-
tical. Interestingly, if we modify Algorithm 9.21 to handle non-additive
noise, by plugging in the expressions from (9.50), we obtain Algorithm 8.4
after some simpliﬁcations, see Exercise 9.8. That is, both Algorithm 8.3
and 8.4 correspond to SLR ﬁlters, which conﬁrms that all the general Gaus-
sian ﬁlters presented in Chapter 8 implicitly use SLR as an enabling ap-
proximation.
Let us now consider a general model in the form of Equation (9.10),
which is expressed in terms of the conditional distributions describing the
dynamic and measurement models:
xk  p.xk j xk 1/;
yk  p.yk j xk/:
(9.67)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
190
Gaussian Filtering by Enabling Approximations
Further assume that we can compute the following conditional moments
(analytically or numerically):
 k .xk 1/ D E Œxk j xk 1
D
Z
xk p.xk j xk 1/ dxk;
P x
k.xk 1/ D Cov Œxk j xk 1
D
Z
.xk    k .xk 1// .xk    k .xk 1//T p.xk j xk 1/ dxk;
k.xk/ D E Œyk j xk
D
Z
yk p.yk j xk/ dyk;
P y
k.xk/ D Cov Œyk j xk
D
Z
.yk   k.xk// .yk   k.xk//T p.yk j xk/ dyk:
(9.68)
We now get the following SLR-based ﬁlter, which uses the conditional
moments above.
Algorithm 9.22 (Statistical linear regression ﬁlter III). The prediction and
update steps of the conditional moments formulation of the SLR ﬁlter are:
 Prediction:
m k D
Z
 k .xk 1/ N.xk 1 j mk 1; Pk 1/ dxk 1;
P  k D
Z
. k .xk 1/   m k / . k .xk 1/   m k /T
 N.xk 1 j mk 1; Pk 1/ dxk 1
C
Z
P x
k.xk 1/ N.xk 1 j mk 1; Pk 1/ dxk 1:
(9.69)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.5 Statistical Linear Regression Filters
191
 Update:
k D
Z
k.xk/ N.xk j m k ; P  k / dxk;
Ck D
Z
.xk   m k / .k.xk/   k/T N.xk j m k ; P  k / dxk;
Sk D
Z
.k.xk/   k/ .k.xk/   k/T N.xk j m k ; P  k / dxk
C
Z
P y
k.xk/ N.xk j m k ; P  k / dxk:
(9.70)
Compute the updated mean and covariance
Kk D Ck S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(9.71)
For example, in the special case of the non-additive Gaussian noise
model in Equation (9.9), we have
 k .xk 1/ D
Z
f.xk 1; qk 1/ N.qk 1 j 0; Qk 1/ dqk 1;
P x
k.xk 1/ D
Z
.f.xk 1; qk 1/    k .xk 1//
 .f.xk 1; qk 1/    k .xk 1//T
 N.qk 1 j 0; Qk 1/ dqk 1
(9.72)
and
k.xk/ D
Z
h.xk; rk/ N.rk j 0; Rk/ drk;
P y
k.xk/ D
Z
.h.xk; rk/   k.xk// .h.xk; rk/   k.xk//T
 N.rk j 0; Rk/ drk:
(9.73)
The conditional moment formulations arguably give rise to algorithms
with more involved expressions, but they also have some advantages. For
example, to modify Algorithm 9.22 to handle additive or conditional distri-
bution models, we only need to modify (9.72) and (9.73), which is useful
from a software engineering point of view.
In situations when we have conditional distribution models as described
in Equation (9.10) (and (9.67)), but the conditional moments in (9.68) are

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
192
Gaussian Filtering by Enabling Approximations
inconvenient to compute, we can instead use Corollary 9.18 to derive the
following Gaussian ﬁlter.
Algorithm 9.23 (Statistical linear regression ﬁlter IV). The prediction
and update steps of a conditional distribution statistical linear regression
(Kalman) ﬁlter for the model in Equation (9.10) are:
 Prediction:
m k D
Z
xk p.xk j xk 1/ N.xk 1 j mk 1; Pk 1/ dxk dxk 1;
P  k D
Z
.xk   m k / .xk   m k /T
 p.xk j xk 1/ N.xk 1 j mk 1; Pk 1/ dxk dxk 1:
(9.74)
 Update:
k D
Z
ykp.yk j xk/ N.xk j m k ; P  k / dyk dxk;
Ck D
Z
.xk   m k / .yk   k/T
 p.yk j xk/ N.xk j m k ; P  k / dyk dxk;
Sk D
Z
.yk    k / .yk   k/T
 p.yk j xk/ N.xk j m k ; P  k / dyk dxk:
(9.75)
Compute the updated moments
Kk D Ck S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(9.76)
Let us next take a look at how SLR ﬁlters can be implemented using
sigma-point and Monte Carlo approximations.
9.6 Practical SLR Filters
From practical algorithm point of view, the ﬁnal conclusions of this chapter
are a bit dull: to implement SLR ﬁlters, the key issue is to compute the mo-
ments k, Ck, and Sk. Given these moments, we can, in principle, form a
statistical linear regression-based linearization and apply an afﬁne Kalman
ﬁlter. However, it turns out that this procedure is equivalent to just using
these same moments in a Gaussian ﬁlter, which we already introduced in

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.6 Practical SLR Filters
193
Chapter 8, and thus by using methods such as unscented transform, Gauss–
Hermite integration, and spherical cubature integration, we recover the cor-
responding ﬁlters already introduced earlier. Still, during the development
of SLR methods we managed to extend the classes of models that SLR ﬁl-
ters and hence Gaussian ﬁlters can be applied to. In this section, we expand
on the set of Gaussian ﬁlters by introducing tractable versions of some re-
maining SLR ﬁlters.
One of the model classes that we did not consider in the Gaussian ﬁl-
tering chapter is general conditional distribution models of the form given
in Equation (9.10). In order to implement a general form of SLR-based
ﬁltering for these models using numerical integration methods (i.e., sigma-
point methods) as in Chapter 8, we need to have a method to compute the
following conditional moments introduced in Equation (9.68):
 k .xk 1/ D E Œxk j xk 1 ;
P x
k .xk 1/ D Cov Œxk j xk 1 ;
k.xk/ D E Œyk j xk ;
P y
k .xk/ D Cov Œyk j xk :
(9.77)
For example, if the model is of the additive form in Equation (9.1), we have
simple closed form expressions  k .xk 1/ D f.xk 1/, P x
k .xk 1/ D Qk 1,
k.xk/ D h.xk/, and P y
k .xk/ D Rk. For the non-additive models in the
form of Equation (9.9), we can use numerical integration approximations
to the integrals in Equations (9.72) and (9.73) to evaluate them. For many
models with non-Gaussian noise (see Section 5.2), we have either closed
form expressions or accurate approximations of these moments.
Given the moment functions or their approximations, we can construct a
conditional moment-based ﬁlter that uses sigma points and can be used for
state space models of the types in (9.1), (9.9), and (9.10). In the following,
we present that algorithm and express the sigma point method in a generic
form. The unit sigma points .i/ and weights Wi for i D 1; : : : ; m are
determined by the numerical integration method at hand (cf. Chapter 8).
Algorithm 9.24 (Sigma-point conditional moment Kalman ﬁlter). The
sigma point conditional moment Kalman ﬁlter (SPCMKF) is the following.
 Prediction:
1. Form the sigma points as:
X .i/
k 1 D mk 1 C
p
Pk 1 .i/:
i D 1; : : : ; m:
(9.78)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
194
Gaussian Filtering by Enabling Approximations
2. Propagate the sigma points through the conditional mean and covari-
ance functions:
 .i/
k
D  k .X .i/
k 1/;
i D 1; : : : ; m;
P x;.i/
k
D P x
k .X .i/
k 1/;
i D 1; : : : ; m:
(9.79)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
m
X
iD1
Wi  .i/
k
;
P  k D
m
X
iD1
Wi

P x;.i/
k
C . .i/
k
  m k / . .i/
k
  m k /T
:
(9.80)
 Update:
1. Form the sigma points:
X  .i/
k
D m k C
q
P  k .i/;
i D 1; : : : ; m:
(9.81)
2. Propagate the sigma points through the conditional mean and covari-
ance functions:
.i/
k D k.X  .i/
k
/;
i D 1; : : : ; m;
P y;.i/
k
D P y
k .X  .i/
k
/;
i D 1; : : : ; m:
(9.82)
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
m
X
iD1
Wi .i/
k ;
Sk D
m
X
iD1
Wi

P y;.i/
k
C ..i/
k   k/ ..i/
k   k/T
;
Ck D
m
X
iD1
Wi .X  .i/
k
  m k / ..i/
k   k/T:
(9.83)
4. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(9.84)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.6 Practical SLR Filters
195
The extension of the Gaussian ﬁltering framework to general conditional
distribution models in Equation (9.10) also allows us to develop the follow-
ing simple Monte Carlo Kalman ﬁlter that uses Monte Carlo sampling (see
Section 11.1) to approximate the integrals in the SLR/Gaussian ﬁlter. It
is worth noting that this ﬁlter still approximates the ﬁltering distribution as
Gaussian, although in Chapter 11 we will get familiar with particle ﬁltering
where this approximation is dropped.
Algorithm 9.25 (Monte Carlo Kalman ﬁlter). The conditional distribution
form of the Monte Carlo Kalman ﬁlter (MCKF) is the following.
 Prediction:
1. Generate samples of xk 1:
x.i/
k 1  N.mk 1; Pk 1/;
i D 1; : : : ; N:
(9.85)
2. Propagate the samples through the dynamic model:
Ox.i/
k  p.xk j x.i/
k 1/;
i D 1; : : : ; N:
(9.86)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D 1
N
N
X
iD1
Ox.i/
k ;
P  k D 1
N
N
X
iD1
.Ox.i/
k   m k / .Ox.i/
k   m k /T:
(9.87)
 Update:
1. Generate samples of xk:
x .i/
k
 N.m k ; P  k /;
i D 1; : : : ; N:
(9.88)
2. Propagate samples through the measurement model:
y.i/
k
 p.yk j x .i/
k
/;
i D 1; : : : ; N:
(9.89)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
196
Gaussian Filtering by Enabling Approximations
3. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D 1
N
N
X
iD1
y.i/
k ;
Sk D 1
N
N
X
iD1
.y.i/
k   k/ .y.i/
k   k/T;
Ck D 1
N
N
X
iD1
.x .i/
k
  m k / .y.i/
k   k/T:
(9.90)
4. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(9.91)
The above MCKF is theoretically appealing since it can approximate the
moments required to perform SLR arbitrarily well and since it can handle
state space models expressed using conditional distributions.
Let us compare the SPCMKF and the MCKF presented above in a small
example.
Example 9.26 (Gaussian ﬁltering with Poisson observations). Let the state
sequence be a scalar random walk,
xk D xk 1 C qk 1;
qk 1  N.0; Q/;
(9.92)
and let exp.xk/ represent the size of a population. As in Example 9.19, we
observe a Poisson-distributed variable,
yk  Po. exp.xk//;
(9.93)
where  is the probability that a speciﬁc event occurs to a single individual
at time step k. Figure 9.3 shows the result of running the MCKF (with
n D 10; 000 samples) and SPCMKF on one sequence with the parameters
 D 0:1 and Q D 0:1 and an initial distribution with mean m0 D 10 and
variance P0 D 0:1. In this simulation, we use the cubature rule to select
the points and weights in the SPCMKF, which means that the SPCMKF
is a CKF. The result from running a Monte Carlo experiment with 500
sequences of length 25 gave root mean squared errors of 0:084 for the

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.6 Practical SLR Filters
197
0
10
20
k
8
9
10
11
x
True signal
MCKF estimate
CKF estimate
Figure 9.3 Simulated population data and estimated posterior
means using MCKF and CKF in Example 9.26.
MCKF and 0:091 for the CKF. That is, MCKF is more computationally
demanding to run but also gave slightly better estimates.
Finally, for concreteness, we present a sigma point version of Algo-
rithm 9.24 for non-additive models of the form of Equation (9.9), that is,
a sigma-point algorithm to perform SLR ﬁltering for non-additive noise
models. This ﬁltering method uses the following approximations for the
conditional moments in Equation (9.72):
 k .xk 1/ 
m0
X
jD1
W 0
j f.xk 1;
p
Qk 1 .j /0/;
P x
k.xk 1/ 
m0
X
j D1
W 0
j .f.xk 1;
p
Qk 1 .j /0/    k .xk 1//
 .f.xk 1;
p
Qk 1 .j /0/    k .xk 1//T;
(9.94)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
198
Gaussian Filtering by Enabling Approximations
and the following in Equation (9.73):
k.xk/ 
m00
X
j D1
W 00
j h.xk;
p
Rk .j /00/;
P y
k.xk/ 
m00
X
j D1
W 00
j .h.xk;
p
Rk .j /00/   k.xk//
 .h.xk;
p
Rk .j /00/   k.xk//T;
(9.95)
where the unit sigma-points .j /0; .j /00 and weights W 0
j ; W 00
j
are deter-
mined by the numerical integration methods for integrating over the noises
qk 1 and rk. The resulting algorithm is the following.
Algorithm 9.27 (Sigma-point non-additive conditional moment ﬁlter).
The sigma-point non-additive noise conditional moment ﬁlter is the
following.
 Prediction:
1. Form the sigma points as:
X .i/
k 1 D mk 1 C
p
Pk 1 .i/;
i D 1; : : : ; m;
Q.j/
k 1 D
p
Qk 1 .j /0;
j D 1; : : : ; m0:
(9.96)
2. Propagate the sigma points through the dynamic model:
OX .i;j /
k
D f.X .i/
k 1; Q.j /
k 1/;
(9.97)
for i D 1; : : : ; m and j D 1; : : : ; m0.
3. Compute the conditional moments  .i/
k
D k.X .i/
k 1/ and P x;.i/
k
D
P x
k .X .i/
k 1/:
 .i/
k
D
m0
X
j D1
W 0
j OX .i;j /
k
;
P x;.i/
k
D
m0
X
j D1
W 0
j . OX .i;j /
k
   .i/
k
/ . OX .i;j /
k
   .i/
k
/T;
(9.98)
for i D 1; : : : ; m.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.6 Practical SLR Filters
199
4. Compute the predicted mean m k and the predicted covariance P  k :
m k D
m
X
iD1
Wi  .i/
k
;
P  k D
m
X
iD1
Wi

P x;.i/
k
C . .i/
k
  m k / . .i/
k
  m k /T
:
(9.99)
 Update:
1. Form the sigma points:
X  .i/
k
D m k C
q
P  k .i/;
i D 1; : : : ; m;
R.j/
k
D
p
Rk .j/00;
j D 1; : : : ; m00:
(9.100)
2. Propagate the sigma points through the measurement model:
Y.i;j /
k
D h.X  .i/
k
; R.j /
k /;
(9.101)
for i D 1; : : : ; m and j D 1; : : : ; m00.
3. Compute the conditional mean and covariance functions .i/
k
D
k.X  .i/
k
/ and P y;.i/
k
D P y
k .X  .i/
k
/:
.i/
k D
m00
X
j D1
W 00
j Y.i;j /
k
;
P y;.i/
k
D
m00
X
j D1
W 00
j .Y.i;j /
k
  .i/
k /.Y.i;j /
k
  .i/
k /T;
(9.102)
for i D 1; : : : ; m.
4. Compute the predicted mean k, the predicted covariance of the mea-
surement Sk, and the cross-covariance of the state and the measure-
ment Ck:
k D
m
X
iD1
Wi .i/
k ;
Sk D
m
X
iD1
Wi

P y;.i/
k
C ..i/
k   k/ ..i/
k   k/T
;
Ck D
m
X
iD1
Wi .X  .i/
k
  m k / ..i/
k   k/T:
(9.103)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
200
Gaussian Filtering by Enabling Approximations
5. Compute the ﬁlter gain Kk and the ﬁltered state mean mk and covari-
ance Pk, conditional on the measurement yk:
Kk D Ck S 1
k ;
mk D m k C Kk Œyk   k ;
Pk D P  k   Kk Sk KT
k:
(9.104)
Algorithm 9.27 is an alternative to the sigma point algorithms for non-
additive noise models presented in Chapter 8. One difference between these
alternatives is how we form the sigma points. In Chapter 8, we used sigma
points to jointly integrate over xk 1 and qk 1 at the prediction step and to
jointly integrate over xk and rk at the update step, and we did that using
augmented random variables. For instance, if n is the dimensionality of
the state and nr is the dimensionality of the measurement noise, the sigma
points used in the update step of the non-additive ﬁlters had dimensionality
n C nr and represented the augmented state .xk; yk/. In Algorithm 9.27,
we instead use separate sigma points for the state and the noise, and we
perform the integrations in a nested fashion.
9.7 Relation to Other Gaussian Filters
We have now seen that all the Gaussian ﬁlters presented earlier in this
book (e.g., EKF, IEKF, UKF, CKF, GHKF) can be understood from the
perspective of enabling approximations. The EKF and IEKF both perform
analytic linearization of the models but use different linearization points,
whereas the general Gaussian ﬁlters in Chapter 8 implicitly perform SLR
to approximate the models.
The fact that we managed to rederive the general Gaussian ﬁlters using
SLR is fundamentally a consequence of the properties of the underlying
approximations. In general Gaussian ﬁlters, we approximate the joint dis-
tribution of two random variables x and y as Gaussian by matching the mo-
ments in the original distribution. Using SLR, we write y ' A x C b C Qe,
Qe  N.0; ƒ/, which yields an approximation to the conditional distribution
p.y j x/ ' N.y j A x C b; ƒ/:
(9.105)
That is, instead of directly approximating p.x; y/ as Gaussian, SLR ap-
proximates p.y j x/. However, the parameters A, b, and ƒ are still se-
lected to ensure that the resulting approximation of the joint distribution
p.x; y/ matches the original distribution, see (9.41). Consequently, when

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
9.7 Relation to Other Gaussian Filters
201
x is Gaussian, SLR yields a Gaussian approximation of the joint distribu-
tion that exactly matches the approximation used in the general Gaussian
ﬁlters. For additive noise models, we can also compare (9.43) in Corol-
lary 9.14 with (8.4) in Algorithm 8.1 and verify that the involved integrals
are identical.
The general Gaussian ﬁlters presented in Chapter 8 approximate the
joint distribution of .xk; xk 1/ as Gaussian during the prediction step and
the joint distribution of .xk; yk/ as Gaussian during the update step. Based
on that approximation, the prediction and update steps are performed in
closed form. Similarly, the SLR ﬁlters presented in Section 9.5 linearize
the models during both the prediction and update steps and then perform
ﬁltering in closed form. Considering that the SLR used by the SLR ﬁlters
corresponds to the same Gaussian approximations used to derive the ﬁl-
ters in Chapter 8, it is not surprising that the two approaches give rise to
identical ﬁlters.
The literature contains several examples of ﬁlters that make use
of higher order expansions of the involved models. For instance, the
second order extended Kalman ﬁlter (EKF2) (Bar-Shalom et al., 2001;
Roth and Gustafsson, 2011), the Fourier–Hermite Kalman ﬁlter (FHKF)
(Sarmavuori and S¨arkk¨a, 2012), and the Gaussian process quadrature ﬁlter
(GPQF) (S¨arkk¨a et al., 2016) all approximate f./ and h./ using different
types of series expansions. These approximations are then used to compute
certain integrals.
Interestingly, it is possible to argue that these higher order ﬁlters are in-
stantiations of SLRF ﬁlters described above. The reason for this is that the
series expansions are introduced to enable us to approximate the integrals
that appear in the general Gaussian ﬁlters that we studied in Chapter 8,
and the higher order ﬁlters (implicitly or explicitly) approximate the joint
distributions of .xk; xk 1/ and .yk; xk/ as Gaussian.
From the perspective of enabling approximations, this means that these
ﬁlters (EKF2, FHKF, and GPQF) implicitly make use of SLR to linearize
the models. That is, even though the higher order series expansions may ap-
proximate the models accurately, we cannot use them as enabling approxi-
mations since they do not enable us to compute the posterior distributions
in closed form. Instead we still use the SLR as enabling approximation and
only use the higher order expansions to approximate the involved integrals.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
202
Gaussian Filtering by Enabling Approximations
9.8 Exercises
9.1
Consider the following non-linear state space model:
xk D xk 1   0:01 sin.xk 1/ C qk 1;
yk D 0:5 sin.2 xk/ C rk;
(9.106)
where qk 1 has a variance of 0:012 and rk has a variance of 0:02, which
we saw already in Exercise 7.1. Derive the required expected values for an
SLF, and implement the SLF for the model. Hint: Use the imaginary part
of the inverse Fourier transform of the Gaussian distribution. Simulate data
from the model, compute the RMSE values, plot the results, and compare
the performance to the EKF.
9.2
In this exercise your task is to derive the derivative form of the statistically
linearized ﬁlter (SLF).
(a) Prove using integration by parts the following identity for a Gaussian
random variable x, differentiable non-linear function g.x/, and its Jaco-
bian matrix Gx.x/ D @g.x/=@x:
EŒg.x/ .x   m/T D EŒGx.x/ P;
(9.107)
where EŒ denotes the expected value with respect to N.x j m; P/. Hint:
@
@xN.x j m; P/ D  P  1.x   m/ N.x j m; P/.
(b) Prove the following. Let
.m/ D EŒg.x/;
(9.108)
where EŒ denotes the expected value with respect to N.x j m; P/. Then
@.m/
@m
D EŒGx.x/:
(9.109)
(c) Write down the additive form of the SLF equations in an alternative
form, where you have eliminated all the cross terms of the form
EŒf.xk 1/ ıxT
k 1 and EŒh.xk/ ıxT
kT, using the result in (a).
(d) How can you utilize the result (b) when using the alternative form of the
SLF? Check that you get the same equations for the SLF in the previous
exercise using this alternative form of the SLF.
9.3
Algorithm 9.9 can be combined with a Gaussian quadrature method to ap-
proximate the expected values EŒf.xk 1/, EŒf.xk 1/ ıxT
k 1, EŒh.xk/ and
EŒh.xk/ ıxT
k. Formulate an algorithm that combines Algorithm 9.9 with
spherical cubature integration described in Algorithm 8.10.
Hint: You can form sigma points as in Algorithm 8.11 and then use them to
approximate the four expected values mentioned above.
9.4
Implement the cubature-based version of the SL formulated in Exercise 9.3
for the model in Exercise 7.1. Plot the results and compare the RMSE values
to the SLF from Exercise 7.1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
203
9.5
Find analytical solutions to the integrals in (9.57).
Hint: One can show that
exp.ˇx/ N.x j m; P / D N.x j m C Pˇ; P / exp.ˇm C Pˇ2=2/:
9.6
Implement the Gauss–Hermite integration-based SLR ﬁlter in Algo-
rithm 9.20 for the model in Exercise 7.1, and check that its result matches
the GHKF for the same model.
9.7
Continue Exercise 9.1 by computing all the expectations needed for the SLR
ﬁlter in Algorithm 9.20 in closed form. Compare its performance numeri-
cally with the EKF and GHKF.
9.8
Formulate an SLR ﬁlter for the non-additive noise models in (9.9), where
we ﬁrst linearize the models and then perform the Kalman ﬁlter prediction
and update. That is, formulate a version of Algorithm 9.20 for non-additive
noise models. Also, verify that it can be simpliﬁed to Algorithm 8.4.
Hint: Considering that we want an algorithm that can be simpliﬁed to Algo-
rithm 8.4 you should use (9.50), and avoid the conditional moments formu-
lation. See also Appendix A.9.
9.9
Formulate an algorithm that combines Algorithm 9.20 with spherical cuba-
ture integration described in Algorithm 8.10.
9.10
Verify that Corollary 9.8 holds.
Hint: Apply Theorem 9.3 to the variables y D g.x; q/ and z in (9.28).
9.11
Consider the bicycle model with the mean dynamic model given by Equa-
tions (4.66) and the covariance approximation constructed in Exercise 4.10.
Implement the conditional moment ﬁlter in Algorithm 9.24 for the model
when linear position measurements are used. You can use, for example, the
cubature integration method. Simulate data from the model, and compute the
RMSE of the ﬁlter.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10
Posterior Linearization Filtering
In Chapter 9, we demonstrated that all the Gaussian ﬁlters presented ear-
lier can be understood as methods that ﬁrst linearize the models and then
use the Kalman ﬁlter equations to solve the resulting state estimation prob-
lem. How we linearize the models may signiﬁcantly inﬂuence the ﬁlter
performance, and we can approximate the models using any afﬁne func-
tion with additive Gaussian noise. In this chapter, we present the concepts
of posterior linearization and iterated posterior linearization ﬁltering, ﬁrst
introduced in Garc´ıa-Fern´andez et al. (2015) and further developed, for
example, in Tronarp et al. (2018), and explain how they can be used to
develop practical Gaussian ﬁlters.
10.1 Generalized Statistical Linear Regression
In the SLR ﬁlters that we encountered in the previous chapter, we implic-
itly used the prediction and update distributions of xk as the linearization
distributions in statistical linear regression (SLR). This then led to ﬁlters
that turned out to be equivalent to moment matching-based Gaussian ﬁl-
ters. However, there is no inherent reason why we should linearize with
respect to this “true” distribution of xk. Instead, the linearization distribu-
tion can even be completely decoupled from the distribution that xk has
with respect to the estimation problem at hand. In fact, linearization was
decoupled from the prediction and update distributions already in the iter-
ated extended Kalman ﬁlter (IEKF), which we saw in Section 7.4, as the
linearization point was optimized by iteration in the IEKF update. A similar
philosophy can also be applied in SLR.
Let us start by deﬁning generalized SLR, which is deﬁned for any lin-
earization distribution .x/.
204

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.1 Generalized Statistical Linear Regression
205
Deﬁnition 10.1 (Generalized statistical linear regression). Let .x/ be an
arbitrary linearization distribution for x. If x and y are two random vari-
ables, y ' A xCbC Qe, Qe  N.0; ƒ/ is called a statistical linear regression
with respect to .x/ if A and b are selected to minimize the mean squared
error
MSE.A; b/ D E

.y   A x   b/T .y   A x   b/

;
(10.1)
where E denotes expectation with respect , A and b are deterministic
variables, and the noise covariance is selected as
ƒ D E

.y   A x   b/ .y   A x   b/T
:
(10.2)
With this deﬁnition we get the following linearization. Below, we have
used a slight abuse of notation by using subscript  to denote means and
covariances when the distribution of x is replaced with .
Theorem 10.2 (Generalized statistical linear regression). Let .x/ be an
arbitrary linearization distribution for x. Suppose x and y are two ran-
dom variables, and let m D EŒx, P D CovŒx, G D EŒy,
SG D CovŒy, and CG D CovŒx; y. In the generalized statistical linear
regression (GSLR) with respect to .x/ for y ' A xCbC Qe, Qe  N.0; ƒ/,
we then have
A D CT
G P  1
 ;
b D G   A m;
ƒ D SG   A P AT:
(10.3)
Proof
The result can be derived in the same way as in Theorem 9.12.
We can now apply GSLR to a transformation of the form y D g.x/Cq,
which gives the following.
Corollary 10.3 (Generalized SLR of an additive transform). Suppose y D
g.x/ C q, where x  N.m; P/ and q  N.0; Q/. If we use generalized
statistical linear regression (GSLR) with respect to a linearization distri-
bution .x/ to form the approximation y ' A x C b C Qe, Qe  N.0; ƒ/, we
get
A D CT
G P  1
 ;
b D G   A m;
ƒ D SG   A P AT;
(10.4)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
206
Posterior Linearization Filtering
where
m D
Z
x .x/ dx;
P D
Z
.x   m/ .x   m/T .x/ dx;
G D
Z
g.x/ .x/ dx;
CG D
Z
.x   m/ .g.x/   G/T .x/ dx;
SG D
Z
.g.x/   G/ .g.x/   G/T .x/ dx C Q:
(10.5)
The corresponding joint Gaussian approximation for .x; y/ is given by
x
y

 N

m
A m C b

;
 P
P AT
A P
A P AT C Q

:
(10.6)
The key thing above is that it no longer reduces to moment matching,
because the distribution x  N.m; P/ is different from the linearization
distribution .x/. This also has the side effect that the moments of the joint
Gaussian approximation no longer exactly match the true ones when we
have x  N.m; P/. However, we can use this to our advantage, because we
do not actually want the linearization to be optimal for the prior distribution
for x, but instead, we are more interested in the posterior distribution of x.
With this in mind, it makes sense to attempt to use the posterior distribution
as the linearization distribution instead of the prior of x. We proceed to
discuss this next.
10.2 Posterior Linearization
Statistical linearization (SL) and statistical linear regression (SLR) are ap-
pealing because they seek linearizations that are accurate on average across
the different state values that may appear. However, once we have observed
measurements, our belief (distribution) on the different state values will
change. Thus, although initially it makes sense to linearize with respect to
the prior distribution of x, after obtaining measurements, a more appropri-
ate choice for the linearization distribution in SL and SLR would be the
posterior distribution. In this section we introduce the posterior lineariza-
tion, which aims to do that. We restrict our discussion to SLR as we already

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.2 Posterior Linearization
207
saw in the previous chapter that SL can be seen as a deterministic version
of SLR where we simply ignore the approximation error.
Deﬁnition 10.4 (Posterior linearization). Let x and y be two random vari-
ables, and assume that we observe y, which then leads to the posterior
distribution p.x j y/. The procedure of putting .x/ D p.x j y/ and
forming the approximation y ' A x C b C Qe, Qe  N.0; ƒ/ with general-
ized statistical linear regression in Deﬁnition 10.1 with respect to .x/ is
called posterior linearization (PL).
The application of the above deﬁnition to a transformation of the form
y D g.x/ C q, where x  N.m; P/ and q  N.0; Q/, then leads to
Corollary 10.3 with .x/ D p.x j y/. Clearly there is a catch – to do the
linearization we need to have access to the posterior distribution, and the
whole aim of linearization is to approximately compute this distribution,
which we do not know. However, we come back to this dilemma in the
next section where we introduce iterated posterior linearization.
The intuition behind posterior linearization is the same as the original
SLR: we want an approximation that is accurate on average across the state
values that we expect to see; but posterior linearization tries to leverage
what we have learned from the measurements and seeks a linearization
that is accurate in the support of the posterior density. Speciﬁcally, A and
b are selected to approximate y accurately on average across the values
of x that we expect to see according to our posterior distribution of x,
whereas the original SLR seeks an approximation that is accurate when we
average according to the prior. In what follows we, therefore, refer to the
two alternatives as prior SLR and posterior SLR, respectively, where the
posterior SLR is also referred to as a posterior linearization.
The motivation for linearizing our models is to compute the posterior
distribution of the state x. If we have a Gaussian prior, p.x/ D N.x j
m; P/, and we observe y D A x C b C Qe where Qe  N.0; ƒ/, the posterior
moments .mC; P C/ can be computed using the calculations:
 D A m C b;
S D A P AT C ƒ;
K D P AT S 1;
mC D m C K .y   /;
P C D P   K S KT:
(10.7)
For both the posterior SLR (i.e., PL) and the prior SLR, we use Equa-
tions (10.7) to compute the posterior, but the linearization parameters are

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
208
Posterior Linearization Filtering
different. What happens in the prior SLR is that the linearization is not ac-
curate (moment matched) when the state x is distributed according to the
posterior distribution – it is only accurate for the prior distribution of x.
However, PL is maximally accurate when x is distributed according to the
posterior distribution. These properties are related to the Kullback–Leibler
divergence optimality properties of prior and posterior SLR, which are dis-
cussed in Garc´ıa-Fern´andez et al. (2015) as well as in Section 10.6.
Example 10.5 (Posterior statistical linear regression). Consider the scalar
variables in Example 9.7, where we have x  N.1; 0:1/ and g.x/ D x3.
To ensure that the posterior density is not degenerate, we assume that
y D g.x/ C q;
(10.8)
where the additive noise is Gaussian: q  N.0; 0:1/.
Figure 10.1(a) illustrates the afﬁne components, A x C b, of the prior
and posterior SLRs when we have observed the value y D 5. The posterior
density p.x j y/ for this observation is centered around x ' 1:7, and
the posterior linearization selects A x C b to approximate g.x/ accurately
close to that value, whereas the prior SLR selects A x C b to approximate
g.x/ accurately around the prior mean x D 1. The standard deviations of
the linearization noise are
p
ƒ ' 0:45 for the prior SLR and
p
ƒ ' 0:01
for the posterior SLR. The reason ƒ is so much smaller for the posterior
SLR is that the posterior density p.x j y/ has much smaller variance than
the prior density p.x/ in this example.
The resulting densities are illustrated in Figure 10.1(b). The posterior
computed using the posterior SLR overlaps with the true posterior p.x j
y/, whereas the posterior computed using the prior SLR has a larger vari-
ance and a different mean. At least in this example, the posterior SLR yields
a more accurate approximation to the posterior than the prior SLR.
10.3 Iterated Posterior Linearization
The concept of posterior linearization (PL) introduced in the previous sec-
tion has the dilemma that in order to form it, we would already need to have
access to the posterior distribution. However, we can construct a practical
iterative algorithm by always making use of the best available approxima-
tion to the posterior when linearizing the models. This is called iterated
posterior linearization (IPL).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.3 Iterated Posterior Linearization
209
0
0.5
1
1.5
2
2.5
x
-10
0
10
g(x)
Prior SLR
Posterior SLR
(a)
0
0.5
1
1.5
2
2.5
x
0
2
4
6
8
10
12
14
16
18
20
p(x)
Exact p(x | y)
Prior SLR p(x | y)
Posterior SLR p(x | y)
(b)
Figure 10.1 Illustrations related to Example 10.5. (a) The
function g.x/ D x3 and the afﬁne approximations y D Ax C b in
the prior SLR and posterior SLR, respectively. (b) The prior
density p.x/, the true posterior p.x j y/, and the approximate
posteriors p.x j y/ computed using prior SLR and posterior SLR,
respectively.
Algorithm 10.6 (Iterated posterior linearization). Given a model y D
g.x/ C q, q  N.0; Q/, a prior density x  N.m; P/, and observation y,
the iterated posterior linearization (IPL) algorithm is:
 Start from the prior density m.0/ D m, P .0/ D P.
 For i D 1; 2; 3; : : : do the following steps:
1. Linearize: Find the SLR parameters A.i/, b.i/, and ƒ.i/ such that
y ' A.i/ x C b.i/ C Qe, Qe  N.0; ƒ.i//:
A.i/ D ŒP xy;.i 1/T ŒP .i 1/ 1;
b.i/ D C;.i 1/   A.i/ m.i 1/;
ƒ.i/ D P y;.i 1/   A.i/ P .i 1/ ŒA.i/T;
(10.9)
where the expectations in P xy;.i 1/ D CovŒx; y, C;.i 1/ D EŒy,
and P y;.i 1/ D CovŒy are taken with respect to our current best

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
210
Posterior Linearization Filtering
approximation to the posterior distribution, x  N.m.i 1/; P .i 1//:
C;.i 1/ D
Z
g.x/ N.x j m.i 1/; P .i 1// dx;
P xy;.i 1/ D
Z
.x   m.i 1// .g.x/   C;.i 1//T
 N.x j m.i 1/; P .i 1// dx;
P y;.i 1/ D
Z
.g.x/   C;.i 1// .g.x/   C;.i 1//T
 N.x j m.i 1/; P .i 1// dx C Q:
(10.10)
2. Update: Compute the updated moments m.i/, P .i/ such that p.x j
y/ ' N.x j m.i/; P .i//:
.i/ D A.i/ m C b.i/;
S.i/ D A.i/ P ŒA.i/T C ƒ.i/;
K.i/ D P ŒA.i/T S 1;
m.i/ D m C K.i/ .y   .i//;
P .i/ D P   K.i/ S.i/ ŒK.i/T:
(10.11)
We note that IPL always performs SLR with respect to the best available
approximation to the posterior, p.x j y/ ' N.x j m.i 1/; P .i 1//. Before
performing the ﬁrst iteration, the best available approximation is the prior
density. The algorithm is iterative since we end each iteration with a new
approximation to the posterior.
Importantly, the update step of IPL in Equation (10.11) updates the prior
density p.x/ D N.x j m; P/ using the most recent linearization of the
model, y ' A.i/x C b.i/ C Qe, Qe  N.0; ƒ.i//. That is, the most recent
approximation to the posterior p.x j y/ ' N.x j m.i 1/; P .i 1// is only
used to linearize the model, and it is not explicitly used in the update step.
Example 10.7 (Iterated posterior linearization). Let us revisit Exam-
ple 10.5, where we had a prior x  N.1; 0:1/ and where we observed
y D x3 C q, q  N.0; 0:1/.
The result of applying IPL to this problem is illustrated in Figure 10.2.
After the ﬁrst iteration, IPL yields the same approximation to the poste-
rior as prior SLR, since we initialize IPL using the prior (see also Fig-
ure 10.1(b) for a comparison). Note that prior SLR yields the same result
as the moment matching approach used in general Gaussian ﬁlters. In this
example, IPL already provides an accurate approximation to the posterior

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.3 Iterated Posterior Linearization
211
0
0.5
1
1.5
2
2.5
x
0
2
4
6
8
10
12
p(x)
Exact p(x | y)
IPL p(1)(x | y)
IPL p(2)(x | y)
IPL p(3)(x | y)
Figure 10.2 An illustration of the densities in Example 10.7. The
densities p.i/.x j y/ are the posterior density approximations
obtained using IPL at iterations i D 1; 2; 3.
after two iterations, and after the third iteration, it is difﬁcult to distinguish
the true posterior from the approximation obtained using IPL.
IPL provides a strategy for selecting the enabling linearization, which
can be used to construct Gaussian ﬁlters and smoothers. In this chapter, we
focus on the ﬁltering problem and present practical algorithms for differ-
ent model families. In the previous chapter we already discussed different
strategies of computing the expectation and covariance deﬁned by integrals
in Equations (10.10), not only for additive noise models covered by Algo-
rithm 10.6 but also for non-additive noise models and general conditional
distribution models. These strategies can also be directly used instead of
Equations (10.10) to apply IPL to these more general model classes.
We can also see that if the expectation and covariances in Equa-
tions (10.10) are approximately computed with Taylor series-based
linearization at the current guess instead of the Gaussian integrals, we ob-
tain a Gauss–Newton method, which is also the basis of IEKF introduced
in Section 7.4. Furthermore, if the posterior variance is small, then the
moment matching approximation and Taylor series expansion coincide,
and we again get the Gauss–Newton method. When the measurement
noise is large, then the posterior distribution resembles the prior, and the
prior and posterior SLR (i.e., PL) are likely to produce similar results.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
212
Posterior Linearization Filtering
10.4 Iterated Posterior Linearization Filter
The iterated posterior linearization (IPL) strategy can be used in different
contexts, and in this chapter, we explore how it can be used in the mea-
surement update of a Gaussian ﬁlter. In the ﬁlters that we describe here, we
perform prediction as in the general Gaussian ﬁlters from Chapter 8 (which
are closely related to the SLR ﬁlters from Chapter 9), and we then use IPL
in the update step. Our objective is to present iterated posterior lineariza-
tion ﬁlters (IPLFs) for additive noise models, for non-additive noise mod-
els, and for the conditional distribution models in Equations (9.1), (9.9),
and (9.10), respectively.
In the iterated posterior linearization ﬁlter, the prediction step is approx-
imated in the same way as in conventional Gaussian ﬁlters, but the update
is done using iterated posterior linearization. In the IPLF update, we iter-
ate to improve our approximations to the posterior moments m.i/
k ; P .i/
k
for
i D 0; 1; 2; : : : . The resulting algorithm for additive models is the follow-
ing.
Algorithm 10.8 (Iterated posterior linearization ﬁlter I). The prediction
and update steps of an additive noise iterated posterior linearization
(Kalman) ﬁlter for model in Equation (9.1) are:
 Prediction:
Compute the predicted moments
m k D
Z
f.x/ N.x j mk 1; Pk 1/ dx;
P  k D
Z
.f.x/   m k / .f.x/   m k /T N.x j mk 1; Pk 1/ dx C Qk 1:
(10.12)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.4 Iterated Posterior Linearization Filter
213
1. Compute the moments with respect to xk  N.m.i 1/
k
; P .i 1/
k
/:
C;.i 1/
k
D
Z
hk.x/ N.x j m.i 1/
k
; P .i 1/
k
/ dx;
P xy;.i 1/
k
D
Z
.x   m.i 1/
k
/ .hk.x/   C;.i 1/
k
/T
 N.x j m.i 1/
k
; P .i 1/
k
/ dx;
P y;.i 1/
k
D
Z
.h.x/   C;.i 1/
k
/ .h.x/   C;.i 1/
k
/T
 N.x j m.i 1/
k
; P .i 1/
k
/ dx C Rk:
(10.13)
2. Linearize measurement model:
H.i/
k D ŒP xy;.i 1/
k
T ŒP .i 1/
k
 1;
b.i/
k D C;.i 1/
k
  H.i/
k m.i 1/
k
;
.i/
k D P y;.i 1/
k
  H.i/
k P .i 1/
k
.H.i/
k /T:
(10.14)
3. Perform the Kalman update using the linearized model:
.i/
k D H.i/
k m k C b.i/
k ;
S.i/
k D H.i/
k P  k .H.i/
k /T C .i/
k ;
K.i/
k D P  k .H.i/
k /T .S.i/
k / 1;
m.i/
k D m k C K.i/
k .yk   .i/
k /;
P .i/
k
D P  k   K.i/
k S.i/
k .K.i/
k /T:
(10.15)
At convergence, set mk D m.i/
k and Pk D P .i/
k .
The prediction step in Algorithm 10.8 is identical to the prediction step
in Algorithms 8.3 and 9.21. Note that the prediction in step Algorithm 9.20
also yields the same result but that the other algorithms make use of sim-
pliﬁed expressions. The update step in Algorithm 10.8 is based on the IPL.
The update equations used in each iteration are closely related to the up-
date step in Algorithm 9.20, where we perform linearization with respect
to xk  N.m k ; P  k /, and which can then be simpliﬁed to Algorithm 9.21.
However, we now linearize with respect to xk  N.m.i 1/
k
; P .i 1/
k
/, which
prevents us from doing such simpliﬁcation.
The above IPLF algorithm is closely related to the IEKF described in
Algorithm 7.9. Both algorithms rely on the intuition that we should use

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
214
Posterior Linearization Filtering
the posterior to select the linearization. The difference is that the IEKF
performs a ﬁrst-order Taylor expansion about m.i 1/
k
, whereas the IPLF
performs SLR with respect to xk  N.m.i 1/
k
; P .i 1/
k
/. We recall that an
SLR seeks a linearization that is accurate on average across the selected
distribution, which has beneﬁts compared to a Taylor expansion in some
contexts.
We can now present a non-additive noise generalization of Algo-
rithm 10.8. It turns out that in the IPL-based update step, only the moment
computations in Equations (10.13) change, and the linearization and
posterior mean and covariance update in Equations (10.14) and (10.15)
remain intact.
Algorithm 10.9 (Iterated posterior linearization ﬁlter II). The prediction
and update steps of a non-additive noise iterated posterior linearization
(Kalman) ﬁlter are:
 Prediction:
Compute the predicted moments
m k D
Z
f.xk 1; qk 1/
 N.xk 1 j mk 1; Pk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1;
P  k D
Z
.f.xk 1; qk 1/   m k / .f.xk 1; qk 1/   m k /T
 N.xk 1 j mk 1; Pk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1:
(10.16)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.4 Iterated Posterior Linearization Filter
215
1. Compute the moments:
C;.i 1/
k
D
Z
h.xk; rk/
 N.xk j m.i 1/
k
; P .i 1/
k
/ N.rk j 0; Rk/ dxk drk;
P xy;.i 1/
k
D
Z
.xk   m.i 1/
k
/ .h.xk; qk/   C;.i 1/
k
/T
 N.xk j m.i 1/
k
; P .i 1/
k
/ N.rk j 0; Rk/ dxk drk;
P y;.i 1/
k
D
Z
.h.xk; rk/   C;.i 1/
k
/ .h.xk; rk/   C
k /T
 N.xk j m.i 1/
k
; P .i 1/
k
/ N.rk j 0; Rk/ dxk drk:
(10.17)
2. Linearize measurement model using Equations (10.14).
3. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
That is, the IPLF for non-additive noise is similar to the IPLF for ad-
ditive noise, but the expressions for the involved moments are different.
These moments can also be expressed using conditional moments. If we
assume that the conditional moments in Equation (9.68) can be computed
(analytically or numerically), we can use the following version of the IPLF.
Algorithm 10.10 (Iterated posterior linearization ﬁlter III). The condi-
tional moments form of the iterated posterior linearization (Kalman) ﬁlter
are:
 Prediction:
Compute the predicted moments
m k D
Z
 k .xk 1/ N.xk 1 j mk 1; Pk 1/ dxk 1;
P  k D
Z
. k .xk 1/   m k / . k .xk 1/   m k /T
 N.xk 1 j mk 1; Pk 1/ dxk 1
C
Z
P x
k.xk 1/ N.xk 1 j mk 1; Pk 1/ dxk 1:
(10.18)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
216
Posterior Linearization Filtering
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Compute the moments:
C;.i 1/
k
D
Z
k.xk/ N.xk j m.i 1/
k
; P .i 1/
k
/ dxk;
P xy;.i 1/
k
D
Z
.xk   m.i 1/
k
/ .k.xk/   C;.i 1/
k
/T
 N.xk j m.i 1/
k
; P .i 1/
k
/ dxk;
P y;.i 1/
k
D
Z
.k.xk/   C;.i 1/
k
/ .k.xk/   C;.i 1/
k
/T
 N.xk j m.i 1/
k
; P .i 1/
k
/ dxk
C
Z
P y
k.xk/ N.xk j m.i 1/
k
; P .i 1/
k
/ dxk:
(10.19)
2. Linearize measurement model using Equations (10.14).
3. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
Algorithm 10.10 can be used for all the considered model types, as
long as the conditional moments in Equation (9.68) can be computed.
For additive noise models (see Equation (9.1)), it is trivial to compute
the conditional moments, and Algorithm 10.10 then simpliﬁes to Algo-
rithm 10.8. For non-additive noise models (see Equation (9.9)) and con-
ditional distribution models (see Equation (9.10)), the expressions for the
conditional moments are given by Equations (A.55) and (A.63), and Equa-
tions (A.56) and (A.64), respectively. Note that we sometimes also en-
counter non-additive noise models for which the conditional moments take
closed-form expressions. Important examples of such models are the dy-
namic models from Chapter 4 for which we have a state dependent covari-
ance matrix such that p.xk j xk 1/ D N.xk j fk 1.xk 1/; Qk 1.xk 1//.
When the model is given in the form of conditional distributions as in
Equation (9.10), we can also use the following form of the IPLF.
Algorithm 10.11 (Iterated posterior linearization ﬁlter IV). The condi-
tional distribution form of the iterated posterior linearization (Kalman)
ﬁlter is:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.5 Practical Iterated Posterior Linearization Filters
217
 Prediction:
Compute the predicted moments
m k D
Z
xk p.xk j xk 1/ N.xk 1 j mk 1; Pk 1/ dxk dxk 1;
P  k D
Z
.xk   m k / .xk   m k /T
 p.xk j xk 1/ N.xk 1 j mk 1; Pk 1/ dxk dxk 1:
(10.20)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Compute the moments:
C;.i 1/
k
D
Z
yk p.yk j xk/ N.xk j m.i 1/
k
; P .i 1/
k
/ dyk dxk;
P xy;.i 1/
k
D
Z
.xk   m.i 1/
k
/ .yk   C;.i 1/
k
/T
 p.yk j xk/ N.xk j m.i 1/
k
; P .i 1/
k
/ dyk dxk;
P y;.i 1/
k
D
Z
.yk   C;.i 1/
k
/ .yk   C;.i 1/
k
/T
 p.yk j xk/ N.xk j m.i 1/
k
; P .i 1/
k
/ dyk dxk:
(10.21)
2. Linearize measurement model using Equations (10.14).
3. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
We have now presented one IPLF for each of the three model types, as
well as one IPLF for the conditional moments formulation.
10.5 Practical Iterated Posterior Linearization Filters
To convert the above IPLFs into practical algorithms, we need to solve
(or approximate) the involved integrals. In this section, we present general
sigma point versions of the additive noise and non-additive noise IPLFs
and a Monte Carlo IPLF for conditional distribution models. We start by
deﬁning an IPLF for the additive noise model in Equations (9.1).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
218
Posterior Linearization Filtering
Algorithm 10.12 (Sigma-point iterated posterior linearization ﬁlter I). The
prediction and update steps of an additive noise sigma-point iterated pos-
terior linearization (Kalman) ﬁlter are:
 Prediction:
1. Form the sigma points as:
X .j/
k 1 D mk 1 C
p
Pk 1 .j /;
j D 1; : : : ; m;
(10.22)
and select the weights W1; : : : ; Wm.
2. Propagate the sigma points through the dynamic model:
X  .j/
k
D f.X .j /
k 1/;
j D 1; : : : ; m:
(10.23)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
m
X
j D1
Wj X  .j/
k
;
P  k D
m
X
j D1
Wj .X  .j/
k
  m k / .X  .j /
k
  m k /T C Qk 1:
(10.24)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Form the sigma points:
X .j/
k
D m.i 1/
k
C
q
P .i 1/
k
.j /;
j D 1; : : : ; m;
(10.25)
and select the corresponding weights W1; : : : ; Wm.
2. Propagate the sigma points through the measurement model:
Y.j/
k
D h.X .j /
k /;
j D 1; : : : ; m:
(10.26)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.5 Practical Iterated Posterior Linearization Filters
219
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
IPLF estimate
Figure 10.3 Simulated pendulum data and the result of tracking
the pendulum with the IPLF (Example 10.13). The resulting
RMSE was 0:14 which is lower than the RMSEs of the EKF and
IEKF (= 0:17) but higher than many of the non-iterated Gaussian
ﬁlters.
3. Compute the required moments:
C;.i 1/
k
D
m
X
jD1
Wj Y.j /
k ;
P xy;.i 1/
k
D
m
X
jD1
Wj .X .j /
k
  m.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D
m
X
jD1
Wj .Y.j /
k
  C;.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T C Rk:
(10.27)
4. Linearize measurement model using Equations (10.14).
5. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
The prediction step in Algorithm 10.12 is analogous to the prediction
step for the sigma points presented in Chapter 8 and, depending on how we
select the sigma points, can become identical to the prediction step in the
corresponding algorithm in that chapter (e.g., CKF, GHKF, or UKF).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
220
Posterior Linearization Filtering
-1.2
-1
-0.8
-0.6
-0.4
-0.2
0
 x1
-1.1
-1
-0.9
-0.8
-0.7
-0.6
-0.5
 x2
True trajectory
GHKF estimate
IGHKF estimate
Figure 10.4 The result of applying GHKF and IPLF with
Gauss–Hermite integration to simulated data from the (polar)
coordinated turn model in Example 7.11 when using an inaccurate
initial guess (see Example 10.14). The ﬁgure only shows the
initial part of trajectory as the result on the rest of the trajectory is
identical for both of the ﬁlters. The resulting RMSE for GHKF
was 0:032 whereas for IPLF it was marginally lower, 0:031,
which can be explained by the faster convergence at the start.
Example 10.13 (Pendulum tracking with IPLF). Figure 10.3 shows the re-
sult of applying a Gauss–Hermite integration-based IPLF to the pendulum
problem ﬁrst considered in Example 7.6. Although the result of the ﬁlter has
a lower error than the EKF and IEKF, it appears that in this model (and
data) the iteration does not improve the result over non-iterated Gaussian
ﬁlters.
Example 10.14 (Coordinated turn model with posterior linearization ﬁl-
ters). Figure 10.4 shows the result of IPLF with Gauss–Hermite integra-
tion to the coordinated turn model problem considered in Example 7.11.
The iteration has the same effect as in EKF versus IEKF – the iteration
helps to initialize the tracking from the inaccurate initial condition, after
which the result is practically identical to the corresponding non-iterated
ﬁlter.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.5 Practical Iterated Posterior Linearization Filters
221
To present a sigma point IPLF for non-additive noise models in (9.9),
we mimic the strategy used in Algorithm 8.12 and construct sigma points
on an augmented state space.
Algorithm 10.15 (Sigma-point iterated posterior linearization ﬁlter II).
The prediction and update steps of a non-additive noise sigma point it-
erated posterior linearization (Kalman) ﬁlter are:
 Prediction:
1. Form sigma points for the augmented random variable .xk 1; qk 1/
as:
QX .j/
k 1 D Qmk 1 C
q
QPk 1 .j /;
j D 1; : : : ; m;
(10.28)
where
Qmk 1 D
mk 1
0

;
QPk 1 D
Pk 1
0
0
Qk 1

;
and select the weights W1; : : : ; Wm.
2. Propagate the sigma points through the dynamic model:
X  .j/
k
D f. QX .j/;x
k 1 ; QX .j /;q
k 1 /;
j D 1; : : : ; m;
(10.29)
where QX .j/;x
k 1
denotes the ﬁrst n D dim.xk 1/ components in QX .j /
k 1
and QX .j/;q
k 1 denotes the last nq D dim.qk 1/ components.
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
m
X
jD1
Wj X  .j /
k
;
P  k D
m
X
j D1
Wj .X  .j /
k
  m k / .X  .j /
k
  m k /T:
(10.30)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Form the sigma points for the augmented vector .xk; rk/ as:
QX .j/
k
D Qm.i 1/
k
C
q
QP .i 1/
k
.j /;
j D 1; : : : ; m;
(10.31)
where
Qm.i 1/
k
D

m.i 1/
k
0

;
QP  k D

P .i 1/
k
0
0
Rk

;

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
222
Posterior Linearization Filtering
and select the corresponding weights W1; : : : ; Wm.
2. Propagate the sigma points through the measurement model:
Y.j/
k
D h. QX .j/;x
k
; QX .j /;r
k
/;
j D 1; : : : ; m;
(10.32)
where QX .j/;x
k
denotes the ﬁrst n components in QX .j /
k
and QX .j /;r
k
de-
notes the last nr D dim.rk/ components.
3. Compute the required moments:
C;.i 1/
k
D
m
X
j D1
Wj Y.j/
k ;
P xy;.i 1/
k
D
m
X
j D1
Wj . QX .j /;x
k
  m.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D
m
X
j D1
Wj .Y.j /
k
  C;.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T:
(10.33)
4. Linearize measurement model using Equations (10.14).
5. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
We can also construct a sigma point version of the conditional moments
IPLF described in Algorithm 10.10.
Algorithm 10.16 (Sigma-point iterated posterior linearization ﬁlter III).
The prediction and update steps of a conditional moments sigma point
iterated posterior linearization (Kalman) ﬁlter are:
 Prediction:
1. Form the sigma points as:
X .j/
k 1 D mk 1 C
p
Pk 1 .j /:
j D 1; : : : ; m:
(10.34)
2. Propagate the sigma points through the conditional mean and covari-
ance functions:
 .j/
k
D  k .X .j /
k 1/;
j D 1; : : : ; m;
P x;.j/
k
D P x
k .X .j /
k 1/;
j D 1; : : : ; m:
(10.35)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.5 Practical Iterated Posterior Linearization Filters
223
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D
m
X
j D1
Wj  .j/
k
;
P  k D
m
X
j D1
Wj

P x;.j/
k
C . .j /
k
  m k / . .j /
k
  m k /T
:
(10.36)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Form the sigma points:
X  .j/
k
D m.i 1/
k
C
q
P .i 1/
k
.j /;
j D 1; : : : ; m;
(10.37)
and select the corresponding weights W1; : : : ; Wm.
2. Propagate the sigma points through the conditional mean and covari-
ance functions:
.j/
k
D k.X  .j /
k
/;
j D 1; : : : ; m;
P y;.j/
k
D P y
k .X  .j /
k
/;
j D 1; : : : ; m:
(10.38)
3. Compute the required moments:
C;.i 1/
k
D
m
X
j D1
Wj .j/
k ;
P xy;.i 1/
k
D
m
X
j D1
Wj .X  .j /
k
  m.i 1/
k
/ ..j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D
m
X
iD1
Wj

P y;.j /
k
C..j /
k
  C;.i 1/
k
/ ..j /
k
  C;.i 1/
k
/T
:
(10.39)
4. Linearize measurement model using Equations (10.14).
5. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
Finally, we present an IPLF for the conditional distribution models in
(9.10), where we make use of Monte Carlo sampling to approximate the
involved integrals. Please note that in this case one has to be careful with
convergence of the inner iteration, because of its stochasticity.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
224
Posterior Linearization Filtering
Algorithm 10.17 (Monte Carlo iterated posterior linearization ﬁlter). The
prediction and update steps of a Monte Carlo sigma point iterated poste-
rior linearization (Kalman) ﬁlter for conditional distribution models are:
 Prediction:
1. Generate samples of xk 1 as:
x.j/
k 1  N.mk 1; Pk 1/;
j D 1; : : : ; N:
(10.40)
2. Propagate the samples through the dynamic model:
x .j/
k
 p.xk j x.j /
k 1/;
j D 1; : : : ; N:
(10.41)
3. Compute the predicted mean m k and the predicted covariance P  k :
m k D 1
N
N
X
j D1
x .j /
k
;
P  k D 1
N
N
X
j D1
.x .j /
k
  m k / .x .j /
k
  m k /T:
(10.42)
 Update:
Start from the predicted density m.0/
k
D m k , P .0/
k
D P  k .
For i D 1; 2; 3; : : : do the following steps:
1. Generate samples of xk from our current approximation to the poste-
rior:
x.j/
k
 N.m.i 1/
k
; P .i 1/
k
/;
j D 1; : : : ; N:
(10.43)
2. Propagate the samples through the measurement model:
y.j/
k
 p.yk j x.j /
k /;
j D 1; : : : ; N:
(10.44)
3. Compute the required moments:
C;.i 1/
k
D 1
N
N
X
j D1
y.j/
k ;
P xy;.i 1/
k
D 1
N
N
X
j D1
.x.j /
k
  m.i 1/
k
/ .y.j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D 1
N
N
X
iD1
.y.j/
k
  C;.i 1/
k
/ .y.j /
k
  C;.i 1/
k
/T:
(10.45)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.6 Optimality Properties of Different Linearizations
225
4. Linearize measurement model using Equations (10.14).
5. Perform the Kalman update using Equations (10.15).
At convergence, set mk D m.i/
k and Pk D P .i/
k .
10.6 Optimality Properties of Different Linearizations
So far in this book we have seen a selection of different deterministic,
stochastic, and iterative linearizations. It is now useful to discuss in which
sense each of these is optimal. The ﬁrst encountered linearization of a
function g.x/ in Section 7.1 was a Taylor series expansion of it on a given
point m:
g.x/ ' g.m/ C Gx.m/ .x   m/;
(10.46)
where Gx is the Jacobian matrix of g. This linearization can be seen to be
optimal when we wish to approximate the function g very close (inﬁnites-
imally close) to the point x D m. The linearization is exact at this point,
and its accuracy quickly decreases when going away from the point.
A slightly less local linearization, the statistical linearization (SL), was
introduced in Section 9.2, and it was formulated as the linearization of the
form
g.x/ ' A x C b;
(10.47)
which minimizes the mean squared error
MSE.A; b/ D E

.g.x/   A x   b/T .g.x/   A x   b/

;
(10.48)
where x  N.m; P/. This linearization is less local than the Taylor se-
ries expansion in the sense that it is formed with respect to the distribu-
tion N.m; P/ instead of a single point x D m. However, as discussed on
page 174, the Taylor and SL are closely related as SL can be seen as a
Taylor series expansion where g.m/ and Gx.m/ in Equation (10.46) are
replaced with their expectations over N.m; P/. This also implies that SL
becomes exactly the Taylor series expansion when P ! 0, because in this
limit the expectation becomes simply evaluation at the mean.
In Section 9.4 we encountered statistical linear regression (SLR), which
strictly speaking only makes sense as an approximation to a stochastic
mapping such as y D g.x/ C q, where q  N.0; Q/. A linearization
was then found of the form
y ' A x C b C Qe;
(10.49)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
226
Posterior Linearization Filtering
where Qe  N.0; ƒ/. In Section 9.4 the SLR linearization was formed to
match the moments of .x; y/. However, it turns out that there is an error
criterion that this linearization also minimizes (see, e.g., Garc´ıa-Fern´andez
et al., 2015). Let us ﬁrst notice that y D g.x/ C q and y D A x C b C Qe
correspond to the conditional distribution models
p.y j x/ D N.y j g.x/; Q/;
q.y j x/ D N.y j A x C b; ƒ/;
(10.50)
respectively. We can now compute the Kullback–Leibler divergence be-
tween the two Gaussian distributions, which gives
KL.pjjq/ D
Z
log
p.y j x/
q.y j x/

p.y j x/ dy
D 1
2

tr
˚
ƒ 1 Q
	
  n C log
jƒj
jQj

C .g.x/   A x   b/T ƒ 1 .g.x/   A x   b/

;
(10.51)
which is still a function of x. Taking expectation with respect to x 
N.m; P/ then leads to the criterion
MKL.A; b; ƒ/ D 1
2 E

tr
˚
ƒ 1 Q
	
  n C log
jƒj
jQj

C .g.x/   A x   b/T ƒ 1 .g.x/   A x   b/

;
(10.52)
which turns out to be the error criterion that SLR minimizes (see Exer-
cise 10.7). The generalized SLR discussed in Section 10.1 minimizes the
same criterion, except that the distribution of x is replaced with an arbitrary
distribution .x/.
In Chapters 9 and 10 we generalized the SLR to conditional distribu-
tions of the form p.y j x/ that might not in general have a Gaussian form
such as p.y j x/ D N.y j g.x/; Q/. It might appear that a suitable gen-
eralization of SLR would be to replace the Kullback–Leibler divergence in
Equation (10.51) by plugging in p.y j x/. However, this is not correct, but
instead, the correct generalization is obtained by approximating the condi-
tional distribution as
p.y j x/ ' N.y j R.x/; SR.x//;
(10.53)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
10.7 Exercises
227
where R.x/ and SR.x/ are the conditional moments deﬁned as in Equa-
tion (9.46). This then leads to the conditional distribution forms of SLR-
based ﬁlters that we discussed in the mentioned chapters.
In (this) Chapter 10 we ﬁnally discussed posterior linearization, which
corresponds to the selection .x/ D p.x j y/ in SLR. To ﬁnd this lin-
earization we had to resort to iteration (iterated posterior linearization).
The posterior linearization has the optimality property that the posterior
mean and covariance using the linearized model match those of the exact
posterior up to the Gaussian approximations needed on the way to comput-
ing the posterior. Thus in this sense posterior linearization has its maximum
accuracy at the posterior distribution. In this regard the linearization used
in the IEKF in Section 7.4 can be seen as a type of posterior linearization
that maximizes the accuracy of Taylor series expansion under this same
philosophy by linearizing at the MAP estimate of the state.
So far in this book we have only applied the SLR and posterior lin-
earization methods to ﬁlters, but in Chapter 14 we proceed to apply them
to non-linear smoothing as well.
10.7 Exercises
10.1
Show that Equation (10.3) reduces to moment matching only when .x/ is
the actual distribution of x.
10.2
Consider the posterior linearization of y D x3 C r, r  N.0; R/, where
R D 0:1, with respect to x  N.m; P /, where m D 1 and P D 0:1. First
perform the linearization for y D 5, and then repeat it for a few other values
of y. To approximate scalar integrals we can use Riemann sums,
Z
f .x/ dx 
1
X
kD 1
f .kx/ x;
(10.54)
where x is the step length (say, 0:01). In practice, it is sufﬁcient to sum k
from n1 to n2 where f .kx/  0 for k < n1 and k > n2.
(a) Use Riemann sums to approximate
I D
Z
N.y j x3; R/ N.x j m; P / dx;
(10.55)
and plot the posterior density
p.x j y/ D N.y j x3; R/ N.x j m; P /
I
:
(10.56)
Note that this becomes an accurate approximation to the posterior for
small values of x. If you prefer, you can instead use Monte Carlo
sampling to approximate the integrals in this exercise.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
228
Posterior Linearization Filtering
(b) Use Riemann sums to perform posterior linearization. Then plot x3 and
the deterministic part, Ax C b, of the posterior linearization. Does the
linearization appear to be accurate in the support of the posterior den-
sity?
Hint: You need to compute the integrals in Corollary 10.3. To this end,
it is helpful to notice that we have
g.x/ D x3;
.x/ D 1
I N.y j x3; R/ N.x j m; P /:
(10.57)
(c) Use the linearized model to compute the posterior density. Plot the result
along with the posterior density computed in (a).
Hint: Note that the linearized model is used to approximate the mea-
surement model, which is then used to (Kalman) update the prior N.x j
m; P /.
(d) Perform a prior linearization, that is, perform an SLR where x is instead
distributed according to the prior, x  N.m; P /. Plot the deterministic
part A x C b along with x3 and the deterministic part of the posterior
linearization in (b).
(e) Use the prior linearization to approximate the posterior density. Plot the
result along with the densities from (b) and (c).
10.3
Use Riemann sums to perform iterated posterior linearization for the model
in Exercise 10.2. It should be sufﬁcient to run the algorithm for a handful
of iterations. Plot A x C b and the approximation of the posterior density ,
at different iterations, along with x3 and the accurate approximation of the
posterior density from Exercise 10.2, respectively.
10.4
Formulate an IPL algorithm that makes use of the spherical cubature rule
to approximate integrals. Use the algorithm to approximate the posterior
density in Exercise 10.2 and compare with the results from Exercise 10.3.
10.5
Implement a GHKF-based IPLF for the model in Exercise 7.1. Plot the re-
sults and compare the RMSE values with other ﬁlters.
10.6
Implement a spherical cubature rule-based IPLF for the bearings-only target
tracking problem in Exercise 7.2. Compare the performance with the EKF
and CKF.
10.7
Show that SLR minimizes the error criterion in Equation (10.52).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11
Particle Filtering
Although in many ﬁltering problems Gaussian approximations work well,
sometimes the ﬁltering distributions can be, for example, multi-modal, or
some of the state components might be discrete, in which case Gaussian
approximations are not appropriate. In such cases sequential importance
resampling-based particle ﬁlters can be a better alternative. This chapter is
concerned with particle ﬁlters, which are methods for forming Monte Carlo
approximations to the solutions of the Bayesian ﬁltering equations.
11.1 Monte Carlo Approximations in Bayesian Inference
In Bayesian inference, including Bayesian ﬁltering, the main inference
problem can often be reduced to computation of the following kind of ex-
pectations over the posterior distribution:1
EŒg.x/ j y1WT  D
Z
g.x/ p.x j y1WT / dx;
(11.1)
where g W Rn ! Rm is an arbitrary function, and p.x j y1WT / is the
posterior probability density of x given the measurements y1; : : : ; yT . Now
the problem is that such an integral can be evaluated in closed form only in
a few special cases, and generally, numerical methods have to be used.
Monte Carlo methods provide a numerical method for calculating inte-
grals of the form (11.1). Monte Carlo refers to a general class of methods
where closed form computation of statistical quantities is replaced by draw-
ing samples from the distribution and estimating the quantities by sample
averages.
1 In this section we formally treat x as a continuous random variable with a density, but
the analogous results apply to discrete random variables.
229

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
230
Particle Filtering
−5
0
5
−5
0
5
(a)
−5
0
5
−5
0
5
(b)
Figure 11.1 (a) Two-dimensional Gaussian distribution. (b)
Monte Carlo representation of the same Gaussian distribution.
In a (perfect) Monte Carlo approximation, we draw N independent ran-
dom samples x.i/  p.x j y1WT /, i D 1; : : : ; N and estimate the expecta-
tion as
EŒg.x/ j y1WT   1
N
N
X
iD1
g.x.i//:
(11.2)
Thus Monte Carlo methods approximate the target distribution by a set
of samples that are distributed according to the target density. Figure 11.1
represents a two-dimensional Gaussian distribution and its Monte Carlo
representation.
The convergence of the Monte Carlo approximation is guaranteed by the
law of large numbers (LLN) and the central limit theorem (CLT, see, e.g.,
Liu, 2001), and the error term is O.N  1=2/, regardless of the dimensional-
ity of x. This invariance with respect to dimensionality is unique to Monte
Carlo methods and makes them superior to practically all other numerical
methods when the dimensionality of x is considerable – at least in the-
ory, not necessarily in practice (see Daum and Huang, 2003; Snyder et al.,
2008).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.2 Importance Sampling
231
11.2 Importance Sampling
Often, in practical Bayesian models, it is not possible to obtain samples
directly from p.x j y1WT / due to its complicated functional form. In im-
portance sampling (IS) (see, e.g., Liu, 2001) we use an approximate dis-
tribution called the importance distribution .x j y1WT /, from which we
can easily draw samples. Importance sampling is based on the following
decomposition of the expectation over the posterior probability density
p.x j y1WT /:
Z
g.x/ p.x j y1WT / dx D
Z 
g.x/ p.x j y1WT /
.x j y1WT /

.x j y1WT / dx;
(11.3)
where the importance density .x j y1WT / is required to be non-zero when-
ever p.x j y1WT / is non-zero, that is, the support of .x j y1WT / needs to be
greater than or equal to the support of p.x j y1WT /. As the above expres-
sion is just the expectation of the term in the brackets over the distribution
.x j y1WT /, we can form a Monte Carlo approximation to it by drawing N
samples from the importance distribution:
x.i/  .x j y1WT /;
i D 1; : : : ; N
(11.4)
and by forming the approximation as
EŒg.x/ j y1WT   1
N
N
X
iD1
p.x.i/ j y1WT /
.x.i/ j y1WT / g.x.i//
D
N
X
iD1
Qw.i/ g.x.i//;
(11.5)
where the weights have been deﬁned as
Qw.i/ D 1
N
p.x.i/ j y1WT /
.x.i/ j y1WT /:
(11.6)
Figure 11.2 illustrates the idea of importance sampling. We sample from
the importance distribution, which is an approximation to the target distri-
bution. Because the distribution of samples is not exact, we need to correct
the approximation by associating a weight with each of the samples.
The disadvantage of this direct importance sampling is that we should
be able to evaluate p.x.i/ j y1WT / in order to use it directly. Recall that
by Bayes’ rule, the evaluation of the posterior probability density can be

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
232
Particle Filtering
-4
-2
0
2
4
 x
0
0.1
0.2
0.3
0.4
0.5
0.6
 p(x)
Target Distribution
Importance Distribution
(a)
0
0.005
0.01
0.015
0.02
0.025
0.03
Weight
-4
-2
0
2
4
 x
(b)
Figure 11.2 (a) The importance distribution approximates the
target distribution. (b) Weights are associated with each of the
samples to correct the approximation.
written as
p.x.i/ j y1WT / D p.y1WT j x.i// p.x.i//
R
p.y1WT j x/ p.x/ dx:
(11.7)
The likelihood p.y1WT j x.i// and prior terms p.x.i// are usually easy to
evaluate, but often the integral in the denominator – the normalization con-
stant – cannot be computed. To overcome this problem, we can form an
importance sampling approximation to the expectation integral by also ap-
proximating the normalization constant by importance sampling. For this

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.2 Importance Sampling
233
purpose we can decompose the expectation integral and form the approxi-
mation as follows:
EŒg.x/ j y1WT  D
Z
g.x/ p.x j y1WT / dx
D
R
g.x/ p.y1WT j x/ p.x/ dx
R
p.y1WT j x/ p.x/ dx
D
R h
p.y1WT jx/ p.x/
.xjy1WT /
g.x/
i
.x j y1WT / dx
R h
p.y1WT jx/ p.x/
.xjy1WT /
i
.x j y1WT / dx

1
N
PN
iD1
p.y1WT jx.i// p.x.i//
.x.i/jy1WT /
g.x.i//
1
N
PN
j D1
p.y1WT jx.j// p.x.j//
.x.j/jy1WT /
D
N
X
iD1
2
4
p.y1WT jx.i// p.x.i//
.x.i/jy1WT /
PN
j D1
p.y1WT jx.j// p.x.j//
.x.j/jy1WT /
3
5
„
ƒ‚
…
w.i/
g.x.i//:
(11.8)
Thus we get the following algorithm.
Algorithm 11.1 (Importance sampling). Given a measurement model
p.y1WT
j x/ and a prior p.x/, we can form an importance sampling
approximation to the posterior as follows.
1. Draw N samples from the importance distribution:
x.i/  .x j y1WT /;
i D 1; : : : ; N:
(11.9)
2. Compute the unnormalized weights by
w.i/ D p.y1WT j x.i// p.x.i//
.x.i/ j y1WT /
(11.10)
and the normalized weights by
w.i/ D
w.i/
PN
j D1 w.j / :
(11.11)
3. The approximation to the posterior expectation of g.x/ is then given as
EŒg.x/ j y1WT  
N
X
iD1
w.i/ g.x.i//:
(11.12)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
234
Particle Filtering
The approximation to the posterior probability density formed by the
above algorithm can then be formally written as
p.x j y1WT / 
N
X
iD1
w.i/ ı.x   x.i//;
(11.13)
where ı./ is the Dirac delta function.
11.3 Sequential Importance Sampling
Sequential importance sampling (SIS) (see, e.g., Doucet et al., 2001) is a
sequential version of importance sampling. The SIS algorithm can be used
for generating importance sampling approximations to ﬁltering distribu-
tions of generic state space models of the form
xk  p.xk j xk 1/;
yk  p.yk j xk/;
(11.14)
where xk 2 Rn is the state at time step k. and yk 2 Rm is the measurement.
The state and measurements may contain both discrete and continuous
components.
The SIS algorithm uses a weighted set of particles f.w.i/
k ; x.i/
k / W i D
1; : : : ; N g, that is, samples from an importance distribution and their
weights, to represent the ﬁltering distribution p.xk j y1Wk/ such that at
every time step k the approximation to the expectation of an arbitrary
function g./ can be calculated as the weighted sample average
EŒg.xk/ j y1Wk 
N
X
iD1
w.i/
k g.x.i/
k /:
(11.15)
Equivalently, SIS can be interpreted as forming an approximation to the
ﬁltering distribution as
p.xk j y1Wk/ 
N
X
iD1
w.i/
k ı.xk   x.i/
k /:
(11.16)
To derive the algorithm, we consider the full posterior distribution of states
x0Wk given the measurements y1Wk. By using the Markov properties of the

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.3 Sequential Importance Sampling
235
model, we get the following recursion for the posterior distribution:
p.x0Wk j y1Wk/ / p.yk j x0Wk; y1Wk 1/ p.x0Wk j y1Wk 1/
D p.yk j xk/ p.xk j x0Wk 1; y1Wk 1/ p.x0Wk 1 j y1Wk 1/
D p.yk j xk/ p.xk j xk 1/ p.x0Wk 1 j y1Wk 1/:
(11.17)
Using a similar rationale as in the previous section, we can now construct
an importance sampling method that draws samples from a given impor-
tance distribution x.i/
0Wk  .x0Wk j y1Wk/ and computes the importance
weights by
w.i/
k
/ p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/ p.x.i/
0Wk 1 j y1Wk 1/
.x.i/
0Wk j y1Wk/
:
(11.18)
If we form the importance distribution for the states xk recursively as fol-
lows:
.x0Wk j y1Wk/ D .xk j x0Wk 1; y1Wk/ .x0Wk 1 j y1Wk 1/;
(11.19)
then the expression for the weights can be written as
w.i/
k
/ p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/
.x.i/
k j x.i/
0Wk 1; y1Wk/
p.x.i/
0Wk 1 j y1Wk 1/
.x.i/
0Wk 1 j y1Wk 1/
:
(11.20)
Let us now assume that we have already drawn the samples x.i/
0Wk 1 from the
importance distribution .x0Wk 1 j y1Wk 1/ and computed the correspond-
ing importance weights w.i/
k 1. We can now draw samples x.i/
0Wk from the
importance distribution .x0Wk j y1Wk/ by drawing the new state samples
for the step k as x.i/
k  .xk j x.i/
0Wk 1; y1Wk/. The importance weights from
the previous step are proportional to the last term in Equation (11.20):
w.i/
k 1 / p.x.i/
0Wk 1 j y1Wk 1/
.x.i/
0Wk 1 j y1Wk 1/
;
(11.21)
and thus the weights satisfy the recursion
w.i/
k
/ p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/
.x.i/
k j x.i/
0Wk 1; y1Wk/
w.i/
k 1:
(11.22)
The generic sequential importance sampling algorithm can now be de-
scribed as follows.
Algorithm 11.2 (Sequential importance sampling). The steps of SIS are
the following:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
236
Particle Filtering
 Draw N samples x.i/
0 from the prior
x.i/
0  p.x0/;
i D 1; : : : ; N;
(11.23)
and set w.i/
0
D 1=N for all i D 1; : : : ; N .
 For each k D 1; : : : ; T , do the following.
1. Draw samples x.i/
k from the importance distributions
x.i/
k  .xk j x.i/
0Wk 1; y1Wk/;
i D 1; : : : ; N:
(11.24)
2. Calculate new weights according to
w.i/
k
/ w.i/
k 1
p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/
.x.i/
k j x.i/
0Wk 1; y1Wk/
;
(11.25)
and normalize them to sum to unity.
Note that it is convenient to select the importance distribution to be
Markovian in the sense that
.xk j x0Wk 1; y1Wk/ D .xk j xk 1; y1Wk/:
(11.26)
With this form of importance distribution we do not need to store the whole
histories x.i/
0Wk in the SIS algorithm, only the current states x.i/
k . This form is
also convenient in sequential importance resampling (SIR) discussed in the
next section, because we do not need to worry about the state histories dur-
ing the resampling step as in the SIR particle smoother (see Section 15.1).
Thus in the following section we assume that the importance distribution
has indeed been selected to have the above Markovian form.
11.4 Resampling
One problem in the SIS algorithm described in the previous section is that
we can easily encounter the situation where almost all the particles have
zero or nearly zero weights. This is called the degeneracy problem in par-
ticle ﬁltering literature, and it prevented practical applications of particle
ﬁlters for many years.
The degeneracy problem can be solved by using a resampling procedure.
It refers to a procedure where we draw N new samples from the discrete
distribution deﬁned by the weights and replace the old set of N samples
with this new set. This procedure can be written as the following algorithm.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.4 Resampling
237
Algorithm 11.3 (Resampling).
The resampling procedure can be
described as follows.
1. Interpret each weight w.i/
k
as the probability of obtaining the sample
index i in the set fx.i/
k
W i D 1; : : : ; N g.
2. Draw N samples from that discrete distribution, and replace the old
sample set with this new one.
3. Set all weights to the constant value w.i/
k
D 1=N.
What resampling actually does is the following. Recall that sequential
importance sampling (SIR) described in Section 11.3 forms a weighted
set of samples f.w.i/
k ; x.i/
k /
W
i D 1; : : : ; N g such that the posterior
expectation of a function g.xk/ can be approximated as
EŒg.xk/ j y1Wk 
N
X
iD1
w.i/
k g.x.i/
k /:
(11.27)
Let us now sample an index A with probabilities .w.1/
k ; : : : ; w.N /
k
/. Then
the expected value over the index is simply the original one:
EAŒg.x.A/
k / j y1Wk D
N
X
iD1
p.A D i/ g.x.i/
k / D
N
X
iD1
w.i/
k g.x.i/
k /:
(11.28)
If we sample N indices A1WN D .A1; : : : ; AN/ and compute their average,
we get an approximation
EŒg.xk/ j y1Wk  1
N
N
X
iD1
g.x.Ai/
k
/;
(11.29)
which has the form of a non-weighted (plain) Monte Carlo. The expected
value over A1WN is still the same (i.e., resampling is unbiased):
EA1WN
"
1
N
N
X
iD1
g.x.Ai/
k
/
#
D
N
X
iD1
w.i/
k g.x.i/
k /:
(11.30)
The idea of resampling is to replace the weighted sample set .w.i/; x.i//
with the newly indexed sample set x.Ai/, which then also effectively re-
sets the weights to w.i/
k
D 1=N . This procedure has the effect of remov-
ing particles with very small weights and duplicating particles with large
weights. Although the theoretical distribution represented by the weighted
set of samples does not change, resampling introduces additional variance
to estimates. This variance introduced by the resampling procedure can be
reduced by proper choice of the resampling method.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
238
Particle Filtering
A naive way to do resampling is to draw N times independently from the
multinomial distribution deﬁned by the weights .w.1/
k ; : : : ; w.N /
k
/. How-
ever, this is inefﬁcient and has high variance and is therefore not recom-
mended. Instead, it is advisable to use more sophisticated resampling al-
gorithms, of which Chopin and Papaspiliopoulos (2020) provide a uniﬁed
formulation. Resampling algorithms (or at least many of them) can be seen
as different ways of a drawing sorted array of uniform random variables
u.i/ for i D 1; : : : ; N such that u.1/ <    < u.N /, which are then used in
the following inverse transform sampler of indices A1WN.
Algorithm 11.4 (Inverse transform sampling for resampling). The resam-
pling indices A1; : : : ; AN can be drawn as follows. Given the weights w.i/
and ordered uniforms u.i/ for i D 1; : : : ; N , do the following:
 Set m D 1 and s D w.1/.
 For n D 1; : : : ; N do
– While s < u.n/ do
ı Set m D m C 1.
ı Set s D s C w.m/.
– Set An D m.
Using Algorithm 11.4, we can implement different resampling methods
(Chopin and Papaspiliopoulos, 2020). The multinomial resampling method
becomes the following.
Algorithm 11.5 (Multinomial resampling). Given the importance weights
w.1/; : : : ; w.N/, we can draw the resampling indices A1; : : : ; AN by using
multinomial resampling as follows.
 Draw v.j/  U.0; 1/ for j D 1; : : : ; N C 1.
 Compute the cumulative sum t.j / D   Pj
iD1 log v.i/.
 Put u.i/ D t.i/=t .N C1/.
 Run the sampling routine in Algorithm 11.4 with the weights w.i/ and
uniforms u.i/ for i D 1; : : : ; N .
However, multinomial resampling has high variance and therefore is
not recommended for many uses. A lower variance alternative is stratiﬁed
resampling, which is the following.
Algorithm 11.6 (Stratiﬁed resampling). Given the importance weights
w.1/; : : : ; w.N/, we can draw the resampling indices A1; : : : ; AN by using
stratiﬁed resampling as follows.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.5 Particle Filter
239
 For n D 1; : : : ; N do
– Sample u.n/  U ..n   1/=N; n=N/.
 Run the sampling routine in Algorithm 11.4 with the weights w.i/ and
uniforms u.i/ for i D 1; : : : ; N .
One more choice for resampling is systematic resampling, which can be
implemented as follows.
Algorithm 11.7 (Systematic resampling). Given the importance weights
w.1/; : : : ; w.N/, we can draw the resampling indices A1; : : : ; AN by using
systematic resampling as follows.
 Sample u  U.0; 1/.
 For n D 1; : : : ; N do
– Set u.n/ D .n   1/=N C u=N.
 Run the sampling routine in Algorithm 11.4 with the weights w.i/ and
uniforms u.i/ for i D 1; : : : ; N .
All the aforementioned resampling methods are unbiased and therefore
valid choices for resampling. For practical use, Chopin and Papaspiliopou-
los (2020) recommend systematic resampling, although its theoretical
properties are not as clear as those of the other methods. In this sense
stratiﬁed resampling is a safe choice as it is ensured to have a lower
variance than multinomial resampling (Chopin and Papaspiliopoulos,
2020).
11.5 Particle Filter
Adding a resampling step to the sequential importance sampling algorithm
leads to sequential importance resampling (SIR)2 (Gordon et al., 1993;
Kitagawa, 1996; Doucet et al., 2001; Ristic et al., 2004; Chopin and Pa-
paspiliopoulos, 2020), which is the algorithm usually referred to as the
particle ﬁlter. In SIR, resampling is not usually performed at every time
step, but only when it is actually needed. One way of implementing this is
to do resampling on every nth step, where n is some predeﬁned constant.
Another way, which is used here, is adaptive resampling. In this method,
the “effective” number of particles, which is estimated from the variance of
the particle weights (Liu and Chen, 1995), is used for monitoring the need
2 Sequential importance resampling is also often referred to as sampling importance
resampling or sequential importance sampling resampling.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
240
Particle Filtering
for resampling. The estimate for the effective number of particles (or ef-
fective sample size, Chopin and Papaspiliopoulos, 2020) can be computed
as
neff 
1
PN
iD1

w.i/
k
2 ;
(11.31)
where w.i/
k
is the normalized weight of particle i at the time step k (Liu
and Chen, 1995). Resampling is performed when the effective number of
particles is signiﬁcantly less than the total number of particles, for example,
neff < N=10, where N is the total number of particles.
Algorithm 11.8 (Sequential importance resampling). The sequential im-
portance resampling (SIR) algorithm, which is also called the particle ﬁlter
(PF), is the following.
 Draw N samples x.i/
0 from the prior
x.i/
0  p.x0/;
i D 1; : : : ; N;
(11.32)
and set w.i/
0
D 1=N , for all i D 1; : : : ; N .
 For each k D 1; : : : ; T do the following:
1. Draw samples x.i/
k from the importance distributions
x.i/
k  .xk j x.i/
k 1; y1Wk/;
i D 1; : : : ; N:
(11.33)
2. Calculate new weights according to
w.i/
k
/ w.i/
k 1
p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/
.x.i/
k j x.i/
k 1; y1Wk/
;
(11.34)
and normalize them to sum to unity.
3. If the effective number of particles (11.31) is too low, perform resam-
pling.
The SIR algorithm forms the following approximation to the ﬁltering
distribution:
p.xk j y1Wk/ 
N
X
iD1
w.i/
k ı.xk   x.i/
k /;
(11.35)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.5 Particle Filter
241
and thus the expectation of an arbitrary function g./ can be approximated
as
EŒg.xk/ j y1Wk 
N
X
iD1
w.i/
k g.x.i/
k /:
(11.36)
Performance of the SIR algorithm depends on the quality of the impor-
tance distribution ./. The importance distribution should be in such a
functional form that we can easily draw samples from it and that it is pos-
sible to evaluate the probability densities of the sample points. The optimal
importance distribution in terms of variance (see, e.g., Doucet et al., 2001;
Ristic et al., 2004) is
.xk j x0Wk 1; y1Wk/ D p.xk j xk 1; yk/:
(11.37)
If the optimal importance distribution cannot be directly used, importance
distributions can sometimes be obtained by local linearization, where
a mixture of extended Kalman ﬁlters (EKF), unscented Kalman ﬁlters
(UKF), or other types of non-linear Kalman ﬁlters are used for forming the
importance distribution (Doucet et al., 2000; Van der Merwe et al., 2001).
It is also possible to use a Metropolis–Hastings step after (or in place of)
the resampling step to smooth the resulting distribution (Van der Merwe
et al., 2001). A particle ﬁlter with UKF importance distribution is also
referred to as the unscented particle ﬁlter (UPF). Similarly, we could
call a particle ﬁlter with the Gauss–Hermite Kalman ﬁlter importance
distribution the Gauss–Hermite particle ﬁlter (GHPF) and one with the
cubature Kalman ﬁlter importance distribution the cubature particle
ﬁlter (CPF). The use of iterated posterior linearization ﬁlters to form the
proposal has also been investigated in Hostettler et al. (2020). However,
the use of this kind of importance distribution can also lead to the failure
of particle ﬁlter convergence, and hence they should be used with extreme
care. Instead of forming the importance distribution directly by using the
Gaussian approximation provided by the EKF, UKF, or other Gaussian
ﬁlter, it may be advisable to artiﬁcially increase the covariance of the
distribution or to replace the Gaussian distribution with a Student’s t
distribution with a suitable number of degrees of freedom (see Capp´e
et al., 2005).
By tuning the resampling algorithm to speciﬁc estimation problems and
possibly changing the order of weight computation and sampling, accuracy
and computational efﬁciency of the algorithm can be improved (Fearnhead
and Clifford, 2003). An important issue is that sampling is more efﬁcient
without replacement, such that duplicate samples are not stored. There is

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
242
Particle Filtering
also evidence that in some situations it is more efﬁcient to use a simple
deterministic algorithm for preserving the N most likely particles. In the
article by Punskaya et al. (2002), it is shown that in digital demodulation,
where the sampled space is discrete and the optimization criterion is the
minimum error, the deterministic algorithm performs better.
The bootstrap ﬁlter (Gordon et al., 1993) is a variation of SIR where the
dynamic model p.xk j xk 1/ is used as the importance distribution. This
makes the implementation of the algorithm very easy, but due to the inefﬁ-
ciency of the importance distribution it may require a very large number of
Monte Carlo samples for accurate estimation results. In the bootstrap ﬁlter
the resampling is normally done at each time step.
Algorithm 11.9 (Bootstrap ﬁlter). The bootstrap ﬁlter algorithm is as fol-
lows.
1. Draw a new point x.i/
k for each point in the sample set fx.i/
k 1 W i D
1; : : : ; N g from the dynamic model:
x.i/
k  p.xk j x.i/
k 1/;
i D 1; : : : ; N:
(11.38)
2. Calculate the weights
w.i/
k
/ p.yk j x.i/
k /;
i D 1; : : : ; N;
(11.39)
and normalize them to sum to unity.
3. Do resampling.
One problem encountered in particle ﬁltering, even when using a resam-
pling procedure, is called sample impoverishment (see, e.g., Ristic et al.,
2004). It refers to the effect that when the noise in the dynamic model is
very small, many of the particles in the particle set will turn out to have ex-
actly the same value. That is, the resampling step simply multiplies a few
(or one) particle(s), and thus we end up having a set of identical copies of
certain high weighted particles. This problem can be diminished by using,
for example, the resample-move algorithm, regularization, or MCMC steps
(Ristic et al., 2004).
Because low noise in the dynamic model causes sample impoverish-
ment, it also implies that pure recursive estimation with particle ﬁlters
is challenging. This is because in pure recursive estimation the process
noise is formally zero and thus a basic SIR-based particle ﬁlter is likely
to perform very badly. Pure recursive estimation, such as recursive esti-
mation of static parameters, can sometimes be done by applying a Rao–
Blackwellized particle ﬁlter instead of the basic SIR particle ﬁlter (see

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.5 Particle Filter
243
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
PF estimate
Figure 11.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with a bootstrap type of
particle ﬁlter (PF) with 10,000 particles. The resulting RMSE was
0:10, which is approximately the same as the best Gaussian ﬁlters.
Section 16.3.6). However, the more common use of Rao–Blackwellization
is in the conditionally linear Gaussian state space models, which we will
discuss in Section 11.7.
Example 11.10 (Pendulum tracking with a particle ﬁlter). The result of the
bootstrap ﬁlter with 10,000 particles in the pendulum model (Example 7.6)
is shown in Figure 11.3. The RMSE of 0:10 is approximately the same as
that of the best Gaussian ﬁlters. This implies that in this case the ﬁltering
distribution is indeed quite well approximated by a Gaussian distribution,
and thus using a particle ﬁlter is not particularly beneﬁcial.
In the above example the model is of the type that is suitable for Gaus-
sian approximation-based ﬁlters, and thus the particle ﬁlter produces much
the same result as they do. But often the noises in the system are not Gaus-
sian, or there might be clutter (outlier) measurements that do not ﬁt into the
Gaussian non-linear state space modeling framework at all. In these kinds
of models, the particle ﬁlter still produces good results, whereas Gaussian
ﬁlters do not work at all. The next example illustrates this kind of situation.
Example 11.11 (Cluttered pendulum tracking with a particle ﬁlter). In this
scenario, the pendulum sensor is broken such that at each time instant it
produces clutter (a random number in the range Œ 2; 2) with probability

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
244
Particle Filtering
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
PF estimate
GHKF estimate
Figure 11.4 Simulated pendulum data in the presence of 50%
clutter (outlier) measurements and the result of tracking with a
bootstrap type of particle ﬁlter (PF) with 10,000 particles (see
Example 11.11). The resulting RMSE was 0:20. The
corresponding error of GHKF was 0.89.
50%, which is a situation that can be modeled with the model given in
Example 5.6. The result of the bootstrap ﬁlter using that model is shown
in Figure 11.4. The RMSE of 0:20 is higher than in the clutter-free case,
but still moderate. In Gaussian ﬁlters a clutter model cannot be easily
implemented. In Figure 11.4 we also show the result of a Gauss–Hermite
Kalman ﬁlter (GHKF), with no clutter model at all, applied to the data.
The resulting RMSE is 0.89, which is signiﬁcantly higher than that of the
bootstrap ﬁlter.
11.6 Auxiliary Particle Filter
The idea of an auxiliary particle ﬁlter (APF, Pitt and Shephard, 1999; Aru-
lampalam et al., 2002; Johansen and Doucet, 2008; Doucet and Johansen,
2011) is to introduce an auxiliary variable  to enable us to use yk to adjust
the probability by which we sample different particles. The construction
results in a ﬁlter that resembles a particle ﬁlter that uses the optimal impor-
tance distribution.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.6 Auxiliary Particle Filter
245
If our weighted particle set at time step k   1 is fx.i/
k 1; w.i/
k 1g for i D
1; : : : ; N , then the predicted density at time step k can be approximated as
p.xk j y1Wk 1/ 
X
i
p.xk j x.i/
k 1/ w.i/
k 1;
(11.40)
and an approximate ﬁltering distribution can be formed as
Op.xk j y1Wk/ / p.yk j xk/
X
i
p.xk j x.i/
k 1/ w.i/
k 1:
(11.41)
A key challenge is that many particles may explain yk poorly, and if we
sample particles at time step k as described in earlier sections, those par-
ticles are likely to obtain a small weight, which means that they do not
contribute much to our representation of the posterior.
Let us instead introduce the augmented target distribution
Op.xk;  j y1Wk/ / p.yk j xk/ p.xk j x./
k 1/ w./
k 1;
(11.42)
where  D 1; : : : ; N is the auxiliary variable. By sampling from this joint
distribution and then discarding , we can generate a sample from the dis-
tribution in Equation (11.41). To do that, we can use sequential impor-
tance sampling, which amounts to sampling from an importance distribu-
tion x.i/
k ; .i/  k.xk;  j y1Wk/ and then computing weights as
w.i/
k
/ p.yk j x.i/
k / p.x.i/
k j x..i//
k 1 / w..i//
k 1
k.x.i/
k ; .i/ j y1Wk/
:
(11.43)
A convenient choice of importance distribution (Pitt and Shephard, 1999)
is
k.xk;  j y1Wk/ / p.yk j ./
k / p.xk j x./
k 1/ w./
k 1;
(11.44)
where ./
k
is, for example, the mean, the mode, a draw, or some other
likely value associated with p.xk j x./
k 1/. By construction, the importance
distribution has the marginal and conditional distributions as follows:
k. j y1Wk/ / w./
k 1 p.yk j ./
k /;
k.xk j ; y1Wk/ D p.xk j x./
k 1/;
(11.45)
which implies that we can sample from the importance distribution by
ﬁrst generating an auxiliary variable with probability ./ / k. j y1Wk/
and then sampling from p.xk j x./
k 1/. Note that we have managed to
incorporate knowledge about yk to adjust the probability by which we

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
246
Particle Filtering
sample different particle indexes. The probabilities ./ are often called
the ﬁrst-stage weights in the algorithm (Pitt and Shephard, 1999).
Using the importance distribution in Equation (11.44), the weights in
Equation (11.43) reduce to
w.i/
k
/
p.yk j x.i/
k /
p.yk j ..i//
k
/
:
(11.46)
These weights could now be used as in a standard SIR algorithm to do
(adaptive) resampling. However, it has been shown (see, e.g., Johansen
and Doucet, 2008) that this additional resampling step is not required or
beneﬁcial.
The resulting algorithm is the following.
Algorithm 11.12 (Auxiliary particle ﬁlter). The steps of auxiliary particle
ﬁlter (APF) are:
 Draw samples x.i/
0 from the prior and set w.i/
0
D 1=N for i D 1; : : : ; N .
 For each k D 1; : : : ; T do the following:
1. Generate .i/
k from p.xk j x.i/
k 1/.
2. Compute the ﬁrst-stage weights
.i/ / w.i/
k 1 p.yk j .i/
k /;
(11.47)
and normalize them to sum to unity.
3. Resample f.; .i//g to get a new set of indices .i/.
4. Draw new samples from the dynamic model
x.i/
k  p.x.i/
k j x..i//
k 1 /:
(11.48)
5. Compute new weights
w.i/
k
/
p.yk j x.i/
k /
p.yk j ..i//
k
/
;
(11.49)
and normalize them to sum to unity.
In step 3 we have used resampling in a slightly different way than in
the previous particle ﬁltering algorithms. Recall that resampling is usually
implemented by drawing new indices from the discrete distribution deﬁned
by the probabilities .i/ (or w.i/
k
in conventional particle ﬁlters), and then
these indices are used to select the resampled particles. In step 3 of Algo-
rithm 11.12, we instead store the indices themselves to use them in steps

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.7 Rao–Blackwellized Particle Filter
247
4 and 5. For a discussion on the relationship and differences between aux-
iliary particle ﬁlters and conventional particle ﬁlters, please see Johansen
and Doucet (2008).
11.7 Rao–Blackwellized Particle Filter
One way of improving the efﬁciency of SIR is to use Rao–Blackwellization.
The idea of the Rao–Blackwellized particle ﬁlter (RBPF) (Akashi and
Kumamoto, 1977; Doucet et al., 2001; Ristic et al., 2004), which is also
called the mixture Kalman ﬁlter (MKF) (Chen and Liu, 2000), is that
sometimes it is possible to evaluate some of the ﬁltering equations ana-
lytically and the others with Monte Carlo sampling instead of computing
everything with pure sampling. According to the Rao–Blackwell theorem
(see, e.g., Berger, 1985), this leads to estimators with less variance than
could be obtained with pure Monte Carlo sampling. An intuitive way of
understanding this is that the marginalization replaces the ﬁnite Monte
Carlo particle set representation with an inﬁnite closed form particle set,
which is always more accurate than any ﬁnite set.
Most commonly Rao–Blackwellized particle ﬁltering refers to marginal-
ized ﬁltering of conditionally linear Gaussian models of the form
p.xk j xk 1; uk 1/ D N.xk j Ak 1.uk 1/ xk 1; Qk 1.uk 1//;
p.yk j xk; uk/ D N.yk j Hk.uk/ xk; Rk.uk//;
p.uk j uk 1/ D (any given form);
(11.50)
where xk is the state, yk is the measurement, and uk is an arbitrary la-
tent variable. If in addition the prior of xk is Gaussian, then due to the
conditionally linear Gaussian structure of the model, the state variables xk
can be integrated out analytically, and only the latent variables uk need to
be sampled. The Rao–Blackwellized particle ﬁlter uses SIR for the latent
variables and computes the conditionally Gaussian part in closed form.
To derive the ﬁltering algorithm, ﬁrst note that the full posterior distri-
bution at step k can be factored as
p.u0Wk; x0Wk j y1Wk/ D p.x0Wk j u0Wk; y1Wk/ p.u0Wk j y1Wk/;
(11.51)
where the ﬁrst term is Gaussian and computable with the Kalman ﬁlter
and RTS smoother. For the second term we get the following recursion

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
248
Particle Filtering
analogously to Equation (11.17):
p.u0Wk j y1Wk/
/ p.yk j u0Wk; y1Wk 1/ p.u0Wk j y1Wk 1/
D p.yk j u0Wk; y1Wk 1/ p.uk j u0Wk 1; y1Wk 1/ p.u0Wk 1 j y1Wk 1/
D p.yk j u0Wk; y1Wk 1/ p.uk j uk 1/ p.u0Wk 1 j y1Wk 1/;
(11.52)
where we have used the Markovianity of uk. Now the measurements are
not conditionally independent given uk, and thus the ﬁrst term differs from
the corresponding term in Equation (11.17). The ﬁrst term can be com-
puted by running the Kalman ﬁlter with ﬁxed u0Wk over the measurement
sequence. The second term is just the dynamic model, and the third term is
the posterior from the previous step.
If we form the importance distribution recursively as follows:
.u0Wk j y1Wk/ D .uk j u0Wk 1; y1Wk/ .u0Wk 1 j y1Wk 1/;
(11.53)
then by following the same derivation as in Section 11.3, we get the fol-
lowing recursion for the weights:
w.i/
k
/ p.yk j u.i/
0Wk; y1Wk 1/ p.u.i/
k j u.i/
k 1/
.u.i/
k j u.i/
0Wk 1; y1Wk/
w.i/
k 1;
(11.54)
which corresponds to Equation (11.22). Thus via the above recursion we
can form an importance sampling-based approximation to the marginal dis-
tribution p.u0Wk j y1Wk/. But because, given u0Wk, the distribution p.x0Wk j
u0Wk; y1Wk/ is Gaussian, we can form the full posterior distribution by us-
ing Equation (11.51). Computing the distribution jointly for the full history
x0Wk would require running both the Kalman ﬁlter and the RTS smoother
over the sequences u0Wk and y1Wk, but if we are only interested in the pos-
terior of the last time step xk, we only need to run the Kalman ﬁlter. The
resulting algorithm is the following.
Algorithm 11.13 (Rao–Blackwellized particle ﬁlter). Given a sequence of
importance distributions .uk j u.i/
0Wk 1; y1Wk/ and a set of weighted sam-
ples fw.i/
k 1; u.i/
k 1; m.i/
k 1; P .i/
k 1 W i D 1; : : : ; N g, the Rao–Blackwellized
particle ﬁlter (RBPF) processes the measurement yk as follows (Doucet
et al., 2001).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
11.7 Rao–Blackwellized Particle Filter
249
1. Perform Kalman ﬁlter predictions for each of the Kalman ﬁlter means
and covariances in the particles i D 1; : : : ; N conditional on the pre-
viously drawn latent variable values u.i/
k 1:
m .i/
k
D Ak 1.u.i/
k 1/ m.i/
k 1;
P  .i/
k
D Ak 1.u.i/
k 1/ P .i/
k 1 AT
k 1.u.i/
k 1/ C Qk 1.u.i/
k 1/:
(11.55)
2. Draw new latent variables u.i/
k for each particle in i D 1; : : : ; N from
the corresponding importance distributions:
u.i/
k  .uk j u.i/
0Wk 1; y1Wk/:
(11.56)
3. Calculate new weights as follows:
w.i/
k
/ w.i/
k 1
p.yk j u.i/
0Wk; y1Wk 1/ p.u.i/
k j u.i/
k 1/
.u.i/
k j u.i/
0Wk 1; y1Wk/
;
(11.57)
where the likelihood term is the marginal measurement likelihood of the
Kalman ﬁlter
p.yk j u.i/
0Wk; y1Wk 1/
D N

yk
ˇˇˇ Hk.u.i/
k / m .i/
k
; Hk.u.i/
k / P  .i/
k
HT
k.u.i/
k / C Rk.u.i/
k /

(11.58)
such that the model parameters in the Kalman ﬁlter are conditioned on
the drawn latent variable value u.i/
k . Then normalize the weights to sum
to unity.
4. Perform Kalman ﬁlter updates for each of the particles conditional on
the drawn latent variables u.i/
k :
v .i/
k
D yk   Hk.u.i/
k / m .i/
k
;
S.i/
k D Hk.u.i/
k / P  .i/
k
HT
k.u.i/
k / C Rk.u.i/
k /;
K.i/
k D P  .i/
k
HT
k.u.i/
k /
h
S.i/
k
i 1
;
m.i/
k D m .i/
k
C K.i/
k v.i/
k ;
P .i/
k
D P  .i/
k
  K.i/
k S.i/
k ŒK.i/
k T:
(11.59)
5. If the effective number of particles (11.31) is too low, perform resam-
pling.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
250
Particle Filtering
The Rao–Blackwellized particle ﬁlter produces for each time step k a
set of weighted samples fw.i/
k ; u.i/
k ; m.i/
k ; P .i/
k
W i D 1; : : : ; N g such that
the expectation of a function g./ can be approximated as
EŒg.xk; uk/ j y1Wk 
N
X
iD1
w.i/
k
Z
g.xk; u.i/
k / N.xk j m.i/
k ; P .i/
k / dxk:
(11.60)
Equivalently, the RBPF can be interpreted to form an approximation to the
ﬁltering distribution as
p.xk; uk j y1Wk/ 
N
X
iD1
w.i/
k ı.uk   u.i/
k / N.xk j m.i/
k ; P .i/
k /:
(11.61)
The optimal importance distribution, that is, the importance distribution
that minimizes the variance of the importance weights in the RBPF case, is
.uk j y1Wk; u.i/
0Wk 1/ D p.uk j y1Wk; u.i/
0Wk 1/
/ p.yk j uk; u.i/
0Wk 1/ p.uk j u.i/
0Wk 1; y1Wk 1/:
(11.62)
In general, normalizing this distribution or drawing samples from this dis-
tribution directly is not possible. But, if the latent variables uk are discrete,
we can normalize this distribution and use this optimal importance distri-
bution directly.
The class of models where Rao–Blackwellization of some linear state
components can be carried out can be extended beyond the conditionally
linear Gaussian models presented here. We can, for example, include ad-
ditional latent-variable-dependent non-linear terms into the dynamic and
measurement models (Sch¨on et al., 2005). In some cases, when the ﬁlter-
ing model is not strictly Gaussian due to slight non-linearities in either the
dynamic or measurement models, it is possible to replace the exact Kalman
ﬁlter update and prediction steps in RBPF with the extended Kalman ﬁlter
(EKF), the unscented Kalman ﬁlter (UKF) prediction and update steps, or
with any other Gaussian approximation-based ﬁlters (S¨arkk¨a et al., 2007b).
11.8 Exercises
11.1
Consider the following linear Gaussian state space model:
xk D
1
1
0
1

xk 1 C qk 1;
yk D
 1
0

xk C rk;
(11.63)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
251
where xk
D
.xk; Pxk/ is the state, yk is the measurement, and
qk
 N.0; diag.1=102; 12// and rk
 N.0; 102/ are white Gaussian
noise processes.
(a) Write down the Kalman ﬁlter equations for this model.
(b) Derive an expression for the optimal importance distribution for the
model:
.xk/ D p.xk j xk 1; y1Wk/:
(11.64)
(c) Write pseudo-code for the corresponding particle ﬁlter algorithm (se-
quential importance resampling algorithm). Also write down the equa-
tions for the weight update.
(d) Compare the number of CPU steps (multiplications and additions)
needed by the particle ﬁlter and Kalman ﬁlter. Which implementation
would you choose for a real implementation?
11.2
Consider the following partially observed random-walk model:
p.xk j xk 1/ D N.xk j xk 1; 1/;
p.yk j xk/ D LogNormal.yk j log jxkj   1=2; 1/;
(11.65)
where LogNormal.a; b/ has the density
LogNormal.x j a; b/ / exp

 .log.x/   a/2
2b2

:
(11.66)
Hint: LogNormal.ln jxkj   1=2; 1/ is deﬁned such that EŒyk j xk D jxkj.
Generate synthetic data from this model and apply
(a) one of the Gaussian approximation-based ﬁlters
(b) a bootstrap particle ﬁlter using 1,000 particles.
Compare the posterior distributions given by the two methods above: for the
Gaussian ﬁlter, plot the mean and uncertainty (0.95 standard deviation), and
for the bootstrap ﬁlter, show a scatter plot of the ﬁltering distribution at each
time step.
11.3
Implement the bootstrap ﬁlter for the model in Exercise 7.1, and test its
performance against the non-linear Kalman ﬁlters.
11.4
Implement the auxiliary particle ﬁlter for the model in Exercise 7.1, and test
its performance against the bootstrap ﬁlter.
11.5
Implement a sequential importance resampling ﬁlter with an EKF-, UKF-,
GHKF-, or CKF-based importance distribution for the model in Exercise 7.1.
Note that you might want to use a small non-zero covariance as the prior of
the previous step instead of plain zero to get the ﬁlters to work better.
11.6
Implement the bootstrap ﬁlter for the bearings-only target tracking model in
Exercise 7.2. Plot the results, and compare the RMSE values to those of the
non-linear Kalman ﬁlters.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
252
Particle Filtering
11.7
Implement the bootstrap ﬁlter for the Cartesian coordinated turn model in
Equations (4.61) and (4.90) with the linear position measurement model.
Also compare its performance with the EKF and UKF.
11.8
Implement the bootstrap ﬁlter for the bicycle model considered in Exer-
cise 9.11, and compare its performance with a non-linear Kalman ﬁlter.
11.9
Implement a Rao–Blackwellized particle ﬁlter for the following clutter
model (outlier model) :
xk D xk 1 C qk 1;
yk D
(
xk C rk;
if uk D 0;
rc
k;
if uk D 1;
(11.67)
where qk 1  N.0; 1/, rk  N.0; 1/, and rc
k  N.0; 102/. The indicator
variables uk are modeled as independent random variables that take the
value uk D 0 with prior probability 0:9 and the value uk D 1 with prior
probability 0:1. Test the performance of the ﬁlter with simulated data, and
compare the performance to a Kalman ﬁlter, where the clutter rc
k is ignored.
What is the optimal importance distribution for this model?

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12
Bayesian Smoothing Equations and Exact
Solutions
So far in this book we have only considered ﬁltering algorithms that use
the measurements obtained before and at the current step for computing
the best possible estimate of the current state (and possibly future states).
However, sometimes it is also of interest to estimate states for each time
step conditional on all the measurements that we have obtained. This prob-
lem can be solved with Bayesian smoothing. In this chapter, we present
the Bayesian theory of smoothing. After that we derive the Rauch–Tung–
Striebel (RTS) smoother, which is the closed form smoothing solution to
linear Gaussian models, as well as its afﬁne extension. We also specialize
the equations to discrete state spaces and present the Viterbi algorithm for
computing maximum a posteriori (MAP) state trajectories.
12.1 Bayesian Smoothing Equations
The purpose of Bayesian smoothing1 is to compute the marginal posterior
distribution of the state xk at the time step k after receiving the measure-
ments up to a time step T , where T > k:
p.xk j y1WT /:
(12.1)
The difference between ﬁlters and smoothers is that the Bayesian ﬁlter
computes its estimates using only the measurements obtained before and
at the time step k, but the Bayesian smoother also uses the future measure-
ments for computing its estimates. After obtaining the ﬁltering posterior
state distributions, the following theorem gives the equations for comput-
ing the marginal posterior distributions for each time step conditionally on
all the measurements up to the time step T .
1 This deﬁnition actually applies to the ﬁxed-interval type of smoothing.
253

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
254
Bayesian Smoothing Equations and Exact Solutions
Theorem 12.1 (Bayesian smoothing equations). The backward recursive
equations (the Bayesian smoother) for computing the smoothed distribu-
tions p.xk j y1WT / for any k < T are given by the following Bayesian
(ﬁxed-interval) smoothing equations (Kitagawa, 1987):
p.xkC1 j y1Wk/ D
Z
p.xkC1 j xk/ p.xk j y1Wk/ dxk;
p.xk j y1WT / D p.xk j y1Wk/
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/

dxkC1;
(12.2)
where p.xk j y1Wk/ is the ﬁltering distribution of the time step k. Note that
the term p.xkC1 j y1Wk/ is simply the predicted distribution of time step
k C 1. The integrations are replaced by summations if some of the state
components are discrete. For more details on this, see Section 12.4.
Proof
Due to the Markov properties, the state xk is independent of ykC1WT
given xkC1, which gives p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/. By
using Bayes’ rule, the distribution of xk given xkC1 and y1WT can be ex-
pressed as
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D p.xk; xkC1 j y1Wk/
p.xkC1 j y1Wk/
D p.xkC1 j xk; y1Wk/ p.xk j y1Wk/
p.xkC1 j y1Wk/
D p.xkC1 j xk/ p.xk j y1Wk/
p.xkC1 j y1Wk/
:
(12.3)
The joint distribution of xk and xkC1 given y1WT can be now computed as
p.xk; xkC1 j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D p.xk j xkC1; y1Wk/ p.xkC1 j y1WT /
D p.xkC1 j xk/ p.xk j y1Wk/ p.xkC1 jy1WT /
p.xkC1 j y1Wk/
;
(12.4)
where p.xkC1 j y1WT / is the smoothed distribution of the time step k C
1. The marginal distribution of xk given y1WT is given by integration (or
summation) over xkC1 in Equation (12.4), which gives the desired result.
A more precise name for the above smoother could be Bayesian
forward-backward smoother, because it assumes that we ﬁrst run a ﬁlter

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.2 Rauch–Tung–Striebel Smoother
255
to compute p.xk
j y1Wk/ and then use Equations (12.2) to compute
the smoothing density p.xk j y1WT / from p.xkC1 j y1WT /. That is, we
ﬁrst run a ﬁlter forward in time, recursively computing p.xk j y1Wk/
from p.xk 1 j y1Wk 1/, and we then run a smoother backward in time,
recursively computing p.xk j y1WT / from p.xkC1 j y1WT /.
An alternative approach to the above forward-backward approach
is the two-ﬁlter smoother (Fraser and Potter, 1969; Kitagawa, 1994).
That approach is based on the factorization p.xk j y1WT / / p.xk j
y1Wk 1/ p.ykWT
j xk/, where the ﬁrst factor is given by the prediction
step in the Bayesian ﬁlter, and the second one can be obtained with a
backward recursion. The backward recursion for the latter term resembles
a ﬁlter that runs backward, hence the term two-ﬁlter smoother. Two-ﬁlter
smoothing is particularly useful in linear Gaussian and discrete-state
models, and the so-called belief propagation algorithm for state space
models (see, e.g., Koller and Friedman, 2009) can be seen as an instance of
two-ﬁlter smoothing. However, because two-ﬁlter smoothing is less useful
in constructing approximate smoothers for non-linear models, in this book
we focus on the forward-backward type of smoothing formulations.
12.2 Rauch–Tung–Striebel Smoother
The Rauch–Tung–Striebel smoother (RTSS, Rauch et al., 1965), which is
also called the Kalman smoother, can be used for computing the closed
form smoothing solution
p.xk j y1WT / D N.xk j ms
k; P s
k/
(12.5)
to the linear ﬁltering model (6.17). The difference to the solution computed
by the Kalman ﬁlter is that the smoothed solution is conditional on the
whole measurement data y1WT , while the ﬁltering solution is conditional
only on the measurements obtained before and at the time step k, that is,
on the measurements y1Wk.
Theorem 12.2 (RTS smoother). The backward recursion equations for the
(ﬁxed interval) Rauch–Tung–Striebel smoother are given as
m kC1 D Ak mk;
P  kC1 D Ak Pk AT
k C Qk;
Gk D Pk AT
k ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k;
(12.6)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
256
Bayesian Smoothing Equations and Exact Solutions
where mk and Pk are the mean and covariance computed by the Kalman
ﬁlter. Note that the ﬁrst two of the equations are simply the Kalman ﬁlter
prediction equations.
The above procedure is a recursion that can be used for computing the
smoothing distribution of time step k from the smoothing distribution of
time step k C 1. Because the smoothing distribution and ﬁltering distribu-
tion of the last time step T are the same, we have ms
T D mT , P s
T D PT ,
and thus the recursion can be used for computing the smoothing distribu-
tions of all time steps by starting from the last step k D T and proceeding
backward to the initial step k D 0.
Proof
Similarly to the Kalman ﬁlter case, by Lemma A.2, the joint distri-
bution of xk and xkC1 given y1Wk is
p.xk; xkC1 j y1Wk/ D p.xkC1 j xk/ p.xk j y1Wk/
D N.xkC1 j Ak xk; Qk/ N.xk j mk; Pk/
D N
 xk
xkC1
 ˇˇˇ Qm1; QP1

;
(12.7)
where
Qm1 D
 mk
Ak mk

;
QP1 D
 Pk
Pk AT
k
Ak Pk
Ak Pk AT
k C Qk

:
(12.8)
Due to the Markov property of the states, we have
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/;
(12.9)
and thus by Lemma A.3 we get the conditional distribution
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D N.xk j Qm2; QP2/;
(12.10)
where
Gk D Pk AT
k .Ak Pk AT
k C Qk/ 1
Qm2 D mk C Gk .xkC1   Ak mk/
QP2 D Pk   Gk .Ak Pk AT
k C Qk/ GT
k:
(12.11)
The joint distribution of xk and xkC1 given all the data is
p.xkC1; xk j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D N.xk j Qm2; QP2/ N.xkC1 j ms
kC1; P s
kC1/
D N
xkC1
xk
 ˇˇˇ Qm3; QP3

;
(12.12)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.2 Rauch–Tung–Striebel Smoother
257
0
20
40
60
80
100
Time step k
-10
-8
-6
-4
-2
0
2
4
6
 xk
Filter estimate
Smoother estimate
Filter's 95% quantiles
Smoother's 95% quantiles
Figure 12.1 Filter and smoother estimates in the Gaussian
random walk smoothing example (Example 12.3).
where
Qm3 D

ms
kC1
mk C Gk .ms
kC1   Ak mk/

;
QP3 D
 P s
kC1
P s
kC1 GT
k
Gk P s
kC1
Gk P s
kC1 GT
k C QP2

:
(12.13)
Thus by Lemma A.3, the marginal distribution of xk is given as
p.xk j y1WT / D N.xk j ms
k; P s
k/;
(12.14)
where
ms
k D mk C Gk .ms
kC1   Ak mk/;
P s
k D Pk C Gk .P s
kC1   Ak Pk AT
k   Qk/ GT
k:
(12.15)
The RTS smoother described in Theorem (12.2) assumes that we ﬁrst
run a Kalman ﬁlter, and store mk and Pk for k D 1; 2; : : : ; T , before
performing smoothing. However, the Kalman ﬁlter actually also computes
m k and P  k , which are also computed in Equations (12.6). An alternative
version of the RTS smoother is therefore to store the values of m k and P  k
computed by the Kalman ﬁlter, and to only compute Gk, ms
k, and P s
k in
Equations (12.6) during smoothing.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
258
Bayesian Smoothing Equations and Exact Solutions
0
20
40
60
80
100
Time step k
0.4
0.5
0.6
0.7
0.8
0.9
1
Variance
Filter variance
Smoother variance
Figure 12.2 Filter and smoother variances in the Gaussian
random walk smoothing example (Example 12.3). The variance
of the smoother is always smaller than that of the ﬁlter. The only
exception is at the ﬁnal step, where the variances are the same.
Example 12.3 (RTS smoother for Gaussian random walk). The RTS
smoother for the random walk model given in Example 6.4 is given by the
equations
m kC1 D mk;
P  kC1 D Pk C Q;
ms
k D mk C
Pk
P  kC1
.ms
kC1   m kC1/;
P s
k D Pk C
 
Pk
P  kC1
!2
ŒP s
kC1   P  kC1;
(12.16)
where mk and Pk are the updated mean and covariance from the Kalman
ﬁlter in Example 6.7. The result of applying the smoother to simulated data
is shown in Figure 12.1. The evolution of the ﬁlter and smoother variances
is illustrated in Figure 12.2.
Example 12.4 (RTS smoother for car tracking). The backward recursion
equations required for implementing the RTS smoother for the car tracking

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.3 Afﬁne Rauch–Tung–Striebel Smoother
259
problem in Example 6.8 are the following:
m kC1 D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA mk;
P  kC1 D
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA Pk
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
C
0
BBBB@
qc
1 t3
3
0
qc
1 t2
2
0
0
qc
2 t3
3
0
qc
2 t2
2
qc
1 t2
2
0
qc
1 t
0
0
qc
2 t2
2
0
qc
2 t
1
CCCCA
;
Gk D Pk
0
BB@
1
0
t
0
0
1
0
t
0
0
1
0
0
0
0
1
1
CCA
T
ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k:
The terms mk and Pk are the Kalman ﬁlter means and covariances com-
puted with the equations given in Example 6.8. It would also be possible to
store the values m kC1 and P  kC1 during Kalman ﬁltering to avoid recom-
putation of them in the ﬁrst two equations above. The gains Gk could be
computed already during the Kalman ﬁltering as well. The result of apply-
ing the RTS smoother to simulated data is shown in Figure 12.3.
12.3 Afﬁne Rauch–Tung–Striebel Smoother
As in the case of ﬁltering, the smoothing equations also have closed form
expressions for afﬁne models of the form in Equation (6.34). The afﬁne
Kalman ﬁltering equations for afﬁne models are given in Theorem 6.9. The
RTS smoother for afﬁne models is almost identical to the RTS smoother for
linear models but is included here for completeness as it is useful later in
constructing non-linear smoothers. Note that the measurement model does

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
260
Bayesian Smoothing Equations and Exact Solutions
-5
0
5
10
 x1
-12
-10
-8
-6
-4
-2
0
2
 x2
True trajectory
Measurements
Smoother estimate
Figure 12.3 Simulated trajectory, measurements, and result of
RTS smoother-based car tracking in Example 6.8. The starting
point is at the top of the trajectory. The RMSE position error
based on the measurements only is 0:77, the position RMSE of
the Kalman ﬁlter estimate is 0:43, and the error of the RTS
smoother is 0:27. It can be seen that the estimate is much
“smoother” than the result of the Kalman ﬁlter in Figure 6.5.
not inﬂuence the RTS smoother, and therefore the only difference com-
pared to Theorem 12.2 is that the constant ak leads to a slight modiﬁcation
to the expression for m kC1.
Theorem 12.5 (Afﬁne RTS smoother). The backward recursion equations
for the afﬁne (ﬁxed interval) Rauch–Tung–Striebel smoother are given as
m kC1 D Ak mk C ak;
P  kC1 D Ak Pk AT
k C Qk;
Gk D Pk AT
k ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k;
(12.17)
where mk and Pk are the mean and covariance computed by the afﬁne
Kalman ﬁlter. The recursion is started from the last time step T , with ms
T D
mT and P s
T D PT . Note that the ﬁrst two of the equations are simply the
Kalman ﬁlter prediction equations for afﬁne models.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.4 Bayesian Smoother for Discrete State Spaces
261
12.4 Bayesian Smoother for Discrete State Spaces
In Section 6.5 we saw how Bayesian ﬁltering equations can be specialized
to the case where the states take values in a discrete space, xk 2 X. Simi-
larly to the Bayesian ﬁlter, the Bayesian smoother can also be formulated
for this kind of model. The result is the following.
Corollary 12.6 (Discrete Bayesian smoothing equations). For a discrete
state-space xk 2 X, the equations for computing the smoothed distribu-
tions p.xk j y1WT / are given as follows:
p.xkC1 j y1Wk/ D
X
xk2X
p.xkC1 j xk/ p.xk j y1Wk/;
p.xk j y1WT / D p.xk j y1Wk/
X
xkC12X
p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/

;
(12.18)
where p.xk j y1Wk/ is the ﬁltering distribution at time step k.
As in the case of ﬁltering, for models with ﬁnite numbers of possible
states and measurements, it is convenient to deﬁne state transition and
emission matrices … and O, respectively, via Equations (6.41). If we fur-
ther denote the ﬁltering and prediction distributions as in Equations (6.42)
and denote
ps
j;k D p.xk D j j y1WT /;
(12.19)
then the smoothing equations can be written as follows.
Corollary 12.7 (Bayesian smoother for discrete HMMs). The Bayesian
smoothing equations for hidden Markov models (HMMs) with ﬁnite state
and measurement spaces can be written as
p j;kC1 D
X
i
…i;j pi;k;
ps
j;k D pi;k
X
j
…i;j
ps
j;kC1
p j;kC1
:
(12.20)
Example 12.8 (Gilbert–Elliot channel smoother). Figure 12.4 shows the
result of applying the Bayesian smoother in Corollary 12.7 to the Gilbert–
Elliot model that we already considered in Examples 5.14 and 6.12.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
262
Bayesian Smoothing Equations and Exact Solutions
20
40
60
80
100
Time step k
1
2
3
4
State xk
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
True states
Smoother estimates
Figure 12.4 Smoothing result for the Gilbert–Elliot channel
model (Example 12.8). The probabilities of the states are denoted
by shades of gray, and the smoother estimates are the most
probable states computed from the smoothing marginals. The
error rate of the smoother when the most probable state is guessed
is 8% while the error rate of the ﬁlter reported in Example 6.12
was 11%.
12.5 Viterbi Algorithm
The Viterbi algorithm (Larson and Peschon, 1966; Viterbi, 1967; Capp´e
et al., 2005) is an algorithm that can be used to compute the maximum
a posterior (MAP) estimates of state trajectories. The algorithm can be
applied to models with discrete or continuous state or measurement spaces,
but the most common practical use is when both of them are discrete.
The aim of the Viterbi algorithm is to ﬁnd the MAP estimate, which
corresponds to maximization of
p.x0WT j y1WT / D p.y1WT ; x0WT /
p.y1WT /
/ p.y0WT ; x1WT /;
(12.21)
which is equivalent to maximizing
p.y1WT ; x0WT / D p.x0/
TY
iD1
Œp.yi j xi/ p.xi j xi 1/;
(12.22)
that is,
x
0WT D arg max
x0WT p.y1WT ; x0WT /:
(12.23)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.5 Viterbi Algorithm
263
It is worth noting that the computation of the MAP estimate of the state tra-
jectory is different from the problem of estimating the smoothing marginals
p.xk j y1WT /, and the maxima of these marginals are not necessarily the
same as the intermediate states along the MAP trajectory. For discrete state-
spaces, it is therefore relevant to develop both Bayesian smoothers, as pre-
sented in Section 12.4, and the MAP estimators presented here, whereas
one algorithm is sufﬁcient for linear Gaussian models since the solutions
to both objectives always coincide for such models.
Theorem 12.9 (Viterbi algorithm for computing the MAP path). The fol-
lowing procedure can be used to compute a MAP path x
0WT . On the for-
ward pass we start from V0.x0/ D p.x0/ and compute the following for
k D 1; : : : ; T :
Vk.xk/ D max
xk 1Œp.yk j xk/ p.xk j xk 1/ Vk 1.xk 1/:
(12.24)
In the backward pass we ﬁrst take
x
T D arg max
xT VT .xT /
(12.25)
and then compute
x
k D arg max
xk Œp.x
kC1 j xk/ Vk.xk/
(12.26)
for k D T   1; : : : ; 0, where arg maxŒ can return any of the maximizing
states if there are more than one of them.
Proof
By deﬁnition, we have V0.x0/ D p.x0/. We ﬁrst show that
Vk.xk/ D max
x0Wk 1 p.x0/
k
Y
iD1
Œp.yi j xi/ p.xi j xi 1/;
(12.27)
using an inductive proof. We note that this holds trivially for k D 0 and we
can use this as our base case. Furthermore, to complete the inductive proof,
let us assume that the relation holds for k   1 and prove that it then must
hold for k. To this end, we note that
Vk.xk/ D max
xk 1

p.yk j xk/ p.xk j xk 1/
 max
x0Wk 2 p.x0/
k 1
Y
iD1
Œp.yi j xi/ p.xi j xi 1/

D max
xk 1Œp.yk j xk/ p.xk j xk 1/ Vk 1.xk 1/;
(12.28)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
264
Bayesian Smoothing Equations and Exact Solutions
which proves that Vk.xk/ satisﬁes Equation (12.24).
To complete the proof, we will now use a second inductive proof to
show that the backward pass gives the MAP sequence x
0WT . In this case,
we ﬁrst note that the relation x
T D arg max VT .xT / follows from Equa-
tion (12.27), and we can use this as our base case. Finally, we assume that
we know the tail of a MAP path x
kC1WT and show that Equation (12.26)
must give the MAP estimate at time step k for k D T   1; : : : ; 0.
When x
kC1WT is given, the MAP estimation problem simpliﬁes to ﬁnding
x
0Wk D arg max
x0Wk p.y1WT ; x0Wk; x
kC1WT /
D arg max
x0Wk p.x
kC1 j xk/p.x0/
k
Y
iD1
Œp.yi j xi/ p.xi j xi 1/:
(12.29)
We can hence express the MAP estimate at time k as
x
k D arg max
xk p.x
kC1 j xk/ max
x0Wk 1 p.x0/
k
Y
iD1
Œp.yi j xi/ p.xi j xi 1/;
D arg max
xk p.x
kC1 j xk/ Vk.xk/;
(12.30)
which proves that Equation (12.26) yields the MAP sequence x
0WT , by
induction.
The Viterbi algorithm has interesting connections to several other algo-
rithms. For instance, the forward pass resembles an operation that jointly
performs prediction and update, but in contrast to our ﬁltering distributions,
Vk.xk/ is not normalized, and xk 1 is not marginalized by summation (as
in the Chapman–Kolmogorov equation) but instead selects the value of
xk 1 that maximizes Vk.xk/, for each value of xk.
The Viterbi algorithm also has a close connection with the so-called
max-product algorithm, which is often used in the context of Bayesian
graphical models (Koller and Friedman, 2009). The max-product algorithm
can roughly be seen as a two-ﬁlter formulation of the Viterbi algorithm
using an analogy with forward-backward versus two-ﬁlter smoothing.
As with discrete-state ﬁlters and smoothers, the Viterbi algorithm can
also be specialized to the case where the state and measurement spaces
are ﬁnite, in which case the model is deﬁned by the state transition and

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
12.5 Viterbi Algorithm
265
0
20
40
60
80
100
Time step k
1
2
3
4
State xk
True states
Viterbi estimates
Figure 12.5 Result of applying the Viterbi algorithm to the
Gilbert–Elliot channel model (Example 12.11). The error rate of
the algorithm was 8% while the ﬁlter rate in Example 6.12 was
11%.
emission matrices … and O given by Equations (6.41). We can then also
denote
Vi;k D Vk.xk D i/:
(12.31)
With this notation, the Viterbi algorithm becomes the following.
Corollary 12.10 (Viterbi algorithm for discrete HMMs). On the for-
ward pass we start from Vi;0 D pi;0 and compute the following for
k D 1; : : : ; T :
Vi;k D max
j

Oi;yk …j;i Vj;k 1

:
(12.32)
On the backward pass we ﬁrst put x
T D arg maxi Vi;T and then proceed as
x
k D arg max
j
h
…j;x
kC1 Vj;k
i
:
(12.33)
Example 12.11 (Viterbi algorithm for Gilbert–Elliot channel). The result
of applying the Viterbi algorithm in Corollary 12.10 to the Gilbert–Elliot
model introduced in Example 5.14 is shown in Figure 12.5.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
266
Bayesian Smoothing Equations and Exact Solutions
12.6 Exercises
12.1
Derive the linear RTS smoother for the non-zero-mean noise model in Exer-
cise 6.1.
12.2
Implement the Gaussian random walk model smoother in Example 12.3,
and compare its performance to the corresponding Kalman ﬁlter. Plot the
evolution of the smoothing distribution.
12.3
The Gaussian random walk model considered in Example 6.4 also deﬁnes
a joint Gaussian prior distribution p.x0; : : : ; xT /. The measurement model
p.y1; : : : ; yT j x0; : : : ; xT / is Gaussian as well. Construct these distribu-
tions, and compute the posterior distribution p.x0; : : : ; xT j y1; : : : ; yT /.
Check numerically that the mean and the diagonal covariance entries of this
distribution exactly match the smoother means and variances.
12.4
Implement the RTS smoother for the resonator model in Exercise 6.4. Com-
pare its RMSE performance to the ﬁltering and baseline solutions, and plot
the results.
12.5
Implement an HMM smoother to the model considered in Exercise 6.5, and
compute the error rate of the smoother when the highest probability state in
the smoothing distribution is used as the estimate. Also compare the perfor-
mance with the HMM ﬁlter.
12.6
Implement Viterbi algorithm to the model in Exercise 6.5, and compare its
performance with the ﬁlter and the smoother in Exercise 12.5.
12.7
Form a grid-based approximation to the Gaussian random walk model
smoother in the same way as was done for the ﬁltering equations in
Exercise 6.6. Verify that the result is practically the same as in the RTS
smoother above.
12.8
Implement Viterbi algorithm for the problem in Exercise 12.7.
12.9
Show that in the linear Gaussian case, the Viterbi algorithm in Theorem 12.9
reduces to the RTS smoother.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13
Extended Rauch–Tung–Striebel Smoothing
In this chapter, we present Taylor series-based extended Rauch–Tung–
Striebel (i.e., Kalman) smoothers along with their iterated versions. These
smoothers use similar approximations as the extended Kalman ﬁlters that
we encountered in Chapter 7. The iterated extended Rauch–Tung–Striebel
smoother also turns out to be an instance of the Gauss–Newton method,
but in contrast to the iterated extended Kalman ﬁlter, it computes the
maximum a posteriori (MAP) estimate of the whole trajectory instead of
just a single state.
13.1 Extended Rauch–Tung–Striebel Smoother
The ﬁrst order (i.e., linearized) extended Rauch–Tung–Striebel smoother
(ERTSS) (Cox, 1964; Sage and Melsa, 1971) can be obtained from the
basic RTS smoother equations by replacing the prediction equations with
ﬁrst order approximations. Various kinds of higher order extended Kalman
smoothers are also possible (see, e.g., Cox, 1964; Sage and Melsa, 1971),
and we present a second order smoother in Section 13.2. The ERTSS forms
(or assumes) a Gaussian approximation to the smoothing distribution as
follows:
p.xk j y1WT / ' N.xk j ms
k; P s
k/:
(13.1)
For the additive model in Equation (7.24), the extended Rauch–Tung–
Striebel smoother algorithm is the following.
267

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
268
Extended Rauch–Tung–Striebel Smoothing
Algorithm 13.1 (Extended RTS smoother). The equations for the extended
RTS smoother are
m kC1 D f.mk/;
P  kC1 D Fx.mk/ Pk F T
x.mk/ C Qk;
Gk D Pk FT
x.mk/ ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k;
(13.2)
where the matrix Fx.mk/ is the Jacobian matrix of f.x/ evaluated at mk.
The recursion is started from the last time step T , with ms
T D mT and
P s
T D PT .
Derivation
Assume that the ﬁltering distributions for the model (7.24)
are approximately Gaussian:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
and we have already computed the means and covariance using the ex-
tended Kalman ﬁlter or a similar method. Further assume that the smooth-
ing distribution of time step k C 1 is known and approximately Gaussian
p.xkC1 j y1WT / ' N.xkC1 j ms
kC1; P s
kC1/:
As in the derivation of the prediction step of the EKF in Section 7.2, the
approximate joint distribution of xk and xkC1 given y1Wk is
p.xk; xkC1 j y1Wk/ D N
 xk
xkC1
 ˇˇˇ Qm1; QP1

;
(13.3)
where
Qm1 D
 mk
f.mk/

;
QP1 D
 Pk
Pk FT
x
Fx Pk
Fx Pk FT
x C Qk

;
(13.4)
and the Jacobian matrix Fx of f.x/ is evaluated at x D mk. By condition-
ing on xkC1 as in the RTS derivation in Section 12.2, we get
p.xk j xkC1; y1WT / D p.xk j xkC1; y1Wk/
D N.xk j Qm2; QP2/;
(13.5)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13.1 Extended Rauch–Tung–Striebel Smoother
269
where
Gk D Pk F T
x .Fx Pk F T
x C Qk/ 1;
Qm2 D mk C Gk .xkC1   f.mk//;
QP2 D Pk   Gk .Fx Pk FT
x C Qk/ GT
k:
(13.6)
The joint distribution of xk and xkC1 given all the data is now
p.xkC1; xk j y1WT / D p.xk j xkC1; y1WT / p.xkC1 j y1WT /
D N
xkC1
xk
 ˇˇˇ Qm3; QP3

;
(13.7)
where
Qm3 D

ms
kC1
mk C Gk .ms
kC1   f.mk//

;
QP3 D
 P s
kC1
P s
kC1 GT
k
Gk P s
kC1
Gk P s
kC1 GT
k C QP2

:
(13.8)
The marginal distribution of xk is then
p.xk j y1WT / D N.xk j ms
k; P s
k/;
(13.9)
where
ms
k D mk C Gk .ms
kC1   f.mk//;
P s
k D Pk C Gk .P s
kC1   Fx Pk F T
x   Qk/ GT
k:
(13.10)
The generalization to the non-additive model (7.39) is analogous to the
ﬁltering case – we just need to replace the ﬁrst two of Equations (13.2)
with their non-additive versions as in Algorithm 7.5.
Example 13.2 (Pendulum tracking with ERTSS). The result of applying
the ERTSS to the pendulum model in Example 7.6 is shown in Figure 13.1.
The resulting RMSE was 0:06, which is much lower than the error of the
EKF, which was 0:17. It is also lower than the errors of any other ﬁlters,
which were in the range 0:10–0:17.
Example 13.3 (Coordinated turn model with ERTSS). Figure 13.2 shows
the result of ERTSS in the coordinated turn model problem considered in
Example 7.7. The resulting error was 0:016 (as opposed to 0:31 for EKF).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
270
Extended Rauch–Tung–Striebel Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
ERTSS estimate
Figure 13.1 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the ERTSS (see
Example 13.2). The resulting RMSE is 0:06 (recall that the
RMSE of the EKF was 0:17).
13.2 Higher Order Extended Rauch–Tung–Striebel Smoothers
We can also form a second order ERTSS by replacing the prediction equa-
tions in the ERTSS with their second order versions appearing in Algo-
rithm 7.8, which results in the following.
Algorithm 13.4 (Second order extended RTS smoother). The equations
for the second order extended RTS smoother are
m kC1 D f.mk/ C 1
2
X
i
ei tr
n
F .i/
xx.mk/ Pk
o
;
P  kC1 D Fx.mk/ Pk FT
x.mk/
C 1
2
X
i;i0
ei eT
i0 tr
n
F .i/
xx.mk/PkF .i0/
xx .mk/Pk
o
C Qk;
Gk D Pk F T
x.mk/ ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k;
(13.11)
where Fx.mk/ is the Jacobian matrix of f.x/ evaluated at mk, and
F .i/
xx.mk/ is its Hessian as deﬁned in Equation (7.54).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13.3 Iterated Extended Rauch–Tung–Striebel Smoother
271
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
ERTSS estimate
Sensors
Figure 13.2 The result of applying ERTSS to simulated data
from the (polar) coordinated turn model in Example 7.7. The
resulting error was 0:016, whereas for the EKF it was 0:31.
13.3 Iterated Extended Rauch–Tung–Striebel Smoother
Similarly to the IEKF presented in Section 7.4, it is also possible to formu-
late an iterated extended Rauch–Tung–Striebel smoother (IERTSS), which
is often called the iterated extended Kalman smoother (IEKS) or just iter-
ated Kalman smoother (IKS, Bell, 1994), as a Gauss–Newton method that
aims to compute the maximum-a-posteriori (MAP) estimate of the whole
trajectory x0WT given the measurements. The intuitive idea is that once we
have computed an ERTSS estimate of the trajectory, we can relinearize the
model at all the time steps simultaneously along this smoother estimate
(conditioned on all the data) and run the smoother again. Iterating this will
result in the IERTSS algorithm. Please note that in the IEKF we only re-
linearized the measurement model at the previous estimate produced by
the EKF, but in the IERTSS we relinearize both dynamic and measurement
models at all time steps before doing the next iteration. Let us now derive
this procedure from the Gauss–Newton point of view.
In order to do that, ﬁrst recall that the joint posterior distribution of the
trajectory can be written as
p.x0WT j y1WT / / p.x0/
Y
k
p.yk j xk/ p.xk j xk 1/;
(13.12)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
272
Extended Rauch–Tung–Striebel Smoothing
and the MAP estimate of the trajectory can be thus computed by
xMAP
0WT D arg max
x0WT p.x0WT j y1WT /
D arg max
x0WT p.x0/
Y
k
p.yk j xk/ p.xk j xk 1/:
(13.13)
Similarly to Section 7.4, it is convenient to work with the negative loga-
rithm
L.x0WT / D   log
"
p.x0/
Y
k
p.yk j xk/ p.xk j xk 1/
#
D   log p.x0/  X
k
log p.yk j xk/  X
k
log p.xk j xk 1/;
(13.14)
in which case the MAP estimation problem becomes
xMAP
0WT D arg min
x0WT L.x0WT /:
(13.15)
When the dynamic and measurement models have the form
p.xk j xk 1/ D N.xk j f.xk 1/; Qk 1/;
p.yk j xk/ D N.yk j h.xk/; Rk/;
(13.16)
and the initial distribution is p.x0/ D N.x0 j m0; P0/, then the negative
logarithm is
L.x0WT / D C C 1
2.x0   m0/T P  1
0
.x0   m0/
C 1
2
X
k
.yk   h.xk//T R 1
k .yk   h.xk//
C 1
2
X
k
.xk   f.xk 1//T Q 1
k 1 .xk   f.xk 1//;
(13.17)
where C is a constant, independent of the states. The MAP estimate of the
trajectory can now be obtained as the minimum of the above cost function.
In Section 7.4, we constructed the IEKF by noticing that the cost func-
tion optimized by the IEKF in Equation (7.61) is a special case of cost
functions that the Gauss–Newton method can handle, which have the form
of Equation (7.63). We can now observe that the cost function in Equa-
tion (13.17) is also a special case of (7.63), and therefore we can use
Gauss–Newton to compute the MAP estimate of the whole trajectory by
iteratively minimizing (13.17).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13.3 Iterated Extended Rauch–Tung–Striebel Smoother
273
The Gauss–Newton iterations are started from some initial trajectory
x.0/
0WT . That can be computed, for example, by using a non-iterated ERTSS.
Let us then assume that we have already computed an estimate of the whole
trajectory x.i 1/
0WT
for iteration step i   1. We can now simultaneously lin-
earize all the dynamic and measurement model functions by using Taylor
series:
f.xk 1/ ' f.x.i 1/
k 1 / C Fx.x.i 1/
k 1 / .xk 1   x.i 1/
k 1 /
D Fx.x.i 1/
k 1 / xk 1 C f.x.i 1/
k 1 /   Fx.x.i 1/
k 1 / x.i 1/
k 1 ;
h.xk/ ' h.x.i 1/
k
/ C Hx.x.i 1/
k
/ .xk   x.i 1/
k
/
D Hx.x.i 1/
k
/ xk C h.x.i 1/
k
/   Hx.x.i 1/
k
/ x.i 1/
k
;
(13.18)
which is done for all k D 1; : : : ; T . Let us now temporarily denote
uk 1 D f.x.i 1/
k 1 /   Fx.x.i 1/
k 1 / x.i 1/
k 1 ;
Ak 1 D Fx.x.i 1/
k 1 /;
dk D h.x.i 1/
k
/   Hx.x.i 1/
k
/ x.i 1/
k
;
Hk D Hx.x.i 1/
k
/;
(13.19)
which then simpliﬁes the notation of the linearizations to
f.xk 1/ ' Ak 1 xk 1 C uk 1;
h.xk/ ' Hk xk C dk:
(13.20)
Substituting the above approximations to L.x0WT / in (13.17) then results in
L.x0WT / ' C C 1
2.x0   m0/T P  1
0
.x0   m0/
C 1
2
X
k
.yk   Hk xk   dk/T R 1
k .yk   Hk xk   dk/
C 1
2
X
k
.xk   Ak 1 xk 1   uk 1/T Q 1
k 1 .xk   Ak 1 xk 1   uk 1/;
(13.21)
which can be recognized to correspond to the afﬁne Gaussian model
p.xk j xk 1/ ' N.xk j Ak 1 xk 1 C uk 1; Qk 1/;
p.yk j xk/ ' N.yk j Hk xk C dk; Rk/:
(13.22)
For a Gaussian distribution, the mean matches the MAP estimate, and
hence we can compute the MAP estimate for this afﬁne Gaussian model
– which is the minimum of (13.21) – by running the afﬁne Kalman ﬁlter

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
274
Extended Rauch–Tung–Striebel Smoothing
in Theorem 6.9 and the afﬁne Rauch–Tung–Striebel smoother in Theo-
rem 12.5 for the above model. The smoother mean sequence ms
0WT then
gives the MAP estimate. The MAP estimate ms
0WT computed for the lin-
earized model can then be used as the next iterate x.i/
0WT D ms
0WT . This leads
to an iterative algorithm given in the following.
Algorithm 13.5 (Iterated extended RTS smoother). The iterated extended
RTS smoother is started from an initial guess for the trajectory x.0/
0WT , which
can be computed, for example, using the (non-iterated) extended Kalman
ﬁlter and smoother. For each i D 1; 2; : : : ; Imax we then do the following.
1. Run the following ﬁlter by starting from m.i/
0 D m0 and P .i/
0
D P0 and
by performing the following predictions and updates for k D 1; : : : ; T :
m .i/
k
D f.x.i 1/
k 1 / C Fx.x.i 1/
k 1 / .m.i/
k 1   x.i 1/
k 1 /;
P  .i/
k
D Fx.x.i 1/
k 1 / P .i/
k 1 F T
x.x.i 1/
k 1 / C Qk 1;
v .i/
k
D yk   h.x.i 1/
k
/   Hx.x.i 1/
k
/ .m .i/
k
  x.i 1/
k
/;
S.i/
k D Hx.x.i 1/
k
/ P  .i/
k
HT
x.x.i 1/
k
/ C Rk;
K.i/
k D P  .i/
k
HT
x.x.i 1/
k
/ ŒS.i/
k  1;
m.i/
k D m .i/
k
C K.i/
k v .i/
k ;
P .i/
k
D P  .i/
k
  K.i/
k S.i/
k ŒK.i/
k T:
(13.23)
2. Run the following smoother by starting from ms;.i/
T
D mT and P s;.i/
T
D
PT and performing the following smoothing steps for k D T  1; : : : ; 0:
m .i/
kC1 D f.x.i 1/
k
/ C Fx.x.i 1/
k
/ .m.i/
k   x.i 1/
k
/;
P  .i/
kC1 D Fx.x.i 1/
k
/ P .i/
k FT
x.x.i 1/
k
/ C Qk;
G.i/
k
D P .i/
k FT
x.x.i 1/
k
/ ŒP  .i/
kC1 1;
ms;.i/
k
D m.i/
k C G.i/
k Œms;.i/
kC1   m .i/
kC1;
P s;.i/
k
D P .i/
k
C G.i/
k ŒP s;.i/
kC1   P  .i/
kC1 ŒG.i/
k T:
(13.24)
3. Form the next iterate as x.i/
0WT D ms;.i/
0WT and go to step 1.
Above, Fx and Hx denote the Jacobians of f and h, respectively, deﬁned
as in Equations (7.28) and (7.29). After the iterations, the ﬁnal smoother
means and covariances can be approximated as
ms
0WT D ms;.Imax/
0WT
;
P s
0WT D P s;.Imax/
0WT
:
(13.25)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13.3 Iterated Extended Rauch–Tung–Striebel Smoother
275
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
IERTSS estimate
Figure 13.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the IERTSS (see
Example 13.6). The resulting RMSE is 0:03 (recall that the
RMSE of ERTSS was 0:06, and the RMSE of EKF was 0:17).
Because the IERTSS is an instance of the Gauss–Newton algorithm, it
can be shown to converge in well-deﬁned conditions (Bell, 1994), and the
convergence is to the MAP estimate of the trajectory. This is in contrast
to the IEKF (Algorithm 7.9), which only does local Gauss–Newton iter-
ation at the update step and hence does not converge to the global MAP
estimate. Furthermore, as mentioned in the IERTSS algorithm description,
one way to initialize the iterations is by using an ERTSS estimate from
Algorithm 13.1. However, the initialization only affects the convergence
speed of the method, and the point of convergence (if the algorithm con-
vergences) will be the MAP estimate regardless of the initial trajectory
guess.
Example 13.6 (Pendulum tracking with IERTSS). The result of applying
the IERTSS to the pendulum model in Example 7.6 is shown in Figure 13.3.
The resulting RMSE was 0:03, which is much lower than the error of the
EKF, which was 0:17. It is also lower than the errors of any other ﬁlters,
which were in the range 0:10–0:17 and lower than the ERTSS, which had
error of 0:06.
Example 13.7 (Coordinated turn model with IERTSS). Figure 13.4 shows
the result of the IERTSS on the coordinated turn model problem considered

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
276
Extended Rauch–Tung–Striebel Smoothing
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
IERTSS estimate
Sensors
Figure 13.4 The result of applying IERTSS to simulated data
from the (polar) coordinated turn model in Example 7.11 when
using an inaccurate initial guess (see Example 13.7). The
resulting RMSE was 0:015, while for the plain ERTSS it is 0:017.
in Example 7.11. The iteration reduces the error from 0:017 of the ERTSS
to 0:015. We also ran the IERTSS on the more accurate initial guess data
in Example 13.3, and the resulting error was the same 0:015.
13.4 Levenberg–Marquardt and Line-Search IERTSSs
Similarly to the IEKF case in Section 7.5 it is also possible to improve
the convergence of the Gauss–Newton method in IERTSS by replacing it
with the Levenberg–Marquardt method or by including a line-search pro-
cedure into it. These kinds of extensions have been presented in S¨arkk¨a and
Svensson (2020). Although we are not giving details here, the basic ideas
are:
 The Levenberg–Marquardt method can be implemented by modifying
the ﬁlter portion in the IERTSS iteration to have a (pseudo-) measure-
ment of the previous state iterate x.i 1/
k
at each time step k separately
with a suitably deﬁned covariance matrix.
 Line-search can be implemented by modifying the computation of the
new iterate x.i/
0WT into the following:
x.i/
0WT D x.i 1/
0WT
C  .ms;.i/
0WT   x.i 1/
0WT /;
(13.26)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
13.5 Exercises
277
where the step size  is chosen to minimize L.x.i 1/
0WT
C  .ms;.i/
0WT  x.i 1/
0WT // where L is as deﬁned in Equation (13.17). This minimization
does not necessarily need to be exact (S¨arkk¨a and Svensson, 2020).
13.5 Exercises
13.1
Derive and implement the extended RTS smoother to the model in Exer-
cise 7.1, and compare the errors of the ﬁlters and smoothers.
13.2
Derive and implement the second order extended RTS smoother to the model
in Exercise 7.1, and compare the errors of the ﬁlters and smoothers.
13.3
Implement the extended RTS smoother to the bearings-only target tracking
problem in Exercise 7.2. Note that even though the full model is non-linear,
due to the linear dynamic model the smoother is linear.
13.4
Implement extended RTS for the Cartesian coordinated turn model in Equa-
tions (4.61) and (4.90) with the linear position measurement model.
13.5
Show that single iteration of the iterated extended RTS smoother corre-
sponds to the non-iterated extended RTS smoother if the initial guess is the
EKF result.
13.6
Derive and implement the iterated extended RTS smoother to the model in
Exercise 7.1, and compare the errors of the ﬁlters and smoothers.
13.7
Implement the iterated extended RTS smoother to the bearings-only target
tracking problem in Exercise 7.2.
13.8
Implement the iterated extended RTS for the Cartesian coordinated turn
model in Equations (4.61) and (4.90) with the linear position measurement
model.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14
General Gaussian Smoothing
In Chapter 12 we encountered the general Bayesian smoothing equations
as well as the Rauch–Tung–Striebel (RTS) smoother for linear Gaussian
(and afﬁne) models. In Chapter 13 we then extended the RTS smoothers to
non-linear models by using Taylor series expansions. These extensions fol-
lowed the path from Kalman ﬁlters to extended Kalman ﬁlters, which we
saw in Chapters 6 and 7. In the ﬁltering case we then proceeded to Gaus-
sian ﬁlters (Chapter 8), enabling approximations (Chapter 9), and posterior
linearization (Chapter 10).
The principles used to develop Gaussian ﬁlters can also be used to ob-
tain Gaussian smoothers. The aim of this chapter is to directly proceed from
the Taylor series expansion-based smoothers in Chapter 13 to all general
Gaussian smoothers, including the enabling approximation and posterior
linearization smoothers. In particular, the moment matching approach used
in Chapter 8, the statistical linear regression described in Chapter 9, and the
posterior linearization presented in Chapter 10 can all be used to develop
Gaussian forward-backward smoothers by leveraging the RTS equations.
In this chapter, we introduce these Gaussian smoothers and explain how
they can be combined with sigma-point methods to obtain practical algo-
rithms.
14.1 General Gaussian Rauch–Tung–Striebel Smoother
The Gaussian moment matching described in Section 8.1 can be used in
smoothers in an analogous manner to the Gaussian ﬁlters in Section 8.2.
If we follow the extended RTS smoother derivation in Section 13.1, we
get the following algorithm, which originally appears in S¨arkk¨a and Har-
tikainen (2010a).
278

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.1 General Gaussian Rauch–Tung–Striebel Smoother
279
Algorithm 14.1 (Gaussian RTS smoother I). The equations of the additive
form Gaussian RTS smoother are the following:
m kC1 D
Z
f.xk/ N.xk j mk; Pk/ dxk;
P  kC1 D
Z
Œf.xk/   m kC1 Œf.xk/   m kC1T N.xk j mk; Pk/ dxk C Qk;
DkC1 D
Z
Œxk   mk Œf.xk/   m kC1T N.xk j mk; Pk/ dxk;
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.1)
Derivation
Assume that the approximate means and covariances of the
ﬁltering distributions are available:
p.xk j y1Wk/ ' N.xk j mk; Pk/;
and the smoothing distribution of time step k C 1 is known and approxi-
mately Gaussian:
p.xkC1 j y1WT / ' N.xkC1 j ms
kC1; P s
kC1/:
We can now derive moment matching-based Gaussian approximation to
the smoothing distribution at step k as follows.
1. In similar way to the derivation of the Gaussian ﬁlter in Section 8.2, we
apply the moment matching in Algorithm 8.1 to xkC1 D f.xk/ C qk
with xk  N.mk; Pk/, to get
p.xk; xkC1 j y1Wk/ ' N
 xk
xkC1
 ˇˇˇ
 mk
m kC1

;
 Pk
DkC1
DT
kC1
P  kC1

;
(14.2)
where m kC1, P  kC1, and DkC1 are as deﬁned in Equation (14.1).
2. Because the distribution (14.2) is Gaussian, by the computation rules of
Gaussian distributions, the conditional distribution of xk is given as
p.xk j xkC1; y1WT / ' N.xk j Qm2; QP2/;
where
Gk D DkC1 ŒP  kC1 1;
Qm2 D mk C Gk.xkC1   m kC1/;
QP2 D Pk   Gk P  kC1 GT
k:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
280
General Gaussian Smoothing
3. The rest of the derivation is completely analogous to the derivation of
the ERTSS in Section 13.1.
The integrals above can be approximated using analogous numerical
integration or analytical approximation schemes as in the ﬁltering case,
that is, with Gauss–Hermite cubatures (Ito and Xiong, 2000; Wu et al.,
2006), spherical cubature rules (McNamee and Stenger, 1967; Arasarat-
nam and Haykin, 2009), or with many other numerical integration schemes.
In the non-additive case, the Gaussian smoother becomes the following
(S¨arkk¨a and Hartikainen, 2010a).
Algorithm 14.2 (Gaussian RTS smoother II). The equations of the non-
additive form Gaussian RTS smoother are the following:
m kC1 D
Z
f.xk; qk/ N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
P  kC1 D
Z
Œf.xk; qk/   m kC1 Œf.xk; qk/   m kC1T
 N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
DkC1 D
Z
Œxk   mk Œf.xk; qk/   m kC1T
 N.xk j mk; Pk/ N.qk j 0; Qk/ dxk dqk;
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.3)
As in the Gaussian ﬁltering case, the above algorithms are mainly theo-
retical, because the integrals can be solved in closed form only in special
cases. Fixed-point and ﬁxed-lag (as opposed to ﬁxed-interval) versions of
the algorithms above can also be found in S¨arkk¨a and Hartikainen (2010a).
14.2 Gauss–Hermite Rauch–Tung–Striebel Smoother
By using the Gauss–Hermite cubature integration approximation from Sec-
tion 8.3 in the additive form Gaussian RTS smoother, we get the following
Gauss–Hermite Rauch–Tung–Striebel smoother (GHRTSS) algorithm.
Algorithm 14.3 (Gauss–Hermite Rauch–Tung–Striebel smoother). The
additive form Gauss–Hermite RTS smoother algorithm is the following.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.2 Gauss–Hermite Rauch–Tung–Striebel Smoother
281
1. Form the sigma points as
X .i1;:::;in/
k
D mk C
p
Pk .i1;:::;in/;
i1; : : : ; in D 1; : : : ; p; (14.4)
where the unit sigma points .i1;:::;in/ were deﬁned in Equation (8.30).
2. Propagate the sigma points through the dynamic model:
OX .i1;:::;in/
kC1
D f.X .i1;:::;in/
k
/;
i1; : : : ; in D 1; : : : ; p:
(14.5)
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
X
i1;:::;in
Wi1;:::;in OX .i1;:::;in/
kC1
;
P  kC1 D
X
i1;:::;in
Wi1;:::;in. OX .i1;:::;in/
kC1
  m kC1/ . OX .i1;:::;in/
kC1
  m kC1/TCQk;
DkC1 D
X
i1;:::;in
Wi1;:::;in.X .i1;:::;in/
k
  mk/ . OX .i1;:::;in/
kC1
  m kC1/T;
(14.6)
where the weights Wi1;:::;in were deﬁned in Equation (8.29).
4. Compute the gain Gk, mean ms
k and covariance P s
k as follows:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.7)
It would also be possible to formulate a non-additive version of the
above smoother analogously, but due to unpleasant exponential compu-
tational scaling of the Gauss–Hermite cubature method in the state dimen-
sion, that extension is not very useful in practice. Recall that the state di-
mension doubles when using the non-additive transform, because we need
to integrate over the state and process noise jointly.
Example 14.4 (Pendulum tracking with GHRTSS). The result of applying
GHRTSS to the pendulum model in Example 7.6 is shown in Figure 14.1.
The resulting RMSE error is 0:04, which is between the ERTSS and IERTSS
errors (which were 0:06 and 0:03/ and signiﬁcantly lower than the GHKF
error of 0:10.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
282
General Gaussian Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
GHRTSS estimate
Figure 14.1 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the GHRTSS. The
resulting RMSE is 0:04, which is lower than that of ERTSS (0:06)
but higher than that of IERTSS (0:03). Recall that GHKF had an
RMSE of 0:10.
14.3 Cubature Rauch–Tung–Striebel Smoother
By using the third order spherical cubature approximation (Section 8.5) to
the additive form Gaussian RTS smoother, we get the following cubature
Rauch–Tung–Striebel smoother (CRTSS) algorithm (see Arasaratnam and
Haykin, 2011).
Algorithm 14.5 (Cubature Rauch–Tung–Striebel smoother I). The addi-
tive form cubature RTS smoother algorithm is the following.
1. Form the sigma points:
X .i/
k
D mk C
p
Pk .i/;
i D 1; : : : ; 2n;
(14.8)
where the unit sigma points are deﬁned as
.i/ D
(pn ei;
i D 1; : : : ; n;
 pn ei n;
i D n C 1; : : : ; 2n;
(14.9)
where ei denotes a unit vector in the direction of the coordinate axis i.
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f.X .i/
k /;
i D 1; : : : ; 2n:

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.3 Cubature Rauch–Tung–Striebel Smoother
283
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D 1
2n
2n
X
iD1
OX .i/
kC1;
P  kC1 D 1
2n
2n
X
iD1
. OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T C Qk;
DkC1 D 1
2n
2n
X
iD1
.X .i/
k
  mk/ . OX .i/
kC1   m kC1/T:
(14.10)
4. Compute the gain Gk, mean ms
k, and covariance P s
k as follows:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.11)
By using the third order spherical cubature approximation to the non-
additive form Gaussian RTS smoother, we get the following algorithm.
Algorithm 14.6 (Cubature Rauch–Tung–Striebel smoother II). A single
step of the non-additive augmented form cubature RTS smoother is as fol-
lows.
1. Form the sigma points for the n0 D n C nq-dimensional augmented
random variable .xk; qk/:
QX .i/
k
D Qmk C
q
QPk .i/0;
i D 1; : : : ; 2n0;
(14.12)
where
Qmk D
mk
0

;
QPk D
Pk
0
0
Qk

:
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f. QX .i/;x
k
; QX .i/;q
k
/;
i D 1; : : : ; 2n0;
where QX .i/;x
k
and QX.i/;q
k
denote the parts of the augmented sigma point
i that correspond to xk and qk, respectively.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
284
General Gaussian Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
CRTSS estimate
Figure 14.2 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the CRTSS. The
resulting RMSE is 0:04, which is similar as that of GHRTSS.
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
1
2n0
2n0
X
iD1
OX .i/
kC1;
P  kC1 D
1
2n0
2n0
X
iD1
. OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T;
DkC1 D
1
2n0
2n0
X
iD1
. QX .i/;x
k
  mk/ . OX .i/
kC1   m kC1/T:
(14.13)
4. Compute the gain Gk, mean ms
k, and covariance P s
k:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk
 ms
kC1   m kC1

;
P s
k D Pk C Gk
 P s
kC1   P  kC1

GT
k:
(14.14)
Example 14.7 (Pendulum tracking with CRTSS). The result of applying
the CRTSS for the pendulum model in Example 7.6 is shown in Figure 14.2.
The error 0:04 and the overall result are similar to GHRTSS.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.4 Unscented Rauch–Tung–Striebel Smoother
285
14.4 Unscented Rauch–Tung–Striebel Smoother
The unscented Rauch–Tung–Striebel smoother (URTSS,
S¨arkk¨a, 2006;
ˇSimandl and Dun´ık, 2006; S¨arkk¨a, 2008) is a Gaussian approximation-
based smoother where the non-linearity is approximated using the
unscented transform, which is a numerical integration solution to the
Gaussian moment matching integrals (recall Sections 8.7 and 8.8). The
smoother equations for the additive model (7.39) are given as follows.
Algorithm 14.8 (Unscented Rauch–Tung–Striebel smoother I). The addi-
tive form unscented RTS smoother algorithm is the following.
1. Form the sigma points:
X .0/
k
D mk;
X .i/
k
D mk C
p
n C 
hp
Pk
i
i ;
X .iCn/
k
D mk  p
n C 
hp
Pk
i
i ;
i D 1; : : : ; n;
(14.15)
where the parameter  was deﬁned in Equation (8.74).
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f.X .i/
k /;
i D 0; : : : ; 2n:
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
2n
X
iD0
W .m/
i
OX .i/
kC1;
P  kC1 D
2n
X
iD0
W .c/
i
. OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T C Qk;
DkC1 D
2n
X
iD0
W .c/
i
.X .i/
k
  mk/ . OX .i/
kC1   m kC1/T;
(14.16)
where the weights were deﬁned in Equation (8.75).
4. Compute the smoother gain Gk, the smoothed mean ms
k, and the co-
variance P s
k as follows:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.17)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
286
General Gaussian Smoothing
The above computations are started from the ﬁltering result of the last
time step ms
T D mT , P s
T D PT , and the recursion runs backward for
k D T   1; : : : ; 0.
Derivation
The derivation is the same as of the general Gaussian
smoother in Algorithm 14.1 except that the moment matching approxima-
tion is replaced with the unscented transform.
It is easy to see that the CRTSS in Algorithm 14.5 is indeed a special case
of the URTSS method with parameters ˛ D 1, ˇ D 0,  D 0. However,
that particular selection of parameters tends to work well in practice, and
due to the simplicity of the sigma-point and weight selection rules, the
method is very simple to implement.
The corresponding augmented version of the smoother for non-additive
models of the form (7.39) is almost the same, except that the augmented
UT in Algorithm 8.16 is used instead of the additive UT in Algorithm 8.15.
The smoother can be formulated as follows (S¨arkk¨a, 2008).
Algorithm 14.9 (Unscented Rauch–Tung–Striebel smoother II). A single
step of the non-additive augmented form unscented RTS smoother for non-
additive models is as follows.
1. Form the sigma points for the n0 D n C nq-dimensional augmented
random variable .xk; qk/:
QX .0/
k
D Qmk;
QX .i/
k
D Qmk C
p
n0 C 0
q
QPk

i
;
QX .iCn0/
k
D Qmk  p
n0 C 0
q
QPk

i
;
i D 1; : : : ; n0;
(14.18)
where
Qmk D
mk
0

;
QPk D
Pk
0
0
Qk

:
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f. QX .i/;x
k
; QX .i/;q
k
/;
i D 0; : : : ; 2n0;
where QX .i/;x
k
and QX .i/;q
k
denote the parts of the augmented sigma point
i that correspond to xk and qk, respectively.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.5 Higher Order Cubature/Unscented RTS Smoothers
287
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
2n0
X
iD0
W .m/0
i
OX .i/
kC1;
P  kC1 D
2n0
X
iD0
W .c/0
i
. OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T;
DkC1 D
2n0
X
iD0
W .c/0
i
. QX .i/;x
k
  mk/ . OX .i/
kC1   m kC1/T;
(14.19)
where the deﬁnitions of the parameter 0 and the weights W .m/0
i
and
W .c/0
i
are the same as in Section 8.7.
4. Compute the smoother gain Gk, the smoothed mean ms
k, and the co-
variance P s
k:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk

ms
kC1   m kC1

;
P s
k D Pk C Gk

P s
kC1   P  kC1

GT
k:
(14.20)
Example 14.10 (Pendulum tracking with URTSS). The result of applying
the URTSS to the pendulum model in Example 7.6 is shown in Figure 14.3.
The resulting RMSE is 0:04, which is the same as for the GHRTSS and
CRTSS.
14.5 Higher Order Cubature/Unscented RTS Smoothers
Similarly to the ﬁltering case discussed in Section 8.9, we can use higher
order cubature or unscented rules (e.g., McNamee and Stenger, 1967; Wu
et al., 2006) to construct approximate Gaussian smoothers. For example,
using the ﬁfth order rule that we used in Algorithm 8.22, we get the fol-
lowing smoother.
Algorithm 14.11 (Fifth order cubature/unscented RTS smoother I). The
additive form of the ﬁfth order cubature/unscented RTS smoother algo-
rithm (URTSS5) is the following.
1. Form the sigma points:
X .i/
k
D mk C
p
Pk .i/;
i D 0; 1; 2; : : : ;
(14.21)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
288
General Gaussian Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
URTSS estimate
Figure 14.3 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the URTSS. The
resulting RMSE is 0:04, which is practically the same as with the
GHRTSS and CRTSS. Recall that the RMSE of the UKF was
0:10, which is signiﬁcantly higher.
where the unit sigma points are deﬁned as in Equation (8.102).
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f.X .i/
k /;
i D 0; 1; 2; : : : :
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
X
i
Wi OX .i/
kC1;
P  kC1 D
X
i
Wi . OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T C Qk;
DkC1 D
X
i
Wi .X .i/
k
  mk/ . OX .i/
kC1   m kC1/T;
(14.22)
where the weights Wi are deﬁned as in Equation (8.103).
4. Compute the gain Gk, mean ms
k, and covariance P s
k as follows:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.23)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.5 Higher Order Cubature/Unscented RTS Smoothers
289
The corresponding non-additive form is the following.
Algorithm 14.12 (Fifth order cubature/unscented RTS smoother II). A sin-
gle step of the augmented form the ﬁfth order cubature/unscented RTS
smoother is as follows.
1. Form the sigma points for the n0 D n C nq-dimensional augmented
random variable .xk; qk/:
QX .i/
k
D Qmk C
q
QPk .i/0;
i D 0; 1; 2; : : : ;
(14.24)
where
Qmk D
mk
0

;
QPk D
Pk
0
0
Qk

;
and the unit sigma points .i/0 are deﬁned as in Equation (8.102) (with
n  n C nq).
2. Propagate the sigma points through the dynamic model:
OX .i/
kC1 D f. QX .i/;x
k
; QX .i/;q
k
/;
i D 0; 1; 2; : : : ;
where QX .i/;x
k
and QX.i/;q
k
denote the parts of the augmented sigma point
i that correspond to xk and qk, respectively.
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D
X
i
W 0
i
OX .i/
kC1;
P  kC1 D
X
i
W 0
i . OX .i/
kC1   m kC1/ . OX .i/
kC1   m kC1/T;
DkC1 D
X
i
W 0
i . QX .i/;x
k
  mk/ . OX .i/
kC1   m kC1/T;
(14.25)
where the weights W 0
i are deﬁned as in Equation (8.103) (with n  
n C nq).
4. Compute the gain Gk, mean ms
k, and covariance P s
k:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk
 ms
kC1   m kC1

;
P s
k D Pk C Gk
 P s
kC1   P  kC1

GT
k:
(14.26)
Please note that the above two algorithms can be easily modiﬁed to use
any (sigma-point) integration method (e.g., McNamee and Stenger, 1967;
Ito and Xiong, 2000; Julier et al., 2000; Wu et al., 2006; Arasaratnam

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
290
General Gaussian Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
URTSS5 estimate
Figure 14.4 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the URTSS5. The
resulting RMSE is 0:04, which is similar as those of the other
Gaussian smoothers.
and Haykin, 2009; S¨arkk¨a et al., 2016; Karvonen et al., 2019) simply by
changing the unit sigma points and weights.
Example 14.13 (Pendulum tracking with URTSS5). The result of applying
the URTSS5 to the pendulum model in Example 7.6 is shown in Figure 14.4.
The error 0:04 and the overall result are similar to the other Gaussian
integration-based smoothers that we have encountered so far.
Example 14.14 (Coordinated turn model with Gaussian smoothers). We
applied numerical integration-based Gaussian smoothers to the coordi-
nated turn model introduced in Example 7.7 using Gauss–Hermite, spher-
ical cubature, unscented, and ﬁfth order cubature/unscented integration.
The resulting RMSE was 0:016 for all of the methods (for ERTSS it was
0:017). Figure 14.5 shows the result of the URTSS, which looks similar to
the other smoothers, together with the ERTSS result.
14.6 Statistical Linear Regression Smoothers
Similarly to Gaussian ﬁlters, the Gaussian smoothers presented here can
also be understood as algorithms that make use of enabling approxima-
tions (see Chapter 9) – that is, as algorithms that ﬁrst linearize the models

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.6 Statistical Linear Regression Smoothers
291
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
ERTSS estimate
URTSS estimate
Sensors
Figure 14.5 The result of applying URTSS to the coordinated
turn model. The result is practically the same as with the other
numerical integration-based smoothers with RMSE of 0:016.
and then make use of closed-form solutions provided by the RTS smoother
to compute the posterior. For example, the extended RTS smoother in Al-
gorithm 13.1 makes use of the same ﬁrst-order Taylor expansions as an
EKF and linearizes the dynamic model about the ﬁltering mean, mk. Sim-
ilarly, the iterated ERTSS in Algorithm 13.5 instead uses a ﬁrst order Tay-
lor expansion about the current estimate of the smoothed posterior mean,
ms;.i 1/
k
.
The general Gaussian smoothers can be understood as methods that lin-
earize the models using statistical linear regression (SLR). The afﬁne RTS
smoother in Theorem 12.5 does not use the measurement model, and, to use
the RTS smoother, it is sufﬁcient to perform SLR on the dynamic model
such that we obtain a linearized model
xkC1 D Ak xk C ak C Qek;
(14.27)
where Qek  N.0; ƒk/. As discussed in Chapter 10 (see Deﬁnition 10.1
and Theorem 10.2), it is possible to perform SLR with respect to differ-
ent choices of distributions. Depending on the distribution that we use to
perform SLR, we obtain different smoothers. It turns out that if we use the
ﬁltering density N.xk j mk; Pk/ to perform SLR on the dynamic model,
we obtain Gaussian RTS smoothers that yield the same result as Algo-
rithms 14.1 and 14.2.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
292
General Gaussian Smoothing
Let us now see how to do general Gaussian smoothing using SLR for
additive noise models (as given, e.g., in Equation (9.1)). Combining SLR
of the dynamic model, where SLR is performed with respect to N.xk j
mk; Pk/, with Theorem 12.5 yields the following algorithm.
Algorithm 14.15 (Statistical linear regression smoother). The addi-
tive noise statistical linear regression RTS smoother (SLRRTSS) is the
following.
 Linearize the dynamic model at time step k:
Find
Ak D .P xx
kC1/T P  1
k ;
ak D  kC1   Ak mk;
ƒk D P x
kC1   Ak Pk AT
k;
(14.28)
where
 kC1 D
Z
f.x/ N.x j mk; Pk/ dx;
P xx
kC1 D
Z
.x   mk/ .f.x/    kC1/T N.x j mk; Pk/ dx;
P x
kC1 D
Z
.f.x/    kC1/ .f.x/    kC1/T N.x j mk; Pk/ dx C Qk:
(14.29)
 Perform RTS smoothing using the afﬁne model
m kC1 D Ak mk C ak 1;
P  kC1 D Ak Pk AT
k C ƒk;
Gk D Pk AT
k ŒP  kC1 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k:
(14.30)
In Algorithm 14.15 we explicitly formulate the linearized model and
then use that to perform RTS smoothing. However, if we compare (14.28)
with (14.30), we notice that m kC1 D  kC1 and P  kC1 D P x
kC1. If we also
introduce the notation DkC1 D Pk AT
k, we get the relation DkC1 D P x
kC1.
Having established these relations, we note that (14.29) precisely matches
the ﬁrst three lines in (14.1). We can conclude that some of the equations
in Algorithm 14.15 are redundant and that the algorithm can be simpliﬁed
into Algorithm 14.1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.6 Statistical Linear Regression Smoothers
293
Similarly, if we formulate an SLR smoother for non-additive models,
by performing SLR with respect to N.xk j mk; Pk/, that algorithm can be
simpliﬁed into Algorithm 14.2. More generally, in SLR smoothing, if we
linearize the dynamic model with respect to the ﬁltering density N.xk j
mk; Pk/, then it yields the same result as the corresponding Gaussian RTS
smoother.
In general, to use a Gaussian smoother we need to compute the mo-
ments m kC1 D EŒxkC1 j y1Wk, P  kC1 D CovŒxkC1 j y1Wk, and DkC1 D
CovŒxk; xkC1 j y1Wk. Based on the theory presented in Chapter 9, it is
possible to present ﬁve different expressions for these moments: one for
additive noise models (9.1), and two each for non-additive (9.9) and con-
ditional distribution models (9.10). Two of those expressions were used to
formulate Algorithms 8.3 and 8.4, and below we use a third expression
to present a Gaussian RTS smoother for conditional distribution models.
For the remaining two expressions, which make use of the conditional mo-
ments formulations, see Exercise 14.3.
Algorithm 14.16 (Gaussian RTS smoother III). The conditional distribu-
tion Gaussian RTS smoother is the following:
m kC1 D
Z
xkC1 p.xkC1 j xk/ N.xk j mk; Pk/ dxkC1 dxk;
P  kC1 D
Z
.xkC1   m kC1/ .xkC1   m kC1/T
 p.xkC1 j xk/ N.xk j mk; Pk/ dxkC1 dxk;
DkC1 D
Z
.xk   mk/ .xkC1   m kC1/T
 p.xkC1 j xk/ N.xk j mk; Pk/ dxkC1 dxk;
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.31)
The three integrals in (14.31) might not have closed form solutions. In
that case, we may need to approximate them numerically, for instance,
using Monte Carlo sampling, as in the following algorithm.
Algorithm 14.17 (Monte Carlo RTS smoother). The conditional distribu-
tion form of the Monte Carlo RTS smoother (MCRTSS) is the following.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
294
General Gaussian Smoothing
1. Generate samples of xk:
x.i/
k  N.mk; Pk/;
i D 1; : : : ; N:
(14.32)
2. Propagate the samples through the dynamic model:
x.i/
kC1  p.xkC1 j x.i/
k /;
i D 1; : : : ; N:
(14.33)
3. Compute the predicted mean m kC1, the predicted covariance P  kC1, and
the cross-covariance DkC1:
m kC1 D 1
N
N
X
iD1
x.i/
kC1;
P  kC1 D 1
N
N
X
iD1
.x.i/
kC1   m kC1/ .x.i/
kC1   m kC1/T;
DkC1 D 1
N
N
X
iD1
.x.i/
k   mk/ .x.i/
kC1   m kC1/T:
(14.34)
4. Perform the RTS backward recursion:
Gk D DkC1 ŒP  kC1 1;
ms
k D mk C Gk .ms
kC1   m kC1/;
P s
k D Pk C Gk .P s
kC1   P  kC1/ GT
k:
(14.35)
An interesting aspect of the Gaussian smoothers that we have seen so far
in this chapter is that they rely on the same linearizations as the Gaussian
ﬁlters. That is, the Gaussian ﬁlters implicitly linearize the dynamic model
by performing SLR with respect to the ﬁltering distribution, and so do the
Gaussian smoothers. Consequently, if we use Algorithm 9.20 to perform
ﬁltering such that we explicitly linearize the dynamic model at each time
step, we could directly use those linearizations to perform RTS smooth-
ing using Theorem 12.5, and this would yield the same result as running
Algorithm 8.3 followed by Algorithm 14.1.
14.7 Posterior Linearization Smoothers
As in the ﬁltering setting (see Chapter 10), there is no inherent reason
to linearize our models with respect to the ﬁltering distributions, and we
can use the generalized SLR introduced in Deﬁnition 10.1 to linearize the
models also for smoothing. Consequently, for each of the dynamic and
measurement models, we are free to select any linearization distribution

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.7 Posterior Linearization Smoothers
295
when linearizing the models. Let f
k.xk/ and h
k .xk/ denote our lineariza-
tion distributions at time step k for the dynamic and measurement models,
respectively, and let mf
k D Ef
kŒxk, P f
k D Covf
kŒxk, mh
k D Eh
k Œxk,
and P h
k D Covh
k Œxk be the corresponding means and covariances for
k D 0; 1; 2; : : : ; T . Given the linearized models, we can perform (afﬁne)
Kalman ﬁltering and RTS smoothing to compute the smoothing distribu-
tions.
Algorithm 14.18 (Generalized SLR smoother). The generalized SLR
smoother for additive noise models is the following.
1. For k D 0; 1; : : : ; T  1, perform SLR of the dynamic model with respect
to f
k.xk/.
(i) Compute moments with respect to xk  f
k.xk/:
 kC1 D
Z
f.x/ f
k.x/ dx;
P xx
kC1 D
Z
.x   mf
k/ .f.x/    kC1/T f
k.x/ dx;
P x
kC1 D
Z
.f.x/    kC1/ .f.x/    kC1/T f
k.x/ dx C Qk:
(14.36)
(ii) Linearize the dynamic model:
Ak D .P xx
kC1/T .P f
k/ 1;
ak D  kC1   Ak mf
k;
ƒk D P x
kC1   Ak P f
k AT
k:
(14.37)
2. For k D 1; 2; : : : ; T , perform SLR of the measurement model with re-
spect to h
k .xk/.
(i) Compute moments with respect to xk  h
k .xk/:
C
k D
Z
h.x/ h
k .x/ dx;
P xy
k D
Z
.x   mh
k/ .h.x/   C
k /T h
k .x/ dx;
P y
k D
Z
.h.x/   C
k / .h.x/   C
k /T h
k .x/ dx C Rk:
(14.38)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
296
General Gaussian Smoothing
(ii) Linearize the measurement model:
Hk D .P xy
k /T .P h
k / 1;
bk D C
k   Hk mh
k;
k D P y
k   Hk P h
k HT
k:
(14.39)
3. Run an afﬁne Kalman ﬁlter on the linearized model. For k
D
1; 2; : : : ; T :
(i) Prediction
m k D Ak 1 mk 1 C ak 1;
P  k D Ak 1 Pk 1 AT
k 1 C ƒk 1:
(14.40)
(ii) Update
k D Hk m k C bk;
Sk D Hk P  k HT
k C k;
Kk D Pk HT
k S 1
k ;
mk D m k C Kk .yk   k/;
Pk D P  k   Kk Sk KT
k:
(14.41)
4. Run an afﬁne RTS smoother on the linearized model. Set ms
T D mT
and P s
T D PT . For k D T   1; T   2; : : : ; 0:
m kC1 D Ak mk C ak;
P  kC1 D Ak Pk AT
k C ƒk;
Gk D Pk AT
k .P  kC1/ 1;
ms
k D mk C Gk Œms
kC1   m kC1;
P s
k D Pk C Gk ŒP s
kC1   P  kC1 GT
k:
(14.42)
The posterior linearization ﬁlters introduced in Chapter 10 were based
on the philosophy that we should construct linearizations that are accurate
on average across our posterior density of the state xk. We can extend this
principle to smoothing and perform SLR with respect to the smoothing dis-
tribution p.xk j y1WT / ' N.xk j ms
k; P s
k/. In other words, we would like
to perform generalized SLR smoothing with f
k.xk/ D h
k .xk/ D p.xk j
y1WT / or at least with respect to p.xk j y1WT / ' N.xk j ms
k; P s
k/. In prac-
tice, the moments .ms
k; P s
k/ are unknown to us as they are the end-products
that we wish to compute. Fortunately, as for the posterior linearization ﬁl-
ters, we can construct an iterative algorithm where we use our current best

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.7 Posterior Linearization Smoothers
297
approximations of the posterior moments at each step. The resulting algo-
rithm is called the iterated posterior linearization smoother (IPLS, Garc´ıa-
Fern´andez et al., 2017; Tronarp et al., 2018).
Algorithm 14.19 (Iterated posterior linearization smoother I). The iterated
posterior linearization smoother for additive noise models is started from
an initial guess for the trajectory moments ms;.0/
0WT , P s;.0/
0WT . For i D 1; 2; : : :
we do the following.
1. For k D 0; 1; : : : ; T  1, perform SLR of the dynamic model with respect
to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
 ;.i 1/
kC1
D
Z
f.x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P xx;.i 1/
kC1
D
Z
.x   ms;.i 1/
k
/ .f.x/    ;.i 1/
kC1
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P x;.i 1/
kC1
D
Z
.f.x/    ;.i 1/
kC1
/ .f.x/    ;.i 1/
kC1
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx C Qk:
(14.43)
(ii) Linearize the dynamic model:
A.i/
k D .P xx;.i 1/
kC1
/T .P s;.i 1/
k
/ 1;
a.i/
k D  ;.i 1/
kC1
  A.i/
k ms;.i 1/
k
;
ƒ.i/
k D P x;.i 1/
kC1
  A.i/
k P s;.i 1/
k
.A.i/
k /T:
(14.44)
2. For k D 1; 2; : : : ; T , perform SLR of the measurement model with re-
spect to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
C;.i 1/
k
D
Z
h.x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P xy;.i 1/
k
D
Z
.x   ms;.i 1/
k
/ .h.x/   C;.i 1/
k
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P y;.i 1/
k
D
Z
.h.x/   C;.i 1/
k
/ .h.x/   C;.i 1/
k
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx C Rk:
(14.45)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
298
General Gaussian Smoothing
(ii) Linearize the measurement model:
H.i/
k D .P xy;.i 1/
k
/T .P s;.i 1/
k
/ 1;
b.i/
k D C;.i 1/
k
  H.i/
k ms;.i 1/
k
;
.i/
k D P y;.i 1/
k
  H.i/
k P s;.i 1/
k
.H.i/
k /T:
(14.46)
3. Run a Kalman ﬁlter on the linearized model. To initiate the algorithm
we set m.i/
0 D m0 and P .i/
0
D P0. For k D 1; 2; : : : ; T :
(i) Prediction
m .i/
k
D A.i/
k 1 m.i/
k 1 C a.i/
k 1;
P  .i/
k
D A.i/
k 1 P .i/
k 1 .A.i/
k 1/T C ƒ.i/
k 1:
(14.47)
(ii) Update
.i/
k D H.i/
k m .i/
k
C b.i/
k ;
S.i/
k D H.i/
k P  .i/
k
.H.i/
k /T C .i/
k ;
K.i/
k D P  .i/
k
.H.i/
k /T .S.i/
k / 1;
m.i/
k D m .i/
k
C K.i/
k .yk   .i/
k /;
P .i/
k
D P  .i/
k
  K.i/
k S.i/
k .K.i/
k /T:
(14.48)
4. Run an RTS smoother on the linearized model. Set ms;.i/
T
D m.i/
T and
P s.i/
T
D P .i/
T . For k D T   1; T   2; : : : ; 0:
m .i/
kC1 D A.i/
k m.i/
k C a.i/
k ;
P  .i/
kC1 D A.i/
k P .i/
k .A.i/
k /T C ƒ.i/
k ;
G.i/
k
D P .i/
k .A.i/
k /T .P  .i/
kC1/ 1;
ms;.i/
k
D m.i/
k C G.i/
k Œms;.i/
kC1   m .i/
kC1;
P s;.i/
k
D P .i/
k
C G.i/
k ŒP s;.i/
kC1   P  .i/
kC1 .G.i/
k /T:
(14.49)
At convergence, set ms;
1WT D ms;.i/
1WT and P s;
1WT D P s;.i/
1WT .
Similarly to the iterated posterior linearization ﬁlter (IPLF), the IPLS
seeks to iteratively improve the linearizations, but there are also important
differences. First, the IPLF performs SLR with respect to the ﬁltering den-
sity, whereas the the IPLS performs SLR with respect to the smoothing
density. The IPLS thus makes use of all measurements y1WT when selecting
the linearizations, which has the potential to yield linearizations that are
much more accurate in the relevant regions. Second, the IPLF only tries

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.7 Posterior Linearization Smoothers
299
to improve on how we linearize the measurement model (and only at one
time step at a time), whereas the IPLS iteratively updates the linearizations
of both dynamic and measurement models, at all time steps.
The IPLS also has important connections to the IERTSS presented
in Section 13.3. Both algorithms use the current approximation to the
smoothed posterior to linearize the models. Given the linearized models,
new smoothed posteriors are found in closed form by running an RTS
smoother. The difference between the two algorithms is that the IEKS
makes use of ﬁrst order Taylor expansions about the mean of the smoothed
posterior, whereas the IPLS performs SLR with respect to the smoothed
posterior.
Algorithm 14.19 is designed for additive noise models, but we can also
develop iterated posterior linearization smoothers for non-additive and con-
ditional distribution models. As for the SLR smoothers, the IPLSs rely on
certain moments to compute the SLR; in Algorithm 14.19 these moments
are computed in (14.43) and (14.45). What changes when we use the IPLS
for the other model classes is that the expressions for these moments are
modiﬁed. As we saw in Section 9.4, we can express these moments in
two different forms for both non-additive and conditional distribution mod-
els. Here we present an IPLS that makes use of the conditional moments
form. This algorithm assumes that we are able to compute (numerically
or analytically) the moments  k .xk 1/ D E Œxk j xk 1, P x
k .xk 1/ D
Cov Œxk j xk 1, k.xk/ D E Œyk j xk, and P y
k .xk/ D Cov Œyk j xk, and
the algorithm can be used for additive, non-additive, and conditional dis-
tribution models as long as we can compute these moments.
Algorithm 14.20 (Iterated posterior linearization smoother II). The con-
ditional moments iterated posterior linearization smoother starts from an
initial guess for the trajectory moments ms;.0/
0WT , P s;.0/
0WT . For i D 1; 2; : : : we
do the following.
1. For k D 0; 1; : : : ; T  1, perform SLR of the dynamic model with respect
to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
300
General Gaussian Smoothing
(i) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
 ;.i 1/
kC1
D
Z
 k .x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P xx;.i 1/
kC1
D
Z
.x   ms;.i 1/
k
/ . k .x/    ;.i 1/
kC1
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P x;.i 1/
kC1
D
Z
. k .x/    ;.i 1/
kC1
/ . k .x/    ;.i 1/
kC1
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx
C
Z
P x
k .x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx:
(14.50)
(ii) Linearize the dynamic model using Equation (14.44).
2. For k D 1; 2; : : : ; T , perform SLR of the measurement model with re-
spect to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
C;.i 1/
k
D
Z
k.x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P xy;.i 1/
k
D
Z
.x   ms;.i 1/
k
/ .k.x/   C;.i 1/
k
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx;
P y;.i 1/
k
D
Z
.k.x/   C;.i 1/
k
/ .k.x/   C;.i 1/
k
/T
 N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx
C
Z
P y
k .x/ N.x j ms;.i 1/
k
; P s;.i 1/
k
/ dx:
(14.51)
(ii) Linearize the measurement model using Equation (14.46).
3. Run a Kalman ﬁlter on the linearized model. To initiate the algorithm we
set m.i/
0 D m0 and P .i/
0
D P0. For k D 1; 2; : : : ; T , perform prediction
and update using Equations (14.47) and (14.48).
4. Run an RTS smoother on the linearized model. Set ms;.i/
T
D m.i/
T and
P s.i/
T
D P .i/
T . For k D T   1; T   2; : : : ; 0, perform RTS backward
recursion using Equation (14.49).
At convergence, set ms
1WT D ms;.i/
1WT and P s
1WT D P s;.i/
1WT .

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.7 Posterior Linearization Smoothers
301
To convert Algorithm 14.19 into a practical algorithm, we need a strat-
egy to approximate the integrals in (14.43) and (14.45). Here we present a
general sigma point version of the IPLS for additive noise models.
Algorithm 14.21 (Sigma-point iterated posterior linearization smoother
I). The sigma-point iterated posterior linearization smoother for additive
noise is started from an initial guess for the trajectory moments ms;.0/
0WT and
P s;.0/
0WT . For i D 1; 2; : : : we do the following.
1. For k D 0; 1; : : : ; T  1, perform SLR of the dynamic model with respect
to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Form the sigma points as:
X .j/
k
D ms;.i 1/
k
C
q
P s;.i 1/
k
.j /;
j D 1; : : : ; m; (14.52)
and select the weights W1; : : : ; Wm.
(ii) Propagate the sigma points through the dynamic model:
X  .j/
kC1 D f.X .j /
k /;
j D 1; : : : ; m:
(14.53)
(iii) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
 ;.i 1/
kC1
D
m
X
j D1
Wj X  .j /
kC1 ;
P xx;.i 1/
kC1
D
m
X
j D1
Wj .X .j /
k
  ms;.i 1/
k
/ .X  .j /
kC1    ;.i 1/
kC1
/T;
P x;.i 1/
kC1
D
m
X
j D1
Wj .X  .j /
kC1    ;.i 1/
kC1
/ .X  .j /
kC1    ;.i 1/
kC1
/TCQk:
(14.54)
(iv) Linearize the dynamic model using (14.44).
2. For k D 1; 2; : : : ; T , perform SLR of the measurement model with re-
spect to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Form the sigma points as:
X .j/
k
D ms;.i 1/
k
C
q
P s;.i 1/
k
.j /;
j D 1; : : : ; m; (14.55)
and select the weights W1; : : : ; Wm.
(ii) Propagate the sigma-points through the measurement model:
Y.j/
k
D h.X .j /
k /;
j D 1; : : : ; m:
(14.56)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
302
General Gaussian Smoothing
(iii) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
C;.i 1/
k
D
m
X
j D1
Wj Y.j /
k ;
P xy;.i 1/
k
D
m
X
j D1
Wj .X .j /
k
  ms;.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D
m
X
j D1
Wj .Y.j /
k
  C;.i 1/
k
/ .Y.j /
k
  C;.i 1/
k
/T C Rk:
(14.57)
(iv) Linearize the measurement model using (14.46).
3. Run an (afﬁne) Kalman ﬁlter on the linearized model. To initiate the
algorithm we set m.i/
0
D m0; P .i/
0
D P0. For k D 1; 2; : : : ; T , perform
prediction using (14.47) and update using (14.48).
4. Run an (afﬁne) RTS smoother on the linearized model. Set ms;.i/
T
D m.i/
T
and P s.i/
T
D P .i/
T . For k D T   1; T   2; : : : ; 0, perform the backward
recursion using (14.49).
At convergence, set ms
1WT D ms;.i/
1WT and P s
1WT D P s;.i/
1WT .
To create the initial guess for the trajectory moments ms;.0/
0WT and P s;.0/
0WT ,
it is common to use a sigma-point RTS smoother. We can also create a
sigma-point implementation of Algorithm 14.20.
Algorithm 14.22 (Sigma-point iterated posterior linearization smoother
II). The sigma-point conditional moment iterated posterior linearization
smoother is started from an initial guess for the trajectory moments ms;.0/
0WT
and P s;.0/
0WT . For i D 1; 2; : : : we do the following.
1. For k D 0; 1; : : : ; T  1, perform SLR of the dynamic model with respect
to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Form the sigma points as:
X .j/
k
D ms;.i 1/
k
C
q
P s;.i 1/
k
.j /;
j D 1; : : : ; m; (14.58)
and select the weights W1; : : : ; Wm.
(ii) Propagate the sigma points through the conditional mean and co-
variance functions of the dynamic model:
 ;.j/
kC1 D  k .X .j /
k /;
j D 1; : : : ; m;
P x;.j/
kC1 D P x
k .X .j /
k /;
j D 1; : : : ; m:
(14.59)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.7 Posterior Linearization Smoothers
303
(iii) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
 ;.i 1/
kC1
D
m
X
j D1
Wj  ;.j /
kC1 ;
P xx;.i 1/
kC1
D
m
X
j D1
Wj .X .j /
k
  ms;.i 1/
k
/ . ;.j /
kC1    ;.i 1/
kC1
/T;
P x;.i 1/
kC1
D
m
X
j D1
Wj . ;.j /
kC1    ;.i 1/
kC1
/ . ;.j /
kC1    ;.i 1/
kC1
/T
C
m
X
j D1
Wj P x;.j /
kC1 :
(14.60)
(iv) Linearize the dynamic model using (14.44).
2. For k D 1; 2; : : : ; T , perform SLR of the measurement model with re-
spect to N.xk j ms;.i 1/
k
; P s;.i 1/
k
/.
(i) Form the sigma points as:
X .j/
k
D ms;.i 1/
k
C
q
P s;.i 1/
k
.j /;
j D 1; : : : ; m; (14.61)
and select the weights W1; : : : ; Wm.
(ii) Propagate the sigma points through the conditional mean and co-
variance functions of the measurement model:
C;.j/
k
D k.X .j /
k /;
j D 1; : : : ; m;
P y;.j/
k
D P y
k .X .j /
k /;
j D 1; : : : ; m:
(14.62)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
304
General Gaussian Smoothing
(iii) Compute moments with respect to xk  N.xk j ms;.i 1/
k
; P s;.i 1/
k
/:
C;.i 1/
k
D
m
X
jD1
Wj C;.j /
k
;
P xy;.i 1/
k
D
m
X
jD1
Wj .X .j /
k
  ms;.i 1/
k
/ .C;.j /
k
  C;.i 1/
k
/T;
P y;.i 1/
k
D
m
X
jD1
Wj .C;.j /
k
  C;.i 1/
k
/ .C;.j /
k
  C;.i 1/
k
/T
C
m
X
j D1
Wj P y;.j /
k
:
(14.63)
(iv) Linearize the measurement model using (14.46).
3. Run an (afﬁne) Kalman ﬁlter on the linearized model. To initiate the
algorithm we set m.i/
0
D m0; P .i/
0
D P0. For k D 1; 2; : : : ; T , perform
prediction using (14.47) and update using (14.48).
4. Run an (afﬁne) RTS smoother on the linearized model. Set ms;.i/
T
D m.i/
T
and P s.i/
T
D P .i/
T . For k D T   1; T   2; : : : ; 0, perform the backward
recursion using (14.49).
At convergence, set ms
1WT D ms;.i/
1WT and P s
1WT D P s;.i/
1WT .
In the above algorithms, we are free to choose any of the numerical
integration methods that we ﬁrst saw in the context of ﬁltering in Chapter 8
are then later in the start of this chapter.
Example 14.23 (Pendulum tracking with IPLS). The result of applying
IPLS with Gauss–Hermite integration to the pendulum model in Exam-
ple 7.6 is shown in Figure 14.6. The resulting RMSE error is 0:03, which
matches that of the IERTSS.
Example 14.24 (Coordinated turn model with Gaussian smoothers). We
applied iterated posterior linearization smoothers to the coordinated turn
model introduced in Example 7.11 using Gauss–Hermite, spherical cuba-
ture, unscented, and ﬁfth order cubature integration. The resulting RMSE
was 0:015 for all of the methods (for IERTSS it was also 0:015). Figure 14.7
shows the result of the IURTSS, which looks similar to the other smoothers,
together with the IERTSS result.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
14.8 Exercises
305
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
IPLS estimate
Figure 14.6 Simulated pendulum data and the result of tracking
the pendulum described in Example 7.6 with the IPLS with
Gauss–Hermite integration. The resulting RMSE is 0:03, which is
practically the same as for IERTSS.
14.8 Exercises
14.1
Implement the Gauss–Hermite-based RTS smoother to the model in Exer-
cise 7.1, and compare the errors of the ﬁlters and smoothers.
14.2
Formulate a Gaussian RTS smoother for non-additive noise models using the
conditional moments formulation of the involved moments. Hint: Modify
Algorithm 14.2 by using expressions for m kC1, P  kC1, and DkC1 on the
conditional form described in (9.51) and (9.52). See also Appendix A.9.
14.3
Formulate a Gaussian RTS smoother that uses conditional moments instead
of the conditional distributions analogously to Algorithm 14.16.
14.4
Write down the detailed derivation of the (additive form) statistically lin-
earized RTS smoother that uses statistical linearization from Section 9.2 in-
stead of Taylor series expansions. You can follow the same steps as in the
derivation of the extended RTS smoother.
14.5
Derive and implement the statistically linearized RTS smoother above to the
model in Exercise 7.1 and compare the errors of the ﬁlters and smoothers.
14.6
Derive and implement an analytical SLR-based RTS smoother to the model
in Exercise 7.1 (cf. Exercise 9.7), and compare the errors of the ﬁlters and
smoothers.
14.7
Implement a cubature integration-based smoother for the bearings-only tar-
get tracking problem in Exercise 7.2. Compare the performance with the
ﬁlters.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
306
General Gaussian Smoothing
-2
-1.5
-1
-0.5
0
0.5
1
1.5
 x1
-1.5
-1
-0.5
0
0.5
1
1.5
 x2
True trajectory
IERTSS estimate
IURTSS estimate
Sensors
Figure 14.7 The result of applying IURTSS to the coordinated
turn model. The result is practically the same as IERTSS, with an
RMSE of 0:015.
14.8
Implement an unscented transform-based smoother for the Cartesian coor-
dinated turn model in Equations (4.61) and (4.90) with the linear position
measurement model. Also compare its performance with ﬁlters.
14.9
Implement the conditional moment-based smoother from Exercise 14.3 to
the bicycle model considered in Exercise 9.11, and compare its performance
with the Gaussian approximation-based ﬁlters.
14.10 Implement
the
Gauss–Hermite-based
iterated
posterior
linearization
smoother to the model in Exercise 7.1, and compare the errors of the ﬁlters
and smoothers.
14.11 Formulate an iterated posterior linearization smoother (IPLS) for the non-
additive state space model in (9.9). Hint: The algorithm is identical to the
IPLS for additive noise models described in Algorithm 14.19 except for
the expressions for the moments in (14.43) and (14.45). Similarly to Al-
gorithm 14.21, you can therefore refer to equations in Algorithm 14.19 for
the other parts.
14.12 Implement a cubature integration-based iterated posterior linearization
smoother for the bearings-only target tracking problem in Exercise 7.2.
Compare the performance with other smoothers.
14.13 Implement an unscented transform-based iterated posterior linearization
smoother for the Cartesian coordinated turn model in Equations (4.61)
and (4.90) with linear position measurement model. Also compare its
performance with other smoothers.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Exercises
307
14.14 Implement an iterated posterior linearization smoother to the bicycle
model considered in Exercise 9.11 and compare its performance with other
smoothers.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15
Particle Smoothing
When smoothing solutions to non-linear/non-Gaussian problems are
sought, Gaussian approximations might not lead to accurate enough
approximations. In that case it is better to use Monte Carlo (particle)
approximations, which in principle can be used for approximating ar-
bitrary smoothing distributions. Although the same SIR algorithm that
is used for particle ﬁltering provides an approximation to the smooth-
ing distribution as a by-product, it does not yet solve the problem of
particle smoothing. The challenge is that the resulting approximation
tends to be degenerate. For this reason other types of particle smoothers
have been developed, and here we present the most commonly used
ones, the forward-ﬁltering backward-sampling (FFBS) smoother and the
reweighting-based (marginal) particle smoother.
15.1 SIR Particle Smoother
The SIR particle smoother (SIR-PS) of Kitagawa (1996) is based on direct
usage of the SIR for smoothing. Recall that in Section 11.3 we derived the
sequential importance sampling (SIS) method to approximate the full pos-
terior distribution, not just the ﬁltering distributions. We then discarded the
sample histories x.i/
0Wk 1 and only kept the current states x.i/
k , because we
were interested in the ﬁltering distributions. But we can get an approxima-
tion to the smoothing distribution by keeping the full histories. To get the
smoothing solution from sequential importance resampling (SIR), we also
need to resample the state histories, not only the current states, to prevent
the resampling from breaking the state histories. The resulting algorithm is
the following.
Algorithm 15.1 (SIR particle smoother). The direct sequential importance
resampling (SIR)-based smoother algorithm is the following.
308

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15.1 SIR Particle Smoother
309
 Draw N samples x.i/
0 from the prior:
x.i/
0  p.x0/;
i D 1; : : : ; N;
(15.1)
and set w.i/
0
D 1=N, for all i D 1; : : : ; N . Initialize the state histories
to contain the prior samples x.i/
0 .
 For each k D 1; : : : ; T do the following:
1. Draw N new samples x.i/
k from the importance distributions:
x.i/
k  .xk j x.i/
k 1; y1Wk/;
i D 1; : : : ; N;
(15.2)
where x.i/
k 1 is the k   1th (last) element in the sample history x.i/
0Wk 1.
2. Calculate the new weights according to
w.i/
k
/ w.i/
k 1
p.yk j x.i/
k / p.x.i/
k j x.i/
k 1/
.x.i/
k j x.i/
k 1; y1Wk/
;
(15.3)
and normalize them to sum to unity.
3. Append the samples to the state histories:
x.i/
0Wk D .x.i/
0Wk 1; x.i/
k /:
(15.4)
4. If the effective number of particles (11.31) is too low, perform resam-
pling on the state histories.
The approximation to the full posterior (smoothed) distribution is (Kita-
gawa, 1996; Doucet et al., 2000)
p.x0WT j y1WT / 
N
X
iD1
w.i/
T ı.x0WT   x.i/
0WT /:
(15.5)
The approximation to the smoothed posterior distribution at time step k,
given the measurements up to time step T > k, is
p.xk j y1WT / 
N
X
iD1
w.i/
T ı.xk   x.i/
k /;
(15.6)
where x.i/
k
is the kth component in x.i/
0WT . However, if T  k, the direct
SIR smoother algorithm is known to produce degenerate approximations
(Kitagawa, 1996; Doucet et al., 2000).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
310
Particle Smoothing
15.2 Backward-Simulation Particle Smoother
A less degenerate particle smoother than the SIR particle smoother can
be obtained by reusing the ﬁltering results instead of simply storing the
full particle histories in SIR. The backward-simulation particle smoother
(BS-PS, Godsill et al., 2004; Lindsten and Sch¨on, 2013), also called the
forward-ﬁltering backward-sampling (FFBS) smoother, is based on simu-
lation of individual trajectories backward, starting from the last step and
proceeding to the ﬁrst. The algorithm is the following.
Algorithm 15.2 (Backward-simulation particle smoother). Given the
weighted set of particles fw.i/
k ; x.i/
k
W
i D 1; : : : ; N; k D 1; : : : ; T g
representing the ﬁltering distributions:
 Choose QxT D x.i/
T with probability w.i/
T .
 For k D T   1; : : : ; 0:
1. Compute new weights by
w.i/
kjkC1 / w.i/
k p.QxkC1 j x.i/
k /:
(15.7)
2. Choose Qxk D x.i/
k with probability w.i/
kjkC1.
Derivation
Assume that we have already simulated a trajectory QxkC1WT
from the smoothing distribution. By using Equation (12.3) we get
p.xk j QxkC1; y1WT / D p.QxkC1 j xk/ p.xk j y1Wk/
p.QxkC1 j y1Wk/
D Z p.QxkC1 j xk/ p.xk j y1Wk/;
(15.8)
where Z is a normalization constant. By substituting the SIR ﬁlter approx-
imation in Equation (11.35) we get
p.xk j QxkC1; y1WT /  Z
X
i
w.i/
k p.QxkC1 j xk/ ı.xk   x.i/
k /:
(15.9)
We can now draw a sample from this distribution by sampling x.i/
k
with
probability / w.i/
k p.QxkC1 j x.i/
k /.
Given S iterations of Algorithm 15.2, resulting in sample trajectories
Qx.j/
0WT for j D 1; : : : ; S, the smoothing distribution can now be approxi-
mated as
p.x0WT j y1WT /  1
S
X
j
ı.x0WT   Qx.j /
0WT /:
(15.10)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15.2 Backward-Simulation Particle Smoother
311
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
PS estimate
Figure 15.1 Simulated pendulum data, and the result of tracking
the pendulum described in Example 7.6 with the
backward-simulation particle smoother. The resulting RMSE is
0:04, which is similar to the Gaussian smoother errors. Recall that
the RMSE of the bootstrap ﬁlter was 0:10, and thus the smoother
reduces the error signiﬁcantly.
The marginal distribution samples for a step k can be obtained by extract-
ing the kth components from the above trajectories. The computational
complexity of the method is O.S T N /. However, the result is much less
degenerate than that of the particle smoother of Kitagawa (1996). Under
suitable conditions, it is also possible to reduce the number of computa-
tions to linear in the number of particles by implementing the backward
simulation using rejection sampling (see next section).
Example 15.3 (Pendulum tracking with BS-PS). The result of applying the
backward-simulation particle smoother with 100 samples (with a bootstrap
ﬁlter with 10,000 samples as the ﬁlter part) to the pendulum model in
Example 7.6 is shown in Figure 15.1. The RMSE error 0:04 is smaller
than the RMSE of the ERTSS, which was 0:06, but slightly higher than
that of the IERTSS, which was 0:03, while being similar to the errors of
Gaussian smoothers. As already concluded in Example 11.10, the use of
particle approximations is not really beneﬁcial in this particular model.
Example 15.4 (Cluttered pendulum tracking with BS-PS). The result of
applying the backward-simulation particle smoother with 100 samples

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
312
Particle Smoothing
1
2
3
4
Time t
-3
-2
-1
0
1
2
3
4
5
Pendulum angle x1,k
True angle
Measurements
PS estimate
GHRTSS estimate
Figure 15.2 Smoothing results for cluttered pendulum tracking
with particle smoother and GHRTSS. The RMSE errors of the
methods were 0:05 and 0:83, respectively.
(with a bootstrap ﬁlter with 10,000 samples as the ﬁlter part) to the
cluttered pendulum model in Example 11.11 is shown in Figure 15.2.
The RMSE error of the particle smoother was 0:05, while the RMSE of
the particle ﬁlter was 0:20. The RMSE of a GHRTSS without a clutter
model in this case was 0:83. Thus in this case the particle smoother
gives a signiﬁcant improvement over the Gaussian approximation-based
smoothers.
15.3 Backward-Simulation with Rejection Sampling
A challenge in the backward-simulation-based smoother introduced in the
previous section is that generating S D N smoothed trajectories from a
particle ﬁlter result with N particles requires a computational complex-
ity of O.T N 2/, where the quadratic dependence on N can be prohibitive
when N is large. The reason for this computational complexity is the nor-
malization of weights required for sampling x.i/
k
from the distribution /
w.i/
k p.QxkC1 j x.i/
k /. However, it is also possible to use rejection sampling
to avoid this computational complexity (Douc et al., 2011; Chopin and Pa-
paspiliopoulos, 2020).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15.3 Backward-Simulation with Rejection Sampling
313
Rejection sampling (see, e.g., Luengo et al., 2020) is a method of draw-
ing samples from a distribution p.x/ by using proposals from another dis-
tribution q.x/ that is selected such that p.x/  M q.x/ for some constant
M. The algorithm is as follows.
Algorithm 15.5 (Rejection sampling). The rejection sampling algorithm
has the following steps:
 Repeat the following until a candidate is accepted:
– Draw a candidate x0  q.x0/ and u  U.0; 1/.
– If
u 
p.x0/
M q.x0/;
(15.11)
accept the candidate x0, otherwise continue with the loop.
 The value x D x0 is now a sample from the distribution p.x/.
We can now use the above algorithm to sample from the following dis-
tribution, which is the one we sample from in the backward-simulation
particle smoothers:
p.i/ D
w.i/
k p.QxkC1 j x.i/
k /
P
j w.j/
k
p.QxkC1 j x.j /
k /
D 1
Zp
w.i/
k p.QxkC1 j x.i/
k /;
(15.12)
where Zp D P
j w.j/
k
p.QxkC1 j x.j /
k /. We can use rejection sampling for it
provided that there exists a function C.xk/ such that
p.QxkC1 j xk/  C.xk/:
(15.13)
What now follows is that if we use the proposal distribution
q.i/ D
w.i/
k C.x.i/
k /
P
j w.j/
k
C.x.j /
k /
D 1
Zq
w.i/
k C.x.i/
k /;
(15.14)
where Zq D P
j w.j/
k
C.x.j/
k /, then we have:
p.i/ D 1
Zp
w.i/
k p.QxkC1 j x.i/
k /  1
Zp
w.i/
k C.x.i/
k / D Zq
Zp
q.i/; (15.15)
where the constant for rejection sampling is thus M D Zq=Zp. The ratio
needed in the rejection sampling then simpliﬁes to:
p.i/
.Zq=Zp/ q.i/ D p.QxkC1 j x.i/
k /
C.x.i/
k /
:
(15.16)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
314
Particle Smoothing
We get the following algorithm.
Algorithm 15.6 (Backward-simulation particle smoother with rejec-
tion sampling). Given the weighted set of particles fw.i/
k ; x.i/
k
W i D
1; : : : ; N; k D 1; : : : ; T g representing the ﬁltering distributions and a
function C.xk/ such that p.QxkC1 j xk/  C.xk/:
 Choose QxT D x.i/
T with probabilities given by the weights w.i/
T .
 For k D T   1; : : : ; 0:
1. While sample not accepted:
(a) Draw proposal index i from distribution q.i/ / w.i/
k C.x.i/
k /.
(b) Draw u  U.0; 1/, and accept x.i/
k if u 
p.QxkC1jx.i/
k /
C.x.i/
k /
.
2. Choose Qxk D x.i/
k .
In practice, to obtain an algorithm with complexity close to O.TN / for
obtaining N trajectories from the smoothing distribution, we need to sam-
ple them jointly, not one-by-one as the above simple algorithm description
implies. For more details, please see Douc et al. (2011) and Chopin and
Papaspiliopoulos (2020).
One practical challenge with Algorithm 15.6 is that the acceptance prob-
abilities for some particles can be very low, which can cause the run-time
of the algorithm to be extremely long. For that reason, Taghavi et al. (2013)
propose a hybrid strategy which falls back to the backward-simulation par-
ticle smoother when the rejection sampling step takes too long.
15.4 Reweighting Particle Smoother
The reweighting particle smoother of H¨urzeler and Kunsch (1998) and
Doucet et al. (2000), which is also called the marginal particle smoother,
is based on computing new weights for the SIR ﬁltering particles such that
we get an approximation to the marginal smoothing distribution.
Algorithm 15.7 (Reweighting particle smoother). Given the weighted set
of particles fw.i/
k ; x.i/
k
W i D 1; : : : ; N g representing the ﬁltering distribu-
tion, we can form approximations to the marginal smoothing distributions
as follows.
 Start by setting w.i/
T jT D w.i/
T for i D 1; : : : ; N .

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15.4 Reweighting Particle Smoother
315
 For each k D T   1; : : : ; 0, compute new weights by
w.i/
kjT D
X
j
w.j/
kC1jT
w.i/
k p.x.j /
kC1 j x.i/
k /
hP
l w.l/
k p.x.j /
kC1 j x.l/
k /
i:
(15.17)
At each step k, the marginal smoothing distribution can be approximated
as
p.xk j y1WT / 
X
i
w.i/
kjT ı.xk   x.i/
k /:
(15.18)
Derivation
Assume that we have already computed the weights for the
following approximation, where the particles x.i/
kC1 are from the SIR ﬁlter:
p.xkC1 j y1WT / 
X
i
w.i/
kC1jT ı.xkC1   x.i/
kC1/:
(15.19)
The integral in the second of Equations (12.2) can be now approximated as
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/
dxkC1

Z
p.xkC1 j xk/
p.xkC1 j y1Wk/
X
i
h
w.i/
kC1jT ı.xkC1   x.i/
kC1/
i
dxkC1
D
X
i
w.i/
kC1jT
p.x.i/
kC1 j xk/
p.x.i/
kC1 j y1Wk/
:
(15.20)
By using SIR ﬁlter approximation in Equation (11.35), we get the follow-
ing approximation for the predicted distribution in the denominator:
p.xkC1 j y1Wk/ 
X
j
w.j /
k
p.xkC1 j x.j /
k /;
(15.21)
which gives
Z p.xkC1 j y1WT / p.xkC1 j xk/
p.xkC1 j y1Wk/
dxkC1

X
i
w.i/
kC1jT
p.x.i/
kC1 j xk/
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i:
(15.22)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
316
Particle Smoothing
By substituting the SIR ﬁlter approximation and the approximation above
into the Bayesian optimal smoothing equation, we get
p.xk j y1WT /
D p.xk j y1Wk/
Z p.xkC1 j xk/ p.xkC1 j y1WT /
p.xkC1 j y1Wk/

dxkC1

X
l
w.l/
k ı.xk   x.l/
k /
X
i
w.i/
kC1jT
p.x.i/
kC1 j x.l/
k /
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i;
(15.23)
where we can identify the weights as
w.l/
kjT D
X
i
w.i/
kC1jT
w.l/
k p.x.i/
kC1 j x.l/
k /
hP
j w.j /
k
p.x.i/
kC1 j x.j /
k /
i:
(15.24)
The computational complexity of the method is O.T N 2/, that is, the
same as of the backward-simulation smoother with S D N simulated
trajectories.
15.5 Rao–Blackwellized Particle Smoothers
Rao–Blackwellized particle smoothers (RBPS) can be used for computing
approximate smoothing solutions to the conditionally Gaussian models de-
ﬁned in Equation (11.50). A simple way to implement an RBPS is to store
the histories instead of the single states in the RBPF, as in the case of the
SIR particle smoother (Algorithm 15.1). The corresponding histories of the
means and the covariances are then conditional on the latent variable his-
tories u0WT . However, the means and covariances at time step k are only
conditional on the measurement histories up to k, not on the later measure-
ments. In order to correct this, RTS smoothers have to be applied to each
history of the means and the covariances.
Algorithm 15.8 (Rao–Blackwellized SIR particle smoother). A set of
weighted samples fws;.i/
T
; us;.i/
0WT ; ms;.i/
0WT ; P s;.i/
0WT
W i D 1; : : : ; N g representing
the smoothed distribution can be computed as follows.
1. Compute the weighted set of Rao–Blackwellized state histories
fw.i/
T ; u.i/
0WT ; m.i/
0WT ; P .i/
0WT W i D 1; : : : ; N g
(15.25)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
15.5 Rao–Blackwellized Particle Smoothers
317
by storing histories in the Rao–Blackwellized particle ﬁlter analogously
to the SIR particle smoother in Algorithm 15.1.
2. Set
ws;.i/
T
D w.i/
T ;
us;.i/
0WT D u.i/
0WT :
(15.26)
3. Apply the RTS smoother to each of the mean and covariance histories
m.i/
0WT ; P .i/
0WT for i D 1; : : : ; N to produce the smoothed mean and co-
variance histories ms;.i/
0WT ; P s;.i/
0WT .
The Rao–Blackwellized particle smoother in this simple form also has
the same disadvantage as the SIR particle smoother, that is, the smoothed
estimate of uk can be quite degenerate if T  k. Fortunately, the smoothed
estimates of the actual states xk can still be relatively good, because their
degeneracy is avoided by the Rao–Blackwellization.
To avoid the degeneracy in estimates of uk, it is possible to use
better sampling procedures for generating samples from the smoothing
distributions analogously to the plain particle smoothing. The backward-
simulation has indeed been generalized to the Rao–Blackwellized case, but
the implementation of the Rao–Blackwellized reweighting smoother seems
to be quite problematic. The Rao–Blackwellized backward-simulation
smoother (see S¨arkk¨a et al., 2012a; Lindsten et al., 2016) can be used
for drawing backward trajectories from the marginal posterior of the
latent variables uk, and the posterior of the conditionally Gaussian part
is obtained via Kalman ﬁltering and RTS smoothing. Another option is
to simulate backward trajectories from the joint distribution of .xk; uk/
(Fong et al., 2002; Lindsten, 2011). However, this approach does not
really lead to Rao–Blackwellized estimates of the smoothing distribution,
because the Gaussian part of the state is sampled as well.
It is also possible to construct approximate Rao–Blackwellized
backward-simulation smoothers by using Kim’s approximation (cf. Kim,
1994; Barber, 2006; S¨arkk¨a et al., 2012a)
Z
p.uk j ukC1; xkC1; y1Wk/ p.xkC1 j ukC1; y1WT / dxkC1
' p.uk j ukC1; y1Wk/:
(15.27)
The result is an algorithm where we ﬁrst apply the backward-simulation
smoother in the Algorithm 15.2 to the marginal samples of uk alone, that
is, we simply use p.ukC1 j uk/ instead of p.xkC1 j xk/ in the algo-
rithm. Given a trajectory of the non-Gaussian variable, the linear Gaussian

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
318
Particle Smoothing
part may be recovered with a Kalman ﬁlter and RTS smoother. However,
this procedure is only an approximation and does not lead to a true Rao–
Blackwellized Monte Carlo representation of the smoothing distribution.
15.6 Exercises
15.1
Implement the backward-simulation particle smoother for the model in Exer-
cise 7.1, and compare its performance to the Gaussian approximation-based
smoothers.
15.2
Implement the backward-simulation particle smoother with rejection sam-
pling for the model in Exercise 7.1, and compare its performance to the
other smoothers.
15.3
Implement the reweighting smoother for the model in Exercise 7.1 and com-
pare its performance to the other smoothers.
15.4
Show that the latent variable sequence in conditionally Gaussian models is
not Markovian in general in the sense that
p.uk j ukC1; y1WT / ¤ p.uk j ukC1; y1Wk/
(15.28)
when T > k, and thus simple backward smoothing in uk does not lead to
the correct result.
15.5
Implement the Rao–Blackwellized SIR particle smoother for the clutter
model in Exercise 11.9.
15.6
Let’s again consider the clutter model in Exercise 11.9. Assume that you
have implemented the ﬁlter as a Rao–Blackwellized particle ﬁlter with re-
sampling at every step (thus the weights are all equal). Write down the al-
gorithm for Kim’s approximation-based backward simulation smoother for
the model. What peculiar property does the smoother have? Does this have
something to do with the property in Equation (15.28)?

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16
Parameter Estimation
In the previous chapters we have assumed that the parameters of the state
space model are known, and only the state needs to be estimated. However,
in practical models, the parameters are unknown as well. In this chap-
ter we concentrate on three types of method for parameter estimation:
optimization-based methods for computing maximum a posteriori (MAP)
or maximum likelihood (ML) estimates, expectation-maximization (EM)
algorithms for computing the MAP or ML estimates, and Markov chain
Monte Carlo (MCMC) methods for generating Monte Carlo approxima-
tions of the posterior distributions. We also show how Kalman ﬁlters and
RTS smoothers, Gaussian ﬁlters and smoothers, and particle ﬁlters and
smoothers can be used for approximating the marginal likelihoods, param-
eter posteriors, and other quantities needed by the methods.
16.1 Bayesian Estimation of Parameters in State Space Models
The Bayesian way of treating unknown parameters  2 Rd is to model
them as random variables with a certain prior distribution p./. A state
space model with unknown parameters can be written in the form
  p./;
x0  p.x0 j /;
xk  p.xk j xk 1; /;
yk  p.yk j xk; /:
(16.1)
A straightforward way to proceed would now be to form the full posterior
distribution via Bayes’ rule:
p.x0WT ;  j y1WT / D p.y1WT j x0WT ; / p.x0WT j / p./
p.y1WT /
;
(16.2)
319

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
320
Parameter Estimation
where the terms p.x0WT j / and p.y1WT j x0WT ; / can be computed as
p.x0WT j / D p.x0 j /
TY
kD1
p.xk j xk 1; /;
p.y1WT j x0WT ; / D
TY
kD1
p.yk j xk; /:
If we are only interested in the parameters , the proper Bayesian way
to proceed is to integrate the states out, which gives the marginal posterior
of parameters:
p. j y1WT / D
Z
p.x0WT ;  j y1WT / dx0WT :
(16.3)
Unfortunately, computation of this high-dimensional integral is hard and
becomes even harder as we obtain more measurements. In this approach
we encounter the same computational problem as was discussed in Sec-
tions 1.3 and 6.1, which led us to consider optimal ﬁltering and smoothing
instead of the straightforward Bayesian approach. Thus it is again advanta-
geous to look at recursive, ﬁltering, and smoothing kinds of solutions.
In this chapter we present methods for parameter estimation that are
based on approximating the marginal posterior distribution
p. j y1WT / / p.y1WT j / p./;
(16.4)
without explicitly forming the joint posterior distribution of the states and
parameters as in Equation (16.2). Instead, we present recursive algorithms
for direct computation of the above distribution. For linear state space mod-
els, this can be done exactly, and in non-linear and non-Gaussian models
we can use Gaussian ﬁltering or particle ﬁltering-based approximations.
Once we know how to evaluate the above distribution, we can estimate the
parameters, for example, by ﬁnding their maximum a posteriori (MAP) es-
timate or by sampling from the posterior by Markov chain Monte Carlo
(MCMC) methods. If direct evaluation of the distribution is not feasible,
we can use the expectation-maximization (EM) algorithm to iteratively ﬁnd
the ML or MAP estimate.
16.1.1 Parameter Posterior and Energy Function
The difﬁcult part in Equation (16.4) is the evaluation of the marginal like-
lihood p.y1WT j /. The prior distribution can usually be selected such that

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.1 Bayesian Estimation of Parameters in State Space Models 321
it is easy to evaluate. Although evaluation of the normalization constant
for the posterior distribution is a difﬁcult problem, its evaluation is usually
avoided by Bayesian computational methods, and thus we do not need to
worry about it.
The key to recursive computation of the parameter posterior in state
space models is the following factorization (often called prediction error
decomposition):
p.y1WT j / D
TY
kD1
p.yk j y1Wk 1; /;
(16.5)
where we have denoted p.y1 j y1W0; / , p.y1 j / for notational conve-
nience. Because each of the terms in the above product can be computed
recursively, the whole marginal likelihood can be computed recursively as
follows.
Theorem 16.1 (Recursion for marginal likelihood of parameters). The
marginal likelihood of parameters is given by Equation (16.5), where the
terms in the product can be computed recursively as
p.yk j y1Wk 1; / D
Z
p.yk j xk; / p.xk j y1Wk 1; / dxk;
(16.6)
where p.yk j xk; / is the measurement model, and p.xk j y1Wk 1; / is
the predictive distribution of the state, which obeys the recursion
p.xk j y1Wk 1; / D
Z
p.xk j xk 1; / p.xk 1 j y1Wk 1; / dxk 1;
p.xk j y1Wk; / D p.yk j xk; / p.xk j y1Wk 1; /
p.yk j y1Wk 1; /
:
(16.7)
Note that the latter equations are just the Bayesian ﬁltering Equa-
tions (6.11) and (6.12), where we have explicitly written down the
parameter dependence.
Proof
Due to the conditional independence of the measurements (Prop-
erty 6.3), we have
p.yk; xk j y1Wk 1; / D p.yk j xk; y1Wk 1; / p.xk j y1Wk 1; /
D p.yk j xk; / p.xk j y1Wk 1; /:
(16.8)
Integrating over xk gives Equation (16.6).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
322
Parameter Estimation
The marginal likelihood obtained via Theorem 16.1 can then be sub-
stituted into Equation (16.4) to give the marginal posterior distribution of
the parameters. However, instead of working with marginal likelihood or
marginal posterior explicitly, in parameter estimation it is often convenient
to deﬁne the unnormalized negative log-posterior or energy function as fol-
lows.
Deﬁnition 16.2 (Energy function).
'T ./ D   log p.y1WT j /   log p./:
(16.9)
Remark 16.3. The deﬁnition of energy function thus implies
p. j y1WT / / exp. 'T .//:
(16.10)
The energy function can be seen to obey the following simple recursion.
Theorem 16.4 (Recursion for energy function). The energy function de-
ﬁned in Equation (16.9) can be evaluated recursively as follows.
 Start from '0./ D   log p./.
 At each step k D 1; 2; : : : ; T , compute the following:
'k./ D 'k 1./   log p.yk j y1Wk 1; /;
(16.11)
where the terms p.yk j y1Wk 1; / can be computed recursively by The-
orem 16.1.
Proof
The result follows from substituting Equation (16.5) into the deﬁ-
nition of the energy function in Equation (16.9) and identifying the terms
corresponding to 'k 1./.
16.2 Computational Methods for Parameter Estimation
In this section we brieﬂy go through the underlying ideas in ML- and MAP-
based parameter estimation and implementation by direct optimization and
by the EM algorithm, as well as the basics of Markov chain Monte Carlo
(MCMC) methods. There exist many other parameter estimation methods
for state space models and for more general statistical models, but here we
concentrate on these, because these approaches are the most widely used
(probabilistic methods) in the state space context.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.2 Computational Methods for Parameter Estimation
323
16.2.1 Maximum A Posteriori and Laplace Approximations
The maximum a posteriori (MAP) estimate is obtained by determining the
location of the maximum of the posterior distribution and using it as the
point estimate:
OMAP D arg max

Œp. j y1WT / :
(16.12)
The MAP estimate can be equivalently computed as the minimum of the
error function deﬁned in Equation (16.9):
OMAP D arg min
 Œ'T ./ ;
(16.13)
which is usually numerically more stable and easier to compute. The max-
imum likelihood (ML) estimate of the parameter is a MAP estimate with a
formally uniform prior p./ / 1.
The minimum of the energy function can be computed by using various
gradient-free or gradient-based general optimization algorithms (see, e.g.,
Luenberger and Ye, 2008). However, to be able to use gradient-based opti-
mization, we will need to evaluate the derivatives of the energy function as
well. It is possible to ﬁnd the derivatives in basically two ways (see, e.g.,
Capp´e et al., 2005).
1. By formally differentiating the energy function recursion equations for a
particular method. This results in so-called sensitivity equations, which
can be implemented as additional recursion equations computed along
with the ﬁltering.
2. Using Fisher’s identity, which expresses the gradient of the energy func-
tion as an expectation of the derivative of the complete data log likeli-
hood over the smoothing distribution. The advantage of this approach
over direct differentiation is that there is no need for an additional re-
cursion.
The disadvantage of the MAP estimate is that it essentially approximates
the posterior distribution with the Dirac delta function
p. j y1WT / ' ı.   OMAP/
(16.14)
and thus ignores the spread of the distribution completely.
It is also possible to use a Laplace approximation (Gelman et al., 2013),
which uses the second derivative (Hessian) of the energy function to form
a Gaussian approximation to the posterior distribution:
p. j y1WT / ' N. j OMAP; ŒH. OMAP/ 1/;
(16.15)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
324
Parameter Estimation
where H. OMAP/ is the Hessian matrix evaluated at the MAP estimate. How-
ever, to implement the Laplace approximation, we need to have a method
to compute (or approximate) the second order derivatives of the energy
function.
16.2.2 Parameter Inference via Markov Chain Monte Carlo
Markov chain Monte Carlo (MCMC) methods (see, e.g., Liu, 2001; Brooks
et al., 2011) are a class of algorithms for drawing random variables from a
given distribution by simulating a Markov chain that has the desired distri-
bution as its stationary distribution. The methods are particularly suited for
simulating samples from Bayesian posterior distributions p. j y1WT /, be-
cause to implement the methods, we only need to know the unnormalized
posterior distribution Qp. j y1WT / D p.y1WT j / p./ or equivalently the
energy function in Equation (16.9), and knowledge of the normalization
constant of the posterior distribution is not required. The usage of MCMC
methods in the state space context has been discussed, for example, by
Ninness and Henriksen (2010) and Andrieu et al. (2010).
The Metropolis–Hastings (MH) algorithm is the most common type of
MCMC method. MH uses a proposal density q..i/ j .i 1// for suggest-
ing new samples .i/ given the previous ones .i 1/. The algorithm is the
following.
Algorithm 16.5 (Metropolis–Hastings). The Metropolis–Hastings (MH)
algorithm consists of the following steps.
 Draw the starting point .0/ from an arbitrary initial distribution.
 For i D 1; 2; : : : ; N, do
1. Sample a candidate point  from the proposal distribution:
  q. j .i 1//:
(16.16)
2. Evaluate the acceptance probability
˛i D min

1; exp.'T ..i 1//   'T .// q..i 1/ j /
q. j .i 1//

: (16.17)
3. Generate a uniform random variable u  U.0; 1/ and set
.i/ D
(
;
if u  ˛i;
.i 1/;
otherwise:
(16.18)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.2 Computational Methods for Parameter Estimation
325
The Metropolis algorithm is a commonly used special case of
Metropolis–Hastings, where the proposal distribution is symmetric,
q..i 1/ j .i// D q..i/ j .i 1//. In this case the acceptance probability
reduces to
˛i D min
n
1; exp.'T ..i 1//   'T .//
o
:
(16.19)
The choice of the proposal distribution is crucial for performance of the
Metropolis–Hastings method, and ﬁnding a good one is a hard task (see,
e.g., Liu, 2001; Brooks et al., 2011). Some choices will lead to Metropolis–
Hastings methods where the samples are highly correlated, whereas with
some choices the rejection rate becomes too high.
One commonly used choice is to use a Gaussian distribution as the pro-
posal distribution,
q..i/ j .i 1// D N..i/ j .i 1/; †i 1/;
(16.20)
where †i 1 is some suitable covariance matrix. The resulting algorithm
is called the random walk Metropolis algorithm, because the transition
distribution above deﬁnes a Gaussian random walk in parameter space.
With this selection of proposal distribution, the challenge is now to ﬁnd a
suitable covariance matrix for the random walk.
One approach to the problem of selection of the covariance matrix is
to use adaptive Markov chain Monte Carlo (AMCMC) methods where the
covariance of the Gaussian proposal in the Metropolis algorithm is auto-
matically adapted during the MCMC run (see, e.g., Haario et al., 1999,
2001; Andrieu and Thoms, 2008; Vihola, 2012). A typical idea in AM-
CMC methods is to use the covariance of the previously generated samples
as an estimate of the actual covariance of the posterior distribution. Given
the covariance, it is possible to compute the covariance of the proposal
distribution such that it causes an acceptance rate N˛ that is optimal in
some suitable sense. For the random walk Metropolis algorithm, the opti-
mal acceptance rate in certain ideal conditions is N˛ D 0:234 (Roberts and
Rosenthal, 2001).
For example, the robust adaptive Metropolis (RAM) algorithm of Vihola
(2012) is similar to the adaptive Metropolis (AM) algorithm of Haario et al.
(2001) except that the adaptation of the covariance †i is done in a slightly
different way. The algorithm is the following.
Algorithm 16.6 (RAM algorithm). The RAM algorithm consists of the
following steps.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
326
Parameter Estimation
1. Draw .0/ from an initial distribution p0./, and initialize S0 to be the
lower-triangular Cholesky factor of the initial covariance †0.
2. Sample a candidate point by  D i 1 C Si 1 ri, where ri  N.0; I/.
3. Compute the acceptance probability
˛i D min f1; exp .'T .i 1/   'T .//g :
(16.21)
4. Sample a uniform random variable u from the uniform distribution
U.0; 1/.
5. If u  ˛i, set .i/ D . Otherwise set .i/ D .i 1/.
6. Compute a lower-triangular matrix Si with positive diagonal elements
satisfying the equation
Si ST
i D Si 1

I C i .˛i   N˛/ ri rT
i
jjrijj2

ST
i 1;
(16.22)
where figi1  .0; 1 is an adaptation step size sequence decaying
to zero. Although any such sequence will do, Vihola (2012) suggests
i D i   with a suitable exponent  2 .1=2; 1.
7. Set i  i C 1, and go to step 2 until the desired number of samples has
been generated.
Instead of the random walk Metropolis algorithm with covariance adap-
tation it is also possible to use the gradient information in the construction
of the proposal distribution. This is the idea used in the Hamiltonian Monte
Carlo (HMC) or hybrid Monte Carlo (HMC) method (Duane et al., 1987;
Neal, 2011). In HMC, the proposal distribution is constructed by simulat-
ing a physical system consisting of particles moving under the inﬂuence
of a potential (the energy function) and heat bath. The gradient of the en-
ergy function enters the equations as the force caused by the potential. The
HMC method has been applied in the state space context by Mbalawata
et al. (2013).
Another commonly used MCMC method is Gibbs’ sampling (see, e.g.,
Liu, 2001; Brooks et al., 2011), which samples components of the param-
eters one at a time from their conditional distributions given the other pa-
rameters. The advantage of this method is that no rejections are needed: the
acceptance probability is identically one. However, in order to implement
the method it is necessary to be able to generate samples from the con-
ditional distributions of parameters, which is possible only in a restricted
class of models. For various other methods the reader is referred to Brooks
et al. (2011).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.2 Computational Methods for Parameter Estimation
327
16.2.3 Expectation Maximization
The expectation-maximization (EM) algorithm is a method to iteratively
ﬁnd an ML estimate of the parameters when direct optimization of the
posterior distribution (or equivalently, energy function) is not feasible.
The algorithm was originally introduced by Dempster et al. (1977), and
applications to state space models have been discussed, for example, in
Shumway and Stoffer (1982), Roweis and Ghahramani (2001), and Sch¨on
et al. (2011). Gaussian smoothing and sigma point-based approximations
in an EM context have also been discussed in V¨a¨an¨anen (2012) and
Kokkala et al. (2016). Although the EM algorithm was originally an
algorithm for computing ML estimates, it can also be easily modiﬁed for
computation of MAP estimates, as discussed below.
The EM algorithm is based on the result that even when we cannot
evaluate the marginal likelihood as such, we are still often able to compute
a lower bound for it as follows. Let q.x0WT / be an arbitrary probability
density over the states; then we have
log p.y1WT j /  F Œq.x0WT /; ;
(16.23)
where the functional F is deﬁned as
F Œq.x0WT /;  D
Z
q.x0WT / log p.x0WT ; y1WT j /
q.x0WT /
dx0WT :
(16.24)
The key idea behind the EM algorithm is that it is possible to maximize
the left-hand side of Equation (16.23) by iteratively maximizing the lower
bound F Œq.x0WT /; . A simple way to do that is the following iteration
(Neal and Hinton, 1999).
Algorithm 16.7 (Abstract EM). The maximization of the lower bound in
Equation (16.24) can be done by coordinate ascent as follows.
 Start from initial guesses q.0/, .0/.
 For n D 0; 1; 2; : : : do the following steps:
1. E-step: Find q.nC1/ D arg maxq F Œq; .n/.
2. M-step: Find .nC1/ D arg max F Œq.nC1/; .
In order to implement the EM algorithm, we need to be able to do the
above maximizations in practice. Fortunately, it can be shown (see, e.g.,
Neal and Hinton, 1999) that the result of the maximization at the E-step is
q.nC1/.x0WT / D p.x0WT j y1WT ; .n//:
(16.25)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
328
Parameter Estimation
Plugging this into the expression of F Œq.nC1/.x0WT /;  gives
F Œq.nC1/.x0WT /; 
D
Z
p.x0WT j y1WT ; .n// log p.x0WT ; y1WT j / dx0WT
 Z
p.x0WT j y1WT ; .n// log p.x0WT j y1WT ; .n// dx0WT :
(16.26)
Because the latter term does not depend on , maximizing F Œq.nC1/;  is
equivalent to maximizing the ﬁrst term above, which in the EM context is
commonly denoted as
Q.; .n// D
Z
p.x0WT j y1WT ; .n// log p.x0WT ; y1WT j / dx0WT ;
(16.27)
which is thus the expectation of the logarithm of the complete data likeli-
hood p.x0WT ; y1WT j / over the full joint posterior of the states given the
parameters .n/. The resulting algorithm is the following.
Algorithm 16.8 (EM algorithm). The EM algorithm consists of the follow-
ing steps.
 Start from an initial guess .0/.
 For n D 0; 1; 2; : : : do the following steps:
1. E-step: compute Q.; .n//.
2. M-step: compute .nC1/ D arg max Q.; .n//.
Due to the Markovian structure of the state space model in Equation
(16.1), the complete data log-likelihood has the form
log p.x0WT ; y1WT j /
D log p.x0 j / C
T
X
kD1
log p.xk j xk 1; / C
T
X
kD1
log p.yk j xk; /:
(16.28)
The expression for Q in Equation (16.27) and thus the E-step in Algo-
rithm 16.8 now reduces to computation of (see Sch¨on et al., 2011)
Q.; .n// D I1.; .n// C I2.; .n// C I3.; .n//;
(16.29)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.2 Computational Methods for Parameter Estimation
329
where
I1.; .n// D
Z
p.x0 j y1WT ; .n// log p.x0 j / dx0;
I2.; .n// D
T
X
kD1
Z
p.xk; xk 1 j y1WT ; .n//
 log p.xk j xk 1; / dxk dxk 1;
I3.; .n// D
T
X
kD1
Z
p.xk j y1WT ; .n// log p.yk j xk; / dxk:
(16.30)
The above expectations are over the smoothing distribution, and the key
thing to observe is that we do not need to compute expectations over the
full posterior, but only over the smoothing distributions p.xk j y1WT ; .n//
and pairwise smoothing distributions p.xk; xk 1 j y1WT ; .n//. It turns out
that the required expectations can be easily (approximately) evaluated us-
ing smoother results. In the case of linear state space models, we can ﬁnd
a closed form expression for the above integrals in terms of RTS smoother
results. In the non-linear case, we can approximate the integrals by us-
ing non-linear smoothers such as Gaussian smoothers. In the more general
probabilistic state space model, we can use particle smoothers to approxi-
mate them.
On the E-step of Algorithm 16.8, we need to maximize the expression
for Q in Equation (16.29) with respect to the parameters . In principle, we
can utilize various gradient-free and gradient-based optimization methods
(see, e.g., Luenberger and Ye, 2008) for doing that, but the most useful
case occurs when we can do the maximization analytically via setting the
gradient to zero:
@Q.; .n//
@
D 0:
(16.31)
This happens, for example, when estimating the parameters of linear state
space models and in certain classes of non-linear state space models.
It turns out that we can calculate MAP estimates using the EM algorithm
by replacing p.x0WT ; y1WT j / in Equation (16.27) with p.x0WT ; y1WT ; /.
In practice, this can be implemented by maximizing Q.; .n//Clog p./
at the M-step instead of the plain Q.
As a side product of the EM formulation above, we also get a method
to compute the gradient of the energy function needed in gradient-based
optimization for ﬁnding the MAP or ML estimates. Fisher’s identity (see,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
330
Parameter Estimation
e.g., Capp´e et al., 2005) states that if we evaluate the gradient of Q at
.n/ D , we get exactly the gradient of the marginal log-likelihood. This
implies that the gradient of the energy function can be evaluated as
@'T ./
@
D  @ log p./
@
  @Q.; .n//
@
ˇˇˇˇ
.n/D
:
(16.32)
Note that here we refer to the above identity as Fisher’s identity although
the original identity is the relationship with the log marginal likelihood and
Q, not with the log posterior and Q. In any case this identity is useful in lin-
ear state space models, because it is often easier to compute and computa-
tionally lighter (Segal and Weinstein, 1989; Olsson et al., 2007). However,
in non-linear state space models it is not as useful, because the approxi-
mations involved in computation of the ﬁltering and smoothing solutions
often cause the gradient to have different approximations from the energy
function approximation implied by the same method. That is, the gradient
approximation computed with Fisher’s identity and Gaussian smoothing
might not exactly match the gradient of the energy function approximation
computed with the corresponding Gaussian ﬁlter. However, in the case of
particle ﬁlters, Fisher’s identity provides a feasible way to approximate the
gradient of the energy function.
16.3 Practical Parameter Estimation in State Space Models
In this section we discuss practical parameter estimation methods for state
space models using linear Kalman ﬁlters and RTS smoothers, Gaussian
approximation-based non-linear Kalman ﬁlters and RTS smoothers, and
particle ﬁlters and smoothers. But before going to them, we outline the
simple but sometimes effective state augmentation approach.
16.3.1 State Augmentation Approach
Before going to more elaborate parameter estimation methods for state
space models, we recall that already in Chapter 3 we used the Kalman
ﬁlter for estimating static parameters in a regression model. The same ap-
proach can be generalized to the state augmentation approach, which sim-
ply means that we augment the parameter as part of the state. For example,
let us say that we have a non-linear model with unknown parameters :
xk D f.xk 1; / C qk 1;
yk D h.xk; / C rk:
(16.33)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
331
We can now rewrite the model as
k D k 1;
xk D f.xk 1; k 1/ C qk 1;
yk D h.xk; k/ C rk;
(16.34)
where the dynamic model for the parameter essentially says that it is con-
stant. If we now redeﬁne the state as Qxk D .xk; k/, we get a state space
model of the form
Qxk D Qf.Qxk 1/ C Qqk 1;
yk D h.Qxk/ C rk;
(16.35)
which does not contain any unknown parameter anymore. The problem
in this state augmentation is the singularity of the dynamic model for the
parameter. It works well when the whole system is linear and we do not
have any approximation errors in the estimator. If the parameters appear
linearly in the system, it sometimes is a good idea to include the parameters
as part of the state. However, this can also fail sometimes.
With approximate non-linear ﬁlters, the singularity of the parameter dy-
namic model indeed causes problems. With non-linear Kalman ﬁlters, the
Gaussian approximation tends to become singular, which causes the ﬁlter
to diverge. As discussed in Section 11.5, particle ﬁlters have a problem with
small amounts of noise in the dynamic model because this causes sample
impoverishment. As the noise in the dynamic model above is exactly zero,
this case is particularly problematic for particle ﬁlters.
A common way to circumvent the problem is to introduce artiﬁcial noise
to the dynamic model of the parameter, that is, replace k D k 1 with
k D k 1 C "k 1;
(16.36)
where "k 1 is a “small” noise process. But the problem is that we are
no longer solving the original parameter estimation problem but another
one with a time-varying parameter. Anyway, this approach is sometimes
applicable and should be considered before jumping into more complicated
parameter estimation methods.
There is also a form of Rao–Blackwellization that sometimes helps. This
approach is discussed in Section 16.3.6, and the idea is to use a closed form
solution for the static parameter (“Rao–Blackwellize” the parameter) and
sample only the original state part. This works if the parameter appears in
the model in a suitable conjugate form.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
332
Parameter Estimation
16.3.2 Parameter Estimation in Linear State Space Models
Consider the following linear Gaussian state space model with unknown
parameters :
xk D A./ xk 1 C qk 1;
yk D H./ xk C rk;
(16.37)
where qk 1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
In the above model, for notational convenience, we have assumed that the
model matrices do not explicitly depend on time. The energy function and
thus the marginal parameter posterior for the linear Gaussian model above
can be obtained as follows.
Theorem 16.9 (Energy function for linear Gaussian model). The recursion
for the energy function is given as
'k./ D 'k 1./ C 1
2 log j2 Sk./j C 1
2v T
k ./ S 1
k ./ vk./; (16.38)
where the terms vk./ and Sk./ are given by the Kalman ﬁlter with the
parameters ﬁxed to .
 Prediction:
m k ./ D A./ mk 1./;
P  k ./ D A./ Pk 1./ AT./ C Q./:
(16.39)
 Update:
vk./ D yk   H./ m k ./;
Sk./ D H./ P  k ./ HT./ C R./;
Kk./ D P  k ./ HT./ S 1
k ./;
mk./ D m k ./ C Kk./ vk./;
Pk./ D P  k ./   Kk./ Sk./ KT
k./:
(16.40)
Proof
The Kalman ﬁlter gives us the Gaussian predictive distribution
p.xk j y1Wk 1; / D N.xk j m k ./; P  k .//, which via Theorem 16.1
thus gives
p.yk j y1Wk 1; /
D
Z
N.yk j H./ xk; R.// N.xk j m k ./; P  k .// dxk
D N.yk j H./ m k ./; H./ P  k ./ HT./ C R.//:
(16.41)
The rest follows from Theorem 16.4.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
333
0
0.5
1
1.5
2
R
0
0.5
1
1.5
2
2.5
3
 p(R | y1:T )
Posterior distribution
True parameter value 
Figure 16.1 Posterior distribution of noise variance R in the
Gaussian random walk model (see Example 6.4).
Thus if we ﬁx  and run the above algorithm from '0./ D   log p./
at k D 0 to the step k D T , then the full energy function is 'T ./. That
is, the marginal posterior density at the point  can be evaluated up to a
normalization constant by Equation (16.10) as
p. j y1WT / / exp. 'T .//:
Given the energy function, it is now easy to implement, for example, a
Metropolis–Hastings-based MCMC sampler for generating a Monte Carlo
approximation of the posterior distribution or to use the energy function in
a gradient-free optimization for ﬁnding the ML or MAP estimates of the
parameters.
Example 16.10 (Parameter posterior for Gaussian random walk). The pos-
terior distribution of the noise variance p.R j y1WT / for the Gaussian ran-
dom walk model in Example 6.4 is shown in Figure 16.1. A formally uni-
form prior p.R/ / 1 was assumed. The true value used in the simulation is
indeed well within the high density area of the posterior distribution. How-
ever, it can also been seen that if we computed the MAP (or equivalently
ML) estimate of the parameter, we would get a smaller value than the true
one.
In order to implement a gradient-based optimization method, we need
to have the gradient of the energy function as well. One way to implement

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
334
Parameter Estimation
the gradient computation is by ﬁrst differentiating the energy function
expression in Theorem 16.9 term-by-term and then each of the Kalman
ﬁlter equations. This results in a recursion called sensitivity equations
(Gupta and Mehra, 1974; Capp´e et al., 2005), which can be evaluated
along with the Kalman ﬁltering computations. The equations are given in
Theorem A.10 in Section A.10. Another way to compute the gradient is
by using Fisher’s identity (16.32), but before going into that, let us take a
look at the EM algorithm for linear Gaussian models.
Recall that for implementing the EM algorithm we need to be able to
compute the expectations in Equations (16.30), which in terms requires the
knowledge of the smoothing distributions and pairwise smoothing distri-
butions. Fortunately, by Equations (12.5) and (12.12) we know that
p.xk j y1WT ; .n// D N.xk j ms
k; P s
k/;
p.xk; xk 1 j y1WT ; .n//
D N
 xk
xk 1
 ˇˇˇ
 ms
k
ms
k 1

;

P s
k
P s
k GT
k 1
Gk 1 P s
k
P s
k 1

;
(16.42)
where the means, covariances, and gains are computed with an RTS
smoother with the model parameters ﬁxed to .n/. Note that in the EM
algorithms appearing in the literature, the cross term P s
k GT
k 1 is some-
times computed with a separate recursion (see, e.g., Shumway and Stoffer,
1982), but in fact this is unnecessary due to the above. The required
expectations for EM in Equations (16.30) can now be computed in closed
form, and the result is the following (cf. Shumway and Stoffer, 1982).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
335
Theorem 16.11 (Evaluation of Q for linear Gaussian model). The expres-
sion for Q for the linear Gaussian model in Equation (16.37) can be writ-
ten as
Q.; .n//
D  1
2 log j2 P0./j   T
2 log j2 Q./j   T
2 log j2 R./j
  1
2 tr
(
P  1
0 ./
h
P s
0 C .ms
0   m0.// .ms
0   m0.//Ti)
  T
2 tr
(
Q 1./
h
†   C AT./   A./ CT C A./ ˆ AT./
i)
  T
2 tr
(
R 1./
h
D   B HT./   H./ BT C H./ † HT./
i)
;
(16.43)
where the following quantities are computed from the results of RTS
smoothers run with parameter values .n/:
† D 1
T
T
X
kD1
P s
k C ms
k Œms
kT;
ˆ D 1
T
T
X
kD1
P s
k 1 C ms
k 1 Œms
k 1T;
B D 1
T
T
X
kD1
yk Œms
kT;
C D 1
T
T
X
kD1
P s
k GT
k 1 C ms
k Œms
k 1T;
D D 1
T
T
X
kD1
yk yT
k:
(16.44)
The usefulness of the EM algorithm for linear state space models stems
from the fact that if the parameters are selected to be some of the full model
matrices (or initial mean), we can indeed perform the M-step of the EM
algorithm in closed form. The same thing happens if the parameters appear
linearly in one of the model matrices (e.g., are some subcomponents of the
matrices), but application of the EM algorithm to the estimation of the full
matrices is the classical result. By setting the gradients of @Q.; .n//=@

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
336
Parameter Estimation
to zero for each  D fA; H; Q; R; P0; m0g separately, we get the following
result.
Theorem 16.12 (Maximization of Q for linear model parameters). The
maximum  D arg max Q.; .n//, when the parameters are selected to
be one of the model parameters  2 fA; H; Q; R; P0; m0g, can be com-
puted as follows.
 When  D P0 we get
P 
0 D P s
0 C .ms
0   m0/ .ms
0   m0/T:
(16.45)
 When  D A we get
A D C ˆ 1:
(16.46)
 When  D Q we get
Q D †   C AT   A CT C A ˆ AT:
(16.47)
 When  D H we get
H D B † 1:
(16.48)
 When  D R we get
R D D   H BT   B HT C H † HT:
(16.49)
 Finally, the maximum with respect to the initial mean  D m0 is
m
0 D ms
0:
(16.50)
Obviously the above theorem can also be used for solving the maximum
of Q with respect to any subset of model matrices by solving the resulting
equations jointly. The EM algorithm for ﬁnding the maximum likelihood
estimates of the linear state space model parameters is now the following.
Algorithm 16.13 (EM algorithm for linear state space models). Let  con-
tain some subset of the model parameters fA; H; Q; R; P0; m0g. We can
ﬁnd maximum likelihood estimates of them via the following iteration.
 Start from some initial guess .0/.
 For n D 0; 1; 2; : : : do the following steps.
1. E-step: Run the RTS smoother using the current parameter values
in .n/, and compute the quantities in Equation (16.44) from the
smoother results.
2. M-step: Find new parameter values by using Equations (16.45) –
(16.50), and store them in .nC1/.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
337
The expression for Q.; .n// also provides an “easy gradient recipe”
(Olsson et al., 2007) for computation of the energy function gradient via
Fisher’s identity (Equation (16.32)), as it enables the computation of the
gradient without an additional recursion (sensitivity equations). The result-
ing expression is given in Theorem A.11 in Section A.10.
16.3.3 Parameter Estimation with Gaussian Filtering and
Smoothing
One way to implement parameter estimation in non-linear models is by
replacing the Kalman ﬁlters and RTS smoothers used in the linear case
with their non-linear counterparts. Let’s consider parameter estimation in
models of the form
xk D f.xk 1; / C qk 1;
yk D h.xk; / C rk;
(16.51)
where qk 1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
The energy function can now be approximated with the following Gaussian
ﬁltering-based algorithm.
Algorithm 16.14 (Gaussian ﬁltering-based energy function). The recur-
sion for the approximate energy function is
'k./ ' 'k 1./ C 1
2 log j2 Sk./j C 1
2v T
k ./ S 1
k ./ vk./; (16.52)
where the terms vk./ and Sk./ are given by the Gaussian ﬁlter with the
parameters ﬁxed to .
 Prediction:
m k ./ D
Z
f.xk 1; / N.xk 1 j mk 1./; Pk 1.// dxk 1;
P  k ./ D
Z
.f.xk 1; /   m k .// .f.xk 1; /   m k .//T
 N.xk 1 j mk 1./; Pk 1.// dxk 1 C Qk 1./:
(16.53)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
338
Parameter Estimation
 Update:
k./ D
Z
h.xk; / N.xk j m k ./; P  k .// dxk;
vk./ D yk   k./;
Sk./ D
Z
.h.xk; /   k.// .h.xk; /   k.//T
 N.xk j m k ./; P  k .// dxk C Rk./;
Ck./ D
Z
.xk   m k .// .h.xk; /   k.//T
 N.xk j m k ./; P  k .// dxk;
Kk./ D Ck./ S 1
k ./;
mk./ D m k ./ C Kk./ vk./;
Pk./ D P  k ./   Kk./ Sk./ KT
k./:
(16.54)
Derivation
This approximation can be derived in the same way as the
linear case in Theorem 16.9 except that Gaussian moment matching-based
approximations are used instead of the true Gaussian distributions.
The above energy function can now be directly used in MCMC sampling
or in gradient-free optimization algorithms for computing ML or MAP es-
timates. However, because the energy function is based on a Gaussian ap-
proximation, the implied posterior distribution is an approximation as well,
and thus the parameter estimates will be biased. The posterior distribution
approximation is also typically thinner than the true posterior distribution,
and thus the uncertainty in the parameter is underestimated. This issue is
illustrated in Example 16.17.
It is also possible to compute the derivatives of the above energy func-
tion analogously to the linear case. In the case of the extended Kalman ﬁlter
(EKF), the derivatives can be easily derived by formally differentiating the
EKF equations (see Mbalawata et al., 2013). When sigma point ﬁlters are
used, a similar approach works, but additional care is needed for compu-
tation of the derivative of the square root matrix @
p
P./=@i arising in
the equations. The equations for computing the derivatives of the energy
function are given in Algorithm A.12.
To compute the expectations required for implementing the EM algo-
rithm, we can approximate the integrals in Equations (16.30) using the
Gaussian assumed density approximation (i.e., moment matching). The re-
sulting expression for Q is the following.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
339
Algorithm 16.15 (Evaluation of Q via Gaussian smoothing). The expres-
sion for Q for the non-linear state space model in Equation (16.51) can be
written as
Q.; .n//
'  1
2 log j2 P0./j   T
2 log j2 Q./j   T
2 log j2 R./j
  1
2 tr
(
P  1
0 ./
h
P s
0 C .ms
0   m0.// .ms
0   m0.//Ti)
  1
2
T
X
kD1
tr
˚
Q 1./ E

.xk   f.xk 1; // .xk   f.xk 1; //T j y1WT
	
  1
2
T
X
kD1
tr
˚
R 1./ E

.yk   h.xk; // .yk   h.xk; //T j y1WT
	
;
(16.55)
where the expectations are over the counterparts of the distributions in
Equations (16.42) obtained from the Gaussian smoother.
In practice, we can approximate the Gaussian smoother and Gaussian in-
tegrals above with Taylor series approximations (EKF/ERTSS) or by sigma
point methods such as Gauss–Hermite or spherical cubature integration or
the unscented transform. The M-step for the noise parameters can indeed
be implemented analogously to the linear case in Theorem 16.12, because
the maxima of the above Q with respect to the noise covariance are simply
Q D 1
T
T
X
kD1
E

.xk   f.xk 1; // .xk   f.xk 1; //T j y1WT

;
R D 1
T
T
X
kD1
E

.yk   h.xk; // .yk   h.xk; //T j y1WT

:
(16.56)
The details of implementation of the M-step for other kinds of parameter
depend on the actual functional form of f and h. If the parameters appear
linearly in the functions, it is possible to ﬁnd closed form solutions for
the maxima analogously to the linear case (Theorem 16.12). Obviously,
even when analytical solutions cannot be found, it would be possible to use
iterative optimization methods inside EM. But if iterative methods need to
be used anyway, then with the same effort we can try to ﬁnd the minimum
of the energy function directly (recall that this is what EM tries to ﬁnd as
well).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
340
Parameter Estimation
Also in the non-linear case, Fisher’s identity (Equation (16.32)), in prin-
ciple, gives an easy way to evaluate the gradients of the energy function.
The problem is that both the energy function and the gradient given by
Fisher’s identity are approximations, and there is no guarantee that the
approximations involved are the same. That is, the derivative given by
Fisher’s identity might not be exactly the derivative of the approximate
energy function given by the Gaussian ﬁlter. The derivation of the Fisher’s
identity-based derivative expression is left as an exercise to the reader (Ex-
ercise 16.6).
16.3.4 Parameter Estimation with Iterated Filtering and Smoothing
In Chapters 7, 10, 13, and 14 we saw a collection of iterated ﬁlters and
smoothers that improve the ﬁlter and smoother estimates by using iteration
either on the update step or over the whole linearization trajectory. In prin-
ciple, iterated ﬁlters can be used to approximate the energy function in the
same way as Gaussian ﬁlters simply by taking the ﬁnal result of iteration
as the ﬁnal ﬁlter approximation. We can also use iterated smoothers to ﬁnd
the best linearization trajectory along with the corresponding linearization
and then use the energy function provided by the (afﬁne) Kalman ﬁlter for
parameter estimation, or alternatively, use the corresponding Q approxi-
mation.
Indeed, the aforementioned approaches work well for parameter estima-
tion in principle, but there is one catch: The linearization resulting from the
iteration will depend on the model parameters, and hence the iterated lin-
earization result will be a complicated function of the parameters. For eval-
uation of the energy function this is not a problem, but it causes problems
when computing the energy gradient. The gradient of the approximation
will no longer be given by, for example, the sensitivity equations, but in-
stead it will also depend on the derivative of the iterated linear linearization
result with respect to the parameters. This issue is addressed, for example,
in Christianson (1994).
16.3.5 Parameter Estimation via Particle Filtering and Smoothing
Particle ﬁltering can also be used for approximate evaluation of the
marginal likelihood and also of the energy function needed in parameter
estimation. In the particle ﬁltering approach, we can consider generic

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
341
models of the form
  p./;
x0  p.x0 j /;
xk  p.xk j xk 1; /;
yk  p.yk j xk; /;
(16.57)
where  2 Rd is the unknown parameter to be estimated. The approxi-
mate evaluation of the marginal likelihood can be done with the following
modiﬁcation of the SIR particle ﬁlter (see, e.g., Andrieu et al., 2004; Creal,
2012).
Algorithm 16.16 (SIR-based energy function approximation). An approx-
imation to the marginal likelihood of the parameters can be evaluated dur-
ing the sequential importance resampling (SIR) algorithm (particle ﬁlter),
as follows.
 Draw N samples x.i/
0 from the prior:
x.i/
0  p.x0 j /;
i D 1; : : : ; N;
(16.58)
and set w.i/
0
D 1=N for all i D 1; : : : ; N .
 For each k D 1; : : : ; T , do the following.
1. Draw samples x.i/
k from the importance distributions:
x.i/
k  .xk j x.i/
k 1; y1Wk; /;
i D 1; : : : ; N:
(16.59)
2. Compute the following weights:
v.i/
k
D p.yk j x.i/
k ; / p.x.i/
k j x.i/
k 1; /
.x.i/
k j x.i/
k 1; y1Wk; /
;
(16.60)
and compute the estimate of p.yk j y1Wk 1; / as
Op.yk j y1Wk 1; / D
X
i
w.i/
k 1 v.i/
k :
(16.61)
3. Compute the normalized weights as
w.i/
k
/ w.i/
k 1 v.i/
k :
(16.62)
4. If the effective number of particles (11.31) is too low, perform resam-
pling.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
342
Parameter Estimation
0.05
0.1
0.15
R
0
20
40
60
80
100
 p(R | y1:T )
PMCMC histogram
Gaussian filter estimate
True parameter value
Figure 16.2 Posterior distribution of the noise variance R in the
pendulum model (see Example 16.17). The approximation
computed with the the Gaussian ﬁlter is very close to the
reference result computed with the PMCMC.
The approximation of the marginal likelihood of the parameters is
p.y1WT j / 
Y
k
Op.yk j y1Wk 1; /;
(16.63)
and the corresponding energy function approximation is
'T ./    log p./  T
X
kD1
log Op.yk j y1Wk 1; /:
(16.64)
The energy function approximation could also be computed recursively
during the SIR algorithm above.
The particle ﬁlter-based energy function approximation can now be
used, for example, in the Metropolis–Hastings-based MCMC algorithm.
The result is the particle Markov chain Monte Carlo (PMCMC) method
(Andrieu et al., 2010) and, more speciﬁcally, the particle marginal
Metropolis–Hastings (PMMH) algorithm variant of it. It turns out that the
resulting MCMC algorithm is exact in the sense that it samples from the
right distribution Andrieu et al. (2010). Thus the result is (asymptotically)
the same as if we had used the exact energy function instead of the particle
ﬁlter-based approximation in the MCMC method.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
343
Example 16.17 (Estimation of noise variance in the pendulum model).
Figure 16.2 shows the posterior distribution approximation for the noise
variance R computed with a Gaussian ﬁlter for the pendulum model in
Example 7.6. The ﬁgure also shows the histogram of samples from the PM-
CMC method, which thus should approach the true posterior of the param-
eter. As can be seen, the posterior distribution estimate of the Gaussian
ﬁlter (ﬁfth order Gauss–Hermite ﬁlter) is a good approximation to the true
posterior distribution.
In principle, it would also be possible to use the likelihood or energy
function approximation in gradient-free optimization methods for ﬁnding
MAP or ML estimates. However, this might turn out to be hard, because
even if we ﬁxed the random number generator sequence in the particle
ﬁlter, the likelihood function would not be continuous in  (see, e.g., Kan-
tas et al., 2009). This also renders the use of gradient-based optimization
methods impossible.
By comparing to the Rao–Blackwellized particle ﬁlter in Algo-
rithm 11.13, it is easy to see that the corresponding likelihood approxima-
tion can be obtained by setting
v.i/
k
D p.yk j u.i/
0Wk; y1Wk 1; / p.u.i/
k j u.i/
k 1; /
.u.i/
k j u.i/
0Wk 1; y1Wk; /
:
(16.65)
The likelihood approximation itself remains the same as in Equa-
tion (16.61):
Op.yk j y1Wk 1; / D
X
i
w.i/
k 1 v.i/
k :
We can also implement the EM algorithm using particle smoothing. Re-
call that to implement the EM algorithm, we need to evaluate Q.; .n//
via Equation (16.29), which in turn requires us to evaluate the expecta-
tions appearing in Equation (16.30). The actual form of the approxima-
tion depends on the particle smoother that we are using. In the case of
the backward-simulation particle smoother, we have the following simple
algorithm (Wills et al., 2013).
Algorithm
16.18
(Evaluation
of Q
via
the
backward-simulation
particle smoother). Assume that we have simulated S trajectories
fQx.i/
0WT
W i D 1; : : : ; Sg using the backward-simulation particle smoother
in Algorithm 15.2 with parameter values ﬁxed to .n/. Then the integrals

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
344
Parameter Estimation
in Equation (16.30) can be approximated as
I1.; .n//  1
S
S
X
iD1
log p.Qx.i/
0 j /;
I2.; .n// 
T  1
X
kD0
1
S
S
X
iD1
log p.Qx.i/
kC1 j Qx.i/
k ; /;
I3.; .n// 
T
X
kD1
1
S
S
X
iD1
log p.yk j Qx.i/
k ; /:
(16.66)
If we are using the reweighting (or marginal) particle smoother in Algo-
rithm 15.7, the corresponding expectations can be approximated as follows
(Sch¨on et al., 2011).
Algorithm 16.19 (Evaluation of Q via the reweighting smoother). Assume
that we have the set of particles fx.i/
k
W k D 0; : : : ; T I i D 1; : : : ; N g
representing the ﬁltering distribution and we have calculated the weights
fw.i/
kjT W k D 0; : : : ; T I i D 1; : : : ; N g using Algorithm 15.7. Then we can
approximate the integrals in Equation (16.30) as follows:
I1.; .n// 
X
i
w.i/
0jT log p.x.i/
0 j /;
I2.; .n// 
T  1
X
kD0
X
i
X
j
w.j /
kC1jT w.i/
k p.x.j /
kC1 j x.i/
k ; .n//
hP
l w.l/
k p.x.j /
kC1 j x.l/
k ; .n//
i
 log p.x.j /
kC1 j x.i/
k ; /;
I3.; .n// 
T
X
kD1
X
i
w.i/
kjT log p.yk j x.i/
k ; /:
(16.67)
By differentiating the expressions in the above algorithms with respect
to , we can also get an approximation for @Q.; .n//=@. This approxi-
mation can be further used in Fisher’s identity in Equation (16.32) to give
approximations for the gradients of the energy function (Ninness et al.,
2010). For more information on this kind of approach as well as other meth-
ods for particle ﬁltering-based parameter estimation, the reader is referred
to Andrieu et al. (2004), Kantas et al. (2009), and Poyiadjis et al. (2011).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
345
16.3.6 Rao–Blackwellization of Parameters
In this section we show how Rao–Blackwellization can sometimes be used
for marginalizing out the static parameters in state space models. Let’s start
by considering the following generalized version of the pendulum example
used in S¨arkk¨a (2006) and S¨arkk¨a and Sottinen (2008):
xk D f.xk 1/ C qk 1;
yk D h.xk/ C rk;
rk  N.0; R/;
R  Inv-2.0; R0/;
(16.68)
where qk 1  N.0; Q/. This is thus the same kind of non-linear state
space model that we have already considered in this book, except that here
the measurement noise variance R is considered as unknown and given an
inverse-chi-squared prior distribution Inv-2.0; R0/.
It turns out that we can do sequential Monte Carlo sampling in this
model such that we do not need to sample the values of R. Instead, it is
enough to sample the state values and then carry the parameters of the dis-
tribution of R, conditional on the previous measurements and the histories
of samples. The idea is the following.
1. Assume that we have generated a set of particle histories fw.i/
k ; x.i/
0Wk W
i D 1; : : : ; N g that approximate the full distribution of the states as
follows:
p.x0Wk 1 j y1Wk 1/ 
X
i
w.i/
k 1 ı.x0Wk 1   x.i/
0Wk 1/;
(16.69)
which is thus the conventional SIR ﬁlter approximation when we store
the full sample histories (see Section 15.1). Further assume that the con-
ditional distribution of R given measurements y1Wk 1 and the sampled
state history x.i/
0Wk 1 is
p.R j x.i/
0Wk 1; y1Wk 1/ D Inv-2.R j .i/
k 1; R.i/
k 1/;
(16.70)
where .i/
k 1; R.i/
k 1 have already been computed for each i. Then we
have the following approximation for the full distribution of states and
parameters:
p.x0Wk 1; R j y1Wk 1/
D p.R j x0Wk 1; y1Wk 1/ p.x0Wk 1 j y1Wk 1/

X
i
w.i/
k 1 Inv-2.R j .i/
k 1; R.i/
k 1/ ı.x0Wk 1   x.i/
0Wk 1/:
(16.71)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
346
Parameter Estimation
2. Let us now draw samples from an importance distribution:
x.i/
k  .x.i/
k j x.i/
k 1; yk/:
(16.72)
3. We can now evaluate the likelihood of the measurement given x.i/
k and
the previous measurements as follows:
p.yk j x.i/
k ; y1Wk 1/
D
Z
N.yk j h.x.i/
k /; R/ Inv-2.R j .i/
k 1; R.i/
k 1/ dR
D t.i/
k .yk j h.x.i/
k /; R.i/
k /;
(16.73)
where the parameters of the Student’s t-distribution above are
.i/
k
D .i/
k 1 C 1;
R.i/
k D .i/
k 1R.i/
k 1 C .yk   h.x.i/
k //2
.i/
k 1 C 1
:
(16.74)
This allows us to compute the next step importance weights for the SIR
algorithm as follows:
w.i/
k
/ p.yk j x.i/
k ; y1Wk 1/ N.x.i/
k j f.x.i/
k 1/; Q/
.x.i/
k j x.i/
k 1; yk/
:
(16.75)
4. Given the measurement and the state, we can further compute the con-
ditional distribution of R given y1Wk and x.i/
0Wk:
p.R j x.i/
0Wk; y1Wk/ D Inv-2.R j .i/
k ; R.i/
k /:
(16.76)
5. Now we again have a similar representation for the ﬁltering distribution
as in step 1, and we can set k  k C1 and go back to step 1. But before
that we can also do resampling jointly for the state histories x.i/
0Wk and
the parameters .i/
k ; R.i/
k as in the conventional SIR algorithm.
In the above algorithm, we would not actually need to carry the whole
state histories in the ﬁlter, but theoretically the parameters of the inverse
chi squared distributions are indeed conditioned on the full state histories.
The procedure above is a Rao–Blackwellized particle ﬁlter where the
static parameter R has been marginalized out and is carried via its sufﬁcient
statistics .i/
k ; R.i/
k conditioned on the particle histories x.i/
0Wk and measure-
ments. In another example given in S¨arkk¨a (2006) and S¨arkk¨a and Sottinen

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
16.3 Practical Parameter Estimation in State Space Models
347
(2008), this procedure is used for marginalizing out the unknown popula-
tion size in a Poisson measurement model. The same idea can be used in
various other types of model.
In an abstract sense the method can be applied to a class of models of
the form
xk  p.xk j xk 1; /;
yk  p.yk j xk; /;
  p./;
(16.77)
where the vector  contains the unknown static parameters. Now if the
posterior distribution of the parameters  depends only on some sufﬁcient
statistics
Tk D Tk.x1Wk; y1Wk/;
(16.78)
and if the sufﬁcient statistics are easy to update recursively, Tk  Tk 1,
then sampling of the state and parameters can be performed by recursively
computing the sufﬁcient statistics conditionally on the sampled states and
the measurements analogously to the example above. The original idea of
the method seems to have appeared quite independently in Storvik (2002),
Fearnhead (2002), and Djuric and Miguez (2002), and it has been applied
to estimation of full noise covariances in state space models by Saha et al.
(2010).
A particularly useful special case, which includes the example above,
is obtained when the dynamic model is independent of the parameters .
In this case, if conditionally to the state xk the prior p./ belongs to the
conjugate family of the likelihood p.yk j xk; /, the static parameters 
can be marginalized out, and only the states need to be sampled. This idea
can be extended to the time-varying case if the dynamic model has a form
that keeps the predicted distribution of the parameter within the conjugate
family (cf. S¨arkk¨a and Nummenmaa, 2009).
When the static parameter appears linearly in the model, we recover
a noise-free version of the conditionally Gaussian Rao–Blackwellization
considered in Section 11.7 (see Sch¨on and Gustafsson, 2003). The Rao–
Blackwellized particle ﬁlter can then be seen as a time-varying extension
of this method in the conditionally linear Gaussian case.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
348
Parameter Estimation
16.4 Exercises
16.1
Implement the EM algorithm for ML estimation of the measurement noise
variance in the Gaussian random walk model considered in Examples 6.4,
6.7, and 12.3. Test the algorithm with simulated data.
16.2
Implement the algorithm for computing the energy function for the Gaussian
random walk model as well as its derivative with respect to the noise vari-
ance (via the sensitivity equations given in Section A.10). Generate some
simulated data, and use a gradient-based optimization method to ﬁnd the
ML estimate of the parameter.
16.3
With the Gaussian random walk model, ﬁnd the expression for the Fisher’s
identity-based derivative with respect to the noise parameter. Check numer-
ically that it matches the expression obtained with the sensitivity equations.
16.4
Implement a random walk Metropolis-based MCMC method for estimating
the noise variance in the Gaussian random walk model. Use the Kalman ﬁlter
to evaluate the energy function. For simplicity, you can assume that the prior
for the parameter has the form p.R/ / 1.
16.5
Derive the sensitivity equations for the ﬁrst order extended Kalman ﬁlter.
16.6
Derive the equation for the derivative of the energy function resulting
from differentiating the Gaussian smoothing-based approximation in
Algorithm 16.15 and using Fisher’s identity (Equation (16.32)).
16.7
Compute and plot the approximate energy function obtained for the noise
variance in the model given in Exercise 7.1 by using a non-linear Kalman
ﬁlter-based estimate of the energy function. You can select the ﬁlter freely.
16.8
Implement a random walk Metropolis-based MCMC method for estimating
the noise variance in the model given in Exercise 7.1. Use one of the non-
linear Kalman ﬁlters to approximate the energy function.
16.9
Implement a random walk Metropolis-based particle MCMC method for
estimating the noise variance in the Gaussian random walk model. Use a
simple bootstrap ﬁlter as the particle ﬁlter.
16.10 Implement a random walk Metropolis-based particle MCMC method for
estimating the noise variance in the model given in Exercise 7.1.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
17
Epilogue
17.1 Which Method Should I Choose?
An important question when preparing to solve a speciﬁc ﬁltering, smooth-
ing, or parameter estimation problem for state space models is: Which of
the numerous methods should I choose for a particular application? Obvi-
ously if the problem is linear, then the Kalman ﬁlter and RTS smoother are
natural choices – also for evaluating the quantities needed for parameter
estimation. But if the system is non-linear/non-Gaussian, the question is
harder.
When the noises in the system can be modeled as Gaussian, and the
model is of the form
xk D f.xk 1/ C qk 1;
yk D h.xk/ C rk;
(17.1)
where f and h are somewhat well-behaved functions, then the ﬁrst choice
would be one of the Gaussian approximation-based ﬁlters and smoothers
– provided that we are working on an application, and the theoretical ex-
actness of the solution is not important per se, but we are interested in
getting good estimates of the state and parameters. If theoretical exactness
is needed, then the only option is to use particle ﬁlters and smoothers (or
grid-based solutions).
Among the Gaussian approximation-based ﬁlters and smoothers, it is al-
ways a good idea to start with an EKF and an ERTSS. These are the only
algorithms that have been used for over half a century in practical appli-
cations, and there are good reasons for that – they simply work. Iterated
versions of the EKF and ERTSS can then be used to improve the results –
in particular, the iterated ERTSS is a powerful algorithm that often leads to
good results, due to its convergence to the MAP estimate.
349

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
350
Epilogue
With some models the EKF and ERTSS do not work well or at all, and
in that case we can move to the sigma point methods. The spherical cuba-
ture and unscented methods have the advantage of being computationally
quite light, but they still tend to produce very good results. However, these
methods have the problem that their error estimates might not always be
consistent with the actual errors, a problem which the EKF/ERTSS meth-
ods also tend to have. The unscented transform has more parameters to tune
for a particular problem than the spherical cubature method, which can be
an advantage or a disadvantage (recall that the spherical cubature method is
an unscented transform with a certain selection of parameters). The Gauss–
Hermite-based methods tend to be more consistent in errors and are thus
more robust approximations, but they have the disadvantage of having high
computational complexity. The higher order cubature/unscented rules also
have a moderate computational complexity while having quite high accu-
racy, but their problem is that they can lead to negative weights. However,
there are various other higher integration rules that do not have (all of)
these problems but which have not been explicitly discussed in this book.
The iterated sigma point methods can also be used to improve the perfor-
mance of the non-iterated versions, and sometimes Monte Carlo integration
can also be used to replace the sigma point-based numerical integration
when using Gaussian approximations. One should always remember that
there is no guarantee that using more complicated ﬁltering and smoothing
algorithms would actually improve the results; therefore it is a good idea to
always test the EKF and ERTSS ﬁrst. The bootstrap ﬁlter has the advantage
that it is very easy to implement, and thus it can sometimes be used as a ref-
erence solution when debugging and testing the performance of Gaussian
approximation-based ﬁlters and smoothers.
If the problem has a more complicated form that cannot be ﬁtted into
the non-linear Gaussian framework or when the Gaussian approximations
do not work for other reasons, we need to go to particle-based solutions.
Because the bootstrap ﬁlter is very easy to implement, it (and probably
one of the particle smoothers) should be the ﬁrst option to test with a
sufﬁciently large number of particles. However, the clear disadvantage of
particle methods is the high computational load, and thus it is a good idea
to check at quite an early stage if any of the states or parameters can be
marginalized out (“Rao–Blackwellized”) exactly or approximately. If this
is the case, then one should always prefer marginalization to sampling.1
1 The rule of thumb is: Use Monte Carlo sampling only as a last resort when all the other
options have failed.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
17.2 Further Topics
351
The other thing to check is if it is possible to use the optimal or almost
optimal importance distribution in the particle ﬁlter. In principle, non-linear
Gaussian approximation-based ﬁlters can be used to form such importance
distributions, but this may also lead to overly heavy computational methods
as well as to convergence problems. If they are used, then it might be
advisable to artiﬁcially increase the ﬁlter covariances somewhat or to use
Student’s t-distributions instead of using the Gaussian approximations as
such.
When it comes to parameter estimation, it is generally a good idea to
use the same approximations in the parameter estimation method as will
be used in the ﬁnal application, assuming that the parameter estimation re-
sults will later be used in ﬁlters and smoothers to solve a state estimation
problem. Furthermore, if a single parameter estimation result (point esti-
mate) is needed anyway, ML and MAP estimates are not bad choices, but
it might be useful to check the spread of the posterior distribution of param-
eters using an MCMC method. But if the true values of the parameters are
of interest, then the combination of particle ﬁltering and MCMC is proba-
bly the safest bet. However, one should remember that estimating the true
parameters of the system is possible only in simulated scenarios and in real
applications the models used will be more or less wrong anyway. On the
other hand, we should be careful not to ruin already probably inaccurate
models with bad approximations of ﬁlters and smoothers.
17.2 Further Topics
This book is mainly concerned with non-linear Kalman ﬁltering and
smoothing as well as particle ﬁltering and smoothing approaches to
Bayesian ﬁltering and smoothing, but numerous other methods exist as
well. It is impossible to list all of them, but below we try to give pointers
to some of the methods. Regarding ﬁlters and smoothers themselves, there
are also various subareas that we did not discuss, and we try to give some
pointers to them as well.
First of all, one huge area that we have not mentioned at all is continu-
ous time ﬁlters and smoothers. In these methods the dynamics of the state
and sometimes the measurements as well are modeled using stochastic dif-
ferential equations (SDEs, Øksendal, 2003; S¨arkk¨a and Solin, 2019). The
full theory of Bayesian ﬁltering in such models can be found in the clas-
sic book of Jazwinski (1970), and the smoothing theory is due to Striebel

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
352
Epilogue
(1965) and Leondes et al. (1970). The extended Kalman type of ﬁlter ap-
proximation can be found in the abovementioned references as well. Ex-
tensions of unscented Kalman ﬁlters and smoothers to the continuous-time
setting can be found in S¨arkk¨a (2006, 2007, 2010). Extensions of Gaus-
sian ﬁlters and smoothers to continuous-time setting have been discussed
in Singer (2008), Arasaratnam et al. (2010), Singer (2011), S¨arkk¨a and
Solin (2012), and S¨arkk¨a and Sarmavuori (2013). Extensions of particle
ﬁlters and smoothers to continuous-time setting can be found, for example,
in Crisan and Rozovskii (2011), S¨arkk¨a and Sottinen (2008), Murray and
Storkey (2011), and references therein.
There also exist various other kinds of Gaussian integration methods that
we have not presented here that could be used for constructing new kinds
of Gaussian ﬁlters and smoothers (see, e.g., O’Hagan, 1991; Nørgaard
et al., 2000; Lefebvre et al., 2002; Wu et al., 2006; S¨arkk¨a and Hartikainen,
2010b; Sandblom and Svensson, 2012). One particularly interesting ap-
proach is to approximate the non-linear functions with a Gaussian process-
based non-parametric model that is ﬁtted using a ﬁnite number of sample
points (Deisenroth et al., 2009, 2012). These methods are related to so-
called kernel or Gaussian process quadratures (see, e.g., O’Hagan, 1991;
S¨arkk¨a et al., 2016; Karvonen and S¨arkk¨a, 2018; Karvonen et al., 2019;
Pr¨uher et al., 2021; Hennig et al., 2022), which are numerical integration
methods based on Gaussian process regression.
One useful class of discrete-time methods is the multiple model ap-
proaches, such as the generalized pseudo-Bayesian methods (GPB1 and
GPB2) as well as the interacting multiple model (IMM) algorithm (Bar-
Shalom et al., 2001). These methods can be used for approximating the
Bayesian solutions to problems with a ﬁxed number of models or modes
of operation. The active mode of the system is described by a discrete la-
tent variable, which is modeled as a discrete-state Markov chain. Given the
value of the latent variable, the system is (approximately) Gaussian. The
GPB1, GPB2, and IMM algorithms are based on an approximation that is
a mixture of Gaussians (a bank of Kalman or extended Kalman ﬁlters) to
the Bayesian ﬁltering solutions by using moment matching.
The abovementioned multiple model methods are also closely related to
so-called expectation correction (EC, Barber, 2006) and expectation prop-
agation (EP, Zoeter and Heskes, 2011) methods, which can also be used
for Bayesian ﬁltering and smoothing in switching linear dynamic systems
(SLDS), which is another term used for multiple mode/model problems.
These models can also be considered as special cases of the conditionally
Gaussian models, and the history of similar approximations dates back to

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
17.2 Further Topics
353
the works of Alspach and Sorenson (1972) and Akashi and Kumamoto
(1977). The relationship between various methods for this type of model
has also been analyzed by Barber (2011).
When the measurement model is non-Gaussian (e.g., Student’s t), it is
sometimes possible to use variational Bayes approximations (Agamennoni
et al., 2011; Pich´e et al., 2012) to yield to tractable inference. The expec-
tation propagation (EP) algorithm (Ypma and Heskes, 2005) can also be
used for approximate inference in non-linear and non-Gaussian dynamic
systems. Both of these approaches are also closely related to the Gaus-
sian ﬁlters and smoothers considered in this book. Variational Bayesian
approximations can also be used for estimation of unknown time-varying
parameters in state space models (S¨arkk¨a and Nummenmaa, 2009).
In the multiple target tracking context, there exist a number of speciﬁc
methods to cope with the problems arising there, namely, the data associa-
tion problem and an unknown numbers of targets. The classical approaches
to the multiple target tracking can be found in the books of Bar-Shalom and
Li (1995) and Blackman and Popoli (1999). For further approaches, the
reader is referred to Ristic et al. (2004), Challa et al. (2011), and Mahler
(2014), along with S¨arkk¨a et al. (2007b), Svensson et al. (2011), Garc´ıa-
Fern´andez et al. (2020); Granstr¨om et al. (2020), and Garc´ıa-Fern´andez
et al. (2021).
There are a number of other important topics that have had to be omitted
here. For example, the Cram´er–Rao lower bounds (CRLB, see, e.g., Ristic
et al., 2004) are theoretical lower bounds for the mean-squared error that
can be achieved with any non-linear ﬁlter in a given ﬁltering problem.
We have also omitted the observability and controllability questions of
linear and non-linear systems (see, e.g., Kailath et al., 2000; Bar-Shalom
et al., 2001), which are related to the question whether it is possible to
determine the state of a given system from the available measurements at
all. A somewhat related issue is the question of under what conditions does
a particle ﬁlter converge to the true distribution. For more details on this
topic, the reader is referred to the works of Crisan and Doucet (2002) and
Hu et al. (2008, 2011). The numerical stability of linear and non-linear
Kalman ﬁlters and RTS smoothers can sometimes also be enhanced by
using square root versions of them. This kind of methods can be found, for
example, in the works of Bierman (1977), Van der Merwe and Wan (2001),
Arasaratnam and Haykin (2009, 2011), and Grewal and Andrews (2015).
There has also been some recent interest in using graphics processing
units (GPUs, Barlas, 2015) for parallel computations, and special parallel
ﬁltering and smoothing methods that allow for parallelization can be found,

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
354
Epilogue
for example, in S¨arkk¨a and Garc´ıa-Fern´andez (2021), Hassan et al. (2021),
Yaghoobi et al. (2021), and Corenﬂos et al. (2022).

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Appendix
Additional Material
A.1 Properties of Gaussian Distribution
Deﬁnition A.1 (Gaussian distribution). A random variable x 2 Rn has a
Gaussian distribution with mean m 2 Rn and covariance P 2 Rnn if its
probability density has the form
N.x j m; P/ D
1
.2 /n=2 jPj1=2 exp

 1
2.x   m/T P  1 .x   m/

;
(A.1)
where jPj is the determinant of the matrix P.
Lemma A.2 (Joint distribution of Gaussian variables). If random variables
x 2 Rn and y 2 Rm have the Gaussian probability distributions
x  N.m; P/;
y j x  N.H x C u; R/;
(A.2)
then the joint distribution of x; y and the marginal distribution of y are
given as
x
y

 N

m
H m C u

;
 P
P HT
H P
H P HT C R

;
y  N.H m C u; H P HT C R/:
(A.3)
Lemma A.3 (Conditional distribution of Gaussian variables). If the ran-
dom variables x and y have the joint Gaussian probability distribution
x
y

 N
a
b

;
 A
C
CT
B

;
(A.4)
355

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
356
Additional Material
then the marginal and conditional distributions of x and y are given as
follows:
x  N.a; A/;
y  N.b; B/;
x j y  N.a C C B 1 .y   b/; A   C B 1CT/;
y j x  N.b C CT A 1 .x   a/; B   CT A 1 C/:
(A.5)
A.2 Block Matrix Inverses and Matrix Inversion Formulas
Block matrix inversion formulas (see, e.g., L¨utkepohl, 1996) and matrix
inversion formulas (sometimes called Woodbury’s identities) are useful
in simplifying various expressions involving Gaussian distributions. The
block matrix inversion formulas are the following, and they are easy to
verify by direct calculation.
Theorem A.4 (Block matrix inverses). When A and D   C A 1 B are
invertible, then
A
B
C
D
 1
D
 
A 1CA 1 B
 D   CA 1 B
 1CA 1
 A 1 B
 D   CA 1 B
 1
  D   CA 1 B
 1 CA 1
 D   CA 1 B
 1
!
:
(A.6)
When D and A   B D 1 C are invertible, then
A
B
C
D
 1
D
 
 A   B D 1 C
 1
  A   B D 1 C
 1 B D 1
 D 1C
 A   B D 1C
 1
D 1CD 1C
 A   B D 1C
 1B D 1
!
:
(A.7)
We can derive various useful formulas for matrices by matching the
blocks in the representations in Equations (A.6) and (A.7). For example,
the following formulas are sometimes useful in deriving Gaussian condi-
tioning, and Kalman ﬁltering and smoothing equations.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.3 Cholesky Factorization and Its Derivative
357
Corollary A.5 (Matrix inversion lemmas). By putting A D P  1, D D
R, B D  HT, and C D H, and matching the top left blocks in Equa-
tions (A.6) and (A.7), we get
 P  1 C HT R 1 H
 1 D P   PHT  R C H P HT 1 H P;
(A.8)
and from the top right block, we get
 P  1 C HT R 1 H
 1 HT R 1 D PHT  R C H P HT 1 :
(A.9)
A.3 Cholesky Factorization and Its Derivative
The Cholesky factor of the symmetric positive deﬁnite matrix P is a lower
triangular matrix A such that
P D A AT:
(A.10)
The matrix A can be computed by the Cholesky factorization algorithm
(see, e.g., Golub and van Loan, 1996) presented below.
Algorithm A.6 (Cholesky factorization). The Cholesky factor A of the
matrix P 2 Rnn can be computed as follows:
procedure CHOL(P)
for i  1 : : : n do
Aii D
q
Pii   P
k<i A2
ik
for j  i C 1 : : : n do
Aji D
 Pji   P
k<i Ajk Aik

=Aii
end for
end for
return A
end procedure
The partial derivative of the Cholesky factor @A=@ with respect to a
scalar parameters  can be computed using the following algorithm once
P and @P=@ are known. The algorithm can be derived by formally differ-
entiating the Cholesky factorization algorithm equations.
Algorithm A.7 (Partial derivative of Cholesky factorization I). The partial
derivative D D @A=@ of the Cholesky factor of P 2 Rnn with respect to
a scalar parameter  can be computed as follows:
procedure DCHOL(P; @P=@)
for i  1 : : : n do

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
358
Additional Material
Aii  
q
Pii   P
k<i A2
ik
Dii  .@Pii=@   P
k<i 2Dik Aik/=Aii=2
for j  i C 1 : : : n do
Aji  .Pji   P
k<i Ajk Aik/=Aii
temp  @Pji=@   P
k<i.Djk Aik C Ajk Dik/
Dji  temp=Aii   .Dii=Aii/ Aji
end for
end for
return D
end procedure
Another way to compute the same derivative is via the following theo-
rem.
Theorem A.8 (Partial derivative of Cholesky factorization II). The partial
derivative @A=@ of the lower triangular Cholesky factor A such that P D
A AT with respect to a scalar parameter  can be computed as
@A
@ D A ˆ

A 1 @P
@ A T

;
(A.11)
where ˆ./ is a function returning the lower triangular part and half the
diagonal of the argument as follows:
ˆij.M/ D
8
ˆ<
ˆ:
Mij;
if i > j;
1
2Mij;
if i D j;
0;
if i < j:
(A.12)
Proof
We use a similar trick that was used in the derivation of the time
derivative of the Cholesky factor in Morf et al. (1978). We have
P D A AT:
(A.13)
By taking the derivative with respect to , we get
@P
@ D @A
@ AT C A @AT
@ :
(A.14)
Multiplying from the left with A 1 and from the right with A T gives
A 1 @P
@ A T D A 1 @A
@ C @AT
@ A T:
(A.15)
Now the right-hand side is the sum of a lower triangular matrix and an
upper triangular matrix with identical diagonals. Thus we can recover

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.4 Afﬁne Stochastic Differential Equations
359
A 1 @A=@ via
A 1 @A
@ D ˆ

A 1 @P
@ A T

;
(A.16)
where the function ˆ./ returns the (strictly) lower triangular part of the
argument and half of the diagonal. Multiplying from the left by A gives the
result.
A.4 Afﬁne Stochastic Differential Equations
Many of the stochastic differential equations (SDEs) that we study in Chap-
ter 4 are afﬁne, and the following lemma can be used to derive several of the
key results in that chapter. Note that a more rigorous derivation of these re-
sults can be obtained using Itˆo calculus (see, e.g., S¨arkk¨a and Solin, 2019).
Lemma A.9 (Analytical solution to afﬁne SDE). Suppose x.t/ obeys the
stochastic differential equation (SDE)
dx.t/
dt
D F x.t/ C b.t/ C L w.t/;
(A.17)
where F is constant, b.t/ is a deterministic function of time, and w.t/ is
white Gaussian noise with the moments (4.4). It then holds that
x.t C / D exp.F/x.t/ C
Z tC
t
exp.F .t C    v// b.v/ dv
C
Z tC
t
exp.F .t C    v// L w.v/ dv;
(A.18)
where
R tC
t
exp.F .t C    v// L w.v/ dv is a Gaussian random variable
with zero mean and covariance
Z 
0
exp.Fv/ L Qc LT exp.Fv/T dv:
(A.19)
Consequently, x.t C / j x.t/ is Gaussian with the moments
E Œx.t C / j x.t/ D exp.F/ x.t/
C
Z tC
t
exp.F .t C    v// b.v/ dv;
Cov Œx.t C / j x.t/ D
Z 
0
exp.Fv/ L Qc LT exp.Fv/T dv:
(A.20)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
360
Additional Material
Furthermore, if b.t/ D b is a constant, it holds that
Z tC
t
exp.F .t C    v// b dv D
Z 
0
exp.F v/ dv b D
 1
X
iD1
i F i 1
iŠ
!
b;
(A.21)
which further simpliﬁes the expressions for x.tC/ and E Œx.t C / j x.t/.
Proof
To solve (A.17), we move the term F x.t/ to the left-hand side and
multiply both sides of the equation with the integrating factor exp. F t/,
which gives
exp. F t/dx.t/
dt
  exp. F t/ F x.t/ D exp. F t/ .b.t/ C L w.t// :
(A.22)
From the deﬁnition of the matrix exponential,
exp.F t/ D
1
X
iD0
Fi t i
iŠ
D I C F t C F2 t2
2Š
C    ;
(A.23)
it follows that d
dt exp. F t/ D  F exp. F t/, and we can use this relation
to identify that the left-hand side in (A.22) is
d
dt .exp. F t/ x.t//, which
implies that
d
dt .exp. F t/ x.t// D exp. F t/ .b.t/ C L w.t// :
(A.24)
Integrating (A.24) from t to t C  therefore gives
exp. F .t C // x.t C /   exp. F t/ x.t/
D
Z tC
t
exp. F v/ .b.t/ C L w.v// dv:
(A.25)
By multiplying both sides of (A.25) by exp.F .t C //, we obtain (A.18).
Let us now analyze the two remaining integrals in (A.18) one at a time.
If b.t/ is a constant, it holds that
Z tC
t
exp.F .t C    v// b dv D
Z tC
t
exp.F .t C    v// dv b: (A.26)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.4 Afﬁne Stochastic Differential Equations
361
Using appropriate changes of integration variables, combined with the def-
inition of the matrix exponential, we get
Z tC
t
exp.F .t C    v// dv D
Z 
0
exp.F v/ dv
D
Z 
0
1
X
iD0
Fi vi
iŠ
dv
D
1
X
iD0
Fi  iC1
.i C 1/Š
D I C F 2
2
C F2 3
3Š
C    ;
(A.27)
which conﬁrms (A.21).
The last integral in (A.18) contains w.t/, which is a Gaussian process
with zero mean, and
R tC
t
exp.F .t C    v// L w.v/ dv is therefore also
a zero mean Gaussian random variable. Two results are central for deriv-
ing its covariance matrix. First, that the covariance matrix of a zero mean
random vector is the expected value of the vector times the transpose of
the vector. Second, that the deﬁnition of the Dirac delta function ı./ that
appears in (4.4) is that
R
ı.v   v0/ f .v/ dv D f .v0/. Using these results
we get
E
 Z tC
t
exp.F .t C    v1// L w.v1/ dv1

Z tC
t
wT.v2/ LT exp.F .t C    v2//T dv2

D
Z tC
t
Z tC
t
exp.F .t C    v1// L E

w.v1/ wT.v2/

LT
 exp.F .t C    v2//T dv1 dv2
D
Z tC
t
Z tC
t
exp.F .t C    v1// L Qc ı.v1   v2/ LT
 exp.F .t C    v2//T dv1 dv2
D
Z tC
t
exp.F .t C    v1// L Qc LT exp.F .t C    v1//T dv1
D
Z 
0
exp.F v/ L Qc LT exp.Fv/T dv:
(A.28)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
362
Additional Material
The above equation conﬁrms (A.19). Finally, (A.20) follows from the ear-
lier results.
A.5 Time Derivative of Covariance in Theorem 4.13
In this appendix, we derive the expression for the time derivative of P.t/
presented in Theorem 4.13. Recall that P.t/ D EŒ.x.t/   m.t//.x.t/  m.t//T  and that
dP.t/
dt
D lim
h!1
P.t C h/   P.t/
h
:
(A.29)
We therefore seek an approximation to P.t C h/ where o.h/ terms are
omitted, that is, we ignore terms that go to zero faster than h as h ! 0.
First of all we have
x.t C h/   x.t/ D
Z tCh
t
a.m.s// ds
C
Z tCh
t
Ax.m.s// .x.s/   m.s// ds C
Z tCh
t
L w.s/ ds:
(A.30)
On the other hand,
m.t C h/   m.t/ D
Z tCh
t
a.m.s// ds:
(A.31)
We can now write
x.t C h/   m.t C h/
D x.t C h/   m.t C h/ C x.t/   x.t/ C m.t/   m.t/
D Œx.t/   m.t/ C Œx.t C h/   x.t/   Œm.t C h/   m.t/
D Œx.t/   m.t/ C
Z tCh
t
Ax.m.s// .x.s/   m.s// ds C
Z tCh
t
L w.s/ ds
D Œx.t/   m.t/ C Ax.m.t// .x.t/   m.t// h C o.h/ C
Z tCh
t
L w.s/ ds;
(A.32)
where we have left the integral involving white noise w.t/ intact because
R tCh
t
L w.s/ ds ¤ L w.t/ h C o.h/ (cf. S¨arkk¨a and Solin, 2019), but in-
stead we need to explicitly use Equation (4.4). Because
R tCh
t
L w.s/ ds is

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.6 Derivation of Mean for Bicycle Model
363
independent of the other terms and E
hR tCh
t
L w.s/ ds
i
D 0, we then get
P.t C h/ D E

.x.t C h/   m.t C h// .x.t C h/   m.t C h//T
D E

.x.t/   m.t// .x.t/   m.t//T
C Ax.m.t// E

.x.t/   m.t// .x.t/   m.t//T
h
C E

.x.t/   m.t// .x.t/   m.t//T
AT
x.m.t// h
C E
"Z tCh
t
L w.s/ wT.s0/ LT ds ds0
#
C o.h/
D P.t/ C Ax.m.t// P.t/ h C P.t/ AT
x.m.t// h
C L Qc LT h C o.h/:
(A.33)
Rearranging and taking the limit h ! 0 then yields Equation (4.53).
A.6 Derivation of Mean for Bicycle Model
In this section, the aim is to derive the solution to the mean differential
equation in Example 4.17. Our aim is now to solve the differential equation
d
dt
0
BBBB@
x1.t/
x2.t/
s.t/
.t/
ı.t/
1
CCCCA
D
0
BBBB@
s.t/ cos..t//
s.t/ sin..t//
0
s.t/=r.t/
0
1
CCCCA
(A.34)
where r.t/ D L= tan.ı.t// for x.t/ D .x1.t/; x2.t/; s.t/; .t/; ı.t// given
the initial condition x.tk 1/ D xk 1. It holds that s.t/ D sk 1, ı.t/ D
ık 1, and thus r.t/ D rk 1 D L= tan.ık 1/, which implies that .t/ D
k 1 C .t   tk 1/ sk 1=rk 1. We can now solve for
x1.t/ D x1;k 1 C
Z t
tk 1
s.v/ cos..v// dv
D x1;k 1 C
Z t tk 1
0
sk 1 cos.k 1 C v sk 1=rk 1/ dv
D x1;k 1 C rk 1 .sin.k 1 C .t   tk 1/ sk 1=rk 1/   sin.k 1// :
(A.35)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
364
Additional Material
Using a similar derivation for x2.t/, we ﬁnally get
0
BBBB@
x1.t/
x2.t/
s.t/
.t/
ı.t/
1
CCCCA
D
0
BBBB@
x1;k 1 C rk 1 .sin.k 1 C ˇ.t   tk 1//   sin.k 1//
x2;k 1 C rk 1 .cos.k 1/   cos.k 1 C ˇ.t   tk 1///
sk 1
k 1 C ˇ.t   tk 1/
ık 1
1
CCCCA
;
(A.36)
where for brevity, we have deﬁned ˇ.t/ D t sk 1=rk 1. When the above
solution is evaluated at t D tk, the corresponding discretized model then
becomes Equation (4.66).
A.7 Mean Discretization for the Polar Coordinated Turn Model
Let us now derive the solution to the differential equation (4.56) that cor-
responds to the mean discretization of the polar coordinated turn model.
The state is given as x.t/ D .x1.t/; x2.t/; s.t/; '.t/; !.t//, and the initial
condition is x.tk 1/ D xk 1. Because the time derivatives of s.t/ and !.t/
are zero, it holds that
s.t/ D sk 1;
!.t/ D !k 1:
(A.37)
Because !.t/ is the time derivative of '.t/, it follows that
'.t/ D '.tk 1/ C .t   tk 1/ !.tk 1/:
(A.38)
Given (A.37) and (A.38), we get
x1.t/ D x1;k 1 C
Z t
tk 1
s.v/ cos.'.v// dv
D x1;k 1 C
Z t
tk 1
sk 1 cos.'k 1 C .v   tk 1/ !k 1/ dv
D x1;k 1 C sk 1
!k 1
.sin.'k 1 C .t   tk 1/ !k 1/   sin.'k 1//
D x1;k 1 C 2sk 1
!.tk 1/ sin
.t   tk 1/ !k 1
2

 cos

'k 1 C .t   tk 1/ !k 1
2

(A.39)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.8 Approximating Qk 1 in the Polar Coordinated Turn Model 365
and, using similar calculations,
x2.t/ D x2;k 1 C 2sk 1
!k 1
sin
.t   tk 1/ !.tk 1/
2

 sin

'k 1 C .t   tk 1/ !.tk 1/
2

:
(A.40)
The ﬁnal discretization is obtained by evaluation at t D tk.
A.8 Approximating Qk 1 in the Polar Coordinated Turn Model
Let us now derive a constant gradient-based covariance approximation as
given by Algorithm 4.19 for the polar coordinated turn model, whose mean
discretization was considered in Example 4.15. The derivation of the mean
discretization is given above in Section A.7. The covariance expression is
thus given as
Qk 1 D
Z tk 1
0
exp.Ax.xk 1/ v/ L Qc LT exp.Ax.xk 1/ v/T dv:
(A.41)
For brevity, we write
xk 1 D
 x1
x2
s
'
!
T :
(A.42)
It follows from (4.56) that
Ax.xk 1/ D
0
BBBB@
0
0
cos.'/
 s sin.'/
0
0
0
sin.'/
s cos.'/
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
1
CCCCA
;
(A.43)
and it is easy to verify that
.Ax.xk 1//2 D
0
BBBB@
0
0
0
0
 s sin.'/
0
0
0
0
s cos.'/
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
CCCCA
;
(A.44)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
366
Additional Material
whereas .Ax.xk 1//n D 0 for n  3. The deﬁnition of the matrix expo-
nential therefore gives
exp.Ax.xk 1/ v/
D I C v Ax.xk 1/ C v2 .Ax.xk 1//2
2
D
0
BBBB@
1
0
v cos.'/
 vs sin.'/
  v2
2 s sin.'/
0
1
v sin.'/
vs cos.'/
v2
2 s cos.'/
0
0
1
0
0
0
0
0
1
v
0
0
0
0
1
1
CCCCA
;
(A.45)
and from the expression for L in (4.43) we now obtain
exp.Ax.xk 1/ v/ L D
0
BBBB@
v cos.'/
  v2
2 s sin.'/
v sin.'/
v2
2 s cos.'/
1
0
0
v
0
1
1
CCCCA
:
(A.46)
For simplicity, we assume that Qc D diag.q1; q2/. To save space, we use
the shorthand notations si D sin.'/, co D cos.'/ and cs D sin.'/ cos.'/
and we only express the lower triangle of the following symmetric matri-
ces. Equation (A.46) yields
exp.Ax.xk 1// v/ L QcLT exp.Ax.xk 1/ v/T
D
0
BBBBB@
q1v2co2 C q2
v4
4 s2si2
q1v2cs   q2
v4
4 s2cs
q1v2si2 C q2
v4
4 s2co2
q1vco
q1vsi
q1
 q2s v3
2 si
q2s v3
2 co
0
q2v2
 q2s v2
2 si
q2s v2
2 co
0
q2v
q2
1
CCCCCA
:
(A.47)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.9 Conditional Moments Used in SLR
367
Finally, we integrate over v to obtain
P. C tk 1/
D
0
BBBBB@
q1
3
3 co2 C q2
5
20s2si2
q1
3
3 cs   q2
5
20s2cs
q1
3
3 si2 C q2
5
20s2co2
q1
2
2 co
q1
2
2 si
q1
 q2s 4
8 si
q2s v4
8 co
0
q2
3
3
 q2s 3
6 si
q2s 3
6 co
0
q2
2
2
q2
1
CCCCCA
;
(A.48)
which gives Qk 1 by setting  D tk 1.
A.9 Conditional Moments Used in SLR
We can use statistical linear regression (SLR) to approximate the dynamic
and measurement models in both ﬁltering and smoothing. Theorems 9.12
and 9.16, combined with Corollaries 9.14, 9.17, and 9.18, provide ﬁve dif-
ferent expressions for moments that we need to compute to perform SLR;
one expression for the additive noise models in (9.1) and two expressions
each for the non-additive noise models in (9.9) and for the conditional dis-
tribution models in (9.10). In this section, we present the explicit forms
that these equations take for the dynamic and measurement models, re-
spectively.
Using SLR, the dynamic model is approximated as
xk ' Ak 1 xk 1 C ak 1 C ek 1;
(A.49)
where ek 1  N.0; ƒk 1/. If1 xk 1  N. Qmk 1; QPk 1/, it holds that
Ak 1 D .P xx
k /T QP  1
k 1;
ak 1 D  k   Ak 1 Qmk 1;
ƒk 1 D P x
k   Ak 1 QPk 1AT
k 1;
(A.50)
where Theorem 9.16 and Corollaries 9.14, 9.17, and 9.18 provide the fol-
lowing ﬁve expressions for  k D EŒxk, P xx
k D CovŒxk 1; xk, and P x
k D
1 We use tildes to indicate that the equations are valid for any mean and covariance, but
note that the choice of these moments inﬂuences the resulting SLR approximation.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
368
Additional Material
CovŒxk. For additive noise models, Corollary 9.14 implies that
 k D
Z
f.xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk 1;
P xx
k D
Z
.xk 1   Qmk 1/ .f.xk 1/    k /T N.xk 1 j Qmk 1; QPk 1/ dxk 1;
P x
k D
Z
.f.xk 1/    k / .f.xk 1/    k /T N.xk 1 j Qmk 1; QPk 1/ dxk 1
C Qk 1I
(A.51)
for non-additive noise models, Equations (9.50) in Corollary 9.17 give
 k D
Z
f.xk 1; qk 1/
 N.xk 1 j Qmk 1; QPk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1;
P xx
k D
Z
.xk 1   Qmk 1/ .f.xk 1; qk 1/    k /T
 N.xk 1 j Qmk 1; QPk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1;
P x
k D
Z
.f.xk 1; qk 1/    k / .f.xk 1; qk 1/    k /T
 N.xk 1 j Qmk 1; QPk 1/ N.qk 1 j 0; Qk 1/ dxk 1 dqk 1I
(A.52)
and for conditional distribution models, Equations (9.53) in Corollary 9.18
give
 k D
Z
xk p.xk j xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk dxk 1;
P xx
k D
Z
.xk 1   Qmk 1/ .xk    k /T
 p.xk j xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk dxk 1;
P x
k D
Z
.xk    k / .xk    k /T
 p.xk j xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk dxk 1:
(A.53)
Theorem 9.16 also implies that we can use the conditional moments for-
mulation to obtain alternative expressions for  k , P xx
k , and P x
k. Introducing

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.9 Conditional Moments Used in SLR
369
 k .xk 1/ D EŒxk j xk 1 and P x
k.xk 1/ D CovŒxk j xk 1, it holds that
 k D
Z
 k .xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk 1;
P xx
k D
Z
.xk 1   Qmk 1/ . k .xk 1/    k /T
 N.xk 1 j Qmk 1; QPk 1/ dxk 1;
P x
k D
Z
. k .xk 1/    k / . k .xk 1/    k /T
 N.xk 1 j Qmk 1; QPk 1/ dxk 1
C
Z
P x
k.xk 1/ N.xk 1 j Qmk 1; QPk 1/ dxk 1:
(A.54)
For additive noise models,  k .xk 1/ D f.xk 1/ and P x
k.xk 1/ D Qk 1,
and (A.54) simpliﬁes to (A.51). For non-additive noise models, Equa-
tions (9.51) in Corollary 9.17 imply that
 k .xk 1/ D
Z
f.xk 1; qk 1/ N.qk 1 j 0; Qk 1/ dqk 1;
P x
k.xk 1/ D
Z
.f.xk 1; qk 1/    k .xk 1//
 .f.xk 1; qk 1/    k .xk 1//T N.qk 1 j 0; Qk 1/ dqk 1:
(A.55)
Finally, for conditional distribution models, Equations (9.54) in Corol-
lary 9.18 give
 k .xk 1/ D
Z
xk p.xk j xk 1/ dxk;
P x
k.xk 1/ D
Z
.xk    k .xk 1// .xk    k .xk 1//T p.xk j xk 1/ dxk:
(A.56)
In total, the above equations present ﬁve different alternatives to compute
the moments  k , P xx
k , and P x
k that we need to approximate the dynamic
model using SLR.
Similarly, we can use SLR to approximate the measurement model as
yk ' Hk xk C bk C vk;
(A.57)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
370
Additional Material
where vk  N.0; k/. If xk  N. Qmk; QPk/, it holds that
Hk D .P xy
k /T QP  1
k ;
bk D C
k   Hk Qmk;
k D P y
k   Hk QPk HT
k;
(A.58)
where we can obtain ﬁve different expressions for C
k D EŒyk, P xy
k
D
CovŒxk; yk, and P y
k D CovŒyk from Theorem 9.16 and Corollaries 9.14,
9.17, and 9.18. For additive noise models, Corollary 9.14 implies that
C
k D
Z
h.xk/ N.xk j Qmk; QPk/ dxk;
P xy
k D
Z
.xk   Qmk/ .h.xk/   C
k /T N.xk j Qmk; QPk/ dxk;
P y
k D
Z
.h.xk/   C
k / .h.xk/   C
k /T N.xk j Qmk; QPk/ dxk C RkI
(A.59)
for non-additive noise models, Equations (9.50) in Corollary 9.17 give
C
k D
Z
h.xk; rk/ N.xk j Qmk; QPk/ N.rk j 0; Rk/ dxk drk;
P xy
k D
Z
.xk   Qmk/ .h.xk; rk/   C
k /T
 N.xk j Qmk; QPk/ N.rk j 0; Rk/ dxk drk;
P y
k D
Z
.h.xk; rk/   C
k / .h.xk; rk/   C
k /T
 N.xk j Qmk; QPk/ N.rk j 0; Rk/ dxk drkI
(A.60)
and for conditional distribution models, Equations (9.53) in Corollary 9.18
give
C
k D
Z
yk p.yk j xk/ N.xk j Qmk; QPk/ dyk dxk;
P xy
k D
Z
.xk   Qmk/ .yk   C
k /T p.yk j xk/ N.xk j Qmk; QPk/ dyk dxk;
P y
k D
Z
.yk   C
k / .yk   C
k /T p.yk j xk/ N.xk j Qmk; QPk/ dyk dxk:
(A.61)
The conditional moments formulation provides two more expressions
for the required moments. Introducing C
k .xk/ D EŒyk
j xk and

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.10 Parameter Derivatives for the Kalman Filter
371
P y
k.xk/ D CovŒyk j xk, Theorem 9.16 gives that
C
k D
Z
C
k .xk/ N.xk j Qmk; QPk/ dxk;
P xy
k D
Z
.xk   Qmk/ .C
k .xk/   C
k /T N.xk j Qmk; QPk/ dxk;
P y
k D
Z
.C
k .xk/   C
k / .C
k .xk/   C
k /T N.xk j Qmk; QPk/ dxk
C
Z
P y
k.xk/ N.xk j Qmk; QPk/ dxk:
(A.62)
For additive noise models, C
k .xk/ D h.xk/ and P y
k.xk/ D Rk, which
means that (A.62) simpliﬁes to (A.59). For non-additive noise models,
Equations (9.51) in Corollary 9.17 imply that
C
k .xk/ D
Z
h.xk; rk/ N.rk j 0; Rk/ drk;
P y
k.xk/ D
Z
.h.xk; rk/   C
k .xk// .h.xk; rk/   C
k .xk//T
 N.rk j 0; Rk/ drkI
(A.63)
and, ﬁnally, for conditional distribution models, Equations (9.54) in Corol-
lary 9.18 give
C
k .xk/ D
Z
yk p.yk j xk/ dyk;
P y
k.xk/ D
Z
.yk   C
k .xk// .yk   C
k .xk//T p.yk j xk/ dyk:
(A.64)
We have now presented ﬁve different alternatives for computing the mo-
ments C
k , P xy
k , and P y
k, which are required to approximate the measure-
ment model using SLR.
A.10 Parameter Derivatives for the Kalman Filter
Theorem 16.9 gives the energy function (i.e., the negative logarithm of the
unnormalized posterior distribution) of the parameters for the following
linear Gaussian model:
xk D A./ xk 1 C qk 1;
yk D H./ xk C rk;
(A.65)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
372
Additional Material
where qk 1  N.0; Q.//, rk  N.0; R.//, and x0  N.m0./; P0.//.
The parameters’ derivatives, which are needed, for example, for imple-
menting a gradient-based optimization method for ﬁnding ML or MAP
estimates, can be evaluated via the following sensitivity equations (Gupta
and Mehra, 1974), which can be derived by termwise differentiation of the
energy function and Kalman ﬁlter equations in Theorem 16.9.
Theorem A.10 (Energy function derivative for linear Gaussian model I).
The derivative of the energy function given in Theorem 16.9 can be com-
puted via the following recursion along with Kalman ﬁltering:
@'k./
@i
D @'k 1./
@i
C 1
2 tr

S 1
k ./ @Sk./
@i

C v T
k ./ S 1
k ./ @vk./
@i
  1
2v T
k ./ S 1
k ./ @Sk./
@i
S 1
k ./ vk./;
(A.66)
where on the Kalman ﬁlter prediction step, we compute
@m k ./
@i
D @A./
@i
mk 1./ C A./ @mk 1./
@i
;
@P  k ./
@i
D @A./
@i
Pk 1./ AT./ C A./ @Pk 1./
@i
AT./
C A./ Pk 1./ @AT./
@i
C @Q./
@i
;
(A.67)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.10 Parameter Derivatives for the Kalman Filter
373
and on the Kalman ﬁlter update step, we compute
@vk./
@i
D  @H./
@i
m k ./   H./ @m k ./
@i
;
@Sk./
@i
D @H./
@i
P  k ./ HT./ C H./ @P  k ./
@i
HT./
C H./ P  k ./ @HT./
@i
C @R./
@i
;
@Kk./
@i
D @P  k ./
@i
HT./ S 1
k ./ C P  k ./ @HT./
@i
S 1
k ./
  P  k ./ HT./ S 1
k ./ @Sk./
@i
S 1
k ./;
@mk./
@i
D @m k ./
@i
C @Kk./
@i
vk./ C Kk./ @vk./
@i
;
@Pk./
@i
D @P  k ./
@i
  @Kk./
@i
Sk./ KT
k./
  Kk./ @Sk./
@i
KT
k./   Kk./ Sk./ @KT
k./
@i
:
(A.68)
The recursion should be started from the initial condition @'0./=@ D
  @ log p./=@ .
Another way to compute the same derivative is by using Fisher’s identity
(Equation 16.32) together with the expression for Q in Theorem 16.11. The
result is the following.
Theorem A.11 (Energy function derivative for linear Gaussian model II).
The derivative of the energy function given in Theorem 16.9 can be com-
puted as
@'T ./
@
D  @ log p./
@
  @Q.; .n//
@
ˇˇˇˇ
.n/D
;
(A.69)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
374
Additional Material
where
@Q.; .n//
@i
ˇˇˇˇ
.n/D
D  1
2 tr

P  1
0
@P0
@i

  T
2 tr

Q 1 @Q
@i

  T
2 tr

R 1 @R
@i

C 1
2 tr
(
P  1
0
@P0
@i
P  1
0
h
P s
0 C .ms
0   m0/ .ms
0   m0/Ti)
C 1
2 tr
(
P  1
0
"
@m0
@i
.ms
0   m0/T C .ms
0   m0/ @mT
0
@i
#)
C T
2 tr
(
Q 1 @Q
@i
Q 1 h
†   C AT   A CT C A ˆ ATi)
  T
2 tr
(
Q 1
"
  C @AT
@i
  @A
@i
CT C @A
@i
ˆ AT C A ˆ @AT
@i
#)
C T
2 tr
(
R 1 @R
@i
R 1 h
D   B HT   H BT C H † HTi)
  T
2 tr
(
R 1
"
  B @HT
@i
  @H
@i
BT C @H
@i
† HT C H † @HT
@i
#)
;
(A.70)
where all the terms are evaluated at .
A.11 Parameter Derivatives for the Gaussian Filter
In this section we consider the computation of the gradient of the Gaussian
ﬁltering-based energy function in Algorithm 16.14, which was considered
with models of the form
xk D f.xk 1; / C qk 1;
yk D h.xk; / C rk:
(A.71)
In order to compute the derivative, it is convenient to ﬁrst rewrite the ex-
pectations as expectations over unit Gaussian distributions as follows:
m k ./ D
Z
f.xk 1; / N.xk 1 j mk 1./; Pk 1.// dxk 1
D
Z
f.mk 1./ C
p
Pk 1./ ; / N. j 0; I/ d:
(A.72)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.11 Parameter Derivatives for the Gaussian Filter
375
The derivative of this expression can now be computed as
@m k ./
@i
D
Z "
Fx.mk 1./ C
p
Pk 1./ ; /

 
@mk 1./
@i
C @
p
Pk 1./
@i

!
C @f
@i
.mk 1./ C
p
Pk 1./ ; /
#
N. j 0; I/ d:
Assuming that we are using the Cholesky factorization-based matrix square
root, the derivative @
p
Pk 1./=@i can be computed with Algorithm A.7
or Theorem A.8 given in Section A.3.
The above form is directly suitable for sigma point methods, because
they are based on the same change of variables. That is, the corresponding
derivative of the sigma point approximation will be
@m k ./
@i

X
j
Wj
"
Fx.mk 1./ C
p
Pk 1./ .j /; /

 
@mk 1./
@i
C @
p
Pk 1./
@i
.j /
!
C @f
@i
.mk 1./ C
p
Pk 1./ .j /; /
#
;
(A.73)
where Wj and .j/ are the weights and unit sigma points of the used sigma
point method. A nice thing in the above expression is that it is exactly the
derivative of the sigma point approximation to m k ./.
The derivatives of the Gaussian ﬁltering-based energy function can now
be expressed as follows.
Algorithm A.12 (Derivatives of Gaussian ﬁltering-based energy function).
The recursion for the derivative of the approximate energy function is
@'k./
@i
' @'k 1./
@i
C 1
2 tr

S 1
k ./ @Sk./
@i

C v T
k ./ S 1
k ./ @vk./
@i
  1
2v T
k ./ S 1
k ./ @Sk./
@i
S 1
k ./ vk./:
(A.74)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
376
Additional Material
The derivatives of the prediction step are
@m k
@i
D
Z "
Fx

mk 1 C
p
Pk 1 ; 
 @mk 1
@i
C @pPk 1
@i


C @f
@i

mk 1 C
p
Pk 1 ; 
 #
N. j 0; I/ d;
@P  k
@i
D
Z "
Fx

mk 1 C
p
Pk 1 ; 
 @mk 1
@i
C @pPk 1
@i


C @f
@i

mk 1 C
p
Pk 1 ; 

  @m k
@i
#

"
f

mk 1 C
p
Pk 1 ; 

  m k
#T
N. j 0; I/ d
C
Z "
f

mk 1 C
p
Pk 1 ; 

  m k
#

"
Fx

mk 1 C
p
Pk 1 ; 
 @mk 1
@i
C @pPk 1
@i


C @f
@i

mk 1 C
p
Pk 1 ; 

  @m k
@i
#T
N. j 0; I/ d C @Qk 1
@i
;
(A.75)
where Fx is the Jacobian matrix of x 7! f.x; /. In the above expressions
as well as in the following, we have dropped the dependencies of various
terms on the parameters  to simplify the notation. The derivatives of the
update step are
@k
@i
D
Z "
Hx

m k C
q
P  k ; 
  
@m k
@i
C @pP  k
@i

!
C @h
@i

m k C
q
P  k ; 
 #
N. j 0; I/ d;
@vk
@i
D  @k
@i
;
@Sk
@i
D
Z "
Hx

m k C
q
P  k ; 
  
@m k
@i
C @pP  k
@i

!

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
A.11 Parameter Derivatives for the Gaussian Filter
377
C @h
@i

m k C
q
P  k ; 

  @k
@i
#

"
h

m k C
q
P  k ; 

  k
#T
N. j 0; I/ d
C
Z "
h

m k C
q
P  k ; 

  k
#

"
Hx

m k C
q
P  k ; 
  
@m k
@i
C @pP  k
@i

!
C @h
@i

m k C
q
P  k ; 

  @k
@i
#T
N. j 0; I/ d C @Rk
@i
;
@Ck
@i
D
Z (
@pP  k
@i

 
h

m k C
q
P  k ; 

  k
!T
C
q
P  k 
"
Hx

m k C
q
P  k ; 
  
@m k
@i
C @pP  k
@i

!
C @h
@i

m k C
q
P  k ; 

  @k
@i
#T)
N. j 0; I/ d;
@Kk
@i
D @Ck
@i
S 1
k
  Ck S 1
k
@Sk
@i
S 1
k ;
@mk
@i
D @m k
@i
C @Kk
@i
vk C Kk
@vk
@i
;
@Pk
@i
D @P  k
@i
  @Kk
@i
Sk KT
k   Kk
@Sk
@i
KT
k   Kk Sk
@KT
k
@i
;
(A.76)
where Hx is the Jacobian matrix of x 7! h.x; /. The derivatives of the
Cholesky factors can be computed with Algorithm A.7 or Theorem A.8
given in Section A.3.
The corresponding sigma point approximations can be obtained by ap-
proximating the integrals analogously to Equation (A.73). The resulting
derivative will be exact in the sense that it is the exact derivative of the
corresponding sigma point-based approximation to the energy function.
We could also change back to the original variable, which gives, for
example, the following representation for the derivative of the predicted

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
378
Additional Material
mean:
@m k
@i
D
Z "
Fx.xk 1; / g.xk 1; / C @f.xk 1; /
@i
#
 N.xk 1 j mk 1; Pk 1/ dxk 1;
(A.77)
where
g.xk 1; /
D @mk 1
@i
C @pPk 1
@i
p
Pk 1
 1
.xk 1   mk 1/ :
(A.78)
The derivation of the full set of equations is left as an exercise for the
reader.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
Agamennoni, G., Nieto, J., and Nebot, E. 2011. An outlier-robust Kalman ﬁlter. Pages
1551–1558 of: IEEE International Conference on Robotics and Automation (ICRA).
(Cited on page 353.)
Akashi, H., and Kumamoto, H. 1977. Random sampling approach to state estimation in
switching environments. Automatica, 13(4), 429–434. (Cited on pages 247 and 353.)
Alspach, D. L., and Sorenson, H. W. 1972. Nonlinear Bayesian estimation using Gaus-
sian sum approximations. IEEE Transactions on Automatic Control, 17(4). (Cited
on page 353.)
Anderson, B. D. O., and Moore, J. B. 1979. Optimal Filtering. Prentice-Hall. (Cited
on page 102.)
Andrieu, C., De Freitas, N., and Doucet, A. 2002. Rao-Blackwellised particle ﬁltering
via data augmentation. In: Dietterich, T. G., Becker, S., and Ghahramani, Z. (eds),
Advances in Neural Information Processing Systems 14.
MIT Press.
(Cited on
page 7.)
Andrieu, C., Doucet, A., Singh, S., and Tadic, V. 2004. Particle methods for change
detection, system identiﬁcation, and control. Proceedings of the IEEE, 92(3), 423–
438. (Cited on pages 341 and 344.)
Andrieu, C., and Thoms, J. 2008. A tutorial on adaptive MCMC. Statistics and Com-
puting, 18(4), 343–373. (Cited on page 325.)
Andrieu, C., Doucet, A., and Holenstein, R. 2010. Particle Markov chain Monte Carlo
methods. The Royal Statistical Society: Series B (Statistical Methodology), 72(3),
269–342. (Cited on pages 324 and 342.)
Aoki, M. 1967. Optimization of Stochastic Systems. Academic Press. (Cited on page 6.)
Arasaratnam, I., and Haykin, S. 2009. Cubature Kalman ﬁlters. IEEE Transactions on
Automatic Control, 54(6), 1254–1269. (Cited on pages 131, 135, 142, 143, 145, 149,
165, 280, 289, and 353.)
Arasaratnam, I., and Haykin, S. 2011.
Cubature Kalman smoothers.
Automatica,
47(10), 2245–2250. (Cited on pages 282 and 353.)
Arasaratnam, I., Haykin, S., and Elliott, R. J. 2007. Discrete-time nonlinear ﬁltering
algorithms using Gauss–Hermite quadrature. Proceedings of the IEEE, 95(5), 953–
977. (Cited on pages 140, 168, 179, and 187.)
Arasaratnam, I., Haykin, S., and Hurd, T. R. 2010.
Cubature Kalman ﬁltering for
continuous-discrete systems: Theory and simulations. IEEE Transactions on Signal
Processing, 58(10), 4977–4993. (Cited on page 352.)
379

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
380
References
Arulampalam, M. S., Maskell, S., Gordon, N., and Clapp, T. 2002. A tutorial on particle
ﬁlters for online nonlinear/non-Gaussian Bayesian tracking. IEEE Transactions on
Signal Processing, 50(2), 174–188. (Cited on page 244.)
Axelsson, P., and Gustafsson, F. 2015. Discrete-time solutions to the continuous-time
differential Lyapunov equation with applications to Kalman ﬁltering. IEEE Trans-
actions on Automatic Control, 60(3), 632–643. (Cited on page 52.)
Bar-Shalom, Y., and Li, X.-R. 1995. Multitarget-Multisensor Tracking: Principles and
Techniques. YBS Publishing. (Cited on pages 3 and 353.)
Bar-Shalom, Y., Li, X.-R., and Kirubarajan, T. 2001. Estimation with Applications to
Tracking and Navigation. Wiley. (Cited on pages 2, 4, 8, 44, 113, 201, 352, and 353.)
Barber, D. 2006. Expectation correction for smoothed inference in switching linear
dynamical systems.
The Journal of Machine Learning Research, 7, 2515–2540.
(Cited on pages 317 and 352.)
Barber, D. 2011. Approximate inference in switching linear dynamical systems using
Gaussian mixtures.
Chap. 8, pages 166–181 of: Barber, D., Cemgil, A. T., and
Chiappa, S. (eds), Bayesian Time Series Models. Cambridge University Press. (Cited
on page 353.)
Barfoot, T. D. 2017. State Estimation for Robotics. Cambridge University Press. (Cited
on page 5.)
Barlas, G. 2015. Multicore and GPU Programming: An Integrated Approach. Morgan
Kaufmann Publishers Inc. (Cited on page 353.)
Bell, B. M. 1994. The iterated Kalman smoother as a Gauss–Newton method. SIAM
Journal on Optimization, 4(3), 626–636. (Cited on pages 271 and 275.)
Bell, B. M., and Cathey, F. W. 1993. The iterated Kalman ﬁlter update as a Gauss–
Newton method. IEEE Transactions on Automatic Control, 38(2), 294–297. (Cited
on page 121.)
Berger, J. O. 1985. Statistical Decision Theory and Bayesian Analysis. Springer. (Cited
on pages 20, 21, and 247.)
Bernardo, J. M., and Smith, A. F. M. 1994. Bayesian Theory. Wiley. (Cited on pages 17
and 20.)
Bierman, G. J. 1977. Factorization Methods for Discrete Sequential Estimation. Aca-
demic Press. (Cited on page 353.)
Bishop, C. M. 2006. Pattern Recognition and Machine Learning. Springer. (Cited on
pages 7, 81, and 84.)
Blackman, S., and Popoli, R. 1999. Design and Analysis of Modern Tracking Systems.
Artech House Radar Library. (Cited on pages 3 and 353.)
Brooks, S., Gelman, A., Jones, G. L., and Meng, X.-L. 2011. Handbook of Markov
Chain Monte Carlo. Chapman & Hall/CRC. (Cited on pages 23, 324, 325, and 326.)
Capp´e, O., Moulines, E., and Ryd´en, T. 2005. Inference in Hidden Markov Models.
Springer. (Cited on pages 87, 241, 262, 323, 330, and 334.)
Challa, S., Morelande, M. R., Muˇsicki, D., and Evans, R. J. 2011. Fundamentals of
Object Tracking. Cambridge University Press. (Cited on pages 2 and 353.)
Chen, R., and Liu, J. S. 2000. Mixture Kalman ﬁlters. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 62(3), 493–508. (Cited on page 247.)
Chopin, N., and Papaspiliopoulos, O. 2020. An Introduction to Sequential Monte Carlo.
Springer. (Cited on pages 238, 239, 240, 312, and 314.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
381
Christianson, B. 1994. Reverse accumulation and attractive ﬁxed points. Optimization
Methods and Software, 3(4), 311–326. (Cited on page 340.)
Corenﬂos, A., Chopin, N., and S¨arkk¨a, S. 2022. De-Sequentialized Monte Carlo: a
parallel-in-time particle smoother. Journal of Machine Learning Research, 23(283),
1–39. (Cited on page 354.)
Cox, H. 1964. On the estimation of state variables and parameters for noisy dynamic
systems. IEEE Transactions on Automatic Control, 9(1), 5–12. (Cited on page 267.)
Crassidis, J. L., and Junkins, J. L. 2004.
Optimal Estimation of Dynamic Systems.
Chapman & Hall/CRC. (Cited on page 2.)
Creal, D. 2012. A survey of sequential Monte Carlo methods for economics and ﬁnance.
Econometric Reviews, 31(3), 245–296. (Cited on page 341.)
Crisan, D., and Doucet, A. 2002. A survey of convergence results on particle ﬁltering
for practitioners. IEEE Transactions on Signal Processing, 50(3), 736–746. (Cited
on page 353.)
Crisan, D., and Rozovskii, B. (eds). 2011. The Oxford Handbook of Nonlinear Filtering.
Oxford University Press. (Cited on page 352.)
Daum, F., and Huang, J. 2003. Curse of dimensionality and particle ﬁlters. Pages
1979–1993 of: Proceedings of the IEEE Aerospace Conference, vol. 4. (Cited on
page 230.)
Deisenroth, M. P., Huber, M. F., and Hanebeck, U. D. 2009. Analytic moment-based
Gaussian process ﬁltering. Pages 225–232 of: Proceedings of the 26th International
Conference on Machine Learning. (Cited on pages 135 and 352.)
Deisenroth, M., Turner, R., Huber, M., Hanebeck, U., and Rasmussen, C. 2012. Robust
ﬁltering and smoothing with Gaussian processes. IEEE Transactions on Automatic
Control, 57(7), 1865–1871. (Cited on page 352.)
Dempster, A., Laird, N., and Rubin, D. 1977.
Maximum likelihood from incom-
plete data via the EM algorithm. Journal of the Royal Statistical Society: Series
B (Methodological), 39(1), 1–38. (Cited on page 327.)
Djuric, P., and Miguez, J. 2002. Sequential particle ﬁltering in the presence of additive
Gaussian noise with unknown parameters. Pages 1621–1624 of: IEEE International
Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 2. (Cited
on page 347.)
Douc, R., Garivier, A., Moulines, E., and Olsson, J. 2011. Sequential Monte Carlo
smoothing for general state space hidden Markov models. Annals of Applied Prob-
ability, 21(6), 2109–2145. (Cited on pages 312 and 314.)
Doucet, A., and Johansen, A. M. 2011. A tutorial on particle ﬁltering and smoothing:
Fifteen years later. Chap. 24, pages 656–704 of: Crisan, D., and Rozovski˘i, B. (eds),
Handbook of Nonlinear Filtering. Oxford University Press. (Cited on page 244.)
Doucet, A., Godsill, S. J., and Andrieu, C. 2000. On sequential Monte Carlo sampling
methods for Bayesian ﬁltering. Statistics and Computing, 10(3), 197–208. (Cited on
pages 241, 309, and 314.)
Doucet, A., De Freitas, N., and Gordon, N. 2001. Sequential Monte Carlo Methods in
Practice. Springer. (Cited on pages 234, 239, 241, 247, and 248.)
Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. 1987. Hybrid Monte
Carlo. Physics Letters B, 195(2), 216–222. (Cited on page 326.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
382
References
Fatemi, M., Svensson, L., Hammarstrand, L., and Morelande, M. 2012. A study of
MAP estimation techniques for nonlinear ﬁltering. Pages 1058–1065 of: 15th Inter-
national Conference on Information Fusion (FUSION). (Cited on page 126.)
Fearnhead, P. 2002. Markov chain Monte Carlo, sufﬁcient statistics, and particle ﬁl-
ters. Journal of Computational and Graphical Statistics, 11(4), 848–862. (Cited on
page 347.)
Fearnhead, P., and Clifford, P. 2003. On-line inference for Hidden Markov models
via particle ﬁlters.
Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 65(4), 887–899. (Cited on page 241.)
Fong, W., Godsill, S. J., Doucet, A., and West, M. 2002. Monte Carlo smoothing with
application to audio signal enhancement. IEEE Transactions on Signal Processing,
50(2), 438–449. (Cited on pages 6 and 317.)
Fraser, D., and Potter, J. 1969. The optimum linear smoother as a combination of two
optimum linear ﬁlters. IEEE Transactions on Automatic Control, 14(4), 387–390.
(Cited on page 255.)
Garc´ıa-Fern´andez, ´A. F., Svensson, L., Morelande, M., and S¨arkk¨a, S. 2015. Poste-
rior linearization ﬁlter: Principles and implementation using sigma points. IEEE
Transactions on Signal Processing, 63(20), 5561–5573. (Cited on pages 204, 208,
and 226.)
Garc´ıa-Fern´andez, ´A. F., Svensson, L., and S¨arkk¨a, S. 2017. Iterated posterior lineariza-
tion smoother. IEEE Transactions on Automatic Control, 62(4), 2056–2063. (Cited
on page 297.)
Garc´ıa-Fern´andez, ´A. F., Tronarp, F., and S¨arkk¨a, S. 2019. Gaussian process classiﬁca-
tion using posterior linearisation. IEEE Signal Processing Letters, 26(5), 735–739.
(Cited on page 82.)
Garc´ıa-Fern´andez, ´A. F., Svensson, L., and Morelande, M. R. 2020. Multiple target
tracking based on sets of trajectories. IEEE Transactions on Aerospace and Elec-
tronic Systems, 56(3), 1685–1707. (Cited on page 353.)
Garc´ıa-Fern´andez, ´A. F., Williams, J. L., Svensson, L., and Xia, Y. 2021. A Poisson
multi-Bernoulli mixture ﬁlter for coexisting point and extended targets. IEEE Trans-
actions on Signal Processing, 69, 2600–2610. (Cited on page 353.)
Gelb, A. 1974. Applied Optimal Estimation. MIT Press. (Cited on pages 119, 121, 171,
and 176.)
Gelb, A., and Vander Velde, W. 1968. Multiple-Input Describing Functions and Non-
linear System Design. McGraw-Hill. (Cited on page 178.)
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B.
2013.
Bayesian Data Analysis. Third edn.
Chapman & Hall/CRC.
(Cited on
pages 17, 19, 22, 40, 108, and 323.)
Gilks, W., Richardson, S., and Spiegelhalter, D. (eds). 1996. Markov Chain Monte
Carlo in Practice. Chapman & Hall. (Cited on page 23.)
Godsill, S. J., and Rayner, P. J. 1998. Digital Audio Restoration: A Statistical Model
Based Approach. Springer-Verlag. (Cited on page 6.)
Godsill, S. J., Doucet, A., and West, M. 2004. Monte Carlo smoothing for nonlinear
time series.
Journal of the American Statistical Association, 99(465), 156–168.
(Cited on page 310.)
Golub, G. H., and van Loan, C. F. 1996. Matrix Computations. Third edn. The Johns
Hopkins University Press. (Cited on page 357.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
383
Golub, G. H., and Welsch, J. H. 1969. Calculation of Gauss quadrature rules. Mathe-
matics of Computation, 23(106), 221–230. (Cited on page 138.)
Gonzalez, R. C., and Woods, R. E. 2008. Digital Image Processing. Third edn. Prentice
Hall. (Cited on page 7.)
Gordon, N. J., Salmond, D. J., and Smith, A. F. M. 1993.
Novel approach to
nonlinear/non-Gaussian Bayesian state estimation. Pages 107–113 of: IEEE Pro-
ceedings on Radar and Signal Processing, vol. 140. (Cited on pages 239 and 242.)
Granstr¨om, K., Fatemi, M., and Svensson, L. 2020.
Poisson multi-Bernoulli mix-
ture conjugate prior for multiple extended target ﬁltering. IEEE Transactions on
Aerospace and Electronic Systems, 56(1), 208–225. (Cited on page 353.)
Grewal, M. S., and Andrews, A. P. 2015. Kalman Filtering: Theory and Practice Using
MATLAB. 4th edn. Wiley. (Cited on pages 98, 113, and 353.)
Grewal, M. S., Weill, L. R., and Andrews, A. P. 2001. Global Positioning Systems,
Inertial Navigation and Integration. Wiley. (Cited on pages 3 and 4.)
Griewank, A., and Walther, A. 2008. Evaluating Derivatives: Principles and Tech-
niques of Algorithmic Differentiation. SIAM. (Cited on pages 117 and 127.)
Gupta, N., and Mehra, R. 1974. Computational aspects of maximum likelihood es-
timation and reduction in sensitivity function calculations. IEEE Transactions on
Automatic Control, 19(6), 774–783. (Cited on pages 334 and 372.)
Haario, H., Saksman, E., and Tamminen, J. 1999.
Adaptive proposal distribution
for random walk Metropolis algorithm. Computational Statistics, 14(3), 375–395.
(Cited on page 325.)
Haario, H., Saksman, E., and Tamminen, J. 2001. An adaptive Metropolis algorithm.
Bernoulli, 7(2), 223–242. (Cited on page 325.)
Hairer, E., Nørsett, S. P., and Wanner, G. 2008. Solving Ordinary Differential Equa-
tions I: Nonstiff Problems. Springer Series in Computational Mathematics, vol. 1.
Springer Science & Business. (Cited on page 60.)
Hartikainen, J., and S¨arkk¨a, S. 2010.
Kalman ﬁltering and smoothing solutions to
temporal Gaussian process regression models. Pages 379–384 of: Proceedings of
IEEE International Workshop on Machine Learning for Signal Processing (MLSP).
(Cited on page 7.)
Hassan, S., S¨arkk¨a, S., and Garc´ıa-Fern´andez, A. F. 2021. Temporal parallelization of
inference in hidden Markov models. IEEE Transactions on Signal Processing, 69,
4875–4887. (Cited on page 354.)
Hauk, O. 2004. Keep it simple: A case for using classical minimum norm estimation
in the analysis of EEG and MEG data. NeuroImage, 21(4), 1612–1621. (Cited on
page 5.)
Hayes, M. H. 1996. Statistical Digital Signal Processing and Modeling. Wiley. (Cited
on pages 7 and 86.)
Haykin, S. 2001. Kalman Filtering and Neural Networks. Wiley. (Cited on pages 7
and 85.)
Hennig, P., Osborne, M. A., and Kersting, H. P. 2022. Probabilistic Numerics. Cam-
bridge University Press. (Cited on page 352.)
Hiltunen, P., S¨arkk¨a, S., Nissil¨a, I., Lajunen, A., and Lampinen, J. 2011. State space
regularization in the nonstationary inverse problem for diffuse optical tomography.
Inverse Problems, 27, 025009. (Cited on page 5.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
384
References
Ho, Y. C., and Lee, R. C. K. 1964. A Bayesian approach to problems in stochastic
estimation and control. IEEE Transactions on Automatic Control, 9(4), 333–339.
(Cited on page 8.)
Hostettler, R., Tronarp, F., Garc´ıa-Fern´andez, ´A. F., and S¨arkk¨a, S. 2020. Importance
densities for particle ﬁltering using iterated conditional expectations. IEEE Signal
Processing Letters, 27, 211–215. (Cited on page 241.)
Hu, X., Sch¨on, T., and Ljung, L. 2008. A basic convergence result for particle ﬁltering.
IEEE Transactions on Signal Processing, 56(4), 1337–1348. (Cited on page 353.)
Hu, X., Sch¨on, T., and Ljung, L. 2011.
A general convergence result for particle
ﬁltering. IEEE Transactions on Signal Processing, 59(7), 3424–3429. (Cited on
page 353.)
H¨urzeler, M., and Kunsch, H. R. 1998. Monte Carlo approximations for general state-
space models. Journal of Computational and Graphical Statistics, 7(2), 175–193.
(Cited on page 314.)
Ito, K., and Xiong, K. 2000. Gaussian ﬁlters for nonlinear ﬁltering problems. IEEE
Transactions on Automatic Control, 45(5), 910–927. (Cited on pages 131, 133, 135,
140, 165, 280, and 289.)
Jazwinski, A. H. 1966. Filtering for nonlinear dynamical systems. IEEE Transactions
on Automatic Control, 11(4), 765–766. (Cited on page 8.)
Jazwinski, A. H. 1970. Stochastic Processes and Filtering Theory. Academic Press.
(Cited on pages xi, 8, 113, and 351.)
Johansen, A. M., and Doucet, A. 2008. A note on auxiliary particle ﬁlters. Statistics &
Probability Letters, 78(12), 1498–1504. (Cited on pages 244, 246, and 247.)
Julier, S. J. 2002. The scaled unscented transformation. Pages 4555–4559 of: Pro-
ceedings of the 2002 American Control Conference, vol. 6. (Cited on pages 150
and 152.)
Julier, S. J., and Uhlmann, J. K. 1995. A General Method of Approximating Nonlinear
Transformations of Probability Distributions. Tech. rept. Robotics Research Group,
Department of Engineering Science, University of Oxford. (Cited on pages 131,
135, 150, and 152.)
Julier, S. J., and Uhlmann, J. K. 2004. Unscented ﬁltering and nonlinear estimation.
Proceedings of the IEEE, 92(3), 401–422. (Cited on pages 150, 155, 157, and 159.)
Julier, S. J., Uhlmann, J. K., and Durrant-Whyte, H. F. 1995. A new approach for
ﬁltering nonlinear systems. Pages 1628–1632 of: Proceedings of the 1995 American
Control, Conference, Seattle, Washington. (Cited on pages 149, 155, and 159.)
Julier, S. J., Uhlmann, J. K., and Durrant-Whyte, H. F. 2000. A new method for the
nonlinear transformation of means and covariances in ﬁlters and estimators. IEEE
Transactions on Automatic Control, 45(3), 477–482. (Cited on pages 131, 135, 150,
165, 187, and 289.)
Kailath, T., Sayed, A. H., and Hassibi, B. 2000. Linear Estimation. Prentice Hall.
(Cited on pages 102 and 353.)
Kaipio, J., and Somersalo, E. 2005. Statistical and Computational Inverse Problems.
Applied Mathematical Sciences, no. 160. Springer. (Cited on pages 5 and 7.)
Kalman, R. E. 1960a. Contributions to the theory of optimal control. Boletin de la
Sociedad Matematica Mexicana, 5(1), 102–119. (Cited on page 8.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
385
Kalman, R. E. 1960b. A new approach to linear ﬁltering and prediction problems.
Transactions of the ASME, Journal of Basic Engineering, 82(1), 35–45. (Cited on
pages 8, 16, 96, and 101.)
Kalman, R. E., and Bucy, R. S. 1961. New results in linear ﬁltering and prediction
theory. Transactions of the ASME, Journal of Basic Engineering, 83(3), 95–108.
(Cited on page 8.)
Kantas, N., Doucet, A., Singh, S., and Maciejowski, J. 2009. An overview of sequential
Monte Carlo methods for parameter estimation in general state-space models. In:
Proceedings IFAC Symposium on System Identiﬁcation (SYSID). (Cited on pages 343
and 344.)
Kaplan, E. D. 1996. Understanding GPS, Principles and Applications. Artech House.
(Cited on page 2.)
Karvonen, T., and S¨arkk¨a, S. 2018. Fully symmetric kernel quadrature. SIAM Journal
on Scientiﬁc Computing, 40(2), A697–A720. (Cited on page 352.)
Karvonen, T., S¨arkk¨a, S., and Oates, C. J. 2019.
Symmetry exploits for Bayesian
cubature methods. Statistics and Computing, 29, 1231–1248. (Cited on pages 135,
165, 290, and 352.)
Keeling, M., and Rohani, P. 2007. Modeling Infectious Diseases in Humans and Ani-
mals. Princeton University Press. (Cited on page 5.)
Kim, C.-J. 1994. Dynamic linear models with Markov-switching. Journal of Econo-
metrics, 60, 1–22. (Cited on page 317.)
Kitagawa, G. 1987. Non-Gaussian state-space modeling of nonstationary time series.
Journal of the American Statistical Association, 82(400), 1032–1041.
(Cited on
page 254.)
Kitagawa, G. 1994. The two-ﬁlter formula for smoothing and an implementation of the
Gaussian-sum smoother. Annals of the Institute of Statistical Mathematics, 46(4),
605–623. (Cited on page 255.)
Kitagawa, G. 1996. Monte Carlo ﬁlter and smoother for non-Gaussian nonlinear state
space models. Journal of Computational and Graphical Statistics, 5(1), 1–25. (Cited
on pages 239, 308, 309, and 311.)
Kloeden, P. E., and Platen, E. 1999.
Numerical Solution to Stochastic Differential
Equations. Springer. (Cited on pages 57, 58, and 69.)
Kokkala, J., Solin, A., and S¨arkk¨a, S. 2016.
Sigma-Point Filtering and Smoothing
Based Parameter Estimation in Nonlinear Dynamic Systems. Journal of Advances
in Information Fusion, 11(1), 15–30. (Cited on page 327.)
Koller, D., and Friedman, N. 2009. Probabilistic Graphical Models: Principles and
Techniques. MIT Press. (Cited on pages 255 and 264.)
Kotz, S., and Nadarajah, S. 2004. Multivariate T-Distributions and Their Applications.
Cambridge University Press. (Cited on page 78.)
Larson, R. E., and Peschon, J. 1966. A dynamic programming approach to trajectory
estimation. IEEE Transactions on Automatic Control, 11(3), 537–540. (Cited on
page 262.)
Lee, R. C. K. 1964. Optimal Estimation, Identiﬁcation and Control. MIT Press. (Cited
on page 8.)
Lefebvre, T., Bruyninckx, H., and Schutter, J. D. 2002. Comment on “A new method
for the nonlinear transformation of means and covariances in ﬁlters and estimators”

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
386
References
[and authors’ reply]. IEEE Transactions on Automatic Control, 47(8), 1406–1409.
(Cited on pages 168, 187, and 352.)
Leondes, C. T., Peller, J. B., and Stear, E. B. 1970. Nonlinear smoothing theory. IEEE
Transactions on Systems Science and Cybernetics, 6(1), 63–71. (Cited on pages 8
and 352.)
Lin, F.-H., Wald, L. L., Ahlfors, S. P., H¨am¨al¨ainen, M. S., Kwong, K. K., and Belliveau,
J. W. 2006. Dynamic magnetic resonance inverse imaging of human brain function.
Magnetic Resonance in Medicine, 56(4), 787–802. (Cited on page 5.)
Lindsten, F. 2011. Rao–Blackwellised Particle Methods for Inference and Identiﬁca-
tion. Licentiate’s thesis, Link¨oping University. (Cited on page 317.)
Lindsten, F., and Sch¨on, T. B. 2013. Backward simulation methods for Monte Carlo
statistical inference. Foundations and Trends in Machine Learning, 6(1), 1–143.
(Cited on page 310.)
Lindsten, F., Bunch, P., S¨arkk¨a, S., Sch¨on, T., and Godsill, S. 2016. Rao-Blackwellized
particle smoothers for conditionally linear Gaussian models. IEEE Journal of Se-
lected Topics in Signal Processing, 10(2), 353–365. (Cited on page 317.)
Liu, J. S. 2001. Monte Carlo Strategies in Scientiﬁc Computing. Springer. (Cited on
pages 23, 230, 231, 324, 325, and 326.)
Liu, J. S., and Chen, R. 1995. Blind deconvolution via sequential imputations. Journal
of the American Statistical Association, 90(430), 567–576. (Cited on pages 239
and 240.)
Luenberger, D. G., and Ye, Y. 2008. Linear and Nonlinear Programming. Third edn.
Springer. (Cited on pages 323 and 329.)
Luengo, D., Martino, L., Bugallo, M., Elvira, V., and S¨arkk¨a, S. 2020. A survey of
Monte Carlo methods for parameter estimation. EURASIP Journal on Advances in
Signal Processing, 2020(25), 1–62. (Cited on page 313.)
L¨utkepohl, H. 1996. Handbook of Matrices. Wiley. (Cited on page 356.)
Mahler, R. P. S. 2014. Advances in Statistical Multisource-Multitarget Information
Fusion. Artech House. (Cited on pages 3 and 353.)
Maybeck, P. 1982a. Stochastic Models, Estimation and Control. Vol. 3. Academic
Press. (Cited on pages 6 and 8.)
Maybeck, P. 1982b. Stochastic Models, Estimation and Control. Vol. 2. Academic
Press. (Cited on pages 113 and 133.)
Mbalawata, I. S., S¨arkk¨a, S., and Haario, H. 2013. Parameter estimation in stochastic
differential equations with Markov chain Monte Carlo and non-linear Kalman ﬁlter-
ing. Computational Statistics, 28(3), 1195–1223. (Cited on pages 326 and 338.)
McNamee, J., and Stenger, F. 1967. Construction of fully symmetric numerical inte-
gration formulas. Numerische Mathematik, 10, 327–344. (Cited on pages 135, 143,
162, 165, 280, 287, and 289.)
Milton, J. S., and Arnold, J. C. 1995. Introduction to Probability and Statistics, Princi-
ples and Applications for Engineering and the Computing Sciences. McGraw-Hill.
(Cited on page 17.)
Morelande, M., and Garc´ıa-Fern´andez, ´A. F. 2013. Analysis of Kalman ﬁlter approx-
imations for nonlinear measurements.
IEEE Transactions on Signal Processing,
61(22), 5477–5484. (Cited on page 124.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
387
Morf, M., L´evy, B., and Kailath, T. 1978. Square-root algorithms for the continuous-
time linear least-square estimation problem. IEEE Transactions on Automatic Con-
trol, 23(5), 907–911. (Cited on page 358.)
Murray, J. D. 1993. Mathematical Biology. Springer. (Cited on page 5.)
Murray, L., and Storkey, A. 2011. Particle smoothing in continuous time: A fast ap-
proach via density estimation.
IEEE Transactions on Signal Processing, 59(3),
1017–1026. (Cited on page 352.)
Neal, R. M. 2011.
MCMC using Hamiltonian dynamics.
Chap. 5 of: Brooks, S.,
Gelman, A., Jones, G. L., and Meng, X.-L. (eds), Handbook of Markov Chain Monte
Carlo. Chapman & Hall/CRC. (Cited on page 326.)
Neal, R., and Hinton, G. 1999. A view of the EM algorithm that justiﬁes incremen-
tal, sparse, and other variants. Pages 355–370 of: Jordan, M. I. (ed), Learning in
Graphical Models. MIT Press. (Cited on page 327.)
Ninness, B., and Henriksen, S. 2010. Bayesian system identiﬁcation via Markov chain
Monte Carlo techniques. Automatica, 46(1), 40–51. (Cited on page 324.)
Ninness, B., Wills, A., and Sch¨on, T. B. 2010. Estimation of general nonlinear state-
space systems. Pages 6371–6376 of: Proceedings of the 49th IEEE Conference on
Decision and Control (CDC), Atlanta, USA. (Cited on page 344.)
Nørgaard, M., Poulsen, N. K., and Ravn, O. 2000. New developments in state estima-
tion for nonlinear systems. Automatica, 36(11), 1627–1638. (Cited on page 352.)
Nocedal, J., and Wright, S. J. 2006. Numerical Optimization. 2nd edn. Springer. (Cited
on pages 122 and 126.)
O’Hagan, A. 1991. Bayes-Hermite quadrature. Journal of Statistical Planning and
Inference, 29(3), 245–260. (Cited on pages 135 and 352.)
Øksendal, B. 2003. Stochastic Differential Equations: An Introduction with Applica-
tions. Sixth edn. Springer–Verlag. (Cited on page 351.)
Olsson, R., Petersen, K., and Lehn-Schiøler, T. 2007. State-space models: From the EM
algorithm to a gradient approach. Neural Computation, 19(4), 1097–1111. (Cited
on pages 330 and 337.)
Pich´e, R., S¨arkk¨a, S., and Hartikainen, J. 2012. Recursive outlier-robust ﬁltering and
smoothing for nonlinear systems using the multivariate Student-t distribution. In:
Proceedings of IEEE International Workshop on Machine Learning for Signal Pro-
cessing (MLSP). (Cited on page 353.)
Pitt, M. K., and Shephard, N. 1999. Filtering via simulation: Auxiliary particle ﬁl-
ters. Journal of the American Statistical Association, 94(446), 590–599. (Cited on
pages 244, 245, and 246.)
Poyiadjis, G., Doucet, A., and Singh, S. 2011. Particle approximations of the score and
observed information matrix in state space models with application to parameter
estimation. Biometrika, 98(1), 65–80. (Cited on page 344.)
Proakis, J. G. 2001. Digital Communications. Fourth edn. McGraw-Hill. (Cited on
pages 6 and 7.)
Pr¨uher, J., Karvonen, T., Oates, C. J., Straka, O., and S¨arkk¨a, S. 2021.
Improved
calibration of numerical integration error in sigma-point ﬁlters. IEEE Transactions
on Automatic Control, 66(3), 1286–1292. (Cited on pages 135 and 352.)
Punskaya, E., Doucet, A., and Fitzgerald, W. J. 2002. On the use and misuse of par-
ticle ﬁltering in digital communications. In: Proceedings of EUSIPCO. (Cited on
page 242.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
388
References
Rabiner, L. R. 1989. A tutorial on hidden Markov models and selected applications in
speech recognition. Proceedings of the IEEE, 77(2), 257–286. (Cited on pages 87,
103, and 105.)
Raiffa, H., and Schlaifer, R. 2000. Applied Statistical Decision Theory. Wiley. (Cited
on page 20.)
Rasmussen, C. E., and Williams, C. K. I. 2006.
Gaussian Processes for Machine
Learning. MIT Press. (Cited on pages 5, 7, and 81.)
Rauch, H. E. 1963. Solutions to the linear smoothing problem. IEEE Transactions on
Automatic Control, 8(4), 371–372. (Cited on page 8.)
Rauch, H. E., Tung, F., and Striebel, C. T. 1965. Maximum likelihood estimates of
linear dynamic systems. AIAA Journal, 3(8), 1445–1450. (Cited on pages 8 and 255.)
Ristic, B., Arulampalam, S., and Gordon, N. 2004. Beyond the Kalman Filter. Artech
House. (Cited on pages 239, 241, 242, 247, and 353.)
Roberts, G. O., and Rosenthal, J. S. 2001. Optimal scaling for various Metropolis–
Hastings algorithms. Statistical Science, 16(4), 351–367. (Cited on page 325.)
Roth, M. 2012.
On the multivariate t distribution.
Tech. rept. LiTH-ISY-R-3059.
Link¨oping University Electronic Press. (Cited on pages 78 and 79.)
Roth, M., and Gustafsson, F. 2011. An efﬁcient implementation of the second order
extended Kalman ﬁlter. In: Proceedings of the 14th International Conference on
Information Fusion. (Cited on page 201.)
Roth, M., ¨Ozkan, E., and Gustafsson, F. 2013. A Student’s t ﬁlter for heavy tailed
process and measurement noise.
Pages 5770–5774 of: Proceedings of the 2013
IEEE International Conference on Acoustics, Speech and Signal Processing. (Cited
on page 78.)
Roweis, S., and Ghahramani, Z. 2001. Learning nonlinear dynamical systems using the
expectation–maximization algorithm. Chap. 6, pages 175–220 of: Haykin, S. (ed),
Kalman Filtering and Neural Networks. Wiley-Interscience. (Cited on page 327.)
Sage, A. P., and Melsa, J. L. 1971. Estimation Theory with Applications to Communi-
cations and Control. McGraw-Hill. (Cited on page 267.)
Saha, S., Ozkan, E., Gustafsson, F., and Smidl, V. 2010. Marginalized particle ﬁlters for
Bayesian estimation of Gaussian noise parameters. Pages 1–8 of: 13th Conference
on Information Fusion (FUSION). (Cited on page 347.)
Sandblom, F., and Svensson, L. 2012. Moment estimation using a marginalized trans-
form.
IEEE Transactions on Signal Processing, 60(12), 6138–6150.
(Cited on
page 352.)
S¨arkk¨a, S., and Garc´ıa-Fern´andez, A. F. 2021. Temporal parallelization of Bayesian
smoothers.
IEEE Transactions on Automatic Control, 66, 299–306.
(Cited on
page 354.)
S¨arkk¨a, S. 2006. Recursive Bayesian Inference on Stochastic Differential Equations.
Doctoral dissertation, Helsinki University of Technology. (Cited on pages 285, 345,
346, and 352.)
S¨arkk¨a, S. 2007. On unscented Kalman ﬁltering for state estimation of continuous-time
nonlinear systems. IEEE Transactions on Automatic Control, 52(9), 1631–1641.
(Cited on page 352.)
S¨arkk¨a, S. 2008. Unscented Rauch-Tung-Striebel smoother. IEEE Transactions on
Automatic Control, 53(3), 845–849. (Cited on pages 285 and 286.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
389
S¨arkk¨a, S. 2010.
Continuous-time and continuous-discrete-time unscented Rauch-
Tung-Striebel smoothers. Signal Processing, 90(1), 225–235. (Cited on page 352.)
S¨arkk¨a, S. 2011. Linear operators and stochastic partial differential equations in Gaus-
sian process regression. In: Proceedings of ICANN. (Cited on page 5.)
S¨arkk¨a, S., and Hartikainen, J. 2010a. On Gaussian optimal smoothing of non-linear
state space models. IEEE Transactions on Automatic Control, 55(8), 1938–1941.
(Cited on pages 278 and 280.)
S¨arkk¨a, S., and Hartikainen, J. 2010b. Sigma point methods in optimal smoothing of
non-linear stochastic state space models. Pages 184–189 of: Proceedings of IEEE
International Workshop on Machine Learning for Signal Processing (MLSP). (Cited
on page 352.)
S¨arkk¨a, S., and Nummenmaa, A. 2009.
Recursive noise adaptive Kalman ﬁltering
by variational Bayesian approximations. IEEE Transactions on Automatic Control,
54(3), 596–600. (Cited on pages 79, 347, and 353.)
S¨arkk¨a, S., and Sarmavuori, J. 2013. Gaussian ﬁltering and smoothing for continuous-
discrete dynamic systems. Signal Processing, 93(2), 500–510. (Cited on page 352.)
S¨arkk¨a, S., and Solin, A. 2012.
On continuous-discrete cubature Kalman ﬁltering.
Pages 1210–1215 of: Proceedings of SYSID 2012. (Cited on page 352.)
S¨arkk¨a, S., and Solin, A. 2019. Applied Stochastic Differential Equations. Cambridge
University Press. (Cited on pages 7, 44, 46, 52, 53, 57, 58, 59, 61, 69, 351, 359,
and 362.)
S¨arkk¨a, S., and Sottinen, T. 2008. Application of Girsanov theorem to particle ﬁltering
of discretely observed continuous-time non-linear systems. Bayesian Analysis, 3(3),
555–584. (Cited on pages 5, 345, 346, and 352.)
S¨arkk¨a, S., and Svensson, L. 2020. Levenberg–Marquardt and line-search extended
Kalman smoothers. In: Proceedings of 45th International Conference on Acoustics,
Speech, and Signal Processing (ICASSP 2020). (Cited on pages 127, 276, and 277.)
S¨arkk¨a, S., Vehtari, A., and Lampinen, J. 2007a. CATS benchmark time series pre-
diction by Kalman smoother with cross-validated noise density. Neurocomputing,
70(13–15), 2331–2341. (Cited on page 7.)
S¨arkk¨a, S., Vehtari, A., and Lampinen, J. 2007b.
Rao-Blackwellized particle ﬁlter
for multiple target tracking. Information Fusion Journal, 8(1), 2–15. (Cited on
pages 250 and 353.)
S¨arkk¨a, S., Bunch, P., and Godsill, S. J. 2012a. A backward-simulation based Rao-
Blackwellized particle smoother for conditionally linear Gaussian models. Pages
506–511 of: Proceedings of SYSID 2012. (Cited on page 317.)
S¨arkk¨a, S., Solin, A., Nummenmaa, A., Vehtari, A., Auranen, T., Vanni, S., and Lin,
F.-H. 2012b. Dynamic retrospective ﬁltering of physiological noise in BOLD fMRI:
DRIFTER. NeuroImage, 60(2), 1517–1527. (Cited on page 5.)
S¨arkk¨a, S., Solin, A., and Hartikainen, J. 2013. Spatiotemporal learning via inﬁnite-
dimensional Bayesian ﬁltering and smoothing. IEEE Signal Processing Magazine,
30(4), 51–61. (Cited on page 7.)
S¨arkk¨a, S., Hartikainen, J., Svensson, L., and Sandblom, F. 2016. On the relation be-
tween Gaussian process quadratures and sigma-point methods. Journal of Advances
in Information Fusion, 11(1), 31–46. (Cited on pages 135, 165, 201, 290, and 352.)
Sarmavuori, J., and S¨arkk¨a, S. 2012. Fourier-Hermite Kalman ﬁlter. IEEE Transactions
on Automatic Control, 57(6), 1511–1515. (Cited on pages 176 and 201.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
390
References
Sch¨on, T., and Gustafsson, F. 2003. Particle ﬁlters for system identiﬁcation of state-
space models linear in either parameters or states. Pages 1287–1292 of: Proceedings
of the 13th IFAC Symposium on System Identiﬁcation, Rotterdam, The Netherlands.
(Cited on page 347.)
Sch¨on, T., Gustafsson, F., and Nordlund, P.-J. 2005. Marginalized particle ﬁlters for
mixed linear/nonlinear state-space models. IEEE Transactions on Signal Processing,
53(7), 2279–2289. (Cited on page 250.)
Sch¨on, T., Wills, A., and Ninness, B. 2011. System identiﬁcation of nonlinear state-
space models. Automatica, 47(1), 39–49. (Cited on pages 327, 328, and 344.)
Segal, M., and Weinstein, E. 1989. A new method for evaluating the log-likelihood
gradient, the Hessian, and the Fisher information matrix for linear dynamic systems.
IEEE Transactions on Information Theory, 35(3), 682–687. (Cited on page 330.)
Shiryaev, A. N. 1996. Probability. Springer. (Cited on page 17.)
Shumway, R., and Stoffer, D. 1982. An approach to time series smoothing and fore-
casting using the EM algorithm. Journal of Time Series Analysis, 3(4), 253–264.
(Cited on pages 327 and 334.)
ˇSimandl, M., and Dun´ık, J. 2006. Design of derivative-free smoothers and predictors.
Pages 991–996 of: Preprints of the 14th IFAC Symposium on System Identiﬁcation.
(Cited on page 285.)
Singer, H. 2008. Nonlinear continuous time modeling approaches in panel research.
Statistica Neerlandica, 62(1), 29–57. (Cited on page 352.)
Singer, H. 2011. Continuous-discrete state-space modeling of panel data with nonlinear
ﬁlter algorithms. AStA Advances in Statistical Analysis, 95(4), 375–413. (Cited on
page 352.)
Skoglund, M., Hendeby, G., and Axehill, D. 2015. Extended Kalman ﬁlter modiﬁca-
tions based on an optimization view point. Pages 1856–1861 of: 18th International
Conference on Information Fusion (FUSION). (Cited on pages 126 and 127.)
Snyder, C., Bengtsson, T., Bickel, P., and Anderson, J. 2008.
Obstacles to high-
dimensional particle ﬁltering. Monthly Weather Review, 136(12), 4629–4640. (Cited
on page 230.)
Stengel, R. F. 1994. Optimal Control and Estimation. Dover. (Cited on pages 6, 8,
and 176.)
Stone, L. D., Barlow, C. A., and Corwin, T. L. 2014. Bayesian Multiple Target Tracking.
2nd edn. Artech House. (Cited on page 3.)
Storvik, G. 2002. Particle ﬁlters in state space models with the presence of unknown
static parameters. IEEE Transactions on Signal Processing, 50(2), 281–289. (Cited
on page 347.)
Stratonovich, R. L. 1968. Conditional Markov Processes and Their Application to the
Theory of Optimal Control. Elsevier. (Cited on page 8.)
Striebel, C. T. 1965. Partial differential equations for the conditional distribution of a
Markov process given noisy observations. Journal of Mathematical Analysis and
Applications, 11, 151–159. (Cited on page 351.)
Svensson, L., Svensson, D., Guerriero, M., and Willett, P. 2011. Set JPDA ﬁlter for
multitarget tracking. IEEE Transactions on Signal Processing, 59(10), 4677–4691.
(Cited on page 353.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
References
391
Taghavi, E., Lindsten, F., Svensson, L., and Sch¨on, T. B. 2013. Adaptive stopping for
fast particle smoothing. Pages 6293–6297 of: IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP). (Cited on page 314.)
Tarantola, A. 2004. Inverse Problem Theory and Methods for Model Parameter Esti-
mation. SIAM. (Cited on pages 5 and 7.)
Thrun, S., Burgard, W., and Fox, D. 2005. Probabilistic Robotics. MIT Press. (Cited
on page 5.)
Titterton, D. H., and Weston, J. L. 1997. Strapdown Inertial Navigation Technology.
Peter Pregrinus Ltd. (Cited on page 3.)
Tronarp, F., Garc´ıa-Fern´andez, A. F., and S¨arkk¨a, S. 2018.
Iterative ﬁltering and
smoothing in nonlinear and non-Gaussian systems using conditional moments. IEEE
Signal Processing Letters, 25(3), 408–412. (Cited on pages 168, 182, 187, 204,
and 297.)
V¨a¨an¨anen, V. 2012. Gaussian Filtering and Smoothing Based Parameter Estimation in
Nonlinear Models for Sequential Data. Master’s Thesis, Aalto University. (Cited on
page 327.)
Van der Merwe, R., and Wan, E. A. 2001. The square-root unscented Kalman ﬁlter for
state and parameter estimation. Pages 3461–3464 of: International Conference on
Acoustics, Speech, and Signal Processing. (Cited on page 353.)
Van der Merwe, R., De Freitas, N., Doucet, A., and Wan, E. 2001. The unscented par-
ticle ﬁlter. Pages 584–590 of: Advances in Neural Information Processing Systems
13. (Cited on page 241.)
Van Trees, H. L. 1968. Detection, Estimation, and Modulation Theory Part I. Wiley.
(Cited on page 6.)
Van Trees, H. L. 1971. Detection, Estimation, and Modulation Theory Part II. Wiley.
(Cited on page 6.)
Vihola, M. 2012. Robust adaptive Metropolis algorithm with coerced acceptance rate.
Statistics and Computing, 22(5), 997–1008. (Cited on pages 325 and 326.)
Viterbi, A. J. 1967. Error bounds for convolutional codes and an asymptotically opti-
mum decoding algorithm. IEEE Transactions on Information Theory, 13(2). (Cited
on pages 6 and 262.)
Wan, E. A., and Van der Merwe, R. 2001. The unscented Kalman ﬁlter. Chap. 7 of:
Haykin, S. (ed), Kalman Filtering and Neural Networks. Wiley. (Cited on pages 150
and 155.)
West, M., and Harrison, J. 1997. Bayesian Forecasting and Dynamic Models. Springer-
Verlag. (Cited on page 8.)
Wiener, N. 1950. Extrapolation, Interpolation and Smoothing of Stationary Time Series
with Engineering Applications. Wiley. (Cited on page 7.)
Wills, A., Sch¨on, T. B., Ljung, L., and Ninness, B. 2013.
Identiﬁcation of
Hammerstein–Wiener models. Automatica, 49(1), 70–81. (Cited on page 343.)
Wu, Y., Hu, D., Wu, M., and Hu, X. 2005. Unscented Kalman ﬁltering for additive noise
case: Augmented versus nonaugmented.
IEEE Signal Processing Letters, 12(5),
357–360. (Cited on page 157.)
Wu, Y., Hu, D., Wu, M., and Hu, X. 2006. A numerical-integration perspective on
Gaussian ﬁlters. IEEE Transactions on Signal Processing, 54(8), 2910–2921. (Cited
on pages 131, 133, 135, 142, 143, 145, 162, 165, 280, 287, 289, and 352.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
392
References
Yaghoobi, F., Corenﬂos, A., Hassan, S., and S¨arkk¨a, S. 2021. Parallel iterated extended
and sigma-point Kalman smoothers. In: Proceedings of IEEE International Confer-
ence on Acoustics, Speech and Signal Processing (ICASSP). (Cited on page 354.)
Ypma, A., and Heskes, T. 2005.
Novel approximations for inference in nonlinear
dynamical systems using expectation propagation. Neurocomputing, 69(1), 85–99.
(Cited on page 353.)
Zoeter, O., and Heskes, T. 2011. Expectation propagation and generalized EP methods
for inference in switching linear dynamical systems. Chap. 7, pages 141–165 of:
Bayesian Time Series Models. Cambridge University Press. (Cited on page 352.)

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
List of Examples
4.1
Dynamic model of a car
47
4.2
Continuous-time constant velocity model
48
4.4
Discretization of the Wiener process
49
4.5
Discrete-time constant/Wiener velocity model
50
4.6
Discretized dynamic model of a car
51
4.7
Noisy pendulum model
52
4.9
Euler–Maruyama discretization of pendulum model
54
4.10
The polar coordinated turn (CT) model
55
4.11
Euler–Maruyama discretization of polar CT model
57
4.15
Analytical mean for the polar CT model
60
4.16
Analytical mean for the Cartesian CT model
61
4.17
Bicycle model
63
4.21
Additive noise approximation for pendulum model
67
4.22
Constant gradient covariance for polar CT model
68
5.1
Position measurement model for a car
74
5.2
Measurement model for noisy pendulum
76
5.3
Radar measurements
76
5.4
Multiple range measurements
77
5.5
Robust measurement model for a car
78
5.6
Clutter model for pendulum
81
5.7
Gyroscope measurement as input
82
5.8
Linear-in-parameters regression model I
83
5.9
Linear-in-parameters regression model II
84
5.10
Generalized linear model
84
5.11
Including bias in state vector
85
5.12
Autoregressive (AR) model
86
5.13
Time-varying autoregressive (TVAR) model
86
5.14
Gilbert–Elliot channel model
87
6.4
Gaussian random walk
92
6.7
Kalman ﬁlter for a Gaussian random walk
98
393

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
394
List of Examples
6.8
Kalman ﬁlter for car tracking
99
6.12
Gilbert–Elliot channel ﬁlter
105
7.6
Pendulum tracking with EKF
117
7.7
Coordinated turn model with EKF
118
7.10
Pendulum tracking with IEKF
124
7.11
Coordinated turn model with IEKF
125
8.8
Pendulum tracking with GHKF
141
8.9
Coordinated turn model with GHKF
142
8.13
Pendulum tracking with CKF
149
8.14
Coordinated turn model with CKF
149
8.19
Pendulum tracking with UKF
160
8.20
Coordinated turn model with UKF
160
8.23
Pendulum tracking with UKF5
165
8.24
Coordinated turn model with UKF5
165
9.7
Statistical linearization
174
9.15
Statistical linear regression
182
9.19
SLR with Poisson observations
185
9.26
Gaussian ﬁltering with Poisson observations
196
10.5
Posterior statistical linear regression
208
10.7
Iterated posterior linearization
210
10.13 Pendulum tracking with IPLF
220
10.14 Coordinated turn model with posterior linearization ﬁlters
220
11.10 Pendulum tracking with a particle ﬁlter
243
11.11 Cluttered pendulum tracking with a particle ﬁlter
243
12.3
RTS smoother for Gaussian random walk
258
12.4
RTS smoother for car tracking
258
12.8
Gilbert–Elliot channel smoother
261
12.11 Viterbi algorithm for Gilbert–Elliot channel
265
13.2
Pendulum tracking with ERTSS
269
13.3
Coordinated turn model with ERTSS
269
13.6
Pendulum tracking with IERTSS
275
13.7
Coordinated turn model with IERTSS
275
14.4
Pendulum tracking with GHRTSS
281
14.7
Pendulum tracking with CRTSS
284
14.10 Pendulum tracking with URTSS
287
14.13 Pendulum tracking with URTSS5
290

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
List of Examples
395
14.14 Coordinated turn model with Gaussian smoothers
290
14.23 Pendulum tracking with IPLS
304
14.24 Coordinated turn model with Gaussian smoothers
304
15.3
Pendulum tracking with BS-PS
311
15.4
Cluttered pendulum tracking with BS-PS
311
16.10 Parameter posterior for Gaussian random walk
333
16.17 Estimation of noise variance in the pendulum model
343

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
List of Theorems, Corollaries, and
Algorithms
4.3
Discretization of linear dynamic models
49
4.8
The Euler–Maruyama method
53
4.12
Simulating SDE solution with Euler–Maruyama
58
4.13
Linearized continuous-time dynamic model
59
4.14
Discretization by mean linearization
60
4.18
Linearization with respect to initial condition
64
4.19
Discretization with a constant gradient
66
4.20
Additive noise approximation
67
6.5
Bayesian ﬁltering equations
94
6.6
Kalman ﬁlter
97
6.9
Afﬁne Kalman ﬁlter
102
6.10
Bayesian ﬁltering equations for discrete state spaces
103
6.11
Bayesian ﬁltering equations for discrete HMMs
104
7.1
Linear approximation of an additive transform
110
7.2
Linear approximation of a non-additive transform
111
7.3
Quadratic approximation of an additive non-linear transform
112
7.4
Extended Kalman ﬁlter I
113
7.5
Extended Kalman ﬁlter II
115
7.8
Second order extended Kalman ﬁlter
119
7.9
Iterated Extended Kalman Filter
124
8.1
Gaussian moment matching of an additive transform
132
8.2
Gaussian moment matching of a non-additive transform
133
8.3
Gaussian ﬁlter I
133
8.4
Gaussian ﬁlter II
135
8.5
Gauss–Hermite quadrature
138
8.6
Gauss–Hermite cubature
139
8.7
Gauss–Hermite Kalman ﬁlter
140
8.10
Spherical cubature integration
144
8.11
Cubature Kalman ﬁlter I
145
8.12
Cubature Kalman ﬁlter II
147
397

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
398
List of Theorems, Corollaries, and Algorithms
8.15
Unscented approximation of an additive transform
153
8.16
Unscented approximation of a non-additive transform
154
8.17
Unscented Kalman ﬁlter I
156
8.18
Unscented Kalman ﬁlter II
157
8.21
Fifth order cubature/unscented integration
163
8.22
Fifth order cubature/unscented Kalman ﬁlter
163
9.1
Gaussian ﬁltering with enabling linearizations
169
9.3
Statistical linearization I
171
9.4
Gaussian approximation from statistical linearization
172
9.5
Statistical linearization II
172
9.6
Statistical linearization of an additive transform
173
9.8
Statistical linearization III
176
9.9
Statistically linearized ﬁlter I
177
9.10
Statistically linearized ﬁlter II
177
9.12
Statistical linear regression I
179
9.13
Gaussian approximation from SLR
180
9.14
SLR of an additive transform
180
9.16
Conditional moments form of SLR joint moments
183
9.17
Non-additive transform in conditional moment form
183
9.18
Conditional moments of conditional distributions
184
9.20
Statistical linear regression ﬁlter I
187
9.21
Statistical linear regression ﬁlter II
188
9.22
Statistical linear regression ﬁlter III
190
9.23
Statistical linear regression ﬁlter IV
192
9.24
Sigma-point conditional moment Kalman ﬁlter
193
9.25
Monte Carlo Kalman ﬁlter
195
9.27
Sigma-point non-additive conditional moment ﬁlter
198
10.2
Generalized statistical linear regression
205
10.3
Generalized SLR of an additive transform
205
10.6
Iterated posterior linearization
208
10.8
Iterated posterior linearization ﬁlter I
212
10.9
Iterated posterior linearization ﬁlter II
214
10.10 Iterated posterior linearization ﬁlter III
215
10.11 Iterated posterior linearization ﬁlter IV
216
10.12 Sigma-point iterated posterior linearization ﬁlter I
218
10.15 Sigma-point iterated posterior linearization ﬁlter II
221
10.16 Sigma-point iterated posterior linearization ﬁlter III
222
10.17 Monte Carlo iterated posterior linearization ﬁlter
224
11.1
Importance sampling
233
11.2
Sequential importance sampling
235

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
List of Theorems, Corollaries, and Algorithms
399
11.3
Resampling
237
11.4
Inverse transform sampling for resampling
238
11.5
Multinomial resampling
238
11.6
Stratiﬁed resampling
238
11.7
Systematic resampling
239
11.8
Sequential importance resampling
240
11.9
Bootstrap ﬁlter
242
11.12 Auxiliary particle ﬁlter
246
11.13 Rao–Blackwellized particle ﬁlter
248
12.1
Bayesian smoothing equations
253
12.2
RTS smoother
255
12.5
Afﬁne RTS smoother
260
12.6
Discrete Bayesian smoothing equations
261
12.7
Bayesian smoother for discrete HMMs
261
12.9
Viterbi algorithm for computing the MAP path
263
12.10 Viterbi algorithm for discrete HMMs
265
13.1
Extended RTS smoother
267
13.4
Second order extended RTS smoother
270
13.5
Iterated extended RTS smoother
274
14.1
Gaussian RTS smoother I
278
14.2
Gaussian RTS smoother II
280
14.3
Gauss–Hermite Rauch–Tung–Striebel smoother
280
14.5
Cubature Rauch–Tung–Striebel smoother I
282
14.6
Cubature Rauch–Tung–Striebel smoother II
283
14.8
Unscented Rauch–Tung–Striebel smoother I
285
14.9
Unscented Rauch–Tung–Striebel smoother II
286
14.11 Fifth order cubature/unscented RTS smoother I
287
14.12 Fifth order cubature/unscented RTS smoother II
289
14.15 Statistical linear regression smoother
292
14.16 Gaussian RTS smoother III
293
14.17 Monte Carlo RTS smoother
293
14.18 Generalized SLR smoother
295
14.19 Iterated posterior linearization smoother I
297
14.20 Iterated posterior linearization smoother II
299
14.21 Sigma-point iterated posterior linearization smoother I
301
14.22 Sigma-point iterated posterior linearization smoother II
302
15.1
SIR particle smoother
308
15.2
Backward-simulation particle smoother
310
15.5
Rejection sampling
313

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
400
List of Theorems, Corollaries, and Algorithms
15.6
Backward-simulation particle smoother with rejection
sampling
314
15.7
Reweighting particle smoother
314
15.8
Rao–Blackwellized SIR particle smoother
316
16.1
Recursion for marginal likelihood of parameters
321
16.4
Recursion for energy function
322
16.5
Metropolis–Hastings
324
16.6
RAM algorithm
325
16.7
Abstract EM
327
16.8
EM algorithm
328
16.9
Energy function for linear Gaussian model
332
16.11 Evaluation of Q for linear Gaussian model
334
16.12 Maximization of Q for linear model parameters
336
16.13 EM algorithm for linear state space models
336
16.14 Gaussian ﬁltering-based energy function
337
16.15 Evaluation of Q via Gaussian smoothing
338
16.16 SIR-based energy function approximation
341
16.18 Evaluation of Q via the backward-simulation particle
smoother
343
16.19 Evaluation of Q via the reweighting smoother
344
A.4
Block matrix inverses
356
A.5
Matrix inversion lemmas
356
A.6
Cholesky factorization
357
A.7
Partial derivative of Cholesky factorization I
357
A.8
Partial derivative of Cholesky factorization II
358
A.10
Energy function derivative for linear Gaussian model I
372
A.11
Energy function derivative for linear Gaussian model II
373
A.12
Derivatives of Gaussian ﬁltering-based energy function
375

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
Index
adaptive Markov chain Monte Carlo, 325
adaptive Metropolis, 325
adaptive resampling, 239
additive noise approximation, 67
for pendulum model, 67
afﬁne Kalman smoother, see RTS
smoother, afﬁne
applications
audio signal processing, 6
biological processes, 5
brain imaging, 5
Gaussian process regression, 5
global positioning system, 2
GPS/INS, 4
inertial navigation, 3
integrated inertial navigation, 4
inverse problems, 7
learning systems, 7
multiple target tracking, 3
physical systems, 7
robotics and autonomous systems, 5
spread of infectious diseases, 5
stochastic optimal control, 6
target tracking, 2
telecommunications, 6
automatic differentiation, 117, 127
auxiliary particle ﬁlter, 246
backward-simulation particle smoother,
310
with rejection sampling, 314
batch solution
general Bayesian, 31
to linear regression, 28
Bayes’ rule, 19
Bayesian estimation of parameters, 319
Bayesian ﬁlter, 94, 103, 104
for Gilbert–Elliot channel model, 105
Bayesian ﬁltering
applications, 2
as Bayesian inference, 9
equations, 94
equations for discrete state space, 103
equations for HMMs, 104
origins, 7
Bayesian inference
building blocks, 19
connection with ML, 17
philosophy, 17
Bayesian optimal ﬁltering, see Bayesian
ﬁltering
Bayesian optimal smoothing, see
Bayesian smoothing
Bayesian smoother, 253, 261
for Gilbert–Elliot channel model, 261
Bayesian smoothing
applications, 2
as Bayesian inference, 9
equations, 253
equations for discrete state spaces, 261
equations for HMMs, 261
origins, 7
block matrix inverse, 356
bootstrap ﬁlter, 242
Chapman–Kolmogorov equation, 94, 104
Cholesky factorization
algorithm, 357
time derivative, 357
companion code repository, 106
conditional distributions
in conditional moments form, 184
constant gradient covariance for polar CT
model, 68
constant velocity model, 48
cubature integration, see spherical
cubature integration
cubature Kalman ﬁlter
401

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
402
INDEX
additive, 145
ﬁfth order, 163
for coordinated turn model, 149
for pendulum tracking, 149
non-additive, 147
cubature RTS smoother
additive, 282
ﬁfth order I, 287
ﬁfth order II, 289
for coordinated turn model, 290
for pendulum tracking, 284
non-additive, 283
cubature/unscented RTS smoother ﬁfth
order
for coordinated turn model, 290
degeneracy problem, 236
discretization by mean linearization, 60
discretization of linear dynamic models,
49
discretization with a constant gradient, 66
discretized model
car dynamics, 51
constant/Wiener velocity model, 50
mean for the bicycle model, 63
mean for the Cartesian CT model, 61
mean for the polar CT model, 60
pendulum dynamics
Euler–Maruyama, 54
polar coordinated turn
Euler–Maruyama, 57
Wiener process, 49
dynamic linear models, 8
dynamic model
deﬁnition, 11
of probabilistic state space model, 91
energy function, 322
derivative for linear Gaussian model,
372, 373
derivative for non-linear Gaussian
model, 375
linear Gaussian model, 332
non-linear Gaussian model, 337
particle ﬁlter approximation, 341
recursion, 322
SIR-based approximation, 341
Euler–Maruyama method, 53
Euler–Maruyama simulation, 58
expectation-maximization
algorithm, 328
as coordinate ascend, 327
backward-simulation particle
smoother-based evaluation of Q,
343
evaluation of linear Gaussian Q, 334
evaluation of non-linear Gaussian Q,
338
for linear Gaussian models, 336
maximization of linear Gaussian Q,
336
reweighting smoother-based
evaluation of Q, 344
extended 2nd order RTS smoother
additive, 270
extended Kalman ﬁlter
ﬁrst order additive, 113
ﬁrst order non-additive, 115
for pendulum tracking, 117
for polar coordinated turn model, 118
iterated, 124
second order additive, 119
extended RTS smoother
additive, 267
for coordinated turn model, 269
for pendulum tracking, 269
iterated, 274
second order, 270
ﬁfth order cubature/unscented RTS
smoother
additive, 287
non-additive, 289
ﬁltering distribution
deﬁnition, 94
ﬁltering model, see state space model
Fisher’s identity, 323, 330
for linear Gaussian model, 373
Gauss–Hermite cubature, 139
Gauss–Hermite Kalman ﬁlter
additive, 140
for coordinated turn model, 142
for pendulum tracking, 141
Gauss–Hermite quadrature, 22, 138
Gauss–Hermite RTS smoother
additive, 280
for coordinated turn model, 290
for pendulum tracking, 281
Gaussian approximation
deﬁnition, 22
in extended Kalman ﬁlter, 113

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
INDEX
403
Gaussian assumed density ﬁlter, see
Gaussian ﬁlter
Gaussian distribution, 355
Gaussian ﬁlter
additive, 133
for Poisson observations, 196
non-additive, 135
with enabling linearizations, 169
Gaussian moment matching, 132, 133
Gaussian process regression, 7
Gaussian random walk, 92
for linear regression, 34
Gaussian RTS smoother
additive, 278
conditional distribution form, 293
non-additive, 280
generalized SLR smoother, 295
generalized statistical linear regression,
205
deﬁnition, 204
Hermite polynomial, 137
Hessian matrix, 109
importance sampling, 23, 233
iterated extended Kalman ﬁlter, 124
for coordinated turn model, 125
for pendulum tracking, 124
iterated extended RTS smoother, 274
for coordinated turn model, 275
for pendulum tracking, 275
iterated posterior linearization, 208
of a cubic function, 210
iterated posterior linearization ﬁlter
additive, 212
conditional distribution form, 216
conditional moment form, 215
non-additive, 214
iterated posterior linearization smoother
additive, 297
conditional moments, 299
for coordinated turn model, 304
Jacobian matrix, 109
Kalman ﬁlter, 8
afﬁne, 102
basic, 97
conditional distribution iterated
posterior linearization, 216
conditional moment iterated posterior
linearization, 215
cubature, 145
cubature non-additive, 147
extended, 113
ﬁfth order cubature, 163
ﬁfth order unscented, 163
for car tracking, 99
for Gaussian random walk, 98
for linear regression, 30
for linear regression with drift, 35
Gauss–Hermite, 140
Gaussian, 133
Gaussian non-additive, 135
iterated extended, 124
iterated posterior linearization, 212
Monte Carlo, 195
Monte Carlo iterated posterior
linearization, 224
non-additive extended, 115
non-additive iterated posterior
linearization, 214
second order extended, 119
sigma-point conditional moment, 193
iterated posterior linearization, 222
sigma-point iterated posterior
linearization, 218
sigma-point non-additive conditional
moment, 198
sigma-point non-additive iterated
posterior linearization, 221
stationary, 102
statistical linear regression I, 187
statistical linear regression II, 188
statistical linear regression III, 190
statistical linear regression IV, 192
statistically linearized, 177
statistically linearized non-additive,
177
unscented, 156, 157
Kalman smoother, see RTS smoother
Laplace approximation, 323
least squares estimate, 25
linear approximation, 110, 111
linear quadratic Gaussian regulator, 8
linear regression, 27
linearization, see linear approximation
linearization with respect to initial
condition, 64
linearized continuous-time dynamic
model, 59
local linearization, 241

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
404
INDEX
loss function
0–1, 21
absolute error, 21
deﬁnition, 21
quadratic error, 21
MAP-estimate, 22, 323
marginal likelihood of parameters, 321
Markov chain Monte Carlo, 23, 324
matrix inversion lemma, 356
measurement model
deﬁnition, 19
joint distribution of measurements, 93
of probabilistic state space model, 91
Metropolis–Hastings, 324
ML-estimate, 18, 323
MMSE-estimate, 21
Monte Carlo iterated posterior
linearization ﬁlter, 224
Monte Carlo Kalman ﬁlter, 195
Monte Carlo method, 23, 229
Monte Carlo RTS smoother, 293
multinomial resampling, 238
non-additive transform
in conditional moments form, 183
non-linear transform
additive Gaussian moment matching,
132
additive generalized statistical linear
regression, 205
additive linear approximation, 110
additive quadratic approximation, 112
additive statistical linear regression,
180
additive statistical linearization, 173
additive unscented transform
approximation, 153
non-additive Gaussian moment
matching, 133
non-additive linear approximation,
111
non-additive unscented transform
approximation, 154
on-line learning, 33
optimal ﬁltering, see Bayesian ﬁltering
optimal importance distribution, 241
optimal smoothing, see Bayesian
smoothing
parameter estimation
deﬁnition, 319
Gaussian random walk, 333
linear Gaussian models, 332
pendulum model, 343
via Gaussian ﬁltering and smoothing,
337
via particle ﬁltering and smoothing,
340
via Rao–Blackwellization, 345
via state augmentation, 330
particle ﬁlter
algorithm, 240
auxiliary, 246
for cluttered pendulum tracking, 243
for pendulum tracking, 243
Rao–Blackwellized, 248
particle marginal Metropolis–Hastings,
342
particle Markov chain Monte Carlo, 342
particle smoother
backward-simulation, 310
Kim’s approximation, 317
marginal, 314
Rao–Blackwellized, 316
reweighting, 314
SIR, 308
posterior distribution
batch linear regression model, 29
deﬁnition, 19
joint distribution of states, 93
recursive linear regression model, 30
posterior linearization
deﬁnition, 207
posterior linearization ﬁlter
for coordinated turn model, 220
posterior mean, 21
posterior statistical linear regression
of a cubic function, 208
prediction, see update
prior distribution
deﬁnition, 19
joint distribution of states, 93
probabilistic notation, 27
quadratic approximation, 112
quadrature Kalman ﬁlter, see
Gauss–Hermite Kalman ﬁlter
Rao–Blackwellization of parameters, 345
Rao–Blackwellized particle ﬁlter, 248
Rao–Blackwellized particle smoother,
316

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
INDEX
405
Rauch–Tung–Striebel smoother, see RTS
Smoother
recursive solution
general Bayesian, 32
to linear regression, 30
rejection sampling, 313
resampling, 237
inverse transform sampling for, 238
multinomial, 238
stratiﬁed, 238
systematic, 239
reweighting particle smoother, 314
robust adaptive Metropolis, 325
RTS smoother
afﬁne, 260
basic, 255
cubature, 282, 283
extended, 267
ﬁfth order cubature/unscented, 287,
289
for car tracking, 258
for Gaussian random walk, 258
Gauss–Hermite, 280
Gaussian, 278, 280
iterated posterior linearization I, 297
iterated posterior linearization II, 299
sigma-point iterated posterior
linearization I, 301
sigma-point iterated posterior
linearization II, 302
unscented, 285, 286
sample impoverishment, 242
second order approximation, see
quadratic approximation
sensitivity equations, 323, 334
linear Gaussian model, 372
non-linear Gaussian model, 375
sequential importance resampling, 240
sequential importance sampling, 235
sigma point conditional moment Kalman
ﬁlter, 193
sigma-point iterated posterior
linearization ﬁlter
additive, 218
conditional moment form, 222
non-additive, 221
sigma-point iterated posterior
linearization smoother
version I, 301
version II, 302
sigma-point non-additive conditional
moment ﬁlter, 198
SIR particle smoother, 308
spherical cubature integration
algorithm, 144
state augmentation, 330
state space model
autoregressive (AR) model, 86
bicycle dynamics, 63
car dynamics, 47
car position measurement, 74
Cartesian CT model dynamics, 61
cluttered pendulum, 81
conditional independence, 92
constant velocity model, 48
Gaussian random walk, 92
generalized linear model, 84
Gilbert–Elliot channel model, 87
gyroscope as input, 82
linear Gaussian, 96
linear-in-parameters regression model,
83, 84
Markov property, 92
multiple range measurements, 77
non-linear additive Gaussian, 113
non-linear non-additive Gaussian, 115
notation, 35
pendulum dynamics, 52
pendulum measurement, 76
polar coordinated turn dynamics, 55
probabilistic, 91
radar measurement, 76
robust car measurement, 78
time-varying autoregressive (TVAR)
model, 86
Wiener velocity model, 48
statistical decision theory, 20
statistical inversion, 5, 9
statistical linear regression
conditional moments form, 183
deﬁnition, 179
Gaussian approximation from, 180
generalized deﬁnition, 204
of a cubic function, 182
of Poisson observations, 185
version I, 179
statistical linear regression ﬁlter
version I, 187
version II, 188
version III, 190
version IV, 192

This material will be published by Cambridge University Press as Bayesian Filtering and Smoothing, Second Edition by Simo
S¨arkk¨a and Lennart Svensson. This pre-publication version is free to view and download for personal use only. Not for re-distribution,
re-sale, or use in derivative works. © Simo S¨arkk¨a and Lennart Svensson 2023.
406
INDEX
statistical linear regression smoother, 292
statistical linearization
deﬁnition, 171
Gaussian approximation from, 172
of a cubic function, 174
version I, 171
version II, 172
version III, 176
statistically linearized ﬁlter
additive, 177
non-additive, 177
stratiﬁed resampling, 238
Student’s t-distribution, 78
systematic resampling, 239
Taylor series, 108
time-invariant model, 36
two-ﬁlter smoother, 255
unscented Kalman ﬁlter
additive, 156
ﬁfth order, 163
for coordinated turn model, 160, 165
for pendulum tracking, 160, 165
non-additive, 157
unscented RTS smoother
additive, 285
ﬁfth order I, 287
ﬁfth order II, 289
for coordinated turn model, 290
for pendulum tracking, 287
non-additive, 286
unscented transform
additive, 153
non-additive, 154
update, see prediction
utility function, 21
Viterbi algorithm, 263
for discrete HMMs, 265
for Gilbert–Elliot channel model, 265
Wiener ﬁlter, 7
Wiener velocity model, 48
Woodbury formula, 356

