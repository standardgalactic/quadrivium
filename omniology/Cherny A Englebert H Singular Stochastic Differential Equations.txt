Lecture Notes in Mathematics
1858
Editors:
J.--M. Morel, Cachan
F. Takens, Groningen
B. Teissier, Paris


Alexander S. Cherny
Hans-J¨urgen Engelbert
Singular Stochastic
Differential Equations
123

Authors
Alexander S. Cherny
Department of Probability Theory
Faculty of Mechanics and Mathematics
Moscow State University
Leninskie Gory
119992, Moscow
Russia
e-mail: cherny@mech.math.msu.su
Hans-J¨urgen Engelbert
Institut f¨ur Stochastik
Fakult¨at f¨ur Mathematik und Informatik
Friedrich-Schiller-Universit¨at Jena
Ernst-Abbe-Platz 1-4
07743 Jena
Germany
e-mail: engelbert@minet.uni-jena.de
Library of Congress Control Number: 2004115716
Mathematics Subject Classification (2000): 60-02, 60G17, 60H10, 60J25, 60J60
ISSN 0075-8434
ISBN 3-540-24007-1 Springer Berlin Heidelberg New York
DOI: 10.1007/b104187
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microfilm or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
for prosecution under the German Copyright Law.
Springer is a part of Springer Science + Business Media
http://www.springeronline.com
c
⃝Springer-Verlag Berlin Heidelberg 2005
Printed in Germany
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a specific statement, that such names are exempt from the relevant protective laws
and regulations and therefore free for general use.
Typesetting: Camera-ready TEX output by the authors
41/3142/ du - 543210 - Printed on acid-free paper

Preface
We consider one-dimensional homogeneous stochastic diﬀerential equations
of the form
dXt = b(Xt)dt + σ(Xt)dBt,
X0 = x0,
(∗)
where b and σ are supposed to be measurable functions and σ ̸= 0.
There is a rich theory studying the existence and the uniqueness of solu-
tions of these (and more general) stochastic diﬀerential equations. For equa-
tions of the form (∗), one of the best suﬃcient conditions is that the function
(1 + |b|)/σ2 should be locally integrable on the real line. However, both in
theory and in practice one often comes across equations that do not satisfy
this condition. The use of such equations is necessary, in particular, if we want
a solution to be positive. In this monograph, these equations are called sin-
gular stochastic diﬀerential equations. A typical example of such an equation
is the stochastic diﬀerential equation for a geometric Brownian motion.
A point d ∈R, at which the function (1 +|b|)/σ2 is not locally integrable,
is called in this monograph a singular point. We explain why these points
are indeed “singular”. For the isolated singular points, we perform a complete
qualitative classiﬁcation. According to this classiﬁcation, an isolated singular
point can have one of 48 possible types. The type of a point is easily computed
through the coeﬃcients b and σ. The classiﬁcation allows one to ﬁnd out
whether a solution can leave an isolated singular point, whether it can reach
this point, whether it can be extended after having reached this point, and
so on.
It turns out that the isolated singular points of 44 types do not disturb
the uniqueness of a solution and only the isolated singular points of the
remaining 4 types disturb uniqueness. These points are called here the branch
points. There exists a large amount of “bad” solutions (for instance, non-
Markov solutions) in the neighbourhood of a branch point. Discovering the
branch points is one of the most interesting consequences of the constructed
classiﬁcation.
The monograph also includes an overview of the basic deﬁnitions and facts
related to the stochastic diﬀerential equations (diﬀerent types of existence and
uniqueness, martingale problems, solutions up to a random time, etc.) as well
as a number of important examples.
We gratefully acknowledge ﬁnancial support by the DAAD and by the
European Community’s Human Potential Programme under contract HPRN-
CT-2002-00281.
Moscow, Jena,
Alexander Cherny
October 2004
Hans-J¨urgen Engelbert


Table of Contents
Introduction
1
1
Stochastic Diﬀerential Equations
5
1.1
General Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2
Suﬃcient Conditions for Existence and Uniqueness . . . . . . . . .
9
1.3
Ten Important Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4
Martingale Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
1.5
Solutions up to a Random Time . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2
One-Sided Classiﬁcation of Isolated Singular Points
27
2.1
Isolated Singular Points: The Deﬁnition . . . . . . . . . . . . . . . . . . .
27
2.2
Isolated Singular Points: Examples . . . . . . . . . . . . . . . . . . . . . . .
32
2.3
One-Sided Classiﬁcation: The Results . . . . . . . . . . . . . . . . . . . . .
34
2.4
One-Sided Classiﬁcation: Informal Description . . . . . . . . . . . . .
38
2.5
One-Sided Classiﬁcation: The Proofs . . . . . . . . . . . . . . . . . . . . . .
42
3
Two-Sided Classiﬁcation of Isolated Singular Points
65
3.1
Two-Sided Classiﬁcation: The Results . . . . . . . . . . . . . . . . . . . . .
65
3.2
Two-Sided Classiﬁcation: Informal Description . . . . . . . . . . . . .
66
3.3
Two-Sided Classiﬁcation: The Proofs. . . . . . . . . . . . . . . . . . . . . .
69
3.4
The Branch Points: Non-Markov Solutions . . . . . . . . . . . . . . . . .
73
3.5
The Branch Points: Strong Markov Solutions. . . . . . . . . . . . . . .
75
4
Classiﬁcation at Inﬁnity and Global Solutions
81
4.1
Classiﬁcation at Inﬁnity: The Results . . . . . . . . . . . . . . . . . . . . .
81
4.2
Classiﬁcation at Inﬁnity: Informal Description . . . . . . . . . . . . . .
82
4.3
Classiﬁcation at Inﬁnity: The Proofs . . . . . . . . . . . . . . . . . . . . . .
85
4.4
Global Solutions: The Results . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
4.5
Global Solutions: The Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
5
Several Special Cases
93
5.1
Power Equations: Types of Zero . . . . . . . . . . . . . . . . . . . . . . . . . .
93
5.2
Power Equations: Types of Inﬁnity . . . . . . . . . . . . . . . . . . . . . . .
97
5.3
Equations with a Constant-Sign Drift: Types of Zero . . . . . . . .
99
5.4
Equations with a Constant-Sign Drift: Types of Inﬁnity . . . . . 102

VIII
Table of Contents
Appendix A: Some Known Facts
105
A.1
Local Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
A.2
Random Time-Changes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
A.3
Bessel Processes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
A.4
Strong Markov Families . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
A.5
Other Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
Appendix B: Some Auxiliary Lemmas
113
B.1
Stopping Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
B.2
Measures and Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
B.3
Other Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
References
119
Index of Notation
123
Index of Terms
127

Introduction
The basis of the theory of diﬀusion processes was formed by Kolmogorov [30]
(the Chapman–Kolmogorov equation, forward and backward partial diﬀer-
ential equations). This theory was further developed in a series of papers by
Feller (see, for example, [16], [17]).
Both Kolmogorov and Feller considered diﬀusion processes from the point
of view of their ﬁnite-dimensional distributions. Itˆo [24], [25] proposed an
approach to the “pathwise” construction of diﬀusion processes. He introduced
the notion of a stochastic diﬀerential equation (abbreviated below as SDE).
At about the same time and independently of Itˆo, SDEs were considered by
Gikhman [18], [19]. Stroock and Varadhan [44], [45] introduced the notion of
a martingale problem that is closely connected with the notion of a SDE.
Many investigations were devoted to the problems of existence, unique-
ness, and properties of solutions of SDEs. Suﬃcient conditions for existence
and uniqueness were obtained by Girsanov [21], Itˆo [25], Krylov [31], [32],
Skorokhod [42], Stroock and Varadhan [44], Zvonkin [49], and others. The
evolution of the theory has shown that it is reasonable to introduce dif-
ferent types of solutions (weak and strong solutions) and diﬀerent types of
uniqueness (uniqueness in law and pathwise uniqueness); see Liptser and
Shiryaev [33], Yamada and Watanabe [48], Zvonkin and Krylov [50]. More
information on SDEs and their applications can be found in the books [20],
[23], [28, Ch. 18], [29, Ch. 5], [33, Ch. IV], [36], [38, Ch. IX], [39, Ch. V], [45].
For one-dimensional homogeneous SDEs, i.e., the SDEs of the form
dXt = b(Xt)dt + σ(Xt)dBt,
X0 = x0,
(1)
one of the weakest suﬃcient conditions for weak existence and uniqueness in
law was obtained by Engelbert and Schmidt [12]–[15]. (In the case, where
b = 0, there exist even necessary and suﬃcient conditions; see the paper [12]
by Engelbert and Schmidt and the paper [1] by Assing and Senf.) Engelbert
and Schmidt proved that if σ(x) ̸= 0 for any x ∈R and
1 + |b|
σ2
∈L1
loc(R),
(2)
then there exists a unique solution of (1). (More precisely, there exists a
unique solution deﬁned up to the time of explosion.)
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 1–4, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

2
Introduction
Condition (2) is rather weak. Nevertheless, SDEs that do not satisfy this
condition often arise in theory and in practice. Such are, for instance, the
SDE for a geometric Brownian motion
dXt = µXtdt + σXtdBt,
X0 = x0
(the Black-Scholes model!) and the SDE for a δ-dimensional Bessel process
(δ > 1):
dXt = δ −1
2Xt
dt + dBt,
X0 = x0.
In practice, SDEs that do not satisfy (2) arise, for example, in the following
situation. Suppose that we model some process as a solution of (1). Assume
that this process is positive by its nature (for instance, this is the price of a
stock or the size of a population). Then a SDE used to model such a process
should not satisfy condition (2). The reason is as follows. If condition (2) is
satisﬁed, then, for any a ∈R, the solution reaches the level a with strictly
positive probability. (This follows from the results of Engelbert and Schmidt.)
The SDEs that do not satisfy condition (2) are called in this monograph
singular SDEs. The study of these equations is the subject of the monograph.
We investigate three main problems:
(i) Does there exist a solution of (1)?
(ii) Is it unique?
(iii) What is the qualitative behaviour of a solution?
In order to investigate singular SDEs, we introduce the following deﬁni-
tion. A point d ∈R is called a singular point for SDE (1) if
1 + |b|
σ2
/∈L1
loc(d).
We always assume that σ(x) ̸= 0 for any x ∈R. This is motivated by the
desire to exclude solutions which have sojourn time in any single point. (In-
deed, it is easy to verify that if σ ̸= 0 at a point z ∈R, then any solution
of (1) spends no time at z. This, in turn, implies that any solution of (1) also
solves the SDE with the same drift and the diﬀusion coeﬃcient σ −σ(z)I{z}.
“Conversely”, if σ = 0 at a point z ∈R and a solution of (1) spends no time
at z, then, for any η ∈R, it also solves the SDE with the same drift and the
diﬀusion coeﬃcient σ + ηI{z}.)
The ﬁrst question that arises in connection with this deﬁnition is: Why are
these points indeed “singular”? The answer is given in Section 2.1, where we
explain the qualitative diﬀerence between the singular points and the regular
points in terms of the behaviour of solutions.
Using the above terminology, we can say that a SDE is singular if and only
if the set of its singular points is nonempty. It is worth noting that in practice
one often comes across SDEs that have only one singular point (usually, it
is zero). Thus, the most important subclass of singular points is formed by
the isolated singular points. (We call d ∈R an isolated singular point if d is

Introduction
3
singular and there exists a deleted neighbourhood of d that consists of regular
points.)
In this monograph, we perform a complete qualitative classiﬁcation of
the isolated singular points. The classiﬁcation shows whether a solution can
leave an isolated singular point, whether it can reach this point, whether
it can be extended after having reached this point, and so on. According
to this classiﬁcation, an isolated singular point can have one of 48 possible
types. The type of a point is easily computed through the coeﬃcients b and
σ. The constructed classiﬁcation may be viewed as a counterpart (for SDEs)
of Feller’s classiﬁcation of boundary behaviour of continuous strong Markov
processes.
The monograph is arranged as follows.
Chapter 1 is an overview of basic deﬁnitions and facts related to SDEs,
more precisely, to the problems of the existence and the uniqueness of solu-
tions. In particular, we describe the relationship between diﬀerent types of
existence and uniqueness (see Figure 1.1 on p. 8) and cite some classical con-
ditions that guarantee existence and uniqueness. This chapter also includes
several important examples of SDEs. Moreover, we characterize all the pos-
sible combinations of existence and uniqueness (see Table 1.1 on p. 18).
In Chapter 2, we introduce the notion of a singular point and give the
arguments why these points are indeed “singular”. Then we study the ex-
istence, the uniqueness, and the qualitative behaviour of a solution in the
right-hand neighbourhood of an isolated singular point. This leads to the
one-sided classiﬁcation of isolated singular points. According to this classiﬁ-
cation, an isolated singular point can have one of 7 possible right types (see
Figure 2.2 on p. 39).
In Chapter 3, we investigate the existence, the uniqueness, and the qual-
itative behaviour of a solution in the two-sided neighbourhood of an isolated
singular point. We consider the eﬀects brought by the combination of right
and left types. Since there exist 7 possible right types and 7 possible left
types, there are 49 feasible combinations. One of these combinations corre-
sponds to a regular point, and therefore, an isolated singular point can have
one of 48 possible types. It turns out that the isolated singular points of only
4 types can disturb the uniqueness of a solution. We call them the branch
points and characterize all the strong Markov solutions in the neighbourhood
of such a point.
In Chapter 4, we investigate the behaviour of a solution “in the neigh-
bourhood of +∞”. This leads to the classiﬁcation at inﬁnity. According to
this classiﬁcation, +∞can have one of 3 possible types (see Figure 4.1 on
p. 83). The classiﬁcation shows, in particular, whether a solution can explode
into +∞. Thus, the well known Feller’s test for explosions is a consequence
of this classiﬁcation.
All the results of Chapters 2 and 3 apply to local solutions, i.e., solutions
up to a random time (this concept is introduced in Chapter 1). In the second

4
Introduction
part of Chapter 4, we use the obtained results to study the existence, the
uniqueness, and the qualitative behaviour of global solutions, i.e., solutions
in the classical sense. This is done for the SDEs that have no more than one
singular point (see Tables 4.1–4.3 on pp. 88, 89).
In Chapter 5, we consider the power equations, i.e., the equations of the
form
dXt = µ|Xt|αdt + ν|Xt|βdBt
and propose a simple procedure to determine the type of zero and the type
of inﬁnity for these SDEs (see Figure 5.1 on p. 94 and Figure 5.2 on p. 98).
Moreover, we study which types of zero and which types of inﬁnity are pos-
sible for the SDEs with a constant-sign drift (see Table 5.1 on p. 101 and
Table 5.2 on p. 103).
The known results from the stochastic calculus used in the proofs are con-
tained in Appendix A, while the auxiliary lemmas are given in Appendix B.
The monograph includes 7 ﬁgures with simulated paths of solutions of
singular SDEs.

1 Stochastic Diﬀerential Equations
In this chapter, we consider general multidimensional SDEs of the form (1.1)
given below.
In Section 1.1, we give the standard deﬁnitions of various types of the
existence and the uniqueness of solutions as well as some general theorems
that show the relationship between various properties.
Section 1.2 contains some classical suﬃcient conditions for various types
of existence and uniqueness.
In Section 1.3, we present several important examples that illustrate var-
ious combinations of the existence and the uniqueness of solutions. Most of
these examples (but not all) are well known. We also ﬁnd all the possible
combinations of existence and uniqueness.
Section 1.4 includes the deﬁnition of a martingale problem. We also recall
the relationship between the martingale problems and the SDEs.
In Section 1.5, we deﬁne a solution up to a random time.
1.1 General Deﬁnitions
Here we will consider a general type of SDEs, i.e., multidimensional SDEs
with coeﬃcients that depend on the past. These are the equations of the form
dXi
t = bi
t(X)dt +
m

j=1
σij
t (X)dBj
t ,
X0 = x0
(i = 1, . . . , n),
(1.1)
where n ∈N, m ∈N, x0 ∈Rn, and
b : C(R+, Rn) × R+ →Rn,
σ : C(R+, Rn) × R+ →Rn×m
are predictable functionals. (The deﬁnition of a predictable process can be
found, for example, in [27, Ch. I, §2 a] or [38, Ch. IV, § 5].)
Remark. We ﬁx a starting point x0 together with b and σ. In our terminology,
SDEs with the same b and σ and with diﬀerent starting points are diﬀerent
SDEs.
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 5–25, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

6
1 Stochastic Diﬀerential Equations
Deﬁnition 1.1. (i) A solution of (1.1) is a pair (Z, B) of adapted processes
on a ﬁltered probability space

Ω, G, (Gt)t≥0, Q

such that
(a) B is a m-dimensional (Gt)-Brownian motion, i.e., B is a m-dimensional
Brownian motion started at zero and is a (Gt, Q)-martingale;
(b) for any t ≥0,
 t
0
 n

i=1
|bi
s(Z)| +
n

i=1
m

j=1
(σij
s (Z))2

ds < ∞
Q-a.s.;
(c) for any t ≥0, i = 1, . . . , n,
Zi
t = xi
0 +
 t
0
bi
s(Z)ds +
m

j=1
 t
0
σij
s (Z)dBj
s
Q-a.s.
(ii) There is weak existence for (1.1) if there exists a solution of (1.1) on
some ﬁltered probability space.
Deﬁnition 1.2. (i) A solution (Z, B) is called a strong solution if Z is

F
B
t

-
adapted, where F
B
t is the σ-ﬁeld generated by σ(Bs; s ≤t) and by the subsets
of the Q-null sets from σ(Bs; s ≥0).
(ii) There is strong existence for (1.1) if there exists a strong solution
of (1.1) on some ﬁltered probability space.
Remark. Solutions in the sense of Deﬁnition 1.1 are sometimes called weak
solutions. Here we call them simply solutions. However, the existence of a
solution is denoted by the term weak existence in order to stress the diﬀerence
between weak existence and strong existence (i.e., the existence of a strong
solution).
Deﬁnition 1.3. There is uniqueness in law for (1.1) if for any solutions
(Z, B) and ( Z, B) (that may be deﬁned on diﬀerent ﬁltered probability
spaces), one has Law(Zt; t ≥0) = Law( Zt; t ≥0).
Deﬁnition 1.4. There is pathwise uniqueness for (1.1) if for any solutions
(Z, B) and ( Z, B) (that are deﬁned on the same ﬁltered probability space),
one has Q{∀t ≥0, Zt = Zt} = 1.
Remark. If there exists no solution of (1.1), then there are both uniqueness
in law and pathwise uniqueness.
The following 4 statements clarify the relationship between various prop-
erties.
Proposition 1.5. Let (Z, B) be a strong solution of (1.1).
(i) There exists a measurable map

1.1 General Deﬁnitions
7
Ψ :

C(R+, Rm), B

−→

C(R+, Rn), B

(here B denotes the Borel σ-ﬁeld) such that the process Ψ(B) is

F
B
t

-adapted
and Z = Ψ(B) Q-a.s.
(ii) If B is a m-dimensional ( Ft)-Brownian motion on a ﬁltered proba-
bility space
Ω, G, ( Gt), Q

and Z := Ψ( B), then ( Z, B) is a strong solution
of (1.1).
For the proof, see, for example, [5].
Now we state a well known result of Yamada and Watanabe.
Proposition 1.6 (Yamada, Watanabe).
Suppose that pathwise unique-
ness holds for (1.1).
(i) Uniqueness in law holds for (1.1);
(ii) There exists a measurable map
Ψ :

C(R+, Rm), B

−→

C(R+, Rn), B

such that the process Ψ(B) is

F
B
t

-adapted and, for any solution (Z, B)
of (1.1), we have Z = Ψ(B) Q-a.s.
For the proof, see [48] or [38, Ch. IX, Th. 1.7].
The following result complements the theorem of Yamada and Watanabe.
Proposition 1.7. Suppose that uniqueness in law holds for (1.1) and there
exists a strong solution. Then pathwise uniqueness holds for (1.1).
This theorem was proved by Engelbert [10] under some additional assump-
tions. It was proved with no additional assumptions by Cherny [7].
The crucial fact needed to prove Proposition 1.7 is the following result. It
shows that uniqueness in law implies a seemingly stronger property.
Proposition 1.8. Suppose that uniqueness in law holds for (1.1). Then, for
any solutions (Z, B) and ( Z, B) (that may be deﬁned on diﬀerent ﬁltered
probability spaces), one has Law(Zt, Bt; t ≥0) = Law( Zt, Bt; t ≥0).
For the proof, see [7].
The situation with solutions of SDEs can now be described as follows.
It may happen that there exists no solution of (1.1) on any ﬁltered prob-
ability space (see Examples 1.16, 1.17).
It may also happen that on some ﬁltered probability space there exists a
solution (or there are even several solutions with the same Brownian motion),
while on some other ﬁltered probability space with a Brownian motion there
exists no solution (see Examples 1.18, 1.19, 1.20, and 1.24).

8
1 Stochastic Diﬀerential Equations
weak
existence
strong
existence
uniqueness
in law
pathwise
uniqueness
weak
existence
strong
existence
uniqueness
in law
pathwise
uniqueness
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@






weak
existence
strong
existence
uniqueness
in law
pathwise
uniqueness
















@@
@@
@
@
@
@
weak
existence
pathwise
uniqueness
strong
existence
uniqueness
in law
the best
possible
situation



T
T
T



T
T
T
Fig. 1.1. The relationship between various types of existence and uniqueness. The
top diagrams show obvious implications and the implications given by the Yamada–
Watanabe theorem. The centre diagram shows an obvious implication and the im-
plication given by Proposition 1.7. The bottom diagram illustrates the Yamada–
Watanabe theorem and Proposition 1.7 in terms of the “best possible situation”.

1.2 Suﬃcient Conditions for Existence and Uniqueness
9
If there exists a strong solution of (1.1) on some ﬁltered probability space,
then there exists a strong solution on any other ﬁltered probability space
with a Brownian motion (see Proposition 1.5). However, it may happen in
this case that there are several solutions with the same Brownian motion (see
Examples 1.21–1.23).
If pathwise uniqueness holds for (1.1) and there exists a solution on some
ﬁltered probability space, then on any other ﬁltered probability space with a
Brownian motion there exists exactly one solution, and this solution is strong
(see the Yamada–Watanabe theorem). This is the best possible situation.
Thus, the Yamada–Watanabe theorem shows that pathwise uniqueness
together with weak existence guarantee that the situation is the best possible.
Proposition 1.7 shows that uniqueness in law together with strong existence
guarantee that the situation is the best possible.
1.2 Suﬃcient Conditions for Existence and Uniqueness
The statements given in this section are related to SDEs, for which bt(X) =
b(t, Xt) and σt(X) = σ(t, Xt), where b : R+ × Rn →Rn and σ : R+ × Rn →
Rn×m are measurable functions.
We begin with suﬃcient conditions for strong existence and pathwise
uniqueness. The ﬁrst result of this type was obtained by Itˆo.
Proposition 1.9 (Itˆo). Suppose that, for a SDE
dXi
t = bi(t, Xt)dt +
m

j=1
σij(t, Xt)dBj
t ,
X0 = x0
(i = 1, . . . , n),
there exists a constant C > 0 such that
∥b(t, x) −b(t, y)∥+ ∥σ(t, x) −σ(t, y)∥≤C∥x −y∥,
t ≥0, x, y ∈Rn,
∥b(t, x)∥+ ∥σ(t, x)∥≤C(1 + ∥x∥),
t ≥0, x ∈Rn,
where
∥b(t, x)∥:=
 n

i=1
(bi(t, x))2
1/2
,
∥σ(t, x)∥:=
 n

i=1
m

j=1
(σij(t, x))2
1/2
.
Then strong existence and pathwise uniqueness hold.
For the proof, see [25], [29, Ch. 5, Th. 2.9], or [36, Th. 5.2.1].

10
1 Stochastic Diﬀerential Equations
Proposition 1.10 (Zvonkin). Suppose that, for a one-dimensional SDE
dXt = b(t, Xt)dt + σ(t, Xt)dBt,
X0 = x0,
the coeﬃcient b is measurable and bounded, the coeﬃcient σ is continuous
and bounded, and there exist constants C > 0, ε > 0 such that
|σ(t, x) −σ(t, y)| ≤C

|x −y|,
t ≥0, x, y ∈R,
|σ(t, x)| ≥ε,
t ≥0, x ∈R.
Then strong existence and pathwise uniqueness hold.
For the proof, see [49].
For homogeneous SDEs, there exists a stronger result.
Proposition 1.11 (Engelbert, Schmidt).
Suppose that, for a one-
dimensional SDE
dXt = b(Xt)dt + σ(Xt)dBt,
X0 = x0,
σ ̸= 0 at each point, b/σ2 ∈L1
loc(R), and there exists a constant C > 0 such
that
|σ(x) −σ(y)| ≤C

|x −y|,
x, y ∈R,
|b(x)| + |σ(x)| ≤C(1 + |x|),
x ∈R.
Then strong existence and pathwise uniqueness hold.
For the proof, see [15, Th. 5.53].
The following proposition guarantees only pathwise uniqueness. Its main
diﬀerence from Proposition 1.10 is that the diﬀusion coeﬃcient here need not
be bounded away from zero.
Proposition 1.12 (Yamada, Watanabe).
Suppose that, for a one-
dimensional SDE
dXt = b(t, Xt)dt + σ(t, Xt)dBt,
X0 = x0,
there exist a constant C > 0 and a strictly increasing function h : R+ →R+
with
	 0+
0
h−2(x)dx = +∞such that
|b(t, x) −b(t, y)| ≤C|x −y|,
t ≥0, x, y ∈R,
|σ(t, x) −σ(t, y)| ≤h(|x −y|),
t ≥0, x, y ∈R.
Then pathwise uniqueness holds.

1.2 Suﬃcient Conditions for Existence and Uniqueness
11
For the proof, see [29, Ch. 5, Prop. 2.13], [38, Ch. IX, Th. 3.5], or [39, Ch. V,
Th. 40.1].
We now turn to results related to weak existence and uniqueness in law.
The ﬁrst of these results guarantees only weak existence; it is almost covered
by further results, but not completely. Namely, here the diﬀusion matrix σ
need not be elliptic (it might even be not a square matrix).
Proposition 1.13 (Skorokhod). Suppose that, for a SDE
dXi
t = bi(t, Xt)dt +
m

j=1
σij(t, Xt)dBj
t ,
Xi
0 = xi
0
(i = 1, . . . , n),
the coeﬃcients b and σ are continuous and bounded. Then weak existence
holds.
For the proof, see [42] or [39, Ch. V, Th. 23.5].
Remark. The conditions of Proposition 1.13 guarantee neither strong exis-
tence (see Example 1.19) nor uniqueness in law (see Example 1.22).
In the next result, the conditions on b and σ are essentially relaxed as
compared with the previous proposition.
Proposition 1.14 (Stroock, Varadhan). Suppose that, for a SDE
dXi
t = bi(t, Xt)dt +
n

j=1
σij(t, Xt)dBj
t ,
X0 = x0
(i = 1, . . . , n),
the coeﬃcient b is measurable and bounded, the coeﬃcient σ is continuous
and bounded, and, for any t ≥0, x ∈Rn, there exists a constant ε(t, x) > 0
such that
∥σ(t, x)λ∥≥ε(t, x)∥λ∥,
λ ∈Rn.
Then weak existence and uniqueness in law hold.
For the proof, see [44, Th. 4.2, 5.6].
In the next result, the diﬀusion coeﬃcient σ need not be continuous.
However, the statement deals with homogeneous SDEs only.
Proposition 1.15 (Krylov). Suppose that, for a SDE
dXi
t = bi(Xt)dt +
n

j=1
σij(Xt)dBj
t ,
X0 = x0
(i = 1, . . . , n),
the coeﬃcient b is measurable and bounded, the coeﬃcient σ is measurable
and bounded, and there exist a constant ε > 0 such that
∥σ(x)λ∥≥ε∥λ∥,
x ∈Rn, λ ∈Rn.
Then weak existence holds. If moreover n ≤2, then uniqueness in law holds.

12
1 Stochastic Diﬀerential Equations
For the proof, see [32].
Remark. In the case n > 2, the conditions of Proposition 1.15 do not guar-
antee uniqueness in law (see Example 1.24).
1.3 Ten Important Examples
In the examples given below, we will use the characteristic diagrams
to illustrate the statement of each example. The ﬁrst square in the
diagram corresponds to weak existence; the second – to strong existence; the
third – to uniqueness in law; the fourth – to pathwise uniqueness. Thus, the
statement “for the SDE . . . , we have + −+ −” should be read as follows:
“for the SDE . . . , there exists a solution, there exists no strong solution,
uniqueness in law holds, and pathwise uniqueness does not hold”.
We begin with examples of SDEs with no solution.
Example 1.16 (no solution). For the SDE
dXt = −sgnXtdt,
X0 = 0,
(1.2)
where
sgn x =

1
if x > 0,
−1
if x ≤0,
(1.3)
we have −−+ + .
Proof. Suppose that there exists a solution (Z, B). Then almost all paths
of Z satisfy the integral equation
f(t) = −
 t
0
sgn f(s)ds,
t ≥0.
(1.4)
Let f be a solution of this equation. Assume that there exist a > 0, t > 0
such that f(t) = a. Set v = inf{t ≥0 : f(t) = a}, u = sup{t ≤v : f(t) = 0}.
Using (1.4), we get a = f(v) −f(u) = −(v −u). The obtained contradiction
shows that f ≤0. In a similar way we prove that f ≥0. Thus, f ≡0, but
then it is not a solution of (1.4). As a result, (1.4), and hence, (1.2), has no
solution.
⊓⊔
The next example is a SDE with the same characteristic diagram and
with σ ≡1.
Example 1.17 (no solution). For the SDE
dXt = −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = 0,
(1.5)
we have −−+ + .

1.3 Ten Important Examples
13
Proof. Suppose that (Z, B) is a solution of (1.5). Then
Zt = −
 t
0
1
2Zs
I(Zs ̸= 0)ds + Bt,
t ≥0.
By Itˆo’s formula,
Z2
t = −
 t
0
2Zs
1
2Zs
I(Zs ̸= 0)ds +
 t
0
2ZsdBs + t
=
 t
0
I(Zs = 0)ds +
 t
0
2ZsdBs,
t ≥0.
The process Z is a continuous semimartingale with ⟨Z⟩t = t. Hence, by the
occupation times formula,
 t
0
I(Zs = 0)ds =

R
I(x = 0)Lx
t (Z)dx = 0,
t ≥0,
where Lx
t (Z) denotes the local time of the process Z (see Deﬁnition A.2). As a
result, Z2 is a positive local martingale, and consequently, a supermartingale.
Since Z2 ≥0 and Z2
0 = 0, we conclude that Z2 = 0 a.s. But then (Z, B) is
not a solution of (1.5).
⊓⊔
Now we turn to the examples of SDEs that possess a solution, but no
strong solution.
Example 1.18 (no strong solution; Tanaka). For the SDE
dXt = sgn XtdBt,
X0 = 0
(1.6)
(for the precise deﬁnition of sgn, see (1.3)), we have + −+ −.
Proof. Let W be a Brownian motion on (Ω, G, Q). We set
Zt = Wt,
Bt =
 t
0
sgn WsdWs,
t ≥0
and take Gt = FW
t . Obviously, (Z, B) is a solution of (1.6) on

Ω, G, (Gt), Q

.
If (Z, B) is a solution of (1.6) on a ﬁltered probability space

Ω, G, (Gt), Q

,
then Z is a continuous (Gt, Q)-local martingale with ⟨Z⟩t = t. It follows from
P. L´evy’s characterization theorem that Z is a Brownian motion. This implies
uniqueness in law.
If (Z, B) is a solution of (1.6), then
Bt =
 t
0
sgn ZsdZs,
t ≥0.
This implies that FB
t = F|Z|
t
(see [38, Ch. VI, Cor. 2.2]). Hence, there exists
no strong solution.
If (Z, B) is a solution of (1.6), then (−Z, B) is also a solution. Thus, there
is no pathwise uniqueness.
⊓⊔

14
1 Stochastic Diﬀerential Equations
The next example is a SDE with the same characteristic diagram, b = 0,
and a continuous σ.
Example 1.19 (no strong solution; Barlow). There exists a continuous
bounded function σ : R →(0, ∞) such that, for the SDE
dXt = σ(Xt)dBt,
X0 = x0,
we have + −+ −.
For the proof, see [2].
The next example is a SDE with the same characteristic diagram and
with σ ≡1. The drift coeﬃcient in this example depends on the past.
Example 1.20 (no strong solution; Tsirelson). There exists a bounded
predictable functional b : C(R+) × R+ →R such that, for the SDE
dXt = bt(X)dt + dBt,
X0 = x0,
we have + −+ −.
For the proof, see [46], [23, Ch. IV, Ex. 4.1], or [38, Ch. IX, Prop. 3.6].
Remark. Let B be a Brownian motion on (Ω, G, Q). Set Gt = FB
t . Then
the SDEs of Examples 1.18–1.20 have no solution on

Ω, G, (Gt), Q

with the
Brownian motion B. Indeed, if (Z, B) is a solution, then Z is (Gt)-adapted,
which means that (Z, B) is a strong solution.
We now turn to examples of SDEs, for which there is no uniqueness in
law.
Example 1.21 (no uniqueness in law). For the SDE
dXt = I(Xt ̸= 0)dBt,
X0 = 0,
(1.7)
we have + + −−.
Proof. It is suﬃcient to note that (B, B) and (0, B) are solutions of (1.7) on

Ω, G, (Gt), Q

whenever B is a (Gt)-Brownian motion.
⊓⊔
Remark. Let B be a Brownian motion on (Ω, G, Q) and η be a random vari-
able that is independent of B with P{η = 1} = P{η = −1} = 1/2. Consider
Zt(ω) =

Bt(ω)
if η(ω) = 1,
0
if η(ω) = −1
and take Gt = FZ
t . Then (Z, B) is a solution of (1.7) on

Ω, G, (Gt), Q

that
is not strong. Indeed, for each t > 0, η is not F
B
t -measurable. Since the sets
{η = −1} and {Zt = 0} are indistinguishable, Zt is not F
B
t -measurable.

1.3 Ten Important Examples
15
The next example is a SDE with the same characteristic diagram, b = 0,
and a continuous σ.
Example 1.22 (no uniqueness in law; Girsanov).
Let 0 < α < 1/2.
Then, for the SDE
dXt = |Xt|αdBt,
X0 = 0,
(1.8)
we have + + −−.
Proof. Let W be a Brownian motion started at zero on (Ω, G, Q) and
At =
 t
0
|Ws|−2αds,
t ≥0,
τt = inf{s ≥0 : As > t},
t ≥0,
Zt = Wτt,
t ≥0.
The occupation times formula and Proposition A.6 (ii) ensure that At is a.s.
continuous and ﬁnite. It follows from Proposition A.9 that At
a.s.
−−−→
t→∞
∞.
Hence, τ is a.s. ﬁnite, continuous, and strictly increasing. By Proposi-
tion A.16, Z is a continuous (FW
τt )-local martingale with ⟨Z⟩t = τt. Using
Proposition A.18, we can write
τt =
 τt
0
ds =
 τt
0
|Ws|2αdAs =
 Aτt
0
|Wτs|2αds =
 t
0
|Zs|2αds,
t ≥0.
(We have Aτt = t due to the continuity of A and the property At
a.s.
−−−→
t→∞∞.)
Hence, the process
Bt =
 t
0
|Zs|−αdZs,
t ≥0
is a continuous (FW
τt )-local martingale with ⟨B⟩t = t. According to P. L´evy’s
characterization theorem, B is a (FW
τt )-Brownian motion. Thus, (Z, B) is a
solution of (1.8).
Now, all the desired statements follow from the fact that (0, B) is another
solution of (1.8).
⊓⊔
The next example is a SDE with the same characteristic diagram and
with σ ≡1.
Example 1.23 (no uniqueness in law; SDE for a Bessel process). For
the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = 0
(1.9)
with δ > 1, we have + + −−.

16
1 Stochastic Diﬀerential Equations
Proof. It follows from Proposition A.21 that there exists a solution (Z, B)
of (1.9) such that Z is positive. By Itˆo’s formula,
Z2
t =
 t
0
(δ −1)I(Zs ̸= 0)ds + 2
 t
0
ZsdBs + t
= δt −
 t
0
(δ −1)I(Zs = 0)ds + 2
 t
0

|Z2s|dBs,
t ≥0.
By the occupation times formula,
 t
0
I(Zs = 0)ds =
 t
0
I(Zs = 0)d⟨Z⟩s =

R
I(x = 0)Lx
t (Z)dx = 0,
t ≥0.
Hence, the pair (Z2, B) is a solution of the SDE
dXt = δdt + 2

|Xt|dBt,
X0 = 0.
Propositions 1.6 and 1.12 combined together show that Z2 is

F
B
t

-adapted.
As Z is positive, Z is also

F
B
t

-adapted, which means that (Z, B) is a strong
solution.
By Proposition 1.5 (i), there exists a measurable map Ψ : C(R+) →
C(R+) such that the process Ψ(B) is

F
B
t

-adapted and Z = Ψ(B) a.s. For
any t ≥0, we have
Ψt(B) =
 t
0
δ −1
2Ψs(B)I

Ψs(B) ̸= 0

ds + Bt
a.s.
The process B = −B is a Brownian motion. Hence, for any t ≥0,
−Ψt(−B) =
 t
0
δ −1
−2Ψs(−B)I

−Ψs(−B) ̸= 0

ds + Bt
a.s.
Consequently, the pair ( Z, B), where Z = −Ψ(−B), is a (strong) solution
of (1.9). Obviously, Z is positive, while Z is negative. Hence, Z and Z have
a.s. diﬀerent paths and diﬀerent laws. This implies that there is no uniqueness
in law and no pathwise uniqueness for (1.9).
⊓⊔
Remark. More information on SDE (1.9) can be found in [5]. In particular,
it is proved in [5] that this equation possesses solutions that are not strong.
Moreover, it is shown that, for the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
(1.10)
(here the starting point x0 is arbitrary) with 1 < δ < 2, we have + + −−;
for SDE (1.10) with δ ≥2, x0 ̸= 0, we have + + + + . The SDE for a Bessel
process is also considered in Sections 2.2, 3.4.

1.3 Ten Important Examples
17
The following rather surprising example has multidimensional nature.
Example 1.24 (no uniqueness in law; Nadirashvili). Let n ≥3. There
exists a function σ : Rn →Rn×n such that
ε∥λ∥≤∥σ(x)λ∥≤C∥λ∥,
x ∈Rn, λ ∈Rn
with some constants C > 0, ε > 0 and, for the SDE
dXi
t =
n

j=1
σij(Xt)dBj
t ,
X0 = x0
(i = 1, . . . , n),
we have +
−−.
For the proof, see [35] or [40].
We ﬁnally present one more example. Its characteristic diagram is diﬀerent
from all the diagrams that appeared so far.
Example 1.25 (no strong solution and no uniqueness). For the SDE
dXt = σ(t, Xt)dBt,
X0 = 0
(1.11)
with
σ(t, x) =

sgn x
if t ≤1,
I(x ̸= 1) sgn x
if t > 1
(for the precise deﬁnition of sgn, see (1.3)), we have + −−−.
Proof. If W is a Brownian motion, then the pair
Zt = Wt,
Bt =
 t
0
sgn WsdWs,
t ≥0
(1.12)
is a solution of (1.11).
Let (Z, B) be the solution given by (1.12). Set τ = inf{t ≥1 : Zt = 1},
Zt = Zt∧τ. Then ( Z, B) is another solution. Thus, there is no uniqueness in
law and no pathwise uniqueness.
If (Z, B) is a solution of (1.12), then
Zt =
 t
0
sgn ZsdBs,
t ≤1.
The arguments used in the proof of Example 1.18 show that (Z, B) is not a
strong solution.
⊓⊔

18
1 Stochastic Diﬀerential Equations
Table 1.1. Possible and impossible combinations of existence and uniqueness. As
an example, the combination “+ −+−” in line 11 corresponds to a SDE, for which
there exists a solution, there exists no strong solution, there is uniqueness in law,
and there is no pathwise uniqueness. The table shows that such a SDE is provided
by each of Examples 1.18–1.20.
Weak
Strong
Uniqueness
Pathwise
existence existence
in law
uniqueness
Possible/Impossible
−
−
−
−
impossible, obviously
−
−
−
+
impossible, obviously
−
−
+
−
impossible, obviously
−
−
+
+
possible, Examples 1.16,1.17
−
+
−
−
impossible, obviously
−
+
−
+
impossible, obviously
−
+
+
−
impossible, obviously
−
+
+
+
impossible, obviously
+
−
−
−
possible, Example 1.25
+
−
−
+
impossible, Proposition 1.6
+
−
+
−
possible, Examples 1.18–1.20
+
−
+
+
impossible, Proposition 1.6
+
+
−
−
possible, Examples 1.21–1.23
+
+
−
+
impossible, Proposition 1.6
+
+
+
−
impossible, Proposition 1.7
+
+
+
+
possible, obviously
Remark. The SDE
dXt = I(Xt ̸= 1) sgn XtdBt,
X0 = 0
is a homogeneous SDE with the same characteristic diagram as in Exam-
ple 1.25. However, it is more diﬃcult to prove that this equation has no
strong solution.
Let us mention one of the applications of the results given above. For
SDE (1.1), each of the following properties:
weak existence,
strong existence,
uniqueness in law,
pathwise uniqueness

1.4 Martingale Problems
19
may hold or may not hold. Thus, there are 16 (= 24) feasible combinations.
Some of these combinations are impossible (for instance, if there is pathwise
uniqueness, then there must be uniqueness in law). For each of these com-
binations, Propositions 1.6, 1.7 and Examples 1.16–1.25 allow one either to
provide an example of a corresponding SDE or to prove that this combination
is impossible. It turns out that there are only 5 possible combinations (see
Table 1.1).
1.4 Martingale Problems
Let n ∈N, x0 ∈Rn and
b : C(R+, Rn) × R+ →Rn,
a : C(R+, Rn) × R+ →Rn×n
be predictable functionals. Suppose moreover that, for any t ≥0 and
ω ∈C(R+, Rn), the matrix at(ω) is positively deﬁnite.
Throughout this section, X = (Xt; t ≥0) will denote the coordinate
process on C(R+, Rn), i.e., the process deﬁned by
Xt : C(R+, Rn) ∋ω −→ω(t) ∈Rn.
By (Ft) we will denote the canonical ﬁltration on C(R+), i.e., Ft
=
σ(Xs; s ≤t), and F will stand for the σ-ﬁeld 
t≥0 Ft = σ(Xs; s ≥0). Note
that F coincides with the Borel σ-ﬁeld B(C(R+, Rn)).
Deﬁnition 1.26. A solution of the martingale problem (x0, b, a) is a measure
P on B(C(R+, Rn)) such that
(a) P{X0 = x0} = 1;
(b) for any t ≥0,
 t
0
 n

i=1
|bi
s(X)| +
n

i=1
aii(X)

ds < ∞
P-a.s.;
(c) for any i = 1, . . . , n, the process
M i
t = Xi
t −
 t
0
bi
s(X)ds,
t ≥0
(1.13)
is a (Ft, P)-local martingale;
(d) for any i, j = 1, . . . , n, the process
M i
tM j
t −
 t
0
aij
s (X)ds,
t ≥0
is a (Ft, P)-local martingale.

20
1 Stochastic Diﬀerential Equations
Let us now consider SDE (1.1) and set
at(ω) = σt(ω)σ∗
t (ω),
t ≥0, ω ∈C(R+, Rn),
where σ∗denotes the transpose of the matrix σ. Then the martingale problem
(x0, b, a) is called a martingale problem corresponding to SDE (1.1). The
relationship between (1.1) and this martingale problem becomes clear from
the following statement.
Theorem 1.27. (i) Let (Z, B) be a solution of (1.1). Then the measure
P = Law(Zt; t ≥0) is a solution of the martingale problem (x0, b, a).
(ii) Let P be a solution of the martingale problem (x0, b, a). Then there
exist a ﬁltered probability space

Ω, G, (Gt), Q

and a pair of processes (Z, B)
on this space such that (Z, B) is a solution of (1.1) and Law(Zt; t ≥0) = P.
Proof. (i) Conditions (a), (b) of Deﬁnition 1.26 are obviously satisﬁed. Let
us check condition (c). Set
Nt = Zt −
 t
0
bs(Z)ds,
t ≥0.
(We use here the vector form of notation.) For m ∈N, we consider the
stopping time Sm(N) = inf{t ≥0 : ∥Nt∥≥m}. Since N is a (Gt, Q)-local
martingale, the stopped process N Sm(N) is a (Gt, Q)-martingale. Hence, for
any 0 ≤s < t and C ∈Fs, we have
EQ

N Sm(N)
t
−N Sm(N)
s

I(Z ∈C)

= 0.
Therefore,
EP

M Sm(M)
t
−M Sm(M)
s

I(X ∈C)

= 0,
where M is given by (1.13) and Sm(M) = inf{t ≥0 : ∥Mt∥≥m}. This
proves that M ∈Mc
loc(Ft, P). Condition (d) of Deﬁnition 1.26 is veriﬁed in
a similar way.
(ii) (Cf. [39, Ch. V, Th. 20.1].) Let Ω1 = C(R+, Rn), G1
t = Ft, G1 = F,
Q1 = P. Choose a ﬁltered probability space

Ω2, G2, (G2
t ), Q2
with a m-
dimensional (G2
t )-Brownian motion W and set
Ω= Ω1 × Ω2,
G = G1 × G2,
Gt = G1
t × G2
t ,
Q = Q1 × Q2.
We extend the processes b, σ, a from Ω1 to Ωand the process W from Ω2
to Ωin the obvious way.
For any t ≥0, ω ∈Ω, the matrix σt(ω) corresponds to a linear operator
Rm →Rn. Let ϕt(ω) be the m × m-matrix of the operator of orthogonal
projection onto (ker σt(ω))⊥, where ker σt(ω) denotes the kernel of σt(ω); let
ψt(ω) be the m × m-matrix of the operator of orthogonal projection onto
ker σt(ω). Then ϕ = (ϕt; t ≥0) and ψ = (ψt; t ≥0) are predictable Rm×m-
valued processes. For any t ≥0, ω ∈Ω, the restriction of the operator σt(ω)

1.4 Martingale Problems
21
to (ker σt(ω))⊥is a bijection from (ker σt(ω))⊥⊆Rm onto Im σt(ω) ⊆Rn,
where Im σt(ω) denotes the image of σt(ω). Let us deﬁne the operator χt(ω) :
Rn →Rm as follows: χt(ω) maps Im σt(ω) onto (ker σt(ω))⊥as the inverse
of σt(ω); χt(ω) vanishes on (Im σt(ω))⊥. Obviously, χ = (χt; t ≥0) is a
predictable Rm×n-valued process. We have χt(ω)σt(ω) = ϕt(ω).
Deﬁne the process Z as Zt(ω1, ω2) = ω1(t) and the process M as
Mt = Zt −
 t
0
bsds,
t ≥0.
Let us set
Bt =
 t
0
χsdMs +
 t
0
ψsdWs,
t ≥0.
(We use here the vector form of notation.) For any i, j = 1, . . . , n, we have
⟨Bi, Bj⟩t =
 t
0
n

k,l=1
χik
s akl
s χjl
s ds +
 t
0
n

k=1
ψik
s ψjk
s ds
=
 t
0
(χsσsσ∗
sχ∗
s)ijds +
 t
0
(ψsψ∗
s)ijds
=
 t
0
(ϕsϕ∗
s)ijds +
 t
0
(ψsψ∗
s)ijds
=
 t
0

(ϕs + ψs)(ϕ∗
s + ψ∗
s)
ijds
=
 t
0
δijds = δijt,
t ≥0.
By the multidimensional version of P. L´evy’s characterization theorem
(see [38, Ch. IV, Th. 3.6]), we deduce that B is a m-dimensional (Gt)-
Brownian motion.
Set ρt(ω) = σt(ω)χt(ω). Let us consider the process
Nt =
 t
0
σsdBs =
 t
0
σsχsdMs +
 t
0
σsψsdWs =
 t
0
ρsdMs,
t ≥0.
Then, for any i = 1, . . . , n, we have
⟨N i⟩t =
 t
0
(ρsasρ∗
s)iids =
 t
0
(σsχsσsσ∗
sχ∗
sσ∗
s)iids
=
 t
0
(σsσ∗
s)iids =
 t
0
aii
s ds = ⟨M i⟩t,
t ≥0.
(1.14)
(We have used the obvious equality σsχsσs = σs.) Furthermore,

22
1 Stochastic Diﬀerential Equations
⟨N i, M i⟩t =
 t
0
(ρsas)iids =
 t
0
(σsχsσsσ∗
s)iids
=
 t
0
(σsσ∗
s)iids =
 t
0
aii
s ds = ⟨M i⟩t,
t ≥0.
(1.15)
Comparing (1.14) with (1.15), we deduce that ⟨N i −M i⟩= 0. Hence,
M = x0 + N. As a result, the pair (Z, B) is a solution of (1.1).
⊓⊔
In this monograph, we will investigate only weak solutions and uniqueness
in law for SDE (1). It will be more convenient for us to consider a solution
of (1) as a solution of the corresponding martingale problem rather than to
treat it in the sense of Deﬁnition 1.1. The reason is that in this case a solution
is a single object and not a pair of processes as in Deﬁnition 1.1. This approach
is justiﬁed by Theorem 1.27. Thus, from here on, we will always deal with
the following deﬁnition, which is a reformulation of Deﬁnition 1.26 for the
case of the SDEs having the form (1).
Deﬁnition 1.28. A solution of SDE (1) is a measure P on B(C(R+)) such
that
(a) P{X0 = x0} = 1;
(b) for any t ≥0,
 t
0

|b(Xs)| + σ2(Xs)

ds < ∞
P-a.s.;
(c) the process
Mt = Xt −
 t
0
b(Xs)ds,
t ≥0
(1.16)
is a (Ft, P)-local martingale;
(d) the process
M 2
t −
 t
0
σ2(Xs)ds,
t ≥0
is a (Ft, P)-local martingale.
Remark. If one accepts Deﬁnition 1.28, then the existence and uniqueness
of a solution are deﬁned in an obvious way. It follows from Theorem 1.27
that the existence of a solution in the sense of Deﬁnition 1.28 is equivalent
to weak existence (Deﬁnition 1.1); the uniqueness of a solution in the sense
of Deﬁnition 1.28 is equivalent to uniqueness in law (Deﬁnition 1.3).
Deﬁnition 1.29. (i) A solution P of (1) is positive if P{∀t ≥0, Xt ≥0} = 1.
(ii) A solution P of (1) is strictly positive if P{∀t ≥0, Xt > 0} = 1.
The negative and strictly negative solutions are deﬁned in a similar way.

1.5 Solutions up to a Random Time
23
1.5 Solutions up to a Random Time
There are several reasons why we consider solutions up to a random time.
First, a solution may explode. Second, a solution may not be extended after
it reaches some level. Third, we can guarantee in some cases that a solution
exists up to the ﬁrst time it leaves some interval, but we cannot guarantee
the existence of a solution after that time (see Chapter 2).
In order to deﬁne a solution up to a random time, we replace the space
C(R+) of continuous functions by the space C(R+) deﬁned below. We need
this space to consider exploding solutions. Let π be an isolated point added
to the real line.
Deﬁnition 1.30. The space C(R+) consists of the functions f : R+ →R ∪
{π} with the following property: there exists a time ξ(f) ∈[0, ∞] such that
f is continuous on [0, ξ(f)) and f = π on [ξ(f), ∞). The time ξ(f) is called
the killing time of f.
Throughout this section, X = (Xt; t ≥0) will denote the coordinate
process on C(R+), i.e.,
Xt : C(R+) ∋ω −→ω(t) ∈R ∪{π},
(Ft) will denote the canonical ﬁltration on C(R+), i.e., Ft = σ(Xs; s ≤t),
and F will stand for the σ-ﬁeld 
t≥0 Ft = σ(Xs; s ≥0).
Remark. There exists a metric on C(R+) with the following properties.
(a) It turns C(R+) into a Polish space.
(b) The convergence fn →f in this metric is equivalent to:
ξ(fn) −−−−→
n→∞ξ(f);
∀t < ξ(f), sup
s≤t
|fn(s) −f(s)| −−−−→
n→∞0.
(In particular, C(R+) is a closed subspace in this metric.)
(c) The Borel σ-ﬁeld on C(R+) with respect to this metric coincides with
σ(Xt; t ≥0).
In what follows, we will need two diﬀerent notions: a solution up to S and
a solution up to S−.
Deﬁnition 1.31. Let S be a stopping time on C(R+). A solution of (1) up
to S (or a solution deﬁned up to S) is a measure P on FS such that
(a) P{∀t ≤S, Xt ̸= π} = 1;
(b) P{X0 = x0} = 1;
(c) for any t ≥0,
 t∧S
0

|b(Xs)| + σ2(Xs)

ds < ∞
P-a.s.;

24
1 Stochastic Diﬀerential Equations
(d) the process
Mt = Xt∧S −
 t∧S
0
b(Xs)ds,
t ≥0
(1.17)
is a (Ft, P)-local martingale;
(e) the process
M 2
t −
 t∧S
0
σ2(Xs)ds,
t ≥0
is a (Ft, P)-local martingale.
In the following, we will often say that (P, S) is a solution of (1).
Remarks. (i) The measure P is deﬁned on FS and not on F since otherwise
it would not be unique.
(ii) In the usual deﬁnition of a local martingale, the probability measure
is deﬁned on F. Here P is deﬁned on a smaller σ-ﬁeld FS. However, in view
of the equality M S = M, the knowledge of P only on FS is suﬃcient to
verify the inclusion M ∈Mc
loc(Ft, P) that arises in (d). In other words, if
P and P′ are probability measures on F such that P|FS = P′|FS = P, then
M ∈Mc
loc(Ft, P) if and only if M ∈Mc
loc(Ft, P′) (so we can write simply
M ∈Mc
loc(Ft, P)). In order to prove this statement, note that the inclusion
M ∈Mc
loc(Ft, P) means that there exists a sequence of stopping times (Sn)
such that
(a) Sn ≤Sn+1;
(b) Sn ≤S;
(c) for any t ≥0, P{t∧Sn = t∧S}−−−−→
n→∞1 (note that {t ∧Sn =t ∧S}∈FS);
(d) for any s ≤t, C ∈Fs, and n ∈N,
EP

Mt∧Sn −Ms∧Sn

I(C)

= 0.
This expression makes sense since the random variable

Mt∧Sn −Ms∧Sn

I(C) =

Mt∧Sn −Ms∧Sn

I(C ∩{Sn > s})
is FS-measurable.
Similarly, in order to verify conditions (a), (b), (c), and (e), it is suﬃcient
to know the values of P only on FS.
Deﬁnition 1.32. (i) A solution (P, S) is positive if P{∀t ≤S, Xt ≥0} = 1.
(ii) A solution (P, S) is strictly positive if P{∀t ≤S, Xt > 0} = 1.
The negative and strictly negative solutions are deﬁned in a similar way.
Recall that a function S : C(R+) →[0, ∞] is called a predictable stopping
time if there exists a sequence (Sn) of (Ft)-stopping times such that
(a) Sn ≤Sn+1;
(b) Sn ≤S and Sn < S on the set {S > 0};
(c) limn Sn = S.
In the following, we will call (Sn) a predicting sequence for S.

1.5 Solutions up to a Random Time
25
Deﬁnition 1.33. Let S be a predictable stopping time on C(R+) with a
predicting sequence (Sn). A solution of (1) up to S−(or a solution deﬁned
up to S−) is a measure P on FS−such that, for any n ∈N, the restriction
of P to FSn is a solution up to Sn.
In the following, we will often say that (P, S−) is a solution of (1).
Remarks. (i) Obviously, this deﬁnition does not depend on the choice of a
predicting sequence for S.
(ii) Deﬁnition 1.33 implies that P{∀t < S, Xt ̸= π} = 1.
(iii) When dealing with solutions up to S, one may use the space C(R+).
The space C(R+) is essential only for solutions up to S−.
In this monograph, we will use the following terminology: a solution in
the sense of Deﬁnition 1.28 will be called a global solution, while a solution in
the sense of Deﬁnition 1.31 or Deﬁnition 1.33 will be called a local solution.
The next statement clariﬁes the relationship between these two notions.
Theorem 1.34. (i) Suppose that (P, S) is a solution of (1) in the sense
of Deﬁnition 1.31 and S = ∞P-a.s. Then P admits a unique extension
P to F. Let Q be the measure on C(R+) deﬁned as the restriction of P to
{ξ = ∞} = C(R+). Then Q is a solution of (1) in the sense of Deﬁnition 1.28.
(ii) Let Q be a solution of (1) in the sense of Deﬁnition 1.28. Let P be
the measure on C(R+) deﬁned as P(A) = Q(A ∩{ξ = ∞}). Then (P, ∞) is
a solution of (1) in the sense of Deﬁnition 1.31.
Proof. (i) The existence and the uniqueness of P follow from Lemma B.5.
The latter part of (i) as well as statement (ii) are obvious.
⊓⊔

2 One-Sided Classiﬁcation
of Isolated Singular Points
In this chapter, we consider SDEs of the form (1).
Section 2.1 deals with the following question: Which points should be called
singular for SDE (1)? This section contains the deﬁnition of a singular point
as well as the reasoning that these points are indeed “singular”.
Several natural examples of SDEs with isolated singular points are given
in Section 2.2. These examples illustrate how a solution may behave in the
neighbourhood of such a point.
In Section 2.3 we investigate the behaviour of a solution of (1) in the right-
hand neighbourhood of an isolated singular point. We present a complete
qualitative classiﬁcation of diﬀerent types of behaviour.
Section 2.4 contains an informal description of the constructed classiﬁca-
tion.
The statements that are formulated in Section 2.3 are proved in Sec-
tion 2.5.
Throughout this chapter, we assume that σ(x) ̸= 0 for all x ∈R.
2.1 Isolated Singular Points: The Deﬁnition
In this section, except for Proposition 2.2 and Theorem 2.8, we will deal with
global solutions, i.e., solutions in the sense of Deﬁnition 1.28.
Throughout the section, except for Proposition 2.2 and Theorem 2.8, X
denotes the coordinate process on C(R+) and (Ft) stands for the canonical
ﬁltration on C(R+).
Deﬁnition 2.1. (i) A measurable function f : R →R is locally integrable at
a point d ∈R if there exists δ > 0 such that
 d+δ
d−δ
|f(x)|dx < ∞.
We will use the notation: f ∈L1
loc(d).
(ii) A measurable function f is locally integrable on a set D ⊆R if f is
locally integrable at each point d ∈D. We will use the notation: f ∈L1
loc(D).
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 27–64, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

28
2 One-Sided Classiﬁcation of Isolated Singular Points
Proposition 2.2 (Engelbert, Schmidt). Suppose that, for SDE (1),
1 + |b|
σ2
∈L1
loc(R).
(2.1)
Then there exists a unique solution of (1) deﬁned up to S−, where S =
supn inf{t ≥0 : |Xt| = n} and X denotes the coordinate process on C(R+).
For the proof, see [15].
Remark. Under the conditions of Proposition 2.2, there need not exist a
global solution because the solution may explode within a ﬁnite time. Theo-
rem 4.5 shows, which conditions should be added to (2.1) in order to guar-
antee the existence of a global solution.
In Chapter 2, we prove the following local analog of Proposition 2.2 (see
Theorem 2.11). If the function (1 + |b|)/σ2 is locally integrable at a point d,
then there exists a unique solution of (1) “in the neighbourhood of d”. There-
fore, it is reasonable to call such a point “regular” for SDE (1).
Deﬁnition 2.3. (i) A point d ∈R is called a singular point for SDE (1) if
1 + |b|
σ2
/∈L1
loc(d).
A point that is not singular will be called regular.
(ii) A point d ∈R is called an isolated singular point for (1) if d is singular
and there exists a deleted neighbourhood of d that consists of regular points.
The next 5 statements are intended to show that the singular points in
the sense of Deﬁnition 2.3 are indeed “singular”.
Proposition 2.4. Suppose that |b|/σ2 ∈L1
loc(R) and 1/σ2 /∈L1
loc(d). Then
there exists no solution of (1) with X0 = d.
For the proof, see [15, Th. 4.35].
Theorem 2.5. Let I ⊆R be an open interval. Suppose that |b|/σ2 /∈L1
loc(x)
for any x ∈I. Then, for any x0 ∈I, there exists no solution of (1).
Proof. (Cf. also [11].) Suppose that P is a solution. By the occupation times
formula and by the deﬁnition of a solution, we have
 t
0
|b(Xs)|ds =
 t
0
|b(Xs)|
σ2(Xs)d⟨X⟩s =

R
|b(x)|
σ2(x)Lx
t (X)dx < ∞
P-a.s.
(2.2)
As Ly
t (X) is right-continuous in y (see Proposition A.6 (i)), we deduce that
P{∀t ≥0, ∀x ∈I, Lx
t (X) = 0} = 1.

2.1 Isolated Singular Points: The Deﬁnition
29
Thus, for the stopping time S = 1 ∧inf{t ≥0 : Xt /∈I}, one has
S =
 S
0
1ds =
 S
0
σ−2(Xs)d⟨X⟩s
=

R
σ−2(x)Lx
S(X)dx =

I
σ−2(x)Lx
S(X)dx = 0
P-a.s.
(Here we used the fact that Lx
S(X) = 0 for x /∈I; see Proposition A.5.) This
leads to a contradiction since S > 0.
⊓⊔
Remark. The above statement shows that a solution cannot enter an open
interval that consists of singular points.
Theorem 2.6. Suppose that d is a singular point for (1) and P is a solution
of (1). Then, for any t ≥0, we have
Ld
t (X) = Ld−
t (X) = 0
P-a.s.
Proof. Since d is a singular point, we have
∀ε > 0,
 d+ε
d
1 + |b(x)|
σ2(x)
dx = ∞
(2.3)
or
∀ε > 0,
 d
d−ε
1 + |b(x)|
σ2(x)
dx = ∞.
(2.4)
If (2.3) is satisﬁed, then (2.2), together with the right-continuity of Ly
t (X)
in y, ensures that, for any t ≥0, Ld
t (X) = 0 P-a.s. If (2.4) is satisﬁed, then,
for any t ≥0, Ld−
t (X) = 0 P-a.s.
We set
Bt =
 t
0
1
σ(Xs)dMs,
t ≥0,
where M is given by (1.16). Then
 t
0
I(Xs = d)dXs =
 t
0
I(Xs = d)b(Xs)ds +
 t
0
I(Xs = d)σ(Xs)dBs
=
 t
0
I(Xs = d)b(Xs)ds + Nt,
t ≥0,
where N ∈Mc
loc(Ft, P). By the occupation times formula,
 t
0
I(Xs = d)b(Xs)ds =
 t
0
I(Xs = d)b(Xs)
σ2(Xs)
d⟨X⟩s
=

R
I(x = d)b(x)
σ2(x)
Lx
t (X)dx = 0
P-a.s.

30
2 One-Sided Classiﬁcation of Isolated Singular Points
Similarly,
⟨N⟩t =
 t
0
I(Xs = d)σ2(Xs)ds = 0
P-a.s.
Therefore,
 t
0
I(Xs = d)dXs = 0,
t ≥0
and, by equality (A.1), for any t ≥0, we have
Ld
t (X) = Ld−
t (X)
P-a.s.
(2.5)
We have already proved that Ld
t (X) = 0 or Ld−
t (X) = 0. This, together
with (2.5), leads to the desired statement.
⊓⊔
Theorem 2.7. Let d be a regular point for (1) and P be a solution of (1).
Suppose moreover that P{Td < ∞} > 0, where Td = inf{t ≥0 : Xt = d}.
Then, for any t ≥0, on the set {t > Td} we have
Ld
t (X) > 0, Ld−
t (X) > 0
P-a.s.
This statement is proved in Section 2.5.
Theorems 2.6 and 2.7 may be informally described as follows. Singular
points for (1) are those and only those points, at which the local time of a
solution vanishes.
Consider now SDE (1) with x0 = 0. If the conditions of Proposition 2.2
are satisﬁed, then the behaviour of a solution is regular in the following sense:
– there exists a solution up to S−;
– it is unique;
– it has alternating signs, i.e.,
P{∀ε > 0 ∃t < ε : Xt > 0} = 1,
P{∀ε > 0 ∃t < ε : Xt < 0} = 1
(these properties follow from the construction of a solution; see [15] for de-
tails). The theorem below, which follows from the results of Chapter 4, shows
that at least one of the above 3 conditions fails to hold if zero is an isolated
singular point.
Theorem 2.8. Suppose that
1 + |b|
σ2
∈L1
loc(R \ {0}),
1 + |b|
σ2
/∈L1
loc(0),
and x0 = 0. Set S = supn inf{t ≥0 : |Xt| = n}, where X is the coordinate
process on C(R+). Then there are only 4 possibilities:
1. There exists no solution up to S−.
2. There exists a unique solution up to S−, and it is positive.
3. There exists a unique solution up to S−, and it is negative.
4. There exist a positive solution as well as a negative solution up to S−. (In
this case alternating solutions may also exist.)

2.1 Isolated Singular Points: The Deﬁnition
31
-
-
-
-
-
6
6
6
6
6
t
t
t
t
t
?
A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






AA
Fig. 2.1. Qualitative diﬀerence between the regular points and the singular points.
The top graph shows the “typical” behaviour of a solution in the neighbourhood
of a regular point. The other 4 graphs illustrate 4 possible types of behaviour of a
solution in the neighbourhood of a singular point. As an example, the sign “
”
in the bottom left-hand graph indicates that there is no positive solution. The sign
“ ? ” in the bottom right-hand graph indicates that an alternating solution may
exist or may not exist.

32
2 One-Sided Classiﬁcation of Isolated Singular Points
2.2 Isolated Singular Points: Examples
A SDE with an isolated singular point is provided by Example 1.17. For this
SDE, there is no solution.
Another SDE with an isolated singular point is the SDE for a Bessel
process, which has been considered as Example 1.23. Here we will study it
for all starting points x0.
As in the previous section, we deal here with global solutions.
Example 2.9 (SDE for a Bessel process). Let us consider the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
(2.6)
with δ > 1.
(i) If x0 > 0 and δ ≥2, then this equation has a unique solution. It is
strictly positive.
(ii) If x0 = 0 or 1 < δ < 2, then this equation possesses diﬀerent solutions.
For any solution P, we have P{∃t ≥0 : Xt = 0} = 1.
Proof. (i) Let P be the distribution of a δ-dimensional Bessel process started
at x0. Proposition A.21 (combined with Theorem 1.27) shows that P is a
solution of SDE (2.6). Suppose that there exists another solution P′. Set
Q = Law(X2
t ; t ≥0 | P),
Q′ = Law(X2
t ; t ≥0 | P′).
By Itˆo’s formula, both Q and Q′ are solutions of the SDE
dXt = δdt + 2

|Xt|dBt,
X0 = x2
0
(2.7)
(see the proof of Example 1.23). Propositions 1.6 and 1.12 combined together
show that weak uniqueness holds for this equation, i.e., Q′ = Q. Hence,
Law(|Xt|; t ≥0 | P′) = Law(|Xt|; t ≥0 | P).
(2.8)
Proposition A.20 (i) guarantees that P{∀t ≥0, Xt > 0} = 1. This, together
with (2.8), implies that P′{∀t ≥0, Xt ̸= 0} = 1. Since the paths of X are
continuous and P′{X0 = x0 > 0} = 1, we get P′{∀t ≥0, Xt > 0} = 1.
Using (2.8) once again, we obtain P′ = P.
(ii) We ﬁrst suppose that x0 = 0. Let P be deﬁned as above and P′ be
the image of P under the map
C(R+) ∋ω −→−ω ∈C(R+).
It is easy to verify that P′ is also a solution of (2.6). The solutions P and P′
are diﬀerent since
P{∀t ≥0, Xt ≥0} = 1,
P′{∀t ≥0, Xt ≤0} = 1.

2.2 Isolated Singular Points: Examples
33
(Moreover, for any α ∈(0, 1), the measure Pα = αP + (1 −α)P′ is also a
solution.)
Suppose now that x0 > 0. Let P denote the distribution of a δ-dimensional
Bessel process started at x0. Since 1 < δ < 2, we have: T0 < ∞P-a.s. (see
Proposition A.20 (ii)). Let P′ be the image of P under the map
C(R+) ∋ω −→ω′ ∈C(R+),
ω′(t) =

ω(t)
if t ≤T0(ω),
−ω(t)
if t > T0(ω).
Then P′ is also a solution of (2.6). Thus, for any x0, SDE (2.6) has diﬀerent
solutions.
Now, let P be an arbitrary solution of (2.6). Let us prove that P{∃t ≥
0 : Xt = 0} = 1. For x0 = 0, this is clear. Assume now that x0 > 0, so
that 1 < δ < 2. The measure Q = Law(X2
t ; t ≥0 | P) is a solution of (2.7).
As there is weak uniqueness for (2.7), Q is the distribution of the square
of a δ-dimensional Bessel process started at x2
0. By Proposition A.20 (ii),
Q{∃t > 0 : Xt = 0} = 1, which yields P{∃t > 0 : Xt = 0} = 1.
⊓⊔
Example 2.10 (SDE for a geometric Brownian motion). Let us con-
sider the SDE
dXt = µXtdt + (Xt + ηI(Xt = 0))dBt,
X0 = x0
(2.9)
with µ ∈R, η ̸= 0.
(i) If x0 > 0, then there exists a unique solution P of this equation. It is
strictly positive. If µ > 1/2, then P{limt→∞Xt = ∞} = 1; if µ < 1/2, then
P{limt→∞Xt = 0} = 1.
(ii) If x0 = 0, then there exists no solution.
Remark. The term ηI(Xt = 0) is added in order to guarantee that σ ̸= 0 at
each point. The choice of η ̸= 0 does not inﬂuence the properties of (2.9) as
seen from the reasoning given below.
Proof of Example 2.10. If P is a solution of (2.9), then, for any t ≥0,
 t
0
I(Xs = 0)ds =
 t
0
I(Xs = 0)
σ2(Xs) d⟨X⟩s = 1
η2

R
I(x = 0)Lx
t (X)dx = 0
P-a.s.
Hence, P is also a solution of the SDE
dXt = µXtdt + XtdBt,
X0 = x0.
(2.10)
Propositions 1.6 and 1.9 combined together show that there is uniqueness in
law for (2.10). Applying Itˆo’s formula and Theorem 1.27, we deduce that the
solution of (2.10) is given by

34
2 One-Sided Classiﬁcation of Isolated Singular Points
Q = Law

x0eBt+(µ−1/2)t; t ≥0

,
where B is a Brownian motion started at zero. Obviously, if x0 ̸= 0, then Q
is also a solution of (2.9); if x0 = 0, then Q is not a solution of (2.9). The
properties of the solution in the case x0 > 0 follow from the strong law of
large numbers for the Brownian motion: Bt
t
a.s.
−−−→
t→∞0.
2
The situations in Examples 1.17, 2.9, and 2.10 may informally be de-
scribed as follows. In Example 1.17, the drift is negative on the positive
half-line and is positive on the negative half-line. Moreover, the drift is so
strong near zero that it does not allow a solution to leave zero. On the other
hand, the measure concentrated on {X ≡0} is not a solution.
In Example 2.9, the drift is positive on the positive half-line and is negative
on the negative half-line. Moreover, the drift is so strong near zero that it
guarantees the existence of both a positive solution and a negative solution
started at zero. If 1 < δ < 2, then a solution started at a point x0 ̸= 0 reaches
zero a.s. After the time it reaches zero, it can go in the positive direction as
well as in the negative direction. This yields diﬀerent solutions. If δ ≥2, then
a solution started at x0 ̸= 0 cannot reach zero. As this “bad” point is not
reached, a solution is unique.
In Example 2.10, the drift and the diﬀusion coeﬃcients are so small near
zero that a solution started at x0 ̸= 0 cannot reach zero. A solution with
X0 = 0 cannot leave zero, but the measure concentrated on {X ≡0} is not
a solution.
The above examples show that a slight modiﬁcation of a parameter in a
SDE may essentially inﬂuence the properties of solutions.
2.3 One-Sided Classiﬁcation: The Results
Throughout this section, we assume that zero is an isolated singular point.
Then there exists a > 0 such that
1 + |b|
σ2
∈L1
loc((0, a]).
(2.11)
Note that the integral
 a
0
1 + |b(x)|
σ2(x)
dx
may converge. In this case the corresponding integral should diverge in the
left-hand neighbourhood of zero.
We will use the functions

2.3 One-Sided Classiﬁcation: The Results
35
ρ(x) = exp
 a
x
2b(y)
σ2(y)dy

,
x ∈(0, a],
(2.12)
s(x) =







 x
0
ρ(y)dy
if
 a
0
ρ(y)dy < ∞,
−
 a
x
ρ(y)dy
if
 a
0
ρ(y)dy = ∞.
(2.13)
The function s is a version of the indeﬁnite integral
	 xρ(y)dy. If
	 a
0 ρ(y)dy<∞,
we choose a version that vanishes at zero; otherwise, we choose a version that
vanishes at a. We will use the notation
Ta = inf{t ≥0 : Xt = a},
T a = sup
n inf{t ≥0 : |Xt −a| ≤1/n},
Ta,c =Ta ∧Tc,
T a,c =T a ∧T c
with the usual convention inf ∅= +∞. Here a, c ∈R and X is the coordinate
process on C(R+). Note that T a may not be equal to Ta since the coordinate
process may be killed just before it reaches a.
We will also consider stochastic intervals
[[S, T ]] = {(ω, t) ∈Ω× R+ : S(ω) ≤t ≤T (ω)},
]]S, T ]] = {(ω, t) ∈Ω× R+ : S(ω) < t ≤T (ω)},
[[S, T [[= {(ω, t) ∈Ω× R+ : S(ω) ≤t < T (ω)},
]]S, T [[= {(ω, t) ∈Ω× R+ : S(ω) < t < T(ω)},
where S, T are stopping times (not necessarily S ≤T ).
Theorem 2.11. Suppose that
 a
0
1 + |b(x)|
σ2(x)
dx < ∞.
If x0 ∈[0, a], then there exists a unique solution P deﬁned up to T0,a. We
have EPT0,a < ∞and P{XT0,a = 0} > 0.
If the conditions of Theorem 2.11 are satisﬁed, we will say that zero has
right type 0.
Theorem 2.12. Suppose that
 a
0
ρ(x)dx < ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)dx < ∞,
 a
0
|b(x)|
σ2(x)dx = ∞.
If x0 ∈[0, a], then there exists a positive solution P deﬁned up to Ta, and
such a solution is unique. We have EPTa < ∞and P{∃t ≤Ta : Xt = 0} > 0.

36
2 One-Sided Classiﬁcation of Isolated Singular Points
If the conditions of Theorem 2.12 are satisﬁed, we will say that zero has
right type 2.
Theorem 2.13. Suppose that
 a
0
ρ(x)dx < ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)dx = ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)s(x)dx < ∞.
(i) For any solution (P, S), we have X ≤0 on [[T0, S]] P-a.s. (i.e., for
any t ≥0, we have Xt ≤0 P-a.s. on {T0 ≤t ≤S}).
(ii) If x0 ∈[0, a], then there exists a unique solution P deﬁned up to T0,a.
We have EPT0,a < ∞and P{XT0,a = 0} > 0.
If the conditions of Theorem 2.13 are satisﬁed, we will say that zero has
right type 1.
Remark. Statement (i) implies that if x0 ≤0, then any solution (P, S) is
negative.
Theorem 2.14. Suppose that
 a
0
ρ(x)dx < ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)s(x)dx = ∞,
 a
0
s(x)
ρ(x)σ2(x)dx < ∞.
(i) If x0 > 0, then any solution (P, S) is strictly positive.
(ii) If x0 ≤0, then any solution (P, S) is negative.
(iii) If x0 ∈(0, a), then there exists a unique solution P deﬁned up to
T 0,a−. We have EPT 0,a < ∞and P{limt↑T 0,a Xt = 0} > 0.
If the conditions of Theorem 2.14 are satisﬁed, we will say that zero has
right type 6.
Remarks. (i) The solution P is deﬁned up to T 0,a−(and not up to T0,a−)
since the stopping time T0,a is not predictable. The reason is that the coor-
dinate process may be killed just before it reaches 0 or a. On the other hand,
T 0,a is obviously predictable.
(ii) Under assumption (2.11), for x0 ∈(0, a), there always exists a unique
solution up to T 0,a−(not only for type 6).
Theorem 2.15. Suppose that
 a
0
ρ(x)dx < ∞,
 a
0
s(x)
ρ(x)σ2(x)dx = ∞.
(i) If x0 > 0, then any solution (P, S) is strictly positive.
(ii) If x0 ≤0, then any solution (P, S) is negative.
(iii) If x0 ∈(0, a], then there exists a unique solution P deﬁned up to Ta.
We have P{Ta = ∞} > 0 and limt→∞Xt = 0 P-a.s. on {Ta = ∞}.

2.3 One-Sided Classiﬁcation: The Results
37
If the conditions of Theorem 2.15 are satisﬁed, we will say that zero has
right type 4.
Theorem 2.16. Suppose that
 a
0
ρ(x)dx = ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)|s(x)|dx < ∞.
(i) If x0 > 0, then any solution (P, S) is strictly positive.
(ii) If x0 ∈(0, a], then there exists a unique solution P deﬁned up to Ta.
We have EPTa < ∞.
(iii) If x0 = 0, then there exists a positive solution P deﬁned up to Ta,
and such a solution is unique. We have EPTa < ∞and X > 0 on ]]0, Ta]]
P-a.s.
If the conditions of Theorem 2.16 are satisﬁed, we will say that zero has
right type 3.
Theorem 2.17. Suppose that
 a
0
ρ(x)dx = ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)|s(x)|dx = ∞.
(i) If x0 > 0, then any solution (P, S) is strictly positive.
(ii) If x0 ≤0, then any solution (P, S) is negative.
(iii) If x0 ∈(0, a], then there exists a unique solution P deﬁned up to Ta,
and Ta < ∞P-a.s.
If the conditions of Theorem 2.17 are satisﬁed, we will say that zero has
right type 5.
Figure 2.2 represents the one-sided classiﬁcation of the isolated singular
points. Note that the integrability conditions given in Figure 2.2 do not have
the same form as in Theorems 2.11–2.17. Nevertheless, they are equivalent.
For example,
 a
0
1 + |b(x)|
σ2(x)
dx < ∞
if and only if
 a
0
ρ(x)dx < ∞,
 a
0
1 + |b(x)|
ρ(x)σ2(x)dx < ∞,
 a
0
|b(x)|
σ2(x)dx < ∞.
(In this case zero has right type 0.)

38
2 One-Sided Classiﬁcation of Isolated Singular Points
2.4 One-Sided Classiﬁcation: Informal Description
Let us now informally describe how a solution behaves in the right-hand
neighbourhood of an isolated singular point for each of types 0, . . . , 6.
If zero has right type 0, then, for any x0 ∈[0, a], there exists a unique
solution deﬁned up to T0,a. This solution reaches zero with strictly positive
probability. An example of a SDE, for which zero has right type 0, is provided
by the equation
dXt = dBt,
X0 = x0.
If zero has right type 1, then, for any x0 ∈[0, a], there exists a unique
solution deﬁned up to T0,a. This solution reaches zero with strictly positive
probability. Any solution started at zero (it may be deﬁned up to another
stopping time) is negative. In other words, a solution may leave zero only in
the negative direction. The SDE
dXt = −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
provides an example of a SDE, for which zero has right type 1 (this follows
from Theorem 5.1). In this example, after having reached zero the solution
cannot be continued neither in the negative nor in the positive direction,
compare with Example 1.17.
If zero has right type 2, then, for any x0 ∈[0, a], there exists a unique
positive solution deﬁned up to Ta. This solution reaches zero with strictly
positive probability and is reﬂected at this point. There may exist other
solutions up to Ta. These solutions take negative values (see Chapter 3). The
SDE for a δ-dimensional Bessel process
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
with 1 < δ < 2 is an example of a SDE, for which zero has right type 2 (this
follows from Theorem 5.1).
If zero has right type 3, then, for any x0 ∈(0, a], there exists a unique
solution deﬁned up to Ta. This solution never reaches zero. There exists a
unique positive solution started at zero and deﬁned up to Ta. There may
exist other solutions started at zero and deﬁned up to Ta. These solutions
take negative values (see Chapter 3). For the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
with δ ≥2, zero has right type 3 (this follows from Theorem 5.1).
If zero has right type 4, then, for any x0 ∈(0, a), there exists a unique
solution deﬁned up to Ta. This solution never reaches zero. With strictly
positive probability it tends to zero as t →∞. Thus, with strictly positive

2.4 One-Sided Classiﬁcation: Informal Description
39
σ ̸= 0,
1 + |b|
σ2
∈L1
loc((0, a])
	
	
	
	
	
		
C
C
C
C
C
C
CW
 a
0
ρ < ∞



B
B
B
BBN
 a
0
ρ = ∞



B
B
B
BBN
 a
0
1 + |b|
ρ σ2
< ∞

A
AAU
 a
0
1 + |b|
ρ σ2
= ∞

A
AAU
 a
0
1 + |b|
ρ σ2 |s| < ∞
3m
 a
0
1 + |b|
ρ σ2 |s| = ∞
5m
 a
0
|b|
σ2 < ∞
0m
 a
0
|b|
σ2 = ∞
2m
 a
0
1 + |b|
ρ σ2 s < ∞
1m
 a
0
1 + |b|
ρ σ2 s = ∞

@@
R
 a
0
s
ρ σ2 < ∞
6m
 a
0
s
ρ σ2 = ∞
4m
-
6
s(x)
a x
-
6
s(x)
a
x
Types
Exit Non-exit
Entrance
2
3
Non-entrance
0 1
4 5 6
ρ(x) = exp
 a
x
2b(y)
σ2(y)dy

,
s(x) =







 x
0
ρ(y)dy
if
 a
0
ρ(y)dy < ∞,
−
 a
x
ρ(y)dy if
 a
0
ρ(y)dy = ∞
Fig. 2.2. One-sided classiﬁcation of isolated singular points

40
2 One-Sided Classiﬁcation of Isolated Singular Points
-
-
-
-
-
-
-
-
6
6
6
6
6
6
6
6
t
t
t
t
t
t
t
t
a
a
a
a
a
a
a
a
m
3
m
2
m
1
m
0
A
AA
A
AA
A
AA






AA
?
?
?
?
Fig. 2.3. (a) Behaviour of solutions for right types 0–3. The graphs show simulated
paths of solutions. The graphs on the left-hand side represent solutions started at a
strictly positive point; the graphs on the right-hand side represent solutions started
at zero. The sign “
” indicates that, for right type 1, any solution started at zero
is negative.

2.4 One-Sided Classiﬁcation: Informal Description
41
-
-
-
-
-
-
6
6
6
6
6
6
t
t
t
t
t
t
a
a
a
a
a
a
m
6
m
5
m
4
A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






AA
?
?
?
Fig. 2.3. (b) Behaviour of solutions for right types 4–6. The graphs show simulated
paths of solutions. The graphs on the left-hand side represent solutions started at a
strictly positive point; the graphs on the right-hand side represent solutions started
at zero. As an example, the sign “
” in the bottom left-hand graph indicates that,
for right type 6, a solution cannot be extended after it hits zero. The signs “ ? ”
indicate that a negative solution may exist or may not exist.

42
2 One-Sided Classiﬁcation of Isolated Singular Points
probability this solution never reaches the point a. For type 4 as well as for
types 5, 6 below, any solution started at zero is negative. The SDE for a
geometric Brownian motion
dXt = µXtdt + (Xt + I(Xt = 0))dBt,
X0 = x0
with µ < 1/2 is an example of a SDE, for which zero has right type 4 (this
follows from Theorem 5.1).
If zero has right type 5, then, for any x0 ∈(0, a], there exists a unique so-
lution deﬁned up to Ta. This solution never reaches zero. Unlike the previous
case, the solution reaches the point a a.s. For the SDE
dXt = µXtdt + (Xt + I(Xt = 0))dBt,
X0 = x0
with µ ≥1/2, zero has right type 5 (this follows from Theorem 5.1).
If zero has right type 6, then, for any x0 ∈(0, a), there exists a unique
solution deﬁned up to T 0,a−. For this solution, T 0,a is a.s. ﬁnite. With strictly
positive probability this solution tends to zero as t ↑T 0,a. There exists no
solution up to T0,a because the integral 	 T 0,a
0
|b(Xs)|ds is a.s. inﬁnite on the
set {limt↑T 0,a Xt = 0}. An example of a SDE, for which zero has right type 6,
is constructed in Section 5.3.
If zero has right type 2 or 3, then there exist positive solutions started
at zero. Thus, types 2 and 3 may be called entrance types. On the other
hand, types 1, 4, 5, 6 are non-entrance ones: any solution started at zero is
negative. The situation with type 0 is as follows. If zero has right type 0 and
is an isolated singular point, then any solution started at zero is negative
(this will be shown in Chapter 3). If zero has right type 0 and is a regular
point, then there exists an alternating solution started at zero (this follows
from Theorem 2.11).
If zero has right type 0, 1, or 2, then, for any x0 ∈(0, a), there exists a
solution that reaches zero with strictly positive probability. Thus, types 0, 1,
2 may be called exit types. If the right type of zero is one of 3, 4, 5, 6, then
any solution with x0 > 0 does not reach zero. So, these types are non-exit
ones.
2.5 One-Sided Classiﬁcation: The Proofs
In what follows, we will use the notation
Ta(Z) = inf{t ≥0 : Zt = a},
Ta,b(Z) = Ta(Z) ∧Tb(Z).
First we prove an auxiliary lemma.

2.5 One-Sided Classiﬁcation: The Proofs
43
Lemma 2.18. Suppose that (2.11) holds. Then
 a
0
|b(x)|
ρ(x)σ2(x)dx < ∞
=⇒
 a
0
1
ρ(x)dx < ∞,
(2.14)
 a
0
|b(x)s(x)|
ρ(x)σ2(x)dx < ∞
=⇒
 a
0
|s(x)|
ρ(x) dx < ∞.
(2.15)
Proof. For any c ∈(0, a], we have
 a
c
2b(x)
ρ(x)σ2(x)dx = −
 a
c
ρ′(x)
ρ2(x)dx = −
 ρ(a)
ρ(c)
1
y2 dy =
1
ρ(a) −
1
ρ(c).
If the integral on the left-hand side of (2.14) converges, then there exists
θ > 0 such that, for any c ∈(0, a], we have
1
ρ(c) < θ. This proves (2.14).
For any c ∈(0, a], we have
 a
c
2b(x)s(x)
ρ(x)σ2(x)dx = −
 a
c
s′′(x)s(x)
(s′(x))2 dx =
 a
c
 s(x)
s′(x)
′
−1

dx
= s(a)
s′(a) −s(c)
s′(c) + c −a = s(a)
ρ(a) −s(c)
ρ(c) + c −a.
(2.16)
If the integral on the left-hand side of (2.15) converges, then there exists θ > 0
such that, for any c ∈(0, a], we have |s(c)|/ρ(c) < θ. This proves (2.15).
⊓⊔
Proof of Theorem 2.11. Existence. Let B = (Bt; t ≥0) be a (Gt)-Brownian
motion started at s(x0) on a ﬁltered probability space

Ω, G, (Gt), Q

. The
ﬁltration (Gt) is supposed to be right-continuous. Let us consider
κ(y) = ρ(s−1(y))σ(s−1(y)),
y ∈[0, α],
(2.17)
At =



 t
0
κ−2(Bs)ds
if t < T0,α(B),
∞
if t ≥T0,α(B),
(2.18)
τt = inf{s ≥0 : As > t},
(2.19)
Yt = Bτt,
t ≥0,
(2.20)
where α = s(a). For any 0 < γ < β < α, we have
 β
γ
κ−2(y)dy =
 s−1(β)
s−1(γ)
1
ρ(x)σ2(x)dx < ∞
(2.21)
(note that ρ is bounded away from zero on (0, a]). Applying the occupation
times formula, we get
 Tγ,β(B)
0
κ−2(Bs)ds =
 β
γ
κ−2(y)Ly
Tγ,β(B)(B)dy < ∞
Q-a.s.

44
2 One-Sided Classiﬁcation of Isolated Singular Points
(note that Ly
Tγ,β(B) is continuous in y; see Proposition A.6 (ii)). Thus, A is
Q-a.s. ﬁnite on [[0, T0,α(B)[[. Obviously, τ is continuous and Q-a.s. ﬁnite. By
Proposition A.16, Y ∈Mc
loc(Gτt, Q) and ⟨Y ⟩t = τt.
We have
lim
t↑T0,α(B) Bt = 0 or α
Q-a.s.
Consequently,
lim
t↑AT0,α(B)−Yt = 0 or α
Q-a.s.
As a result,
AT0,α(B)−= T0,α(Y )
Q-a.s.
(2.22)
Let us now give another expression for τt. On the set {t < AT0,α(B)−} we
have
τt =
 τt
0
κ2(Bs)κ−2(Bs)ds =
 τt
0
κ2(Bs)dAs
=
 t
0
κ2(Bτs)ds =
 t
0
κ2(Ys)ds.
Here we used Proposition A.18 and the equality Aτt = t for t < AT0,α(B)−.
Obviously, τ is continuous and is constant after AT0,α(B)−. Keeping (2.22) in
mind, we get
⟨Y ⟩t = τt =
 t∧T0,α(Y )
0
κ2(Ys)ds,
t ≥0.
Set Z = s−1(Y ). Then
EQ
 T0,a(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt
= EQ
 T0,α(Y )
0

1 + |b(s−1(Yt))| + σ2(s−1(Yt))

dt
= EQ
 T0,α(B)
0
1 + |b(s−1(Bt))| + σ2(s−1(Bt))
κ2(Bt)
dt
= EQ
 α
0
1 + |b(s−1(y))| + σ2(s−1(y))
κ2(y)
Ly
T0,α(B)(B)dy
≤2
 α
0
1 + |b(s−1(y))| + σ2(s−1(y))
κ2(y)
ydy
= 2
 a
0
1 + |b(x)| + σ2(x)
ρ(x)σ2(x)
s(x)dx < ∞.
(2.23)
Here we used the time-change formula (see Proposition A.18) and the in-
equality

2.5 One-Sided Classiﬁcation: The Proofs
45
EQLy
T0,α(B)(B) ≤EQLy
T0(B)(B) ≤2y,
y ∈[0, α]
(see Proposition A.10 (ii)). The conditions of the theorem guarantee that ρ
is bounded on (0, a] and bounded away from zero on (0, a]. Hence, s is also
bounded on (0, a], and therefore, the last expression in (2.23) is ﬁnite.
The function s−1(y) is absolutely continuous on (0, α) and
(s−1)′(y) =
1
ρ(s−1(y)),
y ∈(0, α).
(2.24)
This function, in turn, is absolutely continuous on (0, α) and
(s−1)′′(y) = 2b(s−1(y))
κ2(y)
,
y ∈(0, α).
(2.25)
Moreover,
 α
0
2|b(s−1(y))|
κ2(y)
dy =
 a
0
2|b(x)|
ρ(x)σ2(x)dx < ∞.
Consequently, we can apply the Itˆo–Tanaka formula to the function s−1 :
[0, α] →[0, a]. As a result,
Zt = s−1(Y0) + 1
2
 α
0
2b(s−1(y))
κ2(y)
Ly
t (Y )dy +
 t
0
1
ρ(s−1(Ys))dYs
= x0 +
 t
0
b(s−1(Ys))
κ2(Ys)
d⟨Y ⟩s + Nt
= x0 +
 t∧T0,a(Z)
0
b(Zs)ds + Nt,
t ≥0.
Here N ∈Mc
loc(Gτt, Q) and
⟨N⟩t =
 t
0
1
ρ2(s−1(Ys))d⟨Y ⟩s =
 t∧T0,α(Y )
0
σ2(s−1(Ys))ds
=
 t∧T0,a(Z)
0
σ2(Zs)ds,
t ≥0.
Set P = Law(Zt; t ≥0) and P = P|FT0,a. We will now prove that P is a
solution of (1) deﬁned up to T0,a.
Conditions (a) and (b) of Deﬁnition 1.31 are obvious. Condition (c) follows
from (2.23). Let us check condition (d). For any m ∈N, s < t, and C ∈Fs,
where (Ft) denotes the canonical ﬁltration on C(R+), we have
EQ

(N Sm(N)
t
−N Sm(N)
s
)I(Z ∈C)

= 0,
where Sm(N) = inf{t ≥0 : |Nt| ≥m}. Hence, for the process

46
2 One-Sided Classiﬁcation of Isolated Singular Points
Mt = Xt −x0 −
 t∧T0,a
0
b(Xs)ds,
t ≥0,
we can write
EP

(M Sm(M)
t
−M Sm(M)
s
)I(X ∈C)

= 0.
This proves that M ∈Mc
loc(Ft, P). Condition (e) of Deﬁnition 1.31 is veriﬁed
in a similar way.
Uniqueness. Let P be an arbitrary solution deﬁned up to T0,a. Set P =
P◦Φ−1
T0,a, where Φ is deﬁned by (B.1). We will now construct a solution Q up
to T0,a with the property Q{T0,a < ∞} = 1 by gluing P with the solutions
constructed in the existence part of the proof.
Let Px denote the distribution of the process Z constructed above for the
case, where X0 = x, x ∈[0, a]. It is seen from the construction of Z that the
measures Py converge weakly to Px as y →x (we consider Px as measures on
C(R+) and not on C(R+)). Hence, the collection (Px)x∈[0,a] is a probability
kernel (i.e., for any A ∈B(C(R+)), the map x →Px(A) is measurable).
Fix u > 0. Let R be the measure on C(R+) × C(R+) deﬁned as
R(dω1, dω2) = P(dω1)Pω1(u)(dω2) and let Q be the image of R under the
map
C(R+) × C(R+) ∋(ω1, ω2) −→ω ∈C(R+),
ω(t) =





ω1(t)
if t < u,
ω2(t −u)
if t ≥u, ω1(u) = ω2(0),
ω1(u)
if t ≥u, ω1(u) ̸= ω2(0).
Obviously, Q{X0 = x0} = 1 and, for any t ≥0,
 t∧T0,a
0

|b(Xs)| + σ2(Xs)

ds < ∞
Q-a.s.
Clearly, the process
Kt = Xt∧u −x0 −
 t∧u∧T0,a
0
b(Xs)ds,
t ≥0
is a continuous (Ft, Q)-local martingale. Consider the process
Nt = Xt∨u −Xu −
 (t∨u)∧T0,a
u∧T0,a
b(Xs)ds,
t ≥0
and the stopping times τm = inf{t ≥u : |Nt| ≥m}. Set
X1
t = Xt∧u,
X2
t = Xt+u,
t ≥0.
For any u ≤s ≤t, C1 ∈Fu, C2 ∈Fs−u, and m ∈N, we have

2.5 One-Sided Classiﬁcation: The Proofs
47
EQ

N τm
t
−N τm
s

I(X1 ∈C1, X2 ∈C2)
=

C(R+)

C(R+)

Nt∧τm(ω2) −Ns∧τm(ω2)

I(X1(ω1) ∈C1)
I(X2(ω2) ∈C2)P(dω1)Pω1(u)(dω2) = 0.
It follows from Proposition A.36 that for any C ∈Fu, we have
EQ

N τm
t
−N τm
s

I(X ∈C) = 0.
Combining this with the martingale property of K, we conclude that the
process
Mt = Xt −x0 −
 t∧T0,a
0
b(Xs)ds,
t ≥0
is a continuous (Ft, Q)-local martingale. In a similar way we prove that the
process
M 2
t −
 t∧T0,a
0
σ2(Xs)ds,
t ≥0
is a continuous (Ft, Q)-local martingale.
Set Y = s(X). By the Itˆo-Tanaka formula, Y ∈Mc
loc(Ft, Q) and
⟨Y ⟩t =
 t∧T0,a(Y )
0
κ2(Ys)ds,
t ≥0,
where κ is deﬁned in (2.17). Let us consider
At =



 t
0
κ2(Ys)ds
if t < T0,α(Y ),
∞
if t ≥T0,α(Y ),
τt = inf{s ≥0 : As > t},
Vt = Yτt,
t ≥0.
It follows from the construction of Px that, for any x ∈[0, a], Px{T0,a <
∞} = 1. Hence, Q{T0,a < ∞} = 1. Now we can apply the same arguments
as in the proof of existence to show that AT0,α(Y )−= T0,α(V ) Q-a.s., where
α = s(a), and
τt =
 t∧T0,α(V )
0
κ−2(Vs)ds,
t ≥0.
(2.26)
By Proposition A.16,
⟨V ⟩t = ⟨Y ⟩τt = t ∧AT0,α(Y )−= t ∧T0,α(V ),
t ≥0.
Using the same method as in the proof of Theorem 1.27 (ii), we construct
a Brownian motion W (deﬁned, possibly, on an enlarged probability space)
such that W = V on [[0, T0,α(W)]]. Then (2.26) can be rewritten as

48
2 One-Sided Classiﬁcation of Isolated Singular Points
τt =
 t∧T0,α(W)
0
κ−2(Ws)ds,
t ≥0.
Furthermore, At = inf{s ≥0 : τs > t} and Yt = VAt = WAt, t ≥0. As a
result, the measure Q is determined uniquely (i.e., it does not depend on the
choice of a solution P). Since u > 0 was taken arbitrarily, we conclude that
the measure P is determined uniquely. But P = P|FT0,a (see Lemma B.3).
This completes the proof of uniqueness.
The inequality EPT0,a < ∞follows from (2.23). The property P{XT0,a =
0} > 0 is clear from the construction of the solution. Indeed, for the process Y
deﬁned by (2.20), we have
P{YT0,α(Y ) = 0} = P{BT0,α(B) = 0} > 0.
The proof is completed.
2
Proof of Theorem 2.12. Existence. Consider the functions
ρ(x) = ρ(|x|),
x ∈[−a, a],
s(x) = s(|x|) sgn x,
x ∈[−a, a].
If we apply the same procedure as in the proof of the existence part of Theo-
rem 2.11 with the interval [0, a] replaced by the interval [−a, a], the function
ρ replaced by ρ, the function s replaced by s, and the function κ replaced
by the function κ(y) = ρ(s−1(y))σ(s−1(y)), then we obtain a measure P on
FT−a,a that is a solution of the SDE
dXt = b(Xt)dt + σ(Xt)dBt,
X0 = x0
up to T−a,a. Here
b(x) = b(|x|) sgn x,
x ∈[−a, a],
σ(x) = σ(|x|),
x ∈[−a, a].
In particular, (2.21) is replaced by
 a
−a
κ−2(y)dy =
 a
−a
1
ρ(x)σ2(x)dx =
 a
0
2
ρ(x)σ2(x)dx < ∞,
and one should apply Lemma 2.18 when checking the analogue of (2.23).
The arguments used in the proof of Theorem 2.6 show that L0
t(X) = 0 P-a.s.
The map C(R+) ∋ω −→|ω| ∈C(R+) is FT−a,a|FTa-measurable. Hence, we
can deﬁne a measure P on FTa as the image of P under this map. Using the
Itˆo-Tanaka formula and the equality L0
t(X) = 0 P-a.s., we prove that P is a
solution of (1) up to Ta. Obviously, P is a positive solution.

2.5 One-Sided Classiﬁcation: The Proofs
49
Uniqueness. Let P be an arbitrary solution deﬁned up to Ta. Set P =
P ◦Φ−1
Ta , where Φ is deﬁned by (B.1). Fix u > 0. Using the same method as
in the proof of the uniqueness part of Theorem 2.11, we construct a measure
Q on C(R+) such that Q|Fu = P|Fu, Q{X0 = x0} = 1,
 t∧Ta
0

|b(Xs)| + σ2(Xs)

ds < ∞
Q-a.s.
for any t ≥0, and the processes
Mt = Xt −x0 −
 t∧Ta
0
b(Xs)ds,
t ≥0,
M 2
t −
 t∧Ta
0
σ2(Xs)ds,
t ≥0
are continuous (Ft, Q)-local martingales. Moreover, Q{Ta < ∞} = 1.
Let us choose δ ∈(0, a) and set ∆= s(δ), Y = s(X) ∨∆. By the Itˆo-
Tanaka formula applied to the function x →s(x) ∨∆, we have
Yt = Y0 +
 t
0
I(Xs > δ)ρ(Xs)dMs + 1
2ρ(δ)Lδ
t(X),
t ≥0.
(2.27)
Applying the Itˆo-Tanaka formula to the function y →y ∨∆, we get
Yt = Yt ∨∆= Y0 +
 t
0
I(Ys > ∆)I(Xs > δ)ρ(Xs)dMs
+ 1
2ρ(δ)
 t
0
I(Ys > ∆)dLδ
t(X) + 1
2L∆
t (Y )
= Y0 +
 t
0
I(Ys > ∆)ρ(s−1(Ys))dMs + 1
2L∆
t (Y )
= Y0 + Nt + 1
2L∆
t (Y ).
(2.28)
(In the third equality we applied Proposition A.5.)
Let us consider
Dt =



 t
0
I(Ys > ∆)ds
if t < Tα(Y ),
∞
if t ≥Tα(Y ),
ϕt = inf{s ≥0 : Ds > t},
Ut = Yϕt = U0 + Nϕt + 1
2L∆
ϕt(Y ),
t ≥0,
where α = s(a). It follows from Proposition A.15 that N is τ-continuous.
Proposition A.16 shows that the process Kt = Nϕt is a (F+
ϕt, Q)-local mar-
tingale. On the set {t < DTα(Y )−} we have

50
2 One-Sided Classiﬁcation of Isolated Singular Points
⟨K⟩t = ⟨N⟩ϕt =
 ϕt
0
κ2(Ys)I(Ys > ∆)ds
=
 ϕt
0
κ2(Ys)dDs =
 t
0
κ2(Us)ds,
t ≥0.
The processes K and ⟨K⟩are continuous and are constant after DTα(Y )−.
Moreover,
DTα(Y )−≤Tα(Y ) < ∞
Q-a.s.
Similarly to (2.22), we verify that DTα(Y )−= Tα(U) Q-a.s. As a result,
⟨K⟩t =
 t∧Tα(U)
0
κ2(Us)ds,
t ≥0.
Obviously, U = U ∨∆. Applying the Itˆo-Tanaka formula to the function
x →x ∨∆, we get
Ut = U0 +
 t
0
I(Us > ∆)dKs + 1
2
 t
0
I(Us > ∆)dL∆
ϕs(Y ) + 1
2L∆
t (U),
t ≥0.
By Propositions A.5 and A.18,
 t
0
I(Us > ∆)dL∆
ϕs(Y ) =
 ϕt
ϕ0
I(Ys > ∆)dL∆
s (Y ) = 0,
t ≥0.
It follows from the uniqueness of the semimartingale decomposition of U that
 t
0
I(Us > ∆)dKs = Kt,
t ≥0.
As a result,
Ut = U0 + Kt + 1
2L∆
t (U),
t ≥0.
(2.29)
Let us consider
At =



 t
0
κ2(Us)ds
if t < Tα(U),
∞
if t ≥Tα(U),
τt = inf{s ≥0 : As > t},
Vt = Uτt = V0 + Kτt + 1
2L∆
τt(U),
t ≥0.
Arguing as above, we deduce that ATα(U)−= Tα(V ) Q-a.s. The process
Jt = Kτt is a (Gτt, Q)-local martingale, where Gt = F+
ϕt, and ⟨J⟩t = t∧Tα(V ),
t ≥0. The following equality is obtained similarly as (2.29):
Vt −V0 = Jt + 1
2L∆
t (V ),
t ≥0.

2.5 One-Sided Classiﬁcation: The Proofs
51
There exists a Brownian motion W (deﬁned, possibly, on an enlarged proba-
bility space) such that J coincides with W on [[0, Tα(V )]]. Note that V ≥∆
and V is stopped at the ﬁrst time it reaches α. Propositions A.32 and A.33
taken together show that the process V is a Brownian motion started at
V0 = s(x0) ∨∆, reﬂected at ∆, and stopped at the ﬁrst time it reaches α.
Using the same arguments as in the proof of uniqueness in Theorem 2.11, we
conclude that the measure Rδ = Law(Ut; t ≥0 | Q) is determined uniquely
(i.e., it does not depend on the choice of a solution P). The superscript δ here
indicates that U depends on δ. We can write
 t∧Ta
0
I(Xs = 0)ds =
 t∧Ta
0
I(Xs = 0)
σ2(Xs) d⟨X⟩s
=

R
I(x = 0)
σ2(0)
Lx
t∧Ta(X)dx = 0
Q-a.s.
(2.30)
Combining this equality with the property Q{∀t ≥0,
Xt ≥0} = 1,
we conclude that the measures Rδ converge weakly to the measure R =
Law(s(Xt); t ≥0 | Q) as δ ↓0. As a result, the measure Q is determined
uniquely. The proof of uniqueness is now completed as in Theorem 2.11.
The inequality EPTa < ∞follows from (2.23). The property P{∃t ≤Ta :
Xt = 0} > 0 follows from the construction of the solution.
2
Proof of Theorem 2.13. (i) Suppose that there exists a solution (P, S) such
that
P

supt∈[T0,S] Xt ≥c

> 0
for some c > 0. We can assume that c ≤a,
S is bounded and S ≤T 0
c
where T 0
c := inf{t ≥T0 : Xt = c}. Otherwise, we can choose a smaller c and
consider S ∧T 0
c ∧m instead of S, where m is a suﬃciently large number.
Set P = P ◦Φ−1
S
(Φ is deﬁned by (B.1)) and
X′
t =
 t
0
I(s ≥T0)dXs,
t ≥0.
Take δ ∈(0, c) and set ∆= s(δ), Y = s(δ ∨X′). Computations similar
to (2.27) and (2.28) show that
Yt = ∆+ Nt + 1
2L∆
t (Y ),
t ≥0,
where N ∈Mc
loc(Ft, P) and
⟨N⟩t =
 t
0
I(T0 ≤s ≤S)I(Ys > ∆)κ2(Ys)ds,
t ≥0
(κ is deﬁned in (2.17)).

52
2 One-Sided Classiﬁcation of Isolated Singular Points
Consider
At =

⟨N⟩t
if t < S,
∞
if t ≥S,
τt = inf{s ≥0 : As > t},
Ut = Yτt = ∆+ Nτt + 1
2L∆
τt(Y ),
t ≥0.
It follows from Proposition A.15 that N is τ-continuous. Moreover, τ is
bounded since τ ≤S. By Proposition A.16, the process Vt = Nτt is a (F+
τt, P)-
local martingale with ⟨V ⟩t = t ∧η, where η = AS−. The following equality is
proved similarly as (2.29):
Ut = ∆+ Vt + 1
2L∆
t (U),
t ≥0.
Propositions A.32 and A.33 taken together show that U −∆is the modulus
of a Brownian motion started at zero and stopped at time η. (Note that η is
a (F+
τt)-stopping time.) We have
P{η = Tγ(U)} = P

supt∈[T0,S] Xt ≥c

> 0,
(2.31)
where γ = s(c).
Consider the function
g(y) = 1 + |b(s−1(y))|
κ2(y)
I(0 < y < γ).
The conditions of the theorem guarantee that, for any ε > 0,
 ε
0
g(y)dy =
 s−1(ε)
0
1 + |b(x)|
ρ(x)σ2(x)dx = ∞.
Combining this property with Propositions A.6 (ii) and A.8, we get
 Tγ(∆+|W|)
0
g(∆+ |Ws|)ds =
 Tγ−∆(|W|)
0
g(∆+ |Ws|)ds
=
 γ−∆
0
Ly
Tγ−∆(|W|)(|W|)g(∆+ y)dy
≥
 γ−∆
0
Ly
Tγ−∆(|W|)(W)g(∆+ y)dy
P-a.s.
−−−→
∆↓0
∞,
where W is a Brownian motion started at zero. Consequently, for any λ > 0,
there exists ∆∈(0, γ) such that
P
 Tγ(U)
0
g(Us)ds > λ

> 1 −1
2
P{η = Tγ(U)}.
(2.32)

2.5 One-Sided Classiﬁcation: The Proofs
53
On the other hand, for any ∆∈(0, γ), we have
 η
0
g(Us)ds =
 AS−
0
1 + |b(s−1(Us))|
κ2(Us)
ds
=
 S−
τ0
1 + |b(s−1(Ys))|
κ2(Ys)
dAs
=
 S
0
I(s ≥T0)I(Xs > δ)(1 + |b(Xs)|)ds
≤
 S
0
(1 + |b(Xs)|)ds < ∞
P-a.s.
We arrive at a contradiction with (2.31) and (2.32) since λ can be chosen
arbitrarily large.
(ii) Existence. We deﬁne the process Y
by (2.20), where B is a
(Gt)-Brownian motion started at s(x0) on a ﬁltered probability space

Ω, G, (Gt), Q

. Inequality (2.23) remains valid (take Lemma 2.18 into ac-
count). Set Z = s−1(Y ). The Itˆo–Tanaka formula yields that, for any n ∈N,
the process
N (n)
t
= Zt∧T1/n,a(Z) −x0 −
 t∧T1/n,a(Z)
0
b(Zs)ds,
t ≥0
is a continuous (Gτt, Q)-local martingale. Consider the process
Nt = Zt −x0 −
 t∧T0,a(Z)
0
b(Zs)ds,
t ≥0.
Note that ZT0,a(Z) = Z Q-a.s. It follows from (2.23) that N (n)
Q-u.p.
−−−−→
n→∞N. By
Lemma B.11, N ∈Mc
loc(Gt, Q). In a similar way we prove that
⟨N⟩t =
 t∧T0,a(Z)
0
σ2(Zs)ds,
t ≥0.
The proof of existence is now completed as in Theorem 2.11.
Uniqueness. Let P be the solution up to T0,a constructed above. Suppose
that there exists another solution P′ up to T0,a. If x0 = 0, then the statement
is trivial. Therefore, we can assume that x0 > 0. It follows from Theorem 2.11
that, for each n > 1/x0, P′|FT1/n,a = P|FT1/n,a. Note that T1/n,a(ω) ≤T0,a(ω)
for P, P′-a.e. ω, but not for all ω since ω(0) may not be equal to x0. Therefore,
we use here the convention from Lemma B.5. Applying Lemma B.6, we get
P′ = P.
The inequality EPT0,a < ∞follows from (2.23). The property P{T0,a <
∞and XT0,a = 0} > 0 follows from the construction of the solution.
2

54
2 One-Sided Classiﬁcation of Isolated Singular Points
Proof of Theorem 2.14. (i) Suppose that there exists a solution (P, S) such
that P{S ≥T0} > 0. We can assume that S ≤T0 and S is bounded (oth-
erwise, we can take S ∧T0 ∧m instead of S, where m is a suﬃciently large
number). Set P = P ◦Φ−1
S
(Φ is deﬁned by (B.1)). We choose δ ∈(0, x0 ∧a)
and set ∆= s(δ). Let us consider the process Y = 0 ∨s(X) ∧∆and the
stopping times Sn = S ∧T1/n(Y ), n ∈N. The Itˆo–Tanaka formula yields
that, for any n ∈N,
Yt∧Sn = ∆+ N (n)
t
−1
2ρ(δ)Lδ
t(X),
t ≥0
(we applied the equality L0
t(X) = 0; it is proved similarly as Theorem 2.6),
where N (n) ∈Mc
loc(Ft, P) and
⟨N (n)⟩t =
 t∧Sn
0
I(Ys < ∆)κ2(Ys)ds,
t ≥0
(κ is given by (2.17)). Using the same method as in (2.27), (2.28), we show
that
Yt∧Sn = ∆+ N (n)
t
−1
2L∆−
t
(Y ),
t ≥0,
where L∆−
t
(Y ) = limε↓0 L∆−ε
t
(Y ) (see Proposition A.6 (i)). Consider the
process
Nt = Yt −∆+ 1
2L∆−
t
(Y ),
t ≥0.
Then N (n) = N Sn. Obviously, Sn
P-a.s.
−−−−→
n→∞
S. Thus, N (n)
P-u.p.
−−−−→
n→∞
N. By
Lemma B.11, N ∈Mc
loc(Ft, P) and ⟨N (n)⟩
P-u.p.
−−−−→
n→∞⟨N⟩. Hence,
⟨N⟩t =
 t∧S
0
I(Ys < ∆)κ2(Ys)ds,
t ≥0.
Consider
At =



 t
0
I(Ys < ∆)κ2(Ys)ds
if t < S,
∞
if t ≥S,
τt = inf{s ≥0 : As > t},
Ut = Yτt = ∆+ Nτt −1
2L∆−
τt (Y ),
t ≥0.
The following equality is proved similarly as (2.29):
Ut −∆= Vt −1
2L∆−
t
(U),
t ≥0,

2.5 One-Sided Classiﬁcation: The Proofs
55
where Vt = Nτt. The process V is a standard linear Brownian motion stopped
at the time η = AS−. By Propositions A.32 and A.33 taken together, the
process ∆−U is the modulus of a Brownian motion started at zero and
stopped at time η.
Consider the function
g(y) = 1 + |b(s−1(y))|
κ2(y)
I(0 < y < ∆).
The conditions of the theorem ensure that, for any ε > 0,
 ε
0
yg(y)dy =
 s−1(ε)
0
1 + |b(x)|
ρ(x)σ2(x)s(x)dx = ∞.
Corollary A.24 yields
 T0(∆−|W|)
0
g(∆−|Ws|)ds = ∞
a.s.,
where W is a Brownian motion started at zero. Therefore,
	 η
0 g(Us)ds is P-a.s.
inﬁnite on the set
{η = T0(U)} = {inft≥0 Ut = 0} = {inft≤S Xt = 0},
and this set has strictly positive P-probability. On the other hand,
 η
0
g(Us)ds =
 AS−
0
1 + |b(s−1(Us))|
κ2(Us)
ds
=
 S−
τ0
1 + |b(s−1(Ys))|
κ2(Ys)
dAs
=
 S
0
I(s ≤S)I(Xs < δ)(1 + |b(Xs)|)ds
≤
 S
0
(1 + |b(Xs)|)ds < ∞
P-a.s.
This leads to a contradiction.
(ii) The proof is the same as in Theorem 2.13 (i).
(iii) Existence. We deﬁne the process Y by (2.20). Set Z = s−1(Y ),
P = Law(Zt; t ≥0), P = P|FT 0,a−. The arguments used in the proof of
Theorem 2.11 show that, for any n > 2/a, the measure P|FT1/n,a−1/n is a
solution up to T1/n,a−1/n. The stopping times
Sn = inf{t ≥0 : |Xt| ≤1/n} ∧inf{t ≥0 : |Xt −a| ≤1/n}
form a predicting sequence for T 0,a. Obviously, for each n > 2/a ∨1/x0,
P|FSn is a solution up to Sn. Hence, P is a solution up to T 0,a−.

56
2 One-Sided Classiﬁcation of Isolated Singular Points
Uniqueness. Let P be the solution up to T 0,a constructed above. Sup-
pose that there exists another solution P′ up to T 0,a. For each n ∈N, the
restrictions Pn = P|FSn and P′n = P′|FSn are solutions up to Sn (we use
here the convention from Lemma B.5). By Lemma B.5, each of the measures
Pn, P′n admits a unique extension to T1/n,a−1/n. Obviously, these extensions
are solutions up to T1/n,a−1/n, and, by Theorem 2.11, they coincide. Hence,
P′n = Pn. Now, choose t ≥0 and A ∈Ft. We have
P′(A ∩{T 0,a > t}) = lim
n→∞P′(A ∩{Sn > t}) = lim
n→∞P′n(A ∩{Sn > t})
= lim
n→∞Pn(A ∩{Sn > t}) = lim
n→∞P(A ∩{Sn > t}) = P(A ∩{T 0,a > t}).
Applying Proposition A.36, we get P′ = P.
In order to prove the inequality EPT 0,a < ∞, note that, for any n > 1/x0,
EPT1/n,a ≤2
 a
0
s(x)
ρ(x)σ2(x)dx < ∞
(see (2.23)).
The property P{limt↑T 0,a Xt = 0} > 0 follows from the construction of
the solution.
2
Proof of Theorem 2.15. (i) The proof is the same as in Theorem 2.14 (i).
(ii) The proof is the same as in Theorem 2.13 (i).
(iii) Existence. We deﬁne the process Y
by (2.20), where B is a
(Gt)-Brownian motion started at s(x0) on a ﬁltered probability space

Ω, G, (Gt), Q

. It follows from Corollary A.24 that AT0,α(B)−is Q-a.s. inﬁnite
on the set {T0(B) < Tα(B)}. Hence, Y is Q-a.s. strictly positive. Moreover,
lim
t→∞Yt = 0 Q-a.s. on {T0(B) < Tα(B)}.
(2.33)
Let us set Z = s−1(Y ), P = Law(Zt; t ≥0), P = P|FTa. The estimates used
in (2.23) show that for any c ∈(0, x0),
EQ
 Ta,c(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞.
Letting c →0, we get, for any t ≥0,
 t∧Ta(Z)
0

1 + |b(Zs)| + σ2(Zs)

ds < ∞
Q-a.s.
The proof of existence is now completed in the same way as in Theorem 2.11.
Uniqueness. Let P be the solution up to Ta constructed above. Suppose
that there exists another solution P′ up to Ta. It follows from Theorem 2.11

2.5 One-Sided Classiﬁcation: The Proofs
57
that, for any n > 1/x0, P′|FT1/n,a = P|FT1/n,a. Since the solution (P, Ta) is
strictly positive, P{T1/n,a = Ta} −−−−→
n→∞1. Hence, P′{T1/n,a = Ta} −−−−→
n→∞1.
Applying Lemma B.6, we deduce that P′ = P.
The properties P{Ta = ∞} > 0 and limt→∞Xt = 0 P-a.s. on {Ta = ∞}
follow from (2.33).
2
Proof of Theorem 2.16. (i) Suppose that there exists a solution (P, S) such
that P{T0 < ∞, T0 ≤S} > 0. Then there exists d ∈(0, a) such that
P

T0 < ∞, T0 ≤S, and
sup
t∈[Td,T0]
Xt < a

= θ > 0.
(2.34)
We choose δ ∈(0, d) and consider
X′
t = d +
 t
0
I(s > Td)dXs,
t ≥0,
Yt = s

X′
t∧Tδ,a(X′)

,
t ≥0.
The Itˆo-Tanaka formula shows that Y is a (Ft, P)-local martingale, where
P = P ◦Φ−1
S
(Φ is deﬁned by (B.1)). Moreover, Y is bounded, and therefore,
there exists Y∞= limt→∞Yt. We have
s(d) = Y0 = EPY∞
= EP

Y∞I

Ts(δ)(Y ) = ∞

+ EP

Y∞I

Ts(δ)(Y ) < ∞

≤θs(δ),
where θ is deﬁned in (2.34). (In the above inequality we took into account
that Y ≤0.) Since s(δ) −−→
δ↓0 −∞, we arrive at a contradiction.
(ii) Existence. Let us consider
At =



 t
0
κ−2(Bs)ds
if t < T0(B),
∞
if t ≥T0(B),
(2.35)
τt = inf{s ≥0 : As > t},
(2.36)
Yt = Bτt,
t ≥0,
(2.37)
where B is a Brownian motion started at s(x0) on a ﬁltered probability space
(Ω, G, (Gt), P) and κ is deﬁned in (2.17). Note that s(x0) ≤s(a) = 0. Using
the same arguments as in the proof of the existence part of Theorem 2.11,
we show that AT0(B)−= T0(Y ) Q-a.s. For Z = s−1(Y ), we have

58
2 One-Sided Classiﬁcation of Isolated Singular Points
EQ
 Ta(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt
= EQ
 Ta(Y )
0

1 + |b(s−1(Yt))| + σ2(s−1(Yt))

dt
= EQ
 Ta(B)
0
1 + |b(s−1(Bt))| + σ2(s−1(Bt))
κ2(Bt)
dt
= EQ
 0
−∞
1 + |b(s−1(y))| + σ2(s−1(y))
κ2(y)
Ly
T0(B)(B)dy
≤2
 0
−∞
1 + |b(s−1(y))| + σ2(s−1(y))
κ2(y)
|y|dy
= 2
 a
0
1 + |b(x)| + σ2(x)
ρ(x)σ2(x)
|s(x)|dx
(2.38)
(the inequality here follows from Proposition A.10.) In view of Lemma 2.18,
this expression is ﬁnite. The proof of existence is now completed as in Theo-
rem 2.11.
Uniqueness. The uniqueness of a solution is proved in the same way as in
Theorem 2.15 (iii).
The property EPTa < ∞follows from (2.38).
(iii) Existence. The same estimates as in (2.38) show that, for any
0 < x < c ≤a,
EPx
 Tc
0

1 + |b(Xs)| + σ2(Xs)

ds ≤2
 c
0
1 + |b(u)| + σ2(u)
ρ(u)σ2(u)
|s(u)|du,
where Px is the solution with X0 = x deﬁned up to Ta. The ﬁniteness of the
integral
 a
0
1 + |b(u)| + σ2(u)
ρ(u)σ2(u)
|s(u)|du
(see Lemma 2.18) ensures that there exists a sequence of strictly positive
numbers a = a0 > a1 > . . . such that an ↓0 and
∞

n=1
EPn
 Tan−1
0

1 + |b(Xs)| + σ2(Xs)

ds < ∞,
(2.39)
where Pn is the solution with X0 = an deﬁned up to Tan−1.
We set
Qn = Law

X
Tan−1
t
−an; t ≥0 | Pn
.
Then Qn are probability measures on C0(R+), where C0(R+) is the space of
continuous functions R+ →R vanishing at zero. Let us consider

2.5 One-Sided Classiﬁcation: The Proofs
59
Ω= C0(R+) × C0(R+) × . . . ,
G = B(C0(R+)) × B(C0(R+)) × . . . ,
Q = Q1 × Q2 × . . .
and let Y (n) denote the coordinate process on the n-th copy of C0(R+). We
consider each Y (n) as a process on Ω. Set ηn = Tan−1(an + Y (n)). It follows
from (2.39) that
EQ
∞

n=1
ηn =
∞

n=1
EQnηn =
∞

n=1
EPnTan−1 < ∞,
and hence, ∞
n=1 ηn < ∞Q-a.s. Now we consider
τn =
∞

k=n+1
ηk,
n = 0, 1, . . . .
Let us deﬁne the process (Zt; t ≥0) by
Zt =





0
if t = 0,
an + Y (n)
t−τn
if τn ≤t < τn−1,
a
if t ≥τ0.
Obviously, Z is Q-a.s. continuous on (0, ∞). Furthermore, on each interval
]]0, τn[[ we have Z ≤an Q-a.s. Thus, Z is Q-a.s. continuous on [0, ∞).
Set P = Law(Zt; t ≥0 | Q), P = P|FTa. Let us prove that (P, Ta) is a
solution with X0 = 0. Conditions (a) and (b) of Deﬁnition 1.31 are obviously
satisﬁed. Condition (c) follows from the equalities
EP
 Ta
0

1 + |b(Xs)| + σ2(Xs)

ds
= EQ
 τ0
0

1 + b(Zs) + σ2(Zs)

ds
= EQ
∞

n=1
 τn−1
τn

1 + |b(Zs)| + σ2(Zs)

ds
=
∞

n=1
EPn
 Tan−1
0

1 + |b(Xs)| + σ2(Xs)

ds
and inequality (2.39).
Let us verify conditions (d) and (e). For n ∈N, set U (n) = Zτn and deﬁne
the processes V (n) recursively by
V (1) = G(Y (1), 0, η1),
V (2) = G(Y (2), V (1), η2),
V (3) = G(Y (3), V (2), η3), . . . ,

60
2 One-Sided Classiﬁcation of Isolated Singular Points
where G is the gluing function (see Deﬁnition B.8). Using Lemma B.9, one
can verify that, for each n ∈N, the process
N (n)
t
= V (n)
t
−
 t∧(η1+···+ηn)
0
b(an + V (n)
s
)ds,
t ≥0
is a

FV (n)
t
, Q

-local martingale. Observe that τn is a

FU(n)
t

-stopping time
since τn = Tan(U (n)). Moreover, G(U (n), V (n), τn) = Z. By Lemma B.9,
G(0, N (n), τn) ∈Mc
loc(FZ
t , Q). Obviously, G(0, N (n), τn) = K(n), where
K(n)
t
=



0
if t < τn,
Zt −an −
 t∧τ0
τn
b(Zs)ds
if t ≥τn.
It follows from (2.39) and the continuity of Z that K(n)
u.p.
−−−−→
n→∞K, where
Kt = Zt −
 t∧τ0
0
b(Zs)ds,
t ≥0.
Due to Lemma B.11, K ∈Mc
loc(FZ
t , Q). This means that the process
Mt = Xt −
 t∧Ta
0
b(Xs)ds,
t ≥0
is a (Ft, P)-local martingale. In a similar way we check that
⟨M⟩t =
 t∧Ta
0
σ2(Xs)ds,
t ≥0.
As a result, P is a solution up to Ta.
Uniqueness. Let P be a positive solution deﬁned up to Ta. Set P = P◦Φ−1
Ta
(Φ is deﬁned by (B.1)) and, for each x ∈(0, a], consider the measures Qx =
P( · | Tx < ∞), Rx = Qx ◦Θ−1
Tx , where Θ is deﬁned by (A.4). The same
arguments as those used in the proof of Lemma B.7 show that Rx|FTa is a
solution of (1) with X0 = x deﬁned up to Ta. Therefore, Rx|FTa = Px, where
Px is the unique solution with X0 = x deﬁned up to Ta. On the other hand,
XTa = X Rx-a.s. Hence,
Rx = Rx ◦Φ−1
Ta = (Rx|FTa) ◦Φ−1
Ta = Px ◦Φ−1
Ta ,
(2.40)
which proves that the measures Rx are determined uniquely.
Similarly to (2.30), we prove that
 Ta
0
I(Xs = 0)ds = 0
P-a.s.

2.5 One-Sided Classiﬁcation: The Proofs
61
Since P is a positive solution, this equality shows that Tx
P-a.s.
−−−→
x↓0
0. Hence, Rx
converge weakly to P as x ↓0. Now it follows from (2.40) that P (and hence,
P) is unique.
2
Proof of Theorem 2.17. (i) The proof is the same as that of Theorem 2.16 (i).
(ii) Suppose that there exists a solution (P, S) such that
P

supt∈[0,S] Xt > c

> 0
for some c > 0. We can assume that S is bounded. Set P = P ◦Φ−1
S
(Φ is
deﬁned by (B.1)).
Choose δ ∈(0, c) and consider the process
X′
t = δ +
 t
0
I(s ≥Tδ)dXs,
t ≥0.
Then the arguments used in the proof of Theorem 2.16 (i) show that
P{∀t ≥0, X′
t > 0} = 1.
Set Y = s(X′), ∆= s(δ). According to the Itˆo–Tanaka formula and the
occupation times formula, Y ∈Mc
loc(Ft, P) and
⟨Y ⟩t =
 t
0
I(Tδ ≤s ≤S)κ2(Ys)ds,
t ≥0
(κ is deﬁned in (2.17)).
Consider
At =

⟨Y ⟩t
if t < S,
∞
if t ≥S,
τt = inf{s ≥0 : As > t},
Vt = Yτt,
t ≥0.
The process V −∆is a Brownian motion started at zero and stopped at the
time η = AS−. We have
P{η > Tγ(V )} = P

supt∈[0,S] Xt > c

> 0.
Let us consider the function
g(y) = 1 + |b(s−1(y))|
κ2(y)
I(y < γ).
The conditions of the theorem guarantee that
∀λ < γ,
 λ
−∞
|y −γ|g(y)dy = ∞.
(2.41)

62
2 One-Sided Classiﬁcation of Isolated Singular Points
Let (Wt; t ≥0) be a two-dimensional Brownian motion started at zero. The
set
D =

ω : ∀λ < γ,
 λ
−∞
|Wγ−y(ω)|2g(y)dy = ∞

belongs to the tail σ-ﬁeld X = 
t>0 σ(Ws; s ≥t). In view of Blumenthal’s
zero–one law and the time-inversion property of W, P(D) equals 0 or 1.
Combining (2.41) with Proposition A.34, we conclude that P(D) = 1. Using
Proposition A.10 (i), we get
 Tγ(∆+B)
0
g(∆+ Bs)ds ≥
 γ
∆
Ly−∆
Tγ−∆(B)(B)g(y)dy
law
=
 γ
∆
|Wγ−y|2g(y)dy
P
−−−−−→
∆→−∞
 γ
−∞
|Wγ−y|2g(y)dy
a.s.
= ∞,
where B is a Brownian motion started at zero. The proof is now completed
in the same way as the proof of Theorem 2.13 (i).
(iii) Existence. Deﬁne Y by (2.37), where B is a (Gt)-Brownian motion
started at s(x0) on a ﬁltered probability space (Ω, G, (Gt), P) and κ is deﬁned
in (2.17). Set Z = s−1(Y ). Arguing in the same way as in the proof of the
existence part of Theorem 2.11, we check that AT0(B)−= T0(Y ) Q-a.s. The
estimates used in (2.38) show that for any c ∈(0, x0),
 Ta,c(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞
Q-a.s.
(2.42)
Furthermore, Ta(Z) = T0(Y ) < ∞Q-a.s. Letting c →0 in (2.42), we get
 Ta(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞
Q-a.s.
(2.43)
The proof of existence is now completed in the same way as in Theorem 2.11.
Uniqueness. The uniqueness of a solution is proved in the same way as in
Theorem 2.15 (iii).
The property Ta < ∞P-a.s. follows from (2.43).
2
Proof of Theorem 2.7. As d is a regular point, there exist constants
d1 < d < d2 such that
1 + |b|
σ2
∈L1
loc([d1, d2]).
We will employ the notation used in the proof of Theorem 2.11. Without loss
of generality, we can assume that d1 = 0, d2 = a.
Suppose ﬁrst that x0 = d. Set P = Law

XT0,a
t
; t ≥0 | P

. Then P|FT0,a is
a solution up to T0,a. By Theorem 2.11, this measure is unique. Consequently,

2.5 One-Sided Classiﬁcation: The Proofs
63
P = Law(Zt; t ≥0), where Z = s−1(Y ) and Y is deﬁned by (2.20). By the
Itˆo–Tanaka formula and Proposition A.17,
(Yt −s(x0))+ = (Bτt −s(x0))+ =
 τt
0
I(Bs > s(x0))dBs + 1
2Ls(x0)
τt
(B)
=
 t
0
I(Bτs > s(x0))dBτs + 1
2Ls(x0)
τt
(B)
=
 t
0
I(Ys > s(x0))dYs + 1
2Ls(x0)
τt
(B),
t ≥0.
On the other hand,
(Yt −s(x0))+ =
 t
0
I(Ys > s(x0))dYs + 1
2Ls(x0)
t
(Y ),
t ≥0,
and therefore, Ls(x0)
t
(Y ) = Ls(x0)
τt
(B).
Applying the Itˆo–Tanaka formula to the function y →s−1(y ∨s(x0)) and
keeping (2.24), (2.25) in mind, we get
s−1(Yt ∨s(x0)) = x0 +
 t
0
1
ρ(s−1(Ys))I(Ys > s(x0))dYs
+ 1
2
 t
0
2b(s−1(Ys))
κ2(Ys)
I(Ys > s(x0))d⟨Y ⟩s +
1
2ρ(x0)Ls(x0)
t
(Y )
= x0 +
 t
0
I(Zs > x0)dZs +
1
2ρ(x0)Ls(x0)
t
(Y ),
t ≥0,
(2.44)
where Z = s−1(Y ). Applying now the Itˆo–Tanaka formula to the function
x →x ∨s(x0), we get
s−1(Yt ∨s(x0)) = Zt ∨x0 = x0 +
 t
0
I(Zs > x0)dZs + 1
2Lx0
t (Z),
t ≥0.
Comparing this with (2.44), we deduce that
Lx0
t (Z) =
1
ρ(x0)Ls(x0)
t
(Y ) =
1
ρ(x0)Ls(x0)
τt
(B),
t ≥0.
For any t > 0, τt > 0 a.s. It follows from Proposition A.8 that, for any t > 0,
Ls(x0)
t
(B) > 0 a.s. Hence, for any t > 0, Lx0
t (Z) > 0 a.s., which means that
Lx0
t (XT0,a) > 0 P-a.s. Using the obvious equality Lx0
t (XT0,a) = (Lx0
t (X))T0,a,
we get: for any t > 0, Lx0
t (X) > 0 P-a.s. Taking into account (2.5), we obtain
the desired statement.
Suppose now that x0 ̸= d. Set Q = P( · | Td < ∞), R = Q ◦Θ−1
Td , where Θ
is deﬁned by (B.2). By Lemma B.7, R is a solution of (1) with X0 = d. The

64
2 One-Sided Classiﬁcation of Isolated Singular Points
statement proved above (for the case x0 = d), together with Corollary A.7,
yields that, for any t > 0,
lim
ε↓0
1
ε
 t
0
I(d ≤Xs < d + ε)σ2(Xs)ds > 0
R-a.s.
Hence,
lim
ε↓0
1
ε
 t+Td
Td
I(d ≤Xs < d + ε)σ2(Xs)ds > 0
Q-a.s.
This means that
lim
ε↓0
1
ε
 t+Td
Td
I(d ≤Xs < d + ε)σ2(Xs)ds > 0
P-a.s. on {Td < ∞}.
Consequently,
lim
ε↓0
1
ε
 t+Td
0
I(d ≤Xs < d + ε)σ2(Xs)ds > 0
P-a.s. on {Td < ∞}.
Applying once more Corollary A.7, we get the desired statement.
2

3 Two-Sided Classiﬁcation
of Isolated Singular Points
In this chapter, we investigate the behaviour of a solution of (1) in the two-
sided neighbourhood of an isolated singular point. Many properties related
to the “two-sided” behaviour follow from the results of Section 2.3. However,
there are some properties that involve both the right type and the left type
of a point. The corresponding statements are formulated in Section 3.1.
Section 3.2 contains an informal description of the behaviour of a solution
for various types of isolated singular points.
The statements formulated in Section 3.1 are proved in Sect 3.3.
The results of Section 3.1 show that the isolated singular points of only 4
types can disturb uniqueness. These points are called here the branch points.
Disturbing uniqueness, the branch points give rise to a variety of “bad” so-
lutions. In particular, one can easily construct a non-Markov solution in the
neighbourhood of a branch point. This is the topic of Section 3.4.
However, it turns out that all the strong Markov solutions in the neigh-
bourhood of a branch point admit a simple description. It is given in Sec-
tion 3.5.
Throughout this chapter, we assume that σ(x) ̸= 0 for all x ∈R.
3.1 Two-Sided Classiﬁcation: The Results
Deﬁnition 3.1. An isolated singular point has type (i, j) if it has left type i
and right type j. (The left type of an isolated singular point is deﬁned similarly
as the right type.)
Suppose that zero is an isolated singular point. Then there exist numbers
a < 0 < c such that
1 + |b|
σ2
∈L1
loc

[a, c] \ {0}

.
(3.1)
If zero has right type 0, then
 c
0
1 + |b(x)|
σ2(x)
dx < ∞.
If the right type of zero is one of 1, . . . , 6, then, for any ε > 0,
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 65–79, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

66
3 Two-Sided Classiﬁcation of Isolated Singular Points
 ε
0
1 + |b(x)|
σ2(x)
dx = ∞.
(This can easily be seen from Figure 2.2.)
If zero had type (0, 0), then we would have (1 + |b|)/σ2 ∈L1
loc(0), and
hence, zero would not be a singular point. For the other 48 possibilities,
(1 + |b|)/σ2 /∈L1
loc(0). As a result, an isolated singular point can have one of
48 possible types.
Theorem 3.2. Suppose that zero has type (i, j) with i
=
0, 1, 4, 5, 6,
j = 0, 1, 4, 5, 6 (we exclude the case i = j = 0). Then, for any solution (P, S),
we have S ≤T0 P-a.s.
Theorem 3.3. Suppose that zero has type (i, j) with i = 0, 1, j = 2, 3.
(i) If (P, S) is a solution, then X ≥0 on [[T0, S]] P-a.s.
(ii) If x0 ∈[a, c], then there exists a unique solution P deﬁned up to Ta,c.
Theorem 3.4. Suppose that zero has type (2, 2). Then, for any x0 ∈(a, c),
there exist diﬀerent solutions deﬁned up to Ta,c.
Theorem 3.5. Suppose that zero has type (2, 3).
(i) If (P, S) is a solution, then X
> 0 on ]]T0+, S]] P-a.s., where
T0+ = inf{t ≥0 : Xt > 0}.
(ii) If x0 ∈(a, 0], then there exist diﬀerent solutions deﬁned up to Ta,c.
(iii) If x0 ∈(0, c], then there exists a unique solution deﬁned up to Ta,c,
and it is strictly positive.
Theorem 3.6. Suppose that zero has type (3, 3).
(i) If x0 ∈[a, 0), then there exists a unique solution deﬁned up to Ta,c,
and it is strictly negative.
(ii) If x0 ∈(0, c], then there exists a unique solution deﬁned up to Ta,c,
and it is strictly positive.
(iii) If x0 = 0, then there exist diﬀerent solutions deﬁned up to Ta,c. They
can be described as follows. If P is a solution deﬁned up to Ta,c, then there
exists λ ∈[0, 1] such that P = λP−+ (1 −λ)P+, where P−is the unique
negative solution up to Ta,c and P+ is the unique positive solution up to Ta,c.
We do not formulate here the statements related to types (i, j) with
i = 4, 5, 6, j = 2, 3 because, for these types, the behaviour of a solution
in the neighbourhood of the corresponding point is clear from the one-sided
classiﬁcation, and there are no new eﬀects brought by the two-sided combi-
nation of types.
3.2 Two-Sided Classiﬁcation: Informal Description
If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 0, 1, 4, 5, 6 (the case i = j = 0
is excluded), then after the time a solution has reached zero (if this time is

3.2 Two-Sided Classiﬁcation: Informal Description
67
-
-
-
6
6
6
t
t
t












5
3
0
2
1
1
A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






A
AA
A
AA
A
AA






AA
Fig. 3.1. Behaviour of solutions for various types of the isolated singular points.
The graphs show simulated paths of solutions with diﬀerent starting points. The
top graph illustrates Theorem 3.2. This graph corresponds to the case, where zero
has type (1,1). The signs “
” indicate that a solution cannot be extended after it
has reached zero. The centre graph illustrates Theorem 3.3. This graph corresponds
to the case, where zero has type (0,2). The bottom graph illustrates the situation,
where zero has type (i, j) with i = 4, 5, 6, j = 2, 3. This graph corresponds to the
case, where zero has type (5,3).

68
3 Two-Sided Classiﬁcation of Isolated Singular Points
-
-
-
6
6
6
t
t
t












3
3
2
3
2
2
Fig. 3.2. Behaviour of solutions for various types of the branch points, i.e., points
of type (i, j) with i = 2, 3, j = 2, 3. The graphs show simulated paths of “branching”
solutions. The top graph shows 4 diﬀerent solutions started at zero for the case,
where zero has type (2, 2). The centre graph and the bottom graph are constructed
in a similar way for the cases, where zero has types (2, 3) and (3, 3), respectively.

3.3 Two-Sided Classiﬁcation: The Proofs
69
ﬁnite), it cannot go further either in the positive direction or in the negative
direction. Therefore, a solution can be deﬁned at most up to T0.
If zero has type (i, j) with i = 0, 1, j = 2, 3, then a solution started at a
strictly negative point can reach zero. After this time, the solution cannot go
in the negative direction, but it can go in the positive direction. Thus, there
exists a unique solution “in the neighbourhood of zero” that passes through
zero in the positive direction. In other words, zero is then a “right shunt”.
If zero has type (i, j) with i = 4, 5, 6, j = 2, 3, then the behaviour of a
solution in the neighbourhood of zero is clear from the one-sided classiﬁcation.
Namely, a solution started at a positive point can reach zero if j = 2, but
cannot enter the strictly negative half-line; a solution started at a strictly
negative point cannot reach zero.
If zero has type (i, j) with i = 2, 3, j = 2, 3, then there exist (at least
locally) both a positive solution and a negative solution started at zero.
If zero has type (2, 2), then a solution started at any point in a suﬃciently
small neighbourhood of zero can reach zero with strictly positive probability.
After the time it has reached zero, it may go in the positive direction or in
the negative direction. Thus, for any starting point in the neighbourhood of
zero, there exist diﬀerent (local) solutions.
If zero has type (2, 3), then, by the same reasoning, there exist diﬀerent
(local) solutions for all the starting points in the left-hand neighbourhood
of zero. However, a solution started at a strictly positive point cannot reach
zero, and therefore, the presence of this “bad” point does not disturb the
uniqueness of a solution with x0 > 0.
If zero has type (3, 3), then solutions started outside zero never reach
zero, and therefore, the presence of this “bad” point does not disturb the
uniqueness of a solution with x0 ̸= 0. Of course, this does not mean that, for
x0 ̸= 0, there exists a unique solution since there may exist points of type
(2, 2), (2, 3), (3, 2), or (3, 3) other than zero.
3.3 Two-Sided Classiﬁcation: The Proofs
Proof of Theorem 3.3. (i) We will prove this statement for types (i, j) with
i = 0, 1, j = 1, . . . , 6. If i = 1, then the statement follows from Theo-
rem 2.13 (i). Now, suppose that i = 0. Let (P, S) be a solution. Set P = P◦Φ−1
S
(Φ is deﬁned by (B.1)) and consider the functions

70
3 Two-Sided Classiﬁcation of Isolated Singular Points
ρ−(x) = exp

−
 x
a
2b(x)
σ2(x)dy

,
x ∈[a, 0],
(3.2)
s−(x) = −
 0
x
ρ(y)dy,
x ∈[a, 0],
(3.3)
f(x) =





k1(x −a) + s−(a)
if x < a,
s−(x)
if a ≤x ≤0,
k2x
if x > 0,
(3.4)
where the constants k1 and k2 are chosen in such a way that f is diﬀerentiable
at the points a and 0 (such constants exist since zero has left type 0). By the
Itˆo–Tanaka formula together with the occupation times formula, the process
Y = f(X) is a (Ft, P)-semimartingale with the decomposition
Yt = Y0 +
 t∧S
0

k1I(Ys < s−(a))b(f −1(Ys)) + k2I(Ys > 0)b(f −1(Ys))

ds + Nt
= Y0 +
 t∧S
0
ϕ(Ys)ds + Nt,
t ≥0,
where N ∈Mc
loc(Ft, P) and
⟨N⟩t =
 t∧S
0
(f ′(f −1(Ys)))2σ2(f −1(Ys))ds =
 t∧S
0
ψ2(Ys)ds,
t ≥0.
As the right type of zero is one of 1, . . . , 6, we have for any ε > 0,
 ε
0
1 + |ϕ(y)|
ψ2(y)
dy = ∞.
Combining this with the arguments used in the proof of Theorem 2.5, we
deduce that L0
t(Y ) = 0 P-a.s. By the Itˆo–Tanaka formula,
Y −
t
= Y −
0 +
 t
0
I(Ys ≤0)dYs
= Y −
0 +
 t∧S
0
I(Ys ≤0)ϕ(Ys)ds +
 t
0
I(Ys ≤0)dNs,
where we use the notation x−= x ∧0. Choose ∆∈(f(a), 0) and consider
T = inf{t ≥T0(Y ) : Yt = ∆}. The function ϕ is zero on (s−(a), 0). Therefore,
the process
Zt =
 t
0
I(T0(Y ) ≤s < T )dY −
s ,
t ≥0
is a (Ft, P)-local martingale. As Z is negative and Z0 = 0, we deduce that
Z = 0 P-a.s. Consequently, after the time T0(Y ), the process Y reaches no
level ∆< 0. This leads to the desired statement.

3.3 Two-Sided Classiﬁcation: The Proofs
71
(ii) Existence. If x0 ∈[0, c], then, by Theorems 2.12 and 2.16, there exists
a solution up to Tc. Obviously, its restriction to FTa,c is a solution up to Ta,c.
Suppose now that x0 ∈[a, 0). Then there exists a solution Q deﬁned up
to Ta,0. Let R0 be the positive solution with X0 = 0 deﬁned up to Tc. Set
Q = Q ◦Φ−1
Ta,0, R0 = R0 ◦Φ−1
Tc . We will consider Q as a measure on C(R+)
and R0 as a measure on C0(R+). Let P be the image of Q × R0 under the
map
C(R+) × C0(R+) ∋(ω1, ω2) −→G(ω1, ω2, T0(ω1)) ∈C(R+),
where G is the gluing function. Using Lemma B.9, one can verify that the
measure P = P|FTa,c is a solution up to Ta,c.
Uniqueness. If x0 ∈[0, c], then uniqueness follows from statement (i) of
this theorem and the results of Section 2.3.
Suppose now that x0 ∈[a, 0). Let P be a solution deﬁned up to Ta,c. Set
P = P ◦Φ−1
Ta,c. Let P0 denote the (unique) solution with X0 = 0 deﬁned up
to Ta,c. Set P0 = P0 ◦Φ−1
Ta,c. We will consider
Ω= C(R+) × C(R+),
G = F × F,
Gt = Ft × Ft,
Q = P × P0.
A generic point ω of Ωhas the form (ω1, ω2). Let us deﬁne the processes
Yt(ω) = ω1(t ∧Ta,0(ω1)),
t ≥0,
Zt(ω) =

ω1(t + T0(ω1))
if T0(ω1) < ∞,
ω2(t)
if T0(ω1) = ∞.
Set H = σ(Yt; t ≥0). Let (Qω)ω∈Ωdenote a version of the Q-conditional
distribution of (Zt; t ≥0) with respect to H. We will now prove that, for
Q-a.e. ω, Qω|FTa,c is a solution of (1) with X0 = 0 deﬁned up to Ta,c.
Conditions (a), (b) of Deﬁnition 1.31 are obviously satisﬁed. Furthermore,
for any t ≥0,
 t∧Ta,c(Z)
0

|b(Zs)| + σ2(Zs)

ds < ∞
Q-a.s.
Hence, for Q-a.e. ω, we have
∀t ≥0,
 t∧Ta,c
0

|b(Xs)| + σ2(Xs)

ds < ∞
Qω-a.s.
Thus, condition (c) of Deﬁnition 1.31 is satisﬁed for Q-a.e. ω.
Let us now verify that, for Q-a.e. ω, the measure Qω|FTa,c satisﬁes con-
dition (d) of Deﬁnition 1.31. Consider the process
Nt = Zt −
 t∧Tc(Z)
0
b(Zs)ds,
t ≥0

72
3 Two-Sided Classiﬁcation of Isolated Singular Points
and the stopping times Sm(N) = inf{t ≥0 : |Nt| ≥m}. For any s ≤t,
A ∈Fs, and B ∈H, we have
EQ

N Sm(N)
t
−N Sm(N)
s

I({Z ∈A} ∩B)

= 0.
(This follows from the construction of Q and the optional stopping theorem.)
Hence, for Q-a.e. ω,
EQω

M Sm(M)
t
−M Sm(M)
s

I(X ∈A)

= 0,
where
Mt = Xt −
 t∧Ta,c
0
b(Xs)ds,
t ≥0
and Sm(M) = inf{t ≥0 : |Mt| ≥m}. As a result, for Q-a.e. ω,
M ∈Mc
loc(Ft, Qω).
In a similar way, we prove that, for Q-a.e. ω, Qω|FTa,c satisﬁes condi-
tion (e) of Deﬁnition 1.31. Using now Theorems 2.11, 2.13, we deduce that,
for Q-a.e. ω, Qω|FTa,c = P0. This implies that ZTa,c(Z) is independent of H.
Since Z = ZTa,c(Z) Q-a.s., we conclude that Z is independent of H.
The obtained results show that Law(X1
t ; t ≥0 | Q) coincides with the
“glued” measure constructed in the proof of existence. This means that P is
determined uniquely. Hence, the measure P = P|FTa,c is unique.
2
Proof of Theorem 3.2. It follows from the proof of Theorem 3.3 (i) and the
results of Section 2.3 that, for any solution (P, S), X = 0 on [[T0, S]] P-a.s.
On the other hand, the quadratic variation
⟨X⟩t =
 t∧S
0
σ2(Xs)ds,
t ≥0
is strictly increasing on [[0, S]] since σ2 > 0. This leads to the desired state-
ment.
2
Proof of Theorem 3.4. Without loss of generality, we suppose that x0 ∈(a, 0].
It follows from Theorem 2.12 that there exists a negative solution P deﬁned
up to Ta,c.
There also exists a positive solution P0 with X0 = 0 deﬁned up to Ta,c.
Set P = P ◦Φ−1
Ta,c, P0 = P0 ◦Φ−1
Ta,c (Φ is deﬁned by (B.1)) and let P′ be the
image of P × P0 under the map
C(R+) × C0(R+) ∋(ω1, ω2) −→G(ω1, ω2, T0(ω1)) ∈C(R+),
where G is the gluing function. Using Lemma B.9, one can verify that the
measure P′ = P′|FTa,c is a solution of (1) up to Ta,c. Moreover, P′ is not
negative, and hence, P′ ̸= P.
2

3.4 The Branch Points: Non-Markov Solutions
73
Proof of Theorem 3.5. (i) Let (P, S) be a solution. For 0 ≤α < β < c, we set
T β
α = inf{t ≥Tβ : Xt = α}. Suppose that there exists β ∈(0, c) such that
P{T β
0 < ∞, T β
0 ≤S} > 0. Then there exists α ∈(0, β) such that
P

T β
0 < ∞, T β
0 ≤S, and supt∈[T β
α ,T β
0 ] Xt ≤c

> 0.
Using the same arguments as in the proof of Theorem 2.16 (i), we arrive at a
contradiction. Thus, for any β ∈(0, c), P{T β
0 < ∞, T β
0 ≤S} = 0. This leads
to the desired statement.
(ii) This statement is proved in the same way as Theorem 3.4.
(iii) This statement follows from Theorem 2.16 (ii).
2
Proof of Theorem 3.6. (i),(ii) These statements follow from Theorem 2.16 (ii).
(iii) Let P be a solution up to Ta,c. The proof of Theorem 3.5 (i) shows
that
P{∃t ∈(T0+, Ta,c] : Xt ≤0} = 0,
P{∃t ∈(T0−, Ta,c] : Xt ≥0} = 0,
where T0−= inf{t ≥0 : Xt < 0}. Furthermore, T0+ ∧T0−= 0 P-a.s. since
σ ̸= 0. Thus, P(A+ ∪A−) = 1, where
A+ =

ω ∈C(R+) : ω(0) = 0 and ω > 0 on (0, Ta,c(ω)]

,
A−=

ω ∈C(R+) : ω(0) = 0 and ω < 0 on (0, Ta,c(ω)]

.
Suppose that P coincides neither with P−nor with P+. Then P(A+) > 0
and the conditional probability P( · | A+) is a solution up to Ta,c (note that
A+ ∈
ε>0 Fε). Moreover, this solution is positive, and thus, it coincides
with P+. In a similar way, we prove that P( · | A−) = P−. Thus, P =
λP−+ (1 −λ)P+ with λ = P(A−).
2
3.4 The Branch Points: Non-Markov Solutions
Deﬁnition 3.7. A branch point is an isolated singular point that has one of
types (2, 2), (2, 3), (3, 2), or (3, 3).
The branch points can be characterized by the following statement.
Lemma 3.8. Suppose that zero is an isolated singular point. Then it is a
branch point if and only if there exist both a positive solution and a negative
solution with X0 = 0 deﬁned up to Ta,c. (Here a and c are taken from (3.1).)

74
3 Two-Sided Classiﬁcation of Isolated Singular Points
The statement follows from the results of Section 2.3.
In what follows, X denotes the canonical process on C(R+) and (Ft)
stands for the canonical ﬁltration on C(R+). For s ≥0, the shift operator
Θs : C(R+) →C(R+) is deﬁned by
(Θsω)(t) = ω(s + t),
t ≥0.
Deﬁnition 3.9. A measure P on F has the Markov property if for any t ≥0
and any positive F-measurable function Ψ,
EP[Ψ ◦Θt | Ft] = EP[Ψ ◦Θt | σ(Xt)].
If SDE (1) possesses a unique global solution for any x0 ∈R, then these so-
lutions are Markov (see [45, Th. 6.2] or [28, Th. 18.11]; see also [15, Cor. 4.38]).
The example below shows that the presence of branch points may give rise
to non-Markov solutions.
Example 3.10 (non-Markov solution; SDE for a Bessel process). Let
us consider the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0
(3.5)
with 1 < δ < 2. Take x0 > 0 and let P be the positive solution of (3.5) (this
is the distribution of a δ-dimensional Bessel process started at x0). Consider
the map
C(R+) ∋ω −→ω′ ∈C(R+)
deﬁned by
ω′(t) =





ω(t)
if t ≤T0(ω),
ω(t)
if t > T0(ω) and ω(T0(ω)/2) > 1,
−ω(t)
if t > T0(ω) and ω(T0(ω)/2) ≤1.
Then the image P′ of P under this map is a non-Markov solution of (3.5).
The proof is straightforward.
Remarks. (i) Similarly to Example 3.10, one can construct non-Markov local
solutions for an arbitrary SDE that possesses an isolated singular point of
types (2, 2), (2, 3), or (3, 2). The points of type (3, 3) do not lead to non-
Markov solutions (this follows from Theorem 3.6).
(ii) Let us mention another way to construct non-Markov solutions of
one-dimensional homogeneous SDEs. Consider the equation
dXt = |Xt|αdBt,
X0 = 0
(3.6)

3.5 The Branch Points: Strong Markov Solutions
75
with 0 < α < 1/2. This example was ﬁrst considered by Girsanov [22].
SDE (3.6) possesses diﬀerent solutions (see Example 1.22). In order to con-
struct a non-Markov solution of (3.6), we start a solution at x0 ̸= 0. When
it ﬁrst reaches zero, we hold it at zero for a time period that depends on
the past of the path and then restart it from zero in a nontrivial way. This
way of constructing non-Markov solutions is well known (see [14], [15], or [26,
p. 79]). Actually, the same procedure can be performed with the SDE
dXt = I(Xt ̸= 0)dBt,
X0 = 0.
(3.7)
It is important for both examples (3.6) and (3.7) that σ vanishes at zero. On
the other hand, in Example 3.10, σ ≡1.
3.5 The Branch Points: Strong Markov Solutions
Throughout this section, we assume that (3.1) is true.
Let us ﬁrst consider the case, where zero has type (3,3). Then we know
the structure of all the solutions in the neighbourhood of zero. Indeed, it
follows from Theorem 3.6 that if (Px, Ta,c) is a solution with X0 = x, then
there exists λ ∈[0, 1] such that
Px = Pλ
x =





P−
x
if x ∈[a, 0),
λP−
0 + (1 −λ)P+
0
if x = 0,
P+
x
if x ∈(0, c].
(3.8)
Here P−
x is the unique negative solution deﬁned up to Ta,c; P+
x is the unique
positive solution deﬁned up to Ta,c. Set Pλ
x = Pλ
x ◦Φ−1
Ta,c (Φ is deﬁned
by (B.1)). If λ equals 0 or 1, then (Pλ
x)x∈[a,c] is a strong Markov family
(see Deﬁnition A.25). For λ ∈(0, 1), this family does not have the strong
Markov property. In order to check this, consider the (F+
t )-stopping time
T0+ = inf{t ≥0 : Xt > 0} and the function Ψ(ω) = I(∀t ≥0, ω(t) ≥0).
Thus, we arrive at the following theorem.
Theorem 3.11. Suppose that zero has type (3, 3). For each x ∈[a, c], let
(Px, Ta,c) be a solution with X0 = x. Set Px = Px ◦Φ−1
Ta,c and suppose that
the family (Px)x∈[a,c] has the strong Markov property. Then either Px = P0
x
for any x ∈[a, c] or Px = P1
x for any x ∈[a, c], where P0
x and P1
x are given
by (3.8).
Let us now consider the case, where zero has type (2,3). For x ∈[a, 0],
there exists a unique negative solution P−
x deﬁned up to Ta,c; for x ∈[0, c],
there exists a unique positive solution P+
x deﬁned up to Ta,c. We set
P0
x =

P−
x
if x ∈[a, 0],
P+
x
if x ∈(0, c].
(3.9)

76
3 Two-Sided Classiﬁcation of Isolated Singular Points
For x ∈[a, 0), we deﬁne P1
x as the image of P−
x × P+
0 under the map
C(R+) × C0(R+) ∋(ω1, ω2) −→G(ω1, ω2, T0(ω1)) ∈C(R+),
where G is the gluing function, P−
x = P−
x ◦Φ−1
Ta,c, P+
x = P+
x ◦Φ−1
Ta,c. We set
P1
x =

P1
x|FTa,b
if x ∈[a, 0),
P+
x
if x ∈[0, c].
(3.10)
Using Lemma B.9, one can verify that, for any x ∈[a, c], P0
x and P1
x
are solutions with X0 = x deﬁned up to Ta,c. Moreover, one can check that
both families (P0
x)x∈[a,c], (P1
x)x∈[a,c], where Pλ
x = Pλ
x ◦Φ−1
Ta,c, λ = 1, 2, have
the strong Markov property. However, we will not prove this statement, but
would rather prove the converse statement.
Theorem 3.12. Suppose that zero has type (2, 3). For each x ∈[a, c], let
(Px, Ta,c) be a solution with X0 = x. Set Px = Px ◦Φ−1
Ta,c and suppose that
the family (Px)x∈[a,c] has the strong Markov property. Then either Px = P0
x
for any x ∈[a, c] or Px = P1
x for any x ∈[a, c], where P0
x and P1
x are given
by (3.9) and (3.10), respectively.
Proof. Suppose that P0{T0+ < ∞} > 0. By the strong Markov property, we
have
EP0[I(T0+ < ∞) I(∀t > T0+, Xt > 0)] = P0{T0+ < ∞} P0{∀t > 0, Xt > 0}.
According to Theorem 3.5 (ii), the left-hand side of this equality can be
rewritten as P0{T0+ < ∞}. Thus, P0{∀t > 0, Xt > 0} = 1, which means that
T0+ = 0 P0-a.s. Using the same arguments as in the proof of Theorem 3.3 (ii),
we conclude that Px = P1
x for any x ∈[a, c].
Now, suppose that P0{T0+ < ∞} = 0. This means that the solutions Px
with x ∈[a, 0] are negative. Consequently, Px = P−
x = P0
x for x ∈[a, 0].
If x ∈(0, c], then, by Theorem 2.16 (ii), Px = P+
x = P0
x. This means that
Px = P0
x for any x ∈[a, c].
⊓⊔
We will ﬁnally consider the case, where zero has type (2,2). Let ρ+, s+
denote the functions deﬁned in (2.12), (2.13). Let ρ−, s−be the functions
deﬁned in (3.2), (3.3). For λ ∈(0, 1), we set
sλ(x) =

λs−(x)
if x ∈[a, 0],
(1 −λ)s+(x)
if x ∈[0, c],
mλ(dx) = I(a < x < 0)
λρ−(x)σ2(x)dx +
I(0 < x < c)
(1 −λ)ρ+(x)σ2(x)dx + ∆a(dx) + ∆c(dx),

3.5 The Branch Points: Strong Markov Solutions
77
where ∆a and ∆c denote the inﬁnite masses at the points a and c, respectively.
Take x ∈[a, c], λ ∈[0, 1]. Let B be a Brownian motion started at sλ(x) and
At =

sλ([a,c])
Ly
t (B)mλ ◦(sλ)−1(dy),
τt = inf{s ≥0 : As > t},
Pλ
x = Law

(sλ)−1(Bτt); t ≥0

,
Pλ
x = Pλ
x|FTa,c.
We deﬁne P1
x similarly to (3.10); P0
x is deﬁned in an analogous way.
The measure Pλ
x may informally be described as follows. We start a solu-
tion at the point x, and after each time it reaches zero, it goes in the positive
direction with probability λ and in the negative direction with probability
1 −λ. This can be put on a ﬁrm basis using the excursion theory.
The same arguments as in the proof of Theorem 2.12 allow one to verify
that, for any λ ∈[0, 1] and x ∈[a, c], (Pλ
x, Ta,c) is a solution with X0 = x.
Moreover, one can check that, for any λ ∈[0, 1], the family (Pλ
x)x∈[a,c], where
Pλ
x = Pλ
x ◦Φ−1
Ta,c, has the strong Markov property. However, we will not prove
these statements, but would rather prove the converse statement.
Theorem 3.13. Suppose that zero has type (2, 2). For each x ∈[a, c], let
(Px, Ta,c) be a solution with X0 = x. Set Px = Px ◦Φ−1
Ta,c and suppose that the
family (Px)x∈[a,c] has the strong Markov property. Then there exists λ ∈[0, 1]
such that Px = Pλ
x for any x ∈[a, c].
Proof. Suppose ﬁrst that T0−= ∞P0-a.s. Then, by the strong Markov prop-
erty, X ≥0 on [[T0, Ta,c]] Px-a.s. for any x ∈[a, c]. Using the same arguments
as in the proof of Theorem 3.3 (ii), we conclude that Px = P1
x for any x ∈[a, c].
Similarly, we deduce that if T0+ = ∞P0-a.s., then Px = P0
x for any
x ∈[a, c].
Now, suppose that P0{T0−< ∞} > 0, P0{T0+ < ∞} > 0. We
will prove that the family (Px)x∈[a,c] is regular in this case (see Deﬁni-
tion A.26). Condition (a) of Deﬁnition A.26 is obviously satisﬁed, and we
should check only (b). We will verify this condition for x ∈(0, c), y = a.
Let P+
x denote the positive solution with X0 = x deﬁned up to Ta,c. In
view of Theorem 2.11, Px|FTδ,c = P+
x |FTδ,c for any δ ∈(0, c). Consequently,
Px|FT0,c = P+
x |FT0,c. It follows from Theorem 2.12 that P+
x {T0 < Tc} > 0.
Therefore, Px{T0 < ∞} > 0. Since P0{T0−< ∞} > 0, there exists d ∈[a, 0)
such that P0{Td < ∞} > 0. Furthermore, Pd{Ta < ∞} > 0. Using the strong
Markov property at times T0 and Td, we get Px{Ty < ∞} > 0. Thus, the
family (Px)x∈[a,c] is regular.
Let s and m denote the scale function and the speed measure of (Px)x∈[a,c]
(see Deﬁnitions A.28, A.30). We can assume that s(0) = 0. For x ∈[0, c],

78
3 Two-Sided Classiﬁcation of Isolated Singular Points
deﬁne Qx as the image of Px under the map ω →ωT0,c(ω). Then (Qx)x∈[0,c] is
a regular strong Markov family whose scale function is given by the restriction
of s to [0, c] and whose speed measure is the restriction of m to (0, c). On
the other hand, Px|FT0,c is a solution up to T0,c, and hence, Qx|FT0,c = P+
x .
Since XT0,c = X Qx-a.s., we get Qx = P+
x . The measure P+
x is obtained from
the Wiener measure by a time-change and a space transformation (see the
proof of Theorem 2.11). The explicit form of the time-change and the space
transformation allows us to conclude (see [28, Th. 20.9]) that (P+
x )x∈[0,c] is
a regular strong Markov family with the scale function s+(x) and the speed
measure
m+(dx) = I(0 < x < c)
ρ(x)σ2(x) dx.
The scale function is deﬁned up to an aﬃne transformation (see Proposi-
tion A.27). Therefore, there exists λ+ > 0 such that
s(x) = λ+s+(x),
x ∈[0, c],
m|(0,c)(dx) = I(0 < x < c)
λ+ρ(x)σ2(x)dx.
Similarly, we prove that there exists λ−> 0 such that
s(x) = λ−s−(x),
x ∈[a, 0],
m|(a,0)(dx) = I(a < x < 0)
λ−ρ(x) σ2(x)dx.
We have
 Ta,c
0
I(Xs = 0)ds =
 Ta,c
0
I(Xs = 0)
σ2(0)
d⟨X⟩s
=

R
I(x = 0)
σ2(0)
Lx
Ta,c(X)dx = 0
P0-a.s.
Consequently, m{0} = 0. We arrive at the equalities
s(x) = λ sλ(x),
m(dx) = 1
λmλ(dx),
where λ =
λ−
λ++λ−. Thus, (Px)x∈[a,c] is a regular process whose scale function
and speed measure can be chosen equal to sλ and mλ. It follows from Propo-
sition A.31 that Px = Pλ
x for any x ∈[a, c].
⊓⊔

3.5 The Branch Points: Strong Markov Solutions
79
-
-
-
6
6
6
t
t
t












3
3
2
3
2
2
Fig. 3.3. Behaviour of strong Markov solutions for various types of the branch
points. The graphs show simulated paths of solutions with diﬀerent starting points.
The top graph corresponds to the case, where zero has type (2,2). It represents
a path of the solution Pλ with λ = 0.7. The centre graph and the bottom graph
correspond to the cases, where zero has types (2,3) and (3,3), respectively. These
graphs represent paths of the solution P1.

4 Classiﬁcation at Inﬁnity
and Global Solutions
A classiﬁcation similar to that given in Chapter 2 can be performed at +∞.
This is the topic of Sections 4.1–4.3.
The results of Chapters 2, 3 apply to local solutions, i.e., solutions up to
a random time. In Sections 4.4, 4.5, we study the existence and uniqueness of
a global solution, i.e., a solution in the sense of Deﬁnition 1.28. This is done
for the SDEs that have no more than one singular point.
Throughout this chapter, we assume that σ(x) ̸= 0 for all x ∈R.
4.1 Classiﬁcation at Inﬁnity: The Results
Throughout this section, we assume that
1 + |b|
σ2
∈L1
loc([a, ∞))
(4.1)
for some a ∈R.
We will use the functions
ρ(x) = exp

−
 x
a
2b(y)
σ2(y)dy

,
x ∈[a, ∞),
(4.2)
s(x) = −
 ∞
x
ρ(y)dy,
x ∈[a, ∞)
(4.3)
and the notation
T ∞= lim
n→∞Tn,
T a,∞= T a ∧T ∞.
Theorem 4.1. Suppose that
 ∞
a
ρ(x)dx = ∞.
If x0 ∈[a, ∞), then there exists a unique solution P deﬁned up to Ta. We
have Ta < ∞P-a.s.
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 81–91, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

82
4 Classiﬁcation at Inﬁnity and Global Solutions
If the conditions of Theorem 4.1 are satisﬁed, we will say that +∞has
type A.
Theorem 4.2. Suppose that
 ∞
a
ρ(x)dx < ∞,
 ∞
a
|s(x)|
ρ(x)σ2(x)dx = ∞.
If x0 ∈[a, ∞), then there exists a unique solution P deﬁned up to Ta. If
moreover x0 > a, then P{Ta = ∞} > 0 and limt→∞Xt = +∞P-a.s. on
{Ta = ∞}.
If the conditions of Theorem 4.2 are satisﬁed, we will say that +∞has
type B.
Theorem 4.3. Suppose that
 ∞
a
ρ(x)dx < ∞,
 ∞
a
|s(x)|
ρ(x)σ2(x)dx < ∞.
If x0 ∈(a, ∞), then there exists a unique solution P deﬁned up to T a,∞−.
We have P{T ∞< ∞} > 0. (In other words, the solution explodes into +∞
with strictly positive probability.)
If the conditions of Theorem 4.3 are satisﬁed, we will say that +∞has
type C.
As a consequence of the above results, we obtain Feller’s criterion for
explosions (see [16], [29, Ch. 5, Th. 5.29], or [34, § 3.6]).
Corollary 4.4. Suppose that x0 ∈(a, ∞) and P is a solution deﬁned up
to T a,∞−. Then it explodes into +∞with strictly positive probability (i.e.,
P{T ∞< ∞} > 0) if and only if
 ∞
a
ρ(x)dx < ∞,
 ∞
a
|s(x)|
ρ(x)σ2(x)dx < ∞.
4.2 Classiﬁcation at Inﬁnity: Informal Description
If +∞has type A, then a solution cannot explode into +∞. Moreover, a
solution is recurrent in the following sense. If there are no singular points
between the starting point x0 and a point a < x0, then the solution reaches
the level a a.s. An example of a SDE, for which +∞has type A, is provided
by the equation
dXt = dBt,
X0 = x0.
If +∞has type B, then there is no explosion into +∞and a solution
tends to +∞with strictly positive probability. In other words, a solution is
transient. For the SDE

4.2 Classiﬁcation at Inﬁnity: Informal Description
83
σ ̸= 0,
1 + |b|
σ2
∈L1
loc([a, ∞))







A
A
A
A
A
A
AAU
 ∞
a
ρ = ∞
Am
 ∞
a
ρ < ∞



@
@
@@
R
 ∞
a
|s|
ρσ2 = ∞
Bm
 ∞
a
|s|
ρσ2 < ∞
Cm
6
-
x
a
s(x)
Type
Behaviour
A
recurrent
B
transient
C
explosion
ρ(x) = exp

−
 x
a
2b(y)
σ2(y)dy

,
s(x) = −
 ∞
x
ρ(y)dy
Fig. 4.1. Classiﬁcation at inﬁnity
dXt = µdt + σdBt,
X0 = x0
with µ > 0, +∞has type B (this follows from Theorem 5.5).
If +∞has type C, then a solution explodes into +∞(i.e., it reaches
+∞within a ﬁnite time) with strictly positive probability. A corresponding
example is provided by the equation
dXt = ε|Xt|1+εdt + dBt,
X0 = x0
with ε > 0 (this follows from Theorem 5.5).

84
4 Classiﬁcation at Inﬁnity and Global Solutions
-
-
-
6
6
6
t
t
t
m
C
m
B
m
A
Fig. 4.2. Behaviour of solutions for various types of inﬁnity. The graphs show
simulated paths of solutions.

4.3 Classiﬁcation at Inﬁnity: The Proofs
85
4.3 Classiﬁcation at Inﬁnity: The Proofs
Proof of Theorem 4.1. Existence. Consider the function
r(x) =
 x
a
ρ(y)dy,
x ∈[a, ∞).
Let B be a (Gt)-Brownian motion started at r(x0) on a ﬁltered probability
space

Ω, G, (Gt), Q

. Let us consider
κ(y) = ρ(r−1(y))σ(r−1(y)),
y ∈[0, ∞),
At =



 t
0
κ−2(Bs)ds
if t < T0(B),
∞
if t ≥T0(B),
τt = inf{s ≥0 : As > t},
Yt = Bτt,
t ≥0.
Arguing in the same way as in the proof of Theorem 2.11, we check that
AT0(B)−= T0(Y ) < ∞Q-a.s. Set Z = s−1(Y ). The estimates used in (2.23)
show that, for any c > x0,
EQ
 Ta,c(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞.
(4.4)
Furthermore, Ta(Z) = T0(Y ) < ∞Q-a.s. Letting c →+∞in (4.4), we get
 Ta(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞
Q-a.s.
(4.5)
The proof of existence is now completed in the same way as in Theorem 2.11.
Uniqueness. Uniqueness follows from Lemma B.6 applied to the stopping
times Ta,n.
The property Ta < ∞P-a.s. is a consequence of (4.5).
2
Proof of Theorem 4.2. Existence. Let B be a (Gt)-Brownian motion started
at s(x0) on a ﬁltered probability space

Ω, G, (Gt), Q

. Let us consider
κ(y) = ρ(s−1(y))σ(s−1(y)),
y ∈[α, 0),
At =



 t
0
κ−2(Bs)ds
if t < Tα,0(B),
∞
if t ≥Tα,0(B),
τt = inf{s ≥0 : As > t},
Yt = Bτt,
t ≥0,

86
4 Classiﬁcation at Inﬁnity and Global Solutions
where α = s(a). With the same arguments as in the proof of Theorem 2.11
we check that ATα,0(B)−= Tα,0(Y ) Q-a.s. Furthermore, for any ε > 0,
 0
−ε
|y|
κ2(y)dy =
 ∞
s−1(−ε)
|s(x)|
ρ(x)σ2(x)dx = ∞.
By Corollary A.24, ATα,0(B)−is Q-a.s. inﬁnite on the set {T0(B) < Tα(B)}.
Hence, T0(Y ) = ∞Q-a.s. Thus, the process Z = s−1(Y ) is correctly deﬁned.
The arguments used in (2.23) show that, for any c > x0,
EQ
 Ta,c(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞.
By letting c →+∞, we get, for any t ≥0,
 t∧Ta(Z)
0

1 + |b(Zt)| + σ2(Zt)

dt < ∞
Q-a.s.
The proof of existence is now completed in the same way as in Theorem 2.11.
Uniqueness. The uniqueness of a solution follows from Lemma B.6 applied
to the stopping times Ta,n.
The properties P{Ta = ∞} > 0 and limt→∞Xt = +∞P-a.s. on
{Ta = ∞} follow from the properties that Q{T0(B) < Tα(B)} > 0, and on
the set {T0(B) < Tα(B)} we have Yt
Q-a.s.
−−−→
t→∞0.
2
Proof of Theorem 4.3. The proof is similar to the proof of Theorem 2.14. 2
4.4 Global Solutions: The Results
Throughout this section, we consider global solutions, i.e., solutions in the
sense of Deﬁnition 1.28.
Theorem 4.5. Suppose that SDE (1) has no singular points, i.e.,
1 + |b|
σ2
∈L1
loc(R).
(i) If −∞and +∞have types A or B, then there exists a unique solu-
tion P. For any point a ∈R, we have P{Ta < ∞} > 0.
(ii) If −∞or +∞has type C, then there exists no solution.
Theorem 4.6. Suppose that zero is the unique singular point for (1). Let
x0 > 0.
(i) If +∞has type C, then there exists no solution.

4.4 Global Solutions: The Results
87
(ii) If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 0, 1 (we exclude the
case i = j = 0), then there exists no solution.
(iii) If zero has type (i, j) with i = 2, 3, j = 0, 1, −∞has type A or B,
and +∞has type A or B, then there exists a unique solution P. We have
P{T0 < ∞} > 0 and X ≤0 on [[T0, ∞[[ P-a.s.
(iv) If zero has type (i, j) with i = 2, 3, j = 0, 1 and −∞has type C, then
there exists no solution.
(v) If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 2 and +∞has type A
or B, then there exists a unique solution P. It is positive and P{T0 < ∞} > 0.
(vi) If zero has type (i, j) with i = 2, 3, j = 2, −∞has type A or B, and
+∞has type A or B, then there exist diﬀerent solutions.
(vii) If zero has type (i, j) with i = 2, 3, j = 2, −∞has type C, and
+∞has type A or B, then there exists a unique solution P. It is positive and
P{T0 < ∞} > 0.
(viii) If zero has type (i, j) with j = 3, 4, 5 and +∞has type A or B, then
there exists a unique solution. It is strictly positive.
(ix) If zero has type (i, j) with j = 6, then there exists no solution.
Theorem 4.7. Suppose that zero is the unique singular point for (1). Let
x0 = 0.
(i) If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 0, 1, 4, 5, 6 (we exclude
the case i = j = 0), then there exists no solution.
(ii) If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 2, 3 and +∞has type A
or B, then there exists a unique solution. It is positive.
(iii) If zero has type (i, j) with i = 0, 1, 4, 5, 6, j = 2, 3 and +∞has
type C, then there exists no solution.
(iv) If zero has type (i, j) with i = 2, 3, j = 0, 1, 4, 5, 6 and −∞has type A
or B, then there exists a unique solution. It is negative.
(v) If zero has type (i, j) with i = 2, 3, j = 0, 1, 4, 5, 6 and −∞has type C,
then there exists no solution.
(vi) If zero has type (i, j) with i = 2, 3, j = 2, 3, −∞has type A or B,
and +∞has type A or B, then there exist diﬀerent solutions.
(vii) If zero has type (i, j) with i = 2, 3, j = 2, 3, −∞has type A or B,
and +∞has type C, then there exists a unique solution. It is negative.
(viii) If zero has type (i, j) with i = 2, 3, j = 2, 3, −∞has type C, and
+∞has type A or B, then there exists a unique solution. It is positive.
(ix) If zero has type (i, j) with i = 2, 3, j = 2, 3, −∞has type C, and
+∞has type C, then there exists no solution.
Remark. Theorems 4.6, 4.7 reveal an interesting eﬀect. It may happen that
a branch point does not disturb the uniqueness of a global solution. (As we
have seen in Chapter 3, a branch point always disturbs the uniqueness of
a local solution.) The explanation of this eﬀect is as follows. Suppose, for
example, that zero is a branch point, −∞has type C, +∞has type A or
B, and x0 ≥0. If a solution becomes strictly negative with strictly positive

88
4 Classiﬁcation at Inﬁnity and Global Solutions
Table 4.1. Existence and uniqueness in the case with no singular points. As an
example, line 2 corresponds to the situation, where −∞has type C and there are
no restrictions on the type of +∞. The table shows that in this case there exists
no solution because there is an explosion into −∞.
Type
of −∞
Type
of +∞
Exis-
tence
Uniq-
ness
Comments
A B
A B
+
+
solution can reach any point
C
−
+
explosion into −∞
C
−
+
explosion into +∞
probability, then it explodes into −∞with strictly positive probability, and
hence, it is not a global solution. Thus, any global solution should be positive.
But there exists a unique positive solution.
4.5 Global Solutions: The Proofs
Proof of Theorem 4.5. (i) This statement is proved similarly to Theorems 4.1,
4.2.
(ii) Without loss of generality, we may assume that +∞has type C.
Suppose that there exists a solution P. Fix a < x0. Let Q be the solution
deﬁned up to T a,∞−(it is provided by Theorem 4.3). Then Q{T ∞< ∞} > 0.
Hence, there exist t > 0 and c > a such that Q{T ∞< t ∧Tc} = θ > 0. Then,
for any n > c, we have Q{Tn < t ∧Tc} ≥θ. The set {Tn < t ∧Tc} belongs to
FTc,n, and Q|FTc,n is a solution up to Tc,n. It follows from the uniqueness of a
solution that, for any n > c, P{Tn < t∧Tc} ≥θ. But this is a contradiction. 2
Proof of Theorem 4.6. (i) The proof is similar to the proof of Theorem 4.5 (ii).
(ii) Suppose that there exists a solution P. Fix a > x0. Then P|FT0,a
is a solution up to T0,a. It follows from the results of Section 2.3 that
P{T0,a < ∞and XT0,a = 0} > 0. Hence, P{T0 < ∞} > 0. But this contra-
dicts Theorem 3.2.
(iii) Existence. The results of Section 2.3 ensure that there exists a so-
lution R0 with X0 = 0 deﬁned up to T−1. Employing similar arguments as
in the proofs of Theorems 2.12 and 2.16 (ii), we construct a solution R−1
with X0 = −1 deﬁned up to ∞. Let R′
−1 be the image of R−1 under the map
ω →ω + 1. We consider R′
−1 as a measure on C0(R+). Set R0 = R0 ◦Φ−1
T−1
(Φ is deﬁned by (B.1)). Let Q0 be the image of R0 × R′
−1 under the map

4.5 Global Solutions: The Proofs
89
Table 4.2. Existence and uniqueness in the case, where zero is the unique singular
point. The starting point is greater than zero.
Left
type
of zero
Right
type
of zero
Type
of −∞
Type
of +∞
Exis-
tence
Uniq-
ness
Comments
C
−
+
explosion into +∞
0 1 4 5 6
0 1
−
+
killing at zero
2 3
0 1
A B
A B
+
+
passing through zero
2 3
0 1
C
−
+
explosion into −∞
0 1 4 5 6
2
A B
+
+
reﬂection at zero
2 3
2
A B
A B
+
−
branching at zero
2 3
2
C
A B
+
+
reﬂection at zero
3 4 5
A B
+
+
solution is strictly positive
6
−
+
killing at zero
Table 4.3. Existence and uniqueness in the case, where zero is the unique singular
point. The starting point is equal to zero.
Left
type
of zero
Right
type
of zero
Type
of −∞
Type
of +∞
Exis-
tence
Uniq-
ness
Comments
0 1 4 5 6 0 1 4 5 6
−
+
killing at zero
0 1 4 5 6
2 3
A B
+
+
solution is positive
0 1 4 5 6
2 3
C
−
+
explosion into +∞
2 3
0 1 4 5 6
A B
+
+
solution is negative
2 3
0 1 4 5 6
C
−
+
explosion into −∞
2 3
2 3
A B
A B
+
−
branching at zero
2 3
2 3
A B
C
+
+
solution is negative
2 3
2 3
C
A B
+
+
solution is positive
2 3
2 3
C
C
−
+
explosion into −∞or +∞

90
4 Classiﬁcation at Inﬁnity and Global Solutions
C(R+) × C0(R+) ∋(ω1, ω2) −→G(ω1, ω2, T−1(ω1)) ∈C(R+).
Using Lemma B.9, one can verify that Q0 is a solution of (1) with X0 = 0.
Arguing in the same way as in the proofs of Theorems 4.1, 4.2, we deduce
that there exists a solution Q with X0 = x0 deﬁned up to T0. For this solution,
Q{T0 < ∞} > 0. Set Q = Q◦Φ−1
T0 (Φ is deﬁned by (B.1)). Let P be the image
of Q × Q0 under the map
C(R+) × C0(R+) ∋(ω1, ω2) −→G(ω1, ω2, T0(ω1)) ∈C(R+).
Using Lemma B.9, one can verify that P is a solution of (1).
Uniqueness. The uniqueness of a solution follows from Theorem 3.3 (ii)
and Lemma B.6 applied to the stopping times T−n,n.
The properties P{T0 < ∞} > 0 and X ≤0 on [[T0, ∞[[ P-a.s. follow from
the construction of the solution.
(iv) Suppose that there exists a solution P. For any a > x0, P|FT0,a is
a solution up to T0,a. Applying the results of Section 2.3, we conclude that
P{T0 < ∞} > 0. Set P′ = P( · | T0 < ∞), P0 = P′ ◦Θ−1
T0 , where Θ is deﬁned
by (B.2). By Lemma B.7, P0 is a solution of (1) with X0 = 0. Thus, P0|FT−1,1
is a solution with X0 = 0 up to T−1,1. Applying Theorem 3.3 (i), we deduce
that X ≤0 on [[0, T−1]] P0-a.s. Moreover, P0{∀t ≥T0, Xt = 0} = 0 (see the
proof of Theorem 3.2). Therefore, there exists c < 0 such that P0{Tc < ∞} >
c. Consider P′
0 = P0( · | Tc < ∞), P′
c = P′
0 ◦Θ−1
Tc . By Lemma B.7, P′
c is a
solution of (1) with X0 = c. But this contradicts point (i) of this theorem.
(v) Existence. Using similar arguments as in the proof of Theorem 2.12,
we conclude that there exists a positive solution P.
Uniqueness. Suppose that there exists another solution P′. Then, for any
n > x0, P′|FTn is a solution up to Tn. It follows from the results of Section 2.3
that P′|FTn is positive. Due to Theorem 2.12, P′|FTn = P|FTn. Lemma B.6
yields that P′ = P.
The property P{T0 < ∞} > 0 follows from Theorem 2.12.
(vi) Similar arguments as in the proof of Theorem 2.12 allow us to deduce
that there exists a positive solution P.
Arguing in the same way as in the proof of point (iii) above, we construct
a solution P′ such that P′{T0 < ∞} > 0 and X ≤0 on [[T0, ∞[[ P′-a.s.
Moreover, P′{∀t ≥T0, Xt = 0} = 0 (see the proof of Theorem 3.2). Hence,
P′ is not positive, and therefore, P and P′ are two diﬀerent solutions.
(vii) Existence. Using similar arguments as in the proof of Theorem 2.12,
we deduce that there exists a positive solution P.
Uniqueness. Suppose that there exists another solution P′. Assume ﬁrst
that it is not positive. Then there exists c < 0 such that P{Tc < ∞} > 0. Set
P′ = P( · | Tc < ∞), Pc = P′ ◦Θ−1
Tc . By Lemma B.7, Pc is a solution of (1)
with X0 = c. But this contradicts point (i) of this theorem.

4.5 Global Solutions: The Proofs
91
Assume now that P′ is positive. By Theorem 2.12, for any n > x0,
P′|FTn = P|FTn. Lemma B.6 yields that P′ = P.
The property P{T0 < ∞} > 0 follows from Theorem 2.12.
(viii) Existence. Using the same arguments as in the proofs of Theo-
rems 2.15–2.17, we deduce that there exists a strictly positive solution P.
Uniqueness. Suppose that there exists another solution P′. It follows
from the results of Section 2.3 that, for any n > x0, P′|FTn = P|FTn. By
Lemma B.6, P′ = P.
(ix) This statement follows from Theorem 2.14.
2
Proof of Theorem 4.7. (i) This statement follows from Theorem 3.2.
(ii) This statement is proved in the same way as Theorem 4.6 (v).
(iii) Suppose that there exists a solution P. It follows from the results
of Section 2.3 that P is positive. Moreover, P{∀t ≥0, Xt = 0} = 0 (see the
proof of Theorem 3.2). Hence, there exists a > 0 such that P{Ta < ∞} > 0.
Set P′ = P( · | Ta < ∞), Pa = P′ ◦Θ−1
Ta . By Lemma B.7, Pa is a solution
of (1) with X0 = a. But this contradicts Theorem 4.6 (i).
(vi) Using similar arguments as in Section 2.5, one can construct both a
positive solution and a negative solution.
(vii) This statement is proved in the same way as Theorem 4.6 (vii).
(ix) The proof of this statement is similar to the proof of point (iii).
2

5 Several Special Cases
In Section 5.1, we consider SDEs, for which the coeﬃcients b and σ are
power functions in the right-hand neighbourhood of zero or are equivalent to
power functions as x ↓0. For these SDEs, we propose a simple procedure to
determine the right type of zero.
Section 5.2 contains similar results for the types of inﬁnity.
In Section 5.3, we investigate which types of isolated singular points are
possible if the drift coeﬃcient is positive or negative.
Section 5.4 contains similar results for the types of inﬁnity.
5.1 Power Equations: Types of Zero
Theorem 5.1. Suppose that there exists a > 0 such that
b(x) = µxα,
σ(x) = νxβ,
x ∈(0, a],
(5.1)
where µ, ν, α, β ∈R and ν ̸= 0. Set λ = µ/ν2, γ = α −2β. Then the right
type of zero for (1) is given by Figure 5.1.
Proof. If µ = 0, then the equation is investigated in a trivial way. Suppose
that µ ̸= 0. The function ρ that appears in (2.12) is equal to the following
function up to multiplication by a constant
ρ(x) =



exp

−2λ
γ + 1xγ+1
if γ ̸= −1,
x−2λ
if γ = −1.
Hence, the function s that appears in (2.13) coincides with the following
function up to multiplication by a constant
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 93–103, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

94
5 Several Special Cases
-
6
λ
β
1/2
1
γ > −1
l
0
l
1
l
4
-
6
λ
β
1/2
1
1−γ
2
γ < −1
q
q
l
0
l
3
l
5
l
1
l
4
-
6
λ
β
1/2
1/2
1
γ = −1




q
q
l
0
l
3
l
5
l
1
l
4
l
2
j
Fig. 5.1. The one-sided classiﬁcation for power equations. Here λ = µ/ν2,
γ = α −2β, where α, β, µ, and ν are given by (5.1). One should ﬁrst calculate
γ and select the corresponding graph (out of the three graphs shown). Then one
should plot the point (λ, β) in this graph and ﬁnd the part of the graph the point
lies in. The number i marked in this part indicates that zero has right type i. As
an example, if γ < −1, λ > 0, and β ≥(1 −γ)/2, then zero has right type 5.

5.1 Power Equations: Types of Zero
95
s(x) =

































 x
0
exp

−2λ
γ + 1yγ+1
dy
if γ < −1, λ < 0,
 a
x
exp

−2λ
γ + 1yγ+1
dy
if γ < −1, λ > 0,
x−2λ+1
if γ = −1, λ < 1/2,
ln x −ln a
if γ = −1, λ = 1/2,
−x−2λ+1 + a−2λ+1
if γ = −1, λ > 1/2,
 x
0
exp

−2λ
γ + 1yγ+1
dy
if γ > −1.
The integrability conditions in the formulations of Theorems 2.11–2.17 re-
main unchanged when ρ and s are replaced by ρ and s.
Suppose that γ > −1. In this case ρ(x) −−→
x↓0 1 and s(x)/x −−→
x↓0 1. Now,
it is easy to verify that, for β < 1/2, zero has right type 0; for 1/2 ≤β < 1,
zero has right type 1; for β ≥1, zero has right type 4.
In a similar way, one investigates the cases γ = −1 and γ < −1. The
only nontrivial problem is to ﬁnd the asymptotic behaviour (as x ↓0) of the
function |s(x)|/ρ(x) for γ < −1, µ ̸= 0. This is done with the help of the
following lemma.
⊓⊔
Lemma 5.2. Let γ < −1 and µ ̸= 0. Then there exist constants 0 < c1 < c2
and δ > 0 such that
c1x−γ ≤|s(x)|
ρ(x) ≤c2x−γ,
x ∈(0, δ).
Proof. We will give the proof only for the case, where µ < 0 (the case µ > 0
is considered similarly). If µ < 0, then
	 a
0 ρ(x)dx < ∞and s(x) ≥0 on (0, a].
It follows from (2.12) that ρ′(x) = −2λxγρ(x) for x ∈(0, a), and therefore,
ρ(x) = −2λ
 x
0
yγρ(y)dy = 2|λ|
 x
0
yγρ(y)dy,
x ∈(0, a).
(5.2)
There exists δ′ ∈(0, a) such that
2λ
γ + 1
x
2
γ+1
>
2λ
γ + 1xγ+1 + ln 2γ,
x ∈(0, δ′).
Then ρ(x/2) < 2γρ(x) for x ∈(0, δ′), and therefore,
 x/2
0
yγρ(y)dy = 2−γ−1
 x
0
yγρ(y/2)dy < 1
2
 x
0
yγρ(y)dy,
x ∈(0, δ′).
Consequently,
 x
x/2
yγρ(y)dy > 1
2
 x
0
yγρ(y)dy

96
5 Several Special Cases
and, using (5.2), we get
2|λ|
 x
x/2
yγρ(y)dy < ρ(x) < 4|λ|
 x
x/2
yγρ(y)dy,
x ∈(0, δ′).
Thus, there exist constants 0 < c′
1 < c′
2 such that
c′
1xγ
 x
x/2
ρ(y)dy < ρ(x) < c′
2xγ
 x
x/2
ρ(y)dy,
x ∈(0, δ′).
(5.3)
In a similar way we prove that there exist constants 0 < c′′
1 < c′′
2 and δ′′ > 0
such that
c′′
1
 x
x/2
ρ(y)dy < s(x) < c′′
2
 x
x/2
ρ(y)dy,
x ∈(0, δ′′).
(5.4)
Combining (5.3) and (5.4), we get the desired statement.
⊓⊔
Theorem 5.3. Suppose that
b(x)
µxα −−→
x↓0 1,
σ(x)
νxβ −−→
x↓0 1,
where µ, ν, α, β are such that µ ̸= 0, ν ̸= 0, and α −2β ̸= −1. Set λ = µ/ν2,
γ = α −2β. Then the right type of zero for (1) is given by Figure 5.1.
This statement is proved similarly to Theorem 5.1.
The following example shows that the condition α−2β ̸= −1 in the above
theorem is essential.
Example 5.4. If
b(x) = 1
2x,
σ(x) = 1,
x ∈(0, a]
for some a > 0, then zero has right type 3.
If
b(x) = 1
2x +
1
x ln x,
σ(x) = 1,
x ∈(0, a]
for some a ∈(0, 1), then zero has right type 2.
Proof. The ﬁrst statement follows from Theorem 5.1.
In order to prove the second statement, it is suﬃcient to note that
 a
x
2b(y)
σ2(y)dy = −ln x −2 ln | ln x| + const,
x ∈(0, a].
Thus, the function ρ coincides on (0, a] with the function ρ(x) = 1/(x ln2 x) up
to multiplication by a constant. This implies that the function s(x) coincides
on (0, a] with the function s(x) = −1/ ln x up to multiplication by a constant.
The proof is now completed in a trivial way.
⊓⊔

5.2 Power Equations: Types of Inﬁnity
97
5.2 Power Equations: Types of Inﬁnity
Theorem 5.5. Suppose that there exists a > 0 such that
b(x) = µxα,
σ(x) = νxβ,
x ∈[a, ∞),
(5.5)
where µ, ν, α β ∈R and ν ̸= 0. Set λ = µ/ν2, γ = α −2β. Then the type of
+∞for (1) is given by Figure 5.2.
Proof. If µ = 0, then the equation is investigated in a trivial way. Suppose
that µ ̸= 0. The function ρ that appears in (4.2) is equal to the following
function up to multiplication by a constant
ρ(x) =



exp

−2λ
γ + 1xγ+1
if γ ̸= −1,
x−2λ
if γ = −1.
Hence, the function s that appears in (4.3) coincides with the following func-
tion up to multiplication by a constant
s(x) =









 ∞
x
exp

−2λ
γ + 1yγ+1
dy
if γ ̸= −1,
x−2λ+1
if γ = −1, λ > 1/2,
∞
if γ = −1, λ ≤1/2.
The integrability conditions in the formulations of Theorems 4.1–4.3 remain
unchanged when ρ and s are replaced by ρ and s.
Suppose that γ < −1. In this case ρ(x) −−−−→
x→∞1. It is easy to verify that
+∞has type A.
In a similar way, one investigates the cases γ = −1 and γ > −1. The only
nontrivial problem is to ﬁnd the asymptotic behaviour (as x →∞) of the
function |s(x)|/ρ(x) for γ > −1, µ > 0. This is done with the help of the
following lemma.
⊓⊔
Lemma 5.6. Let γ > −1 and µ > 0. Then there exist constants 0 < c1 < c2
and δ > 1 such that
c1x−γ ≤|s(x)|
ρ(x) ≤c2x−γ,
x ∈(δ, ∞).
The proof is similar to the proof of Lemma 5.2.
Theorem 5.7. Suppose that
b(x)
µxα −−−−→
x→∞1,
σ(x)
νxβ −−−−→
x→∞1,
where µ, ν, α, β are such that µ ̸= 0, ν ̸= 0, and α −2β ̸= −1. Set λ = µ/ν2,
γ = α −2β. Then the type of +∞for (1) is given by Figure 5.2.

98
5 Several Special Cases
-
6
1−γ
2
λ
β
γ > −1
l
A
l
C
l
B
-
6
λ
β
γ < −1
l
A
-
6
λ
β
1/2
1
γ = −1
l
A
l
C
l
B
j
Fig. 5.2. The classiﬁcation at inﬁnity for power equations. Here λ = µ/ν2,
γ = α −2β, where α, β, µ, and ν are given by (5.5). One should ﬁrst calculate
γ and select the corresponding graph (out of the three graphs shown). Then one
should plot the point (λ, β) in this graph and ﬁnd the part of the graph the point
lies in. The letter
ΛΛΛ
marked in this part indicates that +∞has type Λ. As an
example, if γ > −1, λ > 0, and β > (1 −γ)/2, then +∞has type D.

5.3 Equations with a Constant-Sign Drift: Types of Zero
99
This statement is proved similarly to Theorem 5.5.
The following example shows that the condition α−2β ̸= −1 in the above
theorem is essential.
Example 5.8. If
b(x) = x
2 ,
σ(x) = x,
x ∈(a, ∞)
for some a > 0, then +∞has type A.
If
b(x) = x
2 +
x
2 ln x,
σ(x) = x,
x ∈(a, ∞)
for some a > 1, then +∞has type B.
The proof is similar to the proof of Example 5.4.
5.3 Equations with a Constant-Sign Drift: Types of Zero
Throughout this section, we assume that (2.11) is true.
Theorem 5.9. Let σ2 = 1 and b ≥0 on (0, a]. Then zero can only have right
type 0, 2, or 3.
Proof. The condition b ≥0 means that ρ decreases on (0, a]. Suppose that
 a
0
ρ(x)dx < ∞.
(5.6)
Since 1/ρ is bounded on (0, a], we have
 a
0
1
ρ(x)σ2(x)dx =
 a
0
1
ρ(x)dx < ∞.
Furthermore,
 a
0
2|b(x)|
ρ(x)σ2(x)dx = −
 a
0
ρ′(x)
ρ2(x)dx =
 ρ(0)
ρ(a)
1
y2 dy < ∞.
So, if (5.6) holds, then zero has right type 0 or 2.
Suppose now that (5.6) is violated. Then
|s(x)| =
 a
x
ρ(y)dy ≤aρ(x),
x ∈(0, a].
(5.7)
Consequently,
 a
0
|s(x)|
ρ(x)σ2(x)dx =
 a
0
|s(x)|
ρ(x) dx < ∞.

100
5 Several Special Cases
Combining (5.7) with (2.16), we arrive at
 a
0
b(x)|s(x)|
ρ(x)σ2(x)dx < ∞.
Thus, zero has right type 3.
⊓⊔
Theorem 5.10. Let σ2 = 1 and b ≤0 on (0, a]. Then zero can only have
right type 0 or 1.
Proof. The condition b ≤0 means that ρ increases on (0, a]. Hence, (5.6)
holds true.
Suppose that ρ(0+) > 0. Then, by (2.12),
 a
0
|b(x)|
σ2(x)dx < ∞.
Thus, zero has right type 0.
Suppose now that ρ(0+) = 0. Then
 a
0
2|b(x)|
ρ(x)σ2(x)dx = −
 a
0
2b(x)
ρ(x)σ2(x)dx
=
 a
0
ρ′(x)
ρ2(x)dx =
 ρ(a)
0
1
y2 dy = ∞.
Furthermore,
s(x) =
 x
0
ρ(y)dy ≤xρ(x),
x ∈(0, a],
(5.8)
and consequently,
 a
0
s(x)
ρ(x)σ2(x)dx =
 a
0
s(x)
ρ(x)dx < ∞.
Moreover, by (5.8) and (2.16),
 a
0
|b(x)|s(x)
ρ(x)σ2(x)dx < ∞.
(5.9)
Thus, zero has right type 1.
⊓⊔
Theorem 5.11. Let b ≥0 on (0, a]. Then zero can only have right type 0,
1, 2, 3, 4, or 5.
Proof. Assume that zero has right type 6. Then (5.6) holds. In view of (5.8),
s(x)/ρ(x) −−→
x↓0 0. Using (2.16), we get
 a
0
b(x)|s(x)|
ρ(x)σ2(x)dx < ∞.
This means that zero cannot have right type 6.
⊓⊔

5.3 Equations with a Constant-Sign Drift: Types of Zero
101
Theorem 5.12. Let b ≤0 on (0, a]. Then zero can only have right type 0,
1, or 4.
Proof. The condition b ≤0 implies (5.6). Consequently, the right type of
zero is one of 0, 1, 2, 4, 6. Inequalities (5.8), (5.9) hold true, and hence, zero
cannot have right type 6.
It is also clear that the conditions
 a
0
1 + |b(x)|
ρ(x)σ2(x)dx < ∞
and
 a
0
|b(x)|
σ2(x)dx = ∞
cannot hold simultaneously (note that ρ is bounded on [0, a]). Hence, zero
cannot have right type 2.
⊓⊔
Remark. Theorems 5.9–5.12 cannot be strengthened. Indeed, Figure 5.1
shows that all the right types allowed by Theorems 5.9–5.12 are realized.
Table 5.1. Possible right types in the case of a constant-sign drift
σ2 = 1 arbitrary σ
b ≥0
0 2 3
0 1 2 3 4 5
b ≤0
0 1
0 1 4
It follows from Theorems 5.9–5.12 that type 6 can be realized only if the
drift coeﬃcient has alternating signs. The example below shows that this
type is realized.
Example 5.13. Let ρ be an absolutely continuous function on (0, a] such
that
1 ≤ρ(x) ≤2,
x ∈(0, a],
 a
0
x|ρ′(x)|dx = ∞.
Take
σ(x) = 1,
b(x) = −ρ′(x)
2ρ(x).
Then zero has right type 6.
The proof is straightforward.

102
5 Several Special Cases
Remark. Suppose that zero has right type 6 and x0 > 0. Let P denote the
solution of (1) up to T 0,a−. Obviously, there exists a unique measure P on F
such that P|FT 0,a−= P and X is stopped P-a.s. when it reaches 0 or a.
However, the measure P|FT0,a is not a solution deﬁned up to T0,a. The reason
is that
P
 T0,a
0
|b(Xs)|ds = ∞

> 0
(see the proof of Theorem 2.14 (i)). In particular, the integral
 T0,a
0
b(Xs)ds
(5.10)
cannot be deﬁned in the usual Lebesgue-Stieltjes sense. On the other hand,
there exists limt↑T0,a Xt P-a.s. It would be interesting to investigate whether
there exists
lim
t↑T0,a
 t
0
b(Xs)ds.
(5.11)
For example, if σ = 1, then, in view of the equality
Xt = x0 +
 t∧T0,a
0
b(Xs)ds + Mt,
t ≥0,
this limit exists P-a.s. (Note that Xt P-a.s. tends to a limit as t ↑T0,a and
Mt P-a.s. tends to a limit as t ↑T0,a.) If limit (5.11) exists P-a.s. (or in
P-probability), then it can be taken as the principal value of (5.10). In this
case we could modify Deﬁnition 1.31 and say that P|FT0,a is a solution (in
the generalized sense) deﬁned up to T0,a. Thus, if we accept this generalized
deﬁnition, then types 6 and 1 are merged together.
The investigation of the existence of limit (5.11) may lead to the study
of the principal values of integral functionals of diﬀusion processes (see [6],
[47] for results concerning principal values of integral functionals of Brownian
motion).
5.4 Equations with a Constant-Sign Drift: Types of
Inﬁnity
This section is included for the sake of completeness. However, it is totally
trivial. Throughout this section, we assume that (4.1) is true.

5.4 Equations with a Constant-Sign Drift: Types of Inﬁnity
103
It is seen from the results of Section 5.2 that, under the conditions b ≥0
and σ2 = 1, +∞can have all types A, B, C. Therefore, we formulate the
statement related only to the case, where b ≤0.
Theorem 5.14. Let b ≤0. Then +∞has type A.
The proof is straightforward.
Table 5.2. Possible types of +∞in the case of a constant-sign drift
σ2 = 1 arbitrary σ
b ≥0
A B C
A B C
b ≤0
A
A

Appendix A: Some Known Facts
We cite here some known facts from the stochastic calculus that are used in
the proofs.
A.1 Local Times
Most statements of this section are taken from [38, Ch. VI, §§ 1, 2] (alterna-
tively, one may consult [39, Ch. IV, §§ 43–45]).
Throughout this section, Z = (Zt; t ≥0) denotes a continuous semi-
martingale on a ﬁltered probability space

Ω, G, (Gt), Q

.
Proposition A.1. For any a ∈R, there exists an increasing continuous
process La(Z) = (La
t (Z); t ≥0) such that
(Zt −a)+ = (Z0 −a)+ +
 t
0
I(Zs > a)dZs + 1
2La
t (Z),
t ≥0.
Deﬁnition A.2. The process La(Z) is called the local time of Z at the
point a.
Let I ⊆R be some interval (it may be closed, open, or semi-open). Sup-
pose that f : I →R is a diﬀerence of two convex functions and f is continu-
ous. Then, for each x from the interior of I, there exist a left-hand derivative
f ′
−(x) and a right-hand derivative f ′
+(x). Moreover, there exists a second
derivative f ′′ in the sense of distributions. It is a signed measure on I such
that, for any a, b from the interior of I, we have f ′
−(b) −f ′
−(a) = f ′′([a, b)).
If the left endpoint l of I belongs to I, then we deﬁne f ′
−(l) = 0 and assume
that the measure f ′′ has an atom of mass f ′
+(l) at the point l.
Proposition A.3 (Itˆo–Tanaka formula). Suppose that Z a.s. takes values
in I, f : I →R is a diﬀerence of two convex functions, and f is continuous.
Suppose moreover that f ′′ is ﬁnite on any compact subset of I. Then
f(Zt) = f(Z0) +
 t
0
f ′
−(Zs)dZs + 1
2

I
Lx
t (Z)f ′′(dx),
t ≥0.
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 105–118, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

106
Appendix A: Some Known Facts
Proposition A.4 (Occupation times formula). For any positive measur-
able function h and any a.s. ﬁnite stopping time S,
 S
0
h(Zs)d⟨Z⟩s =

R
h(x)Lx
S(Z)dx
a.s.
Proposition A.5. For any a, the measure dLa(Z) is a.s. carried by the set
{t ≥0 : Zt = a}.
Proposition A.6. (i) There exists a modiﬁcation of the random ﬁeld
(La
t (Z); a ∈R, t ≥0) such that the map (a, t) →La
t (Z) is a.s. continuous
in t and c`adl`ag in a. Moreover,
La
t (Z) −La−
t (Z) = 2
 t
0
I(Zs = a)dZs,
t ≥0,
(A.1)
where La−
t (Z) = limε↓0 La−ε
t
(Z).
(ii) If Z is a continuous local martingale, then its local time admits a
bicontinuous modiﬁcation.
Propositions A.4 and A.6 (i) yield
Corollary A.7. For any t ≥0 and a ∈R, we have
La
t (Z) = lim
ε↓0
1
ε
 t
0
I(a ≤Zs < a + ε)d⟨Z⟩s
a.s.
Proposition A.8. If B is a Brownian motion started at zero, then, for any
t > 0, L0
t(B) > 0 a.s.
Proposition A.9. Let B be a Brownian motion and f be a positive Borel
function such that the set {f > 0} has strictly positive Lebesgue measure.
Then
 ∞
0
f(Bs)ds = ∞
a.s.
For the proof, see [38, Ch. X, Prop. 3.11].
Proposition A.10. Let B be a Brownian motion started at a point a ∈R.
Take c < a and set
Zθ = Lθ+c
Tc(B)(B),
θ ≥0,
where Tc(B) = inf{t ≥0 : Bt = c}.
(i) The process (Zθ; θ ∈[0, a−c]) has the same distribution as (|Wθ|2; θ ∈
[0, a −c]), where W is a two-dimensional Brownian motion started at zero.
(ii) For any θ ≥0, EZθ = 2θ ∧2(a −c).
Statement (i) follows from the Ray-Knight theorem (see [38, Ch. XI, Th. 2.2])
and the scaling property of the Brownian motion. Statement (ii) is taken
from [3, (1.2.3.1)].

A.2 Random Time-Changes
107
A.2 Random Time-Changes
Most statements of this section are taken from [38, Ch. V, §1].
Deﬁnition A.11. Let

Ω, G, (Gt), Q

be a ﬁltered probability space. We as-
sume that (Gt)t≥0 is right-continuous. A time-change τ is a family (τt; t ≥0)
of stopping times such that the maps t →τt are a.s. increasing and right-
continuous (τ may take on inﬁnite values).
Proposition A.12. Let (At; t ≥0) be an increasing right-continuous adapted
process on (Ω, G, (Gt), Q) (it may take inﬁnite values). Set
τt = inf{s ≥0 : As > t},
where inf ∅= ∞. Then (τt; t ≥0) is a time-change. Moreover, the ﬁltration
(Gτt)t≥0 is right-continuous and, for every t ≥0, the random variable At is
a (Gτt)-stopping time.
Proposition A.13. Let τ be an a.s. ﬁnite time-change and H be a (Gt)-
progressive process. Then the process Hτt is (Gτt)-progressive.
Remark. If H is only (Gt)-adapted, then Hτt may not be (Gτt)-adapted.
Deﬁnition A.14. A process Z is said to be τ-continuous if Z is constant on
each interval of the form [τt−, τt). (By convention, τ0−= 0.)
The following statement is often used to verify the τ-continuity.
Proposition A.15. If M is a continuous local martingale, then almost-surely
the intervals of constancy are the same for M and ⟨M⟩, i.e., for almost all
ω, we have: Mt(ω) = Ma(ω) for a ≤t ≤b if and only if ⟨M⟩b(ω) = ⟨M⟩a(ω).
For the proof, see [38, Ch. IV, Prop. 1.13].
Proposition A.16. Let τ be an a.s. ﬁnite time-change and M be a contin-
uous (Gt)-local martingale that is τ-continuous. Then the process Mτt is a
continuous (Gτt)-local martingale with ⟨Mτ⟩t = ⟨M⟩τt.
Proposition A.17 (Change of variables in stochastic integrals). Let
τ be an a.s. ﬁnite time-change and M be a continuous (Gt)-local martingale
that is τ-continuous. Let H be a (Gt)-progressive process such that, for any
t ≥0,
 t
0
H2
s d⟨M⟩s < ∞
a.s.
Then, for any t ≥0,
 t
0
H2
τsd⟨Mτ⟩s < ∞
a.s.
and
 t
0
HτsdMτs =
 τt
τ0
HsdMs
a.s.

108
Appendix A: Some Known Facts
Proposition A.18 (Change of variables in Lebesgue-Stieltjes inte-
grals). Let τ : R+ →R+ and A : R+ →[0, ∞] be increasing c`adl`ag functions
such that A is τ-continuous. Then for any Borel function f : R+ →R+ and
any t ≥0, we have
 t
0
f(τs)dAτs =
 τt
τ0
f(s)dAs.
In order to prove this statement, one should ﬁrst consider functions f of the
form I[0,a] and then apply Proposition A.36.
A.3 Bessel Processes
Let us consider the SDE
dXt = δdt + 2

|Xt|dBt,
X0 = x2
0,
(A.2)
where δ > 0, x0 ≥0. It follows from Theorems 4.6 and 4.7 that weak existence
holds for the equation
dXt = δdt + (2

|Xt| + I(Xt = 0))dBt,
X0 = x2
0.
(A.3)
(Indeed, by Theorem 5.1, for this SDE zero has type (1, 2) if 0 < δ < 2 and
type (1, 3) if δ ≥2; by Theorem 5.5, +∞has type A if 0 < δ ≤2 and type B
if δ > 2.) Furthermore, for any solution P of (A.3), we have
 t
0
I(Xs = 0)ds = 0
P-a.s.
and hence, P is also a solution of (A.2). Proposition 1.12 ensures that pathwise
uniqueness holds for (A.2). By Proposition 1.6, there are also strong existence
and pathwise uniqueness (in terms of Section 1.1, this is the “best possible
situation”). Moreover, the comparison theorems (see, [38, Ch. IX, Th. 3.8])
ensure that if (Z, B) is a solution of (A.2), then Z is positive.
Deﬁnition A.19. If (Z, B) is a solution of SDE (A.2), then Z is called the
square of a δ-dimensional Bessel process started at x2
0. The process ρ =
√
Z
is called a δ-dimensional Bessel process started at x0.
Proposition A.20. Let ρ be a δ-dimensional Bessel process started at x0.
(i) If δ ≥2, then P{∃t > 0 : ρt = 0} = 0.
(ii) If 0 < δ < 2, then P{∃t > 0 : ρt = 0} = 1 and the Bessel process is
reﬂected at zero.
For the proof, see [38, Ch. XI, § 1].

A.3 Bessel Processes
109
Proposition A.21. Suppose that δ > 1 and x0 ≥0. Let (Z, B) be a solution
of (A.2) and ρ =
√
Z. Then (ρ, B) is a solution of the SDE
dXt = δ −1
2Xt
I(Xt ̸= 0)dt + dBt,
X0 = x0.
For the proof, see [38, Ch. XI, § 1].
Proposition A.22. Let B be a Brownian motion started at a > 0. Let ρ be
a three-dimensional Bessel process started at zero. Set
T0(B) = inf{t ≥0 : Bt = 0},
Ua(B) = sup{t ≤T0(B) : Bt = a},
Ta(ρ) = inf{t ≥0 : ρt = a}.
Then
Law

BT0(B)−t; 0 ≤t ≤T0(B) −Ua(B)

= Law

ρt; 0 ≤t ≤Ta(ρ)

.
This statement is a consequence of [38, Ch. VII, Cor. 4.6].
Remark. Proposition A.22 can informally be interpreted as follows. The be-
haviour of the Brownian motion before it hits zero is the same as the be-
haviour of the time-reversed three-dimensional Bessel process started at zero.
Proposition A.23. Let ρ be a three-dimensional Bessel process started at
zero and f be a positive measurable function such that, for any ε > 0,
 ε
0
xf(x)dx = ∞.
Then, for any ε > 0,
 ε
0
f(ρs)ds = ∞
a.s.
For the proof, see [4] or [37].
Propositions A.22 and A.23 yield
Corollary A.24. Let B be a Brownian motion started at a > 0. Let f be a
positive Borel function such that, for any ε > 0,
 ε
0
xf(x)dx = ∞.
Then, for any ε > 0,
 T0(B)
T0(B)−ε
f(Bs)ds = ∞
a.s.

110
Appendix A: Some Known Facts
A.4 Strong Markov Families
Throughout this section, X denotes the coordinate process on C(R+) and
(Ft) stands for the canonical ﬁltration on C(R+). By (F+
t ) we will denote its
right modiﬁcation, i.e., F+
t
= 
ε>0 Ft+ε. For a (F+
t )-stopping time S, the
shift operator ΘS : C(R+) →C(R+) is deﬁned by
(ΘSω)(t) =

ω(S(ω) + t)
if S(ω) < ∞,
π
if S(ω) = ∞.
(A.4)
The map ΘS is F|F-measurable (this follows from Lemma B.1).
Deﬁnition A.25. Let I ⊆R be an interval, which may be closed, open,
or semi-open. A family of measures (Px)x∈I on F has the strong Markov
property if
(a) for any x ∈I,
Px{X0 = x} = 1,
Px

∀t ≥0, Xt ∈I ∪{π}

= 1;
(b) for any A ∈F, the map x →Px(A) is Borel-measurable;
(c) for any (F+
t )-stopping time S, any positive F-measurable function Ψ,
and any x ∈I,
EPx[Ψ ◦ΘS | F+
S ] = EPXS Ψ
Px-a.s.
on the set {XS ̸= π}.
Deﬁnition A.26. Let I ⊆R be an interval, which may be closed, open, or
semi-open. A family of measures (Px)x∈I has the regularity property if
(a) for any x ∈I, on the set {ξ < ∞} we have: limt↑ξ Xt exists and does
not belong to I Px-a.s. In other words, X can be killed only at the endpoints
of I that do not belong to I;
(b) for any x from the interior of I and any y ∈I, Px{∃t ≥0 : Xt = y} > 0.
Proposition A.27. Let (Px)x∈I be a regular strong Markov family. There
exists a continuous strictly increasing function s : I →R such that s(XTa,b) is
a (Ft, Px)-local martingale for any a ≤x ≤b in I. Furthermore, the function
s is determined uniquely up to an aﬃne transformation, and it satisﬁes the
following property: for any a ≤x ≤b in I,
Px{Tb < Ta} = s(x) −s(a)
s(b) −s(a) .
For the proof, see [28, Th. 20.7] or [38, Ch. VII, Prop. 3.2].
Deﬁnition A.28. A function s with the stated property is called a scale
function of (Px)x∈I.

A.5 Other Facts
111
Proposition A.29. Let (Px)x∈I be a regular strong Markov family. There
exists a unique measure m on the interior of I such that, for any positive
Borel function f and any a ≤x ≤b in I,
EPx
 Ta,b
0
f(Xs)ds = 2
 b
a
Ga,b(x, y)f(y)m(dy),
where
Ga,b(x, y) =

s(x) ∧s(y) −s(a)

s(b) −s(x) ∨s(y)

s(b) −s(a)
,
x, y ∈[a, b].
Deﬁnition A.30. The measure m with the stated property is called a speed
measure of (Px)x∈I.
Remark. The measure m is unique for a ﬁxed choice of the scale function. If
one takes another variant s(x) = αs(x) + β of the scale function, then a new
variant G = αG of the function G and, as a result, a new variant m = m/α
of the speed measure are obtained.
Proposition A.31. Let I be a compact interval and (Px)x∈I be a regular
strong Markov family with a scale function s and a speed measure m. Suppose
that the endpoints l and r of I are absorbing for this family, i.e., for any
x ∈[a, b], the canonical process X is stopped Px-a.s. at the time Ta,c. Take
x ∈I. Let B be a Brownian motion started at s(x). Consider
At =

s(I)
Ly
t (B)ν(dy),
τt = inf{s ≥0 : As > t},
where ν is the sum of m◦s−1 and the inﬁnite masses at the points s(l), s(r).
Then
Px = Law

s−1(Bτt); t ≥0

.
For the proof, see [28, Th. 20.9] or [39, Ch. VII, Th. 47.1]. Also, the result
can be reduced to the case, where s(x) = x, x ∈I, and then it can be found
in [15].
Remark. The above statement shows, in particular, that the family (Px)x∈I
is uniquely determined by s and m.
A.5 Other Facts
Proposition A.32 (Skorokhod’s lemma). Let Z : R+ →R be a contin-
uous function such that Z(0) ≥0. There exists a unique pair of functions
(Y, L) such that

112
Appendix A: Some Known Facts
(a) Y = Z + L;
(b) Y ≥0;
(c) L is increasing, continuous, vanishing at zero, and the corresponding
measure dL is carried by the set {t ≥0 : Y (t) = 0}.
The function L is moreover given by
L(t) = sup
s≤t
(−Z(s) ∨0).
For the proof of this statement, see [38, Ch. VI, Lem. 2.1].
Proposition A.33. Let B be a Brownian motion started at zero. Set St =
sups≤t Bs. Then
Law(St −Bt; t ≥0) = Law(|Bt|; t ≥0).
This statement follows from P. L´evy’s theorem (see [38, Ch. VI, Th. 2.3]).
Proposition A.34. Suppose that J ⊆R is an interval and µ is a positive
(but not necessarily ﬁnite) measure on J. Let (Zt; t ∈J) be a random process
with measurable sample paths such that E|Zt| < ∞for any t ∈J. Suppose
that there exist constants γ > 1, c > 0, for which
E|Zt|γ ≤c(E|Zt|)γ,
t ∈J.
Then

J
|Zt|µ(dt) < ∞a.s.
⇐⇒

J
E|Zt|µ(dt) < ∞.
For the proof, see [8].
Deﬁnition A.35. A family M of subsets of a space Ωis called a d-system if
the following conditions are satisﬁed:
(a) ∅, Ω∈M;
(b) if A, B ∈M and A ⊆B, then B \ A ∈M;
(c) if A, B ∈M and A ∩B = ∅, then A ∪B ∈M;
(d) if (An)∞
n=1 ∈M and An ⊆An+1, then ∞
n=1 An ∈M.
Proposition A.36. Suppose that A is a family of subsets of a space Ωthat is
closed under ﬁnite intersections (i.e., for any A, B ∈A, we have A∩B ∈A).
Then the minimal d-system that contains all the sets from A coincides with
the σ-ﬁeld generated by A.
For the proof, see [9, Ch. I, Lem. 1.1].

Appendix B: Some Auxiliary Lemmas
We give here some lemmas that are used in the proofs.
B.1 Stopping Times
Throughout this section, (Ft) denotes the canonical ﬁltration on C(R+). All
the results apply to the space C(R+) as well.
Lemma B.1. Let S be a (Ft)-stopping time. Then the random variable
XSI(S < ∞) is FS|B(R ∪{π})-measurable.
Proof. For α ∈R and t > 0, we have
{XS < α}∩{S < t} =
∞

m=1
∞
 
n=1

p,q∈Q∩(0,t)
|p−q|<1/n
{p < S < q}∩{Xp ≤α−1/m} ∈Ft.
Consequently,
{XS < α} ∩{S ≤t} =

{XS < α} ∩{S < t}

∪

{Xt < α} ∩{S = t}

∈Ft.
Furthermore,
{XS = π} ∩{S ≤t} = {S ≤t} \

{XS ∈R} ∩{S ≤t}

∈Ft.
Therefore, for any A ∈B(R ∪{π}),
{XS ∈A} ∩{S ≤t} ∈Ft.
This leads to the desired statement.
⊓⊔
Let S be a (Ft)-stopping time and ω ∈C(R+). Consider the stopping
operator ΦS : C(R+) →C(R+) deﬁned by
(ΦSω)(t) = ω(t ∧S(ω)),
t ≥0.
(B.1)
Proposition B.2. Let S be a (Ft)-stopping time and A ∈F. Then A ∈FS
if and only if A = {ω : ωS ∈A}.
A.S. Cherny and H.-J. Engelbert: LNM 1858, pp. 113–118, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

114
Appendix B: Some Auxiliary Lemmas
For the proof, see [41, Ch. I, § 2].
Lemma B.3. Let S be a (Ft)-stopping time and P be a probability measure
on FS. Then the map ΦS is FS|F-measurable. Moreover, (P ◦Φ−1
S )|FS = P.
Proof. The ﬁrst statement follows from Lemma B.1.
In order to prove the second statement, ﬁx A ∈FS. Using Proposition B.2,
we can write
P ◦Φ−1
S (A) = P{ω : ωS ∈A} = P(A).
2
Proposition B.4 (Galmarino’s test). A measurable function S : C(R+) →
[0, ∞] is a (Ft)-stopping time if and only if the conditions
S(ω) = t,
ω(s) = ω′(s),
s ≤t
imply S(ω′) = t.
For the proof, see [41, Ch. I, § 2].
B.2 Measures and Solutions
Lemma B.5. Let (Gt) be a ﬁltration and U, V be (Gt)-stopping times. Let P
be a measure on GV . Suppose that U ≤V P-a.s. Then there exists a unique
measure Q on GU such that Q|(GU ∩GV ) = P|(GU ∩GV ). This measure will
be denoted as P|GU.
Proof. Existence. For any A ∈GU, the set A∩{U ≤V } belongs to GV . Hence,
the measure Q deﬁned by
Q(A) := P(A ∩{U ≤V }),
A ∈GU
is a correctly deﬁned probability measure on GU. Obviously, for any
A ∈GU ∩GV , Q(A) = P(A).
Uniqueness. Let Q′ be another measure with the stated property. Since
{U > V } ∈GU ∩GV , we can write
Q′{U > V } = P{U > V } = 0.
Hence, for any A ∈GU,
Q′(A) = Q′(A ∩{U ≤V }) + Q′(A ∩{U > V })
= Q′(A ∩{U ≤V }) = P(A ∩(U ≤V }) = Q(A).
This completes the proof.
⊓⊔

B.2 Measures and Solutions
115
Lemma B.6. Let (Ft) be the canonical ﬁltration on C(R+). Let S be
a (Ft)-stopping time and P, P′ be probability measures on FS such that
P{ξ ≤S} = 0, P′{ξ ≤S} = 0. Suppose that there exists a sequence (Sn)
of stopping times such that
(a) for any n ∈N, P{Sn ≤Sn+1 ≤S} = 1 and P′{Sn ≤Sn+1 ≤S} = 1;
(b) limn Sn = S P, P′-a.s.;
(c) for any n ∈N, P′|FSn = P|FSn (we use here the convention from
Lemma B.5).
Then P′ = P.
Proof. Let FSn denote the completion of FSn with respect to the measure
P + P′, i.e., FSn is generated by FSn and by the subsets of the (P + P′)-null
sets from F. Obviously, P′|FSn = P|FSn. Set G = 
n∈N FSn. By Proposi-
tion A.36, P′|G = P|G.
Take A ∈FS. It follows from Proposition B.2 that A = {XS ∈A}. Hence,
FS ⊆σ(XS
t ; t ≥0). For any t ≥0, we have
XS
t = lim
n→∞XSn
t
P, P′-a.s.
By Lemma B.1, each random variable XSn
t
is FSn-measurable. Hence, XS
t is
G-measurable. As a result, FS ⊆G, and therefore, P′ = P.
⊓⊔
For a stopping time S on C(R+), we consider the shift operator
ΘS : C(R+) →C(R+) deﬁned by
(ΘSω)(t) =

ω(S(ω) + t)
if S(ω) < ∞,
0
if S(ω) = ∞.
(B.2)
Lemma B.7. Let P be a global solution of (1) and d ∈R. Suppose that
P{Td < ∞} > 0. Set Q = P( · | Td < ∞), R = Q ◦Θ−1
Td . Then R is a global
solution of (1) with X0 = d.
Proof. Conditions (a), (b) of Deﬁnition 1.28 are obvious. Let us check (c).
Fix λ > 0. Consider
Mt = Xt −d −
 t
0
b(Xs)ds,
t ≥0,
U = inf{t ≥0 : |Ms| ≥λ},
V = inf{t ≥Td : |Mt −MTd| ≥λ},
Nt =
 t
0
I(Td ≤s < V )dMs,
t ≥0.
The process N is a (Ft, P)-local martingale. Being bounded, it is a uniformly
integrable (Ft, P)-martingale. Hence, for any s ≤t, C ∈FS, we have
ER[(M U
t −M U
s )I(C)] = EP

Nt+Td −Ns+Td

I(Θ−1
Td (C))I(Td < ∞)

= 0.

116
Appendix B: Some Auxiliary Lemmas
(Here we have used the optional stopping theorem and the fact that Θ−1
Td (C) ∈
Fs+Td; see Proposition B.2.) Thus, M U ∈Mc
loc(Ft, R). As λ was chosen
arbitrarily, this implies that M ∈Mc
loc(Ft, R). Condition (d) is veriﬁed in a
similar way.
⊓⊔
B.3 Other Lemmas
Deﬁnition B.8. The gluing function is a map G : C(R+)×C0(R+)×[0, ∞] →
C(R+) deﬁned as
G(ω1, ω2, u)(t) = ω1(t ∧u) + ω2((t −u)+),
t ≥0.
Here C0(R+) = {ω ∈C(R+) : ω(0) = 0}. Note that the map G is continuous
and therefore, measurable.
Lemma B.9. Let X = (Xt)t≥0 be a continuous process on (Ω, G, P), Y =
(Yt)t≥0 be a continuous process on (Ω′, G′, P′) with Y0 = 0, and S be a (FX
t )-
stopping time. Let M ∈Mc
loc(FX
t , P), N ∈Mc
loc(FY
t , P′), and suppose that
N0 = 0. Set
Z(ω, ω′) = G(X(ω), Y (ω′), S(ω)),
K(ω, ω′) = G(M(ω), N(ω′), S(ω)).
Then K ∈Mc
loc(FZ
t , P × P′) and
⟨K⟩= G(⟨M⟩, ⟨N⟩, S).
(B.3)
Proof. Clearly, it is suﬃcient to prove the statement for the case, where
Ω= C(R+), Ω′ = C0(R+), and X, Y are coordinate processes. Let us ﬁrst
assume that M and N are bounded. Fix s < t and A ∈Fs, where (Ft) denotes
the canonical ﬁltration on C(R+). By Galmarino’s test, S(X) = S(Z). We
can write
EP×Q

(Kt −Ks)I(S > s)I(Z ∈A)

= EP×Q

(Kt −Ks)I(S > s)I(X ∈A)

= EP×Q

(Mt∧S −Ms)I(S > s)I(X ∈A)

+EP×Q

(N(t−S)+)I(S > s)I(X ∈A)

= EP

(Ms∨(t∧S) −Ms)I(S > s)I(X ∈A)

+EP

I(S > s)I(X ∈A)EQ[N(t−S(X))+]

= 0.
(B.4)
For ω ∈C(R+) such that S(ω) ≤s, we set
Aω = {ω′ ∈C0(R+) : G(ω, ω′, S(ω)) ∈A}.
Then Aω ∈FY
s−S(ω). Therefore,

B.3 Other Lemmas
117
EP×Q

(Kt −Ks)I(S ≤s)I(Z ∈A)

= EP

I(S ≤s)EQ[I(Y ∈AX)(Nt−S(X) −Ns−S(X))]

= 0.
(B.5)
Equalities (B.4) and (B.5) yield K ∈Mc
loc(FZ
t , P×Q). Similar arguments
show that the processes
M 2
t∧S −⟨M⟩t∧S,
N 2
(t−S)+ −⟨N⟩(t−S)+,
Mt∧SN(t−S)+,
t ≥0
belong to Mc
loc(FZ
t , P × Q). Consequently, the process
K2
t −⟨M⟩t∧S −⟨N⟩(t−S)+
= M 2
t∧S −⟨M⟩t∧S + N 2
(t−S)+ −⟨N⟩(t−S)+ + 2Mt∧SN(t−S)+,
t ≥0
is a (FZ
t , P × Q)-local martingale. This yields (B.3).
For unbounded M and N, we deﬁne
K(l) = G

M Tl,−l(M), N Tl,−l(N), S

,
where l ∈N. It is easy to check that
inf{t ≥0 : |Kt| ≥l} = inf{t ≥0 : |K(2l)
t
| ≥l}.
Now, the result for unbounded M and N follows from the result for bounded
M and N.
⊓⊔
Deﬁnition B.10. A sequence of processes Z(n) = (Z(n)
t
; t ≥0) on a prob-
ability space (Ω, G, Q) converges to a process Z = (Zt; t ≥0) in probability
uniformly on compact intervals if for any t ≥0,
sup
s≤t
|Z(n)
s
−Zs|
Q
−−−−→
n→∞0.
We use the notation:
Z(n)
Q-u.p.
−−−−→
n→∞Z.
Lemma B.11. Let

Ω, G, (Gt), Q

be a ﬁltered probability space. Suppose that
M (n) ∈Mc
loc(Gt, Q) and
M (n)
Q-u.p.
−−−−→
n→∞M.
Then M ∈Mc
loc(Gt, Q) and
⟨M (n)⟩
Q-u.p.
−−−−→
n→∞⟨M⟩.
Proof. Fix u ≥0 and ε > 0. Find λ > 0 such that
Q

sup
t≤u
|Mt| ≤λ

> 1 −ε

118
Appendix B: Some Auxiliary Lemmas
and consider
τ = u ∧inf{t ≥0 : |Mt| ≥λ},
τn = τ ∧inf{t ≥0 : |M (n)
t
| ≥2λ}.
Then
sup
t≤u
|Mt∧τn −Mt∧τ|
Q
−−−−→
n→∞0.
For any t ≤u, n ∈N, we have |M (n)
t∧τn| ≤2λ. Therefore, for any s ≤t ≤u
and C ∈Gs,
EQ[(Mt∧τ −Ms∧τ)I(C)] = lim
n→∞EQ

M (n)
t∧τn −M (n)
s∧τn

I(C)

= 0.
As u and ε were chosen arbitrarily, this proves that M ∈Mc
loc(Gt, Q).
In order to prove the second statement, consider
N (n) = M (n) −M,
τ n
m = inf{t ≥0 : |N (n)
t
| ≥m},
N (nm)
t
= N (n)
t∧τ n
m,
t ≥0.
For any m ∈N,
N (nm)
Q-u.p.
−−−−→
n→∞0,
τn
m
Q
−−−−→
n→∞∞.
(B.6)
Applying the Burkholder–Davis–Gundy inequality (see [38, Ch. IV, § 4]), we
conclude that, for any m ∈N,
⟨N (nm)⟩
Q-u.p.
−−−−→
n→∞0.
This, combined with (B.6), gives
⟨N (n)⟩
Q-u.p.
−−−−→
n→∞0.
Using the inequality |⟨N (n), M⟩| ≤⟨N (n)⟩1/2⟨M⟩1/2, we get
⟨N (n), M⟩
Q-u.p.
−−−−→
n→∞0.
Then the equality ⟨M (n)⟩= ⟨M⟩+ 2⟨N (n), M⟩+ ⟨N (n)⟩yields the desired
statement.
⊓⊔

References
1. Assing, S., Senf, T. (1991): On stochastic diﬀerential equations without drift.
Stochastics and Stochastics Reports, 36, No. 1, 21–39
2. Barlow, M.T. (1982): One-dimensional stochastic diﬀerential equations with
no strong solution. Journal of the London Mathematical Society, 26, 335–347
3. Borodin, A.N., Salminen, P. (2002): Handbook of Brownian Motion – Facts
and Formulae. 2nd Ed. Birkh¨auser
4. Cherny, A.S. (2000): Convergence of some integrals associated with Bessel
processes. Theory of Probability and Its Applications, 45, No. 2, 251–267
5. Cherny, A.S. (2000): On the strong and weak solutions of stochastic diﬀerential
equations governing Bessel processes. Stochastics and Stochastics Reports, 70,
No. 3–4, 213–219
6. Cherny, A.S. (2001): Principal values of the integral functionals of Brownian
motion: existence, continuity and an extension of Itˆo’s formula. Lecture Notes
in Mathematics, 1755, 348–370
7. Cherny, A.S. (2001): On the uniqueness in law and the pathwise uniqueness for
stochastic diﬀerential equations. Theory of Probability and Its Applications,
46, No. 3, 483–497
8. Cs¨org¨o, M., Horw´ath, L., Shao, Q.-M. (1993): Convergence of integrals of
uniform empirical and quantile processes. Stochastic Processes and Their Ap-
plications, 45, No. 2, 283–294
9. Dynkin, E.B. (1961): Theory of Markov processes. Prentice-Hall
10. Engelbert, H.-J. (1991): On the theorem of T. Yamada and S. Watanabe.
Stochastics and Stochastics Reports, 36, 205–216
11. Engelbert, H.-J. (2000): Existence and non-existence of solutions of one-
dimensional stochastic equations. Probability and Mathematical Statistics,
20, 343–358
12. Engelbert, H.-J., Schmidt, W. (1981): On the behaviour of certain functionals
of the Wiener process and applications to stochastic diﬀerential equations.
In: Stochastic Diﬀerential Systems, Lecture Notes in Control and Information
Sciences, 36, 47–55. Springer
13. Engelbert, H.-J., Schmidt, W. (1985): On one-dimensional stochastic diﬀer-
ential equations with generalized drift. In: Stochastic Diﬀerential Systems,
Lecture Notes in Control and Information Sciences, 69, 143–155. Springer
14. Engelbert, H.-J., Schmidt, W. (1985): On solutions of one-dimensional
stochastic diﬀerential equations without drift. Probability Theory and Re-
lated Fields, 68, 287–314
15. Engelbert, H.-J., Schmidt, W. (1989, 1991): Strong Markov continuous local
martingales and solutions of one-dimensional stochastic diﬀerential equations,
I, II, III. Math. Nachr., 143, 167–184; 144, 241–281; 151, 149–197

120
References
16. Feller, W. (1952): The parabolic diﬀerential equations and the associated semi-
groups of transformations. Ann. Math., 55, 468–519
17. Feller, W. (1954): Diﬀusion processes in one dimension. Trans. Amer. Math.
Soc., 77, 1–31
18. Gikhman, I.I. (1947): On a method of constructing random processes (in Rus-
sian). Dokl. Acad. Nauk. SSSR, 58, 961–964
19. Gikhman, I.I. (1950, 1951): On the theory of diﬀerential equations for random
processes, I, II (in Russian). Ukr. Math. J., 2, No. 4, 37–63; 3, No. 3, 317–339
20. Gikhman, I.I., Skorokhod, A.V. (1972): Stochastic Diﬀerential Equations.
Springer
21. Girsanov, I.V. (1960): On transforming a certain class of stochastic processes
by absolutely continuous substitution of measures. Theory of Probability and
Its Applications, 5, No. 3, 285–301
22. Girsanov, I.V. (1962): An example of non-uniqueness of a solution to the
stochastic equation of K. Itˆo. Theory of Probability and Its Applications, 7,
No. 3, 325–331
23. Ikeda, N., Watanabe, S. (1989): Stochastic diﬀerential equations and diﬀusion
processes. 2nd Ed. North-Holland
24. Itˆo, K. (1946): On a stochastic integral equation. Proc. Imp. Acad. Tokyo, 22,
32–35
25. Itˆo, K. (1951): On stochastic diﬀerential equations. Memoirs of the American
Mathematical Society, 4, 1–51
26. Itˆo, K., McKean, H.P. (1974): Diﬀusion processes and their sample paths. 2nd
Ed. Springer
27. Jacod, J., Shiryaev, A.N. (2003): Limit theorems for random processes. 2nd
Ed. Springer
28. Kallenberg, O. (2002): Foundations of modern probability. 2nd Ed. Springer
29. Karatzas, I., Shreve, S.E. (1991): Brownian motion and stochastic calculus.
2nd Ed. Springer
30. Kolmogoroﬀ, A.N. (1931): ¨Uber die analytischen Methoden in der Wahrschein-
lichkeitsrechnung. Math. Annalen, 104, 415–458
31. Krylov, N.V. (1966): On quasi-diﬀusion processes. Theory of Probability and
Its Applications, 11, No. 3, 424–443
32. Krylov, N.V. (1969): On Itˆo’s stochastic diﬀerential equations. Theory of Prob-
ability and Its Applications, 14, No. 2, 330–336
33. Liptser, R.S., Shiryaev, A.N. (2001): Statistics of random processes. 2nd Ed.
Springer
34. McKean, H.P. (1969): Stochastic integrals. Academic press, New York
35. Nadirashvili, N.S. (1997): Nonuniqueness in the martingale problem and the
Dirichlet problem for uniformly elliptic operators. Ann. Scuola Norm. Sup.
Pisa Cl. Sci., 24, 537–550
36. Øksendal, B. (2003): Stochastic diﬀerential equations. 6th Ed. Springer
37. Pitman, J.W., Yor, M. (1986): Some divergent integrals of Brownian motion.
In: Analytic and Geometric Stochastics (ed. D. Kendall). Supplement to Adv.
Appl. Probab., 18, 109–116
38. Revuz, D., Yor, M. (1999): Continuous martingales and Brownian motion. 3rd
Ed. Springer
39. Rogers, L.C.G., Williams, D. (2000): Diﬀusions, Markov processes, and mar-
tingales. 2nd Ed. Cambridge University Press

References
121
40. Safonov, M.V. (1999): Nonuniqueness for second-order elliptic equations with
measurable coeﬃcients. Siam. J. Math. Anal., 30, No. 4, 879–895
41. Shiryaev, A.N. (1978): Optimal stopping rules. Springer
42. Skorokhod, A.V. (1965): Studies in the theory of random processes. Addison-
Wesley, Reading, MA
43. Stroock, D.W. (1993): Probability theory: an analytic view. Cambridge Uni-
versity Press
44. Stroock, D.W., Varadhan, S.R.S. (1969): Diﬀusion processes with continuous
coeﬃcients, I, II. Communications in Pure and Applied Mathematics, 22,
345–400; 479–530
45. Stroock, D.W., Varadhan, S.R.S. (1979): Multidimensional diﬀusion processes.
Springer
46. Tsirelson, B. (1975): An example of a stochastic diﬀerential equation with
no strong solution. Theory of Probability and Its Applications, 20, No. 2,
427–430
47. Yamada, T. (1996): Principal values of Brownian local times and their related
topics. In: Itˆo’s stochastic calculus and probability theory, 413–422. Springer
48. Yamada, T., Watanabe, S. (1971): On the uniqueness of solutions of stochastic
diﬀerential equations. J. Math. Kyoto Univ, 11, 155–167
49. Zvonkin, A.K. (1974): A transformation of the phase space of a process that
removes the drift. Math. USSR Sbornik, 93, No. 1, 129–149
50. Zvonkin, A.K., Krylov, N.V. (1975): On the strong solutions of stochastic dif-
ferential equations. In: Proceedings of the school-seminar on random processes
(Druskininkai, 1974), part 2, 9–88

Index of Notation
C(R+)
the space of continuous functions R+ →R
C0(R+)
the space of continuous functions R+ →R vanishing at zero
C(R+)
the space of continuous functions R+ →R ∪{π} killed at some
time, 23
C(R+, Rn)
the space of continuous functions R+ →Rn
Ft
σ(Xs; s ≤t), the canonical ﬁltration on C(R+) or C(R+)
F+
t

ε>0 Ft+ε, the right modiﬁcation of the ﬁltration (Ft)
FZ
t
σ(Zs; s ≤t), the natural ﬁltration of the process Z
F
Z
t
the completed natural ﬁltration of the process Z, 6
FS
the collection of the sets A ∈F such that, for any t ≥0,
A ∩{S ≤t} ∈Ft
FS−
the σ-ﬁeld generated by the sets A ∩{S > t}, where t ≥0 and
A ∈Ft
F

t≥0 Ft
G|A
{B ∩A : B ∈G}, the restriction of the σ-ﬁeld G to the set A ∈G
L1
loc(d)
functions, locally integrable at the point d, 27
L1
loc(D)
functions, locally integrable on the set D, 27
La
t (Z)
the local time of the process Z spent at the point a up to
time t, 105
Law(Zt; t ≥0)
the distribution of the process Z
Law(Zt; t ≥0|Q) the distribution of the process Z under the measure Q
Mc
loc(Gt, Q)
the space of continuous (Gt, Q)-local martingales
P|G
the restriction of the measure P to the σ-ﬁeld G
P ◦ϕ−1
the image of the measure P under the map ϕ
R+
[0, ∞), the positive half-line

124
Index of Notation
[[S, T]]
{(ω, t) ∈Ω× R+ : S(ω) ≤t ≤T(ω)}
]]S, T]]
{(ω, t) ∈Ω× R+ : S(ω) < t ≤T(ω)}
[[S, T[[
{(ω, t) ∈Ω× R+ : S(ω) ≤t < T(ω)}
]]S, T[[
{(ω, t) ∈Ω× R+ : S(ω) < t < T (ω)}
Ta(Z)
inf{t ≥0 : Zt = a}
Ta,b(Z)
Ta(Z) ∧Tb(Z)
Ta
inf{t ≥0 : Xt = a}, where X is the coordinate process on
C(R+) or C(R+)
Ta,b
Ta ∧Tb
T a
supn inf{t ≥0 : |Xt −a| ≤1/n}, where X is the coordinate
process on C(R+)
T a,b
T a ∧T b
T ∞
limn→∞Tn
T a,∞
T a ∧T ∞
T0+
inf{t ≥0 : Xt > 0}, where X is the coordinate process on C(R+)
or C(R+)
T0−
inf{t ≥0 : Xt < 0}, where X is the coordinate process on C(R+)
or C(R+)
Var Z
the variation process of the ﬁnite-variation process Z
X
the coordinate process on C(R+) or C(R+), 19, 23
x+
x ∨0
x−
x ∧0
x ∨y
max{x, y}
x ∧y
min{x, y}
xn ↓0
xn →0 and xn > 0
xn ↑0
xn →0 and xn < 0
⟨Y, Z⟩
the quadratic covariation of the continuous semimartingales Y
and Z
⟨Z⟩
the quadratic variation of the continuous semimartingale Z
ZS−
limt↑S Zt, the left limit of the c`adl`ag process Z at time S
ZS
the process Z stopped at time S: ZS
t = Zt∧S

Index of Notation
125
B(E)
the Borel σ-ﬁeld on the space E
ΘS
the shift operator on C(R+) or C(R+), 115,110
ξ
inf{t ≥0 : Xt = π}, killing time of the coordinate process on
C(R+), 23
σ∗
the transpose of the matrix σ
ΦS
the stopping operator on C(R+) or C(R+), 113
ϕ−1
the inverse of the function ϕ
∥· ∥
the Euclidean norm in Rn
u.p.
−−→
convergence of processes in probability uniformly on compact
intervals, 117


Index of Terms
(Gt)-Brownian motion, 6
τ-continuous process, 107
d-system, 112
Bessel process, 108
Canonical ﬁltration, 19, 23
Change of variables
– in Lebesgue-Stieltjes integrals, 108
– in stochastic integrals, 107
Characteristic diagram of a SDE, 12
Condition of
– Engelbert–Schmidt, 10, 28
– Itˆo, 9
– Krylov, 11
– Skorokhod, 11
– Stroock–Varadhan, 11
– Yamada–Watanabe, 10
– Zvonkin, 10
Coordinate process, 19, 23
Example of
– Barlow, 14
– Girsanov, 15
– Nadirashvili, 17
– Tanaka, 13
– Tsirelson, 14
Existence of a solution of a SDE, 22
– strong, 6
– weak, 6
Explosion, 82
Feller’s criterion for explosions, 82
Function
– locally integrable at a point, 27
– locally integrable on a set, 27
Galmarino’s test, 114
Gluing function, 116
Itˆo–Tanaka formula, 105
Local time, 105
Martingale problem, 19
– corresponding to a SDE, 20
Monotone class, 112
Occupation times formula, 106
Point
– branch, 73
– regular, 28
– singular, 28
– – isolated, 28
Predictable stopping time, 24
Predicting sequence, 24
Property
– Markov, 74
– regularity, 110
– strong Markov, 110
Scale function, 110
SDE, 1
– singular, 2
Shift operator, 110, 115
Skorokhod’s lemma, 111
Solution of a martingale problem, 19
Solution of a SDE, 6, 22
– global, 25
– local, 25
– positive, 22
– strictly positive, 22
– strong, 6
– up to S, 23
– – positive, 24
– – strictly positive, 24
– up to S−, 25

128
Index of Terms
Speed measure, 111
Stopping operator, 113
Time-change, 107
Type
– (i, j), 65
– left, 65
– of inﬁnity, 82
– right, 35–37
– – entrance, 42
– – exit, 42
Uniqueness of a solution of a SDE, 22
– in law, 6
– pathwise, 6
Yamada–Watanabe theorem, 7

