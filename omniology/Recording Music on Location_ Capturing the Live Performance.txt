
 Recording Music on Location 
Recording Music on Location, Second Edition, provides an exceptional col-
lection of information regarding all aspects of recording outside of the 
studio. Featuring clear explanations on how to achieve professional 
results, this book is divided into two distinct sections: popular music 
and classical music. Whether you record in the local rock club, jazz café, 
or in an orchestra hall, Bruce and Jenny Bartlett offer sage advice on each 
stage of the process of location recording. Packed with hints and tips, this 
book is a great reference for anyone planning to venture outside of the 
studio. Audio examples, tracking sheets, weblinks, and downloadable 
checklists are available on the companion website at www.focalpress.
com/cw/bartlett.
This edition has been thoroughly updated and includes new sections 
on iOS devices, USB thumb drive recorders, and digital consoles with 
built-in recorders, along with updated specs on recording equipment, 
software, and hardware. This edition also shows you how to prepare 
recordings for the web and live audio streaming, and covers spectral anal-
ysis, noise reduction, and parallel compression. A new case study goes in 
depth on classical music recording.
Bruce Bartlett has been a recording engineer, audio journalist, and micro-
phone engineer for over 30 years. A member of the Audio Engineering 
Society and SynAudCon, Bruce has presented several papers on micro-
phone design. He has written about 1000 articles and eight books on 
audio topics. Bruce is a composer as well. He currently runs his own 
microphone company (www.bartlettaudio.com) and recording studio, 
including live, on-location recordings.
Jenny Bartlett is a technical writer.

This page intentionally left blank

 Recording 
Music on 
Location 
 Capturing the Live Performance 
 Second Edition 
 Bruce Bartlett 
 Jenny Bartlett 

 First published 2007 by Focal Press. 
 This edition published 2014 by Focal Press 
 70 Blanchard Road, Suite 402, Burlington, MA 01803 
 and by Focal Press 
 2 Park Square, Milton Park, Abingdon, Oxon OX14 4RN 
 Focal Press is an imprint of the Taylor & Francis Group, an informa business 
 © 2014 Taylor & Francis 
 The right of Bruce Bartlett and Jenny Bartlett to be identiﬁ ed as the authors of this work has 
been asserted by them in accordance with sections 77 and 78 of the Copyright, Designs and 
Patents Act 1988. 
 All rights reserved. No part of this book may be reprinted or reproduced or utilised in any 
form or by any electronic, mechanical, or other means, now known or hereafter invented, 
including photocopying and recording, or in any information storage or retrieval system, 
without permission in writing from the publishers. 
 Notices 
 Knowledge and best practice in this ﬁ eld are constantly changing. As new research and 
experience broaden our understanding, changes in research methods, professional practices, or 
medical treatment may become necessary. 
 Practitioners and researchers must always rely on their own experience and knowledge in 
evaluating and using any information, methods, compounds, or experiments described herein. 
In using such information or methods they should be mindful of their own safety and the 
safety of others, including parties for whom they have a professional responsibility. 
 Product or corporate names may be trademarks or registered trademarks, and are used only 
for identiﬁ cation and explanation without intent to infringe. 
 Library of Congress Cataloging-in-Publication Data 
 Bartlett, Bruce. 
  Recording music on location: capturing the live performance / Bruce Bartlett and Jenny 
Bartlett. — Second edition. 
   pages cm 
  1. Magnetic recorders and recording—Handbooks, manuals, etc. 2. Sound—Recording and 
reproducing—Handbooks, manuals, etc. I. Title. 
 TK7881.6.B38 2014 
 781.49—dc23 
 2014003699 
 ISBN: 978-1-138-02237-9 (pbk) 
 ISBN: 978-1-138-02236-2 (hbk) 
 ISBN: 978-1-315-77707-8 (ebk) 
 Typeset in Palatino  
 By Apex CoVantage, LLC 

Bound to Create
You are a creator.  
Whatever your form of expression — photography, filmmaking, 
animation, games, audio, media communication, web design, or 
theatre — you simply want to create without limitation.  Bound 
by nothing except your own creativity and determination.
Focal Press can help.  
For over 75 years Focal has published books that support your 
creative goals. Our founder, Andor Kraszna-Krausz, established 
Focal in 1938 so you could have access to leading-edge expert 
knowledge, techniques, and tools that allow you to create 
without constraint.  We strive to create exceptional, engaging, 
and practical content that helps you master your passion.
Focal Press and you.  
Bound to create.
We’d love to hear how we’ve helped  
you create. Share your experience:
www.focalpress.com/boundtocreate 

This page intentionally left blank

vii
 CONTENTS  
 Preface xv ii
Part 1:  Popular Music Recording 
(Rock, country, jazz, folk, 
R&B, gospel, Christian, 
and so on) 1 
 1 Gear for Live Recording 3 
 Stereo Systems versus Multitrack Systems 3 
 Stereo Recording Systems 4 
 Equipment for Stereo Recording 5 
 Microphones 5 
 Condenser, Dynamic, and Ribbon Types 5 
 Sound Pickup Patterns (Polar Patterns) 6 
 Mic Connectors, Powering, and Cables 6 
 Special-Purpose Mics 8 
 Microphone Mounting Styles 8 
 Mic Specs 9 
 Stereo Recording Devices 9 
 Flash-Memory Handheld Recorder 10 
 iPad with a Recording App and a Plug-In Stereo Mic 12 
 Laptop, Recording Software, and Audio Interface 12 
 Headphones or Earphones 14 
 Multitrack Recording Systems 14 

viii
Contents 
 Equipment for Multitrack Recording 15 
 Microphones and Mic Accessories 15 
 Stage Box and Snake 16 
 Mixer 17 
 Multitrack Recorder 18 
 Recorder-Mixer Option 19 
 Sidebar: Digital Audio Basics 21 
 Bit Depth 23 
 Sampling Rate 24 
 Computer DAW Recording Systems 25 
 DAW Option 1: Mixer, Interface, and Laptop 26 
 DAW Option 2: USB or FireWire Mixer and a Laptop 26 
 DAW Option 3: Interface with Mic Inputs and a Laptop 27 
 DAW Option 4: iOS Recording System 27 
 Mic Splitter 29 
 Headphones, Earphones, or Speakers 31 
 Purchasing Equipment 31 
 2 Recording Techniques from Simple 
to Complex 33 
 Record Off the Board 34 
 Record with a Handheld Recorder 35 
 Record with a Four-Tracker 40 
 Connect the PA Mixer Insert Sends to a Multitrack Recorder 41 
 Connections 42 
 Monitoring 44 
 Setting Levels 45 
 Digital Console Recording Facilities 45 
 Splitting the Mic Signals 46 
 Using Splitters 49 
 Multitrack Recording in a Truck 49 
 3 Before the Session: Planning 51 
 Selecting a Venue 51 
 Musical Preparation 51 

ix
Contents 
 Preproduction Meeting 52 
 Site Survey 53 
 Mic List 54 
 Track Sheet 55 
 Block Diagram 56 
 Equipment List 56 
 Preparing for Easier Setup 58 
 Put It on Wheels 59 
 Mic Mounts 59 
 Snakes and Cables 59 
 Multitrack Wiring 60 
 Other Tips 61 
 4 At the Session: Setup and Recording 63 
 Power and Grounding Practice 63 
 Power Distribution System 63
 Power Source 64 
 Interconnecting Multiple Sound Systems 66 
 Mic Connections 67 
 Running Cables 67 
 Setting Up the Recording Mixer 68 
 Mic Techniques 68 
 Discreet Miking for Video Shoots 77 
 Electric-Guitar Grounding 78 
 Audience Microphones 78 
 Setting Levels and Submixes 80 
 Recording 81 
 Teardown 82 
 5 After the Session: Mixing and Editing 83 
 Editing a Two-Track Recording 83 
 Preparing to Mix a Multitrack Recording on a Computer 86 
 Split the Gig Recording into Song Projects 86 
 Delete Unwanted Material 88 
 Preparing to Mix a Multitrack Recording with a Mixer 88 

x
Contents 
 Do Punch-Ins 88 
 Mix Each Song 88 
 Mixing for Surround Sound 90 
 Mastering an Album 92 
 Mastering a Demo 94 
 Add Fades and EQ 97 
 Spectral Analysis and Noise Reduction 97 
 EQ 97 
 Editing 99 
 Audio Restoration Programs 100 
 Live Recording Website 100 
 6 A Real-World Example: Recording 
a Blues Band in a Club 101 
 Preproduction 101 
 The Recording Session 103 
 Preliminary Mix 104 
 Preparing for the Final Mixes 104 
 Final Mixes 105 
 Mastering 105 
 Burning the CD-R 106 
 7 Web Audio and Streaming 109 
 Streaming versus Downloading 109 
 Data Compression 109 
 Web-Related Audio Files 111 
 What You Need 112 
 How to Prepare and Upload Audio Files 114 
 Putting Your Music On Your Website 116 
 Real-Time Streaming of a Live Concert 118 

xi
Contents 
 Part 2:  Classical Music Recording 
(Orchestra, string quartet, 
pipe organ, choir, soloist) 123 
 8 Microphone Specifications 125 
 Polar Patterns 125 
 Advantages of Each Pattern 128 
 Off-Axis Coloration 128 
 Transducer Type 128 
 Sensitivity 129 
 Self-noise 129 
 Microphone Types 130 
 Free-Field Microphone 130 
 Boundary Microphone 130 
 Stereo Microphone 132 
 Microphone Accessories 133 
 Stands and Booms 133 
 Stereo Microphone Adapter 133 
 Shock Mount 134 
 9 Overview of Stereo Microphone 
Techniques 135 
 Advantages of Stereo Miking 135 
 Goals of Stereo Miking 136 
 Types of Stereo Mic Techniques 137 
 Coincident Pair 138 
 Spaced Pair 140
 Near-Coincident Pair 143 
 Bafﬂ ed-Omni Pair 144 
 Comparing the Four Techniques 145 
 Mic Requirements for Stereo 147 
 How to Test Imaging 147 
 Recommended Reading 147 

xii
Contents 
 10 Stereo Recording Procedures 149 
 Equipment 149 
 Selecting a Venue 152 
 Session Setup 153 
 Mounting the Mics 153 
 Connections 155 
 Monitoring 156 
 Microphone Placement 156 
 Miking Distance 156 
 Stereo-Spread Control 159 
 Monitoring Stereo Spread 160 
 Soloist Pickup and Spot Microphones 160 
 Electronic Music 162 
 Discreet Miking for Video Shoots 163 
 Setting Levels 163 
 Recording a Concert 164 
 Editing 164 
 A Real-World Example: Recording an Orchestra in a Concert Hall 166 
 Preparation 166 
 Setup 167 
 Recording 168 
 Editing 168 
 References 169 
 11 Troubleshooting Stereo Sound 171 
 Distortion in the Microphone Signal 171 
 Too Dead (Not Enough Reverberation) 172 
 Too Detailed, Close, or Edgy 172 
 Too Distant (Too Much Reverberation) 172 
 Narrow Stereo Spread 173 
 Excessive Separation, Hole-in-the-Middle, or Soloist Moves 
 Too Much 173 
 Poorly Focused Images 174 
 Images Shifted to One Side (Left–Right Balance Is Faulty) 174 
 Lacks Depth 175 
 Lacks Spaciousness 175 

xiii
Contents 
 Early Reﬂ ections Too Loud 175 
 Bad Balance (Some Instruments Too Loud or Too Soft) 176 
 Muddy Bass 176 
 Rumble from Air Conditioning, Trucks, and So On 176 
 Bad Tonal Balance (Too Dull, Too Bright, Colored) 177 
 12 Stereo, Surround, and Binaural Microphones 
and Accessories 179 
 Stereo Microphones 180 
 Surround Microphones 183 
 Dummy Heads and Headworn Binaural Mics 184 
 Stereo and Surround Microphone Adapters 186 
 MS Matrix Decoders 187 
 A Stereo Imaging Theory 189 
 Deﬁ nitions 189 
 How We Localize Real Sound Sources 192 
 How We Localize Images Between Speakers 195 
 Requirements for Natural Imaging over Loudspeakers 197 
 Currently Used Image-Localization Mechanisms 200 
 Localization by Amplitude Differences 200 
 Localization by Time Differences 203 
 Localization by Amplitude and Time Differences 204 
 Summary 205 
 Predicting Image Locations 206 
 Choosing Angling and Spacing 210 
 Spaciousness and Spatial Equalization 211 
 References 213 
 B Specific Free-Field Stereo Microphone 
Techniques 217 
 Localization Accuracy 217 
 Examples of Coincident-Pair Techniques 220 

xiv
Contents 
 Coincident Cardioids Angled 180° Apart 220 
 Coincident Cardioids Angled 120°–135° Apart 221 
 Coincident Cardioids Angled 90° Apart 222 
 Blumlein Technique 222 
 Hypercardioids Angled 110° Apart 223 
 Examples of Near-Coincident-Pair Techniques 224 
 The ORTF and DIN Systems 224 
 Examples of Spaced-Pair Techniques 227 
 Omnis Spaced 3 Feet Apart 227 
 Omnis Spaced 10 Feet Apart 228 
 Three Omnis Spaced 5 Feet Apart (10 Feet End to End) 229 
 Decca Tree 229 
 Examples of Bafﬂ ed-Omni Techniques 231 
 Sphere Microphone, SASS-P MKII 231 
 Optimal Stereo Signal or Jecklin Disk 231 
 Other Coincident-Pair Techniques 232 
 Mid–Side 232 
 MS Matrix Box 234 
 MS Advantages 235 
 MS Disadvantages 236 
 Double MS Technique 236 
 SoundField Microphone 237 
 Coincident Systems with Spatial Equalization (Shufﬂ er 
 Circuit) 238 
 Other Near-Coincident-Pair Techniques 238 
 Stereo 180 System 239 
 Faulkner Phased-Array System 239 
 Near-Coincident/Spaced-Pair Hybrid 240 
 Comparisons of Various Techniques 241 
 Michael Williams, “Uniﬁ ed Theory of Microphone Systems for 
 Stereophonic Sound Recording” (1987) 241 
 Carl Ceoen, “Comparative Stereophonic Listening Tests” (1972) 242 
 Benjamin Bernfeld and Bennett Smith, “Computer-Aided 
 Model of Stereophonic Systems” (1978) 242 
 C. Huggonet and J. Jouhaneau, “Comparative Spatial Transfer 
 Function of Six Different Stereophonic Systems” (1987) 243
 M. Hibbing, “XY and MS Microphone Techniques in 
 Comparison” (1989) 244 

xv
Contents 
 Wieslaw Woszczyk, “A New Method for Spatial Enhancement 
 in Stereo and Surround Recording” (1990) 244
 Summary 245
 References 246
 C Stereo Boundary-Microphone Arrays 249 
 Techniques Using Floor-Mounted Mics 250 
 Floor-Mounted Boundary Microphones Spaced 4 Feet Apart 250
 Floor-Mounted Unidirectional Boundary Microphones 251
 Optimal Stereo Signal Boundary-Microphone Floor Array 252 
 “The Musician’s Ear” Stereo Boundary Microphone 252 
 Floor-Mounted Boundary Microphones Conﬁ gured for 
 Mid–Side 253 
 Techniques Using Raised Boundary Mics 253 
 The Stereo Ambient Sampling System (SASS™) 253
 Sphere Microphone 255
 References 255
 D Binaural Techniques 257
 Binaural Recording and the Artiﬁ cial Head 257 
 How It Works 259
 In-Head Localization 261 
 Artiﬁ cial-Head Equalization 261 
 Artiﬁ cial-Head Imaging with Loudspeakers 262 
 References 263
 E 
Surround-Sound Miking Techniques  267
 Surround Speaker Arrangement 268
 Surround-Sound Mic Techniques 270
 SoundField 5.1 Microphone System 270 
 Delos VR 2 Surround Miking Method 270
 NHK Methods 271
 KFM 360 Surround Miking System 271 
 DMP Method 273

xvi
Contents 
 Williams Five Cardioid Mic Array 274 
 Double MS Technique 274
 Surround Ambience Microphone Array 275 
 Chris Burmajster Array 275
 Ideal Cardioid Arrangement 276 
 Holophone H2-PRO Surround Mic 276 
 Sonic Studios DSM-4CS Four-Channel Surround Dummy Head 276
 Slotte Method 277
 Martin Method 277
 Stereo Pair plus Surround Pair 278
 Recommended Reading 278
 Acknowledgments 281 
 Glossary 283 
 Index 311 
 Please note: Focal Press has a website (www.focalpress.com/cw/bartlett) 
for this book with audio clips that demonstrate some techniques discussed 
in the book.  

xvii
 PREFACE 
 Listen to Peter Frampton’s “Do You Feel Like We Do” and you’ll know 
why live, on-location recordings can be so thrilling. 
 Perhaps the most exciting type of recording is done with the musi-
cians playing “live” in a club or concert hall. Many bands want to be 
recorded in concert because they feel that’s when they play best. They 
take chances and surprise the audience. Your job is to capture that perfor-
mance and bring it back alive. 
 Without a doubt, remote recording is exhilarating. The musicians, 
responding to the audience’s energy, often put on a stellar performance. 
You have only one chance to get it recorded and it must be done right. 
You’re working on the edge. But by the end of the night, when everything 
has gone as planned, it’s a great feeling. 
 This book,  Recording Music on Location,  will help you do it right. It 
is the ﬁ rst book to focus exclusively on the special techniques used for 
recording outside the studio. It covers the unique requirements for cap-
turing sound in a room or hall where the music is performed. 
 Whether you want to record an orchestra in a concert hall, a jazz 
combo in a club, or a rock band in a bar, this book offers the practical 
advice to help you do it. The new breed of compact mixers, ﬂ ash-memory 
recorders, digital audio workstations, and multitrack recorders has made 
going on location easier than ever. This book was written to help you take 
advantage of these new tools. 
 Recording Music on Location  is intended for recording engineers, live 
sound engineers, record producers, broadcasters, musicians, concert 
tapers, and podcasters—anyone who wants to know more about remote 
recording. 
 Maybe you’re a musician who wants to record your band. If the 
band is too big for your home studio, or if noise is a problem there, you 
can go out to a venue and record the band in a live performance. With 
less cost than it takes to record in a professional studio, you can record a 
show and produce a live CD. This recording can be used to create a full 
album or simply an audition demo. Some bands start with live-recorded 

xviii
Preface
tracks, and then use them in the studio as a basis for developing com-
plete productions. 
 Focal Press has a website (www.focalpress.com/cw/bartlett) for 
this book with audio clips that demonstrate techniques discussed in 
the book. 
 Recording Music on Location is divided into two main parts: (1) popu-
lar music recording and (2) classical music recording. The recording styles 
for these types of music are quite different. Let’s look at  Part 1 ﬁ rst. 
 Part 1: Popular Music Recording (Rock, 
country, jazz, folk, R&B, gospel, Christian, 
and so on) 
  Chapter 1  offers an overview of audio gear for recording pop music on 
location, both for two-track (stereo) and multitrack recording. 
 There are many ways to record live pop music, from simple to com-
plex.  Chapter 2  walks you through each method. You’ll also learn how 
to interface with the sound-reinforcement (PA) system while making a 
multitrack recording. 
  Chapter 3  helps you plan a live multitrack recording session. When 
you list the necessary equipment and how you will record with it, the 
recording process will be a lot easier and give you a better result. Based 
on my experience as an on-location recording engineer, this chapter also 
offers tips for easier setup. Here you’ll ﬁ nd shortcuts to make your job go 
smoother. 
 In  Chapter 4  we take you step-by-step through a multitrack record-
ing session: connecting to power, running cables, miking, console setup, 
and so on.  Chapter 5  suggests ways to mix and edit a multitrack recording 
of a gig or concert. 
  Chapter 6  describes a real-world recording project: recording a blues 
band in a club. 
 Finally,  Chapter 7  explains how to put your recordings on the Web, 
and how to stream live mixes in real time. 
 The  Frampton Comes Alive!  audio CD by Peter Frampton was origi-
nally released in 1976, produced by Peter Frampton, engineered by Eddie 
Kramer and Chris Kimsey. For other great live recordings, check out 
www.amazon.com/gp/feature.html?docId = 1000426471. 

xix
Preface
 Part 2: Classical Music Recording (Orchestra, 
string quartet, pipe organ, choir, soloist) 
 With pop music, it’s common to use multiple close mics and multitrack 
recorders. But with classical music, stereo mic techniques are the norm. 
There are many ways to make stereo recordings, and  Part 2  covers them 
all. It offers a clear, practical explanation of stereo miking theory, along 
with speciﬁ c techniques, procedures, and hardware. 
 True-stereo microphone techniques use two or three microphones 
to capture the overall sound of the music and the concert hall. The goal 
is to produce a believable illusion of the musical ensemble and the con-
cert hall. 
 For example, an orchestra might be recorded with two microphones 
and played back over two speakers. You would hear sonic images of the 
instruments in various locations between the stereo pair of speakers. 
 These image locations—left to right, front to back—correspond to 
the instrument locations during the recording session. In addition, the 
concert hall acoustics are reproduced with a pleasing spaciousness. The 
result can be a beautiful, realistic re-creation of the original event—or 
even an improvement on it. 
  Part 2 ,  Chapter 8 , explains microphone polar patterns (directional 
pickup patterns), which are key to knowing which mics to use to create 
the effect you want. Then  Chapter 9  overviews the most common stereo 
microphone techniques. 
 Next,  Chapter 10  takes you through a classical music recording 
session: where to record, where to place the mics, recording tips, and 
so on. 
 Later chapters include a troubleshooting guide for stereo sound and 
a listing of stereo, surround, and binaural mics and accessories. A glos-
sary explains the technical terms in the book. 
 The appendices are the most academic sections. They are intended 
for audio engineers who want a deeper understanding of stereo and sur-
round mic techniques, or who want to create their own techniques. 
 Appendix A covers stereo imaging theory in detail: how we hear 
where sounds are coming from, how we localize “images” of musi-
cal instruments between loudspeakers, and how mic techniques create 
images in various locations. You’ll learn how to conﬁ gure stereo arrays to 
achieve various stereo effects. 

xx
Preface
 Appendix A explains speciﬁ c microphone techniques (such as XY, 
MS (mid–side), Blumlein, ORTF, OSS, SASS): their characteristics, stereo 
effects, beneﬁ ts, and drawbacks. 
 Appendix B is devoted to free-ﬁ eld methods; Appendix C to bound-
ary methods; and Appendix D to binaural techniques. 
 Appendix E explores several techniques for surround-sound miking. 
In a surround recording of classical music, we usually hear the orchestra 
up front, and we hear the concert hall ambience from all around. Special 
mic techniques have been developed for capturing this surround effect. 
 I hope you enjoy the thrill of live recording as much as I do. 

 Part 1 
 Popular Music Recording 
(Rock, country, jazz, folk, R&B, 
gospel, Christian, and so on) 

This page intentionally left blank

3
 Whether you are a musician, concert recordist, live sound engineer, or 
studio engineer, your ﬁ rst step is choosing the equipment that suits your 
recording style. 
 The simplest option is to record with a portable stereo recorder. The 
process is easy and the required gear costs around $150 and up. A record-
ing made this way may not offer the sound quality of a professional mul-
titrack recording. But it may be good enough—especially if the recording 
is just for yourself or your friends. 
 Other options for stereo recording include an iPad with a record-
ing app, or a laptop computer with recording software. These setups cost 
about $350 and up. We’ll look at the pros and cons of these options in 
a minute. 
 Stereo Systems versus Multitrack Systems 
 You can make live recordings either with stereo or multitrack techniques. 
Basically, a stereo recording system uses two mics (or a stereo mic) 
plugged into a stereo recorder. The mics pick up the group as a whole 
from several feet away, and the mic signals are recorded. A multitrack 
system uses several mics, each close to an instrument or singer. The mic 
signals are sent to a multitrack recorder. One track might be a recording 
of the lead vocal, another track might be the sax, another the kick drum, 
and so on. You mix the tracks back in the studio. 
 1 
 GEAR FOR LIVE RECORDING 

4
Gear for Live Recording
 Stereo recording is easy and cheap, and it captures the sound as 
heard in the audience (including the room reverberation and background 
noise). You could call it a “documentary” or “audio snapshot” recording. 
The multitrack approach is more challenging and expensive, but it offers 
a cleaner, more commercial sound, probably with a well-balanced mix. 
It’s the most common method for professional recordings of live pop 
music. 
 Please note: Focal Press has a website (www.focalpress.com/cw/bartlett) for 
this book with audio clips that demonstrate some techniques discussed in the 
book. Website track 27 compares a stereo recording to a multitrack recording of a 
blues band. Website track 28 is the same for a jazz trio. 
 A stereo recording can sound very good if no PA system is in use—
but most bands use a PA. When you record the band you’re also recording 
the sound of the PA speakers. Thus, the mix or balance you get depends 
on the PA engineer’s skill. 
 The ﬁ rst half of this chapter focuses on stereo recording systems, 
while the second half covers multitrack systems. 
 Stereo Recording Systems 
   Figure 1-1   shows the parts of a typical stereo recording system. Placed 
several feet from the performers, the mics pick up the group, room sound 
reﬂ ections, and any background noise. The sound and signals move or 
ﬂ ow from start to ﬁ nish (left to right in  Figure 1-1 ). 
    MUSICAL 
INSTRUMENTS
NOISE
RECORDER
DIRECT SOUND
WALLS
     MICS
(TOP VIEW)
REFLECTED SOUND
 (audience, traffic, and
  air conditioning)
 Figure 1-1 Signal ﬂ ow in a typical stereo recording system. 

5
Gear for Live Recording 1
 This is the signal ﬂ ow shown in  Figure 1-1 : 
 1. Musical instruments produce sound. 
 2. Background noise and room reverberation add to the musicians’ sound. 
 3. Microphones pick up the total sound and change it into electrical 
signals. 
 4. Mic choice and placement affect the tone quality (bass and treble), 
the stereo effect, and the amount of background noise and room 
reverberation that are picked up. 
 5. Mic cables carry the mic signals to the recorder. Some mics plug 
directly into the recorder, or are built in. 
 6. The recorder makes a stereo recording of the left- and right-mic signals. 
 If you can record off the PA mixing board, all you need is a portable stereo 
recorder and cables. Some digital consoles can record the stereo mix to a 
USB thumb drive. 
 Equipment for Stereo Recording 
 Let’s describe in detail the gear you need to make a simple stereo recording. 
 Microphones 
 A microphone changes sound into an electrical signal. Classiﬁ ed by 
how that is done, there are three types of mics for recording: condenser, 
dynamic, and ribbon. 
 Condenser, Dynamic, and Ribbon Types 
 C ondenser mics typically give a clear, detailed, natural sound. They are 
the preferred choice for stereo recording. Condenser mics require a power 
supply to work, explained later under the heading “Mic Connectors, 
Powering, and Cables.” 
 Dynamic  (moving-coil) mics work without any power supply. They 
are rugged and reliable. Most dynamic mics do not sound as clear and 
natural as condensers and are less sensitive, so dynamics are seldom used 
for stereo recording. 
 A  ribbon  mic provides a smooth sound that many people prefer, and 
it works without power, but it’s delicate and expensive. 

6
Gear for Live Recording
 Sound Pickup Patterns (Polar Patterns) 
 Microphones also differ in the way they respond to sounds coming from 
different directions: 
 • An  omnidirectional ( omni ) mic picks up sound equally well in all 
directions. 
 • A  unidirectional  mic picks up sound best in front of the microphone. 
It partly rejects sounds to the sides and rear of the mic. Three types of 
unidirectional mic are  cardioid, supercardioid,  and  hypercardioid. Each 
has a progressively narrower pickup pattern. 
 • A  bidirectional (ﬁ gure-eight) mic picks up best in two directions: in 
front of and behind the microphone. Most ribbon mics have a bidirec-
tional polar pattern. Mics with this pattern are used in the Blumlein 
stereo technique, described in  Chapter 9 . Figure 8-1 shows various 
polar patterns, and  Chapter 8 describes polar patterns in more detail. 
 Which mic pattern is right for your needs? Choose omni mics when you 
need all-around pickup, extra deep bass, less handling noise and wind 
noise, or binaural (headworn) miking for headphone playback. Choose 
cardioid mics when you need sharp stereo imaging, rejection of room 
reverberation, and rejection of background noise and feedback. 
 Mic Connectors, Powering, and Cables 
 As shown in   Figure 1-2  , mics come with either an XLR (3-pin) connector or a 
phone plug (called a “jack” plug outside the US). Most condenser mics with 
an XLR connector are powered by 12–48 volts of  phantom power.  This power-
ing can be supplied by a phantom power supply, mic preamp, recorder, or 
mixer. Condenser mics with a phone plug (jack plug) either use an internal 
battery, or they receive  DC bias or plug-in power  (3–10 V DC) from a recorder. 
Some mics can be powered by a separate  battery module,  which helps the mic 
pick up loud sound sources with less distortion (increased dynamic range). 
 A mic with an XLR connector has what’s called a “low-impedance bal-
anced” output. Such a mic can be used with very long mic cables without 
picking up hum or losing treble. A mic with a phone plug (jack plug outside 
the US) comes with a short, permanently attached cable or no cable. This 
type of mic has an unbalanced output that is low-to-medium impedance. 
 What if your mics have XLR connectors, but your recorder or mic 
preamp has one or two phone jacks (sockets outside the United States)? 
You’ll need an adapter cable, shown in  Figure 1-3 . 

Mic
Male XLR
connector
Female XLR
 connector
    Female XLR
connector in mixer
Male XLR
connector
Mic
Mini phone
    plug
Mini phone
   jack in
  recorder
Mic cable
Mic cable
 Figure 1-2  (Top): Male and female XLR connectors. (Bottom): Phone plug and 
phone jack connectors (jack plug and socket connectors outside the US). 
2
1
3
2
1
3
2
1
3
Shield
Cable
Inside each female
   XLR connector
To mic
Tip
Ring
Sleeve
T
R
S
Inside female
XLR connectors
To phantom
power supply
outputs
Left
Right
4.7 µF capacitors
to block plug-in
power
Positive toward
phone plug
Left
Right
RECORDER HAS TWO 1/4" PHONE JACKS WITH PHANTOM POWER
RECORDER HAS ONE 1/8" PHONE JACK WITH PLUG-IN POWER
1/4" balanced phone plug
1/8" stereo phone plug
Shield
To recorder or
preamp mic input
To recorder or
preamp mic input
Shields
Cables
Shield
 Figure 1-3 XLR-to-phone adapters (XLR-to-jack adapters outside the US). 

8
Gear for Live Recording
 Cheap 1/8-inch phone plugs (3.5 mm jack plugs) with thin gold plat-
ing are actually less reliable than plugs with nickel plating. Thin gold plat-
ing wears off quickly, exposing a brass surface that makes poor contact. 
 USB microphones have a built-in analog-to-digital converter and a 
USB connector, which you plug into a computer’s USB port. That lets you 
record the mic’s signal with recording software. 
 Special-Purpose Mics 
 A  stereo mic  has two mic capsules in the same housing for convenient 
stereo recording. A  mini stereo mic  plugs directly into some portable 
digital recorders and Apple iOS devices. Mini stereo mics that use car-
dioid mic capsules tend to have less bass and more noise (hiss) than 
larger stereo mics. A headworn  binaural mic  has two miniature omni 
condenser mics that you wear in or near your ears; you play back the 
recording on headphones.  Chapter 12  lists the websites of all these 
types of microphones. 
 You can make yourself a decent stereo or binaural mic for experi-
menting. Purchase some JLIelectronics JLI-61A omni mic capsules for 
$1.67 each. Get an adapter cable with a 1/8-inch stereo plug (3.5 mm ste-
reo jack plug outside the US) and two RCA (phono) plugs. Cut off the two 
RCA (phono) plugs and solder the wires to the mics. If you want mics that 
are ruggeder, of higher quality, and better looking, check out the commer-
cial mic websites listed in  Chapter 12 . 
 Microphone Mounting Styles 
 Microphones also can be classiﬁ ed by the way they mount onto objects: 
 • Portable handheld recorders have mics built in. 
 • Plug-in mics plug into an iPhone, iPod Touch or iPad. 
 • A stand-mounted stereo mic attaches to a mic stand. A stereo pair 
of mics can mount on a stereo bar (stereo mic adapter), which holds 
two mics on a single mic stand. However, mic stands might be too 
large to be acceptable in certain venues, and they are a hassle to 
carry. 
 • “Goosenoose” stereo mics are worn around the neck. 
 • Clip-on mics can be clipped to a shirt at the shoulders or to eyeglass 
earpieces. 

9
Gear for Live Recording 1
 • Headband-mounted mics are attached to a headband. Some head-
band products have “street” styling. 
 • Desktop mics sit a few inches above a desk or a table, so they might 
pick up an unnatural, ﬁ ltered sound due to surface-sound reﬂ ections. 
 • Boundary mics eliminate that problem by mounting directly on surfaces. 
 Mic Specs 
 When you shop for a mic, consider these other speciﬁ cations on the mic 
data sheet: 
 •  Signal-to-noise (S/N) ratio:  67 dB at 1 Pa (Pascal) is fair; 74 dB is very 
good; 84 is excellent. But 67 dB is good enough if you are recording 
loud rock concerts. 
 •  Frequency response range: 100 Hz to 15 kHz is fair; 50 Hz to 18 kHz is 
very good; 20 Hz to 20 kHz is excellent. 
 •  Frequency response tolerance: ± 6 dB is fair; ± 3 dB is very good; ± 1 dB 
is excellent. 
 •  Maximum sound pressure level:  100 dB is fair; 110 dB is very good; 
120 dB is excellent (high enough for rock concerts). 
 •  Size:  Small-diameter microphones (under 1/2 inch) tend to be rel-
atively noisy, but this may not be a problem if you are recording 
loud music. Omni mics of any size can have excellent bass. They 
pick up deeper bass than small cardioid mics, which sound “thin” 
by comparison. 
 •  Accessories:  A foam windscreen for recording outdoors is a handy 
accessory. If your mic lacks a windscreen, you can purchase one from 
Radio Shack (or a music store) and cut it to ﬁ t. A stereo bar or stereo 
mic adapter mounts a pair of mics on a single mic stand for conve-
nient stereo miking. 
 Stereo Recording Devices 
 Having covered mics for stereo recording, let’s move on to the recording 
device itself. We’ll look at three different types: a ﬂ ash-memory hand-
held recorder, an iPad with a recording app, and a laptop computer with 
recording software. 

10
Gear for Live Recording
 Flash-Memory Handheld Recorder 
 A ﬂ ash-memory handheld recorder (  Figures 1-4   and   1-5  ) is a portable 
digital recorder with no moving parts. Also called a  solid-state recorder, it 
records into a ﬂ ash-memory Secure Digital (SD or SDHC) card. A 2 GB SD 
card can store 2 hours of 24-bit/44.1 kHz WAV audio ﬁ les. Flash-memory 
recorders can record MP3 ﬁ les or uncompressed PCM WAV ﬁ les (which 
are CD quality or better). 
 These recorders have a number of features to consider. Power comes 
from replaceable or rechargeable batteries. Available mic connectors are 
 Figure 1-4 Zoom H4n, an example of a handheld recorder (courtesy: Zoom). 

11
Gear for Live Recording 1
XLR, 1/4-inch phone (6.35 mm socket), or 1/8-inch phone (3.5 mm socket), 
with or without 48 V phantom power or plug-in power. Most recorders 
come with built-in stereo or surround microphones. Prices range from 
$100 to $1000. 
 After making a recording, you connect the USB (Universal Serial Bus) 
port in the recorder to the USB port in a computer. The recorder shows 
up as a storage device on your computer screen. You drag-and-drop the 
recorded sound ﬁ les to the computer’s hard drive for editing and CD 
burning. The ﬁ les transfer in a few minutes. Then the ﬂ ash-memory card 
is empty, free to make more recordings. 
 Nearly all ﬂ ash-memory recorders include a mic-gain switch to 
accommodate both quiet and loud sound sources. Low gain or low ampli-
ﬁ cation (0–15 dB) is for recording loud sounds (rock concerts); medium 
gain (25 dB) is for recording medium sounds (acoustic music, lectures, or 
rehearsals); and high gain (50 dB) is for recording quiet sounds (nature, 
quiet talking). Most recorders have AGC (automatic-gain control), which 
sets the recording level automatically depending on how loud the sound 
is. Some units include a limiter to prevent recording above 0 dB level, 
which otherwise would cause distortion. 
 Google “handheld recorders” to see some examples. 
 Figure 1-5  Tascam HD-P2, an example of a stereo ﬂ ash-memory recorder 
(courtesy: Tascam). 

12
Gear for Live Recording
 iPad with a Recording App and a Plug-In Stereo Mic 
 Apple’s iOS devices, including the iPhone, iPod Touch and iPad, have 
loads of recording-app options. On the iPad, simply tap the App Store 
icon and search for recording apps. Install one, plug in a stereo iOS mic 
and start recording. 
 A few stereo recording apps are GarageBand, Sonoma Wire Works’ 
StudioTrack, RODE Rec, StudioMini XL, Tascam PCM Recorder, and 
n-Track Studio (http://ntrack.com). 
 Some stereo microphones are designed to plug directly into an iPad 
or other iOS devices. Google  “ iOS stereo microphones. ”  Six examples are 
the Rode iXY, IK Multimedia iRig Mic, Blue Mikey Digital, Blue Spark 
Digital, Zoom iQ5, and Tascam iM2. 
 If you want to use microphones with XLR connectors, you’ll also 
need an audio interface that plugs into your iOS device. Three examples 
are the Tascam iU2, the Alesis iO Dock, and the Focusrite iTrack Dock. 
Some devices connect to an iPad with a Lightning connector, some use 
30-pin, and some use both. 
 Laptop, Recording Software, and Audio Interface 
 Another stereo recording device is a laptop computer with recording soft-
ware (  Figure 1-6  ). To get audio into the computer, use a two-channel  audio 
interface.  This is a mic preamp with two mic inputs and a USB or FireWire 
port, which connects to a similar port in your laptop.  
    TWO-CHANNEL 
AUDIO INTERFACE
LAPTOP COMPUTER
Plug into the USB or FireWire 
port (in a PCMCIA or CardBus
card or in the laptop)
 Figure 1-6  An audio interface plugged into a laptop computer via a USB 
connection. 

13
Gear for Live Recording 1
 An example of a two-channel USB audio interface is the M-Audio 
M-Track ( Figure 1-7 ) (www.m-audio.com). 
 You can plug a USB stereo microphone directly into a laptop; then 
no audio interface is necessary. Google “USB stereo microphone” to ﬁ nd 
some models. 
 If your computer lacks a USB or FireWire port, get a USB or FireWire 
PC Card adapter. It is a PCMCIA card with a USB or FireWire port. Plug 
the card into your laptop and connect its port to the audio interface. 
Another option is a CardBus card, which is an advanced PCMCIA card 
with faster speed. 
 USB or FireWire PC Card adapters and CardBus adapters can be 
found in a Google search. Recording software is described under the 
heading “Computer DAW Recording Systems” later in this chapter. 
 When a laptop recording is done, you are ready to edit it. You don’t 
have to transfer the WAV ﬁ les from recorder to computer as you do with 
other methods. 
 Figure 1-7  M-Audio M-Track, an example of a two-channel audio interface 
(courtesy: M-Audio). 

14
Gear for Live Recording
 Headphones or Earphones 
 Headphones or earphones let you know whether the mics are working 
correctly, and let you hear what the mics are picking up. Room noises 
that you wouldn’t otherwise notice become obvious when you listen on 
headphones. Also listen for buzzes, distortion, and crackles from bad 
cables or connections. If the band and PA are loud, it is hard to hear 
what’s being recorded unless you use  isolating headphones (Remote Audio 
HN-7506) or  isolating earphones  (Etymotic ER-4S and ER-4P; Shure SE 
series.) 
 Multitrack Recording Systems 
 Now we get into professional multitrack techniques, which can offer bet-
ter sound than stereo techniques.   Figure 1-8   shows the parts of a typical 
multitrack recording system. Several mics are used,  each close to an instru-
ment or singer. This is the signal ﬂ ow: 
 1. Musical instruments produce sound. 
 2. Microphones pick up the sound and change it into electrical signals. 
Because each mic is close to its instrument, it picks up very little 
background noise and room reverberation. 
 3. Mic choice and placement affect the tone quality and the amount of 
leakage that are picked up. ( Leakage is unwanted sound from instru-
ments other than the one the mic is aimed at.) 
 4. Mic cables carry the mic signals. 
 5. The mic cables plug into a  stage box:  a box with multiple mic connectors. 
Wired to the connectors is a long multiconductor cable called a  snake.  
 6. The snake connectors plug into a mixing console. If the musical 
event is reproduced over a sound system, the mixing console is the 
one used for sound reinforcement. It ampliﬁ es each mic signal up to 
a higher voltage called  line level. 
 7. The ampliﬁ ed signal of each mic appears at an  insert-send connector 
on the PA mixer. 
 8. Cables plugged into the insert-send connectors carry the signal to a 
multitrack HD recorder. 
 9. The multitrack unit records each mic’s signal on a different track. 
You mix these tracks later back in your studio. 

15
Gear for Live Recording 1
 An alternative method is to connect the mic cables to a  splitter, which 
sends each mic’s signal to two mixers: one for PA and the other for record-
ing. You could omit the recording mixer and use an audio interface and 
laptop instead. We cover this equipment later in this chapter. 
 Equipment for Multitrack Recording 
 Let’s explore each piece of gear from left to right in  Figure 1-8 . 
 Microphones and Mic Accessories 
 Mics for multitrack recording have an XLR connector and a low-impedance-
balanced output.  Condenser mics sound great on cymbals, acoustic instru-
ments, and vocals.  Dynamic  mics with a “presence peak,” a rise in the 
frequency response around 5 kHz, are a popular choice for guitar amps, 
drums, and vocals.  Ribbon  mics sound good on vocals, horns, and guitar 
amps. Of course, you can use any mic on any instrument if it sounds good 
to you. Just keep ribbon mics out of kick drums because the ribbon is fragile. 
 Omni mics are seldom used for miking pop groups because omnis 
pick up too much feedback from the PA system and too much leakage 
(unless they are placed very close to the sound source). Unidirectional 
mics (cardioid, supercardioid, and hypercardioid) pick up less feedback 
and leakage. 
 If you are recording a band that has a high-quality sound system, 
typically the sound company’s mics supply the signals for your recording. 
 A  direct box  (DI) can replace a microphone on electric instruments. It 
has a phone jack (socket) input and a male XLR output. You connect the 
MICS
DIRECT BOX
SNAKE
MIXER
STAGE
 BOX
   MULTI-
   TRACK
RECORDER
CABLES
Insert
sends
Track
inputs
 Figure 1-8 Signal ﬂ ow in a typical multitrack recording system. 

16
Gear for Live Recording
input to an electric bass, synthesizer, or instrument pickup; and connect 
the output to a mic connector on the stage box. 
 Two handy accessories reduce mic noises: foam  pop ﬁ lters  or wind-
screens on vocal mics keep “P-pops” under control, while  shock mounts 
reduce pickup of mic-stand thumps and ﬂ oor thumps.  Clamp-on mic 
mounts  attach to drums to reduce clutter. They are made by Mic-Eze 
(www.ac-cetera.com) and others. 
 Mic stands  and  booms  hold the microphones and let you position 
them as desired. A mic stand has a heavy metal base, or a tripod, that 
supports a vertical pipe. At the top of the pipe is a rotating clutch that lets 
you adjust the height of a smaller telescoping pipe inside the large one. 
The top of the small pipe has a standard 5/8-inch 27 thread, which screws 
into a mic stand adapter (mic clip). 
 A  boom  is a long horizontal pipe that attaches to the vertical pipe. 
The angle and length of the boom are adjustable. The end of the boom 
is threaded to accept a mic clip, and the opposite end is weighted to bal-
ance the weight of the microphone. The boom has a lever to loosen or 
tighten it. Be sure to tighten each mic stand securely so it doesn’t droop 
during a performance. 
 You can make stand adjustments easy for a perfomer playing an 
instrument: orient the boom horizontally (like a “T” as viewed from the 
audience). Then the player can raise or lower the mic and move it in or 
out just by grabbing the mic. 
 Stage Box and Snake 
 You could run several mic cables from each mic to the PA mixer, but that 
is unnecessary. Plug the mic cables into a  stage box.  This is a metal box 
or chassis with several female XLR connectors (  Figure 1-9  ). Each con-
nector has a number. The box is wired to a single multiconductor cable 
called a  snake.  At the far end of the snake, the cable divides into several 
individual cables, each with a corresponding numbered male XLR-type 
connector. These male XLRs plug into the PA mixer mic inputs, or into 
an audio interface.   
 A digital snake has a stage box wired to a multichannel A/D 
(analog-to-digital) converter, which sends digital audio via an Ethernet 
CAT5 cable to a digital mixing console. That digital audio can be in vari-
ous protocol formats such as AES/EBU (AES3), AES50, MADI (AES10), 
and so on. 

17
Gear for Live Recording 1
 Mixer 
 A mixer or mixing console (board or desk) is an audio control panel. Each 
mic connector from the snake plugs into its own preamp built into the 
mixer. These preamps amplify the signals of all the microphones up to 
line level so they can feed the line inputs of a multitrack recorder. 
 Here are the main controls in each mixer input module (mic channel) 
(see  Figure 1-10 ):  
 •  Input trim or gain:  Used to adjust the mic preamp gain (ampliﬁ ca-
tion). This affects your recording level on each track. 
 •  Fader:  A sliding volume control for each microphone. This affects 
the listening level but not the recording level. If you have a separate 
recording mixer, you can use its faders to set up a monitor mix over 
headphones. 
 •  EQ or equalization:  Control of the bass, midrange, and treble. Low-
frequency EQ controls the bass (roughly 20–150 Hz); mid-frequency 
EQ controls the midbass (150–500 Hz) through the upper midrange 
(2–5 kHz); and high-frequency EQ controls the treble (5–20 kHz). 
These controls do not affect the recording unless the signals sent to 
the recorder are post-EQ. 
 •  Pan:  If you have a separate recording mixer, its pan pots let you place 
the instruments left, center, and right in the stereo stage. Then you 
STAGE BOX
CONNECTORS TO
MIC CABLES
SNAKE
CONNECTORS TO MIXER
 Figure 1-9 A stage box and snake. 

18
Gear for Live Recording
can distinguish their sounds more easily. Panning affects what you 
are monitoring, but does not affect the multitrack recording. 
 •  Aux (Auxiliary):  In the PA console, the aux knobs are used either to 
control the amount of effect (reverb, echo, chorus, and so on) for each 
mic, or to set up monitor mixes. The aux controls don’t affect the 
recording. 
 •  Assign:  Lets you route or send each mic signal to the desired output 
channel (bus). For example, you might want to send all the drum 
mics to two buses that feed two recorder tracks. Those tracks would 
record the stereo drum mix. 
 •  Insert connectors:  These connect to the multitrack recorder inputs. 
Each channel’s insert-send connector supplies an ampliﬁ ed line-
level signal from the mic plugged into that channel. Sometimes the 
PA engineer plugs a compressor into an insert connector to auto-
matically control the volume of a microphone. 
 Multitrack Recorder 
 This device accepts the signals from the mixer insert connectors and records 
each signal on a separate track. The unit records up to 24 or 48 tracks on 
 Figure 1-10  Typical input module in a mixing console. 

19
Gear for Live Recording 1
a built-in hard drive (  Figure 1-11  ), USB hard drive, or USB thumb drive. 
Recorders can be linked to get more recording tracks. Some examples are 
the Cymatic Audio LR-1, JoeCo BlackBox, IZ Technology Radar, and Tas-
cam X-48 MKII.  
 After the recording is done, you can mix the tracks in your studio 
with an external mixer or copy the track recordings to a computer for 
editing and mixing. 
 Here’s an easy way to record multitrack from your mixer: the Jam-
Hub Tracker MT16 accepts up to 16 signals from your mixer’s direct-out 
or insert-send jacks. Those signals are recorded on an SD card as WAV 
ﬁ les. Then you can copy those tracks to your computer via USB, or upload 
them to BandLab, the shared Cloud recording studio. 
 Instead of the mixer and recorder, you might use one of these sys-
tems instead ( Figure 1-12 ): 
 • A recorder-mixer (a mixer with a built-in multitrack recorder). 
 • A mixer feeding an audio interface, connected by USB or FireWire to 
a laptop. 
 • A mixer with a FireWire or USB port connected to a laptop. 
 • An audio interface with several mic channels, connected by USB or 
FireWire to a laptop. 
 An iPad with multitrack recording software can substitute for a laptop 
computer. Let’s look at each option in   Figure 1-12 . 
 Recorder-Mixer Option 
 Shown in   Figure 1-13  , a recorder-mixer is an alternative to a separate 
multitrack recorder and mixer. Also called a stand-alone digital audio 
Hard drives
Level meters
LCD display
Controls
 Figure 1-11 A multitrack HD recorder. 

PA MIXER OR RECORDING MIXER
        MULTITRACK
HARD-DRIVE RECORDER
CABLES
Insert
sends
Track
inputs
Track inputs
Mic inputs
Insert
sends
RECORDER-MIXER
 MIXER WITH USB or FIREWIRE PORT
USB or FIREWIRE 
        CABLE
CABLES
LAPTOP COMPUTER
LAPTOP COMPUTER
AUDIO INTERFACE
LAPTOP COMPUTER
AUDIO INTERFACE
WITH MIC INPUTS
Line
inputs
Insert
sends
MIXER
Insert
sends
Insert
sends
MIC SPLITTER to RECORDING SNAKE
COMPUTER
DAW
SYSTEMS
OR
MIC SPLITTER
Insert 
sends
RECORDING 
    SNAKE
PA MIXER
 Figure 1-12  Several multitrack recording systems. All offer the same sound 
quality. The snake connectors plug into any one of these systems. 

21
Gear for Live Recording 1
workstation (DAW), portable studio, or digital multitracker; it combines a 
mixer and multitrack recorder in a single package. Some units can record 
and play up to 36 tracks. The mixer includes faders (volume controls) for 
mixing, EQ or tone controls, and aux sends for effects (such as reverb). An 
LCD screen displays recording levels, waveforms for editing, and other 
functions. For on-location work, you might need to record on all tracks at 
once, so make sure the recorder-mixer can do that. Some manufacturers 
of recorder-mixers are Roland, Korg, Fostex, Boss, Yamaha, Zoom, Akai, 
and Tascam. 
 Recording a small group with a recorder-mixer can be easy, very por-
table, and low-cost. You could use your own mics on instruments and 
split any vocal mics to the PA mixer and your recorder-mixer. Simply plug 
in the mics, set levels, and hit Record. 
 Sidebar: Digital Audio Basics 
 Like an analog tape deck, a digital recorder puts audio on a magnetic 
medium, but in a different way. Here’s what happens in the most com-
mon digital recording method—pulse code modulation or PCM: 
 1. The signal from your mixer, preamp or audio interface (  Figure 1-14A  ) 
is run through a lowpass ﬁ lter (anti-aliasing ﬁ lter), which removes all 
frequencies above 20 kHz. 
 Figure 1-13  Zoom R16, an example of a recorder-mixer (courtesy: Samsontech). 

22
Gear for Live Recording
 2. Next, the filtered signal passes through an analog-to-digital 
(A/D) converter. This converter measures (samples) the volt-
age of the audio waveform several thousand times a second 
( Figure 1-14B ). 
 3. Each time the waveform is measured, a binary number (made 
of “1”s and “0”s) is generated that represents the voltage of the 
waveform at the instant it is measured (  Figure 1-14C  ). This pro-
cess is called quantization. Each 1 and 0 is called a bit, which 
stands for binary digit. The more bits that are used to represent 
each measurement (the higher the bit depth), the more accurate 
the measurement is. 
 4. These binary numbers are stored on the recording medium as a 
modulated square wave recorded at maximum level (  Figure 1-14D  ). 
For example, the numbers can be stored magnetically on a hard disk 
or ﬂ ash-memory card. 
 Figure 1-14 Analog-to-digital conversion. 
(A) The audio waveform enters
the A/D converter.
(B) The voltage is measured or
sampled at regular intervals.
(C) The voltage measurements are 
converted to binary numbers.
(D) The numbers are stored on 
the recording medium.
Volts
Time
0.6
0.4
0.2
0.0
–0.2
–0.4
–0.6
Volts
0.6
0.4
0.2
0.0
–0.2
–0.4
–0.6
Sampling
 interval
Time
-1111
-1110
-1101
-1100
-1011
-1010
-1001
-1000
  0000
  1001
  1010
  1011
  1100
  1101
  1110
  1111
-1110 -1100
-1011
-1010
1010
1011
1100 1111
Last value
First value
1100
0000
0000
0000

23
Gear for Live Recording 1
 The playback process is the reverse: 
 1. The binary numbers are read from the recording medium, such as a 
hard disk ( Figure 1-15A ). 
 2. A digital-to-analog (D/A) converter translates the numbers back 
into an analog signal made of voltage steps (  Figure 1-15B ). 
 3. An anti-imaging ﬁ lter (lowpass ﬁ lter, smoothing ﬁ lter) smoothes 
the steps in the analog signal, resulting in the original analog signal 
( Figure 1-15C ). 
 The curve or shape of the analog waveform between samples is re-
created by the anti-imaging ﬁ lter. Nothing is lost . . . digital recording 
does not slice up your music! With recordings made on a CD, the process 
does ﬁ lter out signals above 22 kHz, but we can’t hear that high anyway. 
 Bit Depth 
 As we said, the audio signal is measured many thousand times a second 
to generate a string of binary numbers (called words). The longer each 
 Figure 1-15 Digital-to-analog conversion. 
(C) The voltage steps are 
smoothed out (filtered out).
(B) The binary numbers are converted
to voltage steps.
(A) The numbers are read from 
the recording medium.
-1111
-1110
-1101
-1100
-1011
-1010
-1001
-1000
  0000
  1001
  1010
  1011
  1100
  1101
  1110
  1111
-1110 -1100
-1011
-1010
1010
1011
1100 1111
Last value
First value
1100
0000
0000
0000
Volts
Time
0.6
0.4
0.2
0.0
–0.2
–0.4
–0.6
Volts
0.6
0.4
0.2
0.0
–0.2
–0.4
–0.6

24
Gear for Live Recording
word is (the more bits it has), the greater is the accuracy of each mea-
surement. Short words give poor resolution of the signal voltage (high 
distortion); long words give good resolution (low distortion). Bit depth or 
resolution are other terms for word length. 
 A word length of 16 bits is adequate (but not optimum) for hi-ﬁ  
reproduction. It is the current standard for CDs. Most digital record-
ers offer 24-bit word lengths or higher. More bits sound smoother, more 
transparent, and less noisy; but need more disk storage space. 
 Even though CDs are a 16-bit format, they sound better when made 
from 24-bit recordings. During mastering, you add dither (low-level 
noise) to the 24-bit recording, then export or save it as a 16-bit recording. 
You copy the 16-bit recording to CD. The dither helps the 16-bit record-
ing sound more like the 24-bit recording. In other words, dither lets you 
retain most of the quality and resolution that you recorded at 24 bits, even 
though the recording ends up on a 16-bit CD. 
 Suppose you record with a 24-bit word length. All signal levels in 
that recording have 24-bit resolution. Even low-level signals use all the 
bits—but most of the bits are zeroes. 
 Sampling Rate 
 Sampling rate or sampling frequency is the rate at which the A/D con-
verter samples or measures the analog signal while recording. For 
example, a rate of 48 kHz is 48,000 samples per second; that is, 48,000 
measurements are generated for each second of sound. The higher the 
sampling rate, the wider the frequency response of the recording. 
 The sampling rate for high-quality audio can be 44.1 kHz, 48 kHz, 
88.2 kHz, 96 kHz, or 192 kHz. CD quality is 44.1 kHz/16 bits. A 96 kHz sam-
pling rate should be used on DVD. State-of-the-art formats include DXD 
(Digital eXtreme Deﬁ nition) at 352.8 kHz/24 bits, Super Audio CD, and lin-
ear PCM at 192 kHz/24 bits (but you’re more likely to see 96 kHz/24 bits). 
 When syncing an audio recording to video, be sure to match the 
sampling rate of the video (usually 48 kHz). 
 In summary, a digital audio system samples the analog signal sev-
eral thousand times a second, and quantizes (assigns a value to) each 
sample. Sampling rate affects the high-frequency response. Bit depth 
affects the dynamic range, noise, and distortion. Typical recording for-
mats are 24-bit/44.1 kHz or 24/96. CDs must be 16-bit/44.1 kHz. Record-
ing software can do sample-rate conversion if needed. 
 An alternative to PCM is 1-bit (bitstream) encoding with a 2.8224 MHz 
or higher sampling rate. This is the Direct Stream Digital (DSD) process 

25
Gear for Live Recording 1
used in the Super Audio CD and in some Korg portable digital recorders. 
DSD offers a frequency response from DC to 100 kHz with 120 dB dynamic 
range and a very smooth, analog-like sound. 
 Computer DAW Recording Systems 
 Another multitrack recording system is a computer DAW. A computer with 
recording software can record multiple tracks of audio. For on-location 
work, a laptop computer is easily portable. Or you might use a desktop 
computer in a shock-mounted rack. 
 Caution:  A computer is more likely to crash than a hardware multi-
track recorder or recorder-mixer. 
 PC Audiolabs (www.pcaudiolabs.com) and Sweetwater Sound 
(www.sweetwater.com) offer custom and preconﬁ gured DAW systems. 
 To record 24 or more tracks at once, the computer must be fast. At a 
minimum it should have a 2 GHz CPU, 4 GB RAM, an operating system 
that provides 32-bit or higher data paths, and a USB 2.0 or FireWire port. 
That port can be in the computer, or it can be part of a CardBus FireWire or 
USB 2.0/USB 3.0 adapter. Or use an external SSD or HD for the audio data.  
Ideally that HD has a rotational spindle speed of 7200 rpm or greater and an 
internal buffer of at least 8 MB. When you are done recording, you can plug 
that HD into your studio DAW for editing and mixing. 
 According to tests at Sweetwater Labs, a Mac mini or PowerMac 
dual G5 can record at least 80 48 kHz/24-bit tracks simultaneously via 
FireWire to an internal SATA HD. 
 A slow computer might cause clicks or dropouts (silent spots) in the 
audio, and the recording might stop. If you can’t record enough tracks at 
the same time without dropouts or clicks, try this: 
 • Increase the I/O buffer size in your recording software. 
 • Disable Wi-ﬁ  and LAN. 
 • Google “How to lower hardware acceleration.” Reduce Hardware 
Acceleration as much as you can without degrading the display of 
your audio program. 
 • Defragment your audio hard drive. 
 • Record at 44.1 kHz instead of higher rates. 
 • As a last option, record at 16-bit resolution instead of 24 bits. 
 • Check out www.tweak3d.net/threads/archived-tweaks-articles-
and-how-to-guides.25091/. Google “optimize your computer for 
audio” or “speed up your computer.” 

26
Gear for Live Recording
 Some examples of recording software are Avid Pro Tools (the indus-
try standard), Adobe Audition, MOTU Digital Performer (Mac only), 
Steinberg Cubase and Nuendo, Apple GarageBand, Cakewalk Sonar 
and Home Studio; Emagic Logic (for Mac only), sonycreativesoftware.
com Vegas Pro, cockos.com Reaper, protracksrecording.com, BIAS Deck, 
Magix Samplitude, Mackie Tracktion, Magix Sequoia, RML Labs SAW 
Studio, and Audacity (which is freeware). 
 Several types of DAWs are explained below. 
 DAW Option 1: Mixer, Interface, and Laptop 
 In this system, the mixer feeds a  multichannel audio interface  connected to a 
computer running audio recording software (  Figure 1-16  ). The PA mixer 
or recording mixer ampliﬁ es each mic signal up to a line-level signal, and 
those line-level signals plug into the line inputs in the multichannel audio 
interface. The interface gets audio into and out of the computer. It converts 
the analog signals from the mixer to digital and feeds that digital signal 
to the computer’s USB/FireWire port or USB/FireWire CardBus adapter.  
 Google “audio interface” to see various models. Examples: M-Audio, 
RME, Lynx, Roland, Maya, Apogee, Avid, Presonus, Focusrite, Tascam, 
Akai, Alesis, and Lexicon. USB or FireWire CardBus adapters can be 
found in a Google search as well. 
 Interfaces for multitrack recording typically have eight mic channels. 
You can add more interfaces to record more tracks. A typical connection 
is Interface 1 > FireWire > Interface 2 > FireWire > Laptop FireWire port. 
 DAW Option 2: USB or FireWire Mixer and a Laptop 
 A few mixers have a FireWire or USB port that connects to a computer 
for multitrack recording (  Figure 1-13  , middle). The signal of each input 
AUDIO INTERFACE
LAPTOP COMPUTER
TO PCI SLOT, USB PORT,
OR FIREWIRE PORT
 FROM MIXER
INSERT SENDS
 Figure 1-16 Mixer to interface to laptop. 

27
Gear for Live Recording 1
channel on the mixer (plus the stereo mix) is sent to your computer, and 
a stereo output returns from the computer for monitoring. It’s like hav-
ing a mixer and a multichannel interface in one compact chassis. Exam-
ples are Mackie Onyx Series, Alesis MultiMix Series, Phonic Helix Board 
23 FireWire MKII, and Yamaha MW USB Series Mixing Studios. 
 DAW Option 3: Interface with Mic Inputs and a Laptop 
 In a setup using a mic splitter (explained next), you can use any one of the 
recording systems described before. Another option is to use one or more 
audio interfaces, each with eight built-in mic preamps (  Figure 1-13  , bot-
tom). Plug the recording snake into the interface mic inputs and connect 
the interface to a computer. You might prefer to use several mic preamps 
(maybe in one chassis) feeding an audio interface or an HD recorder. 
 DAW Option 4: iOS Recording System 
 Apple’s iOS devices, including the iPhone and iPad, can run multitrack 
recording apps, which you can access via the App Store icon. 
 For serious on-location multitrack recording, I recommend using 
a 64 GB iPad3 or higher, running iOS 6, 7, or higher. If your iPad 
has 64 GB of storage, you can record nearly six hours of 24 tracks of 
24-bit/44.1 kHz audio. 
 A high-end recording app is Multitrack DAW by Harmonic Dog, 
which can record up to eight tracks and play 24 tracks simultaneously. 
Another is Wavemachine Labs Auria (  Figures 1-17   and   1-18  ). It can record 
up to 24 tracks and play up to 48 tracks simultaneously, at up to 96 kHz 
sampling rate. Price is only $50 at http://auriaapp.com/Products/auria.  
 How do you connect an audio interface to an iPad? Some inter-
faces connect directly to the iPad’s 30-pin dock port. With most inter-
faces, you connect their USB port to an Apple Camera Connection Kit 
plugged into the iPad. Another option is an Apple USB-to-30-pin cable 
or USB-to-Lightning cable. Note that some interfaces require a powered 
USB hub to work properly. Auria lists some recommended interfaces on 
its website. 
 Although Auria can do automated mixes with effects, the iPad’s 
small screen can make that difﬁ cult. You might prefer to use Auria only 
for recording, then copy the recorded tracks to a computer for editing and 
mixing. Export the Auria session as AAF format through iTunes or Drop-
box and import into your DAW. See www.pro-tools-expert.com/home-
page/2012/7/18/export-auria-ipad-daw-session-to-pro-tools.html. 

 Figure 1-18  Auria edit window. 
 Figure 1-17  Auria mix window. 

29
Gear for Live Recording 1
 Mic Splitter 
 Another way to make multitrack recordings is with a mic splitter. You 
connect the mic cables to a multichannel splitter, which sends each mic’s 
signal to two or more destinations: the recording system’s snake and the 
PA mixer’s snake (  Figure 1-19  ). The splitter has one XLR input and two or 
three XLR outputs per mic, sort of like a Y-cord. 
 Using a splitter is the most expensive recording method, but it’s the 
most professional. It gives you and the PA operator independent control 
of the recording level and signal ﬂ ow of each microphone. 
 Inside the splitter, the input XLR is wired to a 1:1 transformer 
(   Figure 1-20  ). The splitter has three feeds or outputs: one direct and two 
isolated. Wired directly to the mic input connector, the direct XLR output 
connects to the mixer that supplies phantom power.   
 The two transformer-isolated XLR outputs connect to the other mix-
ers. Since the transformer electrically isolates the three mixers, phantom 
power from one mixer can’t get into the other mixers. Neither can any 
radio-frequency interference (RFI). Ground-lift switches in the splitter are 
used to prevent ground loops and their resulting hum. 
 Good transformer-isolated mic splitters typically cost $30–$80 
per channel. Some companies that sell splitters are www.procosound.
com, www.rapcohorizon.com, www.radialeng.com, www.rolls.com, 
MICS
DIRECT BOX
SNAKE
RECORDING MIXER
STAGE
 BOX
MULTITRACK
 RECORDER
CABLES
Insert
sends
Track
inputs
SNAKE
PA MIXER
MIC SPLITTER
   AMPLIFIERS/
    SPEAKERS
   
STAGE
 BOX
 Figure 1-19  Splitting the mic signals to the recording mixer and PA mixer. 

30
Gear for Live Recording
and www.whirlwindusa.com. For elaborate productions, multichan-
nel mic splitters (such as the Whirlwind SB series) offer up to 24 inputs 
in a single stage box. 
 Because high-quality mic splitters are expensive, you might want to 
rent them. Some PA consoles have mic splitters built in. Low-cost trans-
former splitters are not worth purchasing because their small transform-
ers have poor bass response. 
 To save money some people use Y-splitters (  Figure 1-21  ) instead of 
transformer-isolated splitters. The resistors shown in   Figure 1-21   prevent 
mic loading and improve isolation, while the ground lifts prevent ground 
loops and block phantom power. Unlike a transformer splitter, a Y-splitter 
does not block RFI.  
 Another way to save money: use your own mics for the instruments, 
and split only the vocal mics with 1-channel splitters. 
 If you employ the mic-splitter approach, you can use any of the 
recording systems described before. For example, you could plug the 
recording snake into: 
 • A recorder-mixer. 
 • A mixer feeding a multirack HD recorder. 
 • A USB or FireWire mixer feeding a laptop. 
 • An audio interface with mic preamps feeding a laptop or iPad. 
 Figure 1-20 Transformer-isolated microphone splitter. 

31
Gear for Live Recording 1
 Headphones, Earphones, or Speakers 
 Headphones, earphones, or monitor speakers in an isolated room let you 
check the signal quality. Listen for hum, crackles, hiss, RFI, and distortion. 
See the heading “Headphones/Earphones” in the section “Equipment for 
Stereo Recording.” 
 Purchasing Equipment 
 Some Web stores in the US that sell audio gear are www.bswusa.com, www.
sweetwater.com, www.musiciansfriend.com, www.americanmusicalsupply.
com, www.wwbw.com, www.guitarcenter.com, www.samash.com, www.
samedaymusic.com, and www.zzounds.com. Some United Kingdom (UK) 
sites are www.10outof10.co.uk, www.dv247.com, www.playrecord.net, and 
www.bonnersmusic.co.uk. If you search for the product model on www.
google.com/shopping you get a list of vendors and prices. Audio and music 
stores in your locale are another option. 
 So far we have covered the equipment for stereo and multitrack 
recording. Next we explore recording techniques in  Chapter 2 . 
1
2
3
DIRECT FEED: MALE XLR
TO MIXER SUPPLYING
PHANTOM
GND LIFT
1
2
3
1
2
3
INPUT: FEMALE
XLR TO MIC
R
R
R
R
All resistors R
are 600 ohms,
1% metal film.
Shields
MALE XLR
TO OTHER MIXER
51 ohms
0.01 uF
RFI filter
 Figure 1-21 A resistor-isolated Y-cable (Y-splitter or hard-wired splitter). 

This page intentionally left blank

33
 2 
 RECORDING TECHNIQUES 
FROM SIMPLE TO COMPLEX 
 You can record pop-music concerts in several ways. Listed below is a 
range of techniques from simple to elaborate. In general, sound quality 
improves as the recording setup becomes more complex: 
 • Record off the board (PA mixer) into a stereo recorder. 
 • Record with two mics into a stereo recorder. For example, use a 
handheld recorder with built-in mics. 
 • Record with a four-tracker: record with a stereo mic on tracks 1 and 
2, while recording the PA mixer output on tracks 3 and 4. Mix the 
tracks later. 
 • Feed the PA mixer’s insert-send signals to a multitrack recorder. Edit 
and mix the recording back in your studio. 
 • Use a mic splitter on stage to feed the PA mixer, monitor mixer, and 
recording mixer. Record to multitrack. Edit and mix the recording 
back in your studio. 
 • Do the multitrack recording in a van or truck. 
 We’ll describe each method and list its pros, cons, and equipment. Then 
you can decide what’s best for you and try it out. 

34
Recording Techniques from Simple to Complex
 Record Off the Board 
 Let’s start with the easiest technique: connect the PA mixing console (board) 
to a stereo recorder. Some people record performances off the board at 
gigs, festivals, or concerts, and—let’s hope, with the artists’ permission—
they put the recordings on the Web as MP3 ﬁ les. 
 Pros: Simple, cheap, and fast. 
 Cons:  Quality depends on the PA company’s mics and board. The 
mix depends on the mixer operator’s skill—you take what he or she 
sends you. 
 Equipment:  Mixer-to-recorder cables, stereo recorder, and head-
phones. Your stereo recorder might be a handheld recorder, iPad, or 
a computer and audio interface. 
 Using cables with the appropriate mating connectors, connect the PA 
mixer’s tape-out or 2-track-out connectors to your stereo recorder’s line 
input(s). If your recorder’s line input is a stereo mini phone jack, use an 
adapter cable: either two 1/4-inch phone plugs to a stereo mini phone or 
two RCA connectors to a stereo mini phone. They are available at Radio 
Shack and other electronic suppliers. Outside the US, if your recorder’s line 
input is a stereo mini socket, use an adapter cable: either two 6.35-mm jack 
plugs to a stereo mini jack, or two phono connectors to a stereo mini jack. 
 If your recording device has balanced line-level inputs (female XLR 
or TRS, tip–ring–sleeve), connect those inputs to some spare master out-
puts on the PA mixer. Another place to connect is the insert-send connec-
tors of the master output channels. 
 Caution:  If you plug into an insert-send connector, you will kill the 
PA mixer’s output signal unless you plug in halfway, to the ﬁ rst click. If 
that doesn’t work, get two Y-cables with phone plugs (called “jack plugs” 
outside the US). At each mixer output channel, insert the Y-cable fully into 
the insert-send connector. Connect one leg of the Y to the insert-return con-
nector. Connect the other leg of the Y to your recording device line input. 
 Digital consoles make live recordings easy. Most can record their 
main L + R outputs to a USB thumb drive. 
 The recorded mix might be poor when you record off the board. 
Here’s why: the sound mixer hears a combination of the band’s instru-
ments, the stage monitors, and the house speakers. So the board mix 
is intended to  augment  the sound of the instruments and monitors on 
stage—not to sound good by itself. For example, if the bass-guitar amp is 
very loud on stage, it will be turned down in the mix that you record off 

35
Recording Techniques from Simple to Complex 2
the board. Vocals will be turned up high in the mix because they can’t be 
heard otherwise. Board mixes can sound good if there is not much sound 
coming off the stage (as with acoustic groups), and the venue is large or 
outdoors. It helps to monitor the board mix with headphones or isolating 
earphones to hear what you’re recording. 
 Record with a Handheld Recorder 
 Here’s another simple method. Connect two mics to a portable stereo 
recorder or use the recorder’s built-in mics (  Figure 2-1  ). Place the mics 
or recorder in front of the group, set the recording level, and hit Record. 
You’ll capture how the band sounds to an audience. 
 Pros:  Simple, fast, and cheap. If you place the mics a few feet from 
a folk group or jazz group without a PA system, the sound can be 
quite good. 
 Cons: When you record a group with a handheld recorder, the sound 
will be distant and muddy compared to using a mic on each instru-
ment and vocal in a multitrack recording. You’ll pick up the sound 
of the PA speakers as well as the band itself. Also, the balance you 
get depends on the skill of the PA mixer operator.  Website track 27 
 Figure 2-1  Recording a pop group with two microphones. 
RECORDER
    MICS
  top view
 (see text)
   MUSICIANS
     top view
      PA
SPEAKER
      PA
SPEAKER

36
Recording Techniques from Simple to Complex
compares a stereo recording to a multitrack recording of a blues band in a 
club. Website track 28 is the same for a jazz group in a small room. 
 Equipment:  Handheld recorder, headphones or earphones, mic 
cables and mics (optional). Four microphone options are listed below: 
 • Mics that are built into the handheld recorder. 
 • A stereo mic on a mic stand. 
 • Two stand-mounted mics of the same model number ( Chapter 9  
shows how to arrange a pair of mics to record in stereo). 
 • Two headworn mini mics. These can be clipped to eyeglass 
frames, either in the ear or on the temples. They make a bin-
aural recording that sounds very realistic when heard over 
headphones. You could clip the mics to your shoulders instead. 
Websites for all these types are listed in  Chapter 12 . 
 Before going on the road, install fresh batteries and clean the connectors with 
isopropyl alcohol or DeOxit from Caig Labs (www.caig.com). Connect all 
your equipment and make a trial recording to make sure everything works. 
Approximate recording levels can be set in advance by recording loud music 
from your home stereo speakers or studio monitors. Then place the stereo 
recording system in a backpack, suitcase, or cloth bag. You might even stow 
your gear in a hunter’s vest or photographer’s vest with pockets. 
 If possible, record in a room where the audience is attentive and 
the background noise is low. You might visit some potential venues in 
advance to check out the noise and acoustics. Avoid very live rooms 
because they can make the recording muddy. 
 To prevent crackles or loss of audio, strain-relieve the mic cable. Use 
tape or Velcro to fasten the mic cable to the recorder, so that the cable 
doesn’t get pulled out accidentally. Check that the mic connector is 
plugged in all the way. 
 If your recorder can record MP3 or WAV ﬁ les, consider these options. 
Unlike MP3 ﬁ les, WAV ﬁ les are uncompressed, linear PCM recordings. 
WAV recordings sound better than MP3 recordings, but WAV ﬁ les con-
sume a lot of memory: about 10 MB/minute for a 16-bit/44.1 kHz stereo 
recording. If you select WAV, set the word length or resolution: 16-bit is CD 
quality and 24-bit is higher quality. Also set the sampling rate: 44.1 kHz 
is CD quality (good enough for professional recordings), 96 kHz is higher 
quality, and 192 kHz is state-of-the-art quality. 
 MP3 ﬁ les typically consume about 1/11 to 1/4 as much memory 
as WAV ﬁ les, depending on the bitrate setting (in kilobits per second or 

37
Recording Techniques from Simple to Complex 2
kbps). A setting of 128 kbps results in good audio quality (cassette qual-
ity), 192 kbps is very good (near-CD quality), and 256–320 kbps is excel-
lent (CD quality). 
 Listed below are approximate recording times on a 1 GB ﬂ ash-memory 
card (which can record a 930 MB ﬁ le). Double these times for a 2 GB card. 
 24-bit/44.1 kHz stereo WAV 
 1.0 hour 
 16-bit/44.1 kHz stereo WAV 
 1.5 hours 
 256 kbps stereo MP3 
 9.0 hours 
 128 kbps stereo MP3 
16.5 hours 
 Be sure you have enough free space on your ﬂ ash-memory card before 
going on location. 
 When you monitor the mics with headphones or earphones, you’ll 
hear the room acoustics and any background noise (audience, air condi-
tioning, trafﬁ c). 
 The closer the mics are to the group, the clearer and cleaner the 
sound will be. In other words, close placement captures more of the music 
and less of the room reverb and background noise. Try to place the mics 
as close as possible to the stage, where you still pick up the house PA 
speakers well, about a stage-width away from the stage (  Figure 2-1  ). An 
alternative placement is near one PA loudspeaker, picking up both the 
speaker and the group. You might even locate at the house mixing console 
because the balance there is what the sound mixer intended. 
 Other placement considerations: keep the mics away from any bars 
or other noise sources. Some concerts have a tapers’ section where you 
are allowed to place your mics. If you are recording your own band, you 
could place the recorder and mics on stage (on a stool or mic stand) and 
record the sound of the monitor speakers. 
 Another way to cut down on room sound is to use a pair of cardioid 
or supercardioid mics aimed straight ahead at the musicians and spaced 
about two feet apart (or headworn). This will give a closer, clearer sound 
than an XY stereo mic or a pair of omni mics. 
 If there are dancers near the stage and the ceiling is low, you might try 
boundary mics (such as two Pressure Zone Microphones (PZMs)) gaffer-
taped to the ceiling or mini mics hung from the ceiling. 
 To record a small folk group or acoustic jazz group, place the mics 
about 3 to 6 feet from the ensemble (  Figure 2-2  ). If the group plays in a 
circle (as in an outdoor jam), try placing omni mics in the center. Or just 
walk around with the mics while monitoring the mics over headphones. 

38
Recording Techniques from Simple to Complex
Find a spot where you hear a good balance and put the mics there. During 
a break in the music, ask the musicians’ permission to record them.  
 Use AC power, not batteries, for critical recordings. You don’t want 
to risk having batteries die in the middle of a recording. 
 The recorder might have a record-level switch labeled “manual” and 
“auto.” Set it to “manual” in order to retain the dynamics of the performance. 
If the switch is labeled “AGC” (Automatic Gain Control), set it to “off.” 
 The recorder also has a meter that shows recording level. Set the level 
so that the meter reads about –6 dB maximum. That allows some head-
room for surprises. Peak levels up to 0 dB are okay, but levels above 0 dB 
result in distortion. (Some handheld recorders include a limiter that pre-
vents recording levels above 0 dB.) After setting the recording level, leave 
it alone as much as possible. If you must change the level, do so slowly and 
try to follow the dynamics of the music. 
 If your recording is distorted even though you did not exceed a 0 dB 
recording level, either the sound was louder than the mic could handle (not 
likely), or the mic signal overloaded the mic preamp in the recorder. You 
can prevent mic-preamp overload with a mic-gain switch or pad (attenu-
ator), available in most recorders. Use low gain for loud sound sources 
(rock bands); use high gain for quiet sound sources (acoustic musicians). 
If you need to set the recording-level control less than 1/3 up to achieve a 
0 dB recording level, use the low-gain setting or switch in the pad. 
 If you are using large-diaphragm condenser mics plugged into a 
phantom power supply, you might need to plug the output of the sup-
ply into the recorder line inputs—rather than the mic inputs—to pre-
vent distortion. 
 Figure 2-2 A method of stereo miking a jazz group. 
BASS
DRUMS
PIANO
SAX
STEREO MIC PAIR

39
Recording Techniques from Simple to Complex 2
 You might be able to record an acoustic group on location without a 
PA system or audience. This gives you the freedom to make adjustments 
to improve the sound. Here is a suggested procedure: 
 1. Adjust the acoustics around the instruments. If the room is too live 
(reverberant), put up some packing blankets, comforters, rugs, 
acoustic foam, or cushions. Often a good-sounding spot for the 
musicians is near the center of a large room. 
 2. Place the musicians around the stereo mic pair where you want 
them to appear in the recording. For example, you might place two 
singing guitarists on the left and right, with bass in the center. 
 3. Experiment with microphone height to vary the vocal/guitar bal-
ance. Try different miking distances to vary the amount of ambience 
or room sound. A 3- to 6-foot distance is typical. 
 4. While the musicians are playing and during playback, monitor the 
mic signals with headphones. If some instruments or vocalists are 
too quiet, move them closer to the mics, and vice versa, until the bal-
ance sounds right. 
 5. If someone makes a mistake, either record another take of the entire 
tune, or record starting from a few bars before the mistake and edit 
the takes together later. 
 Figure 2-3 shows a clever recording method using two omnidirectional 
mics placed to get a good balance of a jazz group. Engineer Gert Palm-
crantz used this technique to record the Ludvig Berghe Trio. 
 Once you copy the recorded ﬁ les to your computer hard drive, you can 
edit the recording and adjust its tonal balance (equalize it) with digital audio 
 Figure 2-3 A method of stereo miking a jazz group. 
BASS
PIANO
OMNI MIC PAIR
DRUMS

40
Recording Techniques from Simple to Complex
workstation (DAW) recording software or with Harmonic Balancer soft-
ware. You might cut 1–6 dB around 300 Hz to reduce boomy reverb and get a 
clearer recording. Mini stereo mics using cardioid mic capsules tend to sound 
weak in the bass, but you can boost 3–6 dB at 50–100 Hz to compensate (or 
whatever amount sounds right). Headworn mics often need a cut around 
3 kHz to compensate for the effect of the head. If you have recorded outdoors 
and the sound is too dry, try adding a little reverb and see if it helps. 
 You’ll ﬁ nd some online resources about live stereo recording. The 
Steam Powered Preservation Society (www.thespps.org) records folk-
music jams and concerts, and posts MP3 ﬁ les of the recordings along with 
detailed information on the recording equipment and techniques. Sonic 
Studios (www.sonicstudios.com/tips.htm) offers a wide array of tips and 
equipment for this type of recording. Mike Billingsley wrote some ﬁ ne 
papers on stereo miking in Preprints 2788 (A-1) and 2791 (A-2), available 
from www.aes.org. 
 Record with a Four-Tracker 
 This method is fairly simple and provides good sound. Put a stereo mic 
or mic pair at the front-of-house (FOH) PA mixer position. Plug the mic 
connectors into mic inputs 1 and 2 of a four-track recorder-mixer (or any 
size recorder-mixer). Connect the PA mixer’s tape output or two-track 
outputs to line inputs 3 and 4 (  Figure 2-4  ). Mix the recording to stereo 
back in the studio. 
 Pros: Fairly simple, cheap, and fast. Good sound quality. 
 Cons:  You can’t control the mix among instruments. Sound quality 
depends on the PA system and the sound mixer’s skill. 
 Figure 2-4 Recording two mics and a PA mix on a four-track recorder-mixer. 
CARDIOID MICS
FOUR-TRACK 
RECORDER-MIXER
PA MIXER
Tape out
or spare
main out

41
Recording Techniques from Simple to Complex 2
 Equipment:  Stereo mic or matched mic pair, stereo bar, mic stand, 
mic cables, mixer-to-recorder cables, headphones, recorder-mixer 
(such as models by Tascam, Boss, Zoom, Fostex, or Korg). 
 The FOH mics pick up the band as the audience hears it: lots of room 
reverb, lots of bass, but rather muddy or distant. The PA mixer output 
sounds tight and clear, but typically is thin in the bass. Luckily, a mix of all 
four tracks can sound surprisingly good. Tracks 1 and 2 provide ambience 
and bass; tracks 3 and 4 provide deﬁ nition and clarity. 
 When you mix the four tracks, you might hear an echo because the 
FOH mics pick up the band with a delay (caused by the sound travel 
time from stage to mics). To remove the echo, import all the tracks into 
digital recording software, and delay the PA mixer tracks by sliding them 
a little to the right. Align the waveforms of the mic tracks and mixer 
tracks at big peaks. 
 Connect the PA Mixer Insert Sends 
to a Multitrack Recorder 
 Now we get into professional techniques. This is an easy way to record, and 
it offers very good sound quality with minimal equipment (  Figure 2-5  ). Use 
the mixer gain trims to set recording levels during the sound check. Edit 
and mix the recording back in the studio.  
 Pros:  Easy, fast, moderate cost, and sounds great. You don’t have 
to mix while recording—instead, mix and monitor back in your 
studio. 
 Figure 2-5  Connecting insert sends to a multitrack recorder provides great 
sound and easy setup. 
PA MIXER
MULTITRACK
RECORDER(S)
INSERT
SENDS*
*PLUG TIP/SLEEVE CONNECTOR
IN HALFWAY, OR WIRE TIP/RING 
TOGETHER
LINE
INPUTS

42
Recording Techniques from Simple to Complex
 Cons:  Sound quality depends on the PA company’s mics and mic 
preamps. You might have to ask the PA operator to adjust the gain 
trims during the show to prevent recorder overload. 
 Equipment:  Multitrack recorder and mixer-to-recorder cables (such 
as a short phone-to-phone snake, called “jack-to-jack” snake outside 
the US). The multitrack unit can be an HD, SSD, or SD recorder; a 
recorder-mixer, or an audio interface and laptop. 
 Connections 
 This section describes how to connect a multitrack recorder to a mixer’s 
insert-send connectors. 
 In making a multitrack remote recording, you usually want to record 
the signal of each mic on a different recorder track. You’ll mix those tracks 
later in the studio. 
 In the console there are several mic preampliﬁ ers, one per mic, which 
amplify the mic-level signal up to line level. For each mic channel, this line-
level signal typically appears at two connectors on the back of the mixer: 
 direct out and  insert send. That’s where to connect to the recorder inputs. 
 Usually the insert send is the best connector to use. Here’s why. Typi-
cally the direct-out signal is postfader (  Figure 2-6  ). This means the signal at 
the direct-out connector comes after the fader, so that the signal is affected 
by the fader (volume) settings. Any fader movements will show up on 
your recording, which is undesirable. It’s better to connect recorder tracks 
to insert sends. They are usually prefader, pre-EQ (pre-equalization). So 
any fader or EQ changes that the PA operator makes will not appear in 
your recording. However, any changes the PA operator makes in the trim 
settings during the show will affect your recording levels.  
 First, ﬁ nd out what kind of insert connectors the PA mixer has, 
and what kind of input connectors your multitrack recorder has. Buy or 
 Figure 2-6  Simpliﬁ ed signal ﬂ ow through part of a mixing console, showing 
insert and direct out. 

43
Recording Techniques from Simple to Complex 2
make some shielded cables (or a snake) that mate with those connec-
tors.   Figure 2-7   shows three ways to wire cables based on the type of 
insert connector.  
 Some boards have a single TRS insert connector per channel, instead 
of separate insert-send and insert-return connectors. Usually the tip is send 
and the ring is return. In the TRS connector that you plug into the TRS insert, 
wire tip and ring together, and also to the cable hot conductor (  Figure 2-7   
top). That way, the insert send goes directly to the insert return. If nothing is 
connected to the insert return, no mic signal goes through the mixer. 
 On some PA mixers with a TRS connector, you can use a TS (tip/
sleeve) connector (  Figure 2-7   middle). Plug it in halfway, to the ﬁ rst click, 
so you don’t break the signal path—the mic signal still goes through the 
PA mixer. If you plug it in all the way to the second click, the signal does 
not go through the PA mixer, just to the recorder. Cover the connections 
with a mixer-case cover or board, because someone could bump into the 
mixer and dislodge a cable. 
TO TIP-RING-SLEEVE
INSERT JACK
T
R
S
SLEEVE (GROUND)
SHIELD
TIP
(SEND)
RING
(RETURN)
WIRE TIP AND
RING TOGETHER
PHONE OR RCA
TO MULTITRACK IN
TO MACKIE
TIP-RING-SLEEVE
INSERT JACK
(INSERT ONLY TO FIRST CLICK)
TIP
(SEND)
T
S
SLEEVE (GROUND)
PHONE OR RCA
TO MULTITRACK IN
TO SEND JACK
TO RETURN JACK
MONITOR INPUT ON MULTITRACK
TO RECORDER IN
PHONE OR RCA
TO RECORDER OUT
 Figure 2-7  Three ways to wire cables based on the type of insert connector. 

44
Recording Techniques from Simple to Complex
 If the PA mixer has separate send and return insert connectors, 
connect the send to the recorder track input, and connect the return 
to the recorder track output (  Figure 2-7   bottom). If necessary, set your 
multitrack recorder to monitor the input analog signal, so that the PA 
mixer will receive a signal. Another option: use an insert snake with 
TRS connectors at the mixer end. Carry some TRS-to-dual-TS adapt-
ers to handle mixers that have separate connectors for insert send 
and return. 
 The insert sends are balanced or unbalanced, and the same is true of 
the recorder inputs. To connect balanced and unbalanced equipment cor-
rectly, see the article “Sound System Interconnection” on the Rane Web-
site, www.rane.com/note110.html. 
 You often encounter PA consoles where some insert sends are tied up 
with signal processors. You must use those channels’ direct-out connec-
tors instead, which usually are postfader (unless they can be switched to 
prefader). Another option is to “Y” the insert send to your recorder and 
to the processor input. Or, assign those mic channels to unused groups 
(buses) and get your recording signals from there. 
 Some rack-mounted mic preamps have insert connectors. Plug the 
mic snake into these preamps. Then connect the preamps’ inserts to the 
PA mixer line inputs, and connect the preamps’ outputs to your recording 
system’s line inputs. That way, any gain changes made on the PA console 
will not affect your recording. 
 Caution:  Any gain changes you make on the mic preamps will affect 
the PA levels. 
 If the PA mixer has a FireWire or USB (Universal Serial Bus) port, 
simply connect the port to a laptop that is running recording software. 
Set up the software to recognize the mixer as its input/output device. The 
signal from each mic channel goes to a separate track in the software. 
 What if you want to record several instruments on one track, such as 
a drum mix? Assign all the drum mics to one or two output buses in the 
PA mixer. Plug the bus out insert connector to the recorder track input. 
Use two buses for stereo. Adjust the faders to get a good drum mix. 
 Monitoring 
 To monitor the quality of the signals you’re recording, you generally let 
the PA system serve as your monitor system. But you may want to set up 
a monitor mix over isolating headphones or earphones so that you can 
hear more clearly. 

45
Recording Techniques from Simple to Complex 2
 Here is a suggested procedure. Connect all the recorder outputs to 
unused line inputs in the PA mixer, or to a separate mixer. Use those fad-
ers to set up a monitor mix. Assign them to an unused bus, and monitor 
that bus with headphones/earphones. If you can spare only a few inputs, 
plug in just one track at a time to check its sound quality. Listen closely for 
any hum, noise, or distortion. 
 Setting Levels 
 Set recording levels with the PA mixer’s gain-trim or input-attenuator 
knobs. This affects the levels in the PA mix, so be sure to discuss your trim 
adjustment in advance with the PA mixer operator. If you turn down an 
input trim, the PA operator must compensate by turning up that chan-
nel’s fader and monitor send. 
 As we said, if the PA operator changes the input gain trims during 
the show, these changes will appear in your recording. 
 Set recording levels before the concert during the sound check (if 
any!). It is better to set the levels a little too low than too high because dur-
ing mixdown you can reduce noise but not distortion. A suggested start-
ing level is –10 dBFS, which allows for surprises. Do not exceed 0 dBFS 
because the signal will distort. Also, if you set the recording level conser-
vatively, you are less likely to change the gain trims during the perfor-
mance. You don’t want to hassle the PA operator. 
 Some recording engineers run each insert-send signal through a 
potentiometer to set the recording level. By adjusting levels on a rack-
mounted panel of potentiometers, you don’t have to ask the PA operator 
to change the gain trims for you. Of course, if you are operating the PA 
console, you can set the gain trims yourself. 
 If you have a spare recorder, record a safety copy on it at the same 
time. This provides a backup in case one recorder fails. 
 Keep a log as you record, noting the counter times of tunes, level 
changes, sonic problems, and so on. You can refer to this log when you mix. 
 Digital Console Recording Facilities 
 Many digital consoles offer multitrack recording: simply connect a com-
puter, multitrack hard-drive recorder or multitrack USB recorder into the 
digital data stream. 
 For example, Avid’s VENUE console interfaces seamlessly with 
Pro Tools, the industry-standard software and hardware for recording. 

46
Recording Techniques from Simple to Complex
Playback of material from studio recordings tracked in Pro Tools is very 
easy to incorporate into a live show with VENUE systems. 
 Other examples: the Yamaha CL5 digital console includes Nuendo 
Live recording software, which you can control via the touch screen. 
The DiGiCo SD11 can record up to 56 channels to multitrack software. 
Allen & Heath’s Qu-16 streams channels 1 through 16, main L + R, and 
three selectable stereo pairs to a Mac. It also has a built-in 18-channel 
interface for recording on a USB hard drive. Recording is also easy 
with the Avid S3L, which offers up 64 audio channels over an AVB 
network, and 2-track USB recording/playback. The Roland M-200i can 
do 2-track USB recording and multitrack recording via its REAC port 
to a Roland R-1000 48-track recorder. PreSonus StudioLive 32.4.2 AI 
records via its FireWire port and also includes multitrack recording 
software. 
 Another digital console with recording facilities is the Solid State 
Logic SSL Live. Its MADI SSL Live-Recorder option is a rack-mounted 
device that records 64 tracks from the console’s mic preamps. The CADAC 
CDC Four includes a port for a FireWire expansion card which streams 
input channels to a computer DAW or a MADI interface card that con-
nects the console to a hardware multitrack recorder. Mackie’s DL-1608 
records its main L + R outputs to a docked iPad. 
 (This section’s information is from Craig Leerman’s article in  Live 
Sound International ’s Oct. 2013 issue.) 
 Splitting the Mic Signals 
 Now let’s consider a different way to make a multitrack recording. Plug 
each mic into a mic splitter, which sends the mic signal to two destina-
tions: the PA mixer and recording mixer. The splitter has one XLR input 
and two or more XLR outputs per mic. Some splitters have a third output, 
which goes to a monitor mixer, and a fourth output might go to a broad-
cast mixer. In  Chapter 1  we described transformer-isolated splitters and 
Y-cable splitters. 
 Splitting the mics is the most expensive method, but is the most pro-
fessional. It gives you and the PA operator independent control of each 
microphone’s recording level and signal ﬂ ow. 
 Pros:  Ultimate sound quality. Independent control at each mixer. 
Consistent sound. 
 Cons: Complicated. Expensive if transformer splitters are used. 

47
Recording Techniques from Simple to Complex 2
 Equipment:  Mic splitters, maybe mic preamps, mic cables, mic snake, 
recording mixer and multitrack recorder or audio interface and lap-
top, mixer-to-recorder cables, headphones or powered monitors. 
 There are many advantages of splitting the mic signals. You use your own 
mic preamps, so you are not dependent on the quality of the PA console 
mic preamps. Also, you are not hassling the operator about adjusting gain 
trims. Each mix engineer can work without interfering with the others. 
The FOH engineer can change trims, level, or EQ and it will have no effect 
on the signals going to the recording engineer. Another plus: a splitter 
provides consistent, unprocessed recordings of the mic signals. This con-
sistency makes it easy to edit between different performances. 
 What’s more, splitters let you use mic preamps on stage if you wish. 
That way, the cable from each mic to its preamp is short, which reduces 
hum and radio-frequency interference. 
 As shown in  Figure 2-8 , connect the outputs from all the splitter chan-
nels to the PA snake and to your recording snake. Connect the recording 
snake to your recording-mixer mic inputs. This mixer is used to set up 
your own monitor mix and to set the recording levels. Connect the record-
ing mixer’s insert sends to a multitrack recording system of your choice.  
 Here’s another method. Connect the recording snake to an audio 
interface. Use a USB cable to connect the interface to a laptop. Set record-
ing levels on the interface during sound check, set a monitor mix with the 
 Figure 2-8  Splitting the mic signals to the recording mixer and PA mixer. 
MICS
DIRECT BOX
SNAKE
RECORDING MIXER
STAGE
 BOX
MULTITRACK
 RECORDER
CABLES
Insert
sends
Track
inputs
SNAKE
PA MIXER
MIC SPLITTER
   AMPLIFIERS/
    SPEAKERS
   
STAGE
 BOX

48
Recording Techniques from Simple to Complex
 Figure 2-9 Radial Convertible V12 splitter-snake. 
interface software, and record the show to multitrack. After the recording 
is done, you can edit and mix the recording back in your studio. 
 Some companies make a combo splitter/snake. The Radial Convert-
ible V12 splitter-snake is shown in   Figure 2-9  . It includes multi-pin con-
nectors for sub-snakes.  

49
Recording Techniques from Simple to Complex 2
 Using Splitters 
 To use a splitter, plug each mic into a splitter input. Decide which mixer 
you want to supply phantom power (usually the PA mixer). Connect the 
splitter’s direct outputs to that mixer’s snake. Connect one set of isolated 
outputs to the recording snake, and another set to the monitor snake (if 
used). Plug the snakes into the mixers.   Figure 2-8   shows splitter connec-
tions to two mixers. 
 If the recording equipment is at FOH, a convenient location for the 
splitter is near the house console. 
 Splitters have a ground-lift switch on each output channel. This 
switch connects or disconnects (ﬂ oats) the cable shield from pin 1 of 
the XLR connector. When the ground-lift switches are set correctly, you 
should get no ground loops and their resulting buzzes. 
 How do you set the ground-lift switches? 
 1. First, turn  off  phantom power in each console. Turn down all the 
faders. 
 2. Make sure the direct feed’s ground-lift switches (if any) are set to 
 ground, not  lift. Otherwise phantom power won’t work. 
 3. Go to the mixer connected to the direct feed. Turn on the mixer, switch 
on phantom power, and bring up each fader to listen for a signal. 
 4. On the splitter, ﬁ nd the ground-lift switches for the recording-mixer 
feed. Set them to the position where you monitor the least hum and 
buzz at the recording mixer. 
 5. Repeat step 4 for the monitor mixer. 
 Multitrack Recording in a Truck 
 Here’s the ultimate setup. Each mic signal is split three ways to feed the stage 
boxes for the recording, reinforcement, and monitor consoles. A long snake 
is run to a recording truck or van parked outside the concert hall or club. 
In the truck, the snake connects to a mixing console plugged into a multi-
track recorder. The interior of the truck is acoustically treated, and powered 
Nearﬁ eld monitor speakers allow accurate monitoring of the signal. Design-
ing a recording truck is a subject in itself and is beyond the scope of this book. 
 Pros:  The truck contains the console, monitors, and recorders, so you 
don’t need to cart them into the venue. This saves setup time. Also, a 
truck provides a quiet, controlled monitoring environment. 

50
Recording Techniques from Simple to Complex
 Cons:  Complicated and expensive. Requires an AC power connec-
tion to the venue circuit-breaker panel or to the house power distro. 
 Equipment:  Mic splitters, maybe mic preamps, mic cables, mic snake, 
recording mixer, mixer-to-recorder cables, multitrack recorder or audio 
interfaces and a computer DAW, powered monitors, acoustically 
treated truck. 
 Although a recording truck offers several advantages, it might not be nec-
essary. And owning a truck might be an unsustainable business practice. 
 A remote truck or van has these requirements: 
 • An access panel for connecting a mic snake. 
 • A Uninterruptable Power Supply (UPS), maybe an electrical generator. 
 • An acoustically treated interior. Google “acoustic treatment.” 
 • A closed-circuit TV system to see what’s happening on stage. 
 • Walkie-talkies or headset communicators for crew inside the venue. 
 • A mixer to monitor the recording and to solo each mic. 
 • Backup USB or hard-drive recorder. 
 • Quiet air conditioning. 
 • Isolation boxes to prevent hum. Google “hum isolation.” 
 There you have a full choice of methods for recording live. Check out all 
the options, and you’ll ﬁ nd a system that works well for your style of 
recording and your budget. 
 

51
 Ready to record a live gig? The recording will go a lot more smoothly 
if you plan what you’re going to do. So sit down, grab a pen, and make 
some lists and diagrams as described here. We’ll go over the steps needed 
to plan a multitrack recording of a concert. 
 Selecting a Venue 
 If you can select a place for the recording, use a room where the audience 
is attentive and enthusiastic, and the background noise is minimal. Visit 
some potential venues and check out the noise and acoustics. A very live 
room with lots of reverb can make the recording muddy. Ideally the stage 
should be large so the performers can spread apart for better separation. 
A large stage also reduces leakage from wall reﬂ ections. 
 Musical Preparation 
 Before the recording, band members might want to upgrade guitar strings 
and drum heads, and repair the “action” and intonation of guitars. 
 3 
 BEFORE THE SESSION: 
 PLANNING 

52
Before the Session: Planning
 Long jams may be fun to play live, but they can get boring on a CD. 
Try to keep the songs short and focused. Be sure to check tuning before 
each song. 
 The band should consider playing some songs more than once. If a 
song is played poorly in the ﬁ rst set, the band can re-play it in a later set 
and re-record it. Put the best performance on the CD. If budget allows, 
record several shows and pick the best takes for the album or demo. The 
song sequence can be changed during mastering. 
 Preproduction Meeting 
 Call or meet with the PA company and the production company (or 
just the musicians) who are putting on the event. Find out the date 
of the event, location, phone numbers, and email addresses of every-
one involved, when the job starts, when you can get into the hall, 
when the second set starts, and other pertinent information. Decide 
who will provide the mic split, which system will be plugged in first, 
 second, and so on. Draw block diagrams for the audio system and 
 communications (comm) system. Determine who will provide the 
comm headphones. 
 If you’re using a mic splitter, work out the splitter feeds. The mixer 
getting the direct side of the split provides phantom power for condenser 
mics that are not powered on stage. If the house system has been in use 
for a long time, give its operators the direct side of the split. 
 Overloud stage monitors can ruin a recording, so work with the 
sound-reinforcement people and musicians toward a compromise. 
Explain to the musicians that if they can play with a low monitor level, 
it will help their recording. In-ear monitors are preferred over ﬂ oor 
monitors for live recording because then no monitor sound gets into 
the mics. 
 Make copies of the meeting notes for all participants. Don’t leave things 
unresolved. Know who is responsible for supplying what equipment. 
   Figure 3-1   shows a typical equipment layout worked out at a pre-
production meeting. There are three systems in use: sound-reinforcement, 
recording, and monitor mixing. The mic signals are split three ways to 
feed these systems. 
 A  stage plot  diagram shows where the musicians and their instru-
ments will be located on stage. It also indicates the monitor-speaker place-
ment and monitor-mix requirements. This book’s website has a sample 
stage plot. 

53
Before the Session: Planning 3
 Site Survey 
 If possible, visit the recording site in advance and go through the follow-
ing checklist: 
 • Check the AC power to make sure the voltage is adequate, the third 
pin is grounded, and the waveform is clean. 
 • Listen for ambient noises—ice machines, coolers, 400 Hz generators, 
heating pipes, air conditioning, nearby discos, etc. Try to have these 
noise sources under control by the day of the concert. 
 • Sketch dimensions of all rooms related to the job. Estimate distances 
for cable runs. 
 • Turn on the sound-reinforcement system to see if it functions okay 
by itself (no hum and so on). Turn the lighting on at various levels 
with the sound system on. Listen for buzzes. Try to correct any prob-
lem so that you don’t document bad PA sound on your recording. 
Figure 3-1 Typical layout for an on-location recording of a live concert.

54
Before the Session: Planning
 • Determine locations for any audience or ambience mics. Keep them 
away from air-conditioning ducts and noisy machinery. 
 • Plan your cable runs from the stage to the recording mixer. 
 • If you plan to hang mic cables, feel the supports for vibration. You 
may need microphone shock mounts. If there’s a breeze in the room, 
plan on taking windscreens. 
 • Make a ﬁ le on each recording venue that includes the dimensions 
and the location of the circuit breakers. 
 • Determine where the control room will be, if any. Find out what 
surrounds it—any noisy machinery? 
 • Visit the site when a crowd is there to see where there may be trafﬁ c 
problems. 
 Mic List 
 Now write down all the instruments and vocals in the band. If you want 
to put several mics on the drum kit, list each drum that you want to mike. 
As for keyboards, decide whether you want to record off each keyboard’s 
output, or off the keyboard mixer (if any). 
 Next, write down the mic or direct box you want to use on each 
instrument; for example: 
 1 
 Bass 
 DI 
 2 
 Kick 
 AKG-D112 
 3 
 Snare 
 Shure Beta 57 
 4 
 Hi-hat 
 AKG C451 
 5 
 Small-rack tom 
 57 
 6 
 Big-rack tom 
 57 
 7 
 Small-ﬂ oor tom 
 Sennheiser MD-421 
 8 
 Big-ﬂ oor tom 
 421 
 9 
 Cymbals overhead left 
 Shure SM81 
 10 
 Cymbals overhead right 
 SM81 
 11 
 Lead guitar 
 57 
 12 
 Rhythm guitar 
 57 
 13 
 Keyboard mixer 
 DI 
 14 
 Lead vocal 
 Beyer M88 
 15 
 Harmony vocal 
 Crown CM-311A 

55
Before the Session: Planning 3
 Make some copies of this mic list. At the gig, place one list by the stage 
box and the other by each mixer. The list will act as a guide to help you 
keep things organized. 
 Track Sheet 
 Next, decide what will go on each track of your multitrack recorder. If you 
have enough tracks, your job is easy: just assign each instrument or vocal 
to its own track. Bass to track 1, kick to track 2, and so on. Then your mic 
list is your track sheet. 
 What if you have more instruments than tracks? Suppose you have 
an eight-track recorder, but there are 15 instruments and vocals (includ-
ing each part of the drum set). You can combine several drum mics into 
one or two drum tracks (or combine several vocal mics into one or two 
vocal tracks). That is, you can set up a submix. 
 Let’s say the drum kit includes a snare, kick drum, two rack toms, 
two ﬂ oor toms, hi-hat, and cymbals. If you want to mike everything 
individually, that’s nine mics including two for the cymbals. But you 
don’t need to use nine tracks. Assign or group those mics to buses 1 
and 2 to create a stereo drum mix. Connect buses 1 and 2 to recorder 
tracks 1 and 2. At the sound check, you set up a submix of all the drum 
mics, and assign them to buses 1 and 2. You control the overall level of 
the drum mix with submaster faders 1 and 2 (also called bus faders or 
group faders). 
 Use tracks 3 through 8 for amps and vocals (as in the following 
example). Feed tracks 3–8 from insert sends. 
 Track/instrument 
 1. Drum mix  L 
 2. Drum mix  R 
 3. Bass 
 4. Lead guitar 
 5. Rhythm guitar 
 6. Keys mix 
 7. Lead vocal 
 8. Harmony vocal 

56
Before the Session: Planning
 Block Diagram 
 Now that your track assignments are planned, you can ﬁ gure out what 
equipment you’ll need. Draw a block diagram of your recording setup 
from input to output (  Figure 3-2  ). Include mics, mic stands, DI boxes, 
cables, snake, mixer, multitrack recorder(s), recording media, and power-
ing. On your diagram, label the cable connectors on each end so you’ll 
know what kind of cables to bring. It is a good idea to keep a ﬁ le of system 
block diagrams for various recording venues. 
 In   Figure 3-2  , the block diagram shows a typical recording method: 
feeding PA-console insert connectors to a multitrack hard-drive recorder. 
We’ll use this example throughout the rest of the chapter. 
 Equipment List 
 From your block diagram, generate a list of recording equipment. Based 
on   Figure 3-2  , you would need the following PA and recording gear (not 
including power amps and speakers): 
MICS
GUITAR CORD
DI
PA MIXER
MIC STANDS
MIC CABLES
SNAKE
INSERT 
SNAKE
Insert 
sends
Line 
inputs
MULTITRACK
 RECORDER
OUTLET STRIP
TO EXT. CORD
HARD DRIVES
(HD recorder or audio
 I/O feeding a laptop)
Figure 3-2 Example block diagram of recording setup.

57
Before the Session: Planning 3
 • Mics and mic cables. 
 • Mic stands and booms. 
 • Direct box. 
 • Guitar cable. 
 • Snake. 
 • PA mixer. 
 • An insert snake made of eight phone-to-phone cables (called “jack-
to-jack” cables outside the US). 
 • Multitrack recorder. 
 • Outlet strip. 
 • Extension cord. 
 • Hard drive (HD) (enough capacity for the duration of the gig). 
Also bring a spare external drive to backup the recording at the 
gig. 
 • Handheld recorder as another backup recording device. 
 • Uninterruptible power supply (UPS). Optional, but it can be a 
lifesaver. 
 Multitrack audio consumes a lot of disk storage space.   Table 3-1   shows 
the amount of HD or ﬂ ash-memory space needed for a 1-hour recording 
with various recording formats. 
Table 3-1 Storage required for a 1-hour recording.
Number of tracks
Bit depth
Sampling rate
Storage needed
 2
16
44.1kHz
606MB
 2
24
44.1kHz
909MB
 2
24
96kHz
1.9GB
 8
16
44.1kHz
2.4GB
 8
24
44.1kHz
3.6GB
 8
24
96kHz
7.7GB
16
16
44.1kHz
4.8GB
16
24
44.1kHz
7.1GB
16
24
96kHz
15.4GB
24
16
44.1kHz
7.1GB
24
24
44.1kHz
10.7GB
24
24
96kHz
23.3GB

58
Before the Session: Planning
  Don’t forget the incidentals: a pen, notebook, ﬂ ashlight, guitar picks, 
heavy-duty guitar cords, drum keys, mic pop ﬁ lters, gaffer tape, console 
tape, tuner, ear plugs, audio-connector adapters, audio ground-lift adapt-
ers, in-line pads, in-line polarity reversers, spare cables, gooseneck lights 
for the console, spare batteries, bottled water, and aspirin. 
 Let’s explain some of those terms. A ground-lift adapter disconnects 
the shield at one end of a line-level balanced cable, preventing hum from 
a ground loop (multiple connections to ground). A pad or attenuator 
reduces the signal level to prevent distortion from overly hot signals. A 
polarity reverser reverses the connections to XLR pins 2 and 3 to correct 
for mics that are wired in opposite polarity. 
 Instead of duct tape, use gaffer tape, which does not leave a sticky 
residue. Gaffer tape and console tape are available at www.markertek.
com. Also use light-colored electrical tape and a Sharpie pen to identify 
your mic stands and mic cables. 
 Bring a tool kit with screwdrivers, pliers, soldering iron and solder, 
AC-outlet checkers, fuses, a pocket radio to listen for interference, ferrite 
beads of various sizes for RFI (radio-frequency interference) suppression, 
canned air to shoot out dirt, cotton swabs and pipe cleaners, and De-Oxit 
from Caig Labs to remove oxide from connectors. 
 Consider packing cables with the equipment they plug into. Include 
backup (redundant) gear to use in case something fails. And of course, 
verify the operation of all gear before and after the gig. 
 Be sure to take a load-in/load-out checklist which documents every 
piece of equipment. Check off each piece of gear when you load it in and 
when you load it out. On this book’s website, see the Excel spreadsheet 
“Loadin-loadout checklist.xls.” 
 Have an insurance policy for your gear, both for on the road and at 
the venue. 
 If you will be recording in a foreign country, take some AC power 
adapters that can handle 50 Hz or 60 Hz power, 110 volt or 240 volt power 
(or other), and various types of AC outlets. Two good references are: 
http://en.wikipedia.org/wiki/AC_power_plugs_and_sockets and 
http://en.wikipedia.org/wiki/Mains_electricity .
 Preparing for Easier Setup 
 You want to make your setup as fast and easy as possible. Here are some 
tips to help this process. 

59
Before the Session: Planning 3
 Put It on Wheels 
 Mount your console and recorders in protective carrying cases. Install 
casters or swivel wheels under racks and carrying cases so you can roll 
them in. Rolling is so much easier than lifting and carrying. 
 You might permanently install the HD recorder in an SKB carrying 
case, which acts as a rack (www.gigcases.com). When a remote job comes 
up, just grab it and go. 
 A very helpful item is a dolly or wheeled cart to transport heavy 
equipment into the venue. Consider getting some lightweight tubular 
carts. Collapsible carts will store easily in your car or truck. One maker of 
equipment carts is Rock n Roller, which advertises in the  Musician’s Friend 
catalog, www.musiciansfriend.com. Another cart is the Remin Kart-a-
Bag, www.kart-a-bag.com. Also see www.gigcases.com. 
 Pack mics, headphones, and other small pieces in trunks or milk 
crates. You might want to build or buy a microphone case: a big box full of 
foam rubber with cutouts for all the mics. Or construct a wheeled cabinet 
with drawers for mics, DIs, and speaker cables. 
 Mic Mounts 
 If you’ll be recording a singer/guitarist, take a short mic mount that clamps 
onto the singer’s mic stand. Put the guitar mic in the mount. Also bring 
some short mounts to clamp onto drum rims and guitar amps. By using 
these mounts, you eliminate the weight and clutter of several mic stands. 
Some examples of short mounts are the Mic-Eze units by Ac-cetera (www.
ac-cetera.com). They have standard 5/8-27 threads (3/8 inches outside 
the US) and mic clamps that either spring shut or are screw tightened. 
 Snakes and Cables 
 You can store mic cables on a cable spool, available in the electrical depart-
ment of a hardware store. Wrap one mic cable around the spool, plug it 
into the next cable and wrap it, and so on. 
 A snake can be wrapped around a garden-hose spool, or coiled 
inside the bottom of a trunk (see   Figure 3-3  ). Commercial snake reels are 
made by such companies as Whirlwind (www.whirlwindusa.com), Pro 
Co Sound (www.procosound.com), and Hannay (www.hannay.com). 
 Use wire ties to join cables that you normally run together, such as 
PA sends and returns. 

60
Before the Session: Planning
 Snake hookup is quicker if the snake has a multi-pin twist-lock connec-
tor or “disconnect” (such as Whirlwind W1 or W2). This connector plugs 
into a mating connector that divides into several male XLRs. Those XLRs 
plug into the mixing console. Leave the XLRs in the console carrying case. 
You’ll ﬁ nd that the snake is easier to handle without the XLR pigtails. 
 For a clean, rapid hookup of drum mics, put a small snake near the 
drum kit and run it to the main stage box. Snakes are made by companies 
such as www.hosatech.com, www.procosound.com, www.whirlwind.
com, www.vaddio.com and www.livewire.com. 
 Check that all your mic cables are wired in the same polarity—pin 
2 hot. 
 In XLR-type cable connectors, do not connect pin 1 to the shell, or 
you may get ground loops when the shell contacts a metallic surface. 
 Label all your line-level cables on both ends according to what they 
plug into; for example, compressor in, track 12 out, power amp  ch.1 in, 
snake aux1 out. Or you might prefer to number the cables near their con-
nectors. Cover these labels with clear heat-shrink tubing. 
 Label both ends of each mic cable with the cable length. Put a drop of 
glue on each connector screw to temporarily lock it in place. 
 Multitrack Wiring 
 You can speed the PA console wiring by using a short phone-to-phone 
snake (jack-to-jack snake outside the US) between the console and your 
multitrack recorder. When packing, plug the snake into the multitrack 
recorder and coil the snake inside the recorder’s carrying case or rack. In 
other words, have all your equipment pre-wired. At the gig, pull out the 
snake and plug it into the console connectors. 
 Use an insert snake with TRS (tip–ring–sleeve) phone plugs (TRS 
jack plugs outside the US) at the console end. Carry some TRS-to-dual-TS 
Figure 3-3 Some cable-storage methods.

61
Before the Session: Planning 3
(tip–sleeve) adapters to handle consoles that have separate connectors for 
insert send and return. Short snakes for rack and multitrack connections 
are available at www.hosatech.com, www.rapcohorizon.com, and www.
procosound.com, among others. 
 Other Tips 
 Here are some more helpful hints for successful on-location recordings: 
 • Plan to use a talk-back mic from the board to the stage monitors dur-
ing sound checks. 
 • Hook up and use unfamiliar equipment before going on the road. 
Don’t experiment on the job. 
 • Consider recording with redundant (double) systems so you have a 
backup if one fails. 
 • Walkie-talkies are okay for preshow use, but don’t use them during 
the performance because they cause RFI. Use hard-wired communi-
cations headsets. Assistants can relay messages to and from the stage 
crew while you’re mixing. 
 • Allow for delays at airline security checkpoints. 
 • Get a public-liability insurance policy to protect yourself against 
lawsuits. 
 • Call the venue and ask directions to the load-in door. Make sure that 
someone will be there at setup time to let you in. Ask the custodian 
not to lock the circuit-breaker box the day of the recording. 
 • A few days before the session, check out the parking situation. 
 • Just before you go, check out all your equipment to make sure it’s 
working. 
 • Arrive several hours ahead of time for parking and setup. Expect 
failures—something always goes wrong, something unexpected. 
Allow 50% more time for troubleshooting than you think you’ll 
need. Have backup plans if equipment fails. 
 • In general, plan everything in advance so you can relax at the gig 
and have fun. 
 By following these suggestions, you should improve your efﬁ ciency—
and your recordings—at on-location sessions. 

62
Before the Session: Planning
 Some of the information in this chapter was derived from two work-
shops presented at the 79th convention of the Audio Engineering Society 
in October 1985. These workshops were titled “On the Repeal of Murphy’s 
Law—Interfacing Problem Solving, Planning, and General Efﬁ ciency On-
Location,” given by Paul Blakemore, Neil Muncy, and Skip Pizzi; and 
“Popular Music Recording Techniques,” given by Paul Blakemore, Dave 
Moulton, Neil Muncy, Skip Pizzi, and Curt Wittig.  

63
 4 
 AT THE SESSION:  SETUP 
AND RECORDING 
 This chapter describes some ways to conduct a multitrack recording ses-
sion of a concert. 
 You’ve arrived at the venue. After parking, ofﬂ oad your gear to a 
holding area, rather than onstage, because gear on stage will most likely 
need to be moved. 
 Learn the names of the PA company crew members and be friendly. 
These people can be your assets or your enemies. Think before you comment 
to them. Try to remain in the background and do not interfere with their nor-
mal way of doing things (e.g., take the secondary side of the split). A success-
ful remote engineer makes others feel comfortable and exudes conﬁ dence. 
 Power and Grounding Practice 
 At the job, you need to take special precautions with power distribution, 
interconnecting multiple sound systems, and electric-guitar grounding. 
 Power Distribution System 
 Consider buying, renting, or making your own single-phase power dis-
tribution system (distro). It will greatly reduce ground loops and increase 

64
At the Session: Setup and Recording 
reliability.   Figure 4-1   shows a suggested AC power distribution system. 
The amp rating of the distro’s main breaker box should exceed the cur-
rent drain of all the equipment that will be plugged into the distro sys-
tem. Ask the house electrician to hook up the distro’s power cable to the 
breaker box.   
 Furman makes a model ACD-100 AC Power Distro. It distributes a 
100-amp feed (from a breaker box) to ﬁ ve 20-amp, 120-V outlets with cir-
cuit breakers. The unit works on 120, 240, or 208 V three-phase circuits 
and provides spike and surge suppression. Furman’s website is www.
furmansound.com. 
 Power Source 
 If your recording system is a multitrack recorder that will connect to the 
PA mixer’s insert sends, simply set up next to the PA mixer and plug into 
the same AC outlet strip that the PA mixer is using. 
 If you split the mic signals, you can run your recording snake up to 
the front-of-house (FOH) position and set up your mixer or mic preamps 
there. Get AC power from the PA mixer’s power outlet strip so that your 
 Figure 4-1 An AC power distribution system for a touring sound system. 

65
At the Session: Setup and Recording  4
mixer and the PA mixer have the same ground voltage. This prevents 
hum when the two mixers are connected. Of course, you might prefer to 
locate in an isolated area for better monitoring. If you plug into a local 
AC outlet there, you should be able to make connections without ground 
loops and hum if the house power distribution system is well designed. 
Otherwise, run one or two thick (14 or 16 gauge) extension cords from 
the PA mixer’s outlet strip to your recording system. These cords may 
need to be 100–200 feet long. Plug AC outlet strips into the extension 
cord, then plug all your equipment into the outlet strips. 
 If you’re using a remote truck, ﬁ nd a source of power that can handle 
the truck’s power requirements, usually at a breaker panel. Some newer 
clubs have separate breaker boxes for sound, lights, and a remote truck. 
Find out whether you’ll need a union electrician to make those connec-
tions (US only). Label your breakers. 
 Check that your AC power source is not shared with lighting dim-
mers or heavy machinery; these devices can cause noises or buzzes in the 
audio. You might want to use a power conditioner with an AC isolation 
transformer. 
 The industry-standard power connector for high-current applica-
tions in the US is the Cam-lok, a large cylindrical connector. Male and 
female Cam-loks join together and lock when you twist the connector 
ring. Distro systems and power cables with Cam-lok connectors can be 
rented from rental houses for ﬁ lm, lighting, electrical equipment, or enter-
tainment equipment. One such rental house is Mole-Richardson (www.
mole.com.). The standard power connector in Europe is the C-form. 
 Use an adapter from Cam-lok to bare wires. Pull the panel off the 
breaker box, insert the bare wires, and connect the Cam-lok to your truck’s 
power. Some breaker boxes have Cam-loks already built in. 
 Caution:  Have an electrician do the wiring if you don’t know what 
you’re doing. A union electrician might be required anyway. 
 Measure the AC line voltage. If the AC voltage varies widely, use a 
line voltage regulator (power conditioner) for your recording equipment. 
If the AC power is noisy, you might need a power isolation transformer. 
 Check AC power on stage with a circuit checker. Are grounded out-
lets actually grounded? Is there low resistance to ground? Are the outlets 
of the correct polarity? There should be a substantial voltage between hot 
and ground, and no voltage between neutral and ground. 
 Some recording companies have a gasoline-powered generator 
ready to switch to if the house power fails. If there are a lot of lighting and 
dimmer racks at the gig, you might want to put the truck on a generator 

66
At the Session: Setup and Recording 
to keep it isolated from the lighting power. Another option is an uninter-
ruptible power supply (UPS). 
 Interconnecting Multiple Sound Systems 
 If you hear a hum or buzz when the systems are connected, ﬁ rst make 
sure that the signal source is clean. You might be hearing hum from a 
broken snake shield or an unused bass-guitar input. If the hum persists, 
experiment with ﬂ ipping the ground-lift switches on the splitter and 
on the direct boxes. On some jobs, you need to lift almost every ground; 
on others, you need to tie all the grounds. The correct ground-lift setting 
can change from day to day because of a change in the lighting. Expect to 
make some trial-and-error adjustments. 
 If the PA has serious hum and buzz problems, offer help. You 
might hear buzzes in your quiet control room or isolating earphones 
that the PA people can’t hear over the main system with noise in the 
background. Maybe the PA company is using balanced line-level 
audio cables that are grounded at both ends, which can cause ground 
loops and hum. You might want to use some cable ground-lift adapt-
ers (  Figure 4-2  ) to float (remove) the extra pin-1 ground connection at 
equipment inputs.  
 A radio station or video crew might want to take an audio feed from 
your mixing console. If so, you can prevent a hum problem by using a 
console with transformer-isolated inputs and outputs. Or use an XLR 
Y-cable with a ground lift. Other options are a direct box or a line-level 
transformer splitter, such as the Whirlwind Line Balancer/Splitter (LBS) 
or the ProCoSound IT-1 Isolation Transformer Unit. For best isolation, use 
a distribution amp with several transformer-isolated feeds. Lift the cable 
shield at the input of the system you’re feeding. 
 Figure 4-2 A ground-lift adapter for balanced line-level cables. 

67
At the Session: Setup and Recording  4
 We recommend the article, “Sound System Interconnection” on the 
Rane website, www.rane.com/note110.html. It describes how to connect 
balanced and unbalanced equipment and prevent ground loops. 
 Mic Connections 
 You have previously created a mic list, so you know what to plug in 
where. Make some copies of the mic list. After unpacking, place one list 
by the splitter, another by each stage box, and another by each mixer. The 
list will act as a guide to help you keep things organized. 
 Attach a strip of white console tape just below the mixer faders. 
Use this strip to write down the name of the instrument that each fader 
affects. 
 Based on the mic list you made, you might plug the bass direct box 
into snake input 1, plug the kick mic into snake input 2, and so on. Label 
fader 1 “bass,” label fader 2 “kick,” etc. Also plug in equipment cables 
according to your block diagram. 
 Have an extra microphone and cable offstage ready to use if a mic fails. 
 If you unplug a mic plugged into phantom power, it will make a 
popping noise in the sound-reinforcement system. Be sure to mute the 
mic channel ﬁ rst. 
 Running Cables 
 To reduce hum pickup and ground-loop problems associated with cable 
connectors, try to use a single mic cable between each mic and its stage-
box connector. 
 Avoid bundling together mic cables, line-level cables, and power 
cables. If you must cross mic cables and power cables, do so at right angles 
and space them vertically. 
 Plug each mic cable into the stage box or splitter (if used), then run 
the cable out to each mic and plug it in. This leaves less of a mess at the 
stage box. Leave the excess cable at each mic stand so you can move the 
mics. Don’t tape down the mic cables until the musicians are settled. 
 It is important that audience members do not trip over your cables. 
In high-trafﬁ c areas, cover cables with rubber ﬂ oor mats or cable cross-
overs (metal ramps). At least tape them down lengthwise with gaffer tape. 
 It helps to set up a closed-circuit TV camera and TV monitor to see 
what’s happening on stage. You need to know when mics get moved acci-
dentally, or when singers use the wrong mic, etc. 

68
At the Session: Setup and Recording 
 Setting Up the Recording Mixer 
 If you are using mic splitters and a recording mixer, here is a suggested 
procedure: 
 1. If the mixer is set up in a dressing room or locker room, add some 
acoustic absorption to deaden the room reﬂ ections. You might bring 
a carpet for the ﬂ oor plus acoustic foam or packing blankets for the 
walls. 
 2. Turn up the recording monitor system and verify that it is clean. 
 3. Plug in one mic at a time and monitor it to check for hums and 
buzzes. Troubleshooting is easier if you listen to each mic as you 
connect it, rather than plugging them all in and trying to ﬁ nd a hum 
or buzz. 
 4. Check and clean up one system at a time: ﬁ rst the sound-reinforcement 
system, then the stage-monitor system, then the recording system. 
Again, this makes troubleshooting easier because you have only one 
system to troubleshoot. 
 5. Use as many designation strips as you need for complex consoles. 
Label the input faders at the bottom and top. Also label the monitor-
mix knobs and the meters. 
 6. Verify that left and right channels are correct and that the pan-pot 
action is not reversed audibly. 
 7. If you are setting up a separate recording monitor mix, do a prelimi-
nary pan-pot setup. Panning similar instruments to different locations 
helps you identify them. 
 8. Make a short test recording and listen to the playback. 
 Mic Techniques 
 Normally the PA company chooses and places the mics, but you might do 
it yourself or collaborate with the PA company. This section offers some 
tips on miking instruments and vocals. 
 In a quiet recording studio with good isolation between instruments, 
you have the freedom to mike instruments 1 or 2 feet away if you want. 
But in a noisy club or auditorium, with band members close together on 
stage, separation is a serious problem. Usually you need to mike a few 

69
At the Session: Setup and Recording  4
inches away to reduce background noise, room acoustics, leakage, and 
feedback. Here are some other ways to control these problems: 
 • Use directional microphones, such as cardioids, supercardioids, or 
hypercardioids. These mics pick up less feedback, leakage, and noise 
than omnidirectional mics at the same miking distance. For example, 
the Audix OM5, OM6, and OM7 vocal mics (www.audixusa.com) 
have a tight hypercardioid pattern that controls leakage. 
 • If possible, hang drapes or other acoustical absorption material on 
the rear wall to reduce sound reﬂ ections into the mics. Consider 
moving the instruments and vocals farther apart to improve isola-
tion and reduce phase interference between mics. 
 • Use direct boxes. A direct box (DI box) is an interface between an 
unbalanced electric instrument and a balanced mixer mic input. 
Bass guitar, electric guitar, and keyboards can be recorded direct 
to eliminate leakage and noise in their signals. However, nothing 
beats the sound of a miked guitar amp. You could record the gui-
tar directly from its effects boxes, then use a guitar-amp emulator 
during mixdown. That is especially helpful if the guitar amp is 
noisy. Note that sequencers and some keyboards have high-level 
outputs, so their direct boxes need transformers that can handle 
line level. 
 • Use contact pickups. On acoustic guitar, acoustic bass, and violin, you 
can avoid leakage by using a contact pickup. It is sensitive only to 
the instrument’s vibration, not so much to sound waves. The sound 
of a pickup is not as natural as a microphone, but a pickup may be 
your only choice. Consider using both a pickup and a microphone 
on the instrument. Connect just the pickup to the PA and monitor 
speakers to prevent feedback, and connect the mic and pickup to the 
recording mixer. If the mic has too much leakage during mixdown, 
you can either use the pickup track or overdub the guitar. 
 • Use clip-on mics. These are designed for close-miking, internally 
EQed to sound natural when mounted on an instrument. 
 • Choose mic positions carefully. Close miking affects the tonal bal-
ance of a recorded instrument. When you change the mic position, 
you change the tone quality. For example, an acoustic guitar picked 
up with a stand mic near the sound hole is bassy, near the bridge is 
mellow, and near the ﬁ ngerboard is bright. 

70
At the Session: Setup and Recording 
 Listed below are some typical miking methods for vocals and instru-
ments. These are just some suggested starting positions—experiment and 
use your ears. 
 Vocal:  Use a condenser, ribbon, or dynamic vocal mic about 0–3 inches 
from the mouth. To reduce breath pops with vocal mics, be sure to use 
foam pop ﬁ lters. Leave a little spacing between the pop ﬁ lter and the mic 
grille. It also helps to switch in a low-cut ﬁ lter (100 Hz high-pass ﬁ lter). If 
the mic is a cardioid, aim the “dead” rear of the mic at the ﬂ oor monitors 
to reduce feedback. If the mic is a supercardioid or hypercardioid, angle 
the mic to be more nearly horizontal so that its zone of least pickup aims 
at the monitors. Caution the performer not to cover the grille with a hand 
because it could color the sound and cause feedback. 
 Acoustic guitar:  Option 1—Place a cardioid condenser mic about 
3 inches to the right of the sound hole (toward the neck) and 3 inches 
away, as in   Figure 4-3  . Option 2—Mount a mini cardioid mic a few 
inches from where the ﬁ ngerboard joins the body. Option 3—Use a clip-
on mini mic designed for the acoustic guitar. Option 4—If you can’t 
get enough gain-before-feedback with a miked acoustic guitar (as often 
 Figure 4-3 Acoustic guitar miking. 

71
At the Session: Setup and Recording  4
happens with a rock band), use a pickup or a pickup mixed with a mic. 
Plug the pickup into a guitar preamp or direct box. During mixdown, 
you might roll off some highs around 10–12 kHz to make the pickup 
track sound less “electric.”  
 Sax:  Place a dynamic or condenser mic a few inches above the bell, 
aiming at the tone holes. For more mobility and a brighter sound, clip a 
mini mic to the bell. 
 Electric guitar or electric bass direct:  For a clean sound, plug the guitar 
into a direct box. Plug the direct-box output into a mixer mic input. For a 
distorted sound, plug the instrument into a guitar signal processor, and 
connect the processor output into a mixer line input. 
 Electric guitar amp:  Place a dynamic mic with a presence peak one 
inch from a speaker cone, slightly off-center. 
 Synthesizer or drum machine:  Use direct boxes. Flip the ground-lift 
switch on the boxes to the position where you monitor the least hum. 
 Drum set:  See   Figure 4-4  . Try two cardioid condenser “stick-type” 
mics about 2 feet above the cymbals (see  Chapter 9  for stereo miking 
techniques). Add a dynamic mic or mini condenser mic just above the 
KICK
 MIC
OVERHEAD
      MIC
OVERHEAD
      MIC
ALTERNATE MIKING
WITH A STEREO PAIR
SNARE
   MIC
 Figure 4-4 Simple drum kit miking. 

72
At the Session: Setup and Recording 
snare-drum rim, and a large-diaphragm dynamic mic in the kick drum. 
That simple miking method may be adequate for a small jazz drum kit. 
For a rock kit, add some dynamic cardioid mics, each two inches above 
and two inches in from each tom-tom rim as in   Figure 4-5  . Stuff a pillow 
or blanket in the kick to get a tight sound, and use a wood or plastic beater 
for extra “click.” The kick drum often requires some EQ to sound good. 
You might cut a few dB around 400 Hz and boost around 4 kHz. 
 Bongos or congas:  Try a dynamic mic midway between the drums a 
few inches away, or mike both drums up close. 
 Percussion (shaker, casaba, guiro, etc.):  Use a stand-mounted condenser 
mic for its excellent transient response. The percussionist can hold each 
instrument near the mic. If the percussionist moves a lot between instru-
ments, you might pick them up with a lavalier mic on the percussionist. 
 Grand piano:  See   Figure 4-6  . Raise the lid. Gaffer-tape a mini mic or 
boundary mic to the underside of the lid in the middle. For stereo, use 
two mics: one over the bass strings and one over the treble strings. If you 
need more isolation, close the lid and tweak EQ to remove the tubby col-
oration (usually cut 1–4 dB around 250 Hz).  
KICK
 MIC
OVERHEAD
      MIC
OVERHEAD
      MIC
ALTERNATE MIKING
WITH A STEREO PAIR
SNARE
   MIC
FLOOR TOM
MIC
RACK TOM MICS
 Figure 4-5 Drum kit miking. 

73
At the Session: Setup and Recording  4
 Another method: raise the lid and place two condenser mics 8 inches 
over the bass and treble strings, about 8 inches horizontally from the ham-
mers. Or place the bass mic about 2 feet toward the tail. If necessary, cut 1 
or 2 dB around 250 Hz to reduce tubbiness. 
 Upright piano:  Face the soundboard toward the room (not next to a 
wall). Mike the soundboard a few inches from the bass and treble areas 
with two dynamic or condenser mics. 
 Banjo:  Tape a mini omni mic to the drum head about halfway between 
the bridge and lower rim. Or place a cardioid dynamic mic or condenser 
mic about 6 inches away, halfway between the bridge and lower rim. 
 Fiddle: Try a dynamic, ribbon, or condenser mic about 8 inches over the 
top. For a ﬁ ddle player who sings, place the mic about 6 inches over the ﬁ d-
dle, aiming at the player’s chin. Some players use a pickup into a direct box. 
 Mandolin, bouzouki, dobro, lap dulcimer:  Place a dynamic, ribbon, or 
condenser mic about 4 to 6 inches away from an f-hole or sound hole. 
 Figure 4-6 Grand piano miking. 
BASS MIC
STEREO PAIR
TREBLE MIC
BASS MIC
TREBLE MIC
HAMMERS
8 TO 12 IN.
HAMMERS
8 TO 12 IN.
(ALTERNATIVE)
MICS angled or 
straight down
BASS MIC
TREBLE MIC
Boundary mics gaffer-taped
to underside of raised lid
A
B
C

74
At the Session: Setup and Recording 
 Hammered dulcimer:  Place a dynamic, ribbon, or condenser instru-
ment mic about 8 inches above the top edge, aiming at the soundboard. 
 Acoustic bass:  See   Figure 4-7  . Mike about 3–6 inches away, just 
above the bridge. For more isolation, wrap a cardioid dynamic mic 
in foam (except for the grille) and stuff it behind the bridge. Many 
players use a pickup, which they plug into a bass-guitar amp. Plug 
the pickup into a direct box and connect the phone-jack output in the 
direct box to the amp. Some amp heads have an XLR direct out and a 
ground-lift switch to prevent hum. The pickup will need some EQ to 
sound natural.  
 Flute:  Place a dynamic, ribbon, or condenser mic halfway between 
the mouthpiece and the tone holes, about 6 inches away. Or wear a 
headworn mic, and place the mic capsule between the mouthpiece and 
tone holes. 
 Harmonica:  Mike up close with a dynamic vocal mic. Or plug a hand-
held mic into a guitar amp, and mike the amp. 
 Accordion, concertina:  Tape a mini mic onto the tone holes on each 
side (two mics total). You might prefer to locate a dynamic mic 6 inches 
from the tone holes on the keyboard side. Some players use a pickup into 
a direct box. 
 Figure 4-7 Some mic techniques for the acoustic bass. 
MIC IN FOAM 
BEHIND BRIDGE
NEAR BOTTOM AREA
MIC OUT FRONT
ACOUSTIC BASS
SIDE VIEW
4–8 IN.
NEAR PLUCKING
FINGERS

75
At the Session: Setup and Recording  4
 Horns:  Mike each horn on-axis with a ribbon mic or with a ﬂ at-
response dynamic mic. 
 Worship leader:  If the leader wanders while talking, use a lavalier 
mic clipped about 8 inches under the chin. If the leader talks at a lec-
tern, either use your own boom-mounted mic or split the signal from 
the lectern mic. 
 Praise group:  This is a small choir of about 8 people. Mike each person 
with a stand-mounted vocal mic, up close and with a foam pop ﬁ lter. 
 Choir:  You can use hanging mics or stand-mounted mics. Place the 
microphones about 1.5 feet in front of the front row and 1.5 feet above 
the head height of the back row. For a small choir, use two mics that are 
spaced to divide the choir in thirds. For large choirs, use a mic on every 
20 people. Add reverb during mixdown. 
 Conferences:  To record a small conference, try an omnidirectional 
boundary mic (such as a Crown PZM) in the center of the table. The mic 
should be no farther than 3 or 4 feet from each participant. For large con-
ferences (  Figure 4-8  ), place a cardioid boundary mic (“conference mic”) 
on the table at arm’s length between every two people. Run all the mics 
into an automatic mixer, which turns off all the mics except the one in use. 
That provides a much clearer sound. An example is the Shure SCM810. 
 Figure 4-8 Conference miking. 

76
At the Session: Setup and Recording 
Some conferences might have this setup already installed, and you can 
just plug in to record the audio.  
 You might want to insert a limiter between the mixer and recorder to 
prevent accidental clipping if someone yells. 
 Drama:  You can record a play or musical with two or more unidi-
rectional boundary mics on the stage ﬂ oor, about 1 foot from the edge. 
Either space the mics 2 to 3 feet apart, or angle them apart 90 degrees 
and space them about 1 foot apart center-to-center (  Figure 4-9  ). Extra-
wide stages might require two more mics toward the stage edges. You 
might need boundary mics on the pit wall to pick up the pit orchestra 
as well.  
 Big band: See  Figure 4-10 . 
 Figure 4-9 Miking drama. 

77
At the Session: Setup and Recording  4
 When you’re recording a group that has been on tour, should you 
use its PA mics or your own mics? In general, go with its mics. The art-
ists and PA company have been using their mics for a while and may not 
want to change anything. Most mics currently used in PA are good qual-
ity anyway, unless they are dirty or defective. 
 If you’re not happy with their choice, you could add your own 
instrument mics. Let the PA people listen to the sound in the recording 
truck, or in headphones. If it sounds bad because of the mic choice, ask, 
“Would it be okay if we tried a different mic (or mic placement)?” Usually 
it’s all right with them—it’s a team effort. Make sure every instrument is 
miked. If not, add your own microphones. 
 Discreet Miking for Video Shoots 
 When a video company shoots a concert that you’re recording, it’s impor-
tant that the mics and mic stands be inconspicuous. Sometimes, sound 
quality must take a back seat to the camera scene. Here are a few tips for 
making your gear less visible: 
 • Use clip-on mics or pickups on acoustic instruments. 
 • Mike each drum with a clip-on mic or Mic-Eze clamp. 
 • Consider miking each cymbal from underneath using a Mic-Eze 
clamp and a small-diaphragm condenser. 
 • Use an AmpClamp mic mount on each guitar amp. 
 Figure 4-10 A miking method for a big band. 
DRUMS
TROMBONES
TRUMPETS
SAXES
MUSIC STANDS
GUITAR
PIANO
BASS
DI

78
At the Session: Setup and Recording 
 • Use black-colored stands instead of chrome stands. 
 • Use wireless mics on singers. 
 • Use boundary mics on the underside of a raised piano lid. 
 Electric-Guitar Grounding 
 While setting up mics, you need to be aware of a safety issue with 
the electric guitar. Electric-guitar players can receive a shock when 
they touch their guitar and a mic simultaneously. This occurs when 
the guitar amp is plugged into an electrical outlet on stage, and the 
mixing console (to which the mics are grounded) is plugged into a 
separate outlet across the room. If you’re not using a power distro, 
these two power points may be at widely different ground voltages. 
So a current can flow between the grounded mic housing and the 
grounded guitar strings. 
 Caution:  Electric-guitar shock is especially dangerous when the gui-
tar amp and the console are on different phases of the AC mains. 
 It helps to power all instrument amps and audio gear from the same 
AC distribution outlets. If you lack a power distro, run a heavy extension 
cord from a stage outlet back to the mixing console (or vice versa). Plug 
all the power-cord ground pins into grounded outlets. That way, you pre-
vent shocks and hum at the same time. 
 If you’re picking up the electric-guitar direct, use a transformer-
isolated direct box and set the ground-lift switch to the minimum-
hum position. 
 Using a neon tester or voltmeter, measure the voltage between the 
electric-guitar strings and the metal grille of the microphones. If there is 
a voltage, ﬂ ip the power polarity switch on the amp (if any). Use foam 
windscreens for additional protection against shocks. 
 Audience Microphones 
 When you make a live recording, audience-reaction mics are essen-
tial. They help the recording to sound “live.” Without audience mics, 
the recording may sound too dry, as if it were done in a studio. And 
there’s nothing like cheering and clapping to add excitement to a 
live recording. 

79
At the Session: Setup and Recording  4
 One easy method is to aim two cardioid condenser mics at the audi-
ence. Hypercardioid or shotgun mics are even better. Put them on regu-
lar mic stands, on the stage ﬂ oor, on either side of the stage. If those mic 
stands must not be seen, hang some mics or put a stereo pair at FOH 
(  Figure 4-11  ).  Chapter 9  describes stereo mic techniques.   
 If the audience mics are far back in the hall—100 feet from the stage, 
or at FOH, for example—they pick up the band’s sound with a delay. 
When mixed with the close mics, the audience mics add an echo. You 
can prevent this echo if you mix the recording using computer software: 
slide the audience tracks to the left (earlier in time). Align the waveforms 
of big peaks. 
 What if you don’t have enough tracks for the audience mics? Record 
them on a two-track recorder. Load this recording into your digital audio 
workstation (DAW) along with the other tracks. Align the two record-
ings in time as just described. You might need to do that alignment at 
several time-points because the digital clocks in the two recorders might 
not agree. Another option is to turn up some stage mics in the mixdown 
when the audience applauds. 
 If the audience mics are run through the PA mixer’s preamps, leave 
the audience mics unassigned in that mixer to prevent feedback. 
 To get more isolation from the house speakers in the audience mics, 
use several mics hung close to the audience. Some engineers put up 4 
audience mics maximum; some use 8 to10. Use directional mics and aim 
them away from the house speakers. 
 Another option is to  not  mike the audience or not use the audience 
tracks. Instead, during mixdown, you could simulate an audience with 
audience-reaction CDs. Simulate room reverb with an effects device or 
plug-in. 
SIDE VIEW OF MIC PLACEMENT
HANGING MICS
STAND MICS
STAGE
AUDIENCE
FOH MICS
 Figure 4-11 Some audience-miking techniques. 

80
At the Session: Setup and Recording 
 Setting Levels and Submixes 
 Now that the mics are set up, you might have time for a sound check. 
Scratch the grille of each mic and make sure you are getting a signal. 
 In the PA system, work on gain-staging. It is the process of setting 
the signal level in each device high enough to override noise, but low 
enough to prevent distortion. The signal in each piece of gear should be 
at its nominal operating level. Here’s what to do: 
 1. Set the master faders, group faders and channel faders to design 
center (unity gain), the shaded portion of fader travel about 3/4 up. 
Turn down the power-amp volume controls all the way. 
 2. With the band playing loudly, turn up each mic preamp’s gain knob 
just until the clip or overload LED ﬂ ashes, then back off about 10 dB 
to add some headroom. 
 3. Turn up the power-amp volume controls until the sound is as loud 
as you want it. 
 Now you set recording levels. Have the band play a loud song. Locate a 
mixer input module that is feeding a recorder track. Set the mic preamp 
gain to get the desired recording level on each track. You might set each 
track’s level to peak around −10 dBFS maximum, which allows some 
headroom for surprises—essential for a live recording. This also results in 
good gain staging between the mixer and recorder. 
 Check all the keyboard patches and guitar effects because some may 
be much louder than others. You might put a limiter in line with some 
insert sends to prevent excessive levels. 
 You often encounter PA consoles where some insert sends are tied 
up with signal processors. You must use those channels’ direct-out jacks 
instead, which usually are postfader (unless they can be switched to pre-
fader). Another option is to “Y” the insert send to your recorder and to the 
processor input. Or, assign those channels to unused groups (buses) and 
get your recording signals from there. 
 If you don’t have enough tracks for all the mics, you could set up 
a two-track drum submix. Ideally you would do this with the record-
ing mixer rather than the PA mixer, and monitor over headphones or 
Nearﬁ eld monitors in a separate room. Assign each drum mic to buses 
3 and 4 (for example), and pan each mic as desired. Put the submaster 

81
At the Session: Setup and Recording  4
faders for buses 3 and 4 at design center—the shaded area about 1/2 to 
3/4 up. 
 Have the drummer hit each drum repeatedly, one at a time, as you 
adjust the input trims to prevent clipping. For example, ask the drum-
mer to bang on the kick drum. Turn down the kick drum’s input trim all 
the way. Slowly bring it up until the clip LED (overload light) ﬂ ashes. 
Then turn down the input trim about 10 dB to allow some headroom. 
When all the drum trims are set, do a drum mix with the faders. Try to 
adjust all the faders up or down by the same amount so that the record-
ing level is correct when the submasters are at design center. 
 Recording 
 If your recording will be synced later with a video recording by using 
SMPTE (Society of Motion Picture and Television Engineers) time code, 
record the video time-code feed on a spare recorder track. Also be sure to 
match the video sample rate (usually 48 kHz). 
 A few minutes before the band starts playing, begin recording. 
Keep a close eye on recording levels. If a track is going into the red, 
slowly turn down its input gain and note the counter time where this 
change occurred. 
 Caution:  If you are recording off the PA mixer, turning down its input 
gain will affect the PA levels. The PA operator will need to turn up the 
corresponding monitor send and channel fader. 
 This is a touchy situation that demands cooperation. Ideally, you 
set enough headroom during the sound check so you won’t have to 
change levels. But be sure the PA operator knows in advance that you 
might need to make changes. Ask the operator whether he or she wants 
to adjust the gain trims for you, so the operator can adjust correspond-
ing levels at the same time. Thank the operator for helping you get a 
good recording. 
 If you are recording with a splitter and mic preamps on stage, 
assign someone to watch the levels and adjust them during the concert. 
Preamps with meters allow more precise level setting than preamps with 
clip LEDs. 
 Keep a track sheet and log as you record. For each song in the set 
list, note the counter time when the song starts. Later, during mixdown, 
you can go to those counter times to ﬁ nd songs you want to mix. Also 

82
At the Session: Setup and Recording 
note where any level changes occurred so you can compensate during 
mixdown. It helps to note a counter time when the signal level was very 
high. When you mix the recording you can start at that point in setting 
your overall mix level. 
 Record each set nonstop so that you don’t miss anything. You can 
edit out unwanted material later. 
 Teardown 
 After the gig, because your mics might be stolen or damaged, pack them 
away ﬁ rst. Refer to your equipment list as you repack everything. Note 
any equipment failures and ﬁ x broken equipment as soon as possible. 
 Important: back up the recording using a hard-drive backup system 
such as the Glyph Triplicator, or back up to the Internet using a service 
like Gobbler (which can be done within Pro Tools). 
 After you haul your gear back to the studio, it’s time for mixing and 
editing, covered next.  

83
 The gig or concert is over, and you’ve brought your recording back to the 
studio. First, be sure to back it up to a separate hard drive. If you recorded 
live to two tracks, you are ready to dump the recording to your computer 
and edit it for CD or online release. If you recorded to multitrack, you will 
mix the tracks to stereo, then edit the stereo mix. This chapter describes 
the process. 
 Editing a Two-Track Recording 
 Suppose you recorded a gig in stereo directly to two-track. Below is a 
procedure to get the recording into your computer and edit it. This will 
let you prepare a CD or MP3 ﬁ le of your recording: 
 • If you used a handheld recorder, connect its USB (Universal Serial 
Bus) port to the one on your computer. The computer will detect the 
recorder as a data-storage device. Click-drag the WAV ﬁ le(s) from 
the recorder to the hard drive that you use for audio ﬁ les. If you 
recorded several WAV ﬁ les—one for each musical set—load them 
all in. 
 5 
 AFTER THE SESSION:  
MIXING AND EDITING 

84
After the Session: Mixing and Editing
 • If you used a four-tracker, set up a pleasing mix of all the tracks. Plug 
the stereo line outputs of the four-tracker into your audio interface 
line input. Play the gig recording, set the recording level, and copy 
the stereo mix in real time to your computer. 
 Now you can launch your recording software and open the gig’s 
WAV file that is on your hard drive. Here is a simple method to cre-
ate tracks for a CD, one track per song, with silent spaces between 
the songs: 
 1. Start with one long WAV ﬁ le of the entire set. It is a single clip, region, 
or segment of audio. Each song appears as a group of high-level 
waves, and the quiet pauses between songs are low-level waves 
( Figure 5-1 ). Normalize the ﬁ le so that it will be as loud as possible 
without distortion. 
   2. Split that long, single clip into separate clips, one per song. Keep 
a few seconds of crowd noise and applause before and after each 
song. 
 3. Cut out unwanted sounds and pauses between songs. Then your 
computer screen will look something like   Figure 5-2 . 
   4. If a song is too long to sustain interest on a CD, remove verses, 
choruses, or solos to shorten it. 
 5. Zoom way in to the beginning of the song. Add a fade-in before the 
song begins (  Figure 5-3  ). During the applause after the song, add a 
fade-out with whatever shape sounds good. 
   6. Next you will save each song’s clip as a separate WAV ﬁ le. Depend-
ing on your software, either (1) highlight a clip and export it to a 
ﬁ le or (2) place song clips on separate tracks, solo one track at a 
time, and export it to a ﬁ le. Name each ﬁ le the same as the song 
title. 
 7. Finally, launch your CD-burning software, load the WAV ﬁ les into a 
playlist, and burn a CD-R. 
 Other ways to create albums and demos from stereo recordings are 
described later under the headings “Mastering an Album” and “Mas-
tering a Demo.” 

Figure 5-1 Songs appear as high-level waves in the set’s sound track.
Figure 5-2 Edited song clips.
Figure 5-3 A fade-in at the beginning of a song clip.

86
After the Session: Mixing and Editing
 Preparing to Mix a Multitrack Recording 
on a Computer 
 Suppose you brought a multitrack recording back to the studio, and you 
want to mix it to stereo. Mixing can be done with a hardware mixer or 
with computer digital audio workstation (DAW) software. This section 
focuses on the DAW process. 
 If you made the multitrack recording directly to a computer, you’re 
ready to mix. Skip to the next section. 
 If you recorded on a multitrack hard-drive recorder, and you want 
to mix the tracks with your computer, ﬁ rst copy the tracks to your 
computer’s hard drive. Depending on the recorder model, use USB, 
FireWire, S/PDIF, Lightpipe, or Ethernet cables for the audio transfer 
to computer. 
 Split the Gig Recording into Song Projects 
 At this point, you need a way to split the multitrack gig recording into 
separate multitrack song recordings. In other words, create one multi-
track recording project for each song so that you can mix each song sepa-
rately. Here are the steps: 
 1. Launch your DAW recording/editing software. Load a multitrack 
template. Import all the tracks from Set 1. You should see the track 
waveforms on your computer monitor (  Figure 5-4  ). The tracks will 
be as long as the set was, typically 40 minutes. Select  File > Save as, 
and name the project “Set 1.” 
 2. Select  File > Save as,  and this time name the project “Song 1” 
(where “Song 1” is the title of the ﬁ rst song you want to work on). 
 3. Play the tracks and ﬁ nd the beginning of Song 1. Put the cursor a 
few seconds before Song 1 where you hear some crowd noise. 
 4. Select all tracks, then split all of them at that point (  Figure 5-4  , the 
left side of the dark area). Use the “split tracks” (or similar) com-
mand in your software to do that. 
 5. Select all the tracks to the left of the split point and delete them, 
closing up the space that is left. 

87
After the Session: Mixing and Editing 5
 6. Put the cursor a few seconds after the applause following 
Song 1. 
 7. Select all tracks, then split all of them at that point (  Figure 5-4  , the 
right side of the dark area). 
 8. Select all the tracks to the right of the split point and delete them. 
Only the tracks for Song 1 remain. 
 9. Again, save the project as “Song 1” or whatever. You have created 
a separate multitrack project for Song 1. 
 10. Now you will repeat this process for the rest of the songs. Load the 
Set 1 project. The tracks for the entire set appear. Repeat Steps 2–9 
for Song 2, Song 3, and so on. 
 Now, when you load the project called Song 1, the multiple tracks for 
Song 1 will appear on screen. They will be as long as Song 1 was. You can 
mix and edit those tracks, and export the mix for Song 1. The same goes 
for Song 2, Song 3, and so on. 
Figure 5-4 Several tracks loaded into a multitrack template on screen. The dark 
area is the group of tracks for one song.

88
After the Session: Mixing and Editing
 Delete Unwanted Material 
 Now you can edit Song 1. Listen to each track by itself or look at its wave-
form on your computer monitor. Erase or delete anything you don’t want 
to keep. For example, erase some unwanted talking on the vocal track 
during the song intro. Or erase a thump on a guitar track that happened 
when someone bumped into the mic stand. 
 Preparing to Mix a Multitrack 
Recording with a Mixer 
 If you recorded on a multitrack hard-drive recorder and you want to mix 
the tracks with a hardware mixer, you’re ready to go. First, remember that 
live gig recordings are long, nonstop programs. It’s hard to mix an entire 
set continuously for an hour or so without making a mistake. A better 
procedure is to set up a mix for the ﬁ rst song, record it or export it to your 
hard drive, set up a mix for the next song, record it, and so on. Then edit 
the mixes together to sound like a single concert. 
 When mixing each song, be sure to include several seconds of crowd 
noise or applause before and after each song. You will use this crowd 
sound when editing later.  Don ’ t fade in or fade out while mixing; you 
will do the fades while mastering. 
 Do Punch-Ins 
 Some band members might want to punch-in (re-record) parts of tracks 
to correct mistakes or to replace tracks that have too much leakage (usu-
ally vocals or a miked acoustic guitar). Important: be careful to match the 
sound of the instrument in the studio to the sound of the track. Use the 
same mic and mic position that you used during the gig. You’ll probably 
need to EQ the punch-in to match the original recording. Also, you might 
want to add some reverb to the re-recorded section because otherwise it 
will sound dry, unlike the live-recorded tracks. 
 Mix Each Song 
 Mixdown procedures can be found in recording textbooks, so I won’t 
cover them here. On-location recordings, however, have some unique 
mixing challenges. 

89
After the Session: Mixing and Editing 5
 Fader levels:  Start with the loudest part of the recording. You noted 
the counter time of this event when you wrote the log during the gig. 
Set fader levels so that the stereo mix peaks at about −3 dBFS maximum 
when the master faders are at 0 dB. The more tracks in use, the lower you 
need to set the fader levels to prevent clipping the stereo output bus. 
 Set up fader automation so that each solo comes in at an appropri-
ate level. Another use for automation is to bring up the applause when 
needed. 
 EQ (equalization):  If background noise and leakage are problems, use 
EQ to ﬁ lter out frequencies above and below the spectrum of each instru-
ment. For example, cut below 100 Hz on vocal tracks. This helps to reduce 
breath pops and bass leakage into the vocal mics. Also use EQ to com-
pensate for the unnatural tonal balances you can get with close miking or 
direct boxes. Roll off excess bass on a close-miked vocal or acoustic guitar, 
and so on. 
 Panning:  You might want to pan the tracks to match the locations 
of the instruments and vocals at the gig. Try to achieve a good balance 
between left, center, and right instruments. For example, you might pan 
stereo keyboards toward the left and lead guitar to the right. Bass, kick, 
snare, and lead vocal are usually panned to center. 
 Compression:  Use compression on some individual tracks to control 
the extreme level variations that may occur in live recordings (especially 
on vocals). 
 Parallel compression:  This effect blends compressed and uncompressed 
sounds of a track. It gives more punch but retains dynamics. Here’s how 
to create it: 
 1. Clone a track. 
 2. Insert a compressor in the cloned track. Set it for extreme compression. 
Typical settings: attack time 1.5 msec, release 200 msec, threshold −50 
dB, ratio 4:1 hard knee. Another setting might be 10:1 ratio and −25 dB 
threshold. 
 3. Mix the original track with the cloned (compressed) track. Gradually 
turn up the cloned track to get the effect you want. 
 Another method: some compressors have a dry/wet mix control. 
Dry is uncompressed and wet is compressed. Adjust for the desired effect. 
You might parallel-compress an entire mix to “glue it together” without 
affecting dynamics. 

90
After the Session: Mixing and Editing
 Gating:  Use a noise gate to remove buzzes between electric-guitar 
passages, or to reduce leakage in the tom, snare, and kick-drum tracks. 
 Reverb:  If the tracks sound too dry, as if they were done in a studio, 
add a little reverb with a decay time like that of the venue. Or mix in the 
audience tracks if they sound good. Apply the same stereo reverb device 
(or plug-in) to all the tracks so they sound like they are in the same room. 
To do that, set up an aux send on each track, with all the sends feeding the 
same reverb bus. Omit the reverb on the kick and bass to prevent muddi-
ness. Turn down the reverb during spoken introductions. 
 Echo:  Any echo applied to a vocal track will appear on any instru-
ment that leaked into the vocal mic. For example, you might hear an echo 
on the drum leakage. Avoid echo if you have this problem. 
 Pitch correction:  If the mics picked up a lot of leakage from the PA or 
monitor speakers, any pitch correction applied to the vocal track might 
sound strange. The vocal track will be pitch-shifted, but the leakage 
won’t, so you will hear two pitches. 
 Audience tracks:  Keep the audience mics in the mix to make it sound 
live. Audience mics can muddy the sound if mixed in too loudly. Keep 
them down in level, just enough to add some ambience. Bring them up 
gently to emphasize crowd reactions. You can reduce muddiness by roll-
ing off the lows in the audience mics. 
 The audience mics might sound delayed compared to the stage mics, 
causing an echo. If so, slide the audience tracks earlier in time so that their 
waveforms align with those of the stage mics. 
 Create a template:  Once you’ve set up a good mix for Song 1, save 
your settings as a template that you can recall for all of the other songs. 
 Website track 26 demonstrates a mixdown of a blues band live recording. You 
will hear the effects of panning, EQ, compression, reverb, gating, and audience mics. 
 Mixing for Surround Sound 
 If you are mixing a live gig for surround, you can put the listener inside 
a simulated concert hall. To do this, feed the audience mics to the rear 
surround channels. Also feed some or all of the reverberation to the rear, 
whether it was miked or made with an effects unit. 
 To create the subwoofer channel, turn up an aux send equally on 
each input channel that has low-frequency content. Low-pass ﬁ lter the 
aux-mix output at 120 Hz. That ﬁ ltered aux becomes your low-frequency 
effects (LFE) channel. You also could use a spare bus for the sub-channel 
and assign bass, kick, and low-synth notes to that bus. 

91
After the Session: Mixing and Editing 5
 To adjust the overall monitor level of the six tracks, you could plug 
them into a surround receiver and use its volume control. Or, if you have 
an automated console, you could control six input modules (used only for 
monitoring) with a single group fader. 
 A monitor level that does not exaggerate the bass and treble is 
85 dB SPL. Get an SPL meter (say, from Radio Shack) and set it to 
C-weighted, slow-reading scale. Play pink noise through your monitor 
speakers one at a time, and set each speaker’s monitor level to get an 
85 dB SPL reading. 
 In stereo mixdowns it’s common to pan the bass, kick drum, snare, and 
lead vocal to center. But feeding all these sounds to the center speaker can 
cause it to overload. You might want to feed these sounds partly to front-
left and front-right, as this takes some of the load off the center speaker. 
 If you start with an instrument in the center speaker, you can send 
some of its signal to the surrounds to move the instrument toward you. 
 A center  phantom image  is an apparent source of sound in the center of 
two stereo loudspeakers. The sound appears in the center when the level 
and timing of the signals in both speakers are equal. A center speaker has 
more output around 2 kHz than a center phantom image does, because 
the phantom image has some phase cancellation at 2 kHz due to sound 
delay around the head. The 2 kHz bump in the center speaker can sound 
annoying on vocals, so be careful with EQ. 
 Instruments are more distinct in surround mixes. It’s easier to hear 
what each one is doing. So you may ﬁ nd that you need less level-adjusting 
and less compression in surround than in stereo. 
 You might start with a standard stereo mix on two speakers, then 
add the center channel, surrounds, and sub. Adjust the mix to send some 
tracks to the other speakers. 
 Be sure to check your surround mix in stereo and mono to make 
sure it is compatible. The perceived reverb level in stereo listening should 
match the perceived reverb level in multichannel listening. Most engi-
neers prefer to do separate stereo and surround mixes, rather than doing 
a surround mix and hoping it sounds good when folded down to stereo. 
 A suggested channel assignment for surround mixes is: 
 1. Left front. 
 2. Right front. 
 3. Center. 
 4. LFE (or subwoofer channel). 

92
After the Session: Mixing and Editing
 5. Left surround. 
 6. Right surround. 
 7. SMPTE (Society of Motion Picture and Television Engineers) time 
code (if desired). 
 Appendix E describes several mic techniques for recording in surround. 
 Mastering an Album 
 At this point, your mixes are recorded on your hard drive. Each 
song mix is a separate WAV file. Now you can master the mixes with 
recording/editing software. When the mastering is done, the songs 
will play in the desired order with a smooth transition between them. 
There will be no excess pauses or noises. Let’s run through the pro-
cess step by step: 
 1. Launch your recording software and open a multitrack template. 
Import the ﬁ rst song’s mix into track 1. Import the second song’s 
mix into track 2 at the end of the ﬁ rst song. Repeat for the rest of the 
songs on successive tracks (  Figure 5-5  ). Because each song is on its 
own track, it’s easy to change the level or EQ for each track and slide 
song clips in time. 
Figure 5-5 Placing each song clip on its own track makes mastering easier.

93
After the Session: Mixing and Editing 5
   2. The audio waveform of each song appears on your monitor screen. 
You can zoom out to see the entire program, or zoom in to work on 
tiny spans of time. 
 3. At the beginning and end of each mix, edit out any unwanted sounds 
or pauses. There should be some crowd noise or applause before the 
ﬁ rst note. That way, you can start the edited recording by fading up 
on crowd noise. This helps to establish the recording as being “live.” 
 If there is no crowd noise before the ﬁ rst song, ﬁ nd some crowd 
noise elsewhere in your recording. Mark off a section of it about 
5 seconds long and save it as a region or clip called “Crowd.” 
 4. Is any song too long to sustain interest on a CD? Maybe that 15-minute 
jam worked at the live show, but it might get boring with repeated 
home listening. Remove verses, choruses, or solos to shorten the song. 
 5. Slide Song 2 in time so that the end of Song 1’s applause overlaps the 
beginning of Song 2 (  Figure 5-6  ). Or overlap the crowd noise after 
Song 1’s applause with the beginning of Song 2. You might want 
to fade out the end of Song 1’s clip (  Figure 5-6  ). Repeat for the rest 
of the songs. If done well, the edited program should sound like a 
single continuous concert. 
Figure 5-6 Overlap the ending applause of one song with the beginning of the 
next song.

94
After the Session: Mixing and Editing
 6. You might need to adjust the level of each track so the songs are 
equally loud. Also, you might want to add EQ or Harmonic Balanc-
ing to songs that need it. If you want to make a hot (loud) CD, set the 
output of each track to a common stereo bus. Insert a peak limiter/
normalizer in that stereo bus, and adjust its threshold for the desired 
amount of limiting (usually no more than 6 dB). 
 7. Once you’re happy with the program, write down the start time of 
each song. You will use those start times to create a cuelist that cre-
ates track start IDs when you burn a CD. Some CD-burning software 
uses marks on a waveform to deﬁ ne the start IDs. 
 8. Finally, turn on dither and export the mix to a 16-bit/44.1 kHz stereo 
WAV ﬁ le (the CD format). That single ﬁ le contains all the songs in the 
album with no silence between them. 
 Time to burn a master CD. You need CD-burning software that lets you 
burn a CD from a cuelist or cuesheet. This is a list of start times for all the 
songs within the single stereo WAV ﬁ le you just exported. It tells the CD 
burner when to start each CD track. The cuelist also gives the ﬁ lepath 
of the mastering WAV ﬁ le. Some examples of cuelist-controlled software 
are Wavelab, Samplitude Sequoia, SonyCreative Software CD Architect, 
Pyramix, and Nero Burning ROM. 
 Another option: you can split a long audio ﬁ le of an entire concert 
into shorter ones (one per song). Save each mix as a 16-bit/44.1 kHz WAV 
ﬁ le with dither turned on. When you burn the CD, set the pause length 
between songs to 0 seconds. 
 In the cuelist, make each song’s start time 10 frames earlier than the 
actual start time. That way, during CD playback no audio will be skipped 
at the beginning of each track. After you type the cuelist, burn a CD. 
There’s your ﬁ nished CD master. 
 Be sure not to sell your recordings without authorization from the 
performers or their manager. 
 Mastering a Demo 
 If you want to create a demo CD rather than an album, you might want to 
keep only about 1 minute of each song. That way, the listener can quickly 
sample all the band’s styles without having to hear each song from start 
to ﬁ nish. The edited version would be something like this: 

95
After the Session: Mixing and Editing 5
 Song 1 intro, verse, chorus, fade out. 
 Song 2 intro, verse, chorus, fade out. 
 Song 3 intro, verse, chorus, fade out. 
 And so forth. 
 Last song intro, verse, LAST chorus, and fade out applause. 
 You could fade into the middle of each song if that is more effective than 
starting each song from the beginning. 
 Here is a procedure to edit the song mixes to create song samples. 
Let’s say you imported all the song mixes to the tracks as in   Figure 5-5  . 
Each song mix appears as a clip on a separate track: 
 1. Place the cursor a few seconds before the ﬁ rst song and edit out the 
audio before that point. In other words, trim the beginning of the 
ﬁ rst song. 
 2. Place the cursor about 5 seconds after the ﬁ rst chorus ends, and split 
the clip there. Delete the rest of the song to the right of the split 
point. 
 3. For each remaining song, delete the pause just before the begin-
ning of the song (leaving a space), and delete the rest of the song 
starting about 5 seconds after the ﬁ rst chorus ends. You will end 
up with a group of approximately 1-minute clips, one clip per song 
( Figure 5-7 , top).  
   4. You want the demo to end with applause. So, when you edit the last 
song, you will keep the ending of the last song and about 15 seconds of 
applause afterward. By “last song,” I mean the last song you want to 
play in your edited program. It’s not necessarily the last song played 
at the gig. 
 Display the waveform of the last song clip. Using the DAW editing tools, 
split the clip at the beginning of the ﬁ rst chorus and at the beginning of 
the last chorus (  Figure 5-8  ). Zoom way in so you can mark those points 
with precision, just before a beat. Cut out the audio between the split 
points and close up the space. 
   Play the transition from  part 1  to  part 2  in the last song. If your timing 
was correct, it should sound like a single, nonstop song. If not, you can go 
back and ﬁ ne-tune the edit points. 

Figure 5-7 Top: Edited song clips from a gig recording. Bottom: The edited demo 
with fades added.
Edited song clips from a gig recording
The edited demo with fades added
Song 1
1st part
Song 2
1st part
Song 3
1st part
Song 4
1st part
Song 4
2nd part
Level
Applause
Time
Applause
Applause
Applause
Time
Level
Fade
  in
Fade
 out
1
2
3
4-1
4-2
1
2
3
4-1 4-2
Figure 5-8 Cutting out part of the last song.

97
After the Session: Mixing and Editing 5
 Add Fades and EQ 
 Now that you have edited the songs into short samples, you can put them 
close together and add the fades. First, slide the song clips together so that 
Song 2 starts right after Song 1 ends, Song 3 starts after Song 2, and so on 
( Figure 5-7 , bottom): 
 1. Using your DAW’s fade function, fade up the applause or crowd 
noise just before Song 1. Fade up over 4 seconds or so (  Figure 5-7  , 
bottom left). 
 2. At the end of Song 1’s chorus, fade to silence over about 4 seconds. 
 3. Immediately after Song 1 fades out, start Song 2 at full volume. Fade 
the end of Song 2, start Song 3 at full volume, and so on (  Figure 5-7  , 
bottom). 
 4. At the end of “Last song  part 2 ,” let the applause run for about 
3 seconds, then slowly fade it out over about 8 seconds. 
 Those fade times are just suggestions—use your ears and do what 
sounds right. 
 When you’re ﬁ nished, export the mix to a stereo WAV ﬁ le as described 
before. Burn a CD master from that ﬁ le, and enjoy your demo. 
 Spectral Analysis and Noise Reduction 
 Unlike the controlled environment of studio recordings, live recordings 
may be full of noises: coughs, chair creaks, door slams, vehicles driving 
past the venue, air-conditioning rumble, mic-stand thumps, and so on. 
Your job is to remove those noises as much as possible without damaging 
the music. 
 That can be difﬁ cult, as noises and music often occupy the same 
frequency range. Removing the noise by ﬁ ltering it out also can remove 
some of the notes or their harmonics. Removing the noise by editing it out 
can leave silent spots in the music. Let’s examine some noise-reduction 
methods: EQ, editing, and audio restoration plug-ins. 
 EQ 
 Equalization can be an excellent tool for removing noise. If the noise is 
air-conditioning rumble, vehicles, breath pops or mic-stand thumps, they 

98
After the Session: Mixing and Editing
emphasize low frequencies. So you can reduce them by inserting a high-
pass (low-cut) ﬁ lter on every track. 
 1. Set up an equalizer plug-in for high-pass ﬁ ltering in each track. 
 2. Set the ﬁ lter frequency to 100 Hz and the Q to 1.7, which results in a ﬂ at 
frequency response above the ﬁ lter cutoff frequency. See   Figure 5-9  . 
For kick drum and bass, use a frequency of 40 Hz. 
   3. While soloing each track, play it and raise the ﬁ lter frequency slowly 
until the sound begins to thin out, then back off a little. 
 If a noise has a deﬁ nite tone, like a mic-stand hit producing a 
“bonggg,” ﬁ nd the frequency of that tone by sweeping a narrow (high-Q) 
peak. Then remove the noise with a narrow notch ﬁ lter set to the same fre-
quency. In your DAW software, create a clip around the noise, and insert 
the EQ plug-in only on that clip. 
 A tool for seeing the frequencies of a noise is a spectrum analyzer 
plug-in. It shows the level versus frequency of an audio program. Google 
“spectrum analyzer plugin.” Some examples are Voxengo Span (  Figure 
5-10  ), Roger Nichols Inspector Free, Spectre from Audioﬁ le Engineering, 
Bismark Spectrum analyzer, Blue Cat, and Nugen Visualizer. Set the dis-
play for high resolution and fast response. Look for a peak in the display 
when the noise occurs. 
Figure 5-9 Frequency response of a 100 Hz high-pass ﬁ lter.

99
After the Session: Mixing and Editing 5
 Editing 
 Sometimes you can remove a noise by highlighting its waveform and 
deleting it. To minimize the disruption in audio caused by the removal, 
perform the edit only on the track(s) that need it. Or create a volume auto-
mation envelope and reduce the volume a few dB during the noise rather 
than cutting it out entirely. 
 You can remove breath pops with editing: zoom into the pop until 
you can see its low-frequency waveform where the cycles are farther 
apart than the voice cycles. Highlight the pop waveform and edit it out 
(  Figure 5-11  ). If the edit is very narrow in time it should be inaudible—
especially if you apply fades to the transition. 
Figure 5-10 Voxengo Span.

100
After the Session: Mixing and Editing
 Audio Restoration Programs 
 Many programs can reduce noise such as continuous hiss, buzz, or hum. 
They sample the noise during a silent part of the music, then remove that 
kind of noise from the entire audio program. The deeper the noise reduc-
tion that you set up, the more audio artifacts become audible, such as a 
swirly effect that sounds like a low bit-rate MP3 ﬁ le. 
 Google “audio restoration programs.” Some examples of excellent 
programs are Magix Sequoia, Z-Noise plug-in by Waves, DartPro, iZotope 
RX3, and Sound Forge Audio Studio 10. 
 Live Recording Website 
 Check out the following website for some excellent posts about live recording: 
www.gearslutz.com/board/remote-possibilities-acoustic-music-location-
recording/. Especially study the posts by moderator Remoteness. This same 
link is in this book’s website. Also Google “live recording” for more tips. 
Figure 5-11 Left: The pop waveform is highlighted in this vocal track. Right: The 
pop is removed and fades are added.

101
 6 
 A REAL-WORLD EXAMPLE: 
RECORDING A BLUES 
BAND IN A CLUB 
 In this chapter I’ll describe an on-location recording project that I did 
recently. The leader of a local blues band phoned me, saying that his band 
wanted to be recorded live in a club. The band members thought that a 
live recording would capture their energy better than a studio recording, 
and would cost less to make. 
 Preproduction 
 In talking with the leader, I got this information: 
 Performance date and time: Dec. 31, 2014, at 8 p.m. 
 Load-in time: 5:30 p.m. 
 Length of performance: Three 40-minute sets (approximately). 
 Venue and venue address: Riverside Café, Chester, Michigan. It is a 
restaurant with a stage for a band. 

102
A Real-World Example: Recording a Blues Band in a Club 
 Instrumentation: Bass, drum set, electric guitar, two stereo keyboards 
(fed into a keyboard mixer), sax, and three vocals. 
 Directions to venue: I used Mapquest and a GPS. 
 In order to get a good kick sound with lots of attack, I asked the drummer 
ahead of time to remove the front head of the kick drum, use a wooden 
beater, and put a blanket in the bottom of the kick, pressed against the 
beater head. 
 I planned to do the PA mix and recording at the same time. I would 
mix the show over the band’s PA speakers while recording each instru-
ment’s signal on a separate track for later mixdown back in the studio. 
The insert sends from the PA mixer would connect to a multitrack hard-
drive (HD) recorder. 
 Based on the instrumentation, I drew a block diagram of the record-
ing system. From the block diagram, I generated a track list and equip-
ment list: 
 Track 
 Instrument 
 Mic 
  1 
 Bass 
 Direct box 
   2 
 Kick drum 
 AKG D112 
   3 
 Snare 
 Shure SM57 
   4 
 Overhead L 
 Neumann KM140 
   5 
 Overhead R 
 Neumann KM140 
   6 
 Lead guitar 
 Shure SM57 
   7 
 Keyboards L 
 Direct box into keyboard mixer L output 
   8 
 Keyboards R 
 Direct box into keyboard mixer R output 
   9 
 Sax 
 Studio Projects B1 
 10 
 Lead vocal 
 Crown CM-200A 
 11 
 Vocal 
 CM-200A 
 12 
 Vocal 
 CM-200A 
 13 
 Audience L 
 Audio-Technica AT4041 
 14 
 Audience R 
 AT4041 
 Other equipment 
 10 mic stands (three of these belonged to the band) 
 Stereo mic-stand adapter (for the audience mics) 
 14 mic cables 
 16-channel snake 
 16-channel Mackie 1604 VLZ4 mixer 

103
A Real-World Example: Recording a Blues Band in a Club  6
 TASCAM X-48MKII 48-track HD recorder 
 Snake from mixer insert jacks to HD recorder inputs 
Headphones
 Cable from the mixer’s monitor send output to the band’s monitor power amp 
 Cable from the mixer’s master output to the band’s PA power amp 
 AC output strip 
 Notebook, pens, gaffer tape, ﬂ ashlight, and console tape 
 The Recording Session 
 On the day of the gig, I checked all the equipment and packed it in my 
car. I arrived at the venue 2 1/2 hours before showtime. The venue owner 
showed me where I could set up (on a table near the stage). After the 
load-in, I set up the equipment according to the system block diagram. 
Gaffer tape kept the snake in place so that no one would trip on it. The 
mixer insert sends fed the multitrack HD recorder inputs. I set the HD 
recorder to record 24-bits, 44.1 kHz. 
 When the band arrived and set up, I placed the mics and plugged 
in the direct boxes. The audience mics were two cardioids mounted as a 
near-coincident stereo pair, on a mic stand near the mixer, aiming at the 
audience. 
 I would be doing the live sound mix as well as the recording. I con-
nected the mixer’s main outputs to the band’s power amp for the house 
speakers. Then I connected the mixer’s aux output to the band’s monitor 
amp—and heard a loud hum. An isolating transformer between the mixer 
and power amp solved the problem. 
 Next we did a sound check. I set recording levels using the mixer’s 
gain trim pots. A minute before the band started playing, I hit Record. 
What a great show! I mixed it for the audience with the mixer’s faders and 
equalization (EQ). This did not affect the levels or sound being recorded 
because the mixer’s insert sends are pre-fader and pre-EQ. 
 While the band played, I watched the recording levels and noted the 
counter times where each song started and stopped. I also noted the time 
of the loudest part of the show. That would be a good place to set initial 
levels while mixing the multitrack recording later. 
 After the gig, I packed up, drove all the gear back home, and set it 
back up in the studio. 

104
A Real-World Example: Recording a Blues Band in a Club 
 Preliminary Mix 
 The band wanted to hear a rough mix of the gig so that they could decide 
which songs to include on the CD. I played the multitrack HD recording 
through an analog mixer, set up a mix, and recorded it nonstop to my com-
puter’s hard drive. Each 40-minute set was mixed to a separate WAV ﬁ le. 
 Looking at each ﬁ le’s waveform on-screen, I wrote down the time 
where each song started. I typed a cuesheet that listed those start times, 
then loaded the cuesheet into CD-burning software. Finally, I burned 
three CDs and mailed them to the band for evaluation. 
 Preparing for the Final Mixes 
 I planned to mix the recording in my computer digital audio workstation 
(DAW), so I needed to transfer the HD multitrack recordings to the com-
puter hard drive. For each set, I copied the 14 tracks from the HD recorder 
into my computer. On my D: drive, I created one folder per set to hold the 
tracks. Each set’s folder contained 14 WAV ﬁ les, one per track, each about 
40 minutes long. 
 Now I could split the long gig recording into shorter songs. I loaded 
all the tracks into a multitrack template in Cakewalk Sonar Producer and 
saved the project as Set 1. Then I split the WAV ﬁ les across all the tracks 
into individual songs: one set of multitrack clips per song.  Chapter 5  
describes how to do this under the heading “Split the Gig Recording into 
Song Projects.” In deciding where to split the tracks, I included the audi-
ence noise before each song and the applause after each song. 
 The band had told me which songs to keep. The ﬁ rst was called “TV 
Mama.” I saved the project as “TV Mama,” deleted the tracks before and 
after that song’s multitrack clips, and re-saved the project. In other words, 
I deleted all the songs before and after “TV Mama” and saved that song’s 
multiple tracks as a separate project. (Deleting in this context does not 
remove any audio from the hard drive.) All the tracks for the song “TV 
Mama” (bass, drums, vocals, etc.) resided in a folder called “TV Mama” 
on my D: drive. I repeated the process for each song: 
 1. Load the project called “Set 1” containing the multiple tracks of all 
the songs. 
 2. Delete everything but Song 2’s tracks, and save the project as “Song 2.” 
 3. Load Set 1, delete everything but Song 3’s tracks, save the project as 
“Song 3,” and so on. 

105
A Real-World Example: Recording a Blues Band in a Club  6
 Final Mixes 
 Now that each song was saved as a separate project, I could start mixing. 
First I loaded a 16-track template into Sonar that I use for mixdowns. Each 
track’s fader is set to −12 dB for starters, and each track has an aux send 
and an EQ plug-in. Then I loaded the project for a particular song. The 
waveforms of all the tracks showed up on screen.  Website track 26 demon-
strates the mixdown of this band’s recording. 
 The sax player wanted to redo some of his parts, so we brought him 
into the studio. He overdubbed new studio parts over the live parts. I added 
some short reverb to the new sax track, which made the sax sound like it 
was in the original venue. The keyboard player re-recorded a few solos, too. 
 Some of the tracks needed to be cleaned up. In the electric-guitar 
track, I inserted a gate plug-in to remove buzzes between musical phrases. 
I also gated the kick to knock out background noise between beats. The kick 
required some EQ to sound punchy: −6 dB at 400 Hz and +6 dB at 4 kHz. Bass, 
keys, and sax sounded okay as they were. I rolled some bass off the vocals to 
counteract the mics’ proximity effect, and I compressed the vocals so that they 
could always be heard over the instrumental background. Most tracks needed 
a little reverb, set for a reverb time of 0.6 second to match the original venue. 
 Whenever the crowd cheered or clapped, I turned up the stereo 
audience track. This track was not up all the time because that can give a 
muddy, distant sound. 
 I panned each track to match the layout of the live band: sax left, 
bass center, vocals center, drums and keys in stereo, and lead guitar right. 
After tweaking the EQ and the fader automation (volume envelopes), I 
had a mix of the ﬁ rst song. I exported the song mix to a 24-bit WAV ﬁ le. 
Also, I exported the template (track conﬁ guration and settings) of that 
mix for use in mixing the other songs. 
 Finally, I loaded each song mix into Har-Bal (Harmonic Balancer), a 
program that lets you equalize the spectrum of a mix to improve its tonal 
balance. You can bring down any big peaks in the spectrum and ﬁ ll in 
the holes, resulting in a better-sounding mix that translates well to many 
types of loudspeakers. I touched up each song mix with Har-Bal’s EQ. 
Using Har-Bal is optional. 
 Mastering 
 Now all the songs’ stereo mixes were on the hard drive as individual 24-bit 
WAV ﬁ les. Each one was equalized by Har-Bal. Time to master the album. 

106
A Real-World Example: Recording a Blues Band in a Club 
 I loaded a mastering template that contained 16 tracks and a stereo 
output bus called Bus 1. That bus had a “maximizer” plug-in inserted, 
which is a peak-limiter/normalizer. It makes the CD as hot or loud as 
possible without affecting the dynamics. I set each track’s output to Bus 1, 
so that all the tracks would be maximized by the same plug-in. 
 The band had given me the song order for the CD. I imported the 
ﬁ rst EQ’d song into track 1, imported the second EQ’d song into track 2 
at the end of the ﬁ rst song, and so on. On screen was a series of audio 
clips, one per song, each on a separate track for easy time sliding and level 
adjustment (as in Figure 5-5). 
 Each song mix had some crowd noise and applause before and after 
each song. I overlapped the ending applause of Song 1 with the beginning 
of Song 2 (Figure 5-6), and so on, so that the program sounded like one 
continuous concert. If there wasn’t enough applause for a smooth transi-
tion between songs, I copied and pasted some applause from elsewhere 
in the program. 
 With the maximizer turned off, I touched up the playback level of 
each track to make the songs equally loud. That was easy because all the 
songs were recorded and mixed at about the same level. 
 I noted the start time and duration of each song clip to create a 
cuesheet for the CD-burning software. 
 When all the edits were done, and all the songs sounded equally 
loud, I enabled the maximizer to see how much peak limiting could be 
applied without distorting the mix. I turned up the gain on the maximizer 
until the gain reduction reached 6 dB on the loudest peaks. More gain 
reduction made the music distorted. Some engineers use compression as 
well to make the average level louder, but this reduces dynamic range. 
(When all music players have automatic level matching of songs, maxi-
mizing a song’s level won’t be necessary.) 
 Then I turned on dither and exported the mastered program to a 
16-bit WAV ﬁ le. Dither is low-level noise added to a 24-bit ﬁ le just before 
the last 8 bits are truncated (cut off) to make a 16-bit ﬁ le. This process 
retains most of the high resolution of the 24-bit ﬁ le when it is converted 
to a 16-bit format for CD. 
 Burning the CD-R 
 Now I could prepare to burn a CD-R of the mastered program. I wrote a 
cuesheet (shown below) that listed each song’s start time in the WAV ﬁ le. 
Actually, I set each start time about 1/3 second earlier, so that CD players 

107
A Real-World Example: Recording a Blues Band in a Club  6
won’t miss any audio at the beginning of songs. After loading the cuesheet 
into the CD-burning program, I burned a test CD and listened to it. I made 
sure that each track started on time when I pressed the CD player’s “Next 
track” button. 
 CUESHEET 
 FILE d:\bluesband\bluesbandmaster.wav 
 TRACK 01 AUDIO 
  INDEX 01 00:00:00 
 TRACK 02 AUDIO 
  INDEX 01 10:43:26 
 TRACK 03 AUDIO 
  INDEX 01 18:12:10 
 TRACK 04 AUDIO 
  INDEX 01 26:33:12 
 TRACK 05 AUDIO 
  INDEX 01 30:06:21 
 TRACK 06 AUDIO 
  INDEX 01 37:06:21 
 TRACK 07 AUDIO 
  INDEX 01 40:28:12 
 TRACK 08 AUDIO 
  INDEX 01 46:20:22 
 TRACK 09 AUDIO 
  INDEX 01 54:23:04 
 TRACK 10 AUDIO 
  INDEX 01 59:44:03 
 TRACK 11 AUDIO 
  INDEX 01 64:49:04 
 I labeled the CD-R with a CD-marking Sharpie pen. You could use a 
CD-labeling kit, but a paper label can slightly increase jitter (small timing 
errors in the digital signal). Since this CD-R was a master to be duplicated, 
I wanted it to have as little jitter as possible. Also, adhesive on the paper 
label can degrade the data on the CD-R over time. Finally, I put the CD-R 
in a soft “clamshell” case, and—after receiving payment—mailed it to the 
band. They were happy to get their CD-R: “Live at the Riverside Café.” 

This page intentionally left blank

109
 Suppose you’ve recorded a live concert and you want to distribute it on 
the Web. Or suppose you want to stream a live concert in real time on the 
Web. This chapter tells how. 
 Streaming versus Downloading 
 There are two basic ways to transmit music on the Internet: streaming 
ﬁ les and downloading ﬁ les. A streaming ﬁ le plays as soon as you click on 
its title. A downloaded ﬁ le doesn’t play until you copy the entire ﬁ le to 
your hard disk. Streaming audio can be interrupted by net congestion or 
a slow Internet connection; a downloaded ﬁ le plays without interruption. 
 You can stream audio from a recording (such as an MP3 ﬁ le). Or you 
can stream audio live in real time from an audio interface fed by mics or 
a mixer. 
 Data Compression 
 Audio ﬁ les that you record on your computer are usually WAV or AIFF 
ﬁ les. They have no data reduction (data compression), so they take up 
lots of memory. A 3-minute song recorded at 16 bits, 44.1 kHz consumes 
about 32 MB. Downloading a 32-MB WAV ﬁ le on the Web might take sev-
eral minutes. So, audio WAV ﬁ les intended for Web download are usually 
 7 
 WEB AUDIO AND STREAMING 

110
Web Audio and Streaming
data-reduced or data-compressed by encoding them as MP3, WMA, or 
other formats. For example, if you compressed a 3-minute song by 10:1 it 
would consume about 3.2 MB and would download 10 times faster than 
the equivalent WAV ﬁ le. 
 Most types of data compression tend to degrade sound quality. 
The sound quality of a compressed-data format depends on its bit rate, 
measured in kilobits per second (kbps). The higher the bit rate, the bet-
ter the sound, but the greater the ﬁ le size. A bit rate of 128 kbps for 
stereo MP3 ﬁ les is considered to be a good compromise between sound 
quality and ﬁ le size. At low bit rates (at and below 128 kbps), you can 
hear artifacts such as “swirly” cymbals, smeared transients such as 
drum hits, a general “phasey” effect, and less treble. At higher bit rates 
above 192 kbps, the artifacts start to disappear, and to most listeners the 
sound is CD quality. 
 In short, data compression reduces the ﬁ le size and the download 
time at the expense of sound quality. 
 A stereo MP3 ﬁ le encoded at 128 kbps is 64 kbps per channel. A mono 
MP3 ﬁ le encoded at 64k is equal in quality to a stereo MP3 ﬁ le encoded at 
128k. Mono ﬁ les consume half the ﬁ le space of stereo ﬁ les if both are the 
same bit rate. 
 Table 7.1 relates MP3 stereo bit rate to sound quality. 
   It’s okay to share WAV ﬁ les on the Web; it just takes longer to down-
load them than data-reduced ﬁ les such as MP3. As Internet speed increases 
in the future, there will be less need for data reduction, and we can go back 
to streaming and downloading high-quality WAV ﬁ les. For example, an 
Internet connection by ﬁ ber-optic cable (such as Verizon’s FiOS) is much 
faster than a standard copper-wire connection. FiOS is claimed to offer 
up to 50 or 30 Mbps downloads and up to 20 or 5 Mbps uploads. With 
FiOS, it’s possible to transfer WAV ﬁ les—even hi-res ones—in a short time. 
For example, www.itrax.com offers songs for sale online that are surround 
ﬁ les or 24-bit/96 kHz stereo ﬁ les. 
Table 7-1 Data Compression Ratio and Sound Quality of Various MP3 Bit Rates.
Bit Rate (CBR)
Compression
Sound Quality
64 kbps
20:1
AM radio quality
128 kbps
10:1
Cassette quality
192 kbps
7:1
Near-CD quality
256 kbps
5:1
CD quality
320 kbps
4:1
CD quality

111
Web Audio and Streaming 7
 Compression can be either lossless or lossy. To reduce ﬁ le size, 
lossless compression eliminates statistical redundancy. No information 
is lost in lossless compression—the sound quality of the original ﬁ le is 
maintained. Lossy compression (such as MP3) removes sounds that are 
deemed inaudible due to masking. It sacriﬁ ces some sound quality in 
return for a smaller ﬁ le size. Note that converting an MP3 into a WAV 
does not improve its quality. 
 Web-Related Audio Files 
 You can put audio on the Web in several ﬁ le formats. Let’s look at some of 
the ﬁ le types in current use. 
 WAVE (.WAV) : A standard PC format for audio ﬁ les. It encodes 
sound without any data reduction by using pulse code modulation. WAV 
ﬁ les that are used to make audio CDs are 16 bit, 44.1 kHz. 
 AIFF (.AIF) : Audio Interchange File Format, a standard Mac format 
for audio ﬁ les. Use this format to transfer audio ﬁ les between a PC and a 
Mac. Like WAV ﬁ les, AIFF ﬁ les are not data-compressed. 
 The following formats use data compression. 
 MP3 (MPEG Level-1 Layer-3) : The most popular format. You can 
choose a low bit rate to make a small ﬁ le with lower sound quality, or 
choose a high bit rate to make a larger ﬁ le with higher quality. 
 When encoding an MP3 ﬁ le, you have a choice of constant bit rate 
(CBR) or variable bit rate (VBR). VBR uses more bits on complex musical 
passages and fewer bits on simpler passages. CBR encodes every frame at 
the same bit rate, so it is less efﬁ cient. Use VBR to get a ﬁ xed level of qual-
ity at the lowest possible bit rate and ﬁ le size. CBR is recommended only 
for streaming where the bit rate must be ﬁ xed. Average bit rate (ABR) is 
a compromise between CBR and VBR modes. Use ABR when you need 
to know the size of the encoded ﬁ le but still allow some variation in the 
bit rate. 
 MP3PRO : An improvement over MP3. Songs encoded at 64 kbps with 
MP3PRO are said to sound as good as songs encoded at 128 kbps with 
MP3. MP3PRO offers faster downloads and nearly doubles the amount 
of music you can put on a ﬂ ash-memory player. MP3 and MP3PRO ﬁ les 
are compatible with each other’s players, but a free MP3PRO player is 
needed to hear MP3PRO’s improvement in sound quality. See www.
MP3prozone.com. 
 WMA (Windows Media Audio) : This popular Microsoft format pro-
vides Digital Rights Management (DRM), which is licensing technology 

112
Web Audio and Streaming
that provides copy protection. It’s useful for online music stores. For 
more information see http://windows.microsoft.com/en-us/windows/
windows-media. WMA Pro also supports multichannel and high-
resolution audio. 
 OGG (Ogg Vorbis) : License-free open software. For a given ﬁ le size, 
Vorbis sounds better than MP3. Vorbis takes up less ﬁ le size than MP3 
ﬁ les of equal quality. For more information see www.vorbis.com. 
 AAC (MPEG Advanced Audio Coding) : AAC offers better sound qual-
ity than MP3 at the same bit rate. Many listeners claim that AAC ﬁ les 
made at 128 kbps sound like the original uncompressed audio source. 
What’s more, AAC supports multichannel audio and a wide range 
of sample rates and bit depths. It’s also used with Digital Rights Man-
agement technology, helping to control the copying and distributing 
of music. 
 HD-AAC  combines MPEG-4 AAC lossy compression with MPEG-4 
SLS lossless coding. It provides a single ﬁ le which can be scaled anywhere 
from audiophile quality to low-bitrate quality. From a single HD-AAC 
encoded ﬁ le, you can play a lossless, high-quality version on your home 
stereo, and play a lossy, small-ﬁ lesize version on an iPod. 
 FLAC (Free Lossless Audio Codec) : A codec that keeps the sound qual-
ity of your mix, but reduces ﬁ le size by about half. It’s lossless: the audio 
is compressed (data reduced) without any loss in sound quality. Unlike 
WAV ﬁ les, FLAC lets you embed metadata into the ﬁ le which is displayed 
by a music player—artist, album, song, ISRC, and so on. See https://xiph.
org/ﬂ ac/. 
 Currently, WMA and MP3 are the most popular types of data-
compressed files. 
 What You Need 
 To put your music on the Web, you need to download a few pieces of 
software, which are low cost or free: 
 Ripper : Also called a grabber, this program converts audio from a CD 
or CD-R to a WAV ﬁ le. Examples are Exact Audio Copy (www.exactau-
diocopy.de), CDex (http://cdexos.sourceforge.net), and FreeRip3 (www.
freerip.com/). Windows Media Player 12 rips to MP3 and other formats 
(http://windows.microsoft.com/en-us/windows/windows-media-
player). If your recording is on a computer hard drive instead of a CD, 
you don’t need a ripper. 

113
Web Audio and Streaming 7
 MP3 Encoder : A program that converts a WAV or AIFF ﬁ le to an 
MP3 ﬁ le. Examples of freeware are RazorLame (www.free-codecs.com/
download/RazorLame.htm) and Lame MP3 Encoder (www.free-codecs.
com/download/Lame_Encoder.htm). You need both. Another option 
is Switch WAV to MP3 Converter from www.nch.com.au/switch/MP3.
html?gclid=CKfzgObX-rkCFRPl7AodYxYAlw. In Google search for WAV 
to MP3 converter. Some recording software includes an MP3 encoder, 
and so does FreeRip3, CDex, dBpowerAmp, foobar2000, Audio MP3 Edi-
tor, and Exact Audio Copy. 
 ID3 Tag Editor : This program lets you add song title, artist, genre, and 
other metadata information to an MP3 ﬁ le. This information displays on 
screen when the MP3 ﬁ le plays. You can add studio contact information in 
a comments ﬁ eld. Two freeware programs are Stamp ID3 Tag Editor and 
MP3tag. Several MP3 playback programs include a tag editor. If you create 
Broadcast WAV ﬁ les for download, use this utility to create the appropri-
ate metadata: http://sourceforge.net/projects/bwfmetaedit/. 
 WMA Encoder : An optional program that converts a WAV or AIFF ﬁ le 
to a WMA ﬁ le. Several are at www.team-MP3.com/wma/wma_encoder.
htm. Windows Media Technologies has Digital Rights Management, 
which limits copies or format conversions. 
 Ogg Vorbis Encoder (optional) : from www.vorbis.com. Converts 
CD tracks or WAV ﬁ les to Vorbis format. For a given ﬁ le size, Vorbis 
sounds better than MP3. Vorbis takes up less ﬁ le size than MP3 ﬁ les of 
equal quality. 
 To listen to your music that you put on the Web, you need: 
 MP3 Player : A program or a device that plays MP3 ﬁ les. Some soft-
ware player examples are Windows Media Player from www.microsoft.
com/windows/windowsmedia, RealPlayer Cloud from www.real.com, 
and QuickTime in Apple’s OS or www.apple.com/quicktime/. Most new 
computers include an MP3 player. Portable MP3 players play MP3 ﬁ les 
downloaded from the Web. 
 Windows Media Player : Although intended to play mainly Windows 
Media ﬁ les, this free program plays many ﬁ le types: .avi, .asf, .asc, .rmf, .wav, 
.wma, .wax, .mpg, .mpeg, .m1v, .mp2, .MP3, .mpa, .mpe, .ra, .mid, .rmi, .qt, 
.aif, .aifc, .aiff, .mov, .au, .snd, .vod. This player is a free download from www.
microsoft.com/windows/windowsmedia/ .  
 A source for players, rippers, and encoders is www.team-MP3.
com. Some digital audio editing programs can output MP3 and 
WMA files. 

114
Web Audio and Streaming
 How to Prepare and Upload Audio Files 
 Got everything you need? Let’s go. Basically, here’s what you will be 
doing: 
 1. Start with a WAV ﬁ le of a song on your computer. Or convert your 
song from a CD to a WAV ﬁ le by using a ripper. 
 2. Edit and process the WAV ﬁ le to optimize it for the Internet. 
 3. Then use an encoder to convert the WAV ﬁ le to an MP3 or WMA ﬁ le. 
 4. Finally, send (upload) the converted ﬁ le to a website that features 
music in the MP3 or WMA format. 
 Let’s go over the procedure in more detail. You can substitute WMA for 
MP3 in the procedure below. 
 1. Start with a WAV ﬁ le of the song. Edit the start and stop points of 
the song. You might want to edit a 30-second excerpt of a song to use 
as a preview of your music. If so, add a fade-in and fade-out to the 
preview. 
 2. Next, you might want to process the audio so that it will sound louder 
and clearer when played on the Web. To do this, reduce the band-
width: apply low cut below 40 Hz and high cut above 15 kHz. You 
might want to try a higher-frequency low cut and a lower-frequency 
high cut. If you’re not working with classical music, apply a little 
compression or multiband compression, apply peak limiting, then 
normalize the song to maximize its level. 
  
  Save the edited, processed song as a WAV ﬁ le (PC) or AIFF ﬁ le 
(Mac) on your hard drive. 
 3. Use an MP3 encoder to convert the song’s WAV or AIFF ﬁ le to an 
MP3 ﬁ le on your hard drive. You might want to use a bit rate of 
128 kbps, which many websites require. It’s a good compromise 
between ﬁ le size and sound quality. 
 4. If you want, add the song’s title, artist, and comments using an ID3 
tag editor. 
 5. Next you will upload your MP3 ﬁ les to an MP3 server—a website 
that accepts MP3 ﬁ les for distribution on the Web. Examples inc lude 
www.soundcloud.com, www.bandcamp.com, and www.reverbnation.
com. The CD duplicator Disc Makers will upload your songs quickly 
to a variety of services for a small fee. Also see the MP3 Sites page 

115
Web Audio and Streaming 7
at http://www.team-mp3.com. Some sites offer free downloads of 
their music ﬁ les; others charge the listener so that you make some 
income. 
 As an alternative, you can send your physical CD to CD Baby (www.
cdbaby.com), and they will convert it to data-compressed ﬁ les for you. 
  Figure 7-1   shows their website. They are a popular, affordable way for 
independent artists to sell CDs. Another such site is www.discogs.com. 
   CD Baby’s MusicStore on Facebook is a free, easy way to stream and 
sell your music from your Facebook band page. You can also upload photos 
and videos, customize your store’s design, and more. Create a CD Baby 
account at www.members.cdbaby.com. Then you can sell your music on 
Facebook, as well as iTunes, Amazon, Spotify, and many other online music 
stores. CD Baby will handle all the transactions and accounting for you. 
 ReverbNation is another digital distributor worth checking out. 
With it you can build an online store for your music and integrate it with 
Facebook. Bandcamp and Nimbit also provide that service. 
 eMusic (www.emusic.com) does not work with unsigned artists, 
but they do accept music from independent labels. Usually this is done 
through a service such as The Orchard (www.theorchard.com), INgrooves 
Figure 7-1 CD Baby Website.

116
Web Audio and Streaming
(www.ingrooves.com) or TuneCore (www.tunecore.com). They can com-
press and deliver a label’s CD catalog to all digital music stores. All 
income from digital sales is combined and reported to you. 
 Once you have chosen a site, go there and click on the button labeled 
“Artists Only,” “Submit your music,” “Sell your music,” or something 
similar. This is where you upload your MP3 ﬁ les. 
 After you sign up and ﬁ ll out some forms, click on “Upload” (or 
whatever). You can also upload scanned photos of your band, your album 
cover, and text describing your band and its music. Some sites take a few 
days or weeks to approve your songs. 
 Some Internet radio stations might be willing to play your record-
ings. You could email WAV, MP3 or WMA ﬁ les to them. If you want to 
use those compressed-data formats, encode the MP3 or WMA ﬁ les at 
256 kbps or higher, VBR, for best sound quality. 
 Sending WAV, MP3 or WMA ﬁ les by email can be cumbersome 
because some email programs limit attachments to 10 MB. Also, the per-
son receiving the ﬁ le attachment will have to wait a long time for the 
email to download. A better arrangement is to upload the audio ﬁ les to 
a ﬁ le-sharing website such as www.hightail.com or www.dropbox.com. 
When the recipient is ready to download the Hightail ﬁ le, they simply 
click on a link that Hightail emails to them. 
 Congratulations—you’re on the Web! 
 Putting Your Music On Your Website 
 So far I’ve covered how to upload your songs to an MP3 server. Now I’ll 
explain how to put your songs on your own website. Basically, you load MP3 
ﬁ les of your recordings to your website and create links to those ﬁ les. People 
visiting your site can click on a song title to hear a streaming song preview, 
or to download an entire song. You might upload your MP3 ﬁ les to Sound-
Cloud, and use a SoundCloud player on your website or Facebook page. 
 You can substitute WMA for MP3 in the procedure below. 
 1. Suppose you have a song called “Blues Bash” on a CD or on your 
hard drive as a WAV ﬁ le. If the song is on a CD, use ripper software 
to transfer that song to your hard drive as a WAV ﬁ le (PC) or AIFF 
ﬁ le (Mac). In this example, we’ll call the ﬁ le  blues.wav. 
 2. Use an MP3 encoder to convert the WAV ﬁ le to an MP3 ﬁ le. I recom-
mend a setting of 160-kbps bit rate, VBR, stereo. This setting gives 

117
Web Audio and Streaming 7
pretty good sound with a relatively small ﬁ le, so it’s fairly quick to 
download. You now have an MP3 ﬁ le called  blues.MP3. 
 3. You can add song-title and artist information with an ID3 tag 
editor. 
 4. In your FTP program or your website’s administration area, upload 
 blues.MP3  to your website server. Choose an appropriate folder in 
which to put the MP3 ﬁ le. 
 5. Use webpage design software to open your band’s webpage. Here 
we’ll call it  bandpage.htm. 
 6. On that page, where you want the song title to appear, type in the 
title of the song. In this example it’s “Blues Bash.” Link that title to 
 blues.MP3 (including the folder it’s in, if necessary). 
 When you left-click on the song title,  blues.MP3 should load and 
play. When you right-click on the song title, you can select “Save Target 
As” to copy the MP3 ﬁ le to a directory on your hard drive. 
 If you want to use HTML code: 
 1. Open your webpage with a browser such as Windows Explorer. 
 2. Select View > Source. You’ll see the HTML code for that page in 
plain text format. 
 3. Find a spot on the page where you want the song title to appear. 
Type in the title of the song and the link to its MP3 ﬁ le. If the MP3 
ﬁ le is in the root directory of your website, the HTML code would 
look something like this: 
 <a href = “blues.MP3”> Blues Bash </a>. 
 For a WMA ﬁ le it would be: 
 <a href = “blues.wma”>Blues Bash</a>. 
 If  blues.MP3  is in a subdirectory called “audio_ﬁ les” in your website, 
the code would be: 
 <a href = “../audio_ﬁ les/blues.MP3”>Blues Bash</a>. 
 4. Save and close the text ﬁ le, go to Windows Explorer, and select 
View > Refresh. You should see the link to the MP3 or WMA song. 
When you left-click on the link, you should hear the song. When 
you right-click on it, you can select “Save Target As” to copy the 
MP3 ﬁ le to a directory on your hard drive. 

118
Web Audio and Streaming
 Real-Time Streaming of a Live Concert 
 So far we covered how to stream a recording on the Web. But suppose you 
want to stream (broadcast) your mix of a live concert in real time. This 
webcast can be fairly easy. 
 A webcast is an audio and/or video event broadcast on the Web, 
using streaming technology, to several Web listeners or viewers at the 
same time. A webcast may be distributed live (streaming) or on demand 
(downloaded). 
 You’ll need the following hardware: 
 • A 2.4 GHz or faster computer with at least 2 GB of RAM 
 • A 2-channel or higher audio interface 
 • A broadband Internet connection with a minimum upload speed of 
256 kbps. Use satellite, T1, T3, DSL, cable, or ISDN, not dialup. 
 Streaming audio requires a fast computer. So defragment your hard 
drive, turn off your network and file-sharing, and close all unused 
programs. 
 Several online sites will stream your audio for you. For more infor-
mation on streaming software, Google “live audio streaming.” An easy 
site to use is www.mixlr.com. You can stream audio using Mixlr as an 
Internet radio station, or customize your own live player and embed it in 
your website by copying and pasting some widget code from their site. 
Mixlr also has tutorials that show how to create a SoundCloud playlist, 
share broadcasts on Facebook or Twitter, and invite listeners to a live con-
cert online. 
 Since Mixlr is free (in its basic version) and easy to use, let’s try it 
out. First, you will install an Mixlr app that lets you stream live audio 
from your audio interface to the Mixlr website, and to your own website’s 
embedded player. 
 1. Go to www.mixlr.com. Sign up (it’s free). 
 2. Click Broadcast > Get Mixlr app > Download Now. 
 3. Install the app on your computer.  Figure 7-2 shows the app. 
   Get an audio interface, plug it into your computer, install its software, and 
turn it on. Plug a mic into the interface, talk, and set the level as high as 
possible without clipping. 

119
Web Audio and Streaming 7
 When everything is ready: 
 1. Launch the Mixlr app that is on your computer. 
 2. In that app, select the audio source: your audio interface. 
 3. Click on My Broadcast > Enter a title, musical category, and select 
Social ON or OFF. 
 4. Select Recording ON if you want to record the broadcast to the 
“Showreel” on Mixlr. 
 5. Click “Start Broadcast” and begin talking into the mic. 
Figure 7-2 Mixlr app.

120
Web Audio and Streaming
 6. After about 30 seconds of buffer delay, your live audio from your 
interface will be heard streaming on the Mixlr website in the musical 
category you selected. If you embedded a player on your website, 
the audio will play on your website when the listener selects “Click 
to play” on the player. The player audio occurs about ﬁ ve seconds 
after the live audio. 
 Now let’s say you want to stream a live concert using Mixlr. Once you 
know the date, time and website of the broadcast, tell your potential lis-
teners using email, Facebook, Twitter, Mixlr, your website, etc. 
 You’re at the concert venue from which you want to stream your 
audio mix. You’ve set up mics, mic stands, DIs, a mic snake, mic split-
ter and a mixer to create the live mix. Install your mixer and monitor 
speakers in a quiet room separate from the concert hall so you can hear 
what you’re mixing. Use a mic splitter that feeds the FOH mixer, monitor 
mixer, and your own mixer. 
 Here’s a low-cost option that omits the splitter: set up in the concert 
hall or room. Take an audio feed from the FOH console and mix it with 
a stereo pair of mics facing the stage. A drawback of this method is that 
the FOH mix might not sound good. So you might prefer to use your own 
mics and mixer, independent of the house system. If so, do the mix in an 
isolated room where you can hear what you’re mixing. Use a Y-cable or 
small splitter on each vocal mic to feed both your mixer and the FOH 
mixer. 
 Set up a good mix with proper levels during the sound check. You 
might also want to have a stand-mounted mic plugged into your mixer to 
announce the show to your Internet listeners. Connect your audio mixer 
to an audio interface. Plug the interface USB or FireWire cable into your 
computer and turn everything on. 
   Figure 7-3   is a diagram of the complete audio capture and streaming 
system. 
   Launch the Mixlr app on your computer and click “Start Broadcast” 
a few minutes before the concert starts. At the designated time, you can 
announce the concert using a mic plugged into your mixer. 
 Another easy-to-use streaming audio site is Rogue Amoeba. They 
offer Nicecast software for Mac, which broadcasts audio in real time over 
the Internet (www.rogueamoeba.com/nicecast/ ). 
 For more advanced users, choose a Content Distribution Network 
(CDN), also called a streaming service provider. They charge a fee to 
broadcast your audio. Some examples are PPLive, Amazon Cloudfront, 

121
Web Audio and Streaming 7
Netromedia.com and NetDNA. Each offers online tutorials on how to use 
them, so they won’t be covered here. Also check out www.live365.com. 
With a Live365 Pro Package you get distribution on iTunes, Internet, 
Roku, Tivo, mobile devices (Android, iPhone), and more. Other features 
are social-media sharing tools and customizable player windows for your 
website. They have a setup fee and a monthly fee. 
 Before using a CDN, choose a bit rate at which you want to broadcast. 
20 kbps is adequate for speech; 64 kbps mono is considered near-CD qual-
ity for music; 128 kbps stereo is considered near CD quality. The upload 
speed of your Internet connection should be at least 2.5X the bit rate. A 
speed of 2.5 Mbps or more is recommended for video. 
 Facebook is partnering with streaming sites—such as Spotify, MOG, 
turntable.fm and Pandora—to stream music for free. Spotify and others 
also offer a subscription service for a monthly fee. It doesn’t generate 
much income for artists—fractions of a cent per stream—but the exposure 
can be huge, especially on Facebook. 
 Here’s a tutorial on using Shoutcast to set up your own Internet 
radio station: 
 www.webradiocentral.com/setup -internet- radio -station. 
Figure 7-3 Real-time streaming system.

122
Web Audio and Streaming
 You can stream video as well. Check out www.ustream.tv/ and http://
new.livestream.com/live-video-tools. When broadcasting live video and 
audio simultaneously, you might need to delay the audio to match the 
video. Wirecast Pro includes this feature. 
 To learn more, search www.amazon.com under “Books” for “streaming 
media.” 

Part 2
Classical Music Recording 
(Orchestra, string quartet, 
pipe organ, choir, soloist)

This page intentionally left blank

125
 Classical music ensembles usually are recorded with stereo microphone 
techniques. You place two or three mics several feet in front of the ensem-
ble to pick up the group and the hall reverberation as a whole. 
 Before you can understand how stereo microphone arrays work, 
you need to understand microphone polar patterns. This chapter explains 
them, as well as other speciﬁ cations that help you choose mics and acces-
sories for stereo recording. 
 Polar Patterns 
 Microphones differ in the way they respond to sounds coming from dif-
ferent directions. Some mics pick up sound equally from all directions. 
Other mics emphasize sound from the front, but have reduced pickup of 
sounds coming from the sides and rear. In other words, the sensitivity of 
the mic varies depending on the angle of the sound source. 
 For example, a source in front of a mic (0° on axis) might produce a 
signal level from the mic that we’ll call 0 dB. That same source at the side 
of the mic (90° off axis) might produce a signal at –6 dB. The same source 
at the rear of the mic (180° off axis) might produce a signal at –20 dB. 
A mic with this characteristic has a cardioid polar pattern. If you talk 
 8 
 MICROPHONE 
SPECIFICATIONS 

126
Microphone Specifications
into a cardioid microphone from all sides while listening to its output, 
your reproduced voice will be loudest when you talk into the front of the 
microphone and softest when you talk into the rear. 
 If we graph or plot this varying sensitivity versus angle around the 
mic, we get a polar pattern for the microphone. Sensitivity in dB is plotted 
versus the angle of sound incidence in degrees. Often, several plots are 
made at various frequencies. 
 The three major polar patterns are omnidirectional, unidirectional, 
and bidirectional (  Figure 8-1 ):  
 1. An  omnidirectional  (omni) mic is equally sensitive to sounds arriving 
from all directions. 
 2. A  unidirectional  microphone is most sensitive to sounds arriving 
from one direction—in front of the microphone—and rejects sounds 
entering the sides and rear of the microphone. 
 3. A  bidirectional  microphone is most sensitive to sounds arriving 
from two directions—in front of and behind the microphone—but 
rejects sounds entering the sides. Another name for “bidirectional” 
is “ﬁ gure-eight.” 
 Three types of unidirectional patterns are cardioid, supercardioid, and 
hypercardioid (  Figure 8-1 ): 
 1. The  cardioid  mic is sensitive to sounds arriving from a broad angle 
in front of the microphone. It is about 6 dB less sensitive at the sides 
and about 15–25 dB less sensitive at the rear. 
 2. The  supercardioid  pattern is about 9 dB down at the sides and has 
two nulls—points of least pickup—at 125° either side off axis. “Off 
axis” means “away from the front.” 
 3. The  hypercardioid  pattern is 12 dB down at the sides and has two 
nulls of least pickup at 110° either side off axis. 
 An omnidirectional boundary microphone (a surface-mounted micro-
phone, explained later) has a half-omni, or hemispherical, polar pattern. 
A unidirectional boundary microphone has a half-supercardioid or half-
cardioid polar pattern. The boundary mounting increases the directionality 
of the microphone and reduces pickup of room acoustics. 
 Some condenser mics come with switchable polar patterns. 
 Note that a polar plot is not a geographical map of the “reach” of a 
microphone; a microphone does not suddenly become dead outside its 

Figure 8-1 Various polar patterns. Sensitivity is plotted versus angle of sound 
incidence.

128
Microphone Specifications
polar pattern. There is no “outside.” The graph merely plots sensitivity at 
one frequency as distance from the origin; it is not the spatial spread of 
the pattern. 
 Advantages of Each Pattern 
 Omnidirectional microphones have several characteristics that make 
them especially useful for certain applications. Use omni mics when you 
need: 
 • all-around pickup 
 • extra pickup of room reverberation 
 • low handling noise and low wind noise 
 • extended low-frequency response in omni condenser mics 
 • freedom from proximity effect (up-close bass boost). 
 Use directional microphones when you need: 
 • rejection of room acoustics and background noise, 
 • coincident or near-coincident stereo (explained in the next chapter). 
 Off-Axis Coloration 
 In a quality microphone, the polar pattern is about the same at all frequen-
cies between about 100 Hz and 10 kHz. If not you’ll hear off-axis coloration: 
the mic will sound tonally different on and off axis. For example, the treble 
might be strong on axis and weak off axis. 
 Transducer Type 
 We’ve seen that microphones differ in their polar patterns. They also differ 
in the way they convert sound into electricity. The three operating prin-
ciples of recording microphones are condenser, moving coil, and ribbon. 
 Of the three types, the condenser microphone generally has the widest, 
smoothest frequency response, and the highest sensitivity. It tends to have a 
natural, detailed sound, and it produces a strong signal that overrides mic-
preamp noise. So it is the ﬁ rst choice for miking a classical music ensemble. 

129
Microphone Specifications 8
 The condenser mic requires a power supply to operate, such as a 
battery or phantom power. Phantom power is provided by an external 
phantom-power supply, a mixer, or a mic preamp. 
 Ribbon mics have a smooth response, and most have a ﬁ gure-eight 
polar pattern—making them suitable for the Blumlein stereo mic tech-
nique covered in Appendix B. 
 Sensitivity 
 Sensitivity is another speciﬁ cation to consider. It is a measure of the efﬁ -
ciency of a microphone. A very sensitive microphone produces a relatively 
high output voltage from a sound source of a given loudness. 
 Microphone sensitivity is usually stated in millivolts/Pa, where 1 Pa = 
1 pascal = 94 dB SPL. The following list gives typical sensitivity specs for the 
three microphone types: 
 Condenser: 10 mV/Pa (high sensitivity) 
 Moving coil: 2 mV/Pa (medium sensitivity) 
 Ribbon or small moving coil: 1 mV/Pa (low sensitivity) 
 A low-sensitivity mic requires more mixer gain to achieve a good record-
ing level than a high-sensitivity mic, and more gain usually results in 
more noise. If you record quiet, distant instruments, such as a classical 
guitar or those of a chamber music ensemble, you’ll hear more mixer 
noise with a low-sensitivity mic than with a high-sensitivity mic, all else 
being equal. Because stereo miking is usually done at a distance, high 
sensitivity is an asset. 
 Self-noise 
 Self-noise is the electrical noise (hiss) a microphone produces. This spec 
is usually A-weighted—that is, the noise was measured through a ﬁ l-
ter that makes the measurement correlate more closely with the annoy-
ance value. The ﬁ lter rolls off low and high frequencies to simulate the 
frequency response of the human ear. An A-weighted self-noise spec of 
14 dB SPL or less is excellent (quiet); a spec around 20 dB SPL is very 
good, and a spec around 25 dB SPL is verging on too noisy for distant 
miking of quiet music. 

130
Microphone Specifications
 Microphone Types 
 Another speciﬁ cation is the type of microphone: the generic classiﬁ cation. 
Some types of microphones for stereo miking are free ﬁ eld, boundary, and 
stereo. 
 Free-Field Microphone 
 Most microphones are of this type. They are meant to be used in a free 
ﬁ eld—that is, away from reﬂ ective surfaces. Two types of free-ﬁ eld mics 
are the side-addressed large-diaphragm type (  Figure 8-2  ) and the end-
addressed small-diaphragm type (  Figure 8-3  ). Both types are used to 
mike orchestras. In general the large-diaphragm type has lower noise and 
deeper bass in cardioid models, while the small-diaphragm type has less 
off-axis coloration (the tone quality is almost the same on and off axis).  
 Boundary Microphone 
 A boundary microphone is designed to be used on such surfaces as a 
ﬂ oor, wall, table, piano lid, bafﬂ e, or panel. One example of a bound-
ary microphone is the Crown Pressure Zone Microphone (PZM) shown 
in   Figure 8-4  . It includes a miniature omni condenser capsule mounted 
facedown next to a sound-reﬂ ecting plate or boundary. Because of this 
Figure 8-2 A side-addressed, large-diaphragm microphone.
DIAPHRAGM
GRILLE
ELECTRONICS

131
Microphone Specifications 8
construction, the microphone diaphragm receives direct and reﬂ ected 
sounds in-phase at all frequencies, avoiding phase interference between 
them. The claimed beneﬁ ts are a wide, smooth frequency response free of 
phase cancellations, excellent clarity and “reach,” a hemispherical polar 
TYPICAL DYNAMIC VOCAL MIC
TYPICAL CONDENSER INSTRUMENT MIC
GRILLE
MIC CAPSULE
WIRES
CONNECTOR
DIAPHRAGM
MAGNET
SHOCK MOUNT
HOUSING
GRILLE
DIAPHRAGM
REAR PORT
HOUSING
CIRCUIT BOARD
CONNECTOR
Figure 8-3 An end-addressed, small-diaphragm microphone.
Figure 8-4 Crown PZM construction (courtesy: Crown International).

132
Microphone Specifications
pattern, and uniform frequency response anywhere around the micro-
phone. Because of this last characteristic, hall reverberation is picked up 
without tonal coloration. 
   Boundary microphones are also available with a unidirectional polar 
pattern. They have the beneﬁ ts of both boundary mounting and the unidi-
rectional pattern. Such microphones are well suited for stage-ﬂ oor pickup 
of drama, opera, musicals, soloists, and small musical ensembles. 
 Stereo Microphone 
 A stereo microphone combines two mic capsules in a single housing for 
convenient stereo recording. Simply place the microphone about 10–15 
feet in front of a band, choir, or orchestra, and you’ll get a stereo recording 
with little fuss. In general, a stereo microphone is easier to set up than two 
separate microphones, but it’s more expensive. 
 Several websites of stereo microphones are listed in  Chapter 12 , and 
one is shown in  Figure 8-5 . 
Most stereo microphones are made with coincident microphone cap-
sules; they occupy nearly the same point in space. Since there is no hori-
zontal spacing between the capsules, there also is no delay or phase shift 
between their signals. If you combine the two stereo mic channels to mono, 
there is no phase interference that can degrade the frequency response. 
Thus, the coincident-pair stereo microphone is mono-compatible: the fre-
quency response is the same in mono as in stereo.
Figure 8-5 A stereo microphone.

133
Microphone Specifications 8
 Stereo microphones are available in many conﬁ gurations, such as 
XY, MS, Blumlein, ORTF, OSS, and SoundField (all described in Appen-
dices B and C). The MS (mid–side) stereo microphone and SoundField 
microphone let you remote-control the stereo spread and vary the stereo 
spread after recording. 
 Microphone Accessories 
 Various accessories used with microphones enhance their convenience, 
aid in placement, or reduce vibration pickup. 
 Stands and Booms 
 The top of a mic stand has a standard 5/8 inch-27 thread (3/8 inch out-
side the US), which screws into a microphone stand adapter. Camera 
stores have photographic stands, which are collapsible and lightweight—
ideal for recording on location. The thread is usually 1/4 inch-20, which 
requires an adapter to ﬁ t a 5/8 inch-27 (or 3/8 inch) thread in a mic stand 
adapter. Some mic stands have telescoping sections for extra height, and 
some have collapsible tripod stands for more stability and less weight. 
 You can use a mic boom as an extension to raise a microphone far-
ther off the ﬂ oor—in order to stereo mike an orchestra, for example. 
 Stereo Microphone Adapter 
 A stereo microphone adapter (stereo bar or stereo rail) mounts two micro-
phones on a single stand for convenient stereo miking. Several websites 
of these are listed in  Chapter 12 , and one is shown in   Figure 8-6  . In most 
models, the microphone spacing and angling are adjustable. 
Figure 8-6 A stereo microphone adapter.

134
Microphone Specifications
 Shock Mount 
 When mounted on a mic stand, this device holds a microphone in a resil-
ient suspension to isolate the microphone from mechanical vibrations, 
such as stand and ﬂ oor thumps. The shock mount acts as a spring that 
resonates at a sub-audible frequency with the mass of the microphone. 
This mass-spring system attenuates mechanical vibrations above its reso-
nance frequency. 
 Many microphones have an internal shock mount that isolates the 
microphone capsule from its housing; this reduces handling noise as well 
as stand thumps. 
 With a good grasp of microphone specs and accessories, we’re ready 
to discuss stereo mic techniques. 

135
 Stereo miking is the preferred way to record classical music ensembles 
and soloists, such as a symphony performed in a concert hall or a string 
quartet piece played in a recital hall. 
 Stereo mic techniques capture the sound of a musical group as a 
whole, using only two or three microphones. When you play back a 
stereo recording, you hear  phantom images  of the instruments in vari-
ous spots between the speakers. These image locations—left to right, 
front to back—correspond to the instrument locations during the 
recording session. 
 In this chapter we look at several techniques for recording in stereo. 
 Advantages of Stereo Miking 
 When recording popular music, we put a mic near each instrument, record 
it, and pan its image somewhere between our two monitor speakers. Then 
we hear where each instrument is: left, center, half-right, or whatever. But 
panned mono tracks are not the same as true stereo. A two-mic stereo 
recording captures the holistic sound of the ensemble playing together 
in a shared space. Large single instruments—such as piano, drums, and 
pipe organ—also beneﬁ t from being recorded in stereo. 
 9 
 OVERVIEW OF STEREO 
MICROPHONE TECHNIQUES 

136
Overview of Stereo Microphone Techniques
 Stereo miking adds lifelike realism to a recording because it captures: 
 • The left-to-right position of each instrument. 
 • The depth or distance of each instrument. 
 • The distance of the ensemble from the listener (the perspective). 
 • The spatial sense of the acoustic environment, the ambience or hall 
reverberation. 
 • The timbres of the instruments as heard in the audience. 
 These characteristics are lost with multiple close-up microphones. 
 Another advantage of stereo miking is that it tends to preserve the 
ensemble balance as intended by the composer. The composer has assigned 
dynamics (loudness notations) to the instruments in order to produce a 
pleasing ensemble balance in the audience area. Thus, the correct balance 
or mix of the ensemble occurs at a distance, where all the instruments blend 
together acoustically. But this balance can be upset with multiple miking. 
You must rely on your own judgment (and the conductor’s) regarding 
mixer settings to produce the composer’s intended balance. Of course, even 
a stereo pair of mics can yield a faulty balance. But a stereo pair, being at a 
distance, is more likely to reproduce the balance as the audience hears it. 
 Some outstanding examples of non-orchestral two-mic stereo record-
ings are those by Bob Katz (www.chesky.com), Pierre Sprey (www.
mapleshaderecords.com), and Kavi Alexander (www.waterlilyacoustics.
com). 
 Goals of Stereo Miking 
 One goal we aim for when miking an ensemble in stereo is accurate local-
ization. That is, instruments in the center of the group are reproduced 
midway between the two speakers. Instruments at the sides of the group 
are heard from the left or right speaker. Instruments halfway to one side 
are heard halfway to one side, and so on. 
  Figure 9-1  shows four stereo localization effects.  Figure 9-1(a)  shows 
some instrument positions in an orchestra: left, left-center, center, right-
center, right. In  Figure 9-1(b) , the reproduced images of these instruments 
are accurately localized between the speakers. The stereo spread, or stage 
width, extends from speaker to speaker. (You might want to record a 
string quartet with a narrower spread.) 
 A stereo pair of microphones can be angled apart, spaced apart, or 
both. Angling and spacing affect the stereo localization, as does the polar 
pattern of the microphones. 

137
Overview of Stereo Microphone Techniques 9
 If you space or angle the mics too close together, you get a narrow 
stage width ( Figure 9-1(c) ). If you space or angle the mics too far apart, 
you hear exaggerated separation ( Figure 9-1(d) ). That is, instruments 
halfway to one side are heard near the left or right speaker. 
 To judge stereo effects, you have to sit exactly between your moni-
tor speakers (the same distance from each). Sit as far from the speakers 
as the spacing between them. Then the speakers appear to be 60° apart. 
That is about the same angle an orchestra ﬁ lls when viewed from a typical 
ideal seat in the audience (say, tenth-row center). If you sit off-center, the 
images shift toward the side on which you’re sitting and are less sharp. 
 Play Website tracks 1–4 to set up your monitor speakers correctly for stereo 
listening. 
 Types of Stereo Mic Techniques 
 To make a stereo recording, you can use one of these basic techniques: 
 1. Coincident pair. 
 2. Spaced pair. 
 Figure 9-1 Stereo localization effects: (a) orchestra instrument locations (top 
view); (b) images localized accurately between speakers (the listener’s perception); 
(c) narrow-stage effect; and (d) exaggerated separation effect. 

138
Overview of Stereo Microphone Techniques
 3. Near-coincident pair. 
 4. Bafﬂ ed pair. 
 Let’s look at each technique. 
 Coincident Pair 
 With this method (also called XY), you mount two directional mics 
with grilles touching, diaphragms one above the other, and angled 
apart ( Figures 9-2 and  9-3 ). For example, mount two cardioid mics with 
one grille above the other, and angle them 120° apart. You can use other 
patterns too: supercardioid, hypercardioid, or bidirectional. The wider 
the angle between mics, the wider the stereo spread.  
 Figure 9-2 Coincident-pair technique. 
 Figure 9-3 Photo of coincident-pair technique. 

139
Overview of Stereo Microphone Techniques 9
 How does this technique make images we can localize? Recall that a 
directional mic is most sensitive to sounds in front of the mic (on axis) and 
progressively less sensitive to sounds arriving off axis. That is, a direc-
tional mic puts out a high-level signal from the sound source it’s aimed 
at, and produces lower-level signals from sources to the side of the mic. 
 The coincident pair uses two directional mics that are angled sym-
metrically from the center line ( Figure 9-2 ). Instruments in the center of 
the group produce the same signal from each mic. When you monitor the 
mics, the same signal comes out of each speaker. Identical signals from 
two speakers produce a phantom image midway between the speakers. 
So you hear the center instruments in the center. 
 If an instrument is off-center to the right, it is more on axis to the 
right-aiming mic than to the left-aiming mic. So the right mic will produce 
a higher-level signal than the left mic. When you monitor the mics, the 
right speaker’s signal is louder than the left speaker’s signal. This repro-
duces the image off-center to the right. So you hear the right-side instru-
ments toward the right side. 
 That is how coincident stereo miking works. The coincident pair 
codes instrument positions into level differences between channels. The 
brain decodes these level differences back into corresponding image loca-
tions. A pan pot in a mixing console works on the same principle. If one 
channel is 15–20 dB louder than the other, the image shifts all the way to 
the louder speaker . Play Website track 5 to hear image location versus level 
differences between channels. 
 Suppose we want the right side of the orchestra to be reproduced 
at the right speaker. That means the far-right musicians must produce a 
signal level 20 dB higher from the right mic than from the left mic. This 
happens when the mics are angled apart by a certain amount. 
 Instruments partway off-center produce interchannel level differ-
ences less than 20 dB, so you hear them partway off-center. 
 Listening tests have shown that coincident cardioid mics tend to repro-
duce the musical group with a narrow stereo spread. That is, the group 
does not spread all the way between speakers.  Play Website tracks 8 – 11 to 
hear the image localization of some coincident cardioid techniques.  
 A coincident-pair method with excellent localization is the Blumlein 
array. It uses two bidirectional mics angled 90° apart and facing the left 
and right sides of the group. 
 A special form of the coincident-pair technique is the mid–side (MS) 
recording method illustrated in  Figure 9-4 . It uses a “mid” microphone 
facing the middle of the orchestra and a bidirectional microphone aiming 

140
Overview of Stereo Microphone Techniques
to the sides. The middle mic is most commonly cardioid, but it can be 
any pattern.  
 In a device called a matrix, the signals from both mics are summed 
(mixed together) to produce the left-channel signal and are differenced 
(mixed in opposite polarity) to produce the right-channel signal. 
 You can remote-control the stereo spread by changing the mid/side 
ratio in the matrix. This remote control is useful at live concerts, where 
you can’t physically adjust the mics during the concert. You can also con-
trol the stereo spread during mixdown rather than during the recording. 
In  Chapter 10 , under the heading “Stereo-Spread Control,” I describe how 
to use a computer digital audio workstation (DAW) to vary the stereo 
spread without using a matrix device. MS is covered in detail in Appen-
dix B under the heading “Mid–Side.” 
 A recording made with coincident mics is mono-compatible. If you 
expect that your recordings will be heard in mono (say, on TV), then you’ll 
probably want to use coincident methods. 
 Spaced Pair 
 With this method (also called AB), you place two identical mics a few feet 
apart and aim them straight ahead ( Figures 9-5  and  9-6 ). The mics can 
have any polar pattern, but omni is most popular for this method. The 
greater the spacing between mics, the greater the stereo spread. 
 How does this method work? Instruments in the center of the group 
produce the same signal from each mic. When you monitor the mics, you 
 Figure 9-4 MS technique. 

141
Overview of Stereo Microphone Techniques 9
hear a phantom image of the center instruments midway between your 
speakers. 
 If an instrument is off-center, it is closer to one mic than the other, so 
its sound reaches the closer microphone before it reaches the other one. 
Both mics produce the same signal, except that the farther mic’s signal is 
delayed compared to the closer mic’s signal. 
 If you send the same signal to two speakers with the signal in one 
channel delayed, the sound image shifts off-center. With a spaced-pair 
recording, off-center instruments produce a delay in one mic channel, so 
they are reproduced off-center. 
 The spaced pair codes instrument positions into time differences 
between channels. During playback, the brain decodes these time differences 
 Figure 9-5 Spaced-pair technique. 
 Figure 9-6 Photo of spaced-pair technique. 

142
Overview of Stereo Microphone Techniques
back into corresponding image locations.  Play Website track 6 to hear image 
location versus time differences between channels.  
 A delay of 1.2 milliseconds (msec) is enough to shift an image all 
the way to one speaker. You can use this fact when you set up the mics. 
Suppose you want to hear the right side of the orchestra from the right 
speaker. The sound from the right-side musicians must reach the right mic 
about 1.2 milliseconds before it reaches the left mic. To make this happen, 
space the mics about 2–3 feet apart. This spacing makes the correct delay 
to place right-side instruments at the right speaker. Instruments partway 
off-center produce interchannel delays less than 1.2 milliseconds, so they 
are reproduced partway off-center. 
 If the spacing between mics is, say, 12 feet, then instruments that are 
slightly off-center produce delays between channels that are greater than 
1.2 milliseconds. This places their images at the left or right speaker. I call 
this “exaggerated separation” or a “ping-pong” effect ( Figure 9-1(d) ).  Play 
Website tracks 18 – 20 to hear the image localization of some spaced-pair techniques. 
 On the other hand, if the mics are too close together, the delays pro-
duced will be too small to provide much stereo spread. Also, the mics will 
tend to emphasize instruments in the center because the mics are closest 
to them. 
 To record a good musical balance of an orchestra, you need to space 
the mics about 10 or 12 feet apart. But then you get too much separation. 
You could place a third mic midway between the outer pair and mix its 
output to both channels. That way, you pick up a good balance, and you 
hear an accurate stereo spread. 
 The spaced-pair method tends to make off-center images unfocused 
or hard to localize. Why? Spaced-pair recordings have time differences 
between channels. Stereo images produced solely by time differences are 
not very sharp. You still hear the center instruments clearly in the center, 
but off-center instruments are harder to pinpoint. Spaced-pair miking is a 
good choice if you want the sonic images to be diffuse or blended, instead 
of sharply focused.  Play Website track 24 to hear a comparison of a spaced pair 
versus a coincident pair on a drum set. 
 Another ﬂ aw of spaced mics: if you mix both mic channels to mono, 
you may get phase cancellations of various frequencies. This may or may 
not be audible. 
 Spaced mics, however, give a “warm” sense of ambience, in which 
the concert-hall reverb seems to surround the instruments and, some-
times, the listener. Here’s why: the two channels of recorded reverb are 
incoherent—that is, they have random phase relationships. Incoherent 

143
Overview of Stereo Microphone Techniques 9
signals from stereo speakers sound diffuse and spacious. Since spaced 
mics pick up reverb incoherently, it sounds diffuse and spacious. The sim-
ulated spaciousness caused by the phasiness is not necessarily realistic, 
but it is pleasing to many listeners. 
 Another advantage of the spaced pair is that you can use omni mics. 
An omni condenser mic has deeper bass than a uni condenser mic. 
 Near-Coincident Pair 
 In this method, you angle apart two directional mics, and space their 
grilles a few inches apart horizontally ( Figures 9-7  and  9-8 ). Even a few 
inches of spacing increases the stereo spread and adds a sense of ambient 
warmth or air to the recording. The greater the angle or spacing between 
mics, the greater the stereo spread. 
 Figure 9-8 Photo of near-coincident-pair technique. 
 Figure 9-7 Near-coincident-pair technique. 

144
Overview of Stereo Microphone Techniques
 How does this method work? Angling directional mics produces 
level differences between channels. Spacing mics produces time differ-
ences. The level differences and time differences combine to create the 
stereo effect.  Play Website track 7 to hear image location versus level and time 
differences between channels. 
 If the angling or spacing is too great, you get exaggerated separation. 
If the angling or spacing is too small, you hear a narrow stereo spread. 
 A common near-coincident method is the ORTF (French) system, 
which uses two cardioids angled 110° apart and spaced 7 inches (17 cm) 
horizontally. Usually this method gives accurate localization. That is, 
instruments at the sides of the orchestra are reproduced at or very near 
the speakers, and instruments halfway to one side are reproduced about 
halfway to one side. 
 The NOS (Dutch) system uses two cardioids angled 90° and spaced 
12 inches (30 cm), while the DIN (German) system is 90° and 7.8 inches 
(20 cm). Compared to ORTF, those methods have less off-axis coloration 
because the mics are less angled away from the center instruments. Also 
their 90° angle between mics is easier to set up visually than the ORTF 
110° angle between mics.  Play Website tracks 12–14 to hear the image localiza-
tion of some near-coincident-pair methods. 
 Baffled-Omni Pair 
 This method uses two omni mics, usually ear-spaced, and separated by a 
hard or padded bafﬂ e ( Figure 9-9 ). To create stereo, it uses time differences 
 Figure 9-9 Bafﬂ ed-omni technique. 

145
Overview of Stereo Microphone Techniques 9
at low frequencies and level differences at high frequencies. The spacing 
between mics creates time differences. The bafﬂ e creates a sound shadow 
(reduced high frequencies) at the mic farthest from the source. Between 
the two channels, there are spectral differences (differences in frequency 
response). 
 Three examples of a bafﬂ ed-omni pair are the Schoeps sphere micro-
phone ( Figure 9-10 ), the audio.com BS-3D sphere microphone, and the 
Jecklin Disk ( Figure 12-3 ). The omni condenser mics used in the bafﬂ ed-
omni method have excellent low-frequency response.  Play Website tracks 
15 – 17 to hear the image localization of some bafﬂ ed-omni-pair methods. 
 A special form of the bafﬂ ed-omni pair is binaural recording with 
an artiﬁ cial head (dummy head). The head contains a microphone ﬂ ush 
mounted in each ear. You record with these microphones and play back 
the recording over headphones. This process can re-create the locations 
of the original performers and their acoustic environment with startling 
realism. For more detail on binaural recording see Appendix D. 
 You can clip a pair of miniature omni or cardioid mics onto the temple 
pieces of eyeglasses. Each mic is on the opposite side of your head, either in 
your ears or on your temples.  Chapter 12  lists some websites of these bin-
aural microphones. To compensate for the acoustic effect of the head, the 
signals need some equalization (EQ), which is a broad dip around 3 kHz. 
 Boundary (surface-mounted) mics can be used for any type of stereo 
miking. Appendix C describes some stereo mic techniques using bound-
ary mics.  Play Website tracks 21 – 23 to hear the image localization of some stereo 
boundary-mic techniques. 
 Comparing the Four Techniques 
 1. Coincident pair 
 • Uses two directional mics angled apart with grilles touching. 
 • Level differences between channels produce the stereo effect. 
 • Images are sharp. 
 Figure 9-10 Sphere microphone. 
LEFT
MIC
SPHERE
RIGHT
MIC

146
Overview of Stereo Microphone Techniques
 • Stereo spread ranges from narrow to accurate. 
 • Signals are mono-compatible. 
 2. Spaced pair 
 • Uses two mics spaced a few feet apart, aiming straight ahead. 
 • Time differences between channels produce the stereo effect. 
 • Off-center images are diffuse. 
 • Stereo spread tends to be exaggerated unless a third center mic is 
used, or unless spacing is under 2–3 feet. 
 • Provides a warm sense of ambience. 
 • Provides excellent low-frequency response if you use omni 
condensers. 
 • Tends not to be mono-compatible, but this might not be audible. 
 3. Near-coincident pair 
 • Uses two directional mics angled apart and spaced a few inches 
apart horizontally. 
 • Level and time differences between channels produce the stereo 
effect. 
 • Images are sharp. 
 • Stereo spread tends to be accurate. 
 • The hall sounds more spacious than with coincident methods. 
 • Tends not to be mono-compatible. 
 4. Bafﬂ ed-omni pair 
 • Uses two omni mics, usually ear-spaced, with a bafﬂ e between 
them. 
 • Level, time, and spectral differences produce the stereo effect. 
 • Images are sharp. 
 • Stereo spread tends to be accurate. 
 • Excellent low-frequency response. 
 • Good imaging with headphones. 
 • The hall sounds more spacious than with coincident methods. 
 • Stereo spread is not adjustable except by panning the two chan-
nels toward the center. 
 • More conspicuous than other methods. 
 • Tends not to be mono-compatible, but this might not be audible. 

147
Overview of Stereo Microphone Techniques 9
 Mic Requirements for Stereo 
 For sharp imaging, the microphone pair should be well matched in fre-
quency response and polar pattern. Be sure both mics are the same model 
number, and match their levels when picking up a sound source in the 
center. Or use a stereo mic, which mounts two mic capsules in a single 
housing for convenience. 
 Surprisingly, different transducer types have different imaging. Why? 
For sharpest imaging, microphone polar patterns and off-axis phase shift 
should be uniform with frequency. In a ribbon mic, these needs are met. But 
a condenser mic tends to be less uniform with frequency, and a dynamic 
tends to be still less uniform. These characteristics affect the imaging of a 
stereo pair of microphones. 
 How to Test Imaging 
 Here is a way to check the stereo imaging of a mic technique: 
 1. Set up the stereo mic array in front of a stage. 
 2. Record yourself speaking from various locations on stage where 
the instruments will be: center, half-right, far right, half-left, far left. 
Announce your position. 
 3. Play back the recording over speakers. Sit exactly between them, as 
far away from them as they are spaced apart. 
 You’ll hear how accurately the technique translated your positions, 
and you’ll hear how sharp the images are. If you hear a narrow ste-
reo spread, you need to angle or space the mics farther apart. If you 
hear exaggerated separation, you need to angle or space the mics closer 
together. 
 We looked at several mic arrays to record in stereo. Each has its pros 
and cons. Which method you choose depends on the sonic compromises 
you’re willing to make. 
 Recommended Reading 
 Blumlein, A. “British Patent Speciﬁ cation 394,325.”  Journal of Audio Engineering 
Society, Vol. 6, No. 2 (April 1958), p. 91. 
 Keller, A. “Early Hi Fi and Stereo Recording at Bell Laboratories (1931–1932).” 
 Journal of Audio Engineering Society, Vol. 29, No. 4 (April 1991), pp. 274–280. 

148
Overview of Stereo Microphone Techniques
 These references can be found in  Stereophonic Techniques,  an anthology pub-
lished by the Audio Engineering Society, 60 E. 42nd Street, New York, NY, 
10165. 
 Check out DPA Microphones’ articles on stereo mic techniques: 
 www.dpamicrophones.com/en/Mic - University/StereoTechniques.aspx. 
 Also do an Internet search for stereo microphone techniques. 

149
 This chapter explains how to do an on-location stereo recording of a clas-
sical music ensemble. We cover both equipment and procedures. 
 Equipment 
 • Microphones (low-noise condenser or ribbon type, omni or direc-
tional, free ﬁ eld or boundary, stereo or matched pair). 
 • Multitrack recorder or stereo recorder. These were described in 
 Chapter 1 in the sections “Multitrack Recording Systems” and “Stereo 
Recording Systems.” 
 • Low-noise mic preamps or low-noise mini mixer (necessary if the 
mic preamps in your recorder are low quality). 
 • Phantom-power supply (necessary if your mixer or mic preamp 
lacks phantom power). 
 • Stereo bar. 
 • Mic stands and booms, or ﬁ shing line to hang mics. 
 • Shock mount (optional). 
 10 
 STEREO RECORDING 
PROCEDURES 

150
Stereo Recording Procedures
 • Mixer (necessary if you use more than two mics). 
 • Mid–side (MS) matrix box (if you are recording with the MS 
technique). 
 • Headphones and/or speakers. 
 • Power ampliﬁ er for speakers (optional) or powered Nearﬁ eld 
monitors. 
 • Recording medium: hard drive or ﬂ ash memory. 
 • Power strip and extension cords. 
 • Notebook and pen. 
 • Talkback mic and powered speaker (optional). 
 • Tool kit. 
 • Fresh batteries. 
 • External hard drive for backing up the recording. 
 • Tape measure. 
 First on the list are microphones. You’ll need at least two or three 
of the same model number or one or two stereo microphones. Websites 
of stereo and surround microphones are listed in  Chapter 12  under the 
headings “Stereo Microphones” and “Surround Microphones.” Good 
microphones are essential, for the microphones—and their placement—
determine the sound of your recording. To achieve professional-quality 
recordings of music, you should expect to spend at least $100 per micro-
phone or $250 for a stereo microphone. 
 For classical music recording, the preferred microphones are con-
denser or ribbon types with a wide, ﬂ at frequency response and very low 
self-noise (explained in  Chapter 8 ). A self-noise spec of less than 20 dB 
equivalent SPL, A-weighted, is recommended. 
 If you want to do spaced-pair recording, you can use either omnidi-
rectional or directional microphones. Omnis are preferred because they 
generally have a deeper low-frequency response. If you want to do coin-
cident or near-coincident recording for sharper imaging, use directional 
microphones (cardioid, supercardioid, hypercardioid, or bidirectional). 
Mics with those polar patterns tend to roll off in the low frequencies, but 
you can compensate for this with equalization. 
 You need a power supply for condenser microphones: either an 
external phantom-power supply, a mixer or mic preamp with phantom 
power, or internal batteries. A low-noise stereo mic preamp (or low-noise 
portable mixer) lets you make recordings free of electronic hiss. 

151
Stereo Recording Procedures 10
 You can mount the microphones on stands or hang them from the 
ceiling with nylon ﬁ shing line or black paracord. Make sure that the ﬁ sh-
ing line’s tensile strength exceeds the weight of the mics. Check legal 
safety issues with hanging mics; different rules apply in different places. 
Stands are much easier to set up, but more visually distracting at live 
concerts. Stands are more suitable for recording rehearsals or sessions 
with no audience present. Neumann makes tiltable “auditorium hang-
ers” that suspend mic capsules of the KM 100 or KM 180 system from 
their cables. 
 The mic stands should have a tripod-folding base and should extend 
at least 13 feet high. Some suitable products are telescoping photographic 
stands (available from camera stores). They are lightweight and compact. 
Other examples are the Shure S15A (www.shure.com), Quik Lok A50 
(www.quiklok.com), AEA-13MDV (www.wesdooley.com), and K&M 
21411B. You can use baby booms or stand extenders to increase the height 
of regular mic stands. 
 A useful accessory is a stereo bar (stereo microphone adapter, ste-
reo mic mount). This device mounts two microphones on a single stand 
for coincident or near-coincident stereo recording. A long stereo bar can 
accommodate spaced-pair miking. Some websites are given in  Chapter 12  
under the heading “Stereo and Surround Microphone Adapters.” 
 Another needed accessory in most cases is a shock mount to pre-
vent pickup of ﬂ oor vibrations. Some models are the On-Stage MY410 
and MY320 (various vendors), Sabra Som SSM-1 (www.sabra-som.
com), Shure A55 M (www.shure.com), and AKG H85 and H100 (www.
akg.com). 
 In difﬁ cult mounting situations, boundary microphones may come 
in handy. They can lie ﬂ at on the stage ﬂ oor to pick up small ensembles or 
can be mounted on the ceiling or on the front edge of a balcony. They also 
can be attached to clear Plexiglas panels that are hung or mounted on mic 
stands. Boundary mics are made by most microphone companies. 
 To monitor in the same room as the musicians, you need some closed-
cup, circumaural (around the ear) headphones, or isolating earphones to 
block out the sound of the musicians. You want to hear only what is being 
recorded. Of course, the headphones should be wide-range and smooth 
for accurate monitoring. A better monitoring arrangement might be to set 
up powered Nearﬁ eld loudspeakers in a separate room. 
 If you’re in the same room as the musicians, you have to sit far 
from them to clearly monitor what you’re recording. To do that, you 
need a pair of 50-foot microphone extension cables. Longer extensions 

152
Stereo Recording Procedures
are needed if the mics are hung from the ceiling or if you monitor in a 
separate room. 
 A mixer is necessary when you want to record more than one source—
for example, an orchestra and a choir, an orchestra with spot mics, or a 
band and a soloist. You might put a pair of microphones on the orchestra 
and another pair on the choir. Connect the insert sends from the mixer to a 
multitrack recorder, then mix the tracks to stereo back in the studio. If your 
budget doesn’t allow a multitrack recorder you could mix the mic signals 
live to a stereo recorder. 
 For monitoring an MS recording, bring an MS matrix box that con-
verts the MS signals to left-right signals, which you monitor. Websites of 
MS matrix devices are listed in  Chapter 12  under the heading “MS Matrix 
Decoders.” 
 A tape measure lets you note the microphones’ height and distance 
from the podium. You might need to duplicate your mic placement at a 
later session in order to record inserts that you edit into the main record-
ing. A tape measure helps you reset the mics where they were during the 
original recording session. 
 Selecting a Venue 
 If possible, plan to record in a venue with good acoustics. It should have 
adequate reverberation time for the music being performed (about 2 sec-
onds for orchestral music). This is very important, because it can make the 
difference between an amateur-sounding recording and a commercial-
sounding one. Try to record in an auditorium, concert hall, or house of 
worship rather than in a band room or gymnasium. Halls with wooden 
surfaces and a shoebox shape tend to sound best. 
 You may be forced to record in a hall that is too dead: that is, the 
reverberation time is too short. In this case, you may want to add artiﬁ cial 
reverberation from a digital reverb unit or plug-in, or cover the seats with 
plywood sheets or 4-mm polyethylene plastic sheeting. Strong echoes can 
be controlled with carpets, RPG diffusors, or drapes. 
 If the venue is surrounded by noisy trafﬁ c, consider recording after 
midnight. Turn off noisy air conditioning if possible while recording. 
 Call the venue manager and ask that the circuit breakers for the stage 
outlets be turned on the day of the session. Ask where you can load-in 
your equipment. Also make sure that the load-in door will be unlocked 
when you plan to load in. 

153
Stereo Recording Procedures 10
 Session Setup 
 Be sure to test all your equipment for correct operation before going on 
the job. If you are using battery-powered devices, install fresh batteries 
in them just before the concert. Keep your equipment inside your home 
or studio until you’re ready to leave. A recorder left outside in a cold 
car may become sluggish if the lubricant stiffens, and batteries may lose 
some voltage. 
 Make sure your hard drive or SD card has enough capacity for the 
session. Table 3-1 in  Chapter 3  shows the storage required for a 1-hour 
recording. 
 Arrive at the venue a few hours early to allow for setup and for ﬁ x-
ing problems. 
 First, power-up the equipment. You can use batteries or an AC exten-
sion cord plugged into an outlet near the stage. AC power is preferred 
because it’s more reliable. Make sure this outlet is live. Gaffer-tape the 
extension cord lengthwise or cover it with mats to prevent tripping. Tie 
your outlet strip’s AC cord to the extension cord, so that they can’t sepa-
rate if someone pulls on the extension cord. 
 If this is a session, listen to the ensemble playing on the stage. Is the 
sound bad? You might want to move the musicians out onto the ﬂ oor of 
the hall. 
 Mounting the Mics 
 Place your microphones in the desired stereo miking arrangement. As an 
example, suppose you’re recording an orchestra rehearsal with two crossed 
cardioids on a stereo bar (the near-coincident method). Screw the stereo bar 
onto a mic stand and mount two cardioid microphones on the stereo bar. 
For starters, angle them 110° apart and space them 7 inches apart horizon-
tally. Aim them slightly downward, so that they’ll point at the orchestra 
when raised. You may want to mount the microphones in shock mounts or 
put the stands on sponges to isolate the mics from ﬂ oor vibration. 
 Basically, place two or three mics (or a stereo mic) several feet in 
front of the group, raised up high (as in  Figure 10-1 ). The microphone 
placement controls the acoustic perspective or sense of distance to the 
ensemble, the balance among instruments, and the stereo imaging.  
 As a starting position, place the mic stand behind the conductor’s 
podium, about 12 feet from the front-row musicians. Connect mic cables 

154
Stereo Recording Procedures
and gaffer-tape them to the top of each mic stand for strain relief. Raise 
the microphones about 14 feet off the ﬂ oor. This prevents overly loud 
pickup of the front row relative to the back row of the orchestra. It also 
reduces audience noise by mounting the mics farther from the audience. 
Gaffer-tape the mic cables to the bottom of the stand to keep it from being 
pulled over. 
 Leave some extra turns of mic cable at the base of each stand, so that 
you can reposition the stands. This slack also allows for people acciden-
tally pulling on the cables. Try to route the mic cables where they won’t 
be stepped on, or cover them with mats. 
 Live, broadcast, or ﬁ lmed concerts require an inconspicuous mic place-
ment, which may not be sonically ideal. In these cases, or for permanent 
 Figure 10-1  Typical microphone placement for on-location recording of a clas-
sical music ensemble: (a) top view and (b) side view. 

155
Stereo Recording Procedures 10
installations, you probably want to hang the microphones from the ceiling 
rather than using stands. You can position a stereo bar with three nylon 
ﬁ shing lines spaced apart. Make sure that the tensile strength of the ﬁ shing 
line exceeds the weight of the mics and stereo bar. Hang individual mics 
by their cables and attach two ﬁ shing lines to the front of each mic to aim 
it. Another inconspicuous mic placement is on mic-stand booms project-
ing forward of a balcony. For dramas or musicals, directional boundary 
mics can be placed on the stage ﬂ oor near the footlights. 
 If you are uncertain which mic technique to use, you could set up 
two or more mic arrays and record them to multitrack. When you master 
the program, choose the best-sounding technique. You might even mix the 
signals of two or more mic pairs. 
 Connections 
 Now you’re ready to make connections. Here are some connection meth-
ods for just two mics: 
 • If your stereo recorder has high-quality mic preamps and phantom 
power, plug the mics directly into the recorder mic inputs. 
 • If your recorder lacks phantom power (or the phantom voltage is 
lower than the mics require), plug the mics into a phantom supply, 
and from there into your recorder mic inputs. 
 • If your recorder lacks high-quality mic preamps, plug the mics into 
a low-noise mic preamp or mixer with phantom power. Connect 
cables from there into your recorder line inputs. 
 Here are some connection methods for more than two mics: 
 • Plug the mics into a stage box (described in  Chapter 1 ) and run the 
snake back to your mixer. Plug the snake mic connectors into your 
mixer mic inputs. If you are recording to two-track, plug the mixer 
stereo outputs into the recorder line inputs. If you are recording to 
multitrack, plug the mixer insert-send jacks into the recorder line 
inputs. 
 • If you have a multichannel audio interface with mic preamps, plug 
the mics into the interface. Connect the interface USB or FireWire 
port to a laptop computer. 
 • If you want to feed your mic signals to several mixers—recording, 
broadcast, PA—plug your mic cables into a mic splitter or distribution 

156
Stereo Recording Procedures
amp (described in  Chapter 2  under the heading “Splitting the Micro-
phones”). Connect the splitter outputs to the snakes for each mixer. 
Supply phantom from one mixer only, on the direct side of the split. 
Each split will have a ground-lift switch on the splitter. Set it to  ground 
for the mixer supplying phantom. Set it to  lift  for the other mixers (or 
to  ground  if that results in the least hum). This prevents hum caused 
by ground loops between the different mixers. 
 • If you’re using directional microphones and want to make their 
response ﬂ at at low frequencies, you can run them through a mixer 
with equalization for bass boost. You might prefer to equalize the 
recording during mastering instead. Boost around 50–100 Hz until 
the bass sounds natural or until it matches the bass response of omni 
condenser mics. You won’t need this equalization (EQ) if the micro-
phones have been factory equalized for ﬂ at response at a distance. 
 Monitoring 
 Put on your headphones or listen over loudspeakers in a separate room. 
Sit equidistant from the speakers, as far from them as they are spaced 
apart. You’ll probably need to use a Nearﬁ eld arrangement (speakers 
about 3 feet apart and 3 feet from you) to reduce coloration of the speak-
ers’ sound from the room acoustics.  Play Website tracks 1–4 to set up your 
monitor speakers correctly for stereo listening. 
 Turn up the recording-level controls and monitor the signal. When 
the orchestra starts to tune up, set the recording levels to peak around 
–15 dB, so that you have a clean signal to monitor. You can set levels more 
carefully later on. 
 Microphone Placement 
 Nothing has more effect on the production style of a classical music record-
ing than microphone placement. Miking distance, polar patterns, angling, 
spacing, and spot miking all inﬂ uence the recorded sound’s character. 
 Miking Distance 
 The microphones must be placed closer to the musicians than a good live 
listening position. If you place the mics out in the audience where the 
live sound is good, the recording probably will sound muddy and distant 

157
Stereo Recording Procedures 10
when played over speakers. That is because all the recorded reverbera-
tion is reproduced up-front along a line between the monitor speakers, 
along with the direct sound of the orchestra. Close miking (5–20 feet from 
the front row) compensates for this effect by increasing the ratio of direct 
sound to reverberant sound. 
 The closer the mics are to the orchestra, the closer the orchestra 
sounds in the recording. If the instruments sound too close, too edgy, or 
too detailed, or if the recording lacks hall ambience, the mics are too close 
to the ensemble. Move the mic stand a foot or two farther from the orches-
tra and listen again. 
 If the orchestra sounds too distant, muddy, or reverberant, the mics 
are too far from the ensemble. Move the mic stand a little closer to the 
musicians and listen again. 
 Eventually, you’ll ﬁ nd a sweet spot, where the direct sound of the 
orchestra is in a pleasing balance with the ambience of the concert hall. 
Then the reproduced orchestra will sound neither too close nor too far. 
 Here’s why miking distance affects the perceived closeness (perspec-
tive) of the musical ensemble: the level of reverberation is fairly constant 
throughout a room, but the level of the direct sound from the ensemble 
increases as you get closer to it. Close miking picks up a high ratio of direct-
to-reverberant sound; distant miking picks up a low ratio. The higher the 
direct-to-reverb ratio, the closer the sound source is perceived to be.  Play 
Website track 25 to hear how miking distance affects the direct-to-reverb ratio.  
 If the recording venue is “live” because of hard surfaces—brick, glass, 
stone—chances are you will need to mike closely. On the other hand, if the 
venue is “dead” because of soft surfaces—carpet, drapes, stuffed seats—
expect to mike farther away. 
 An alternative to ﬁ nding the sweet spot is to place a stereo pair 
close to the ensemble (for clarity) and another stereo pair distant from 
the ensemble (for ambience). According to Delos recording director John 
Eargle, the distant pair should be no more than 30 feet from the main pair, 
otherwise the signal might simulate an echo. You record the two pairs to 
a multitrack recorder and mix them back in the studio. The advantages of 
this method are as follows: 
 • It avoids pickup of bad-sounding early reﬂ ections. 
 • Close miking reduces pickup of background noise. 
 • After the recording is ﬁ nished, you can adjust the direct-to-reverb 
ratio or the perceived distance to the ensemble. 

158
Stereo Recording Procedures
 • Comb ﬁ ltering due to phase cancellations between the two pairs is 
not severe because the delay between them is great and their levels 
and spectra are different. 
 Similarly, Skip Pizzi recommends a “double MS” technique, which uses 
a close MS microphone mixed with a distant MS microphone (as shown 
in  Figure 10-2 ). One MS microphone is close to the performing ensemble 
for clarity and sharp imaging, and the other is out in the hall for ambience 
and depth. The distant mic could be replaced by an XY pair for lower cost.    
 If the ensemble is being ampliﬁ ed through a sound-reinforcement sys-
tem, you might be forced to mike very close to avoid picking up ampliﬁ ed 
sound and feedback from the reinforcement speakers. In that case you will 
need to add high-quality artiﬁ cial reverberation or convolution reverb. 
 For broadcast or communications, consider miking the conductor 
with a wireless lavalier mic or stand-mounted mic. 
 Figure 10-2  Double MS technique using a close main pair and a distant pair 
for ambience. Spot mics also are shown. 

159
Stereo Recording Procedures 10
 Stereo-Spread Control 
 Concentrate on the stereo spread. If the monitored spread is too narrow, 
it means that the mics are angled or spaced too close together. Increase 
the angle or spacing between mics until localization is accurate.  Note: 
increasing the angle between mics will make the instruments sound far-
ther away; increasing the spacing will not.  Play Website track 9. The mics are 
angled and spaced too close together, so the stereo spread is narrow. 
 If off-center instruments are heard far left or far right, that indicates 
your mics are angled or spaced too far apart. Move them closer together 
until localization is accurate.  Play Website track 20. The mics are too far apart, 
so the stereo separation is exaggerated. 
 If you record with an MS microphone, you can change the monitored 
stereo spread either during the recording or after. 
 To change the spread during the recording, connect the stereo mic 
outputs to the matrix box and connect the matrix-box L — R output to 
the recorder. Use the stereo-spread control ( M/S  ratio) in the matrix box to 
adjust the stereo spread. 
 To alter the spread after the recording using a matrix box: record 
the mid signal on one track and the side signal on another track. Monitor 
the output of the recorder with a matrix box. Back in the studio, run the 
mid and side tracks through the matrix box, adjust the stereo spread as 
desired, and record the left and right outputs. 
 To alter the spread after the recording using a digital audio worksta-
tion (DAW): 
 1. Record the mid mic on track 1; record the side mic on track 2. 
 2. Copy or clone track 2 to track 3. Be sure the waveforms are aligned. 
 3. Pan track 2 hard left; pan track 3 hard right. 
 4. Reverse the polarity of track 3 or use an “invert polarity” plug-in. 
 5. Group tracks 2 and 3, so their faders move together. 
 6. To change the stereo spread, vary the levels of tracks 2 and 3 relative 
to track 1. 
 If you are set up before the musicians arrive, check the localization by 
recording yourself speaking from various positions in front of the micro-
phone pair while announcing your position (“left side,” “mid-left,” “cen-
ter”). Play back the recording to judge the localization accuracy provided 
by your chosen stereo array. Recording this localization test is an excellent 
practice.  Play Website tracks 8–24 to hear the localization of several stereo mic 

160
Stereo Recording Procedures
techniques. Listen using an audio interface, not a sound card, which can degrade 
stereo imaging. 
 Monitoring Stereo Spread 
 Full stereo spread on speakers is a spread of images all the way between 
speakers, from the left speaker to the right speaker. Full stereo spread on 
headphones can be described as stereo spread from ear to ear. The stereo 
spread heard on headphones may or may not match the stereo spread 
heard over speakers, depending on the microphone technique used. 
 Due to psychoacoustic phenomena, coincident-pair recordings have 
less stereo spread over headphones than over loudspeakers. Take this into 
account when monitoring with headphones or use only loudspeakers for 
monitoring.  Play Website tracks 9–10 alternately over loudspeakers and head-
phones. Compare the stereo spread. 
 If you are monitoring your recording over headphones or anticipate 
headphone listening to the playback, you may want to use near-coincident 
miking techniques, which have similar stereo spread on headphones and 
loudspeakers.  Play Website tracks 13–14 alternately over loudspeakers and 
headphones. Compare the stereo spread. 
 Ideally, monitor speakers should be set up in a Nearﬁ eld arrangement 
(say, 3 feet from you and 3 feet apart) to reduce the inﬂ uence of room acous-
tics and to improve stereo imaging. On the wall behind the monitors, attach 
a panel of acoustic foam that extends a few feet beyond the speaker spacing. 
 If you want to use large monitor speakers placed farther away from 
you, deaden the control-room acoustics with acoustic foam or thick ﬁ ber-
glass insulation (covered with muslin). Place the acoustic treatment on 
the walls behind and to the sides of the loudspeakers. This smoothes the 
frequency response and sharpens stereo imaging. 
 You might include a stereo/mono switch in your monitoring system 
to check for mono compatibility. 
 Soloist Pickup and Spot Microphones 
 Sometimes a soloist plays in front of the orchestra. You have to capture a 
tasteful balance between the soloist and the ensemble. That is, the main 
stereo pair should be placed so that the relative loudness of the soloist 
and the accompaniment is musically appropriate. If the soloist is too loud 
relative to the orchestra (as heard on headphones or loudspeakers), raise 
the mics. If the soloist is too quiet, lower the mics. You may want to add 
a spot mic (accent mic) about 3 feet from the soloist and mix it with the 

161
Stereo Recording Procedures 10
other microphones. Take care that the soloist appears at the proper depth 
relative to the orchestra. 
 If a sound-reinforcement system is in use, place the soloist mic 
8–12 inches away to prevent feedback. Use a foam windscreen on a vocal 
mic. To make the soloist mic inconspicuous, you could place a small-
diaphragm mic at about chest height aiming at the mouth, and use a 
slender mic stand such as the Schoeps Active ExtensionTube RC. 
 Many record companies prefer to use multiple microphones and 
multitrack techniques when recording classical music. Such methods pro-
vide extra control of balance and deﬁ nition and are necessary in difﬁ cult 
situations. Often you must add spot or accent mics on various instru-
ments or instrumental sections to improve the balance or enhance clarity 
(as shown in  Figure 10-2 ). In fact, John Eargle contended that a single 
stereo pair of mics rarely works well. 
 A choir that sings behind the orchestra can be miked separately with 
two to four cardioids. You might place the choir in the audience area fac-
ing the orchestra, and mike the choir. 
 If the recording mics are also used for sound reinforcement, place the 
choir mics about 3 feet out front and 3 feet above the head height of the 
back row. Add piano mics and windscreened soloist mics about 8 inches 
from their sound sources. Record all the mics to multitrack, and mix the 
tracks back in your studio. Add reverb and EQ as needed. 
 Pan each spot mic so that its image position coincides with that of the 
main microphone pair. Using the mute switches on your mixing console, 
alternately monitor the main pair and each spot mic to compare image 
positions. 
 You might want to use an MS microphone or stereo pair for each 
spot mic. Adjust the stereo spread of each local sound source to match 
that reproduced by the main pair. For example, suppose that a violin sec-
tion appears 20° wide as picked up by the main pair. Adjust the perceived 
stereo spread of the MS spot mic used on the violin section to 20°, then 
pan the center of the section image to the same position that it appears 
with the main mic pair. 
 When you use spot mics, mix them at a low level relative to the main 
pair—just loud enough to add deﬁ nition but not loud enough to destroy 
depth. Operate the spot-mic faders subtly or leave them untouched. Oth-
erwise the close-miked instruments may seem to jump forward when the 
fader is brought up, then fall back in when the fader is brought down. If 
you bring up a spot-mic fader for a solo, drop it only 6 dB when the solo 
is over, not all the way off. 

162
Stereo Recording Procedures
 Often the timbre of the instrument(s) picked up by the spot mic is too 
bright. You can ﬁ x it with a high-frequency rolloff or by using a mic with 
that characteristic. Adding artiﬁ cial reverb to the spot mic can help too. 
 To further integrate the sound of the spots with the main pair, you 
might want to delay each spot’s signal to coincide with those of the main 
pair. That way, the main and spot signals are heard at the same time. For 
each spot mic, the formula for the required delay is: 
 T  D/C 
 where 
 T: delay time in seconds 
 D: distance between each spot mic and the main pair in feet 
 C: speed of sound, 1130 feet/second. 
 For example, if a spot mic is 20 feet in front of the main pair, the required 
delay is 20/1130 or 17.7 milliseconds. Some engineers add even more 
delay (10–15 milliseconds) to the spot mics to make them less noticeable 
(Streicher and Dooley). As a rule of thumb, 1 foot corresponds to about 
1 millisecond of delay. 
 A suggested track assignment for multitrack concert recordings is 
shown below: 
 Tracks 1–2: main pair 
 Tracks 3–4: distant pair 
 Tracks 5–6: “outriggers” or widely spaced pair 
 Tracks 7–8: spot mics and conductor’s mic (for announcing takes). 
 Once the microphones are positioned properly, gaffer-tape the mic-stand 
legs to the ﬂ oor, so that the stands can’t be knocked over. 
 Electronic Music 
 Concerts of electronic music are played through loudspeakers, so you 
need to consider them as sound sources. Try a mic on-axis to each loud-
speaker about 12 feet away to capture some of the hall acoustics. Move 
the mics closer and farther during a sound check while monitoring the 
results, and ﬁ nd a spot with a good balance between direct sound from 
the loudspeakers and reverberant sound from the hall. 
 In addition to or instead of miking loudspeakers, you might obtain 
a CD or digital ﬁ le of the pre-recorded music. Then in editing, line up the 
CD or digital ﬁ le waveforms with the recording of the live performance. 

163
Stereo Recording Procedures 10
 The house sound mixer might need to provide monitors for the 
musicians. 
 Discreet Miking for Video Shoots 
 When a video company shoots a concert that you’re recording, it’s impor-
tant that the mics and mic stands be inconspicuous. Sometimes, sound 
quality must take a back seat to the camera scene. Here are a few tips for 
making your gear less visible: 
 • Use thin mic stands such as made by Schoeps and Audix, or choir 
mics with thin stands. See www.acebackstage.com/abc_pages/choir_
stick_mics.html. 
 • Use black-colored stands instead of chrome stands. 
 • Place vocal mics at chest height aiming up at the mouth. 
 • Use a near-coincident or coincident pair rather than a spaced pair on 
a long stereo bar. 
 • Use hanging mics over an orchestra and choir instead of stand-
mounted mics. 
 • Use a widely-spaced pair of mic stands if a central stand would be in 
the shot. 
 • Use boundary mics on the stage ﬂ oor instead of stand mics.  Caution: 
the front row of the ensemble is likely to be emphasized with this 
technique unless the ensemble is small. 
 • Use boundary mics on the underside of a raised piano lid. 
 • Use small pencil-type mics rather than large-diaphragm mics. 
 Setting Levels 
 Now you’re ready to set recording levels. Ask the conductor to have the 
orchestra play the loudest part of the composition, and set the record-
ing level for the desired meter reading. A typical recording level is –6 dB 
maximum on a peak-reading meter for a digital recorder. The level can go 
up to 0 dB maximum without distortion, but aiming for –6 dB allows for 
surprises. Bass-drum and tympani hits produce the highest peaks. 
 For each stereo pair of microphones, make sure their preamps have 
identical gain and ﬁ lter settings. Otherwise the stereo balance will be skewed. 
 If you plan to record a concert with no sound check, you have to set the 
record-level knobs to a nearly correct position ahead of time. Do this during 
a pre-concert trial recording, or just go by experience: set the knobs where 

164
Stereo Recording Procedures
you did at previous sessions (assuming you are using the same micro-
phones in the same venue). Another way to pre-set the recording level is to 
aim for a peak meter level of –15 dBFS when the orchestra tunes up. 
 Before going on-location, you could play loud orchestral music over 
your studio monitors or home stereo, set up your mics and recorder, and 
set approximate recording levels. If you need to set the level less than one-
third up to get a 0-dB meter level, you probably need to insert a pad or set 
the mic-gain switch to low gain. 
 In a very critical recording you might record the stereo signal on 
4 tracks. Set one pair of tracks to a normal recording level. Then, as a 
backup, route the signal to the other pair of tracks with the record level 
reduced by 15 dB. 
 Recording a Concert 
 Before the concert obtain a printed program of the musical selections. On 
this program, next to each piece, you will write down the recorder coun-
ter times of the beginning and end of that piece. That will help you locate 
and identify the pieces correctly when you edit the recording later. 
 Start recording when the conductor walks out (or sooner). Record 
the concert nonstop if your recording medium allows. Document your 
mic placement and recording level for future jobs. 
 Editing 
 At this point, the recording is ﬁ nished and you’ve brought it back to your 
studio. The concert recording has long applause after each piece. Suppose 
you want to edit the applause shorter and insert a few seconds of silence 
between the compositions. Here is a suggested procedure for editing a 
stereo recording using a DAW: 
 1. Connect a USB cable between the computer and recorder. Then the 
computer recognizes the recorder as a storage device. Click-drag the 
recorder’s WAV ﬁ le of the concert to your hard drive. 
 2. In the audio editing software, start a new project and set up an audio 
track. 
 3. Import the concert ﬁ le from the hard drive into the audio track. 
 4. Play the track and locate the ﬁ rst piece. Refer to the counter times 
you wrote on your session notes or concert program. 
 5. Delete the part of the recording before the ﬁ rst piece but do not close 
up the space. 

165
Stereo Recording Procedures 10
 6. Find the applause at the end of the piece. About 10 seconds into the 
applause, split the clip or region. Also split the clip a few seconds 
before the start of the next piece. Cut out the audio between the split 
points, but do not close up the space. 
 7. Label the clip of the composition with its title. 
 8. Repeat Step 6 for the rest of the pieces. 
 Now each musical piece is in a separate clip or region on your screen. 
Slide the ﬁ rst piece to the beginning of the program. Next you will add 
fades and adjust the spacing between the pieces (refer to  Figure 10-3 ): 
 1. At the end of each piece, let the applause play for 3 seconds then 
fade it out over about 8 seconds. Use a fade that starts quickly and 
ends slowly. 
 2. If there is background noise such as air-conditioning rumble, insert 
a fade-in about 2 seconds before the beginning of each piece ( Fig-
ure 10-3 ). Or you may want the track to start right when the music 
starts; that is, with no ambience before it starts. 
 3. Time-slide the clips to create a 4-second gap between them (or what-
ever interval sounds right). 
 Figure 10-3  A DAW screen showing an applause fade-out, a 4-second gap, 
and a fade-in before the next piece. 
FADE-OUT
FADE-IN
4-SECOND
GAP
END OF
FIRST PIECE
BEGINNING OF
SECOND PIECE
APPLAUSE

166
Stereo Recording Procedures
 If you don’t want total silence between pieces, do not fade out the 
applause. End each piece’s clip where the applause stops, and leave about 
4 seconds of recorded “room tone” between clips. 
 To edit a session that has no applause, set the beginning of each clip 
just before the ﬁ rst note. Set the end of each clip just after the reverberant 
tail fades to silence. Leave about a 4-second silent gap between clips (or 
whatever sounds right). 
 When you’re ﬁ nished editing, note the start time and duration of 
each clip. You will use this information to write a cuesheet that deter-
mines the start IDs when burning a CD. Export the edited program to a 
24-bit stereo ﬁ le. 
 Sometimes, despite your best intentions and the ﬁ nest microphones, 
the spectral balance of the recording might be poor. The bass might be 
weak, the strings strident, and so on. Room acoustics play a strong part in 
this. Fortunately, a recording having a skewed tonal balance can often be 
salvaged with equalization. An effective tool for this purpose is Harmonic 
Balancer (www.har-bal.com ),  which shows the spectrum of the recording 
and lets you equalize it as needed. 
 Once the program is equalized (if necessary), import the equalized 
ﬁ le and normalize it, so that the highest peak reaches –0.3 dBFS. Finally, 
enable dither and export the normalized mix to a 16-bit stereo ﬁ le. You 
will burn a CD from this ﬁ le. 
 A Real-World Example: Recording 
an Orchestra in a Concert Hall 
 The musical director of a high-school orchestra called me up one day, ask-
ing me to record their upcoming concert. He gave me this information: 
 • One-hour concert in the Elco Theater. 
 • No solos except during a violin concerto, where the violinist stands 
by the conductor’s podium. 
 • No sound check. The students had exams that week and couldn’t 
ﬁ t it in. 
 Preparation 
 I went to the venue ahead of time to check it out. It was a fairly “dead” older 
theater with lots of carpeting and drapes, and not enough reverberation 

167
Stereo Recording Procedures 10
to sound good. Also, the heating system produced a steady rumble. The 
custodian was not willing to turn it off during the concert. 
 Since I usually start a recording setup with microphones about 12 feet 
from the conductor, I located that spot in the third row. I planned to put 
my mic stand there. Luckily, there was an AC outlet in the stage front near 
that area, and it tested “live” with an AC tester. 
 Next I wrote an equipment list: 2 cardioid condenser mics, a stereo 
bar, a telescoping mic stand, mic cables, headphones, a handheld digi-
tal recorder, and a backup recorder. The recorder had built-in phantom 
power to power the condenser mics. I also brought a ﬂ ashlite, gaffer tape, 
a pen and notebook. 
 Using the recorder’s menu, I set the recording format to 24 bits/44.1 
kHz to get a high-quality recording, and made sure I had plenty of mem-
ory installed for a one-hour concert. 
 Setup 
 It takes me about 20 minutes to set up, so I arrived at the theater an hour 
before the concert. While carrying in the gear on a hand truck, I grabbed 
a printed program in the lobby. 
 First, I ran a power extension cord from the stage outlet to my 
recording area, and plugged in my recorder. I taped down the exten-
sion cord lengthwise with gaffer tape so no one would trip on it. I also 
taped a loop of extension cord to the wall for security in case the cord 
got yanked. 
 I could have used batteries instead of AC power, but didn’t want to 
risk them failing. Once I recorded a concert using batteries which died 
near the end of the concert, and I lost the entire recording. 
 Next, I opened the tripod mic stand in the third row, raised it to 
chest height, and screwed on the stereo bar. I inserted the mics in their 
mic clips on the bar, and angled them down to aim at the center of the 
orchestra when raised. They were set in an N.O.S. near-coincident array, 
which tends to provide accurate stereo and is visually inconspicuous. To 
keep audience members away from the mic stand, I attached some gaffer 
tape between two rows of nearby seats. 
 After plugging cables into the mics, I formed a sideways “U” out 
of the cables and taped them to the top of the mic stand to act as strain 
reliefs. Then I raised the stand to full height, 14 feet. I taped the cables to 
the bottom of the stand to prevent pulling the stand over accidentally. The 
other end of the mic cables plugged into the recorder’s XLR mic inputs. 

168
Stereo Recording Procedures
I made sure that phantom power was on, then made a test recording and 
playback of the room sound.
Past experience had shown me that a recording level of 47 out of 
100 resulted in a good recording level (–10 dBFS maximum) for a loud 
orchestra picked up with those mics. I set the recording level to 47 for 
starters. Here’s another method to preset recording levels: play an orches-
tral recording at live volume over a stereo, pick it up with your mics and 
recorder, and set the level for –10 dBFS maximum on the recorder meters.
Although a recording level near 0 dBFS results in slightly lower noise, 
you really need to allow lots of headroom for surprises—hence the –10 dBFS 
maximum level. You won’t hear the slight increase in noise at that level.
Recording
When the conductor entered, I started recording non-stop. On the printed 
program I noted the start and end time of each composition for easy iden-
tification later during editing.
Editing
Back in the studio I transferred the recorded files to a hard drive via USB. 
After launching my DAW software I was ready for editing. I created a 
clip of each composition and named it according to its title taken from the 
printed program. Then I performed the edits described earlier, mostly to 
remove long spaces between pieces and to fade the applause after each 
song. Someone in the audience had been crackling a cellophane candy 
wrapper, and those noises were edited out. I couldn’t eliminate the heating-
system rumble, but a 40 Hz high-pass filter took out most of it without 
affecting the lowest bass notes in the music.
The recorded sound of the concert was rather dry because of the 
venue’s acoustics. So I added a little high-quality digital reverb with 
an RT60 of 1.5 seconds, which seemed to suit the music. This reverb 
made the recording sound more “commercial” and less like an ama-
teur recording.
After all the edits were done, I noted the start time and dura-
tion of each piece. Then I exported the concert as one long WAV file at 
16 bits/44.1 kHz so it would be playable on a CD.
Next, I imported that WAV file into Har-Bal software, which does 
a long-term spectral analysis. There was a notable hump around 500 Hz 
due to some room coloration, and a rolloff in the low end due to the mics’ 

169
Stereo Recording Procedures 10
rolloff. So I used Har-Bal’s EQ feature to remove the 500 Hz hump and to 
boost the lows. The resulting spectrum was mostly ﬂ at up to 1 kHz and 
rolled off smoothly above that—a typical spectrum for orchestral music. 
After applying that EQ, the recording sounded more realistic: fuller in the 
bass and less colored in the midrange. 
 I saved the EQ’d ﬁ le, wrote a cue sheet of the start times, and burned 
a CD-R. Playback of the CD-R veriﬁ ed that the CD player accurately found 
the beginning of each piece and played without glitches. I made a few cop-
ies for the orchestra leader. He and the students enjoyed re-hearing their 
concert with professional sound quality. 
 References 
 Pizzi, S. “Stereo Microphone Techniques for Broadcast.”  Audio Engineering Society 
Preprint No. 2146 (D-3), Presented at the 76th Convention,  October 8–11, 1984, 
New York. 
 Streicher, R., and Dooley, W. “Basic Stereo Microphone Perspectives—A Review.” 
 Journal of the Audio Engineering Society, Vol. 33, No. 7/8 (July/August 1985), 
pp. 548–556. 
 Eargle, J.  The Microphone Book. Boston: Focal Press, 2001. 
 

This page intentionally left blank

171
 Suppose that you’re monitoring a stereo recording in progress or listening 
to a recording you’ve already made. Something doesn’t sound right. How 
can you pinpoint what’s wrong, and how can you ﬁ x it? 
 This section lists several procedures to solve audio-related prob-
lems. Read down the list of bad sound descriptions until you find 
one matching what you hear, then try the solutions until your prob-
lem disappears. 
 Before you start, check for faulty cables and connectors. Also 
check all control positions, rotate knobs, and flip switches to clean 
the contacts. 
 Distortion in the Microphone Signal 
 • Use pads or turn down the gain trims in your mixer. 
 • Switch in the pad in the condenser microphone, if any. 
 • If your recorder has a pad, switch it in. If your recorder has a mic 
gain switch, set it to the low-gain setting. 
 • Use a microphone with a higher “maximum SPL” speciﬁ cation. 
 11 
 TROUBLESHOOTING 
STEREO SOUND 

172
Troubleshooting Stereo Sound
 Too Dead (Not Enough Reverberation) 
 • Place microphones farther from performers. Play Website track 25 
to hear how miking distance affects the amount of reverberation and 
depth. 
 • Use omnidirectional microphones. 
 • Record in a concert hall with better acoustics (longer reverberation 
time). 
 • Add artiﬁ cial reverberation. 
 • Add plywood or plastic sheeting over the audience seats. 
 • If the venue acoustics are good, mix in a second pair of mics about 
30 feet from the main pair. 
 Too Detailed, Close, or Edgy 
 • Place microphones farther from performers. Play Website track 25 
to hear how miking distance affects the amount of reverberation and 
depth. 
 • Place microphones lower or on the ﬂ oor (as with a boundary 
microphone). 
 • Using an equalizer in your mixing console, roll off the high frequencies. 
 • Use duller-sounding microphones. 
 • If using both a close-up pair and a distant ambience pair, turn up the 
ambience pair. 
 • If using spot mics, add artiﬁ cial reverb or delay their signals to coin-
cide with the main pair’s signals. 
 Too Distant (Too Much Reverberation) 
 • Place microphones closer to performers. Play Website track 25 to hear 
how miking distance affects the amount of reverberation and depth. 
 • Use directional microphones (such as cardioids). 
 • Use a spaced pair of directional mics aiming straight ahead. 
 • Record in a concert hall that is less “live” (reverberant). 
 • If using both a close-up pair and a distant ambience pair, turn down 
the ambience pair. 

173
Troubleshooting Stereo Sound 11
 Narrow Stereo Spread 
 See  Figure 11-1 (c). Play Website track 9 to hear narrow stereo spread. 
 • Angle or space the main microphone pair farther apart. 
 • If doing mid–side stereo recording, turn up the side signal. 
 • Place the main microphone pair closer to the ensemble.  Note: this 
also will make the ensemble sound closer. 
 • If monitoring with headphones, narrow stereo spread is normal when 
you use coincident techniques. Try monitoring with loudspeakers, or 
use near-coincident or spaced techniques. 
 Excessive Separation, Hole-in-the Middle, 
or Soloist Moves Too Much 
 See Figure 11-1(d). Play Website track 20 to hear excessive separation. 
 • Angle or space the main microphone pair closer together. 
 • If doing mid–side stereo recording, turn down the side signal or use 
a cardioid mid instead of an omni mid. 
 Figure 11-1  Stereo localization effects: (a) orchestra instrument locations (top 
view); (b) images accurately localized between speakers (the listener’s perception); 
(c) narrow stage effect; and (d) exaggerated separation effect. 

174
Troubleshooting Stereo Sound
 • In spaced-pair recording, add a microphone midway between the 
outer pair and pan its signal to the center. 
 • Place the microphones farther from the performers.  Note:  this also 
will make the ensemble sound more distant. 
 • Place the loudspeaker pair closer together. Ideally, they should be as 
far apart as you are sitting from them, to form a listening angle of 60°. 
 Poorly Focused Images 
 • Avoid spaced-microphone techniques. Play Website tracks 6, 18–20, 
22, and 24 to hear the image focus of some spaced-microphone techniques. 
 • Use a microphone pair that is better matched in frequency response. 
 • If the sound source is out of the in-phase region of microphone pickup, 
move the source or the microphone. For example, the in-phase 
region of a Blumlein pair of crossed ﬁ gure-eights is ± 45° relative 
to center. 
 • Be sure that each spot mic is panned so that its image location coin-
cides with that of the main pair. 
 Maybe the image-focus problem is in your monitoring system 
instead of the mic technique. Try these suggestions: 
 • Use loudspeakers designed for sharp imaging. Usually these are sig-
nal aligned, have vertically aligned drivers, have curved edges to 
reduce diffraction, and are sold in matched pairs. 
 • Place the loudspeakers several feet from the wall behind them and 
from side walls to delay and weaken the early reﬂ ections that can 
degrade stereo imaging. 
 • Put acoustic foam on the wall behind the speakers to absorb early 
reﬂ ections. 
 • Use Nearﬁ eld monitors (about 3 feet apart and 3 feet from you). 
 Images Shifted to One Side (Left–Right 
Balance Is Faulty) 
 • Adjust the right-or-left recording level so that center images are 
centered. 
 • Use a microphone pair that is better matched in sensitivity. 

175
Troubleshooting Stereo Sound 11
 • Aim the center of the mic array exactly at the center of the ensemble. 
 • Sit exactly between your stereo speakers, equidistant from them. 
Adjust the balance control or level controls on your monitor ampli-
ﬁ er to center a mono signal.  Play Website tracks 1–4 to set up your 
speakers correctly for stereo listening. 
 Lacks Depth 
 Play Website track 25 to hear a voice reproduced with gradually increasing depth. 
 • Avoid spot mics. 
 • If you must use spot mics, keep their level low in the mix, and delay 
their signals to coincide with those of the main pair. 
 • The problem might be your monitor speakers. Use monitors with 
signal-aligned drivers, put acoustical absorption on the wall behind 
the speakers, and space the speakers several feet from the wall 
behind them. 
 Lacks Spaciousness 
 • Use spatial equalization (described in Appendix A under the head-
ing “Spaciousness and Spatial Equalization”). 
 • Space the microphones apart. 
 • Place the microphones farther from the ensemble.  Play Website track 
25 to hear how miking distance affects the sense of spaciousness. 
 • Mix in a distant mic pair placed about 30 feet back in the hall. 
 • Use a spaced pair or near-coincident pair instead of a coincident pair. 
 • Record in a venue with stronger side reﬂ ections or longer reverbera-
tion time. 
 • Add artiﬁ cial reverb. 
 • See the suggestions under the heading “Early Reﬂ ections Too Loud” 
below. 
 Early Reflections Too Loud 
 • Place mics closer to the ensemble and add a distant microphone for 
reverberation (or use artiﬁ cial reverberation). 

176
Troubleshooting Stereo Sound
 • Place the musical ensemble in an area with weaker early reﬂ ections. 
 • If the early reﬂ ections come from the sides, try aiming bidirectional 
mics at the ensemble. Their nulls will reduce pickup of side-wall 
reﬂ ections. 
 Bad Balance (Some Instruments 
Too Loud or Too Soft) 
 • Place the microphones higher or farther from the performers. 
 • Move quiet instruments closer to the stereo pair and vice versa. 
 • Ask the conductor or performers to change the instruments’ written 
dynamics. 
 • Add spot microphones close to instruments or sections needing rein-
forcement. Mix them in subtly with the main microphones’ signals. 
 • Increase the angle between mics to reduce the volume of center 
instruments and vice versa. 
 • If using a mid–side mic and matrix, vary the mid–side ratio to slightly 
change the balance of middle instruments to side instruments. This 
will also change the stereo spread. 
 Muddy Bass 
 • Aim the bass-drum head at the microphones. 
 • Put the microphone stands and bass-drum stand on resilient isolation 
mounts, or place the microphones in shock-mount stand adapters. 
 • Suggest that the tympani player use hard sticks instead of soft, and 
maybe play quieter. 
 • Roll off the low frequencies or use a high-pass ﬁ lter set around 
40–80 Hz. 
 • Record in a concert hall with less low-frequency reverberation. 
 Rumble from Air Conditioning, 
Trucks, and So On 
 • Temporarily shut off air conditioning. Record in a quieter location or 
at a quieter time of day. 

177
Troubleshooting Stereo Sound 11
 • Use a high-pass ﬁ lter set around 40–80 Hz. Use microphones with 
limited low-frequency response. 
 • Mike closer and add artiﬁ cial reverberation. 
 Bad Tonal Balance (Too Dull, 
Too Bright, Colored) 
 • Try different microphones. 
 • If a microphone must be placed near a hard reﬂ ective surface, use a 
boundary microphone to prevent phase cancellations between direct 
and reﬂ ected sounds. 
 • Adjust equalization. Compared to omni condenser mics, directional 
mics usually have a rolled-off low-frequency response and may need 
some bass boost. 
 • If strings sound strident, move mics farther away or lower. 
 • If the tone quality is colored only in mono monitoring, use coincident-
pair techniques. 
 

This page intentionally left blank

179
 This is a listing of websites that sell stereo microphones, surround micro-
phones, headworn mics, dummy heads, mid–side (MS) matrix boxes, and 
stereo microphone stand adapters. The list is up to date only for the date 
of publication of this book. Since models and prices change, please contact 
the manufacturers for current information. This chapter is not a catalog of 
preferred products, but rather an illustration of currently available prod-
ucts and their features. 
 Note the following deﬁ nitions of microphone speciﬁ cations: 
 •  Side-addressed: The axis of maximum sensitivity is at right angles to 
the microphone’s long axis. You aim the side of the mic at the sound 
source. 
 •  End-addressed:  The axis of maximum sensitivity is the same as the 
mic’s long axis. You aim the front of the mic at the sound source. 
 •  Binaural:  Two small mics are mounted ﬂ ush with each ear canal. They 
pick up the “sound shadowing” effect of the head on the spectrum of 
 12 
 STEREO, SURROUND, AND 
BINAURAL MICROPHONES 
AND ACCESSORIES 

180
Stereo, Surround, and Binaural Microphones and Accessories
the sound source (the frequency response and phase response of the 
head), plus the acoustic effects of the pinnae, or outer ears. 
 •  HRTF (head-related transfer function):  Two small mics are mounted on 
the temples. They pick up the effect of the head on the spectrum of 
the sound source (the frequency response and phase response of the 
head), but not the effects of the pinnae. 
 Stereo Microphones 
 AKG Acoustics US www.akgusa.com 
 Audio Technica US Inc. www.audio-technica.com 
 Beyerdynamic Inc. www.beyerdynamic.com 
 Church Audio www.church-audio.com 
 Core Sound (Jecklin Disk) www.core-sound.com 
 Josephson Engineering (Jecklin Disk) www.josephson.com 
 Microtech Gefell www.microtechgefell.de 
 MXL www.mxlmics.com 
 Neumann USA www.neumannusa.com 
 Pearl Microphones AB www.pearlmicrophones.com 
 Rode Microphones www.rodemic.com 
 Royer Microphone Labs www.royerlabs.com 
 Sanken Microphones www.sanken-mic.com/en 
 Schoeps Microphones www.schoeps.de 
 Sennheiser Electronic Corp. USA http://en-us.sennheiser.com 
 Shure Inc. www.shure.com 
 Sony Professional Products http://pro.sony.com/bbsc/ssr/cat-audio/
cat-wiredmics/ 
 SoundField Ltd. www.soundﬁ eld.com 
 Sound Professionals www.soundprofessionals.com 
 Studio Projects www.studioprojects.com 
 T.H.E. Audio www.theaudio.com 

181
Stereo, Surround, and Binaural Microphones and Accessories 12
Figure 12-1 AKG C-426B Comb stereo microphone (courtesy: AKG Acoustics, Inc.).
Figure 12-2 Audio-Technica BP4025 end-addressed XY mic (courtesy: Audio-
Technica).
 Examples of stereo microphones: 
 AKG C-426B. See  Figure 12-1 . 
 Audio-Technica BP4025. See  Figure 12-2 . 

182
Stereo, Surround, and Binaural Microphones and Accessories
   Core Sound Jecklin Disk (Optimal Stereo Signal (OSS) system): Padded 
bafﬂ e mount for two ear-spaced omni mics ( Figure 12-3 ). 
   Neumann USM69i: Multi-pattern dual stereo MS/XY microphone. 
Upper capsule can be rotated relative to the lower one through 270°. Side-
addressed. See  Figure 12-4 . 
   Rode NT4: XY stereo microphone, battery or phantom powered 
( Figure 12-5 ). 
   Schoeps KFM 360 Sphere Microphone: Smaller version of Schoeps 
KFM6 Sphere Microphone for surround use (see Figure 9-10). 
 The Sound Professionals offer a wide variety of stereo mics at differ-
ent price/quality levels. 
 Mini stereo mics are at 
 www.microphones.com/links.cfm?catid = Miniature%20Stereo%20
Microphones . 
Figure 12-3 Jecklin Disk (courtesy: Josephson Engineering).
Figure 12-4 Neumann USM69i stereo microphone (courtesy: Neumann USA).

183
Stereo, Surround, and Binaural Microphones and Accessories 12
Figure 12-5 Rode NT4 XY stereo microphone (courtesy: Rode Microphones).
 Surround Microphones 
 Holophone www.holophone.com 
 Microtech Gefell www.microtechgefell.de 
 Schoeps Microphones www.schoeps.de 
 SoundField Ltd. www.soundﬁ eld.com 
 Zoom (part of H2n handheld recorder) 
https://www.zoom-na.com/products/ﬁ eld-video-recording/ﬁ eld-
recording/zoom-h2n-handy-recorder 
 Example of a surround microphone: 
 Holophone H2 Pro: Surround microphone captures up to 7.1 channels 
using an ellipsoid bafﬂ e with mic capsules. Discrete outputs; no matrix 
needed. See  Figure 12-6 . 

184
Stereo, Surround, and Binaural Microphones and Accessories
 Dummy Heads and Headworn 
Binaural Mics 
 Bruel & Kjaer Instruments, Inc. www.bkhome.com 
 Church Audio www.church-audio.com 
 Core Sound www.core-sound.com 
 Neumann USA www.neumannusa.com 
 Sonic Studios (DSM mics) www.sonicstudios.com 
 SoundField Ltd. www.soundﬁ eld.com 
 T.H.E. Audio www.theaudio.com 
 Examples of dummy heads and binaural miking systems: 
 Core Sound binaural mics: A variety of binaural microphone sets 
that you wear on your head ( Figure 12-7 ). Omni or cardioid capsules. 
Figure 12-6 Holophone H2 Pro surround microphone (courtesy: Holophone).

185
Stereo, Surround, and Binaural Microphones and Accessories 12
Figure 12-7 Core Sound CSB1 binaural microphones (courtesy: Core Sound).
Figure 12-8 Neumann KU 100 dummy head (courtesy: Neumann USA).
Powered by a battery box or DC bias (plug-in power) from a recorder. 
High-end models use DPA 4060/4061 capsules. Stealthy Cardioid set 
uses cardioid capsules to reduce pickup of room acoustics. 
   Neumann KU 100 “Fritz III” dummy head binaural system: A 
detailed human-head replica with omni microphones inside the ears. 
Loudspeaker compatible. For music recording, radio drama, ﬁ lm spe-
cial effects, outdoor nature recordings, acoustic evaluation, and scien-
tiﬁ c research. Powered by internal batteries or external phantom-power 
supply. See  Figure 12-8 . 

186
Stereo, Surround, and Binaural Microphones and Accessories
 Headworn binaural mics are at 
 www.microphones.com/links.cfm?catid=Miniature%20Stereo%20
Microphones. 
 Stereo and Surround Microphone Adapters 
 Audio Engineering Associates (AEA) www.wesdooley.com 
 Audio Technica US, Inc. www.audio-technica.com 
 Beyerdynamic, Inc. www.beyerdynamic.com 
 Bruel & Kjaer Instruments, Inc. www.bkhome.com 
 Danish Pro Audio www.dpamicrophones.com 
 Neumann USA www.neumannusa.com 
 On-Stage MY500 http://onstagestands.com/products/view/MY500 
 Sabra Som www.sabra-som.com 
 Schoeps Microphones www.schoeps.de 
 Shure Inc. www.shure.com 
 Sonic Studios (DSM mics) www.sonicstudios.com 
 The Sound Professionals www.soundprofessionals.com 
 Examples of stereo mic adapters: 
 Audio Engineering Associates (AEA) Stereo Microphone Positioner 
(SMP) ( Figure 12-9 ): Positions coincident and near-coincident arrays. 
Handles large mics, such as Coles 4038. Vertical or horizontal arrays, 
stand mounted or hung. Rotation angles are lines engraved at ± 30°, 
45°, and 55°. Center-to-center spacing is marked on a ruler with ORTF 
position shown. Various lengths available. 
Figure 12-9 AEA SMP (courtesy: AEA).

187
Stereo, Surround, and Binaural Microphones and Accessories 12
   Shure A27M: Uses two rotating stacked cylinders. Lets you adjust 
angle and spacing for coincident and near-coincident methods. See 
 Figure 12-10 . 
 MS Matrix Decoders 
 Schoeps Microphones www.schoeps.de 
 SoundField Ltd. www.soundﬁ eld.com 
 ka-electronics www.ka-electronics.com/KAelectronics/MS_Matrix/MS_
Matrix.htm 
Figure 12-10 Shure A27M stereo microphone adapter (courtesy: Shure, Inc.).

This page intentionally left blank

189
 These appendices are more academic than the rest of the book. They are 
for readers who want a deeper understanding of stereo mic techniques. 
You can use those techniques without reading this material. However, if 
you want to know how stereo works or to develop your own stereo array, 
it’s worthwhile to study the theory and math in this appendix. 
 A sound system with good stereo imaging can form apparent sources 
of sound, such as reproduced musical instruments, in well-deﬁ ned loca-
tions, and usually between a pair of loudspeakers placed in front of the 
listener. These apparent sound sources are called  images. 
 This appendix explains terms related to stereo imaging, how we 
localize real sound sources, how we localize images, and how microphone 
placement controls image location. 
 Definitions 
 First, we’ll deﬁ ne several terms related to stereo imaging.  Fusion  refers to 
the synthesis of a single apparent source of sound (an image or “phantom 
image”) from two or more real sound sources (such as loudspeakers). 
 The  location of an image is its angular position relative to a point 
straight ahead of a listener or its position relative to the loudspeakers. 
This is shown in Figure A-1. A goal of high ﬁ delity is to reproduce the 
images in the locations intended by the recording engineer or producer. 
 A 
STEREO IMAGING THEORY 

190
Stereo Imaging Theory
In some productions, usually classical music recordings, the goal is to 
place the images in the same relative locations as the instruments were 
during the live performance.  
 Stereo spread  or  stage width  (Figure A-2) is the distance between the 
extreme-left and extreme-right images of a reproduced ensemble of instru-
ments. The stereo spread is wide if the ensemble appears to spread all the 
way between a pair of loudspeakers. The spread is narrow if the ensemble 
occupies only a small space between the speakers. Sometimes the repro-
duced reverberation or ambience spreads from speaker to speaker even 
when the reproduced ensemble width is narrow.  Play Website tracks 14 and 
 Figure A-1 Example of image location: (a) listener’s view and (b) top view. 

191
Stereo Imaging Theory A
17 to hear accurate stereo imaging with a wide spread. Play Website tracks 9 
and 10 to hear a narrow stereo spread. 
 Image  focus  or  size  (Figure A-3) refers to the degree of fusion of an 
image, its positional deﬁ nition. A sharply focused image is described as 
being pinpointed, precise, narrow, sharp, resolved, well deﬁ ned, or easy 
to localize. A poorly focused image is hard to localize, spread, broad, 
smeared, vague, and diffuse. A  natural image  is focused to the same 
degree as the real instrument being reproduced.  Play Website track 17 to 
hear sharply focused images and play Website track 22 to hear poorly focused 
images.    
 Depth  is the apparent distance of an image from a listener, the sense 
of closeness and distance of various instruments.  Play Website track 25 to 
hear how miking distance affects the sense of depth. 
 Elevation  refers to an image position above the line between the 
speakers. 
 Image movement is a reproduction of the movement of the sound 
source, if any. The image should not move unaccountably. 
 Localization  is the ability of a listener to tell the direction of a sound. 
It is also the relation between interchannel or interaural differences and 
perceived image location. (“Interaural differences” means “differences 
between signals at the two ears.”) 
 Figure A-2 Stereo spread or stage width. 
 Figure A-3 Image focus or size (listener’s perception). 

192
Stereo Imaging Theory
 How We Localize Real Sound Sources 
 The human hearing system uses the direct sound and early reﬂ ections 
to localize a sound source. The direct sound and reﬂ ections within about 
2 milliseconds contribute to localization (Wallach et al., 1973; Bartlett, 
1979). Reﬂ ections occurring up to 5–35 milliseconds after the direct sound 
inﬂ uence image broadening (Gardner, 1973). Distance or depth cues are 
conveyed by early reﬂ ections (less than 33 milliseconds after the direct 
sound). Echoes delayed more than about 5–50 milliseconds (depending 
on program material) do not fuse in time with the early sound but con-
tribute to the perceived tonal balance (Carterette and Friedman, 1978, 
pp. 62, 210). 
 Imagine a sound source and a listener. Let’s say that the source 
is in front of the listener and to the left of center (as in Figure A-4). 
Sound travels a longer distance to the right ear than to the left ear, so 
the sound arrives at the right ear after it arrives at the left ear. In other 
words, the right-ear signal is delayed relative to the left-ear signal. Every 
source location produces a unique arrival-time difference between ears 
(Vanderlyn, 1979).   
 In addition, the head acts as an obstacle to sounds above about 
1000 Hz. High frequencies are shadowed by the head, so a different 
spectrum (amplitude versus frequency) appears at each ear (Shaw, 1974; 
 Figure A-4 Sound traveling from a source to a listener’s ears. 

193
Stereo Imaging Theory A
Mehrgardt and Mellert, 1977). Every source location produces a unique 
spectral difference between ears (Figure A-5). 
 We have learned to associate certain interaural differences with spe-
ciﬁ c directions of the sound source. When presented with a new source 
location, we match what we hear with a memorized pattern of a similar 
situation to determine direction (Rumsey, 1989, p. 6). 
 As stated before, an important localization cue is the interaural 
arrival-time difference of the signal envelope. We perceive this difference 
at any change in the sound: a transient, a pause, or a change in timbre. For 
this reason, we localize transients more easily than continuous sounds 
(Rumsey, 1989, p. 3). The time difference between ear signals can also be 
considered as a phase difference between sound waves arriving at the 
ears (Figure A-6). This phase shift rises with frequency. 
 When sound waves from a real source strike a listener’s head, a 
different spectrum of amplitude and phase appears at each ear. These 
 Figure A-5  Frequency response of the ear at different azimuth angles: 0° is 
straight ahead; 90° is to the side of the ear being measured; and 180° is behind 
the head (after Mehrgardt and Mellert). 

194
Stereo Imaging Theory
interaural differences are translated by the brain into a perceived direc-
tion of the sound source. Every direction is associated with a different set 
of interaural differences. 
 The ears make use of interaural phase differences to localize sounds 
between about 100 and 700 Hz. Frequencies below about 100 Hz are not 
localized (making “subwoofer/satellite” speaker systems feasible; Harvey 
and Schroeder, 1961). Above about 1500 Hz, amplitude differences between 
ears contribute to localization. Between about 700 and 1500 Hz, both phase 
and amplitude differences are used to tell the direction of a sound (Eargle, 
1976,  Chapters 2 and  3 ; Cooper and Bauck, 1980). 
 Small movements of the head change the arrival-time difference at 
the ears. The brain uses this information as another cue for source location 
(Rumsey, 1989, p. 4), especially for distance and front/back discrimination. 
 The outer ears (pinnae) play a part as well (Gardner and Gardner, 
1973). In each pinna, sound reﬂ ections from various ridges combine with 
the direct sound, causing phase cancellations and frequency notches in 
the perceived spectrum. The positions of the notches in the spectrum vary 
with the source height. We perceive these notch patterns not as a tonal 
 Figure A-6 Phase shift ϕ between sound waves at the ears. 

195
Stereo Imaging Theory A
coloration but as height information. Also, we can discriminate sounds in 
front from those in back because of the pinnae’s shadowing effect at high 
frequencies. 
 Some of the cues used by the ears can be omitted without destroying 
localization accuracy if other cues are still present. 
 How We Localize Images Between Speakers 
 Now that we’ve discussed how we localize real sound sources, let’s look 
at how we localize their images reproduced over loudspeakers. Imagine 
that you’re sitting between two stereo speakers, as in  Figure A-7 . If you 
feed a musical signal equally to both channels in the same polarity, you’ll 
perceive an image between the two speakers. Normally, you’ll hear a sin-
gle synthetic source, rather than two separate loudspeaker sources.  Play 
Website track 1 to hear a phantom image in the center between your speaker pair.  
 Figure A-7 Two ears receiving signals from two speakers. 

196
Stereo Imaging Theory
 Each ear hears both speakers. For example, the left ear hears the 
left-speaker signal, then, after a short delay due to the longer travel path, 
hears the right-speaker signal. At each ear, the signals from both speak-
ers sum or add together vectorially to produce a resultant signal of a 
certain phase. 
 Suppose that we make the signal louder in one speaker. That is, we 
create a level difference between the speakers. Surprisingly, this causes a 
signal time difference at the ears (Rumsey, 1989, p. 8). This is a result of 
the phasor addition of both speaker signals at each ear. For example, if the 
left-speaker signal is louder, the phase delay of the vector sum is higher 
in the right ear than in the left ear. So the right-ear signal is delayed with 
respect to the left-ear signal. 
 Remember to distinguish interchannel differences (between speaker 
channels) from interaural differences (between ears). An interchannel 
level difference does not appear as an interaural level difference, but 
rather as an interaural time difference. 
 We can use this speaker-generated interaural time difference to 
place images. Here’s how: suppose we want to place an image 15° to 
one side. A real sound source 15° to one side produces an interaural time 
difference of 0.13 millisecond. If we can make the speakers produce an 
interaural time difference of 0.13 millisecond, we’ll hear the image 15° 
to one side. We can fool the hearing system into believing there’s a real 
source at that angle. This occurs when the speakers differ in level by a 
certain amount. 
 The polarity of the two channels affects localization as well. To 
explain polarity, if the signals sent to two speaker channels are in polarity, 
they are in phase at all frequencies; both go positive in voltage at the same 
time. If the signals are out of polarity, they are 180° out of phase at all 
frequencies. One channel’s signal goes positive when the other channel’s 
signal goes negative. Opposite-polarity signals are sometimes incorrectly 
referred to as being  out of phase. 
 If the signals are in opposite polarity between channels and equal 
level in both channels, the resulting image has a diffuse, directionless 
quality and cannot be localized.  Play Website track 4 to hear in-polarity and 
opposite-polarity signals. If the signals are in opposite polarity and higher 
level in one channel than the other, the image often appears outside the 
bounds of the speaker pair. You’d hear an image left of the left speaker or 
right of the right speaker (Eargle, 1976). 
 Opposite polarity can occur in several ways. Two microphones are of 
opposite polarity if the wires to connector pins 2 and 3 are reversed in one 

197
Stereo Imaging Theory A
microphone. Two speakers are of opposite polarity if the speaker-cable 
leads are reversed at one speaker. A single microphone might have dif-
ferent parts of its polar pattern in opposite polarity. For example, the rear 
lobe of a bidirectional pattern is opposite in polarity to the front lobe. If 
sound from a particular direction reaches the front lobe of the left-channel 
mic and the rear lobe of the right-channel mic, the two channels will be of 
opposite polarity. The resulting image of that sound source will either be 
diffuse or outside the speaker pair. 
 Requirements for Natural Imaging 
over Loudspeakers 
 To the extent that a sound recording and reproducing system can dupli-
cate the interaural differences produced by a real source, the resultant 
image will be accurately localized. In other words, when reproduced 
sounds reaching a listener’s ears have amplitude and phase differences 
corresponding to those of a real sound source at some particular angle, 
the listener perceives a well-fused, naturally focused image at that same 
angle. Conversely, when unnatural amplitude and phase relations are 
produced, the image appears relatively diffuse rather than sharp and is 
harder to localize accurately (Cooper and Bauck, 1980). 
 The required interaural differences for realistic imaging can be pro-
duced by certain interchannel differences. Placing an image in a precise 
location requires a particular amplitude difference versus frequency and 
phase difference versus frequency between channels. These have been 
calculated by Cooper and Bauck (1980) for several image angles. Gerzon 
(1980), Nakabayashi (1975), and Koshigoe and Takahashi (1976) have cal-
culated the interaural or interchannel differences required to produce any 
image direction at a single frequency. 
  Figure A-8 , for example, shows the interchannel differences required 
to place an image at 15° to the left of center when the speakers are placed 
± 30° in front of the listener (Cooper and Bauck, 1980). 
 As  Figure A-8  shows, the interchannel differences required for 
natural imaging vary with frequency. Speciﬁ cally, Cooper and Bauck 
(1980) indicate that interchannel amplitude differences are needed below 
approximately 1700 Hz and interchannel time differences are needed 
above that frequency (Cooper, 1987). Speciﬁ cally: 
 • At low frequencies, the amplitude difference needed for a 15° image 
angle is about 10 dB. 

198
Stereo Imaging Theory
 • Between 1.7 and 5 kHz, the amplitude difference goes to approximately 
0 dB. But there still is a phase difference to shift the image off-center. 
 • Above 1.7 kHz, the phase difference corresponds to a group 
delay (interchannel time difference) of about 0.547 millisecond, or 
7.39 inches for a hypothetical spacing between microphones used 
for stereo recording. 
 Figure A-8  Amplitude (top) and phase (bottom) of right channel relative to left 
channel, for image location 15° to the left of center when speakers are ± 30° in front 
of listener. 

199
Stereo Imaging Theory A
 This theory is based on the “shadowing” of sound traveling around a 
sphere. The description given here simpliﬁ es the complex requirements, 
but it conveys the basic idea. Cooper (1980) notes that “moderate devia-
tions from these speciﬁ cations might not lead to noticeable auditory dis-
tress or faulty imaging.” 
 The Cooper–Bauck criteria can be met by recording with a dummy 
head whose signals are specially processed. A dummy head used for binau-
ral recording is a modeled head with a ﬂ ush-mounted microphone in each 
ear. Time and spectral differences between channels create the stereo images. 
(Spectral differences are amplitude differences that vary with frequency.) 
 Although a dummy-head binaural recording can provide excellent 
imaging over headphones, it produces poor localization over loudspeakers 
at low frequencies (Huggonet and Jouhaneau, 1987,  Figure 13 , p. 16) unless 
spatial equalization (a shufﬂ er circuit) is used (Griesinger, 1989). Spatial 
equalization boosts the low frequencies in the difference ( L –  R ) signal. 
 Binaural recording can produce images surrounding a listener wear-
ing headphones but only frontal images over loudspeakers, unless a trans-
aural converter is used. A transaural converter is an electronic device that 
converts binaural signals (for headphone playback) into stereo signals (for 
loudspeaker playback). Transaural stereo is a method of surround-sound 
reproduction using a dummy head for binaural recording, processed elec-
tronically to remove head-related crosstalk when the recording is heard 
over two loudspeakers (Bauer, 1961; Schroeder and Atal, 1963; Damaske, 
1971; Eargle, 1976, pp. 122–123; Sakamoto et al., 1978, 1981, 1982; Mori 
et al., 1979; Cooper and Bauck, 1989; Moller, 1989). 
 Cooper recommends that, for natural imaging, the speakers’ inter-
channel differences be controlled so that their signals sum at the ears to 
produce the correct interaural differences. According to Theile (1987), 
Cooper’s theory (based on summing localization) is in error because 
it applies only to sine waves and may not apply to broadband spectral 
effects. He proposes a different theory of localization, the association 
model. This theory suggests that, when listening to two stereo loudspeak-
ers, we ignore our interaural differences and instead use the speakers’ 
interchannel differences to localize images. 
 The interchannel differences needed for best stereo, Theile says, 
are head related. The ideal stereo miking technique would use, perhaps, 
two ear-spaced microphones ﬂ ush mounted in a head-size sphere and 
equalized for ﬂ at subjective response. This would produce interchannel 
spectral and time differences that, Theile claims, are optimum for stereo. 
The interchannel differences—time differences at low frequencies and 

200
Stereo Imaging Theory
amplitude differences at high frequencies—are the opposite of Cooper’s 
requirements for natural stereo imaging. Time will tell which theory is 
closer to the truth. 
 Currently Used Image-Localization 
Mechanisms 
 The ear can be fooled into hearing reasonably sharp images between speak-
ers by less sophisticated signal processing. Simple amplitude and/or time 
differences between channels, constant with frequency, can produce local-
izable images. Bartlett (1979, pp. 38, 40), Madsen (1957), Dutton (1962), 
Cabot (1977), Williams (1987), Blauert (1983), and Rumsey (1989) give test 
results showing image location as a function of interchannel amplitude or 
time differences. Bartlett’s results are shown later in this appendix. 
 For example, given a speech signal, if the left channel is 7.5 dB louder 
than the right channel, an image will appear at approximately 15° to the 
left of center when the speakers are placed ± 30° in front of the listener. 
A delay in the right channel of about 0.5 millisecond will accomplish the 
same thing, although image locations produced solely by time differences 
are relatively vague and hard to localize. 
 Griesinger notes that pure interchannel time differences do not 
localize low-pass-ﬁ ltered male speech below 500 Hz over loudspeak-
ers. Amplitude (level) differences are needed to localize low-frequency 
sounds. Either amplitude or time differences can localize high-frequency 
sounds (Griesinger, 1987). 
 With a bafﬂ ed omni pair, the bafﬂ e attenuates or “shadows” high 
frequencies arriving from the opposite side, so the amplitude difference 
between mics increases with frequency. The time difference is constant 
with frequency. 
 The interchannel differences produced by coincident, near-
coincident, and spaced-pair techniques are constant with frequency—just 
simple approximations of what is required. Still, reasonably sharp images 
are produced. Let’s look at exactly how these differences localize images 
(Bartlett, 1979). 
 Localization by Amplitude Differences 
 The location of images between two loudspeakers depends in part on 
the signal amplitude differences between the loudspeakers. Suppose a 

201
Stereo Imaging Theory A
speech signal is sent to two stereo loudspeakers, with the signal to each 
speaker identical except for an amplitude (level) difference (as shown in 
 Figure A-9 ). We create an amplitude difference by inserting an attenuator 
in one channel.  
  Figure A-10  shows the approximate sound-image location between 
speakers versus the amplitude difference between channels, in decibels. 
A 0 dB difference (equal level from each speaker) makes the image of 
the sound source appear in the center, midway between the speakers. 
Increasing the difference places the image farther away from the center. 
A difference of 15–20 dB makes the image appear at only one speaker.  Play 
Website track 5 to hear a demonstration of image location versus level difference 
between channels. 
 The information in this ﬁ gure is based on carefully controlled listening 
tests. The data is the average of the responses of 10 trained listeners. They 
auditioned a pair of signal-aligned, high-quality loudspeakers several feet 
 Figure A-9  Sending a speech signal to two stereo loudspeakers with attenuation 
in one channel. 
 Figure A-10  Stereo-image location versus amplitude difference between chan-
nels, in dB (listener’s perception). 

202
Stereo Imaging Theory
from the walls in a “typical” listening room, while sitting centered between 
the speakers at a 60° listening angle. Your own results may vary. 
 How can we create this effect with a stereo microphone array? Sup-
pose two cardioid microphones are crossed at 90° to each other, with the 
grille of one microphone directly above the other ( Figure A-11 ). The micro-
phones are angled 45° to the left and right of the center of the orchestra. 
Sounds arriving from the center of the orchestra will be picked up equally 
by both microphones. During playback, there will be equal levels from 
both speakers and, consequently, a center image is produced.  
 Suppose that the extreme right side of the orchestra is 45° off-cen-
ter, from the viewpoint of the microphone pair. Sounds arriving from the 
extreme right side of the orchestra approach the right-aiming microphone 
on axis, but they will approach the left-aiming microphone at 90° off axis (as 
shown in  Figure A-11 ). A cardioid polar pattern has a 6 dB lower level at 90° 
off axis than it has on axis. So, the extreme-right sound source will produce a 
6 dB lower output from the left microphone than from the right microphone. 
 So we have a 6 dB amplitude difference between channels. Accord-
ing to  Figure A-10 , the image of the extreme-right side of the orchestra 
will now be reproduced right of center. Instruments in between the center 
and the right side of the orchestra will be reproduced somewhere between 
the 0 and 6 dB points. 
 Figure A-11  Cardioids crossed at 90°, picking up a source at one end of an 
orchestra. 

203
Stereo Imaging Theory A
 If we angle the microphones farther apart, for example 135°, the dif-
ference produced between channels for the same source is around 10 dB. 
As a result, the right-side stereo image will appear farther to the right 
than it did with 90° angling. (Note that it is not necessary to aim the 
microphones exactly at the left and right sides of the ensemble.) 
 The farther to one side a sound source is, the greater the amplitude 
difference between channels it produces and, thus, the farther from center 
is its reproduced sound image. 
 Localization by Time Differences 
 Phantom-image location also depends on the signal time differences 
between channels. Suppose we send the same speech signal to two speak-
ers at equal levels but with one channel delayed (as in  Figure A-12 ). 
  Figure A-13  shows the approximate sound-image location between 
speakers, with various time differences between channels, in millisec-
onds. A 0 millisecond difference (no time difference between speaker 
channels) makes the image appear in the center. As the time difference 
increases, the phantom image appears farther off-center. A difference or 
delay of 1.2 to 1.5 milliseconds is sufﬁ cient to place the image at only one 
speaker.  Play Website track 6 to hear a demonstration of image location versus 
time difference between channels. 
 Figure A-12  Sending a speech signal to two speakers with one channel delayed. 

204
Stereo Imaging Theory
 Spacing two microphones apart horizontally, even by a few inches, 
produces a time difference between channels for off-center sources. A sound 
arriving from the right side of the orchestra will reach the right microphone 
ﬁ rst, simply because it is closer to the sound source (as in  Figure A-14 ). For 
example, if the sound source is 45° to the right, and the microphones are 8 
inches apart, the time difference produced between channels for this source 
is about 0.4 millisecond. For the same source, a 20-inch spacing between 
microphones produces a 1.5 millisecond time difference between channels, 
placing the reproduced sound image at one speaker.  
 With spaced-pair microphones, the farther a sound source is from 
the center of the orchestra, the greater the time difference between chan-
nels and, thus, the farther from center is its reproduced sound image. 
 Localization by Amplitude and Time Differences 
 Suppose 90° angled cardioid microphones are spaced 8 inches apart (as 
in  Figure A-15 ). A sound source 45° to the right will produce a 6 dB level 
 Figure A-13  Approximate image location versus time difference between chan-
nels, in milliseconds (listener’s perception). 
 Figure A-14  Microphones spaced apart, picking up a source at one end of an 
orchestra. 

205
Stereo Imaging Theory A
difference between channels and a 0.4 millisecond difference between 
channels. The image shift of the 6 dB level difference adds to the image 
shift of the 0.4 millisecond difference to place the sound image at the right 
speaker. Certain other combinations of angling and spacing accomplish 
the same thing.  Play Website track 7 to hear a demonstration of image location 
versus level and time differences between channels. 
 Summary 
 If a speech signal is recorded on two channels, its reproduced sound 
image will appear at only one speaker if: 
 • the signal is at least 15–20 dB lower in one channel 
 • the signal is delayed at least 1.2–1.5 milliseconds in one channel 
 • the signal in one channel is lower in level and delayed by a certain 
amount. 
 When amplitude and time differences are combined to place images, the 
sharpest imaging occurs when the channel that is lower in level is also 
the channel that is delayed. If the higher-level channel is delayed, image 
confusion results because of the conﬂ icting time and amplitude cues. 
 Figure A-15  Cardioids angled 90° and spaced 8 inches, picking up a source 
at one end of an orchestra. 

206
Stereo Imaging Theory
 We have seen that angling directional microphones (coincident 
placement) produces amplitude differences between channels. Spacing 
microphones (spaced-pair placement) produces time differences between 
channels. Angling and spacing directional microphones (near-coincident 
placement) produces both amplitude and time differences between chan-
nels. These differences localize the reproduced sound image between a 
pair of loudspeakers. 
 Predicting Image Locations 
 Suppose you have a pair of microphones for stereo recording. Given 
their polar pattern, angling, and spacing, you can predict the inter-
channel amplitude and time differences for any sound-source angle. 
Hence, you can predict the localization of any stereo microphone array 
(in theory). 
 This prediction assumes that the microphones have ideal polar 
patterns, and that these patterns do not vary with frequency. It’s an 
unrealistic assumption, but the prediction agrees well with listen-
ing tests .  
 The amplitude difference between channels in dB is given by 
△dB
a
b
a
b
m
s
m
s
=
+
+
20
2
2
log
cos(θ
θ
θ
θ
/
)
cos(
/
)
 
(A-1) 
 where 
 ΔdB = amplitude difference between channels, in dB; 
 a   b cos( θ ) = polar equation for the microphone; 
 Omnidirectional  a = 1  b = 0 
 Bidirectional  a = 0  b = 1 
 Cardioid  a = 0.5  b = 0.5 
 Supercardioid  a = 0.366  b = 0.634 
 Hypercardioid  a = 0.25  b = 0.75 
 θ m = angle between microphone axes, in degrees; 
 θ s = source angle (how far off-center the sound source is), in degrees. 
 These variables are shown in  Figure A-16 . 

207
Stereo Imaging Theory A
 The time difference between channels is given by 
Δ
+
+
+
T
θ
θ
D
S
D
D
S
D
C
2
s
2
2
s
2
[( /2)
[( /2)
tan
]
tan
]


 
(A-2) 
 where 
Δ T = time difference between channels, in seconds; 
 D = distance from the source to the line connecting the microphones, 
in feet; 
 S = spacing between microphones, in feet; 
 θ s = source angle (how far off-center the sound source is), in degrees; 
 C = speed of sound (1130 feet per second). 
 These variables are shown in  Figure A-17 . 
 For near-coincident microphone spacing of a few inches, the equa-
tion can be simpliﬁ ed to this: 
ΔT
θ
S
C
sin
s   
(A-3) 
 Figure A-16 Microphone angle ( θ m ) and source angle ( θ s ). 

208
Stereo Imaging Theory
 where 
 ΔT = time difference between channels, in seconds; 
 S = microphone spacing, in inches; 
 θ s = source angle, in degrees; 
 C = speed of sound (13,560 inches per second). 
 These variables are shown in  Figure A-18 . 
 Figure A-17  Source angle ( θ s ), mic-to-source distance ( D ), and mic spacing ( S ). 
 Figure A-18 Mic spacing ( S ) and source angle ( u s ). 

209
Stereo Imaging Theory A
 Let’s consider an example. If you angle two cardioid microphones 
135° apart, and the source angle is 60° (as in  Figure A-19 ), the dB differ-
ence produced between channels for that source is calculated as follows.  
 For a cardioid,  a = 0.5 and  b = 0.5 (from the list following equation 
(A-1)). The angle between microphone axes,  θ m , is 135° and the source 
angle,  θ s , is 60°. That is, the sound source is 60° off-center. So the ampli-
tude difference between channels, using equation (A-1), is 
 
+
+
dB
20 log 0.5
0.5 cos((135 /2)
60 )
0.5
0.5 cos((135 /2)
60 )
14 dB amplitude diff
+
=
erence between channels
 
 
 So, according to  Figure A-10 , that sound source will be reproduced nearly 
all the way at one speaker. 
 Here is another example. If you place two omnidirectional micro-
phones 10 inches apart, and the sound source is 45° off-center, what is the 
time difference between channels? (Refer to  Figure A-20 .) 
 Microphone spacing,  S,  is 10 inches and source angle,  θ s , is 45°. By 
equation (A-3), 
 
=
T
10 sin 45
13,560
0.52 millisecond time dif

ference between channels
 
 
Δ
 Figure A-19 Cardioids angled 135° apart, with a 60° source angle. 
Δ

210
Stereo Imaging Theory
 So, according to  Figure A-10 , that sound source will be reproduced about 
halfway off-center. 
 Choosing Angling and Spacing 
 Many combinations of microphone angling and spacing are used to place 
the images of the ends of the orchestra at the right and the left speaker. 
In other words, there are many ways to achieve a full stereo spread. You 
can use a narrow spacing and a wide angle, or a wide spacing and a nar-
row angle—whatever works. The particular angle and spacing you use 
is not sacred. Many do not realize this, and rely on a ﬁ xed angle and/or 
spacing, such as the ORTF (Ofﬁ ce de Radiodiffusion Télévision Française) 
system (110°, 17 cm or 6.7 in). That is a good place to start, but if the repro-
duced stage width is too narrow, there’s no harm in increasing the angle 
or spacing slightly. 
 If the center instruments are too loud, you can angle the mics farther 
apart while decreasing the spacing so that the reproduced stage width is 
unchanged. In this way, you can control the loudness of the center image 
to improve the balance. 
 Figure A-20 Omnis spaced 10 inches apart, with a 45° source angle. 

211
Stereo Imaging Theory A
 To reduce pickup of early reﬂ ections from the stage ﬂ oor and walls: 
(1) increase angling, (2) decrease spacing, and (3) place the mics closer to 
the ensemble. This works as follows: 
 1. Angling the mics farther apart softens the center instruments. 
 2. Decreasing the spacing between mics maintains the original repro-
duced stage width. 
 3. Since center instruments are quieter, you can place the mics closer to 
the ensemble and still achieve a good balance. 
 4. Since the mics are closer, the ratio of reﬂ ected sound to direct sound 
is decreased. You can add distant mics or artiﬁ cial reverberation for 
the desired amount of hall ambience. 
 In general, a combination of angling and spacing (intensity and time 
differences) gives more accurate localization and sharper imaging than 
intensity or time differences alone (Griesinger, 1987). 
 Angling the mics farther apart increases the ratio of reverberation in 
the recording, which makes the orchestra sound farther away. Spacing the 
mics farther apart does not change the sense of distance, but it degrades 
the sharpness of the images. 
 Spaciousness and Spatial Equalization 
 The information in this section is from Griesinger’s (1987) article, “New 
Perspectives on Coincident and Semi-coincident Microphone Arrays.” 
 The spaciousness of a microphone array is the ratio of  L −  R energy 
to  L +  R  energy in the reﬂ ected sound. Ideally, this ratio should be equal 
to or greater than 1. In other words, the sum and difference energy are 
equal. Spaciousness implies a low correlation between channels of the 
reﬂ ected sound. 
 Some microphone arrays with good spaciousness (a value of 1) are 
listed below: 
 • the spaced pair 
 • the Blumlein pair (ﬁ gure-eight mics crossed at 90°) 
 • the mid–side (MS) array with a cardioid mid pattern and a 1:1  M / S 
ratio 
 • coincident hypercardioids angled 109° apart. 

212
Stereo Imaging Theory
 Spatial equalization or shufﬂ ing is a low-frequency shelving boost of dif-
ference ( L −  R ) signals, and a complementary low-frequency shelving cut 
of sum ( L +  R ) signals. This has two beneﬁ ts: 
 1. It increases spaciousness, so that coincident and near-coincident 
arrays can sound as spacious as spaced arrays. 
 2. It aligns the low- and high-frequency components of the sound 
images, which results in sharper image focus. 
 You can build a spatial equalizer as shown in Griesinger’s article. Or use 
an MS technique and boost the low frequencies in the  L −  R  or side signal, 
and cut the low frequencies in the  L +  R or mid signal. The required boost 
or cut depends on the mic array, but a typical value is 4–6 dB shelving 
below 400 Hz. Excessive boost can split off-center images, with bass and 
treble at different positions. The correction should be done to the array 
before it is mixed with other mics. 
 Gerzon (1987) points out that the sum and difference channels should 
be phase compensated, as suggested by Vanderlyn (1957). Gerzon notes 
that spatial equalization is best applied to stereo microphone techniques 
not having a large antiphase reverberation component at low frequencies, 
such as coincident or near-coincident cardioids. With the Blumlein tech-
nique of crossed ﬁ gure-eight mics, antiphase components tend to become 
excessive. He suggests a 2.4 dB cut in the sum ( L +  R ) signal and a 5.6 dB 
boost in the difference ( L −  R ) signal for better bass response. 
 Griesinger (1989) states, “Spatial equalization can be very helpful in 
coincident and semi-coincident techniques [especially when listening is 
done in small rooms]. Since the strongest localization information comes 
from the high frequencies, microphone patterns and angles can be chosen 
which give an accurate spread to the images at high frequencies. Spatial 
equalization can then be used to raise the spaciousness at low frequencies.” 
 Alan Blumlein devised the ﬁ rst shufﬂ er, revealed in his 1933 pat-
ent. He used it with two omni mic capsules spaced apart the width of a 
human head. The shufﬂ er differenced the two channels (added them in 
opposite polarity). When two omnis are added in opposite polarity, the 
result is a single bidirectional pattern aiming left and right. Blumlein used 
this pattern as the side pattern in an MS pair (Lipshitz, 1990). 
 The frequency response of the synthesized bidirectional pattern is 
weak in the bass: it falls 6 dB/octave as frequency decreases. So Blum-
lein’s shufﬂ er circuit also included a 6 dB/octave low-frequency boost 
below 700 Hz to compensate. 

213
Stereo Imaging Theory A
 The shufﬂ er converts phase differences into intensity differences. 
The farther off-center the sound source is, the greater the phase differ-
ence between the spaced mics. And the greater the phase difference, the 
greater the intensity difference between channels created by the shufﬂ er. 
 References 
 Bartlett, B. “Stereo Microphone Technique.”  db,  Vol. 13, No. 12 (December 1979), 
pp. 34–46. 
 Bauer, B. “Stereophonic Earphones and Binaural Loudspeakers.”  Journal of the 
Audio Engineering Society, Vol. 9, No. 2 (April 1961), pp. 148–151. 
 Blauert, J.  Spatial Hearing. Cambridge, MA: MIT Press, 1983. 
 Cabot, R. “Sound Localization in Two and Four Channel Systems: A Comparison 
of Phantom Image Prediction Equations and Experimental Data.” Preprint 
No. 1295 (J3), paper presented at the Audio Engineering Society 58th Con-
vention, November 4–7, 1977, New York. 
 Carterette, E. and Friedman, M.  Handbook of Perception. Vol. 4: Hearing. New York: 
Academic Press, 1978. 
 Cooper, D. H. “Problems with Shadowless Stereo Theory: Asymptotic Spectral 
Status.”  Journal of the Audio Engineering Society,  Vol. 35, No. 9 (September 
1987), p. 638. 
 Cooper, D. and Bauck, J. “On Acoustical Speciﬁ cation of Natural Stereo Imag-
ing.” Preprint No. 1616 (X3), paper presented at the Audio Engineering Soci-
ety 65th Convention, February 25–28, 1980, London. 
 Cooper, D. and Bauck, J. “Prospects for Transaural Recording.”  Journal of the 
Audio Engineering Society,  Vol. 37, No. 1–2 (January–February 1989), pp. 9–19. 
 Damaske, P. “Head-Related Two-Channel Stereophony with Loudspeaker 
Reproduction.”  Journal of the Acoustical Society of America,  Vol. 50, No. 4 
(1971), pp. 1109–1115. 
 Dutton, G. “The Assessment of Two-Channel Stereophonic Reproduction Per-
formance in Studio Monitor Rooms, Living Rooms, and Small Theatres.” 
 Journal of the Audio Engineering Society,  Vol. 10, No. 2 (April 1962), pp. 98–105. 
 Eargle, J.  Sound Recording. New York: Van Nostrand Reinhold Company, 1976. 
 Gardner, M. “Some Single and Multiple Source Localization Effects.”  Journal of 
the Audio Engineering Society, Vol. 21, No. 6 (July–August 1973), pp. 430–437. 
 Gardner, M. and Gardner, R. “Problems of Localization in the Median Plane-
Effect of Pinnae Cavity Occlusion.”  Journal of the Acoustical Society of America, 
Vol. 53 (February 1973), pp. 400–408. 
 Gerzon, M. “Pictures of Two-Channel Directional Reproduction Systems.” Pre-
print No. 1569 (A4), paper presented at the Audio Engineering Society 65th 
Convention, February 25–28, 1980, London. 
 Gerzon, M. Letter to the Editor, reply to comments on “Spaciousness and Local-
ization in Listening Rooms and Their Effects on the Recording Technique.” 

214
Stereo Imaging Theory
 Journal of the Audio Engineering Society,  Vol. 35, No. 12 (December 1987), 
pp. 1014–1019. 
 Griesinger, D. “New Perspectives on Coincident and Semi-coincident Micro-
phone Arrays.” Preprint No. 2464 (H4), paper presented at the Audio Engi-
neering Society 82nd Convention, March 10–13, 1987, London. 
 Griesinger, D. “Equalization and Spatial Equalization of Dummy Head Record-
ings for Loudspeaker Reproduction.”  Journal of the Audio Engineering Society, 
Vol. 34, No. 1–2 (January–February 1989), pp. 20–29. 
 Harvey, F. and Schroeder, M. “Subjective Evaluation of Factors Affecting Two-
Channel Stereophony.”  Journal of the Audio Engineering Society,  Vol. 9, No. 1 
(January 1961), pp. 19–28. 
 Huggonet, C. and Jouhaneau, J. “Comparative Spatial Transfer Function of Six 
Different Stereophonic Systems.” Preprint No. 2465 (H5), paper presented 
at the Audio Engineering Society 82nd Convention, March 10–13, 1987, 
London. 
 Koshigoe, S. and Takahashi, S. “A Consideration on Sound Localization.” Pre-
print No. 1132 (L9), paper presented at the Audio Engineering Society 54th 
Convention, May 4–7, 1976. 
 Lipshitz, S. Letter to the Editor.  Audio (April 1990), p. 6. 
 Madsen, E. R. “The Application of Velocity Microphones to Stereophonic Record-
ing.”  Journal of the Audio Engineering Society, Vol. 5, No. 2 (April 1957), p. 80. 
 Mehrgardt, S. and Mellert, V. “Transformation Characteristics of the External 
Human Ear.”  Journal of the Acoustical Society of America,  Vol. 61, No. 6 (1977) 
p. 1567. 
 Moller, H. “Reproduction of Artiﬁ cial-Head Recordings Through Loudspeakers.” 
 Journal of the Audio Engineering Society,  Vol. 37, No. 1–2 (January–February 
1989), pp. 30–33. 
 Mori, T., Fujiki, G., Takahashi, N., and Maruyama, F. “Precision Sound-Image-
Localization Technique Utilizing Multi-track Tape Masters.”  Journal of the 
Audio Engineering Society,  Vol. 27, No. 1–2 (January–February 1979), pp. 32–38. 
 Nakabayashi, K. “A Method of Analyzing the Quadraphonic Sound Field.”  Jour-
nal of the Audio Engineering Society, Vol. 23, No. 3 (April 1975), pp. 187–193. 
 Rumsey, F.  Stereo Sound for Television. Boston: Focal Press, 1989. 
 Sakamoto, N., Gotoh, T., Kogure, T., and Shimbo, M. “On the Advanced Stereo-
phonic Reproducing System ‘Ambience Stereo.’” Preprint No. 1361 (G3), 
paper presented at the Audio Engineering Society 60th Convention, May 
2–5, 1978, Los Angeles. 
 Sakamoto, N., Gotoh, T., Kogure, T., and Shimbo, M. “Controlling Sound-Image 
Localization in Stereophonic Reproduction, Part I.”  Journal of the Audio Engi-
neering Society, Vol. 29, No. 11 (November 1981), pp. 794–799. 
 Sakamoto, N., Gotoh, T., Kogure, T., and Shimbo, M. “Controlling Sound-Image 
Localization in Stereophonic Reproduction, Part II.”  Journal of the Audio Engi-
neering Society, Vol. 30, No. 10 (October 1982), pp. 719–722. 

215
Stereo Imaging Theory A
 Schroeder, M. and Atal, B. “Computer Simulation of Sound Transmission in 
Rooms.”  IEEE Convention Record, Part 7 (1963), pp. 150–155. 
 Shaw, E. “Transformation of Sound Pressure Levels from the Free Field to the 
Eardrum in the Horizontal Plane.”  Journal of the Acoustical Society of America, 
Vol. 56, No. 6 (December 1974), pp. 1848–1861. 
 Theile, G. “On the Stereophonic Imaging of Natural Spatial Perspective via 
Loudspeakers: Theory.” In  Perception of Reproduced Sound 1987,  eds. Soren 
Bech and O. Juhl Pedersen. Munich: Institut fur Rundfunktechnik, 1987. 
 Vanderlyn, P. British Patent 781,186 (August 14, 1957). 
 Vanderlyn, P. “Auditory Cues in Stereophony.”  Wireless World  (September 1979), 
pp. 55–60. 
 Wallach, H., Newman, E., and Rozenzweig, M. “The Precedence Effect in Sound 
Localization.”  Journal of the Audio Engineering Society,  Vol. 21, No. 10 (December 
1973), pp. 817–826. 
 Williams, M. “Uniﬁ ed Theory of Microphone Systems for Stereophonic Sound 
Recording.” Preprint No. 2466 (H6), paper presented at the Audio Engineer-
ing Society 82nd Convention, March 10–13, 1987, London.  

This page intentionally left blank

217
 Some stereo microphone techniques work better than others. Each method 
has different effects. A few techniques provide sharper imaging; some create 
a narrow stage effect; some have exaggerated separation, and so on. In this 
appendix, I compare the characteristics of several speciﬁ c stereo microphone 
techniques. All of these use free-ﬁ eld microphones; the next appendix cov-
ers stereo techniques using boundary microphones and dummy heads. 
 Localization Accuracy 
 One characteristic that varies among different types of arrays is local-
ization accuracy. Localization is accurate if instruments at the sides of 
the ensemble are reproduced from the left or right speaker; instruments 
halfway off-center are reproduced halfway between the center and one 
speaker, and so on. In other words, there is little or no distortion of the 
geometry of the musical ensemble. 
 For example, suppose your stereo speakers are spaced the same 
distance apart as you’re sitting from them, so that each speaker is ± 30° 
off-center. (This is the recommended arrangement for good stereo.) If the 
 B
SPECIFIC FREE-FIELD 
STEREO MICROPHONE 
TECHNIQUES 

218
Specific Free-Field Stereo Microphone Techniques
orchestral width “seen” by the microphone pair is 90°, we want sources 
that are 45° to one side of center to be reproduced out of only one speaker. 
Sources 22.5° off-center should be reproduced halfway between the cen-
ter of the speaker pair and one speaker (15° off-center). 
  Figure B-1  illustrates this. In  Figure B-1 (a), the letters A through E 
represent live sound-source positions relative to the microphone pair. In 
 Figure B-1 (b), the corresponding images of these sources are accurately 
localized between the speaker pair. 
 Spacing or angling the microphones more than is necessary to 
achieve a full stereo spread produces an “exaggerated separation” effect: 
instruments near the center are reproduced to the extreme left or right, 
rather than slightly off-center. Instruments exactly in the center are still 
reproduced between the speakers (see  Figure B-1 (c)). Conversely, too 
little angling or spacing gives a poor stereo spread or a “narrow stage” 
effect (see Figure B-1(d)).  Play Website track 20 to hear exaggerated separation 
and play Website tracks 9 – 10 to hear the narrow stage effect. 
Figure B-1 Stereo localization effects for a 90° (± 45°) orchestral width: 
(a) letters A through E represent live sound-source positions (top view); (b) accu-
rately localized images between speakers (listener’s perception); (c) exagger-
ated separation effect; and (d) narrow stage effect.

219
Specific Free-Field Stereo Microphone Techniques B
 A listening test was performed to determine the localization accu-
racy of various stereo microphone techniques, for a 90° orchestral width 
(Bartlett, 1979). Recordings were made of a speech source at 0°, 22.5°, and 
45° relative to the microphone pair (as in Figure B-2(a)). Tests were made 
in an anechoic chamber and in a reverberant gymnasium. Listeners were 
Figure B-2 Image location of some stereo mic arrays versus source posi-
tion: (a) letters A through E are live speech-source positions relative to the mic 
array; (b) images A through E are the perceived image locations that each 
stereo mic array produces.

220
Specific Free-Field Stereo Microphone Techniques
asked to note the reproduced sound-image locations for several tech-
niques. The image locations of the anechoic and reverberant recording 
rooms were averaged, with results shown in Figure B-2(b). 
   Since results may vary under different listening conditions, this 
information is meant to be indicative, rather than deﬁ nitive. Different lis-
teners hear stereo effects differently, so your perceptions may not agree 
exactly with those shown. Still,  Figure B-2  lets you compare one tech-
nique to another.  Play Website tracks 8 – 24 to hear imaging comparisons of 
various stereo mic techniques. 
 The 90° orchestral width used is arbitrary. The actual width of the 
orchestra varies with the size of the ensemble and the mic-to-source dis-
tance. If the orchestral width is more than 90°, the stereo spread of all 
these techniques is wider than shown in Figure B-2(b). 
 The closer to the ensemble a microphone array is placed, the greater 
is the orchestral width as seen by the microphone pair, and, thus, the 
wider is the stereo spread (up to the limit of the speaker spacing). 
 Examples of Coincident-Pair Techniques 
 In general, coincident cardioids tend to give a narrow stereo spread 
and lack a sense of air or spaciousness. Imaging at high frequencies 
is not optimum because there is no time difference between channels, 
which, according to Cooper, is essential. Also, when microphones are 
angled apart, they receive much of the sound off axis. Many micro-
phones have off-axis coloration (a different frequency response on and 
off axis). 
 Coincident techniques are mono-compatible: the frequency response 
is the same in mono and stereo. That is because there are no phase or 
time differences between channels to cause phase cancellations if the two 
channels are mixed to mono. 
 Coincident Cardioids Angled 180° Apart 
 According to Figure B-2(b), it seems reasonable to angle two coincident 
cardioid microphones 180° apart to achieve maximum stereo spread (as 
shown in  Figure B-3 ). However, sounds arriving from straight ahead 
approach each microphone 90° off axis. The 90° off-axis frequency 
response of some microphones is weak in high frequencies, giving a dull 
sound to instruments in the center of the orchestra. In addition, it has been 
the experience of another experimenter, Michael Gerzon (1976, p. 36), that 

221
Specific Free-Field Stereo Microphone Techniques B
180° angling places the reproduced reverberation to the extreme left and 
right.  Play Website track 11 to hear the imaging of coincident cardioids angled 
180 ° apart. 
  Coincident Cardioids Angled 120°–135° Apart 
 A 120°–135° angle between microphones might be a better compromise. 
Gerzon has reported that the 120° angle gives a uniform spread of rever-
beration between speakers, while the 135° angle ( Figure B-4 ) provides 
a slightly wider stereo spread. These angles are useful when you don’t 
Figure B-3 Coincident cardioids angled 180° apart.
Figure B-4 Coincident cardioids angled 135° apart.

222
Specific Free-Field Stereo Microphone Techniques
want the reproduced ensemble to spread all the way between speakers. 
For a wider stereo spread, you can use a near-coincident or spaced pair. 
However, the 135° angle just described can provide a full stereo spread if 
the orchestral width or source angle is 150°.  Play Website track 10 to hear the 
stereo imaging of coincident cardioids angled 120 ° apart. 
 Coincident Cardioids Angled 90° Apart 
 Angling cardioids at 90° ( Figure B-5 ) reproduces most of the reverberation 
in the center. It gives a narrow stage width, unless the ensemble surrounds 
the microphone pair in a semicircle (180° source angle).  Play Website track 9 
to hear the stereo imaging of coincident cardioids angled 90 ° apart.  
 Blumlein Technique 
 This classic method uses two coincident bidirectional mics angled 90° 
apart ( Figure B-6 ). As shown in Figure B-2(b), it provides accurate local-
ization. According to Gerzon (1976) and the listening tests, it also pro-
vides sharp imaging, a ﬁ ne sense of depth, and the most uniform possible 
spread of reverberation across the reproduced stereo stage. It has the 
sharpest perceived image focus of any system, other than spatially equal-
ized systems (Huggonet and Jouhaneau, 1987, p. 11, Figure 8). 
Figure B-5 Coincident cardioids angled 90° apart.

223
Specific Free-Field Stereo Microphone Techniques B
   Note that each bidirectional pattern has a rear lobe in opposite polar-
ity to the front lobe. If a sound source is more than 45° off-center (say, off to 
the left side), it is picked up by the front-left lobe and the back-right lobe. 
These are opposite in polarity. This creates antiphase information between 
channels, which produces vague localization. For this reason, the micro-
phones should aim at the extreme-left and -right ends of the performing 
ensemble. This prevents sound sources from being outside the 45° limit. 
However, this limitation ﬁ xes the mic-to-source distance. You can’t adjust 
this distance to vary the sense of perspective, unless you also change the 
angle between microphones or the size of the musical ensemble. 
 Another drawback is that the microphones pick up a large amount 
of reverberation. If you place the microphone pair closer to the ensem-
ble to increase the direct/reverb ratio, the stereo spread becomes exces-
sive and instruments in the center of the ensemble are emphasized. In 
addition, instruments at either end of the ensemble are reproduced with 
opposite-polarity signals from both channels, so they are not localized. 
 The Blumlein technique works best in a wide room with minimal 
side-wall reﬂ ections, where strong signals are not presented to the sides 
of the stereo pair (Streicher and Dooley, 1985). 
 Hypercardioids Angled 110° Apart 
 Shown in  Figure B-7 , this method gives accurate localization. Listening 
tests also reveal sharp imaging and very good spaciousness. This array 
has the widest in-phase region of any array that has a spaciousness of 1 
Figure B-6 The Blumlein or stereosonic technique (coincident bidirectionals 
crossed at 90°).

224
Specific Free-Field Stereo Microphone Techniques
(Griesinger, 1987). The tight pattern of the hypercardioid allows a more 
distant placement than with crossed cardioids. As for drawbacks, hyper-
cardioid microphones tend to have a bass roll-off; but this can be cor-
rected with equalization (bass boost). 
   Another coincident technique is the mid–side (MS) technique, which 
will be covered in detail later in this appendix. 
 Examples of Near-Coincident-Pair Techniques 
 If you start with a coincident pair and space the mics a few inches apart 
(making them near coincident), the stereo spread will increase. So will the 
spaciousness and depth, because of the random-phase relationships (low 
correlation) between channels at high frequencies. 
 Near-coincident methods are not mono-compatible: if both channels 
are combined to mono, there are dips in the frequency response caused 
by phase cancellations. Also, since the microphones are angled apart, the 
sound source might be reproduced with off-axis coloration. 
 The ORTF and DIN Systems 
 The listening tests summarized in Figure B-2(b) reveal that the 110° 
angled, 17-cm (6.7-inch) spaced cardioid array (the ORTF system) and the 
90° angled, 8-inch (20-cm) spaced cardioid array (the DIN system) tend to 
Figure B-7 Hypercardioids angled 110° apart.

225
Specific Free-Field Stereo Microphone Techniques B
provide accurate localization. These two methods are shown in  Figures B-8  
and  B-9 . According to a listening test conducted by Carl Ceoen (1972), the 
ORTF system was preferred over several other stereo miking techniques. 
It provided the best overall compromise of localization accuracy, image 
Figure B-8 The ORTF system: cardioids angled 110° and spaced 17 cm (6.7 inches) 
apart.
Figure B-9 The DIN system: cardioids angled 90° and spaced 20 cm (8 inches) 
apart.

226
Specific Free-Field Stereo Microphone Techniques
sharpness, an even balance across the stage, and ambient warmth.  Play 
Website track 13 to hear the stereo imaging of the ORTF technique.  
 The origin of the ORTF system was described by Condamines (1978). 
The 17 cm (6.7 in) spacing was chosen because it provided the best image 
stability with head motion, assuming a speaker angle of ± 30°. The 
110° angle was chosen because it provided the best image precision and 
placement when used with a 17 cm (6.7 in) spacing. Condamines reported 
that, if the mic angle is less than 110°, the sound stage usually does not 
spread all the way between speakers; if the angle is greater than 110°, the 
center image becomes weak (a hole-in-the-middle effect). 
 The ORTF image position varies with frequency, according to calcula-
tion (Bernfeld and Smith, 1978) and perception (Huggonet and Jouhaneau, 
1987, p. 14, Figure 11). 
 Shown in  Figure B-10 , this system was proposed by the Dutch 
Broadcasting Foundation. It uses two cardioids angled 90° apart and 
spaced 30 cm (11.8 inches) horizontally. Since the spacing of the NOS sys-
tem exceeds the 90° angled, 8-inch-spaced array in the listening test, we 
could expect it to have a slightly wider stereo spread for halfway-left and 
-right instruments.  Play Website track 14 to hear the stereo imaging of the 
NOS technique. 
Figure B-10 The NOS system: cardioids angled 90° and spaced 30 cm (11.8 inches) 
apart.

227
Specific Free-Field Stereo Microphone Techniques B
 Examples of Spaced-Pair Techniques 
 In general, listeners commented that the spaced-pair methods give rela-
tively vague, hard-to-localize images for off-center sources. These meth-
ods are useful when you want diffuse images for special effect. Spaced 
arrays have a pleasing sense of spaciousness. This is produced artiﬁ cially 
by the random-phase relationships between channels, and by opposite-
polarity signals at various frequencies (Lipshitz, 1986). 
 Spaced-pair techniques are not mono-compatible: peaks and dips in 
the frequency response of the direct sound occur when both channels are 
combined to mono. This effect may or may not be audible, because rever-
beration approaches the microphones from all angles, and each angle of 
sound incidence relates to a different pattern of phase cancellations. The 
reverberation randomizes the frequencies of these cancellations, so that 
the effect is less audible. 
 An advantage of the spaced-pair technique is that it allows the use 
of omnidirectional condenser microphones, which have a more extended 
low-frequency response than directional microphones. That is, the tone 
quality is warmer and fuller in the bass. Of course, you can equalize direc-
tional microphones to have ﬂ at bass response at a distance. 
 Another advantage is that the listening area for good stereo is wider 
than with coincident-pair techniques. The spaced-pair delay cues counter-
act the amplitude imbalance that occurs when the listener sits off-center. 
 Many instruments, such as the ﬂ ute, have quiet, weak areas in their 
sound-radiation pattern that move around as different notes are played. 
Thus, one mic of a spaced pair might pick up a note at a low signal level, 
while the other mic would pick it up at a high signal level, so the image 
would wander with the note played. However, one mic will pick up notes 
that the other mic misses. Our ears have the same ability due to their spac-
ing. Thus, the spaced pair offers the potential for better ﬁ delity (no missed 
notes) at the expense of wandering images (Lemon, 1989). 
 You can use cardioids or other unidirectional patterns in a spaced 
array to reduce pickup of hall reverberation. These patterns, however, 
tend to have less bass than omnis. Spaced ﬁ gure-eight mics have very 
little off-axis coloration. 
 Omnis Spaced 3 Feet Apart 
 Shown in  Figure B-11 , this method gives fairly accurate localization (Fig-
ure B-2(b)), but with poorly focused imaging of off-center sources. A 2-foot 

228
Specific Free-Field Stereo Microphone Techniques
spacing would give more accurate localization ( as in Website track 19 ). Since 
omnis must be placed relatively close to a performing ensemble for an 
acceptable direct/reverb ratio, this array is likely to overemphasize the 
center instruments. That is, the microphone pair is most sensitive to instru-
ments in the center of the orchestra, with reduced pickup of the sides. 
     Telarc often uses a 2-foot spaced pair, angled 90° to each other, about 
10 feet high, plus a pair of ﬂ anking omnis spaced 10–15 feet each side of 
center. The ﬂ anking mics are 2–3 dB below the center pair. The center 
mics are panned partly left and right; the ﬂ anks are panned hard left 
and right. 
 Omnis Spaced 10 Feet Apart 
 Shown in  Figure B-12 , this spacing provides a more even coverage of the 
orchestra (a better balance). However, spacings greater than 3 feet give an 
exaggerated separation effect, in which instruments slightly off-center are 
reproduced full-left or -right (Figure B-2(b)). This dispels the myth that 
spaced microphones should be as far apart as the playback loudspeakers. 
Instruments directly in the center of the ensemble are still reproduced 
exactly between the speakers.  Website track 20 demonstrates the stereo imag-
ing of two mics spaced 6 feet apart. 
Figure B-11 Omnis spaced 3 feet apart.

229
Specific Free-Field Stereo Microphone Techniques B
 Three Omnis Spaced 5 Feet Apart 
(10 Feet End to End) 
 With this method ( Figure B-13 ), a third microphone is placed between the 
other two, mixed in at an approximate equal level, and split to both chan-
nels. This reduces stereo separation while maintaining full coverage of the 
orchestra (see  Figure B-2 ). The three-spaced-omnis technique is often used 
by Telarc Records. Image focus and mono-compatibility are fair to good. 
 Decca Tree 
 Developed in 1954 by the Decca Record Company, the Decca Tree is an 
array of three spaced omnidirectional mics ( Figure B-14 ; Gayford, 1994; 
www.josephson.com/deccatree). Mic spacing depends on the desired 
amount of width and spaciousness. The center mic is placed slightly for-
ward of the outer pair. Because the center mic’s signal precedes that of the 
outer pair, the center mic helps to “solidify” the center image.  
 As for placement, the triangle of mics is mounted about 10–12 feet 
above the stage, just behind the conductor. The outer pair is angled out-
ward to point at the edges of the stage, so that the edges are picked up 
with the best high-frequency response. Central sounds are on axis to the 
Figure B-12 Omnis spaced 10 feet apart.

230
Specific Free-Field Stereo Microphone Techniques
center microphone. The center mic may exacerbate the comb-ﬁ ltering 
effects that occasionally occur with spaced pairs. 
 Sometimes, an additional pair of ﬂ anking mics is used near the edges 
of the orchestra or about one-third of the way in. These ﬂ anking mics face 
diagonally across the orchestra and help to add width and spaciousness. All 
Figure B-14 Decca Tree stereo microphone technique.
Figure B-13 Three omnis spaced 5 feet apart.

231
Specific Free-Field Stereo Microphone Techniques B
mics are mixed at an equal level. The center mic is panned to center, both left 
mics are panned hard left, and both right mics are panned hard right. 
 Mic spacing varies with the venue and the ensemble size. The center 
mic or the outriggers might be omitted in some cases. 
 Examples of Baffled-Omni Techniques 
 Sphere Microphone, SASS-P MKII 
 This mic can be called either a “bafﬂ ed-omni mic” or “boundary mic.” It 
is described in Appendix C, Stereo Boundary-Microphone Arrays, under 
the heading “Sphere Microphone.”  Play Website track 17 to hear the stereo 
imaging of a sphere microphone. 
 Optimal Stereo Signal or Jecklin Disk 
 The Jecklin disk uses two omnidirectional microphones spaced 16.5 cm 
(6.5 inches) apart and separated by a disk with a diameter of 28 cm 
(11 7/8 inches) (Jecklin, 1981). The disk is hard and is covered with ﬂ at, 
absorbent material to reduce reﬂ ections ( Figure B-15 ). The Schneider disk 
is the same but is covered with two foam hemispheres. The optimal ste-
reo signal (OSS) system could be called  quasi binaural , in that the human 
binaural hearing system also uses two omni “microphones” separated 
by a bafﬂ e (the head). 
   Below 200 Hz, both microphones receive the same amplitude, and 
the array acts like closely spaced omnis. As frequency increases, the disk 
becomes more of a sound barrier, which makes the array increasingly 
directional. At high frequencies, the array acts like a near-coincident pair 
of subcardioids angled 180° apart. 
 Since both channels receive the same signal level at low frequen-
cies, stereo localization at low frequencies can be due only to the cap-
sule spacing, which causes direction-dependent delays. But, according to 
Griesinger (1987), delay panning does not create localizable images below 
500 Hz. If that is true, the OSS system localizes only above 200 Hz. 
 According to the inventor (Jecklin, 1981), “the stereo image is nearly 
spectacular, and the sound is rich, full, and clear.” It “seems to be superior 
to all other recording methods.” The full sound is probably due to the use 
of omnidirectional condenser microphones, which have an extended low-
frequency response.  Play Website track 16 to hear the stereo imaging and full 
bass of the Jecklin Disk method. 

232
Specific Free-Field Stereo Microphone Techniques
 Listening tests (Figure B-2(b)) show that the OSS stereo spread for 
a 90° orchestral width is somewhat narrow. But, since the system uses 
omni microphones, it is usually placed close to the ensemble, where the 
angular width of the ensemble is wide. This results in a wider stereo 
spread. 
 Other Coincident-Pair Techniques 
 Let’s return to coincident-pair methods and go over some speciﬁ c tech-
niques in detail. 
 Mid–Side 
 This method uses a middle (mid) microphone capsule aiming straight 
ahead toward the center of the performing ensemble, plus a side-aiming 
Figure B-15 The OSS system or Jecklin disk. Omnis spaced 16.5 cm (6.5 inches) 
apart and separated by a foam-covered disk of 28 cm (11 7/8 inches) diameter.

233
Specific Free-Field Stereo Microphone Techniques B
(side) bidirectional microphone capsule. These capsules are coincident 
and at right angles to each other (as shown in  Figure B-16 ). The mid cap-
sule is most commonly cardioid, but it can be any pattern. 
 The outputs of both capsules are summed (mixed) to produce the 
left-channel signal and are differenced (mixed in opposite polarity) to 
produce the right-channel signal. In effect, this creates two virtual polar 
patterns angled apart: 
 M   S   L 
 M   S   R 
 For example, suppose that the mid capsule is omnidirectional and the side 
capsule is bidirectional. Also suppose that the sensitivity of both capsules 
is set equal. When you add these two patterns together, you get a cardi-
oid aiming 90° to the left. When you subtract these patterns (add them in 
opposite polarity) you get a cardioid aiming 90° to the right. Thus, an MS 
microphone with an omni mid capsule is equivalent to two coincident 
cardioids angled 180° apart. An MS microphone with a bidirectional mid 
capsule is equivalent to two ﬁ gure-eight mics crossed at 90° (the Blumlein 
technique). 
 Some stereo microphones have switchable polar patterns. Changing 
the mid-capsule pattern changes the pattern and angling of the virtual 
polar patterns. The more directional the mid mic is, the more direc-
tional are the sum-and-difference (virtual) polar patterns ( Figure B-17 ). 
Figure B-16 MS stereo microphone technique.

234
Specific Free-Field Stereo Microphone Techniques
Consequently, you can change the apparent distance from the sound 
source by changing the mid pattern. 
 MS Matrix Box 
 The  M  and  S  outputs of the microphone are connected to an MS matrix 
box or decoder. This decoder uses either a tapped transformer or an active 
circuit to sum-and-difference the  M  and  S  signals. The output of the box 
is a left- and a right-channel signal. Some sources of MS matrix decoders 
are given in  Chapter 12 in the section “MS Matrix Decoders.” 
 A rotating knob in the box controls the ratio of the mid signal to the 
side signal. By varying the ratio of mid-to-side signals, you change the polar 
pattern and angling of the left and right virtual mic capsules. In turn, this 
Figure B-17 Equivalent directional patterns for MS system, with mid pattern 
varied. (From a letter by Les Stuck to db magazine, March 1981.)

235
Specific Free-Field Stereo Microphone Techniques B
varies the stereo spread and the ratio of direct-to-reverberant sound. As you 
turn up the side signal, the stereo-spread widens and the ambience increases, 
as shown in  Figure B-18 . The optimum starting  M / S ratio is near 1:1. 
   A dual-mode matrix lets you vary the spread of an MS array, and 
also vary the spread of any standard left/right stereo mic array. 
 In  Chapter 10  under the heading “Stereo-Spread Control,” I describe 
how to use a computer digital audio workstation (DAW) to act as an 
MS matrix. 
 Some MS mics have an MS matrix built in. These microphones have 
a left-right output and usually include a stereo-spread switch in the 
mic body. 
 MS Advantages 
 A major advantage of the MS system is that you can control the stereo 
spread from a remote location, or after the recording is done. This feature 
is especially useful for live concerts, where you can’t change the micro-
phone array during the concert. Since the stereo spread is adjustable, the 
MS system can be made to have accurate localization. 
 If you record the  M and  S signals directly to a two-track recorder 
during the concert, you can play them back through a matrix decoder 
Figure B-18 Effects of varying M/S ratio on stereo spread: (a) high M/S ratio 
gives a narrow spread and (b) low M/S ratio gives a wide spread.

236
Specific Free-Field Stereo Microphone Techniques
after the concert and adjust the stereo spread then. In postproduction, 
you can vary the spread from very narrow (mono) to very wide. While 
recording the concert, you monitor the outputs of the matrix decoder but 
do not record them. 
 The MS method has another advantage: it is fully mono-compatible. 
If you sum the left and right channels to mono, you get just the output of 
the forward-facing mid capsule. This is shown in the following equations: 
 Left  ( M   S ) 
 Right  ( M   S ) 
 Left  Right  ( M   S ) + ( M   S )  2 M 
 With XY- or near-coincident techniques, the center image is formed by 
adding the outputs of two angled directional capsules. If they are not per-
fectly matched in frequency and phase responses, the fusion of the center 
image can be degraded. But the MS system has very sharp center imaging 
because the center image is the output of the single mid capsule. 
 MS Disadvantages 
 The MS system has been criticized for a lack of warmth, intimacy, and 
spaciousness (Ceoen, 1972; Griesinger, 1987). However, Griesinger states 
that MS recordings can be made more spacious by giving the low fre-
quencies a shelving boost of 4 dB (starting with 2 dB at 600 Hz) in the 
 L   R  or side signal, with a complementary shelving cut in the  L   R or 
mid signal. 
 There are other disadvantages to the MS technique. It requires a 
matrix decoder, which is extra hardware to take on location. A ﬁ nal dis-
advantage is that the stereo spread and direct-to-reverb ratio are interde-
pendent: you can’t change one without changing the other. 
 When the signals from an MS stereo microphone are mixed to mono, 
the resulting signal is only from the front-facing mid capsule. If this cap-
sule’s pattern is cardioid, sound sources to the far left or right will be 
attenuated. Thus, the balance might be different in stereo and mono. If 
this is a problem, use an XY-coincident pair rather than MS. 
 Double MS Technique 
 Skip Pizzi recommends a double MS technique, which uses a close MS 
microphone mixed with a distant MS microphone. One MS microphone 

237
Specific Free-Field Stereo Microphone Techniques B
is close to the performing ensemble for clarity and sharp imaging, and the 
other is 50–75 feet out in the hall for ambience and depth. The distant mic 
could be replaced by an XY pair for lower cost (Pizzi, 1984). 
 For a comprehensive discussion of the MS system, see Streicher and 
Dooley (1985). 
 SoundField Microphone 
 This British microphone (shown in  Figure B-19 ) is an elaboration on the 
MS system. It uses four closely spaced cardioid mic capsules arranged 
in a tetrahedron and aiming outward. Their outputs are phase shifted to 
make the capsules seem perfectly coincident. 
Figure B-19 SoundField Mk V Microphone: (a) external view and (b) internal 
view, showing capsules.

238
Specific Free-Field Stereo Microphone Techniques
   The capsule outputs are called the  A-format signals . They are elec-
tronically matrixed by a control unit to produce: 
 • An omnidirectional component (the sound pressure). 
 • A vertical pressure-gradient component. 
 • A left—right pressure-gradient component. 
 • A fore—aft pressure-gradient component. 
 These B-format signals can be further processed into stereo or sur-
round signals. With a remote-control box, the user can adjust polar pat-
terns, azimuth (horizontal rotation), elevation (vertical tilt), dominance 
(apparent distance), and angle (stereo spread) (Farrar, 1979; Streicher and 
Dooley, 1985). 
 As for drawbacks, the microphone system is expensive and requires 
a complex matrix circuit. But it is the world’s premier microphone for spa-
tial recording. Several websites of these models are given in  Chapter 12  
under the heading “Surround Microphones.” 
 Coincident Systems with Spatial Equalization 
(Shuffler Circuit) 
 Coincident-pair systems have been criticized for a lack of spacious-
ness. However, as discovered by Blumlein (1958), Vanderlyn (1954), and 
Griesinger (1986, 1987), the focus and spaciousness can be improved by 
a shufﬂ er circuit (spatial equalization). This circuit decreases stereo sepa-
ration at high frequencies or increases separation at low frequencies, in 
order to align the image locations at low and high frequencies. To increase 
low-frequency separation, the circuit applies a shelving boost to low fre-
quencies in the left-minus-right (difference) signal, and applies a comple-
mentary cut to the left-plus-right (sum) signal. 
 Griesinger reports that spatially equalized coincident or near-coincident 
arrays have very sharp imaging, and sound as spacious as a spaced array. As 
stated earlier, MS recordings can be made more spacious by boosting the bass 
4 dB shelving (2 dB at 600 Hz) in the  L   R  or side signal, and cutting the 
sum signal by the same amount. 
 Other Near-Coincident-Pair Techniques 
 Let’s look more closely at some unusual near-coincident miking methods. 

239
Specific Free-Field Stereo Microphone Techniques B
 Stereo 180 System 
 Another near-coincident method is the Stereo 180 System developed by 
Olson (1979), shown in  Figure B-20 . It uses two hypercardioid pattern 
microphones angled 135° apart, and spaced 4.6 cm (1.8 inches) horizon-
tally. The hypercardioid patterns have opposite-polarity rear lobes, which 
create the illusion that the reproduced reverberation is coming from the 
sides of the listening room as well as between the speakers. The localiza-
tion accuracy and image focus of the array are reported to be very good.  
 Faulkner Phased-Array System 
 Invented by Tony Faulkner (1982), this method uses two bidirectional 
(ﬁ gure-eight) microphones aiming straight ahead with axes parallel and 
spaced 20 cm (7.87 inches) apart ( Figure B-21 ). The plane of maximum 
sound-path difference coincides with the null in the directional polar pat-
tern of the microphones. Since the microphones are aimed forward rather 
than angled apart, you can place them farther from the ensemble for a 
Figure B-20 Stereo 180 system: hypercardioids angled 135° and spaced 4.6 cm 
(1.8 inches) apart.

240
Specific Free-Field Stereo Microphone Techniques
better balance. This distant placement also lets you place the microphones 
at ear height, rather than raised. Faulkner says that the array is not mono-
compatible in theory but has presented no problems in practice.  
 Sometimes Faulkner adds a pair of omnidirectional microphones 
2–3 feet apart, ﬂ anking the ﬁ gure-eights. These omnis add ambient 
spaciousness. 
 Near-Coincident/Spaced-Pair Hybrid 
 John Eargle, past Director of Recording at Delos International, Inc., pre-
ferred to use a combination of near-coincident and spaced-pair methods 
( Symphonic Sound Stage  CD). A quasi-ORTF pair is placed about 4 feet 
behind the conductor, 9–12 feet high. This pair is ﬂ anked by two omnis 
12–16 feet apart, typically 6 dB below the main pair. The ORTF pair pro-
vides sharp imaging and depth, while the spaced pair adds width to the 
strings and time cues from the hall. Since the spaced pair uses omnidirec-
tional mics, low-frequency reproduction is excellent. 
 A second stereo pair is placed up to 30 feet behind the main pair to 
capture hall reverb. The woodwinds often are picked up with an overhead 
pair, and accent mics are added if necessary for soloists, harp, celeste, and 
other instruments. 
Figure B-21 Faulkner phased-array system: two ﬁ gure-eights spaced 20 cm 
(7.8 inches) apart.

241
Specific Free-Field Stereo Microphone Techniques B
 Comparisons of Various Techniques 
 Many studies have been done comparing standard stereo miking tech-
niques. The results of some of these are presented here. They do not all 
agree.  Play Website tracks 8 – 24 to compare various techniques for yourself. 
 Michael Williams, “Unified Theory 
of Microphone Systems for Stereophonic 
Sound Recording” (1987) 
 Michael Williams calculated the recording angle and standard deviation 
of several ﬁ xed systems.  Recording angle  means the angle subtended by 
the sound source required for a speaker-to-speaker stereo spread. It is the 
angular width of the performing ensemble (as seen by the microphone 
array) that causes a full stereo spread. 
 The  standard deviation  represents geometric distortion of the sound 
stage. The bigger the standard deviation in degrees, the wider is the image 
separation of halfway-left and -right instruments. If standard deviation is 
0°, instruments halfway left in the orchestra are reproduced halfway left 
between the loudspeakers (that is, at 15° off-center for speakers separated 
± 30°). If standard deviation is large, this is the exaggerated separation 
effect mentioned earlier. 
 Here are his ﬁ ndings for various ﬁ xed mic arrays: 
 Coincident cardioids at 90° 
 The recording angle is ± 90° (180° in all). In other words, the orches-
tra must form a semicircle (180°) around the microphone pair to be 
reproduced from speaker to speaker. 
 The standard deviation is about 6°. In other words, an instrument 
that is half-right in the orchestra would be reproduced 6° beyond 
half-right. 
 Coincident figure-eights at 90° (Blumlein) 
 Recording angle is ± 45° (90° in all). 
 Standard deviation is about 5°. 
 Cardioids angled 110° and spaced 17 cm (6.7 in) (ORTF) 
 Recording angle is ± 50° (100° in all). 
 Standard deviation is about 5°. 

242
Specific Free-Field Stereo Microphone Techniques
 Cardioids angled 90° and spaced 30 cm (11.8 in) (NOS) 
 Recording angle is ± 40° (80° in all). 
 Standard deviation is about 4°. 
 Omnis spaced 50 cm (20 inches) 
 Recording angle is ± 50° (100° in all). 
 Standard deviation is about 8°. 
 Williams’s article has graphs showing the calculated recording angle 
and standard deviation for a wide range of polar patterns, anglings, 
and spacings, as well as other useful information. 
 Carl Ceoen, “Comparative Stereophonic 
Listening Tests” (1972) 
 Carl Ceoen used listening tests to compare several typical stereo tech-
niques. He reported the following average resolution distortion (image 
focus or sharpness) for these methods: 
 XY (coincident cardioids angled 135°): 3° 
 MS (equivalent to coincident hypercardioids angled apart): 5.5° 
 Blumlein (coincident bidirectionals angled 90°): 4° 
 ORTF (coincident cardioids at 110°, 17 cm (6.7 in)): 3° 
 NOS (cardioids angled 90° and spaced 30 cm (11.8 in)): 4° 
 Pan pot: 3° 
 According to Ceoen, the listening audience agreed that the ORTF system 
was the best overall compromise, and that the MS system lacked intimacy. 
 Benjamin Bernfeld and Bennett Smith, 
“Computer-Aided Model of Stereophonic 
Systems” (1978) 
 Bernfeld and Smith computed the image location versus frequency for vari-
ous stereo miking techniques. The better the coincidence of image locations at 
various frequencies, the sharper the imaging. Here are the condensed results: 
 Blumlein (coincident bidirectionals at 90 ° ) : Image focus is good except 
near the speakers; there, high frequencies are reproduced with a 
wider stereo spread than low frequencies. 

243
Specific Free-Field Stereo Microphone Techniques B
 Coincident cardioids angled 90 ° apart : Image focus is very good, but the 
stereo spread is very narrow. 
 Coincident cardioids angled 120 ° apart : Image focus is fairly good, but the 
stereo spread is narrow. 
 Coincident hypercardioids angled 120 ° apart : Image focus is good, but not 
excellent because high frequencies around 3 kHz are reproduced 
with a wider spread than low frequencies. 
 Coincident hypercardioids angled 120 ° apart, compensated with Vanderlyn’s 
shufﬂ er circuit (Vanderlyn, 1954) : Excellent image focus and stereo 
spread. 
 Blumlein (coincident bidirectionals at 90 ° ), compensated with shufﬂ er circuit : 
Very good image focus and stereo spread. 
 ORTF (cardioids angled 110 ° and spaced 17 cm (6.7 in)) : Good image focus; 
low frequencies have narrow spread and high frequencies have wide 
spread. 
 ORTF with hypercardioids : Similar to the above, with wider stereo 
separation. 
 Two omnis spaced 9.5 feet : Poor image focus; high frequencies have 
much wider spread than low frequencies; exaggerated separation 
effect. 
 Three cardioids spaced 5 feet : Poor image focus as above, with exagger-
ated separation at high frequencies. 
 C. Huggonet and J. Jouhaneau, “Comparative Spatial 
Transfer Function of Six Different Stereophonic 
 Systems” (1987) 
 Huggonet and Jouhaneau used a modulated tone burst at various fre-
quencies, plus a violin, with listening tests to compare the spatial transfer 
function of six different stereophonic systems. Each system has an angu-
lar dispersion (image spread) that depends on frequency. In general, the 
angular dispersion of coincident systems was least. The Blumlein array 
gave the sharpest imaging, the dummy head, and the NOS system the 
worst. The dummy head gave the best depth perception, followed by 
ORTF. MS gave the worst depth perception. 

244
Specific Free-Field Stereo Microphone Techniques
 M. Hibbing, “XY and MS Microphone Techniques 
in Comparison” (1989) 
 In comparing XY and MS coincident methods, Hibbing concluded that 
MS has several advantages over XY: 
 1. The MS system can use an omnidirectional mid element, but the XY 
system cannot use omnidirectional capsules. Since an omni capsule 
generally has better low-frequency response than a uni, the MS sys-
tem can have better low-frequency response than the XY system. 
 2. With MS, any stereo spread can be had with any polar pattern. XY is 
more limited. 
 3. With MS, a wider source angle is usable than with XY if polar pat-
terns with a low bidirectional component are used. 
 4. With MS, the mid element aims at the center of the sound source, 
so most of the sound arrives close to on axis. With XY, most of the 
sound arrives off axis and is subject to off-axis coloration. 
 5. With MS, both the mid- and side-polar patterns are more uniform 
with frequency than the patterns in the XY conﬁ guration. Conse-
quently, the left/right polar patterns generated by MS are more uni-
form with frequency than those of XY. 
 6. With MS, the stereo spread is easy to control by a fader. With XY, 
the stereo spread must be adjusted mechanically. MS allows stereo-
spread adjustment after the session; XY does not. 
 7. With MS, the mid (mono sum) signal is independent of the stereo 
spread, so it stays consistent and predictable. With XY, the mono 
sum varies with the angle between the microphones. 
 Wieslaw Woszczyk, “A New Method 
for Spatial Enhancement in Stereo 
and Surround Recording” (1990) 
 Using female speech and a soprano recorder as a sound source, Woszcyk 
recorded the source with several stereo arrays in the diffuse ﬁ eld (29–80 feet 
from the source). Blind listening tests were done using a stereo pair of speak-
ers and a Dolby surround system. The latter system used front-left and -right 
speakers, a center front speaker, a center rear speaker, and left/right sur-
round speakers. 

245
Specific Free-Field Stereo Microphone Techniques B
 The results are brieﬂ y summarized below: in general, listening in 
Dolby surround reduces the stereo separation (stage width) because of 
the center speaker. Mic techniques for Dolby surround should be opti-
mized to counteract this effect. 
 In these descriptions,  stage width  means the perceived width of the 
stage (about ± 65° in front of the mic pair).  Spatial effect means the per-
ceived spaciousness of the concert hall: 
 XY at 90 °: Very narrow stage width, narrow spatial effect. 
 XY at 180 °: Extremely wide stage width and weak center image in ste-
reo, but fairly accurate in surround. This method gave the best spa-
tial effect of the listening test: wide, intense, and natural. 
 ORTF with cardioids : Fairly accurate stage width in stereo but much nar-
rower in surround. Narrow spatial effect. 
 ORTF with hypercardioids : Wide stage width, “split” spatial effect. 
 Blumlein : Accurate stage width up to ± 45° in stereo, slightly narrower 
in Dolby surround. Wide and smooth spatial effect. 
 14-inch-spaced omni pair : Somewhat narrow stage width in stereo, even 
less in surround. Smooth and natural spatial effect. 
 Dummy head : Wide stage width in stereo, narrower in surround. Supe-
rior spatial effect: wide and smooth. 
 Pressure Zone Microphone (PZM) wedge (two 18-inch   29-inch hard bafﬂ es 
angled 45 ° ) : Overly wide stage width in stereo but accurate in sur-
round. Superior, natural spatial effect. Somewhat honky coloration. 
Spherical microphones should produce equally good imaging but 
without coloration. 
 Summary 
 Although these experimenters disagree in certain areas, they all agree that 
widely spaced microphones give poorly focused imaging and that the 
Blumlein technique gives sharp imaging. Blumlein and Bernfeld say that 
the imaging of the Blumlein array can be further sharpened with a shuf-
ﬂ er or spatial equalizer. Ceoen’s results indicate that ORTF is best, but 
others report less-than-optimal image focus with ORTF. 
 The most accurate systems for frontal stereo appear to be coincident 
or near-coincident arrays with spatial equalization, or dual MS arrays. 
The near-coincident/spaced-pair hybrid method used by Delos also 
works quite well. 

246
Specific Free-Field Stereo Microphone Techniques
 It helps to know about all the stereo techniques in order to conquer the 
acoustic problems of various halls or to create speciﬁ c effects. No particu-
lar technique is magic; you often can improve the results by changing the 
microphone angling or spacing. 
 I recommend the following recording, which demonstrates the imaging 
differences among various free-ﬁ eld stereo microphone techniques:  The Per-
formance Recordings Demonstration of Stereo Microphone Technique (PR-6-CD), 
recorded by James Boyk, Mark Fischman, Greg Jensen, and Bruce Miller; 
available at www.performancerecordings.com/albums.html. 
 References 
 The website www.dpamicrophones.com has a section called “Microphone Univer-
sity,” which includes an excellent discussion of stereo microphone techniques. 
 Bartlett, B. “Stereo Microphone Technique.”  db , Vol. 13, No. 12 (December 1979), 
pp. 310–346. 
 Bernfeld, B. and Smith, B. “Computer-Aided Model of Stereophonic Systems.” 
Preprint No. 1321, paper presented at the Audio Engineering Society 59th 
Convention, 1978–2002, p. 14. 
 Blumlein, A. “British Patent Speciﬁ cation.”  Journal of the Audio Engineering Soci-
ety , Vol. 6, No. 2 (April 1958), p. 91. Also in  Stereophonic Techniques Anthology. 
New York: Audio Engineering Society, 1986. 
 Ceoen, C. “Comparative Stereophonic Listening Tests.”  Journal of the Audio Engi-
neering Society , Vol. 20, No. 1 (January–February 1972), pp. 19–27. Also in  Ste-
reophonic Techniques Anthology. New York: Audio Engineering Society, 1986. 
 Condamines, R. “La Prise de Son.” In  Stereophonic.  Paris and New York: Masson 
Publishers, 1978. 
 Farrar, K. “Sound Field Microphone.”  Wireless World (October 1979). 
 Faulkner, T. “Phased Array Recording.”  The Audio Amateur (January 1982). 
 Gayford, M.  Microphone Engineering Handbook.  Trowbridge, Wiltshire: Focal Press, 
1994. 
 Gerzon, M. “Blumlein Stereo Microphone Technique.”  Journal of the Audio Engi-
neering Society , Vol. 24, No. 11 (January–February 1976), p. 36. 
 Griesinger, D. “Spaciousness and Localization in Listening Rooms and Their 
Effects on Recording Technique.”  Journal of the Audio Engineering Society , 
Vol. 34, No. 4 (April 1986), pp. 255–268. 
 Griesinger, D. “New Perspectives on Coincident and Semi-coincident Microphone 
Arrays.” Preprint No. 2464 (H4), paper presented at the Audio Engineering 
Society 82nd Convention, March 10–13, 1987, London. 
 Hibbing, M. “XY and MS Microphone Techniques in Comparison.”  Journal of the 
Audio Engineering Society , Vol. 37, No. 10 (October 1989), pp. 823–831. 

247
Specific Free-Field Stereo Microphone Techniques B
 Huggonet, C. and Jouhaneau, J. “Comparative Spatial Transfer Function of Six 
Different Stereophonic Systems.” Preprint No. 2465 (H5), paper presented 
at the Audio Engineering Society 82nd Convention, March 10–13, 1987, 
London. 
 Jecklin, J. “A Different Way to Record Classical Music.”  Journal of the Audio Engi-
neering Society , Vol. 29, No. 5 (May 1981), pp. 329–332. Also in  Stereophonic 
Techniques Anthology. New York: Audio Engineering Society, 1986. 
 Lemon, J. “Spacing for Fidelity,” letter to the editor.  Recording Engineer/Producer 
 (September 1989), p. 76. 
 Lipshitz, S. ”Stereo Microphone Techniques: Are the Purists Wrong?”  Journal of 
the Audio Engineering Society , Vol. 34, No. 9 (September 1986), pp. 716–744. 
 Olson, L. “The Stereo-180 Microphone System.”  Journal of the Audio Engineering 
Society , Vol. 27, No. 3 (March 1979), pp. 158–163. Also in  Stereophonic Tech-
niques Antholog y. New York: Audio Engineering Society, 1986. 
 Pizzi, S. “Stereo Microphone Techniques for Broadcast.” Preprint No. 2146 (D-3), 
paper presented at the Audio Engineering Society 76th Convention, October 
8–11, 1984, New York. 
 Streicher, R. and Dooley, W. “Basic Stereo Microphone Perspectives—A Review.” 
 Journal of the Audio Engineering Society , Vol. 33, No. 7–8 (July–August 1985), 
pp. 548–556. Also in  Stereophonic Techniques Anthology. New York: Audio 
Engineering Society, 1986. 
 The Symphonic Sound Stage , Vol. 2. Delos Compact Disc D/CD 3504. 
 Vanderlyn, P. British Patent Speciﬁ cation 23989 (1954). 
 Williams, M. “Uniﬁ ed Theory of Microphone Systems for Stereophonic Sound 
Recording.” Preprint No. 2466 (H-6), paper presented at the  Audio Engineering 
Society, 82nd Convention , March 10–13, 1987, London. 
 Woszcyk, W. “A New Method for Spatial Enhancement in Stereo and Surround 
Recording.” Preprint No. 2946, paper presented at the Audio Engineering 
Society 89th Convention, September 21–25, 1990, Los Angeles. 

This page intentionally left blank

249
 Boundary microphones (discussed in  Chapter 7 ) can make excellent 
stereo recordings. This appendix explains the characteristics of several 
boundary-mic arrays. 
 First, here are some ways to create basic stereo arrays using boundary 
microphones (Bartlett, 1987): 
 • To make a spaced-pair boundary array, space two boundary micro-
phones a few feet apart. They can be omni or unidirectional. Place 
them on the ﬂ oor, on a wall, or on stand-mounted panels. 
 • To make a coincident array, mount two omni boundary mics back-
to-back on a 2-foot × 2-foot clear plastic panel, with the edge of the 
panel aiming at the sound source. 
 • To make a near-coincident array, mount each omni boundary micro-
phone on a separate panel, and angle the panels apart to form a “V.” 
Or use two unidirectional boundary mics on the ﬂ oor, angled and 
spaced. 
 Boundary microphones can be placed directly on the ﬂ oor or can be 
raised above the ﬂ oor. We explain several stereo techniques using both 
methods. 
 C
STEREO BOUNDARY-
MICROPHONE ARRAYS 

250
Stereo Boundary-Microphone Arrays
 Techniques Using Floor-Mounted Mics 
 You can place two boundary microphones on the ﬂ oor to record in stereo. 
Floor mounting provides several advantages: 
 • Phase cancellations due to sound reﬂ ections off the ﬂ oor are eliminated. 
 • Floor mounting provides the best low-frequency response for boundary 
microphones. 
 • The mics are very easy to place. 
 • The mics are nearly invisible. At live concerts, hiding the micro-
phones is often the main consideration. 
 When a ﬂ oor-placed boundary array is used to record an orchestra, the 
front-row musicians are usually reproduced too loudly, due to their rela-
tive proximity to the microphones. Musical groups with little front-to-back 
depth—such as small chamber groups, jazz groups, or soloists—may be 
the best application for this system. 
 Let’s consider speciﬁ c techniques for ﬂ oor-mounted microphones. 
 Floor-Mounted Boundary Microphones 
Spaced 4 Feet Apart 
 Listening tests showed that a spacing of 3–4 feet between microphones is 
sufﬁ cient for a full stereo spread, when the sides of the musical ensem-
ble are 45° off-center, from the viewpoint of the center of the microphone 
array (see  Figure C-1 ).  Listen to Website track 22 to hear the stereo imaging of 
two ﬂ oor-mounted PZMs (Pressure Zone Microphones) placed 3 feet apart. 
 With a ﬂ oor-placed array, the stereo spread decreases as the sound-
source height increases. For example, if you record a group of people 
who are standing, the spread will be narrower than if the people are sit-
ting. That’s because the higher the source is, the less the time difference is 
between microphones. 
 Spaced boundary mics have the same drawbacks as spaced free-ﬁ eld 
mics: poorly focused images, potential lack of mono-compatibility, and 
large phase differences between channels.  Listen to Website track 22 to hear 
the stereo imaging of two ﬂ oor-mounted PZMs placed 3 feet apart. 
 Two advantages, however, are a warm sense of ambience and a 
good stereo effect even for off-center listeners. A ﬂ oor-mounted spaced 
pair of omni boundary mics provides stereo without needing Plexiglas ™ 

251
Stereo Boundary-Microphone Arrays C
boundaries. So the low-frequency response is excellent and the mics are 
inconspicuous. 
 Floor-Mounted Unidirectional Boundary 
Microphones 
 Two of these can be set up as a near-coincident pair or a spaced pair. For 
near-coincident use, place the mics on the ﬂ oor side by side and angle 
them apart ( Figure C-2 ). Adjust their angling and spacing for the desired 
stereo spread. This is an effective arrangement for recording stage plays 
or musicals. Other mics are needed for the pit orchestra. 
   As shown in  Figure C-1 , a ﬂ oor-mounted array of supercardioid 
boundary mics, angled 90° and spaced 8 inches, provides a narrow stage 
Figure C-1 Stereo localization of some stereo boundary-microphone arrays: 
(a) letters A through E are live speech-source positions relative to mic array; (b) A 
through E are the perceived image locations produced by the mic arrays.

252
Stereo Boundary-Microphone Arrays
width. More spacing or angling is needed for accurate localization. The 
image focus is sharper with this arrangement than with spaced bound-
ary microphones.  Website track 23 demonstrates the stereo imaging of a pair of 
cardioid boundary mics angled 90° and spaced 12 inches. 
 Optimal Stereo Signal Boundary-Microphone 
Floor Array 
 In this conﬁ guration by Josephson Engineering (1988), two boundary 
microphones are on opposite sides of a hard, absorbent bafﬂ e or Jecklin 
disk cut in half. This array has the characteristics of the Optimal Stereo 
Signal (OSS) system described in the previous appendix plus the advan-
tages of boundary miking. 
 “The Musician’s Ear” Stereo Boundary 
Microphone 
 This unit has two condenser mics ﬂ ush-mounted in opposite sides of a 
wooden bafﬂ e that sits on the ﬂ oor (www.performancerecordings.com/
ear.html). 
Figure C-2 Floor-mounted directional boundary microphones set in a near-
coincident array.

253
Stereo Boundary-Microphone Arrays C
 Floor-Mounted Boundary Microphones 
Configured for Mid–Side 
 The mid–side (MS) technique can be applied to boundary microphones. 
The following method was invented by Jerry Bruck (1985) of Posthorn 
Recordings. The mid unit is an omnidirectional boundary microphone; the 
side unit is a small-diameter bidirectional condenser microphone mounted 
a few millimeters (several thousandths of an inch) above the omni unit. 
 The bidirectional microphone is close enough to the boundary to 
prevent phase cancellations between direct and reﬂ ected sounds over 
most of the audible spectrum. 
 Since the mid microphone is a boundary type, it has the same high-
frequency response anywhere around it (no off-axis coloration). This con-
tributes to very sharp stereo imaging. And since the mid capsule is an 
omni condenser unit, it has excellent low-frequency response. The system 
is low proﬁ le and unobtrusive. 
 Like other ﬂ oor-mounted methods, this system is limited to record-
ing small ensembles or soloists. It also could be used on a piano lid. No 
microphones are made this way; you must set a bidirectional microphone 
over a boundary microphone to form the array. 
 Techniques Using Raised Boundary Mics 
 If you mount two omni mic capsules on boundaries, such as panels or a 
sphere, the mics become directional. You can raise the panel or sphere sev-
eral feet off the ﬂ oor to record large ensembles in stereo. We will describe 
two mics of this type. 
 The Stereo Ambient Sampling System (SASS™) 
 No longer in production, the SASS was a stereo condenser microphone 
using boundary-microphone technology (Bartlett, 1989; Billingsley, 1987, 
1989a, 1989b, 1989c). It was designed to give sharp stereo imaging for loud-
speaker or headphone reproduction. The device was a mono-compatible, 
near-coincident array. According to soundmixer Gary Pillon, a stereo ambi-
ent sampling system (SASS) mounted on a Steadicam platform gives an 
excellent match between audio and video perspectives. 
 The SASS used two PZMs mounted on boundaries to make each 
microphone directional (as shown in  Figure C-3 ). 

254
Stereo Boundary-Microphone Arrays
   For each channel, an omni mic capsule is mounted very near a 5-inch 
square boundary. The two boundaries are angled left and right of cen-
ter. The sound diffraction of each boundary, along with a foam barrier 
between the capsules, creates a directional polar pattern at high frequen-
cies. The patterns aim left and right of center, much like a near-coincident 
array. The capsules are “ear-spaced” 17 cm (6.7 inches) apart. 
 The polar patterns of the boundaries and the spacing between cap-
sules have been chosen to provide natural perceived stereo imaging. Like 
an artiﬁ cial head (described in Appendix D), the SASS localizes images by 
time and spectral differences between channels. 
 The foam barrier or bafﬂ e between the capsules limits acoustic 
crosstalk between the two sides at higher frequencies. Although the 
microphone capsules are spaced apart, little phase cancellation occurs 
when both channels are combined to mono because of the shadowing 
effect of the bafﬂ e. That is, despite phase differences between channels, 
the extreme amplitude differences (caused by the bafﬂ e) reduce phase 
cancellations in mono. 
 Application notes for the SASS are given in Bartlett (1989) and Billingsley 
(1987, 1989a, 1989b, 1989c, 1990). 
Figure C-3 Crown SASS-P MKII PZM stereo microphone (courtesy: Crown 
International, Inc.).

255
Stereo Boundary-Microphone Arrays C
 Sphere Microphone 
 A sphere microphone uses a hard globe 8 inches in diameter, with a pair 
of pressure-response omni mic capsules ﬂ ush-mounted in either side, 
180° apart. An example is the Schoeps KFM 6. 
 A spherical stereo mic uses time and spectral differences between 
channels to create stereo images. A circuit corrects the frequency response 
and phase response of the capsules in the sphere. 
 Claimed beneﬁ ts are accurate and sharp imaging, excellent repro-
duction of depth, extended low-frequency response, and low pickup of 
wind and vibration. The sphere shape is used because it provides the least 
diffraction (disturbance of the sound ﬁ eld). As a result, the frequency 
response is ﬂ at not only for sounds in front of the sphere but also for 
reverberant, diffuse sound.  Play Website track 17 to hear the stereo imaging of 
a sphere microphone. It is two mini omni mics taped to either side of a head-size 
sphere. 
 The mic is largely mono-compatible because, in the bass frequencies, 
phase shift is small; and, in the high frequencies, the acoustic shadow of 
the sphere produces strong interchannel differences making phase cancel-
lations less probable. 
 A sphere mic is not the same as a dummy head. Sphere-mic record-
ings are for speaker listening; dummy-head recordings are for headphone 
listening. 
 References 
 Bartlett, B.  Crown Boundary Microphone Application Guide.  Elkhart, IN: Crown 
International, 1999. Billingsley, M. US Patent 4,658,931 (April 21, 1987).  
http://www.crownaudio.com
 Bartlett, B. “An Improved Stereo Microphone Array Using Boundary Tech-
nology: Theoretical Aspects.” Preprint No. 2788 (A-1), paper presented 
at the Audio Engineering Society 86th Convention, March 7–10, 1989, 
Hamburg. 
Billingsley, M. US Patent 4,658,931 (April 21, 1987).
 Billingsley, M. “Practical Field Recording Applications for an Improved Stereo 
Microphone Array Using Boundary Technology.” Preprint No. 2788 (A-1), 
paper presented at the Audio Engineering Society 86th Convention, March 
7–10, 1989a, Hamburg. 
 Billingsley, M. “An Improved Stereo Microphone Array for Pop Music Recording.” 
Preprint No. 2791 (A-2), paper presented at the Audio Engineering Society 
86th Convention, March 7–10, 1989b, Hamburg. 

256
Stereo Boundary-Microphone Arrays
 Billingsley, M. “A Stereo Microphone for Contemporary Recording.”  Recording 
Engineer/Producer (November 1989c). 
 Billingsley, M. “Theory and Application of a New Near-Coincident Stereo Micro-
phone Array for Soundtrack, Special Effects and Ambience.” Paper presented 
at the Audio Engineering Society 89th Convention, September 21–25, 1990, 
Los Angeles. 
 Bruck, J. “The Boundary Layer Mid/Side (M/S) Microphone: A New Tool.” Pre-
print No. 2313 (C-11), paper presented at the Audio Engineering Society 79th 
Convention, October 12–16, 1985, New York. 
 Josephson Engineering.  Catalog. San Jose, CA: Josephson Engineering, 1988. 

257
 D 
BINAURAL TECHNIQUES 
 This appendix covers binaural recording with an artiﬁ cial (dummy) head. 
The head contains a microphone ﬂ ush-mounted in each ear. You record 
with these microphones and play back the recording over headphones. 
This process can re-create the locations of the original performers and 
their acoustic environment with exciting realism. 
 You can substitute your own head for the artiﬁ cial head by placing 
miniature condenser microphones in your ears, or on your temples, and 
recording with them. Some podcasts are made this way. 
 Thanks to the popularity of MP3 players with earphones, many people 
have the opportunity to hear binaural recordings. 
 Binaural Recording and the Artificial Head 
 Binaural (two-ear) recording starts with an artiﬁ cial head or dummy 
head. This is a model of a human head with a ﬂ ush-mounted microphone 
in each ear ( Figure D-1 ). These microphones capture the sound arriving 
at each ear. The microphones’ signals are recorded. When this recording 
is played back over headphones, your ears hear the signals that originally 
appeared at the dummy head’s ears ( Figure D-2 ). That is, the original 
sound at each ear is reproduced (Geil, 1979; Genuit and Bray, 1989; Peus, 
1989; Sunier, 1989a, 1989b, 1989c). 

Figure D-1 A dummy head used for binaural recording (courtesy: Neumann USA).
Figure D-2 Binaural recording and headphone playback.

259
Binaural Techniques D
 Binaural recording works on the following premise. When we lis-
ten to a natural sound source in any direction, the input to our ears is 
just two one-dimensional signals: the sound pressures at the eardrums. If 
we can re-create the same pressures at the listener’s eardrums as would 
have occurred “live,” we can reproduce the original listening experience, 
including directional information and reverberation (Moller, 1989). 
 Binaural recording with headphone playback is the most spatially 
accurate method now known. The re-creation of sound-source locations 
and room ambience is startling. Often, sounds can be reproduced all 
around your head—in front, behind, above, below, and so on. You may 
be fooled into thinking that you’re hearing a real instrument playing in 
your listening room. To see some articles on binaural recording, Google 
“binaural John Sunier.” Sunier is a binaural expert. Samples can be heard 
here: https://soundcloud.com/groups/binaural-recording. 
 As for drawbacks: the artiﬁ cial head is conspicuous, which limits its 
use for recording live concerts; it is not mono-compatible; and it is rela-
tively expensive. Some sources for dummy heads are given in  Chapter 12  
under the heading “Dummy Heads and Headworn Binaural Mics.” 
 How It Works 
 An artiﬁ cial head picks up sound as a human head does. The head is an 
obstacle to sound waves at middle to high frequencies. On the side of the 
head away from the sound source, the ear is in a sonic shadow: the head 
blocks high frequencies. In contrast, on the side of the head toward the 
source, there is a pressure buildup (a rise in the frequency response) at 
middle to high frequencies. 
 The folds in the pinna (outer ear) also affect the frequency response 
by reﬂ ecting sounds into the ear canal. These reﬂ ections combine with the 
direct sound, causing phase cancellations (dips in the response) at certain 
frequencies. 
 The human eardrum is inside the ear canal, which is a resonant tube. 
The ear canal’s resonance does not change with sound-source direction, 
so the ear canal supplies no localization cues. For this reason, it is omitted 
in most artiﬁ cial heads. Typically, the microphone diaphragm is mounted 
nearly ﬂ ush with the head, 4 mm (0.16 in) inside the ear canal. 
 To summarize: the head and outer ear cause peaks and dips in the 
frequency response of the sound received. These peaks and dips vary 
with the angle of sound incidence; they vary with the sound-source loca-
tion. The frequency response of an artiﬁ cial head is different in different 

260
Binaural Techniques
directions. In short, the head and outer ear act as a direction-
dependent equalizer. 
 Each ear picks up a different spectrum of amplitude and phase 
because one ear is shadowed by the head and the ears are spaced apart. 
These interaural differences vary with the source location around 
the head. 
 When the signals from the dummy-head microphones are repro-
duced over headphones, you hear the same interaural differences that the 
dummy head picked up. This creates the illusion of images located where 
the original sources were. 
 Physically, an artiﬁ cial head is a near-coincident array using bound-
ary microphones: the head is the boundary, and the microphones are 
ﬂ ush-mounted in this boundary. The head and outer ears create direc-
tional patterns that vary with frequency. The head spaces the micro-
phones about 6 1/2 inches apart. Some dummy heads include shoulders 
or a torso, which aids front/back localization in human listening but can 
degrade it in binaural recording and playback (Griesinger, 1989). 
 The microphones in a near-coincident array are directional at all 
frequencies and use no bafﬂ e between them. In contrast, the mics in an 
artiﬁ cial head are omni at low frequencies and unidirectional at high fre-
quencies (due to the head bafﬂ e effect). 
 Ideally, the artiﬁ cial head is as solid as a human head, to attenuate 
sound passing through it (Sunier, 1989c). For example, the Head Acous-
tics artiﬁ cial head is made of molded, dense ﬁ berglass (Genuit and Bray, 
1989). In contrast, the Sonic Studios GUY and LiteGUY artiﬁ cial heads are 
made of absorbent Sorbothane. 
 As we said, you can substitute your own head for the artiﬁ cial head 
by placing miniature condenser microphones in your ears and recording 
with them. The more that a dummy head and ears are shaped like your 
particular head and ears, the better the reproduced imaging. Thus, if you 
record binaurally with your own head, you might experience more pre-
cise imaging than you would if you recorded with a dummy head. This 
recording will have a nonﬂ at response because of head diffraction (which 
I will explain later). 
 Core Sound (www.core-sound.com) is the world’s largest manufac-
turer of binaural microphones. The company offers miniature omni con-
denser mics that can be clipped onto eyeglass earpieces. These mics make 
excellent binaural recordings. Sonic Studios (www.sonicstudios.com) has 
a similar product, DSM (Dimensional Stereo Microphones), that are worn 
on the temples rather than in the ear. Based on the head-related transfer 

261
Binaural Techniques D
function (HRTF), DSM mics are said to provide better stereo over loud-
speakers than binaural mics can provide. HRTF is the effect of the head 
on the frequency response and phase response of a sound coming from a 
particular direction. 
 Another substitute for a dummy head is a head-size sphere with 
ﬂ ush-mounted microphones where the ears would be. This system, 
called the  Kugelﬂ achenmikrofon,  was developed by Gunther Theile for 
improved imaging over loudspeakers (Griesinger, 1989). See Appendix C 
under the heading “Sphere Microphones.”  Website track 17 demonstrates 
the stereo imaging of a sphere microphone. Listen to it over headphones as well 
as loudspeakers. 
 Some websites of commercial products are listed in  Chapter 12  under 
the headings “Dummy Heads and Headworn Binaural Mics” and “Stereo 
Microphones.” 
 In-Head Localization 
 You might hear the binaural images inside your head, rather than outside. 
One reason has to do with head movements. When you listen to a sound 
source that is outside your head and move your head slightly, you hear 
small changes in the arrival-time differences at your ears. This is a cue 
to the brain that the source is outside your head. Small movements of 
your head help to externalize sound sources. But headphones lack this 
cue because the images move with your head motion. 
 Headphones with head-tracking sensors can make the images appear 
to be stationary when you turn your head, resulting in very realistic out-
of-head localization. See http://www.sony.net/Products/vpt/tech/. 
 Another reason for in-head localization is that the conch resonance 
of the pinna is disturbed by most headphones. The conch is the large cav-
ity in the pinna just outside the ear canal. If you equalize the headphone 
signal to restore the conch resonance, you hear images somewhat outside 
the head (Cooper and Bauck, 1989). 
 Artificial-Head Equalization 
 An artiﬁ cial head (or a human head) has a nonﬂ at frequency response due 
to the head’s diffraction, the disturbance of a sound ﬁ eld by an obstacle. 
The diffraction of the head and pinnae creates a very rough frequency 
response, generally with a big peak around 3 kHz for frontal sounds. 
Therefore, binaural recordings sound tonally colored unless custom 

262
Binaural Techniques
equalization is used. Some artiﬁ cial heads have built-in equalization that 
compensates for the effect of the head. 
 What is the best equalization for an artiﬁ cial head to make it sound 
tonally like a conventional ﬂ at-response microphone? Several equaliza-
tion schemes have been proposed: 
 •  Diffuse-ﬁ eld equalization:  This compensates for the head’s average 
response to sounds arriving from all directions (such as reverberation 
in a concert hall). 
 •  Frontal free-ﬁ eld equalization:  This compensates for the head’s response 
to a sound source directly in front, in anechoic conditions. 
 •  10 ° averaged, free-ﬁ eld equalization:  This compensates for the head’s 
response to a sound source in anechoic conditions, averaged over 
± 10° off-center. 
 •  Free ﬁ eld with source at  ±  30 ° equalization:  This compensates for the 
head’s response to a sound source 30° off-center, in anechoic condi-
tions. This is a typical stereo loudspeaker location. 
 The Neumann KU-100 and KEMAR artiﬁ cial heads use diffuse-ﬁ eld 
equalization, which Theile also recommends. However, Griesinger 
(1989) found that the Neumann head needed additional equalization 
to sound like a Calrec SoundField microphone: approximately 7 dB 
at 3 kHz and 4 dB at 15 kHz. He prefers either this equalization or a 
10° averaged free-ﬁ eld response for artiﬁ cial heads. The Head Acoustics 
head, developed by Gierlich and Genuit, is equalized ﬂ at for free-ﬁ eld 
sounds in front (Genuit and Bray, 1989), while Cooper and Bauck (1989) 
recommend that artiﬁ cial heads be equalized ﬂ at for free-ﬁ eld sounds 
at ± 30°. 
 To provide a net ﬂ at response from microphone to listener, the artiﬁ cial-
head equalization should be the inverse of the headphone frequency 
response. If the dummy head is equalized with a dip around 3 kHz to yield a 
net ﬂ at response, the headphones should have a mirror-image peak around 
3 kHz (most do). 
 Artificial-Head Imaging with Loudspeakers 
 How does an artiﬁ cial-head recording sound when reproduced over loud-
speakers? According to Griesinger (1989), it can sound just as good as an 
ordinary stereo recording, with superior reproduction of location, height, 
depth, and hall ambience. But it sounds even better over headphones. 

263
Binaural Techniques D
Images in binaural recordings are mainly up front when you listen with 
speakers but are all around when you listen with headphones. 
 Genuit and Bray (1989) report that more reverberation is heard over 
speakers than over headphones, due to a phenomenon called  binaural 
reverberance suppression.  For this reason, it is important to monitor artiﬁ cial-
head recordings with headphones and speakers. 
 Griesinger notes that a dummy head must be placed relatively close 
to the musical ensemble to yield an adequate ratio of direct-to-reverberant 
sound over loudspeakers. This placement yields exaggerated stereo sepa-
ration with a hole in the middle. However, the center image can be made 
more solid by boosting in the presence range (see Griesinger’s, 1989, rec-
ommended equalization previously). 
 Although a dummy-head binaural recording can provide excellent 
imaging over headphones, it produces inadequate spaciousness at low 
frequencies over loudspeakers (Huggonet and Jouhaneau, 1987) unless 
spatial equalization is used (Griesinger, 1989). Spatial equalization was 
discussed in Appendix B under the heading “Coincident Systems with 
Spatial Equalization (Shufﬂ er Circuit).” A low-frequency boost in the  L −  R 
difference signal of about 15 dB at 40 Hz and 1 dB at 400 Hz can improve 
the low-frequency separation over speakers. 
 References 
 Cooper, D. and Bauck, J. “Prospects for Transaural Recording.”  Journal of the Audio 
Engineering Society, Vol. 37, No. 1/2 (January–February 1989), pp. 3–19. 
 Geil, F. “Experiments with Binaural Recording.”  db (June 1979), pp. 30–35. 
 Genuit, K. and Bray, W. “The Aachen Head System: Binaural Recording for Head-
phones and Speakers.”  Audio  (December 1989), pp. 58–66. 
 Griesinger, D. “Equalization and Spatial Equalization of Dummy Head Record-
ings for Loudspeaker Reproduction.”  Journal of the Audio Engineering Society, 
Vol. 37, No. 1/2 (January–February 1989), pp. 20–29. 
 Huggonet, C. and Jouhaneau, J. “Comparative Spatial Transfer Function of Six Differ-
ent Stereophonic Systems.” Preprint No. 2465 (H5), paper presented at the Audio 
Engineering Society 82nd Convention, March 10–13, 1987, London, p. 16, Fig. 13. 
 Moller, H. “Reproduction of Artiﬁ cial-Head Recordings through Loudspeakers.” 
 Journal of the Audio Engineering Society,  Vol. 37, No. 1/2 (January–February 
1989), pp. 30–33. 
 Peus, S. “Development of a New Studio Artiﬁ cial Head.”  db  (June 1989), pp. 34–36. 
 Sunier, J. “A History of Binaural Sound.”  Audio (March 1989a), pp. 312–346. 
 Sunier, J. “Binaural Overview: Ears Where the Mics Are, Part 1.”  Audio (November 
1989b), pp. 75–84. 

264
Binaural Techniques
 Sunier, J. “Binaural Overview: Ears Where the Mics Are, Part 2.”  Audio (December 
1989c), pp. 48–57. 
 Several papers on binaural sound were presented at the 89th Convention of 
the Audio Engineering Society, September 21–25, 1990, Los Angeles. These 
papers are: 
 “Subjective Evaluation of Spatial Image Formation Processors,” Elizabeth A. 
Cohen and Charles M. Salter Associates, Inc., San Francisco, CA. 
 “A New Method for Spatial Enhancement in Stereo and Surround Recording,” 
Dr. Wieslaw R. Woszczyk, McGill University, Montreal, Canada. 
 “Multi-Channel Sound in the Home: Further Developments of Stereophony,” 
Gunther Theile, Institut fur Rundfunktechnik, GmbH, Munich, Germany. 
 “Development and Use of Binaural Recording Technology,” W. Bray, K. Genuit, 
and H. W. Gierlich, Jaffe Acoustics, Norwalk, CT. 
 “Spaciousness Enhancement of Stereo Reproduction Using Spectral Stereo Tech-
niques,” D. J. Furlong and A. G. Garvey, Preprint 3007. 
 “An Intuitive View of Coincident Stereo Microphones,” S. Julstrom, Preprint 
2984. 
 More-recent Audio Engineering Society preprints: 
 “Investigations on a New Reproduction Procedure for Binaural Recordings,” 
Ning Xiang, Klaus Genuit, and Hans W. Gierlich, Head Acoustics, Herzo-
genrath, Germany, #3732, October 1993. 
 “Temporal Localization Cues and Their Role in Auditory Perception,” Martin D. 
Wilde, Wilde Acoustics, Chicago, IL, #3708, October 1993. 
 “Early Reﬂ ections and Reverberant Field Distribution in Dual Microphone Ste-
reophonic Sound Recording Systems,” Michael Williams, Paris, France, #3155 
(R4), October 1991. 
 “Binaural Record/Reproduction Systems and Their Use in Psychoacoustic 
Investigations,” Floyd E. Toole, National Research Council Canada, Ottawa, 
Ontario, #3179 (L6), October 1991. 
 “Development and Use of Binaural Recording Techniques,” K. Genuit, H. W. 
Gierlich, and Wade Bray, HEAD Acoustics, Aachen, Germany, Norwalk, CT, 
#2950, September 1990. 
 “Further Developments of Loudspeaker Stereophony,” Gunther Theile, Institut 
fur Rundfunktechnik GmbH, Munich, Germany, #2947, September 1990. 
 “Microphone Arrays Optimized for Music Recording,” W. Woszczyk, McGill 
University, #3255, March 1992. 
 “Frequency Dependent Hybrid Microphone Arrays for Stereophonic Sound 
Recording,” Michael Williams, Paris, France, #3252, March 1992. 
 “Standard Stereo Recording Techniques in Non-Standard Situations,” Albert G. 
Swanson, Location Recording, Seattle, #3313, March 1992. 

265
Binaural Techniques D
 “Improved Externalization and Frontal Perception of Headphone Signals,” Soren 
Gert Weinrich, Oticon A/S Research Unit, Snekkersten, Denmark, #3291, 
March 1992. 
 “BAP Binaural Audio Processor,” F. Richter, AKG Acoustics, #3323, March 1992. 
 “Transfer Characteristics of Headphones,” Henrik Moller et al., Institute for Elec-
tronic Systems, #3290, March 1992. 
 “Improved Possibilities of Binaural Recording and Playback Techniques,” K. Genuit 
et al., HEAD Acoustics, Herzogenrath, Germany, #3332, March 1992. 
 “Applications of Blumlein Shufﬂ ing to Stereo Microphone Techniques,” Michael 
Gerzon, Oxford, UK, #3448 (S-1), October 1992. 
 Preprints can be ordered from the Audio Engineering Society, www.aes.org. 
 More articles in the  Journal of the Audio Engineering Society: 
 “Measuring a Dummy Head in Search of Pinna Cues,” H. L. Han, January–February 
1994. 
 “Binaural Technique: Do We Need Individual Recordings?” Henrik Moller et al., 
Acoustics Laboratory, Aalborg University, Aalborg, Denmark, June 1996. 
 “Comments on ‘Spaciousness and Localization in Listening Rooms and Their 
Effects on the Recording Technique’,” Stanley Lipshitz, Audio Research 
Group, University of Waterloo, Waterloo, Ont., Canada, December 1987. 
 “The Effect of Head Shape on Spectral Stereo Theory,” K. Rasmussen and P. Juhl, 
Acoustics Laboratory, Technical University of Denmark, Denmark, March 
1993. 
 “On the Naturalness of Two-Channel Stereo Sound,” Gunther Theile, Institut fur 
Rundfunktechnik GmbH, Munich, Germany, October 1991. 
 “A Computer Model of Binaural Localization for Stereo Imaging Measurement,” 
E. Macpherson, Audio Research Group, University of Waterloo, Waterloo, 
Ont., Canada, September 1991. 
 “Room-Related Balancing Technique: A Method for Optimizing Recording Quality,” 
M. Wohr, G. Theile, H. Goeres, and A. Persterer, September 1991. 

This page intentionally left blank

267
 E 
SURROUND-SOUND 
MIKING TECHNIQUES 
 So far we’ve examined two-channel stereo recording techniques. These 
methods reproduce the instruments and hall reverb in front of the listener, 
in the area between the two loudspeakers. In contrast, surround-sound 
places audio images around the listener. The musical ensemble is usually 
up front, and the hall ambience is all around. 
 Stereo uses two channels feeding two loudspeakers. Surround sound 
uses multiple channels feeding multiple speakers. 
 Surround gives a wonderfully spacious effect. It puts you inside 
the concert hall with the musicians. You and the music occupy the same 
space—you’re part of the performance. For this reason, surround is more 
musically involving, more emotionally intense, than regular stereo. 
 Here are the basic steps to create a surround recording: 
 1. Set up four or ﬁ ve mics in a surround array (described later in this chap-
ter) and plug them into mic preamps, an audio interface, or a mixer. 
 2. Record the ampliﬁ ed mic signals onto a multitrack recorder. 
 3. Master a surround DVD from the four or ﬁ ve channels. You need DVD-
Audio authoring software, a DVD-R recorder, and blank DVD discs. 
One example of authoring software is at www.audio -dvd-creator.com. 
 4. Alternatively, master the surround recordings on a DVD video disc. 

268
Surround-Sound Miking Techniques
 Surround Speaker Arrangement 
 In a technique inherited from the ﬁ lm industry, 5.1 surround-sound 
uses six channels feeding six speakers placed around the listener. This 
forms a 5.1 surround system, where the “point 1” is the subwoofer or 
low-frequency effects (LFE) channel. The LFE channel is band-limited to 
120 Hz and below. 
 The six speakers are: 
 • left front 
 • center 
 • right front 
 • left surround 
 • right surround 
 • subwoofer. 
  Figure E-1 shows the recommended placement of monitor speakers for 5.1 
surround sound. It is the standard setup proposed by the International 
Telecommunication Union (ITU). From the center speaker, the left and right 
speakers should be placed at ± 30°, and the surrounds at ± 110°. 
   The left- and right-front speakers provide regular stereo. The surrounds 
provide a sense of envelopment due to room ambience. They also allow 
Figure E-1 Recommended placement of monitor speakers for 5.1 surround sound.

269
Surround-Sound Miking Techniques E
sound images to appear behind the listener. Deep bass is ﬁ lled in by the sub-
woofer. Because we do not localize low frequencies below about 120 Hz, the 
sub can be placed almost anywhere without degrading localization. 
 In a system originally developed for theaters, the center-channel 
speaker is mounted directly in front of the listener. In a home-theater sys-
tem, it is placed just above the TV screen, or just below and in front of the 
TV screen. This speaker plays center-channel information in mono, such 
as dialog. 
 Why use a center speaker, when two stereo speakers create a phan-
tom center image? If you use only two speakers and you sit off-center, 
the phantom image shifts toward the side on which you’re sitting. But a 
center-channel speaker produces a real image, which does not shift as you 
move around the listening area. 
 Also, the phantom center image does not have a ﬂ at frequency 
response, but a center speaker does. Why is this? Remember that a center 
image results when you feed identical signals to both stereo speakers. The 
right-speaker signal reaches your right ear, but so does the left-speaker 
signal after a delay around your head. The same thing occurs symmetri-
cally at your left ear. Each ear receives direct and delayed signals, which 
interfere and cause phase cancellations at 2 kHz and above. A center-
channel speaker does not have this response anomaly. 
 With a phantom center image, the response is weak at 2 kHz because 
of the phase cancellation just mentioned. To compensate, recording 
engineers often choose mics with a presence peak in the upper mid-
range for vocal recording. The center-channel speaker does not need 
this compensation. 
 For sharpest imaging and continuity of the soundﬁ eld, all the speakers 
should be: 
 • the same distance from the listener 
 • the same model (except the sub) 
 • the same polarity 
 • direct-radiator types 
 • driven with identical power amps 
 • matched in sound pressure level with pink noise. 
 Typically the speakers are 4–8 feet from the listener and 4 feet high. Use a 
length of string to place the monitors the same distance from your head. 
The sub can go along the front wall on the ﬂ oor. 

270
Surround-Sound Miking Techniques
 Be sure that all the speakers sound the same so there is no change in 
tonal balance as you pan images around. 
 Surround-Sound Mic Techniques 
 You can record classical music in surround using four or ﬁ ve microphones, 
which capture the three-dimensional spatial character of the concert hall 
in which the musical ensemble is playing. Each mic feeds a separate track 
of a multitrack recorder. 
 Surround mic techniques are somewhat different from stereo mic 
techniques. In addition to the usual front-left and -right mics, you need 
two surround mics to pick up the hall ambience and a center mic to feed 
to the center channel. You don’t need a subwoofer channel with this type 
of recording. Note that listening in surround reduces the stereo separa-
tion (stage width) because of the center speaker, but mic techniques for 
surround are optimized to counteract this effect. 
 A number of mic techniques have been developed for recording in 
surround. Let’s take a look at them. 
 SoundField 5.1 Microphone System 
 This system is a single, multiple-capsule microphone and SoundField 
Surround Decoder for recording in surround. The decoder translates the 
mic’s B-format signals (X, Y, Z, and W) into L, C, R, LR, RR, and mono 
subwoofer outputs. For details, see www.soundﬁ eld.com . 
 Delos VR 2 Surround Miking Method 
 John Eargle, Delos’s past director of recording, developed Delos’s VR 2 
(Virtual Reality Recording) format. 
 In making these recordings, Eargle typically used the mic placement 
shown in  Figure E-2 . This method employs an Ofﬁ ce de Radiodiffusion 
Télévision Française (ORTF) pair in the center, ﬂ anked by two spaced 
omnis typically 12 feet apart. Two house mics (to pick up hall reverb) are 
placed about 23–52 feet behind the main pair. These house mics are car-
dioids aiming at the upper rear corners of the hall, spaced about 12 feet 
apart and about 30 feet high. Spot mics (accent mics) are placed within the 
orchestra to add deﬁ nition to certain instruments. 

271
Surround-Sound Miking Techniques E
 The mics are assigned to various tracks of a digital multitrack recorder: 
 • 1 and 2: A mix of the ORTF-pair mics, ﬂ anking mics, house mics, and 
spot mics 
 • 3 and 4: ORTF-pair mics 
 • 5 and 6: Flanking mics 
 • 7 and 8: House mics (surround mics). 
 NHK Methods 
 Sanken and NHK show a wide variety of surround techniques at this 
website: www.sanken-mic.com/en/qanda .  One example is shown in 
 Figure E-3 . 
 KFM 360 Surround Miking System 
 Jerry Bruck of Posthorn Recordings developed this elegant surround mik-
ing method. It is a form of the mid–side (MS) stereo technique. 
 Bruck starts with a modiﬁ ed Schoeps KFM 6 stereo microphone, 
which is a pair of omni mics mounted on opposite sides of a 7-inch hard 
Figure E-2 A Delos surround miking method.

272
Surround-Sound Miking Techniques
sphere. Next to those mics, nearly touching, are two ﬁ gure-eight mics, one 
on each side of the sphere, each aiming front and back ( Figure E-4 ). This 
array creates two MS mic arrays aimed sideways in opposite directions. 
The mics do not seriously degrade one another’s frequency response. 
   In the left channel, the omni and ﬁ gure-eight mic signals are summed 
to give a front-facing cardioid pattern. They are also differenced to give 
a rear-facing cardioid pattern. The same thing happens symmetrically in 
the right channel. The sphere, acting as a boundary and a bafﬂ e, “steers” 
the cardioid patterns off to either side of center and makes their polar pat-
terns irregular. 
 By adjusting the relative levels of the front and back signals, the user 
can control the front/back separation. As a result, the mic sounds like it is 
moving closer to or farther from the musical ensemble. 
Figure E-3 An NHK surround-sound miking method.
Figure E-4 The KFM 360 surround miking system.

273
Surround-Sound Miking Techniques E
 According to Bruck: “The system is revelatory in its ability to recre-
ate a live event. Perhaps most remarkable is the freedom a listener has to 
move around and select a favored position, as one might move around in 
a concert hall to select a preferred seat. The image remains stable, without 
a discernible ‘sweet spot.’ The reproduction is unobtrusively natural and 
convincing in its sense of ‘being there.’” 
 The four mic signals can be recorded on a four-track recorder for 
later matrixing. The ﬁ gure-eight mics need some equalization (EQ) to 
compensate for their low-frequency rolloff and loss in the extreme highs. 
To maintain a good signal-to-noise ratio, this EQ can be applied after the 
signal is digitized. 
 DMP Method 
 DMP engineer Tom Jung has recorded in surround using a Decca Tree 
stereo array for the band and a rear-aiming stereo pair for the surround 
ambience ( Figure E-5 ). Spot mics in the band complete the miking. The 
Decca Tree uses three omni mics spaced a few feet apart, with the center 
mic placed slightly closer to the performers. It feeds the center channel in 
the 5.1 system. 
   The rear-aiming mics are either a coincident stereo mic, another 
Decca tree, or a spaced pair whose spacing matches that of the Decca tree 
outer pair. Jung tries to aim the rear mics at irregular surfaces to pick up 
diffuse sound reﬂ ections. 
Figure E-5 A DMP surround miking method.

274
Surround-Sound Miking Techniques
 Williams Five Cardioid Mic Array 
 Michael Williams, an independent audio consultant, worked out the 
math to determine the best cardioid microphone arrangement for real-
istic reproduction of surround-sound ﬁ elds. His method is shown in 
 Figure E-6 . 
 Double MS Technique 
 Developed by Curt Wittig and Neil Muncy, the double MS technique uses 
a front-facing MS mic pair for direct sound pickup and a rear MS pair 
facing away from the front ( Figure E-7 ). The rear pair is placed at or just 
beyond the critical distance of the room, where the reverberant-sound 
Figure E-6 The Williams ﬁ ve cardioid mic array (MMA or Multichannel Micro-
phone Array).
Figure E-7 The double MS technique.

275
Surround-Sound Miking Techniques E
level equals the direct-sound level. The matrixed outputs feed front-left, 
front-right, rear-left, and rear-right speakers. No center channel mic is 
speciﬁ ed, but you could use the front-facing cardioid mic of the front MS 
pair for this purpose. 
 Surround Ambience Microphone Array 
 Surround Ambience Microphone (SAM) array was developed by Gun-
ther Theile of the Institute für Rundfunktechnik (IRT). Four cardioid mics 
are placed at 90° to each other and 21–25 cm apart. No center channel is 
described. 
 Chris Burmajster Array 
 Based on extensive listening tests, this array was invented by Chris 
Burmajster of Innocent Ear Ltd. It includes an ORTF pair for left- and 
right-front channels, a center mic, and two rear-facing cardioids angled 
90° for the left- and right-rear channels. The mics are mounted on the 
metal bar shown in  Figure E-8  (not commercially available). According 
27 cm
30 cm
LF
RF
LR
RR
Center
LF and RF are ORTF.  Center mic hangs downward from bar.
LR and RR are rear-facing cardioids angled 90°.
(11.8 in)
(11.8 in)
30 cm
17 cm (6.7 in)
Hole for
mic stand
(10.6 in)
Holes contain mounts for side-addressed mics.
Figure E-8 Mounting bar for Burmajster surround array.

276
Surround-Sound Miking Techniques
to the inventor, this arrangement provides solid central imaging. The rear 
ambience channels sound coherent with the front channels, rather than 
“disjointed” as can happen with mics far back in the hall. Details are at 
 http://homepage.ntlworld.com/chris.burmajster. 
 Ideal Cardioid Arrangement 
 This system uses a special mic mount with ﬁ ve arms that radiate out from 
a center point, like a star. At the end of each arm is a condenser mic aiming 
outward from the center. An example is the Microtech Gefell INA 5, which 
uses ﬁ ve M930 mics in shock mounts (www.microtechgefell.de). It uses 
the Ideal Cardioid Arrangement (ICA 5, ITU-775 speciﬁ cation,  Figure E-9 ) 
developed by Volker Henkels and Ulf Herrmann. 
 Holophone H2-PRO Surround Mic 
 This is a surround microphone using several omni mic capsules ﬂ ush-
mounted in a football-shaped surface (see Figure 11-6). It captures up to 
eight channels of discrete surround sound and has eight XLR connectors 
(www.holophone.com). 
 Sonic Studios DSM-4CS Four-Channel 
Surround Dummy Head 
 The Sonic Studios website (www.sonicstudios.com) offers a four-mic 
array to record in surround that you can put on your head or on their 
LiteGuy HTRF mic bafﬂ e. 
Figure E-9 ICA used in the Microtech Gefell INA 5 surround microphone.

277
Surround-Sound Miking Techniques E
 Slotte Method 
 Benedict Slotte developed a surround miking technique intended to pro-
duce very sharp images. The front three mics ( Figure E-10 ) are an opti-
mized near-coincident array using three supercardioid mics. The array 
was designed for minimal crosstalk and time differences between mics. 
The level and time differences between the left-center pair are zero for 
a sound source at the midpoint between them. The same is true for the 
right-center pair. In his Audio Engineering Society (AES) paper (see Rec-
ommended Reading), Slotte lists a range of mic angling, spacing, and 
relative levels that work well. 
 Martin Method 
 Geoff Martin invented a surround technique using two Blumlein pairs: 
one for front left-right and the other for surround left-right ( Figure E-11 ). 
The goal is high interchannel coherence for direct sounds and low inter-
channel coherence for reverberation. Not shown is the center-channel 
mic, a ﬁ gure-eight that is coincident with the front pair. The center mic 
can aim straight down to minimize image distortion, or it can aim for-
ward but located at least 2.4 in (6 cm) below the main pair. Forward 
aiming is recommended if you want a lot of direct sound in the center 
speaker. 
TO MUSICAL ENSEMBLE
FRONT-LEFT
FRONT-RIGHT
CENTER
Three supercardioid mics 
 provide the front signals.
Top view
Figure E-10 The Slotte method.

278
Surround-Sound Miking Techniques
 Stereo Pair plus Surround Pair 
 In this method, the center-channel mic is omitted. You use a standard stereo 
pair of your choice to pick up the musical ensemble, plus another stereo 
pair of your choice to pick up the hall ambience. The hall mics feed the left- 
and right-surround channels. For example, the system might include two 
stereo mics placed back-to-back, separated by several feet. 
 You might try a hybrid approach for a pop-music concert: feed the 
front speakers a mix of multiple close-up mics on stage, and feed the rear 
speakers the signals from a rear-aiming stereo mic. 
 Recommended Reading 
 The website for DPA Microphones has a section called “Microphone University.” 
In this section are several excellent papers on surround microphone tech-
niques, many of which are not covered here. http://www.dpamicrophones.
com/en/Mic-University/Surround%20Techniques.aspx .
Figure E-11 The Martin method.
MUSICAL ENSEMBLE
FRONT PAIR
REAR PAIR
2.3 FEET
OR LESS
TOP VIEW
90
45 - 90
FL
FR
RL
RR

279
Surround-Sound Miking Techniques E
J. Bruck “The Boundary Layer Mid/Side (M/S) Microphone: A New Tool.” Pre-
print No. 2313 (C-11), Paper Presented at the Audio Engineering Society 79th 
Convention, October 12–16, 1985, New York.
 Michael Williams and Guillaume Le Dû. “The Quick Reference Guide to Multi-
channel Microphone Arrays, Part 1: Using Cardioid Microphones.” Preprint 
No. 5336, paper presented at the Audio Engineering Society 110th Convention, 
May 2001. 
 Paul Segar and Francis Rumsey. “Optimisation and Subjective Assessment of 
Surround Sound Microphone Arrays.” Preprint No. 5368, paper presented 
at the Audio Engineering Society 110th Convention, May 2001. 
 Benedict Slotte. “Sharpening the Image in 5.1 Surround Recording.” Preprint 
No. 6509, paper presented at the Audio Engineering Society 118th Conven-
tion, May 2005. 
 Geoff Martin. “A New Microphone Technique for Five-Channel Recording.” 
Preprint No. 6427, paper presented at the Audio Engineering Society 118th 
Convention, May 2005. 

This page intentionally left blank

281
 Thank you to all the manufacturers who sent photographs for this book. 
I greatly appreciate the contributions and advice of reviewers Jim Loomis, 
an instructor at Ithaca College; Bruce Outwin, an instructor at Emerson 
College; Dr. Kevin Daniel Kelleher of Stephen F. Austin State University, 
Adam Lansky of Lansky Sound LLC; Ron Estes of NBC in Burbank and 
Mike Pailthorpe. A special thanks to Sam Kambol for his clever ideas. 
Thanks very much to Megan Turner, Emma Elder, and Meagan White at 
Focal Press for their skillful editorial assistance. 
 Thank you to the publishers who allowed me to use some of my own 
material for this book. Some chapters are reprinted with permission from: 
 MR&M Publishing Corp. and Sagamore Publishing Co., Inc., “Record-
ing Techniques” series by Bruce Bartlett. 
 Radio World, “Stereo Microphone Techniques Part 1,” November 
1989, and “Stereo Microphone Techniques Part 2,” February 1990, by Bruce 
Bartlett. 
 Parts of Appendix C were based on the article by Bruce Bartlett, “An 
Improved Stereo Microphone Array Using Boundary Technology: Theo-
retical Aspects,”  Journal of the Audio Engineering Society,  Vol. 38, No. 7/8, 
(July/August 1990), pp. 543–552. 
 ACKNOWLEDGMENTS 

This page intentionally left blank

283
 A–B  See  Spaced-pair method. Also, an A–B test is a listening comparison 
between two audio programs, or between two components playing the 
same program, performed by switching immediately from one to the other. 
The levels of the two signals are matched. 
 Accent microphone  See Spot microphone. 
 AES67 An audio networking standard intended to make several other 
audio networking standards work with each other. 
 Ambience Room acoustics, early reﬂ ections, and reverberation. Also, 
the audible sense of a room or environment surrounding a recorded 
instrument. 
 Ambience microphone A microphone placed relatively far from its 
sound source to pick up ambience. 
 Amplitude Level, intensity, or magnitude. For a sine wave, the RMS 
(root mean square) amplitude of a sound wave or signal is almost the 
same as the average amplitude. The RMS value is the effective or DC 
equivalent value. The peak amplitude is the voltage of the signal wave-
form peak. The RMS amplitude is 0.707 times the peak amplitude. 
 Analog-to-digital (A/D) converter A circuit that converts an analog signal 
to a digital signal. 
 Antiphase Referring to two identical signals in opposite polarity.  See 
Polarity. 
 Artificial head  See Dummy head. 
 Assign To route or send an audio signal to one or more selected channels. 
 Attenuate To reduce the level of a signal. 
  Audio interface (audio I/O box)  A device with mic and line input connec-
tors, and a USB or FireWire output connector, that converts analog audio 
to digital and sends it to a computer USB or FireWire port for recording. 
 GLOSSARY 

284
Glossary
 Aux bus In a mixing console, the bus that feeds effects devices (signal 
processors) or a monitor power ampliﬁ er. A submixer in a mixing console 
that combines signals from aux sends, and then feeds the mixed signal to 
the input of an effects device. 
 Aux return In the output section of a mixing console, a control that 
adjusts the amount of signal received from an effects unit. Also, the con-
nectors in a mixer to which you connect the effects-unit output signal. 
They might be labeled “bus in” instead. The effects-return signal is mixed 
with the program bus signal. 
 Aux send In each input module of a mixing console, a control that 
adjusts the amount of signal sent to an effects unit or monitor power 
ampliﬁ er. Also, the connectors in a mixer to which you connect the effects-
unit input signal. 
 Aux send master A control that affects the master level of each aux bus. 
 AVB network  Audio Video Bridging, a standard protocol for network-
ing digital audio based on the IEEE 802.1BA standard. 
 Baffled-omni A stereo miking arrangement that uses two ear-spaced 
omnidirectional microphones separated by a hard padded bafﬂ e. 
 Balance The relative volume levels of tracks in a mix or instruments in 
a musical ensemble. 
 Balanced line A cable with two conductors surrounded by a shield, in 
which each conductor is at equal impedance to ground. With respect to 
ground, the conductors are at equal potential but opposite polarity; the 
signal ﬂ ows through both conductors. 
 Binaural recording A two-channel recording made with an omnidirec-
tional microphone mounted in or near each ear of a human or a dummy 
head, for playback over headphones. The object is to duplicate the acoustic 
signal appearing at each ear. 
 Blumlein array A stereo microphone technique in which two coincident 
bidirectional microphones are angled 90° apart (45° to the left and right 
of center). 
 Board  See Mixing console. 
 Boundary microphone A microphone designed to be used on a bound-
ary (a hard reﬂ ective surface). The microphone capsule is mounted very 

285
Glossary
close to the boundary (or ﬂ ush with it), so that direct and reﬂ ected sounds 
arrive at the microphone diaphragm in phase (or nearly so) for all fre-
quencies in the audible band. 
 Bus A common connection of many different signals. An output of a 
mixer or submixer. A channel that feeds a recorder track, signal processor, 
or power ampliﬁ er. 
 Bus in An input to a program bus, usually used for effects returns. 
 Bus master In the output section of a mixing console, a potentiometer 
(fader or volume control) that controls the output level of a bus. 
 Bus out The output connector of a bus. 
 Buzz An unwanted edgy tone that sometimes accompanies audio, con-
taining high harmonics of 60 Hz (50 Hz in the UK and Europe). 
 CardBus A faster version of a PC card, a CardBus card supports computer-
bus mastering, speeds up to 33 MHz, and 32 bits instead of 16 bits.  See 
PCMCIA. 
 Cardioid microphone A unidirectional microphone with side attenua-
tion of 6 dB and maximum rejection of sound at the rear of the microphone 
(180° off axis). A microphone with a heart-shaped directional pattern. 
 Channel A single path of an audio signal. Usually, each channel con-
tains a different signal. 
 Channel assign  See Assign. 
 Clean Free of noise, distortion, overhang, and leakage. Not muddy. 
 Clear Easy to hear, easy to differentiate. Reproduced with sufﬁ cient 
high frequencies and not too much reverberation. 
 Clip (1)  See  Region. (2) To turn up an audio signal so high that the peaks 
of the audio waveform are clipped off, causing distortion. (3) A clip LED 
in a mixer ﬂ ashes to indicate signal clipping. 
 Closely spaced method  See Near coincident. 
 Coincident-pair method A stereo microphone, or two separate micro-
phones, placed so that the microphone diaphragms occupy approximately 
the same point in space. They are angled apart and mounted one directly 
above the other. 

286
Glossary
 Comb-filter effect The frequency response caused by combining a 
sound with its delayed replica. The frequency response has a series of 
peaks and dips caused by phase interference. The peaks and dips resem-
ble the teeth of a comb. This effect can occur with near-coincident and 
spaced-pair techniques when the left- and right-channel signals are com-
bined to mono. 
 Compact flash card A type of ﬂ ash-memory card used to store data, 
such as digital audio recorded by a portable ﬂ ash-memory recorder.  See 
also Flash memory. 
 Compressor A signal processor that reduces dynamic range by means 
of automatic volume control; an ampliﬁ er whose gain decreases as the 
input-signal level increases above a preset point.  See Data Compression. 
 Condenser microphone A microphone that works on the principle of 
variable capacitance to generate an electrical signal. The microphone 
diaphragm and an adjacent metallic disk (called a backplate) are charged 
to form two plates of a capacitor. Incoming sound waves vibrate the dia-
phragm, varying its spacing to the backplate, which varies the capaci-
tance, which in turn varies the voltage between the diaphragm and the 
backplate. 
 Connector A device that makes electrical contact between a signal-
carrying cable and an electronic device, or between two cables. A device 
used to connect or hold together a cable and an electronic component so 
that a signal can ﬂ ow from one to the other. 
 Console  See Mixing console. 
 Contact pickup  See Pickup. 
 Convolution reverb (sampling reverb) A reverberation device or plug-
in that creates the reverb from impulse-response samples (WAV ﬁ les) of 
real acoustic spaces, rather than from algorithms. The resulting sound 
quality is very natural. 
 Crosstalk The unwanted transfer of a signal from one channel to another. 
Head-related crosstalk is the right-speaker signal that reaches the left ear, 
and the left-speaker signal that reaches the right ear. In the transaural 
stereo system, this acoustic crosstalk is canceled by processing the stereo 
signal with electronic crosstalk that is the inverse of the acoustic crosstalk. 
 Dante  An audio networking protocol developed by Audinate. 

287
Glossary
 DAT  A digital audio tape recorder that uses a rotating head to record 
digital audio on tape. Now obsolete. 
 Data compression An algorithm to reduce the ﬁ le size of an audio ﬁ le 
by removing parts of the signal deemed inaudible. The result is an MP3, 
AAC, WMA, Ogg Vorbis, or similar ﬁ le. 
 DAW Abbreviation for digital audio workstation.  See Digital audio 
workstation. 
 dB Abbreviation for decibel.  See Decibel. 
 dBA Decibels, A weighted. 
 dBm Decibels relative to 1 milliwatt. 
 dBu Decibels relative to 0.775 volt. 
 dBV Decibels relative to 1 volt. 
 Dead Having very little or no reverberation. 
 Decay The portion of the envelope of a note in which the envelope 
goes from maximum to some midrange level. Also, the decline in level of 
reverberation over time. 
 Decay time  See Reverberation time. 
 Decibel The unit of measurement of audio level. Ten times the loga-
rithm of the ratio of two power levels. Twenty times the logarithm of the 
ratio of two voltages. A decibel measurement is relative to some other 
level, not an absolute measurement.  See dB. 
 Delay The time interval between a signal and its repetition. A digital 
delay is a signal processor or plug-in that delays a signal for a short 
time. 
 Depth The audible sense of nearness and farness of various instru-
ments. Instruments recorded with a high ratio of direct-to-reverberant 
sound are perceived as being close; instruments recorded with a low ratio 
of direct-to-reverberant sound are perceived as being distant. 
 Design center The portion of fader travel (usually shaded), about 
10–15 dB from the top, in which console gain is distributed for optimum 
headroom and signal-to-noise ratio. During normal operation, master 
faders and group faders should be placed at or near design center. 

288
Glossary
 Designation strip A strip of tape attached near console faders to desig-
nate the instrument that each fader controls. 
 Desk The British term for mixing console. 
 Destructive editing In a digital audio workstation, editing that rewrites 
the data on disk. A destructive edit cannot be undone unless a backup 
copy was made of the data before it was written over. 
 DI Acronym for direct injection, recording with a direct box. 
 Diffuse field A sound ﬁ eld in which the sounds arrive randomly from 
all directions, such as the reverberant ﬁ eld in a concert hall. Diffuse-ﬁ eld 
equalization might be applied to a dummy head so that it has a net ﬂ at 
response in a diffuse sound ﬁ eld. 
 Digigrid  An audio networking protocol that shares DSP processing. 
 Digital audio Encoding an analog audio signal in the form of binary 
digits (ones and zeros). 
 Digital audio workstation (DAW) A system, device, or software that 
allows you to record, edit, and mix audio programs entirely in digital 
form. A computer DAW includes a computer, recording software, and 
sound card or audio interface. It has virtual controls on-screen. A stand-
alone DAW is a digital recorder-mixer with real mixer controls. 
 Digital recording A recording system in which the audio signal is stored 
in the form of binary digits (ones and zeros). 
 Digital-to-analog converter A circuit that converts a digital audio sig-
nal into an analog audio signal. 
 DIN A German standard for a near-coincident stereo microphone tech-
nique in which two cardioid microphones are angled apart 90° and spaced 
20 cm (7.9 in) horizontally. 
 Direct box A device used for connecting an electric musical instrument 
directly to a mixer mic input. The direct box converts a high-impedance 
unbalanced audio signal into a low-impedance balanced audio signal. 
 Direct injection (DI) Recording with a direct box. 
 Directional microphone A microphone that has different sensitivity in 
different directions. A unidirectional or bidirectional microphone. 

289
Glossary
 Direct out In a mixing console, an output connector following a mic 
preampliﬁ er, fader, and equalizer, used to feed the signal of one instru-
ment to one track of a multitrack recorder.  See also Insert jack. 
 Direct sound Sound traveling directly from the sound source to the 
microphone (or to the listener) without reﬂ ections. 
 Distortion An unwanted change in the audio waveform, causing a raspy 
or gritty sound quality. The appearance of frequencies in a device’s output 
signal that were not in the input signal. Distortion is caused by recording at 
too high a level, improper mixer settings, components failing, or overdriving 
an ampliﬁ er. (Distortion can be desirable—for an electric guitar, for example.) 
 Dither Low-level noise added to a digital signal to reduce quantization 
distortion caused by truncating (removing) bits in a digital word. It’s a 
good idea to add dither to a 24-bit program when you convert it to 16 bits 
for CD release. Doing that retains most of the quality of the 24-bit record-
ing after it is converted to 16 bits. 
 Dry Having no echo or reverberation. Referring to a close-sounding sig-
nal that is not yet processed by an effects device or plug-in. 
 DSD Abbreviation for direct stream digital, a Sony and Philips trade-
mark for 1-bit encoding of digital signals used in their Super Audio CD 
format, and used in some Korg handheld recorders. 
 DSP Abbreviation for digital signal processing, modifying a signal in 
digital form. 
 Dummy head A modeled head with microphones in the ears, used for 
binaural recording; same as artiﬁ cial head. 
 DVD Digital versatile disc. A storage medium the size of a compact disc 
that holds much more data. The DVD stores video, audio, or computer data. 
 Dynamic microphone A microphone that generates electricity when 
sound waves cause a conductor to vibrate in a stationary magnetic ﬁ eld. 
The two types of dynamic microphone are moving coil and ribbon. A 
moving-coil microphone is usually called a dynamic microphone.  See 
Moving-coil microphone. 
 Dynamic range The range of volume levels in a program from softest 
to loudest. 

290
Glossary
 Earth ground A connection to moist dirt (the ground we walk on). This 
connection is usually done via a long copper rod. 
 Echo A delayed repetition of a signal or a sound. A sound delayed 
50 milliseconds or more, combined with the original sound. 
 Editing In a DAW, the cutting and rejoining of an audio waveform 
to delete unwanted material, to insert silence, or to rearrange recorded 
material into the desired sequence. 
 Effects Interesting sound phenomena created by signal processors or plug-
ins, such as reverberation, echo, ﬂ anging, doubling, compression, or chorus. 
 Effects loop A set of connectors in a mixer for connecting an external 
effects unit, such as a reverb or delay device. The effects loop includes a 
send section and a return section.  See Aux send, Aux return. 
 Electret-condenser microphone A condenser microphone in which the 
electrostatic ﬁ eld of the capacitor is generated by an electret—a material 
that permanently stores an electrostatic charge. 
 Electrostatic field The force ﬁ eld between two conductors charged with 
static electricity. 
 Electrostatic interference The unwanted presence of an electrostatic 
hum ﬁ eld in signal conductors. 
 Elevation An image displacement in height above the speaker plane. 
 End-addressed Referring to a microphone whose main axis of pickup is 
perpendicular to the front of the microphone. You aim the front of the mic 
at the sound source.  See Side-addressed. 
 Envelope The rise and fall in volume of one note. The envelope con-
nects successive peaks of the waves comprising a note. Each harmonic in 
the note might have a different envelope. 
 Equalization (EQ) The adjustment of frequency response to alter the 
tonal balance or to attenuate unwanted frequencies. 
 Equalizer A circuit and its controls (usually in each input module of a 
mixing console or in a separate unit) that alter the frequency spectrum of 
a signal passed through it. 
 Fade-out To gradually reduce the volume of the last several seconds of 
a recorded song, from full level down to silence, by slowly pulling down 
the master fader. 

291
Glossary
 Fader A linear or sliding potentiometer (volume control), used to adjust 
signal level. 
 Faulkner method Named after Tony Faulkner, a stereo microphone 
technique using two bidirectional microphones aiming at the sound 
source and spaced about 8 inches apart. 
 Feed (1) To send an audio signal to some device or system. (2) An out-
put signal sent to some device or system. 
 Feedback (1) The return of some portion of an output signal to the sys-
tem’s input. (2) The squealing sound you hear when a PA system micro-
phone picks up its own ampliﬁ ed signal through a loudspeaker. 
 Filter A circuit that sharply attenuates frequencies above or below a 
certain frequency. Used to reduce noise and leakage above or below the 
frequency range of an instrument or voice. 
 FireWire A standard protocol and port for high-speed transfer of data 
between digital devices. Also called IEEE 1394. Connects a computer to 
external devices such as MIDI interfaces, memory sticks, memory record-
ers, and audio interfaces. Faster than a standard serial port. 
 Flash memory An erasable, removable computer memory card that can 
store data permanently. SD (Secure Digital) is an example. 
 Float To disconnect from ground. 
 Focus The degree of fusion, compactness, or positional deﬁ nition of a 
sonic image. A sharp image is highly focused and easy to locate. 
 FOH Abbreviation for front-of-house, the location of the sound-
reinforcement mixer in a venue. 
 Free field The sound ﬁ eld coming directly from the sound source with-
out reﬂ ections; the sound ﬁ eld in an anechoic chamber. Free-ﬁ eld equal-
ization can be applied to a dummy head to make it have a net ﬂ at response 
in a free ﬁ eld. 
 Frequency The number of cycles per second of a sound wave or an 
audio signal, measured in hertz (Hz). A low frequency (for example, 
100 Hz) has a low pitch; and a high frequency (for example, 10,000 Hz) 
has a high pitch. 
 Frequency response (1) The range of frequencies that an audio device 
will reproduce at an equal level (within a tolerance, such as ± 3 dB). 
(2) The range of frequencies that a device (mic, human ear, etc.) can detect. 

292
Glossary
 Fundamental The lowest frequency in a complex wave. 
 Fusion The formation of a single image by two or more sound sources, 
such as loudspeakers. 
 Gain Ampliﬁ cation. The ratio, expressed in decibels, between the out-
put voltage and the input voltage, or between the output power and the 
input power. 
 Graphic equalizer An equalizer with a horizontal row of faders; the 
fader-knob positions indicate graphically the frequency response of the 
equalizer. Usually used to equalize monitor speakers for the room they 
are in. Sometimes used for complex EQ of a track. 
 Ground The zero-signal reference point for a system of audio components. 
 Ground bus A common connection to which equipment is grounded, 
usually a heavy copper plate. 
 Grounding Connecting pieces of electronic equipment to ground. 
Proper grounding ensures that there is no voltage difference between 
equipment chassis. An electrostatic shield needs to be grounded to be 
effective. 
 Ground loop (1) A loop or circuit formed of ground leads. (2) The loop 
formed when two or more audio components are connected together via 
two ground paths: the connecting-cable shield and the safety ground 
pins in the components’ AC power cords. If there is a voltage difference 
between the two equipment grounds, the ground loop causes hum. 
 Group  See Submix. 
 Handheld recorder A device that records two tracks of audio to a ﬂ ash-
memory card in MP3 or WAV format. Also called “memory recorder” or 
“portable digital recorder.” 
 Hard disk A random-access storage medium for computer data. A hard-
disk drive contains a stack of magnetically coated hard disks that are read 
by, and written to by, an electromagnetic head. 
  Hard-disk recorder (HD recorder)  A device dedicated to recording 
digital audio on a hard-disk drive. A hard-disk recorder-mixer includes a 
built-in mixer. 
 Harmonic In a complex wave, an overtone whose frequency is a whole-
number multiple of the fundamental frequency. 

293
Glossary
 Headroom The safety margin, measured in decibels, between the signal 
level and the maximum undistorted signal level. 
 Hertz (Hz) Cycles per second, the unit of measurement of frequency. 
 High-pass filter A ﬁ lter that passes frequencies above a certain fre-
quency and attenuates frequencies below that same frequency. A low-cut 
ﬁ lter. 
 Hiss A noise signal containing all frequencies, but with greater energy 
at higher octaves. Hiss sounds like wind blowing through trees. It is usu-
ally caused by random signals generated by microphones and electronics. 
 Hot (1) A high recording level causing slight distortion; may be used for 
special effect. (2) A condition in which a chassis or circuit has a potentially 
dangerous voltage on it. (3) Referring to the conductor in a microphone 
cable, which has a positive voltage on it at the instant that sound pressure 
moves the diaphragm inward. 
 HRTF  Head-Related Transfer Function. The effect of the head on the 
amplitude versus frequency and phase versus frequency of a sound com-
ing from a particular direction. 
 Hum An unwanted low-pitched tone (60 Hz and its harmonics, 50 Hz 
in Europe) heard in the monitors. The sound of interference generated in 
audio circuits and cables by AC power wiring. Hum pickup is caused by 
such things as faulty grounding, poor shielding, and ground loops. 
 Hypercardioid microphone A directional microphone with a polar pat-
tern that has 12 dB attenuation at the sides, 6 dB attenuation at the rear, 
and two nulls of maximum rejection at 110° off axis. 
 Image An illusory sound source located somewhere around the listener. 
An image is generated by two or more loudspeakers. In a typical stereo 
system, images are located between the two stereo speakers. 
 Imaging The ability of a microphone array or a speaker pair to form 
easily localizable images. 
 Impedance The opposition of a circuit to the ﬂ ow of alternating cur-
rent, measured in ohms. Impedance is the complex sum of resistance and 
reactance. Abbreviated as Z. In a microphone, low impedance is under 
600 ohms, medium impedance is about 1500 ohms, and high impedance 
is over 10 kilohms. 

294
Glossary
 Input The connection going into an audio device. In a mixer or mixing 
console, a connector for a microphone, line-level device, or other signal 
source. 
 Input attenuator  See Attenuator. 
 Input module In a mixing console, the set of controls affecting a sin-
gle input signal. An input module usually includes an attenuator (trim), 
fader, equalizer, aux sends, and channel-assign controls. 
 Input section The row of input modules in a mixing console. 
  Insert jacks (insert sockets outside the US)  One or two jacks (sockets 
outside the US) in a console input module or output module that allow 
access to points in the signal path, usually for connecting a compressor. 
Plugging into the insert connectors breaks the signal ﬂ ow and allows you to 
insert a signal processor or multitrack recorder in series with the signal. The 
insert-send connector can feed a signal to a recorder track input, while the 
insert-return connector can accept a signal from a recorder’s track output. 
 Intensity stereo (XY stereo) A method of forming stereo images by 
intensity or amplitude differences between channels.  See Coincident-pair 
method. 
 iOS Apple’s operating system for the iPhone, iPod or iPad. 
 ITE/PAR Acronym for In The Ear/Pinna Acoustic Response, a stereo 
recording system developed by Don and Carolyn Davis of Synergetic 
Audio Concepts. It uses two probe microphones in the ear canals, near 
the ear drum of a human listener. Playback is over two speakers up front 
and two to the sides of the listener. 
 Jack (US definition) A female or receptacle-type connector for audio 
signals into which a plug is inserted. Outside the US, a jack is called a 
socket, and a jack plug inserts into a socket. 
 Jecklin disk Named after its inventor, a stereo microphone array using 
two omnidirectional microphones spaced 6 1/2 inches apart and sepa-
rated by a disk or bafﬂ e 11 7/8 inches in diameter, covered with ﬂ at sound-
absorbent material; also known as the OSS system.  See also  Schneider disk. 
 Kilo A preﬁ x meaning one thousand, abbreviated k. 
 Leakage The overlap of an instrument’s sound into another instru-
ment’s microphone. Also called bleed or spill. 

295
Glossary
 Level The degree of intensity of an audio signal; the voltage, power, or 
sound pressure level. The original deﬁ nition of level is the power in watts. 
 Level setting In a recording system, the process of adjusting the input-
signal level to obtain maximum level on the recording media without dis-
tortion. A meter shows recording level. 
 Limiter An ampliﬁ er whose output is constant above a preset input 
level. A compressor with a compression ratio of 10:1 or greater, with the 
threshold set just below the point of distortion of the following device. 
Used to prevent distortion of attack transients or peaks. 
 Line level In balanced professional recording equipment, a signal 
whose nominal level is approximately 1.23 volts (+4 dBu). In unbalanced 
equipment (most home hi-ﬁ  or semipro recording equipment), a signal 
whose level is approximately 0.316 volt (−10 dBV). 
 Live (1) Having audible reverberation. (2) Occurring in real time, in person. 
 Live recording A recording made at a gig or concert. Also, a recording 
made of a musical ensemble playing all at once, rather than overdubbing. 
 Localization Our ability to tell the direction of a real sound source or an 
image (illusory sound source). 
 Localization accuracy The accuracy with which a stereo microphone 
array translates the location of real sound sources into image locations. If 
localization is accurate, instruments at the side of the musical ensemble 
are reproduced from the left or right speaker; instruments halfway off-
center are reproduced halfway between the center of the speaker pair and 
one speaker, and so on. 
 Location The angular position of an image relative to a point straight 
ahead of a listener, or its position relative to the loudspeakers. 
 M Abbreviation for mega, or one million (as in megabytes). 
  MADI (Multichannel Audio Digital Interface or AES10)  An Audio 
Engineering Society (AES) standard electronic communications protocol 
that deﬁ nes the data format and electrical characteristics of an interface 
that carries multiple channels of digital audio. 
 Master (1) A completed CD used to generate compact discs. (2) To mas-
ter an audio program is to put the song mixes in order, insert silent spaces 
between them, and match their volumes and tonal balances. 

296
Glossary
 Master fader A volume control that affects the level of all program 
buses simultaneously. It is the last stage of gain adjustment before the 
two-track recorder. 
 Memory recorder A device that records two tracks of audio to a ﬂ ash-
memory card in MP3 or WAV format. Also called “handheld recorder” or 
“portable digital recorder.” 
 Meter A device that indicates voltage, resistance, current, or signal level. 
 Mic An abbreviation for microphone. 
 Mic level The level or voltage of a signal produced by a microphone, 
typically 2 millivolts. 
 Mic preamp  See Preampliﬁ er. 
 Microphone A transducer or device that converts an acoustical signal 
(sound) into a corresponding electrical signal. 
 Microphone techniques The selection and placement of microphones 
to pick up sound sources. 
 Mid–side A coincident-pair stereo microphone technique using a 
forward-facing unidirectional, omnidirectional, or bidirectional mic and 
a side-facing bidirectional mic. The microphone signals are summed and 
differenced to produce right- and left-channel signals. 
 Mike To pick up with a microphone. 
 Milli A preﬁ x meaning one-thousandth, abbreviated m. 
 Mix (1) To combine two or more different signals into a common signal. 
(2) A control on an effect unit that varies the ratio between the dry and the 
processed signals. 
 Mixdown The process of playing recorded tracks through a mixing con-
sole and mixing them to two stereo channels or six surround channels. 
 Mixer A device that mixes or combines audio signals and controls the 
relative levels of the signals. 
 Mixing console A large mixer with additional functions such as equal-
ization or tone control, pan pots, monitoring controls, solo functions, 
channel assigns, and aux sends. 
 Monaural Referring to listening with one ear; often incorrectly used to 
mean monophonic. 

297
Glossary
 Monitor To listen to an audio signal with headphones or loudspeakers. 
Also, a loudspeaker in a control room, or headphones, used for judging 
sound quality. Also, a video display screen used with a computer. 
 Monitoring Listening to an audio signal with a monitor. 
 Mono, monophonic Referring to a single channel of audio. A mono-
phonic program can be played over one or more loudspeakers, or one or 
more headphones. 
 Mono-compatible A characteristic of a stereo program, in which the 
program channels can be combined to a mono program without altering 
the frequency response or balance. A mono-compatible stereo program 
has the same frequency response in stereo or mono because there is no 
delay or phase shift between channels to cause phase interference. 
 Moving-coil microphone A microphone with a diaphragm attached to 
a coil of wire moving in a magnetic ﬁ eld. The diaphragm vibrates when 
struck with sound waves, which vibrates the coil and generates an electri-
cal signal similar to the incoming sound wave. Usually called a dynamic 
microphone. 
  MP3 (MPEG Level-1 Layer-3)  A data-compression format for audio. In 
an MP3 ﬁ le (.mp3), the data has been compressed or reduced typically to 
1/10 its original size or less. Compressed ﬁ les take up less memory, so 
they download faster. You download MP3 ﬁ les to your hard drive, then 
listen to them. MP3 audio quality at a 192 kbps or higher rate is nearly the 
same as that of CDs (depending on source material).  See also WMA. 
 MS recording  See Mid–side. 
 Muddy Unclear sounding; having excessive leakage, reverberation, or 
an undamped envelope. 
 Multitrack Referring to a recorder that has more than two tracks. 
 Mute To turn off an input signal on a mixing console by disconnecting 
the input-module output from channel assign and direct out. During mix-
down, the mute function in a track is used to reduce noises and leakage 
during silent portions of the audio, or to turn off unused performances. 
During recording, mute is used to turn off mic signals. 
 Near coincident A stereo microphone technique in which two direc-
tional microphones are angled apart symmetrically on either side of cen-
ter and spaced a few inches apart horizontally. 

298
Glossary
 Nearfield™ monitoring A monitor-speaker arrangement in which 
the speakers are placed about 3 feet apart and 3 feet from the listener to 
reduce the audibility of control-room acoustics. 
 Noise Unwanted sound, such as hiss from electronics or tape. An audio 
signal with an irregular, non-periodic waveform. 
 Non-destructive editing In a digital audio workstation, editing done by 
changing pointers (location markers) to information on the hard disk. A 
non-destructive edit can be undone. 
 Nonlinear (1) Referring to a storage medium in which any data can be 
accessed or read almost instantly. Examples are a hard disk, compact disc, 
and MiniDisc.  See Random access. (2) Referring to an audio device that is 
distorting the signal. 
 NOS A Dutch Broadcasting System standard for a near-coincident ste-
reo microphone technique in which two cardioid microphones are angled 
apart 90° and spaced 30 cm (11.8 in) horizontally. 
 Off axis Not directly in front of a microphone or a loudspeaker. 
 Off-axis coloration In most microphones, the deviation from the on-axis 
frequency response that occurs at angles off the axis of the microphone. 
The coloration of sound (alteration of tone quality) for sounds arriving off 
axis to the microphone. 
 Omnidirectional microphone A microphone that is equally sensitive to 
sounds arriving from all directions. 
 On-location recording A recording made outside the studio, in a room 
or hall where the music usually is performed or practiced. 
 ORTF Named after the French broadcasting network (Ofﬁ ce de 
Radiodiffusion Télévision Française), a near-coincident stereo mic tech-
nique that uses two cardioid mics angled 110° apart and spaced 17 cm 
horizontally. 
 OSS system Abbreviation for optimal stereo signal system.  See Jecklin 
disk. 
 Output A connector in an audio device from which the signal comes 
and feeds successive devices. 
 Overdub To record a new musical part on an unused track in synchro-
nization with previously recorded tracks. 

299
Glossary
 Overload The distortion that occurs when an applied signal exceeds a 
system’s maximum input level. 
 Pad A resistive network that reduces the microphone signal level to pre-
vent overloading of the input transformer and mic preampliﬁ er. 
 Pan pot Abbreviation for panoramic potentiometer. In each input mod-
ule in a mixing console, a control that divides a signal between two chan-
nels in an adjustable ratio. By doing so, a pan pot controls the location of 
a sonic image between a stereo pair of loudspeakers. 
 PC card  See PCMCIA. 
 PCMCIA An acronym for Personal Computer Memory Card Interna-
tional Association, a standard for credit-card-size PC Cards that plug into 
portable computers to add extra functions such as memory, modems, por-
table disk drives, or USB/FireWire ports. Comes in three types that have 
different thicknesses. 
 Perspective In the reproduction of a recording, the audible sense of dis-
tance to the musical ensemble, the point of view. A close perspective has a 
high ratio of direct sound to reverberant sound; a distant perspective has 
a low ratio of direct sound to reverberant sound. 
 PFL Abbreviation for prefader listen.  See also Solo. 
 Phantom image  See Image. 
 Phantom power A DC voltage (usually 12–48 volts) applied to a balanced 
microphone’s two signal conductors to power a condenser microphone. 
 Phantom power supply A stand-alone device, or a circuit built into a 
mixer or mic preamp, that provides phantom power. 
 Phase The degree of progression in the cycle of a wave, where one com-
plete cycle is 360°. 
  Phase cancellation, phase interference  The cancellation of certain fre-
quency components of a signal that occurs when the signal is combined 
with its delayed replica. At certain frequencies, the direct and delayed sig-
nals are of equal level and opposite polarity (180° out of phase), and when 
combined, they cancel out. The result is a comb-ﬁ lter frequency response 
having a periodic series of peaks and dips. Phase interference can occur 
between the signals of two microphones picking up the same source at 
different distances, or can occur at a microphone picking up both a direct 
sound and its reﬂ ection from a nearby surface. 

300
Glossary
 Phase shift The difference in degrees of phase angle between corre-
sponding points on two waves. If one wave is delayed with respect to 
another, there is a phase shift between them of 2π FT, where π = 3.14,  F = 
frequency in Hz, and  T = delay in seconds. 
 Phone plug (US deﬁ nition) A cylindrical, coaxial connector of 1/4- or 
1/8-inch diameter. An unbalanced phone plug has a tip for the hot signal 
and a sleeve for the shield or ground. A balanced phone plug has a tip for 
the hot signal, a ring for the return signal, and a sleeve for the shield or 
ground. A phone plug used with a TRS (tip–ring–sleeve) insert jack has 
a tip for the insert-send signal, a ring for the insert-return signal, and a 
sleeve for the common shield or ground. 
 Outside the US, a phone plug is called a jack plug. It is a cylindrical, coax-
ial connector of 6.35 or 3.5 mm diameter. An unbalanced jack plug has a 
tip for the hot signal and a sleeve for the shield or ground. A balanced jack 
plug has a tip for the hot signal, a ring for the return signal, and a sleeve 
for the shield or ground. A jack plug used with a TRS (tip–ring–sleeve) 
insert socket has a tip for the insert-send signal, a ring for the insert-return 
signal, and a sleeve for the common shield or ground. 
 Phono plug A coaxial plug with a central pin for the hot signal and a 
ring of pressure-ﬁ t tabs for the shield or ground. Also called RCA plug. 
 Pickup A piezoelectric transducer that converts mechanical vibrations 
to an electrical signal. Used in acoustic guitars, acoustic basses, and ﬁ d-
dles. Also, a magnetic transducer in an electric guitar that converts string 
vibration to a corresponding electrical signal. Same as contact pickup. 
 Pinnae The outer ears. Reﬂ ections from folds of skin in the pinnae aid 
in localizing sounds. 
 Plug A male connector that inserts into a jack outside the US, a jack plug 
is a male connector that inserts into a socket. 
 Plug-in power DC power for an unbalanced condenser microphone 
supplied on a single wire from the connected recording equipment.  See 
also Phantom power. 
 Plug-ins Software effects that you install in your computer. The plug-in 
software becomes part of another program you are using (the host), such 
as a digital editing program. You can access the plug-in from the host 
software. 

301
Glossary
 Polar pattern The directional pickup pattern of a microphone. A plot of 
microphone sensitivity plotted versus angle of sound incidence. Examples 
of polar patterns are omnidirectional, bidirectional, and unidirectional. 
Subsets of unidirectional are cardioid, supercardioid, and hypercardioid. 
 Polarity Referring to the positive or negative direction of an electrical, 
acoustical, or magnetic force. Two identical signals in opposite polarity 
are 180° out of phase with each other at all frequencies. 
 Pop (1) A thump or little explosion sound heard in a vocalist’s micro-
phone signal. Pop occurs when the user says words with  p, t,  or  b,  so that a 
turbulent puff of air is forced from the mouth and strikes the microphone 
diaphragm. (2) A noise heard when a mic is plugged into a monitored 
channel or when a switch is ﬂ ipped. 
 Pop filter A screen placed on or near a microphone grille that attenu-
ates or ﬁ lters out pop disturbances before they strike the microphone dia-
phragm. Usually made of open-cell plastic foam or nylon fabric, a pop 
ﬁ lter reduces pop and wind noise. 
 Power amplifier An electronic device that ampliﬁ es or increases the 
power level fed into it to a level sufﬁ cient to drive a loudspeaker. 
  Power ground (safety ground)  A connection to the power company’s 
earth ground through the U-shaped hole in a power outlet. In the power 
cable of an electronic component with a three-prong plug, the U-shaped 
prong is wired to the component’s chassis. This wire conducts electricity 
to power ground if the chassis becomes electrically hot, preventing shocks. 
 Preamplifier (preamp) In an audio system, the ﬁ rst stage of ampliﬁ ca-
tion that boosts a mic-level signal to line-level. A preamp is a stand-alone 
device or a circuit in a mixer. 
 Prefader–postfader switch A switch that selects a signal either ahead of 
the fader (prefader) or following (postfader) the fader. The level of a pre-
fader signal is independent of the fader position; the level of a postfader 
signal follows the fader position. Signals sent from mixer input modules 
to a multitrack recorder should be prefader so that fader adjustments 
don’t change the recording level. 
 Preproduction Planning in advance what will be done at a recording 
session, in terms of track assignments, overdubbing, instrument layout, 
and microphone selection. 

302
Glossary
 Presence peak A rise in the frequency response of a microphone around 
5 kHz to add clarity or deﬁ nition. 
  Pressure Zone Microphone (PZM)   Trademarked by Crown International,  
 a boundary microphone constructed with the microphone diaphragm paral-
lel to and facing a reﬂ ective surface. 
 Pressure-response microphone An omnidirectional microphone whose 
frequency response is ﬂ at at high frequencies when the mic is used as a 
boundary microphone.  See Boundary microphone. 
 Production (1) A recording that is enhanced by effects. (2) The supervi-
sion of a recording session to create a satisfactory recording. This involves 
getting musicians together for the session, making musical suggestions to 
the musicians to enhance their performance, and making suggestions to the 
engineer for sound balance and effects. 
 Program bus A bus or output that feeds an audio program to a recorder 
track. 
 Program mixer In a mixing console, a mixer formed of input-module 
outputs, combining ampliﬁ ers, and program busses. 
 Proximity effect The bass boost that occurs with a single-D directional 
microphone when it is placed a few inches from a sound source. The 
closer the microphone, the greater the low-frequency boost due to prox-
imity effect. 
 Rack A 19-inch-wide wooden or metal cabinet used to hold audio 
equipment. 
 Radio-frequency interference (RFI) Radio-frequency electromagnetic 
waves induced in audio cables or equipment, causing various noises in 
the audio signal. 
 Random access Referring to a storage medium in which any data point 
can be accessed or read almost instantly. Examples are a hard disk, com-
pact disc, and ﬂ ash-memory card. 
  REAC (Roland Ethernet Audio Communication)   Roland’s system of 
low-latency, 24-bit multichannel digital audio transfer. 
 Recorder-mixer A combination of multitrack recorder and mixer in one 
chassis. 
 Rednet  A Focusrite audio networking protocol. 

303
Glossary
 Reflected sound Sound waves that reach the listener after being reﬂ ected 
from one or more surfaces. 
 Region In a digital audio editing program, a deﬁ ned segment of the 
audio program, such as a song, song section, musical phrase, or a note. 
Also called a clip. 
 Remote recording  See On-location recording. 
  Removable hard drive (external hard drive)  A hard-disk drive that can 
be removed and replaced with another, used in a digital audio worksta-
tion to store audio and editing ﬁ les, and used in some multitrack hard-
disk recorders to store digital audio. Usually it connects to the computer 
via USB. 
 Reverberation (reverb) Natural reverberation in a room is a series of 
multiple sound reﬂ ections that makes the original sound persist and grad-
ually die away or decay. These reﬂ ections tell the ear that you’re listening 
in a large or hard-surfaced room. For example, reverberation is the sound 
you hear just after you shout in an empty gymnasium. A reverb effect 
simulates the sound of a room—a club, auditorium, or concert hall—by 
generating random multiple echoes that are too numerous and rapid for 
the ear to resolve. The timing of the echoes is random, and the echoes 
increase in number with time as they decay. An echo is a discrete repeti-
tion of a sound; reverberation is a continuous fade-out of sound. 
 Reverberation time (RT60) The time it takes for reverberation to decay 
to 60 dB below the original steady-state level and has become inaudible. 
 RFI  See Radio-frequency interference. 
 Ribbon microphone A dynamic microphone in which the conductor is 
a long metallic diaphragm (ribbon) suspended in a magnetic ﬁ eld. Usu-
ally a ribbon microphone has a bidirectional (ﬁ gure-eight) polar pattern 
and can be used for the Blumlein method of stereo recording. 
 Sampling Recording a short sound event into computer memory. The 
audio signal is converted into digital data representing the signal wave-
form, and the data is stored in memory chips or on disk for later playback. 
 SASS The Stereo Ambient Sampling System™, a stereo microphone 
using two boundary microphones, each on a 5-inch square panel, angled 
apart and ear-spaced, with a bafﬂ e between the microphones. No longer 
in production. 

304
Glossary
 Schneider disk Named after its inventor, a stereo microphone array 
using two omnidirectional microphones spaced 6½ inches apart and 
separated by a disk or bafﬂ e 11⅞ inches in diameter, covered with hemi-
spheres of sound-absorbent material.  See also Jecklin disk. 
  SD (secure digital) card (compact flash card)  A type of ﬂ ash-memory 
card used to store data, such as digital audio recorded by a portable ﬂ ash-
memory recorder. Generally has a smaller physical size than a compact 
ﬂ ash card.  See also Flash memory. 
 Semi-coincident method  See Near coincident. 
 Sensitivity (1) The output of a microphone in volts for a given input 
in sound pressure level. (2) The sound pressure level a loudspeaker pro-
duces at 1 meter when driven with 1 watt of pink noise.  See also Sound 
pressure level. 
 Shield A conductive enclosure (usually a chassis, metal braid, or foil) 
around one or more signal conductors, used to keep out electrostatic 
ﬁ elds that cause hum or buzz. 
 Shock mount A suspension system that mechanically isolates a microphone 
from its stand or boom, preventing the transfer of mechanical vibrations. 
  Shotgun microphone (line microphone)  A highly directional micro-
phone made of a slotted “line interference” tube mounted in front of a 
hypercardioid microphone capsule. 
 Shuffling S ee Spatial equalization. 
 Sibilance In a speech recording, excessive frequency components in the 
5–10 kHz range, which are heard as an overemphasis of  s and  sh sounds. 
 Side-addressed Refers to a microphone whose main axis of pickup is 
perpendicular to the side of the microphone. You aim the side of the mic 
at the sound source.  See also End-addressed. 
 Signal A varying electrical voltage that represents information, such as 
a sound. 
 Signal path The path a signal travels from input to output in a piece of 
audio equipment. 
 Signal processor A device that is used to alter a signal in a controlled 
way. Signal processors provide compression, gating, or equalization; or 
provide such effects as chorus, reverberation, pitch shift, and echo. 

305
Glossary
 Signal-to-noise (S/N) ratio The ratio in decibels between signal and 
noise voltage. An audio component with a high S/N has little background 
noise accompanying the signal; a component with a low S/N is noisy. 
 Single-D microphone A directional microphone having a single dis-
tance between its front and rear sound entries. Such a microphone has 
proximity effect. 
 Size  See Focus. 
 SMPTE time code A modulated 1200 Hz square-wave signal used to 
synchronize two or more video transports with audio recorders. SMPTE 
is an abbreviation for the Society of Motion Picture and Television Engi-
neers, which developed the time code. In Europe, engineers use the EBU 
time code (a 1000 Hz modulated square wave). 
 Snake A multipair or multichannel mic cable. Also, a multipair mic 
cable attached to a stage box containing mic connectors. 
 Solo On an input module in a mixing console, a switch that lets you 
monitor that particular input signal by itself. The switch routes only that 
input signal to the monitor system. 
 Sound card A circuit card that plugs into a PCI slot in a computer and 
converts an audio signal into computer data for storage in memory or 
on hard disk. The sound card also converts computer data into an audio 
signal. 
  Sound pressure level (SPL)  The acoustic pressure of a sound wave, 
measured in decibels above the threshold of hearing. dB SPL = 20 log 
( P / P ref ), where  P ref = 0.0002 dyne/cm 2 . 
 Spaced-pair method A stereo microphone technique using two identi-
cal microphones spaced several feet apart horizontally, usually aiming 
straight ahead toward the sound source. Also called A–B. 
 Spatial equalization A low-frequency shelving boost in the  L –  R (dif-
ference) signal of a stereo program, and a complementary shelving cut 
in the  L +  R  (sum) signal, in order to align the locations of the low- and 
high-frequency components of images, and to increase spaciousness or 
stereo separation. 
 Spatial processor A signal processor that allows images to be placed 
beyond the limits of a stereo pair of speakers, even behind the listener or 
toward the sides. 

306
Glossary
 Spectrum The output versus frequency of a sound source, including the 
fundamental frequencies and harmonics. 
 SPL  See Sound pressure level. 
 Splitter A transformer or circuit used to divide a microphone signal 
into two or more identical signals to feed different sound systems. 
 Spot microphone In classical music recording, a close-placed micro-
phone that is mixed with more-distant microphones to add presence or to 
improve the balance of a certain instrument or instrumental section. 
 Stage box A chassis with several mic connectors, wired to a multicon-
ductor cable called a snake. The stage box and snake carry the signals of 
several microphones to a mixer. 
 Stage width  See Stereo spread. 
 Stereo, stereophonic An audio recording and reproduction system 
with correlated information between two channels (usually discrete chan-
nels), and meant to be heard over two or more loudspeakers to give the 
illusion of sound-source localization and depth.  Stereo  means “solid” or 
three-dimensional. 
  Stereo bar, stereo microphone adapter  A microphone-stand adapter that 
mounts two microphones on a single stand for convenient stereo miking. 
 Stereo imaging The ability of a stereo recording or reproduction system 
to form clearly deﬁ ned audio images at various locations between a stereo 
pair of loudspeakers. 
 Stereo microphone A microphone containing two mic capsules in a 
single housing for convenient stereo recording. The capsules usually are 
coincident. 
 Stereo spread The reproduced stage width. The distance between the 
reproduced images of the left and right side of a musical ensemble. 
  Submaster (group master, bus master)  A master volume control for an 
output bus. 
 Submix A small preset mix within a larger mix, such as a drum mix, 
keyboard mix, vocal mix, etc. Also a cue mix, monitor mix, or effects mix. 
 Submixer A smaller mixer within a mixing console (or standing alone) 
that is used to set up a submix, a cue mix, an effects mix, or a monitor mix. 

307
Glossary
 Supercardioid microphone A unidirectional microphone that attenu-
ates side-arriving sounds by 8.7 dB, attenuates rear-arriving sounds by 
11.4 dB, and has two nulls of maximum sound rejection at 125° off axis. 
 Surround microphone A microphone with four or ﬁ ve microphones 
mounted on a common holder for convenient surround recording. 
 Surround sound A multichannel recording and reproduction system 
that plays sound all around the listener. The 5.1 surround system uses 
the following speakers: front-left, center, front-right, left-surround, right-
surround, and subwoofer. 
 Sync, synchronization Aligning two separate audio programs in time, 
and maintenance of that alignment as the programs play. 
 Three-pin connector A 3-pin professional audio connector used for bal-
anced signals. Pin 1 is soldered to the cable shield, pin 2 is soldered to the 
signal hot (in-polarity) lead, and pin 3 is soldered to the signal cold lead. 
 See also XLR-type connector. 
 Three-to-one rule A rule in microphone applications. When multiple 
mics are mixed to the same channel, the distance between mics should be 
at least 3 times the distance from each mic to its sound source. This pre-
vents audible phase interference. 
 Thunderbolt A serial computer connection running at 10 Gbits per sec-
ond. Thunderbolt 2 runs at 20 Gbits per second.  See USB and FireWire. 
 Tie Connect electrically; for example, by soldering a wire between two 
points in a circuit. 
 Tight (1) Having very little leakage or room reﬂ ections in the sound 
pickup. (2) Refers to well-synchronized playing of musical instruments. 
(3) Having a well-damped, rapid decay. 
 Timbre The subjective impression of spectrum and envelope. The quality 
of a sound that allows us to differentiate it from other sounds. For example, 
if you listen to a trumpet, a piano, and a drum, you will hear that each has a 
different timbre or tone quality that identiﬁ es it as a particular instrument. 
 Time code  See SMPTE time code. 
 Tonal balance The balance or volume relationships among different 
regions of the frequency spectrum, such as bass, midbass, midrange, 
upper midrange, and highs. 

308
Glossary
 Track A group of bytes in a digital signal (on tape, on hard disk, on 
compact disc, or in a data stream) that represents a single channel 
of audio or MIDI. Usually one track contains a performance of one musi-
cal instrument. 
 Transaural stereo A method of recording surround sound heard over 
two loudspeakers. During recording, the signals from a dummy head 
are processed for playback over loudspeakers, so that acoustic crosstalk 
around the head is canceled. This crosstalk is the signal from the right 
speaker that reaches the left ear, and the signal from the left speaker that 
reaches the right ear. The net effect is to enable the listener to hear, over 
loudspeakers, what the dummy head heard in the original environment. 
 Transducer A device that converts energy from one form to another, 
such as a microphone or a loudspeaker. 
 Transformer An electronic component made of two magnetically cou-
pled coils of wire. The input signal is transferred magnetically to the out-
put, without a direct connection between input and output. 
 Transient A rapidly changing signal with a fast attack and a short decay, 
such as a drum beat. 
 Trim (1) In a mixing console, a control for ﬁ ne adjustment of level, as in 
a bus trim control. (2) In a mixing console, a control that adjusts the gain 
of a mic preamp to accommodate various signal levels. 
 TRS Tip–ring–sleeve designation for a balanced (or stereo) phone plug 
or phone jack. Outside the US, TRS is the tip–ring–sleeve designation for 
a balanced (or stereo) jack plug or socket. 
 TS Tip–sleeve designation for an unbalanced (or mono) phone plug or 
phone jack. Outside the US, TS is the tip–sleeve designation for an unbal-
anced (or mono) jack plug or socket. 
 Tube A vacuum tube, an amplifying component made of electrodes in 
an evacuated glass tube. Tube sound is characterized as being “warmer” 
than solid state or transistor sound. 
 Unbalanced line An audio cable having one conductor surrounded by 
a shield that carries the return signal. The shield is at ground potential. 
 Unidirectional microphone A microphone that is most sensitive to 
sounds arriving from one direction, in front of the microphone. Examples 
are cardioid, supercardioid, and hypercardioid. 

309
Glossary
 USB (Universal Serial Bus) A Mac/PC computer serial port and protocol 
for high-speed transfer of data between digital devices. Connects a com-
puter to external devices such as MIDI interfaces, memory sticks, memory 
recorders, and audio interfaces. Faster than a standard serial port. 
 Valve The British term for vacuum tube. 
 Virtual controls Audio equipment controls that are simulated on a com-
puter monitor screen. You adjust them with a mouse or a control surface. 
 Virtual loudspeaker A transaural image synthesized to simulate a loud-
speaker placed at a desired location. 
 Virtual surround system An audio reproduction system using two 
speakers to create the illusion that the listener is surrounded by virtual 
loudspeakers in a 5.1 surround array. 
 Virtual track A recording in a hard-disk recorder-mixer of a single take 
of a performance. You choose which virtual track(s) that you want to feed 
to a real track during mixdown. 
 VU meter A voltmeter with a speciﬁ ed transient response, calibrated in 
VU or volume units, used to show the relative volume of various audio 
signals, and to set recording level. In digital equipment, the VU meter is 
often replaced by the peak-reading LED or LCD meter. 
 Waveform A graph of a signal’s sound pressure or voltage versus time. 
The waveform of a pure tone is a sine wave. 
 Windscreen A foam or fur cover for a microphone that rejects wind noise. 
  WMA (Windows Media Audio)  A popular compressed audio ﬁ le format 
for streaming audio and for downloads. Windows Media 9.1 promises per-
formance similar to that of MP3PRO: near-CD quality at 48 kbps and CD 
quality at 64 kbps. 
 XLR-type connector An ITT Cannon part number that has become the 
popular deﬁ nition for a 3-pin professional audio connector.  See also Three-
pin connector. 
 XY  See Coincident-pair method. 
 Y-adapter A cable that divides into two cables in parallel to feed one 
signal to two destinations. 
 Z Mathematical variable for impedance. 

This page intentionally left blank

311
 Note: page numbers in  boldface indicate tables; those in  italics indicate ﬁ gures. 
 AAC (Advanced Audio Coding) 
ﬁ les 112 
 ABR (average bit rate) 111 
 AB technique 140–3,  141 
 Ac-cetera 59 
 accordion miking 74 
 ACD-10 AC Power Distro 64 
 acoustical absorption material 69 
 acoustic bass miking 74,  74 
 acoustic guitar miking  70, 70–1 
 AC power adapters 58 
 AC power distribution system 
64,  64 
 adapter cable 6,  7 
 A/D (analog-to-digital) converter 
22,  22 
 Advanced Audio Coding (AAC) 
ﬁ les 112 
 AEA (Audio Engineering 
Associated) Stereo Microphone 
Positioner (SMP) 186,  186 
 A-format signals 238 
 AGC (automatic-gain control) 
11, 38 
 .AIF (Audio Interchange File 
Format) 111 
 AIFF (Audio Interchange File 
Format) 111 
 air conditioning rumble 176–7 
 AKG C-426B Comb stereo 
microphone  181 
 AKG H85 shock mount 151 
 AKG H100 shock mount 151 
 album mastering  92, 92–4,  93 
 Alexander, Kavi 136 
 Amazon Cloudfront 120 
 AmpClamp mic mount 77 
 amplitude differences: localization 
by 194, 200–3,  201, 202 ; 
localization by time and 204–5, 
 205 
 analog-to-digital (A/D) converter 
22,  22 
 anti-aliasing ﬁ lter 21 
 anti-imaging ﬁ lter 23 
 Apple iOS devices: in digital 
audio workstation 27,  28 ; 
as recording device 12 
 artiﬁ cial head(s): binaural 
recording with 145, 257–63, 
 258 ; DSM-4CS four-channel 
surround 276; examples of  184, 
184–6,  185,  257,  258 ; substitutes 
for 260–1 
 artiﬁ cial-head equalization 261–2 
 artiﬁ cial-head imaging with 
loudspeakers 199, 262–3 
 assign control 18 
 association model of localization 
199 
 attenuator 58 
 audience microphones 78–9,  79, 90 
 audience tracks: in mixing 90; real-
world example of 105 
 Audio Engineering Associates 
(AEA) Stereo Microphone 
Positioner (SMP) 186,  186 
 audio ﬁ les: compression of 
109–11,  110 ; preparation and 
uploading of 114–16,  115 ; web-
related 111–12 
 Audio Interchange File Format 
(AIFF, .AIF) 111 
 audio interface with laptop  12, 
12–13,  13 
 audio restoration programs for 
noise reduction 100 
 Audio-Technica BP4025 end-
addressed XY mic  181 
 Auria 27,  28 
 automatic-gain control (AGC) 
11, 38 
 auxiliary (Aux) control 18 
 average bit rate (ABR) 111 
 A-weighted self-noise spec 129 
 backup of recording 82, 83 
 bafﬂ ed-omni techniques  144, 144–5, 
 145, 231–2; key features of 146; 
optimal stereo signal or Jecklin 
Disk as 231–2,  232 ; sphere 
microphone SASS-P MKII 
as 231 
 balance: bad tonal 177; faulty 
left-right 174–5; too loud/too 
soft 176 
 banjo miking 73 
 bass, muddy 176 
 bass miking: acoustic 74,  74 ; 
electric 71 
 battery module 6 
 Bernfeld, Benjamin 242–3 
 B-format signals 238 
 bidirectional mic 6, 126,  127 
 big band miking 76,  77 
 Billingsley, Mike 40 
 binaural microphones 8, 145, 
179–80, 260–1; headworn 
184–6,  185 
 binaural recording 145, 199, 257–65; 
artiﬁ cial-head equalization 
with 261–2; artiﬁ cial-head 
imaging with loudspeakers in 
262–3; artiﬁ cial head in 257–9, 
 258 ; with headphone playback 
257–9,  258 ; how it works 
259–61; in-head localization 
with 261 
 binaural reverberance suppression 
263 
 binaural system, quasi 182, 
231–2,  232 
 bit 22 
INDEX

312
Index
 bit depth 23–4 
 bit rate: in data compression 110; 
for live audio streaming 121 
 bitstream encoding 24–5 
 Blakemore, Paul 62 
 block diagram 56,  56 
 Blumlein, Alan 212 
 Blumlein technique 222–3,  223 
 board, recording off 34–5 
 bongo miking 72 
 booms 16, 133 
 boundary microphone 9, 37, 130–2, 
 131, 145 
 boundary microphone arrays 
249–56; ﬂ oor-mounted 250–3, 
 251, 252 ; raised 253–5,  254 
 bouzouki miking 73 
 breaker boxes 65 
 breath pop removal 99,  100 
 brightness 177 
 Bruck, Jerry 253, 271, 273 
 BS-3D sphere microphone 145 
 built-in mics 8 
 Burmajster, Chris 275 
 Chris Burmajster array  275, 275–6 
 cable(s) 6–8,  7,  59–60,  60 ; running 67 
 cable spool 59 
 Caig Labs 58 
 Cam-lok power connector 65 
 CardBus adapters 13 
 cardioid microphones: angled 
90º apart 222,  222 ; angled 
120º-135º apart  221, 221–2; 
angled 180º apart 220–1,  221 ; 
for classical music recording 
125–6,  127 ; for popular music 
recording 6, 69; room sound 
with 37; for surround sound 
274,  274 
 cardioid polar pattern 127;  see also 
unidirectional microphones 
 carts 59 
 casaba miking 72 
 CBR (constant bit rate) 111 
 CD Baby 115,  115 
 CD burning 94; real-world example 
of 106–7 
 CDex 112 
 CDN (Content Distribution 
Network) 120–1 
 center speaker in surround speaker 
arrangement 269 
 Ceoen, Carl 225, 242 
 choir miking 75, 161;  see also 
classical music recording 
 Christian music  see popular music 
recording 
 circuit checker 65 
 clamp-on mic mounts 16 
 classical music recording: 
microphone speciﬁ cations 
for 125–34; stereo, surround, 
and binaural microphones 
and accessories for 179–87; 
stereo microphone techniques 
for 135–48; stereo recording 
procedures for 149–69; 
troubleshooting stereo sound 
for 171–7 
 clip-on mics 8, 69 
 close stereo sound 172 
 coincident bidirectionals crossed 
at 90º 222–3,  223 
 coincident cardioids: angled 
90º apart 222,  222 ; angled 
120º–135º apart  221, 221–2; 
angled 180º apart 220–1,  221 
 coincident-pair techniques  138, 
138–40, 220–4; Blumlein 
technique as 222–3,  223 ; 
coincident cardioids angled 90º 
apart as 222,  222 ; coincident 
cardioids angled 120º-135º 
apart as  221, 221–2; coincident 
cardioids angled 180º apart 
as 220–1,  221 ; hypercardioids 
angled 110º apart as 223–4, 
 224 ; key features of 145–6; 
mid-side 139–40,  140, 232–7, 
 233–5 ; SoundField microphone 
as  237, 237–8; with spatial 
equalization (shufﬂ e circuit) 
238 
 collapsible carts 59 
 colored tone quality 177 
 compression in mixing 89 
 computer-aided model of 
stereophonic systems 242–5 
 computer mixing of multitrack 
recording 86–8,  87 
 concertina miking 74 
 condenser microphone 5, 15, 128–9 
 conference miking  75, 75–6 
 conga miking 72 
 connections for mics 6–8,  7, 156–67 
 constant bit rate (CBR) 111 
 contact pickups 69 
 Content Distribution Network 
(CDN) 120–1 
 continuous sounds, localization 
of 193 
 Core Sound binaural microphones 
184–5,  185, 260 
 Core Sound Jecklin Disk 145, 
182,  182 
 counter times 81–2 
 country music  see popular music 
recording 
 crowd noise 93 
 Crown Pressure Zone Microphone 
(PZM) 37, 75, 130–2,  131 
 Crown Stereo Ambient Sampling 
System (SASS) 253–4,  254 
 D/A (digital-to-analog) conversion 
23,  23 
 data compression for web audio 
109–11,  110 
 DAW  see digital audio workstation 
(DAW) 
 DB (direct box) 15–16, 69 
 DC bias 6 
 dead stereo sound 172 
 Decca Tree 229–31,  230 ; in surround 
miking 273,  273 
 deletion of unwanted material 88 
 Delos VR 2 surround miking 
method 270–1,  271 
 demo mastering 94–5,  96 
 De-Oxit 58 
 depth, lack of 175 
 depth cues 192 
 desktop mics 9 
 detailed stereo sound 172 
 DI box (direct box) 15–16, 69 
 diffuse-ﬁ eld equalization 262 
 DiGiCo SD11 digital console 46 
 digital audio basics 21–5,  22, 23 
 digital audio workstation (DAW): 
computer 25–7,  26, 28 ; stand-
alone 19–21,  21 ; for stereo-
spread control 159 

313
Index
 digital console recording facilities 
45–6 
 digital multitracker 19–21,  21 
 Digital Rights Management (DRM) 
111–12, 113 
 digital-to-analog (D/A) conversion 
23,  23 
 Dimensional Stereo Microphones 
(DSM) 260–1, 276 
 DIN system 144, 224–6,  225 
 direct box (DB, DI box) 15–16, 69 
 directional microphone 69, 126, 
 127, 128; ﬂ oor-mounted 
boundary 251–2,  252 
 direct out connector in multitrack 
recording system 42,  42 
 direct sound in localization 192 
 Direct Stream Digital (DSD) 24–5 
 Disc Makers 114 
 disk storage space 57,  57 
 distance cues 192 
 distant stereo sound 172 
 distortion in microphone signal 171 
 distro (power distribution system) 
63–4,  64 
 DMP surround miking method 
273,  273 
 dobro miking 73 
 dolly 59 
 double MS technique 158,  158, 
236–7; for surround sound 
 274, 274–5 
 downloading vs. streaming 109 
 drama miking 76,  76 
 drapes 69 
 DRM (Digital Rights Management) 
111–12, 113 
 drum machine miking 71 
 drum set miking  71, 71–2,  72 
 drum submix 80–1 
 dry/wet mix control 89 
 DSD (Direct Stream Digital) 24–5 
 DSM (Dimensional Stereo 
Microphones) 260–1, 276 
 DSM-4CS four-channel surround 
dummy head 276 
 dulcimer miking: hammered 74; 
lap 73 
 dullness 177 
 dummy head(s): binaural 
recording with 145, 257–63, 
 258 ; DSM-4CS four-channel 
surround 276; examples of  184,  
184–6,  185, 257,  258 ; substitutes 
for 260–1 
 dummy-head imaging with 
loudspeakers 199, 262–3 
 dummy-head localization 261–2 
 Dutch system 144, 226,  226 
 dynamic mics 5, 15 
 eardrum in binaural recording 
259 
 Eargle, John 157, 161, 240, 270 
 ear in binaural recording 259–60 
 early reﬂ ections: in localization 192; 
too loud 175–6 
 earphones: for multichannel 
recording 31; for stereo 
recording 14, 151 
 echo in mixing 90 
 edgy stereo sound 172 
 editing: to delete unwanted sound 
88; for noise reduction 99,  100 ; 
of stereo recording 164–6,  165, 
168–9; of two-track recording 
83–4,  85 
 electric bass miking 71 
 electric guitar: grounding of 78; 
miking of 71 
 electric guitar amp miking 71 
 electronic music, stereo recording 
of 162–3 
 eMusic 115–16 
 end-addressed small-diaphragm 
microphone 130,  131, 179,  181 
 equalization (EQ): artiﬁ cial-head 
261–2; diffuse-ﬁ eld 262; free-
ﬁ eld with source at ± 30º 262; 
frontal free-ﬁ eld 262; in mixing 
89; for noise reduction 97–8, 
 98, 99 ; spatial 211–13; of stereo 
recording 166; 10º averaged 
free-ﬁ eld 262 
 equalization (EQ) control 17 
 equipment 3–31; for multitrack 
recording 14–31; purchase of 
31; for stereo recording 5–14, 
149–52; on wheels 59 
 equipment list 56–8,  57 ; real-world 
example of 102–3 
 Exact Audio Copy 112 
 exaggerated separation effect  137, 
142,  173, 173–4, 218,  218 
 Facebook 121 
 fade-in: on computer 84,  85 ; with 
master CD 93, 97; with mixer 
88; on stereo recording 165,  165 
 fade-out: on computer 84; with 
demo 95; with master CD 93, 
97; with mixer 88; on stereo 
recording  165, 165–6 
 fader control 17 
 fader levels in mixing 89 
 Faulkner, Tony 239–40 
 Faulkner phased-array system 
239–40,  240 
 ﬁ ddle miking 73 
 ﬁ gure-eight mic 6, 126,  127 
 ﬁ le formats for web audio 111–12 
 ﬁ le preparation for web audio 
114–16,  115 
 ﬁ le-sharing website 116 
 ﬁ nal mixes 104–5 
 FiOS 110 
 FireWire mixer in digital audio 
workstation 26–7 
 FireWire PC Card adapter 13 
 FLAC (Free Lossless Audio Codec) 
ﬁ les 112 
 ﬂ ash-memory handheld recorder 
 10, 10–11,  11 
 ﬂ oor-mounted boundary 
microphones 250–3; mid-
side conﬁ guration of 253; 
“The Musician’s Ear” as 252; 
Optimal Stereo Signal as 252; 
spaced 4 feet apart 250–1,  251 ; 
unidirectional 251–2,  252 
 ﬂ ute miking 74 
 foam windscreen for mic 9, 16 
 FOH (front-of-house) mics  40, 40–1 
 folk music  see popular music 
recording 
 four-trackers, recording with  40, 
40–1 
 free-ﬁ eld equalization: frontal 262; 
with source at ± 30º 262; 10º 
averaged 262 
 free-ﬁ eld microphone 130,  130, 131 
 free-ﬁ eld microphone techniques 
217–47; bafﬂ ed-omni 231–2, 

314
Index
 232 ; coincident-pair 220–4, 
232–8; comparison of 241–5; 
computer-aided model of 
242–5; listening tests for 242; 
and localization accuracy 
217–20,  218, 219 ; near-
coincident-pair 224–6, 238–40; 
recording angle and standard 
deviation for 241–2; spaced-
pair 227–31,  228–30 
 Free Lossless Audio Codec (FLAC) 
ﬁ les 112 
 FreeRip3 112 
 French system 144, 224–6,  225 
 frequency notches in localization 
194–5 
 frequency response: of ear at 
different azimuth angles 
192–3,  193 ; in noise reduction 
98,  98 
 frequency response range of mics 9 
 frequency response tolerance of 
mics 9 
 “Fritz III” dummy head binaural 
system 185,  185, 262 
 frontal free-ﬁ eld equalization 262 
 front-of-house (FOH) mics  40,  
40–1 
 Furman 64 
 gaffer tape 58 
 gain control 17 
 gain-staging 80 
 gating in mixing 90 
 generator 65–6 
 German system 144, 224–6,  225 
 Gerzon, Michael 220–2 
 Glyph Triplicator 82 
 Gobbler 82 
 “goosenoose” stereo mics 8 
 gospel music  see popular music 
recording 
 grabber 112 
 grand piano miking 72–3,  73 
 grounding of electric guitar 78 
 ground-lift adapter 58, 66,  66 
 ground-lift switches 66 
 ground voltage 65 
 guiro miking 72 
 guitar miking: acoustic  70, 70–1; 
electric 71 
 GUY 260 
 hammered dulcimer miking 74 
 handheld recorders  10, 10–11,  11 ; 
recording with  35, 35–40,  38, 39 
 hanging mics 151, 155 
 Hannay 59 
 harmonica miking 74 
 Harmonic Balancer (Har-Bal) 40, 
105, 166 
 HD-AAC ﬁ les 112 
 Head Acoustics artiﬁ cial head 260, 
262 
 headband-mounted mics 9 
 headphone(s): for multichannel 
recording 31; for stereo 
recording 14, 151 
 headphone playback, binaural 
recording with 257–9,  258 
 head-related transfer function 
(HRTF) 180, 260–1 
 headworn binaural mics 184–6,  185 
 Hibbing, M. 244 
 high-pass ﬁ lter 98 
 hole in the middle effects 173–4 
 Holophone H2-PRO surround 
microphone 183,  184, 276 
 horn miking 75 
 HRTF (head-related transfer 
function) 180, 260–1 
 Huggonet, C. 243 
 hypercardioid microphones 6, 69, 
126,  127 ; angled 110º apart 
223–4,  224 
 ID3 tag editor 113 
 Ideal Cardioid Arrangement (ICA) 
276,  276 
 image(s) and imaging  see phantom 
images; stereo images and 
imaging 
 image broadening 192 
 image depth 191 
 image elevation 191 
 image focus 191,  191 
 image localization  see localization 
 image location 189–90,  190 ; 
predicting 206–10,  207–10 
 image movement 191 
 image size 191,  191 
 impedance 6, 15 
 INgrooves 115–16 
 in-head localization 261 
 in-line pads 58 
 in-line polarity reversers 58 
 input trim control 17 
 insert connectors 18 
 insert-send connector in multitrack 
recording system 14, 42,  42 
 insert sends connected to 
multitrack recorder  41–3, 41–5 
 insert snake 60 
 insurance policy 58, 61 
 interaural differences 191, 193–4; 
interchannel differences to 
produce 197–200,  198 ; speaker-
generated 196 
 interchannel differences 196; 
for natural imaging over 
loudspeakers 197–200,  198 
 interconnection of multiple sound 
systems  66, 66–7 
 interface: in digital audio 
workstation 26,  26, 27; with 
laptop  12, 12–13,  13 
 Internet, audio on  see web audio 
 Internet radio stations 116, 118, 121 
 iOS devices (iPad, iPhone): in 
digital audio workstation 27, 
 28 ; as recording device 12 
 isolating earphones for stereo 
recording 14 
 isolating headphones for stereo 
recording 14 
 IT-1 Isolation Transformer Unit 66 
 jack plug connector 6,  7, 8 
 jack-to-jack snake 60 
 Jam-Hub Tracker MT16 19 
 jazz  see popular music recording 
 Jecklin Disk 145, 182,  182, 231–2,  232 
 Jouhaneau, J. 243 
 Jung, Tom 273 
 Katz, Bob 136 
 KEMAR artiﬁ cial heads 262 
 KFM 360 surround miking system 
271–3,  272 
 K&M 21411B mic stand 151 
 Kugelﬂ achenmikrofon 261 
 Lame MP3 Encoder 113 
 lap dulcimer miking 73 
 laptop: in digital audio workstation 
 26, 26–7; as recording device 
 12, 12–13,  13 

315
Index
LBS (Line Balancer/Splitter) 66
leakage in multitrack recording 
system 14
Leerman, Craig 46
left-right balance, faulty 174–5
level setting 45, 80, 163–4
LFE (low-frequency effects) 
channel 90; in surround 
speaker arrangement 268
limiter 11
Line Balancer/Splitter (LBS) 66
line level in multitrack recording 
system 14
line voltage regulator 65
listening tests for comparing stereo 
techniques 242
LiteGuy 260
Live365 Pro Package 121
live recordings xviii
live audio streaming 109, 118–21, 
119, 121
load-in door 61
load-in/load-out checklist 58
localization: by amplitude and 
time differences 204–5, 205; by 
amplitude differences 200–3, 
201, 202; association model of 
199; currently used mechanisms 
for 200–6; defined 191; of 
images between speakers 195, 
195–7; in-head 261; microphone 
array and accuracy of 217–20, 
218, 219; predicting 206–10, 
207–10; of real sound sources 
192–4, 192–5; stereo miking and 
136–7, 137; by time differences 
203, 203–4, 204
location: predicting 206–10, 207–10; 
of stereo image 189–90, 190
lossless compression 111
lossy compression 111
loudness: bad balance of 176; of 
early reflections 175–6
loudspeakers: artificial-head 
imaging with 199, 262–3; 
requirements for natural 
imaging over 197–200, 198
low-frequency effects (LFE) 
channel 90; in surround 
speaker arrangement 268
low-impedance balanced output 6
lowpass filter 23
MADI SSL Live-Recorder option 46
mandolin miking 73
Martin, Geoff 277
Martin method 277, 278
mastering: adding fades in 97; 
of album 92, 92–4, 93; audio 
restoration programs in 100; 
of demo 94–5, 96; editing in 
99, 100; equalization in 97–8, 
98, 99; real-world example of 
105–6; spectral analysis and 
noise reduction in 97–100, 
98–100
matrix 140
M-Audio M-Track audio interface 
13, 13
maximum sound pressure level of 
mics 9
Mic-Eze units 59, 77
mic-gain switch 11
microphone(s) (mics): accessories 
for 9, 133, 133–4; audience 
78–9, 79, 90; bidirectional 
(figure-eight) 6, 126, 127; 
binaural 8, 145, 179–80, 260–1; 
boundary 9, 37, 130–2, 131, 
145; built-in 8; cardioid 6, 
37, 69, 125–6, 127; clip-on 8, 
69; condenser 5, 15, 128–9; 
connectors, powering, and 
cables for 6–8, 7, 156–67; 
desktop 9; directional 69, 126, 
127, 128; dynamic (moving-
coil) 5, 15; end-addressed 
small-diaphragm 130, 131, 
179, 181; free-field 130, 130, 
131; frequency response range 
of 9; frequency response 
tolerance of 9; front-of-house 
(FOH) 40, 40–1; “goosenoose” 
stereo 8; hanging 151, 155; 
headband-mounted 9; 
hypercardioid 6, 69, 126, 127; 
maximum sound pressure 
level of 9; mini stereo 8, 182; 
mounting styles for 8, 153–5, 
154; for multitrack recording 
15–16; off-axis coloration 
with 128; omnidirectional 
(omni) 6, 15, 126, 127, 128; 
plug-in 8; position of 69; 
ribbon 5, 15, 129; self-noise 
of 129; sensitivity of 129; 
side-addressed large-
diaphragm 130, 130, 179; 
signal-to-noise (S/N) ratio 
of 9; size of 9; SoundField 
237, 237–8; sound pickup 
patterns (polar patterns) of 6, 
125–8, 127; special-purpose 
8; specifications for 9; sphere 
145, 145, 255, 261; spot 160–2; 
stand-mounted stereo 8; stereo 
8, 132, 132–3, 180–2, 181–3; 
for stereo recording 5–9, 7, 
150; supercardioid 6, 37, 69, 
126, 127; surround 183, 184; 
talk-back 61; transducer type 
of 128–9; types of 130–2, 130–3; 
unidirectional 6, 15, 126, 127; 
USB 8
microphone (mic) angle: choice of 
210–11; coincident cardioids at 
90º apart 222, 222; coincident 
cardioids at 120º-135º apart 
221, 221–2; coincident 
cardioids at 180º apart 220–1, 
221; hypercardioids at 110º 
apart 223–4, 224; in image 
localization 207, 209, 209
microphone (mic) array(s): and 
accuracy of localization 
217–20, 218, 219; spaciousness 
of 211–13
microphone booms 16, 133
microphone (mic) case 59
microphone (mic) connections 67
microphone (mic) connectors 6–8, 7
microphone extension cables 151–2
microphone (mic) list 54–5
microphone (mic) mounts 8, 59
microphone (mic) placement 156–
64; for electronic music 162–3; 
miking distance in 156–8, 
158; soloist pickup and spot 
microphones in 160–2; stereo-
spread control in 159–60; for 
video shoots 163
microphone (mic) requirements for 
stereo 147
microphone (mic) signal distortion 
171
microphone (mic) signal splitting 
46–9, 47, 48

316
Index
 microphone (mic) spacing: choice 
of 210–11; in image localization 
207–8,  208, 209–10,  210 
 microphone (mic) speciﬁ cations 
for classical music recording 
125–34, 179–80 
 microphone (mic) splitter 15, 29–30, 
 29–31 ; use of 46–9,  47, 48 
 microphone (mic) stands 16, 133, 151 
 microphone (mic) techniques 
68–77; for accordion or 
concertina 74; for acoustic bass 
74,  74 ; for acoustic guitar  70, 
70–1; for audience mics 78–9, 
 79 ; for banjo 73; for big band 
76,  77 ; for bongos or congas 72; 
choice of mic positions as 69; 
for choir 75; for conferences 
 75, 75–6; for drama 76,  76 ; 
for drum sets  71, 71–2,  72 ; 
for electric guitar amp 71; 
for electric guitar or electric 
bass direct 71; for ﬁ ddle 73; 
for ﬂ ute 74; for grand piano 
72–3,  73 ; for group on tour 
77; for hammered dulcimer 
74; hanging drapes as 69; for 
harmonica 74; for horns 75; for 
mandolin, bouzouki, dobro, or 
lap dulcimer 73; for percussion 
(shaker, casaba, guiro, etc.) 72; 
for praise group 75; for sax 
71; for synthesizer or drum 
machine 71; for upright piano 
73; use of clip-on mics as 69; 
use of contact pickups as 69; 
use of direct boxes as 69; use 
of directional mics as 69; for 
video shoots 77–8, 163; for 
vocals 70; for worship leader 
75 
 microphone (mic)-to-source 
distance in image localization 
 208 
 Microtech Gefell INA5 276,  276 
 mid-side technique  see MS 
technique 
 miking distance 156–8,  158 
 mini stereo microphones 8, 182 
 mix and mixing: of each song 
88–90; ﬁ nal 104–5; for 
live audio streaming 120; 
of multitrack recording 
on computer 86–8,  87 ; of 
multitrack recording with 
mixer 88–92; preliminary 104; 
punch-ins during 88; real-
world example of 104–5; for 
surround sound 90–2; tips on 
100 
 mixer 17–18,  18 ; in digital audio 
workstation  26, 26–7; for 
multitrack recording 88–92; 
setup of 68; for stereo 
recording 152 
 mixer insert sends connected to 
multitrack recorder  41–3, 41–5 
 mixing board 17–18,  18 
 mixing console 17–18,  18 
 mixing desk 17–18,  18 
 Mixlr app 118–20,  119 
 MMA (Multichannel Microphone 
Array) 274,  274 
 Mole-Richardson 65 
 monitoring: of multitrack recording 
44–5; of stereo recording 151, 
152, 156; of stereo spread 160 
 monitor level 91 
 Moulton, Dave 62 
 moving coil mics 5, 15 
 MP3 encoder 113, 114 
 MP3 ﬁ les 36–7,  110, 110–11 
 MP3 player 113 
 MP3PRO ﬁ le format 111 
 MP3 server 114–15 
 MP3tag 113 
 MPEG Advanced Audio Coding 
(AAC) ﬁ les 112 
 MPEG Level-1 Layer-3  See MP3 
 MS matrix 235 
 MS matrix box 152, 234–5,  235 
 MS matrix decoders 187 
 M/S ratio 235,  235 
 MS technique 139–40,  140, 232–7, 
 233 ; advantages of 235–6; 
disadvantages of 236; double 
158,  158, 236–7,  274, 274–5; 
ﬂ oor-mounted boundary 
microphones conﬁ gured for 
253; monitoring with 152; 
MS matrix box in 152, 234–5, 
 235 ; with switchable polar 
patterns  233, 233–4; vs. XY 
technique 244 
 muddy bass 176 
 multichannel audio interface in 
digital audio workstation 
26,  26 
 Multichannel Microphone Array 
(MMA) 274,  274 
 multiple sound systems, 
interconnection of  66, 66–7 
 Multitrack DAW 27 
 multitrack recorder 18–19,  19, 20 ; 
connecting PA mixer insert 
sends to  41–3, 41–5 
 multitrack recording: deleting 
unwanted material from 88; 
editing of 99,  100 ; mixing on 
computer of 86–8,  87 ; mixing 
with mixer of 88–92; splitting 
into song projects of 86–7,  87 ; 
in truck 49–50 
 multitrack recording systems 
14–31; computer DAW 25–7, 
 26, 28 ; digital audio basics 
for 21–5,  22, 23 ; headphones, 
earphones, or speakers in 
31; microphones and mic 
accessories in 15–16; mic 
splitter in 15, 29–30,  29–31 ; 
mixer in 17–18,  18 ; recorder-
mixer option in 19–21,  21 ; 
recording device in 18–19,  19, 
20 ; signal ﬂ ow in 14–15,  15 ; 
stage box and snake in 14, 16, 
 17 ; stereo vs. 3–4 
 multitrack wiring 60–1 
 Muncy, Neil 62, 274 
 musical preparation 51–2 
 “The Musician’s Ear” stereo 
boundary microphone 252 
 narrow-stage effect 137,  137, 173, 
 173, 218,  218 
 natural images and imaging: focus 
of 191; over loudspeakers 
197–200,  198 
 near-coincident-pair techniques 
 143,  143–4, 146; Faulkner 
phased-array system as 
239–40,  240 ; ORTF and DIN 
systems as 224–6,  225, 226 ; 
Stereo 180 System as 239,  239 
 near-coincident/spaced-pair 
hybrid technique 240 

317
Index
 NetDNA 121 
 Netromedia.com 121 
 Neumann KU 100 “Fritz III” 
dummy head binaural system 
185,  185, 262 
 Neumann USM69i stereo 
microphone 182,  182 
 NHK surround-sound miking 
method 271,  272 
 Nicecast software 120 
 noise gate in mixing 90 
 noise reduction 97–100,  98–100 ; 
real-world example of 105 
 NOS system 144, 226,  226 
 off-axis coloration 128 
 Ofﬁ ce de Radiodiffusion Télévision 
Française (ORTF) system 144, 
224–6,  225, 270 
 Ogg Vorbis encoder 113 
 Ogg Vorbis (OGG) ﬁ les 112 
 omnidirectional (omni) 
microphones 6, 15, 126,  127, 
128; set of three spaced 5 feet 
apart (10 feet end to end) 
229,  230 ; spaced 3 feet apart 
227–8,  228 ; spaced 10 feet apart 
228,  229 
 1-bit encoding 24–5 
 on-line audio  see web audio 
 On-Stage MY320 shock mount 151 
 On-Stage MY410 shock mount 151 
 opposite polarity and localization 
196–7 
 Optimal Stereo Signal (OSS) system 
182, 231–2,  232, 252 
 The Orchard 115 
 orchestral music  see classical music 
recording 
 orchestral width and stereo 
localization effects 218,  219, 
220 
 ORTF (Ofﬁ ce de Radiodiffusion 
Télévision Française) system 
144, 224–6,  225, 270 
 OSS (Optimal Stereo Signal) system 
182, 231–2,  232, 252 
 overdubbing 88; real-world 
example of 105 
 pads 58 
 Palmcrantz, Gert 39 
 PA mixer insert send connected to 
multitrack recorder  41–3, 41–5 
 PA mixing console, recording off 
34–5 
 pan control 17–18 
 panning: to center 91; in mixing 89; 
real-world example of 105 
 parallel compression in mixing 89 
 PC Audiolabs 25 
 PCM (pulse code modulation) 
21–3,  22, 23 
 PCMCIA card 13 
 percussion miking 72 
 phantom images 91, 135; 
localization of 200–6,  201–5 ; 
outstanding examples of 
136; in surround speaker 
arrangement 269;  see also stereo 
images and imaging 
 phantom power 6, 129, 150 
 phase cancellations in localization 
194–5 
 phase shift in localization 193–4,  194 
 phone plug connector 6,  7, 8 
 phone-to-phone snake 60 
 piano miking: grand 72–3,  73 ; 
upright 73 
 Pillon, Gary 253 
 ping-pong effect  137, 142,  173, 
173–4 
 pinnae in localization 194–5 
 pipe organ  see classical music 
recording 
 pitch correction in mixing 90 
 Pizzi, Skip 62, 158,  158, 236–7 
 planning 51–62; block diagram 
in 56,  56 ; equipment list in 
56–8,  57 ; mic list in 54–5; 
musical preparation in 51–2; 
other tips for 61; preparing 
for easier setup in 58–61,  60 ; 
preproduction meeting in 
52,  53 ; real-world example 
of 101–3; site survey in 53–4; 
track sheet in 55; venue 
selection in 51 
 plug-in mics 8 
 plug-in power 6 
 polarity and localization 196–7 
 polarity reverser 58 
 polar patterns 6, 125–8,  127 ; 
advantages of 128 
 pop ﬁ lters 9, 16, 70 
 popular music recording: gear 
for 3–31; mixing and editing 
for 83–100; planning for 
51–62; real-world example of 
101–7; recording process for 
81–2; recording techniques 
for 33–50; setup for 63–81; 
teardown after 82; web audio 
and streaming of 109–22 
 pop waveform 99,  100 
 portable studio 19–21,  21 
 power conditioner 65 
 power distribution system (distro) 
63–4,  64 
 powering of mics 6–8,  7 
 power source 64–6 
 power supply for stereo recording 
150 
 PPLive 120 
 praise group miking 75 
 preamps 17, 150 
 preliminary mix 104 
 preparation for stereo recording 
166–7 
 preproduction  see planning 
 preproduction meeting 52,  53 
 PreSonus StudioLive 32.4.2 AI 
digital console 46 
 pressure buildup 259 
 Pressure Zone Microphone (PZM) 
37, 75, 130–2,  131 
 ProCoSound 59 
 ProCoSound IT-1 Isolation 
Transformer Unit 66 
 pulse code modulation (PCM) 
21–3,  22, 23 
 punch-ins 88; real-world example 
of 105 
 PZM (Pressure Zone Microphone) 
37, 75, 130–2,  131 
 Qu-16 digital console 46 
 quantization 22 
 quasi binaural system 182, 231–2, 
 232 
 QuickTime 113 
 Quik Lok A50 mic stand 151 
 Radial Convertible V12 splitter-
snake 48,  48 
 radio stations, Internet 116, 118, 121 

318
Index
 raised boundary microphone 
arrays 253–5; sphere 
microphone as 255; stereo 
ambient sampling system 
(SASS) as 253–4,  254 
 RazorLame 113 
 R&B  see popular music recording 
 RealPlayer Cloud 113 
 real-time streaming of live concert 
118–22,  119, 121 
 real-world example: of classical 
music recording 166–9; of 
popular music recording 101–7 
 recorder: handheld  10, 10–11,  11 ; 
multitrack 18–19,  19, 20 
 recorder-mixer 19–21,  21 
 recording 81–2; backup of 82, 83; 
binaural 145, 199, 257–65; 
off board 34–5; real-world 
example of 101–7; teardown 
after 82;  see also classical 
music recording; multitrack 
recording; popular music 
recording; stereo recording 
 recording angle and standard 
deviation 241–2 
 recording device: laptop as  12, 
12–13,  13 ; in multitrack 
recording systems 18–19, 
 19, 20 ; stereo 9–13 
 recording levels 45, 80 
 recording mixer setup 68 
 recording session, real-world 
example of 103 
 recording techniques 33–50; 
connecting PA mixer insert 
sends to multitrack recorder 
as  41–3, 41–5; digital console 
recording facilities as 45–6; 
multitrack recording in truck as 
49–50; recording off the board 
as 34–5; recording with four-
tracker as  40, 40–1; recording 
with handheld recorder as 
 35, 35–40,  38, 39 ; splitting mic 
signals as 46–9,  47, 48  
 redundant systems 61 
 reﬂ ections: in localization 192; too 
loud 175–6 
 Remin Kart-a-Bag 59 
 re-recording 88; real-world 
example of 105 
 resolution 23–4 
 reverberation (reverb): in mixing 90; 
not enough 172; too much 172 
 ReverbNation 115 
 ribbon mics 5, 15, 129 
 ripper 112 
 rock music  see popular music 
recording 
 Rock n Roller 59 
 Rode NT4 XY stereo microphone 
182,  183 
 Rogue Amoeba 120 
 Roland M-200i digital console 46 
 rough mix 104 
 rumble from air conditioning, 
trucks, etc. 176–7 
 Sabra Som SSM-1 shock mount 151 
 SAM (Surround Ambiance 
Microphone) array 275 
 sampling frequency 24–5 
 sampling rate 24–5 
 Sanken surround miking 271 
 SASS (Stereo Ambient Sampling 
System) 253–4,  254 
 sax miking 71 
 Schneider disk 231 
 Schoeps KFM 360 Sphere 
Microphone 145,  145, 182 
 self-noise of microphone 129 
 sensitivity of microphone 129 
 setting levels 45, 80 
 setup 63–81; of audience 
microphones 78–9,  79 ; of 
discrete mics for video 
shoots 77–8, 163; electric-
guitar grounding in 78; 
interconnecting multiple 
sound systems in  66, 66–7; 
of levels and submixes 80–1; 
mic connections in 67; mic 
techniques in 68–77,  70–7 ; 
power distribution system 
in 63–4,  64 ; power source in 
64–6; preparing for easier 
58–61,  60 ; real-world example 
of 103; of recording mixer 68; 
running cables in 67; for stereo 
recording 153, 167–8 
 “shadowing” of sound traveling 
around sphere 199 
 shaker miking 72 
 shock mounts 16, 134, 151 
 Shoutcast 121 
 shufﬂ er circuit, coincident systems 
with 238 
 shufﬂ ing 212–13 
 Shure A27M stereo microphone 
adapter 187,  187 
 Shure A55 M shock mount 151 
 Shure S15A mic stand 151 
 Shure SCM810 automated mixer 75 
 side-addressed large-diaphragm 
microphone 130,  130, 179 
 signal ﬂ ow: in multitrack recording 
system 14–15,  15 ; in stereo 
recording system  4, 4–5 
 signal-to-noise (S/N) ratio of 
mics 9 
 site survey 53–4 
 Slotte, Benedict 277 
 Slotte method 277,  277 
 Smith, Bennett 242–3 
 smoothing ﬁ lter 23 
 SMP (Stereo Microphone 
Positioner) 186,  186 
 snake(s) 14, 16,  17, 59–61,  60 
 snake reels 59 
 S/N (signal-to-noise) ratio of mics 9 
 softness, bad balance of 176 
 software for web audio 112–13 
 Solid State Logic (SSL) Live digital 
console 46 
 solid-state recorder  10, 10–11,  11 
 soloist: pickup for 160–2; too much 
movement by 173–4;  see also 
classical music recording 
 song clips 84,  85, 94–5,  96 
 song mixing 88–90 
 song projects, splitting of 
multitrack recording into 
86–7,  87 
 song samples 94–5,  96 
 sonic shadow 259 
 Sonic Studios binaural 
microphones 40, 260–1 
 Sonic Studios DSM-4CS four-
channel surround dummy 
head 276 
 Sonic Studios GUY 260 
 Sonic Studios LiteGUY 260 
 sound check 80; real-world 
example of 103 
 SoundCloud 116, 118 

319
Index
SoundField 5.1 microphone 
system 270
SoundField Mk V microphone 
237, 237–8
SoundField Surround Decoder 270
sound pickup patterns 6, 125–8, 
127; advantages of 128
sound pressure level (SPL) 
meter 91
Sound Professionals 182
sound source localization 192–4, 
192–5
source angle in image localization 
207, 208, 209–10, 210
spaced-pair techniques 140–3, 141, 
227–31; Decca Tree as 229–31, 
230; key features of 146; omnis 
spaced 3 feet apart as 227–8, 
228; omnis spaced 10 feet apart 
as 228, 229; three omnis spaced 
5 feet apart (10 feet end to end) 
as 229, 230
spacial enhancement in stereo and 
surround recording 244–5
spaciousness 211–13; lack of 175
spatial effect 245
spatial equalization 211–13; 
coincident systems with 238
spatial transfer function of 
stereophonic systems 243
speaker arrangement for surround 
sound 268, 268–70
speaker(s) for multichannel 
recording 31
spectral analysis 98, 99
sphere, “shadowing” of sound 
traveling around 199
sphere microphone 145, 145, 
255, 261
splitters 15, 29–30, 29–31; use of 49
splitting of mic signals 46–9, 47, 48
SPL (sound pressure level) meter 
91
Spotify 121
spot microphones 160–2
Sprey, Pierre 136
SSL (Solid State Logic) Live digital 
console 46
stage box 14, 16, 17
stage plot diagram 52, 53
stage width see stereo spread
Stamp ID3 Tag Editor 113
standard deviation, recording 
angle and 241–2
stand-mounted stereo mic 8
Stealthy Cardioid set 185
Steam Powered Preservation 
Society 40
Stereo 180 System 239, 239
Stereo Ambient Sampling System 
(SASS) 253–4, 254
stereo bar 8, 9, 133, 133, 151, 186, 
186–7, 187
stereo images and imaging 
189–215; choosing angling 
and spacing for 210–11; 
definitions for 189–91; depth 
of 191; elevation of 191; focus 
or size of 191, 191; how to 
test for 147; localization of 
191, 192–7, 200–5; location of 
189–90, 190; movement of 191; 
poorly focused 174; predicting 
locations of 206–10, 207–10; 
requirements for natural 
imaging over loudspeakers 
in 197–200, 198; shifted to 
one side 174–5; spaciousness 
and spatial equalization for 
211–13; stereo spread or stage 
width in 190–1, 191; see also 
phantom images
stereo localization see localization
stereo microphone(s) 8, 132, 
132–3; examples of 181–2, 
181–3; “goosenoose” 8; mini 8, 
182; sources of 180; stand-
mounted 8
stereo microphone adapters 8, 9, 
133, 133, 151, 186, 186–7, 187
stereo microphone mount 8, 9, 133, 
133, 151, 186, 186–7, 187
Stereo Microphone Positioner 
(SMP) 186, 186
stereo microphone techniques 
135–48; advantages of 135–6; 
baffled-omni-pair 144, 144–5, 
145, 146; coincident-pair (XY) 
138, 138–40, 145–6; comparison 
of 145–6; goals of 136–7, 137; 
how to test imaging with 147; 
mic requirements for 147; mid-
side (MS) 139–40, 140; near-
coincident-pair 143, 143–4, 
146; recommended reading on 
147–8; spaced-pair (AB) 140–3, 
141, 146; types of 137–45
stereo pair plus surround pair 278
stereophonic listening tests, 
comparative 242
stereophonic sound recording: 
new method for spatial 
enhancement in 244–5; unified 
theory of microphone systems 
for 241–2
stereophonic systems: comparative 
spatial transfer function of 243; 
computer-aided model of 242–5
stereo rail 8, 9, 133, 133, 151, 186, 
186–7, 187
stereo recording devices 9–13; 
flash-memory handheld 
recorder as 10, 10–11, 11; 
iPad with recording app 
and plug-in stereo mic as 11; 
laptop, recording software, 
and audio interface as 11, 
11–12, 12
stereo recording procedures 
149–69; connections as 155–6; 
editing as 164–6, 165, 168–9; 
for electronic music 162–3; 
equipment for 5–14, 149––152; 
microphone placement as 
156–64; miking distance as 
156–8, 158; monitoring as 151, 
152, 156; mounting mics as 
153–5, 154; preparation for 
166–7; real-world example of 
166–9; recording as 164, 168; 
references on 169; session 
setup as 153, 167–8; setting 
levels as 163–4; soloist pickup 
and spot microphones as 
160–2; stereo-spread control as 
159–60; venue selection in 152; 
for video shoots 163
stereo recording systems 5–14; 
headphones or earphones 
in 14; microphones in 5–9, 7; 
multitrack vs. 3–4; recording 
devices in 9–13, 10–13; signal 
flow in 4, 4–5
stereosonic technique 222–3, 223
stereo sound problems 171–7; bad 
balance (some instruments 

320
Index
too loud or too soft) as 176; 
bad tonal balance (too dull, 
too bright, colored) as 177; 
distortion in microphone 
signal as 171; early reﬂ ections 
too loud as 175–6; excessive 
separation, hole-in-the-
middle, or soloist moves too 
much as  173, 173–4; images 
shifted to one side (faulty 
left-right balance) as 174–5; 
lack of depth as 175; lack of 
spaciousness as 175; muddy 
bass as 176; narrow stereo 
spread as 173,  173 ; poorly 
focused images as 174; rumble 
from air conditioning, trucks, 
etc. as 176–7; too dead (not 
enough reverberation) as 172; 
too detailed, close, or edgy 
as 172; too distant (too much 
reverberation) as 172 
 stereo spread: control of 159–60; 
deﬁ ned 190–1,  191 ; monitoring 
of 160; narrow 137,  137, 173, 
 173 
 streaming: vs. downloading 109; 
real-time of live concert 
118–21,  119, 121 ; video 122 
 streaming service provider 120–1 
 string quartet  see classical music 
recording 
 submixes 80–1 
 subwoofer channel 90; in surround 
speaker arrangement 268 
 supercardioid mics 6, 37, 69, 126, 
 127 
 Surround Ambiance Microphone 
(SAM) array 275 
 surround microphones 183,  184 
 surround sound, mixing for 90–2 
 surround sound miking techniques 
267–79; Chris Burmajster 
array as  275, 275–6; Delos VR 2 
surround miking method as 
270–1,  271 ; DMP method as 
273,  274 ; double MS technique 
as  274, 274–5; Holophone 
H2-PRO surround mic as 276; 
Ideal Cardioid Arrangement 
as 276,  276 ; KFM 360 
surround miking system as 
271–3,  272 ; Martin method 
as 277,  278 ; NHK methods 
as 271,  272 ; recommended 
readings on 278–9; Slotte 
method as 277,  277 ; Sonic 
Studios DSM-4CS four-
channel surround dummy 
head as 276; SoundField 5.1 
microphone system as 270; 
stereo pair plus surround pair 
as 278; Surround Ambience 
Microphone (SAM) array as 
275; Williams ﬁ ve cardioid mic 
array as 274,  274 
 surround sound recording, 
new method for spatial 
enhancement in 244–5 
 surround speaker arrangement  268, 
268–70 
 Sweetwater Sound 25 
 Switch WAV to MP3 Converter 
113 
 synthesizer miking 71 
 talk-back mic 61 
 tape measure 152 
 Tascam HD-P2 recorder  11 
 teardown 82 
 template for mixing 90 
 10º averaged free-ﬁ eld equalization 
262 
 Theile, Gunther 261, 275 
 3-pin connector 6,  7 
 time-code feed 81 
 time differences: localization by 
 203, 203–4,  204 ; localization by 
amplitude and 204–5,  205 
 tip-ring-sleeve (TRS) connector 34, 
43,  43, 60 
 tip-ring-sleeve–to–dual tip-sleeve 
(TRS-to-dual-TS) adapters 
60–1 
 tonal balance, bad 177 
 tool kit 58 
 track sheet 55; real-world example 
of 102 
 transaural converter 199 
 transducer type, of microphone 
128–9 
 transformer-isolated splitters 
29–30,  30 
 transients, localization of 193 
 TRS (tip-ring-sleeve) connector 34, 
43,  43, 60 
 TRS-to-dual-TS (tip-ring-sleeve–to–
dual tip-sleeve) adapters 60–1 
 trucks: multitrack recording in 
49–50; rumble from 176–7 
 TuneCore 116 
 two-track recording, editing of 
83–4,  85 
 unidirectional microphones 6, 
15, 126,  127 ; ﬂ oor-mounted 
boundary 251–2,  252 
 uninterruptible power supply 
(UPS) 57, 66 
 Universal Serial Bus  see USB 
 unwanted material, deletion of 88 
 uploading for web audio 
114–16,  115 
 upright piano miking 73 
 UPS (uninterruptible power 
supply) 57, 66 
 USB adapter 13 
 USB connector 8 
 USB microphones 8 
 USB mixer in digital audio 
workstation 26–7 
 USB ports 11, 83 
 variable bit rate (VBR) 111 
 VENUE console 45–6 
 venue selection 51, 152 
 video shoots, discrete miking for 
77–8, 163 
 video streaming 122 
 video time-code feed 81 
 Virtual Reality Recording (VR 2 ) 
format 270–1,  271 
 vocal miking 70 
 Voxengo Span spectrum analyzer 
98,  99 
 walkie-talkies 61 
 WAVE (.WAV) ﬁ les 36, 109–10, 111 
 web audio 109–22; data 
compression for 109–11,  110 ; 
ﬁ le formats for 111–12; how 
to prepare and upload ﬁ les 
for 114–16,  115 ; putting your 
music on your website for 
116–17; real-time streaming of 
live concert in 118–22,  119, 121 ; 

321
Index
software for 112–13; streaming 
vs. downloading of 109 
 webcast 118–22,  119, 121 
 website, putting your music on 
your 116–17 
 wheel(s), equipment on 59 
 wheeled cart 59 
 Whirlwind Line Balancer/Splitter 
(LBS) 66 
 Whirlwind snake reel 59 
 Whirlwind W1 or W2 60 
 Williams, Michael 241–2, 274 
 Williams ﬁ ve cardioid mic array 
274,  274 
 Windows Media Audio (WMA) 
encoder 113 
 Windows Media Audio (WMA) 
ﬁ les 110, 111–12 
 Windows Media Player 113 
 Windows Media Player 12 112 
 Windows Media Technologies 113 
 windscreen for mic 9, 16 
 wiring, multitrack 60–1 
 Wittig, Curt 62, 274 
 WMA (Windows Media Audio) 
encoder 113 
 WMA (Windows Media Audio) 
ﬁ les 110, 111–12 
 words 23–4 
 worship leader miking 75 
 Woszczyk, Wieslaw 244–5 
 XLR connectors 6,  7 
 XLR-to-phone adapters 6,  7 
 XY technique  138, 138–40, 145–6; 
vs. MS technique 244 
 Yamaha CL5 digital console 46 
 Y-splitters 30,  31 
 Zoom H4n recorder  10 
 Zoom R16 recorder-mixer  21 

