Preface
The area of stochastic programming was created in the middle of the last
century,
following
fundamental
achievements
in
linear
and
nonlinear
programming. While it has been quickly realized that the presence of
uncertainty in optimization models creates a need for new problem formul-
ations, many years have passed until the basic stochastic programming models
have been formulated and analyzed. Today, stochastic programming theory
oﬀers a variety of models to address the presence of random data in
optimization problems: chance-constrained models, two- and multi-stage
models, models involving risk measures. New problem formulations appear
almost every year and this variety is one of the strengths of the ﬁeld.
Stochastic programming can be quite involved, starting with sophisticated
modeling and is based on advanced mathematical tools such as nonsmooth
calculus, abstract optimization, probability theory and statistical techniques.
One of the objectives of this Handbook is to bring these techniques together
and to show how they can be used to analyze and solve stochastic program-
ming models.
Because of the inherent diﬃculty of stochastic optimization problems, it
took a long time until eﬃcient solution methods have been developed. In the
last two decades a dramatic change in our abilities to solve stochastic
programming problems took place. It is partially due to the progress in large
scale linear and nonlinear programming, in nonsmooth optimization and
integer programming, but mainly it follows the development of techniques
exploiting speciﬁc properties of stochastic programming problems. Computa-
tional advances are also due to modern parallel processing technology.
Nowadays we can solve stochastic optimization problems involving tens of
millions of variables and constraints.
Our intention was to bring together leading experts in the most
important sub-ﬁelds of stochastic programming to present a rigorous
overview of basic models, methods, and applications of stochastic pro-
gramming. We hope that this Handbook will prove useful to researchers,
students, engineers and economists, who encounter in their work optimiza-
tion problems involving uncertainty. We also hope that our work will
encourage many to undertake research in this exciting and practically impor-
tant ﬁeld.
v

We want to thank all the Authors involved in this project for their
contributions. We also want to thank Darinka Dentcheva, Shabbir Ahmed,
Tito Homem-de-Mello and Anton Kleywegt, who have helped us to review
and improve several chapters of this Handbook.
Andrzej Ruszczyn´ ski and Alexander Shapiro
December 2002.
vi
Preface

Contents
Preface
v
CHAPTER 1
Stochastic Programming Models
A. Ruszczyn´ ski and A. Shapiro
1
1. Introduction
1
2. Two-stage models
11
3. Multistage models
22
4. Robust and min–max approaches to stochastic optimization
48
5. Appendix
55
6. Bibliographic notes
62
References
63
CHAPTER 2
Optimality and Duality in Stochastic Programming
A. Ruszczyn´ ski and A. Shapiro
65
1. Expectation functions
65
2. Two-stage stochastic programming problems
72
3. Multistage models
93
4. Optimality conditions, basic case
97
5. Optimality conditions for multistage models
99
6. Duality, basic case
103
7. Duality for multistage stochastic programs
115
8. Min–max stochastic optimization
122
9. Appendix
126
10. Bibliographic notes
137
References
138
CHAPTER 3
Decomposition Methods
A. Ruszczyn´ ski
141
1. Introduction
141
2. The cutting plane method
144
3. Regularized decomposition
161
4. Trust region methods
175
vii

5. Nested cutting plane methods for multistage problems
180
6. Introduction to dual methods
187
7. The dual cutting plane method
192
8. The augmented Lagrangian method
195
9. Progressive hedging
200
10. Bibliographic notes
207
References
209
CHAPTER 4
Stochastic Integer Programming
F.V. Louveaux and R. Schultz
213
1. Introduction
213
2. Structural properties
215
3. Algorithms
235
References
264
CHAPTER 5
Probabilistic Programming
A. Pre´ kopa
267
1. Model constructions
267
2. Convexity theory
272
3. Numerical solution of probabilistic constrained stochastic
programming problems
287
4. Dynamic type stochastic programming problems with
probabilistic constraints
309
5. Bounding, approximation and simulation of probabilities
311
6. Duality and stability
334
7. Selected applications
338
References
345
CHAPTER 6
Monte Carlo Sampling Methods
A. Shapiro
353
1. Introduction
353
2. Statistical properties of SAA estimators
357
3. Exponential rates of convergence
371
4. Validation analysis
382
5. Variance reduction techniques
393
6. Multistage stochastic programming
399
7. Stochastic generalized equations
410
8. Appendix
416
9. Bibliographic notes
421
References
423
viii
Contents

CHAPTER 7
Stochastic Optimization and Statistical Inference
G.Ch. Pﬂug
427
1. Uncertain and ambiguous optimization problems
427
2. The empirical problem
430
3. Properties of statistical estimates
433
4. Risk functionals and Lipschitz properties
445
5. Arithmetic means of of i.i.d. random variables
449
6. Entropic sizes of stochastic programs
458
7. Epiconvergence
461
8. Epipointwise convergence for stochastic programs
467
9. Asymptotic stochastic programs
470
10. Bibliographic remarks
479
References
480
CHAPTER 8
Stability of Stochastic Programming Problems
W. Ro¨ misch
483
1. Introduction
483
2. General stability results
488
3. Stability of two-stage and chance constrained programs
510
4. Approximations of stochastic programs
538
5. Bibliographical notes
547
Acknowledgements
548
References
549
CHAPTER 9
Stochastic Programming in Transportation and Logistics
W.B. Powell and H. Topaloglu
555
1. Introduction
555
2. Applications and issues
557
3. Modeling framework
564
4. A case study: freight car distribution
576
5. The two-stage resource allocation problem
579
6. Multistage resource allocation problems
609
7. Some experimental results
623
8. A list of extensions
627
9. Implementing stochastic programming models in the
real world
629
10. Bibliographic notes
631
References
633
Contents
ix

CHAPTER 10
Stochastic Programming Models in Energy
S.W. Wallace and S.-E. Fleten
637
1. Introduction
637
2. Electricity in regulated markets
639
3. Electricity in deregulated markets
653
4. Oil
667
5. Gas
670
6. Conclusion
672
Acknowledgements
673
References
673
Subject Index
679
Contents of Previous Volumes
683
x
Contents

Chapter 1
Stochastic Programming Models
Andrzej Ruszczyn´ski
Department of Management Science and Information Systems, Rutgers University,
94 Rockefeller Rd, Piscataway, NJ 08854, USA
Alexander Shapiro
School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta,
GA 30332, USA
Abstract
In this introductory chapter we discuss some basic approaches to modeling of
stochastic optimization problems. We start with motivating examples and then
proceed to formulation of linear, and later nonlinear, two stage stochastic
programming problems. We give a functional description of two stage pro-
grams. After that we proceed to a discussion of multistage stochastic program-
ming and its connections with dynamic programming. We end this chapter by
introducing robust and min–max approaches to stochastic programming.
Finally, in the appendix, we introduce and brieﬂy discuss some relevant
concepts from probability and optimization theories.
Key words:
Two stage stochastic programming, expected value solution,
stochastic programming with recourse, nonanticipativity constraints, multistage
stochastic programming, dynamic programming, chance constraints, value at
risk, scenario tree, robust stochastic programming, mean–risk models.
1
Introduction
1.1
Motivation
Uncertainty is the key ingredient in many decision problems. Financial
planning, airline scheduling, unit commitment in power systems are just few
examples of areas in which ignoring uncertainty may lead to inferior or simply
wrong decisions. Often there is a variety of ways in which the uncertainty can be
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
1

formalized and over the years various approaches to optimization under
uncertainty were developed. We discuss a particular approach based on
probabilistic models of uncertainty. By averaging possible outcomes or
considering probabilities of events of interest we can deﬁne the objectives and
the constraints of the corresponding mathematical programming model.
To formulate a problem in a consistent way, a number of fundamental
assumptions need to be made about the nature of uncertainty, our knowledge
of it, and the relations of decisions to the observations made. In order to
motivate the main concepts let us start by discussing the following classical
example.
Example 1 (Newsvendor Problem). A newsvendor has to decide about the
quantity x of newspapers which he purchases from a distributor at the begin-
ning of a day at the cost of c per unit. He can sell a newspaper at the price s per
unit and unsold newspapers can be returned to the vendor at the price of r per
unit. It is assumed that 0  r < c < s. If the demand D, i.e., the quantity of
newspapers which he is able to sell at a particular day, turns out to be greater
than or equal to the order quantity x, then he makes the proﬁt sx  cx ¼ (s  c)x,
while if D is less than x, his proﬁt is sD þ r(x  D)  cx ¼ (r  c)x þ (s  r)D.
Thus the proﬁt is a function of x and D and is given by
Fðx, DÞ ¼
ðs  cÞx,
if x  D,
ðr  cÞx þ ðs  rÞD,
if x > D:

ð1:1Þ
The objective of the newsvendor is to maximize his proﬁt. We assume that
the newsvendor is very intelligent (he has Ph.D. degree in mathematics from a
prestigious university and sells newspapers now), so he knows what he is
doing. The function F(  , D) is a continuous piecewise linear function with
positive slope s  c for x < D and negative slope r  c for x>D. Therefore, if
the demand D is known, then the best decision is to choose the order quantity
x* ¼ D. However, in reality D is not known at the time the order decision
has to be made, and consequently the problem becomes more involved.
Since the newsvendor has this job for a while he collected data and has quite a
good idea about the probability distribution of the demand D. That is, the
demand D is viewed now as a random variable with a known, or at least well
estimated, probability distribution measured by the corresponding cumulative
distribution function (cdf) G(w) :¼ P(D  w). Note that since the demand
cannot be negative, it follows that G(w) ¼ 0 for any w < 0. By the Law of Large
Numbersthe averageproﬁtover along periodof timetendsto theexpected value
E½Fðx, DÞ ¼
Z 1
0
Fðx, wÞ dGðwÞ:
2
A. Ruszczyn´ski and A. Shapiro

Therefore, from the statistical point of view it makes sense to optimize the
objective function on average, i.e., to maximize the expected proﬁt E[F(x, D)].
This leads to the following stochastic programming problem1
Max
x0
f ðxÞ :¼ E½Fðx, DÞ


:
ð1:2Þ
Note that we treat here x as a continuous rather than integer variable. This
makes sense if the quantity of newspapers x is reasonably large.
In the present case it is not diﬃcult to solve the above optimization problem
in a closed form. Let us observe that for any D  0, the function F(  , D)
is concave (and piecewise linear). Therefore, the expected value function f(  ) is
also concave. Suppose for a moment that G(  ) is continuous at a point x>0.
Then
f ðxÞ ¼
Z x
0
½ðr  cÞx þ ðs  rÞw dGðwÞ þ
Z 1
x
ðs  cÞx dGðwÞ:
Using integration by parts it is possible to calculate then that
f ðxÞ ¼ ðs  cÞx  ðs  rÞ
Z x
0
GðwÞ dw:
ð1:3Þ
The function f(  ) is concave, and hence continuous, and therefore formula
(1.3) holds even if G(  ) is discontinuous at x. It follows that f(  ) is
diﬀerentiable at x iﬀ(that is, if and only if) G(  ) is continuous at x, in which
case
f 0ðxÞ ¼ s  c  ðs  rÞGðxÞ:
ð1:4Þ
Consider the inverse G  1() :¼ min{x: G(x)  } function2 of the cdf G,
which is deﬁned for  2 (0, 1). Since f(  ) is concave, a necessary and suﬃcient
condition for x*>0 to be an optimal solution of problem (1.2) is that
f 0(x*) ¼ 0, provided that f(  ) is diﬀerentiable at x*. Note that because
r < c < s, it follows that 0 < (s  c)/(s  r) < 1. Consequently, an optimal
solution of (1.2) is given by
x* ¼ G1 s  c
s  r


:
ð1:5Þ
This holds even if G(  ) is discontinuous at x*. It is interesting to note
that G(0) is equal to the probability that the demand D is zero, and
1 The notation ‘‘ :¼ ’’ means equal by deﬁnition.
2 Recall that G  1() is called the -quantile of the cdf G.
Ch. 1. Stochastic Programming Models
3

hence if this probability is positive and (s  c)/(s  r)  G(0), then the optimal
solution x* ¼ 0.
Clearly the above approach explicitly depends on the knowledge of the
probability distribution of the demand D. In practice the corresponding cdf
G(  ) is never known exactly and could be approximated (estimated) at best. In
the present case the optimal solution is given in a closed form and therefore its
dependence on G(  ) can be easily evaluated. It is well known that -quantiles
are robust (stable) with respect to small perturbations of the corresponding
cdf G(  ), provided that  is not too close to 0 or 1. In general, it is important
to investigate sensitivity of a considered stochastic programming problem with
respect to the assumed probability distributions.
The following deterministic optimization approach is also often used for
decision making under uncertainty. The random variable D is replaced by its
mean  ¼ E[D], and then the following deterministic optimization problem is
solved:
Max
x0
Fðx, Þ:
ð1:6Þ
A resulting optimal solution x is sometimes called the expected value
solution. In the present example, the optimal solution of this deterministic
optimization problem is x ¼ . Note that the mean solution x can be very
diﬀerent from the solution x* given in (1.5). It is well known that the quantiles
are much more stable to variations of the cdf G than the corresponding
mean value. Therefore, the optimal solution x* of the stochastic optimization
problem is more robust with respect to variations of the probability
distributions than an optimal solution x of the corresponding deterministic opti-
mization problem. This should be not surprising since the deterministic
problem (1.6) can be formulated in the framework of the stochastic
programming problem (1.2) by considering the trivial distribution of D being
identically equal to .
For any x, F(x, D) is concave in D. Therefore the following Jensen’s
inequality holds:
Fðx, Þ  E½Fðx, DÞ:
Hence
max
x0 Fðx, Þ  max
x0 E½Fðx, DÞ:
Thus the optimal value of the deterministic optimization problem is
biased upward relative to the optimal value of the stochastic optimization
problem. This should be also not surprising since the optimization problem
4
A. Ruszczyn´ski and A. Shapiro

(1.6) is ‘‘too optimistic’’ in the sense that it does not take into account possible
variability of the demand D.
Another point which is worth mentioning is that by solving (1.2) the
newsvendor tries to optimize the proﬁt on average. However, for a particular
realization of the demand D, on a particular day, the proﬁt F(x*, D) could be
very diﬀerent from the corresponding expected value f (x*). This may happen
if F(x*, D), considered as a random variable, has a large variability which
could be measured by its variance Var [F(x*, D)]. Therefore, if the newsvendor
wants to hedge against such variability he may consider the following
optimization problem
Max
x0
fðxÞ :¼ E½Fðx, DÞ  Var½Fðx, dÞ


:
ð1:7Þ
The coeﬃcient   0 represents the weight given to the conservative part of
the decision. If  is ‘‘large’’, then the above optimization problem tries to ﬁnd
a solution with minimal proﬁt variance, while if  ¼ 0, then problem (1.7)
coincides with problem (1.2). Since
Var½Fðx, DÞ ¼ E½Fðx, DÞ2  ½EFðx, DÞ2,
from a mathematical point of view problem (1.7) is similar to the expected
value problem (1.2). Note, however, that the additional (variance) term in
(1.7) destroys the convexity of the optimization problem (see Section 4 for a
further discussion).
The newsvendor may be also interested in making at least a speciﬁed
amount of money, b, on a particular day. Then it would be reasonable
to consider the problem of purchasing the minimum number of newspapers,
x, under the condition that the probability of making at least b is not
less than 1  , where  2 (0, 1) is ﬁxed. Such a problem can be formulated in
the form
Min x
ð1:8Þ
s:t:
P Fðx, DÞ  b


 1  :
ð1:9Þ
The newsvendor can solve this problem, too (remember that he is really
smart). It is clear that the following inequality should be satisﬁed
ðs  cÞx  b,
ð1:10Þ
since otherwise there is no way of making b. For a ﬁxed x satisfying this
condition, the proﬁt F(x, D) is a nondecreasing function of the demand D.
Ch. 1. Stochastic Programming Models
5

Therefore
P Fðx, DÞ  b


¼ P D  dðx, bÞ


,
where (after straightforward calculations)
dðx, bÞ ¼ b þ ðc  rÞx
s  r
:
It follows from (1.9) that d(x, b)  G  1(), which can be written as
b þ ðc  rÞx  ðs  rÞG1ðÞ:
ð1:11Þ
It is clear that the solution can exist iﬀthe constraints (1.10)–(1.11) are
consistent, that is, if
b  ðs  cÞG1ðÞ:
ð1:12Þ
Therefore, we obtain that problem (1.8)–(1.9) is feasible iﬀ(1.12) holds, in
which case it has the optimal solution
ˆx ¼
b
s  c :
ð1:13Þ
1.2
The basic model
Let us formalize optimization problems of the type discussed in the
newsvendor example. To this end we use the following notation and
terminology. By X we denote the space of decision variables. In most
applications considered in this book X can be identiﬁed with a ﬁnite
dimensional vector space Rn. It is assumed that there is a given set X  X of
feasible (or permissible) decisions and an (objective) function F(x, !) of
decision vector x  X and random element !. In an abstract setting
we consider ! as an element of a sample space  equipped with a sigma
algebra F. In typical applications considered in this book, the involved
random data is formed by a ﬁnite number of parameters. Consequently, the
objective function is given in the form Fðx, !Þ:¼ Vðx, ð!ÞÞ, where (!) is a
ﬁnite dimensional random vector and V(x, ) is a function of two vector
variables x and .
Of course, the mathematical programming problem of minimization
(or maximization) of F(x, !) subject to x 2 X depends on ! and does not make
much sense. For diﬀerent realizations of the random parameters one would
obtain diﬀerent optimal solutions without any insight which one is ‘‘better’’
6
A. Ruszczyn´ski and A. Shapiro

than the others. A way of dealing with that is to optimize the objective function
on average. This leads to the following mathematical programming problem
Min
x2X f ðxÞ :¼ E½Fðx, !Þ


:
ð1:14Þ
The above formulation of a stochastic programming problem assumes
implicitly that the expected value is taken with respect to a known probability
distribution (measure) P on (, F ) and that the expected value operator
E½Fðx, !Þ ¼
Z

Fðx, !Þ dPð!Þ
ð1:15Þ
is well deﬁned. We refer to the function f(x), deﬁned in (1.14), as the
expectation or expected value function. Note that we will have to deal with
extended real valued functions. That is, the function F(x, !) (as well as its
expectation) is allowed to take values þ 1 or  1. The precise meaning of
the involved concepts is discussed in the Appendix (Section 5).
1.3
Modeling the constraints
In (1.14) we have assumed that we have an explicit description of the
feasible set X. For example, the feasible set X can be written in a standard
mathematical programming formulation as follows
X :¼ fx 2 X0 : giðxÞ  0, i ¼ 1, . . . , mg,
ð1:16Þ
where X0 is a convex subset of X :¼ Rn and gi (x) are real valued functions.
When
the
uncertain
quantities
enter
the
‘raw’
constraints
of
our
background model,
Giðx, !Þ  0,
i ¼ 1, . . . , m,
ð1:17Þ
we need to specify what we mean by ‘feasibility’. Some values of x may satisfy
(1.17) for some ! and violate these conditions for other !. Often it is
unrealistic to require that constraints (1.17) should hold for all ! 2 . In our
newsvendor example, for instance, the requirement to make at least proﬁt
b can hardly be satisﬁed for all realizations of the demand D.
Several approaches can be used to introduce a meaningful notion of
feasibility in this context. One of them is to consider the expected values,
giðxÞ :¼ E½Giðx, !Þ,
i ¼ 1, . . . , m,
ð1:18Þ
as constraint functions in (1.16).
Ch. 1. Stochastic Programming Models
7

Expected value constraints usually occur in situations when we have, in
fact, several objectives, and we put some of them into the constraints, as in the
example below.
Example 2 (Reservoir Capacity). Consider the system of two reservoirs (Fig. 1),
whose objective is to retain the ﬂood in the protected area. The ﬂood is
produced by two random inﬂows, 1 and 2. Flood danger occurs once a year,
say, and 1, 2 appear simultaneously. The damage from ﬂood of size y  0 is
modeled as a convex nondecreasing function L( y), where L(0) ¼ 0. Our
objective is to determine the reservoir capacities, x1 and x2, so that the
expected damage from the ﬂood is below some speciﬁed limit b, and the cost of
the reservoirs, f (x1, x2) is minimized.
The size of the ﬂood is random and is given by the expression
y ¼ max 0, 1 þ 2  x1  x2, 2  x2
f
g:
Our problem takes on the form
Min f ðx1, x2Þ
s:t:
E Lðmaxf0, 1 þ 2  x1  x2, 2  x2gÞ
½
  b:
x1  0, x2  0:
ð1:19Þ
It would be an error to replace the random inﬂows in this problem by their
expected values, 1 and 2. By Jensen’s inequality we have
Lðmaxf0, 1 þ 2  x1  x2, 2  x2gÞ
 E Lðmaxf0, 1 þ 2  x1  x2, 2  x2gÞ
½
;
and the diﬀerence may be large, even for a linear function L(  ). As a result,
the expected losses from a ﬂood may be much higher than foreseen by a naive
deterministic model.
Another way to deﬁne the feasible set is to use constraints on the
probability of satisfying (1.17):
P Giðx, !Þ  0


 1  ,
i ¼ 1, . . . , m,
ð1:20Þ
Fig. 1. The water reservoir system.
8
A. Ruszczyn´ski and A. Shapiro

with some ﬁxed  2 (0,1) (as in our newsvendor example). Such constraints are
called probabilistic or chance constraints.3
For a set A we denote by 1A(  ) its characteristic function,
1AðtÞ :¼
1,
if t 2 A,
0,
if t 62 A:

ð1:21Þ
Then (1.20) can be written as the expected value constraints
E½1ð1, 0ÞðGiðx, !ÞÞ  1  ,
i ¼ 1, . . . , m:
ð1:22Þ
Note, however, that the discontinuity of the characteristic function makes
such constraints very speciﬁc and diﬀerent from the ‘standard’ expected value
constraints.
Following is an example where probabilistic constraints appear in a natural
way.
Example 3 (Value at Risk). Suppose that there are n investment opportunities,
with random returns R1, . . . , Rn in the next year. We have a practically
unlimited initial capital and our aim is to invest some of it in such a way that
the expected value of our investment after a year is maximized, under the
condition that the chance of losing no more than some ﬁxed amount b>0 is at
least 1  , where  2 (0, 1). Such a requirement is called the Value at Risk
constraint.
Let x1, . . . , xn be the amounts invested in the n opportunities. The
net increase of the value of our investment after a year is Gðx, RÞ ¼ Pn
i¼1 Rixi:
Our problem takes on the form of a probabilistic constrained stochastic
program:
Max
X
n
i¼1
ixi
s:t:
P
X
n
i¼1
Rixi  b
(
)
 1  ,
x  0,
ð1:23Þ
where i ¼ E½Ri. Note that for the sake of simplicity we do not impose here
the constraint x1 þ    þ xn ¼ W0, where W0 is the total invested amount, as
compared with the example of ﬁnancial planning (Example 7) discussed later.
3 In the extreme case when  ¼ 0, conditions (1.20) mean that constraints Gi(x, !)  0, i ¼ 1, . . . , m,
should hold for a.e. ! 2 .
Ch. 1. Stochastic Programming Models
9

If the returns have a joint normal distribution with the covariance matrix
, the distribution of the proﬁt (or loss) is normal, too, with the expected
value Tx, and variance xTx. Consequently, ðGðx, RÞ  TxÞ=
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTx
p
has the
standard normal distribution (i.e., normal distribution with mean zero and
variance one). Our probabilistic constraint is therefore equivalent to the
inequality
b þ Tx
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTx
p
 z,
where z is the (1  )-quantile of the standard normal variable. If   1/2 then
z  0. After elementary manipulations we obtain the following convex
programming equivalent of problem (1.23)
Max Tx
s:t:
z
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTx
p
 Tx  b,
x  0:
ð1:24Þ
If we ignore the nonnegativity constraint on x we can solve this problem
analytically. Indeed, x ¼ 0 is a feasible solution and both functions are
positively homogeneous in x, so either the probabilistic constraint has to be
satisﬁed as an equality or the problem is unbounded. Let   0 be the
Lagrange multiplier associated with this constraint. We obtain the equation
ð1 þ Þ  zx
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTx
p
¼ 0:
From here we deduce that there must exist a scalar t such that x ¼ t. We
assume that the matrix  is nonsingular and  6¼ 0. Substitution to the
constraint
yields
(after
simple
calculations)
t ¼ b=ðz  Þ
and
 ¼
ðz=  1Þ1, with  :¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
T1
p
(note that 1 is positive deﬁnite and
hence T1 is positive). If   z, then the problem is unbounded, i.e., its
optimal value is þ 1. If  < z, then the vector
ˆx :¼
b
ðz  Þ 1
is the solution to the problem without sign restrictions on x. If, in addition,
1  0, then the vector ˆx solves our original problem. Otherwise, numerical
methods of convex programming are needed to ﬁnd the optimal solution.
10
A. Ruszczyn´ski and A. Shapiro

In many practical situations, though, the returns are not jointly normally
distributed, and even the single Value at Risk constraint, like the one analyzed
here, may create signiﬁcant diﬃculties.
Let us now assume that our planning horizon is T years, and let
R1(t), . . . , Rn(t) be the random investment returns in years t ¼ 1, . . . , T. We
want to maximize the expected value of our investment after T years, under
the condition that with probability at least 1   the value of our investment
will never drop by more than b from the initial amount invested. We do not
want to re-allocate our investment, we just want to invest once and then watch
our wealth grow (hopefully).
Let x1, . . . , xn be the amounts invested in the n opportunities. The net
change in the value of our investment in year t is
Gðx, R, tÞ ¼
X
n
i¼1
SiðtÞxi,
where SiðtÞ :¼ t
¼1ð1 þ RiðÞÞ  1 is the compounded return of investment
i up to year t. Denoting i :¼ E[Si (T)], our problem takes on the form:
Max
x0
X
n
i¼1
ixi
s:t:
P Gðx, R, tÞ  b, t ¼ 1, . . . , T


 1  :
ð1:25Þ
This is an example of a problem with a joint probabilistic constraint,
which is diﬀerent from imposing the constraints PfGðx, R, tÞ  bg 
1  , t ¼ 1, . . . , T, requiring that for each year the probability of losing
no more than b is 1   or higher. A joint probabilistic constraint can be
formally treated as a constraint for one function, deﬁned as the worst case
among
the
individual
constraints.
In
our
example
we
may
deﬁne
Gðx, RÞ :¼ min1tT Gðx, R, tÞ and require that
PfGðx, RÞ  bg  1  :
ð1:26Þ
Such constraints may be diﬃcult to handle, both theoretically and
computationally.
2
Two-stage models
2.1
The linear model
We can view the decision problem which the newsvendor faces in Example 1
as two stage. In the morning, before a realization of the demand D is known,
Ch. 1. Stochastic Programming Models
11

he has to decide about the quantity x of newspapers which he purchases for
that day. By the end of the day when value of D becomes known, he optimizes
his behavior by selling as many newspapers as possible. Although simple, his
second stage decision can be also formulated as an optimization problem.
His second stage decision variables can be deﬁned as the quantity y which he
sells at price s, and the quantity z which he returns at price r. Then, given a value
of the ﬁrst stage decision variable x and a realization of the demand D, the
second stage problem consists of maximizing the proﬁt and can be written as
follows
Max
y, z
sy þ rz
subject
to
y  D, y þ z  x, y  0, z  0:
The
optimal
solution
of
the
above
problem
is
y* ¼ minfx, Dg,
z* ¼ maxfx  D, 0g, and its optimal value is the proﬁt F(x, D) deﬁned in (1.1).
This is the basic idea of a two stage process. At the ﬁrst stage, before a
realization of the corresponding random variables becomes known, one
chooses the ﬁrst stage decision variables to optimize the expected value of an
objective function which in turn is the optimal value of the second stage
optimization problem. A two-stage stochastic linear program can be written as
follows
Minx cTx þ E½Qðx, ð!ÞÞ
s:t:
Ax ¼ b, x  0,
ð2:2Þ
where Q(x, ) is the optimal value of the second stage problem
Miny qTy
s:t:
Tx þ Wy ¼ h, y  0:
ð2:3Þ
Here x and y are vectors of ﬁrst and second stage decision variables,
respectively. The second stage problem depends on the data  :¼ (q, h, T, W ),
some (all) elements of which can be random. Therefore we view  ¼ (!) as a
random vector. The expectation in (2.2) is taken with respect to the probability
distribution of (!), which is supposed to be known. The matrices T and W are
called the technology and recourse matrices, respectively. If the matrix W is ﬁxed
(not random), the above two-stage problem is called the problem with ﬁxed
recourse. In a sense the second stage problem (2.3) can be viewed as a penalty
term for violation of the constraint Tx ¼ h, hence is the name ‘‘with recourse’’.
For any x and  the function Q(x, ), although not given explicitly, is a well
deﬁned extended real valued function: it takes the value þ 1 if the feasible set
of the second stage problem (2.3) is empty, and the value  1 if the second
12
A. Ruszczyn´ski and A. Shapiro

stage problem is unbounded from below. As it is discussed in Section 5.2, it
should be veriﬁed that the expected value in (2.2) is well deﬁned. It is
worthwhile to note at this point that problem (2.2) is a particular case of the
stochastic programming problem (1.14) with Fðx, !Þ :¼ cTx þ Qðx, ð!ÞÞ and
X :¼ fx: Ax ¼ b, x  0g.
By the deﬁnition of the function Q(x, ) we have that it can be written in the
form Qðx, Þ ¼ Qðh  TxÞ, where
QðÞ :¼ inffqTy: Wy ¼ , y  0g:
ð2:4Þ
By the duality theory of linear programming the optimal value Q()
of the linear program in the right hand side of (2.4) is equal to sup
f	T: WT	  qg,unlessbothsystems:Wy ¼ ,y  0andWT	  q,areinfeasible.
Consequently,
Qðx, Þ ¼ sup 	Tðh  TxÞ: WT	  q


:
ð2:5Þ
The feasible set {	: WT	  q} of the dual problem is convex polyhedral.
Therefore, for any realization of random data , the function Q(  , ) is
convex piecewise linear. Chapter ‘‘Optimality and Quality in Stochastic
Programming’’ of this book provides a detailed analysis of the properties of
Q(  , ) and of its expected value.
2.2
The case of discrete distributions
There are equivalent formulations of the two-stage linear recourse problem
(2.2)–(2.3) which are useful in diﬀerent situations. In order to simplify
the presentation and to defer technical details let us assume now that the
random data have a discrete distribution with a ﬁnite number K of possible
realizations k ¼ (qk, hk, Tk, Wk), called scenarios, with the corresponding
probabilities pk. In that case E½Qðx, Þ ¼ PK
k¼1 pkQðx, kÞ where
Qðx, kÞ ¼ inffqT
k yk : Tkx þ Wkyk ¼ hk, yk  0g:
ð2:6Þ
Consequently, we can write (2.2)–(2.3) in the form
Min
x, y1,..., yk cTx þ
X
K
k¼1
pkqT
k yk
s:t:
Ax ¼ b,
Tkx þ Wkyk ¼ hk,
k ¼ 1, . . . , K,
x  0, yk  0,
k ¼ 1, . . . , K:
ð2:7Þ
That is, the two-stage problem can be formulated as one large linear
programming problem.
Ch. 1. Stochastic Programming Models
13

Example 4 (Capacity Expansion). Consider a directed graph with node set N
and arc set A. With each arc a 2 A we associate a decision variable xa and call
it the capacity of a. There is a cost ca for each unit of capacity of arc a.
For each pair of nodes (m, n) 2 N  N we have a random demand Dmn for
shipments from m to n. These shipments have to be sent through the network
and they can be arbitrarily split into pieces taking diﬀerent paths. We denote
by ymn
a
the amount of the shipment from m to n sent through arc a. There is a
unit cost qa for shipments on each arc a.
Our objective is to assign arc capacities and to organize shipments in such a
way that the expected total cost, comprising the capacity cost and the shipping
cost, is minimized. The condition is that the capacities have to be assigned
before the actual demands Dmn become known, while the shipments can be
arranged after that.
We recognize in this model a linear two-stage stochastic programming
model with ﬁrst stage variables xa, a 2 A, and second stage variables
ymn
a , a 2 A, (m, n) 2 N  N.
Let us deﬁne the second stage problem. For each node i denote by A þ(i)
and A (i) the sets of arcs entering and leaving node i. The second stage
problem is the multicommodity network ﬂow problem
Min
X
m, n2N
X
a2A
qaymn
a
s:t:
X
a2AþðiÞ
ymn
a

X
a2AðiÞ
ymn
a
¼
Dmn,
if i ¼ m,
Dmn,
if i ¼ n,
0,
otherwise,
8
><
>:
X
m, n2N
ymn
a
 xa,
a 2 A,
ymn
a
 0,
a 2 A, i, m, n 2 N :
ð2:8Þ
This problem depends on the random demand vector D and on the arc
capacities, x. Its optimal value will be denoted Q(x, D).The ﬁrst stage problem
has the form
Min
x0
X
a2A
caxa þ E½Qðx, DÞ:
In this example only some right hand side entries in the second stage
constraints are random. All the matrices and cost vectors are deterministic.
Nevertheless, the size of this problem, even for discete distributions of the
demands, may be enormous. If the number of nodes is 
, the demand vector
has 
(
  1) components. If they are independent, and each of them has r
possible realizations, we have to deal with K ¼ r
(
  1) scenarios. For each of
14
A. Ruszczyn´ski and A. Shapiro

them the second stage vector has j
ð
  1ÞjAjj components and there are

2ð
  1Þ þ jAj constraints (excluding nonnegativity constraints). As a result,
the large scale linear programming formulation has jAj þ 
ð
  1ÞjAjr
ð
1Þ
variables and ð
2ð
  1Þ þ jAjÞr
ð
1Þ constraints. These are large numbers,
even for moderately sized networks and distributions with only few
possibilities.
A more complex situation occurs when the arcs are subject to failures and
they may lose random fractions a of their capacities. Then the capacity
constraint in the second stage problem has a slightly diﬀerent form:
X
m, n2N
ymn
a
 ð1  aÞxa,
a 2 A,
and we have a two-stage problem with a random ‘technology’ matrix. Its
complexity, of course, is even higher than before.
2.3
Scenario formulation and nonanticipativity
Let us relax problem (2.7) by replacing the ﬁrst stage decision vector x by K
possibly diﬀerent vectors xk. We obtain the problem
Min
x1,..., xK
y1,..., yK
X
K
k¼1
pkðcTxk þ qT
k ykÞ
s:t:
Axk ¼ b,
Tkxk þ Wkyk ¼ hk;
xk  0, yk  0,
k ¼ 1, . . . , K:
ð2:9Þ
Problem (2.9) is separable in the sense that it can be split into K smaller
problems, one for each scenario, and therefore it is much easier for a
numerical solution. However, (2.9) is not suitable for modeling a two stage
process. This is because the ﬁrst stage decision variables xk in (2.9) are now
allowed to depend on a realization of the random data at the second stage.
This can be ﬁxed by introducing the additional constraints
xk ¼ xj,
for all 1  k < j  K:
ð2:10Þ
Together with the additional constraints (2.10), problem (2.9) becomes
equivalent to (2.7).
Constraints (2.10) are called nonanticipativity constraints. They ensure that
the ﬁrst stage decision variables do not depend on the second stage realization
of the random data. Such nonanticipativity constraints will be especially
important in multistage modeling which we will discuss later.
Ch. 1. Stochastic Programming Models
15

In fact, some of the constraints in (2.10) are redundant; for example, it is
suﬃcient to require that xk ¼ xk þ 1 for k ¼ 1, . . . , K  1. There are many other
ways to express these conditions, but they all deﬁne the same linear subspace
of the space of decision variables of (2.9). A way to express the non-
anticipativity condition is to require that
xk ¼
X
K
i¼1
pixi,
k ¼ 1, . . . , K;
ð2:11Þ
which is convenient for extensions to the general case.
2.4
General formulation
As it was discussed above the essence of two stage modeling is that there are
two distinct parts of the decision vector. The value of the ﬁrst vector x 2 X,
with X ¼ Rn, has to be chosen before any realization of the unknown
quantities, summarized in the data vector  ¼ (!), are observed. The value of
the second part, y, can be chosen after the realization of  becomes known and
generally depends on the realization of  and on the choice of x. Consequently,
at the ﬁrst stage one has to solve the expectation optimization problem
Min
x2X E½Fðx, !Þ:
ð2:12Þ
In the case of two-stage linear problem (2.2),
Fðx, !Þ :¼ cTx þ Qðx, ð!ÞÞ
with Q(x, ) being the optimal value of the second stage optimization problem
(2.3) (viewed as an extended real valued function). In such formulation an
explicit dependence on the second stage decision variables y is suppressed. It
will be convenient to discuss that formulation ﬁrst.
As in the example of problem (2.9), we may relax the expectation problem
(2.12) by allowing the ﬁrst stage decision variables to depend on the random
data and then to correct that by enforcing nonanticipativity constraints.
Denote by M ¼ M(, F, X ) the space of measurable mappings4 x(  ):  ! X
such that the expectation E[F(x(!), !)] is well deﬁned. Then the relaxed
problem can be formulated in the form
Min
xðÞ2M E½Fðxð!Þ, !Þ:
ð2:13Þ
4 We write here x (  ), instead of x, in order to emphasize that x(  ) is not a vector, but rather a vector
valued function of !.
16
A. Ruszczyn´ski and A. Shapiro

Denote
#ð!Þ :¼ inf
x2X Fðx, !Þ
the optimal value function of problem (2.12).
Note that optimization in (2.13) is performed over all mappings x(!) in the
functional space M. In particular, if  :¼ {!1, . . . , !K} is ﬁnite, with respective
probabilities p1, . . . , pk, then x(!) can be identiﬁed with (x1, . . . , xK), where
xk:¼ xð!kÞ. In that case problem (2.13) can be written in the form
Min
x1,..., xK
X
K
k¼1
pkFðxk, !kÞ:
ð2:14Þ
Proposition 5. Suppose that: (i) the function F(x, !) is random lower
semicontinuous,5 (ii) either E½#ð!Þ þ  < þ 1 or E½ð#ð!ÞÞ þ  < þ 1. Then
inf
xðÞ2M E½Fðxð!Þ, !Þ ¼ E inf
x2X Fðx, !Þ


:
ð2:15Þ
Proof. Since F(x, !) is random lsc we have by Theorem 19 that #(!) is
measurable. Together with the assumption (ii) this implies that the expectation
in the right hand side of (2.15) is well deﬁned. For any x(  ) 2 M(, F, X ) we
have that F(x(!), !)  #(!) for all ! 2 , and hence the left hand side of (2.15)
is always greater than or equal to the right hand side of (2.15). Conversely, if
#(!)>  1 for a.e. ! 2 , then for any given ">0 and a.e. ! 2  there exists
an "-optimal solution ~xð!Þ. Moreover, since F(x, !) is random lsc, ~xð!Þ can be
chosen to be measurable, i.e., ~x 2 Mð, F, XÞ. It follows that
E½Fð ~xð!Þ, !Þ  E½#ð!Þ þ ":
Since " is an arbitrary positive number, this implies that the left hand side of
(2.15) is less than or equal to the right hand side of (2.15). Finally, if the event
‘‘#(!) ¼  1’’ happens with positive probability, then both sides of (2.15) are
equal to  1.
u
5 See Section 5.3 of the Appendix for the deﬁnition and discussion of random lower semicontinuous
functions.
Ch. 1. Stochastic Programming Models
17

We also have that problem (2.12) is equivalent to
Min
xðÞ2M E½Fðxð!Þ, !Þ
ð2:16Þ
s:t:
xð!Þ ¼ E½xð!Þ,
8! 2 :
ð2:17Þ
Constraints (2.17) give an extension of constraints (2.11), and represent the
nonanticipativity condition.6 Since problem (2.13) is a relaxation of (2.16)–
(2.17), and because of (2.15), we obtain that
inf
x2X E½Fðx, !Þ  E inf
x2X Fðx, !Þ


:
ð2:18Þ
The above inequality also follows directly from the obvious inequality
Fðx, !Þ  #ð!Þ for all x 2 X and ! 2 .
Let us give now a formulation where the second stage decision variables
appear explicitly:
Min
x2X E Vðx, ð!ÞÞ
½
,
ð2:19Þ
where Vðx, Þ is the optimal value of the second stage problem
Min
y2Y Fðx, y, Þ
s:t:
Giðx, y, Þ  0,
i ¼ 1, . . . , m:
ð2:20Þ
Here X is a subset of Rn1, Y is a subset of Rn2, and
F : Rn1  Rn2  Rd ! R,
Gi : Rn1  Rn2  Rd ! R,
i ¼ 1, . . . , m,
are the objective and the constraint functionals, respectively.
Alternatively, in an abstract form the above two stage stochastic
programming problem can be formulated as follows
Min
x2X, yðÞ2Y E Fðx, yð!Þ, ð!ÞÞ
½

ð2:21Þ
s:t:
Giðx, yð!Þ, ð!ÞÞ  0,
i ¼ 1, . . . , m,
ð2:22Þ
x 2 X,
ð2:23Þ
6 Since the expected value of two random variables which may diﬀer on a set of measure zero is the
same, it actually suﬃces to verify the constraints (2.17) for P-almost every ! 2 .
18
A. Ruszczyn´ski and A. Shapiro

yð!Þ 2 Y,
ð2:24Þ
where X :¼ Rn1 and Y is a space of measurable functions from  to Rn2. In
that formulation yð!Þ is viewed as a random vector in Rn2. Note, however, an
important diﬀerence between random vectors ð!Þ and yð!Þ. Vector ð!Þ
represents the random data of the problem with a given (known) distribution,
while yð!Þ denotes the second stage decision variables. We have explicitly
marked the dependence of y on the elementary event ! to stress the recourse
nature of these variables. The inequalities (2.22) and the inclusion (2.24) are
understood in the almost sure sense, i.e., they have to hold for P-almost every7
! 2 . Recall that the probability measure P on ð, FÞ generates the
corresponding probability distribution of ðð!Þ, yð!ÞÞ viewed as a random
vector. Therefore, ‘‘for P-almost every ! 2 ’’ means that the event happens
for almost every realization of the random vector ð, yÞ.
The diﬃculty in the formulation (2.21)–(2.24) is the fact that the second
stage decisions y are allowed to be functions of the elementary event !. We
need to specify from which classes of functions these decisions have to be
chosen, i.e., to deﬁne the functional space Y. The mappings y:  ! Rn2, have
to be measurable with respect to the sigma algebra F and such that the
expectation in (2.21) makes sense. Otherwise we shall not be able to talk in a
meaningful way about the expectation of the objective functional and the
‘almost sure’ satisfaction of the constraints. Moreover, in fact y is a function
of . Therefore, we can identify the probability space ð, F, PÞ with the
probability space ðRd, B, PÞ of the random vector , and view yðÞ as an
element of a space of measurable mappings from Rd into Rn2. In particular, in
the case of ﬁnitely many realizations 1, . . . , K, we can identify the sample
space with the set :¼ f1, . . . , Kg equipped with the sigma algebra of all its
subsets. In that case it suﬃces to consider mappings y: f1, . . . , Kg ! Rn2,
which could be identiﬁed with vectors y1, . . . , yK 2 Rn2. As a result, the
decision
space
in
the
case
of
ﬁnitely
many
realizations
is
just
Rn1  Rn2      Rn2
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
K times
:
The constraints (2.22)–(2.24) can be absorbed into the objective function by
deﬁning
Fðx, y, Þ :¼
Fðx, y, Þ,
if x 2 X, y 2 Y, Giðx, y, Þ  0, i ¼ 1, . . . , m,
þ 1,
otherwise:
(
7 Written: ‘‘a.e. ! 2 ’’.
Ch. 1. Stochastic Programming Models
19

Then problem (2.21)–(2.24) can be written in the form
Min
x2, yðÞ2Y E Fðx, yð!Þ, ð!ÞÞ


:
ð2:25Þ
In a way similar to the proof of Proposition 5 it is possible to show that the
two formulations (2.19)–(2.20) and (2.21)–(2.24) are equivalent if for every
x 2 X, the function Fðx,  , Þ is random lsc and the expectation of the optimal
value function infy2Rn2Fðx, y, ð!ÞÞ is well deﬁned.
Let us now consider both parts of the decision vector, x and y as random
elements. We obtain the problem
Min
xðÞ, yðÞ E½Fðxð!Þ, yð!Þ, ð!ÞÞ
s:t:
Giðxð!Þ, yð!Þ, ð!ÞÞ  0,
i ¼ 1, . . . , m,
xð!Þ 2 X, yð!Þ 2 Y:
All constraints here are assumed to hold P-almost surely, i.e., for a.e.
! 2 . The above problem is an analogue of (2.13) with optimization
performed over mappings ðxðÞ, yðÞÞ in an appropriate functional space, and as
in the ﬁnite scenario case, is a relaxation of the problem (2.21)–(2.24). To
make it equivalent to the original formulation we must add the nonanti-
cipativity constraint which can be written, for example, in the form (2.17).
For example, consider the two-stage linear program (2.2)–(2.3). We can
write it in the form
Min
x, yðÞ E cTx þ qð!ÞTyð!Þ


s:t:
Tð!Þx þ Wð!Þyð!Þ ¼ hð!Þ, a:e: ! 2 ,
Ax ¼ b, x  0,
yð!Þ  0, a:e: ! 2 ,
with yðÞ being a mapping from  into Rn2. In order for the above problem to
make sense the mapping yð!Þ should be measurable and the corresponding
expected value should be well deﬁned. Suppose for a moment that vector q is
not random, i.e., it does not depend on !. Then we can assume that yð!Þ is an
element of the space Ln2
1 ð, F, PÞ of F-measurable mappings8 y:  ! Rn2
8 In fact an element of Ln2
1 ð, F, PÞ is a class of mappings which may diﬀer from each other on sets of
P-measure zero.
20
A. Ruszczyn´ski and A. Shapiro

such that
R
 jjyð!Þjj dPð!Þ < þ 1. If qð!Þ is random we can consider a space
of measurable mappings yðÞ such that R
 jqð!ÞTyð!Þj dPð!Þ < þ 1.
2.5
Value of perfect information
Consider a two stage stochastic programming problem in the form (2.19)
with Vðx, Þ being the optimal value of the second stage problem (2.20). If we
have a perfect information about the data , i.e., the value of  is known at the
time when the ﬁrst stage decision should be made, then the optimization
problem becomes the deterministic problem
Min
x2X Vðx, Þ,
ð2:26Þ
and can be written in the following equivalent form
Minx2X, y2Y Fðx, y, Þ
s:t:
Giðx, y, Þ  0,
1, . . . , m:
ð2:27Þ
Of course, the optimal solution xðÞ (if it exists) and the optimal value ðÞ of
problem (2.26) depend on the realization  of the data. The average of ðÞ
over all possible realizations of the random data  ¼ ð!Þ, i.e., the expected
value
E½ðÞ ¼ E inf
x2X Vðx, ð!ÞÞ


,
ð2:28Þ
is called the wait-and-see solution.
We have that for any x 2 X and any  the inequality Vðx, Þ  ðÞ holds,
and hence
E Vðx, ð!Þ
½
  E inf
x2X Vðx, ð!ÞÞ


:
ð2:29Þ
Therefore, as it was mentioned earlier (see (2.18)), it follows that
inf
x2X E Vðx, ð!Þ
½
  E inf
x2X Vðx, ð!ÞÞ


:
ð2:30Þ
That is, the optimal value of the stochastic programming problem (2.19) is
always greater than or equal to E½ðÞ. Suppose further that problem (2.19)
has an optimal solution ˆx. We have that Vð ˆx, Þ  ðÞ is nonnegative for all ,
Ch. 1. Stochastic Programming Models
21

and hence its expected value is zero iﬀVð ˆx, Þ  ðÞ ¼ 0 w.p.1. That is, the
equality in (2.30) holds, iﬀ
Vð ˆx, ð!ÞÞ ¼ inf
x2X Vðx, ð!ÞÞ
for a:e: ! 2 :
ð2:31Þ
In particular, the equality in (2.30) holds, if there exists an optimal solution
of (2.26) which does not depend on  w.p.1.
The diﬀerence Vð ˆx, Þ  ðÞ is the value of perfect information of knowing
the realization . Consequently,
EVPI :¼ inf
x2X E Vðx, ð!ÞÞ
½
  E inf
x2X Vðx, ð!ÞÞ


ð2:32Þ
represents the expected value of perfect information. It follows from (2.30) that
EVPI is always nonnegative, and EVPI ¼ 0 iﬀcondition (2.31) holds.
3
Multistage models
3.1
The linear case
The two-stage model is a special case of a more general structure, called the
multi-stage stochastic programming model, in which the decision variables
and constraints are divided into groups corresponding to stages t ¼ 1, . . . , T:
The fundamental issue in such a model is the information structure: what is
known at stage t when decisions associated with this period are made? We ﬁrst
give a general description of such multistage models and then discuss
examples in Section 3.4.
Let x1, . . . , xT be decision vectors corresponding to time periods (stages)
1, . . . , T. Consider the following linear programming problem
Min
cT
1 x1
þ
cT
2 x2
þ
cT
3 x3
þ
...
þ
cT
TxT
s:t:
A11x1
¼ b1,
A21x1
þ A22x2
¼ b2,
A32x2
þ A33x3
¼ b3,
........................................................................
AT,T1xT1 þ ATTxT ¼ bT,
x1 0,
x2 0,
x3 0,
...
xT 0:
ð3:1Þ
We view it as a multiperiod stochastic program where c1, A11 and b1 are
known, but some (all) of the entries of the cost vectors c2, . . . , cT, matrices
22
A. Ruszczyn´ski and A. Shapiro

At, t1 and Att, t ¼ 2, . . . , T, and right hand side vectors b2, . . . , bT are random.
At each stage some of these quantities become known, and we have the
following sequence of actions:
decision ðx1Þ
observation 2 :¼ ðc2, A21, A22, b2Þ
decision ðx2Þ
..
.
observation T :¼ ðcT, AT, T1, ATT, bTÞ
decision ðxTÞ:
Our objective is to design the decision process in such a way that the
expected value of the total cost is minimized while optimal decisions are
allowed to be made at every time period t ¼ 1, . . . , T:
Let us denote by t the data which become known at time period t. In the
setting of the multiperiod problem (3.1), t is assembled from the components
of ct, At, t1, Att, bt, some (all) of which can be random, and the data
1 ¼ ðc1, A11, b1Þ at the ﬁrst stage of problem (3.1) which is assumed to be
known. For 1  t1  t2  T, denote by
½t1, t2 :¼ ðt1, . . . , t2Þ
the history of the process from time t1 to time t2. In particular, ½1, t represents
the information available up to time t. The important condition in the above
multistage process is that every decision vector xt may depend on the
information available at time t (that is, ½1, t), but not on the results of
observations to be made at later stages. This diﬀers multistage stochastic
programs from deterministic multiperiod problems, in which all the inform-
ation is assumed to be available at the beginning.
There are several possible ways how multistage stochastic programs can be
formulated in a precise mathematical form. In one such formulation
xt ¼ xtð½1, tÞ, t ¼ 2, . . . , T, is viewed as a function of ½1, t ¼ ð1, . . . , tÞ, and
the minimization in (3.1) is performed over appropriate functional spaces (as
it was discussed in Section 2.4 in the case of two-stage programming). If the
number of scenarios is ﬁnite, this leads to a formulation of the linear
multistage stochastic program as one large (deterministic) linear programming
problem. We discuss that further in the following Section 3.2. It is also useful
to connect dynamics of the multistage process starting from the end as
follows.
Let us look at our problem from the perspective of the last stage T. At that
time the values of all problem data, ½1, T , are already known, and the values
Ch. 1. Stochastic Programming Models
23

of the earlier decision vectors, x1, . . . , xT1, have been chosen. Our problem is,
therefore, a simple linear programming problem
Min
xT
cT
TxT
s:t:
AT, T1xT1 þ ATTxT ¼ bT,
xT  0:
ð3:2Þ
The optimal value of this problem depends on the earlier decision vector
xT1 and data T ¼ ðcT, AT, T1, AT, T, bTÞ, and is denoted by QTðxT1, TÞ.
At stage T  1 we know xT2 and ½1, T1. We face, therefore, the following
two-stage stochastic programming problem
Min
xT1 cT
T1xT1 þ E QTðxT1, TÞ j ½1, T1


s:t:
AT1, T2xT2 þ AT1, T1xT1 ¼ bT1,
xT1  0:
ð3:3Þ
The optimal value of the above problem depends on xT2 and data ½1, T1,
and is denoted QT1ðxT2, ½1, T1Þ.
Generally, at stage t ¼ 2, . . . , T  1, we have the problem
Min
xt
cT
t xt þ E Qtþ1ðxt, ½1, tþ1Þ j ½1, t


s:t:
At, t1xt1 þ At, txt ¼ bt,
xt  0:
ð3:4Þ
Its optimal value is denoted Qtðxt1, ½1, tÞ and is called the cost-to-go
function.
Note that, since 1 is not random, the conditional distribution of t þ 1 given
½1, t is the same as the conditional distribution of t þ 1 given ½2, t,
t ¼ 2, . . . , T  1. Therefore, it suﬃces to take the conditional expectation in
(3.4) (in (3.3)) with respect to ½2, t (with respect to ½2, T1), only.
On top of all these problems is the problem to ﬁnd the ﬁrst decisions, x1,
Min
x1
cT
1 x1 þ E Q2ðx1, 2Þ
½

s:t:
A11x1 ¼ b1,
x1  0:
ð3:5Þ
Note that all subsequent stages t ¼ 2, . . . , T are absorbed in the above
problem (3.5) into the function Q2ðx1, 2Þ through the corresponding
24
A. Ruszczyn´ski and A. Shapiro

expected values. Note also that since 1 is not random, the optimal value
Q2ðx1, 2Þ does not depend on 1. In particular, if T ¼ 2, then (3.5) coincides
with the formulation (2.2) of a two-stage linear problem.
We arrived in this way at the following nested formulation:
Min
A11x1¼b1
x10
cT
1 x1þE
min
A21x1þA22x2¼b2
x20
cT
2 x2þE þE
min
AT,T1xT1þATTxT¼bT
xT0
cT
TxT
2
4
3
5
2
64
3
75
2
64
3
75:
Recall that the random process 1, . . . , T is said to be Markovian, if for each
t ¼ 2, . . . , T  1 the conditional distribution of t þ 1 given ½1, t ¼ ð1, . . . , tÞ
is the same as the conditional distribution of t þ 1 given t. If the process
1, . . . , T
is Markovian, the model is simpliﬁed considerably. In the
Markovian case, for given T1, the conditional expectation in problem
(3.3) does not depend on 1, . . . , T2, and hence the optimal value of (3.3)
depends only on xT2 and T1. Similarly, at stage t ¼ 2, . . . , T  1, the
optimal value of problem (3.4) is then a function of xt1 and t, and can be
denoted by Qtðxt1, tÞ. We shall call then t the information state of the model.
In particular, the process 1, . . . , T is Markovian if the random vectors t,
t ¼ 2, . . . , T,
are
mutually
independent.
In
that
case
the
conditional
expectation in problem (3.3) does not depend on ½1, T1, and hence the
optimal value QT1ðxT2, T1Þ of (3.3) depends on T1 only through the
linear constraint of that problem, and similarly, at stages t ¼ T  2, . . .,
the optimal value Qtðxt1, tÞ depends on t only through the linear constraint
of (3.4).
The assumption that the blocks At1, . . . , At, t2 in the constraint matrix are
zeros, allowed us to express the optimal value Qt of (3.4) as the function of the
immediately preceding decision, xt1, rather than all earlier decisions
x1, . . . , xt1. Suppose now that we deal with an underlying model with a full
lower block triangular constraint matrix:
Min
cT
1 x1
þ
cT
2 x2
þ
cT
3 x3
þ
...
þ
cT
TxT
s:t:
A11x1
¼ b1,
A21x1
þ A22x2
¼ b2,
A31x1
þ A32x2
þ A33x3
¼ b3,
........................................................................
AT1x1 þ AT2x2 þ
...
þ AT,T1xT1 þ ATTxT ¼ bT,
x1 0,
x2 0,
x3 0,
...
xT 0:
ð3:6Þ
Ch. 1. Stochastic Programming Models
25

Then, of course, each subproblem (3.4) depends on the entire history of our
decisions, x½1, t1 :¼ ðx1, . . . , xt1Þ. It takes on the form
Min
xt
cT
t xt þ E Qt þ 1ðx½1, t, ½1, t þ 1Þ j ½1, t


s:t: At1x1 þ    þ At, t1xt1 þ At, txt ¼ bt,
xt  0:
ð3:7Þ
Its optimal value is denoted Qtðx½1, t1, ½1, tÞ.
Sometimes it is convenient to convert such a lower triangular formulation
into the staircase formulation from which we started our presentation. This
can be accomplished by introducing additional variables rt which summarize
the relevant history of our decisions. We shall call these variables the model
state variables (to distinguish from information states discussed before). The
relations that describe the next values of the state variables as a function of the
current values of these variables, current decisions and current random
parameters are called model state equations.
For the general problem (3.6) the vectors x½1, t ¼ ðx1, . . . , xtÞ are suﬃcient
model state variables. They are updated at each stage according to the state
equation x½1, t ¼ ðx½1, t1, xtÞ (which is linear), and the constraint in (3.7) can
be formally written as
½At1At2 . . . At, t1x½1, t1 þ At, txt ¼ bt:
Although, it looks a little awkward in this general case, in many problems it
is possible to deﬁne model state variables of reasonable size. As an example let
us consider the structure
Min
cT
1 x1
þ
cT
2 x2
þ
cT
3 x3
þ

þ
cT
TxT
s:t:
A11x1
¼ b1,
B1x1
þ
A22x2
¼ b2,
B1x1
þ
B2x2
þ
A33x3
¼ b3,
........................................................................
B1x1
þ
B2x2
þ
...
þ BT1xT1 þ ATTxT ¼ bT,
x1 0,
x2 0,
x3 0,
...
xT 0,
in which all blocks Ait, i ¼ 2, . . . , T are identical and observed at time t. Then
we can deﬁne the state variables rt, t ¼ 1, . . . , T recursively by the state
26
A. Ruszczyn´ski and A. Shapiro

equation rt ¼ rt1 þ Btxt, t ¼ 1, . . . , T  1, where r0 ¼ 0. Subproblem (3.7)
simpliﬁes substantially:
Min
xt, rt cT
t xt þ E Qtþ1ðrt, ½1, tþ1Þ j ½1, t


s:t:
rt1 þ Attxt ¼ bt,
rt ¼ rt1 þ Btxt,
xt  0:
Its optimal value depends on rt1 and is denoted Qtðrt1, ½1, tÞ.
Trucking Example 9 (discussed in Section 3.4) uses such model state
variables: the capacities rt available at all locations at the end of day t. We do
not need to remember all decisions made in the past, we only need to know the
numbers of trucks at each location today.
It should be clear, too, that the simple sign constraints xt  0 can be
replaced in our model by a general constraint xt 2 Xt, where Xt is a convex
polyhedron deﬁned by some linear equations and inequalities (local for
stage t). The set Xt may be random, too, but has to become known at stage t.
3.2
The case of finitely many scenarios
Suppose that in our basic problem (3.1) there are only ﬁnitely many, say K,
diﬀerent values the problem data can take. We shall call them scenarios.
With each scenario k is associated probability pk and the corresponding
sequence of decisions9 xk ¼ ðxk
1, xk
2, . . . , xk
TÞ: Of course, it would not be
appropriate to try to ﬁnd the optimal values of these decisions by solving the
relaxed version of (3.1):
MinPK
k¼1pk½ðc1ÞTxk
1 þðck
2ÞTxk
2 þðck
3ÞTxk
3 þ

þðck
TÞTxk
T
s:t:
A11xk
1
¼ b1,
Ak
21xk
1 þ Ak
22xk
2
¼ bk
2,
Ak
32xk
2 þ Ak
33xk
3
¼ bk
3,
.....................................................................................
Ak
T,T1xk
T1 þ Ak
TTxk
T ¼bk
T,
xk
10,
xk
20,
xk
30,
...
xk
T0,
k¼1,...,K:
ð3:8Þ
9 To avoid ugly collisions of subscripts we change our notation a little and we put the index of the
scenario, k, as a superscript.
Ch. 1. Stochastic Programming Models
27

The reason is the same as in the two-stage case: in the problem above all
parts of the decision vector are allowed to depend on all parts of the random
data, while in reality each part xt is allowed to depend only on the data known
up to stage t. In particular, problem (3.8) may suggest diﬀerent values of x1 for
each scenario k, but we need only one value.
It is clear that we need the nonanticipativity constraints
xk
1 ¼ x j
1
for all 1  k < j  K,
ð3:9Þ
similarly to (2.10). But this is not suﬃcient, in general. Consider the second
part of the decision vector, x2. It is allowed to depend only on ½1, 2 ¼ ð1, 2Þ,
so it has to have the same value for all scenarios k for which k
½1, 2 is identical.
We must therefore, satisfy the equations
xk
2 ¼ x j
2
for all k, j for which k
½1, 2 ¼ j
½1, 2:
ð3:10Þ
Generally, at stage t ¼ 1, . . . , T, the scenarios that have the same history
½1, t cannot be distinguished, so we need to enforce the nonanticipativity
constraints
xk
t ¼ x j
t
for all k, j for which k
½1, t ¼ j
½1, t,
t ¼ 1, . . . , T:
ð3:11Þ
Problem (3.8) together with the nonanticipativity constraints (3.11)
becomes equivalent to our original formulation (3.1).
Let us observe that if in the problem (3.8) only the constraints (3.9) are
enforced, then from the mathematical point of view the obtained problem
becomes a two-stage stochastic linear program with K scenarios. In that two-
stage program the ﬁrst stage decision vector is x1, the second stage decision
vector is ðx2, . . . , xKÞ, the technology matrix is A21 and the recourse matrix is
the block matrix
A22
0
::::::
0
0
A32
A33
::::::
0
0
::::::::::::::::::
0
0
::::::
AT, T1
ATT
2
6666664
3
7777775
:
Since the obtained two-stage problem is a relaxation of the multistage
problem (3.1), its optimal value gives a lower bound for the optimal value of
28
A. Ruszczyn´ski and A. Shapiro

problem (3.1) and in that sense can be useful. Note, however, that this model
does not make much sense, since it assumes that at the end of the process
when all realizations of the random data become known, one can go back in
time and make all decisions x2, . . . , xK.
It is useful to depict the possible sequences of data ½1, t in a form of
a scenario tree. It has nodes organized in levels which correspond to
stages 1, 2, . . . , T. At level 1 we have only one root node, and we associate
with it the value of 1 (which is known at stage 1). At level 2 we have at
least as many nodes as many diﬀerent realizations of 2 may occur. Each
of them is connected with the root node by an arc. For each node i of
level 2 (which corresponds to a particular realization i
2 of 2) we create
at least as many nodes at level 3 as diﬀerent values of 3 may follow i
2,
and we connect them with the node i, etc. Generally, nodes at level
t correspond to possible values of t that may occur. Each of them is
connected to a unique node at level t  1, called the ancestor node, which
corresponds to the identical ﬁrst t  1 parts of the process ½1, t, and is also
connected to nodes at level t þ 1, which correspond to possible continuations
of history ½1, t.
Note that, in general, realizations i
t are vectors and it may happen that
some of the values i
t, associated with nodes at a given level t, are equal to each
other. Nevertheless, such equal values may be represented by diﬀerent nodes
since they may correspond to diﬀerent histories of the process. Note also that
if for every t ¼ 1, . . . , T all realizations i
t are diﬀerent from each other, then the
random process 1,. . . , T is Markovian because of the tree structure of the
process. Indeed, in that case the conditional probability of t to be at state
i
t depends on the previous history of the process only through the ancestor
node at level t  1.
In order to illustrate the above ideas let us discuss the following simple
example.
Example 6 (Scenario Tree). An example of the scenario tree is depicted
in Fig. 2. Numbers along the arcs represent conditional probabilities of moving
from one node to the next. The associated process t ¼ ðct, At, t1, Att, btÞ,
t ¼ 1, . . . , T, with T ¼ 4, is deﬁned as follows. All involved variables are
assumed to be one dimensional, with ct, At, t1, Att, t ¼ 2, 3, 4, being ﬁxed and
only right hand side variables bt being random. The numerical values
(realizations) of the random process b1, . . . , bT are indicated by the bold
numbers at the nodes of the tree. Numerical values of ct, At, t1, Att will be
speciﬁed later. That is, at level t ¼ 1, b1 has unique value 36. At level t ¼ 2, b2
has two values 15 and 50 with respective probabilities 0:4 and 0:6. At level
t ¼ 3 we have 5 nodes with which are associated the following numerical
values (from left to right) 10, 20, 12, 20, 70. That is, b3 can take 4 diﬀerent
values with
respective probabilities
Pfb3 ¼ 10g ¼ 0:4  0:1,
Pfb3 ¼ 20g ¼
0:4  0:4
þ 0:6  0:4, Pfb3 ¼ 12g ¼ 0:4  0:5 and Pfb3 ¼ 70g ¼ 0:6  0:6. At
Ch. 1. Stochastic Programming Models
29

level t ¼ 4, the numerical values associated with eight nodes are deﬁned, from
left to right, as 10, 10, 30, 12, 10, 20, 40, 70. The respective probabilities can
be calculated by using the corresponding conditional probabilities. For
example,
Pfb4 ¼ 10g ¼ 0:4  0:1  1:0 þ 0:4  0:4  0:5 þ 0:6  0:4  0:4:
Note
that
although
some
of
the
realizations
of
b3,
and
hence
of 3, are equal to each other, they are represented by diﬀerent nodes.
This is necessary in order to identify diﬀerent histories of the process
corresponding to diﬀerent scenarios. The same remark applies to b4
and 4. Altogether, there are eight scenarios in this tree. Figure 3 illustrates
the way in which sequences of decisions are associated with scenarios from
Fig. 2.
The process bt (and hence the process t) in the above example is not
Markovian. For instance,
P b4 ¼ 10 j b3 ¼ 20, b2 ¼ 15, b1 ¼ 36
f
g ¼ 0:5,
while
P b4 ¼ 10 j b3 ¼ 20
f
g ¼ Pfb4 ¼ 10, b3 ¼ 20g
Pfb3 ¼ 20g
¼ 0:5  0:4  0:4 þ 0:4  0:4  0:6
0:4  0:4 þ 0:4  0:6
¼ 0:44 6¼ 0:5:
Fig. 2. Scenario tree. Nodes represent information states. Paths from the root to leaves
represent scenarios. Numbers along the arcs represent conditional probabilities of moving
to the next node. Bold numbers represent numerical values of the process.
30
A. Ruszczyn´ski and A. Shapiro

On the other hand, the process bt in this example is a martingale.10 For
instance,
E b2 j b1 ¼ 36
½
 ¼ E b2
½
 ¼ 15  0:4 þ 50  0:6 ¼ 36,
E b3 j b2 ¼ 15, b1 ¼ 36
½
 ¼ 10  0:1 þ 20  0:4 þ 12  0:5 ¼ 15, etc:
Suppose now that cT ¼ 1 and AT, T1 ¼ ATT ¼ 1. Then the cost-to-go
function QTðxT1, TÞ is given by the optimal value of the problem
Min
xT
xT
subject to
xT1 þ xT ¼ bT, xT  0,
and hence
QTðxT1, TÞ ¼
bT  xT1,
if xT1  bT,
þ 1,
otherwise:

Note again that bT has six possible realizations.
Suppose further that cT1 ¼ 1 and AT1, T2 ¼ AT1, T1 ¼ 1. Then the
cost-to-go function QT1ðxT2, ½1, T1Þ is the optimal value of the problem
Min
xT1 xT1 þ E½QTðxT1, TÞ j ½1, T1
subject to
xT2 þ xT1 ¼ bT1, xT1  0:
Fig. 3. Sequences of decisions for scenarios from Fig. 2. Horizontal dotted lines represent
the equations of nonanticipativity.
10 Recall that a random process Zt, t ¼ 1, . . . , is called a martingale if the equalities E Zt þ 1jZ½1, t

 ¼
Zt, t ¼ 1, . . . , hold with probability one.
Ch. 1. Stochastic Programming Models
31

The history b½1, 3 of the process bt, and hence the history ½1, 3 of the process
t, is in one-to-one correspondence with the nodes of the tree at level t ¼ 3. It
has 5 possible realizations i
½1, 3, i ¼ 1, . . . , 5, numbered from left to right, i.e.,
for i ¼ 1 it corresponds to the realization b1 ¼ 36, b2 ¼ 15, b3 ¼ 10 of b½1, 3.
We have that
E

QTðxT1,4Þj½1,3¼1
½1,3

¼QTðxT1,1
4Þ ¼ 10xT1, if xT110,
þ 1,
otherwise,

where 1
4 ¼

1, 1, 1, b1
4

and b1
4 ¼ 10. Consequently,
QT1

xT2, 1
½1, 3

¼
10,
if 0  xT2  10,
þ 1,
otherwise:

Similarly,
E

QT

xT1, 4

j½1, 3 ¼ 2
½1, 3

¼ 1
2 QTðxT1, 2
4Þ þ 1
2 QTðxT1, 3
4Þ,
and hence
QT1

xT2, 2
½1, 3

¼
20,
if 10  xT2  20,
þ 1,
otherwise,

etc. By continuing the above backward calculations (which, of course, depend
on numerical values of c2, A21, A22 and c1, A11) one can either show that the
problem is infeasible or ﬁnd the optimal value and an optimal solution of the
ﬁrst stage problem.
It is also possible to solve this multistage problem by formulating it as a
linear programming problem of the form (3.8) subject to the corresponding
nonanticipativity constraints. Such linear program will have 4  8 ¼ 32
decision variables, 16 nonanticipativity constraints and four linear equality
constraints.
Consider now a scenario tree and corresponding process 1, . . . , T. With
each scenario of the tree is associated a probability pk, k ¼ 1, . . . , K. These
probabilities are related to the time structure of the multistage process and can
be constructed as follows. In order to deal with the nested structure of
problems (3.4) we need to specify the conditional distribution of t given11
11 Since 1 is not random, for t ¼ 2 the distribution of 2 is independent of 1.
32
A. Ruszczyn´ski and A. Shapiro

½1, t1, t ¼ 2, . . . , T. Consider a node i 2 N and its ancestor a ¼ aðiÞ in the
scenario tree. Denote by ai the probability of moving from the node a to
the node i. For instance, in the tree of Fig. 2 it is possible to move from the
root node to two nodes at stage t ¼ 2, say i1 and i2, with the corresponding
probabilities 1i1 ¼ 0:4 and 1i2 ¼ 0:6. Clearly the numbers ai should be
nonnegative and for a given a 2 N the sum of ai over all continuations i 2 N
of the node a should be equal to one. Each probability ai can be viewed as the
conditional probability of the process being in the node i given its history up
to the ancestor node a ¼ aðiÞ. Note also that probabilities ai are in one-to-one
correspondence with the arcs of the scenario tree. Every scenario can be
deﬁned by its nodes i1, i2, . . . , iT, arranged in the chronological order, i.e.,
node i2 (at level t ¼ 2) is connected to the root i1 ¼ 1, node i3 is connected to
the node i2, etc. The probability of that scenario is then given by the product
i1i2, i2i3, . . . , iT1iT. The conditional probabilities ai describe the probabil-
istic structure of the considered problem and could be speciﬁed together with
the corresponding scenario tree.
It is possible to derive these conditional probabilities from scenario
probabilities pk as follows. Let us denote by BðiÞ the set of scenarios passing
through node i (at level t) of the scenario tree, and let pðiÞ :¼ P½BðiÞ. If
i1, i2, . . . , it, with i1 ¼ 1 and it ¼ i, is the history of the process up to node i,
then the probability pðiÞ is given by the product
pðiÞ ¼ i1i2, i2i3, . . . , it1it
of the corresponding conditional probabilities. In another way we can write
this in the recursive form pðiÞ ¼ aipðaÞ, where a ¼ aðiÞ is the ancestor of the
node i. This equation deﬁnes the conditional probability ai from the
probabilities pðiÞ and pðaÞ. Note that if a ¼ aðiÞ is the ancestor of the node i,
then
BðiÞ  BðaÞ
and
hence
pðiÞ  pðaÞ.
Consequently
if
pðaÞ > 0,
then
ai ¼ pðiÞ=pðaÞ. Otherwise BðaÞ is empty, i.e., no scenario is passing through
the node a, and hence no scenario is passing through the node i.
Recall that a stochastic process Zt, t ¼ 1, 2, . . ., that can take a ﬁnite
number fz1, . . . , zmg of diﬀerent values, is said to be a Markov chain if
P Zt þ 1 ¼ zjjZt ¼ zi, Zt1 ¼ zit1, . . . , Z1 ¼ zi1


¼ pij,
ð3:12Þ
for all states zit1, . . . , zi1,zi, zj and all t ¼ 1, . . . : In some instances it is natural
to model the data process as a Markov chain with the corresponding state
space12 f1, . . . , mg and probabilities pij of moving from state i to state j,
i, j ¼ 1, . . . , m. We can model such process by a scenario tree. At stage t ¼ 1
there is one root node to which is assigned one of the values from the state
space, say i. At stage t ¼ 2 there are m nodes to which are assigned values
12 In our modeling, values 1, . . . , m can be numbers or vectors.
Ch. 1. Stochastic Programming Models
33

1, . . . , m with the corresponding probabilities pi1, . . . , pim. At stage t ¼ 3
there are m2 nodes, such that each node at stage t ¼ 2, associated with a state
a, a ¼ 1, . . . , m, is the ancestor of m nodes at stage t ¼ 3 to which are assigned
values 1, . . . , m with the corresponding conditional probabilities pa1, . . . , pam.
At stage t ¼ 4 there are m3 nodes, etc. At each stage t of such T-stage Markov
chain process there are mt1 nodes, the corresponding random vector
(variable) t can take values 1, . . . , m with respective probabilities which
can be calculated from the history of the process up to time t, and the total
number of scenarios is mT1. We have here that the random vectors
(variables) 1, . . . , T
are independently distributed iﬀpij ¼ pi0j for any
i, i0, j ¼ 1, . . . , m, i.e., the conditional probability pij of moving from state i
to state j does not depend on i.
In the above formulation of the Markov chain the corresponding scenario
tree represents the total history of the process with the number of scenarios
growing exponentially with the number of stages. Now if we approach the
problem by writing the cost-to-go functions Qtðxt1, tÞ, going backwards,
then we do not need to keep the track of the history of the process. That is, at
every stage t the cost-to-go function Qtð, tÞ only depends on the current state
(realization) t ¼ i, i ¼ 1, . . . , m, of the process. On the other hand, if we want
to write the corresponding optimization problem (in the case of a ﬁnite
number of scenarios) as one large linear programming problem, we still need
the scenario tree formulation. This is the basic diﬀerence between the
stochastic and dynamic programming approaches to the problem. That is, the
stochastic programming approach does not necessarily rely on the Markovian
structure of the considered process. This makes it more general at the price of
considering a possibly very large number of scenarios.
There are many ways to express the nonanticipativity constraints (3.11)
which may be convenient for diﬀerent solution methods. One way is
particularly elegant from the theoretical point of view:
xk
t ¼
P
j2AtðkÞ pjx j
t
P
j2AtðkÞ pj
,
k ¼ 1, . . . , K, t ¼ 1, . . . , T,
ð3:13Þ
where AtðkÞ :¼ f j : j
½1, t ¼ k
½1, tg is the set of scenarios that share with scenario
k the history up to stage t. The expression at the right hand side of the above
relation is the conditional expectation of xt under the condition that
½1, t ¼ k
½1, t, where xt is viewed as a random variable which can take values
x j
t with probabilities pj, j ¼ 1, . . . , K. We can therefore rewrite (3.13) as
xt ¼ E xt j ½1, t


,
t ¼ 1, . . . , T:
ð3:14Þ
This formulation of the nonanticipativity constraints can be conveniently
extended to the case of a general distribution of the data ½1, T.
34
A. Ruszczyn´ski and A. Shapiro

The nonanticipativity conditions (3.14) can be analytically eliminated from
the multistage model. As before, denote by N the set of nodes of the scenario
tree (with root 1), and let i 2 N be a node at level t. Recall that BðiÞ denotes the
set of scenarios passing through node i and aðiÞ denotes the ancestor of node i.
We have that xt has to be constant for scenarios k 2 BðiÞ. Let us denote the
value of xt associated with node i by xðiÞ. Similarly, let cðiÞ, DðiÞ
i , WðiÞ and hðiÞ be
the values ct, Ak
t, t1, Ak
tt and bk
t , respectively, corresponding to node i. We can
rewrite then the corresponding linear programming problem as follows
Min
X
i2N
pðiÞðcðiÞÞTxðiÞ
s:t:
DðiÞxaðiÞ þ WðiÞxðiÞ ¼ hðiÞ,
i 2 N nf1g,
Wð1Þxð1Þ ¼ hð1Þ,
xðiÞ  0,
i 2 N :
3.3
The general model
In the general multistage model, similarly to the linear case, we have a
sequence of data vectors 1 2 Rd1, 2 2 Rd2, . . . , T 2 RdT, and a sequence of
decisions: x1 2 Rn1, x2 2 Rn2, . . . , xT 2 RnT. We assume that 1 is already
known and random vectors 2, . . . , T are observed at the corresponding time
periods. The decision process has then the form:
decision ðx1Þ 4 observation ð2Þ 4 decision ðx2Þ 4
      4 observation ðTÞ 4 decision ðxTÞ:
The values of the decision vector xt, chosen at stage t, may depend on the
information ½1, t available up to time t, but not on the results of future
observations. We can formulate this requirement using nonanticipativity
constraints. That is, we view each xt ¼ xtðÞ as an element of the space of
measurable mappings from  to Rnt, and hence consider xtð!Þ as a random
(vector valued) process of time t. It has to satisfy the following additional
condition, called the nonanticipativity constraint,
xt ¼ E½xt j ½1, t,
t ¼ 1, . . . , T:
ð3:15Þ
If F t is the sigma algebra generated by13 ½1, t, then F 1  F 2  . . . 
F T  F, and condition (3.15) ensures that xtð!Þ is measurable with respect F t.
13 F t is the minimal subalgebra of the sigma algebra F such that 1ð!Þ, . . . , tð!Þ are F t-measurable.
Since 1 is not random, F 1 contains only two sets ; and . We can assume that F T ¼ F.
Ch. 1. Stochastic Programming Models
35

One
can
use
this
measurability
requirement
as
a
deﬁnition
of
the
nonanticipativity constraint.
To describe the objective and other constraints, let us denote the decisions
associated with stages 1, . . . , T, as before, by x½1, t :¼ ðx1, . . . , xtÞ: We have the
objective functional
F : Rn1 þ  þ nT  Rd1 þ  þ dT ! R,
and constraint functionals
Gti : Rn1 þ  þ nt  Rd1 þ  þ dt ! R,
t ¼ 2, . . . , T, i ¼ 1, . . . , mt:
The multistage stochastic programming problem is abstractly formulated as
follows
Min E Fðx½1, Tð!Þ, ½1, Tð!ÞÞ


s:t:
Gtiðx½1, tð!Þ, ½1, tð!ÞÞ  0,
i ¼ 1, . . . , mt, t ¼ 1, . . . , T,
xtð!Þ 2 Xt,
t ¼ 1, . . . , T,
xt ¼ E xt j ½1, t


,
t ¼ 1, . . . , T:
ð3:16Þ
In the above formulation Xt is a convex closed subset of Rnt, and all
constraints are assumed to hold almost surely.
The nested formulation can be developed similarly to the linear case. At
stage T we know ½1, T and x½1, T1 and we have the problem
Min
xT
F x½1, T1, xT, ½1, T


s:t:
GTiðx½1, T1, xT, ½1, TÞ  0,
i ¼ 1, . . . , mT,
xT 2 XT:
ð3:17Þ
Its optimal value is denoted QT x½1, T1, ½1, T

. Generally, at stage
t ¼ T  1, . . . , 1 we have the problem
Min
xt
E Qtþ1ðx½1, t1, xt, ½1, tþ1Þ
 ½1, t


s:t:
Gti x½1, t1, xt, ½1, t


 0,
i ¼ 1, . . . , mt,
xt 2 Xt:
ð3:18Þ
Its optimal value is denoted Qt x½1, t1, ½1, t


.
If F and Gti are random lsc functions and the sets Xt are closed and
bounded, then all Qt are random lsc functions, too. This can be proved by
36
A. Ruszczyn´ski and A. Shapiro

recursively applying Theorem 20 (from the Appendix) to problems (3.18) at
stages T, T  1, . . . , 1. By the forward induction, for t ¼ 1, . . . , T, we can also
prove that each problem (3.18) has its data measurable with respect to F t and
has, by the measurable selection theorem (Theorem 16 in the Appendix), a
solution which is F t-measurable (if a solution exists at all). Therefore, under
natural assumptions, the multistage stochastic program (3.16) is a well deﬁned
model.
3.4
Examples of multistage models
Example 7 (Financial Planning). Suppose that there are n investment
opportunities, with random returns Rt ¼ ðR1t, . . . , RntÞ in time periods
t ¼ 1, . . . , T. One of possible investments is just cash. Our objective is to
invest the given amount W0 at time t ¼ 0 so as to maximize the expected
utility of our wealth at the last period T. The utility of wealth W is represented
by a concave nondecreasing function UðWÞ. In our investment strategy we are
allowed to rebalance our portfolio after each period, but without injecting
additional cash into it.
Let x10, . . . , xn0 denote the initial amounts invested in assets 1, . . . , n at
time t ¼ 0. Clearly, they have to be nonnegative and to satisfy the condition
X
n
i¼1
xi0 ¼ W0:
ð3:19Þ
We can put an equation sign here, because one of our assets is cash.
After the ﬁrst period, our wealth may change, due to random returns from
the investments, and at time t ¼ 1 it will be equal to
W1 ¼
X
n
i¼1
ð1 þ Ri1Þxi0:
ð3:20Þ
If we stop at that time, our problem becomes the stochastic programming
problem
Max
x02Rn E U
X
n
i¼1
ð1 þ Ri1Þxi0
 
!
"
#
s:t:
X
n
i¼1
xi0 ¼ W0,
xi0  0,
i ¼ 1, . . . , n:
ð3:21Þ
In particular, if UðWÞ:W, i.e., we want to maximize the expected wealth,
then
the
objective
function
in
the
above
problem
(3.21)
becomes
Ch. 1. Stochastic Programming Models
37

Pn
i¼1 ð1 þ E½Ri1Þxi0, and hence problem (3.21) becomes a deterministic
optimization program. It has the trivial optimal solution of investing
everything into the asset with the maximum expected return.
Suppose, on the other hand, that UðWÞ is deﬁned as
UðWÞ:¼
ð1 þ qÞðW  aÞ,
if W  a,
ð1 þ rÞðW  aÞ,
if W  a,

ð3:22Þ
with r > q > 0 and a > 0. We can view the involved parameters as follows: a is
the amount that we have to pay at time t ¼ 1, q is the interest at which we can
invest the additional wealth W  a, provided that W > a, and r is the interest
at which we will have to borrow if W is less than a. For the above utility
function, problem (3.21) can be formulated as the following two-stage
stochastic linear program
Max
x02Rn E½Qðx0, R1Þ,
s:t:
X
n
i¼1
xi0 ¼ W0,
xi0  0,
i ¼ 1, . . . , n,
ð3:23Þ
where Qðx0, R1Þ is the optimal value of the second stage program
Max
y, z2R ð1 þ qÞy  ð1 þ rÞz
s:t:
X
n
i¼1
ð1 þ Ri1Þxi0 ¼ a þ y  z,
y  0, z  0:
ð3:24Þ
Suppose now that T > 1. In that case we can rebalance the portfolio at time
t ¼ 1, by specifying the amounts x11, . . . , xn1 invested in the assets in the
second period. Note that we already know the actual returns in the ﬁrst
period, so it is reasonable to use this information in the rebalancing decisions.
Thus, our second stage decisions are actually functions of R1 ¼ ðR11, . . . , Rn1Þ,
and they can be written as x11ðR1Þ, . . . , xn1ðR1Þ. We also must remember about
our balance of wealth:
X
n
i¼1
xi1ðR1Þ ¼ W1
ð3:25Þ
38
A. Ruszczyn´ski and A. Shapiro

and the condition of nonnegativity. In general, the wealth after period t is
equal to
Wt ¼
X
n
i¼1
ð1 þ RitÞxi, t1ðR½1, t1Þ,
ð3:26Þ
where R½1, t :¼ ðR1, . . . , RtÞ:
Our next decisions, x1t, . . . , xnt may depend on R1, . . . , Rt. They have to be
nonnegative and satisfy the balance constraint,
X
n
i¼1
xitðR½1, tÞ ¼ Wt:
ð3:27Þ
At the end, the wealth after period T is
WT ¼
X
n
i¼1
ð1 þ RiTÞxi, T1ðR½1, T1Þ:
ð3:28Þ
Our objective is to maximize the expected utility of this wealth,
Max E½UðWTÞ:
ð3:29Þ
It is a multistage stochastic programming problem, where stages are
numbered from t ¼ 0 to t ¼ T  1, and decisions xt at each stage are allowed
to depend on the history R1, . . . , Rt of returns prior to this stage.
Of course, in order to complete the description of the above multistage
stochastic programming problem, we need to deﬁne the probability structure
of the random process R1, . . . , RT. This can be done in many diﬀerent ways.
For example, one can construct a particular scenario tree deﬁning time
evolving of the process. If at every stage the random return of each asset is
allowed to have just two continuations independently of other assets, then the
total number of scenarios is 2nT. It also should be ensured that 1 þ Rit > 0,
i ¼ 1, . . . , n, t ¼ 1, . . . , T, for all possible realizations of the random data.
Let us consider the above multistage problem backwards, as it was
discussed in Section 3.1. At the last stage t ¼ T  1 all realizations of the
random process R1, . . . , RT1 are known and xT2 has been chosen.
Therefore, we have to solve the problem
Max E U
X
n
i¼1
ð1 þ RiTÞxi, T1
"
#R½1, T1
(
)
s:t:
X
n
i¼1
xi, T1 ¼
X
n
i¼1
ð1 þ Ri, T1Þxi, T2,
xi, T1  0,
i ¼ 1, . . . , n:
ð3:30Þ
Ch. 1. Stochastic Programming Models
39

Its optimal value is denoted QT1ðxT2, R½1, T1Þ. At stage t ¼ T  2 reali-
zations of the random process R1, . . . , RT2 are known and xT3 has been
chosen. We have then to solve the following two-stage stochastic program
Max E QT1ðxT2, R½1, T1ÞjR½1, T2


s:t:
X
n
i¼1
xi, T2 ¼
X
n
i¼1
ð1 þ Ri, T2Þxi, T3,
xi, T2  0,
i ¼ 1, . . . , n:
ð3:31Þ
Its optimal value is denoted QT2ðxT3, R½1, T2Þ, etc. At stage t ¼ 0 we
have to solve the following program
Max E Q1ðx0, R1Þ
½

s:t:
X
n
i¼1
xi0 ¼ W0,
xi0  0,
i ¼ 1, . . . , n:
ð3:32Þ
Note that in the present case the cost-to-go function QT1ðxT2, R½1, T1Þ
depends on xT2 ¼ ðx1, T2, . . . , xn, T2Þ only through WT1 ¼ Pn
i¼1 ð1 þ
Ri, T1Þxi, T2. That is, if
~QT1ðWT1, R½1, T1Þ is deﬁned as the optimal
value of the problem
Max E U
X
n
i¼1
ð1 þ RiTÞxi, T1
"
#R½1, T1
(
)
s:t:
X
n
i¼1
xi, T1 ¼ WT1, xi, T1  0, i ¼ 1, . . . , n,
ð3:33Þ
then
QT1ðxT2, R½1, T1Þ ¼ ~QT1
X
n
i¼1
ð1 þ Ri, T1Þxi, T2, R½1, T1
 
!
:
Similarly, QT2ðxT3, R½1, T2Þ depends on xT3 only through WT2, and
so on.
We may also note that the need for multistage modeling occurs here mainly
because of the nonlinearity of the utility function UðÞ. Indeed, if UðWÞ:W,
and the returns in diﬀerent stages are independent random vectors, it is
40
A. Ruszczyn´ski and A. Shapiro

suﬃcient to maximize the expected wealth after each period, in a completely
myopic fashion, by solving for t ¼ 0, . . . , T  1 the single stage models
Max
xt
E
X
n
i¼1
ð1 þ Ri, tþ1Þxi, tjR½1, t
"
#
s:t:
X
n
i¼1
xit ¼ Wt,
xt  0,
ð3:34Þ
where Wt and R1, . . . , Rt are already known. This, in turn, becomes a
deterministic model with the objective coeﬃcients
itðR½1, tÞ :¼ 1 þ E½Ri, tþ1jR½1, t:
Such a model has a trivial optimal solution of investing everything in the
asset with the maximum expected return in the next period.
A more realistic situation occurs in the presence of transaction costs. These
are losses associated with the changes in the numbers of units (stocks, bonds)
held. In such a situation multistage modeling is necessary, too, even if we use
the expected wealth objective.
Let us observe now that the above problem can be also modeled
as a T-period two-stage problem. To that end suppose that one makes a
decision at the beginning of the process without thinking of rebalancing
the portfolio. That is, our decision variables are initial amounts x1, . . . , xn
invested in assets 1, . . . , n at time t ¼ 0. After T periods of time each
asset i will be worth

 QT
t¼1 ð1 þ RitÞ

xi, and hence the total wealth will be
Pn
i¼1

 QT
t¼1 ð1 þ RitÞ

xi: The corresponding stochastic program can be then
written as follows
Max
x2Rn E U
X
n
i¼1
Y
T
t¼1
ð1 þ RitÞ
"
#
xi
 
!
"
#
s:t:
X
n
i¼1
xi ¼ W0,
xi  0,
i ¼ 1, . . . , n:
ð3:35Þ
Problem (3.35) is a two-stage stochastic program. It gives an extension of
the two-stage problem (3.21) for T periods of time. If the utility function is
given in the form (3.22), then problem (3.35) can be formulated as a linear
two-stage stochastic program in a way similar to (3.23)–(3.24).
The
diﬀerence
between
the
two-stage
(3.35)
and
multistage
(3.29)
programs is that in the two-stage model the value xit of asset i at time t is
Ch. 1. Stochastic Programming Models
41

deﬁned by the recursive equation14 xit ¼ ð1 þ RitÞxi, t1, which implies that
xit ¼ Qt
s¼1 ð1 þ RisÞ

xi0. Consequently, xit is completely determined by the
initial value xi0 ¼ xi and a realization of the random process Ri1, . . . , Rit. On
the other hand in the multistage model values xit are rebalanced at every
period of time subject to the constraints (3.26)–(3.27). Therefore the
multistage problem (3.29) can be viewed as a relaxation of the two-stage
problem (3.35), and hence has a larger optimal value.
We discuss further the above example in section ‘‘An Example of Financial
Planning’’ of chapter ‘‘Monte Carlo Sampling Methods’’.
The following example also demonstrates that in some cases the same
practical problem can be modeled as a multistage or two-stage multiperiod
program.
Example 8 (Queueing Process). Consider stochastic process It, t ¼ 1, 2, . . . ,
governed by the recursive equation
It ¼ ½It1 þ xt  Dtþ,
ð3:36Þ
with initial value I0. Here Dt are random numbers and xt represent
decision variables. The above process It can describe the waiting time of
t-th customer in a G=G=1 queue, where Dt is the interarrival time between
the ðt  1Þ-th and t-th customers and xt is the service time of ðt  1Þ-th
customer. Alternatively, we may view It as an inventory of a certain product
at time t, with Dt and xt representing the demand and production
(or reordering), respectively, of the product at time t. Equation (3.36)
assumes that the excess demand (over It1 þ xt) is not backordered, but
simply lost.
Suppose that the process is considered over a ﬁnite horizon at periods
t ¼ 1, . . . , T. Our goal then is to minimize (or maximize) the expected value of
an objective function involving I1, . . . , IT. For instance, one may be interested
in maximizing a proﬁt which at time t is given by ct min It1 þ xt, Dt
½
  htIt,
where ct and ht are positive parameters representing the marginal proﬁt and
the holding cost, respectively, of the product at period t. The negative of the
total proﬁt is then given by
Fðx, DÞ :¼
X
T
t¼1

htIt  ct min ½It1 þ xt, Dt

:
Here x ¼ ðx1, . . . , xTÞ is a vector of decision variables, D ¼ ðD1, . . . , DTÞ is a
random vector of the demands at periods t ¼ 1, . . . , T. By using the recursive
14 This deﬁnes an implementable and feasible policy for the multistage problem (3.29), see section
‘‘Multistage Models’’ of Chapter ‘‘Optimality and Quality in Stochastic Programming’’ for the
deﬁnition of implementable and feasible policies.
42
A. Ruszczyn´ski and A. Shapiro

equation (3.36) it is straightforward to show that Fðx, DÞ can be also written in
the form
Fðx, DÞ ¼
X
T
t¼1
qtIt 
X
T
t¼1
ctxt  c1I0,
where qt :¼ ht  ctþ1 þ ct, t ¼ 1, . . . , T  1, and qT :¼ cT þ hT. We assume
that all numbers qt are positive, this certainly holds if c1 ¼    ¼ cT. By
(3.36) we have that It is a convex function of x1, . . . , xt. Since qt are positive, it
follows that the function Fð, DÞ is convex for any realization of D.
We can formulate a corresponding stochastic programming problem
in several ways. First, suppose that the production cannot be changed
during the process as some realizations of the demands become known. That
is, a decision about production quantities x1, . . . , xT should be made before
any realization of the demands D1, . . . , DT is available, and is not changed
at times t ¼ 1, . . . , T. This leads to the problem of minimization of the
expectation E½Fðx, DÞ, which is taken with respect to the probability
distribution of the random vector D. Although, we have here a multiperiod
process, the above formulation can be viewed as a two-stage problem.
In fact it can be formulated as a linear two-stage stochastic program as
follows:15
Min
x0
cTx þ E½Qðx, DÞ


,
ð3:37Þ
where c ¼ ðc1, . . . , cTÞ and Qðx, DÞ is the optimal value of the problem
Min
y0
X
T
t¼1
qtyt
s:t:
yt1 þ xt  Dt  yt, t ¼ 1, . . . , T,
y0 ¼ I0:
ð3:38Þ
Note that It ¼ Itðx, DÞ is equal to y*t , t ¼ 1, . . . , T, where y* is the optimal
solution of (3.38).
Suppose now that the random vector D can take a ﬁnite number or
realizations (scenarios) D1, . . . , DK
with the corresponding probabilities
p1, . . . , pK. For example, if components Dt of the demand vector form a
Markov chain with m possible realizations at each period, then the total
15 Since I0 does not depend on x, the term c1I0 is omitted.
Ch. 1. Stochastic Programming Models
43

number of scenarios K ¼ mT. We can write then the two stage problem (3.37)–
(3.38) as the linear problem (compare with (2.7)):
Min 
X
T
t¼1
ctxt þ
X
K
k¼1
pk
X
T
t¼1
qtyk
t
 
!
s:t:
yk
t1 þ xt  Dk
t  yk
t ,
t ¼ 1, . . . , T,
xt  0, yk
0 ¼ I0, yk
t  0, t ¼ 1, . . . , T, k ¼ 1, . . . , K:
ð3:39Þ
Note that the optimal values of yk
t in (3.39) represent Itðx, DkÞ. Since
Itðx, DkÞ depend only on the realization Dk up to time t, the nonanticipativity
constraints with respect to yk
t hold in (3.39) automatically.
On the other hand, depending on the ﬂexibility of the production process,
one can update production quantities at every time period t ¼ 1, . . . , T using
known realizations of the demand up to time t. This can be formulated as a
multistage stochastic program where an optimal decision is made at every
period of time based on available realizations of the random data. Consider
the following relaxation of (3.39):
Min
X
K
k¼1
pk
X
T
t¼1
qtyk
t  ctxk
t


"
#
s:t:
y k
t1 þ x k
t  Dk
t  y k
t ,
t ¼ 1, . . . , T,
x k
t  0, y k
0 ¼ I0, y k
t  0, t ¼ 1, . . . , T, k ¼ 1, . . . , K:
ð3:40Þ
By adding to the above problem (3.40) the nonanticipativity constraints
associated with the scenario tree of the considered T-period process, we obtain
the
linear
programming
formulation
of
the
corresponding
multistage
stochastic program.
Example 9 (Trucking). A trucking company serves n locations. For simplicity
we assume that it takes exactly one day for a truck to go from one location to
another, independently whether it is loaded or not. At the beginning of each
day t, the company observes for each pair of locations, i and j, a random
demand Dijt for cargo to be shipped from i to j on day t. If they have a
suﬃcient number of trucks at location i at this moment, they may take an
order and ship the cargo. The revenue for shipping a unit of cargo from i to j
is qij. The part of the demand that is not served is simply lost, and it does not
result in any revenue or cost. It is important to stress that the numbers of
trucks at diﬀerent locations result from earlier decisions of moving the trucks
and are therefore parts of the policy. The company may also move empty
trucks between diﬀerent locations (in anticipation of strong demand some-
where else). The cost of moving one unit of capacity from i to j is cij,
44
A. Ruszczyn´ski and A. Shapiro

independently whether it is loaded or empty (this is not a simpliﬁcation,
because we can always adjust the qij’s). Currently, the company has the
capacity ri0 at each location i. Their objective is to maximize the expected
proﬁt in the next T days.
We recognize this problem as a multistage stochastic programming
problem. With each day (stage) t ¼ 1, . . . , T we associate the following
decision variables:
yijt - the total capacity moved from i to j, where i, j ¼ 1, . . . , n,
zijt - the amount of cargo moved from i to j, where i, j ¼ 1, . . . , n,
rit - the capacity available at i at the end of day t, where i ¼ 1, . . . , n.
Note that Diit ¼ 0 and ziit ¼ 0 by deﬁnition, and yiit is the capacity waiting
at i for the next day.
The problem takes on the form
Max
y, z, r E
X
T
t¼1
X
n
i, j¼1
ðqijzijt  cijyijtÞ
"
#
s:t:
zijt  Dijt,
i, j ¼ 1, . . . , n,
t ¼ 1, . . . , T,
zijt  yijt,
i, j ¼ 1, . . . , n,
t ¼ 1, . . . , T,
ri, t1 þ
X
n
k¼1
ykit 
X
n
j¼1
yijt ¼ rit,
i ¼ 1, . . . , n,
t ¼ 1, . . . , T,
r  0, y  0, z  0:
ð3:41Þ
In a more reﬁned version we may want to put some additional constraints
on the capacity riT available at each location i at the end of the planning
period.
In the above problem the demand DðtÞ ¼ ½DijðtÞi, j¼1,..., n is a random vector
valued process. The decisions yijt and zijt and the resulting numbers of trucks
rit at diﬀerent locations may depend on all past and current demand values
DðÞ,   t, but not on the future values of the demand vector. Therefore, at
stage t, we cannot exactly predict how many trucks we shall need at each
location at stage t þ 1; we can only use past data and our knowledge of the
joint distribution of all demands to re-position our truck ﬂeet. For a speciﬁed
scenario tree of the demand process DðtÞ, the corresponding multistage
problem can be written as a large linear program.
3.5
Relations to dynamic programming
There exist close relations between multistage stochastic programming
models and classical models of dynamic programming and optimal control.
Ch. 1. Stochastic Programming Models
45

To illustrate these relations, consider the linear dynamical system described by
the state equation
stþ1 ¼ Atst þ Btut þ Ctet,
t ¼ 1, . . . , T,
in which st denotes the state of the system at time t, ut is the control vector,
and et is a random ‘disturbance’ at time t. The matrices At, Bt and Ct are
known. The random vectors et, t ¼ 1, . . . , T, are assumed to be independent.
At time t we observe the current state value, st, but not the disturbances et.
Our objective is to ﬁnd a control law, ^utðÞ, t ¼ 1, . . . , T, so that the actual
values of the control variables can be determined through the feedback rule:
ut ¼ ^utðstÞ,
t ¼ 1, . . . , T  1:
We want to do it in such a way that the expected value of the performance
index,
E
X
T1
t¼1
Ftðst, utÞ þ FTðsTÞ
"
#
is minimized. In a more involved formulation, there may be additional
constraints on the control variables, or mixed state–control constraints:
gtiðst, utÞ  0,
i ¼ 1, . . . , mt,
t ¼ 1, . . . , T  1:
For the sake of simplicity we assume that they are all incorporated into the
deﬁnition of the partial objectives, that is, Ftðst, utÞ ¼ þ1 if these constraints
are not satisﬁed.
The crucial characteristics of the optimal control model is that we look for
a solution in the form of a function of the state vector. We are allowed to
focus on such a special form of the control rule due to the independence of the
disturbances at diﬀerent stages. If the disturbances are dependent in certain
ways, augmentation of the state space may reduce the model to the case of
independent et’s.
The key role in the optimal control theory is played by the cost-to-go
function
VtðstÞ :¼ infE
X
T1
¼t
Fðs, uÞ þ FTðsTÞ
"
#
,
46
A. Ruszczyn´ski and A. Shapiro

where the minimization is carried out among all possible feedback laws
applied at stages t, . . . , T  1. The functions VtðÞ give the dynamic program-
ming equation:
VtðstÞ ¼ inf
ut ðFtðst, utÞ þ E½Vtþ1ðAtst þ Btut þ CtetÞÞ,
t ¼ T  1, . . . , 1:
The optimal feedback rule is the minimizer of the above expression.
Except for very special cases, such as linear–quadratic or time optimal
control, the form of the optimal feedback rule may be very involved. Usually,
some functional form of the rule is assumed and parametric optimization
employed to ﬁnd the best rule within a chosen class. Discretization of the state
space is a common approach here.
To transform the above model into a stochastic programming model we
just need to make the substitutions:
xt ¼ ðut, stÞ,
t ¼ 1, . . . , T  1,
xT ¼ sT,
t ¼ Ct1et1,
t ¼ 2, . . . , T:
The function VtðÞ can be formally expressed as the optimal value of
Min
st, ut

Ftðst, utÞ þ E½Vtþ1ðAtst þ Btut þ CtetÞ

s:t:
st ¼ At1st1 þ Bt1ut1 þ t:
Thus, we can deﬁne
Qtðst1, ut1, tÞ ¼ VtðAt1st1 þ Bt1ut1 þ tÞ
to perfectly match both models.
The opposite of that is also true. A multistage stochastic programming
model with model state variables and independent random parameters t can
be transformed into a control problem, as in the following example.
Example 10 (Trucking (continued)). Let us consider Example 9 in which the
demand vectors Dijt, i, j ¼ 1, . . . , n are independent for t ¼ 1, . . . , T. We can
formally deﬁne:
st :¼ ½rt1, Dt, ut :¼ ½yt, zt, et :¼ Dtþ1:
Ch. 1. Stochastic Programming Models
47

Then the next state stþ1 is a function of st, ut and et:
rit ¼ ri, t1 þ
X
n
k¼1
ykit 
X
n
j¼1
yijt,
Dtþ1 ¼ et:
At each time t ¼ 1, . . . , T we have mixed state–control constraints:
zijt  Dijt,
i, j ¼ 1, . . . , n,
zijt  yijt,
i, j ¼ 1, . . . , n:
The objective functional has the form:
Ftðst, utÞ ¼
X
n
i, j¼1
ðqijzijt  cijyijtÞ,
and depends on controls alone. So, if the demands in diﬀerent days are
independent, the optimal solution has the form of a feedback rule:
yt ¼ ^ytðrt1, DtÞ,
zt ¼ ^ztðrt1, DtÞ:
The form of these functions is rather involved, though.
As we shall see it later, the stochastic programming formulation tries to
exploit as much as possible some advantageous properties of the functions
VtðÞ or QtðÞ, such as convexity, or polyhedral structure, which are hard to
exploit in the dynamic programming setting. Also, the stochastic program-
ming model does not assume the independence of the random disturbances.
It does require, though, in the scenario tree formulation the discretization of
the disturbances distributions.
4
Robust and min–max approaches to stochastic optimization
4.1
Robust models
Consider the two-stage stochastic linear program (2.2)–(2.3). In that
problem the optimal value Qðx, ð!ÞÞ of the second stage problem is optimized
on average. Of course, for a particular realization  of the random data ð!Þ
the corresponding value Qðx, Þ can be quite diﬀerent from the expected
value E½Qðx, ð!Þ. An ‘‘unlucky’’ realization of ð!Þ may have disastrous
48
A. Ruszczyn´ski and A. Shapiro

consequences for the user of stochastic programming. For instance, in
Example 1 the newsvendor may loose all his savings on an unlucky day, so
that he will have to borrow from the mob on murderous interest to continue
his business next day. In order to avoid such disastrous consequences one may
try to be more conservative and to reach a compromise between the average
(i.e, the mean) and a risk associated with variability of Qðx, Þ. It appears then
natural to add the term Var½Qðx, Þ to the objective of the optimization
problem, where coeﬃcient   0 represents a compromise between the
expectation and variability of the objective. Unfortunately, this destroys two
important properties of the two-stage linear program (2.2)–(2.3), namely its
convexity and second stage optimality.
In order to see that let us suppose for the sake of simplicity that there is a
ﬁnite number of scenarios and hence the problem can be formulated in the
form (2.7). By adding the term Var½Qðx, Þ to the objective function in (2.2)
we obtain the problem
Min
x
cTx þ  ðQðx, 1Þ, . . . , Qðx, KÞÞ
s:t:
Ax ¼ b, x  0,
ð4:1Þ
where
 ðzÞ :¼
X
K
k¼1
pkzk þ 
X
K
k¼1
pkz2
k 
X
K
k¼1
pkzk
 
!2
2
4
3
5:
Now for  > 0 the objective function of the above problem is not necessarily
convex even though the functions Qð, iÞ, i ¼ 1, . . . , K, are all convex, and the
second stage optimality does not hold in the sense that problem (4.1) is not
equivalent to the problem
Min
x, y1,..., yk cTx þ  

qT
1 y1, . . . , qT
KyK

s:t:
Ax ¼ b,
Tkx þ Wkyk ¼ hk,
x  0, yk  0, k ¼ 1, . . . , K:
ð4:2Þ
In order to preserve the property of second stage optimality we may change
the function  ðzÞ to a componentwise nondecreasing function. Recall that a
function  : RK ! R is said to be componentwise nondecreasing if  ðzÞ   ðz0Þ
for any z, z0 2 RK such that z  z0.
Ch. 1. Stochastic Programming Models
49

Proposition 11. Suppose that problem (4.2) is feasible and function  ðzÞ is
componentwise nondecreasing. Then problems (4.1) and (4.2) have the same
optimal value, and if, moreover, problem (4.2) has an optimal solution, then
problems (4.1) and (4.2) have the same set of ﬁrst stage optimal solutions.
Proof. Since (4.2) is feasible it follows that there exists a feasible x such that
all Qðx, kÞ, k ¼ 1, . . . , K, are less than þ1, and hence the optimal value of
problem (4.1) is also less than þ1. By (2.6) we have that Qðx, kÞ is given by
the optimal value of a linear programming problem. Therefore, if Qðx, kÞ is
ﬁnite, then the corresponding linear programming problem has an optimal
solution. It follows that if all Qðx, kÞ are ﬁnite, then  ðQðx, 1Þ, . . . , Qðx, KÞÞ
is equal to  ðqT
1 y1, . . . , qT
KyKÞ for some yk, k ¼ 1, . . . , K, satisfying the
constraints of problem (4.2) and hence the optimal value of (4.1) is greater
than or equal to the optimal value of (4.2). Conversely, for a given x, Qðx, kÞ
is less than or equal to qT
k yk, k ¼ 1, . . . , K, for any y1, . . . , yk feasible for (4.2).
Since  ðzÞ is componentwise nondecreasing, it follows that the optimal value
of (4.2) is greater than or equal to the optimal value of (4.1), and hence these
two optimal values are equal to each other. Moreover, it follows that if
x*, y*1, . . . , y*K is an optimal solution of problem (4.2), then x* is an optimal
solution of problem (4.1), and vice versa.
u
We also have that if  ðzÞ is componentwise nondecreasing and convex,
then since functions Qð, kÞ, k ¼ 1, . . . , K are convex, the corresponding
composite function and hence the objective function of problem (4.1) are
convex.
Of course, for  ðzÞ :¼ PK
k¼1 pkzk
problem (4.2) coincides with the
two-stage linear problem (2.7). Another possibility is to use a separable
function  ðzÞ ¼ PK
k¼1  kðzkÞ with one of the following two choices of
functions  k:
 kðzkÞ :¼ pkzk þ pkðzk  Þþ,
ð4:3Þ
 kðzkÞ :¼ pkzk þ pk½ðzk  Þþ2,
ð4:4Þ
for some   0 and  2 R. Note that for both above choices of  k, the
corresponding function  ðzÞ is componentwise nondecreasing and convex.
If the parameter  in (4.4) is equal to E½Qðx, Þ and the distribution of
Qðx, Þ is symmetrical around its mean, then
 ðQðx, 1Þ, . . . , Qðx, KÞÞ ¼ E½Qðx, Þ þ ð=2ÞVar½Qðx, Þ:
Of course, the mean (expected value) of Qðx, Þ depends on x; in practical
applications it would have to be iteratively adjusted during an optimization
procedure. An advantage of using  k given in (4.3) is that then the function
50
A. Ruszczyn´ski and A. Shapiro

 ðzÞ is piecewise linear, and hence (4.2) can be formulated as a linear
programming problem. The above approach to stochastic programming is
called robust by some authors.
The model (4.2) with (4.3) or (4.4) is an example of a mean–risk model. For
a random outcome Fðx, Þ, these models use an objective which is composed of
two parts: the expected outcome (the mean) E½Fðx, Þ, and a scalar composite
measure of the size and frequency of undesirable outcome values, the risk
ðFðx, ÞÞ. The risk measure ðZÞ is understood here as a function of the entire
distribution of the random variable Z. For example, our formulas (4.3) and
(4.4) correspond to risk measures
1ðZ; Þ :¼ E½ðZ  Þþ
and
2ðZ; Þ :¼ E


ðZ  Þþ
2
,
respectively, which represent the expected excess (or square excess) over the
target
level
.
More
sophisticated
are
semideviation
measures,
which
use, instead of the ﬁxed target level , the expected value of the random
outcome. The simplest and most convenient in applications is the absolute
semideviation:
1ðZÞ :¼ E½ðZ  EZÞþ:
ð4:5Þ
The presence of the expected value of the outcome in the deﬁnition of the
measure makes the resulting risk term
1ðFðx, ÞÞ ¼ E ðFðx, Þ  E½Fðx, ÞÞþ


,
a nonconvex function of x, even if Fð, Þ is convex. Nevertheless, the
corresponding mean–risk model
Min E½Fðx, Þ þ E ðFðx, Þ  E½Fðx, ÞÞþ




remains a convex problem, provided that the coeﬃcient  in front of the risk
term is conﬁned to ½0, 1. This can be seen from the representation:
E½Fðx, Þ þ E ðFðx, Þ  E½Fðx, ÞÞþ


¼ ð1  ÞE½Fðx, Þ þ E½maxfE½Fðx, Þ, Fðx, Þg,
in which the convexity of all terms is evident.
Ch. 1. Stochastic Programming Models
51

Example 12. Let us consider Example 3 again, but instead of bounding our
risk of loss by the probabilistic constraint P Pn
i¼1 Rixi  b

  1  , let us
modify the objective by subtracting a risk measure

X
n
i¼1
Rixi
 
!
:
ð4:6Þ
For example, similarly to (4.3), we may use
ðZÞ :¼ E½ð  ZÞþ,
ð4:7Þ
in which case (4.6) represents the expected shortfall below some target proﬁt
level . If  ¼ b < 0, our measure represents the expected loss in excess of b.
Supposing that our initial capital (wealth) is W, we may formulate the
following mean–risk optimization problem
Max
x0
X
n
i¼1
ixi  
X
n
i¼1
Rixi
 
!
(
)
s:t:
X
n
i¼1
xi  W:
ð4:8Þ
Problems of this type are usually solved as a family parametrized by   0.
Their solutions can be graphically depicted in the form of the eﬃcient frontier:
the collection of mean–risk pairs corresponding to the optimal solutions of
(4.8) for all   0.
If the risk measure (4.7) is used, the term E

  Pn
i¼1 Rixi


þ

can be
interpreted as the expected cost of a loan to cover the shortfall below , where
 is the interest rate. In this case problem (4.8) has a convenient linear
programming formulation, provided that the distribution of the returns is
discrete. It is very similar to the model for the semideviation risk measure
discussed below.
As we deal with a maximization problem, the semideviation risk measure
(4.5) should be modiﬁed to represent the shortfall below the mean:
1ðZÞ :¼ E½ðEZ  ZÞþ:
Then the mean–risk model (4.7) takes on the form
Max
x0
ð1  Þ
X
n
i¼1
ixi þ E min
X
n
i¼1
ixi,
X
n
i¼1
Rixi
 
!
"
#
(
)
s:t:
X
n
i¼1
xi  W:
52
A. Ruszczyn´ski and A. Shapiro

For a discrete distribution of R we can convert the above mean–risk model
into a linear programming problem. Indeed, let k ¼ 1, . . . , K denote scenarios,
and let Rik be the realization of the return of security i in scenario k. The
probabilities of scenarios are p1, . . . , pK, PK
k¼1 pk ¼ 1. Introducing new
variables  (representing the mean), and rk, k ¼ 1, . . . , K (representing the
worst case of return and its expected value) we obtain the problem
Max
x0, , r
ð1  Þ þ 
X
K
k¼1
pkrk
(
)
s:t:
X
n
i¼1
ixi ¼ ,
rk  ,
k ¼ 1, . . . , K,
rk 
X
n
i¼1
Rikxi,
k ¼ 1, . . . , K,
X
n
i¼1
xi  W:
It can be solved by standard linear programming techniques.
4.2
Min–max stochastic programming
In practical applications probability distributions of the involved uncertain
parameters are never known exactly and can be estimated at best. Even worse,
quite often the probabilities are assigned on an ad hoc basis by a subjective
judgment. Suppose now that there is a set S of probability distributions,
deﬁned on a sample space ð, FÞ, which in some reasonable sense give a
choice of the underlying probability distributions. For instance, in Example 3
one may foresee that the random investment returns will generally increase,
stay ﬂat or even decrease over the next T years. By specifying means,
representing a possible trend, and variability of the investment returns one
may assign a ﬁnite number of possible probability distributions for the
random data. Alternatively, certain properties, like ﬁrst- and maybe second-
order moments, unimodality or speciﬁed marginal distributions of the random
data can be postulated. Typically, this leads to an inﬁnite set S of considered
probability distributions.
There are two basic ways of dealing with such cases of several distributions.
One can assign a priori probability distribution over S, and hence reduce
the problem to a unique distribution. Suppose, for example, that S is
ﬁnite, say S :¼ fP1, . . . , Plg. Then by assigning probability i
to Pi,
i ¼ 1, . . . , l, one obtains the unique (posteriori) distribution P :¼ Pl
i¼1 iPi.
Ch. 1. Stochastic Programming Models
53

The distribution P represents an averaging over possible distributions Pi.
Again a choice of the a priori distribution f1, . . . , lg is often subjective.
An alternative approach is to hedge against the worst distribution by
formulating the following min–max analogue of stochastic programs (1.14),
(2.12):
Min
x2X Max
P2S EP½Fðx, !Þ:
ð4:9Þ
For the above problem to make sense it is assumed, of course, that for every
P 2 S the expectation EP½Fðx, !Þ is well deﬁned for all x 2 X.
In order to see a relation between these two approaches let us assume for
the sake of simplicity that the set S ¼ fP1, . . . , Plg is ﬁnite. Then problem (4.9)
can be written in the following equivalent way
Min
ðx, zÞ2XR z
s:t:
fiðxÞ  z,
i ¼ 1, . . . , l,
ð4:10Þ
where fiðxÞ :¼ EPi½Fðx, !Þ. Suppose further that problem (4.10), and hence
problem (4.9), is feasible and for every ! 2  the function Fð, !Þ is convex. It
follows from convexity of Fð, !Þ that the functions fiðÞ are also convex, and
hence problem (4.10) is a convex programming problem. Then, by the duality
theory of convex programming, there exist Lagrange multipliers i  0,
i ¼ 1, . . . , l, such that Pl
i¼1 i ¼ 1 and problem (4.10) has the same optimal
value as the problem
Min
x2X
f ðxÞ :¼
X
l
i¼1
i fiðxÞ
(
)
and the set of optimal solutions of (4.10) is included in the set of optimal
solutions of the above problem. Since f ðxÞ ¼ EP*½Fðx, !Þ, where P* :¼
Pl
i¼1 iPi, we obtain that problem (4.9) is equivalent to the stochastic
programming problem
Min
x2X EP*½Fðx, !Þ:
This shows that, under the assumption of convexity, the min–max
approach automatically generates an a priori distribution given by the
corresponding Lagrange multipliers. Of course, in order to calculate these
Lagrange multipliers one still has to solve the min–max problem. Existence of
such Lagrange multipliers, and hence of the a priori distribution, can be also
shown for an inﬁnite set S under the assumption of convexity and mild
regularity conditions.
54
A. Ruszczyn´ski and A. Shapiro

5
Appendix
In this section we brieﬂy discuss some basic concepts and deﬁnitions from
probability and optimization theories, needed for the development of
stochastic programming models. Of course, a careful derivation of the
required results goes far beyond the scope of this book. The interested reader
may look into standard textbooks for a thorough development of these topics.
5.1
Random variables
Let  be an abstract set. It is said that a set F of subsets of  is a sigma
algebra (also called sigma ﬁeld) if it is closed under standard set theoretic
operations, the set  belongs to F, and if Ai 2 F, i 2 N, then [i2NAi 2 F. The
set  equipped with a sigma algebra F is called a sample or measurable space
and denoted ð, FÞ. A set A   is said to be F-measurable if A 2 F. It is said
that the sigma algebra F is generated by its subset A if any F-measurable set
can be obtained from sets belonging to A by set theoretic operations and by
taking the union of a countable family of sets from A. That is, F is generated
by A if F is the smallest sigma algebra containing A.
If  coincides with a ﬁnite dimensional space Rm, unless stated otherwise,
we always equip it with its Borel sigma algebra B. Recall that B is generated by
the set of open (or closed) subsets of Rm. A function P : F ! ½0, 1 is called a
probability measure on ð, FÞ if PðÞ ¼ 1, and for every collection Ai 2 F,
i 2 N, such that Ai \ Aj ¼ ; for all i 6¼ j, we have Pð[i2NAiÞ ¼ P
i2N PðAiÞ. A
sample space ð, FÞ equipped with a probability measfure P is called a
probability space and denoted ð, F, PÞ. Recall that F is said to be P-complete
if A  B, B 2 F and PðBÞ ¼ 0, implies that A 2 F, and hence PðAÞ ¼ 0. Since
it is always possible to enlarge the sigma algebra and extend the measure in
such a way as to get complete space, we can assume without loss of generality
that considered probability measures are complete. It is said that an event
A 2 F happens P-almost surely (a.s.) or almost everywhere (a.e.) if PðAÞ ¼ 1,
or equivalently PðnAÞ ¼ 0.
A mapping V :  ! Rm is said to be measurable if for any Borel set A 2 B,
its
inverse
image
V1ðAÞ :¼ f! 2 : Vð!Þ 2 Ag
is
F-measurable.16
A
measurable mapping Vð!Þ from probability space ð, F, PÞ into Rm is called
a random vector. Note that the mapping V generates the probability measure
(also called the probability distribution) PðAÞ :¼ PðV1ðAÞÞ on ðRm, BÞ, which
provides all relevant probabilistic information about the considered random
vector. Clearly an event A 2 B happens P-almost surely iﬀthe corresponding
event V1ðAÞ 2 F happens P-almost surely. In particular, a measurable
mapping (function) Z:  ! R is called a random variable. Its probability
16 In fact it suﬃces to verify F-measurability of V1ðAÞ for any family of sets generating the Borel
sigma algebra of Rm.
Ch. 1. Stochastic Programming Models
55

distribution is completely deﬁned by the cumulative distribution function (cdf )
FZðzÞ :¼ PfZ  zg. Note that since the Borel sigma algebra of R is generated
by the family of half line intervals ð1, a, in order to verify measurability of
Zð!Þ it suﬃces to verify measurability of sets f! 2 : Zð!Þ  zg for all z 2 R.
We denote random vectors (variables) by capital letters, like V, Z etc., or ð!Þ,
and often suppress their explicit dependence on the elementary event !. Also
quite often we denote by the same symbol  a particular realization of the
random vector  ¼ ð!Þ. Usually, the meaning of such notation will be clear
from the context and will not cause any confusion. The coordinate functions
V1ð!Þ, . . . , Vmð!Þ of the m-dimensional random vector Vð!Þ are called its
components. While considering a random vector V we often talk about its
probability distribution as the joint distribution of its components (random
variables) V1, . . . , Vm.
Since we often deal with random variables which are given as optimal
values of optimization problems we need to consider random variables Zð!Þ
which can also take values þ1 or 1, i.e., functions Z:  ! R, where
R:¼ R [ f1g [ fþ1g denotes the set of extended real numbers. Such
functions Z:  ! R are referred to as extended real valued functions.
Operations between real numbers and symbols 1 are clear except for such
operations as adding þ1 and 1 which should be avoided. Measurability of
an extended real valued function Zð!Þ is deﬁned in the standard way, i.e., Zð!Þ
is measurable if the set f! 2 : Zð!Þ  zg is F-measurable for any z 2 R. A
measurable extended real valued function is called an (extended) random
variable. Note that here limz!þ1FZðzÞ is equal to the probability of the
event
f! 2 : Zð!Þ < þ1g
and
can
be
less
than
one
if
the
event
f! 2 : Zð!Þ ¼ þ1g has a positive probability.
The expected value or expectation of an (extended) random variable
Z:  ! R is deﬁned by the integral
EP½Z :¼
Z

Zð!Þ dPð!Þ:
ð5:1Þ
When there is no ambiguity as to what probability measure is considered,
we omit the subscript P and simply write E½Z. For a nonnegative valued
measurable function Zð!Þ such that the event :¼ f! 2 : Zð!Þ ¼ þ1g has
zero probability the above integral is deﬁned in the usual way and can take
value þ1. If probability of the event  is positive, then, by deﬁnition,
E½Z ¼ þ1. For a general (not necessarily nonnegative valued) random
variable we would like to deﬁne17 E½Z :¼ E½Zþ  E½ðZÞþ. In order to do
that we have to ensure that we do not add þ1 and 1. We say that the
expected value E½Z of an (extended real valued) random variable Zð!Þ is well
deﬁned if it does not happen that both E½Zþ and E½ðZÞþ are þ1, in which
case E½Z ¼ E½Zþ  E½ðZÞþ. That is, in order to verify that the expected
17 Recall that Zþ :¼ maxf0, Zg.
56
A. Ruszczyn´ski and A. Shapiro

value of Zð!Þ is well deﬁned one has to check that Zð!Þ is measurable and
either E½Zþ < þ1 or E½ðZÞþ < þ1. Note that if Zð!Þ and Z0ð!Þ are two
(extended) random variables such that their expectations are well deﬁned and
Zð!Þ ¼ Z0ð!Þ for all ! 2  except possibly on a set of measure zero, then
E½Z ¼ E½Z0. It is said that Zð!Þ is P-integrable if the expected value E½Z is
well deﬁned and ﬁnite. The expected value of a random vector is deﬁned
componentwise.
If the random variable Zð!Þ can take only a countable (ﬁnite) number of
diﬀerent values, say z1, z2, . . . , then it is said that Zð!Þ has a discrete
distribution (discrete distribution with a ﬁnite support). In such cases all
relevant
probabilistic
information
is
contained
in
the
probabilities
pi :¼ PfZ ¼ zig. In that case E½Z ¼ P
i pizi.
5.2
Expectation functions
Consider now the expectation optimization problem (1.14) with X :¼ Rn.
For a given x we can view FðxÞ ¼ Fðx, !Þ as a random variable. We assume
that the expectation function
f ðxÞ ¼ E½Fðx, !Þ
is well deﬁned, i.e., for every18 x 2 Rn the function Fðx, Þ is measurable, and
either E½FðxÞþ < þ1 or E½ðFðxÞÞþ < þ1. The (eﬀective) feasible set of
the problem (1.4) is given by X \ ðdom f Þ, where
dom f :¼ fx 2 Rn : f ðxÞ < þ1g
denotes the domain of f. It is said that f is proper if f ðxÞ > 1 for all x 2 Rn
and dom f 6¼ ;.
From the theoretical point of view it is convenient to incorporate the
constraints ‘‘x 2 X’’ into the objective function. That is, for any ! 2  deﬁne
Fðx, !Þ :¼
Fðx, !Þ,
if x 2 X,
þ1,
if x 62 X:

Then problem (1.4) can be written in the form
Min
x2X E½Fðx, !Þ:
ð5:2Þ
18 Since we are interested here in x belonging to the feasible set X, we can assume that f ðxÞ is well
deﬁned for x 2 X.
Ch. 1. Stochastic Programming Models
57

Clearly, the domain of the expectation function E½Fð, !Þ is X \ ðdom f Þ,
i.e., it coincides with the feasible set of problem (1.14). In the remainder of this
section we assume that the objective function Fðx, !Þ is extended real valued
and that the corresponding constraints are already absorbed into the objective
function.
For "  0 we say that x* 2 X is an "-optimal solution of the problem of
minimization of f ðxÞ over X if
f ðx*Þ  inf
x2X f ðxÞ þ ":
If the problem is infeasible (that is, f ðxÞ ¼ þ1 for every x 2 X), then any
x* 2 X is "-optimal. If the problem is feasible, and hence infx2X f ðxÞ < þ1,
then "-optimality of x* implies that f ðx*Þ < þ1, i.e., that x* 2 dom f . Note
that by the nature of the minimization process, if infx2Xf ðxÞ > 1, then for
any " > 0 there always exists an "-optimal solution.
An extended real valued function f : Rn ! R is called lower semicontinuous
(lsc) at a point x0 if
lim inf
x ! x0 f ðxÞ  f ðx0Þ:
It is said that f is lower semicontinuous if it is lsc at every point x 2 Rn. It is not
diﬃcult to show that f is lsc iﬀits epigraph
epi f :¼ fðx, Þ: f ðxÞ  g
is a closed subset of Rn  R.
Theorem 13. Let f : Rn ! R be a proper extended real valued function. Suppose
that f is lsc and its domain dom f is bounded. Then the set arg min x2 Rnf ðxÞ of its
optimal solutions is nonempty.
Since f is proper, its domain is nonempty, and hence infx2Rnf ðxÞ < þ1.
Let
us
take
a
number
c > infx2Rnf ðxÞ,
and
consider
the
level
set
S :¼ fx: f ðxÞ  cg. We have that the set S is nonempty, is contained in
dom f and hence is bounded, and is closed since f is lsc. Consequently, the set
S is compact, and clearly argmin x2 Rnf ðxÞ coincides with argmin x2 S f ðxÞ.
Therefore, the above theorem states the well known result that a lsc real
valued function attains its minimum over a nonempty compact subset of Rn.
The expected value function f ðxÞ:¼ E½Fðx, !Þ inherits various properties of
the functions Fð, !Þ. If for P-almost ! 2  the function Fð, !Þ is convex, then
the expected value function f ðÞ is also convex. Indeed, if  is ﬁnite, then f ðÞ is
a weighted sum of convex functions with nonnegative weights, and hence is
convex. The case of a general distribution can be then proved by passing to
a limit.
58
A. Ruszczyn´ski and A. Shapiro

As it is shown in the next proposition the lower semicontinuity of the
expected value function follows from the lower semicontinuity of Fð, !Þ.
Proposition 14. Suppose that: (i) for P-almost every ! 2  the function Fð, !Þ
is lsc at x0, (ii) Fðx, Þ is measurable for every x in a neighborhood of x0, (iii)
there exists P-integrable function Zð!Þ such that Fðx, !Þ  Zð!Þ for P-almost
all ! 2  and all x in a neighborhood of x0. Then for all x in a neighborhood of
x0 the expected value function f ðxÞ :¼ E½Fðx, !Þ is well deﬁned and lsc at x0.
Proof. It follows from assumptions (ii) and (iii) that f ðÞ is well deﬁned in a
neighborhood of x0. Under assumption (iii), it follows by Fatou’s lemma that
lim inf
x ! x0
Z

Fðx, !Þ dPð!Þ 
Z

lim inf
x ! x0 Fðx, !Þ dPð!Þ:
ð5:3Þ
Together with (i) this implies lower semicontinuity of f at x0.
u
In particular, let us consider the probabilistic constraints (1.20). We can
write these constraints in the form
E 1ð0, þ1ÞðGiðx, !ÞÞ


 ,
i ¼ 1, . . . , m:
ð5:4Þ
Suppose further that for P-almost every ! 2  the functions Gið, !Þ are lsc,
and for all x, Giðx, Þ are measurable. Then functions 1ð0, þ1ÞðGið, !ÞÞ are also
lsc for P-almost every ! 2 , and clearly are bounded. Consequently we
obtain by Proposition 14 that the corresponding expected value functions in
the left hand side of (5.4) are lsc. It follows that constraints (5.4), and hence
the probabilistic constraints (1.20), deﬁne a closed subset of Rn.
5.3
Optimal values and optimal solutions
We often have to deal with optimal value functions of min or max types.
That is, consider an extended real valued function h: Rn  Rm ! R and the
associated functions
fðxÞ:¼ inf
y2 Rm hðx, yÞ
and
 ðxÞ:¼ sup
y2 Rm hðx, yÞ:
ð5:5Þ
Proposition 15. The following holds. (i) Suppose that for every y 2 Rm
the function hð, yÞ is lsc. Then the max-function  ðxÞ is lsc. (ii) Suppose that
the function hð, Þ is lsc and there exists a bounded set S  Rm such that
dom hðx, Þ  S for all x 2 Rn. Then the min-function fðxÞ is lsc.
Ch. 1. Stochastic Programming Models
59

Proof. (i) The epigraph of the max-function  ðÞ is given by the intersection of
the epigraphs of hð, yÞ, y 2 Rm. By lower semicontinuity of hð, yÞ, these
epigraphs are closed, and hence their intersection is closed. It follows that  ðÞ
is lsc.
(ii) Consider a point x0 2 Rn and let fxkg be a sequence converging to x0
along which the lim infx!x0 fðxÞ is attained. If limk!1fðxkÞ ¼ þ1, then
clearly limk!1fðxkÞ  fðx0Þ, and hence f is lsc at x0. Therefore, we can
assume that fðxkÞ < þ1 for all k. Let " be a given positive number and
yk 2 Rm be such that hðxk, ykÞ  fðxkÞ þ ". Since yk 2 dom hðxk, Þ  S and S
is bounded, by passing to a subsequence if necessary we can assume that yk
converges to a point y0. By lower semicontinuity of hð, Þ we have then that
limk!1fðxkÞ  hðx0, y0Þ  "  fðx0Þ  ". Since " was arbitrary, it follows that
limk!1fðxkÞ  fðx0Þ, and hence fðÞ is lsc at x0. This completes the
proof.
u
Let F : Rn   ! R and let us now consider the optimal value
#ð!Þ :¼ inf
x2X Fðx, !Þ
ð5:6Þ
and the corresponding set
X*ð!Þ :¼ arg min
x2X Fðx, !Þ
ð5:7Þ
of optimal solutions. In order to deal with measurability of these objects we
need the following concepts.
Let G be a mapping from  into the set of subsets of Rn, i.e., G assigns to
each ! 2  a subset (possibly empty) Gð!Þ of Rn. We refer to G as a
multifunction and write G:  !
! Rn. It is said that G is closed valued if Gð!Þ is a
closed subset of Rn for every ! 2 . A closed valued multifunction G is said to
be measurable, if for every closed set A  Rn one has that the inverse image
G1ðAÞ :¼ f! 2 : Gð!Þ \ A 6¼ fg is F-measurable. Note that measurability of
G implies that the domain
dom G :¼ f! 2 : Gð!Þ 6¼ ;g ¼ G1ðRnÞ
of G is an F-measurable subset of .
It is said that a mapping G: dom G ! Rn is a selection of G if Gð!Þ 2 Gð!Þ
for all ! 2 dom G. If, in addition, the mapping G is measurable, it is said that
G is a measurable selection of G.
Theorem 16 (Castaing Representation theorem). A closed valued multifunction
G:  !
! Rn is measurable iﬀits domain is an F-measurable subset of  and there
exists a countable family fGigi2N, of measurable selections of G such that for
every ! 2 , the set
Gið!Þ: i 2 N


is dense in Gð!Þ.
60
A. Ruszczyn´ski and A. Shapiro

It follows from the above theorem that if G:  !
! Rn is a closed valued
measurable multifunction, then there exists at least one measurable selection
of G.
Deﬁnition 17. It is said that the function ðx, !Þ  Fðx, !Þ is random lower
semicontinuous if the associated epigraphical multifunction !  epi Fð, !Þ is
closed valued and measurable.
Note that close valuedness of the epigraphical multifunction means that for
every ! 2 , the epigraph epi Fð, !Þ is a closed subset of Rn  R, i.e., that
Fð, !Þ is lsc.
Theorem 18. Suppose that the sigma algebra F is P-complete. Then an extended
real valued function F : Rn   ! R is random lsc iﬀthe following two
properties hold: (i) for every ! 2 , the function Fð, !Þ is lsc, (ii) the function
Fð, Þ is measurable with respect to the sigma algebra of Rn   given by the
product of the sigma algebras B and F.
A large class of random lower semicontinuous functions is given by the
so-called Carathe´odory functions, i.e., real valued functions F : Rn   ! R
such that Fðx, Þ is F-measurable for every x 2 Rn and Fð, !Þ continuous for
a.e. ! 2 .
Theorem 19. Let F : Rn   ! R be a random lsc function. Then the optimal
value function #ð!Þ and the optimal solution multifunction X*ð!Þ are both
measurable.
Note that it follows from lower semicontinuity of Fð, !Þ that the optimal
solution multifunction X*ð!Þ is closed valued. Note also that if Fðx, !Þ is
random lsc and G:  !
! Rn is a closed valued measurable multifunction, then
the function
Fðx, !Þ :¼
Fðx, !Þ,
if x 2 Gð!Þ,
þ1,
if x 62 Gð!Þ,

is
also
random
lsc.
Consequently
the
corresponding
optimal
value
!  infx2Gð!ÞFðx, !Þ
and
the
optimal
solution
multifunction
! 
argminx2Gð!ÞFðx, !Þ are both measurable, and hence by the measurable selection
theorem, there exists a measurable selection xð!Þ 2 argminx2Gð!ÞFðx, !Þ.
Theorem 20. Let F : Rnþm   ! R be a random lsc function and
#ðx, !Þ :¼ inf
y2Rm Fðx, y, !Þ
ð5:8Þ
be the associated optimal value function. Suppose that there exists a bounded set
S  Rm such that domFðx,  , !Þ  S for all ðx, !Þ 2 Rn  . Then the optimal
value function #ðx, !Þ is random lsc.
Ch. 1. Stochastic Programming Models
61

Let us ﬁnally observe that the above framework of random lsc functions
is aimed at minimization problems. Of course, the problem of maximization
of E½Fðx, !Þ is equivalent to minimization of E½Fðx, !Þ. Therefore, for
maximization problems one would need the comparable concept of random
upper semicontinuous functions.
6
Bibliographic notes
Stochastic programming with recourse originated in the works of Beale
(1955) and Dantzig (1955). Basic properties of two-stage problems were
investigated by Wets (1966), Walkup and Wets (1967, 1969) and Kall (1976).
A comprehensive treatment of the theory and numerical methods for
expectation models can be found in Birge and Louveaux (1997). Simulation-
based approaches to stochastic optimization were discussed by various
authors, see Chapter ‘‘Monte Carlo Sampling Methods’’.
Models involving constraints on probability were introduced by Charnes
et al. (1958), Miller and Wagner (1965), and Pre´ kopa (1970). Pre´ kopa (1995)
discusses in detail the theory and numerical methods for linear chance-
constrained models. Applications to ﬁnance are discussed by Dowd (1997).
Klein Haneveld (1986) introduced the concept of integrated chance constraints,
which are the predecessors of conditional value at risk constraints of Uryasev
and Rockafellar (2001).
A general discussion of interchangeability of minimization and integration
operations can be found in Rockafellar and Wets (1998). Proposition 5 is a
particular case of Theorem 14.60 in Rockafellar and Wets (1998).
Expected value of perfect information is a classical concept in decision
theory (see, e.g., Raiﬀa (1968)). In stochastic programming this and related
concepts were analyzed ﬁrst by Madansky (1960). Other advances are due to
Dempster (1981) and Birge (1982).
Early contributions to multistage stochastic programming models appeared
in Marti (1975), Beale et al. (1980), Louveaux (1980), Birge (1985), Noe¨ l and
Smeers (1986) and Dempster (1981). Varaiya and Wets (1989) discuss
relations of multistage stochastic programming and stochastic control. For
other examples and approaches to multistage modeling see Birge and
Louveaux (1997).
Robust approaches to stochastic programming were initiated by Mulvey
et al. (1995). Proposition 11 is based on the work of Takriti and Ahmed
(2002). Mean–risk models in portfolio optimization were introduced by
Markowitz (1952). For a general perspective, see Markowitz (1987) and
Luenberger (1998). Mean–absolute deviation models for portfolio problems
were introduced by Konno and Yamazaki (1991). Semideviations and other
risk measures were analyzed by Ogryczak and Ruszczyn´ ski (1999, 2001, 2002).
Min–max approach to stochastic programming was initiated in Z˘ a´ cˇ kova´
(1966), Dupacˇ ova´ (1980), Dupacˇ ova´ (1987).
62
A. Ruszczyn´ski and A. Shapiro

There are many good textbooks on probability and measure theory, e.g.,
Billingsley (1995), to which we refer for a thorough discussion of such basic
concepts as random variables, probability space, etc. Also a proof of Fatou’s
lemma, used in the proof of Proposition 14, can be found there. For an
additional discussion of the expected value function see section ‘‘Expectation
Functions’’ of Chapter 2. Continuity and diﬀerentiability properties of the
optimal value functions, of the form deﬁned in equation (5.5), were studied
extensively in the optimization literature (see, e.g., Bonnans and Shapiro
(2000) and the references therein).
Measurable selection theorem (Theorem 16) is due to Castaing. A thorough
discussion of measurable mappings and selections can be found in Castaing
and Valadier (1977), Ioﬀe and Tihomirov (1979) and Rockafellar and Wets
(1998). Random lower semicontinuous functions are called normal integrands
(see Deﬁnition 14.27 in Rockafellar and Wets (1998)) by some authors. Proofs
of theorems 18, 19 and 20 can be found in the section on normal integrands of
Rockafellar and Wets (1998).
References
Beale, E.M.L. (1955). On minimizing a convex function subject to linear inequalities. Journal of the
Royal Statistical Society Series B 17, 173–184.
Beale, E.M.L., J.J.H. Forrest, C.J. Taylor (1980). Multi-time-period stochastic programming, in:
M.A.H. Dempster (ed.), Stochastic Programming, Academic Press, New York, pp. 387–402.
Billingsley, P. (1995). Probability and Measure, John Wiley & Sons, New York.
Birge, J.R. (1982). The value of the stochastic solution in stochastic linear programs with ﬁxed
recourse. Mathematical Programming 33, 314–325.
Birge, J.R. (1985). Decomposition and partitioning methods for multistage stochastic linear programs.
Operations Research, 989–1007.
Birge, J.R., F.V. Louveaux (1997). Introduction to Stochastic Programming, Springer-Verlag,
New York.
Bonnans, J.F., A. Shapiro (2000). Perturbation Analysis of Optimization Problems, Springer-Verlag,
New York, NY.
Castaing, C., M. Valadier (1977). Convex Analysis and Measurable Multifunctions, Lecture Notes
in Mathematics, Vol. 580, Springer-Verlag, Berlin.
Charnes, A., W.W. Cooper, G.H. Symonds (1958). Cost horizons and certainty equivalents: an
approach to stochastic programming of heating oil. Management Science 4, 235–263.
Dantzig, G.B. (1955). Linear programming under uncertainty. Management Science 1, 197–206.
Dempster, M.A.H. (1981). The expected value of perfect information in the optimal evolution of
stochastic systems, in: M. Arato, D. Vermes, A.V. Balakrishnan (eds.), Stochastic Diﬀerential
Systems, Lecture Notes in Control and Information Systems, Vol. 36. Springer-Verlag, Berlin,
pp. 25–41.
Dowd, K. (1997). Beyond Value at Risk. The Science of Risk Management, Wiley, New York.
Dupacˇ ova´ , J. (1980). On minimax decision rule in stochastic linear programming Studies on
Mathematical Programming, A. Pre´ kopa Akade´ miai Kiado´ , Budapest, pp. 47–60.
Dupacˇ ova´ , J. (1987). The minimax approach to stochastic programming and an illustrative
application. Stochastics 20, 73–88.
Ioﬀe, A.D., V.M. Tihomirov (1979). Theory of Extremal Problems, North-Holland Publishing
Company, Amsterdam.
Ch. 1. Stochastic Programming Models
63

Kall, P. (1976). Stochastic Linear Programming, Springer-Verlag, Berlin.
Klein Haneveld, W.K. (1986). Duality in Stochastic Linear and Dynamic Programming, Lecture Notes
in Economic and Mathematical Systems, Vol. 274, Springer-Verlag, New York.
Konno, H., H. Yamazaki (1991). Mean–absolute deviation portfolio optimization model and its
application to Tokyo stock market. Management Science 37, 519–531.
Louveaux, F.V. (1980). A solution method for multistage stochastic programs with recourse with
applications to an energy investment problem. Operations Research 28, 889–902.
Luenberger, D.G. (1998). Investment Science, Oxford University Press, New York.
Madansky, A. (1960). Inequalities for stochastic linear programming problems. Management Science 6,
197–204.
Markowitz, H.M. (1952). Portfolio selection. Journal of Finance 7, 77–91.
Markowitz, H.M. (1987). Mean–Variance Analysis in Portfolio Choice and Capital Markets, Blackwell,
Oxford.
Marti, K. (1975). U¨ ber zwei- und mehrstuﬁge stochastische Kontrollprobleme, in: Vortra¨ ge der
Wissenschaftlichen Jahrestagung der Gesellschaft fu¨ r Angewandte Mathematik und Mechanik
(Bochum, 1974). Zeitschrift fu¨r Angewandte Mathematik und Mechanik 55, T281–T282.
Miller, L.B., H. Wagner (1965). Chance-constrained programming with joint constraints. Operations
Research 13, 930–945.
Mulvey, J.M., R.J. Vanderbei, S.A. Zenios (1995). Robust optimization of large-scale systems.
Operations Research 42, 264–281.
Noe¨ l, M.-C., Y. Smeers (1986). On the use of nested decomposition for solving nonlinear multistage
stochastic programs, in: Stochastic Programming (Gargnano, 1983), Lecture Notes in Control and
Inform. Sci., Vol. 76, Springer-Verlag, Berlin, pp. 235–246.
Ogryczak, W., A. Ruszczynski (1999). From stochastic dominance to mean–risk models: semidevia-
tions as risk measures. European Journal of Operational Research 116, 33–50.
Ogryczak, W., A. Ruszczyn´ ski (2001). On consistency of stochastic dominance and mean–
semideviation models. Mathematical Programming 89, 217–232.
Ogryczak, W., A. Ruszczynski (2002). Dual stochastic dominance and related mean–risk models.
SIAM Journal on Optimization 13, 60–78.
Pﬂug, G.Ch. (1996). Optimization of Stochastic Models. The Interface Between Simulation and
Optimization, Kluwer Academic Publishers, Boston, MA.
Pre´ kopa, A. (1970). On probabilistic constrained programming: Proceedings of the Princeton
Symposium on Mathematical Programming, Princeton University Press, Princeton, pp. 113–138.
Pre´ kopa, A. (1995). Stochastic Programming, Kluwer, Dordrecht, Boston.
Raiﬀa, H. (1968). Decision Analysis, Addison–Wesley, Reading, MA.
Rockafellar, R.T., R.J.-B. Wets (1998). Variational Analysis, Springer-Verlag, Berlin.
Takriti, S., S. Ahmed (2002). On robust optimization of two-stage systems. Mathematical
Programming. To appear.
Uryasev, S., R.T. Rockafellar (2001). Conditional value-at-risk: optimization approach). Stochastic
optimization: algorithms and applications (Gainesville, FL, 2000), Applied Optimization, Vol. 54,
Kluwer Academic Publishers, Dordrecht, pp. 411–435.
Varaiya, P., R.J.-B. Wets (1989). Stochastic dynamic optimization approaches and computation, in:
M. Iri, K. Tanabe (eds.), Mathematical Programming: Recent Developments and Applications,
Kluwer, Dordrecht, pp. 309–332.
Walkup, D., R.J.-B. Wets (1967). Stochastic programs with recourse. SIAM Journal on Applied
Mathematics 15, 1299–1314.
Walkup, D., R.J.-B. Wets (1969). Stochastic programs with recourse II: on the continuity of the
objective. SIAM Journal on Applied Mathematics 15, 1299–1314.
Wets, R.J.-B. (1966). Programming under uncertainty: the equivalent convex program. SIAM Journal
on Applied Mathematics 14, 89–105.
Z˘ a´ ckova´ , J. (1966). On minimax solutions of stochastic linear programming problems. C˘as. Pest. Mat.
91, 423–430.
64
A. Ruszczyn´ski and A. Shapiro

Chapter 2
Optimality and Duality in Stochastic Programming
Andrzej Ruszczyn´ski
Department of Management Science and Information Systems, Rutgers University,
94 Rockafeller Rd, Piscataway, NJ 08854, USA
Alexander Shapiro
School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta,
GA 30332, USA
Abstract
In this chapter we discuss basic mathematical properties of convex stochastic
programming models. We develop expressions for the subdiﬀerentials of the
objective function in two- and multi-stage models. Then we present necessary
and suﬃcient conditions of optimality, and duality relations for these problems.
Key words:
Expected value function, two stage stochastic programming,
multistage stochastic programming, optimality conditions, duality.
1
Expectation functions
In this section we discuss general properties of the expectation (also called
expected value) functions of the form
f ðxÞ :¼ EP½Fðx, !Þ:
ð1:1Þ
Here P is a probability measure deﬁned on a measurable space ð, FÞ and
F : Rn   ! R is an extended real valued function, called an integrand. The
function f(x) is well deﬁned on a set X  Rn if for every x 2 X the function
Fðx, Þ is measurable, and either E½Fðx, !Þþ < þ1 or E½ðFðx, !ÞÞþ < þ1
(see Chapter 1, Appendix).
The expected value function f(x) inherits various properties of the integrand
Fðx, !Þ. We already gave a preliminary discussion of that in Section 5.2 of
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
65

Chapter 1. In particular, it was shown in Proposition 14 that as a consequence
of Fatou’s lemma, f ðÞ inherits lower semicontinuity of Fð, !Þ under the
condition that, locally in x, Fðx, Þ is bounded from below by a P-integrable
function. The following proposition gives similar conditions for the continuity
of f(x) at a point x0 2 Rn.
Proposition 1. Suppose that: (i) for P-almost every ! 2  the function Fð, !Þ is
continuous at x0, (ii) Fðx, Þ is measurable for every x in a neighborhood of x0,
(iii) there exists P-integrable function Z(!) such that jFðx, !Þj  Zð!Þ for
P-almost every ! 2  and all x in a neighborhood of x0. Then for all x in a
neighborhood of x0 the expected value function f (x) is well deﬁned and
continuous at x0.
Proof. It follows from assumptions (ii) and (iii) that f (x) is well deﬁned for all
x in a neighborhood of x0. Moreover, by the Lebesgue Dominated
Convergence Theorem we can take the limit inside the integral, which
together with (i) implies
lim
x!x0
Z

Fðx, !Þ dPð!Þ ¼
Z

lim
x!x0 Fðx, !Þ dPð!Þ ¼
Z

Fðx0, !Þ dPð!Þ:
ð1:2Þ
This shows the continuity of f ðxÞ at x0.
u
Consider, for example, the characteristic function Fðx, !Þ :¼ 1ð1, xðð!ÞÞ,
with x 2 R
and  ¼ ð!Þ being a
real valued random variable. We
have then that f ðxÞ ¼ Pð  xÞ, i.e., that f ðÞ is the cumulative distribution
function of . It follows that in this example the expected value function is
continuous at a point x0 iﬀthe the probability of the event f ¼ x0g is zero.
Note that x ¼ ð!Þ is the only point at which the function Fð, !Þ is
discontinuous.
We discuss now the diﬀerentiability properties of the expected value
function f(x) deﬁned in (1.1). We sometimes write F!ðÞ for the function Fð, !Þ
and denote by F0
!ðx0, hÞ the directional derivative of F!ðÞ at the point x0 in the
direction h. Deﬁnitions and basic properties of directional derivatives are
given in Section 9.1 of the Appendix.
Proposition 2. Suppose that: (i) Fðx, Þ is measurable for all x in a neighborhood
of x0, (ii) EjFðx0, !Þj < þ1, (iii) there exists a positive valued random variable
Cð!Þ such that E½Cð!Þ < þ1, and for all x1, x2 in a neighborhood of x0 and
almost every ! 2  the following inequality holds
jFðx1, !Þ  Fðx2, !Þj  Cð!Þkx1  x2k,
ð1:3Þ
66
A. Ruszczyn´ski and A. Shapiro

(iv) for almost every ! the function F!ðÞ is directionally diﬀerentiable at x0.
Then the expected value function f (x) is Lipschitz continuous in a neighborhood
of x0, directionally diﬀerentiable at x0, and
f 0ðx0, hÞ ¼ E F0
!ðx0, hÞ


,
for all h:
ð1:4Þ
If, in addition, the function Fð, !Þ is diﬀerentiable at x0 w.p.1, then f (x) is
diﬀerentiable at f (x) and
rf ðx0Þ ¼ E rxFðx0, !Þ
½
:
ð1:5Þ
Proof. It follows from (1.3) that for any x1, x2 in a neighborhood of x0,
j f ðx1Þ  f ðx2Þj 
Z

jFðx1, !Þ  Fðx2, !Þj dPð!Þ  Ckx1  x2k,
where C :¼ E½Cð!Þ. Since f(x0) is ﬁnite by assumption (ii), it follows that f(x)
is well deﬁned, ﬁnite valued and Lipschitz continuous in a neighborhood of x0.
For t 6¼ 0 consider the ratio
Rtð!Þ :¼ t1½Fðx0 þ th, !Þ  Fðx0, !Þ:
By assumption (iii) we have that jRtð!Þj  Cð!Þkhk, and by assumption (iv)
that
lim
t#0 Rtð!Þ ¼ F0
!ðx0, hÞ
w:p:1:
Therefore, it follows from the Lebesgue Dominated Convergence Theorem
that
lim
t#0
Z

Rtð!Þ dPð!Þ ¼
Z

lim
t#0 Rtð!Þ dPð!Þ:
Together with assumption (iv) this implies formula (1.4).
Finally, if F0
!ðx0, hÞ is linear in h for almost every !, i.e., the function F!ðÞ is
diﬀerentiable at x0 w.p.1, then (1.4) implies that f 0ðx0, hÞ is linear in h, and
hence (1.5) follows. Note that since f (x) is locally Lipschitz continuous, we
only need to verify linearity of f 0ðx0, Þ in order to establish (Fre´ chet)
diﬀerentiability of f(x) at x0.
u
The above analysis shows that two basic conditions for interchangeability
of the expectation and diﬀerentiation operators, i.e., for the validity of
Ch. 2. Optimality and Duality in Stochastic Programming
67

formula (1.5), are: (a) the local Lipschitz continuity of the random function
Fð, !Þ; and (b) the diﬀerentiability of Fð, !Þ at the given point x0 w.p.1. The
following lemma shows that if, in addition to the assumptions of the above
proposition, the directional derivative F0
!ðx0, hÞ is convex in h w.p.1 (i.e., for
almost every !), then f(x) is diﬀerentiable at x0 if and only if Fð, !Þ is
diﬀerentiable at x0 w.p.1.
Lemma 3. Let  : Rn   ! R be a function such that for almost every ! 2 
the function  ð, !Þ is convex and positively homogeneous, and the expected
value function ðhÞ :¼ E½ ðh, !Þ is well deﬁned and ﬁnite valued. Then the
expected value function ðÞ is linear if and only if the function  ð, !Þ is linear
w.p.1.
Proof. We have here that the expected value function ðÞ is convex and
positively homogeneous. Moreover, it immediately follows from the linearity
properties of the expectation operator that if the function  ð, !Þ is linear
w.p.1, then ðÞ is also linear.
Conversely, let e1, . . . , en be a basis of the space Rn. Since ðÞ is convex
and
positively
homogeneous,
it
follows
that
ðeiÞ þ ðeiÞ  ð0Þ ¼
0, i ¼ 1, . . . , n: Furthermore, since ðÞ is ﬁnite valued, it is the support
function of a convex compact set. This convex set is a singleton iﬀ
ðeiÞ þ ðeiÞ ¼ 0,
i ¼ 1, . . . , n:
ð1:6Þ
Therefore, ðÞ is linear iﬀcondition (1.6) holds. Consider the sets
Ai :¼ f! 2 :  ðei, !Þ þ  ðei, !Þ > 0g:
Thus the set of ! 2  such that  ð, !Þ is not linear coincides with the set
[n
i¼1Ai. If P [n
i¼1Ai


> 0, then at least one of the sets Ai has a positive
measure. Let, for example, PðA1Þ be positive. Then ðe1Þ þ ðe1Þ > 0, and
hence ðÞ is not linear. This completes the proof.
u
Regularity conditions which are required for formula (1.4) to hold are
simpliﬁed further if the integrand Fðx, !Þ is convex, i.e., the function Fð, !Þ is
convex for almost every ! 2 . In that case, by using the Monotone
Convergence Theorem instead of the Lebesgue Dominated Convergence
Theorem, it is possible to prove the following result.
Proposition 4. Suppose that: (i) the expected value function f ðxÞ is well deﬁned
and ﬁnite valued in a neighborhood of a point x0, (ii) for almost every ! 2  the
function F!ðÞ :¼ Fð, !Þ is convex. Then f (x) is convex, directionally dif-
ferentiable at x0 and formula (1.4) holds. Moreover, f (x) is diﬀerentiable at x0 if
and only if F!ðxÞ is diﬀerentiable at x0 w.p.1, in which case formula (1.5) holds.
68
A. Ruszczyn´ski and A. Shapiro

Proof. The convexity of f (x) follows immediately from the convexity of F!ðÞ
(we already discussed that in Chapter 1). Consider a direction h 2 Rn. By
assumption (i) we have that f(x0) and, for some t0 > 0, f ðx0 þ t0hÞ are ﬁnite. It
follows from the convexity of F!ðÞ that the ratio
Rtð!Þ :¼ t1½Fðx0 þ th, !Þ  Fðx0, !Þ
is monotonically decreasing to F0
!ðx0, hÞ as t # 0. Also we have that
EjRt0ð!Þj  t1
0 ðEjFðx0 þ t0h, !Þj þ EjFðx0, !ÞjÞ < þ1:
Then it follows by the Monotone Convergence Theorem that
lim
t#0 E½Rtð!Þ ¼ E lim
t#0 Rtð!Þ


¼ E F0
!ðx0, hÞ


:
This proves formula (1.4). The last assertion follows then from Lemma 3.
u
Remark 5. It is possible to give a version of the above result for a particular
direction h 2 Rn. That is, suppose that: (i) the expected value function f(x)
is well deﬁned in a neighborhood of a point x0, (ii) f(x0) is ﬁnite, (iii) for almost
every ! 2  the function F!ðÞ :¼ Fð, !Þ is convex, (iv) E½Fðx0 þ t0h, !Þ < þ1
for some t0 > 0. Then f 0ðx0, hÞ < þ1 and formula (1.4) holds. Note also that
if the above assumptions (i)–(iii) are satisﬁed and E½Fðx0 þ th, !Þ ¼ þ1 for
any t > 0, then clearly f 0ðx0, hÞ ¼ þ1.
Often the expectation operator smoothes the integrand Fðx, !Þ. Consider,
for example, Fðx, !Þ :¼ jx  ð!Þj with x 2 R and ð!Þ being a real valued
random variable. Suppose that f ðxÞ ¼ E½Fðx, !Þ is ﬁnite valued. We have here
that Fð, !Þ is convex and Fð, !Þ is diﬀerentiable everywhere except x ¼ ð!Þ.
The corresponding derivative is given by @Fðx, !Þ=@x ¼ 1 if x > ð!Þ and
@Fðx, !Þ=@x ¼ 1 if x < ð!Þ. Therefore, f(x) is diﬀerentiable at x0 iﬀthe event
ð!Þ ¼ x0


has zero probability, in which case df ðx0Þ=dx ¼ E @Fðx0, !Þ=@x
½
. If
the event ð!Þ ¼ x0


has positive probability, then the directional derivatives
f 0ðx0, hÞ exist but are not linear in h, that is,
f 0ðx0,  1Þ þ f 0ðx0, 1Þ ¼ 2Pðð!Þ ¼ x0Þ > 0:
We can also investigate diﬀerentiability properties of the expectation
function by studying the subdiﬀerentiability of the integrand. Suppose for the
moment that the set  is ﬁnite, say  :¼ !1, . . . !K
f
g with Pf! ¼ !kg ¼ pk > 0,
and that the functions Fð, !Þ, ! 2 , are proper. Then f ðxÞ ¼ PK
k¼1 pkFðx, !kÞ
and dom f ¼ \
k¼1dom Fk, where FkðÞ :¼ Fð, !kÞ. The Moreau–Rockafellar
Ch. 2. Optimality and Duality in Stochastic Programming
69

Theorem (Theorem 50) allows us to express the subdiﬀerential of f ðxÞ as the
sum of subdiﬀerentials of pkFðx, !kÞ.
Theorem 6. Suppose that: (i) the set  ¼ !1, . . . !K
f
g is ﬁnite, (ii) for every
!k 2  the function FkðÞ :¼ Fð, !kÞ is proper and convex, (iii) the sets
riðdom FkÞ, k ¼ 1, . . . , K, have a common point. Then for any x0 2 dom f ,
@f ðx0Þ ¼
X
K
k¼1
pk@Fðx0, !kÞ:
ð1:7Þ
Note that the regularity assumption (iii) holds, in particular, if the interior
of dom f is nonempty.
The subdiﬀerentials at the right hand side of (1.7) are taken with respect to
x, and the sum of these subdiﬀerentials is understood to be the set of all points
of the form PK
k¼1 pkGk with Gk being a selection (i.e., an element) of
@Fðx0, !kÞ. Note that @Fðx0, !kÞ, and hence @f ðx0Þ, in (1.7) can be unbounded
or empty. Suppose that all probabilities pk are positive. It follows then from
(1.7) that @f ðx0Þ is a singleton iﬀall subdiﬀerentials @Fðx0, !kÞ, k ¼ 1,. . . ,K, are
singletons. That is, f ðÞ is diﬀerentiable at a point x0 2 dom f iﬀall Fð, !kÞ
are diﬀerentiable at x0.
In the case of a ﬁnite set  we did not have to worry about the
measurability of the multifunction !  @Fðx, !Þ. Consider now a general case
where the measurable space does not need to be ﬁnite. Recall that the function
Fðx, !Þ is said to be random lower semicontinuous if the multifunction
!  epi Fð, !Þ is closed valued and measurable (see the Appendix of Chapter 1
for a discussion of that concept).
Proposition 7. Suppose that the function Fðx, !Þ is random lower semicontin-
uous and for a.e. ! 2  the function Fð, !Þ is convex and proper. Then for any
x 2 Rn, the multifunction !  @Fðx, !Þ is measurable.
Proof. Consider the conjugate
F*ðz, !Þ :¼ sup
x2Rn zTx  Fðx, !Þ


of the function Fð, !Þ. It is possible to show that the function F*ðz, !Þ is also
random lower semicontinuous. Moreover, by the Fenchel–Moreau Theorem,
F** ¼ F and by convex analysis (see (9.15))
@Fðx, !Þ ¼ arg max
z2Rn
zTx  F*ðz, !Þ


:
70
A. Ruszczyn´ski and A. Shapiro

It follows then by Theorem 19 from the Appendix of Chapter 1 that the
multifunction !  @Fðx, !Þ is measurable.
u
Deﬁnition 8. For a given x 2 Rn, the integral
R
 @Fðx, !Þ dPð!Þ is deﬁned as
the set of all points of the form
R
 Gð!Þ dPð!Þ, where Gð!Þ is P-integrable
selection of @Fðx, !Þ, i.e., Gð!Þ 2 @Fðx, !Þ for a.e. ! 2 , Gð!Þ is measurable
and
R
 kGð!Þk dPð!Þ is ﬁnite.
Of course, if  ¼ f!1, . . . , !Kg is ﬁnite, then we do not have to worry about
the integrability of a selection Gð!Þ 2 @Fðx, !Þ and
Z

@Fðx, !Þ dPð!Þ ¼
X
K
k¼1
pk@Fðx, !kÞ:
In general we have the following extension of formula (1.7).
Theorem 9. Suppose that: (i) the function Fðx, !Þ is random lower semiconti-
nuous, (ii) for a.e. ! 2  the function Fð, !Þ is convex, (iii) the expectation
function f is proper, (iv) the domain of f has a nonempty interior. Then for any
x0 2 dom f ,
@f ðx0Þ ¼
Z

@Fðx0, !Þ dPð!Þ þ Ndom f ðx0Þ:
ð1:8Þ
Proof. Consider a point z 2
R
 @Fðx0, !Þ dPð!Þ. By the deﬁnition of that
integral we have then that there exists a P-ntegrable selection Gð!Þ 2 @Fðx0, !Þ
such that z ¼ R
 Gð!Þ dPð!Þ. Consequently, for a.e. ! 2  the following holds
Fðx, !Þ  Fðx0, !Þ  Gð!ÞTðx  x0Þ,
8 x 2 Rn:
By taking the integral of the both sides of the above inequality we obtain
that z is a subgradient of f at x0. This shows that
Z

@Fðx0, !Þ dPð!Þ  @f ðx0Þ:
ð1:9Þ
In particular, it follows from (1.9) that if @f ðx0Þ is empty, then the set at the
right hand side of (1.8) is also empty. If @f ðx0Þ is nonempty, i.e., f is
subdiﬀerentiable at x0, then Ndom f ðx0Þ forms the recession cone of @f ðx0Þ. In
any case it follows from (1.9) that
Z

@Fðx0, !Þ dPð!Þ þ Ndom f ðx0Þ  @f ðx0Þ:
ð1:10Þ
Ch. 2. Optimality and Duality in Stochastic Programming
71

Note that inclusion (1.10) holds irrespective of assumption (iv).
Proving the converse of inclusion (1.10) is a more delicate problem. Let us
outline main steps of such a proof based on the interchangeability property
of the directional derivative and integral operators. We can assume that both
sets at the left and right hand sides of (1.9) are nonempty. Since the
subdiﬀerentials @Fðx0, !Þ are convex, it is quite easy to show that the set
R
 @Fðx0, !Þ dPð!Þ is convex. With some additional eﬀort it is possible to show
that this set is closed. Let us denote by s1ðÞ and s2ðÞ the support functions of
the sets at the left and right hand sides of (1.10), respectively. By virtue of
inclusion (1.9), Ndom f ðx0Þ forms the recession cone of the set at the left hand
side of (1.10) as well. Since the tangent cone Tdom f ðx0Þ is the polar of
Ndom f ðx0Þ, it follows that s1ðhÞ ¼ s2ðhÞ ¼ þ1 for any h 62 Tdom f ðx0Þ. Suppose
now that (1.8) does not hold, i.e., inclusion (1.10) is strict. Then s1ðhÞ < s2ðhÞ
for some h 2 Tdom f ðx0Þ. Moreover, by assumption (iv), the tangent cone
Tdom f ðx0Þ has a nonempty interior and there exists h in the interior of
Tdom f ðx0Þ such that s1ðhÞ < s2ðhÞ. For such h the directional derivative f 0ðx0, hÞ
is ﬁnite for all h in a neighborhood of h, f 0ðx0, hÞ ¼ s2ðhÞ and (see Remark 5)
f 0ðx0, hÞ ¼
Z

F0
!ðx0, hÞ dPð!Þ:
Also, F0
!ðx0, hÞ is ﬁnite for a.e. ! and for all h in a neighborhood of
h, and hence F0
!ðx0, hÞ ¼ h
TGð!Þ for some Gð!Þ 2 @Fðx0, !Þ. Moreover, since
the multifunction !  @Fðx0, !Þ is measurable, we can choose a measurable
Gð!Þ here. Consequently,
Z

F0
!ðx0, hÞ dPð!Þ ¼ h
T Z

Gð!Þ dPð!Þ:
Since
R
 Gð!Þ dPð!Þ is a point of the set at the left hand side of (1.9), we
obtain that s1ðhÞ  f 0ðx0, hÞ ¼ s2ðhÞ, a contradiction.
u
2
Two-stage stochastic programming problems
2.1
Linear two-stage problems. Discrete distributions
In this section we discuss two-stage stochastic linear programs of the form
Minx cTx þ E½Qðx, Þ
s:t:
Ax ¼ b, x  0,
ð2:1Þ
72
A. Ruszczyn´ski and A. Shapiro

where Qðx, Þ is the optimal value of the second stage problem
Min
y
qTy
subject to
Tx þ Wy ¼ h, y  0:
ð2:2Þ
Here  ¼ ðq, h, T, WÞ is the data of the problem with some (all) elements of
which can be random. The above two-stage problem is the same as problem
(2.2)–(2.3) discussed in Section 2 of Chapter 1.
The second stage problem (2.2) is a particular case of the convex problem
(2.51) discussed in the following Section 2.4. Therefore, in principle, one can
apply results of Section 2.4 to problem (2.2). Note, however, that problem
(2.2) has a speciﬁc linear structure which allows us to give a more detailed
description of its properties. In particular, some regularity conditions can be
relaxed.
The second stage problem (2.2) is a linear programming problem. Its dual
can be written in the form
Max

Tðh  TxÞ
subject to
WT  q:
ð2:3Þ
By the theory of linear programming, the optimal values of problems (2.2)
and (2.3) are equal unless both problems are infeasible. Moreover, if their
common optimal value is ﬁnite, then each problem has a nonempty set of
optimal solutions.
Consider the function
sqðÞ :¼ inf qTy: Wy ¼ , y  0


:
ð2:4Þ
Clearly Qðx, Þ ¼ sqðh  TxÞ. By the duality theory of linear programming
we have that if the set
ðqÞ :¼ : WT  q


ð2:5Þ
is nonempty, then
sqðÞ ¼ sup
2ðqÞ
T,
ð2:6Þ
i.e., sqðÞ is the support function of the set ðqÞ. The set ðqÞ is convex closed
and polyhedral, and hence has a ﬁnite number of extreme points. It follows
that if ðqÞ is nonempty, then sqðÞ is a positively homogeneous polyhedral
function (see the following deﬁnition of polyhedral functions). If the set ðqÞ
is empty, then the inﬁmum at the right hand side of (2.4) may take only two
Ch. 2. Optimality and Duality in Stochastic Programming
73

values: þ1 or 1. In any case it is not diﬃcult to verify directly that the
function sqðÞ is convex.
Deﬁnition 10. An extended real valued function g: Rm ! R is called
polyhedral if its epigraph is a convex closed polyhedron, and gðxÞ is ﬁnite
for at least one x (which implies that the function g is proper). In other words,
gðÞ is polyhedral if it is proper convex and lower semicontinuous, its domain
is a convex closed polyhedron and gðÞ is piecewise linear on its domain.
Proposition 11. For any given , the function Qð, Þ is convex. Moreover, if the
set f: WT  qg is nonempty and problem (2.2) is feasible for at least one x,
then Qð, Þ is polyhedral.
Proof. Since Qðx, Þ ¼ sqðh  TxÞ, the above properties of Qð, Þ follow from
the corresponding properties of sqðÞ.
u
Proposition 12. Suppose that for a given x ¼ x0, the value Qðx0, Þ is ﬁnite.
Then Qð, Þ is subdiﬀerentiable at x0 and
@Qðx0, Þ ¼ TTDðx0, Þ,
ð2:7Þ
where Dðx, Þ :¼ arg max2ðqÞTðh  TxÞ is the set of optimal solutions of the
dual problem (2.3).
Proof. Since Qðx0, Þ is ﬁnite, the set ðqÞ (deﬁned in (2.5)) is nonempty, and
hence the function sqðÞ is the support function of the set ðqÞ. It is
straightforward to see from the deﬁnitions that the support function sqðÞ is the
conjugate function of the indicator function1
iqðÞ :¼
0,
if  2 ðqÞ;
þ1
otherwise:
	
Since the set (q) is closed and convex, the function iqðÞ is convex and lower
semicontinuous. It follows then by the Fenchel–Moreau Theorem that the
conjugate of sqðÞ is iqðÞ. Therefore, for 0 :¼ h  Tx0, we have (see (9.15))
@sqð0Þ ¼ arg max

T0  iqðÞ


¼ arg max
2ðqÞ
T0:
ð2:8Þ
Since the set ðqÞ is polyhedral and sqð0Þ is ﬁnite, it follows that @sqð0Þ is
nonempty. Moreover, the function s0ðÞ is piecewise linear, and hence formula
(2.7) follows from (2.8) by the chain rule of subdiﬀerentiation.
u
1 For a set A its indicator function iAðÞ takes zero value on A and þ1 otherwise.
74
A. Ruszczyn´ski and A. Shapiro

Problem (2.2) is a particular case of problems of form (9.26). Therefore
formula (2.7) is a particular case of the class of such formulas discussed in
Section 8.2 (and also in the following Section 1.4, like formula (2.56)). In the
present case there is no need for an additional regularity condition (constraint
qualiﬁcation) because the function Qð, Þ is polyhedral.
It follows from the above that if the function Qð, Þ has a ﬁnite value in at
least one point, then it is subdiﬀerentiable at that point, and hence it is proper.
Its domain can be described in a more explicit way.
The positive hull of a matrix W is deﬁned as
pos W :¼ :  ¼ Wy, y  0


:
ð2:9Þ
It is a convex polyhedral cone generated by the columns of W. Directly
from the deﬁnition (2.4) we see that dom sq ¼ pos W: Therefore,
dom Qð, Þ ¼ fx: h  Tx 2 pos Wg:
ð2:10Þ
Suppose that x is such that  ¼ h  Tx 2 pos W and let us analyze formula
(2.7). The recession cone of ðqÞ is equal to
0 :¼ ð0Þ ¼ : WT  0


:
ð2:11Þ
Then it follows from (2.6) that sqðÞ is ﬁnite iﬀT  0 for every  2 0,
that is, iﬀ is an element of the polar cone to 0. This polar cone is nothing
else but pos W.
If 0 2 intðpos WÞ, then the set of maximizers in (2.6) must be bounded.
Indeed, if it was unbounded, there would exist an element 0 2 0 such that
T
0  ¼ 0. By perturbing 0 a little to some , we would be able to keep 
within pos W and get T
0  > 0, which is a contradiction, because pos W is the
polar of 0. Therefore, the set of maximizers in (2.6) is the convex hull of the
vertices v of ðqÞ for which vT ¼ sqðÞ. Note that ðqÞ must have vertices in
this case, because otherwise the polar to 0 would have no interior.
If 0 is a boundary point of pos W, then the set of maximizers in (2.6) is
unbounded. Its recession cone is the intersection of the recession cone 0 of
ðqÞ and the set f: T0 ¼ 0g. This intersection is nonempty for boundary
points 0 and is equal to the normal cone to pos W at 0. Indeed, let 0
be normal to pos W at 0. Since both 0 and 0 are feasible directions
at 0, we must have T
0 0 ¼ 0. Next, for every  2 pos W
we have
T
0  ¼ T
0 ð  0Þ  0, so 0 2 0. The converse argument is similar.
Let us consider now the expected value function
ðxÞ :¼ E½Qðx, Þ:
ð2:12Þ
Ch. 2. Optimality and Duality in Stochastic Programming
75

The expectation here is taken with respect to random components of
the data . Suppose that the distribution of  has a ﬁnite support, i.e.,  has a
ﬁnite number of realizations (scenarios) k ¼ ðqk, hk, Tk, WkÞ with respective
(positive) probabilities pk, k ¼ 1, . . . , K. Then
E½Qðx, Þ ¼
X
K
k¼1
pkQðx, kÞ:
ð2:13Þ
For a given x, the expectation E½Qðx, Þ is equal to the optimal value of the
linear program
Min
y1,..., yk
X
K
k¼1
pkqT
k yk
s:t:
Tkx þ Wkyk ¼ hk,
yk  0,
k ¼ 1, . . . , K:
ð2:14Þ
Now if for at least one k 2 f1, . . . , Kg the system Tkx þ Wkyk ¼ hk, yk  0,
has no solution, i.e., the corresponding second stage problem is infeasible,
then the above problem (2.14) is infeasible, and hence its optimal value is þ1.
From that point of view the sum in the right hand side of (2.13) equals þ1 if at
least one of Qðx, kÞ ¼ þ1. That is, we assume here that þ1 þ ð1Þ ¼ þ1.
Proposition 13. Suppose that the distribution of  has a ﬁnite support and that
the expectation function ðÞ :¼ E½Qð, Þ has a ﬁnite value in at least one point
x 2 Rn. Then the function ðÞ is polyhedral, and for any x0 2 dom ,
@ðx0Þ ¼
X
K
k¼1
pk@Qðx0, kÞ:
ð2:15Þ
Proof. Since ðxÞ is ﬁnite, it follows that all values Qðx, kÞ, k ¼ 1, . . . , K, are
ﬁnite. Consequently, by Proposition 12, every function Qð, kÞ is polyhedral.
It is not diﬃcult to see that a positive linear combination of polyhedral
functions is also polyhedral. Therefore, it follows that ðÞ is polyhedral. We
also have that dom  ¼ \K
k¼1 dom Qk, where QkðÞ :¼ Qð, kÞ, and for any
h 2 Rn, the directional derivatives Q0
kðx0, hÞ > 1 and
0ðx0, hÞ ¼
X
K
k¼1
pkQ0
kðx0, hÞ:
ð2:16Þ
76
A. Ruszczyn´ski and A. Shapiro

Formula (2.15) then follows from (2.16) by duality arguments. Note that
equation (2.15) is a particular case of the Moreau–Rockafellar Theorem
(Theorem 50). Since the functions Qk are polyhedral, there is no need here for
an additional regularity condition for (2.15) to hold.
u
The subdiﬀerential @Qðx0, kÞ of the second stage optimal value function is
described in Proposition 12. That is, if Qðx0, kÞ is ﬁnite, then
@Qðx0, kÞ ¼ TT
k arg max Tðhk  Tkx0Þ: WT
k   qk


:
ð2:17Þ
It follows that the expectation function  is diﬀerentiable at x0 iﬀfor every
 ¼ k, k ¼ 1, . . . , K, the maximum in the right hand side of (2.17) is attained
at a unique point, i.e., the corresponding second stage dual problem has a
unique optimal solution.
Example 14 (Capacity Expansion). Let us consider a simpliﬁed, single-
commodity version of the capacity expansion example discussed in Chapter 1
(Example 4). We have a directed graph with node set N and arc set A. With
each arc a 2 A we associate a decision variable xa and call it the capacity of a.
There is a cost ca for each unit of capacity of arc a. The vector x constitutes
the vector of ﬁrst stage variables. They are restricted to satisfy the inequalities
x  xmin, where xmin are the existing capacities.
At each node n of the graph we have a random demand n for shipments to
n (if n is negative, its absolute value represents shipments from n and we have
P
n2N n ¼ 0). These shipments have to be sent through the network and they
can be arbitrarily split into pieces taking diﬀerent paths. We denote by ya the
amount of the shipment sent through arc a. There is a unit cost qa for
shipments on each arc a.
Our objective is to assign the arc capacities and to organize the shipments in
such a way that the expected total cost, comprising the capacity cost and the
shipping cost, is minimized. The condition is that the capacities have to be
assigned before the actual demands n become known, while the shipments can
be arranged after that.
Let us deﬁne the second stage problem. For each node n denote by AþðnÞ
and AðnÞ the sets of arcs entering and leaving node i. The second stage
problem is the network ﬂow problem
Min
X
a2A
qaya
ð2:18Þ
s:t:
X
a2AþðnÞ
ya 
X
a2AðnÞ
ya ¼ n,
n 2 N ,
ð2:19Þ
Ch. 2. Optimality and Duality in Stochastic Programming
77

0  ya  xa,
a 2 A:
ð2:20Þ
This problem depends on the random demand vector  and on the arc
capacities, x. Its optimal value will be denoted Qðx, Þ.
Suppose that for a given x ¼ x0 the second stage problem (2.18)–(2.20) is
feasible. Let n, n 2 N , be the optimal Lagrange multipliers (node potentials)
associated with the node balance equations (2.19). With no loss of generality
we can assume that n0 ¼ 0 for some ﬁxed node n0. Let us denote by ðx0, Þ
the set of optimal multiplier vectors (satisfying the additional condition
n0 ¼ 0) for a given demand vector .
For each arc a ¼ ði, j Þ the multiplier ij associated with the constraint (2.20)
has the form
ij ¼ maxf0, i  j  qijg:
Roughly, if the diﬀerence of node potentials i  j is greater than qij, the
arc is saturated and the capacity constraint yij  xij is relevant. Since T ¼ I
in this case, formula (2.17) provides the description of the subdiﬀerential of
Qð, DÞ at x0:
@Qðx0, Þ ¼
maxf0, i  j  qijg


ði, jÞ2A:  2 ðx0, Þ
n
o
:
The ﬁrst stage problem has the form
Min
xxmin
X
a2A
caxa þ E½Qðx, Þ:
If  has ﬁnitely many realizations k attained with probabilities pk,
k ¼ 1, . . . , K, the subdiﬀerential of the overall objective can be calculated
by (2.15):
@f ðxÞ ¼ c þ
X
K
k¼1
pk@Qðx0, kÞ:
2.2
Linear two-stage problems, general distributions
Let us discuss now the case of a general distribution of the random vector
 2 Rd. We have here that Qð, Þ is the minimum value of the integrand which
is a random lower semicontinuous function. Therefore, it follows by Theorem
19 from the Appendix of Chapter 1 that Qð, Þ is measurable with respect to
the Borel sigma algebra of Rn  Rd. Also for every  the function Qð, Þ
is lower semicontinuous. It follows that Qðx, Þ is a random lower
78
A. Ruszczyn´ski and A. Shapiro

semicontinuous function. Recall that in order to ensure that the expectation
 (x) is well deﬁned we have to verify two types of conditions, namely that:
(i) Qðx, Þ is measurable (with respect to the Borel sigma algebra of Rd),
(ii) either E½Qðx, Þþ or E½ðQðx, ÞÞþ is ﬁnite. Since Qðx, Þ is measurable, we
only have to verify condition (ii). We describe below some important parti-
cular situations where this condition holds.
Two-stage linear program (2.1)–(2.2) is said to have ﬁxed recourse if the
matrix W is ﬁxed (not random). Moreover, we say that the recourse is
complete if the system Wy ¼  and y  0 has a solution for any , or in other
words the positive hull of W is equal to the corresponding vector space. By
duality arguments the ﬁxed recourse is complete iﬀthe feasible set ðqÞ of the
dual problem (2.3) is bounded (in particular it may be empty) for every q.
Then its recession cone, 0 ¼ ð0Þ, must contain only the point f0g, provided
that ðqÞ is nonempty. Therefore, another equivalent condition for complete
recourse is that  ¼ 0 is the only solution of the system WT  0.
It is said that the recourse is relatively complete if for every x in the set
fx: Ax ¼ b, x  0g, the feasible set of the second stage problem (2.2) is
nonempty for a.e. ! 2 . That is, the recourse is relatively complete if for
every feasible ﬁrst stage point x the inequality Qðx, ð!ÞÞ < þ1 holds w.p.1.
This deﬁnition is in accordance with the general principle that an event which
happens with zero probability is irrelevant for the calculation of the
corresponding expected value.
Let  be the support of the random vector  2 Rd, i.e.,  is the small-
est closed subset of Rd such that the probability of the event f 62 g is zero.
A suﬃcient condition for relatively complete recourse is the following.

For every x  0 such that Ax ¼ b, the inequality Qðx, Þ < þ1 holds for
all  2 .
Unfortunately, in general, this condition is not necessary. This condition is
necessary and suﬃcient in the following two cases: (i) the random vector (!)
has a ﬁnite support, (ii) the recourse is ﬁxed. Indeed, suﬃciency is clear. If (!)
has a ﬁnite support, i.e., the set  is ﬁnite, then the necessity is also clear.
In order to show the necessity in the case of ﬁxed recourse, we argue as
follows. Suppose that the recourse is relatively complete. This means that if x
is a feasible point of the ﬁrst stage problem, then Qðx, Þ < þ1 for all  in 
accept possibly for a subset of  of measure zero. We have that Qðx, Þ < þ1
iﬀh  Tx 2 pos W. Note that this condition does not depend on q and that
W is ﬁxed here. Therefore, the condition h  Tx 2 pos W should hold for
almost every (h,T). This implies that the set fðh, TÞ: h  Tx 2 pos Wg
should form a dense subset of the support of the probability distribution of
ðhð!Þ, Tð!ÞÞ. Now if (hn,Tn) is a sequence converging to a point (h,T) and
hn  Tnx 2 pos W, then hn  Tnx ! h  Tx and hence h  Tx 2 pos W since
the set pos W is closed. This completes the argument. Let us also note that, of
course, if a two-stage linear program with ﬁxed recourse is complete, then it is
relatively complete.
Ch. 2. Optimality and Duality in Stochastic Programming
79

Example 15. Consider
Qðx, Þ :¼ inffy: y ¼ x, y  0g,
with x 2 ½0, 1 and  being a random variable whose probability density
function is pðzÞ :¼ 2z, 0  z  1. We have that for any >0 and x 2 ½0, 1,
Qðx, Þ ¼ x=, and hence
E½Qðx, Þ ¼
Z 1
0
x
z

 
2z dz ¼ 2x:
That is, the recourse here is relatively complete and the expectation of
Qðx, Þ is ﬁnite. On the other hand, the support of (!) is the interval ½0, 1, and
for  ¼ 0 and x>0 the value of Qðx, Þ is þ1 since the corresponding problem
is infeasible. Of course, probability of the event ‘‘ ¼ 0’’ is zero, and from the
mathematical point of view the expected value function E½Qðx, Þ is well
deﬁned and ﬁnite for all x 2 ½0, 1. Note, however, that arbitrary small
perturbation of the probability distribution of  may change that. Take, for
example, a discretization of the distribution of  with the ﬁrst discretization
point t ¼ 0. Then, does not matter how small is the assigned (positive)
probability at t ¼ 0, we obtain that Qðx, Þ ¼ þ1 with positive probability,
and hence, E½Qðx, Þ ¼ þ1, for any x>0. That is, from a numerical point of
view the above problem is extremely unstable and is not well posed. As it was
discussed above, such behavior cannot happen if the recourse is ﬁxed.
Let us consider the support function sqðÞ of the set ðqÞ. We want to ﬁnd
suﬃcient conditions for the existence of the expectation E½sqðh  TxÞ. By
Hoﬀman’s lemma (Theorem 53) there exists a constant , depending on W,
such that if for some q0 the set ðq0Þ is nonempty, then for any q the following
inclusion holds
ðqÞ  ðq0Þ þ kq  q0kB,
ð2:21Þ
where B :¼ : kk  1
f
g and k  k denotes the Euclidean norm. Consider the
support function sqðÞ of the set ðqÞ. Since the support function of the unit
ball B is k  k, it follows from (2.21) that if the set ðq0Þ is nonempty, then
sqðÞ  sq0ðÞ þ kq  q0k k  k:
ð2:22Þ
In particular, for the support function s0ðÞ of the cone 0 we have that
s0ðÞ ¼ 0 if  2 pos W and s0ðÞ ¼ þ1 otherwise. Therefore, by taking q0 ¼ 0
in (2.22) we obtain that if ðqÞ is nonempty, then sqðÞ  kqk kk for
 2 pos W, and sqðÞ ¼ þ1 for  62 pos W. Since ðqÞ is polyhedral, if ðqÞ is
80
A. Ruszczyn´ski and A. Shapiro

nonempty then sqðÞ is piecewise linear on its domain, which coincides with
pos W, and
jsqð1Þ  sqð2Þj  kqk k1  2k,
8 1, 2 2 pos W:
ð2:23Þ
We say that a random variable Z(!) has a ﬁnite r-th moment if
EjZð!Þjr < þ1. It is said that (!) has ﬁnite r-th moments if each component
of (!) has a ﬁnite r-th moment.
Proposition 16. Suppose that the recourse is ﬁxed and
E kqk khk
½
 < þ1
and
E kqk kTk
½
 < þ1:
ð2:24Þ
Consider a point x 2 Rn. Then E½Qðx, Þþ is ﬁnite if and only if the following
condition holds w.p.1:
h  Tx 2 pos W:
ð2:25Þ
Proof. We have that Qðx, Þ < þ1 iﬀcondition (2.25) holds. Therefore, if
condition (2.25) does not hold w.p.1, then Qðx, Þ ¼ þ1 with positive
probability, and hence E½Qðx, Þþ ¼ þ1.
Conversely, suppose that condition (2.25) holds w.p.1. Then Qðx, Þ ¼
sqðh  TxÞ with sqðÞ being the support function of the set ðqÞ. By (2.22) there
exists a constant  such that for any ,
sqðÞ  s0ðÞ þ kqk kk:
ð2:26Þ
Also for any  2 pos W we have that s0ðÞ ¼ 0, and hence w.p.1,
sqðh  TxÞ  kqk kh  Txk  kqkðkhk þ kTk kxkÞ:
ð2:27Þ
It follows then by (2.24) that E sqðh  TxÞþ


< þ1.
u
Remark 17. If q and (h,T ) are independent and have ﬁnite ﬁrst moments, then
Ekqk khk ¼ E kqk
½
 E khk
½

and
E kqk kTk
½
 ¼ E kqk
½
 E kTk
½
,
and hence condition (2.24) follows. Also condition (2.24) holds if (h, T, q) has
ﬁnite second moments.
We obtain that, under the assumptions of Proposition 16, the expectation
 (x) is well deﬁned and ðxÞ < þ1 iﬀcondition (2.25) holds w.p.1. If,
moreover, the recourse is complete, then (2.25) holds for any x and , and
Ch. 2. Optimality and Duality in Stochastic Programming
81

hence ðÞ is well deﬁned and is less than þ1. Since the function ðÞ is
convex, we have that if ðÞ is less than þ1 on Rn and is ﬁnite valued in at
least one point, then ðÞ is ﬁnite valued on the entire space Rn.
Proposition 18. Suppose that: (i) the recourse is ﬁxed, (ii) for a.e. q the set ðqÞ
is nonempty, (iii) condition (2.24) holds. Then the expectation function  (x) is
well deﬁned and ðxÞ > 1 for all x 2 Rn. Moreover,  is convex, lower
semicontinuous and Lipschitz continuous on dom , its domain dom  is a
convex closed subset of Rn and
dom  ¼ x 2 Rn : h  Tx 2 pos W w:p:1


:
ð2:28Þ
Proof. Since by assumption (ii) the feasible set ðqÞ of the dual problem is
nonempty w.p.1, we have that Qðx, Þ is equal to sqðh  TxÞ w.p.1 for any x,
where sqðÞ is the support function of the set ðqÞ. Let ðqÞ be the element of
the set ðqÞ that is closest to 0. Since ðqÞ is closed, such an element exists. By
Hoﬀman’s lemma (see (2.21)) there is a constant  such that kðqÞk  kqk.
Then for any x the following holds w.p.1:
sqðh  TxÞ  ðqÞTðh  TxÞ  kqk khk þ kTk kxk
ð
Þ:
ð2:29Þ
By condition (2.24) it follows from (2.29) that ðÞ is well deﬁned and
ðxÞ > 1 for all x 2 Rn. Moreover, since sqðÞ is lower semicontinuous, the
lower semicontinuity of ðÞ follows by Fatou’s lemma. The convexity and the
closedness of dom  follow from the convexity and the lower semicontinuity
of  . We have by Proposition 16 that ðxÞ < þ1 iﬀcondition (2.25) holds
w.p.1. This implies (2.28).
Consider two points x, x0 2 dom . Then by (2.28) the following holds
w.p.1:
h  Tx 2 pos W
and
h  Tx0 2 pos W:
ð2:30Þ
By (2.23) we have that if the set ðqÞ is nonempty and (2.30) holds, then
jsqðh  TxÞ  sqðh  Tx0Þj  kqk kTk kx  x0k:
ð2:31Þ
It follows that
jðxÞ  ðx0Þj   E kqk kTk
½
 kx  x0k:
Together with condition (2.24) this implies the Lipschitz continuity of  on
its domain.
82
A. Ruszczyn´ski and A. Shapiro

Denote by  the support2 of the probability distribution (measure) of ðh, TÞ.
Formula (2.28) means that a point x belongs to dom  iﬀthe probability of the
event fh  Tx 2 pos Wg is one. Note that the set fðh, TÞ: h  Tx 2 pos Wg is
convex and polyhedral, and hence is closed. Consequently x belongs to dom 
iﬀfor every ðh, TÞ 2  it follows that h  Tx 2 pos W. Therefore, we can write
formula (2.28) in the form
dom  ¼
\
ðh, TÞ2
x: h  Tx 2 pos W


:
ð2:32Þ
It should be noted that the above holds since we assume here that the
recourse is ﬁxed.
Let us observe that for any set H of vectors h, the set \h2Hðh þ pos WÞ is
convex and polyhedral. Indeed, we have that pos W is a convex polyhedral
cone, and hence can be represented as the intersection of a ﬁnite number of
half spaces Ai ¼ f: aT
i   0g, i ¼ 1, . . . , l. Since the intersection of any
number of half spaces of the form b þ Ai, with b 2 B, is still a half space of the
same form (provided that this intersection is nonempty), we have the set
\h2Hðh þ pos WÞ can be represented as the intersection of half spaces of the
form bi þ Ai, i ¼ 1, . . . , l, and hence is polyhedral. It follows that if T and W
are ﬁxed, then the set at the right hand side of (2.32) is convex and polyhedral.
Let us discuss now the diﬀerentiability properties of the expectation
function ðxÞ. By Theorem 9 and formula (2.7) of Proposition 12 we have the
following result.
Proposition 19. Suppose that the expectation function ðÞ is proper and its
domain has a nonempty interior. Then for any x0 2 dom ,
@ðx0Þ ¼ TTE Dðx0, Þ
½
 þ Ndom ðx0Þ,
ð2:33Þ
where Dðx, Þ :¼ arg max2ðqÞTðh  TxÞ. Moreover,  is diﬀerentiable at x0
if and only if x0 belongs to the interior of dom  and the set Dðx0, Þ is a
singleton w.p.1.
As we discussed earlier, when the distribution of  has a ﬁnite support (i.e.,
there is a ﬁnite number of scenarios) the expectation function  is piecewise
linear on its domain and is diﬀerentiable everywhere only in the trivial case if
it is linear.3 In the case of a continuous distribution of  the expectation
operator smoothes the piecewise linear function Qð, Þ out. For example, the
following result holds.
2 Recall that the support of a probability distribution (measure) is the smallest closed set such that the
probability (measure) of its complement is zero.
3 By linear we mean here that it is of the form aTx þ b. It is more accurate to call such a function
aﬃne.
Ch. 2. Optimality and Duality in Stochastic Programming
83

Proposition 20. Suppose that the assumptions of Proposition 18 hold, and the
conditional distribution of h, given ðT, qÞ, is absolutely continuous for almost all
ðT, qÞ. Then  is continuously diﬀerentiable on the interior of its domain.
Proof. By Proposition 18 we have here that the expectation function ðÞ is
well deﬁned and is greater than 1. Let x be a point in the interior of dom .
For ﬁxed T and q, consider the multifunction
ZðhÞ :¼ arg max
2ðqÞ
Tðh  TxÞ:
Clearly, conditional on ðT, qÞ, the set Dðx, Þ coincides with ZðhÞ. Since
x 2 dom , we have by (2.28) that h  Tx 2 pos W w.p.1. Also we have that if
h  Tx 2 pos W, then ZðhÞ is nonempty and forms a face of the polyhedral set
ðqÞ. Moreover, there is a set A given by the union of a ﬁnite number of linear
subspaces of Rm (where m is the dimension of h) perpendicular to the faces of
sets ðqÞ, such that if h  Tx 2 ðpos WÞnA, then ZðhÞ is a singleton. Since an
aﬃne subspace of Rm has Lebesgue measure zero, it follows that the Lebesgue
measure of A is zero. Therefore, since the conditional distribution of h given
ðT, qÞ is absolutely continuous, the probability of the event that ZðhÞ is not a
singleton is zero. By integrating this probability over the distribution of ðT, qÞ,
we obtain that the probability of the event that Dðx, Þ is not a singleton is
zero. By Proposition 19 this implies the diﬀerentiability of ðÞ. Since ðÞ is
convex, it follows that for any x 2 intðdom Þ the gradient rðxÞ coincides
with the (unique) subgradient of  at x, and that rðxÞ is continuous at x.
u
Of course, if h and ðT, qÞ are independent, then the conditional distribution
of h given ðT, qÞ is the same as the unconditional (marginal) distribution of h.
Therefore, if h and ðT, qÞ are independent, then it suﬃces to assume in
the above proposition that the (marginal) distribution of h is absolutely
continuous.
2.3
Polyhedral two-stage problems
Let us consider a slightly more general formulation of a two-stage
stochastic programming problem:
Min
x
f1ðxÞ þ E½Qðx, !Þ,
ð2:34Þ
where Qðx, !Þ is the optimal value of the second stage problem
Min
y
f2ðy, !Þ
subject to
Tð!Þx þ Wð!Þy ¼ hð!Þ:
ð2:35Þ
84
A. Ruszczyn´ski and A. Shapiro

We assume in this section that the above two-stage problem is polyhedral.
That is, the following holds.

The function f1ðÞ is polyhedral (see Deﬁnition 10). This means that there
exist vectors cj and scalars j, j ¼ 1, . . . , J1, vectors ak and scalars bk,
k ¼ 1, . . . , K1, such that f1(x) can be represented as follows:
f1ðxÞ ¼
max1 j J1 j þ cT
j x,
if aT
k x  bk,
k ¼ 1, . . . , K1,
þ1;
otherwise,
	
ð2:36Þ
and its domain dom f1 ¼ x: aT
k x  bk, k ¼ 1, . . . , K1


is nonempty.

The function f2 is random polyhedral. That is, there exist random vectors
qj ¼ qjð!Þ and random scalars j ¼ jð!Þ, j ¼ 1, . . . , J2, random vectors
dk ¼ dkð!Þ and random scalars rk ¼ rkð!Þ, k ¼ 1, . . . , K2, such that
f2ð y, !Þ can be represented as follows:
f2ðy, !Þ¼ max1jJ2 jð!Þ þ qjð!ÞTy, if dkð!ÞTyrkð!Þ, k¼1, . . . , K2,
þ1;
otherwise,
	
ð2:37Þ
and for a.e. ! the domain of f2ð, !Þ is nonempty.
Clearly, the linear two-stage model (2.1)–(2.2) is a special case of a
polyhedral two-stage problem. The converse is also true, i.e., every polyhedral
two-stage model can be reformulated as a linear two-stage model. For
example, the second stage problem (2.35) can be written as follows:
Min
y, v
v
s:t:
Tð!Þx þ Wð!Þy ¼ hð!Þ,
jð!Þ þ qjð!ÞTy  v,
j ¼ 1, . . . , J2,
dkð!ÞTy  rkð!Þ,
k ¼ 1, . . . , K2:
Here both v and y play the role of the second stage variables, and the data
ðq, T, W, hÞ in (2.2) have to be re-deﬁned in an appropriate way. In order to
avoid all these manipulations and the unnecessary notational complications
that come together with such a conversion, we shall address polyhedral
problems in a more abstract way. This will also help us to deal with the
general convex case.
Consider the Lagrangian
Lð y, ; x, !Þ :¼ f2ð y, !Þ þ Tðhð!Þ  Tð!Þx  Wð!ÞyÞ
Ch. 2. Optimality and Duality in Stochastic Programming
85

of the second stage problem (2.35). We have
inf
y
Lðy, ; x, !Þ ¼ Tðhð!Þ  Tð!ÞxÞ þ inf
y
f2ðy, !Þ  TWð!Þy


¼ Tðhð!Þ  Tð!ÞxÞ  f *
2 ðWð!ÞT, !Þ,
where f *
2 ð, !Þ is the conjugate4 of f2ð, !Þ. We obtain that the dual of problem
(2.35) can be written as follows
Max

Tðhð!Þ  Tð!ÞxÞ  f *
2 ðWð!ÞT, !Þ


:
ð2:38Þ
By the duality theory of linear programming we have that if, for some
ðx, !Þ, the optimal value Qðx, !Þ of problem (2.35) is less than þ1 (i.e.,
problem (2.35) is feasible), then it is equal to the optimal value of the dual
problem (2.38).
Let us denote, as before, by Dðx, !Þ the set of optimal solutions of the dual
problem (2.38). We then have an analogue of Proposition 12.
Proposition 21. Let ! 2  be given and suppose that Qð, !Þ is ﬁnite in at least
one point x. Then the function Qð, !Þ is convex polyhedral. Moreover, Qð, !Þ is
subdiﬀerentiable at every x ¼ x0, at which the value Qðx0, !Þ is ﬁnite, and
@Qðx0, !Þ ¼ Tð!ÞTDðx0, !Þ:
ð2:39Þ
Proof. Let us deﬁne the function  ðÞ :¼ f *
2 ðWTÞ (for simplicity we suppress
the argument !). We have that if Qðx, !Þ is ﬁnite, then it is equal to the
optimal value of problem (2.38), and hence Qðx, !Þ ¼  *ðh  TxÞ: Therefore,
Qð, !Þ is a polyhedral function. Moreover, it follows by the Fenchel–Moreau
Theorem that
@ *ðh  Tx0Þ ¼ Dðx0, !Þ,
and the chain rule for subdiﬀerentiation yields formula (2.39). Note that we do
not need here additional regularity conditions because of the polyhedricity of
the considered case.
u
If Qðx, !Þ is ﬁnite, then the set Dðx, !Þ of optimal solutions of problem
(2.38) is a nonempty convex closed polyhedron. If, moreover, Dðx, !Þ is
bounded, then it is the convex hull of its ﬁnitely many vertices (extreme
points), and Qð, !Þ is ﬁnite in a neighborhood of x. If Dðx, !Þ is unbounded,
4 Note that since f2ð, !Þ is polyhedral, so is f *
2 ð, !Þ.
86
A. Ruszczyn´ski and A. Shapiro

then its recession cone (which is polyhedral) is the normal cone to the domain
of Qð, !Þ at the point x.
Let us consider now the expected value function ðxÞ :¼ E½Qðx, !Þ.
Suppose that the probability measure P has a ﬁnite support, i.e., there exists a
ﬁnite number of scenarios !k with respective (positive) probabilities pk,
k ¼ 1, . . . , K. Then
E½Qðx, !Þ ¼
X
K
k¼1
pkQðx, !kÞ:
ð2:40Þ
For a given x, the expectation E½Qðx, !Þ is equal to the optimal value of the
program
Min
y1,..., yk
X
K
k¼1
pk f2ð yk, !kÞ
s:t:
Tkx þ Wkyk ¼ hk,
k ¼ 1, . . . , K,
ð2:41Þ
where ðhk, Tk, WkÞ :¼ ðhð!kÞ, Tð!kÞ, Wð!kÞÞ. Similarly to the linear case, if for
at least one k 2 f1, . . . , Kg the set
dom f2ð, !kÞ \ y: Tkx þ Wky ¼ hk


is empty, i.e., the corresponding second stage problem is infeasible, then
problem (2.41) is infeasible, and hence its optimal value is þ1.
Proposition 22. Suppose that the probability measure P has a ﬁnite support and
that the expectation function ðÞ :¼ E½Qð, !Þ has a ﬁnite value in at least one
point x 2 Rn. Then the function ðÞ is polyhedral, and for any x0 2 dom ,
@ðx0Þ ¼
X
K
k¼1
pk@Qðx0, !kÞ:
ð2:42Þ
The proof is identical to the proof of Proposition 13. Since the functions
Qð, !kÞ are polyhedral, formula (2.42) follows by the Moreau–Rockafellar
Theorem.
The subdiﬀerential @Qðx0, !kÞ of the second stage optimal value function is
described in Proposition 21. That is, if Qðx0, !kÞ is ﬁnite, then
@Qðx0, !kÞ ¼ TT
k arg max Tðhk  Tkx0Þ  f *
2 ðWT
k , !kÞ


:
ð2:43Þ
Ch. 2. Optimality and Duality in Stochastic Programming
87

It follows that the expectation function  is diﬀerentiable at x0 iﬀfor every
!k, k ¼ 1, . . . , K, the maximum at the right hand side of (2.43) is attained at a
unique point, i.e., the corresponding second stage dual problem has a unique
optimal solution.
Let us now consider the case of a general probability distribution P. We
need to ensure that the expectation function ðxÞ :¼ E½Qðx, !Þ is well deﬁned.
General conditions are messy, so we resort again to the case of ﬁxed recourse.
We say that the two-stage polyhedral problem has ﬁxed recourse if the
matrix W and the set5 Y :¼ dom f2ð, !Þ are ﬁxed, i.e., do not depend on !. In
that case,
f2ð y, !Þ ¼
max1 j J2 jð!Þ þ qjð!ÞTy,
if y 2 Y,
þ1;
otherwise:
	
Denote WðYÞ :¼ fWy: y 2 Yg. Let x be such that
hð!Þ  Tð!Þx 2 WðYÞ w:p:1:
ð2:44Þ
This means that for a.e. ! the system
y 2 Y, y ¼ hð!Þ  Tð!Þx
ð2:45Þ
has a solution. Let for some !0 2 , y0 be a solution of the above system, i.e.,
y0 2 Y and hð!0Þ  Tð!0Þx ¼ Wy0. Since system (2.45) is deﬁned by linear
constraints, we have by Hoﬀman’s lemma that there exists a constant  such
that for almost all ! we can ﬁnd a solution yð!Þ of the system (2.45) with
kyð!Þ  y0k  kðhð!Þ  Tð!ÞxÞ  ðhð!0Þ  Tð!0ÞxÞk:
Therefore the optimal value of the second stage problem can be bounded
from above as follows:
Qðx, !Þ  max
1 j J2 jð!Þ þ qjð!ÞTyð!Þ


 Qðx, !0Þ þ
X
J2
j¼1
jjð!Þ  jð!0Þj
þ 
X
J2
j¼1
kqjð!Þk khð!Þhð!0Þk þ kxkkTð!ÞTð!0Þk
ð
Þ: ð2:46Þ
5 Note that since it is assumed that f2ð, !Þ is polyhedral, it follows that the set Y is nonempty and
polyhedral.
88
A. Ruszczyn´ski and A. Shapiro

Proposition 23. Suppose that the recourse is ﬁxed and
Ejjj<þ1, E kqjk khk


<þ1
and
E kqjk kTk


<þ1,
j ¼ 1, . . . , J2:
ð2:47Þ
Consider a point x 2 Rn. Then E½Qðx, !Þþ is ﬁnite if and only if condition
(2.44) holds.
The proof uses (2.46), similarly to the proof of Proposition 16.
Let us now formulate conditions under which the expected recourse cost is
bounded from below. Let C be the recession cone of Y, and C* be its polar.
Consider the conjugate function f *
2 ð, !Þ. It can be veriﬁed that
dom f *
2 ð, !Þ ¼ convfqjð!Þ, j ¼ 1, . . . , J2g þ C*:
ð2:48Þ
Indeed, by the deﬁnition of the function f2ð, !Þ and its conjugate, we have
that f *
2 ðz, !Þ is equal to the optimal value of the problem
Maxy, v v
s:t:
zTy  jð!Þ  qjð!ÞTy  v,
j ¼ 1, . . . , J2, y 2 Y:
Since it is assumed that the set Y is nonempty, the above problem is
feasible, and since Y is polyhedral, it is linear. Therefore its optimal value is
equal to the optimal value of its dual. In particular, its optimal value is less
than þ1 iﬀthe dual problem is feasible. Now the dual problem is feasible iﬀ
there exist j  0, j ¼ 1, . . . , J2, such that PJ2
j¼1 j ¼ 1 and
supy2Y yT z  PJ2
j¼1 jqjð!Þ


< þ1:
The last condition holds iﬀz  PJ2
j¼1 jqjð!Þ 2 C*, which completes the
argument.
Let us deﬁne the set
ð!Þ :¼ f: WT 2 conv qjð!Þ, j ¼ 1, . . . , J2


þ C*g:
We may remark that in the case of a linear two stage program the above set
coincides with the one deﬁned in (2.5).
Proposition 24. Suppose that: (i) the recourse is ﬁxed, (ii) the set ð!Þ is
nonempty w.p.1, (iii) condition (2.47) holds. Then the expectation function ðxÞ
is well deﬁned and ðxÞ > 1 for all x 2 Rn. Moreover,  is convex, lower
Ch. 2. Optimality and Duality in Stochastic Programming
89

semicontinuous and Lipschitz continuous on dom , its domain dom  is a
convex closed subset of Rn and
dom  ¼ x 2 Rn : h  Tx 2 WðYÞ w:p:1


:
ð2:49Þ
Note that the dual problem (2.38) is feasible iﬀWT 2 dom f *
2 ð, !Þ. By
formula (2.48) assumption (ii) means that problem (2.38) is feasible, and hence
Qðx, !Þ is equal to the optimal value of (2.38), for a.e. !. The remainder of the
proof is similar to the linear case (Proposition 18).
2.4
Convex two-stage problems
Let us consider the following two-stage problem
Min
x2X f f ðxÞ :¼ E½Fðx, !Þg,
ð2:50Þ
where Fðx, !Þ is the optimal value of the second stage problem
Min
y2Y qð y, !Þ subject to gið y, !Þ þ i  0,
i ¼ 1, . . . , m,
ð2:51Þ
and i ¼ tiðx, !Þ. Here X is a subset of Rn, Y is a subset of Rs, and qð y, !Þ,
giðy, !Þ and tiðx, !Þ are real valued functions. The above problem is a
particular case of the two-stage problem (2.19)–(2.20) discussed in Chapter 1.
We assume throughout this section that for a.e. ! 2  the problem (2.51) is
convex, that is, the set Y is convex, and the functions qð, !Þ and gið, !Þ,
tið, !Þ, i ¼ 1, . . . , m, are convex. Recall that real valued convex functions are
continuous, in fact they are even locally Lipschitz continuous.
The second stage constraints can be absorbed into the objective function by
deﬁning qðy, , !Þ :¼ qðy, !Þ if ðy, Þ satisﬁes the constraints of (2.51), and
qðy, , !Þ :¼ þ1 otherwise. Consequently, problem (2.51) can be written as
Min
y2Rs qðy, , !Þ:
ð2:52Þ
Our convexity assumptions imply that for a.e. ! 2  the function qð,  , !Þ
is convex. Therefore we can study this problem in the framework of conjugate
duality discussed in Section 7.2 of the Appendix.6
Let us denote by #ð, !Þ the optimal value of problem (2.51), or
equivalently of problem (2.52). Note that Fðx, !Þ ¼ #ðTðx, !Þ, !Þ, where
6 Note that in order to be consistent with the notation of two-stage programming, in the present case
the optimization in (2.51) is performed with respect to y while in Section 7.2 the corresponding
optimization is performed with respect to x.
90
A. Ruszczyn´ski and A. Shapiro

Tðx, !Þ :¼ ðt1ðx, !Þ, . . . , tmðx, !ÞÞ. The dual of problem (2.51) can be written in
the form
Max
0
T þ inf
y2Y Lð y, , !Þ
	

,
ð2:53Þ
where
Lð y, , !Þ :¼ qð y, !Þ þ
X
m
i¼1
igið y, !Þ
is the Lagrangian of problem (2.51). By the theory of conjugate duality we
have the following results (see Proposition 55).
Proposition 25. Let  and ! 2  be given. Suppose that problem (2.51) is
convex. Then the following holds. (i) The functions #ð, !Þ and Fð, !Þ are convex.
(ii) Suppose that problem (2.51) is subconsistent. Then there is no duality gap
between problem (2.51) and its dual (2.53) if and only if the optimal value
function #ð, !Þ is lower semicontinuous at . (iii) There is no duality gap between
problems (2.51) and (2.53) and the dual problem (2.53) has a nonempty set of
optimal solutions if and only if the optimal value function #ð, !Þ is
subdiﬀerentiable at . (iv) Suppose that the optimal value of (2.51) is ﬁnite.
Then there is no duality gap between problems (2.51) and (2.53) and the dual
problem (2.53) has a nonempty and bounded set of optimal solutions if and only
if  2 int ðdom #ð, !ÞÞ.
The regularity condition  2 intðdom #ð, !ÞÞ means that for all small
perturbations of  the corresponding problem (2.51) remains feasible. We can
also characterize the diﬀerentiability properties of the optimal value functions
in terms of the dual problem (2.53). Let us denote by Dð, !Þ the (possibly
empty) set of optimal solutions of the dual problem (2.53).
Proposition 26. Let ! 2  and  ¼ Tðx, !Þ be given. Suppose that problem
(2.51) is convex, and that problems (2.51) and (2.53) have ﬁnite and equal
optimal values. Then
@#ð, !Þ ¼ Dð, !Þ:
ð2:54Þ
Suppose, further, that the functions tið, !Þ, i ¼ 1, . . . , m, are diﬀerentiable,
and that the condition
0 2 intfTðx, !Þ þ rTðx, !ÞRs  dom #ð, !Þg
ð2:55Þ
Ch. 2. Optimality and Duality in Stochastic Programming
91

holds. Then
@Fðx, !Þ ¼ rTðx, !ÞTDð, !Þ:
ð2:56Þ
As before, all subdiﬀerentials and derivatives in the above formulas are
taken with respect to x and .
Corollary 27. Let ! 2  and  ¼ Tðx, !Þ be given. Suppose that problem (2.51)
is convex. Then #ð, !Þ is diﬀerentiable at  if and only if Dð, !Þ is a singleton.
Suppose, further, that the functions tið, !Þ, i ¼ 1, . . . , m, are diﬀerentiable. Then
Fð, !Þ is diﬀerentiable at x if Dð, !Þ is a singleton.
Proof. If Dð, !Þ is a singleton, then the set of optimal solutions of the dual
problem (2.53) is nonempty and bounded, and hence there is no duality gap
between problems (2.51) and (2.53). Thus formula (2.54) holds. Conversely, if
@#ð, !Þ is a singleton and hence is nonempty, then again there is no duality
gap between problems (2.51) and (2.53), and hence formula (2.54) holds.
Now if Dð, !Þ is a singleton, then #ð, !Þ is continuous at  and hence the
regularity condition (2.55) holds. It follows then by formula (2.56) that Fð, !Þ
is diﬀerentiable at x and formula
rFðx, !Þ ¼ rTðx, !ÞTDð, !Þ
ð2:57Þ
holds.
u
Let us discuss now properties of the expectation function f ðxÞ :¼ E½Fðx, !Þ.
If the set  is ﬁnite, say  ¼ f!1, . . . , !Kg with corresponding probabilities pk,
k ¼ 1, . . . , K, then f ðxÞ ¼ PK
k¼1 pkFðx, !kÞ and subdiﬀerentiability of f ðxÞ
is described in Theorem 6 together with formula (2.56). In particular, we
obtain that f ðÞ is diﬀerentiable at a point x if the functions tið, !Þ,
i ¼ 1, . . . , m, are diﬀerentiable at x and for every ! 2  the corresponding
dual problem (2.53) has a unique optimal solution.
Let us discuss now the general case where  does not need to be ﬁnite.
Assume that the functions qðy, !Þ and giðy, !Þ, tiðx, !Þ, i ¼ 1, . . . , m, are random
lower semicontinuous. Then it follows that the function qðy, Tðx, !Þ, !Þ is also
random lower semicontinuous. Consequently, we obtain by Theorem 19 from
the Appendix of Chapter 1 that for any x the optimal (minimal) value Fðx, Þ is
measurable. If, moreover, for a.e. ! 2  the function Fð, !Þ is lower
semicontinuous, then the integrand Fðx, !Þ is random lower semicontinuous.
Since, by convexity, the functions tið, !Þ are continuous, we have that Fð, !Þ
is lower semicontinuous if #ð, !Þ is lower semicontinuous. Also since Fðx, Þ is
measurable, in order to verify that f ðxÞ is well deﬁned we only need to check
that either E½Fðx, !Þþ or E½ðFðx, !ÞÞþ is ﬁnite.
By Theorem 9 and Proposition 26 we obtain the following result.
92
A. Ruszczyn´ski and A. Shapiro

Theorem 28. Suppose that: (i) the functions qð y, !Þ and gið y, !Þ, tiðx, !Þ,
i ¼ 1, . . . , m, are random lower semicontinuous, (ii) for a.e. ! 2  the problem
(2.51) is convex, (iii) for a.e. ! 2  the optimal value function #ð, !Þ is lower
semicontinuous, (iv) for a.e. ! 2  the functions tið, !Þ, i ¼ 1, . . . , m, are dif-
ferentiable and the regularity condition (2.55) holds, (v) the expectation function
f ðxÞ is proper and its domain has a nonempty interior. Then for any x 2 dom f ,
@f ðxÞ ¼
Z

rTðx, !ÞTDðTðx, !Þ, !Þ dPð!Þ þ Ndom f ðxÞ:
ð2:58Þ
Proof. It follows from assumptions (i)–(iii) that Fðx, !Þ is random lower
semicontinuous. If #ð, !Þ < þ1, then # ð, !Þ is lower semicontinuous at  iﬀ
there is no duality gap between problems (2.51) and (2.53). Formula (2.58)
follows then from the corresponding formula of Theorem 9 and formula (2.56)
of Proposition 26.
u
Under the assumptions of the above theorem we have that f ðÞ is dif-
ferentiable at a point x iﬀx 2 intðdom f Þ and DðTðx, !Þ, !Þ is a singleton w.p.1.
The above analysis can be applied to the second stage problem of form
(2.35) with the function f2ð, !Þ being convex (not necessarily polyhedral) for
a.e. ! 2 . The dual of (2.35) can be still written in the form (2.38) However,
in the non-polyhedral case one needs some additional conditions in order to
ensure that there is no duality gap between the (primal) problem (2.35) and its
dual (2.38). For example, we have that if, for a given ðx, !Þ, the optimal value
of (2.35) is ﬁnite, then there is no duality gap between (2.35) and (2.38) and the
dual problem (2.38) has a nonempty and bounded set of optimal solutions iﬀ
the following condition holds
hð!Þ  Tð!Þx 2 intfWð!Þ ½dom f2ð, wÞg:
ð2:59Þ
The
above
condition
means
that
for
small
perturbations
of
 ¼
hð!Þ  Tð!Þx the corresponding (primal) problem remains feasible.
3
Multistage models
Consider the linear multistage problem
MinE ½ cT
1 x1
þ cT
2 x2
þ cT
3 x3
þ
...
þ cT
TxT
s:t:
A11x1
¼ b1,
A21x1 þ A22x2
¼ b2,
A32x2 þ A33x3
¼ b3,
...........................................................................
AT,T1xT1 þ ATTxT ¼ bT,
x1 0,
x2 0,
x3 0,
...
xT 0:
ð3:1Þ
Ch. 2. Optimality and Duality in Stochastic Programming
93

In this problem x1 2 Rn1, . . . , xT 2 RnT are the parts of the decision vector
corresponding to stages 1, . . . , T, and the random variables associated with
period t are t :¼ ðct, At, t1, Att, btÞ. Each xt is allowed to depend on
½1, t :¼ ð1, . . . , tÞ, but not on future observations tþ1, . . . , T. That is,
xt ¼ xtð½1, tÞ is viewed as a function of ð1, . . . , tÞ, and the minimization is
performed over appropriate functional spaces. In particular, x1 depends only
on 1 which is deterministic, and hence x1 is deterministic. The constraints of
(3.1) are assumed to hold for almost every realization of the random data
 ¼ ð1, . . . , TÞ. If the number of scenarios is ﬁnite, i.e., the distribution of
 has a ﬁnite support, then problem (3.1) can be written as a large linear
programming problem. See Chapter 1 for additional motivation and
discussion of multistage models.
We discuss in this section a slightly more general structure, a polyhedral
multistage model, which is formulated as follows:
Min E ½ f1ðx1, 1Þ þ f2ðx2, 2Þ þ f3ðx3, 3Þ þ . . . þ fTðxT, TÞ
s:t:
A11ð1Þx1
¼ b1ð1Þ,
A21ð2Þx1 þ A22ð2Þx2
¼ b2ð2Þ,
A32ð3Þx2 þ A33ð3Þx3
¼ b3ð3Þ,
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
AT, T1ðTÞxT1 þ ATTðTÞxT
¼ bTðTÞ:
ð3:2Þ
Here 1, . . . , T is a vector valued random process associated with stages
1, . . . , T, and the objective parts ftðxt, tÞ, t ¼ 1, . . . , T, associated with the
successive stages, are assumed to be random polyhedral functions. Random
polyhedral functions were introduced in Section 2.3, see equation (2.37) in
particular. Note a slight diﬀerence in notation here, it is explicitly assumed in
(3.2) that all random data are a function of the process 1, . . . , T, which
include random variables deﬁning the (polyhedral) objective functions and the
constraints. As in the linear multistage model (3.1), each xt may only depend
on ½1, t but not on future observations, i.e., xt ¼ xtð½1, tÞ is a function of ½1, t,
and the minimization is performed over appropriate functional spaces. Since
1 becomes known before the ﬁrst decision is made, we may assume that f1
depends on x1 only, but for the uniformity of notation we keep 1 in the
formulation of the problem.
Similarly to the two-stage case, every polyhedral multistage problem (with a
ﬁnite number of scenarios) can be converted into a linear multistage problem
by adding new variables and constraints. The form (3.2), though, is
more convenient to analyze. So in the remainder of this section we deal with
model (3.2). We denote  :¼ ½1, T ¼ ð1, . . . , TÞ the random data of the
considered problem.
94
A. Ruszczyn´ski and A. Shapiro

Deﬁnition 29. A sequence of mappings xtðÞ, t ¼ 1, . . . , T, is called an
implementable policy if each xtðÞ is a function of the history ½1, t of the
process. An implementable policy xtð½1, tÞ, t ¼ 1, . . . , T, is said to be a feasible
policy if it satisﬁes all constraints of (3.2) and xtð½1, tÞ 2 dom ftð, tÞ,
t ¼ 1, . . . , T, for a.e. .
Let us denote, as in Chapter 1, by Qtðxt1, ½1, tÞ the optimal value of the
following problem (the cost-to-go)
MinE½ ftðxt,tÞþftþ1ðxtþ1,tþ1Þ þ

þfTðxT,TÞj½1,t
s:t:
At,t1ðtÞxt1þAttðtÞxt
¼btðtÞ,
Atþ1,tðtþ1Þxt þ Atþ1,tþ1ðtþ1Þxtþ1
¼btþ1ðtþ1Þ,
.............................................................................................
AT,T1ðTÞxT1 þATTðTÞxT
¼bTðTÞ:
ð3:3Þ
In the above problem values of xt1 and 1, . . . , t are assumed to be known,
and hence the optimal value of (3.3) is a function of these values. Problem
(3.3) is viewed as a multistage problem with the ﬁrst period starting at time t,
and depending on xt1 2 Rnt1 through the ﬁrst equation constraint.
As outlined in Chapter 1, functions Qtðxt1, ½1, tÞ satisfy, for a.e. , the
following dynamic programming equation:
Qtðxt1, ½1, tÞ ¼ infxt2Rnt ’tðxt, ½1, tÞ: At, t1ðtÞxt1 þ AttðtÞxt ¼ bt

,
ð3:4Þ
where
’tðxt, ½1, tÞ :¼ ftðxt, tÞ þ E Qtþ1ðxt, ½1, tþ1Þj ½1, t


:
ð3:5Þ
In the remainder of this section we focus our attention on distributions with
a ﬁnite support of the random data vector . Note that since it is assumed that
the problem is polyhedral and the distribution of ð!Þ has a ﬁnite support, the
functions ’tð, Þ are random polyhedral. Let us analyze the Lagrangian
Ltðxt, tÞ :¼ ’tðxt, ½1, tÞ þ T
t ðbtðtÞ  At, t1ðtÞxt1  AttðtÞxtÞ
of problem (3.4) and the dual functional
DtðtÞ :¼ infxt2Rnt Ltðxt, tÞ ¼ ’tðxtÞ  T
t Attxt þ T
t ðbt  At, t1xt1Þ


:
Ch. 2. Optimality and Duality in Stochastic Programming
95

We omit for brevity the arguments ½1, t in these expressions. It follows that
we can write the dual of the problem (3.4) as follows
Max
t
DtðtÞ ¼ ’*t AT
ttt


þ T
t ðbt  At, t1xt1Þ


,
ð3:6Þ
where ’*t is the conjugate of ’t. We deal here with polyhedral problems, so by
the duality theory of linear programming, if Qtðxt1, ½1, tÞ < þ1, then there is
no duality gap between problems (3.4) and (3.6), and hence
Qtðxt1, ½1, tÞ ¼ sup
t
’*t AT
ttt


þ T
t ðbt  At, t1xt1Þ


:
ð3:7Þ
Moreover, if Qtðxt1, ½1, tÞ is ﬁnite, then both problems (3.4) and (3.6) have
nonempty sets of optimal solutions. Let us denote, as before, by Dtðxt1, ½1, tÞ
the set of optimal solutions of the dual problem (3.6). We then have an
analogue of Proposition 21.
Proposition 30. For every t ¼ 2, . . . , T the function Qtð, ½1, tÞ is a convex
polyhedral function. Moreover, Qtð, ½1, tÞ is subdiﬀerentiable at every xt1, at
which Qtðxt1, ½1, tÞ is ﬁnite, and
@Qtðxt1, ½1, tÞ ¼ AT
t, t1ðtÞDtðxt1, ½1, tÞ:
ð3:8Þ
Proof. The assertion is true for t ¼ T by Proposition 21. Suppose now that
t < T and the assertion holds for t þ 1. Since the distribution of tþ1 is
discrete, the function (3.5) is a convex polyhedral function, as a sum of ﬁnitely
many convex polyhedral functions. Consequently, Proposition 21 applies to
problem (3.4) and our assertion is true for all t.
u
Identically to the two stage case, the set of maximizers in (3.6), denoted
Dtðxt1, ½1, tÞ, is a convex closed polyhedron. Two cases are possible. If it
is bounded, then it is the convex hull of its ﬁnitely many vertices, and
Qtð, ½1, tÞ is ﬁnite around xt1. If Dtðxt1, ½1, tÞ is unbounded, then its
recession cone (which is polyhedral) is the normal cone to the domain of
Qtð, ½1, tÞ at xt1.
Example 31 (Trucking). Let us return to the trucking example (Example 9)
from Chapter 1. Let us develop the dynamic programming equations for
96
A. Ruszczyn´ski and A. Shapiro

this model. We have here that Qtðrt1, D½1, tÞ is equal to the optimal value of
the following problem
Max
yt, zt, rt
X
n
i, j¼1
ðqijzijt  cijyijtÞ þ E Qtþ1 rt, D½1, tþ1

 j D½1, t


(
)
s:t:
zijt  Dijt,
i, j ¼ 1, . . . , n,
zijt  yijt,
i, j ¼ 1, . . . , n,
ri, t1 þ
X
n
k¼1
ykit 
X
n
j¼1
yijt ¼ rit,
i ¼ 1, . . . , n,
rt  0, yt  0, zt  0:
ð3:9Þ
We used here the fact that rt is a suﬃcient state vector for this problem.
Let it denote the Lagrange multipliers associated with the state constraints
in (3.9) and let tðrt1, D½1, tÞ be the set of the optimal values of these
multipliers. Then we know that the function Qtð, D½1, tÞ is concave (we have a
maximization problem here) and its superdiﬀerential7 is equal to
@Qtðrt1, D½1, tÞ ¼ tðrt1, D½1, tÞ:
ð3:10Þ
4
Optimality conditions, basic case
In this section we discuss optimization problems of the form
Min
x2X f f ðxÞ :¼ E½Fðx, !Þg,
ð4:1Þ
where F: Rn   ! R is an integrand and X is a nonempty subset of Rn. We
assume that the expectation function f ðÞ is well deﬁned on Rn. Let us recall
that from the theoretical point of view the feasibility constraint x 2 X can be
absorbed into the objective function by deﬁning8 Fðx, !Þ :¼ Fðx, !Þ þ iXðxÞ,
i.e.,
Fðx, !Þ ¼
Fðx, !Þ,
if x 2 X,
þ1,
if x 62 X:
	
7 Since we deal here with a concave rather than convex function, we call @Qtðrt1, D½1, tÞ the
superdiﬀerential rather than subdiﬀerential.
8 Recall that iXðÞ denotes the indicator function of the set X.
Ch. 2. Optimality and Duality in Stochastic Programming
97

The optimization problem (4.1) can be formulated then in the form
Min
x2 Rn f f ðxÞ :¼ E½Fðx, !Þg:
ð4:2Þ
Clearly it follows that f ðxÞ ¼ f ðxÞ þ iXðxÞ, and hence dom f ¼ X \ dom f .
Note that the feasible set of the problem (4.1) is given by the intersection of
the set X and dom f . This set coincides, of course, with the feasible set of the
problem (4.2) given by dom f . In this section we discuss the case where the set
X is convex and the integrand Fð, !Þ is convex for a.e. ! 2 , and hence the
expectation function f ðÞ is also convex.
In the following proposition we present necessary and suﬃcient conditions
for a feasible point x0 to be an optimal solution of the problem (4.1). In order
to ensure necessity of these conditions we need a regularity assumption
(constraint qualiﬁcation). A simple constraint qualiﬁcation of such type is the
following:
riðXÞ \ riðdom f Þ 6¼ ;,
ð4:3Þ
i.e., there exists a point x 2 riðXÞ belonging to the relative interior of the
domain of f . Note that if a point x 2 X, then any neighborhood of x has a
nonempty intersection with riðXÞ. Therefore, if the domain of f has a
nonempty
interior,
and
hence
riðdom f Þ ¼ intðdom f Þ,
then
the
above
constraint qualiﬁcation (4.3) is equivalent to the following
X \ intðdom f Þ 6¼ ;:
ð4:4Þ
Note also that if f is ﬁnite in at least one point of the interior of its domain,
then f is continuous and subdiﬀerentiable at that point, and hence is proper.
Proposition 32. Suppose that the set X and the function f are convex. Consider
a point x0 2 X such that f ðx0Þ is ﬁnite. Then x0 is an optimal solution of problem
(4.1) if the following condition holds:
0 2 @f ðx0Þ þ NXðx0Þ:
ð4:5Þ
Moreover, if f is proper and the constraint qualiﬁcation (4.3) is satisﬁed, then
condition (4.5) is also necessary for x0 to be an optimal solution of the problem
(4.1).
Proof. We have here that x0 2 dom f , where f ðxÞ :¼ f ðxÞ þ iXðxÞ. It follows
immediately from the deﬁnition of subdiﬀerentials that x0 is an optimal
solution of the problem (4.2) iﬀ0 2 @f ðx0Þ. Since the set X is nonempty, the
indicator function iX is proper. If condition (4.5) holds, then @f ðx0Þ is nonempty,
98
A. Ruszczyn´ski and A. Shapiro

and hence f is a proper function. It follows then by the Moreau–Rockafellar
Theorem (Theorem 50) that @f ðx0Þ includes the set @f ðx0Þ þ @iXðx0Þ. Also we
have
that
@iXðx0Þ
coincides
with
NXðx0Þ.
Therefore,
we
obtain
that
@f ðx0Þ þ NXðx0Þ  @f ðx0Þ:Consequently,ifcondition(4.5)holds,then0 2 @f ðx0Þ,
and hence x0 is an optimal solution of (4.2). Moreover, under the constraint
qualiﬁcation (4.3) and the assumption that f is proper, @f ðx0Þ þ @iXðx0Þ is
equal to @f ðx0Þ by the Moreau–Rockafellar Theorem, and hence the necessity
of (4.5) follows.
u
The above optimality conditions can be combined, of course, with the
formula for the subdiﬀerential of the expectation function given in Theorem 9.
Note that the constraint qualiﬁcation condition (4.4) implies that the domain
of f has a nonempty interior.
Theorem
33. Suppose
that:
(i)
the
function
Fðx, !Þ
is
random
lower
semicontinuous, (ii) for a.e. ! 2  the function Fð, !Þ is convex, (iii) the
expectation function f is proper, (iv) the set X is convex, (v) the constraint
qualiﬁcation (4.4) is satisﬁed. Then a point x0 2 X \ dom f is an optimal
solution of the problem (4.1) if and only if the following condition holds:
0 2
Z

@Fðx0, !Þ dPð!Þ þ Ndom f ðx0Þ þ NXðx0Þ:
ð4:6Þ
In particular, if x0 belongs to the interior of the domain of f, then
Ndom f ðx0Þ ¼ f0g, and hence in that case the optimality condition (4.6) takes on
the form
0 2
Z

@Fðx0, !Þ dPð!Þ þ NXðx0Þ:
ð4:7Þ
5
Optimality conditions for multistage models
Let us now turn to the polyhedral multistage model (3.2). We assume that
the random vector  ¼ ð1, . . . , TÞ has a distribution with a ﬁnite support.
Recall Deﬁnition 29 of a feasible policy xtð½1, tÞ of problem (3.2).
Since the distribution of  has a ﬁnite support, the value of the objective
function of (3.2) is ﬁnite for every feasible policy. A question arises when a
feasible policy is optimal. Note that since we deal with distributions with a
ﬁnite support, a statement that a certain property holds for a.e.  is equivalent
here to that this property holds for every realization of . We write this simply
as ‘‘for every realization  . . .’’.
Ch. 2. Optimality and Duality in Stochastic Programming
99

Theorem 34. A feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, is optimal for (3.2) if and
only if, for all t ¼ 1, . . . , T, and every realization ,
^xtð½1, tÞ2arg min
xt2Rnt ’tðxt, ½1, tÞ:AttðtÞxt ¼btðtÞAt, t1ðtÞ ^xt1ð½1, t1Þ


,
ð5:1Þ
where ’tðxt, ½1, tÞ is deﬁned in (3.5) with the term QTþ1 omitted for t ¼ T.
Proof. The assertion is obvious for T ¼ 1. Let us suppose that it is true for
T  1. Consider problem (3.3) for t ¼ 2, where ^x1 is assumed to be ﬁxed. By
our assumption, the policy ^xtð½1, tÞ, t ¼ 2, . . . , T is optimal for this problem if
and only if relations (5.1) hold for t ¼ 2, . . . , T. On the other hand, since
Q2ðx1, ½1, 2Þ is the optimal value of (3.3) for t ¼ 2 for any ðx1, ½1, 2Þ, the ﬁrst
stage decision ^x1 is optimal for (3.2) if and only if (5.1) is true for t ¼ 1.
u
It follows from the above result that the multistage problem can be viewed
as a nested family of stochastic optimization problems of form (4.1), and we
can apply all the results derived in the preceding section.
Theorem 35. (i) A feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, is optimal for (3.2) if
and only if, for all t ¼ 1, . . . , T, and every realization ½1, t, there exist multipliers
^tð½1, tÞ such that9
0 2 @ftð ^xtð½1, tÞ, tÞAttðtÞT ^tð½1, tÞ þ E @Qtþ1ð ^xtð½1, tÞ, ½1, tþ1Þ j ½1, t


:
ð5:2Þ
(ii) Multipliers ^tð½1, tÞ satisfy (5.2) for a feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, if
and only if for every realization ½1, t,
^tð½1, tÞ 2 Dtð ^xt1ð½1;t1Þ, ½1, tÞ,
ð5:3Þ
where Dtð ^xt1ð½1, t1Þ; ½1;tÞ is the set of optimal solutions of the dual problem
(3.6).
Proof. By Proposition 30 the functions in problem (5.1) are polyhedral, so the
optimality conditions of Theorem 33 hold without any additional constraint
qualiﬁcation assumptions. Relation (5.2) follows then from Theorem 34.
Relation (5.3) is the consequence of the duality theorem in convex pro-
gramming applied to problem (5.1).
u
9 For t ¼ T we omit the term with QTþ1 in (1.2).
100
A. Ruszczyn´ski and A. Shapiro

Proposition 30 provides us with the explicit form of the subdiﬀerentials
involved in (5.2):
@Qtþ1ðxt, ½1, tþ1Þ ¼ Atþ1, tðtþ1ÞTDtþ1ðxt, ½1, tþ1Þ:
ð5:4Þ
This allows us to reformulate part (i) of Theorem 35 as follows.
Corollary 36. A feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, is optimal for (3.2) if and
only if, for all t ¼ 1, . . . , T, and every realization ½1, t, there exist multipliers
^tð½1, tÞ such that10
02@ftð ^xtð½1, tÞ, tÞAttðtÞT ^tð½1, tÞE Atþ1, tðtþ1ÞT ^tþ1ð½1, tþ1Þ j ½1, t


,
t ¼ 1, . . . , T:
ð5:5Þ
Proof. Suppose that a policy ^xtð½1, tÞ, t ¼ 1, . . . , T, is optimal for (3.2).
Consider t ¼ 1. By Theorem 35, we can choose multipliers ^1 2 D1 such that
(5.2) holds for t ¼ 1. Note that there is no preceding stage, so the set D1 is
ﬁxed. It follows from (5.2) and (5.4) that we can choose a measurable selection
^2ð½1, 2Þ 2 D2ð ^x1, ½1, 2Þ
such that11
0 2 @f1ð ^x1ð1Þ, 1Þ  A11ð1ÞT ^1ð1Þ  E A2,1ð2ÞT ^2ð½1, 2Þj 1


,
ð5:6Þ
so formula (5.5) is true for t ¼ 1. By Theorem 35 (ii), the same selection
^2ð½1, 2Þ can be used in (5.2) for t ¼ 2. Then there exists a measurable selection
^3ð½1, 3Þ 2 D3ð ^x1, ½1, 3Þ
such that (5.5) is true for t ¼ 2. Proceeding in this way we ﬁnd selections (5.3)
such that (5.5) holds for all t ¼ 1, . . . , T.
u
It should be stressed that both the polyhedrality of the objective and the
ﬁnite number of realizations of  are essential for Theorems 34 and 35, and
for Corollary 36, because we could avoid the veriﬁcation of constraint
qualiﬁcation conditions for problems appearing in (5.1). For the nested
formulation (3.4) these conditions are diﬃcult to ensure, in general. However,
when the distribution of  remains ﬁnite, we can formulate the necessary and
suﬃcient conditions for problems of form (3.2) with general convex functions.
10 Again, for t ¼ T we omit the term with T þ 1 in (5.5).
11 Since 1 is not random, the conditional expectation in (5.6) does not depend on 1, we write it for
uniformity of the notation.
Ch. 2. Optimality and Duality in Stochastic Programming
101

Let us rewrite (3.2) in a compact form
Min E½ f ðx, Þ
ð5:7Þ
s:t:
Ax ¼ b,
ð5:8Þ
where
f ðx, Þ :¼
X
T
t¼1
ftðxtð½1, tÞ, tÞ,
A is the block matrix deﬁning the constraints of (3.2), and b is the
corresponding vector of the right hand sides. We should keep in mind that the
decision vector x ¼ xðÞ is an implementable policy, that is,
xðÞ ¼ ðxtð½1, tÞÞt¼1,..., T,
and each constraint of (3.2), associated with stage t, has as many realizations
as there are diﬀerent values of ½1, t possible. All these numbers are ﬁnite, so
(5.7)–(5.8) is a ﬁnite dimensional convex optimization problem.
Denote by X the linear manifold (aﬃne space) deﬁned by (5.8). It follows
from Proposition 32 that a policy ^x 2 X \ dom Ef ð, Þ is optimal if the
following condition holds:
0 2 @ E½ f ð ^x, Þ þ NXð ^xÞ:
ð5:9Þ
Moreover, if E½ f ð, Þ is proper and the constraint qualiﬁcation12 (4.3) is
satisﬁed, then condition (5.9) is also necessary for ^x to be an optimal solution
of the problem (3.2).
Since X is a linear manifold, the normal cone NXðxÞ is constant (i.e., does
not depend on x 2 X) and coincides with the linear space orthogonal to X.
Consequently, NXðxÞ is equal to the set of vectors of form AT, where
 ¼ tð½1, tÞ


t¼1,..., T:
Let us introduce an equivalent representation of the normal cone. For each
possible realization k
½1, t of ½1, t we deﬁne13
^t k
½1, t


:¼ 
1
Pf½1, t ¼ k
½1, tg
 
!
t k
½1, t


:
ð5:10Þ
12 Since X is an aﬃne space, its relative interior coincides with X.
13 To avoid collisions of subscripts we slightly change our notation and use superscripts to denote
realizations (scenarios).
102
A. Ruszczyn´ski and A. Shapiro

It is legitimate, because Pf½1, t ¼ k
½1, tg > 0. Then NXðxÞ is the set of vectors
of the form
AttðtÞT ^tð½1, tÞ þ E Atþ1, tðtþ1ÞT ^tþ1ð½1, tþ1Þj ½1, t




t¼1,..., T,
where, for uniformity, we take the convention that all the terms involving
T þ 1 are 0.
Then simple manipulations show that the relation (5.9) is identical with
(5.5).
Corollary 37. Suppose that the distribution of  has a ﬁnite support and the
functions ftð, tÞ, t ¼ 1, . . . , T, are convex for every realization of . Then for a
feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, to be optimal it is suﬃcient that for all
t ¼ 1, . . . , T, and every realization ½1, t, there exist multipliers ^tð½1, tÞ such that
the relations (5.5) are satisﬁed. If, in addition, the constraint qualiﬁcation (4.3)
holds, then conditions (5.5) are also necessary for ^xtð½1, tÞ to be optimal for the
problem (3.2).
6
Duality, basic case
Let us discuss ﬁrst the case where the set  is ﬁnite, say  ¼ f!1, . . . , !Kg
with corresponding probabilities pk > 0, k ¼ 1, . . . , K. As it was mentioned in
Chapter 1, in that case we can formulate problem (4.2) in the following
equivalent form
Minx1,..., xK, z
X
K
k¼1
pkFðxk, !kÞ,
subject to
xk ¼ z,
k ¼ 1, . . . , K,
ð6:1Þ
where x1, . . . , xK and z are n-dimensional vectors. Of course, we can eliminate
z from the above problem by expressing it in terms of x1, . . . , xK. However, it
will be convenient to view z as an additional variable.
Since the probabilities pk are assumed to be positive, the constraints of
problem (6.1) can be also written as the equations pkðxk  zÞ ¼ 0. This
suggests the following Lagrangian for problem (6.1),
Lðx1, . . . , xK, z, 1, . . . , KÞ :¼
X
K
k¼1
pkFðxk, !kÞ þ
X
K
k¼1
pkT
k ðxk  zÞ,
ð6:2Þ
Ch. 2. Optimality and Duality in Stochastic Programming
103

where k 2 Rn, k ¼ 1, . . . , K, are called Lagrange multipliers. The problem
(6.1) can be represented as the min–max problem
Min
x1,..., xK, z
sup
1,..., K
Lðx1, . . . , xK, z, 1, . . . , KÞ
	

:
ð6:3Þ
Its dual problem is obtained by interchanging the order of the Min and
Max operators. Since the inﬁmum of the Lagrangian over z is 1 unless
PK
k¼1 pkk ¼ 0, this leads to the following dual of the problem (6.1):
Max1,..., K
infx1,..., xK
X
K
k¼1
pk Fðxk, !kÞ þ T
k xk


(
)
subject to
X
K
k¼1
pkk ¼ 0
ð6:4Þ
Note the separable structure of the above problem,14 that is
inf
x1,..., xK
X
K
k¼1
pk Fðxk, !kÞ þ T
k xk


¼
X
K
k¼1
pk inf
xk Fðxk, !kÞ þ T
k xk




:
ð6:5Þ
We also have that
inf
xk
FkðxkÞ þ T
k xk


¼  sup
xk
ðkÞTxk  FkðxkÞ


¼ F*
kðkÞ,
where FkðÞ:¼ Fð, !kÞ and F*
k is the conjugate of Fk. Therefore we can write
the dual problem (6.4) in the form
Max1,..., K

X
K
k¼1
pkF*
k k
ð
Þ
(
)
,
subject to
X
K
k¼1
pkk ¼ 0:
ð6:6Þ
Problems (6.1) and (6.4) can be represented by employing the min–max and
max–min operators, respectively, applied to the Lagrangian. It follows that
14 One should be careful in writing equation (6.5) since some of the optimal values there can be þ1 or
1, and adding þ1 and 1 should be avoided.
104
A. Ruszczyn´ski and A. Shapiro

the optimal value of the problem (6.1) is always greater than or equal to the
the optimal value of its dual problem (6.4). It is also not diﬃcult to see this
directly. Indeed, for any 1, . . . , K such that PK
k¼1 pkk ¼ 0 the following
inequality holds
inf
x1,..., xK
X
K
k¼1
pkFðxk, !kÞ þ
X
K
k¼1
pkT
k xk
(
)
 inf
x
f ðxÞ ¼
X
K
k¼1
pkFðx, !kÞ
(
)
:
ð6:7Þ
The above inequality is obtained by restricting the search at the left hand
side to xk ¼ x, k ¼ 1, . . . , K. Since (6.7) holds for any multipliers k satisfying
constraint PK
k¼1 pkk ¼ 0, it follows that the optimal value of (6.4) is less than
or equal to the optimal value of (4.2).
In order to ensure that problems (6.1) and (6.4) have equal optimal values,
i.e., that there is no duality gap between (6.1) and (6.4), one needs a constraint
qualiﬁcation condition. It is possible to deal with the duality gap problem by
employing various techniques of convex analysis. We outline below a
particular approach which is relatively elementary and easy to extend to
inﬁnite dimensional cases.
By the min–max representation, there is no duality gap between (6.1) and
(6.4) and both problems have optimal solutions iﬀthe Lagrangian has a saddle
point. That is, there is a feasible point ðx1, . . . , zÞ of problem (6.1) and a
feasible point ð1, . . . , KÞ of (6.4) such that Lð, . . . ,  , 1, . . . , KÞ attains
its (unconstrained) minimum at ðx1, . . . , zÞ and Lðx1, . . . , z,  , . . . , Þ attains
its maximum at ð1, . . . , KÞ. Equivalently, ðx1, . . . , z, 1, . . . , KÞ is a saddle
point iﬀ
xk ¼ z, k ¼ 1, . . . , K;
X
K
k¼1
pkk ¼ 0,
ð6:8Þ
and ðx1, . . . , xKÞ is an optimal solution of the (unconstrained) problem
Min
x1,..., xK
X
K
k¼1
pkFðxk, !kÞ þ
X
K
k¼1
pk
T
k xk
(
)
:
ð6:9Þ
In that case z is an optimal solution of (4.2) (or, equivalently, of (4.1)) and
ð1, . . . , KÞ is an optimal solution of (6.4). Since problem (6.9) is separable,
ðx1, . . . , xKÞ is an optimal solution of problem (6.9) iﬀ
xk 2 arg min
xk
Fðxk, !kÞ þ 
T
k xk
n
o
,
k ¼ 1, . . . , K:
ð6:10Þ
Ch. 2. Optimality and Duality in Stochastic Programming
105

The functions Fð, !kÞ are assumed to be convex, so condition (6.10)
holds iﬀk 2 @Fðxk, !kÞ, k ¼ 1, . . . , K. Therefore ðx0, . . . , x0, 1, . . . , KÞ is
a saddle point of the Lagrangian iﬀ
k 2 @Fðx0, !kÞ, k ¼ 1, . . . , K,
and
X
K
k¼1
pkk ¼ 0:
ð6:11Þ
Theorem 38. Suppose that the set X and the functions Fð, !kÞ, k ¼ 1, . . . , K,
are convex. Then the following holds. (i) Points x0 and ð1, . . . , KÞ are optimal
solutions of problems (4.1) and (6.4), respectively, and there is no duality gap
between these problems if and only if condition (6.11) is satisﬁed. (ii) Problems
(4.1) and (6.4) have optimal solutions and there is no duality gap between these
problems if and only if there exists a point x0 such that
0 2
X
K
k¼1
pk@Fðx0, !kÞ:
ð6:12Þ
(iii) Problems (4.1) and (6.4) have optimal solutions and there is no duality gap
between these problems if problem (4.1) has an optimal solution x0, the function f
is proper and the regularity condition (4.3) is satisﬁed.
Proof. By the discussion preceding the theorem, ðx0, . . . , x0, 1, . . . , KÞ is a
saddle point of the Lagrangian iﬀcondition (6.11) is satisﬁed. This proves
assertion (i). Since it is assumed that all pk are positive, condition (6.12) is
equivalent to existence of k satisfying (6.11). Note that (6.12) implies that all
functions Fð, !kÞ are subdiﬀerentiable at x0 and hence Fðx0, !kÞ is ﬁnite, and
consequently f ðx0Þ is ﬁnite. Assertion (ii) then follows. By the Moreau–
Rockafellar Theorem, if the regularity condition (4.3) is satisﬁed and
x0 2 dom f , then
@f ðx0Þ ¼
X
K
k¼1
pk@Fðx0, !kÞ:
ð6:13Þ
Moreover, if x0 is an optimal solution of (4.1), then 0 2 @f ðx0Þ, and hence
assertion (iii) follows from (ii).
u
The above results can be formulated in the following form. Consider the
problem
Min
xð!Þ2X E Fðxð!Þ, !Þ þ ð!ÞTxð!Þ


:
ð6:14Þ
106
A. Ruszczyn´ski and A. Shapiro

Here xðÞ:  ! Rn is a mapping, the constraint xð!Þ 2 X is assumed to
hold for every ! 2 , and ðÞ:  ! Rn is such that E½ð!Þ ¼ 0. Since it is
assumed that  is ﬁnite, mappings xð!Þ and ð!Þ can be identiﬁed with vectors
ðx1, . . . , xKÞ and ð1, . . . , KÞ, respectively. Therefore, problem (6.14) is
the same as problem (6.9) (for k ¼ k). By Theorem 38, if the set X and the
functions Fð, !kÞ, k ¼ 1, . . . , K, are convex, x0 is an optimal solution of the
problem (4.1), the function f is proper and the regularity condition (4.3) is
satisﬁed, then there exists ð!Þ such that E½ð!Þ ¼ 0 and xð!Þ:x0 is an
optimal solution of (6.14).
We can also investigate dual problems (6.1) and (6.4) in the framework of
conjugate duality. Let vð	Þ be the optimal value of the problem
Minx1,..., xK, z
X
K
k¼1
pkFðxk, !kÞ,
subject to
pkðxk  zÞ þ 	k ¼ 0,
k ¼ 1, . . . , K,
ð6:15Þ
where 	 ¼ ð	1, . . . , 	KÞ and 	k 2 Rn, k ¼ 1, . . . , K, are viewed as parameters
giving perturbations of problem (6.1). Clearly, for 	 ¼ 0 problem (6.15)
coincides with problem (6.1), and vð0Þ is the optimal value of (6.1). It is
straightforward to verify that the function vð	Þ is convex and its conjugate is
v*ðÞ ¼ sup
X
K
k¼1
T
k yk
X
K
k¼1
pkFðxk, !kÞ :pkðxkzÞþ	k ¼0, k¼1,. . ., K
(
)
¼ sup 
X
K
k¼1
pkT
k ðxk  zÞ 
X
K
k¼1
pkFðxk, !kÞ
(
)
¼ inf
X
K
k¼1
pkFðxk, !kÞ þ
X
K
k¼1
pkT
k ðxk  zÞ
(
)
:
Consequently the dual problem (6.4) coincides with the problem of
maximization of v*ðÞ. That is, the optimal value of the dual problem is
equal to v**ð0Þ. By the theory of conjugate duality (see Section 9.2 in the
Appendix) we have the following results.
Proposition 39. Suppose that the set X and the functions Fð, !kÞ, k ¼ 1, . . . , K,
are convex. Then the following holds. (i) Suppose that the problem (6.1) is
subconsistent. Then there is no duality gap between problems (4.1) and (6.4)
if and only if the optimal value function vð	Þ is lower semicontinuous at 	 ¼ 0.
Ch. 2. Optimality and Duality in Stochastic Programming
107

(ii) There is no duality gap between problems (4.1) and (6.4) and the dual
problem (6.4) has a nonempty set of optimal solutions if and only if vð	Þ is
subdiﬀerentiable at 	 ¼ 0. (iii) There is no duality gap between problems (4.1)
and (6.4) and the dual problem (6.4) has a nonempty and bounded set of
optimal solutions if and only if vð0Þ is ﬁnite and 0 2 intðdom vÞ. (iv) If the
dual problem (6.4) has a nonempty and bounded set of optimal solutions, then
vð	Þ is continuous at 	 ¼ 0 and there is no duality gap between problems (4.1)
and (6.4).
Remark 40. In the case of polyhedral problem (2.34)–(2.35) we have that
Fðx, !Þ ¼ f1ðxÞ þ Qðx, !Þ, where Qðx, !Þ is the optimal value of the second
stage problem (2.35). In that case problems (4.1) and (6.4) form a pair of dual
linear programming problems, and hence there is no duality gap between these
problems unless both of them are infeasible. Moreover, if the (common)
optimal value of the primal and dual problems is ﬁnite, then both problems
have nonempty sets of optimal solutions. That is, in the polyhedral case with a
ﬁnite number of scenarios, there is no need for additional regularity
conditions for the strong duality relation to hold.
Example 41 (Betting on Horses). There are n horses in a race. For every horse
i we know the probability pi that it wins and the amount si that the rest of the
public is betting on it. The track keeps a certain proportion C 2 ð0, 1Þ of the
total amount bet and distributes the rest among the public in proportion to
the amounts bet on the winning horse. We want to place bets totaling b dollars
to maximize the expected net return.
Let us denote by xi the amount bet on horse i. There are n scenarios
!1, . . . , !n in this problem, with scenario !k representing the event that horse k
wins the race. Then that the amount FkðxÞ ¼ Fðx, !kÞ gained in scenario k is
FkðxÞ ¼ Axk=ðxk þ skÞ,
where A :¼ ð1  CÞðb þ Pn
i¼1 siÞ is the total sum to be split. We can now write
the corresponding optimization problem as follows:
Max
x
A
X
n
k¼1
pkxk
xk þ sk
ð6:16Þ
s:t:
X
n
i¼1
xi ¼ b,
ð6:17Þ
x  0:
ð6:18Þ
108
A. Ruszczyn´ski and A. Shapiro

In the extended formulation (6.1) we have separated decision vectors
xk ¼ ðxk
1, . . . , xk
nÞ for each scenario k ¼ 1, . . . , n. The problem takes on the
form
Max A
X
n
k¼1
pkxk
k
xk
k þ sk
ð6:19Þ
s:t:
X
n
i¼1
x k
i ¼ b,
k ¼ 1, . . . , n,
ð6:20Þ
x k  0,
k ¼ 1, . . . , n,
ð6:21Þ
x k ¼ z,
k ¼ 1, . . . , n:
ð6:22Þ
Without
the
nonaticipativity
constraints
(6.22)
this
would
mean
the comfortable situation of knowing the winning horse before placing the
bet. The optimal solution would be then, of course, xk
k ¼ b, and xk
i ¼ 0 for
i 6¼ k.
Note that FkðxÞ ¼ Að1  sk=ðxk þ skÞÞ, and hence functions Fk are concave
on Rn
þ, and therefore, since we deal here with a maximization problem, (6.19)–
(6.22) is a convex problem. Clearly its feasible set is nonempty and bounded,
and hence it has an optimal solution. Since, in fact, functions Fk are strictly
concave, problem (6.19)–(6.22) possesses a unique optimal solution. Of
course, similar remarks apply to problem (6.16)–(6.18) as well. Moreover,
under small perturbations of the nonanticipativity constraints (6.22) it
remains feasible, and hence by Proposition 39 (iii) we have that the dual of
(6.19)–(6.22) has a nonempty and bounded set of optimal solutions and there
is no duality gap between these problems. In the present case we will be able to
write these optimal solutions explicitly.
Suppose that a ‘friend’ with inside information oﬀers us ‘protection’ against
the uncertainty inherent in betting on horses. He oﬀers to provide us with a
table of payments k
i , k, i ¼ 1, . . . , n, such that in the event that horse k wins
we shall pay him the amount k
i xi for each horse i, proportionally to the
amount xi bet on this horse. The payments k
i can be negative (in which case
he pays us), and in fact
X
N
k¼1
pkk
i ¼ 0,
i ¼ 1, . . . , n,
ð6:23Þ
so that the expected cost of the deal is zero. If we shall enter the deal, he will
tell us which horse is going to win.
Ch. 2. Optimality and Duality in Stochastic Programming
109

It is intuitively clear that getting such information at the average cost zero
should give us a certain advantage. And, indeed, in that case we could
optimize our behavior by solving for k ¼ 1, . . . , K the problems
Max
xk
A
xk
k
xk
k þ sk


 ðkÞTx k
ð6:24Þ
s:t:
X
n
i¼1
xk
i ¼ b,
ð6:25Þ
xk  0:
ð6:26Þ
The expectation of the optimal values of the above problems (6.24)–(6.26)
represents the value of the dual problem for the agreed choice of the costs
(i.e., multipliers) k
i . Consequently, by the weak duality we have that this
expectation is always greater than or equal to the optimal value of the
problem (6.16)–(6.18). That is, in such a deal we expect on average to gain an
additional nonnegative amount of money. In particular, if all k
i are zeros, i.e.,
the information is given to us free of charge, then the expected value of our
additional gain is equal to the expected value of perfect information (see
Chapter 1 for a discussion of EVPI).
Suppose now that our ‘friend’ makes his own optimization by choosing k
i
to minimize our expected gain. Thus he minimizes the dual value subject to the
constraints (6.23), i.e., the multipliers k
i form an optimal solution of the dual
problem. It turns out that in this case the deal will not help us at all. Since in
the present example there is no duality gap between the optimal values of the
primal and dual problems, for the optimal choice of k
i the expected value of
the additional gain is zero, and the optimal solution of the original problem
(6.16)–(6.18) provides the optimal solution of every problem (6.24)–(6.26),
k ¼ 1, . . . , n, of the well-informed. By the strict concavity, the opposite is true,
too: the optimal solutions of (6.24)–(6.26), k ¼ 1, . . . , n, form the optimal
solution of (6.16)–(6.18).
In other words, knowing the winning horse is not harmful, so the expected
optimal value of problems (6.24)–(6.26), in view of (6.23), is at least as good as
the optimal value of our original problem. If the multipliers k
i are chosen in
the optimal way, these values become equal, and this is the essence of duality
in this case.
We can ﬁnd the optimal solution ^x and the payment table  by the
following argument. Denoting by 
 the multiplier associated with the budget
constraint (6.17), we see that the optimal solution has the form
^xi ¼ max 0,
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Apisi=
p
 si


,
i ¼ 1, . . . , n:
110
A. Ruszczyn´ski and A. Shapiro

Ordering
the
horses
(and
scenarios)
in
such
a
way
that
p1=s1 
p2=s2  . . .  pn=sn we see that there must exist l such that
^xi ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Apisi=
p
 si,
i ¼ 1, . . . , l,
0,
otherwise:
	
Since the budget b must be used, we can ﬁnd l as the smallest integer for
which
ﬃﬃﬃﬃpl
sl
r
>
Pl
i¼1
ﬃﬃﬃﬃﬃﬃﬃ
pisi
p
b þ Pl
i¼1 si

ﬃﬃﬃﬃﬃﬃﬃﬃ
plþ1
slþ1
r
:
Note that the left inequality holds for l ¼ 1. If such an integer does not
exist, we set l ¼ n. In any case

 ¼
A Pl
i¼1
ﬃﬃﬃﬃﬃﬃﬃ
pisi
p

2
b þ Pl
i¼1 si

2
We leave to the reader the elementary manipulations that support these
results. Then we get
k
i ¼

if i 6¼ k,

 þ 
=pk
if i ¼ k:
	
It turns out that the (optimal) payment table k
i has a very special form.
Our friend pays us up front the amount 
b. We have to bet the amount b the
way we wish. In return we promise to pay him 
xk	=pk	, where k* is the
winning horse. If we enter this deal, he will tell us what k* will be. It will not
help us at all. Our bets will be the same as if we did not know it.
Let us consider now the general case where the probability space  is not
necessarily ﬁnite. Recall that the constraint x 2 X can be absorbed into the
objective function, and hence problem (4.1) can be written in form (4.2).
Problem (4.2), in turn, can be formulated in the following equivalent form
MinxðÞ2M, z2Rn E Fðxð!Þ, !Þ

,
subject to
xð!Þ ¼ z, a:e: ! 2 :
ð6:27Þ
Since, in fact, optimization in the above problem is performed over
constant mappings xð!Þ, the set M can be any space of measurable mappings
x:  ! Rn such that the expectation in (6.27) is well deﬁned. The choice of
Ch. 2. Optimality and Duality in Stochastic Programming
111

the space M aﬀects, however, the corresponding duality relations. It appears
natural to take M to be the space of all measurable mappings xð!Þ.
Unfortunately, this may create problems with the deﬁnition of the expectation
of the functions Fðxð!Þ, !Þ and ð!ÞTxð!Þ. Therefore, it is convenient to
restrict the space M to essentially bounded15 mappings. That is, we
assume that M :¼ Ln
1ð, F, PÞ, where Ln
1ð, F, PÞ is the linear space of
essentially bounded measurable mappings x:  ! Rn. We assume in the
subsequent analysis that the expectation E ½Fðxð!Þ, !Þ is well deﬁned for all
xðÞ 2 Ln
1ð, F, PÞ. Note that if xðÞ 2 Ln
1ð, F, PÞ and16 ðÞ 2 Ln
1ð, F, PÞ,
then E ½ð!ÞTxð!Þ is well deﬁned and ﬁnite. When it will not cause a confusion
we will use subsequently the shortened notation Ln
1 ¼ Ln
1ð, F, PÞ and
Ln
1 ¼ Ln
1ð, F, PÞ:
With problem (6.27) is associated the Lagrangian
Lðx, z, Þ :¼ E Fðxð!Þ, !Þ þ ð!ÞTðxð!Þ  zÞ


,
ð6:28Þ
where ðx, zÞ 2 Ln
1  Rn and  2 Ln
1. By minimizing this Lagrangian with
respect to xðÞ and z and maximizing with respect to ðÞ we obtain the
following dual of the problem (6.27):
MaxðÞ2Ln
1
infx2Ln
1E ½Fðxð!Þ, !Þ þ ð!ÞTxð!Þ


,
subject to
E ½ð!Þ ¼ 0:
ð6:29Þ
We have that a point ðx, z, Þ 2 Ln
1  Rn  Ln
1 is a saddle point of the
Lagrangian iﬀ
xð!Þ ¼ z, a:e: ! 2 ,
and
E ð!Þ


¼ 0,
ð6:30Þ
and
x 2 arg min E½Fðxð!Þ, !Þ þ ð!ÞTxð!Þ: x 2 Ln
1


:
ð6:31Þ
Let us observe that condition (6.31) can be equivalently expressed as
z 2 arg min Fðz, !Þ þ ð!ÞTz: z 2 Rn


,
a:e: ! 2 :
ð6:32Þ
15 A function xð!Þ is called essentially bounded if there exists a constant c such that jjxð!Þjj  c for a.e.
! 2 .
16 Ln
1ð, F, PÞ
denotes
the
linear
space
of
measurable
mappings
y:  ! Rn
such
that
R
 jjyð!Þjj dPð!Þ < þ1.
112
A. Ruszczyn´ski and A. Shapiro

Indeed, for a constant w.p.1 mapping xð!Þ:z, condition (6.31) is satisﬁed
iﬀfor any x ðÞ 2 Ln
1 the inequality
Fðxð!Þ, !Þ þ ð!ÞTxð!Þ  Fðz, !Þ þ ð!ÞTz
holds w.p.1. This, in turn, is equivalent to (6.32).
Since Fð, !Þ is convex w.p.1, condition (6.32) is equivalent to
ð!Þ 2 @Fðz, !Þ,
a:e: ! 2 :
ð6:33Þ
Therefore, we obtain that a point ðx, z, Þ 2 Ln
1  Rn  Ln
1 is a saddle point
of the Lagrangian iﬀconditions (6.30) and (6.33) hold. Suppose, further, that
the function Fðx, !Þ is random lower semicontinuous, and hence the
expectation
E½@Fðz, !Þ ¼
Z

@Fðz, !Þ dPð!Þ
is well deﬁned. Then, by the deﬁnition of the integral of a multifunction, (6.33)
and the second equation of (6.30) imply that
0 2 E½@Fðz, !Þ:
ð6:34Þ
Conversely, if (6.34) holds, then there exists  2 Ln
1 satisfying (6.33) and
(6.30). Therefore, the Lagrangian, given in (6.28), has a saddle point iﬀthere
exists z 2 Rn satisfying condition (6.34). We can formulate this results in the
following form.
Proposition 42. Suppose that the set X is convex, for a.e. ! 2  the function
Fð, !Þ is convex, and the function Fðx, !Þ is random lower semicontinuous. Then
there is no duality gap between problems (4.1) and (6.29) and both problems have
optimal solutions if and only if there exists z 2 Rn satisfying condition (6.34).
Recall that the inclusion E ½@Fðz, !Þ  @f ðzÞ always holds. Therefore,
condition (6.34) implies that 0 2 @f ðzÞ, and hence z is an optimal solution of
(4.1). Conversely, if z is an optimal solution of (4.1), then 0 2 @f ðzÞ, and hence
if in addition E ½@Fðz, !Þ ¼ @f ðzÞ, then (6.34) follows. Therefore, Theorem 9
and Proposition 42 imply the following result.
Theorem
43. Suppose
that:
(i)
the
function
Fðx, !Þ
is
random
lower
semicontinuous, (ii) for a.e. ! 2  the function Fð, !Þ is convex, (iii) the set
X is convex, (iv) problem (4.1) possesses an optimal solution x0 such that
x0 2 intðdom f Þ. Then there is no duality gap between problems (4.1) and (6.29),
Ch. 2. Optimality and Duality in Stochastic Programming
113

the dual problem (6.29) has an optimal solution , and the constant mapping
xð!Þ:x0 is an optimal solution of the problem
Min
xðÞ2Ln
1
E Fðxð!Þ, !Þ þ ð!ÞTxð!Þ


:
ð6:35Þ
Proof. Since x0 is an optimal solution of (4.1) we have that x0 2 X and f ðx0Þ
is ﬁnite. Moreover, since x0 2 intðdom f Þ and f is convex, it follows
that f is proper and Ndom f ðx0Þ ¼ f0g. Therefore, it follows by Theorem 9
that @f ðx0Þ ¼ E @Fðx0, !Þ
½
. Furthermore, since x0 2 intðdom f Þ we have that
@f ðx0Þ ¼ @f ðx0Þ þ NXðx0Þ. Consequently, 0 2 E @Fðx0, !Þ


, and hence the
assertions follow by Proposition 42.
u
It is also possible to investigate dual problems (4.1) and (6.29) in the
framework of conjugate duality. However, since we deal here with inﬁnite
dimensional spaces like Ln
1ð, F, PÞ, this would require an application of
functional analysis which will go beyond the scope of this book.
One can note again the separable structure of the problem (6.35). For each
! 2 ,
inf
x2Rn Fðx, !Þ þ Tx

 ¼ F*ð, !Þ,
where F*ð, !Þ is the conjugate of the function Fð, !Þ. For a given
 2 Ln
1ð, F, PÞ, denote by M ¼ Mð, F, RnÞ the space of all measurable
mappings x:  ! Rn such that the expectation E ½Fðxð!Þ, !Þ þ ð!ÞTxð!Þ is
well deﬁned. By Proposition 5 of Chapter 1, the inﬁmum with respect to
x 2 Mð, F, RnÞ can be taken inside the expected value, that is
inf
xðÞ2M E Fðxð!Þ, !Þ þ ð!ÞTxð!Þ


¼ E F*ðð!Þ, !Þ


,
ð6:36Þ
provided that Fðx, !Þ (and hence Fðx, !Þ) is random lower semicontinuous
and the expectation of the minimal value is well deﬁned. The space
Mð, F, RnÞ in the optimization problem at the left hand side of (6.36)
can be replaced by, possibly smaller, space Ln
1ð, F, RnÞ if this optimization
problem has an optimal (nearly optimal) solution which is essentially
bounded. This happens, for example, if the set X is bounded. In that case
the dual problem (6.29) can be written in the form
MaxðÞ2Ln
1 E F*ðð!Þ, !Þ

,
subject to
E½ð!Þ ¼ 0:
ð6:37Þ
114
A. Ruszczyn´ski and A. Shapiro

7
Duality for multistage stochastic programs
Let us consider again the multistage stochastic programming problem (3.2).
Unless stated otherwise we assume in this section that the distribution of  has
a ﬁnite support and the functions ftð, Þ are random polyhedral, i.e., the
problem (3.2) is polyhedral.
The ﬁrst approach introduces Lagrange multipliers t, t ¼ 1, . . . , T,
associated with the constraints of (3.2) and the Lagrangian
Lðx, Þ :¼ E
X
T
t¼1
h
ftðxt, tÞ þ T
t ðbtðtÞ  AttðtÞxt  At, t1ðtÞxt1Þ
i
(
)
¼ E
X
T
t¼1
h
ftðxt, tÞT
t AttðtÞxtT
tþ1Atþ1, tðtþ1ÞxtþT
t btðtÞ
i
(
)
,
ð7:1Þ
with the convention that x0 ¼ 0 and the terms involving T þ 1 are zeros. The
multipliers t, similarly to the decisions xt, may depend on ½1, t, but not on
tþ1, . . . , T. That is, xt ¼ xtð½1, tÞ and t ¼ tð½1, tÞ are viewed as functions of
½1, t.
The dual functional is deﬁned as
DðÞ :¼ inf
x2M E Lðx, Þ
½
,
ð7:2Þ
where M is an appropriate functional space of allowable mappings
xðÞ ¼ ðx1ðÞ, . . . , xTðÞÞ. Since, for given , the Lagrangian Lð, Þ is separable
in xtðÞ, we can move the operation of minimization with respect to xt under
the conditional expectation Eðj½1, tÞ (see Proposition 5 of Chapter 1).
Therefore, we obtain
DðÞ ¼ E
X
T
t¼1
inf
xt2Rnt ftðxt, tÞT
t AttðtÞxtE T
tþ1Atþ1, tðtþ1Þj½1, t

xt


(
)
þ E
X
T
t¼1
T
t btðtÞ
(
)
:
It follows that
DðÞ ¼ E
X
T
t¼1
Dtðt, tþ1, ½1, tÞ
(
)
þ E
X
T
t¼1
T
t btðtÞ
(
)
,
Ch. 2. Optimality and Duality in Stochastic Programming
115

where
Dtðt, tþ1, ½1, tÞ :¼ inf
xt2Rnt ftðxt, tÞ  T
t AttðtÞ


þE T
tþ1Atþ1, tðtþ1Þj½1, t


xt

:
ð7:3Þ
The dual problem has the form
Max

DðÞ,
ð7:4Þ
where the maximization is performed over such tðÞ which depend only on
½1, t, t ¼ 1, . . . , T.
Since we assume here that there is a ﬁnite number of scenarios, the
allowable mappings xtðÞ and tðÞ can be identiﬁed with ﬁnite dimensional
vectors. Moreover, since we deal with the polyhedral case, both primal and
dual problems can be written as large linear programming problems.
Therefore, the following duality result is a consequence of the general theory
of linear programming.
Theorem 44. The optimal values of problems (3.2) and (7.4) are equal unless
both problems are infeasible. If the (common) optimal value of these problems is
ﬁnite, then both problems have optimal solutions.
If the functions ftð, tÞ are convex (not necessarily polyhedral), a constraint
qualiﬁcation like (4.3) is needed to ensure that there is no duality gap between
problems (3.2) and (7.4).
The form of the dual problem is particularly simple in the case of the linear
multistage problem (3.1). Indeed, let
ftðxt, tÞ :¼
cT
t ðtÞxt,
if xt  0,
þ1,
otherwise:
(
Then the inﬁmum in (7.3) is 1, unless
AttðtÞTt þ E Atþ1, tðtþ1ÞTtþ1j½1, t


 ctðtÞ,
116
A. Ruszczyn´ski and A. Shapiro

in which case the inﬁmum is zero. Thus the dual problem (7.4) takes on the
form
Max

E
X
T
t¼1
btðtÞTt
"
#
s:t:
AttðtÞTtþE Atþ1, tðtþ1ÞTtþ1j½1, t


ctðtÞ,
t¼1, . . . , T, ð7:5Þ
where for the uniformity of notation we set all ‘T þ 1 terms’ equal to 0. The
multipliers t in problem (7.5) are restricted to depend only on ½1, t, that is,
they have to form a dual implementable policy.
For the dual problem (7.5) we can develop dynamic programming
equations, similarly to the primal problem (3.2). Let us consider the problem
Max
t,..., T E
X
T
¼t
bT
 ðÞj½1, t
"
#
s:t: AðÞTþE Aþ1, ðþ1ÞTþ1j½1, 


ctðÞ,  ¼ t1, . . . , T,
ð7:6Þ
In this problem, the values of t1 and of ½1, t are assumed to be known.
We denote the optimal value of this problem by Stðt1, ½1, tÞ. These values
are related for t ¼ 1, . . . , T through the dual dynamic programming equation:
Stðt1, ½1, tÞ is equal to the optimal value of the following problem
Maxt btðtÞTt þ E Stþ1ðt, ½1, tþ1Þj½1, t


s:t:
At1, t1ðt1ÞTt1 þ E At, t1ðtÞTtj½1, t1


 ct1ðt1Þ,
ð7:7Þ
where, for the uniformity of the notation, we assume that all terms involving
t ¼ 0 are zero.
There is a duality relation between the primal cost-to-go functions
Qtðxt1, ½1, tÞ, deﬁned in (3.3), and their dual counterparts Stðt1, ½1, tÞ.
Theorem 45. A feasible policy ^xtð½1, tÞ, t ¼ 1, . . . , T, is optimal for (3.1) and a
dual feasible policy ^tð½1, tÞ, t ¼ 1, . . . , T, is optimal for (7.5) if and only if for
every realization of  the following holds
Qt ^xt1ð½1, t1Þ, ½1, t

 ¼ St ^t1ð½1, t1Þ, ½1, t

,
t ¼ 1, . . . , T:
There is another group of duality relations for multistage stochastic
programs, associated with the nonaticipativity constraints.
Let us consider problem (3.2) again, but let us assume now that each
decision xt may depend on all random data, . Since  has ﬁnitely many
Ch. 2. Optimality and Duality in Stochastic Programming
117

realizations, k, k ¼ 1, . . . , K (attained with probabilities p1, . . . , pK), we may
model our assumption by assigning a decision sequence,
xk ¼ ðxk
1, . . . , xk
TÞ,
to the k-th realization of .17 The problem takes on the form
Min P
K
k¼1
pk
h
f1ðxk
1,k
1Þþf2ðxk
2,k
2Þþf3ðxk
3,k
3Þþ... þ fTðxk
T,k
TÞ
i
s:t:
A11ðk
1Þxk
1
¼ b1ðk
1Þ,
A21ðk
2Þxk
1 þA22ðk
2Þxk
2
¼ b2ðk
2Þ,
A32ðk
3Þxk
2 þA33ðk
3Þxk
3
¼ b3ðk
3Þ,
.................................................................
AT,T1ðk
TÞxk
T1 þATTðk
TÞxk
T
¼ bTðk
TÞ,
k ¼ 1,...,K:
ð7:8Þ
Although similar in appearance, this formulation is not equivalent to the
original problem (3.2), unless we introduce additional constraints that limit
the dependence of xt on  to the information that is available up to time t. As
discussed in Chapter 1, these conditions take the form of nonanticipativity
constraints,
xk
t ¼ xj
t for all k, j for which k
½1, t ¼ j
½1, t,
t ¼ 1, . . . , T:
ð7:9Þ
This allows us to write problem (7.8)–(7.9) in a more abstract way. Deﬁne
f kðxkÞ ¼
PT
t¼1 ftðxk
t , k
t Þ,
if the constraints of ð7:8Þ are satisfied
for scenario k,
þ1
otherwise:
8
<
:
Also, let W be the set of policies satisfying the nonanticipativity constraints
(7.9). We see that W is a linear subspace of the set of all policies. The problem
can be now written in a lucid form
Min f ðxÞ :¼
X
K
k¼1
pk f kðxkÞ
(
)
s:t:
x 2 W:
ð7:10Þ
17 To avoid collisions of subscripts we slightly change our notation and use superscripts to denote
realizations (scenarios).
118
A. Ruszczyn´ski and A. Shapiro

Clearly, f is a polyhedral function, so if this problem has a solution, the
optimality conditions and duality relations hold. Let us introduce the
Lagrangian associated with (7.10):
Lðx, Þ :¼ f ðxÞ þ , x
h
i:
ð7:11Þ
The scalar product , x
h
i is understood in the usual way, as
, x
h
i :¼
X
k
k¼1
X
T
t¼1
k
t , xk
t


:
Theorem 46. A policy ^x 2 W is an optimal solution of (7.10) if and only if there
exist multipliers ^l 2 W? such that
^x 2 arg min
x
Lðx, ^lÞ:
ð7:12Þ
Proof. The result follows from Proposition 32. Indeed, NWðxÞ ¼ W? for all
x 2 W. Denoting by ^l the element of NWð ^xÞ that appears in the optimality
conditions, we get
0 2 @Lð ^x, ^lÞ:
ð7:13Þ
Since W is a linear space, this is necessary and suﬃcient for (7.12).
u
Also, we can deﬁne the dual function
DðÞ :¼ min
x Lðx, Þ,
and the dual problem
Max
2W? DðÞ:
ð7:14Þ
Theorem 47. The optimal values of problems (7.10) and (7.14) are equal unless
both problems are infeasible. If their (common) optimal value is ﬁnite, then both
problems have optimal solutions.
The crucial role in our approach is played by the requirement that  2 W?.
Let us decipher this condition. For
 ¼ k
t


t¼1,..., T, k¼1,..., K
Ch. 2. Optimality and Duality in Stochastic Programming
119

the condition  2 W? is equivalent to
X
k
k¼1
X
T
t¼1
k
t , xk
t


¼ 0
for all x 2 W:
Substituting
k ¼ k=pk,
k ¼ 1, . . . , K,
we can write the last relation in a more abstract form as
E
X
T
t¼1
t, xt
h
i
"
#
¼ 0,
for all x 2 W:
ð7:15Þ
Since18 Etxt ¼ xt for all x 2 W, we obtain from (7.15) that
E
X
T
t¼1
Ett, xt
h
i
"
#
¼ 0,
for all x 2 W,
which is equivalent to
Ett ¼ 0,
t ¼ 1, . . . , T:
ð7:16Þ
We can now rewrite our necessary conditions of optimality and duality
relations in a more explicit form. Let us re-deﬁne the Lagrangian (with a slight
abuse of notation)
Lðx, Þ ¼ f ðxÞ þ E
X
T
t¼1
t, xt
h
i
"
#
,
the dual functional
DðÞ ¼ min
x
Lðx, Þ,
18 In order to simplify notation we denote in the remainder of this section by Et the conditional
expectation conditional on ½1, t.
120
A. Ruszczyn´ski and A. Shapiro

and the dual problem
Max DðÞ
s:t:
Ett ¼ 0,
t ¼ 1, . . . , T:
ð7:17Þ
Corollary 48. A policy ^x 2 W is an optimal solution of (7.10) if and only if there
exist multipliers ^ satisfying (7.16) such that
^x 2 arg min
x Lðx, ^Þ:
ð7:18Þ
Moreover, problem (7.10) has an optimal solution if and only if problem (7.17)
has an optimal solution. The optimal values of these problems are equal unless
both are infeasible.
An equivalent approach to formulating the dual problem is to use algebraic
expressions for the nonanticipativity constraints (7.9) and incorporate them
(with the corresponding multipliers) into the Lagrangian. For example, if we
write (7.9) as
Etxt ¼ xt,
t ¼ 1, . . . , T,
we may formulate the Lagrangian
Lðx, Þ ¼ f ðxÞ þ E
X
T
t¼1
t, xt  Etxt
h
i
"
#
,
the dual functional
DðÞ ¼ min
x Lðx, Þ,
and the dual problem
Max DðÞ:
ð7:19Þ
There are no constraints on  in this dual problem. Since f is polyhedral
and the nonanticipativity conditions linear, Kuhn–Tucker optimality condi-
tions and duality relations hold for this formulation, similarly to Corollary 48,
but without additional constraints on  of form (7.16). However, these
constraints may be included into the dual problem without any loss of
optimality. To prove that, let us consider any dual solution  and deﬁne
t ¼ t  Ett,
t ¼ 1, . . . , T:
Ch. 2. Optimality and Duality in Stochastic Programming
121

Clearly, it satisﬁes (7.16). Now, for any x we have
Lðx, Þ  Lðx, Þ ¼ E
X
T
t¼1
Ett, xt  Etxt
h
i
"
#
¼
X
T
t¼1
E Ett, xt
h
i  E Ett, Etxt
h
i
ð
Þ ¼ 0:
Consequently, @Lðx, Þ ¼ @Lðx, Þ, DðÞ ¼ DðÞ, so  can be substituted
for  in the optimality conditions and duality relations.
There are many diﬀerent ways to express the nonanticipativity constraints
(7.9), and thus there are many equivalent ways to formulate the Lagrangian
and the dual problem. Some of them may be more convenient for some
computational methods, other may be more suitable for other methods. We
shall return to these issues in the sections devoted to numerical methods for
solving stochastic programming problems.
8
Min–max stochastic optimization
In practical applications the required probability distributions are either
estimated from available historical data or assigned by a subjective judgment.
Consequently, these distributions are never known exactly and to some extent
are also uncertain. We already brieﬂy discussed that problem in Section 4 of
Chapter 1. In order to deal with the distribution uncertainty one can
formulate the following min–max analogue of problem (4.1):
Min
x2X Max

2S E
½Fðx, !Þ:
ð8:1Þ
Here S is a given set of probability measures (distributions), deﬁned on a
sample space ð, FÞ, and the notation E
 means that the expectation is taken
with respect to measure 
 2 S. Of course, if S :¼ fPg is a singleton, then the
above problem (8.1) coincides with problem (4.1). In this section we discuss
some basic properties of the min–max problem (8.1).
We assume that the sets X and S are nonempty, and that for every x 2 X
and 
 2 S, the expectation ðx, 
Þ :¼ E
½Fðx, !Þ is well deﬁned. Interchanging
the order of Min and Max operators, we obtain the following dual of the
problem (8.1):
Max

2S Min
x2X E
½Fðx, !Þ:
ð8:2Þ
122
A. Ruszczyn´ski and A. Shapiro

By the general theory of min–max duality we have that the optimal value of
(8.1) is always greater than or equal to the optimal value of (8.2).
The function ðx, 
Þ is linear in 
. Therefore, the max-value of
problem (8.1) is not changed if the set S is substituted by its convex hull
S* :¼ convðSÞ. This substitution may eﬀect, however, the optimal value of
problem (8.2). We assume throughout this section that the set X is convex
and for every ! 2 , the function Fð, !Þ is convex. This implies, of course,
that the expectation function ð, 
Þ is also convex for any 
 2 S. In order to
get a better insight into the problem let us discuss the following particular
cases.
Suppose that the set S is ﬁnite, say S :¼ fP1, . . . , Plg. We already brieﬂy
discussed that case in Section 4 of Chapter 1. Suppose also, for the sake of
simplicity, that the functions fiðxÞ :¼ EPi½Fðx, !Þ, i ¼ 1, . . . , l, are real valued
for all x 2 Rn. By the convexity assumption we have that these functions are
convex. Then the max-function
f0ðxÞ :¼
max
i2f1,..., lg fiðxÞ
is also real valued and convex. Since functions fi, i ¼ 0, . . . , l, are real valued
and convex, these functions are continuous and subdiﬀerentiable on Rn. We
have the following formula for the subdiﬀerential of the max-function (see
Theorem 51 in the Appendix)
@f0ðxÞ ¼ conv [i2IðxÞ@fiðxÞ

,
ð8:3Þ
where
IðxÞ :¼ i: f0ðxÞ ¼ fiðxÞ, i ¼ 1, . . . , l


is the set of active at x functions. By the optimality condition (4.5) we have19
that a point x 2 X is an optimal solution of the corresponding min–max
problem (8.1) iﬀthere exist nonnegative multipliers i, i 2 IðxÞ, such that
P
i2Ið x Þ i ¼ 1 and
0 2
X
i2Ið x Þ
i@fiðxÞ þ NXðxÞ:
ð8:4Þ
19 Since it is assumed here that the function f ðxÞ is real valued, and hence its domain is Rn, constraint
qualiﬁcation (4.4) holds automatically.
Ch. 2. Optimality and Duality in Stochastic Programming
123

By the Moreau–Rockafellar Theorem we also have that
X
i2Ið x Þ
i@fiðxÞ ¼ @
X
i2IðxÞ
i fiðxÞ
 
!
:
Therefore, x is an optimal solution of the problem
Min
x2X Ep*½Fðx, !Þ,
ð8:5Þ
where P* :¼ P
i2IðxÞ iPi: It also follows that ðx, P*Þ is a saddle point of the
corresponding min–max problem with the set S replaced by its convex hull
S* :¼ convðSÞ. We have here that there is no duality gap20 between problem
(8.1) and its dual
Max

2S* Min
x2X E
½Fðx, !Þ,
ð8:6Þ
and the set of optimal solutions of the dual problem (8.6) is nonempty. Note
that the optimal value of problem (8.2) can be smaller that the optimal value
of (8.6), and therefore it is essential here that the (ﬁnite) set S is replaced in
(8.6) by its convex hull S*.
Suppose now that the set  ¼ f!1, . . . , !Kg is ﬁnite. Then a probability
measure (distribution) on  is deﬁned by a vector P ¼ ð p1, . . . , pKÞ 2 RK
þ
such that PK
k¼1 pk ¼ 1. Let S  RK
þ be a set of such vectors. Then the
corresponding min–max problem can be written as
Min
x2X
f0ðxÞ :¼ sup
P2S
X
K
k¼1
pkFðx, !kÞ
(
)
:
ð8:7Þ
Suppose that the set S is convex and compact, the set X is convex and the
functions Fð, !kÞ are convex real valued. We have then that the max-function
f0ðxÞ is convex real valued, and by Theorem 51,
@f0ðxÞ ¼ conv
[
P2S0ðxÞ
X
K
k¼1
pk@Fðx, !kÞ
 
!
(
)
,
ð8:8Þ
20 The above derivations are based on existence of an optimal solution of (8.1). In the present case,
however, this is not essential for the ‘‘no duality gap’’ property to hold, which can be proved directly,
for example, by using the conjugate duality approach.
124
A. Ruszczyn´ski and A. Shapiro

where
S0ðxÞ :¼ arg max
P2S
X
K
k¼1
pkFðx, !kÞ:
Note that the set S0ðxÞ is convex, nonempty and compact since the set S is
convex, nonempty and compact.
By the optimality condition (4.5) together with formula (8.8) we obtain that
ðx, P*Þ is a saddle point of the corresponding min–max problem iﬀx 2 X,
P* 2 S0ðxÞ and
0 2 @ EP	½Fðx, !Þ
ð
Þ þ NXðxÞ:
ð8:9Þ
We also have that a point x 2 X is an optimal solution of problem (8.7) iﬀ
there exists P* 2 S0ðxÞ such that (8.9) holds. Therefore, if problem (8.7) has an
optimal solution, then its dual problem also has an optimal solution P*, there
is no duality gap between (8.7) and its dual, and the set of optimal solutions of
(8.7) coincides with the set of optimal solutions of the corresponding problem
(8.5).
The above analysis can be extended to the following general case of
a metric space  and its Borel sigma algebra B. Denote S0ðxÞ :¼
arg max
2SE
½Fðx, !Þ.
Theorem 49. Let  be a metric space equipped with its Borel sigma algebra B, X
be a nonempty convex subset of Rn and S be a nonempty convex set of
probability measures on ð, BÞ. Suppose that  is compact, for every x 2 Rn the
function Fðx, Þ is continuous on , and for every ! 2  the function Fð, !Þ is
real valued and convex on Rn. Then there is no duality gap between problem (8.1)
and its dual (8.2). Suppose, further, that the set S is closed in the weak topology
of the space of probability measures on ð, BÞ, and the optimal value of problem
(8.1) is ﬁnite. Then the dual problem (8.2) has a nonempty set of optimal
solutions, and a point x 2 X is an optimal solution of (8.1) if and only if there
exists P* 2 S0ðxÞ such that x is an optimal solution of problem (8.5).
Proof. We outline a proof in the case where problem (8.1) has an optimal
solution. Since Fðx, Þ is continuous and  is compact, the expectation
E
½Fðx, !Þ is well deﬁned for any ðx, 
Þ 2 Rn  S. Let us equip S with the
weak topology and consider function ðx, 
Þ :¼ E
½Fðx, !Þ. We have that for
any 
 2 S the function ð, 
Þ is convex and for any x 2 Rn the function ðx, Þ
is continuous on S. Since  is compact, we have by Prohorov’s theorem that
the topological closure of S is compact. We can assume that S is closed and
therefore is compact. It follows that the max-function f0ðxÞ :¼ sup
2Sðx, 
Þ is
Ch. 2. Optimality and Duality in Stochastic Programming
125

convex real valued. Let x be an optimal solution of problem (8.1). By
Theorem 51 (from the Appendix) we have that
@f0ðxÞ ¼ conv
[

2S0ð x Þ
@ðx, 
Þ
 
!
:
ð8:10Þ
This implies existence of a saddle point ðx, P*Þ, and hence the assertions of
the theorem follow.
u
Suppose now that the set S is deﬁned as the set of probability measures 
on ð, BÞ satisfying the constraints
E
½ jð!Þ ¼ bj,
j ¼ 1, . . . , m:
ð8:11Þ
Here  1ð!Þ, . . . ,  mð!Þ are real valued measurable functions on ð, BÞ and
b1, . . . , bm are given numbers. Then the problem
Max

2S E
½Fðx, !Þ
ð8:12Þ
is called the problem of moments. By Theorem 60 (from the Appendix) we have
that it suﬃces to perform optimization in the above problem (8.12) over
probability measures with a ﬁnite support of at most s ¼ m þ 1 points. That
is, problem (8.12) is equivalent to the problem
Max
X
s
i¼1
piFðx, !iÞ
s:t:
X
s
i¼1
pi jð!iÞ ¼ bi,
j ¼ 1, . . . , m,
X
s
i¼1
pi ¼ 1, pi  0,
i ¼ 1, . . . , s,
ð8:13Þ
where
the
maximum
is
taken
with
respect
to
P ¼ ð p1, . . . , psÞ
and
!1, . . . , !s 2 .
9
Appendix
9.1
Differentiability and convex analysis
Consider a mapping g: Rn ! Rm. It is said that g is directionally dif-
ferentiable at a point x0 2 Rn in a direction h 2 Rn if the limit
126
A. Ruszczyn´ski and A. Shapiro

g0ðx0, hÞ :¼ lim
t#0
gðx0 þ thÞ  gðx0Þ
t
ð9:1Þ
exists, in which case g0ðx0, hÞ is called the directional derivative of gðxÞ at x0
in the direction h. If g is directionally diﬀerentiable at x0 in every
direction h 2 Rn, then it is said that g is directionally diﬀerentiable at x0.
Note that whenever exists, g0ðx0, hÞ is positively homogeneous in h, i.e.,
g0ðx0, thÞ ¼ tg0ðx0, hÞ for any t  0. If gðxÞ is directionally diﬀerentiable at x0
and g0ðx0, hÞ is linear in h, then it is said that gðxÞ is Gaˆ teux diﬀerentiable at x0.
(9.1) can be also written in the form
gðx0 þ hÞ ¼ gðx0Þ þ g0ðx0, hÞ þ rðhÞ,
ð9:2Þ
where the remainder term r(h) is such that rðthÞ=t ! 0, as t # 0, for any ﬁxed
h 2 Rn. If, moreover, g0ðx0, hÞ is linear in h and the remainder term rðhÞ
is ‘uniformly small’ in the sense that rðhÞ=khk ! 0 as h ! 0, then it is said
that gðxÞ is diﬀerentiable at x0 in the sense of Fre´ chet, or simply diﬀerentiable
at x0.
Clearly Fre´ chet diﬀerentiability implies Gaˆ teux diﬀerentiability. The
converse of that is not necessarily true. However, for locally Lipschitz
continuous mappings both concepts do coincide. That is, if g(x) is Lipschitz
continuous in a neighborhood of x0 and directionally diﬀerentiable at x0,
then g(x) is directionally diﬀerentiable at x0 in the sense of Fre´ chet and
g0ðx0, Þ is Lipschitz continuous on Rn. Recall that gðxÞ is said to be Lipschitz
continuous on a set X  Rn if there is a positive constant c such that
jjgðx1Þ  gðx2Þjj  cjjx1  x2jj for all x1, x2 2 X.
Let C be a subset of Rn. It is said that x 2 Rn is an interior point of C
if there is a neighborhood N of x such that N  C. The set of interior points
of C is denoted intðC Þ. The convex hull of C, denoted convðCÞ, is the
smallest convex set including C. It is said that C is a cone if for any
x 2 C and t  0 it follows that tx 2 C. The polar cone of a cone C  Rn is
deﬁned as
C* :¼ z 2 Rn : zTx  0, 8 x 2 C


:
ð9:3Þ
We have that the polar of the polar cone C** ¼ ðC*Þ* is equal to the
topological closure of the convex hull of C, and that C** ¼ C iﬀthe cone C is
convex and closed.
Let C be a convex subset of Rn. The aﬃne space generated by C is the space
of points in Rn of the form tx þ ð1  tÞy, where x, y 2 C and t 2 R. It is said
that a point x 2 Rn belongs to the relative interior of the set C if x is an interior
point of C relative to the aﬃne space generated by C, i.e., there exists a
neighborhood of x such that its intersection with the aﬃne space generated by
Ch. 2. Optimality and Duality in Stochastic Programming
127

C is included in C. The relative interior set of C is denoted riðCÞ. Note that if
the interior of C is nonempty, then the aﬃne space generated by C coincides
with Rn, and hence in that case riðCÞ ¼ intðCÞ. The normal cone to C at a point
x0 2 C is deﬁned as
NCðx0Þ :¼ z: zTðx  x0Þ  0, 8 x 2 C


:
ð9:4Þ
The topological closure of the radial cone RCðx0Þ:¼ [t>0 ft1ðC  x0Þg is
called the tangent cone to C at x0, and denoted TCðx0Þ. Both cones TCðx0Þ and
NCðx0Þ are closed and convex, and each one is the polar cone of the other.
The support function of a set C  Rn is deﬁned as
sðhÞ :¼ sup
z2C
zTh:
ð9:5Þ
The support function sðÞ is convex, positively homogeneous and lower
semicontinuous. If s1ðÞ and s2ðÞ are support functions of convex closed sets
A and B, respectively, then s1ðÞ  s2ðÞ iﬀA  B, and s1ðÞ ¼ s2ðÞ iﬀA ¼ B.
Consider an extended real valued function f : Rn ! R. The domain of f is
deﬁned as dom f :¼ fx 2 Rn : f ðxÞ < þ1g. It is said that f is proper if its
domain is nonempty and f ðxÞ > 1 for all x 2 Rn. It is not diﬃcult to show
that f is convex iﬀits epigraph epi f :¼ fðx, Þ: f ðxÞ  g is a convex subset
of Rnþ1.
Suppose now that f : Rn ! R is a convex function and x0 2 Rn is a point
such that f ðx0Þ is ﬁnite. Then f ðxÞ is directionally diﬀerentiable at x0, its
directional derivative f 0ðx0, Þ is an extended real valued convex positively
homogeneous function and can be written in the form
f 0ðx0, hÞ ¼ inf
t>0
f ðx0 þ thÞ  f ðx0Þ
t
:
ð9:6Þ
Moreover, if x0 is in the interior of the domain of f ðÞ, then f ðxÞ is Lipschitz
continuous in a neighborhood of x0, the directional derivative f 0ðx0, hÞ is ﬁnite
valued for any h 2 Rn, and f ðxÞ is diﬀerentiable at x0 iﬀf 0ðx0, hÞ is linear in h.
It is said that a vector z 2 Rn is a subgradient of f ðxÞ at x0 if
f ðxÞ  f ðx0Þ  zTðx  x0Þ,
8 x 2 Rn:
ð9:7Þ
The set of all subgradients of f ðxÞ, at x0, is called the subdiﬀerential
and denoted @f ðx0Þ. The subdiﬀerential @f ðx0Þ is a closed convex subset of Rn.
It is said that f is subdiﬀerentiable at x0 if @f ðx0Þ is nonempty. If f is
subdiﬀerentiable at x0, then the normal cone Ndom f ðx0Þ, to the domain of f at
128
A. Ruszczyn´ski and A. Shapiro

x0, forms the recession cone of the set @f ðx0Þ. It is also clear that if f is
subdiﬀerentiable at x0, then f ðxÞ > 1 for any x and hence f is proper.
By duality theory of convex analysis we have that if the directional
derivative f 0ðx0, Þ is lower semicontinuous, then
f 0ðx0, hÞ ¼
sup
z2@f ðx0Þ
zTh,
ð9:8Þ
i.e., f 0ðx0, Þ is the support function of the set @f ðx0Þ. In particular, if x0 is an
interior point of the domain of f ðxÞ, then f 0ðx0, Þ is continuous, @f ðx0Þ is
nonempty and compact and (9.8) holds. Conversely, if @f ðx0Þ is nonempty and
compact, then x0 is an interior point of the domain of f ðxÞ. Also f ðxÞ is
diﬀerentiable at x0 iﬀ@f ðx0Þ is a singleton, i.e., contains only one element,
which then coincides with the gradient rf ðx0Þ.
Theorem 50 (Moreau–Rockafellar). Let fi : Rn ! R, i ¼ 1, . . . , m, be proper
convex functions, f ðÞ :¼ f1ðÞ þ . . . þ fmðÞ and x0 be a point such that fiðx0Þ
are ﬁnite, i.e., x0 2 \m
i¼1dom fi Then
@f1ðx0Þ þ    þ @fmðx0Þ  @f ðx0Þ:
ð9:9Þ
Moreover,
@f1ðx0Þ þ    þ @fmðx0Þ ¼ @f ðx0Þ
ð9:10Þ
if any one of the following conditions holds: (i) the set \m
i¼1riðdom fiÞ is
nonempty, (ii) the functions f1, . . . , fk, k  m, are polyhedral and the intersection
of the sets \k
i¼1dom fi and \m
i¼kþ1riðdom fiÞ is nonempty, (iii) there exists a point
x 2 dom fm such that x 2 intðdom fiÞ, i ¼ 1, . . . , m  1.
In particular, if all functions f1, . . . , fm in the above theorem are polyhedral,
then the equation (9.10) holds without an additional regularity condition.
The following result gives a description of subdiﬀerentials of max-
functions. By clðAÞ we denote the topological closure of a set A  Rn.
Theorem 51 (Levin-Valadier). Let U be a compact topological space and
g: Rn  U ! R be a real valued function. Suppose that: (i) for every u 2 U the
function guðÞ ¼ gð, uÞ is convex on Rn, (ii) for every x 2 Rn the function gðx, Þ is
upper semicontinuous on U. Then the max-function f ðxÞ :¼ supu2Ugðx, uÞ is
convex real valued and
@f ðxÞ ¼ cl conv [u2U0ðxÞ@guðxÞ




,
ð9:11Þ
Ch. 2. Optimality and Duality in Stochastic Programming
129

where U0ðxÞ :¼ arg maxu2U gðx, uÞ.
Let us make the following observations regarding the above theorem. Since
U is compact and by the assumption (ii), we have that the set U0ðxÞ is
nonempty and compact. Since the function f ðÞ is convex real valued, it is
subdiﬀerentiable at every x 2 Rn and its subdiﬀerential @f ðxÞ is a convex,
closed bounded subset of Rn. It follows then from (9.11) that the set
A :¼ [u2U0ðxÞ@guðxÞ is bounded. Suppose further that:
(iii) For every x 2 Rn the function gðx, Þ is continuous on U.
Then the set A is closed, and hence is compact. Indeed, consider a sequence
zk 2 A. Then, by the deﬁnition of the set A, zk 2 @gukðxÞ for some sequence
uk 2 U0ðxÞ. Since U0ðxÞ is compact and A is bounded, by passing to a
subsequence if necessary, we can assume that uk converges to a point
u 2 U0ðxÞ and zk converges to a point z 2 Rn. By the deﬁnition of subgradients
zk we have that for any x0 2 Rn the following inequality holds
gukðx0Þ  gukðxÞ  zT
k ðx0  xÞ:
By passing to the limit in the above inequality as k ! 1, we obtain that
z 2 @guðxÞ. It follows that z 2 A, and hence A is closed. Now since convex hull
of a compact subset of Rn is also compact, and hence is closed, we obtain that
if the assumption (ii) in the above theorem is strengthened to the assumption
(iii), then the set inside the parentheses in (9.11) is closed, and hence formula
(9.11) takes the form
@f ðxÞ ¼ conv
[
u2U0ðxÞ
@guðxÞ
0
@
1
A:
ð9:12Þ
Let f : Rn ! R be an extended real valued function. The conjugate function
of f is
f *ðzÞ :¼ sup
x2Rn zTx  f ðxÞ


:
ð9:13Þ
The
conjugate
function
f * : Rn ! R
is
always
convex
and
lower
semicontinuous.
Theorem 52 (Fenchel–Moreau). Let f : Rn ! R be a proper extended real
valued function. Then
f ** ¼ lscðconv f Þ:
ð9:14Þ
130
A. Ruszczyn´ski and A. Shapiro

Here f ** denotes the conjugate of f * and conv f denotes the convex hull of f ,
ðconv f ÞðxÞ ¼ inff: ðx, Þ 2 convðepi f Þg,
i.e., conv f is the largest convex function majorized by f . Note that if
f ðxÞ ¼ 1 at some x 2 Rn, then f *ðÞ: þ 1 and f **ðÞ:  1. It follows
from (9.14) if f is proper, then f ** ¼ f iﬀf is convex and lower semicontinuous.
It immediately follows from the deﬁnitions that
z 2 @f ðxÞ
iff
f *ðzÞ ¼ zTx  f ðxÞ:
By applying that to the function f **, instead of f , we obtain that
z 2 @f **ðxÞ iﬀf ***ðzÞ þ f **ðxÞ ¼ zTx. Now by the Fenchel–Moreau theorem
we have that f *** ¼ f *. Consequently, we obtain
@f **ðxÞ ¼ arg max
z2Rn zTx  f *ðzÞ


:
ð9:15Þ
The following result about Lipschitz continuity of linear systems is known
as Hoﬀman’s lemma.
Theorem 53 (Hoﬀman). Consider the multifunction MðbÞ :¼ fx 2 Rn : Ax  bg,
where A is a given m  n matrix. Then there exists a positive constant ,
depending on A, such that for any x 2 Rn and any b 2 dom M,
distðx, MðbÞÞ  kðAx  bÞþk:
ð9:16Þ
The term21 kðAx  bÞþk, in the right hand side of (9.16), measures the
infeasibility of the point x.
9.2
Duality of optimization problems
Consider a real valued function L : X  Y ! R, where X and Y are
arbitrary sets. We can associate with the function Lðx, yÞ the following two
optimization problems:
Min
x2X
f ðxÞ :¼ sup
y2Y
Lðx, yÞ
(
)
,
ð9:17Þ
21 The operator ðÞþ applied to a vector is taken componentwise.
Ch. 2. Optimality and Duality in Stochastic Programming
131

Max
y2Y
gðyÞ :¼ inf
x2X Lðx, yÞ
	

,
ð9:18Þ
viewed as dual to each other. We have that for any x 2 X and y 2 Y,
gðyÞ ¼ inf
x02X Lðx0, yÞ  Lðx, yÞ  sup
y02Y
Lðx, y0Þ ¼ f ðxÞ,
and hence the optimal value of problem (9.17) is greater than or equal to the
optimal value of problem (9.18). It is said that a point ðx, yÞ 2 X  Y is a
saddle point of Lðx, yÞ if
Lðx, yÞ  Lðx, yÞ  Lðx, yÞ, 8 ðx, yÞ 2 X  Y:
ð9:19Þ
Proposition 54. The following holds: (i) The optimal value of problem (9.17) is
greater than or equal to the optimal value of problem (9.18). (ii) Problems
(9.17) and (9.18) have the same optimal value and each has an optimal solution if
and only if there exists a saddle point ðx, yÞ. In that case x and y are optimal
solutions of problems (9.17) and (9.18), respectively. (iii) If problems (9.17) and
(9.18) have the same optimal value, then the set of saddle points coincides with
the Cartesian product of the sets of optimal solutions of (9.17) and (9.18).
In applications of the above results to optimization problems with
constraints, the function Lðx, yÞ usually is the Lagrangian of the problem and
y is a vector of Lagrange multipliers.
An alternative approach to duality, referred to as conjugate duality, is the
following. Consider an extended real valued function  : Rn  Rm ! R. Let
#ðyÞ be the optimal value of the parameterized problem
Min
x2Rn  ðx, yÞ,
ð9:20Þ
i.e., #ðyÞ :¼ infx2Rn ðx, yÞ. Note that implicitly the optimization in the above
problem is performed over the domain of the function  ð, yÞ, i.e., dom  ð, yÞ
can be viewed as the feasible set of problem (9.20).
The conjugate of the function #ðyÞ can be expressed in terms of the
conjugate of  ðx, yÞ. That is, the conjugate of  is
 *ðx*, y*Þ :¼
sup
ðx, yÞ2RnRm
n
ðx*ÞTx þ ðy*ÞTy   ðx, yÞ
o
,
132
A. Ruszczyn´ski and A. Shapiro

and hence the conjugate of # can be written as
#*ðy*Þ :¼ supy2Rm ð y*ÞTy  #ð yÞ

 ¼ supy2Rm ð y*ÞTy  infx2Rn ðx, yÞ


¼ supðx, yÞ2RnRm ð y*ÞTy   ðx, yÞ


¼  *ð0, y*Þ:
Consequently, the conjugate of #* is
#**ð yÞ ¼ sup
y*2Rm ð y*ÞTy   *ð0, y*Þ


:
ð9:21Þ
This leads to the following dual of (9.20):
Max
y*2Rm ð y*ÞTy   *ð0, y*Þ


:
ð9:22Þ
In the above formulation of problem (9.20) and its (conjugate) dual (9.22)
we have that #ð yÞ and #**ð yÞ are optimal values of (9.20) and (9.22),
respectively. We also have by the Fenchel–Moreau Theorem that either #**ðÞ
is identically 1, or
#**ðyÞ ¼ lscðconv #ÞðyÞ,
8 y 2 Rm:
ð9:23Þ
It follows that #**ð yÞ  #ð yÞ for any y 2 Rm. It is said that there is no
duality gap between (9.20) and its dual (9.22) if #**ð yÞ ¼ #ð yÞ.
Suppose now that the function  ðx, yÞ is convex (as a function of
ðx, yÞ 2 Rn  Rm). It is straightforward then to verify that the optimal value
function #ð yÞ is also convex, and hence conv #ðÞ:#ðÞ. It is said that the
problem (9.20) is subconsistent, for a given value of y, if lsc #ð yÞ < þ1. If
problem (9.20) is feasible, i.e., dom  ð, yÞ is nonempty, then #ð yÞ < þ1, and
hence (9.20) is subconsistent.
Proposition 55. Suppose that the function  ð, Þ is convex. Then the following
holds: (i) The optimal value function #ðÞ is convex. (ii) If problem (9.20) is
subconsistent, then #**ð yÞ ¼ #ð yÞ if and only if the optimal value function #ðÞ is
lower semicontinuous at y. (iii) If #**ð yÞ is ﬁnite, then the set of optimal
solutions of the dual problem (9.22) coincides with @#**ð yÞ. (iv) The set of
optimal solutions of the dual problem (9.22) is nonempty and bounded if and only
if #ðyÞ is ﬁnite and #ðÞ is continuous at y.
A few words about the above statements are now in order. Assertion (ii)
follows by the Fenchel–Moreau Theorem. Assertion (iii) follows from formula
(9.15). If #ðÞ is continuous at y, then it is lower semicontinuous at y, and
hence #**ð yÞ ¼ #ð yÞ. Moreover, in that case @#**ð yÞ ¼ @#ð yÞ and is nonempty
and bounded provided that #ð yÞ is ﬁnite. It follows then that the set of
Ch. 2. Optimality and Duality in Stochastic Programming
133

optimal solutions of the dual problem (9.22) is nonempty and bounded.
Conversely, if the set of optimal solutions of (9.22) is nonempty and bounded,
then, by (iii), @#**ð yÞ is nonempty and bounded, and hence by convex analysis
#ðÞ is continuous at y. Note also that if @#ð yÞ is nonempty, then
#**ð yÞ ¼ #ð yÞ and @#**ð yÞ ¼ @#ð yÞ.
The above analysis can be also used in order to describe diﬀerentiability
properties of the optimal value function #ðÞ in terms of its subdiﬀerentials.
Proposition 56. Suppose that the function  ð, Þ is convex and let y 2 Rm be a
given point. Then the following holds: (i) The optimal value function #ðÞ is
subdiﬀerentiable at y if and only if #ðÞ is lower semicontinuous at y and the dual
problem (9.22) possesses an optimal solution. (ii) The subdiﬀerential @#ð yÞ is
nonempty and bounded if and only if #ð yÞ is ﬁnite and the set of optimal
solutions of the dual problem (9.22) is nonempty and bounded. (iii) In both above
cases @#ð yÞ coincides with the set of optimal solutions of the dual problem (9.22).
Since #ðÞ is convex, we also have that @#ðyÞ is nonempty and bounded iﬀ
#ð yÞ is ﬁnite and y 2 intðdom #Þ. The condition y 2 intðdom #Þ means the
following: there exists a neighborhood N of y such that for any y0 2 N the
domain of  ð, y0Þ is nonempty.
As an example let us consider the following problem
Minx2X f ðxÞ
subject to
giðxÞ þ yi  0,
i ¼ 1, . . . , m,
ð9:24Þ
where X is a subset of Rn, f ðxÞ and giðxÞ are real valued functions, and
y ¼ ðy1, . . . , ymÞ is a vector of parameters. We can formulate this problem in
the form (9.20) by deﬁning
 ðx, yÞ :¼ f ðxÞ þ FðGðxÞ þ yÞ,
where f ðxÞ :¼ f ðxÞ þ iXðxÞ and FðÞ is the indicator function of the negative
orthant, i.e., FðzÞ :¼ 0 if zi  0, i ¼ 1, . . . , m, and FðzÞ :¼ þ1 otherwise, and
GðxÞ :¼ ðg1ðxÞ, . . . , gmðxÞÞ.
Suppose that the problem (9.24) is convex, that is, the set X and the
functions f ðxÞ and giðxÞ, i ¼ 1, . . . , m, are convex. Then it is straightforward to
verify that the function  ðx, yÞ is also convex. Let us calculate the conjugate of
the function  ðx, yÞ,
 *ðx*, y*Þ ¼ supðx, yÞ2RnRm ððx*ÞTx þ ðy*ÞTy  f ðxÞ  FðGðxÞ þ yÞ


¼ supx2Rn ððx*ÞTx  f ðxÞ  ðy*ÞTGðxÞ

þsupy2Rm ðy*ÞTðGðxÞ þ yÞ  FðGðxÞ þ yÞ


:
134
A. Ruszczyn´ski and A. Shapiro

By change of variables z ¼ GðxÞ þ y we obtain that
sup
y2Rm ðy*ÞTðGðxÞ þ yÞ  FðGðxÞ þ yÞ


¼ sup
z2Rm ðy*ÞTz  FðzÞ


¼ iRm
þðy*Þ:
Therefore we obtain
 *ðx*, y*Þ ¼ sup
x2X
ðx*ÞTx  Lðx, y*Þ


þ iRm
þðy*Þ,
where Lðx, y*Þ :¼ f ðxÞ þ Pm
i¼1 y*i giðxÞ, is the Lagrangian of the problem.
Consequently, the dual of the problem (9.24) can be written in the form
Max
0
Ty þ inf
x2X Lðx, Þ
	

:
ð9:25Þ
Note that we changed the notation from y* to  in order to emphasize that
the above problem (9.25) is the standard Lagrangian dual of (9.24) with
 being vector of Lagrange multipliers. The results of Propositions 55 and 56
can be applied to problem (9.24) and its dual (9.25) in a straightforward way.
As another example consider the problem
Minx2X f ðxÞ
subject to
giðxÞ þ hiðzÞ  0,
i ¼ 1, . . . , m,
ð9:26Þ
where X is a convex subset of Rn, f ðxÞ and giðxÞ are real valued convex
functions, and hiðzÞ are real valued convex functions of the parameter vector
z 2 Rl. By change of variables yi ¼ hiðzÞ, the above problem can be reduced to
the problem (9.24), and hence the optimal value vðzÞ of problem (9.26) is equal
to #ðHðzÞÞ, where #ðÞ is the optimal value of problem (9.24) and
HðzÞ :¼ ðh1ðzÞ, . . . , hmðzÞÞ. Note that if y  y0, then the feasible set of problem
(9.24) corresponding to y0 is included in the feasible set corresponding to y,
and hence #ðyÞ  #ðy0Þ, i.e., #ðÞ is componentwise nondecreasing function. It
follows that the optimal value function vðzÞ is convex, which is also not
diﬃcult to show directly.
Suppose that the functions hiðzÞ, i ¼ 1, . . . , m, are diﬀerentiable and
consider a point z 2 Rl. Then, since #ðÞ is componentwise nondecreasing and,
by convexity of hiðzÞ, Hðz þ zÞ is componentwise greater than or equal to
HðzÞ þ rHðzÞz for any z 2 Rl, we have that for y :¼ HðzÞ and any y* 2 @#ð yÞ
the following inequalities hold
vðz þ zÞ ¼ #ðHðz þ zÞÞ  # HðzÞ þ rHðzÞz
ð
Þ  vðzÞ þ ð y*ÞTrHðzÞz:
Ch. 2. Optimality and Duality in Stochastic Programming
135

It follows that rHðzÞTy* 2 @vðzÞ, or in other words that
rHðzÞT@#ð yÞ  @vðzÞ:
ð9:27Þ
As a consequence of the above inclusion we obtain that if #ðÞ is
subdiﬀerentiable at y, then vðÞ is subdiﬀerentiable at z. If, moreover, the
constraint qualiﬁcation
0 2 int HðzÞ þ rHðzÞRl  dom #


ð9:28Þ
is satisﬁed, then it is possible to show that the inverse of the inclusion (9.28)
also holds, and hence in that case
rHðzÞT@#ð yÞ ¼ @vðzÞ:
ð9:29Þ
The constraint qualiﬁcation (9.28) holds, in particular, if the Jacobian
matrix rHðzÞ has full row rank m, or if y ¼ HðzÞ belongs to the interior of the
domain of #. Note that dom # is formed by such vectors y that the
corresponding problem (9.24) is feasible.
9.3
Probability and measure
It is said that an m-dimensional random vector V ¼ Vð!Þ has an absolutely
continuous distribution if for any set A  Rm of Lebesgue measure zero the
event fV 2 Ag has zero probability. The distribution of V is absolutely
continuous iﬀit has a density, i.e., there exists a real valued function gðÞ such
that for any Borel set A  Rm probability of the event fV 2 Ag is equal to the
integral
R
A gðxÞ dx. The function gðÞ is called the probability density function.
Let fnð!Þ be a sequence of real valued measurable functions on a probability
space ð, F, PÞ. By fn " f a.e. we mean that for almost every ! 2  the
sequence fnð!Þ is monotonically nondecreasing and hence converges to a limit
denoted f ð!Þ, where f ð!Þ can be equal to þ1.
Theorem 57 (Monotone Convergence Theorem). Suppose that fn " f a.e. and
there exists a P-integrable function gð!Þ such that fnðÞ  gðÞ. Then
R
 f dP is
well deﬁned and
R
 fn dP "
R
 f dP.
Theorem 58 (Fatou’s lemma). Suppose that there exists a P-integrable function
gð!Þ such that fnðÞ  gðÞ. Then
Z

lim inf
n ! 1 fn dP  lim inf
n ! 1
Z

fn dP:
ð9:30Þ
136
A. Ruszczyn´ski and A. Shapiro

Theorem 59 (Lebesgue Dominated Convergence Theorem). Suppose that there
exists a P-integrable function gð!Þ such that jfnj  g a.e., and that fnð!Þ
converges to f ð!Þ for almost every ! 2 . Then
R
 fn dP is well deﬁned and
R
 fn dP !
R
 f dP.
The following result can be proved by induction in m.
Theorem 60 (Richter–Rogosinsky). Let ð, FÞ be a measurable space, f1, . . . , fm
be measurable on ð, FÞ real valued functions, and 
 be a nonnegative ﬁnite
measure on ð, FÞ such that f1, . . . , fm are 
-integrable. Suppose that every ﬁnite
subset of  is F-measurable. Then there exists a nonnegative measure 	 on
ð, FÞ with a ﬁnite support of at most m points such that
R
 fid
 ¼
R
 fid	 for
all i ¼ 1, . . . , m.
10
Bibliographic notes
Basic properties of expectations, deﬁned as integrals on probability spaces,
can be found in numerous books on probability and measure theory. For
example, we may refer to Billingsley (1995) where the interested reader can
ﬁnd proofs of the Lebesgue and Monotone Convergence Theorems and
Fatou’s Lemma. Diﬀerentiability properties of the expectation functions were
discussed by many authors. Proposition 2 follows easily from the Lebesgue
Dominated Convergence Theorem (cf., e.g., Rubinstein and Shapiro (1993)).
For a thorough development of integration of multifunctions and integral
functionals we refer to Rockafellar (1976) and Chapter 8 in Ioﬀe and
Tihomirov (1979), where some additional references can be found. The
interchangeability formula (1.8) for the subdiﬀerential and expectation
operators, given in Theorem 9, is taken from Theorem 4, p. 351, of Ioﬀe and
Tihomirov (1979). In the convex case it follows from the interchangeability
formula (1.8) that the expected value function f ðxÞ is diﬀerentiable at a point
x0 iﬀ@Fðx0, !Þ is a singleton for a.e. ! 2 . We derived this result in a more
direct way in Proposition 4.
Properties of the optimal value Qðx, Þ of the second stage linear
programming problem were studied by Walkup and Wets (1967, 1969),
Wets (1966, 1974) and Kall (1976), so most of the material of Sections 2.1 and
2.2 can be found there. Example 15 is discussed in Birge and Louveaux (1997).
Polyhedral and convex two-stage problems, discussed in Sections 2.3 and 2.4,
are natural extensions of the linear two-stage problems. The conjugate duality,
used in Proposition 25 is based on Fenchel duality (Fenchel (1953)) and was
developed by Rockafellar (1974).
Optimality conditions of the type used in Proposition 32 are well known
(see, e.g., Chapter 1 in Ioﬀe and Tihomirov (1979)). See also Hiriart-Urruty
(1978) and Fla˚ m (1992, 1995) for the analysis in the case of Lipschitz
continuous functions.
Ch. 2. Optimality and Duality in Stochastic Programming
137

Duality analysis of stochastic problems, and in particular dualization of
the nonanticipativity constraints was developed by Eisner and Olsen (1975),
Wets (1976), Rockafellar and Wets (1975, 1976a,b,c, 1977) (see also Wets
(1980) and Klein Haneveld (1986) and Rockafellar (1999) and the references
therein). We tried to keep the presentation in Section 6 and Section 7 relatively
elementary without an extensive use of functional analysis.
The min–max approach to stochastic programming, discussed in Section 8,
was investigated extensively by Dupacˇ ova´ (1977, 1978, 1987).
For a thorough treatment of the convex analysis theory we refer to
Rockafellar (1970). Theorem 53 is due to Hoﬀman (1952). For a proof of
Richter-Rogosinsky Theorem (theorem 60) see Rogosinsky (1958).
References
Billingsley, P. (1995). Probability and Measure, John Wiley & Sons, New York.
Birge, J.R., F. Louveaux (1997). Introduction to Stochastic Programming, Springer-Verlag, New York,
NY.
Dupacˇ ova´ , J. (1977). The minimax problem of stochastic linear programming and the moment
problem. Ekonom.-Mater. Obzor 13, 279–307.
Dupacˇ ova´ , J. (1978). Minimax approach to stochastic linear programming and the moment problem.
Selected results. Z. Angew. Math. Mech. 58, T466–T467.
Dupacˇ ova´ , J. (1987). The minimax approach to stochastic programming and an illustrative
application. Stochastics 20, 73–88.
Eisner, M., P. Olsen (1975). Duality for stochastic programming interpreted as l.p. in Lp-space. SIAM
J. Appl. Math. 28, 775–792.
Fenchel, W. (1953). Convex Cones, Sets, and Functions, lecture notes, Princeton University.
Fla˚ m, S.D. (1992). Lagrange multipliers in stochastic programming. SIAM Journal on Control and
Optimization 30, 1–10.
Fla˚ m, S.D. (1995). Corrigendum: Lagrange multipliers in stochastic programming. SIAM Journal on
Control and Optimization 33, 667–671.
Hiriart-Urruty, J.-B. (1978). Conditions ne´ cessaires d‘optimalite´ pour un programme stochastique avec
recours. SIAM Journal on Control and Optimization 16, 317–329.
Hoﬀman, A. (1952). On approximate solutions of systems of linear inequalities. Journal of Research of
the National Bureau of Standards, Section B. Math. Sci. 49, 263–265.
Ioﬀe, A.D., V.M. Tihomirov (1979). Theory of Extremal Problems, North–Holland, Amsterdam.
Kall, P. (1976). Stochastic Linear Programming, Springer-Verlag, Berlin.
Klein Haneveld, W.K. (1986). Duality in Stochastic Linear and Dynamic Programming, Lecture Notes
in Economic and Mathematical Systems, Vol. 274, Springer-Verlag, New York.
Rockafellar, R.T. (1970). Convex Analysis, Princeton University Press, Princeton, NJ.
Rockafellar, R.T. (1974). Conjugate Duality and Optimization, Regional Conference Series in Applied
Mathematics, SIAM, Philadelphia.
Rockafellar, R.T. (1976). Integral functionals, normal integrands and measurable selections. Nonlinear
Operators and the Calculus of Variations, Lecture Notes in Mathematics, Vol. 543, Springer-Verlag,
Berlin, pp. 157–207.
Rockafellar, R.T. (1999). Duality and optimality in multistage stochastic programming. Annals of
Operations Research 85, 1–19.
Rockafellar, R.T., R.J-B. Wets (1975). Stochastic convex programming: Kuhn-Tucker conditions.
J. Math. Econom. 2, 349–370.
138
A. Ruszczyn´ski and A. Shapiro

Rockafellar, R.T., R.J.-B. Wets (1976a). Stochastic convex programming: basic duality. Paciﬁc J.
Math. 62, 173–195.
Rockafellar, R.T., R.J.-B. Wets (1976b). Stochastic convex programming: singular multipliers and
extended duality, singular multipliers and duality. Paciﬁc J. Math. 62, 507–522.
Rockafellar, R.T., R.J.-B. Wets (1976c). Stochastic convex programming: relatively complete recourse
and induced feasibility. SIAM Journal on Control and Optimization 14, 574–589.
Rockafellar, R.T., R.J-B. Wets (1977). Measures as Lagrange multipliers in multistage stochastic
programming. J. Math. Anal. Appl. 60, 301–313.
Rogosinsky, W.W. (1958). Moments of non-negative mass. Proc. Roy. Soc. London Ser. A 245, 1–27.
Rubinstein, R.Y., A. Shapiro (1993). Discrete Event Systems: Sensitivity Analysis and Stochastic
Optimization by the Score Function Method, John Wiley & Sons, Chichester.
Walkup, D., R.J.-B. Wets (1967). Stochastic programs with recourse. SIAM J. Appl. Math. 15,
1299–1314.
Walkup, D., R.J.-B. Wets (1969). Stochastic programs with recourse II: on the continuity of the
objective. SIAM J. Appl. Math. 15, 1299–1314.
Wets, R.J.-B. (1966). Programming under uncertainty: the equivalent convex program. SIAM J. Appl.
Math. 14, 89–105.
Wets, R.J.-B. (1974). Stochastic programs with ﬁxed recourse: the equivalent deterministic program.
SIAM Review 16, 309–339.
Wets, R.J.-B. (1976). Duality relations in stochastic programming, in: Symposia Mathematica,
Vol. XIX (Convegno sulla Programmazione Matematica e sue Applicazioni, INDAM, Rome,
1974), Academic Press, London, pp. 341–355.
Wets, R.J.-B. (1980). Stochastic multipliers, induced feasibility and nonanticipativity in stochastic
programming: Stochastic Programming (Proc. Internat. Conf., Univ. Oxford, Oxford, 1974),
Academic Press, London, pp. 137–146.
Ch. 2. Optimality and Duality in Stochastic Programming
139

Chapter 3
Decomposition Methods
Andrzej Ruszczyn´ski
Department of Management Science and Information Systems, Rutgers University,
94 Rockafeller Rd, Piscataway, NJ 08854, USA
Abstract
Two- and multistage stochastic programming problems have very large dimen-
sion and characteristic structures which are tractable by decomposition. We
present cutting plane methods, nested decomposition methods, regularized
decomposition methods, trust region methods, augmented Lagrangian methods,
and splitting methods for convex stochastic programming problems.
Key words:
Stochastic programming, decomposition, primal methods, dual
methods, operator splitting.
1
Introduction
Two- and multistage stochastic programming problems have very speciﬁc
structures which can be exploited by decomposition. The objective of this
chapter is to provide a detailed description and analysis of the main decom-
position methods used in stochastic programming.
To illustrate the main concepts, let us consider the two-stage stochastic
programmingproblem,whichhasbeenextensivelyanalyzedinChapters1and2.
Recall that there are two groups of decision variables in the two-stage
problem: the ﬁrst stage decisions x 2 Rn1, which are deterministic, and the
second stage decisions y 2 Rn2, which are allowed to depend on the random
problem data, . The linear two-stage problem has the form
Min fcTx þ EQðx, Þg
s:t:
Ax ¼ b, x  0,
ð1:1Þ
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
141

where  ¼ (q, W, h, T ) is the vector of (possibly random) problem data, and
Qðx, Þ :¼ inf
y2R
n2
þ
qTy j Wy ¼ h  Tx


:
ð1:2Þ
We assume that the probability space O is ﬁnite, we denote by !s, s ¼ 1,. . . , S,
all elementary events and by ps, s ¼ 1,. . . , S, their probabilities. We also use
the notation T s ¼ T(!s), W s ¼ W(!s), hs ¼ h(!s), ys ¼ y(!s), qs ¼ q(!s). Then we
can rewrite (1.1) and (1.2) as
Min
x2X
f ðxÞ :¼ cTx þ
X
S
s¼1
psQsðxÞ
(
)
,
ð1:3Þ
with
QsðxÞ :¼ inf
y2R
n2
þ
ðqsÞTy j Wsy ¼ hs  Tsx


ð1:4Þ
and
X ¼ fx 2 Rn1 : Ax ¼ b, x  0g:
The polyhedral structure of Qs(  ) is characterized in Proposition 11 in
Chapter 2. To avoid unnecessary technical complications we assume that
Qs(x)>1 for all x 2 X.
The main idea of primal decomposition methods is to address the problem in
its form (1.3). These methods solve many subproblems of form (1.4) to
construct some models (approximations) of the recourse costs Qs(  ) and of the
expected recourse cost. These models are used in a master problem, which
generates approximations of the ﬁrst stage solution, x. The diﬀerences
between various primal methods lie mainly in the way the master problem is
constructed and solved. We shall discuss several versions of primal methods in
Sections 2–4. In Section 5 we shall extend these ideas to multistage problems.
Problem (1.3)–(1.4) can be rewritten as a large scale linear programming
problem
Min
cTx þ
X
S
s¼1
psðqsÞTys
(
)
s:t:
Ax ¼ b,
Tsx þ Wsys ¼ hs,
s ¼ 1, . . . , S,
x  0, ys  0,
s ¼ 1, . . . , S:
ð1:5Þ
142
A. Ruszczyn´ski

Splitting the ﬁst stage decisions x into copies x1,. . . , xS corresponding to
scenarios we can reformulate (1.5) as follows:
Min
X
S
s¼1
psðcTxs þ ðqsÞTysÞ
s:t:
Axs ¼ b,
s ¼ 1, . . . , S,
Tsx þ Wsys ¼ hs,
s ¼ 1, . . . , S,
xs  0, ys  0,
s ¼ 1, . . . , S,
xs ¼ x,
s,  ¼ 1, . . . , S:
ð1:6Þ
The idea of dual methods is to relax the last group of constraints, which are
called
in
stochastic
programming
the
nonanticipativity
constraints,
by
assigning to them some Lagrange multipliers. In the most straightforward
approach a multiplier s, is associated with each scenario pair1 and we
formulate the Lagrangian
Lðx, y, Þ ¼
X
S
s¼1
ps

cTxs þ ðqsÞTys
þ
X
S
s¼1
X
s
¼1
ðs,ÞTðxs  xÞ:
The problem of minimizing the Lagrangian, subject to all the remaining
constraints, splits into S independent scenario subproblems, each for vectors
xs and ys. Their solutions depend on the multipliers and the role of the master
problem is to ﬁnd the optimal values of these multipliers, so that the x-parts of
the scenario solutions will become identical. Dual decomposition methods
diﬀer in the ways the nonanticipativity constraints are spelled out, the ways
the Lagrangian is deﬁned, the subproblems constructed, and multipliers
changed. We shall present them in Sections 6–9.
There are two fundamental advantages of decomposition methods. First,
they replace a large and diﬃcult stochastic programming problem by a
collection of smaller and easier problems. This allows for solving extremely
large models, which are intractable otherwise. Secondly, the subproblems
involved in decomposition methods are usually standard linear, quadratic or
nonlinear problems, which need to be developed and solved for the simplest
deterministic versions of the model. Consequently, standard oﬀ-the-shelf
optimization software may be used for the solution of these subproblems. As a
result, decomposition methods provide a highly eﬃcient and specialized
methodology for solving very large and diﬃcult stochastic programming
problems by employing readily available tools.
1 A smaller set of constraints can express nonanticipativity, but this form is suﬃcient to introduce the
idea of dualization.
Ch. 3. Decomposition Methods
143

It should be stressed that the form of the constraints Ax ¼ b and x  0 has
been chosen only for the simplicity of presentation. We may have here
arbitrary constraints of form x 2 X, where X is a convex closed polyhedron.
Similarly, instead of the conditions y  0 in the second stage problems, we may
require ys 2 Ys, where Ys is a convex closed polyhedron for each scenario
s ¼ 1,. . . , S. Also, the constraints linking the ﬁrst and the second stage
decisions in (1.1) or (1.2) may have the form of an arbitrary combinations of
linear equations and inequalities.
2
The cutting plane method
2.1
The main concepts
The idea of cutting plane methods is to construct a sequence {xk} of
approximations to the solution of (1.3) in the following way. The known
pieces of the functions Qs(  ) and facets of their domains are used to construct
an
approximation
of
the
expected
recourse
cost
PS
s¼1 psQsðxÞ.
This
approximation is employed to compute the values of the ﬁrst stage variables,
xk, at the current iteration. At these values of the ﬁrst stage decisions sub-
problems (1.4) yield new information about the shape of Qs(  ). This is used to
calculate xk þ 1, and the iteration continues.
To see how the new information can be obtained, let us suppose that
Qs(xk)<1. Then, as described in Proposition 12 of Chapter 2,
@QsðxkÞ ¼ ðTsÞTDsðxkÞ,
ð2:1Þ
where
DsðxkÞ :¼ arg max
ðWsÞTqs Tðhs  TsxkÞ
ð2:2Þ
is the set of optimal solutions of the dual to problem in (1.4) at x ¼ xk. Let k,s
be one of these optimal dual solutions. Then, by the deﬁnition of the
subdiﬀerential,
QsðxÞ  QsðxkÞ  ðTsÞTk,s, x  xk


for all
x 2 Rn1:
This inequality deﬁnes an objective cut:
QsðxÞ  k,s þ ðgk,sÞTx,
for all
x 2 Rn1,
ð2:3Þ
144
A. Ruszczyn´ski

where
gk,s ¼ ðTsÞTk,s,
ð2:4Þ
k,s ¼ QsðxkÞ þ ðk,sÞTTsxk ¼ ðhsÞTk,s:
ð2:5Þ
In the last equation (2.5) we have used the duality relation between (1.4) and
the optimal value of problem (2.2):
QsðxkÞ ¼ ðk,sÞTðhs  TsxkÞ:
It follows that to obtain an objective cut for Qs(  ) at xk we need to solve
problem (1.4) at x ¼ xk, retrieve Lagrange multipliers k,s associated with its
constraints, and apply formulas (2.3)–(2.5). Equivalently, we may solve the
dual problem appearing in (2.2). Moreover, if we restrict our attention to basic
solutions of these problems, the multipliers k,s will be chosen from a ﬁnite set
which does not depend on xk: the set of basic feasible solutions of the dual
problem. We shall call such cuts basic objective cuts.
If subproblem (1.4) at x ¼ xk is infeasible, we can derive an inequality that
must be satisﬁed by every x 2 dom Qs:
k,s þ ðrk,sÞTx  0,
ð2:6Þ
and which is violated at xk. We shall call it a feasibility cut, and we shall say
that it cuts xk oﬀ. To see how such a feasibility cut can be obtained, consider
the Phase I problem corresponding to (1.4):
Min
y,z kzk
s:t:
Wsy þ z ¼ hs  Tsx,
y  0:
ð2:7Þ
Here z ¼ (z1,. . . , zm) is a vector of artiﬁcial variables and k  k denotes a norm
on
the
space
Rm.
For
technical
reasons
we
will
use
the
‘1
norm
kzk1 :¼ jz1j þ    þ jzmj, or the max-norm kzk1 :¼ maxfjz1j, . . . , jzmjg. Note
that both norms k  k1 and k  k1 are polyhedral in the sense that they can be
represented as a maximum of a ﬁnite number of linear functions. Let us
denote by Us(x) the optimal value of (2.7). It is clear that problem (2.7) is
always feasible and its optimal value is ﬁnite, and moreover Qs(x)<1 if and
only if Us(x) ¼ 0. We have, therefore, Us(xk)>0.
The function Us(x) is an optimal value of a convex problem having x as a
parameter in the constraint right hand side. Moreover, if the norm k  k is
Ch. 3. Decomposition Methods
145

polyhedral, then (2.7) can be formulated as a linear programming problem.
The dual of (2.7) is given by the max–min problem
Max

Min
z,y0 fkzk þ Tðhs  Tsx  Wsy  zÞg:
By calculating the minimum in the above problem, we can write the dual in the
following form
Max

Tðhs  TsxÞ
s:t:
ðWsÞT  0,
kk*  1,
ð2:8Þ
where k  k* denotes the dual of the norm k  k (recall that the norms k  k1 and
k  k1 are dual to each other). We have, by the standard theory of linear
programming, that in the case of a polyhedral norm k  k there is no duality
gap between problems (2.7) and (2.8) and both problems have optimal
solutions. Furthermore, the function Us(  ) is a piecewise linear convex
function and its subdiﬀerential @Us(x) is equal to (Ts)Ts(x), where s(x) is
the set of optimal solutions of the dual problem (2.8).
Therefore, we can construct for Us(  ) an objective cut (k,s, rk,s) in a way
similar to (2.3):
rk,s 2 @UsðxkÞ,
k,s ¼ UsðxkÞ  hrk,s, xki:
Then for every x 2 Rn1
UsðxÞ  UsðxkÞ þ hrk,s, x  xki ¼ k,s þ ðrk,sÞTx,
and the above relation turns into equality at x ¼ xk. Since Us(x) ¼ 0 at all
feasible x, the last inequality implies (2.6). Moreover, Us(xk)>0, so (2.6) cuts
xk oﬀ, as promised. Again, by restricting the dual solutions to basic solutions
we can guarantee that the number of all possible feasibility cuts is ﬁnite. We
shall call such cuts basic feasibility cuts.
Summing up, the epigraph of Qs(  ) is a closed convex polyhedron deﬁned
by ﬁnitely many basic objective and feasibility cuts.
The objective cuts at xk (if they can be computed successfully) yield a cut
for the expected second stage cost
QðxÞ ¼
X
S
s¼1
psQsðxÞ  k þ ðgkÞTx,
ð2:9Þ
146
A. Ruszczyn´ski

where
gk ¼
X
S
s¼1
psgk,s,
k ¼
X
S
s¼1
psk,s:
ð2:10Þ
Let k ¼ 1, 2, . . . be the iteration number and let Jk
obj be the set of iteration
numbers j  k such that the cut (2.10) could be calculated. Similarly, let Jk
feaðsÞ
be the set of iterations when a feasibility cut was generated for scenario s.
The cuts constructed so far are used in the master problem
Min fcTx þ vg
ð2:11Þ
s:t:
 j þ ðg jÞTx  v,
j 2 Jk
obj,
ð2:12Þ
 j,s þ ðr j,sÞTx  0,
j 2 Jk
feaðsÞ,
s ¼ 1, . . . , S,
ð2:13Þ
Ax ¼ b,
x  0,
ð2:14Þ
whose solution (xk þ 1, vk þ 1) is the next approximation to the solution of (1.3)
and a lower bound for Q(  ).
To describe the cutting plane method and analyze its properties, let
us assume at ﬁrst that the initial point, x1, is such that Qs(x1)<1 for all
s ¼ 1, . . . , S. We also assume that the set
X ¼ fx 2 Rn1: Ax ¼ b, x  0g
is bounded. The operation of the Cutting Plane Method is presented in Fig. 1.
Step 0. Set k ¼ 1, J0
obj ¼ ;, J0
feaðsÞ ¼ ;, s ¼ 1,. . . , S, v1 ¼ 1.
Step 1. For s ¼ 1,. . . , S solve subproblem (1.4) with x ¼ xk.
(a) If Qs(xk)<1, construct the objective cut (2.3) and set Jk
feaðsÞ ¼ Jk1
fea ðsÞ;
(b) If Qs(xk) ¼ 1 (i.e., problem (1.4) is infeasible), construct the feasibility cut (2.6) and
set Jk
feaðsÞ ¼ Jk1
fea ðsÞ [ fkg.
If Qs(xk)<1 for all s ¼ 1,. . . , S, construct the aggregate objective cut (2.9) and set
Jk
obj ¼ Jk1
obj [ fkg; otherwise set Jk
obj ¼ Jk1
obj .
Step 2. If Q(xk) ¼ vk then stop (optimal solution has been found); otherwise continue.
Step 3. Solve the master problem (2.11)–(2.14). If it is infeasible, stop (the original
problem has no feasible solutions). Otherwise, denote by (xk þ 1, vk þ 1) its solution,
increase k by one, and go to Step 1.
Fig. 1. The cutting plane algorithm.
Ch. 3. Decomposition Methods
147

2.2
Convergence
Let us denote by f * the optimal value of the original two-stage problem
(1.3), with the convention that f * ¼ 1 if this problem is infeasible.
The key property of the master problem is that its optimal value provides a
lower bound for the optimal value of the original problem. To see this, let us
consider the function
QkðxÞ :¼ max
j2Jk
obj
½ j þ ðg jÞTx:
ð2:15Þ
By (2.9),
QkðxÞ  QðxÞ,
for all x and all k ¼ 1, 2, . . . ,
ð2:16Þ
Let us assume that x is ﬁxed in (2.11)–(2.14), so that the optimization is
carried out with respect to the variable v. The optimal value of v is then clear
from (2.12):
^vðxÞ ¼ max
j2Jk
obj
½ j þ ðg jÞTx ¼ QkðxÞ:
It follows that the master problem is equivalent to minimizing cTx þ Qk(x)
subject to the constraints (2.13)–(2.14).
Let us also introduce the sets
Xk :¼ fx: constraints ð2:13Þ holdg:
ð2:17Þ
By the construction of the feasibility cuts
Xk  dom QðÞ,
k ¼ 1, 2, . . .
ð2:18Þ
Consequently, the master problem (2.11)–(2.14) is equivalent to
Min fcTx þ QkðxÞg
ð2:19Þ
s:t:
x 2 Xk,
ð2:20Þ
Ax ¼ b, x  0:
ð2:21Þ
By virtue of (2.16) and (2.17) we have the following result.
148
A. Ruszczyn´ski

Lemma 1. If the master problem is feasible at iteration k, then cTxk þ 1 þ
vk þ 1  f *. If the master problem is infeasible at iteration k, then f * ¼ þ 1.
Consequently, the infeasibility test at Step 3 is correct.
We can now prove the convergence of the cutting plane algorithm in its
simplest form.
Theorem 2. Assume that the set X is bounded and that Q(x1)<1. Moreover,
let all cuts constructed at Step 1a and Step 1b be basic objective and feasibility
cuts. Then after ﬁnitely many iterations the Cutting Plane Algorithm ﬁnds an
optimal solution of (1.3).
Proof. If Q(xk) ¼ vk then
cTxk þ QðxkÞ ¼ cTxk þ QkðxkÞ  cTx þ QkðxÞ  cTx þ QðxÞ
for all x 2 Xk \ X. By virtue of (2.18), the point xk is optimal for (1.3). If
vk<Q(xk)<1, the new objective cut (2.9) cuts the point (xk, vk) oﬀthe set of
feasible solutions of the master problem. If Qs(xk) ¼ 1 for some s, the new
feasibility cut (2.6) cuts xk oﬀthe set of feasible solutions of the master
problem. In any case, if xk is not optimal, Step 2 generates a new cut which is
diﬀerent from the cuts present in the master problem. Since the number of
diﬀerent basic objective and feasibility cuts is ﬁnite, the algorithm must
stop.
u
The assumption that the cuts are basic has been made only for simplicity.
We can prove exactly the same result without it, and we shall do it right now.
Let us recall that we assume that the set X is bounded. Also, to allow
infeasible starting points we add the constraint v  M to (2.14), where M is
a lower bound for the optimal cost.
Lemma 3. For every s ¼ 1,. . . , S the number of iterations for which Us(xk)>0 is
ﬁnite.
Proof. Since Us(  ) is polyhedral and its domain is the whole Rn1, it may be
represented as
UsðxÞ ¼ max 0, max
j2J ðj þ ðdjÞTxÞ


,
where J is a ﬁnite set. For each x we can deﬁne the set
IðxÞ :¼ f j : j þ ðdjÞTx ¼ UsðxÞg;
Ch. 3. Decomposition Methods
149

(it may be empty when Us(x) ¼ 0). Clearly, there may be only a ﬁnite number
of diﬀerent sets I(x), and we shall denote them by I1, I2,. . . , IL. Each of the sets
Il deﬁnes a cell:
Cl :¼ fx: j þ ðdjÞTx ¼ UsðxÞ, j 2 Il; j þ ðdjÞTx < UsðxÞ, j 2 JnIlg:
Suppose that our assertion is false, and Us(xk)>0 for inﬁnitely many k. Let us
consider an iteration k such that Us(xk)>0, and let Cl be the cell containing
xk. Then the feasibility cut generated at xk,
UsðxkÞ þ hrk,s, x  xki  0,
ð2:22Þ
has
rk,s ¼
X
j2Il
jdj,
j  0,
X
j2Il
j ¼ 1:
For all x 2 Cl we have:
UsðxÞ ¼
X
j2Jl
jðj þ ðdjÞTxÞ
¼
X
j2Jl
jðj þ ðdjÞTxk þ ðdjÞTðx  xkÞÞ
¼ UsðxkÞ þ hrk,s, x  xki:
By (2.22) no point xm generated by the algorithm for m>k may belong to
the set fx 2 Cl : UsðxÞ > 0g. Since the number of cells is ﬁnite, we obtain a
contradiction.
u
We are now ready to state our main result.
Theorem 4. After ﬁnitely many iterations the Cutting Plane Algorithm either
discovers infeasibility or ﬁnds an optimal solution of (1.3).
Proof. By Lemma 3, after ﬁnitely many iterations the method either discovers
infeasibility, or continues without any new feasibility cuts added, i.e.,
xk 2 dom Q(  ) for all suﬃciently large k.
Since Q(  ) is polyhedral it may be represented as
QðxÞ ¼ max
j2J ð	j þ ðujÞTxÞ,
for all
x 2 dom Q,
150
A. Ruszczyn´ski

where J is a ﬁnite set. For each x we can deﬁne the set
IðxÞ :¼ f j : 	j þ ðujÞTx ¼ QðxÞg:
There may be only a ﬁnite number of diﬀerent sets I(x), and we shall denote
them by I1, I2,. . . , IL. Each of the sets Il deﬁnes a cell:
Cl :¼ fx: 	j þ ðujÞTx ¼ QðxÞ, j 2 Il; 	j þ ðujÞTx < QðxÞ, j 2 JnIlg:
Suppose that our assertion is false, and f (xk)>f * for inﬁnitely many k.
Let f (xk)>f * for some xk 2 Cl. If xk 2 int dom Q, the objective cut generated at
xk has the form
QðxkÞ þ hgk, x  xki  v,
ð2:23Þ
with the subgradient
gk ¼
X
j2Il
juj,
j  0,
X
j2Il
j ¼ 1:
For all x 2 Cl \ int dom Q we have:
QðxÞ ¼
X
j2Jl
jð	j þ ðujÞTxÞ
¼
X
j2Jl
jð	j þ ðujÞTxk þ ðujÞTðx  xkÞÞ
¼ QðxkÞ þ hgk, x  xki:
By (2.23), for every m>k such that xm 2 Cl \ int dom Q we must have
QðxmÞ  vm,
so no new cut will be generated at xm.
Let us now consider the case when xk 2 Cl and xk is a boundary point of
dom Q. Since dom Q is a convex closed polyhedron, it may be represented as
dom Q ¼ fx: wT
j x  j, j 2 J0g,
for some vectors wj and constants j. Its boundary is a ﬁnite collection of
facets deﬁned as

 :¼ fx: wT
j x ¼ j, j 2 J
; wT
j x < j, j 2 J0nJ
g,
Ch. 3. Decomposition Methods
151

where J
, 
 ¼ 1,. . . , M, are all nonempty subsets of J0 for which the above
formula deﬁnes a nonempty set. Every subgradient of Q(  ) at xk has the form
gk ¼
X
j2Il
juj þ zk,
j  0,
X
j2Il
j ¼ 1:
where zk is a normal vector to dom Q at xk. By the deﬁnition of the normal
vector
hzk, x  xki ¼ 0,
for all x 2 
:
Thus, for all x 2 Cl \ 
 we have:
QðxÞ ¼
X
j2Jl
jð	j þ ðujÞTxÞ
¼
X
j2Jl
jð	j þ ðujÞTxk þ ðujÞTðx  xkÞÞ
¼ QðxkÞ þ hgk  zk, x  xki
¼ QðxkÞ þ hgk, x  xki:
By (2.23), no new cuts will be generated at iteration m>k such that
xm 2 Cl \ 
.
Thus, after visiting ﬁnitely many cells and intersections of cells with facets
the algorithm will satisfy the stopping test of Step 2.
u
Simplicity is the main advantage of the Cutting Plane Method. However,
the number of cuts in the master problem grows and there is no easy way to
keep it bounded. A natural idea would be to drop inactive cuts, that is, these
objective and feasibility cuts which are satisﬁed as sharp inequalities at the
current solution (xk, vk) of the master problem.
If we use the method with basic cuts only (as discussed in Theorem 2), we
may drop inactive cuts whenever the optimal value of the master program
increases.
We note at ﬁrst that when inactive cuts are deleted, no decrease of the
optimal value of the master problem may result. Thus the sequence of optimal
values of the master problem, {cTxk þ vk<f *} is monotone. To prove that it is
convergent to f *, suppose that cTxk þ vk<f * for some k and that no increase
of the master’s objective occurs for all m>k. Then no deletion takes place,
and
Theorem
2
guarantees
the
convergence
of
cTxm þ vm
to
f *,
a
contradiction. Therefore, an increase in the master’s objective must occur at
some m  k. The number of diﬀerent optimal values of the master problem is
ﬁnite, because there exists a ﬁnite number of diﬀerent sets of basic objective
152
A. Ruszczyn´ski

and feasibility cuts. Therefore, an increase in this value can occur only ﬁnitely
many times, and the method must stop at an optimal solution after ﬁnitely
many iterations.
In the version with arbitrary subgradient cuts we have no guaranteed
ﬁniteness of the sets of objective and feasibility cuts, and it is diﬃcult to
propose a useful and reliable rule for deleting inactive cuts.
Actually, in both cases, deleting all inactive cuts is not a good idea, because
experience shows that many of them will have to be reconstructed.
2.3
The multicut version
Convergence properties of the Cutting Plane Method can be improved by
using the objective cuts in their original form, without the averaging operation
(2.9)–(2.10). For each s we deﬁne a lower approximation Qk,s of Qs as follows:
Qk,sðxÞ :¼
max
j2Jk
objðsÞ  j,s þ ðg j,sÞTx
	

,
if  j,s þ ðr j,sÞTx  0, j 2 Jk
feaðsÞ,
þ1,
otherwise:
(
ð2:24Þ
Here Jk
objðsÞ is the subset of {1,. . . , k} corresponding to iterations at which cuts
(2.3) were obtained. These models enter the master problem
Min
x2X
cTx þ
X
S
s¼1
psQk,sðxÞ
(
)
,
ð2:25Þ
which is an approximation of (1.3) from below.
A more explicit form of (2.25), similar to (2.11)–(2.14), can be written as
follows:
Min cTx þ
X
S
s¼1
psvs
(
)
ð2:26Þ
j,s þ ðg j,sÞTx  vs,
j 2 Jk
objðsÞ,
s ¼ 1, . . . , S,
ð2:27Þ
j,s þ ðr j,sÞTx  0,
j 2 Jk
feaðsÞ,
s ¼ 1, . . . , S,
ð2:28Þ
Ax ¼ b, x  0:
ð2:29Þ
The multicut method requires more memory, but it uses the previously-
collected data more eﬃciently, because cuts from diﬀerent scenarios can be
combined in various ways.
Ch. 3. Decomposition Methods
153

The algorithm is presented in detail in Fig. 2. To allow starting the method
without any cuts available, we may add the constraint v  M to the master,
where M is a lower bound for the optimal cost.
Theoretical convergence properties of the Multicut Method are exactly the
same as the properties of the Cutting Plane Method. Theorem 2 remains valid,
and its proof is the same. Lemma 3 is also true, because the feasibility cuts are
used in the same way in both versions. To prove the analogue of Theorem 4
we need only technical adjustments.
Theorem 5. After ﬁnitely many iterations the Multicut Algorithm either
discovers infeasibility or ﬁnds an optimal solution of (1.3).
Proof. Since each Qs(  ) is polyhedral it may be represented as
QsðxÞ ¼ max
j2Js ð	s
j þ ðus
jÞTxÞ,
for all x 2 dom Qs,
where Js is a ﬁnite set. For each x and every s we deﬁne
IsðxÞ :¼ f j 2 Js : 	s
j þ ðus
jÞTx ¼ QsðxÞg:
There may be only a ﬁnite number of diﬀerent sets Is(x), and we shall denote
them by Is
1, Is
2, . . . , Is
Ls. Each of the sets Is
l deﬁnes a cell:
Cs
l :¼ fx: 	s
j þ ðus
jÞTx ¼ QsðxÞ, j 2 Is
l ; 	s
j þ ðus
jÞTx < QsðxÞ, j 2 JsnIs
l g:
Next, similarly to the proof of Theorem 4, let 
, 
 ¼ 1,. . . , M, be the facets of
dom Q, and let 0 ¼ int dom Q.
Step 0. Set k ¼ 1, J0
objðsÞ ¼ ;, J0
feaðsÞ ¼ ;, v1,s ¼ 1, s ¼ 1,. . . , S.
Step 1. For s ¼ 1,. . . , S solve subproblem (1.4) with x ¼ xk.
(a) If Qs(xk)<1 then set Jk
feaðsÞ ¼ Jk1
fea ðsÞ. If Qs(xk)>vk,s then construct the objective
cut (2.3) and set Jk
objðsÞ ¼ Jk1
obj ðsÞ [ fkg; otherwise set Jk
objðsÞ ¼ Jk1
obj ðsÞ.
(b) If Qs(xk) ¼ 1 (i.e., problem (1.4) is infeasible), construct the feasibility cut (2.6) and
set Jk
objðsÞ ¼ Jk1
obj ðsÞ, Jk
feaðsÞ ¼ Jk1
fea ðsÞ [ fkg.
Step 2. If QðxkÞ ¼ PS
s¼1 psvk,s then stop (optimal solution has been found); otherwise
continue.
Step 3. Solve the master problem (2.26)–(2.29). If it is infeasible, stop (the original
problem has no feasible solutions). Otherwise, denote by (xk þ 1, vk þ 1) its solution,
increase k by one, and go to Step 1.
Fig. 2. The multicut algorithm.
154
A. Ruszczyn´ski

Let f(xk)>f * for some xk in the intersection C1
l1 \ C2
l2 \    \ CS
lS \ 
.
Thus, for at least one s we must have Qs(xk)>vk,s. Proceeding exactly like in
the proof of Theorem 4 we can prove that for every m>k such that xm is in the
same intersection of cells and a facet, we have
QsðxmÞ  vm,s:
Consequently, the intersection C1
l1 \ C2
l2 \    \ CS
lS \ 
 may be visited at
most S times.
Since there are ﬁnitely many possible intersections of cells and a facet and
each of them may be visited only ﬁnitely many times, the algorithm will satisfy
the stopping test of Step 2.
u
Our remarks about deleting inactive cuts made at the end of the preceding
section remain valid for the Multicut Method. If basic cuts are used, inactive
cuts may be removed whenever the optimal value of the master problem
increases. If general subgradient cuts are employed, no easy rule can be found.
2.4
Estimating objective cuts
So far we have assumed that the number of elementary events ! in (1.1)–
(1.2) is ﬁnite, and that we are able to solve all possible realizations of
subproblem (1.2) for ! 2 O. In many cases these assumptions are not satisﬁed.
For example, if the right hand side in (1.2) has m independent components and
each may have r diﬀerent realizations, the number of elementary events equals
S ¼ rm, which is a very large number, even for moderate values of r and m. A
good example here is the capacity expansion problem of Chapter 1, Section 2,
in which the number of possible scenarios is so large that the solution of all
possible realizations of the second stage problem is practically impossible.
There are two ways around this diﬃculty. One is to generate a sample
1,. . . , N of the problem data, having cardinality N which is manageable.
Then we can solve the two-stage problem with this sample rather than with the
true distribution of the data, hoping that the sample is representative enough
to lead to a good approximation of the true solution. In Chapter 5 we discuss
in detail the properties of this method.
The second approach is to work with estimated cuts rather than with exact
cuts at each iteration of the Cutting Plane Method. Let us illustrate this
approach on the case of a ﬁnite sample space O of very large cardinality S. The
main diﬃculty is then the necessity to solve at each iteration of the method
S subproblems (1.4), corresponding to data realizations 1,. . . , S. These
solutions are needed to calculate the objective value at xk:
QðxkÞ ¼
X
S
s¼1
psQðxk, sÞ
ð2:30Þ
Ch. 3. Decomposition Methods
155

and the objective cut (2.9)–(2.10):
QðxÞ  k þ ðgkÞTx,
ð2:31Þ
where
gk ¼
X
S
s¼1
psgk,s,
k ¼
X
S
s¼1
psk,s:
ð2:32Þ
Let us assume that the second stage problem (1.4) is solvable for all
x satisfying the ﬁrst stage constraints and for all 1, . . . , S, that is, we deal
with a problem with relatively complete recourse.
In order to estimate the quantities deﬁned by (2.30)–(2.32), at iteration k we
draw independent realizations 1, . . . , N of random problem data, which will
be, in general, diﬀerent at each iteration. They correspond to a random sample
s1, . . . , sN of the scenario numbers: 
 ¼ s
.
Then we solve (1.4) only for these sampled scenarios and we construct the
Monte Carlo estimates
~QðxkÞ :¼ 1
N
X
N

¼1
Qðxk, 
Þ,
~gk :¼ 1
N
X
N

¼1
gs
:
ð2:33Þ
Unfortunately, for reasonable sample sizes N the variance of these estimates
may be large. The chapter on Monte Carlo techniques will discuss in much
detail methods to deal with this diﬃculty, such as the importance sampling
method. Here we provide only a superﬁcial characterization of this approach.
Let ˜P be another probability distribution on O, that is, let ~ps be some new
probabilities assigned to the scenarios 1,. . . , S. We assume that the recourse
cost Q(x, ) is nonnegative for feasible ﬁrst stage decisions.2 We can rewrite
the expression for the expected value of the second stage cost as follows:
QðxÞ ¼
X
S
s¼1
~ps½Qðx, sÞps=~ps:
ð2:34Þ
2 We can treat in a similar way any recourse cost that is bounded from below.
156
A. Ruszczyn´ski

This formula can be interpreted as the expectation of the function in brackets
with respect to the distribution ˜P. The Monte Carlo estimate of (2.34) takes
on the form
~QðxÞ ¼ 1
N
X
N

¼1
Qðx, 
Þp
=~p
,
ð2:35Þ
where 1, . . . , N are independent observations drawn according to the
new distribution ˜P. We can now choose ˜P to decrease the variability of
Qðx, sÞps=~ps. In fact, setting ~ps ¼ psQðx, sÞ=QðxÞ, we can make this function
constant with respect to s, and the Monte Carlo estimate (2.35)—perfect for
any N. This, however, involves the expected cost that we want to compute.
Still, our hypothetical construction suggests a way to proceed: use
~ps ¼ psWðx, sÞ=WðxÞ,
ð2:36Þ
with some approximation W of Q. The approximation should be, of course,
nonnegative, easy to compute, and easy to integrate. Clearly, the way in which
such an approximation may be constructed depends on the structure of the
original problem. However, there is a big danger of numerical instability here
(see the chapter on Monte Carlo methods).
In the derivation of
˜P we paid much attention to the accuracy of
the recourse cost estimation (2.35). The same probabilities, though, and the
same observations 
 can be used to construct a subgradient estimate
~gk ¼ ð1=NÞððPN

¼1 gk

p
Þ=~p
Þ, which is consistent with (2.35).
2.5
Extension to convex problems
The Cutting Plane Method can be extended to two-stage problems with
convex objectives of the following form
Min
x2X
f ðxÞ :¼ f1ðxÞ þ
X
S
s¼1
psQsðxÞ
(
)
,
ð2:37Þ
where Qs(x) is the optimal value of the second stage problem
Min
y
f s
2ð yÞ
subject to
Tsx þ Wsy ¼ hs, y 2 Ys:
ð2:38Þ
We assume that the functions f1 : Rn1 ! R and f s
2 : Rn2 ! R, s ¼ 1,. . . , S, are
convex and the sets X and Ys are bounded convex polyhedra. Our model
(2.37)–(2.38) is a special case of the model (2.50)–(2.51) from Chapter 2, but
Ch. 3. Decomposition Methods
157

with linear constraints linking the ﬁrst and the second stage variables, and
with polyhedral domains of the objectives at both stages. Since the sets Ys are
bounded, for every x the second stage problem (2.38) either has an optimal
solution or is infeasible.
The dual to the second stage problem (2.38) has the form
Max

Tðhs  TsxÞ  ð f
s
2 Þ* ðWsÞT
	

n
o
,
ð2:39Þ
where ð f
s
2Þ* is the convex conjugate of the second stage objective,
f
s
2 ð yÞ :¼
f s
2ðyÞ
if y 2 Ys
þ1
otherwise:

We refer the reader to Chapter 2, Sections 2.3 and 2.4, for the derivation of the
dual problem. By the duality theory of convex programming we have that if,
for some x, problem (2.38) has a solution, then the dual problem (2.39) has a
solution, and the optimal values of both problems are equal.3
By Proposition 25 of Chapter 2, each function Qs(  ) is convex and lower
semicontinuous. Proposition 26 of Chapter 2 provides us with the general
form of a subgradient of Qs(x) at points x at which (2.38) has a solution. Due
to the linearity of the constraints and the ﬁniteness of f s
2 we do not need
additional constraint qualiﬁcation conditions and we get
@QsðxÞ ¼ ðTsÞTDsðxÞ,
ð2:40Þ
where Ds(x) is the set of solutions to the dual problem (2.39). Of course, the
elements of Ds(x) are the values of Lagrange multipliers associated with the
constraints of (2.38).
It follows that at every point xk at which the second stage problem (2.38)
has a solution, we can construct an objective cut in a way similar to (2.3):
QsðxÞ  k,s þ ðgk,sÞTx,
for all x 2 Rn1,
ð2:41Þ
where
gk,s ¼ ðTsÞTk,s,
k,s ¼ QsðxkÞ þ ðk,sÞTTsxk,
3 By the polyhedrality of the feasible sets and by the ﬁniteness of f s
2 we do not need additional
constraint qualiﬁcation conditions here.
158
A. Ruszczyn´ski

and k,s 2 Ds(xk). We can also calculate a cut for f1(  ) at xk:
f1ðxÞ  k,0 þ ðgk,0ÞTx,
for all x 2 Rn1,
where
gk,0 2 @f1ðxkÞ,
k,0 ¼ f1ðxkÞ  ðgk,0ÞTxk:
All these objective cuts at xk (if they can be computed successfully) yield a cut
for the overall objective
f ðxÞ  k þ ðgkÞTx,
ð2:42Þ
where
gk ¼ gk,0 þ
X
S
s¼1
psgk,s,
k ¼ k,0 þ
X
S
s¼1
psk,s:
ð2:43Þ
If the second stage problem (2.38) is infeasible, we can derive the feasibility
cut (2.6) exactly as in the linear case, just with the constraint y 2 Ys instead of
y  0 in the Phase I problem (2.7).
The Cutting Plane Method for convex problems is almost identical with the
method for linear problems. It has the master problem
Min v
s:t:
 j þ ðg jÞTx  v,
j 2 Jk
obj,
 j,s þ ðr j,sÞTx  0,
j 2 Jk
feaðsÞ,
s ¼ 1, . . . , S,
x 2 X,
ð2:44Þ
whose solution is denoted (xk þ 1, vk þ 1). The detailed algorithm is presented in
Fig. 3.
To allow starting from infeasible points, we may add the constraint v  M
to (2.44), where M is a lower bound for the optimal cost.
To carry out the convergence analysis of the Cutting Plane Method in the
convex case, we shall need an additional assumption.
Assumption 6. There exists a constant C such that kgk,sk  C for all k ¼ 1, 2,. . .
and all s ¼ 1,. . . , S, whenever Qs(xk)<1.
Ch. 3. Decomposition Methods
159

Due to the boundedness of the sets X and Ys, the linearity of second stage
constraints and the ﬁniteness of f s
2ðÞ, this assumption can always be satisﬁed.
Indeed, we already know that Qs(  ) is lower semicontinuous and sub-
diﬀerentiable at every point of its domain. Moreover, dom Qs is a compact set,
and the existence of bounded subgradients follows from general properties of
convex functions. We can show it in our case directly, by showing the
existence of uniformly bounded Lagrange multipliers k,s at the solutions to
the dual problem (2.38).
Theorem 7. If problem (2.37)–(2.38) has no feasible solutions the Cutting Plane
Method will stop at Step 3 after ﬁnitely many iterations. If problem (2.37)–
(2.38) has feasible solutions then the Cutting Plane Method either stops at Step 2
at an optimal solution, or generates a sequence of points {xk} such that
lim
k!1 f ðxkÞ ¼ f *:
Proof. Since the master problem is a relaxation of (2.37), if the method stops
at Step 3, the original problem is infeasible. Also, we always have vk  f *, so
the method can stop at Step 2 only if xk is optimal. It remains to analyze the
case of inﬁnitely many steps.
The construction and the use of feasibility cuts is the same as in the linear
case, and Lemma 3 remains valid. Thus, if the problem has no feasible
solutions, the method will discover this after ﬁnitely many iterations.
Moreover, if feasible points exist and the method does not stop at an optimal
solution, we shall have f (xk)<1 for all suﬃciently large k.
For ">0 we deﬁne
K" ¼ fk: f * þ " < f ðxkÞ < þ1g:
Step 0. Set k ¼ 1, J0
obj ¼ ;, J0
feaðsÞ ¼ ;, s ¼ 1,. . . , S, v1 ¼ 1.
Step 1. For s ¼ 1,. . . , S solve subproblem (2.38) with x ¼ xk.
(a) If Qs(xk)<1, construct the objective cut (2.41) and set Jk
feaðsÞ ¼ Jk1
fea ðsÞ;
(b) If Qs(xk) ¼ 1 (i.e., problem (2.38) is infeasible), construct the feasibility cut (2.6)
and set Jk
feaðsÞ ¼ Jk1
fea ðsÞ [ fkg.
If Qs(xk)<1 for all s ¼ 1,. . . , S, construct the aggregate objective cut (2.42) and set
Jk
obj ¼ Jk1
obj [ fkg; otherwise set Jk
obj ¼ Jk1
obj .
Step 2. If Q(xk) ¼ vk then stop (optimal solution has been found); otherwise continue.
Step 3. Solve the master problem (2.44). If it is infeasible, stop (the original problem has
no feasible solutions). Otherwise, denote by (xk þ 1, vk þ 1) its solution, increase k by
one, and go to Step 1.
Fig. 3. The cutting plane algorithm for convex problems.
160
A. Ruszczyn´ski

Let k1, k2 2 K" with k1<k2. Since f ðxk1Þ > f * þ " and f *  vk1 there will be a
new objective cut generated at xk1. It will be in the master from k1 on, so it has
to be satisﬁed at xk2:
f ðxk1Þ þ hgk1, xk2  xk1i  vk2  f *:
On the other hand, " < f ðxk2Þ  f *, which combined with the last inequality
yields
" < f ðxk2Þ  f ðxk1Þ  hgk1, xk2  xk1i:
The function f (  ) is subdiﬀerentiable in its domain and X is compact, so there
is a constant C such that f ðx1Þ  f ðx2Þ  Ckx1  x2k, for all x1, x2 2 dom f \ X.
By Assumption 6 we can choose C big enough so that kgkk  C for all k. It
follows that
" < 2Ckxk1  xk2k
for all k1, k2 2 K":
Since the set X is compact, the last inequality implies that the set K" is ﬁnite for
each ">0.
u
Similarly to the linear case, we can develop a multicut version of the
method. It is virtually identical to the method discussed in the preceding
section; the only diﬀerence is that we also need to construct and store cuts for
the ﬁrst stage objective. We leave to the reader the obvious technical details.
Its theoretical convergence properties are exactly the same as those of the
method with aggregate cuts discussed here.
The proof of convergence of the cutting plane method in the convex case
indicates that the problem of deleting inactive cuts is even more acute than in
the linear case. In fact, no reliable rule exists for the deletion of inactive cuts in
the general convex case.
3
Regularized decomposition
3.1
The idea of regularization
The principal diﬃculty associated with cutting plane methods is the growth
of the number of cuts that need to be stored in the master problem. Also, there
is no easy way to make use of a good starting solution.
Ch. 3. Decomposition Methods
161

To mitigate these diﬃculties we add a quadratic regularizing term to the
polyhedral model used in the master problem (2.25). We obtain the following
regularized master problem:
Min
x2X

2 kx  wkk2 þ cTx þ
X
S
s¼1
psQk,sðxÞ
(
)
,
ð3:1Þ
where the models Qk,sðÞ are deﬁned in (2.24). In the proximal term
(/2)kxwkk2, where >0, the center wk is updated depending on the
relations between the value of f(xk þ 1) at the master’s solution, xk þ 1, and its
prediction provided by the current model:
f kðxkþ1Þ :¼ cTxkþ1 þ
X
S
s¼1
psQk,sðxkþ1Þ:
ð3:2Þ
Recall that f(  ) is our true objective (see (1.3)). If these values are equal or
close, we set wk þ 1 ¼ xk þ 1 (serious step); otherwise wk þ 1 ¼ wk (null step). In
any case, the collections of objective and feasibility cuts are updated, and the
iteration continues.
We present the Regularized Decomposition Method in its most eﬃcient
multicut version. A method with averaged cuts can be developed and analyzed
in an identical way.
The regularized master can be equivalently formulated as a quadratic
programming problem
Min cTx þ
X
S
s¼1
psvs þ 
2 kx  wkk2
(
)
ð3:3Þ
j,s þ ðg j,sÞTx  vs,
j 2 Jk
objðsÞ,
s ¼ 1, . . . , S,
ð3:4Þ
j,s þ ðr j,sÞTx  0,
j 2 Jk
feaðsÞ,
s ¼ 1, . . . , S,
ð3:5Þ
Ax ¼ b, x  0:
ð3:6Þ
The detailed algorithm is stated in Fig. 4. As before, we assume that the initial
point x1 is such that Q(x1)<1. Also, 	 2 (0, 1) is a ﬁxed constant used to
compare the observed improvement in the objective value to the predicted
improvement.
162
A. Ruszczyn´ski

3.2
Relation to the proximal point method
To
understand
the
mechanism
of
convergence
of
the
Regularized
Decomposition Method, let us suppose that the models Qk,sðÞ in the master
problem (3.1) are exact: Qk,sðxÞ ¼ QsðxÞ for all x 2 Rn1 and all s ¼ 1,. . . , S.
Consider the optimal value of such an ideal master problem
fðwÞ :¼ min
x2X

2 kx  wk2 þ cTx þ
X
S
s¼1
psQsðxÞ
(
)
:
ð3:7Þ
The function f(  ) is called the Moreau–Yosida regularization of f(  ). If
dom f \ X 6¼ ;, its regularization has many remarkable properties: convexity,
continuous diﬀerentiability, Lipschitz continuity with constant 1, etc. For our
purposes, its relations to f are of primary importance.
Lemma 8. Suppose that there exists ~x 2 X such that f ð ~xÞ < f ðwÞ. Then
fðwÞ  f ðwÞ  k ~x  wk2’ f ðwÞ  f ð ~xÞ
k ~x  wk2


,
Step 0. Set k ¼ 1, J0
objðsÞ ¼ ;, J0
feaðsÞ ¼ ;, v1,s ¼ 1, s ¼ 1,. . . , S.
Step 1. For s ¼ 1,. . . , S solve subproblem (1.4) with x ¼ xk.
(a) If Qs(xk)<1 then set Jk
feaðsÞ ¼ Jk1
fea ðsÞ. If Qs(xk)>vk,s then construct the objective
cut (2.3) and set Jk
objðsÞ ¼ Jk1
obj ðsÞ [ fkg; otherwise set Jk
objðsÞ ¼ Jk1
obj ðsÞ.
(b) If Qs(xk) ¼ 1 (i.e., problem (1.4) is infeasible), construct the feasibility cut (2.6) and
set Jk
objðsÞ ¼ Jk1
obj ðsÞ, Jk
feaðsÞ ¼ Jk1
fea ðsÞ [ fkg.
Step 2. If k ¼ 1 or if
f ðxkÞ  ð1  	Þf ðwk1Þ þ 	f k1ðxkÞ,
then set wk ¼ xk; otherwise set wk ¼ wk1.
Step 3. Solve the master problem (3.3)–(3.6). If it is infeasible, stop (the original problem
has no feasible solutions). Otherwise, denote by (xk þ 1, vk þ 1) its solution and set
f kðxkþ1Þ ¼ cTxkþ1 þ PS
s¼1 psvkþ1,s.
Step 4. If f k(xk þ 1) ¼ f(wk) then stop (wk is an optimal solution); otherwise continue.
Step 5. Remove from the sets of cuts Jk
objðsÞ and Jk
feaðsÞ, s ¼ 1,. . . , S, some (or all) cuts
whose Lagrange multipliers at the solution of (3.3)–(3.6) were 0. Increase k by one, and
go to Step 1.
Fig. 4. The regularized decomposition algorithm.
Ch. 3. Decomposition Methods
163

where
’ðÞ ¼
0
if  < 0,
2
if 0    1,
1 þ 2
if  > 1:
8
<
:
Proof. By convexity, the entire segment containing points x ¼ w þ tð ~x  wÞ
with 0  t  1 is feasible for (3.7). Restricting the minimization to these x will
provide an upper bound:
fðwÞ  min
0t1 f ðð1  tÞw þ t ~xÞ þ t2
2
k ~x  wk2


 f ðwÞ þ min
0t1 tð f ð ~xÞ  f ðwÞÞ þ t2
2
k ~x  wk2


:
In the last estimate we also used the convexity of f(  ). The value of t that
minimizes the above expression is equal to
^t ¼ min 1, f ðwÞ  f ð ~xÞ
k ~x  wk2


:
Our assertion follows now from a straightforward calculation.
u
At the solution x(w) of problem (3.7) we shall have
f ðxðwÞÞ  fðwÞ  f ðwÞ  k ~x  wk2’ f ðwÞ  f ð ~xÞ
k ~x  wk2


:
Therefore, if a better point exists, the ideal master (3.7) will ﬁnd a better point.
Consequently, x ¼ w is the minimizer in (3.7) if and only if w is a minimizer
of f.
In fact, the Proximal Point Method,
wkþ1 ¼ xðwkÞ,
k ¼ 1, 2, . . .
ð3:8Þ
must converge to an optimal solution, if an optimal solution exists.
Theorem 9. Suppose that problem (1.3) has an optimal solution. Then the
sequence {wk} generated by the Proximal Point Method is convergent to an
optimal solution of (1.3).
164
A. Ruszczyn´ski

Proof. Let x* be an optimal solution. We have the identity
kwkþ1x*k2 ¼ kwk  x*k2 þ 2hwkþ1  wk, wkþ1  x*i  kwkþ1  wkk2:
ð3:9Þ
The necessary condition of optimality for (3.7) at the solution wk þ 1 ¼ x(wk)
yields
0 2 @ f ðxÞ þ 
2 kx  wkk2
h
i
,
at x ¼ wkþ1:
Thus,
ðwkþ1  wkÞ 2 @f ðwkþ1Þ:
ð3:10Þ
By the subgradient inequality,
f ðx*Þ  f ðwkþ1Þ  hwkþ1  wk, x*  wkþ1i:
Using this inequality in (3.9) (and skipping the last term) we obtain
kwkþ1  x*k2  kwk  x*k2  2
 ð f ðwkþ1Þ  f ðx*ÞÞ:
ð3:11Þ
Several conclusions follow from this inequality. First, the sequence {wk} is
bounded, because the distance to x* is nonincreasing. Secondly, summing up
(3.11) from k ¼ 1 to 1, we get
X
1
k¼2
ð f ðwkÞ  f ðx*ÞÞ  
2 kw1  x*k2,
so f (wk) ! f (x*). Consequently, for every accumulation point ~x of {wk} we
have f ð ~xÞ ¼ f ðx*Þ. We choose one such ~x, substitute it for x* in (3.11) and
conclude that the entire sequence {wk} is convergent to ~x.
u
It is easy to see that we have not used in our analysis the fact that f is
polyhedral; Theorem 9 remains true for any convex function f which has a
minimum.4 For polyhedral f the convergence is ﬁnite.
4 A more general view on the Proximal Point Method is presented in Section 9.2.
Ch. 3. Decomposition Methods
165

Theorem 10. Suppose that f is a convex polyhedral function and that a minimum
of f exists. Then the Proximal Point Method stops after ﬁnitely many steps at a
minimizer of f.
Proof. Suppose that the method does not stop. Therefore, 0 62 @f(wk þ 1),
k ¼ 1, 2,. . . and thus,
0 62
[
1
k¼1
@f ðwkþ1Þ:
Since f is polyhedral, only ﬁnitely many diﬀerent subdiﬀerentials @f(wk þ 1)
exist. Each of them is a convex closed polyhedral set, so the right hand side of
the last displayed relation is a union of ﬁnitely many closed sets. Thus, it is
closed. Consequently, there exists ">0 such that the ball B(0, ") of radius "
centered at 0 has no common points with this union of subdiﬀerentials. We get
Bð0, "Þ \ @f ðwkþ1Þ ¼ ;,
k ¼ 1, 2, . . . :
Since the sequence {wk} is convergent by Theorem 9, we have wk þ 1wk ! 0.
Therefore, (wk þ 1wk) 2 B(0, ") for large k and we obtain a contradiction
with (3.10).
u
3.3
Convergence of the regularized decomposition method
The main diﬀerence between the Regularized Decomposition Method (and
bundle methods, in general) and the Proximal Point Method (see Section 3.2) is
that the master problem (3.1) uses a model f k(  ) instead of the true function
f (  ). Recall that
f kðxÞ ¼
cTx þ PS
s¼1 psQk,sðxÞ
if x 2 X,
þ1
otherwise:

Its minimizer, xk þ 1, is no longer guaranteed to be better than wk. The role of
null steps is to correct the model f k, if xk þ 1 is not better than wk. We shall see
that such model improvements ensure that progress will be made whenever
any progress is possible.
The analysis of convergence of the Regularized Decomposition Method
requires an additional assumption.
Assumption 11. There exists a constant C such that kgk,sk  C for all
k ¼ 1, 2,. . . and all s ¼ 1,. . . , S, whenever Qs(xk)<1.
166
A. Ruszczyn´ski

It is clearly satisﬁed if basic objective cuts are employed. Also, if
dom Qs ¼ Rn1, by the polyhedrality of Qs, Assumption 11 holds. The only
situation, in which a potential for violating this assumption exists, is when xk is
a boundary point of dom Qs, in which case arbitrary large elements of the
normal cone to dom Qs may be added to the subgradient of Qs(  ).
Technically, in such a situation the active second stage constraints are linearly
dependent and arbitrary large multipliers k,s may be used in formula (2.4).
If our method for solving the second stage problem does not exhibit such
properties, Assumption 11 will hold in this case, too.
By the construction of the method, the sequence { f(wk)} is nonincreasing.
Our ﬁrst result shows that the algorithm cannot get stuck at a nonoptimal
point.
This property is obvious when basic cuts are employed, because each new
cut added at Step 1 cuts the current master’s solution oﬀ. As a result, due to
the strict convexity of the master’s objective, the optimal value of (3.1)
increases after each null step. Since the number of possible combinations of
basic cuts is ﬁnite, either a serious step will occur, or the stopping test of Step 4
will be satisﬁed.
For general subgradient cuts we need some analysis, but the conclusion
remains the same.
Lemma 12. Suppose that wk is not an optimal solution of problem (1.3). Then
there exist m>k such that f (wm)<f (wk).
Proof. Suppose that null steps are made at iterations j ¼ k þ 1, k þ 2,. . . . Thus
wj ¼ wk and
f ðx jÞ > f j1ðx jÞ þ ð1  	Þð f ðw j1Þ  f j1ðx jÞÞ:
Denote j ¼ f ðw kÞ  f j1ðx jÞ. We have
f ðx jÞ > f j1ðx jÞ þ ð1  	Þj:
ð3:12Þ
We shall show that the optimal value of the master problem increases by a
quantity related to j, when new objective cuts are added.
First, the master’s optimal value will not change, if we delete inactive cuts.
We shall denote the model without inactive cuts by f j1ðxÞ. Subdiﬀerentiating
(3.1) we see that (wkx j ) is a subgradient of f j1ðÞ at x j, because x j is the
master’s solution. Thus,
f jðxÞ  f j1ðxÞ  f j1ðx jÞ þ hwk  x j, x  x ji,
for all x:
ð3:13Þ
Ch. 3. Decomposition Methods
167

Secondly, by (3.12), after adding new objective cuts at x j we shall have
f jðx jÞ > f j1ðx jÞ þ ð1  	Þj:
Therefore, for all x,
f jðxÞ > f j1ðx jÞ þ ð1  	Þj þ hg, x  x ji,
where g 2 @f j(x j). Combining (3.13) with the last inequality we obtain
f jðxÞmaxð f j1ðx jÞþhw kx j, xx ji, f j1ðx jÞþð1	Þjþhg, xxjiÞ
 f j1ðx jÞ þ hw k  x j, x  x ji
þ maxð0, ð1  	Þj þ hg   ðw k  x jÞ, x  x jiÞ:
Consequently, the next master’s objective can be estimated from below as
follows:
f jðxÞ þ 
2 kx  wkk2  f j1ðx jÞ þ hw k  x j, x  x ji þ 
2 kx  w kk2
þ maxð0, ð1  	Þj þ hg  ðw k  x jÞ, x  x jiÞ
¼ f j1ðx jÞ þ 
2 kx j  w kk2 þ 
2 kx  x jk2
þ maxð0, ð1  	Þj þ hg  ðw k  x jÞ, x  x jiÞ:
It follows that the master’s optimal value,
j ¼ f jðx jþ1Þ þ 
2 kx jþ1  w kk2,
satisﬁes the inequality
j  j1  min
x2X

2 kxx jk2þmaxð0, ð1	Þjþhgðw kx jÞ, xx jiÞ
h
i
 min
h2R
h2
2 þ maxð0, ð1  	Þj  2ChÞ


,
where in the last relation we have used the estimates kgk  C and
kðw k  x jÞk  C:
168
A. Ruszczyn´ski

The right hand side of the above expression can be estimated as follows.
If (1	)j  4C2/ we have
h ¼ ð1  	Þj=ð2CÞ,
j  j1  ð1  	Þ22
j =ð8C2Þ,
otherwise
h ¼ 2C=,
j  j1  2C2= þ ð1  	Þj  ð1  	Þj=2:
The sequence {j} is increasing and bounded above by f (wk). If there
are no serious steps after iteration k we conclude that j ! 0. Since
f (wk)  j  f (wk)j þ 1, we have j"f (wk).
On the other hand, the master’s objective is bounded above by the Moreau–
Yosida regularization (3.7)
j  fðw jÞ ¼ fðwkÞ:
If wk is not optimal, Lemma 8 yields f(wk)<f(wk) and we obtain a
contradiction.
u
We are now ready to prove the convergence of the Regularized
Decomposition Method. Our analysis will have much in common with the
analysis of the Proximal Point Method.
Theorem 13. Suppose that problem (1.3) has an optimal solution. Then the
Regularized Decomposition Method generates a sequence {wk} which is
convergent to an optimal solution of (1.3).
Proof. If wk is optimal for some k, then w j þ 1 ¼ w j for j ¼ k, k þ 1,. . . , and the
theorem is true. If wk is not optimal for any k, then, by Lemma 12, each series
of null steps is ﬁnite and is followed by a serious step. Thus, the number of
serious steps is inﬁnite. Let us denote by K the set of iterations at which
serious steps occur. If wk þ 1 ¼ xk þ 1 is the optimal solution of the master (3.1),
we have the necessary condition of optimality
0 2 @ f kðxÞ þ 
2 kx  wkk2
h
i
,
at x ¼ wkþ1:
Thus,
ðwkþ1  wkÞ 2 @f kðwkþ1Þ:
Ch. 3. Decomposition Methods
169

Let x* be an optimal solution of (1.3). By the subgradient inequality for f k
we get
f kðx*Þ  f kðwkþ1Þ  hwkþ1  wk, x*  wkþ1i:
ð3:14Þ
There is a serious step from wk to wk þ 1 ¼ xk þ 1, so the test of Step 2 is satisﬁed
(for k þ 1):
f ðwkþ1Þ  ð1  	Þf ðwkÞ þ 	f kðwkþ1Þ:
After elementary manipulations we can rewrite it as
f kðwkþ1Þ  f ðwkþ1Þ  1  	
	
½ f ðwkÞ  f ðwkþ1Þ:
ð3:15Þ
Combining the last inequality with (3.14) and using the obvious relation
f (x*)  f k(x*) we obtain
f ðx*Þ  f ðwkþ1Þ þ 1  	
	
½ f ðwkþ1Þ  f ðwkÞ  hwkþ1  wk, x*  wkþ1i:
This can be substituted to the identity (3.9) which, after skipping the last term,
yields
kwkþ1  x*k2  kwk  x*k2  2
 ½ f ðwkþ1Þ  f ðx*Þ
þ 2ð1  	Þ
	
½ f ðwkÞ  f ðwkþ1Þ
for all k 2 K:
ð3:16Þ
It is very similar to inequality (3.11) in the proof of Theorem 9, and our
analysis will follow the same line.
The series P1
k¼1 ½ f ðwkÞ  f ðwkþ1Þ is convergent, because { f (wk)} is
nonincreasing and bounded from below by f (x*). Therefore, we obtain
from (3.16) that the distance kwk þ 1x*k is uniformly bounded, and {wk}
must have accumulation points.
Summing up (3.16) for k 2 K we get
X
k2K
ð f ðwkþ1Þ  f ðx*ÞÞ  
2 kw1  x*k2 þ 1  	
	
f ðw1Þ  lim
k!1 f ðwkÞ


,
170
A. Ruszczyn´ski

so f (wk þ 1) ! f (x*), k 2 K. Consequently, at every accumulation point ~x
of {wk} one has f ð ~xÞ ¼ f ðx*Þ. Since ~x is optimal, we can substitute it for x* in
(3.16). Skipping the negative term we get
kwkþ1  ~xk2  kwk  ~xk2 þ 2ð1  	Þ
	
½ f ðwkÞ  f ðwkþ1Þ:
It is true not only for k 2 K but for all k, because at k 62 K we
have a trivial equality here. Summing these inequalities from k ¼ j to k ¼ l>j
we get
kwlþ1  ~xk2  kwj  ~xk2 þ 2ð1  	Þ
	
½ f ðw jÞ  f ðw lþ1Þ:
Since ~x is an accumulation point, for any ">0 we can ﬁnd j such that
kw j  ~xk  ". Also, if j is large enough, f (w j )f (w l þ 1)  " for all l>j, because
{ f(wk)} is convergent. Then kwlþ1  ~xk2  "2 þ 2"ð1  	Þ=ð	Þ for all l>j, so
the entire sequence {wk} is convergent to ~x.
u
Let us now prove a useful technical property of the Regularized
Decomposition Method.
Remark 14. Under the conditions of Theorem 13,
lim
k!1 k ¼ f *,
ð3:17Þ
lim
k!1 f kðxkþ1Þ ¼ f *,
ð3:18Þ
lim
k!1ðxkþ1  wkÞ ¼ 0,
ð3:19Þ
where f * is the optimal value of our problem.
Proof. We shall prove at ﬁrst that
f ðwkÞ  	k  f ðwk1Þ  	k1,
k ¼ 1, 2, . . . :
ð3:20Þ
Ch. 3. Decomposition Methods
171

The inequality is true at all null steps, as shown in the proof of Lemma 12. If
there is serious step at iteration k, we get from (3.13) that
k  min
x
f kðxÞ þ 
2 kx  wkk2
h
i
 min
x
f k1ðwkÞ þ hwk1  wk, x  wki þ 
2 kx  wkk2
h
i
¼ f k1ðwkÞ  
2 kwk  wk1k2
¼ k1  kwk  wk1k2:
ð3:21Þ
The test for a serious step is satisﬁed, so
f ðwk1Þ  f ðwkÞ  	½ f ðwk1Þ  f k1ðwkÞ
¼ 	½ f k1ðwk1Þ  f k1ðwkÞ  	kwk  wk1k2,
where in the last transformation we have used (3.13) again. Combining the last
relation with (3.21) we obtain (3.20), as required.
The optimal value of the master satisﬁes the inequality k  f (wk), so
f ðwkÞ  	k  ð1  	Þf ðwkÞ  ð1  	Þ f *:
It follows from (3.20) that the sequence { f (wk)	k} is convergent, hence {k}
is convergent. If there is a serious step at iteration k, inequality (3.15) implies
that
f ðwkÞ  k  f kðwkþ1Þ  f ðwkþ1Þ  1  	
	
½ f ðwkÞ  f ðwkþ1Þ:
Both sides converge to f * as k ! 1, k 2 K, so k ! f * at serious steps. But the
entire sequence {k} is convergent and (3.17) follows.
The objective of the master problem (3.1) is strictly convex. Therefore, its
value at wk can be estimated by using its minimum value, k, and the distance
to the minimum, kwkxk þ 1k, as follows:
f ðwkÞ  k þ 
2
wk  xkþ1

2:
Therefore,
0  
2 wk  xkþ1

2 f ðwkÞ  k:
172
A. Ruszczyn´ski

Since the right hand side converges to zero, (3.19) holds. Relation (3.18)
follows directly from it.
u
If problem (1.3) has feasible solutions but is unbounded, the Regularized
Decomposition Method generates a sequence {wk} such that f(w k) ! 1. To
prove this suppose that f(wk) remains bounded from below. Then we can
choose x* such that f(x*)<f(wk) for all k, and inequality (3.16) remains true.
Thus, f(wk) ! f(x*) as proved in the above theorem. But f(x*) can be made
arbitrarily small by the choice of x*, and we obtain absurd.
Our analysis, so far, did not rely on the fact that the function f(  ) is
polyhedral. Actually, the convexity and Assumption 11 are suﬃcient for the
convergence of the Regularized Decomposition Method to a solution, if a
solution exists.
In the polyhedral case we can prove ﬁnite convergence of the method,
provided that basic cuts are employed and that the deletion rules are slightly
reﬁned.
Lemma 15. Suppose that problem (1.3) has an optimal solution. Assume that the
Regularized Decomposition Method uses basic objective and feasibility cuts. If
the method does not stop then the number of serious steps is inﬁnite and there
exists k0 such that for all k>k0
xkþ1 ¼ arg min f kðÞ,
ð3:22Þ
and
f kðxkþ1Þ ¼ f *,
ð3:23Þ
where f * denotes the optimal value of f.
Proof. By Theorem 13, the sequence {wk} is convergent to some optimal
solution x*. If the number of serious steps is ﬁnite, we must have wk ¼ x* for
all suﬃciently large k. We have already discussed such a situation before
Lemma 12. Since each new cut added at Step 1 cuts the current master’s
solution oﬀ, the optimal value of (3.1) increases after each null step. The
number of possible combinations of basic cuts is ﬁnite, so the stopping test of
Step 4 must activate. Thus, if the method does not stop, the number of serious
steps must be inﬁnite.
Let us now look more closely at the master problem (3.1). The necessary
condition of optimality for (3.1) implies
ðxkþ1  wkÞ 2 @f kðxkþ1Þ:
ð3:24Þ
Ch. 3. Decomposition Methods
173

There are only ﬁnitely many models f k(  ) possible and each of them, as a
polyhedral function, has ﬁnitely many diﬀerent subdiﬀerentials. Therefore,
the quantity dist(0, @f k(xk þ 1)) may take only ﬁnitely many diﬀerent values.
Since the left hand side of (3.24) converges to zero by Remark 14, we must
have
0 2 @f kðxkþ1Þ
for all suﬃciently large k, so (3.22) is true.
Since only ﬁnitely many diﬀerent minimum values of models f k(  ) may
occur, Remark 14 implies (3.23) for all suﬃciently large k.
u
It follows that in the case of inﬁnitely many steps, the serious steps of the
Regularized Decomposition Method look (for all suﬃciently large k) similarly
to the steps of the Cutting Plane Method. The only role of the regularizing
term at these late iterations is to select the solution of the linear master
problem that is closest to the current center wk. We also see that the minimum
value of the linear master does not change and remains equal to the minimum
value of the original problem. We need, therefore, to exclude the possibility of
inﬁnitely many such degenerate iterations. To achieve this, we need to slightly
modify the algorithm.
The simplest modiﬁcation is to forbid deletion of cuts at any iteration k at
which the value of the linear part of the master’s objective does not change,
i.e., when
f kðxkþ1Þ ¼ f k1ðxkÞ:
Indeed,
by
Lemma
15,
after
ﬁnitely
many
steps
the
Regularized
Decomposition Method will enter the phase when (3.23) holds. From then
on, no deletion will take place. By (3.22) the optimal solution of each master
problem is the same as the optimal solution of the master problem (2.25) of the
multicut method. By Theorem 5, the method will stop after ﬁnitely many steps.
The possibility to delete inactive cuts is one of the main computational
advantages
of
the
Regularized
Decomposition
Method.
It
becomes
particularly important when the number of scenarios S is much larger than
the dimension n1 of the ﬁrst stage vector x. The number of linearly
independent active cuts in (3.1) cannot exceed n1 þ S. Since each of S models
Qk,s(  ) must have at least one active objective cut, it follows that at most n1 of
them will be represented by more than one active cut. We call them critical
scenarios. All the other scenarios can be suﬃciently well represented by linear
models. Increasing S can only increase the number of noncritical scenarios,
which do not contribute much to the complexity of the problem. Clearly, the
set of critical scenarios depends on the current data: , wk, f k. Our algorithm
can be viewed as an iterative way of updating this set, by introducing new cuts
174
A. Ruszczyn´ski

to some scenarios (possibly making them critical) and removing cuts from
some other scenarios (possibly making them noncritical). The notion of
critical scenarios can also be exploited in developing methods for the solution
of the master problem (3.1).
The eﬃciency of the Regularized Decomposition Method can be improved
by dynamically changing the proximal parameter, . The general principle
is clear: if the steps are too long, increase , if they are too short, decrease .
A good way to decide whether steps are too long is to observe the diﬀerence
k ¼ f ðxkÞ  f ðwk1Þ:
We know that if it is positive (actually, not suﬃciently negative) a null step will
be made. If k is large, for example larger than f(wk1)f k1(xk), it is
advisable to increase . On the other hand, when f(xk) ¼ f k1(xk), we may
conclude that the step is too short, because we do not learn new cuts, so  has
to be decreased. Detailed rules are discussed in the literature listed at the end
of this chapter.
Another practical question associated with the Regularized Decomposition
Method is the solution of the master problem (3.1). While for linear master
problems, like (2.25), commercially available linear programming solvers may
be employed, the regularized master requires a quadratic programming solver.
Fortunately, the quadratic regularizing term is particularly simple, just the
sum of squares, so the problem is very stable.
To allow infeasible starting points, we may add the constraints vs  M to
the master (3.3)–(3.6), where M is a lower bound for the optimal cost. If no
feasible solution exists, the method will discover it in ﬁnitely many steps.
4
Trust region methods
One of the advantages of the Regularized Decomposition Method over the
Cutting Plane Method is the ability to control the length of the steps made. It
avoids making long shots towards minima of poor approximations and it
makes good use of a reasonable initial point. Another way to prevent
ineﬃcient long steps is to explicitly limit the step size in the master problem
(2.11)–(2.14) or in its multicut version (2.25). This is the idea of Trust Region
Methods. The trust region master has the form
Min
x2X
cTx þ
X
S
s¼1
psQk,sðxÞ
(
)
,
ð4:1Þ
s:t:
kx  wkk*  :
ð4:2Þ
Ch. 3. Decomposition Methods
175

Here, similarly to the Regularized Decomposition Method, wk is the ‘‘best’’
point found so far. The role of the constraint (4.2) is to keep the master’s
solution, xk þ 1, in a neighborhood of wk: a ball of radius >0 centered at wk.
From the theoretical point of view, the norm k  k* may be any norm in Rn1.
However, if we use the Euclidean norm, the master problem (4.1)–(4.2)
becomes a quadratically constrained optimization problem. There is no
advantage of using it instead of the regularized decomposition master (3.1).
Indeed, if k is the Lagrange multiplier associated with the constraint
kx  wkk2  2,
which is equivalent to (4.2), then xk þ 1 is also a solution of the regular-
ized master (3.1) with  ¼ 2k. For these reasons we shall discuss the Trust
Region Method with
kdk* ¼ max
1 j n1 jdjj:
Then the constraint (4.2) can be represented as simple bounds
  xj  wk
j  ,
j ¼ 1, . . . , n1,
and the master problem (4.1)–(4.2) becomes a linear programming problem.
Our presentation of the Trust Region Method will be very similar to the
description of the Regularized Decomposition Method. We use f k(x) to
denote the master’s objective:
f kðxÞ ¼
cTx þ PS
s¼1 psQk,sðxÞ
if x 2 X,
þ1
otherwise:

As before, we assume that the initial point x1 is such that Q(x1)<1. Also,
	 2 (0, 1) is a parameter of the method used to judge whether the master’s
solution, xk þ 1, is signiﬁcantly better than wk. The detailed algorithm is
presented in Fig. 5.
The analysis of convergence of the Trust Region Method is much easier
than in the case of the Regularized Decomposition Method.
Theorem 16. Suppose that problem (1.3) has an optimal solution. Then the
sequence {wk} generated by the Trust Region Method has the property that
lim
k!1 f ðwkÞ ¼ f *,
where f * is the optimal value of (1.3).
176
A. Ruszczyn´ski

Proof. Suppose that the number of serious steps is ﬁnite and let w denote the
last point to which a serious step has been made. After the last serious step,
the Trust Region Method becomes identical with the Cutting Plane Method
(in its multicut version), for problem (1.3) with the additional constraint
that kxwk*  . By Theorem 5 we have that { f(xk)} is convergent to the
minimum value of the problem having the additional constraint kxwk*  .
This minimum value must be equal to f(w), if no serious steps are made after
w. Thus f (w) ¼ f *, since otherwise a small step from w towards an optimal
solution x* would guarantee improvement.
Let us now consider the case of inﬁnitely many serious steps. Let x* be a
solution of problem (1.3), and let
hk ¼ kwk  x*k*:
Suppose that there is a serious step after iteration k, that is wk þ 1 ¼ xk þ 1.
Then we have (by the rule of Step 2)
f ðxkþ1Þ  f *  ð1  	Þð f ðwkÞ  f *Þ þ 	ð f kðxkþ1Þ  f *Þ:
ð4:3Þ
If hk  , then x* is feasible for the master problem and
f kðxkþ1Þ  f kðx*Þ  f ðx*Þ:
Step 0. Set k ¼ 1, J0
objðsÞ ¼ ;, J0
feaðsÞ ¼ ;, v1,s ¼ 1, s ¼ 1,. . . , S.
Step 1. For s ¼ 1,. . . , S solve subproblem (1.4) with x ¼ xk.
(a) If Qs(xk)<1 then set Jk
feaðsÞ ¼ Jk1
fea ðsÞ. If Qs(xk)>vk,s then construct the objective
cut (2.3) and set Jk
objðsÞ ¼ Jk1
obj ðsÞ [ fkg; otherwise set Jk
objðsÞ ¼ Jk1
obj ðsÞ.
(b) If Qs(xk) ¼ 1 (i.e., problem (1.4) is infeasible), construct the feasibility cut (2.6) and
set Jk
objðsÞ ¼ Jk1
obj ðsÞ, Jk
feaðsÞ ¼ Jk1
fea ðsÞ [ fkg.
Step 2. If k ¼ 1 or if
f ðxkÞ  ð1  	Þf ðwk1Þ þ 	f k1ðxkÞ,
then set wk ¼ xk; otherwise set wk ¼ wk1.
Step 3. Solve the master problem (4.1)–(4.2). If it is infeasible, stop (the original problem
has no feasible solutions). Otherwise, denote by (xk þ 1, vk þ 1) its solution and set
f kðxkþ1Þ ¼ cTxkþ1 þ PS
s¼1 psvkþ1,s.
Step 4. If f k(xk þ 1) ¼ f (wk) then stop (wk is an optimal solution); otherwise increase k by
one, and go to Step 1.
Fig. 5. The trust region algorithm.
Ch. 3. Decomposition Methods
177

This combined with (4.3) yields
f ðxkþ1Þ  f *  ð1  	Þð f ðwkÞ  f *Þ:
Suppose now that hk>. Consider the point
~x ¼ 
hk
x* þ
1  
hk


wk:
By construction, its distance to w k is . Since it is feasible for the master
problem, we have
f kðxkþ1Þ  f *  f kð ~xÞ  f * 
1  
hk


ð f ðwkÞ  f *Þ,
where we have also used the convexity of f k(  ). Combining this inequality
with (4.3) we see that
f ðxkþ1Þ  f * 
1  	
hk


ð f ðwkÞ  f *Þ:
In both cases, if there is a serious step after iteration k we have
f ðwkþ1Þ  f * 
1 
	
maxð, hkÞ


ð f ðwkÞ  f *Þ:
Let the index l ¼ 1, 2, . . . number the serious steps only and let us write l for
the value of f(wk)f * at the l-th new center wk. The last inequality can be then
rewritten as
lþ1 
1 
	
maxð, hkðlÞÞ


l,
l ¼ 1, 2, . . . ,
where k(l ) is the iteration number at which the l-th serious step is made. By the
triangle inequality for the norm k  k* we have
hkðlÞ  h1 þ l:
178
A. Ruszczyn´ski

Therefore,
lþ1 
1 
	
h1 þ l


l,
l ¼ 1, 2, . . . ,
ð4:4Þ
The sequence {l} is decreasing and bounded from below by 0. Suppose that
l  ">0 for all l. Then, summing (4.4) from l ¼ 1 to m we obtain
0  mþ1  1  "	
X
m
l¼1
1
h1 þ l ,
which yields a contradiction as m ! 1, because the series P1
l¼1 l1 is
divergent. Thus l ! 0.
u
Let us observe that we have not used the polyhedrality of f(  ) in our
analysis. In fact, Theorem 16 remains true for the convex problem (2.37)–
(2.38). The proof can be repeated verbatim, only at the beginning, in the case
of ﬁnitely many serious steps, we have to use Theorem 7 instead of Theorem 5.
Also, similarly to the analysis of the Regularized Decomposition Method,
we can prove that f(wk) ! inf f even if the problem has no solution.5 Indeed,
suppose that there exists f *>inf f such that f(wk)  f * for all k. Then Theorem
16 implies that f(wk) ! f *. But f * can be chosen arbitrarily close to inf f, and
the result follows.
In the linear case we can prove the ﬁnite convergence of the Trust Region
Method.
Theorem 17. The Trust Region Method ﬁnds an optimal solution of problem
(1.3) after ﬁnitely many steps.
Proof. If the number of serious steps is ﬁnite, the result follows from
Theorem 5. Suppose that the number of serious steps is inﬁnite. It follows
from Theorem 16 that, for suﬃciently large k, there exists an optimal solution
in the -neighborhood of wk. Therefore,
f kðxkþ1Þ  f *,
for all suﬃciently large k.
Proceeding as in the proof of Theorem 5 we conclude that the number of
steps at which new cuts are added to the master problem must be ﬁnite,
because there are ﬁnitely many cells of linearity of f(  ). Thus,
f ðxkþ1Þ ¼ f kðxkþ1Þ
5 inf f denotes the inﬁmum of f over the feasible set of (1.3).
Ch. 3. Decomposition Methods
179

for all suﬃciently large k. Combining the last two relations we see that we
must have f(xk þ 1) ¼ f * for all suﬃciently large k. Consequently, only one
serious step can be made after that, a contradiction.
u
As in the case of the Cutting Plane Method, deleting inactive cuts is not
easy. If we use basic cuts alone, we may aﬀord deleting inactive cuts whenever
the optimal value of the master problem increases. For general subgradient
cuts, no reliable rule can be found. Things are easier if we use the Euclidean
norm for the trust region deﬁnition, because the arguments from the analysis
of the Regularized Decomposition Method apply here. Using Euclidean
norms, though, does not provide any signiﬁcant beneﬁts over the Regularized
Decomposition Method.
The size of the trust region , similarly to the parameter  of the
Regularized Decomposition Method, can be adjusted in the course of
computation. If f(xk þ 1) is signiﬁcantly larger than f k(xk þ 1), we may decrease
 to avoid too long steps. If no new cuts are generated, we may increase  to
allow longer steps.
The Trust Region Method has been deﬁned and analyzed under the
assumption that a feasible starting point, x1, is known. If such a point is not
readily available, we may add the constraints vs  M to (2.14), and start the
method with some >0. If inconsistency is detected (which must happen after
ﬁnitely many steps by Theorem 5), we may increase , and repeat the
procedure. If (1.3) has feasible points, after ﬁnitely many such adjustments a
feasible point will be found. After that, we may return to a smaller , if we wish.
5
Nested cutting plane methods for multistage problems
5.1
Basic ideas
The idea of cutting plane methods can be extended to linear and polyhedral
multistage stochastic programming problems with ﬁnitely many scenarios. We
shall present it for the polyhedral model analyzed in detail in Chapter 2. The
problem has the form:
Min
E
n
f1ðx1, 1Þ þ f2ðx2, 2Þ þ f3ðx3, 3Þ þ    þ fTðxT, TÞ
o
s:t:
A11ð1Þx1
¼ b1ð1Þ,
A21ð2Þx1
þ
A22ð2Þx2
¼ b2ð2Þ,
A32ð3Þx2
þ
A33ð3Þx3
¼ b3ð3Þ,
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
AT,T1ðTÞxT1
þ
ATTðTÞxT
¼ bTðTÞ,
ð5:1Þ
180
A. Ruszczyn´ski

where ft, t ¼ 1,. . . , T, are random polyhedral functions, as deﬁned in Chapter 2.
In (5.1) each xt ¼ xt([1,t]) is a function of [1,t], the random data of the
problem. We assume that the process  has ﬁnitely many scenarios:
s ¼ ðs
1, . . . , s
TÞ, each of them with probability ps>0.
The probabilistic structure of the random data can be given in the form of a
scenario tree. It has nodes arranged at levels which correspond to stages
1, 2,. . . , T. At level 1 we have only one root node, and we associate with it the
value of 1 (which is known at stage 1). At level 2 we have at least as many
nodes as many diﬀerent realizations of 2 may occur. Each of them is
connected with the root node by an arc. For each node i at level 2 (which
corresponds to a particular realization ðiÞ
2 of 2) we create at least as many
nodes at level 3 as diﬀerent values of 3 may follow ðiÞ
2 , and we connect
them with the node i, etc. Generally, nodes at level t correspond to possible
values of t that may occur. Each of them is connected to a unique node at
level t1, called the ancestor node, which corresponds to the identical ﬁrst t1
parts of the process [1,t], and is also connected to nodes at level t þ 1,
which correspond to possible continuations of [1,t]. The set of nodes is
denoted N. We refer the reader to Figure 2 in Chapter 1 for an example of a
scenario tree.
For each node i 2 N and its ancestor a ¼ a(i) in the scenario tree we denote
by ai the probability of moving from node a to node i. Each probability ai
can be viewed as the conditional probability of the process being in node
i given its history up to the ancestor node a ¼ a(i). We can relate them to
scenario probabilities ps as follows. Every scenario s can be deﬁned by its
nodes i1, i2,. . . , iT, arranged in the chronological order, i.e., node i2 (at
level t ¼ 2) is connected to the root i1 ¼ 1, node i3 is connected to the node
i2, etc. The probability of that scenario is then given by the product
ps ¼ i1i2i2i3    iT1iT.
It is also convenient to introduce node probabilities p(i). Denoting by B(i)
the set of scenarios passing through node i (at level t) of the scenario tree, we
let p(i) :¼ P[B(i)]. If i1, i2,. . . , it, with i1 ¼ 1 and it ¼ i, is the history of the process
up to node i, then the probability p(i) is given by the product
pðiÞ ¼ i1i2i2i3    it1it
of
the
corresponding
conditional
probabilities.
We
also
have
the
recursive relation: p(i) ¼ aip(a), where a ¼ a(i) is the ancestor of the node i.
This equation deﬁnes the conditional probability ai from the probabilities
p(i) and p(a).
Proceeding exactly as in Section 3.2 of Chapter 1, we denote the value
of xt associated with node i at level t by x(i). Similarly, let T (i), W (i) and h(i)
be the values At,t1, Att and bt in scenarios passing through node i. Finally,
let f (i)(  ) ¼ ft(  , s), where s is a scenario passing through node i (the value
Ch. 3. Decomposition Methods
181

of t is identical in all these scenarios). We can then rewrite the problem as
follows
Min
X
i2N
pðiÞf ðiÞðxðiÞÞ
s:t:
TðiÞxðaðiÞÞ þ WðiÞxðiÞ ¼ hðiÞ,
i 2 N nf1g,
Wð1Þxð1Þ ¼ hð1Þ:
ð5:2Þ
The idea of nested decomposition is embedded in the tree formulation (5.2).
For each node i of the scenario tree we deﬁne the subtree T (i) rooted at i and
the associated cost-to-go function
QðiÞðxðaðiÞÞÞ:¼ inf
X
j2T ðiÞ
ijf ðjÞðx ðjÞÞ
 T ðjÞxa ðjÞ þ W ðjÞx ðjÞ ¼ h ðjÞ, j 2 T ðiÞ
(
)
ð5:3Þ
with ij ¼ p(j)/p(i) denoting the conditional probability of reaching node j 2 T (i)
from i. It is the specialization to the tree model of the function deﬁned in
Chapter 2, formula (3.3). Our superscript (i) of Q represents in a suﬃcient way
the entire history of  before node i has been reached.6
As outlined in Chapters 1 and 2, these functions are related through the
dynamic programming equation
QðiÞðxðaðiÞÞÞ ¼ inf
xðiÞ
f ðiÞðxðiÞÞ þ
X
j2SðiÞ
ijQð jÞðxðiÞÞ
 TðiÞxðaðiÞÞ þ WðiÞxðiÞ ¼ hðiÞ
(
)
,
ð5:4Þ
where S(i) is the set of successors of node i: such j that i ¼ a( j). Clearly, when
i is the leaf node (it corresponds to the last stage T ) there are no successors,
and the summation is over the empty set. If i is the root node corresponding to
the initial stage, there is no ancestor a(i), and Q has no arguments (it is just the
optimal value of the entire problem). However, for the uniformity of notation,
we shall work with the general form (5.4).
By Propositions 21 and 30 of Chapter 2, each cost-to-go function Q(i)(  ),
if it is ﬁnite at at least one point, is a convex polyhedral function.
Therefore, (5.4) is a two-stage problem with convex polyhedral ‘second-stage’
functions Q( j)(  ).
Equation (5.4) carries much information about our problem. In particular,
it allows us to construct in a recursive way polyhedral approximations to the
6 For i ¼ 1 the cost-to-go Q(1) has no arguments and represents the optimal value of problem (5.1).
182
A. Ruszczyn´ski

cost-to-go functions at every node, by employing objective and feasibility cuts
in a manner similar to the two-stage case. Indeed, let Qð jÞðÞ be lower
polyhedral approximations to Q(j)(  ), j 2 S(i). Then
QðiÞðxðaðiÞÞÞ  inf
xðiÞ
f ðiÞðxðiÞÞ þ
X
j2SðiÞ
ijQð jÞðxðiÞÞ
TðiÞxðaðiÞÞ þ WðiÞxðiÞ ¼ hðiÞ
(
)
:
ð5:5Þ
Let x(a(i)) be ﬁxed and let the problem at the right hand side of (5.5) have a
solution with the optimal value vðxðaðiÞÞÞ. Denote by (i) the Lagrange
multipliers associated with the constraint T(i)x(a(i)) þ W(i)x(i) ¼ h(i). Then, by
Proposition 21 of Chapter 2, we can construct an objective cut, similarly
to (2.3):
QðiÞðxÞ  vðxðaðiÞÞÞ  h½TðiÞTðiÞ, x  xðaðiÞÞi
for all x:
This inequality deﬁnes an objective cut:
QðiÞðxÞ  ðiÞ þ ðgðiÞÞTx,
for all x,
ð5:6Þ
where
gðiÞ ¼ ðTðiÞÞTðiÞ,
ð5:7Þ
ðiÞ ¼ vðxðaðiÞÞÞ þ ððiÞÞTTðiÞxðaðiÞÞ:
ð5:8Þ
Thus, to obtain an objective cut for Q(i)(  ) at x(a(i)) we need to solve the
problem at the right hand side of (5.5), retrieve the Lagrange multipliers (i)
associated with its constraints, and apply formulas (5.6)–(5.8). In general, we
have
vðxðaðiÞÞÞ  QðiÞðxðaðiÞÞÞ,
and our objective cut does not have to support Q(i)(  ) at x(a(i)). However, if the
models Qð jÞðxðiÞÞ, j 2 S(i), are exact, then our objective cut is exact at x(a(i)).
If the problem in (5.5) is infeasible, we can construct a feasibility cut,
ðiÞ þ ðrðiÞÞTx  0,
ð5:9Þ
similarly to the way described in Section 2.1. If f (i)(  ) is a linear function, we
proceed identically as in Section 2.1. If f (i)(  ) is a more complex convex
Ch. 3. Decomposition Methods
183

polyhedral function, we convert the problem in a usual way to a problem with
a linear objective, by adding one new variable and new constraints describing
the pieces of f (i)(  ).
It is important to remember that the right hand side of (5.5) is a lower
bound for Q(i)(  ), so the feasibility cuts remain valid for the true cost-to-go
function.
5.2
The nested cutting plane method
With each node of the scenario tree we can associate an approximate
problem P(i) of the form appearing at the right hand side of (5.5). Each of
these problems maintains and updates the following data: its current solution
x(i), convex polyhedral models of the cost-to-go functions Qð jÞðÞ of its
successors j 2 S(i) (if any), and the current approximation v(i) of the optimal
value of its own cost-to-go function. The operation of each subproblem is
formalized in Fig. 6.
It remains to describe the way in which these subproblems are initiated,
activated in the course of the solution procedure, and terminated.
We assume that we know a suﬃciently large number M such that each cost-
to-go function can be bounded from below by M. Our initial approxi-
mations of the successors’ functions are just
QðjÞðÞ ¼ M:
Step 1. If i is not the root node, retrieve from the ancestor problem P(a(i)) its current
approximate solution x(a(i)).
Step 2. If i is not a leaf node, retrieve from each successor problem P( j ), j 2 S(i), all new
objective and feasibility cuts and update the approximations of their cost-to-go
functions QðjÞðÞ.
Step 3. Solve the problem
Min
f ðiÞðxðiÞÞ þ
X
j2SðiÞ
ijQð jÞðxðiÞÞ
(
)
s:t:
TðiÞxðaðiÞÞ þ WðiÞxðiÞ ¼ hðiÞ:
(a) If it is solvable, replace x(i) by the new solution and v(i) by the optimal value. If
i is not the root node and v(i) increased, construct a new objective cut (5.6)–(5.8).
(b) If the problem is infeasible, and i is not the root node, construct a new feasibility
cut (5.9). If i is the root node, then stop, because the entire problem is infeasible.
Step 4. Wait for the command to activate again, and then go to Step 1.
Fig. 6. Subproblem P(i) of the nested decomposition method.
184
A. Ruszczyn´ski

At the beginning, no ancestor solutions are available, but we can initiate
each subproblem with some arbitrary point x(i) 2 dom f (i).
There is much freedom in determining the order in which the subproblems
are solved. Three rules have to be observed.
I. There is no sense to activate a subproblem P(i) whose ancestor’s
solution x(a(i)) did not change, and whose successors P( j), j 2 S(i), did
not generate any new cuts since this problem was activated last.
II. If a subproblem P(i) has a new solution x(i), each of its successors P( j),
j 2 S(i) has to be activated some time after this solution has been
obtained.
III. If a subproblem P(i) generates a new cut, i.e., if it is infeasible or has a
new optimal value v(i), its ancestor P(a(i)) has to be activated some time
after this cut has been generated.
We shall terminate the method if Rule I applies to all subproblems, in
which case we claim that the current solutions x(i) constitute the optimal
solution of the entire problem. The other stopping test is the infeasibility test
at Step 3(a) for the root node. It is obvious, because we operate with
relaxations here, and if a relaxation is infeasible, so is the true problem.
Theorem 18. The Nested Cutting Plane Method after ﬁnitely many subproblem
solutions either discovers the infeasibility of problem (5.1) or stops at its optimal
solution.
Proof. Arguing exactly as in the proofs of Theorems 4 and 5 we can prove
that each leaf subproblem can generate only ﬁnitely many diﬀerent object-
ive and feasibility cuts. Thus, each of its predecessors can have only ﬁnitely
many diﬀerent polyhedral models of the leaves’ optimal value functions.
Consequently, it can also generate only ﬁnitely many diﬀerent objective and
feasibility cuts. Proceeding in this way from the leaves to the root we conclude
that the root subproblem can be activated only ﬁnitely many times, because it
may receive only ﬁnitely many diﬀerent cuts. This, however, implies that its
successors can be activated only ﬁnitely many times, by new root’s solutions
or by new cuts coming from their successors. Continuing this argument from
the root to the leaves we deduce that each subproblem can be activated only
ﬁnitely many times. The method must stop.
Suppose that the method stops as a result of Rule I. Consider the
immediate predecessors of the leaf nodes. Arguing as in the proofs of
Theorems 4 and 5 we have
xðiÞ ¼ arg min f ðiÞðxÞ þ
X
j2SðiÞ
ijQð jÞðxÞ j TðiÞxðaðiÞÞ þ WðiÞx ¼ hðiÞ
(
)
:
ð5:10Þ
Ch. 3. Decomposition Methods
185

Moreover, we know that the cuts generated at these solutions support Q(i) at
x(a(i)). Thus, QðiÞðxðaðiÞÞÞ ¼ QðiÞðxðaðiÞÞÞ. Consequently, relations (5.10) must hold
at the ancestor a(i). By induction, these relations are true at all nodes.
The optimality of the current solution follows then from Theorem 34 of
Chapter 2.
u
5.3
Modifications and extensions
There are many ways in which the general idea of nested decomposition can
be modiﬁed and adapted to a particular problem.
Regularization and trust regions
First, we may use the concepts of regularization or trust regions to stabilize
the iterates and to facilitate the convergence. The best place to introduce
these modiﬁcations is the root problem, associated with the ﬁrst stage.
The operation of the method is then almost identical with the two-stage case:
the root node is the regularized (trust region) master, and the subtrees rooted
at its successors are giant second stage problems. The protocol for processing
the subproblems cannot be so ﬂexible as in the purely linear method: we
need an exact solution to the ‘second stage problem’ in order to decide
whether a serious step can be made. In other words, we solve the ‘second stage
problems’ by a linear nested decomposition method with a ﬂexible protocol,
and only after they are solved to optimality, we make adjustments at the
root node.
Regularization or trust regions at lower level nodes introduce more
complication. In general, optimal values of these modiﬁed subproblems
are no longer lower bounds for the true cost-to-go functions. Therefore,
these subproblems cannot generate objective cuts for their predecessors so
easily as linear subproblems could. Only when the entire subtree rooted at
such a subproblem is solved to optimality, a valid cut can be generated. It
follows that using regularization or trust regions at lower levels of the tree
restricts the processing order of the subproblems to depth-ﬁrst protocols, in
which a subproblem is processed only if all its successors are solved to
optimality.
Cut sharing
The number of cuts that are generated and stored by the nested
decomposition method may easily become very large. In some cases we may
reduce this number by using the similarity between the cost-to-go functions
Q(i) corresponding to diﬀerent nodes. The most dramatic simpliﬁcation occurs
when the parts of the data vector t, corresponding to diﬀerent time stages
t ¼ 1,. . . , T are statistically independent, in which case the distribution
of [t þ 1,T ] does not depend on [1,t]. In simple words, the data subtrees
rooted at nodes i at level t may diﬀer only by the data at level t and are
186
A. Ruszczyn´ski

identical otherwise. If the data at two nodes i and j at level t are the same, their
cost-to-go functions Q(i)(  ) and Q(j)(  ), deﬁned by (5.3), are identical.
It follows that every cut generated for a particular function Q(i)(  ) is valid for
all other functions at this level which happen to have identical data f (i)(  ), T (i),
W (i) and h(i).
Estimating cuts
Similarly to the two-stage case discussed in Section 2.4, we may work with
estimated expected value cuts rather than with exact averages. However, in the
nested method the estimation errors propagate quickly in the subproblem tree.
For more information see the chapter on Monte Carlo methods.
6
Introduction to dual methods
Dual methods for stochastic programming problems are based on duality
relations associated with the nonanticipativity constraints. Since the methods
are essentially the same for two-stage and multistage models, we shall present
them here only for the general multistage case.
Let us consider the polyhedral multistage problem:
Min Ef f1ðx1, 1Þ þ f2ðx2, 2Þ þ f3ðx3, 3Þ þ    þ fTðxT, TÞg
s:t:
A11ð1Þx1
¼ b1ð1Þ,
A21ð2Þx1
þ
A22ð2Þx2
¼ b2ð2Þ,
A32ð3Þx2
þ
A33ð3Þx3
¼ b3ð3Þ,
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
AT,T1ðTÞxT1
þ
ATTðTÞxT
¼ bTðTÞ,
ð6:1Þ
with each xt ¼ xt([1,t]) being a function of [1,t]. We assume throughout this
chapter that the process t, t ¼ 1,. . . , T, has ﬁnitely many realizations, s,
s ¼ 1,. . . , S,
attained
with
probabilities
p1,. . . , ps.
The
objective
parts
associated with the successive stages, ft(xt, t), t ¼ 1,. . . , T, are random
polyhedral functions.7
In the dual approach we assume that each decision xt may depend on all
random data, . Since  has ﬁnitely many realizations we may model our
assumption by assigning a decision sequence,
xs ¼ ðxs
1, . . . , xs
TÞ,
7 See Chapter 2, Section 2.3.
Ch. 3. Decomposition Methods
187

to the sth realization of . The problem takes on the form
Min
X
S
s¼1
ps½ f1ðxs
1, s
1Þ þ f2ðxs
2, s
2Þ þ f3ðxs
3, s
3Þ þ    þ fTðxs
T, s
TÞ
s:t:
A11ðs
1Þxs
1
¼ b1ðs
1Þ,
A21ðs
2Þxs
1
þ
A22ðs
2Þxs
2
¼ b2ðs
2Þ,
A32ðs
3Þxs
2
þ
A33ðs
3Þxs
3
¼ b3ðs
3Þ,
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
AT,T1ðs
TÞxs
T1
þ
ATTðs
TÞxs
T
¼ bTðs
TÞ,
s ¼ 1, . . . , S:
ð6:2Þ
As discussed extensively in Chapters 1 and 2, this formulation is not
equivalent to the original problem (6.1), unless we introduce additional
constraints that limit the dependence of xt on  to the information that is
available up to time t. These conditions take the form of nonanticipativity
constraints,
xs
t ¼ x
t
for all s,  for which s
½1,t ¼ 
½1,t,
t ¼ 1, . . . , T:
ð6:3Þ
Abstractly, they deﬁne a subspace W of implementable policies. For numerical
methods it is convenient to describe this subspace by a set of algebraic
equations. Clearly, (6.3) is such a set, but there is much redundancy in it. Let
us describe one way in which the nonanticipativity constraints can be written
explicitly.
Let It be the set of nodes at level t. For a node i 2 It we denote by B(i) the set
of scenarios that pass through node i and are, therefore, indistinguishable
on the basis of the information available up to time t. The sets B(i) for all i 2 It
are the atoms of the sigma-subalgebra Ft associated with the time stage t.
We denote them by B1
t , . . . , B	t
t .
Let us assume that all scenarios are ordered in such a way that each set B
t is
a set of consecutive numbers l
t , l
t þ 1, . . . , r
t. Then nonanticipativity can be
expressed by the system of equations
xs
txsþ1
t
¼0,
s ¼ l
t , . . . , r
t 1, t ¼ 1, . . . , T  1, 
 ¼ 1, . . . , 	t:
ð6:4Þ
In other words, each decision is related to its neighbors from the left and from
the right, if they correspond to the same node of the scenario tree. The
coeﬃcients of constraints (6.4) deﬁne a giant matrix
G ¼ ½G1    GS
188
A. Ruszczyn´ski

whose rows have two nonzeros each: 1 and 1. Thus, we obtain an algebraic
description of the nonanticipativity constraints:
Gx ¼ 0:
Example 19. Consider the scenario tree depicted in Fig. 7.
Let us assume that the scenarios are numbered from the left to the right.
Our nonanticipativity constraints take on the form:
x1
1  x2
1 ¼ 0, x2
1  x3
1 ¼ 0, . . . , x7
1  x8
1 ¼ 0,
x1
2  x2
2 ¼ 0, x2
2  x3
2 ¼ 0, x3
2  x4
2 ¼ 0,
x5
2  x6
2 ¼ 0, x6
2  x7
2 ¼ 0, x7
2  x8
2 ¼ 0,
x2
3  x3
3 ¼ 0,
x5
3  x6
3 ¼ 0, x6
3  x7
3 ¼ 0:
Using I to denote an identity matrix of an appropriate dimension, we may
write the constraint matrix G as shown in Fig. 8. G is always a very sparse
matrix, because each of its rows has only two nonzeros.
Let us deﬁne the objective functions associated with the scenarios:
f sðxsÞ :¼
PT
t¼1 ftðxs
t, s
tÞ
if the constraints of ð6:2Þ are satisfied
for scenario s,
þ1
otherwise:
8
><
>:
Fig. 7. Example of a scenario tree.
Ch. 3. Decomposition Methods
189

Problem (6.2)–(6.3) can be now written compactly as
Min
f ðxÞ :¼
X
S
s¼1
ps f sðxsÞ
(
)
s:t:
Gx ¼ 0:
ð6:5Þ
The optimality conditions and the duality theory for problem (6.5) have been
studied in Chapter 2. Let us recall brieﬂy the main concepts and results.
Consider the Lagrangian of (6.5):
Lðx, Þ :¼ f ðxÞ þ h, Gxi
¼
X
S
s¼1
ps f sðxsÞ þ
X
S
s¼1
h, Gsxsi:
The associated dual function has the form
DðÞ :¼ inf
x Lðx, Þ ¼
X
S
s¼1
inf
xs ½ ps f sðxsÞ þ h, Gsxsi:
ð6:6Þ
Fig. 8. The constraint matrix corresponding to the scenario tree from Fig. 7. The
subdivision corresponds to scenario subvectors x1,. . . , x8.
190
A. Ruszczyn´ski

Thus,
DðÞ ¼
X
S
s¼1
DsðÞ
with each Ds(  ) deﬁned by a scenario subproblem:
DsðÞ ¼ inf
xs ½ ps f sðxsÞ þ h, Gsxsi,
s ¼ 1, . . . , S:
ð6:7Þ
We see that
DðÞ ¼ sup
x ½hGT, xi  f ðxÞ ¼ f *ðGTÞ,
where f *(  ) is the Fenchel conjugate of f (  ). Thus, D(  ) is concave and
polyhedral. By the Fenchel–Moreau Theorem, at any point  at which
D()>1 we have
@DðÞ ¼ fGx: x 2 ^XðÞg,
ð6:8Þ
where ^XðÞ is the set of minimizers in (6.6).8 Clearly,
^XðÞ ¼ ^X1ðÞ      ^XSðÞ
with ^XsðÞ denoting the solution set of the sth subproblem in (6.7).
We shall restrict our presentation to the case when the sets dom f s are
bounded for each s. In this case the dual functional D(  ) is ﬁnite everywhere
and each set ^XðÞ is a bounded convex polyhedron.
It follows that in order to calculate the value and a subgradient of D() we
need to solve scenario subproblems (6.7) and aggregate their values to D()
and their solutions to a subgradient of D at .
Also, we see that
DsðÞ ¼ sup
xs ½hðGsÞT, xsi  ps f sðxsÞ ¼ psð f sÞ*ðGT=psÞ,
Thus,
@DsðÞ ¼ fGsxs : xs 2 ^XsðÞg:
ð6:9Þ
8 Since D(  ) is concave, @D() is the set of vectors g such that D(0)  D() þ hg, 0i for all 0.
Ch. 3. Decomposition Methods
191

The dual problem has the form
Max DðÞ:
ð6:10Þ
By the duality theory (cf. Theorems 46 and 47 of Chapter 2) we know that if
the primal problem (6.5) has an optimal solution then the dual problem (6.10)
has an optimal solution, optimal values of both problems coincide, and for
any optimal solution ^l of the dual problem and any optimal solution ^x of the
primal problem we have
^x 2 ^Xð^lÞ,
i.e., the primal solution solves the scenario subproblems (6.7).
This is the fundament of the dual methods. Their main structure is the same:
employ an iterative method for solving (6.10) and recover the primal solution
from the scenario subproblems (6.7). In the solution of the dual problem we
shall take advantage of the decomposable structure of the dual function.
7
The dual cutting plane method
The structure of the dual problem (6.10) is very similar to the form of the
primal problem (1.3) discussed in connection with the two-stage model: we
have to maximize a sum of many concave polyhedral functions. Therefore, we
may adapt to our case the Cutting Plane Method presented in Section 2.
At any point k generated by the method we can solve each scenario
subproblem (6.7) and obtain a solution xk,s. They deﬁne objective cuts:
DsðÞ  DsðkÞ þ hGsxk,s,   ki,
s ¼ 1, . . . , S,
for each scenario subproblem, and the objective cut
DðÞ  DðkÞ þ hGxk,   ki
ð7:1Þ
for the entire dual function.
Since the feasible sets Xs are assumed to be bounded, for any  the scenario
subproblems have optimal solutions and the dual function is bounded.
Therefore, we do not need to operate with feasibility cuts here.
We shall assume that we know a polyhedron  which contains the optimal
solution of the dual problem. It may be a suﬃciently large box. Let J k be a
subset of {1,. . . , k}. The cuts collected at iterations j 2 J k are included into the
master problem:
Max v
ð7:2Þ
192
A. Ruszczyn´ski

s:t:
DðjÞ þ hGx j,   ji  v,
j 2 Jk,
ð7:3Þ
 2 ,
ð7:4Þ
whose decision variables are  and v 2 R. To illustrate its meaning, let us ﬁx 
and carry out the maximization in v. We see that the optimal value of v is
equal to
D
kðÞ ¼ min
j2Jk ½DðjÞ þ hGx j,   ji:
By the subgradient inequality (7.1), D
kðÞ  DðÞ for all . Thus, the master
problem (7.2)–(7.4) is the problem to maximize a certain upper estimate of the
dual functional. After this problem is solved, the true value of the dual
functional is calculated, the approximation Dk(  ) improved, and the iteration
continues. The algorithm in its simplest form is presented in Fig. 9.
The convergence properties of the method have been analyzed in Section 2.
Theorem 4 can be rephrased here as follows.
Theorem 20. If the dual problem has an optimal solution in the set , then the
Dual Cutting Plane Algorithm ﬁnds an optimal solution of the dual problem in
ﬁnitely many iterations.
In the presentation above we have assumed that all cuts collected at earlier
iterations are retained in the master problem, that is, J k ¼ {1,. . . , k}. We
would like to decrease their number by deleting some or all inactive cuts.
As discussed in Section 2 it is safe in the version of the method which uses so-
called basic cuts. In our case, basic cuts correspond to optimal solutions of the
scenario subproblems which are drawn from a ﬁnite set. Since the feasible sets
of the scenario subproblems are bounded convex polyhedra, such ﬁnite sets
exist: they are basic feasible solutions of the scenario subproblems. So, if our
method generates only basic solutions to scenario subproblems, we may drop
inactive cuts, whenever the optimal value of the master problem decreases.
Step 0. Set k ¼ 1, J0 ¼ ;, v1 ¼ 1.
Step 1. For s ¼ 1,. . . , S solve subproblem (6.7) with  ¼ k, construct the objective cut
(7.1) and set Jk ¼ Jk1 [ {k}.
Step 2. If D(k) ¼ vk then stop (optimal dual solution has been found); otherwise
continue.
Step 3. Solve the master problem (7.2)–(7.4), denote by (k þ 1, vk þ 1) its solution,
increase k by one, and go to Step 1.
Fig. 9. The dual cutting plane algorithm.
Ch. 3. Decomposition Methods
193

On the other hand, after the dual problem has been solved, we need to
recover the optimal solution of the primal problem. In general, it will not be
composed of basic solutions of the scenario subproblems. Combinations of
basic solutions are needed.
To illustrate how such a combination can be constructed, let us assume that
the optimal solution ^l of the dual problem has been found by the Dual
Cutting Plane Method at iteration k, and that it is an interior point of the set .
It follows that
0 2 @D
kð^lÞ
(because ^l is the maximizer of D
kðÞ). Therefore, there exists a subset ^J of
cardinality at most m þ 1 among the constraints (7.3), which has the following
properties. First, these cuts are active at ^l, i.e.,
Dð^lÞ ¼ DðjÞ þ hGx j, ^l  ji,
j 2 ^J:
ð7:5Þ
Secondly, the convex hull of their gradients contains 0, that is, there exist
nonnegative multipliers j, j 2 ^J, such that
X
j2 ^J
jGx j ¼ 0,
ð7:6Þ
X
j2 ^J
j ¼ 1:
ð7:7Þ
The multipliers j are Lagrange multipliers associated with the cuts indexed
by j 2 ^J at the optimal solution to the master problem. Consider the point
^x ¼
X
j2 ^J
jx j:
By (7.6) it satisﬁes the nonanticipativity condition Gx ¼ 0.
Let us denote by ^f the common optimal value of the primal and the dual
problem. Adding equations (7.5) multiplied by j and using (7.6)–(7.7) we get
^f ¼
X
j2 ^J
j½DðjÞ  hGx j, ji ¼
X
j2 ^J
jf ðx jÞ  f ð ^xÞ,
where in the last inequality we have used the convexity of f. Since ^x satisﬁes
the nonanticipativity constraint (see (7.6)), it is optimal.
194
A. Ruszczyn´ski

The dual problem, however, is rather diﬃcult to solve, because of the large
dimension of the dual vector . It might be interesting to compare (6.10) with
the problem (1.3) arising in the primal approach to the two-stage problem.
Both involve sums of many polyhedral functions, but in the two-stage case the
dimension of the decision vector x does not grow with the scenario number S,
which allows for eﬃcient solution techniques exploiting the notion of critical
scenarios. On the other hand, in (6.10) the dimension of  grows with the
number of scenarios.
We can use more sophisticated algorithms to solve the dual problem (6.10):
regularized (bundle) methods or trust region methods. Their analysis is the
same as in Sections 3 and 4.
8
The augmented Lagrangian method
8.1
The basic method
The high dimension of the dual vector  in (6.10) suggests another
approach to (6.2)–(6.3): the augmented Lagrangian method. Let us consider
the compact formulation (6.5) and deﬁne the augmented Lagrangian as
follows:
Lðx, Þ :¼ f ðxÞ þ h, Gxi þ 
2 kGðxÞk2,
ð8:1Þ
where >0 is a penalty coeﬃcient. The Multiplier Method applied to (6.5)
carries out for k ¼ 1, 2,. . . the following iteration:
(a) given k, ﬁnd xk ¼ arg min Lðx, kÞ;
(b) set kþ1 ¼ k þ Gxk.
The convergence of this algorithm is analyzed in the following theorem.
Theorem 21. Assume that the dual problem (6.10) has an optimal solution.
Then the sequence {k} generated by the Multiplier Method after ﬁnitely many
steps ﬁnds an optimal solution of (6.10).
Proof. We shall show that the Multiplier Method is equivalent to the
Proximal Point Method9 for solving the dual problem:
kþ1 ¼ arg max DðÞ  1
2 k  kk2


,
k ¼ 1, 2, . . . :
ð8:2Þ
9 The Proximal Point Method is discussed in Sections 3.2 and 9.2.
Ch. 3. Decomposition Methods
195

The problem above can be written as a max-min problem:
Max

Min
x2X
f ðxÞ þ h, Gxi  1
2 k  kk2


:
Let us interchange the ‘Max’ and ‘Min’ operators (we shall soon show that it
is legitimate):
Min
x2X Max

f ðxÞ þ h, Gxi  1
2 k  kk2


:
Now we can calculate the maximum with respect to  in a closed form:
ðxÞ ¼ k þ Gx:
ð8:3Þ
After substituting the optimal , the min-max problem becomes equivalent to
Min
x2X Lðx, kÞ:
Its solution is the point xk calculated in Step (a) of the Multiplier Method. The
corresponding multiplier value follows from (8.3) and is equal to k þ 1, as
deﬁned in Step (b) of the Multiplier Method. Now we can provide a proof for
the validity of the interchange of the ‘Min’ and ‘Max’ operations, by verifying
that the pair (xk, k þ 1) is a saddle point of the function
kðx, Þ ¼ f ðxÞ þ h, Gxi  1
2 k  kk2:
Indeed, k(xk, k þ 1) ¼ L(xk, k) and xk minimizes L(x, k) in X, while k þ 1
maximizes h, Gxi(1/2)kkk2, as shown in (8.3). Thus the saddle point
(xk, k þ 1) is a solution of both ‘min-max’ and ‘max-min’ problems.
The convergence of the Multiplier Method follows now from Theorems
9 and 10.
u
In fact, the same result is true for the convex case (but without ﬁnite
convergence, in general).
The utmost simplicity of the multiplier update (b) is the main advantage of
this approach. On the other hand, the minimization step (a) cannot be easily
decomposed into scenario subproblems, as it could be done in (6.6) for the
ordinary Lagrangian, because of the quadratic term kGxk2. We shall address
this issue in the next section.
196
A. Ruszczyn´ski

8.2
The separable approximation
One possibility to overcome the nonseparability of the augmented
Lagrangian is to apply an iterative nonlinear Jacobi method to the minimi-
zation of (8.1). This method uses, at iteration j, a certain approximation ~xk, j of
the minimizer x k in (a), and solves for each scenario s simpliﬁed problems:
x k, jþ1,s ¼ arg min
x s2Xs
ps f sðxsÞ þ hk, Gsx siþ 
2 Gsx s þ
X
6¼s
G ~xk, j, 


2
(
)
:
ð8:4Þ
In other words, the augmented Lagrangian (8.1) is minimized with respect to
the decisions associated with scenario s, while keeping the decisions associated
with other scenarios  6¼ s ﬁxed at ~xk, j,. This is done for all scenarios s. Then,
with some stepsize  2 (0, 1), the reference point is updated
~xk, jþ1 ¼ ð1  Þ ~xk, j þ xk, j,
and the iteration continues. This general scheme converges for suﬃciently
small stepsizes , but the convergence may be slow. What makes it particularly
useful in our case is its application together with the construction of the
constraint matrix G in (6.4).
The quadratic term of the augmented Lagrangian has then the form
kGxk2 ¼
X
T1
t¼1
X
	t

¼1
X
r
1
s¼l
kxs
t  xsþ1
t
k2:
The minimization in (8.4) involves at most two simple quadratic terms for each
subvector xs
t, t ¼ 1,. . . , T1, relating it to the reference values at its neighbors:
~xs1
t
and ~xsþ1
t
. Not only makes it the subproblems easier to manipulate
and solve, but it has a positive impact on the speed of convergence.
Denote the functions minimized at (8.4) by
~Lsðxs, ~x, Þ ¼ ps f sðxsÞ þ h, Gsxsi þ 
2
Gsxs þ
X
6¼s
G ~x


2
,
and let
~Lðx, ~x, Þ ¼
X
S
s¼1
~Lsðxs, ~x, Þ  
2 ðS  1Þ
X
S
¼1
G ~x


2
:
Ch. 3. Decomposition Methods
197

Clearly, ~Lð, ~x, Þ is the function minimized in parallel in (8.4). The error of the
approximation to L can be estimated as follows.
Lemma 22. For all x, ~x and  the following inequality is true:
jLðx, Þ  ~Lðx, ~x, Þj  
2
X
S
s¼1
kGsðxs  ~xsÞk2:
Proof. By direct calculation we obtain
Lðx, Þ  ~Lðx, ~x, Þ ¼ 
2
X
S
s¼1
X
6¼s
hGsðxs  ~xsÞ, Gðx  ~xÞi:
ð8:5Þ
The scalar products above can be nonzero only for  ¼ s1 and  ¼ s þ 1
(otherwise (Gs)TG ¼ 0). For such (s, ) pairs we have
hGsðxs  ~xsÞ, Gðx  ~xÞi¼
X
n
i¼1
X
n
l¼1
hGs
iðxs
i  ~xs
iÞ, G
l ðx
l  ~x
l Þi:
ð8:6Þ
Let us denote by J(s, ) the set of variables linked by nonanticipativity
constraints in scenarios s and . We have
jhGs
i, G
l ij ¼
1
if l ¼ i and i 2 Jðs, Þ,
0
otherwise,

and
jhGsðxs  ~xsÞ, Gðx  ~xÞij 
X
i2Jðs,Þ
ðxs
i  ~xs
iÞðx
i  ~x
i Þ
 1
2
X
i2Jðs,Þ
½ðxs
i  ~xs
iÞ2 þ ðx
i  ~x
i Þ2:
Using this in (8.5) we obtain the inequality
jLðx, Þ  ~Lðx, ~x, Þj  
4
X
S
s¼1
X
6¼s
X
i2Jðs,Þ
½ðxs
i  ~xs
iÞ2 þ ðx
i  ~x
i Þ2:
198
A. Ruszczyn´ski

Each term ðxs
i  ~xs
iÞ2 appears in this sum at most 2kGs
ik2 times and we can
continue our estimate as follows:
jLðx, Þ  ~Lðx, ~x, Þj  
2
X
S
s¼1
X
i2Jðs,Þ
kGs
ik2ðxs
i  ~xs
iÞ2:
Noting that the columns Gs
i, i ¼ 1,. . . , n, are orthogonal, we obtain the
required result.
u
Our next result estimates the progress that is made within each subproblem.
Lemma 23. Suppose that xs minimizes in Xs the function ~Lsð, ~x, Þ. Then
~Lsðxs, ~x, Þ  ~Lsð ~xs, ~x, Þ   
2 kGsðxs  ~xsÞk2:
Proof. For every gs 2 @ ~Lsðxs, ~x, Þ we have
~Lsð ~xs, ~x, Þ  ~Lsðxs, ~x, Þ  hgs, ~xs  xsi þ 
2 kGsðxs  ~xsÞk2:
Since xs is a minimizer, there exists a subgradient gs of ~Lsð, ~x, Þ at xs such that
hgs, ~xs  xsi  0,
and the result follows.
u
We are now ready to prove the convergence of the Jacobi method.
Theorem 24. Assume that the sets Xs, s ¼ 1,. . . , S are bounded. Then
(a) For all s ¼ 1,. . . , S we have limj!1 Gsðxs, j  ~xs, jÞ ¼ 0;
(b) Every accumulation point of the sequence ~xk, j, j ¼ 1, 2,. . . , is a minimizer
of L(x, k) over X.
Proof. Let us estimate the progress made for the true augmented Lagrangian
function. By Lemma 22 we have
Lð ~xk, j þ ðxk, j  ~xk, jÞ, kÞ  ~Lð ~xk, j þ ðxk, j  ~xk, jÞ, kÞ
 1
2 2 X
S
s¼1
kGsðxk, j,s  ~xk, j, sÞk2:
Ch. 3. Decomposition Methods
199

By Lemma 23 and by the convexity of ~L,
~Lð ~xk, jþðxk, j ~xk, jÞ, kÞ ~Lð ~xk, j, kÞ 1
2 
X
S
s¼1
kGsðxk, j,s  ~xk, j,sÞk2:
Combining the last two inequalities we obtain
Lð ~xk, jþ1, kÞ  Lð ~xk, j, kÞ  1
2 ð1  Þ
X
S
s¼1
kGsðxs  ~xsÞk2:
ð8:7Þ
This proves (a). At any accumulation point x* we then must have that x*,s
is a minimizer of
~Lsðxs, x*, kÞ over Xs. Thus, x* minimizes L(x, k), as
required.
u
It follows from our analysis that the sparsity of the nonanticipativity
constraints allows for using relatively large stepsizes in the Jacobi method.
The best estimate of the speed of convergence is obtained in (8.7) for  ¼ 1/2.
Another advantage is the minimal amount of communication between
scenario subproblems within the Jacobi method. In fact, each subproblem s
needs to communicate with at most two subproblems: s1 and s þ 1, which is
very important for parallel and distributed computation.
Also, both iterative processes: the outer iterations for the multipliers and the
inner iterations of the Jacobi method, are very simple and they can be carried
out for a very large number of scenarios, and for large scenario subproblems.
9
Progressive hedging
9.1
The method
Let us write the multistage stochastic programming problem (6.5) in an
abstract form
Min
x2W
X
S
s¼1
ps f sðxsÞ,
ð9:1Þ
where W denotes the linear subspace of nonanticipative policies, that is,
policies satisfying the nonanticipativity constraints Gx ¼ 0. As before, xs
denotes the sequence of decisions associated with scenario s. Using
f ðxÞ ¼
X
S
s¼1
ps f sðxsÞ
200
A. Ruszczyn´ski

and the indicator function of the subspace of nonanticipative policies,
WðxÞ ¼
0
if x 2 W,
þ1
otherwise,

we can rewrite (9.1) as follows:
Minf f ðxÞ þ WðxÞg:
ð9:2Þ
Let us note that each of the components individually is easy to deal with: f by
decomposition into scenarios, and W by linear algebra. Problems of this form
are well understood and a number of operator splitting methods have been
suggested to exploit the properties of the two components in solving the
whole. One of the most general is the Douglas–Rachford method.
The method generates a sequence (xk, uk) such that
uk 2 @WðxkÞ,
which means two things: xk is an element of W, and uk 2 W?. This is
accomplished in the following way (>0 is a ﬁxed parameter):
(a) ﬁnd yk and gk 2 @f ( yk) such that
yk þ gk ¼ xk  uk;
ð9:3Þ
(b) ﬁnd xk þ 1 2 W and uk þ 1 2 W? such that
xkþ1 þ ukþ1 ¼ yk þ uk:
ð9:4Þ
Step (a) amounts to ﬁnding
yk ¼ arg min
y
f ð yÞ þ huk, yi þ 1
2 ky  xkk2


,
ð9:5Þ
and gk is the subgradient of f that appears in the necessary conditions of
optimality for this problem. Problem (9.5) decomposes into individual
scenarios
Min
ys
ps f sð ysÞ þ huk,s, ysi þ 1
2 kys  xk,sk2


:
Ch. 3. Decomposition Methods
201

Their solutions yk,s form a policy yk which is feasible with respect to scenario
constraints, but not necessarily nonanticipative. The nonanticipativity is
restored in step (b).
Since both uk and uk þ 1 are in W?, step (b) implies that
xkþ1  yk ? W:
Therefore,
xkþ1 ¼ WðykÞ,
where W is the orthogonal projection on the subspace of nonanticipative
policies. To perform this operation, for each time stage t we consider
bundles B1
t , . . . , B	t
t
of scenarios which cannot be distinguished up to
time t. They correspond to nodes of the scenario tree located at level t.
For each of these bundles, say B j
t , we replace all ys
t, s 2 B j
t , by their average
on Bj
t:
xkþ1,s
t
¼
1
jB j
t j
X
2Bj
t
yk,
t :
ð9:6Þ
Finally, directly from (b),
ukþ1 ¼ uk þ 1ðyk  xkþ1Þ ¼ uk þ 1W?ðykÞ:
We can specialize and simplify this general technique by taking into account
the speciﬁc nature of our objective function f and of the subspace W. We
change the scalar product in the entire decision space to
hx, uiP ¼
X
S
s¼1
pshxs, usi:
ð9:7Þ
This changes in a corresponding manner W? and the orthogonal projection
operation. Then problem (9.5) (with the new scalar product and the corres-
ponding norm) decomposes into scenario subproblems
Min
ys
f sð ysÞ þ huk,s, ysi þ 1
2 kys  xk,sk2


:
ð9:8Þ
202
A. Ruszczyn´ski

Its solution, as before, will be denoted yk,s. The orthogonal projection on W
(in the new geometry) can be calculated in way similar to (9.6), but with the
conditional expectation on B j
t , instead of the plain average:
xkþ1,s
t
¼
1
PðB j
tÞ
X
2Bj
t
pyk,
t :
ð9:9Þ
The formula for the multiplier,
ukþ1 ¼ uk þ 1ðyk  xkþ1Þ,
ð9:10Þ
remains the same. Note that uk is always orthogonal to xk in the new geometry:
huk, xkiP ¼ 0. The Progressive Hedging Method is presented in Fig. 10.
The main diﬃculty associated with the application of the Progressive
Hedging Method is the absence of a merit function whose improvements can
be monitored from iteration to iteration. This makes adjustments in the
penalty parameter  harder than in the case of other decomposition methods.
9.2
Convergence
To prove the convergence of the Progressive Hedging Method, we need to
put it into a more abstract framework of the theory of maximal monotone
operators. For a multivalued operator M: Rn!
!Rn we deﬁne its domain as the
set of x for which M(x) 6¼ ;. Its graph is the set
GðMÞ :¼ fðx, yÞ: y 2 MðxÞg:
An operator M is called monotone, if
hx0  x, y0  yi  0,
for all x, x0 2 dom M, y 2 MðxÞ, y0 2 Mðx0Þ:
Step 0. Set x0 ¼ W and u0 ¼ W?. Set k ¼ 0.
Step 1. For s ¼ 1,. . . , S solve the scenario subproblems (9.8).
Step 2. For each stage t ¼ 1,. . . , T and for each bundle B j
t of scenarios which cannot be
distinguished up to stage t, calculate the corresponding components of xkþ1,s
t
for s 2 B j
t
by (9.9).
Step 3. Calculate new multipliers by (9.10).
Step 4. Increase k by one, and go to Step 1.
Fig. 10. The progressive hedging algorithm.
Ch. 3. Decomposition Methods
203

It is maximal monotone if its graph is not contained in the graph of another
monotone operator. An example of a maximal monotone operator is the
subdiﬀerential of a proper convex function.
Together with a maximal monotone operator M we shall consider its
resolvent:
JM :¼ ðI þ MÞ1,
where >0. It is well deﬁned on the whole space Rn, that is, for every z 2 Rn
there exists a unique x 2 dom M and a unique y 2 M(x) such that z ¼ x þ y.
Consider the inclusion
0 2 MðxÞ:
If x is its solution, then
x ¼ JMðxÞ,
i.e., x is a ﬁxed point of the resolvent. The opposite is also true: every ﬁxed
point of the resolvent is a zero of M.
Let us introduce yet another operator derived from M:
OM :¼ 2JM  I:
By the maximal monotonicity of M, every z 2 Rn can be uniquely represented
as z ¼ x þ y with y 2 M(x). Then JM(z) ¼ x and we get
OMðx þ yÞ ¼ x  y:
ð9:11Þ
This identity can be used as follows. Let z ¼ x þ y with y 2 M(x), z0 ¼ x0 þ y0
with y0 2 M(x0). We have
kOMðzÞ  OMðz0Þk2 ¼ kðx  yÞ  ðx0  y0Þk2
¼ kðx þ yÞ  ðx0 þ y0Þk2  4hx  x0, y  y0i:
By the monotonicity of M, we have hxx0, yy0i  0, and the last displayed
inequality yields
kOMðzÞ  OMðz0Þk  kz  z0k
for all z, z0 2 Rn:
This means that the operator OM is nonexpansive.
204
A. Ruszczyn´ski

For any nonexpansive D : Rn ! Rn and every  2 (0, 1) the classical method
xkþ1 ¼ ð1  Þxk þ DðxkÞ,
k ¼ 1, 2, . . . ,
ð9:12Þ
is convergent to a ﬁxed point of D, if a ﬁxed point of D exists. By setting
D ¼ OM and  ¼ 1/2, we get
zkþ1 ¼ ð1  Þzk þ OMðzkÞ ¼ JMðzkÞ:
ð9:13Þ
The above iteration is called the Proximal Point Method for maximal
monotone operators. We have just proved that it is convergent to a ﬁxed point
of OM, which, by (9.11), must be a zero of M. In the special case when M is
the subdiﬀerential of a convex function, algorithm (9.13) becomes identical
with the method analyzed in Section 3.2, with  ¼ 1/.
We can use all these observations in the analysis of the Douglas–Rachford
method. Consider
M ¼ A þ B,
where A and B are maximal monotone. We deﬁne the operator D as the
functional composition of OA and OB:
D ¼ OA  OB:
It is nonexpansive, because both OA and OB are nonexpansive. The method
(9.12) for  ¼ 1/2 takes on the form:
zkþ1 ¼ 1
2 OAðOBðzkÞÞ þ 1
2 zk:
ð9:14Þ
It is called the Douglas–Rachford method for ﬁnding a zero of A þ B.
Iterations (9.14) can be carried out as follows. We ﬁnd the unique
representation zk ¼ xk þ uk with uk 2 B(xk). Then, by (9.11),
OBðzkÞ ¼ xk  uk:
Next, we ﬁnd the unique yk and gk 2 A(yk) for which
yk þ gk ¼ xk  uk:
ð9:15Þ
Ch. 3. Decomposition Methods
205

This gives us
OAðOBðzkÞÞ ¼ yk  gk:
The next point zk þ 1 ¼ xk þ 1 þ uk þ 1 is deﬁned as
zkþ1 ¼ 1
2 ð yk  gkÞ þ 1
2 ðxk þ ukÞ ¼ yk þ uk:
ð9:16Þ
Theorem 25. Assume that A and B are maximal monotone and a zero of A þ B
exists. Then the sequence {zk} generated by the Douglas–Rachford method
(9.14) is convergent to a point ^z ¼ ^x þ ^u, ^u 2 Bð ^xÞ, such that ^x is a zero of
A þ B.
Proof. Let us assume that a ﬁxed point of D exists. Then, by the convergence
theory of method (9.12) we know that the sequence {zk} is convergent to a
ﬁxed point ^z ¼ ^x þ ^u of D, ^u 2 Bð ^xÞ.
It remains to characterize ﬁxed points of D. If z1 ¼ ^z, operations (9.15)–
(9.16) generate for all k points xk ¼ ^x, uk ¼ ^u, yk ¼ ^y and gk ¼ ^g. Since
zk þ 1 ¼ zk we have ^x þ ^u ¼ ^y þ ^u, so ^x ¼ ^y. From (9.15) we see that ^u ¼  ^g.
In other words,
0 ¼ ^u þ ^g,
where ^u 2 Að ^xÞ and ^g 2 Bð ^xÞ. Thus ^x is a zero of A þ B. The converse is also
true. If x is a zero of A þ B, then there exists u 2 A(x) \ [B(x)] and x þ u is a
ﬁxed point of D. Therefore, our assumption that a zero of A þ B exists implies
the existence of ﬁxed point of D. Consequently, the sequence {xk} converges to
a zero A þ B.
u
In fact, the operator 1
2 ðD þ IÞ is a resolvent of another maximal monotone
operator N and the entire Douglas–Rachford method can be interpreted as a
proximal point method for N.
Now it is easy to rephrase the Progressive Hedging Method in terms of the
abstract Douglas–Rachford method for maximal monotone operators. By
setting
AðxÞ ¼ @f ðxÞ,
BðxÞ ¼ @WðxÞ,
we immediately see that (9.3)–(9.4) are identical with (9.15)–(9.16). Therefore,
the method (9.3)–(9.4) generates a sequence {xk} which is convergent to a
point ^x at which
0 2 @f ð ^xÞ þ @Wð ^xÞ:
206
A. Ruszczyn´ski

It is an optimal solution of (9.1) if
@ð f þ WÞ ¼ @f þ @W,
which can be guaranteed by the constraint qualiﬁcation condition
ri dom f \ W 6¼ ;:
ð9:17Þ
The same analysis can be carried out for the ﬁnal version of the Progressive
Hedging Method, developed with the new scalar product (9.7) and described
in Fig. 10. Let us deﬁne the matrix
P ¼ diagf ps, s ¼ 1, . . . , Sg:
The operator
APðxÞ ¼ P1@f ðxÞ,
which is the subdiﬀerential of f in the new geometry, is maximal monotone
with respect to the scalar product (9.7). The operator
BPðxÞ ¼
P1W?
if x 2 W,
;
otherwise,

is maximal monotone in the new geometry, too. For these two operators steps
(9.15)–(9.16) are equivalent to (9.8)–(9.9). Thus, under the constraint
qualiﬁcation condition (9.17), the sequence {xk} is convergent to a solution
of (9.1), provided that a solution exists.
10
Bibliographic notes
The cutting plane method for two-stage linear programming is due to
Benders (1962). Wets (1966) analyzed two-stage stochastic linear program-
ming problems. Van Slyke and Wets (1969) developed for these problems the
cutting plane method. The multicut version was analyzed by Birge and
Louveaux (1988). Our proof of ﬁnite termination with nonbasic cuts is
original. The cutting plane method for stochastic programming is dual to the
decomposition method of Dantzig and Wolfe (1960). It was discussed by
Dantzig and Madansky (1961). The cutting plane method for convex
programming was invented by Kelley (1960). Our analysis of the general
convex case follows Hiriart-Urruty and Lemare´ chal (1993). Solution methods
for many similar scenario subproblems were developed by Wallace (1986a,b),
Haugland and Wallace (1988) and Wets (1988). Zakeri et al. (2000) discuss the
Ch. 3. Decomposition Methods
207

case of inexact cuts derived from approximate solutions of subproblems.
Importance sampling was discussed by Glynn and Iglehart (1989). Stochastic
cutting plane methods were developed by Higle and Sen (1996).
The Regularized Decomposition Method was proposed by Ruszczyn´ ski
(1986). The proximal point method is due to Martinet (1970). Rockafellar
(1976a) analyzed it in the context of monotone operators. Bundle methods
were developed by Lemare´ chal (1978), Miﬄin (1982) and Kiwiel (1983) (see
also the monographs by Hiriart-Urruty and Lemare´ chal, 1993, and by Kiwiel,
1985). Algorithmic advances were discussed in Kiwiel (1990) and Ruszczyn´ ski
and S´ wietanowski (1997).
Trust region methods are standard techniques in nonlinear and nonsmooth
optimization (see, e.g., More´ , 1983; Kiwiel, 1996). In stochastic programming
a trust region method was proposed and implemented in parallel by Linderoth
and Wright (2001). Our version and its analysis are original.
Nested decomposition for multistage linear programming was introduced
by Glassey (1973) and Ho and Manne (1974). For multistage stochastic
programming problems the method was proposed by Birge (1985), Noe¨ l and
Smeers (1986, 1987). Parallel versions were analyzed by Ruszczyn´ ski (1993),
Birge et al. (1996), Nielsen and Zenios (1996) and Dempster and Thompson
(1998). Chen and Powell (1999) use statistical estimates within nested
decomposition. Cut sharing was discussed by Infanger and Morton (1996).
Algorithmic
reﬁnements,
bounds
and
applications
are
discussed
by
Frauendorfer (1992) and Infanger (1994).
Decomposition based on Lagrangian duality with bundle methods for
solving the dual was analyzed by Chun and Robinson (1995). Bacaud et al.
(2001) suggest a specialized preconditioning scheme in such approaches.
General augmented Lagrangian methods are due to Hestenes (1969), Powell
(1969) and Haarhoﬀand Buys (1970). For a modern theory with connections
to proximal point methods see Rockafellar (1976b) and Bertsekas (1982).
Augmented
Lagrangian
decomposition
techniques
were
analyzed
by
Stephanopoulos
and
Westerberg
(1975)
and
Cohen
(1980).
Scenario
decomposition
for
stochastic
programming
is
due
to
Mulvey
and
Ruszczyn´ ski (1995). Parallel versions were developed by Berger et al. (1994).
Our analysis exploiting the sparsity of the nonanticipativity constraints
follows Ruszczyn´ ski (1995).
The Progressive Hedging Method is due to Rockafellar and Wets (1991).
The operator splitting method is due to Douglas and Rachford (1956). The
proximal point method is due to Martinet (1970). Relations with augmented
Lagrangians were analyzed by Lions and Mercier (1979) and Gabay (1983).
Relations of operator splitting and proximal point methods were analyzed by
Eckstein and Bertsekas (1992). The method (9.12) for nonexpansive operators
in Banach spaces was developed by Opial (1967). Lawrence and Spingarn
(1987) analyzed its application to operator splitting methods. For further
modiﬁcations of operator splitting and their relations to bundle methods see
Kiwiel et al. (1999).
208
A. Ruszczyn´ski

References
Bacaud, L., C. Lemare´ chal, A. Renaud, C. Sagastiza´ bal (2001). Bundle methods in stochastic optimal
power management: A disaggregated approach using preconditioners. Computational Optimization
and Applications 20, 227–244.
Benders, J.F. (1962). Partitioning procedures for solving mixed-variables programming problems.
Numerische Mathematik 4, 238–252.
Berger, A.J., J.M. Mulvey, A. Ruszczyn´ ski (1994). An extension of the DQA algorithm to convex
stochastic programs. SIAM Journal on Optimization 4, 735–753.
Bertsekas, D.P. (1982). Constrained Minimization and Lagrange Multiplier Methods, Academic Press,
New York.
Birge, J.R. (1985). Decomposition and partitioning methods for multistage stochastic linear programs.
Operations Research 33, 989–1007.
Birge, J.R., C.J. Donohue, D.F. Holmes, O.G. Svintsitski (1996). A parallel implementation of the
nested
decomposition
method
for
multistage
stochastic
linear
programs.
Mathematical
Programming, Series B 75, 327–352.
Birge, J.R., F.V. Louveaux (1988). A multicut algorithm for two-stage stochastic linear programs.
European Journal of Operational Research 34, 384–392.
Chen, Z.L., W.B. Powell (1999). Convergent cutting-plane and partial-sampling algorithm for
multistage stochastic linear programs with recourse. Journal of Optimization Theory and
Applications 102, 497–524.
Chun, B.J., S.M. Robinson (1995). Scenario analysis via bundle decomposition. Annals of Operations
Research 56, 39–63.
Cohen, G. (1980). Auxiliary problem principle and decomposition of optimization problems. Journal
of Optimization Theory and Applications 32, 277–305.
Dantzig, G., A. Madansky (1961). On the solution of two-stage linear programs under uncertainty, in:
Proceedings of the 4th Berkeley Symposium on Mathematical Statistics and Probability, University
of California Press, Berkeley, pp. 165–176.
Dantzig, G., P. Wolfe (1960). Decomposition principle for linear programs. Operations Research 8,
101–111.
Dempster, M.A.H., R.T. Thompson (1998). Parallelization and aggregation of nested Benders
decomposition. Annals of Operations Research 81, 163–187.
Douglas, J., H.H. Rachford (1956). On the numerical solution of heat conduction problems in two and
three space variables. Transactions of the American Mathematical Society 82, 421–439.
Eckstein, J., D.P. Bertsekas (1992). On the Douglas–Rachford splitting method and the proximal point
algorithm for maximal monotone operators. Mathematical Programming 55, 293–318.
Frauendorfer, K. (1992). Stochastic Two-Stage Programming. Lecture Notes in Economics and
Mathematical Systems 392, Springer, Berlin.
Gabay, D. (1983). Applications of the method of multipliers to variational inequalities, in: M. Fortin,
R. Glowinski (eds.), Augmented Lagrangian Methods: Applications to the Solution of Boundary-
Value Problems, North-Holland, Amsterdam.
Glassey, C.R. (1973). Nested decomposition and multistage linear programs. Management Science 20,
282–292.
Glynn, P.W., D.L. Iglehart (1989). Importance sampling for stochastic simulation. Management
Science 35, 1367–1392.
Haarhoﬀ, P.C., J.D. Buys (1970). A new method for the minimization of a nonlinear function subject
to nonlinear constraints. Computer Journal 13, 178–184.
Haugland, D., S.W. Wallace (1988). Solving many linear programs that diﬀer only in the righthand
side. European Journal of Operational Research 37, 318–324.
Hestenes, M.R. (1969). Multiplier and gradient methods. Journal of Optimization Theory and
Applications 4, 303–320.
Higle, J.L., S. Sen (1996). Stochastic Decomposition: A Statistical Method for Large Scale Stochastic
Linear Programming, Kluwer, Dordrecht.
Ch. 3. Decomposition Methods
209

Hiriart-Urruty, J.-B., C. Lemare´ chal (1993). Convex Analysis and Minimization Algorithms, Springer-
Verlag, Berlin.
Ho, J.K., A.S. Manne (1974). Nested decomposition for dynamic models. Mathematical Programming
6, 121–140.
Infanger, G. (1994). Planning under Uncertainty: Solving Large-Scale Stochastic Linear Programs,
Boyd & Fraser, Danvers.
Infanger, G., D.P. Morton (1996). Cut sharing for multistage stochastic linear programs with
interstage dependency. Mathematical Programming 75, 241–256.
Kelley, J.E. (1960). The cutting plane method for solving convex programs. J. SIAM 8, 703–712.
Kiwiel, K.C. (1983). An aggregate subgradient method for nonsmooth convex minimization.
Mathematical Programming 27, 320–341.
Kiwiel, K.C. (1985). Methods of Descent for Nondiﬀerentiable Optimization, Lecture Notes in
Mathematics 1133, Springer-Verlag, Berlin.
Kiwiel, K.C. (1990). Proximity control in bundle methods for convex nondiﬀerentiable optimization.
Mathematical Programming 46, 105–122.
Kiwiel, K.C. (1996). Restricted step and Levenberg–Marquardt techniques in proximal bundle
methods for nonconvex nondiﬀerentiable optimization. SIAM Journal on Optimization 6, 227–249.
Kiwiel, K.C., C.H. Rosa, A. Ruszczyn´ ski (1999). Decomposition via alternating linearization. SIAM
Journal on Optimization 9, 153–172.
Lawrence, J., J.E. Spingarn (1987). On ﬁxed points of nonexpansive piecewise isometric mappings.
Proceedings of the London Mathematical Society 55, 605–624.
Lemare´ chal, C. (1978). Nonsmooth optimization and descent methods. Research Report 78-2,
International Institute for Applied Systems Analysis, Laxenburg.
Linderoth, J.T., S.J. Wright (2001). Implementing a decomposition algorithm for stochastic programming
on a computational grid. Preprint ANL/MCS-P875-0401, Mathematics and Computer Science
Division, Argonne National Laboratory, April 2001.
Lions, P.L., B. Mercier (1979). Splitting algorithms for the sum of two nonlinear operators. SIAM
Journal on Numerical Analysis 16, 964–979.
Martinet, B. (1970). Re´ gularisation d’ine´ quations variationelles par approximations successives. Revue
Franc. Rech. Ope´r. R3, 154–158.
Miﬄin, R. (1982). A modiﬁcation and an extension of Lemare´ chal’s algorithm for nonsmooth
optimization. Mathematical Programming Study 17, 77–90.
More´ , J.J. (1983). Recent developments in algorithms and software for trust region methods,
in: A. Bachem, M. Gro¨ tschel, B. Korte (eds.), Mathematical Programming, The State of the Art,
Springer, Berlin, pp. 258–287.
Mulvey, J.M., A. Ruszczyn´ ski (1995). A new scenario decomposition method for large-scale stochastic
optimization. Operations Research 43, 477–490.
Nielsen, S.S., S.A. Zenios (1996). Solving multistage stochastic network programs on massively parallel
computers. Mathematical Programming 73, 227–250.
Noe¨ l, M.-C., Y. Smeers (1986). On the use of nested decomposition for solving nonlinear multistage
stochastic programs, in: Stochastic Programming (Gargnano, 1983), Lecture Notes in Control and
Inform. Sci., Vol. 76, Springer, Berlin, pp. 235–246.
Noe¨ l, M.-C., Y. Smeers (1987). Nested decomposition of multistage nonlinear programs with recourse.
Mathematical Programming 37, 131–152.
Opial, Z. (1967). Weak convergence for the sequence of successive approximations for nonexpansive
mappings. Bulletin of the American Mathematical Society 73, 591–597.
Powell, M.J.D. (1969). A method for nonlinear constraints in minimizing problems, in: R. Fletcher
(ed.), Optimization, Academic Press, New York, pp. 283–298.
Rockafellar, R.T. (1976). Monotone operators and the proximal point algorithm. SIAM Journal on
Control and Optimization 14, 877–898.
Rockafellar, R.T. (1976). Augmented Lagrangians and applications of the proximal point algorithm in
convex programming. Mathematics of Operations Research 1, 97–116.
210
A. Ruszczyn´ski

Rockafellar, R.T., R.J.-B. Wets (1991). Scenarios and policy aggregation in optimization under
uncertainty. Mathematics of Operations Research 16, 1–23.
Ruszczyn´ ski, A. (1986). A regularized decomposition method for minimizing a sum of polyhedral
functions. Mathematical Programming 35, 309–333.
Ruszczyn´ ski, A. (1993). Parallel decomposition of multistage stochastic programming problems.
Mathematical Programming 58, 201–228.
Ruszczyn´ ski, A. (1995). On convergence of an augmented Lagrangian decomposition method for
sparse convex optimization. Mathematics of Operations Research 20, 634–656.
Ruszczyn´ ski, A., A. S´ wietanowski (1997). Accelerating the regularized decomposition method for two
stage stochastic linear problems. European Journal of Operational Research 101, 328–342.
Stephanopoulos, G., W. Westerberg (1975). The use of Hestenes’ method of multipliers to resolve
dual gaps in engineering system optimization. Journal of Optimization Theory and Applications 15,
285–309.
Van Slyke, R., R.J.-B. Wets (1969). L-shaped linear programs with applications to optimal control and
stochastic programming. SIAM Journal on Applied Mathematics 17, 638–663.
Wallace, S.W. (1986). Solving stochastic programs with network recourse. Networks 16, 295–317.
Wallace, S.W. (1986). Decomposing the requirement space of the transportation problem into
polyhedral cones. Mathematical Programming Study 28, 29–47.
Wets, R.J.-B. (1966). Programming under uncertainty: the equivalent convex program. SIAM Journal
on Applied Mathematics 14, 89–105.
Wets, R.J.-B. (1988). Large scale linear programming techniques in stochastic programming,
in: Yu.M. Ermoliev, R.J.-B. Wets (eds.), Numerical Techniques for Stochastic Optimization,
Springer-Verlag, Berlin, pp. 65–93.
Zakeri, G., A.B. Philpott, D.M. Ryan (2000). Inexact cuts in Benders decomposition. SIAM Journal on
Optimization 10, 643–657.
Ch. 3. Decomposition Methods
211

Chapter 4
Stochastic Integer Programming
Franc¸ois V. Louveaux
De´partement des Me´thodes Quantitatives, Faculte´s Universitaires Notre Dame de la Paix,
Rempart de la Vierge 8, B-5000 Namur, Belgium, E-mail: flouveaux@fundp.ac.be
Ru¨diger Schultz
Institut fu¨r Mathematik, Universita¨t Duisburg-Essen, Lotharstraße 65, D-47048 Duisburg,
Germany, E-mail: schultz@math.uni-duisburg.de
Abstract
When introducing integer variables into traditional linear stochastic programs
structural properties and algorithmic approaches have to be rethought from the
very beginning. Employing basics from parametric integer programming and
probability theory we analyze the structure of stochastic integer programs. In
the algorithmic part of the paper we review solution techniques from integer
programming and discuss their impact on the specialized structures met in
stochastic programming.
Key words:
Stochastic integer programs, mixed-integer recourse, simple integer
recourse, multi-stage models, decomposition schemes, cutting planes,
Lagrangian relaxation, integer L-shaped algorithm, sampling methods.
1
Introduction
Like in other branches of mathematical optimization, integer variables are
indispensable in many stochastic programming models. Integrality either may
occur explicitly via indivisibles or Boolean decisions. Or it may occur in
implicit fashion as a modelling tool, for instance when handling disjunctions
and discontinuities, or when dealing with nonconvex piecewise linearity.
As an example let us reconsider the popular newsboy problem: a newsboy
can purchase from a publisher a number of newspapers with purchase costs
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
213

ci and selling costs qi, i ¼ 1,. . . , s. Each newspaper has a weight ai, and a
total weight b is available to the newsboy. The demand for newspapers,
which is unknown to the newsboy at the time of purchase, is described by a
random vector h(!) 2 Rs on some probability space (O, F, P). Unsold
newspapers cannot be returned to the publisher. The newsboy faces the
problem to purchase from the publisher in such a way that the proﬁt after
selling is maximal. Maximizing the expected proﬁt leads to the stochastic
program
minfcTx þ EP½Qðx, hð!ÞÞ: 0  aTx  bg
ð1:1Þ
where
Qðx, hð!ÞÞ ¼ minfqTy: 0  y  hð!Þ, y  xg:
ð1:2Þ
The newsboy problem is a specimen from a class of cost minimization (or
proﬁt maximization) problems where planning decisions must be taken before
and operational decisions are taken after observation of a random demand. It
is quite common to model these problems under the assumption that the
commodities involved are inﬁnitely divisible. As in (1.1), (1.2) this leads to
decision variables in the real numbers. However, when dealing with
indivisibles, as the newsboy obviously does, the precise modeling would
require integer variables. The model (1.1), (1.2) then has to be supplemented
by the conditions x 2 Zs
þ and y 2 Zs
þ.
Now let us assume that, for renting a newsstand, for instance, the newsboy
faces ﬁxed charge costs f when selling the newspapers. Then, disregarding
divisibility or indivisibility of goods, the discontinuity of the cost structure
leads to an integer variable in (1.2):
Qðx, hð!ÞÞ ¼ minfqTy þ fu: 0  y  hð!Þu, y  x, u 2 f0, 1gg:
In the simple examples discussed above integrality, of course, does not
pose a real challenge. This changes drastically if the above modeling
paradigms occur in more complex situations. In principle, any integer or
mixed-integer programming model arising in operations research may be
aﬀected by randomness and hence give rise to a stochastic programming
extension.
In the present chapter we will see that the appearance of integer
requirements
has
substantial
structural
and
algorithmic
consequences
for stochastic programming models as discussed in Chapters 1 and 2, for
instance.
214
F.V. Louveaux and R. Schultz

2
Structural properties
2.1
Two-stage models with complete integer recourse
Introducing integer requirements into the two-stage stochastic linear
program from Section 2 of Chapter 2 leads to the optimization problem
min
x fcTx þ EP½Qðx, ð!ÞÞ: x 2 Xg
ð2:3Þ
where Q(x, (!)) is the optimal value of the second-stage problem
min
ðy,y0ÞfqTy þ q0Ty0 : Tx þ Wy þ W0y0 ¼ hð!Þ, y 2 Zn2
þ , y0 2 R
n0
2
þ g:
ð2:4Þ
We assume that all ingredients above have conformable dimensions, that W,
W 0 are rational matrices, and that X  Rn1 is a nonempty closed polyhedron,
possibly involving integrality constraints on components of the vector x. For
ease of exposition, q, q0, W, W 0, T are deterministic, such that the random
variable (!) ¼ h(!), living on some probability space (O, F, P), is the only
stochastic ingredient. So far, most of the subsequent results on stochastic
integer programs were obtained for that special case. Where appropriate, we
will point to existing results under more general randomness.
As with the two-stage stochastic linear program, the second-stage value
function : Rm2 ! R with
ðtÞ :¼ min
ðy,y0ÞfqTy þ q0Ty0 : Wy þ W0y0 ¼ t, y 2 Zn2
þ , y0 2 R
n0
2
þ g
ð2:5Þ
is of prime importance for the structure of (2.3). Recall that, without integer
requirements,  is convex on its domain of ﬁniteness. To obtain a ﬁrst
impression on the impact of integrality let us start with two illustrative
examples. They are both derived from
ðtÞ ¼ minfyþ þ y : yþ  y ¼ t, yþ 2 Rþ, y 2 Rþg:
ð2:6Þ
This is the classical simple-recourse situation. By duality one immediately
obtains that (t) ¼ jtj.
Ch. 4. Stochastic Integer Programming
215

Now we add another variable v which we require to be integral:
ðtÞ ¼ min 1
2 vþyþþy : v þ yþ  y ¼t, v 2 Zþ, yþ 2 Rþ, y 2 Rþ


¼ min 1
2 v þ jt  vj: v 2 Zþ


:
Understanding v 2 Z þ as indices, the function  can be seen as the pointwise
minimum of staggered absolute values. Hence,  is no longer convex but still
continuous, even Lipschitz continuous on R.
The second example is basically derived by turning y þ and y into integer
variables:
ðtÞ ¼ minfvþ þ v : y þ vþ  v ¼ t, y 2 Rþ, vþ 2 Zþ, v 2 Zþg
¼
0,
t  0
t,
t < 0:

Here d  e denotes the integer round-up operation. Obviously,  is no longer
continuous, but still lower semicontinuous. Moreover, discontinuities occur in
a set of Lebesgue measure zero only, and ‘‘jump heights’’ at discontinuities are
globally bounded.
From these observations it becomes quite clear that, with stochastic integer
programs, basic properties like convexity and duality, that are so important in
the purely linear case, cannot be maintained for reasonable problem classes.
Let us now study the mixed-integer value function in more detail.
Proposition 1. Suppose that the recourse in (2.3)–(2.4) is complete, i.e.,
WðZn2
þ Þ þ W0ðR
n0
2
þ Þ ¼ Rm2,
ð2:7Þ
and that the LP relaxation to the second-stage problem has a feasible dual, i.e.,
fu 2 Rm2 : WTu  q, W0Tu  q0g 6¼ ;,
ð2:8Þ
then the value function (  ) is well-deﬁned on Rm2.
Proof. Let t 2 Rm2. By (2.7), the mixed-integer program deﬁning (t) is
feasible. By the existence theorem of mixed-integer linear programming this
problem then is solvable provided it is bounded. The latter, however, follows
from the solvability of the LP relaxation to the mixed-integer program
deﬁning (t) which is a consequence of the primal feasibility implied by (2.7)
and the dual feasibility in (2.8).
u
216
F.V. Louveaux and R. Schultz

Before proceeding further, let us have a quick look at the linear-
programming counterpart to  that has been studied in more detail in
Chapter 2:
linðtÞ :¼ minfq0Ty0 : W0y0 ¼ t, y0 2 R
n0
2
þ g:
ð2:9Þ
If we assume that W0ðR
n0
2
þ Þ is full-dimensional and that
fu 2 Rm2 : W0Tu  q0g 6¼ ;,
then the latter set has vertices dk, k ¼ 1,. . . , K, and it holds by linear
programming duality that
linðtÞ ¼ maxftTu: W0Tu  q0g ¼ max
k¼1,...,K dT
k t
for all t 2 W0ðR
n0
2
þ Þ:
Hence, lin is convex and piecewise linear on its (conical) domain of
deﬁnition.
Imposing the basic assumptions (2.7) and (2.8) we obtain
ðtÞ ¼ minfqTy þ q0Ty0 : Wy þ W0y0 ¼ t, y 2 Zn2
þ , y0 2 R
n0
2
þ g
¼ min
y fqTy þ min
y0 fq0Ty0: W0y0 ¼ t  Wy, y0 2 R
n0
2
þ g: y 2 Zn2
þ g
¼ min
y fyðtÞ: y 2 Zn2
þ g,
ð2:10Þ
where
yðtÞ ¼ qTy þ max
k¼1,...,K dT
k ðt  WyÞ
for all t 2 Wy þ W0ðR
n0
2
þ Þ:
Here, dk, k ¼ 1,. . . , K are the vertices of fu 2 Rm2 : W0Tu  q0g, and we have
applied the argument about lin from the purely linear case. For t 62
Wy þ W0ðR
n0
2
þ Þ the problem miny0fq0Ty0 : W0y0 ¼ t  Wy, y0 2 R
n0
2
þ g is infeasible,
and we put y(t) ¼ þ 1. It is convenient to introduce the notation
YðtÞ :¼ fy 2 Zn2
þ : yðtÞ < þ1g.
According to (2.10) the value function  is made up by the pointwise
minimum of a family of convex, piecewise linear functions whose domains
of deﬁnition are polyhedral cones arising as shifts of the cone W0ðR
n0
2
þ Þ.
By our basic assumption WðZn2
þ Þ þ W0ðR
n0
2
þ Þ ¼ Rm2, the cone W0ðR
n0
2
þ Þ is full-
dimensional.
Ch. 4. Stochastic Integer Programming
217

Some ﬁrst conclusions about the continuity of  may be drawn from the
above observations:
(1) Suppose that t 2 Rm2 does not belong to any boundary of any of the
sets Wy þ W0ðR
n0
2
þ Þ, y 2 Zn2. Then the same is true for all points  in
some open ball B around t. Hence, Y() ¼ Y(t) for all  2 B. With an
enumeration (y) 2 N of Y(t) we consider the functions ðÞ :¼
minfyðÞ:   g for all  2 B. Then lim!1 ðÞ ¼ ðÞ for all  2 B.
Since, for any function y, its ‘‘slopes’’ are determined by the same,
ﬁnitely many vectors dk, k ¼ 1,. . . , K, the functions ,  2 N are all
Lipschitz continuous on B with a uniform Lipschitz constant. Thus, the
family of functions ,  2 N is equicontinuous on B and has a pointwise
limit there. Consequently, this pointwise limit  is continuous on B, in
fact Lipschitz continuous with the mentioned uniform constant.
(2) Any discontinuity point of  must be located at the boundary of some
set Wy þ W0ðR
n0
2
þ Þ, y 2 Zn2. Hence, the set of discontinuity points of  is
contained in a countable union of hyperplanes. Since W0ðR
n0
2
þ Þ has only
ﬁnitely many facets, this union of hyperplanes subdivides into ﬁnitely
many classes, such that, in each class, the hyperplanes are parallel. By
the rationality of the matrices W and W0, within each class, the pairwise
distance of the hyperplanes is uniformly bounded below by some
positive number.
(3) Let t ! t and y 2 Zn2 such that t 2 Wy þ W0ðR
n0
2
þ Þ for all suﬃciently
large
.
Since
the
set
Wy þ W0ðR
n0
2
þ Þ
is
closed,
this
yields
t 2 Wy þ W0ðR
n0
2
þ Þ. Therefore, for suﬃciently large , Y(t)  Y(t).
This paves the way for showing that lim inft!t ðtÞ  ðtÞ, which is
the lower semicontinuity of  at t.
The above analysis can be extended into the following result that dates back
to a series of papers by Blair and Jeroslow, out of which we refer to Blair and
Jeroslow (1977), and to the monographs Bank et al. (1982) and Bank and
Mandel (1988).
Proposition 2. Let W, W0 be matrices with rational entries and assume that
WðZn2
þ Þ þ W0ðR
n0
2
þ Þ ¼ Rm2
as
well
as
fu 2 Rm2 : WTu  q, W0Tu  q0g 6¼ ;.
Then it holds
(1)  is real-valued and lower semicontinuous on Rm2,
(2) there exists a countable partition Rm2 ¼ [1
i¼1 T i such that the restrictions
of  to Ti are piecewise linear and Lipschitz continuous with a uniform
constant L>0 not depending on i,
(3) each of the sets Ti has a representation T i ¼ fti þ Kgn [N
j¼1 ftij þ Kg
where K denotes the polyhedral cone W0ðR
n0
2
þ Þ and ti, tij are suitable points
from Rm2, moreover, N does not depend on i,
(4) there exist positive constants ,  such that j(t1)(t2)j  kt1t2k þ 
whenever t1, t2 2 Rm2.
218
F.V. Louveaux and R. Schultz

Let us now consider the expected value function
ðxÞ :¼ EP½Qðx, ð!ÞÞ ¼ EP½ðð!Þ  TxÞ ¼ E½ð  TxÞ
ð2:11Þ
where  denotes the image measure P1 on Rm2. Thanks to the lower
semicontinuity in part (1) of Proposition 2, the integrand Q(x,  ) is
measurable for all x 2 Rn1. Moreover, lower semicontinuity and continuity
are inherited according to the general principles displayed in Proposition 14
of Chapter 1 and Proposition 1 of Chapter 2. This is made precise in the
following proposition.
Proposition 3. Suppose that: (i) W, W0 are rational, (ii) WðZn2
þ Þ þ W0ðR
n0
2
þ Þ ¼
Rm2, (iii) fu 2 Rm2 : WTu  q, W0Tu  q0g 6¼ ;, (iv) E½kk < 1. Then the
expected value function  is lower semicontinuous on Rn1. If, moreover,
(E(x)) ¼ 0 where EðxÞ :¼ f 2 Rm2 :  is discontinuous at   Txg, then  is
continuous at x.
Proof. Let x 2 Rn1 and xk ! x. Denote r :¼ maxk 2 N kxkk. Assumptions (ii)
and (iii) in particular imply that (0) ¼ 0. Part (4) of Proposition 2 then yields
the estimate
ð  TxkÞ  ð0Þ  jð  TxkÞ  ð0Þj  k  Txkk  
 kk  rkTk  
such that, together with (iv), the function k  krkTk provides an
integrable minorant for the functions (  Txk), k 2 N. Fatou’s Lemma and
the lower semicontinuity of  now imply
ðxÞ ¼
Z
Rm2 ð  TxÞðdÞ 
Z
Rm2 lim inf
k!1 ð  TxkÞðdÞ
 lim inf
k!1
Z
Rm2 ð  TxkÞðdÞ ¼ lim inf
k!1 ðxkÞ
which proves the desired lower semicontinuity. For proving continuity we
again employ part (4) of Proposition 2 together with (0) ¼ 0. We obtain the
estimate
jð  TxkÞj ¼ jð  TxkÞ  ð0Þj  kk þ rkTk þ 
Ch. 4. Stochastic Integer Programming
219

which, in view of (iv), provides us with an integrable majorant for the
functions j(  Txk)j, k 2 N. By (E(x)) ¼ 0, we have
lim
k!1 ð  TxkÞ ¼ ð  TxÞ
for -almost all  2 Rm2:
Now Lebesgue’s Dominated Convergence Theorem completes the proof:
lim
k!1 ðxkÞ ¼ lim
k!1
Z
Rm2ð  TxkÞðdÞ ¼
Z
Rm2ð  TxÞðdÞ ¼ ðxÞ:
u
Recall that, by conclusion (1.2) in front of Proposition 2, the set of
discontinuity points of , and hence E(x), is contained in a countable union of
hyperplanes, which is a set of Lebesgue measure zero. Assume that  has a
density and that (i)–(iv) are fulﬁlled. Then (E(x)) ¼ 0 for all x 2 Rn1, and  is
continuous on Rn1. The next statement addresses Lipschitz continuity. To
avoid further technicalities, we formulate the result for the case that  has a
density.
Proposition 4. Suppose that: (i) q, q0, W, W0 all have rational entries, (ii)
WðZn2
þ Þ þ W0ðR
n0
2
þ Þ ¼ Rm2,
(iii)
fu 2 Rm2 : WTu  q, W0Tu  q0g 6¼ ;,
(iv)
E[kk]<1, (v)  has a density and for any nonsingular linear transformation
B 2 LðRm2, Rm2Þ all one-dimensional marginal distributions of B have
bounded densities which, outside some bounded interval, are monotonically
decreasing with growing absolute value of the argument. Then  is Lipschitz
continuous on any bounded subset of Rn1.
Proof. Let x0, x00 belong to some bounded subset D of Rn1. Denote
Sðx0, x00Þ :¼
[
i2N
ððTx0 þ T iÞ \ ðTx00 þ T iÞÞ
where Ti are as in part (2) of Proposition 2. Note that for all  2 S(x0, x00) we
then have the estimate
jð  Tx0Þ  ð  Tx00Þj  L  kTx0  Tx00k:
ð2:12Þ
220
F.V. Louveaux and R. Schultz

Now
jðx0Þ  ðx00Þj 
Z
Sðx0,x00Þ
jð  Tx0Þ  ð  Tx00ÞjðdÞ
þ
Z
Rm2 nSðx0,x00Þ
jð  Tx0Þ  ð  Tx00ÞjðdÞ:
Employing (2.12) and part (4) of Proposition 2 gives the estimate
jðx0Þ  ðx00Þj  ðL þ Þ  kTk  kx0  x00k þ   ðRm2nSðx0, x00ÞÞ:
We complete the proof by deducing a Lipschitz estimate for the second term
on the right. Let Hk, k ¼ 1,. . . , K be the hyperplanes containing the facets of
the cone W0ðR
n0
2
þ Þ that arises in part (3) of Proposition 2 and is full-
dimensional by (ii). The set Rm2nSðx0, x00Þ then is contained in a ﬁnite union of
sets Hk, k ¼ 1,. . . , K each of which is a countable union of ‘‘sandwiches’’ Hk,i,
i 2 N. Each ‘‘sandwich’’ Hk,i is the region in between and including the aﬃne
hyperplanes
ti þ Tx0 þ Hk
and
ti þ Tx00 þ Hk
where ti, i 2 N, are as in part (3) of Proposition 2. By a nonsingular linear
transformation Bk we map the hyperplane Hk to the hyperplane which is
orthogonal to the ﬁrst coordinate vector. Then (Hk) can be estimated using
the marginal density 	k of the ﬁrst component with respect to the image
measure   B1
k :
ðHkÞ  c1 
X
i2N
Z i,kðx00Þ
i,kðx0Þ
	kðÞ d:
Here, c1>0 is some constant, and i,k(x0), i,k(x00) are the ﬁrst components of
Bk(ti þ Tx0) and Bk(ti þ Tx00), respectively. Without loss of generality we
assume that i,k(x0)<i,k(x00). Clearly, there exists a constant c2>0 such that
i,kðx00Þ  i,kðx0Þ  c2  kx0  x00k:
ð2:13Þ
Using the rationality of q, q0, W, W0 one can show that the sequence
(i,k(x0))i 2 N has no accumulation points. Since x0, x00 belong to the bounded set
D, there exists an index i ¼ iðDÞ, independent of x0, x00, such that the intervals
[i,k(x0), i,k(x00)] (up to renumbering) meet the bounded interval from
assumption (v) at most of i  i.
Ch. 4. Stochastic Integer Programming
221

According to assumption (v) we have an upper bound 	k for 	k(  ). For
i > i, we denote by ~i,k the left or right endpoint of [i,k(x0), i,k(x00)] depending
on whether 	k is decreasing or increasing on that interval. This allows the
estimate
X
i2N
Z
i,kðx00Þ
i,kðx0Þ
	kðÞ d 
X
ii
	k  ði,kðx00Þ  i,kðx0ÞÞ
þ
X
i>i
	kð~i,kÞ  ði,kðx00Þ  i,kðx0ÞÞ:
In view of (2.13), there exists a constant c3>0 such that the ﬁrst sum on the
right is estimated above by c3kx0x00k. For the second sum we obtain the
upper estimate c2
P
i>i 	kð~i,kÞ  kx0  x00k. It remains to show that P
i>i 	kð~i,kÞ
is ﬁnite.
Let us do so for the sum over all i > i belonging to those ~i,k around which
	k is decreasing. For the remaining i > i a similar argument applies. Since the
~i,k do not accumulate, it holds with some ">0
1 
X
i
Z~i,k
~i,k"
	kðÞ d 
X
i
Z~i,k
~i,k"
	kð~i,kÞ d ¼ " 
X
i
	kð~i,kÞ,
providing the desired ﬁniteness. Repeating the above arguments for all Hk,
k ¼ 1,. . . , K, one conﬁrms that there exists a constant c>0 such that
ðRm2nSðx0, x00ÞÞ 
X
K
k¼1
ðHkÞ  c  kx0  x00k,
and the proof is complete.
u
The following examples show that the boundedness and the monotonicity
in assumption (v) of the above proposition are indispensable.
Example
5. Let
ðtÞ ¼ minfy: y  t, y 2 Zg ¼ dte
and

be
given
by
the (unbounded) density 	, for which 	() ¼ 1/2 if 0<  1/4 and 	() ¼ 0,
otherwise. Then (x) ¼ 1 for 3/4  x  0 and ðxÞ ¼ 1  2
ﬃﬃﬃx
p
if 0  x  1/4.
This function is not Lipschitz continuous on neighborhoods of x0 ¼ 0.
Example 6. Let ðtÞ ¼ minfy: y  t, y 2 Zg ¼ dte and  be given by the
density 	, for which 	() ¼ 1/ if  2 ½,  þ 1
2  c, c :¼ ðP1
k¼1 1=k3Þ1,  2 N,
and 	() ¼ 0, otherwise. This density violates the monotonicity assumption in
222
F.V. Louveaux and R. Schultz

Proposition 4. We show that  is not Lipschitz continuous on neighborhoods
of x0 ¼ 0.
Assumptions (i)–(iii) of Proposition 4 are clearly met. Moreover, 	 is
bounded and assumption (iv) is fulﬁlled, since
Z
þ1
1
	ðÞ d 
X
1
¼1
ð þ 1Þ  1
  1
2  c ¼ c 
2
6 þ 1:
For arbitrary x 2 R, 0<x<1, it holds
ð0Þ  ðxÞ ¼
X
1
¼1
Z
þx

	ðÞ d 
X
ðxÞ
¼1
1
  x,
where ðxÞ :¼ 8
ﬃﬃc
x
p 9. Consider xk :¼ 1
k2  c, k 2 N. The above yields
1
xk
ðð0Þ  ðxkÞÞ 
X
k
¼1
1
 :
For k ! 1, the left-hand side tends to inﬁnity, proving that  is not Lipschitz
continuous on neighborhoods of x0 ¼ 0.
When studying the stability behaviour of the stochastic program (2.3)
with respect to perturbations of the underlying probability measure, see
the chapter ‘‘Stability of Stochastic Programming Problems’’ for an exposition
of stability analysis, it is crucial to detect the continuity of the expected
recourse function , jointly in the decision vector x and the probability measure
. As a prerequisite, then a suitable convergence notion for probability
measures is needed. Here, weak convergence of probability measures has
proven both suﬃciently general to cover relevant applications and suﬃciently
speciﬁc to enable substantial results. A sequence (k)k 2 N in the space PðRm2Þ
of Borel probability measures on Rm2 is said to converge weakly to  2 PðRm2Þ,
written k!
w , if for any bounded continuous function g : Rm2 ! R we have
Z
Rm2
gðÞkðdÞ !
Z
Rm2
gðÞðdÞ
as
k ! 1:
ð2:14Þ
For
establishing
joint
continuity
of
 ¼ (x, )
a
theorem
on
weak
convergence of image measures attributed to Rubin will be very useful. This
theorem says: Let gk, g (k 2 N) be measurable functions from Rm2 to R and
Ch. 4. Stochastic Integer Programming
223

denote
E :¼ f 2 Rm2 : 9k !  such that gkðkÞ 6! gðÞg.
If
k!
w 
and
(E) ¼ 0, then k  g1
k !
w   g1.
Proposition 7. Fix arbitrary p>1 and K>0, and denote p,KðRm2Þ :¼
f 2 PðRm2Þ: E½kkp  Kg. Let  2 p,KðRm2Þ be such that (E(x)) ¼ 0.
Then the function  : Rn1  p,KðRm2Þ ! R is continuous at (x, ).
Proof. Let xk ! x in Rn1 and k!
w  in p,KðRm2Þ. Introduce measurable
functions gk, k 2 N, and g by gkðÞ :¼ ð  TxkÞ and gðÞ :¼ ð  TxÞ. For
the corresponding exceptional set E a simple continuity argument provides
E(x)c  E c or, equivalently, E  E(x). Hence, (E) ¼ 0, and Rubin’s Theorem
yields
k  g1
k !
w   g1:
ð2:15Þ
Changing variables in the assertion
lim
n!1
Z
Rm2 gkðÞkðdÞ ¼
Z
Rm2 gðÞðdÞ
yields the equivalent statement
lim
n!1
Z
R
k  g1
k ðdÞ ¼
Z
R
  g1ðdÞ:
For ﬁxed a 2 R þ, consider the truncation a: R ! R with
aðÞ :¼
,
jj < a
0,
jj  a:

Now

Z
R
k  g1
k ðdÞ 
Z
R
  g1ðdÞ



Z
R
ð  aðÞÞk  g1
k ðdÞ
 þ

Z
R
aðÞk  g1
k ðdÞ

Z
R
aðÞ  g1ðdÞ
 þ

Z
R
ðaðÞ  Þ  g1ðdÞ
:
ð2:16Þ
224
F.V. Louveaux and R. Schultz

The proof is completed by showing that, for a given ">0, each of the three
expressions on the right becomes less than "/3 provided that n and a are
suﬃciently large.
For the ﬁrst expression we obtain

Z
R
ð  aðÞÞk  g1
k ðdÞ
 
Z
f:jjag
jjk  g1
k ðdÞ
¼
Z
f:jgkðÞjag
jgkðÞjkðdÞ:
ð2:17Þ
Since p>1,
Z
Rm2
jgkðÞjpkðdÞ 
Z
f:jgkðÞjag
jgkðÞj  jgkðÞjp1kðdÞ
 ap1
Z
f:jgkðÞjag
jgkðÞjkðdÞ:
ð2:18Þ
Therefore, the estimate in (2.17) can be continued by
 a1p
Z
Rm2
jgkðÞjpkðdÞ:
ð2:19Þ
Proposition 2, part (4), and gk(0) ¼ 0 imply
jgkðÞjp  ðkk þ kxkk  kTk þ Þp:
Since (xk)k 2 N is bounded and all k belong to p,KðRm2Þ, there exists a
positive constant c such that
Z
Rm2
jgkðÞjpkðdÞ  c
for all k 2 N:
Hence, (2.19) can be estimated above by c/ap1 which becomes less than "/3 if
a is suﬃciently large.
Ch. 4. Stochastic Integer Programming
225

We now turn to the second expression in (2.16). Since every probability
measure on the real line has at most countably many atoms, we obtain that
  g1ðf : jj ¼ agÞ ¼ 0 for (Lebesgue-) almost all a 2 R. Therefore, a is a
measurable function whose set of discontinuity points Da has g1-measure
zero for almost all a 2 R. We apply Rubin’s Theorem to the weakly convergent
sequence k  g1
k !
w   g1, cf. (2.15), and the identical sequence of functions
a. The role of the exceptional set then is taken by Da, and Rubin’s Theorem
is working due to g1(Da) ¼ 0. This yields the conclusion
k  g1
k  1
a !
w   g1  1
a
for almost all a 2 R:
ð2:20Þ
Consider the bounded continuos function  : R ! R given by
ð0Þ :¼
a,
0  a
0,
a  0  a
a,
0  a:
8
>><
>>:
By the weak convergence in (2.20), we obtain for n ! 1
Z
R
ð0Þk  g1
k  1
a ðd0Þ !
Z
R
ð0Þ  g1  1
a ðd0Þ:
ð2:21Þ
Changing variables provides
Z
R
ð0Þk  g1
k  1
a ðd0Þ ¼
Z
1
a ðRÞ
ðaðÞÞk  g1
k ðdÞ
¼
Z
R
aðÞk  g1
k ðdÞ:
Analogously,
Z
R
ð0Þ  g1  1
a ðd0Þ ¼
Z
R
aðÞ  g1ðdÞ:
226
F.V. Louveaux and R. Schultz

The above identities together with (2.21) conﬁrm that the second expression
on the right-hand side of (2.16) becomes arbitrarily small for suﬃciently large
n and almost all suﬃciently large a.
Let us ﬁnally turn to the third expression in (2.16). Analogously to (2.17),
(2.18) and (2.19) we obtain

Z
R
ðaðÞ  Þ  g1ðdÞ
  a1p
Z
Rm2
jgðÞjpðdÞ:
The integral
R
Rm2 jgðÞjpðdÞ is ﬁnite due to part (4) of Proposition 2 and
E[kkp]  K. Hence, the third expression in (2.16) becomes less than "/3 if a is
large enough.
u
Employing
well-established
arguments
of
parametric
optimization
Proposition 7, together with standard assumptions such as boundedness of
the unperturbed solution set, leads to (qualitative) continuity of the (multi-)
functions assigning to the underlying probability measure the optimal value
and the set of optimal solutions to (2.3), respectively. Quantitative continuity
of (  ,  ) and quantitative stability of (2.3) require the identiﬁcation of
suitable distances on the space PðRm2Þ of probability measures.
2.2
Simple integer recourse
Simple recourse models are two-stage stochastic programs where deviations
of a ﬁrst-stage bid Tx against the random outcome h(!) have to be
compensated at certain costs in the second-stage. In simple integer recourse
this compensation must be integer. In (2.6) we had already seen a second-stage
value function  corresponding to a simple recourse model in case h(!) maps
to R1.
A two-stage stochastic program with simple integer recourse is given by
min
x fcTx þ E½ð  TxÞ: x 2 Xg
ð2:22Þ
where
ðtÞ :¼ minfðqþÞTyþ þ ðqÞTy : yþ  t, y  t, yþ 2 Zs
þ, y 2 Zs
þg:
ð2:23Þ
Ch. 4. Stochastic Integer Programming
227

It is easy to see that the optimization problem in (2.23) is feasible for any
t 2 Rs, so the model has complete recourse. If, moreover, we assume that
q þ  0 and q  0, then the LP relaxation to the second-stage problem has a
feasible dual, and (t) 2 R for all t 2 Rs. Finally, the assumption E[kk]<1
will guarantee that the expectation in (2.22) is ﬁnite such that (2.22) becomes a
well-deﬁned optimization problem.
The crucial fact, allowing for a much richer analysis in simple integer
recourse than in the general situation of (2.3)–(2.4), is the expressibility of the
value function (t) in closed form, namely
ðtÞ ¼
X
s
i¼1
qþ
i dtieþ þ q
i dtieþ


ð2:24Þ
where d  e þ :¼ max{d  e, 0}. For the expected value function this implies the
following separable representation
ðxÞ ¼ E½ð  TxÞ
¼
X
s
i¼1
qþ
i Ei di  ðTxÞieþ


þ
X
s
i¼1
q
i Ei dðTxÞi  ieþ


where i is the probability measure corresponding to the marginal distribution
of the i-th component of . Studying (x) thus is studying the functions
uiðiÞ :¼ Ei di  ieþ


and
viðiÞ :¼ Ei di  ieþ


ð2:25Þ
reﬂecting expected surplus and expected shortage, respectively. Both these
functions in one variable are quite similar, such that we will restrict
further considerations to the expected surplus function. The following
proposition reveals a close relationship with the cumulative distribution
function FiðÞ :¼ iðfi : i  gÞ of i. For notational convenience, we drop
the index i from now on.
Proposition 8. In the above setting it holds for all  2 R
uðÞ ¼
X
1
k¼0
ð1  Fð þ kÞÞ:
ð2:26Þ
228
F.V. Louveaux and R. Schultz

Proof. We have
X
1
k¼0
ð1  Fð þ kÞÞ ¼
X
1
k¼0
ð   > kÞ
¼
X
1
k¼0
X
1
j¼kþ1
 d  eþ ¼ j


¼
X
1
j¼1
X
j1
k¼0
 d  eþ ¼ j


¼
X
1
j¼1
j   d  eþ ¼ j


¼ E d  eþ


¼ uðÞ,
and the proof is complete.
u
Continuity and smoothness properties of u now result from those of the
distribution function F or, existence provided, from those of a suitable
probability density function of . In particular, it can be shown that u is
Lipschitz continuous on R if there exists a density of  with bounded
variation. Moreover, u is diﬀerentiable on R if there exists a continuous
density of .
The function u is convex if  has a probability density function that is
piecewise constant on every interval ] þ j,  þ j þ 1[, j 2 Z for some  2 [0, 1[.
Hence, when relating with arbitrary probability measures piecewise constant
densities depending on the shift parameter , one obtains convex functions
related with the in general nonconvex function u. Given  2 P(R), its
cumulative distribution function F, and  2 [0, 1[ we denote 89 :¼ 89 þ 
and relate the following probability density function with 
	ðÞ :¼ F 89 þ 1
ð
Þ  F 89
ð
Þ,
 2 R:
In the literature, the density 	 and the corresponding measure  as well as
the resulting convex function related with u are called -approximations. We
will adopt this here although it is quite clear that the ‘‘distance’’ of  and ,
and thus the approximation error in terms of the functions, in general cannot
be made arbitrarily small.
Ch. 4. Stochastic Integer Programming
229

Proposition 9. For any  2 [0, 1[ the -approximation
uðÞ :¼ E d  eþ


of the expected surplus function u is a convex function on R.
For the expected shortage function v an analogous statement is valid.
Interestingly, the resulting convex -approximation for
~ðÞ :¼ qþuðÞ þ qvðÞ,
qþ þ q > 0,
then, up to an additive constant, arises as an expected value function of a
simple recourse model with continuous variables where the underlying
probability measure has been properly modiﬁed:
Proposition 10. Let  2 [0, 1[, q þ þ q>0, and u, v denote the -approxima-
tions for the expected surplus and shortage function u and v, respectively. Then it
holds for all  2 R:
~ðÞ :¼ qþuðÞ þ qvðÞ
¼ qþE d  eþ


þ qE d  eþ


þ
qþq
qþ þ q
where v is a discrete probability measure such that for all k 2 Z
ðf þ kgÞ :¼
qþ
qþ þ q ðFð þ kÞ  Fð þ k  1ÞÞ
þ
q
qþ þ q ðFð þ k þ 1Þ  Fð þ kÞÞ:
The results outlined above are derived in detail in van der Vlerk (1995), see
also the articles mentioned in the Bibliographical Notes below.
2.3
Multi-stage models
The models discussed so far assume a two-stage setting for the gain of
information. Uncertainty is unveiled at once and decisions subdivide into
those before and those after the unveiling. Often, a more complex view is
appropriate at this place. Multistage stochastic programs address the situation
230
F.V. Louveaux and R. Schultz

where uncertainty is unveiled stepwise with intermediate decisions that must
not anticipate future information. We refer to Chapters 1 and 2 for basic
statements about modeling principles and structure in the multi-stage
situation. In what follows, we will adopt a fairly general modeling perspective,
similar to Section 3.3 of Chapter 1. We will go beyond the setting of that
section by adding integer requirements, and we will study some ﬁrst
implications of such a model extension.
Consider a ﬁnite horizon sequential decision process under uncertainty
where the decision xt 2 Rnt at stage t 2 {1,. . . , T} is based on information
available up to time t only. Information is modeled as a discrete time
stochastic process ftgT
t¼1 on some probability space (O, F, P) with t taking
values in Rmt. The random vector t :¼ (1,. . . , t) then reﬂects the information
available up to time t. Nonanticipativity, i.e., the requirement that xt must not
depend on future information, is formalized by saying that xt is measurable
with respect to the -algebra Ft  F which is generated by t, t ¼ 1,. . . , T.
Clearly, Ft  Ft þ 1 for all t ¼ 1,. . . , T1. As in the two-stage case, the ﬁrst-
stage decision x1 usually is deterministic. Therefore, F1 ¼ {;, O}. Moreover,
we assume that FT ¼ F.
The constraints of our multi-stage models are subdivided into three groups.
The ﬁrst group comprises conditions on xt arising from the individual time
stages:
xtð!Þ 2 Xt,
Btðtð!ÞÞxtð!Þ  dtðtð!ÞÞ
P-almost surely,
t ¼ 1, . . . , T:
ð2:27Þ
Here, Xt  Rnt is a set whose convex hull is a polyhedron. In this way, integer
requirements to components of xt are allowed for. For simplicity we assume
that Xt is compact. Note that, by the integrality in Xt, we go beyond the setting
of all the multi-stage models analyzed in Chapters 1 and 2. As in the two-stage
case, convexity will no longer be available. In particular, the arguments based
on duality and conjugacy that led to Proposition 30 in Chapter 2, stating that
the multi-stage stochastic program is convex, are not working anymore, and,
in fact, the models become nonconvex.
The next group of constraints models linkage between diﬀerent time stages:
X
t
¼1
Atðtð!ÞÞxð!Þgtðtð!ÞÞ
P-almost surely, t ¼ 2, . . . , T:
ð2:28Þ
Finally, there is the nonanticipativity of xt, i.e.,
xt is measurable with respect to F t,
t ¼ 1, . . . , T:
ð2:29Þ
Ch. 4. Stochastic Integer Programming
231

In addition to the constraints we have a linear objective function
X
T
t¼1
ctðtð!ÞÞxtð!Þ:
The matrices At(  ), Bt(  ) as well as the right-hand sides dt(  ), gt(  ) and the
cost coeﬃcients ct(  ) all have conformable dimensions and depend aﬃnely
linearly on the relevant components of .
The decisions xt are understood as members of the function spaces
L1ðO, F, P; RntÞ, t ¼ 1,. . . , T. The constraints (2.27), (2.28) then impose
pointwise conditions on the xt, whereas (2.29) imposes functional constraints,
in fact, membership in a linear subspace of T
t¼1 L1ðO, F, P; RntÞ.
The multistage extension of (2.3) is the minimization of expected minimal
costs subject to nonanticipativity of decisions:
min
Z
O
min
xð!Þ
X
T
t¼1
ctðtð!ÞÞxtð!Þ : ð2:27Þ, ð2:28Þ
(
)
Pðd!Þ: x fulfilling ð2:29Þ
8
<
:
9
=
;
ð2:30Þ
The minimization in the integrand of (2.30) being separable with respect to
! 2 O, it is possible to interchange integration and minimization, and the
problem can be restated as
min
Z
O
X
T
t¼1
ctðtð!ÞÞxtð!ÞPðd!Þ: x fulfilling ð2:27Þ, ð2:28Þ, ð2:29Þ
8
<
:
9
=
;:
ð2:31Þ
Due to the mentioned interplay of pointwise and functional constraints it
remains to check whether (2.31) is well deﬁned, cf. Section 3.3 of Chapter 1
where this is addressed for a noninteger counterpart of (2.31).
Recall that Xt is compact and assume that t 2 L1ðO, F, P; RmtÞ for
t ¼ 1,. . . , T. For each ! 2 O we deﬁne the subset Y(!) of X :¼ T
t¼1 Rnt
Yð!Þ :¼
y 2 X : yt 2 Xt, Btðtð!ÞÞyt  dtðtð!ÞÞ, t ¼ 1, . . . , T,
(
X
t
¼1
Atðtð!ÞÞy  gtðtð!ÞÞ, t ¼ 2, . . . , T
)
ð2:32Þ
232
F.V. Louveaux and R. Schultz

and the extended real-valued function ’
’ð y1, . . . , yT, !Þ :¼
X
T
t¼1
ctðtð!ÞÞyt,
ð y1, . . . , yTÞ 2 Yð!Þ,
þ1,
otherwise
8
><
>:
ð2:33Þ
from X  O to (1, þ 1]. With these notations, (2.31) is equivalent to
minfEP½’ðx1, . . . , xT, !Þ: xt measurable w:r:t: F t, t ¼ 1, . . . , Tg:
ð2:34Þ
The real-valued function ð y, !Þ  PT
t¼1 ctðtð!ÞÞyt is continuous in y for each
! 2 O and measurable in ! for each y 2 X, and the set-valued mapping
Y from O to X is closed-valued and measurable (cf. Theorem 14.36 in
Rockafellar and Wets, 1997). With B(X ) denoting the -algebra of Borel sets
in X, the function ’ is B(X ) 	 F-measurable (cf. Example 14.32 in Rockafellar
and Wets, 1997). Furthermore, the following estimate is valid for each
y 2 T
t¼1 Xt and ! 2 O:
j’ð y1, . . . , yT, !Þj 
X
T
t¼1
kctðtð!ÞÞk sup
yt2Xt
kytk
ð2:35Þ
Hence, EP½’ðx1, . . . , xT, !Þ is ﬁnite for each decision x ¼ (x1,. . . , xT) such that
x(!) 2 Y(!) for P-almost all ! 2 O.
As in Evstigneev (1976), we construct recursively two sequences of
functions by putting  T þ 1 :¼ ’ and
’tð y1, . . . , yt, !Þ :¼ Er
P½ tþ1ð y1, . . . , yt, Þ j F tð!Þ,
ð2:36Þ
 tð y1, . . . , yt1, !Þ :¼ inf
y ’tð y1, . . . , yt1, y, !Þ,
ð2:37Þ
for t ¼ T, . . . , 1, and for each ! 2 O and y 2 X,  ¼ 1, . . . , T.
Here, Er
P½ j F t denotes the regular conditional expectation with respect to
Ft. By deﬁnition, the regular conditional expectation is a version of the
conditional expectation (i.e., Er
P½ j F t ¼ EP½ j F t, P-a.s.) with the property
that
the
mapping
ðz, !Þ  ðz, !Þ :¼ Er
P½ðz, Þ j F tð!Þ
from
Zt  O
to
(1, þ 1] is B(Zt) 	 Ft-measurable if  is B(Zt) 	 F-measurable. Here, Zt is
allowed to be an arbitrary closed subset of a Euclidean space. The regular
conditional expectation exists if  is B(Zt) 	 F-measurable and uniformly
integrable, i.e., there exists a (real) random variable  with ﬁnite ﬁrst moment
such that j(z, !)j  (!) for z 2 Zt and ! 2 O (see Dynkin and Evstigneev, 1976).
Ch. 4. Stochastic Integer Programming
233

Due to condition (2.35), relation (2.36) is well deﬁned for t ¼ T and leads to a
B(Z) 	 FT-measurable function T, where Z :¼ T
t¼1 Xt. It is shown in
Evstigneev (1976) that the relations (2.36) and (2.37) are well deﬁned for all
t ¼ T,. . . , 1. Furthermore, the following optimality criterion and existence
result for (2.34) or, equivalently, for (2.31) is valid.
Proposition 11. Adopt the above setting for (2.31) and assume that (2.31) has a
feasible solution. Then fxtgT
t¼1 is an optimal solution of (2.31) iﬀ
’tðxtð!Þ, !Þ ¼  tðxt1ð!Þ, !Þ,
P  a:s:, t ¼ 1, . . . , T:
ð2:38Þ
Moreover, there exists a solution x1 of the ﬁrst-stage optimization problem
minf’1ðx1Þ ¼ EP½ 2ðx1, !Þ: x1 2 X1, B1ð1Þx1  d1ð1Þg,
ð2:39Þ
and given F-measurable functions x for  ¼ 1,. . . , t1, there exists an F-
measurable function xt such that ’tðxtð!Þ, !Þ ¼  tðxt1ð!Þ, !Þ, P-a.s.
Relations (2.36) and (2.37) deﬁne the mixed-integer analogon to the nested
formulation developed in Section 3.1 of Chapter 1 for the purely linear case,
see also the general nested problem in continuous variables in Section 3.3 of
Chapter 1. In particular, the optimal value  tð y1, . . . , yt1, !Þ is the cost-to-go,
cf. (3.3) in Chapter 2, and (2.38) states the fact that an optimal solution to
(2.31) has to fulﬁl the dynamic programming equation, cf. (3.4) and
Proposition 30 in Chapter 2. As in (3.5) of Chapter 1, in problem (2.39) all the
subsequent stages are absorbed into the function ’1(x1). Hence, (2.39) is a
well-deﬁned mixed-integer extension of (3.5) in Chapter 1, with the only
diﬀerence that (3.5) has staircase whereas (2.39) triangular form.
In Proposition 30 of Chapter 2 convexity of the noninteger counterpart to
’1(  ) is shown. With integer requirements, this convexity already breaks down
for two-stage problems and hence cannot be expected to hold. However, lower
semicontinuity of ’1(  ) still can be established.
Proposition 12. Adopt the above setting for (2.31) and assume that the matrices
At(  ), Bt(  ) as well as the cost coeﬃcients ct(  ) all are deterministic. Then the
objective function ’1(  ) of the ﬁrst-stage optimization problem (2.39) is lower
semicontinuous on its domain of deﬁnition.
Proof. (Outline) The proof is done by induction over the time stages
t ¼ T, T1,. . . , 1. According to the deﬁnitions in (2.33) and (2.37), at each
stage an inﬁmum of a parameter dependent function over a mixed-integer set
constrained by linear inequalities is taken. Moreover, the latter set has
parameters in the right-hand sides of the inequalities. At each stage, it can be
234
F.V. Louveaux and R. Schultz

shown that the set-valued mapping assigning to the relevant right-hand side
parameter the relevant mixed-integer constraint set is upper semicontinuous.
At stage T, the objective function of the above parametric optimization
problem is linear and does not depend on a parameter. In fact, we have a
mixed-integer linear program with right-hand side parameters, whose value
function is lower semicontinuous according to the argument given in item (3)
in front of Proposition 2. A conditional expectation of this value function, cf.
(2.36), which, by Fatou’s Lemma for conditional expectations, is again lower
semicontinuous, enters the objective at stage T1, cf. (2.37).
Therefore, at stage T1, as well as in all subsequent stages t ¼ T2,. . . , 2,
we have a parametric program where, with respect to the relevant parameter,
the objective function is lower semicontinuous and the constraint set mapping
is upper semicontinuous. Basic results from parametric optimization, such as
Theorem 1.17 of Rockafellar and Wets (1997) then imply that the value
function of the optimization problem at stage T1 is lower semicontinuous
with respect to the relevant parameters. Fatou’s Lemma for conditional
expectations then inherits lower semicontinuity to the objective in stage T2,
and the above arguments can be repeated.
u
Structural properties for problem (2.31) beyond the above propositions are
widely open and a ﬁeld of current research.
3
Algorithms
3.1
Decomposition schemes
Consider a classical deterministic integer program
ðIPÞ
minfcTx: x 2 Xg:
ð3:40Þ
For simplicity, we consider the pure integer case, where X  Zn, although most
of the deﬁnitions and properties presented here extend to the mixed integer
case. In practice, the set X is described through a ﬁnite set of linear
constraints, deﬁning a polyhedron P ¼ fx 2 Rn : Ax  bg and through inte-
grality restrictions.
A polyhedron P  Rn is a formulation for X  Zn iﬀX ¼ P \ Zn. The ideal
formulation would be to replace IP by the equivalent linear program
minfcTx: x 2 convðXÞg
ð3:41Þ
as all extreme points of the convex hull of X belong to X. Such a formulation
naturally gives an integer solution to the linear programming relaxation
of (3.41).
Ch. 4. Stochastic Integer Programming
235

An inequality 
Tx  
0 is a valid inequality for X  Rn if 
Tx  
0 for all
x 2 X. The Chvatal–Gomory procedure to construct a valid inequality for
X ¼ P \ Zn is to consider a vector u 2 Rm
þ of nonnegative weights for the rows
of A, take the linear combination of the rows
uTAx  uTb,
round down the coeﬃcients in the l.h.s,
X
n
j¼1
8uTaj9xj  uTb
where aj is the jth column of A, then round-down the r.h.s.
X
n
j¼1
8uTaj9xj  8uTb9:
ð3:42Þ
The ﬁrst transformation is justiﬁed by u  0, the second by Pn
j¼1 8uTaj9xj 
Pn
j¼1 uTajxj, and the third as Pn
j¼1 8uTaj9xj is integer. Thus, for all u  0,
(3.42) is a valid inequality for X. More surprisingly, every valid inequality for
X can be obtained by applying the Chvatal–Gomory procedure a ﬁnite
number of times.
The separation problem SP associated with IP is the following : given
x 2 Rn, is x 2 convðXÞ? If not, ﬁnd a valid inequality 
Tx  
0 for X such that

Tx > 
0. As the Chvatal–Gomory procedure is not a constructive one, a
considerable amount of research has been devoted to characterize strong valid
inequalities, which deﬁne facets of P, and related separation algorithms (SA).
Among the popular SA, we may cite lifted cover inequalities for knapsack
constraints, mixed integer rounding inequalities (a generalization of Gomory
mixed integer cuts) and disjunctive inequalities. Separation algorithms are not
always eﬃcient, as sometimes the separation problem itself is NP-hard. Even
when the separation algorithm is eﬃcient, it may not be wise to generate all
possible valid inequalities as the linear program would tend to become huge.
Early attempt to use Gomory cuts appeared to be disappointing as successive
cuts tend to be less and less eﬃcient and the corresponding LP harder and
harder to solve. Cutting planes are thus very often combined with a branch &
bound scheme. Branching on a fractional value xj consists of deﬁning two
subregions X \ fx: xj  8xj9g and X \ fx: xj  8xj9 þ 1g. These subregions
can in turn be subdivided by later branchings. This generates a number of
nodes N,  ¼ 1,. . . , R, that form a partition of Rn, i.e., Rn ¼ U ¼ 1,. . . , RN and
N \ N ¼ ;,  6¼ .
236
F.V. Louveaux and R. Schultz

Clearly,
minfcTx: x 2 Xg ¼
min
¼1,..., RfminfcTx: x 2 X \ Ngg
The branch & bound procedure is ﬁnite as only ﬁnitely many nodes can be
generated when X is compact. Nodes are fathomed for three reasons: when
they have integer solution, when they have an optimal value, which is worse
than an already known integer solution, and when they are infeasible. As
already said, modern codes combine cut generation and branching in so called
branch & cut procedures. Another basic technique in integer programming is
Lagrangian relaxation. Its main idea is to relax ‘‘complicating’’ constraints to
end up with manageable subproblems that are coordinated by a nonsmooth
dual optimization. In general, integer requirements imply the lack of duality
such that, typically, heuristics have to be employed for ﬁnding promising
primal solutions on the basis of the results of the dual optimzation. We now
show how stochastic programming decomposition techniques could be
designed using cutting planes and branch & bound in the second-stage as
well as Lagrangian relaxation of nonanticipativity constraints.
Decomposition by cutting planes
Let the two stage stochastic integer problem be
ðSIPÞ
minfcTx þ E½ð  TxÞ: x 2 Xg
ð3:43Þ
with
ðtÞ :¼ minfqTy: Wy ¼ t, y 2 Yg
ð3:44Þ
and Y  Zn2
þ . All notations are as in Section 2. The deterministic equivalent
program is
ðDEPÞ
minfcTx þ QðxÞ: x 2 Xg
ð3:45Þ
where Q(x) ¼ E[(Tx)]. For all practical purposes, it can be transformed
into
minfcTx þ 	: x 2 X, 	  QðxÞg
ð3:46Þ
In view of the properties presented just above, the diﬃculty of solving (3.46)
precisely lies in having a formulation to replace 	  Q(x). Any valid constraint
in the Rn1þ1 space of (x, 	) is called an optimality cut. It takes the form of a
constraint 	  f(x) that holds for every x 2 X, and 	  Q(x).
Ch. 4. Stochastic Integer Programming
237

Deﬁnition 13. A set of s optimality cuts {	  fl(x), l ¼ 1,. . . , s} is said to be
suﬃcient at x 2 X if
	 2 f	: 	  flðxÞ, l ¼ 1    sg ) 	  QðxÞ:
In the classical L-shaped algorithm where the second-stage only involves
continuous variables and  has a ﬁnite support, the linear programming
duality theory implies that a suﬃcient set of optimality cuts can be found for
all x 2 X.
We now show how optimality cuts could be generated through a cutting
plane solution of the second-stage program. For simplicity of presentation,
we assume complete recourse for the second-stage so that feasibility cuts
can be left aside. Take the case when the assumptions of Proposition 4 are
satisﬁed. We also assume Y  Zn2. For each outcome k 2 , the second-stage
problem is
ðk  TxÞ ¼ minfqTy: Wy  k  Tx, y 2 Zn2g
ð3:47Þ
Let F be the set of dual price functions. Although more general classes can be
considered, take F to be the class of functions F : Rm2 ! R that are
nondecreasing, subadditive and satisfy F(0) ¼ 0. The dual problem of (3.47) is
max
F fFðk  TxÞ: FðwjÞ ¼ qj, j ¼ 1, . . . , n2, F 2 Fg
ð3:48Þ
where wj is the jth column of W.
Proposition 14. Suppose
^Fk, k ¼ 1,. . . , K, are optimal dual price functions
obtained by solving (3.48) with x ¼ x for each k 2 . Then, an optimality cut at
x is given by
	 
X
K
k¼1
pk ^Fkðk  TxÞ
ð3:49Þ
Proof. For each k ¼ 1,. . . , K, let yk and ^Fk be optimal solutions of (3.47) and
(3.48), respectively, corresponding to x ¼ x. By integer duality, they satisfy
qTyk ¼ ^Fkðk  TxÞ. For each feasible F 2 F and each feasible y 2 Zn2, we
have Fðk  TxÞ  ^Fkðk  TxÞ ¼ qTyk  qTy. Now, for each x 2 X and
corresponding optimal dual price F
k, we have
QðxÞ ¼
X
K
k¼1
pkF
kðk  TxÞ 
X
K
k¼1
pk ^Fkðk  TxÞ,
238
F.V. Louveaux and R. Schultz

with
QðxÞ ¼
X
K
k¼1
pk ^Fkðk  TxÞ:
u
In a cutting plane procedure, the LP-relaxation of the integer program is
considered. Valid inequalities are successively generated and added to the
formulation, until the LP-relaxation optimal solution spontaneously meets the
integrality restrictions. The valid inequalities can be written as
X
n2
j¼1
FðlÞðwjÞyj  FðlÞðqÞ,
l ¼ 1, . . . , s,
ð3:50Þ
where F(l) 2 F, l ¼ 1,. . . , s. Let ðu1, . . . , um2, um2þ1, . . . , um2þsÞ be the dual
variables associated to the optimum of the ﬁnal LP-relaxation. We construct
the function F : Rm2 ! R as
FðtÞ :¼
X
m2
i¼1
uiti þ
X
s
i¼1
um2þiFðiÞt
ð3:51Þ
By construction, F 2 F and is an optimal solution to (3.48).
As an example, consider the case where valid inequalities are generated by
the Gomory’s fractional cutting plane algorithm.
Let h ¼ kTx in (3.47).
Let
yBi þ
X
j2NB
wijyj ¼ hi
for i ¼ 1, . . . , m2
ð3:52Þ
be the optimal basis for second-stage problem (3.47) associated with a
given k and given x. This optimal basis can be rewritten in such a way that
wij  0, j 2 NB, hi  0, i ¼ 1, . . . , m2. NB is the set of nonbasic variables, while
Bi is the variable basic in row i. Let y* be the corresponding optimal solution.
If y* does not meet the integrality requirements, there is at least one row i with
hi 62 Z1. Choosing such a row, the Chvatal–Gomory cut for row i is
yBi þ
X
j2NB
8wij9 yj  8hi9
Ch. 4. Stochastic Integer Programming
239

which, by eliminating yBi, can be rewritten as
X
j2NB
ðwij  8wij9Þyj  hi  8hi9
or
X
j2NB
fijyj  fi
ð3:53Þ
where fij ¼ wij  8wij9, fi ¼ hi  8hi9. By construction, 0  fij<1 and 0<fi<1.
As y*
i ¼ 0, i 2 NB at the optimal LP solution, this inequality cuts oﬀy*.
Now let  be the row in the basis inverse corresponding to the row which
generated the cut (3.53). Let g ¼ 89. Then, the Gomory cut (3.53) can be
rewritten in terms of the original variables as the Chvatal–Gomory inequality
X
n
j¼1
8gwj9 yj  8gh9,
namely
X
n
j¼1
8gwj9 yj  8gðk  TxÞ9:
ð3:54Þ
Thus, expressed in terms of the ﬁrst-stage variable, the optimality cuts involve
8g(kTx)9 terms, i.e., rounding-down of combinations of x. Each one of
these rounding down operations requires an additional constraint and an
additional integer variable in the ﬁrst-stage. The left-hand-side of (3.54) does
not depend on x, so that similar cuts could be generated for various
realizations of  2 . At the moment, it is not known how to use this property
eﬃciently. The approach remains impracticable as the number of auxiliary
variables and constraints will equal the total number of round down
operations needed to generate the cuts.
Decomposition by branch & bound
We now indicate how optimality cuts can be obtained through a branch &
bound solution procedure in the second-stage. Consider a given ﬁrst-stage
iterate point x and a given realization k of . Based on a full branching on
the second-stage problem (3.47) for x ¼ x, one obtains a partition of Rn2 into
R terminal nodes Y ¼ fy: a  y  bg,  ¼ 1, . . . , R. The optimal objective
value of the second-stage program over Y is
Qðx, kÞ ¼ minfqTy: Wy ¼ k  Tx, a  y  bg
240
F.V. Louveaux and R. Schultz

By linear programming duality, it is also
Qðx, kÞ ¼ ð
ÞTðk  TxÞ þ ð
ÞTa þ ð
ÞTb
where 
, 
 and 
 are the optimal dual variables associated with the original
constraints, lower and upper bounds on y 2 Y, respectively.
To simplify notations, we represent this expression as
Qðx, kÞ ¼ ð
kÞTx þ 
k
with ð
kÞT ¼ ð
ÞT  T and 
k ¼ ð
ÞTk þ ð
ÞTa þ ð
ÞTb.
Duality theory also implies that Qðx, kÞ  ð
kÞTx þ 
k.
Also, by construction of the branch & bound,
Qðx, kÞ ¼
min
¼1,...,R Qðx, kÞ:
Thus,
	k  pk
min
¼1,...,Rfð
kÞTx þ 
kg
ð3:55Þ
is a valid optimality cut for Q(x, k). It can thus be embedded in a multicut
representation 	 ¼ P
k¼1,...,K 	k. When SIP has not complete recourse, some of
the terminal nodes may be infeasible, in which case their dual solutions
contain unbounded rays with dual objective values going to 1, so that the
minimum is restricted to the feasible terminal nodes.
The optimality cut (3.55) is a suﬃcient set of optimality cuts at x for 	k.
Unfortunately, as it is well known, (3.55) is a nonlinear expression. R auxiliary
binary variables and R þ 1 constraints are required to describe (3.55) in a
polyhedral representation with mixed integer variables. This, plus solving a
full branch & bound for each x and each k, makes a decomposition by branch
& bound of little practical value.
Scenario decomposition
In a general setting, scenario decomposition can be understood as a
solution method for the multi-stage stochastic integer program (2.31) where,
out of the constraints (2.27), (2.28), (2.29), the nonanticipativity condition
(2.29) is subjected to Lagrangian relaxation. We will demonstrate scenario
decomposition at the following two-stage model:
minfcTx þ E½ð  TxÞ: x 2 Xg
ð3:56Þ
Ch. 4. Stochastic Integer Programming
241

with
ðtÞ :¼ minfqTy: Wy ¼ t, y 2 Yg
where X  Rn1, Y  Rn2 are polyhedra, possibly involving integer require-
ments to components of x and y. We assume that all problem data have
conformable dimensions, that W is rational, and that  follows a discrete
distribution with realizations (or scenarios) 1,. . . , N and probabilities

1,. . . , 
N. Then problem (3.56) can be written as the following mixed-integer
linear program
min
x,yj
cTx þ
X
N
j¼1

jqTyj : Tx þ Wyj ¼ j, yj 2 Y, x 2 X
(
)
:
ð3:57Þ
Due to the sheer size, general purpose mixed-integer linear programming
solvers quickly fail at these problems. We reformulate (3.57) by introducing
copies xj, j ¼ 1,. . . , N, and adding the explicit nonanticipativity constraints
x1 ¼    ¼ xN, or an equivalent system. For notational convenience, the latter
is written as PN
j¼1 Hjxj ¼ 0 with proper (l, n1)-matrices Hj, j ¼ 1,. . . , N.
Problem (3.57) then becomes
min
X
N
j¼1

jðcTxj þ qTyjÞ: Txj þ Wyj ¼ j, xj 2X, yj 2Y,
X
N
j¼1
Hjxj ¼0
(
)
:
ð3:58Þ
For  2 Rl we consider the functions
Ljðxj, yj, Þ :¼ 
jðcTxj þ qTyjÞ þ 
jTHjxj,
j ¼ 1, . . . , N,
ð3:59Þ
and form the Lagrangian
Lðx, y, Þ :¼
X
N
j¼1
Ljðxj, yj, Þ:
Later on, the Lagrangian will have to be minimized over a mixed-integer
polyhedral set, which will be accomplished by mixed-integer linear program-
ming solvers. To avoid nonlinearities, our Lagrangian is very much standard
in that it is based on linear expressions and does not involve nonlinear
augmentation terms.
242
F.V. Louveaux and R. Schultz

Given that the objective in (3.58) is an expectation, it is natural to base the
Lagrangian at a probabilistic inner product which, in (3.59), leads to the
factors 
j in front of the terms THjxj. Conceptually, this follows the lines
of dualization as developed in Rockafellar and Wets (1978). Furthermore,
ill-conditioning in the Lagrangian dual when disregarding the probabilities in
the second term of (3.59) is avoided this way, see Bacaud et al. (2001) and
Gro¨ we-Kuska et al. (2002) for respective observations.
The Lagrangian dual of (3.58) is the optimization problem
maxfDðÞ:  2 Rlg
ð3:60Þ
where
DðÞ¼min
X
N
j¼1
Ljðxj, yj, Þ: Txj þ Wyj ¼ j, xj 2 X, yj 2 Y
(
)
:
ð3:61Þ
The above minimization is separable, and we have
DðÞ ¼
X
N
j¼1
DjðÞ
ð3:62Þ
where
DjðÞ ¼ minfLjðxj, yj, Þ: Txj þ Wyj ¼ j, xj 2 X, yj 2 Yg:
ð3:63Þ
Dj () is the pointwise minimum of aﬃne functions in , and hence piecewise
aﬃne and concave. Therefore, (3.60) is a nonsmooth concave maximization
(or convex minimization) problem that can be solved by bundle methods from
nondiﬀerentiable optimization, see Hiriart-Urruty and Lemare´ chal (1993) and
Kiwiel (1990). At each iteration, these methods require the objective value and
one subgradient of D. These are obtained by solving the optimization problem
in (3.61) which, thanks to the separability in (3.62), reduces to solving N
problems of single-scenario size. The latter are mixed-integer linear programs
and very often within the reach of advanced general purpose solvers.
Altogether, the optimal value ’LD of (3.60) provides a lower bound to the
optimal value ’ of problem (3.57). Specifying a well-known result in
Lagrangian relaxation of mixed-integer linear programs, see e.g., Nemhauser
and Wolsey (1988), leads to the following proposition.
Proposition 15. It holds ’  ’LD. If for some multiplier  2 Rl the optimal
solutions (xj, yj), j ¼ 1,. . . , N, to the optimization problem in (3.61) fulﬁl
PN
j¼1 Hjxj ¼ 0, then ’ ¼ ’LD and (xj, yj), j ¼ 1,. . . , N, are optimal for (3.58).
Ch. 4. Stochastic Integer Programming
243

With ’LP denoting the optimal value of the linear programming relaxation to
(3.58) it holds ’LD  ’LP.
Equality of ’ and ’LD in Proposition 15 being a rare exception,
‘‘promising’’ feasible points for the original primal problem (3.58) are derived
by heuristics using the results of the dual optimization. Since, in our situation,
the relaxed constraints (x1 ¼    ¼ xN) are particularly simple, ideas for such
heuristics arise quite naturally. For example, examine the xj-components,
j ¼ 1,. . . , N, of solutions to (3.63) for optimal or nearly optimal , and decide
for the most frequent value arising or average and round if necessary. If the
heuristic provides a feasible solution to (3.58), then the objective value of the
latter yields an upper bound ’ for ’.
The diﬀerence ’  ’LD then indicates the quality of the feasible solution
found. If desired, this quality certiﬁcate can be improved by embedding the
procedure described so far into a branch & bound scheme for (3.56) seen as a
nonconvex global optimization problem. Recall from (2.11) the notation
ðxÞ :¼ E½ð  TxÞ. Let P denote the list of current problems and
’LD ¼ ’LD(P) the Lagrangian lower bound for P 2 P. The scheme then
consists of the following steps.
Scenario decomposition algorithm
Step 1 Initialization: Set ’ ¼ þ1 and let P consist of problem (3.58).
Step 2 Termination: If P ¼ ; then the solution ^x that yielded ’ ¼ cT ^x þ ð ^xÞ is
optimal.
Step 3 Node selection: Select and delete a problem P from P and solve its
Lagrangian dual. If the optimal value ’LD(P) hereof equals þ 1 (infeasi-
bility of a subproblem) then go to step 2.
Step 4 Bounding: If ’LDðPÞ  ’ go to step 2 (this step can be carried out as
soon as the value of the Lagrangian dual rises above ’).
(i) The scenario solutions xj, j ¼ 1,. . . , N, are identical: if cTxj þ ðxjÞ < ’
then let ’ ¼ cTxj þ ðxjÞ and delete from P all problems P0 with
’LDðP0Þ  ’. Go to step 2.
(ii) The scenario solutions xj, j ¼ 1,. . . , N diﬀer: compute the average
x ¼ PN
j¼1 
jxj and round it by some heuristic to obtain xR. If cTxRþ
ðxRÞ < ’ then let ’ ¼ cTxR þ ðxRÞ and delete from P all problems
P0 with ’LDðP0Þ  ’. Go to step 5.
Step 5 Branching: Select a component x(k) of x and add two new problems
to P obtained from P by adding the constraints xðkÞ  8xðkÞ9 and xðkÞ 
8xðkÞ9 þ 1, respectively (if x(k) is an integer component), or xðkÞ  xðkÞ  "
and xðkÞ  xðkÞ þ ", respectively, where ">0 is a tolerance parameter to
have disjoint subdomains.
This scheme is obviously ﬁnite if X is bounded and all x-components have
to be integers. If x is mixed-integer some stopping criterion to avoid endless
branching on the continuous components has to be employed.
244
F.V. Louveaux and R. Schultz

As neither of the classical approaches for IP can provide a comprehensible
decomposition for SIP, research has been devoted to a number of cases which
receive a nice treatment. Subsequently, some of these cases will be addressed.
3.2
Simple integer recourse
A two-stage stochastic program with simple integer recourse was deﬁned in
Section 2.2 as
min
x fcTx þ E½ð  TxÞ: x 2 Xg
where
ðtÞ ¼ minfðqþÞTyþ þ ðqÞTy : yþ  t, y  t, yþ 2 Zs
þ, y 2 Zs
þg:
We again use the notation
uiðiÞ :¼ Ei di  ieþ


and
viðiÞ :¼ Ei 8i  i9þ


to represent the expected surplus and the expected shortage, respectively.
Letting
iðiÞ ¼ qþ
i uiðiÞ þ q
i viðiÞ
ð3:64Þ
the two-stage stochastic program with simple integer recourse can be trans-
formed into
min
x
cTx þ
X
s
i¼1
iðiÞ:  ¼ Tx, x 2 X
(
)
:
ð3:65Þ
To make the presentation simpler, we now consider the case with expected
shortage only. It is deﬁned as
min
x
cTx þ
X
s
i¼1
qþ
i uiðiÞ:  ¼ Tx, x 2 X
(
)
:
ð3:66Þ
Note that all results available for the expected shortage easily translate to the
expected surplus, and therefore also to the functions i (i), i ¼ 1,. . . , s. For
notational convenience, we will drop the index i whenever it is not required.
Ch. 4. Stochastic Integer Programming
245

Proposition 16. u( þ 1)u() is a nondecreasing function of .
Proof. From Proposition 8, we have
uðÞ ¼
X
1
k¼0
ð1  Fð þ kÞÞ:
It follows that, for all n 2 Z þ, we have
uð þ nÞ ¼ uðÞ 
X
n1
k¼0
ð1  Fð þ kÞÞ:
ð3:67Þ
Taking n ¼ 1, we get
uð þ 1Þ  uðÞ ¼ FðÞ  1:
The proposition holds as F(  ) is a cumulative distribution function.
u
If we consider  values which are integer apart, we may draw a piecewise
linear function through successive points ( 
 k, u( 
 k)), k integer. This
piecewise linear function is convex by Proposition 16. It may sometimes be the
convex hull of u(). A suﬃcient condition for that is that the support of 
is a subset of Z. But in general, it is not. Take the simple example where
 ¼ 1/2 or 3/2 with probability 1/2 each, and observe that uð1=4Þ ¼ 3=2 >
1
2 ðuð0Þ þ uð1=2ÞÞ, as u(0) ¼ 3/2 and u(1/2) ¼ 1/2. In any case, as this piecewise
linear function is convex, we can derive valid inequalities in the (, u()) space
which are supporting half-lines of this function.
Proposition 17. Let  2 Z. Deﬁne 
 ¼ u()u( þ 1) and e ¼ ( þ 1)u()
u( þ 1). Then, for all  2 Z,
uðÞ  e  
:
ð3:68Þ
Moreover
uðÞ ¼ e  
  :
ð3:69Þ
Proof. Consider the case where   . Then
uðÞ  uðÞ ¼
X
1
k¼0
½uð  kÞ  uð  k  1Þ:
246
F.V. Louveaux and R. Schultz

By Proposition 16, each term in the sum is bounded below by u( þ 1)u().
Hence u()u()  ()(u( þ 1)u()).
The inequality (3.68) follows. The case where    is similar. Finally, (3.69)
is obtained by straightforward computation of e
.
u
We now propose an exact algorithm for the case where  is integer.
Algorithm SPSIR
Step 1 Initialization:  :¼ 0, ri :¼ 0, i ¼ 1,. . . , s.
Step 2 Current problem: Let  :¼  þ 1. Solve the program
min
x
cTxþ
X
s
i¼1
qþ
i 	i : ¼Tx, x 2 X, 
lðiÞi þ 	i  elðiÞ, lðiÞ ¼ 1, . . . , ri
(
)
:
ð3:70Þ
Let ðx, 	
1, . . . , 	
sÞ be an optimal solution to (3.70). If ri ¼ 0 for some i, 	
i is
set to 1 and is not considered in the computation of x.
Step 3 Termination: Let  ¼ Tx. If 	
i ¼ uið
i Þ for i ¼ 1,. . . , s, then x is an
optimal solution. Stop.
Step 4 Cut generation: For any i, i ¼ 1,. . . , s, such that 	
i < uið
i Þ, compute

riþ1 ¼ uið
i Þ  uið
i þ 1Þ
and
eriþ1 ¼ ð
i þ 1Þuið
i Þ  
i uið
i þ 1Þ:
Set ri :¼ ri þ 1. Go to step 2.
Proposition 18. Assume X is bounded. Also assume  2 Zs for all x 2 X. Then,
the SPSIR algorithm ﬁnds an optimal solution to (3.66) in a ﬁnite number of
steps, provided ui(i) can be obtained through a ﬁnite computation, i ¼ 1,. . . , s.
Proof. X being bounded, there are only ﬁnitely many diﬀerent values of i,
i ¼ 1,. . . , s. For each i, only one cut can be generated. Thus, ri is ﬁnite. By
(3.69), the same cut can only be generated once in step 4.
u
Example 19. Newsboy Problem Revisited. Assume now that the newsboy can
purchase a number of publications (newspaper, magazines, . . . ). Each
publication i, i ¼ 1,. . . , s, has a purchase cost ci, a selling cost si and a demand
which is a random variable i with cumulative distribution function Fi. For
simplicity, we assume unsold publications cannot be returned to the vendor.
Ch. 4. Stochastic Integer Programming
247

Each publication has a weight (or volume) ai. A total weight (or volume) b is
available to the newsboy.
The problem is naturally an integer program as publications sell by the
unit. It reads as follows
min
X
s
i¼1
cixi þ E 
X
s
i¼1
siyiðiÞ
"
#
:
X
s
i¼1
aixi  b,
(
0  yiðiÞ  i, yiðiÞ  xi, x 2 Zs
þ, yðÞ 2 Zs
þ
)
:
Letting yþ
i ðiÞ ¼ i  yiðiÞ, one obtains an equivalent formulation
min
X
s
i¼1
cixi þ E
X
s
i¼1
siyþ
i ðiÞ
"
#
 E
X
s
i¼1
i
"
#
:
(
X
s
i¼1
aixi  b, yþ
i ðiÞ  i  xi, x 2 Zs
þ, yþðÞ 2 Zs
þ
)
:
Omitting the constant term and using the notation ui(xi) previously deﬁned for
the expected surplus, the newsboy problem becomes
min
X
s
i¼1
cixi þ
X
s
i¼1
siuiðxiÞ:
X
s
i¼1
aixi  b, x 2 Zs
þ
(
)
:
This problem obviously satisﬁes the assumptions in Proposition 18: X is
bounded through the upper limit on the total weight and  ¼ x is integer by
deﬁnition.
It now remains to study a number of cases where the computation of u() is
ﬁnite.
(i)  has a ﬁnite range.
This case includes random variables with ﬁnite support, but also
continuous random variables on a ﬁnite range. For instance, if  has a
uniform density on [0, a], then for 0  x  a,
uðxÞ ¼
X
daxe1
k¼0
½1  Fðx þ kÞ:
(ii) Closed form expressions can be found.
248
F.V. Louveaux and R. Schultz

Let  have a negative exponential density with parameter >0. Then, for
x  0,
uðxÞ ¼
X
1
k¼0
ð1  Fðx þ kÞÞ ¼
X
1
k¼0
eðxþkÞ
¼
ex
1  e
(iii) The support of  is a subset of Z.
By (3.67), we have
uð þ nÞ ¼ uðÞ 
X
n1
k¼0
ð1  Fð þ kÞÞ:
Observe that FðtÞ ¼ F 8t9
ð
Þ for all t 2 R, as the support of  2 Z. Thus,
uðtÞ ¼ u 8t9
ð
Þ for all t 2 R. Consider x  0. Apply (3.67) with  ¼ 0 and
n ¼ 8x9. It follows that
uðxÞ ¼ uð0Þ  n þ
X
n1
k¼0
FðkÞ:
Now, as the support of  is a subset of Z, uð0Þ ¼ E½deþ ¼ E½þ ¼
E½maxð, 0Þ. In particular, for such distributions with   0, u(0) ¼ E[]. Such
is the case for a Poisson distribution, for instance.
Example 20. Newsboy Problem Continued. Take the newsboy problem with
s ¼ 2, cT ¼ (1, 2), s1 ¼ 3, s2 ¼ 7, aT ¼ (2, 3), b ¼ 12. Assume the demand for both
publications follows a Poisson distribution with parameter 3. Assume a
starting point of xT ¼ (0, 0). The initial cuts are found as follows.
By
deﬁnition,
u(0) ¼ 3.
Compute
u(1) ¼ u(0) þ F(0)1 ¼ 2.0498.
Then

1 ¼ 0.9502 and e1 ¼ 3.
The next iterate will be xT ¼ (0, 4), with one extra cut generated, then
xT ¼ (3, 2) with two new cuts, then xT ¼ (3, 2) again, which is optimal. Observe
that the mean value optimum is xT ¼ (1, 3).
Note, ﬁnally, that even for such continuous densities as the normal
distribution, it is possible to compute u(x) within a ﬁxed tolerance in a ﬁnite
number of steps (see Theorem 3.30 in Birge and Louveaux, 1997). This
tolerance can be chosen equal to the machine tolerance so that the
computation can be considered exact.
Ch. 4. Stochastic Integer Programming
249

3.3
Binary first-stage variables
When the ﬁrst-stage variables are binary, it is possible to obtain a suﬃcient
set of optimality cuts at each x 2 X \ f0, 1gn1. A ﬁnite algorithm, called the
integer L-shaped, has been designed. It can be made eﬃcient for hard
problems when lower bounding functionals are available.
Assumption 21. There exists a ﬁnite lower bound L satisfying
L  min
x fQðxÞ: x 2 Xg:
Assumption 22. For x 2 X, Q(x) is computable in a ﬁnite number of steps.
At a given stage of the algorithm, we consider the current problem (CP)
ðCPÞ
min
x,	 fcTx þ 	: x 2 P \ N, 	  L, 	  flðxÞ, l ¼ 1, . . . , sg
where P is a formulation of X, N is node  of the ﬁrst-stage branching
scheme, Rn1 ¼ [¼1,...,R N. L is a ﬁnite lower bound as in Assumption 21 and
	  f(x), l ¼ 1,. . . , s, are the optimality cuts. We now present a general scheme.
Integer L-shaped algorithm
Step 1 Initialization: Let s ¼ 0,  ¼ 0,  ¼ 1, z ¼ 1, 	 :¼ L. A list is created that
contains one single node corresponding to the initial problem, i.e.,
N1 :¼ Rn1.
Step 2 Selection: Select one node  in the list, if none exists, stop.
Step 3 Solution: Set  :¼  þ 1. Solve (CP). If it is infeasible, fathom node N
and go to step 2. Otherwise, let (x, 	) be an optimal solution. If
cTx þ 	  z, fathom node N and go to step 2.
Step 4 Branch & cut: Check for integrality restrictions. If some restriction is
violated, apply a separation algorithm to ﬁnd a valid inequality. If some is
found, adapt P, then return to step 3. If not, create two new nodes
following the usual branching. Append the nodes to the list, fathom node
N and go to step 2.
Step 5 Second-stage value. Compute Q(x) and z ¼ cTx þ Q(x). If z < z,
update z :¼ z.
Step 6 Optimality cuts: If 	  Q(x), fathom node N and go to step 2.
Otherwise, ﬁnd some optimality cut, set s :¼ s þ 1 and go to step 3.
The integer L-shaped method yields an optimal solution (when one exists)
in a ﬁnite number of steps when a suﬃcient set of optimality cuts exists for
each x 2 X. As X  f0, 1gn1, step 6 can only be performed a ﬁnite number
250
F.V. Louveaux and R. Schultz

of times. All other steps of the method are ﬁnite, as the branch & cut
procedure is ﬁnite.
When needed, the integer L-shaped can be used in a multicut version. Then,
	
is
replaced
by
P
k¼1,...,K 	k,
and
the
restriction
	  Q(x)
becomes
	k  Q(x, k), k ¼ 1,. . . , K. In this case, step 6 becomes
Step 6 Optimality cuts in the multicut version: If (	k)  Q(x, k), for all
k ¼ 1,. . . , K, fathom node N and go to step 2. Otherwise, for each k such
that (	k)<Q(x, k), ﬁnd some optimality cut, adapt sk and go to step 3.
Based on the fact that the ﬁrst-stage variables are binary, we easily obtain a
suﬃcient set of optimality cuts.
Proposition 23. Let xi ¼ 1, i 2 S, and xi ¼ 0, i 62 S, be some ﬁrst-stage feasible
solution. Let qS ¼ Q(x) be the corresponding recourse function value. Deﬁne the
optimality cut as
	  ðqS  LÞ
X
i2S
xi 
X
i62S
xi
 
!
 ðqS  LÞðjSj  1Þ þ L:
ð3:71Þ
Then, the optimality cut (3.71) is suﬃcient at x.
Proof. Let ðx, SÞ ¼ P
i2S xi  P
i62S xi. We have (S)  jSj. (S) ¼ jSj only if
xi ¼ 1, i 2 S, and xi ¼ 0, i 62 S. In that case, the right-hand side of (3.71) takes
the value qS and 	  qS is valid as qS is precisely Q(x). In all other cases,
(S)  jSj1. Then the right hand side of (3.71) takes a value smaller than or
equal to L and 	  L is valid by Assumption 21. This single cut is suﬃcient at x
since Q(x) ¼ qS.
u
An alternative is to consider the integer L-shaped as a particular case of the
cutting plane decomposition of Section 3.1.1, with
FðtÞ ¼
ðtÞ
for t    Tx,
L
otherwise:
(
To avoid sending too many optimality cuts, it is helpful to add a number of
lower bounding functionals on Q(x). One general possibility is to add cuts
from the continuous L-shaped. Let
ðx, Þ ¼ minfqTy: Wy ¼   Tx, y 2 Rn2
þ g
Ch. 4. Stochastic Integer Programming
251

and ðxÞ ¼ E½ðx, Þ. Then,
	  ðxÞ þ @ðxÞTðx  xÞ
ð3:72Þ
is a valid lower bounding functional. We now present two diﬀerent situations
where the optimality cuts can be improved and the integer L-shaped becomes
more eﬃcient.
s-Neighbors
When more information is available on Q(x), improvements on (3.71) can
be obtained. Let
Nðs, SÞ ¼ fx: ðx, SÞ ¼ jSj  s, x 2 Xg
be the s-neighbors of S. Assume we can ﬁnd
ðs, SÞ  minfQðxÞ: x 2 Nðs, SÞg, s ¼ 0, . . . , jSj,
or at least a series of (s, S), s  t. Observe that (0, S) ¼ qS.
Proposition 24. Let xi ¼ 1, i 2 S, xi ¼ 0, i 62 S, be a feasible solution to SIP, with
qS ¼ Q(x). Deﬁne a ¼ maxfqS  ð1, SÞ, ðqS  LÞ=2g. Then
	  aðx, SÞ þ qS  ajSj
ð3:73Þ
is a suﬃcient optimality cut at x.
Proof. For x 2 N(s, S), the right-hand side of (3.73) is equal to qSas. We
show that this value is a valid lower bound on Q(x). This is obvious for s ¼ 0.
When s ¼ 1, the r.h.s. is qSa. By deﬁnition of a, qSa is bounded above by
qS  ðqS  ð1, SÞÞ ¼ ð1, SÞ, which is by deﬁnition a lower bound on one
neighbors of S. When s ¼ 2, q  2a  qS  2ðqS  LÞ=2 ¼ L. Finally, for s  3,
qS  as  qS  2a  L. (3.73) is suﬃcient at x as 	  qS for s ¼ 0.
u
Geometrically, (3.73) deﬁnes a half-space in the (, 	) space, above a line
passing
through
the
two
points
(jSj, qS)
and
(jSj1, (1, S))
when
a ¼ qS(1, S), or the two points (jSj, qS) and (jSj2, L) where a ¼ (qSL)/2.
Proposition 25. Let xi ¼ 1, i 2 S, xi ¼ 0, i 62 S, be a feasible solution, with
qS ¼ Q(x). Let 1  t  jSj be some integer. Then (3.73) holds with
a ¼ maxfmax
st ðqS  ðs, SÞ=s; ðqS  LÞ=ðt þ 1Þg:
ð3:74Þ
252
F.V. Louveaux and R. Schultz

Proof. If x 2 N(s, S), the right-hand-side of (3.73) is qSas. By (3.74), for all
s  t, qS  as  qS  ðqS  ðs, SÞÞ ¼ ðs, SÞ which is a lower bound on Q(x)
by deﬁnition. For s>t, qS  as  qS  aðt þ 1Þ  qS  ðqS  LÞ ¼ L which is
also valid.
u
Proposition 26. Assume qS>(1, S). If (s1, S)(s, S) is nonincreasing in s
for 1  s  8ðqS  LÞ=ðqS  ð1, SÞÞ9, then (3.73) holds with a ¼ qS(1, S).
Proof. It suﬃces to show that in (3.74), the maximum in the right-hand side is
obtained when s ¼ 1. Let t ¼ 8ðqS  LÞ=qS  ð1, SÞ9. For s  t, we have
qS  ðs, SÞ ¼ Ps
i¼1 ðði  1, SÞ  ði, SÞÞ. By assumption, each term of the
sum is smaller than the ﬁrst term of the sum, so the total is less than s times
qS(1, S). By deﬁnition of t, we have t þ 1  ðqS  LÞ=ðqS  ð1, SÞÞ or
qS  ð1, SÞ  ðqS  LÞ=ðt þ 1Þ.
u
Example 27. Let QðxÞ ¼ Pm2
j¼1 QjðxÞ with
Qjðx, Þ ¼ min rjyj : djyj  dj 
X
i2Tð jÞ
ijxi, yj 2 f0, 1g
(
)
and
QjðxÞ ¼ E½Qjðx, Þ:
Assume xi 2 {0, 1}, i 2 T, with T ¼ [j¼1,..., m2Tð jÞ and Tð jÞ \ TðkÞ ¼ , j 6¼ k.
This can be seen as a number of investments xi, i 2 T, which are made in a ﬁrst
stage. They have a random yield ij in product j. Any deﬁciency in attaining
the target dj for product j results in a penalty rj. The second-stage value is then
simply
QðxÞ ¼
X
m2
j¼1
rjP
X
i2Sð jÞ
ij < dj
 
!
ð3:75Þ
where
SðjÞ ¼ fi 2 Tð jÞ: xi ¼ 1g,
j ¼ 1, . . . , m2, at the current solution x:
To apply Proposition 26, take S ¼ [j¼1,..., m2Sð jÞ. By deﬁnition, qS ¼ Q(x) and
is easily computed from (3.75) when the sum of the random variables ij,
i 2 S( j), has a known distribution, j ¼ 1,. . . , m2. Such is case for standard
distributions as the Poisson or normal distribution. There are two ways
1-neighbors can be obtained. First, for one j, 1  j  m2, one xi, i 2 S( j), goes
Ch. 4. Stochastic Integer Programming
253

from one to zero (and all other xi’s are unchanged). In that case, Q(x) is
increased and any value smaller than or equal to qS is a valid lower bound.
Second, we may have one single xi, i 62 S, going from zero to one, and again all
other xi’s unchanged. As the T( j), j ¼ 1,. . . , m2, form a partition, one single
term is modiﬁed in (3.75). We easily obtain a lower bound by simply assuming
this term vanishes. Thus
qS  ð1, SÞ 
max
j¼1,...,m2 rj P
X
i2Sð jÞ
ij < dj
 
!
(
)
Without
loss
of
generality,
order
the
j’s
in
decreasing
order
of
rj PðP
i2Sð jÞ ij < djÞ. Repeating the argument above, we get
qS  ðs, SÞ 
X
s
j¼1
rj P
X
i2Sð jÞ
ij < dj
 
!
and Proposition 26 applies.
Vehicle routing problems
The integer L-shaped method can be used to solve hard problems for
speciﬁc applications. We now illustrate this on an example of a routing
problem. The capacitated vehicle routing problem, is deﬁned on an undirected
graph G ¼ (V, E) where V ¼ {v1,. . . , vn} is a vertex set and E ¼ fðvi, vjÞ:
vi, vj 2 V, i < jg is an edge set. Vertex v1 is a depot at which are based m
identical vehicles of capacity D, while the remaining vertices are customers. A
symmetric travel cost matrix C ¼ (cij) is deﬁned on E. With each customer vi is
associated a nonnegative demand to be collected or delivered, but not both.
Without loss of generality, we consider the ﬁrst case here. In the classical
VRP, each vi has a known demand di. The problem then consists of designing
m vehicle routes: (i) each starting and ending at the depot, (ii) such that every
customer is visited only once by one vehicle, (iii) the total demand of any route
does not exceed D, and (iv) the total routing cost is minimized. The VRP is
known to be NP-hard.
In the stochastic case, each customer vi has a stochastic demand i. The
consequence of having stochastic demands is that a planned vehicle route may
fail at a given customer location whenever the accumulated demand exceeds
D. In such a case, a failure is said to occur and a recourse action must be
implemented. The stochastic VRP can easily be represented as
minfcx þ QðxÞ: x 2 Xg
254
F.V. Louveaux and R. Schultz

where X deﬁnes the usual restrictions on the routes (degree constraints at the
nodes, no subtour, and expected demand of any route does not exceed the
vehicle capacity). x ¼ (xij) is deﬁned as the arc variables, with xij ¼ 1 if (vi, vj)
belongs to a route and xij ¼ 0 otherwise, and Q(x) is the expected cost of
recourse actions in case of failure. This expected cost is separable in the routes
and must be computed for each of its two orientations
QðxÞ ¼
X
m
k¼1
minfQk,1, Qk,2g
where Qk, denotes the expected cost of recourse corresponding to route k
and orientation  ¼ 1 or 2. For a given route k deﬁned by Vk ¼ ðvi1 ¼
v1, vi2, . . . , vitþ1 ¼ v1Þ, one orientation corresponds to following the route with
customers visited in the natural order. The other orientation corresponds to
visiting them in backward order. Observe that orientation does matter in a
stochastic setting, while it does not in a deterministic one. Assume the recourse
action simply consists of the following steps: return to the depot, unload the
vehicle then resume the route at the customer where failure occurs. This
recourse action is called a return trip to the depot. Then, the expected recourse
cost for the ﬁrst orientation is
Qk,1 ¼ 2
X
t
j¼2
X
1
l¼1
P
X
j1
s¼2
is  lD 
X
j
s¼2
is
 
!
c1ij:
ð3:76Þ
It can be rewritten as
Qk,1 ¼ 2
X
t
j¼2
X
1
l¼1
½Fj1ðlDÞ  FjðlDÞc1ij
ð3:77Þ
where FjðlDÞ ¼ PðPj
s¼2 is  lDÞ. If i  D a.s. for all i, then the upper limit
in the second summation in (3.76) and (3.77) can be brought down to j1.
(i) Lower bounding functionals on Q(x) can be obtained at fractional ﬁrst-
stage solutions. They are based on the concept of ‘‘partial routes’’. A
partial route h is speciﬁed by two ordered vertex sets Sh ¼ fv1, . . . , vshg
and Th ¼ fv1, . . . , vthg satisfying Sh \ Th ¼ {v1}, and a third set Uh
satisfying Sh \ Uh ¼ {vsh} and Th \ Uh ¼ {vth}.
For simplicity, we write (vi, vj) 2 Sh or Th if vi and vj are consecutive
in Sh or Th. The partial route h induced by these sets is made up of the
two chains ðv1, . . . , vshÞ, ðv1, . . . , vthÞ and of the unstructured set Uh. Let
Rh ¼ Sh [ Th [ Uh. Deﬁne
WhðxÞ ¼
X
ðvi,vjÞ2Rh
xij  jRhj þ 1:
Ch. 4. Stochastic Integer Programming
255

Let P be a lower bound on any solution containing the partial routes
and, as usual, L a lower bound on Q(x).
Proposition 28. The constraint
	  L þ ðP  LÞ
X
r
h¼1
WhðxÞ  r þ 1
 
!
ð3:78Þ
is a valid inequality for SVRP.
Proof. By construction Wh(x)  1. Hence, Pr
h¼1 WhðxÞ  r þ 1  1. It is only
1 when Wh(x) ¼ 1 for all h. In this case, (3.78) becomes 	  P. Otherwise (3.78)
is redundant.
u
A greedy heuristic to ﬁnd out partial routes proves to be an eﬃcient
separation algorithm to detect violated inequalities (3.78). We construct
P ¼ Prþ1
h¼1 Ph as follows. For h  r, we create an artiﬁcial customer va with
demand a ¼ P
vi2Uhnfvsh, vthg i and c1a ¼ minvi2Uhnfvsh, vthg fc1ig. Then construct
route k equal to fv1, . . . , vsh, va, vth, . . . , v1g and compute Ph ¼ minfQk,1, Qk,2g
as before for this artiﬁcial route. Pr þ 1 is a lower bound on the expected
recourse restricted to the customer set VnUr
h¼1 Rh and mr vehicles. It is
similar to the computation of L for Q(x), that is now described in the next
paragraph.
(ii) Lower bound on Q(x). Relabel all customers in nondecreasing order of
their distance to the depot. Denote by Xk the random demand on route
k, k ¼ 1,. . . , m, and let Fk(  ) be its distribution function. Let XT be the
total random demand and FT(  ) its distribution function.
Proposition 29. Let 
(Fk, D) be a lower bound on the probability of having at
least one failure on a route whose demand is deﬁned by Fk. A valid lower bound
on Q(x) is given by
L ¼
inf
ðF1,...,FmÞ
(
2
X
m
k¼1
c1,kþ1
ðFk, DÞ :
Z
  
Z
x1þ  þxmx
dF1ðx1Þ    dFmðxmÞ ¼ FTðxÞ
for all x,
Fk 2 Fk, k ¼ 1, . . . , m
)
ð3:79Þ
where Fk is a family of distribution functions to be speciﬁed. In particular, it
must be such that E[Xk]  D.
256
F.V. Louveaux and R. Schultz

Proof. From (3.77), the expected cost Qk, of route k with orientation 
is obtained by computing the cost of having the lth failure at the jth
customer, then summing up over all l and j. Each of these terms contribute
to Qk, by a nonnegative amount. A valid lower bound is obtained by only
considering the ﬁrst failure, l ¼ 1. By deﬁnition of 
(Fk, D), we obtain
QðxÞ  2 Pm
k¼1 k  
ðFk, DÞ for any lower bound k on the distance of a
customer in route k to the depot. We may then replace 1,. . . , m by the m
least distances to the depot, to obtain the objective function in (3.79).
u
Apply this proposition to the case where Fk is the set of normal
distributions. Let xk ¼ E[Xk] and yk ¼ Var[Xk]. Let also T ¼ E[XT] and
2
T ¼ Var½XT. Let x ¼ (x1,. . . , xm), y ¼ (y1,. . . , ym).
Then (3.79) reduces to
L ¼ min
x,y
2
X
m
k¼1
c1,kþ1 1  G D  xk
ﬃﬃﬃﬃﬃ
yk
p
	



:
X
m
k¼1
xk ¼ T,
(
X
m
k¼1
yk ¼ 2
T, y  0, x  0
)
:
ð3:80Þ
where GðtÞ ¼ PðZ  tÞ, Z  Nð0, 1Þ.
As the objective function is neither convex nor concave, we obtain a
more workable problem by replacing yk by some lower bound y0. We know
that for each route xk  x0 :¼ maxfT  ðm  1ÞD; mini¼2,..., n E½ig. Then,
y0 ¼ minZfPn
i¼2 Var½izi : Pn
i¼2 E½izi  x0, zi 2 f0, 1gg is a lower bound on
yk. We may thus replace (3.80) by
L ¼ min
x
2
X
m
k¼1
c1,kþ1 1  G D  xk
ﬃﬃﬃﬃﬃ
y0
p
	



:
X
m
k¼1
xk ¼ T, x  0
(
)
:
ð3:81Þ
The objective function in (3.81) is convex in xk for xk  D, so that (3.81) can
be solved by applying the Karush–Kuhn–Tucker conditions. Let  be the
multiplier on Pm
k¼1 xk ¼ T. Deﬁne b ¼ 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

y0=2
p
. Then
xk ¼
D
if c1,kþ1  b
D 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2y0 lnðc1,kþ1=bÞ
p
if c1,kþ1  b:
(
As xk, k ¼ 1,. . . , m, is a nondecreasing function of b, they can be determined
recursively up to the moment where Pm
k¼1 xk ¼ T within some tolerance.
Similar results apply for other cases, such as the Poisson distribution.
Ch. 4. Stochastic Integer Programming
257

The combination of lower bounding functionals on partial routes and the
calculation of a lower bound L based on (3.81) for the normal case prove to be
very eﬃcient.
3.4
Second-stage integer variables
We now consider the case where Y  Zn2
þ . Assume again T and W are ﬁxed.
Suppose also that the second-stage program for a given  can be represented
as
ð, ð!ÞÞ ¼ minfqTy: Wy    , y 2 Yg
where Y  Zn2
þ . Assume also that  has a ﬁnite support.
Proposition 30. Let W be integer. Assume fu 2 Rm2 : WTu  qg 6¼ ;. For every
 2  and j ¼ 1,. . . , m2, (j, ) is lower semicontinuous and nondecreasing in j.
Moreover, for any h 2 Z, (j, ) is constant over j 2 ðh  j  1, h  j,
 2 , j ¼ 1, . . . , m2.
Proof. The ﬁrst part of the proposition comes from Proposition 2. Any
solution y 2 arg minfqTy: Wy    0, y 2 Yg belongs to fy: Wy    ,
y 2 Yg when 0  . So ð, ðwÞÞ  ð0, ðwÞÞ. Deﬁne h ¼ dj  0
je. With
integral W, the jth constraint (Wy)j  jj implies (Wy)j  hj. Hence
(j, (!)) is constant over (hj1, hj].
u
It is thus possible to partition the  space in an orthogonal complex C,
where each cell C 2 C is of the form Q
j¼1,..., m2 ðaj, bj. On each of these cells,
() is constant. The closure of a nonempty cell forms a full-dimensional
hyper-rectangle. The nonempty cells form a partition of Rm2. A branch &
bound algorithm can be constructed, where the branching consists of
considering other cells of this orthogonal complex than those already
considered.
Deﬁne, as usual,
ðÞ ¼ E½ð, ð!ÞÞ
Deﬁne the current problem associated to a set S as
CPðSÞ
z ¼ inf
x,,	fcx þ 	: x 2 X,  2 S, Tx ¼ , 	  flðxÞ, l ¼ 1, . . . , sg
where, as before, 	  fl(x) are optimality cuts or lower bounding functionals.
Typically, (3.72) can be used here.
258
F.V. Louveaux and R. Schultz

Algorithm for second-stage integer variables
Step 1 Initialization: Set  ¼ 0, z ¼ 1. Choose s and ﬁnd s valid inequalities
	  fl(x), l ¼ 1,. . . , s. A list is created that contains the single node N1 :¼ .
Set  ¼ 1.
Step 2 Selection: Select a node N in the list; if none exists, stop.
Step 3 Current solution: Set  :¼  þ 1. Solve CP(N). If N is infeasible,
fathom node N, go to step 2. Otherwise, let (x, , 	) be an optimal
solution. If cx þ 	  z, fathom the current node and go to step 2.
Step 4 Cell: Find the cell C ¼ Q
j¼1,..., m2 ðaj, bj s.t.  2 C. Let b ¼ ðb1, . . . , bm2Þ.
Compute (b, ) for all  2  and let  ¼ E½ðb, Þ.
Step 5 Solution value: Solve
v ¼ inf
x,fcTx: x 2 X,  2 C, Tx ¼ g:
Let x,  be an optimal solution. Compute z ¼ cx þ . If z < z, update
z :¼ z.
Step 6 Branch: Select a component j, 1  j  m2. Create two new nodes
N \ f: j  ajg and N \ f: j > bjg. Fathom node N and go to step 2.
The algorithm is ﬁnite as the number of cells of the complex is ﬁnite since X
is compact. Additional valid inequalities can be found along the way in step 3.
In practice, open sets and inf would be replaced by closed sets and min,
through a well-chosen tolerance on open sets. In the following case, the
deﬁnition of the cells is easier. When the discrete random variable is such that
all realizations of component j, j ¼ 1,. . . , m2, are of the form hj þ k, k 2 Z for
some hj. Then, all cells can be deﬁned as Q
j¼1,..., m2 ðaj, ajþ1.
Sampling
In many cases, the second-stage value function may be hard or impossible
to compute, even for a ﬁxed value of the ﬁrst-stage solution. It is natural then
to design methods based on some form of sampling. Such methods are
currently used in continuous stochastic programming and are described
elsewhere in this handbook. We provide here an introduction to some speciﬁc
aspects of stochastic discrete programs.
Stochastic branch & bound
At a given stage of the algorithm, one considers a current problem
ðCPÞ
z*ðNÞ ¼ minfcTx þ E½ðx, Þ: x 2 P \ Ng
ð3:82Þ
where P is a formulation of X, N, is a node of the ﬁrst-stage branching
scheme, Rn ¼ [¼1,...,R N and
ðx, Þ ¼ minfqTðÞy: WðÞy  hðÞ  TðÞx, y 2 Yg:
ð3:83Þ
Ch. 4. Stochastic Integer Programming
259

As z*(N) is too diﬃcult to compute, the stochastic branch & bound does try
to ﬁnd a lower bound function L(N) and an upper bound function U(N)
which satisfy the following two conditions
(i) for every N 6¼ ;, LðNÞ  z*ðNÞ  UðNÞ
(ii) for
every
singleton
x 2 X,
LðfxgÞ ¼ z*ðfxgÞ ¼ UðfxgÞ.As
usual,
z* ¼ min¼1,..., Rz*ðNÞ. Also, z*  z ¼ min¼1,..., R UðNÞ. Thus, a node
N can only be fathomed when LðNÞ  z. Alternatively, a node Nl ¼ ;
can also be fathomed.
There are various ways to obtain lower and upper bound functions in
stochastic discrete programs. One such way is to use the classical wait-and-see
(WS) and expected result of using the EV solution (EEV) values. Let
xðÞ 2 arg minfcTx þ ðx, Þ: x 2 P \ Ng be the WS solution for a given
 2  and node N. Similarly, let x* 2 arg minfcTx þ E½ðx, Þ: x 2 P \ Ng
be a solution of the current problem (CP). For any  2 , cTxðÞþ
ðxðÞ, Þ  cTx* þ ðx*, Þ. The lower bound function is obtained by taking
the expectation of the left-hand-side of this inequality:
LðNÞ :¼ E½minfcTx þ ðx, Þ: x 2 P \ Ng:
By deﬁnition, the expectation of the right-hand of the same inequality is
precisely z*(N), which proves the condition L(N)  z*(N) holds. Moreover,
for every singleton x, we have LðfxgÞ ¼ z*ðfxgÞ ¼ cTx þ E½ðx, Þ.
Similarly, let x 2 arg minfcTx þ ðx, E½Þ: x 2 P \ Ng be the solution of
the EV problem on node N. We deﬁne
UðNÞ :¼ E½cTx þ ðx, Þ
which is the EEV value for node N. As x is a feasible solution to (CP), it
follows
that
z*(N)  U(N)
holds.
Clearly,
for
every
singleton,
U({x}) ¼ z*({x}). We now illustrate why ﬁnding U(N) and, especially,
L(N) is still a hard problem.
Example 31. Project Financing. Assume we can invest in n projects. Project j
can be started at a cost cj. In the second stage, projects which have been
started can be continued or not. If project j is continued, it provides a revenue
qj (). Project j requires tij units of resource i in the ﬁrst stage and an
additional wij () units to be continued. A total of hi() units of resource i will
be available over the two stages. The two-stage stochastic program reads as
minfcTx þ E½ðx, Þ: x 2 Pg where P is a formulation of some ﬁrst-stage
constraints and
ðx, Þ ¼ minfqTðÞy: WðÞy  hðÞ  Tx, y  x, y 2 f0, 1gng:
ð3:84Þ
260
F.V. Louveaux and R. Schultz

The current problem is as (3.82). To obtain an upper bound on N, we solve
the expected value problem
minfcTx þ E½qTðÞy: Tx þ E½WðÞy  E½hðÞ,
y  x, y 2 f0, 1gn, x 2 P \ Ng:
ð3:85Þ
This is a multiknapsack problem. For simplicity, assume P  {0, 1}n. Now, N
will include additional restrictions on x. If x 2 N implies xj ¼ 0 for some j,
then xj and yj can be removed from the computation in (3.84). If x 2 N
implies xj ¼ 1 for some j, then xj is also removed from the computation in
(3.84). Finally, if x 2 N implies xj 2 {0, 1}, then it follows that (3.84) can be
simpliﬁed as yj ¼ xj in any deterministic solution. Thus, ﬁnding x is relatively
easy. Yet, ﬁnding U(N) still requires computing E½ðx, Þ. This involves
solving a multiknapsack problem for each  2 . Unless the support of  is
discrete with low cardinality, E½ðx, Þ cannot be computed exactly, but
only estimated through sampling. Similarly, computing L(N) amounts to
solving a deterministic multiknapsack for each  2 . The same simpliﬁcations
as above are available, yet L(N) cannot be computed exactly but only
estimated through sampling.
A stochastic lower bound function can be obtained by Monte Carlo
simulation. For i.i.d. observations k, k ¼ 1,. . . , S, one obtains
ðnÞ ¼ 1
S
X
S
k¼1
minfcTx þ ðx, kÞ: x 2 P \ Ng:
For the same sample, one obtains a stochastic upper bound
ðNÞ ¼ 1
S
X
S
k¼1
ðcTx þ ðx, kÞÞ
where, as before, x is the solution of the EV problem on node N.
When the lower and upper bounds are random variables, fathoming
of the nodes becomes more problematic. Deletion of a node on the basis
of the statistical estimates may lead to the loss of the optimal solution.
On the other hand, the stochastic lower and upper bounds (N) and (N)
can be updated each time a new sample is drawn, in a manner similar
to the one which updates cuts in a stochastic decomposition method. As
limS!1 ðNÞ ! LðNÞ, a.s. and limS!1 ðNÞ ¼ UðNÞ a.s., the errors
j(N)L(N)j and j(N)U(N)j can be bounded in probability. Then,
deletion can only occur after a suﬃciently larger number of iterations where
the estimations of the bounds are improved. Convergence of the stochastic
Ch. 4. Stochastic Integer Programming
261

branch & bound relies on two arguments. As just mentioned, repeated
sampling lets the stochastic bounds tend to the lower and upper bounds L(N)
and U(N). On the other hand, repeated partitioning lets the nodes tend to
singletons for which, by construction, L({x}) ¼ z*({x}) ¼ U({x}). A detailed
description can be found in Norkin et al. (1998).
Sample average approximation
Consider a sample k, k ¼ 1,. . . , S, of sample scenarios generated from !
according
to
the
probability
distribution
P.
The
Sample
Average
Approximation problem is the following
ðSAAÞ
zS ¼ min cTx þ 1
S
X
S
k¼1
ðx, kÞ: x 2 P
(
)
where P is a formulation of X. It is a stochastic program with discrete
distribution. It can be solved by the classical L-shaped method if the second-
stage is continuous, combined with a branch & cut scheme to recover
integrality in the ﬁrst-stage. The SAA method proceeds by solving problem
(SAA) repeatedly. Assume M independent samples, each of size S, are
generated and, for each, the corresponding (SAA) problem is solved. We
obtain optimal values z1
S, z2
S, . . . , zM
S
and associated candidate solutions
^x1, ^x2, . . . , ^xM. It is then natural to pick-up one of these as the (estimated)
optimal solution. This would require ﬁnding the one which minimizes
cTx þ E[(x, )]. As this calculation is again impossible to carry out, this
value is estimated by
^zNðxÞ ¼ cTx þ 1
N
X
N
n¼1
ðx, nÞ
where {1,. . . , N} is a sample of size N. Typically, N is chosen to be quite large
and must be independent of the M samples generated above.
The estimated optimal solution is
^x* 2 arg min f^zNðxÞ: x 2 f ^x1, ^x2, . . . , ^xMgg:
Now, for any x, ^zNðxÞ is an unbiased estimator of cTx þ E[(x, )], and
therefore, for any feasible x, we have E½^zNðxÞ  z*. On the other hand, we
may also consider the average of the M optimal values of the SAA problems
zS ¼ 1
M
X
M
m¼1
zm
S :
262
F.V. Louveaux and R. Schultz

As E½zS ¼ WS, it follows that E½zS  z*. Thus, the quality of the solution ^x*
can be evaluated by computing the optimality gap estimate ^zNð ^x*Þ  zS. As
this quantity is random, it is helpful to estimate its variance. As the samples
used to compute those quantities are independent, the variance of the gap is
simply the sum of the variances of the two terms. These are
^2
zS ¼
1
ðM  1ÞM
X
M
m¼1
ðzm
S  zSÞ2
and
^2
^zNð ^x*Þ ¼
1
ðN  1ÞN
X
N
n¼1
ðcT ^x* þ ð ^x, nÞ  ^zNð ^x*ÞÞ2:
The above procedure for statistical evaluation of a candidate solution was
suggested in Mak et al. (1999). Convergence properties of the SAA method were
studied in Kleywegt et al. (2001) and Ahmed and Shapiro (2002). An example
of application to routing problems can be found in Verweij et al. (2003).
3.5
Bibliographical notes
The systematic investigation of stochastic integer programs started during
the 1990s, only. Survey and introductory articles were published by Klein
Haneveld and van der Vlerk (1999) and Ro¨ misch and Schultz (2001). An
annotated bibliography was compiled by Stougie and van der Vlerk (1997).
The textbook Birge and Louveaux (1997) has a chapter on stochastic integer
programs. Integer programming basics are laid out in the textbooks
Nemhauser and Wolsey (1988) and Wolsey (1998), for instance.
The ﬁrst continuity result for the expected recourse function of a stochastic
linear program with integer recourse is due to Stougie (1985). The suﬃcient
conditions for lower semicontinuity, continuity, and Lipschitz continuity of
Propositions 3 and 4, with extensions to random technology matrix T in (2.4),
were derived in Schultz (1993, 1995). Joint qualitative (semi-) continuity of the
expected recourse as a function of the ﬁrst-stage decision and the integrating
probability measure together with conclusions towards stability were addressed
in Artstein and Wets (1994), Schultz (1992, 1995). Quantitative joint continuity
of the expected recourse function and quantitative stability of the problem (2.3)
were studied in Rachev and Ro¨ misch (2002) and in Schultz (1996).
For the ﬁrst time, stochastic programs with simple integer recourse were
investigated in Louveaux and van der Vlerk (1993). The analysis was pushed
ahead in Klein Haneveld and van der Vlerk (1994), Klein Haneveld et al.
(1996, 1997), see also the dissertation van der Vlerk (1995).
Ch. 4. Stochastic Integer Programming
263

So far, very little is known about the structure of multi-stage stochastic
integer programs. An introduction into this problem class was given in
Ro¨ misch and Schultz (2001). Our exposition in Section 2.3 essentially follows
parts of that paper. Power problems leading to multi-stage stochastic integer
programs and specialized methods for their solution were discussed in
Dentcheva and Ro¨ misch (1998), Nowak (2000), Nowak and Ro¨ misch (2000)
and Takriti et al. (1996).
More details on the deﬁnitions and properties presented in Section 3.1 can
be found in Wolsey (1998).
The ﬁrst use of decomposition methods in stochastic programs having
discrete decisions in the second-stage is the integer L-shaped method of
Laporte and Louveaux (1993) for the case of ﬁrst-stage binary variables. This
method has been applied to solve a variety of location and routing problems.
The example considered in Section 3.3.2 is taken from Laporte et al. (2002).
The generalization of the integer L-shaped to mixed integer ﬁrst-stage was
done by Carøe (1998) in his doctoral dissertation and presented in Carøe and
Tind (1997, 1998).
The ﬁrst attempt to design a method based on ﬁrst-stage integer variables
branching is due to Ahmed et al. (2000), see the exposition in Section 3.4. In
Schultz et al. (1998) a solution procedure based on enumeration and bounding
in the ﬁrst-stage while handling the second-stage by algebraic methods
exploiting problem similarities has been proposed. Another application of
algebraic methods to stochastic integer programming has been carried out in
Hemmecke and Schultz (2003). The paper deals with test set decomposition. It
identiﬁes building blocks that enable generation of improving vectors for the
stochastic program and that can be computed by a completion procedure
from computational algebra.
The scenario decomposition method displayed in Section 3.1.3 stems from
Carøe and Schultz (1999). In Løkketangen and Woodruﬀ(1996) a scenario
decomposition method employing Augmented Lagrangians for the dualiza-
tion and tabu search for the resulting quadratic mixed-integer subproblems
has been developed.
Recently, Alonso-Ayuso et al. (2003) have proposed a branch-and-ﬁx
coordination approach to solving multi-stage stochastic integer programs.
Their idea is to formulate the stochastic program in a splitting variable
representation, to perform scenario-wise an LP-based branch & bound, and to
establish the nonanticipativity in the course of the branching. The latter is
achieved by a coordinated ﬁxing of variables that puts variables for diﬀerent
scenarios at identical values provided a nonanticipativity condition requires
the identity.
References
Ahmed, S., A. Shapiro (2002). The sample average approximation method for stochastic programs
with integer recourse, Preprint, Georgia Institute of Technology, Atlanta.
264
F.V. Louveaux and R. Schultz

Ahmed, S., M. Tawarmalani, N.V. Sahinidis (2000). A ﬁnite branch and bound algorithm for two-
stage stochastic integer programs. Stochastic Programming E-Print Series 16—2000, http://
dochost.rz.hu-berlin.de/speps/.
Alonso-Ayuso, A., L.F. Escudero, A. Garı´n, M.T. Ortun˜ o, G. Pe´ rez (2003). An approach for strategic
supply chain planning under uncertainty based on stochastic 0-1 programming. Journal of Global
Optimization 26, 97–124.
Artstein, Z., R.J.-B. Wets (1994). Stability results for stochastic programs and sensors, allowing for
discontinuous objective functions. SIAM Journal on Optimization 4, 537–550.
Bacaud, L., C. Lemare´ chal, A. Renaud, C. Sagastiza´ bal (2001). Bundle methods in stochastic optimal
power management: A disaggregated approach using preconditioners. Computational Optimization
and Applications 20, 227–244.
Bank, B., J. Guddat, D. Klatte, B. Kummer, K. Tammer (1982). Non-linear Parametric Optimization,
Akademie-Verlag, Berlin.
Bank, B., R. Mandel (1988). Parametric Integer Optimization, Akademie-Verlag, Berlin.
Birge, J.R., F.V. Louveaux (1997). Introduction to Stochastic Programming, Springer-Verlag, New York.
Blair, C.E., R.G. Jeroslow (1977). The value function of a mixed integer program: I. Discrete
Mathematics 19, 121–138.
Carøe, C.C. (1998). Decomposition in stochastic integer programming, Ph.D. Thesis, Institute of
Mathematical Sciences, Department of Operations Research, University of Copenhagen, Denmark.
Carøe, C.C., R. Schultz (1999). Dual decomposition in stochastic integer programming. Operations
Research Letters 24, 37–45.
Carøe, C.C., J. Tind (1997). A cutting plane approach to mixed 0–1 stochastic integer programs.
European Journal of Operations Research 101, 306–316.
Carøe, C.C., J. Tind (1998). L-shaped decomposition of two-stage stochastic programs with integer
recourse. Mathematical Programming 83, 139–152.
Dentcheva, D., W. Ro¨ misch (1998). Optimal power generation under uncertainty via stochastic
programming, in: K. Marti, P. Kall (eds.), Stochastic Programming Methods and Technical
Applications. Lecture Notes in Economics and Mathematical Systems, Vol. 458, Springer-Verlag,
Berlin, pp. 22–56.
Dynkin, E.B., I.V. Evstigneev (1976). Regular conditional expectation of correspondences. Theory of
Probability and Applications 21, 325–338.
Evstigneev, I. (1976). Measurable selection and dynamic programming. Mathematics of Operations
Research 1, 267–272.
Gro¨ we-Kuska, N., K.C. Kiwiel, M.P. Nowak, W. Ro¨ misch, I. Wegner (2002). Power management in a
hydro-thermal
system
under
uncertainty
by
Lagrangian
relaxation,
in:
C.
Greengard,
A. Ruszczyn´ ski (eds.), Decision Making under Uncertainty: Energy and Power IMA Volumes in
Mathematics and its Applications, Vol. 128, Springer-Verlag, New York.
Hemmecke, R., R. Schultz (2003). Decomposition of test sets in stochastic integer programming.
Mathematical Programming 94, 323–341.
Hiriart-Urruty, J.B., C. Lemare´ chal (1993). Convex Analysis and Minimization Algorithms, Springer-
Verlag, Berlin.
Kiwiel, K.C. (1990). Proximity control in bundle methods for convex nondiﬀerentiable optimization.
Mathematical Programming 46, 105–122.
Klein Haneveld, W.K., M.H. van der Vlerk (1994). On the expected value function of a simple integer
recourse problem with random technology matrix. Journal of Computational and Applied
Mathematics 56, 45–53.
Klein Haneveld, W.K., L. Stougie, M.H. van der Vlerk (1996). An algorithm for the construction of
convex hulls in simple integer recourse programming. Annals of Operations Research 64, 67–81.
Klein Haneveld, W.K., L. Stougie, M.H. van der Vlerk (1997). Convex approximations for simple
integer recourse models by perturbing the underlying distribution. Research Report 97A19, SOM,
University of Groningen.
Klein Haneveld, W.K., M.H. van der Vlerk (1999). Stochastic integer programming: General models
and algorithms. Annals of Operations Research 85, 39–57.
Ch. 4. Stochastic Integer Programming
265

Kleywegt, A.J., A. Shapiro, T. Homem-de-Mello (2001). The sample average approximation method
for stochastic discrete optimization. SIAM Journal on Optimization 12, 479–502.
Laporte, G., F.V. Louveaux (1993). The integer L-shaped method for stochastic integer programs with
complete recourse. Operations Research Letters 13, 133–142.
Laporte, G., F.V. Louveaux, L. Van Hamme (2002). An integer L-shaped algorithm for the
capacitated vehicle routing problem with stochastic demands. Operations Research 50, 415–423.
Løkketangen, A., D.L. Woodruﬀ(1996). Progressive hedging and tabu search applied to mixed integer
(0,1) multi-stage stochastic programming. Journal of Heuristics 2, 111–128.
Louveaux, F.V., M.H. van der Vlerk (1993). Stochastic programming with simple integer recourse.
Mathematical Programming 61, 301–325.
Mak, W.K., D.P. Morton, R.K. Wood (1999). Monte-Carlo bounding techniques for determining
solution quality in stochastic programs. Operations Research Letters 24, 47–56.
Nemhauser, G.L., L.A. Wolsey (1988). Integer and Combinatorial Optimization, Wiley, New York.
Norkin, V.I., Y.M. Ermoliev, A. Ruszczyn´ ski (1998). On optimal allocation of indivisibles under
uncertainty. Operations Research 46, 381–395.
Nowak, M.P. (2000). Stochastic Lagrangian relaxation in power scheduling of a hydro-thermal system
under uncertainty. Ph.D. Thesis, Institute of Mathematics, Humboldt-University Berlin.
Nowak, M.P., W. Ro¨ misch (2000). Stochastic Lagrangian relaxation applied to power scheduling in a
hydro-thermal system under uncertainty. Annals of Operations Research 100, 251–272.
Rachev, S.T., W. Ro¨ misch (2002). Quantitative stability in stochastic programming: The method of
probability metrics. Mathematics of Operations Research 27, 792–818.
Rockafellar, R.T., R.J.-B. Wets (1978). The optimal recourse problem in discrete time: L1-multipliers
for inequality constraints. SIAM Journal on Control and Optimization 16, 16–36.
Rockafellar, R.T., R.J.-B. Wets (1997). Variational Analysis, Springer-Verlag, Berlin.
Ro¨ misch,
W.,
R.
Schultz
(2001).
Multistage
stochastic
integer
programs:
an
introduction,
in: M. Gro¨ tschel, S.O. Krumke, J. Rambau (eds.), Online Optimization of Large Scale Systems,
Springer-Verlag, Berlin, pp. 581–600.
Schultz, R. (1992). Continuity and stability in two-stage stochastic integer programming, in: Marti, K.
(ed.), Stochastic Optimization, Numerical Methods and Technical Applications. Lecture Notes in
Economics and Mathematical Systems, Vol. 379, Springer, Berlin.
Schultz, R. (1993). Continuity properties of expectation functions in stochastic integer programming.
Mathematics of Operations Research 18, 578–589.
Schultz, R. (1995). On structure and stability in stochastic programs with random technology matrix
and complete integer recourse. Mathematical Programming 70, 73–89.
Schultz, R. (1996). Rates of convergence in stochastic programs with complete integer recourse. SIAM
Journal on Optimization 6, 1138–1152.
Schultz, R., L. Stougie, M.H. van der Vlerk (1998). Solving stochastic programs with integer recourse
by enumeration: A framework using Gro¨ bner basis reductions. Mathematical Programming 83,
229–252.
Stougie, L. (1985). Design and analysis of algorithms for stochastic integer programming. Ph.D.
Thesis, Center for Mathematics and Computer Science, Amsterdam.
Stougie, L., M.H. van der Vlerk (1997). Stochastic integer programming: Annotated Bibliographies in
Combinatorial Optimization, in: M. Dell’Amico, F. Maﬃoli, S. Martello (eds.), Wiley, Chichester,
pp. 127–141.
Takriti, S., J.R. Birge, E. Long (1996). A stochastic model for the unit commitment problem. IEEE
Transactions on Power Systems 11, 1497–1508.
van der Vlerk, M.H. (1995). Stochastic programming with integer recourse. Ph.D. Thesis, University of
Groningen.
Verweij, B., S. Ahmed, A.J. Kleywegt, G.L. Nemhauser, A. Shapiro (2003). The sample average
approximation
method
applied
to
stochastic
routing
problems:
a
computational
study.
Computational Optimization and Applications 24, 289–333.
Wolsey, L.A. (1998). Integer Programming, Wiley, New York.
266
F.V. Louveaux and R. Schultz

Chapter 5
Probabilistic Programming
Andra´s Pre´kopa
RUTCOR, Rutgers Center for Operations Research, 640 Bartholomew Road, Piscataway,
NJ 08854-8003, USA
Abstract
Probabilistic programming means two strongly connected models as well as the
study of their mathematical properties, solutions of the relevant optimization
problems and their applications. The two models are: maximizing (or mini-
mizing) a probability under constraints and programming under probabilistic
constraints. There are a number of variants and special cases of these models
and we present them in Section 1. In Section 2 we summarize those mathe-
matical theories which can be used to prove the convexity of large classes of our
problems and we also show how they can be applied in this context. In Section 3
we present solution algorithms of our stochastic programming problems. Since
we are handling probabilities of sets in higher dimensional spaces, it is necessary
to use bounding and other approximation algorithms to ﬁnd these probabilities
with satisfactory precision. This is the subject of Section 5. In Section 4 we
present
two-stage
and
multi-stage
problems
which
are
combined
with
probabilistic constraints. Some duality and stability theorems are presented
in Section 6. Finally, in Section 7, we present applications of our model
constructions.
1
Model constructions
1.1
Statistical decisions
Stochastic programming is a science that solves problems in connection
with stochastic systems, where the mathematical form of the problem is of
optimization type. It follows from this that the main ingredients of this science
are: statistical decision principles, optimization methods and computer
science. If decision is taken only once in time, then the model is static.
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
267

If decisions are taken subsequently in such a way that between two subsequent
decisions an observation of a random variable takes place, then the model is
dynamic.
Looking at the problem from another angle, a stochastic programming
model can be of a type where the functioning of the system is paramount and
we maximize the probability of the system functioning or optimize another
objective function subject to a probabilistic constraint. Another case is, where
we allow violations of the constraints that describe the system but penalize
them in such a way that the system cost plus the expected penalty of violations
should be as small as possible. Both of these principles can be used in static
and dynamic model constructions.
One of the simplest and most classical examples of statistical decisions is the
testing of statistical hypotheses. Assume, for the sake of simplicity, that we
have two probability distributions P ¼ { pk} and Q ¼ {qk} on the set of integers
and we want to test the hypothesis that P is the true distribution, against the
alternative that it is Q. The way the test is constructed is as follows: ﬁnd a set
of integers, the critical set, such that its probability with respect to P is smaller
than or equal to ">0 (where " is a previously given ﬁxed number) and the
probability of this set with respect to Q should be maximal. The problem can
be formalized in the following way:
max
X
k
qkxk
subject to
X
k
pkxk  ",
ð1:1Þ
where xk 2 {0, 1} for every k. The critical set C is then given by
C ¼ fk j xk ¼ 1g:
The probability P(C) is called the ﬁrst kind error, while the probability QðCÞ is
the second kind error.
After the construction of the test we work with it in such a way that we take
a sample, a random integer, and reject the hypothesis P if the integer is in C
otherwise we accept it (or at least say that the sample does not contradict the
hypothesis.) Problem (1.1) can be termed the Neyman-Pearson problem.
Problem (1.1) can also be described in such a way that the ﬁrst kind error
(rejecting the true hypothesis) should be smaller than or equal to the small
number ", and, given this, the second kind error (accepting a false hypothesis)
should be as small as possible.
The above statistical decision is static one. An example for dynamic type
statistical decision situation is provided by Wald’s sequential analysis, where
268
A. Pre´kopa

we want to decide in favor or against the hypothesis by given probabilities,
respectively, by the use of a sequential decision process.
In the above examples we see that optimization under probabilistic
constraints and maximizing a probability under constraints are classical
statistical decision principles.
1.2
Static stochastic programming models: programming under probabilistic
constraints and maximizing a probability under constraints
A general formulation of the ﬁrst problem mentioned in the title is the
following:
min hðxÞ
subject to
h0ðxÞ ¼ Pðg1ðx, Þ  0, . . . , grðx, Þ  0Þ  p0
h1ðxÞ  p1, . . . , hmðxÞ  pm,
ð1:2Þ
where x is the decision vector,  is a random vector, h(x), h1(x),. . . , hm(x) are
given functions, 0<p0  1, p1,. . . , pm are given numbers.
A special case of problem (1.2) is the following:
min cTx
subject to
PðTx  Þ  p
Ax  b, x  0:
ð1:3Þ
Sometimes we have no special objective function that expresses some
cost and we only want to maximize a probability. The general form of this
problem is
max Pðg1ðx, Þ  0, . . . , grðx, Þ  0Þ
subject to
h1ðxÞ  p1, . . . , hmðxÞ  pm:
ð1:4Þ
A stochastic programming problem is frequently formulated in such a way
that we have a ‘‘deterministic underlying problem’’ also called ‘‘base
problem’’. Then we observe that some of the parameters in it are not constants
but random variables and therefore the problem is meaningless in its original
form. The use of a statistical decision principle takes us to a stochastic
programming problem which can be problem (1.1) or (1.2).
Ch. 5. Probabilistic Programming
269

Note that the use of a probabilistic constraint does not exclude the use of
another principle: penalizing constraint violations. In fact, both principles can
be used simultaneously, thereby arriving at a hybrid model. For example, a
hybrid model constructed from problem (1.3) is the following:
min cTx þ
X
r
i¼1
qiEð½i  TixþÞ
(
)
subject to
PðTx  Þ  p
Ax  b, x  0,
ð1:5Þ
where T1,. . . , Tr are the rows of the matrix T, 1,. . . , r are the components of
the random vector  and q1,. . . , qr are nonnegative constants, penalizing
violations of T1x  1,. . . , Trx  r, respectively.
1.3
Related measures of violation
In connection with the stochastic constraints Tix  i, i ¼ 1,. . . , r, some
measure of violation has been incorporated into the objective function in
problem (1.5). There are, however, other measures of violation that can be
used in practice. We present two of them.
The ﬁrst one, introduced in Pre´ kopa (1973a), is the collection of the
conditional expectations E(iTix j iTix>0), i ¼ 1,. . . , r. We can incorpo-
rate them into problem (1.5) but we prefer to use them among the constraints,
rather than in the objective function. The new constraints that we supplement
to problem (1.5) are:
Eði  Tix j i  Tix > 0Þ  di
i ¼ 1, . . . , r,
ð1:6Þ
where di, i ¼ 1,. . . , r are some given constants. We call them conditional
expectation constraints. Problem (1.5), together with the constraints (1.6)
prescribes that if we decide on x and after that observe the random vector ,
then in at least p100% of the cases no violation occurs in Tx  , further, if we
single out the cases where iTix>0, then the average magnitude of the
violation should be less than or equal to di, i ¼ 1,. . . , r. Subject to these
constraints we minimize the system cost cTx plus the expected penalized sum
of the violations.
Another measure of violation is the integrated chance or probabilistic
constraint. For the case of r ¼ 1 it is deﬁned as
Eð½  TxþÞ  d:
ð1:7Þ
270
A. Pre´kopa

For the case of r  1 the integrated chance constraint is
E max
i
½i  Tixþ


 d:
ð1:8Þ
In (1.7) and (1.8) d is a constant.
A more general form of this kind of constraint can be formulated as
follows. Suppose that in the underlying problem we have the stochastic
constraints
giðx, Þ  0,
i ¼ 1, . . . , r,
where g1,. . . , gr are some functions. Then in the stochastic programming
problem we may include the constraint
E max
i
½giðx, Þþ


 d:
ð1:9Þ
A practical interpretation of the integrated chance constraint is the
following. If  designates the demand for power in an area on a given day and
Tx is the total generating capacity (r ¼ 1 now), then E([Tx] þ) is the
expected unserved energy. In power system engineering this measure is
considered equally important to loss of load probability (LOLP), accounted
for in probabilistic constraints.
1.4
Bibliographical notes
Historically the ﬁrst paper that used the programming under probabilistic
constraint principle was the one by Charnes et al. (1958), where, however,
probabilistic constraints are imposed individually on each constraint involving
random variables. This formulation called ‘‘chance constrained program-
ming’’ by the authors may be correct in some cases, especially when the
random variables, appearing in diﬀerent stochastic constraints, are indepen-
dent. In general, however, it has the serious defect of ignoring joint probability
distribution, i.e., the type of stochastic dependence of the random variables
involved. A paper by Miller and Wagner (1965) takes the probabilistic
constraint jointly on the stochastic constraints but handles only independent
random variables appearing on the right hand sides of the stochastic
constraints. Pre´ kopa (1970, 1973a) initiated the model and its research, where
the probabilistic constraint is taken jointly for the stochastic constraints and
the random variables involved are stochastically dependent, in general.
Constraints of type (1.6) were introduced in Pre´ kopa (1973a) and those in
(1.8) by Klein Haneveld (1986).
Ch. 5. Probabilistic Programming
271

2
Convexity theory
2.1
Basic theory of logconcave and -concave measures
Logconcave measures have been introduced in the stochastic programming
framework but they became widely used also in statistics, convex geometry,
mathematical analysis, economics, etc.
Deﬁnition 2.1. A function f(z)  0, z 2 Rn is said to be logarithmically concave
(logconcave), if for any z1, z2 and 0<<1 we have the inequality
f ðz1 þ ð1  Þz2Þ  ½ f ðz1Þ½f ðz2Þð1Þ:
ð2:1Þ
If f(z)>0 for z 2 Rn, then this means that log f(z) is a concave function in Rn.
Deﬁnition 2.2. A probability measure deﬁned on the Borel sets of Rn is said to
be logarithmically concave (logconcave) if for any convex subsets of Rn: A, B
and 0<<1 we have the inequality
PðA þ ð1  ÞBÞ  ½PðAÞ½PðBÞ1,
ð2:2Þ
where A þ (1)B ¼ {z ¼ x þ (1)y j x 2 A, y 2 B}. The basic theorem of
logconcave measures is the following.
Theorem 2.1. If the probability measure P is absolutely continuous with respect
to the Lebesgue measure and is generated by a logconcave probability density
function then the measure P is logconcave.
Remark 2. The proof of Theorem 2.1 provides us with a more general
assertion: if P is an absolutely continuous probability measure (that can be
extended in a trivial way to all measurable subsets of R) and A, B  Rn are two
Borel sets then we have the inequality (2.2) for any 0<<1. In this assertion
we used the fact that Borel measurability of A and B implies the (Lebesgue)
measurability of A þ (1)B. Even though this more general assertion holds
true, Theorem 2.1 provides us with enough basis to derive our convexity
theory of stochastic programming.
Theorem 2.2. If P is a logconcave probability distribution and A  Rn is a
convex set, then P(A þ x), x 2 Rn is a logconcave function.
Theorem 2.3. If  2 Rn is a random variable, the probability distribution of
which is logconcave, then the probability distribution function F(x) ¼ P(  x) is
a logconcave function in Rn.
272
A. Pre´kopa

Theorem 2.4. If n ¼ 1 in Theorem 2.3 then also 1F(x) ¼ P(>x) is a
logconcave function in R1.
Theorems 2.2, 2.3 and 2.4 are easy consequences of the notion of a
logconcave measure. Less obvious are the following
Theorem 2.5. If g1(x, y),. . . , gr(x, y) are quasi-concave functions of the variables
x 2 Rn, y 2 Rm and  2 Rm is a random variable that has logconcave probability
distribution, then the function G(x) ¼ P(g1(x, )  0,. . . , gr(x, )  0), x 2 Rn is
logconcave.
Theorem 2.6. If f(x, y), x 2 Rn, y 2 Rm is a logconcave function, then
Z
Rm
f ðx, yÞ dy,
x 2 Rn
is also a logconcave function. The above theorem implies
Theorem 2.7. If f(x), g(x), x 2 Rn, are logconcave functions then their
convolution
Z
Rm
f ðx  yÞgðyÞ dy,
x 2 Rn
is also logconcave.
Theorem 2.8. If the random vector  has logconcave probability distribution and
A is a constant matrix of appropriate size, then  ¼ A also has a logconcave
distribution.
Deﬁnition 2.3. A function f(z), z 2 Rn is said to be -concave if for any
x, y 2 Rn, such that f(x)>0, f(y)>0 we have the inequality
f ðx þ ð1  ÞyÞ  ½f ðxÞ þ ð1  Þf ðyÞ
1
,
ð2:3Þ
where 1  <1. The expression on the right hand side is deﬁned by
continuity for the cases of  ¼ 1,  ¼ 0.
Inequality (2.3) for diﬀerent  values means the following:
(a)  ¼ 1. In this case we have f(x þ (1)y)  min( f(x), f ( y)), i.e., the
function is quasi-concave.
(b) 1<<0. Then we have f (x þ (1)y)  f a(x) þ (1) f a(y), i.e.,
f a(x) is convex on the set {x j f(x)>0}.
Ch. 5. Probabilistic Programming
273

(c)  ¼ 0. We have the inequality f(x þ (1)y)  [ f(x)][ f( y)]1, and the
function is logconcave.
(d) 0<<1. This case is similar to case (b) but now f a(x) is concave on
the set {x j f(x)>0}.
Deﬁnition 2.4. The probability measure P deﬁned on the Borel sets of Rn is
said to be -concave, if for any convex subsets of Rn: A, B for which P(A),
P(B)>0 and<<1 we have the inequality
PðA þ ð1  ÞBÞ  ð½PðAÞ þ ð1  Þ½PðBÞÞ
1
,
ð2:4Þ
where 1  <1. The expression on the right hand side is deﬁned by
continuity for the cases  ¼ 1,  ¼ 0. The inequality (2.4) has similar
interpretation in the special cases as the inequality (2.3). If  ¼ 1, then the
measure P is said to be quasi-concave. If  ¼ 0, then P is a logconcave
measure.
Theorem 2.9. If the probability measure P is generated by an -concave
probability density function, then P is -concave, where  ¼ =ð1 þ nÞ.
Theorem 2.10. If the probability measure P is generated by the probability
density function f(z), z 2 Rn which has the property that f 1=nðzÞ, z 2 Rn is
convex, then the probability measure P is quasi-concave, i.e., for any convex
subsets A, B of Rn and 0<<1, we have the inequality
PðA þ ð1  ÞBÞ  minðPðAÞ, PðBÞÞ:
ð2:5Þ
Note that in this case there is no need to assume that P(A)>0, P(B)>0
because if at least one of them is 0 then (2.5) holds trivially.
Theorem 2.9 holds in a stronger form, too. That form, however, requires
the probability measure P to be deﬁned on all (Lebesgue) measurable sets of
Rn. If P is deﬁned on the -algebra of all Borel sets of Rn, then there is a trivial
extension of P to all measurable sets provided that P is generated by a
probability density function. In fact, any measurable set can be obtained from
a Borel set by adding to it or removing from it a measurable set of measure 0.
Thus if we assign P(C) ¼ 0 to all measurable set C with measure 0, then the
required extension can be obtained.
It is well-known, that if A, B are Borel sets in Rn and 0<<1, then
A þ (1)B is a Lebesgue measurable set.
The extension of Theorem 2.9 asserts that if P is generated by an -convex
probability density function and A, B are Borel sets in Rn, 0<<1 then (2.4)
holds with  replaced by  ¼ =ð1 þ nÞ. In the applications, however, we use
274
A. Pre´kopa

our Theorem 2.1 and 2.9 in their original forms, rather than their more general
forms.
Theorem 2.5 has a counterpart for -concave measures.
Theorem 2.11. If g1(x, y), . . . , gr(x, y) are quasi-concave functions of the
variables x 2 Rn, y 2 Rm and  2 Rm is a random variable that has continuous
probability distribution and -concave probability density with 1 þ m  0, then
the function G(x) ¼ P(g1(x, ), . . . , gr(x, )  0) satisﬁes (2.3) with  replaced
by  ¼ =ð1 þ mÞ, where the inequalities for  ¼ 1,  ¼ 0 are interpreted by
continuity.
It follows that if  ¼ 0, then G(x) is logconcave (as asserted in Theorem 2.5)
and if  ¼ ð1=mÞ, then G(x) is quasi-concave.
2.2
Examples of multivariate probability distributions
(1) Uniform distribution. Let D be a convex subset of Rn with ﬁnite,
positive measure j D j Then
f ðxÞ ¼
1
jDj
if x 2 D
0
if x 62 D
(
is a lonconcave probability density function.
(2) Normal distribution. Its probability density function is deﬁned by
f ðxÞ ¼
1
ﬃﬃﬃﬃﬃﬃﬃ
jCj
p
ð2Þ
n
2 e1
2ðxÞTC1ðxÞ,
x 2 Rn,
where  is the expectation vector and C the covariance matrix of the
distribution; j C j designates the determinant of C. The matrix C is
supposed to be positive deﬁnite. It follows that C1 is also positive
deﬁnite, hence the quadratic form (x)TC1(x) is a convex
function (as it is well-known and easy to prove). This implies that
f(x) is a logconcave function.
(3) Wishart distribution. The probability density function of it is deﬁned by
f ðXÞ ¼
jXj
Np2
2
e1
2SpC1X
2
N1
2 p 
pðp1Þ
4
jCj
N1
2 Y
p
i¼1
 N  i
2


if X is positive deﬁnite, and f(X) ¼ 0 otherwise. Here C and X are p  p
matrices, C is ﬁxed and positive deﬁnite while X contains the variables.
Ch. 5. Probabilistic Programming
275

Since X is assumed to be symmetrical, there are n ¼ 1
2 pðp þ 1Þ
independent variables. We also assume that N  p þ 2. Since the p  p
matrices form a convex set in the n-dimensional space and it is well-
known that for any two p  p positive deﬁnite matrices we have the
inequality
jX1 þ ð1  ÞX2j  jX1jjX2j1,
where 0<<1, the function f is logconcave.
(4) Beta distribution. Its probability density function is deﬁned by
f ðXÞ ¼ cðn1, pÞcðn2, pÞ
cðn1 þ n2, pÞ
jXj
1
2ðn1p1Þ jI  Xj
1
2ðn2p1Þ,
if X, 1X are positive deﬁnite p  p matrices and f(X) ¼ 0 otherwise,
where
1
cðk, pÞ ¼ 2
pk
2 
pðp1Þ
2
Y
p
i¼1
 k  i þ 1
2


:
It is supposed that n1  p þ 1, n2  p þ 1. The number of independent
variables in X is n ¼ 1
2 pð p þ 1Þ. The logconcavity of the function f
follows the same way as that of f in example (3).
(5) Dirichlet distribution. Its probability density function is deﬁned by
f ðxÞ ¼ ð p1 þ    þ pnþ1Þ
ð p1Þ    ð pnþ1Þ xp11
1
   xpn1
n
ð1  x1      xnÞpnþ11
for x1>0, . . . , xn>0, x1 þ    þ xn<1 and f(x) ¼ 0 otherwise, where
p1, . . . , pn þ 1 are positive constants. If p1  1, . . . , pn þ 1  1, then f is a
logconcave function in Rn. If, however, p1<1, . . . , pn þ 1<1, then f is
logconvex, i.e., the inequality (2.1) holds always in reversed form. The
logconvexity of f does not hold in the entire space Rn but it holds in the
open simplex x1>0, . . . , xn>0, x1 þ    þ xn<1.
(6) Cauchy distribution. It is the joint distribution of the random variables
	i ¼
ﬃﬃﬃ
p i

,
i ¼ 1, . . . , n,
where (1,. . . , n) has standard normal distribution (each component
is N(0, 1)-distributed), (1,. . . , n) is independent of  which has
276
A. Pre´kopa

-distribution with 
 degrees of freedom. The probability density
function is
f ðxÞ ¼
 1
2 ð
 þ nÞ


ð
Þ
n
2 1
2 


jRj
1
2
1 þ 1

 xTR1x

1
2ð
þnÞ
for x 2 Rn. If n ¼ 1 and 
 ¼ 1 this reduces to the well-known univariate
Cauchy density
f ðxÞ ¼ 1

1
1 þ x2 ,
 1 < x < 1:
The n-variate Cauchy density has the property that f 1
n is convex in Rn,
hence Theorem 2.10 applies and the distribution is quasi-concave.
(7) Pareto distribution. Its probability density function is
f ðxÞ ¼ aða þ1Þ    ða þ n1Þ
Y
n
j¼1
j
 
!1 X
n
j¼1
1
j xjnþ1
 
!ðaþnÞ
for xi>i, i ¼ 1,. . . , n and f(x) ¼ 0 otherwise; 1,. . . , n are positive
constants. Since f 1
n is convex in Rn, Theorem 2.10 applies and the
probability distribution is quasi-concave.
(8) Gamma distribution. A univariate probability distribution is said to be
gamma distribution if its probability density has the form
f ðzÞ ¼ #z#1ez
ð#Þ
if z > 0
and f(z) ¼ 0 for z  0; >0, #>0 are constants. If  ¼ 1, then the
distribution is said to be standard. If  has gamma distribution, then #
has standard gamma distribution. Both the expectation and the
variance of a standard gamma distribution are equal to #.
An r-variate gamma distribution can be deﬁned in the following
way. Let A be the r  (2r1) matrix the columns of which are all 0–1
component vectors of size r except for the 0 vector. Let 1,. . . , s,
s ¼ 2r1 be independent standard gamma distributed random variables
and designate by  the vector of these components. Then we say that
the random vector
 ¼ A
has an r-variate standard gamma distribution.
Ch. 5. Probabilistic Programming
277

Let #1,. . . , #s be the expectations of 1,. . . , s, respectively and
designate by # the vector of these components. Then E() ¼ AE() and
the components of E() are, simultaneously, the variances of the
components of . A practical method for ﬁtting this distribution to
empirical data is the following.
Suppose we have the random variables 	i ¼ 1
i i, i > 0, i ¼ 1, . . . , r,
where we assume that  can be written as  ¼ A. Suppose that we
estimated E() and the covariances cik of the pairs i, k, i<k. Let
a1,. . . , ar be the rows of A and aiak the componentwise product of ai
and ak. Then we write up the problem:
find #
such that
cik ¼ ðaiakÞ#,
i  k
#  0:
Note that cii ¼ Var(i) ¼ E(i), i ¼ 1,. . . , r. The problem can be solved by
the ﬁrst phase of the simplex method. The joint probability distribution
function of the components of  is logconcave. If #1  1,. . . , #s  1, then
the assertion follows from the fact that any linear combination of
independent random variables having logconcave density is logcon-
cave. If #i<1 for some i’s then the logconcavity of the joint distribution
still holds but it needs a separate proof.
(9) The
posynomial
distribution.
This
distribution
has
support
{z j 0  zi  1, i ¼ 1,. . . , r} and its distribution function is deﬁned by
Fðz1, . . . , zrÞ ¼
1
X
N
i¼1
cizi1
1
   zir
r
,
0 < zi  1, i ¼ 1, . . . , r,
where i1  0,. . . , ir  0, i1 þ ,. . . , þ ir<0, and ci>0, i ¼ 1,. . . , N are
constants. Since the denominator is the sum of logconvex functions and
logconvexity carries over for sums, it follows that F(z1,. . . , zr) is
logconcave in the support of the distribution. There is no general rule,
however, to decide that under what parameter values is F in fact a
probability distribution function. It is easy to see that F is non-
decreasing in each variable and is 0 if at least one variable is 1, and is 1,
if all variables are þ 1. Thus, we only need to know that under what
condition do we have
@rFðz1, . . . , zrÞ
@z1, . . . , @zr
 0:
278
A. Pre´kopa

It is proved that if r ¼ 2 and 11  12  , . . . ,  1r, 21  22  , . . . ,  2r,
then the above inequality is satisﬁed and F(z1, z2) is a probability distribution
function.
2.3
Discrete distributions
There is no discrete counterpart of the theory of logconcave and -concave
measures described in Section 2.1. Already the logconcavity and -concavity
has many forms in the literature. There is no problem, however, in the
univariate case.
Deﬁnition 2.5. The discrete distribution { pn} deﬁned on the integer lattice
points of the real line is said to be logconcave if
p2
n  pn1pnþ1,
n ¼ 0,  1, . . . :
It follows from this that if n, i, j are three integers such that n ¼ i þ (1)j,
where 0<<1, then
pn  p
i p1
j
:
ð2:6Þ
The convolution theorem (Theorem 2.7) has a counterpart for univariate
discrete distributions and is the following.
Theorem 2.12. If { pn} and {qn} are two logconcave distributions on the lattice
points of R, then their convolution
rn ¼
X
1
k¼1
pnkqk,
n ¼ 0,  1, . . .
is also a logconcave distribution on the same lattice.
The above theorem implies that if { pn} is logconcave, then for any ﬁxed k
the sequence of nonnegative numbers
X
n
i¼nk
pi
Ch. 5. Probabilistic Programming
279

is also logconcave (satisﬁes the inequality in Deﬁnition 2.5). This, in turn,
implies that both sequences
FðnÞ ¼
X
n
i¼1
pi,
1  FðnÞ ¼
X
1
i¼nþ1
pi
are logconcave.
Examples for univariate logconcave distributions are the binomial, Poisson,
geometric, hypergeometric, uniform and other known distributions.
Simple examples show that Theorem 2.12 does not carry over to the
multivariate case. This is one indication why logconcavity and -concavity
properties of discrete distributions remain largely unexplored.
There are a few deﬁnitions to call a multivariate discrete distribution,
deﬁned on the lattice points, logconcave. One way is to write up (2.6) for
vectors with integer components i, j, n. Similar deﬁnition is possible for
-concavity (see, e.g., Dentcheva et al. (2000)). However, there is no general
theorem that would infer from logconcavity or -concavity of the probability
function to the same property of the distribution function, say.
Still, there is one deﬁnition of discrete logconcavity which enables us to
enunciate some results.
Deﬁnition 2.6. The multivariate discrete distribution p(k) deﬁned on the lattice
points of Rn is said to be logconcave if there exists a logconcave function f(x),
x 2 Rn such that p(k) ¼ f(k) for any lattice point k of Rn.
Our assertion concerns trinomial distributions on the nonnegative lattice
points of R2. A triangular distribution is the distribution of a sum of
independent bivariate random variables 1, . . . , r where the support of each i
is {(0, 0), (0, 1), (1, 0)} but their distributions may be diﬀerent. The following
theorem holds true.
Theorem 2.13. Any triangular distribution is logconcave and the convolution of
two triangular distributions is logconcave.
The second assertion follows from the ﬁrst one because the sum of two
triangularly distributed random vectors is also triangularly distributed.
2.4
Applications to stochastic programming and other convexity statements
Theorem 2.5 and 2.11 give direct answers to the convexity questions that
arise in connection with problems (1.2) and (1.4). Recall that a nonlinear
programming problem is said to be convex if the set of feasible solutions is
convex and the objective function to be minimized is convex (or to be
maximized is concave).
280
A. Pre´kopa

Any logconcave function is quasi-concave, hence if  2 Rq has a continuous
distribution and logconcave density or a density which is  1
q-concave
then h0(x) in problem (1.2) is quasi-concave. Hence, h0(x) allows for the
convex programming property of problem (1.2). If h is convex and we assume
that h1, . . . , hm are quasi-concave, then the problem is in fact convex.
As regards problem (1.4), if  2 Rq has logconcave probability density
function, then the objective function is logconcave. The function can be
replaced by its logarithm, without changing the problem, and then it allows
for a convex programming problem. To have a convex problem, the functions
h1, . . . , hm have to be quasi-concave.
Problem (1.3) and the problem
max PðTx  Þ
subject to
Ax  b, x  0
ð2:7Þ
are special cases of problems (1.2) and (1.4), respectively, so the convexity of
these problems can be derived from the above discussion.
It is noteworthy, however, that if F(z) ¼ P(  z) is the distribution function
of the random vector  which is assumed to have continuous distribution and
logconcave density, then, by Theorem 2.3, F(z) is a logconcave function. This
implies that F(Tx) is a logconcave function of x 2 Rn, and thus, the constraint
PðTx  Þ ¼ FðTxÞ  p
determines a convex set of x vectors for any ﬁxed p. Also, the objective
function of problem (2.7) is logconcave.
There are practical problems where the random vector  in problem (1.3)
has a probability distribution which is a mixture of logconcave distributions.
Since logconcavity does not carry over from terms to sums, we may need the
stronger concavity property of the probability distributions involved, in order
to obtain convex nonlinear programming problems. For the case of the
normal distribution we have the following
Theorem 2.14. Let (z, R) be the n-variate standard normal distribution
function. This function is concave on the set fz j zi 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
n  1
p
, i ¼ 1, . . . , ng.
Some further results can be mentioned in connection with bivariate normal
distributions. First we introduce a notion and mention a general theorem.
Deﬁnition 2.7. Let F(z), z 2 Rn be a probability distribution function,
where the variables are partitioned as z ¼ (xT, yT)T. Suppose that x, y have
k1 and k2 components, respectively, 1  k1, k2  n1. We say that F(x, y) is
Ch. 5. Probabilistic Programming
281

concave with respect to x in the positive direction on the convex set E  Rn, if
for any pair
z1 ¼
x1
y1


2 E,
z2 ¼
x2
y2


2 E
for which x1  x2, the function F is concave on the line segment connecting
z1 and z2.
Theorem
2.15. If
F(z)
is
concave
in
the
positive
direction
in
a
closed n-dimensional interval E, with respect to any subset of its variables
having at most n1 elements, then F is quasi-concave in all variables in the same
interval E.
Let (z1, z2; %) be the bivariate standard normal probability distribution
function. It is easy to see that
@2ðz1, z2; %Þ
@z2
1
¼  z2  %z1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  %2
p
 
!
%
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  %2
p
’ðz1Þ   z2  %z1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  %2
p
 
!
z1’ðz1Þ
and a similar formula holds for the second derivative with respect to z2, where
’(z) is the univariate standard normal probability density function. If %  0
and E ¼ {z j z1  0, z2  0}, then (z1, z2; %) is concave on E with respect to any
of the variables z1, z2. Hence, by Theorem 2.15, we have
Theorem 2.16. If %  0, then (z1, z2; %) is concave in the positive direction and
it is quasi-concave in E.
For the case of the non-positive correlation we have
Theorem 2.17. If %  0, then the function (z1, z2; %) is concave in each
variable on
E ¼
z j zi 
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
’ð1Þ
2ð1Þ þ ’ð1Þ
s
¼ 0:346,
i ¼ 1, 2
(
)
:
Also, the function is quasi-concave on E.
If % ¼ 0 or % ¼ 1, then (z1, z2; %) is easily seen to be a concave function on
the nonnegative orthant.
282
A. Pre´kopa

The conditional expectation constraints (1.6) can easily be converted into
equivalent
linear
constraints
if
the
random
variables
1,. . . , r
have
(individually) continuous distributions and logconcave density functions.
Let r ¼ 1 for the sake of simplicity. This case already captures the result in this
respect. First we mention
Theorem 2.18. If  is a univariate random variable that has continuous
distribution and logconcave density function, then
gðzÞ ¼ Eð  z j   z > 0Þ
ð2:8Þ
is a decreasing function of z.
Proof. If P(z>0) ¼ 0, then the conditional expectation (2.8) is 0, by
deﬁnition. Let P(z>0)>0. If F(z) ¼ P(  z) is the probability distribution
function of , then
gðzÞ ¼ Eð  z j   z > 0Þ ¼
Z 1
z
ð1  FðtÞÞ dt
1  FðzÞ
¼
1
d
dz log
Z 1
z
ð1  FðtÞÞ dt
:
ð2:9Þ
By Theorem 2.4, 1F(t) is a logconcave function and the same theorem
implies that
Z 1
z
ð1  FðtÞÞ dt
is also logconcave. This already implies that (2.9) is a decreasing function.
u
The constraint
gðTxÞ ¼ Eð  Tx j   Tx > 0Þ  d
can be written in the equivalent form:
Tx  g1ðdÞ
which is a linear one.
Ch. 5. Probabilistic Programming
283

So far we have looked at stochastic programming problems where random
variables appear only on the right hand sides of the constraints. Now we turn
our attention to stochastic constraints where there are random variables also
in the technology matrix. We state some results for the case where the random
variables have joint normal or related distribution.
One of the most interesting case is connected with Kataoka’s model that
has important applications in ﬁnance, among others:
max d
subject to
P
X
n
i¼1
ixi  d
 
!
 p
X
n
i¼1
xi ¼ M, x  0
ð2:10Þ
We assume that  ¼ (1,. . . , n)T has an n-variate (nondegenerate or degenerate)
normal distribution with
i ¼ EðiÞ,
i ¼ 1, . . . , n,  ¼ ð1, . . . , nÞT
C ¼ E½ð  Þð  ÞT:
Problem (2.10) can be converted into a problem that turns out to be convex
provided that p  1=2. Note that p and M are constants and the decision
variables are x1, . . . , xn, d. Since E(x) ¼ Tx, Var(Tx) ¼ xTCx, if for an x we
have xTCx>0, then
PðTx  dÞ ¼ P ð  ÞTx
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p
 d  Tx
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p


¼ 1   d  Tx
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p


,
hence the probabilistic constraint in (2.10) is equivalent to
Tx þ 1ð1  pÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p
 d:
284
A. Pre´kopa

If, on the other hand, xTCx ¼ 0, then the above constraint is also equivalent to
the probabilistic constraint. This implies that (2.10) can be written in the
equivalent form:
max Tx þ 1ð1  pÞ
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p
n
o
subject to
X
n
i¼1
xi ¼ M,
x  0:
ð2:11Þ
Since C is a positive semideﬁnite matrix, the function
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
xTCx
p
is convex. On
the other hand, p  1
2, hence 1(1p)  0 and (2.11) turns out to be a convex
programming problem.
Few convexity results are known for the case where randomness is in the
technology matrix and the number of constraints is more than one. We take
the stochastic constraints in the form Tx  0, where T is an r  n random
matrix and consider the set of x 2 Rn vectors that satisfy the probabilistic
constraint
PðTx  0Þ  p:
ð2:12Þ
If the original stochastic constraint is of the form Tx  , where  may be
constant or random, then we introduce the new matrix (T, ) and the new
decision vector (xT, xn þ 1)T. The set of x vectors satisfying
PðTx  Þ  p
ð2:13Þ
is the same as those, satisfying
P ðT,  Þ
x
xnþ1




 0


 p
xnþ1 ¼ 1:
ð2:14Þ
The constraint in the ﬁrst line of (2.14) is already of the form (2.12) and the
second constraint determines a convex set of the decision vectors. Hence, a
statement for the constraint (2.12) can easily be carried over to the constraint
(2.13). Let Ti* and T*j designate the ith row and the jth column of T,
respectively. Let further i* and *j designate the corresponding expectation
vectors.
Ch. 5. Probabilistic Programming
285

Theorem 2.19. Suppose that the entries of T have a joint normal distribution and
for the cross-covariance matrices of the columns of T we have that
E½ðT*j  *jÞðT*k  *kÞT ¼ sjkC,
where C is a ﬁxed covariance matrix and the sjk ¼ skj, j, k ¼ 1,. . . , n are con-
stants, then the set of x vectors satisfying (2.12) is convex, provided that p  1
2.
If there is just one random column in T, then the above condition is clearly
satisﬁed.
Theorem 2.20. Suppose that the entries of T have a joint normal distribution and
for the cross-covariance matrices of the rows of T we have that
E½ðTi*  i*ÞTðTk*  k*Þ ¼ sikC,
where C is a ﬁxed covariance matrix and the sik ¼ ski, i, k ¼ 1, . . . , r, then the set
of x vectors satisfying (2.12) is convex.
In our last convexity theorem we assume that the random entries in T are
nonnegative and are lognormally distributed. While in Theorems 2.19 and
2.20 it is unimportant if we write up the stochastic constraint in the form
Tx  0 or Tx  0, because the entries of T have joint normal distribution iﬀthe
same holds for their negatives, in the next theorem it is otherwise. The result is
stated for the probabilistic constraint
GðxÞ ¼ PðTx  dÞ  p,
ð2:15Þ
where d is a constant vector.
Theorem 2.21. Suppose that the random entries ti,k, (i, k) 2 I, of the matrix T
are positive valued and the joint probability distribution of ik ¼ log tik, (i, k) 2 I
is logconcave. Assume, for the sake of simplicity, that the random entries of T
are in the ﬁrst s columns and that all non-random entries of T in these columns
are nonnegative.
Under these conditions the function
Gðex1, . . . , exs, xsþ1, . . . , xnÞ
is logconcave in x 2 Rn.
The above theorem tells us that if we replace exi for xi, i ¼ 1, . . . , s in the
probabilistic constraint (2.15), then the set of x ¼ (x1, . . . , xs, xs þ 1, . . . , xn)T
vectors that satisfy this new form of the constraint is convex.
286
A. Pre´kopa

2.5
Bibliographical notes
The notion of a logconcave measure was introduced in Pre´ kopa (1971),
where also Theorem 2.1 and its simple consequences (Theorems 2.2–2.4) were
also proved. Theorems 2.5 was proved in Pre´ kopa (1972a, 1973c) for the case of
concave gi(x, y), i ¼ 1, . . . , r. Tamm (1977) has observed that in the proof it is
enough to assume that these functions are quasi-concave. Theorem 2.6 is from
Davidovich et al. (1969) and Pre´ kopa (1973b). Borell (1975) and Brascamp and
Lieb (1976) introduced the -concave measures (as generalizations of
logconcave measures) and proved Theorem 2.9 and its special case Theorem
2.10. Theorem 2.11 can be proved in the same way as Theorem 2.5. It is
mentioned in Pre´ kopa (1995). Theorem 2.8 is a simple consequence of the
logconcavity inequality written up for the probability measure associated with
the random vector . The logconcavity of the distributions in Examples (1)–(5)
in Section 2.2 were shown in Pre´ kopa (1971). Borell (1975) has shown the
quasi-concavity of the probability distributions in Examples (6)–(7) of the same
section. The gamma distribution in Example (8) is from Pre´ kopa and Sza´ ntai
(1978a). The posynomial distribution in Example (9) is from Pre´ kopa (1988).
Theorem 2.12 is due to Fekete (see Fekete and Po´ lya (1912)). The notion of
a discrete multivariate logconcave distribution (Deﬁnition 2.6) is due to
Barndorﬀ–Nielsen (1973). Theorem 2.13 is due to Pedersen (1975).
Theorem 2.14 was proved in Pre´ kopa (2001). Theorems 2.15–2.17 are taken
from Pre´ kopa (1970). Theorem 2.18 has been known in reliability theory and
actuarial science, where the value g(z) is called expected residual lifetime and
remaining life, respectively. In the stochastic programming context Pre´ kopa
(1973a) has mentioned it ﬁrst.
The model (2.10) and its equivalent (2.11) was introduced, independently,
by Kataoka (1963) and van de Panne and Popp (1963). The last mentioned
paper applies it to an animal feed problem while the ﬁrst one to ﬁnance.
Theorems 2.19 and 2.21 are from Pre´ kopa (1974). A special case of Theorem
2.20, assuming the rows of T to be stochastically independent, was proved in
the same paper. Its present generality is due to Burkauskas (1986).
3
Numerical solution of probabilistic constrained stochastic
programming problems
3.1
The case of continuously distributed random variable
We will consider the following special cases of problems (1.2) and (1.4):
min hðxÞ
subject to
GðxÞ ¼ PðTx  Þ  p
Ax ¼ b, x  0,
ð3:1Þ
Ch. 5. Probabilistic Programming
287

max GðxÞ ¼ PðTx  Þ
subject to
Ax ¼ b
x  0:
ð3:2Þ
The methods that we describe in this section apply to more general
problems too. However, we restrict ourselves to problems (3.1) and (3.2)
because these are the problems which can be solved by existing codes.
There are two separate issues to solve these problems: (1) to adapt or create a
nonlinear programming technique and (2) to adapt or develop a suitable
method to compute the values and gradients (if necessary) of the function G(x).
First we concentrate on issue (1). However, we remark that if  has logconcave
probability density function then both problems (3.1) and (3.2) are convex.
The method of feasible directions
Historically it was the ﬁrst technique to solve problem (3.1). The method
can be described as follows. Assuming that an initial feasible solution x has
been found, the method works as follows. Let x0 ¼ x.
Step 1. Solve the following direction ﬁnding problem:
Minimize z
subject to
rhðxkÞðx  xkÞ  z  0
rGðxkÞðx  xkÞ þ z  0,
if GðxkÞ ¼ p
Ax ¼ b
x  0,
ð3:3Þ
where  is a positive constant, ﬁxed throughout the procedure. Let
(zopt, x*) be an optimal solution of problem (3.3). If zopt ¼ 0 then x* is an
optimal solution of problem (3.1). If zopt>0 then go to Step 2.
Step 2. Solve the steplength determining problem:
max 
subject to
  0
and
xk þ ðx*  xkÞ
is feasible:
ð3:4Þ
Go to Step 1.
The convergence of this procedure was proved by Pre´ kopa (1970) under the
following conditions: h, G are quasi-concave and have continuous gradients;
288
A. Pre´kopa

there exists an x0 such that G(x0)>p (Slater’s condition); the set {x j Ax ¼ b,
x  0} is bounded.
To ﬁnd an initial feasible solution we may use a simple gradient method to
maximize G(x) subject to the constraints Ax ¼ b, x  0. It is needless to carry
out the whole procedure, we may stop when an x0 is encountered that satisﬁes
G(x0)>p.
The advantage of this method, when solving problem (3.1), is that it
provides us with a possibility to handle the determination and use of G(x) as
well as rG(x) in a stable manner. The eﬀect of noise when these values are
approximated by simulation or bounding methods, can be controlled and, if
the result is not satisfactory, the sample size can be increased or the bounds
can be improved. This remark applies to all other solution methods too, that
we present here concerning problem (3.1).
The Logarithmic Barrier Function Method (SUMT)
If G(x) is a logconcave function in Rn then so is G(x)p on the set
{x j G(x)  p}. This fact suggests the application of the Sequential Uncon-
strained Minimization Technique (SUMT) to solve problem (3.1).
The method works in such a way that we take a sequence of positive
numbers {sk} such that sk>sk þ 1, k ¼ 0, 1,. . . ,
lim
k!1sk ¼ 0 and solve the
problem
min fhðxÞ  sk logðGðxÞ  pÞg
subject to
Ax ¼ b
x  0,
ð3:5Þ
in principle for each k. If xk is an optimal solution of (3.5) then, under some
conditions, we have that
lim
k!1 hðxkÞ ¼
min
GðxÞ  p
Ax ¼ b, x  0
hðxÞ:
ð3:6Þ
The conditions are satisﬁed if h is a continuous, convex and G is a continuous
logconcave
function;
G(x0)>p
for
some
x0 2 {x j Ax ¼ b,
x  0}
and
{x j Ax ¼ b, x  0} is a bounded set. Under these conditions the objective
function in problem (3.5) is convex for any s. For a more general convergence
Ch. 5. Probabilistic Programming
289

theory of the SUMT method we refer to the book by Fiacco and McCormick
(1968).
The supporting hyperplane method
It is assumed that h, G are quasi-concave and have continuous gradients;
there exists a vector x0 such that G(x0)>p, x0 2 {x j Ax ¼ b, x  0}; there exists
a bounded convex polyhedron K1 containing the set of feasible solutions of
problem (3.1).
In a ﬁrst phase we ﬁnd a feasible x0 satisfying Slater’s condition. This can
be done by maximizing G(x) subject to Ax  b, x  0, by use of the method
described below. The second phase consists of the following steps.
Step 1. Solve the problem:
min hðxÞ
subject to
x 2 Ks:
ð3:7Þ
Let xs be an optimal solution. If xs is feasible, then Stop, xs is an optimal
solution of problem (3.1). Otherwise, go to Step 2.
Step 2. Let s be the largest   0 such that x0 þ (xsx0) is feasible and
ys ¼ x0 þ sðxs  x0Þ:
Choose any constraint that is satisﬁed with equality sign for ys. If it is
G( ys) ¼ p, then we deﬁne
Ksþ1 ¼ fx j x 2 Ks, rGð ysÞðx  ysÞ  0g:
If it is a linear constraint then Ks þ 1 is deﬁned as the intersection of Ks and the
set determined by this linear constraint. Go to Step 1.
The reduced gradient method
Let hðxÞ ¼ cTx in problem (3.1) that we intend to solve. We assume that
GðxÞ is logconcave, rGðxÞ is Lipschitz-continuous, Slater’s condition holds
and the set of feasible solutions is bounded.
In the kth iteration we are given a feasible xk, a tolerance "k, the
partitioning xk ¼ ð yk, zkÞ, A ¼ ðB, RÞ, c ¼ ðcB, cRÞ, where B is a nonsingular
square matrix and ð ykÞj  1 for all j. We perform the following steps.
290
A. Pre´kopa

Step 1. Solve the direction ﬁnding problem
min t
subject to
cT
Bu þ cT
Rv  t
rGðxkÞu þ rGðxkÞv  t,
if GðxkÞ  p þ "k
Bu þ Rv ¼ 0
vj  0
if zj  "k
vj  1
all j,
ð3:8Þ
where u, v and t are the decision variables and  is a positive constant. An
equivalent form of this problem is
min t
subject to
rTv  t
sTv  t,
if GðxkÞ  p þ "k
vj  0
if zj  "k
vj  1
all j,
ð3:9Þ
where r ¼ cR  cT
BB1R and s ¼ rzGðxkÞ  ryGðxkÞB1R are the reduced
gradients of the objective function and the probabilistic constraint,
respectively. Let (v*, t*) be an optimal solution of problem (3.9). There
are two cases.
Case 1. We have t* > "k. Then we compute u* ¼ B1Rv* and go to Step 2.
Case 2. We have t*  "k. Then "k is halved. If the new "k is smaller than a
zero tolerance then we accept xk as optimal solution. Otherwise we solve
problem (3.8) with the new "k and go to Step 2.
Step 2. Let 1 be the largest   0 such that xk þ w* satisﬁes the linear
constraints, where w* ¼ ðu*, v*Þ. Let 2 be any  satisfying
p  Gðxk þ w*Þ  p þ "k
and * ¼ minð1, 2Þ. Deﬁne xkþ1 ¼ xk þ *w* and go to Step 3.
Step 3. If ð ykþ1Þj  "k for some j then the nondegeneracy assumption is
violated. Find a new partition for which the nondegeneracy assumption
holds. If necessary, reduce "k to meet this assumption. Go to Step 1.
Ch. 5. Probabilistic Programming
291

A primal–dual method
A primal–dual method has been developed to solve the following problem
min cTx
subject to
Fð yÞ  p
Tx  y
Dx  d,
ð3:10Þ
where F is the probability distribution function of the random vector n:
Fð yÞ ¼ Pðn  yÞ. Problem (3.10) comes from the problem
min cTx
subject to
PðTx  nÞ  p
Dx  d,
ð3:11Þ
to which it is equivalent. Let x 2 Rn, y 2 Rr and suppose F is a strictly
logconcave probability distribution function, i.e., for every pair y1, y2 2 Rr,
y1 6¼ y2, and 0 <  < 1, we have
Fðy1 þ ð1  Þy2Þ > ½Fð y1Þ½Fð y2Þ1:
The advantage of problem (3.10) over problem (3.11) is that the probabilistic
constraint involves only the probability distribution function of n and not the
composite function FðTxÞ.
Starting to solve problem (3.10) we associate with it a dual problem
max
min
FðyÞp uTy þ vTd


subject to
TTu þ DTv ¼ c
u  0, v  0:
ð3:12Þ
The procedure works in the following manner. First we assume that a pair of
vectors ðuð1Þ, vð1ÞÞ is available, for which
uð1Þ, vð1Þ

 2 V ¼ ðu, vÞ j TTu þ DTv ¼ c, v  0

	:
292
A. Pre´kopa

Suppose that ðuðkÞ, vðkÞÞ has already been chosen where uðkÞ  0. Then we
perform the following steps.
Step 1. Solve the problem
minðuðkÞÞTy
subject to
Fð yÞ  p:
ð3:13Þ
Let yðuðkÞÞ designate the optimal solution. Then we solve the direction ﬁnding
problem
max uTyðuðkÞÞ þ dTv

	
subject to
ðu, vÞ 2 V:
ð3:14Þ
Let ðu*k, v*kÞ be an optimal solution to this problem. If u*k ¼ %uðkÞ then ðu*k, v*kÞ
is an optimal solution of the dual problem (3.12) is an optimal solution to
the primal problem (3.10), where ^x is an optimal solution of the LP:
min cTx
subject to
Tx  yðuðkÞÞ
Dx  d:
Otherwise, go to Step 2.
Step 2. Find ðkÞ ð0 <  < 1Þ satisfying
u*k

Ty
ðkÞ
1  ðkÞ uðkÞ þ u*k


> uðkÞ

Ty uðkÞ


þ vðkÞ

Td:
Then we deﬁne
uðkþ1Þ ¼ ðkÞuðkÞ þ ð1  ðkÞÞu*k
vðkþ1Þ ¼ ðkÞvðkÞ þ ð1  ðkÞÞv*
k:
Ch. 5. Probabilistic Programming
293

If the procedure is inﬁnite, then the sequence ðuðkÞ, vðkÞÞ converges and the
limiting pair has the same property as ðu*k, v*kÞ in Step 1.
A primal–dual interior point algorithm
If we look at problem (1.2), where hðxÞ is assumed to be convex, h0ðxÞ
logconcave, and h1ðxÞ, . . . , hmðxÞ concave or logconcave, then the barrier
function
hðxÞ  
X
m
i¼0
log hiðxÞ
ð3:15Þ
is a convex function for any ﬁxed  > 0.
Function (3.15) is the classical Fiacco McCormick logarithmic barrier
function in connection with which usually three problems arise: the convexity
of the function, ﬁnding an initial feasible solution, and the ill-conditioning of
the Hessian matrix. In our case the barrier function is convex, under general
assumptions, an initial feasible solution can frequently be found by using the
probabilistic nature of the problem. If this is not the case, we would maximize
h0ðxÞ subject to all remaining constraints, until a point x, with h0ðxÞ > 0 is
found.
We introduce slack variables and rewrite (1.2) as
min hðxÞ
hiðxÞ  wi ¼ 0
wi  0,
i ¼ 0, 1, . . . , m:
The next step is to eliminate the inequalities wi  0 by the introduction of
logarithmic barrier terms to the objective function. This yields the problem
min
hðxÞ  
X
m
i¼0
log wi
"
#
subject to
hiðxÞ  wi ¼ 0,
wi >
¼ 0,
i ¼ 0, 1, . . . , m:
Then we take the Lagrangian
Lðx, w, y, Þ ¼ hðxÞ  
X
m
i¼0
log wi 
X
m
i¼0
yiðhiðxÞ  wiÞ,
294
A. Pre´kopa

write up the ﬁrst order KKT conditions and the method is essentially
an iterative solution method for these equations, based on Newton’s method.
The search directions x, y, z are determined by the system of linear
equations
Hðx, yÞ
0
ATðxÞ
0
W1Y
I
AðxÞ
I
0
0
BB@
1
CCA
x
w
y
0
B@
1
CA ¼


%
0
B@
1
CA,
where
Hðx, yÞ ¼ r2hðxÞ 
X
m
i¼0
yi r2hiðxÞ
AðxÞ ¼
rh0ðxÞ
..
.
rhmðxÞ
0
BBB@
1
CCCA
 ¼ rhðxÞ  ATðxÞy,
W is the diagonal matrix with w0, . . . , wm in the main diagonal,  ¼ W1e
y, % ¼ ð%0, . . . , %mÞT, %i ¼ wi  hiðxÞ, i ¼ 0, . . . , m, and e is the vector with all
components equal to one.
Starting from an initial x0, w0, y0, we proceed through a sequence of points:
xkþ1 ¼ xk þ k xk,
wkþ1 ¼ wk þ k wk,
ykþ1 ¼ yk þ k yk,
where xk, wk and yk are the subsequent search directions.
The above algorithm proved to be very eﬃcient on a large number of
problems.
In the next two methods we present not only problem solving algorithms
but, simultaneously, the estimation of the probabilities involved.
Ch. 5. Probabilistic Programming
295

Solution of the probabilistic constrained problem by the use of nonparametric
estimates of distribution functions
We look at the problem
min cTx
subject to
PðTx  Þ  p
Ax ¼ b
x  0,
ð3:16Þ
where we assume that the random variables 1, . . . , r are independent and
each has continuous distribution. If we introduce the notations FiðzÞ ¼
Pði  zÞ, i ¼ 1, . . . , r, Tx ¼ y, then problem (3.16) has the equivalent form:
min cTx
subject to
Y
r
i¼1
ð1  Fið yiÞÞ  p
Tix ¼ yi,
i ¼ 1, . . . , r
Ax ¼ b
x  0:
ð3:17Þ
The method works with the hazard rate functions deﬁned by
giðtÞ ¼
fiðtÞ
1  FiðtÞ
ð3:18Þ
if FiðtÞ < 1 and giðtÞ ¼ 0 if FiðtÞ ¼ 1, i ¼ 1, . . . , r, where fiðtÞ is the probability
density function corresponding to FiðtÞ, i ¼ 1, . . . , r.
Assume that the functions fiðtÞ, i ¼ 1, . . . , r are logconcave. Then, by
Theorem 2.4 the functions 1  FiðtÞ, i ¼ 1, . . . , r are also logconcave. If, in
addition, we assume that for any x, y1, . . . , yr, satisfying the last three
constraints in (3.17), we have FiðyiÞ < 1, i ¼ 1, . . . , r, then we can take
logarithm on both sides in the ﬁrst constraint.
The logconcavity of 1  FiðtÞ implies that giðtÞ is a decreasing function.
Integrating (3.18) we obtain
1  FiðyiÞ ¼ e

Zyi
1
giðtÞ dt
:
296
A. Pre´kopa

We estimate the functions giðtÞ from samples.
Let gðnÞ
i
denote an original estimator of gi for a given n. We take a sample
ni
f
g from the population with distribution function Fi, and create a grid
tn,1 < tn,2 < . . . < tn,N. The grid may depend on i but we suppress it, for the
sake of simplicity. The original estimator gðnÞ
i
can then be deﬁned as
gðnÞ
i ðtÞ ¼
FðnÞ
i ðtn, jþ1Þ  FðnÞ
i ðtn, jÞ
ðtn, jþ1  tn, jÞð1  FðnÞ
i ðtn, jÞÞ
,
tn, j < x  tn, jþ1,
where
FðnÞ
i
is
the
empirical
distribution
function
corresponding
to
Fi, i ¼ 1, . . . , r.
The next step is to choose a point xn, j from the window ðtn,j, tn, jþ1 and
assign a weight to it: wðxn, jÞ. Then solve the problem
inf
Uj increasing
X
N
j¼1
Uj  gðnÞ
i ðxn, jÞ

2
wðxn, jÞ:
Let ^gðnÞ
i ðxn, jÞ be the optimal solution and assign this value to each element
of the window ðtn, j, tnþ1, j. Then
^gðnÞ
i
is a nondecreasing step function
approximating gðnÞ
i
in the least square sense. Now our approximation to
1  FiðyiÞ is
1  ^FðnÞ
i ðyiÞ ¼ e

Zyi
1
^gðnÞ
i ðtÞ dt
:
This estimate has several good properties.
It remains to show how this estimate can be used to solve problem (3.17).
Since
log
1  ^FðnÞ
i ð yiÞ


¼ 
Zyi
1
^gðnÞ
i ðtÞ dt,
this function is piecewise linear and concave. Assume that the function
consists of a ﬁnite number of linear pieces, the equations of which are
aT
ij y þ bij,
j ¼ 1, . . . , Ji,
i ¼ 1, . . . , r:
Ch. 5. Probabilistic Programming
297

The problem (3.17) is equivalent to the following LP:
min cTx
subject to
yi  aT
ij y þ bij,
j ¼ 1, . . . , Ji
Tix ¼ yi,
i ¼ 1, . . . , r
Ax ¼ b
x  0:
Solution by a regression method
We solve problem (1.2) under the following conditions: the random vector 
has continuous distribution and logconcave density; g1, . . . , gr are concave or
quasi-concave functions; the other constraints are linear that we write in the
form Ax ¼ b, x  0; the objective function is linear: hðxÞ ¼ cTx. The method
works under more general assumptions as well but we restrict ourselves to a
relatively simple case.
Under the above assumptions the constraining function
GðxÞ ¼ Pðg1ðx, Þ  0, . . . , grðx, Þ  0Þ
ð3:19Þ
is logconcave in x. We approximate log GðxÞ by a quadratic function
xTDx þ bTx þ c, where xTDx is negative deﬁnite, solve the approximate
problem, take a new feasible point to improve on the approximation,
again solve the problem etc. The function values GðxÞ computed for the
approximation may be noisy, a least square approximation procedure will
eliminate much of the noise. The solution algorithm can be described as
follows.
Step 1. Find x0, . . . , xk1 which are feasible solutions to the problem. Compute
the corresponding values pi ¼ log GiðxÞ, i ¼ 1, . . . , k  1.
Step 2. Let
qkðxÞ ¼ xTDkx þ bT
k x þ ck
be a quadratic function, where Dk, bk, ck are obtained from the least square
approximation
min
X
k1
i¼0
ðpi  qkðxiÞÞ2:
298
A. Pre´kopa

Step 3. Solve the approximate problem
min cTx
subject to
xTDkx þ bT
k x þ ck  log p
Ax ¼ b
x  0:
Let xk be an optimal solution. Suppose that we have a criterion to decide if xk
is ‘‘good enough’’ as a solution to the original problem. In principle the KKT
conditions are the best from this point of view but we may have some other
stopping rule as well, e.g., the optimum values of the approximate problem do
not change signiﬁcantly in several subsequent iterations. Now, if xk is ‘‘good
enough’’, then stop and accept it as optimal solution to the original problem.
Otherwise let k  k þ 1 and go to Step 2.
3.2
The case of discrete distribution
We look at problem (1.3), where we assume that the random vector  has
discrete distribution. First we formulate the deﬁnition of a p-level eﬃcient
point (or PLEP). Let F designate the distribution function of .
Deﬁnition 3.1. A point z 2 Rr is said to be a p-level eﬃcient point of the
probability distribution F, if FðzÞ  p and there is no y such that
y  z, y 6¼ z, Fð yÞ  p.
If r ¼ 1, then for any p 2 ð0, 1Þ there exists exactly one p-level eﬃcient
point. Sometimes we need p-level eﬃcient points deﬁned in connection with
functions obtained from a distribution function by holding some of the
variables ﬁxed. This is the case, e.g., in the forthcoming enumeration
algorithm. Deﬁnition 3.1 extends in a trivial way to this case. We have the
following
Theorem 3.1. If the components of the random vector  are integer-valued, then
for any p 2 ð0,1Þ the set of p-level eﬃcient points is nonempty and ﬁnite. The set
of p-level eﬃcient points serves as the p-quantile of the probability distribution
determined by F.
From the practical point of view we may restrict ourselves to the case where
the distribution has a ﬁnite support. We do not assume, however, that the
support set is part of the integer lattice in Rr.
Ch. 5. Probabilistic Programming
299

Let Zi ¼ fzi0, . . . , zikiþ1g be the set of possible values of i, i ¼ 1, . . . , r and
deﬁne the direct product
Z ¼ Z1  . . .  Zr:
ð3:20Þ
The set Z contains all possible values of  but may be somewhat larger than
the set of possible values. Below we present an algorithm to ﬁnd all p-level-
eﬃcient points of the distribution. We remark that any p-level-eﬃcient point is
necessarily an element of Z.
Algorithm to enumerate the p-efficient points
Step 0. Initialize k  0. Go to Step 1.
Step 1. Let
z1, j1 ¼ arg min y j Fðy, z2,k2þ1, . . . , zr,krþ1Þ  p

	
z2, j2 ¼ arg min y j Fðz1, j1, y, . . . , zr,krþ1Þ  p

	
...
zr,jr ¼ arg min y j Fðz1, j1, . . . , zr1, jr1, yÞ  p

	
:
Go to step 2
Step 2. Let E  fz1,j1, . . . , zr,jrg. Go to Step 3.
Step 3. Let k  k þ 1. If j1 þ k > k1 þ 1, then go to Step 5. If j1 þ k  k1 þ 1,
then go to Step 4.
Step 4. Enumerate all p-level-eﬃcient points of the function Fðz1, j1þk, yÞ,
where y 2 Rr1 and eliminate those which dominate at least one element in
E. ( y dominates z, if y  z and y 6¼ z). If H is the set of the remaining
p-level-eﬃcient points, which may be empty, then let E  E [ H. Go to
Step 3.
Step 5. Stop. E is the set of p-level-eﬃcient points of the distribution function F.
Remark. The above algorithm allows for the enumeration of all p-level-
eﬃcient points of functions F which assign probability  1 to the entire space.
Example. Let
r ¼ 2, Z1 ¼ Z2 ¼ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9
f
g, pik ¼ 0:019
if
0 
i  4, 0  k  5
or
k ¼ 8, 9;
pik ¼ 0:038
if
0  i  4, k ¼ 6;
pik ¼ 0
if
0  i  4, k ¼ 7; pik ¼ 0:001 if 5  i  9, 0  k  9 and p ¼ 0:6. In Step 1
we obtain
3 ¼ arg min y j Fðy, 9Þ  0:6

	
6 ¼ arg min y j Fð3, yÞ  0:6

	:
300
A. Pre´kopa

Thus, ðz1, j1, z2, j2Þ ¼ ð3, 6Þ and at Step 2 we have k ¼ 0, E ¼ ð3, 6Þ

	
. In Step 3
we take k ¼ 4 and go to Step 4, where we obtain H ¼ ð4, 6Þ

	. We eliminate
(4, 6) and E ¼ ð3, 6Þ

	
. Now we go to Step 3 and ﬁnd H empty for
k ¼ 2, 3, 4, 5. In case of k ¼ 6 we obtain H ¼ ð9, 5Þ

	
and the algorithm
terminates. The result is E ¼ ð3, 6Þ, ð9, 5Þ

	
.
Cutting plane method for the solution of problem (1.3) with discrete
random vector 
We assume that the support of  is Z, given by (3.20), or a part of it. Let
zð1Þ, . . . , zðNÞ designate the p-level-eﬃcient points of the distribution F and
suppose that we have already enumerated them. Problem (1.3) is equivalent to
the disjunctive programming problem:
min cTx
subject to
Tx  zðiÞ
for at least one i ¼ 1, . . . , N
Ax ¼ b, x  0:
ð3:21Þ
Problem (3.21) is relaxed as
min cTx
subject to
Tx 
X
N
i¼1
izðiÞ
Ax ¼ b, x  0
X
N
i¼1
i ¼ 1,   0
ð3:22Þ
and we propose an algorithm to solve (3.22). Introducing slack variables the
problem becomes
min cTx
subject to
Tx  u ¼
X
N
i¼1
izðiÞ
Ax ¼ b, x  0
X
N
i¼1
i ¼ 1,
  0, u  0:
ð3:23Þ
Ch. 5. Probabilistic Programming
301

Since the set of p-level eﬃcient points may be concentrated on a manifold with
dimension smaller than r, ﬁrst we determine this manifold. Let
z ¼ 1
N
X
N
i¼1
zðiÞ
and consider the system of linear equations with unknown vector w:
wTðzðiÞ  zÞ ¼ 0,
i ¼ 1, . . . , N:
ð3:24Þ
If w1, . . . , wh is a maximum number of linearly independent vectors
satisfying (3.24), then we append the constraints
wT
l ðTx  uÞ ¼ 0,
l ¼ 1, . . . , h
to the constraints Ax ¼ b and keep them together throughout the procedure.
The steps of the algorithm are the following.
Step 1. Enumerate all the p-level eﬃcient points zð1Þ, . . . , zðNÞ. Initialize k  0
and go to Step 2.
Step 2. Solve the LP:
min cTx
subject to
Ax ¼ b,
wT
l ðTx  uÞ ¼ 0,
l ¼ 1, . . . , h
ðwiÞTðTx  u  zÞ  0,
i ¼ 1, . . . , k
x  0, u  0:
ð3:25Þ
If k ¼ 0 then ignore the cuts, i.e., the constraints in the second to the last
line in (3.25). Let ðxðkÞ, uðkÞÞ be an optimal solution. Go to Step 3.
Step 3. Solve the auxiliary problem
min eT ¼ 
subject to
X
N
i¼1
zðiÞ  z


i ¼ TxðkÞ  uðkÞ  z
  0,
ð3:26Þ
where e ¼ ð1, . . . , 1ÞT and the decision vector is . The solution of (3.26)
needs some care because the matrix of the problem may not have full
302
A. Pre´kopa

row rank. In this case we may use a more general variant of the simplex
method (see Pre´ kopa (1996)) or use a well-known technique involving
artiﬁcial variables.
If   1, then Stop, the current ðxðkÞ, uðkÞÞ is an optimal solution of problem
(3.25). If >1 then go to Step 4.
Step 4. Let zði1Þ  z, . . . , zðirhÞ  z be an optimal basis to the problem (3.26).
Then ﬁnd a w satisfying
wTwi ¼ 0,
i ¼ 1, . . . , h
wTðzðijÞ  zði1ÞÞ ¼ 0,
j ¼ 2, . . . , r  h:
These r  1 equations determine w up to a constant factor. Assume that we
have determined w in such a way that
wT TxðkÞ  uðkÞ  z


< 0:
Then deﬁne wkþ1 ¼ w and introduce the cut
wkþ1

TðTx  u  zÞ  0:
Set k  k þ 1 and go to Step 2.
The ﬁniteness of the above algorithm is guaranteed if fzðiÞ, i ¼ 1, . . . , Ng is a
discrete convex set, i.e., zð jÞ 62 riconvfzðiÞ, i ¼ 1, . . . , Ng, j ¼ 1, . . . , N.
The cone generation method
The method solves problem (3.22). Before presenting it we introduce the
notion of a discrete -concave function. In Section 2 we already introduced
this notion in connection with functions deﬁned on the entire r-space and
stated in Theorem 2.9 that if the probability measure is generated by an -
concave density function, then the measure is -concave in the sense of
Deﬁnition 2.4, where  ¼ =ð1 þ rÞ. As we have remarked in Section 2, there
is no discrete counterpart of this theorem. Still, the notion of -concavity
can be deﬁned in connection with a function deﬁned on the integer lattice of
the r-space.
Deﬁnition 3.2. The function f ðzÞ  0, deﬁned on the integer lattice of the
r-space is said to be -concave if for any integer component vectors x, y, z
and 0 <  < 1 such that f ðxÞ > 0, f ð yÞ > 0, z  x þ ð1  Þy, we have the
inequality
f ðx þ ð1  ÞyÞ  ½f ðxÞ þ ð1  Þf ð yÞ1=,
ð3:27Þ
Ch. 5. Probabilistic Programming
303

where 1   < 1; for  ¼ 1,  ¼ 0 the expression in (3.27) is deﬁned by
continuity in the same way as we have deﬁned it in Deﬁnition 2.3.
If a function is -concave in the entire r-space, then it is -concave on the
integer lattice of the same space.
Assume that the probability distribution function FðzÞ ¼ Pð  zÞ, z 2 Rr is
-concave on the integer lattice of the space. Let
Zp ¼ fz 2 Rr j FðzÞ  pg:
Then we have the relation (for the proof see Dentcheva et al. (2000))
Zp \ Zr
þ ¼ conv ðZpÞ \ Zr
þ,
ð3:28Þ
where Zr
þ is the nonnegative orthant of the r-space, Zr
þ ¼ fz 2 Zr j z  0g.
Relation (3.28) gives some information regarding the relationship of
problems (3.21) and (3.22). Equivalence between the two problems, however,
can be stated only if further information is available. If, for example x is also
restricted to be integer and the matrix T has integer entries, then, by (3.28), the
two problems are equivalent.
The cone generation method consists of the following steps.
Step 1. Find a p-level eﬃcient point z(1) and set I1 ¼ f1g, k ¼ 1.
Step 2. Solve the master problem
min cTx
subject to
Tx 
X
i2Ik
izðiÞ
Ax ¼ b, x  0
X
i2Ik
i ¼ 1,   0:
ð3:29Þ
Let uk be the part of the optimal dual vector which is associated with the
ﬁrst part of the constraints.
Step 3. Calculate an upper bound on the value
min
i2Ik ðukÞTzðiÞ:
ð3:30Þ
If for jk 2 Ik we have jk > 0 then ðukÞTzjk is a suitable upper bound on this
value.
Step 4. Find a p-level eﬃcient solution to the problem
min
FðzÞp uk

Tz,
ð3:31Þ
304
A. Pre´kopa

where FðzÞ ¼ Pð  zÞ, z 2 Rr. Let z(k þ 1) designate an optimal solution to this
problem. If the optimal values in (3.31) and (3.30) coincide, then Stop, the
optimal solution of problem (3.29) is an optimal solution to problem (3.22).
Otherwise set Ikþ1  Ik [ fk þ 1g, k  k þ 1 and go to Step 2.
The solution of problem (3.31) may be diﬃcult in the general case.
However, if the random variables 1, . . . , r are independent, there is a simple
way to do the job. We assume that Z is the integer grid of Rr. Let FiðzÞ
designate the probability distribution function of the random variable
i, i ¼ 1, . . . , r. Then the probabilistic constraint FðzÞ  p can be written in
the form
log FðzÞ ¼
X
r
i¼1
log FiðziÞ  log p:
If FðzÞ  p, then we also have FiðziÞ  p, i ¼ 1, . . . , r. This implies that if li is the
p-level eﬃcient point of the distribution function Fi, then zi  li, i ¼ 1, . . . , r: It
follows that problem (3.31) is equivalent to the nonlinear knapsack problem:
min
X
r
i¼1
uizi
subject to
X
r
i¼1
log FiðziÞ  log p
zi  li,
zi
integer,
i ¼ 1, . . . , r:
ð3:32Þ
If bi is a known upper bound on zi, i ¼ 1, . . . , r, then problem (3.32) can be
transformed into the following equivalent 01 variable LP:
min
X
r
i¼1
X
bi
j¼li
juiyi, j
subject to
X
r
i¼1
X
bi
j¼li
log Fið jÞ
ð
Þyi, j  log p
X
bi
j¼li
yi, j ¼ 1,
i ¼ 1, . . . , r
yi, j 2 f0, 1g,
j ¼ li, . . . , bi,
i ¼ 1, . . . , r:
ð3:33Þ
The variable zi in problem (3.32) is replaced by Pbi
j¼li j yi,j in problem (3.33). If
FiðzÞ is the distribution function of a logconcave distribution on the integers
Ch. 5. Probabilistic Programming
305

i ¼ 1, . . . , r, then we introduce zi ¼ li þ Pbi
j¼liþ1 ij, i ¼ 1, . . . , r, where ij are
01 variables. Then we reformulate problem (3.32) as follows:
min
X
r
i¼1
X
bi
j¼liþ1
uiij
subject to
X
r
i¼1
X
bi
j¼liþ1
aijij  q,
ij 2 f0, 1g,
j ¼ li þ 1, . . . , bi, i ¼ 1, . . . , r,
ð3:34Þ
where
aij ¼ log Fið jÞ  log Fið j  1Þ ¼ Pð ¼ jÞ
and
q ¼ log p  log l,
l ¼ ðl1, . . . lrÞT. Problem (3.34) is a knapsack problem, for which many
eﬃcient solution techniques exist.
The advantage of the cone generation method is that problem (3.31) is
separated from the other parts of the problem and, as we have seen, this
problem sometimes has simple solution technique.
A branch and bound method
The method solves problem (1.3) with the additional restriction that x and 
are integers. The matrix T is assumed to have integer entries. As we have
remarked in the discussion of the previous method, under these conditions the
problem
min cTx
subject to
Tx  zðiÞ,
for at least one
i ¼ 1, . . . , n
Ax ¼ b, x  0 integer,
ð3:35Þ
which is the same as problem (3.1) with the integrality restriction on x, is the
same as the problem
min cTx
subject to
Tx 
X
N
i¼1
izðiÞ
Ax ¼ b,
x  0 integer
X
N
i¼1
i ¼ 1,   0:
ð3:36Þ
306
A. Pre´kopa

A new PLEP generation technique is also proposed by the authors. In order to
describe it we need some preparation.
In connection with a vector w satisfying FðwÞ  p for some p 2 ð0, 1Þ we
deﬁne li ¼ liðwÞ to be the p=FðwÞ-level eﬃcient point of the conditional
marginal distribution Fiðzi j   wÞ, i.e.,
liðwÞ ¼ arg min j j Fið j j   wÞ 
p
FðwÞ


,
i ¼ 1, . . . , r:
Let l ¼ lðwÞ designate the vector of components liðwÞ, i ¼ 1, . . . , r. The
following assertions hold true:
(i) for every p-level eﬃcient point v  w we have v  lðwÞ;
(ii) if z  w, then lðzÞ  lðwÞ;
(iii) w is p-level eﬃcient if and only if lðwÞ ¼ w.
To every nonnegative integer component vector z we assign a level
jzj ¼ z1 þ . . . þ zr. We also create a graph out of these points as nodes
and draw a directed arc from v to w if jw j ¼ j v j þ 1 and the two vectors
diﬀer in one component only. There are two variants of the enumeration
technique: the forward and the backward schemes. In the latter one we start at
the highest level candidate, in the former one at the lowest level candidate.
Since p 	 1, the backward algorithm produces the result faster, in general,
therefore we present only that one.
Backward enumeration scheme
Step 0. Let v ¼ ðk1, . . . , krÞ and set k ¼ jvj1, level counter; Sk ¼ ;, the set of
PLEP’s at level k; Ck ¼ f
g, the set of candidate points at level k; J ¼ ;, the
set of all PLEP’s.
Step 1. For each v 2 Ck generate its predecessors and supplement them
to Ck1.
Step 2. For each v 2 Ck1 compute lðvÞ. If lðvÞ ¼ v, move the point from Ck1
to Sk1.
Step 3. Set J ¼ J [ SK1. If Ck1 ¼6 0, Stop. Otherwise decrease k by 1 and go
to Step 1.
In the implementation an important issue is to avoid generating the same
point more than once. Granted, the procedure terminates in a ﬁnite number of
iterations.
In the solution algorithm of the problem we use the value zðl*ðvÞÞ deﬁned by
z l*ðvÞ
ð
Þ ¼ min cTx
subject to
Tx  l*ðvÞ
Ax ¼ b, x  0 integer,
ð3:37Þ
Ch. 5. Probabilistic Programming
307

where l*ðvÞ designates the smallest vector in Z such that l*ðvÞ  lðvÞ. The value
zðl*ðvÞÞ is a lower bound on the optimal values of all predecessors of v.
Let zI designate the best known feasible solution to the problem, at some
point of the algorithm. Then, if zðl*ðvÞÞ  zI, node v can be discarded. If
zðl*ðvÞÞ < zI, then v is either stored as candidate for further use (if the solution
is fractional), or replaces zI (if the solution is integer).
The branch and bound algorithm
Step 0. Let v ¼ ðk1, . . . , krÞ. Compute an initial upper bound zI and set
k ¼ jvj1, level counter; Sk ¼6 0, set of PLEP’s at level k; CK ¼ fvg, set of
candidate points at level k; J ¼6 0, set of all PLEP’s; M ¼6 0, set of PLEP’s
corresponding to integer problems.
Step 1. For each v 2 Ck generate the predecessors and supplement them
to Ck1.
Step 2. For each v 2 Ck1 compute the conditional lower bound lðvÞ on
PLEP’s. If lðvÞ ¼ v, move the point from Ck1 to Sk1.
Step 3. Set J ¼ J [ Sk1. If Ck1 ¼6 0 and Sk1 ¼6 0, Stop. Otherwise decrease
k by 1.
Step 4. For each point v 2 Sk [ Ck solve a relaxation of problem (3.37). Let
xðl*ðvÞÞ be an optimal solution.
(1) If zðl*ðvÞÞ  zI, discard the point v.
(2) If zðl*ðvÞÞ < zI and v 2 Sk, then (I) if xðl*ðvÞÞ is fractional, then
supplement the point v to M; (II) otherwise update zI and remove from
M all points w having worse lower bound values zðl*ðvÞÞ.
If Ck ¼ ;, Stop. Otherwise go to Step 1.
The algorithm terminates in a ﬁnite number of steps. At the end M contains
all PLEP’s corresponding to the integer problem.
As a special case of the above described probabilistic integer programming
problem
the
probabilistic
set
covering
problem
has
been
considered
and solved, where the components of the decision vector x are 01 variables
and the random vector  has 01 components as well. The special structure of
the problem is exploited in the solution algorithm.
Finally, we mention that an algebraic geometry approach has been deve-
loped for the solution of the probabilistic constrained integer programming
problem, where the random variables are also integer valued and are located in
the technology matrix. The method uses Gro¨ bner bases. The description of it
is, however, rather lengthy therefore we disregard its presentation here.
3.3
Bibliographical notes
The method of feasible direction is due to Zoutendijk (1960). Its application
(algorithm P2) to solve probabilistic constrained stochastic programming
problemswasproposedbyPre´ kopa(1970).Dea´ k(1971)implementedit together
with the calculation of multivariate normal distribution function values and
308
A. Pre´kopa

their gradients. Pre´ kopa et al. (1980) applied the developed method for the
solution of an economic problem concerning electrical energy. Problem (1.5)
with normal distribution was also eﬃciently solved by Sza´ ntai (1985). The use
of SUMT (see Fiacco and McCormick (1968) for its general description) for
the same problem was suggested by Pre´ kopa (1972a) and implemented by
Rapcsa´ k (1974). It was ﬁrst applied (in the probabilistic constrained framework)
by Pre´ kopa et al. (1978). Further application is mentioned in Section 7. The
application of a variant of the supporting hyperplane method of Veinott
(1967), to solve problem (1.3) was proposed by Pre´ kopa and Sza´ ntai (1978b).
The solution code, due to Sza´ ntai, is described in his (Sza´ ntai, 1988) paper.
The reduced gradient method, developed by Abadie and Carpentier (1969), was
applied by Mayer (1979, 1980, 1988, 2000) to solve problem (1.3). See also his
summarizing paper (1992) (Mayer (1992)) and book (1998) (Mayer (1998)) .
The paper by Kall and Mayer (1996) presents, among others, the solution of
(1.3), by the use of the reduced gradient method, in a general model management
framework. The next, primal-dual, method is due to Koma´ romi (1986b, 1987).
The primal-dual interior point algorithm is due to Vanderbei and Shanno
(2000). The ill-conditioning in the Hessian can be balanced by a method due to
Nash and Sofer (1993). Other reﬁnement is due to the same authors (1998) (Nash
and Sofer, 1998). It addresses the problem of the infeasibility of a returned .
The method, using nonparametric estimates of the distribution functions,
when in problem (1.3) the random vector  has independent components, is
due to Gro¨ we (1995, 1997). The regression method is due to Dea´ k (2000).
Another approximation method is presented in Salinetti (1983).
The concept of a p-level eﬃcient point PLEP was introduced by Pre´ kopa
(1990a). It is also termed p-eﬃcient point and sometimes abbreviated as PEP.
The algorithm to enumerate the p-level eﬃcient points and the subsequent
cutting plane method is due to Pre´ kopa, Vı´zva´ ri and Badics (1998). The cone
generation method, together with the embedded enumeration of the p-level
eﬃcient points is due to Dentcheva, Pre´ kopa and Ruszczyn´ ski (2000). Vı´zva´ ri
(2002) has revised it from the point of view of integer programming. The next,
branch and bound method and the embedded enumeration technique of the
p-level eﬃcient points is due to Beraldi and Ruszczyn´ ski (2001). They have
another, paper (2002), where they solve a stochastic set covering problem by a
similar method.
The algebraic-geometry method, using Gro¨ bner bases (see Becker and
Weispfenning), is due to Tayur et al. (1995). Inequalities in connection with
probabilistic constrained problems with discrete random variables are
presented in Sen (1992).
4
Dynamic type stochastic programming problems with probabilistic
constraints
The simplest dynamic type stochastic programming problem is the
two-stage programming under uncertainty, or, stochastic programming
Ch. 5. Probabilistic Programming
309

with recourse. This can be formulated as
min cTx þ E qðx, Þ
ð
Þ

	
subject to
Ax ¼ b, x  0,
x 2 K,
ð4:1Þ
where
qðx, Þ ¼ min qTy
subject to
Wy    Tx, y  0:
ð4:2Þ
Problems (4.1) and (4.2) are called the ﬁrst and the second stage problems,
respectively. The set K in problem (4.1) is the set of all x vectors for which
problem (4.2) has feasible solution for any possible values of the random
vector . Since the projection of the convex polyhedron
ðx, , yÞ j Wy    Tx, y  0

	
onto the space of the x,  vectors can be described by the (in x and )
homogeneous linear inequalities
Hx  G,
ð4:3Þ
it follows that
K ¼ x j Hx  h
f
g,
ð4:4Þ
where
hi ¼ sup
2
G
ð
Þi
and  is the support of the random vector . By (4.4), K is a convex
polyhedron.
If we assume that the dual of problem (4.2) has feasible solution and E()
exists, then the optimum value of (4.2) exists for any x 2 K,  2  and
Eðqðx, ÞÞ exists for any x 2 K.
The condition that the second stage problem be solvable for any  2  is
frequently too restrictive in practice. In the power system engineering, for
example, we cannot design power systems in such a way that no blackout
should occur, ever. Similarly, in water resources engineering we cannot design
a dam in such a way that no ﬂood should occur, ever. We have to allow
310
A. Pre´kopa

disaster to occur but we may limit the frequency of its occurrence. A model
where the solvability of the second stage problem is ensured only by a (large)
probability has been formulated by Pre´ kopa (1973a). Since (4.3) is a necessary
and suﬃcient condition for the solvability of problem (4.2), we formulate our
new problem in such a way that impose a probabilistic constraint on the
inequalities (4.3). This raises the question that what optimum value shall we
enter into problem (4.1) if problem (4.2) is not always solvable. To overcome
this diﬃculty we introduce new variables (components of) z into problem (4.2)
that we add to the left hand side of the constraints and enter the same
variables with high costs into the objective function. The high costs should
render z ¼ 0 automatically whenever the original second stage problem (4.2) is
solvable. Our new two-stage problem with probabilistic constraint is the
following:
min cTx þ E qðx, Þ
ð
Þ

	
subject to
PðHx  GÞ  p
Ax ¼ b, x  0,
ð4:5Þ
where
qðx, Þ ¼ min qTy þ dTz

	
subject to
Wy þ z    Tx, y  0:
ð4:6Þ
Pre´ kopa (1980b, 1995) formulated the power system expansion problem as
a special case of problem (4.5)–(4.6). A solution technique for the above
problem is proposed by Dea´ k (2001). Similar models can be formulated for
the multiperiod case. A practical way, however, to incorporate probabilistic
constraints into dynamic type models is to include them in rolling horizon
models, where we solve static models subsequently in time. Examples will be
presented in Section 7.
5
Bounding, approximation and simulation of probabilities
In Section 3 we presented nonlinear programming procedures suitable to
solve probabilistic constrained stochastic programming problems. We left
open the question how to compute the constraining function values and their
gradients in the probabilistic constraint. First we look at the function values
which are joint probabilities of ﬁnite numbers of random events, where
each event is determined by some relation involving multivariate functions.
For example the constraining function PðTx  Þ in the probabilistic
constraint is the joint probability of r random events: Tix  i, i ¼ 1, . . . , r,
Ch. 5. Probabilistic Programming
311

for every ﬁxed x. If r is large, then we may not expect that the joint probability
of these events can be computed, therefore we look for bounding,
approximation and simulation procedures.
The combined use of simulation and optimization appeared in the
probabilistic constrained stochastic programming publications as early as
1974 (see Pre´ kopa et al. (1980)). More recent is the use of bounding techniques
which, among other methods, serve for approximation of probabilities.
First we look at the bounding techniques because some of them are used
also in the approximation and simulation procedures.
5.1
Bounding probabilities of boolean functions of events
Let A1, . . . , Ar be events in an arbitrary probability space. We intend to give
lower and upper bounds for some Boolean functions of them. We are
primarily interested in the union [r
i¼1 Ai and the intersection \r
i¼1 Ai of the
events as their Boolean functions. The intersection of r events appears in the
stochastic constraint Tx  , where Ai ¼ fTix  ig, i ¼ 1, . . . , r. The union of
events has also signiﬁcance here because, by De Morgan’s equality,
\
r
i¼1
Ai ¼
[
r
i¼
Ai
and, consequently,
P
\
r
i¼1
Ai
 
!
¼ 1  P
[
r
i¼1
Ai
 
!
:
Sometimes it is easier to present bounding formulas for the union.
Let us introduce the notation
Sk ¼
X
1i1<  <ikr
P Ai1 \ . . . \ Air


,
k ¼ 0, 1, . . . , r,
where S0 ¼ 1. These values appear in the inclusion-exclusion formula:
PðA1 [ . . . [ ArÞ ¼ S1  S2 þ    þ ð1Þr1Sr:
ð5:1Þ
Formula (5.1) provides us, in principle, with the possibility to ﬁnd the
probability of the union of events, provided that we can ﬁnd the probabilities
of the intersections of any number of them. However, if r is large, then this is
not the case and in practice we are able to ﬁnd only a few of S1, S2, . . ..
Let 
 designate the number of events, out of A1, . . . , Ar, which occur. Then
we have the following
312
A. Pre´kopa

Theorem 5.1. The following equalities hold true
E

k




¼ Sk,
k ¼ 1, . . . , r:
For a proof see, e.g., Pre´kopa (1995).
In view of Theorem 5.1 we call the values S1, S2, . . . binomial moments. Let
vi ¼ Pð
 ¼ iÞ,
i ¼ 0, 1, . . . , r:
Then Theorem 5.1 can be stated in the equivalent form
X
r
i¼0
i
k


vi ¼ Sk,
k ¼ 0, 1, . . . ,r:
ð5:2Þ
The v0, . . . , vr and S1, . . . , Sr values uniquely determine each other through
the relation (5.2).
If only S1, . . . , Sm are known in some situation, then we can formulate the
question: what are the best lower and upper bounds, for the probability of the
union, that can be given, based on this information. The answer to this
question is given by the pair of linear programming problems:
minðmaxÞ
X
r
i¼1
vi
subject to
X
r
i¼0
i
k


vi ¼ Sk,
k ¼ 0, 1, . . . , m
vi  0,
i ¼ 0, 1, . . . , r:
ð5:3Þ
In (5.3) v0, . . . , vr are decision variables, they are no longer uniquely
determined by the available binomial moments S1, . . . , Sm. A slightly more
convenient formulation of these LP’s is:
minðmaxÞ
X
r
i¼1
vi
subject to
X
r
i¼1
i
k


vi ¼ Sk,
k ¼ 1, . . . , m
vi  0,
i ¼ 1, . . . , r:
ð5:4Þ
Ch. 5. Probabilistic Programming
313

Problem (5.4) arises from problem (5.3) in such a way that we remove v0 as
well as the constraint involving S0. If Vmin and Vmax designate the optimum
values of problems (5.4), then Vmin is also the optimum value of the (5.3)
minimum problem and min (Vmax, 1) is the optimum value of the (5.3)
maximum problem. Problems (5.3) and (5.4) are called binomial moment
problems.
The dual of problem (5.4) can be written as
maxðminÞ
X
m
k¼1
ykSk
subject to
X
m
k¼1
i
k


yk 
ðÞ1:
ð5:5Þ
While in problem (5.4) the input data (the binomial moments S1, . . . , Sm)
are in the constraints, in problem (5.5) the constraints are universal,
independent on the special events, and the input data appear only in the
objective function.
Let A ¼ ða1, . . . , arÞ, b, c designate the matrix of the equality constraint, the
right hand side and the objective function coeﬃcient vectors, respectively.
Deﬁnition 5.1. A basis B in the minimization (maximization) problem (5.4) is
said to be dual feasible if
cT
BB1ak  ck,
k ¼ 1, . . . , r
cT
BB1ak  ck,
k ¼ 1, . . . , r


:
Note that inequality holds with equality if ak is a basic vector.
Deﬁnition 5.2. A basis B in any of the problems (5.4) is said to be dual
nondegenerate if
cT
BB1ak 6¼ ck
for nonbasic ak:
It is well-known in linear programming theory that a dual feasible basis in
the minimization (maximization) problem has objective function value which
is a lower (upper) bound for the optimum value. In view of this we have the
following relations
cT
B1B1
1 b  Vmin  PðA1 [ . . . [ ArÞ  Vmax  cT
B2B1
2 b,
ð5:6Þ
314
A. Pre´kopa

where B1(B2) is a dual feasible basis for the minimum (maximum) problem
(5.4).
We have a complete description of dual feasible bases of problem (5.4).
This is expressed in
Theorem 5.2. Every dual feasible basis in problem (5.4) is dual non-degenerate
and has one of the following structures described by the subscripts of the vectors:
m even
m odd
min problem
i, i þ 1, . . . , j, j þ 1,
i, i þ 1, . . . , j, j þ 1, r
max problem
1, i, i þ 1, . . . , j, j þ 1, r
1, i, i þ 1, . . . , j, j þ 1:
In other words, if m is even, then a basis is dual feasible in the min (max)
problem iﬀ. the subscript set of the basic vectors consists of consecutive pairs (1,
r and consecutive pairs). If m is odd, then in case of the min (max) problem the
subscript set is formed by consecutive pairs and r (by 1 and consecutive pairs).
The optimal dual vector y, i.e., the optimal solution of problem (5.5) has an
interesting property expressed in
Theorem 5.3. The components y1, . . . , ym of the optimal solution y of problem
(5.5) have alternating signs, starting with þ , and have the following property
jy1j  jy2j  . . .  jymj:
Since all bases of problem (5.4) are dual nondegenerate, the optimal basis is
unique. If m is small (m  4), then we can ﬁnd the optimal basis in such a way
that we look for that basis, among the dual feasible ones, which is also primal
feasible. This method provides us with bounds that can be obtained in a
relatively simple way for the cases of m ¼ 2, 3. For m ¼ 4 we present the upper
bound. The lower bound is complicated and we disregard its presentation here.
The number m, indicating the largest number of intersections of which the
probabilities appear in a formula, is called the order of the bound. The bounds
presented below are sharp in the sense that under the given information (input
data) no better bounds can be obtained.
Second order bounds using S1, S2
The lower bound is expressed by
PðA1 [ . . . [ ArÞ 
2
i þ 1 S1 
2
iði þ 1Þ S2,
where
i ¼ 1 þ
2S2
S1


:
Ch. 5. Probabilistic Programming
315

The upper bound is expressed by
PðA1 [ . . . [ ArÞ  min S1  2
r S2, 1


:
Third order bounds using S1, S2, S3
The lower bound is expressed by
PðA1 [ . . . [ ArÞ  i þ 2r  1
ði þ 1Þr
S1  2ð2i þ r  2Þ
iði þ 1Þr
S2 þ
6
iði þ 1Þr S3,
where
i ¼
6S3 þ 2ðr  2ÞS2
2S2 þ ðr  1ÞS1


:
The upper bound is given by
PðA1 [ . . . [ ArÞ  S1  2ð2i  1Þ
iði þ 1Þ S2 þ
6
iði þ 1Þ S3,
where
i ¼ 2 þ
3S3
S2


:
Fourth order upper bound using S1, S2, S3, S4
The bound is expressed by
PðA1 [...[ArÞ
min S1 2ðði1Þði2Þþð2i1ÞrÞ
iðiþ1Þr
S2 þ6ð2iþr4Þ
iðiþ1Þr
S3 
24
iðiþ1Þr S4,1


:
Any bound, obtained by any method in the literature, is either a special case
of our bounds, in the sense that it is the objective function value
corresponding to some dual feasible basis in problem (5.4), or it is not the
best possible bound and can be majorized by one of our bounds. As an
example we mention the Bonferroni bounds. By Theorem 5.2 the basis
316
A. Pre´kopa

B ¼ ða1, . . . , amÞ is dual feasible in the minimization (maximization) problem if
m is even (odd). Since
B1 ¼
1 2
2

m
1
3
2
 

m
2


..
.
..
.
1
0
BBBB@
1
CCCCA
1
¼
1 2
3

ð1Þm1m
1
 3
2
 
 ð1Þm2 m
2


..
.
..
.
1
0
BBBBB@
1
CCCCCA
,
it follows that
cT
BB1b ¼ S1  S2 þ    þ ð1Þm1Sm
and, by (5.6), we have established the Bonferroni bounds:
PðA1 [ . . . [ ArÞ  S1  S2 þ    þ Sm1  Sm,
if m is even and
PðA1 [ . . . [ ArÞ  S1  S2 þ    þ Sm2  Sm1 þ Sm,
if m is odd.
For an m for which the bounds are not available in formulas, we can
execute a simple dual algorithm, a variant of Lemke’s dual method, to ﬁnd the
optimum of problem (5.4). The algorithm presented below is valid for both the
minimization and maximization problems (5.4).
Dual algorithm to solve problem 5.4
Step 0. Find an initial dual feasible basis B, by the use of the structural
Theorem 5.2.
Step 1. If B1b  0, Stop, the basis B is optimal and cT
BB1b gives us the
optimal value, i.e., the required bound for the probability of the union.
Otherwise go to Step 2.
Step 2. Choose any j such that (B1b)j<0 and remove the jth vector from the
basis B. Go to Step 3.
Step 3. Include that vector into the basis which restores the dual feasible basis
structure described in Theorem 5.2. There is exactly one such vector. Go to
Step 1.
Note that the incoming vector can be found by a simple search procedure.
The other parts of the algorithm can also be executed in a simple way as
described in Pre´ kopa (2001b).
Ch. 5. Probabilistic Programming
317

Another probability bounding scheme, which provides us with better
bounds but the corresponding LP is more diﬃcult to solve, is the Boolean
scheme or Boolean problem. In this case we use the joint probabilities of
events individually, rather than just their sums in the binomial moments Sk.
Let again A1, . . . , Ar be events in an arbitrary probability space and
introduce the notations
vJ ¼ P
\
j2J
Aj
 
!
\
j2J
Aj
0
@
1
A
0
@
1
A
pI ¼ P
\
i2I
Ai
 
!
,
where I, J  f1, . . . , rg. Here vJ is the probability that the events Aj, j 2 J
occur but the events Aj, j 2 J do not occur; pI is the probability that the events
Ai, i 2 I occur. If we introduce the incidence matrix
aIJ ¼
1
if I  J
0
if I 6 J,

then we have the equation
X
Jf1,..., rg
aIJvj ¼ pI,
I  f1, . . . , rg:
ð5:7Þ
If for input data those probabilities pI are available for which jIj  m
(where jIj designates the number of elements of the set I), then (5.7), restricted
to jIj  m, does not determine uniquely the probabilities vJ. We can, however,
write up minimization and maximization LP’s which provide us with the best
lower and upper bounds for the probability of the union, under the given
information. As we have done in problem (5.4), here too, we disregard one
variable and one constraint, those which correspond to J ¼6 0 and I ¼6 0,
respectively. So we are led to the following problems
minðmaxÞ
X
6 06¼Jf1,..., rg
vJ
subject to
X
6 06¼Jf1,..., rg
aIJvJ ¼ pI,6 0 6¼ I  f1, . . . , rg,
jIj  m
vJ  0,6 0 6¼ J  f1, . . . , rg:
ð5:8Þ
318
A. Pre´kopa

Problem (5.8) is called Boolean probability bounding scheme.
Problems (5.4) can be regarded as aggregated problems of those in (5.8) and
problems (5.8) are disaggregated as compared to those in (5.4). Problems (5.8)
provide us with better bounds than problems (5.4). However, no general dual
feasible basis structure theorem is available for problems (5.8) and its
numerical solution is computationally intensive as there are 2r1 variables in
it. Still, a number of important bounds can be derived from (5.8) and some
bounds that have been known in the literature can be recovered as objective
function values corresponding to some dual feasible bases in (5.8). In the ﬁrst
category we mention the cherry tree bound and its generalizations. In the
second category noteworthy is the classical Hunter’s bound.
Hunter’s upper bound for the probability of the union of events
Let A1, . . . , Ar be events in an arbitrary probability space and pi ¼ PðAiÞ
pij ¼ PðAi \ AjÞ for i 6¼ j. Create the complete graph with nodes 1, . . . , r and
assign to arc ði, jÞ the weight pij, i 6¼ j. Let T be any spanning tree in this
graph. Then we have the relation
PðA1 [ . . . [ ArÞ  S1 
X
ði, jÞ2T
pij,
ð5:9Þ
where S1 ¼ p1 þ    þ pr. The best upper bound of the type (5.9) is obtained
from the heaviest spanning tree T*:
X
ði, jÞ2T*
pij ¼
max
T spanning tree
X
ði, jÞ2T
pij:
Inequality (5.9) provides us with Hunter’s upper bound if we choose
T ¼ T*.
To ﬁnd the heaviest spanning tree Kruskal’s algorithm is available. It
consists of the following steps:
Step 1. Initialize k ¼ 1 and ﬁnd the heaviest arc. Go to Step 2.
Step 2. Increase k by 1. If k ¼ n then Stop, the heaviest spanning tree T* has
been found. Otherwise go to Step 3.
Step 3. Find the heaviest arc that does not create cycle. Go to Step 2.
Any upper bound in (5.9) can be represented as the objective function value
corresponding to a suitable dual feasible basis in the maximization problem
(5.8) when m ¼ 2. The basis can be constructed as follows: take all paths that
can be created by the use of the nodes and arcs in T; in case of any of these
paths take the set of nodes used by the path and consider it as a label set J in
problem (5.8); the columns in problem (5.8) corresponding to these labels
provide us with the required dual feasible basis.
Ch. 5. Probabilistic Programming
319

Hunter’s upper bound is always at least as good as the second order
binomial moment bound.
Finally, we mention that the probability bounding schemes can be
incorporated into the probabilistic constrained stochastic programming
problems. We present two examples in this respect.
In the ﬁrst example we use the simple probability bound
PðA1 \ . . . \ ArÞ 
X
r
i¼1
PðAiÞ  ðr  1Þ,
replace Tix  i for Ai and impose a probabilistic constraint on the right hand
side to obtain
X
r
i¼1
PðTix  iÞ  ðr  1Þ  p:
This can replace the constraint PðTx  Þ  p in problem (1.3). However,
we are somewhat better oﬀ, if we formulate for problem (1.3) the following
approximate problem:
min cTx
subject to
PðTix  iÞ  pi,
i ¼ 1, . . . , r
X
r
i¼1
ð1  piÞ  1  p
Ax ¼ b, x  0,
ð5:10Þ
where p is a ﬁxed probability but p1, . . . , pr are variables. It can be shown that
the ﬁrst two sets of constraints imply that PðTx  Þ  p. If FiðzÞ is the
probability distribution function of the random variable i, then the constraint
PðTix  iÞ  pi is equivalent to Tix  F1ðpiÞ, i ¼ 1, . . . , r. If we replace
problem (5.10) for problem (1.3), then the set of feasible solutions shrinks, in
general, and the optimum value of problem (5.10) will be larger than that of
problem (1.3). The same is true for the second example that we present below.
Let us introduce the functions:
SkðxÞ ¼
X
1i1<...<ikr
P Ti1x  i1, . . . , Tirx  ir

,
k ¼ 0, 1, . . . , m,
320
A. Pre´kopa

where S0ðxÞ:1. Out of problem (1.3) we create the new problem:
min cTx
subject to
X
r
i¼0
i
k
 
!
vi ¼ SkðxÞ,
k ¼ 0, 1, . . . , m
vr  p
Ax ¼ b, x  0 :
ð5:11Þ
Similar problem can be formulated by the use of the Boolean minimization
problem but in this case we have to reestablish the constraint as well as the
variable corresponding to the empty set. In fact, in problem (5.11) we have
used the binomial moment problem (5.3), and not (5.4), because problems
(5.3) and (5.4) are equivalent only in the case of bounding the union whereas
in problem (5.11) we create a bound for the intersection.
There is a considerable recent literature on the binomial and Boolean
probability bounding schemes.
5.2
Approximation and simulation of probabilities
Programming under probabilistic constraints is the research area where
optimization combined with simulation ﬁrst appeared as a problem solving
methodology.
The joint probabilistic constraint with stochastically dependent random
variables presumes that we are able to compute or at least estimate the values
and gradients of multivariate distribution functions. The normal distribution
seems to be the most frequent among the multivariate distributions hence we
pay special attention to it.
The r-variate nondegenerate standard normal probability density function
has the form
’ðz; RÞ ¼
1
ð2Þr=2
ﬃﬃﬃﬃﬃﬃﬃ
jRj
p
ezTR1z,
z 2 Rr:
A random variable  that has this probability density function can be
represented in the form
 ¼ rT	,
Ch. 5. Probabilistic Programming
321

where r is -distributed random variable with r degrees of freedom, 	 is an
r-variate random vector, uniformly distributed on the surface of the unit sphere:
Sr ¼
z j
X
r
i¼1
z2
i ¼ 1
(
)
and T is lower triangular matrix such that
TTT ¼ R:
The most important problem is to approximate, or estimate the integral
p ¼
Z
Q
’ðz; RÞ dz,
ð5:12Þ
where Q is a ﬁnite or inﬁnite rectangle. An eﬃcient method works in the
following way.
Let the rectangle Q be bounded, for the sake of simplicity, and given by
Q ¼ fz j a  z  bg:
Let further krðtÞ designate the probability density function of the -
distribution with r degrees of freedom and
z1ðvÞ ¼ min,
subject to
a  Tv  b
z2ðvÞ ¼ max ,
subject to
a  Tv  b:
The probability in (5.12) can be expressed in the form
p ¼
Z
Q
’ðz; RÞ dz ¼
Z
Sr
Z
z2ðvÞ
z1ðvÞ
krðtÞ dt
0
B@
1
CA dUðvÞ,
ð5:13Þ
where U is the probability distribution function of 	.
To estimate the probability p in (5.13) we can generate a sample v1, . . . , vN
for the random vector 	 and take
1
N
X
N
i¼1
eðviÞ,
322
A. Pre´kopa

where e(v) designates the interior integral on the right hand side of (5.13). This
way, however, the procedure is slow. In order to speed it up, the generation of
the sampling elements of Sr by the use of random orthonormalized systems
has been proposed. This means that we randomly pick an orthonormalized
system of vectors g1, . . . , gr (gT
i gj ¼ ij, where ij is Kronecker’s delta), then
choose k out of the r in all possible ways and for each choice of k vectors we
multiply them by
þ 1 and 1 in all possible ways. The number of
orthonormal systems generated this way out of the single system g1, . . . , gr,
is 2kðr
kÞ. One choice of k vectors can be represented by an index set
I ¼ fi1, . . . , ikg  f1, . . . , rg and a set of þ 1, 1 multipliers is designated by
s1, . . . , sk. Then we form the sum
gðS, IÞ ¼ 1ﬃﬃﬃ
k
p
X
k
j¼1
sjgij:
If initially there are N orthonormal systems gðlÞ
1 , . . . , gðlÞ
r , l ¼ 1, . . . , N
chosen, then our estimation for the probability p is
#k ¼ 1
N
X
N
l¼1
1
2k
r
k


X
S,I
e Tgðl ÞðS, IÞ


,
ð5:14Þ
where the second summation extends over all k element subsets of f1, . . . , rg
and all 2k k-component vectors with components 1, þ 1. The value #k is an
unbiased estimator of p.
The main advantage of the above procedure is that whenever we generate
one orthonormalized system, we immediately produce 2kðr
kÞ out of it. There is,
however, another important advantage of it oﬀered by the formula (5.14).
When we compute TgðlÞðS, IÞ, then ﬁrst we form the products TgðlÞ
1 , . . . , TgðlÞ
r
and only after that pick the k vectors and multiply them by s1, . . . , sk. This
arrangement of computation also saves considerable time.
The method has been extended to ﬁnd probabilities of convex polyhedra
and other convex sets in Rn. The only diﬃculty in the more general cases is to
ﬁnd the intersections z1(v), z2(v) of the straight line Tv ð1 <  < 1Þ with
the boundary of the convex set. It is reported that three digit accuracy can be
obtained in less than 1 s. for all r  20.
The next simulation technique that we describe is more general, it can be
applied in principle for arbitrary multivariate probability distributions.
However,
numerical
results
are
available
only
for
three
multivariate
distributions: normal, gamma and Dirichlet. We describe the general method
for the case where Ai ¼ fi  xig, i ¼ 1, . . . , r and we want to estimate the joint
probability distribution function of 1, . . . , r:
F x1, . . . , xr
ð
Þ ¼ P A1 \ . . . \ Ar
ð
Þ:
Ch. 5. Probabilistic Programming
323

We pass to the complementary events Ai ¼ fi > xig, i ¼ 1, . . . , r, and deﬁne
Sk ¼
X
1i1<...<ikr
P Ai1 \ . . . \ Aik


, k ¼ 1, . . . , r:
If we use S1, S2, S3, then, using the bounds described in Section 5.1, we can
create lower and upper bounds for the probability of the union A1 [ . . . [ Ar,
and, in turn, for the probability of the intersection which is Fðx1, . . . , xrÞ.
Three lower bounds: L1, L2, L3 and two upper bounds: U1, U2 are used. These
are the following
L1 ¼ 1  S1
first order binomial moment bound
L2 ¼ 1  S1 þ 2
r S2
second order binomial moment bound
L3 ¼ 1  S1 þ
X
ði, jÞ2T*
P Ai \ Aj


Hunter0s bound
U1 ¼ 1  S1 þ S2
second order Bonferroni bound
U2 ¼ 1
2
i þ 1 S1þ
2
iði þ 1Þ S2 second order binomial moment bound,
where i ¼ 1 þ
2S2
S1


:
We have the relations:
Fðx1, . . . , xrÞ  L1 ¼ S2 þ S3     þ ð1ÞrSr
Fðx1, . . . , xrÞ  L2 ¼
1  2
r


S2  S3 þ    þ ð1ÞrSr
Fðx1, . . . , xrÞ  L3 ¼ 
X
ðijÞ2T*
P Ai \ Aj


þ S2  S3 þ    þ ð1ÞrSr
Fðx1, . . . , xrÞ  U1 ¼ S3 þ    þ ð1ÞrSr
Fðx1, . . . , xrÞU2¼
k
i þ 11


S1þ 1
2
iði þ 1Þ


S2S3þ   þð1ÞrSr:
ð5:15Þ
The simulation technique uses the exact values of the univariate and
bivariate marginal probability distribution function values. We compute them
324
A. Pre´kopa

by deterministic numerical integration method. These values enter into
L1, L2, L3, U1, U2. Then we simulate the values on the right hand sides of
((5.15)), to obtain estimations of Fðx1, . . . , xrÞ.
Let ððsÞ
1 , . . . , ðsÞ
r Þ, s ¼ 1, . . . , N be a sample of size N for the random vector
ð1, . . . , rÞ. For ﬁxed s let ðsÞ designate the number of those inequali-
ties ðsÞ
1  x1, . . . , ðsÞ
r
 xr which are not fulﬁlled. Let further ðsÞ designate the
number of those pairs ði, jÞ 2 T* for which we have ðsÞ
i
> xi, ðsÞ
j
> xj. Since we
have the relations
E
ðsÞ
k
 
!
"
#
¼ Sk,
k ¼ 0, 1, . . . , r;
s ¼ 1, . . . , N
E ðsÞ


¼
X
ði, jÞ2T*
P Ai \ Aj


,
it follows that ððsÞ
k Þ and ðsÞ are unbiased estimators of the right hand side
values in (5.16), respectively. If we use this and the relation
ð1  1ÞðsÞ ¼
X
ðsÞ
j¼0
ð1Þj
ðsÞ
j


¼ 0,
then we can easily show that the follwooing random variables are unbiased
estimators of the right hand sides of (5.15):

ðsÞ
L1 ¼
ðsÞ  1,
if ðsÞ  2
0
otherwise
(

ðsÞ
L2 ¼
1
r ðsÞ  1


r  ðsÞ


,
if ðsÞ  2
0
otherwise
(

ðsÞ
L3 ¼
ðsÞ  1  ðsÞ,
if ðsÞ  2
0
otherwise
(

ðsÞ
U1 ¼
1
2 ðsÞ  1


2  ðsÞ


,
if ðsÞ  3
0
otherwise
(

ðsÞ
U2 ¼
iðsÞ
ð
Þ ðsÞi1
ð
Þ
iðiþ1Þ
,
if ðsÞ  1
0
otherwise
8
<
:
Ch. 5. Probabilistic Programming
325

Taking averages with respect to s we obtain ﬁve unbiased estimators for
Fðx1, . . . , xrÞ:

Lj ¼ Lj þ 1
N
X
N
s¼1

ðsÞ
Lj ,
j ¼ 1, 2, 3

Uj ¼ Uj þ 1
N
X
N
s¼1

ðsÞ
Uj,
j ¼ 1, 2:
ð5:17Þ
A sixth unbiased estimator is given by

0 ¼ 1
N
X
N
s¼1

ðsÞ
0 ,
ð5:18Þ
where 
ðsÞ
0 ¼ 1, if all relations ðsÞ
1  x1, . . . , ðsÞ
r
 xr are satisﬁed and 
ðsÞ
0 ¼ 0
otherwise.
Out of the six estimators in (5.17) and (5.18) one estimator is formed:

 ¼ w0
0 þ wL1
L1 þ wL2
L2 þ wL3
L3 þ wU1
U1 þ wU2
U2,
where the sum of hte weights is equal to one and weights are computed in such
a way that the variance of 
 should be minimum. The covariances of the six
estimators for this minimization problem are estimated from the sample.
Based on the above two simulation methods a hybrid method can be
created. Let again Cj ¼ ½aj, bj, j ¼ 1, . . . , r and deﬁne the sets
DiðvÞ ¼ f j aj  Tjv  bj is violated for exactly i indices jg:
We estimate the probability PðA1 [    [ ArÞ, where Aj ¼ fj 62 Cjg, j ¼
1, . . . , r. Let pj ¼ PðAjÞ, j ¼ 1, . . . , r. Then we have
Sk ¼
X
r
i¼1
i
k


pi,
k ¼ 1, . . . , r:
By Theorem 5.1 we have the equalities
S2  S3 þ    þ ð1ÞrSr ¼
X
r
i¼2
ði  1Þpi
ð5:19Þ
326
A. Pre´kopa

S3 þ    þ ð1ÞrSr ¼ 
X
r
i¼3
i  1
2


pi:
ð5:20Þ
In addition, from the previous descriptions we know that
pi ¼
Z
Sr
Z
DiðvÞ
krðtÞ dt
0
B@
1
CA dUðvÞ,
i ¼ 1, . . . , r:
ð5:21Þ
Combining the above–mentioned equalities we obtain
PðA1 \    \ ArÞ ¼ P A1 [    [ Ar


¼ 1  S1 þ S2 þ    þ ð1ÞrSr


¼ 1  S1 þ
Z
Sr
X
r
i¼2
ði  1Þ
Z
DiðvÞ
krðtÞ dt
0
B@
1
CAdUðvÞ
ð5:22Þ
and
PðA1 \    \ ArÞ ¼ P A1 [    [ Ar


¼ 1  S1 þ S2 þ S3 þ    þ ð1ÞrSr


¼ 1  S1 þ S2 
Z
Sr
X
r
i¼3
i  1
2

 Z
DiðvÞ
krðtÞ dt
0
B@
1
CAdUðvÞ:
ð5:23Þ
If we compute S1 and S2 exactly, by some numerical quadrature and choose
randomly the vector v, that appear on the right hand sides of (5.21)–(5.23),
and designate by 
1 and 
2, respectively the obtained last terms in these
equations, then we have two estimators for PðA1 \    \ ArÞ. These are
^P1 ¼ 1  S1 þ 
1, ^P2 ¼ 1  S1 þ S2 þ 
2:
We can use ^P0 ¼ 
0 in (5.18) as a third estimator. Our ﬁnal estimator is a
minimum variance linear combination of the three:
^P ¼ w0 ^P0 þ w1 ^P1 þ w2 ^P2
Ch. 5. Probabilistic Programming
327

where w0 þ w1 þ w2 ¼ 1. The covariance of
^P0, ^P1, ^P2 can be estimated
from the sample and w0, w1, w2 can be obtained as optimal solution of the
problem:
min wTCw
subject to
w0 þ w1 þ w2 ¼ 1:
A simple procedure is available to ﬁnd the sets DiðvÞ, i ¼ 1, . . . , r, for a
given v.
The above described method has been compared for the case of a
multivariate normal distribution to methods of deterministic numerical
integration. It is suggested that before choosing the method to approximate
the probability p ¼ PðA1 \    \ ArÞ, a few trial point should be generated to
obtain a preliminary indication about the magnitude of the probability p. It is
stated that, choosing the most suitable method, a twenty dimensional
probability can be computed with four digit accuracy in less than six minutes
on an ordinary desktop computer.
To close this section, we brieﬂy describe a recently developed numerical
integration method to ﬁnd the values of the multivariate normal integrals.
The method works both in the nondegenerate and degenerate cases and its
code is publicly available on the internet.
Assume that
the distribution is a
nondegenerate standard normal
distribution with correlation matrix  of which the Cholesky factorization
 ¼ CCT is known. Let a and b be the lower and upper boundary points of
the r-dimensional rectangular set, respectively. We want to compute the integral
p ¼
Zb1
a1
  
Zbr
ar
1
jj1=2ð2Þr=2 e1
2 xT1x dxr    dx1:
ð5:24Þ
If we use the transformation x ¼ Cy, then we have to integrate with respect
to the components of y satisfying
a1  y1  b1
a0
ið y1, . . . , yi1Þ ¼
ai 
X
j<i
cijyj
 
!
1
cii
 yi

bi 
X
j<i
cijyj
 
!
1
cii
¼ b0
iðy1, . . . , yi1Þ,
i ¼ 2, . . . , r:
328
A. Pre´kopa

With this transformation the integral (5.24) becomes (’ is the univariate
standard normal probability density function):
Zb1
a1
’ð y1Þ
Z
b0
2ð y1Þ
a0
2ð y1Þ
’ð y2Þ   
Z
b0
rð y1,...,yr1Þ
a0rð y1,...,yr1Þ
’ð yrÞ dyr    dy1:
If we introduce the further transformation yi ¼ 1ðziÞ, i ¼ 1, . . . , r, where
 is the univariate standard normal distribution function, and introduce the
notations
g1 ¼ ða1Þ,
h1 ¼ ðb1Þ
giðz1, . . . , zi1Þ ¼ 
ai 
X
i1
j¼1
cij1ðzjÞ
 
!.
cii
 
!
hiðz1, . . . , zi1Þ ¼ 
bi 
X
i1
j¼1
cij1ðzjÞ
 
!.
cii
 
!
,
i ¼ 2, . . . , r,
then the integral (5.24) transforms into
p ¼
Zh1
g1
Z
h2ðz1Þ
g2ðz1Þ
  
Z
hrðz1,..., zr1Þ
grðz1,..., zr1Þ
dzr    dz1:
The ﬁnal transformation zi ¼ gi þ wiðhi  giÞ, i ¼ 1, . . . , r transforms the
integral into
p ¼ ðh1  g1Þ
Z1
0
ðh2ðw1Þ  g2ðw1ÞÞ
Z1
0
  
Z1
0
ðhrðw1, . . . , wr1Þ  grðw1, . . . , wr1ÞÞ dwr1    dw1
where the integration region is standardized.
The above procedure is applicable in any ordering of the variables. The
method works best if the innermost integral carries the most weight, then
comes the second etc. These weights can be ranked by ranking the
probabilities ðbiÞ  ðaiÞ, i ¼ 1, . . . , r.
Ch. 5. Probabilistic Programming
329

5.3
Calculation of the gradient values
Let
 ¼ ð1, . . . , rÞ
be
a
continuously
distributed
random
vector,
Fðz1, . . . , zrÞ its probability distribution function and fiðzÞ the probability
density function of i, i ¼ 1, . . . , r. Let further
Fðz1, . . . , zi1, ziþ1, . . . , zr j ziÞ
¼ Pð1  z1, . . . , i1  zi1, iþ1  ziþ1, . . . , r  zr j i ¼ ziÞ
i ¼ 1, . . . , r:
It is easy to see that
@Fðz1, . . . , zrÞ
@zi
¼ Fðz1, . . . , zi1, ziþ1, . . . , zr j ziÞfiðziÞ
i ¼ 1, . . . , r
ð5:25Þ
and this formula provides us with a general method to compute the gradients
of F. In case of many known probability distributions the conditional
distribution function Fðz1, . . . , zi1, ziþ1, . . . , zr j ziÞ is of the same type as the
original distribution function, hence using the same code and a code to
calculate fiðziÞ, we can obtain the ith component of rF.
As an example we present the gradient of the multivariate standard normal
probability distribution function ðz1, . . . , zr; RÞ, where R ¼ ðijÞ is the
correlation matrix. We can use formula (5.25), where we replace
Fðz1, . . . , zi1, ziþ1, . . . , zr j ziÞ
¼  z11, izi
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
1,i
q
, . . . , zi1i1, izi
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
i1,i
q
, ziþ1iþ1, izi
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
iþ1,i
q
, . . . , zrr, izi
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
r,i
q
; R
0
B@
1
CA,
and R is the (r1)  (r1) correlation matrix with entries
sj,k ¼
j,k  j,i k,i
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
j,i
q
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  2
k,i
q
,
j, k ¼ 1, . . . , r, j 6¼ i, k 6¼ i:
In addition we replace ’ðziÞ for fiðziÞ, where ’ is the standard normal
probability density function. We see that r z; R
ð
Þ can be computed by
computing the values of r1-variate standard normal distribution functions
and the values of the univariate standard normal probability density function.
330
A. Pre´kopa

Note that in the probabilistic constraint PðTx  Þ  p the random vector
can be standardized and we can write the constraint in the form:
 Tix  i
i
, i ¼ 1, . . . , r; R


 p:
To compute the gradient of the constraining function the just obtained
formula can be used.
Other examples, where the gradients can be computed by the use of the
same type but lower dimensional distribution functions, include the gamma
and the Dirichlet distributions.
General formulas for gradients of ‘‘probability functions’’ are also available.
We look at the function
FðxÞ ¼
Z
f ðx, yÞ0
pðx, yÞ dy,
where pðx, yÞ is a probability density function and f ðx, yÞ  0 is the compact
form of the inequalities fiðx, yÞ  0, i ¼ 1, . . . , k. There are altogether three
formulas, the ﬁrst one is called the integral over the surface formula, the
second one the integral over the volume formula and the third one is a general
formula.
The integral over the surface formula
Let ðxÞ ¼ fy j f ðx, yÞ  0g and @ðxÞ the boundary of the set ðxÞ. Let
further @iðxÞ ¼ ðxÞ \ fy j fiðx, yÞ ¼ 0g, i.e., that part of the boundary set
@ðxÞ which is determined by fi. Then we have the equation
rxFðxÞ ¼
Z
ðxÞ
rxpðx, yÞ dy 
X
k
i¼1
Z
@iðxÞ
pðx, yÞ
kry fiðx, yÞk rx fiðx, yÞ dS:
The integral over the volume formula
We introduce the notations ðx 2 Rn, y 2 RmÞ:
f1, lðx, yÞ ¼
f1ðx, yÞ
...
flðx, yÞ
0
B@
1
CA,
f ðx, yÞ ¼ f1, kðx, yÞ
Ch. 5. Probabilistic Programming
331

ryf ðx, yÞ ¼
@f1ðx, yÞ
@y1
  
@fkðx, yÞ
@y1
..
.
..
.
..
.
@f1ðx, yÞ
@ym
  
@fkðx, yÞ
@ym
0
BBB@
1
CCCA
H ¼
h1, 1
  
h1, m
...
...
...
hn, 1
  
hn, m
0
BB@
1
CCA,
hi, j ¼ hi, jðx, yÞ
divyH ¼
X
m
i¼1
@h1, j
@yj
...
X
m
i¼1
@hn, j
@yj
0
BBBBBBBB@
1
CCCCCCCCA
,
j ¼ 1, . . . , m:
We have the gradient formula
rxFðxÞ ¼
Z
ðxÞ
rxpðx, yÞ dy þ
Z
ðxÞ
divyðpðx, yÞHðx, yÞÞ dy,
where H(x, y) satisﬁes the equation
Hðx, yÞryf ðx, yÞ þ rx f ðx, yÞ ¼ 0:
This last equation may not have a solution and in that case the general
formula may be useful.
The general formula for the gradient
We split the set of constraints into two groups and designate the
corresponding subscript sets by K1 ¼ f1, . . . , lg and K2 ¼ fl þ 1, . . . , kg. We
have the formula
rxFðxÞ ¼
Z
ðxÞ
rxpðx, yÞ dy þ
Z
ðxÞ
divyð pðx, yÞHlðx, yÞÞ dy

X
k
i¼lþ1
Z
@iðxÞ
pðx, yÞ
kryfiðx, yÞk
rx fiðx, yÞ þ Hlðx, yÞryfiðx, yÞ


dS,
332
A. Pre´kopa

where the n  m matrix Hlðx, yÞ satisﬁes the equation
Hlðx, yÞry f1,lðx, yÞ þ rx f1,lðx, yÞ ¼ 0:
5.4
Bibliographical notes
Combined use of simulation and optimization appeared ﬁrst, in the
stochastic programming context, in a paper by Pre´ kopa et al. (1980). The
paper was presented at the First International Conference on Stochastic
Programming, in Oxford, England, 1974.
For the history of inclusion–exclusion formula see Taka´ cs (1967). For the
proof of Theorem 5.1 see Taka´ cs (1967) and Pre´ kopa (1995). Problems (5.3)–
(5.5) and Theorem 5.2 are taken from Pre´ kopa (1988). Since Sk is the kth
binomial moment of v, problems (5.3) and (5.4) are termed binomial moment
problems. Theorem 5.3 is from Boros and Pre´ kopa (1989).
The second order lower bound, based on S1, S2, was obtained by Dawson
and Sankoﬀ(1967). The upper bound is due to Kwerel (1975a,b) and Sathe
et al. (1980). The third order lower and upper bounds have been obtained by
Kwerel (1975a,b) and Pre´ kopa and Boros (1989). Kwerel used linear
programming theory specialized for the cases m ¼ 2, 3, without writing up the
more general problems (5.3), (5.4). Boros and Pre´ kopa (1989) presented a
variety of bounds, based on the dual feasible basis structure theorem
(Theorem 5.2). The fourth order bound, based on S1, S2, S3, S4 is also from
Boros and Pre´ kopa (1989). The Bonferroni bounds are due to Bonferroni
(1937). The dual algorithm to solve problem (5.4) is due to Pre´ kopa (1988). A
more reﬁned version of it, formulated for the (equivalent) power moment
problem, was presented in Pre´ kopa (2001b).
Problem (5.8), more exactly its dual was initiated by Boole (1854). Its exact
formulation is due to Hailperin (1965). Hunter’s upper bound is due to Hunter
(1976) and Worsley (1983). The algorithm to ﬁnd the heaviest spanning tree is
due to Kruskal (1956). One generalization of Hunter’s bound is presented in
Pre´ kopa et al. (2001) and another one, the cherry tree bound, in Buksza´ r and
Pre´ kopa (2001). The use of bounds in probabilistic constrained stochastic
programming problems, presented at the end of Section 5.1, is from Pre´ kopa
(1999).
Other useful probability bounds are presented in Galambos and Simonelli
(1996), Buksza´ r and Sza´ ntai (2002), Buksza´ r (2001) etc.
The simulation method based on (5.13), to estimate the normal probability
distributionfunction value,is dueto Dea´ k(1980,1986,1988, 1990,2000b,2002).
The next, more general method that can be used to estimate the values of arbit-
raryprobabilitydistributionfunctions,isduetoSza´ ntai(1986,2000).Thehybrid
method was proposed by Gassmann (1988) and it is called Dea´ k, Sza´ ntai,
Gassmann (DSG) method. A more recent paper by Gassmann et al. (2002)
Ch. 5. Probabilistic Programming
333

improves on this and revises other methods to compute multivariate normal
integrals. The last method in Section 5.2 is due to Genz (1992).
The formula to compute gradients of multivariate normal integrals was ﬁrst
proposed in Pre´ kopa (1970) and used in computerized problem solution in
Pre´ kopa et al. (1980). Gradient formula for the multivariate gamma
distribution, presented in Section 2.2 (distribution (8)) is described in
Pre´ kopa and Sza´ ntai (1978a). Sza´ ntai (1985) derived the gradient of the
Dirichlet distribution. For its description see also Pre´ kopa (1995).
The general surface and volume integral formulas are due to Uryasev (1989,
2001). Some special formulas have been derived by Raik (1972), Kibzun and
Kurbakooskij (1991), Kibzun and Kan (1996) and Marti (1988).
6
Duality and stability
Probabilistic constrained stochastic programming problems are nonlinear
optimization problems, hence nonlinear duality theory has a straightforward
application there. There is, however, one primal-dual relationship, involving
two special probabilistic constrained problems, and a corresponding duality
theorem which are special and deserve presentation here. The theory that we
describe is due to Koma´ romi (1986).
Let A be an m  n matrix and  2 Rm,  2 Rn two continuously distributed
random variables. Designate by F and G the probability distribution functions
of  and , respectively, and suppose that they are quasi-concave functions.
Let supp F and supp G designate the supports of F and G, respectively, i.e., the
smallest closed sets where the probability measures, generated by these
distribution functions, are equal to one. Introduce the notations
B ¼ fb j FðbÞ  p, b 2 supp Fg
XðbÞ ¼ fx j Ax  b, x  0g
C ¼ fc j GðcÞ  q,  c 2 supp Gg
YðcÞ ¼ fy j ATy  c, y  0g:
Consider the pair of primal-dual problems:
min sup
c2C
cTx
subject to
FðbÞ  p, b 2 supp F
Ax  b, x  0
ð6:1Þ
334
A. Pre´kopa

and
max inf
b2B bTy
subject to
GðcÞ  q,  c 2 supp G
ATy  c, y  0:
ð6:2Þ
Note
that
the
constraints
in
problem
(6.1)
are
equivalent
to
PðAx  Þ  p, x  0 and the constraints in problem (6.2) are equivalent to
PðATy  Þ  q, y  0. We have the following duality theorem.
Theorem 6.1. The following three assertions hold true.
(a) Suppose that the function F is strictly increasing in each variable, supp G
is bounded and Slater’s condition: intfb j b 2 B, XðbÞ 6¼ ;g 6¼ ; holds. If
the objective function of problem (6.1) is unbounded, then the problem
(6.2) has no feasible solution. Otherwise, problem (6.2) has feasible
solution, the optimum values of the two problems are equal and that value
is attained in problem (6.2).
(b) Suppose that the function G is strictly increasing in each variable, supp F
is bounded and Slater’s condition: intfc j c 2 C, YðcÞ 6¼ ;g 6¼ ; holds. If
the objective function of problem (6.2) is unbounded, then problem (6.1)
has no feasible solution. Otherwise, problem (6.1) has feasible solution,
the optimum values of the two problems are equal and that value is
attained in problem (6.1).
(c) Suppose that both F and G are strictly increasing functions in each
variable, supp F and supp G are bounded and Slater’s conditions:
intfb j b 2 B, XðbÞ 6¼ ;g 6¼ ;, intfc j c 2 C, YðcÞ 6¼ ;g 6¼ ; hold. Then both
problems (6.1) and (6.2) have optimal solutions. If (x0, y0) is a pair of
optimal solutions of the problems, then it is a saddle point of yTAx with
respect to minimizing over X and maximizing over Y.
A logconcave probability distribution function is also quasi-concave, hence
the above theory applies to this case.
Another interesting duality theorem, involving logconcave probability
distributions, was obtained by Luc (1983).
Stability and sensitivity are important issues in probabilistic constrained
stochastic programming problems. Since decision making takes place based
on tail probabilities, it is particularly important to know how the optimum
value of the problem changes if the probability distribution of the random
variables in the model changes. If the probability distribution belongs to some
known class, the question can be formulated in such a way that: how the
change of the distribution parameters inﬂuences the optimum value or the
problem in general?
Ch. 5. Probabilistic Programming
335

The case of the normal distribution oﬀers nice illustration. Consider
problem (1.3), where  has a multivariate normal distribution with expecta-
tions EðiÞ ¼ i, variances VarðiÞ ¼ 2
i , i ¼ 1, . . . , r and correlation matrix R.
The probabilistic constraint can equivalently be written in the form
PðTx  Þ ¼ P Tix  i
i
 i  i
i
, i ¼ 1, . . . , r


¼ ðL1ðxÞ, . . . , LrðxÞ; RÞ  p,
where LiðxÞ ¼ ðTiðxÞ  iÞ=i, i ¼ 1, . . . , r. If we introduce the new variables
yi ¼ LiðxÞ, i ¼ 1, . . . , r, then problem (1.3) can be written in the equivalent form:
min cTx
 y; R
ð
Þ  p
LðxÞ ¼ y
Ax ¼ b, x  0:
ð6:3Þ
The changes in i, i, i ¼ 1, . . . , r change only the linear constraint LðxÞ ¼ y
and its eﬀect to the optimum value can be computed by the use of some
standard methods (see, e.g., Pre´ kopa (1995, Chapter 15)). When we apply a
method of this kind ﬁrst we linearize the probabilistic constraining function
around the optimal y but then concentrate on the eﬀect of the change in the
next linear constraint.
The problem is more complicated if the change occurs in the correlation
matrix R. We present a few facts that can be used to do further analysis.
Let ’ð y; RÞ designate the r-variate standard normal probability density
function with correlation matrix R ¼ ði, jÞ. Then, as it is easy to check, we
have the equality
@’
@i,j
¼ @2’
@yi@yj
:
Integrating on both sides with respect to y, in 1 < yi  zi, i ¼ 1, . . . , r,
and choosing i ¼ 1, j ¼ 2, for the sake of simplicity, we obtain the equation
@ðz; RÞ
@1, 2
¼
Zz1
1
  
Zzr
1
@2’ð y;RÞ
@y1@y2
dyr . . . dy2 dy1
¼
Zz3
1
  
Zzr
1
’ð y;RÞ dyr . . . dy3:
ð6:4Þ
336
A. Pre´kopa

If we choose another correlation matrix K ¼ ði, jÞ and take

i, j ¼ i, j þ ð1  Þi, j
as functions of the variable 0    1, then, in view of (6.4), we get
dðz; GÞ
d
¼
X
i<j
@ðz; GÞ
@
i, j
ði, j  i, jÞ,
ð6:5Þ
where G ¼ ð
i,jÞ. If i, j  i, j, then the derivative in (6.5) is positive and
integrating on the left hand side of (6.5) with respect to  from 0 to 1, we
obtain the inequality
ðz; RÞ  ðz; KÞ,
for R  K:
ð6:6Þ
Inequality (6.6) is known as Slepian’s inequality (see Slepian (1962)).
A large number of stability results have been obtained over the past
ﬁfteen years by Dupacˇ ova´ (1991) Kall (1987), Ro¨ misch and Schultz (1991),
Henrion and Ro¨ misch (1998, 2000), Henrion (2000) and others. As the results
and their descriptions are rather involved we only demonstrate the ﬂavor of
the more recent results by presenting a theorem from Henrion and Ro¨ misch
(1998).
Consider problem (1.3) and assume that  has an -concave probability
density function (see Theorem 2.9 for the implication with respect to the
distribution of ), the problem has feasible solution and ﬁnite optimum. Let
ðPÞ designate the set of optimal solutions. Together with P we consider
another probability distribution Q and designate by Fp and FQ, respectively,
the corresponding distribution functions. The set of optimal solutions under
the distribution Q is designated by ðQÞ. We assume that there exists an x
such that Ax ¼ b, x  0 and FPðTxÞ > p. Moreover, we assume that Fp is
strictly convex in a convex neighborhood of AðPÞ. We have the following.
Theorem 6.2. Under the above conditions there exist constants L > 0,  > 0
such that
dHððPÞ, ðQÞÞ  LkFP  FQk
1
21,
whenever
kFP  FQk1 < :
Ch. 5. Probabilistic Programming
337

7
Selected applications
7.1
Energy problems
An optimal investment problem, formulated for the electrical energy sector
of the Hungarian economy, was the ﬁrst real life application of probabilistic
constrained stochastic programming with stochastically dependent random
variables. The application was done by Pre´ kopa et al. and was presented at the
First International Conference on Stochastic Programming held in Oxford,
England, 1974 (see Pre´ kopa et al. (1980)). The model was based on a deter-
ministic model that had been formulated earlier. The number of stochastic
constraints is four in the stochastic model. Let G(x) designate the probability
that all these are satisﬁed. Let further xlin and xstoch designate the optimal
solutions of the deterministic and stochastic problems, respectively. An
interesting phenomenon turned up. The reliability level of the joint probability
of the stochastic constraints, taken with xlin, was only 0.1, whereas the
optimum value cTx subject
to
G(x)  p, and the other deterministic
constraints, came out as (almost) the same as cTxlin, i.e., cTxlin ¼ cTxstoch, in
both the p ¼ 0.9 and p ¼ 0.95 cases. Thus, in case of each p, an optimal
solution, providing us with high reliability in power service, could be obtained
with no additional cost as compared to the optimal cost in the deterministic
problem. The optimal solutions xlin and xstoch, however, were diﬀerent.
Normal distribution was used and the method of feasible directions to solve
the problem.
Two-stage optimal capacity design in power networks, with probabilistic
constraint for the solvability of the second stage problem, was formulated in
Pre´ kopa (1980). Numerical solution for a special case of this problem was
presented by Pre´ kopa et al. (1998). Optimal capacity design problems with
probabilistic constraints have been formulated by several authors. Among
them we mention Bloom et al. (1984), Bloom (1988), Cote´ and Laughton
(1982), Bisthoven et al. (1988) and Dodu et al. (1981).
7.2
Water resources
One of the revealing problems, where the use of joint probabilistic
constraint is the only justiﬁed possibility, is a ﬂood control reservoir system
design problem. In its simplest (but nontrivial) version there are only two
possible reservoir sites where capacities x1, x2 have to be determined and these
serve to protect a downstream area from ﬂood that may happen once in a
year, say. If 1, 2 are the water amounts to be retained by the reservoirs (see
Fig. 1 for the topology of the system).
Then the ﬂood will be retained if and only if x1 þ x2  1 þ 2, x2  2
are satisﬁed. Since 1, 2 are random variables, the fulﬁlment of these
inequalities can be guaranteed only on a probability level p, chosen by ourselves.
338
A. Pre´kopa

If c(x1, x2) is the reservoir building cost function, then our stochastic
programming problem is:
min cðx1, x2Þ
subject to
P
x1 þ x2  1 þ 2
x2  2
 
!
 p
0  x1  V1, 0  x2  V2,
ð7:1Þ
where V1, V2 are upper bounds determined by the local geographic situation.
We can see in problem (7.1) that to prescribe probabilistic constraints
separately for the two stochastic constraints has no meaning at all because
they jointly ensure the reliability of the system. The problem was solved under
normal and gamma distributions. The above simple and a more general ﬂood
control problem was formulated and solved by Pre´ kopa and Sza´ ntai (1978b).
The method of supporting hyperplanes was applied to solve the problem.
Further results in this respect are in Kelman et al. (1989), Pre´ kopa Rapcsa´ k
and Zsuﬀa (1978) formulated and solved a reservoir system design problem,
where the possible sites are located along one river. The probabilistic
constraint prescribes the simultaneous probability of retaining the streamﬂow
and serve all demands. Normal distribution was used and the SUMT to solve
the problem.
Pre´ kopa and Sza´ ntai (1976) formulated and solved a multi-period reservoir
system operation problem, using the rolling horizon principle. A multivariate
Fig. 1
Ch. 5. Probabilistic Programming
339

gamma distribution was ﬁtted to the empirical data and was used, together
with the supporting hyperplane method, in the solution of the optimization
problem.
A sequential probability maximization problem was formulated for the
water level regulation of Lake Balaton in Hungary, the largest lake in Central
and Western Europe. A Gaussian process was used to describe the inﬂow
process. The result enabled to improve on the water level regulation reliability
(to keep the water level within prescribed limits) from the former 80% to 97.5%.
Dupacˇ ova´ et al. (1991) compared the diﬀerent reservoir system operation
models and solutions under diﬀerent probability distributions.
7.3
Production and inventory
A reliability type multi-item inventory problem was formulated by Pre´ kopa
and Kelle (1978). Further results are in Kelle (1984, 1985). It is assumed that
during a given period of time the total delivery is the same as the total demand
in each item. However, deliveries take place at random epochs and random
quantities. In order to ensure that all demands be met during the given period,
initial safety stocks are needed. The problem is to minimize their total holding
costs subject to a reliability constraint that serves to ensure the above-
mentionedrequirement.TheSUMTwasusedtosolvetheoptimizationproblem.
Murr and Pre´ kopa (2000) have solved a product substitution problem in
connection with ﬁber manufacturing. The manufacturing process produces
random yield and the problem is to set the original production goals so that all
demands be met, on a given reliability level, with minimum cost. Normal
distribution was assumed and the method of feasible direction was applied
(Sza´ ntai’s code).
Beraldi and Ruszczyn´ ski (2002) formulated and solved the stochastic set
covering problem which has many applications in the production and service
industry. The right hand side random variables i may represent occurrences
of requests for service and the jth column of the technology matrix has
entries that describe capabilities of the diﬀerent facilities to respond to
these requests. The authors have developed their own method to solve the
problem, where both the random variables and the decision variables are
discrete (0–1-valued).
Beraldi and Ruszczyn´ ski (2001) have formulated a probabilistic lot sizing
problem, as an application of their general method to solve probabilistic
constrained stochastic programming problems with integer valued right hand
side random variables. The problem is to minimize the total setup, production
and holding costs subject to the condition that all demands should be met in
the course of the planning horizon.
Singh, Abraham and Akella (1990) formulated and solved a chip
manufacturing problem. Given a number of possible chip sites and chip
types, the problem is to ﬁnd an optimal allocation of types to sites so that the
probability of getting a prescribed non-defective chip composition will be
340
A. Pre´kopa

maximized. In this problem both the random and the decision variables are
nonnegative integer valued.
Henrion et al. (2001) and Henrion and Mo¨ ller (2002) have formulated a
model for a continuous distillation process under stochastic inﬂows in a feed
tank. The problem is to control an extracting process so that lower and upper
level constraints in the feed tank should be met by a large probability. In the
most important case, analysed in this paper regarding the type of randomness,
the inﬂow process is supposed to be Gaussian. For the numerical solution of
the problem Sza´ ntai’s code, to solve the probabilistic constrained problems,
was applied. Similar problem is dealt with in another paper by Henrion et al.
(2001). The above problem appears to have strong connection to the water
level regulation problem of Lake Balaton mentioned in Section 2.
7.4
Telecommunication problems
Some of the most recent works in this area are the following. Dentcheva,
Pre´ kopa and Ruszczyn´ ski (2000) formulated and solved a traﬃc assignment
problem for Time Division Multiple Access (TDMA) satellite communication
systems. The problem has the form:
min
X
n
i¼1
xi
subject to
P
X
n
i¼1
QðiÞxi  D
 
!
 p
x  0, integer,
where QðiÞ, i ¼ 1, . . . , n are m  m permutation matrices and D is an m  m
matrix with nonnegative integer entries (representing demands). The solution
technique that solves the problem, the cone generation technique, is described
in Section 3.2.
Medova and Scott (2000) formulated a quality of service management
problem, where an upper bound is imposed on blocking probabilities. These
are transformed into simpler constraints, by the use of large deviation theory.
Then the total cost of link capacities minus revenues is minimized subject to
the above mentioned constraints.
In her Thesis Heikkinen (2001) formulated an elegant model for the
stochastic power control problem in mobile telecommunication systems. The
model has interesting connection to game theory and von Neumann’s
economic model. Further results are in Heikkinen and Pre´ kopa (2002) and
Gao and Pre´ kopa (2001).
Ch. 5. Probabilistic Programming
341

7.5
Diet problems and food service management
A classical formulation of the deterministic diet problem is an LP: min cTx,
subject to Ax  b, x  0. Here A is an m  n matrix with entries equal to the
nutrient contents of the diﬀerent foods, m is the number of nutrients, n is the
number of foods, b is the nutrient requirement vector and c is the vector of
costs of the unit amounts of the diﬀerent foods.
If one thinks that the food is served for a population, where each individual
has his/her own nutrient requirement vector, then the probabilistic constrained
problem (where we use  rather than b on the right hand side) can be
formulated as:
min cTx
subject to
PðAx  Þ  p
x  0,
ð7:2Þ
to decide on the quantities of foods to be served. In practical problems A may
also be random in which case the solution of the problem becomes hard.
Approximation and solution to problem (7.2), for this case, is presented in
Armstrong and Balintfy (1975). Further papers on the problem include
Balintfy and Pre´ kopa (1966), Balintfy and Armstrong (1980), Lancaster
(1992). There are other formulations of the diet problem too, and given the
underlying problem, there are stochastic programming formulations for the
problem, other than (7.2), as well. Problem (7.2) prescribes that 100p% of the
population should receive all nutrients on at least minimum level. If we
formulate the problem by the use of conditional expectation constraints (see
Section 2.4), then we prescribe upper bounds on the averages of the unserved
nutrients.
In this area another problem is the minimum cost animal feed problem. A
classical work in this respect is the one published by van de Panne and Popp
(1963).
7.6
Finance problems
There are a large number of stochastic programming models applied to
ﬁnancial problems. Most of them, however, that have been formulated so far,
belong to the class of recourse problems. Recently, safety type considerations,
that have existed since the nineteen ﬁfties but have not gained enough
attention during the past decades, came into prominence. The important step
342
A. Pre´kopa

in this direction was the formulation of the concept of Value at Risk (VaR)
and its variants. These notions have already existed in a probabilistic/
statistical framework with the name of quantile and its generalizations or
variants. Before presenting some results in this respect we mention an
application of probabilistic constrained stochastic programming to optimal
portfolio composition.
The classical portfolio models of Markowitz (1952, 1959, 1987) have safety
aspect but it is incorporated into the models in the form of the variance of
the return. Given the expected return, the smaller the variance of the return,
the better the portfolio. Markowitz looks for eﬃcient portfolios which means
that given the expectation of the return, its variance cannot be decreased
and given the variance, the expectation cannot be increased. To illustrate
the power of probabilistic constrained stochastic programming formulation
we present a bond portfolio construction model. Let us introduce the
notations:
n
number of bond types which are candidates for inclusion into the
portfolio
m
number of periods
ai k
cash ﬂow of a bond of type k in period i, k ¼ 1, . . . , n
i ¼ 1, . . . , m
pk
unit price of bond of type k
i
random liability value in period i, i ¼ 1, . . . , m
xk
decision variable, number of bonds of type k to include into the
portfolio
zi
cash carried forward from period i to period i þ 1, i ¼ 1, . . . , m, where
z1 is an initial cash amount that we include into the portfolio and
zmþ1 ¼ 0; zi, i ¼ 1, . . . , m are decision variables
i
rate of interest in period i, i ¼ 1, . . . , m.
If the liabilities were deterministic values then our optimal bond portfolio
model would be the following
min
X
n
k¼1
pkxk þ z1
(
)
subject to
X
n
k¼1
ai kxk þ ð1  iÞzi  ziþ1  i,
i ¼ 1, . . . , m
xk  0,
k ¼ 1, . . . , n
zi  0,
i ¼ 1, . . . , m, zmþ1 ¼ 0:
ð7:3Þ
Ch. 5. Probabilistic Programming
343

The probabilistic constrained variant of it can be formulated as
min
X
n
k¼1
pkxk þ z1
(
)
subject to
P
X
n
k¼1
ai kxk þ ð1  iÞzi  ziþ1  i, i ¼ 1, . . . , m
 
!
 p
xk  0,
k ¼ 1, . . . , n
zi  0,
i ¼ 1, . . . , m,
ð7:4Þ
where p is a safety (reliability) level chosen by ourselves, e.g., p ¼ 0:8, 0:9, 0:95
etc. Some of the liability values (e.g., those corresponding to the early periods)
may be deterministic. Then they should be removed from the probabilistic
constraint in (7.4) and listed separately. The properties and solution methods
of the model can be learned from theorems and methods presented in the
previous sections.
Value at Risk, or VaR has been deﬁned in connection with a random
variable 	 or its probability distribution function F(z) by the equation F(z) ¼ p,
where 0<p<1. If F(z) is strictly increasing then there is exactly one solution
to this equation. Otherwise we may take the smallest z satisfying F(z)  p.
This deﬁnition of VaR is suitable in connection with a random variable that
designates loss. If  designates revenue then we take  ¼  which means loss
and we deﬁne VaR for . The VaR can be deﬁned in connection with a
portfolio, where the total random return is Tx. In this case we may look for
the VaR of the probability distribution of Tx, i.e., for that value of z that
minimizes PðTx  zÞ ¼ PðTx  zÞ subject to the constraint that this
probability is at least p.
A closely related notion is the Conditional Value at Risk (CVaR), deﬁned
in connection with a random variable 	 (or its probability distribution) by
CVaRð	Þ ¼ Eð	 j 	  z > 0Þ,
z ¼ VaRð	Þ:
provided that the distribution is continuous. Other forms of CVaR(	) are:
CVaR ¼
1
1  p
Z1
z
u dFðuÞ,
z ¼ VaRð	Þ
ð7:5Þ
CVaR ¼ inf
a
a þ
1
1  p Eð½	  aþÞ


:
ð7:6Þ
344
A. Pre´kopa

This last form of CVaR is due to Rockafellar and Uryasev (2000).
Minimizing CVaR can be used as a decision principle to compose optimal
portfolios. An example is the following credit risk optimization problem (see
Andersson et al. (2001)). Suppose there are n obligors and let xi, bi, i
designate the weight, the debt and the lost part of it of the ith obligor. Then
the loss function is f(x, ) ¼ (b)Tx . If we replace f(x, ) for 	 in (7.6), then we
obtain the objective function
a þ
1
1  p Eð½ f ðx, Þ  aþÞ
ð7:7Þ
that is to be minimized with respect to x and a. Suppose that there are some
deterministic constraints, expressed by x 2 X, and we approximate the
expectation in (7.7) by the use of a sample with respect to the distribution of
 : y1, . . . , yn, then we obtain the approximate problem:
min
a, x, z a þ
1
1  p
1
N
X
N
i¼1
zi
(
)
subject to
x 2 X
zi  f ðx, yiÞ,
zi  0, i ¼ 1, . . . , N:
Another example is presented in Borgentoft et al. (2001).
There are many other applications of the probabilistic constrained
stochastic programming model and its variant, maximizing a probability
subject to constraints. E.g., Pickens et al. (1991) applies it to forrestry, Pinte´ r
(1991) to environmental problems, Thoft-Christensen and Murotsu (1986)
to engineering structures, Singh, Abraham and Akella (1990) to chip
manufacturing, Shapiro (1986) to insurance, Cooper et al. (1998) to data
envelopment analysis, Kibzun and Kan (1996) to aviation, etc.
References
Abadie, J., J. Carpentier (1969). Generalization of Wolfe reduced gradient method to the case of
nonlinear constraints, in: R. Fletcher (ed.), Optimization, Academic Press.
Andersson, F., H. Mausser, D. Rosen, S. Uryasev (2001). Credit risk optimization with conditional
value at risk criterion. Math. Programming Ser. B 89, 273–291.
Armstrong, R.D., J.L. Balintfy (1975). A chance constrained multiple choice algorithm. Oper. Res. 23,
494–510.
Balintfy, J.L., R.D. Armstrong (1980). A chance constrained multiple choice programming algorithm
with applications in: Stochastic Programming (Proc. Internat. Conf., Univ. Oxford, Oxford,
England, 1974, M.A.H. Dempster). Academic Press, London, New York, pp. 301–325.
Balintfy, J.L., A. Pre´ kopa (1996). Nature of random variation in the nutrient composition of meals.
Health Services Research 1, 148–169.
Barndorﬀ–Nielsen, O. (1973). Unimodality and exponential families. Comm. Stat. 1, 189–216.
Ch. 5. Probabilistic Programming
345

Becker, T., V. Weispfenning (1993). Gro¨bner Bases, Springer, New York.
Beraldi, P., A. Ruszczyn´ ski (1999). The probabilistic set covering problem. RUTCOR Research Reports
88–99. Op. Res. 50, 956–967.
Beraldi, P., A. Ruszczyn´ ski (2002). A branch and bound method for stochastic integer problems under
probabilistic constraints. RUTCOR Research Reports 16, 2001. Optimization Method and Software
17, 359–382.
Bisthoven, O.J., de P. Schuchewytsch, Y. Smeers (1988). Power generation planning with uncertain
demand, in: Y. Ermeliev, R.J.-B. Wets (eds.), Numerical Techniques for Stochastic Optimization,
Springer-Verlag, New York, pp. 465–480.
Bloom, J.A., M. Caramanis, L. Charny (1984). Long-range generation planning using generalized
Benders’ decomposition: implementation and experience. Operations Research 32, 290–313.
Bloom, J.A. (1988). Solving an electricity generating capacity expansion planning problem by
generalized Benders’ decomposition. Operations Research 31, 84–100.
Bogentoft, E., H.E. Romeijn, S. Uryasev (2001). Pension Funds Using CVaR constraints. The Journal
of Risk Finance, 57–71.
Bonferroni, C.E. (1937). Teoria Statistica Delle Classi e Calcolo Delle Probabilita`. Volume in onore di
Riccardo Dalla Volta, Universita` di Firenze, 1–62.
Boole, G. (1854). Laws of Thought. Americam reprint of 1854 edition. Dover, New York.
Borell, C. (1975). Convex set functions in d-space. Periodica Mathematica Hungarica 6, 111–136.
Boros, E., A. Pre´ kopa (1989). Closed form two-sided bounds for probabilities that exactly r and at
least r out of n events occur. Math. Opns. Res. 14, 317–342.
Brascamp, H.J., E.H. Lieb (1976). On extensions of the Brunn-Minkowski and Pre´ kopa-Leindler
theorems, including inequalities for log concave functions, and with an application to the diﬀusion
equations. Journal of Functional Analysis 22, 366–389.
Buksza´ r, J., A. Pre´ kopa (2001). probability bounds with cherry trees. Math. of Oper. Res. 26, 174–192.
Buksza´ r, J., T. Sza´ ntai (2002). Probability bounds given by hypercherry trees. Optimization Methods
and Software 17, 409–422.
Buksza´ r, J. (2001). Probability bounds with multitrees. Adv. Appl. Prob. 33, 437–452.
Burkauskas, A. (1986). On the convexity problem of probabilistic constrained stochastic programming
problems (in Hungarian). Alkalmazott Matematikai Lapok (Applied Mathematical Papers) 12,
77–90.
Charnes, A., W.W. Cooper, G.H. Symonds (1958). Cost horizons and certainty equivalents; an
approach to stochastic programming of heating oil. Management Science 4, 235–263.
Cooper, W.W., Z. Huang, S.X. Li, O.B. Olesen (1998). Chance constrained programming formulations
for stochastic characterizations of eﬃciency and dominance in DEA. J. of Productivity Anal. 9,
53–79.
Cote´ , C., M. Laughton (1982). Stochastic production costing in generation planning: a large-scale
mixed integer model. Mathematical Programming Study.
Davidovich, Yu.S., B.L. Korenblum, B.I. Hacet (1969). A property of logarithmically concave
functions. Soviet Mathematics, Doklady 10, 477–480 (English Translation).
Dawson, D., A. Sankoﬀ(1967). A inequality for probabilities. Proc. Am. Math. Soc. 18, 504–507.
Dea´ k, I. (1980). Three digit Accurate Multiple Normal Probabilities. Numerische Mathematik, 35,
369–380.
Dea´ k, I. (1990). Random Number Generators and Simulation, Akade´ miai Kiado´ , Budapest.
Dea´ k, I. (1998). Linear regression estimators for multinormal distributions in optimization of
stochastic programming problems. EJOR III, 555–568.
Dea´ k, I. (1971). Computer evaluation of a stochastic programming model. Thesis, L. Eo¨ tvo¨ s Univ. of
Budapest (in Hungarian).
Dea´ k, I. (1986). Computing probabilities of rectangles in case of multidimensional distribution. Journal
of Statistical Computation and Simulation 26, 101–114.
Dea´ k, I. (1988). Multidimensional integration and stochastic programming, in: Yu Ermoliev,
R.J.-B. Wets (eds.),
Numerical Techniques for Stochastic Optimization, Springer-Verlag,
Berlin, pp. 187–200.
346
A. Pre´kopa

Dea´ k, I. (2000a). Solving stochastic programming problems by successive regression approximations.
Computational Optimization and Applications (submitted).
Dea´ k, I. (2000b). Subroutins for computing normal probabilities of sets – computer experinces. Annals
of Oper. Res. 100, 103–122.
Dea´ k, I. (2001). Two-stage stochastic problems with correlated normal variables: computational
experiences. Annals of Oper. Res., to appear.
Dea´ k, I. (2002). Probabilities of simple n-dimensional sets for the normal distribution. I.I.E.
Transactions, to appear.
Dentcheva, D., A. Pre´ kopa, A. Ruszczyn´ ski (2000). Concavity and eﬃcient points of discrete
distributions in probabilistic programming. Mathematical Programming Series A. 89, 55–77.
Dert, C.L. (1995). Asset-Liability Management for Pension Funds: A Multistage Chance-Constrained
Programming Approach, PhD Thesis, Erasmus University, Rotterdam.
Dodu, J.C., M. Goursat, A. Hertz, J.P. Quadrat, M. Viot (1981). Methode de gradient stochastique
pour l’optimization des investissement dans un Re´ seau E´ lectrique, Electricite´ de France. Bulletin
Dir. Etudes et Rech. Seriec. Math. 2, 133–164 (in French).
Dupacˇ ova´ , J. (1991). Statistical security analysis in stochastic programming. Annals of Operations
Research 30, 199–214.
Dupacˇ ova´
J., A. Gaivoronski, Z. Kos, T. Sza´ ntai (1991). Stochastic programming in water
management: a case study and a comparsion of solution techniques. Journal of Operations
Research 52, 28–44.
Fekete, M. and Gy. Po´ lya (1912). U¨ ber ein Problem von Laguerre. Rediconti del Circolo Matematico di
Palermo 23, 89–120.
Fiacco,
A.V.,
G.P.
McCormick
(1968).
Nonlinear
Programming:
Sequential
Unconstrained
Minimization Techniques, John Wiley & Sons, New York.
Galambos, J., J. Simonelli (1996). Bonferroni-Type Inequalities with Applications, Springer, New York.
Gao, L., A. Pre´ kopa (2001). On performance prediction of cellular telephone networks. RUTCOR
Research Report.
Gassmann, H.I. (1988). Conditional probability and conditional expectation of a random vector, in:
Y. Ermeliev, R.J.-B. Wets (eds.), Numerical Techniques for Stochastic Optimization, Springer
Verlag, Berlin, Heidelberg, New York, pp. 237–254.
Gassmann, H.I., A. Pre´ kopa (2001). On stages and constraint replication in stochastic programming.
Manuscript.
Gassmann, H.I., I. Dea´ k, T. Sza´ ntai (2002). Computing multivariate normal probabilities. J. of
Computational and Graphical Stat. 11, 920–949.
Genz, A. (1992). Numerical computation of the multivariate normal probabilities. Journal of
Computational and Graphical Statistics 1, 141–150.
Gro¨ we, N. (1995). Numerical Solution and Asymptotic Analysis of Stochastic Programs. Thesis,
Humboldt University, Berlin.
Gro¨ we, N. (1997). Estimated stochastic programs with chance constraint. EJOR 101, 285–305.
Hailperin, Th. (1965). Best possible inequalities for the probability of a logical functions of events, Am.
Math. Monthly 72, 343–359.
Heikkinen, T., A. Pre´ kopa (2002). Optimal power control under probabilistic quality-of-service
constraints. Manuscript.
Heikkinen, T.M. (2001). On resource allocation in externality networks. Thesis, RUTCOR, Rutgers
Center for Operations Research.
Henrion, R., A. Mo¨ ller (2002). Optimization of a continuous distillation process under random inﬂow
rate. Computers and Math. with App., to appear.
Henrion, R., P. Li, A. Mo¨ ller, M. Wendt, G. Wozny (2001). Optimal control of a continuous
distillation process under probabilistic constraints, in: M. Gro¨ tschel, S. Krumke, J. Rambau (eds.)
Optimization of Large Scale Systems, Springer, Berlin, pp. 499–517.
Henrion, R., W. Ro¨ misch (1998). Metric regularity and quantitative stability in stochastic programs
with probabilistic constraints. Mathematical Programming 84, 55–88.
Ch. 5. Probabilistic Programming
347

Henrion, R., W. Ro¨ misch (2000). Stability of solutions to chance constrained stochastic programs, in:
J. Guddat, et al. (eds.), Parametric Optimization and Related Topics V, Peter Lang, Frankfurt a. M,
pp. 95–114.
Henrion, R. (2000). Qualitative stability of convex programs with probabilistic constraints. Lecture
Notes in Economics and Math. Systems 481, 164–180.
Hunter, D. (1976). Bounds for the probability of a union. Journal of Applied Probability 13, 597–603.
Kall, P. (1987). On approximations and stability in stochastic programming, in: Parametric
Optimization and Related Topics, Akademie-Verlag, Berlin, pp. 387–407.
Kall, P., J. Mayer (1996). SLP–IOR: an interactive model management system for stochastic linear
programs. Mathematical Programming 75, 221–240.
Kataoka, S. (1963). A stochastic progamming model. Econometrica 31, 181–196.
Kelle, P. (1984). On the safety stock problem for random delivery processes. European Journal of
Operational Research 17, 191–200.
Kelle, P. (1985). Safety stock planning in a multi-stage production-inventory system. Engineering Costs
and Production Economics 9, 231–237.
Kelman, J., J.M. Damazio, J.L. Marie¨ n, J.P. da Costa (1989). The determination of ﬂood control
volumes in a multireservoir system. Water Resources Research 25, 337–344.
Kibzun, A.I., Y.S. Kan (1996). Stochastic Programming Problems with Probability and Quantile
Functions, Wiley, New York.
Kibzun, A.I., V.Y. Kurbakovszkij (1991). Guaranteeing approach to solving quantile optimization
problems. Annals of Operations Research 30, 81–99.
Klein Haneveld, W.K. (1986). Duality in Stochastic Linear and Dynamic Programming. Lecture Notes
in Economics and Mathematical Systems, Springer-Verlag, New York.
Koma´ romi, E´ (1986a). Duality in probabilistic constrained programming, in: A. Pre´ kopa et al. (eds.),
System Modelling and Optimization. Proceedings of the 12th IFIP Conference 1986, pp. 423–429.
Koma´ romi, E´ . (1986b). A dual method of probabilistic constrained problem. Mathematical
Programming Study 28, 94–112.
Koma´ romi, E´ . (1987). On properties of the probabilistic constrained linear programming problem and
its dual. Journal of Optimization Theory and Applications 55, 337–390.
Kruskal, J. B. (1956). On the shortest spanning subtree of a graph and the traveling salesman problem.
Proceedings of the American Mathematical Society 7, 48–50.
Kwerel, S.M. (1975a). Most stringent bounds on aggregated probabilities of partially speciﬁed
dependent probability systems. J. Am. Statist. Assoc. 472–479.
Kwerel, S.M. (1975b). Bounds on the probability of a union and intersection of m events. Adv. Appl.
Prob. 7, 431–448.
Lancaster, L.M. (1992). The evolution of the diet model in managing food systems. Interfaces 22, 59–68.
Luc, D.T. (1983). Duality in programming under probabilistic constrained problems. Problems of
Control and Information Theory 12, 429–437.
Markowitz, H. (1952). Portfolio selection. Journal of Finance 7, 77–91.
Markowitz, H. (1959). Portfolio Selection, Wiley, New York.
Markowitz, H. (1987). Mean-Variance Analysis in Portfolio Choice and Capital Markets, Blackwell,
New York.
Marti, K. (1988). Descent Directions and Eﬃcient Solutions in Descretely Distributed Stochastic
Programs, in: Lecture Notes in Economics and Mathematical Systems 299, Springer Verlag, Berlin,
New York.
Mayer, J. (1980). A nonlinear programming method for the solution of a stochastic programming
model of A. Pre´ kopa, in: A. Pre´ kopa (ed.), Survey of Mathematical Programming, Vol. 2, North-
Holland, pp. 129–139.
Mayer, J. (1988). Probabilistic constrained programming: a reduced gradient algorithm implemented
on PC. IIASA Working Paper, WP–88–39.
Mayer, J. (2000). On the numerical solution of jointly chance constrained problems.
Probabilistic
Constrained
Optimization:
Methodology
and
Applications,
Kluwer
Academic
Publishers,
pp. 220–233.
348
A. Pre´kopa

Mayer, J. (1992). Computational techniques for probabilistic constrained optimization problems).
Stochastic Optimization, Numerical Methods and Technical Applications, Springer Verlag, Berlin.
Mayer, J. (1998). Stochastic linear programming algorithms: a comparsion based on a model management
system, Gordon and Breach Science Publishers.
Medova, E.A., J.E. Scott (2000). Management of quality of service through chance constraint in
multimedia networks, in: S.P. Uryasev (ed.), Probabilistic Constrained Optimization, Kluwer
Academic Publishers, pp. 236–251.
Murr, M.R., A. Pre´ kopa (2000). Solution of a product substitution problem using stochastic
programming, in: Uryasev, S.P. (ed.), Probabilistic Constrained Optimization, Kluwer, Dordrecht.
Nash, S.G., A. Sofer (1993). A barrier-method for large-scale constrained optimization. ORSA Journal
on Computing 5, 40–53.
Nash, S.G., A. Sofer (1998). Why extrapolation helps barrier methods. Working paper, Department of
Operations Research and Engineering, George Mason University, Fairfax, Va.
Norkin V.I., N.V. Roenko (1991). -concave functions and measures and their applications
Kibernet. Sistem. Anal. 189, 77–88. (in Russian). Translation in: Cybernet. Systems Anal. 27
(1991) 860–869.
Ogryczak, W., A. Ruszczyn´ ski (2002). Dual stochastic dominance and related mean risk models. SIAM
Journal on Optimization 13, 60–78.
Panne, van de C., W. Popp (1963). Minimum Cost Cattle Feed under Probabilistic Problem
Constraints. Management Science 9, 405–430.
Pedersen, J.G. (1975). On strong unimodality and m-ancillarity with applications to contingency
tables. Scandinavian Journal of Statistics 2, 127–137.
Pickens, J.B., J.G. Hof, B.M. Kent (1991). Use of chance-constrained programming to account for
stochastic variation in the A-matrix of large scale linear programs: a forestry application. Annals of
Operations Research 31, 511–526.
Pinte´ r, J. (1991). Stochastic modelling and optimization for envirenmental management. Annals of
Operations Research 31, 527–544.
Pre´ kopa, A. (1999). The use of discrete moment bounds in probabilistic constrained stochastic
programming models. Annals of Operations Research 85, 21–38.
Pre´ kopa, A. (1972a). A class of stochastic programming decision problems. Matematische Operations
forschung und Statistik, 349–354.
Pre´ kopa,
A.
(1973b).
On
logarithmic
concave
measures
and
functions.
Acta
Scientiarium
Mathematicarum (Szeged) 34, 335–343.
Pre´ kopa, A. (2001a). On the concavity of multivariate probability distributions. Operations Research
Letters 29, 1–4.
Pre´ kopa, A., B. Vı´zva´ ri, T. Badics (1998). Programming under probabilistic constraint with discrete
random variable, in: Giannessi et al. (ed.), New Trends in Mathematical Programming, Kluwer,
Dordrecht, Boston, pp. 235–255.
Pre´ kopa, A., P. Kelle (1978). Reliability-type inventory models based on stochastic programming.
Math. Programming Study 9, 43–58.
Pre´ kopa, A., T. Sza´ ntai (1976). On Multi-Stage Stochastic Programming.
Colloquia Mathematica
Societas Ja´nos Bolyai, North Holland Publishing Company, pp. 733–755.
Pre´ kopa, A., T. Sza´ ntai (1978a). A new multivariate gamma distribution and its ﬁtting to empirical
streamﬂow data. Water Resources Research 14, 19–24.
Pre´ kopa, A., T. Sza´ ntai (1978b). Flood control reservoir system design using stochastic programming.
Math. Programming Study 9, 138–151.
Pre´ kopa, A., T. Sza´ ntai (1979). On optimal regulation of a storage level with application to the water
level regulation of a lake. European Journal of Operations Research 3, 175–189, also in: Survey of
Math Prog Publ. House of the H. A. S. Budapest, Vol. II, 183–210.
Pre´ kopa A., B. Vı´zva´ ri, G. Rego¨ s, L. Gao (2001). Bounding the probability of the union of events by
the use of aggregation and disaggregation of linear programs. RUTCOR Research Report 99–97.
Submitted to Discrete Applied Math.
Ch. 5. Probabilistic Programming
349

Pre´ kopa, A., T. Rapcsa´ k, I. Zsuﬀa (1978). Serially linked reservoir system design using stochastic
programming. Water Resources Research 14, 672–678.
Pre´ kopa, A., S. Ganczer, I. Dea´ k, K. Patyi (1980). The STABIL stochastic programming model and its
experimental application to the electrical energy sector of the Hungarian economy, in: M.A.H.
Dempster (ed.), Stochastic Programming, Academic Press, London, pp. 369–385.
Pre´ kopa, A. (1965). Reliability equation for an inventory problem and its asymptotic solutions.
Colloquium on Appl. of Math. to Economics, Publ. House. of the Hungarian Acad. Sci., Budapest,
pp. 317–327.
Pre´ kopa, A. (1970)
On Probabilistic Constrained Programming Proceedings of the Princeton
Symposium on Math. Prog, Princeton University Press, Princeton, NJ, pp. 113–138.
Pre´ kopa, A. (1971). Logarithmic concave measures with applications to stochastic programming. Acta
Scientiarium Mathematicarum (Szeged) 32, 301–316.
Pre´ kopa, A. (1973a). Contributions to the theory of stochastic programming. Math. Progr. 4, 202–221.
Pre´ kopa, A. (1973c). Stochastic programming models for inventory control and water storage. Coll.
Math. Soc. J. Bolyai 7, North-Holland, Amsterdam, pp. 229–245.
Pre´ kopa, A. (1974b). Programming under probabilistic constraints with a random technology matrix.
Matematische Operationsforschung und Statistik, Ser. Optimization 5, 109–116.
Pre´ kopa, A. (1980a). Logarithmic concave measures and related topics, in: M.A.H. Dempster (ed.),
Stochastic Programming, Academic Press, London, pp. 63–82.
Pre´ kopa, A. (1980b). Network planning using two-stage programming under uncertainty, in: Recent
Results in Stochastic Programming, Lecture Notes in Economics and Mathematical Systems, Springer-
Verlag, Berlin, pp. 216–237.
Pre´ kopa, A. (1985). Recent results in optimization of electro-energetic systems. Proceedings of the
Conference Applied Optimization Techniques in Energy Problems (June 25–29, 1984, Linz,
Austrlia, Hj. Wacker, ed.), Teubner, Stuttgart, pp. 354–383.
Pre´ kopa, A. (1988). Boole-Bonferoni inequalities and linear programming. Operations Research 36,
145–162.
Pre´ kopa, A. (1988). Numerical solution of probabilistic constrained programming problems
Numerical Techniques for Stochastic Optimization, Springer, New York, pp. 123–139.
Pre´ kopa, A. (1990). Dual method for the solution of a one-stage stochastic programming problem with
random RHS obeying a discrete probality distribution. ZOR Methods and Models of Operations
Research 34, 441–461.
Pre´ kopa, A. (1990a). Sharp bound on probabilities using linear programming. Operations Research 38,
227–239.
Pre´ kopa, A. (1995). Stochastic Programming, Kluwer Academic Publishers, Dordrecht, Boston.
Pre´ kopa, A. (2001b). Discrete higher order convex functions and their applications. Generalized
convexity and monotonicity, in: N. Hadjisavvas et al. (eds.), Lecture Notes in Economics and
Mathematical Systems, Springer, Berlin, pp. 21–47.
Raik, E. (1971). The quantile function in stochastic nonlinear programming (in Russian). Eesti NSV
Teaduste Akademia Toimetised (News of the Estonian Academy of Sciences) Fu¨u¨s. Mat. 20,
229–231.
Raik, E. (1972). On the stochastic programming problem with the probability and quantile functionals
(in Russian). Eesti NSV Teaduste Akademia Toimetised (News of the Estonian Academy of
Sciences) Fu¨u¨s. Mat. 21, 142–148.
Raik, E. (1970). Inequalities in problems of stochastic programming (in Russian). Eesti NSV Teaduste
Akademia Toimetised (News of the Estonian Academy of Sciences) Fu¨u¨s. Mat. 19, 292–298.
Raik, E. (1971). Qualitative research into the stochastic nonlinear programming problems (in Russian).
Eesti NSV Teaduste Akademia Toimetised (News of the Estonian Academy of Sciences) Fu¨u¨s. Mat.
20, 8–14.
Rapcsa´ k, T. (1974). On the Numerical Solution of a Reservoir Model. Ph.D. Thesis, University of
Debrecen, Hungary (in Hungarian).
Rinott, Y. (1976). On convexity of measures. Annals of Probability 4, 1020–1026.
350
A. Pre´kopa

Rockafellar, R.T., S. Uryasev (2000). Optimization of conditional value at risk. The Journal of Risk 2,
21–41.
Ro¨ misch, W., R. Schultz (1991). Distribution sensitivity for certain classes of chance-constrained
models with application to power dispatch. J. Optimization Theory Appl. 71, 569–588.
Roy, A.D. (1952). Safety ﬁrst and the holding of assets. Econometrica 20, 431–449.
Salinetti, G. (1983). Approximations for chance constrained programming problems. Stochastics 10,
157–169.
Sathe, Y.S., M. Pradhan, S.P. Shah (1980). Inequalities for the probability of the occurence of at least
m out of n events. J. Appl. Prob. 17, 1127–1132.
Sen, S. (1992). Relaxations for the probabilistically constrained programs with discrete random
variables. Operations Research Letters 11, 81–86.
Shapiro, A.F. (1986). Applications of operations research techniques in insurance, in: Goovaerts et al.
(eds.), Insurance and Risk Theory, pp. 129–143.
Singh, M.R., C.T. Abraham, R. Akella (1990). Wafer design problem in semiconductor manufacturing
for reliable customer service. IEEE Transaction on Components. Hybrids and Manufacturing
Technology 13, 103–108.
Slepian, D. (1962). On the one-sided barrier problem for Gaussian noise. Bell System Technical Journal
41, 463–501 .
Stancu-Minasian, I.M. (1984). Stochastic Programming with Multiple Objective Functions, Reidel
Publishing Company, Boston.
Sza´ ntai, T. (1985). On the numerical computation on probabilities in connection with multivariate
probability distributions. Thesis, Hung. Acad. Sci. (in Hungarian).
Sza´ ntai, T. (1988). A computer code for solution of probabilistic-constrained stochastic programming
problems,
Y. Ermoliev, R.J.-B. Wets (eds.),
Numerical Techniques for Stochastic Optimization
Springer-Verlag, Berlin, pp. 229–235.
Sza´ ntai, T. (1986). Evaluation of a special multivariate gamma distribution. Mathematical
Programming Study 27, 1–16.
Sza´ ntai, T. (2000). Improved bounds and simulation procedures on the value of the multivariate
normal probability distribution function. Annals of Oper. Res.100, 85–101.
Sza´ ntai, T. (2001). Approximation of multivariate probability integrals, in: P.M. Pardalos, C.A.
Floudas (eds.) Encyclopedia of Optimization, Kluwer Academic Publishers.
Taka´ cs, L. (1967). On the method of inclusion and exclusion. J. of the Amer. Math. Association 62,
102–113.
Tamm, E. (1977). On g-concave functions and probability measures. Eesti NSV Teaduste Akademia
Toimetised (News of the Estonian Academy of Sciences) Fu¨u¨s. Mat. 26, 376–379.
Tayur S.L., R.L. Thomas, N.R. Natraj (1995). An algebraic geometry algorithm for scheduling in the
presence of setups and correlated demands. Mathematical Programming 69, 369–401.
Thoft-Christensen, P., Y. Murotsu (1986). Applications of Structural Systems Reliability Theory,
Springer-Verlag, New York.
Uryas’ev, S. (1989). A diﬀerentiation formula for integrals over sets given by inclusion. Numerical
Functional Analysis and Optimization 10, 827–841.
Uryasev, S. (2001). Derivatives of probability and integral functions, in: P.M. Pardalos, C. M. Floudas
(eds.), Encyclopedia of Optimization, Kluwer Academic Publishers.
Vanderbei R.J., D.F. Shanno (2000). Interior-point algorithms for nonconvex nonlinear programming:
orderings and higher-order methods, Math. Prog. 87, 303–316.
Veinott, A.F. (1967). The supporting hyperplane method for unimodal programming. Operations
Research 15, 147–152.
Vı´zva´ ri, B. (1987). Beitra¨ge zum Frobenius Problem, D. Sc. Nat. Dissertation, Technische Hochschule
Carl Schorlemmer, Leuna-Merseburg, Germany.
Vı´zva´ ri, B. (2002). The integer programming background of a stochastic integer programming
algorithm of Dentcheva-Pre´ kopa-Ruszczyn´ ski, Optimization Methods and Software 17, 543–559.
Worsley, K.J. (1982). An improved Bonferroni inequality and applications. Biometrica 69, 297–302.
Zoutendijk, G. (1960). Methods of Feasible Directions. Elsevier Publishing Co. Amsterdam, New York.
Ch. 5. Probabilistic Programming
351

Chapter 6
Monte Carlo Sampling Methods
Alexander Shapiro
School of Industrial and Systems Engineering, Georgia Institute of Technology,
Atlanta, GA 30332, USA
Abstract
In this chapter we discuss Monte Carlo sampling methods for solving large scale
stochastic programming problems. We concentrate on the ‘‘exterior’’ approach
where a random sample is generated outside of an optimization procedure, and
then the constructed, so-called sample average approximation (SAA), problem is
solved by an appropriate deterministic algorithm. We study statistical properties
of the obtained SAA estimators. The developed statistical inference is
incorporated into validation analysis and error estimation. We describe some
variance reduction techniques which may enhance convergence of sampling
based estimates. We also discuss diﬃculties in extending this methodology to
multistage stochastic programming. Finally, we brieﬂy discuss the SAA method
applied to stochastic generalized equations and variational inequalities.
Key words:
Two-stage stochastic programming, Monte Carlo sampling,
sample average approximation, consistency of estimators, Law of Large
Numbers, exponential rates of convergence, conditioning of stochastic
problems, validation analysis, variance reduction techniques, multistage
stochastic programming, conditional sampling, stochastic generalized equations,
variational inequalities.
1
Introduction
Let us consider a stochastic programming problem in the form
Min
x2X f f ðxÞ :¼ E½Fðx, nÞg,
ð1:1Þ
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
353

where F(x, ) is a function of two vector variables x 2 Rn and  2 Rd, X  Rn is
a given set and n ¼ (!) is a random vector. The expectation in (1.1) is taken
with respect to the probability distribution of n which assumed to be known.
In some applications considered in this chapter, the underlying probability
space of the elementary events ! will be irrelevant. Therefore, in order
to distinguish between random data and their numerical values we often use
the bold script like n for the random vector (!), and  for its particular
realization (numerical value). We denote by   Rd the support of the
probability distribution of n, that is,  is the smallest closed set in Rd such that
the probability of the event n 2 Rd\ is zero. We denote by Prob(A) or P(A)
the probability of an event A.
Often one can view the optimization problem (1.1) as a two-stage stochastic
programming problem with F(x, ) and  being the optimal value and data
vector, respectively, of the corresponding second stage program. For example,
in the case of two-stage linear stochastic programming with recourse,
F(x, ) :¼ cTx þ Q(x, ), where Q(x, ) is the optimal value of the following
second stage problem
Min
y2Rm qTy
subject to
Tx þ Wy ¼ h, y  0,
ð1:2Þ
with  :¼ (q, T, W, h). As such we need to consider situations where F(x, ) can
take values þ 1 or 1. That is, unless stated otherwise, we assume that
F(x, ) is an extended real valued function and the expected value E[F(x, n)] is
well deﬁned for every considered x 2 Rn (see the Appendix of chapter
‘‘Stochastic Programming Models’’ for a discussion of the concept of ‘‘well
deﬁned’’ expected value). It is also important to notice that it is implicitly
assumed in the above setting that for any x 2 X and  2  the value F(x, ) can
be eﬃciently calculated. This generally holds true for two-stage programming.
For multistage programming, however, the situation is more delicate, we will
discuss this in Section 6.
If n has a ﬁnite number of possible realizations (called scenarios), say
 ¼ {1, . . . , K} with respective (positive) probabilities pk, k ¼ 1, . . . , K, then
we can write the expected value function in the form
f ðxÞ ¼
X
K
k¼1
pkFðx, kÞ:
ð1:3Þ
Note, however, that even a crude discretization of the probability distribution
of n leads to an exponential growth of the number of scenarios. For example,
if components of the random vector n are independent, each having just three
possible realizations, then the total number of scenarios K ¼ 3d. No computer
in a foreseeable future will be able to handle calculations involving 3100
scenarios. Therefore, that way or another, one needs to reduce the number of
354
A. Shapiro

scenarios to a manageable level. In this chapter we discuss an approach to
solving the expected value problem (1.1), referred to as the true optimization
problem, by using Monte Carlo sampling techniques.
Suppose that we can generate a sample of N replications of the random
vector n. In the Monte Carlo sampling method this is accomplished by
generating a random (or rather pseudorandom) sequence U1, U2, . . . , of
numbers independent of each other and uniformly distributed on the interval
[0, 1], and then constructing a sample of n by an appropriate transformation.
In that way we can consider the sequence ! :¼ {U1, U2, . . . } as an element
of
the
probability
space
equipped
with
the
corresponding
(product)
probability measure, and the sample ni ¼ i(!), i ¼ 1, 2, . . . , as a function of
!. We can view the generated sample n1, n2, . . . , as a sequence of random
vectors, each having the same probability distribution as n. If the generated
random vectors are (stochastically) independent of each other, we say that the
sample is independent identically distributed (iid). By 1, 2, . . . , we denote a
particular realization of the considered random sample.
With the generated sample 1, . . . , N, we associate the sample average
function
^fNðxÞ :¼ 1
N
X
N
i¼1
Fðx, iÞ:
ð1:4Þ
Note again that for any x 2 X, the sample average ^fNðxÞ can be viewed as a
numerical value associated with the generated sample or as a random variable.
Which one of these two meanings will be used in a particular situation will be
clear from the context.
Since each ni has the same probability distribution as n, we have that for
any x 2 X, E[F(x, ni)] ¼ f(x) and hence
E ^fNðxÞ
h
i
¼ f ðxÞ:
ð1:5Þ
That is, ^fNðxÞ is an unbiased estimator of f(x). Moreover, under various
conditions the Law of Large Numbers (LLN) can be applied1 with the
implication that ^fNðxÞ converges with probability one (w.p.1) to f(x) as
N ! 1. In that case we say that ^fNðxÞ is a consistent estimator of f(x). This
certainly holds true if the sample is iid.
For the purpose of solving a particular stochastic programming problem,
sampling techniques can be applied in diﬀerent ways. One approach uses
sampling in an ‘‘interior’’ fashion. Such algorithms aim at solving the
considered problem by resorting to sampling whenever the procedure requires
to compute (approximately) the value, and may be derivatives, of the expected
1 Note again that we allow for f(x) to take values þ 1 or 1.
Ch. 6. Monte Carlo Sampling Methods
355

value function at a current iteration point. Typically such an algorithm is
tailored for a speciﬁc class of optimization problems and tries to mimic its
deterministic counterpart. Often diﬀerent samples are used each time the true
function or its derivatives are estimated at diﬀerent iteration points. Several
such algorithms were suggested with a diﬀerent level of statistical and
convergence analysis.
In this chapter we mainly discuss an alternative approach, referred to as the
‘‘exterior’’ method. First, a sample 1, . . . , N is generated, and then the true
problem (1.1) is approximated by the optimization problem
Min
x2X
^fNðxÞ ¼ 1
N
X
N
i¼1
Fðx, iÞ
(
)
:
ð1:6Þ
Note that once the sample is generated, i.e., numerical values of vectors
1, . . . , N are computed,
^fNðxÞ becomes a deterministic function and its
value can be calculated at any given point x 2 X. From an optimization point
of view, problem (1.6) can be considered as a stochastic programming
problem with the ﬁnite set {1, . . . , N} of scenarios each with equal
probability N1. Therefore, any numerical algorithm suitable for the
considered class of problems can be applied to (1.6). The optimal value ^vN
and an optimal solution ^xN of the problem (1.6) are considered as statistical
estimators of their counterparts of the true problem (1.1).
The above approach is called ‘‘exterior’’ since the sample is generated
outside of the considered optimization problem, and then the constructed
problem (1.6) is solved by an appropriate deterministic algorithm. It should be
noted that this method is not an algorithm, but rather a general approach to
solving stochastic programs. One still needs to employ a particular (hopefully
eﬃcient) deterministic algorithm in order to solve the obtained problem (1.6).
The basic idea of the ‘‘exterior’’ approach is simple indeed and the method
was suggested by several authors in diﬀerent contexts under various names.
We refer to (1.6) as the sample average approximation (SAA) problem. The
approach is also known as the sample path or the stochastic counterpart
method.
Let us also remark that values of the sample average function ^fNðxÞ can be
computed in two somewhat diﬀerent ways. The generated sample 1, . . . , N
can be stored in the computer memory, and called every time a new value of
the sample average function should be computed. In another way the same
sample is computed by using the common random number generator at every
iteration of the numerical procedure. Which one to use depends on
convenience of a particular application.
The idea of common random number generation is well known in
simulation. That is, suppose that we want to compare values of the objective
function at two points x1, x2 2 X. In that case we are interested in the
356
A. Shapiro

diﬀerence f(x1)f(x2) rather than in the individual values f(x1) and f(x2). If we
use sample average estimates ^fNðx1Þ and ^fNðx2Þ based on independent samples,
both of size N, then
Var ^fNðx1Þ  ^fNðx2Þ
h
i
¼ Var ^fNðx1Þ
h
i
þ Var ^fNðx2Þ
h
i
:
ð1:7Þ
On the other hand, if we use the same sample for the estimators ^fNðx1Þ and
^fNðx2Þ, then
Var ^fNðx1Þ ^fNðx2Þ
h
i
¼Var ^fNðx1Þ
h
i
þVar ^fNðx2Þ
h
i
2Cov ^fNðx1Þ, ^fNðx2Þ


:
ð1:8Þ
In both cases,
^fNðx1Þ  ^fNðx2Þ is an unbiased estimator of f(x1)f(x2).
However, in the case of the same sample the estimators
^fNðx1Þ and
^fNðx2Þ tend to be positively correlated with each other, in which case the
variance in (1.8) is smaller than the one in (1.7). The diﬀerence between the
independent and the common random number generated estimators of
f(x1)f(x2) can be especially dramatic when the points x1 and x2 are close to
each other and hence the common random number generated estimators are
highly correlated.
There are several advantages in the exterior approach as compared with
interior methods. One advantage is simplicity of the exterior method. In the
following sections we discuss convergence properties of statistical estimators
derived by the SAA method. For such statistical analysis a particular
numerical algorithm applied to solve the SAA problem is irrelevant.
2
Statistical properties of SAA estimators
In this section we discuss statistical properties of the optimal value ^vN
and the set
^SN of optimal solutions of the SAA problem (1.6). Unless
stated otherwise we assume that the set X is nonempty and closed. We
denote by v* and S the optimal value and the set of optimal solutions,
respectively, of the true problem (1.1). For sets A, B  Rn we denote by
dist(x, A) :¼ infx 0 2 A jjxx0jj the distance from x 2 Rn to A, and by
DðA, BÞ :¼ sup
x2A
distðx, BÞ
and
HðA, BÞ :¼ maxfDðA, BÞ, DðB, AÞg
ð2:1Þ
Ch. 6. Monte Carlo Sampling Methods
357

the deviation of the set A from the set B and the Hausdorﬀdistance between
the sets A and B, respectively. By the deﬁnition, dist(x, A) ¼ þ 1 if A is
empty, and H(A, B) ¼ þ 1 if A or B is empty.
As it was mentioned earlier, we assume that the expected value f(x) is well
deﬁned for every considered point x 2 Rn. That is, F(x,  ) is measurable, with
respect to the Borel sigma algebra of Rd, and either E[F(x, n) þ] or
E[F(x, n) þ] is ﬁnite. If we view the random vector n ¼ (!) as a measurable
mapping deﬁned on a probability space (, F, P), then the above measura-
bility requirement can be formulated as the F-measurability of F(x, (  )).
We also assume that the integrand function F(x, (!)) is random lower
semicontinuous (random lsc). Assuming that F is P-complete, this holds if
F(  ,  ) is measurable, with respect to the Borel sigma algebra of Rn  Rd, and
F(  , )
is
lower
semicontinuous
for
every
 2 .
We
can
also
view
^fNðxÞ ¼ ^fNðx, !Þ as a sequence of random functions deﬁned on the same
probability space (, F, P). The above assumption that F is random lsc
implies that the optimal value ^vN ¼ ^vNð!Þ, of the SAA problem, and the
multifunction !  ^SNð!Þ are measurable. Consequently, Dð ^SN, SÞ is measur-
able and there exists a measurable selection ^xN 2 ^SN. This takes care of
measurability of the considered statistical estimators. We refer to the
Appendix of chapter ‘‘Stochastic Programming Models’’ for a more detail
discussion of these concepts.
Let us observe that the feasible set X can be absorbed into the objective
function. That is, deﬁne2 Fðx, Þ :¼ Fðx, Þ þ iXðxÞ, i.e.,
Fðx, Þ :¼
Fðx, Þ,
if x 2 X,
þ1,
if x 62 X:

ð2:2Þ
The true problem (1.1) can then be written in the form
Min
x2Rn f ðxÞ :¼ E½Fðx, nÞ


:
ð2:3Þ
Similarly, the SAA problem (1.6) can be writted as
Min
x2Rn
~fNðxÞ :¼ 1
N
X
N
i¼1
Fðx, iÞ
(
)
:
ð2:4Þ
Note that f ðxÞ ¼ f ðxÞ þ iXðxÞ and ~fNðxÞ ¼ ^fNðxÞ þ iXðxÞ.
2 Recall that iX denotes the indicator function of the set X, i.e., iX(x) ¼ 0 if x 2 X and iX(x) ¼ þ 1 if
x 62 X.
358
A. Shapiro

2.1
Consistency of SAA estimators
We say that ^vN is a consistent estimator of v* if ^vN converges w.p.1 to v* as
N ! 1. Similarly, we say that an optimal solution ^xN of the SAA problem is
consistent if distð ^xN, SÞ tends to zero w.p.1 as N ! 1. If S ¼ {x*} is a
singleton, this means that ^xN ! x* w.p.1. In the case of nonunique optimal
solutions, we would like to ensure that every ^xN is consistent. That is, we
would like to have that Dð ^SN, SÞ ! 0 w.p.1. We also consider the set S" of
"-optimal solutions of the true problem. That is, for "  0 we say that x is
an
"-optimal
solution
of
the
true
problem
if
f ðxÞ
is
ﬁnite3
and
f ðxÞ  infx2X f ðxÞ þ ". Similarly is deﬁned the set ^S"
N of "-optimal solutions
of the SAA problem.
Deﬁnition 1. We say that the LLN holds, for
^fNðxÞ, pointwise if
^fNðxÞ
converges w.p.1 to f(x), as N ! 1, for any ﬁxed x 2 Rn.
If the sample is iid, then the LLN holds4 pointwise provided that the
expected value f(x) is well deﬁned. Unfortunately, such pointwise convergence
of ^fNðxÞ to f(x) does not necessarily imply convergence of ^vN to v*. In order to
ensure consistency of ^vN we need a uniform, or more generally epicon-
vergence, type of convergence. The analysis is relatively simple in the convex
case, which we consider ﬁrst.
As it was mentioned earlier we can view ^fNðxÞ ¼ ^fNðx, !Þ as a sequence of
random functions deﬁned on a common probability space (, F, P). Another
way of saying that an event happens w.p.1 is to say that it happens for almost
every (a.e.) ! 2 , i.e., it happens for all ! 2 \ where  is an F-measurable
subset of  such that P() ¼ 0. We also say that an event happens w.p.1
for N large enough if for a.e. ! 2  there exists M(!) 2 R such that the
event happens for all N  M(!). We say that the functions ^fN epiconverge to
f w.p.1, written
^fN!
e f
w.p.1, if for a.e. ! 2  the functions
^fNð, !Þ
epiconverge5 to f(  ). The following result is a simple consequence of
Theorem 25 from Section 8.1 in the Appendix.
Proposition 2. Suppose that for almost every  2  the function F(  , )
is convex, the expected value function f(  ) is lower semicontinuous and its
domain, dom f, has a nonempty interior, and the LLN holds pointwise. Then
^fN!
e f w.p.1.
3 Note that we assume here that if x* is an optimal or "-optimal solution of the true problem, then
f(x*) is ﬁnite. Therefore, if the true problem possesses an optimal solution, then v* is ﬁnite. Also v* is
ﬁnite iﬀfor any ">0 the true problem has an "-optimal solution.
4 Often, LLN which ensures convergence w.p.1, is called strong Law of Large Numbers as opposed to
weak LLN which ensures only convergence in probability. Since in this chapter we deal only with the
strong LLN we omit the word ‘‘strong’’.
5 See the Appendix for the deﬁnition of epiconvergence of a sequence of deterministic functions.
Ch. 6. Monte Carlo Sampling Methods
359

Proof. It follows from the assumed convexity of F(  , ) that the function f(  )
is convex and that w.p.1 the functions ^fNðÞ are convex. Let us choose a
countable and dense6 subset D of Rn. By the pointwise LLN we have that for
any x 2 D, ^fNðxÞ converges to f(x) w.p.1 as N ! 1. This means that there
exists a set x   of P-measure zero such that for any ! 2 \x, ^fNðx, !Þ
tends to f(x) as N ! 1. Consider the set  :¼ [ x 2 D x. Since the set D
is countable and P(x) ¼ 0 for every x 2 D, we have that P() ¼ 0. We also
have that for any ! 2 \, ^fNðx, !Þ converges to f (x), as N ! 1, pointwise on
D. It follows then by Theorem 25 that ^fNð, !Þ!
e f ðÞ for any ! 2 \. That is,
^fNðÞ!
e f ðÞ w.p.1.
u
As it was mentioned in the above proof, convexity of f(  ) follows from
convexity of F(  , ),  2 . Also, by Fatou’s lemma, lower semicontinuity of
f(  ) is implied by lower semicontinuity of F(  , ),  2 , under the additional
assumption that F(x,  ) is bounded from below by an integrable function (see
the Appendix of chapter ‘‘Stochastic Programming Models’’).
By the assertion (iii) of Theorem 25 we obtain the following corollary.
Corollary 3. Suppose that for almost every  2  the function F(  , ) is convex
and the LLN holds pointwise. Let C be a compact subset of Rn such that f(  )
is ﬁnite valued on a neighborhood of C. Then ^fN!
e f converges to f uniformly
on C, that is
sup
x2C
j ^fNðxÞ  f ðxÞj ! 0
w:p:1 as N ! 1:
ð2:5Þ
By the result (8.3) of Proposition 24 we have that ^fN!
e f , w.p.1, implies that
lim sup
N!1
^vN  v*,
w:p:1:
ð2:6Þ
Without an additional assumption the inequality in (2.6) can be strict. In
addition to convexity we need a boundedness type condition to ensure
consistency of ^vN.
Theorem 4. Suppose that: (i) the integrand function F is random lower
semicontinuous, (ii) for almost every  2  the function F(  , ) is convex, (iii) the
set X is closed and convex, (iv) the expected value function f is lower semi-
continuous and there exists a point x 2 X such that f(x)< þ 1 for all x in a
neighborhood of x, (v) the set S of optimal solutions of the true problem is
nonempty and bounded, (vi) the LLN holds pointwise. Then ^vN ! v* and
Dð ^SN, SÞ ! 0 w.p.1 as N ! 1.
6 It is said that D is a dense subset of Rn if for any point x 2 Rn and ">0 there exists a point x0 2 D such
that jjxx0jj<".
360
A. Shapiro

Proof. Clearly we can restrict both the true and the SAA problems to the
aﬃne space generated by the convex set X. Relative to that aﬃne space the set
X has a nonempty interior. Therefore, without loss of generality we can
assume that the set X has a nonempty interior. Since it is assumed that
f(x) possesses an optimal solution, we have that v* is ﬁnite and hence
f(x)  v*>1 for all x 2 X. Since f(x) is convex and is greater than 1 on
an open set (e.g., interior of X), it follows that f(x) is proper.
Now let f ðxÞ and ~fNðxÞ be extended real valued functions deﬁned in
(2.3) and (2.4), respectively. Observe that the pointwise LLN for F(x, )
(assumption (vi)) implies the corresponding pointwise LLN for Fðx, Þ. Since
X is convex and closed, it follows that f is convex and lower semicontinuous.
Moreover, because of the assumption (iv) and since the interior of X is
nonempty, we have that dom f has a nonempty interior. By Proposition 2 it
follows then that ~fN!
e f w.p.1. Consider a compact set K with a nonempty
interior and such that it does not contain a boundary point of dom f , and f ðxÞ
is ﬁnite valued on K. Since dom f has a nonempty interior such set exists. Then
it follows from ~fN!
e f , that ~fNðÞ converge to f ðÞ uniformly on K, all w.p.1 (see
Theorem 25). It follows that w.p.1 for N large enough the functions ~fNðxÞ are
ﬁnite valued on K, and hence are proper.
Now let C be a compact subset of Rn such that the set S is contained in the
interior of C. Such set exists since it is assumed that the set S is bounded.
Consider the set ~SN of minimizers of ~fNðxÞ over C. Since C is nonempty and
compact and ~fNðxÞ is lower semicontinuous and proper for N large enough,
and because by the pointwise LLN we have that for any x 2 S, ~fNðxÞ is ﬁnite
w.p.1 for N large enough, the set ~SN is nonempty w.p.1 for N large enough.
Let us show that Dð ~SN, SÞ ! 0 w.p.1. Let ! 2  be such that ~fNð, !Þ !
e f ðÞ.
We have that this happens for a.e. ! 2 . We argue now by a contradiction.
Suppose that there exists a minimizer ~xN ¼ ~xNð!Þ of ~fNðx, !Þ over C such that
distð ~xN, SÞ  " for some ">0. Since C is compact, by passing to a subsequence
if necessary, we can assume that ~xN tends to a point x 2 C. It follows that
x 62 S. On the other hand, we have by Proposition 24 that x 2 arg minx2C f ðxÞ.
Since arg minx2C f ðxÞ ¼ S, we obtain a contradiction.
Now because of the convexity assumptions, any minimizer of ~fNðxÞ over C
which lies inside the interior of C, is also an optimal solution of the SAA
problem (2.4). Therefore, w.p.1 for N large enough we have that ~SN ¼ ^SN.
Consequently, we can restrict both the true and the SAA optimization
problems to the compact set C, and hence the assertions of the above
proposition follow.
u
Let us make the following observations. It was assumed in the above
proposition that the LLN holds pointwise for all x 2 Rn. Actually it suﬃces to
assume that this holds for all x in some neighborhood of the set S. Under the
assumptions of the above theorem we have that f(x)>1 for every x 2 Rn.
The above assumptions do not prevent, however, for f(x) to take value þ 1 at
some points x 2 X. Nevertheless, it was possible to push the proof through
Ch. 6. Monte Carlo Sampling Methods
361

because in the considered convex case local optimality implies global
optimality. There are two possible reasons why f(x) can be þ 1. Namely, it
can be that F(x,  ) is ﬁnite valued but grows suﬃciently fast so that its integral
is þ 1, or it can be that F(x,  ) is equal þ 1 on a set of positive measure, and
of course it can be both. For example, in the case of two-stage programming it
may happen that for some x 2 X the corresponding second stage problem is
infeasible with a positive probability p. Then w.p.1 for N large enough, for at
least one of the sample points i the corresponding second stage problem will
be infeasible, and hence ^fNðxÞ ¼ þ1. Of course, if the probability p is very
small, then the required sample size for such event to happen could be
very large.
Theorem 4 shows that in the convex case consistency of SAA estimators
follows from the pointwise LLN and natural boundedness conditions.
Without convexity the epiconvergence analysis becomes more involved. We
give below convergence results based on uniform convergence which often are
suﬃcient for practical applications.
Proposition 5. Suppose that ^fNðxÞ converges to f(x) w.p.1, as N ! 1, uniformly
on X. Then ^vN converges to v* w.p.1 as N ! 1.
Proof. The uniform convergence of ^fNðxÞ to f(x) w.p.1 means that for any
">0 the following inequality holds w.p.1 for N large enough,
sup
x2X
j ^fNðxÞ  f ðxÞj  ":
ð2:7Þ
It follows then that j^vN  v*j  " w.p.1 for N large enough, which completes
the proof.
u
Proposition 6. Suppose that there exists a compact set C  Rn such that: (i) the
set S of optimal solutions of the true problem is nonempty and is contained in C,
(ii) the function f(x) is ﬁnite valued and continuous on C, (iii) ^fNðxÞ converges to
f(x) w.p.1, as N ! 1, uniformly in x 2 C, (iv) w.p.1 for N large enough the set ^SN
is nonempty and ^SN  C. Then ^vN ! v* and Dð ^SN, SÞ ! 0 w.p.1 as N ! 1.
Proof. Assumptions (i) and (iv) imply that both the true and SAA problems
can be restricted to the set C. It can be easily veriﬁed that assumptions (ii) and
(iii) imply that the functions ^fN restricted to X \ C epiconverge to the function
f restricted to X \ C, i.e., ^fN þ iX\C!
e f þ iX\C, w.p.1. Since C is compact, the
proof then can be completed in a way similar to the proof of Theorem 4.
u
The last assumption (iv) in the above proposition holds, in particular, if the
feasible set X is closed, the functions ^fNðxÞ are lower semicontinuous and for
some >v* the level sets fx 2 X: ^fNðxÞ  g are uniformly bounded w.p.1.
362
A. Shapiro

There is a variety of results on uniform LLN (assumption (iii) of the above
proposition). In the convex case this is ensured by the assumptions of
Corollary 3. Following is a relatively simple uniform LLN without the
convexity assumption. We say that F(x, ), x 2 C, is dominated by an integrable
function if there exists a nonnegative valued measurable function G()
such that E½GðnÞ < þ1 and for every x 2 C the inequality jF(x, n)j  G(n)
holds w.p.1.
Proposition 7. Let C be a nonempty compact subset of Rn and suppose that:
(i) for almost every  2  the function F(  , ) is continuous on C, (ii) F(x, ),
x 2 C, is dominated by an integrable function, (iii) the sample is iid. Then the
expected value function f(x) is ﬁnite valued and continuous on C, and ^fNðxÞ
converges to f(x) w.p.1 uniformly on C.
Proof. It
follows
from
the
assumption
(ii)
that
j f(x)j  E[G(n)],
and
consequently j f (x)j< þ 1 for all x 2 C. Consider a point x 2 C and let xk
be a sequence of points in C converging to x. By the Lebesgue Dominated
Convergence Theorem assumption (ii) implies that
lim
k!1 E½Fðxk, nÞ ¼ E lim
k!1 Fðxk, nÞ


:
Since by (i), F(xk, n) ! F(x, n) w.p.1, it follows that f(xk) ! f(x), and hence
f(x) is continuous.
Choose now a point x 2 C, a sequence k of positive numbers converging
to zero, and deﬁne Vk :¼ fx 2 C: kx  xk  kg and
kðÞ :¼ sup
x2Vk
jFðx, Þ  Fðx, Þj:
ð2:8Þ
By the assumption (i) we have that for any  2 , k() tends to zero as k ! 1.
Moreover, by the assumption (ii) we have that k(), k ¼ 1, . . . , are dominated
by
an
integrable
function,
and
hence
by
the
Lebesgue
Dominated
Convergence Theorem we have that
lim
k!1 E½kðnÞ ¼ E lim
k!1 kðnÞ


¼ 0:
ð2:9Þ
We also have that
j ^fNðxÞ  ^fNðxÞj  1
N
X
N
i¼1
jFðx, niÞ  Fðx, niÞj,
Ch. 6. Monte Carlo Sampling Methods
363

and hence
sup
x2Vk
j ^fNðxÞ  ^fNðxÞj  1
N
X
N
i¼1
kðniÞ:
ð2:10Þ
Since the sample ni is iid, it follows by the LLN that the right hand side of
(2.10) converges w.p.1 to E[k(n)] as N ! 1. Together with (2.9) this implies
that for any given ">0 there exists a neighborhood W of x such that w.p.1 for
suﬃciently large N,
sup
x2W\C
j ^fNðxÞ  ^fNðxÞj < ":
Since C is compact, there exists a ﬁnite number of points x1, . . . , xm 2 C and
corresponding neighborhoods W1, . . . , Wm covering C such that w.p.1 for
N large enough the following holds
sup
x2Wj\C
j ^fNðxÞ  ^fNðxjÞj < ",
j ¼ 1, . . . , m:
ð2:11Þ
Furthermore, since f(x) is continuous on C, these neighborhoods can be
chosen in such a way that
sup
x2Wj\C
j f ðxÞ  f ðxjÞj < ",
j ¼ 1, . . . , m:
ð2:12Þ
Again by the LLN we have that ^fNðxÞ converges pointwise to f(x) w.p.1.
Therefore,
j ^fNðxjÞ  f ðxjÞj < ",
j ¼ 1, . . . , m,
ð2:13Þ
w.p.1 for N large enough. It follows from (2.11)–(2.13) that w.p.1 for N large
enough
sup
x2C
j ^fNðxÞ  f ðxÞj < 3":
ð2:14Þ
Since ">0 was arbitrary, we obtain that (2.5) follows and hence the proof is
complete.
u
It is possible to extend the above result in various directions. For example,
the assumption that the sample is iid was used in the proof in two places,
364
A. Shapiro

namely, to ensure pointwise convergence w.p.1 of ^fNðxÞ to f(x) (i.e., pointwise
LLN) and applicability of the LLN to the right hand side of (2.10). As it was
mentioned earlier, there is a variety of results, in the probability theory, on the
(pointwise) LLN without the iid assumption, which can be applied to the
present case.
Remark 8. We assumed that the feasible set X in the SAA problem (1.6) is
ﬁxed, i.e., independent of the sample. However, in some situations it also
should be estimated. Then the corresponding SAA problem takes the form
Min
x2XN
^fNðxÞ,
ð2:15Þ
where XN is a subset of Rn depending on the sample, and therefore is random.
Suppose that in addition to the assumptions of Proposition 6 the following
two conditions hold with probability one:
(a) If xN 2 XN and xN converges w.p.1 to a point x, then x 2 X.
(b) For some point x 2 S there exists a sequence xN 2 XN such that xN ! x
w.p.1.
Under the assumption of the uniform convergence of ^fN to f, the above
conditions (a) and (b) ensure conditions (i) and (ii) of the (epiconvergence)
Deﬁnition 23 as applied to the functions ^fN þ iXN\C and f þ iX\C at the point x.
Consistency of the SAA estimators then follows.
Suppose, for example, that the set X is deﬁned by the constraints
X :¼ x 2 X0 : gjðxÞ  0, j ¼ 1, . . . , p


,
ð2:16Þ
where X0 is a nonempty closed subset of Rn and the constraint functions are
given as the expected value functions
gjðxÞ :¼ E½Gjðx, nÞ,
j ¼ 1, . . . , p,
ð2:17Þ
with Gj being random lsc functions. Then the set X can be estimated by
XN :¼ x 2 X0 : ^gjNðxÞ  0, j ¼ 1, . . . , p


,
ð2:18Þ
where ^gjNðxÞ :¼ N1 PN
i¼1 Gjðx, iÞ. If for a given point x 2 X0 we have that
^gjN converge uniformly to gj w.p.1 on a neighborhood of x and the functions
gj are continuous, then the above condition (a) holds.
In order to ensure condition (b) one needs to impose a constraint quali-
ﬁcation (on the true problem). Consider, for example, X :¼ fx 2 R: gðxÞ  0g
with g(x) :¼ x2. Clearly X ¼ {0}, while an arbitrary small perturbation of the
Ch. 6. Monte Carlo Sampling Methods
365

function g(  ) can result in the corresponding set XN being empty. It is possible
to show that if a constraint qualiﬁcation for the true problem is satisﬁed at x,
then condition (b) follows. For instance, if the set X0 is convex and for every
 2  the functions Gj (  , ) are convex, and hence the corresponding expected
value functions gj (  ), j ¼ 1, . . . , p, are also convex, then such a simple
constraint qualiﬁcation is the Slater condition. Recall that it is said that the
Slater condition holds if there exists a point x 2 X0 such that gjðxÞ < 0,
j ¼ 1, . . . , p.
2.2
Asymptotics of the SAA optimal value
Consistency of the SAA estimators gives us a certain assurance that the
error of the estimation approaches zero in the limit as the sample size grows to
inﬁnity. Although this is important conceptually, it does not give any
indication of the magnitude of the error for a chosen sample size N. Suppose
for a moment that the sample is iid and let us ﬁx a point x 2 X. Then we have
that the sample average estimator ^fNðxÞ, of f(x), is unbiased and has variance
2(x)/N, where 2(x) :¼ Var[F(x, n)] is supposed to be ﬁnite. Moreover, by the
Central Limit Theorem (CLT) we have that
N1=2 ^fNðxÞ  f ðxÞ
h
i
) YðxÞ,
ð2:19Þ
where ‘‘ ) ’’ denotes convergence in distribution and Y(x) has a normal
distribution with mean 0 and variance 2(x), written Y(x)  N(0, 2(x)). That
is, for large N, ^fNðxÞ has approximately normal distribution with mean f(x) and
variance 2(x)/N.
This leads to the following (approximate) 100(1)% conﬁdence interval
for f(x):
^fNðxÞ  z=2 ^ðxÞ
ﬃﬃﬃﬃ
N
p
, ^fNðxÞ þ z=2 ^ðxÞ
ﬃﬃﬃﬃ
N
p


,
ð2:20Þ
where z/2 :¼ 1(1/2) and7
^2ðxÞ :¼
1
N  1
X
N
i¼1
Fðx, iÞ  ^fNðxÞ
h
i2
ð2:21Þ
is the sample variance estimate of 2(x). That is, the error of estimation of f(x)
is (stochastically) of order Op(N1/2). The involved constant, which is
proportional to (x), can be reduced (sometimes signiﬁcantly) by variance
7 Here (  ) denotes the cdf of the standard normal distribution. For example, to 95% conﬁdence
intervals corresponds z0.025 ¼ 1.96.
366
A. Shapiro

reduction techniques. However, the basic rate of Op(N1/2) is characteristic for
Monte Carlo sampling and cannot be changed.
Consider now the optimal value ^vN of the SAA problem (1.6). Clearly we
have that for any x0 2 X the inequality ^fNðx0Þ  infx2X ^fNðxÞ holds. By taking
the expected value of both sides of this inequality and minimizing the left hand
side over all x0 2 X we obtain
inf
x2X E ^fNðxÞ
h
i
 E inf
x2X
^fNðxÞ


:
ð2:22Þ
Since E½ ^fNðxÞ ¼ f ðxÞ, it follows that v*  E½^vN. In fact, typically, E½^vN is
strictly less than v*, i.e., ^vN is a downwards biased estimator of v*. Note that
the inequality (2.22) holds even if f(x) ¼ þ 1 or f(x) ¼ 1 for some x 2 X.
Let us discuss now the following simple example which demonstrates
various basic properties of the SAA estimators.
Example 9. Consider the function F(x, ) :¼ jxj, with x,  2 R, and X :¼ R.
In that case optimal solutions of the true and SAA problems are given by
the true (population) and the sample medians, respectively. Suppose, ﬁrst,
that the corresponding random variable n has a discrete distribution with
P(n ¼ 1) ¼ P(n ¼ 1) ¼ 1/2. Then
f ðxÞ ¼ 1
2 ðjx  1j þ jx þ 1jÞ,
and hence v* ¼ 1 and S ¼ [1, 1]. Let 1, . . . , N be an iid sample of n, i.e., each
i can take value 1 or 1 with probability half and they are independent of
each other. Then
^fNðxÞ ¼ pNjx  1j þ ð1  pNÞjx þ 1j,
where pN is the proportion of times that i ¼ 1. It follows that if pN<1/2, then
^SN ¼ f1g and ^vN ¼ 2pN. If pN>1/2, then
^SN ¼ f1g and ^vN ¼ 2ð1  pNÞ,
and ﬁnally if pN ¼ 1/2, then
^SN ¼ ½1, 1 and
^vN ¼ 1. That is,
^vN ¼
minf2pN, 2ð1  pNÞg. Now by the CLT we have that N1/2(2pN1) converges
in distribution to N(0, 1). It follows that N1=2ð^vN  1Þ converges in distribution
to W :¼ jZj, where Z  N(0, 1). In general, convergence in distribution does
not imply convergence of the corresponding expected values. However, in the
present case the uniform integrability condition8 can be veriﬁed, and hence we
obtain that
E½^vN ¼ v*  N1=2C þ oðN1=2Þ,
ð2:23Þ
8 See the Appendix, (8.5) in particular, for a deﬁnition of the uniform integrability condition.
Ch. 6. Monte Carlo Sampling Methods
367

where C :¼ E½Z ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
2=
p
. That is, the estimator ^vN has a negative bias of
order O(N1/2).
Suppose now that n can take three values 1, 0 and 1 with equal
probabilities 1/3. In that case v* ¼ 2/3 and S ¼ {0}, i.e., the true optimization
problem has unique optimal solution x* ¼ 0. The SAA estimator ^xN can be
equal to 1, 0, or 1. Moreover, the event f ^xN ¼ 1g happens if more than half of
the sample points are equal to one. Probability of that is given by P(W>N/2),
where W has a binomial distribution B(N, 1/3). If exactly half of the sample
points are equal to one, then the sample estimate can be any number
in the interval [0, 1]. Similar conclusions hold for the event f ^xN ¼ 1g.
Therefore, the probability that ^xN ¼ 0 is at least 12P(W  N/2). By the
Large Deviations theory (see Section 8.3 in the Appendix) we have that
P(W>N/2)  eN, with the (best) exponential constant  can be calculated
to be  ¼ 0.059. It follows that
1  Pð ^xN ¼ 0Þ  2eN:
ð2:24Þ
That is, the probability that the SAA estimator ^xN is equal exactly to the
true optimal solution x* approaches one exponentially fast. Consequently,
it happens with probability approaching one exponentially fast that ^vN ¼
^fNðx*Þ. Since ^fNðx*Þ is an unbiased estimator of v*, it follows then that the bias
E½^vN  v*, although is negative, approaches zero very fast as N increases.
Finally, suppose that the probability distribution of n is continuous, i.e., its
cumulative distribution function (cdf) G(  ) is continuous. Then the expected
value function f(x) is continuously diﬀerentiable with df(x)/dx ¼ 2G(x)1.
Suppose further that G(  ) is diﬀerentiable at x* with gðx*Þ :¼ dGðx*Þ=dx > 0.
Then d2f ðx*Þ=dx2 ¼ 2gðx*Þ is positive, and hence, since f(x) is convex, it
follows that the minimizer x* is unique. Also, it is well known that in this case
N1=2ð ^xN  x*Þ converges in distribution to normal with zero mean and
variance [2g(x*)]2. That is, ^xN tends to x* at a stochastic rate of Op(N1/2).
By the Mean Value Theorem we have that
^fNð ^xNÞ  ^fNðx*Þ ¼ Nð ^xN  x*Þ,
where N is a subgradient of ^fN calculated at some point ~xN 2 ½x*, ^xN. By
the uniform LLN we also have that jN  df ð ~xNÞ=dxj tends w.p.1, and
hence in probability, to zero. Moreover, since x* is a minimizer of f(x), we have
that df(x*)/dx ¼ 0, and hence it follows that N ¼ op(1). Consequently, we
obtain that ^fNð ^xNÞ  ^fNðx*Þ ¼ opðN1=2Þ, and hence
^vN ¼ ^fNð ^xNÞ ¼ ^fNðx*Þ þ opðN1=2Þ:
ð2:25Þ
368
A. Shapiro

Together with (2.19) this implies that N1=2ð^vN  v*Þ ) Nð0, 2ðx*ÞÞ. Typically
in such cases the bias E½^vN  v* tends to zero at a rate of O(N1).
Let us consider now the general case. Let Y(x) be random variables deﬁned
in (2.19). Recall that YðxÞ  Nð0, 2ðxÞÞ and that the covariance between
Y(x1) and Y(x2), for some x1, x2 2 X, is the same as the covariance between
F(x1, n) and F(x2, n). We use the following assumptions about the integrand F:
(A1) For some point x 2 X the expectation E[F(x, n)2] is ﬁnite.
(A2) There exists a measurable function K:  ! R þ such that E[K(n)2] is ﬁnite
and
jFðx1, Þ  Fðx2, Þj  KðÞkx1  x2k,
ð2:26Þ
for all x1, x2 2 X and  2 .
The above assumptions imply that the expected value f(x) and variance
2(x) are ﬁnite valued for all x 2 X. Moreover, it follows from (2.26) that
j f ðx1Þ  f ðx2Þj  kx1  x2k, where  :¼ E[K(n)], and hence f(x) is Lipschitz
continuous on X. If X is compact, we have then that the set S, of minimizers of
f(x) over X, is nonempty.
Theorem 10. Suppose that the sample is iid, the set X is compact and
assumptions (A1) and (A2) are satisﬁed. Then the following holds
^vN ¼ inf
x2S
^fNðxÞ þ opðN1=2Þ,
ð2:27Þ
N1=2 ^vN  v*
ð
Þ ) inf
x2S YðxÞ:
ð2:28Þ
Proof of (2.27) is based on upper and lower estimates, while (2.28) follows
from (2.27). It is clear that ^vN  infx2S ^fNðxÞ, which leads to the required
upper bound. Derivation of the lower bound is more involved and is based on
a functional CLT, and will be not given here.
Under mild additional conditions (see Section 8.2 in the Appendix) it
follows from (2.28) that
E½^vN  v* ¼ N1=2E inf
x2S YðxÞ


þ oðN1=2Þ:
ð2:29Þ
In particular, it follows from (2.28) that if S ¼ {x*} is a singleton, then
N1=2 ^vN  v*
ð
Þ ) Nð0, 2ðx*ÞÞ:
ð2:30Þ
Ch. 6. Monte Carlo Sampling Methods
369

Moreover, since E[Y(x*)] ¼ 0, we obtain that in this case the bias E½^vN  v* is
of order o(N1/2). On the other hand, if the true problem has more than one
optimal solution, then the right hand side of (2.28) is given by the minimum of
a number of random variables. Although each Y(x) has mean zero, their
minimum typically has a negative mean. Therefore, if S is not a singleton, then
the bias E½^vN  v* typically is negative and of order O(N1/2). Moreover, the
bias tends to be bigger the larger the set S is.
Suppose now that the feasible set X is deﬁned by constraints in the form
(2.16). The Lagrangian function of the true problem is Lðx, 	Þ :¼ f ðxÞþ
Pp
j¼1 	jgjðxÞ. Suppose also that the problem is convex, that is the set X0
is convex and for all  2  the functions F(  , ) and Gj(  , ), j ¼ 1, . . . , p,
are convex. Suppose, further, that the functions f(x) and gj(x) are ﬁnite valued
on a neighborhood of S and the Slater condition holds. Then with
every optimal solution x* 2 S is associated a nonempty and bounded set  of
Lagrange
multipliers
vectors
	 ¼ (	1, . . . , 	p)
satisfying
the
optimality
conditions:
x* 2 arg min
x2X0 Lðx, 	Þ,
	j  0
and
	jgjðx*Þ ¼ 0, j ¼ 1, . . . , p:
ð2:31Þ
The set  coincides with the set of optimal solutions of the dual of the true
problem, and therefore is the same for any optimal solution x* 2 S.
Let ^vN be the optimal value of the SAA problem (2.15) with XN given in the
form (2.18). We use the assumptions (A1) and (A2), given before Theorem 10,
applied to the integrands Gj as well as to the integrand F. It follows then that
the functions f (x) and gj (x) are ﬁnite valued and continuous on X. As in
Theorem 10, we denote by Y(x) random variables which are normally
distributed and have the same covariance structure as F(x, n). We also denote
by Yj (x) random variables which are normally distributed and have the same
covariance structure as Gj (x, n), j ¼ 1, . . . , p.
Theorem 11. Suppose that the sample is iid, the problem is convex and the
following conditions are satisﬁed: (i) the set X is compact, (ii) the functions f(x)
and gj(x) are ﬁnite valued on a neighborhood of S, (iii) the Slater condition for
the true problem holds, (iv) the assumptions (A1) and (A2) hold for the
integrands F and Gj, j ¼ 1, . . . , p. Then
N1=2 ^vN  v*
ð
Þ ) inf
x2S sup
	2
YðxÞ þ
X
p
j¼1
	jYjðxÞ
"
#
:
ð2:32Þ
Proof of the above theorem is based on duality theory of convex
programming and a functional CLT, and will be not given here. It follows
370
A. Shapiro

from (2.32) that if S ¼ {x*} and  ¼ f	g are singletons, i.e., both the true and
its dual problems have unique optimal solutions, then
N1=2 ^vN  v*
ð
Þ ) Nð0, 2
0Þ,
ð2:33Þ
with 2
0 :¼ Var½Fðx*, nÞ þ Pp
j¼1 	jGjðx*, nÞ.
3
Exponential rates of convergence
In this section we discuss exponential rates of convergence of optimal
and nearly optimal SAA solutions. This allows to give an estimate of
the sample size which is required to solve the true problem with a given
accuracy by solving the SAA problem. Although such estimates of the sample
size typically are too conservative for a practical use, they give an insight
into the complexity of solving the true (expected value) problem. The
analysis is based on the Large Deviations theory.9 For the sake of simplicity,
unless stated otherwise, we assume in this section that the random sample
is iid.
3.1
The case of finite feasible set
In this section we consider cases where10 jXj<1, i.e., the set X is ﬁnite,
although may be very large. For the sake of simplicity we assume that F(x, )
is ﬁnite for all x 2 X and  2  and f(x) is ﬁnite for every x 2 X. Then the sets
^S"
N and S" of "-optimal solutions of the SAA and true problems, respectively,
are nonempty and, of course, ﬁnite for any "  0. Consider numbers "  0,
  0 with   ", and the event f ^S
N  S"g which means that any -optimal
solution of the SAA problem provides an "-optimal solution of the true
problem. We estimate now the probability of that event.
We can write
^S
N 6 S"
n
o
¼
[
x2XnS"
\
y2X
^fNðxÞ  ^fNð yÞ þ 
n
o
,
ð3:1Þ
and hence
P
^S
N 6 S"



X
x2XnS"
P
\
y2X
^fNðxÞ  ^fNð yÞ þ 
n
o
 
!
:
ð3:2Þ
9 See Section 8.3 of the Appendix for a brief discussion of the LD theory.
10 By jXj we denote the cardinality of the set X.
Ch. 6. Monte Carlo Sampling Methods
371

Consider a mapping u: X\S" ! X. It follows from (3.2) that
P
^S
N 6 S"



X
x2XnS"
P ^fNðxÞ  ^fNðuðxÞÞ  
n
o
:
ð3:3Þ
We assume that the mapping u(x) is chosen in such a way that for some "*>",
f ðuðxÞÞ  f ðxÞ  "*
for all x 2 XnS":
ð3:4Þ
Note that if u(  ) is a mapping from X\S" into the set S, i.e., u(x) 2 S for all
x 2 X\S", then (3.4) holds with
"* :¼ min
x2XnS" f ðxÞ  v*,
ð3:5Þ
and such that "* is greater than " since the set X is ﬁnite. Therefore, a mapping
u(  ) satisfying condition (3.4) always exists. Of course, there are many
possible choices of the mapping u(x) with diﬀerent values of the constant "*.
For each x 2 X\S", deﬁne
Yðx, Þ :¼ FðuðxÞ, Þ  Fðx, Þ:
Note that E[Y(x, n)] ¼ f(u(x))f(x), and hence E[Y(x, n)]  "* for all x 2 X\S".
The corresponding sample average is
^YNðxÞ :¼ 1
N
X
N
i¼1
Yðx, iÞ ¼ ^fNðuðxÞÞ  ^fNðxÞ:
By (3.3) we have
P
^S
N 6 S"



X
x2XnS"
P
^YNðxÞ  
n
o
:
ð3:6Þ
Let Ix(  ) denote the (large deviations) rate function11 of the random variable
Y(x, n). The inequality (3.6) together with the LD upper bound (8.6) implies
1  P
^S
N  S"



X
x2XnS"
eNIxðÞ:
ð3:7Þ
11 See Section 8.3 of the Appendix for the deﬁnition of the rate function.
372
A. Shapiro

Note that the above inequality (3.7) is not asymptotic and is valid for any
random sample of size N.
Assumption (B). For every x 2 X\S" the moment generating function of the
random variable Y(x, n) is ﬁnite valued in a neighborhood of t ¼ 0.
The above assumption (B) holds, for example, if the support  of n is a
bounded subset of Rd, or if Y(x,  ) grows at most linearly and n has a
distribution from the exponential family.
Theorem 12. Let " and  be nonnegative numbers such that   ". Then
1  P
^S
N  S"


 jXjeN
ð, "Þ,
ð3:8Þ
where

ð, "Þ :¼ min
x2XnS" IxðÞ:
ð3:9Þ
Moreover, if assumption (B) holds, then 
(, ")>0.
Proof. The inequality (3.8) is an immediate consequence of the inequality
(3.7). We have that >"*  E[Y(x, n)], and hence it follows by assumption
(B) that Ix()>0 for every x 2 X\S". This implies that 
(, ")>0.
u
The following asymptotic result is an immediate consequence of inequality
(3.8),
lim sup
N!1
1
N log 1  P
^S
N  S"


h
i
 
ð, "Þ:
ð3:10Þ
It means that the probability of the event that any -optimal solution of the
SAA problem provides an "-optimal solution of the true problem approaches
one exponentially fast as N ! 1. This suggests that the SAA method
can eﬃciently ﬁnd an "-optimal solution of the true problem by solving the
SAA problem with accuracy , provided that the constant 
(, ") is not
‘‘too small’’.
For  close to E[Y(x, n)], we can write by (8.9) that
IxðÞ 	 ð  E½Yðx, nÞÞ2
22
x
 ð"*  Þ2
22
x
,
ð3:11Þ
Ch. 6. Monte Carlo Sampling Methods
373

where
2
x :¼ Var½Yðx, nÞ ¼ Var½FðuðxÞ, nÞ  Fðx, nÞ:
Recall that Ix(  ) is a convex function attaining its minimum at E[Y(x, n)], and
hence Ix(z) is monotonically increasing for z  E[Y(x, n)] as z ! 1.
Therefore, for all "*  0 suﬃciently small and  2 [0, "], the constant 
(, "),
given in (3.9), can be estimated (see (8.10)) as

ð, "Þ  ð"*  Þ2
32
max
 ð"  Þ2
32
max
,
ð3:12Þ
where
2
max :¼ max
x2XnS" Var½FðuðxÞ, nÞ  Fðx, nÞ:
ð3:13Þ
3.2
Estimates of the sample size
Let us ﬁx a signiﬁcance level  2 (0, 1), and estimate the sample size N which
is needed for the probability Pð ^S
N  S"Þ to be at least 1. By requiring the
right-hand side of (3.8) to be less than or equal to , we obtain that
N 
1

ð, "Þ log jXj

	

:
ð3:14Þ
Moreover, we have by (3.12) that 
ð, "Þ  ð"  Þ2=ð32
maxÞ for all "  0
suﬃciently small and  2 [0, "]. It follows that for all ">0 small enough and
0  <", the sample size which is required for Pð ^S
N  S"Þ  1   to hold can
be estimated as
N  32
max
ð"  Þ2 log jXj

	

:
ð3:15Þ
Of course, the constant 2
max, deﬁned in (3.13), depends on the choice of the
mapping u(x) and could be diﬃcult to estimate. Moreover, as it was
mentioned earlier, the bound (3.15) typically is too conservative for practical
estimates of the required sample sizes. However, the estimate (3.15) has
interesting consequences for complexity issues. A key characteristic of (3.15) is
that N depends only logarithmically both on the size of the feasible set X and
on the tolerance probability .
Suppose now that X is a bounded, not necessarily ﬁnite, subset of Rn, and
that f(x) is ﬁnite valued for all x 2 X. Then we can apply the sample size
estimate (3.15) as follows. Recall that any two norms on the ﬁnite dimensional
374
A. Shapiro

space Rn are equivalent. For technical reasons it will be convenient to use here
the max-norm jjxjj :¼ max{jx1j, . . . , jxnj}. For a given >0, consider a ﬁnite
subset X of X such that for any x 2 X there is x0 2 X satisfying jjxx0jj  .
Since X is bounded, its diameter D :¼ supx, y 2 X jjxyjj is ﬁnite. Then such set
X can be constructed with jXj  (D/)n. By reducing the feasible set X to its
subset X, as a consequence of (3.15) we obtain the following estimate of the
sample size, required to solve the reduced problem with an accuracy "0>:
N  32
max
ð"0  Þ2
n log D
  log 
	

:
ð3:16Þ
Suppose, further, that the expectation function f(x) is Lipschitz continuous
on X modulus L, that is, j f ðxÞ  f ð yÞj  Lkx  yk for all x, y 2 X. Then an
"0-optimal solution of the reduced problem is an "-optimal solution of the
true problem with " ¼ "0 þ L. Let us set  :¼ (")/(2L) and "0 :¼ "  L ¼
"  ð"  Þ=2. By employing (3.16) we obtain the following estimate of the
sample size N required to solve the true problem:
N  122
max
ð"  Þ2
n log 2DL
"    log 
	

:
ð3:17Þ
The above estimate (3.17) shows that the sample size which is required to solve
the true problem with probability 1 and accuracy ">0 by solving the SAA
problem with accuracy <", grows linearly in dimension n of the decision
vector x. The estimate (3.17) also involves constants D, L and 2
max which
should be estimated for the considered class of problems. Note that the
variance constant 2
max appears linearly in the estimate (3.17). This should not
be surprising since for deciding (comparing), with a given accuracy, which one
of just two values f(u(x)) and f(x), of the true objective function, is smaller we
need a sample of a size proportional to 2
x.
3.3
Piecewise linear case
The estimate (3.17) is general and can be applied to any stochastic problem
of the form (1.1). In the case of two-stage linear stochastic programming it is
possible to say more. In that case the feasible set X and the optimal value
F(x, ) of the second stage problem satisfy the following assumptions.
(C1) The set X is a convex closed polyhedron.
(C2) For every  2  the function F(  , ) is polyhedral.12
12 Recall that a function g : Rn ! R is said to be polyhedral if it is proper convex and lower
semicontinuous, its domain is a convex closed polyhedron and g(x) is piecewise linear on its domain.
Ch. 6. Monte Carlo Sampling Methods
375

We also assume in this section that the support of n is ﬁnite.
(C3) The support  of n is ﬁnite,  ¼ {1, . . . , K}, with respective (positive)
probabilities pk, k ¼ 1, . . . , K.
We can absorb the feasible set X into the objective function by formulating
the true and SAA problems in the forms (2.3) and (2.4), respectively. Denote
FkðÞ :¼ Fð, kÞ. We have then that
f ðÞ ¼
X
K
k¼1
pkFkðÞ,
and dom f ¼ \K
k¼1 dom Fk. Note also that dom Fk ¼ X \ dom Fð, kÞ. It
follows from the above assumptions (C1)–(C3) that the function f is polyhedral
provided that its domain is nonempty.
Suppose, further, for the sake of simplicity that the true problem has
unique optimal solution, i.e., S ¼ {x*}. Consider the following event.
(EN) The SAA problem (1.6) has unique optimal solution ^xN and ^xN ¼ x*.
The above event can also be formulated in the form: ‘‘the point x* is the
unique optimal solution of the SAA problem’’.
Theorem 13. Suppose that the assumptions (C1)–(C3) hold and the true problem
has unique optimal solution x*. Then the event (EN) happens w.p.1 for N large
enough and, moreover, there exists a constant 
*>0 such that
lim
N!1
1
N log½1  PðENÞ ¼ 
*:
ð3:18Þ
Proof of the above theorem is based on the following lemma which is
implied by the polyhedral structure of the considered problem. Denote by
X :¼ dom f ¼ X \ dom f
the domain of the function f , by TXðx*Þ the tangent cone to X at x*, and by
f
0ðx*, dÞ the directional derivative of f at the point x* in the direction d 2 Rn.
Note that since f ðx*Þ is ﬁnite and the function f is polyhedral, the directional
derivative f
0ðx*, dÞ is ﬁnite if d 2 TXðx*Þ, and f
0ðx*, dÞ ¼ þ1 otherwise.
Lemma 14. Suppose that the assumptions (C1)–(C3) hold and the true problem
has unique optimal solution x*. Then there exists a ﬁnite number of directions
d1, . . . , dJ 2 Rn\{0} such that f
0ðx*, djÞ > 0, j ¼ 1, . . . , J, and the event (EN)
happens if and only if ~f 0
Nðx*, djÞ > 0, j ¼ 1, . . . , J.
376
A. Shapiro

Proof. For the sake of notational convenience we can assume without loss of
generality that x* ¼ 0. We have that for every k 2 {1, . . . , K}, the function FkðÞ
is polyhedral and Fkðx*Þ is ﬁnite. Because of the polyhedral structure of Fk we
have that the tangent cone to the domain of Fk at the point x* ¼ 0 can be
represented as a union of a ﬁnite number of closed convex polyhedral cones
such that Fk is linear13 on each cone in a neighborhood of x* ¼ 0. By taking all
possible intersections of these cones for k ¼ 1, . . . , K, we can construct a ﬁnite
number of closed convex polyhedral cones T1, . . . , TM with the following
properties. (i) The union of the tangent cones Tdom Fkðx*Þk2f1, ..., Kg coincides
with [M
m¼1 Tm. (ii) To every k 2 {1, . . . , K} corresponds a subset Mk of
{1, . . . , M} such that the tangent cone Tdom Fkðx*Þ coincides with [m2Mk Tm and
Fk is linear on each cone Tm, m 2 Mk, in a neighborhood of x* ¼ 0. Now let
d1, . . . , dJ be the set of vectors of length one generating all extreme rays of all
cones Tm, m ¼ 1, . . . , M.
For any generated sample i, i ¼ 1, . . . , N, we have that the corresponding
function ~fN is polyhedral and dom ~fN ¼ \N
i¼1 dom Fð, iÞ. Moreover, by the
above construction we have that there exists a set M  {1, . . . , M} such that
the tangent cone to dom ~fN at x* coincides with [m2M Tm and ~fNðÞ is linear on
each cone Tm, m 2 M, in a neighborhood of x* ¼ 0. Let J be a subset of
{1, . . . , J} such that the vectors dj, j 2 J, generate the set of all extreme rays of
the cones Tm, m 2 M. We have then that if ~f 0
Nðx*, djÞ > 0 for all j 2 J, then
x* ¼ 0 is the minimizer of ~fN over every cone Tm, m 2 M. By convexity this
implies that x* is the unique minimizer of ~fN over Rn. Conversely, if ~f 0
Nðx*, djÞ
is less than or equal to zero for some j 2 {1, . . . , J}, then either x* is not a
minimizer or x* is not a unique minimizer of ~fN over Rn. The last assertion
follows since ~fN is polyhedral.
Finally, the expected value function f has the same type of structure with
the corresponding extreme rays forming a subset of the set {d1, . . . , dJ}. We
have
then
that
f
0ðx*, djÞ
is
positive
and
ﬁnite
for
dj 2 TXðx*Þ,
and
f
0ðx*, djÞ ¼ þ1 otherwise. This completes the proof of the lemma.
u
Proof (of Theorem 13). Since f ðx*Þ is ﬁnite we have that for any d 2 Rn,
f
0ðx*, dÞ ¼
X
K
k¼1
pkF
0
kðx*, dÞ ¼ E F
0
nðx*, dÞ
h
i
,
ð3:19Þ
where FðÞ :¼ Fð, Þ and F
0
ðx*, dÞ denotes the directional derivative of F at
x* in the direction d. We also have that
~f 0
Nðx*, dÞ ¼ 1
N
X
N
i¼1
F 0
iðx*, dÞ:
ð3:20Þ
13 We say here that a real valued function g(x) is linear if g(x) ¼ aTx þ b for some a, b 2 Rn. It is more
accurate to call such a function aﬃne.
Ch. 6. Monte Carlo Sampling Methods
377

For a given d 2 Rn, by applying the LLN to the random variable F
0
nðx*, dÞ we
obtain that
~f 0
Nðx*, dÞ ! f
0ðx*, dÞ
w:p:1 as N ! 1:
ð3:21Þ
Note that (3.21) holds if f
0ðx*, dÞ ¼ þ1 as well. Now let d1, . . . , dJ be vectors
speciﬁed in Lemma 14. Since f
0ðx*, djÞ > 0, j ¼ 1, . . . , J, it follows by (3.21)
that ~f 0
Nðx*, djÞ > 0, j ¼ 1, . . . , J, and hence the event (EN) happens, w.p.1 for
N large enough.
Now by the upper LD bound (see (8.8) and (8.13)) we have that for any
d 2 Rn the inequality
P ~f 0
Nðx*, dÞ  0
n
o
 eN
d,
ð3:22Þ
holds with

d :¼ logð1  pdÞ1 þ %dIdð0Þ:
Here pd is the probability that F
0
nðx*, dÞ ¼ þ1, Id (  ) is the rate function
of F
0
nðx*, dÞ conditional on the event fF
0
nðx*,dÞ < þ 1g, and %d :¼ 1 if
the mean of F
0
nðx*, dÞ conditional on fF
0
nðx*, dÞ < þ1g is positive, and %d :¼ 0
otherwise. If d 62 TXðx*Þ, then pd is positive, and hence 
d>0. If d 2 TXðx*Þ,
then pd ¼ 0 and f
0ðx*, dÞ is ﬁnite. Since n has a ﬁnite support we have that in
this case Id (0)>0 if f
0ðx*, dÞ > 0. Note also that if pd ¼ 0 and f
0ðx*, dÞ > 0,
then 
d ¼ Id (0) with Id(  ) being the rate function of F
0
nðx*, dÞ.
Now by Lemma 14 we have that the complement of the event (EN) coincides
with the union of the events f ~f 0
Nðx*, djÞ  0gj2f1,...,Jg. Therefore, it follows from
(3.22) that
1  PðENÞ 
X
J
j¼1
eN
dj ,
ð3:23Þ
which in turn implies
lim sup
N!1
1
N log½1  PðENÞ   min
1 j J 
dj:
ð3:24Þ
We also have that
1  PðENÞ  P ~f 0
Nðx*, djÞ  0
n
o
,
j ¼ 1, . . . , J:
ð3:25Þ
378
A. Shapiro

Since n has a ﬁnite support, the lower bound of Crame´ r’s LD Theorem can be
applied to the right hand side of (3.25) to obtain
lim inf
N!1
1
N log½1  PðENÞ  
dj,
j ¼ 1, . . . , J:
ð3:26Þ
The inequalities (3.25) and (3.26) imply (3.18) with

* :¼ min
1 j J 
dj:
ð3:27Þ
By the above discussion we have that every 
dj is positive and hence 
*>0.
This completes the proof.
u
Theorem 13 shows that, under the assumed polyhedral structure, by solving
the SAA problem one obtains the exact optimal solution of the true problem
for suﬃciently large sample size, and moreover, the probability of that event
approaches one exponentially fast with increase of the sample size. Note that
even so, the corresponding optimal value ^vN is not exact and may have a
relatively large variability. Of course, although (3.18) ensures an exponential
convergence of the probability P(EN) to one, the convergence can be very
slow if the constant 
* is small. Consider, for example, a situation where for
some direction d 2 Rn the directional derivative F
0
kðx*, dÞ ¼ þ1 for just one
k 2 {1, . . . , K} with the corresponding probability pk being very small,
while F 0
lðx*, dÞ < 0 for all l 6¼ k. Then f
0ðx*, dÞ ¼ þ1, while ~f 0
Nðx*, dÞ is
negative unless the corresponding sample includes the point k in which case
~f 0
Nðx*, dÞ ¼ þ1, and that happens with probability 1(1pk)N. Therefore, in
such situation one will need a very large sample to ensure that ~f 0
Nðx*, dÞ ¼ þ1
with a reasonably large probability.
Suppose now that the assumptions (C1)–(C3) hold, but the set S of optimal
solutions of the true problem is not necessarily a singleton. Because of the
assumed polyhedral structure we have here that the set S is a convex closed
polyhedron. The set ^SN of optimal solutions of the SAA problem is also a
convex closed polyhedron. Consider the following event.
(GN) The set ^SN is nonempty and forms a face of the set S.
Proof of the following result is similar to the proof of Theorem 13.
Theorem 15. Suppose that the assumptions (C1)–(C3) hold and the set S is
nonempty and bounded. Then the event (GN) happens w.p.1 for N large enough
and, moreover,
lim sup
N!1
1
N log½1  PðGNÞ < 0:
ð3:28Þ
Ch. 6. Monte Carlo Sampling Methods
379

The above analysis is based on the polyhedral structure of the functions
Fð, Þ,  2 , which is inherited by the expected value function f ðÞ because 
is ﬁnite. Since f ðÞ is polyhedral, it follows that the set S ¼ arg min f is
nonempty, provided that f ðÞ is bounded from below, and moreover,
f ðxÞ  v* þ c distðx, SÞ
ð3:29Þ
for all x 2 Rn and some constant c>0. In particular, if S ¼ {x*} is a singleton,
then (3.29) takes the form
f ðxÞ  f ðx*Þ þ ckx  x*k:
ð3:30Þ
Optimal solution x* is said to be sharp if the above condition (3.30) holds.
Since f ðÞ is polyhedral, x* is always sharp provided it is unique.
If n has a continuous distribution, and hence its support  is not a ﬁnite set,
then condition (3.30) still may hold in some particular situations. It is possible
to show that in such cases, under some mild additional conditions, the event
(EN) happens w.p.1 for N large enough and the probability P(EN) approaches
one at an exponential rate. By convexity of f ðÞ, condition (3.30) is equivalent
to the condition that f
0ðx*, dÞ  ckdk for all d 2 Rn. If n has a continuous
distribution, then it may happen that f
0ðx*, dÞ ¼ 0 for some d 6¼ 0 even if the
optimal solution x* is unique. In such cases an SAA optimal solution ^xN
converges to x* typically at a rate of Op(N1/2).
3.4
Conditioning of piecewise linear stochastic programs
It was shown in Section 3.3 that, under the assumed polyhedral structure of
the problem, one can ﬁnd an exact optimal solution of the true problem by
solving the SAA problem with suﬃciently large sample size. Of course, the
sample size N which is required for that to happen, with a reasonably large
probability, is problem dependent. It turns out that in some cases the true
problem possesses unique optimal solution x* which can be computed exactly
by solving the corresponding SAA problem based on a relatively small sample.
This usually is indicated by the fact that while solving several SAA problems,
based on independent samples of n of a relatively small size, one obtains the
same optimal solution. It is natural to call such problems well conditioned. On
the other hand, it may happen that either the set S is not a singleton or the
sample size which is needed for the event (EN) to happen, with a reasonably
large probability, is very large. We call such problems ill conditioned.
Suppose, for the sake of simplicity, that in addition to the assumptions
(C1)–(C3) the following holds.
(C4) The expected value function f(x) is ﬁnite valued for all x 2 X in a
neighborhood of the point x*.
380
A. Shapiro

In the case of two-stage stochastic programming the above assumption
holds, for example, if the recourse is relatively complete. We have by Lemma
14 that, under the assumptions (C1)–(C4), there exists a ﬁnite number of
nonzero vectors d1, . . . , dJ 2 TX(x*) such that the event (EN) happens iﬀ
~f 0
Nðx*, djÞ > 0, j ¼ 1, . . . , J. Furthermore, the (3.18) holds with the exponential
constant 
* given by

* ¼ min
1jJ Idjð0Þ,
ð3:31Þ
where Id (  ) denotes the rate function of the random variable F0
nðx*, dÞ.
We have that E½F0
nðx*, dÞ ¼ f 0ðx*, dÞ. Moreover, because of the assumption
(C4) and the assumed polyhedral structure, we have here that if d 2 TX(x*),
then f 0ðx*, dÞ is ﬁnite, and hence F0
ðx*, dÞ is ﬁnite for any  2  ¼ {1, . . . , K}.
Now, by (8.9), for f 0(x*, d) close to zero we can approximate Id (0) as follows
Idð0Þ 	
½ f 0ðx*, dÞ2
2Var½F0
nðx*, dÞ :
ð3:32Þ
This leads to the following concept. We call
 :¼ max
1 j J
Var½F0
nðx*, djÞ
½ f 0ðx*, djÞ2
ð3:33Þ
the condition number of the true problem. By (3.21) and (3.22) we have that

* 	 (2)1. That is, for large  the true problem is viewed as ill conditioned
since one needs a very large sample in order to solve it exactly. Note that
f 0(x*, d) ¼ 0 for some d 2 TX(x*)\{0} iﬀthe true problem has another optimal
solution apart from x*, i.e., the set S is not a singleton. In that case  ¼ þ 1.
Of course, it is impractical to try to compute the above condition number.
For one thing it depends on the optimal solution x* which is not known a
priori. Therefore, the above analysis has rather a conceptual value. Note also
that we approach here the question of conditioning of the true problem from
the point of view of SAAs. That is, problems which are ‘‘ﬂat’’ in some feasible
directions near the optimal solution x* are diﬃcult to solve exactly. This is
measured by the squared coeﬃcient of variation of the corresponding
directional derivative.
As it was mentioned in the previous section, in case n has a continuous
distribution it can happen that f 0(x*, d) ¼ 0 for some d 2 TX(x*)\{0} even if the
optimal solution x* is unique. Typically in such cases ^xN converges to x* at a
rate of Op(N1/2), i.e., accuracy of the estimator ^xN improves slowly with
increase of the sample size N. From the above point of view any such problem
is ill conditioned.
Ch. 6. Monte Carlo Sampling Methods
381

Let us also remark that it is possible to introduce a similar concept of
condition number for problems with ﬁnite feasible set X by replacing the
directional derivatives with the corresponding ﬁnite diﬀerences (see the
discussion of Section 3.1).
4
Validation analysis
Suppose that we are given a feasible point x 2 X as a candidate for an
optimal solution of the true problem. For example, x can be an output of a
run of the corresponding SAA problem. In this section we discuss ways to
evaluate quality of this candidate solution. This is important, in particular, for
a choice of the sample size and stopping criteria in simulation based
optimization. There are basically two approaches to such validation analysis.
We can either try to estimate the optimality gap f ðxÞ  v*, or to evaluate ﬁrst
order (KKT) optimality conditions at the considered point x.
Let us emphasize that the following analysis is designed for the situations
where the value f ðxÞ, of the true objective function at the considered point, is
ﬁnite. In the case of two-stage programming this requires, in particular, that
the second stage problem, associated with ﬁrst stage decision variables x, is
feasible for almost every realization of the random data.
4.1
Estimation of the optimality gap
In this section we consider the problem of estimating the optimality gap
gapðxÞ :¼ f ðxÞ  v*
ð4:1Þ
associated with the candidate solution x. Clearly, for any feasible x 2 X,
gapðxÞ is nonnegative and gapðxÞ ¼ 0 iﬀx is an optimal solution of the true
problem.
Consider the optimal value ^vN of the SAA problem (1.6). As it was
discussed in Section 2.2 we have that v*  E½^vN. This means that ^vN provides
a valid statistical lower bound for the optimal value v* of the true problem. The
expectation E½^vN can be estimated by averaging. That is, one can solve M
times SAA problems based on independently generated samples each of size
N. Let ^v1
N, . . . , ^vM
N be the computed optimal values of these SAA problems.
Then
vN,M :¼ 1
M
X
M
j¼1
^v j
N
ð4:2Þ
382
A. Shapiro

is an unbiased estimator of E½^vN. Since the samples, and hence ^v1
N, . . . , ^vM
N , are
independent, we can estimate the variance of vN,M by
^2
N, M :¼ 1
M
1
M  1
X
M
j¼1
^v j
N  vN, M

2
"
#
:
ð4:3Þ
Note that the above make sense only if the optimal value v* of the true
problem is ﬁnite. Note also that the inequality v*  E½^vN holds and ^vN gives a
valid statistical lower bound even if f(x) ¼ þ 1 for some x 2 X.
In general, the random variable ^vN, and hence its replications ^v j
N, does not
have a normal distribution, even approximately (see Theorem 10 and the
following up discussion). However, by the CLT, the probability distribution
of the average vN,M becomes approximately normal as M increases. Therefore,
we can use
LN,M :¼ vN,M  t,M1 ^N,M
ð4:4Þ
as an approximate 100(1)% conﬁdence14 lower bound for the expectation
E½^vN.
We can also estimate f ðxÞ by sampling.15 That is, let ^fN0ðxÞ be the sample
average estimate of f ðxÞ, based on a sample of size N0 generated independently
of samples involved in computing x. Let ^2
N0ðxÞ be an estimate of the variance
of ^fN0ðxÞ. In the case of iid sample, one can use the sample variance estimate
^2
N0ðxÞ :¼
1
N0ðN0  1Þ
X
N0
i¼1
Fðx, iÞ  ^fN0ðxÞ
h
i2
:
ð4:5Þ
Then
UN0ðxÞ :¼ ^fN0ðxÞ þ z ^N0ðxÞ
ð4:6Þ
gives an approximate 100(1)% conﬁdence upper bound for f ðxÞ. Note that
since N0 typically is large, we use here the standard normal critical value z.
We have that
E ^fN0ðxÞ  vN,M
h
i
¼ f ðxÞ  E½^vN ¼ gapðxÞ þ v*  E½^vN  gapðxÞ,
14 Here t, is the -critical value of t-distribution with  degrees of freedom. This critical value is
slightly bigger than the corresponding standard normal critical value z, and t, quickly approaches z
as  increases.
15 Compare with the discussion of Section 2.2, see (2.20) in particular.
Ch. 6. Monte Carlo Sampling Methods
383

i.e., ^fN0ðxÞ  vN,M is a biased estimator of the gapðxÞ. Also the variance of
this estimator is equal to the sum of the variances of ^fN0ðxÞ and vN,M, and
hence
^fN0ðxÞ  vN,M þ z
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
^2
N0ðxÞ þ ^2
N,M
q
ð4:7Þ
provides a conservative 100(1)% conﬁdence upper bound for the gapðxÞ.
We say that this upper bound is ‘‘conservative’’ since in fact it gives a
100(1)% conﬁdence upper bound for the gapðxÞ þ v*  E½^vN, and we have
that v*  E½^vN  0.
In order to calculate the estimate ^fN0ðxÞ one needs to compute the value
Fðx, iÞ of the objective function for every generated sample realization i,
i ¼ 1, . . . , N0. Typically it is much easier to compute Fðx, Þ, for a given  2 ,
than to solve the corresponding SAA problem. Therefore, often one can use a
relatively large sample size N0, and hence to estimate f ðxÞ quite accurately.
Evaluation of the optimal value v* by employing the estimator vN,M is a more
delicate problem.
There are two types of errors in using vN,M as an estimator of v*, namely the
bias v*  E½^vN and variability of vN,M measured by its variance. Both errors
can be reduced by increasing N, and the variance can be reduced by increasing
N and M. Note, however, that the computational eﬀort in computing vN,M is
proportional to M, since the corresponding SAA problems should be solved
M times, and to the computational time for solving a single SAA problem
based on a sample of size N. Naturally one may ask what is the best way of
distributing computational resources between increasing the sample size N
and the number of repetitions M. This question is, of course, problem
dependent. Let pN be the probability that an optimal solution of an SAA
problem, based on a sample of size N, is an optimal solution of the true
problem. Then the probability that in M repetitions of the SAA problems at
least one optimal solution is an optimal solution of the true problem is
1(1pN)M. Now if we use the asymptotic pN 	 1eN
 for some positive
constant 
, then
1  ð1  pNÞM 	 1  eNM
,
which is the same as the asymptotic pNM 	 1eNM
. Of course, the above are
asymptotics and for ﬁnite sample sizes the situation can be diﬀerent. In any
case it appears that in cases where complexity of SAA problems grows fast
with increase of the sample size, it is more advantageous to use a larger
number of repetitions M. On the other hand, in some cases the computational
eﬀort in solving an SAA problem grows only linearly with the sample size N.
In such cases one can use a larger N and make only a few repetitions M in
order to estimate the variance of vN,M.
384
A. Shapiro

The bias v*  E½^vN does not depend on M, of course. The following result
shows that it decreases monotonically with increase of the sample size N.
Proposition 16. Suppose that the sample is iid. Then E½^vN  E½^vNþ1 for
any N 2 N.
Proof. We can write
^fNþ1ðxÞ ¼
1
N þ 1
X
Nþ1
i¼1
1
N
X
j6¼i
Fðx, jÞ
"
#
:
Moreover,
inf
x2X E 1
N
X
j6¼i
Fðx, njÞ
"
#
 E inf
x2X
1
N
X
j6¼i
Fðx, njÞ
"
#
,
ð4:8Þ
and since the sample is iid the right hand side of (4.8) is equal to E½^vN. It
follows that
E½^vNþ1¼ inf
x2X E ^fNþ1ðxÞ
h
i

1
N þ 1
X
Nþ1
i¼1
E inf
x2X
1
N
X
j6¼i
Fðx, njÞ
"
#
¼ E½^vN,
which completes the proof.
u
As it was discussed in Section 2.2 (see (2.29) in particular) we have that if
the set S is not a singleton, then the bias v*  E½^vN typically converges to zero,
as N increases, at a rate of O(N1/2), and tends to be bigger for a larger set S.
Ill conditioned problems with a large set of optimal or nearly optimal
solutions show a similar behavior of the bias. On the other hand, in well cond-
itioned problems, the event ^xN ¼ x*, and hence ^vN ¼ ^fNðx*Þ, happens with
probability approaching one exponentially fast. Since E½ ^fNðx*Þ ¼ f ðx*Þ, in
such cases the bias v*  E½^vN ¼ f ðx*Þ  E½^vN tends to be much smaller.
In the above approach the upper and lower statistical bounds were
computed independently of each other. Alternatively, it is possible to use the
same sample for estimating f ðxÞ and E½^vN. That is, for M generated samples
each of size N, the gap is estimated by
d
gap
gapN,MðxÞ :¼ 1
M
X
M
j¼1
^f j
NðxÞ  ^v j
N
h
i
,
ð4:9Þ
Ch. 6. Monte Carlo Sampling Methods
385

where
^f j
NðxÞ and
^v j
N
are computed from the same sample j ¼ 1, . . . ,
M. We have that the expected value of d
gap
gapN,MðxÞ is f ðxÞ  E½^vN, i.e., the
estimator d
gap
gapN,MðxÞ has the same bias as ^fN0ðxÞ  vN,M. On the other hand,
for well conditioned problems it happens with high probability that ^v j
N ¼
^f j
Nðx*Þ, and as a consequence ^f j
NðxÞ tends to be highly positively correlated
with ^v j
N, provided that x is close to x*. In such cases variability of d
gap
gapN,MðxÞ
can be considerably smaller than variability of ^fN0ðxÞ  vN,M. This is the idea
of common random number generated estimators which was discussed at the
end of Section 1 (see (1.7) and (1.8), in particular).
In order to reduce the bias of the above estimators of the optimality gap let
us consider the following approach. Let 	:  ! Rn be a measurable mapping
such that E[	(n)] ¼ 0. We have then that E½Fðx, nÞ þ 	ðnÞTx ¼ E½Fðx, nÞ for
any x 2 Rn, where Fð, Þ is deﬁned in (2.2). Consequently, v* is equal to the
optimal value of the problem
Min
x2Rn E Fðx, nÞ þ 	ðnÞTx


:
ð4:10Þ
It follows that v*  E½~v	
N, where ~v	
N is the optimal value of the SAA problem
corresponding to the problem (4.10). That is, ~v	
N provides a valid statistical
lower bound for the true optimal value v*. Of course, quality of this lower
bound depends on a choice of the mapping 	(  ). This is closely related to a
variance reduction technique called ‘‘Linear Control Random Variables’’
method. We discuss that later (see Section 5.2).
From a theoretical point of view there is an optimal choice of the mapping
	(  ). As it was discussed in Chapter ‘‘Optimality and Duality in Stochastic
Programming’’, with the problem (4.10) is associated a dual problem such that
if the function Fð, nÞ is convex w.p.1 and 	ðÞ is an optimal solution of that
dual problem, then under mild regularity conditions,
v* ¼ E inf
x2Rn Fðx, nÞ þ 	ðnÞTx




,
ð4:11Þ
and for a.e. n the set of minimizers of Fðx, nÞ þ 	ðnÞTx contains S. In
particular, if the set  ¼ {1, . . . , K} is ﬁnite, then this dual problem can be
written in the form
Max
	1,...,	K 
X
K
k¼1
pkF
*
kð	kÞ
subject to
X
K
k¼1
pk	k ¼ 0,
ð4:12Þ
where F*
kðÞ is the conjugate of the function FkðÞ :¼ Fð, kÞ. Of course, if 	ðÞ
is known, i.e., the dual problem is solved, then the expected value problem
(1.1) can be easily solved and one does not need sampling.
386
A. Shapiro

4.2
KKT statistical test
Suppose that the feasible set X is deﬁned by constraints in the form
X :¼ fx 2 Rn : gjðxÞ ¼ 0, j ¼ 1, . . . , q; gjðxÞ  0, j ¼ q þ 1, . . . , pg,
ð4:13Þ
where gj(x) are smooth (at least continuously diﬀerentiable) deterministic
functions. Let x* 2 X be an optimal solution of the true problem and suppose
that the expected value function f(x*) is diﬀerentiable at x*. Then, under a
constraint qualiﬁcation, ﬁrst order (KKT) optimality conditions hold at x*.
That is, there exist Lagrange multipliers 	j such that 	j  0, j 2 I(x*) and
rf ðx*Þ þ
X
j2J ðx*Þ
	jrgjðx*Þ ¼ 0,
ð4:14Þ
where IðxÞ :¼ f j : gjðxÞ ¼ 0, j ¼ q þ 1, . . . , pg denotes the index set of inequal-
ity constraints active at a point x 2 Rn, and J ðxÞ :¼ f1, . . . , qg [ IðxÞ. Note
that if the constraint functions are linear, say gjðxÞ :¼ aT
j x þ bj, then
rgj(x) ¼ aj and the above KKT conditions hold without a constraint quali-
ﬁcation. Consider the (polyhedral) cone
KðxÞ :¼
z 2 Rn : z ¼
X
j2J ðxÞ
jrgjðxÞ, j  0, j 2 IðxÞ
(
)
:
ð4:15Þ
Then the KKT optimality conditions can be written in the form rf(x*) 2 K(x*).
Suppose now that f(  ) is diﬀerentiable at the candidate point x 2 X, and
that the gradient rf ðxÞ can be estimated by a (random) vector NðxÞ. In
particular, if F(  , n) is diﬀerentiable at x w.p.1, then we can use the estimator
NðxÞ :¼ 1
N
X
N
i¼1
rxFðx, iÞ ¼ r ^fNðxÞ
ð4:16Þ
associated with the generated16 random sample. Note that if, moreover, the
derivatives can be taken inside the expectation, that is,
rf ðxÞ ¼ E½rxFðx, nÞ,
ð4:17Þ
16 We emphasize that the random sample in (4.16) is generated independently of the sample used to
compute the candidate point x.
Ch. 6. Monte Carlo Sampling Methods
387

then the above estimator is unbiased, i.e., E½NðxÞ ¼ rf ðxÞ. Regularity
conditions which are required for the interchangeability formula (4.17) to hold
are discussed in section ‘‘Expectation Functions’’ of the chapter ‘‘Optimality
and Duality in Stochastic Programming’’. In the case of two-stage linear
stochastic programming with recourse, formula (4.17) typically holds if the
corresponding random data have a continuous distribution. On the other
hand, if the random data have a discrete distribution with a ﬁnite support,
then the expected value function f(x) is piecewise linear and typically is
nondiﬀerentiable at an optimal solution.
Suppose, further, that VN :¼ N1=2½NðxÞ  rf ðxÞ converges in distribution,
as N tends to inﬁnity, to multivariate normal with zero mean vector and
covariance matrix , written VN ) N(0, ). For the estimator NðxÞ deﬁned in
(4.16), this holds by the CLT if the interchangeability formula (4.17) holds, the
sample is iid, and rxFðx, nÞ has ﬁnite second order moments. Moreover, in
that case the covariance matrix  can be estimated by the corresponding
sample covariance matrix
^N :¼
1
N1
X
N
i¼1
rxFðx, iÞr ^fNðxÞ
h
i
rxFðx, iÞ  r ^fNðxÞ
h
iT
:
ð4:18Þ
Under the above assumptions, the sample covariance matrix
^N is an
unbiased and consistent estimator of .
We have that if VN ) N(0, ) and the covariance matrix  is nonsingular,
then given a consistent estimator ^N of , the following holds
NðNðxÞ  rf ðxÞÞT ^1
N ðNðxÞ  rf ðxÞÞ ) 2
n,
ð4:19Þ
where 2
n denotes the chi-square distribution with n degrees of freedom. This
allows to construct the following (approximate) 100(1)% conﬁdence
region17 for rf ðxÞ:
z 2 Rn : ðNðxÞ  zÞÞT ^1
N ðNðxÞ  zÞÞ  2
,n
N
(
)
:
ð4:20Þ
Consider the statistic
TN :¼ N
inf
z2KðxÞ ðNðxÞ  zÞT ^1
N ðNðxÞ  zÞ:
ð4:21Þ
17 Here 2
,n denotes the -critical value of chi-square distribution with n degrees of freedom. That is, if
Y  2
n, then ProbfY  2
,ng ¼ .
388
A. Shapiro

Note that since the cone KðxÞ is polyhedral and ^1
N is positive deﬁnite, the
minimization in the right hand side of (4.21) can be formulated as a quadratic
programming problem, and hence can be solved by standard quadratic
programming algorithms. We have that the conﬁdence region, deﬁned in
(4.20), does not have common points with the cone KðxÞ iﬀTN > 2
,n. We can
also use the statistic TN for testing the hypothesis:
H0: rf ðxÞ 2 KðxÞ
against the alternative
H1 : rf ðxÞ 62 KðxÞ:
ð4:22Þ
The TN statistic represents the squared distance, with respect to the norm18
k  k ^1
N , from N1=2NðxÞ to the cone KðxÞ. Suppose for the moment that
only equality constraints are present in the deﬁnition (4.13) of the feasible set,
and that the gradient vectors rgjðxÞ, j ¼ 1, . . . , q, are linearly independent.
Then the set KðxÞ forms a linear subspace of Rn of dimension q, and the
optimal value of the right hand side of (4.21) can be written in a closed form.
Consequently, it is possible to show that TN has asymptotically noncentral
chi-square distribution with nq degrees of freedom and the noncentrality
parameter19
 :¼ N
inf
z2Kð x Þ ðrf ðxÞ  zÞT1ðrf ðxÞ  zÞ:
ð4:23Þ
In particular, under H0 we have that  ¼ 0, and hence the null distribution of
TN is asymptotically central chi-square with nq degrees of freedom.
Consider now the general case where the feasible set is deﬁned by equality
and inequality constraints as in (4.13). Suppose that the gradient vectors
rgjðxÞ, j 2 J ðxÞ, are linearly independent and that the strict complementarity
condition holds at x, that is, the Lagrange multipliers 	j, j 2 IðxÞ,
corresponding to the active at x inequality constraints, are positive. Then
for NðxÞ suﬃciently close to rf ðxÞ the minimizer in the right hand side of
(4.21) will be lying in the linear space generated by vectors rgjðxÞ, j 2 J ðxÞ.
Therefore, in such case the null distribution of TN is asymptotically central
chi-square with  :¼ n  jJ ðxÞj degrees of freedom. Consequently, for a
computed value T *
N of the statistic TN we can calculate (approximately) the
corresponding p-value, which is equal to ProbfY  T *
Ng, where Y  2
. This
p-value gives an indication of the quality of the candidate solution x with
respect to the stochastic precision.
It should be understood that by accepting (i.e., failing to reject) H0, we do
not claim that the KKT conditions hold exactly at x. By accepting H0 we
rather assert that we cannot separate rf ðxÞ from KðxÞ, given precision of the
18 For a positive deﬁnite matrix A, the norm jj  jjA is deﬁned as jjzjjA :¼ (zTAz)1/2.
19 Note that under the alternative (i.e., if rf ðxÞ 62 KðxÞ), the noncentrality parameter  tends to inﬁnity
as N ! 1. Therefore, in order to justify the above asymptotics one needs a technical assumption
known as Pitman’s parameter drift.
Ch. 6. Monte Carlo Sampling Methods
389

generated sample. That is, statistical error of the estimator NðxÞ is bigger than
the squared k  k1-norm distance between rf ðxÞ and KðxÞ. Also rejecting H0
does not necessarily mean that x is a poor candidate for an optimal solution
of the true problem. The calculated value of TN statistic can be large, i.e., the
p-value can be small, simply because the estimated covariance matrix N1 ^N
of NðxÞ is ‘‘small’’. In such cases, NðxÞ provides an accurate estimator of
rf ðxÞ with the corresponding conﬁdence region (4.20) being ‘‘small’’.
Therefore, the above p-value should be compared with the size of the
conﬁdence region (4.20), which in turn is deﬁned by the size of the matrix
N1 ^N measured, for example, by its eigenvalues. Note also that it may
happen that jJ ðxÞj ¼ n, and hence  ¼ 0. Under the strict complementarity
condition, this means that rf ðxÞ lies in the interior of the cone KðxÞ, which in
turn is equivalent to the condition that f
0ðx, dÞ  ckdk for some c>0 and all
d 2 Rn. Then, by the LD principle (see (4.15) in particular), the event
NðxÞ 2 KðxÞ happens with probability approaching one exponentially fast.
Let us remark again that the above testing procedure is applicable if F(  , n)
is diﬀerentiable at x w.p.1 and the interchangeability formula (4.17) holds.
This typically happens in cases where the corresponding random data have a
continuous distribution. On the other hand, under the conditions (C1)–(C2),
of Section 3.3, and condition (C3) which assumes that the distribution of n has
a ﬁnite support, the expectation function f(  ) typically is nondiﬀerentiable at
an optimal solution, in which case the above statistical KKT test is not
applicable. We discuss such cases in the next section.
4.3
Testing optimality conditions in nondifferentiable cases
Suppose that the feasible set X is deﬁned by constraints in the form (4.13)
with the index sets I(x) and J(x) deﬁned in the same way as in the previous
section. Suppose further that for every  2  the function F(  , ) is convex.
Then the function f(  ) is convex and ﬁrst order optimality conditions, at a
point x* 2 X, can be written in the form: there exist Lagrange multipliers 	j
such that 	j  0, j 2 I(x*), and
0 2 @f ðx*Þ þ
X
j2J ðx*Þ
	jrgjðx*Þ:
ð4:24Þ
If the true problem is convex, i.e., the functions gj, j ¼ 1, . . . , q, are aﬃne and
gj, j ¼ q þ 1, . . . , p, are convex, the above conditions are suﬃcient for x* to be
an optimal solution of the true problem. Under a constraint qualiﬁcation,
conditions (4.24) are also necessary optimality conditions. If the function
f(x) is diﬀerentiable at x*, i.e., the subdiﬀerential @f(x*) is a singleton,
@f(x*) ¼ {rf(x*)}, then conditions (4.24) coincide with the KKT optimality
conditions (4.14). In this section we discuss cases where @f(x*) possibly is not a
singleton, i.e., f(x) is not necessarily diﬀerentiable at x*.
390
A. Shapiro

For a point x 2 X deﬁne
ðxÞ :¼
inf
2@f ðxÞ dist , KðxÞ
ð
Þ,
ð4:25Þ
where K(x) is the cone deﬁned in (4.15). We have that the optimality condi-
tions (4.24) hold at the point x iﬀðxÞ ¼ 0.
It is natural to try to test optimality conditions (4.24) by replacing the
subdiﬀerential @f(x*) with its sample average estimate @ ^fNðx*Þ, and con-
sequently estimating ðxÞ by
^NðxÞ :¼
inf
2@ ^fNðxÞ
dist , KðxÞ
ð
Þ:
ð4:26Þ
There are, however, two basic problems with such an approach. First, in order
to calculate the estimate ^NðxÞ one needs to compute the whole subdiﬀerential
@ ^fNðxÞ. Second, the mapping (multifunction) x  @f(x) is not continuous
unless @f(x) is a singleton. Take, for example, f(x) :¼ jxj, x 2 R. This function
has unique minimizer x* ¼ 0 with @f(x*) ¼ [1, 1]. On the other hand for
x 6¼ 0, the subdiﬀerential @f ðxÞ is either {1} or {1}, and hence ðxÞ ¼ 1, does
not matter how close x to x*. This makes testing optimality conditions (4.24)
in nondiﬀerentiable cases really diﬃcult.
We give below some results about convergence of the subdiﬀerentials @ ^fNðxÞ
which have an independent interest.
Proposition 17. Suppose that the sample is iid, for every  2  the function
F(  , ) is convex, and the expected value function f(x) is well deﬁned and ﬁnite
valued in a neighborhood of a point x 2 Rn. Then
lim
N!1 H @ ^fNðxÞ, @f ðxÞ


¼ 0
w:p:1:
ð4:27Þ
Proof. As it was shown in section ‘‘Expectation Functions’’ of chapter
‘‘Optimality and Duality in Stochastic Programming’’, we have here that f(x)
is directionally diﬀerentiable at x and
f 0ðx, dÞ ¼ E F0
nðx, dÞ
h
i
:
ð4:28Þ
We also have that
^f 0
Nðx, dÞ ¼ 1
N
X
N
i¼1
F0
iðx, dÞ:
ð4:29Þ
Ch. 6. Monte Carlo Sampling Methods
391

Therefore, by the LLN it follows from (4.28) that for any d 2 Rn, ^f 0
Nðx, dÞ
converges to f 0ðx, dÞ w.p.1 as N ! 1. Consequently, for any countable set
D  Rn we have that the event
lim
N!1
^f 0
Nðx, dÞ ¼ f 0ðx, dÞ,
8 d 2 D,
happens w.p.1. Let us take a countable and dense subset D of Rn. Since the
functions ^f 0
Nðx, Þ are convex, it follows by Theorem 25 that ^f 0
Nðx, Þ converges
to f 0ðx, Þ w.p.1 uniformly on the unit ball {d: jjdjj  1}. Furthermore, we have
H @ ^fNðxÞ, @f ðxÞ


¼ sup
kdk1
j ^f 0
Nðx, dÞ  f 0ðx, dÞj,
ð4:30Þ
and hence (4.27) follows.
u
Note that the assumption that the sample is iid in the above proposition
was used only to ensure that the LLN, for the random variable F0
nðx, dÞ, holds
pointwise, i.e., for any (ﬁxed) d 2 Rn.
Under the polyhedricity assumptions (C2) and (C3) of Section 3.3, it is
possible to say more. In that case the functions f(  ) and ^fNðÞ are polyhedral
and hence their subdiﬀerentials are polyhedrons. Suppose, further, that f(x) is
ﬁnite valued in a neighborhood of a point x. Then the convergence in (4.27) is
uniform on a neighborhood of x. Also because of the polyhedral structure of
the functions F(  , ),  2 , we have here that the space Rn can be partitioned
into a union of polyhedral cones Tm, m ¼ 1, . . . , M, such that f(  ) is linear on
each x þ Tm in a neighborhood of x, and there is a one-to-one correspondence
between vertices (extreme points) of @f ðxÞ and rf(x) for x 2 x þ Tm f0g
suﬃciently close to x. Similarly, every sample average function ^fNðÞ is linear
on unions of x þ Tm in a neighborhood of x. Consequently, the number of
vertices of @ ^fNðxÞ is always less than or equal to the number of vertices of
@f ðxÞ. Moreover, because of the convergence (4.27) it follows that w.p.1 for N
large enough there is a one-to-one correspondence between vertices of @ ^fNðxÞ
and @f ðxÞ, and vertices of @ ^fNðxÞ converge to the corresponding vertices of
@f ðxÞ w.p.1 as N ! 1.
This suggests the following procedure for estimating @ ^fNðxÞ, and hence the
number ^NðxÞ. Generate L points x1, . . . , xL randomly, say uniformly or
normally, distributed in a small neighborhood of x. At each point calculate
the gradient (subgradient) of
^fN, and consequently estimate
^NðxÞ by
replacing @ ^fNðxÞ with the convex hull of r ^fNðxlÞ, l ¼ 1, . . . , L. It is not diﬃcult
to show that the convex hull of r ^fNðxlÞ, l ¼ 1, . . . , L, will converge w.p.1 to
@ ^fNðxÞ
as
L ! 1. However,
numerical
experiments indicate
that the
convergence is slow and one needs a large number L for a test, based on
such procedure, to be reasonably accurate. Therefore, even for moderate
392
A. Shapiro

values of the dimension n such procedure appears to be not practical. For
numerical experiments and an additional discussion see Linderoth et al.
(2002).
Remark 18. It is also possible to derive the Large Deviations principle for the
Hausdorﬀdistance between @ ^fNðxÞ and @f ðxÞ. Let us consider for the sake of
simplicity the polyhedral case, i.e., suppose that the assumptions (C2) and
(C3) of Section 3.3 hold and the expected value function f(x) is ﬁnite valued in
a neighborhood of a point x 2 Rn. Then there exist a ﬁnite number of
directions d1, . . . , dJ, independent of the sample, such that the supremum in
the right hand side of (4.30) is attained at one of dj. This can be shown
essentially in the same way as in the proof of Lemma 14. Now let us choose a
constant ">0. By Crame´ r’s LD Theorem we have that for every dj,
j ¼ 1, . . . , J, there exists a constant j>0 such that
lim
N!1
1
N log P j ^f 0
Nðx, djÞ  f 0ðx, djÞj  "


h
i
¼ j:
ð4:31Þ
Because of (4.30) we have that the event fHð@ ^fNðxÞ, @f ðxÞÞ  "g coincides with
the union of the events fj ^f 0
Nðx, djÞ  f 0ðx, djÞj  "g, j ¼ 1, . . . , J. It follows then
that
lim
N!1
1
N log P H @ ^fNðxÞ, @f ðxÞ


 "
n
o
h
i
¼ ,
ð4:32Þ
where  :¼ min1 j J j. In a general, not necessarily polyhedral, case the
estimate (4.32) can be obtained, under certain regularity conditions, by
applying an inﬁnite dimensional form of the LD principle in the functional
space of continuous real valued functions deﬁned on the unit sphere of Rn.
5
Variance reduction techniques
Consider the sample average estimators ^fNðxÞ. We have that if the sample is
iid, then the variance of ^fNðxÞ is equal to 2(x)/N, where 2(x) :¼ Var[F(x, n)].
In some cases it is possible to reduce the variance of generated sample
averages, which in turn enhances convergence of the corresponding SAA
estimators. It is beyond the scope of this chapter to give a complete survey of
such variance reduction techniques. Therefore, we brieﬂy discuss in this
section a few variance reduction approaches which seem to be useful in the
SAA method. For an interval [a, b]  R, we denote by U[a, b] the uniform
probability distribution on that interval.
Ch. 6. Monte Carlo Sampling Methods
393

5.1
Latin hypercube sampling
Suppose that the random data vector n ¼ (!) is one dimensional with the
corresponding cdf G(  ). We can then write
E½Fðx, nÞ ¼
Z þ1
1
Fðx, Þ dGðÞ:
ð5:1Þ
In order to evaluate the above integral numerically it will be much better to
generate sample points evenly distributed than to use an iid sample. That is,
we can generate independent random points
Ui  U½ði  1Þ=N, i=N,
i ¼ 1, . . . , N,
ð5:2Þ
and then to construct the random sample of n by the inverse20 transformation
ni :¼ G1(Ui), i ¼ 1, . . . , N.
Now suppose that i is chosen at random from the set {1, . . . , N} (with equal
probability for each element of that set). Then conditional on i the
corresponding random variable Ui is uniformly distributed on the interval
[(i1)/N, i/N ], and the unconditional distribution of Ui is uniform on the
interval [0, 1]. Consequently, let {i1, . . . , iN} be a random permutation of the
set {1, . . . , N}. Then the random variables ni1, . . . , niN have the same marginal
distribution, with the same cdf G(  ), and are negatively correlated with each
other. Therefore, the expected value of
^fNðxÞ ¼ 1
N
X
N
i¼1
Fðx, niÞ ¼ 1
N
X
N
s¼1
Fðx, nisÞ
ð5:3Þ
is f(x), while21
Var ^fNðxÞ
h
i
¼ N12ðxÞ þ 2N2 X
s<t
Cov Fðx, nisÞ, Fðx, nitÞ


:
ð5:4Þ
If the function F(x,  ) is monotonically increasing or decreasing, than the
random variables Fðx, nisÞ and Fðx, nitÞ, s 6¼ t, are also negatively correlated.
Therefore, the variance of ^fNðxÞ tends to be smaller, and in some cases much
smaller, than 2(x)/N.
20 From the theoretical point of view such inverse transformation always exists although it can be
diﬃcult to calculate numerically.
21 By Cov(X, Y) and Corr(X, Y) we denote the covariance and correlation, respectively, between
random variables X and Y.
394
A. Shapiro

Suppose now that the random vector n ¼ (n1, . . . , nd) is d-dimensional, and
that its components nj, j ¼ 1, . . . , d, are distributed independently of each
other. Then we can use the above procedure for each component nj. That is, a
random sample Ui of the form (5.2) is generated, and consequently N
replications of the ﬁrst component of n are computed by the corresponding
inverse transformation applied to randomly permuted Uis. The same procedure
is applied to every component of n with the corresponding random samples of
the form (5.2) and random permutations generated independently of each
other. This sampling scheme is called the Latin Hypercube (LH) sampling.
If the function F(x,  ) is decomposable, i.e., Fðx, Þ :¼ F1ðx, 1Þ þ    þ
Fdðx, dÞ, then E½Fðx, nÞ ¼ E½F1ðx, n1Þ þ    þ E½Fdðx, ndÞ, where each expec-
tation is calculated with respect to a one dimensional distribution. In that case
the LH sampling ensures that each expectation E½Fjðx, njÞ is estimated in
nearly optimal way. Therefore, the LH sampling works especially well in cases
where the function F(x,  ) tends to have a somewhat decomposable structure.
In any case the LH sampling procedure is easy to implement and can be
applied to SAA optimization procedures in a straightforward way. Since in
LH sampling the random replications of F(x, n) are correlated with each other,
one cannot use variance estimates like (2.21) or (4.5). Therefore, the LH
method usually is applied in several independent batches in order to estimate
variance of the corresponding estimators.
5.2
Linear control random variables method
Suppose that we have a measurable function A(x, ) such that E[A(x, n)] ¼ 0
for all x 2 X. Then, for any t 2 R, the expected value of Fðx, nÞ þ tAðx, nÞ is
f(x), while
Var½Fðx, nÞ þ tAðx, nÞ
¼ Var½Fðx, nÞ þ t2 Var½Aðx, nÞ þ 2t CovðFðx, nÞ, Aðx, nÞÞ:
It follows that the above variance attains its minimum, with respect to t, for
t* :¼ F, AðxÞ VarðFðx, nÞÞ
VarðAðx, nÞÞ

1=2
,
ð5:5Þ
where F,AðxÞ :¼ CorrðFðx, nÞ, Aðx, nÞÞ, and with
Var½Fðx, nÞ þ t*Aðx, nÞ ¼ Var Fðx, nÞ
½
½1  F, AðxÞ2:
ð5:6Þ
Ch. 6. Monte Carlo Sampling Methods
395

For a given x 2 X and generated sample 1, . . . , N, one can estimate, in the
standard way, the covariance and variances appearing in the right hand side of
(5.5), and hence to construct an estimate ^t of t*. Then f(x) can be estimated by
^f A
N ðxÞ :¼ 1
N
X
N
i¼1
Fðx, iÞ þ ^tAðx, iÞ


:
ð5:7Þ
By (5.6), the linear control estimator ^f A
N ðxÞ has a smaller variance than ^fNðxÞ if
F(x, n) and A(x, n) are highly correlated with each other.
Let us make the following observations. The estimator ^t, of the optimal
value t*, depends on x and the generated sample. Therefore, it is diﬃcult to
apply linear control estimators in an SAA optimization procedure. That is,
linear control estimators are mainly suitable for estimating expectations at a
ﬁxed point. Also if the same sample is used in estimating ^t and ^f A
N ðxÞ, then
^f A
N ðxÞ can be a slightly biased estimator of f(x).
Of course, the above Linear Control procedure can be successful only if a
function A(x, ), with mean zero and highly correlated with F(x, ), is
available. Choice of such a function is problem dependent. For instance, one
can use a linear function A(x, ) :¼ 	()Tx (compare with the discussion at
the end of Section 4.1). Consider, for example, two-stage stochastic
programming with recourse. Suppose that the random vector h ¼ h(!) and
matrix T ¼ T(!), in the second stage problem (1.2), are independently
distributed, and let  :¼ E(h). Then
E½ðh  ÞTT ¼ E½ðh  ÞTE½T ¼ 0,
and hence one can use Aðx, Þ :¼ ðh  ÞTTx as the control variable.
Let us ﬁnally remark that the above procedure can be extended in a
straightforward way to a case where several functions A1ðx, Þ, . . . , Amðx, Þ,
each with zero mean and highly correlated with F(x, ), are available.
5.3
Importance sampling and likelihood ratio methods
Suppose that n has a continuous distribution with probability density
function (pdf ) g(  ). Let  (  ) be another pdf such that the so-called likelihood
ratio function L(  ) :¼ g(  )/ (  ) is well deﬁned. That is, if  (z) ¼ 0 for some
z 2 Rd, then g(z) ¼ 0, and by the deﬁnition, 0/0 ¼ 0, i.e., we do not divide a
positive number by zero. Then we can write
f ðxÞ ¼
Z
Fðx, ÞgðÞ d ¼
Z
Fðx, ÞLðÞ ðÞ d ¼ E ½Fðx, fÞLðfÞ,
ð5:8Þ
396
A. Shapiro

where the integration is performed over the space Rd and the notation E 
emphasizes that the expectation is taken with respect to the random vector
f having pdf  (  ).
Let us show that, for a ﬁxed x, the variance of F(x, f)L(f) attains its
minimal value for  (  ) proportional to jF(x,  )g(  )j, i.e., for
 *ðÞ :¼
jFðx, ÞgðÞj
R
jFðx, ÞgðÞj d :
ð5:9Þ
Since E ½Fðx, fÞLðfÞ ¼ f ðxÞ and does not depend on  (  ), we have that the
variance of F(x, f)L(f) is minimized if
E ½Fðx, fÞ2LðfÞ2 ¼
Z
Fðx, Þ2gðÞ2
 ðÞ
d,
ð5:10Þ
is minimized. Furthermore, by Cauchy inequality we have
Z
jFðx, ÞgðÞj d
	

2

Z Fðx, Þ2gðÞ2
 ðÞ
d
	

 Z
 ðÞ d
	

:
ð5:11Þ
It remains to note that
R
 () d ¼ 1 and the left hand side of (5.11) is equal to
the expected value of squared F(x, f)L(f) for  (  ) ¼  *(  ).
Note that if F(x,  ) is nonnegative valued, then  *ðÞ ¼ Fðx, ÞgðÞ=f ðxÞ and
for that choice of the pdf  (  ), the function F(x,  )L(  ) is identically equal to
f(x). Of course, in order to achieve such absolute variance reduction to zero we
need to know the expectation f(x) which was our goal in the ﬁrst place.
Nevertheless, it gives the idea that if we can construct a pdf  (  ) roughly
proportional to jF(x,  )g(  )j, then we may achieve a considerable variance
reduction by generating a random sample 1, . . . , N from the pdf  (  ), and
then estimating f(x) by
~f  
N ðxÞ :¼ 1
N
X
N
i¼1
Fðx, iÞLðiÞ:
ð5:12Þ
The estimator
~f  
N ðxÞ is an unbiased estimator of f(x) and may have
signiﬁcantly smaller variance than ^fNðxÞ depending on a successful choice of
the pdf  (  ).
Similar analysis can be performed in cases where n has a discrete
distribution by replacing the integrals with the corresponding summations.
Let us remark that the above approach, called importance sampling, is
extremely sensitive to a choice of the pdf  (  ) and is notorious for its
instability. This is understandable since the likelihood ratio function in the tail
Ch. 6. Monte Carlo Sampling Methods
397

is the ratio of two very small numbers. For a successful choice of  (  ), the
method may work very well while even a small perturbation of  (  ) may be
disastrous. This is why a single choice of  (  ) usually does not work for
diﬀerent points x, and consequently cannot be used for a whole optimization
procedure. Note also that E [L()] ¼ 1. Therefore, L()1 can be used as a
linear control variable for the likelihood ratio estimator ~f  
N ðxÞ.
In some cases it is also possible to use the likelihood ratio method for
estimating ﬁrst and higher order derivatives of f(x). Consider, for example, the
optimal value Q(x, ) of the second stage linear program (1.2). Suppose that
the vector q and matrix W are ﬁxed, i.e., not stochastic, and for the sake of
simplicity that h ¼ h(!) and T ¼ T(!) are distributed independently of each
other. We have then that Q(x, ) ¼ Q(hTx), where
QðzÞ :¼ inf qTy: Wy ¼ z, y  0


:
Suppose, further, that h has a continuous distribution with pdf g(  ). We have
that
E½Qðx, nÞ ¼ ET EhjT½Qðx, nÞ


,
and by using the transformation z ¼ hTx, since h and T are independent we
obtain
EhjT½Qðx, nÞ ¼ Eh½Qðx, nÞ¼
Z
Qðh  TxÞgðhÞ dh ¼
Z
QðzÞgðz þ TxÞ dz
¼
Z
QðÞLðx, Þ ðÞ d ¼ E ½Lðx, fÞQðfÞ,
ð5:13Þ
where  (  ) is a chosen pdf and Lðx, Þ :¼ gð þ TxÞ= ðÞ. If the function g(  )
is smooth, then the likelihood ratio function L(  , ) is also smooth. In that
case, under mild additional conditions, ﬁrst and higher order derivatives can
be taken inside the expected value in the right hand side of (5.13), and
consequently can be estimated by sampling. Note that the ﬁrst order
derivatives of Q(  , ) are piecewise constant, and hence its second order
derivatives are zeros whenever deﬁned. Therefore, second order derivatives
cannot be taken inside the expectation E[Q(x, n)] even if n has a continuous
distribution.
398
A. Shapiro

6
Multistage stochastic programming
Analysis developed in the previous sections can be applied to two-stage
stochastic programming in a straightforward way. However, for multi-
stage programming the situation is more subtle. In this section we discuss
T-stage linear stochastic programming problems with recourse of the form22
Min
A11x1¼b1
x10
c1x1þE
min
A21x1þA22x2¼b2
x20
c2x2þE   þE
min
AT,T1xT1þATTxT¼bT
xT0
cTxT
2
64
3
75
2
64
3
75
2
64
3
75,
ð6:1Þ
driven by the random data process n2, . . . , nT. Here xt 2 Rnt, t ¼ 1, . . . , T, are
decision variables, 1 :¼ (c1, A11, b1) is known at the ﬁrst stage (and hence is
nonrandom), and t :¼ ðct, At,t1, Att, btÞ 2 Rdt, t ¼ 2, . . . , T, are data vectors
some (all) elements of which can be random. Such multistage problems
were discussed in section ‘‘Multistage Models’’ of chapter ‘‘Stochastic
Programming Models’’, notation and terminology of which we follow.
If we denote by Q2(x1, 2) the optimal value of the (T1)-stage problem
Min
A21x1þA22x2¼b2
x20
c2x2 þ E
   þ E
min
AT,T1xT1þATTxT¼bT
xT0
cTxT
2
64
3
75
2
64
3
75,
ð6:2Þ
then we can write the T-stage problem (6.1) in the following form of two-stage
programming problem
Min
x1
c1x1 þ E½Q2ðx1, n2Þ
subject to
A11x1 ¼ b1, x1  0:
ð6:3Þ
Note, however, that if T  3, then problem (6.2) in itself is a stochastic
programming problem. Consequently, if the number of scenarios involved
in (6.2) is very large, or inﬁnite, then the optimal value Q2(x1, 2) may be
calculated only approximately, say by sampling.
There are several ways how sampling can be applied to multistage
programming. Sampling strategies are closely related to derivations of upper
and lower statistical bounds for the optimal value of the true problem. We
discuss that in the next section.
22 For the sake of notational convenience we write in this section the scalar product between two
vectors c, x 2 Rn as cx instead of cTx.
Ch. 6. Monte Carlo Sampling Methods
399

6.1
Statistical bounds
For given x1 and 2, the corresponding expected value(s) can be estimated
by generating random samples and solving the obtained SAA problems.
Let us observe that in case T  3, it follows from (2.22) that for any
estimator ^Q2ðx1, 2Þ of Q2(x1, 2) obtained in that way the following relation
holds23
Q2ðx1, 2Þ  E
^Q2ðx1, n2Þjn2 ¼ 2
h
i
ð6:4Þ
for every feasible x1 and 2. That is, for T  3 any SAA estimator of Q2(x1, 2)
is biased downwards.
In order to get a better insight into the above problem of bias let us assume
for the sake of simplicity that T ¼ 3. In that case problem (6.2) becomes the
two-stage program
Min
x2
c2x2 þ E½Q3ðx2, n3Þjn2
subject to
A21x1 þ A22x2 ¼ b2, x2  0,
ð6:5Þ
where Q3(x2, 3) is the optimal value of the problem
Min
x3
c3x3
subject to
A32x2 þ A33x3 ¼ b3, x3  0:
ð6:6Þ
The corresponding ﬁrst stage problem is then (6.3) with Q2(x1, 2) given by the
optimal value of (6.5). The functions Q2(  , 2) and Q3(  , 3) are extended real
valued convex functions for any 2 and 3.
Let us note that if we relax the nonanticipativity constraints at the second
stage of the above three-stage problem we obtain the following two-stage
program
Min
x12X1 c1x1 þ E½Qðx1, n2, n3Þ,
ð6:7Þ
where
X1 :¼ x1 2 Rn1 : A11x1 ¼ b1, x1  0
f
g,
23 The notation E[  jn ¼ ] denotes the conditional expectation given the event ‘‘n ¼ ’’.
400
A. Shapiro

and Q(x1, 2, 3) is the optimal value of the following problem
Min
x2,x3 c2x2 þ c3x3
subject to
A21x1 þ A22x2 ¼ b2,
A32x2 þ A33x3 ¼ b3,
x2  0, x3  0:
ð6:8Þ
Since (6.7)–(6.8) is obtained by a relaxation of the nonanticipativity
constraints, its optimal value is smaller than the optimal value of the
corresponding three-stage problem.
There are several ways how one can sample from the random data n2, n3
(recall that 1 is not random). Let P be the probability distribution of the
random vector (n2, n3). Suppose that a random sample
i
2, i
3


¼ ðci
2, Ai
21, Ai
22, bi
2Þ, ðci
3, Ai
32, Ai
33, bi
3Þ


 P,
i ¼ 1, . . . , N,
ð6:9Þ
of N replications of the random data is generated. Suppose, further, that for
each ði
2, i
3Þ the corresponding linear programming problem
Min
x1,x2,x3 c1x1 þ ci
2x2 þ ci
3x3
subject to
A11x1 ¼ b1,
Ai
21x1 þ Ai
22x2 ¼ bi
2,
Ai
32x2 þ Ai
33x3 ¼ bi
3,
x1  0, x2  0, x3  0:
ð6:10Þ
is solved, and the obtained optimal values are averaged.
For each i 2 {1, . . . , N}, the above problem (6.10) is equivalent to the problem
Min
x12X1 c1x1 þ Qðx1, i
2, i
3Þ:
ð6:11Þ
Similar to (2.22), we have that
inf
x12X1 E½c1x1 þ Qðx1, n2, n3Þ  E
inf
x12X1 fc1x1 þ Qðx1, n2, n3Þg


:
ð6:12Þ
We also have that the average of the optimal values of (6.10) is an unbiased
and consistent estimator of the right hand side of (6.12). Recall that the left
Ch. 6. Monte Carlo Sampling Methods
401

hand side of (6.12) is the optimal value of two-stage relaxation (6.7)–(6.8) of
the considered three-stage problem. It follows that the average of the optimal
values of (6.10) provides a valid, but not consistent, statistical lower bound for
the optimal value of (6.7)–(6.8), and hence for the considered three-stage
problem.
Suppose that E½Qðx1, n2, n3Þ is ﬁnite. Then by the LLN we have that
c1x1 þ 1
N
X
N
i¼1
Qðx1, ni
2, ni
3Þ!c1x1þE½Qðx1, n2, n3Þ
w:p:1 as N ! 1,
ð6:13Þ
and the expected value of the left hand side of (6.13) is equal to the right hand
side of (6.13). Therefore, for any feasible x1 2 X1 of the ﬁrst stage problem, the
left hand side of (6.13) provides a valid upper statistical bound for the optimal
value of the two-stage problem (6.7)–(6.8). However, as we discussed earlier,
the optimal value of (6.7)–(6.8) is smaller than the optimal value of the
corresponding three-stage problem. Therefore, there is no guarantee that the
left hand side of (6.13) gives a valid upper statistical bound for the optimal
value of the three-stage problem.
In order to improve the above statistical lower bound let us consider the
following optimization problem
Min
x12X1 c1x1 þ 1
N
X
N
i¼1
Qðx1, i
2, i
3Þ:
ð6:14Þ
Problem (6.14) can be considered as a two-stage program with scenarios
ði
2, i
3Þ, i ¼ 1, . . . , N, having equal probabilities N1. We have that the optimal
value of (6.14) gives a valid and consistent statistical lower bound for the two-
stage problem (6.7)–(6.8). Yet for the three-stage problem it gives a valid, but
not consistent24 lower statistical bound.
Let us observe that if the number of scenarios of the considered (true) three-
stage problem is ﬁnite, then some of the generated second stage vectors i
2 can
be equal to each other. In that case we can view the generated sample as a
scenario tree and associate with it a (sample) three-stage stochastic pro-
gramming problem. The program (6.14) becomes then a two-stage relaxation
of the obtained three-stage sample program. Note, however, that if the
number of scenarios K1 at the second stage of the considered (true) three-stage
problem is very large, then the probability that some of ni
2 are equal to each
other is very small unless the sample size N is comparable with K1. For example,
24 Unless the optimal value of the three-stage problem coincides with the optimal value of its two-stage
relaxation (6.7) and (6.8).
402
A. Shapiro

if each scenario at the second stage can happen with equal probability K1
1 ,
then the probability that at least two of ni
2 are equal to each other is
N ¼ 1 
Y
N1
i¼1
1  i
K1
	

	 1  eNðN1Þ=ð2K1Þ:
In order to attain N at a given level  2 (0, 1), one needs then a sample of size
N 	
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2K1 log½ð1  Þ1
p
. This shows that if K1 is very large, then trying to
construct a scenario tree by sampling from the distribution of the random
vector (n2, n3) does not help much in improving the statistical lower bound
derived from the program (6.14). Moreover, if n2 has a continuous
distribution, then the probability that some of ni
2 are equal to each other is
zero for any sample size. Therefore, in that case such sampling will never
produce a scenario tree structure.
The above discussion shows that a valid upper statistical bound cannot be
obtained by a straightforward sampling. In order to compute such an upper
bound one needs to construct an implementable and feasible policy. Recall
that a sequence of mappings xt(  ), t ¼ 1, . . . , T, is called an implementable
policy if x1ðÞ ¼ x1 2 Rn1 and each xtðÞ 2 Rnt, t ¼ 2, . . . , T, is a function of
x1 and the history ½1,t :¼ ð1, . . . , tÞ of the process up to time t. An
implementable policy is feasible if it satisﬁes, w.p.1., the corresponding
feasibility constraints at each stage t ¼ 1, . . . , T. Given any implementable and
feasible25 policy x1, x2ðx1, ½1,2Þ, . . . , xTðx1, ½1,TÞ, the expectation
E½c1x1 þ c2x2ðx1, n½1,2Þ þ    þ cTxTðx1, n½1,TÞ
ð6:15Þ
provides an upper bound for the optimal value of the true multistage problem.
The above expectation can be estimated by the average
1
N
X
N
i¼1
½c1x1 þ ci
2x2ðx1, i
½1,2Þ þ    þ ci
TxTðx1, i
½1,TÞ
ð6:16Þ
for a generated sample i
2, . . . , i
T of N realizations of the random process
n2, . . . , nT.
In the case of two-stage problem (i.e., for T ¼ 2), one can construct an
implementable and feasible policy by choosing a feasible ﬁrst stage point
x1 2 X1 and computing x2(x1, 2) as an optimal solution of the corresponding
second stage problem26
Min
x2
c2x2
subject to
A21x1 þ A22x2 ¼ b2, x2  0:
ð6:17Þ
25 Recall that 1 is not random. Therefore, the decision variables actually do not depend on 1, we
write 1 in [1,t] for uniformity of notation. In particular, x2(x1, [1,2]) ¼ x2(x1, 2).
26 Recall that 2 ¼ (c2, A21, A22, b2).
Ch. 6. Monte Carlo Sampling Methods
403

For such choice of the policy, we have that c2x2(x1, 2) is equal to the optimal
value of the above problem (6.17), and hence the statistical upper bound (6.16)
is the same as the one used in Section 4.1. For T>2 one would like to
construct x2(x1, 2) as an optimal solution of the problem (6.2), and so on for
x3(x1, [1,3]), etc. Note, however, that this would require solving multistage
programming problems and numerically may be infeasible.
To summarize the discussion of this section we can say the following:

Any SAA method provides a valid statistical lower bound for the
optimal value of the true stochastic program. However, direct sampling
from the distribution of the random data vector n ¼ (n1, n2, . . . , nT) does
not give a consistent statistical lower bound if T  3.

If the (total) number K of scenarios is ﬁnite, then by direct sampling
from the scenario population, one can eventually reconstruct the
scenario tree of the true problem. However, for T  3 and K very large,
the sample size which will be required for a reasonable approximation of
the true scenario tree would be comparable with K.

For T  3, by taking a feasible point x1 2 X1 of the ﬁrst stage program
and then applying the SAA procedure in a straightforward way, as it
was discussed above, to a generated random sample of n, does not give a
valid statistical upper bound for the optimal value of the corresponding
multistage program.

In order to compute a valid statistical upper bound one needs to
construct an implementable and feasible policy. However, for T  3, it
could be diﬃcult to construct such a policy which will provide a tight
and numerically feasible upper bound.
In order to improve these bounds one needs to increase the sample size at
every stage conditionally on the scenarios generated at the previous stage. We
discuss this in the next section.
6.2
Conditional sampling of multistage programs
For the sake of simplicity we discuss in this section the linear multistage
program (6.1) with T ¼ 3. Let us generate a random sample in the following
way. First we generate a random sample
i
2 ¼ ðci
2, Ai
21, Ai
22, bi
2Þ,
i ¼ 1, . . . , N1,
of N1 replications of the random vector n2. Then for every i 2 {1, . . . , N1}, we
generate a random sample
ij
3 ¼ ðcij
3, Aij
32, Aij
33, bij
3Þ,
j ¼ 1, . . . , N2,
404
A. Shapiro

from the conditional distribution of n3 given the event fn2 ¼ i
2g. In that way
we obtain the following three-stage stochastic program
Min
x1
c1x1 þ 1
N1
X
N1
i¼1
^Q2,N2ðx1, i
2Þ
subject to
A11x1 ¼ b1, x1  0,
ð6:18Þ
where ^Q2, N2ðx1, i
2Þ is the optimal value of
Min
x2
ci
2x2þ 1
N2
X
N2
j¼1
Q3ðx2, ij
3Þ
subject to
Ai
21x1þAi
22x2 ¼ bi
2, x2  0,
ð6:19Þ
with Q3(x2, 3) being the optimal value of the problem (6.6).
We refer to the above sampling scheme as the conditional sampling. The
sample size of third stage scenarios, associated with each second stage
scenario, does not need to be the same, we assumed it to be constant for
the sake of simplicity. The constructed three-stage stochastic programming
problem (6.18)–(6.19) has N ¼ N1N2 scenarios, each with equal probability 1/
N. It can be noted that for any ﬁxed j 2 {1, . . . , N2} in the above conditional
sampling, the corresponding sample ði
2, ij
3Þ, i ¼ 1, . . . , N1, is a random
sample of the type (6.9), i.e., is derived from the distribution of the random
vector (n2, n3). Therefore, if N2 ¼ 1, then the above conditional sampling
becomes the same as the sampling (6.9). Note also that at this stage we do
not specify how the conditional samples ij
3 are generated. For example, we do
not necessarily assume that for diﬀerent i, k 2 {1, . . . , N1} the corresponding
random samples nij
3 and nkj
3 , j ¼ 1, . . . , N2, are independent of each other
conditional on ni
2 and nk
2, respectively.
As it was discussed in the previous section (see (6.4) in particular), we have
that
Q2ðx1, i
2Þ ¼
inf
Ai
21x1þAi
22x2¼bi
2
x20
ci
2x2 þ E
1
N2
X
N2
j¼1
Q3ðx2, nij
3Þ
n2 ¼ i
2
"
#
(
)
 E
inf
Ai
21x1þAi
22x2¼bi
2
x20
ci
2x2 þ 1
N2
X
N2
j¼1
Q3ðx2, nij
3Þ
(
)n2 ¼ i
2
2
64
3
75
¼ E
^Q2,N2ðx1, n2Þjn2 ¼ i
2
h
i
:
ð6:20Þ
Ch. 6. Monte Carlo Sampling Methods
405

We also have that
inf
x12X1 c1x1 þ E½Q2ðx1, n2Þ


 E
inf
x12X1 c1x1 þ 1
N1
X
N1
i¼1
Q2ðx1, ni
2Þ
(
)
"
#
:
ð6:21Þ
It follows from (6.20) and (6.21) that the optimal value ^vN1,N2 of the ﬁrst stage
(6.18), of the problem (6.18)–(6.19), gives a valid statistical lower bound for
the optimal value v* of the corresponding (true) three-stage stochastic
programming problem.
As it was shown in Section 2.1 (see Theorem 4 in particular), under mild
boundedness conditions, for any ﬁxed x1 and i
2 the estimator ^Q2,N2ðx1, i
2Þ
converges to Q2ðx1, i
2Þ w.p.1 as N2 tends to inﬁnity. Therefore, it is natural to
expect that ^vN1,N2 ! v* w.p.1 as N1 ! 1 and N2 ! 1, i.e., that ^vN1,N2 is a
consistent estimator of v*. And, indeed, it is possible to show that this holds
true under some regularity conditions. Note, however, that although
conceptually important such consistency result in itself is insuﬃcient for a
justiﬁcation of the conditional sampling. If, in the case of a ﬁnite number of
scenarios, the sample size, which is required for a reasonably accurate
approximation of the true problem, is comparable with the total number of
scenarios, one does not need sampling. Unfortunately, at this moment we do
not have a useful theory or numerical evidence for rates of convergence
of Monte Carlo sampling methods in multistage programming. Note also
that for T-stage problems the above conditional sampling, with the corres-
ponding branching of sizes N1, N2, . . . , NT1, results in N ¼ N1 N2    NT1
number of scenarios. That is, in conditional sampling the total number
of scenarios of SAA problems grows fast with increase of the number of
stages.
6.3
An example of financial planning
In this section we discuss the example of ‘‘Financial Planning’’ described in
section ‘‘Examples of Multistage Models’’ of the chapter ‘‘Stochastic
Programming Models’’, to which we refer for details. We now brieﬂy recall
the basic model. Let Rt ¼ (R1t, . . . , Rnt), t ¼ 1, . . . , T, be a random process
representing returns of n investment opportunities, and U(W ) be a chosen
utility function. For the sake of simplicity we assume that the process Rt is
Markovian, i.e., for all t ¼ 1, . . . , T1, the conditional distribution of Rt þ 1
given (R1, . . . , Rt) is the same as the conditional distribution of Rt þ 1 given Rt.
The associated (multistage) stochastic programming problem is deﬁned by the
cost-to-go functions Qt(xt1, Rt), t ¼ 1, . . . , T1, and the following ﬁrst stage
406
A. Shapiro

problem at t ¼ 0,
Max
x0
E½Q1ðx0, R1Þ
s:t:
X
n
i¼1
xi0 ¼ W0,
xi0  0, i ¼ 1, . . . , n:
ð6:22Þ
Here W0 is the initial wealth, the function QT1ðxT2, RT1Þ is the optimal
value of the problem
Max
xT1 E U
X
n
i¼1
ð1 þ RiTÞxi,T1
"
#RT1 ¼ RT1
(
)
s:t:
X
n
i¼1
xi,T1 ¼
X
n
i¼1
ð1 þ Ri,T1Þxi,T2,
xi,T1  0, i ¼ 1, . . . , n,
ð6:23Þ
and Qt(xt1, Rt) is the optimal value of the problem
Max
xt
E½Qtþ1ðxt, Rtþ1ÞjRt ¼ Rt
s:t:
X
n
i¼1
xit ¼
X
n
i¼1
ð1 þ RitÞxi,t1,
xit  0, i ¼ 1, . . . , n,
ð6:24Þ
for t ¼ T2, . . . , 1. Note that the above is a maximization rather than
minimization problem.
As it was mentioned in the chapter ‘‘Stochastic Programming Models’’,
the
cost-to-go
function
Qt(xt1, Rt)
depends
on
xt1
through
Wt ¼
Pn
i¼1 ð1 þ RitÞxi,t1 only. That is, if
~QtðWt, RtÞ is the optimal value of the
problem
Max
xt
E½Qtþ1ðxt, Rtþ1ÞjRt ¼ Rt
s:t:
X
n
i¼1
xit ¼ Wt,
xit  0, i ¼ 1, . . . , n,
ð6:25Þ
then Qtðxt1, RtÞ ¼ ~QtðPn
i¼1 ð1 þ RitÞxi,t1, RtÞ.
Ch. 6. Monte Carlo Sampling Methods
407

We can deﬁne the following implementable and feasible policy for the
above problem. Choose a feasible vector x0 2 Rn for the problem (6.22), and
deﬁne
xit :¼ ð1 þ RitÞxi,t1 ¼
Y
t
¼1
ð1 þ RiÞ
"
#
xi0,
t ¼ 1, . . . , T  1:
We have that xt is a function of R½1,t :¼ ðR1, . . . , RtÞ and x0, and hence deﬁnes
an implementable policy, and satisﬁes the constraints of (6.24) and hence
is feasible. This policy corresponds to the initial investment x0 without
rebalancing the portfolio at the later stages. It gives the following lower bound
(remember that this is a maximization problem) for the multistage problem
(6.22)–(6.24):
E U
X
n
i¼1
Y
T
t¼1
ð1 þ RitÞ
"
#
xi0
 
!
(
)
:
ð6:26Þ
In order to investigate the value of this lower bound suppose further that
U(W ):W. We have then that
QT1ðxT2, RT1Þ ¼ MT1ðRT1Þ
X
n
i¼1
ð1 þ Ri,T1Þxi,T2,
ð6:27Þ
where MT1ðRT1Þ :¼ max1in E½1 þ RiTjRT1 ¼ RT1,
QT2ðxT3, RT2Þ ¼ MT2ðRT2Þ
X
n
i¼1
ð1 þ Ri,T2Þxi,T3,
ð6:28Þ
where
MT2ðRT2Þ:¼ max
1in E
max
1in E½1þRiTjRT1
	

ð1þRi,T1ÞjRT2 ¼RT2


¼ max
1in E MT1ðRT1Þð1 þ Ri,T1ÞjRT2 ¼ RT2


,
and so on with
Qtðxt1, RtÞ ¼ MtðRtÞ
X
n
i¼1
ð1 þ RitÞxi,t1,
ð6:29Þ
408
A. Shapiro

and MtðRtÞ :¼ max1in EfMtþ1ðRtþ1Þð1 þ Ri,tþ1ÞjRt ¼ Rtg, t ¼ T2, . . . , 1.
In particular, suppose for the moment that the process Rt is between stages
independent. Then the optimal value v* of the multistage problem is given by
v* ¼ W0
Y
T
t¼1
max
1in it
	

,
ð6:30Þ
where it :¼ 1 þ E½Rit. On the other hand, maximization of the expectation
(6.26), subject to the feasibility constraints of problem (6.22), gives the
following ‘‘best’’ lower bound of the form (6.26):
vL ¼ W0 max
1in
Y
T
t¼1
it
 
!
:
ð6:31Þ
Therefore, one can easily construct examples where the ratio v*/vL can be
arbitrary large. It should be not surprising that this ratio could be large in
cases where the maximal value of the expected return moves from one asset to
another with the stages of the process. Recall that, in the considered case
U(W):W, the multistage problem can be solved in a completely myopic
fashion by investing everything in the asset with the maximal expected return
in the next period. Therefore, if it ¼ i do not depend on t, then there is no
need to rebalance the portfolio and v* ¼ vL ¼ W0ðmax1in iÞT.
Suppose now that we relax the nonanticipativity constraints starting
from the second stage of the multistage problem (see section ‘‘The Case of
Finitely Many Scenarios’’ of chapter ‘‘Stochastic Programming Models’’ for a
discussion of such relaxation). The obtained two-stage stochastic program has
the following optimal value
vU ¼ W0E
Y
T
t¼1
max
1in ð1 þ RitÞ
"
#
,
ð6:32Þ
which gives an upper bound for v*. If we assume, further, the between stages
independence, then vU ¼ W0
QT
t¼1 E½max1inð1 þ RitÞ. We have that, for all t,
E max
1in ð1 þ RitÞ


 max
1in E½1 þ Rit ¼ max
1in it:
ð6:33Þ
The diﬀerence between the left and right hand sides of (6.33) tends to be bigger
if there is a larger number of assets with the maximal (or nearly) maximal
expected return.
Ch. 6. Monte Carlo Sampling Methods
409

7
Stochastic generalized equations
In this section we discuss the following so-called stochastic generalized
equations. Consider a random vector n, whose distribution is supported on
a set   Rd, a mapping : Rn   ! Rn and a multifunction27 : Rn!
!Rn.
Suppose that the expectation  (x) :¼ E[(x, n)] is well deﬁned. We refer to
ðxÞ 2 ðxÞ
ð7:1Þ
as true, or expected value, generalized equation and say that a point x* 2 Rn is
a solution of (7.1) if  (x*) 2 (x*).
The above abstract setting includes the following cases. If (x) :¼ {0} for
every x 2 Rn, then (7.1) becomes the ordinary equation  (x) ¼ 0. As another
example, let (  ) :¼ NX(  ), where X is a nonempty closed convex subset of Rn
and NX(x) denotes the outwards normal cone to X at x. Recall that by the
deﬁnition NX(x) ¼ D if x 62 X. In that case x* is a solution of (7.1) iﬀx* 2 X
and the following, so-called variational inequality, holds
ðx  x*ÞTðx*Þ  0,
8 x 2 X:
ð7:2Þ
Since the mapping  (x) is given in the form of the expectation, we refer to
such variational inequalities as stochastic variational inequalities. Note that if
X ¼ Rn, then NX(x) ¼ {0} for any x 2 Rn, and hence in that case the above
variational inequality is reduced to the equation  (x) ¼ 0. Let us also remark
that if ðx, Þ :¼ rxFðx, Þ, for some real valued function F(x, ), and the
interchangeability formula (4.17) holds, i.e.,
 (x) ¼ rf(x), then (7.2)
represents ﬁrst order necessary, and if f(x) is convex, suﬃcient conditions
for x* to be an optimal solution for the optimization problem (1.1).
Also if the feasible set X of the optimization problem (1.1) is deﬁned by
constraints in the form (4.13), with gjðxÞ :¼ E½Gjðx, nÞ, j ¼ 1, . . . , p, then the
corresponding KKT optimality conditions (4.14) can be written in a form of
variational inequality. That is, let z :¼ ðx, 	Þ 2 Rnþp and
Lðz, Þ :¼ Fðx, Þ þ
X
p
j¼1
	jGjðx, Þ
ð7:3Þ
be the Lagrangian associated with the stochastic problem (1.1). Deﬁne
ðz, Þ :¼ ðrxLðz, Þ, G1ðx, Þ, . . . , Gpðx, ÞÞ
and
ðzÞ :¼ NKðzÞ,
ð7:4Þ
27 Recall that (x) is said to be a multifunction if it maps a point x 2 Rn into a subset of Rn.
410
A. Shapiro

where K :¼ Rn  Rq  Rpq
þ
 Rnþp. Then assuming that the interchange-
ability formula holds, we have that
ðzÞ :¼ E½ðz, nÞ ¼
rf ðxÞ þ
X
p
j¼1
	jrgjðxÞ, g1ðxÞ, . . . , gpðxÞ
 
!
,
ð7:5Þ
and hence variational inequality  (z) 2 NK(z) represents the KKT optimality
conditions for the true optimization problem.
We make the following assumption about the multifunction (x).
(E1) The multifunction (x) is closed, that is, the following holds: if xk ! x,
yk 2 (xk) and yk ! y, then y 2 (x).
The above assumption implies that the multifunction (x) is closed valued,
i.e., for any x 2 Rn the set (x) is closed. For variational inequalities
assumption (E1) always holds, i.e., the multifunction x  NX(x) is closed.
Now let 1, . . . , N be a random sample of N realizations of the random
vector n, and
^NðxÞ :¼ N1 PN
i¼1 ðx, iÞ be the corresponding sample
average estimate of  (x). We refer to
^NðxÞ 2 ðxÞ
ð7:6Þ
as the SAA generalized equation. There are standard numerical algorithms for
solving nonlinear equations which can be applied to (7.6) in the case
(x):{0}, i.e., when (7.6) is reduced to the ordinary equation ^NðxÞ ¼ 0.
More recently numerical procedures were developed for solving variational
inequalities. We are not going to discuss such numerical algorithms but rather
concentrate on statistical properties of solutions of SAA equations. We denote
by S and ^SN the sets of (all) solutions of the true (7.1) and SAA (7.6)
generalized equations, respectively.
7.1
Consistency of solutions of the SAA generalized equations
In this section we discuss convergence properties of the SAA solutions.
Recall that D(A, B) denotes the deviation of the set A from the set B.
Proposition 19. Let C be a compact subset of Rn such that S  C. Suppose that:
(i) assumption (E1) holds, (ii) the mapping  (x) is continuous on C, (iii) w.p.1 for
N large enough the set ^SN is nonempty and ^SN  C, (iv) ^NðxÞ converges to
 (x) w.p.1 uniformly on C as N ! 1. Then Dð ^SN, SÞ ! 0 w.p.1 as N ! 1.
Proof. The above result basically is deterministic in the sense that if we view
^NðxÞ ¼ ^Nðx, !Þ as deﬁned on a common probability space, then it should be
Ch. 6. Monte Carlo Sampling Methods
411

veriﬁed for a.e. !. Therefore, we omit saying ‘‘w.p.1’’. Consider a sequence
^xN 2 ^SN. Because of the compactness assumption (iii), by passing to a
subsequence if necessary, we only need to show that if ^xN converges to a point
x, then x 2 S (compare with the proof of Theorem 4). Now since it is assumed
that  (  ) is continuous and ^NðxÞ converges to  (x) uniformly, it follows that
^Nð ^xNÞ ! ðxÞ. Since ^Nð ^xNÞ 2 ð ^xNÞ, it follows by assumption (E1) that
ðxÞ 2 ðxÞ, which completes the proof.
u
A few remarks about the assumptions involved in the above consistency
result are now in order. By Proposition 7 we have that, in the case of iid
sampling, the assumptions (ii) and (iv) of the above proposition are satisﬁed
for any compact set C if the following assumption holds.
(E2) For every  2  the function (  , ) is continuous on C, and jj(x, )jj,
x 2 C, is dominated by an integrable function.
There are two parts to the assumption (iii) of Proposition 19, namely, that
the SAA generalized equations do not have a solution which escapes to
inﬁnity, and that they possess at least one solution w.p.1 for N large enough.
The ﬁrst of these assumptions can be often veriﬁed by ad hoc methods. The
second assumption is more subtle. We are going to discuss it next. The
following concept of strong regularity is due to Robinson (1980).
Deﬁnition 20. Suppose that the mapping  (x) is continuously diﬀerentiable.
We say that a solution x* 2 S is strongly regular if there exist neighborhoods
N1 and N2 of 0 2 Rn and x*, respectively, such that for every  2 N1 the
following (linearized) generalized equation
 þ ðx*Þ þ rðx*Þðx  x*Þ 2 ðxÞ
ð7:7Þ
has a unique solution in N2, denoted xðÞ, and xðÞ is Lipschitz continuous on
N1.
Note that it follows from the above conditions that xð0Þ ¼ x*. In case
(x):{0}, strong regularity simply means that the n  n Jacobian matrix
J :¼ r  (x*) is invertible, or in other words nonsingular. Also in the case of
variational inequalities, the strong regularity condition was investigated
extensively, we discuss this later.
Let V be a compact neighborhood of x*. Consider the space C1(V, Rn) of
continuously diﬀerentiable mappings  : V ! Rn equipped with the norm:
k k1,V :¼ sup
x2V
ðkðxÞk þ krðxÞkÞ:
412
A. Shapiro

The following (deterministic) result is essentially due to Robinson (1982)
(see also Bonnans and Shapiro, 2000, Theorem 5.13, and the following up
discussion).
Suppose that  (x) is continuously diﬀerentiable on V, i.e.,  2 C1(V, Rn).
Let x* be a strongly regular solution of the generalized equation (7.1). Then
there exists ">0 such that for any u 2 C1(V, Rn) satisfying jju  jj1,V  ", the
generalized equation u(x) 2 (x) has a unique solution
^x ¼ ^xðuÞ in a
neighborhood of x*, such that ^xðÞ is Lipschitz continuous (with respect the
norm jj  jj1,V), and
^xðuÞ ¼ xðuðx*Þ  ðx*ÞÞ þ oðku  k1,VÞ:
ð7:8Þ
By employing the above results for the mapping uðÞ :¼ ^NðÞ we immediately
obtain the following.
Proposition 21. Let x* be a strongly regular solution of the true generalized
equation (7.1), and suppose that  (x) and ^NðxÞ are continuously diﬀerentiable
in a neighborhood V of x* and k ^N  k1,V ! 0 w.p.1 as N ! 1. Then w.p.1
for N large enough the SAA generalized equation (7.6) possesses a unique
solution ^xN in a neighborhood of x*, and ^xN ! x* w.p.1 as N ! 1.
The assumption that k ^N  k1,V ! 0 w.p.1, in the above theorem, means
that ^NðxÞ and r ^NðxÞ converge w.p.1 to  (x) and r  (x), respectively,
uniformly on V. By Proposition 7, in the case of iid sampling this is ensured by
the following assumption.
(E3) For every  2  the mapping (  , ) is continuously diﬀerentiable on V,
and jj(x, )jj and jjrx(x, )jj, x 2 V, are dominated by an integrable
function.
Note that the assumption that (  , ) is continuously diﬀerentiable on
a neighborhood of x* is essential in the above analysis. By combining
Propositions 19 and 21 we obtain the following result.
Theorem 22. Let C be a compact subset of Rn and x* be a unique in C solution
of the true generalized equation (7.1). Suppose that: (i) assumption (E1) holds,
(ii) for every  2  the mapping (  , ) is continuously diﬀerentiable on C, and
jj(x, )jj and jjrx(x, )jj, x 2 C, are dominated by an integrable function,
(iii) the solution x* is strongly regular, (iv) ^NðxÞ and r ^NðxÞ converge w.p.1 to
 (x) and r  (x), respectively, uniformly on C. Then w.p.1 for N large enough
the SAA generalized equation possesses unique in C solution ^xN converging to x*
w.p.1 as N ! 1.
Ch. 6. Monte Carlo Sampling Methods
413

Note again that if the sample is iid, then the assumption (iv) in the above
theorem is implied by the assumption (ii) and hence is redundant.
7.2
Asymptotics of SAA estimators
By using the ﬁrst order approximation (7.8) it is also possible to derive
asymptotics of ^xN. Suppose for the moment that (x):{0}. Then strong
regularity means that the Jacobian matrix J :¼ r  (x*) is nonsingular, and
xðÞ is the solution of the corresponding linear equations and hence can be
written in the form
xðÞ ¼ x*  J1:
ð7:9Þ
By using (7.9) and (7.8) with uðÞ :¼ ^NðÞ, we obtain under certain regularity
conditions which ensure that the remainder in (7.8) is of order op(N1/2), that
N1=2ð ^xN  x*Þ ¼ J1YN þ opðN1=2Þ,
ð7:10Þ
where YN :¼ N1=2½ ^Nðx*Þ  ðx*Þ. Moreover, in the case of iid sample, we
have by the CLT that YN ) N(0, ), where  is the covariance matrix of the
random vector (x*, n). Consequently,
^xN
has asymptotically normal
distribution with mean vector x* and the covariance matrix N1J1J1.
Suppose now that (  ) :¼ NX(  ), with the set X being nonempty closed
convex and polyhedral, and let x* be a strongly regular solution of (7.1). Let
xðÞ be the (unique) solution, of the corresponding linearized variational
inequality (7.7), in a neighborhood of x*. Consider the cone
Cðx*Þ :¼ y 2 TXðx*Þ: yTðx*Þ ¼ 0


,
called the critical cone, and the Jacobian matrix J :¼ r  (x*). Then for all
 suﬃciently close to 0 2 Rn, we have that xðÞ  x* coincides with the solution
dðÞ of the variational inequality
 þ Jd 2 NCðx*ÞðdÞ:
ð7:11Þ
Note that the mapping dðÞ is positively homogeneous, i.e., for any  2 Rn
and t  0, it follows that dðtÞ ¼ tdðÞ. Similar to (7.10) we have, under
regularity conditions ensuring that the remainder term is of order op(N1/2),
that
N1=2ð ^xN  x*Þ ) dðYÞ,
ð7:12Þ
414
A. Shapiro

where Y N(0, ). It follows that ^xN is asymptotically normal iﬀthe mapping
dðÞ is linear. This, in turn, holds if the cone C(x*) is a linear space.
In the case (  ) :¼ NX(  ), with the set X being nonempty closed convex and
polyhedral, there is a complete characterization of the strong regularity in
terms of the so-called coherent orientation associated with the matrix
(mapping) J :¼ r  (x*) and the critical cone C(x*). The interested reader is
referred to Robinson (1992) and Gu¨ rkan et al. (1999) for a discussion of this
topic. Let us just remark that if C(x*) is a linear subspace of Rn, then the
variational inequality (7.11) can be written in the form
P þ PJd ¼ 0,
ð7:13Þ
where P denotes the orthogonal projection matrix onto the linear space C(x*).
Then x* is strongly regular iﬀthe matrix (mapping) PJ restricted to the space
C(x*) is invertible, or in other words nonsingular.
Suppose now that S ¼ {x*} is such that  (x*) belongs to the interior of
the set (x*). Then, since ^Nðx*Þ converges w.p.1 to  (x*), it follows that
the event f ^Nðx*Þ 2 ðx*Þg happens w.p.1 for N large enough. Moreover, by
the LD principle (see (8.15)) we have that this event happens with probability
approaching one exponentially fast. Of course, ^Nðx*Þ 2 ðx*Þ means that
^xN ¼ x* is a solution of the SAA generalized equation (7.6). Therefore, in
such case one may compute an exact solution of the true problem (7.1),
by solving the SAA problem, with probability approaching one exponentially
fast with increase of the sample size. Note that if (  ) :¼ NX(  ) and
x* 2 S, then  (x*) 2 int (x*) iﬀthe critical cone C(x*) is equal to {0}.
In that case the variational inequality (7.11) has solution d* ¼ 0 for any ,
i.e., dðÞ:0.
The above asymptotics can be applied, in particular, to the generalized
equation (variational inequality)  (z) 2 NX(z), where  (z) and NX(z) are
deﬁned in (7.4) and (7.5). Recall that this variational inequality represents the
KKT optimality conditions of the corresponding expected value optimization
problem. Therefore, in that way the asymptotics of the optimal solutions and
Lagrange multipliers of the associated SAA optimization problems can be
derived. In the case of optimization problems strong regularity of a point
z* ¼ (x*, 	*), where x* 2 S, is equivalent to a certain (strong) form of second
order optimality conditions. Also in that case the critical cone is a linear space,
and hence the SAA estimator ^zN ¼ ð ^xN, ^	NÞ is asymptotically normal, iﬀthe
strict complementarity condition holds.
Let us ﬁnally remark the following. Consider variational inequality (7.2).
Suppose that the set X is deﬁned by
X :¼ x 2 Rn : gjðxÞ  0, j ¼ 1, . . . , p


,
ð7:14Þ
Ch. 6. Monte Carlo Sampling Methods
415

where gj(x), j ¼ 1, . . . , p, are convex real valued functions. Suppose further that
the Slater condition holds. Then, for any x 2 X,
NXðxÞ ¼
z 2 Rn : z ¼
X
j2IðxÞ
jrgjðxÞ, j  0, j 2 IðxÞ
(
)
,
ð7:15Þ
where IðxÞ :¼ f j : gjðxÞ ¼ 0, j ¼ 1, . . . , pg. Therefore, in that case one can
proceed with statistical testing of a candidate solution x in exactly the same
way as in testing KKT optimality conditions in Section 4.2.
8
Appendix
8.1
Epiconvergence
Consider a sequence fk : Rn ! R, k ¼ 1, . . . , of extended real valued
functions. It is said that the functions fk epiconverge to a function f : Rn ! R,
written fk!
e f , if the epigraphs of the functions fk converge, in a certain set
valued sense, to the epigraph of f. It is also possible to deﬁne the
epiconvergence in the following equivalent way.
Deﬁnition 23. It is said that fk epiconverge to f if for any point x 2 Rn the
following two conditions hold: (i) for any sequence xk converging to x one has
lim inf
k!1 fkðxkÞ  f ðxÞ,
ð8:1Þ
(ii) there exists a sequence xk converging to x such that
lim sup
k!1
fkðxkÞ  f ðxÞ:
ð8:2Þ
Epiconvergence fk!
e f implies that the function f is lower semicontinuous.
Epiconvergence is discussed extensively in Rockafellar and Wets (1998),
Chapter 7. We need a few basic results from that theory. We denote by
arg min f the set of minimizers of f, i.e., x 2 arg min f iﬀf ðxÞ ¼ inf f ðxÞ, where
the inﬁmum is taken over all x 2 Rn. For "  0 we say that a point x 2 Rn
is an "-minimizer28 of f if f ðxÞ  inf f ðxÞ þ ". Clearly, for " ¼ 0 the set of
"-minimizers of f coincides with arg min f.
28 For the sake of convenience we allow in this section for a minimizer, or "-minimizer, x to be such
that f ðxÞ is not ﬁnite, i.e., can be equal to þ 1 or 1.
416
A. Shapiro

Proposition 24. Suppose that fk!
e f . Then
lim sup
k!1
½inf fkðxÞ  inf f ðxÞ:
ð8:3Þ
Suppose, further, that: (i) for some "k#0 there exists an "k-minimizer xk of fk(  )
such that the sequence xk converges to a point x. Then x 2 arg min f and
lim
k!1 ½inf fkðxÞ ¼ inf f ðxÞ:
ð8:4Þ
Proof. Consider a point x 2 Rn and let xk be a sequence converging to x such
that the inequality (8.2) holds. Then fk(xk)  inf fk(x). Together with (8.2) this
implies that
f ðxÞ  lim sup
k!1
fkðxkÞ  lim sup
k!1
½inf fkðxÞ:
Since the above holds for any x, the inequality (8.3) follows.
Now let xk be a sequence of "k-minimizers of fk converging to a point x. We
have then that fk(xk)  inf fk(x) þ "k, and hence by (8.3) we obtain
lim inf
k!1 ½inf fkðxÞ¼lim inf
k!1 ½inf fkðxÞþ"klim inf
k!1 fkðxkÞf ðxÞinf f ðxÞ:
Together with (8.3) this implies (8.4) and f ðxÞ ¼ inf f ðxÞ. This completes the
proof.
u
Assumption (i) in the above proposition can be ensured by various
boundedness conditions.
The following result is taken from Rockafellar and Wets (1998), Theorem
7.17.
Theorem 25. Let fk : Rn ! R be a sequence of convex functions and
f : Rn ! R be a convex lower semicontinuous function such that dom f has a
nonempty interior. Then the following are equivalent: (i) fk!
e f , (ii) there exists a
dense subset D of Rn such that fk(x) ! f(x) for all x 2 D, (iii) fk(  ) converges
uniformly to f(  ) on every compact set C that does not contain a boundary point
of dom f.
8.2
Uniform integrability, and Op(  ) and op(  ) notation
Let Yk, k ¼ 1, . . . , be a sequence of random variables converging in
distribution to a random variable Y. In general, convergence in distribution
does not imply convergence of the expected values E[Yk] to E[Y], as k ! 1,
Ch. 6. Monte Carlo Sampling Methods
417

even if all these expected values are ﬁnite. This implication holds under the
additional condition that Yk are uniformly integrable, that is
lim
c!1 sup
k2N
E½YkðcÞ ¼ 0,
ð8:5Þ
where Yk(c) :¼ jYkj if jYkj  c, and Yk(c) :¼ 0 otherwise. A simple suﬃcient
condition ensuring uniform integrability, and hence the implication that
Yk ) Y implies E[Yk] ! E[Y], is the following: there exists ">0 such that
supk E[jYkj1 þ "]<1.
The notation Op(  ) and op(  ) stands for a probabilistic analogue of the
usual order notation O(  ) and o(  ), respectively. That is, let Xk and Yk be
sequences of random variables. It is written that Yk ¼ Op(Xk) if for any ">0
there exists c>0 such that P(jYk/Xkj>c)  " for all k 2 N. It is written that
Yk ¼ op(Xk) if for any ">0 it holds that limk!1 PðjYk=Xkj > "Þ ¼ 0. Usually
this is used with the sequence Xk being deterministic. In particular, the
notation Yk ¼ Op(1) asserts that the sequence Yk is bounded in probability,
and Yk ¼ op(1) means that the sequence Yk converges in probability to zero.
8.3
Large deviations theory
Consider an iid sequence Y1, . . . , YN of replications of a real valued
random variable Y, and let ZN :¼ N1 PN
i¼1 Yi be the corresponding
sample average. Then for any real numbers a and t>0 we have that
PðZN  aÞ ¼ PðetZN  etaÞ, and hence, by Chebyshev’s inequality
PðZN  aÞ  etaE½etZN ¼ eta½Mðt=NÞN,
where M(t) :¼ E[etY] is the moment generating function of Y. Suppose that Y
has ﬁnite mean  :¼ E[Y] and let a  . By taking the logarithm of both sides
of the above inequality, changing variables t0 ¼ t/N and minimizing over t0>0,
we obtain
1
N log½PðZN  aÞ  IðaÞ,
ð8:6Þ
where
IðzÞ :¼ sup
t2R
ftz  ðtÞg
ð8:7Þ
is the conjugate of the logarithmic moment generating function (t) :¼
log M(t). In the LD theory, I(z) is called the (large deviations) rate function,
and the inequality (8.6) corresponds to the upper bound of Crame´ r’s LD
Theorem.
418
A. Shapiro

Note that the constraint t>0 is removed in the above deﬁnition of the rate
function I(  ). This is because of the following. Consider the function
 (t) :¼ ta(t). The function (t) is convex, and hence  (t) is concave.
Suppose that the moment generating function M(  ) is ﬁnite valued at some
t > 0. Then M(t) is ﬁnite for all t 2 ½0, t , and it follows by the Dominated
Convergence Theorem that M(t), and hence the function (t), are right side
diﬀerentiable at t ¼ 0. Moreover, the right side derivative of M(t) at t ¼ 0 is ,
and hence the right side derivative of  (t) at t ¼ 0 is positive if a>.
Consequently, in that case  (t)> (0) for all t>0 small enough, and hence
I(a)>0 and the supremum in (8.7) is not changed if the constraint t>0 is
removed. If a ¼ , then the supremum in (8.7) is attained at t ¼ 0 and hence
I(a) ¼ 0. In that case the inequality (8.6) trivially holds. Now if M(t) ¼ þ 1
for all t>0, then I(a) ¼ 0 for any a   and the inequality (8.6) trivially holds.
Note that for a   the upper bound (8.6) takes the form
1
N log½PðZN  aÞ  IðaÞ:
ð8:8Þ
The rate function I(z) is convex and has the following properties. Suppose that
the random variable Y has ﬁnite mean . Then I() ¼ 0 and I(z) attains its
minimum at z ¼ . Suppose, further, that the moment generating function
M(t) is ﬁnite valued for all t in a neighborhood of t ¼ 0. Then it follows by
the Dominated Convergence Theorem that M(t), and hence the function (t),
are inﬁnitely diﬀerentiable at t ¼ 0, and 0(0) ¼  and 00(0) ¼ 2, where
2 :¼ Var[Y ]. It follows by the above discussion that in that case I(a)>0 for
any a 6¼ . We also have then that I 0() ¼ 0 and I 00() ¼ 2, and hence by
Taylor’s expansion,
IðaÞ ¼ ða  Þ2
22
þ oðja  j2Þ:
ð8:9Þ
Consequently, for a close to  we can approximate I(a) by (a)2/22.
Moreover, for any ">0 there is a neighborhood N of  such that
IðaÞ  ða  Þ2
ð2 þ "Þ2 ,
8 a 2 N :
ð8:10Þ
In particular, we can take " ¼ 1.
The constant I(a) in (8.6) gives, in a sense, the best possible exponential rate
at which the probability P(ZN  a) converges to zero. This follows from the
Ch. 6. Monte Carlo Sampling Methods
419

lower bound
lim inf
N!1
1
N log½PðZN  aÞ  IðaÞ
ð8:11Þ
of Crame´ r’s LD Theorem, which holds for a  .
We also need to consider cases where the random variable Y can take value
þ 1 with positive probability p. In such a case E[Y] ¼ þ 1 and ZN ¼ þ 1 if
at least one Yi ¼ þ 1. We have then that for any a 2 R,
PðZN  aÞ ¼ ð1  pÞNPfZN  ajYi < þ1, i ¼ 1, . . . , Ng:
ð8:12Þ
Let Y0 be a random variable with probability distribution given by the pro-
bability distribution of Y conditional on Y< þ 1, and let I0(  ) be the large
deviations rate function of Y0. It follows then from (8.8) and (8.12) that
1
N log½PðZN  aÞ   logð1  pÞ1 þ %ðaÞI0ðaÞ


,
ð8:13Þ
where %(a) :¼ 1 if a<E[Y0], and %(a) :¼ 0 if a  E[Y0].
The above, one dimensional, LD results can be extended to multivariate
and even inﬁnite dimensional settings, and also to non iid random sequences.
In particular, suppose that Y is a d-dimensional random vector and let
 :¼ E[Y] be its mean vector. We can associate with Y its moment generating
function M(t), of t 2 Rd, and the rate function I(z) deﬁned in the same way as
in (8.7) with the supremum taken over t 2 Rd and tz denoting the standard
scalar product of vectors t, z 2 Rd. Consider a (Borel) measurable set A  Rd.
Then, under certain regularity conditions, the following Large Deviations
Principle holds:
 inf
z2intðAÞ IðzÞ  lim inf
N!1 N1 log½PðZN 2 AÞ
 lim sup
N!1
N1 log½PðZN 2 AÞ   inf
z2clðAÞ IðzÞ,
ð8:14Þ
where
int(A)
and
cl(A)
denote
the
interior
and
topological
closure,
respectively, of the set A. In the above one dimensional setting, the LD
principle (8.14) was derived for sets A :¼ [a, þ 1).
We have that if  2 int(A) and the moment generating function M(t) is ﬁnite
valued for all t in a neighborhood of 0 2 Rd, then infz2Rdnðint AÞ IðzÞ is positive.
Moreover, if the sequence is iid, then
lim sup
N!1
N1 log½PðZN 62 AÞ < 0,
ð8:15Þ
420
A. Shapiro

i.e., the probability P(ZN 2 A) ¼ 1P(ZN 62 A) approaches one exponentially
fast as N tends to inﬁnity. For a thorough discussion of the Large Deviations
theory, the interested reader is referred to Dembo and Zeitouni (1998), for
example.
9
Bibliographic notes
The idea of using Monte Carlo sampling for solving stochastic optimization
problems of the form (1.1) certainly is not new. There is a variety of sampling
based optimization techniques, which were suggested in the literature. It will
be beyond the scope of this chapter to give a comprehensive survey of these
methods, we mention a few approaches related to the material of this chapter.
One approach uses the Inﬁnitesimal Perturbation Analysis (IPA) techniques
to estimate the gradients of f(  ), which consequently are employed in the
Stochastic Approximation (SA) method. For a discussion of the IPA and SA
methods we refer to Ho and Cao (1991), Glasserman (1991), Kushner and
Clark (1978) and Nevelson and Hasminskii (1976), respectively. For an
application of this approach to optimization of queueing systems see Chong
and Ramadge (1993) and L’Ecuyer and Glynn (1994), for example. Closely
related to this approach is the Stochastic Quasi-Gradient method (see
Ermoliev, 1983).
Another class of methods uses sample average estimates of the values of the
objective function, and may be its gradients (subgradients), in an ‘‘interior’’
fashion. Such methods are aimed at solving the true problem (1.1) by
employing sampling estimates of f(  ) and rf(  ) blended into a particular
optimization algorithm. Typically, the sample is updated or a diﬀerent sample
is used each time function or gradient (subgradient) estimates are required at a
current iteration point. In this respect we can mention, in particular, the
statistical L-shaped method of Infanger (1994) and the stochastic decomposi-
tion method of Higle and Sen (1996b).
In this chapter we mainly discussed an ‘‘exterior’’ approach, in which a
sample is generated outside of an optimization procedure and consequently
the constructed SAA problem is solved by an appropriate deterministic
optimization algorithm. There are several advantages in such approach. The
method separates sampling procedures and optimization techniques. This
makes it easy to implement and, in a sense, universal. From the optimization
point of view, given a sample 1, . . . , N, the obtained optimization problem
can be considered as a stochastic program with the associated scenarios
1, . . . , N, each taken with equal probability N1. Therefore, any optimization
algorithm which is developed for a considered class of stochastic programs
can be applied to the constructed SAA problem in a straightforward way.
Also the method is ideally suited for a parallel implementation. From the
theoretical point of view, as it was shown in the previous sections, there is
available a quite well developed statistical inference of the SAA method. This,
Ch. 6. Monte Carlo Sampling Methods
421

in turn, gives a possibility of error estimation, validation analysis and hence
stopping rules. Finally, various variance reduction techniques can be
conveniently combined with the SAA method.
It is diﬃcult to point out an exact origin of the SAA method. The idea is
simple indeed and it was used by various authors under diﬀerent names.
Variants of this approach are known as the stochastic counterpart method
(Rubinstein
and
Shapiro,
1990,
1993)
and
sample-path
optimization
(Plambeck et al., 1996; Robinson, 1996), for example. Also similar ideas were
used in statistics for computing maximum likelihood estimators by Monte
Carlo techniques based on Gibbs sampling (see, e.g., Geyer and Thompson,
1992 and references therein). Numerical experiments with the SAA approach,
applied to linear and discrete (integer) stochastic programming problems, can
be also found in more recent publications (Ahmed and Shapiro, 2002;
Linderoth et al., 2002; Verweij et al., 2003).
Statistical theory of the SAA estimators is closely related to the statistical
inference of the Maximum Likelihood (ML) method and M-estimators.
Starting with a pioneering work of Wald (1949), consistency properties of the
Maximum
Likelihood
and
M-estimators
were
studied
in
numerous
publications. Epi-convergence approach to studying consistency of statistical
estimators was developed in Dupacˇ ova´ and Wets (1988). In the context of
stochastic programming, consistency of SAA estimators was also investigated
by tools of epi-convergence analysis in King and Wets (1991) and Robinson
(1996). Uniform Laws of Large Numbers take their origin in the Glivenko–
Cantelli theorem. For a further discussion of the uniform LLN we refer to
van der Vaart and Wellner (1996), and for applications to stochastic
programming to the recent paper by Pﬂug et al. (1998).
Asymptotic normality of M-estimators was proved, under quite weak
diﬀerentiability assumptions, in Huber (1967). For a further discussion, and
additional references, of the asymptotics of SAA optimal solutions see chapter
‘‘Stochastic Optimization and Statistical Inﬂuence’’ of this book. Theorems 10
and 11 are taken from Shapiro (1991).
It is possible to show that in smooth (diﬀerentiable) cases, and under some
mild regularity conditions, the (unconstrained) SAA estimators ^xN converge
to the (unique) optimal solution x* of the true problem at the same asymptotic
rate as the corresponding stochastic approximation estimators based on the
asymptotically optimal step sizes (Shapiro, 1996). As it is shown in Section 3,
the situation is quite diﬀerent in cases where the feasible set X is ﬁnite or the
problem is polyhedral. Presentation of Sections 3.1 and 3.2 is based on
Kleywegt et al. (2001), and of Section 3.3 on Shapiro and Homem-de-Mello
(2000). The discussion of conditioning of stochastic programs is based on
Shapiro et al. (2002). It is somewhat surprising that some problems with
astronomically large number of scenarios are very well conditioned and can be
solved exactly with a small sample size (see Linderoth et al., 2002 for such
numerical
examples).
Exponential
rates
of
convergence
in
stochastic
programming were also studied in Kaniovski et al. (1995) and Dai et al. (2000).
422
A. Shapiro

The statistical bounds of Section 4.1 were suggested in Norkin et al. (1998),
and developed further in Mak et al. (1999). The ‘‘common random numbers’’
estimator d
gap
gapN,MðxÞ of the optimality gap was introduced in Mak et al. (1999).
Proposition 16 is due to Norkin et al. (1998) and Mak et al. (1999). The KKT
statistical test, discussed in Section 4.2, was developed in Shapiro and
Homem-de-Mello (1998), so that the material of that section is based on
Shapiro and Homem-de-Mello (1998). See also Higle and Sen (1996a).
Proposition 17 is taken from Shapiro and Homem-de-Mello (2000).
For a discussion of variance reduction techniques in Monte Carlo sampling
we refer to Fishman (1999) and a survey paper by Avramidis and Wilson
(1996), for example. In the context of stochastic programming, variance
reduction techniques were discussed in Rubinstein and Shapiro (1993),
Dantzig and Infanger (1991), Higle (1998) and Bailey et al. (1999), for example.
Section 6 is based on Shapiro (2002). It appears by now that statistical
behavior of two-stage stochastic programming problems is quite well
understood with theoretical developments supported by numerical experi-
ments. It was demonstrated that huge two-stage linear programs, with
astronomically large number of scenarios, can be solved eﬃciently with a
proved accuracy. On the other hand, little is known about large scale
multistage programs. In a sense the conclusions of Section 6 are mostly
negative. At this moment we do not have a useful theory or numerical
evidence which can guide us in solving large multistage problems. So further
research in this direction is needed.
An extension of the SAA method to stochastic generalized equations is a
natural one. Stochastic variational inequalities were discussed by Gu¨ rkan et al.
(1999). Proposition 21 and Theorem 22 are similar to Theorems 1 and 2 in
Gu¨ rkan et al. (1999).
References
Ahmed, S., A. Shapiro (2002). The sample average approximation method for stochastic programs
with integer recourse. E-print available at http://www.optimization-online.org.
Avramidis, A.N., J.R. Wilson (1996). Integrated variance reduction strategies for simulation.
Operations Research 44, 327–346.
Bailey, T.G., P. Jensen, D.P. Morton (1999). Response surface analysis of two-stage stochastic linear
programming with recourse. Naval Research Logistics 46, 753–778.
Bonnans, J.F., A. Shapiro (2000). Perturbation Analysis of Optimization Problems, Springer-Verlag,
New York, NY.
Chong, E.K.P., P.J. Ramadge (1993). Optimization of queues using an inﬁnitesimal perturbation
analysis-based stochastic algorithm with general update times. SIAM Journal of Control and
Optimization 31, 698–732.
Dai, L., C.H. Chen, J.R. Birge (2000). Convergence properties of two-stage stochastic programming.
Journal of Optimization Theory and Applications 106, 489–509.
Dantzig, G.B., G. Infanger (1992). Large-scale stochastic linear programs—importance sampling and
Benders decomposition: Computational and Applied Mathematics, I (Dublin, 1991), North-
Holland, Amsterdam, pp. 111–120.
Ch. 6. Monte Carlo Sampling Methods
423

Dembo, A., O. Zeitouni (1998). Large Deviations Techniques and Applications, Springer-Verlag,
New York, NY.
Dupacˇ ova´ , J., R.J.B. Wets (1988). Asymptotic behavior of statistical estimators and of optimal
solutions of stochastic optimization problems. The Annals of Statistics 16, 1517–1549.
Ermoliev, Y. (1983). Stochastic quasi-gradient methods and their application to systems optimization.
Stochastics 4, 1–37.
Fishman, G.S. (1999). Monte Carlo, Concepts, Algorithms and Applications, Springer-Verlag,
New York.
Geyer, C.J., E.A. Thompson (1992). Constrained Monte Carlo maximum likelihood for dependent
data, (with discussion). Journal of the Royal Statistical Society, Series B 54, 657–699.
Glasserman, P. (1991). Gradient Estimation via Perturbation Analysis, Kluwer Academic Publishers,
Norwell, MA.
Gu¨ rkan, G., A.Y. O¨ zge, S.M. Robinson (1999). Sample-path solution of stochastic variational
inequalities. Mathematical Programming 21, 313–333.
Higle, J.L. (1998). Variance reduction and objective function evaluation in stochatsic linear programs.
INFORMS Journal on Computing 10(2), 236–247.
Higle, J.L., S. Sen (1996). Duality and statistical tests of optimality for two stage stochastic programs.
Mathematical Programming (Series B) 75(2), 257–275.
Higle, J.L., S. Sen (1996). Stochastic Decomposition: A Statistical Method for Large Scale Stochastic
Linear Programming, Kluwer Academic Publishers, Dordrecht.
Ho, Y.C., X.R. Cao (1991). Perturbation Analysis of Discrete Event Dynamic Systems, Kluwer
Academic Publishers, Norwell, MA.
Huber, P.J. (1967). The Behavior of Maximum Likelihood Estimates under Nonstandard Conditions,
Vol. 1, Univ. California Press pp. 221–233.
Infanger, G. (1994). Planning Under Uncertainty: Solving Large Scale Stochastic Linear Programs,
Boyd and Fraser Publishing Co, Danvers, MA.
Kaniovski, Y.M., A. King, R.J.-B. Wets (1995). Probabilistic bounds for the solutions of stochastic
programming problems. Annals of Operations Research 56, 189–208.
King, A.J., R.J.-B. Wets (1991). Epi-consistency of convex stochastic programs. Stochastics Stochastics
Rep. 34(1–2), 83–92.
Kleywegt, A.J., A. Shapiro, T. Homem-De-Mello (2001). The sample average approximation method
for stochastic discrete optimization. SIAM Journal of Optimization 12, 479–502.
Kushner,
H.J.,
D.S.
Clark
(1978).
Stochastic
Approximation
Methods
for
Constrained
and
Unconstrained Systems, Springer-Verlag, Berlin, Germany.
L’Ecuyer, P., P.W. Glynn (1994). Stochastic optimization by simulation: Convergence proofs for the
GI/G/1 queue in steady-state. Management Science 11, 1562–1578.
Linderoth, J., A. Shapiro, S. Wright (2002). The empirical behavior of sampling methods for stochastic
programming. Optimization Technical Report 02-01, Computer Sciences Department, University
of Wisconsin-Madison.
Mak, W.K., D.P. Morton, R.K. Wood (1999). Monte Carlo bounding techniques for determining
solution quality in stochastic programs. Operations Research Letters 24, 47–56.
Nevelson, M.B., R.Z. Hasminskii (1976). Stochastic Approximation and Recursive Estimation.
American Mathematical Society Translations of Mathematical Monographs, Vol. 47, Rhode
Island.
Norkin, V.I., G.Ch. Pﬂug, A. Ruszczyn´ ski (1998). A branch and bound method for stochastic global
optimization. Mathematical Programming 83, 425–450.
Pﬂug, G.Ch., A. Ruszczyn´ ski, R. Schultz (1998). On the Glivenko Cantelli problem in stochastic
programming: Linear recourse. Mathematics of Operations Research 23, 204–220.
Plambeck, E.L., B.R. Fu, S.M. Robinson, R. Suri (1996). Sample-path optimization of convex
stochastic performance functions. Mathematical Programming, Series B 75, 137–176.
Robinson, S.M. (1980). Strongly regular generalized equations. Mathematics of Operations Research 5,
43–62.
424
A. Shapiro

Robinson, S.M. (1982). Generalized equations and their solutions, part ii: Applications to nonlinear
programming. Mathematical Programming Study 19, 200–221.
Robinson, S.M. (1992). Normal maps induced by linear transformations. Mathematics of Operations
Research 17, 691–714.
Robinson, S.M. (1996). Analysis of sample-path optimization. Mathematics of Operations Research 21,
513–528.
Rockafellar, R.T., R.J.-B. Wets (1998). Variational Analysis, Springer, Berlin.
Rubinstein, R.Y., A. Shapiro (1990). Optimization of static simulation models by the score function
method. Mathematics and Computers in Simulation 32, 373–392.
Rubinstein, R.Y., A. Shapiro (1993). Discrete Event Systems: Sensitivity Analysis and Stochastic
Optimization by the Score Function Method, John Wiley & Sons, Chichester, England.
Shapiro, A. (1991). Asymptotic analysis of stochastic programs. Annals of Operations Research 30,
169–186.
Shapiro, A. (1996). Simulation-based optimization: Convergence analysis and statistical inference.
Stochastic Models 12, 425–454.
Shapiro, A. (2002). Statistical inference of multistage stochastic programming problems. E-print
available at http://www.optimization-online.org.
Shapiro, A., T. Homem-de-Mello (1998). A simulation-based approach to two-stage stochastic
programming with recourse. Mathematical Programming 81, 301–325.
Shapiro, A., T. Homem-de-Mello (2000). On rate of convergence of Monte Carlo approximations of
stochastic programs. SIAM Journal on Optimization 11, 70–86.
Shapiro, A., T. Homem de Mello, J.C. Kim (2002). Conditioning of convex piecewise linear stochastic
programs. Mathematical Programming, 94, 1–19.
van der Vaart, A.W., A. Wellner (1996). Weak Convergence and Empirical Processes, Springer-Verlag,
New York.
Verweij, B., S. Ahmed, A.J. Kleywegt, G. Nemhauser, A. Shapiro (2003). The sample average
approximation
method
applied
to
stochastic
routing
problems:
A
computational
study.
Computational Optimization and Applications 24, 289–333.
Wald, A. (1949). Note on the consistency of the maximum likelihood estimates. Annals Mathematical
Statistics 20, 595–601.
Ch. 6. Monte Carlo Sampling Methods
425

Chapter 7
Stochastic Optimization and Statistical Inference
G.Ch. Pflug
Department of Statistics and Decision Support Systems, University of Vienna,
Universita¨tsstrasse 5, A-1090 Vienna, Austria
Abstract
If the distribution of the random parameters of a stochastic program is
unknown, the empirical distribution based on a sample may be used as a proxy.
This empirical approximation is related to the ‘‘true’’ stochastic program in the
same way as a statistical estimate is related to the true parameter value.
Properties of statistical estimators, like consistency, asymptotical distributions
and the construction of conﬁdence regions are reviewed in the realm of
stochastic optimization. The entropic size of a stochastic program determines
the quality of the approximation. In case that random constraints are present,
the notion of epiconvergence replaces in a natural way the notion of uniform
convergence of functions. The asymptotic structures are described by the
asymptotic stochastic program associated to the sequence of empirical
programs.
Key words:
Empirical program, statistical estimates, asymptotic statistics, risk
functionals, entropic size, epiconvergence, asymptotic stochastic programs.
1
Uncertain and ambiguous optimization problems
In deterministic optimization, a decision x must be found, which minimizes
a known cost function f(x) among all possible candidates x lying in the feasible
set X  Rd, a closed subset of the euclidean d-dimensional space
Min
x2X f ðxÞ:
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
427

In stochastic optimization, the cost function is not exactly known at the time
when the decision is made. Only a stochastic model F(x, ) for the costs is
known, where  is some random vector deﬁned on a probability space
(0, A0, P), taking its values in Rm. The crucial point is that although the
particular value of  is unknown, its distribution is completely known. We
refer to this situation as the uncertainty problem. Since the decision maker is
not clairvoyant and does not know the actual value of , he/she cannot
minimize the cost function for each value of  separately, but has to minimize
some real functional F, which summarizes the random costs F(x, ) in an
appropriate manner. Think of the expectation functional E as the summariz-
ing functional for the moment. The uncertainty problem reads
Min
x2X f f ðxÞ ¼ E½Fðx, Þg
ð1:1Þ
or—using a more general summarizing functional—
Min
x2X f f ðxÞ ¼ F½Fðx, Þg:
ð1:2Þ
Any functional F: G!
F R, which maps G, a set of distribution functions on R,
onto the real line may be used as summarizing functional. We call such
functionals risk functionals. Examples for risk functionals are the expectation,
the variance, the median, quantiles, etc. A collection of widely used risk
functionals can be found in Section 4.
For simplicity, we assume for the moment that the set of constraints X does
not depend on the random vector . In Sections 7 and 8 of this chapter, we will
indicate how to deal with additional ‘‘random constraints’’, i.e., constraints
involving random variables such as
X \ fx: E½F1ðx, Þ  b1, . . . , E½FJðx, Þ  bJg:
Example 1. A one-period portfolio optimization problem. An investor has a
budget B to spend in m investment categories, like bonds, stocks or other
contracts. If one currency unit is invested in the ith category, then the value
after the holding period is i. Here  ¼ (1,. . . , m) is a vector of random price
changes.
If
xi
denotes
the
amount
invested
in
category
i,
then
Fðx, Þ ¼ Pm
i¼1 xii is the value of the portfolio at the end of the holding
period. The decision maker wants to maximize the risk-adjusted expected
return. He chooses for instance the expectation minus 10% of the mean
absolute deviation as risk functional, i.e.,
F½Fðx, Þ ¼ E½Fðx, Þ  1
10  EjFðx, Þ  E½Fðx, Þj:
428
G.C. Pflug

This value should be maximized (or its negative value should be minimized)
under the budget and the nonnegativity constraints
Min F½Fðx, Þ:
X
m
i¼1
xi ¼ B, xi  0
(
)
:
This is a typical stochastic optimization problem of the form (1.2).
The assumption that the distribution P, i.e., P(A) ¼ P{ 2 A} of the random
part  of the cost function is exactly known is rarely fulﬁlled. Typically, the
probability measure P is unknown (this is called the ambiguity problem) and
only some information about it is available.
In the ambiguity situation, the stochastic optimization problem gets an
additional diﬃculty: the unknown probability P has to be guessed through the
available information and this gives an additional source of error.
Typically, the available information is contained in a sample of historic
data. In other situations, moments or some other characteristics of the
unknown probability measure are known (see e.g., Gaivoronski et al., 1985).
In this chapter, we consider the case that a sample 1,. . . , N of independent,
identically distributed random variables with distribution P is available. This
sample may be used in two ways:

The parametric approach: A parametric family (P) of probability
measures is chosen as the true model and the parameter  is estimated by
an estimate ^ on the basis of the sample. The probability measure P ^ is
then taken as the distribution of  in (1.2).

The nonparametric approach: No assumption about a parametric family
is made. The empirical measure
^PN (see (2.4) below for its formal
deﬁnition), which puts mass 1/N on each observation in the sample,
serves as a proxy of the unknown P.
For illustration, consider the above portfolio optimization example: no
ﬁnancial analyst knows correct distribution of the price change vectors.
Typically, either the historical data distribution is used directly (the
nonparametric approach, called historic simulation by ﬁnance managers) or
some theoretical models are ﬁtted using prior knowledge and some data (the
parametric approach).
In this chapter, we treat only the nonparametric approach and study the
quality of this approximation. The quality of the parametric approach
depends strongly on the right choice of the parametric model.
The fact that the true probability measure P is unknown and replaced by
some data-based estimate apparently makes the problem harder, since one has
to cope with the statistical estimation error in addition. However, as a positive
eﬀect of this approximation, one typically gets an easier problem to solve,
Ch. 7. Stochastic Optimization and Statistical Inference
429

since the empirical distribution generated by the data sits on ﬁnitely many
points. To deal with such discrete distributions is much easier than to deal
with arbitrary (continuous) distributions. Just think of the fact, how much
easier it is to numerically calculate a ﬁnite sum than a multidimensional
integral.
The advantage in the numerical treatment of the ﬁnite-sample approxima-
tion sometimes outweighs the disadvantage of the additional approximation
error. As a consequence, an artiﬁcially generated sample may be used to
replace a nonambiguous model. The results for sampling approximation carry
of course over to the case of artiﬁcially generated samples. Notice, however,
that in the case that the sample is artiﬁcially generated, one has the freedom to
choose the sample in various ways. Instead of mimicking randomness by
pseudo-random numbers (Monte-Carlo method, see chapter Monte Carlo
Sampling Methods by Shapiro in this volume), one could also use a
nonrandom low-discrepancy quasi-random sequence (Quasi-Monte Carlo
method, see Niederreiter, 1992) or some other, well chosen discrete
approximation. The Monte-Carlo method allows to generate an approxima-
tion in a very simple way, however, it produces only random approximations
of the unknown distribution P, which is a disadvantage since the quality of the
approximation can only be stated in statistical terms.
In this chapter, we will only treat the approximation by sampling from a
sequence of either observed or artiﬁcially generated random variables.
2
The empirical problem
Denote by Gx the distribution function of the costs, parameterized by the
decision x
GxðuÞ ¼ PfFðx, Þ  ug ¼
Z
1fFðx, !Þug dPð!Þ:
ð2:3Þ
Here 1B is the indicator function of the set B
1BðuÞ ¼
1
u 2 B
0
u 62 B

Let 1,. . . , N be a random sample, independently and identically distributed
with the same distribution P. Denote by
^PN the empirical distribution
generated by this sample, i.e.,
^PNðAÞ ¼ 1
N
X
N
n¼1
1fn2Ag:
ð2:4Þ
430
G.C. Pflug

Notice that ^PN depends on the random sample and is therefore a random
probability measure. For every ﬁxed set A, ^PNðAÞ converges almost surely to
P(A) due the Strong Law of Large Numbers. If P is a probability measure on
a separable metric space, then ^PN converges as a measure almost surely in the
weak sense to P as N tends to inﬁnity. This basic fact of statistics was proved
by Varadarajan (1958).
Based on the empirical distribution ^PN of the random part of the cost
function, we may form the empirical cost distribution ^Gx,N, parameterized by
the decision x
^Gx,NðuÞ ¼ 1
N
X
N
n¼1
1fFðx,nÞug ¼
Z
1fFðx,!Þug d ^PNð!Þ,
ð2:5Þ
which is the empirical counterpart of (2.3).
The risk functional F maps distributions to real numbers. By a slight abuse
of notation, but with no danger of confusion, we use the notation F(Z) for a
random variable Z and F(GZ) for its distribution GZ in parallel. The main
problem (1.2) in new notation reads now
Min
x2X f f ðxÞ ¼ F½Gxg:
ð2:6Þ
Its empirical counterpart, which is based on the sample 1,. . . , N is
Min
x2X f ^fNðxÞ ¼ F½ ^Gx,Ng:
ð2:7Þ
The relation between f and ^fN is like in statistical estimation theory: ^fNðÞ
is an estimate of the unknown objective function f(  ) and arg minx2X ^fNðxÞ is
an estimate of the unknown solution arg minx 2 X f(x). Recall here the notion
of the arg min set
arg min
x2X
f ðxÞ :¼
z 2 X : f ðzÞ ¼ min
x2X f ðxÞ


:
The arg min set is empty if the minimum is not attained.
In statistics, the function f is called the criterion function. Estimates of the
arg min type are the most important group of estimates in statistics: they
include maximum-likelihood estimates, M-estimates, minimum-contrast and
minimum-distance estimates. In the usual setup of statistical estimation
theory, the sample 1,. . . , N stems from a distribution P, which is a member of
some family P. Here P may be a parametric family P ¼ ðPÞ2 or a
nonparametric family. In either case, suppose that a parametric function
Ch. 7. Stochastic Optimization and Statistical Inference
431

P 2 P ! (P) is given. This unknown parametric function is estimated by an
estimator ^N ¼ ^Nð1, . . . , NÞ based on the observed data.
Statistical convergence results are formulated for the whole family P, i.e., a
typical result reads: if the data stem from P*, then the estimate ^N converges to
the true * ¼ (P*), for all P* 2 P (Table 7.1).
Example 2. Quantile estimation and the newsboy problem. Suppose that we are
interested in estimating the -quantile * from a random distribution P with
distribution function G and continuous density g. Suppose that g(x)>0, if
G(x) ¼ . Then the -quantile * ¼ G1() is uniquely determined. The
statistician estimates * by the sample quantile.
The newsboy problem, introduced in the chapter Stochastic Programming
Models by Ruszczynski and Shapiro in this volume is a stochastic
optimization version of the quantile estimation problem. Recall that the
proﬁt function, i.e., the negative cost function is
Fðx, Þ ¼ ðs  cÞx þ ðr  sÞ½x  þ,
where x is the decision,  is the demand variable, s is the sell price, c is the buy
price and r is the return price (0<r<c<s). Let G(u) ¼ P{  u} and Gð1ÞðuÞ ¼
Eð½u  þÞ ¼
R u
1 ðu  vÞ dGðvÞ ¼
R u
1 GðvÞ dv. The objective function is
f ðxÞ ¼ E½Fðx, Þ ¼ ðs  cÞx þ ðr  sÞGð1ÞðxÞ:
By simple calculus one sees that every optimal solution * 2 arg min(f )
satisﬁes the necessary condition G(*) ¼ (sc)/(sr), i.e., is an -quantile of G,
Table 7.1
The relation between Statistical Estimation and Stochastic Optimization
Statistics
Stochastic optimization
The true probability measure P* is a member of a family P. P* is unknown, but a sample
1, . . . , N is available
A parametric function P  (P), P 2 P is
given. The statistician wants to estimate
* ¼ (P*), where P* is the true probabil-
ity measure
The cost function F and a functional F,
both representing some economic decision
problem are given
The statistician chooses a criterion func-
tion F and a functional F in such a way
that (P) ¼ arg min x 2 X F[F(x, )], where 
is distributed according to P
The estimate is in both cases
^N 2 arg min
x
f ^fN ¼ F½Fðx, Þg,
where  is distributed according to the empirical measure ^PN based on the sample 1, . . . , N
432
G.C. Pflug

where  ¼ (sc)/(sr). Moreover, the arg min is unique. Thus, the newsboy
problem of stochastic optimization turns out to be equivalent to the quantile
estimation problem in statistics. All results about properties of the sample
quantile estimate carry over to the newsboy stochastic optimization problem.
Generally spoken, the same type of results about convergence, asymptotics
and conﬁdence regions hold for the estimation of statistical parameters of the
arg min type and for the solution of empirical stochastic programs. Notice,
however, that the interpretation is slightly diﬀerent: in statistics the emphasis
is on the identiﬁcation of a parameter or the distribution itself. In stochastic
optimization the goal is to make optimal decisions, the unknown probability
measure is not in the center of interest. In statistical estimation, the loss
function plays the role of the cost function. It is typically up to the statistician
to choose an appropriate loss function. In contrast, the cost function is given
in a stochastic optimization problem.
The estimate of the objective function (the criterion function) lies in some
metric space of functions, for instance the space of continuous functions
endowed with the sup-norm, the space of lower semicontinuous functions
endowed with epigraphical distance (see Section 7) or the space of cad-lag
functions endowed with the Skorohod-distance. The arg mins need not be
singletons in general, they may be sets, and the arg min estimates lie in some
metric space of sets (e.g., the metric space of closed sets endowed with the
Hausdorﬀdistance or some variant of it).
We denote by ^N an estimate of an unknown value *, based on a sample
1,. . . , N. Assume that ^N and * lie in a metric space (, d ). This notation is
valid for the estimation of criterion functions (in which case  is a space of
functions) or arg min sets (in which case  is a space of sets) or singleton
arg mins (in which case  is the Rd).
There are some fundamental concepts of describing the quality of statistical
estimates: an estimate ^N is good if it is close to the true value *, i.e., if the
random variable dð ^N, *Þ is small. Since there are several ways of expressing
the fact that a random variable is ‘‘small’’, there are several quality notions for
estimates. We describe some of them in the next section.
3
Properties of statistical estimates
Let ^N ¼ ^Nð1, . . . , NÞ be a sequence of estimates for an unknown true
value * based on the sample 1,. . . , N. Assume that the estimates and the true
value lie in a metric space (, d ).

Consistency.
A sequence ( ^N) of estimates is weakly consistent, if
dð ^N, *Þ ! 0
ð3:8Þ
Ch. 7. Stochastic Optimization and Statistical Inference
433

in probability, i.e., for every ">0
Pfdð ^N, *Þ > "g ! 0
as N ! 1:
The sequence ( ^N) is strongly consistent, if
dð ^N, *Þ ! 0
almost surely, as N ! 1,
ð3:9Þ
i.e.,
Pfdð ^N, *Þ ! 0g ¼ 1:
Strong consistency implies weak consistency. Consistency is a minimal
requirement to qualify the estimate as an acceptable approximation of
the unknown true value.

Speed of convergence.
Let (N ) be an appropriate blow-up function, i.e., a function which
satisﬁes (N ) ! 1 as N ! 1.
The sequence ( ^N) is weakly (N)-consistent, if ðNÞ dð ^N, *Þ stays
bounded in probability as N tends to inﬁnity, i.e., for every ">0, there is
a K" such that
PfðNÞ dð ^N, *Þ > K"g  "
ð3:10Þ
for suﬃciently large N (by possibly enlarging K", the condition (3.10)
may be assumed to hold for all N).
The sequence ( ^N) is strongly (N)-consistent, if ðNÞ dð ^N, *Þ is
almost surely bounded, i.e.,
P sup
N
ðNÞ dð ^N, *Þ < 1


¼ 1:
ð3:11Þ

Asymptotic distribution.
If the parameter space is a linear normed space (, k  k), then one may
consider the diﬀerence between estimate and true value rescaled with
some blow-up function (N) ! 1, i.e.,
ðNÞ½ ^N  *:
ð3:12Þ
The sequence of estimates ( ^N) has an asymptotic distribution, if the
expression in (3.12) converges in distribution to a nondegenerate limit.
In regular cases the appropriate blow-up function is (N) ¼ N1/2 (see
Section 9).
434
G.C. Pflug

The knowledge of the asymptotic distribution gives a precise statement
about the situation for large sample sizes, but may give only little
information about the quality of the estimate for a realistic sample size
N: suppose one knows that ðNÞ½ ^N  * converges in distribution to
some nondegenerated random variable V. Then for every K, which is a
continuity point of kVk
PfðNÞk ^N  *k  Kg ! PfkVk  Kg
ð3:13Þ
as N tends to inﬁnity. A conﬁdence set ^*
N may be constructed as
^*
N ¼ f: dð ^N, Þ  K=ðNÞg,
where dð1, 2Þ ¼ k1  2k and K is chosen such that the right hand side
in (3.13) is not larger than "0. Then ^*
N is an asymptotic conﬁdence set,
i.e., it satisﬁes
lim sup
N
Pf* 62 ^*
Ng  "0:

Universal bounds.
For getting good small sample conﬁdence bounds, it is not necessary
that the sequence ðNÞ½ ^N  * possesses an asymptotic distribution. It is
only necessary that ðNÞdð ^N, *Þ is bounded in probability. We say that
ðNÞdð ^N, *Þ is bounded in probability with explicit tail behavior, if we
can ﬁnd an explicit function K  "(K ), with the property that "(K ) ! 0
for K ! 1 such that for all K
sup
N
PfðNÞdð ^N, *Þ  Kg  "ðKÞ:
Explicit tail functions allow the construction of universal conﬁdence
sets. Let
^*
N ¼ f: dð ^N, Þ  K=ðNÞg:
This is a universal conﬁdence set: choosing ﬁrst the desired level 1"0
and then K such that "(K )  "0 one gets that
sup
N
Pf* 62 ^*
Ng  "ðKÞ  "0:
ð3:15Þ
Ch. 7. Stochastic Optimization and Statistical Inference
435

Based on the size of ^*
N the decision maker may decide to stop or to
increase the sample size by continuing sampling and data collection.
It is one purpose of this chapter to discuss universal bounds for empirical
stochastic programs. The basic notion is rigorously introduced in the
following deﬁnition.
Deﬁnition 2. Let "(K ) be a nonnegative function on (0, 1) with the property
that "(K) ! 0 as K ! 1.
(i) A sequence of random variables (ZN) is bounded in probability with tail
function "(K), if for all K>0
sup
N
PfjZNj  Kg  "ðKÞ:
(ii) The sequence of random variables (ZN) is bounded in probability with
normal tails, if it fulﬁlls (i) and the function "(K) satisﬁes
"ðKÞ  C1 expðC2K2Þ
ð3:16Þ
for all K>0 and some constants C1>0, C2>0.
The name in (ii) comes from the following property of the standard normal
distribution function : the two sided tail probability "ðKÞ ¼ ðKÞþ
1  ðKÞ satisﬁes (3.16) with C1 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃ
2=
p
and C2 ¼ 1/2 (Mill’s ratio).
Recall that the main goal is to judge the quality of approximation of a
stochastic optimization problem by the pertaining empirical problem and to
ﬁnd good error bounds. To this end, we discuss three diﬀerent, but related
questions: (Q1) the quality of the approximation of the objective function as a
whole, (Q2) the quality of the approximation of the optimal value and (Q3)
the quality of the approximation of the solution (or the solution set if the
solution is not unique).
3.1
The three basic questions about the approximation quality of a
stochastic program
Consider a stochastic optimization problem of type (2.6)
Min
x2X f f ðxÞ ¼ F½Gxg
ð3:17Þ
and its empirical counterpart (see (2.7))
Min
x2X f ^fNðxÞ ¼ F½ ^Gx,Ng:
ð3:18Þ
436
G.C. Pflug

The basic questions about the approximation quality of the true problem
by the empirical problem are:
(Q1) Approximation of the objective function:
Under which conditions is
ðNÞ sup
x2X
j ^fNðxÞ  f ðxÞj
ð3:19Þ
bounded in probability for some blow-up function (N)? Does one get
the explicit tail behavior? Does the normal tail behavior hold?
(Q2) Quality of the solution:
Under which conditions is
ðNÞ sup f ð yÞ: y 2 arg min
x2X
^fNðxÞ


 min
x2X f ðxÞ


ð3:20Þ
bounded in probability for some blow-up function (N)? Does one get
the explicit tail behavior? Does the normal tail behavior hold?
(Q3) Approximation of the arg min:
Suppose for the moment that all arg mins are singletons. Then the
question is: under which conditions is
ðNÞkarg min
x2X
^fNðxÞ  arg min
x2X
f ðxÞk
ð3:21Þ
bounded in probability for some blow-up function (N)? Does one get
the explicit tail behavior? Does the normal tail behavior hold?
The assumption that all arg mins are singletons is restrictive. Often arg mins
are (closed) sets. We introduce therefore the Hausdorﬀdistance between sets:
the distance between a point x 2 Rd and a set B  Rd is deﬁned as
dðx, BÞ ¼ inffkx  yk: y 2 Bg:
The one-sided Hausdorﬀdistance between sets A and B is
dðA k BÞ ¼ supfdðx, BÞ: x 2 Ag:
ð3:22Þ
We set d(B k ;) ¼ 1 and d(;, B) ¼ 0 for the empty set ;. dðAkBÞ is asymmetric
as is illustrated in Fig. 1. The Hausdorﬀdistance between A and B is
dðA, BÞ ¼ maxfdðA k BÞ, dðB k AÞg:
ð3:23Þ
Ch. 7. Stochastic Optimization and Statistical Inference
437

For closed sets A and B, d(A k B) ¼ 0 if and only if A  B and d(A, B) ¼ 0 if
and only if A ¼ B.
In the set-valued notation, the question (Q3) has to be formulated as (Q3a)
or (Q3b).
(Q3a) Asymptotic dominance of the arg min set
Under which conditions is
ðNÞ d arg min
x2X
^fNðxÞ k arg min
x2X
f ðxÞ


ð3:24Þ
bounded in probability for some blow-up function (N). Does one get
the explicit tail behavior? Does the normal tail behavior hold?
Introducing the "-fattening of a set B as
½B" ¼ fx: dðx, BÞ  "g,
the property (3.24) can be reformulated as follows: the relation
arg min
x2X
^fNðxÞ 
arg min
x2X
f ðxÞ

K=ðNÞ
holds with arbitrarily high probability, if K and N are large enough.
(Q3b) Asymptotic convergence of the arg min set
Under which conditions is
ðNÞ d arg min
x2X
^fNðxÞ, arg min
x2X
f ðxÞ


ð3:25Þ
bounded in probability for some blow-up function (N). Does one get
the explicit tail behavior? Does the normal tail behavior hold?
Fig. 1. An example, where d(A jj B) ¼ " but d(B jj A) is large.
438
G.C. Pflug

The property (3.25) can be reformulated that both relations
arg min
x2X
f ðxÞ 
arg min
x2X
^fNðxÞ

K=ðNÞ
arg min
x2X
^fNðxÞ 
arg min
x2X
f ðxÞ

K=ðNÞ
hold with arbitrarily high probability, if K and N are large enough.
If there is a positive answer to (Q3a) or (Q3b), then a conﬁdence region
for the arg min may be constructed in a canonical way. Let the conﬁdence
region ^CN be
^CN ¼
x: d x, arg min
x2X
^fNðxÞ


 K=ðNÞ


where K has to be chosen in such a way that "(K)  "0, with 1"0 being the
desired level of conﬁdence. If (3.24) has been established with tail function
"(K), then ^CN is a weak universal conﬁdence set, i.e.,
sup
N
P
^CN \ arg min
x2X
f ðxÞ ¼ ;


 "0:
ð3:26Þ
If even (3.25) holds, then ^CN is a strong universal conﬁdence set, i.e.,
sup
N
P arg min
x2X
f ðxÞ 6 ^CN


 "0:
The term universal refers to the fact that the inequality is valid for all N, in
contrast to an asymptotic conﬁdence set, which is valid only for large N.
Notice that (3.26) can be established, if (3.24) holds and arg minx2X f ðxÞ is a
singleton. Unfortunately, no other method for proving (3.26) is known at the
time being.
3.2
Relations between the different types of approximation errors
The basic question (Q1) is the fundamental one. Questions (Q2) and (Q3)
are related to (Q1) as is shown in this section.
Proposition 3. If the answer to (Q1) is positive, then the answer to (Q2) is also
positive. More precisely, if
ðNÞ sup
x2X
j ^fNðxÞ  f ðxÞj
Ch. 7. Stochastic Optimization and Statistical Inference
439

is bounded in probability with tail function "(K), and arg minx2X ^fNðxÞ is
nonempty, then
ðNÞ sup f ð yÞ: y 2 arg min
x2X
^fNðxÞ


 min
x2X f ðxÞ


is also bounded in probability with tail function "(K/2).
Proof. The proposition is established, if we show that for two functions f, g
sup f ð yÞ: y 2 arg min
x2X
gðxÞ


 min
x2X f ðxÞ  2 sup
u2X
j gðuÞ  f ðuÞj
ð3:27Þ
and apply the result for gðxÞ ¼ ^fNðxÞ. Suppose ﬁrst that the minima of f
and g are attained. Let y 2 arg minu2X gðuÞ and x 2 arg minu2X f ðuÞ. Then
f ð yÞf ðxÞgð yÞgðxÞþjg ð yÞ  f ð yÞj þ jgðxÞ  f ðxÞj  2 supu2X jgðuÞ f ðuÞj,
since g( y)g(x)  0. If the minima of f and g are not attained, they may be
approximated with an error at most ". The same argument as before together
with the fact that " is arbitrary leads to (3.27).
u
The relation between (Q3) and (Q1) depends on the validity of some growth
condition.
Deﬁnition 4. Growth functions. The function f possesses the growth function
(d) on X, if  is a strictly increasing function on (0, 1) satisfying (d) ! 0 as
d ! 0 and
f ðxÞ  inf
y2X f ð yÞ þ  d x, arg min
z2X
f ðzÞ




:
ð3:28Þ
Notice that this deﬁnition requires that arg minz2X f ðzÞ is nonempty.
Proposition 5. Suppose that f is a lower semicontinuous function (see Section 7
for the deﬁnition) having growth function  where limd!0 ððdÞÞ=d ¼ C: If the
answer to (Q1) is positive, then also the answer to (Q3) is positive in the
following sense:
(i) If ðNÞ supx2X j ^fNðxÞ  f ðxÞj is bounded in probability with tail function
"(K), then
½ðNÞ1= d arg min
x2X
^fNðxÞ k arg min
x2X
f ðxÞ


is bounded in probability with tail function "(CK/2).
440
G.C. Pflug

(ii) Let ðd Þ ¼ ðd Þ=d and suppose that ðd Þ is strictly increasing and
satisﬁes ðdÞ ! 0 as d ! 0. If the diﬀerence quotients have the property
that
ðNÞ
sup
x,y2X,x6¼y
j ^fNðxÞ  ^fNð yÞ  f ðxÞ þ f ð yÞj
kx  yk
is bounded in probability with tail function "(K), then
½ðNÞ1=ð1Þd arg min
x2X
^fNðxÞ k arg min
x2X
f ðxÞ


is bounded in probability with tail function "ðCK1Þ.
Proof. The proof rests on the following inequalities:
(i) If supx j f ðxÞ  gðxÞj  " then for each minimizer x þ of g
dðxþ, arg min f Þ  1ð2"Þ:
ð3:29Þ
(ii) If for all x 6¼ y we have that j f ðxÞ  gðxÞ  f ð yÞ þ gð yÞj  "kx  yk,
then for each minimizer x þ of g
dðxþ, arg min f Þ  
1ð"Þ:
ð3:30Þ
where ðdÞ ¼ ðdÞ=d: We show (3.29) ﬁrst. Let x* 2 arg min f such that
kx þx*k ¼ d(x þ, arg min f ). Such a point x þ exists because argmin f is
closed by the lower semicontinuity property. Since  is a growth function,
0  gðxþÞ  gðx*Þ  f ðxþÞ  f ðx*Þ  j f ðx*Þ  gðx*Þj  j f ðxþÞ  gðxþÞj
 ðkx*  xþkÞ  2"
whence (3.29) follows. To show (ii), we use the following inequality
0  gðxþÞ  gðx*Þ  f ðxþÞ  f ðx*Þ  j f ðx*Þ  gðx*Þ  f ðxþÞ þ gðxþÞj
 ðkx*  xþkÞ  "kx*  xþk
Ch. 7. Stochastic Optimization and Statistical Inference
441

whence ðkx*  xþkÞ=kx*  xþk ¼ ðkx*  xþkÞ  " and we have estab-
lished (3.29). The proposition follows from setting gðxÞ ¼ ^fNðxÞ and "=(k)/
((N)).
u
Example 2. The Newsboy problem (continued). Recall again this problem from
the chapter Stochastic Programming Models of this volume. It was already
shown earlier that the objective function has the representation
f ðxÞ ¼ E½Fðx, Þ ¼ ðs  cÞx þ ðr  sÞGð1ÞðxÞ,
where Gð1ÞðuÞ ¼
R u
1 ðu  vÞ dGðvÞ ¼
R u
1 GðvÞ dv. Suppose that G has contin-
uous density g and that it is known that in a symmetric neighborhood of
diameter 2h this density is not smaller than a constant g0>0. Then the
following function  is a growth function for f:
ðdÞ ¼
ðr  sÞ 1
2 g0d2
d  h
ðr  sÞðg0dh  1
2 g0h2Þ
d > h
(
Thus f is locally quadratic in a neighborhood of x*, but grows globally only at
a linear rate. The curvature at the minimum is f 00ðx*Þ ¼ ðr  sÞgðx*Þ > 0. The
function f(x) is depicted in Fig. 1. In addition, this ﬁgure shows three
empirical estimates ^fNðxÞ, each based on a sample size of N ¼ 10. Observe that
the approximating function may be quite far from the true function, but the
arg mins may be rather close (Fig. 2).
Fig. 2. Solid line: The negative objective function of the newsboy problem (r ¼ 9, c ¼ 10,
s ¼ 15,  N(100, 8)). This function is locally quadratic, but globally only of linear growth.
Dotted lines: Three empirical approximations of the objective function.
442
G.C. Pflug

The growth function depends on the feasible set. If one knows that the
approximating solution is already in a small neighborhood of the true
solution, then usually a better growth function can be established and hence a
smaller conﬁdence interval can be found. For practical purposes, a two stage
procedure may be used: in a ﬁrst stage, the validity of some conﬁdence region
may be shown using a global growth function. In a second stage this
conﬁdence region may be improved using a local growth function.
3.3
The uniform boundedness property
We have seen so far that the crucial question is (Q1), i.e., to bound
the approximation error of the objective function. How can this be done? The
approach we will use here is to impose Lipschitz continuity properties on the
risk functional F and to use uniform bounds for the Law of Large Numbers.
The ﬁrst step is to introduce some sup-metrics dH. Let H be a set of
measurable functions on R and let GH the class of those distributions G, for
which all functions from H have ﬁnite integrals:
GH ¼
G:
Z
hðuÞ dGðuÞ is well defined and finite for all h 2 H


:
On GH one may deﬁne a semidistance through
dHðG1, G2Þ ¼ sup

Z
hðuÞ dG1ðuÞ 
Z
hðuÞ dG2ðuÞ
: h 2 H


:
Recall the deﬁnition of the Lipschitz property: F is Lipschitz continuous w.r.t.
dH if there is a constant L (called the Lipschitz constant) such that
FðG1Þ  FðG2Þ
  L  dHðG1, G2Þ:
ð3:31Þ
Example. If F ¼ E, i.e., if the risk functional is the expectation, then (3.31)
holds with L ¼ 1, if H contains the identity function h(x) ¼ x. Other, less trivial
examples are discussed in Section 4.
The relation between distances of probability measures and the pertaining
stochastic programs is extensively studied in chapter Stability of Stochastic
Programming Problems by Ro¨ misch in this volume. Here we are interested in
uniform approximations of the true program by the empirical program. The
uniform approximation may be expressed in terms of a uniform boundedness
principle of appropriate families F of integrable functions.
Ch. 7. Stochastic Optimization and Statistical Inference
443

Deﬁnition 6. A family F of integrable functions deﬁned on a probability space
(, A, P) has the uniform boundedness property with blow-up function (N ) and
explicit tail function "(K), if for i.i.d. random variables (n) with distribution P,
ðNÞ sup
F2F
 1
N
X
N
n¼1
FðnÞ  E½FðÞ

is bounded in probability with tail function "(K ), i.e.,
sup
N
P ðNÞ sup
F2F
 1
N
X
N
n¼1
FðnÞ  E½FðÞ
  K
(
)
 "ðKÞ
(compare with Deﬁnition 2 (i)). If the tail function "(K) satisﬁes (3.16), then
the tails are called normal.
The uniform boundedness property of classes of function is the key for
proving uniform bounds for the error in the objective function, i.e., the
diﬀerence between f(x) ¼ F(Gx) and ^fNðxÞ ¼ Fð ^Gx,NÞ, compare (2.6) and (2.7).
The following theorem is obvious, but crucial.
Theorem 7. Suppose that F is Lipschitz continuous w.r.t. dH, i.e., that (3.31) is
fulﬁlled.
(i) If the family F H ¼ fh 	 Fðx, Þ: x 2 X, h 2 Hg satisﬁes the uniform boun-
dedness property with blow-up function (N) and explicit tail function
"(K), then
ðNÞ sup
x2X
j ^fNðxÞ  f ðxÞj
is bounded in probability (see Deﬁnition 2) with tail function "(K/L). Thus,
under the assumptions of Proposition 5,
½ðNÞ1= d arg min
x2X
^fNðxÞ k arg min
x2X
f ðxÞ


is bounded in probability with tail function "(C(K/L)/2).
(ii) If the family F r
H ¼ fðh 	 Fðx, Þ  h 	 Fðy, ÞÞ=ðkx  ykÞ: x,y 2 X; x 6¼ yg
satisﬁes the uniform boundedness property with blow-up function (N)
and explicit tail function "(K), then
ðNÞ
sup
x,y2X,x6¼y
j ^fNðxÞ  ^fNð yÞ  f ðxÞ þ f ð yÞj
kx  yk
444
G.C. Pflug

is bounded in probability with tail function "(K/L). Thus, under the
assumptions of Proposition 5,
½ðNÞ1=ð1Þ d arg min
x2X
^fNðxÞ k arg min
x2X
f ðxÞ


is bounded in probability with tail function "ðCðK=LÞ1Þ.
To summarize the results of this section, we have seen that bounds for the
uniform approximation of the objective function gives automatically bounds
for the quality of the solution. Bounding the approximation error of the
arg min is a more diﬃcult problem, since it depends on the curvature of the
objective f (the growth condition). If the objective is ﬂat near its arg min, a
small error in function value may cause a large error in the arg min. Also,
bounds for the diﬀerences of the objective give much better bounds for the
solutions than bounds for function values only.
If the risk functional F is the expectation, uniformity in the class
F ¼ fFðx, Þ: x 2 Xg or F r ¼ fðFðx, Þ  Fð y, ÞÞ=ðkx  ykÞ: x, y 2 X; x 6¼ yg
is required. If the risk functional is not the expectation, but at least Lipschitz
continuous
w.r.t.
dH,
then
uniform
versions
of
the
Law
of
Large
Numbers are needed for larger classes F H ¼ fh 	 Fðx, Þ: x 2 X, h 2 Hg or
F r
H ¼ fðh 	 Fðx, Þ  h 	 Fð y, ÞÞ=ðkx  ykÞ: x, y 2 X; x 6¼ yg.
In most applications, the quality of the solution matters much more than
the arg min error. But even if one is interested in the arg min error, the error in
the objective function has to be bounded ﬁrst: all methods of dealing with the
arg min error are based on bounds for the error in the objective function. Two
steps are necessary for this goal: ﬁrst to establish the Lipschitz continuity for
the risk functional (this step can be omitted if the risk functional is the
expectation) and then to prove uniformity for the appropriate function class
F. The ﬁrst step will be considered in the next Section 4, the second step is
done in the subsequent Section 5.
4
Risk functionals and Lipschitz properties
The expectation is not the only functional which appears in stochastic
optimization problems. Especially in recent years it has been well understood
that risk management is done by controlling various risk parameters like
variance, quantiles etc., of the cost, wealth or income distribution.
To minimize the expected costs makes sense for situations which contain
many repetitions of the same problem. Examples are the optimal design of
service systems, manufacturing systems and inventory systems. If, however,
the decision is only to be made once, then it is questionable whether the
expectation is the appropriate risk functional for the problem. In portfolio
optimization for instance, the use of variance risk adjusted expectation
Ch. 7. Stochastic Optimization and Statistical Inference
445

FðGxÞ ¼ EðGxÞ    VarðGxÞ as objective has become a standard (the so called
Markowitz model).
Recall that any probability functional can be seen as a statistical parameter.
The basic question, whether and how fast the empirical version of this
parameter converges to the true one, depends on the continuity properties of
this parameter with respect to appropriate distances.
Based on a set of integrable functions H, we have already deﬁned the
semidistance dH for distributions G1, G2 as
dHðG1, G2Þ ¼ sup

Z
hðuÞ dG1ðuÞ 
Z
hðuÞ dG2ðuÞ
: h 2 H


:
If H is separating on GH, i.e., if
R
hðuÞ dG1ðuÞ ¼
R
hðuÞ dG2ðuÞ for all h 2 H
implies that G1 ¼ G2, then dH is a distance. The larger the class H, the ﬁner is
the topology generated by dH.
Notice also that enlarging the set H to its convex hull conv(H) does not
change the semidistance dH.
4.1
A list of distances for probability measures

If H is chosen as the class of indicator functions of half-open intervals
in R1
KS ¼ f1ð1,aðuÞ: a 2 Rg,
the Kolmogorov–Smirnov distance dKS is obtained.

If H is chosen as the class of Lipschitz-continuous functions with
Lipschitz-constant 1
Lip ¼ fh: jhðuÞ  hðvÞj  ju  vjg,
the Wasserstein distance dLip(G1, G2) is obtained.

Deﬁne the Lipschitz-constant of order p of h as
Lpð f Þ ¼ inffL: jhðuÞ  hðvÞj  Lju  vj maxð1, jujp1, jvjp1Þg:
Choosing H as the class of all functions with Lp  1, we get the Fortet–
Mourier distance.

If H is chosen as the class of the indicator functions 1A of all measurable
sets (or equivalently the class Mþ
b ð1Þ of all nonnegative measurable
functions bounded by 1), the variational distance is obtained
dMþ
b ð1ÞðG1, G2Þ ¼ sup
A
Z
1AðuÞ d½G1  G2ðuÞ:
446
G.C. Pflug


Consider the class of power functions given by
Hk ¼ fsignðuÞjujk1fuag : a 2 Rg
ð4:1Þ
for integer k. The corresponding distance will be brieﬂy denoted by
dkðG1, G2Þ
instead of
dHkðG1, G2Þ:
ð4:2Þ
By deﬁnition, if X1 G1 and X2 G2, then
dkðG1, G2Þ ¼ supfjEðXk
11fX1agÞ  EðXk
2 1fX2agÞj: a 2 Rg:
In particular, jEðXk
1 Þ  EðXk
2 Þj  dkðG1, G2Þ. The distance d0 coincides with the
Kolmogorov–SmirnovmetricdKS,sincesupu jG1ðuÞG2ðuÞj¼supu jð1G1ðuÞÞ
ð1  G2ðuÞÞj. We also introduce
dk ¼ maxfdl : l ¼ 0, . . . , kg:
ð4:3Þ
4.2
A list of frequently used risk functionals
Recall that risk functionals are real valued mappings G!
F R deﬁned on the
family of G of all probability measures on R or some subfamily.

Location equivariant measures (location parameters).
They have the property that
F½Gð  aÞ ¼ F½GðÞ þ a
for all a. Examples are the expectation
EðGÞ ¼
Z
u dGðuÞ,
the value-at-risk (at level )
V@RðGÞ ¼ G1ð1  Þ,
the conditional value-at-risk (at level )
CV@RðGÞ ¼ 1

Z 1
1
G1ðvÞ dv ¼ 1

Z
ðG1ð1Þ,1Þ
u dGðuÞ:
Ch. 7. Stochastic Optimization and Statistical Inference
447

Alternatively, CV@R may be deﬁned as
CV@RðGÞ ¼ inf a þ
1
1  
Z
½u  aþ dGðuÞ: a 2 R


(see Rockafellar and Uryasev, 1999).

Location invariant measures (pure risk measures).
They have the property that
F½Gð  aÞ ¼ F½GðÞ
for all a. Examples arethe mean absolute deviation
MadðGÞ ¼
Z
ju  EðGÞj dGðuÞ,
the upper semi-deviation
MadþðGÞ ¼
Z
½u  EðGÞþ dGðuÞ,
the variance
VarðGÞ ¼
Z
½u  EðGÞ2 dGðuÞ,
the upper semi-variance
VarþðGÞ ¼
Z
ð½u  EðGÞþÞ2 dGðuÞ:

Other risk measures.
The expected utility
Z
UðvÞ dGðvÞ,
where U is a nonnegative, monotone utility function, the excess
probability (over threshold t)
1  GðtÞ:
448
G.C. Pflug

4.3
Continuity properties of risk functionals
Suppose that we may prove that the functional F is continuous w.r.t dH.
Then the convergence of ^Gx,N to Gx in metric dH implies the convergence
of Fð ^Gx,NÞ to F(Gx). If F is Lipschitz, then every estimate for dHð ^Gx,N, GxÞ
implies in a simple manner an estimate for jFð ^Gx,NÞ  FðGxÞj. Uniformity of
the convergence in x carries over.
The following Proposition 8, which is stated without proof uses the
distances dk and dk introduced in (4.2) and (4.3).
Proposition 8. Continuity of probability functionals. Let X1 G1 and X2 G2.
Then
(i) jG1(t)G2(t)j  d0(G1, G2)
(ii) jE(G1)E(G2)j  d1(G1, G2)
(iii) jMadðG1Þ  MadðG2Þj  d1ðG1, G2Þ þ 2d1ðG1, G2Þ
(iv) jVarðG1Þ  VarðG2Þj  d2ðG1, G2Þ þ d1ðG1, G2ÞðEX1 þ d1ðG1, G2Þ
(v) jVarþðG1ÞVarþðG2Þjd2ðG1,G2Þð2EX1þ1Þþd1ðG1,G2Þ½3þEjX1EX1j
(vi) Suppose that G1(q) ¼  and that G1ðuÞ  G1ðqÞ  cðu  qÞ for juqj  ".
Then, if d0(G1, G2)  ",
jV@RðG1Þ  V@RðG2Þj  1
c d0ðG1, G2Þ:
(vii) jCV@RðG1ÞCV@RðG2Þjd0ðG1, G2ÞþjV@RðG1ÞV@RðG2Þj
5
Arithmetic means of of i.i.d. random variables
This section reviews some results from probability theory, which are
relevant for deriving statistical properties of the estimates in stochastic
optimization.
5.1
Basic properties
Let (Xn) be a sequence of i.i.d. random variables. We are interested in the
behavior of their arithmetic mean
XN ¼ 1
N
X
N
n¼1
Xn
as N tends to inﬁnity. There are four basic theorems, which describe the
pointwise and distributional properties of XN: the Strong Law of Large
Numbers (SLLN), the Central Limit Theorem (CLT), the Law of Iterated
Logarithm (LIL) and the Large Deviations Theorem (LDT).
Ch. 7. Stochastic Optimization and Statistical Inference
449

Theorem 9. (Strong Law of Large Numbers-SLLN) Let (Xn) be a sequence of
i.i.d. random variables. If X1 is integrable, then
XN ¼ 1
N
X
N
n¼1
Xn ! EX1
almost surely:
Proof. See Etemadi (1981).
u
Theorem 10. (Central Limit Theorem-CLT). Assume that X1 has ﬁnite variance
2 ¼ Var(X1). Then, for all u,
P
1

ﬃﬃﬃﬃ
N
p
X
N
n¼1
½Xn  EX1  u
(
)
! ðuÞ ¼
1ﬃﬃﬃﬃﬃﬃ
2
p
Z u
1
ev2=2 dv:
Proof. See Shiryaev (1996, pp. 328–341) for this and more on the CLT.
u
Theorem 11. (Law of iterated logarithm-LIL). Under the assumptions of the
previous theorem the following limit relations hold almost surely
lim sup
N!1
1
 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N log log N
p
X
N
n¼1
½Xn  EX1 ¼ 1
lim inf
N!1
1
 2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
N log log N
p
X
N
n¼1
½Xn  EX1 ¼ 1:
Proof. See Shiryaev (1996), Theorem 1, p. 397.
u
The LDT will be presented in the next section.
5.2
Universal probability bounds
Assume as before that (Xn) is an i.i.d sequence. Let all Xn have the same
distribution as X. If X has exponential moments of order s 6¼ 0 (i.e., E(esX)
exists for some s 6¼ 0), then interesting inequalities and tight bounds may be
derived. The ﬁrst basic step is Chernoﬀ’s inequality for s>0:
PfX  tg ¼ PfesX  estg  estEðesXÞ:
Applied to the arithmetic mean of the centered variables
1
N
PN
n¼1 Xn
EX ¼ XN  EX, the Chernoﬀbound reads
PfXN  EX  tg  estN½EðesðXEXÞÞN:
ð5:1Þ
450
G.C. Pflug

This bound is one-sided, but putting together this inequality and the corres-
ponding inequality for X one gets easily the two-sided version, since for
t  0,
PfjXN  EXj  tg  PfXN  EX  tg þ PfXN þ EX  tg:
ð5:2Þ
If the random variables Xn are bounded in [a, b], then the Hoeﬀding bound
PfXN  EX  tg  e2t2N=ðbaÞ2
ð5:3Þ
can be obtained (see Devroye and Lugosi, 2001). Consequently, if the Xn are
bounded and take values in [C, C ], we get normal tail behavior for the
arithmetic mean blown up with
ﬃﬃﬃﬃ
N
p
in the sense of Deﬁnition 2
P jXN  EXj  K=
ﬃﬃﬃﬃ
N
p
n
o
 2eK2=2C2
ð5:4Þ
by setting t ¼ K=
ﬃﬃﬃﬃ
N
p
.
If the random variables Xn are unbounded, Hoeﬀding’s bound is not
applicable, but a similar bound may be derived using the logarithmic moment
generating function of XEX:
MXðsÞ ¼ log EðesðXEXÞÞ:
We assume that MX(s) is ﬁnite for s in a neighborhood [", "] of 0. Outside
this neighborhood MX may be equal 1. The region of ﬁniteness of MX is
determined by the tail behavior of X: if X is bounded, then MX is ﬁnite on the
whole R. The lighter are the tails, the larger is the interval of ﬁniteness of MX.
MX is a convex, extended real function which satisﬁes
MXð0Þ ¼ 0,
M0
Xð0Þ ¼ 0,
M00
Xð0Þ ¼ VarðXÞ:
Let M*
X be the conjugate (dual) function of MX
M*
XðuÞ ¼ supfsu  MXðsÞ: s 2 Rg
ð5:5Þ
which is also convex. Taking the inﬁmum over all s in (5.1) we get
PfXN  EX  tÞ  inf
s estN½EðesðXEXÞÞN
¼ inf
s expðN½MXðsÞ  stÞ ¼ expðNM*
XðtÞÞ:
ð5:6Þ
Ch. 7. Stochastic Optimization and Statistical Inference
451

Notice that the inequality (5.6) holds for all t and all N. The following lemma
links the growth of the conjugate logarithmic moment generating function to
the tail behavior of the arithmetic mean.
Lemma 12.
(i) If the logarithmic moment generating function MX satisﬁes
MXðtÞ  t2,
ð5:7Þ
for all t and for some constant , then the arithmetic mean has normal tail
behavior:
P XN  EX  K=
ﬃﬃﬃﬃ
N
p
n
o
 eK2=4:
ð5:8Þ
(ii) If MX(s)  s2 for jsj  ", then
P XN  X  K=
ﬃﬃﬃﬃ
N
p
n
o

eK2=4
if N 
K2
42"2
e ﬃﬃﬃ
N
p
K"=2
otherwise
(
ð5:9Þ
i.e., the arithmetic mean has normal tails for suﬃciently large N.
Proof. (i) If MX(s)  s2, then M*
XðtÞ  t2=4. (5.8) follows from setting t ¼
K=
ﬃﬃﬃﬃ
N
p
in
(5.6).
In
case
(ii)
M*
XðtÞ  t2
4 1fjtj2"g þ ðjtj"  "2Þ1fjtj>2"g 
t2
4 1fjtj2"g þ ðjtj"=2Þ1fjtj>2"g and this must be used in (5.6).
u
A slight generalization of the just proven result is Cramer’s theorem (see
Deuschel and Strook, 1989).
Theorem 13. (Large deviations theorem-LDT). For every closed set A
lim sup
N
1
N log PfXN 2 Ag  inffM*
XðtÞ: t 2 Ag
Remark. A lower bound is also valid (see also Deuschel and Strook, 1989): for
every open set B
lim inf
N
1
N log PfXN 2 Bg  inffM*
XðtÞ: t 2 Bg:
452
G.C. Pflug

5.3
Uniformity
Let F be a class of measurable functions on (, A, P) and let (n) be a
sequence of i.i.d. random variables with values in . If the F contains only one
function F, then setting Xn ¼ F(n), we know that this sequence fulﬁlls under
the appropriate conditions SLLN, CLT, LIL, LDT.
For the applications we have in mind, uniform versions of these theorems
are needed. Let F be a class of functions deﬁned on Rm and (n) a sequence of
i.i.d. random variables with values in Rm.
We want to know under which conditions for F a uniform Law of Large
Numbers with explicit tail behavior as introduced in Deﬁnition 6 holds, i.e.,
sup
F2F
ðNÞ
 1
N
X
N
n¼1
FðnÞ  EFð1Þ

ð5:10Þ
is uniformly bounded in probability with explicit tail behavior.
For measurability assumptions, we assume throughout this chapter that F
is a countable family of functions.
If the measurability of the supremum error can be ensured, then the family
F may be uncountable as well. In our application, F will be the family of all
cost functions F ¼ fFðx, Þ: x 2 Xg. If x  F(x, ) is a.s. lower semicontin-
uous (see Section 7), then countably many x 2 X suﬃce to determine the
supremum error. Therefore, all results hold for the uncountable set F in this
case.
We begin with just a uniform Law of Large Numbers without blowing up
function and explicit tail behavior.
Deﬁnition 14. The countable class F of integrable functions is said to fulﬁll a
uniform Strong Law of Large Numbers (SLLN), if
sup
F2F
1
N
X
N
n¼1
½FðnÞ  E½Fð1Þ ! 0
ð5:11Þ
almost surely, as N tends to inﬁnity.
Uniform SLLN Theorems are also known under the name of Glivenko–
Cantelli Theorems. The original Glivenko–Cantelli Theorem was indepen-
dently
formulated
by
Glivenko
and
Cantelli
for
the
function
class
F ¼ f1ð1,uðvÞ: u 2 Rg. Uniformity holds in a trivial manner, if the class
F contains only ﬁnitely many functions. Typically, suﬃcient conditions for
uniformity for inﬁnite F require that this set may be approximated in a certain
sense by ﬁnitely many functions. One distinguishes between shattering type
conditions and covering type conditions.
Ch. 7. Stochastic Optimization and Statistical Inference
453

Theorem 15. Vapnik–Cervonenkis shattering type theorem Let U be a
subfamily of measurable sets. The Vapnik–Cervonenkis (VC ) index V(U ) of U is
deﬁned as
VðUÞ ¼ inf n: max
x1,...,xn #fU \ fx1, . . . , xng: U 2 Ug < 2n


:
Here # denotes the cardinality. If V(U )<1, then
sup
U2U
j ^PNðUÞ  PðUÞj ! 0
a:s:
Proof. See Shorack and Wellner (1986), p. 828.
u
The VC index was formulated for families of sets, but it has also a version
for families of functions: as an easy corollary one gets the following theorem: a
class of functions F satisﬁes a uniform SSLN (5.11), if the collection of all
level sets {x: F(x)<t}, t 2 R, F 2 F has ﬁnite VC index.
The ﬁniteness of the VC index guarantees that the function class satisﬁes
the uniform SLLN, but does not allow ﬁner estimates of the deviation of the
empirical functions from the true functions. A more reﬁned analysis is made
possible by the notion of the metric entropy. Deﬁne ﬁrst the notion of a
bracket [G, H]: for two real, measurable functions G  H, let the bracket be
deﬁned as
½G, H ¼ fF : G  F  H a:s:g:
The bracket is empty, if G  H a.s. does not hold.
Deﬁnition 16. Metric entropy (with bracketing). Deﬁne kFk1 ¼
R
jFð!Þj dPð!Þ.
Let F be a family of integrable functions. The metric entropy of F is deﬁned as
N1ð	Þ ¼ min k: There exist integrable functions G1 H1, . . . , Gk Hk,
	
such that F  [
k
i¼1 ½Gi, Hi and kHi  Gik1 < " for all i
o
Function classes with ﬁnite entropy satisfy a uniform Law of Large
Numbers as the next theorem shows.
Theorem 17. Blum-de Hardt metric entropy type theorem. Suppose that N1(") is
ﬁnite for every ">0. Then the uniform SLLN (5.11) holds.
454
G.C. Pflug

Proof. Choose an arbitrary ">0. It is suﬃcient to show that
lim sup
N
sup
F2F
1
N
X
N
n¼1
FðnÞ  E½FðÞ  "
a.s. Let ðGi, HiÞi¼1,...,N1ð"Þ be chosen as in Deﬁnition 16. Then
sup
F2F
1
N
X
N
n¼1
FðnÞ  E½FðÞ ¼
max
i¼1,...,N1ð"Þ
sup
F2½Gi,Hi
1
N
X
N
n¼1
FðnÞ  E½FðÞ

max
i¼1,...,N1ð"Þ
1
N
X
N
n¼1
HiðnÞ  E½GiðÞ

max
i¼1,...,N1ð"Þ
1
N
X
N
n¼1
HiðnÞ  E½HiðÞ þ "
By the standard Law of Large Numbers, the lim sup of this expression for
N ! 1 is bounded by " and the theorem is shown.
u
A more reﬁned analysis relates the growth of the function N1(") to the tail
behavior of the sequence (5.10). If an assumption about the growth of the
function "  N1(") can be made, then good estimates of the approximation
error are possible. The assumptions about N1(") are called covering type
conditions.
5.4
Covering types and universal bounds
Deﬁnition 18. A set A 
 Rd is said to be of covering type (v, V), if for every
">0 one can ﬁnd at most 8(V"/")v9 balls B1, B2,. . . , BN", each with diameter
", which cover A, i.e., A  [N"
i¼1 Bi and lim" ! 0 V" ¼ V.
Example 5. The unit cube in Rd is of covering type ðd, 2
ﬃﬃﬃ
d
p
Þ.
Deﬁnition 19. Let (, A, P) be a probability space. A family F of L2-functions
is of covering type (v, V), if for every ">0 there are at most N2(") ¼ 8(V/")v9
pairs of functions ðG1, H1Þ, . . . , ðGN2ð"Þ, HN2ð"ÞÞ with the properties
(i) Gi(!)  Hi(!) a.s. for 1  i  N2(");
(ii)
R
ðHið!Þ  Gið!ÞÞ2Pðd!Þ  "2;
(iii) For each F 2 F there is a index i 2 {1,. . . , N2(")} such that
Gið!Þ  Fð!Þ  Hið!Þ:
Ch. 7. Stochastic Optimization and Statistical Inference
455

Property (iii) may be expressed in the following way:
F 
[
N2ð"Þ
i¼1
½Gi, Hi:
The covering type is essential for uniform conﬁdence bands as was
demonstrated by Talagrand (1994).
Theorem 20. Let jF(w)j  1 for all F 2 F. Suppose that F is countable and of
covering type (v, V ). Then
P sup
F2F
 1
N
X
N
n¼1
FðnÞ  EF
  Kﬃﬃﬃﬃ
N
p
(
)

MðVÞ Kﬃﬃﬃv
p

v
expð2K2Þ,
ð5:12Þ
where M(  ) is a universal function. To put it diﬀerently, F satisﬁes the
uniform boundedness property of Deﬁnition 6 with blow-up function
ðNÞ ¼
ﬃﬃﬃﬃ
N
p
and normal tails.
Proof. See Talagrand (1994) or Van der Vaart and Wellner (1996).
u
The theorem holds also for uncountable classes F, provided that the
supremum is measurable.
Remark. Notice that the factor Kv appearing in the tail function does not
aﬀect the normal tail behavior, since
Kv expð2K2Þ  expðv=2Þ v
2

v=2
expðð2  ÞK2Þ
for all 0<<2. Thus the tail behavior is normal for all v>0. If the functions F
are bounded by C, then the right hand side has to be replaced by
ðMðVÞ K=ðC
ﬃﬃﬃv
p ÞÞv expð2K2=C2Þ, still with normal tails.
If the family F is unbounded, then the foregoing result has to be modiﬁed.
If uniform exponential moments exist, then a similar result may be proved,
but the price is an extra [log(N)]1 term in the blow-up function. A bounding
technique is used to show this result: let for any random variable X and c>0
Xc ¼
c
if X > c
c
if X < c
X
otherwise
8
<
:
456
G.C. Pflug

Theorem 21. Suppose that F is countable and of covering type (v, V ). Suppose
further that the functions Sc ¼ supF2FfF  Fc  E½F  E½Fcg satisfy the
following conditions
(i) ESc  ec/2
(ii) log E exp(s[ScESc])  s2 for all c. Then
P sup
F2F
 1
N
X
N
n¼1
FðnÞ  EF
  K logðNÞ
ﬃﬃﬃﬃ
N
p
(
)

MðVÞ Kﬃﬃﬃv
p

v
expðK2=2Þ þ exp
1
4


exp K2 log2 N
32


,
ð5:13Þ
where M(  ) is a universal function. To put it diﬀerently, F satisﬁes the
uniform boundedness property (see Deﬁnition 6) with blow-up function
ðNÞ ¼
ﬃﬃﬃﬃ
N
p
=logðNÞ and normal tails.
Proof. We use a truncation argument and set cN ¼ log(N).
P sup
F2F
1
N
X
N
n¼1
FðnÞ  EF  K logðNÞ
ﬃﬃﬃﬃ
N
p
(
)
 P sup
F2F
1
N
X
N
n¼1
FcNðnÞ  EFcN  K logðNÞ
2
ﬃﬃﬃﬃ
N
p
(
)
þ P sup
F2F
1
N
X
N
n¼1
½FðnÞ  FcNðnÞ  EFðnÞ þ EFcN  K logðNÞ
2
ﬃﬃﬃﬃ
N
p
(
)
 P sup
F2F
1
N
X
N
n¼1
1
cN
FcNðnÞ  E
1
cN
FcN



K
2
ﬃﬃﬃﬃ
N
p
(
)
þ P
1
N
X
N
n¼1
sup
F2F
½FðnÞ  FcNðnÞ  EF þ EFcN  K logðNÞ
2
ﬃﬃﬃﬃ
N
p
(
)

MðVÞ
K
2
ﬃﬃﬃv
p

v
expðK2=2Þ
þ P
1
N
X
N
n¼1
ScNðnÞ  EScN  K logðNÞ
2
ﬃﬃﬃﬃ
N
p
 EScN
(
)
:
It remains to show the bound for the second summand.
By assumption, EScN  expðlog N=2Þ ¼ N1=2. Therefore, ðK logðNÞ=
ð2
ﬃﬃﬃﬃ
N
p
Þ  EScNÞ2  ððK  2ÞlogðNÞ=ð2
ﬃﬃﬃﬃ
N
p
Þ2:
Ch. 7. Stochastic Optimization and Statistical Inference
457

Using Lemma 12, the second summand can be estimated by
P
1
N
X
N
n¼1
ScNðnÞ  EScN  K logðNÞ
2
ﬃﬃﬃﬃ
N
p
 EScN
(
)
 P
1
N
X
N
n¼1
ScNðnÞ  EScN  K logðNÞ  2
2
ﬃﬃﬃﬃ
N
p
(
)
 exp  ðK log N  2Þ2
16


 exp
1
4


exp  K2 log2 N
32


,
which gives the claimed bound.
u
The following inequality is helpful for ﬁnding bounds for truncated random
variables, which have exponential moments.
Lemma 22. Suppose that the random variable X satisﬁes E[exp sX ]<1 for
some s>0. Then for c>0
E½X  cþ  esc
s
E½exp sX:
Proof. By the convexity of the exponential function, expðsXÞ  expðscÞ þ
s expðscÞðX  cÞ  s expðscÞðX  cÞ. Thus,
Eð½X  cþÞ  esc
s
E½exp sX1Xc  esc
s
E½exp sX:
u
Example. Consider the Newsboy Example of Section 1. Suppose that
x 2 [a, b],
but

is
unbounded.
Then
Fðx, Þ ¼ x þ ½x  þ
is also unbounded. Here we have set sc ¼  and rs ¼ . Using now the
symbol c for the truncation and assuming that c  b, we get F  Fc ¼
½ð þ Þx    cþ. The supremum of ½F  Fc  EF þ EFc is bounded by
½ð þ   cÞ=  þ Gð1Þðð þ   cÞ=Þ. If  has some ﬁnite exponential
moments (e.g., if  has normal tails) then conditions (i) and (ii) are fulﬁlled.
6
Entropic sizes of stochastic programs
In this section we specialize the results about covering types to stochastic
optimization problems. We treat only problems with nonrandom constraints
of the form Minx2Xf f ðxÞ ¼ F½Fðx, Þg.
If the risk functional is the expectation, then—in view of Section 5.4—one
has to consider the entropic size of the family F ¼ fFðx, Þ: x 2 Xg.
458
G.C. Pflug

Suppose that the covering type of F is (v, V ) and that the functions F are
bounded by 1. Then by Theorem 20,
P
ﬃﬃﬃﬃ
N
p
sup
x2X
j ^fNðxÞ  f ðxÞj  K



MðVÞ Kﬃﬃﬃv
p

v
expð2K2Þ:
This gives a positive answer to the basic question (Q1) of Section 3, showing
the blowing up function is
ﬃﬃﬃﬃ
N
p
and the tail behavior is normal. If the functions
F(x, ) are unbounded, then Theorem 21 has to be used instead. The answers
to questions (Q2), resp. (Q3), i.e., about the quality of the solution and
the approximation of the arg min set, can then be found using Propositions 3
resp. 5.
In view of Theorem 7, a better estimate for the approximation of the
arg min set can be found, if the entropic size of the family F r ¼ fðFðx, Þ
Fð y, ÞÞ=ðkx  ykÞ: x, y 2 X; x 6¼ yg can be calculated.
If the risk functional F is not the expectation, but Lipschitz w.r.t. the
distance dH, then the entropic sizes of the families F H ¼ fh 	 Fðx, Þ: x 2 X;
h 2 Hg resp. F r
H ¼ fðh 	 Fðx, Þ  h 	 Fð y, ÞÞ=ðkx  ykÞ: x, y2X; x6¼y; h 2 Hg
have to be determined.
We illustrate the method of determining the entropic size of a stochastic
program for the case F ¼ E. It consists in studying: (1) the covering type of the
feasible set X, and (2) the structure of the mappings x  F(x, ).
Assumption A1. The constraint set X is a compact set in Rd, which has
covering type (d, V ). This means that it can be covered by N" ¼ 8ðV
"Þd9 balls of
radius ", i.e., for every ">0, there are balls Bðx1, "Þ, . . . , BðxN", "Þ with xi 2 X
such that
X 
[
N"
i¼1
Bðxi, "Þ:
For a collection of square integrable functions F ¼ {F()}, let the diameter be
deﬁned as
diam2ðFÞ ¼ E½supfF : F 2 Fg  inffF : F 2 Fg2:
The diameter is well deﬁned only if sup and inf are measurable and square
integrable.
A ‘‘Lipschitz condition’’ of order 
 links the covering type of X with the
covering type of F.
Lemma 23. Suppose that the Assumption A1 is fulﬁlled, i.e., X is of covering
type (d, V ), and that F(x, ) satisﬁes for each x0 2 X and >0
diamðfFðx, Þ: x 2 Bðx0, ÞgÞ  L
ð6:1Þ
Ch. 7. Stochastic Optimization and Statistical Inference
459

for some exponent 
>0 and some constant L. Then F ¼ fFðx, Þ: x 2 Xg is of
covering type (d/
, V
L).
Proof. Let  ¼ ("/L)1/
. Cover X by N ¼ 8 V
 9d balls B(xi, ) of radius . By
(6.1), the diameter of fFðx, Þ: x 2 Bðx0, Þg is at most L
 ¼ ". The number of
balls needed is
N ¼
V


d
¼
V
L
"

d=
:
u
Theorem 24. Suppose that Assumption A1 holds and that the following
conditions are fulﬁlled
(i) x  F(x, ) is Lipschitz continuous with Lipschitz constant L(), i.e.,
jFðx, Þ  Fðy, Þj  LðÞ kx  yk:
(ii) L ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
EL2ðÞ
p
<1: Then F¼fFðx, Þ: x 2 Xg is of covering type ðd, VLÞ.
Proof. This result is a consequence of Lemma 23, since diam2ðfFðx, Þ: x 2
Bðx0, Þg  2EðL2ðÞÞ ¼ 2L
2. Thus, 
 ¼ 1 in (6.1).
u
6.1
Example: The entropic size of a linear recourse problem
As a typical example, consider a linear recourse problem, where the
functions F(x, ) are of the form
Fðx, Þ ¼ minfqðÞTy: WðÞy ¼ bðx, Þ, y  0g
with q() 2 Rm, W() a random [k  m] matrix and b(x, ) a Rk-valued random
function.
We make the following assumption:
Assumption A2.
(i) There exists a measurable function ~u :  ! Rm and a constant C1 such
that
~uðÞ 2 fu: WðÞTu  qðÞg  fu: kuk  C1g:
(ii) The function b: X   ! Rk is diﬀerentiable w.r.t. x and satisﬁes
kb(x, )k  C0 a.s. and
R
supx2X krbðx, Þk2PðdÞ ¼ C2
2 < 1.
460
G.C. Pflug

Theorem 25. Let Assumptions A1 and A2 be fulﬁlled. Then
F X ¼ fFðx, Þ: x 2 Xg ¼ fminfqðÞTy:WðÞy ¼ bðx, Þ, y  0g: x 2 Xg
is of covering type (d, C1C2V ).
Proof. By duality, we may write F as the solution of the dual program, i.e., as
the maximum of a ﬁnite number of K functions v1,. . . , vK.
Fðx, Þ ¼ max
k¼1,...,K bðx, ÞTvkðÞ:
ð6:2Þ
Here vk are the vertices of the dual feasible polyhedron fu: WðÞTu  qðÞg and
K is their maximal number. Since kb(x, )k  C0 and kvk()k  C1, we get
jFðx, Þj  C0C1:
Finally, for all x0,
diam2fFðx, Þ: x 2 Bðx0, Þg  2
Z
C2
1 sup
x2X
krbðx, Þk2PðdÞ
 2C2
1C2
2:
ð6:3Þ
Apply now Lemma 23.
u
The most important special case is that of a linear b(x, !):
bðx, Þ ¼ kðÞ  TðÞx:
Since krb(x, )k ¼ kT()k, independent of x, the constant C2 is here simply
C2
2 ¼
Z
kTðÞk2PðdÞ:
7
Epiconvergence
Up to now, the distance for measuring the approximation error of the
objective functions was the supremum norm. The pertaining topology is
uniform convergence on compacta. This setup is standard in statistical
parameter estimation. However, the approach fails for stochastic programs
with probabilistic constraints, i.e., constraints involving random variables. A
conceptually sound way to deal with constraints and especially with stochastic
Ch. 7. Stochastic Optimization and Statistical Inference
461

constraints is to consider the extended problem by introducing the extended
indicator function
iXðxÞ ¼
0
if x 2 X
1
if x 62 X

ð7:1Þ
and to add iX to the objective function as a penalty term. The two
optimization problems
ðIÞ
minf f ðxÞ: x 2 X  Rdg
and
ðIIÞ
minf f ðxÞ þ iXðxÞ: x 2 Rdg
are clearly equivalent. The problem (II) is only seemingly unconstrained. For
algorithmic purposes, there is no diﬀerence between the formulations (I) and
(II). Conceptually, there is, however, a diﬀerence: problem (II) has the
advantage that is entirely formulated in terms of the objective extended real
function. A disadvantage of (II) is that the notion of uniform convergence is
not applicable. This is the main reason for introducing a new concept of
convergence, especially suited for extended real functions: the concept of
epiconvergence. The standard reference is the book by Rockafellar and Wets
(1998). We give here a short introduction into the theory.
Recall that an extended real valued function f deﬁned on Rd is called lower
semicontinuous (lsc), if for all x and all sequences xN ! x, it follows that
lim infN f(xN)  f(x). f is lower semicontinuous if and only if it is the pointwise
supremum of a countable family of continuous functions.
The epigraph of a function f deﬁned on Rd is
epi f ¼ fðx, Þ:   f ðxÞ; x 2 Rd;  2 Rg:
A function f is lower semicontinuous if and only if epi f is a closed set in Rd þ 1.
Let B(x, r) be the closed ball with center x and radius r in an euclidean
space, i.e., Bðx, rÞ ¼ fy: ky  xk  rg. The unit ball is denoted by B ¼ B(0, 1).
Let C be the family of all closed sets in Rd þ 1 (including the empty set ;). We
introduce the topology of setwise convergence. Let (CN) be a sequence of
closed sets in C. We deﬁne the (topological) limes superior (ls) and limes
inferior (li) as
li CN ¼
x: 9ðxNÞ, xN 2 CN, x ¼ lim
N xN


ls CN ¼
x: 9ðxNkÞ, xNk 2 CNk, x ¼ lim
k xNk


:
462
G.C. Pflug

Obviously, li CN  ls CN. The sequence (CN) of closed sets converges setwise to
C (in the sense of Painleve´ –Kuratowski, in symbol CN!
setC), if
li CN ¼ ls CN ¼ C:
ð7:2Þ
The topology of !
set convergence can be metrizised by the following metric:
ðC1, C2Þ ¼
X
1
k¼1
2k
dðC1 \ kB, C2 \ kBÞ
1 þ dðC1 \ kB, C2 \ kBÞ
where B is the unit ball in Rd þ 1 and d is the Hausdorﬀmetric (see (3.23)). The
localization to the sets kB is necessary, because d(C1, CN) may be inﬁnite for
all N, even if CN!
setC. The family C of all closed sets Rd þ 1 is a separable,
metric space. A countable dense family of sets is given by all ﬁnite sets with
points having rational coordinates.
A sequence of lsc functions ( fN) epiconverges to a lsc function f ( fN!
epif ) if
the following properties hold for all x 2 Rd
(i) for all sequences (xN) with xN ! x, lim infN fN(xN)  f(x)
(ii) there is a sequence yN ! x such that lim supN fN( yN)  f(x).
Setwise convergence and epiconvergence of functions are closely related:
fN epiconverges to f if and only if epi fN!
setepi f . On the other hand, the
sequence of closed sets AN converges setwise to A if and only if the extended
indicator functions iAN epiconverge to iA.
The family of all l.s.c. extended real functions is a separable metric space
under the topology of epiconvergence. A countable dense set of functions is
given by functions of the form f(xi) ¼ ri for a ﬁnite set of rational points xi and
rational values ri and f(x) ¼ 1 elsewhere.
Epiconvergence
does
not
imply
and
is
not
implied
by
pointwise
convergence.
Example 26. Consider the following sequence of functions
f ð1Þ
N ¼
Nx
if 0  x  1=N
Nx  2
if 1=N x2=N
0
otherwise
f ð2Þ
N ¼
Nx  1
if 1=N x0
1 þ Nx
if 0  x  1=N
0
otherwise
8
<
:
8
<
:
Both sequences epiconverge to f(x) ¼ 1{x ¼ 0}. The ﬁrst sequence converges
pointwise to another limit, namely 0. The second sequence converges also
pointwise, but not uniformly to f(x). Uniform convergence of a sequence of lsc
functions to a limit function implies, however, that the limit is lsc and that
epiconvergence holds.
Ch. 7. Stochastic Optimization and Statistical Inference
463

Most
important
is
the
relation
between
epiconvergence
and
the
convergence of minima and argminima.
Lemma 27. Let fN!
epif . Then
(i) lsN arg min fN 
 arg min f :
(ii) If for all ">0 there is an index N" and a compact set K" such that
inff fNðxÞ: x 2 K"g  inff fNðxÞ : x 2 Rdg þ " for all N  N", then
inf
x fNðxÞ ! inf
x f ðxÞ:
(iii) Suppose that there is a compact set K such that arg min fN 
 K, for suﬃ-
ciently large N. Suppose further that arg min f ¼ {x*} is a singleton. Then
lsN arg min fN ¼ fx*g,
i.e., for every selection xN 2 arg min fN, xN ! x* as N ! 1.
Proof. (i) Let xNk 2 arg min fNk and suppose that xNk ! x. We have to show
that x 2 arg min f. By epiconvergence lim infk fNkðxNkÞ  f ðxÞ and by (7.3)
lim supk fNkðxNkÞ  infu f ðuÞ. Combining the two inequalities, we get f ðxÞ 
infu f ðuÞ and therefore x 2 arg min f. (ii) Let x such that f ðxÞ < infu f ðuÞ þ ".
There is a sequence ( yN) ! x with lim supN fNð yNÞ  f ðxÞ and therefore
lim supN infu fNðuÞ  lim supN fNð yNÞ  f ðxÞ  infu f ðuÞ þ ". Since " was arbi-
trary,
lim sup
N
inf
u fNðuÞ  inf
u f ðuÞ:
ð7:3Þ
To show the opposite inequality we choose an " and a sequence of points
(xN) 2 K" with the property that fNðxNÞ  infu fNðuÞ þ 2". We can choose a
subsequence (xNk) which converges to some x 2 K". By epiconvergence,
lim infN infu fNðuÞ  lim infN fNðxNÞ  2"  f ðxÞ  2"  infu f ðuÞ  2". Since "
is arbitrary, (ii) follows. (iii) Every selection xN 2 arg min fN has cluster points,
because of compactness. But every cluster point must be in arg min f, i.e., must
be equal to x*.
u
The inclusion in (i) may be strict as is shown by the following example:
fNðxÞ ¼
x=N
if 0  x  1
1
otherwise
:

fN epiconverges to
f ðxÞ ¼
0
if 0  x  1
1
otherwise
,

but arg min fN ¼ {0} does not converge to arg min f ¼ [0, 1].
464
G.C. Pflug

However, if we introduce the notion of "-arg min
"-arg min f :¼
x: f ðxÞ  inf
u f ðuÞ þ "
n
o
,
the following lemma can be shown.
Lemma 28. Suppose that fN!
epif and that infx fNðxÞ ! infx f ðxÞ. Then there is
a sequence "N ! 0 such that "N-arg min fN ! f . Conversely, if "N ! 0 and
"N-arg min fN ! f then infx fNðxÞ ! infx f ðxÞ.
Proof. See Rockafellar and Wets (1998), Theorem 7.31.
u
Besides this qualitative statement, a quantitative statement of the relation
between the epidistance of functions and the distance of the arg mins is highly
desirable. The following Theorem 29 links the epidistance of functions with
the distance of "-arg mins. Such a theorem can be used to formulate an
analogue to Proposition 5 (which was formulated for sup-norms) within the
epiconvergence setup.
For the formulation of the result, we introduce two new distances for
functions:
^dð f , gÞ ¼ dðepi f , epi gÞ
where d is the Hausdorﬀdistance introduced in (3.23) and a variant
^dþð f , gÞ¼inff: f ðxÞinf gy2Bðx,Þ; gðxÞinf fy2Bðx,Þ for all xg:
We have that
^dþð f , gÞ  ^dð f , gÞ 
ﬃﬃﬃ
2
p ^dð f , gÞ
(see Rockafellar and Wets, 1998, Proposition 7.61, p. 284).
Remark. The original deﬁnition of ^d and ^dþ in Rockafellar and Wets (1998)
includes the restriction to a ball B. In some applications, this restriction may
be necessary. The concept and idea, however, may be demonstrated without
this restriction.
If two functions f and g are close to each other w.r.t. distance ^dþ, both their
min’s and their "-arg min’s are close to each other according to the following
theorem.
Ch. 7. Stochastic Optimization and Statistical Inference
465

Theorem 29. Suppose that f and g are lsc convex functions on a compact set 
in Rd. Suppose further that dð0, 3"-arg min f Þ  , dð0, 3"-arg min gÞ   for
some constant . Then ^dþð f , gÞ ¼  and <" implies that
(i) jmin fmin gj  
(ii) ^dð"-arg min f , "-arg min gÞ   þ
2
"þ2 2.
Proof. The proof is a modiﬁcation of the proof of Theorem 7.69, p. 291 in
Rockafellar and Wets (1998). Let x þ 2 arg min f. By the deﬁnition of
^dþð f , gÞ < , min g  miny2Bðxþ,Þ gðyÞ  f ðxþÞ þ  ¼ min f þ . Exchanging f
and g, wet get (i). Next we show that
"-arg min f  ð" þ 2Þ-arg min g:
Suppose that x 2 "-arg min f . Let y 2 B(x, ) such that g(y)  f(x) þ . Then
gðyÞ  min f þ " þ   min g þ " þ 2. Finally, we show that
ð" þ 2Þ-arg min g  ð"-arg min gÞ þ
2
" þ 2 2


B:
ð7:4Þ
Let 0 ¼ min g, 1 ¼ min g þ ", 2 ¼ min g þ " þ 2. Let x 2 ð" þ 2Þ-arg min g,
i.e., g(x)  2. and let x* 2 arg min g. Let y ¼ ð1  Þx þ x*, where  ¼
ð21Þ=ð20Þ ¼ 2=ð" þ 2Þ. Then, by convexity, gðyÞ  ð1  Þ2 þ 0 ¼
1. Thus, y 2 "-arg min g. Since kx  yk ¼ kx  x*k  2dð0, 3"-arg min gÞ
 2, (7.4) is established. Putting the pieces together, we have shown that
"-arg min f  "-arg min g þ
 þ
2
" þ 2 2


B
which is equivalent to dð"-arg min f k "-arg min gÞ   þ
2
"þ2 2. By exchan-
ging the roles of f and g we get the assertion (ii).
u
For the application of the concept of epiconvergence in statistics and
stochastic optimization it has to be extended to stochastic processes. A
stochastic process ðx, !Þ  Zðx, !Þ is called a random lower semicontinuous
function if it is jointly measurable and for all ! 2 , x  Z(x, !) is lower
semicontinuous.
If Z is a random lsc process on Rd, then epi Z induces a probability measure
on the Borel sets of the metric space (Cd þ 1, ). For a sequence (ZN) of random
lsc processes, the notion of a.s. convergence in the epi sense is well deﬁned: ZN
epiconverges to Z almost surely, if
PfZN!
epiZg ¼ 1:
466
G.C. Pflug

Of course, also the notion of convergence in distribution is deﬁned: (ZN)
epiconverges in distribution to Z (in symbol: ZN !
epi-DZ), if the probability
distributions induced by epi ZN on the separable metric space (Cd þ 1, ) weakly
converge to that induced by epi Z.
An equivalent formulation of the epiconvergence in distribution is given by
the following theorem.
Theorem 30. Let ZN(x,  ) be a l.s.c. process. Then ZN epiconverges in
distribution (ZN !
epi-DZ) if and only if for all k, all collections of closed rectangles
R1,. . . , Rk and all reals 1,. . . , k
P
inf
x2R1 Zðx, Þ > 1, . . . , inf
x2Rk Zðx, Þ > k


 lim inf
N
P
inf
x2R1 ZNðx, Þ > 1, . . . , inf
x2Rk ZNðx, Þ > k


 lim sup
N
P
inf
x2Ro
1
ZNðx, Þ  1, . . . , inf
x2Ro
k
ZNðx, Þ  k


 P
inf
x2Ro
1
Zðx, Þ  1, . . . , inf
x2Ro
k
Zðx, Þ  k


:
Proof. See Salinetti and Wets (1986) and Pﬂug (1992).
u
8
Epipointwise convergence for stochastic programs
In this section we consider a stochastic program with random constraints
Min
x2X\y f f ðxÞ ¼ EP½Fðx, Þg
where
Y ¼ fx: E½F1ðx, Þ  b1, . . . , E½FJðx, Þ  bJg:
The empirical counterpart of f is ^fNðxÞ ¼ 1
N
P1
n¼1 Fðx, nÞ and the empirical
counterpart of the constraint set Y is
^YN ¼ x: 1
N
X
N
n¼1
F1ðx, nÞb1þlog N
ﬃﬃﬃﬃ
N
p
, . . . , 1
N
X
N
n¼1
FJðx, nÞbJ þlog N
ﬃﬃﬃﬃ
N
p
(
)
:
Ch. 7. Stochastic Optimization and Statistical Inference
467

The extra term log Nﬃﬃﬃ
N
p
is added for consistency reasons. Consider the extended
function
f eðxÞ ¼ f ðxÞ þ iYðxÞ
and its empirical counterpart
^f e
NðxÞ ¼ ^fNðxÞ þ i ^YNðxÞ
where i, the extended indicator function, is given by (7.1).
^f e
NðxÞ converges a.s. pointwise to f e(x), but not uniformly. Epiconvergence
holds often in addition to that. The combination of pointwise convergence
and epiconvergence leads to the following deﬁnition.
Deﬁnition 31. The extended real functions fN converges epipointwise to
f (in symbol: fN !
epipwf ), if
(i) xN ! x implies that lim infN fNðxNÞ  f ðxÞ
(ii) fN(x) ! f(x) for all x.
Epipointwise convergence is a stronger concept than just epiconvergence:
take the functions f ð1Þ
N
and f ð2Þ
N
of Example 26. While f ð2Þ
N
converge to f ðxÞ
¼ 1fx¼0g in the epipointwise sense, the functions f ð1Þ
N do not converge in this
sense. On the other hand, epipointwise convergence is weaker than uniform
convergence. There is an equivalent deﬁnition for epipointwise convergence.
Lemma 32. For lsc functions, fN !
epipwf if and only if
lim inf
x2R fNðxÞ ¼ inf
x2R f ðxÞ
for all compact rectangles R.
Proof. Suppose that fN !
epipwf . Let x 2 R such hat f ðx*Þ ¼ infx2R f ðxÞ. Then,
since
fNðx*Þ ! f ðx*Þ,
lim sup infx2R fNðxÞ  infx2R f ðxÞ.
Together
with
lim sup infx2R fNðxÞ  infx2R f ðxÞ this implies the assertion. Conversely, let
lim infx2R fNðxÞ ¼ infx2R f ðxÞ for all compact R. By setting R ¼ {x} pointwise
convergence follows. Let xN ! x. Suppose that lim inf fNðxNÞ ¼ f ðxÞ  ",
where ">0. We may ﬁnd a compact rectangle R such that x lies in its
interior and such that infy2R f ðyÞ  f ðxÞ  "=2. By assumption, f ðxÞ  " ¼
lim inf fNðxNÞ  limy2R inf fNðyÞ infy2R f ðyÞ  f ðxÞ  "=2.
This contradiction
proves the lemma.
u
468
G.C. Pflug

It is in general not true that fN!
epif and gN!
epig implies that fN þ gN!
epif þ g
(as a counter example, take the functions fN ¼ f ð2Þ
N
of Example 26 and
gN ¼ fN. Then because of the asymmetry of the epiconvergence, fN þ gN:0,
but f þ g ¼ 1{x ¼ 0}). However, epipointwise convergence is compatible with
sums.
Lemma 33. If fN !
epipwf and gN !
epipwg, then fN þ gN !
epipwf þ g.
Proof. Since
lim infN fNðxNÞ þ gNðxNÞ  lim infN fNðxNÞ þ lim infN gNðxNÞ,
the assertion follows from the deﬁnition of epipointwise convergence
(Deﬁnition 31).
u
As an important consequence of this lemma one sees that for the epi-
pointwise convergence of ^f e
N one may consider the two parts ^fNðxÞ and i ^YNðxÞ
separately.
Assume that the functions F(x, ) and Fj(x, ), j ¼ 1,. . . , J have for x 2 X the
uniform boundedness property (see Deﬁnition 6). Suppose that the constraint
set Y fulﬁlls the following condition:
Condition (B). There is a function "()>0, for >0 such that the following
implications hold: if x 2 Y, then infy2Bðx,Þ fjðxÞ < bj  "ðÞ for at least one
j 2 [1,. . . , J ]. If B(x, ) \ Y ¼ ;, then fj(x)>bj þ "() for at least one j 2 [1,. . . , J].
Theorem 34. Suppose that ^fN converges a.s. uniformly to f and that ^fN,j converge
a.s. uniformly to fj for all j. Suppose further that supx VarðFjðx, ÞÞ ¼  < 1.
Then, under Condition (B), ^fN þ i ^YN converges a.s. epipointwise to f þ iY.
Proof. In view of Lemma 33, we have only to show that i ^YN converges a.s.
epipointwise to iY. We show ﬁrst the pointwise convergence. If x 62 Y, then
there is a j such that fj (x)>bj for some j. Therefore, since ^fN, jðxÞ ! fjðxÞ a.s.,
for every ! there is an N0(!) such that ^fN, j > bj þ ðlog N=
ﬃﬃﬃﬃ
N
p
Þ for N  N0.
Consequently, i ^YN  if ^fN,jðxÞbjþðlog NÞ= ﬃﬃﬃ
N
p g ! 1 ¼ iffjðxÞbjg. If x 2 Y, then by the
LIL (Theorem 11) ^fN, jðxÞ  bj þ 2 ðlog log NÞ=
ﬃﬃﬃﬃ
N
p
a.s., where  is the standard
deviation
of
Fj(x, ).
Therefore,
also
in
this
case
if ^fN,jðxÞbjþðlog NÞ= ﬃﬃﬃ
N
p
g
! 0 ¼ iffjðxÞbjg.
For the epiconvergence property, we have to show that for all x and all >0,
P sup
x
inf
y2Bðx,Þ i ^YNðyÞ  iY  


! 0
and
P inf
x
inf
y2Bðx,Þ iYðyÞ  i ^YNðxÞ  


! 0:
Ch. 7. Stochastic Optimization and Statistical Inference
469

Since we assume that 11 ¼ 0, this is equivalent to
Pf9x 2 Y : for all y 2 Bðx, Þ: y 62 ^YNg ! 0
Pf9x 2 ^YN : for all y 2 Bðx, Þ: y 62 Yg ! 0
By Assumption (B), if x 2 Y, then there is a j and some y 2 B(x, ) such
that fj(y)<bj"(). But this implies that Pf fN, jðyÞ > bj þ ðlog NÞ=
ﬃﬃﬃﬃ
N
p
g ! 0.
On the other hand, if for all y 2 B(x, ), y 62 Y, then there is a j such that
f(x)>bj þ "(), which implies that Pf ^fj,NðxÞ  bj þ ðlog NÞ=
ﬃﬃﬃﬃ
N
p
g ! 0.
u
9
Asymptotic stochastic programs
Consider a stochastic program in the extended form
Min
x2Rd f f eðxÞ ¼ E½Fðx, Þ þ iXg
ð9:1Þ
where iX the extended indicator function of the constraint set X, is deﬁned as
in (7.1). We assume that the constraint set X is closed, convex and nonran-
dom. Program (9.1) has the empirical counterpart
Min
x2Rd
^f e
NðxÞ ¼ 1
N
X
N
n¼1
Fðx, nÞ þ iX
(
)
:
ð9:2Þ
Let v be the minimal value of (9.1) and ^vN the (random) minimal value of (9.2).
Any measurable selection of the empirical arg min set ^xN 2 ^X *
N, where
^X *
N ¼ arg min
x2Rd
1
N
X
N
n¼1
Fðx, nÞ þ iX
(
)
is called an empirical solution.
We study ﬁrst the asymptotic behavior of the empirical minima ^vn and later
the asymptotic behavior of the empirical arg minima ^xN.
The basic observation is: if ^f e
NðÞ converges (a.s. or in probability) to f e(  ) in
some function space and the min-operator f  Mð f Þ ¼ minx f ðxÞ is continuous
in this function space, then ^vN converges (a.s. or in probability) to v.
A more reﬁned analysis considers the errors in more detail: suppose that
YNðxÞ ¼ ðNÞð ^f e
NðxÞ  f eðxÞÞ
ð9:3Þ
470
G.C. Pflug

converges in distribution to a nondegenerate limit process Y in a function
space. If the min-operator is diﬀerentiable in this function space, then
ðNÞð^vN  vÞ converges in distribution to a limit law. A theorem of this kind is
stated below.
Theorem 35. Suppose that ðNÞð ^f e
NðxÞ  f eðxÞÞ converges in the Banach space
C(X ) of continuous functions to a limiting distribution Y. If X is compact, then
ðNÞð^vN  vÞ
converges in law to
min
x2X* YðxÞ
where X* is the set of solutions of (9.1).
Proof. The ‘‘delta’’ method of proof was already mentioned (see Shapiro,
1993): if M is an (at least directionally (Hadamard-) diﬀerentiable operator
in C(X) and YN given by (9.3) converges in law to Y, then ðNÞ½M
ð ^f e
NðxÞÞ  Mð f eðxÞÞ converges in law to M0ðMð f eðxÞÞ, YÞ. Here M0ð f , gÞ ¼
limh#0 1
h ½Mð f þ hgÞ  Mð f Þ. It is easy to see that the directional derivative of
the min-operator M in C(X) is
M0ð f , gÞ ¼ minfgðxÞ: x 2 arg min f g:
A more direct proof (which is also applicable, if the function space is not
a
Banach
space)
shows
that
the
asymptotic
distribution
of
ðNÞ
½minx2X ^f e
NðxÞ minx2X f eðxÞ is the same as the asymptotic distribution
of
ðNÞ½minx2X* ^f e
NðxÞ  minx2X* f eðxÞ ¼ minx2X* ðNÞ½ ^f e
NðxÞ  f eðxÞ.
The
latter expression has asymptotic distribution minx2X* YðxÞ.
u
For studying the limiting distribution of the solutions we suppose that (9.1)
has a unique solution
x* ¼ arg min
x2Rd
fE½Fðx, Þ þ iXg,
ð9:4Þ
and that ^xN is a measurable selection from ^X *
N.
The goal is to ﬁnd the limiting distribution of
1
N ð ^xN  x*Þ,
where N is an appropriately chosen sequence of regular matrices.
The basic equation is
1
N ðarg min
x
^f e
NðxÞ  x*Þ ¼ arg min
t
^f e
Nðx* þ NtÞ:
ð9:5Þ
Ch. 7. Stochastic Optimization and Statistical Inference
471

Here t is called the local coordinate around the solution x*. The left hand side
of (9.5) appears as the arg min of a stochastic program in local coordinates.
Evidently, the right hand side may be written as
arg min
t
^f e
Nðx* þ NtÞ ¼ arg min
t
N½ ^f e
Nðx* þ NtÞ  f ðx*Þ
¼ arg min ZNðtÞ ðsayÞ
where N>0 is arbitrary. Now, suppose that N and N are chosen such that
the extended real stochastic process ZNðÞ ¼ N½ ^f e
Nðx* þ NtÞ  f ðx*Þ con-
verges to a limiting process Z(  ). Then, using a M-theorem (Minimizer
theorem) of the form
lim
N arg min
t
ZNðtÞ ¼ arg min
t
lim
N ZNðtÞ
ð9:7Þ
we may identify the limiting distribution of 1
N ð ^xN  x*Þ as the distribution of
arg mint Z(t). A useful M-theorem will be given below (see Theorem 37).
Under rather general assumptions ZN(  ) converges in distribution to a
limiting process
ZðÞ ¼ DðÞ þ SðÞ þ iXþðÞ,
ð9:8Þ
where D(t) is a regularly varying deterministic function, S(t) is a zero mean
stochastic process on Rd, which by the classical result of P. Le´ vy, must be
inﬁnitely divisible, and X þ is some closed convex set.
To be more precise about the type of convergence, we assume that
N
X
N
n¼1
½Fðx* þ Nt, nÞ  Fðx*, nÞ
converges to
DðtÞ þ SðtÞ
in distribution in the sup-norm sense, whereas
iXðx* þ NtÞ
converges to
iXþðtÞ
in distribution in the epi-sense (which is equivalent to setwise convergence of
the constraint sets).
The sum then converges also in the epi-sense. We consider the process ZN
as a random element in the separable metric space of lsc functions on Rd (see
Section 7).
472
G.C. Pflug

Deﬁnition 36. Suppose that ZN(  ) deﬁned by (9.6) epiconverges in distribu-
tion to Z(  ) given by (9.8). Then the stochastic program
Min
t
ZðtÞ ¼ Min
t2XþfDðtÞ þ SðtÞg
ð9:9Þ
is called the asymptotic stochastic program associated to (9.1).
Notice that S(t) is a stochastic process and hence the arg min of (9.9) is a
random variable or a random set.
Now we make the cited M-theorem (9.7) precise.
Theorem (M-Theorem) 37. Suppose that the l.s.c. processes ZN(  ) epiconverge
in distribution to a l.s.c. limiting process Z(  ). Suppose further that these
processes satisfy the assumptions of Lemma 27 (iii), i.e., there is a (random)
compact set K(!) such that arg min ZNð!Þ  Kð!Þ a.s. and that arg min Z is a.s.
a singleton. Then any measurable selection from arg mint ZNðtÞ converges in
distribution to arg mint ZðtÞ.
Proof. Using the Shorohod–Wichura–Dudley theorem (see Shorack and
Wellner, 1986, p. 47), one may construct, on an appropriate probability space,
versions ~ZN and ~Z of the processes ZN and Z, which converge almost surely in
the episense. These versions satisfy for almost all !, the assumptions of
Lemma 27(iii). Thus, all measurable selections from arg min ~ZN converge to
arg min ~Z almost surely. A fortiori, convergence in distribution of any
selection from arg min ZN to the distribution of arg min Z holds.
u
The technique to prove the asymptotics of a stochastic program consists
therefore in two steps

identiﬁcation of the asymptotic stochastic program,

calculation of the arg min distribution of the asymptotic program.
There are some classes of stochastic processes Z(  ) which may occur as
limits. In principle, by letting  be a degenerate random variable, one sees that
the class of limiting stochastic programs is at least as large as the class of
deterministic programs. However, by a general result due to P. Le´ vy, a
nondegenerate limiting process appearing in (9.8) must be a stable process.
The simplest stable process is the normal shift process, i.e., SðtÞ ¼ tTY, where
Y  Nð0, Þ. Here tT denotes the transposition. Examples for other stable
processes appearing as limits of stochastic programs, like Wiener type
processes and Poisson type processes were given by Pﬂug (1995).
We consider here only the smooth case, which leads to normal shift limit
process. The other mentioned limit processes may appear only for cost
functions having jumps.
Ch. 7. Stochastic Optimization and Statistical Inference
473

There is a distinction to be made between the two cases

The optimum x* lies in the interior of the feasible set X, no constraints
appear in the limiting stochastic program. This is case 1.

The optimum x* lies on the boundary of X. This is case 2.
9.1
Case 1: No constraints in the limit
The basic assumption concerns the local behavior of x  F(x, ) near the
optimum x*. We introduce the following set of assumptions:
Condition C1. F(x, ) is a smooth function in the sense that it allows an
expansion
Fðx* þ t, Þ ¼ Fðx*, Þ þ tT½kðÞ þ tTQðÞt þ rðt, Þ
such that jrðt, Þj ¼ rðÞoðktk2Þ for a function r satisfying EðrðÞÞ < 1. All
entries of the vector k() are square integrable and all entries of the matrix
Q() are integrable.
Theorem 38. Let Assumption C1 be satisﬁed and suppose that x* lies in the
interior of X. Then with N ¼
1ﬃﬃﬃ
N
p
I
ZNðtÞ ! ZðtÞ ¼ tTY þ tTAt
in distribution, uniformly on compact sets, where A ¼ EðQðÞÞ and Y  Nð0, Þ
with  ¼ EðkðÞ  kðÞTÞ.
Proof. Expand ZN(t) as
ZNðtÞ ¼
X
N
n¼1
F x* þ t=
ﬃﬃﬃﬃ
N
p
, n


 Fðx*, nÞ
¼ t=
ﬃﬃﬃﬃ
N
p
X
N
n¼1
kðnÞ þ 1=N
X
N
n¼1
tTQðiÞt þ
X
N
n¼1
r x* þ t=
ﬃﬃﬃﬃ
N
p
, n


¼ tTYN þ tTANt þ rNðtÞ ðsayÞ:
Here YN ¼ N1=2 PN
n¼1 kðnÞ converges by the CLT in distribution to a
normal distribution Y  Nð0, Þ with  ¼ Eðk  kTÞ and hence tTYN ! tTY.
(Notice that EðkðÞÞ ¼ 0 because of the optimality condition). By the Strong
474
G.C. Pflug

Law of Large Numbers (9) 1=N PN
n¼1 tTQðnÞt ! tTEðQðÞÞt ¼ tTAt almost
surely. By Assumption C1, for all T,
sup
ktkT
jrNðtÞj ¼ sup
ktkT

X
N
n¼1
r x* þ t=
ﬃﬃﬃﬃ
N
p
, n


¼ oð1ÞkTk2 1=N
X
N
n¼1
rðnÞ ! 0
a:s:
u
The arg min distribution of the process Z appearing in Theorem 38 is
normal, since
arg minftTY þ tTAt: t 2 Rdg ¼ 1
2 A1Y  N 0, 1
4 ½A1TA1


:
9.2
Case 2: The limiting arg min lies on the boundary of the constraint set
Suppose that the solution x* lies on the boundary of the convex set X  Rd.
Let k be the gradient of the objective function at point x*. Necessarily, k
points outwards X. By a possible translation and rotation of the parameter
space X, we may standardize the problem such that x* is the origin and k is a
positive multiple of the ﬁrst unit vector e1.
Suppose therefore w.l.o.g. that x* ¼ 0 and k=kkk ¼ e1. The asymptotics
depend on the local curvature of the convex set X near its boundary point 0 as
will be deﬁned now.
Deﬁne the function X on the sphere S :¼ fs: ksk ¼ 1g of Rd with values in
[0, 1] as
XðvÞ ¼ supf :   v 2 Xg:
ð9:10Þ
X(v) characterizes X completely. The tangential cone X0 of X at 0 is the
closure of fv: XðvÞ > 0g. Recall that a point x is extremal in a convex set Z, if
x cannot be represented as x ¼ 1
2 z1 þ 1
2 z2, where zi 2 Z and z1 6¼ z2.
Assumption C2. Either 0 is extremal in the tangential cone X0, in which case
we set  ¼ 1 (see Figs. 3 and 4), or there is an >1 such that for all s?e1
Xðs þ e1Þ ¼ cðsÞ1=ð1Þð1 þ oð1ÞÞ
ð9:11Þ
where o(1) ! 0 uniformly in s as  ! 0 and s  c(s) is upper semicontinuous.
The constant  is called the degree of curvature of X at 0.
Ch. 7. Stochastic Optimization and Statistical Inference
475

The blow-up matrices will be chosen as
N ¼
N
0
  
0
0
N
  
0
..
.
..
.
..
.
..
.
0
0
..
.
N
0
BBB@
1
CCCA
ð9:12Þ
Proposition 39. Let Assumption C2 be satisﬁed with >1. If N ! 0 and
N
N ! 1 then with N given by (9.12) XN ¼ 1
N X!
setX*, where
X * ¼ fs þ e1 : s ? e1;   cðsÞ  ; ,  0g:
ð9:13Þ
Fig. 3. A convex set X (left) and its asymptotic set X* (right) expanded at the origin using
the blow-up matrices N with N ¼ N1, N ¼ N1. Here the local curvature is  ¼ 1.
The asymptotic set is a cone.
Fig. 4. A convex set X (left) and its asymptotic set X* (right) expanded at the origin using
the blow-up matrices N with N ¼ N1, N ¼ N1/2. Here the local curvature is  ¼ 2.
The asymptotic set is a parabola.
476
G.C. Pflug

If, however, N
N !1 then XN ¼ 1
N X!
setX 0, where X 0 is the tangential cone
X0 ¼ fs þ e1 : s ? e1; ,   0g
ð9:14Þ
which is a half-space.
Proof. See Pﬂug (1995).
u
The situation is illustrated in Figs. 3 and 4.
Theorem 40. Let Assumptions C1 and C2 be satisﬁed with >1 being the
degree of curvature of X at x*. Set  ¼ min(, 2). Let
N ¼
N=2ð1Þ
0
  
0
0
N1=2ð1Þ
  
0
...
...
..
.
...
0
0
..
.
N1=2ð1Þ
0
BBB@
1
CCCA,
and N ¼ Nð2Þ=ð22Þ. Then ZN epiconverges in distribution to Z, where Z(  ) is
of the following form: if <2, then
ZðtÞ ¼ tTk þ tTY þ iX*ðtÞ;
if  ¼ 2, then
ZðtÞ ¼ tTk þ tTY þ tTPTAPt þ iX*ðtÞ;
if >2, then
ZðtÞ ¼ tTk þ tTY þ tTPTAPt þ iX0ðtÞ:
Here P ¼ I  kkk2k k
T
is the projection operator onto the orthogonal
complement of k,  ¼ PTEðkkTÞP and Y  Nð0, Þ. X * is given by (9.13)
and X 0 is the tangential cone.
Proof. See Pﬂug (1995).
u
Example 41. Consider the following program
Minfx1 þ E½x11 þ x22: kjx2j  x1  0g
ð9:15Þ
Ch. 7. Stochastic Optimization and Statistical Inference
477

where 1<<2, E(1) ¼ E(2) ¼ 0 and
Covð1, 2Þ ¼  ¼
2
1
12
12
2
2


:
It is evident that x* ¼ (0, 0) is the solution of (9.15). Let 
 ¼ 1/(21) and
N ¼
N
0
0
N


:
Let (1,n, 2,n) be an i.i.d. sequence distributed like (1, 2). The empirical
program pertaining to (9.15) is
Min N
 N
t1þN
N1t2
X
N
n¼1
2,iþN
N1t1
X
N
n¼1
1,n
"
#
:kjt2jt1 0
(
)
¼ Min t1 þ N1=2t2
X
N
n¼1
2,iþ: kjt2j  t1  0
(
)
which converges to the asymptotic program
Minft1 þ t2Y : kjt2j  t1  0g
ð9:16Þ
where Y  Nð0, 2
2Þ. Let (T1, T2) be distributed according to the arg min-
distribution of (9.16). Then T1 ¼ k1=ð1Þj Y
 j=ð1Þ and T2 ¼ signðYÞj Y
k j1=ð1Þ.
For the case  ¼ 2, T1 has a 2 distribution and T2 has a normal distribution.
Remark. If the curvature  ¼ 1, then an asymptotic distribution exists if
E(k()) ¼ 0.
In
this
case
the
asymptotic
stochastic
program
is
MinfZðtÞ ¼ tTY þ iX0ðtÞg. The appropriate localizing sequence is N ¼ N1I.
Instead of using the just presented ‘‘local coordinates’’ one may use in
smooth cases the ‘‘generalized delta method’’. The idea of this method is to
relate the variations of the objective function to the variations of the arg mins:
suppose that xðvÞ ¼ arg minx2X f ðxÞ þ x  v. The mapping v  xðvÞ may be
complicated. Only in very simple cases it is linear or locally linear. As an
example, take X ¼ Rd, f ðxÞ ¼ 1
2 xTAx for a positive deﬁnite A. Then
xðvÞ ¼ A1v, hence linear. If the criterion function f is, however, not locally
quadratic or some constraints are active in the optimum, then this function is
478
G.C. Pflug

not locally linear. The idea of the generalized delta method is to use the
following argument
arg min ^fNðxÞ ¼ arg min
x
f f ðxÞ þ ½ ^fNðxÞ  f ðxÞ  ½ ^fNðx*Þ  f ðx*Þg
¼ arg min
x
f f ðxÞþðxx*Þ½r ^fNðx*Þrf ðx*Þþremainderg
¼ arg min
x
f f ðxÞ þ x½r ^fNðx*Þ  rf ðx*Þ þ remainderg
 xðr ^fNðx*Þ  rf ðx*ÞÞ:
(see Shapiro, 1993). The random variable ½ r ^fNðx*Þ  rf ðx*Þ may be normal
in regular cases. The random variable xð½r ^fNðx*Þ  rf ðx*ÞÞ is normal only in
the
special
case,
when
x
is
locally
linear.
One
way
to
look
at
xðr ^fNðx*Þ  rf ðx*ÞÞ is to ﬁnd its directional derivatives x0ð0, dÞ. This method
is elaborated in the book by Bonnans and Shapiro (1999).
If the constraints are also random, then the asymptotic results may be
based on a generalized equation approach and a Z-theorem (Zero Theorem):
suppose for instance, that the stochastic program is
Minff ðxÞ ¼ E½Fðx, Þ: gðxÞ ¼ E½Gðx, Þ  0, x 2 Xg:
ð9:17Þ
Assuming convexity of f, g and the set X, the generalized equations, which
characterize the solution, are
0 2 rf ðxÞ þ yrgðxÞ þ NXðxÞ
0 2 gðxÞ þ NðyÞ
Here NXðxÞ ¼ fu: uTðv  xÞ  0, v 2 Xg and Nð yÞ ¼ fu  0: uTy ¼ 0g.
The abstract Z-theorem reads: if the set-valued process ^HNðÞ converges to
H(  ), then the solutions ^xN of the generalized equation 0 2 ^HNðxÞ converge to
the solution x* of 0 2 H(x).
Such an approach was used by King and Rockafellar (1993) and Shapiro
(1993). For Z-theorems see Anisimov and Pﬂug (2000) and the chapter
Stability of Stochastic Programs by Ro¨ misch in this volume and references
therein.
10
Bibliographic remarks
Glivenko and independently Cantelli proved what is now called the
Glivenko–Cantelli Theorem in 1933. It states the uniformity of the empirical
measure convergence for intervals. Blum (1955) and DeHardt (1971) gave the
Ch. 7. Stochastic Optimization and Statistical Inference
479

ﬁrst bracketing conditions for uniformity. This idea was further developed by
Ossiander (1987) and Van der Vaart (1994) and many others. In 1971 Vapnik
and Cervonenkis published their seminal paper on the shattering dimension of
a class of sets and the relation to uniformity. The ﬁrst uniform entropy result
is due to Pollard (1982). Ledoux and Talagrand introduced in their 1991 book
about probability in Banach spaces isoperimetric methods. These methods are
extensively used in Talagrand’s fundamental paper about sharper bounds. The
1996 book by van der Vaart and Wellner summarizes various results about
Glivenko–Cantelli and Donsker classes of functions. It also contains a
simpliﬁed proof of Talagrand’s theorem.
The foregoing results were obtained for i.i.d. random variables. For
robustness reasons, one is also interested in ‘‘slightly’’ dependent variables.
Whereas Laws of Large Numbers are well known for dependent variables
(Andrews, 1988; Andrews and Pollard, 1994), tight bounds are still missing.
The most promising direction of generalization of the i.i.d. case goes through
mixing conditions (Doukhan et al., 1994, 1995), see also the book by De la
Pen˜ a and Gine´ (1999). Talagrand’s measure concentration techniques were
generalized by Marton (1996).
The notion of epiconvergence was introduced by Wijsman (1964). This
reference and much more can be found in the book Rockafellar and Wets
(1998). Salinetti and Wets (1986) introduced the concept of convergence in
probability for sequences of closed-set valued random variables. Vogel (1994)
considered ‘‘one-sided’’ versions of it by deﬁning upper and lower semi-
convergence in probability.
Asymptotic distribution for solutions of stochastic programs were given by
King and Rockafellar, Dupacova and Wets, Shapiro, Ro¨ misch, Pﬂug and
many others.
There is a close relation between the asymptotic theory of stochastic
optimization programs and the asymptotic theory of statistical estimation
under constraints. Among the large number of papers in the latter area, we
cite here: Geyer (1994), Dong and Wets (2000) and Shapiro (2000).
References
Andrews, D.W.K. (1988). Laws of large numbers for dependent non-identically distributed random
variables. Econometric Theory 4, 458–467.
Andrews, D.W.K., D. Pollard (1994). An introduction to functional central limit theorems for
dependent stochastic processes. International Statistical Review 62, 119–132.
Anisimov, A., G.Ch. Pﬂug (2000). Z-Theorems: limits of stochastic equations. Bernoulli 6(5), 124–135.
Attouch, H., R.J.B. Wets (1990). Laws of large numbers for random lsc functions. Seminaire Anal.
Convexe 20, Exp. 13, Universite´ de Montpellier.
Billingsley, P. (1968). Convergence of Probability Measures, Wiley, New York.
Blum, J.R. (1955). On the convergence of empirical distributions. Ann. Math. Statist. 26, 527–529.
Bonnans, F., A. Shapiro (1999). Perturbation Analysis of Optimization Problems, Springer-Verlag,
New York.
480
G.C. Pflug

Dehardt, J. (1971). Generalizations of the Glivenko–Cantelli Theorem. Ann. Math. Statist. 42,
2050–2055.
De la Pen˜ a, V.H., E. Gine´ (1999). Decoupling. From Dependence to Independence, Springer, New York.
Deuschel, J.D., D.W. Strook (1989). Large Deviations, Academic Press, Boston.
Devroye, L., G. Lugosi, (2001). Combinatorial Methods in Density Estimation, Springer Series in
Statistics, New York.
Dong, M., R.J.B. Wets (2000). Estimatind density functions: A constrained maximum likelihood
approach. Journal of Nonparametric Statistics 12(4), 549–595.
Doukhan, P., P. Massart, E. Rio (1994). The functional central limit theorem for strongly mixing
processes. Annales Institut Henri Poincare´ Probabilite´s et Statistiques 30(1), 63–82.
Doukhan, P., P. Massart, E. Rio (1995). Invariance principles for absolutely regular empirical
processes. Annales Institut Henri Poincare´ Probabilite´s et Statistiques 31(2), 393–427.
Dudley, R.M. (1982). A course on empirical processes. Lecture Notes in Mathematics, 1097, Springer,
New York, pp. 1–142.
Dudley, R.M. (1999). Uniform Central Limit Theorems, Cambridge University Press, Cambridge.
Dupacova, J., R.J.B. Wets (1988). Asymptotic behavior of statistical estimates and optimal solutions
of stochastic optimization problems. The Annals of Statistics 16, 1517–1549.
Etemadi,
N.
(1981).
An
elementary
proof
of
the
strong
law
of
large
numbers.
Z.
Wahrscheinlichkeitstheorie verw. Geb. 55(1), 119–122.
Gaivoronski, A., Yu. Ermoliev, C. Nedeva (1985). Stochastic optimization problems with incomplete
information on distribution functions. SIAM Journal on Control and Optimization 23(5), 697–716.
Geyer, Ch. (1994). On the asymptotics of constrained M-estimation. The Annals of Statistics 22, 1993–
2010.
Gine´ , E., J. Zinn (1984). Some limit theorems for empirical processes. The Annals of Probability 12,
929–989.
Gine´ , E., J. Zinn (1986). Lectures on the central limit theorem for empirical processes. Lecture Notes in
Mathematics, Vol. 1221, Springer, Berlin, pp. 50–113.
Hackenbroch, W., A. Thalmaier (1994). Stochastische Analysis, B.G. Teubner, Stuttgart.
Hall, P., C.C. Heyde (1980). Martingale Limit Theory and its Application, Academic Press, New York.
Kaniovski, Yu.M., A. King, R.J.-B. Wets (1993). Probabilistic bounds (via large deviations) for the
solutions of stochastic programming problems. Research Report Rc 18752, IBM Research Center,
Yorktown Heights.
King, A.J., R.T. Rockafellar (1993). Asymptotic theory for solutions in statistical estimation and
stochastic programming. Math. Oper. Research 18, 148–162.
Ledoux, M., M. Talagrand (1991). Probability in Banach Spaces, Springer, New York.
Louhichi, S. (2000). Weak convergence for empirical processes of associated sequences. Annales Institut
Henri Poincare´, Probabilite´s et Statistiques 36(5), 547–569.
Marton, K. (1996). Bounding d-distance by informational divergence: A method to prove measure
concentration. The Annals of Probability 24(2), 857–866.
Niederreiter, H.(1992). Random Number Generation and Quasi Monte Carlo Methods. CBMS-NSF
Regional Conference Series in Applied Mathematics 63, SIAM Philadelphia.
Ossiander, M. (1987). A central limit theorem under metric entropy with L2-bracketing. The Annals of
Probability 15, 897–919.
Pﬂug, G.Ch. (1992). Asymptotic dominance and conﬁdence for solutions of stochastic programs.
Czechoslovak Journal of OR 1(1), 21–30.
Pﬂug, G.Ch. (1995). Asymptotic stochastic programs. Mathematics of OR 20(4), 769–789.
Pﬂug, G.Ch. (1999). Stochastic programs and statistical data. Annals of OR 85, 59–78.
Pﬂug, G.Ch., A. Ruszczynski, R. Schultz (1998). On the Glivenko Cantelli problem in stochastic
programming: Linear recourse. Mathematics of OR 23(1), 204–220.
Pﬂug, G.Ch., A. Ruszczynski, R. Schultz (1998). On the Glivenko–Cantelli problem in stochastic
programming: Mixed integer linear recourse. Math. Methods of OR 47, 39–49.
Pollard, D. (1982). A central limit theorem for empirical processes. Journal of the Australian
Mathematical Society (Series A) 33, 235–248.
Ch. 7. Stochastic Optimization and Statistical Inference
481

Pollard, D. (1984). Convergence of Stochastic Processes, Springer, New York.
Rio, E. (1993). Covariance inequalities for strongly mixing processes. Annales Institut Henri Poincare´,
Probabilite´s et Statistiques 29, 587–597.
Rockafellar, T.R., R.J.B. Wets (1998). Variational Analysis. Grundlehren der Mathematischen
Wissenschaften, Vol. 317, Springer, Berlin.
Rockafellar T.R., S.P. Uryasev (1999). Optimization of conditional value-at-risk. The Journal of Risk
2(3), 2000, 21–41.
Ro¨ misch, W. (1986). On the convergence of measurable selections and applications to approximations
in stochastic optimization. Zeitschrift fu¨r Analysis und Anwendungen 5, 277–288.
Salinetti, G., R.J.B. Wets (1986). On the convergence in distribution of measurable multifunctions
(random sets), normal integrands, stochastic processes and stochastic inﬁma. Mathematics of OR
11, 385–419.
Shapiro, A. (1989). Asymptotic properties of statistical estimators in stochastic programming. The
Annals of Statistics 17(2), 841–858.
Shapiro, A. (1993). Asymptotic behavior of optimal solutions in stochastic programming. Mathematics
of Operations Research 18, 829–845.
Shapiro, A. (1994). Quantitative stability in stochastic programming. Mathematical Programming 67,
99–108.
Shapiro, A. (2000). Statistical inference of stochastic optimization problems, in: S.P. Urasev (ed.),
Probabilistic Constrained Optimization, Kluwer Academic Publishers, Norwell, USA, pp. 288–313.
Shapiro, A. (2000). On the asymptotics of constrained local M-estimators. The Annals of Statistics
28(3), 948–960.
Shiryaev, A.N. (1996). Probability, 2nd ed., Graduate Texts in Mathematics
95, Springer-Verlag,
New York.
Shorack, G.R., J.A. Wellner (1986). Empirical Processes with Applications to Statistics, Wiley,
New York.
Talagrand, M. (1987). The Glivenko–Cantelli problem. The Annals of Probability 15, 837–870.
Talagrand, M. (1994). Sharper bounds for Gaussian and empirical processes. The Annals of Probability
22, 28–76.
Talagrand, M. (1995). Concentration of measure and isoperimetric inequalities in product spaces.
Publ. IHES 81, 73–205.
Talagrand, M. (1996). The Glivenko–Cantelli problem, ten years later. Journal of Theoretical
Probability 9, 371–384.
Van der Vaart, A. (1994). Bracketing smooth functions. Stochastic Processes and their Applications 52,
93–105.
Van der Vaart, A.W., J.W. Wellner (1996). Weak Convergence and Empirical Processes, Springer,
New York.
Van der Vaart, A.W. (1998). Asymptotic Statistics, Cambridge University Press, Cambridge.
Vapnik, V.N., A.Y. Chervonenkis (1971). On the uniform convergence of relative frequences of events
to their probabilities. Theory of Probability and its Applications 16, 264–280.
Vapnik, V.N., A.Y. Chervonenkis (1981). Necessary and suﬃcient conditions for the uniform
convergence of means to their expectations. Theory of Probability and its Applications 24, 532–553.
Varadarajan, V.S. (1958). Weak convergence of measures in separable metric spaces. On the
convergence of sample probability distributions. Sankhya 19, 15–22 and 23–26.
Vogel, S. (1994). A stochastic approach to stability in stochastic programming. Journal of
Computational and Applied Mathematics 56, 65–96.
Wijsman, R.A. (1964). Convergence of sequences of convex sets, cones and functions. Bulletin of the
AMS 70, 186–188.
Yukich, J.E. (1986). Rates of convergence for classes of functions: the non-iid case. Journal of
Multivariate Analysis 20, 175–189.
482
G.C. Pflug

Chapter 8
Stability of Stochastic Programming Problems
Werner Ro¨misch
Institute of Mathematics, Humboldt-University Berlin, D-10099 Berlin, Germany,
E-mail: romisch@mathematik.hu-berlin.de
Abstract
The behaviour of stochastic programming problems is studied in case of the
underlying probability distribution being perturbed and approximated, respec-
tively. Most of the theoretical results provide continuity properties of optimal
values and solution sets relative to changes of the original probability distribu-
tion, varying in some space of probability measures equipped with some con-
vergence and metric, respectively. We start by discussing relevant notions of
convergence and distances for probability measures. Then we associate a
distance with a stochastic program in a natural way and derive (quantitative)
continuity properties of values and solutions by appealing to general perturba-
tion results for optimization problems. Later we show how these results relate to
stability with respect to weak convergence and how certain ideal probability
metrics may be associated with more speciﬁc stochastic programs. In particular,
we establish stability results for two-stage and chance constrained models.
Finally, we present some consequences for the asymptotics of empirical
approximations and for the construction of scenario-based approximations of
stochastic programs.
Key words:
Stochastic programming, stability, weak convergence, probability
metric, Fortet–Mourier metric, discrepancy, risk measure, two-stage, mixed-
integer, chance constrained, empirical approximation, scenario reduction.
1
Introduction
Stochastic programming is concerned with models for optimization problems
under stochastic uncertainty that require a decision on the basis of given
probabilistic information on random data. Typically, deterministic equiva-
lents of such models represent ﬁnite-dimensional nonlinear programs whose
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
483

objectives and/or constraints are given by multivariate integrals with respect
to the underlying probability measure. At the modelling stage these pro-
bability measures reﬂect the available knowledge on the randomness at hand.
This fact and the numerical challenges when evaluating the high-dimensional
integrals have drawn great attention to the stability analysis of stochastic
programs with respect to changes in the underlying probability measure. In
this chapter we present a uniﬁed framework for such a stability analysis by
regarding stochastic programs as optimization problems depending on the
probability measure varying in some space of measures endowed with some
distance. We give stability results both for general models and for more
speciﬁc stochastic programs like two-stage and chance constrained models and
include most of the proofs. Moreover, we discuss some conclusions about
speciﬁc approximation procedures for stochastic programs.
To specify the stochastic programming models for our analysis, we recall
that many deterministic equivalents of such models are of the form
min
Z

F0ðx, Þ dPðÞ: x 2 X,
Z

Fjðx, Þ dPðÞ  0, j ¼ 1, . . . , d
8
<
:
9
=
;,
ð1:1Þ
where the set X  Rm is closed,  is a closed subset of Rs, the functions Fj
from Rm   to the extended reals R are random lower semicontinuous
functions for j ¼ 0, . . . ,d, and P is a Borel probability measure on .
The set X is used to describe all constraints not depending on P, and the set
 contains the supports of the relevant measures and provides some ﬂexibility
for formulating the models and the corresponding assumptions. We recall that
Fj is a random lower semicontinuous function if its epigraphical mapping
  epi Fjð, Þ :¼ fðx, rÞ 2 Rm  R: Fjðx, Þ  rg is closed-valued and measur-
able, which implies, in particular, that Fjð, Þ is lower semicontinuous for each
 2  and Fjðx,Þ is measurable for each x 2 Rm.
Although, our stability analysis mainly concerns model (1.1) and its
speciﬁcations, we also provide an approach to the stability of more general
models that contain risk functionals and are of the form
min F0 P½F0ðx, Þ1


: x 2 X, FjðP½Fjðx, Þ1Þ  0, j ¼ 1, . . . , d


,
ð1:2Þ
where the risk functionals Fj, j ¼ 0, . . . , d,, map from suitable subsets of the
set PðRÞ of all probability measures on R to R. In general, the functionals
Fj depend on a measure in PðRÞ in a more involved way than the expecta-
tion functional FeðGÞ :¼
R
R r dGðrÞ, for which we have FeðP½F0ðx, Þ1Þ ¼
R
R r dP½F0ðx, Þ1ðrÞ ¼
R
 F0ðx, Þ dPðÞ. Another example is the variance
484
W. Ro¨misch

functional FvðGÞ :¼
R
R r2 dGðrÞ  ð
R
R r dGðrÞÞ2. We also refer to the value-at-
risk functional in Example 1 and to the examples in Section 2.4.
We illustrate the abstract models by the classical newsboy example (see e.g.,
Dupacˇ ova´ (1994), Example 1 in Ruszczyn´ ski and Shapiro (2003)).
Example 1. (newsboy problem) A newsboy must place a daily order for a
number x of copies of a newspaper. He has to pay r dollars for each copy and
sells a copy at c dollars, where 0 < r < c. The daily demand  is random with
(discrete) probability distribution P 2 PðNÞ and the remaining
copies
yðÞ ¼ maxf0, x  g have to be removed. The newsboy might wish that the
decision x maximizes his expected proﬁt or, equivalently, minimizes his
expected costs, i.e.,
Z
R
F0ðx, Þ dPðÞ :¼
Z
R
½ðr  cÞx þ cmaxf0, x  g dPðÞ
¼ ðr  cÞx þ c
X
k2N
kmax 0, x  k
f
g
¼ rx  cx
X
k2N
kx
k  c
X
k2N
k<x
kk
where k is the probability of demand k 2 N. The unique integer solution is
the maximal k 2 N such that P1
i¼k i  r
c. Another possibility is that the
newsboy wishes to maximize his proﬁt and, at the same time, to minimize his
risk costs cs where s bounds the number y() of copies that remain with
probability p. The minimal s corresponds to his value-at-risk at level p. The
resulting stochastic program reads
min
x2Rþ ðr  cÞx þ c inf fs 2 Rþ : PðyðÞ  sÞ  pg


:
The latter program is equivalent to the chance constrained model
min
ðx,sÞ2R2
þ
ðr  cÞx þ cs:
X
k2N
xsk
k  p
8
<
:
9
=
;
ð1:3Þ
whose unique integral solution is ðk,0Þ with the maximal k 2 N such that
P1
i¼k i  p. Hence, the minimum risk solution is more pessimistic than the
minimal expected cost solution if r
c < p < 1, i.e., if the newsboy wants to be
sure with high probability that no copies of the newspaper remain.
Ch. 8. Stability of Stochastic Programming Problems
485

However, the inherent diﬃculty of all these approaches is that the newsboy
does not know the probability distribution P of the demand and has to use
some approximation instead. Hence, he is interested in the stability of his
decision which means that it does not vary too much for small perturbations
of the data. For instance, his decision might be based on n independent
identically distributed observations i, i ¼ 1, . . . , n, of the demand, i.e., on
approximating P by the empirical measure Pn (cf. Section 4.1) and, in case of
minimal expected costs, on solving the approximate problem
min
x2Rþ ðr  cÞx þ c
n
X
n
i¼1
maxf0, x  ig
(
)
:
ð1:4Þ
Of course, this approach is only justiﬁed if some optimal solution xn of the
approximate problem (1.4) is close to some original solution for suﬃciently
large n. Both variants of the newsboy problem represent speciﬁc two-stage and
chance constrained stochastic programs, respectively. Their discussion will be
continued in the Examples 15, 19 and 54.
Throughout we will denote the set of all Borel probability measures on 
by PðÞ, the feasible set of (1.1) by X(P), the optimal value by #(P) and the
("-approximate) solution set of (1.1) by X*" ðPÞ and X*ðPÞ, respectively, i.e.,
XðPÞ :¼
x 2 X :
Z

Fjðx, Þ dPðÞ  0, j ¼ 1, . . . , d
8
<
:
9
=
;,
ð1:5Þ
#ðPÞ :¼ inf
Z

F0ðx, Þ dPðÞ: x 2 XðPÞ
8
<
:
9
=
;,
ð1:6Þ
X*" ðPÞ :¼
x 2 XðPÞ:
Z

F0ðx, Þ dPðÞ  #ðPÞ þ "
8
<
:
9
=
;
ð"  0Þ,
ð1:7Þ
X*ðPÞ :¼ X*0 ðPÞ ¼
x 2 XðPÞ:
Z

F0ðx, Þ dPðÞ ¼ #ðPÞ
8
<
:
9
=
;:
ð1:8Þ
In this chapter, stability mostly refers to continuity properties of the
optimal value function #(  ) and the ("-approximate) solution-set mapping
X*" ðÞ at P, where both #(  ) and X*" ðÞ are regarded as mappings given on a set
of probability measures endowed with a suitable distance. The distance has to
be selected such that it allows to estimate diﬀerences of objective and
constraint function values, and, that it is optimum adapted to the model at hand.
486
W. Ro¨misch

Fortunately, there exists a diversity of convergence notions and metrics in
probability theory and statistics that address diﬀerent goals and are based on
various constructions (see, e.g., Rachev (1991) and van der Vaart (1998)). We
will use so-called distances with -structure that are given as uniform distances
of expectations of functions taken from a class F of measurable functions
from  to R, i.e.,
dFðP,QÞ ¼ sup
F2F

Z

FðÞ dPðÞ 
Z

FðÞ dQðÞ
:
ð1:9Þ
In a ﬁrst step we choose the class F as the set fFjðx,Þ: x 2 X \ cl U, j ¼
0, . . . ,dg, where U is a properly chosen open subset of Rm, and derive some
(qualitative and quantitative) stability results in the Sections 2.2 and 2.3. Such
a distance forms a kind of minimal information (m.i.) metric for the stability of
(1.1). Some of the corresponding results (e.g., the Theorems 5 and 9) work
under quite weak assumptions on the underlying data of (1.1). In particular, if
possible diﬀerentiability or even continuity assumptions on the functions
x 
R
 Fjðx,Þ dPðÞ are avoided for the sake of generality. The approach is
inspired by general perturbation results for optimization problems in Klatte
(1987, 1994); Attouch and Wets (1993) and in the monographs by Bank et al.
(1982) and Rockafellar and Wets (1998) and Bonnans and Shapiro (2000).
Since the m.i. metrics are often rather involved and diﬃcult to handle, we
look, on the one hand, for implications of the general qualitative result on
stability with respect to the topology of weak convergence. On the other hand,
we look for another metric having -structure by enlarging the class F and,
hence, bounding the m.i. metric from above. Our strategy for controlling this
enlargement procedure consists in adding functions to the enlarged class that
share the essential analytical properties with some of the functions Fj(x,  ). As
a result of this process we obtain ideal metrics that are optimum adjusted to
the model (1.1) or to a whole class of models and that enjoy pleasant pro-
perties (e.g., a duality and convergence theory). In Section 3, we show for
three types of stochastic programs how such ideal metrics come to light in a
natural way by revealing the analytical properties of the relevant functions
Fj(x,  ). At the same time, we obtain quantitative stability results for all models.
For two-stage models containing integer variables and for chance con-
strained models, the relevant functions are discontinuous and their ideal classes
contain products of (locally) Lipschitzian functions and of characteristic
functions of sets describing regions of continuity (see Sections 3.2 and 3.3).
When using stability results for designing or analyzing approximation
schemes or estimation procedures, further properties of the function classes F
and of the metrics may become important. For example, we derive covering
numbers of certain function classes and discuss their implications on
probabilistic bounds for empirical optimal values and solution sets.
The chapter is organized as follows. First Section 2 contains some
prerequisites on convergences and metric distances of probability measures.
Ch. 8. Stability of Stochastic Programming Problems
487

This is followed by our main qualitative stability result (Theorem 5) and its
conclusions on the stability with respect to weak convergence of probability
measures. We continue with the quantitative stability results for solution sets
of (1.1) (Theorems 9 and 12) and a Lipschitz continuity result (Theorem 13)
for "-approximate solution sets of convex models. We add a discussion of how
to associate ideal metrics with more speciﬁc stochastic programs. Section 2 is
ﬁnished by discussing the challenges and by presenting ﬁrst results of a
perturbation analysis for stochastic programs containing risk functionals
(1.2). In Section 3 we consider linear two-stage, mixed-integer two-stage and
linear chance constrained stochastic programs and present various perturba-
tion results for such models. The potential of our general perturbation
analysis is explained in Section 4 for two types of approximations of the
underlying probability measure P. First, we consider empirical measures as
nonparametric estimators of P and derive asymptotic statistical properties of
values and solutions by using empirical process theory. Secondly, we discuss
the optimal construction of ﬁnitely discrete measures based on probability
metrics and sketch some results and heuristic algorithms for the optimal
reduction of discrete measures. We conclude the chapter with some
bibliographical notes on the relevant literature.
2
General stability results
2.1
Convergences and metrics of probability measures
Let us consider the set PðÞ of all Borel probability measures with support
contained in a closed subset  of Rs. We will endow the set PðÞ or some of its
subsets with diﬀerent convergences and distances, which are adapted to the
underlying stochastic program or to a whole class of stochastic programs. The
classical convergence concept in probability theory is the weak convergence of
measures in PðÞ (see e.g., Billingsley (1968) and Dudley (1989)). A sequence
(Pn) in PðÞ is said to converge weakly to P 2 PðÞ, shortly Pn!
w P, if
lim
n!1
Z

gðÞ dPnðÞ ¼
Z

gðÞ dPðÞ
ð2:10Þ
holds for each g in the space CbðÞ of bounded continuous functions from 
to R. It is well known that the topology w of weak convergence is metrizable
(e.g., by the bounded Lipschitz metric (2.11)) and that Pn!
w P holds iﬀthe
sequence of probability distribution functions of Pn converges pointwise to the
distribution function FP of P at all continuity points of FP. Another important
property of weak convergence is the continuous mapping theorem: If Pn!
w P
and g:  ! R is measurable, bounded and P-continuous, i.e., Pðf 2 : g is
not continuous at gÞ ¼ 0, we have (2.10).
488
W. Ro¨misch

Most of the distances on (subsets of) PðÞ that will be considered are of the
form dF in (1.9), where F is a class of measurable functions from  to R, and
are deﬁned on the set PF :¼ fQ 2 PðÞ: supF2Fj
R
 FðÞ dQðÞj < 1jg, where
dF is ﬁnite. A uniform distance of the form (1.9) is called a distance having
-structure (see Zolotarev (1983) and Rachev (1991)). Clearly, dF does not
change if the set F is replaced by its convex hull. It is nonnegative, symmetric
and satisﬁes the triangle inequality, i.e., a pseudometric on PF. dF is a metric if
the class F is rich enough to preserve that dF (P, Q) ¼ 0 implies P ¼ Q. Next we
list some important examples of distances having -structure, where the classes
F range from (locally) Lipschitz continuous functions to piecewise constant
functions with a prescribed structure of discontinuity sets.
Example 2. (metrics with -structure)
(a) For p ¼ 0 and p  1 we introduce classes F pðÞ of locally Lipschitz
continuous functions that increase with p
F pðÞ :¼
F :   R:
FðÞ  Fð ~Þ
  cpð, ~Þk  ~k,8, ~ 2 
n
o
,
F 0ðÞ :¼ F 1ðÞ \
F 2 CbðÞ: sup
2
FðÞ
  1
(
)
:
Here,
k  k
denotes
some
norm
on
Rs
and
cpð, ~Þ :¼ maxf1,kk,k ~kg
p1 for all , ~ 2  and p  1 describes the
growth of the local Lipschitz constants. The corresponding distance
with -structure for p ¼ 0 is the bounded Lipschitz metric (Section 11.3
of Dudley (1989))
ðP, QÞ :¼
sup
F2F 0ðÞ

Z

FðÞ dPðÞ 
Z

FðÞ dQðÞ

ð2:11Þ
and metrizes the weak convergence on PðÞ. For p ¼ 1 we arrive at the
Kantorovich metric
1ðP, QÞ :¼
sup
F2F 1ðÞ

Z

FðÞ dPðÞ 
Z

FðÞ dQðÞ

ð2:12Þ
and for p  1 at the p-th order Fortet–Mourier metrics (see Fortet and
Mourier (1953) and Rachev (1991))
pðP, QÞ :¼
sup
F2F pðÞ

Z

FðÞ dPðÞ 
Z

FðÞ dQðÞ

ð2:13Þ
Ch. 8. Stability of Stochastic Programming Problems
489

on
the
set
PpðÞ :¼ fQ 2 PðÞ
R
 kkp dQðÞ < 1g
of
probability
measures having ﬁnite p-th order absolute moments. It is known that
a sequence ðPnÞ converges to P in ðPpðÞ,pÞ iﬀit converges weakly and
lim
n!1
Z

kkp dPnðÞ ¼
Z

kkp dPðÞ
holds. Furthermore, the estimate

Z

kkp dPðÞ 
Z

kkp dQðÞ
  ppðP, QÞ
is valid for each p  1 and all P,Q 2 PpðÞ (Section 6 in Rachev
(1991)). Hence, closeness with respect to p implies the closeness of q-th
order absolute moments for q 2 ½1, p.
(b) Let B denote a set of Borel subsets of  and consider the class
F B :¼ fB : B 2 Bg of their characteristic functions B taking the value
1 if the argument belongs to B and 0 otherwise. The distance with
-structure generated by FB is deﬁned on PðÞ. It takes the form
BðP, QÞ :¼ dF BðP,QÞ ¼ sup
B2B
jPðBÞ  QðBÞj
and is called B-discrepancy. The following instances play a special role
in the context of stability in stochastic programming:
(b1) Let  be convex and BcðÞ the set of all closed convex subsets of .
(b2) Let  be polyhedral and BphkðÞ the set of all polyhedra being
subsets of  and having at most k faces.
(b3) Let  ¼ Rs and BhðÞ be the set of all closed half-spaces in Rs.
(b4) Let  ¼ Rs and BKðÞ :¼ fð1,:  2 Rsg be the set of all cells.
The
corresponding
distances
are
the
isotrope
discrepancy
c, the polyhedral discrepancy phk, the half-space discrepancy h and
the Kolmogorov metric. The latter metric coincides with the uniform
distance of distribution functions on Rs and is denoted by dK, i.e.,
dKðP, QÞ ¼ BKðP, QÞ ¼ sup
2RsjPðð1, Þ  Qðð1, Þj:
A sequence ðPnÞ converges to P in PðÞ with respect to B, where B
is a class of closed convex subsets of , iﬀðPnÞ converges weakly to P
490
W. Ro¨misch

and Pðbd BÞ ¼ 0 holds for each B 2 B (with bd B denoting the
boundary of the set B).
The examples reveal some relations between the weak convergence of
probability measures and their convergence with respect to a uniform metric
dF for some classes F. Such relations have already been explored more
systematically in the literature. A class F of measurable functions from  to R
is called a P-uniformity class if
lim
n!1dFðPn,PÞ ¼ 0
ð2:14Þ
holds for each sequence ðPnÞ that converges weakly to P. Necessary conditions
for F to be a P-uniformity class are that F is uniformly bounded and that
every function in F is P-continuous. Suﬃcient conditions are given in
Billingsley and Topsøe (1967), Topsøe (1967, 1977) and Lucchetti et al. (1994).
For example, F is a P-uniformity class if it is uniformly bounded and it
holds
that
Pðf 2 : F is not equicontinuous at gÞ ¼ 0
(Topsøe
(1967)).
Unless F is uniformly bounded, condition (2.14) cannot be valid for any
sequence (Pn) that converges weakly to P. In that case, a uniform integra-
bility condition with respect to the set fPn : n 2 Ng has to be additionally
imposed on F. The set F is called uniformly integrable with respect to
fPn : n 2 Ng if
lim
R!1sup
n2N
sup
F2F
Z
FðÞ>R
jFðÞjdPnðÞ ¼ 0:
ð2:15Þ
Note that condition (2.15) is satisﬁed if the moment condition
sup
n2N
sup
F2F
Z

jFðÞj1þ"dPnðÞ < 1
ð2:16Þ
holds for some " > 0 (Section 5 in Billingsley (1968)). Then the condition
(2.14) is valid for any sequence ðPnÞ that converges weakly to P in PF and has
the property that F is uniformly integrable with respect to fPn : n 2 Ng if the
set F R :¼ f½FRðÞ :¼ maxfR, minfFðÞ, Rgg: F 2 Fg of truncated functions
of F is a P-uniformity class for large R > 0. Since the class FR is uniformly
bounded, it is a P-uniformity class if Pðf 2 : F R is not equicontinuous
at gÞ ¼ 0. Suﬃcient conditions for classes of characteristic functions of
convex sets to be P-uniformity classes are mentioned in Example 2(b).
Ch. 8. Stability of Stochastic Programming Problems
491

2.2
Qualitative stability
Together with the original stochastic programming problem (1.1) we
consider a perturbation Q 2 PðÞ of the probability distribution P and the
perturbed model
min
Z

F0 x, 
ð
Þ dQ ð Þ: x 2 X,
Z

Fj x, 
ð
Þ dQ ð Þ  0, j ¼ 1, . . . , d
8
<
:
9
=
;
ð2:17Þ
under the general assumptions imposed in Section 1. To ﬁx our setting, let k  k
denote the Euclidean norm and ,
h
i the corresponding inner product. By B we
denote the Euclidean unit ball and by dðx, DÞ the distance of x 2 Rm to the set
D  Rm. For any nonempty and open subset U of Rm we consider the follow-
ing sets of functions, elements and probability measures
F U :¼ Fjðx,Þ: x 2 X \ cl U, j ¼ 0, . . . , d

,
XUðQÞ :¼ x2X\ cl U :
Z

Fjðx,Þ dQðÞ0, j ¼ 1, . . . , d
8
<
:
9
=
; ðQ2PF UðÞÞ,
PF UðÞ :¼fQ2PðÞ:1<
Z

inf
x2X\ rBFj x,
ð
Þ dQðÞ
for each r>0 and
sup
x2X\ cl U
Z

Fjðx,Þ dQðÞ < 1
for each j ¼ 0, . . . , dg,
and the pseudometric on PF U :¼ PF UðÞ
dF UðP,QÞ:¼ sup
F2F U

Z

FðÞðPQÞðdÞ
¼sup
j¼0,...,d
x2X\ cl U

Z

Fjðx,ÞðPQÞðdÞ
:
Thus, dF U is a distance of probability measures having -structure. It
is nonnegative, symmetric and satisﬁes the triangle inequality (see also
Section 2.1). Our general assumptions and the Fatou Lemma imply that the
objective function and the constraint set of (2.17) are lower semicontinuous on
X and closed in Rm, respectively, for each Q 2 PF UðÞ. Our ﬁrst results
provide further basic properties of the model (2.17).
492
W. Ro¨misch

Proposition 3. Let U be a nonempty open subset of Rm. Then the mapping
ðx, QÞ  R
 Fjðx, Þ dQðÞ from ðX \ cl UÞ  ðPF U,dF UÞ to R is sequentially
lower semicontinuous for each j ¼ 0, . . . , d.
Proof. Let j ¼ 0, . . . , d, x 2 X \ cl U, Q 2 PF U, ðxnÞ be a sequence in X \ cl U
such that xn ! x, and ðQnÞ be a sequence converging to Q in ðPF U,dF UÞ. Then
the lower semicontinuity of Fjð,Þ for each  2  and the Fatou Lemma imply
the estimate
Z

Fj x,
ð
Þ dQ ð Þ  lim inf
n!1
Z

Fj xn,
ð
Þ dQ ð Þ
 lim inf
n!1
dF UðQ, QnÞ þ
Z

Fjðxn, ÞQnðdÞ
8
<
:
9
=
;
¼ lim inf
n!1
Z

Fjðxn, ÞQnðdÞ:
u
Proposition 4. Let U be a nonempty open subset of Rm. Then the graph of the
set-valued mapping Q  XUðQÞ from ðPF U,dF UÞ into Rm is sequentially closed.
Proof. Let ðQnÞ be a sequence converging to Q in ðPF U,dF UÞ and ðxnÞ be a
sequence converging to x in Rm and such that xn 2 XUðQnÞ for each n 2 N.
Clearly, we have x 2 X \ cl U. For j 2 f1, . . . , dg we obtain from Proposition 3
that the estimate
Z

Fj x, 
ð
Þ dQ ð Þ  lim inf
n!1
Z

Fj xn, 
ð
ÞQn d
ð
Þ  0:
and, thus, x 2 XUðQÞ holds.
u
To obtain perturbation results for (1.1), a stability property of the
constraint set X(P) when perturbing the probabilistic constraints is needed.
Consistently with the general deﬁnition of metric regularity for multifunctions
(see, e.g., Rockafellar and Wets (1998)), we consider the set-valued mapping
y  XyðPÞ from Rd to Rm, where
XyðPÞ ¼
x 2 X :
Z

Fjðx, Þ dPðÞ  yj, j ¼ 1, . . . ,d
8
<
:
9
=
;,
and say that its inverse x  X1
x ðPÞ ¼ fy 2 Rd : x 2 XyðPÞg from Rm to Rd is
metrically regular at some pair ðx,0Þ 2 Rm  Rd with x 2 XðPÞ ¼ X0ðPÞ if
Ch. 8. Stability of Stochastic Programming Problems
493

there are constants a  0 and " > 0 such that it holds for all x 2 X and y 2 Rd
with kx  xk  " and max
j¼1,...,djyjj  " that
dðx, XyðPÞÞ  a max
j¼1,...,dmax 0,
Z

Fjðx, Þ dPðÞ  yj
8
<
:
9
=
;:
To state our results we will need localized versions of optimal values and
solution sets. We follow the concept proposed in Robinson (1987) and Klatte
(1987), and set for any nonempty open set U  Rm and any Q 2 PF U
#UðQÞ ¼ inf
Z

F0ðx, Þ dQðÞ: x 2 XUðQÞ
8
<
:
9
=
;,
X*UðQÞ ¼
x 2 XUðQÞ:
Z

F0 x, 
ð
Þ dQ ð Þ ¼ #UðQÞ
8
<
:
9
=
;:
A nonempty set S  Rm is called a complete local minimizing (CLM ) set of
(2.17) relative to U if U  Rm is open and S ¼ X*UðQÞ  U. Clearly, CLM sets
are sets of local minimizers, and the set X*ðQÞ of global minimizers is a CLM
set with X*ðQÞ ¼ X*UðQÞ if X*ðQÞ  U.
Now, we are ready to state the main qualitative stability result.
Theorem 5. Let P 2 PF U and assume that
(i) X*ðPÞ is nonempty and U  Rm is an open bounded neighbourhood of
X*ðPÞ,
(ii) if d  1, the function x 
R
 F0ðx, Þ dPðÞ is Lipschitz continuous on
X \ cl U,
(iii) the mapping x  X1
x ðPÞ is metrically regular at each pair ðx, 0Þ with
x 2 X*ðPÞ.
Then the multifunction X*U from ðPF U, dF UÞ to Rm is upper semicontinuous at
P, i.e., for any open set O 	 X*UðPÞ it holds that X*UðQÞ  O if dF UðP,QÞ is
suﬃciently small. Furthermore, there are positive constants L and  such that
j#ðPÞ  #UðQÞj  LdF UðP,QÞ
ð2:18Þ
holds and X*UðQÞ is a CLM set of (2.17) relative to U whenever Q 2 PF U and
dF UðP,QÞ < . In case d ¼ 0, the estimate (2.18) is valid with L ¼ 1 and for any
Q 2 PF U.
494
W. Ro¨misch

Proof. We consider the (localized) parametric optimization problem
min f ðx,QÞ ¼
Z

F0 x,
ð
Þ dQðÞ: x 2 XUðQÞ
8
<
:
9
=
;,
where the probability measure Q is regarded as a parameter varying in the
pseudometric space ðPF U,dF UÞ. Proposition 4 says that the graph of the
multifunction XU from PF U to Rm is sequentially closed. Hence, XU is upper
semicontinuous on PF U, since cl U is compact. Furthermore, we know by
Proposition 3 that the function f from ðX \ cl UÞ  PF U to R is sequentially
lower semicontinuous and ﬁnite. Let us ﬁrst consider the case of d ¼ 0. Since
f ð, QÞ is lower semicontinuous, X*UðQÞ is nonempty for each Q 2 PF U. Let
x* 2 X*ðPÞ, Q 2 PF U and ~x 2 X*UðQÞ. Then the estimate
j#ðPÞ  #UðQÞj  max
Z

F0 x*, 
ð
Þ Q  P
ð
ÞðdÞ,
Z

F0ð ~x, ÞðP  QÞðdÞ
8
<
:
9
=
;
 dF UðP,QÞ
holds. This implies that the multifunction X*U from ðPF U,dF UÞ to Rm is closed
at P and, thus, upper semicontinuous at P.
In case d  1, condition (ii) implies that the function f is even continuous
on ðX \ cl UÞ  PF U. Then we use Berge’s classical stability analysis (see Berge
(1963) for topological parameter spaces and Theorem 4.2.1 in Bank et al.
(1982) for metric parameter spaces) and conclude that X*U is upper semicon-
tinuous at P if XU satisﬁes the following (lower semicontinuity) property at
some pair ðx, PÞ with x 2 X*ðPÞ:
XUðPÞ \ Bðx, "Þ  XUðQÞ þ a dF UðP, QÞB whenever dF UðP, QÞ < ",
ð2:19Þ
where a  0 is the corresponding constant in condition (iii), and " > 0 is suf-
ﬁciently small. To establish property (2.19), let x 2 X*ðPÞ, and a ¼ aðxÞ  0,
" ¼ "ðxÞ > 0 be the metric regularity constants from (iii). First we observe
that
the
estimate
R
 Fjðx, ÞðQ  PÞðdÞ  dF UðP, QÞ
holds
for
any
x 2 X \ cl U, j 2 f1, . . . ,dg and Q 2 PF U. Next we choose " ¼ "ðxÞ such that
0 < " < " and x þ ða þ 1Þ" B  U. Hence, we have x þ a" B  U for any
x 2 x þ " B. Let Q 2 PF U be such that dF UðP,QÞ < ". Putting yj ¼ dF UðP,QÞ,
j ¼ 1, . . . ,d,
the
above
estimate
implies
that
XyðPÞ \ cl U  XUðQÞ.
Due to the choice of " we have dðx,XyðPÞ \ cl UÞ ¼ dðx,XyðPÞÞ for any
Ch. 8. Stability of Stochastic Programming Problems
495

x 2 XUðPÞ \ ðx þ " BÞ, and, hence, the metric regularity condition (iii) yields
the estimate
dðx, XUðQÞÞ  dðx, XyðPÞ \ cl UÞ ¼ dðx, XyðPÞÞ
 a max
j¼1,...,d max 0,
Z

Fjðx, Þ dPðÞ þ dF UðP, QÞ
8
<
:
9
=
;
 a dF UðP, QÞ,
which is equivalent to the property (2.19). Hence, X*U is upper semicontinuous
at P and there exists a constant ^ > 0 such that X*UðQÞ  U for any Q 2 PF U
with dF UðP,QÞ < ^. Thus X*UðQÞ is a CLM set of (2.17) relative to U for
each such Q.
Moreover, for any x 2 XUðQÞ \ ðx þ "BÞ (iii) implies the estimate
dðx,XUðPÞÞ ¼ dðx,X0ðPÞ \ cl UÞ ¼ dðx, X0ðPÞÞ
 a max
j¼1,...,dmax 0,
Z

Fjðx, Þ dPðÞ
8
<
:
9
=
;
 a max
j¼1,...,dmax 0,
Z

Fjðx, Þ dPðÞ 
Z

Fjðx, Þ dQðÞ
8
<
:
9
=
;
 a dF UðP,QÞ ,
which is equivalent to the inclusion
XUðQÞ \ ðx þ " BÞ  XUðPÞ þ a dF UðP,QÞB:
Since X*(P) is compact, we employ a ﬁnite covering argument and
arrive at two analogues of both inclusions, where a neighbourhood
N of X*(P) appears instead of the balls x þ " B in their left-hand sides, and
a uniform constant ^a appears instead of a in their right-hand sides. Moreover,
there exists a uniform constant ^" > 0 such that the (new) inclusions are valid
whenever dF UðP, QÞ < ^". Now, we choose  > 0 such that   minf ^,^"g and
X*UðQÞ  N whenever dF UðP, QÞ < .
496
W. Ro¨misch

Let Q 2 PF U be such that dF UðP,QÞ <  and ~x 2 X*UðQÞ  XUðQÞ \ N . Then
there exists an element x 2 XUðPÞ satisfying k ~x  xk  ^a dF UðP,QÞ. We obtain
#ðPÞ  f ðx,PÞ  f ð ~x,QÞ þ j f ðx,PÞ  f ð ~x,QÞj
 #UðQÞ þ j f ðx,PÞ  f ð ~x,PÞj þ j f ð ~x,PÞ  f ð ~x,QÞj
 #UðQÞ þ Lf kx  ~xk þ dF UðP,QÞ
 #UðQÞ þ ðLf ^a þ 1ÞdF UðP,QÞ ,
where Lf  0 denotes a Lipschitz constant of f ð, PÞ on X \ cl U. For the
converse estimate, let x 2 X*ðPÞ and Q 2 PF U be such that dF UðP, QÞ < .
Then there exists ~x 2 XUðQÞ such that k ~x  xk  ^a dF UðP, QÞ. We conclude
#UðQÞ  f ð ~x, QÞ  #ðPÞ þ j f ð ~x, QÞ  f ðx,PÞj
and arrive analogously at the desired continuity property of #U by putting
L ¼ Lf ^a þ 1.
u
The above proof partly parallels arguments in Klatte (1987). The most
restrictive requirement in the above result is the metric regularity condition
(iii). Example 40 in Section 3.3 provides some insight into the necessity of
condition (iii) in the context of chance constrained models. Criteria for the
metric regularity of multifunctions are given e.g., in Section 9G of Rockafellar
and Wets (1998) and in Mordukhovich (1994b). Here, we do not intend to
provide a speciﬁc suﬃcient condition for (iii), but recall that the constraint
functions
R
 Fjð, Þ dPðÞ ( j ¼ 1, . . . ,d) are often nondiﬀerentiable or even
discontinuous in stochastic programming. In Section 3.3 we show how metric
regularity is veriﬁed in case of chance constrained programs.
Although, Theorem 5 also asserts a quantitative continuity property for
optimal values, its essence consists in a continuity result for optimal values
and solution sets. As a ﬁrst conclusion we derive consequences for the stability
of (1.1) with respect to the weak convergence of probability measures (cf.
Section 2.1). To state our main stability result for (1.1) with respect to the
topology of weak convergence, we need the classes F R
U of truncated functions
of FU for R > 0 and the uniform integrability property of FU (see Section 2.1).
Theorem 6. Let the assumptions of Theorem 5 for (1.1) be satisﬁed. Further-
more, let F R
U be a P-uniformity class for large R > 0 and ðPnÞ be a sequence in
PF U that is weakly convergent to P.
Then the sequence ð#UðPnÞÞ converges to #ðPÞ, the sets X*UðPnÞ are CLM sets
relative to U for suﬃciently large n 2 N and
lim
n!1 sup
x2X*UðPnÞ
dðx, X*ðPÞÞÞ ¼ 0
holds if FU is uniformly integrable with respect to fPn : n 2 Ng.
Ch. 8. Stability of Stochastic Programming Problems
497

Proof. Let ðPnÞ be a sequence in PF Uthat converges weakly to P and has the
property that FU is uniformly integrable with respect to fPn : n 2 Ng. Then the
assumption implies (see Section 2.1)
lim
n!1dF UðPn,PÞ ¼ 0
and, hence, the result is an immediate consequence of Theorem 5.
u
Compared to Theorem 5, the stability of (1.1) with respect to weakly
convergent perturbations of P requires additional conditions on FU . The
previous theorem provides the suﬃcient conditions that its truncated class F R
U
has the P-uniformity property for large R > 0 and that FU is uniformly
integrable with respect to the set of perturbations. The ﬁrst condition is
satisﬁed if F R
U is P-almost surely equicontinuous on  (cf. Section 2.1). It
implies, in particular, the P-continuity of Fjðx,Þ for each j ¼ 0, . . . , d and
x 2 X \ cl U. The uniform integrability condition
lim
R!1sup
n2N
max
j¼0,...,d
sup
x2X\ cl U
Z
jFjðx,Þj>R
jFjðx, ÞjdPnðÞ ¼ 0
ð2:20Þ
is satisﬁed if the moment condition
sup
n2N
max
j¼0,...,d
sup
x2X\ cl U
Z

jFjðx, Þj1þ"dPnðÞ < 1
ð2:21Þ
holds for some " > 0. Assume, for example, that the functions Fj satisfy an
estimate of the form
jFjðx, Þj  Ckkk,
8ðx, Þ 2 ðX \ cl UÞ  ,
for some positive constants C, k and all j ¼ 0, . . . , d (see e.g., Sections 3.1 and
3.2). In this case, the uniform integrability condition (2.20) is satisﬁed if
lim
R!1sup
n2N
Z
kk>R
kkkdPnðÞ ¼ 0:
The corresponding suﬃcient moment condition reads
sup
n2N
Z

kkkþ"dPnðÞ < 1
498
W. Ro¨misch

for some " > 0. The latter condition is often imposed in stability studies with
respect to weak convergence.
The P-continuity property of each function Fjðx,Þ and condition (2.20) are
not needed in Theorem 5. However, the following examples show that both
conditions are indispensable for stability with respect to weak convergence.
Example 7. Let m ¼ s ¼ 1, d ¼ 0,  ¼ R, X ¼ R, F0ðx,Þ ¼ ð1,xðÞ for
ðx,Þ 2 R   and P ¼ 0, where  denotes the measure that places unit mass
at . Then #ðPÞ ¼ 1 and X*ðPÞ ¼ f0g. The sequence ð1
nÞ converges weakly to P
in PðÞ, but it holds that #ðPnÞ ¼ 0 for each n 2 N. This is due to the fact that,
for some neighbourhood U of 0, the set fð1,xðÞ: x 2 X \ cl Ug is not a
P-uniformity class since Pðbd ð1,0Þ ¼ Pðf0gÞ ¼ 1.
Example 8. Let m ¼ s ¼ 1, d ¼ 0,  ¼ Rþ, X ¼ ½1,1, F0ðx,Þ ¼ maxf
x,0g for ðx,Þ 2 R   and P ¼ 0. Then #ðPÞ ¼ 0 and X*ðPÞ ¼ ½0,1. Consider
the sequence Pn ¼ ð1  1
nÞ0 þ 1
n n, n 2 N, which converges weakly to P. It
holds that #ðPnÞ ¼ 1  1
n and X*ðPnÞ ¼ f1g for each n 2 N and, thus, ð#ðPnÞÞ
does not converge to #ðPÞ. Here, the reason is that the class fmaxf  x, 0g:
x 2 ½1, 1g is not uniformly integrable with respect to fPn : n 2 Ng.
Indeed, the weak convergence of measures is a very weak condition on
sequences and, hence, requires strong conditions on (1.1) to be stable. Many
approximations of P (e.g., in Section 4.1), however, have much stronger
properties than weak convergence and, hence, work under weaker assump-
tions than Theorem 6. To give an example, we recall that the P-continuity
property of each function Fjðx, Þ is an indispensable assumption in case of
stability with respect to weak convergence, but this property is not needed
when working with dF U and with speciﬁcally adjusted ideal metrics (and the
corresponding convergences of measures) in case of (mixed-integer) two-stage
and chance constrained models (see Sections 3.1, 3.2 and 3.3). Consequently,
we prefer to work with these distances, having in mind their relations to the
topology of weak convergence.
2.3
Quantitative stability
The main result in the previous section claims that the multifunction X*UðÞ
is nonempty near P and upper semicontinuous at P. In order to quantify the
upper semicontinuity property, a growth condition on the objective function
in a neighbourhood of the solution set to the original problem (1.1) is needed.
Instead of imposing a speciﬁc growth condition (as e.g. quadratic growth), we
consider the growth function  P deﬁned on R þ by
 PðÞ :¼ min
Z

F0ðx, Þ dPðÞ  #ðPÞ: dðx, X*ðPÞÞ  , x 2 XUðPÞ
8
<
:
9
=
;
ð2:22Þ
Ch. 8. Stability of Stochastic Programming Problems
499

of problem (1.1) on cl U, i.e., near its solution set X*ðPÞ, and the associated
function
Pð	Þ :¼ 	 þ  1
P ð2	Þ
ð	 2 RþÞ,
ð2:23Þ
where we set  1
P ðtÞ :¼ supf 2 Rþ :  PðÞ  tg. Both functions,  P and P,
depend on the data of (1.1) and, in particular, on P. They are lower
semicontinuous on R þ;  P is nondecreasing, P increasing and both vanish
at 0 (cf. Theorem 7.64 in Rockafellar and Wets (1998)). The second main
stability result establishes a quantitative upper semicontinuity property of
(localized) solution sets and identiﬁes the function P as modulus of semi-
continuity. In the convex case, it also provides continuity moduli of countable
dense families of selections to solution sets.
Theorem 9. Let the assumptions of Theorem 5 be satisﬁed and P 2 PF U. Then
there exists a constant ^L  1 such that
; 6¼ X*UðQÞ  X*ðPÞ þ Pð ^LdF UðP, QÞÞB
ð2:24Þ
holds for any Q 2 PF U with dF UðP, QÞ < . Here,  is the constant in Theorem 5
and P is given by (2.23). In case d ¼ 0, the estimate (2.24) is valid with ^L ¼ 1
and for any Q 2 PF U.
Proof. Let L > 0,  > 0 be the constants in Theorem 5, Q 2 PF U with
dF UðP, QÞ <  and ~x 2 X*UðQÞ. As argued in the proof of Theorem 5, there
exists an element x 2 XUðPÞ such that k ~x  xk  ^a, where  :¼ dF UðP, QÞ. Let
LP  0 denote a Lipschitz constant of the function x  R
 F0ðx,Þ dPðÞ on
X \ cl U. Then the deﬁnition of  P and Theorem 5 imply that
ð1 þ LP ^a þ LÞ  ð1 þ LP ^aÞ þ #UðQÞ  #ðPÞ
¼ ð1 þ LP ^aÞ þ
Z

F0ð ~x, Þ dQðÞ  #ðPÞ
 LP ^a þ
Z

F0ð ~x, Þ dPðÞ  #ðPÞ

Z

F0ðx, Þ dPðÞ  #ðPÞ   Pðdðx, X*ðPÞÞÞ

inf
y2 ~xþ ^aB
 Pðdð y, X*ðPÞÞÞ ¼  Pðdð ~x, X*ðPÞ þ ^aBÞÞ:
500
W. Ro¨misch

Hence, we obtain
dð ~x, X*ðPÞÞ  ^a þ dð ~x, X*ðPÞ þ ^aBÞ
 ^a þ  1
P ðð1 þ LP ^a þ LÞÞ  ^L þ  1
P ð2 ^LÞ ¼ Pð ^LÞ,
where ^L :¼ maxf ^a, 1
2 ð1 þ LP ^a þ LÞg  1. In case d ¼ 0, we may choose ^x ¼ ~x,
^a ¼ 1, L ¼ 1, LP ¼ 0 and an arbitrary . This completes the proof.
u
Parts of the proof are similar to arguments of Theorem 7.64 in Rockafellar
and Wets (1998). Next, we brieﬂy comment on some aspects of the general
stability theorems, namely, speciﬁc growth conditions and localization issues.
Remark 10. Problem (1.1) is said to have k-th order growth at the solution set
for some k  1 if  PðÞ  
k for each small  2 Rþ and some 
 > 0, i.e., if
Z

F0ðx, Þ dPðÞ  #ðPÞ þ 
dðx, X*ðPÞÞk
holds for each feasible x close to X*ðPÞ. Then Pð	Þ  	 þ ð2	=
Þ
1
k  C	
1
k for
some constant C > 0 and suﬃciently small 	 2 Rþ. In this case, Theorem 9
provides the Ho¨ lder continuity of X*U at P with rate 1
k. Important special cases
are the linear and quadratic growth for k ¼ 1 and k ¼ 2, respectively.
Remark 11. In the Theorems 5 and 9 the localized optimal values #UðQÞ and
solution sets X*UðQÞ of the (perturbed) model (2.17) may be replaced by their
global versions #ðQÞ and X*ðQÞ if there exists a constant 0 > 0 such that for
each Q 2 PF U with dF UðP, QÞ < 0 either of the following conditions is
satisﬁed: (a) The model (2.17) is convex and X*UðQÞ is a CLM set, (b) the
constraint set of (2.17) is contained in some bounded set V  Rm not
depending on Q, and it holds that V  U.
In case of a ﬁxed constraint set, i.e., d ¼ 0, we derive an extension of
Theorem 9 by using a probability distance that is based on divided diﬀerences
of the functions x  R
 F0ðx, ÞdðP  QÞðÞ around the solution set of (1.1).
For some nonempty, bounded, open subset U of Rm we consider the following
set of probability measures
^PF U :¼
n
Q 2 PF U : 9CQ >0
such that
Z

F0ðx, ÞF0ðx, Þ
kx  xk
dQðÞCQ,
8x, x 2 X \ cl U, x 6¼ x
o
Ch. 8. Stability of Stochastic Programming Problems
501

and the distance
^dF UðP, QÞ :¼ sup
Z

F0ðx, ÞF0ðx, Þ
kx  xk
dðPQÞðÞ: x, x2X\cl U, x6¼x
8
<
:
9
=
;
which is well deﬁned and ﬁnite on ^PF U. The following result has been inspired
by Section 4.4.1 in Bonnans and Shapiro (2000).
Theorem 12. Let d ¼ 0, P 2 ^PF U, X*ðPÞ be nonempty and U  Rm be a boun-
ded and open neighbourhood of X*ðPÞ. Then the estimate
sup
x2X*UðQÞ
dðx,X*ðPÞÞ  ð r
PÞ1ð ^dF UðP,QÞÞ
is valid for any Q 2 ^PF U, where  r
Pð0Þ ¼ 0,  r
PðÞ :¼  PðÞ

for each  > 0 and
 PðÞ is the growth function given by (2.22).
If, moreover, ð r
PÞ1 is continuous at  ¼ 0, there exists a constant  > 0 such
that X*UðQÞ is a CLM set relative to U whenever ^dF UðP,QÞ < .
If, in particular, the original problem (1.1) has quadratic growth, i.e.,
 PðÞ  
2 for some 
 > 0, there exists a constant  > 0 such that the inclusion
; 6¼ X*UðQÞ  X*ðPÞ þ 1

^dF UðP, QÞB
holds whenever ^dF UðP, QÞ < .
Proof. Let Q 2 ^PF U, x 2 X*UðQÞ and x 2 X*ðPÞ be such that kx  xk ¼
dðx, X*ðPÞÞ > 0. We denote fQðyÞ :¼ R
 F0ð y,Þ dQðÞ for each y 2 X, and have
fQðxÞ  fQðxÞ and fPðxÞ  fPðxÞ   Pðdðx,X*ðPÞÞÞ ¼  Pðkx  xkÞ. This leads
to the following estimate
 r
P kx  xk
ð
Þ ¼
1
kx  xk  P kx  xk
ð
Þ 
1
kx  xk ð fPðxÞ  fPðxÞÞ

1
kx  xk ð fPðxÞ  fQðxÞ þ fQðxÞ  fPðxÞÞ
¼
1
kx  xk ðð fP  fQÞðxÞ  ð fP  fQÞðxÞÞ
 ^dF UðP, QÞ,
which completes the ﬁrst part. Since U is open, there exists an " > 0 such
that the "-enlargement fx 2 Rm : dðx, X*ðPÞÞ  "g of X*ðPÞ is contained in U.
502
W. Ro¨misch

Let  > 0 be chosen such that ð r
PÞ1ðÞ  ". Then dðx, X*ðPÞÞ  " and, thus,
x 2 U holds for each x 2 X*UðQÞ, completing the second part.
Finally, it remains to remark that quadratic growth implies  r
PðÞ  
 for
any  > 0 and some 
 > 0.
u
Compared to the estimate in Theorem 9 based on function values of the
function F0, the above bound uses divided diﬀerence information of F0
relative to x and leads to Lipschitz-type results in case of quadratic growth.
While the growth behaviour of the objective function is important for the
quantitative stability of solution sets even for convex models, the situation is
much more advantageous for "-approximate solution sets. For convex models
(1.1) with a ﬁxed constraint set (i.e., d ¼ 0), we will see that the latter sets
behave Lipschitz continuously with respect to changes of probability
distributions measured in terms of the distance dF U, but for a larger set
U compared with stability results for solution sets. To state the result, let
DðC,DÞ :¼ inff	  0: C \ B  D þ 	B, D \ B  C þ 	Bg
ð2:25Þ
D1ðC,DÞ :¼ inf 	  0: C  D þ 	B, D  C þ 	B
f
g
ð2:26Þ
denote the -distance (  0) and the Pompeiu–Hausdorﬀdistance, respec-
tively, of nonempty closed subsets C, D of Rm.
Theorem 13. Let d ¼ 0, F0 be a random lower semicontinuous convex function,
X be closed convex, P 2 PF U and X*ðPÞ be nonempty and bounded. Then there
exist constants  > 0 and " > 0 such that the estimate
D1ðX*" ðPÞ,X*" ðQÞÞ  2
" dF UðP, QÞ
holds for U :¼ ð þ "ÞB and any " 2 ð0, "Þ, Q 2 PF U such that dF UðP, QÞ < ".
Proof. First we choose 0 > 0 such that X*ðPÞ is contained in the open ball
U0 around the origin in Rm with radius 0 and that #ðPÞ  0 þ 1. Applying
Theorem 5 with U0 as the bounded open neighbourhood of X*ðPÞ, we obtain
some constant "0 > 0 such that X*ðQÞ is nonempty and contained in U0 and
#ðQÞ  0 holds whenever Q 2 PF U0 and dF U 0ðP,QÞ < "0. Now, let  >
0, " :¼ minf"0,  0,1g and U :¼ ð þ "ÞB.
For any Q 2 PF U we set again fQðxÞ :¼
R
 F0ðx, Þ dQðÞ for each x 2 Rm.
Furthermore, we denote by
^dþ

the auxiliary epi-distance of fP and fQ
introduced in Proposition 7.61 in Rockafellar and Wets (1998):
^dþ
 ð fP, fQÞ :¼ inff	  0: inf
y2xþ	B fQð yÞ  maxf fPðxÞ,  g þ 	,
inf
y2xþ	B fPð yÞ  maxf fQðxÞ,  g þ 	, 8x 2 Bg:
Ch. 8. Stability of Stochastic Programming Problems
503

From Theorem 7.69 in Rockafellar and Wets (1998) we conclude that the
estimate
DðX*" ðPÞ, X*" ðQÞÞ  2
"
^dþ
þ"ð fP, fQÞ
is valid for " 2 ð0, "Þ if ^dþ
þ"ð fP, fQÞ < ". Furthermore, we may estimate the
auxiliary epi-distance ^dþ
þ"ð fP, fQÞ from above by the uniform distance dF U
ðP, QÞ (cf. also Example 7.62 in Rockafellar and Wets (1998)).
It remains to note that the level sets X*" ðPÞ and X*" ðQÞ are also bounded,
since fP and fQ are lower semicontinuous and convex, and their solution sets
are nonempty and bounded, respectively. Hence, we may choose the constant
 large enough such that the equality DðX*" ðPÞ, X*" ðQÞÞ ¼ D1ðX*" ðPÞ, X*" ðQÞÞ
holds. This completes the proof.
u
Most of the results in this and the previous section illuminate the role of the
distance dF U as a minimal information (m.i.) pseudometric for stability, i.e., as
a pseudometric processing the minimal information of problem (1.1) and
implying quantitative stability of its optimal values and solution sets.
Furthermore, notice that all results remain valid when enlarging the set F U
and, thus, bounding dF U from above by another distance, and when reducing
the set PF U to a subset on which such a distance is deﬁned and ﬁnite.
Such a distance did bounding dF U from above will be called an ideal
probability metric associated with (1.1) if it has -structure (1.9) generated by
some class of functions F ¼ F id from  to R such that Fid contains the
functions CFjðx, Þ for each x 2 X \ cl U, j ¼ 0, . . . ,d, and some normalizing
constant C > 0, and such that any function in Fid shares typical analytical
properties with some function Fjðx,Þ.
In our applications of the general analysis in Section 3 we clarify such
typical analytical properties. Here, we only mention that typical functions
Fjðx, Þ in stochastic programming are nondiﬀerentiable, but piecewise locally
Lipschitz continuous with discontinuities at boundaries of polyhedral sets.
More precisely, function classes F contained in
span fFB : F 2 F, B 2 Bg,
ð2:27Þ
where F  F pðÞ, B  BphkðÞ for some p  1 and k 2 N, are candidates for
an ideal class Fid. The extremal cases, namely, F pðÞ and FB, are discussed in
Section 2.1. To get an idea of how to associate an ideal metric with a sto-
chastic program, we consider the p-th order Fortet–Mourier metric p
introduced in Section 2.1. Then the following result is an immediate conse-
quence of the general ones.
Corollary 14. Let d ¼ 0 and assume that
(i) X*ðPÞ is nonempty and U is an open, bounded neighbourhood of X*ðPÞ,
504
W. Ro¨misch

(ii) X is convex and F0ð, Þ is convex on Rm for each  2 ,
(iii) there exist constants L > 0, p  1 such that 1
L F0ðx, Þ 2 F pðÞ for each
x 2 X \ cl U.
Then there exists a constant  > 0 such that
j#ðPÞ  #ðQÞj  LpðP, QÞ
and
; 6¼ X*ðQÞ  X*=ðPÞ þ PðLpðP, QÞÞB
whenever Q 2 PpðÞ and pðP, QÞ < . Here, the function P is given by (2.23).
Proof. The assumptions of Theorem 5 are satisﬁed. Hence, the result is a
consequence of the Theorems 5 and 9 and the fact that (iii) is equivalent to
jF0ðx, Þ  F0ðx, ~Þj  Lmax 1,kk,k ~k
n
op1
k  ~k
for each , ~ 2  and x 2 X \ cl U, and, thus, it implies dF UðP, QÞ  LpðP, QÞ
for all P, Q 2 PpðÞ. Furthermore, due to the convexity assumption (ii) the
localized optimal values #U and solution sets X*U may be replaced by # and X*,
respectively, if Q is close to P (see Remark 11).
u
Example 15. (newsboy continued) In case of minimal expected costs the set
FU is a speciﬁc class of piecewise linear functions of the form fðr  cÞxþ
cmaxf0, x  g: x 2 X \ cl Ug. Furthermore,
R
 F0ðx, Þ dPðÞ is also piecewise
linear and Corollary 14 applies with L :¼ c, p :¼ 1 and a linear function P.
Hence, the solution set X*ðÞ behaves upper Lipschitzian at P1ðNÞ with respect
to 1, i.e.,
sup
x2X*ðQÞ
dðx, X*ðPÞÞc1ðP, QÞ¼c
Z
R
FPðrÞFQðrÞ
dr¼c
X
k2N

X
k
i¼1
ði ~iÞ
:
Here, we made use of an explicit representation of the Kantorovich metric
on P(R) (Section 5.4 in Rachev (1991)), and FP and FQ are the probability
distribution functions of the measures P ¼ P
k2N kk and Q ¼ P
k2N ~kk,
respectively.
2.4
Mean-risk models
The expectation functional appearing in the basic model (1.1) is certainly
not the only statistical parameter of interest of the (real-valued) cost or
constraint functions Fj, j ¼ 0, . . . ,d, with respect to P. Risk functionals or risk
measures are regarded as statistical parameters of probability measures in
P(R), i.e., they are mappings from subsets of P(R) to R. When risk functionals
Ch. 8. Stability of Stochastic Programming Problems
505

are used in the context of the model (1.1), they are evaluated at the probability
distributions P½Fjðx, Þ1 for x 2 X and j ¼ 0, . . . ,d. Practical risk manage-
ment in decision making under uncertainty often requires to minimize or
bound several risk functionals of the underlying distributions. Typical examples
for risk functionals are (standard semi-) deviations, excess probabilities,
value-at-risk, conditional value-at-risk etc. Some risk measures are deﬁned as
inﬁma of certain (simple) stochastic optimization models (e.g., value-at-risk,
conditional value-at-risk). Other measures are given as the expectation of a
nonlinear function and, hence, their optimization ﬁts into the framework of
model (1.1) (e.g., expected utility functions, excess probabilities).
We refer to Section 4 of Pﬂug (2003) for an introduction to risk functionals
and various examples, to Artzner et al. (1999), Delbaen (2002), Fo¨ llmer and
Schied (2002) for a theory of coherent and convex risk measures, to Ogryczak
and Ruszczyn´ ski (1999) for the relations to stochastic dominance and to
Rockafellar and Uryasev (2002) for the role of the conditional value-at-risk.
Now, we assume that risk functionals Fj, j ¼ 0, . . . ,d are given. In addition
to the mean-risk model (1.2) we denote by Q a perturbation of the original
probability measure P and consider the perturbed model
minfF0ðQ½F0ðx, Þ1Þ: x 2 X,FjðQ½Fjðx, Þ1Þ  0, j ¼ 1, . . . ,dg:
ð2:28Þ
To have all risk functionals Fj well deﬁned, we assume for simplicity that
they are given on the subset Pb(R) of all probability measures in P(R) having
bounded support. Then both models, (1.2) and (2.28), are well deﬁned if we
assume that all functions Fjðx,Þ are bounded. Furthermore, we will need a
continuity property of risk functionals.
A risk functional F on Pb(R) is called Lipschitz continuous w.r.t. to a class H
of measurable functions from R to R if the estimate
jFðGÞ  Fð ~GÞj  sup
H2H

Z
R
HðrÞdðG  ~GÞðrÞ

ð2:29Þ
is valid for all G, ~G 2 PbðRÞ. The following examples and Proposition 8 in
Pﬂug (2003) show that many risk functionals satisfy such a Lipschitz property.
Example 16. We consider the conditional value-at-risk of a probability
distribution G 2 PbðRÞ at level p 2 ð0,1Þ, which is deﬁned by
CVaRpðGÞ :¼ inf
r þ
1
1  p
Z
R
maxf0,  rg dGðÞ: r 2 R
8
<
:
9
=
;:
506
W. Ro¨misch

Hence, CVaRpðGÞ is the optimal value of a stochastic program with recourse
(see Section 3.1). Clearly, the estimate
jCVaRpðGÞ  CVaRpð ~GÞj 
1
1  p sup
r2R

Z
R
maxf0,  rgdðG  ~GÞðÞ

is valid for all G, ~G 2 PbðRÞ. Hence, the conditional value-at-risk is Lipschitz
continuous w.r.t. the class H :¼ fmaxf0,  rg: r 2 Rg.
The value-at-risk of G 2 PbðRÞ at level p 2 ð0,1Þ is given by
VaRpðGÞ :¼ inf fr 2 R: Gð  rÞ  pg:
Thus, VaRpðGÞ is the optimal value of a chance constrained stochastic
program. In Section 3.3 it is shown that the metric regularity of the mapping
r  fy 2 R: Gð  rÞ  p  yg at pairs ðr, 0Þ with r 2 X*ðGÞ is indispenable for
Lipschitz continuity properties of the optimal value. If the metric regularity
property is satisﬁed for the measure G and the level p, we obtain, from
Theorem 39 the estimate
jVaRpðGÞ  VaRpð ~GÞj  LdKðG, ~GÞ ¼ sup
r2R

Z
R
Lð1,rðÞdðG  ~GÞðÞ

for some constant L > 0 and suﬃciently small Kolmogorov distance dKðG, ~GÞ.
Hence, the corresponding class of functions is H :¼ fLð1,r : r 2 Rg. We note
that the metric regularity requirement may lead to serious complications when
using the value-at-risk in stochastic programming models because VaRpðÞ has
to be evaluated at measures depending on x.
Example 17. The upper semi-deviation sdþðGÞ of a measure G 2 PbðRÞ, which
is deﬁned by
sdþðGÞ :¼
Z
R
max 0, 
Z
R
u dGðuÞ
8
<
:
9
=
; dGðÞ,
is Lipschitz continuous w.r.t. the class H :¼ fmaxf0,  rg þ : r 2 Rg.
The examples indicate that typical Lipschitz continuity classes H of
risk functionals contain products of some functions in F kðRÞ for some
k 2 N and of characteristic functions ð1,r for some r 2 R. Hence, their
structure is strongly related to that of the ideal function classes (2.27) for
stability.
Ch. 8. Stability of Stochastic Programming Problems
507

To state our main stability result for the model (1.2), let XðPÞ, #ðPÞ, X*ðPÞ
denote the following more general quantities in this section:
XðPÞ :¼ fx 2 X : FjðP½Fjðx, Þ1Þ  0, j ¼ 1, . . . , dg
#ðPÞ :¼ inffF0ðP½F0ðx, Þ1Þ: x 2 XðPÞg,
X*ðPÞ :¼ fx 2 XðPÞ: F0ðP½F0ðx, Þ1Þ ¼ #ðPÞg:
The localized notions #UðPÞ and X*UðPÞ are deﬁned accordingly.
Theorem 18. For each j ¼ 0, . . . ,d, let the function Fj be uniformly bounded and
the risk functional Fj be Lipschitz continuous on PbðRÞ w.r.t. some class Hj of
measurable functions from R to R. Let P 2 PðÞ and assume that
(i) X*ðPÞ 6¼  and U  Rm is an open bounded neighbourhood of X*ðPÞ,
(ii) if d  1, the function x  F0ðP½F0ðx, Þ1Þ is Lipschitz continuous
on X \ cl U,
(iii) the
mapping
x  fy 2 Rd : x 2 X,FjðP½Fjðx, Þ1Þ  yj, j ¼ 1, . . . ,dg
from Rm to Rd is metrically regular at each pair ðx,0Þ with x 2 X*ðPÞ.
Then there exist constants L > 0 and  > 0 such that the estimates
j#ðPÞ  #UðQÞj  LdF H
U ðP,QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ LPðdF H
U ðP,QÞÞB
are valid whenever Q 2 PðÞ and dF H
U ðP,QÞ < . Here, P is given by (2.23) and
the distance dF H
U is deﬁned by
dF H
U ðP,QÞ :¼ sup
j¼0,...,d
x2X\ cl U
Hj2Hj

Z

HjðFjðx, ÞÞðP  QÞðdÞ
:
Proof. We proceed as in the proofs of Theorems 5 and 9, but now we use the
distance
^dFðP,QÞ :¼ sup
j¼0,...,d
x2X\ cl U
jFjðP½Fjðx, Þ1Þ  FjðQ½Fjðx, Þ1Þj
508
W. Ro¨misch

instead of dF U. In this way we obtain constants L > 0,  > 0 and the estimates
j#ðPÞ  #UðQÞj  L ^dFðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ LPð ^dFðP, QÞÞB
for each Q 2 PðÞ such that ^dFðP, QÞ < . It remains to appeal to the estimate
^dFðP, QÞ sup
j¼0,...,d
x2X\cl U
sup
Hj2Hj

Z
R
HjðrÞdððP  QÞ½Fjðx, Þ1ÞðrÞ
¼ dF H
U ðP, QÞ,
which is a consequence of the Lipschitz continuity (2.29) of the risk func-
tionals Fj, j ¼ 0, . . . , d.
u
The result implies that stability properties of the mean-risk model (1.2)
containing risk functionals Fj with Lipschitz continuity classes Hj, j ¼ 0, . . . ,d,
depend on the class
F H
U :¼ fHjðFjðx,ÞÞ: x 2 X \ cl U, Hj 2 Hj, j ¼ 0, . . . ,dg
instead of FU in case of model (1.1). Hence, the stability behaviour may
change considerably when replacing the expectation functionals in (1.1) by
other risk functionals. For example, the newsboy model based on minimal
expected costs behaves stable at all P 2 P1ðNÞ (Example 15), but the minimum
risk variant of the model (see Example 1) may become unstable.
Example 19. (newsboy continued) We consider the chance constrained model
(1.3) whose solution set is X*ðPÞ ¼ fðk,0Þg with the maximal k such that
P1
i¼k i  p in its ﬁrst component. We assume that equality P1
i¼k i ¼ p
and
k > 0
holds.
To
establish
instability,
we
consider
the
appro-
ximations Pn :¼ P1
i¼1ðnÞ ðnÞ
i i of P, where ðnÞ
i
:¼ i for all i 62 fk  1, kg
and ðnÞ
k1 :¼ k1 þ 1
n, ðnÞ
k :¼ k  1
n for suﬃciently large n 2 N such that
k  1
n > 0. Then the perturbed solution set is X*ðPnÞ ¼ fðk  1,0Þg for any
suﬃciently large n. On the other hand, we obtain for the Kolmogorov distance
dKðP, PnÞ ¼ 1
n, i.e., weak convergence of ðPnÞ to P. Furthermore, the model
(1.3) is stable with respect to the metric dK at each P ¼ P1
i¼1 ii 2 PðNÞ such
that Pk
i¼1 i 6¼ 1  p for each k 2 N. The latter fact is a consequence of
Theorem 5 as the metric regularity condition is satisﬁed (see also Remark 2.5
in Ro¨ misch and Schultz (1991b)).
However, if the conditional value-at-risk or the upper semi-deviation are
incorporated into the objective of (mixed-integer) two-stage stochastic pro-
grams, their ideal function classes and, thus, their ideal metrics (see Sections
3.1 and 3.2) do not change. These observations are immediate consequences of
the following more general conclusion of the previous theorem.
Ch. 8. Stability of Stochastic Programming Problems
509

Corollary 20. Let d ¼ 0. We consider the stochastic programming model
minfF0ðP½F0ðx, Þ1Þ: x 2 Xg,
ð2:30Þ
where F0 is uniformly bounded and the risk functional F0 is Lipschitz continuous
on PbðRÞ w.r.t. some class H0.
Let P 2 PðÞ, X*ðPÞ 6¼ ; and U be an open bounded neighbourhood of X*ðPÞ.
Assume that fF0ðx,Þ: x 2 X \ cl Ug is contained in some class Fc of functions
from  to R and H 
 F 2 L0F c holds for all H 2 H0, F 2 F c and some positive
constant L0.
Then there exist constants L > 0 and  > 0 such that the estimates
j#ðPÞ  #UðQÞj  LdF cðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ LPðdF cðP, QÞÞB
are valid whenever Q 2 PðÞ and dFcðP, QÞ < .
Proof. Clearly, we have in that case dF H
U ðP,QÞ  L0dF cðP,QÞ.
u
Important examples for H0 and Fc are multiples of F1(R) and of F pðÞ ( for
p  1) and fFXB : F 2 F 1ðÞ,B 2 Bg, respectively.
3
Stability of two-stage and chance constrained programs
3.1
Linear two-stage models
We consider the linear two-stage stochastic program with ﬁxed recourse
min hc, xiþ
Z

hqðÞ, yðÞi dPðÞ:WyðÞ¼hðÞTðÞx, yðÞ0, x 2 X


, ð3:31Þ
where c 2 Rm, X  Rm and   Rs are convex polyhedral, W is an ðr, mÞ-
matrix, P 2 P(), and the vectors qðÞ 2 Rm, h() 2 Rr and the (r, m)-matrix
T() depend aﬃne linearly on  2 . The latter assumption covers many
practical situations. At the same time, it avoids the inclusion of all com-
ponents of the recourse costs, the technology matrix and the right-hand side
into , because this could lead to serious restrictions when imposing additional
conditions on P. We deﬁne the function F0 : Rm   ! R by
F0ðx, Þ¼
hc, xiþðqðÞ, hðÞTðÞxÞ,
hðÞTðÞx2pos W, qðÞ2D
þ1,
otherwise

510
W. Ro¨misch

where pos W ¼ fWy: y 2 Rm
þg, D ¼ fu 2 Rm : fz 2 Rr : W0z  ug 6¼ ;g (with W0
denoting the transpose of the matrix W) and ðu, tÞ ¼ inffhu, yi: Wy ¼
t, y  0g (ðu, tÞ 2 Rm  Rr). Then problem (3.31) may be rewritten equivalently
as a minimization problem with respect to the ﬁrst stage decision x, namely,
min
Z

F0ðx, Þ dPðÞ: x 2 X


:
ð3:32Þ
In order to utilize the general stability results of Section 2, we need a
characterization of the continuity and growth properties of the function F0. As
a ﬁrst step we recall some well-known properties of the function , which were
derived in Walkup and Wets (1969a).
Lemma 21. The function  is ﬁnite and continuous on the ðm þ rÞ-dimensional
polyhedral cone D  pos W and there exist ðr, mÞ-matrices Cj and ðm þ rÞ-
dimensional polyhedral cones Kj, j ¼ 1,. . . , N, such that
[
N
j¼1
Kj ¼ D  pos W,
int Ki \ int Kj ¼ ;, i 6¼ j,
ðu, tÞ ¼ hCju, ti,
for each ðu, tÞ 2 Kj, j ¼ 1, . . . , N:
Moreover, (u,  ) is convex on pos W for each u 2 D, and (  , t) is concave on
D for each t 2 pos W.
To
have
problem
(3.32)
well
deﬁned
we
introduce
the
following
assumptions:
(A1) For each (x, ) 2 X   it holds that h()T()x 2 pos W and q() 2 D.
(A2) P 2 P2(), i.e.,
R
 kk2 dPðÞ < 1.
Condition (A1) sheds some light on the role of the set . Due to the aﬃne
linearity of q(  ), h(  ) and T(  ) the polyhedrality assumption on  is not
restrictive. (A1) combines the two usual conditions: relatively complete
recourse and dual feasibility. It implies that X    dom F0.
Proposition 22. Let (A1) be satisﬁed. Then F0 is a random convex function.
Furthermore, there exist constants L>0,
^L > 0 and K>0 such that the
following holds for all , ~ 2  and x, ~x 2 X with maxfkxk, k ~xkg  r:
jF0ðx, Þ  F0ðx, ~Þj  Lr maxf1, kk, k ~kgk  ~k,
jF0ðx, Þ  F0ð ~x, Þj  ^L maxf1, kk2gkx  ~xk,
jF0ðx, Þj  Kr maxf1, kk2g:
Ch. 8. Stability of Stochastic Programming Problems
511

Proof. From Lemma 21 and (A1) we conclude that F0 is continuous on
dom F0 and, hence, on X  . This implies that F0 is a random lower semi-
continuous function (cf. Example 14.31 in Rockafellar and Wets, 1998). It is a
random convex function since the properties of  in Lemma 21 imply that
F0(  , ) is convex for each  2 . In order to verify the Lipschitz property of
F0, let x 2 X with kxk  r and consider, for each j ¼ 1,. . . , N, and  2 j the
function
gjðÞ :¼ F0ðx, Þ ¼ ðqðÞ, hðÞ  TðÞxÞ ¼ hCjqðÞ, hðÞ  TðÞxi,
where the sets j :¼ f 2 : ðqðÞ, hðÞ  TðÞxÞ 2 Kjg are polyhedral, and Cj
and Kj are the matrices and the polyhedral cones from Lemma 21, respec-
tively. Since q(  ), h(  ) and T(  ) depend aﬃne linearly on , the function gj
depends quadratically on  and linearly on x. Hence, there exists a constant
Lj>0 such that gj satisﬁes the following Lipschitz property:
jgjðÞ  gjð ~Þj  Ljr maxf1, kk, k ~kgk  ~k
for all , ~ 2 j:
Now, let , ~ 2 , assume that  2 i and ~ 2 k for some i, k 2 {1,. . . , N} and
consider the line segment ½, ~ ¼ fðÞ ¼ ð1  Þ þ  ~:  2 ½0, 1g. Since
½, ~  ,
there
exist
indices
ij,
j ¼ 1,. . . , l,
such
that
i1 ¼ i,
il ¼ k,
½, ~ \ ij 6¼ ; for each j ¼ 1,. . . , l and ½, ~  [l
j¼1 ij. Furthermore, there
exist
increasing
numbers
ij 2 ½0, 1
for
j ¼ 0,. . . , l1
such
that
ði0Þ ¼ ð0Þ ¼ , ðijÞ 2 ij \ ijþ1 and ðÞ 62 ij if ij <   1. Then we
obtain
jF0ðx, Þ  F0ðx, ~Þj ¼ jgi1ðÞ  gilð ~Þj

X
l1
j¼0
jgijþ1ððijÞÞ  gijþ1ððijþ1ÞÞj

X
l1
j¼0
Lijþ1r maxf1, kk, k ~kgkðijÞ  ðijþ1Þk
 max
j¼1,...,N Ljr maxf1, kk, k ~kg
X
l1
j¼0
kðijÞ  ðijþ1Þk
 max
j¼1,...,N Ljr maxf1, kk,k ~kgk  ~k,
where we have used for the last three estimates that kðÞk  maxfkk, k ~kg for
each  2 [0, 1] and j  ~jk  ~k ¼ kðÞ  ð ~Þk holds for all , ~ 2 ½0, 1.
Lipschitz continuity of F0 with respect to x is shown in Theorem 10 of Kall
(1976) and in Theorem 7.7 of Wets (1974). In particular, the second estimate
512
W. Ro¨misch

of the proposition is a consequence of those results. Furthermore, from
Lemma 21 we conclude the estimate
jF0ðx, Þj  sup
kxkr
jhc, xij þ max
j¼1,..., N jhCjqðÞ, hðÞ  TðÞxij


 kckr þ
max
j¼1,...,N kCjk

	
kqðÞkðkhðÞk þ kTðÞkrÞ
for any pair (x, ) 2 X   with kxk  r. Then the third estimate follows again
from the fact that q(  ), h(  ) and T(  ) depend aﬃne linearly on .
u
The estimate in Proposition 22 implies that, for any r>0, any nonempty
bounded U  Rm and some >0, it holds that
Z

inf
x2X
kxkr
F0ðx, Þ dQðÞ  Kr 1 þ
Z

kk2 dQðÞÞ

	
> 1,
sup
x2X\U

Z

F0ðx, Þ dQðÞ
  K 1 þ
Z

kk2 dQðÞ

	
< 1,
if Q 2 P() has a ﬁnite second order moment. Hence, for any nonempty
bounded U  Rm the set of probability measures PF U contains the set of
measures on  having ﬁnite second order moments, i.e.,
PF U 	
Q 2 PðÞ:
Z

kk2 dQðÞ < 1


¼ P2ðÞ:
The following stability results for optimal values and solution sets of the
two-stage problem (3.32) are now a direct consequence of the results of
Section 2.
Theorem 23. Let (A1) and (A2) be satisﬁed and let X*(P) be nonempty and U be
an open, bounded neighbourhood of X*(P).
Then there exist constants L>0 and >0 such that
j#ðPÞ  #ðQÞj  L2ðP, QÞ
; 6¼ X*ðQÞ  X*ðPÞ þ PðL2ðP, QÞÞB
whenever Q 2 P2() and 2(P, Q)<, where P is given by (2.23).
Ch. 8. Stability of Stochastic Programming Problems
513

Proof. The result is a consequence of Corollary 14 with p ¼ 2. The assump-
tions (ii) and (iii) of Corollary 14 are veriﬁed in Proposition 22.
u
Theorem 24. Let (A1) and (A2) be satisﬁed and let X*(P) be nonempty and
bounded. Then there exist constants L > 0 and " > 0 such that the estimate
D1ðX*" ðPÞ, X*" ðQÞÞ  L
" 2ðP, QÞ
holds for any " 2 ð0, "Þ and Q 2 P2() such that 2(P, Q)<. Here, D1 denotes
the Pompeiu–Hausdorﬀdistance (2.26).
Proof. Since the assumptions of Theorem 13 are satisﬁed, we conclude that
there exist constants >0 and " > 0 such that
D1ðX*" ðPÞ, X*" ðQÞÞ  2
" dF UðP, QÞ
holds for U :¼ ð þ "ÞB and any " 2 ð0, "Þ, Q 2 PF U such that dF UðP, QÞ < ".
Proposition 22 implies the estimate dF UðP, QÞ  Lð þ "Þ2ðP, QÞ, for some
constant L>0, which completes the proof.
u
The theorems establish the quantitative stability of #(  ) and X*(  ) and the
Lipschitz stability of X*" ðÞ with respect to 2 in case of two-stage models with
ﬁxed recourse for fairly general situations. In case that either only the recourse
costs or only the technology matrix and right-hand side are random, both
results are valid for (P1(), 1) instead of (P2(), 2). We verify this
observation for the corresponding conclusion of Theorem 23.
Corollary 25. Let either only q(  ) or only T(  ) and h(  ) be random and (A1) be
satisﬁed. Let P 2 P1(), X*(P) be nonempty and U be an open, bounded
neighbourhood of X*(P). Then there exist constants L>0, >0 such that
j#ðPÞ  #ðQÞj  L1ðP, QÞ
; 6¼ X*ðQÞ  X*ðPÞ þ PðL1ðP, QÞÞB
whenever Q 2 P1() and 1(P, Q)<, where P is given by (2.23).
514
W. Ro¨misch

Proof. By inspecting the proof of Proposition 22 one observes that now the
function F0 satisﬁes the following continuity and growth properties for all
, ~ 2  and x, ~x 2 X with maxfkxk, k ~xkg  r:
jF0ðx, Þ  F0ðx, ~Þj  Lrk  ~k,
jF0ðx, Þj  Kr maxf1, kkg:
Hence, the set PF U contains P1() and Corollary 14 applies with p ¼ 1.
u
Next we provide some examples of recourse models showing that, in
general, the estimate for solution sets in Theorem 23 is the best possible one
and that X*(  ) is not lower semicontinuous at P if X*(P) is not a singleton.
All examples exploit the speciﬁc structure provided by the simple recourse
condition, i.e., m ¼ 2s, q ¼ (q þ, q) and W ¼ (I, I ), where q þ, q 2 Rs and I
is the (s, s)-identity matrix. Then pos W ¼ Rs holds and, hence, (A1) is satisﬁed
iﬀq 2 D, which is equivalent to the condition q þ þ q  0, and
ðq, tÞ ¼ supfht, ui: q  u  qþg:
Example 26. Let m ¼ s ¼ r ¼ 1, m ¼ 2, c ¼ 0, W ¼ (1, 1), X ¼ [1, 1],  ¼ R,
q() ¼ (1, 1), T() ¼ 1, h() ¼ , 8  2 . Let P 2 P(R) be the uniform distribu-
tion on the interval ½ 1
2 , 1
2. Then #(P) ¼ 1, X*(P) ¼ {0}, and quadratic growth
Z

F0ðx, Þ dPðÞ ¼
Z 1=2
1=2
j  xj d ¼ 1
4 þ x2 ¼ #ðPÞ þ dðx, X*ðPÞÞ2
holds for each x 2 ½ 1
2 , 1
2. Let us consider the following perturbations
Pn 2 P(R) of P for n>4 given by
Pn ¼
1
2  "n

	
ðPln þ PrnÞ þ "nð"n þ "nÞ,
where " ¼ n1/2, Pln and Prn are the uniform distributions on ½ 1
2 ,  "nÞ and
ð"n, 1
2, respectively, and r is the measure placing unit mass at r. Using the
explicit representation of 1 in case of probability distributions on R (see
Chapter 5.4 of Rachev, 1991), we obtain
1ðP, PnÞ ¼
Z 1
1
jPðð1, Þ  Pnðð1, Þj d ¼ 1
n ¼ "2
n:
Ch. 8. Stability of Stochastic Programming Problems
515

Furthermore, it holds that #ðPnÞ ¼ 1
2 ð"2
n þ 1
4Þ, X*ðPnÞ ¼ ½"n, "n and, hence,
j#ðPÞ  #ðPnÞj ¼ 1
2 "2
n andsupx2X*ðPnÞ dðx, X*ðPÞÞ ¼ "n foreachn 2 N.Hence,the
estimate in Theorem 23 is best possible.
Next we consider the distribution
^P ¼ 1
2 ð1=2 þ 1=2Þ. Then we have
#ð ^PÞ ¼ 1
2 and X*ð ^PÞ ¼ ½ 1
2 , 1
2 and the linear growth condition
Z

F0ðx, Þ d ^PðÞ ¼
Z

j  xj d ^PðÞ ¼ 1
2
x þ 1
2
 þ
x  1
2


	
 #ð ^PÞ þ dðx, X*ð ^PÞÞ
for each x 2 X. Consider the perturbations ^Pn ¼ ð1  1
nÞ ^P þ 1
n 0 (n 2 N) of ^P.
Then
1ð ^P, ^PnÞ ¼
Z 1
1
j ^Pðð1, Þ  ^Pnðð1, Þj d ¼ 1
2n ,
holds for each n 2 N, where we have again used the explicit representa-
tion of 1 in case of probability measures on R. Furthermore, it holds that
#ð ^PnÞ ¼ ð1  1
nÞ 1
2
and
X*ð ^PnÞ ¼ f0g
for
each
n 2 N.
Hence,
we
have
supx2X*ð ^PÞ dðx, X*ð ^PnÞÞ ¼ 1
2.
Next we consider models with a stochastic technology matrix and recourse
costs, respectively, and show that in such cases X*(  ) is also not lower
semicontinuous at P, in general.
Example 27. Let m ¼ s ¼ r ¼ 1, m ¼ 2, c ¼ 0, W ¼ (1, 1), X ¼ [0, 1],  ¼ R þ,
h() ¼ 0, 8  2 .
In the ﬁrst case, we set q() ¼ (1, 1) and T() ¼ , 8  2 .
In the second case, we set q() ¼ (, ) and T() ¼ 1, 8  2 .
In both cases (A1) is satisﬁed. We consider P ¼ 0 and Pn ¼ 1=n, i.e., the
unit masses at 0 and 1
n, respectively, for each n 2 N. Clearly, (Pn) converges
with respect to the metric 1 to P in P1(R). Furthermore, in both cases
Z

F0ðx, Þ dPnðÞ ¼
Z

x dPnðÞ ¼ x
n
holds for each x 2 X. Then X*(P) ¼ X and X*(Pn) ¼ {0} for any n 2 N, which
implies supx2X*ðPÞ dðx, X*ðPnÞÞ ¼ 1.
The examples show that continuity properties of X*(  ) at P in terms of the
Pompeiu–Hausdorﬀdistance cannot be achieved in general unless X*(P) is a
singleton. Nevertheless, we ﬁnally establish such quantitative stability results
for models where the technology matrix is ﬁxed, i.e., T():T, and a speciﬁc
516
W. Ro¨misch

nonuniqueness of X*(P) is admitted. For their derivation we need an
argument that decomposes the original two-stage stochastic program into
another two-stage program with decisions taken from T(X) and a parametric
linear program not depending on P.
Lemma 28. Let (A1) be satisﬁed and let Q 2 P2() be such that X*(Q) is
nonempty. Then we have
#ðQÞ ¼ inf ðÞ þ
Z

ðqðÞ, hðÞ  Þ dQðÞ:  2 TðXÞ


¼ ðTxÞ þ
Z

ðqðÞ, hðÞ  TxÞ dQðÞ,
8x 2 X*ðQÞ,
X*ðQÞ ¼ ðY*ðQÞÞ,
where
Y*ðQÞ :¼ arg min ðÞ þ
Z

ðqðÞ, hðÞ  Þ dQðÞ:  2 TðXÞ


,
ðÞ :¼ inffhc, xi: x 2 X, Tx ¼ g,
ðÞ :¼ arg minfhc, xi: x 2 X, Tx ¼ g
ð 2 TðXÞÞ:
Moreover,  is convex polyhedral on T(X ) and  is a polyhedral set-valued
mapping which is Lipschitz continuous on T(X ) with respect to the Pompeiu–
Hausdorﬀdistance.
Proof. Let x 2 X*ðQÞ. We set QðÞ :¼
R
 ðqðÞ, hðÞ  Þ dQðÞ and have
#ðQÞ ¼ hc, xi þ QðTxÞ  inffðÞ þ QðÞ:  2 TðXÞg:
For the converse inequality, let ">0 and  2 TðXÞ be such that
ðÞ þ QðÞ  inffðÞ þ QðÞ:  2 TðXÞg þ "
2 :
Then there exists an x 2 X such that Tx ¼  and hc, xi  ðÞ þ "
2. Hence,
#ðQÞ  hc, xi þ QðTxÞ  ðÞ þ QðÞ þ "
2
 inffðÞ þ QðÞ:  2 TðXÞg þ ":
Ch. 8. Stability of Stochastic Programming Problems
517

Since ">0 is arbitrary, the ﬁrst statement is veriﬁed. In particular, x 2 (Tx)
and Tx 2 Y*(Q) for any x 2 X*(Q). Hence, it holds that X*ðQÞ  ðY*ðQÞÞ.
Conversely, let x 2 (Y*(Q)). Then x 2 () for some  2 Y*(Q). Thus Tx ¼ 
and hc, xi ¼ () ¼ (Tx), implying
hc, xi þ QðTxÞ ¼ ðTxÞ þ QðTxÞ ¼ inffðÞ þ QðÞ:  2 TðXÞg
¼ #ðQÞ
and
x 2 X*ðQÞ:
Furthermore,  is clearly convex and polyhedral, and the properties of  are
well known (cf. Walkup and Wets, 1969b).
Theorem 29. Let (A1), (A2) be satisﬁed, X*(P) be nonempty and U be an open
bounded neighbourhood of X*(P). Furthermore, assume that T(X*(P)) is a
singleton. Then there exist constants L>0 and >0 such that
D1ðX*ðPÞ, X*ðQÞÞ  LPðL2ðP, QÞÞ
whenever Q 2 P2() and 2(P, Q)<, where P is given by (2.23) and D1
denotes the Pompeiu–Hausdorﬀdistance.
Proof. Let * be the single element belonging to T(X*(P)). We use the
notation of Lemma 28 and conclude that Y*(P) ¼ {*}. Let V denote a
neighbourhood of * such that T1(V)  U and consider the growth function
 *PðÞ :¼ minfðÞ þ PðÞ  #ðPÞ: k  *k  ,  2 TðXÞ \ Vg
and the associated function *Pð	Þ :¼ 	 þ ð *PÞ1ð2	Þ of the stochastic program
inffðÞ þ PðÞ:  2 TðXÞg. Applying Corollary 14 to the latter program
yields the estimate
sup
2Y*ðQÞ
dð, Y*ðPÞÞ ¼
sup
2Y*ðQÞ
k  *k  *PðL*2ðP, QÞÞ
for some L*>0 and small 2(P, Q). Since X*(P) ¼ (*) and X*(Q) ¼ (Y*(Q))
hold due to Lemma 28 and the set-valued mapping  is Lipschitz continuous
on T(X) with respect to D1 (with some constant L>0), we obtain
D1ðX*ðPÞ, X*ðQÞÞ ¼ D1ðð*Þ, ðY*ðQÞÞ 
sup
2Y*ðQÞ
D1ðð*Þ, ðÞÞ
 L
sup
2Y*ðQÞ
k*  k  L*PðL*2ðP, QÞÞ:
518
W. Ro¨misch

It remains to explore the relation between the two growth functions  P and
 *P, and the associated functions P and *P, respectively. Let  2 R þ and
 2 T(X) \ V such that k*k   and  *PðÞ ¼ ðÞ þ PðÞ  #ðPÞ. Let
x 2 X,
~x 2 X*ðPÞ be such that Tx ¼ , () ¼ cx and dðx, X*Þ ¼
kx  ~xk. Hence, we obtain x 2 U,  *PðÞ ¼ cx þ PðTxÞ  #ðPÞ and
  k  *k ¼ kTx  T ~xk  kTkdðx, X*Þ,
where kTk denotes the matrix norm of T. If kTk 6¼ 0, we conclude that
 *PðÞ   Pð 
kTkÞ holds for any  2 R þ
and, hence, we have ð *PÞ1ð	Þ
 kTk 1
P ð	Þ and *Pð	Þ  maxf1, kTkgPð	Þ for any 	 2 R þ. This implies
D1ðX*ðPÞ, X*ðQÞÞ  maxf1, kTkgLPðL*2ðP, QÞÞ,
and, thus, the desired estimate. In case of kTk ¼ 0, the solution set X*(P) is
equal to arg minfhc, xi: x 2 Xg and, consequently, does not change if P is
perturbed. Hence, the result is correct in the latter case, too.
u
Theorem 30. Let (A1), (A2) be satisﬁed, X*(P) be nonempty, U be an open
bounded neighbourhood of X*(P) and T(X*(P)) be a singleton. Assume that the
function ð r
PÞ1 is continuous at  ¼ 0, where  r
Pð0Þ ¼ 0,  r
PðÞ :¼ 1
  PðÞ for
each >0 and  P(  ) is the growth function given by (2.22).
Then there exists constants L>0 and >0 such that the estimate
D1ðX*ðPÞ, X*ðQÞÞ  Lð r
PÞ1ð ^dUðP, QÞÞ
ð3:33Þ
is valid for each Q 2 P2() with ^dUðP, QÞ < . Here, we denote
^dUðP, QÞ:¼sup

Z

ðqðÞ, hðÞTxÞðqðÞ, hðÞTxÞ
kxxk
dðPQÞðÞ
:

x, x 2 X \ cl U, x 6¼ x
o
:
If the two-stage model (3.31) has quadratic growth, the estimate (3.33) asserts
Lipschitz continuity with respect to ^dU.
Proof. Using the same notation as in the previous proof we conclude again
that
D1ðX*ðPÞ, X*ðQÞÞ  L
sup
2Y*ðQÞ
k*  k:
Ch. 8. Stability of Stochastic Programming Problems
519

If T is the null matrix, the result is true since X*(Q) does not depend on Q.
Otherwise, we denote by kTk the matrix norm of T, argue as in the proofs of
the Theorem 12 and 29 and arrive at the estimate
 P
1
kTk k*k

	
 *Pðk*kÞPðÞQðÞðPð*ÞQð*ÞÞ
for each  2 Y*(Q), where PðÞ :¼
R
 ðqðÞ, hðÞ  Þ dPðÞ. The latter
estimate implies (3.33).
u
Remark 31. In all cases, where the original and perturbed solution sets X*(P)
and X*(Q) are convex and an estimate of the form
D1ðX*ðPÞ, X*ðQÞÞ  ðdðP, QÞÞ
whenever Q 2 Pd, dðP, QÞ < 
is available for some (pseudo) metric d on a set of probability measures Pd and
some function  from R þ to R þ, this estimate may be complemented by a
quantitative continuity property of a countable dense family of selections.
Namely, there exists a family fx*kðQÞgk2N of selections of X*(Q) such that
X*ðQÞ ¼ cl
[
k2N
x*kðQÞ
 
!
kx*kðPÞ  x*kðQÞk  LkðdðP, QÞÞ
whenever Q 2 Pd, dðP, QÞ < 
for some constant Lk>0 and any k 2 N. To derive this conclusion, let us ﬁrst
recall the notion of a generalized Steiner point of a convex compact set C  Rm
(see Dentcheva, 2000). It is given by StðCÞ :¼
R
B ð@CðxÞÞðdxÞ, where C(  )
is the support function of C, i.e., CðxÞ :¼ supy2C hx, yi, @C(x) is the
convex subdiﬀerential of C at x and (@C(x)) its norm-minimal element.
Furthermore,  is a probability measure on B having a C1-density with respect
to the Lebesgue measure. A generalized Steiner selection St(  ) is Lipschitz
continuous (with a Lipschitz constant depending on ) on the set of all
nonempty convex compact subsets of Rm equipped with the distance D1.
Furthermore, there exists a countable family {k}k 2 N of probability measures
on R, each having a C1-density with respect to the Lebesgue measure, such
that the corresponding family of generalized Steiner selections fStkðCÞgk2N is
dense in C. Both results are proved in Dentcheva (2000). By combining these
two arguments for the countable family fx*kðQÞ :¼ StkðX*ðQÞÞgk2N
of
selections to the convex compact sets X*(Q) the desired result follows.
The previous Theorems 29 and 30 extend the main results of Ro¨ misch and
Schultz (1993, 1996) and Shapiro (1994) to the case of a general growth
condition. The crucial assumption of both results is that T(X*(P)) is a singleton.
520
W. Ro¨misch

The latter condition is satisﬁed, for example, if the expected recourse function
PðÞ :¼ R
 ðqðÞ, hðÞ  Þ dPðÞ is strictly convex on a convex neighbour-
hood of T(X*(P)).
The situation simpliﬁes in case of random right-hand sides only, i.e.,
q():q and h() ¼ . Then the distance ^dU can be bounded above by a
discrepancy w.r.t. certain polyhedral cones. Namely,
^dUðP, QÞ  ^L supfjðP  QÞðTx þ BiðRs
þÞÞj: x 2 cl U, i ¼ 1, . . . , lg,
holds, where
^L > 0 is some constant and Bi, i ¼ 1,. . . , l, are certain
nonsingular submatrices of the recourse matrix W (Ro¨ misch and Schultz,
1996). In this case, veriﬁable suﬃcient conditions for the strict and strong
convexity of the expected recourse function P are also available (Schultz,
1994). Namely, the function P is strictly convex on any open convex subset
of the support of P if P has a density on Rs and the set fz 2 Rs : W0z < qg is
nonempty. It is strongly convex if, in addition to the conditions implying strict
convexity, the density of P is bounded away from zero on the corresponding
convex neighbourhood. Furthermore, the model (3.31) has quadratic growth
if the function P is strongly convex on some open convex neighbourhood of
T(X*(P)). The latter fact was proved in Dentcheva and Ro¨ misch (2000) by
exploiting the Lipschitz continuity of the mapping  in Lemma 28. The
Lipschitz continuity result of Theorem 30 in case of quadratic growth forms
the basis of the following diﬀerential stability result for optimal values and
solution sets proved in Dentcheva and Ro¨ misch (2000).
Theorem 32. Let (A1), (A2) be satisﬁed, X*(P) be nonempty and bounded, and
T(X*(P)) be a singleton, i.e., T(X*(P)) ¼ {*}. Let Q 2 P().
Then the function # is Gateaux directionally diﬀerentiable at P in direction
QP and it holds
#0ðP; Q  PÞ :¼ lim
t!0þ
1
t ð#ðP þ tðQ  PÞÞ  #ðPÞÞ ¼ Qð*Þ  Pð*Þ:
If, in addition, model (3.31) has quadratic growth and P is twice continuously
diﬀerentiable at {*}, then the second-order Gateaux directional derivative of #
at P in direction QP exists and we have
#00ðP; QPÞ :¼ lim
t!0þ
1
t2 ð#ðP þ tðQ  PÞÞ  #ðPÞ  t#0ðP; Q  PÞÞ
¼inf 1
2 hr2Pð*ÞTx, Txi þ ðQPÞ0ð*; TxÞ: x2SðxÞ


,
Ch. 8. Stability of Stochastic Programming Problems
521

where SðxÞ ¼ fx 2 TXðxÞ: cx þ hrPð*Þ, Txi ¼ 0g and TXðxÞ is the tangent
cone to X at some x 2 X*ðPÞ. The directional derivative ðQ  PÞ0ð*; TxÞ of
QP exists since both functions are convex and P is diﬀerentiable.
The ﬁrst-order Gateaux directional derivative of the set-valued mapping X*(  )
ðX*Þ0ðP, x; Q  PÞ :¼ lim
t!0þ
1
t ðX*ðP þ tðQ  PÞÞ  xÞ
at the pair ðP, xÞ, x 2 X*ðPÞ, in direction QP exists and coincides with
arg minf1
2 hr2Pð*ÞTx, Txi þ ðQ  PÞ0ð*; TxÞ: x 2 SðxÞg.
3.2
Mixed-integer two-stage models
Next we allow for mixed-integer decisions in both stages and consider the
stochastic program
min hc, xi þ
Z

ðhðÞ  TðÞxÞ dPðÞ: x 2 X


,
ð3:34Þ
where
ðtÞ :¼ minfhq, yi þ hq, yi: Wy þ Wy ¼ t, y 2 Z ^m
þ, y 2 Rm
þg
ðt 2 RrÞ,
ð3:35Þ
c 2 Rm, X is a closed subset of Rm,  a polyhedron in Rs, q 2 R ^m, q 2 Rm,
W and W are ðr, ^mÞ- and ðr, mÞ-matrices, respectively, h() 2 Rr and the (r, m)-
matrix T() are aﬃne linear functions of  2 Rs, and P 2 P().
Basic properties of  like convexity and continuity on dom  in the purely
linear case cannot be maintained for reasonable problem classes. Since  is
discontinuous, in general, it is interesting to characterize its continuity regions.
Similarly, as for the two-stage models without integrality requirements in the
previous section, we need some conditions to have the model (3.34) well-
deﬁned:
(B1) The matrices W and W have only rational elements.
(B2) For each pair (x, ) 2 X   it holds that h()T()x 2 T, where
T :¼ ft 2 Rr : t ¼ Wy þ Wy, y 2 Z ^m
þ, y 2 Rm
þg:
(B3) There exists an element u 2 Rr such that W0u  q and W
0u  q.
(B4) P 2 P1(), i.e.,
R
 kk dPðÞ < þ1.
522
W. Ro¨misch

The conditions (B2) and (B3) mean relatively complete recourse and dual
feasibility, respectively. We note that condition (B3) is equivalent to (0) ¼ 0,
and that (B2) and (B3) imply (t) to be ﬁnite for all t 2 T (see Proposition 1 in
Louveaux and Schultz, 2003). In the context of this section, the following
properties of the value function  on T are important.
Lemma 33. Assume (B1)–(B3). Then there exists a countable partition of T into
Borel subsets Bi, i.e., T ¼ [i2N Bi such that
(1) each of the sets has a representation Bi ¼ fbi þ pos Wgn [N0
j¼1 fbijþ
pos Wg, where bi, bij 2 Rr for i 2 N and j ¼ 1,. . . , N0. Moreover, there
exists an N1 2 N such that for any t 2 T the ball B(t, 1) in Rr is intersected
by at most N1 diﬀerent subsets Bi;
(2) the restriction jBi of  to Bi is Lipschitz continuous with a constant
L>0 that does not depend on i.
Furthermore, the function  is lower semicontinuous and piecewise polyhedral
on T and there exist constants a, b>0 such that it holds for all t, ~t 2 T :
jðtÞ  ð~tÞj  akt  ~tk þ b:
Part (i) of the lemma was proved in Section 5.6 of Bank et al. (1982) and in
Lemma 2.5 of Schultz (1996), (ii) was derived as Lemma 2.3 in Schultz (1996)
and the remaining properties of  were established in Blair and Jeroslow
(1977). Compared to Lemma 21 for optimal value functions of linear pro-
grams without integrality requirements, the representation of  is now given
on countably many (possibly unbounded) Borel sets. This requires to incor-
porate the tail behaviour of P and leads to the following representation of the
function F0ðx, Þ :¼ hc, xi þ ðhðÞ  TðÞxÞ for each pair (x, ) in X  .
Proposition 34. Assume (B1)–(B3) and let U be an open bounded subset of Rm.
For each R  1 and x 2 X \ cl U there exist disjoint Borel subsets R
j,x of ,
j ¼ 1,. . . , , whose closures are polyhedra with a uniformly bounded number of
faces such that the function
F0ðx, Þ ¼
X

j¼0
ðhc, xi þ ðhðÞ  TðÞxÞR
j,xðÞ
ððx, Þ 2 X  Þ
isLipschitzcontinuouswithrespectto oneachR
j,x,j ¼ 1,. . . , ,withsomeuniform
Lipschitz constant. Here, R
0,x :¼ n [
j¼1 R
j,x is contained in { 2 Rs: kk>R}
and  is bounded by a multiple of Rr.
Proof. Since h(  ) and T(  ) are aﬃne linear functions, there exists a constant
C2>0 such that the estimate kh()T()xk1  C2 max{1, kk} holds for each
Ch. 8. Stability of Stochastic Programming Problems
523

pair in X \ cl U. Let R>0 and T R :¼ T \ RC2B1, where B1 refers to the
closed unit ball in Rr with respect to the norm k  k1. Now, we partition the
ball RC2B1 into disjoint Borel sets whose closures are B1-balls with radius 1,
where possible gaps are ﬁlled with maximal balls of radius less than 1. Then
the number of elements in this partition of RC2B1 is bounded above by
(2RC2)r. From Lemma 33 (i) we know that each element of this partition is
intersected by at most N1 subsets Bi ( for some N1 2 N). Another consequence
of Lemma 33 (i) is that each Bi splits into disjoint Borel subsets whose closures
are polyhedra. Moreover, the number of such subsets can be bounded from
above by a constant not depending on i. Hence, there exist a number  2 N
and disjoint Borel subsets {Bj : j ¼ 1,. . . , } such that their closures are
polyhedra, their union contains TR, and  is bounded above by Rr, where the
constant >0 is independent of R. Now, let x 2 X \ cl U and consider the
following disjoint Borel subsets of :
R
j,x :¼ f 2 : hðÞ  TðÞx 2 Bjg
ð j ¼ 1, . . . , Þ,
R
0,x :¼ n [

j¼1 R
j,x f2: khðÞTðÞxk1 >RC2g  f 2 : kk>Rg:
For each j ¼ 1,. . . ,  the closures of the sets Bj are polyhedra with a number of
faces that is bounded above by some number not depending on j,  and R.
Hence, the same is true for the closures of the sets R
j,x, i.e., for
f 2 : hðÞ  TðÞx 2 cl Bjg, where, moreover, the corresponding number
k 2 N does not depend on x 2 X \ cl U. Finally, we conclude from Lemma 33
that there exists a constant L1>0 (which does not depend on x 2 X \ cl U,
j ¼ 1,. . . ,  and R>0) such that the function F0ðx, ÞjR
j,x ¼ cx þ jBjðhðÞ
TðÞxÞ is Lipschitz continuous with constant L1.
u
For further structural properties of model (3.34) we refer to Louveaux and
Schultz (2003). In order to state stability results for model (3.34), we consider
the following probability metrics with -structure on P1() for every k 2 N:
1,phkðP, QÞ :¼ sup

Z
B
f ðÞðP  QÞðdÞ
: f 2 F 1ðÞ, B 2 BphkðÞ


¼ sup

Z

f ðÞBðÞðP  QÞðdÞ
: f 2F 1ðÞ, B2BphkðÞ


: ð3:36Þ
Here, BphkðÞ and F1() denote the sets of polyhedra in  and of Lipschitz
continuous functions from  to R introduced in Section 2.1.
Theorem 35. Let the conditions (B1)–(B4) be satisﬁed, X*(P) be nonempty and
U  Rm be an open bounded neighbourhood of X*(P).
524
W. Ro¨misch

Then there exist constants L>0, >0 and k 2 N such that
j#ðPÞ  #UðQÞj  LPð1,phkðP, QÞÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðLPð1,phkðP, QÞÞÞB,
ð3:37Þ
and X*UðQÞ is a CLM set of (3.34) relative to U whenever Q 2 P1() and
1,phkðP, QÞ < . Here, the function P on R þ is deﬁned by
Pð0Þ ¼ 0
and
PðtÞ :¼ inf
R1 Rrt þ
Z
f2: kk>Rg
kk dPðÞ


ðt > 0Þ
and continuous at t ¼ 0, and the function P is given by (2.23).
If P has a ﬁnite absolute moment of pth order for some p>1, the estimate
PðtÞ  Ctðp1Þ=ðp1þrÞ holds for small t>0 and some constant C>0.
Proof. Since the function  is lower semicontinuous on T (Lemma 33), F0 is
lower semicontinuous on X   and, hence, a random lower semicontinuous
function (Example 14.31 in Rockafellar and Wets, 1998). Using Lemma 33 we
obtain the estimate
jF0ðx, Þj  kck kxk þ aðkhðÞk þ kTðÞk kxkÞ þ b
for each pair (x, ) 2 X  . Since h() and T() depend aﬃne linearly on ,
there exists a constant C1>0 such that jF0ðx, Þj  C1 maxf1, kkg holds for
each pair (x, ) 2 (X \ cl U)  . Hence, PF UðÞ 	 P1ðÞ and Theorems 5 and 9
apply with d ¼ 0 and the distance dF U on P1().
From Proposition 34 we know that, for each R  1 and x 2 X \ cl U, there
exist Borel subsets R
j,x, j ¼ 1,. . . , , of  such that the function f R
j,xðÞ :¼
F0ðx, ÞjR
j,x is Lipschitz continuous on R
j,x with some Lipschitz constant L1>0
(not depending on x, j and R). We extend each function f R
j,xðÞ to the whole of
 by preserving the Lipschitz constant L1. Proposition 34 also implies that the
closures of R
j,x are contained in BphkðÞ for some k 2 N, that the number  is
bounded above by Rr, where the constant >0 is independent on R, and that
R
0,x :¼ n [
j¼1 R
j,x is a subset of { 2 : kk>R}.
For each Q 2 P1() and x 2 X \ cl U we obtain

Z

F0ðx, Þ dðPQÞðÞ
¼

X

j¼0
Z
R
j,x
F0ðx, Þ dðP  QÞðÞ


X

j¼1

Z
R
j,x
f R
j,xðÞ dðP  QÞðÞ
 þ IR
x ðP, QÞ
L1 sup
f 2F 1ðÞ
j¼1,...,

Z

f ðÞR
j,x dðPQÞðÞ
þIR
x ðP, QÞ,
Ch. 8. Stability of Stochastic Programming Problems
525

where IR
x ðP, QÞ :¼ j
R
R
0,x F0ðx, Þ dðP  QÞðÞj.
For each R
j,x we now consider a sequence of polyhedra BR
j,x, which are
contained in R
j,x and belong to BphkðÞ, such that their characteristic
functions BR
j,x converge pointwise to the characteristic function R
j,x. Then the
sequence consisting of the elements j
R
 f ðÞBR
j,xðÞ dðP  QÞðÞj converges to
j
R
 f ðÞR
j,xðÞ dðP  QÞðÞj while each element is bounded by 1,phkðP, QÞ.
Hence, the above estimate may be continued to

Z

F0ðx, Þ dðP  QÞðÞ
  L1Rr1,phkðP, QÞ þ IR
x ðP, QÞ:
ð3:38Þ
For the term IR
x ðP, QÞ we have
IR
x ðP, QÞ  C1
Z
f2: kk>Rg
kk dðP þ QÞðÞ
 C1
Z
f2: kk1>R=C2g
kk dðP þ QÞðÞ
where we have used the estimate jF0(x, )j  C1kk for each pair ðx, Þ 2
ðX \ cl UÞ  f 2 : kk > Rg and C2>0 is a norming constant such that
kk  C2kk1 holds for each  2 Rs. Clearly, the set f 2 : kk1 > R
C2g can be
covered by 2s intersections of  by open halfspaces whose closures belong to
BphkðÞ. Hence, a similar argument as the one above yields the estimate
Z
f2: kk1>R=C2g
kk dQðÞ 2s1,phkðP, QÞ þ
Z
f2: kk1>R=C2g
kk dPðÞ:
Hence, from the previous estimates we obtain that
dF UðP, QÞ  ðL1Rr þ 2sC1Þ1,phkðP, QÞ þ 2C1
Z
f2: kk1>R=C2g
kkdPðÞ
 CRr1,phkðP, QÞ þ
Z
f2: kk>Rg
kk dPðÞ
for some constants C>0 and  2 (0, 1), the latter depending on the norming
constants of k  k and k  k1, respectively. Finally, we obtain
dF UðP, QÞ  ^CPð1,phkðP, QÞÞ,
ð3:39Þ
526
W. Ro¨misch

where
Pð0Þ:¼ 0
and
PðtÞ:¼ inf
R1 Rrt þ
Z
f2: kk>Rg
kk dPðÞ


ðt > 0Þ
ð3:40Þ
with some constant ^C > 0. Now, the result is a consequence of the Theorem 5
and Theorem 9. If R
 kkp dPðÞ < 1, it holds that R
f2: kk>Rg kk dPðÞ 
R1p R
 kkp dPðÞ by Markov’s inequality. The desired estimate follows by
inserting R ¼ t1=ðpþr1Þ for small t>0 into the function whose inﬁmum w.r.t.
R  1 is P(t).
u
In case that the underlying distribution P and its perturbations Q have
supports in some bounded subset of Rs, the stability result improves slightly.
Corollary 36. Let the conditions (B1)–(B3) be satisﬁed and  be bounded.
Assume that P 2 P(), X*(P) is nonempty and U  Rm is an open bounded
neighbourhood of X*(P).
Then there exist constants L>0, >0 and k 2 N such that
j#ðPÞ  #UðQÞj  L1,phkðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðL1,phkðP, QÞÞB,
and X*UðQÞ is a CLM set of (3.34) relative to U whenever Q 2 P() and
1,phkðP, QÞ < .
Proof. Since  is bounded, we have P1() ¼ P(). Moreover, the function
P(t) can be estimated by Rrt for some suﬃciently large R>0. Hence,
Theorem 35 implies the assertion.
u
Remark 37. Since  2 BphkðÞ for some k 2 N, we obtain from (3.36) by
choosing B :¼  and f:1, respectively,
maxf1ðP, QÞ, phkðP, QÞg  1,phkðP, QÞ
ð3:41Þ
for large k and all P, Q 2 P1(). Here, phk denotes the polyhedral discrepancy
(see Section 2.1). Hence, convergence with respect to 1,phk implies weak
convergence, convergence of ﬁrst order absolute moments and convergence
with respect to the polyhedral discrepancy phk. The converse is also true. The
latter observation is a consequence of the estimate
1,phkðP, QÞ  CsphkðP, QÞ1=ðsþ1Þ
ðP, Q 2 PðÞÞ
ð3:42Þ
Ch. 8. Stability of Stochastic Programming Problems
527

for some constant Cs>0. It is valid for bounded   Rs and can be derived by
using the technique in the proof of Proposition 3.1 in Schultz (1996). In view
of (3.41) and (3.42) the metric 1,phk is stronger than phk in general, but in case
of bounded  both metrize the same topology on P().
For more speciﬁc models (3.34), improvements of the above results are
possible. The potential of such improvements consists in exploiting speciﬁc
recourse structures, i.e., in additional information on the shape of the sets Bi in
Lemma 33 and on the behaviour of the (value) function  on these sets. These
considerations may lead to stability results with respect to probability metrics
that are (much) weaker than 1,phk. To illustrate such an improvement, let us
consider the case of pure integer recourse where  is given by
ðtÞ ¼ minfhq, yi: Wy  t, y 2 Z ^mg,
ð3:43Þ
the technology matrix is ﬁxed and the right-hand side is fully stochastic, i.e.,
T():T and h():. This situation ﬁts into the general model (3.34) by setting
q ¼ 0, m ¼ r and W ¼ Ir, with Ir denoting the (r, r)-identity matrix. For such
models Schultz (1996) observed that stability holds with respect to the
Kolmogorov metric dK on P().
Corollary 38. Let  be given by (3.43), T():T, h(): and  be bounded.
Furthermore, let the conditions (B1)–(B3) be satisﬁed with T ¼ Rs. Assume that
P 2 P(), X*(P) is nonempty and U  Rm is an open bounded neighbourhood of
X*(P). Then there exist constants L>0 and >0 such that
j#ðPÞ  #UðQÞj  LdKðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðLdKðP, QÞÞB,
and X*UðQÞ is a CLM set of (3.34) relative to U whenever Q 2 P() and
dK(P, Q)<. Here, the function P is given by (2.23).
Proof. The assumptions imply that  is even constant on Bi for each i 2 N and
the continuity regions of  are rectangular (see Schultz, 1996). Without loss of
generality the set  may be chosen to be rectangular. Then the sets R
j,x in
Proposition 34 are also bounded rectangular sets and F0(x,  ) is constant on
each R
j,x. Hence, the estimate (3.38) takes the form

Z

F0ðx, Þ dðP  QÞðÞ
  L1RsboxðP, QÞ,
528
W. Ro¨misch

where boxðP, QÞ :¼ supfjPðBÞ  QðBÞj: B is a box in Rsg. Finally, we use the
known estimate
boxðP, QÞ  CdKðP, QÞ
for some constant C>0 and derive the result from Theorem 35.
u
3.3
Linear chance constrained programs
In this section, we study consequences of the general stability analysis of
Section 2 for linear chance constrained stochastic programs of the form
minfhc, xi: x 2 X, Pðf 2 : TðÞx  hðÞgÞ  pg,
ð3:44Þ
where c 2 Rm, X and  are polyhedra in Rm and Rs, respectively, p 2 (0, 1),
P 2 P() and the right-hand side h() 2 Rr and the (r, m)-matrix T() depend
aﬃne linearly on  2 .
We set d ¼ 1, F0ðx, Þ ¼ hc, xi, F1ðx, Þ ¼ p  HðxÞðÞ where HðxÞ ¼ f 2
: TðÞx  hðÞg and H(x) its characteristic function, and observe that the
program (3.44) is a special case of the general stochastic program (1.1). We
note that the set H(x) is polyhedral for each x 2 X. In fact, these sets are given
as
the
ﬁnite
intersection
of
r
closed
half-spaces.
Furthermore,
the
multifunction H from Rm to Rs has a closed graph and, hence, the mapping
ðx, Þ  HðxÞðÞ from Rm   to R is upper semicontinuous. This implies that
F1 is lower semicontinuous on Rm   and, hence, a random lower
semicontinuous function (Example 14.31 in Rockafellar and Wets, 1998).
Moreover, we have p  1  F1ðx, Þ  p for any pair (x, ). By specifying the
general class of probability measures and the minimal information probability
metric in Section 2.2 we obtain
PF UðÞ ¼
Q 2 PðÞ:
sup
x2X\cl U
max
j¼0, 1

Z

Fjðx, Þ dQðÞ
<1


¼ PðÞ
dF UðP, QÞ ¼
sup
x2X\cl U
max
j¼0, 1

Z

Fjðx, ÞðP  QÞðdÞ

¼
sup
x2X\cl U
PðHðxÞÞ  QðHðxÞÞ

for each P, Q 2 P() and any nonempty, open and bounded subset U of Rm.
Due to the polyhedrality of the sets H(x) for any x 2 Rm, the polyhedral
discrepancies phk on P() for every k 2 N (see Section 2.1) or related discre-
pancies appear as natural candidates for suitable probability metrics in case of
model (3.44). The following result is an immediate consequence of the general
methodology in Section 2.
Ch. 8. Stability of Stochastic Programming Problems
529

Theorem 39. Let P 2 P() and assume that
(i) X*(P) 6¼ ; and U  Rm is an open bounded neighbourhood of X*(P),
(ii) the mapping x  fy 2 R: Pðf 2 : TðÞx  hðÞgÞ  p  yg is metrically
regular at each pair ðx, 0Þ with x 2 X*ðPÞ.
Then there exist constants L>0, >0 and k 2 N such that
j#ðPÞ  #UðQÞj  LphkðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðLphkðP, QÞÞB,
and X*UðQÞ is a CLM set of (3.44) relative to U whenever Q 2 P() and
phkðP, QÞ < . Here, the function P is given by (2.23).
Proof. All sets H(x) are polyhedra in Rs given by r linear inequalities. Hence,
the number of faces of H(x) is bounded by some k 2 N not depending on
x 2 Rm. Since all assumptions of Theorem 5 are satisﬁed for the special
situation considered here, the result follows from the Theorems 5 and 9 by
taking into account the estimate dF UðP, QÞ  phkðP, QÞ.
u
We show that Theorem 39 applies to many chance constrained models
known from the literature. First we discuss the metric regularity property (ii)
of the original probabilistic constraint in (3.44). The following example shows
that condition (ii) is indispensable for Theorem 39 to hold.
Example 40. Let
P 2 P(R) have a
distribution function FP which is
continuously diﬀerentiable and satisﬁes FPðxÞ ¼ x2sþ1 þ p for all x in a
neighbourhood of x ¼ 0 and some p 2 (0, 1) and s 2 N. Let us consider the
model
minfx: x 2 R, Pð  xÞ ¼ FPðxÞ  pg:
Then the condition rFPðxÞ 6¼ 0 is necessary and suﬃcient for the metric
regularity at x with FPðxÞ ¼ p (Example 9.44 in Rockafellar and Wets, 1998).
Clearly, this condition is violated at the minimizer x ¼ 0. To show that the
result gets lost, we consider the measures Pn ¼ ð1  1
nÞP þ 1
n 1=n, n 2 N.
The sequence (Pn) converges weakly to P and, thus, it converges with respect
to the Kolmogorov metric dK as P is continuous. Then j#ðPÞ  #ðPnÞj ¼
ð p
n1Þ1=ð2sþ1Þ ¼: xn, but dKðP, PnÞ  jFPðxnÞ  FPnðxnÞj ¼
p
n1.
When looking for general conditions implying (ii), one has to resort to
results for nonconvex and nondiﬀerentiable situations. The function
gðxÞ :¼ Pðf 2 : TðÞx  hðÞgÞ
530
W. Ro¨misch

from Rm into R is known to be upper semicontinuous (Proposition 3.1 in
Ro¨ misch and Schultz, 1991c). However, g happens to be nondiﬀerentiable or
even discontinuous not only in cases where the probability distribution P is
discrete, but even if T() is nonstochastic and P is continuous.
Example 41. Let P be the standard normal distribution with distribution
function . First let TðÞ ¼
1
1

 
and hðÞ ¼

0

 
for each  2 R. Then
gðxÞ ¼ Pðf 2 R: x  , x  0gÞ ¼
0,
x < 0
ðxÞ,
x  0 :

Secondly, let TðÞ ¼
1
1


and hðÞ ¼



 
for each  2 R. Then we have
gðxÞ ¼ Pðf 2 R: x  ,  x  gÞ ¼ ðminfx, xgÞ:
We also refer to Example 9 in Henrion and Ro¨ misch (1999) for a probability
distribution P having a (bounded) continuous density on  ¼ R2, but a
probability distribution function (i.e., g in case of T() ¼ I and h() ¼ ) that is
not locally Lipschitz continuous.
Hence, one has to go back to tools from nonsmooth analysis in general. For
example, if the function g is locally Lipschitz continuous on Rm, condition (ii)
is satisﬁed if the constraint qualiﬁcation
@ðgÞðxÞ \ ðNXðxÞÞ ¼ ;
ð3:45Þ
holds at each x 2 X*ðPÞ with gðxÞ ¼ p (Corollary 4.2 in Mordukhovich,
1994b). Here, the symbol @ stands for the Mordukhovich subdiﬀerential (cf.
Mordukhovich, 1994a) and NXðxÞ :¼ fx* 2 Rm : hx*, x  xi  0, 8x 2 Xg is
the normal cone to the polyhedral set X at x 2 X.
For more speciﬁc structures of probabilistic constraints, even in case of
a stochastic matrix T(), the situation may become much more comfortable if
P is a multivariate normal distribution. To demonstrate this, we consider
the case  ¼ Rm þ 1, TðÞx ¼ Pm
i¼1 ixi, i.e., T() consists of one single row,
and h() ¼ m þ 1. Then H(x) takes the form
HðxÞ ¼
 2 Rmþ1 :
X
m
i¼1
ixi  mþ1
(
)
ð3:46Þ
for each x 2 Rm, i.e., the sets H(x) are closed half-spaces in Rm þ 1.
Ch. 8. Stability of Stochastic Programming Problems
531

Corollary 42. Let P be a normal distribution on Rm þ 1 with mean  2 Rm þ 1 and
nonsingular covariance matrix  2 R(m þ 1)  (m þ 1), H be given by (3.46) and
p 2 ð1
2 , 1Þ. Let X*(P) be nonempty and U  Rm be an open bounded neigh-
bourhood of X*(P). Assume that there exists an ^x 2 X such that PðHð ^xÞÞ > p.
Then there are constants L>0 and >0 such that
j#ðPÞ  #UðQÞj  LhðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðLhðP, QÞÞB
holds and X*UðQÞ is a CLM set for (3.44) relative to U for each Q 2 P() with
h(P, Q)<. Here, the function P is given by (2.23) and h is the half-space
discrepancy (see Section 2.1).
Proof. For any x 2 Rm, we set x0 :¼ ðx1, . . . , xm,  1Þ and ðxÞ :¼ hx0, x0i1=2.
Let  denote the standard normal distribution function and  the standard
normal density. Then h, x0i is normal with mean h, x0i and standard devia-
tion (x0)>0 (due to the nonsingularity of ), and
gðxÞ ¼ Pðf 2 Rmþ1 : h, x0i  0gÞ ¼  h, x0i
ðx0Þ

	
holds for any x 2 Rm. Further, the function
^gðxÞ :¼ h, x0i  1ð pÞðx0Þ ¼ ½1ðgðxÞÞ  1ð pÞðx0Þ
is concave on Rm due to 1( p)>0 and continuously diﬀerentiable on Rm
with gradient
r ^gðxÞ ¼ ðx0Þ
ðgðxÞÞ rgðxÞ þ ½1ðgðxÞÞ  1ð pÞrðx0Þ
Im
0

	
:
Let x 2 X be such that gðxÞ ¼ p and ^x 2 X be the element having the property
PðHð ^xÞÞ > p or, equivalently, ^gð ^xÞ > 0. Then the concavity of ^g implies
hr ^gðxÞ, ^x  xi > 0 and, thus, r ^gðxÞ 62 NXðxÞ. Due to the equation r ^gðxÞ ¼
ðx0Þ
ðgðxÞÞ rgðxÞ, we conclude rgðxÞ 62 NXðxÞ. Hence, the constraint qualiﬁcation
(3.45) and, thus, condition (ii) of Theorem 39 are satisﬁed.
u
For the remainder of this section we assume that the technology matrix
T(  ) is ﬁxed, i.e., T():T. We will show that the constraint qualiﬁcation of
Corollary 42, i.e., PðHð ^xÞÞ > p for some ^x 2 X, implies condition (ii) of
Theorem 39 for any r-concave probability distribution.
532
W. Ro¨misch

To recall the notion of r-concavity, we introduce ﬁrst the generalized mean
function mr on R þ  R þ  [0, 1] for r 2 [1, 1] by
mrða, b; Þ :¼
ðar þ ð1ÞbrÞ1=r, r 2 ð0, 1Þ or r 2 ð1, 0Þ, ab>0,
0,
ab ¼ 0, r 2 ð1, 0Þ,
ab1,
r ¼ 0,
maxfa, bg,
r ¼ 1,
minfa, bg,
r ¼ 1:
8
>>>>>><
>>>>>>:
ð3:47Þ
A measure P 2 P(Rs) is called r-concave for some r 2 [1, 1] (cf. Prekopa,
1995) if the inequality
PðB1 þ ð1  ÞB2Þ  mrðPðB1Þ, PðB2Þ; Þ
holds for all  2 [0, 1] and all convex Borel subsets B1, B2 of Rs such that
B1 þ ð1  ÞB2 is Borel. For r ¼ 0 and r ¼ 1, P is also called logarithmic
concave and quasi-concave, respectively. Since mr(a, b; ) is increasing in r if all
the other variables are ﬁxed, the sets of all r-concave probability measures are
increasing if r is decreasing. It is known that P 2 PðRsÞ is r-concave for some
r 2 [1, 1/s] if P has a density fP such that
fPðz þ ð1  Þ~zÞ  mrðsÞð fPðzÞ, fPð~zÞ; Þ,
ð3:48Þ
where rðsÞ ¼ rð1  rsÞ1, holds for all  2 [0, 1] and z, ~z 2 Rs. Let us mention
that many multivariate probability distributions are r-concave for some
r 2 (1, 1], e.g., the uniform distribution (on some bounded convex set), the
(nondegenerate) multivariate normal distribution, the Dirichlet distribution,
the multivariate Student and Pareto distributions (see Prekopa, 1995).
The key observation of r-concave measures in the context of probabilistic
constraints is the following one.
Lemma 43. Let H be a multifunction from Rm to Rs with closed convex graph
and P be r-concave for some r 2 [1, 1]. Then the function g :¼ PðHðÞÞ from
Rm to R has the property
gðx þ ð1  Þ ~xÞ  mrðgðxÞ, gð ~xÞ; Þ
for each x, ~x 2 Rm and  2 [0, 1].
Ch. 8. Stability of Stochastic Programming Problems
533

Proof. In particular, H(x) is a closed convex subset of Rs for any x 2 Rm. Let
x, ~x 2 Rm and  2 [0, 1]. Then the set HðxÞ þ ð1  ÞHð ~xÞ is also closed and
convex and it holds that HðxÞ þ ð1  ÞHð ~xÞ  Hðx þ ð1  Þ ~xÞ. Using the
r-concavity of P this implies
gðx þ ð1  Þ ~xÞ  mrðPðHðxÞÞ, PðHð ~xÞÞ; Þ ¼ mrðgðxÞ, gð ~xÞ; Þ:
u
Corollary 44. Let T():T and P be r-concave for some r 2 (1, 1]. Let X*(P)
be nonempty and U  Rm be an open bounded neighbourhood of X*(P). Assume
that there exists an element ^x 2 X such that PðHð ^xÞÞ > p holds.
Then there are constants L>0, >0 and k 2 N such that
j#ðPÞ  #UðQÞj  LphkðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðLphkðP, QÞÞB,
and X*UðQÞ is a CLM set for (3.44) relative to U whenever Q 2 P() and
phkðP, QÞ < . Here, the function P is given by (2.23).
Proof. We assume without loss of generality that r<0. Again we have to
verify the metric regularity condition (ii) of Theorem 39. To this end, we use
the function ^gðÞ :¼ pr  grðÞ instead of gðÞ :¼ PðHðÞÞ. Since P is r-concave,
the function ^gðÞ is concave on Rm. We consider the set-valued mapping
ðxÞ :¼ fv 2 R: x 2 X, ^gðxÞ  vg from Rm to R. Its graph is closed and convex.
Let x 2 X with gðxÞ ¼ p, i.e., ^gðxÞ ¼ pr. As there exists an ^x 2 X such that
gð ^xÞ > p, i.e., ^gð ^xÞ > 0, the element v ¼ 0 belongs to the interior of the range of
. Hence, the Robinson–Ursescu Theorem (Theorem 9.48 in Rockafellar and
Wets, 1998) implies the existence of constants a>0 and ">0 such that
dðx, 1ðvÞÞ  adðv, ðxÞÞ  a maxf0, v  ^gðxÞg
holds whenever x 2 X, kx  xk  " and jvj  ". For x 2 X with kx  xk  " and
suﬃciently small jyj we obtain
dðx, XyðPÞÞ ¼ dðx, 1ð pr  ð p  yÞrÞÞ  a maxf0, grðxÞ  ð p  yÞrg
Finally, it remains to use that the function v  vr is locally Lipschitz
continuous on (0, þ 1).
u
The above result improves in case of h(): and, hence, g(x) ¼ FP(Tx),
where FP is the distribution function of P. Then the polyhedral discrepancy
phk can be replaced by the Kolmogorov distance dK.
534
W. Ro¨misch

The next result provides a suﬃcient condition for (ii) in situations where P
is not quasiconcave, but has a density on Rs. Here, metric regularity is implied
by a growth condition of gðÞ ¼ FPðTÞ (see Henrion and Ro¨ misch, 1999).
Corollary 45. Let TðÞ:T, hðÞ:, P 2 PðRsÞ have a density fP, X*ðPÞ be
nonempty and U  Rm be an open bounded neighbourhood of X*ðPÞ. Assume the
following two conditions for each x 2 X*ðPÞ:
(i) ðTx þ bd Rs
Þ \ f 2 Rs : 9" > 0 such that fPð	Þ  ",8	 2  þ "Bg 6¼ ;,
(ii) there exists an ^x 2 X such that T ^x > Tx holds componentwise.
Then there are constants L > 0 and  > 0 such that
j#ðPÞ  #UðQÞj  L dKðP, QÞ
; 6¼ X*UðQÞ  X*ðPÞ þ PðL dKðP, QÞÞB,
and X*UðQÞ is a CLM set of (3.44) relative to U whenever Q 2 PðÞ and
dKðP,QÞ < . Here, the function P is given by (2.23).
The essential condition (i) says that, for each  2 TðX*ðPÞÞ, the boundary
of the cell  þ Rs
 meets the strict positivity region of the density of P
somewhere. This implies a suitable growth behaviour of the distribution
function FP at elements of TðX*ðPÞÞ, and hence metric regularity.
Finally, we study the growth function  P of (3.44) and derive conditions
implying quadratic growth near solution sets in case of hðÞ: and a
logarithmic concave measure P. The ﬁrst step of our analysis consists in a
reduction argument that decomposes problem (3.44) into two auxiliary
problems. The ﬁrst one is a stochastic program with modiﬁed objective and
probabilistic constraints (with decisions taken in Rs) whereas the second one
represents a parametric linear program. The argument is similar to Lemma 28
for two-stage models and was proved in Henrion and Ro¨ misch (1999).
Lemma 46. Let Q 2 PðRsÞ and U  Rm be a nonempty open set such that its
closure is a polytope. Then we have
#UðQÞ ¼ inffUðyÞ: y 2 TðXUÞ, FQð yÞ  pg and X*UðQÞ ¼ UðYUðQÞÞ,
where
XU ¼ X \ cl U,
YUðQÞ ¼ arg min fUð yÞ: y 2 TðXUÞ, FQð yÞ  pg,
Uð yÞ ¼ inff c,x
h
i: Tx ¼ y, x 2 XUg,
Uð yÞ ¼ arg min
c, x
h
i: Tx ¼ y, x 2 XU


ð y 2 TðXUÞÞ:
Ch. 8. Stability of Stochastic Programming Problems
535

Here, U is convex polyhedral on TðXUÞ and U is Lipschitz continuous on
TðXUÞ with respect to the Pompeiu–Hausdorﬀdistance on Rs.
Theorem 47. Let TðÞ:T, hðÞ:, P 2 PðRsÞ be logarithmic concave and
X*ðPÞ be nonempty and bounded. Assume that
(i) X*ðPÞ \ arg min f c,x
h
i: x 2 Xg ¼ ;;
(ii) there exists an x 2 X such that FPðTxÞ > p;
(iii) log FP is strongly concave on some convex neighbourhood V of
T ðX*ðPÞÞ.
Then there exist L > 0 and  > 0 and a neighbourhood U of X*ðPÞ such that
D1ðX*ðPÞ,X*UðQÞÞ  LdKðP, QÞ1=2
holds whenever Q 2 PðRsÞ and dKðP,QÞ < . Here, D1 denotes the Pompeiu–
Hausdorﬀdistance on subsets of Rm and dK the Kolmogorov metric on PðRsÞ.
Proof. Let U0  Rm be an open convex set such that X*ðPÞ  U0 and
TðU0Þ  V. For each x 2 X*ðPÞ select "ðxÞ > 0 such that the polyhedron
x þ "ðxÞB1 (with B1 denoting the closed unit ball w.r.t. the norm k  k1 on
Rm) is contained in U0. Since X*ðPÞ is compact, ﬁnitly many of these balls
cover X*ðPÞ. The closed convex hull U of their union is a polyhedron with
X*ðPÞ  U  U  U0, where U ¼ int U. With the notations of Lemma 46 we
consider the problem
minfUðyÞ: y 2 TðXUÞ, ^gðyÞ:¼ log p  log FPðyÞ  0g:
According to Lemma 46 the solution set YUðPÞ of this problem fulﬁls
X*ðPÞ ¼ X*UðPÞ ¼ UðYUðPÞÞ. Let y* 2 YUðPÞ and y ¼ Tx with x 2 X from
(ii). Then the logarithmic concavity of P implies for any  2 ð0,1:
^gðy þ ð1  Þy*Þ ¼ log p  log FPðy þ ð1  Þy*Þ
 log p  log FPðyÞ  ð1  ÞlogFPðy*Þ
 ðlog p  log FPðyÞÞ < 0:
Thus, we may choose ^ 2 ð0,1 such that ^y ¼ ^y þ ð1  ^Þy* belongs to
TðXUÞ and has the property ^gð^yÞ < 0. This constraint qualiﬁcation implies the
existence of a Kuhn–Tucker coeﬃcient *  0 such that
Uðy*Þ ¼ min fUðyÞ þ * ^gðyÞ: y 2 TðXUÞg
and
* ^gðy*Þ ¼ 0:
536
W. Ro¨misch

In case * ¼ 0, this would imply y* 2 arg min fUðyÞ: y 2 TðXUÞg and,
hence, the existence of some x* 2 X*ðPÞ with c, x*
h
i ¼ UðTx*Þ ¼ minf c, x
h
i:
Tx ¼ y*, x 2 XUg. Hence, condition (i) would be violated due to x* 2 int U.
Thus * > 0 and V þ * ^g is strongly convex on TðXUÞ. Hence, y* is the
unique minimizer of V þ * ^g and the growth property
ky  y*k2  Uð yÞ þ * ^gð yÞ  Uð y*Þ
ð3:49Þ
holds for some  > 0 and all y 2 TðXUÞ.
As the assumptions of Corollary 44 are satisﬁed, the set-valued mapping
X*UðÞ is upper semicontinuous at P and X*UðQÞ 6¼ ; is a complete local
minimizing set if dKðP,QÞ is suﬃciently small. Hence, there exists a  > 0 such
that ; 6¼ X*UðQÞ  U for all Q 2 PðRsÞ with dKðP:QÞ < . With the notations
from Lemma 46 and using the fact that YUðPÞ ¼ fy*g and X*ðPÞ ¼ X*UðPÞ ¼
Uðy*Þ we obtain
D1ðX*ðPÞ, X*UðQÞÞ ¼ D1ðUðy*Þ, UðYUðQÞÞÞ  ^L sup
y2YUðQÞ
ky  y*k,
where ^L > 0 is the Lipschitz constant of U (cf. Lemma 46). Using (3.49) and
YUðQÞ  TðXUÞ, the above chain of inequalities extends to
D1ðX*ðPÞ, X*UðQÞÞ 
^L
1=2
sup
y2YUðQÞ
½Uð yÞ þ * ^gð yÞ  Uð y*Þ1=2
¼
^L
1=2 ½#UðQÞ  #ðPÞ þ *ðlog p  logFPð yÞÞ1=2

^L
1=2 ½#UðQÞ  #ðPÞ þ *ðlog FQð yÞlog FPð yÞÞ1=2

^L
1=2
L þ *
p

	
dKðP, QÞ

1=2
,
where L > 0 is the constant from Theorem 39 and 1
p the Lipschitz constant of
logðÞ on ½ p, 1. This completes the proof.
u
A slightly more general version of the result for r-concave measures was
proved in Henrion and Ro¨ misch (1999). The assumptions (i)–(iii) imposed in
Theorem 47 concern the original problem. The conditions (i) and (ii) mean
that the probability level p is not chosen too low and too high, respectively.
Condition (i) expresses the fact that the presence of the probabilistic
constraint FPðTxÞ  p moves the solution set X*ðPÞ away from the one
obtained without imposing that constraint. Recent results in Henrion and
Ro¨ misch (2002) show that assumption (i) is not necessary for Theorem 47 to
hold. Assumption (iii) is decisive for the desired growth condition of the
Ch. 8. Stability of Stochastic Programming Problems
537

objective function around X*ðPÞ. In contrast to the global concavity of logFP,
(iii) requires the strong concavity of logFP as a local property around
TðX*ðPÞÞ. Since general suﬃcient criteria for (iii) are not available so far, we
provide a few examples.
Example 48. (strong logarithmic concavity of measures) Let P be the uniform
distribution on some bounded rectangle in Rs having the form D ¼ s
i¼1½ai,bi.
Then logFPðÞ ¼ Ps
i¼1 logði  aiÞ,  2 D. Clearly, logð  aiÞ is strongly con-
cave on any closed subinterval of ðai,biÞ. Hence, logFPðÞ is strongly concave
on any closed convex subset of int D.
Let P be the multivariate normal distribution on Rs having a nonsingular
diagonal covariance matrix. A direct computation for the standard normal dis-
tribution function  on R shows that log is strongly concave on any bounded
interval. Since logFP is equal to the sum of logarithms of the marginal
distribution functions, it is strongly concave on any bounded convex set in Rs.
4
Approximations of stochastic programs
Many approximations of stochastic programs result from replacing the
underlying probability distribution by some other measure, which typically
leads to simpler models. Important examples are nonparametric statistical
estimates (e.g., empirical ones) and scenario tree constructions using pro-
bability distribution information. Next we give an idea how the results of the
previous sections may be used to design and to analyse approximations of
stochastic programs. We begin with some glimpses into the analysis of
empirical approximations and the relations to empirical process theory. A
more far-reaching analysis is given in Pﬂug (2003) and Shapiro (2003).
4.1
A glimpse of empirical approximations
Let P 2 PðÞ and 1,2, . . . ,n, . . . be independent identically distributed -
valued random variables on a probability space ð,A,PÞ having the common
distribution P, i.e., P ¼ P1
1 . We consider the empirical measures
Pnð!Þ :¼ 1
n
X
n
i¼1
ið!Þ
ð! 2 ; n 2 NÞ,
where  denotes the unit mass at  2 , and the empirical approximations of
the stochastic program (1.1), i.e., the models that result from replacing P by
PnðÞ. These take the form
min
X
n
i¼1
F0ðx, iðÞÞ: x 2 X,
X
n
i¼1
Fjðx, iðÞÞ  0 , j ¼ 1, . . . ,d
(
)
,
ð4:50Þ
538
W. Ro¨misch

where the factor 1
n in the objective and constraints has been removed. Since the
objective and constraint functions Fj, j ¼ 0, . . . ,d, are assumed to be random
lower semicontinuous functions from Rm   to R, the constraint set is
closed-valued and measurable from  to Rm and, hence, the optimal value
#ðPnðÞÞ of (4.50) is measurable from  to R and the solution set X*ðPnðÞÞ is a
closed-valued measurable multifunction from  to Rm (see Chapter 14 and, in
particular, Theorem 14.37 in Rockafellar and Wets (1998)). The same
conclusion is valid for the localized concepts #U and X*U for any nonempty
open subset U of Rm.
Another measurability question arises when studying uniform convergence
properties of the empirical process
n
n
1
2ðPnðÞ  PÞF ¼ n1
2X
n
i¼1
ðFðiðÞÞ  PFÞ
o
F2F,
indexed by some class F of functions that are integrable with respect to P.
Here, we set QF :¼
R
 FðÞ dQðÞ for any Q 2 PðÞ and F 2 F. Since the
suprema dFðPnðÞ,PÞ ¼ supF2FjPnðÞF  PFj may be non-measurable func-
tions from  to R, we introduce a condition on F that simpliﬁes matters and is
satisﬁed in most stochastic programming models. A class F of measurable
functions from  to R is called P-permissible for some P 2 PðÞ if there exists
a countable subset F0 of F such that for each function F 2 F there exists a
sequence ðFnÞ in F0 converging pointwise to F and such that the sequence
ðPFnÞ also converges to PF. Then
dFðPnð!Þ, PÞ ¼ sup
F2F
jðPnð!Þ  PÞFj ¼ dF 0ðPnð!Þ, PÞ
holds for each n 2 N and ! 2 , i.e., the analysis is reduced to a countable
class and, in particular, dFðPnðÞ, PÞ is a measurable function from  to R.
A P-permissible class F is called a P-Glivenko–Cantelli class if the sequence
ðdFðPnðÞ, PÞÞ of random variables converges to 0 P-almost surely. If F is P-
permissible, the empirical process fn
1
2ðPnðÞ  PÞFgF2F is called uniformly
bounded in probability with tail CFðÞ if the function CFðÞ is deﬁned on ð0, 1Þ
and decreasing to 0, and the estimate
Pðf! : n
1
2dFðPnð!Þ, PÞ  "gÞ  CFð"Þ
ð4:51Þ
holds for each " > 0 and n 2 N. Whether a given class F is a P-Glivenko–
Cantelli class or the empirical process is uniformly bounded in probability
depends on the size of the class F measured in terms of certain covering
numbers or the corresponding metric entropy numbers deﬁned as their logari-
thms (e.g., Dudley (1984), Pollard (1990), van der Vaart and Wellner (1996)).
Ch. 8. Stability of Stochastic Programming Problems
539

To introduce these concepts, let F be a subset of the normed space Lrð, PÞ
for some r  1 equipped with the usual norm kFkP,r ¼ ðPjFjrÞ
1
r. The covering
number Nð", F, Lr ð, PÞÞ is the minimal number of open balls fG 2 Lrð, PÞ:
kG  FkP,r < "g needed to cover F. A measurable function FF from  to R is
called an envelope of the class F if jFðÞj  FFðÞ holds for every  2  and
F 2 F. The following result provides criteria for the desired properties in
terms of uniform covering numbers.
Theorem 49.
Let F be P-permissible with envelope FF. If PFF < 1 and
sup
Q
Nð"kFFkQ,1, F, L1ðQÞÞ < 1,
ð4:52Þ
then F is a P-Glivenko–Cantelli class. If F is uniformly bounded and there exist
constants r  1 and R  1 such that
sup
Q
Nð"kFFkQ,2, F, L2ðQÞÞ 
R
"
 	r
ð4:53Þ
holds for all " > 0, then the empirical process indexed by F is uniformly bounded
in probability with exponential tail CFð"Þ ¼ ðKðRÞ"r1
2Þrexpð2"2Þ with some
constant KðRÞ depending only on R.
The suprema in (4.52) and (4.53) are taken over all ﬁnitely discrete
probability measures Q with kFFkQ,1 ¼ QFF > 0 and kFFk2
Q,2 ¼ QF2
F > 0,
respectively.
For the proof we refer to Talagrand (1994), van der Vaart and Wellner
(1996) and van der Vaart (1998). For studying entropic sizes of stochastic
programs Pﬂug (1999, 2003) uses results of this type but with bracketing
numbers instead of uniform covering numbers. He also studies situations
where F is not uniformly bounded and shows that he blow-up function n
1
2 for
n ! 1 has to be replaced by some function converging to 1 more slowly.
Here, we use the concept of uniform covering numbers since they turn out to
be useful for discontinuous functions.
The stability results of Section 2 directly translate into convergence results
and rates, respectively, for empirical optimal values and solution sets.
Theorem 50. Assume that the conditions (i)–(iii) of Theorem 5 are satisﬁed and
that FU is P-permissible.
If FU is a P-Glivenko–Cantelli class, the sequences
ðj#ðPÞ  #UðPnðÞÞjÞ
and
sup
x2X*UðPnðÞÞ
dðx, X*ðPÞÞ
 
!
540
W. Ro¨misch

converge P-almost surely to 0. Furthermore, the set X*UðPnð!ÞÞ is a CLM set of
(4.50) relative to U for suﬃciently large n 2 N and for P-almost all ! 2 .
If the empirical process indexed by FU is uniformly bounded in probability
with tail CF UðÞ, the following estimates hold for each " > 0 and each n 2 N:
Pðj#ðPÞ  #UðPnðÞÞj > "n1
2Þ  CF U min , "
L
n
o


,
ð4:54Þ
P
sup
x2X*UðPnðÞÞ
dðx, X*ðPÞÞ > "n1
2
 
!
 CF Uðminf, ^L11
P ð"ÞgÞ:
ð4:55Þ
Proof. Let L > 0, ^L > 0,  > 0 be the constants in Theorems 5 and 9. First, let
F U be a P-Glivenko–Cantelli class and A 2 A be such that PðAÞ ¼ 0 and
ðdF UðPnð!Þ,PÞÞ converges to 0 for every ! 2 nA. Let ! 2 nA. Then
X*UðPnð!ÞÞ is nonempty, since the objective function
R
 F0ð,Þ dPðÞ is lower
semicontinuous on X and the constraint set XUðPnð!ÞÞ is compact due to
Proposition 3. Let n0ð!Þ 2 N be such that dF UðPnð!Þ,PÞ <  holds for each
n  n0ð!Þ. Due to the Theorems 5 and 9 the estimates
j#ðPÞ  #UðPnð!ÞÞj  dF UðPnð!Þ,PÞ
sup
x2X*UðPnð!ÞÞ
dðx,X*ðPÞÞ  Pð ^LdF UðPnð!Þ,PÞÞ
hold for n  n0ð!Þ. In particular, the sequences ðj#ðPÞ  #UðPnð!ÞÞjÞ and
ðsupx2X*UðPnð!ÞÞdðx, X*ðPÞÞÞ converge to 0. Hence, X*UðPnð!ÞÞ  U and, thus,
X*UðPnð!ÞÞ is a CLM set relative to U for suﬃciently large n 2 N.
Now, let " > 0 be arbitrary. The Theorems 5 and 9 also imply
Pðj#ðPÞ  #UðPnðÞÞj > "Þ  P dF UðPnðÞ, PÞ  min , "
L
n
o


,
ð4:56Þ
Pð
sup
x2X*UðPnðÞÞ
dðx, X*ðPÞÞ > "Þ  PðdF UðPnðÞ, PÞ  minf, ^L11
P ð"ÞgÞ:
ð4:57Þ
If the empirical process indexed by FU is uniformly bounded in probability
with tail CF UðÞ, the estimates (4.56) and (4.57) may be continued by using
(4.51) and, thus, lead to (4.54) and (4.55).
u
The estimates (4.54) and (4.55) may be used to derive the speed of
convergence in probability of optimal values and solution sets, respectively.
Clearly, the speed depends on the asymptotic behaviour of the tail CF Uð"Þ as
Ch. 8. Stability of Stochastic Programming Problems
541

" ! 1 and of the function P. For the situation of exponential tails, this is
elaborated in Rachev and Ro¨ misch (2002).
Next we show how our analysis applies to two-stage stochastic programs
with and without integrality requirements and to chance constrained models.
It turns out that, under reasonable assumptions on all models, the empirical
process indexed by F U is uniformly bounded in probability with exponential
tails.
Example 51. (linear chance constrained models) A class B of Borel sets of Rs is
called a Vapnik-Cˇervonenkis (VC ) class of index r ¼ rðBÞ if r is ﬁnite and equal
to the smallest n 2 N for which no set of cardinality n þ 1 is shattered by B.
B is said to shatter a subset f1, . . . ,lg of cardinality l in Rs if each of its
2l subsets is of the form B \ f1, . . . ,lg for some B 2 B. For VC classes B it
holds that
Nð",fB : B 2 Bg,L1ð,QÞÞ  K"r
for any " > 0 and Q 2 PðÞ, and some constant K > 0 depending only on the
index r (Theorem 2.6.4 in van der Vaart and Wellner (1996)).
For any polyhedral set   Rs and k 2 N the class BphkðÞ is a VC class,
since the class of all closed half spaces is VC and ﬁnite intersections of VC
classes are again VC. The corresponding class of characteristic functions is
permissible for P, since the set of all polyhedra in BphkðÞ having vertices at
rational points in Rs plays the role of the countable subset in the deﬁnition of
permissibility. Hence, Theorem 49 applies and the empirical process indexed
by F U ¼ fHðxÞ : x 2 X \ cl Ug, where U is a bounded open set containing
X*ðPÞ,
is
uniformly
bounded
in
probability
with
exponential
tail
CF Uð"Þ ¼ ^K"rexpð2"2Þ for some index r 2 N and some constant ^K > 0. For
example, from Theorem 50 we obtain for each " > 0 and n 2 N the estimate
P
sup
x2X*UðPnðÞÞ
dðx,X*ðPÞÞ > "n1
2
 
!
 ^K"rexpð2minf, ^L11
P ð"Þg2Þ:
Example 52. (two-stage models without integrality) Let F0 be deﬁned as in
Section 3.1 and let (A1) and (A2) be satisﬁed. Then, for each nonempty open
and bounded subset U of Rm, the class F U ¼ fF0ðx, Þ: x 2 X \ cl Ug is a
subset
of
L1ð, PÞ.
FU
is
also
permissible
for
P,
since
any
class
fF0ðx, Þ: x 2 Xcg with Xc being a countable and dense subset of X \ cl U
may be used as the countable subset of FU in the deﬁnition of permissibility.
Proposition 22 implies that the function FF UðÞ :¼ Kmaxf1, kk2g ( 2 ) is an
envelope of F U for suﬃciently large K > 0. Furthermore, due to the Lipschitz
continuity property of F0ð, Þ with Lipschitz constant
^Lmaxf1,kk2g (see
Proposition 22), the uniform covering numbers of F U are bounded by the
542
W. Ro¨misch

covering numbers of X \ cl U (see Theorem 2.7.11 in van der Vaart and
Wellner (1996)). In particular, for each ﬁnitely discrete measure Q 2 PðÞ and
with ^FðÞ :¼ ^Lmaxf1,kk2g ð 2 Þ it holds that
Nð"k ^FkQ,r, F U, Lrð,QÞÞ  Nð",X \ cl U, RmÞ  K"m,
ð4:58Þ
for each " > 0, r  1 and some constant K > 0 depending only on m and the
diameter of X \ cl U. Using (4.58) for r ¼ 1, Theorem 49 implies that F U is a
P-Glivenko-Cantelli class. If  is bounded, F U is uniformly bounded and,
using (4.58) for r ¼ 2, Theorem 49 implies that the empirical process indexed
by F U is uniformly bounded in probability with exponential tail.
Example 53. (mixed-integer two-stage models) Let F0 be deﬁned as in Section
3.2 and let (B1)–(B3) be satisﬁed and  be bounded. Then, for each nonempty
open and bounded subset U of Rm, the class
FU ¼
n
F0ðx,Þ ¼
X

j¼1
ð c,x
h
i þ ðhðÞ  TðÞxÞR
j,xðÞ: x 2 X \ cl U
o
is a subset of L1ð,PÞ. This representation follows from Proposition 34 if
R > 0 is chosen suﬃciently large such that f 2 : khðÞ  TðÞxk1 > Rg ¼ ;
for each x 2 X \ cl U. For each X \ cl U the sets R
j,x (j ¼ 1, . . . ,) form a
disjoint partition of  into Borel sets whose closures are in BphkðÞ for some
k 2 N. Furthermore, the function ðhðÞ  TðÞxÞ is Lipschitz continuous on
each of these sets with a uniform constant L1 > 0. Let Fj
0ðx,Þ denote a
Lipschitz extension of the function c,x
h
i þ ðhðÞ  TðÞxÞ from R
j,x to R by
preserving the Lipschitz constant L1 (j ¼ 1, . . . ,). Furthermore, let F j
U :¼
fFj
0ðx,Þ: x 2 X \ cl Ug and Gj
U :¼ fR
j,x : x 2 X \ cl Ug (j ¼ 1, . . . ,).
Now, we use a permanence property of the uniform covering numbers (cf.
Section 2.10.3 in van der Vaart and Wellner (1996)). Let Q 2 PðÞ be discrete
with ﬁnite support. Then the estimate
Nð"C0, F U, L2ð, QÞÞ
Y

j¼1
Nð"Cj, F j
U, L2ð, QjÞÞNð" ^Cj, G j
U, L2ð, ^QjÞÞ ð4:59Þ
is valid, where C0, Cj > 1, ^Cj, j ¼ 1, . . . ,, are certain constants and Qj, ^Qj,
j ¼ 1, . . . ,, certain discrete measures having ﬁnite support. The constants
depend on the bounds of the uniformly bounded classes F j
U and Gj
U,
j ¼ 1, . . . ,. Since the latter classes satisfy the condition (4.53) (see Example 51
and Example 52), the estimate (4.59) implies that FU satisﬁes (4.53), too.
Hence, we obtain the same estimates for mixed-integer two-stage models as in
Example 52 for two-stage models without integrality requirements and in
Example 51 for linear chance constrained models.
Ch. 8. Stability of Stochastic Programming Problems
543

Example 54. (newsboy continued) According to Example 15, the class FU is of
the form F U ¼ fF0ðx,Þ ¼ ðr  cÞx þ cmaxf0, x  g: x 2 X \ cl Ug with envel-
ope FF UðÞ ¼ r supX2 Xncl Ujxj þ cjj and a uniform Lipschitz constant c. Hence,
FU is a subset of L1ð,PÞ if
R
 jjdPðÞ ¼ P
k2N kk < 1. As in Example 52
we obtain
Nð"c,F U,L2ð,QÞÞ  Nð",X \ cl U,RmÞ  C"m
for each ﬁnitely discrete measure Q 2 PðÞ and, hence, Theorem 50 provides
the rate of convergence of the solution sets X*UðPnðÞÞ of (1.4) with linear P.
4.2
Scenario generation and reduction
Most of the numerical solution approaches for stochastic programs resort
to discrete approximations of the underlying probability measure P. Several
approaches have been developed for the generation or construction of discrete
approximations and are in use for solving applied stochastic programming
models (see the overview by Dupacˇ ova´
et al. (2000) and the references
therein). The quantitative stability results of Section 2.3 suggest another
approach, namely, to construct approximations for the original measure P
such that they are close to P with respect to the corresponding probability
(pseudo) metric. Let F be a set of measurable functions from  to R such that
the stochastic programming model (1.1) is stable in the sense of the Theorems
5 and 9 with respect to the (pseudo) metric
dFðP,QÞ ¼ sup
F2F
j
Z

FðÞdðP  QÞðÞj
or some other distance bounding dFðP,QÞ from above. This means that the
optimal values and the solution sets of (1.1) behave continuously at P when
perturbing P with respect to dF.
Then it is a natural requirement to construct approximate probability
distributions such that they are best approximations to P in the sense of dF.
For instance, the principle of optimal scenario generation with a prescribed
number of scenarios may be formulated as follows:
Given P 2 PðÞ and M 2 N, determine a discrete probability measure
Q* 2 PðÞ having M scenarios such that
dFðP, Q*Þ ¼ min dF

P,
X
M
j¼1
qjj
	
:
X
M
j¼1
qj ¼ 1, qj  0, j 2 , j ¼ 1, . . . ,M
(
)
:
544
W. Ro¨misch

Further constraints could be incorporated into the minimization problem,
e.g., constraints implying that the scenarios exhibit a tree structure.
Unfortunately, it seems to be hopeless to solve this problem for general
measures P, function classes F, supports , and large numbers M of scenarios.
However, it is of course a challenging problem to develop approaches for
solving the best approximation problem for more speciﬁc situations, like e.g.
for the unconstrained case  ¼ Rs, discrete measures P (involving very many
scenarios) and function classes that are relevant in Section 3. An approach for
solving the best approximation problem in case of  ¼ Rs and F ¼ F 1ðRsÞ is
developed in Pﬂug (2001).
Another
important
problem
consists
in
reducing
a
given
discrete
probability measure P ¼ PN
i¼1 pii with a (very) large number N of scenarios
to a measure containing n of the original scenarios with n << N. Similarly as
in case of optimal scenario generation, the problem of optimal scenario
reduction may be formulated in the form
min dF

 X
N
i¼1
pii,
X
j2J
qjj

: J  f1, . . . ,Ng,jJj ¼ n,
X
j2J
qj ¼ 1,qj  0
(
)
,
ð4:60Þ
i.e., as a nonlinear mixed-integer program. Since its objective function is
diﬃcult to compute for general classes F, solution methods for (4.60) are a
challenging task. However, in the special case that F ¼ F pðÞ, for some
p  1, the objective function of (4.60) turns out to be the dual optimal value of
the standard network ﬂow problem (see Rachev and Ru¨ schendorf (1998))
min
X
N
i¼1
j2J
cpði,jÞki  jk	ij : 	ij  0,
X
N
i¼1
	ij 
X
j2J
	ij ¼ qj  pi,8i, j
8
<
:
9
=
;
where
cpði,jÞ ¼ max 1,kikjk

p1,
i, j ¼ 1, . . . ,N,
and,
hence,
it
is
a
polyhedral function of q. Furthermore, in case of F ¼ F 1ðÞ problem
(4.60) simpliﬁes considerably.
Proposition 55. Given J  f1, . . . ,Ng we have
min dF 1ðÞ
X
N
i¼1
pii,
X
j2J
qjj
 
!
:
X
j2J
qj ¼ 1,qj  0
(
)
¼
X
i62J
pimin
j2J ki  jk:
Ch. 8. Stability of Stochastic Programming Problems
545

Moreover, the minimum is attained at qj ¼ pj þ P
i2Jj pi, for each j 2 J,
where Jj :¼ fi 62 J : j ¼ jðiÞg and jðiÞ 2 arg min
j2J ki  jk for each i 62 J.
The proposition provides an explicit formula for the redistribution of the
given probabilities pi, i ¼ 1, . . . ,N, to the scenarios with indices in J. For its
proof we refer to Theorem 2 in Dupacˇ ova´ et al. (2003). Due to Proposition 55
the optimal scenario reduction problem (4.60) in case of F ¼ F 1ðÞ takes the
form: Given P 2 PðÞ and n 2 N, determine a solution of
min
X
i62J
pi min
j2J ki  jk: J  f1, . . . ,Ng,jJj ¼ n
(
)
ð4:61Þ
and compute the optimal weights q according to the redistribution rule in
Proposition 55. Notice that problem (4.61) means that the set f1, . . . ,Ng has to
be covered by a subset J of f1, . . . ,Ng and by f1, . . . ,NgnJ such that jJj ¼ n
and the cover has minimal cost P
i62J piminj2Jki  jk. Hence, problem (4.61)
is of set-covering type and, thus, NP-hard. However, the speciﬁc structure of
the objective function allows the design of fast heuristic algorithms for its
approximate solution (see Dupacˇ ova´ et al. (2003), Heitsch and Ro¨ misch
(2003)). Depending on the size of the number n of remaining scenarios, the
two basic ideas are backward reduction and forward selection, respectively. In
the backward reduction heuristic an index set J ¼ fl1, . . . ,lng is determined
such that
li 2 arg min
l2J½i1
r
X
k2J½i1
r
nflg
pk
min
j62J½i1
r
nflg
kk  jk
ði ¼ 1, . . . ,nÞ,
where J½0
r
¼ f1, . . . ,Ng, J½i
r ¼ J½i1
r
nflig, i ¼ 1, . . . ,n. In the forward selection
heuristic the index set J ¼ fl1, . . . ,lng is chosen by an opposite strategy such
that
li 2 arg min
l62J½i1
s
X
k62J½i1
s
[flg
pk
min
j2J½i1
s
[flg
kk  jk
ði ¼ 1, . . . ,nÞ
holds, where J½0
s
¼ ;, J½i
s ¼ J½i1
s
[ flig, i ¼ 1, . . . ,n. We refer to Heitsch and
Ro¨ misch (2003) for a discussion of the complexity of both heuristics, for
implementation issues and encouraging numerical results.
546
W. Ro¨misch

5
Bibliographical notes
The beginnings of approximation and estimation results in stochastic
programming date back to the 1970s and the papers by Kall (1974) (see also
the monograph Kall (1976)), Marti (1975, 1979) and Olsen (1976) on
approximations, and the work of Kanˇ kova´
(1977) and Wets (1979) on
empirical estimation in stochastic programming. Surveys on stability were
published by Dupacˇ ova´ (1990) and Schultz (2000). The notion of stability of
stochastic programs appeared ﬁrst in Bereanu (1975), in the context of the
distribution problem, and in Kanˇ kova´ (1978), where stability of minima of
more general stochastic programming models was studied with respect to
weak convergence of measures for the ﬁrst time.
Later Dupacˇ ova´ (1984, 1987) and Wang (1985) studied the stability of
stochastic programs with respect to changes of ﬁnite-dimensional parameters
in the underlying probability distribution. Kall and Stoyan (1982), Salinetti
(1983) and Ro¨ misch (1981, 1985) dealt with discrete approximations to
stochastic programs. Further early work has been done in the surveys by Wets
(1983, 1989) and in Friedrich and Tammer (1981) (on stability), Birge and
Wets (1986) (on discrete approximation schemes), Ro¨ misch (1986b), Kall
(1987), Robinson and Wets (1987), Ro¨ misch and Wakolbinger (1987), Vogel
(1988), Kall, Ruszczyn´ ski and Frauendorfer (1988) (on discrete approxima-
tions), Dupacˇ ova´ and Wets (1988), Shapiro (1989) and Wang (1989). The
landmark papers by Kall (1987) and by Robinson and Wets (1987) address
qualitative stability results for optimal values and solution sets with respect to
weak convergence of measures. This line of research was continued in the
important work by Artstein and Wets (1994) and in Vogel (1992), Schultz
(1992, 1995), Lucchetti and Wets (1993), Wang (1995) and Wets (1998),
Zervos (1999) and Riis and Schultz (2002). Attempts to quantify such stability
results using distances of probability measures were started in Ro¨ misch
(1986b), Ro¨ misch and Wakolbinger (1987) and continued in Ro¨ misch and
Schultz (1991a,b,c, 1993, 1996) and Artstein (1994), Kankova´
(1994b),
Kankova´ (1998), Shapiro (1994), Fiedler and Ro¨ misch (1995), Schultz (1996),
Henrion and Ro¨ misch (1999, 2000), Dentcheva (2000) and Rachev and
Ro¨ misch (2002).
Most of the stability studies allow for general perturbations of the
underlying probability measure and develop a general framework for both
discrete and statistical approximations of stochastic programs. Nevertheless,
these two kinds of approximations developed independently by exploiting
their speciﬁc structures (e.g., bounding techniques on the one hand and
asymptotic
statistical
arguments
on
the
other
hand).
For
(discrete)
approximations we mention the work in Birge and Wets (1986), Kall et al.
(1988), Lepp (1990), Birge and Qi (1995a,b), Frauendorfer (1992, 1996) and
Kall (1998).
In parallel, statistical inference in stochastic programming models was
studied intensively. After the early work by Kankova´ and Wets, many authors
Ch. 8. Stability of Stochastic Programming Problems
547

contributed to this line of research on asymptotic properties of statistical
estimators, e.g., their consistency, rates of convergence and limit theorems.
We mention, in particular, the work of Dupacˇ ova´
and Wets (1988),
Vogel (1988), Shapiro (1989, 1990, 1991, 1996, 2000), King (1989) and
Kankova´ (1990, 1994), King and Wets (1991), Wets (1991), Ermoliev and
Norkin (1991), Norkin (1992), King and Rockafellar (1993), Rubinstein
and Shapiro (1993), Bouza (1994), Geyer (1994), Artstein and Wets (1995),
Kaniovski et al. (1995), Lachout (1995), Pﬂug (1995, 1999), Robinson (1996),
Gro¨ we (1997), Pﬂug et al. (1998a,b), Mak et al. (1999) and Shapiro and
Homem-de-Mello (2000).
Another line of research on approximations of stochastic programs is based
on the convergence (almost surely, in probability and in distribution) of
measurable set-valued mappings and on the epi-convergence of integrands.
Here, we mention the fundamental paper by Salinetti and Wets (1986) and the
work of Salinetti (1981, 1983), Ro¨ misch (1986a), Vogel (1988, 1992, 1994,
1995) and Wets (1991), Hess (1996) and the recent papers by Korf and Wets
(2000, 2001) and by Vogel and Lachout (2000).
Much is known on the stability of values and solutions of classical two-
stage stochastic programs (Section 3.1). The situation is already diﬀerent for
the stability of solutions to chance constrained models and even more to
mixed-integer two-stage models. The stability of multi-stage stochastic
programs is widely open, especially in the mixed-integer case. Another open
matter are the stability eﬀects of incorporating risk functionals into stochastic
programming models (cf. Section 2.4).The paper by Rachev and Ro¨ misch
(2002) provides an important source for the material presented in this chapter,
in particular, for the Sections 2.2, 2.3, and 4.1 and parts of the Sections 3.1
and 3.2. Some of the results are directly taken from that paper, namely,
Theorems 5, 9, 23 and 39. Some other results represent modiﬁed or extended
versions of those in Rachev and Ro¨ misch (2002) (e.g. Theorem 35 and
Theorem 50). Theorems 13 and 24 are due to work in preparation by Ro¨ misch
and Wets. Corollary 45 and Theorem 47 are taken from Henrion and Ro¨ misch
(1999) and the Corollaries 42 and 44 from Ro¨ misch and Schultz (1991c). The
Example 41 is due to Henrion and the notion of a Lipschitz continuous risk
functional goes back to Pﬂug (2002).
Acknowledgements
This work was supported by the Deutsche Forschungsgemeinschaft, in
particular, by the Schwerpunktprogramm Online Optimization of Large Scale
Systems. The author wishes to thank Darinka Dentcheva (Stevens Institute of
Technology) and Rene´ Henrion (Weierstrass Institute Berlin) for invaluable
discussions, in particular, on Steiner selections of set-valued maps and on the
stability of chance constrained models, respectively. Further thanks are due to
548
W. Ro¨misch

Georg Pﬂug (University of Vienna) and Roger Wets (University of California
at Davis) for valuable conversations on empirical processes and risk
functionals and on the stability of stochastic programs, respectively.
References
Artstein, Z. (1994). Sensitivity with respect to the underlying information in stochastic programs.
Journal of Computational and Applied Mathematics 56, 127–136.
Artstein, Z., R.J.-B. Wets (1994). Stability results for stochastic programs and sensors, allowing for
discontinuous objective functions. SIAM Journal on Optimization 4, 537–550.
Artstein, Z., R.J.-B. Wets (1995). Consistency of minimizers and the SLLN for stochastic programs.
Journal of Convex Analysis 2, 1–17.
Artzner, P., F. Delbaen, J.-M. Eber, D. Heath (1999). Coherent measures of risk. Mathematical
Finance 9, 203–228.
Attouch, H., R.J.-B. Wets (1993). Quantitative stability of variational systems II. A framework for
nonlinear conditioning. SIAM Journal on Optimization 3, 359–381.
Bank, B., J. Guddat, D. Klatte, B. Kummer, K. Tammer (1982). Non-Linear Parametric Optimization,
Akademie-Verlag, Berlin.
Bereanu,
B.
(1975).
Stable
stochastic
linear
programs
and
applications.
Mathematische
Operationsforschung und Statistik 6, 593–607.
Berge, C. (1963). Topological spaces, Oliver & Boyd, Edinburgh-London.
Billingsley, P. (1968). Convergence of Probability Measures, Wiley, New York.
Billingsley,
P.,
F.
Topsøe
(1967).
Uniformity
in
weak
convergence.
Zeitschrift
fu¨r
Wahrscheinlichkeitstheorie und verwandte Gebiete 7, 1–16.
Birge, J.R., L. Qi (1995a). Subdiﬀerential convergence in stochastic programs. SIAM Journal on
Optimization 5, 436–453.
Birge, J.R., L. Qi (1995b). Continuous approximation schemes for stochastic programs. Annals of
Operations Research 56, 15–38.
Birge, J.R., R.J.-B Wets (1986). Designing approximation schemes for stochastic optimization
problems, in particular for stochastic programs with recourse. Mathematical Programming Study
27, 54–102.
Blair, C.E., R.G. Jeroslow (1977). The value function of a mixed integer program. Discrete
Mathematics 19, 121–138.
Bonnans, J.F., A. Shapiro (2000). Perturbation Analysis of Optimization Problems, Springer-Verlag,
New York.
Bouza, C. (1994). Approximation of the value of the optimal solution in stochastic programming.
Revista Investigacion Operacional 15, 13–33.
Delbaen, F. (2002). Coherent risk measures on general probability spaces, in: K. Sandmann,
P.J. Scho¨ nbucher (eds.), Advances in Finance and Stochastics, Springer, Berlin, pp. 1–37.
Dentcheva, D. (2000). Regular Castaing representations of multifunctions with applications to
stochastic programming. SIAM Journal on Optimization 10, 732–749.
Dentcheva, D., W. Ro¨ misch (2000). Diﬀerential stability of two-stage stochastic programs. SIAM
Journal on Optimization 11, 87–112.
Dudley, R.M. (1984). A course on empirical processes, in: E´ cole d’E´ te´ de Probabilities de Saint-Flour
XII – 1982, Lecture Notes in Mathematics 1097, Springer, Berlin, pp. 2–142.
Dudley, R.M. (1989). Real Analysis and Probability, Wadsworth & Brooks/Cole, Paciﬁc Grove.
Dupacˇ ova´ , J. (1984). Stability in stochastic programming with recourse - estimated parameters.
Mathematical Programming 28, 72–83.
Dupacˇ ova´ , J. (1987). Stochastic programming with incomplete information: A survey of results on
postoptimization and sensitivity analysis. Optimization 18, 507–532.
Ch. 8. Stability of Stochastic Programming Problems
549

Dupacˇ ova´ , J. (1990). Stability and sensitivity analysis for stochastic programming. Annals of
Operations Research 27, 115–142.
Dupacˇ ova´ , J. (1994). Applications of stochastic programming under incomplete information. Journal
of Computational and Applied Mathematics 56, 113–125.
Dupacˇ ova´ , J., G. Consigli, S.W. Wallace (2000). Scenarios for multistage stochastic programs. Annals
of Operations Research 100, 25–53.
Dupacˇ ova´ , J., N. Gro¨ we-Kuska, W. Ro¨ misch (2003). Scenario reduction in stochastic programming:
An approach using probability metrics. Mathematical Programming, Ser. A 95, 493–511.
Dupacˇ ova´ , J., R.J.-B. Wets (1988). Asymptotic behaviour of statistical estimators and of optimal
solutions of stochastic optimization problems. The Annals of Statistics 16, 1517–1549.
Ermoliev, Y.M., V.I. Norkin (1991). Normalized convergence in stochastic optimization. Annals of
Operations Research 30, 187–198.
Fiedler, O., W. Ro¨ misch (1995). Stability in multistage stochastic programming. Annals of Operations
Research 56, 79–93.
Fo¨ llmer, H., A. Schied (2002). Convex risk measures and trading constraints. Finance and Stochastics
6, 429–447.
Fortet, R., E. Mourier (1953). Convergence de la re´ partition empirique vers la re´ partition the´ orique.
Ann. Sci. Ecole Norm. Sup. 70, 266–285.
Frauendorfer, K. (1992 Stochastic Two-Stage Programming, Lecture Notes in Economics and
Mathematical Systems, Vol. 392, Springer, Berlin.
Frauendorfer, K. (1996). Barycentric scenario trees in convex multistage stochastic programming.
Mathematical Programming 75, 277–293.
Friedrich, B., K. Tammer (1981). Untersuchungen zur Stabilita¨ t einiger Ersatzprobleme der
stochastischen Optimierung in bezug auf A¨ nderungen des zugrunde gelegten Zufallsvektors,
Wissenschaftliche Zeitschrift der Humboldt-Universita¨ t Berlin. Math.-Naturwiss. Reihe 30, 373–376.
Geyer, C.J. (1994). On the asymptotics of constrained M-estimation. The Annals of Statistics 22,
1993–2010.
Gro¨ we, N. (1997). Estimated stochastic programs with chance constraints. European Journal of
Operational Research 101, 285–305.
Heitsch, H., W. Ro¨ misch (2003). Scenario reduction algorithms in stochastic programming.
Computational Optimization and Applications 24, 187–206.
Henrion, R. (2000). Qualitative stability of convex programs with probabilistic constraints, in:
V.H. Nguyen, J.-J. Strodiot, P. Tossings (eds.), Optimization, Lecture Notes in Economics and
Mathematical Systems, Vol. 481, Springer, Berlin, pp. 164–180.
Henrion, R., W. Ro¨ misch (1999). Metric regularity and quantitative stability in stochastic programs
with probabilistic constraints. Mathematical Programming 84, 55–88.
Henrion, R., W. Ro¨ misch (2000). Stability of solutions to chance constrained stochastic programs, in:
J. Guddat, R. Hirabayashi, H.Th. Jongen, F. Twilt (eds.), Parametric Optimization and Related
Topics V, Peter Lang Verlag, Frankfurt a.M., pp. 95–114.
Henrion, R., W. Ro¨ misch (2002). Ho¨ lder and Lipschitz stability of solution sets in programs with
probabilistic constraints, Preprint No. 798, Weierstrass Institute for Applied Analysis and
Stochastics Berlin, and submitted.
Hess, C. (1996). Epi-convergence of sequences of normal integrands and strong consistency of the
maximum likelihood estimator. The Annals of Statistics 24, 1298–1315.
Kall, P. (1974). Approximations to stochastic programs with complete recourse. Numerische
Mathematik 22, 333–339.
Kall, P. (1976). Stochastic Linear Programming, Springer, Berlin.
Kall, P. (1987). On approximations and stability in stochastic programming, in: J. Guddat,
H.Th. Jongen, B. Kummer, F. Nozicka (eds.), Parametric Optimization and Related Topics,
Akademie-Verlag, Berlin, pp. 387–407.
Kall, P., A. Ruszczyn´ ski, K. Frauendorfer (1988). Approximation techniques in stochastic
programming, in: Y. Ermoliev, R.J.-B. Wets (eds.), Numerical Techniques for Stochastic
Optimization, Springer, Berlin, pp. 33–64.
550
W. Ro¨misch

Kall, P. (1998). Bounds for and approximations to stochastic linear programs with recourse, in:
K. Marti, P. Kall (eds.), Stochastic Programming Methods and Technical Applications, Lecture
Notes in Economics and Mathematical Systems, Vol. 458, Springer, Berlin, pp. 1–21.
Kaniovski, Y.M., A.J. King, R.J.-B. Wets (1995). Probabilistic bounds (via large deviations) for the
solutions of stochastic programming problems. Annals of Operations Research 56, 189–208.
Kankova´ , V. (1977). Optimum solution of a stochastic optimization problem with unknown
parameters, in: Transactions of the 7th Prague Conference on Information Theory, Statistical
Decision Functions and Random Processes, Academia, Prague, pp. 239–244.
Kankova´ , V. (1978). Stability in the stochastic programming. Kybernetika 14, 339–349.
Kankova´ , V. (1990). On the convergence rate of empirical estimates in chance constrained stochastic
programming. Kybernetika 26, 449–461.
Kankova´ , V. (1994). A note on estimates in stochastic programming. Journal of Computational and
Applied Mathematics 56, 97–112.
Kankova´ , V. (1994). On distribution sensitivity in stochastic programming, Research Report No. 1826,
Institute of Information Theory and Automation, Academy of Sciences of the Czech Republic.
Kanˇ kova´ , V. (1998). A note on multifunctions in stochastic programming, in: K. Marti, P. Kall (eds.),
Stochastic Programming Methods and Technical Applications, Lecture Notes in Economics and
Mathematical Systems, Vol. 458, Springer, Berlin, pp. 154–168.
King, A.J. (1989). Generalized delta theorems for multivalued mappings and measurable selections.
Mathematics of Operations Research 14, 720–736.
King, A.J., R.T. Rockafellar (1993). Asymptotic theory for solutions in statistical estimation and
stochastic programming. Mathematics of Operations Research 18, 148–162.
King, A.J., R.J.-B. Wets (1991). Epi-consistency of convex stochastic programs. Stochastics and
Stochastics Reports 34, 83–92.
Klatte, D. (1987). A note on quantitative stability results in nonlinear optimization, in: K.
Lommatzsch
(ed.),
Proceedings
19.
Jahrestagung
Mathematische
Optimierung,
Humboldt-
Universita¨ t Berlin, Sektion Mathematik. Seminarbericht Nr. 90, 77–86.
Klatte, D. (1994). On quantitative stability for non-isolated minima. Control and Cybernetics 23,
183–200.
Korf, L., R.J.-B. Wets (2000). Random lsc functions: scalarization, Stochastic Programming E-Print
Series 7.
Korf, L., R.J-B. Wets (2001). Random lsc functions: An ergodic theorem. Mathematics of Operations
Research 26, 421–445.
Lachout, P. (1995). On multifunction transforms of probability measures. Annals of Operations
Research 56, 241–249.
Lepp, R. (1990). Approximations to stochastic programs with complete recourse. SIAM Journal on
Control and Optimization 28, 382–394.
Louveaux, F., R. Schultz (2003). Stochastic Integer Programming, chapter 4, this volume.
Lucchetti, R., R.J.-B. Wets (1993). Convergence of minima of integral functionals, with applications to
optimal control and stochastic optimization. Statistics & Decisions 11, 69–84.
Lucchetti, R., G. Salinetti, R.J.-B. Wets (1994). Uniform convergence of probability measures:
Topological criteria. Journal of Multivariate Analysis 51, 252–264.
Mak, W.-K., D. Morton, R. Wood (1999). Monte Carlo bounding techniques for determining solution
quality in stochastic programs. Operations Research Letters 24, 47–56.
Marti, K. (1975). Approximationen der Entscheidungsprobleme mit linearer Ergebnisfunktion und
positiv homogener, subadditiver Verlustfunktion. Zeitschrift fu¨r Wahrscheinlichkeitstheorie und
verwandte Gebiete 31, 203–233.
Marti, K. (1979). Approximationen stochastischer Optimierungsprobleme, Mathematical Systems in
Economics Vol. 43, A. Hain, Ko¨ nigstein/Ts.
Mordukhovich, B.S. (1994a). Generalized diﬀerential calculus for nonsmooth and set-valued
mappings. Journal of Mathematical Analysis and Applications 183, 250–288.
Mordukhovich, B.S. (1994b). Lipschitzian stability of constraint systems and generalized equations.
Nonlinear Analysis, Theory, Methods & Applications 22, 173–206.
Ch. 8. Stability of Stochastic Programming Problems
551

Norkin, V.I. (1992). Convergence of the empirical mean method in statistics and stochastic
programming. Cybernetics and Systems Analysis 28, 253–264.
Ogryczak, W., A. Ruszczyn´ ski (1999). From stochastic dominance to mean-risk models: semideviation
as risk measures. European Journal of Operational Research 116, 33–50.
Olsen, P. (1976). Discretizations of multistage stochastic programming problems. Mathematical
Programming Study 6, 111–124.
Pﬂug, G. (1995). Asymptotic stochastic programs. Mathematics of Operations Research 20, 769–789.
Pﬂug, G. (1999). Stochastic programs and statistical data. Annals of Operations Research 85, 59–78.
Pﬂug, G. (2001). Scenario tree generation for multiperiod ﬁnancial optimization by optimal
discretization. Mathematical Programming Series B 89, 251–271.
Pﬂug, G. (2003). Stochastic Optimization and Statistical Inference, chapter 7, this volume.
Pﬂug, G., A. Ruszczynski, R. Schultz (1998a). On the Glivenko-Cantelli problem in stochastic
programming: Linear recourse and extensions. Mathematics of Operations Research 23, 204–220.
Pﬂug, G., A. Ruszczynski, R. Schultz (1998b). On the Glivenko-Cantelli problem in stochastic
programming: Mixed-integer linear recourse. Mathematical Methods of Operations Research 47,
39–49.
Pollard, D. (1990). Empirical Processes: Theory and Applications, NSF-CBMS Regional Conference
Series in Probability and Statistics Vol. 2, Institute of Mathematical Statistics.
Pre´ kopa, A. (1995). Stochastic Programming, Kluwer, Dordrecht.
Rachev, S.T. (1991). Probability Metrics and the Stability of Stochastic Models, Wiley, Chichester.
Rachev, S.T., W. Ro¨ misch (2002). Quantitative stability in stochastic programming: The method of
probability metrics, Mathematics of Operations Research, 27, 792–818.
Rachev, S.T., L. Ru¨ schendorf (1998). Mass Transportation Problems, Vol. I, Theory, Springer,
New York.
Riis, M., R. Schultz (2002). Applying the minimum risk criterion in stochastic recourse programs.
Computational Optimization and Applications (to appear).
Robinson, S.M. (1987). Local epi-continuity and local optimization. Mathematical Programming 37,
208–223.
Robinson, S.M. (1996). Analysis of sample-path optimization. Mathematics of Operations Research 21,
513–528.
Robinson, S.M., R.J-B Wets (1987). Stability in two-stage stochastic programming. SIAM Journal on
Control and Optimization 25, 1409–1416.
Rockafellar, R.T., R.J.-B. Wets (1998). Variational Analysis, Springer, Berlin.
Rockafellar, R.T., S. Uryasev (2002). Conditional value-at-risk for general loss distributions. Journal
of Banking & Finance 26, 1443–1471.
Ro¨ misch, W. (1981). On discrete approximations in stochastic programming, in: K. Lommatzsch (ed.),
Proceedings 13. Jahrestagung Mathematische Optimierung, Humboldt-Universita¨ t Berlin, Sektion
Mathematik. Seminarbericht Nr. 39, 166–175.
Ro¨ misch, W. (1985). An approximation method in stochastic optimization and control Mathematical
Control Theory, Vol. 14, Banach Center Publications, PWN, Warsaw, 477–490.
Ro¨ misch, W. (1986a). On the convergence of measurable selections and an application to
approximations in stochastic optimization. Zeitschrift fu¨r Analysis und Anwendungen 5, 277–288.
Ro¨ misch, W. (1986b). On convergence rates of approximations in stochastic programming, in: K.
Lommatzsch
(ed.),
Proceedings
17.
Jahrestagung
Mathematische
Optimierung,
Humboldt-
Universita¨ t Berlin, Sektion Mathematik. Seminarbericht Nr. 80, 82–91.
Ro¨ misch, W., R. Schultz (1991a). Distribution sensitivity in stochastic programming. Mathematical
Programming 50, 197–226.
Ro¨ misch, W., R. Schultz (1991b). Distribution sensitivity for certain classes of chance-constrained
models with application to power dispatch. Journal of Optimization Theory and Applications 71,
569–588.
Ro¨ misch, W., R. Schultz (1991c). Stability analysis for stochastic programs. Annals of Operations
Research 30, 241–266.
552
W. Ro¨misch

Ro¨ misch, W., R. Schultz (1993). Stability of solutions for stochastic programs with complete recourse.
Mathematics of Operations Research 18, 590–609.
Ro¨ misch, W., R. Schultz (1996). Lipschitz stability for stochastic programs with complete recourse.
SIAM Journal on Optimization 6, 531–547.
Ro¨ misch, W., A. Wakolbinger (1987). Obtaining convergence rates for approximations in stochastic
programming, in: Guddat, J., Jongen, H.T., Kummer, B., Nozicka, F. (eds.), Parametric
Optimization and Related Topics, Akademie-Verlag, Berlin, pp. 327–343.
Rubinstein, R.Y., A. Shapiro (1993). Discrete Event Systems, Sensitivity Analysis and Stochastic
Optimization by the Score Function Method, Wiley, Chichester.
Ruszczynski, A., A. Shapiro (2003). Stochastic Programming Models, chapter 1, this volume.
Salinetti, G. (1981). Convergence of measurable multifunctions: An application to stochastic
optimization problems, in: Castellani, G., Mazzoleni, P. (eds.), Mathematical Programming and
its Economic Applications, Angeli, Milano, pp. 757–774.
Salinetti, G. (1983). Approximations for chance-constrained programming problems. Stochastics 10,
157–179.
Salinetti, G., R.J.-B. Wets (1986). On the convergence in distribution of measurable multifunctions
(random sets), normal integrands, stochastic processes and stochastic inﬁma. Mathematics of
Operations Research 11, 385–419.
Schultz, R. (1992). Continuity and stability in two-stage stochastic integer programming, in: K. Marti
(ed.), Stochastic Optimization, Numerical Methods and Technical Applications, Lecture Notes in
Economics and Mathematical Systems, Vol. 379, Springer, Berlin, pp. 81–92.
Schultz, R. (1994). Strong convexity in stochastic programs with complete recourse. Journal of
Computational and Applied Mathematics 56, 3–22.
Schultz, R. (1995). On structure and stability in stochastic programs with random technology matrix
and complete integer recourse. Mathematical Programming 70, 73–89.
Schultz, R. (1996). Rates of convergence in stochastic programs with complete integer recourse. SIAM
Journal on Optimization 6, 1138–1152.
Schultz, R. (2000). Some aspects of stability in stochastic programming. Annals of Operations Research
100, 55–84.
Shapiro, A. (1989). Asymptotic properties of statistical estimators in stochastic programming. The
Annals of Statistics 17, 841–858.
Shapiro, A. (1990). On diﬀerential stability in stochastic programming. Mathematical Programming 47,
107–116.
Shapiro, A. (1991). Asymptotic analysis of stochastic programs. Annals of Operations Research 30,
169–186.
Shapiro, A. (1994). Quantitative stability in stochastic programming. Mathematical Programming 67,
99–108.
Shapiro, A. (1996). Simulation-based optimization – Concergence analysis and statistical inference.
Communications in Statistics – Stochastic Models 12, 425–454.
Shapiro, A. (2000). Statistical inference of stochastic optimization problems: Probabilistic Constrained
Optimization, Uryasev, S.P. (ed.), Kluwer, Dordrecht, pp. 282–307.
Shapiro, A. (2003). Monte Carlo Sampling Methods, chapter 6, this volume.
Shapiro, A., T. Homem-de-Mello (2000). On rate of convergence of optimal solutions of Monte Carlo
approximations of stochastic programs. SIAM Journal on Optimization 11, 70–86.
Talagrand, M. (1994). Sharper bounds for Gaussian and empirical processes. Annals of Probability 22,
28–76.
Talagrand, M. (1996). The Glivenko-Cantelli problem, ten years later. Journal of Theoretical
Probability 9, 371–384.
Topsøe, F. (1967). On the connection between -continuity and -uniformity in weak convergence.
Probability Theory and its Applications 12, 281–290.
Topsøe, F. (1977). Uniformity in convergence of measures. Zeitschrift fu¨r Wahrscheinlichkeitstheorie
und verwandte Gebiete 39, 1–30.
van der Vaart, A.W. (1998). Asymptotic Statistics, Cambridge University Press.
Ch. 8. Stability of Stochastic Programming Problems
553

van der Vaart, A.W., J.A. Wellner (1996). Weak Convergence and Empirical Processes, Springer,
New York.
Vogel, S. (1988). Stability results for stochastic programming problems. Optimization 19, 269–288.
Vogel, S. (1992). On stability in multiobjective programming–A stochastic approach. Mathematical
Programming 56, 91–119.
Vogel, S. (1994). A stochastic approach to stability in stochastic programming. Journal of
Computational and Applied Mathematics 56, 65–96.
Vogel, S. (1995). On stability in stochastic programming–Suﬃcient conditions for continuous
convergence and epi-convergence, Preprint No. M 12/95, Technical University Ilmenau, Faculty of
Mathematics and Natural Sciences.
Vogel, S., P. Lachout (2000). On continuous convergence and epi-convergence of random functions – I
and II, Research Report No. 1988 and 1989, Institute of Information Theory and Automation,
Academy of Sciences of the Czech Republic.
Walkup, D., R.J.-B. Wets (1969a). Lifting projections of convex polyhedra. Paciﬁc Journal of
Mathematics 28, 465–475.
Walkup, D., R.J.-B. Wets (1969b). A Lipschitzian characterization of convex polyhedra. Proceedings
of the American Mathematical Society 23, 167–173.
Wang, J. (1985). Distribution sensitivity analysis for stochastic programs with complete recourse.
Mathematical Programming 31, 286–297.
Wang, J. (1989). Continuity of feasible solution sets of probabilistic constrained programs. Journal of
Optimization Theory and Applications 63, 79–89.
Wang, J. (1995). Stability of multistage stochastic programming. Annals of Operations Research 56,
313–322.
Wets, R.J-B (1974). Stochastic programs with ﬁxed recourse: The equivalent deterministic program.
SIAM Review 16, 309–339.
Wets, R.J.-B. (1979). A statistical approach to the solution of stochastic programs with (convex) simple
recourse, Working Paper, Department of Mathematics, University of Kentucky, Lexington.
Wets, R.J.-B. (1983). Stochastic programming: Solution techniques and approximation schemes, in:
Bachem, A., Gro¨ tschel, M., Korte, B. (eds.), Mathematical Programming: the State-of-the-Art,
Springer, Berlin, pp. 566–603.
Wets, R.J.-B. (1989). Stochastic programming, in: G.L. Nemhauser, A.H.G. Rinnooy Kan, M.J. Todd
(eds.), Handbooks in Operations Research and Management Science, Vol. 1, Optimization, North-
Holland, Amsterdam, 573–629.
Wets, R.J.-B. (1991). Constrained estimation: Consistency and asymptotics. Applied Stochastic Models
and Data Analysis 7, 17–32.
Wets, R.J.-B. (1998). Stochastic programs with chance constraints: Generalized convexity and
approximation issues, in: Crouzeix, J.-P., Martı´nez-Legaz, J.-E., Volle, M. (eds.), Generalized
Convexity, Generalized Monotonicity: Recent Results, Kluwer, Dordrecht, pp. 61–74.
Zervos, M. (1999). On the epiconvergence of stochastic optimization problems. Mathematics of
Operations Research 24, 495–508.
Zolotarev, V.M. (1983). Probability metrics. Theory of Probability and its Applications 28, 278–302.
554
W. Ro¨misch

Chapter 9
Stochastic Programming in Transportation and
Logistics
Warren B. Powell and Huseyin Topaloglu
Department of Operations Research and Financial Engineering, Princeton University,
Princeton, NJ 08544, USA
Abstract
Freight
transportation
is
characterized
by
highly
dynamic
information
processes: customers call in orders over time to move freight; the movement
of freight over long distances is subject to random delays; equipment failures
require last minute changes; and decisions are not always executed in the ﬁeld
according to plan. The high-dimensionality of the decisions involved has made
transportation a natural application for the techniques of mathematical
programming, but the challenge of modeling dynamic information processes
has limited their success. In this chapter, we explore the use of concepts from
stochastic programming in the context of resource allocation problems that arise
in freight transportation. Since transportation problems are often quite large, we
focus on the degree to which some techniques exploit the natural structure of
these problems. Experimental work in the context of these applications is quite
limited, so we highlight the techniques that appear to be the most promising.
1
Introduction
Operational models of problems in transportation and logistics oﬀer a ripe
set of applications for stochastic programming since they are typically
characterized by highly dynamic information processes. In freight transporta-
tion, it is the norm to call a carrier the day before, or sometimes the same day,
to request that a shipment be moved. In truckload trucking, last minute phone
calls are combined with requests that can be made a few days in advance,
putting carriers in the position of committing to move loads without knowing
the last minute demands that will be made of them (sometimes by their most
important customers). In railroads, requests to move freight might be made a
week in the future, but it can take a week to move a freight car to a customer.
The eﬀect is the same.
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
555

The goal of this chapter is to provide some examples of problems, drawn
from the arena of freight transportation, that appear to provide a natural
application of stochastic programming. Optimization models in transporta-
tion and logistics, as they are applied in practice, are almost always
formulated based on deterministic models. Our intent is to show where
deterministic models can exhibit fundamental weaknesses, not from the
perspective of academic theory, but in terms of practical limitations as
perceived by people in industry. At the same time, we want to use the richness
of real problems to raise issues that may not have been addressed by the
stochastic programming community. We want to highlight what works, what
does not, and where there are rich areas for new research.
We do not make any eﬀort to provide a comprehensive treatment of
stochastic optimization problems in transportation and logistics. First, we
consider only problems in freight transportation (for the uninitiated,
‘‘transportation and logistics’’ refers to the operational problems surrounding
the movement of goods). These problems are inherently discrete, giving rise to
stochastic, integer programming problems, but we focus on problems where
linear programming formulations represent a good starting point. We
completely avoid the general area of stochastic vehicle routing or the types of
batch processes that often arise in the movement of smaller shipments, and
focus instead on problems that can be broadly described as dynamic resource
allocation problems.
Our presentation begins in Section 2 with an overview of diﬀerent classes of
applications. This section provides a summary of the diﬀerent types of
uncertainty that arise, and addresses the fundamental question of why
stochastic programming is a promising technology for freight transportation.
Section 3 provides a general modeling framework that represents a bridge
between linear programming formulations and a representation that more
explicitly captures the dimensions of transportation applications. In Section 4
we present a case study based on the distribution of freight cars for a railroad.
This case study provides us with a problem context where dynamic
information processes play an important role. We use this case study in the
remainder of the chapter to keep our discussions grounded in the context of a
real application.
We approach the stochastic modeling of our freight car problem in two
steps. First, we discuss in Section 5 the basic two-stage resource allocation
problem. This problem is particularly relevant to the car distribution problem.
The characteristics of the car distribution problem nicely illustrate diﬀerent
types of recourse strategies that can arise in practice. Specialized strategies
give way to approximations which exploit the underlying network structure.
For the most general case (network recourse) we brieﬂy review a broad range
of stochastic programming strategies, focusing on their ability to handle the
structure of transportation problems.
Section 6 addresses multistage problems. Our approach toward multistage
problems is that they can and should be solved as sequences of two-stage
556
W.B. Powell and H. Topaloglu

problems. As a result, we solve multistage problems by building on the theory
of two-stage problems.
Transportation problems oﬀer far more richness than can be covered in a
single chapter. Section 8 provides a hint of the topics that we do not attempt
to cover. We close with Section 9 that discusses some of the challenges of
actually implementing stochastic models in an operational setting.
2
Applications and issues
It is important to have in mind a set of real problems that arise in
transportation and logistics. We begin our discussion of applications by listing
some sample problems that arise in practice, and then use these problems: (a)
to discuss sources of uncertainty; (b) to raise special modeling problems that
arise in transportation applications; and ﬁnally (c) to highlight, from a
practical perspective, the limitations of deterministic models and how
stochastic programming can improve the quality of our models from a
practical perspective.
2.1
Some sample problems
Transportation, fundamentally, is the business of moving things so that
they are more useful. If there is a resource at a location i, it may be more
useful at another location j. Within this simple framework, there is a
tremendous variety of problems that pose special modeling and algorithmic
issues. Below is a short list of problems that helps to highlight some of the
modeling issues that we will have to grapple with.
1) Product distribution—Perhaps one of the oldest and most practical
problems is the determination of how much product to ship from a plant
to intermediate warehouses before ﬁnally shipping to the retailer (or
customer). The decision of how much to ship and where must be made
before we know the customer demand. There are a number of important
variations of this problem, including:
a) Separability of the distribution process—It is often the case that each
customer will be served by a unique warehouse, but substitution
among warehouses may be allowed.
b) Multiple product types with substitution—A company may make
multiple product types (for example, diﬀerent types of salty food
snacks) for a market that is willing to purchase diﬀerent products
when one is sold out. For the basic single period distribution
problem, substitution between products at diﬀerent locations is the
same as substitution across diﬀerent types of products, as long as the
substitution cost is known (when the cost is a transportation cost,
Ch. 9. Stochastic Programming in Transportation and Logistics
557

this is known, whereas when it represents the cost of substituting for
diﬀerent product types, it is usually unknown).
c) Demand backlogging—In multiperiod problems, if demand is not
satisﬁed in one time period, we may assume the demand is lost or
backlogged to the next time period. We might add that the same issue
arises in the product being managed; highly perishable products
vanish if not used at a point in time, whereas nonperishable products
stay around.
2) Container management—Often referred to as ﬂeet management in the
literature, ‘‘containers’’ represent boxes of various forms that hold
freight. These might be trailers, boxcars, or the intermodal containers
that are used to move goods across the oceans (and then by truck
and rail to inland customers). Containers represent a reusable resource
where the act of satisfying a customer demand (moving freight from
i to j) also has the eﬀect of changing the state of the system (the
container is moved from i and j). The customer demand vanishes from
the system, but the container does not. Important problem variations
include:
a) Single commodity problems—These arise when all the containers are
the same, or when there are diﬀerent container types with no
substitution between diﬀerent types of demands. When there is no
substitution, the problem decomposes into a series of single
commodity problems for each product type.
b) Multicommodity problems—There may be diﬀerent container types,
and the customers may be willing to substitute between them. For
example, they may accept a bigger container, or be willing to move
their dry goods in a refrigerated container (although no refrigeration
is necessary).
c) Time windows and demand backlogging—The most common model
represents customer demands at a point in time, where they are lost if
they are not served at that point in time. In practice, it is usually the
case that customer orders can be delayed.
d) Transshipment and relay points—The simplest models represent a
demand as the need to move from i to j, and where the movement is
represented as a single decision. More complex operations have to
model transportation legs (ocean or rail movements) with relays or
transshipment points (ports, rail yards) where the containers move
from one mode to the next. A major element of complexity is when
capacity constraints are imposed on the transportation legs.
3) Managing complex equipment—The major railroads in North America
need to manage ﬂeets of several thousand locomotives. The air mobility
command has to move freight and people on a global scale using
diﬀerent types of aircraft. Recently formed companies service a high end
558
W.B. Powell and H. Topaloglu

market with personal jet service using jets in which the customers own
a fraction. These problems have been modeled in the past using the
same framework as container management problems with multiple
container types. These complex pieces of equipment require something
more. For example, there are four major classes of locomotive, reﬂecting
whether they are high or low ‘‘adhesion’’ (a technology that determines
the slippage of the wheels on a rail), and whether they are four axle or
six axle units (six axle locomotives are more powerful). On closer
inspection, we ﬁnd that the horsepower rating of a locomotive can be
divided into 10 or 12 reasonable divisions. It matters if the locomotive
has its home shop in Chicago, Atlanta or southern California. Since
locomotives may move from the tracks of one railroad to another,
it matters who owns the locomotive. And it matters if the locomotive
is due into the shop in 1,2, . . . , 10 days, or more than 10 days.
In short, complex equipment is complex, and does not lend itself
easily to a multicommodity formulation. As we show later, this
characteristic determines whether the size of the attribute space of a
resource is small enough to enumerate the entire space, or too large to
enumerate.
4) People and crews—Trucks, trains and planes move because people
operate them. Not surprisingly, the modeling of the people is not only
important, but requires a set of attributes that makes complex equip-
ment look simple. A truck driver, for example, might be characterized
by his current location, his home base, his skill level, whether he has
experience driving into Mexico or Canada, how many hours he has
driven in the last 8 days, how many consecutive hours he has been ‘‘on
duty’’ today, and how many hours he has been actively driving during
his current duty period. Production software systems have to cover these
and many other issues.
These problems are all examples of resource allocation problems where, with
few exceptions, a single ‘‘resource’’ serves a single ‘‘demand.’’ ‘‘Bundling’’
arises when, for example, you need several locomotives to pull a single train,
or two drivers (a sleeper team) to operate a single truck. ‘‘Layering’’ arises
when you need an aircraft, a pilot, fuel and special loading equipment to move
a load from one airbase to another. In some cases, the resource/task
dichotomy breaks down. For example, we may be managing locomotives,
crews and boxcars. The boxcar needs to go from A to B. We need the crew to
move the train, but the crew needs to get back to its home domicile at C. And
the locomotive needs to get to shop at D. We would refer to the locomotives,
crew and boxcars as three resource layers, since the locomotives, crew and
boxcars are all needed to move the train. In fact, for more complex problems,
we refer to the objects being managed as resource layers (or sometimes,
resource classes), where one layer is almost always one that would be referred
to as a customer, or job, or task.
Ch. 9. Stochastic Programming in Transportation and Logistics
559

2.2
Sources of uncertainty
Uncertainty arises whenever we need to make a decision based on
information that is not fully known. We are aware of three scenarios under
which this can arise:
1) The information is not yet known, but will become known at some point
in the future. This is the standard model of uncertainty.
2) Information is known to someone (or something), but is not known to
the decision-maker. We would generally say that this information is
knowable but for various reasons (most commonly, it is simply too
expensive)
has
not
been
properly
communicated
to
where
the
information is needed for a decision.
3) The information will never be known (optimization under incomplete
information). For any of a variety of economic or technical reasons, an
unknown variable is never measured, even though it would help improve
decisions. Since the information is never known, we are not able to
develop a probability distribution for it.
Cases (2) and (3) above both represent instances where decisions have to be
made without information, but we assume that case (3) represents information
that never becomes known explicitly, whereas (2) represents the case where
someone knows the information, raising the possibility that the information
could be shared (at a cost) or at a minimum, where a probability distribution
might be constructed after the fact and shared with others.
Classical uncertainty arises because information arrives over time. It is
possible to divide the diﬀerent types of dynamic information processes into
three basic classes: the ‘‘resources’’ being managed (including customer
demands), the physical processes that govern the evolution of the system over
time, and the decisions that are actually implemented to drive the system. This
division reﬂects our modeling framework, presented in Section 3. Since the
focus of this volume is on modeling uncertainty, it is useful to give each of
these at least a brief discussion.
Resources
Under the heading of ‘‘resources’’ we include all the information classes
that we are actively managing. More formally, these are ‘‘endogenously
controllable information classes which constrain the system,’’ a deﬁnition that
includes not just the trucks, trains and planes that we normally think of as
resources, but also the customer orders that these resources are normally
serving. Dynamic information processes for resources may include:
a) Information about new (exogenous) arrivals to the system—This
normally includes the arrival of customer orders, but may also include
the arrivals of the product, equipment or people required to satisfy the
customer order. For example, a trucking company is constantly hiring
560
W.B. Powell and H. Topaloglu

new drivers (there is a lot of turnover) so the arrival of new drivers to the
ﬂeet is a dynamic information process. Similarly, a railroad has to
manage boxcars, and the process of boxcars becoming empty turns out
to be a highly stochastic process (far more uncertain than the customer
orders).
b) Information about resources leaving the system—Drivers may quit,
locomotives may be retired from service, product can perish. The
challenge of modeling departures is that they depend on the state of the
system, whereas exogenous arrivals are normally modeled as being
independent of the state of the system.
c) Information about the state of a resource—An aircraft may break down
or a driver may call in sick.
An important dimension of the modeling of resources is the concept of
knowability and actionability. It is not uncommon for a customer to call in and
book an order in advance. Thus, the order becomes known right now (time t)
but actionable when it actually arrives to the system at some point in the
future (at time t0  t). Most stochastic models implicitly assume that a
customer demand is not known until it actually arrives. By contrast, most
deterministic models assume that we know all orders in advance (or more
precisely, that we do not want to make a decision taking into account any
order that is not already known). In practice, both extremes arise, as well as
the case of prebooking where customers call at least some of their orders in
advance.
Processes
Under this category, we include information about parameters that govern
the evolution of the system over time. The most important classes include:
a) The time required to complete a decision—In most areas of trans-
portation, travel times are random, and sometimes highly so (although
applications vary in the degree to which random travel times actually
matter). In air traﬃc control problems, planes may land at 20 minute
intervals. Flights of several hours can easily vary in duration by 10 or
20 minutes, so they have to maintain a short backlog of ﬂights to ensure
that there is always an aircraft available to land when the runway has
the capacity to handle another arrival. In railroads, it is not unusual for
the travel time between two points to take anywhere from 5 to 8 days.
b) The cost of a decision—This is often the least uncertain parameter, but
there are a number of reasons why we might not know the cost of a
decision until after the fact. Costs which are typically not fully known in
advance include tolls, transportation accidents, and processing costs
that are not always easy to allocate to a particular activity. Even
more uncertain is the revenue that might be received from satisfying
a customer which might arise as a result of complex accounting
procedures.
Ch. 9. Stochastic Programming in Transportation and Logistics
561

c) Parameters that determine the attributes of a resource after a decision—
Examples might include the fuel consumption of an aircraft or
locomotive (which determines the fuel level), or the maintenance status
of the equipment at the end of a trip.
Controls
In real problems, there is a diﬀerence between the decisions that we are
planning to make, and the decisions that are actually made. The ﬂow of actual
decisions is an important exogenous information process. There are several
reasons why an actual physical system does not evolve as planned:
1) The decisions made by a model are not as detailed as what is actually
needed in operations. The user has to take a plan developed by the
model and convert it into something implementable.
2) The user has information not available to the model.
3) The user simply prefers to use a diﬀerent problem solving approach
(possibly suboptimal, but this assumes the solution provided by the
model is in some way optimal).
When there is a diﬀerence between what a model recommends and the
decisions that are actually made, we encounter an instance of the user non-
compliance problem. This is a source of uncertainty that is often overlooked.
2.3
Special modeling issues in transportation
Transportation problems introduce an array of issues that provide special
modeling and algorithmic challenges. These include:
a) Time staging of information—In freight transportation, information
arrives over time. This is the heart of any stochastic model.
b) The lagging of information—Often, a customer will call at time t to
place an order to be served at time t0>t. The same lagging of
information may apply to the vehicles used to serve customers. Since we
have information about the future, it is tempting to assume that we can
make plans about the future, even before new information becomes
known.
c) Complex resource attributes—It is often assumed that the number of
diﬀerent types of resources is ‘‘not too large.’’ The number of resource
types determines the number of constraints. In practice, the attributes of
resources can be surprisingly complex, creating problems where the
number of constraints can number in the millions. This is a challenge
even for deterministic models, but poses special diﬃculties in the context
of stochastic problems.
d) Integrality—Many transportation problems exhibit network structure
that makes it much easier to obtain integer or near-integer solutions.
This structure can be easily destroyed when uncertainty is introduced.
562
W.B. Powell and H. Topaloglu

e) Travel times—The common behavior in transportation problems that it
takes time to move from one location to the next is generally a minor
issue in deterministic models. In stochastic models, it can introduce
major complications. If the travel times are deterministic, the result can
be a dramatic growth in the size of the state space. However, it is often
the case that travel times not only are stochastic, they are not even
measurable when the trip is initiated.
f) Multi-agent control—Large transportation systems might be controlled
by diﬀerent agents who control speciﬁc dimensions of the system. The
decisions of other agents can appear as random variables to a particular
agent.
g) Implementation—What we plan may not be the same as what actually
happens. An overlooked source of uncertainty is the diﬀerence between
planned and executed decisions.
2.4
Why do we need stochastic programming?
There are two types of modeling technologies that are widely used in
practice: simulation models, which are used almost entirely for planning
purposes where there is a need to understand the behavior of a system that
evolves over time, and deterministic optimization models and algorithms,
when there is a need for the computer to recommend what action should be
taken. Stochastic programming brings the modeling of uncertainty explicitly
into the process of making a decision (using an optimization algorithm). But,
there is a large community of both academic researchers and consultants who
feel that they are being quite productive with the algorithms that they are
developing based on deterministic models.
There is a broad perception, in both the academic research community
and in engineering practice, that deterministic optimization algorithms are
‘‘good enough.’’ In part this can be attributed to both the mathematical
maturity that has been required to understand stochastic models, and the lack
of practical, problem-solving tools. But equally important, we need to
understand the ways in which stochastic models can provide solutions that are
not just better, but noticeably better in a way that would attract the attention
of industry. An understanding of these issues will also indicate where
stochastic models are not necessarily appropriate. A partial list of motivations
for stochastic models should include:
1) The newsvendor eﬀect—Providing the right amount of resource to meet
demand given the uncertainty in demand and the relative costs of
providing too much or too little. A deterministic model will never
allocate more than the point forecast, even when there are excess
resources. Stochastic models can overallocate or underallocate depend-
ing on the overall availability of resources to meet forecasted demands.
Ch. 9. Stochastic Programming in Transportation and Logistics
563

2) Robust allocation—We might need the container in city A or city C, but
we are not sure, so we send the truck halfway in between to city B where
it can wait and respond to the demand at the last minute. A
deterministic model will never send capacity to a location that does not
need it.
3) The value of advance information—Stochastic models can explicitly
model the staging of information over time. A carrier might want to
know the value of having customers book orders farther in advance. A
proper analysis of this question needs to consider the value of reducing
the uncertainty in a forecast.
4) Forecasts of discrete items—Sometimes it is necessary to forecast low
volume demands; for example, orders might be 1 with probability 0.20
and 0 with probability 0.80. A point forecast would produce a demand
of 0.20, but a routing and scheduling model is unable to assign 0.20
trucks to the order (the algorithm routes a single truck). Integer
rounding amounts to little more than Monte Carlo sampling (simple
rounding produces biases—it is necessary to round based on a random
sample whose expectation is the same).
5) The algorithmic challenge of solving problems over extended planning
horizons—Classical optimization algorithms struggle with optimization
problems deﬁned over long horizons, typically as a result of degeneracy.
Formulations based on a stochastic ‘‘view’’ of the world produces
time-staged problems that are much easier to solve. Sequences of two-
stage problems are much easier to solve than a single, large integer
program.
6) Overoptimizing problems with imperfect data—A deterministic view of
the world can produce problems that are larger and more complex than
necessary. An appreciation of uncertainty, not only of the future but
also of the ‘‘here and now’’ data (which in practice is a major form of
uncertainty) produces models that are smaller and more compact.
3
Modeling framework
The ﬁrst chapter of this handbook provides a basic mathematical
framework for multistage stochastic programming problems. The problem
with these abstract formulations is spanning the gap between generic mathe-
matical formulations and real problems. In this section, we oﬀer a notational
framework that helps to bridge the gap between real-world dynamic resource
allocation problems, and the basic framework of math programming in
general, and stochastic programming in particular.
We divide our modeling framework between three fundamental dimen-
sions: the resources being managed, the processes that govern the dynamics of
the system, and the structure and organization of controls which manage the
system. Our presentation is not the most general, but allows us to focus on the
564
W.B. Powell and H. Topaloglu

dimensions that are important for modeling the organization and ﬂow of
information.
3.1
Resources
To help formalize the discussion, we oﬀer the following deﬁnition:
Deﬁnition 1. A resource is an endogenously controllable information class
that constrains the system.
From a math programming perspective, a resource is anything that shows
up as a right hand side of a constraint (no surprise that these are often referred
to as ‘‘resource constraints’’). For transportation, resources include trucks,
trains, planes, boxcars, containers, drivers/crews, and special equipment that
may be needed to complete a trip. Sometimes, but not always, the ‘‘demands’’
being served also meet this deﬁnition. For example, the load of freight that we
are moving from one location to the next is both endogenously controllable
(we often have to determine when to move the load, and sometimes how it is
routed) and it constrains the system.
We describe resources using the following:
CR
¼ The set of resource classes (e.g., tractors, trailers, drivers, freight).
Rc
¼ The set of (discrete) resources in class c 2 CR.
ar
¼ The attributes of resource r 2 Rc, c 2 CR.
Ac
¼ The space of attributes for resource class c 2 CR, with element ac 2 Ac.
We often use A to represent the attribute space of a generic resource.
The attribute vector is a very ﬂexible device for describing the charac-
teristics of a resource. In truckload trucking, it might be the case that all
trucks are the same, in which case the attribute vector consists only of the
location of the truck. In rail car distribution, the attribute vector can be the
type of car as well as the location. If the resource is a human operator,
the vector can grow to include attributes such as the home domicile, days
away from home, hours of service, and skill sets.
The deﬁnition of the attribute space requires an understanding of how a
resource evolves over time, and in particular the ﬂow of information. For
example, an air cargo carrier working for the military airlift command might
have to move a load of cargo from the eastern United States to southeast Asia.
This trip might require midair refueling, as well as stops at several
intermediate airbases. Is it necessary to represent the aircraft at each of these
intermediate points, or is it enough to assign the aircraft to move a load, and
then model its status at the destination? The answer depends on the evolution
of information and decisions. For example, if we can completely model all the
steps of a trip using the information available when the aircraft ﬁrst takes oﬀ
from the origin, then there is no need to model the intermediate points. But we
Ch. 9. Stochastic Programming in Transportation and Logistics
565

might wish to model the possibility of a failure in the midair refueling, or the
failure of the aircraft itself at any of the intermediate airbases. Both of these
represent examples of new information arriving to the system, which requires
modeling the status of the aircraft just before the new information arrives. The
new information may produce new decisions (we may wish to reroute the
aircraft) or a change in the dynamics (the aircraft may be unexpectedly
delayed at an airbase).
The need to model our aircraft at intermediate points raises a new and
even more complex issue. An aircraft that is fully loaded with freight takes
on the characteristics of a layered (or composite) resource. That is, we
have not only the characteristics of the aircraft, but also the characteristics of
the freight on the aircraft. This sort of layering arises frequently in
transportation operations. Another example arises in the management of
locomotives. A locomotive may be sitting idle at a rail yard, or it may be
attached to an inbound train (which is making an intermediate stop). If the
locomotive is attached to an inbound train, then we have not only the
attributes of the locomotive, but also of the train itself (such as its ﬁnal
destination).
We handle this behavior by deﬁning layered attribute vectors. For example,
let:
aA
¼ The attributes of an aircraft.
aR
¼ The attributes of a load of freight being moved (known as
requirements).
aC
¼ The attributes of the crew piloting the aircraft.
When an aircraft is loaded and making a set of stops, then the attributes of
the composite resource at the intermediate stops would be represented using:
a(A) ¼ The attributes of the aircraft layer.
¼ aA j aR j aC, where aA, aR and aC are the attributes of the primitive
aircraft, requirement and crew resources.
A layer is a concatenation of attributes. An aircraft which is currently
sitting idle (a primitive resource) would have the attribute a(A) ¼ aA j a j a.
In more complex problems, we may encounter three, four or even ﬁve
layers. For these problems, we have to deﬁne in advance how resources may
be combined.
Regardless of our problem class, we let:
Rt,a ¼ The number of resources with attribute a 2 A at time t.
Rt
¼ ðRt,aÞa2A.
One issue that often arises in transportation is the concept of knowability
and actionability. We may know of a resource r with attribute ar at time t
566
W.B. Powell and H. Topaloglu

which is not actionable until some time t0>t. This can arise when a customer
calls in an order in advance, or when a plane takes oﬀfrom airport i at time t
but will not arrive at airport j until time t0. Actionability can arise as an
‘‘estimated time of arrival,’’ an order pickup time, or the time when a task
(such as maintenance) will be ﬁnished. Actionability can be viewed as being
simply an attribute of a resource, and therefore part of the vector a. But often,
the actionable time is suﬃciently important that it needs to be represented
explicitly. In this case, we write:
Rt,at0 ¼ Number of resources that we know about with attribute a at time t
that will not be actionable until time t0  t.
Rtt0
¼ ðRt,at0Þa2A:
Rt
¼ ðRtt0Þt0t:
Thus, we can continue to use the vector Rt as our general state vector,
recognizing that it may be divided into elements Rtt0.
This discussion illustrates a division in the operations research community
on the meaning of a time index. Deterministic models of time-staged processes
always use time to refer to when an action will happen (‘‘actionability’’).
Stochastic models almost always use time to refer to the information content
of a variable (‘‘knowability’’ or, in formal terms, ‘‘measurability’’). In general
problems, it is necessary to use both, but this can sometimes be clumsy. We
use the double time index (t, t0) when we want to explicitly refer to the
information content of a variable (‘‘t’’), and when an activity actually takes
place (‘‘t0’’). Whenever we use a single time index, such as Rt, we will always
intend the time index to refer to the information content.
3.2
Processes
A dynamic process evolves because of two types of information processes:
exogeneous information processes, that arrive as a series of events which
update the state of the system, and endogenous information processes,
otherwise known as decisions. Following the conventions described in the ﬁrst
chapter of this volume, we let:
t
¼ The information arriving in time period t.  can represent new
information about customer demands, new equipment entering the
system, equipment breakdowns, and travel delays.

¼ ðtÞt2T
¼ The information process over the model horizon represented by the
set of time periods T.
In general, new information arriving from external sources is captured in a
knowledge base which summarizes all the information known at time t.
Following standard convention, we let Ft be the -algebra generated by the
vector (0, . . . , t).
Ch. 9. Stochastic Programming in Transportation and Logistics
567

The standard representation of information in real problems does not
always follow standard assumptions. To illustrate, let:
Kt
¼ Our (data) knowledge base at time t.
UK
¼ The knowledge updating function which updates Kt1 using new
information t.
We would representing our updating process as:
Kt  UKðKt1, tÞ
Realizing that Ft1  Ft, one would expect that (Kt) (the -algebra
generated by the random variable Kt) would satisfy (Kt1)  (Kt). This
assumes that computer databases do not ‘‘forget’’ information. But this is not
always the case. It is not our intent to raise this as a serious issue, but just as a
reminder to the reader that standard mathematical assumptions do not always
apply to the real world.
For our problems, we can typically divide new information into two classes:
the arrivals of new resources (including new customer demands, as well as new
equipment or new drivers), and information about model parameters (such as
costs and times). This distinction is important in our problem representation,
so we deﬁne:
^t
¼ Updates to model parameters arriving in time period t.
^Rtt0
¼ The vector of new resources arriving in time period t that become
actionable at time t0  t.
^Rt
¼ ð ^Rtt0Þt0t:
Thus, we would write t ¼ ð ^t, ^RtÞ with sample realization !t ¼ tð!Þ ¼
ð ^tð!Þ, ^Rtð!ÞÞ.
We represent decisions using:
CD
¼ The set of decision classes (move empty, move loaded, refuel,
maintain the equipment, have a driver go on rest, etc.)
Dc
¼ The set of discrete decisions in decision class c 2 CD.
D
¼ [c2CD Dc
We use D to refer to the complete set of decisions. In most transportation
applications, it is useful to capture the fact that the set of decisions also
depends on the attribute of the resource being acted on. For this purpose we
deﬁne:
Da
¼ The set of decisions that can be used to act on a resource with
attribute a 2 A.
568
W.B. Powell and H. Topaloglu

For the purposes of our presentation, we consider only direct decisions that
act on the attributes of a resource (this would exclude, for example, decisions
about pricing or what speed to ﬂy an aircraft). For transportation problems, if
d 2 D is an instance of a decision, then the impact of the decision is captured
through the modify function, which is a mapping:
MðKt, a, dÞ ! ða0, c, Þ
ð2:1Þ
where d is a decision acting on a (possibly layered) resource with attribute a at
time t producing a resource with attribute a0, generating a contribution c and
requiring time  to complete the action. a0, c and  are all functions, which we
can represent using the triplet ðaMðt, a, d Þ, cMðt, a, d Þ, Mðt, a, d ÞÞ (for nota-
tional compactness, we index these functions by time t instead of modeling the
explicit dependence on Kt). We call aMðt, a, d Þ the terminal attribute function.
Normally, we represent the costs and times using the vectors ctad ¼ cMðt, a, dÞ
and tad ¼ Mðt, a, d Þ. We note as an aside that while we will usually model
ðaMðt, a, d Þ, cMðt, a, d Þ, Mðt, a, d ÞÞ as Ft—measurable, this is certainly not
always the case. For example, Section 4 describes an application in rail car
distribution. In this application, empty freight cars are moved to customers to
move loads of freight. The destination of a load is typically not known until
the car is released loaded back to the railroad. The travel time of the
movement is not known until the car actually reaches the destination.
The set D is the set of types of decisions we make. The decision vector itself
is represented using:
xtad ¼ The number of times that we act on a resource with attribute a using
decision d at time t.
xt
¼ ðxtadÞa2A, d2D:
¼ The vector of decisions at time t.
Letting ct similarly represent the vector of contributions at time t provides
for a compact representation that matches standard modeling notation. Most
transportation costs are linear in the decision variables, and as a result, the
total contribution at time t can be written as:
CtðxtÞ ¼
X
a2A
X
d2D
ctadxtad
¼ ctxt:
It is important to realize that our notation for stochastic problems is
diﬀerent in a subtle but important way than the notation conventionally used
in deterministic transporation models. For example, it is normal to let xijt be
the ﬂow from location i to location j departing at time t. The index j eﬀectively
Ch. 9. Stochastic Programming in Transportation and Logistics
569

presumes a deterministic outcome of the decision (the notation xijt(!) does not
ﬁx the problem; we would have to write xi, jð!Þ, t which is quite ugly). We might
not question the outcome of a decision to send a truck or plane from i to j
(frequent ﬂiers will remember at least one occasion when the plane did not
arrive at the proper destination as a result of weather problems). But in more
complex problems where we are capturing a larger vector of attributes, the
terminal attribute function aMðt, a, d Þ cannot in general be assumed to be a
deterministic function of (t, a, d ). The representation of a decision using xtad is
important for stochastic problems since the variable is indexed only by
information available when the decision is made.
For algebraic purposes, it is useful to deﬁne:
t0,a0ðt, a, dÞ ¼ Change in the system at time t0 given a decision
executed at time t:
¼
1
if Mtðt, a, dÞ ¼ ða0,  , t0  tÞ
0
otherwise

We note that if d represents a decision to couple two resources, then a is the
attributes of the resource, d contains the information about the resource being
coupled with, and a0 is the concatenation of two attribute vectors.
Using this notation, we can now write the dynamics of our resource
variable (incorporating the time-lagging of information):
Rtþ1,a0t0 ¼ Rt,a0t0þ ^Rtþ1,a0t0ð!Þ þ
X
d2D
X
a2A
t0,a0ðt, a, dÞxtad
a0 2 A,
t0 > t:
ð2:2Þ
3.3
Controls
It is common in transportation problems to focus on decisions that move
resources from one location to the next. While this is the most obvious
dimension, it is important to capture other types of decisions.
Our notation for representing decisions oﬀers considerable ﬂexibility. It is a
common misconception in the modeling of transportation systems that
decisions always represent movements from one location to another.
Examples of diﬀerent classes of decisions other than spatial movements
include: cleaning dirty vehicles, repairing or maintaining equipment, sending a
driver oﬀ-duty, using outside contractors to perform a task, transferring rail
cars from one shipper pool to another (this is a form of classiﬁcation, and does
not mean moving from one location to another), buying/selling/leasing
equipment, and hiring/ﬁring drivers.
570
W.B. Powell and H. Topaloglu

In deterministic problems, decisions are made by solving a particular
instance of an optimization problem. In stochastic problems, we have to
capture the time staging of decisions and information. We represent the
process of making decisions at time t using:
It
¼ The set of information available for making a decision.
X
t ðItÞ ¼ The decision function of policy  2  which returns a vector xt
given the information set It.
In Section 3.6, we describe diﬀerent classes of information, and the types of
decision functions these produce.
For our problems, the decision function will be some sort of mathematical
program, since the decisions typically are vectors, possibly of fairly high
dimensionality. Later we provide speciﬁc examples of decision functions, but
for now, we simply assume that they produce feasible solutions. The most
important constraint that must be satisﬁed is ﬂow conservation:
X
d2D
xtad ¼ Rta
8a 2 A:
In addition, the ﬂows must be nonnegative and, in many applications
(virtually all involving operational problems in transportation) integer.
3.4
Modeling state variables
It is useful at this point to make a brief comment about ‘‘state variables,’’
since these take on diﬀerent meanings in diﬀerent communities. In our modeling
framework, the attribute vector a captures the ‘‘state’’ of a particular resource.
Rt ¼ ðRtaÞa2A is the ‘‘state’’ of the vector of resources. It (which we have not
completely deﬁned) is the ‘‘information state’’ of the system. In some
subcommunities (notably, people who solve crew scheduling problems using
column generation techniques), the management of multiple resources is
decomposed into subproblems involving the optimization of a single resource.
In this context, someone might talk about a large ‘‘state space’’ but refer to the
attribute space of a single resource.
It is very common in the operations research literature (most commonly in
the context of dynamic programming and Markov decision processes) to talk
about the ‘‘state’’ of the system, where the state variable captures the amount
of product being stored or the customer demands that have been backlogged.
In this setting, the ‘‘state’’ of the system refers to the resource state variable,
Rt. Even recently, discrete dynamic programming models have been proposed
using Rt as the state variable. Not surprisingly, the number of possible
realizations of Rt (assuming it is discrete) will be huge even for toy problems.
Ch. 9. Stochastic Programming in Transportation and Logistics
571

Of course, the real state variable must be what we know or, literally, the
state of our knowledge, which we denote by Kt. Other authors refer to this as
the information state. We let It be the information state, but claim that there
are potentially four classes of information:
a) Knowledge—This is the data in the vector Kt, capturing the exogenous
data that has been provided to the system.
b) Forecasts
of
exogenous
processes—This
is
information
from
a
forecasting model, representing projections of what might happen in
the future. If we are making a decision at time t, this would be a
projection of ð ^tþ1, ^tþ2, . . . , ^TÞ. We may use a point forecast of future
events, or forecast a set of future scenarios which would be represented
using the set ^t (the set of future events forecasted at time t). If j ^tj ¼ 1,
then we are using a traditional point forecast.
c) Forecasts of the impact of decisions now on the future. In this chapter,
this dimension will be captured through the recourse function and hence
we denote the set of possible recourse functions, estimated at time t (but
capturing the impact on the future) by Qt.
d) Plans—These are projections of decisions to be made in the future,
which can be expressed in a variety of ways (it is useful to think of these
as forecasts of future decisions). A convenient way is to represent them
as a vector of decisions x p
t ¼ ðx p
tt0Þt0t, where x p
tt0 is the plan for time t0
using the information available at time t. We note that plans are almost
always expressed at some level of aggregation. Normally, we use plans
as a guide and penalize deviations from a plan.
The last three classes of information are all forms of forecasts. We assume
that these are generated from data that is a function of Kt. However, while a
forecast is generated from knowledge, they do not represent knowledge itself.
All companies seek to improve decision-making by improving the knowledge
base Kt, but they also consider the value of including forecasts (many
transportation companies do not perform short term operational forecasts,
and most research into problems such as dynamic vehicle routing does not use
forecasts) or future plans. Companies make explicit decisions to add these
classes of information to their decision making process (and adjust the process
accordingly).
Using this deﬁnition of information, the information state can come in a
variety of forms, such as It ¼ (Kt), It ¼ ðKt, ^tÞ, It ¼ ðKt, x p
t Þ and It ¼ (Kt, Qt).
Later we show that diﬀerent classes of information give rise to the major
classes of algorithms known in the operations research community. For
the moment, it is necessary only to understand the diﬀerent ways of
representing the ‘‘state’’ of the system. Our notation contrasts with the
standard notation St for a state variable. The problem is that St is not
very explicit about what is comprising the state variable. We suggest using St
when we want to refer to a generic ‘‘state,’’ and use a, Rt, Kt or It when we
want to express explicit dependence on, respectively, the attribute of a single
572
W.B. Powell and H. Topaloglu

resource, the resource state vector, the entire knowledge base, or a broader
information set.
Using these notions of state variables, it is useful to revisit how we write our
cost and decision functions. The representation of costs and decisions using
the notation ctad and xtad suggests that both the costs and decisions are a
function only of the attribute vector of the resource, although this does not
have to be the case. We may write the decision function as X (Rt) if all other
types of information are static. The reader may write X (Kt) to express the
explicit dependence on the larger knowledge base, but this generality should
be reserved for problems where there are parameters which are evolving over
time, and whose values aﬀect the forward evolution of the system.
3.5
The optimization problem
Our problem is to ﬁnd a decision function X  that solves the following
expression:
F* ¼ sup
2
EF
ð2:3Þ
¼ sup
2
E
X
t2T
CtðX
t ðItÞÞ
(
)
:
ð2:4Þ
The system has to respect the following equations governing the physical
and information dynamics:
Physical dynamics:
Rtþ1,a0t0ð!Þ¼Rt,a0t0ð!Þþ ^Rtþ1,a0t0ð!Þþ
X
d2D
X
a2A
t0,a0ðt, a, dÞxtad
a0 2A, t0 >t:
ð2:5Þ
Informational dynamics:
Ktþ1 ¼ UKðKt, tþ1Þ:
ð2:6Þ
The decision function X
t is assumed to produce a feasible decision. For this
reason, ﬂow conservation constraints and upper bounds are not included in
this formulation.
The optimization problem is one of choosing a function. The structure of
the decision function depends on the information available. Within an
information class, a decision function is typically characterized by a family of
parameters and we have to choose the best value for these parameters.
Ch. 9. Stochastic Programming in Transportation and Logistics
573

3.6
A brief taxonomy of problems
Using our modeling framework, we can provide a brief taxonomy of major
problem classes that arise in transportation. We divide our taxonomy along
the three major dimensions of resources, processes and controls.
Resources
By just using the attribute vector a notation, we can describe six major
problem classes in terms of the resources being managed:
1) Basic inventory problems—a ¼ {} (no attributes). This is the classical
single product inventory problem.
2) Multiproduct inventory problems—a ¼ {k} where k 2 K is a product type.
3) Single commodity ﬂow problems—a ¼ {i} where i 2 I is a state variable
(such as a city or geographical location).
4) Multicommodity ﬂow problems—a ¼ {i, k} where i 2 I is a state variable
(such as a location) and k 2 K is a commodity class.
5) Heterogeneous resource allocation problem—a ¼ {a1, a2, . . . , aN}. In
these more complex problems, it is possible to divide the attribute vector
into static attributes, as which do not change over time, and dynamic
attributes, ad, which do change. Writing a ¼ {as, ad}, we can think of ad
as a resource state variable, and as as a resource type variable.
6) The multilayered resource allocation problem—a ¼ fa1 j a2 j    j aLg
where ac is the attributes of resource class c. Here, a is a concatenation
of attribute vectors.
Although the sixth class opens the door to multilayered problems, it is
useful to divide resource allocations between single layer problems, two-layer
problems (which most often involve an active resource layer representing
people or equipment, and a passive layer representing customer requests), and
multilayer problems.
We focus on single layer problems in this chapter, which include the ﬁrst
ﬁve types of attribute vectors. Of these, the ﬁrst four are typically
characterized by small attribute spaces, where it is possible to enumerate all
the elements in A, while heterogeneous resource allocation problems are
typically characterized by an attribute space that is too large to enumerate. As
we point out later, this creates special problems in the context of stochastic
resource allocation problems.
System dynamics
Under the heading of system dynamics, we divide problems along three
major dimensions:
1) The time staging of information—The two major problem classes are:
a) Two-stage problems.
b) Multistage problems.
574
W.B. Powell and H. Topaloglu

2) Travel times (or more general, decision completion times). We deﬁne
two major classes:
a) Single-period times—tad ¼ 1 for all a 2 A, d 2 D.
b) Multiperiod times—1  tad  max. We assume that tad  1 but we
can relax this requirement and model problems where tad ¼ 0.
3) Measurability of the modify function. We again deﬁne two major
classes:
a) The
function
M(t, a, d)
is
Ft—measurable.
This
means
that
ðaMðt, a, dÞ, cMðt, a, dÞ, Mðt, a, dÞÞ is deterministic given a, d and
other parameters that are known at time period t.
b) The function M(t, a, d) is not Ft-measurable. This is common,
although we are not aware of any research addressing this issue.
Controls
We ﬁrst divide problems into two broad classes based on control structure:
1) Single agent control structure—The entire company is modeled as being
controlled by a single agent.
2) Multiagent control structure—We model the division of control between
multiple agents.
Starting with the single agent control structure, we can organize problems
based on the information available to make a decision. Earlier, we described
four classes of information. We can now describe four classes of algorithms
built around these information sets:
a) It ¼ (Kt)—This is our classic myopic algorithm, widely used in simu-
lations. This is also the standard formulation used (both in practice and
in the research community) for dynamic vehicle routing problems, and
other on-line scheduling problems.
b) It ¼ ðKt, ^tÞ—If j ^tj ¼ 1, this is our classical rolling horizon procedure
using a point forecast of the future. This represents standard engineer-
ing practice for ﬂeet management problems and other dynamic
resource allocation problems. If j ^tj > 1, then we would obtain a
scenario-based stochastic programming model. The use of these
formulations for multistage problems in transportation and logistics is
very limited.
c) It ¼ ðKt, xp
t Þ—Here we are making decisions reﬂecting what we know
now, but using plans to help guide decisions. This information set
typically gives rise to proximal point algorithms, where the proximal
point term penalizes deviations from plan.
d) It ¼ (Kt, Qt)—This information set gives rise to dynamic programming
formulations, Benders decomposition and other methods for approx-
imating the future. Typically, the recourse function Qt is itself a function
Ch. 9. Stochastic Programming in Transportation and Logistics
575

of a distributional forecast ^t, so it is appropriate to write Qtð ^tÞ to
express this dependence.
This breakdown of diﬀerent types of decision functions, each based on
diﬀerent types of information, nicely distinguishes engineering practice
(It ¼ (Kt) or It ¼ ðKt, ^tÞ with j ^j ¼ 1) from the stochastic programming
literature (It ¼ ðKt, ^tÞ with j ^j > 1 or It ¼ ðKt, QtÞ). The use of proximal
point algorithms has been studied in the stochastic programming literature,
but the use of plans (generated from prior data) to help guide future decisions
is often overlooked in the modeling and algorithmic community. If stochastic
programming is to gain a foothold in engineering practice (within the trans-
portation and logistics community), it will be necessary to ﬁnd the problem
classes where the more advanced decision sets add value.
Complex problems in transportation, such as railroads, large trucking
companies and the air traﬃc control system, are characterized by multiple
decision-making agents. We would represent this structure by deﬁning:
Dq
¼ The subset of decisions over which agent q has control.
Itq
¼ The information available to agent q at time t.
Then X
tqðItqÞ is the decision function for agent q given information Itq at
time t.
Multiagent systems capture the organization of information. By contrast,
classical stochastic programming models focus on the ﬂow of information. In
transportation, modeling information is important, but we typically have to
capture both the organization and ﬂow. We also ﬁnd that in a multiagent
system, we may have to forecast the behavior of another agent (who may work
within the same company). This can be an important source of uncertainty in
large operations.
4
A case study: freight car distribution
When moving freight by rail (for the purposes of this discussion, we exclude
the movement of intermodal freight such as trailers and containers on
ﬂatcars), a shipper requests one or more cars, of a particular type, at his dock
for a particular day. The request may be for one or two cars, or as many as
100 or more. The railroad identiﬁes speciﬁc cars that can be assigned to the
request, and issues a ‘‘car movement order’’ to get the car to the shipper. The
car may be in a nearby yard, requiring only the movement of a ‘‘local’’ train to
get the car to the shipper. Just as easily, the car may have to move from a
much farther location through a sequence of several trains before arriving at
the ﬁnal destination.
Freight cars come in many types, often looking the same to the untrained
eye but appearing very diﬀerent to the shipper. For example, there are 30 types
576
W.B. Powell and H. Topaloglu

of open top gondola cars (‘‘gons’’ in the industry). When a railroad cannot
provide the exact type of car from the closest depot on the correct day, it may
resort to three types of substitution:
1) Geographic substitution—The railroad may look at diﬀerent sources of
cars and choose a car that is farther away.
2) Temporal substitution—The railroad may provide a car that arrives on
a diﬀerent day.
3) Car type substitution—The railroad may try to satisfy the order using a
slightly diﬀerent car type.
Once the decision has been made to assign a car to a customer request, the
railroad begins the process of moving a car to the destination. If the car is far
away, this may require movements on several trains, passing through one or
more intermediate classiﬁcation yards which handle the sorting process. Travel
times are long, and highly variable. It can take up to two or three weeks to
move an empty car to a customer, wait for it to load, move it loaded, and then
wait for it to unload (known as a car cycle). Travel times typically range
between one and ﬁve days or more. Travel times between a pair of locations
that averages six days can see actual transit times between four and eight days.
From the perspective of car distribution, there are three important classes
of dynamic information: the ﬂow of customer requests for capacity, the
process of cars becoming empty (either because a shipper has emptied and
released the car or because another railroad has returned the car empty), and
the travel times for cars moving from one location to another. Customer
orders are typically made the week before the car is actually needed, but some
orders are made more than a week in advance, and some orders are made at
the last minute (especially from large, high priority customers). There is very
little advance information about empty cars, and of course, transit times are
only known after the movement is completed. Thus, we see information
processes where the diﬀerence when a resource is knowable and actionable is
large (customer orders), small (empty cars), and where the modify function is
not Ft-measurable.
It is useful to get a sense of the variability of the data. Fig. 1 is an actual
graph of the demand for cars at a regional level, showing actual, predicted,
and both 10th and 90th percentiles. This graph ignores the presence of booked
orders, and in practice, most orders are known a week into the future. For this
reason, customer orders are not the largest source of uncertainty in an
operational model. A much more signiﬁcant source of error arises from the
forecast of empty cars. Fig. 2 shows a similar graph for a particular type of
freight car at a speciﬁc location. We again see a large degree of variability. In
this case, there is little advance information.
One of the most diﬃcult sources of uncertainty arises in transit times. In
railroads, it is not unusual to see transit times that range between 5 and 10
days. This source of noise is particularly problematic. It means that if we ship
10 cars from i to meet a demand at j, we are not sure when they will arrive.
Ch. 9. Stochastic Programming in Transportation and Logistics
577

It has been suggested that we can improve our forecast of empty cars
becoming available by using what we know about cars that are currently
moving loaded (we know where they are going, so if we could estimate the
transit time, we could estimate when they are becoming available). The
uncertainty of transit times complicates this analysis.
Fig. 1. Actual vs. predicted forecasts of future demands for empty cars, showing the 10th
and 90th percentiles.
Fig. 2. Actual vs. predicted forecasts of supplies of empty cars, showing the 10th and 90th
percentiles.
578
W.B. Powell and H. Topaloglu

We are now ready to consider more carefully the decision classes that
govern the problem. As a result of the long travel times and high degree of
uncertainty, it is not possible to simply wait until orders become known before
a car is assigned to satisfy the order. The situation is further complicated by
the fact that they cannot always let a car sit until there is an order to assign it
to. A car may become available at a location that does not have the capacity
to store the car. As a result, the railroad faces four possible classes of decisions
when a car becomes empty:
1) Send it directly to a customer who has booked an order. Normally, we
assume that this decision is to assign a car to a speciﬁc order, but it
could be modiﬁed to send the car to a customer (where it would be
assigned to a speciﬁc order after it arrives).
2) Send it to a regional depot which only serves customers in the region.
3) Send it to a classiﬁcation yard where cars can be sorted and moved out
on diﬀerent trains. A classiﬁcation yard at a railroad is a major facility
and represents a point where it is easiest to make a decision about a car.
From a classiﬁcation yard, a car may be sent to another classiﬁcation
yard, a regional depot or directly to a customer.
4) Do nothing. This means storing the car at its current location. This is
generally not possible if it just became available at a customer, but is
possible if it is at a storage depot.
Not every car can be immediately assigned to an order, partly because some
orders simply have not been booked yet, and partly because there are times of
the year when there are more cars than we need. At the same time, one would
expect that we do not always assign a car to a particular order, because not all
the available cars are known right now. However, there is a strong bias to ﬁnd
an available car that we know about right now (even if it is a longer distance
from the order) than to use a car that might become available later.
5
The two-stage resource allocation problem
We start with the two-stage problem because it is fundamental to
multistage problems, and because some important algorithmic issues can be
illustrated with minimum complexity. It should not be surprising that we are
going to solve multistage problems basically by applying our two-stage logic
over and over again. For this reason, it is particularly important that we be
able to understand the two-stage problem very well.
We begin our presentation in Section 5.1 with a brief discussion of our
notational style. Two-stage problems are relatively simple, and it is common
to use notational shortcuts to take advantage of this simplicity. The result,
however, is a formulation that is diﬃcult to generalize to harder problems.
Section 5.2 summarizes some of the basic notation used speciﬁcally for the car
Ch. 9. Stochastic Programming in Transportation and Logistics
579

distribution problem. We introduce our ﬁrst model in Section 5.3 which
presents models that are in practice today. We then provide three levels of
generalization on this basic model. The ﬁrst (Section 5.4) introduces
uncertainty without any form of substitution, producing the classical
‘‘stochastic programming with simple recourse’’ formulation. The second
models the eﬀect of regional depots (Section 5.5), which produces a separable
two-stage problem which can be solved using specialized techniques. The last
model
considers
classiﬁcation
yards
which
requires
modeling
general
substitution (Section 5.6), and brings into play general two-stage stochastic
programming, although we take special advantage of the underlying network
structure. Finally, Section 5.7 discusses some of the issues that arise for
problems with large attribute spaces.
5.1
Notational style
One of the more subtle modeling challenges is the indexing of time. In a two
stage problem, this is quite simple. Often, we will let x denote an initial
decision, followed by new information (say, ), after which there is a second
decision (perhaps denoted by y) that is allowed to use the information in the
random variable .
This is very simple notation, but does not generalize to multistage
problems. Unfortunately, there is not a completely standard notation for
indexing activities over time. The problem arises because there are two
processes: the information process, and the physical process. Within the infor-
mation process, there is exogenous information, and the process of making
decisions (which can be viewed as endogenously controllable information). In
many problems, and especially true of transportation, there is often a lag
between the information process (when we know about an activity) and the
physical process (when it happens). (We ignore a third process, which is the
ﬂow of ﬁnancial rewards, such as billing a customer for an activity at the end
of a month.)
In the operations research literature, it is common to use notation such as
xt to represent the vector of ﬂows occurring (or initiating) in time t. This is
virtually always the case in a deterministic model (which ignores completely
the time staging of information). In stochastic models, it is more common
(although not entirely consistent) to index a variable based on the information
content. In our presentation, we uniformly adopt the notation that any
variable indexed by time t is able to use the exogenous information up through
and including time t (that is, 0, 1, . . . , t). If xt is a decision made in time t,
then it is also allowed to see the information up through time t. It is often
useful to think of t as information arriving ‘‘during time period t’’ whereas
the decision xt is a function determined at the end of time period t.
We treat t ¼ 0 as the starting point in time. The discrete time t ¼ 1 refers to
the time interval between 0 and 1. As a result, the ﬁrst set of new information
would be 1. If we let S0 be our initial state variable, we can make an initial
580
W.B. Powell and H. Topaloglu

decision using only this information, which would be designated x0. A
decision made using 1 would be designated x1.
There may be a lag between when the information arrives about an activity
and when the activity happens. It is tempting, for example, to let Dt be the
demands that arrive in period t, but we would let Dt be the orders that become
known in time period t. If a customer calls in an order during time interval t
which has to be served during time interval t0, then we would denote this
variable by Dtt0. Similarly, we might make a decision in time period t to serve
an order in time period t0; such an activity would be indexed by xtt0.
A more subtle notational issue arises in the representation of state
variables. Here we depart from standard notation in stochastic programming
which typically avoids an explicit deﬁnition of a state variable (the ‘‘state’’ of
the system going into time t is the vector of decisions made in the previous
period xt1). In resource allocation problems, vectors such as xt can have a
very large number of dimensions. These decisions produce future inventories
of resources which can be represented using much lower dimensional state
variables. In practice, these are much easier to work with.
It is common in multistage problems to let St be the state of the system at
the beginning of time period t, after which a decision is made, followed by new
information. Following our convention, St would represent the state after the
new information becomes known in period t, but it is ambiguous whether this
represents the state of the system before or after a decision has been made. It is
most common in the writing of optimality equations to deﬁne the state of the
system to be all the information needed to make the decision xt. However, for
computational reasons, it is often useful to work in terms of the state of the
system immediately after a decision has been made. If we let Sþ
t
be the
complete state variable, giving all the information needed to make a decision,
and let St be the state of the system immediately after a decision is made, the
history of states, information and decisions up through time t would be
written:
ht ¼ fSþ
0 , x0, S0, 1, Sþ
1 , x1, S1, 2, Sþ
2 , x2, S2, . . . , t, Sþ
t , xt, St, . . .g:
ð5:1Þ
We sometimes refer to St as the incomplete state variable, because it does
not include the information t þ 1 needed to determine the decision xt þ 1. For
reasons that are made clear later (see Section 6.2), we ﬁnd it more useful to
work in terms of the incomplete state variable St (and hence use the more
cumbersome notation Sþ
t for the complete state variable).
In this section, we are going to focus on two-stage problems, which consist
of two sets of decision vectors (the initial decision, and the one after new
information becomes known). We do not want to use two diﬀerent variables
(say, x and y) since this does not generalize to multistage problems. It is
tempting to want to use x1 and x2 for the ﬁrst and second stage, but we ﬁnd
Ch. 9. Stochastic Programming in Transportation and Logistics
581

that the sequencing in equation (5.1) better communicates the ﬂow of deci-
sions and information. As a result, x0 is our ﬁrst stage decision while x1 is our
second stage decision.
5.2
Modeling the car distribution problem
Given the complexity of the problem, the simplicity of the models in
engineering practice is amazing. As of this writing, we are aware of two basic
classes of models in use in North America: myopic models, which match
available cars to orders that have already been booked into the system, and
models with deterministic forecasts, which add to the set of known orders
additional orders that have been forecasted. We note that the railroad that
uses a purely myopic model is also characterized by long distances, and
probably has customers which, in response to the long travel times, book
farther in advance (by contrast, there is no evidence that even a railroad with
long transit times has any more advance information on the availability of
empty cars). These models, then, are basically transportation problems, with
available cars on the left side of the network and known (and possibly
forecasted) orders on the right side.
The freight division of the Swedish National Railroad uses a deterministic
time–space network to model the ﬂows of loaded and empty cars and
explicitly models the capacities of trains. However, it appears that the train
capacity constraints are not very tight, simplifying the problem of forecasting
the ﬂows of loaded movements. Also, since the model is a standard,
deterministic optimization formulation, a careful model of the dynamics of
information has not been presented, nor has this data been analyzed.
The car distribution problem involves moving cars between the locations
that handle cars, store cars and serve customers. We represent these using:
I c
¼ Set of locations representing customers.
I rd ¼ Set of locations representing regional depots.
I cl
¼ Set of locations representing classiﬁcation yards.
It is common to represent the ‘‘state’’ of a car by its location, but we use our
more general attribute vector notation since it allows us to handle issues that
arise in practice (and which create special algorithmic challenges for the
stochastic programming community):
Ac
¼ The set of attributes of the cars.
Ao
¼ The set of attributes of an order, including the number of days into
the future on which the order should be served (in our vocabulary, its
actionable time).
Rc
t,at0 ¼ The number of cars with attribute a that we know about at time t that
will be available at time t0. The attribute vector includes the location
of the car (at time t0) as well as its characteristics.
582
W.B. Powell and H. Topaloglu

Ro
t,at0 ¼ The vector of car orders with attribute a 2 Ao that we know about at
time t which are needed to be served at time t0.
Following the notational convention in equation (5.1), we let Rþ,c
0
and Rþ,o
0
be the initial vectors of cars and orders at time 0 before any decisions have
been made, whereas Rc
0 and Ro
0 are the resource vectors after the initial
decision x0 has been implemented.
It is common to index variables by the location. We use a more general
attribute vector a, where one of the elements of an attribute vector a would be
the location of a car or order. Rather than indexing the location explicitly, we
simply make it one of the attributes.
The decision classes are given by:
Dc
¼ The decision class to send cars to speciﬁc customers, where Dc consists
of the set of customers (each element of Dc corresponds to a location
in Ic).
Do
¼ The decision to assign a car to a type of order. Each element of D0
corresponds to an element of Ao. If d 2 Do is the decision to assign a
type of car (as apposed to a particular car), we let ad 2 Ao be the
attributes of the car type associated with decision d.
Drd ¼ The decision to send a car to a regional depot (the set Drd is the set of
regional depots—we think of an element of I rd as a regional depot,
while an element of Drd as a decision to go to a regional depot).
Dcl
¼ The decision to send a car to a classiﬁcation yard (each element of Dcl
is a classiﬁcation yard).
d 
¼ The decision to hold the car (‘‘do nothing’’).
The diﬀerent decision classes are illustrated in Fig. 3, where a car can be
shipped directly to a customer, a regional depot, or a classiﬁcation yard.
Our complete set of decisions, then, is D ¼ Dc [ Do [ Drd [ Dcl [ d. We
assume that we only act on cars (cars are the only active resource class,
whereas orders are referred to as a passive resource class). We could turn
orders into an active resource class if we allowed them to move without a car
(this would arise in practice through outsourcing of transportation). Of these,
decisions in Do are constrained by the number of orders that are actually
available. As before, we let xtad be the number of times that we apply decision
d to a car with attribute a given what we know at time t.
The contribution function is:
ctad ¼ The contribution from assigning a car with attribute a to an order for
cars of type d 2 Do, given what we know at time t. If d 2 Do, then we
assume that the contribution is a ‘‘reward’’ for satisfying a customer
order, minus the costs of getting the car to the order. For all other
decision classes, the contributions are the (negative) costs from
carrying out the decision.
Ch. 9. Stochastic Programming in Transportation and Logistics
583

Since all orders have to be satisﬁed, it is customary to formulate these
models in terms of minimizing costs: the cost of moving a car from its current
location to the customer, and the ‘‘cost’’ of assigning a particular type of car
to satisfy the order. Since rail costs are extremely complex (what is the
marginal cost of moving an additional empty car on a train?), all costs are
basically surrogates. The transportation cost could be a time or distance
measurement. If we satisfy the customer order with the correct car type, then
the car type cost might be zero, with higher costs (basically, penalties) for
substituting diﬀerent car types to satisfy an order. Just the same, we retain our
maximization framework because this is more natural as we progress to more
general models (where we maximize ‘‘proﬁts’’ rather than minimize costs).
5.3
Engineering practice—Myopic and deterministic models
The most basic model used in engineering practice is a myopic model,
which means that we only act on the vectors Rc
0t0 and Ro
0t0 (we believe that in
practice, it is likely that companies even restrict the vector of cars to those that
are actionable now, which means Rc
00). We only consider decisions based on
what we know now (x0ad), and costs that can be computed based on what we
know now (c0ad). This produces the following optimization problem:
min
x
X
a2A
X
d2D
c0adx0ad
ð5:2Þ
subject to:
X
d2D
x0ad ¼ Rc
0a
a 2 A
ð5:3Þ
Fig. 3. Car distribution through classiﬁcation yards.
584
W.B. Powell and H. Topaloglu

X
a2A
x0ad  Ro
0ad
d 2 Do
ð5:4Þ
x0ad 2 Zþ:
ð5:5Þ
Equation (5.4) restricts the total assignment of all car types to a demand type
ad, d 2 Do, by the total known demand for that car type across all actionable
times. The model allows a car to be assigned to a demand, even though the car
may arrive after the time that the order should have been served. Penalties for
late service are assumed to be captured in c0ad.
It is easy to pick this model apart. First, the model will never send a car to a
regional depot or classiﬁcation yard (unless there happens to be a customer
order at precisely that location). Second, the model will only send a car to an
order that is known. Thus, we would not take a car that otherwise has nothing
to do and begin moving to a location which is going to need the car with a
high probability. Even worse, the model may move a car to an order which
has been booked, when it could have been moved to a much closer location
where there probably will be an order (but one has not been booked as yet). If
there are more cars than orders, then the model provides almost no guidance
as to where cars should be moved in anticipation of future orders.
Amidst these weaknesses are some notable strengths. First, the model is
simple to formulate and solve using commercial solvers. Second, the model
handles all three types of substitution extremely easily (especially important is
substitution across time, something that models often struggle with). But,
perhaps the most important feature is that the solution is easy to understand.
The most overlooked limitation of more sophisticated models is that their
solutions are hard to understand. If the data were perfect, then we would
argue that the user should simply trust the model, but the limitations of the
data preclude such a casual response.
The ﬁrst generalization used in practice is to include forecasts of future
orders, which we would represent using the vector Ro
tt0 for t 2 T ph, where T ph is
the set of time periods in our planning horizon. The details of the process of
forecasting future orders are, of course, not documented. The process of
forecasting would generally have to be made at some level of aggregation
(daily/weekly, customer level or regional, and the car class). Particularly tricky
is handling the time staging of orders. If a forecast is generated for a particular
time t0 in the future (using, for example, standard time series forecasting
techniques applied to a historical dataset showing customer orders by time
period), then we would be forecasting the total orders for time t0, and then
adding in the orders to be satisﬁed at time t0 that are known now. We assume
that we have a forecast Ro
tt0 representing the orders that would be placed at
time t to be satisﬁed at time t0.
We let Ro
tt0 be a point forecast of future demands for t  1, t0  t, with Ro
0t0,
as before, the orders we know about now. We could also make a forecast of
Ch. 9. Stochastic Programming in Transportation and Logistics
585

cars that will become available in the future, but this is still not normally done.
As a result, our model using a deterministic forecast is given by:
min
x
X
a2A
X
d2D
c0adx0ad
ð5:6Þ
subject to:
X
d2D
x0ad ¼ Ro
0a
a 2 A
ð5:7Þ
X
a2A
x0ad 
X
t2T ph
Ro
tad
d 2 Do
ð5:8Þ
x0ad 2 Zþ
ð5:9Þ
Equation (5.8) includes demands that are known now ðRo
0aÞ and all orders
that are forecasted to become known within the planning horizon. Note that
we are using forecasted orders, but not forecasted cars. One model in indus-
trial practice separately forecasts future cars becoming available, but these
forecasts are independent of decisions being made now. To model this process,
we would replace equation (5.7) with:
X
d2D
x0ad ¼
X
t2T ph
Ro
ta
a 2 A
It would be possible to use a deterministic, time staged model over a
planning horizon, but this would actually be fairly hard to solve, since it
would be a moderately large integer multicommodity ﬂow problem with time
windows on the loads (it is the time windows that really complicates the
formulation).
Models that incorporate forecasted demands have the immediate advantage
of providing recommendations for cars which would otherwise not be
assigned in a myopic model. The model will send cars to locations which
normally book new orders, allowing the railroad to start the process of
moving the car, rather than waiting until the last minute. Since we are only
using a point forecast, the model will not be able to send cars to a location
where they might be needed. This can be a problem when we are in a period
where there is excess supply. This model can recommend letting cars sit at a
location where there is absolutely no chance of them being used, rather than
moving them to a location where they might be used.
Our model does not include forecasts of empty cars. The common rationale
for leaving these forecasts out is that they are so uncertain (it is not unusual for
practitioners to ignore information which cannot be reasonably approximated
586
W.B. Powell and H. Topaloglu

by a point forecast). It also ignores many other operational issues such as train
capacities (which we have already identiﬁed to be highly uncertain), yard
capacities (which determines how many cars can be stored at a location) or the
value of cars at the end of the horizon (which we could overcome with a
multistage model).
There are a number of limitations of these simple models, but we would
argue that a serious practical limitation is that the model will never
recommend sending a car to a regional depot or classiﬁcation yard. In one
application with which we are familiar, the model will recommend sending a
car to a particular customer (perhaps to serve a forecasted order). In the
process of routing the car to the customer, the car will have to go through a
regional depot. The railroad will then route the car to the classiﬁcation yard,
reoptimizing the assignment of the car to new orders as they become available.
This is a highly heuristic way of accounting for uncertainty.
5.4
No substitution—a simple recourse model
Our ﬁrst eﬀort to incorporate uncertainty is a simple recourse model where
we replace the decision class to assign cars to a speciﬁc order and instead allow
us to send cars to a particular customer (or equivalently, to a customer
location). The diﬀerence is that if a customer only places one order, then in the
ﬁrst model we can only send him one car. In our simple recourse model, we
may send more cars to the customer location at time t than has been ordered
at time t0 in the hopes that new orders will come in later. For this case, we
deﬁne:
Ro
t,ct0 ¼ The number of orders for customer c that we ﬁrst learn about at time t
that are actionable (must be served) at time t0.
Ro
t,c ¼ All the orders for customer c known at time t.
¼ ðRo
t,ct0Þt0t.
Of course, Ro
0 are the orders we know about now, while ðRo
t Þt>0 are the
forecasted orders for the future. Unlike our ﬁrst models, we are now going to
explicitly model the uncertainty in the forecast of future orders. Looking at
equation (5.8), we see that we only need the total forecast of future demands.
For this reason, it is simpler to deﬁne:
R
o
1,c ¼
X
t2T phnf0g
X
t02T ph
Ro
t,ct0:
R
o
1c is a random variable representing all ‘‘future’’ demands, which would be
derived from a forecasting model. Note that we have aggregated not
Ch. 9. Stochastic Programming in Transportation and Logistics
587

only across all orders that would become known in the future (t), but across
the dates when the orders would need to be satisﬁed (t0). Let:
Rc
0,id ¼ The number of cars (indicated by the superscript c) sent to customer
id, d 2 Dc, where the decision is made at time 0 but the cars can be used
at time 1 (the second stage).
¼ P
a2A x0ad:
The decisions x0ad must be made before the orders ðRo
tiÞt>0 become known.
In our simple recourse model, we assume that a car sent to customer c cannot
then, at a later time, be sent to another customer. It is either used to satisfy an
order (within our planning horizon) or it sits idle. Let:
co
i
¼ The (positive) contribution from satisfying an order for customer
i 2 Ic.
ch
i
¼ The contribution (typically negative) from sending a car to customer i
and then having it sit.
Now let:
xo
1i
¼ The number of cars assigned to serve an order (after they arrive at
customer i).
xh
1i
¼ The number of cars that are held at customer i.
xo
1 and xh
1 are random variables deﬁned by:
xo
1c Rc
0,c, R
o
1cð!Þ


¼ min Rc
0,c, R
o
1cð!Þ
n
o
xh
1c Rc
0,c, R
o
1cð!Þ


¼ max 0, Rc
0,c  R
o
1cð!Þ
n
o
:
We should note that our choices for xo
1cðRc
0,c, R
o
1cð!ÞÞ and xh
1cðRc
0,c, R
o
1cð!ÞÞ
seem a bit obvious, but they are in fact the result of a trivial optimization
problem.
Rc
0,c1 is a function of the ﬁrst stage decisions x0. Given x0, the expected
second stage reward is given by:
C0,1 Rc
0ðx0Þ


¼ Expected costs using the information available in time
period 0 that would be incurred in time period 1:
¼ E
X
c2Ic
co
cxo
1cðRc
0cðx0Þ, R
o
1cÞ þ ch
cxh
1cðRc
0c, R
o
1cÞ


(
)
¼
X
c2Ic
C0,c1ðRc
0cðx0ÞÞ


:
588
W.B. Powell and H. Topaloglu

The functions C0,c1ðRc
0cÞ are concave. If the random demands are discrete,
then it is also possible to show that C0,c1ðRc
0cÞ is piecewise linear, concave, with
the breakpoints at integer values of Rc
0c. Since these functions are computed as
expectations of scalar random variables, computing them is quite easy once
the distribution of demands is known. Of course, forecasting future demands
is in practice fairly tricky, primarily because of the process of customers
booking orders in advance.
We can now formulate our problem as follows:
min
x0
c0x0 þ C0,1ðRc
0ðx0ÞÞ


ð5:10Þ
subject to:
X
d2D
x0ad ¼ Rþ,c
0a
a 2 A
ð5:11Þ
X
a2A
x0ad  Rþ,c
0ad
d 2 Do
ð5:12Þ
x0ad 2 Zþ:
ð5:13Þ
This is a convex nonlinear programming problem with network constraints.
If the demands are discrete, producing piecewise-linear concave reward
functions for each shipper, then we can use a standard trick for converting
these problems into pure networks, as shown in Fig. 4.
Fig. 4. The simple recourse problem as a pure network.
Ch. 9. Stochastic Programming in Transportation and Logistics
589

5.5
Shipping to regional depots—a separable recourse model
The major weakness of the simple recourse model is that it does not capture
the ability of the railroad to send cars to a regional depot, and then wait until
the last minute to send cars from the depot to the customer. In fact, it is
generally not possible to send a car to a customer unless the customer has
speciﬁcally asked for the car. A more realistic model is to assume that the car
has been sent to a local yard (which we refer to as a regional depot) where it is
stored waiting for customers.
In this section we present a more general model which captures the ability
of a railroad to send cars to a regional depot, after which it can be distributed
to customers. We must, however, introduce one key simpliﬁcation (which
we relax later), which is that while we can model general substitution
rules between car types and order types in the ﬁrst stage, we are not going to
allow any substitution between car types in the second stage. One way to
mitigate this approximation is to aggregate car types into more aggregate
categories, and then assume that there is no substitution between major car
categories.
We show in this section how we can solve this more general model,
producing a solution that requires solving a network with the same structure
as that produced for the case of simple recourse (Fig. 4). We begin by
assuming that the demands from diﬀerent shippers are statistically indepen-
dent, and then present a more general result which uses a technique that we
will use for harder problems.
The case of independent demands—an exact result
We begin by setting up some notation that we need for both models. For
this work, it is easier to index decisions and contributions by the spatial
location. This notation is clearer, although not as general.
For each regional depot there is a set of customers in this region. We
represent this using:
Ic
r
¼ The subset of customers in region r 2 I rd. We assume that
customers in Ic
r can only be served using box cars at depot r.
x1ri
¼ The number of cars sent from r 2 I rd to i 2 Ic
r to satisfy customer
orders that become known in the second stage (here the
destination i plays the role of the decision d in our earlier
notation).
c1ri
¼ The contribution from sending cars from r 2 I rd to i 2 Ic
r to
satisfy customer orders that become known in the second stage.
Ro
1c
¼ Random variable giving the number of orders for customer c in
the second stage.
Rc
0rðx0Þ ¼ Total number of cars sent to region r as a result of decisions made
in the ﬁrst period.
590
W.B. Powell and H. Topaloglu

Both x1 and Ro
1 are random variables. For a given realization of the second
stage orders, we would ﬁnd ourselves solving:
Q Rc
0r, Ro
1rð!Þ


¼ max
x1
X
r2Ird
X
i2Ic
r
c1rix1rið!Þ
ð5:14Þ
subject to:
X
i2Ic
r
x1rið!Þ þ x1rdð!Þ ¼ Rc
0r
8r 2 Ird
ð5:15Þ
x1rið!Þ  Ro
1ið!Þ
8i 2 Ic
r, r 2 Ird
ð5:16Þ
x1rið!Þ  0
8i 2 Ic
r, r 2 Ird
ð5:17Þ
where, as a reminder, d  is the ‘‘do nothing’’ decision. Problem (5.14)–(5.17)
decomposes by regional depot, where the problem for each regional depot is
easily solved as a sort. For a given region r 2 Ic
r, assume that
co
r1  co
r2  . . .  co
rjIc
rj  ch
r
where jIc
rj is the number of customers in region r. We have ordered the
customers so that customer 1 is the most attractive, 2 is the second most
attractive, and we have assumed that satisfying any customer is better than
doing nothing (this assumption is easy to relax). Clearly, we would like to
assign as much capacity as possible to the most valuable customers. We want
to ﬁnd the expectation of E½QrðRc
0r, Ro
1rÞ ¼ QrðRc
0rÞ. We are in particular
interested in the slopes QRðRc
0r þ 1Þ  QrðRc
0rÞ, since these form the coeﬃcients
on the arcs which give the marginal value of each additional unit of ﬂow. We
solve this using the following simple observation. Let s ¼ Rc
0r, and let Eðs, iÞ be
the event that results in the sth unit of ﬂow being assigned to the ith—most
valuable customer. Deﬁne:
R
o
1ðJÞ ¼
X
J
j¼1
Ro
1, j
¼ Cumulative number of orders made by the top J customers:
The probability of the event E(s, J ), then, is given by:
Prob½Eðs, JÞ ¼ Prob½ðR
o
1ðJ  1Þ < sÞ \ ðR
o
1ðJÞ  sÞ
¼ Prob½R
o
1ðJ  1Þ < s þ Prob½R
o
1ðJÞ  s
 Prob½ðR
o
1ðJ  1Þ < sÞ [ ðR
o
1ðJÞ  sÞ
ð5:18Þ
Ch. 9. Stochastic Programming in Transportation and Logistics
591

The events ðRo
1ðJ  1Þ < sÞ and ðR
o
1ðJÞ  sÞ are collectively exhaustive, so
the last probability in equation (5.18) is equal to one. This allows us to reduce
(5.18) to:
Prob ½Eðs, JÞ ¼ Prob ½R
o
1ðJ  1Þ < s  ð1  Prob ½R
o
1ðJÞ  sÞ
¼ Prob½R
o
1ðJ  1Þ < s  Prob½R
o
1ðJÞ < s:
Thus, the probability that the sth unit of ﬂow is assigned to the Jth option is
simply the diﬀerence between two cumulative distributions. These are easy to
compute if the demands across customers are independent. Now let vr(s) be
the expected value of the sth unit of ﬂow in depot r, given by:
vrðsÞ ¼
X
i2Ir
co
i Prob½Eðs, iÞ þ ch
r
1 
X
i2Ir
Prob½Eðs, iÞ
 
!
:
The values vr(s) give the expected marginal value of each additional unit of
ﬂow sent into a regional depot.
Using the marginal values vr(s), our ﬁrst stage problem is again a pure
network very similar to the one used for simple recourse, but now with the
property that the decision to send ﬂow to a regional depot is considered
explicitly. Our model will now send cars either directly to customers (to serve
orders that have already been booked) or to regional depots for later
assignment to orders that become known in the future.
Earlier, we considered the problem where we would send cars directly to the
customer before knowing the customer demand. We would then incur an
overage or underage penalty after learning the outcome. This strategy is
referred to as simple recourse. In this section, we send a car to a regional
depot; then, after we learn the demand, we decide which customers to allocate
cars to. Since we are assigning cars from a single node over several links, this
strategy has been referred to as nodal recourse.
Our analysis has been simpliﬁed in part by the assumption that the
demands are independent (making it possible to ﬁnd the partial cumulative
distributions) and to an even greater degree by the assumption that each
customer can be served by a single regional depot. We ﬁrst generalize our
analysis to relax the assumption of independent demands, where we use a
technique that will also allow us to relax the assumption that each customer is
served by a single regional depot.
The general case—Monte Carlo methods
We have seen that in both the simple recourse case and the regional depot
(nodal recourse) case, the problem reduces to ﬁnding piecewise linear, concave
functions characterizing the value of cars at a location. Now we are going to
592
W.B. Powell and H. Topaloglu

introduce another technique for estimating these concave functions based on
Monte Carlo sampling, which does not require making any independence
assumptions between the demands of diﬀerent customers.
Our second stage problem consists of ﬁnding:
QðRc
0Þ ¼ EQðRc
0, Ro
1Þ:
ð5:19Þ
Our strategy is to solve this iteratively. At each iteration, we would choose
an outcome !. For this outcome, the conditional second stage function is
given by:
QðRc
0, Ro
1ð!ÞÞ ¼ max
x1ð!Þ
X
r2I rd
X
i2I c
r
c1rix1rið!Þ
ð5:20Þ
subject to:
X
i2Ic
r
x1rið!Þ þ x1rdð!Þ ¼ Rc
0r
8r 2 Ird
ð5:21Þ
x1rið!Þ  Ro
1ið!Þ
8i 2 Ic
r, r 2 Ird
ð5:22Þ
x1rið!Þ  0
8r 2 Ird, i 2 Ic
r:
ð5:23Þ
Problem (5.20)–(5.23) is pretty easy to solve for a sample realization. Let
^q1rð!Þ be the dual variable for constraint (5.21), reﬂecting the marginal value
of another car. We would like to use this sample gradient information to build
an approximation of QðRc
0Þ. The simplest strategy, of course, is to build a
linear approximation of the form:
^QðRc
0Þ ¼ ^q  Rc
0
ð5:24Þ
but these are notoriously unstable. Although techniques are available to help
these techniques (proximal point strategies, auxiliary functions), we are going
to try to build a nonlinear function similar to the exact functions that we have
seen so far. The simplest that we have seen starts with a piecewise linear
function and then ‘‘tilts’’ it using stochastic subgradients. For example, we
could start with any concave function such as:
^Q0ðRÞ ¼ 0ð1  e1RÞ
^Q0ðRÞ ¼ ln ðR þ 1Þ
^Q0ðRÞ ¼ 0ðR  1Þ2
Ch. 9. Stochastic Programming in Transportation and Logistics
593

where R is a scalar. As an alternative, we would initialize the function by
assuming independence between the demands. Continuous functions can be
converted to piecewise linear functions by extrapolating the function between
integer values of R. Let ~qn ¼ qð!nÞ be a stochastic subgradient of Q (given by
the dual variable of equaion (5.21)), and let Rn be the resource vector at the
nth iteration. We can then update our approximation ^Q using the following
updating equation:
^Qnþ1ðRÞ ¼ ^QnðRÞ þ nð~qn  r ^QnðRnÞÞ  R:
ð5:25Þ
This strategy, dubbed the ‘‘SHAPE’’ algorithm, is provably convergent
when the function Q(R) (and its approximations
^QnðRÞ) are continuously
diﬀerentiable, but in transportation, we are typically managing discrete
resources, and we are interested in integer solutions.
When we are using piecewise linear functions, we can get an even better
estimate by using left and right gradients of QðRc
0, Ro
1ð!ÞÞ rather than a simple
subgradient. Let ~qnþ and ~qn be the right and left gradients, respectively, of
QðRc
0, Ro
1ð!ÞÞ. Then we can perform a two-sided update using:
~Qnþ1ðRÞ ¼
~QnðRÞ þ nð~qnþ  r ~QnðRnÞÞ  R
R  Rn
~QnðRÞ þ nð~qn  r ~QnðRnÞÞ  R
R < Rn
8
<
:
ð5:26Þ
There is another class of strategies that we refer to broadly as structured
adaptive functional estimators (or ‘‘SAFE’’ algorithms). In our problem, we
are trying to estimate piecewise linear, concave functions which can be
represented by a sequence of slopes that are decreasing monotonically. At
each iteration, we obtain stochastic gradients that allow us to update estimates
of these slopes, but it is important to maintain the concavity of our function
or, equivalently, the monotonicity of the slopes. We brieﬂy review two
strategies for performing this estimation. The ﬁrst is referred to as a leveling
technique since violations of concavity are ﬁxed by leveling the estimates of
the slopes (see below). The second is called a separable, projective
approximation routine (SPAR), since we maintain monotonicity in the slopes
by performing a projection of the updated function onto the space of concave
functions.
Both approaches begin by representing the piecewise linear function Q(R)
by its slopes as follows. Let:
qr ¼ Qðr þ 1Þ  QðrÞ
594
W.B. Powell and H. Topaloglu

be the right derivative of Q(R) at R ¼ r. We can the write:
QðRÞ ¼ Qð0Þ þ
X
R1
r¼0
qr:
Let ^qn
r be an estimate of qr at iteration n. As before, let ~qn be a stochastic
gradient of Q at iteration n, and assume they have the property that
E½ ~qn
r ¼ qr. Assume that at iteration n we sample r ¼ Rn(!). We could estimate
the slopes using the simple updating equations:
^qnþ1
r
¼
ð1  nÞ^qn þ n ~qn
if r ¼ Rnð!Þ
qn
r
otherwise

ð5:27Þ
If we assume assume that we are going to sample all the slopes inﬁnitely
often, then it is not hard to show that limn!1 ^qn
r ¼ qr. But this updating scheme
would not work in practice since it does not maintain the concavity of the
function ^QnðRÞ. We know from the concavity of Q(R) that q0  q1  . . .  qr.
It is apparent that equation (5.27) would not maintain this relationship
between the slopes. Within an algorithm, this forces us to solve nonconcave
optimization problems, which is quite hard. We note that concavity is
automatically maintained in equation (5.25) since we are updating a concave
approximation with a linear updating term. Concavity is also maintained in
equation (5.26), since we are guaranteed that ~qn  ~qnþ.
The ﬁrst of our two approaches maintains concavity (monotonicity in the
slopes) by using a technique that we call leveling. Here, all we are doing is
identifying a violation of concavity after a basic update (as in equation (5.27)),
and then adjusting the neighbors of the updated slope so that concavity is
maintained. As before, let Rn(!) be the point that we sample in iteration n.
The updating equations are given by (see Fig. 5):
^qnþ1
r
¼
n ~qnð!Þ þ ð1 nÞ ^qn
r
if Rnð!Þ ¼ r
n ~qnð!Þ þ ð1 nÞ ^qn
i
if Rnð!Þ ¼ i < r and n ~qnð!Þ þ ð1 nÞ ^qn
i < ^qn
r
n ~qnð!Þ þ ð1 nÞ ^qn
i
if Rnð!Þ ¼ i > r and n ~qnð!Þ þ ð1 nÞ ^qn
i > ^qn
r
^qn
r
otherwise
8
>>>><
>>>>:
ð5:28Þ
The second method starts with the estimate of the slopes given by equation
(5.27) and then performs a projection onto the space of functions whose slopes
are monotonically decreasing. We start by letting the left hand side of
equation (5.27) be denoted by the vector qnþ1 which clearly may violate
concavity. We can now think of Q as the space of concave functions, and let
Ch. 9. Stochastic Programming in Transportation and Logistics
595

Q be the nearest point projection onto the space Q. This allows us to
represent the process of converting the vector qnþ1 as the projection:
^qnþ1 ¼ Q ðqnþ1Þ
ð5:29Þ
The projection Q is the solution to the quadratic programming problem:
min
q
kq  qnk2
ð5:30Þ
subject to:
qrþ1  qr  0
ð5:31Þ
Solving this projection problem is very easy. Assume that after the basic
update, we have an instance where qn
r1 < qn
r. Let r ¼ arg minr0<rfqn
r0 < qn
rg be
the smallest index such that qn < qn
r. Now ﬁnd the average over all these
elements:
qn
½r, r ¼
1
r  r þ 1
X
r
r0¼r
qn
r0
Fig. 5. Maintaining concavity by the levelling method.
596
W.B. Powell and H. Topaloglu

Finally, we let
^qnþ1
r0
¼
qn
½r,r
if r  r0  r
qn
r
otherwise
(
Both the leveling method and the projection method produce convergent
algorithms from two perspectives. First, if all the slopes are sampled inﬁnitely
often, then we obtain that limn!1 ^qn
r ¼ qr for all r a.s. But, we are not going to
sample all the slopes inﬁnitely often. What we want to do is to use the
approximation ^Qn as an approximation of the second stage to determine the
solution to the ﬁrst stage. Thus, our algorithm is going to proceed by solving:
xn
0 ¼ arg max
x0
c0x0 þ ^QnðR0ðx0ÞÞ
ð5:32Þ
subject to our ﬁrst stage constraints:
X
d2D
x0ad ¼ Rþ,c
0,a
a 2 A
ð5:33Þ
X
a2A
x0ad1,a0ð0, a, dÞ ¼ Rc
0,a0
a0 2 A
ð5:34Þ
Fig. 6. The separable recourse problem as a pure network.
Ch. 9. Stochastic Programming in Transportation and Logistics
597

X
a2A
x0ad  Rþ,c
0,ad
d 2 Do
ð5:35Þ
x0ad 2 Zþ
ð5:36Þ
The problem (5.32)–(5.36) is a pure network shown in Fig. 6. Once we
obtain xn
0, we ﬁnd a sample realization !n and solve the optimization problem
in (5.20) again. The duals from this problem are used to update the value
function, and the process repeats itself.
Our algorithm, then, does not sample the entire domain for R0, but rather
only those that are produced by solving our ﬁrst stage approximation.
Fortunately we can show that this algorithm will visit the optimal solution
inﬁnitely often. A side beneﬁt is that we are solving sequences of pure
networks which readily yield integer solutions. Integrality can be a major
headache in transportation applications, but we have now designed an
algorithm which always produces integer solutions. Of central importance in
this regard is the fact that our algorithm never performs smoothing on the
decision variables, as would be required if we used stochastic linearization
methods.
At this point it may seem that we are simply solving very special cases. In
fact, as we soon show, we actually have all the machinery we need to solve
very general instances of this problem.
5.6
Shipping to classification yards—a network recourse model
The next level of generalization is the challenge of working with what we
call ‘‘classiﬁcation yards.’’ For the purpose of this presentation, we are going
to assume that we can send cars from classiﬁcation yards to any customers in
the network (for the moment, we are not going to allow ourselves to send cars
to regional depots, since this would take us past our basic two-stage model).
For the moment, we are going to continue to assume that once cars reach a
classiﬁcation yard that there is no substitution between car types: if a customer
order is for car type k, then we must provide car type k. But we are going to
assume that a single customer can be served from more than one depot.
This problem is known to the stochastic programming community as a two-
stage stochastic program with network recourse. The reason is that, unlike our
previous models, the second stage is now a general network problem (as
opposed to the much simpler problems posed by simple or nodal recourse).
Solving a network problem in the second stage is almost as diﬃcult as solving
a general linear program, which means that we should consider algorithms
designed for general two-stage stochastic linear programs.
The research community has developed a number of algorithmic strategies
over the years. The question of whether an algorithmic strategy works has to
be answered in three levels: (1) Does the algorithm appear to work in theory?
Does it capture the mathematical properties of the problem? (2) Does it
598
W.B. Powell and H. Topaloglu

produce reasonable numerical results in laboratory experiments? For example,
using datasets reﬂecting speciﬁc classes of problems, we would like to know if
it converges quickly, producing stable, high quality solutions. (3) Does it work
in practice, producing recommendations that are acceptable to those who
have to implement them?
As of the writing of this chapter, there is a strong handle on the theory, but
numerical testing is extremely limited (given the broad diversity of problems).
For example, showing that an algorithm works well on car distribution
problems for one railroad will not always convince another railroad that it will
work on their network! Container management problems (in trucking, rail
and intermodal applications) come in a variety of sizes and characteristics.
The dynamics of short-haul regional truckload carriers are completely
diﬀerent from those of long-haul national carriers. Experiments in pure
transportationapplicationsdonottelluswhetheritwouldworkinotherresource
allocation settings such as supply chain management and distribution problems.
And we are not even talking about applications outside of transportation and
logistics. In short, each subcommunity (and these can be very specialized) needs
to see numerical work to demonstrate eﬀectiveness on its own problem class.
Given the very limited amount of laboratory testing of the diﬀerent
algorithmic strategies (even within general transportation problems), our
discussion focuses on the qualities of diﬀerent algorithms and their potential
strengths and weaknesses for our problem. We cannot deﬁnitively state what
will and will not work for our problem class, but we can discuss the qualities
of diﬀerent approaches. In particular, we are interested in the degree to which
a technique allows us to exploit the underlying structure of the transportation
problem. Many transportation problems require integer solutions, and also
exhibit near-network structure. Algorithms which allow us to exploit this
network structure are more likely to yield integer solutions from LP
relaxations, or at least provide tight LP relaxations.
Scenario methods
Perhaps the best known algorithmic strategy in stochastic programming is
scenario programming, popular because of its conceptual simplicity, generality,
and use of general-purpose optimization algorithms. But, its eﬀectiveness for
transportation applications is doubtful.
Let ^ be a (not too large) sample of outcomes (future car orders, future car
supplies, as well as travel times). Further let ^pð!Þ be the probability of
outcome ! 2 ^. We can approximate our original problem using the method
of scenarios:
max
x0,x1 c0x0 þ
X
!2 ^
^pð!Þc1x1ð!Þ
ð5:37Þ
Ch. 9. Stochastic Programming in Transportation and Logistics
599

subject to:
First-stage constraints:
X
d2D
x0ad ¼ Rc
0a
a 2 A
ð5:38Þ
X
a2A
x0ad ¼ Rc
0ad
d 2 Do
ð5:39Þ
X
a2A
X
d2D
x0ad1,a0ð0, a, dÞ  Rc
0a01 ¼ 0
a0 2 A
ð5:40Þ
x0ad 2 Zþ
a 2 A, d 2 D:
ð5:41Þ
Second stage constraints:
X
d2Dc
a
x1adð!Þ þ x1adð!Þ ¼ Rc
0,a
8a 2 A,
8! 2 ^
ð5:42Þ
X
a2A
x1adð!Þ  Ro
1cdð!Þ
d 2 Dc,
8! 2 ^
ð5:43Þ
x1adð!Þ  0
8a 2 A, d 2 Dc
a, 8! 2 ^:
ð5:44Þ
We note that our decision class D only allows us to assign cars to a known
order, or to reposition cars to a general or regional depot. As a result, the
second stage problem is primarily one of assigning cars from the general and
regional depots to orders that became known in the second stage.
Scenario methods have been very popular in ﬁnancial applications, but we
feel that there are speciﬁc characteristics of ﬁnancial applications that are not
shared in transportation applications, and vice versa. Financial applications
are characterized by very complex stochastic processes with high levels of
interdependence reﬂecting the dependence of random outcomes on a relatively
smaller number of common factors. It is easier, then, to reasonably
approximate the future with a smaller number of scenarios. Also, ﬁnancial
applications typically do not have integer variables.
Transportation applications, on the other hand, are characterized by a
large number of relatively independent random variables. The optimization
problems, which are typically integer, are often so large that deterministic
problems are hard (although they often have embedded network structures).
The formulation in (5.37)–(5.44) has the eﬀect of taking a computationally
intractable problem and blowing it up into a problem that is many times
larger. Furthermore, many transportation problems exhibit a natural network
structure that is destroyed by the representation of the second stage problem.
600
W.B. Powell and H. Topaloglu

Benders decomposition
Benders decomposition is an appealing algorithm that replaces the very
large problems posed in scenario optimization with sequences of relatively
small problems of the form (which we state here as a minimization problem as
is standard practice in the literature):
min
x0
c0x0 þ z
ð5:45Þ
subject to the ﬁrst stage constraints (5.38)–(5.41) which we represent
compactly using:
A0x0 ¼ R0
ð5:46Þ
x0  0
ð5:47Þ
and the constraints:
z  	ix0  i,
8
i ¼ 1, . . . , n
ð5:48Þ
where 	i and i are generated by solving the dual of the second stage problem,
which for compactness we can write as:
min
x1
c1x1ð!Þ
subject to:
A1x1ð!Þ ¼ R1ð!Þ þ B0x0
x1ð!Þ  0:
Diﬀerent algorithms have been proposed for generating cuts. The ﬁrst
algorithm of this class is the so-called ‘‘L-shaped’’ decomposition, which
works on a ﬁnite set of outcomes (which cannot be too large, since we have to
solve a linear program for each outcome). This concept was generalized by the
stochastic decomposition algorithm which generates cuts from a potentially
inﬁnite sample space. A sketch of the algorithm is given in Fig. 7. This
algorithm converges almost surely to the optimal solution, but the rate of
convergence on practical applications remains an open question.
The CUPPS algorithm (outlined in Fig. 8) requires a ﬁnite sample
space which can be quite large (for example, thousands or tens of thousands
of scenarios). The critical step in the stochastic decomposition is equation
(5.50) which requires smoothing on the coeﬃcients of the cuts. The critical
step in the CUPPS algorithm is equation (5.51) which requires a simple
Ch. 9. Stochastic Programming in Transportation and Logistics
601

arithmetic calculation over the entire sample space. Since equation (5.51) is
quite simple, it is not hard to execute even for tens of thousands of scenarios,
but it prevents the algorithm from ever being applied rigorously to complete
sample spaces (for realistic problems) which can be of the order 1010 or even
10100. From a practical perspective, it is not clear if this is useful.
We need to keep in mind that Benders decomposition is probably limited
(in transportation applications) to the types of resource allocation problems
that we have been considering (since these can be reasonably approximated as
continuous linear programs). However, there are unanswered experimental
questions even for this special problem class. First, there is the usual issue of
rate of convergence. Real car distribution problems may have over 100
regional depots and thousands of customers (for our model, it is the number
of regional depots that really impacts the second stage problem). If there are
50 car types (a conservative estimate) and 100 depots, then (realizing that we
do not have all car types at all locations) we can still anticipate upwards of a
Step 1. Solve the following master problem:
xn
0 ¼ arg minfc0x0 þ z : A0x0 ¼ R0, z  	n
t x  n
t , t ¼ 1, . . . , n  1, x  0g
Step 2. Sample !n 2  and solve the following subproblem:
minfc1x1 : A1x1 ¼ R1ð!nÞ þ B0xn
0, x1  0g
to obtain the optimal dual solution:
vðxn
0, !nÞ ¼ arg min
v fðR1ð!nÞ þ B0xn
0Þ v : AT
1 v  c1g
Augment the set of dual vertices by:
Vn ¼ Vn1 [
fvðxn
0, !nÞg
Step 3. Set:
vn
t ¼ arg maxfðR1ð!tÞ þ B0xn
0Þv : v 2 Vng for all t ¼ 1, . . . , n
Step 4. Construct the coeﬃcients of the nth cut to be added to the master problem by:
n
n þ 	n
nx0: 1
n
X
n
k¼1
ðR1ð!kÞ þ B0x0Þvn
k
ð5:49Þ
Step 5. Update the previously generated cuts by:
n
k ¼ n  1
n
n1
k
, 	n
k ¼ n  1
n
	n1
k
, k ¼ 1, . . . , n  1
ð5:50Þ
Fig. 7. Sketch of the stochastic decomposition algorithm.
602
W.B. Powell and H. Topaloglu

thousand resource states for the second stage problem. How quickly does
Benders decomposition converge for problems of this size? The problem is
that a single cut may not improve our approximation of the value of cars in a
particular location.
A second issue with Benders decomposition is that real applications require
integer solutions. When the ﬂows are relatively large, solutions are easily
rounded to obtain reasonable approximations to the discrete version of the
problem. In actual applications, there can be many instances where ﬂows (to
small locations, or of unusual car types) are quite sparse and fractional
solutions become more problematic. In these cases, fractional solutions can
involve ﬂows that are less than one, and simple rounding may produce
infeasible solutions. At a minimum, dealing with fractional solutions can be a
nuisance.
Despite these questions, Benders decomposition is a promising technique
that needs to be tested in the context of speciﬁc applications.
Stochastic linearization techniques
A powerful set of techniques is based on linear approximations of the
recourse function. These fall into two groups. The ﬁrst uses pure linear
approximations, but performs smoothing on the ﬁrst stage variables to
stabilize the solution. The second group introduces some sort of nonlinear
stabilization term.
Step 1. Solve the following master problem:
xn
0 ¼ arg minfcx þ z : A0x0 ¼ R0, z  	n
kx  n
k, k ¼ 1, . . . , n  1, x  0g
Step 2. Sample !n 2  and solve the following dual subproblem:
vðxn, !nÞ ¼ arg minfðRoð!nÞ þ B0xn
0Þv : AT
1 v  c1g
Augment the set of dual vertices by:
Vn ¼ Vn1 [
fvðxn, !nÞg
Step 3. Set:
vnð!Þ ¼ arg maxfðRoð!Þ þ B0xn
0Þv : v 2 Vng
for all ! 2 
ð5:51Þ
Step 4. Construct the coeﬃcients of the nth cut to be added to the master problem by:
n
n þ 	n
nx0:
X
!2
pð!ÞðR1ð!Þ þ B0x0Þvnð!Þ
Fig. 8. Sketch of the CUPPS algorithm.
Ch. 9. Stochastic Programming in Transportation and Logistics
603

The pure linearization strategy solves sequences of problems of the form:
^xn
0 ¼ arg min
x0
c0x0 þ qn1  R1ðx0Þ:
ð5:52Þ
To calculate qn, let ~qn as before be our stochastic gradient obtained as the
dual variable of the resource constraint from the second stage using a Monte
Carlo realization !n. We then smooth these gradients to obtain:
qn ¼ ð1  nÞqn1 þ n ~qn:
ð5:53Þ
Having obtained the solution ^xn
1, we then smooth this as well:
xn
0 ¼ ð1  	nÞxn1
0
þ 	n ^xn
0:
ð5:54Þ
For both equations (5.53) and (5.54), we would normally require the usual
conditions on the stepsizes for stochastic problems, namely that P1
n¼0 n ¼ 1
and P1
n¼0 ðnÞ2 < 1, although we note in passing that this is not normally
satisﬁed by the stepsize rules used in practice.
Stochastic linearization techniques are clearly the simplest to use, but are
unlikely to work in practice simply because of the lack of stability. Stability is
imposed on the solution primarily through the use of declining stepsizes, but
this is an artiﬁcial form of stability. Furthermore, the smoothing on the ﬁrst
stage variables performed in equation (5.54) is a serious practical problem
because it completely destroys integrality. Rounding is hard for large
problems because it can be diﬃcult ensuring conservation of ﬂow in the
presence of substitutable resources.
Despite these weaknesses, techniques based on linear approximations are
attractive for transportation applications since they retain the structure of the
original problem. If the ﬁrst stage is a network problem, then adding a linear
adjustment term retains this property. Linear approximations are also easy to
compute and store. We may be able to overcome the instability of pure
linearization techniques by employing any of a variety of nonlinear
stabilization terms. One notable example is proximal point algorithms,
which solve sequences of problems of the form:
xn
0 ¼ arg min
x0
c0x0 þ qn1  R1ðx0Þ þ 
 ðx0, xn1
0
Þ
where  ðx, xn1Þ is a distance metric such as  ðx, xn1Þ ¼ kx  xn1k2. xn is
computed using:
xn ¼ ð1  	nÞxn1 þ 	nxn:
604
W.B. Powell and H. Topaloglu

Note that at the last iteration, the ﬁnal solution is xn, not xn. xn is used only
to stabilize the solution.
In engineering practice, we can be creative in the construction of the
distance metric  ðx, xn1Þ. If it is separable in x, then we may ﬁnd ourselves
solving a separable, convex optimization problem. If we are particularly
interested in integer solutions, we can construct a piecewise linear function
deﬁned on discrete values of x (even if xn1 is fractional).
A second type of nonlinear stabilization strategy is the SHAPE algorithm
ﬁrst presented in Section 5.5.2. This is a type of auxiliary function algorithm
where we start with an artiﬁcial auxiliary function ^Q0ðRÞ, and then update it
using stochastic gradients as demonstrated in equation (5.25). An attractive
feature of this algorithm is that the auxiliary function can (and should) be
chosen to retain the structure of the ﬁrst stage problem as much as possible.
For our car distribution problem (and similar applications), piecewise linear,
separable approximations are particularly attractive.
Nonlinear functional approximations
Our last class of strategies tries to explicitly approximate the recourse
function, without any guarantee of convergence to the exact function. We do
not include algorithms such as the one-sided SHAPE algorithm (equation
(5.25)) in this group because there is no explicit attempt to approximate the
recourse function. We also do not include Benders decomposition simply
because we feel that this strategy is in a class by itself. But we do include both
the two-sided SHAPE algorithm (equation (5.26)) and the structured adaptive
functional estimators.
We ﬁrst introduced these algorithms in the context of a recourse function
Q(R) which could be written as a separable function of the resource vector R.
Now consider what would happen if we apply the exact same algorithms to a
nonseparable problem. We still produce a separable approximation of Q, and
we still solve sequences of networks that are identical to Fig. 5. The important
diﬀerence is that we are solving sequences of separable approximations of
otherwise nonseparable functions. For continuously diﬀerentiable problems,
this can be an optimal strategy (in the limit). For nondiﬀerentiable problems
(as we are considering) the result is an algorithm that is very near optimal with
a much faster rate of convergence than has been achieved using Benders
decomposition.
Extension to substitution across car types
In the previous section, we retained our assumption that there was no
substitution between car types in the second stage. However, the substitution
between classiﬁcation yards (spatial substitution) produced a problem with
network recourse (we had to solve a transshipment problem in the second
stage). Now consider what happens if we allow substitution between car types,
which produces the second stage network illustrated in Fig. 9. We quickly see
that while this expands the set of options for a car, it is still a network, and is
Ch. 9. Stochastic Programming in Transportation and Logistics
605

mathematically
equivalent
to
the
problem
which
only
allows
spatial
substitution. In addition, we are also implicitly allowing temporal substitu-
tion. In the second stage, we will forecast demands that are actionable on
diﬀerent days, as well as cars that will become available on diﬀerent days.
However, we are allowing general assignments of cars to demands that may
require cars to be held to meet the demand, or require demands to wait until
the car arrives.
We see, then, that we can use the same algorithmic strategy for
handling substitution between car types as we did for geographic substitution.
But this avoids the more practical question: will it work? It is much more
convincing to argue that spatial problems will produce approximately
separable recourse functions than would arise in the case with other forms
of substitution. For example, it is quite likely that the cost of substituting
other box cars in the same car group is quite small. In fact, this is the reason
that a railroad might reasonably ignore car subgroups and just model car
groups.
For two-stage problems, there is a strong reason to believe that separable
approximations will work well, even when the recourse function is not even
approximately separable. The logic behind this argument is that for n suﬃ-
ciently large, ^Qn will stabilize, and therefore so will xn
0. As xn
0 (approximately)
approaches a limit point, Rn
1ðxn
0Þ will approach a limit point, allowing us
to produce an accurate (but not perfect) piecewise linear approximation
Fig. 9. Illustration of second stage substitution between car types and locations.
606
W.B. Powell and H. Topaloglu

^Qn
j ðRjÞ of the jth dimension of Q(R), at the point R ¼ Rn
1ðxn
0Þ. Thus, a
separable approximation only needs to be a good local approximation to
provide good results.
Summary
The choice of the best algorithm for two-stage resource allocation problems
remains an open question. Two-stage problems are an important foundational
problem, but in transportation applications, the usual goal is to solve
multistage problems. However, it is important to study the performance of an
algorithm in a two-stage setting ﬁrst, and it is diﬃcult to believe that an
algorithm that does not work well for two-stage problems would turn out to
work well in a multistage application. But the converse may not be true; an
algorithm that does work well for a two-stage problem may not work well in a
multistage setting. It is possible for an algorithm (such as the separable,
nonlinear functional approximations) to exploit the limiting behavior of the
ﬁrst stage decisions, a property that we lose immediately in the context of
multistage problems.
Our belief is that while scenario methods are unlikely to prove attractive in
practice, the other three major classes of techniques (Benders decomposition,
stochastic linearization with nonlinear stabilization strategies, and nonlinear
functional approximations) all deserve serious study. We believe that non-
linear functional approximations are going to work the best for two-stage
problems because: (a) they attempt to explicitly approximate the recourse
function; and (b) they exploit the structure of problems that arise in
transportation. However, we have not yet addressed some of the more diﬃcult
dimensions of transportation applications (some of which are touched on
below). Nonlinear approximations can work the best in laboratory experi-
ments, but are much more diﬃcult to use than linear approximations. Pure
linear approximations are too unstable, but linear approximations with
nonlinear
stabilization
terms
(proximal
point
algorithms
or
auxiliary
functions) may oﬀer an attractive alternative. All of these approximations
are separable, and it is simply not clear how well these will work in multistage
applications.
5.7
Extension to large attribute spaces
Up to now, we have considered a problem where there are jKj car types
spread among jIj locations. Using our earlier notation, the attribute vector of
a car would be represented by a ¼ (k, i). Thus, our attribute space A has
jAj ¼ jKj  jIj elements. A large railroad might have several hundred regional
depots and 50 to 100 car types, with a total of several thousand combinations.
Large, but not hard to enumerate on modern computers.
Now consider what a real car distribution problem looks like. While
there are, in fact, 50 to 100 real car types, these cars are allocated among
Ch. 9. Stochastic Programming in Transportation and Logistics
607

several dozen pools which represent groups of cars controlled by individual
shippers. The allocation of cars to pools is negotiated periodically between the
shipper and the railroad, and cars can be moved from one pool to another,
reﬂecting the evolving needs of the shippers. Cars are also characterized
by the railroad that owns them (when they are not in a pool). Box cars
sometimes carry dirty freight that limits their ability to carry cargo (such as
food) that requires a clean car. For this reason, cars carry the attribute of the
commodity type that they last carried. Finally, some cars may have equipment
problems that require maintenance. These problems may range from
minor issues that do not aﬀect the use of the car to more serious equipment
problems.
When we use this full vector of attributes, we now ﬁnd that there are not
several thousand possible attributes, but several million. Now we cannot even
generate the entire attribute space. This creates an interesting problem. In our
optimization model, we may wish to consider acting on a car with what is now
a multiattribute vector a with decision d, producing a car with attribute vector
a0. Since we are not able to enumerate the space A, we may not have an
approximation for
^Qn
a0ðRa0Þ. As a result, we have to devise a strategy for
approximating ^Qn
a0ðRa0Þ.
We are not able to address this issue in depth, but it is important to
understand some of the problems that arise. First, it is easy to see that we
should try to make sure that our initial approximation d ^Q0
a0ðRa0Þ=dRa0jRa0¼0 is
an optimistic estimate of @QðRÞ=@Ra0jR¼0. If we did not do this, then a low
estimate might result in us choosing not to make the decision d that produces
a resource with attribute a0. Since we never visit that resource state, we never
improve our approximation.
In practice, the use of optimistic estimates of the value of a resource
may not work. We have found that initial approximations that are
guaranteed to be optimistic are actually too optimistic. Consider choosing
between decisions d0 and d00. Assume that decision d0 produces a resource
with attribute a0 while decision d00 produces a resource with attribute a00.
Further assume that we have generated the attribute a0 (and therefore
have an approximation ^Qn
a0ðRa0Þ), but we have never generated the attribute a00.
If we use an optimistic approximation for ^Qn
a00ðRa00Þ, then we would choose
d00 just because we have never tried it before. The result is the steady
exploration of every possible decision, and a virtual enumeration of the
attribute space A.
A more practical approach is to assume that we have access to an
aggregation function GðaÞ  ^a where ^a 2 ^A is an aggregation of the original
attribute space. We assume that ^A is not too large and can be enumerated.
We further assume that ^Qn
^aðR ^aÞ is a ‘‘good’’ approximation of ^Qn
aðRaÞ when
GðaÞ ¼ ^a. We then make sure that we repeatedly sample gradients and update
^Qn
^aðR^aÞ for all ^a 2 ^A.
We are not aware of any formal convergence theory for this approach (or
for any other algorithm for this problem class). But real problems in
608
W.B. Powell and H. Topaloglu

transportation are characterized by a much richer vector of attributes than is
normally considered by the academic community.
6
Multistage resource allocation problems
We now turn to the challenge of solving multistage problems. In multistage
problems, we have to capture the sequential decision-making process as
information (and decisions) evolve over time. For transportation problems,
we encounter the reusability of resources; once a vehicle moves a load, it is
available to be used again.
We could motivate our multistage problem using our rail car distribution
example, but it is useful to bring other applications into the picture. Examples
include:
1) Fleet management for truckload trucking—In truckload trucking, a
truck moves an entire load of freight from origin to destination.
Uncertainty plays a major role in the long haul truckload market, where
loads can take between 1 and 4 days to deliver. Customers sometimes
request trucks the same day the order is made, but more often call in one
or 2 days in advance. In sharp contrast with the rail industry, the
truckload carrier does not have to accept every load, and this is one of
the major challenges. Emerging electronic market places, where loads
are posted on web sites, open the possibility of taking loads that do not
have to move for several days. This is a classic problem of decision-
making under uncertainty.
2) Driver management for long-haul less-than-truckload motor carriers—
LTL carriers face the problem of timing the movement of loads over the
network, requiring the careful management of drivers.
3) Management of jets in the fractional ownership industry—In this
business, high net worth individuals and business executives will own a
fraction of a jet. This gives them access to the entire ﬂeet of jets. They
may call the company with as little as 8 h notice and request that a jet
move them from a local airport to any other airport. After the move, the
ﬂeet operator will move the jet to another location.
4) Routing
and
scheduling
transport
aircraft
for
the
air
mobility
command—The AMC works like a large trucking company, moving
freight for the military using large transport aircraft. They are typically
used in support of emergency situations where requests for freight
movement arise dynamically.
Compared to our rail car distribution problem, these applications are
characterized by relatively shorter travel times and less ﬂexibility to satisfy
customer orders at times other than when they were requested.
Multistage problems are, of course, much harder than two-stage problems,
but we are going to approach them by building on the tools we have
Ch. 9. Stochastic Programming in Transportation and Logistics
609

already introduced. Our strategy for solving multistage problems is to solve
them as sequences of two-stage problems. Students of dynamic programming
will see strong similarities in our modeling approach. But multistage problems
do introduce a fresh set of modeling and algorithmic issues that simply do not
arise in two-stage problems.
We start in Section 6.1 with a formulation of the problem. Then, Section
6.2 outlines the general algorithmic strategy. Section 6.3 describes the
implementation in the context of single commodity ﬂow problems. Section 6.4
outlines the challenges that arise when we solve multicommodity problems in
a multistage setting. Finally, Section 6.5 describes the complications that are
introduced when we model the property that it takes more than one time
period to go from one location to another.
6.1
Formulation
We present the basic multistage problem with somewhat more generality
than we have used previously. We ﬁrst deﬁne the exogenous information
arriving to our system:
^Rt
¼ Vector of new arrivals in period t, where ^Rt ¼ ð ^Ro
t , ^Rc
tÞ.
t
¼ Complete vector of new information arriving in period t, including
both ^Rt as well as other information about system parameters (travel
times, costs, and parameters governing the physics of the problem).
For our purposes, we are only interested in the resource state Rt, and the
only information process we are modeling at the moment is the arrival of new
resources,
^Rt. Using this notation, our history of states, information and
decisions (given earlier in equation (5.1)) would look like:
ht ¼fRþ
0 , x0, R0, ^R1, Rþ
1 , x1, R1, ^R2, Rþ
2 , x2, R2, . . . , ^Rt, Rþ
t , xt, Rt, . . .g
ð6:1Þ
There are three perspectives of the state of our system:
Rt
¼ Vector of resources available in period t after decisions xt have been
made.
Kt
¼ What is known at time t after the new information t has been incor-
porated. Kt includes Rt plus what we know about parameters that
govern the dynamics of the system.
It
¼ Set of information available at time t for making a decision. It includes
Kt, but it might also include forecasts of future activities (activities
which are not ‘‘known’’ now, but are the result of a forecasting
exercise).
610
W.B. Powell and H. Topaloglu

Our process is controlled by the decisions we make:
xt
¼ Decisions which are made after new information in period t has
become known.
X
t ðItÞ ¼ The decision function of policy .
Our decisions are chosen to maximize the expected total contribution over a
planning horizon. Our contribution function is expressed as:
ct(xt, Kt) ¼ The contribution generated in period t given decision xt, and
what is known, Kt.
When resources are allocated in time t, they have to satisfy ﬂow con-
servation equations of the form:
X
d2D
xtad ¼ Rt1,at þ ^Rt,at
where we assume that we can only act on resources that are actionable now
(Rtt). The physical dynamics of the system are given by:
Rt,a0t0 ¼ Rt1,a0t0 þ
X
a2A
X
d2Da
t0,a0ðt, a, dÞxtad
8a0 2 A,
t0  t þ 1:
ð6:2Þ
It is often useful to express ﬂow conservation and system dynamics in
matrix form, which we do using:
Atxt ¼ Rt1 þ ^Rt
ð6:3Þ
Rt  Btxt ¼ Rt1:
ð6:4Þ
For reasons that are made clear in Section 6.2, we have written our
equations directly in terms of the incomplete resource vector Rt. The complete
resource vector is simply Rþ
t ¼ Rt1 þ ^Rt.
The informational dynamics can be written generally as:
Ktþ1 ¼ UKðKt, tþ1Þ
ð6:5Þ
which is how we would represent the process of updating demand forecasting
equations, parameter estimation equations, and the storage of other types of
information.
Ch. 9. Stochastic Programming in Transportation and Logistics
611

The basic statement of the multistage problem is now given by:
max
2 E
X
t2T
ctðXðItÞ, KtÞ
(
)
subject to ﬂow conservation (equation (6.3)), resource dynamics (equation
(6.4)) and informational dynamics (equation (6.5)). There may also be upper
bounds on ﬂows representing physical constraints.
The challenge, now, is choosing a function X(It). Popular choices include
myopic policies (It ¼ Kt), or rolling horizon procedures, where It ¼ ðKt, ^tÞ
where ^t represents a forecast of future events made with the information
known at time t. If jtj ¼ 1 then we are using a point estimate of the future and
we obtain classical deterministic methods for handling the future. In the next
section, we discuss how adaptive dynamic programming methods can be used.
6.2
Our algorithmic strategy
Our strategy for solving multistage problems is based on techniques from
approximate dynamic programming. Since this approach is not familiar to the
stochastic programming community, some background presentation is useful.
Recall from Section 6.1 (and in particular equation (6.1)) that we can measure
the state of our system before or after we make a decision. It is common in the
dynamic programming and control community to write the optimality
equations using the state before we make a decision, producing optimality
equations of the form:
Qþ
t ðRþ
t Þ ¼ arg max
xt
ctðXðItÞ, Rþ
t Þ þ EfQþ
tþ1ðRþ
tþ1Þ j Rþ
t g:
ð6:6Þ
Classical dynamic programming techniques are computationally intractable
for this problem class. Solving equation (6.6) using classical discrete dynamic
programming techniques encounters three ‘‘curses of dimensionality’’: the
state space, the outcome space and the action space. Each of these variables
are vectors (and potentially vectors of high dimensionality). Computing the
value functions using a backward recursion requires computing equation (6.6)
for each possible value of the state variable. Computing the expectation
requires summing over all the outcomes in the outcome space. Finally, since
the expected value function may not have any special structure, solving the
optimization problem requires evaluating all possible values of the decision
vector xt.
We overcome this problem using the following strategy. First, recognizing
that we do not know Qþ
tþ1, we replace it with an appropriate approximation
that for the moment we denote by ^Qþ
tþ1ðRþ
tþ1Þ. Next, we recognize that we
cannot compute the expectation in equation (6.6). The common strategy is to
612
W.B. Powell and H. Topaloglu

replace the expectation with an approximation based on a sample taking from
the outcome space:
Qþ
t ðRþ
t Þ ¼ arg max
xt
ctðXðItÞ, Rþ
t Þ þ
X
^!2 ^
pð ^!ÞQþ
tþ1ðRþ
tþ1ð ^!ÞÞ:
ð6:7Þ
Equation (6.7) can be exceptionally diﬃcult to solve for the types of high
dimensional, discrete resource allocation problems that arise in transporta-
tion. It is particularly inelegant when we realize that it is often the case that the
myopic problem (maximizing ctxt) is a pure network, which means the
introduction of the approximate value function is making a trivial integer
program quite diﬃcult (the LP relaxation is not a good approximation).
Equation (6.7) is quite easy to solve if we use a linear approximation for
^Qtþ1. In this case:
^Qþ
tþ1ðRþ
tþ1Þ ¼ ^qþ
tþ1  Rþ
tþ1
¼ ^qþ
tþ1  ðRt þ Atxt þ ^Rtþ1Þ:
ð6:8Þ
Taking conditional expectations of both sides of equation (6.8) gives:
Ef ^Qþ
tþ1ðRþ
tþ1Þ j Rþ
t g ¼ Ef^qþ
tþ1  ðRt þ Atxt þ ^Rtþ1Þ j Rþ
t g
¼ ^q1
tþ1Rt þ ^qþ
tþ1Atxt þ Ef^qþ
tþ1 ^Rtþ1 j Rþ
t g:
ð6:9Þ
The only term on the right side of equation (6.9) involving the expectation
is not a function of xt, so it is only a constant term and can be dropped. The
resulting optimization problem is identical to the original myopic optimiza-
tion problem with a linear adjustment term which would never destroy any nice
structural properties of the original problem (for example, network structure).
So, a linear approximation allows us to avoid the problem of taking multi-
dimensional expectations. But what if we use a nonlinear approximation?
Now the presence of the expectation presents a serious computational com-
plication. We can circumvent the problem by formulating our optimality
recursion around the incomplete state variable Rt. This gives us optimality
equations of the form:
Qt1ðRt1Þ ¼ Efarg max
xt
ctxt þ QtðRtðxtÞÞjRt1g:
ð6:10Þ
Again, we propose to replace the recourse function Qt(Rt) with an
approximation
^QtðRtÞ. Note the shift in the time index, which reﬂects the
information content of each variable. We still face the problem of computing
(at least approximately) the expectation. However, we are not really interested
in computing the expectation. Instead, we need an action xt which depends on
Ch. 9. Stochastic Programming in Transportation and Logistics
613

both Rt1 and the new arrivals ^Rt. For this reason, we would make a decision
contingent on a single sample realization, allowing us to write our decision
function using:
X
t ðRt1, ^Rtð!ÞÞ ¼ arg max
xt
ctxt þ ^QtðRtðxt, !ÞÞ
ð6:11Þ
subject to:
X
d2D
xtad ¼ Rc
ta þ ^Rc
tað!Þ
a 2 A
ð6:12Þ
X
a2A
xtad  Ro
tad ^Ro
tadð!Þ
d 2 Do
ð6:13Þ
xtad 2 Zþ
ð6:14Þ
X
t is an approximate decision function which can be viewed as a class of policy
(in the language of Markov decision theory), where the policy is determined
by the choice of ^Qt. Because we have formulated the recourse function in
terms of the incomplete state variable, there is no need to directly approximate
the expectation (this is being done indirectly through the estimation of ^Qt). We
now face the challenge of determining ^Qt. Fortunately, we only have to use the
techniques that we described earlier for the two stage problems. Linear
approximations remain the simplest to use, but current experimental evidence
suggests that piecewise linear, separable approximations are both relatively
easy to solve and also provide much higher quality solutions.
Our overall algorithmic strategy is shown in Fig. 10. We refer to this as the
‘‘single-pass’’ version of the algorithm. We initialize ^Qt for all t. We then
simulate forward in time, using dual variables to update the approximation of
^Qt, sampling new information as the algorithm progresses.
The single pass version of the algorithm is the easiest to implement, but it
may not work the best. The problem is that it takes a full forward iteration to
pass information back one time period. An alternative is to use a two-pass
version of the algorithm, where there is a forward pass making decisions, and a
backward pass updating dual variables. This version is described in Fig. 11.
These algorithms do not describe speciﬁcally how to update the functional
approximations ^Qn. For the single-pass version of the algorithm, this updating
process is identical to that used for the two-stage problem. We simply use the
dual variables for the ﬂow conservation constraint to update ^Qn just as we did
in Section 5.5.2. As we have seen, there are a number of ways to update the
value function, so we represent this in general using the notation:
^Qn
t  UQð ^Qn1
t
, qn
t , Rn
t Þ:
614
W.B. Powell and H. Topaloglu

Updating the value function in the two-pass version is a bit more
involved, but the payoﬀis an updating process that possesses one particularly
nice theoretical property. In addition, it appears to work better in
practical applications. For the pedagogical purposes of this chapter, we are
going to outline the basic idea graphically. Recall that we are solving
sequences of pure networks at each time t. At each point in time, we obtain
not only an optimal solution but also an optimal basis. Fig. 12 shows
the sequence of optimal bases over three time periods. Recall that
the
network
structure
of
our
one-period
problems
consists
of
links
representing decisions in time period t plus links that represent our piecewise
linear value functions. We are interested only in the portion of the basis
that consists of links in time period t (with coeﬃcients from the vector ct),
and not in the links which represent the approximation ^Q. We note that as a
result of our network structure, each basis path from a resource node consists
of one or more links in time period t, ﬁnally ending in a node in a future
time period.
After building the basis paths in the forward simulation, we now have a set
of paths extending through the entire horizon. We then compute the cost of a
path from a resource node t for attribute vector a until the end of the horizon.
Let qn
ta be the cost of the path from resource node a at time t until the end
Step 0. Initialization:
Initialize ^Q0
t ,
t 2 T .
Set n ¼ 0.
Step 1. Do while n  N:
Choose !n 2 
Step 2. Do for t ¼ 0, 1, . . . , T1:
Step 2a. Solve equation (6.11) to obtain xn
t ¼ X
t ðRn
t , ^Qn1
tþ1 Þ and the duals ^qn
t of the
resource constraint equation (6.12).
Step 2b. Update the resource state: Rn
tþ1.
Step 2c. Update the value function approximations using ^Qn
t .
Step 3. Return the policy X
t and ^QN.
Fig. 10. Single pass version of the adaptive dynamic programming algorithm.
Step 0. Initialize ^Q0
t , t 2 T.
Set n ¼ 0.
Step 1. Do while n  N:
Choose !n 2 
Step 2. Do for t ¼ 0, 1, . . . , T1:
Step 2a. Solve (6.11) to obtain xn
t ¼ X
t ðRn
t , ^Qn1
tþ1 Þ and the duals ^Qn
t of the resource
constraint (6.12).
Step 2b. Update the resource state: Rn
tþ1.
Step 3. Do for t ¼ T1, T2, . . . , 1, 0:
Step 3a. Compute marginal value of a resource, qn
t , using ^Qn
tþ1 and the optimal basis
from the forward pass.
Step 3b. Update the value function approximations, ^Qn
t  UQð ^Qn1
t
, qn
t , Rn
t Þ.
Step 4. Return policy X
t and ^QN.
Fig. 11. Double pass version of the adaptive dynamic programming algorithm.
Ch. 9. Stochastic Programming in Transportation and Logistics
615

of the horizon along this basis path. These path costs have a very nice
property. Let:
F
t ðRt, !nÞ ¼
X
T
t0¼t
ctX
t ðItð!nÞÞ
ð6:15Þ
be the costs of a policy  (determined by the functional approximation ^Qn) for
outcome !n in iteration n, starting in time period t. Then we have:
Theorem 2. Let qn
t ¼ ðqn
taÞa2A be the vector of path costs from time t to the end
of the horizon, given outcome !n and functional approximations f ^Qn
t gt2T
computed from a backward pass. Then qt satisﬁes:
F
t ðRt, !nÞ  F
t ðR0
t, !nÞ  qn
t  ðRt  R0
tÞ
Furthermore, if the basis paths in each period t are ﬂow augmenting paths into
the supersink, then qn
t is a right gradient of F
t ðRt, !nÞ.
This is a very nice result. These paths are not too hard to compute and
provide accurate estimates of the future value of a resource. It turns out that
the ability to compute right derivatives is very important. If we just use the
dual variables, we overestimate the value of a resource in the future,
producing unwanted empty moves.
With our ability to compute valid stochastic gradients of the cost function,
we are ready to apply all the tricks we learned for two-stage problems for
computing the approximate value functions, ^Qn
t . The forward pass/backward
Fig. 12. Optimal network basis from the forward pass.
616
W.B. Powell and H. Topaloglu

pass logic is easy to execute and computationally tractable. The Monte Carlo
sampling logic avoids problems with expectations. This almost looks too good
to be true.
Multistage problems, however, have a few more surprises for us. We begin
by discussing the problem of computing expectations, even when we use
approximations of the recourse function. We next focus on the issue of
problem structure. Keep in mind that transportation problems can be very
large, and we are still interested in integer solutions. The ﬁrst challenge that
arises in multistage problems is that resources are reusable (box cars do not
simply vanish after we use them). This introduces structural problems that did
not occur with two-stage problems, which we review in the context of both
single and multicommodity ﬂow problems. We then brieﬂy discuss one of the
more annoying, but unavoidable, features of transportation problems:
multiperiod travel times.
6.3
Single commodity problems
The diﬀerence between the two-stage problem and the one-period problem
in a multistage application is that the assignment of a resource to a task
produces a resource in the future. In two-stage problems, once the car was
assigned to an order in the second stage, it vanished from the system. In
multistage problems, we ﬁnd that we have to solve the type of network
depicted in Fig. 13, which is a pure network. This can be solved with
commercial LP solvers or specialized network algorithms. Assuming that the
functions
^Qn
tþ1ðRÞ is piecewise linear, with breakpoints deﬁned for integer
values of R, our pure network has integer data (upper bounds and resources)
and as a result simplex-based algorithms will return integer solutions.
Pure networks have another attractive property. Linear programming
codes will return a dual variable ~qta for the resource constraint equation
(6.12). It is far more desirable to obtain explicit right and, if possible, left
Fig. 13. Network structure of a one-period single commodity problem.
Ch. 9. Stochastic Programming in Transportation and Logistics
617

gradients, which we can denote ~qþ
t and ~q
t . With pure networks, left and right
gradients can be found by solving ﬂow augmenting path problems into and
out of (respectively) the supersink. A right gradient gives us a precise estimate
of a particular slope of the recourse function. The computation of explicit left
and right gradients is very important in problems with large attribute spaces,
where the values of Rta can be relatively small. If A is small relative to the
number of resources being managed (implying that the values of Rta are much
greater than one), then the issue is unlikely to be noticeable.
The pure network structure actually arises in a larger class of problems.
Assume that we are modeling resources with attribute a, and recall from
Section 3 that aMðt, a, d Þ is the terminal attribute function, giving the attributes
of a resource with attribute a after decision d has been applied to it. Now
deﬁne:
Deﬁnition 3. A resource allocation problem has the Markov property if
aMðt, a, dÞ ¼ aMðt, a0, dÞ, 8a, a0 2 A.
The Markov property for resource allocation problems implies that the
attributes of a resource after it has been acted on is purely a function of the
decision. Classical single commodity ﬂow problems exhibit this property
because a truck in location i which is then assigned to move a load from i to j,
is now a truck at location j. If all the trucks are the same, then the attribute of
the truck (its location) is purely a function of the attribute of the decision
which was to move a load to j. If there were diﬀerent types of trucks that could
serve the load (a multicommodity problem), then the attribute of the truck
after moving the load continues to have the attribute of the truck before the
load (a characteristic that has nothing to do with the decision).
It is apparent that classical multicommodity problems which allow
substitution of diﬀerent commodity types for the same task will never have the
Markov property, but multiattribute problems (where the attribute vector a
consists purely of dynamic attributes), can possess this property. Consider a
chemical trailer that can move basic argon gas or puriﬁed argon gas. Only
‘‘clean’’ trailers can move puriﬁed argon gas. A clean trailer can move basic
gas, but then it is no longer clean. There is no substitution for puriﬁed argon
gas, and any truck moving basic argon gas is no longer clean (although it can
be put through a cleansing process). Thus, the attributes of the truck after a
trip are determined completely by the characteristics of the trip.
6.4
Multicommodity problems
When we encountered single commodity problems, we found that the single
period problems were pure networks if the approximation of the recourse
function were linear, or piecewise linear, separable. Now we consider what
happens when we try to solve multicommodity problems. Recall that we let I
be a set of locations and K be the set of commodities. We follow the standard
notation of multicommodity ﬂow problems and let Rk
ti be the number of
618
W.B. Powell and H. Topaloglu

resources of type k in location i, and let xk
tid be the number of resources of type
k in location i that we act on with decision d at time t.
Below, we show that multistage, multicommodity problems are especially
easy to solve if we use linear value function approximations, whereas the use
of separable nonlinear (piecewise-linear) approximations introduces compli-
cations which, while tractable, have to be addressed.
The case of linear approximations
When we replace the value function Qt(Rt) with an approximation ^QtðRtÞ,
we obtain the decision function:
X
t ðItÞ ¼ arg max
x
X
i2I
X
d2D
ctidxtid þ Ef ^QtðRtðxtÞÞ j Rt1g
ð6:16Þ
If we use a linear approximation for ^Q, the equation (6.16) reduces to:
X
t ðItÞ ¼ arg max
x
X
i2I
X
d2D
ctidxtid þ
X
t0>t
X
j2I
^qt, jt0ðRt, jt0ðxt, !tÞÞ
ð6:17Þ
¼ arg max
x
X
i2I
X
d2D
ctidxtid þ
X
t0>t
X
j2I
^qt, jt0Rt, jt0ðxt, !tÞ
ð6:18Þ
where:
Rt,jt0 ¼
X
i2I
X
d2Di
t0, jðt, i, dÞxtid
ð6:19Þ
Substituting equation (6.19) into (6.18) gives:
XðItÞ ¼ max
x
X
i2I
X
d2D
ctidxtid þ
X
t0>t
X
j2I
^qt, jt0
X
i2I
X
j2D
t0, jðt, i, dÞxtid
ð6:20Þ
¼ max
x
X
i2I
X
d2D
ctidxtid þ
X
i2I
X
d2D
X
t0>t
X
j2I
t0, jðt, i, dÞ^qt, jt0xtid
 
!
ð6:21Þ
It is easy to see that:
X
t0>t
X
j2I
t0, jðt, i, dÞ^qt, jt0xtid ¼ ^qt,iM
tid,tþM
tidxtid
ð6:22Þ
Ch. 9. Stochastic Programming in Transportation and Logistics
619

where iM
tid is our terminal attribute function (using location indices instead of
attribute vectors) and M
tid is the time required to complete the decision. This
allows us to reduce equation (6.22) to:
XðItÞ ¼ max
x
X
i2I
X
d2D

ctid þ ^qtþ1,iM
tid,tþM
tid

xtid:
ð6:23Þ
Equation (6.23) demonstrates that a linear approximation of the recourse
function is the same as adding a price to the cost of each assignment, with the
same structure as the original one-period problem. So, solving multi-
commodity ﬂow problems with linear approximations is no harder than
solving single commodity problems.
The case of nonlinear approximations
The situation is somewhat diﬀerent when we are using nonlinear functional
approximations. Our one-period problem now takes on the network structure
shown in Fig. 14 which is itself a multicommodity ﬂow problem, if we are
using nonlinear functional approximations. We note, however, that these are
not especially large multicommodity ﬂow problems, since they are for a single
time period. Perhaps the most signiﬁcant practical problem that might arise is
the loss of integrality. In fact, we have found that a commercial LP package
solving a continuous relaxation of the problem returns integer solutions
99.9% of the time (the rare instance of a fractional solution is quickly solved
with branch and bound or simple rounding heuristics).
Perhaps the more practical challenge of multicommodity ﬂow problems is
that we do lose the ability to ﬁnd left and right gradients using ﬂow
Fig. 14. Network structure of a one-period multicommodity problem.
620
W.B. Powell and H. Topaloglu

augmenting path calculations. As we pointed out before, this is not necessary
for all problem classes, but we have worked on problems with large attribute
spaces where dual variables from the LP solver are simply not good enough. In
this case, we are resorting to performing numerical derivatives (incrementing
the right hand side and solving the problem again). Since the optimal basis is
often optimal for the perturbed problem, this procedure can be quite fast.
6.5
The problem of travel times
One of the most annoying characteristics of transportation is the property
that it takes time to complete a decision. Using the vocabulary of discrete time
models, we refer to these problems as having ‘‘multiperiod’’ travel times. More
generally, we would refer to these as ‘‘multiperiod transfer times,’’ since there
are many activities in transportation that do not actually involve moving from
one location to another (drivers have to go on rest, trailers have to be cleaned,
locomotives have to be maintained). But, the concept of traveling between
locations is easy to visualize.
The implication of multiperiod travel times is that after acting on a resource
at time t, the resource is committed to an activity in time period t þ 1 and we
cannot act on it. At the same time, we cannot ignore it, because it will
eventually complete its movement, and we have to take this into account when
we make decisions in time period t þ 1. Fig. 15 illustrates the issue in the
context of ﬂeet management. Assume that we will need containers at location
c at time t ¼ 6, and we can move them there from either a, which is ﬁve time
periods away, or from d, which is only two time periods away. Because a is
Fig. 15. Multiperiod travel times imply that decisions to move vehicles at diﬀerent points
in time can produce available capacity at the same time in the future.
Ch. 9. Stochastic Programming in Transportation and Logistics
621

farther away, we will ﬁrst look at the problem of the shortage of containers at
c for time t ¼ 6 at time t ¼ 1. At this point, we would not have considered
moving containers from location d, since this decision would not be made
until t ¼ 4. Seeing the shortage, we might move containers the longer distance
from a to c, rather than waiting until time t ¼ 4 and moving them from the
closer location at d.
The modeling of multiperiod travel times is the same as the modeling of
lagged information processes. Earlier in the chapter, we introduced the
notation Rtt0 which gives the vector of resources that we know about at time t
which become actionable at time t0. The diﬀerence between t0 and t is the
information lag. Lags can arise when customers call in orders in advance. In
the case of our rail car distribution problem, it can arise when a shipper tells
the carrier that a freight car will become empty in 3 days. Information lags
also arise whenever the travel time from one location to another is more than
one time period.
The problem of multiperiod travel times is unique to multistage stochastic
models, and furthermore it is unique to the usage of nonlinear functional
approximations. With a nonlinear function, location a ‘‘sees’’ the steeper part
of the slope of the function at c, since we have not yet made the decision to
move cars from d. The result is something that we call the ‘‘long haul bias,’’
which arises in any application where resources can be committed in the
future.
The standard solution for problems of this type is to use an augmented
state variable. Assume that a container started moving from i to j, departing at
time t, on a trip that requires time ij. Now let the variable s be the remaining
time in the trip, so at time t þ 1, we would have s ¼ ij  1. Using our
multiattribute notation, the remaining trip time s simply becomes a new
dimension of the attribute vector a. Given this representation, we can solve
multiperiod problems using the same techniques that we have described up to
now.
This particular solution creates practical problems in transportation
applications. Problems in trucking and rail, for example, can have trip
times that range from 30 min to 3 days (for movements from the midwest
to the west coast). We can often work with time steps of 2 or 4 h, producing
trips that are often 10–20 time periods in length. The result is an attribute
space A that is now approximately 10 times bigger (a dramatic increase
in the size of the problem). Since a single movement is now broken into 10
or
20
time
steps,
pure
forward
pass
algorithms
become
completely
unworkable, although we can partly overcome the slow backward communi-
cation of duals using shortcuts that take advantage of the properties of the
problem.
The augmented state representation has to be viewed as a brute force
solution to the problem of multiperiod travel times which can actually hide
nice structural properties. For example, it is not readily apparent using this
representation that the problem of multiperiod travel times vanishes when we
622
W.B. Powell and H. Topaloglu

use linear functional approximations. When ^QC,tþ6 is a linear function, both
locations a and d ‘‘see’’ the same slope. If they both send containers in
response to an attractive slope, then the sample gradient of the function at
location c will be reduced, and the location will become less attractive. Over
suﬃcient iterations, the model should discover the slope that attracts capacity
from closer locations but not farther ones.
It is beyond the scope of our presentation to fully describe the solution to
the ‘‘multiperiod travel time’’ problem when using nonlinear functional
approximations, but we note that it involves replacing the single functional
approximation ^Qt0 with a family of functions ^Qtt0 which are used to describe
the impact of decisions made at time t on future points in time t0>t. This
approach produces solutions that are comparable in quality to those obtained
using nonlinear approximations with single-period travel times, but as of this
writing, the theory behind this approach is immature.
We again see that linear approximations avoid complexities that arise in
the context of nonlinear approximations. But, the jury is still out regarding
the approach that will produce the best results in the laboratory, and
implementable results in the ﬁeld.
7
Some experimental results
There is surprisingly little work comparing diﬀerent stochastic program-
ming approaches. This is especially true of multistage problems, but it is even
true of the much more mature two-stage problem. Furthermore, the work on
two-stage problems has not been done explicitly in the context of resource
allocation problems (they are simply characterized as two-stage linear
programs) which makes it diﬃcult to generate a library of datasets which
focus on the speciﬁc dimensions of resource allocation problems (such as
number of locations, number of commodity types, repositioning costs in the
second stage, and so on). As a result, we do not have a standard library of test
datasets for either two-stage or multistage resource allocation problems.
This
chapter
has
described
the
use
of
a
relatively
new
class
of
approximation strategies that are especially well suited to resource allocation
problems. These approximations focus on using linear or separable, nonlinear
approximations of the recourse function. Many resource allocation problems
require integer solutions. Separable, nonlinear functions can be constructed as
piecewise linear approximations which produces ﬁrst stage problems that are
either pure networks, or integer multicommodity ﬂow problems with very
tight LP relaxations. In this section, we provide some preliminary compari-
sons between these approximation strategies and a variant of Benders
decomposition called the CUPPS algorithm.
Section 7.1 describes some experiments that were performed in the context
of two-stage problems. Section 7.2 then presents some results for multistage
problems.
Ch. 9. Stochastic Programming in Transportation and Logistics
623

7.1
Experimental results for two-stage problems
Virtually all problems in transportation and logistics involve multistage
problems, but as our discussion has demonstrated, multistage problems are
typically solved as sequences of two-stage problems. As a result, we have to
begin with an understanding of how well we can solve two-stage problems.
We undertook a series of preliminary experiments focusing on questions
regarding rate of convergence, scalability and solution quality. We used a
randomly generated dataset (which allowed us control over its characteristics),
and compared SPAR (which uses separable, piecewise linear approximations)
and CUPPS (based on Benders decomposition). Our evaluation strategy
consisted of running each algorithm for a ﬁxed number of training iterations,
and then comparing solution quality over a series of testing iterations.
Our datasets were created very simply. N locations were uniformly
generated over a 100  100 square. Initial supplies of resources were randomly
generated and spread around these locations. The resources and demands
were generated in such a way that ensured that the expected number of
resources equaled the expected number of demands (our work has shown that
this is when the problems are the most diﬃcult, the most interesting and the
most realistic). Demands (in the form of loads of freight to be moved) were
randomly generated with both an origin and a destination, where the contri-
bution from covering a demand was set at $1.5 per mile, where the length
of the load is given by the distance from the origin to the destination.
Transportation costs in the ﬁrst stage are ﬁxed at $1 per mile, while
transportation costs in the second stage are ﬁxed at $2 per mile. This
provides an incentive to reposition in the ﬁrst stage before we know what the
demands are.
Our ﬁrst experiments studied the rate of convergence of each algorithm on
a dataset with 30 locations. Fig. 16 shows the objective function for SPAR and
CUPPS averaged over 50 testing iterations, as a function of the number of
training iterations. With 950 training iterations, the methods are virtually
identical. However, as the number of training iterations diminishes, SPAR
seems to perform better, suggesting that it has a faster rate of convergence.
This conclusion is supported in Fig. 17 which compares SPAR and CUPPS
as a function of the number of locations. For each run, we used 200 training
iterations, and the algorithms were run on problems with 20, 30, 40 and 90
locations. The results show that SPAR and CUPPS work similarly for smaller
problems, but that SPAR works better (with 200 training iterations) for larger
problems. This suggests that the SPAR-class algorithms exhibit a faster rate of
convergence, especially as the problem size grows.
We ﬁnally looked at the results for every observation within the test sample
to get a sense of the distribution of the diﬀerence between SPAR and CUPPS
(see Fig. 18). To our surprise, we found that SPAR and CUPPS provide
almost identical results for every outcome for smaller datasets. For larger
datasets, SPAR outperformed CUPPS on every outcome.
624
W.B. Powell and H. Topaloglu

Fig. 16. The eﬀect of the number of training iterations on SPAR and CUPPS, illustrating
the faster convergence for SPAR.
Fig. 17. SPAR vs. CUPPS for two-stage problems, illustrating better results for SPAR
when the problem size grows.
Ch. 9. Stochastic Programming in Transportation and Logistics
625

7.2
Experimental results for multistage problems
The solution of multistage problems for our applications consist of solving
sequences of two-stage problems. The question now is, how well does this
work? Should we expect that an optimal or near-optimal algorithm for two-
stage problems will work similarly on multistage problems?
The biggest diﬀerence between two-stage and multistage problems for our
problem class is that the sequences of two-stage problems that we solve in a
multistage setting have random initial starting states. When we solve a two-
stage problem, the initial state is (normally) deterministic. This means that the
optimal solution to the ﬁrst stage is deterministic, which means that our
approximation for the second stage has to be accurate only in the vicinity of the
optimal solution of the ﬁrst stage. In the case of multistage problems, the initial
resource state at some time t in the future depends on previous decisions, while
the approximation of the recourse function for this problem is ﬁxed, and must
perform well over a range of initial states. As a result, the demands on the
accuracy of the recourse function for the second stage are much higher.
A major diﬃculty that arises in the evaluation of approximations for
multistage problems is identifying a good benchmark. Optimal solutions are
simply not obtainable, and tight bounds are not readily available. For this
reason, we use two strategies. First, it is useful to see how well a stochastic
algorithm works on a deterministic problem. This need arises since it is
typically the case that a company will want to test how well the algorithm
works by running it on past history (which is deterministic). Deterministic
formulations tend to be the benchmark, and if a stochastic algorithm does not
work well on a deterministic problem, it raises the question of how it can be a
good method for a stochastic problem.
The second strategy we use is to compare against deterministic rolling
horizon procedures using stochastic data. Again, this is the most common
strategy used in engineering practice for solving stochastic problems.
We ﬁrst ran the SPAR algorithm on a deterministic, single commodity
problem which can be formulated as a pure network. A signiﬁcant assumption
is that the time at which a load had to be moved was ﬁxed (so-called tight
time windows). Table 1 reports these results for problems with 20, 40 and
Table 1
Percentage of integer optimal value obtained using SAFE for second set of
deterministic experiments with single-period time windows (network problems)
Locations
Simulation horizon
15
30
60
20
100.00%
100.00%
100.00%
40
100.00%
99.99%
100.00%
80
99.99%
100.00%
99.99%
626
W.B. Powell and H. Topaloglu

80 locations. These results indicate that the algorithm is eﬀectively returning
optimal solutions (Fig. 18).
We then ran the algorithm on four stochastic datasets and compared
against a rolling horizon procedure (RHP). The RHP used a point forecast of
the future to make decisions for the current time period. Tests were run with
diﬀerent planning horizons to ensure that we were using the best possible
planning horizon for the RHP. The results are shown in Fig. 19 which shows
that the SPAR algorithm is producing results that are signiﬁcantly better than
a deterministic RHP.
Further research is needed before we understand the true value of a
stochastic formulation. Our rolling horizon experiments were performed
assuming that there was no advance information. The value of a stochastic
model also depends on the economics of making the wrong decision (the
recourse).
8
A list of extensions
This chapter has introduced a basic problem class, discussing along the way
practical algorithmic strategies, but steadily introducing issues that address
the richness of transportation problems. Our notational framework, which at
ﬁrst may seem clumsy to researchers accustomed to even simpler notation, is
Fig. 18. SPAR outperforms CUPPS as the problem size grows for every outcome in the
testing dataset.
Ch. 9. Stochastic Programming in Transportation and Logistics
627

designed to provide a natural bridge between the classical notation of
mathematical and stochastic programming, while providing for some of the
issues that arise in practice. Our progression of problems, from two-stage to
multistage, from single commodity with no substitution through multi-
commodity and heterogeneous resource allocation problems, was designed to
bring the reader through a list of issues that add to the realism of the model
being considered.
We have brought the reader to the edge of realistic problems that rise in
practice, but real problems of the type that arise in freight transportation have
even more surprises to delight and frustrate the research community. In this
section, we provide a hint of problems that remain to be addressed. All of the
issues listed below represent forms of inaccurate information.
a) Random travel times—Not only are there multiperiod travel times, it is
normally the case that the travel time is random. A travel time may be
uncertain even when a decision is made.
b) Advance information—Customers place orders in advance. Railroads
might let you know that they will give you empty cars in 3 days. A driver
might tell you that he will start in a week. We need to model the
presence of information that is known, but not actionable.
c) Demand backlogging and the ‘‘now vs. later’’ problem—If we do not
serve the customer request now, we may be able to serve it later (at a
price). We can assign a driver to a distant load now, or wait for a closer
Fig. 19. Comparison of SPAR approximations to rolling horizon procedures for 20
location datasets and diﬀerent substitution rules.
628
W.B. Powell and H. Topaloglu

load to be called in later. We need to identify when we should make a
decision now (to serve a request) or wait until later.
d) Multiple, reusable layers—Perhaps the most challenging problem is the
presence of multiple resource layers. (Recall that customer demands can
also represent a kind of resource layer). The simplest example arises with
backlogging demands: if we do not serve a demand now, it is still in the
system in the next time period. In freight transportation, we may have to
manage drivers, tractors and trailers, or locomotives, boxcars and crews.
It is possible to model some freight transportation operations with four
or ﬁve layers, and most of them are reusable.
e) User noncompliance—An overlooked dimension of most models is that
what the model is recommending is not what is being implemented. So
the costs and contributions that we are adding up in the computer are
not the costs and contributions we are getting in the ﬁeld. The diﬀerence
between what a model recommends and what is implemented in the ﬁeld
is a source of randomness that draws into question the value of so-called
optimal solutions that ignore this source of randomness.
f) Multiagent control—Large problems are typically broken into smaller
problems which are managed by diﬀerent people. Decisions made by one
person need to anticipate the impact on another. But it is impossible to
predict what someone else will do with certainty. This is not the same as
the user compliance problem, but it is another instance of solving a
problem where the randomness is in predicting what someone will do.
g) Data errors—We all know about data problems and recognize that we
have to ﬁx them, but we overlook the fact that the presence of data
errors is again a source of noise. If data errors are going to require
humans to override model recommendations, then so-called ‘‘optimal’’
solutions are no longer optimal (even within a single stage).
h) Incomplete information—Random variables arise
when we
have
information that is not known now, but can be measured later. There
are problems where information is unknown but can never be measured
directly,
which
means
we
could
never
estimate
a
probability
distribution. But the missing information is captured in historical
databases of past decisions.
9
Implementing stochastic programming models in the real world
We close our discussion of stochastic problems by raising some of the issues
that arise when we try to implement stochastic programming models in
practice. In the beginning of this chapter, we made the argument that explicit
models of uncertainty produce more realistic behaviors, often exactly the
behaviors that humans will mimic (perhaps with less precision) but
deterministic models will overlook.
Ch. 9. Stochastic Programming in Transportation and Logistics
629

Humans have an innate ability to deal with imperfect information and
noise. We allow more time to make an appointment. We provide slack time in
airline schedules to allow for possible delays. We own extra trucks and
locomotives to account for breakdowns, congestion and spikes in demand.
Trucking companies have large rooms of people planning operations who
spend 90% of their time collecting and verifying data, and only 10% actually
making decisions. We would expect that planners would quickly embrace
models which capture the uncertainty that they spend so much time dealing
with.
Surprisingly, this is not the case. Stochastic models arise because of the
need to forecast an activity in the future, a forecast that is made with
uncertainty. And yet in the business world, the word ‘‘forecast’’ is
synonymous with the concept of a ‘‘point forecast.’’ When we ask for a
forecast of the number of box cars needed in a region next week, we do not
want to be told ‘‘somewhere between 70 and 100.’’ When we ask for a forecast,
we expect an answer such as ‘‘85.’’
At the heart of any stochastic programming application is a distributional
forecast, an explicit recognition that a range of outcomes is possible. As much
as people in operations have learned to deal with uncertainty, they uniformly
have diﬃculty working with models which capture this uncertainty. Often this
is because they are looking either for a speciﬁc recommendation of what to do
right now (which even a stochastic model should do) or a plan of what should
be done in the future. It can be said that a plan is a (point) forecast of a
decision. Even for events in the future, people want to be told what is going to
happen (even if they realize a plan has uncertainty, they are still looking for a
speciﬁc estimate of what is going to happen).
Consider the practical diﬃculty of testing a stochastic model. In a
deterministic model, we expect the model to move exactly the number of
freight cars that are needed. If a deterministic model moved 60 cars to satisfy
orders for 50, we might reasonably conclude that there was some sort of bug
in the software. Yet this might be exactly the right answer for a stochastic
model. But how do we know that we are getting optimal behavior, or simply
the result of a programming error?
For this reason, we usually ﬁrst test a stochastic programming model by
solving a deterministic problem, and comparing the solution against a
standard solver for deterministic problems. It seems obvious that an algorithm
that can solve a stochastic problem should also be able to solve a deterministic
problem, but this can be harder than it looks. Figure 20 shows a recourse
function for deterministic and stochastic models. As a rule, stochastic
problems are smoother and better behaved. As a result, linear approximations
can work quite well. However, these same techniques will not work as well
on the sharply angled function produced when we replace our range of
possible outcomes with a point forecast. While we can argue that we should
not have to test our stochastic algorithm on a deterministic model, this is
a powerful debugging and testing tool, and we have found that it is necessary
630
W.B. Powell and H. Topaloglu

to develop techniques that work well on deterministic as well as stochastic
problems.
10
Bibliographic notes
The techniques in this chapter have their roots in stochastic approximation
methods (Robbins and Monro (1951), Blum (1954), Dvoretzky (1956),
Gladyshev (1965)), stochastic gradient methods Ermoliev (1988), general
stochastic linear programming (Birge and Louveaux (1997), Infanger (1994),
KallandWallace(1994),HigleandSen(1991))anddynamicprogramming(both
classical methods reviewed in Puterman (1994), and approximate methods,
such as those covered in Bertsekas and Tsitsiklis (1996)). For reviews of these
topics, the reader is referred to the introductory chapters in this volume.
Applications in transportation and logistics represented some of the earliest
motivations for stochastic programming. Dantzig (1955) used ﬂeet manage-
ment (in an airline setting) as an early motivation for stochastic programming.
Ermoliev et al. (1976) formulated the planning of empty shipping containers
as a stochastic program.
There has been a rich history of research in ﬂeet management in the context
of the ‘‘car distribution problem’’ of railroads. Most of this work consists of
deterministic linear programming models (Feeney (1957), Leddon and Wrathall
(1967), Gorenstein et al. (1971), Misra (1972), White (1972), Herren (1973,
1977), White and Bomberault (1969), Haghani (1989), Mendiratta (1981) and
Mendiratta and Turnquist (1982)). Dejax and Crainic (1987) provide a thor-
ough review of the research in ﬂeet management at the time, covering both rail
and intermodal container applications. Crainic et al. (1993) provide a general
stochastic, dynamic model for container distribution.
Jordan and Turnquist (1983) provide a stochastic formulation of the empty
car distribution problem. In their model, a car could be assigned to at most
one demand, and cars could not be repositioned more than once. This structure
allowed the problem to be formulated as a nonlinear programming problem.
Powell (1986) extended this methodological approach, using the trucking
industry as the context, to multistage problems with reusable resources.
Fig. 20. Recourse functions for deterministic and stochastic functions.
Ch. 9. Stochastic Programming in Transportation and Logistics
631

This formulation involved forming deterministic decision variables which
speciﬁed the percentage of the supply of trucks at a node that would be moved
loaded or empty from one location to another. This line of research, however,
was unable to properly model the recourse strategy where a truck might be
assigned to choose from a set of loads going out of a location to various
destinations.
Powell (1987) solved this problem in a way that produced a pure network
formulation for the ﬁrst stage subproblem (see Powell (1988) for an overview
of diﬀerent ways of formulating the problem). A major strength of the
technique was that it produced nonlinear functions of the value of vehicles in
the future. The ideas behind this research produced a series of articles that
approximated the recourse function by using the structure of the underlying
recourse function (Powell and Frantzeskakis (1992), Frantzeskakis and Powell
(1990), Powell and Cheung (1994a,b) and Cheung and Powell (1996)). These
papers introduced concepts such as nodal recourse (the recourse is to allocate
ﬂow over diﬀerent links out of a node), tree recourse (the recourse is to
optimize ﬂows over a tree) and other restricted recourse strategies aimed at
approximating more complex problems. Although the results were promising,
this line of research required approximating the future in a way that prevented
the techniques from being applied to the most general (and realistic) problems.
Powell (1998) (see also Carvalho and Powell (2000)) took a diﬀerent tact
and solved the problem as a sequence of network problems, using linear
approximations of the value of the future. This approach was computationally
quite easy, and scaled to much harder problems. Powell et al. (2002b) showed
how the technique could be applied to the heterogeneous resource allocation
problem, which is a more general problem than the multicommodity ﬂow
problem (the resource attribute space is much larger). The use of linear
approximations to represent the future, however, produced instabilities that
were solved by the use of control variables that limited the amount of ﬂow
that could be moved from one location to another. This worked very well for
single commodity problems, but did not scale well to multicommodity or
heterogeneous resource allocation problems.
Godfrey and Powell (2001) introduce an adaptive sampling technique,
dubbed the CAVE algorithm, that produces nonlinear approximations of a
recourse function using stochastic gradients. The method is easy to apply and
produces piecewise linear, separable approximations of a recourse function.
Furthermore, all it requires is the dual variable from a second stage problem,
and does not require that the problem have any particular structure. Experi-
mental work suggested that the algorithm might be optimal for two-stage
problems, but at a minimum it produced results that were extremely close to
optimal for both deterministic and specially structured stochastic problems.
Godfrey and Powell (2002a) apply it to stochastic, multistage problems and
demonstrate very good results relative to rolling horizon procedures. Godfrey
and Powell (2002b) investigated the case of resource allocation where
the travel time from one location to another can be multiple periods.
632
W.B. Powell and H. Topaloglu

A naive application of the CAVE algorithm produced extremely poor results,
and a variation is suggested that provides results that are comparable to the
single period travel time case.
Topaloglu and Powell (2002) applies similar techniques to stochastic
multicommodity ﬂow problems. This problem class introduces the additional
complexity
that
multicommodity
problems,
combined
with
nonlinear
approximations of the future, produce sequences of (usually integer)
multicommodity ﬂow problems. The method appears to work well on both
deterministic
and
multistage
stochastic
integer
multicommodity
ﬂow
problems.
The SPAR algorithm is part of a broader class of algorithms that use
stochastic gradients but maintain structural properties such as concavity. This
strategy was ﬁrst suggested in Godfrey and Powell (2001) as the CAVE
algorithm, but the SPAR algorithm, introduced by Powell et al. (2002a), oﬀers
several provable convergence results and appears to also work better
experimentally (see Topaloglu and Powell, 2002 for the use of these techniques
for multistage problems). Auxiliary function methods (Culioli and Cohen,
1990; Cheung and Powell, 2000) maintain concavity by starting with a
concave function and using stochastic gradients to update the function
(eﬀectively tilting it).
References
Bertsekas, D., J. Tsitsiklis (1996). Neuro-Dynamic Programming, Athena Scientiﬁc, Belmont, MA.
Birge, J., F. Louveaux (1997). Introduction to Stochastic Programming, Springer-Verlag, New York.
Blum, J. (1954). Multidimensional stochastic approximation methods. Annals of Mathematical
Statistics 25, 737–744.
Carvalho, T.A., W.B. Powell (2000). A multiplier adjustment method for dynamic resource allocation
problems. Transportation Science 34, 150–164.
Cheung, R., W.B. Powell (1996). An algorithm for multistage dynamic networks with random arc
capacities, with an application to dynamic ﬂeet management. Operations Research 44(6), 951–963.
Cheung, R.K.-M., W.B. Powell (2000). SHAPE: A stochastic hybrid approximation procedure for
two-stage stochastic programs. Operations Research 48(1), 73–79.
Crainic, T., M. Gendreau, P. Dejax (1993). Dynamic stochastic models for the allocation of empty
containers. Operations Research 41, 102–126.
Culioli, J.-C., G. Cohen (1990). Decomposition/coordination algorithms in stochastic optimization.
SIAM Journal of Control and Optimization 28, 1372–1403.
Dantzig, G. (1955). Linear programming under uncertainty. Management Science 1, 197–206.
Dejax, P., T. Crainic (1987). A review of empty ﬂows and ﬂeet management models in freight
transportation. Transportation Science 21, 227–247.
Dvoretzky, A. (1956). On stochastic approximation, in: J. Neyman (ed.), Proc. Berkeley Sym. on Math.
Stat. and Prob., University of California Press, Berkeley, pp. 39–55.
Ermoliev, Y. (1988). Stochastic quasigradient methods, in: Y. Ermoliev, Wets, R. (eds.), Numerical
Techniques for Stochastic Optimization, Springer-Verlag, Berlin.
Ermoliev, Y., T. Krivets, V. Petukhov (1976). Planning of shipping empty seaborne containers.
Cybernetics 12, 664.
Feeney, G. (1957), Controlling the distribution of empty cars, in: Proc. 10th National Meeting,
Operations Research Society of America.
Ch. 9. Stochastic Programming in Transportation and Logistics
633

Frantzeskakis, L., W.B. Powell (1990). A successive linear approximation procedure for stochastic
dynamic vehicle allocation problems. Transportation Science 24(1), 40–57.
Gladyshev, E.G. (1965). On stochastic approximation. Theory of Prob. and its Appl. 10, 275–278.
Godfrey, G., W.B. Powell (2002). An adaptive, dynamic programming algorithm for stochastic
resource allocation problems I: Single period travel times. Transportation Science 36(1), 21–39.
Godfrey, G., W.B. Powell (2002). An adaptive, dynamic programming algorithm for stochastic
resource allocation problems II: Multi-period travel times. Transportation Science 36(1), 40–54.
Godfrey, G.A., W.B. Powell (2001). An adaptive, distribution-free approximation for the newsvendor
problem with censored demands, with applications to inventory and distribution problems.
Management Science 47(8), 1101–1112.
Gorenstein, S., S. Poley, W. White (1971). On the scheduling of the railroad freight operations,
Technical report 320-2999, ibm philadelphia scientiﬁc center, IBM.
Haghani, A. (1989). Formulation and solution of a combined train routing and makeup, and empty car
distribution model. Transportation Research 23B(6), 433–452.
Herren, H. (1973). The distribution of empty wagons by means of computer: An analytical model for
the Swiss Federal Railways (SSB). Rail International 4(1), 1005–1010.
Herren, H. (1977). Computer controlled empty wagon distribution on the SSB. Rail International 8(1),
25–32.
Higle, J.L. and S. Sen (1991), Stochastic Decomposition: an algorithm for two stage linear programs
with recourse, Math. of Operations Research 16, 215–240.
Infanger, G. (1994). Planning under Uncertainty: Solving Large-scale Stochastic Linear Programs, The
Scientiﬁc Press Series, Boyd & Fraser: New York.
Jordan, W., M. Turnquist (1983). A stochastic dynamic network model for railroad car distribution.
Transportation Science 17, 123–145.
Kall, P., S. Wallace (1994). Stochastic Programming, John Wiley and Sons, New York.
Leddon, C., E. Wrathall (1967). Scheduling empty freight car ﬂeets on the louisville and nashville
railroad, in: Second International Symposium on the Use of Cybernetics on the Railways, October,
Montreal, Canada, pp. 1–6.
Mendiratta, V. (1981). A dynamic optimization model of the empty car distribution process, Ph.D.
Dissertation, Department of Civil Engineering, Northwestern University.
Mendiratta, V., M. Turnquist (1982). A model for the management of empty freight cars. Trans. Res.
Rec. 838, 50–55.
Misra, S. (1972). Linear programming of empty wagon disposition. Rail International 3, 151–158.
Powell, W.B. (1986). A stochastic model of the dynamic vehicle allocation problem. Transportation
Science 20, 117–129.
Powell, W.B. (1987). An operational planning model for the dynamic vehicle allocation problem with
uncertain demands. Transportation Research 21B, 217–232.
Powell, W.B. (1988). A comparative review of alternative algorithms for the dynamic vehicle allocation
problem, in: B. Golden, A. Assad (eds.), Vehicle Routing: Methods and Studies, North Holland:
Amsterdam, pp. 249–292.
Powell, W.B., A., C.T. (1998). Dynamic control of logistics queuing network for large-scale ﬂeet
management, Transportation Science 32(2), 90–109.
Powell, W.B., R. Cheung (1994). A network recourse decomposition method for dynamic networks
with random arc capacities. Networks 24, 369–384.
Powell, W.B., R. Cheung (1994). Stochastic programs over trees with random arc capacities. Networks
24, 161–175.
Powell, W.B., L. Frantzeskakis (1992). Restricted recourse strategies for stochastic, dynamic networks.
Transportation Science 28(1), 3–23.
Powell, W.B., A. Ruszczynski, H. Topaloglu (2002a). Learning algorithms for separable approxima-
tions of stochastic optimization problems, Technical report, Princeton University, Department of
Operations Research and Financial Engineering.
Powell, W.B., J.A. Shapiro, H.P. Sima˜ o (2002). An adaptive dynamic programming algorithm for the
heterogeneous resource allocation problem. Transportation Science 36(2), 231–249.
634
W.B. Powell and H. Topaloglu

Puterman, M.L. (1994). Markov Decision Processes, John Wiley and Sons, Inc, New York.
Robbins, H., S. Monro (1951). A stochastic approximation method. Annals of Math Stat. 22, 400–407.
Sutton, R., A. Barto (1998). Reinforcement Learning, The MIT Press, Cambridge, Massachusetts.
Topaloglu, H., W.B. Powell (2002). Dynamic programming approximations for stochastic, time-staged
integer multicommodity ﬂow problems, Technical report, Princeton University, Department of
Operations Research and Financial Engineering.
White, W. (1972). Dynamic transshipment networks: An algorithm and its application to the
distribution of empty containers. Networks 2(3), 211–236.
White, W., A. Bomberault (1969). A network algorithm for empty freight car allocation. IBM Systems
Journal 8(2), 147–171.
Ch. 9. Stochastic Programming in Transportation and Logistics
635

Chapter 10
Stochastic Programming Models in Energy
Stein W. Wallace
Molde University College, Servicebox 8, NO-6405 Molde, Norway
Stein-Erik Fleten
Department of Industrial Economics and Technology Management, Alfred Getz v. 1,
Norwegian University of Science and Technology, NO-7491 Trondheim, Norway
Abstract
We give the reader a tour of good energy optimization models that explicitly
deal with uncertainty. The uncertainty usually stems from unpredictability of
demand and/or prices of energy, or from resource availability and prices. Since
most energy investments or operations involve irreversible decisions, a stochastic
programming approach is meaningful. Many of the models deal with electricity
investments and operations, but some oil and gas applications are also
presented. We consider both traditional cost minimization models and newer
models that reﬂect industry deregulation processes. The oldest research precedes
the development of linear programming, and most models within the market
paradigm have not yet found their ﬁnal form.
Key words:
Stochastic programming, energy, regulated markets, deregulation,
uncertainty, electricity, natural gas, oil.
1
Introduction
The purpose of this chapter is to discuss the use of stochastic programming
in energy models. This is not a well deﬁned topic. Let us therefore start by
outlining what this chapter is and what it is not. First, this is not an annotated
bibliography. Its purpose is to help the reader see where stochastic pro-
gramming can be used, and to point to relevant existing literature. We do not
attempt to be complete in our references, only to help the reader ﬁnd good
starting points. We shall discuss both existing models and the potential for
new arenas.
A. Ruszczyn´ ski and A. Shapiro, Eds., Handbooks in OR & MS, Vol. 10
 2003 Elsevier Science B.V. All rights reserved.
637

Then, what shall we understand by the reference to energy models in
stochastic programming? Generally, stochastic programming refers to a
problem class, and not to the choice of solution procedures. Many of the
models in this class can be solved both with tools from mathematical
programming and as stochastic dynamic programs (SDPs). This book is about
stochastic programs solved with tools from mathematical programming.
However, the view we have taken in this chapter is that we cannot include or
exclude interesting models solely on the basis of what solution method the
authors have chosen. Hence, if an existing model represents a stochastic
dynamic decision problem which can be formulated as a stochastic program,
we include it irrespective of whether it is solved with methodology from
mathematical programming or set and solved as an SDP.
Furthermore, to have made the point, this chapter is not about operations
research and energy. This ought not to aﬀect our models too much, as we are
of the opinion that most real decision are made under uncertainty, but it will
aﬀect our referencing to the literature.
As part of the preparation for this chapter we had the privilege of reading a
text, which for our ﬁeld, is very old. Masse´ (1946) authored two volumes on
hydro scheduling. The books are based on work performed before and during
World War II. Of course, he does not discuss stochastic programming as
such—the term was not invented at the time—but he discusses models and
methodology that would ﬁt the premises of this chapter. It is very interesting
to see how he walks his readers through some very deep arguments about why
deterministic model are not good enough. He points to the fact that looking
at a deterministic future is far too optimistic, and that ﬂexibility will be
disregarded.
His major point is that hydro scheduling is about releasing water such that
the immediate ﬁnancial gain equals the expected future value of water. The
expected future value of water is presented as a function of reservoir level,
present inﬂow (to the extent that there is memory in that process), and time
(to represent seasonality). He gives optimality conditions for this case. In fact,
he has a long discussion to the eﬀect that all uses of natural resources is a
tradeoﬀbetween use now and use in a stochastic future. To illustrate the use
of statistics about the future, he makes the reference that if you wish to check
the probability that you are alive tomorrow, you look at your present health,
if you wish to know if you are alive in thirty years, you resort to statistics.
Another fact, dear to all stochastic programmers, is his pointing out that
while deterministic multiperiod optimization yields decisions for all periods, a
stochastic approach only yields policies or strategies.
A further major issue in the books is the objective function of the opti-
mization. Should we maximize expected proﬁt or expected utility (which he
denotes psychological expectation in contrast to mathematical expectation)?
He is concerned about some of the well known paradoxes when using expected
proﬁt, and he always refers to Borel for these examples. He is also very much
concerned about risk, and strongly believes that risk will always be with us.
638
S.W. Wallace and S.-E. Fleten

(He clearly had not thought of hedging in the ﬁnancial markets.) He comes
very close to deﬁning an eﬃcient frontier with expected proﬁt on one axis and
the probability of shortage of water on the other. His premise here is that the
owner of a reservoir has agreements with some supplier, and that any
reasonable agreement will be such that in extremely dry years, the contract
cannot be fulﬁlled.
When decision problems are formulated and solved as deterministic
problems, odd and special situations are often automatically excluded from
consideration as only the expected values—the normal cases—are considered.
Masse´ has the view that this can be dangerous, as what may appear to be a
detail at the time of analysis, may later turn out to have had a major eﬀect on
the development: ‘‘Le nez de Cle´ opaˆ tre, s’il euˆ t e´ te´ plus court, toute la face de
la terre aurait e´ te´ change´ e.’’
This chapter has ﬁve more sections. Section 2 is on regulated electricity
markets. This is clearly the best developed area for use of stochastic
programming in energy. Section 3 discusses the much newer area of de/re-
regulated electricity markets. We close with two shorter sections on oil and
natural gas, and a conclusion.
2
Electricity in regulated markets
This section discusses models for electricity production, thermal and hydro-
based, in a setting of a regulated utility. Transmission planning and operations
will not be considered. The utility can be either a single producer, or several
producers that are perfectly coordinated by choice or by law. Much of the
newer literature on electricity production is set in a framework of de(re)regu-
lation and competition. We wait with this subject until the next session.
2.1
Overview of models
Many diﬀerent models are used in power systems planning. A possible
classiﬁcation divides the diﬀerent models according to the planning horizon.
Long term planning models deal with investments and typically have a 15–20
year horizon. Medium term planning is done over a 1–3 year range, and deal,
for example, with reservoir management. Short term planning typically deals
with problems with horizons of one week or shorter, such as unit commitment
and economic dispatch.
The perspective taken in these models is that of a social planner or an ideal
public utility. The industry has traditionally been heavily regulated with
considerable central planning. The reason for regulation is that the industry is
prune to market failure; use of the transmission grid causes changes in its
capacity in other parts of the network (externalities). If demand and supply is
not matched at each instant, the whole or large parts of the system breaks
Ch. 10. Stochastic Programming Models in Energy
639

down; reliability is a public good. Local utilities have typically had a
monopoly within their area, preventing competition.
The demand in these models is mostly portrayed as price-inelastic; a
deterministic or stochastic demand is to be met at minimum cost. A standard
textbook on electricity operations is Wood and Wollenberg (1996). Some of
these models may still have some relevance in a market setting, because the
deregulated utility often still has the obligation to serve local demand.
Similarly, the utility may have committed to a particular load schedule in the
spot market.
2.2
Long term planning
By long term planning we will normally mean planning large investments,
be that building thermal units, or constructing hydro reservoirs and turbines.
The starting point for such an analysis is always a projection of future load
(demand). Let us ﬁrst brieﬂy see how the load is normally presented in such a
setting. The starting point will a load curve for each individual day of the
year—possibly split into groups of days with similar patterns. These curved
will possess the common pattern of having peaks in the morning and
afternoon, reﬂecting our way of life. The ﬁrst step is to sort these curves
according to decreasing loads, to achieve daily load duration curves. These
curves are then added together to form a curve like the one in Fig. 1. To the
left is the hour with the highest load during the whole year, and to the right the
one with the lowest. For example, h is the number of hours in a year for which
the load is at least L (MW).
Normally, this curve is not smooth, but step-wise, as the unit along the
horizontal axis is at least one hour. To simplify the presentation, let us assume
that there are only two steps, the base load period and the peak load period.
What we are about to present is inspired by Murphy et al. (1982), and the ﬁrst
result we are to illustrate comes from that paper. Consider the simpliﬁed
picture in Fig. 2
The total energy consumption in base load is given by t2L1, and in peak
load t1ðL2  L1Þ. Assume we have two technologies, for example two diﬀerent
Fig. 1. Load duration curve for one year (8760 h).
640
S.W. Wallace and S.-E. Fleten

types of thermal units, and let us simply denote them ‘1’ and ‘2’. Let f1 be the
annualized ﬁxed costs per unit of production capacity for technology 1, and let
c1 be the operating costs per MWh, also for technology 1. For technology 2, f2
and c2 are similarly deﬁned. Let xi for i ¼ 1, 2 be the installed capacity of
technology i. Furthermore, let yib be the production of base load for
technology i and correspondingly yip for peak load. The (deterministic)
problem now becomes:
min
X
2
i¼1
fixi þ
X
2
i¼1
ciðt2yib þ t1yipÞ
ð2:1Þ
subject to
y1b þ y1p  x1
y2b þ y2p  x2
t2ð y1b þ y2bÞ ¼ dbð¼ t2L1Þ
t1ð y1p þ y2pÞ ¼ dpð¼ t1ðL2  L1ÞÞ
and non-negativity
ð2:2Þ
where db is the load in the base period and dp the additional demand in the
peak period. The ﬁrst two constraint say that production cannot exceed
installed capacity of the two technologies, whereas the last two constraints
express that base load and additional peak load must be satisﬁed.
This model helps us ﬁnd the optimal investment to meet a known future
demand. But, of course, future demand is not known. Hence, as a ﬁrst step of
making the model more realistic, let us assume that there are several possible
future load duration curves. Let curve k occur with probability pk. A
straightforward recourse model now becomes.
min
X
2
i¼1
fixi þ
X
K
k¼1
pk
X
2
i¼1
ck
i ðt2yk
ib þ t1yk
ipÞ
ð2:3Þ
Fig. 2. Simpliﬁed load duration curve for illustrative purposes.
Ch. 10. Stochastic Programming Models in Energy
641

subject to, for all k
yk
1b þ yk
1p  x1
yk
2b þ yk
2p  x2
tk
2ð yk
1b þ yk
2bÞ ¼ dk
bð¼ tk
2Lk
1Þ
tk
1ð yk
1p þ yk
2pÞ ¼ dk
pð¼ tk
1ðLk
2  Lk
1ÞÞ
and non-negativity
ð2:4Þ
where superscript k always refers to load duration curve (scenario) k. Note
that the ﬁrst stage variables xi do not have a superscript k. Also note that for
given values of the ﬁrst-stage decisions xi, this problem falls apart and
becomes standard transportation network ﬂow problems, one for each load
duration curve, see Wallace (1986) for details.
What would we expect to get from (2.3) and (2.4) if we compare its solution
to the case where (2.1) and (2.2) are solved with the expected load duration
curve, that is, the case where we instead of scenarios use a ‘typical’ or average
year and arrive at a deterministic model? Or even more importantly, how do
we expect the solution to the stochastic optimization problem to diﬀer from
individual scenario problems? Diﬀerent technologies for energy production
will vary in some aspects. Some will have long lead times, high investments
costs and low operating costs, others will have shorter lead times, lower
investment costs, but at the price of higher operating costs. In a given
scenario, the future demand will be known with certainty. That will tend to
produce the use of a technology which perfectly matches the load. This will
typically be a technology with high investment costs and low operating costs.
The capacity of the unit will perfectly match the needs reﬂected in the load
duration curve (scenario). Over-investments will never take place, and
shortages will never occur. Smaller units which are more ﬂexible, but have
higher operating costs, will tend to lose out, as their qualities will not be
reﬂected in the model. Why pay for ﬂexibility you do not need? An example of
these aspects is shown by Smeers (1990), where he discusses the relationship
between coal (expensive but ﬂexible) and nuclear (inexpensive but also
inﬂexible).
An interesting question raised in Murphy et al. (1982) is if there is a version
of the deterministic problem, such that if we solve that problem, we obtain the
solution to the stochastic problem. From a general point of view, this is
something we normally do not ﬁnd for stochastic programs, but in this case
there is a result.
Take the individual load duration curves, and multiply the duration of each
block by pk. In our simpliﬁed example, multiply all numbers on the horizontal
axis by pk to obtain tk
1pk and tk
2pk. Notice that a year is 8760 h, thus
P tk
2pk ¼ 8760. Create a new load duration curve from these new curves to
642
S.W. Wallace and S.-E. Fleten

arrive at a new aggregated curve. This is illustrated in Fig. 3. In the horizontal
summation we have kept the patterns for peak and base load in the scenarios.
This is only to make it easier to see where the columns come from. In reality,
in the summation, there are four diﬀerent load levels, to be treated with four
parameters ti and four load levels Li. Generally, the number of steps in the
sum equals the sum of the number of steps in the individual load duration
curves.
The main result here is that if we carry out a deterministic investment
analysis using this horizontally aggregated load duration curve, we obtain the
same solution as if we had solved the recourse problem above. But the
problem is simpler as the number of constraints saying that we cannot use
capacity not installed will decrease from k times the number of technologies to
just the number of technologies.
But the result is dependent on some assumptions, in particular that the
operating costs do not vary with output level, implying that the ck
i are ﬁxed
irrespective of technology i being used for base or peak load (as it is in (2.3)
and (2.4)), and irrespective of scenario, so ck
i :ci. But even so, this is a strong
and interesting result for the two-stage case.
Sherali et al. (1982, 1984) discuss the model in greater detail, with an
emphasis on cost sharing for the ﬁxed charges fi. This brings the problem into
the realm of peak load pricing, that is, the cost of capacity is always related to
those (users or scenarios) that have the maximal use of the capacity.
The load duration curve can also be approximated in a diﬀerent way. An
example is given in Fig. 4. In this case the resulting problem is quadratic. For
a discussion, see the very early paper of Louveaux (1980).
Discrete decisions
The basic recourse model above can of course be extended in many
directions. First, in many cases the variables xi can take on only a ﬁnite
Fig. 3. Horizontal aggregation of two load duration curves.
Ch. 10. Stochastic Programming Models in Energy
643

number of values, which brings us into (stochastic) mixed integer program-
ming. Bienstock and Shapiro (1988) integrates capacity expansion, supply
contracts and operations planning in an electricity utility via a two-stage
stochastic program with integer variables in both stages.
Multi-stage and lead times
In the same way, there are obvious possibilities in setting up a multi-stage
problem, where load duration curves are revealed over time, and investments
made stage by stage. Such a setup will show the importance of lead times in
construction. The option to wait will favor the technologies with short lead
times. This eﬀect is not easy to capture in single- or two-stage models. Hence,
this dynamic eﬀect comes in addition to the eﬀect discussed earlier where a
stochastic model will be able to favor ﬂexible technologies (that are never
optimal in deterministic worlds). A good discussion of this problem can be
found in Gardner and Rogers (1999). Flexibility is also discussed by Gardner
(1996), where there is a focus on the relationship between ﬂexibility in the
ﬁnancial sense, and the eﬀects of emission control of acid-gas. The paper
shows that when acid-gas emission control is added, some of the more ﬂexible
technologies lose in the competition. This is particularly true for gas
combustion turbines. For further discussions of emission policies, see Manne
and Richels (1991, 1995), Manne and Olsen (1996) and Birge and Rosa (1996).
Other contributions in the multi-stage setting are Manne and Richels (1978),
Gorenstin et al. (1993), Dantzig and Infanger (1993), Escudero et al. (1995)
and Pereira et al. (1995).
Shortage—or lost load
It is traditional in monopoly-based production planning to take it for
granted that all demand must be satisﬁed. Qiu and Girgis (1993) take a
diﬀerent view, and say that since, ultimately, end users must always pay for
the investments, they may be better oﬀwith a slight probability of an outage.
They therefore set up a capacity investment problem where outages are priced
rather than forbidden. Taking into account that scenarios (possible load
duration curves) will always be somewhat subjectively chosen, and that
Fig. 4. Discretization of load duration curve resulting in a quadratic objective function.
644
S.W. Wallace and S.-E. Fleten

outages to some extent correspond to worst-case analysis, it may be very
good, modeling-wise, to allow for outages at a high cost. There will always be
a slight chance that something even worse than the worst scenario of the
model could occur, and hence, that an outage could occur even if the model
claimed otherwise.
A further discussion of long-term planning can be found in Hobbs (1995).
2.3
Medium-term planning
Hydro-thermal scheduling
An important problem in the medium-term scale is hydro-thermal
scheduling. For hydro reservoirs, the problem is essentially to strike a
balance between immediate and future (opportunity) costs of using the water.
Stochastic optimization models for this problem are in daily use in hydro-
dominated systems.
The following section presents the production scheduling problem. There
are T time periods, or stages, as illustrated in Fig. 5.
Periods are time intervals between stages, which are discrete points in time.
The ﬁrst period is deterministic. To simplify exposition, the problem is
formulated for a producer with only one reservoir.
The producer is operating an ongoing business with an inﬁnite future. We
would like to avoid end eﬀects, which are distortions in the model decisions
due to the fact that the model has a ﬁnite horizon, whereas the real business
problem has an inﬁnite horizon. For example, if in the model the value of the
reservoir at the end of the model horizon is too low, say equal to zero, then the
end eﬀect would be that too much water is sold in the last stage. There are
several alternatives for this problem. One is choosing the date of stage T such
that it makes sense to constrain the reservoir to be either empty or full at that
date, i.e., in the spring before snowmelt, or in the fall before winter sets in.
Another alternative requires estimating the end-of-horizon value of water in
the reservoirs from a more aggregate model with a longer time span. Third,
one can choose the time horizon of the model to be long enough to make the
ﬁrst stage decisions unaﬀected by the choice of horizon reservoir value
function. See Grinold (1980) for an approach to dealing with end eﬀects in
general energy models. Grinold’s observation is that the dual variables at the
end of the horizon should be in a steady state, and suggests introducing dual
constraints (i.e., primal variables) to ensure this. Another way of achieving
steady state dual variables in the reservoir management problem is described
by Lindqvist (1962). It involves starting with a guess for the dual variables,
which in this case equals the incremental values of stored water in the
Fig. 5. Time scale example.
Ch. 10. Stochastic Programming Models in Energy
645

(equivalent) reservoir, and iterating over the last year of the planning horizon
replacing the guesses with the water values obtained for one year before the
end of the horizon.
The stochastic variables are inﬂow, and demand . Scenarios are possible
histories of realizations of the stochastic variables up to the end of the
horizon. The event tree in Fig. 6 shows how the uncertainty unfolds over time.
A scenario in the event tree is a path from the root node to a leaf node. Each
node n represents a decision point, or equivalently a state, corresponding to a
realization of the random variables up to the stage of state n, denoted t(n). The
root state is n ¼ 1, and scenarios are uniquely identiﬁed by states at the last
stage, belonging to the set S. The set of all states is denoted N. The states have
unconditional probabilities Pn, satisfying
8 tP
njt(n) ¼ tPn ¼ 1. Every state
except the root has a parent state a(n). Let stage t decisions (for period t) be
made after learning the realization of the stochastic variables for that period.
The
inﬂow
process
is
multidimensional
and
has
strong
seasonal
components. The main bulk of inﬂow to reservoirs in North America and
northern Europe comes during spring, whereas in winter the precipitation
accumulates as snow. Forecasting the inﬂows and capturing the structure of
the processes and their degree of predictability is of vital importance to hydro
scheduling models. This issue is discussed by Tejada-Guibert et al. (1995).
The decision variables are reservoir discharge, vn, spill, rn, and reservoir
level ln. Each variable in the problem is indexed by the state to which it
belongs. Power generation is generally a nonlinear function of the height of
the water in the reservoir and the discharge, and could be non-convex. In our
exposition we disregard head variation eﬀects, and assume that generation is
proportional to ﬂow through the station, vn, where  is the constant hydro-
plant eﬃciency. In practice however, head variation eﬀects can be signiﬁcant,
particularly when balancing reservoirs with diﬀerent characteristics. If a
downstream reservoir has little storage capacity, then keeping its head up in
order to maximize eﬃciency may lead to increased risk of spilling water if
inﬂow increases too rapidly. This area needs further research.
Let VLðlnÞ be the value of the reservoir at the end of the horizon as
a function of the reservoir level. This function must be speciﬁed to avoid
end eﬀects. If a long term scheduling model is available, VL may be extracted
Fig. 6. Event tree and time scale example for T ¼ 5. The nodes represent decisions, while
the arcs represent realizations of the uncertain variables.
646
S.W. Wallace and S.-E. Fleten

from this model, e.g., in the form of incremental value of stored water in
reservoirs.
It is assumed that there is no direct variable cost of hydro production.
Thermal generation is represented by pin, for energy generated by unit i 2 I in
state n. This incurs variable cost FCið pinÞ, a convex function of pin. It consists
mainly of fuel costs, and is usually modeled as linear, piecewise linear or
quadratic. Nonconvex cases are plausible, for example in the case of a unit
that can be fed multiple types of fuels. With a typical minimum time
resolution of one week it is reasonable not to include startup costs for thermal
generation. Let  be a discount interest rate, Nt is the number of years (in
fractions of years) to period t,
min
p,v
X
n2N
Pnð1 þ ÞNtðnÞ X
i2I
FCiðpinÞ
"
#

X
s2S
Psð1 þ ÞNTVLðlsÞ
ð2:5Þ
The hydro reservoir balance is
ln  laðnÞ þ vn þ rn ¼ n,
ð2:6Þ
The demand constraint reads
vn þ
X
i2I
pin  n
ð2:7Þ
Time-dependent upper and lower limits on release and reservoir level are
imposed using
vtðnÞ  vn  vtðnÞ,
ð2:8Þ
ltðnÞ  ln  ltðnÞ,
ð2:9Þ
rn  0,
ð2:10Þ
for n 2 N and with initial reservoir level given.
Load curtailment is sometimes modeled as an extra thermal unit
having a marginal cost equal to an estimate of the marginal cost of unserved
energy.
In many systems the transmission system limits the opportunities for hydro-
thermal scheduling. There will be cases when transferring more electric energy
from one node of the system to another will not be possible. Electricity ﬂow in
transmission networks is governed by Kirchoﬀ’s laws and is limited by line
capacities. These physical phenomena must be taken into account when
including transmission constraints in the scheduling problem. Accurate
mathematical representations of these features typically involve nonlinear
and nonconvex equations with phase angles, voltages and power ﬂows.
Ch. 10. Stochastic Programming Models in Energy
647

For hydro-thermal scheduling, the network constraints are usually linearized,
however, into linearized (DC) power ﬂow (Wood and Wollenberg, 1996). This
problem has been modeled by Gorenstin et al. (1992).
Some schedulers feel more comfortable using deterministic models for this
problem. An important question in this context is what is the value of
stochastic optimization? Starting with Masse´ (1946), many researchers argue
that the stochastic aspects of the problem are important, and their neglect
should result in some loss. Deterministic solutions will underestimate the true
costs and the risk of spilling water, and deterministic models will not see any
value in waiting with releasing water in order to learn more about future
demand and/or inﬂow. The degree of cost underestimation depends on the
problem, e.g., Tejada-Guibert et al. (1995) show that it depends, for a given
system, on the demand and the severity of penalties on shortages. Philbrick
and Kitanidis (1999) show that the performance of deterministic solutions is
particularly poor for reservoir systems with limited storage capacity.
The typical horizon for hydro scheduling is a few months to a few years. A
typical length of the ﬁrst time step ranges from one week to a month. The
hydro scheduling model gives signals to hydro unit commitment via marginal
values of stored water in the reservoirs and/or via total generation during the
ﬁrst week.
2.4
Short term planning
Hydro unit commitment
In the hydro unit commitment problem the scheduler must determine what
turbine units to run in each time step (hourly or shorter) the next day or week,
and at which output level the running units should generate. Generating
stations may have several turbines each and may be coupled by their location
along the same river system. Turbines incur startup costs and the generation
of each station varies nonlinearly with the volume and with the net head1 of
the hydro discharge. This problem can be formulated as a large mixed-integer
nonlinear programming model with an objective of minimizing cost subject to
meeting a given demand. The cost is measured in terms of the volume of water
used or as the opportunity cost associated with that volume, i.e., using the
marginal values of stored water in each reservoir coming from medium-term
generation planning models. Stochasticity in such models may reside in load,
inﬂow, unit availability or cost. Of these, load is considered most important,
since it is temperature dependent, and temperature cannot be predicted with a
precision better than a few degrees even just a few hours in advance. Other
factors such as hydro inﬂow are accurately predictable on such short time
scales. The stochastic hydro unit commitment problem has been studied by
Philpott et al. (2000).
1 The net head is the diﬀerence between the height of the water immediately before and immediately
after the power station.
648
S.W. Wallace and S.-E. Fleten

If the net head varies signiﬁcantly on short term with upper reservoir
storage level, which is usually the case for small upper reservoirs and/or small
maximum head, there may be signiﬁcant gains from letting reservoir levels
cycle between high and low levels during the course of the day or week. Such
problems call for global optimization techniques, such as in Feltenmark and
Lindberg (1997). Other complicating issues are time delays from ﬂows leaving
a station to arriving downstream, a delay that may depend on the ﬂow rate.
Further, the generation function is not always concave in discharge, making
the standard approach of replacing it with a piecewise linear function
problematic. Discharge ramping and reservoir level constraints due to
navigational, environmental and recreational requirements add to the
diﬃculty. To avoid end eﬀects, horizon unit states must be constrained or
valued. In the case of time delays, in-transition ﬂows at the horizon must be
dealt with similarly.
Thermal unit commitment
In contrast to hydro unit commitment, where there are power stations
situated along rivers, the problem here is characterized by higher startup costs
and restrictions preventing thermal stress. When starting up a coal ﬁred unit
there is a time delay before the unit is available for generation. The task is to
ﬁnd a cost-minimal schedule, and a production level, for each generating unit
over time. The problem is to decide which units will be on/running, and how
much units that are on (committed) will produce. As mentioned above, the
load that is to be met and the availability of the generating units are uncertain
parameters aﬀecting the problem.
This has been modeled as a mixed integer stochastic program and has been
explored by Takriti et al. (1996), Carpentier et al. (1996), Dentcheva and
Ro¨ misch (1998) and Caroe and Schultz (1998). See also Gro¨ we-Kuska et al.
(2002), Nowak and Ro¨ misch (2000) and Gollmer et al. (2000).
Having jIj thermal and jJ j hydro plants, the objective is to minimize the
operating costs. Let uin be unit states, i.e., a binary decision variable that
represents whether thermal unit i is running (uin ¼ 1) or not (uin ¼ 0) in state n.
Operating costs consist of fuel cost FCið pin, uinÞ and startup costs SCinðuiÞ for
thermal units. Startup costs may depend on the amount of time the unit was
down before startup. Thus ui is a vector consisting of uin and unit states ui for
one or several predecessor states of n. Hydro plants only contribute to the
objective function with the water value VSðlsÞ at the end of the time horizon T,
where the vector ls ¼ ½fljsgj2J . This water value function approximates the
objective value for the problem (2.5)–(2.10) with T going to inﬁnity. The
objective function reads:
min
u,p,v
X
n2N
X
i2I
FCið pin, uinÞ þ SCinðuiÞ 
X
s2S
VSðlsÞ:
ð2:11Þ
Ch. 10. Stochastic Programming Models in Energy
649

The local demand n has to be satisﬁed in all states:
8 n 2 N :
X
i2I
pin þ
X
j2J
jvjn  n,
ð2:12Þ
where jvjn is the generation of hydro unit j. Additional constraints follow
(index i omitted since all constraints are for each unit i): The output of a unit
should be zero if the unit is oﬄine; otherwise it should be between a lower and
an upper bound ( p and p):
8 n 2 N : unp  pn  unp:
ð2:13Þ
Further single-unit constraints are minimum up- and down-times and
additional must-on/oﬀconstraints. Minimum up- and down-time constraints
are imposed to prevent thermal stress and high maintenance costs due to
excessive unit cycling. Denoting by  the minimum down-time of the unit, the
corresponding constraints are described by the inequalities (temporarily
switching to time subscripts instead of states):
utþ þ ut1  ut  1,
ð2:14Þ
for all  ¼ 1, . . . , minfT  t,   1g. Analogous constraints can be formulated
for describing minimum up-time restrictions, see e.g., Gro¨ we-Kuska et al.
(2002).
A reserve margin rt  0 is often imposed via reserve constraints
8 n 2 N :
X
i2I
ðuinpi  pinÞ  rtðnÞ
ð2:15Þ
to ensure that the model recommends an on-line capacity that exceeds the
predicted load, giving a ‘spinning reserve’. This is used, particularly in
deterministic models, to avoid an energy imbalance resulting from the
unexpected failure of a generating unit or an unexpected increase in load,
which may cause very costly brownouts or blackouts. Carpentier et al. (1996)
discuss the relationship between spinning reserve in a deterministic model of
the problem compared to a stochastic model without spinning reserve, and
uses rolling horizon optimization to arrive at an optimal level of reserve
margin. The models consider uncertainty in generator availability.
Deterministic approaches
Unit commitment is usually solved as a deterministic large scale mixed
integer program (Sheble and Fahd, 1994). It is therefore interesting to learn
about qualitative diﬀerences between stochastic programming solutions of the
650
S.W. Wallace and S.-E. Fleten

unit commitment problem and deterministic solutions. A priori we can state
that deterministic solutions will be characterized by extensive use of large
plants with high start-up costs, with relatively few starts. SP solutions on the
other hand, will typically use smaller units and will involve more startups of
ﬂexible but possibly high-marginal cost plants such as gas ﬁred units.
Deterministic models will know exactly how much power is needed at any time
and can thus plan to run low fuel cost plants at high output for long periods of
time. The gains that the model sees from such scheduling will outweigh the
high startup costs that typically come with such plants.
In deterministic models, a common approach to the uncertainty regarding
generator failure is to ‘‘derate’’ the units’ maximum generation rate according
to the probability of availability. However, this will underestimate the
expected operations cost and the probability of load being larger than peaking
capacity. Recognizing such operations cost underestimation, a class of models
known as production costing models have been developed (Wood and
Wollenberg, 1996). The purpose of these models is a more accurate estimation
of production costs by simulating and/or optimizing the dispatch of
generation under uncertainty of load and generator outages. Production
costing models are used both in long-term and operations planning. These
models are conceptually not much diﬀerent from SP-based generation
planning models, in fact, good SP models lessen the need for separate
production costing and reliability models. SP contributions in this class have
been made by e.g., Bloom (1983), Pereira et al. (1987, 1992) and Hobbs and Ji
(1999). See also the review by Hobbs (1995).
Economic dispatch and optimal power flow
Optimal dispatch of power under uncertainty has been considered by e.g.,
Bunn and Paschentis (1986), Gro¨ we and Ro¨ misch (1992) and Gro¨ we et al.
(1995). The models have a short time horizon, usually a day, with hourly or
ﬁner resolution. The unit commitment schedule (the unit states uin) is regarded
as given, and the problem is to determine a generation schedule (in the pin
variables) that minimizes operating costs (FCið pin, uinÞ) and satisﬁes the
demand.
Since this problem is near real-time operations, it is meaningful to include
transmission issues. This is considered by Pereira et al. (1987), who solve a
two-stage optimal power ﬂow problem.
2.5
Solution methods and computations
We focus on the modeling process and not the solution methods. However,
most of the SP energy papers focus on the solution method used to solve the
model, not the modeling process itself. Still, there is a relationship between
research on solution methods and model development, because models tend to
be developed only if there is hope of solving the model. Thus, as new solution
algorithms are published, new models are reported solved using twists of the
Ch. 10. Stochastic Programming Models in Energy
651

state of the art algorithms. Thus solution methods are discussed brieﬂy in this
subsection.
For hydro planning problems, stochastic dynamic programming has been
used for a long time; an early reference is Masse´ (1946). For surveys see
Yakowitz (1982), Yeh (1985) and Stedinger (1998). These methods have also
been used in unit commitment and expansion planning. However, a well
known problem with these methods is the curse of dimensionality. To use
them, it has been necessary to aggregate and/or decompose the problems
before solving them. An example of this is the aggregation of several hydro
reservoirs and connected power stations into a single equivalent reservoir/
power station pair. Relatively good heuristics have been developed for
supporting the aggregation/de-aggregation approximation process. Important
applications are presented by Terry et al. (1986) and Gjelsvik et al. (1992). A
somewhat
diﬀerent
approach
for
the
multireservoir
problem,
using
decomposition, is presented by Turgeon (1980) and Sherkat et al. (1985).
Still, methods that could handle multidimensional problems having many
state variables, were in demand. In the late 1970s, authors at Stanford
University (Birge, 1985) began experimenting with nested Benders’ decom-
position, and in electricity models this was used and reﬁned by Pereira and
Pinto (1985), Jacobs et al. (1995) and Morton (1996).
This method was able to solve multidimensional state type problems, but
was unable to match SDPs time decomposition abilities with respect to solving
stochastic programs having many stages. Nested Benders’ decomposition
works on a scenario tree whose number of nodes explodes with the number of
stages, and the size of the problem to be solved is proportional to the number
of such nodes. For a comparison of the main algorithms on reservoir
management problems see Archibald et al. (1999).
With this background, the algorithm of Pereira and Pinto (1991) created a
lot of interest in the energy optimization community. Termed stochastic dual
dynamic
programming (SDDP),
it
eﬀectively combines
the state-time
decomposition features of dynamic programming and the beneﬁts of nested
Benders’ decomposition. It represents a very important expansion of nested
Benders’ decomposition using two important concepts of cut sharing and
sampling. Commercial software based on this algorithm is in widespread use.2
In a deregulated setting, spot market prices become important as input to
power scheduling models. Assuming the price-taker case, prices are exogenous
and can be treated by ordinary linear stochastic programming.3 Prices are
autocorrelated, so the current price carries information about the likely future
outcomes of price. Thus it must be treated as a state variable, which posts a
problem in SDDP, because the future cost function is no longer convex in all
state variables. (As is well known and probably shown in earlier chapters in
2 The Stanford group under G. B. Dantzig worked out a similar decomposition/sampling algorithm
based on importance sampling approximately at the same time (Dantzig, 1989).
3 Ordinary is meant in contrast to game-theoretic approaches.
652
S.W. Wallace and S.-E. Fleten

this volume, the recourse cost function, or future cost function, is concave in
changes to objective function coeﬃcients and convex in changes to right hand
side coeﬃcients.) Thus the future cost function can no longer be supported by
cuts. This issue is discussed by Gjelsvik and Wallace (1996), who introduce an
algorithm that can handle stochastic prices by not sharing cuts across price
states. During the course of the algorithm the future cost function (a function
of all state variables) is built for each price state at each stage. Pereira et al.
(2000) approach the issue of stochastic prices causing nonconvex recourse
functions by using a cut classiﬁcation scheme.
Stochastic unit commitment problems are not yet in daily use, as far as we
know, and for algorithmic work on these stochastic integer problems we refer
to Gro¨ we-Kuska et al. (2002) and to other chapters in this volume.
3
Electricity in deregulated markets
This section discusses issues related to electricity production under market
conditions. Researchers have studied hydrothermal scheduling, risk manage-
ment, unit commitment and bidding problems in deregulated market settings.
Assumptions on market form, institutional and market design and existence
of derivative markets vary.
At the time of writing, electricity markets are still in transition from the old
regulated regime, motivating the development of hybrid models where there is
both a demand constraint and a wholesale market. The local load is to be met
at each instant, but the producer can choose to serve this load by his own
production capacity or by buying capacity in the market. The producer may
also produce more than the local load, selling the surplus in the market. See
f.ex. Takriti et al. (2000) and Gro¨ we-Kuska et al. (2002). A hybrid approach
may also be motivated by ‘‘imperfections’’ causing constraints on how much
the company can buy or sell in the wholesale market, or by a signiﬁcant
diﬀerence between the price of buying electricity in the spot market and the
price of selling to the spot market.
3.1
System-wide models
Some models try to capture aspects of the whole electricity system, having
the power price as endogenous variable, i.e., as a result of matching supply
and demand. Examples of such models are MARKAL, MPS, which focuses
on markets with a large share of hydro power, and BALMOREL. Stochastic
programming eﬀorts related to these models are reported by Fragniere and
Haurie (1996), Botnen et al. (1992) and Hindsberger (2003, papers F and G).
These models serve the needs of utility planners and policy makers in that they
can derive scenarios of market prices of electricity. The major advantage of
such models is that they capture the speciﬁc aspects of electricity and that the
scenarios generated are consistent with the assumptions underlying analyses
Ch. 10. Stochastic Programming Models in Energy
653

regarding e.g., future system-wide capacity and emission allowance policies.
These models are all developed for regulated markets. However, they have
become very popular for generating price scenarios in deregulated markets.
The reason is that in perfect markets, price will equal (long term) marginal
cost. A regulated market, as described in Section 2 of this chapter, is normally
based on a policy of eﬃciency and cost minimization so as to achieve exactly
the same result—price equal to long term marginal cost. Care must be taken,
however, so that the price-scenario generation does not take the form of pure
scenario analysis, that is, a large number of ‘‘What-if ’’-questions on the
external events. That would result in prices of electricity being too low, as each
path of investments would be done under full knowledge of the future,
underestimating the need to invest in (expensive) ﬂexibility. The modern
versions of MARKAL, like the one referenced above and Kanudia and
Loulou (1998), take this into account.
It is also important to remember the setting here. These models can be used
to generate price-scenarios (consistent with external events) for a small market
participant who does not herself aﬀect the market. A policy-maker can view
the price scenarios as the result of her actions, but cannot use them to make
other policy decisions. That would create a logical loop.
These models could of course also have been discussed in the previous
section on regulated markets, as some of them represent long term stochastic
investment models in the light of random demand and emission policies.
3.2
The role of futures markets
The electricity markets are developing into regional commodity markets.
This can be seen in the contract market where there is decreasing use of
complex physical sales contracts and increasing use of standardized ﬁnancial
contracts. As these derivative markets mature, they will serve an important
role in risk sharing and in giving economic signals to investment and
operations planning.
A common commodity contract is a forward contract, which entitles the
buyer of a contract the diﬀerence between the spot price and the agreed
contract price in the settlement period of the contract. In some markets these
contracts are known as contracts for diﬀerences (CfDs).
If the commodity can be stored, such as coal, oil and gas, the contract price
will be closely related to storage costs and interest rates, due to the arbitrage
opportunities that would otherwise be present. If futures prices are higher
than current spot prices compounded at the risk free rate plus storage costs,
an arbitrageur can buy a unit of the good (at price S0), ﬁnance this with a
bank loan, and short sell a futures contract. The storage costs may include
opportunity costs associated with the operational beneﬁts of having the
commodity immediately available in storage (convenience yield). At the time
of maturity, the arbitrageur sells the good (at ST), pays back the loan
654
S.W. Wallace and S.-E. Fleten

(erTS0), pays storage costs (C ) and settles the futures contract (FT  ST).
The safe future value of this project is
FV ¼ ST  S0 erT  C þ FT  ST ¼ FT  S 0erT  C:
If this value is positive, the futures price FT is too high compared to
the current spot price since the arbitrageur actually can make money on
this deal. Clearly, this value must be nonpositive in a reasonable model
of price dynamics. Similarly, a speculator holding the commodity in stock
may arbitrage on temporarily reducing his storage by selling a unit of
the commodity and buying a futures contract. This means that the above
future value must be nonnegative, leading to FT ¼ S0 erT þ C for commodities
that are stored.
Electricity can to a certain extent be stored as potential energy in reservoirs.
Hydroelectric producers are thus in a position to arbitrage between the spot
and futures markets using their reservoirs, hydro stations and possibly pumps.
If aggregate reservoir capacity is large then such behaviour can be expected to
inﬂuence the pricing of electricity futures relative to spot. In many power
systems, however, the aggregate reservoir capacity is low compared to
aggregate system capacity, and the price will be determined by short term
equilibrium of supply and demand for the contract. Supply and demand are
driven by hedging and speculation, where selling hedgers are the producers
and buying hedgers are power marketers and large industry. Speculators take
positions on either side depending on their capacity and willingness to take
risks and their expectations on the future spot price or the future movement of
the contract price.
Regardless of its determination, the contract price represents the current
market value of future delivery of the commodity. This is obviously important
for investment and operational planning. If an electricity company is
considering an investment that will give a certain production capacity
in a future time period, the current value of the revenues coming from the
use of that capacity is given by multiplying the capacity with the forward
price for settlement in the same future period, and discounting to present
using the risk free rate of interest. This is a simple valuation procedure that
will value production resources in a way that is consistent with how the
market prices contracts. Rational decisions based on such valuation will
contribute to maximizing the market value of the ﬁrm owning the production
assets.
Valuation of future production is needed in stochastic programming
models in energy. It is what many such SP models are about. These models
are based on describing the uncertainty in the form of scenarios of the spot
price of the commodity. However, basing the scenarios on forecasts of spot
prices will not give a valuation that is consistent with the market. Price
scenarios need to be adjusted for risk in order to give consistent valuation;
Ch. 10. Stochastic Programming Models in Energy
655

they must be adjusted so that the values of derivatives as calculated in the
scenario tree are the same as can be observed in the market for futures,
options and other contracts.4 Once this adjustment is made, the appropriate
discount interest rate to use is the risk free one, and the SP is now in the
position to value the decision ﬂexibility using a price of risk that is consistent
with the market.
Adjusting for risk is necessary because expected spot prices in future
periods are generally diﬀerent from forward prices for the same future
periods. This in turn is due to the limited capacity or willingness of speculators
to trade on the mentioned diﬀerence, called the risk premium.
This quantity, deﬁned more formally as E½ST  FT where E½ST is the
expected spot price at future time T, and FT is the current forward price for
delivery at time T.5
Note that if one makes optimal decisions based on price forecasts (i.e., on
E½ST), the expected proﬁt is maximized. If one makes decisions based on risk
adjusted prices (i.e., on FT), the value of cash ﬂows is maximized. Thus, one
cannot have proﬁt maximization and shareholder value maximization at the
same time. Only the latter will maximize the value of the ﬁrm.
When constructing scenario trees (or more generally, when modeling the
stochastic processes involved) we must therefore make sure that the path of
the expected spot price in the tree matches that of the term structure of futures
prices, and that the path of the standard deviation of price returns in the tree
matches the term structure of volatility (which has to be estimated, see Hull
(2000)). One should possibly also match higher moments and dynamic
properties of commodity prices such as mean reversion. An approach for
scenario generation based on matching such statistical properties is described
by Høyland and Wallace (2001). Alternatively, one may prefer modeling the
stochastic processes as stochastic integrals, i.e., a parametric approach. This
would have the advantage of capturing the theoretical developments in the
ﬁnancial commodity pricing literature, as in e.g., Schwartz (1997) and Lucia
and Schwartz (2000). In this case, the scenario trees can be built using the
approach of Pﬂug (2001) or by discretizing the continuous stochastic processes
directly as in Hull (2000).
Example 1. Let us give a very simple example of how market data can be
used to extract useful information for a stochastic program, and in parti-
cular to obtain an understanding of the world in which stochastic programs
operate.
Assume we are facing an uncertain future price for electricity. Assume that
presently, 1 MW delivered in the next period costs 100. In the next period,
we know (e.g., by estimation), that the price for immediate delivery will
4 At least approximately the same. Current market prices will change in the future. See Hull (2000,
Chap. 18.6).
5 This is positive for most commodities most of the time (Hull, 2000).
656
S.W. Wallace and S.-E. Fleten

increase to 125 or decrease to 70. Each of these cases occurs with a true
probability of 50%. In the next period, our production will be worth 2000 if
prices go up, and 1500 if they go down. Hence, the expected value of our
production, using the true probabilities, is 1750. However, we should note that
100 6¼ 0:5  125 þ 0:5  70. Let us disregard discounting, and assume that
there is a risk free asset that costs 100 now, and pays 100 in any state in the
next period. We then have two instruments (price of electricity delivered in the
next period and a risk free asset) in a world with two states, and we can set up
the equations for the state prices 1 and 2.
100 ¼ 1251 þ 702
100 ¼ 1001 þ 1002
which yields 1 ¼ 0:5455 and 2 ¼ 0:4545. Hence, the market value of our
production equals
0:5455  2000 þ 0:4545  1500 ¼ 1773,
above its expected value using true probabilities. Someone understanding
markets better could obtain arbitrage by for example buying our produc-
tion for above its expected value (according to the stochastic program),
say for 1751, which should make us happy, and then sell it in the forward
market for its true market value, 1773, to obtain a risk free proﬁt (arbitrage)
of 22.
Again, the purpose of this example is to observe a fact about market values.
To maximize the market value of our electricity production we need to use risk
adjusted probabilities, and not the physically correct ones. Of course, often we
do not know the true ones either, but that is not the point here—the point is
that the relevant probabilities to look for are the risk adjusted ones. And they
are to be found in the market prices of contracts, not in historical spot price
data. This also means that if we use the true probabilities in a stochastic
program, we shall not be maximizing market value, and hence, we open up
our business for speculation based on the true values of risk.
As a theoretical digression, note that transforming a scenario tree, or a
stochastic process with an associated probability measure P, for the true or
forecasted spot price, to a scenario tree matching the term structure of futures
prices and volatility, is equivalent to changing the probability measure into an
equivalent martingale measure Q. The existence and uniqueness of such a
probability measure can be analyzed via stochastic programming by setting up
the problem of hedging a general contingent claim (contract) in the original
(P-measure) scenario tree. This has been done by e.g., Ross (1977), Kreps
(1979), Naik (1995) and King (2002).
Ch. 10. Stochastic Programming Models in Energy
657

3.3
Energy bidding
The bidding problem can be viewed as a short term optimization problem
in which the market participant oﬀers to buy or sell capacity to the market in
the form of price-quantity pairs for given time intervals that typically are 30
min or one hour long. A market operator collects such bids and calculates
clearing prices and quantities for each node or zone in the network, resulting
in a dispatch for the system. The price clearing process aims at maximizing the
sum of consumer and producer surplus as implied by the bids, subject to
transmission constraints, reserve constraints and possibly other technical
constraints. In sending their bids, individual market participants try to
maximize proﬁts resulting from the dispatch (thus buyers minimize the cost of
buying electricity).
The exact setup regarding market structure and market rules diﬀers from
market to market. The Electricity Pool of England and Wales was the ﬁrst to
be
established,
in
1988,
and
has
served
as
a
model
for
much
of
the restructuring worldwide, e.g., in Australia, New Zealand and parts of
Latin America and North America. These countries use a centralized dispatch
and pricing mechanism, called an electricity pool. The second country
to deregulate was Norway in 1991. The Norwegian electricity trade is much
more decentralized and its structure has been adopted by the other Nordic
countries and in some aspects by California. Participation in the organized
markets is voluntary and there is demand-side bidding. This is called a
bilateral market.
Some markets have only a few or even only one round of bidding, and after
these rounds the generator is assigned a generation schedule for the near
future (e.g., for the next 12–36 h). In this situation, after the market operator
has announced the dispatch, the traditional unit commitment models that
include a demand constraint become relevant again. Furthermore, the bidding
problem, i.e., determining optimal bids to send to the market operator,
becomes a nontrivial task that can be supported by optimization models.
Nowak et al. (2000) study this problem and present an integrated stochastic
unit commitment and bidding model.
Neame et al. (1999) consider the bidding problem for a price taker in an
electricity pool type market. The bids are required to be in the form of a
piecewise constant increasing supply curve, i.e., a set of price-quantity pairs. If
the bids could be in any form, price-taking generators maximize their proﬁt by
bidding according to the marginal cost of generation. However, since
marginal cost is not generally a piecewise constant curve having a ﬁnite
number of price-quantity pairs, the generator needs to optimize his bid curve.
The authors study this problem and ﬁnds, among other things, that it is
nonconvex.
For
special
cases
dynamic
programming
algorithms
for
computing the globally optimal bid are presented.
Anderson and Philpott (2002a) consider bidding problems in day-ahead
markets for producers having market power under varying assumptions on
658
S.W. Wallace and S.-E. Fleten

the allowed smoothness of the bids, and on whether there is uncertainty in
demand only or also in the supply functions oﬀered by competing generators.
An important vehicle in the analysis is the ‘‘market-distribution function’’ 
encapsulating uncertainty in demand and competitor behavior. Let ðq, pÞ be
the probability of not being fully dispatched by the market operator if
quantity q is oﬀered at price P. The generator is said to be fully dispatched if
the whole oﬀer was knocked down in the auction, i.e., the market operator
declares it will use all of the quantity q oﬀered. The other cases are
those of not being dispatched, and of being partially dispatched if a fraction
of the quantity is cleared. The problem is to ﬁnd a supply curve
s ¼ ððqðaÞ, pðaÞ, 0  a  AÞ where qðaÞ is the quantity the generator is
willing to supply at a corresponding price pðaÞ. This curve is assumed
to be continuous with qðÞ and pðÞ non-decreasing in the parameter a.
If CðqÞ is the cost associated with generation of q, the payoﬀresulting
from a dispatch ðq, pÞ is Rðq, pÞ ¼ qp  CðqÞ. If the generator has sold a
quantity Q at price f via physical or ﬁnancial contracts for delivery in the
period in question, the payoﬀis Rðq, pÞ ¼ qp  CðqÞ þ Qð f  pÞ. With a
continuous market distribution function the expected payoﬀbecomes a line
integral given by
VðsÞ ¼
Z
s
Rðq, pÞ dðq, pÞ,
see Anderson and Philpott (2002b). With certain (nonrestrictive) diﬀerentia-
bility and monotonicity properties for , the problem can be formulated with
respect to the parameter a as follows:
max
Z A
0
Rðq, pÞ
@
@q ðq, pÞq0ðaÞ þ @
@pðq, pÞp0ðaÞ
"
#
da
s:t:
0  qðaÞ  qM
0  pðaÞ  pM
q0ðaÞ  0
p0ðaÞ  0
where qM is the maximum capacity of the generator and pM is some upper
bound on price. This is a nonlinear optimal control problem, and the authors
analyze its properties and various extensions, for example to the case where
the generator is required to submit piecewise constant bid curves instead of
smooth continuous curves.
Ch. 10. Stochastic Programming Models in Energy
659

3.4
Scheduling in a market
We ﬁrst assume that this generation utility is not large enough to be able to
inﬂuence electricity prices by changing the amount of generation capacity
oﬀered to the market. The market is liberalized, but not necessarily perfectly
competitive.
We discuss how diﬀerent classical power generation planning problems
change in the face of liberalization.
Signiﬁcant changes are necessary in traditional long and mid-term power
scheduling, unit commitment and economic dispatch. Under the price taker
assumption and that the utility does not have to worry about the transmission
constraints, either because transmission is not the utility’s responsibility or
because there is suﬃcient capacity in the transmission grid, these changes
aﬀect both planning objectives and constraints.
First, the objective of the planning models should now be to maximize
utility proﬁts instead of minimizing overall system costs. The revenues are
(hopefully) greater than the generation costs. From an optimization point of
view, this may not amount to more than multiplying the objective function by
1 and maximize instead of minimize, but for the management focus the
change is more profound.
Second, the demand constraint in these models becomes superﬂuous
(except possibly in the very short run). Since utilities no longer have an
obligation to serve demand by using only own generation resources, they now
can use the spot and contract markets (i.e., other companies’ resources) to
meet customer obligations.
Third, reserve constraints, as used in unit commitment, also become
unimportant for the utility. This happens because spinning reserve and other
ancillary services become the responsibility of the system operator rather than
the utilities collectively, or because well-functioning markets for diﬀerent
levels of reserve develop.
To see why the demand constraint becomes superﬂuous, consider the
following problem, where et is the net sale (selling minus buying) in the spot
market and t is the spot market price:
min
u,p,v
X
n2N
Pn ðnenÞ þ
X
i2I
FCiðpin, uinÞ þ SCinðuiÞ
(
)

X
s2S
PsVðlsÞ
ð3:1Þ
s:t: 8 n 2 N :
X
i2I
pin þ
X
j2J
vjn  en  n:
ð3:2Þ
This formulation assumes that the cost of buying is the same as the income
of selling the same energy volume. With a signiﬁcant diﬀerence between
660
S.W. Wallace and S.-E. Fleten

purchase price and sale price, the argument becomes invalid. Due to the
presence of operating ranges ½ pi, pi for each unit, the demand constraint
(3.2) may not be satisﬁed as an equality in an optimal solution, as one
mightexpectfromcostminimization.However,thisrarelyoccursinpracticeand
we ignore this possibility. If there are no binding constraints on it, the net sale
variable en and (3.2) can be substituted out to give the following model:
min
u,p,v
X
n2N
Pn
X
i2I
FCið pin, uinÞ þ SCinðuiÞ 
X
s2S
PsVðlsÞ
 n
X
i2I
pin þ
X
j2J
vjn  n
 
!
ð3:3Þ
This is a model that is decomposable; one can solve for each thermal unit
and for each group of hydrologically coupled hydro units independently.
The total implication for the models is that all or most constraints coupling
the diﬀerent generating units should be removed as the deregulation process is
moving forward. The management is left with a set of decoupled subproblems
for power operation planning, one for each unit or plant, instead of one big
problem with the plants depending on each other to cover demand and
spinning reserve.
In a liberalized market, the following tasks are most important for a
generation utility: Risk management, hydro scheduling, unit commitment and
bidding in the organized markets. In addition, short- and long term market
analyses are important. Forecasting the future development of prices and
other uncertain factors from now to several months or years into the future is
important for trading and risk management. Short term forecasting of prices,
loads and inﬂows is important for short term operational planning.
Hydro scheduling
Next, we present hydro scheduling. Gjelsvik and Wallace (1996), Fosso
et al. (1999), Pereira et al. (2000) study hydro scheduling assuming perfect
competition. For simplicity, we show a model with a single reservoir. For
cascaded reservoirs, a multi-reservoir formulation is warranted. Since hydro
plants are independent of each other under our assumptions, we omit the
index j.
The release decisions for period t are taken after learning the realization of
the stochastic variables for that period.
Decision variables and parameters for hydro scheduling are measured in
energy units. The problem can be formulated as:
max
X
n2N
ðð1 þ ÞNtðnÞPnnvnÞ þ ð1 þ ÞNT X
s2S
PsVðlsÞ
ð3:4Þ
Ch. 10. Stochastic Programming Models in Energy
661

s:t:
8 n 2 N : ln  laðnÞ þ vn þ rn ¼n ,
ð3:5Þ
8 n 2 N : ltðnÞ  ln  ltðnÞ,
ð3:6Þ
8 n 2 : vtðnÞ  vn  vtðnÞ,
ð3:7Þ
where ltðnÞ, ltðnÞ, vtðnÞ and vtðnÞ are lower and upper bounding parameters for
reservoir level and discharge, and spill rn  0. Equation (3.5) is the energy
balance in the reservoir, and (3.6) and (3.7) impose lower and upper bounds
on reservoir level and discharge.
Using deterministic models for hydro scheduling in a market setting will
lead to operating policies that essentially allocates the water to the periods
with the highest prices. As in the case without markets, the spilling risk will be
underestimated and true proﬁt will be overestimated. There will be no extra
release in the fall in case of extra inﬂow at near maximum reservoir levels, and
no holding back water before the spring ﬂood in case snow melting starts late
and prices skyrocket.
Market power
Operations scheduling in deregulated markets when the operator has
market power is discussed by Scott and Read (1996). Their focus is on
imperfect competition due to the low number of suppliers in New Zealand. In
particular, they develop a hydro scheduling model for a Cournot-type
producer having the contract position as exogenously given. A multistage
stochastic programming algorithm is developed to solve the optimization
problem with a Cournot market equilibrium superimposed on it at each stage.
A similar study by Kelman et al. (2001) reach the same conclusions as Scott
and Read, namely that the more contracts the strategic generators have sold,
the less incentive they have to withhold capacity in order to increase prices. A
major limitation in these analyses is that buying and selling of contracts is in
reality determined simultaneously with production. The players are also
limited in the degree to which they can dynamically anticipate and react to
opponents’ strategies.
Unit commitment
Thermal unit commitment for price takers can be formulated as follows
(index i omitted):
max
u,p
X
n2N
ðPnnpn  FCnðpn, unÞ  SCnðuÞÞ
ð3:8Þ
8 n 2 N : unp  pn  unp:
ð3:9Þ
662
S.W. Wallace and S.-E. Fleten

Further, single-unit constraints are minimum up- and down-times and
additional must-on/oﬀconstraints as explained in Section 2.
The decomposition that the liberalization induces should have profound
implications for the organization of the utilities: Now each plant manager can
be given responsibility for operating as she thinks is best. She can and should
be supported by planning models that now sensibly only includes local
generating units. Tseng and Barz (2002) consider such stochastic single-unit
commitment problems.
In summary, we propose that generation utilities comprehensively revise
their generation planning models. New models should include (stochastic)
prices instead of using demand constraints and spinning reserve constraints.
The problems become much easier to solve, thanks to the decoupling eﬀects of
the new markets.
3.5
Risk management
Basic ﬁnancial theory implies that it is not necessary to hedge at the
corporate level, since investors can do that on their own account. In practice,
however, there are ‘‘market imperfections’’ that make the case for risk
management, for example the fact that it is cheaper for a ﬁrm to operate in the
power derivatives markets than for individual owners, due to the economy of
scale in the risk management function.
Example 2. Let us illustrate the use of ﬁnancial instruments on risk manage-
ment to see, in a very simple world, how the instruments can change the risk
picture. In Fig. 7, the ﬁrst ﬁgure shows the distribution of proﬁts from one
unit of production without any ﬁnancial contracts. Assume next that we sell
50% of our production in the forward market at the expected price of 100.
That results in a new distribution of proﬁts, given in the right-hand part of
Fig. 7. The risk has clearly decreased (even if we are not very speciﬁc about
what we mean by risk).
Fig. 7. Distribution of proﬁt without and with a forward contract. The horizontal axis
shows proﬁt for one unit of production, the vertical axis probabilities.
Ch. 10. Stochastic Programming Models in Energy
663

This example indicates that trading in the forward market will reduce the
risk. But this may not be the case. Assume that we are facing uncertain
production and uncertain prices, as outlined in Table 3.1. The most likely
situations (each having 40% probability) is low production and high prices
(low inﬂow) or high production and low prices (high inﬂow). But there are two
other cases, representing the possibility that while we have high inﬂow to our
reservoirs, the general picture is the reverse. Hence, there is a chance of seeing
low prices and low production at the same time. The same goes for high
production and high prices.
Consider the illustration in Fig. 8. The white set of columns shows the
proﬁt without any ﬁnancial contracts. Assume next that we sell 100 units of
production (the expected production) in the forward market at a price of 15
(the expected price). The last row in Table 3.1 shows the resulting proﬁt. Each
number is the sum of the income from the forward contract (1500) and sales or
purchases in the ‘‘spot’’ market for what is left or what is missing relative to
our forward contract. The result is the distribution in black in Fig. 8. We see
that the variance has increased, and that most measures of risk will show the
same. In this case, selling the expected production at expected prices increased
the risk.
The purpose of these two examples is simply to illustrate the use of
ﬁnancial instruments for risk management, and a warning that using
these markets to ﬁx income in the future will not automatically mean reduced
risks.
Table 3.1
Production, prices and probabilities with and without a forward contract
Production
50
150
50
150
Price
10
10
20
20
Probability
10%
40%
40%
10%
Proﬁt without contract
500
1500
1000
3000
Proﬁt with contract
1000
2000
500
2500
Fig. 8. Distribution of proﬁt without and with a forward contract. The horizontal axis
shows total proﬁt, the vertical axis probabilities.
664
S.W. Wallace and S.-E. Fleten

Mo et al. (2001) and Fleten et al. (2002) suggest that production planning
and contract risk management should be integrated in order to maximize
expected proﬁt at some acceptable level of risk. However, in some
circumstances (no production uncertainty or basis risk) production planning
can be done independently from hedging (separation). So then it is possible to
have a relatively decentralized organization, with local plant managers having
much responsibility, and a centralized treasury department in charge of
overall risk management. The main tasks of such a department are to
speculate and hedge using derivatives in order to satisfy the goals of owners
and top management regarding expected proﬁt and risk. Of course, this
requires that the relevant attitude toward risk must be expressed.
The requirements needed to invoke the separation theorem are not likely to
be met 100% in practice. However, the beneﬁts of a decoupled set of models
and corresponding decentralized organizational units will probably outweigh
the small theoretical gain from integrating production planning and trading.
Another argument for separating risk management is as follows: From
ﬁnancial theory we know that the market value of any ﬁnancial contract is
zero at the time it is entered into. This also holds for electricity contracts that
are fairly priced, and consequently, buying a new contract will not change the
market value of the electricity portfolio in question. In particular, buying and
selling a range of contracts that jointly are selected in order to minimize the
risk of a given electricity portfolio, will not alter the market value of that
portfolio. However, operational decisions do change the market value of the
electricity portfolio, and so generation should be allocated in order to achieve
maximal market value. Any production decision that deviates from the value-
maximal strategy will erode value for the owners of the generation utility.
Consequently, a natural setup for the coordination of generation planning and
risk management is to ﬁrst schedule generation so that market value is
maximized. Second, given this optimal strategy, ﬁnd a set of contracts (or a
trading strategy) that will minimize the risk of the total portfolio.
We model the risk management problem as follows: Given calculated
(optimal) proﬁt from hydro and thermal generation in each state in the
scenario tree, summed over all plants, dynamically trade in futures and
options in order to minimize some risk measure.
Let t be the stochastic proﬁt estimated from all generation activities in
period t. This information must be extracted from the optimal objective
function value of hydro and thermal sub-models (3.4). The scenario tree used
for these sub-models is assumed to be identical to the one used for risk
management.
Trading in forward contracts is modeled by the variables fkn, gkn and hkn.
Let fkn, k ¼ 2, . . . , T, n 2 fN : tðnÞ < kg be the position, measured in energy
units, in state n for a contract with delivery in period k. Negative fkn represent
a short position in product k. Buying and selling forward contracts are
represented by gkn and hkn (both nonnegative). Contract prices are denoted
’kn, and markets are inﬁnitely liquid and perfectly competitive.
Ch. 10. Stochastic Programming Models in Energy
665

The position accumulated in state n is
fkn ¼ fk,aðnÞ þ gkn  hkn,
ð3:10Þ
with the initial forward position given. Contract variables and rebalancing
constraints (3.10) are only deﬁned for relevant states satisfying tðnÞ < k.
Rebalancing decisions are made in each state n, after the realizations of the
random electricity prices for period tðnÞ are known. Transaction costs are
proportional to the trade volume and is TF per unit energy bought or sold.
European-type option contracts can also be included. To conserve space,
the involvement of options in rebalancing, proﬁt measurement and objective is
not shown (see Fleten (2000) for models including options).
Modeling of risk depends on the attitude toward risk in the generation
utility. A simple approach that leads to a piecewise linear model is to minimize
expected shortfall (Kusy and Ziemba, 1986). Shortfall is deﬁned as proﬁt
underperformance relative to some preset proﬁt targets at various periods. Let
tot
n
be the proﬁt to be measured. The exact deﬁnition of this proﬁt depends
on how the generation utility deﬁnes risk. A possible deﬁnition is:
8 n 2 N : tot
n
¼ n þ n ft,aðnÞ
þ
X
k<tðnÞ
½ð’tn  TFÞhkn  ð’kn þ TFÞgkn,
ð3:11Þ
where ft,aðnÞ is the forward position in the product that has delivery in period t,
during the actual delivery period.
Let Cmt be the marginal shortfall cost in segment (piece) m and let snm be
shortfall. The following constraint deﬁnes shortfall variables:
tot
t
þ
X
m
smn  Bt,
ð3:12Þ
for all states n for which there is a proﬁt target Bt.
Let W be a weight parameter. In order to avoid incurring excess transaction
costs, the objective function maximizes expected proﬁt minus the weight times
expected shortfall:
max
f ,g,h
X
n2N
Pnð1 þ rÞNtðnÞ tot
n  W
X
m
Cmtsmn
"
#
:
ð3:13Þ
This model does not treat physical and ﬁnancial forward-type contracts
diﬀerently. The reason is that with the assumptions we have made, a ﬁnancial
contract is a perfect substitute for a physical contract. It generates the exact
666
S.W. Wallace and S.-E. Fleten

same cash ﬂow. Some generation utilities in newly liberalized markets have
physical bilateral sales contracts that have a minimum energy volume that is
very large and whose tariﬀstructure is complex. The market for such
wholesale consumption contracts will quickly become competitive, since small
power marketers can sell such contracts and cover the liability in the spot and
ﬁnancial markets. The integrality of these contracts (large minimum volume)
will not be a problem either, since one can always add or delete energy volume
by buying or selling additional (physical or ﬁnancial) contracts. The decision
support tool needed for such bilateral sales contracts is thus not only a
portfolio optimization model, but also a good model for pricing the specialties
(e.g., embedded physical load risk) of the individual contracts. See e.g.,
Thompson (1995) for such an approach applied to take-or-pay contracts.
3.6
Capacity expansion
In a deregulated and well-functioning market, capacity expansion decisions
should be analyzed in view of their proﬁt and market value adding potential,
and not their ability to serve growing demand at minimum cost. As such,
future electricity prices, as opposed to demand, is the central object of
analysis. A lot of work remains to be done on this arena, but as a starting
point the readers are referred to Deng and Oren (2001), who analyze an
investment in a gas-ﬁred power plant using a stochastic dynamic program-
ming model that includes startup costs, operating-dependent eﬃciency and
ramping constraints.
4
Oil
4.1
Optimal field development
Haugland et al. (1988) discuss an optimization model for an oil ﬁeld
based on a two-dimensional reservoir model of the same type that is used in
reservoir simulations (but of course much simpler). The goal is to determine
platform capacity, the number of wells (and their placement and timing),
plus the production proﬁle of each well. This way of using the reservoir
simulation equations within an optimization model provides a setting that
spans two diﬀerent ﬁelds of research. This is useful both for quality and
acceptance.
But since the model is deterministic, all aspects of ﬂexibility are gone,
including the postponement of decisions. Jonsbra˚ ten (1998a) adds one type of
stochasticity to these models by assuming that future oil prices are random.
He describes them using scenarios. He then solves the resulting stochastic
mixed integer program with scenario aggregation on the continuous variables
and a heuristic for ﬁnding feasible integer solutions. He observes what is
expected, namely that as soon as stochasticity is introduced, timing of
Ch. 10. Stochastic Programming Models in Energy
667

decisions, in order to take into account accumulation of information, becomes
important.
It is clearly possible to expand this type of models to include other types
of randomness. However, we should be aware that gathering of information
about the reservoir (over time) will depend on the actual decisions
made. Stochastic programming for such cases is barely developed. An
initial discussion can be found in Jonsbra˚ ten’s doctoral thesis (Jonsbra˚ ten,
1998b).
4.2
Scheduling arrivals of tankers at a refinery
This problem originates from Bjørstad et al. (1991), and is interesting as its
randomness is diﬀerent from what we have seen elsewhere. A reﬁnery is about
to receive a large ship for loading of gasoline for export. For simplicity, we
shall assume that gasoline is characterized by two qualities, namely sulphur
content (the lower, the better) and octane number (the higher, the better).
In reality, there are many other properties, but this is enough for our example.
For the arriving ship, it is known how much gasoline it needs, and there
are given a minimal value for octane number and a maximal value for sulphur
content. At a reﬁnery, gasoline is not stored as ﬁnal products, but rather
as intermediate components, such as propane, butane etc. These are the results
of the reﬁning process, and are stored in tanks (with limited capacity).
To fulﬁll an export order, one mixes components from the diﬀerent tanks, to
achieve a product with the desired properties. It is not always possible
to achieve exactly the boundary values of the qualities, and in such a case it
is a goal to give away as little extra quality as possible. Clearly, if one gives
away very little extra quality in one shipment, one may be left in a situation in
terms of stored components, such that for later shipments the quality
giveaway is very high. Hence, one needs to have a somewhat long view on the
production.
For many reﬁneries, the arrival time of the exporting ships is uncertain.
This is caused mainly by bad weather, but other reasons are of course possible
as well. Hence, although both production of components, and requirements
(quantities and qualities) relating to arriving vessels may be known for some
periods into the future, the very fact that their arrival times are unknown will
cause some concern. Problems may occur both with respect to production (full
tanks because no ship arrived), and the mixing of gasoline for a speciﬁc ship,
since production continuously change the qualities of the contents in the
tanks. Even more severe eﬀects occur if ships arrive in an unexpected order.
Assume we look four periods into the future, and that we know that during
those periods three ships will arrive. The model is run when a ship arrives, so
ship 1 is known to arrive in the ﬁrst period. Figure 9 shows the six possible
arrival sequences, with given estimated probabilities.
The scenario representing what we expect to happen is scenario 2, where
ship A arrives in period 2, and ship B in period 4. This has a probability of 60%.
668
S.W. Wallace and S.-E. Fleten

This sequence is almost certain, as it is only 5% chance that B arrives before A.
So in a deterministic model, we would clearly use scenario 2.
But let us describe the problem in some detail. When a continous model is
made discrete, as it is here, there is always the need to make assumptions
about the order in which things happen. The assumptions here are:

No two ships arrive in the same period.

Gasoline for export is subtracted from the tanks before the production
of the period is added.

The periods are long enough to ﬁnish loading a ship.
In this example, it turns out that if we solve the problem corresponding to
the most likely scenario, we may end up with all sorts of problems later on.
For some scenarios we shall experience serious problems with high giveaways,
tanks that ﬁll up (resulting in stopped production) and orders that cannot be
fulﬁlled. The optimal solution to the stochastic program takes the future
appropriately into account and avoids these problems. In this case, the
optimal solution is a scenario solution. But as always, this can be determined
only by solving the stochastic program.
4.3
Refinery planning
In addition to the problem outlined above about the arrival of tankers to a
reﬁnery, there will always be interesting problems related to the reﬁning
process itself. Examples of short-term decisions are what qualities to produce
and what tanks to use, medium-term decisions concern which crude oils to
buy when, and of course there are long term investment problems. An
example of a model in this area is Escudero et al. (1999).
Fig. 9. The possible arriving sequence for the three ships over four periods, with given
probabilities.
Ch. 10. Stochastic Programming Models in Energy
669

5
Gas
5.1
Scheduling of gas fields
Haugen (1993) discusses the following question from the North Sea. Gas
was at the time mostly sold on long term contracts. The income of the
producer depended to a large extent on his ability to meet the contracted
volumes. The market was connected to the oﬀshore gas ﬁelds by pipelines.
Some of the ﬁelds and pipelines already existed, but new ones had to be
developed to satisfy the demands (i.e., the contracts). A stochastic dynamic
programming model was set up to decide which ﬁelds should be developed
when, and which pipelines should be constructed when. Although, as the
author points out, many aspects of such a problem are random, this paper
focuses on resource uncertainty. The uncertainty is described by deﬁning a
production proﬁle, consistent with how that is normally done in the industry,
and then letting the time at peak production be stochastic. The size of the
peak production is a design variable (production capacity of the platform),
while the time spent there is a function of ﬁeld properties, and hence, random.
Some small examples are given. The main result, apart from the model itself, is
the fact that the author is not able to extract simple decision rules. This is not
a negative result, but shows that the problem is inherently diﬃcult, and that
care must be taken (in the real world) when arguments are made on how to
develop such ﬁelds and infrastructure. Simple arguments are very likely to
be false.
5.2
Use of gas storage
In light of the nature of stochastic programs, storage will always be
important. Storage of gas will be a way to solve many diﬀerent problems of
ﬂexibility. To mention but a few:

A gas producer has an obligation to deliver certain amounts of gas at
certain points in the network at certain times. He is aware that at times
there are interruptions in his production or transportation systems. By
having storage facilities near the delivery points, he can reduce the
chance of failing to deliver.

At certain points in the network spot markets for gas exist. For some
producers it is hard to take part in such markets, as it may take them
several days from a decision about increased production is made until
the gas actually reaches the point of spot delivery. A storage facility near
the spot market will make it possible to take part in a potentially
proﬁtable spot market.

A local distribution company may have as its sole goal to supply
its customers according to their (random) demand at lowest possible
cost. In this case storage can both help buy gas at times when it
670
S.W. Wallace and S.-E. Fleten

is cheap, as well as supply gas in periods of high demand (typically
cold periods) where there may be problems of delivery (in addi-
tion to high costs). The problems may be caused both by lack of
available gas (limited production capacity) and lack of transportation
capacity.

Utilities producing electricity from gas will have very similar problems
as above. They can save money as well as secure supply of gas by having
a storage facility.
The storage facility will create both strategic and operational decisions. The
strategic decisions, which normally are the ones interesting from a stochastic
programming point of view, can be such as:

Building a storage facility—in many ways a classical facility location
problem.

Renting (part of ) a storage facility. If there are several possibilities, this
is also a kind of facility location problem.

Investing in equipment determining the speed by which gas can be put
into and removed from storage—by some called deliverability.
There are also more indirect strategic decisions, such as changing
the production capacity of a gas ﬁeld (changing the number of wells,
for example) to take into account the value of being able to add gas to the
storage at an increased rate also in periods of high production with direct
delivery.
These strategic decisions can show up in many stages of a model. For
example, rental of storage capacity can be updated at times, new contracts can
be entered into, old ones continued or dropped. This way, storage rental turns
into a portfolio problem, where characteristics are geography, deliverability
and size. As always, we should expect that the more ﬂexible is a certain
storage, the more it costs to build or rent.
Operational decisions are more obvious. In combination with purchases,
production or delivery, whichever is the relevant trade, we must optimally use
the storage facilities to maximize proﬁt or minimize costs, whatever is the
objective.
Useful references here are Butler and Dyer (1999), Bopp et al. (1996) and
Takriti et al. (2001).
5.3
Portfolio management of gas contracts
Whether we are selling or buying natural gas, the chance is that we need to
buy or sell the gas on contracts of diﬀerent types. These may vary in price and
duration. The price diﬀerence may stem from diﬀerences in forward prices,
such that gas on a one-year contract may cost more or less than gas on a two-
year contact. But the diﬀerences may also stem from how the gas price
Ch. 10. Stochastic Programming Models in Energy
671

depends on other entities, such as oil price, or by special rules on renegotia-
tions of contract details.
In such a picture, we are faced with a portfolio management problem. The
goal may be to buy or sell gas so as to obtain an optimal tradeoﬀbetween
expected proﬁt and some measure of risk. Haurie et al. (1992) discuss this
problem for a Canadian producer. The diﬀerent gas contracts have diﬀerent
time spans and diﬀerent rules for how prices are set. They have many diﬀerent
models. The ﬁrst is in the spirit of the Markowitz’ mean-variance model, the
last is a stochastic program with recourse. Risk is measured in terms of the
variance of proﬁts.
6
Conclusion
The purpose of this chapter has been to give an introduction to the use of
stochastic programming in energy. Based on the available literature, the focus
has naturally been on electricity production, but we have tried to provide
some pointers also for natural gas (particularly the treatment of contracts)
and oil. The purpose has not been to have a full overview over the literature,
but to provide the reader with pointers to interesting problems and starting
points for reading.
Stochastic programming used in regulated markets, that is, in monopolies,
is a well-established activity. The ﬁrst articles go far back, and the literature is
enormous. Articles typically mix discussions of models and methods, and very
often the chosen methodology is stochastic dynamic programming (SDP). We
have chosen to base our presentation on models rather than methods, so as to
avoid a split of papers into two arbitrary piles; those that use stochastic
programming (as understood in this handbook) and those that use SDP. For
regulated markets, as that is such a well established ﬁeld, and since methods
and models are almost always mixed, we have chosen to discuss also
methodology in that section. For deregulated markets, on the other hand, we
have chosen to focus very little on methodology, simply assuming that the
reader will use the rest of this handbook to look for appropriate methodology.
Instead, we have tried to focus on what the new markets may bring us, and
tried to point to relevant theory outside stochastic programming, in particular
market theory and options theory. The deregulated markets have not found
their ﬁnal forms, so it is impossible to provide the reader with clear-cut
descriptions of where we will end up. Hence, our goal has been to assist and
present ideas.
Many problems in resource management concern situations where our
decisions will change the (conditional) probability distributions. Drilling
exploration wells in an oil or gas ﬁeld is a good example. As stochastic
programming, as it stands today, cannot treat this case in any good way, we
have chosen to let those problems rest, and mostly focused on problems where
the uncertainty is external to the model at hand.
672
S.W. Wallace and S.-E. Fleten

Acknowledgements
Much of this work was done while Stein W. Wallace headed a research group
at the Centre for Advanced Study, at the Academy of Science and Letters in
Oslo, during the academic year 2000/01. We would like to thank our
cooperators during the last few years on energy related issues, in particular (in
alphabetical order) T. Bjørkvoll, J. Lemming, T. T. Lie, M. P. Nowak, A.
Tomasgard, and W. T. Ziemba. We would also like to pay tribute to J. Birge,
L. F. Escudero, A. Manne, M. V. F. Pereira, A. B. Philpott, W. Ro¨ misch, R.
Schultz, Y. Smeers, and J. R. Stedinger, who have helped to collect material
for this chapter. Partial funding from the European Commission through EUs
5th framework programme project IST–1999–12088 is gratefully acknowl-
edged.
References
Anderson, E.J., A.B. Philpott (2002). On supply function bidding in electricity markets, in: C.
Greengard, A. Ruszczyn´ ski (eds.), Decision Making under Uncertainty: Energy and Power. Vol. 128
of IMA volumes on Mathematics and its Applications, Springer-Verlag, pp. 115–134.
Anderson, E.J., A.B. Philpott (2002). Optimal oﬀer construction in electricity markets. Mathematics of
Operations Research 27(1), 82–100.
Archibald, T.W., C.S. Buchanan, K.I.M. McKinnon, L.C. Thomas (1999). Nested Benders
decomposition and dynamic programming for reservoir optimisation. Journal of the Operational
Research Society 50(5), 468–479.
Bienstock, D., J.F. Shapiro (1988). Optimizing resource acquisition decisions by stochastic
programming. Management Science 34(2), 215–229.
Birge, J.R. (1985). Decomposition and partitioning methods for multistage stochastic linear programs.
Operations Research 33, 989–1007.
Birge, J.R., C.H. Rosa (1996). Incorporating investment uncertainty into greenhouse policy models.
Energy Journal 17(1), 79–90.
Bjørstad, H., D. Haugland, R. Helming, (1991). A stochastic model for gasoline blending, in:
M. Breton, G. Zaccour (eds.), Advances in Operations Research in the Oil and Gas Industry,
pp. 137–142.
Bloom, J.A. (1983). Solving an electricity generation capacity expansion planning problem by
generalized Benders’ decomposition. Operations Research 31, 84–100.
Bopp, A.E., V.R. Kannan, S.W. Palocsay, S.P. Stevens (1996). An optimization model for planning
natural gas purchases, transportation, storage and deliverability. Omega, International Journal of
Management Science 24(5), 511–522.
Botnen, O.J., A., Johannesen, A. Haugstad, S. Kroken, O. Frøystein, June 1992. Modelling of
hydropower scheduling in a national/international context, in: E. Broch, D.K. Lysne (eds.),
Proceedings of the 2nd International Conference on Hydropower Development (Hydropower ’92),
Lillehammer, Norway, Balkema, Rotterdam, pp. 575–584.
Bunn, D.W., S.N. Paschentis (1986). Development of a stochastic model for the economic dispatch of
electric power. European Journal of Operational Research 27, 179–191.
Butler, J.C., J.S. Dyer (1999). Optimizing natural gas ﬂows with linear programming and scenarios.
Decision Sciences 30(2), 563–580.
Caroe, C.C., R. Schultz (1998). A two-stage stochastic program for unit commitment under
uncertainty in a hydro-thermal power system. Preprint SC 98-11, Konrad-Zuse-Zentrum fu¨ r
Informationstechnik Berlin.
Ch. 10. Stochastic Programming Models in Energy
673

Carpentier, P., G. Cohen, J.C. Culioli, A. Renaud (1996). Stochastic optimization of unit commitment:
A new decomposition framework. IEEE Transactions on Power Systems 11(2), 1067–1073.
Dantzig, G., G. Infanger (1993). Approaches to stochastic programming with application to electric
power systems, in: K. Frauendorfer, H. Glavitsch, R. Bacher (eds.), Optimization in Planning and
Operation of Electric Power Systems, Physica-Verlag, Heidelberg, pp. 125–138.
Dantzig, G.B. (1989). Decomposition techniques for large-scale electric power systems planning under
uncertainty, in: R. Sharda, B.L. Golden, E. Wasil, O. Balci, W. Steward (eds.), Impacts of Recent
Computer Advances on Operations Research, North-Holland, pp. 3–20.
Deng, S.-J., S.S. Oren (2001). Incorporating operational characteristics and startup costs in option-
based valuaton of power generation capacity, forthcoming, Probability in the Engineering and
Informational Sciences (PEIS), April 2003.
Dentcheva, D., W. Ro¨ misch (1998). Optimal power generation under uncertainty via stochastic
programming, in: K. Marti, P. Kall (eds.), Stochastic Programming Methods and Technical
Applications, Lecture Notes in Economics and Mathematical Systems, Vol. 458, Springer-Verlag,
Berlin, pp. 22–56.
Escudero, L.F., I. Paradinas, F.J. Prieto (1995). Generation expansion planning under uncertainty in
demand, economic environment, generation availability and book life, in: Proceedings of the IEEE
Stockholm Power Tech. Stockholm, Sweden, pp. 226–233.
Escudero, L.F., F.J. Quintana, J. Salmeron (1999). CORO, a modeling and an algorithmic framework
for oil supply, transformation and distribution optimization under uncertainty. European Journal
of Operational Research 114(3), 638–656.
Feltenmark, S., P.O. Lindberg (1997). Network methods for head-dependent hydro power planning,
in: P.M. Pardalos, D.W. Hearn, W.W. Hager (eds.), Network Optimization. Lecture Notes in
Economics and Mathematical Systems, Springer-Verlag, Berlin, pp. 249–264.
Fleten, S.-E. (2000). Portfolio management emphasizing electricity market applications. a stochastic
programming approach. Ph.D. thesis, Norwegian University of Science and Technology,
Trondheim, doktor Ingeniøravhandling 2000:16.
Fleten, S.-E., S.W. Wallace, W.T. Ziemba (2002). Hedging electricity portfolios using stochastic
programming, in: C. Greengard, A. Ruszczynski (eds.), Decision Making under Uncertainty: Energy
and Power. Vol. 128 of IMA Volumes on Mathematics and Its Applications, Springer-Verlag, pp. 71–
94.
Fosso, O.B., A. Gjelsvik, A. Haugstad, B. Mo, I. Wangensteen (1999). Generation scheduling in a
deregulated system. The Norwegian case. IEEE Transactions on Power Systems 14(1), 75–80.
Fragniere, E., A. Haurie (1996). A stochastic programming model for energy/environment choices
under uncertainty. International Journal of Environment and Pollution 6 (4-6), 587–603, in: A.V.
Georghe, (ed.), Integrated Regional Health and Environmental Risk Assessment and Safety
Management.
Gardner, D.T. (1996). Flexibility in electric power planning: Coping with demand uncertainty. Energy
21(2), 1207–1218.
Gardner, D.T., J.S. Rogers (1999). Planning electric power systems under demand uncertainty with
diﬀerent technology lead times. Management Science 45, 1289–1306.
Gjelsvik, A., T.A. Røtting, J. Røynstrand, June 1992. Long-term scheduling of hydro-thermal power
system, in: E. Broch, D.K. Lysne, (eds.), Proceedings of the 2nd International Conference on
Hydropower
Development
(Hydropower’92),
Lillehammer,
Norway.
Balkema,
Rotterdam,
pp. 539–546.
Gjelsvik, A., S.W. Wallace (1996). Methods for stochastic medium-term scheduling in hydro-
dominated power systems. EFI TR A4438, Norwegian Electric Power Research Institute,
Trondheim.
Gollmer, R., M.P. Nowak, W. Ro¨ misch, R. Schultz (2000). Unit commitment in power generation—a
basic model and some extensions. Annals of Operations Research 96, 167–189.
Gorenstin, B.G., N.M. Campodo´ nico, J.P. Costa, M.V.F. Pereira (1992). Stochastic optimization of a
hydrothermal system including network constraints. IEEE Transactions on Power Systems 7(2),
791–797.
674
S.W. Wallace and S.-E. Fleten

Gorenstin, B.G., N.M. Campodo´ nico, J.P. Costa, M.V.F. Pereira, N. Deeb (1993). Power-system
expansion planning under uncertainty. IEEE Transactions on Power Systems 8(1), 129–136.
Grinold, R.C. (1980). Time horizons in energy planning models, in: W.T. Ziemba, S.L. Schwarz (eds.),
Energy Policy Modeling: United States and Canadian Experiences, Vol. II, Martinus Nijhoﬀ,
Boston, pp. 216–237.
Gro¨ we, N., W. Ro¨ misch, (1992). A stochastic programming model for optimal power dispatch:
Stability and numerical treatment, in: K. Marti (ed.), Stochastic Optimization. Vol. 379 of Lecture
Notes in Economics and Mathematical Systems, Springer-Verlag, Berlin, pp. 111–139.
Gro¨ we, N., W. Ro¨ misch, R. Schultz (1995). A simple recourse model for power dispatch under
uncertain demand. Annals of Operations Research 59, 135–164.
Gro¨ we-Kuska, N., K.C. Kiwiel, M.P. Nowak, W. Ro¨ misch, I. Wegner (2002). Power management in a
hydro-thermal system under uncertainty by Lagrangian relaxation, in: C. Greengard, A.
Ruszczynski (eds.), Decision Making under Uncertainty: Energy and Power. Vol. 128 of IMA
volumes on Mathematics and its Applications, Springer-Verlag, pp. 39–70.
Haugen, K.K. (1993). A stochastic dynamic programming model for scheduling of oﬀshore petroleum
ﬁelds with resource uncertainty. European Journal of Operational Research 88, 88–100.
Haugland, D., A. Hallefjord, H. Asheim (1988). Models for petroleum ﬁeld exploitatin. European
Journal of Operational Research 37(1), 58–72.
Haurie, A., Y. Smeers, G. Zaccour (1992). Toward a contract portfolio management model for a gas
producing ﬁrm. INFOR 30(3), 257–273.
Hindsberger, M. (2003) Interconnected hydro-thermal systems. Ph.D. thesis, Technical University of
Denmark.
Hobbs, B.F. (1995). Optimization methods for electric utility resource planning. European Journal of
Operational Research 83(1), 1–20.
Hobbs, B.F., Y.D. Ji (1999). Stochastic programming-based bounding of expected production costs for
multiarea electric power systems. Operations Research 47(6), 836–848.
Høyland, K., S.W. Wallace (2001). Generating scenario trees for multistage decision problems.
Management Science 47(2), 295–307.
Hull, J.C. (2000) Options, Futures and Other Derivatives, 4th Edition, Prentice Hall International,
Upper Saddle River, N.J.
Jacobs, J., G. Freeman, J. Grygier, D. Morton, G. Schultz, K. Staschus, J. Stedinger (1995).
SOCRATES–A system for scheduling hydroelectric generation under uncertainty. Annals of
Operations Research 59, 99–133.
Jonsbra˚ ten, T.W. (1998). Oil ﬁeld optimization under price uncertainty. Journal of the Operational
Research Society 49(8), 811–818.
Jonsbra˚ ten, T.W. (1998b). Optimization models for petroleum ﬁeld exploitation. Ph.D. thesis,
Norwegian School of Economics and Business Administration, Bergen, Norway.
Kanudia, A., R. Loulou (1998). Robust responses to climate change via stochastic MARKAL: The
case of Quebec. European Journal of Operational Research 106(1), 15–30.
Kelman, R., L.A.N. Barroso, M.V.F. Pereira (2001). Market power assessment and mitigation in
hydrothermal systems. IEEE Transactions on Power Systems 16(3), 354–359.
King, A.J. (2002) Duality and martingales: A stochastic programming perspective on contingent
claims. Mathematical Programming 91(3), 543–562.
Kreps, D. (1979). Multi-period securities and eﬃcient allocation of risk: The Economics of Information
and Uncertainty, McCall, J.J. University of Chicago Press, Chicago, pp. 203–232.
Kusy, M.I., W.T. Ziemba (1986). A bank asset and liability management model. Operations Research
34(3), 356–376.
Lindqvist, J. (1962). Operation of a hydrothermal electric system: A multistage decision process. AIEE
Trans. Power Apparatus and Systems 81, 1–7.
Louveaux, F.V. (1980). A solution method for multistage stochastic programs with recourse with
application to an energy investment problem. Operations Research 28(4), 889–902.
Lucia, J.J., E.S. Schwartz (2000) Electricity prices and power derivatives. Evidence from the Nordic
Power Exchange. Review of Derivatives Research 5(1), 5–50.
Ch. 10. Stochastic Programming Models in Energy
675

Manne, A.S., T.R. Olsen (1996). Greenhouse gas abatement—toward Pareto-optimal decisions under
uncertainty. Annals of Operations Research 68, 267–279.
Manne, A.S., R.G. Richels (1978). A decision analysis of the U.S. breeder reactor program. Energy
3(6), 747–767.
Manne, A.S., R.G. Richels (1991). Buying greenhouse insurance Energy Policy, Vol. 19(6).
Manne, A.S., R.G. Richels (1995). The greenhouse debate: Economic eﬃciency, burden sharing and
hedging strategies. The Energy Journal 16(4), 1–37.
Masse´ , P. (1946). Les Re´ serves et la Re´ gulation de l’Avenir dans la vie E´ conomique. Hermann, Paris,
vol I and II.
Mo, B., A. Gjelsvik, A. Grundt (2001). Integrated risk management of hydro power scheduling and
contract management. IEEE Transactions on Power Systems 16(2), 216–221.
Morton, D.P. (1996). An enhanced decomposition algorithm for multistage stochastic hydroelectric
scheduling. Annals of Operations Research 64, 211–235.
Murphy, F.H., S. Sen, A.L. Soyster (1982). Electric utility capacity expansion planning with uncertain
load forecasts. IIE Transactions 14(1), 52–59.
Naik, V., (1995). Finite state securities market models and arbitrage, in: R. Jarrow, V. Maksimovic
W.T. Ziemba (eds.), Finance. Vol. 9 of Handbooks in Operations Research and Management Science,
Elsevier, Amsterdam, pp. 31–64.
Neame, P.J., A.B. Philpott, G. Pritchard (1999). Oﬀer stack optimisation for price takers in electricity
markets, in: Proceedings of the 34th Annual Conference of ORNZ, University of Waikato,
Hamilton, New Zealand, pp. 3–12.
Nowak, M.P., R. Nu¨ rnberg, W. Ro¨ misch, R. Schultz, M. Westphalen, (2000) Stochastic programming
for power production and trading under uncertainty. Preprint SM-DU-471, Fachbereich
Mathematik, Universita¨ t Duisburg, submitted.
Nowak, M.P., W. Ro¨ misch (2000). Stochastic Lagrangian relaxation applied to power scheduling in a
hydro-thermal system under uncertainty. Annals of Operations Research 100, 251–272.
Pereira, M.V.F., N. Campodo´ nico, R. Kelman (2000). Stochastic optimization of complex
hydrothermal systems in a competitive framework, not published.
Pereira, M.V.F., N.M. Campodo´ nico, B.G. Gorenstin, J.P. Costa (1995) Application of stochastic
optimization to power system planning and operation, in: Proceedings of the IEEE Stockholm
Power Tech. Stockholm, Sweden, pp. 234–239.
Pereira, M.V.F., B.G. Gorenstin, M.M. Fo, J.B. Silva (1992). Chronological probabilistic production
costing and wheeling calculations with transmission network modeling. IEEE Transactions on
Power Systems 7(2), 885–891.
Pereira, M.V.F., L.M.V.G. Pinto (1985). Stochastic optimization of a multireservoir hydroelectric
system—a decomposition approach. Water Resources Research 21(6), 779–792.
Pereira, M.V.F., L.M.V.G. Pinto (1991). Multi-stage stochastic optimization applied to energy
planning. Mathematical Programming 52(2), 359–375.
Pereira, M.V.F., L.M.V.G. Pinto, S. Granville, A. Monticelli (1987) A decomposition approach to
security constrained optimal power ﬂow with post-contingency corrective rescheduling, in: Power
Systems Computation Conference 1987.
Pﬂug, G.C. (2001). Scenario tree generation for multiperiod ﬁnancial optimization by optimal
discretization. Mathematical Programming 89(2), 251–271.
Philbrick, C.R., P.K. Kitanidis (1999). Limitations of deterministic optimization applied to reservoir
operations. Journal of Water Resources Planning and Management-ASCE 125(3), 135–142.
Philpott, A.B., M. Craddock, H. Waterer (2000). Hydro-electric unit commitment subject to uncertain
demand. European Journal of Operational Research 125(2), 410–424.
Qiu, J., A.A. Girgis (1993). Optimization of power-system reliability level by stochastic-programming.
Electric Power Systems Research 26(2), 87–95.
Ross, S. (1977). Risk, return and arbitrage, in: I. Friend, J.L. Bicksler (eds.), Risk and Return in
Finance, Ballinger, Cambridge, Massachusetts.
Schwartz, E.S. (1997). The stochastic behavior of commodity prices: Implications for valuation and
hedging. Journal of Finance 52(3), 922–973.
676
S.W. Wallace and S.-E. Fleten

Scott, T.J., E.G. Read (1996). Modelling hydro reservoir operation in a deregulated electricity sector.
International Transactions in Operations Research 3(3–4), 209–221.
Sheble, G.B., G.N. Fahd (1994). Unit commitment literature synopsis. IEEE Transactions on Power
Systems 9(1), 128–135.
Sherali, H.D., A.L. Soyster, F.H. Murphy, S. Sen (1982). Linear programming based analysis of
marginal cost pricing in electric utility capacity expansion. European Journal of Operational
Research 11, 349–360.
Sherali, H.D., A.L. Soyster, F.H. Murphy, S. Sen (1984). Intertemporal allocation of capital costs in
electric utility capacity expansion planning under uncertainty. Management Science 30, 1–19.
Sherkat, V.R., R. Campo, K. Moslehi, E.O. Lo (1985). Stochastic long-term hydrothermal
optimization for a multireservoir system. IEEE Trans. Power Apparatus and Systems 104(8),
2040–2049.
Smeers, Y. (1990). Traitement de l’incertain dans le calcul des plans d’e´ quipement e´ lectrique, in: B.
Cornet, H. Tulkens, (eds.), Mode´lisation et De´cision Economique, De Boeck Universite´ , Bruxelles.
Stedinger, J.R. (1998). Stochastic multi-reservoir hydroelectric scheduling, in: Proceedings 28.
Internationales
Wasserbau-Symposium,
Wasserwirtschaﬂiche
Systeme-Konzepte,
Konﬂikte,
Kompromisse.
Institut
fu¨ r
Wasserbau
und
Wasserwirtschaft,
Rheinisch-Westfa¨ lischen
Technischen Hochschule Aachen, Aachen, Germany, pp. 89–117.
Takriti, S., J.R. Birge, E. Long (1996). A stochastic model for the unit commitment problem. IEEE
Transactions on Power Systems 11(3), 1497–1506.
Takriti, S., B. Krasenbrink, L.S.Y. Wu (2000). Incorporating fuel constraints and electricity spot prices
into the stochastic unit commitment problem. Operations Research 48(2), 268–280.
Takriti, S., C. Supatgiat, L.S.Y. Wu (2001). Coordinating fuel inventory and electric power generation
under uncertainty. IEEE Transactions on Power Systems 16(4), 603–608.
Tejada-Guibert, S.A. Johnson, J.R. Stedinger (1995). The value of hydrologic information in
stochastic dynamic programming models of a multireservoir system, Water Resources Research 31,
2571–2579.
Terry, L.A., M.V.F. Pereira, T.A.A. Neto, L.E.C.A. Pinto, P.R.H. Sales (1986). Coordinating the
energy
generation
of
the
Brazilian
national
hydrothermal
electrical
generating
system.
INTERFACES 16(1), 16–38.
Thompson, A.C. (1995). Valuation of path-dependent contingent claims with multiple exercise
decisions over time—the case of take-or-pay. Journal of Financial and Quantitative Analysis 30(2),
271–293.
Tseng, C.-L., G., Barz (2002). Short-term generation asset valuation: A real options approach.
Operations Research 50(2), 297–310.
Turgeon, A. (1980). Optimal operation of multireservoir power systems with stochastic inﬂows. Water
Resources Research 16, 275–283.
Wallace, S.W. (1986). Solving stochastic programs with network recourse. Networks 16, 295–317.
Wood, A.J., B.F. Wollenberg (1996). Power Generation, Operation, and Control, 2nd ed., John Wiley &
Sons, New York.
Yakowitz, S. (1982). Dynamic programming applications in water resources. Water Resources
Research 18(4), 673–696.
Yeh, W.W.-G. (1985). Reservoir management and operation models: a state of the art review. Water
Resources Research 21(12), 1797–1818.
Ch. 10. Stochastic Programming Models in Energy
677

Subject Index
-approximations, 229
-concave function, 273
-concave measure, 274
Absolute semideviation, 51
Absolutely continuous distribution, 136
Actionability, 566
arg min set, 431
Asymptotic conﬁdence set, 435
Attribute vector, 565
Augmented Lagrangian, 195
Backward enumeration, 307
Backward reduction, 546
Basic feasibility cuts, 146
Basic objective cuts, 145
Biased estimator, 367
Binomial moments, 313
Binomial moment problems, 314
Blow-up function, 434
Boolean probability bounding
scheme, 318, 319
Bounded in probability (random
variable), 418, 435
Bounded Lipschitz metric, 489
Branch & bound, 237, 240, 244, 306
Bundle methods, 166, 243
Central limit theorem, 366, 450
Chance constraints, 9
Characteristic function, 9
Chvatal–Gomory procedure, 236
Closed multifunction, 411
Coherent orientation, 415
Common random number generator, 356
Complete local minimizing set, 494
Complete recourse, 79
Conditional expectation constraints, 270
Condition number, 381
Conditional sampling, 405
Conditional value-at-risk, 344, 447, 506
Cone, 127
Cone generation method, 303
Conjugate duality, 107, 132
Conjugate function, 130
Consistent estimator, 355, 359
Constraints, 7
Container management, 558
Control law, 46
Controls, 562
Convergence in distribution, 366
Convex hull, 127
Cost-to-go function, 24, 46, 95, 182
Covering type, 455
Crame´ r’s LD theorem, 418
Crew management, 559
Critical cone, 414
Critical scenarios, 174
Cutting plane methods, 144, 192, 301, 601
Cutting plane procedure, 239
Decision function, 573
Dense subset, 360
Deterministic forecast, 586
Deviation of a set, 358
Directional derivative, 66, 127
Directionally diﬀerentiable function, 126
Discrepancy, 490
Discrete -concave function, 303
Discrete distribution, 57, 279
Domain, 57
Douglas–Rachford method, 201
Dual dynamic programming equation, 117
Dual feasibility, 511, 523
Dual function, 115, 120
Dual methods, 143
Dual problem, 104, 112, 116, 121
Duality gap, 133
Duality theorem, 335
679

Dynamic process, 567
Dynamic programming, 45, 612
Dynamic programming equation, 47, 95, 182
Eﬃcient frontier, 52
Eﬃcient point, 299
Empirical counterpart, 431, 436, 470
Empirical distribution, 430
Empirical process, 539
Empirical solution, 470
Epiconvergence, 416, 463
Epiconverge in distribution, 467
Epi-distance, 503
Epigraph, 58
"-optimal solution, 359
Equipment management, 558
Essentially bounded mapping, 112
Event tree, 646
Expectation function, 57
Expected payoﬀ, 659
Expected shortage, 228
Expected shortfall, 666
Expected surplus, 228
Expected value function, 7, 65, 75, 219
Expected value of perfect information, 22
Expected value, 56
Extended real valued functions, 56
Fatou’s lemma, 136, 145
Feasibility cut, 183
Feasible policy, 95, 403
Feedback rule, 46
Fenchel–Moreau theorem, 130
Finite support, 57
First order optimality conditions, 390
Fixed recourse, 12, 79, 88
Fleet management, 609
Fortet–Mourier distance, 446
Fortet–Mourier metrics, 489
Forward selection, 546
Fourth order upper bound, 316
Fre´ chet diﬀerentiability, 127
Fractional cutting plane algorithm, 239
Gaˆ teux diﬀerentiable, 127
Glivenko–Cantelli class, 539
Glivenko–Cantelli theorem, 453
Gomory cuts, 236
Growth function, 440, 499
Hausdorﬀdistance, 358, 437
Hazard rate function, 296
Hoﬀman theorem, 131
Hunter’s upper bound, 319
Ill conditioned problem, 380
Implementable policy, 95, 102, 188, 403
Importance sampling, 156, 397
Incidence matrix, 318
Inclusion-exclusion formula, 312
Independent identically distributed (iid), 355
Indicator function, 74
Information processes, 560
Information state, 25, 571, 572
Integer L-shaped algorithm, 250
Integer program, 235
Integrand, 65
Integrated chance constraint, 270
Interior point, 127
Inventory problems, 574
Jacobi method, 197
Joint probabilistic constraint, 11
Kantorovich metric, 489
(KKT) optimality conditions, 387
Knowability, 566
Knowledge base, 567
Lagrange multipliers, 104, 135
Lagrangian dual, 135
Lagrangian relaxation, 237
Lagrangian, 85, 103, 112, 115, 120, 135, 242
Large deviations theorem, 452
Latin Hypercube (LH) sampling, 395
Law of iterated logarithm, 450
Leaf node, 646
Lebesgue dominated convergence
theorem, 137
Level sets, 362
Likelihood ratio function, 396
Linear control estimator, 396
Linear multistage problem, 93
Linear two-stage problem, 141
Lipschitz continuous, 127
Load duration curve, 640
Local curvature, 475
Logconcave, 279
Logarithmically concave function, 272
Logarithmically concave measure, 272
Logarithmic barrier function, 289
Lower semicontinuous function, 58, 462
Markov chain, 33
Markowitz model, 446
Master problem, 147, 159, 192
Max-function, 123
Maximal monotone operator, 204
680
Subject Index

Mean absolute deviation, 448
Mean–risk model, 51
Measurable mapping, 55
Measurable selection, 60
Measurable set, 55
Method of feasible directions, 288
Metric entropy, 454
Metric regularity, 493
Min–max problem, 122
Minimizer theorem, 472
Mixed-integer nested formulation, 234
Model state equations, 26
Model state variables, 26
Moment generating function, 373, 418
Monotone convergence theorem, 136
Monte Carlo methods, 592
Moreau–Rockafellar theorem, 129
Moreau–Yosida regularization, 163
Multicommodity ﬂow problems, 574
Multicut method, 153
Multicut version, 251
Multifunction, 60
Multiplier method, 195
Multistage stochastic programming
problem, 23, 36, 230, 612
Myopic model, 584
Nested formulation, 25, 36
Network ﬂow problem, 642
Network recourse, 598
Nodal recourse, 592
Nonanticipativity constraints, 15, 28, 34, 35,
118, 143, 188
Nonanticipativity, 18, 231
Nonparametric estimates, 296
Normal cone, 128
Null step, 162
Objective cut, 144, 158, 183
Operator splitting methods, 201
Operator monotone, 203
Operator nonexpansive, 204
Optimal value function, 59, 486
Optimality conditions, 99
Optimality cuts, 238, 240
Optimality gap, 382
Order growth, 501
P-integrable, 57
Pointwise Law of Large Number, 359
Polar cone, 75, 127
Polyhedral two stage problem, 85
Polyhedral function, 74
Polyhedral multistage problem, 187
Polyhedral multistage stochastic
programming problems, 180
Pompeiu–Hausdorﬀdistance, 503
Positive hull, 75
Primal decomposition methods, 142
Primal–dual method, 292
Primal–dual interior point
algorithm, 294
Probabilistic constraints, 9
Probability density function, 136
Probability space, 55
Problem of moments, 126
Product distribution, 557
Progressive hedging method, 203
Proper function, 57, 128
Proximal point method, 164, 195, 205
Radial cone, 128
Random lower semicontinuous
function, 61, 70, 466
Random polyhedral function, 85
Random probability measure, 431
Random variable, 55, 56
Random vector, 55
Rate function, 372, 418
Recession cone, 75
Recourse matrix, 12
Reduced gradient method, 290
Regression method, 298
Regularized decomposition method, 162
Regularized master problem, 162
Relative interior, 127
Relatively complete recourse, 79, 511, 523
Resolvent, 204
Resource allocation problem, 574
Resources, 560, 565
Risk functionals, 428, 505
Risk measure, 51, 505
Risk premium, 656
Root node, 646
Routing and scheduling, 609
Rubin’s theorem, 223
Saddle point, 105, 132
Sample average approximation problem
(SAA), 356
Sample space, 55
Sample average approximation, 262
Sample average function, 355, 356
Scenarios, 13, 27, 76
Scenario decomposition, 241
Scenario decomposition algorithm, 244
Scenario generation, 544
Subject Index
681

Scenario programming, 599
Scenario reduction, 545
Scenario subproblem, 143, 191, 202
Scenario tree, 29, 33, 181
Second order bounds, 315
Second-stage value function, 215
Semi-deviation, 448
Semideviation measures, 51
Semi-variance, 448
Separable approximation, 594
Separation problem, 236
Serious step, 162
Sigma algebra, 55
Simple integer recourse, 227, 245
Simple recourse, 515
Simple recourse model, 227, 588
Slater condition, 366
Solution-set mapping, 486
Standard normal critical value, 383
Statistical decision, 268
Statistical lower bound, 382
Stochastic branch & bound method, 259
Stochastic decomposition, 601
Stochastic generalized equation, 410
Stochastic linearization, 603
Stochastic variational inequalities, 410
Strict complementarity, 389
Strongly consistent estimator, 434
Strong Law of Large Numbers, 359, 450
Strong regularity, 412
Subconsistent problem, 133
Subdiﬀerential, 70, 77, 87, 128
Subgradient, 128
Support of a measure, 79
Supporting hyperplane method, 290
Tangent cone, 128
Technology matrix, 12
Testing of statistical hypothesis, 268
Third order bounds, 316
Topological closure, 129
Trust region methods, 175
Two-stage problem, 12, 18, 90
Two-stage problem with probabilistic
constraint, 311
Two stage stochastic integer problem, 237
Two-stage stochastic programming problem,
20, 72, 215
Unbiased estimator, 355
Uniform Law of Large Numbers, 363
Uniform probability distribution, 393
Uniform Strong Law of Large
Numbers, 453
Uniformly integrability, 491
Uniformly integrable, 418
Universal conﬁdence, 439
Valid inequality, 236
Value at Risk, 9, 344, 447, 507
Vapnik-C˘ ervonenkis (VC) index, 454
Vapnik-C˘ ervonenkis (VC) class, 542
Variational distance, 446
Variational inequality, 410
Wait-and-see solution, 21
Weak convergence of probability
measures, 223
Weak convergence, 488
Weakly consistent estimator, 433
Well conditioned problem, 380
Well deﬁned expectation, 56, 57, 65
Zero Theorem, 479
682
Subject Index

