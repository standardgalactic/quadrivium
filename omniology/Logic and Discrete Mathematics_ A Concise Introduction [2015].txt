

LOGIC AND DISCRETE MATHEMATICS


LOGIC AND DISCRETE MATHEMATICS
A CONCISE INTRODUCTION
Willem Conradie
University of Johannesburg,
South Africa
Valentin Goranko
Stockholm University, Sweden

This edition first published 2015
© 2015 John Wiley and Sons Ltd
Registered office
John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom
For details of our global editorial offices, for customer services and for information about how to apply for permission to
reuse the copyright material in this book please see our website at www.wiley.com.
The right of the author to be identified as the author of this work has been asserted in accordance with the Copyright,
Designs and Patents Act 1988.
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any
form or by any means, electronic, mechanical, photocopying, recording or otherwise, except as permitted by the UK
Copyright, Designs and Patents Act 1988, without the prior permission of the publisher.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available
in electronic books.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this
book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this
book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. It is sold on
the understanding that the publisher is not engaged in rendering professional services and neither the publisher nor the
author shall be liable for damages arising herefrom. If professional advice or other expert assistance is required, the
services of a competent professional should be sought
Library of Congress Cataloging-in-Publication Data
Conradie, Willem, 1978- author.
Logic and discrete mathematics : a concise introduction / Willem Conradie, Valentin Goranko.
pages cm
Includes index.
ISBN 978-1-118-75127-5 (pbk.)
1.
Logic, Symbolic and mathematical–Textbooks. 2.
Computer science–Mathematics–Textbooks.
I. Goranko, Valentin, author.
II. Title.
QA9.C7423 2015
511.3–dc23
2014035964
A catalogue record for this book is available from the British Library.
Front cover image: Narrow walkway inside the Great Enclosure at the Great Zimbabwe ruins. Reproduced by kind
permission of Kenneth Meeks.
Set in 9/11pt, PalatinoLTStd by Laserwords Private Limited, Chennai, India
1
2015

Contents
List of Boxes
xiii
Preface
xvii
Acknowledgements
xxi
About the Companion Website
xxiii
1. Preliminaries
1
1.1 Sets
2
1.1.1 Exercises
7
1.2 Basics of logical connectives and expressions
9
1.2.1 Propositions, logical connectives, truth tables, tautologies
9
1.2.2 Individual variables and quantiﬁers
12
1.2.3 Exercises
15
1.3 Mathematical induction
17
1.3.1 Exercises
18
2. Sets, Relations, Orders
20
2.1 Set inclusions and equalities
21
2.1.1 Properties of the set theoretic operations
22
2.1.2 Exercises
26
2.2 Functions
28
2.2.1 Functions and their inverses
28
2.2.2 Composition of mappings
31
2.2.3 Exercises
33
2.3 Binary relations and operations on them
35
2.3.1 Binary relations
35
2.3.2 Matrix and graphical representations of relations on ﬁnite sets
38

vi
Contents
2.3.3 Boolean operations on binary relations
39
2.3.4 Inverse and composition of relations
41
2.3.5 Exercises
42
2.4 Special binary relations
45
2.4.1 Properties of binary relations
45
2.4.2 Functions as relations
47
2.4.3 Reﬂexive, symmetric and transitive closures of a relation
47
2.4.4 Exercises
49
2.5 Equivalence relations and partitions
51
2.5.1 Equivalence relations
51
2.5.2 Quotient sets and partitions
53
2.5.3 The kernel equivalence of a mapping
56
2.5.4 Exercises
57
2.6 Ordered sets
59
2.6.1 Pre-orders and partial orders
59
2.6.2 Graphical representing posets: Hasse diagrams
61
2.6.3 Lower and upper bounds. Minimal and maximal elements
63
2.6.4 Well-ordered sets
65
2.6.5 Exercises
67
2.7 An introduction to cardinality
69
2.7.1 Equinumerosity and cardinality
69
2.7.2 Exercises
73
2.8 Isomorphisms of ordered sets. Ordinal numbers
75
2.8.1 Exercises
79
2.9 Application: relational databases
80
2.9.1 Exercises
86
3. Propositional Logic
89
3.1 Propositions, logical connectives, truth tables, tautologies
90
3.1.1 Propositions and propositional connectives. Truth tables
90
3.1.2 Some remarks on the meaning of the connectives
90
3.1.3 Propositional formulae
91
3.1.4 Construction and parsing tree of a propositional formula
92

Contents
vii
3.1.5 Truth tables of propositional formulae
93
3.1.6 Tautologies
95
3.1.7 A better idea: search for a falsifying truth assignment
96
3.1.8 Exercises
97
3.2 Propositional logical consequence. Valid and invalid propositional inferences
101
3.2.1 Propositional logical consequence
101
3.2.2 Logically sound rules of propositional inference. Logically correct propositional arguments
104
3.2.3 Fallacies of the implication
106
3.2.4 Exercises
107
3.3 The concept and use of deductive systems
109
3.4 Semantic tableaux
113
3.4.1 Exercises
117
3.5 Logical equivalences. Negating propositional formulae
121
3.5.1 Logically equivalent propositional formulae
121
3.5.2 Some important equivalences
123
3.5.3 Exercises
124
3.6 Normal forms. Propositional resolution
126
3.6.1 Conjunctive and disjunctive normal forms of propositional formulae
126
3.6.2 Clausal form. Clausal resolution
129
3.6.3 Resolution-based derivations
130
3.6.4 Optimizing the method of resolution
131
3.6.5 Exercises
132
4. First-Order Logic
135
4.1 Basic concepts of ﬁrst-order logic
136
4.1.1 First-order structures
136
4.1.2 First-order languages
138
4.1.3 Terms and formulae
139
4.1.4 The semantics of ﬁrst-order logic: an informal outline
143
4.1.5 Translating ﬁrst-order formulae to natural language
146
4.1.6 Exercises
147
4.2 The formal semantics of ﬁrst–order logic
152
4.2.1 Interpretations
152
4.2.2 Variable assignment and term evaluation
153

viii
Contents
4.2.3 Truth evaluation games
156
4.2.4 Exercises
159
4.3 The language of ﬁrst-order logic: a deeper look
161
4.3.1 Translations from natural language into ﬁrst-order languages
161
4.3.2 Restricted quantiﬁcation
163
4.3.3 Free and bound variables. Scope of a quantiﬁer
164
4.3.4 Renaming of a bound variable in a formula. Clean formulae
165
4.3.5 Substitution of a term for a variable in a formula. Capture of a variable
166
4.3.6 Exercises
167
4.4 Truth, logical validity, equivalence and consequence in ﬁrst-order logic
171
4.4.1 More on truth of sentences in structures. Models and countermodels
171
4.4.2 Satisﬁability and validity of ﬁrst-order formulae
172
4.4.3 Logical equivalence in ﬁrst-order logic
173
4.4.4 Some logical equivalences involving quantiﬁers
174
4.4.5 Negating ﬁrst-order formulae
175
4.4.6 Logical consequence in ﬁrst-order logic
176
4.4.7 Exercises
180
4.5 Semantic tableaux for ﬁrst-order logic
185
4.5.1 Some derivations using ﬁrst-order semantic tableau
186
4.5.2 Semantic tableaux for ﬁrst-order logic with equality
189
4.5.3 Discussion on the quantiﬁer rules and on termination of semantic tableaux
189
4.5.4 Exercises
191
4.6 Prenex and clausal normal forms
195
4.6.1 Prenex normal forms
195
4.6.2 Skolemization
197
4.6.3 Clausal forms
198
4.6.4 Exercises
199
4.7 Resolution in ﬁrst-order logic
201
4.7.1 Propositional resolution rule in ﬁrst-order logic
201
4.7.2 Substitutions of terms for variables revisited
201
4.7.3 Uniﬁcation of terms
202
4.7.4 Resolution with uniﬁcation in ﬁrst-order logic
204
4.7.5 Examples of resolution-based derivations
205

Contents
ix
4.7.6 Resolution for ﬁrst-order logic with equality
207
4.7.7 Optimizations of the resolution method for ﬁrst-order logic
207
4.7.8 Exercises
207
4.8 Applications of ﬁrst-order logic to mathematical reasoning and proofs
211
4.8.1 Proof strategies: direct and indirect proofs
211
4.8.2 Tactics for logical reasoning
215
4.8.3 Exercises
216
5. Number Theory
219
5.1 The principle of mathematical induction revisited
220
5.1.1 Exercises
222
5.2 Divisibility
224
5.2.1 Basic properties of divisibility
224
5.2.2 Division with a remainder
224
5.2.3 Greatest common divisor
225
5.2.4 Exercises
227
5.3 Computing greatest common divisors. Least common multiples
230
5.3.1 Euclid’s algorithm for computing greatest common divisors
230
5.3.2 Least common multiple
232
5.3.3 Exercises
233
5.4 Prime numbers. The fundamental theorem of arithmetic
236
5.4.1 Relatively prime numbers
236
5.4.2 Prime numbers
237
5.4.3 The fundamental theorem of arithmetic
238
5.4.4 On the distribution of prime numbers
239
5.4.5 Exercises
240
5.5 Congruence relations
243
5.5.1 Exercises
246
5.6 Equivalence classes and residue systems modulo n
248
5.6.1 Equivalence relations and partitions
248
5.6.2 Equivalence classes modulo n. Modular arithmetic
249
5.6.3 Residue systems
250

x
Contents
5.6.4 Multiplicative inverses in ℤn
251
5.6.5 Exercises
251
5.7 Linear Diophantine equations and linear congruences
253
5.7.1 Linear Diophantine equations
253
5.7.2 Linear congruences
254
5.7.3 Exercises
256
5.8 Chinese remainder theorem
257
5.8.1 Exercises
259
5.9 Euler’s function. Theorems of Euler and Fermat
261
5.9.1 Theorems of Euler and Fermat
262
5.9.2 Exercises
264
5.10 Wilson’s theorem. Order of an integer
266
5.10.1 Wilson’s theorem
266
5.10.2 Order of an integer
266
5.10.3 Exercises
267
5.11 Application: public key cryptography
269
5.11.1 About cryptography
269
5.11.2 The idea of public key cryptography
269
5.11.3 The method RSA
270
5.11.4 Exercises
271
6. Combinatorics
274
6.1 Two basic counting principles
275
6.1.1 Exercises
281
6.2 Combinations. The binomial theorem
284
6.2.1 Counting sheep and combinations
284
6.2.2 Some important properties
286
6.2.3 Pascal’s triangle
287
6.2.4 The binomial theorem
287
6.2.5 Exercises
289
6.3 The principle of inclusion–exclusion
293
6.3.1 Exercises
296

Contents
xi
6.4 The Pigeonhole Principle
299
6.4.3 Exercises
302
6.5 Generalized permutations, distributions and the multinomial theorem
304
6.5.1 Arranging nondistinct objects
304
6.5.2 Distributions
306
6.5.3 The multinomial theorem
308
6.5.4 Summary
310
6.5.5 Exercises
311
6.6 Selections and arrangements with repetition; distributions of identical objects
312
6.6.1 Selections with repetition
312
6.6.2 Distributions of identical objects
314
6.6.3 Arrangements with repetition
315
6.6.4 Summary
316
6.6.5 Exercises
316
6.7 Recurrence relations and their solution
318
6.7.1 Recurrence relations. Fibonacci numbers
318
6.7.2 Catalan numbers
319
6.7.3 Solving homogeneous linear recurrence relations
322
6.7.4 Exercises
327
6.8 Generating functions
329
6.8.1 Introducing generating functions
329
6.8.2 Computing coefﬁcients of generating functions
332
6.8.3 Exercises
335
6.9 Recurrence relations and generating functions
337
6.9.1 Exercises
341
6.10 Application: classical discrete probability
343
6.10.1 Common sense probability
343
6.10.2 Sample spaces
343
6.10.3 Discrete probability
345
6.10.4 Properties of probability measures
346
6.10.5 Conditional probability and independent events
348
6.10.6 Exercises
352

xii
Contents
7. Graph Theory
356
7.1 Introduction to graphs and digraphs
357
7.1.1 Graphs
357
7.1.2 Digraphs
364
7.1.3 Exercises
367
7.2 Incidence and adjacency matrices
370
7.2.1 Exercises
374
7.3 Weighted graphs and path algorithms
377
7.3.1 Dijkstra’s algorithm
378
7.3.2 The Floyd–Warshall algorithm
381
7.3.3 Exercises
383
7.4 Trees
385
7.4.1 Undirected trees
385
7.4.2 Computing spanning trees: Kruskal’s algorithm
388
7.4.3 Rooted trees
390
7.4.4 Traversing rooted trees
392
7.4.5 Exercises
393
7.5 Eulerian graphs and Hamiltonian graphs
395
7.5.1 Eulerian graphs and digraphs
396
7.5.2 Hamiltonian graphs and digraphs
398
7.5.3 Exercises
400
7.6 Planar graphs
404
7.6.1 Exercises
408
7.7 Graph colourings
411
7.7.1 Colourings
411
7.7.2 The four- and ﬁve-colour theorems
413
7.7.3 Exercises
414
Index
419

List of Boxes
1. Preliminaries
1
Paradoxes
19
2. Sets, Relations, Orders
20
Russell’s paradox
27
Georg Cantor
35
The notation of set theory
45
Fuzzy sets
50
Zermelo–Fraenkel set theory
58
The axiom of choice
68
The continuum hypothesis
74
Hilbert’s Hotel
80
Charles Sanders Peirce
88
3. Propositional Logic
89
Aristotle
100
George Boole
109
David Hilbert
112
Early proof theory
120
Augustus De Morgan
126
The Boolean satisﬁability problem and NP-completeness
133

xiv
List of Boxes
4. First-Order Logic
135
Gottlob Frege
151
Giuseppe Peano
160
Bertrand Russell
170
Alfred Tarski
184
Kurt Gödel
194
Thoralf Skolem
200
Alonzo Church
210
Alan Turing
217
5. Number Theory
219
Carl Friedrich Gauss
223
Pythagoras of Samos
229
Euclid of Alexandria
235
Primality testing
242
Richard Dedekind
247
Babylonian mathematics
252
Diophantus of Alexandria
257
Ancient Chinese mathematics
260
Pierre de Fermat
265
Ancient and Medieval Indian and Arabic mathematics
268
History of codes and ciphers
272
6. Combinatorics
274
Stirling’s approximation of n!
283
Pascal’s triangle
292
Venn diagrams
298
Lejeune Dirichlet
304
Braille
312
Blaise Pascal
317
Fibonacci
328
Combinatorial games: Nim
336

List of Boxes
xv
Fibonacci numbers and the golden ratio
342
Pierre-Simon de Laplace
355
7. Graph Theory
356
Leonhard Euler
369
Ramsey theory
376
Edsger Dijkstra
385
Paul Erdõs
395
William Hamilton
403
Graph theory and Sudoku
410
The four-colour problem
417


Preface
Discrete Mathematics1 refers to a range of mathematical disciplines that study discrete struc-
tures and phenomena, unlike other classical fields of mathematics, such as analysis, geometry
and topology, which study continuous structures, processes and transformations. Intuitively
put, discrete structures – such as the linear order of natural numbers or the set of cities and
towns in a country together with the roads between them – consists of separable, discretely
arranged objects, whereas continuous structures – such as the trajectory of a moving object, the
real line, the Euclidian plane or a sphere – are densely filled, with no “gaps”. The more impor-
tant distinction, however, is between the types of problems studied and solved in discrete and
continuous mathematics and also between the main ideas and techniques that underly and
characterize these two branches of mathematics. Nevertheless, this distinction is often blurred
and many ideas, methods and results from each of these branches have been fruitfully applied
to the other.
The intuitive explanation above is not meant to define what should be classified as Dis-
crete Mathematics, as every such definition would be incomplete or debatable. A more useful
description would be to list what we consider to be the basic mathematical disciplines tradi-
tionally classified as Discrete Mathematics and included in most university courses on that
subject: the Theory of Sets and Relations, Mathematical Logic, Number Theory, Graph The-
ory and Combinatorics. These are the topics covered in this book. Sometimes textbooks and
courses on Discrete Mathematics also include Abstract Algebra, Classical Probability Theory,
Automata Theory, etc. These topics are not included here, mainly for practical reasons.
Logic was born in the works of Aristotle as a philosophical study of reasoning some 25 cen-
turies ago. Over the past 150 years it has gradually developed as a fundamental mathematical
discipline, which nowadays has deep and mature mathematical content and also applications
spreading far beyond foundational and methodological issues. While the field of Mathemat-
ical Logic is often regarded as included in the broad scope of Discrete Mathematics, in this
book it is treated essentially on a par with it.
As mathematical fields of their own importance, both Logic and Discrete Mathematics
are relatively young and very dynamically developing disciplines, especially since the mid
20th century, when the computer era began. Many of the most exciting current developments
1 Not to be confused with discreetly done mathematics!

xviii
Preface
in Logic and Discrete Mathematics are motivated and inspired by applications in Computer
Science, Artificial Intelligence and Bioinformatics. We have accordingly included some such
selected applications in the book.
About the book
The work on this book started more than a decade ago as a loose collection of lecture notes
that we wrote and used to teach courses on Logic and Discrete Mathematics, partly because
we could not find available suitable textbooks that would meet our needs and requirements.
Eventually we decided to write a book of our own, which would best reflect the content and
features we consider most important:
1. Being logicians, we have provided a much more detailed and deeper treatment of
Logic than is usual in textbooks on Discrete Mathematics. We believe that such a treat-
ment is necessary for the proper understanding and use of Logic as a mathematical
and general reasoning tool, and we consider it a distinguishing feature of the book.
2. We included only what we consider to be the core disciplines within the field of Dis-
crete Mathematics (without claiming that ours is the only good choice) but have treated
these disciplines in considerable depth for an undergraduate text. That enabled us to
keep the book within reasonable size limits without compromising on the content and
exposition of the topics included.
3. We have tried to keep the exposition clear and concise while still including the
necessary technical detail and illustrating concepts and techniques with numerous
examples.
4. We have included comprehensive sets of exercises, most of them provided with
answers or solutions in an accompanying solutions manual.
5. We have also included “boxes” at the end of each section. Some contain mathemat-
ics titbits or applications of the content in the section. Others are short biographies of
distinguished scientists who have made fundamental contributions to Discrete Math-
ematics. We hope the reader will find it inspiring to learn a little about their lives and
their contributions to the fields covered in the book.
To the instructor
We have aimed this book to be suitable for a variety of courses for students in both Mathe-
matics and Computer Science. Some parts of it are much more relevant to only one of these
audiences and we have indicated them by introducing Mathematics Track and Computer Science
Track markers in the text. We regard everything not explicitly on either of these tracks to be
suitable for both groups.
In addition, the book can be used for designing courses on different undergraduate or
lower graduate levels. Some material that could reasonably be omitted in courses at a lower
undergraduate level is indicated with an Advances Track marker. These tracks are, of course,
only suggestions, which should serve as our recommendations to the instructor.

Preface
xix
The single stars shown in the exercises are deemed to be exercises that are more difficult,
while the double stars are considered to be exercises that are challenging.
The whole book can be comfortably covered in two semester courses, or various selections
can be made for a single semester course. Apart from assuming knowledge of the background
material in the preliminary Chapter 1, the chapters are essentially independent and can be
taught in any order. The only exception is Chapter 4 on first-order logic, which presupposes
knowledge of the material on propositional logic covered in Chapter 3. Also, much of the
content of Chapter 2 covers general mathematical background, useful for the rest of the book.


Acknowledgements
A number of people have contributed, one way or another, to our work on this book over the
years. With the risk of inadvertently omitting some names, for which we apologize in advance,
we would like to thank Gerhard Benadé, Thomas Bolander, Izak Broere, Ruaan Kellerman,
Heidi Maartens, Chantel Marais and Claudette Robinson for helpful feedback, comments,
technical or editorial corrections and some solutions to exercises. Besides them, thanks are
due to many students at the University of Johannesburg, the University of the Witwatersrand
and the Technical University of Denmark, who pointed out some errors in earlier versions of
the manuscript. We thank Justin Southey for the use of the GraphScribe application authored
by him, which greatly speeded up the drawing of some combinatorial graphs, and also for his
suggestions on the applications of Graph Theory. Valentin is also grateful to Nina Ninova for
her general support during the work on this book as well as help with collecting photos and
references for many of the historical boxes. Willem would like to thank Dion Govender for his
patience and support during the final months of intense work on the book. Last but not least,
we wish to thank Richard Davies, Audrey Koh, Kathryn Sharples, Mark Styles and Jo Taylor
from Wiley as well as Krupa Muthu from Laserwords for their kind support and technical
advice during the work on this book.


About the Companion Website
This book is accompanied by a companion website:
www.wiley.com/go/conradie/logic
The website includes:
• Lecture Slides
• Quizzes

1
Preliminaries
1.1.
Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2.
Basics of logical connectives and expressions
. . . . . . . . . . . . . . . . . . . .
9
1.3.
Mathematical induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
Here we briefly review some minimal background knowledge that we will assume in the rest
of the book. Besides a small amount of that nebulous quality called “mathematical maturity”,
we only expect some basic concepts from set theory and mathematical indiction. The reader
who is familiar with these concepts can safely skip on to the next chapter.
Some notation
We denote the set of natural numbers {0‚ 1‚ 2‚ …} by ℕ. There is some inconsistency in the
mathematical literature as to whether 0 belongs to the natural numbers or not: some authors
choose to include it, other do not. For our purposes it is convenient to include 0 as a natural
number. Other number sets which will be of importance to us include the sets of integers ℤ,
positive integers ℤ+, rational numbers ℚ, positive rational numbers ℚ+, real numbers ℝ, and
positive real numbers ℝ+.
The product 1 × 2 × 3 × · · · × n of the first n positive integers turns up in many mathemati-
cal situations. It is therefore convenient to have a more compact notation for it. We accordingly
define 0! = 1 and n! = 1 × 2 × 3 × · · · × n, for n ≥1. We read n! as ‘n factorial’. The definition of
0! as 1 is not supposed to carry any intuitive meaning: it is simply a useful convention.
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

2
Logic and Discrete Mathematics: A Concise Introduction
1.1.
Sets
Sets and elements. By a set we intuitively mean a collection of objects of any nature (num-
bers, people, concepts, sets themselves, etc.) that is considered as a single entity. The objects in
that collection are called elements of the set. If an object x is an element of a set A, we denote
that fact by
x ∈A;
otherwise we write
x ∉A.
We also say that x is a member of the set A or that x belongs to A. If a set has finitely many elements
(here we rely on your intuition of what finite is), we can describe it precisely by listing all of
them, for example:
A = {3‚ 4‚ 5}.
We often rely on our common intuition and use ellipses, as in
A = {1‚ 2‚ …‚ n}.
We sometimes go further and use the same for infinite sets; for example, the set of natural
numbers can be specified as
ℕ= {0‚ 1‚ 2‚ 3‚ …}.
Further we will discuss a more universal method of describing sets.
Equality and containment of sets. Two sets are declared equal if and only if they have the
same elements. In other words, the sets A and B are equal, denoted as usual by A = B, if every
element of A is an element of B and every element of B is an element of A. For example, the
sets {a‚ b‚ c} and {b‚ c‚ a} are equal, and so are the sets {1‚ 9‚ 9‚ 7}, {1‚ 9‚ 7} and {7‚ 1‚ 9‚ 1‚ 7‚ 1}.
A set A is a subset of a set B, denoted A ⊆B, if every element of A is an element of B. If
A ⊆B, we also say that A is included in B, or that B contains A. For example, {3‚ 5} ⊆{5‚ 4‚ 3}.
Note that every set is a subset of itself.
The following facts are very useful. They are direct consequences of the definitions of
equality and containment of sets.
• Two sets A and B are equal if, and only if, A ⊆B and B ⊆A.
• A set A is not a subset of a set B, denoted A ⊈B, if, and only if, there is an element of A that
is not an element of B.
• A set A is not equal to a set B if A is not a subset of B or if B is not a subset of A.
A set A is a proper subset of a set B, denoted A ⊂B or A ⫋B, if A ⊆B and A ≠B. In other
words, A is a proper subset of B if A is a subset of B and B is not a subset of A, i.e. if at least
one element of B is not in A. In particular, no set is a proper subset of itself. If A is not a proper
subset of B, we denote that by A ⊈B.
The empty set. Amongst all sets there is one that is particularly special. That is the empty
set, i.e. the set that has no elements. By definition of equality of sets, there is only one empty

Preliminaries
3
set. One might think that the empty set is a useless abstraction. On the contrary, it is a very
important set, and probably the most commonly used one in mathematics (like the number 0
is the most commonly used number). That is why it has a special notation: ∅.
Sets and properties. Set-builder notation. We cannot always list the elements of a set, even
if it is finite, so we need a more universal method for specifying sets. The commonly used
method is to describe the property that determines membership of the set, e.g.:
“A is the set of all objects x such that…x….”
where “…x…” is a certain property (predicate) involving x. We use the following convenient
notation, called the set-builder notation for the set described above:
A = {x ∣…x…}.
Here are some examples:
• {x ∣x is a negative real number} defines the set of negative real numbers;
• {x ∣x is a student in the MATH3029 class} defines the set of students in the MATH3029 class.
• {x ∣x ∈ℤand 3 ≥x > −2} defines the set {−1‚ 0‚ 1‚ 2‚ 3}.
• {x ∣x = m
n ‚ where m ∈ℤn ∈ℤand n ≠0} defines the set of rational numbers.
Sometimes, we use the set-builder notation more liberally and, for instance, describe the
set of rational numbers as
{
m
n
||| m and n are integers and n ≠0
}
or the set of positive real num-
bers as {x ∈ℝ∣x > 0}.
Operations on sets. We describe below the basic operations on sets.
Intersection. The intersection of two sets A and B is the set
A ∩B = {x ∣x ∈A and x ∈B}
consisting of all elements that are both in A and in B. If A ∩B = ∅, then A and B are called
disjoint.
Union. The union of two sets A and B is the set
A ∪B = {x ∣x ∈A or x ∈B}
consisting of all elements that are in at least one of A and B.
Difference. The difference of the sets A and B is the set
A −B = {x ∣x ∈A and x ∉B}
consisting of all elements that are in A but not in B. An alternative notation for A −B is
A\B.
For
example,
if
A = {1‚ 2‚ 3‚ 4}
and
B = {3‚ 4‚ 5‚ 6‚ 7}
then
A ∩B = {3‚ 4},
A ∪B =
{1‚ 2‚ 3‚ 4‚ 5‚ 6‚ 7}, A −B = {1‚ 2} and B −A = {5‚ 6‚ 7}.

4
Logic and Discrete Mathematics: A Concise Introduction
Universal sets and complements of sets. Often, all sets that we consider are subsets of one
set, called the domain of discourse. We also call that set the universe or the universal set. For
example, in arithmetic, the universe is usually the set of natural numbers or the set of integers,
while in algebra and calculus, the universe is the set of real numbers; talking about humans,
the universe is the set of all humans, etc.
Definition 1.1.1 Let a universal set U be fixed and A ⊆U. The complement of A (with respect to
U) is the set
A′ = U −A.
The complement of a set A is sometimes also denoted by A.
Thus, the complement of A consists of those objects from the universal set that do not
belong to A. For example, if the universal set is ℝ, then the complement of the interval (0‚ 2] is
(−∞‚ 0] ∪(2‚ ∞); the complement of ℚis the set of irrational numbers.
Powersets. The power set of a set A is the set of all subsets of A:
𝒫(A) = {X ∣X ⊆A}.
Here are some examples:
• 𝒫(∅) = {∅};
• 𝒫({a}) = {∅‚ {a}}, in particular, 𝒫({∅}) = {∅‚ {∅}};
• 𝒫({a‚ b}) = {∅‚ {a}‚ {b}‚ {a‚ b}};
• 𝒫({a‚ b‚ c}) = {∅‚ {a}‚ {b}‚ {c}‚ {a‚ b}‚ {a‚ c}‚ {b‚ c}‚ {a‚ b‚ c}}.
Cartesian products of sets. In order to introduce the next operation we need the notion of
ordered pair. Let a, b be any objects. Intuitively, the ordered pair of a and b, denoted (a‚ b) (do
not confuse this with an open interval of real numbers!), is something like a set consisting of
a as a first element (or first component) and b as a second element (or second component). Thus,
if a ≠b, then the ordered pair (a‚ b) is different from the ordered pair (b‚ a) and each of these
is different from the set {a‚ b} because the elements of a set are not ordered. In particular, the
ordered pair (a‚ a) is different from the set {a‚ a} = {a}. Here is a formal definition of an ordered
pair as a set that satisfies the intuition:
Definition 1.1.2 Given the objects a and b, the ordered pair (a‚ b) is the set {{a}‚ {a‚ b}}.
Here is the fundamental property of ordered pairs:
Proposition 1.1.3 The ordered pairs (a1‚ a2) and (b1‚ b2) are equal if and only if a1 = b1 and a2 = b2.
Proof: Exercise.
Definition 1.1.4 The Cartesian product of the sets A and B is the set
A × B = {(a‚ b) ∣a ∈A and b ∈B}‚
consisting of all ordered pairs where the first component comes from A and the second component comes
from B. In particular, we denote A × A by A2 and call it the Cartesian square of A.

Preliminaries
5
For example, if A = {a‚ b}‚ B = {1‚ 2‚ 3}, then
A × B = {(a‚ 1)‚ (a‚ 2)‚ (a‚ 3)‚ (b‚ 1)‚ (b‚ 2)‚ (b‚ 3)}‚
while
B × A = {(1‚ a)‚ (1‚ b)‚ (2‚ a)‚ (2‚ b)‚ (3‚ a)‚ (3‚ b)}.
Note that if A or B is empty, then A × B is empty too. Moreover, if A has n elements and
B has m elements, then A × B has mn elements (why?). This is one of the reasons for the term
“product”.
The Cartesian coordinate system in the plane is a representation of the plane as the Carte-
sian1 square ℝ2 of the real line ℝ, where we associate a unique ordered pair of real numbers
(its coordinates) with every point in the plane.
The notion of an ordered pair can be generalized to ordered n-tuple, for any n ∈ℕ+. An
n-tuple is an object of the type (a1‚ a2‚ …‚ an) where the order of the components a1‚ a2‚ …‚ an
matters. We will not give a formal set theoretic definition in the style of Definition 1.2.1, but
leave this as an exercise (Exercise 11).
Accordingly, the Cartesian product can be extended to n sets:
A1 × A2 × · · · × An = {(a1‚ a2‚ …‚ an) ∣a1 ∈A1‚ a2 ∈A2‚ · · · ‚ an ∈An}.
As before, we will use the notation An for A × A × · · · × A
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟
n times
.
Relations. Relations, also called predicates, are ubiquitous in mathematics. Relations
between numbers like “being equal”, “being less than” and “being divisible by” come to
mind at once. As these examples indicate, many of the relations we commonly encounter
are binary, i.e., relations relating two objects at a time. It will be convenient for us to identify
a binary relation with the set of all ordered pairs of elements that stand in that relation. We
thus have the following definition:
Definition 1.1.5 A binary relation on a set A is any subset of A2.
For example the relation < on the set ℕof natural numbers is a binary relation, which we
identify with the set
{(a‚ b) ∣a‚ b ∈ℕand a is less than b}.
The relation of “being the mother of” is a binary relation on the set of humans, which we
identify with the following set of ordered pairs:
{(x‚ y) ∣x and y are humans and x is the mother of y}.
Definition 1.1.6 An n-ary relation on a set A is any subset of An.
1 The term “Cartesian” comes from the name of the French mathematician René Descartes (1596–1650), who was
the first to introduce coordinate systems and to apply algebraic methods in geometry.

6
Logic and Discrete Mathematics: A Concise Introduction
More generally, relations may relate objects from different sets:
Definition 1.1.7 An n-ary relation between sets A1‚ A2‚ …‚ An is any subset of A1 × A2 × · · · × An.
If n = 1 we speak of a unary relation, when n = 2 of a binary relation, when n = 3 of a
ternary relation and so on.
Unary relations correspond to sets. For instance, “being positive” is a unary relation on
the set ℝ, which we identify with the set
{a ∣a ∈ℝand 0 < a}.
Conversely, every set A defines the unary relation of “being a member of A”.
The set
{(f(x)‚ a) ∣f(x) is a polynomial, a ∈ℝand f(a) = 0}
is a binary relation between the set of all polynomials in x and the set ℝof real numbers,
relating every polynomial to its real roots. The ordered pairs (x2 −4‚ 2) and (x2 −4‚ −2) are in
this relation. There is no pair in this relation that has x2 + 2 as first component. Why?
Examples of ternary relations are the relation “A is between B and C” relating triples of
points in the plain or the relation “a is greater than b + c” between triples of real numbers.
Functions. Informally, a function from a set A to a set B, denoted by f ∶A →B, can be though
a rule that assigns to every element a ∈A a unique element f(a) ∈B. A is called the domain of
f while B is the codomain, or the target set of f.
Functions need not take only one argument. The function addition on ℝ, for example,
takes two arguments. In general, a function can take any finite number of arguments, but
it can always be regarded as a one-argument function if we consider the domain to be the
Cartesian product of the domains of the different arguments. For instance, we can think of +
as a one-argument function from ℝ× ℝto ℝ. Here is the general definition.
Definition 1.1.8 An n-ary function f from A1 × A2 × · · · × An to B, denoted
f ∶A1 × A2 × · · · × An →B‚
is any rule that to every ordered n-tuple (a1‚ a2‚ …‚ an) ∈A1 × A2 × · · · × An assigns a unique value
f(a1‚ a2‚ …‚ an) ∈B.
In particular, when A1 = A2 = · · · = An = A we call f an n-ary function on the set A, denoted
f ∶An →A.
Functions are naturally associated with special relations, called their graphs. For instance,
think of some familiar function f ∶ℝ→ℝ, such as f(x) = x2. The graph of this function, as
drawn in the plane, consists of the sets of points (x‚ y) in the Cartesian plane such that y = x2,
i.e. the set {(x‚ x2) ∣x ∈ℝ}. This set completely determines the function. Here is the general
definition.
Definition 1.1.9 Given an n-ary function f ∶A1 × · · · × An →B the graph of f is the subset of A1 ×
A2 × · · · × An × B, defined as follows:
Gf = {(a1‚ a2‚ …‚ an‚ f(a1‚ a2‚ …‚ an)) ∣(a1‚ a2‚ …‚ an) ∈A1 × A2 × · · · × An}

Preliminaries
7
Sometimes it is technically convenient to identify functions with their graphs. Thus, an
n-ary function f can be alternatively defined as a subset of A1 × A2 × · · · × An × B, such that
for all (a1‚ a2‚ …‚ an) ∈A1 × A2 × · · · × An, there is a unique b ∈B such that (a1‚ a2‚ …‚ an‚ b) ∈f.
This last condition means that if (a1‚ a2‚ …‚ an‚ b) ∈f and (a1‚ a2‚ …‚ an‚ b′) ∈f then b = b′. Thus
an n-ary function can be regarded as a special type of (n + 1)-ary relation. For instance, the
multiplication of two integers can be regarded as the ternary relation:
{(a‚ b‚ c) ∣a‚ b‚ c ∈ℤ, and a × b = c}.
We will generally use the standard definition of functions as rules but, whenever conve-
nient, we may also adopt the handling functions in terms of their graphs.
1.1.1.
Exercises
➊List all elements of the following sets:
(a) A = {x ∈ℝ∣x2 −3x = 4}
(b) B = {y ∈ℤ∣(y −1)(y + 3)(2y + 3)(y + 5) = 0}
(c) C = {x ∈ℤ∣−3 ≤x < 3}
(d) D = {x ∈ℤ∣−3 ≤x < 3 ∧x2 −3x = 4}
(e) E = {x ∈ℤ∣−3 ≤x < 3 ∧x2 −3x ≠4}
(f) F = {x ∈ℕ∣x is an odd single-digit number}
➋Describe the following sets, using set-builder notation:
(a) B = {−
√
3‚
√
3}
(b) A = {2‚ 4‚ 6‚ 8}
(c) A = {2‚ 4‚ 6‚ 8‚ 10‚ 12‚ …}
(d) A = {…‚ −7‚ −4‚ −1‚ 2‚ 5‚ 8‚ …}
(e) A = {0‚ 1‚ 8‚ 27‚ 64‚ 125‚ …}
(f) A = {−3‚ −2‚ −1‚ 1‚ 2‚ 3‚ 4‚ 5‚ 6}
(g) A = {…‚ −6‚ −5‚ −4‚ −3‚ 5‚ 6‚ 7‚ 8‚ …}
➌Let A = {a‚ b‚ c}. Which of the following are true?
(a) c ∈A
(b) b ⊂A
(c) b ⊆A
(d) {a} ⊂A
(e) {a} ⊆A
(f) {a} ∈A
(g) {a‚ c} ⊂A
(h) {a‚ c} ⊆A
(i) {a‚ b‚ c} ⊂A
(j) {a‚ b‚ c} ⊆A

8
Logic and Discrete Mathematics: A Concise Introduction
➍Let A = {1‚ 2}‚ B = {1‚ {2}‚ A}. Which of the following are true?
(a) 1 ∈A
(b) 2 ∈B
(c) {2} ⊂B
(d) A ⊂B
(e) 2 ⊂B
(f) {2} ⊂B
(g) {2} ⊂A
(h) {A} ⊂A
(i) {A} ⊆B
(j) A ∈B
(k) {A} ∈B
(l) {{2}} ⊆B
(m) {1‚ 2} ∈B
(n) {{1‚ 2}} ⊆B
➎Let U = {0‚ 1‚ 2‚ 3‚ 4‚ 5‚ 6‚ 7‚ 8‚ 9} be the universal set, A = {1‚ 2‚ 4‚ 7} and B = {0‚ 2‚ 5‚ 6‚ 7‚ 9}.
Determine:
(a) A ∩B
(b) A ∪B
(c) A −B
(d) B −A
(e) A −(A −B)
(f) B −(A −B)
(g) B′
(h) (A ∩B)′
(i) A ∩B′
(j) (A ∪B)′
(k) (A ∪B)′ −(B −A)′
➏Let A = {0}, B = {0‚ A} and C = {0‚ {0}‚ {A}}. Determine:
(a) A ∩B
(b) A ∪B
(c) B −A
(d) A ∩(B ∪C)
(e) (B ∪C) −A
(f) (A ∩B) ∪(A ∩C)
(g) (C −B) −A
(h) A ∩(C −A)
➐If A = {1‚ 2‚ 3‚ 4} and B = {0‚ 1}, list the elements of A × B and of B × A.
➑If C = {a‚ b}, D = {𝛼‚ 𝛽‚ 𝛾‚ 𝛿‚ 𝜃} and E = {a‚ c‚ d}, how many elements does each of the follow-
ing sets have?
(a) C × D × E
(b) C × (D ∩E)
(c) D × (C ∩E)
(d) D ∩(C × E)
(e) (C ∪D) × (C ×
E)
(f) (C × E) ∩(E ×
C)
➒Which of the following relations are graphs of functions?
(a) {(a‚ b) ∣a‚ b ∈ℝand b = a2}
(b) {(a‚ b) ∣a‚ b ∈ℝand a = b2}
(c) {(a‚ b‚ c) ∣a‚ b‚ c ∈ℤand c divides a × b without remainder}
(d) {(x‚ y) ∣x and y are humans and y is a parent of x}
(e) {(x‚ y) ∣x and y are humans and y is the mother of x}
➓Prove Proposition 1.2.1: two ordered pairs (a1‚ a2) and (b1‚ b2) (seen as special sets as in Def-
inition 1.2.1) are equal if and only if a1 = b1 and a2 = b2.
11 Generalize Definition 1.2.1 to a formal set-theoretic definition of an ordered n-tuple.

Preliminaries
9
1.2.
Basics of logical connectives and expressions
Here we only provide a compendium of basic logical symbols and notation, commonly used in
mathematics. We will not discuss here the underlying concepts of logical languages, semantics
and deduction; these will be presented in a detailed and systematic way in the chapters on
logic, Chapters 3 and 4.
1.2.1.
Propositions, logical connectives, truth tables, tautologies
Propositions
The basic concept of propositional logic is the proposition. A proposition is a sentence that
can be assigned a truth value: true or false.
Some simple examples are:
• The Sun is hot.
• The Earth is made of cheese.
• 2 plus 2 equals 22.
• The 999-th decimal digit of the number 𝜋is 9.
Here are some sentences that are not propositions (why?):
• Are you bored?
• Please, don’t go away!
• She loves him.
• x is an integer.
• This sentence is false.
Propositional logical connectives
The propositions above are very simple. They have no logical structure, so we call them primi-
tive propositions. From primitive propositions one can form compound ones by using logical
connectives. The most commonly used connectives are:
• not, called negation, denoted by ¬;
• and, called conjunction, denoted by ∧(or sometimes, by &);
• or, called disjunction, denoted by ∨;
• if…then…, called implication, or conditional, denoted by →;
• … if and only if … , called biconditional, denoted by ↔.
Remark 1 It is usually not grammatically correct to read compound propositions by simply inserting
the names of the logical connectives in between the primitive components. A typical problem arises with
the negation: one does not say “Not the earth is square”. A uniform way to get round that difficulty
and to negate a proposition P is to say “It is not the case that P”.

10
Logic and Discrete Mathematics: A Concise Introduction
Thus, given the propositions
“Two plus two equals five” and “The Sun is hot”
we can form the propositions
• “It is not the case that two plus two equals five.”
• “Two plus two equals five and the Sun is hot.”
• “Two plus two equals five or the Sun is hot.”
• “If two plus two equals five then the Sun is hot.”
• “Two plus two equals five if and only if the Sun is hot.”
Example 1.2.1
Here is a more involved example. Suppose Mary is a particular person, about whom it is
known whether she is clever, lazy, and whether she likes logic. Then, we can consider the
following sentences as propositions:
“Mary is clever”, “Mary is lazy” and “Mary likes logic.”
From these, we can compose a proposition (smoothed out a bit), such as
“Mary is not clever or if she likes logic then she is clever and not lazy.”
Truth tables
How about the truth value of a compound proposition? It can be calculated from the truth
values of the components (in much the same way as we can calculate the value of the algebraic
expression A × (B −C) + B∕A as soon as we know the values of A‚ B‚ C) by following the rules
of “propositional arithmetic”:
• The proposition ¬A is true if and only if the proposition A is false.
• The proposition A ∧B is true if and only if both A and B are true.
• The proposition A ∨B is true if and only if either of A or B (possibly both) is true.
• The proposition A →B is true if and only if A is false or B is true, i.e. if the truth of A implies
the truth of B.
• The proposition A ↔B is true if and only if A and B have the same truth values.
We can systematize these rules in kinds of “multiplication tables”. For that purpose, and to
make it easier for symbolic (i.e. mathematical) manipulations, we introduce a special notation
for the two truth values by denoting the value true by T and the value false by F. Another
common notation, particularly used in computer science, is to denote true by 𝟏and false
by 𝟎.

Preliminaries
11
Now the rules of the “propositional arithmetic” can be tabulated by means of the following
truth tables (p and q below stand for arbitrary propositions):
p
¬p
T
F
F
T
p
q
p ∧q
p ∨q
p →q
p ↔q
T
T
T
T
T
T
T
F
F
T
F
F
F
T
F
T
T
F
F
F
F
F
T
T
Computing truth values of propositions
One can see from the truth tables that the truth value of a compound proposition does not depend
on the meaning of the component propositions, but only on their truth values. Therefore, to check
the truth of such a proposition we merely need to replace all component propositions by their
respective truth values and then ‘calculate’ the truth of the whole proposition, using the truth
tables of the logical connectives. Thus,
• “It is not the case that two plus two equals five” is true;
• “Two plus two equals five and the Sun is hot” is false;
• “Two plus two equals five or the Sun is hot” is true;
• “If two plus two equals five, then the Sun is hot” is true (even though it does not make much
sense).
Returning to Example 1.2.1, suppose we know that
“Mary is clever” is true,
“Mary is lazy” is false,
“Mary likes logic” is true.
Then the truth value of the compound proposition
“Mary is not clever or if she likes logic, then she is clever and not lazy”
can be determined just as easily. However, in order to do so, we first have to analyze the syntac-
tic structure of the proposition, i.e. to determine how it has been composed or in what order the
logical connectives occurring therein have been applied. With algebraic expressions such as
A × (B −C) + B∕A that analysis is a little easier thanks to the use of parentheses and the estab-
lished priority order amongst the arithmetic operations. Let us also make use of parentheses
and rewrite the sentence in the way we (presumably) all understand it:
“(Mary is not clever) or (if (she likes logic), then ((she is clever) and (not lazy))).”
The structure of the sentence should be clear now. We can, however, go one step further
and make it look exactly like an algebraic expression by using letters to denote the occurring

12
Logic and Discrete Mathematics: A Concise Introduction
Table 1.1 Logical connectives paired
with set theoretic operations
Logical symbol
Set-theoretic symbol
∧
∩
∨
∪
¬
′
primitive propositions. Let us, for instance, denote
“Mary is clever” by A,
“Mary is lazy” by B,
“Mary likes logic” by C.
Now our compound proposition can be neatly rewritten as
(¬A) ∨(C →(A ∧¬B)).
The last step is to calculate the truth value. Here we make use of our observation above
and simply replace the primitive propositions A‚ B and C by their truth values and do the
formal calculation following the truth tables step by step:
(¬T) ∨(T →(T ∧¬F)) = F ∨(T →(T ∧T)) = F ∨(T →T) = F ∨T = T.
A note on the relation between logic and set theory
The astute reader would have noticed a close connection between basic, “propositional”
logical connectives and their properties, studied further in Chapter 3, on the one hand, and
the basic set theoretic operations and their properties, on the other. To explore this connection
fully would lead us far beyond the scope of this book, but a few comments are nevertheless
in order. Firstly, we can compile something like a “translation manual” of the symbols, as
depicted in Table 1.1.
Using this table, one can translate any proposition into a set-theoretic expression (by
regarding the primitive propositions as names of sets) and conversely. For example, the set
theoretic translation of the propositional A ∨¬A would be A ∪A′′, with A regarded as the
name of a set. How are these related? Intuitively, two propositions have the same logical
meaning precisely when their “set-theoretic translations” represent equal sets. We will give a
more precise answer in Chapter 3.
1.2.2.
Individual variables and quantifiers
Using only propositional logical connectives we cannot express very simple mathematical
statements such as
“x + 2 is greater than 5”,
“There exists y such that y2 = 2”,

Preliminaries
13
“For every real number x, if x is greater than 0, then there exists a real number y such
that y is less than 0 and y2 equals x”, etc.
Indeed, an expression such as “x + 2 is greater than 5” is not a proposition, for it can be true
or false depending on the choice of x. Neither is “There exists y such that y2 = 2” a proposition
until the range of possible values of y is specified: if y is an integer, then the statement is false,
but if y can be any real number, then it is true. As for the third sentence above, it is a proposition,
but its truth heavily depends on its internal logical structure and mathematical meaning of
all phrases involved, and those are not tractable on a propositional level. All these sentences
are from the realm of first-order logic, often just called classical logic, which we study in
Chapter 4. Here we only introduce the basic symbols of first-order logic as they are widely
used in the mathematical literature, and will also be used in Section 2.4, before we study logic
itself.
Individual variables
Often in mathematics we deal with unknown or unspecified objects (individuals) from the
domain of discourse: integers, real numbers, geometric points, elements of abstract sets, etc.
In order to be able to reason and make statements about such objects, we use individual vari-
ables to denote them. For instance, talking about numbers, we use phrases like “Take a positive
integer n”, “For every real number x greater than
√
2 … ”, etc. In natural language instead of
variables we usually use pronouns or other syntactic constructions but that can often lead to
awkwardness or even ambiguity (e.g. “If a man owes money to another man then that man
hates the other man”). Therefore, the use of variables in mathematics is indispensable. We also
use variables as placeholders for the arguments of the various predicates and functions we deal
with. Usually, individual variables will be denoted by x‚ y‚ z‚ …, possibly with indices.
Quantifiers
In both mathematical discourse and in everyday speech, we often use special phrases used to
quantify over objects of our discourse, such as (note the use of individual variables here):
• “(for) every (objects) x”,
• “there is (an object) x such that ”,
• “for most (objects) x”,
• “there are at least 5 (objects) x such that”,
• “there are more (objects) x than y such that ”, etc.
Such phrases are called quantifiers. The first two of those listed above are particularly
important and most commonly used in mathematics, and many others can be expressed by
means of them, so they are given special names and notation:
– The quantifier “for every ” is called universal quantifier, denoted by ∀.
– The quantifier “there exists ” is called existential quantifier, denoted by ∃.

14
Logic and Discrete Mathematics: A Concise Introduction
Besides the phrases above, the universal quantifier is usually represented by “all”, “for
all” and “every” while the existential quantifier can appear as “there is”, “some” and “for some”,
particularly, in a nonmathematical discourse.
Mathematical terms and formulae
Typically, we build mathematical expressions by using individual variables and constants
(names) for specific individuals (e.g. the numbers 0,−5,
√
2, 𝜋) and functions and relations
that we apply to these. We also use auxiliary symbols, such as parentheses, and logical sym-
bols, including the propositional connectives introduced earlier, as well as equality = and
quantifiers. Using all these components and following certain syntactic rules, we can com-
pose formal expressions that allow us to symbolically represent mathematical statements, to
reason about them and to prove them in precise, well-structured and logically correct ways,
which we will present and discuss in detail in Chapter 4.
There are two main types of expressions used in mathematics:
1. Terms, used to denote objects, which we build from names and variables for such
objects, possibly by applying functions to them. Some examples of mathematical terms
are: 1, x, (x + 1), (x + 1)(x −2),
√
(x + 1)(y −z), sin(x + 𝜋∕2), etc.
2. Formulae, used to make statements about objects, by applying relations between
terms, and then composing more complex formulae from simpler ones by applying
logical symbols. Here are some examples of formulae used to make statements about
numbers:
• x > 0, saying that (the value of) x is greater than 0. This could be true or false, depend-
ing on the actual value ofx.
• x × y = y × x, saying that multiplication is commutative. This is true for all real values
of x and y but not necessarily true if x and y denote, say, matrices.
• x < y →¬y < x, saying that if (the value of) x is less than (the value of) y then it is
not the case that y is less than x. Again, this is true for all numerical values of x and
y, because of the standard meaning of < and >.
• ∃x(x < 0), saying that there is a (value of) x that is less than 0. This is true if x is an
integer or real, but false if x represents a natural number.
• ∀x∀x(x < y →¬y < x), saying that for all (values of) x and y, if x is less than y then it
is not the case that y is less than x. As noted above, this is true if x and y represent
natural numbers, because of the meaning of < and > on real numbers.
• ∀x(x > 0 →∃y(y > 0 ∧y < x)), saying that for every positive (value of) x there is a
lesser, still positive (value of) y. This is true if x and y represent rational or real num-
bers, but false if they represent integers, when x is taken as 1.
At this stage it is sufficient to understand the meaning of such mathematical expressions
and statements informally and to be able to use logical symbols to make such simple state-
ments. In Chapter 4 these skills will be lifted to a higher level and be made much more precise.

Preliminaries
15
1.2.3.
Exercises
➊Which of the following are propositions?
(a) 23 + 32 = 17
(b) 23 + 32 = 71
(c) 23 + 32 = x
(d) Will you marry me?
(e) John married on January 1st, 1999.
(f) Mary is not happy.
(g) I told her about John.
(h) If John loves Lisa then Mary is not happy.
➋If A and B are true propositions and C and D are false ones, determine the truth values of
the following compound propositions:
(a) A ∧(¬B ∨C)
(b) ¬(¬A ∨D) →¬B
(c) ¬(¬D ∧(B →¬A))
(d) (C →A) →D
(e) C →(A →D)
(f) ¬(C →A) ∨(C →D)
(g) (A →¬A) ∨(C ↔¬B)
➌Write each of the following composite propositions in a symbolic form by identifying its
atomic propositions and logical structure. Then determine its truth value.
(a) The Sun is hot and if the Earth is larger than Jupiter then there is life on Jupiter.
(b) If the Sun rotates around the Earth or the Earth rotates around the Moon then the Sun
rotates around the Moon.
(c) The Moon does not rotate around the Earth if the Sun does not rotates around the Earth
and the Earth does not rotate around the Moon.
(d) The Earth rotate around itself only if the Sun rotates around the Earth or the Moon does
not rotate around the Earth.
(e) The Earth rotates around itself if and only if the Sun does not rotate around itself or the
Moon does not rotate around itself.
➍Determine the truth value of the proposition A in each of the following cases:
(a) B and B →A are true.
(b) A →B is true and B is false.

16
Logic and Discrete Mathematics: A Concise Introduction
(c) ¬B and A ∨B are true.
(d) Each of B →¬A, ¬B →¬C and C is true.
(e) Each of ¬C ∧B, C →(A ∨B) and ¬(A ∨C) →C is true.
(Hint: consider cases for the truth of B and C.)
➎Translate the following formulae into English and determine which of them are true propo-
sitions in the set of natural numbers and which are true propositions in the set of real
numbers .
(a) ¬∀x(x ≠0)
(b) ∀x(x3 ≥x)
(c) ∀x(x = x2 →x > 𝟎)
(d) ∃x(x = x2 ∧x < 𝟎)
(e) ∀x(x > 𝟎→x2 > x)
(f) ∀x(x = 𝟎∨¬x + x = x)
(g) ∀x∀y(x > y ∨y > x)
(h) ∀x∃y(x > y2)
(i) ∀x∃y(x > y2 ∨y > 𝟎)
(j) ∀x(x ≥𝟎→∃y(y > 𝟎∧x = y2))
(k) ∀x∃y(x > y →x > y2)
(l) ∀x∃y(¬x = y →x > y2)
(m) ∃x∀y(x > y)
(n) ∃x∀y(x + y = x)
(o) ∃x∀y(x + y = y)
(p) ∃x∀y(x > y ∨−x > y)
(q) ∃x∀y(x > y ∨¬x > y)
(r) ∃x∀y(y > x →y2 > x)
(s) ∃x∀y(x > y →x > y2)
(t) ∃x∃y(xy = x + y)
(u) ∀x∀y(x > y →∃z(x > z ∧z > y)

Preliminaries
17
1.3.
Mathematical induction
Mathematical induction is a method for proving statements about all natural numbers. Recall
that we assume the set of natural numbers to be ℕ= {0‚ 1‚ 2‚ …}. Here is the most common
version of the Principle of Mathematical Induction (PMI):
Theorem 1.3.1 (Principle of Mathematical Induction) Suppose that some property P of natural
numbers holds for 0 and whenever P holds for some natural number k, then it also holds for k + 1. Then
P holds for every natural number.
We write P(n) to say that the property P holds for the number n. Thus, using the PMI to
prove a statement of the type “P(n) holds for every natural number n” requires proving the
following two steps:
1. Base step: P(0) holds.
2. Induction step: for any k ∈ℕ, if P(k) holds, then P(k + 1) also holds.
We illustrate the use of the PMI with the following example.
Example 1.3.2
Prove that for every natural number n,
0 + 1 + · · · + n = n(n + 1)
2
.
(1.1)
Proof: Let us denote the statement in Equation (1.1) by P(n). First, we have to verify the Base
step, i.e. to show that P(0) is true. Here:
0 = 0(0 + 1)
2
.
Then, to verify the Induction step, suppose that P(k) is true for some k ≥0. This assump-
tion is called the Inductive Hypothesis (IH). We now have to show that P(k + 1) is also true.
Here we go:
0 + 1 + · · · + k + (k + 1) = (0 + 1 + · · · + k) + (k + 1)
= k(k + 1)
2
+ (k + 1)
= k(k + 1) + 2(k + 1)
2
= (k + 1)((k + 1) + 1)
2
‚
where we use the Inductive Hypothesis to justify the second equality.
Thus, by the Principle of Mathematical Induction, we conclude that P(n) holds for every
natural number n.

18
Logic and Discrete Mathematics: A Concise Introduction
Sometimes, we only need to prove that a property holds for all natural numbers greater
than some m ≥0. Then the PMI works just as well, by starting with a Base step P(m) and
applying the Induction step only to natural numbers k ≥m.
Example 1.3.3
Prove that n2 ≤2n for every natural number n ≥4.
Proof: Let P(n) be the statement n2 ≤2n.
Base step. Prove that P(4) is true:
42 = 16 ≤16 = 24
Induction step. Assume that P(k) is true for some k ≥4 (the Inductive Hypothesis (IH)), i.e.
k2 ≤2k.
Now we have to prove that (k + 1)2 ≤2(k+1). We begin with:
(k + 1)2 = k2 + 2k + 1 = k
(
k + 2 + 1
k
)
Our goal is to rewrite this equation so that we can use the IH. Note that 1∕k < 1 since k ≥4.
Therefore
k
(
k + 2 + 1
k
)
≤k(k + 2 + 1) = k(k + 3) ≤k(k + k) = 2k2
We can now use the IH to get
2k2 ≤2.2k = 2(k+1)
Therefore we have that (k + 1)2 ≤2(k+1), as required.
By the PMI, we conclude that n2 ≤2n for all natural numbers n ≥4.
Later, in the beginning of the chapter on number theory (Chapter 5), we will extend and
generalize the Principle of Mathematical Induction.
1.3.1.
Exercises
➊Prove, by using the PMI, that n2 + n is even for all natural numbers n.
➋Prove that 2n < n! for all natural numbers n ≥4.
➌Show that for every natural number n ≥1, the power set of the set {1‚ 2‚ 3‚ …‚ n} has 2n
elements.

Preliminaries
19
Paradoxes
A paradox is a statement or an argument that is an apparent contradiction, either with well-known
and accepted truths or simply with itself. Unlike a fallacy, a paradox is not due to an incorrect
reasoning, but it could be based on a play of words, or on using self-referential statements, or on
a very subtle ambiguity in the assumptions or concepts involved. Some set-theoretic paradoxes,
however, such as Russell’s paradox (see the box at the end of Section 2.1 in Chapter 2), lead to deeper
foundational issues of mathematics.
Probably the best-known logical Paradox of the Liar is the person saying “I am lying now”, i.e.
“This sentence is false”. If the sentence is true, then it truly claims that it is false and, if it is false,
then it falsely states so; hence it must be true.
There are may variations of this paradox, one of them being Jourdain’s card paradox. This is a
card, on both sides of which there is a written statement. The statement on one side of the card says
“The sentence on the other side of this card is true” and the one on the other side says “The sentence
on the other side of this card is false”. Think of each of these as to whether it is true or false.
We will see more on logical fallacies and set theory paradoxes further. Here we offer an assort-
ment of some simple mathematical fallacies and genuine paradoxes.
The heap paradox.
How many grains of wheat, put together, form a heap? A hundred, a million
… ? Well, neither! Indeed, one grain is certainly not a heap and, if k grains do not form a heap, adding
just one more will not make a heap either. Therefore, by induction, for every n ∈ℕ, a collection of
n grains is not a heap. What is wrong with this argument?
All horses have the same colour.
Here is another proof by induction, of the claim that all horses
have the same colour. Indeed, there are only finitely many horses, so it suffices to prove that for every
n ∈ℕ, in any set of n horses they all have the same colour. When n = 1 this is certainly true. Now,
suppose this claim is true for n and let us take any set of n + 1 horses, say H1‚ H2‚ …‚ Hn+1. Then,
by the inductive hypothesis, the first n of them, H1‚ H2‚ …‚ Hn, have the same colour, in particular
H1‚ H2 have the same colour and the last n of them, H2‚ …‚ Hn+1, have the same colour. Therefore,
they all have the same colour. Do you agree? Why?
All natural numbers are interesting.
Surely, there are many interesting natural numbers, for
instance 0 is the first natural number, 1 is interesting for being the first positive natural number,
2 is the first prime number, etc. However, are there any natural numbers that are not interesting?
Suppose there are. Then, there is a least number amongst them, say k. However, then k is the least
non interesting natural number, which is certainly quite an interesting property, isn’t it? Therefore, k
is in fact interesting, which is a contradiction. Therefore, all natural numbers are interesting!
Berry paradox.
Every natural number can be defined in English with sufficiently many words.
However, if we bound the number of words that can be used, then only finitely many natural num-
bers can be defined, so there will be ones that cannot be defined with that many words. Therefore,
there must be a smallest so undefinable natural number. Now, consider the following sentence: “The
least natural number that is not deﬁnable in English with less than twenty words.” There is a uniquely
determined natural number that satisfies this description, so it is a definition in English, correct?
Well, count how many words it uses.

2
Sets, Relations, Orders
2.1.
Set inclusions and equalities
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.2.
Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.3.
Binary relations and operations on them
. . . . . . . . . . . . . . . . . . . . . . .
35
2.4.
Special binary relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
2.5.
Equivalence relations and partitions . . . . . . . . . . . . . . . . . . . . . . . . . .
51
2.6.
Ordered sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
2.7.
An introduction to cardinality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
2.8.
Isomorphisms of ordered sets. Ordinal numbers . . . . . . . . . . . . . . . . . . .
75
2.9.
Application: relational databases
. . . . . . . . . . . . . . . . . . . . . . . . . . .
80
Set theory is one of the most fundamental parts of modern mathematics. Every mathematical
object you are likely to encounter is built (or can be built) from sets using set theoretic oper-
ations. As we saw in Chapter 1, even the functions and relations themselves are sets, namely
subsets of appropriate Cartesian powers of the domain, satisfying certain conditions. In fact,
all mathematical objects that appear in this book – even natural numbers – can be based on sets.
For instance, graphs studied in Chapter 7 are just sets together with certain binary relations.
The systematic theory of sets was initiated by the German mathematician Georg Cantor
(see the box at the end of Section 2.2) in the second half of the 19th century. Today set theory
is a fully developed, fundamental and very important branch of mathematics. Because sets
are such basic mathematical objects, no precise and formal explicit mathematical definition
of a set can be given, but only an intuitive idea (which everybody has to a certain extent). Of
course we could try to define a set as a collection of objects, but then we would have to define
what we mean by a collection, and that definition would again involve terms that need to
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

Sets, Relations, Orders
21
be defined, leading to an infinite regress. It is important to realize that in the foundations of
mathematics we cannot formally define every term that we use without falling into circularity
or an infinitely regressing chain of definitions.
2.1.
Set inclusions and equalities
In Chapter 1 we gave a quick review of the basic notions relating to sets, including member-
ship, containment and equality of sets, the empty set, set-builder notation, as well as the basic
operations on sets including intersection, union, difference, complement, and products. We
advise the reader who needs to refresh his or her knowledge of these concepts to turn back to
Chapter 1.
The emphasis in this chapter, besides learning the basics of the theory of sets and relations,
will be on writing correct and mathematically rigorous proofs – a very important and useful
skill to master, for which we will develop more systematic methods in the chapters on logic,
Chapters 3 and 4. Many of the properties of sets proved here might seems quite obvious, yet
writing precise proofs for them might still be challenging.
Let us first take a closer look at the basic operations on sets and the fundamental identities
that hold of these. The key fact that we will use to prove identities between sets is the following:
Proposition 2.1.1 For all sets A and B, A = B if and only if A ⊆B and B ⊆A.
Proof: The proof is a nice and simple exercise on precise mathematical reasoning, so we will
do it in full detail.
We have to prove an equivalence: “ … if and only if … ”. We do that by proving the impli-
cations in both directions.
1. To prove the implication “If A = B, then A ⊆B and B ⊆A” we assume the premise “A =
B” and try to reach the conclusion “A ⊆B and B ⊆A”. That conclusion is a conjunction,
so we have to prove both “A ⊆B” and “B ⊆A”. To prove that A ⊆B, by definition we
must show that every element of A is an element of B. Therefore, let x be any (arbitrary)
element of A. Then, because A = B, we also have x ∈B. Since x ∈A was arbitrary, we
conclude that A ⊆B.
Likewise, to show that B ⊆A, let x be any element of B. Because A = B, it follows that
x ∈A. Therefore, since x ∈B was arbitrary, we conclude that B ⊆A.
2. To prove “If A ⊆B and B ⊆A, then A = B”, again we assume the premise “A ⊆B and
B ⊆A” and try to deduce “A = B”. By the definition of equality of sets, we have to show
that A and B have exactly the same elements. Let x be an arbitrary element. If x ∈A, then
since A ⊆B, we have x ∈B. Similarly, if x ∈B, then since B ⊆A, we have x ∈A. Thus we
have shown that, for any x, it holds that x ∈A iff x ∈B, i.e. that A and B have the same
elements and thus A = B.
As a corollary, we note that there is only one empty set.1
Another often used fact is that the empty set is a subset of every set.
1 A more orderly minded reader may object here that the empty sent of oranges just cannot be the same as the
empty set of ideas, or the empty set of sets. However, they are, essentially, by definition.

22
Logic and Discrete Mathematics: A Concise Introduction
Proposition 2.1.2 For every set A, it holds that ∅⊆A.
Proof: By definition of inclusion we need to show that every element of ∅is an element of A.
However, because ∅has no elements, there is nothing to do, so we are done.2
2.1.1.
Properties of the set theoretic operations
Each of the following propositions lists a number of identities relating to a particular set the-
oretic operation. We only prove some of these identities and leave the proofs of the rest as
exercises for the reader.
Proposition 2.1.3 (Properties of the intersection) For any sets A‚ B‚ C and X it holds that:
1. A ∩∅= ∅
2. A ∩A = A
3. A ∩B = B ∩A
4. A ∩(B ∩C) = (A ∩B) ∩C
5. A ⊆B if and only if A ∩B = A
6. A ∩B ⊆A and A ∩B ⊆B
7. If X ⊆A and X ⊆B, then X ⊆A ∩B
Proof: We will prove properties 1 and 7.
1. To prove A ∩∅= ∅we proceed by contradiction: suppose A ∩∅is nonempty and take
any element of x of A ∩∅. Then, in particular, x ∈∅, which is impossible. Thus, A ∩∅is
the empty set.
7. Suppose X ⊆A and X ⊆B; we need to show that X ⊆A ∩B. To that end, suppose that
x ∈X. Since X ⊆A we have x ∈A, and since X ⊆B we also have x ∈B. Thus, by the
definition of intersection, x ∈A ∩B.
Proposition 2.1.4 (Properties of the union) For any sets A‚ B‚ C and X it holds that:
1. A ∪∅= A
2. A ∪A = A
3. A ∪B = B ∪A
4. A ∪(B ∪C) = (A ∪B) ∪C
5. If A ⊆B if and only if A ∪B = B
6. A ⊆A ∪B and B ⊆A ∪B
7. If A ⊆X and B ⊆X, then A ∪B ⊆X
Proof: We will prove property 1. To prove that A ∪∅⊆A, suppose that x ∈A ∪∅. Hence x ∈A
or x ∈∅. However, since it cannot be the case that x ∈∅, it must be the case that x ∈A.
2 Another way of stating this is that, because ∅has no elements, it holds vacuously that every element of ∅is an
element of A.

Sets, Relations, Orders
23
A − B
B − A
A   B
A
B
Figure 2.1: Properties of set theoretic difference
For the inclusion A ⊆A ∪∅, suppose that x ∈A. Then x ∈A or x ∈∅, so x ∈A ∪∅.
The fourth clauses of Propositions 2.1.3 and 2.1.4 above tell us that intersection and union
of sets are associative operations. Intuitively this means that no matter in which order we
take the union (respectively, intersection) of three or more sets, the result will be the same, so
we can write simply A ∩B ∩C for A ∩(B ∩C) or (A ∩B) ∩C, and also A ∪B ∪C for A ∪(B ∪C)
or (A ∪B) ∪C. This also suggests the following generalizations of the intersection and union
operations. Suppose that is a set of sets: we can think of ⊆𝒫(U) for some universal set U.
Then we write ⋂for the intersection of all members of , i.e. x ∈⋂iff x ∈X for every set
X ∈. Similarly, the union ⋃consists of all those elements belonging to at least one X ∈.
Example 2.1.5
Consider the set = {[a‚ ∞) ∣[a‚ ∞) ⊆ℝand a < 0} consisting of all intervals [a‚ ∞) of the
real line where a is negative. Then we claim ⋂is equal to the set [0‚ ∞) of all non-negative
real numbers. Indeed, [0‚ ∞) ⊆[a‚ ∞) for every negative real number a, so we have [0‚ ∞) ⊆
⋂X (by an extension of Proposition 2.1.3(7)). Conversely, if x ∉[0‚ ∞), then x < 0. Then x <
x∕2 < 0, so x ∉[x∕2‚ ∞). Now since [x∕2‚ ∞) ∈, we conclude that x ∉⋂.
Similarly, it is easy to see that ⋃= ℝ.
The difference of two sets is visualized by means of the Venn diagram in Figure 2.1 and
the following proposition lists some properties of the set theoretic difference.
Proposition 2.1.6 (Properties of set theoretic difference) For any sets A‚ B and C:
1. A −A = ∅
2. ∅−A = ∅
3. A −∅= A
4. A −B ⊆A
5. (A −B) ∩B = ∅
6. A −B = ∅if and only if A ⊆B

24
Logic and Discrete Mathematics: A Concise Introduction
7. (A −B) ∩(B −A) = ∅
8. (A −B) ∪B = A ∪B
9. A −(A ∩B) = A −B
10. A −(B ∩C) = (A −B) ∪(A −C)
11. A −(B ∪C) = (A −B) ∩(A −C)
12. A ∪B = (A −B) ∪(B −A) ∪(A ∩B)
Proof: We prove properties 1, 5 and 11.
1. Suppose that x ∈A −A. That means x ∈A and x ∉A, which is impossible. There can
therefore be no element x ∈A −A, i.e. A −A = ∅.
5. Suppose x ∈(A −B) ∩B. This means that x ∈(A −B) and x ∈B. However, x ∈(A −B)
means that x ∈A and x ∉B, so it cannot be the case that x ∈B, which is a contradiction.
We conclude that (A −B) ∩B has no elements, i.e. (A −B) ∩B = ∅.
11. We will prove both inclusions. To prove that A −(B ∪C) ⊆(A −B) ∩(A −C), suppose
that x ∈A −(B ∪C). Then x ∈A and x ∉(B ∪C), i.e. x ∈A but x ∉B and x ∉C. Then
x ∈A −B and x ∈A −C, i.e. x ∈(A −B) ∩(A −C).
For the inclusion (A −B) ∩(A −C) ⊆A −(B ∪C), suppose that x ∈(A −B) ∩(A −C).
This means that x ∈(A −B) and x ∈(A −C), i.e. x ∈A but x ∉B and x ∉C. Since x ∉B
and x ∉C we have x ∉(B ∪C). Combining these with x ∈A, we have x ∈A −(B ∪C).
Proposition 2.1.7 (Interaction between union and intersection) For all sets A, B and C the
following hold:
1. A ∩(B ∪C) = (A ∩B) ∪(A ∩C) (distributivity of ∩over ∪)
2. A ∪(B ∩C) = (A ∪B) ∩(A ∪C) (distributivity of ∪over ∩)
3. A ∩(A ∪B) = A (absorption)
4. A ∪(A ∩B) = A (absorption)
Proof: Properties 1 and 2 are illustrated in Figure 2.2 by means of Venn diagrams. We will prove
only property 1 and leave the proofs of the others as exercises. The proof goes through a chain
of “if and only ifs”:
x ∈A ∩(B ∪C)
iff x ∈A and x ∈(B ∪C)
iff x ∈A‚ and x ∈B or x ∈C
iff x ∈A and x ∈B‚ or x ∈A and x ∈C
iff x ∈A ∩B or x ∈A ∩C
iff x ∈(A ∩B) ∪(A ∩C)
Next we will consider the properties of powersets. Figure 2.3 shows a three-element set
and its powerset.

Sets, Relations, Orders
25
B
B
A
A
C
C
Figure 2.2: A ∩(B ∪C) = (A ∩B) ∪(A ∩C) and A ∪(B ∩C) = (A ∪B) ∩(A ∪C)
a
a
a
b
b
b
c
c
c
b   c
a   c
a   b
A
𝒫(X)
Figure 2.3: A three-element set and its powerset
Proposition 2.1.8 (Properties of the powerset) For any sets A, B and X:
1. A ∈𝒫(B) iff A ⊆B.
2. ∅∈𝒫(A).
3. A ∈𝒫(A).
4. If A ⊆B then 𝒫(A) ⊆𝒫(B).
5. If A ∈𝒫(X) then X −A ∈𝒫(X).
6. If A ∈𝒫(X) and B ∈𝒫(X) then A ∩B, A ∪B and A −B are in 𝒫(X).
7. If X has n elements then 𝒫(X) has 2n elements.
Proof: Properties 1, 2 and 3 are direct consequences of the definition of the powerset (see Section
1.1 in Chapter 1). We leave the proofs of items 4, 5 and 6 as exercises and only prove 7. In order
to construct a subset A of X, for each element of X we must decide whether it will be in A or
not, and these choices completely determine A. For each element of X there are therefore two
choices, “in” or “out”. Thus the number of ways to form the subset A is 2 × 2 × × · · · × 2
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏟
ntimes
= 2n.
(Counting techniques like this are extensively studied in Chapter 6; see especially Section 6.1.)
Proposition 2.1.8 implies that if U is a universal set, then ∪, ∩and ′ are operations
on (U). (Recall that we write A′ for U −A.) Thus, we obtain an algebraic structure
⟨𝒫(U); ∪‚ ∩‚ ′‚ ∅‚ U⟩, called the powerset Boolean algebra of U.

26
Logic and Discrete Mathematics: A Concise Introduction
Proposition 2.1.9 (Properties of the Cartesian product) For any sets A, B and C:
1. A × (B ∪C) = (A × B) ∪(A × C), (B ∪C) × A = (B × A) ∪(C × A)
2. A × (B ∩C) = (A × B) ∩(A × C), (B ∩C) × A = (B × A) ∩(C × A)
3. A × (B −C) = (A × B) −(A × C)
Proof: We prove the identity 1. For the inclusion A × (B ∪C) ⊆(A × B) ∪(A × C), suppose that
x ∈A × (B ∪C). Then x = (y‚ z) for some y ∈A and z ∈(B ∪C). Since z ∈(B ∪C), we have z ∈B
or z ∈C. Therefore (y‚ z) ∈A × B or (y‚ z) ∈A × C, and hence x = (y‚ z) ∈(A × B) ∪(A × C).
For the inclusion (A × B) ∪(A × C) ⊆A × (B ∪C) suppose that x = (y‚ z) ∈(A × B) ∪(A ×
C). Then (y‚ z) ∈(A × B) or (y‚ z) ∈(A × C). Thus y ∈A, while z ∈B or z ∈C. Thus y ∈A, while
z ∈B ∪C, and hence x = (y‚ z) ∈A × (B ∪C).
2.1.2.
Exercises
➊Prove that for all sets A, B, C and X it holds that:
(a) A ∩A = A
(b) A ∩B = B ∩A
(c) A ∩(B ∩C) = (A ∩B) ∩C
(d) A ∩B ⊆A and A ∩B ⊆B
(e) A ⊆B if and only if A ∩B = A
(f) A ∪A = A
(g) A ∪B = B ∪A
(h) A ∪(B ∪C) = (A ∪B) ∪C
(i) A ⊆A ∪B and B ⊆A ∪B
(j) If A ⊆B if and only if A ∪B = B
(k) If A ⊆X and B ⊆X, then A ∪B ⊆X
➋Prove that for all sets A, B and C it holds that:
(a) ∅−A = ∅
(b) A −∅= A
(c) A −B ⊆A
(d) A −B = ∅if and only if A ⊆B
(e) (A −B) ∩(B −A) = ∅
(f) (A −B) ∪B = A ∪B
(g) A −(A ∩B) = A −B
(h) A −(B ∩C) = (A −B) ∪(A −C)
(i) A ∪B = (A −B) ∪(B −A) ∪(A ∩B)
(j) A ∪(B ∩C) = (A ∪B) ∩(A ∪C)
(k) A ∩(A ∪B) = A
(l) A ∪(A ∩B) = A

Sets, Relations, Orders
27
➌Prove that for all sets A, B and X it holds that:
(a) If A ⊆B then 𝒫(A) ⊆𝒫(B).
(b) If A ∈𝒫(X) and B ∈𝒫(X) then A ∩B ∈𝒫(X), A ∪B ∈𝒫(X), A −B ∈𝒫(X), X −A ∈
𝒫(X).
➍Prove that for all sets A, B, and C it holds that:
(a) (B ∪C) × A = (B × A) ∪(C × A)
(b) A × (B ∩C) = (A × B) ∩(A × C)
(c) (B ∩C) × A = (B × A) ∩(C × A)
(d) A × (B −C) = (A × B) −(A × C).
Russell’s paradox
Elements of a set can be sets themselves, and their elements can be sets, etc. In the early times of set
theory, at the end of the 19th century, there were no restrictions as to what conceivable collections
could be regarded as sets. That, however, soon led to constructions of sets, the existence of which
brought contradictions. A famous example is the set defined by the prominent British philosopher
Bertrand Russell (see the box at the end of Section 4.3 in Chapter 4) in the beginning of the 20th
century. Russell considered the set , defined as follows:
is the set consisting of exactly those sets which are not elements of themselves.
Even though it might look strange, this set seems legitimate until one goes through the following
argument.
Since is a set, it either belongs to itself or not.
If it belongs to itself, then, by definition, it is not one of its elements, i.e. it does not belong
to itself.
But, if it does not belong to itself, then, again by definition, it must belong to itself.
Thus, belongs to itself if and only if it does not belong to itself.
This contradiction is known as Russell’s paradox. It arises from the very assumption that the set 
exists or, rather, that the conceivable collection can be regarded as a set. Russell’s and similar
paradoxes discovered around the beginning of the 20th century dealt a serious blow to the then
young and naive theory of sets and caused a crisis in the very foundations of mathematics and logic.
That crisis brought about the development of new philosophies of mathematics and initiated new
approaches to its foundations, the most popular of which became the axiomatic method, promoted by
the famous German mathematician David Hilbert (1862–1943) and his followers. In particular, an
axiomatic set theory (see the box at the end of Section 2.5) was systematically developed during the
20th century, the purpose of which was, among others, to avoid paradoxes by strictly prescribing
all permitted constructions of sets.

28
Logic and Discrete Mathematics: A Concise Introduction
2.2.
Functions
In Chapter 1 we mentioned that functions can be seen equivalently, either as mappings that
assign values to elements of a set or as special types of relations. In this section it will be
convenient for us to take the first view. We will therefore use the terms function and mapping
interchangeably.
2.2.1.
Functions and their inverses
Definition 2.2.1 A function (or mapping, or map) from a set A to a set B, denoted by
f ∶A →B‚
assigns to each element a ∈A a unique element f(a) ∈B. The element f(a) is called the value of a
under f, or also the image of a under f. If f(a) = b then a is called a pre-image of b under f.
The set A is called the domain of f, denoted A = dom(f), and B is called the co-domain, or the
target set, of f, denoted B = cod(f).
The notion of image can be generalized from elements to subsets of the domain as follows. For any
subset X ⊆A of the domain of f, the image of X under f is the set
f[X] = {f(a) ∣a ∈X}.
The image of the domain A under f, i.e. the set of all values of f,
f[A] = {f(a) ∣a ∈A}‚
is called the range, or image, of f, also denoted by rng(f).
Example 2.2.2
Figure 2.4 depicts a mapping f ∶A →B where A = {a‚ b‚ c‚ d}, B = {2‚ 3‚ 4‚ 5‚ 6} and f(a) = 2,
f(b) = 2, f(c) = 5, f(d) = 4 and f(e) = 6. In this example dom(f) = A, cod(f) = B and rng(f) =
{2‚ 4‚ 5‚ 6}.
B
f
A
b
a
c
d
e
2
3
4
5
6
Figure 2.4: A mapping f ∶A →B (see Example 2.2.2)

Sets, Relations, Orders
29
Example 2.2.3
Let sq ∶ℝ→ℝbe the function that takes a real number and squares it. We use the notation
sq ∶x →x2
to indicate that this is how sq, seen as a rule, works. Then dom(sq) = ℝ, cod(sq) = ℝand
rng(sq) = {y ∈ℝ∣0 ≤y}.
The addition function acts on pairs of real numbers, so we can see it as a function
add ∶ℝ× ℝ→ℝgiven by the rule add ∶(x1‚ x2) →x1 + x2. We have dom(add) = ℝ× ℝand
cod(add) = rng(add) = ℝ.
In the example above we could have chosen the non-negative reals as the co-domain of
the squaring function, which could have made it a function sq′ ∶ℝ→ℝ+
0 , where R+
0 = {x ∈
ℝ∣0 ≤x}. However, we usually identify (unless otherwise specified) two functions f and f ′
that have the same domain A, and for which f(a) = f ′(a) for every a ∈A, even though their
co-domains may be different.
Definition 2.2.4 (Equality of functions) Two functions f and g are equal if
1. dom(f) = dom(g),
2. cod(f) = cod(g) and
3. f(a) = g(a) for every a ∈dom(f).
Example 2.2.5
Let f ∶ℕ→ℤand g ∶ℕ→ℤbe functions such that
f ∶x →x2 −4
and
g ∶x →(x −2)(x + 2).
Now we have dom(f) = ℕ= dom(g) and cod(f) = ℤ= cod(g). Also, for every a ∈ℕwe have
f(a) = a2 −4 = (a −2)(a + 2) = g(a). Therefore, the conditions of Definition 2.2.4 are satisfied,
and we conclude that f = g.
As discussed in Chapter 1 we can also regard a function as a set of pairs, i.e. a special type
of relation. The following definition makes this more precise:
Definition 2.2.6 (Graph of a function) The graph of a function f ∶A →B is the set of pairs
{(a‚ f(a)) ∣a ∈A}.

30
Logic and Discrete Mathematics: A Concise Introduction
(a)
(b)
(c)
(d)
Figure 2.5: Four functions that are: (a) neither injective nor surjective; (b) injective but not surjective; (c) surjective but not
injective; (d) bijective.
Definition 2.2.7 Let X ⊆A and f ∶A →B be a mapping. The restriction of f to X is the mapping
f ∣X ∶X →B defined by
f ∣X(a) = f(a) for each a ∈X.
If g is a restriction of f, then f is called an extension of g.
Definition 2.2.8 A mapping f ∶A →B is (see Figure 2.5):
• injective, or into, if for every a1‚ a2 ∈A,
f(a1) = f(a2) implies a1 = a2;
• surjective, or onto, if
rng(f) = B.
• bijective, or one-to-one, if it is both injective and surjective.
Example 2.2.9
Neither the squaring function sq nor the addition function add from Example 2.2.3 is injec-
tive. For example, sq(2) = 4 = sq(−2) and add(3‚ 4) = 3 + 4 = 7 = 2 + 5 = add(2‚ 5). However,
the restriction sq∣ℝ+
0 of the squaring function to the non-negative real numbers is injective. The
addition function add is surjective. The cubing function cb ∶ℝ→ℝgiven by cb ∶x →x3 is
bijective.

Sets, Relations, Orders
31
Definition 2.2.10 Let f ∶A →B be injective. The inverse (mapping) of f is the mapping
f −1 ∶rng(f) →A‚
defined by
f −1(f(a)) = a for every a ∈A.
Proposition 2.2.11 For every bijective mapping f:
1. f −1 is a bijection.
2. (f −1)−1 = f.
Proof: We will prove property 1 and leave property 2 as an exercise. Since f is surjective,
we have rng(f) = B = dom(f −1). To prove that f −1 is injective, suppose that b1‚ b2 ∈B and that
f −1(b1) = f −1(b2). Since rng(f) = B, there are a1‚ a2 ∈A such that f(a1) = b1 and f(a2) = b2. Thus
a1 = f −1(f(a1)) = f −1(b1) = f −1(b2) = f −1(f(a2)) = a2. Therefore, since we now have a1 = a2, the
injectivity of f allows us to conclude that f(a1) = f(a2), and thus that b1 = b2, as desired.
To show that f −1 is surjective, suppose that a ∈A. We must show that there is a b ∈B such
that f −1(b) = a. Take f(a) ∈B: we then have f −1(f(a)) = a.
Hereafter we restrict the notion of inverse mappings to bijections only.
Example 2.2.12
The squaring function and addition functions, sq and add, from Example 2.2.3 are not injec-
tive, so neither has an inverse. If we were to restrict the domain and range of sq to the
non-negative real numbers to obtain a function sq′′ ∶ℝ+
0 →ℝ+
0 such that sq′′ ∶x →x2, this
function would be bijective, and its inverse would be given by (sq′′)−1x ∶→
√
x.
2.2.2.
Composition of mappings
Definition 2.2.13 If f ∶A →B and g ∶B →C then the composition of f and g is the mapping
gf ∶A →C
defined by
gf(a) = g(f(a)) for each a ∈A.
Sometimes we also denote the composition gf by f⚬g. The reason for swapping the posi-
tions of f and g in the alternative notation will become clear later.
Whenever we refer to a composition gf of two mappings f and g, we will assume that
rng(f) ⊆dom(g).

32
Logic and Discrete Mathematics: A Concise Introduction
Example 2.2.14
rng(add) = ℝ⊆dom(sq) = ℝ, so we can form the composition sq add, which would give
sq add(x‚ y) = sq(add(x‚ y)) = (x + y)2. Notice that rng(sq) ⊈dom(add) = ℝ× ℝso the com-
position add sq cannot be formed.
Proposition 2.2.15 Let f ∶A →B, g ∶B →C be any mappings (see Figure 2.6). Then:
1. If f and g are injective then gf is also injective.
2. If f and g are surjective then gf is also surjective.
3. In particular, the composition of bijections is a bijection.
4. If gf is injective then f is injective.
5. If gf is surjective then g is surjective.
Proof:
1. Suppose f and g are injective and that a1‚ a2 ∈A such that gf(a1) = gf(a2). We must show
that a1 = a2. Thus g(f(a1)) = g(f(a2)). However, since g is injective this means that f(a1) =
f(a2) which in turn means that a1 = a2 since f is injective.
2. Exercise.
3. Follows immediately from 1 and 2.
4. Exercise.
5. Suppose that gf is surjective and that c ∈C. We need to find a b ∈B such that g(b) = c. By
the surjectivity of gf there is an a ∈A such that gf(a) = c, i.e. g(f(a)) = c. Then, f(a) ∈B is
the desired element of B.
Proposition 2.2.16 Composition of mappings is associative, i.e. f(gh) = (fg)h, whenever either of these
is defined.
Proof: Exercise.
A
B
C
a
f
f (a)
g
g(f(a))
g f
Figure 2.6: The composition of two mappings f ∶A →B and g ∶B →C

Sets, Relations, Orders
33
Proposition 2.2.17 If f ∶A →B, g ∶B →C are bijective mappings then gf has an inverse, and par-
ticularly
(gf)−1 = f −1g−1.
Proof: By Proposition 2.2.15(3) gf is bijective and therefore we know that it has an inverse
(gf)−1. Clearly dom(f −1g−1) = C = dom((gf)−1) and rng(f −1g−1) = A = rng((gf)−1). We need
to show that f −1g−1(c) = (gf)−1(c) for all c ∈C. To this end let c ∈C arbitrarily. Then,
because gf is surjective, there is an a ∈A such that gf(a) = c. By definition of inverses
(gf)−1(c) = (gf)−1(gf(a)) = a. Now f −1g−1(c) = f −1g−1(gf(a)) = f −1g−1(g(f(a))) = f −1(g−1(g(f(a)))).
By the associativity of function composition (Proposition 2.2.16) the last expression is equal
to f −1((g−1g)(f(a))) = f −1((f(a)) = a.
Proposition 2.2.18 A mapping f is injective iff it has the following property: for every two mappings
g1 and g2 with dom(g1) = dom(g2) and cod(g1) = dom(f) = cod(g2), the following left cancellation
property holds:
if fg1 = fg2 then g1 = g2.
Proof: For the sake of definiteness, suppose that f ∶A →B. To prove the left-to-right impli-
cation suppose that f is injective and take any mappings g1 ∶C →A and g2 ∶C →A. Fur-
ther suppose that g1f = g2f. We must show that g1 = g2. Therefore, let c ∈C arbitrarily. Then
fg1(c) = fg2(c), i.e. f(g1(c)) = f(g2(c)). Since f is injective, it follows that g1(c) = g2(c).
To prove the converse we will proceed by contraposition, so suppose that f is not injective.
Then there are a1‚ a2 ∈A such that a1 ≠a2 but f(a1) = f(a2). We need to show that the left can-
cellation rule does not hold. For this it is sufficient to find two mappings g1 and g2 such that
fg1 = fg2 but g1 ≠g2. Let g1 ∶A →A and g2 ∶A →A be maps such that g1 is the identity map
on A, i.e. g1(a) = a for all a ∈A and g2(a) = a for all a ∈A −{a1‚ a2} but g(a1) = a2 and g(a2) = a1.
Then it is easy to check that fg1 = fg2, but g1 ≠g2.
Proposition 2.2.19 A mapping f is surjective iff it has the following property: for every two mappings
g1 and g2 with dom(g1) = dom(g2) = cod(f), the following right cancelation property holds:
ifg1f = g2f then g1 = g2.
Proof: Exercise.
2.2.3.
Exercises
➊
Let f ∶ℤ→ℝ, g ∶ℝ→ℝand h ∶ℝ× ℝ→ℝbe functions such that f ∶x →x∕3, g ∶x →x3
and h ∶(x‚ y) →x × y.
(a) Describe gf. Specifically, determine dom(gf) and rng(gf).
(b) Describe gh. Specifically, determine dom(gh) and rng(gh).
(c) Is gf = fg?

34
Logic and Discrete Mathematics: A Concise Introduction
(d) Can one form the composition hf?
(e) Can one form the composition fg?
➋
Find examples of well-known functions f1 ∶ℝ→ℝ, f2 ∶ℝ→ℝ, f3 ∶ℝ→ℝand f4 ∶ℝ→
ℝsuch that
(a) f1 is neither surjective nor injective.
(b) f2 is surjective but not injective.
(c) f3 is injective but not surjective.
(d) f4 is bijective.
➌
Give an example of two functions f ∶A →B and g ∶B →C such that gf is injective but g
is not injective.
➍
Give an example of two functions f ∶A →B and g ∶B →C such that gf is surjective but f
is not surjective.
➎
Let f ∶ℝ→ℝ, g ∶ℝ+ →ℝand h ∶ℝ× ℝ→ℝbe functions such that f ∶x →x + 2, g ∶x →
√
x and h ∶(x‚ y) →x∕y.
(a) What is cod(h)?
(b) Determine rng(f), rng(g) and rng(h).
(c) Determine which of f, g and h are injective.
(d) Determine which of f, g and h are surjective.
(e) Determine which of f, g and h are bijective.
➏
A fixed point of a function f ∶A →A is an element a ∈A such that f(a) = a.
(a) Which are the fixed points of the squaring function sq?
(b) Give an example of a function f ∶ℤ→ℤthat has no fixed points.
(c) Let abs ∶ℝ→ℝbe the function given by abs ∶x →|x|. How many fixed points that
does abs have?
➐∗
Prove that for every bijective mapping f, it holds that (f −1)−1 = f.
➑∗
Let f ∶A →B, g ∶B →C be any mappings. Show that
(a) If f and g are surjective then gf is also surjective.
(b) If gf is injective then f is injective.
➒∗
Let h ∶A →B, g ∶B →C and f ∶C →D be any mappings. Show that the f(gh) = (fg)h, i.e.
show that the composition of mappings is associative.
➓** Prove that a mapping f is surjective iff it has the following property: for every two map-
pings g1 and g2 with dom(g1) = dom(g2) = cod(f), the following right cancellation property
holds: ifg1f = g2f then g1 = g2.

Sets, Relations, Orders
35
Georg Cantor (1845–1918)
Georg Cantor is the founding father of set theory or, more specifi-
cally, the theory of infinite sets. The notion of infinity is a tricky topic
and very easily leads to paradoxes like those of Zeno of Elea (c. 490–c.
430 BC). Because of these dangers, mathematicians up to the time
of Cantor had preferred to work with “potential” infinities (e.g., for
every natural number there is a greater one) rather than actual “com-
pleted” infinities (e.g. the set of all natural numbers). In 1831 Gauss
said: “I protest against the use of on infinite magnitude as something
completed, which is never permissible in mathematics. Infinity is
merely a way of speaking, the true meaning being a limit [· · ·].” (Of
course, here Gauss was probably thinking not of an infinite set, but
rather of the use of infinity as a value in a calculation. Still, the quo-
tation captures the general suspicion in which infinity was viewed.)
Cantor was the first to embrace actual infinite sets, perform opera-
tions on them and compare them: something we do as a matter of routine in mathematics today.
Cantor was born in St Petersburg in Russia in 1845, the son of a prosperous merchant father
and an artistic mother. His father wanted him to become an engineer, but after it became clear that
he was temperamentally unsuited for this profession, he was allowed to study mathematics, first at
the University of Zurich and then the University of Berlin. In Berlin he was taught by some of the
leading mathematicians of the age, including Kummer, Weierstrass and Kronecker. Cantor’s first
paper on infinite sets was published shortly before his thirtieth birthday. The mathematical estab-
lishment of the day did not welcome his innovations: many mathematicians were openly hostile
towards it, especially Kronecker. However, as time went by, the immense value of his work was
increasingly recognized, so much so that in the early 1890s he was elected president of the Ger-
man Mathematical Society. He taught at the University of Halle in Germany from 1869 until his
retirement in 1913.
2.3.
Binary relations and operations on them
We already introduced the abstract notion of a relation in Chapter 1. Binary (or two-place)
relations are the most common relations in the mathematical practice, so in this section we
will be exploring them in some more detail.
2.3.1.
Binary relations
Definition 2.3.1 Given sets A and B, a binary relation between A and B is any subset of A × B. In
particular, a binary relation on a set A is any subset of A2 = A × A.
Let R ⊆A × B be a binary relation between sets A and B. If (a‚ b) ∈R, we will also write
aRb and say that a is R-related to b.

36
Logic and Discrete Mathematics: A Concise Introduction
Definition 2.3.2 Given sets A and B and a binary relation R ⊆A × B:
1. The domain of R is the set
dom(R) = {a ∈A ∣∃b ∈B(aRb)}.
2. The range of R is the set
rng(R) = {b ∈B ∣∃a ∈A(aRb)}.
More generally, given subsets X ⊆A and Y ⊆B, we define:
3. The direct image of X under R is the set
R[X] = {b ∈B ∣∃x ∈X(xRb)}.
4. The inverse image of Y under R is the set
R−1[Y] = {a ∈A ∣∃y ∈Y(aRy)}.
Notice that we have dom(R) = R−1[B] and rng(R) = R[A].
Example 2.3.3
On the set of ℤintegers the “less than” relation < is the set {(x‚ y) ∣x‚ y ∈ℤand x < y}. Its
domain and range are both equal to ℤ. The “less than or equal to” relation ≤is the set
{(x‚ y) ∣x‚ y ∈ℤand x ≤y} and also has both domain and range equal to ℤ.
The relation “properly divides” on the positive natural numbers ℕ+, which we will
denote by div, is given by {(x‚ y) ∣x‚ y ∈ℕ+ and (∃z ∈ℕ)(1 < z < y ∧x × z = y)}. The domain
of this relation is {2‚ 3‚ 4‚ 5‚ …} while its range is the set of all composite numbers. The direct
image div[{2}] of {2} under div is the set {4‚ 6‚ 8‚ 10‚ …} consisting of multiples of 2 greater
than or equal to 4, i.e. the set of positive natural numbers that can be properly divided by 2.
Also div−1[{385}] = {5‚ 7‚ 11‚ 35‚ 55‚ 77}, i.e. the set of proper factors of 385.
The (usual, nonstrict) divisibility relation on the non-zero integers ℤ−{0}, denoted by ∣,
is given by {(x‚ y) ∣x‚ y ∈ℤ−{0} and ∃z ∈ℤ(x × z = y)} (cf. Definition 5.2.1).
For a non-numerical example, consider the containment relation on the powerset of a set
U: {(X‚ Y) ∣X‚ Y ⊆U and X ⊆Y}. Here the domain and range are both equal to 𝒫(U).
Example 2.3.4
Here are some binary relations on the set of humans:
• ChildOf = {(a‚ b) ∣a and b are humans and b is a child of b}.
• ParentOf = {(a‚ b) ∣a and b are humans and a is a parent of b}.
• IsMarriedTo = {(a‚ b) ∣a and b are humans and a is married to b}.

Sets, Relations, Orders
37
Here are some other relations between humans and other things:
• OwnsDog = {(a‚ b) ∣a is a human and b is a dog and a owns b}.
• IsCitizenOf = {(a‚ b) ∣a is a human and b is a country and a is a citizen of b}.
• IsMemberOf = {(a‚ b) ∣a is a human and b is a club and a is a member of b}.
Since every human has (biological) parents, the domain of the relation ChildOf is the set
of all humans, while the range is the set of all humans who have children. The identification
of the domains and ranges of the other relations is left as an exercise.
Some special relations on a set A:
• The empty relation is just the empty set ∅and relates no element of A.
• The equality (identity, diagonal) relation
EA = {(a‚ a) ∣a ∈A}
relates every element of A only to itself.
• The universal relation A2 relates every element of A to every element of A.
We can also restrict the domain of a relation, just like that of a function:
Definition 2.3.5 If R is a binary relation on a set A and B ⊆A, then the restriction of R to B, denoted
R∣B, is the relation
R∣B = R ∩(B × B) = {(x‚ y) ∣(x‚ y) ∈R and x‚ y ∈B}.
In other words, the restriction of a relation R on a set A to a subset B of A is the relation we
get by throwing out of R those ordered pairs that have one or more coordinates that do not
belong to B. Equivalently, it is the relation obtained from R by keeping exactly those ordered
pairs in R that have both their coordinates in B.
Example 2.3.6
One could restrict the relation ≤on ℤ(Example 2.3.3) to any subset of ℤ, for example to the
set of odd integers or to the members of the interval from −3 to 121.
If we were to restrict the proper division relation div (Example 2.3.3) to the set of all
prime numbers in ℕ+ we would obtain the empty relation ∅, for no prime number properly
divides any prime number.
On the other hand, if we were to restrict the division relation ∣(Example 2.3.3) to the set
P of all prime numbers in ℕ+ we would obtain the relation
{(x‚ y) ∣x ∣y and x‚ y ∈P} = {(x‚ x) ∣x ∈P}.

38
Logic and Discrete Mathematics: A Concise Introduction
2.3.2.
Matrix and graphical representations of relations on finite sets
Binary relations on finite sets can be conveniently represented either graphically or by means
of matrices. A common way to represent a binary relation R on a finite set A graphically is
to draw nodes representing the elements of A on the page in some convenient configuration,
and then, for every two elements a‚ b ∈A, draw an arrow from the node representing a to the
node representing b if and only if aRb. For example, the proper divisibility relation div on the
set {2‚ 3‚ …‚ 10} can be represented as:
10
7
5
9
8
6
4
2
3
The nonstrict divisibility relation ∣on the set {2‚ 3‚ …‚ 10} is the same as the strict one,
except that each number also divides itself. This is reflected in the graphical representation by
the fact that each number now also has an arrow linking it to itself:
10
9
8
4
6
5
7
3
2
Another way of representing a binary relation on a finite set is by means of a matrix. If
the set has n elements this will be an n × n matrix with rows and columns corresponding to
the elements of the set. We then place a 1 in row i column j if iRj and a 0 otherwise. Thus, the
matrix representation of the proper divisibility relation div on the set {2‚ 3‚ …‚ 10}, graphically

Sets, Relations, Orders
39
represented above, will be the following:
2
3
4
5
6
7
8
9
10
2
3
4
5
6
7
8
9
10
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
0
1
0
1
0
1
0
1
0
0
0
0
1
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
The matrix representation of the relation ≤on the set {2‚ 3‚ …‚ 10} is
2
3
4
5
6
7
8
9
10
2
3
4
5
6
7
8
9
10
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜⎝
1
1
1
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
0
0
1
1
1
1
1
1
1
0
0
0
1
1
1
1
1
1
0
0
0
0
1
1
1
1
1
0
0
0
0
0
1
1
1
1
0
0
0
0
0
0
1
1
1
0
0
0
0
0
0
0
1
1
0
0
0
0
0
0
0
0
1
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟⎠
2.3.3.
Boolean operations on binary relations
Since binary relations are sets themselves, the set operations ∪‚ ∩‚ −also apply to them.
Besides, the complementation of a relation R ⊆A × B is defined as R′ = (A × B) −R.
Note that we can always assume that two relations are defined between the same sets
because if R1 ⊆A1 × B1 and R2 ⊆A2 × B2, then both R1 ⊆(A1 ∪A2) × (B1 ∪B2) and R2 ⊆(A1 ∪
A2) × (B1 ∪B2).
Example 2.3.7
Consider again the relations <, ≤and div from Example 2.3.3. Then < ∪≤=≤, < ∩≤= <,
<′ = ℤ2−<=≥and ≤′ = ℤ2−≤=>. Also, div ∪<=< and div ∩<= div.
Example 2.3.8
Consider again the relation from Example 2.3.4. Unless there are people who are married
to their parents, it should hold that ChildOf ∩IsMarriedTo = ∅. Also, unless some dogs are
clubs, OwnsDog ∩IsMemberOf = ∅. The relation (IsCitizenOf)′ relates every person to all
those countries of which (s)he is not a citizen.

40
Logic and Discrete Mathematics: A Concise Introduction
Example 2.3.9
Let F denote the sets of all female humans, D be the set of all Dachshunds, and let c denote the
Rotary Club. Then ParentOf−1[F] is the set of all people with a female child, ParentOf[F] is
the set all humans (since everyone has a mother) and IsMemberOf−1[{c}] ∩OwnsDog−1[D]
is the set of all members of the Rotary Club who own a Dachshund.
Proposition 2.3.10 For any relations R‚ S ⊆A × B the following hold:
1. dom(R ∪S) = dom(R) ∪dom(S)
2. rng(R ∪S) = rng(R) ∪rng(S)
3. dom(R ∩S) ⊆dom(R) ∩dom(S)
4. rng(R ∩S) ⊆rng(R) ∩rng(S)
Proof: We will prove property 1. For the sake of the inclusion dom(R ∪S) ⊆dom(R) ∪dom(S),
suppose that a ∈dom(R ∪S), i.e. there exists b ∈B such that (a‚ b) ∈R ∪S. However, then
(a‚ b) ∈R or (a‚ b) ∈S, i.e. a ∈dom(R) or a ∈dom(S), so a ∈dom(R) ∪dom(S).
For the converse inclusion, suppose that a ∈dom(R) ∪dom(S), i.e. a ∈dom(R) or
a ∈dom(S), so there is a b ∈B such that (a‚ b) ∈R or (a‚ b) ∈S. However, then (a‚ b) ∈R ∪S
and hence a ∈dom(R ∪S).
Example 2.3.11
The graphical representation of the relation ∣on the set {2‚ 3‚ …‚ 10} was given above. Now
consider the relation ∣′ ∩≤on the set {2‚ 3‚ …‚ 10}. Here is the graphical representation of this
relation:
10
8
9
6
5
7
4
2
3
In effect, we have exactly those arrows linking smaller to larger numbers and that were
not in the graphical representation of ∣.

Sets, Relations, Orders
41
2.3.4.
Inverse and composition of relations
The inverse of a binary relation R is the relation obtained by swapping the components in each
ordered pair in R. Formally:
Definition 2.3.12 Let R ⊆A × B. The inverse of R is the relation R−1 ⊆B × A, defined as
R−1 = {(b‚ a) ∣(a‚ b) ∈R}.
Thus, we have aRb iff bR−1a.
Example 2.3.13
Let us consider the inverses of the relations from Example 2.3.3. Here we have <−1 =>,
≤−1 =≥, and the inverse of the “strictly divides” relation is the “proper multiple” relation.
The inverse of the subset relation ⊆on 𝒫(U) is the superset relation ⊇.
Next, let us look at the inverse of some of the relations from Example 2.3.4. Here we have
ChildOf−1 = ParentOf and ParentOf−1 = ChildOf. Notice that IsMarriedTo−1 = IsMarriedTo.
Such relations are called “symmetric”.
Proposition 2.3.14 For any relations R‚ S ⊆A × B the following hold:
1. dom(R−1) = rng(R)
2. rng(R−1) = dom(R)
3. (R−1)−1 = R
4. (R ∪S)−1 = R−1 ∪S−1
5. (R ∩S)−1 = R−1 ∩S−1
6. (R′)−1 = (R−1)′, where R′ is the complement of R
Proof: We will prove properties 1 and 4. In both cases we need to prove the equality of two
sets, which we will do through a chain of “iff’s”.
1. b ∈dom(R−1) iff ∃a ∈A such that (b‚ a) ∈R−1 iff ∃a ∈A such that (a‚ b) ∈R iff b ∈rng(R)
2. (b‚ a) ∈(R ∪S)−1 iff (a‚ b) ∈(R ∪S) iff (a‚ b) ∈R or (a‚ b) ∈S iff (b‚ a) ∈R−1 or (b‚ a) ∈S−1 iff
(b‚ a) ∈R−1 ∪S−1
Definition 2.3.15 Let R ⊆A × B and S ⊆B × C. The composition of R and S is the binary relation
R⚬S ⊆A × C defined by
R⚬S = {(a‚ c) ∣∃b ∈B(aRb ∧bSc)}.
In particular, when R ⊆A2, then R⚬R is defined and denoted by R2.
Note that we can always form the composition of two relations, even if their domains
and ranges do not match, by applying the same trick we did for the Boolean combinations
of relations, above. Specifically, if R ⊆A × B1 and S ⊆B2 × C, then R ⊆A × (B1 ∪B2) and S ⊆
(B1 ∪B2) × C.

42
Logic and Discrete Mathematics: A Concise Introduction
Example 2.3.16
Let us look at the compositions of some of the relations from Examples 2.3.3 and 2.3.4.
• (a‚ b) ∈(< ⚬<) iff a is less than an integer that is less than b; i.e. (< ⚬<) consists of all ordered
pairs of integers (a‚ b) such that a is at least 2 less than b.
• < ⚬≤= <. Indeed, (a‚ b) ∈(< ⚬≤) iff there exists an integer c ∈ℤsuch that a < c and c ≤
ba < b, iff (a‚ b) ∈<.
• div⚬< consists of exactly those ordered pairs (a‚ b) of integers where a properly divides a
number strictly less that b. For example, (11‚ 23) ∈(div⚬<) since 11 div 22 and 22 < 23.
• < ⚬div consists of exactly those ordered pairs (a‚ b) of integers where a is strictly less than
a number that properly divides b. For example, (7‚ 16) ∈(< ⚬div) since 7 < 8 and 8 div 16.
Note that < ⚬div is not equal to div⚬< since (11‚ 23) ∉(< ⚬div).
• The relation ChildOf⚬OwnsDog consists of exactly those pairs (a‚ b) such that a is a human,
b is a dog and b is owned by a parent of a.
• The relation IsMarriedTo⚬IsCitizenOf relates humans a to countries b, where a is married
to a citizen of b.
Proposition 2.3.17 The composition of binary relations is associative, i.e. (R⚬S)⚬T = R⚬(S⚬T).
Proof: To be definite, let R ⊆A × B, S ⊆B × C and T ⊆C × D. Then (a‚ d) ∈(R⚬S)⚬T iff there
exists a c ∈C such that (a‚ c) ∈(R⚬S) and (c‚ d) ∈T, iff there exists c ∈C and b ∈B such that
(a‚ b) ∈R, (b‚ c) ∈S and (c‚ d) ∈T, iff there exists b ∈B such that (a‚ b) ∈R and (b‚ d) ∈S⚬T and
iff (a‚ d) ∈R⚬(S⚬T).
Note, however, that the composition of binary relations is not commutative. Indeed, as we
have already seen in Example 2.3.16, < ⚬div is not equal to div⚬<.
Proposition 2.3.18 For any binary relations R and S, it holds that (R⚬S)−1 = S−1⚬R−1.
Proof: Exercise.
2.3.5.
Exercises
➊
Identify the domains and ranges of the relations ParentOf, IsMarriedTo, OwnsDog,
IsCitizenOf and IsMemberOf from Example 2.3.4.
➋
Determine:
(a) div[{2‚ 5}]
(b) div−1[{3‚ 10‚ 12}]
(c) < [{12‚ 303}]
(d) <−1[{12‚ 303}]

Sets, Relations, Orders
43
➌
Let F and M denote the sets of all female and male humans, respectively. Let E and A denote
the sets of all European and all African countries, respectively, and let D be the set of all
Dachshunds, S the set of all Scotish Terriers and let c denote the Rotary Club.
Then, for example, F ∩(OwnsDog−1[S] ∪IsMarriedTo−1[IsCitizenOf−1[A]]) is the set of all
women who own Scotish Terriers or who are married to citizens of African countries.
Determine the content of the following sets:
(a) D ∩OwnsDog[IsCitizenOf−1[E]]
(b) S ∩OwnsDog[ChildOf−1[IsMemberOf−1[{c}]]]
(c) S ∩OwnsDog[ChildOf[IsMemberOf−1[{c}]]]
(d) ChildOf−1[CitizenOf−1[A]] ∩ChildOf−1[CitizenOf−1[E]]
(e) ChildOf[CitizenOf−1[A]] ∩ChildOf[CitizenOf−1[E]]
(f) M ∩ChildOf−1[IsMemberOf−1[{c}]]
(g) F ∩ChildOf[IsMemberOf−1[{c}]]
➍
The graphical representation of binary relations R1 and R2 on the set {a‚ b‚ c‚ d‚ e‚ f} are
given.
b
b
c
c
R1
R2
d
d
e
e
f
f
a
a
Give the graphical representations of the following relations:
(a) R1 ∩R2
(b) R1 ∪R2
(c) R1 −R2
(d) R′
1
(e) R−1
1
(f) R1⚬R2
➎
If R1 and R2 are binary relations on a set A, describe how the graphical representations of
the following relations relate to the graphical representations of R1 and R2:
(a) R1 ∩R2
(b) R1 ∪R2
(c) R1 −R2

44
Logic and Discrete Mathematics: A Concise Introduction
(d) R′
1
(e) R−1
1
(f) R1⚬R2
➏
The matrix representations of two relations S1 and S2, respectively, on the set {𝛼‚ 𝛽‚ 𝛾‚ 𝛿‚ 𝜖}
are given as
0
1
1
1
0
0
0
1
1
1
1
0
0
1
1
1
1
0
0
1
1
1
1
0
0
0
1
0
0
1
1
0
1
0
0
0
1
0
1
0
0
0
1
0
1
1
0
0
1
0
Determine the matrix representations of the following relations:
(a) S1 ∩S2
(b) S1 ∪S2
(c) S1 −S2
(d) S′
1
(e) S−1
1
(f) S1⚬S2
➐
If S1 and S2 are binary relations on a set A, describe how you would compute the matrix
representations of the following relations from the matrix representations of S1 and S2:
(a) S1 ∩S2
(b) S1 ∪S2
(c) S1 −S2
(d) S′
1
(e) S−1
1
(f) S1⚬S2
➑∗Prove that for any relations R‚ S ⊆A × B the following hold:
(a) rng(R ∪S) = rng(R) ∪rng(S)
(b) dom(R ∩S) ⊆dom(R) ∩dom(S)
(c) rng(R ∩S) ⊆rng(R) ∩rng(S)
➒
In each case, give an example of a set X and binary relations R and S on X such that
(a) dom(R) ∩dom(S) ⊈dom(R ∩S)
(b) rng(R) ∩rng(S) ⊈rng(R ∩S)

Sets, Relations, Orders
45
(c) dom(R ∩S) = dom(R) ∩dom(S)
(d) rng(R ∩S) = rng(R) ∩rng(S)
➓∗Prove that for any relations R‚ S ⊆A × B the following hold:
(a) rng(R−1) = dom(R)
(b) (R−1)−1 = R
(c) (R ∩S)−1 = R−1 ∩S−1
(d) (R′)−1 = (R−1)′, where R′ is the complement of R
11∗Prove that for any binary relations R‚ S it holds that (R⚬S)−1 = S−1⚬R−1.
The notation of set theory
Much of the notation that we use today for the set theoretic operations and concepts was first
introduced by the Italian mathematician Giuseppe Peano (1858–1932), who made important contri-
butions to set theory and logic (see the box at the end of Section 4.2 in Chapter 4). The membership
symbol ∈is a stylised version of the Greek letter 𝜖, which is the first letter of the word 𝜖𝜎𝜏𝜄meaning
“is”. Peano also introduced the notations ∩and ∪for the intersection and the union of sets.
The symbols ∉for nonmembership and ∅for the empty set were introduced by Nicolas Bour-
baki – the collective pseudonym of a group of French mathematicians who wrote highly influential
and very rigorous expositions of core mathematical topics, starting in 1935. Bourbaki also intro-
duced the terminology injection, surjection and bijection.
2.4.
Special binary relations
In this section will be taking a closer look at some of the properties of well-known binary
relations. We will also study functions seen as special types of relations.
2.4.1.
Properties of binary relations
The commonly encountered binary relations usually have certain special properties. The fol-
lowing definition lists some of the most important properties of binary relations, expressed by
formulae of first-order logic (see Section 1.2 if you are not sure about the meaning of these).
Definition 2.4.1 A binary relation R ⊆X2 is called:
• reflexive, if it satisfies ∀x(xRx);
• irreflexive, if it satisfies ∀x¬(xRx), i.e. if X2\R is reflexive;
• serial, if it satisfies ∀x∃y(xRy).
• functional, if it satisfies ∀x∃!y(xRy), where ∃!y means “there exists a unique y”;
• symmetric, if it satisfies ∀x∀y(xRy →yRx);
• asymmetric, if it satisfies ∀x∀y(xRy →¬yRx);
• antisymmetric, if it satisfies ∀x∀y(xRy ∧yRx →x = y);

46
Logic and Discrete Mathematics: A Concise Introduction
• connected, if it satisfies ∀x∀y(xRy ∨yRx ∨x = y);
• transitive, if it satisfies ∀x∀y∀z((xRy ∧yRz) →xRz);
• an equivalence relation, if it is reflexive, symmetric, and transitive;
• euclidean, if it satisfies ∀x∀y∀z((xRy ∧xRz) →yRz).
• a pre-order (or quasi-order), if it is reflexive; and transitive.
• a partial order, if it is reflexive, transitive and antisymmetric, i.e. an antisymmetric pre-order;
• a strict partial order, if it is irreflexive and transitive;
• a linear order (or total order), if it is a connected partial order;
• a strict linear order (or total order), if it is a connected strict partial order.
Example 2.4.2
Let us consider which of these properties hold for each of the relations <, ≤, div, ∣, ChildOf
and IsMarriedTo from Example 2.3.3. This is summarized in the table below. We leave as an
exercise to the reader to fill in the blanks.
<
≤
div
∣
ChildOf
IsMarrriedTo
Reflexive
×
✓
×
✓
×
×
Irreflexive
✓
×
✓
×
✓
✓
Serial
✓
✓
×
✓
✓
×
Functional
×
×
×
×
×
×
Symmetric
×
×
×
✓
Asymmetric
✓
×
Antisymmetric
✓
✓
Connected
✓
✓
Transitive
✓
✓
Equivalence relation
×
×
Euclidean
×
×
Pre-order
×
✓
Partial order
×
✓
Strict partial order
✓
×
Linear order
×
✓
Strict linear order
✓
×
Looking at the table one might be tempted to draw the conclusion that a relation is not
reflexive if and only if it is irreflexive. This is not true, for consider the relation Shaves =
{(x‚ y) ∣x and y are men and x shaves y} on the set of all men.
Proposition 2.4.3 For any binary relation R ⊆X × X the following hold:
1. R is reflexive iff EX ⊆R.
2. R is symmetric iff R−1 ⊆R iff R−1 = R.

Sets, Relations, Orders
47
3. R is asymmetric iff R−1 ∩R = ∅.
4. R is antisymmetric iff R−1 ∩R ⊆EX.
5. R is connected iff R ∪R−1 ∪EX = X2.
6. R is transitive iff R2 ⊆R.
Proof: We will prove properties 3 and 5.
3. Suppose that R is asymmetric, i.e. ∀x∀y(xRy →¬yRx). Now suppose that (x‚ y)∈R−1∩R,
i.e. (x‚ y) ∈R−1 and (x‚ y) ∈R, or (y‚ x) ∈R and (x‚ y) ∈R, which is impossible by the
asymmetry of R. Hence, R−1 ∩R = ∅.
For the converse we argue contrapositively. Suppose that R is not asymmetric, i.e.
¬∀x∀y(xRy →¬yRx), i.e. there exists x‚ y ∈X such that (x‚ y) ∈R and (y‚ x) ∈R, i.e.
(x‚ y) ∈R and (x‚ y) ∈R−1, i.e. (x‚ y) ∈R ∩R−1. We therefore conclude that R−1 ∩R ≠∅.
5. Suppose R is connected. To show that R ∪R−1 ∪EX = X2 we only need to show that X2 ⊆
R ∪R−1 ∪EX since the converse containment holds for any relation. To that end, take an
arbitrary (x‚ y) ∈X2. If x = y then (x‚ y) = (x‚ x) ∈EX and we are done. If x ≠y, then since
R is connected, we know that xRy or yRx, i.e. xRy or xR−1y, or (x‚ y) ∈R ∪R−1.
Conversely, suppose that X2 = R ∪R−1 ∪EX. Thus, for all x‚ y ∈X, if x ≠y, we have
(x‚ y) ∈R or (x‚ y) ∈R−1, i.e. for all x‚ y ∈X, we have (x‚ y) ∈R or (y‚ x) ∈R, which
precisely means that R is connected.
2.4.2.
Functions as relations
The idea that a function can be regarded as a special type of relation was already discussed in
Chapter 1.
Definition 2.4.4 The graph of a function (mapping) f ∶A →B is the binary relation Gf ⊆A × B
defined by
Gf = {(a‚ f(a)) ∣a ∈A}.
Proposition 2.4.5 A relation R ⊆A × B is functional iff it is the graph of a function from A to B.
Proof: Exercise.
2.4.3.
Reflexive, symmetric and transitive closures of a relation
Reflexivity, symmetry and transitivity are properties of relations that are often of particular
interest, as we will see, for example, when we study equivalence relations in Section 2.5. Notice
that each of these conditions requires the existence of certain ordered pairs in the relation. For
example, if R is a relation of X, then reflexivity requires that (x‚ x) ∈R for each x ∈X, while
transitivity requires that (x‚ z) ∈R whenever (x‚ y) ∈R and (y‚ z) ∈R. Thus if we start with a
relation lacking one of these properties, it seems reasonable that we can extend it to a relation
that has the property, by adding suitable pairs. We make the following definition:

48
Logic and Discrete Mathematics: A Concise Introduction
Definition 2.4.6 Let R ⊆X × X be a binary relation on a set X. Then:
• the reflexive closure of R, denoted Rref, is the smallest reflexive binary relation on X such that
R ⊆Rref,
• the symmetric closure of R, denoted Rsym, is the smallest symmetric binary relation on X such that
R ⊆Rsym and
• the transitive closure of R, denoted Rtran, is the smallest transitive binary relation on X such that
R ⊆Rtran.
Remark 2 A few remarks on Definition 2.4.6 are in order. Firstly, the word “smallest” is used in the
sense of set inclusion. For example, item 1 says that Rref is a reflexive relation on X such that R ⊆Rref,
and for any other reflexive relation R′ ⊆X2, if R ⊆R′, then Rref ⊆R′.
Secondly, note that in Definition 2.4.6, when speaking of the reflexive closure of R as the smallest
reflexive binary relation on X such that R ⊆Rref, we make the implicit assumption that such a relation
exists and is unique. Likewise, for the clauses for the symmetric and transitive closures. Proposition
2.4.8 below justifies these assumptions.
Example 2.4.7
Some examples:
• The transitive closure ChildOftran of the ChildOf relation on the set of humans is the
DescendentOf relation, which relates every human to all his/her ancestors. To see this, we
reason informally as follows: ChildOf relates me to my mother and father, who in turn are
related by ChildOf to their parents (my grandparents). Consequently, since ChildOftran
must be transitive, it will have to relate me to all my grandparents. Now my grandparents
are related to their parents (my great-grandparents) by ChildOf (and hence also by
ChildOftran), so by transitivity ChildOftran must relate me to my great-grandparents, etc.
Eventually, we see that ChildOftran relates me to all my ancestors.
• Similarly, ParentOftran relates every human to all his/her predecessors.
• Since the divisibility relation ∣is transitive, it is itself the smallest transitive relation con-
taining ∣, and hence ∣tran = ∣.
• The symmetric closure ∣sym of ∣relates every member of ℤ−{0} to all its multiples and all
its divisors in ℤ−{0}.
Proposition 2.4.8 Let R ⊆X × X. Then:
1. Rref = ⋂{S ∣R ⊆S ⊆X2 and S is reflexive}‚
2. Rsym = ⋂{S ∣R ⊆S ⊆X2 and S is symmetric}‚
3. Rtran = ⋂{S ∣R ⊆S ⊆X2 and S is transitive}.

Sets, Relations, Orders
49
Proof: We will only prove clause 3, the proofs of 1 and 2 being very similar (see Exercise 9). Let
= {S ∣R ⊆S ⊆X2 and S is transitive}, i.e. is the set consisting of all transitive binary rela-
tions on X that contain R. We must show that Rtran = ⋂. We begin by noting that ≠∅,
since X2 is transitive and R ⊆X2. By definition of we have that R ⊆S for all S ∈, so
R ⊆⋂by Proposition 2.1.3(7). Also, ⋂is transitive: suppose that (x‚ y)‚ (y‚ z) ∈⋂. Then
(x‚ y)‚ (y‚ z) ∈S for all S ∈and, since each S ∈is transitive, (x‚ z) ∈S for all S ∈. Hence
(x‚ z) ∈⋂. Thus we have established that ⋂is a transitive binary relation containing R. All
that remains is to show that ⋂is the smallest such relation. To that end, suppose that R′ ⊆X2
is transitive and R ⊆R′. Then, by definition of we have R′ ∈, and hence ⋂⊆R′.
2.4.4.
Exercises
➊
Complete the table in Example 2.4.2.
➋
Give examples of binary relations, other than those mentioned in Example 2.4.2, that have
the following properties:
(a) a relation that is transitive and reflexive but not antisymmetric;
(b) a partial order;
(c) serial but not functional;
(d) an equivalence relation.
➌
The graphical representations of two binary relations, R1 and R2, on the set {a‚ b‚ c‚ d‚ e‚ f}
are given.
b
b
c
c
d
d
e
e
f
f
a
a
R1
R2
Draw the graphical representations of the following relations:
(a) Rref
1
(b) R
sym
2
(c) Rtran
1
(d) Rtran
2
➍
Draw graphical representations of relations with the following properties:
(a) a relation that is serial but not functional;
(b) an irreflexive, functional and symmetric relation;

50
Logic and Discrete Mathematics: A Concise Introduction
(c) an irreflexive, serial and asymmetric relation;
(d) an equivalence relation that is not connected;
(e) an Euclidean relation that is serial but not functional.
➎∗Show that for any binary relations R‚ S‚ T ⊆X2 the following hold:
(a) If R and S are transitive and R⚬S = S⚬R = T, then T is also transitive.
(b) If one of R and S is reflexive and R⚬S = EX, then R = S = EX.
➏
Describe the following relations in the style of Example 2.4.7.
(a) divref
(b) divsym
(c) divtran
(d) <ref
(e) ≤sym
(f) ≤tran
➐∗Prove that for any binary relation R ⊆X × X the following hold:
(a) R is reflexive iff EX ⊆R.
(b) R is symmetric iff R−1 ⊆R iff R−1 = R.
(c) R is antisymmetric iff R−1 ∩R ⊆EX.
(d) R is transitive iff R2 ⊆R. (Recall that R2 = R⚬R.)
➑∗Prove that a relation R ⊆A × B is functional iff it is the graph of a function from domA to
B.
➒∗Prove that for any binary relation R ⊆X × X,
(a) Rsym = ⋂{S ∣R ⊆S ⊆X2 and S is symmetric}.
(b) Rref = ⋂{S ∣R ⊆S ⊆X2 and S is reflexive}.
Fuzzy sets
Many concepts we use in everyday life are vague. For example, consider “the tall members of the
American Mathematical Society”, “the democratic countries of the world”, or “the hot days in Syd-
ney during January 2014”. It we were asked to determine the members of these sets, some cases
would be clear-cut: for example, a day that reached a high of 34∘C would definitely be a member of
the set of hot days, while one on which the maximum temperature was 15∘C would not. However,
what about a day that reached 25∘C? Even membership in the set of living organisms is vague at
its edges. Elephants are clearly living creatures while granite boulders are not, but things become a
bit fuzzy when it comes to viruses, which scientists currently regard as falling in a sort of grey area.
(Viruses cannot reproduce on their own but need to hijack the replication machinery of the cells
of the living organisms that they infect; nor can they perform their own metabolic functions, all of
which makes them look not alive. Yet, viruses evolve and spread their genes like living organisms.)

Sets, Relations, Orders
51
The notion of a fuzzy set can be used to reason about such vague concepts. A fuzzy set is a pair
(U‚ 𝜇) where U is a (universal) set and 𝜇∶U →[0‚ 1] is a function assigning each element of U a real
number between 0 and 1, which is its grade of membership. An element x is not included in (U‚ 𝜇)
if 𝜇(0) = 0, it is fully included if 𝜇(0) = 1 and it is a fuzzy member if 0 < 𝜇(0) < 1. Ordinary sets can
be seen as the special case of fuzzy sets where 𝜇only takes on values 0 and 1.
(U‚ 𝜇A) is a fuzzy subset of (U‚ 𝜇B) if 𝜇A(x) ≤𝜇B(x) for all x ∈U, i.e. if every element is a member
if (U‚ 𝜇B) at least to the extent that it is a member of (U‚ 𝜇A). The fuzzy intersection of (U‚ 𝜇A) and
(U‚ 𝜇B) is the fuzzy set (U‚ 𝜇A∩B) where 𝜇A∩B(x) = min{𝜇A(x)‚ 𝜇B(x)}, while their union is the fuzzy
set (U‚ 𝜇A∪B) where 𝜇A∪B(x) = max{𝜇A(x)‚ 𝜇B(x)}.
Fuzzy set theory and the fuzzy logic and mathematics built upon it has found many appli-
cations, for example in Artificial Intelligence, where it can be used to reason about real world
situations where information is often incomplete or vague. Fuzzy sets were first introduced in 1965
by Lotfi A. Zadeh, a mathematician, electrical engineer, computer scientist and artificial intelligence
researcher.
2.5.
Equivalence relations and partitions
In many settings, mathematical and otherwise, we often want to regard two objects as “the
same” or “interchangeable” if they agree with regards to a certain property. In that case we say
that the objects are “equivalent”. For example, working with distances, I might want to regard
two numbers as equivalent if they have the same absolute value; we can say that two compos-
ite propositions are logically equivalent if they always have the same truth value, regardless of
the truth values of their primitive components; we could declare two algorithms equivalent if
they always give the same output when given the same input; we could regard two insurance
policies as equivalent if they give the same cover for the same premiums and under the same
conditions; etc.
In this section we will take a closer look at relations of equivalence and give a precise
mathematical definition of the notion of equivalence relation; we will see how an equivalence
relation divides (or partitions) the set on which it is defined into equivalence classes and how,
consequently, equivalence relations and partitions are two sides of the same coin.
2.5.1.
Equivalence relations
Having discussed the informal notion of equivalence, let us consider how one would cap-
ture this as a formal mathematical concept. Firstly, equivalence is a relationship between two
objects, i.e. a binary relation. Now it is also clear that not every binary relation can be regarded
as an equivalence; for example, the binary relation < on ℤis not such a relation. Therefore we
would have to impose constraints on the relations if it is to capture the notion of equivalence:
every object should be equivalent to itself; if object a is equivalent to object b, then object b
must, of course, also be equivalent to object a; if object a is equivalent to object b and object
b is in turn equivalent to an object c, it seems reasonable to require that object a must also be
equivalent to object c. Putting all this together yields the following definition.

52
Logic and Discrete Mathematics: A Concise Introduction
Definition 2.5.1 Let X be a set and R ⊆X × X a binary relation on X. We call R an equivalence
relation on X if it is reflexive, symmetric and transitive, i.e. if for all x‚ y‚ z ∈X it holds that
1. xRx,
2. if xRy then yRx and
3. if xRy and yRz then xRy.
Example 2.5.2
The following are equivalence relations on the set ℤ:
1. The equality relation =. For every x ∈ℤwe have x = x. If x‚ y ∈ℤand x = y then y = x. If
x‚ y‚ z ∈ℤand x = y and y = z, then x = z.
2. The relation of having the same absolute value. Let us write x ≡abs y if |x| = |y| and check
that this relation ≡abs satisfies the requirements of Definition 2.5.1. For any number x ∈ℤ
we have |x| = |x|, i.e. x ≡abs x, so ≡abs is a reflexive relation. Next, to prove that ≡abs is
symmetric suppose that x‚ y ∈ℤand that x ≡abs y. This means that |x| = |y|. However, then
|y| = |x| and so y ≡abs x. Lastly, to prove that ≡abs is transitive, suppose that x‚ y‚ z ∈ℤand
that x ≡abs y and y ≡abs z. This means that |x| = |y| and |y| = |z|. However, then |x| = |z|,
so x ≡abs z, as desired.
3. The relation of having the same remainder when divided by 3, denoted ≡3. There are of
course exactly three possible remainders after division by 3, namely 0 (in the case of mul-
tiples of 3), 1 and 2. For example, 3 ≡30 ≡3 −3 ≡36, −2 ≡31 ≡34 ≡37 and −1 ≡32 ≡35 ≡38. It
is easy to prove that ≡3 is an equivalence relation (see Exercise 1).This type of equivalence
relation will be studied in much greater detail in Section 5.5.1.
4. The relation sim of similarity on the set of all triangles in the plane.
Definition 2.5.3 Let R ⊆X × X be an equivalence relation on X and x ∈X. The subset
[x]R = {y ∈X ∣xRy}
is called the equivalence class (or the cluster) of x generated under R.
Proposition 2.5.4 For every equivalence relation R on a set X and x‚ y ∈X the following hold:
1. x ∈[x]R,
2. x ∈[y]R implies [x]R = [y]R,
3. x ∉[y]R implies [x]R ∩[y]R = ∅,
4. if [x]R ≠[y]R then [x]R ∩[y]R = ∅.
Proof: The proofs of (1), (2) and (4) are left as Exercise 8. We prove (3), by proving the contra-
positive. Suppose that [x]R ∩[y]R ≠∅. Thus, there is at least one element z ∈[x]R ∩[y]R, and
so xRz and yRz. By symmetry we also have zRx, and then by transitivity from yRz and zRx we
get yRx, i.e. x ∈[y]R.
Items (1) and (2) mean that it does not matter which member of an equivalence class we
choose to name or represent it: if x‚ z ∈[y]R then [x]R = [y]R = [z]R. Together items (1), (2) and

Sets, Relations, Orders
53
(3) imply (4), which, taken together, imply that any two equivalence classes are either the same
or disjoint.
Example 2.5.5
Let us see what the equivalence classes of the equivalence relations of Example 2.5.2 look
like.
1. The equivalence classes under = are singletons, e.g. [3]= = {3}, [0]= = {0} and [−99]= =
{−99}. In general [x]= = {x} for all x ∈ℤ. Since each equivalence class has only one mem-
ber there is only one way to represent each class.
2. [2]≡abs = {−2‚ 2}, [−50]≡abs = {−50‚ 50} and [0]≡abs = {0}. It is clear that the equivalence class
under ≡abs of every integer x other than 0 will consist of exactly two elements, namely
x and −x. Moreover, [x]≡abs = [−x]≡abs, for example [2]≡abs = [−2]≡abs. Notice that there are
infinitely many different equivalence classes under ≡abs.
3. The equivalence class of 4 under the relation ≡3 consists of all those integers that have the
same remainder as 4 upon division by 3, namely 1, i.e. [4]≡3 = {…‚ −5‚ −2‚ 1‚ 4‚ 7‚ 10‚ …}.
We also have [0]≡3 = {…‚ −6‚ −3‚ 0‚ 3‚ 6‚ 9‚ …} and [2]≡3 = {…‚ −7‚ −4‚ −1‚ 2‚ 5‚ 8‚ …}. As
you would expect, these are the only three equivalence classes under ≡3, since there are
exactly three different remainders after division by 3. Notice that we can represent each of
these equivalence classes in infinitely many different ways, for example [4]≡3 = [−5]≡3 =
[7]≡3 = · · ·, etc.
4. If ABC is a triangle of which all side lengths are 1 unit, then [ABC]sim is the set of all equi-
lateral triangles.
2.5.2.
Quotient sets and partitions
An equivalence relation divides up the set on which it is defined into equivalence classes.
The resulting set of equivalence classes is an important mathematical object, known as the
quotient set.
Definition 2.5.6 Let R ⊆X × X be an equivalence relation. The set
X∕R = {[x]R ∣x ∈X}‚
consisting of all equivalence classes of elements of X under R, is called the quotient set of X by R.
The equivalence class [x]R, also denoted by x∕R, is also called the quotient element of x by R.
The mapping 𝜂R ∶X →XR defined by 𝜂R(x) = [x]R is called the canonical mapping of X onto
X∕R.
The quotient set ℤ∕≡3 is graphically represented in Figure 2.7. Notice, as we already hinted
above, that the different equivalence classes (in this case [0]≡3, [1]≡3 and [2]≡3) are disjoint and
that [0]≡3 ∪[1]≡3 ∪[2]≡3 = ℤ. That is to say, the sets [0]≡3, [1]≡3 and [2]≡3 form a partition of ℤ.
Here is the formal definition of partition.
Definition 2.5.7 A partition of a set X is any family of nonempty and pairwise disjoint subsets of
X, the union of which is X.

54
Logic and Discrete Mathematics: A Concise Introduction
3
0
−30
−12
999
1
−2
100
−29
1000
13
−65
403
2
902
5
−88
101
−1
36
Figure 2.7: The quotient set ℤ∕≡3
Example 2.5.8
The family {{d‚ b‚ c}‚ {a}‚ {g‚ f}‚ {e‚ h}} is a partition of the set {a‚ b‚ c‚ d‚ e‚ f‚ g‚ h}. Indeed,
{d‚ b‚ c} ∪{a} ∪{g‚ f} ∪{e‚ h} = {a‚ b‚ c‚ d‚ e‚ f‚ g‚ h}
and
{d‚ b‚ c} ∩{a} = ∅
{d‚ b‚ c} ∩{g‚ f} = ∅
{d‚ b‚ c} ∩{e‚ h} = ∅
{a} ∩{g‚ f} = ∅
{a} ∩{e‚ h} = ∅
{g‚ f} ∩{e‚ h} = ∅.
As we mentioned before, the quotient set {[0]≡3‚ [1]≡3‚ [2]≡3} of ℤby ≡3 is a partition of ℤ.
This is no coincidence, as every quotient set by an equivalence relation is a partition of the set
on which the relation is defined, a fact we now enshrine and prove as a theorem.
Proposition 2.5.9 If R is an equivalence relation on a set X, then the quotient set
{[x]R ∣x ∈X}
is a partition of X.
Proof: In order to show that {[x]R ∣x ∈X} satisfies the conditions of Definition 2.5.7, we need
to show that ⋃{[x]R ∣x ∈X} = X and that, for any two different equivalence classes [x]R and
[y]R, it holds that [x]R ∩[y]R = ∅.
Since [x]R ⊆X for each x ∈X we immediately have that ⋃{[x]R ∣x ∈X} ⊆X. For the sake
of the inclusion in the other direction, let y ∈X arbitrarily. By Proposition 2.5.4(1), y ∈[y]R and
therefore y ∈⋃{[x]R ∣x ∈X}. We have therefore established that ⋃{[x]R ∣x ∈X} = X.
Next suppose that [x]R ≠[y]R. By Proposition 2.5.4(4) this implies that [x]R ∩[y]R = ∅. This
completes the proof.

Sets, Relations, Orders
55
Example 2.5.10
The quotient set ℤ∕≡abs of ℤby ≡abs is a partition of ℤinto infinitely many sets, namely
{0}‚ {−1‚ 1}‚ {−2‚ 2}, {−3‚ 3}‚ …. The canonical mapping 𝜂≡abs sends each integer n to the set
consisting of n and its additive inverse −n, i.e. 𝜂≡abs(n) = {−n‚ n}. This means that 𝜂≡abs(n) is a
two-element set for each nonzero integer n, but that 𝜂≡abs(0) = {−0‚ 0} = {0}.
Proposition 2.5.9 tells us that each equivalence relation corresponds to a partition. The
converse of this is also true, as the next theorem shows.
Proposition 2.5.11 If is a partition of a set X then the relation ∼⊆X × X defined by
x∼y iff x and y belong to the same member of 
is an equivalence relation on X.
Proof: See Exercise 11.
Together Propositions 2.5.9 and 2.5.11 tell us that, for any set X, equivalence relations on
X and partitions of X are the two faces of the same coin.
Example 2.5.12
Consider the partition of the set {1‚ 2‚ 3‚ …‚ 12} pictured below.
4
9
1
8
6
12
10
5
11
7
3
2
Formally, = {{1}‚ {2‚ 3‚ 5‚ 7‚ 11}‚ {4‚ 9}‚ {8‚ 6‚ 10}‚ {12}}. In this case the equivalence
relation ∼relates every number in {1‚ 2‚ 3‚ …‚ 12} to those that have the same number
of divisors as it. For example, each of the prime numbers 2‚ 3‚ 5‚ 7 and 11 has exactly two
divisors, namely 1 and the number itself. So ∼relates all these numbers to themselves and
to each other. The number 12 is the only number in the set having exactly 6 divisors (namely,
1, 2, 3, 4, 6 and 12) and so ∼relates 12 only to itself.

56
Logic and Discrete Mathematics: A Concise Introduction
2.5.3.
The kernel equivalence of a mapping
With every mapping we can associate an equivalence relation on the domain. The idea is that
two elements x1 and x2 in the domain of a mapping f should be related if and only if f(x1) =
f(x2). Here is the formal definition.
Definition 2.5.13 Let f ∶X →Y. Then the kernel equivalence of f is the relation ̃f ⊆X × X defined
such that
x̃fy iff f(x) = f(y).
The following theorem shows that we are justified in calling the kernel equivalence an
equivalence.
Theorem 2.5.14 Let f ∶X →Y. Then the kernel equivalence of f is an equivalence relation on X.
Proof: Exercise.
Example 2.5.15
Let f ∶ℤ→ℤbe defined by f(x) →|x|. We therefore have that x̃fy if and only if |x| = |y|. In
other words, ̃f is exactly the same relation as ≡abs defined in Example 2.5.2.
Theorem 2.5.16 Let f ∶X →Y, and let 𝜇∶X∕̃f →Y be the mapping defined as
𝜇([x]̃f) = f(x).
Then
1. 𝜇is well defined,
2. 𝜇is an injection and
3. f = 𝜇𝜂̃f.
Before we prove Theorem 2.5.16, let us discuss what it means for 𝜇to be “well defined” and
why it is important to know this about 𝜇. Notice that the definition of 𝜇([x]̃f) as f(x) makes use
of the particular element x used to represent the equivalence class [x]̃f. What if [x]̃f had been
written as [y]̃f, where y is another element of [x]̃f? By Proposition 2.5.4 this would mean that
[x]̃f = [y]̃f. Certainly, then, we would want 𝜇([x]̃f) = 𝜇([y]̃f), i.e. we would not want the value
of 𝜇to depend on the particular choice of representative of the equivalence class, but simply
on the equivalence class itself. This is what it means for 𝜇to be well defined. Therefore, to prove
that 𝜇is well defined, it would be enough to show that if [x]̃f = [y]̃f, then 𝜇([x]̃f) = 𝜇([y]̃f). Now
we are ready for the proof.
Proof:
1. As explained above, to prove that 𝜇is well defined, we must show that 𝜇([x]̃f) = 𝜇([y]̃f)
whenever [x]̃f = [y]̃f. Accordingly, suppose that [x]̃f = [y]̃f. Then x̃fy and hence f(x) = f(y),
i.e. 𝜇([x]̃f) = 𝜇([y]̃f), so 𝜇is well defined.

Sets, Relations, Orders
57
2. Suppose 𝜇([x]̃f) = 𝜇([y]̃f). Then f(x) = f(y), i.e. x̃fy. Then if follows by Proposition 2.5.4 that
[x]̃f = [y]̃f and so 𝜇is injective.
3. Finally, (𝜇𝜂̃f)(x) = 𝜇(𝜂̃f(x)) = 𝜇([x]̃f) = f(x).
The above theorem shows, in particular, that every mapping can be represented as a com-
position of a surjective mapping followed by an injective mapping.
Example 2.5.17
Consider again the mapping f ∶ℤ→ℤdefined by f(x) →|x|. Suppose we were to define a
map 𝛾∶ℤ∕̃f →ℤsuch that 𝛾∶[x]̃f →x −1. This 𝛾would be an example of a map that is
not well defined on ℤ∕̃f. For example, [−2]̃f = [2]̃f, but 𝛾([−2]̃f) = −2 −1 = −3 while 𝛾([2]̃f) =
2 −1 = 1.
2.5.4.
Exercises
➊
Prove that the relation ≡3 defined in Example 2.5.2 is an equivalence relation on ℤ.
➋
Let X = {a‚ b‚ c‚ d‚ e‚ f‚ g‚ h}. For each of the following families of subsets of X, determine
whether or not it is a partition of X. If it is a partition of X draw the graphical representation
of the corresponding equivalence relation.
(a) {{a‚ c‚ e‚ g}‚ {b‚ d}‚ {h‚ f‚ c}}
(b) {{a}‚ {b}‚ {c}‚ {d}‚ {e}‚ {f}‚ {g}‚ {h}}
(c) {{a‚ c‚ e‚ g}‚ {d‚ f‚ h}}
(d) {{a‚ c‚ e‚ g}‚ {b‚ h}‚ {d‚ f}}
➌
.(a) Show that the relation of being parallel (denoted ||) is an equivalence relation on the
set L of all lines in the Cartesian plane.
(b) How many elements are there in L∕||?
(c) Give an example of a binary relation on L that is not an equivalence relation.
➍
Let 2∗be the set of all strings of 0s and 1s of finite length. We can think of 2∗as the set
of all binary representations of positive integers. Let n be a positive integer and let ∼n be
the binary relation on 2∗that relates two elements if either (i) they are both shorter than
n positions or (ii) they are both at least n positions long and they agree in their first n
positions. For example, we will have 010∼411 (because both are shorter than 4 positions)
and 101111001010∼4101100, but 101≁41011 and 11011≁411111.
(a) Prove that ∼n is an equivalence relation on 2∗.
(b) Describe the equivalence class [1]∼1.
(c) How many elements does [1]∼3 have?
(d) How many elements does [1]∼n have?

58
Logic and Discrete Mathematics: A Concise Introduction
➎
Draw the graphical representation of the relation ∼in Example 2.5.12.
➏∗
Prove that if R ⊆ℤ× ℤis an equivalence relation on ℤ, then = ⊆R, i.e. prove that the
equality relation is contained in every equivalence relation on ℤ. Conclude that = is the
smallest equivalence relation on ℤ.
➐∗
Let R1 and R2 be equivalence relations on a set X.
(a) Is it always the case that R1 ∩R2 is an equivalence relation on X? Justify your answer.
(b) Is it always the case that R1 ∪R2 is an equivalence relation on X? Justify your answer.
(c) Is it always the case that Rc
1 is an equivalence relation on X? Justify your answer.
➑∗
Let R be an equivalence relation on a set X. Prove that for all x‚ y ∈X the following hold
(see Proposition 2.5.4):
(a) x ∈[x]R.
(b) x ∈[y]R implies [x]R = [y]R.
(c) If [x]R ≠[y]R then [x]R ∩[y]R = ∅.
➒∗
Prove that a relation R ⊆X2 is an equivalence relation on X if and only if it is reflexive and
euclidean.
➓** Let E1 and E2 be equivalence relations in a set X. Prove that the composition E1⚬E2 is an
equivalence relation if and only if the two relations commute, i.e. if and only if
E1⚬E2 = E2⚬E1.
11** Prove Proposition 2.5.11.
Zermelo–Fraenkel set theory
Russell’s paradox (see the box in Section 2.1) arises from the assumption that any collection of
objects that can be described forms a set. This assumption is made in what is known as naive set
theory. To avoid such paradoxes we need to be more explicit about what we allow to be a set. This is
done by adopting an Axiomatic Set Theory, which states explicitly which sets we assume to exist and
in which ways new sets can be constructed from old. The best-known example of such a system is
Zermelo–Fraenkel set theory, which is due to the German mathematician Ernst Zermelo (1871–1953)
and the German-born Israeli mathematician Abraham Fraenkel (1891–1965). It can be argued that
its eight axioms, possibly with the addition of the Axiom of Choice (see the box in Section 2.6), are
sufficient to build all mathematical objects, i.e. that a mathematical object exists if and only if it can
be shown to exist on the basis of these axioms. As such, Zermelo–Fraenkel set theory provides a
foundation for mathematics.
Some of the axioms are a bit involved, so we will not list them all here, but will only provide a
few examples to give an idea of the spirit of axiomatic set theory.
Axiom of Pairing. For any sets a and b there exists a set {a‚ b} that contains exactly a and b as
elements. Expressed in first-order logic this becomes
∀a∀b∃c∀x[x ∈c ↔x = a ∨x = b].

Sets, Relations, Orders
59
Axiom of Union. For every set x there exists a set y = ⋃x, i.e. a set containing exactly the elements
of the elements of x. Expressed in first-order logic this becomes
∀x∃y∀u(u ∈y ↔∃z(z ∈x ∧u ∈z)).
Powerset Axiom. The powerset of any set exists. In first-order logic:
∀x∃y∀u(u ∈y ↔∀v(v ∈u →v ∈x)).
Zermelo–Fraenkel set theory is often abbreviated to ZF, while ZFC denotes a system with the
addition of the Axiom of Choice.
2.6.
Ordered sets
Many well-known binary relations impose some type of order on the sets on which they are
defined. For example, the relation ≤orders the integers ℤfrom smaller to larger; the relation ⊆
orders the members of the powerset 𝒫(X) from “smaller to larger” according to containment;
the Ancestor relation orders humans into generation according to descent. Such ordering rela-
tions are extremely important in the mathematical sciences, and are the topic of the current
section.
2.6.1.
Pre-orders and partial orders
Partial orders and the more general pre-orders were already mentioned in Section 2.4. Par-
tial orders are the most fundamental of the ordering relations that we want to study, and we
therefore recall their definition.
Definition 2.6.1 Let X be a set and R a binary relation on X. The relation R is called a pre-order if it
is reflexive and transitive. If, moreover, R is also antisymmetric, then it is called a partial order.
If R is a partial order on X, then the pair (X‚ R) is known as a partially ordered set or as a poset.
If the ordering relation R is clear from the context we will often simply refer to X on its own as a poset.
Example 2.6.2
The pairs (ℕ‚ ≤) (ℤ‚ ≤), (ℚ‚ ≤) and (ℝ‚ ≤) are all posets. The pair ({1‚ 2‚ 3‚ …‚ 10}‚ ∣), where
∣is the relation of divisibility, is a poset. For any set X, the pair (𝒫(X)‚ ⊆) is a poset.
When we want to speak about an arbitrary poset, we will often denote it as (X‚ ≤), using
the symbol “≤” to denote the partial order relation, even though the elements of X need not
be numbers of any sort. Given a poset (X‚ ≤) the following notations are standardly used:
x ≥y
means
y ≤x
x < y
means
x ≤y and x ≠y
x > y
means
y < x

60
Logic and Discrete Mathematics: A Concise Introduction
Let (X‚ ≤) be a poset. For elements x‚ y ∈X we say that x is covered by y if
1. x < y and
2. for every z ∈X, if x ≤z < y then x = z.
We use the notation x ≺y to indicate that x is covered by y. Notice that x being covered by
y means that x < y and that there is no element of X strictly in between x and y.
Example 2.6.3
In the poset (ℤ‚ ≤) every integer n is covered by exactly one integer, namely n + 1. In symbols,
n ≺n + 1.
In the poset (ℚ‚ ≤) no element is covered by another element. The same is true of the
poset (ℝ‚ ≤).
Let Y = {a‚ b‚ c‚ d‚ e‚ f} and consider the poset (𝒫(Y)‚ ⊆). The element {a‚ b} is covered
by exactly those subsets of Y that extend it with one element of Y, i.e. the subsets {a‚ b‚ c},
{a‚ b‚ d}, {a‚ b‚ e} and {a‚ b‚ f}. The empty set ∅is covered by exactly the singleton subsets of
Y, while Y is not covered by anything.
The following proposition shows that by taking a suitable quotient we can transform any
pre-order into a partial order. It is a typical application of a quotient construction.
Proposition 2.6.4 Let R be a pre-order on X. Then:
1. The relation ∼on X, defined by
x ∼y iff xRy and yRx‚
is an equivalence relation on X.
2. The relation ̃R on X∕∼, defined by
[x]∼̃R [y]∼iff xRy‚
is a well-defined partial order on X∕∼, called the partial order induced by R.
Proof: We leave the proof of part (1) as Exercise 11 and prove only part (2). To show that ̃R is well
defined means, as usual, to show that the definition of ̃R does not depend on the particular
choice of representatives of equivalence classes. In particular, we need to show that if [x]∼=
[x′]∼and [y]∼= [y′]∼, then [x]∼̃R [y]∼iff [x′]∼̃R [y′]∼. To that purpose, suppose that [x]∼=
[x′]∼and [y]∼= [y′]∼and that [x]∼̃R [y]∼. We need to show that [x′]∼̃R [y′]∼. Since [x]∼̃R [y]∼
we have xRy. From the facts [x]∼= [x′]∼and [y]∼= [y′]∼it follows by Proposition 2.5.4 that
x ∼x′ and y ∼y′. Now applying the definition of ∼to these last two facts we get xRx′, x′Rx,
yRy′ and y′Ry. Next applying the fact that R is transitive to the facts x′Rx and xRy yields x′Ry,
and then again applying the transitivity of R to the facts x′Ry and yRy′ yields x′Ry′. Then, by
the definition of ̃R we have [x′]∼̃R [y′]∼, as we wanted. A symmetric argument proves that
[x]∼̃R [y]∼if [x′]∼̃R [y′]∼.

Sets, Relations, Orders
61
Now that we have established that ̃R is well defined, we proceed to prove that it is a partial
order X∕∼.
Reflexivity. Since R is reflexive we have xRx for all x ∈X and hence that [x]∼̃R [x]∼for all
[x]∼∈X∕∼.
Transitivity. Suppose [x]∼̃R [y]∼and [y]∼̃R [z]∼. By the definition of ̃R we have xRy and
yRz and hence by the transitivity of R that xRz. Again applying the definition of ̃R we get
[x]∼̃R [z]∼.
Antisymmetry. Suppose that [x]∼̃R [y]∼and [y]∼̃R [x]∼. By the definition of ̃R we have xRy
and yRx and, consequently, by the definition of ∼that x ∼y. Then, by Proposition 2.5.4, [x]∼=
[y]∼.
Every subset of a poset is itself a poset with respect to the restriction of the partial order,
as the following proposition shows. We leave the proof as Exercise 12.
Proposition 2.6.5 If (X‚ ≤) is a poset and Y ⊆X, then (Y‚ ≤∣Y) is also a poset.
2.6.2.
Graphical representing posets: Hasse diagrams
We have already seen how useful graphical representations can be for visualizing and under-
standing relations (Section 2.3.2). In particular, they can be applied to partial orders. The
properties of partial orders allow for a simplified graphical representation. Informally speak-
ing, we will omit all arrows linking nodes to themselves, since reflexivity implies that these
are always present; we will also omit arrows, the existence of which can be inferred from the
transitivity of the relation; lastly, we will link nodes with line segments instead of arrows but
place them in such a way that the “direction” of the relational links is always upwards on
the page. Such a representation of a poset is known as its Hasse diagram. More formally, the
Hasse diagramme of a finite poset (X‚ ⪯) is constructed as follows:
1. Place a node in the plane. Call it p(x), representing each x ∈X.
2. Draw a line segment linking p(x) and p(y) iff x ≺y.
3. Do this in such a way that
(a) if x ≺y then p(x) is lower than p(y) in the plane and
(b) line segments never cross in a node, but may cross elsewhere.

62
Logic and Discrete Mathematics: A Concise Introduction
Example 2.6.6
Consider the poset consisting of the integers 1 to 10 together with the divisibility relation ∣
restricted to this set. Here is its Hasse diagram:
10
8
4
2
6
9
5
7
3
1
Notice that, even though there is no line segment from 2 to 8, the diagram does imply that
2 ∣8, since the line segments from 2 to 4 and from 4 to 8 mean that 2 ∣4 and 4 ∣8 and hence
2 ∣8 by the transitivity of ∣. On the other hand, the diagram does not imply that 6 divides 10,
even though 10 is placed above 6, because they are not connected by a line segment.
If you try to draw the graphical representation (as in Section 2.3.2) of this relation you
will appreciate how much simpler and less cluttered the Hasse diagrams are.
Example 2.6.7
Here is the Hasse diagram of the poset consisting of the power set of the three element set
{a‚ b‚ c} together with the set inclusion relation ⊆:
{a, b, c}
{b, c}
{a, c}
{a, b}
{a}
{b}
{c}

Sets, Relations, Orders
63
2.6.3.
Lower and upper bounds. Minimal and maximal elements
There are special elements in a partially ordered set: for example, there may be a smallest or
largest element, or – more generally – maximal or minimal elements, in the whole set or in a
given subset. Here we will define and discuss these and related notions.
Definition 2.6.8 Let (X‚ ≤) be a poset and Y ⊆X.
• An element x ∈X is a lower bound for Y in X if x ≤y for every y ∈Y.
• An element x ∈X is the greatest lower bound, also called infimum, of Y in X if
– x is a lower bound for Y in X and
– x′ ≤x for every lower bound x′ of Y in X.
• An element x ∈X is an upper bound for Y in X if x ≥y for every y ∈Y.
• An element x ∈X is the least upper bound, also called supremum, of Y in X if
– x is an upper bound for Y in X, and
– x ≤x′ for every upper bound x′ of Y in X.
When the poset X is clear from the context we will simply speak of a lower bound of Y, omitting “in
X”, and similarly for upper bounds, infima and suprema.
When speaking of the supremum or infimum in the definition above we are making the
implicit assumption that such an element is unique, if it exists. The next proposition shows
that we are justified in this.
Proposition 2.6.9 Let (X‚ ≤) be a poset and Y ⊆X.
1. If Y has a infimum in X then it is unique.
2. If Y has a supremum in X then it is unique.
Proof: We prove (1). Suppose that x and x′ are infima of Y. Then, since x is a lower bound of
Y we must have x ≤x′. Similarly, since x′ is a lower bound of Y we must have x′ ≤x. Then
x = x′, by the antisymmetry of ≤.

64
Logic and Discrete Mathematics: A Concise Introduction
Example 2.6.10
Consider the poset depicted below:
a
d
c
b
e
h
f
g
• The upper bounds for {e‚ b‚ f} are a and b. The least of these upper bounds is b, so {e‚ b‚ f}
has a supremum, namely b, which, in this case, is itself a member of the set {e‚ b‚ f}. This is
always the case for a set that has a greatest element, in this case b.
• The upper bounds for {e‚ g} are a and c, and the least upper bound is c. This shows that the
supremum of a set need not itself be a member of the set.
• The upper bounds for {e‚ f} are a, b and c. In this case the least upper bound does not exist:
it cannot be a, since b ≤a, it cannot be b, since b ≰c and it cannot be c, since c ≰b.
The possibilities for infima are similar (see Exercise 3).
Even if a subset of a poset does not have a least element, it may have minimal elements, i.e.
ones that are not greater than any element in the subset. For example, in the poset introduced
in Example 2.6.10 the subset {b‚ c‚ e‚ f} does not have a least element. However, no element in
it is less than e or less than f. Likewise, maximal elements can be defined. This is made precise
in the following definition.
Definition 2.6.11 Let (X‚ ≤) be a poset and Y ⊆X.
1. An element x ∈Y is called minimal in Y if there is no element of Y strictly less than x, i.e. for
every y ∈Y, if y ≤x then x = y.
2. An element x ∈Y is called maximal in Y if there is no element of Y strictly greater than x, i.e.
for every y ∈Y, if y ≥x then x = y.
Note that the least (respectively, greatest) element of Y, if it exists, is the only minimal
(respectively, maximal) element of Y.

Sets, Relations, Orders
65
Example 2.6.12
Consider the poset (ℤ+‚ ∣) of positive integers with the divisibility relation ∣. The whole set
ℤ+ has a least element, namely 1, but no maximal (hence, no greatest) elements.
The subset {2‚ 3‚ 4‚ …} has no least element while it has infinitely many minimal elements,
namely all primes.
2.6.4.
Well-ordered sets
Well-ordered sets are a special type of poset in which it is impossible to “go downwards”
forever, i.e. one in which whenever following the relation > one will always come to a stop
after a finite number of steps. Linear orders with this property are of particular interest, as
it is possible to formulate an induction principle for them that generalizes the principle of
mathematical induction. Let us make these intuitions a bit more precise:
Definition 2.6.13 An ascending (respectively, strictly ascending) chain in a poset (X‚ ≤) is any
finite or infinite sequence x1‚ x2‚ x3‚ … of elements of X such that x1 ≤x2 ≤x3 ≤· · · (respectively,
x1 < x2 < · · ·).
A descending (respectively, strictly descending) chain in a poset (X‚ ≤) is any finite or infinite
sequence x1‚ x2‚ x3‚ … of elements of X such that x1 ≥x2 ≥· · · (respectively, x1 > x2 > · · ·).
Example 2.6.14
1‚ 2‚ 2‚ 5‚ 6‚ 7‚ 7‚ 7‚ 101 is an ascending chain in the poset (ℕ‚ ≤). It is not strictly ascending.
The chain 1‚ 1‚ 1‚ … is both ascending and descending in the poset (ℕ‚ ≤). 2‚ 4‚ 8‚ 16‚ 32 · · · is
an infinite strictly ascending chain in the poset (ℕ‚ ∣). The chain 0‚ −2‚ −4‚ −6‚ −8‚ −10‚ …
is an infinite strictly descending one in the poset (ℤ‚ ≤).
Definition 2.6.15 A poset is called well-founded if it contains no infinite strictly descending chains.
For instance, every finite poset is well founded.
Proposition 2.6.16 The poset (𝒫(X)‚ ⊆), where X is any infinite set, is not well founded.
Proof: See Exercise 9.
Definition 2.6.17 A well-founded linear order is called a well order.
Example 2.6.18
(ℕ‚ ≤) is a well order, while (ℤ‚ ≤), (ℚ‚ ≤) and (ℝ‚ ≤) are not. In particular, 0‚ −1‚ −2‚ −
3‚ … is an infinite strictly descending chain in each of the posets (ℤ‚ ≤), (ℚ‚ ≤) and (ℝ‚ ≤).

66
Logic and Discrete Mathematics: A Concise Introduction
Proposition 2.6.19 The lexicographic order in ℕ2 defined by
⟨x1‚ y1⟩≤⟨x2‚ y2⟩iff x1 < x2 or (x1 = x2 and y1 ≤y2)
is a well order on ℕ2.
Proof: Exercise.
Proposition 2.6.20 A poset (X‚ ≤) is well founded if and only if every nonempty subset of X has a
minimal element.
In particular, a linear order (X‚ ≤) is a well order if and only if every nonempty subset of X has a
least element.
Proof: We prove the first claim and leave the second one as Exercise 13.
(⇒) Suppose that (X‚ ≤) is well founded but, for the sake of contradiction, that there is a
subset ∅≠Y ⊆X such that Y has no minimal element. Take an arbitrary element of Y
and call it y1. Since y1 cannot be a minimal element of Y there must be another element,
y2 say, such that y2 ∈Y and y1 > y2. Again, since y2 cannot be a minimal element of Y
there must be another element, y3 say, such that y3 ∈Y and y1 > y2 > y3. Continuing in
this way we can construct an infinite descending chain, contradicting our assumption
that (X‚ ≤) is well founded. (This step of the proof requires a special axiom of set theory
known as the Axiom of Choice; see the box at the end of this section.)
(⇐) We prove the contrapositive. Suppose that (X‚ ≤) is not well founded. If (X‚ ≤) is not
well founded it must contain an infinite descending chain, say x1 > x2 > x3 > · · ·. Now
let Y = {x1‚ x2‚ x3‚ …}. Clearly, Y is a nonempty subset of X that does not have a least
element.
As promised, we now generalize the principle of mathematical induction to induction on
arbitrary well-founded sets.
Theorem 2.6.21 (Induction principle for well-founded sets) Let (X‚ ≤) be a well-founded set
and P ⊆X be such that for every x ∈X, if all elements of X less than x belong to P, then x itself belongs
to P. Then P = X.
Proof: Assume the contrary, i.e. X\P ≠∅. Then X\P has a minimal element x. Then all elements
of X less than x belong to P; hence x must belong to P – a contradiction.
Example 2.6.22
The set of formulae of propositional logic (see Definition 3.1.3) together with the subformula
relation forms a well-founded set, which is not linear. Many properties of propositional for-
mulae are proved by induction, using Theorem 2.6.21. For example, it can be proven in this
way that every propositional formula is logically equivalent to one involving only the con-
nectives ∧and ¬.

Sets, Relations, Orders
67
2.6.5.
Exercises
➊
Draw the Hasse diagrams of the following posets:
(a) The set of integers {−2‚ 0‚ …‚ 8‚ 10} with the ≤relation restricted to it.
(b) The set 𝒫({0‚ 1‚ 2}) together with the ⊆relation.
(c) The set X = {a‚ b‚ c‚ d‚ e} together with the relation
R = (X × X) ∪{(a‚ b)‚ (a‚ c)‚ (a‚ d)‚ (a‚ e)‚ (b‚ c)‚ (e‚ d)‚ (e‚ c)‚ (a‚ c)}.
➋
A binary string is a finite sequence of 0s and 1s, e.g. 0, 1001 and 11010101100. The empty
string is the string of length 0 and is denoted by 𝜖. We say that a string s is an initial segment
of a string t if t can be obtained from s by adding zero or more 0s and/or 1s to the end of
s. For example, 10 is an initial segment of each of the strings 101, 10, 1011 and 10101.
(a) Show that the set of binary strings together with the initial segment relation forms a
poset.
(b) Show that the set of binary strings of length at most 4 together with the initial segment
relation restricted to this set forms a poset.
(c) Draw the Hasse diagram of the poset in question 2(b).
➌
Give an example of a poset (X‚ ≤) and subsets Y1‚ Y2‚ Y3 ⊆X such that
(a) Y1 does not have an infimum in X,
(b) Y2 has an infimum in X that is also a member of Y2,
(c) Y3 has an infimum in X but that is not a member of Y3.
➍
Consider the poset (ℤ‚ ≤) where ≤is the usual ordering on the integers.
(a) Give an example of a proper subset of ℤthat has no upper bounds.
(b) Give an example of a proper subset of ℤthat has no lower bounds but does have an
upper bound.
(c) Are there subsets of ℤwith infinitely many upper bounds? Motivate.
(d) Are there subsets of ℤwith finitely many upper bounds? Motivate.
(e) Is there a subset of ℤthat has lower bounds but no infimum? Motivate.
➎
Repeat Exercise 4,but this time for the poset (ℚ‚ ≤). What changes are there if the exercise
is repeated for the poset (ℝ‚ ≤)?
➏
Consider the poset (𝒫(X)‚ ⊆), where X is a nonempty set. Show that every subset ⊆
𝒫(X) has both a supremum and an infimum in (𝒫(X)‚ ⊆).
➐
Give an example of a poset that has a unique minimal element, which that is not a least one.
➑
Give an example of a poset that has infinitely many maximal elements.
➒∗Let X be an infinite set. Show that the poset (𝒫(X)‚ ⊆) is not well founded. (Hint: in order
to do this, it is sufficient to exhibit an infinite strictly descending chain of elements of 𝒫(X).
The key idea is that what remains after removing a single element from an infinite set is
again an infinite set.)

68
Logic and Discrete Mathematics: A Concise Introduction
➓∗Let (X‚ ≤) be a poset and Y ⊆X. Show that if Y has a supremum in X, then it is unique.
11∗Let R be a pre-order in X. Prove that the relation ∼on X defined by
x ∼y iff
xRy and yRx
is an equivalence relation on X (see Proposition 2.6.4).
12∗Show that if (X‚ ≤) is a poset and Y ⊆X, then (Y‚ ≤∣Y) is also a poset.
13∗Complete the proof of Proposition 2.6.20, i.e. show that a linear order (X‚ ≤) is a well order
if and only if every nonempty subset of X has a least element.
The axiom of choice
The axiom of choice states that, given any set {Ai ∣i ∈I} of non-empty, pairwise disjoint sets Ai,
there exists a set X containing exactly one element from each Ai. Various different, but equivalent,
forms of the axiom of choice are known and used, including the often-encountered principle known
as Zorn’s Lemma.
The axiom is not needed in case there are only finitely many Ais or if the set X can be explicitly
defined in some way. For example, suppose that each set Ai is a subset of the natural numbers and
that the Ais are pairwise disjoint. Then, by the well-ordering of the natural numbers (see Section
2.6.4), each Ai has a least element. We could then define X to consist of the least element from each
of the sets Ai. So defined, X would contain exactly one element from each Ai, but its existence would
not depend on the axiom of choice.
Another example is due to Bertrand Russell (see the box at the end of Section 4.3 in Chapter
4): suppose I have denumerably many pairs of shoes {Pi ∣i ∈ℕ}. I could construct a set containing
one shoe from each pair by, for example, choosing the left shoe from each pair. In contrast, if I had
denumerable many pairs of socks {Si ∣i ∈ℕ}, because the socks in a pair are identical, I would not
be able to specify such a procedure for picking exactly one from each pair. I would need to appeal
to the axiom of choice to justify the existence of a set containing exactly one sock from each pair.
The axiom of choice cannot be derived from the other axioms of Zermelo–Fraenkel (see Section
2.5) set theory and must consequently be added as a separate axiom if we want to use it. There
is some controversy attached to the axiom of choice as some mathematicians have objected to it
on philosophical grounds. Also, using this axiom one can prove the existence of nonmeasurable
sets of real numbers, which can be used to prove some rather unbelievable claims, such as the
Banach–Tarski paradox, stating intuitively that a ball of radius 1 can be partitioned into finitely many
subsets from which a ball of radius 2 can be composed. Therefore, even though the vast majority
of mathematicians accept the axiom of choice as a valid principle, it is still customary to explicitly
note its use in a proof.

Sets, Relations, Orders
69
2.7.
An introduction to cardinality
In this section we look into two somewhat more advanced topics. First, we investigate what it
means for two sets to have the same “size” – something that is intuitively clear in the case of
finite sets, but rather trickier when it comes to infinite sets. Secondly, we explore the different
shapes that well orders can come in, which leads us to the notion of ordinal.
2.7.1.
Equinumerosity and cardinality
When do two sets have the same size? Intuitively, “size” means the “number of elements”.
For finite sets the answer is easy: simply count the elements in the two sets and if you came
up with the same number in both cases they have the same size, otherwise not. When we
try to extend this to infinite sets, for example when comparing the sizes of the sets ℕand ℤ,
we run into a problem: we cannot count the number of natural numbers or the number of
integers because these sets are both infinite. Still, it seems that there are more – perhaps, twice
as many – integers than there are natural numbers: one positive and one negative integer with
the same absolute value per positive natural number. However, is that true? As we will see
below, this is, in fact, not true: actually, the sets ℕand ℤhave the same size! Perhaps even
more surprising is the fact that ℕand ℚalso have the same size. Are we therefore saying that
all infinite sets have the same size? No! We will show that ℝis strictly larger in size than ℕ,
and in fact there are infinitely many possible different “infinite sizes” of a set.
The standard way used to compare the sizes of sets takes us back to the very origins of
counting. Scholars believe that counting originated as a means of keeping track of possessions,
like livestock. In a typical scenario (see Figure 2.8), a herder would make a mark on a post or
put a pebble in the bag for each of his sheep as it left the sheep pen in the morning. In the
evening these marks would be crossed off, or the pebbles taken out of the bag, one by one, as
the sheep returned to the pen. If all marks were crossed off or all pebbles taken out, he knew
that all his sheep were safely in the pen, but if a mark or a pebble remained, that meant that
a sheep was missing. The idea being used here is that of a one-to-one correspondence (or a
bijection) between the set of sheep and the set of marks or pebbles.
Definition 2.7.1 Two sets X and Y are said to be equinumerous, or equipotent, if there exists a
bijection between them. We use the notation X ≈Y to indicate that X and Y are equinumerous.
Example 2.7.2
The sets ℕand ℤare equinumerous. To show this we need to find a bijective mapping from
ℕon to ℤ. We let f ∶ℕ→ℤbe the mapping defined by
f(n) =
{ n
2‚
n is even
−n+1
2 ‚
n is odd .
It is easy to show that f is a bijection; the details are left as Exercise 3.

70
Logic and Discrete Mathematics: A Concise Introduction
Figure 2.8: A one-to-one correspondence between marks on a post and a ﬂock of sheep
Example 2.7.3
Now, as promised, we show that ℕand ℚare equinumerous, by constructing a function
from ℕon to ℚ. It is not so easy to specify this function with an explicit formula as we did in
Example 2.7.2. Instead we describe how the desired function works. We begin by arranging
all fractions a∕b, with a ∈ℤand b ∈ℕ−{0}, in a grid as follows:
· · ·
−3
1 ∗
−2
1 ∗
←
−1
1 ∗
0
1 ∗
→
1
1 ∗
2
1 ∗
→
3
1 ∗
· · ·
↑
↓
↑
↓
↑
↓
· · ·
−3
2 ∗
−2
2
−1
2 ∗
←
0
2
←
1
2 ∗
2
2
3
2 ∗
· · ·
↑
↓
↑
↓
↑
↓
· · ·
−3
3
−2
3 ∗
→
−1
3 ∗
→
0
3
→
1
3 ∗
→
2
3 ∗
3
3
· · ·
↑
↓
· · ·
−3
4 ∗
←
−2
4
←
−1
4 ∗
←
0
4
←
1
4 ∗
←
2
4
←
3
4 ∗
· · ·
⋮
⋮
⋮
⋮
⋮
⋮
⋮
Since every rational can be represented in this way, every rational number occurs in the
grid. In fact every rational occurs infinitely often, e.g. 1∕2 occurs as 1∕2, 2∕4, 3∕6, 4∕8‚ ….
Next we trace a path through the grid as indicated by the arrows, starting at 0∕1. We put a
star on each rational number when it occurs on the path for the first time, e.g. we star 1∕1
but but not 2∕2. Now define g ∶ℕ→ℚby specifying that g maps n to the (n + 1)st starred
rational number. Thus g(0) = 0∕1, g(1) = 1∕1, g(2) = 1∕2, g(3) = −1∕2, g(4) = −1∕1, etc. Since
the range of g consists of exactly the starred fractions in the grid, it follows that g is injective.
Also, since every rational occurs in the grid and is visited by the path, it will be the image of
some natural number under g, i.e. g is surjective.

Sets, Relations, Orders
71
Until now we have been relying on an intuitive understanding of what it means for a set to
be finite or infinite. It is time we made these notions a little more precise. We use the notation
ℕn, where n ∈ℕ, for the set {0‚ 1‚ …‚ n −1}. Note that ℕn has n elements and, in particular, that
ℕ0 = ∅.
Definition 2.7.4 A set X is finite if it is equinumerous to ℕn for some n ∈ℕ. If X is not finite, then
it is infinite.
The finite sets together with those equinumerous to ℕare called countable:
Definition 2.7.5 A set is called denumerable (or countably infinite) if it is equinumerous to ℕ. A
set is countable if it is either finite or denumerable. A set that is not countable is uncountable.3
We have seen that the natural numbers, the integers and the rationals are all countable
sets. What about the set of real numbers? We will show that this is an uncountable set, but
first we will need a preliminary lemma. Since subsets are “smaller” than their supersets it
seems plausible that subsets of countable sets should be countable. This is indeed the case, as
stated by the next lemma. The proof is left as an exercise (see Exercise 8).
Lemma 2.7.6 If a set X is countable and Y ⊆X, then Y is also countable.
Theorem 2.7.7 The set ℝof real numbers is not countable.
Proof: We will show that the subset I = {x ∈ℝ∣0 ≤x ≤1} is uncountable. The theorem then
follows by Lemma 2.7.6. Suppose, for the sake of contradiction, that there is a surjective func-
tion f ∶ℕ→I. We make use of the fact that every number in I has a decimal representation
of the form 0.a1a1a3⋅, where each ai is a digit between 0 and 9. (It can be shown that if a real
number has two decimal representations, one representation always terminates in repeating
0s and the other in repeating 9s. Specifically, 1 = 0. ̇9.) We can enumerate the numbers in the
range of f as follows:
f(0) = 0 ⋅a01a02a03…a0n · · ·
f(1) = 0 ⋅a11a12a13…a1n · · ·
f(2) = 0 ⋅a21a22a23…a2n · · ·
⋮
f(n) = 0 ⋅an1an2an3…ann · · ·
⋮
We will now construct a number in I that is not a value of f. Let y = 0 ⋅y1y2y3 · · · yn · · ·,
where
yn =
{
2
if ann ≥5
7
if ann ≤4 ⋅
3 In some texts the word countable is used more narrowly to refer to countably infinite sets. It is good to be aware
of these differing usages in order to avoid the confusion that this can cause.

72
Logic and Discrete Mathematics: A Concise Introduction
Note that y cannot be equal to f(n) for any n ∈ℕ. Indeed, by construction, yn ≠ann, because
y and ann differ in the nth decimal place. (Note also that y is not a real number with two decimal
representations as it does not contain 0 or 9 as a digit.) Thus, y ∉rng(f), contradicting the
assumption that f is on to I.
We began this subsection by noting that we could compare the sizes of finite sets by count-
ing their elements, i.e. we can associate a number with each set (its size) and compare the
numbers. We would like to be able to associate in this way some abstract “numbers” also with
infinite sets. This should be done in such a way that equinumerous sets are of the same asso-
ciated “number”. The abstract number associated with a set in this way is called the cardinal
number, or the cardinality, of the set.
Definition 2.7.8 With any set X we associate a cardinal number, denoted |X|, in such a way that
|X| = |Y| iff X ≈Y. Specifically:
1. For any finite set S the cardinality |S| of S is its number of elements, i.e. the natural number n
for which S ≈ℕn.
2. |ℕ| = ℵ0. Hence, the cardinality of every denumerably infinite set is ℵ0.
3. |ℝ| = 𝔠, where 𝔠is known as the cardinality of the continuum.
The natural numbers are the finite cardinal numbers; all other cardinals numbers are infinite car-
dinal numbers.
Therefore, for example, we have {a‚ b‚ c} = 3, |ℕn| = n and |{0‚ 2‚ 4‚ 6‚ 8‚ 10‚ …}| = ℵ0.
To be able to compare different cardinal numbers we impose the following ordering:
Definition 2.7.9 Let 𝜆and 𝜅be cardinal numbers and K and L sets such that |K| = 𝜅and |L| = 𝜆.
Then we define
𝜅≤𝜆if and only if there exists an injection f ∶K →L.
We write 𝜅< 𝜆if 𝜅≤𝜆and 𝜅≉𝜆.
Proposition 2.7.10 The relation ≤defined on cardinal numbers in Definition 2.7.9 is a well-defined
linear order. Moreover, if X ⊆Y, then |X| ≤|Y|.
Proof: We only sketch an outline of the proof. The details are left as Exercise 12.
To prove that ≤is well defined on cardinal numbers, we need to show that it does not
depend on particular choices of sets of the given cardinality. That is, we need to show that if
|K1| = 𝜅= |K2| and |L1| = 𝜆= |L2|, then there exists an injection f ∶K1 →L1 if and only if there
exists an injection f ∶K2 →L2. This is an easy exercise.
Then, to show that ≤is of linear order we need to show the following:
• ≤is reflexive. For that it is enough to show that, for every set X, there exists an injection
f ∶X →X.
• ≤is transitive. For that it is enough to show that if there exist injections f ∶X →Y and g ∶
Y →Z, then there exists an injection h ∶X →Z.

Sets, Relations, Orders
73
• ≤is antisymmetric. For that it is enough to show that if there exits injections f ∶X →Y and
g ∶Y →X, then X ≈Y. This is the claim of a well-known theorem in Set Theory, known as
the Cantor–Schröder–Bernstein Theorem, the proof of which is can be found in most advanced
texts on Set Theory and will not be given here.
• Lastly, ≤is total, i.e. that for any sets X and Y either |X| ≤|Y| or |Y| ≤|X|. In other words,
we need to prove that either there exists an injection f ∶X →Y or an injection g ∶Y →X.
The proof of this requires the use of the Axiom of Choice. In fact, it can be shown that this
assertion is equivalent to the Axiom of Choice. Again, a proof of this claim can be found in
most advanced textbooks on Set Theory.
Showing that |X| ≤|Y| when X ⊆Y is easy – see Exercise 12.
We are now in a position to compare the cardinal numbers we have encountered so far.
Theorem 2.7.11 (Comparing cardinal numbers)
1. n ≤ℵ0 for every natural number n ∈ℕ.
2. ℵ0 < 𝔠.
3. ℵ0 is the least infinite cardinal, i.e. ℵ0 ≤𝜅for all infinite cardinals 𝜅.
Proof: We leave item (1) as Exercise 11.We omit the proof of item (3), which requires the use
of the Axiom of Choice, and only prove (2). Since ℕ⊆ℝwe know by Proposition 2.7.10 that
|ℕ| ≤|ℝ|, i.e. ℵ0 ≤𝔠. To obtain the strict inequality it is therefore enough to know that ℵ0 ≉𝔠,
which is exactly what Theorem 2.7.7 says.
2.7.2.
Exercises
➊
Show that ℤis equinumerous to the set E of even integers.
➋
Determine the cardinalities of the following sets:
(a) {𝛼‚ 𝛽‚ 𝛾‚ 𝛿‚ 𝜖}
(b) {x ∈ℤ∣x2 = 4}
(c) {x ∈ℚ∣3 ≤x ≤4}
(d) {(x‚ y) ∈ℝ∣x2 + y2 = 3}
➌
Show that the function f defined as
f(n) =
{ n
2‚
n is even
−n+1
2 ‚
n is odd
in Example 2.7.2 is a bijection between ℕand ℤ.
➍
For any n ∈ℕ, let Sn be the set of binary sequences of length n. Show that 𝒫(ℕn) ≈Sn.
➎
Show that if A and B are finite sets then A × B is finite.
➏
Let be a set of sets. Show that the equinumerosity relation restricted to is an equiva-
lence relation.

74
Logic and Discrete Mathematics: A Concise Introduction
➐
Show that if S is a countable set and a ∉S, then the set S ∪{a} is also countable.
➑
Show that if a set X is countable and Y ⊆X, then Y is also countable. (Hint: it is sufficient
to show that every subset of ℕis countable.)
➒
Let A and B be countable sets. Show that the following sets are countable:
(a) A ∩B
(b) A ∩B
(c) A × B
➓
For any n ∈ℕ, let Fn be the set {f ∣f ∶ℕn →{0‚ 1}} of all functions from ℕn into the
two-element set {0‚ 1}. Show that 𝒫(ℕn) ≈Fn.
11** Prove that n < ℵ0 for every natural number n ∈ℕ.
12** With this exercise we fill in the details left out in the proof of Proposition 2.7.10.
(a) Show that if |K1| = 𝜅= |K2| and |L1| = 𝜆= |L2|, then an injection f ∶K1 →L1 exists if
and only if an injection f ∶K2 →L2 exists.
(b) Show that for every set X there exists an injection f ∶X →X. Now conclude that ≤is
transitive on cardinal numbers.
(c) Show that, for all sets X, Y and Z, if there exist injections f ∶X →Y and g ∶Y →Z
then there exists an injection h ∶X →Z. Now conclude that ≤is transitive on cardinal
numbers.
(d) Show that if X ⊆Y then there exists an injection f ∶X →Y. Now conclude that if X ⊆Y
then |X| ≤|Y|.
The continuum hypothesis
We have seen that the cardinality of the set of natural numbers is strictly less than the cardinality
of the set of real numbers, i.e.
|ℕ| = ℵ0 < 𝔠= |ℝ|.
However, are there sets that have cardinality strictly in between ℵ0 and 𝔠? The statement that there
are no such sets is known as the Continuum Hypothesis (CH). If ℵ1 denotes the least cardinal number
greater than ℵ0, then the CH asserts that ℵ0 = 𝔠, i.e. that the first cardinal greater than ℵ0 is equal
to the cardinality of the continuum of real numbers, whence the name “continuum hypothesis”.
The problem to determine whether the CH is true or false was the first one on Hilbert’s (see
the box at the end of Section 3.3 in Chapter 3) famous list of 23 open problems, published in 1900.
Hilbert’s Problems exerted a very significant influence on the mathematics of the 20th century, and
problem 1 was no exception. In 1940 Kurt Gödel (see the box at the end of Section 4.4 in Chapter
4) showed that the CH cannot be disproved within ZFC (see the box in Section 2.5). In 1963 Paul
Cohen proved that the CH cannot be proven within ZFC either. For this work he was awarded the
Fields Medal, which is the highest award in mathematics. The combined consequence of these two

Sets, Relations, Orders
75
results is that the CH is independent of ZFC, which means that our fundamental intuitions about
sets, as captured by the axioms of ZCF, do not imply anything about the (non-)existence of sets
with cardinality in between ℵ0 and 𝔠.
How does one interpret this situation? Those who feel that mathematics is a human creation
might say that this means that it is up to mathematicians to decide whether they want the CH to
be true or false. In other words, we can decide whether we want sets with cardinalities strictly in
between that of the naturals and that of the reals to exist or not. Depending on what we decide, we
can simply add an axiom to our set theory that would make it so. On the other hand, those who feel
that mathematical objects have an existence independent of human thought, often referred to as Pla-
tonists, might claim that the CH is either true or false, but we just do not know yet. Accordingly, they
would claim that ZFC is simply too weak to capture all there is to know about the independently
existing realm of sets.
2.8.
Isomorphisms of ordered sets. Ordinal numbers
In the previous subsection we were comparing the sizes of sets and the associated numbers
were cardinal numbers. Here we will be looking specifically at well-ordered sets and compare
the “lengths” of their orderings. The first tool we will need for this endeavour is the notion of
an order preserving map.
Definition 2.8.1 Let (X‚ ≤X) and (Y‚ ≤Y) be posets. An order preserving map between X and Y is a
map f ∶X →Y that respects the order, i.e. for all x1‚ x2 ∈X
x1 ≤X x2 if and only if f (x1) ≤Y f(x2).
If, in addition, f is a bijection, it is called an order isomorphism between X and Y. If there is
an order isomorphism between (X‚ ≤X) and (Y‚ ≤Y) we say that they are order isomorphic and write
(X‚ ≤X) ≅(Y‚ ≤Y), or simply X ≅Y if the ordering relations are clear from the context.
This definition has the following immediate consequence.
Proposition 2.8.2 Every order preserving map is an injection.
Proof: Let f ∶X →Y be an order preserving map between posets (X‚ ≤X) and (Y‚ ≤Y). Suppose
f(x1) = f(x2). Therefore, f(x1) ≤Y f(x2). Since f is order-preserving, it follows that x1 ≤X x2. Sim-
ilarly, f(x2) ≤Y f(x1) and hence x2 ≤X x1. We conclude that x1 = x2.

76
Logic and Discrete Mathematics: A Concise Introduction
Example 2.8.3
1. The map f ∶ℕ→ℤwhich sends every natural number to itself in an order preserving
map. It is not an order isomorphism, since it is not surjective.
2. The map g ∶ℕ→ℕdefined by f ∶n →2n is an order preserving map between ℕand itself.
Again, it is not an order isomorphism as it is not surjective.
3. Below are Hasse diagrams of two-order isomorphic posets. The action of the isomorphism
is indicated by the dashed arrows. On the left is the poset consisting of the powerset of the
three-element set {a‚ b‚ c} with the inclusion relation ⊆. The poset on the right consists of
the set {1‚ 2‚ 3‚ 5‚ 6‚ 10‚ 15‚ 30} with the divisibility relation.
{a, b, c}
{a, b}
{a, c}
{b, c}
{a}
{b}
{c}
30
6
10
15
2
3
5
1
Saying that two posets are isomorphic means that they are essentially the same poset:
even though the elements might have different names, there are “equal numbers” of them
in both posets and, as far as the ordering relation is concerned, they are arranged in exactly
the same way. The word “isomorphic” means “to have the same shape”, and most kinds of
mathematical structures have an associated notion of isomorphism: we talk of isomorphic
first-order structures, isomorphic graphs, isomorphic groups and many more. If two mathe-
matical structures are isomorphic, a mathematician would regard them as the same structure
“up to isomorphism”.
The following proposition says that, up to isomorphism, there is only one well-ordered
set of any given finite cardinality. For the proof, see Exercise 7.
Proposition 2.8.4 If (X‚ ≤X) and (Y‚ ≤Y) are finite well-ordered sets such that |X| = |Y|, then
(X‚ ≤X) ≅(Y‚ ≤Y).
To every well order X we want to assign a number ord(X), called the ordinality of X, in
such a way that ord(X) = ord(Y) if and only if X ≅Y. Together with the ordinals we want to
define a well-ordering relation in such a way that, for every set of ordinals, there is a least
ordinal strictly greater than every ordinal in the set.

Sets, Relations, Orders
77
The least ordinal is the natural number 0. The next ordinal is the natural number 1, etc. In
fact, all natural numbers are ordinals, and they are ordered by the usual ordering of the natural
numbers. These are the finite ordinals. The least ordinal greater than all finite ordinals is called
𝜔. It corresponds to the ordering of all natural numbers ℕ. The next ordinal is 𝜔+ 1, then
𝜔+ 2, 𝜔+ 3 and so on. The least ordinal greater than all members of {𝜔+ n ∣n ∈ℕ} is 𝜔+ 𝜔,
written 𝜔⋅2. The next ordinal is 𝜔⋅2 + 1, then 𝜔⋅2 + 2 and so on. The least ordinal greater than
all members of {𝜔⋅2 + n ∣n ∈ℕ} is 𝜔⋅3. Now the least ordinal greater than all members of
{𝜔⋅m + n ∣n‚ m ∈ℕ} is 𝜔⋅𝜔= 𝜔2. The least ordinal greater than all ordinals in {𝜔2 ⋅n ∣n ∈ℕ}
is 𝜔3, and the least ordinal greater than all ordinals 𝜔n, n ∈ℕ, is 𝜔𝜔. Summarizing:
0 < 1 < 2 < · · · < 𝜔< 𝜔+ 1 < 𝜔+ 2 < · · · < 𝜔⋅2 < 𝜔⋅2 + 1 < · · · < 𝜔⋅n < 𝜔⋅n + 1 < · · ·
< 𝜔2 < 𝜔2 + 1 < · · · < 𝜔2 ⋅2 < 𝜔2 ⋅2 + 1 < · · · < 𝜔2 ⋅n < 𝜔2 ⋅n + 1 < · · · < 𝜔3 < 𝜔3 + 1 < · · ·
< 𝜔n < 𝜔n + 1 < · · · 𝜔𝜔< · · · .
Every ordinal 𝛼has a direct successor, namely 𝛼+ 1, which is the least ordinal strictly
greater than it. Not every ordinal has a direct predecessor, however: the direct predecessor
of 3 is 2 and the direct predecessor of 𝜔+ 1 is 𝜔, but 𝜔has no direct predecessor. Ordinals
with direct predecessors are called successor ordinals and those with predecessors but with
no direct ones are limit ordinals. For example, all positive natural numbers are successor
ordinals, while ordinals like 𝜔, 𝜔⋅2, 𝜔5 and 𝜔𝜔are limit ordinals.
In fact, we can define all ordinals as special sets, so that every ordinal 𝛼is the well-ordered
set {𝛽∣𝛽< 𝛼} of all ordinals strictly less than 𝛼, as follows. Since there are no ordinals strictly
less than 0, we declare the ordinal 0 to be identical with the empty set ∅. The only ordi-
nal strictly less than 1 is 0, so the ordinal 1 is the set {0} = {∅}. Similarly, the ordinal 2 is
{0‚ 1} = {∅‚ {∅}}, 3 is {0‚ 1‚ 2} = {∅‚ {∅}‚ {∅‚ {∅}}}, and so forth. In general, for any natural
number n, the set ℕn = {0‚ …‚ n −1} together with the usual ordering on natural numbers is
the well-ordered set of ordinals less than n, i.e. it is the ordinal n. Hereafter, we will identify
every finite ordinal n with the number n. Further, the ordinal 𝜔is the same as the well-ordered
set ℕof all natural numbers; then 𝜔+ 1 = {0‚ 1‚ 2‚ …‚ 𝜔}, etc.
Eventually, it can be shown that every well-ordered set is order isomorphic to a unique
ordinal. We can therefore define the “ordinality” of a well-ordered set unambiguously.
Definition 2.8.5 The ordinality of a well ordered set X, denoted ord(X), is the unique ordinal number
𝛼such that 𝛼≅X.
In particular, ord(ℕn) = n for every natural number n and ord(ℕ) = 𝜔.
Here are two more examples of ordinalities of well-ordered sets.

78
Logic and Discrete Mathematics: A Concise Introduction
Example 2.8.6
Consider the well-ordered set ℕ∗= ℕ∪{0′} consisting of the natural numbers with their
usual ordering together with the new element 0′, which we declare to be greater than every
natural number.
0
1
2
3
0′
Let f ∶ℕ∗→𝜔+ 1 be the map defined by
f(x) =
{
x
if x ∈ℕ
𝜔
if x = 0′ .
This is an order isomorphism between ℕ∗and 𝜔+ 1. Thus ord(ℕ∗) = 𝜔+ 1.
Example 2.8.7
Consider the well ordered set A = ℕ∪ℕ′ where ℕ′ = {n′ ∣n ∈ℕ} together with the
well-ordering relation ≤A defined as ≤A =:
{(n‚ m) ∈ℕ× ℕ∣n ≤m}∪
{(n′‚ m′) ∈ℕ′ × ℕ′ ∣n ≤m}∪
{(n‚ m′) ∣n ∈ℕand m′ ∈ℕ′}.
In other words, A consists of two copies of the natural numbers, each with the usual
ordering, but the second copy placed “after” the first such that each of its members is greater
than each member of the first copy.
0
1
2
3
0′
1′
2′
3′
Let g ∶A →𝜔⋅2 be the map defined by
g(x) =
{
x
if x ∈ℕ
𝜔+ n
if x = n′ .
This is an order isomorphism between A and 𝜔⋅2 (see Exercise 4), so ord(A) = 𝜔⋅2.

Sets, Relations, Orders
79
2.8.1.
Exercises
➊
Let X = {∅‚ {1}‚ {2}‚ {1‚ 3}‚ {1‚ 4}‚ {2‚ 5}‚ {2‚ 6}}. Show that (X‚ ⊆) is order isomorphic to
the set of binary string of length at most 4 ordered by the initial segment relation (see
Exercise 2 from Section 2.6.5).
➋
Show that if two posets are order isomorphic then they are equinumerous.
➌
Show that the map defined in Example 2.8.6 is an order isomorphism.
➍
Show that the map defined in Example 2.8.7 is an order isomorphism.
➎
Show that 𝜔⋅n is a countable set, for every n ∈ℕ.
➏
Let X be a nonempty set and let 2X = {f ∣f ∶X →{0‚ 1}} be the set of all maps from X into
the set {0‚ 1}. Define a relation ≦on 2X such that f1 ≦f2 iff f1(x) ≤f2(x) for all x ∈X.
(a) Show that (2X‚ ≦) is a poset.
(b) Show that (2X‚ ≦) is order-isomorphic to (𝒫(X)‚ ≤).
➐** The aim of this exercise if to prove Proposition 2.8.4.
(a) Let (Z‚ ≤Z) be a well order and z0 the least element of Z. Prove that (Z −{z0}‚ ≤′
Z) is a
well order, where ≤′
Z is the restriction of ≤′
Z to Z −{z0}.
(b) Let (Z‚ ≤Z) be a well order and a an element not occurring in Z. Prove that (Z ∪{a}‚ ≤+
Z)
is a well order, where ≤+
Z= ≤Z ∪{(a‚ a)} ∪{(a‚ z) ∣z ∈Z}. That is to say, (Z ∪{a}‚ ≤+
Z) is
obtained from (Z‚ ≤Z) by adding the new element a and declaring it to be the new least
element.
(c) Let (X‚ ≤X) and (Y‚ ≤Y) be well orders, a‚ b ∉X ∪Y, and (X ∪{a}‚ ≤+
X) and (Y ∪{b}‚ ≤+
Y)
obtained by adding a and b as respective new least elements of X and Y. Then prove
that if (X‚ ≤X) ≅(Y‚ ≤Y) then (X ∪{a}‚ ≤+
X) ≅(Y ∪{b}‚ ≤+
Y).
(d) Now prove that if (X‚ ≤X) and (Y‚ ≤Y) are finite well-ordered sets such that |X| = |Y|,
then (X‚ ≤X) ≅(Y‚ ≤Y). Do this by induction in n = |X| using the three claims above for
the induction step.

80
Logic and Discrete Mathematics: A Concise Introduction
Hilbert’s Hotel
Here is a story that originally appeared in the 1947 book One, Two, Three, … Infinity by the physicist
George Gamow (1904–1968). In a certain city there is a hotel, called Hilbert’s Hotel, with denumerably
many rooms, numbered 0‚ 1‚ 2‚ 3‚ 4‚ …. One evening a weary travel arrives at the front desk and asks
for a room, only to be informed that the hotel is completely full. However, after a moment’s thought
the clerk says: “Wait a minute, Sir. I think we can still accommodate you, but it will take a bit of
rearranging. I will ask every guest to move to the room with number one greater than the room he
or she is currently occupying. That way room 0 will become vacant and we can put you in there.”
So even though this hotel may be completely booked out, it can always accommodate one more
guest, and then one more, and then another, and so on. Of course, this is possible because we can
always define an injection from an infinite set to a proper subset of itself. In the example above the
injection is f ∶ℕ→ℕ, given by f(n) = n + 1, which increases the room number of each current guest
by one and thus making room for the new guest in room 0, where no current guest is sent. In fact it
is not essential that the new guest be placed in room 0: we could vacate room n for him by simply
moving every one in a room with number n or higher up one room. Moreover, even if countably
many new guests arrive at the same time after Hilbert’s Hotel is fully occupied, the receptionist can
still accommodate them, by asking the guest in room n to move to room 2n for every n ∈ℕ, thus
freeing all odd-numbered rooms.
This is an example of an apparently paradoxical situation, which arises when we try to think of
infinite versions of finite physical objects, like hotels. Since all sets in the physical world are finite,
our intuitions are often baffled by the infinite.
2.9.
Application: relational databases
A relational database consists of a number of tables filled with data items. Here are three tables
from the database of a veterinary clinic.
The rows in a table form n-tuples – 3-tuples, 5-tuples and 3-tuples, respectively, in the case
of Tables 2.1, 2.2 and 2.3 – with the coordinates of the tuples coming from particular sets – in
Table 2.1 from the sets of character strings, real numbers and the set {Y,N}, respectively. Look-
ing at a table in this way suggests that it can be seen as an n-ary relation between sets. This
is precisely what the relational database model does and what enables it to bring the math-
ematical theory of relations to bear on the problems of data manipulation and retrieval. As
our tables show, apart from the n-tuples forming the rows of the table (and the elements in
the relation) we also need names for the columns, which are referred to as the attributes of
the table.

Sets, Relations, Orders
81
Table 2.1 Clients
Client Name
Account balance
Payments-up-to-date
N Bates
−45.93
N
L du Plessis
+0.12
Y
V Tshabalala
−76.01
Y
A Winterbottom
−235.54
N
Table 2.2 Pets
Pet Name
Type
Breed
Owner
Vet Name
Fluffy
Dog
Maltese
L du Plessis
Dr Dolittle
Nefertiti
Cat
Sphinx
A Winterbottom
Dr Dolittle
Mopsy
Dog
Cross breed
L du Plessis
Dr Yang
Tiger
Cat
Domestic shorthair
A Winterbottom
Dr Dolittle
Butch
Dog
Bulldog
V Tshabalala
Dr Yang
Montgomery
Cat
Domestic longhair
N Bates
Dr Khumba
Table 2.3 Vets
Vet Name
Staff ID
Day off
Dr Dolittle
A64B8
Sat
Dr Yang
A57C6
Mon
Dr Khumba
A55B9
Sun
Definition 2.9.1 An n-ary relation schema R(A1‚ A2‚ …‚ An) is an n-tuple (A1‚ A2‚ …‚ An) of
attributes each with an associated data type, denoted DT(Ai). Here attributes are simply names and
the data type DT(Ai) is a set.
An instance of an n-ary relation schema R(A1‚ A2‚ …‚ An) is an n-ary relation
R ⊆DT(A1) × DT(A2) × · · · × DT(An).
In other words, an instance of R(A1‚ A2‚ …‚ An) is a relation with matching arity (n-ary) and where
each coordinate from each n-tuple in the relation is of the right data type.
A relational database schema is a set of relation schemas and an instance of is a set con-
sisting of an instance of each of the relation schemas in .
Consider the relation schemas:
• CLIENT(Client Name, Account balance, Payments-up-to-date) with
– DT(Client Name) = STRING;
– DT(Account balance) = ℝ;

82
Logic and Discrete Mathematics: A Concise Introduction
– DT(Payments-up-to-date) = {Y‚ N}.
• PET(Pet Name, Type, Breed, Owner, Vet Name) with
– DT(Pet Name) = STRING;
– DT(Type) = {Cat‚ Dog‚ Bird‚ Reptile‚ Rodent};
– DT(Breed) = STRING;
– DT(Owner) = STRING;
– DT(Vet Name) = STRING.
• VET(Vet Name, Staff ID, Day off) with
– DT(Vet Name) = STRING;
– DT(Staff ID) = STRING ;
– DT(Name) = DAY = {Mon‚ Tue‚ Wen‚ Thu‚ Fri‚ Sat‚ Sun}.
The relations given by Tables 2.1, 2.2 and 2.3 are instances of the relation schemas CLIENT,
PET and VET, respectively. These tree tables, taken together, are an instance of the relational
database schema {CLIENT‚ PET‚ VET}.
Relational databases are not simply stores of information: their true usefulness lies in the
queries that can be made on them. For example, we might want to retrieve the account balances
of all clients who have pets treated by Dr Yang, or retrieve a list of all vets who treat cats
and who have their day off on Wednesday. These queries may be answered by performing
appropriate set theoretic operations on the relations (= tables). The study of operations on
relations dates back to the work of mathematicians like Augustus De Morgan (1806–1871),
Charles Peirce (1839–1914) and Ernst Schröder (1841–1902). There is a standard set of such
operations used for database queries, known as the relational calculus, which was introduced
by Edgar F. Codd in the 1970s.
Intersection of relations
Let R and S be n-ary relations that are instances of the same relation schema. Then we can
form their set-theoretic intersection, namely
R ∩S = {(a1‚ …‚ an) ∣(a1‚ …‚ an) ∈R and (a1‚ …‚ an) ∈S}.
Difference of relations
Let R and S be n-ary relations that are instances of the same relation schema. Then we can
form their set-theoretic difference, namely
R −S = {(a1‚ …‚ an) ∣(a1‚ …‚ an) ∈R and (a1‚ …‚ an) ∉S}.

Sets, Relations, Orders
83
Flattened Cartesian product
Let R be an n-ary and S an m-ary relation. Then we can form their flattened Cartesian product,
namely the (n + m)-ary relation
R × S = {(a1‚ …‚ an‚ b1‚ …‚ bm) ∣(a1‚ …‚ an) ∈R and (b1‚ …‚ bm) ∈S}.
Note that this is different from the ordinary Cartesian product, which would yield a set of
ordered pairs
{((a1‚ …‚ an)‚ (b1‚ …‚ bm)) ∣(a1‚ …‚ an) ∈R and (b1‚ …‚ bm) ∈S}
instead of a set of (n + m)-tuples.
Projection
Let R be an n-ary relation that is an instance of a relation schema R(A1‚ A2‚ …‚ An). If
{Ai1‚ …‚ Aim} ⊆{A1‚ A2‚ …‚ An} we can form the projection of R on to coordinates (Ai1‚ …‚ Aim),
namely
𝜋Ai1‚…‚ Aim(R)
= {(a1‚ …‚ am) ∣there exists (b1‚ …bn) ∈R such that a1 = bi1‚ …‚ am = bim}.
In other words, the projection function forms a new relation by keeping only the indicated
coordinates from the tuples in the original relation, rearranged in the order indicated. For
example, if Pets is the relation defined in Table 2.2, then the projection 𝜋Owner,Pet Name(Pets) is
the relation given in Table 2.4.
Selection
The selection operation allows one to select the the elements of a relation (= rows in a table)
that satisfy a certain condition. The conditions are expressions built in the following way:
Atomic conditions (1). If A1 and A2 are attributes of the same data type and c is a constant
of this data type, then A1 = A2, A1 ≠A2, A1 = c and A1 ≠c are atomic conditions.
Table 2.4 𝜋Owner,Pet Name(Pet)
Owner
Pet Name
L du Plessis
Fluffy
A Winterbottom
Nefertiti
L du Plessis
Mopsy
A Winterbottom
Tiger
V Tshabalala
Butch
N Bates
Montgomery

84
Logic and Discrete Mathematics: A Concise Introduction
Table 2.5 ΘVet=DrDolittle∧Type=Cat(Pets)
Pet Name
Type
Breed
Owner
Vet
Nefertiti
Cat
Sphinx
A Winterbottom
Dr Dolittle
Tiger
Cat
Domestic shorthair
A Winterbottom
Dr Dolittle
Table 2.6 ΘAccountbalance<−100∧Payments−up−to−date=N(Clients)
Client Name
Account balance Payments-up-to-date
A Winterbottom
−235.54
N
Atomic conditions (2). If A1 and A2 are attributes of the same data type, c is a constant of
the data type and ≤is a linear order on the elements of this data type, then A1 ≤A2, A1 < A2,
A1 ≰A2, A1 ≤c, A1 < c, A1 ≰c, c ≤A2, c < A2, c ≰A2 are atomic conditions.
Compound conditions. If 𝜙1 and 𝜙2 are conditions, then 𝜙1 ∧𝜙2 and 𝜙1 ∨𝜙2 are conditions.
Here are some conditions using attributes from our running veterinary example:
Vet = DrDolittle ∨Vet = DrYang,
Vet = DrDolittle ∧Type = Cat,
Day off ≠Saturday
and
Accountbalance < −100 ∧Payments −up −to −date = N.
The selection operation applies conditions to relations (= tables) and returns the elements
(= rows) that satisfy the condition. To be precise, if 𝜙is a condition and R a relation, then
Θ𝜙(R) = {(a1‚ …‚ an) ∈R ∣(a1‚ …‚ an) satisfies 𝜙}.
For example, the results of selection ΘVet=DrDolittle∧Type=Cat(Pets) and
ΘAccountbalance<−100∧Payments−up−to−date=N (Clients) are given in Tables 2.5 and 2.6, respectively.
Definition 2.9.2 Relational algebra consists of the following five operations on relations: union,
difference, flattened Cartesian product, projection and selection.
As we have seen, the operations of relational algebra can be used to answer queries on
databases. However, the real power of these operations lies in their composition. Suppose we
want to retrieve a list of all pets with the days of the week on which their vets are off, needed
for scheduling appointments. Here is what we do: since this query asks for information that is
spread over two tables, namely Pets and Vets, we first need to bring this information into one
table. The only operation of relational algebra that can do this for us is the flattened Cartesian
product. Accordingly we form
Pets × Vets.
This table will contain rows in which the values of the attribute Vet Name coming from table
Pets does not match with the value of the attribute Vet Name coming from table Vets. To elim-
inate such rows we apply the selection operation as follows:
ΘVets.Vet Name=Pets.Vet Name(Pets × Vets)‚

Sets, Relations, Orders
85
Table 2.7 ΘVets.Vet Name=Pets.Vet Name(Pets × Vets)
Pet Name
Type Breed
Owner
Pets.Vet
Name
Vets.Vet
Name
Staff ID Day off
Fluffy
Dog Maltese
L du Plessis
Dr Dolittle
Dr Dolittle
A64B8
Sat
Nefertiti
Cat
Sphinx
A Winterbottom Dr Dolittle
Dr Dolittle
A64B8
Sat
Mopsy
Dog Cross breed
L du Plessis
Dr Yang
Dr Yang
A57C6 Mon
Tiger
Cat
Domestic
shorthair
A Winterbottom Dr Dolittle
Dr Dolittle
A64B8
Sat
Butch
Dog Bulldog
V Tshabalala
Dr Yang
Dr Yang
A57C6 Mon
Montgomery Cat
Domestic
longhair
N Bates
Dr Khumba Dr Khumba A55B9
Sun
Table 2.8 Pets ⋈Vets
Pet Name
Type
Breed
Owner
Vet Name
Staff ID
Day off
Fluffy
Dog
Maltese
L du Plessis
Dr Dolittle
A64B8
Sat
Nefertiti
Cat
Sphinx
A Winterbottom
Dr Dolittle
A64B8
Sat
Mopsy
Dog
Cross breed
L du Plessis
Dr Yang
A57C6
Mon
Tiger
Cat
Domestic shorthair
A Winterbottom
Dr Dolittle
A64B8
Sat
Butch
Dog
Bulldog
V Tshabalala
Dr Yang
A57C6
Mon
Montgomery
Cat
Domestic longhair
N Bates
Dr Khumba
A55B9
Sun
where Vets.Vet Name and Pets.Vet Name is the Vet Name attributes coming from the Vets and
Pets tables, respectively. The resulting table (Table 2.7) will still contain some redundancy, since
the name of the vet will be listed twice in each row.
To eliminate redundancy, we can apply the following instance of the projection function:
𝜋Pets.Pet Name,Pets.Type,Pets.Breed,Pets.Owner,Pets.Vet Name,Vets.Staff ID,Vets.Day off
which keeps every column in ΘVets.Vet Name=Pets.Vet Name(Pets × Vets) except the copy of Vet Name,
which comes from the Vets table. The result is given in Table 2.8. The operation we just per-
formed on Pets and Vets is a very commonly used one and is known as the natural join. Here
is the formal definition:
Natural join
Let R and S be two relations which share the attributes A1‚ …‚ Ak. Then the natural join of R
and S is given by
R ⋈S = 𝜋⟨list⟩(ΘR.A1=S.A1‚…‚ R.Ak=S.A(R × S))
where ⟨list⟩is the list of all attributes of R or S, other than S.A1‚ …S.Ak. The result of applying
the natural join to Pets and Vets is given in table 2.8.

86
Logic and Discrete Mathematics: A Concise Introduction
2.9.1.
Exercises
➊Consider Tables 2.9–2.12 from the database of a university. Compute the following tables:
(a) Enrollment2014 ∩Enrollment2013
(b) Enrollment2014 −Enrollment2013
(c) Student × Lecturer
(d) 𝜋Name‚ StudyYear(Student)
(e) Θ1<StudyYear(Student)
(f) Student ⋈Enrollment2014
(g) 𝜋Name‚ Course(Student ⋈Enrollment2014)
➋Write down relational algebra queries on Tables 2.9–2.12 that would produce:
(a) The student ID of every student that was enrolled for Psychology both in 2013 and 2014.
(b) The student IDs of all students enrolled for Algebra in 2013.
(c) All the lecturers of courses for which a second year student was enrolled for in 2014.
(d) The names of all lecturers of S. Nkosi in 2014.
➌Write down relational algebra queries on Tables 2.1–2.3 that would produce:
(a) The names of all dogs treated by Dr Yang.
(b) The name and owner’s name of every dog in the database.
(c) The names of all dogs who are treated by a vet who is off on Sundays.
(d) The names of all clients who have pets treated by a vet who is off on Sundays.
Table 2.9 Student
Name
Student ID
Study Year
W Adams
186753
2
S Nkosi
268356
1
T Ling
647537
3
U de Klerk
723934
1
Table 2.10 Enrollment2013
Student ID
Course
647537
Psychology
647537
AI
268356
French
186753
Algebra
723934
Algebra

Sets, Relations, Orders
87
Table 2.11 Enrollment2014
Student ID
Course
268356
Algebra
647537
Psychology
723934
Algebra
268356
Chemistry
186753
Psychology
647537
French
Table 2.12 Lecturer
Lecturer Name
Course
W Morton
Algebra
F Jung
Psychology
D Shkatov
AI
B Mamba
Chemistry
J Southey
French
Y Jacobs
Calculus
Table 2.13 Lecturer ⋉Enrollment2014
Lecturer Name
Course
W Morton
Algebra
F Jung
Psychology
B Mamba
Chemistry
J Southey
French
➍An often used operation on relations is the semi-join, denoted R ⋉S. The semi-join is similar
to the natural join. It reruns those tuples in R for which there is a tuple in S such that the
shared attributes match. The result of applying the semi-join to Lecturer and Enrollment2014
is given in Table 2.13.
Like the natural join, the semi-join can be expressed in terms of the operations of relational
algebra.
(a∗) Express the semi-join operation in terms of the operations of relational algebra.
(b)
Calculate Lecturer ⋉Enrollment2013.
(c)
Show that R ⋈S = (R ⋉S) ⋈S.
➎Another operation on relations useful for answering queries is the division operation. Let
R and S be relations such that the attributes of S form a strict subset of the attributes of R.
Then R ÷ S consists of the restriction of tuples in R to attributes only occurring in R and such
that their combination with every tuple in S yields a tuple in R. To be specific, suppose that

88
Logic and Discrete Mathematics: A Concise Introduction
R is an n-ary relation that is an instance of the relation schema R(A1‚ …‚ An−m‚ B1‚ …‚ Bm) and
that S is an m-ary relation that is an instance of the relation schema S(B1‚ …‚ Bm). Then
R ÷ S = {(a1‚ …an−m) ∣(a1‚ …‚ an−1‚ b1‚ …‚ bm) ∈R for all (b1‚ …‚ bm) ∈S}.
(a)
Calculate:
Student ⋈Enrollment2014 ÷ ΘCourse=Algebra∨Course=ChemistryEnrollment2014.
(b)
What query is answered by the calculation in 5(a)?
(c)
Write a query in relation algebra, also using ÷ and any other operations we have intro-
duced so far, which would return the details of all clients who have all their pets treated
by Dr Dolittle.
(d∗) Express the division operation in terms of the operations of relational algebra.
Charles Sanders Peirce (1839–1914)
Charles Peirce was an American universal scientist, philosopher, logician
and mathematician. He made pioneering contributions to early mathemat-
ical logic and the algebra of relations, philosophy, scientific methodology
and many other fields. He is regarded as a founding father of pragmatism, a
philosophical theory and method of scientific research, and of semiotics, the
study of the meaning of symbols.
Peirce made many important scientific contributions in an extremely
wide range of disciplines – too many to mention here. While he was trained and worked as a chemist
and geodesist, he regarded himself mainly as a logician, philosopher and mathematician. His pio-
neering work on the algebraic and logical study of relations, starting with his 1870 paper Logic of
Relatives, laid the foundations for the relational model of databases developed by Edgar F. Codd,
a scientific descendant of Peirce. He further developed Boole’s work on algebraic logic, where he
showed that a single binary logical operator (logical NOR, now also called Peirce’s arrow) suffices
to express all other Boolean connectives. He made contributions to cardinal arithmetic for infinite
numbers, years before Cantor’s first attempts, to the theory of infinitesimals and to the mathemat-
ics of continua. He introduced first-order and second-order quantification, independent from Frege
and Peano. He also did important work in many other branches of pure and applied mathematics,
and was one of the founders of modern statistics. Notably, already in 1886 – more than 50 years
before the first digital computers were constructed – he showed how Boolean logical operations
could be carried out by electrical switching circuits.
While Russell and Whitehead did not yet know of his work when they published Principia
Mathematica in 1910 and did not mention him there, in 1959 Russell wrote: “Beyond doubt […]
he was one of the most original minds of the later nineteenth century, and certainly the greatest
American thinker ever.” In 1934, the philosopher Paul Weiss called Peirce “the most original and
versatile of American philosophers and America’s greatest logician” and Karl Popper viewed him
as “one of the greatest philosophers of all time”.

3
Propositional Logic
3.1.
Propositions, logical connectives, truth tables, tautologies . . . . . . . . . . . . . .
90
3.2.
Propositional logical consequence. Valid and invalid propositional inferences . .
101
3.3.
The concept and use of deductive systems
. . . . . . . . . . . . . . . . . . . . . .
109
3.4.
Semantic tableaux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
3.5.
Logical equivalences. Negating propositional formulae . . . . . . . . . . . . . . .
121
3.6.
Normal forms. Propositional resolution
. . . . . . . . . . . . . . . . . . . . . . . .
126
Logic studies and guides our reasoning – more precisely, logically correct reasoning. It does so
by providing formal and unambiguous logical languages, where all statements are expressed
by means of logical formulae. Formulae have precise syntax and grammar and their meaning
is given by a precise semantics, based on a formally defined notion of truth. The fundamental
notions in logic that capture the notion of logically correct reasoning are the notions of logical
consequence and, in particular, logical validity. These can be “computed” by purely mechanical
procedures called deductive systems.
There are two levels of logical expressions and reasoning in classical logic. The lower level
is propositional logic, which we will discuss in this chapter, and the higher level is first-order
logic, also known as predicate logic, which is the topic of the next chapter.
Propositional logic is about reasoning with propositions. These are sentences built, using
propositional logical connectives, from primitive statements called atomic propositions, which can
be assigned a truth value: true or false. These truth values propagate over all propositions
through truth tables for the propositional connectives.
In the chapter we explain how to compute the truth value of propositions and how to
reason correctly using propositions, by introducing the notion of propositional logical conse-
quence. We then present several deductive systems used for deriving logical consequences in
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

90
Logic and Discrete Mathematics: A Concise Introduction
propositional logic and show how they can be used for checking the logical correctness of
propositional reasoning.
3.1.
Propositions, logical connectives, truth tables, tautologies
3.1.1.
Propositions and propositional connectives. Truth tables
Recall from Chapter 1 that a proposition is a sentence that can be assigned a truth value: true
denoted by T or false denoted by F. Propositions can be either primitive (atomic) or built from
primitive propositions by using propositional logical connectives, the most common of which
are:
• not, called negation, denoted by ¬;
• and, called conjunction, denoted by ∧(or, sometimes, by &);
• or, called disjunction, denoted by ∨;
• if…then…, called implication, or conditional, denoted by →;
• … if and only if … , called biconditional, denoted by ↔.
These logical connectives are also called Boolean connectives, after the famous mathe-
matician and logician, George Boole.
The propositional connectives act as functions on the truth values, determined by their
truth tables:
p
¬p
T
F
F
T
p
q
p ∧q
p ∨q
p →q
p ↔q
T
T
T
T
T
T
T
F
F
T
F
F
F
T
F
T
T
F
F
F
F
F
T
T
The truth value of a compound proposition is then computed by replacing the atomic
propositions occurring in it by their truth values and then doing the formal calculations fol-
lowing these truth tables.
3.1.2.
Some remarks on the meaning of the connectives
The use and meaning of the logical connectives in natural language does not always match
their formal logical meaning. For instance, quite often the conjunction is loaded with a causal
relationship that makes the common sense meanings of the sentences “He threw the stone and
the window broke” and “ The window broke and he threw the stone” quite different, while they
have the same truth value, by the truth table of the conjunction. Also, the disjunction is often
used in an exclusive sense, e.g. in “I shall win or I shall die”, while in formal logic we use it by
convention in an inclusive sense, so “You will win or I will win” will be true if we both win.
Amongst all logical connectives, however, the implication seems to be the most question-
able one. For instance, it is not so easy to accept that a proposition such as “If 2+2=5, then the
Moon is made of cheese”, if it makes any sense at all, should be true. The leading motivation

Propositional Logic
91
in determining the truth behaviour of the implication is, of course, the logical meaning we
assign to it. The proposition A →B means:
If A is true, then B must be true.
Note that if A is not true, then the implication A →B requires nothing regarding the truth
of B. Therefore, there is only one case where that proposition should be regarded as false, namely
when A is true, and yet B is not true. In all other cases we have no reason to consider it false.
Hence, for it to be a proposition, it must be regarded as true. This argument justifies the truth
table of the implication. It is very important to understand this particular truth table, because
the implication is the logical connective that is most closely related to the concepts of logical
reasoning and deduction.
Remark 2 One can also think of an implication as a promise, e.g. Johnny’s father tells him: “If you
pass your logic exam, then I’ll buy you a motorbike.” Now consider the four possible situations (Johnny
passes/fails his exam and his father buys/does not buy him a motorbike) and see in which of them the
promise is kept (the implication is true) and in which it is broken (the implication is false).
Some terminology: the proposition A in the implication A →B is called the antecedent
and the proposition B is the consequent of the implication.
The implication A →B can be expressed in many different but logically equivalent ways,
which one should be able to recognize:
• A implies B
• If A (then) B.
• A only if B.
• B if A.
• B whenever A.
• A is sufficient for B. (Meaning: the truth of A is sufficient for the truth of B.)
• B is necessary for A. (Meaning: the truth of B is necessary for A to be true.)
3.1.3.
Propositional formulae
If we only discuss particular propositions, our study of logic would be no more useful than a
study of algebra based on particular equalities such as 2 + 3 = 5 or 12345679 × 9 = 111111111.
Instead, we should look at schemes of propositions and their properties, like we study algebraic
formulae and equations and their properties. To begin with, we use propositional constants:
⊤, which always takes a truth value true, and ⊥, which always takes a value false. We also
use propositional variables (also called Boolean variables) p‚ q‚ r‚ …, possibly indexed, to
denote unspecified propositions, just in the same way as we use algebraic variables to denote
unspecified or unknown numbers. Using propositional constants and variables, the logical
connectives and parentheses whenever necessary, we can form propositional formulae in the
way in which we are used to forming algebraic expressions from variables and arithmetic

92
Logic and Discrete Mathematics: A Concise Introduction
operations. Here are a few examples of propositional formulae:
⊤‚ p‚ ¬⊥‚ ¬¬p‚ p ∨¬q‚ p1 ∧¬(p2 →(¬p1 ∧⊥)).
Note that there are infinitely many possible propositional formulae, so we cannot list them all
here. However, there is a simple and elegant way to give a precise definition of propositional
formulae, viz. the so-called inductive definition (or recursive definition). It consists of the
following clauses (formation rules):
1. Every propositional constant or variable is a propositional formula.
2. If A is a propositional formula then ¬A is a propositional formula.
3. If A‚ B are propositional formulae then (A ∨B), (A ∧B), (A →B) and (A ↔B) are propo-
sitional formulae.
Hereafter we will be omitting the “unnecessary” pairs of parentheses, whenever that
would not lead to syntactic ambiguity.
Propositional formulae are also called Boolean formulae. Note that the notion of proposi-
tional formula is used in its own definition; this is the idea of recursion. The definition works as
follows: the first rule above gives us some initial stock of propositional formulae; as we keep
applying the other rules, we construct more and more formulae and use them further in the
definition. Eventually, every propositional formula can be obtained in several (finitely many!)
steps of applying these rules. Thus, one can think of the definition above as a “construction
manual” prescribing how new objects (here, propositional formulae) can be built from already
constructed ones.
The formulae that occur in the process of the construction of a formula A are called subfor-
mulae of A. The last propositional connective introduced in the construction of A is called the
main connective of A and the formula(e) to which it is applied is/are the main subformula(e)
of A. We will make all these more precise in what follows.
3.1.4.
Construction and parsing tree of a propositional formula
The sequence of formulae constructed in the process of applying the definition and ending
with A is called a construction sequence of the formula A. A formula has many construc-
tion sequences and a construction sequence may contain many redundant formulae. A better
notion capturing the construction of a formula is the construction tree of that formula. A con-
struction tree is a tree-like directed graph with nodes labelled with propositional constants,
variables and propositional connectives, such that:
1. Every leaf is labelled by a propositional constant or variable.
2. Propositional constants and variables label only leaves.
3. Every node labelled with ¬ has exactly one successor node.
4. Every node labelled with any of ∧‚ ∨‚ →or ↔has exactly two successor nodes – a left
successor and a right successor.

Propositional Logic
93
Thus, a construction tree looks like this:
Leaves
The main connective
Binary connective (∧, ∨, →, ↔)
Unary connective (   )
Every construction tree defines a formula C, built starting from the leaves and going
towards the root, by applying at every node the formula construction rule corresponding to
the label at that node. The formulae constructed in the process are precisely the subformulae
of C and the propositional connective labelling the root of the construction tree of a formula
C is the main connective of C.
Example 3.1.1 (Construction tree)
Formula:
(p ∨¬(q ∧¬r)) →¬¬r.
Construction tree:
r
r
q
p
The parsing tree of a formula looks the same as its construction tree, but is produced in
inverse order, starting from the main connective (if any), drawing edges to the main compo-
nents and then recursively producing the parsing trees for each of them.
3.1.5.
Truth tables of propositional formulae
One can think of a propositional formula as a scheme that becomes a proposition whenever we
substitute propositions for all occurring propositional variables. Of course, we mean uniform

94
Logic and Discrete Mathematics: A Concise Introduction
substitutions; that is, the same variables are replaced by the same propositions throughout
the formula. We cannot assign a truth value to a propositional formula before we assign con-
crete propositions, or at least concrete truth values, to all occurring propositional variables,
for the same reason that we cannot evaluate x(y + z) before we know the values of x‚ y‚ z.
Remember, in order to evaluate the truth value of a compound proposition, we only need
to know the truth values of the occurring atomic propositions, and not of the propositions
themselves.
For instance, if we substitute “0.5 is an integer” for p, “2 is less than 3” for q and “The
Moon is larger than the Sun” for r in the propositional formula
(p ∨¬(q ∧¬r)) →¬¬r
we find that the resulting proposition is true:
(F ∨¬(T ∧¬F)) →¬¬F = (F ∨¬(T ∧T)) →¬T = (F ∨¬T) →F
= (F ∨F) →F = F →F = T.
If, however, we substitute any true propositions for p and q and a false proposition for r, then
the resulting proposition will be false:
(T ∨¬(T ∧¬F)) →¬¬F = (T ∨¬(T ∧T)) →¬T = (T ∨¬T) →F
= (T ∨F) →F = T →F = F.
We can tabulate the “truth behaviour” of any propositional formula in a truth table where we
list all possible combinations of truth values of the occurring variables, and for each combina-
tion we calculate the corresponding truth value of the formula. We can do that by successively
calculating the truth values of all occurring subformulae, as we did just now. For example, the
truth table for the formula above is compiled as follows:
p
q
r
¬r
¬¬r
q ∧¬r
¬(q ∧¬r)
p ∨¬(q ∧¬r)
(p ∨¬(q ∧¬r)) →¬¬r
T
T
T
F
T
F
T
T
T
T
T
F
T
F
T
F
T
F
T
F
T
F
T
F
T
T
T
T
F
F
T
F
F
T
T
F
F
T
T
F
T
F
T
T
T
F
T
F
T
F
T
F
F
T
F
F
T
F
F
F
The last two rows are left to the reader as exercises.
Truth tables can be somewhat simplified if we notice that every occurrence of a logical
connective in a propositional formula determines a unique subformula where that occurrence is
the main connective, i.e. the connective applied last in the construction of the subformula. For
instance, the conjunction occurring in the formula (p ∨¬(q ∧¬r)) →¬¬r is the main connective
of the subformula q ∧¬r, the first negation is the main connective of ¬(q ∧¬r) and the implica-
tion is the main connective of the whole formula. Now we can simplify the truth table of the
formula by listing only the occurring variables and the whole formula and by calculating the

Propositional Logic
95
truth table of every subformula in the column below the corresponding main connective:
p
q
r
(p
∨
¬
(q
∧
¬
r))
→
¬
¬
r
T
T
T
T
T
T
T
F
F
T
T
T
F
T
T
T
F
T
T
F
T
T
T
F
F
F
T
F
T
F
T
T
T
T
F
F
F
T
T
T
F
T
T
F
F
T
T
T
F
F
T
F
F
F
T
F
F
T
T
F
T
T
T
F
F
T
T
T
F
T
F
T
F
F
F
F
T
T
T
F
T
F
T
F
F
F
T
· · ·
F
F
F
· · ·
Thus, we see that a propositional formula can represent a true or a false proposition,
depending of the choice of the occurring atomic propositions, or rather on their truth values.
3.1.6.
Tautologies
Definition 3.1.2 A tautology is a propositional formula that obtains a truth value true for any
assignment of truth values to the occurring variables. Tautologies are also called logically valid for-
mulae.
Thus, every tautology always renders a true proposition. So, it represents a logical law
in the same way that the identity x + y = y + x represents a law of arithmetic and, therefore,
holds no matter what values we assign to x and y.
Here are a few simple tautologies that represent some important laws of propositional
logic:
• (p ∨¬p): the law of excluded middle – every proposition p is either true or false (and in the
latter case ¬p must be true);
• ¬(p ∧¬p): the law of non-contradiction – it cannot be the case that both p and ¬p are true;
• ((p ∧(p →q)) →q): if p is true and it is true that p implies q, then q is true.
How can one determine if a propositional formula A is a tautology? Quite easily: complete
the truth table of A and check if it always takes a truth value true. For example, let us check
the formulae mentioned above:
p
¬p
(p ∨¬p)
(p ∧¬p)
¬(p ∧¬p)
T
F
T
F
T
F
T
T
F
T
p
q
(p →q)
(p ∧(p →q))
((p ∧(p →q)) →q)
T
T
T
T
T
T
F
F
F
T
F
T
T
F
T
F
F
T
F
T

96
Logic and Discrete Mathematics: A Concise Introduction
The opposite concept of a tautology is a contradictory formula – a formula that always
takes a truth value false. For instance, (p ∧¬p) is a contradictory formula.
Question 1 How are the concepts of tautology and contradictory formula related?
Definition 3.1.3 A propositional formula that obtains a truth value true for some assignment of truth
values to the variables is called satisfiable.
Example 3.1.4
The formula p ∧¬q ∧r is satisfied by the assignment p ∶T, q ∶F, r ∶T. The formula p ∧¬p
is not satisfiable.
Question 2 How are the concepts of tautology and satisfiable formula related?
3.1.7.
A better idea: search for a falsifying truth assignment
Checking tautologies with truth tables is straightforward, but laborious and – let’s
admit – rather boring. There is a somewhat streamlined method, whereby we attempt
to show that the formula is not a tautology by finding an appropriate falsifying assignment,
i.e. a combination of truth values of the propositional variables which renders it false. If
we succeed in finding such an assignment, then the formula is indeed not a tautology; if,
however, we end up with a contradiction (e.g. some variable must be both true and false)
in every possible case during our exploration, then we have proved that the formula cannot
be falsified, and hence it is a tautology.1 The search for a falsifying assignment is based on
a step-by-step decomposition of the formula using the truth tables of the propositional
connectives occurring in it. Let us see how this works on some examples.
Example 3.1.5
To save on some writing, we will use signed formulae A ∶T, meaning ‘A must be true’, and
A ∶F, meaning ‘A must be false’.
1. Consider ¬(p →¬q) →(p ∨¬r).
To falsify it, it must be the case that ¬(p →¬q) ∶T and p ∨¬r ∶F.
For the former, p →¬q ∶F, and hence p ∶T and ¬q ∶F.
For the latter, p ∶F and ¬r ∶F.
Therefore, p must be both true and false, which is impossible. Thus, our attempt to falsify
the formula has failed, and hence it is a tautology.
2. Consider now ¬p →¬(p ∨¬q).
To falsify it, it must be the case that ¬p ∶T while ¬(p ∨¬q) ∶F.
Therefore p ∶F and p ∨¬q ∶T.
For the latter, p ∶T or ¬q ∶T.
1 This method of proof is called indirect proof or proof by contradiction and will be discussed in more detail later.

Propositional Logic
97
Let us consider both cases:
Case 1 p ∶T. This contradicts p ∶F.
Case 2 ¬q ∶T. Then q ∶F. In this case we have not reached any contradiction and there
is nothing more we can do in order to obtain one. Indeed, we can check that p ∶F
and q ∶F renders the formula false.
3. A contradiction in the truth values can be reached on any subformula, not necessarily a
variable. For instance, take (p ∨¬q) →(¬p →(p ∨¬q)). For it to be false, (p ∨¬q) ∶T and
(¬p →(p ∨¬q)) ∶F must be the case. From the latter, ¬p ∶T and (p ∨¬q) ∶F, which con-
tradicts the former.
4. Finally, take ((p ∧¬q) →¬r) ↔((p ∧r) →q). For it to be false, there are two possible cases:
Case 1 ((p ∧¬q) →¬r) ∶T and ((p ∧r) →q) ∶F. The latter implies (p ∧r) ∶T and q ∶F,
hence p ∶T, q ∶F, r ∶T. For the former, two subcases are possible:
Case 1.1 ¬r ∶T. Then r ∶F, which is a contradiction with r ∶T.
Case 1.2 (p ∧¬q) ∶F. Then:
Case 1.2.1 p ∶F – a contradiction with p ∶T.
Case 1.2.1 ¬q ∶F. Then q ∶T – again a contradiction, now with q ∶F.
Note that the consideration of these subcases could have been avoided if we had
noticed that the assignment p ∶T, q ∶F, r ∶T renders ((p ∧¬q) →¬r) ∶F.
Case 2 ((p ∧r) →q) ∶T and (p ∧¬q) →¬r) ∶F. The former implies (p ∧¬q) ∶T and ¬r ∶F,
i.e., p ∶T, q ∶F, r ∶T. Again, we can either notice that this assignment renders
((p ∧r) →q) ∶F or consider the cases for ((p ∧r) →q) ∶T and see that all lead to a
contradiction.
Thus, in neither case can the formula be falsified, so it is a tautology.
This method can be mechanized completely into a formal procedure, called semantic
tableaux, which will be presented in Section 3.4.
3.1.8.
Exercises
➊Determine the antecedent and the consequent in each of the following implications:
(a) If John talks everyone else listens.
(b) Everyone else listens if John talks.
(c) John talks only if everyone else listens.
(d) An integer is positive if its cube is positive.

98
Logic and Discrete Mathematics: A Concise Introduction
(Hint: to make it easier, introduce a name for the object in question, e.g. “An integer n is
positive if the cube of n is positive.”)
(e) An integer is positive only if its cube is positive.
(f) A function is continuous whenever it is differentiable.
(g) The continuity of a function is necessary for it to be differentiable.
(h) The continuity of a function is sufficient for it to be differentiable.
➋Which of the following conditions are sufficient and which are necessary for the truth of
“The integer n is composite”?
(a) “n is divisible by 3.”
(b) “n is divisible by 6.”
(c) “n is even.”
(d) “n has at least two different factors.”
(e) “n has more than two different factors.”
(f) “n = 15.”
(g) “n has a factor different from n.”
(h) “n has a prime factor.”
(i) “n has a prime factor different from n.”
➌Let P‚ Q‚ R and S be propositions. Using only the truth tables of the propositional connec-
tives and informal reasoning, show that:
(a) if the propositions P and P →Q are true, then Q is true;
(b) if P →Q‚ Q →R and P ∧S are true, then R ∧S is true;
(c) if P →Q‚ R ∨(S ∧¬Q)‚ ¬R are true, then P is false;
(d) if ¬R‚ ¬(P ∧¬R)‚ ¬P →¬Q are all true, then Q is false;
(e) if the propositions (P ∨Q) →R and P ∨R are true, then R is true.
(Hint: suppose the contrary.)
➍Let P‚ Q‚ R and S be propositions. Using truth tables, check whether:
(a) if Q →(R ∧S) is true and Q ∧S is false, then R ∧Q is false;
(b) if P →Q and Q →(R ∨S) are true and P →R is false, then ¬R →S is true;
(c) if ¬P →(¬Q ∨¬R)‚ Q ∧(P ∨R) are true, then P is true;
(d) if P →Q and Q →(R ∨S) are true and P →R is false, then S is true;
(e) if Q →(R ∧S) is true and Q ∧S is false, then Q is false.
(Hint: regard P‚ Q‚ R and S as propositional variables and inspect the truth tables of the
respective formulae.)

Propositional Logic
99
➎Construct the truth tables of the following propositional formulae and determine which of
them (if any) are tautologies, which are contradictory formulae and which are satisfiable
formulae.
(a) ¬(p →¬p)
(b) p ∨(p →¬p)
(c) p ∧(q ∨¬q)
(d) ¬((p ∧¬p) →q)
(e) ¬p ∧¬(p →q)
(f) ((p →q) →p) →p
(g) (p ∨¬q) →¬(q ∧¬p)
(h) (p →q) ∧(q →r) ∧¬(¬p ∨r)
(i) ¬(¬p ↔q) →(r ∨¬q)
(j) ¬((p ∧¬q) →r) ↔(¬(q ∨r) →¬p)
➏Lastly, some logical puzzles.2 On the remote planet Nologic there are two types of intelligent
creatures:
• truth tellers, who always tell the truth, and
• liars, who – you guessed it – always lie.
It is not possible to distinguish them by appearance, but only by the truth or falsity of the
statements they make.
(a)
Once a space stranger visited Nologic and met there two inhabitants, P and Q. He asked
them: “Is any of you a liar?” “At least one of us is a liar”, replied P. Can you find out
what P and Q are?
(b)
Next, the stranger met two other inhabitants and I asked one of them again “Is any of
you a truth teller?” He got a ‘yes’ or ‘no’ answer and from that answer he was able to
determine for each of them whether he is a liar or not. What was the answer and what
was the stranger’s conclusion?
(c)
Walking about Nologic, the stranger met two other inhabitants, A and B, and asked A,
“Is any of you a liar?” “If B is a liar, then I am a liar, too”, replied A. What are A and B?
(d∗) The stranger went on and met three locals, X, Y and Z and asked X: “Are you a liar?” X
answered something that the stranger did not hear, so he asked Y: “What did X say?”
“He said that he is a liar”, replied Y. Then Z added “Don’t believe Y, he is a liar.” Who
are liars?
(e∗) The stranger went on. In the evening, he began to look for a shelter for the night, but
was very cautious because he knew that some of the inhabitants were man-eaters and
2 For many more of these, we warmly recommend to the reader the marvellous books by Raymond Smullyan,
including What is the name of this book? and Lady or the Tiger? And Other Logic Puzzles.

100
Logic and Discrete Mathematics: A Concise Introduction
it was not possible to recognize them by appearance. Then he met three inhabitants, C,
D and E. He asked C “How many of you are truth-tellers?” “Flam flim”, answered C
in her language. “What did she say?”, asked the stranger D. “Just one”, replied D. “Do
not trust D, he is a liar. Come with me, I’m not a man-eater”, said E. “No, come with
me, I’m not a man-eater”, countered D. What should the stranger do?
(f∗) The stranger decided to go back to the port where his spaceship was, but he got lost.
After a long walk he got to a fork in the road. He knew that one of the two roads would
take him to the spaceship port, but did not know which one. Luckily, he saw two of the
inhabitants whom he had met before, so he knew that one of them was a liar and the
other a truth-teller, but could not remember who was who.
Can the stranger ask just one question to any of these inhabitants in order to find out
for sure which is the correct road to the spaceship port? If so, what question should
he ask?
Aristotle (384–322 BC)
Aristotle was one of the greatest ancient Greek philosophers and, according
to Encyclopaedia Britannica, “the first genuine scientist in history”. He joined
Plato’s Academy in Athens at the age of 18 and did scholarly work there for
about 20 years. After the death of Plato, he left Athens and, at the request of
King Philip of Macedonia, became the private teacher of his son, Alexander
the Great, during the years 356–323 BC.
It is believed that only about a third of Aristotle’s original works have
survived. In them he made influential contributions to just about every field
of science and arts existing in his time: philosophy, poetry, theatre, music,
rhetoric, politics, government and ethics, physics, geology, biology, etc. Aristotle’s legacy, not only
in philosophy, continues to be the object of active academic study today. For instance, his ideas of
systematic classification of plants and animals are still in use in our times.
Aristotle is regarded–amongst his many other seminal contributions – as the founding father
of Logic. He was the first to propose the use of formal logical languages in the study of reasoning
and to undertake and accomplish a systematic study of the principles of correct reasoning, unsur-
passed during the next more than 2000 years. His treatises were collected by his followers under
the name Organon (from the Greek word meaning “instrument”, “tool”), consisting of six books:
Categories, On Interpretation, Prior Analytics, Posterior Analytics, Topics and On Sophistical Refutations.
In the Organon Aristotle developed a theory of deduction for a special kind of logical arguments
called syllogisms, built on several forms of expressions, like “All As are (not) Bs”, “Some As are (not)
Bs”, “No As are Bs”, etc. A typical example of a syllogism is “All men are mortal. Socrates is a man.
Therefore, Socrates is mortal”. In his logical system, now called the Syllogistic, there are 256 differ-
ent types of syllogisms, classified according to their logical form. Aristotle further classified these
types as logically valid and invalid, and gave compelling counter-examples to the invalid ones. He
also proved many “meta-properties” of correct logical reasoning, thus anticipating the rigorous,
mathematical study of modern logic.

Propositional Logic
101
3.2.
Propositional logical consequence. Valid and invalid
propositional inferences
Logic is not concerned with what is true and what is false, but rather with the correctness of
argumentation and reasoning. Here, we discuss what it means for an argument to be logically
correct or not, by formalizing the concept of (propositional) logical consequence.
First are a couple of examples, providing some food for thought.
Syllogisms, first studied by Aristotle, are specific patterns of arguments. A typical
example of a syllogism (not due to Aristotle) is:
All logicians are clever.
All clever people are rich.
All logicians are rich.
The way we actually read this is:
If all logicians are clever and all clever people are rich, then all logicians are rich.
This sounds like a correct piece of reasoning, and it is one, but – and this is very important to
understand – it does not mean that the conclusion is necessarily true. (In fact, unfortunately, it is
not.) What then makes it correct?
Here is another one:
All natural numbers are integers.
Some integers are odd numbers.
Some natural numbers are odd numbers.
Note that all of the statements above are true. Therefore, is this a correct argument? If you think
so, then how about this: take the same argument and replace the words “natural numbers”
by “mice”, “integers” by “animals” and “odd numbers” by “elephants”. This will not change
the logical form of the argument and, therefore, should not change the correctness. The result
speaks for itself:
All mice are animals.
Some animals are elephants.
Some mice are elephants.
So, what makes an argument logically correct? We will answer this question in full later in
the book. Now we will provide and discuss the answer for a simple type of logical argument
that only involves propositional reasoning, called propositional arguments.
3.2.1.
Propositional logical consequence
The intuition behind logically correct reasoning is simple: starting from true premises it should
always lead to true conclusions. Let us first make this intuition precise.
Definition 3.2.1 A propositional formula B is a logical consequence of the propositional formulae
A1‚ …‚ An, denoted A1‚ …‚ An ⊨B, if B is true whenever all A1‚ …‚ An are true, that is:
Every truth assignment to the variables occurring in A1‚ …‚ An and B that renders the formulae
A1‚ …‚ An true also renders the formula B true.

102
Logic and Discrete Mathematics: A Concise Introduction
When A1‚ …‚ An ⊨B‚ we also say that B follows logically from A1‚ …‚ An or that A1‚ …‚ An
logically imply B.
In the context of A1‚ …‚ An ⊨B, the formulae A1‚ …‚ An are called assumptions while the
formula B is called the conclusion. When A1‚ …‚ An ⊨B is not the case, we write A1‚ …‚ An ⊭B.
Thus, if A1‚ …‚ An ⊨B then every substitution of propositions for the variables occurring in
A1‚ …‚ An‚ B that turns the formulae A1‚ …‚ An into true propositions also turns the formula B
into a true proposition.
In order to check if A1‚ …‚ An ⊨B we can simply complete the truth tables of A1‚ …‚ An‚ B
and check row by row if the following holds: whenever all formulae A1‚ …‚ An have a truth value T
in that row, B must have a truth value T as well.3 If that holds in every row in the table, then B does
follow logically from A1‚ …‚ An; if that fails in at least one row, then B does not follow logically
from A1‚ …‚ An.
Thus, B does not follow logically from A1‚ …‚ An if and only if there is a truth value assign-
ment that renders all formulae A1‚ …‚ An true and B false.
Example 3.2.2
Let us start with a few simple cases:
1. Any formula B follows logically from any set of formulae that contains B. (Why?)
2. Q follows logically from P and P →Q, for any formulae P and Q.
First note that, whatever the formulae P and Q are, any truth assignment eventually ren-
ders each of them true or false, and all combinations of these truth values are possible.
Therefore, we can just as well treat P and Q as propositional variables and consider the
truth tables for P, Q and P →Q:
P
Q
P
P →Q
Q
T
T
T
T
T
T
F
T
F
F
F
T
F
T
T
F
F
F
T
F
Indeed, in every row where the third and fourth entries are T, the fifth entry is also T.
3. Is it true that p ∨q‚ q →p ⊨p ∧q? Let us check the definition:
p
q
p ∨q
q →p
p ∧q
T
T
T
T
T
T
F
T
T
F
F
T
…
…
…
F
F
…
…
…
We see that in the second row both assumptions are true while the conclusion is false, and
this suffices to conclude that p ∨q‚ q →p ⊭p ∧q, so there is no need to complete the truth
table any further.
3 Of course, it is possible for B to be true without all, or any, of A1‚ …‚ An being true.

Propositional Logic
103
A logical consequence can be expressed quite simply in terms of tautologies:
The formula B follows logically from A1‚ …‚ An if and only if the formula (A1 ∧…∧
An) →B is a tautology.
In particular, a formula A is a tautology if and only if it follows logically from the empty set
of formulae. Indeed, if ⊨A then, trivially, ∅⊨A. Now, to see that ∅⊨A implies ⊨A, suppose
∅⊨A and take any truth assignment. Note that it satisfies every formula from ∅. Why? Well,
there can be no formula in ∅that is not satisfied, because there are no formulae in ∅at all!
Then, since ∅⊨A, that truth assignment must also satisfy A. Thus, A is satisfied by every
truth assignment.4
Checking logical consequences can be streamlined, just like checking tautologies, by
searching for a falsifying assignment; i.e. in order to check if B follows logically from
A1‚ …‚ An we look for an assignment of truth values to the variables occurring in A1‚ …‚ An‚ B
that renders all A1‚ …‚ An true and B false. If we succeed, we have shown that B does not follow
logically from A1‚ …‚ An; otherwise we try to prove that no such assignment is possible by
showing that the assumption that it exists leads to a contradiction.
Example 3.2.3
Show that p →r and q →r logically imply (p ∨q) →r.
• Method 1 (truth tables)
p
q
r
p →r
q →r
p ∨q
(p ∨q) →r
T
T
T
T
T
T
T
T
T
F
F
F
T
F
T
F
T
T
T
T
T
T
F
F
F
T
T
F
F
T
T
T
T
T
T
F
T
F
T
F
T
F
F
F
T
T
T
F
T
F
F
F
T
T
F
T
In every row where the truth values of p →r and q →r are T, the truth value of (p ∨q) →r
is also T.
• Method 2 (search for falsifying assignment). Recall that A ∶T (respectively A ∶F) means that
A has, or is required to have, a truth value T (respectively F). Now, suppose that for some
assignment (p →r) ∶T, (q →r) ∶T and ((p ∨q) →r) ∶F. Then (p ∨q) ∶T and r ∶F , and
hence p ∶T or q ∶T.
Case 1: p ∶T. Then (p →r) ∶F – a contradiction.
Case 2: q ∶T. Then (q →r) ∶F – again, a contradiction.
Thus, there is no assignment that falsifies the logical consequence.
4 Note that, what we did here was a piece of logical reasoning based on the very same concepts of truth and
logical consequence that we are discussing. When reasoning about logic, this kind of bootstrapping argument is
inevitable!

104
Logic and Discrete Mathematics: A Concise Introduction
In the next section we are going to develop this method systematically.
3.2.2.
Logically sound rules of propositional inference. Logically correct propositional
arguments
Definition 3.2.4 A rule of propositional inference (inference rule, for short) is a scheme:
P1‚ …‚ Pn
C
where P1‚ …‚ Pn‚ C are propositional formulae. The formulae P1‚ …‚ Pn are called premises of the infer-
ence rule and C is its conclusion.
An instance of an inference rule, obtained by uniform substitution of propositions for the variables
occurring in all formulae of the rule, is called a propositional inference, or a propositional argument
based on that rule.
Definition 3.2.5 An inference rule is (logically) sound if its conclusion follows logically from the
premises. A propositional inference is (logically) correct if it is an instance of a logically sound infer-
ence rule.
Example 3.2.6
Here are some simple but important examples:
1. The inference rule (known as the Detachment rule, or Modus Ponens)
p‚ p →q
q
is sound (as we have already seen).
Therefore, the inference
Chantel is singing.
If Chantel is singing, then Chantel is happy.
Chantel is happy
is logically correct, being an instance of that inference rule.
2. The inference rule
p‚ q →p
q
is not sound: if p is true and q is false, then both premises are true, while the conclusion is
false.
Therefore the inference
2 plus 2 equals 4 .
If 5 is greater than 3‚ then 2 plus 2 equals 4.
5 is greater than 3.
is not logically correct (despite the truth of the conclusion), being an instance of a logically
unsound rule.

Propositional Logic
105
Some remarks are in order here.
• It is important to realize that the logical correctness of an inference does not always guarantee
the truth of the conclusion, but only when all premises are true. In other words, if at least one
premise of a logically correct inference is false, then the conclusion may also be false. For
instance, the inference
5 divides 6.
If 5 divides 6, then 5 divides 11.
5 divides 11.
is logically correct (being an instance of the detachment rule) in spite of the falsity of the
conclusion; this does not contradict our idea of logical correctness of an inference, because
the first premise is false. (What about the second premise?)
• Conversely, if the conclusion of an inference happens to be true, this does not necessarily
mean that the inference is logically correct, as in Example 3.2.6(2).
• Moreover, it may happen that the truth of the premises of an inference does imply the truth
of the conclusion, and yet the inference is not logically correct. For instance, the correctness
of the inferences
Today is Monday.
Tomorrow will be Tuesday.
or
a = 2‚ a + b = 5
b = 3
is based not on logical consequence but, in the first case, on the commonly known fact that
Tuesday always follows Monday, and in the second case on some laws of arithmetic. Indeed,
the first inference is based on the rule
p
q
and the second one (though the statements in that rule are not real propositions) on
p‚ q
r ‚
both of which are clearly unsound.
To summarize, the meaning and importance of logically correct inferences is that only such
inferences guarantee that if all premises are true, then the conclusions will also be true. That is
why only logically correct inferences are safe to be employed in our reasoning.

106
Logic and Discrete Mathematics: A Concise Introduction
Example 3.2.7
Let us now look at a few more examples.
1. The inference rule
q‚ p ∨¬q
p
is logically sound. You can check this in two ways: by applying the definition or by show-
ing that the corresponding formula
(q ∧(p ∨¬q)) →p
is a tautology. In particular, the inference
Josephine is singing or Josephine does not feel happy.
Josephine feels happy.
Josephine is singing.
is valid, being an instance of the rule above.
2. Now, take the argument
If a divides b or a divides c‚then a divides bc.
a divides bc.
a does not divide b.
Therefore a divides c.
where a‚ b‚ c are certain integers. This argument is an instance of the following inference
rule:
(p ∨q) →r‚ r‚ ¬p
q
.
Let us see if we can invalidate this rule. For that we need an assignment such that ((p ∨
q) →r) ∶T, r ∶T, ¬p ∶T; hence p ∶F and q ∶F. Indeed, the assignment p ∶F,q ∶F,r ∶T
renders all premises true and the conclusion false. (Check this.)
Therefore, the rule is not logically sound and hence the argument above is not logically
correct.
3.2.3.
Fallacies of the implication
As an application let us analyze some very common forms of correct and incorrect reasoning
related to implications. Given the implication
A →B
we can form the so-called derivative implications:
• the converse of A →B: B →A;

Propositional Logic
107
• the inverse of A →B: ¬A →¬B ;
• the contrapositive of A →B: ¬B →¬A.
Now, suppose we know that A →B is true. What can we say about the truth of its deriva-
tives? To answer that question, look at the inferences
A →B
B →A‚
A →B
¬A →¬B‚
A →B
¬B →¬A
Exercise
Show that the first two of these inferences are incorrect, while the third one is correct.
Therefore, the truth of A →B only implies the truth of its contrapositive, but not the truth
of the converse, or inverse. These are mistakes that people often make, respectively called the
fallacy of the converse implication and the fallacy of the inverse implication. For example,
the truth of the implication “If it has just rained, then the tennis court is wet” does not imply that
either of “If the tennis court is wet, then it has just rained” and “If it has not just rained, then the
tennis court is not wet” is true – for someone may have just watered the court on a clear sunny
day – but it certainly implies that “If the tennis court is not wet, then it has not just rained”.
In fact, one can easily check that the inference
¬B →¬A
A →B
is also logically correct. This is the basis of the method of proof by contraposition, which will
be discussed later.
3.2.4.
Exercises
➊Show that the following is true:
The formula B follows logically from A1‚ …‚ An if and only if the formula (A1 ∧
· · · ∧An) →B is a tautology.
➋Show that the first two of the following inference rules, corresponding to the derivative
implications, are logically unsound, while the third one is sound.
(a) p →q
q →p
(b)
p →q
¬p →¬q
(c)
p →q
¬q →¬p
➌Using truth tables, check if the following inference rules are valid.
(a) p →q‚ ¬q ∨r‚ ¬r
¬p
(b) p →q‚ p ∨¬r‚ ¬r
¬q ∨r

108
Logic and Discrete Mathematics: A Concise Introduction
(c) ¬p →¬q‚ q‚ ¬(p ∧¬r)
r
(d) ((p ∧q) →r)‚ ¬(p →r)
q →r
➍Write down the inference rules on which the following arguments are based and check their
logical validity, using truth tables.
(a) In the following argument, x is a certain number.
x is greater than 3.
x is greater than or equal to 3.
(b) In the following argument, a is a certain number.
If a is greater than −1‚ then a is greater than −2.
a is not greater than −2.
a is not greater than −1.
(c)
If the triangle ABC has a right angle, then it is not equilateral.
The triangle ABC does not have a right angle.
Therefore, the triangle ABC is equilateral.
(d)
If Bill likes logic, then he is clever.
If Bill is clever, then he is rich.
Therefore, if Bill likes logic, then he is rich.
(e) In the following argument n is a certain integer.
If n is divisible by 2 and n is divisible by 3, then n is divisible by 6.
If n is divisible by 6, then n is divisible by 2.
n is not divisible by 3.
Therefore, n is not divisible by 6.
➎For each of the following implications construct the converse, inverse and the contraposi-
tive, phrased in the same way.
(a) If a is greater than −1, then a is greater than −2.
(b) If x is divisible by 6 then x is not prime.
(c) x is positive only if its square is positive.
(d) The triangle ABC is equilateral whenever its medicentre and orthocentre coincide.
(e) For the function f to be continuous it is sufﬁcient that it is differentiable.
(f) For the function f not to be differentiable it is sufﬁcient that it is discontinuous.
(g) For the integer n to be prime it is necessary that it is not divisible by 10.

Propositional Logic
109
George Boole (2.11.1815–8.12.1864)
George Boole was an English mathematician and the first
to propose and develop an algebraic approach to the study
of logical reasoning. Boole’s first contribution to logic was
a pamphlet called Mathematical Analysis of Logic, written in
1847. He published his main work on logic, An Investiga-
tion of the Laws of Thought, on Which Are Founded the Mathe-
matical Theories of Logic and Probabilities, in 1854. In it Boole
developed a general mathematical method of logical infer-
ence and thus laid the foundations of modern mathemati-
cal logic. His system proposed a formal algebraic treatment
of propositions by processing only their two possible truth
values: yes–no, true–false, zero–one. For instance, in Boole’s
system, if x stands for “white things”, then 1 −x stands for
“non-white things”, and if also y stands for “sheep”, then xy stands for “white sheep”, etc. Then
x(1 −x) denotes things that are both white and non-white, which is impossible, so a proposition of
the shape x(1 −x) is always false, i.e. has a truth value 0. Thus an algebraic law emerges: x(1 −x) = 0,
etc. The resulting algebraic system is known today as (the simplest) Boolean algebra.
Boole also argued that symbolic logic is needed in other mathematical disciplines, especially
in probability theory. He wrote: “…no general method for the solution of questions in the theory of prob-
abilities can be established which does not explicitly recognise those universal laws of thought which are the
basis of all reasoning…”
Propositional logic today is somewhat different from Boole’s system of logic 150 years ago, but
the underlying ideas are the same. That is why propositional logic is also often called Boolean logic
in recognition of Boole’s groundbreaking contribution. Boolean logic is not only fundamental as a
system of formal logical reasoning but it also provides the mathematical basis of the logical circuits
underlying the architecture of the modern digital computers.
3.3.
The concept and use of deductive systems
The most fundamental concept in Logic is logical consequence. It extends the concept of logi-
cal validity and is the basis of logically correct reasoning. While verifying logical consequence
in propositional logic is conceptually simple and technically easy (though possibly computa-
tionally expensive), this is not so any more for the full first-order logic, which we will introduce
later in Chapter 4, nor for the variety of nonclassical logics, which we will not discuss here.
In fact, verifying logical consequence (in particular, logical validity) is usually an infinite task,
as it generally requires checking infinitely many possible “models”, rather than a finite num-
ber of simple truth assignments. Thus, a different approach for proving logical validity and
consequence, not based on the semantic definition, becomes practically necessary. Such an
approach is provided by the notion of the deductive system: a formal, mechanical – or, at least
mechanizable – procedure for derivation (inference, deduction) of formulae, or lists (“sequents”)
of formulae, by applying precise inference rules and possibly using some formulae that are
postulated as derived, called axioms. The underlying idea of deductive systems is to simulate

110
Logic and Discrete Mathematics: A Concise Introduction
and substitute the semantic notion of logical consequence with the formal, mechanical notion
of deductive consequence, which is based only on the syntactic shape of the formulae to which
inference rules are applied, but not on their meaning. Thus, at least theoretically, any person
with no knowledge and understanding of the meaning of logical formulae and logical conse-
quence, or even a suitably programmed computer, should be able to do successful derivations
in a given logical deductive system.
The idea of logical deductive systems goes back to antiquity, most notably to the book
Organon of the famous ancient Greek philosopher and founding father of Formal Logic,
Aristotle (384–322 BC). Perhaps the first real prototype of a deductive system can be found in
the fundamental work Elements of the “father of Geometry”, the greatest ancient Greek mathe-
matician Euclid (ca. 300 BC), who provided a systematic development of elementary geometry
based on several simple assumptions about points and lines, called postulates (such as “Every
two different points determine exactly one line”, “For every line there is a point not belonging to
that line”, etc.). Using these postulates and some informal logical reasoning, other geometric
facts are derived and thus the entire body of Euclidean geometry is eventually built. The
logical concept of a deductive system gradually emerged much later, notably through the ideas
of one of the most influential philosophers and mathematicians of all times, Gottfried Leibniz
(1646–1716) for a characteristica universalis (universal language) and a calculus ratiocinator (cal-
culus of reasoning). The first really formal deductive system, however, was only constructed
in the late 19th century by the mathematician and philosopher Gottlob Frege (1848–1925) in
his seminal book Begriffsschrift (1879), for his prototype of the modern first-order logic. Later,
David Hilbert5 (1862–1943), one of the leading mathematicians of the late 19th and early 20th
century, re-worked Euclid’s system of geometry developed in the Elements into a rigorous and
mathematically precise treatment that resulted in his book Foundations of Geometry (1899) and
the mathematician Giuseppe Peano (1858–1932) developed a formal system of arithmetic,
still known as Peano’s axiomatic system, in his most important work Formulario Mathematico.
The concept of formal deductive system was further developed by the famous philosophers
Bertrand Russell (1872–1970) and Alfred North Whitehead (1861–1947) in their three-volume
book Principia Mathematica (1910–1913), and by David Hilbert and Wilhelm Ackermann
(1896–1962) in their book Principles of Mathematical Logic (1928), followed by the two-volume
book Grundlagen der Mathematik of Hilbert and Paul Bernays (1888–1977), published in 1934
and 1939. These books were most influential for the development of logic and the foundations
of mathematics in the first half of the 20th century. In particular, Hilbert vigorously promoted
the idea of building the whole body of mathematics as a formal axiomatic system – a deductive
system mainly based on axioms and on a very few and simple rules of inference. Thus, Hilbert
was the leading proponent of the development of the formal, axiomatic approach in mathe-
matics, meant to replace the semiformal notion of mathematical proof by the completely
formalized notion of derivation in an axiomatic system, thus freeing mathematics from
paradoxes and other possible contradictions and putting it on sound logical foundations.6
5 Read more on Hilbert in the box at the end of this section.
6 In the early 1930s it turned out from the groundbreaking works of the most famous logician of the 20th century
Kurt Gödel (1906–1978) that Hilbert’s idea was only partly realizable, for purely logical validity and consequence in
first-order logic, but it was not realizable for “mathematical” consequence, even in relatively simple mathematical
systems such as arithmetic.

Propositional Logic
111
There are different types of deductive systems, but they all share several common aspects
and principles:
• A deductive system works within a formal logical language, where derivations are performed
on formal expressions, called formulae (or “sequents”, being finite sequences of formulae),
which are special words–finite strings of symbols – in the formal language, having precise
syntax.7
• The main component of a deductive system is the notion of derivation (inference, deduction)
from a given set of assumptions, based on a set of precisely specified rules of inference. The idea,
again, is that by systematically applying these rules, one can derive (infer, deduce) formulae
from other formulae that are already derived, or assumed as given, and called assumptions
(premises). In addition, axiomatic systems also allow for an initial set of formulae, called
axioms, to be accepted as derived without applying any rules of inference. Thus, the axioms
can always be used as premises in derivations.
If a formula A can be derived from a set of assumptions Γ in a deductive system , we
denote this by
Γ ⊢A
and say that A is a deductive consequence from Γ in . In particular, if Γ = ∅, we write
⊢A
and say that A is a theorem of .
• A very important aspect of deductive systems is that derivations in them are completely
mechanical procedures, which do not require any intelligence or understanding of the mean-
ing of the formulae or rules involved; in fact, such meaning need not be specified at all. Thus,
derivations in a given deductive system can be performed by a mechanical device, such as
computer, without any human intervention, as long as the axioms and rules of inference of
the deductive system have been programmed into it.
• While deductive systems are not concerned with the meaning (semantics) of the formulae
they derive, they are designed with the purpose of deriving valid, and only valid, logical con-
sequences from the assumptions. A deductive system with this property is called sound. In
particular, every theorem in a sound deductive system must be true; i.e. in the case of propo-
sitional logic it must be a tautology. Formally, a deductive system is sound (or correct) for
a given logical semantics (i.e. well-defined notions of logical validity and consequence) if 
can only derive logically valid consequences, i.e.:
A1‚ …‚ An ⊢C implies A1‚ …‚ An ⊨C.
In particular:
⊢C implies
⊨C.
• A deductive system is complete for a given logical semantics if can derive every valid
logical consequence, i.e.:
A1‚ …‚ An ⊨C implies A1‚ …‚ An ⊢C.
7 In this aspect a deductive system is much like a programming language.

112
Logic and Discrete Mathematics: A Concise Introduction
In particular:
⊨C implies ⊢C‚
i.e. a complete deductive system can derive every logically valid formula.
A deductive system is adequate for a given semantics if it is both sound and complete for
it, i.e.:
A1‚ …‚ An ⊨C if and only if A1‚ …‚ An ⊢C.
In particular:
⊨C if and only if ⊢C.
The most popular types of deductive systems for classical logic are: Axiomatic systems,
Natural deduction, Sequent calculi, Semantic tableaux and Resolution. In this book we only present
Semantic tableaux and Resolution, as they are the easiest to use and automatize.
David Hilbert (23.01.1862–14.02.1943)
David Hilbert was one of the leading and most influential mathematicians
of the late 19th and early 20th centuries. He studied at the University of
Königsberg and in 1895 was appointed Professor of Mathematics at the Uni-
versity of Göttingen – the world leading research center for mathematics at
that time – where he remained for the rest of his life. Hilbert’s contributions
to mathematics were encyclopaedic, ranging from his fundamental ideas in
mathematical logic and the foundations of mathematics to revolutionizing
the theory of invariants and the theory of algebraic number fields, introducing (what is now called)
Hilbert spaces, and founding the field of functional analysis as the main instrument of modern
mathematical physics. At the end of the 19th century Hilbert completely revised and modernized
Euclid’s seminal work Elementa (see the box at the end of Section 5.3 in Chapter 5) in his book Foun-
dations of Geometry published in 1899, with which he put the foundations of geometry in a formal
axiomatic setting. With this work Hilbert also promoted the formal, axiomatic approach to mathe-
matics and essentially launched what became known as Hilbert’s programme for axiomatizing and
formalizing the entire body of mathematics. This was the most influential development in the foun-
dations of mathematics throughout the 20th century. By putting forward and persistently pursuing
that programme for many decades, Hilbert became one of the founders of proof theory – which he
called metamathematics – a major branch of mathematical logic.
In his historical speech The Problems of Mathematics, delivered at the Second International
Congress of Mathematicians in Paris in 1900, Hilbert presented his famous list of 23 unsolved
mathematical problems, the solutions of which would, according to him, guide and chart the
development of mathematics in the 20th century. Many of Hilbert’s 23 problems were solved
during the 20th century and their solutions influenced much of the development of mathematics
at the time. Others, such as Goldbach’s conjecture and the Riemann hypothesis, are still famous
unsolved problems.
Hilbert was baptized and raised in the Protestant church, but later on he became an agnostic.
He argued that mathematical truth was independent of the existence of God or other a priori
assumptions. In his 1930 retirement address he responded to the Latin maxim: “Ignoramus et
ignorabimus” (“We do not know, we shall not know”), used in the 19th century in connection with the
perceived limits of scientific knowledge, by stating his famous mathematician’s credo: “Wir müssen
wissen. Wir werden wissen” (“We must know. We will know”). These words became the epitaph on his
tombstone in Göttingen.

Propositional Logic
113
3.4.
Semantic tableaux
Here we will formalize the idea of testing the validity of propositional formulae and inferences
by a systematic search for a falsifying truth assignment into a formal (deductive) system, called
the semantic tableaux. The first versions of the semantic tableaux were designed in the 1950s
by the logicians Evert Beth and Jaakko Hintikka and further developed in the 1960s and later
by Raymond Smullyan, Melvin Fitting and others.
In order to prove a logical consequence A1‚ …‚ An ⊨B‚ the method of semantic tableaux
attempts to show that there is no truth assignment that falsifies it, which is equivalent to show-
ing that the formulae A1‚ …‚ An and ¬B cannot be satisfied simultaneously.
The system of semantic tableaux (ST) is based on formula-decomposition rules, which
reduce the truth or falsity of a formula to the truth or falsity of its main subformulae. These
rules can be extracted from the truth tables of the propositional connectives as follows:
1. ¬ ∶
(¬T) For ¬A to be true, A must be false.
(¬F) For ¬A to be false, A must be true.
2. ∧∶
(∧T) For A ∧B to be true, A must be true and B must be true.
(∧F) For A ∧B to be false, A must be false or B must be false.
3. ∨∶
(∨T) For A ∨B to be true, A must be true or B must be true.
(∨F) For A ∨B to be false, A must be false and B must be false.
4. →∶
(→T) For A →B to be true, A must be false or B must be true.
(→F) For A →B to be false, A must be true and B must be false.
5. ↔∶
(↔T) For A ↔B to be true, A and B must be true or A and B must be false.
(↔F) For A ↔B to be false, A must be true and B must be false or A must be false and
B must be true.

114
Logic and Discrete Mathematics: A Concise Introduction
These rules can be formalized further as follows:
Rules for semantic tableaux in propositional logic
Non-branching rules ( -rules)
Branching rules ( -rules)
(∧T)
A ∧B ∶T
↓
A ∶T, B ∶T
(∧F)
A ∧B ∶F
↙           ↘
A ∶F
B ∶F
(∨F)
A ∨B ∶F
↓
A ∶F, B ∶F
(∨T)
A ∨B ∶T
↙            ↘
A ∶T
B ∶T
(→F)
A →B ∶F
↓
A ∶T, B ∶F
(→T)
A →B ∶T
↙
↘
A ∶F
B ∶T
(¬T)
¬A ∶T
↓
A ∶F
(↔T)
A ↔B ∶T
↙
↘
A ∶T, B ∶T
A ∶F, B ∶F
(¬F)
¬A ∶F
↓
A ∶T
(↔F)
A ↔B ∶F
↙
↘
A ∶T, B ∶F
A ∶F, B ∶T
Using these rules we can search systematically for an assignment, falsifying a given for-
mula. In the process of this systematic application of the rules we build a “search tree”, called
a tableau.
If we are to derive the consequence A1‚ …‚ An ⊨B we start by placing the signed formulae
A1 ∶T,…‚ An ∶T,B ∶F
at the root of the tree and then extend it downwards by applying repeatedly the decomposition
rules to signed formulae appearing on the tree as follows:
1. A branch on the tree is selected.
2. A signed formula occurring on that branch is selected to which a decomposition rule
has not been applied yet on that branch.
3. The respective decomposition rule is applied to that signed formula. As a result, one
(for the 𝛼-rules) or two (for the 𝛽-rules) successor nodes are added, labelled with the
signed formulae which that rule introduces.
We repeat that procedure along every branch of the tableau until:
• either a contradictory pair of signed formulae – i.e. a pair of the type A ∶T, A ∶F – appears
on the branch, in which case we declare that branch closed (meaning that no assignment
can ever be found which satisfies all signed formulae on that branch), mark it by × and do
not extend it any further
or

Propositional Logic
115
• no new applications of decomposition rules are possible on that branch, i.e. every signed
formula appearing on the branch has already been decomposed further on that branch. Then
we say that the branch is saturated. If a saturated branch is not closed yet, we declare it open
and mark it by ○. If the tableau construction ends with at least one open branch, the tableau
is declared open.
Note that an open branch defines an assignment for all variables occurring on that branch
as follows: a variable p is true under that assignment if p ∶T appears on the branch and is
false otherwise (in which case, p ∶F may or may not appear on the branch). It is easy to check
that such an assignment will satisfy all signed formulae on the branch. That can be done step
by step by going up the branch. Eventually, all signed formulae at the root will be satisfied,
which will falsify the logical consequence A1‚ …‚ An ⊨B and will thus prove it invalid.
On the other hand, if all branches of the tableau close, then the entire tableau is declared
closed. This means that the systematic search for an assignment satisfying the input formulae
listed at the root has failed. Then we say that B is derived from A1‚ …‚ An in ST, which we
denote by
A1‚ …‚ An⊢STB.
In particular, if ∅⊢ST B then we say that B is a theorem of ST.
It can be proved that the semantic tableaux is sound and complete, i.e.:
A1‚ …‚ An ⊢ST B iff A1‚ …‚ An ⊨B.
In particular, the tableau applied to B ∶F closes iff B is a tautology.
Example 3.4.1
Let us demonstrate the method of semantic tableaux on some of the examples we did infor-
mally in Example 3.1.5:
1. Show that ¬(p →¬q) →(p ∨¬r) is a tautology:
¬(p →¬q) →(p ∨¬r) ∶F
↓
¬(p →¬q) ∶T, (p ∨¬r) ∶F1
↓
p →¬q ∶F
↓
p ∶T, ¬q ∶F
↓
q ∶T
↓1
p ∶F, ¬r ∶F
×
Thus, ⊢ST¬(p →¬q) →(p ∨¬r) and hence ⊨¬(p →¬q) →(p ∨¬r).

116
Logic and Discrete Mathematics: A Concise Introduction
Note that no branching rules were applicable in this example, so the tableau consists of
only one branch, which closes because the complementary pair p ∶T,p ∶F appears on it.
The superscript 1 is used as a label indicating where the decomposition rule is applied to
the formula (p ∨¬r) ∶F. This label is not needed for the derivation; it has only been added
for bookkeeping purposes and as an aid to following the construction of the tableau, and
will not be systematically used further.
2. Check if ¬p ⊨¬(p ∨¬q).
¬p ∶T, ¬(p ∨¬q) ∶F
↓
p ∶F
↓
p ∨¬q ∶T
↙
↘
p ∶T
¬q ∶T
×
↓
q ∶F
○
The left-hand branch closes, but the right-hand one does not close and no more decompo-
sition rules are applicable on it. Thus it is declared open, and therefore the whole tableau
is open, which means that ¬p ⊭¬(p ∨¬q). Indeed, the right-hand branch provides a falsi-
fying valuation for that consequence: p ∶F,q ∶F. (Check it!)
3. Check whether (¬p →q)‚ ¬r ⊨p ∨¬q ∶
(¬p →q) ∶T, ¬r ∶T, p ∨¬q ∶F
↓
r ∶F
↓
p ∶F, ¬q ∶F
↓
q ∶T
↙
↘
¬p ∶F
q ∶T
↓
○
p ∶T
×
Again, the tableau is open, and a falsifying valuation is provided by the open
branch: p ∶F,q ∶T,r ∶F. Note that we chose to first decompose the subformu-
lae ¬r ∶T and (p ∨¬q) ∶F because they are nonbranching (𝛼-formulae) and then
¬p →q ∶T, which is branching (𝛽-formula). This does not make a difference in
the outcome of the tableau but saves some work, so it is a generally preferrable
strategy.

Propositional Logic
117
4. Check whether ((p ∧¬q) →¬r) ↔((p ∧r) →q) is a tautology.
((p ∧¬q) →¬r) ↔((p ∧r) →q) ∶F
↙
↘
(p ∧¬q) →¬r ∶T, (p ∧r) →q ∶F
↓
p ∧r ∶T, q ∶F
↓
p ∶T, r ∶T
↙
p ∧¬q ∶F
↙
p ∶F
×
↘
¬q ∶F
↓
q ∶T
×
↘
¬r ∶T
↓
r ∶F
×
(p ∧r) →q ∶T, (p ∧¬q) →¬r ∶F
↓
p ∧¬q ∶T, ¬r ∶F
↓
p ∶T, ¬q ∶T
↓
q ∶F
↓
r ∶T
↙
p ∧r ∶F
↙
p ∶F
×
↘
r ∶F
×
↘
q ∶T
×
The tableau closes and hence the formula is a tautology.
Lastly, here are a few further remarks:
1. At any stage during the construction of a semantic tableau, more than one decom-
position rule may be applicable. Depending of the order of their application, the
tableau tree may develop differently, but the final result – whether the tableau closes
or not – will always be the same. That order is therefore inessential. However, it may
affect the size of the tableau tree. As a general guideline, it is better to first apply the
non-branching rules before applying the branching rules (if there is a choice) as this
would defer the branching and would reduce the size of the tableau.
2. Note that no node in a tableau can have more than two children nodes. Thus, if a node
in your tableau has three or more children then there is something wrong!
3. Although we can use equivalences like p ∧(q ∨p) ≡p and ¬(p ∧q) ≡¬p ∧¬q when rea-
soning informally, these equivalences do not form part of the rules of the deductive
system of ST and should not be used in the construction of the tableaux tree. As we
emphasized in Section 3.3, derivations within a deductive system may only use the
rules of that system, in order to be completely mechanizable.
3.4.1.
Exercises
For each of the following exercises use the method of semantic tableaux.
➊Check which of the following formulae are tautologies.

118
Logic and Discrete Mathematics: A Concise Introduction
(a) ((p →q) →q) →q
(b) ((q →p) →q) →q
(c) ((p →q) ∧(p →¬q)) →¬p
(d) ((p ∨q) →¬r) →¬(¬q ∧r)
(e) ((p →q) ∧(p →r)) →(p →(q ∧r))
(f) ((p →r) ∧(q →r)) →((p ∨q) →r)
(g) ((p →r) ∨(q →r)) →((p ∨q) →r)
(h) ((p →r) ∧(q →r)) →((p ∧q) →r)
(i) p →((q →r) →((p →q) →r))
(j) (p →(q →r)) →((p →q) →(p →r))
➋Check which of the following logical consequences are valid.
(a) ¬p →q‚ ¬p →¬q ⊨p
(b) p →(q ∧r) ⊨(p →q) ∧(p →r)
(c) (p ∧q) →r ⊨(p →r) ∧(q →r)
(d) (p ∧q) →r ⊨(p →r) ∨(q →r)
(e) (p ∨q) →r ⊨(p →r) ∧(q →r)
(f) (¬p ∧q) →¬r‚ r ⊨p ∨¬q
➌Let P‚ Q‚ R and S be propositions. Check whether:
(a) if P →Q‚ Q →R and P ∧S are true, then R ∧S is true;
(b) if R and (P ∧¬R) are false and ¬P →¬Q is true, then Q is false;
(c) if Q →(R ∧S) is true and Q ∧S is false, then R ∧Q is false;
(d) if P →Q and Q →(R ∨S) are true and P →R is false, then S is true;
(e) if Q →(R ∧S) is true and Q ∧S is false, then Q is false.
➍Check the soundness of each of following inference rules.
(a) Rule of propositional resolution:
p ∨r‚ q ∨¬r
p ∨q
(b)
(p ∨q) →r‚ p ∨r
r
(c)
p →q‚ ¬q ∨r‚ ¬r
¬p

Propositional Logic
119
(d)
p →q‚ p ∨¬r
q →r
(e)
¬p →¬q‚ ¬(p ∧¬r)‚ ¬r
¬q
(f)
p →q‚ r ∨(s ∧¬q)‚ q
¬p
(g)
p →q‚ q →(r ∨s)‚ ¬(p →r)
s
➎Check the logical correctness of each of the following propositional arguments.
(a)
If the triangle ABC has a right angle, then it is not equilateral.
The triangle ABC does not have a right angle.
Therefore, the triangle ABC is equilateral.
(b) In the following argument n is a certain integer.
If n is divisible by 2 and n is divisible by 3‚then n is divisible by 6.
If n is divisible by 6‚then n is divisible by 2.
n is not divisible by 3.
Therefore n is not divisible by 6.
(c)
If Bill likes logic, then he is clever.
If Bill is clever, then he is rich.
Therefore, if Bill likes logic, then he is rich.
(d)
Socrates is wise or not happy.
If Socrates is not wise then Socrates is not a philosopher.
Therefore, if Socrates is a philosopher then Socrates is not happy.
(e)
If Christina is not a good student, then she is not clever or she is lazy.
If Christina is clever, then she is not lazy.
Therefore, if Christina is clever, then she is a good student.

120
Logic and Discrete Mathematics: A Concise Introduction
(f)
If Victor studies hard and he is clever, then he will go to a university.
If Victor does not study hard, then he will not get a good job.
Therefore, if Victor is clever, then he will go to a university or will not get a good job.
(g)
Johnny will not learn logic if he skips lectures
Johnny will pass the exam if he learns logic and does not skip lectures.
Therefore if Johnny skips lectures or does not pass the exam then he will not learn logic.
(h) Replace the second premise of the propositional argument in the previous question with
“Johnny will pass the exam only if he learns logic and does not skip lectures” and deter-
mine whether the resulting argument in logically correct.
Early proof theory
The idea of proof as demonstrative argumentation goes back to Aristotle, but the idea of a formal
proof as a sequence of precisely specified derivation steps in a formal system of logical and mathe-
matical deduction was perhaps first suggested in the late 17th century by Leibniz, with his calculus
ratiocinator. This idea has been systematically developed only since the late 19th century, first by
Frege (see the box at the end of Section 4.1 in Chapter 4) and later mainly by Hilbert (see Section
3.3), in the context of his programme on the foundations of mathematics.
Hilbert’s concept of a formal proof, or derivation, in an axiomatic system was a purely syntactic,
mechanically implementable and verifiable procedure producing a sequence of formulae, derived
by means of explicitly specified simple rules of inference by using axioms – formulae assumed to be
given without derivation – or other already derived formulae, ending up with the desired conclu-
sion. The main purpose was to avoid any paradoxes and contradictions in mathematics by doing
all mathematical proofs within such a formal system of deduction, which could be proved to be
consistent, i.e. free from contradictions. Such a system, based on first-order logic, was proposed by
Hilbert and Ackermann in their book Principles of Mathematical Logic and Hilbert’s ultimate goal
was to prove that that system was both consistent and complete, i.e. capable of deriving every
mathematical truth. Later, Hilbert’s idea of axiomatic systems, as a paradigm of a deductive system,
was extended by adding the possibility of making and withdrawing assumptions in derivations,
i.e. formulae that are neither axioms nor have been derived. First versions of such systems, now
called natural deduction, were independently developed by Stanisław Ja´skowski in 1929 and Ger-
hard Gentzen in 1934. Gentzen’s system involved two kinds of inference rules: introduction rules
and elimination rules for each logical connective, an idea that turned out to be very important in
proof theory. In his thesis Untersuchungen über das Logische Schliessen (Investigations into Logical Infer-
ence), completed in 1933 under Bernays’ supervision, he wrote that his aim was formal analysis of
mathematical proofs as they occur in practice.
Gentzen’s motivation was to provide a purely syntactic, combinatorial proof of the consistency
of Peano’s axiom system of arithmetic (see the box at the end of Section 4.2). In this he was partly

Propositional Logic
121
successful. In order to analyse derivations better and to prove a special property of derivations that
could be used for the proof of consistency, Gentzen also introduced the sequent calculus, a deduction
system based not just on formulae but on sequents–pairs of lists of formulae, assumptions on the
left and conclusions on the right – with a set of rules for manipulating and deriving sequents.
A few years later, in 1931, Kurt Gödel (see the box at the end of Section 4.5) proved his Second
Incompleteness Theorem, stating that no sufficiently expressive deductive system, such as Peano’s
system of arithmetic, can prove its own consistency – suitably encoded as a formula in that sys-
tem – unless it is inconsistent (in which case it can derive any formula by using the sound logical
rule Ex Falso Quodlibet), and therefore an absolute and finitary proof of consistency of such system
is impossible. Thus, Hilbert’s dream of formalizing the whole of mathematics was shattered and
Gentzen’s ultimate goal was proved unattainable. Still, proof theory flourished as one of the main
branches of mathematical logic after Gentzen’s ground-breaking work, and it has achieved a lot
in analyzing the notion of derivation and in proving relative consistency results. The method of
semantic tableaux, also known as analytic tableaux, was first introduced as a system of logical deduc-
tion in the mid 1950s, independently by the Dutch logician Evert Beth and the Finnish philosopher
Jaakko Hintikka. It was further developed and simplified by the American logician, philosopher
and magician, Raymond Smullyan, in the late 1960s. Since then, systems of semantic tableaux have
also been developed for a great variety of non-classical logical systems.
3.5.
Logical equivalences. Negating propositional formulae
3.5.1.
Logically equivalent propositional formulae
Definition 3.5.1 Propositional formulae A and B are logically equivalent, which will be denoted by
A ≡B, if for every assignment of truth values to the variables occurring in them they obtain the same
truth values.
Being a little imprecise (you will see why), we say that A and B are logically equivalent if
they have the same truth tables. The following are examples of logically equivalent formulae:
• p ∨¬p ≡⊤(excluded middle) and p ∧¬p ≡⊥(contradiction).
• p ≡(¬¬p): a double negation of a proposition is equivalent to the proposition itself.
• ¬(p ∧q) ≡(¬p ∨¬q) and ¬(p ∨q) ≡(¬p ∧¬q). These are known as De Morgan’s laws.
Let us check the first one, using the simplified version of truth tables:
p
q
¬
(p
∧
q)
(¬
p
∨
¬
q)
T
T
F
T
T
T
F
T
F
F
T
T
F
T
T
F
F
F
T
T
T
F
F
T
T
F
F
T
T
F
T
F
T
F
F
T
F
F
F
T
F
T
T
F
• (p ∧(p ∨q)) ≡(p ∧p). There is a small problem here: it is not quite clear what it means to say
that the truth tables of these formulae are the same, for the first one contains two variables

122
Logic and Discrete Mathematics: A Concise Introduction
(p and q) while the second one contains only p. We can always think that q occurs vacuously
in the second formula and include it in its truth table:
p
q
(p
∧
(p
∨
q))
(p
∧
p)
T
T
T
T
T
T
T
T
T
T
T
F
T
T
T
T
F
T
T
T
F
T
F
F
F
T
T
F
F
F
F
F
F
F
F
F
F
F
F
F
Warning: do not confuse the logical connective ↔and logical equivalence between formu-
lae. These are different things but there is a simple relation between them:
The propositions A and B are logically equivalent if and only if the proposition A ↔B is a
tautology.
Indeed, both mean the same: A and B always take the same truth values.
Checking logical equivalence can be streamlined, just like checking validity or logical con-
sequence, by searching systematically for a falsifying assignment: in order to check if A ≡B
we try to construct an assignment of truth values to the variables occurring in A and B that
renders one of them true and the other false. If such an assignment exists, the formulae are
not logically equivalent; otherwise they are. For example, let us check the second of De Mor-
gan’s laws: ¬(p ∨q) ≡(¬p ∧¬q). There are two possibilities for an assignment to falsify that
equivalence:
(i) ¬(p ∨q) ∶T,(¬p ∧¬q) ∶F. Then p ∨q ∶F and hence p ∶F, and q ∶F, but then (¬p ∧
¬q) ∶T – a contradiction.
(ii) ¬(p ∨q) ∶F,(¬p ∧¬q) ∶T . Then ¬p ∶T and ¬q ∶T and hence p ∶F, and q ∶F, but
then ¬(p ∨q) ∶T – a contradiction again.
Thus, there is no such assignment; hence the logical equivalence holds.
The idea above can be formalized further, using the semantic tableaux, by reducing logical
equivalence to a tautology:
The propositions A and B are logically equivalent if and only if ⊨A ↔B.
Alternatively, sometimes it is better to apply the semantic tableaux by reducing logical
equivalence to logical consequences:
The propositions A and B are logically equivalent if and only if A ⊨B and B ⊨A.
This approach allows us to establish which of the two formulae implies the other, if any,
in case the equivalence does not hold.
In the case of the example above, check that both tableaux, for ¬(p ∨q) ⊨(¬p ∧¬q) and for
(¬p ∧¬q) ⊨¬(p ∨q), close.

Propositional Logic
123
3.5.2.
Some important equivalences
Let us now discuss some kinds of important and useful logical equivalences. Verifying them
is an easy but useful exercise.
Equivalences expressing algebraic laws for the logical connectives
We begin with some important logical equivalences, which are used, for example for equiv-
alent transformations of propositional formulae to so-called conjunctive and disjunctive normal
forms, to be introduced later in Section 3.6.
• Idempotency: p ∧p ≡p and p ∨p ≡p.
• Commutativity: p ∧q ≡q ∧p and p ∨q ≡q ∨p.
• Associativity: (p ∧(q ∧r)) ≡((p ∧q) ∧r) and (p ∨(q ∨r)) ≡((p ∨q) ∨r). This property allows
us to omit the parentheses in multiple conjunctions and disjunctions.
• Absorption: p ∧(p ∨q) ≡p and p ∨(p ∧q) ≡p.
• Distributivity: p ∧(q ∨r) ≡(p ∧q) ∨(p ∧r) and p ∨(q ∧r) ≡(p ∨q) ∧(p ∨r).
Equivalences mutually expressing logical connectives
The following logical equivalences can be used to define logical connectives in terms of others:
• ¬A ≡A →⊥. (We sometimes use this equivalence in colloquial expressions, such as “If this
is true then I can ﬂy”, meaning to say: “This cannot be true”.)
• A ↔B ≡(A →B) ∧(B →A). This equivalence allows us to consider the biconditional as a
definable connective, which we will do often.
• A ∨B ≡¬(¬A ∧¬B).
• A ∧B ≡¬(¬A ∨¬B).
• A →B ≡¬A ∨B ≡¬(A ∧¬B).
• A ∨B ≡¬A →B.
• A ∧B ≡¬(A →¬B).
Thus, we see that each of ∧‚ ∨‚ →can be expressed by means of any other of them, using
negation.
Some simplifying equivalences
Other useful logical equivalences can be used to simplify formulae:
• A ∨¬A ≡⊤; A ∧¬A ≡⊥
• A ∧⊤≡A; A ∧⊥≡⊥
• A ∨⊤≡⊤; A ∨⊥≡A
• ¬A →¬B ≡B →A (Every implication is equivalent to its contrapositive.)

124
Logic and Discrete Mathematics: A Concise Introduction
Negating propositional formulae. Negation normal form
In mathematical and other arguments we sometimes have to negate a formalized statement
and then use the result in further reasoning. For that it is useful to transform, up to logical
equivalence, the formula formalizing the statement into negation normal form, where nega-
tion may only occur in front of propositional variables. Such transformation can be done by
importing all occurrences of negations inside the other logical connectives step by step, using
the following equivalences, some of which we already know:
• ¬¬A ≡A
• ¬(A ∧B) ≡¬A ∨¬B
• ¬(A ∨B) ≡¬A ∧¬B
• ¬(A →B) ≡A ∧¬B
• ¬(A ↔B) ≡(A ∧¬B) ∨(B ∧¬A)
Example 3.5.2
Equivalent transformation to negation normal form:
¬((A ∨¬B) →(¬C ∧D))
≡(A ∨¬B) ∧¬(¬C ∧D)
≡(A ∨¬B) ∧(¬¬C ∨¬D)
≡(A ∨¬B) ∧(C ∨¬D)
3.5.3.
Exercises
➊Verify the following logical laws:
(a) Idempotency: p ∧p ≡p‚ p ∨p ≡p
(b) Commutativity: p ∧q ≡q ∧p p ∨q ≡q ∨p
(c) Associativity: (p ∧(q ∧r)) ≡((p ∧q) ∧r) (p ∨(q ∨r)) ≡((p ∨q) ∨r)
(d) Absorption: p ∧(p ∨q) ≡p‚ p ∨(p ∧q) ≡p
(e) Distributivity: p ∧(q ∨r) ≡(p ∧q) ∨(p ∧r)‚ p ∨(q ∧r) ≡(p ∨q) ∧(p ∨r)
(f) De Morgan’s laws: ¬(p ∧q) ≡(¬p ∨¬q)‚ ¬(p ∨q) ≡(¬p ∧¬q)
➋Prove the following logical equivalences:
(a) (p →q) ∧(p →r) ≡p →(q ∧r)
(b) (p →q) ∨(p →r) ≡p →(q ∨r)

Propositional Logic
125
(c) ((p ∨q) →r)‚ (p →r) ∧(q →r)
(d) p ↔q ≡(p →q) ∧(q →p)
(e) ¬(p ↔q) ≡(p ∧¬q) ∨(q ∧¬p)
(f) ¬(p ↔q) ≡¬p ↔q ≡p ↔¬q
(g) p ↔q ≡q ↔p
(h) p ↔(q ↔r) ≡(p ↔q) ↔r
➌Determine which of the following pairs of formulae are logically equivalent:
(a) p →q‚ q →p
(b) p →q‚ ¬p →¬q
(c) p →¬q‚ q →¬p
(d) ¬(p →¬q)‚ p ∧q
(e) ((p →q) →q) →q‚ p ∨q
(f) (p →r) ∧(q →r)‚ (p ∧q) →r
(g) (p →r) ∨(q →r)‚ (p ∨q) →r
(h) ((p ∧q) →r)‚ (p →r) ∨(q →r)
(i) p →(q →r)‚ (p →q) →r
(j) p ↔(q ↔r)‚ q ↔(p ↔r)
(k) p →(q →r)‚ (p →q) →(p →r)
➍Negate each of the following propositional formulae and transform the result to an equiv-
alent formula in a negation normal form.
(a) (p ∨¬q) ∧¬p
(b) (p →¬q) →p
(c) p →(¬q →p)
(d) (p ↔¬q) →¬r
(e) p →(¬q ↔r)

126
Logic and Discrete Mathematics: A Concise Introduction
Augustus De Morgan (27.6.1806–18.3.1871)
Augustus De Morgan was a British mathematician, logician and a pop-
ularizer of mathematics. Influenced by George Boole (see Section 3.2),
he pioneered the application of algebraic methods to the study of logic
in the mid 19th century, thus becoming one of the founding fathers of
modern mathematical logic. In particular, he was the first to formulate
the logical equivalences now known as de Morgan’s laws.
De Morgan was born in Madura, India, and became blind in one eye
soon after his birth. He graduated from Trinity College, Cambridge, and
in 1828 became the first Professor of Mathematics at the newly estab-
lished University College in London, where he taught during most of his academic life.
He was an enthusiastic and prolific writer of over 700 popular articles in mathematics for the
Penny Cyclopaedia, aimed at advancing broad education in mathematics in Britain. In one of them,
in 1838, he formally introduced the term “mathematical induction” and made the so far informally
used method of mathematical induction a precise mathematical technique. He also wrote books,
such as Trigonometry and Double Algebra and The Differential and Integral Calculus. In 1847 he pub-
lished his main work on mathematical logic, called Formal Logic: The Calculus of Inference, Necessary
and Probable, which was used for a very long time and was last reprinted in 2003. De Morgan was
also a passionate collector of mathematical puzzles and curiosities, paradoxes, etc., many of which
he included in his book A Budget of Paradoxes published in 1872 (now digitalized and available on
the Internet).
In 1866 De Morgan became one of the founders and the first President of the London Mathe-
matical Society.
There is a crater on the Moon named De Morgan after him.
3.6.
Normal forms. Propositional resolution
Here we will present another system for the derivation of logical consequences, which is par-
ticularly suitable for automated and computer-aided reasoning as it is based on a single rule
of inference, called (propositional) resolution. Just like the semantic tableaux, it is sound and
complete, i.e. it can derive all and only the valid logical consequences.
The Resolution Rule is very simple:
A ∨C‚ B ∨¬C
A ∨B
‚
where A‚ B‚ C are any propositional formulae. The formula A ∨B is called a resolvent of A ∨C
and B ∨¬C, and we write A ∨B = Res(A ∨C‚ B ∨¬C).
The Rule of Propositional Resolution is logically sound. Exercise 1.4(a) asked you to
check that.
3.6.1.
Conjunctive and disjunctive normal forms of propositional formulae
The Resolution Rule is particularly efficient when applied to formulae that are pre-processed
into so-called clausal form. In order to define that we need some technical preparation.

Propositional Logic
127
Definition 3.6.1 First, we need some terminology:
1. A literal is a propositional variable or its negation.
2. An elementary disjunction (respectively elementary conjunction) is any literal or a dis-
junction (respectively conjunction) of two or more literals.
3. A disjunctive normal form (DNF) is any elementary conjunction or a disjunction of two or
more elementary conjunctions.
4. A conjunctive normal form (CNF) is any elementary disjunction or a conjunction of two or
more elementary disjunctions.
Example 3.6.2
Some examples illustrating these notions are:
• p, ¬q, p ∨¬q, p ∨¬p ∨q ∨¬r are elementary disjunctions;
• p, ¬q, ¬p ∧q, ¬p ∧q ∧¬r ∧¬p are elementary conjunctions;
• p, ¬q, p ∧¬q, p ∨¬q, (p ∧¬p) ∨¬q, (r ∧q ∧¬p) ∨(¬q ∧p) ∨(¬r ∧p) are disjunctive normal
forms;
• p, ¬q, p ∧¬q, p ∨¬q, p ∧(¬p ∨¬q), (r ∨q ∨¬r) ∧¬q ∧(¬p ∨r) are conjunctive normal forms.
The normal forms are convenient for various symbolic manipulations and logical compu-
tations. Also, they are used for construction and optimization of logical circuits in computer
systems design. That is why the following fact is quite important.
Theorem 3.6.3 Every propositional formula is equivalent to a disjunctive normal form and to a con-
junctive normal form.
We will give two methods for constructing such equivalent normal forms.
Method 1 This method is based on the following algorithm, which transforms any formula into a DNF,
respectively CNF.
1. Eliminate all occurrences of ↔and →using the logical equivalences
A →B ≡¬A ∨B‚
A ↔B ≡(A →B) ∧(B →A).
2. Import all negations to stand directly in front of the propositional variables, using the logical
equivalences listed above.
3. For DNF: distribute all conjunctions over disjunctions using the distributive law: p ∧(q ∨r) ≡
(p ∧q) ∨(p ∧r).
4. Respectively, for CNF: distribute all disjunctions over conjunctions using the other distributive
law: p ∨(q ∧r) ≡(p ∨q) ∧(p ∨r).

128
Logic and Discrete Mathematics: A Concise Introduction
Throughout this process the formulae can be simplified by using commutativity, associa-
tivity and idempotency of ∨and ∧, as well as:
p ∨¬p ≡⊤‚ p ∧¬p ≡⊥‚ ‚ ; p ∧⊤≡p‚ p ∧⊥≡⊥; p ∨⊤≡⊤‚ p ∨⊥≡p.
Example 3.6.4
(p ∧¬r) →(p ↔¬q)
≡¬(p ∧¬r) ∨((p →¬q) ∧(¬q →p))
≡(¬p ∨¬¬r) ∨((¬p ∨¬q) ∧(¬¬q ∨p))
≡¬p ∨r ∨((¬p ∨¬q) ∧(q ∨p))
For a DNF we further distribute ∧over ∨and simplify:
≡¬p ∨r ∨(((¬p ∨¬q) ∧q) ∨((¬p ∨¬q) ∧p))
≡¬p ∨r ∨((¬p ∧q) ∨(¬q ∧q)) ∨((¬p ∧p) ∨(¬q ∧p))
≡¬p ∨r ∨((¬p ∧q) ∨⊥) ∨(⊥∨(¬q ∧p))
≡¬p ∨r ∨(¬p ∧q) ∨(¬q ∧p).
For a CNF we distribute ∨over ∧and simplify:
≡(¬p ∨r ∨¬p ∨¬q) ∧(¬p ∨r ∨q ∨p)
≡(¬p ∨r ∨¬q) ∧(⊤∨r ∨q)
≡(¬p ∨r ∨¬q) ∧⊤
≡¬p ∨r ∨¬q.
As we can see, in this case the CNF turns out to be a DNF as well, even simpler than the
one we obtained above. The problem of minimization of normal forms, which is of practical
importance, will not be discussed here.
Method 2 This second method constructs the normal forms directly from the truth table of the given
formula. We will outline it for DNF.
Given the truth table of the formula A we consider all rows (i.e. all assignments of truth
values to the occurring variables) where the truth value of A is true. If there are no such rows,
the formula is a contradiction and a DNF for it is, for example, p ∧¬p. Otherwise, with every
such row we associate an elementary conjunction in which all variables assigned value T occur
positively, while those assigned value F occur negated. For instance, the assignment F‚ T‚ F to
the variables p‚ q‚ r is associated with the elementary conjunction ¬p ∧q ∧¬r. Note that such
an elementary conjunction is true only under the assignment with which it is associated.

Propositional Logic
129
Example 3.6.5
The formula p ↔¬q has a truth table
p
q
p ↔¬q
T
T
F
T
F
T
F
T
T
F
F
F
The corresponding DNF is (p ∧¬q) ∨(¬p ∧q). Check this!
3.6.2.
Clausal form. Clausal resolution
Definition 3.6.6 (Clausal form) Some basic notions related to clausal forms:
1. A clause is essentially an elementary disjunction l1 ∨· · · ∨ln but written as a set of literals
{l1‚ …‚ ln}.
2. The empty clause is a clause containing no literals; a unit clause is a clause containing only
one literal.
3. A clausal form is a (possibly empty) set of clauses, written as a list: C1 · · · Ck. It represents
the conjunction of these clauses.
Thus, every CNF can be rewritten in a clausal form, and therefore every propositional
formula is equivalent to one in a clausal form.
For instance, the clausal form of the CNF formula (p ∨¬q ∨¬r) ∧¬p ∧(¬q ∨r) is
{p‚ ¬q‚ ¬r}{¬p}{¬q‚ r}.
The Resolution Rule can be rewritten for clauses as follows:
{A1‚ …‚ C‚ …‚ Am}{B1‚ …‚ ¬C‚ …‚ Bn}
{A1‚ …‚ Am‚ B1‚ …‚ Bn}
.
The clause {A1‚ …‚ Am‚ B1‚ …‚ Bn} is a resolvent of the clauses {A1‚ …‚ C‚ …‚ Am} and
{B1‚ …‚ ¬C‚…‚ Bn}.
Example 3.6.7
Some examples of applications of clausal resolution:
{p‚ q‚ ¬r}{¬q‚ ¬r}
{p‚ ¬r}
‚
{¬p‚ q‚ ¬r}{r}
{¬p‚ q}
‚
{¬p}{p}
{}
.

130
Logic and Discrete Mathematics: A Concise Introduction
Note that two clauses can have more than one resolvents, e.g.:
{p‚ ¬q}{¬p‚ q}
{p‚ ¬p}
‚ {p‚ ¬q}{¬p‚ q}
{¬q‚ q}
.
However, it would be wrong to apply the Resolution Rule for both pairs of complementary
literals concurrently and obtain
{p‚ ¬q}{¬p‚ q}
{}
.
Indeed, check that the above inference is not logically correct.
3.6.3.
Resolution-based derivations
The idea behind the method of resolution is similar to that of semantic tableaux. In order
to determine whether a logical consequence A1‚ …‚ An ⊨B holds using the method of res-
olution, we negate the conclusion B and transform each of the formulae A1‚ …‚ An‚ ¬B into
clausal form. Then we test whether the resulting set of clauses is unsatisfiable, by looking for
a resolution-based derivation of the empty clause from that set of clauses. Formally, this can
be defined as follows.
Definition 3.6.8 A resolution-based derivation of a formula B from a list of formulae A1‚ …‚ An is
a derivation of the empty clause {} from the set of clauses obtained from the formulae A1‚ …‚ An‚ ¬B,
by successive applications of the Rule of Propositional Resolution.
Example 3.6.9
Using Propositional Resolution, check the logical consequence p →q‚ q →r ⊨p →r.
Solution
First, we transform each of p →q‚ q →r‚ ¬(p →r) to clausal form. The resulting set of clauses
is:
C1 = {¬p‚ q}‚ C2 = {¬q‚ r}‚ C3 = {p}‚ C4 = {¬r}.
Now we apply the Resolution Rule successively:
C5 = {q} = Res(C1‚ C3);
C6 = {r} = Res(C2‚ C5);
C6 = {} = Res(C4‚ C6).
The derivation of the empty clause completes the proof that p →q‚ q →r ⊨p →r.

Propositional Logic
131
Example 3.6.10
Check whether (¬p →q)‚ ¬r ⊨p ∨(¬q ∧¬r) holds.
Solution
First transform (¬p →q)‚ ¬r‚ ¬(p ∨(¬q ∧¬r)) to clausal form:
C1 = {p‚ q}‚ C2 = {¬r}‚ C3 = {¬p}‚ C4 = {q‚ r}.
Now, applying resolution successively:
C5 = Res(C1‚ C3) = {q};
C6 = Res(C2‚ C4) = {q}.
At this stage, no new applications of the Propositional Resolution Rule are possible hence
the empty clause is not derivable. Therefore, (¬p →q)‚ ¬r ⊭p ∨(¬q ∧¬r).
Remark 3 Remember that, even though the clauses are represented as lists of literals, they are actually
sets, so if a literal occurs more than once in a clause, the repeated occurrences may be removed with no
harm. In fact, such repeated occurrences must be removed whenever they occur, else they may prevent
the derivation of the empty clause. For instance, the set of clauses {p‚ q}‚ {¬p‚ q}‚ {p‚ ¬q}‚ {¬p‚ ¬q}
is not satisfiable but the empty clause cannot be derived without deletion of repeating literals in the
resolvents. Check this!
3.6.4.
Optimizing the method of resolution
The method of resolution is amenable to various optimizations by means of special additional
rules and derivation strategies that we will not discuss here. We only mention some simple
rules that remove redundant clauses:
• Deletion of repeating literals: we have already discussed this as a necessary processing rule.
For instance, we derive
{p‚ ¬q‚ ¬r}{q‚ ¬r}
{p‚ ¬r}
instead of {p‚ ¬q‚ ¬r}{q‚ ¬r}
{p‚ ¬r‚ ¬r}
.
• Tautology deletion: if a clause contains a complementary pair of literals, then it is a tautology
and therefore is of no use for deriving a contradiction, i.e. the empty clause, so it can be
removed.
• Subsumption deletion: if a clause C contains (as a set of literals) a clause C′, then it is subsumed
by C′, and hence can be safely removed from the set of clauses, because every derivation of
the empty clause using C can be reduced to a possibly shorter derivation using C′ instead.
• Removal of all clauses containing a monopolar literal: if a clause C contains a literal l such that its
complementary literal l does not occur in any clause of the current set, then C can be removed
from the set, because every derivation of the empty clause using C can be simplified to a
possibly shorter derivation not using C. The reason is simple: the literal l will be inherited in

132
Logic and Discrete Mathematics: A Concise Introduction
every resolvent clause produced by using C as a parent clause because the complementary
literal l can never appear in a clause produced from the current clause set.
3.6.5.
Exercises
Some of the following exercises deal with Propositional Resolution. They are intended only
for the Computer science track.
➊
Prove that the Rule of Propositional Resolution is logically sound.
➋
Show that the disjunction of all elementary conjunctions associated with the rows in the
truth table of a formula A is logically equivalent to A.
➌∗
Outline a similar method for construction of a CNF from the truth table of a formula as in
Example 3.6.5. Prove your claim.
➍
Construct a DNF and a CNF, equivalent to each of the following formulae, using both
methods.
(a) ¬(p ↔q)
(b) ((p →q) ∧¬q) →p
(c) (p ↔¬q) ↔r
(d) p →(¬q ↔r)
(e) (¬p ∧(¬q ↔p)) →((q ∧¬p) ∨p)
➎
Using the method of resolution check which of the following formulae are tautologies.
(a) ((p →q) →q) →q
(b) ((q →p) →q) →q
(c) ((p →q) ∧(p →¬q)) →¬p
(d) ((p ∨q) →¬r) →¬(¬q ∧r)
(e) ((p →q) ∧(p →r)) →(p →(q ∧r))
(f) ((p →r) ∧(q →r)) →((p ∧q) →r)
(g) ((p →r) ∨(q →r)) →((p ∨q) →r)
(h) ((p →r) ∧(q →r)) →((p ∨q) →r)
(i) p →((q →r) →((p →q) →r))
(j) (p →(q →r)) →((p →q) →(p →r))
➏
Using the method of resolution check the following logical consequences.
(a) ¬p →q‚ ¬p →¬q ⊨p
(b) p →r‚ q →r ⊨(p ∨q) →r
(c) (p ∧q) →r ⊨(q →r) ∨(p →r)

Propositional Logic
133
(d) p →q‚ p ∨¬r‚ ¬r ⊨¬q ∨r
(e) (p ∨q) →r ⊨(p →r) ∧(q →r)
(f) (¬p ∧q) →¬r‚ r ⊨p ∨¬q
(g) p →q‚ r ∨(s ∧¬q)‚ ⊨¬r →¬p
(h) p →q‚ q →(r ∨s)‚ ¬(p →r) ⊨s
The Boolean satisfiability problem and NP-completeness
The Boolean satisfiability (SAT) is the problem of deciding whether a given propositional (Boolean)
formula is satisfiable, i.e. whether there is a truth assignment to the propositional (Boolean) vari-
ables occurring in the formula that makes it true. It is probably the most popular NP-complete decision
problem, the meaning of which we will explain here.
Firstly, NP stands for “nondeterministic polynomial” time. An algorithmic decision problem
(which requires an answer Yes/No for every input) is in the complexity class NP if, intuitively, there
is a fixed polynomial f such that for every input where the answer is Yes there is a piece of evi-
dence (proof, or witness) that can be verified “quickly and efficiently”, which is assumed to mean
in polynomial time, i.e. in a number of steps that is bounded by the value f(n) where n is the length
of the input. Equivalently, and again intuitively, a problem is in NP if there is an algorithm that can
run on a hypothetical nondeterministic computing device (e.g. a nondeterministic Turing machine)
to always solve the problem and, when the answer is Yes, to produce that answer in a polynomially
bounded amount of time. Simply put, an NP problem may be computationally difficult (slow) to
find a solution but it is easy (quick) to check whether a proposed, or guessed, solution is correct.
Of course, every decision problem that can be solved (for any answer) by an algorithm that
works in deterministic polynomial time – i.e. one that runs on a usual digital computer and always
takes a number of steps that is bounded by the value of a fixed polynomial in the length of the
input – is in NP. Besides, there may be problems that are in NP but for which there is no algorithm
that can solve them in polynomial time. The SAT problem seems to be a case in point. Indeed, it is in
NP because whenever a Boolean formula is satisfiable, any given satisfying truth assignment can be
verified very quickly, in a number of steps that is linear in length of the input formula. Alternatively,
the SAT problem can be solved efficiently with a nondeterministic computing device that guesses
a satisfying assignment, if there is one, and then verifies in linear time that it does indeed works.
Equivalently, one can think of solving SAT by using a hypothetical unboundedly parallel computing
device, simply by checking simultaneously for all truth assignments whether any of them renders the
formula true.
On the other hand, there is no currently known algorithm, run on a usual digital computer, that
can always solve the SAT problem efficiently, i.e. in polynomial time. Indeed, all methods for solving
the SAT problem that are known so far – including truth tables, semantic tableau and propositional
resolution, and many more modern, extremely clever and practically efficient algorithms for solving
SAT – require in the worst case a number of steps that is exponential in the number of variables
occurring in the input formula, and therefore exponential in the length of the formula. This is so
because there are 2n possible truth assignments for a set of n propositional variables.

134
Logic and Discrete Mathematics: A Concise Introduction
There are many hundreds of other very important algorithmic problems that are in NP, includ-
ing problems of scheduling, colouring of maps with a given number of colours, finding the prime
factorization of a given integer, etc.
Some of the problems in NP, such as SAT, are also known to be NP-complete. An algorithmic
decision problem X is NP-complete if solving any problem that is in NP can be reduced efficiently
(i.e. in a number of steps bounded by some fixed polynomial in the length of the input) to solving
the problem X. Therefore, any algorithm solving an NP-complete problem can be transformed into
an at most “polynomially slower” (i.e. not much slower) algorithm solving any given problem in NP.
Therefore, if an efficient (always using a number of steps polynomial in the size of the input) algo-
rithm solving SAT is found, it can be suitably modified to solve efficiently any other problem in NP.
Can there be an efficient (always working in a polynomial number of steps) algorithm solving
SAT, or any other NP-complete problem? This has been an open problem since 1971 when it was first
stated by Stephen Cook in his seminal paper “The complexity of theorem proving procedures”. It is now
literally a million dollar question, being one of the 7 Millennium Prize Problems stated by the Clay
Mathematics Institute in 2000, each bearing a 1 000 000 US$ prize tag for the first published solution
that is officially accepted as correct by the scientific community. The problem is known as “P=NP?”
and is considered to be currently the most challenging and important unsolved problem in com-
puter science. Most computer scientists believe that such miracle algorithm, solving NP-complete
problems in polynomial time, does not exists at all.

4
First-Order Logic
4.1.
Basic concepts of ﬁrst-order logic
. . . . . . . . . . . . . . . . . . . . . . . . . . .
136
4.2.
The formal semantics of ﬁrst–order logic . . . . . . . . . . . . . . . . . . . . . . . .
152
4.3.
The language of ﬁrst-order logic: a deeper look . . . . . . . . . . . . . . . . . . .
161
4.4.
Truth, logical validity, equivalence and consequence in ﬁrst-order logic . . . . . .
171
4.5.
Semantic tableaux for ﬁrst-order logic . . . . . . . . . . . . . . . . . . . . . . . . .
185
4.6.
Prenex and clausal normal forms . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
4.7.
Resolution in ﬁrst-order logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
4.8.
Applications of ﬁrst-order logic to mathematical reasoning and proofs
. . . . . .
211
Propositional logic can formalize simple patterns of reasoning, but it is certainly insufficient
for knowledge representation and practical reasoning. In this chapter we will extend it to the
system of first-order logic, which is essentially sufficient to express any common or mathe-
matical statements and therefore provides an adequate framework for logical reasoning. That
is why it is usually regarded as the language of mathematics.
First-order logic builds on propositional logic by using constants and variables for objects
of any nature (numbers, sets, points, human beings, etc.), functions and predicates over objects,
as well as quantifiers over them.
Here we will present and discuss the basics of first-order logical languages and structures,
and the fundamental notions of truth of a first-order formula in a structure, as well as validity,
logical consequence and logical equivalence of first-order formulae. We will discuss the use
of first-order languages for knowledge representation with emphasis on translations between
natural language and first-order logic.
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

136
Logic and Discrete Mathematics: A Concise Introduction
First-order logical consequence can be established by using deductive systems, like in
propositional logic. We will extend the systems of semantic tableaux and resolution to sound
and complete systems for first-order logic. Unlike the propositional case, however, no sound
and complete deductive system for first-order logic can be designed to always terminate its search for
a derivation, even when such a derivation exists. In fact, it was proved in 1936 by one of the
most influential logicians of the 20th century, Alonso Church, that the problem of whether a
given first-order logical consequence is valid is not algorithmically decidable.
At the end of the chapter we discuss and illustrate how first-order logic can be used for
structuring correct mathematical reasoning.
4.1.
Basic concepts of ﬁrst-order logic
As we noted in Chapter 1, propositional logic cannot grasp the logical structure of sentences
that involve variables, functions, predicates and quantification. All these can be captured in
first-order (classical) logic (also known as predicate logic), the basic concepts of which we shall
introduce and discuss briefly here. First-order logic has two major aspects:
• precise syntax involving a formal language, called a first-order language, that enables us to
express statements in a uniform way, by means of formulae;
• formal semantics, specifying the meaning of all components of the language by means of
their interpretation in a mathematical structure, and formal truth definitions, extending the
truth tables for the propositional connectives.1
Here we will discuss in a rather informal manner the basic components of the syntax and
semantics of predicate logic and their relevance to mathematical reasoning.
4.1.1.
First-order structures
First-order logic can be used to formalize statements and reasoning in just about any mathe-
matical or nonmathematical situation, by representing them as appropriate (first-order) struc-
tures. First we will discuss the basic components of a structure, and then will give a more
formal definition.
• Domains of discourse. When we reason and make statements about objects, we have in
mind a certain domain of discourse. In mathematics, that domain usually consists of numbers
(integers, rationals, reals, etc.), vectors, geometric figures (points, lines, triangles, spheres, etc.),
sets, graphs, etc. A domain in a nonmathematical discourse may consist of material objects,
human beings, ideas or anything else. In either case, it is important that we have specified
our domain of discourse, so that we know what we are talking about. Moreover, as one of
the sentences mentioned above suggests, the same statement can be true or false, depending
on the domain in which it is considered.
1 Those who have some experience with computer programming languages should find the concepts of syntax
and semantics familiar.

First-Order Logic
137
• Predicates. When we reason about the objects from our domain of discourse, we usually
make statements about properties they have or do not have. For instance, talking about
integers, we may discuss properties like being “positive”, “divisible by 3”, “not greater than
1999”, etc. Triangles can be “obtuse”, “equilateral”, etc. A human being can be “female”,
“male”, “young”, etc.
The logical term for a property is predicate. Predicates need not only concern a single object,
like all the examples mentioned above. Those are called unary predicates. We also deal with
binary predicates, relating two objects, such as: “_is less than _”, “_ is divisible by _” (for
numbers) or “_ is a son of _”, “_ loves _” (for humans), etc.; ternary predicates, relating three
objects, such as “_ is between _and _” (for points on a line), “ _ and _ are the parents of _”,
(for humans), etc. In general, we can talk about n-ary predicates, relating n objects.
Note that, as long as we specify the meaning (semantics) of a predicate and the objects that
it relates, that predicate becomes true or false, i.e. represents a proposition. For example, the
propositions “12 is divisible by 6” and “13 is divisible by 7” are both instances of the binary
predicate “_ is divisible by _”. Furthermore, we can connect predicates, by using proposi-
tional connectives, in compound propositions, just as we did earlier with propositions.
• Functions. Typically in mathematics (and not only there) we use functions to represent oper-
ations that, applied to one or several objects, determine an object. Depending on the number
of arguments, we talk about unary, binary, etc., functions. Standard examples are all arith-
metic operations and, more generally, all algebraic functions we have studied at school; and
so are “the mother of_”, “the older grandfather of_”, etc., in the domain of humans.
Note that in our logical framework all functions will be considered total, i.e. defined for all
possible values of the argument or tuple of arguments in the domain. This is quite often not
the case, e.g. the subtraction in the domain of natural numbers, division in the domain of
reals or the function “the daughter of_” in the domain of humans. This problem has an easy
(albeit artificial) fix, good enough for our formal purposes: we designate an element u (for
“undefined”) from the domain and make the function total by assigning u to be its value for all
(tuples of) arguments for which it is not defined. For instance, we can extend division by 0 in
the domain of reals by putting x∕0 = 17 for any real x. This may seem reckless, but if proper
care is taken when reasoning about division, it will not lead to confusion or contradiction.
There will be more on this later.
• Constants.2 Some objects in the domain can be distinguished in a way that would allow us to
make direct references to them, by giving them names. Such distinguished objects are called
constants. Examples in the domain of real numbers are 0‚ 1‚ 𝜋‚ e‚ etc. Note that the notion of
a constant pertains to the language rather than to the domain. For instance, in common cal-
culus we do not have a special name for the least positive solution of the equation cos x = x,
but if for some purposes we need to refer directly to it, then we can extend our mathematical
language by giving it a name, i.e. make it a constant in our domain.
Now we are ready to define the notion of a structure.
Definition 4.1.1 A (first-order) structure consists of a nonempty domain and a family of distin-
guished functions, predicates and constants in that domain.
2 Note that the use of the word “constant” in first-order logic is not exactly the same as in the common mathe-
matical language.

138
Logic and Discrete Mathematics: A Concise Introduction
Here are some examples of structures, which will often be used further:
• , with domain being the set of natural numbers ℕ, the unary function s (successor, i.e.
s(x) = x + 1), the binary functions + (addition) and × (multiplication), the predicates = ‚ <
and > ‚ and the constant 0.
• : likewise, but with the domain being the set of integers ℤand the additional function −
(subtraction).
• With the same functions and predicates we take the domain to be the set of rational numbers
ℚor the reals ℝ. The obtained structures will be denoted by and respectively.
• For those familiar with some abstract algebra, algebraic structures such as groups, rings,
fields are all examples of first-order structures. Usually, algebraic structures only involve
functions and constants, and no predicates except = and possibly <.
• : the domain is the set of all humans, with functions m (for “the mother of”) and f (for
“the father of”), unary predicates M (for “man”) and W (for “woman”), binary predicates P
(for “parent of”), C (for “child of”), L (for “loves”), and constants (names), e.g. John, Mary,
Adam, Eve.
• ∶the domain is the set of all points and lines in the plane, with unary predicates Pfor
“point”, L for “line” and the binary predicate I for “incidence” between a point and a line.
• : the domain is the collection of all sets, with binary predicates = for equality and ∈for
membership.3
4.1.2.
First-order languages
In order to refer to objects, functions and predicates in our domain, we give them names. In
mathematics, they are typically symbols or abbreviations, such as 5‚ 𝜋‚ + ‚ √‚ sin ‚ = ‚ <; the
proper names for humans, etc. Together with logical connectives, variables and some auxiliary
symbols, these symbolic names determine formal logical languages called first-order languages.
In particular, with every structure we can associate a first-order language for that struc-
ture, containing:
1. Functional, predicate and constant symbols, used as names for the functions, predi-
cates and constants we consider in the structure. All these are referred to as nonlogical
symbols.
2. Individual variables. Quite often, particularly in mathematics, we deal with unknown
or unspecified objects (individuals) from the domain of discourse. In order to be able
to reason and make statements about such objects, we use individual variables to denote
them. For instance, talking about numbers, we use phrases like “Take a positive integer
n”, “For every real number x greater than
√
2 … ”, etc. In natural language instead
of variables we usually use pronouns or other syntactic constructions but that often
leads to awkwardness or even ambiguity (e.g. “If a man owes money to another man
then that man hates the other man”). Therefore the use of variables in mathematics is
indispensable and it is very important to learn how to use them properly.
3 Strictly speaking, this is not a structure because the collection of all sets is not a proper set, but we can obtain a
structure if we relativize it to the family of all subsets of a given set.

First-Order Logic
139
We also use variables as placeholders for the arguments of the various predicates and
functions we deal with. Thus, we can talk about the (unary) functions, such as f(x) =
x + 1 and m(z) = “the mother of z”, or the (binary) predicates x < y and “x loves y”, etc.
Usually, for variables we will be using letters u‚ v‚ w‚ x‚ y‚ z‚ possibly indexed.
3. Auxiliary symbols, such as ( ‚ ), etc.
4. Last and most important, logical symbols, including:
(a) propositional connectives, which we already know, and
(b) quantifiers. Often we use specific phrases to quantify over objects of our discourse,
such as:4
“(for) every (object) x”,
“there is (an object) x such that”,
“for most (objects) x”,
“there are at least 5 (objects) x such that”,
“there are more (objects) x than y such that”,
etc.
The first two of these are particularly important in mathematics and many others can be
expressed by means of them, so they are given special names and notation:
The quantifier “for every” is called the universal quantifier, denoted by ∀.
The quantifier “there exists” is called the existential quantifier, denoted by ∃.
These are the only quantifiers used in first-order languages, so they are called first-order
quantifiers.5
Besides the phrases above, the universal quantifier is usually represented by “all”, “for
all” and “every” while the existential quantifier can appear as “there is”, “some” and “for some”,
particularly, in a nonmathematical discourse.
4.1.3.
Terms and formulae
Using all these components, and following certain syntactic rules, we can compose formal
expressions that allow us to represent mathematical statements symbolically, to reason about
them and to prove them in a precise, well-structured and logically correct way.
There are two basic syntactic categories in a first-order language: terms and (first-order)
formulae.
Terms
Terms are formal expressions (think of algebraic expressions) built from constant symbols and
individual variables, using functional symbols. Terms are used to denote specified or unspec-
ified individuals, i.e. elements of the domain.
4 Note the use of variables here.
5 The term “first-order” refers to the fact that quantification in these languages is only allowed over individuals
in the universe of discourse – called “first-order objects” – but not over more complex objects such as sets, relations,
functions, etc.

140
Logic and Discrete Mathematics: A Concise Introduction
Here is the formal inductive definition of terms of the first-order language :
1. Every constant symbol in is a term.
2. Every individual variable in is a term.
3. If t1‚ …‚ tn are terms and f is an n-ary functional symbol in , then f(t1‚ …‚ tn) is a term in .
We denote the set of terms of by TM(). The set of variables occurring in a term t is
denoted by VAR(t). Terms that do not contain variables are called constant terms, or ground
terms.
Examples
1. In the language ∶to start with, 0‚ x‚ s(0)‚ s(s(0))‚ …, are all ground terms. We will
denote the term s(…s(0)…)‚ where s occurs n times, by n.6
More examples of terms are:
• +(𝟐‚ 𝟐), which in a more familiar infix notation written as 𝟐+ 𝟐;
• 𝟑× y (written in the usual infix notation);
• (x2 + x) + 𝟓, where x2 is an abbreviation of x × x;
• x1 + s((y2 + 𝟑) × s(z)), etc.
2. In the “human” language ∶
• Mary;
• x;
• m(John) (intended meaning: “the mother of John”);
• f(m(y)) (intended meaning: “the father of the mother of y”), etc.
With every term we can associate a construction tree and a parsing tree, just like with
propositional formulae. For instance, here is the parsing tree of the term t = +(×(x‚ + (𝟏‚ y))‚ ×
(s(s(x))‚ y)) (recall that 𝟏= s(𝟎)):
x
s
s
0
s
y
x
y
Respectively, for every term t we define the set sub(t) of subterms being all terms used
in the construction of that term, i.e. all terms with construction trees rooted as subtrees at
6 One should distinguish the term n, which is a syntactic object, just a string of symbols, from the number n, which
is a mathematical entity.

First-Order Logic
141
nodes of the construction tree of t. For instance, for the term t in the example above sub(t) =
{t‚ × (x‚ + (𝟏‚ y))‚ x‚ + (𝟏‚ y)‚ 𝟏‚ 𝟎‚ y‚ × (s(s(x))‚ y)‚ s(s(x))‚ s(x)}.
Atomic formulae
Applying predicate symbols to terms we can build atomic formulae. These are the simplest
first-order formulae. They have no internal logical structure and correspond to atomic propo-
sitions in propositional logic. Here is the formal definition:
If t1‚ …‚ tn are terms in a language and p is an n-ary predicate symbol in , then
p(t1‚ …‚ tn) is an atomic formula in .
We denote the set of atomic formulae of by AFOR().
Examples
1. In , using the traditional infix notation:
• 𝟏< 𝟐, or in formal notation: < (𝟏‚ 𝟐),
• x = 𝟐‚
• 𝟓< (x + 𝟒)‚
• 𝟐+ s(x1) = s(s(x2)),
• (x2 + x) + 𝟓= 𝟎,
• x × (y + z) = x × y + x × z, etc.
2. In :
• x = m(Mary) (intended meaning: “x is the mother of Mary”).
• L(f(y)‚ y) (intended meaning: “the father of y loves y”), etc.
Formulae
Finally, using atomic formulae and logical connectives we can build compound formulae, just
like in propositional logic, except that now we can also use quantifiers.
The inductive definition of formulae of a first-order language naturally extends the
definition of propositional formulae:
1. Every atomic formula in is a formula in .
2. If A is a formula in then ¬A is a formula in .
3. If A‚ B are formulae in then (A ∨B), (A ∧B), (A →B)‚ (A ↔B) are formulae in .
4. If A is a formula in and x is a variable, then ∀xA and ∃xA are formulae in .
We denote the set of formulae of by FOR(). The set of variables occurring in a formula
A is denoted by VAR(A). Formulae that do not contain variables are called ground formulae.

142
Logic and Discrete Mathematics: A Concise Introduction
Examples
1. In ;
• (𝟓< x ∧x2 + x −𝟐= 𝟎);
• ∃x(𝟓< x ∧x2 + x −𝟐= 𝟎);
• ∀x(𝟓< x ∧x2 + x −𝟐= 𝟎);
• (∃y(x = y2) →(¬x < 𝟎));
• ∀x(∃y(x = y2) →(¬x < 𝟎)); etc.
2. In :
• John = f(Mary ) →∃xL(x‚ Mary );
• ∃x∀z(¬L(z‚ y) →L(x‚ z));
• ∀x(∃y(x = m(y)) →∃z(L(z‚ x))).
Exercise 4.1.2 What is the intended meaning of each of these formulae?
Some syntactic conventions
As in propositional logic, we will allow ourselves to omit parentheses wherever possible with-
out producing ambiguity. For that purpose we will, again, impose a priority order amongst
the logical connectives:
• the unary connectives: negation and quantifiers have the strongest binding power, i.e. the
highest priority,
• then come the conjunction and disjunction,
• then the implication and
• the biconditional has the lowest priority.
Example 4.1.3
∀x((∃y(x = y2)) →((¬(x < 0)) ∨(x = 0))) can be simplified to ∀x(∃y x = y2 →¬x < 0 ∨x = 0).
On the other hand, sometimes we will be using redundant parentheses in order to improve
the readability.
With every first-order formula we can associate a construction tree and a parsing tree,
just like with propositional formulae. The only differences are that the leaves of the con-
struction/parsing tree of a formula are labelled with atomic formulae rather than proposi-
tional variables and that internal nodes can also be labelled with pairs ⟨quantifier, individual
variable⟩, such as ∀x or ∃x, and these nodes have single successor nodes.
Respectively, for every first-order formula A we define its main connective, being the
one labeling the root of the construction/parsing tree of the formula, and the set sub(A) of

First-Order Logic
143
subformulae of A, being all formulae with construction trees rooted as subtrees at nodes of
the construction tree of A.
First-order instances of propositional formulae
Definition 4.1.4 Given a propositional formula A‚ any uniform substitution of first-order formulae
for the propositional variables in A produces a first-order formula, called a first-order instance of A.
Example: The formula ((𝟓< x) ∧¬∃y(x = y2)) →(∃y(x = y2) ∨(𝟓< x)) is a first-order instance
of (p ∧¬q) →(q ∨p).
Unique readability of terms and formulae
A very important property of formal logical languages, which gives them a technical advan-
tage over natural languages not only in mathematics but in every exact science, is the syntactic
unambiguity that allows for making precise statements. Without going into details here, we
will only state some syntactic facts about first-order terms and formulae which will guarantee
that every term or a formula has the unique readability property, intuitively meaning that it can
be “read” (parsed) in an essentially unique way and is therefore syntactically unambiguous.
More precisely, every term or formula has an essentially unique construction tree (respectively
parsing tree) up to the order of listing of the successor nodes.
Proposition 4.1.5 Let be any first-order language. Then:
1. Every occurrence of a functional symbol in a term t from TM() is the beginning of a unique
subterm of t.
2. Every occurrence of ¬, ∃, ∀, or a predicate symbol in a formula A from FOR() is the beginning
of a unique subformula of A.
4.1.4.
The semantics of first-order logic: an informal outline
The precise meaning of logical formulae is determined by their formal semantics, which we are
going to present here. We offer two versions of that presentation: the first one, here, is quick
and informal; the second, in the next section, is more detailed and somewhat more formal and
abstract, but proper and precise.
Consider an arbitrarily fixed first-order language . In order to determine the meaning of
the statement expressed by a given formula of our language we first need to fix its interpre-
tation. It is a first-order structure – the structure of discourse – that “matches” the language , in
a sense that all distinguished functions, predicates and constants in the structure should have
names in , i.e. respective functional, predicate and constant symbols, and, conversely, all
these nonlogical symbols of the language should correspond to explicitly defined functions,
predicates and constants in the structure. The semantics – in particular, the truth value – of
a formula is “computed” in the given interpretation compositionally, using the values of the
occurring variables and the meaning of the logical and nonlogical symbols occurring in it and
following the construction tree of the formula.

144
Logic and Discrete Mathematics: A Concise Introduction
When the structure of discourse and the interpretation of the nonlogical symbols occurring
in the formula are fixed, we need to assign values to the individual variables of the language,
or at least to those occurring in the formula (in fact, as we will see later, not even to all of them
but only to those that are not quantified over). These values are elements of the structure of
discourse. Thus, every variable refers to the element in the structure that is its value.
As a running example, consider the following formula from the language of arithmetic:
∃x(¬(x < y + z) ∧(z × x < (x × (y + 𝟏))) →(x = z + 𝟐)).
We consider the intended interpretation, namely the structure with the standard mean-
ings of < ‚ + ‚ × ‚ 1‚ 2. Take an assignment of values in to the variables as follows: x = 5‚ y =
3‚ z = 2 (we are not interested in the values of the other variables).
Once the interpretation and the variable assignment in the structure of discourse are fixed,
the value of every term can be computed step by step, following the construction tree of that
term, just like we evaluate arithmetic expressions following the addition and multiplication
tables. Eventually, every term of the language is evaluated into a unique element of the struc-
ture – its value.
In our example, the terms occurring in the formula are evaluated as follows:
y + z = 5‚ z × x = 10‚ x × (y + 𝟏) = 20‚ z + 𝟐= 4.
Next, we are ready to “compute” the meaning of every atomic formula: all we need to
do is to apply the predicate indicated in the formula to the values of the terms appearing as
its arguments. That meaning is a truth value: true or false, just like in propositional logic.
Once these truth values are computed, we can treat atomic formulae just like propositional
variables.
In our example, the atomic subformulae of the formula acquire truth values as follows: x <
(y + z) becomes 5 < 5, the truth value of which is false, z × x < x × (y + 𝟏) becomes 10 < 20,
which has the truth value true, and x = (z + 𝟐) becomes 5 = 4, which has truth value false.
Once we have the truth values of the atomic formulae computed, we can compute the
truth value of any first-order formula, following the structure of that formula, just like we
computed the truth values of propositional formulae.
Let us start computing the truth values of the subformulae in our example: since x < (y + z)
is false, we find that ¬(x < y + z) is true. Then, since z × x < (x × (y + 𝟏)) is true, we find that
(¬(x < y + z) ∧(z × x < (x × (y + 𝟏))) is true. Hence, since x = z + 𝟐is false, ¬(x < y + z) ∧(z ×
x < (x × (y + 𝟏))) →(x = z + 𝟐) is false.
Now we come across an essential new step: the quantifiers. This is where computing the
meaning, i.e. truth value, of a formula becomes generally difficult. Conceptually, there is no
problem, as we understand quite well what the quantifiers mean intuitively:
• For the existential quantifier: ∃xA is true if there is a possible value of the variable x in the
given structure of discourse – i.e. there is an element of that structure assigned as a value to
x – that renders the formula A true.
• Respectively, for the universal quantifier: ∀xA is true if every possible value of the variable x
in the given structure of discourse – i.e. every element of that structure, assigned as a value
to x – renders the formula A true.

First-Order Logic
145
At this point we have informally defined the notion of a formula A being true in a structure
under a variable assignment v, denoted
‚ v ⊨A.
Well, that is all. Sounds simple and, in a sense, it is simple. The difficulty is only technical:
the structure may have many – possibly, infinitely many – elements, and checking that all of
them (respectively some of them) make the formula A true can be a long – possibly, infinitely
long – and hard task. Therefore in practice one tries to guess a suitable value of x in the case of
existential quantification, or respectively come up with a uniform argument, that works for all
possible values of x, in the case of universal quantification.
In our example, in order to determine the truth value of the entire formula, we need to find
out whether there is any natural number that, assigned as a value to x while y and z keep the
same values as before, will render the subformula ¬(x < y + z) ∧(z × x < (x × (y + 𝟏))) →(x =
z + 𝟐) true. In this case it is not difficult to guess such a value – it suffices to find one that makes
the antecedent of the implication false. For that, we can take any value that makes ¬(x < y + z)
false, i.e. x < y + z true, for instance x = 0. Thus, the formula ∃x(¬(x < y + z) ∧(z × x < (x × (y +
𝟏))) →(x = z + 𝟐)) is true in .
Now, let us change the existential quantifier into a universal one. Is the formula ∀x(¬(x <
y + z) ∧(z × x < (x × (y + 𝟏))) →(x = z + 𝟐)) still true in ? In order to determine that, in prin-
ciple we have to consider all natural numbers as possible values of x and determine the truth
value of ¬(x < y + z) ∧(z × x < (x × (y + 𝟏))) →(x = z + 𝟐) for each of them. However, in our
case this is not necessary, for we already know a value of x that makes that subformula false,
and therefore we find that ∀x(¬(x < y + z) ∧(z × x < (x × (y + 𝟏))) →(x = z + 𝟐)) is false in .
However what if the existentially quantified formula were false or the universally quan-
tified formula were true? Would we have to do all the infinitely many checks then? Usu-
ally a uniform argument can be found that proves the case. For instance, one can prove that
∀x((x + 1)2 = x2 + 2x + 1) by straightforward calculations or that ∃x(x2 + x + 1 ≤0) is false, by
using some high school algebra.
In general, however, this question is much deeper than it looks, so we will leave it open
here, but will only mention that it was proved7 in 1973 (by the collective effort of several
logicians and mathematicians, including Martin Davis, Yuri Matiyasevich, Hilary Putnam and
Julia Robinson) that there is no general algorithm that can answer such questions, even when
the formula is a very simple one of the type ∃x(P(x) = 0), where P(x) is a polynomial with
integer coefficients. The truth of some formulae in the language or simple extensions of it
has been settled with a formal proof only after hundreds of years of futile attempts of many
great minds. One famous example is Fermat’s Last Theorem,8 which can be stated by a simple
one-line formula, using exponentiation in :
∀x∀y∀z∀n((x ≠0 ∧y ≠0 ∧z ≠0 ∧n > 2) →xn + yn ≠zn)
7 This was a negative answer to Hilbert’s Tenth Problem, one of the 23 famous open challenges to the mathematics
of the 20th century posed by David Hilbert at the World Congress of Mathematics in 1900.
8 Read more on Fermat’s Last Theorem in Chapter 5 on Number Theory.

146
Logic and Discrete Mathematics: A Concise Introduction
The truth of yet other such formulae is still unsettled, even after centuries of attempts, e.g. the
famous Goldbach conjecture saying that “Every even integer greater than 2 is the sum of two prime
natural numbers”.9 Formalizing this statement in is given later as an exercise.
This is the end of our quick and informal exposition. In Section 4.2 we provide a more
detailed and formal presentation.
4.1.5.
Translating first-order formulae to natural language
First-order formulae formalize statements about first-order structures and these statements
can be translated back to natural language. Of course, a formula is just a string of symbols,
so a formal translation could simply consist in writing all symbols in words. That, however,
would be of no use for understanding the meaning of the formula. While evaluating the truth of
the formula in a given structure formally does not require translating that formula to natural
language and understanding its intuitive meaning, that is essential for practically carrying
out the truth evaluation procedure. Indeed, the meaning of (the statement expressed by) a
first-order formula in a given interpretation is closely related to its truth in that interpretation.
In fact, one can argue that understanding the logical meaning of a formula, spelled out in
a natural language, and determining its truth are the two sides of the same coin.
Example 4.1.6
Let us look at some examples of translating to natural language and evaluating the truth of
first-order formulae, now interpreted in the structure of real numbers . Note that a good
translation is usually not word by word, but it needs some polishing and rephrasing in the
target language so that it eventually sounds natural and makes good sense.
1. .
∃x(x = x2)
– “There is a real number which equals its square.” (True, take x = 0.)
2. .
∀x(x < 𝟎→x3 < 𝟎)
– “Every negative real number has a negative cube.” (True.)
3. .
∀x∀y(xy > 𝟎→(x > 𝟎∨y > 𝟎)).
– “If the product of (any) two real numbers is positive, then at least one of them is positive.”
(False: take x = y = −1.)
4. .
∀x(x > 𝟎→∃y(y2 = x))
9 A natural number is prime if it has no other positive integer divisors but 1 and itself (see Chapter 5).

First-Order Logic
147
– “Every positive real number is a square of a real number.” (True: algebraic fact.)
5. .
∃x∀y(xy < 𝟎→y = 𝟎)
– “There is a real number x such that, for every real number y, if xy is negative, then y is
0.” (True or false?)
Now, some examples of formulae in :
1. .
John = f(Mary) ∧L(John‚ Mary)
– “John is the father of Mary and he loves her.”
2. .
(John = f(Mary)) →∃xL(x‚ Mary)
– “If John is the father of Mary then (there is) someone (who) loves Mary.”
3. .
∃x∀z(¬L(z‚ y) →L(x‚ z))
– “There is someone (x) who loves everyone who does not love y.”
(Note that y stands for an unspecified person here, so this is not a proposition.)
4. .
∀x(∃y(x = m(y)) →∀z(x = m(z) →L(x‚ z)))
– “Every mother loves all her children.”
4.1.6.
Exercises
➊
Define suitable first-order structures and introduce appropriate first-order languages for
the following types of mathematical structures: graphs, groups, rings, matrices, vector
spaces.
➋
Define suitable first-order structures and introduce appropriate first-order languages for
the following data types: Booleans, strings, lists, trees.
➌
Which of the following are syntactically correct terms in the language ? Rewrite them
in the usual infix notation.
(a) ×(x‚ y)
(b) ×(𝟐‚ x‚ y)
(c) +xy
(d) +(𝟓‚ × (x‚ + (𝟑‚ y))
(e) +(×(x‚ + (𝟑‚ y))‚ × (+(𝟑‚ y)‚ x))
(f) ×(s(×(𝟐‚ x)‚ + (𝟑‚ y)))

148
Logic and Discrete Mathematics: A Concise Introduction
(g) s(×(×(𝟐‚ x)‚ + (𝟑‚ s)))
(h) s(×(×(𝟐‚ x)‚ + (𝟑‚ y)))
(i) ×(s(×(𝟐‚ x))‚ s(+(s(𝟑)‚ y)));
(j) s(×(s(s(x))‚ s(s(s(𝟐))))‚ s(𝟐))
➍
Construct the parsing tree of each of the syntactically correct terms from the previous
exercise and determine the set of its subterms.
➎∗
Prove that every occurrence of a functional symbol in a term t is the beginning of a unique
subterm of t.
➏
Which of the following are syntactically correct formulae in the language ? Assume
that terms are written in the usual infix notation and parentheses can be omitted whenever
possible or added for better readability.
(a) ¬∀x(x = 𝟎)
(b) ∀¬x(x = 𝟎)
(c) ∀x(¬x = 𝟎)
(d) ∀x(x¬ = 𝟎)
(e) ∀x(x = ¬𝟎)
(f) ¬∀x(¬x = 𝟎)
(g) ¬∃x(¬x = 𝟎.𝟓)
(h) ∀x(x ∨¬x)
(i) ∀x∀y((x + y) →(y + x))
(j) ∀x((x < 𝟎) →∀x(x > 𝟎))
(k) ∀x((x + 𝟎) →∀x(x > 𝟎))
(l) ∀x(∀x(x > 𝟎) →x < 𝟎)
(m) ∀y(x < x →∀x(x < x))
(n) ∀y((y < y)¬∀x(x < x))
➐
Construct the parsing tree of each of the syntactically correct formulae from the previous
exercise and determine its main connective and the set of its subformulae.
➑∗
Prove that every occurrence of a predicate symbol ¬‚ ∃or ∀in a formula A from FOR()
is the beginning of a unique subformula of A.
➒** Prove that every occurrence of any binary connective ⚬∈{∧‚ ∨‚ →‚ ↔} in a formula A
is in a context (B1⚬B2) for a unique pair of subformulae B1 and B2 of A.
➓
Evaluate the occurring terms and determine the truth of the following atomic formu-
lae in :
(a) ×(s(s(x))‚ 𝟐) = ×(x‚ s(s(𝟐))), where x is assigned the value 3.
(b) +(𝟓‚ × (x‚ + (𝟑‚ y))) > s(×(𝟑‚ × (𝟐‚ x))), where x is assigned the value 1
2 and y is assigned
the value −5.

First-Order Logic
149
(c) (s(×(×(x‚ x)‚ x))) < ×(s(x)‚ + (×(x‚ x)‚ −(𝟏‚ x))), for each of the following values of x: 2,
√
2, 𝜋.
11
Determine the first-order instances of the propositional formula
A = (¬p →(q ∨¬(p ∧q)))
where:
(a) ¬(f(x) = y) is substituted for p and ∃x(x > y) is substituted for q.
(b) ¬(x = y) is substituted both for p and q.
12
Is the formula (¬(x = y) →(∃x(x > y) ∨¬((y = x) ∧∃x(x > y)))) a first-order instance of the
propositional formula A from the previous exercise?
13
Consider the structure and a variable assignment v such that v(x) = 1, v(y) = 2, v(z) =
3. Determine the truth in for v of each of the following formulae by using informal
semantic reasoning.
(a) z > y →x > y
(b) ∃x(z > y →x > y)
(c) ∃y(z > y →x > y)
(d) ∃z(z > y →x > y)
(e) ∀y(z > y →x > y)
(f) ∃x∀y(z > y →x > y)
(g) ∃x∀z(z > y →x > y)
(h) ∃z∀y(z > y →x > y)
(i) ∃z∀x(z > y →x > y)
(j) ∃y∀x(z > y →x > y)
(k) ∃y∀z(z > y →x > y)
(l) ∀x∃y(z > y →x > y)
(m) ∀x∃z(z > y →x > y)
(n) ∀y∃x(z > y →x > y)
(o) ∀y∃z(z > y →x > y)
(p) ∀z∃x(z > y →x > y)
(q) ∀z∃y(z > y →x > y)
14
Consider the first-order language for humans, with functions m for “the mother of”,
f for “the father of”, the unary predicates M for “man”, W for “woman”, and the binary
predicates, C(x,y) meaning “x is a child of y”, K(x,y) meaning “x knows y”, and L(x,y)
meaning “x likes y” . Translate each of following first-order sentences of the language 
into English and try to determine its truth in the domain of human beings.

150
Logic and Discrete Mathematics: A Concise Introduction
(a) ∀x(W(x) →∀z(C(z‚ x) →m(z) = x))
(b) ∀x(∃y f(y) = x →¬∃z
m(z) = x)
(c) ¬∃x(M(x) ∧∀z(C(z‚ x) →¬K(x‚ z)))
(d) ∀x∃y(¬P(y‚ x) ∧∀z(P(x‚ z) →∃u(P(u‚ z) ∧P(y‚ u))))
(e) ∀x(∃y(x = m(y)) →∀z(∃uC(z‚ u) →L(x‚ z)))
(f) ∃x(W(x) ∧∀y(M(y) ∧L(y‚ x) →¬L(x‚ y)))
(g) ¬∃x(∃yC(x‚ y) ∧∃z(∃u(z = m(u) ∧¬L(z‚ u)) ∧L(x‚ z)))
15
Translate each of the following formulae from the language for reals extended with the
unary predicate I for integers into English and determine their truth in for any given
variable assignment, by using informal semantic reasoning.
(a) ∃x∀y(x + y = y)
(b) ∃x∀y(x + y > y)
(c) ∃x∀y(x + y > x)
(d) ∀x∃y(x + y = x −y)
(e) ∀x∃y(x + y > y)
(f) ∀x∃y(x + y > x)
(g) ∃x∀y(xy = y)
(h) ∃x∀y(xy > y)
(i) ∀x∃y(xy > y)
(j) ∀x∃y(xy > x)
(k) ∀x(I(x) →x2 > 𝟎)
(l) ¬∀x∃y(I(y) ∧x > y)
(m) ∀x(I(x) →∃y(I(y) ∧x < y))
(n) ∃x(I(x) ∧¬∀y(x < y))
(o) ¬∃x∀y(I(y) →x > y)
(p) ∀x∀y(x < y →∃z(x < z ∧z < y))
(q) ∀x∀y(x < y →∃z(I(z) ∧x < z ∧z < y))

First-Order Logic
151
Friedrich Ludwig Gottlob Frege (8.11.1848–26.7.1925)
Gottlob Frege was a German mathematician, logician and philoso-
pher, who did profound and groundbreaking work on the philoso-
phy of mathematics, logic and language. He is one of the founders
of modern first-order logic, where his contribution is regarded by
many as the most important development in logic since Aristotle.
Frege’s first major scientific work, and also his most influen-
tial for the future development of mathematical logic, was his book
Begriffsschrift, eine der arithmetischen nachgebildete Formelsprache des
reinen Denkens (Concept notation, a formal language modeled on that of
arithmetic, for pure thought) published in 1879. In this book he sys-
tematically developed a system of logic, with rather unusual nota-
tion but very close in spirit to the modern-day first-order logic (also
known as “predicate calculus”), in which he explicitly introduced
quantifiers, quantification and logical formulae. He also formalized the notion of a “proof” in a way
that is still used today. Frege had realized that natural everyday language is often imprecise and
ambiguous, and therefore unreliable for performing rigorous mathematical reasoning. He therefore
wanted to develop a precise, unambiguous language for expressing mathematical statements and a
formal logical system for mathematical reasoning. Frege held the view, known as logicism, that the
whole of mathematics should be reducible to logic. In the preface to the Begriffsschrift he stated that
he wanted to prove all basic results in arithmetic “by means of pure logic”. He pursued this idea
further in his next major work, The Foundations of Arithmetic, published in 1884, where he made a
lot of progress towards his goal by formalizing much of arithmetic in purely logical terms.
The reaction of Frege’s contemporary mathematicians and philosophers to his work was dis-
appointingly weak and shallow, as very few of them were able to understand his groundbreaking
ideas. Particularly devastating was the criticism of Cantor (see the box at the end of Section 2.2
in Chapter 2), who held philosophical views on the the foundations of mathematics very close to
Frege’s own. Nevertheless, Frege went on developing and elaborating his philosophy of logic and
mathematics and was about to publish the 2nd volume of his The Foundations of Arithmetic when,
in 1902, he received a letter from the young philosopher and mathematician Bertrand Russell (see
Section 4.3), who pointed out a contradiction in Frege’s system of axioms, revealed by Russell’s
paradoxical set of all sets that are not elements of themselves. This was a heavy blow to Frege,
who attempted (as it turned out later, unsuccessfully) to fix the problem in an appendix to his book
by amending one of his axioms, but he was so strongly shaken by that discovery that he stopped
working on that project and never published the planned 3rd volume. Thus, he never succeeded to
reduce the entire mathematics to logic. Much later, in the early 1920s, Frege came to the conclusion
that this goal was impossible and decided, instead, that the whole of mathematics should be based
on geometry, but he never managed to develop his ideas until the end of his life.
However, Frege exerted a strong influence on the views and work of Peano (see Section 4.2),
Wittgenstein, Husserl, Carnap and Russell. Gradually, after his death, his revolutionary work in the
philosophy of mathematics, logic and language started to receive its due recognition for the major
scientific importance it has.

152
Logic and Discrete Mathematics: A Concise Introduction
4.2.
The formal semantics of ﬁrst–order logic
We now consider an arbitrarily fixed first-order language . The formulae of are meant to
express statements about structures of discourse “matching” the language . The meaning
of the formulae is relative to the given structure of discourse and is “computed” composi-
tionally, following the structure of the formula, the values of the occurring variables and the
meaning of the logical and nonlogical symbols occurring in it. The precise meaning of logical
formulae is determined by their formal semantics, which we are going to present here in a more
detailed and somewhat more formal and precise manner, a method we recommend to the dili-
gent reader. If you have less time or patience and have found the short and informal version
sufficiently clear, you may skip the detailed one and proceed further with the next section. If,
however, you encounter problems with the understanding and use of first-order logic further
on, return to this section and go through the formal presentation of the semantics of first-order
formulae.
4.2.1.
Interpretations
To repeat, formulae are meant to express statements. The meaning of the statement expressed
by a formula cannot be determined only from the symbols occurring in the formula and its
shape, i.e. from the syntax. The meaning of a formula is relative to the structure of discourse
and to the interpretation, i.e. the associated meaning of the nonlogical symbols of the formula
in that structure. Formally, an interpretation of a first-order language involves a first-order
structure and a mapping, which assigns:
• to every constant symbol c in a designated constant c;
• to every n-ary functional symbol f in a designated n-ary function f ;
• to every n-ary predicate symbol P in a designated n-ary predicate P.
For instance:
• The structure provides an interpretation of the language . It is the intended, or stan-
dard interpretation of .
• There are many other, natural and “unnatural” (unintended), interpretations of the language
, e.g. in the structure of reals with the standard meanings of the arithmetic operations;
or still in the set of naturals, but with nonstandard meanings, e.g. s(x) meaning x + 13, +(x‚ y)
meaning x × y + 1 and ×(x‚ y) meaning ∣x −y ∣; or even in a non-numerical domain with
arbitrary and meaningless interpretations.
• Every graph (see Chapter 7) is an intended (standard) interpretation of the language of
graphs Graph, containing one binary relational symbol R for the edge relation.

First-Order Logic
153
• Likewise, every (mathematical) group is an intended (standard) interpretation of the lan-
guage of groups Group, containing one binary functional symbol ⚬(the group operation),
one unary functional symbol ′ (the inverse) and one constant symbol e (the identity).
• Again, there are many more, “almost-standard” interpretations of (e.g. monoids with
x′ = x), as well as completely nonstandard interpretations.
Once interpreted, the meaning of a formula can be “computed”, as in the propositional
case, from the interpretation of the nonlogical symbols and the meaning of the logical ones.
The rules for computing this meaning determine the semantics of first-order logic. We will
spell out these rules in some technical detail.
4.2.2.
Variable assignment and term evaluation
In order to compute the truth value of a formula in a given structure we first have to eval-
uate the terms occurring in it, i.e. to determine the elements of the structure denoted by these
terms. For that, we must first assign values to the variables in the structure , by means of a
variable assignment in , which is a mapping v ∶VAR →|| from the set of variables VAR to
the domain of .
The evaluation of a term is now done just like the evaluation of an algebraic expression,
which we know from primary school: starting with the values of the variables and constant
symbols we systematically apply the functions in that interpret the respective functional
symbols occurring in the term; i.e. when evaluating a term f(u1‚ …‚ um)‚ we first compute the
values of the arguments u1‚ …‚ um and then apply the interpretation of f in to these values.
Formally, due to the unique readability of terms, every variable assignment v ∶VAR →
|| in a structure can be uniquely extended to a mapping v∶TM() →||, called term
evaluation, such that, for every n-tuple of terms t1‚ …‚ tn and an n-ary functional symbol f,
v(f(t1‚ …‚ tn)) = f (v(t1)‚ …‚ v(tn))‚
where f is the interpretation of f in .
Once a variable assignment v in the structure is fixed, every term t in TM() is evaluated
into a unique element v(t) of (or just v(t) when is fixed), called the value of the term t
under the variable assignment v.
The following proposition implies that the value of any term only depends on the assign-
ment of values to the variables occurring in that term. We leave the proof as an exercise.
Proposition 4.2.1 For any given first-order language , term t ∈TM() and an -structure , if
v1‚ v2 are variable assignments in that assign the same values to all variables in VAR(t), then v
1 (t) =
v
2 (t).

154
Logic and Discrete Mathematics: A Concise Introduction
Example 4.2.2
If x is assigned a value 3 and y is assigned a value 5 in ‚ then the term s(s(x) × y) is formally
evaluated as follows:
v(s(s(x) × y))
= s(v(s(x) × y))
= s(v(s(x))×v(y))
= s(s(v(x))×v(y))
= s(s(3)×5)
= s((3 + 1)×5)
= ((3 + 1) × 5) + 1
= 21.
Likewise, v(𝟏+(x × s(s(𝟐)))) = 13.
For a non-numerical term evaluation, if x is assigned the value ‘Mary’ in then
v(f(m(x))) = the father of the mother of Mary.
Computing the truth values of formulae
We are now ready to start computing truth values of formulae, beginning with the logically
simplest ones: atomic formulae.
Truth of atomic formulae
Eventually, we want to define the notion of a formula A being true in a structure under a
variable assignment v, denoted
‚ v ⊨A‚
compositionally on the structure of the formula A, beginning with the case when A is an atomic
formula.
The truth value of the atomic formula P(t1‚ …‚ tn) is determined by the interpretation of
the predicate symbol P in , applied to the tuple of arguments v(t1)‚ …‚ v(tn):
‚ v ⊨P(t1‚ …‚ tn) iff Pholds (is true) for v(t1)‚ …‚ v(tn).
Otherwise, we write ‚ v ⊭P(t1‚ …‚ tn).
The following proposition implies that the truth value of any atomic formula only depends
on the assignment of values to the variables occurring in that formula. It follows quite easily
from Proposition 4.2.1 and we leave the proof as an exercise.
Proposition 4.2.3 For any given first-order language , atomic formula A ∈AFOR() and an
-structure , if v1‚ v2 are variable assignments in that assign the same values to all variables in
VAR(A), then ‚ v1 ⊨A iff ‚ v2 ⊨A.

First-Order Logic
155
Example 4.2.4
If L is a binary predicate symbol interpreted in as “less than” and the variables x and y are
assigned values as above, then:
• ‚ v ⊨L(𝟏+ (x × s(s(𝟐)))‚ s(s(x) × y)) iff L((𝟏+ (x × s(s(𝟐))))‚ (s(s(x) × y))) iff 13 < 21,
which has a truth value true, while the atomic formula 𝟏+ (x × s(s(𝟐))) = s(s(x) × y) has a
truth value false.
• Likewise, ‚ v ⊨𝟖× (x + s(s(y))) = (s(x) + y) × (x + s(y)) iff (𝟖× (x + s(s(y))))= ((s(x) + y)
×(x + s(y)))iff 80 = 81, which is false.
Semantics of the propositional connectives
The truth values propagate over the propositional connectives according to their truth tables,
as in propositional logic:
• ‚ v ⊨¬A iff ‚ v ⊭A;
• ‚ v ⊨(A ∧B) iff ‚ v ⊨A and ‚ v ⊨B;
• ‚ v ⊨(A ∨B) iff ‚ v ⊨A or ‚ v ⊨B;
• ‚ v ⊨(A →B) iff ‚ v ⊭A or ‚ v ⊨B;
• and likewise for (A ↔B).
Semantics of the quantifiers
Finally, the truth of formulae ∀xA(x) and ∃xA(x) is computed according to the meaning of
the quantifiers and the truth values of A. First we need to define a technical notion. Given a
structure and two variable assignments v and v′ in , we say that v′ is an x-variant of v if
v′ coincides with v on every variable except possibly x. Equivalently, v′ is an x-variant of v if
there exists an element a ∈such that v′ = v[x ∶= a], where v[x ∶= a] is obtained from v by
redefining v(x) to be a.
• ∀xA(x) is true if every object a from the domain of , assigned as a value of x, satisfies (i.e.,
renders true) the formula A. Formally, ‚ v ⊨∀xA(x) if ‚ v′ ⊨A(x) for every variable assign-
ment v′ that is an x-variant of v.
• ∃xA(x) is true if there is an object a from the domain of that, assigned as a value of x‚ satisfies
the formula A. Formally, ‚ v ⊨∀xA(x) if ‚ v′ ⊨A(x) for some variable assignment v′ that is
an x-variant of v.
The following theorem implies that the truth value of any formula only depends on the
assignment of values to the variables occurring in that formula. (We will see later that not all
of these variables matter.) We leave the proof as an exercise.
Theorem 4.2.5 For any given first-order language , formula A ∈FOR() and an -structure ,
if v1‚ v2 are variable assignments in that assign the same values to all variables in VAR(A), then
‚ v1 ⊨A iff ‚ v2 ⊨A.

156
Logic and Discrete Mathematics: A Concise Introduction
Some examples
Example 4.2.6
Consider the structure and a variable assignment v such that v(x) = 0, v(y) = 1, v(z) = 2.
Then:
• ‚ v ⊨¬(x > y).
• ‚ v ⊨∃x(x > y). Indeed, ‚ v[x ∶= 2] ⊨x > y.
• In fact, the above holds for any value assignment of y and therefore ‚ v ⊨∀y∃x(x > y).
• On the other hand, ‚ v ⊨∃x(x < y), but ‚ v ⊭∀y∃x(x < y). Why?
• What about ‚ v ⊨∃x(x > y ∧z > x)?
• For the same variable assignment in the structure of rationals, ‚ v ⊨∃x(x > y ∧z > x).
Does this hold for every variable assignment in ?
4.2.3.
Truth evaluation games
There is an equivalent but somewhat more intuitive – and even possibly more entertain-
ing – way to evaluate the truth of first-order formulae in given structures. It is done by playing
a special kind of a two-player game, called the formula evaluation game.10 The two players
are called Verifier and Falsifier.11
The game is played on a given first-order structure , variable assignment v in it and a
formula A, the truth of which is to be evaluated in the structure for the assignment v. As
suggested by the names of the players, the objective of Verifier in the game is to defend and
verify the claim that ‚ v ⊨A, while the objective of Falsifier is to attack and refute that claim.
The game goes in rounds and, in each round, exactly one of the players – depending on
the current “game configuration” – has to make a move according to rules that we will specify
below, until the game ends. The current game configuration (‚ w‚ C) consists of the structure
, an assignment w in and a formula C (the truth of which is to be evaluated in for the
assignment w). The initial configuration is (‚ v‚ A). We will identify every such game with its
initial configuration.
At every round, the player to make a move, as well as the possible moves, are deter-
mined by the main connective of the formula in the current configuration (‚ w‚ C) by rules
that closely resemble the truth definitions for the logical connectives. Here are the rules:
• If the formula C is atomic, the game ends.
If ‚ w ⊨C then Verifier wins; otherwise Falsifier wins.
• If C = ¬B then Verifier and Falsifier swap their roles and the game continues with the configu-
ration (‚ w‚ B). Swapping the roles means that Verifier wins the game (‚ w‚ ¬B) iff Falsifier
10 Also known as the model checking game.
11 Also known by various other names, e.g. Proponent and Opponent, Eloise and Abelard, Eve and Adam. For
the sake of convenience, and without prejudice, here we will assume that both players are male.

First-Order Logic
157
wins the game (‚ w‚ B) and Falsifier wins the game (‚ w‚ ¬B) iff Verifier wins the game
(‚ w‚ B).
Intuition: verifying ¬B is equivalent to falsifying B and vice versa.
• If C = C1 ∧C2 then Falsifier chooses i ∈{1‚ 2} and the game continues with the configuration
(‚ w‚ Ci).
Intuition: for Verifier to defend the truth of C1 ∧C2 he should be able to defend the truth of
any of the two conjuncts, so it is up to Falsifier to question the truth of either of them.
• If C = C1 ∨C2 then Verifier chooses i ∈{1‚ 2} and the game continues with the configuration
(‚ w‚ Ci).
Intuition: for Verifier to defend the truth of C1 ∨C2 it suffices to be able to defend the truth
of at least one of the two disjuncts, so he can choose which one.
• If C = C1 →C2 then Verifier chooses i ∈{1‚ 2} and, depending on that choice, the game con-
tinues respectively with the configuration (‚ w‚ ¬C1) or (‚ w‚ C2).
Intuition: C1 →C2 ≡¬C1 ∨C2.
• If C = ∃xB then Verifier chooses an element a ∈and the game continues with the configu-
ration (‚ w[x ∶= a]‚ B).
Intuition: by the truth definition of ∃xB, verifying that ‚ w ⊨∃xB amounts to verifying that
‚ w[x ∶= a] ⊨B for some suitable element a ∈.
• If C = ∀xB then Falsifier chooses an element a ∈and the game continues with the config-
uration (‚ w[x ∶= a]‚ B).
Intuition: by the truth definition of ∀xB, falsifying ‚ w ⊨∀xB amounts to falsifying ‚ w[x ∶=
a] ⊨B for some suitable element a ∈.
It is easy to see that any formula evaluation game always ends in a finite number of steps,
because the number of logical connectives in the formula in the current configuration strictly
decreases after every move until an atomic formula is reached. It is also obvious that the game
always ends with one of the players winning. Now clearly the winner of such a game depends
not only on the truth or falsity of the claim ‚ v ⊨A but also on how well the players play the
game, so we suppose they always play a best possible move. Thus, the game will be won by the
player who has a winning strategy for that game, i.e. a rule that, for every possible configuration
from which that player is to move assigns such a move, he is guaranteed to eventually win the
game, no matter how the other player plays. It is not quite obvious that one of the players is sure to
have a winning strategy in every such game, but it follows from a more general result in game
theory. This also follows from the following claim – which we take here for granted – relating
the existence of a winning strategy to the truth of the formula in the initial configuration.
Theorem 4.2.7 For every configuration (‚ v‚ A):
1. ‚ v ⊨A if and only if Verifier has a winning strategy for the evaluation game (‚ v‚ A).
2. ‚ v ⊭A if and only if Falsifier has a winning strategy for the evaluation game (‚ v‚ A).
How does one find a winning strategy for one of the players in a truth evaluation game?
We see from the theorem above that this problem is as difficult as determining the truth of a
first-order formula in a given structure and variable assignment, so there is no general magic

158
Logic and Discrete Mathematics: A Concise Introduction
recipe. Still, a sensible translation of the formula to natural language that helps to understand
its meaning would also help the player who has a winning strategy in the evaluation game to
come up with the right strategy.
Example 4.2.8
Consider the structure and the variable assignment v such that v(x) = 0, v(y) = 1, v(z) = 2.
1. Verifier has a winning strategy for the game (‚ v‚ ∀y∃x(x > y + z)).
Indeed, the first move of the game is by Falsifier, who has to choose an integer n and the
game continues from configuration (‚ v[y ∶= n]‚ ∃x(x > y + z)).
Now, Verifier has to choose an integer m. For every given n ∈Verifier can choose, for
example, m = n + 3. Then he wins the game (‚ v[y ∶= n][x ∶= m]‚ (x > y + z)) because n +
3 > n + 2.
Thus, he has a winning strategy for the game (‚ v[y ∶= n]‚ ∃x(x > y + z)), for any n ∈.
Hence, he has a winning strategy for the game (‚ v‚ ∀y∃x(x > y + z)).
Therefore, ‚ v ⊨∀y∃x(x > y + z).
In fact, the above winning strategy for Verifier is easy to generalize for any assignment of
value to z, thus showing that ‚ v ⊨∀z∀y∃x(x > y + z).
2. Verifier has a winning strategy for the game (‚ v‚ ∀x(y < x ∨x < z)).
Indeed, the first move in the game is by Falsifier, who has to choose an integer n and the
game continues from configuration (‚ v[x ∶= n]‚ (y < x ∨x < z)) in which Verifier must
choose one of the disjuncts y < x and x < z.
The strategy for Verifier goes as follows: if Falsifier has chosen n > 1 then Verifier chooses
the disjunct y < x and wins the game (‚ v[x ∶= n]‚ y < x); if Falsifier has chosen n ≤1
then Verifier chooses the disjunct x < z and wins the game (‚ v[x ∶= n]‚ x < z).
Therefore, ‚ v ⊨∀x(y < x ∨x < z).
3. Falsifier has a winning strategy for the game (‚ v‚ ∀x(x < z →∃y(y < x))).
Indeed, let Falsifier choose 0 in the first move. Then the game continues from configura-
tion (‚ v[x ∶= 0]‚ (x < z →∃y(y < x))) and now Verifier is to choose the antecedent or the
consequent of the implication.
If Verifier chooses the antecedent, then the game continues from configuration (‚ v[x ∶=
0]‚ ¬(x < z)), which is won by Falsifier because the game (‚ v[x ∶= 0]‚ x < z) is won by
Verifier, since 0 < 2.
If Verifier chooses the consequent of the implication, then the game continues from config-
uration (‚ v[x ∶= 0]‚ ∃y(y < x)) and Verifier is to choose a suitable value for y. However,
whatever n ∈Verifier chooses, he loses the game (‚ v[x ∶= 0][y ∶= n]‚ y < x) because
n < 0 is false for every n ∈.
Thus, the Verifier has no winning move after the first move of Falsifier choosing 0 as a
value for x. Therefore, ‚ v ⊭∀x(x < z →∃y(y < x)).
Furthermore, the winning strategy for Falsifier in the game (‚ v‚ ∀x(x < z →∃y(y < x)))
is a winning strategy for Verifier in the game (‚ v‚ ¬∀x(x < z →∃y(y < x))); hence ‚ v ⊨
¬∀x(x < z →∃y(y < x)).

First-Order Logic
159
4.2.4.
Exercises
➊
Consider the structure and a variable assignment v such that v(x) = 1, v(y) = 2, v(z) = 3.
Determine the truth in for v of each of the following formulae by using the formal truth
definition. You may wish to use formula evaluation games as well.
(a) ∃x∀y∀z(z > y →x > y)
(b) ∃y∀x∀z(z > y →x > y)
(c) ∃z∀x∀y(z > y →x > y)
(d) ∀y∃x∀z(z > y →x > y)
(e) ∀x∃y∀z(z > y →x > y)
(f) ∀z∃x∀y(z > y →x > y)
(g) ∀x∀y∃z(z > y →x > y)
(h) ∀y∀z∃x(z > y →x > y)
(i) ∀z∀x∃y(z > y →x > y)
➋
Translate the following first-order formulae into English and determine which of them
represent true propositions when interpreted in , by using the formal truth definition.
You may wish to use formula evaluation games as well.
(a) ¬∀x(x ≠0)
(b) ∀x(x3 ≥x)
(c) ∀x(x = x2 →x > 𝟎)
(d) ∃x(x = x2 ∧x < 𝟎)
(e) ∃x(x = x2 →x < 𝟎)
(f) ∀x(x > 𝟎→x2 > x)
(g) ∀x(x = 𝟎∨¬x + x = x)
(h) ∀x((x = x2 ∧x > 𝟏) →x2 < 𝟏)
(i) ∀x∀y(x > y ∨y > x)
(j) ∀x∃y(x > y2)
(k) ∀x∃y(x > y2 ∨y > 𝟎)
(l) ∀x(x ≥𝟎→∃y(y > 𝟎∧x = y2))
(m) ∀x∃y(x > y →x > y2)
(n) ∀x∃y(¬x = y →x > y2)
(o) ∃x∀y(x > y)

160
Logic and Discrete Mathematics: A Concise Introduction
(p) ∃x∀y(x + y = x)
(q) ∃x∀y(x + y = y)
(r) ∃x∀y(x > y ∨−x > y)
(s) ∃x∀y(x > y ∨¬x > y)
(t) ∃x∀y(y > x →y2 > x)
(u) ∃x∀y(x > y →x > y2)
(v) ∃x∃y(xy = x + y)
(w) ∀x∃y∀z(xy = yz)
(x) ∃x∀y∃z((x + y)z = 𝟏)
(y) ∀x∀y(x > y →∃z(x > z ∧z > y)
(z) ∀x∃z∀y(x > z →z > y)
➌∗Prove Proposition 4.2.1, by induction on the length of terms.
➍
Prove Proposition 4.2.3, by using Proposition 4.2.1.
➎∗Prove Theorem 4.2.5, by induction on the length of formulae.
Giuseppe Peano (27.8.1858–20.4.1932)
Giuseppe Peano was an Italian mathematician and one of the
founders of mathematical logic and set theory. He played a key role
in the axiomatization of the arithmetic that is now known as the
Peano system of axioms.
Peano was born and grew up on a farm in Northern Italy. He
graduated from the University of Turin in 1880 where he subse-
quently took up a position and worked for most of his career as
Professor of Mathematics.
Peano was strongly influenced by the logical system developed
by Frege and, along with Russell, did a lot to popularize and further
develop these ideas. In 1889 Peano published his famous axioms,
now called Peano axioms, which defined the natural numbers in terms
of sets. Here are Peano’s main axioms:
1.
Zero is a number.
2.
The successor of any number is another number.
3.
There are no two numbers with the same successor.
4.
Zero is not the successor of a number.
5.
(Axiom of induction) If a set S of numbers contains zero and also the successor of every num-
ber in S, then every number is in S.

First-Order Logic
161
In 1890 Peano constructed a “space-filling curve” – a continuous curve filling the entire unit
square, an early example of a fractal – as a counterexample to the claim that a continuous curve can
be enclosed in an arbitrarily small region.
In 1892 Peano embarked on the extremely ambitious project, called Formulario Mathematico,
intended as an encyclopedia of all mathematical formulae and theorems expressed in a symbolic
language. Many of the symbols that Peano used in the Formulario are still in use today. Thus mon-
umental work, eventually completed in 1908, had a strong influence in terms of its rigorous expo-
sition and modern style, but Peano’s use of it for teaching was liked by neither his students nor his
colleagues.
In 1903 Peano started developing an international auxiliary language called Latino sine flexione,
later also called Interlingua, using Latin vocabulary but with very simplified grammar to make it
easier to learn. He published the final edition of Formulario Mathematico in Latino sine flexione,
which was an added reason for its lack of popularity.
Eventually, Peano received wide recognition and many awards for his crucial contributions to
modernizing mathematics and making the mathematical notation and reasoning more rigorous,
based on mathematical logic.
Below is an illustration of the first of several steps of an iterative construction of Peano’s curve,
eventually defined as the limit of the construction, filling up the whole square.
4.3.
The language of ﬁrst-order logic: a deeper look
4.3.1.
Translations from natural language into first-order languages
When learning a new language, it is usually more difficult to translate into that language than
to translate from it into our own. This is likewise the case for first-order languages. In both
cases the best learning strategy is practicing.
1. Let us start with translating
“There is an integer greater than 2 and less than 3.”
Surely, this is false, but now we are not concerned with its truth, only with its transla-
tion to . It is immediate:
∃x(x > 𝟐∧x < 𝟑).
Note that 𝟐and 𝟑here are terms, not the numbers 2 and 3.

162
Logic and Discrete Mathematics: A Concise Introduction
2. Now, does the same translation work for ? No, because the quantification is over
all elements of the domain of discourse, so the same formula would say in “There is a
rational number greater than 2 and less than 3”, which is true, but not what we wanted
to say. So, what now? If we want to refer to integers while the domain of discourse is a
larger set, viz. the rational numbers, we need to extend the language with an additional
predicate I which says that the element of the domain is an integer. Now the translation
is easy:
∃x(I(x) ∧x > 𝟐∧x < 𝟑).
We will come back to this trick later again.
3. Let us now translate
“There is no real number, the square of which equals −1.”
to . How about
∃x(¬x2 = −𝟏)?
Although the sentence begins with “There is … ”, do not be confused: this is not an
existential statement, but a negation of one. It actually says
“It is not true that there is a real number the square of which equals −1.”
so the correct translation is
¬∃x(x2 = −𝟏).
Here are some nonmathematical examples.
1. Take the sentence
“Every man loves a woman.”
It looks deceptively simple; how about just ∀x∃yL(x‚ y)? Wrong! This only means
“Everybody loves somebody”.
This sentence presents a problem we have already seen before: the quantifiers in our
formal language range over the whole domain of discourse, in our case over all human
beings. So whenever we write ∀x in this context it will mean “every human being”, not
“every man”; likewise, using ∃x we say “there is a human being”, but we cannot say
“there is a woman”.
Thus, in order to formalize our sentence in the language of first-order logic, we need
to resolve this problem. For that, we use again the little trick with the predicates,
called restricted quantification (see more on that further). After thinking a little on
the sentence, we realize that it can be rephrased in the following way which is more
convenient to formalize in first-order logic, even though it sounds a bit awkward:
“For every human, if he is a man then there is a human who is a woman and
the man loves that woman.”

First-Order Logic
163
Now the translation into is immediate:
∀x(M(x) →∃y(W(y) ∧L(x‚ y))).
2. Likewise, we can translate “Every mother has a child whom she loves.”
∀x(∃y(x = m(y)) →∃z(C(z‚ x) ∧L(x‚ z))).
Make an effort to understand how these translations work. Pay special attention to the use
of variables and the quantification.
4.3.2.
Restricted quantification
As already discussed, we often quantify not over all individuals from the domain, but over a
specified family of them, e.g. “There is a positive number x such that … ”, “Every woman … ”,
etc. There are two natural ways in which to formalize such a restricted quantification. We can
either use a many-sorted domain (e.g. in the domain of numbers we can have sorts for integers,
positive numbers, rational numbers, etc.; in the domain of humans we can have sorts for male,
female, young, etc., individuals) and different stocks of variables for each sort12 or we can use
unary predicates for each sort and logical connectives to express the restricted quantification
schemes, as we did when we formalized the sentence “Every man loves a woman.” For instance,
in order to quantify over positive numbers, we can introduce a predicate P(x), saying that “x
is a positive number” and then
∃x(P(x) ∧· · · x · · ·)
says that there exists an object x which is a positive number and which satisfies · · · x · · ·. Likewise,
∀x(P(x) →· · · x · · ·)
says that all objects x, which are positive numbers, satisfy · · · x · · ·.
Of course, in this case we need not introduce the predicate for positive numbers because
it is definable as long as we have the symbol < in our language. Thus, the formulae ∃x(𝟎<
x ∧· · · x · · ·) and ∀x(𝟎< x →· · · x · · ·) will do the same job as those above.
While the former method is more commonly used in informal reasoning, the latter is a
more universal one. In usual mathematical practice, though, the following convenient combi-
nation of the two methods is used. For the most important families of individuals, we intro-
duce some standard notation, e.g. the set of natural numbers is usually denoted by ℕ, the set
of integers by ℤ, the set of rational numbers by ℚand the set of reals by ℝ. Now, if we want
to quantify, for example, over integers, we can say: “for all x in ℤ”, respectively “ there is x in ℤ
such that”, or symbolically:
∀x ∈ℤ(· · · x · · ·)‚ and ∃x ∈ℤ(· · · x · · ·)
For instance, ∀x ∈ℤ(x2 ≥x) states (truly) that the square of every integer is greater than or
equal to that integer, ∃x ∈ℚ(x3 −𝟐x + 𝟐= 𝟎) states (falsely) that there is a rational solution of
12 In fact, quite often we do that in mathematical discourse. It is a tradition to denote a real number by x‚ y‚ z,
etc., while an integer would rather be denoted by i‚ j‚ k‚ n‚ m‚ a function by f‚ g‚ h‚ etc. Of course, there is no inherent
reason, apart from the risk of confusion, not to use f for an integer or j for a real number. And, when working with
complex numbers, i becomes something quite different.

164
Logic and Discrete Mathematics: A Concise Introduction
the equation x3 −𝟐x + 𝟐= 𝟎and ∀x ∈ℝ∃z ∈ℤ(x < z) says that for every real number there is
an integer greater than it. (True or false?)
4.3.3.
Free and bound variables. Scope of a quantifier
There are two essentially different ways in which we use individual variables in first-order
formulae.
1. First, we use them to denote unknown or unspecified objects, like in (𝟓< x) ∨(x2 + x −
𝟐= 𝟎). We say that the variable x occurs free in that formula. As long as a formula
contains free variables, it cannot (in general) be assigned a truth value until these free
variables are assigned values. Therefore, it cannot be regarded as a proposition, for
its truth may vary depending on the different possible values of the occurring free
variables. For example, assigning value 1 or 6 to x in the formula above turns it into a
true proposition in , while assigning value 2 to x turns it into a false one.
2. Second, we use individual variables in order to quantify, as in ∀x((𝟓< x) ∨(x2 + x −
𝟐= 𝟎)) and ∃x((𝟓< x) ∨(x2 + x −𝟐= 𝟎)). In these formulae the variable x is said to be
bound by the quantifier ∀(i.e. universally bound) in the first example and, respec-
tively, by ∃(i.e. existentially bound) in the second one.
Note that the same variable can be both free and bound in a formula. For example: x in the
formula x > 𝟎∧∃x(𝟓< x). That is why we talk about free and bound occurrences of a variable
in a formula.
To make the notion of a bound occurrence of a variable more precise, note that every occur-
rence of a quantifier Q in a formula is the beginning of a unique subformula QxA‚ called the
scope of that occurrence of the quantifier. For example, in the formula ∀x((x > 𝟓) →∀y(y < 𝟓→
(y < x ∧∃x(x < 𝟑)))), the scope of the first occurrence of ∀is the whole formula, while the scope
of the second occurrence of ∀is ∀y(y < 𝟓→(y < x ∧∃x(x < 𝟑))) and the scope of the occurrence
of ∃is ∃x(x < 𝟑).
Now, every bound occurrence of a variable x is bound by the innermost occurrence of a
quantifier Q over x in which scope that occurrence of x is. In other words, an occurrence of a
variable x is bound by the first occurrence of the quantifier Q in a formula QxA‚ if and only
if that occurrence of x is free in the subformula A. For example, in the formula ∀x((x > 𝟓) →
∀y(y < 𝟓→(y < x ∧∃x(x < 𝟑)))) the first three occurrences of x are bound by the first occur-
rence of ∀, while the last two are bound by the occurrence of ∃.
Definition 4.3.1 A formula with no bound variables is called an open formula. A formula with no
free variables is called a closed formula or a (first-order) sentence.
Once interpreted in a structure, first-order sentences have a determined meaning and rep-
resent propositions about that structure.
The following important observation allows us to only consider the assignment of values
to the free variables occurring in a formula in order to determine the truth of that formula.
Proposition 4.3.2 The truth of a formula in a given first-order structure under a given variable assign-
ment only depends on the assignment of values to the free variables occurring in that formula. That

First-Order Logic
165
is, if v1‚ v2 are variable assignments in such that v1∣FVAR(A) = v2∣FVAR(A), where FVAR(A) is the set
of free variables in A, then
‚ v1 ⊨A iff ‚ v2 ⊨A.
In particular, if a variable x does not occur free in A, then ‚ v ⊨A if and only if ‚ v′ ⊨A
for every x-variant v′ of v and, therefore, if and only if ‚ v ⊨∀xA.
4.3.4.
Renaming of a bound variable in a formula. Clean formulae
Note that a bound variable in a formula plays an auxiliary rôle and does not have its own meaning
(we also call it a dummy variable) in the sense that we can replace it by another one throughout
the formula without altering the meaning of that formula. For example, it should be intu-
itively clear that ∃x(𝟓< x ∨x2 + x −𝟐= 𝟎) means exactly the same as ∃y(𝟓< y ∨y2 + y −𝟐= 𝟎)
(in particular, these two are equally true); likewise ∀x(𝟓< x ∨x2 + x −𝟐= 𝟎) means the same as
∀y(𝟓< y ∨y2 + y −𝟐= 𝟎). On the other hand, 𝟓< x ∨x2 + x −𝟐= 𝟎is essentially different from
𝟓< y ∨y2 + y −𝟐= 𝟎; depending on the values of the free variables x and y, one of these can
be true, while the other one is false.
You should be able to distinguish very well between the meaning and the use of free and
bound variables. For example, the free and the bound occurrences of the variable x in the
formula (x > 𝟓) ∧∀x(x < 𝟐x) have nothing to do with each other.
Furthermore, different occurrences of the same variable can be bound by different quan-
tifiers, and that may also be confusing. Examples are:
• ∃x(x > 𝟓) ∨∀x(𝟐x > x). Clearly, the occurrences of x, bound by the first quantifier, have noth-
ing to do with those bound by the second one.
• ∃x(x > 𝟓) ∧∃x(x < 𝟑). Likewise, the two x’s claimed to exist here need not (in fact, cannot)
be the same, so this formula has the same meaning as ∃y(y > 𝟓) ∧∃x(x < 𝟑) or ∃x(x > 𝟓) ∧
∃z(z < 𝟑) or ∃y(y > 𝟓) ∧∃z(z < 𝟑).
• ∀x((x > 𝟓) →∃x(x < 𝟑)). Again, the occurrences of x in the subformula ∃x(x < 𝟑) are bound
by ∃and are not related to the first two occurrences of x, bound by ∀, so this formula
has the same meaning as ∀x((x > 𝟓) →∃y(y < 𝟑)) or ∀z((z > 𝟓) →∃x(x < 𝟑)) or ∀z((z > 𝟓) →
∃y(y < 𝟑)).
The best way to avoid confusions like these in formal mathematical arguments and proofs
is always to use different variables for different purposes. In particular, never use the same variable
as both free and bound, nor as bound by two different quantifiers in the same formula or proof.
Definition 4.3.3 A formula A is clean if no variable occurs both free and bound in A and every two
occurrences of quantifiers bind different variables.
Thus, ∃x(x > 𝟓) ∧∃y(y < z) is clean, while ∃x(x > 𝟓) ∧∃y(y < x) and ∃x(x > 𝟓) ∧∃x(y < x)
are not.
Definition 4.3.4 The uniform replacement of all occurrences of a variable x bound by the same occur-
rence of a quantifier in a formula A with a variable not occurring in A is called renaming the variable
x in A.

166
Logic and Discrete Mathematics: A Concise Introduction
For instance, a correct renaming of (x > 𝟓) ∧∀x(x > 𝟓→¬∃x(x < y)) is the formula (x >
𝟓) ∧∀x(x > 𝟓→¬∃z(z < y)), but neither (z > 𝟓) ∧∀x((x > 𝟓) →¬∃x(x < y)), nor (x > 𝟓) ∧∀z((z >
𝟓) →¬∃z(z < y)), nor (x > 𝟓) ∧∀x(x > 𝟓→¬∃y(y < y)) is correct.
Every formula can be transformed into a clean formula by means of several consecutive
renamings of variables. For example, the formula
(x > 𝟓) ∧∀x((x > 𝟓) →¬∃x(x < y))
can be transformed into the clean formula
(x > 𝟓) ∧∀z1((z1 > 𝟓) →¬∃z2(z2 < y)).
4.3.5.
Substitution of a term for a variable in a formula. Capture of a variable
Substitution of a term for a variable in a formula
Given a formula A‚ a variable x and a term t, we can obtain a formula A[t∕x] by simultaneously
substituting t for all free occurrences of x in A. The formula A[t∕x] is called the result of sub-
stitution of t for x in A. The semantic meaning of such substitution is to assign the value of
the term t to the variable x when evaluating the truth of A. For instance, given the formula
A = ∀x(P(x‚ y) →(¬Q(y) ∨∃yP(x‚ y)))‚
we have
A[f(y‚ z)∕y] = ∀x(P(x‚ f(y‚ z)) →(¬Q(f(y‚ z)) ∨∃yP(x‚ y)))‚
while
A[f(y‚ z)∕x] = A‚
because x does not occur free in A.
Capture of a variable
Intuitively, A[t∕x] is supposed to say about the individual denoted by t the same as what A
says about the individual denoted by x. However, is that always the case? No. An unwanted
“capture” effect can occur after such a substitution if we substitute a term t for a variable x in
a formula A where x is in the scope of a quantifier over another variable y that occurs in t. For
example, substituting y + 𝟏for x in the formula ∃y(x < y), which is true in for every value
assigned to x, will produce the false sentence ∃y(y + 𝟏< y) since the occurrence of y in the term
y + 𝟏is captured by the quantifier ∃y because the substitution mixed free and the bound uses of
y. Similarly, in the formula ∀x∃z(x < z), meaning that for every number there is a greater one,
renaming x with the variable z will produce ∀z∃z(z < z), which clearly distorts the meaning of
the formula. The reason is that when substituting z for x it is captured by the quantifier ∃z.
Formally, capture happens when new occurrences of a variable, say y, are introduced in
the scope of a quantifier Qy in a formula A as a result of substitution of a term t containing y for
another variable x in that formula. The following definition means to eliminate substitutions
that allow capture.
Definition 4.3.5 A term t is free for (substitution for) a variable x in a formula A if no variable
in t is captured by a quantifier as t is substituted for any free occurrence of x in A.

First-Order Logic
167
To avoid the confusions mentioned above we only allow a substitution t∕x in a formula A
when t is free for x in A.
Hereafter, when t is a constant symbol c, we will often write A(c) instead of A[c∕x].
A note on renamings and substitutions in a formula
Note that renaming and substitution are very different operations: renaming always acts on
bound variables, while substitution always acts on free variables. Also, as we will see later,
renamings preserve the formula up to logical equivalence, while substitutions do not.
On the other hand, a suitable renaming of a formula can prepare it for a substitution, by
rendering the term to be substituted free for such substitution in the renamed formula. For
instance, the term f(x‚ y) is not free for substitution for y in
A = ∀x(P(x‚ y) ∧∃yQ(y))‚
but it becomes free for such substitution after renaming of A, for example, to
A′ = ∀x′(P(x′‚ y) ∧∃yQ(y)).
4.3.6.
Exercises
➊
Using the additional predicate I(x) for “x is an integer” formalize the following sentences
in the first-order language for the structure of real numbers .
(a) Every square of an integer is greater than 0.
(b) Every square of a real number that is not an integer is greater than 0.
(c) Some real numbers are not integers.
(d) Every integer is even or odd.
(e) No integer is both even and odd.
(f) For every integer there is a greater integer.
(g) Every positive integer is a square of some negative real number.
(h) Not every real number is greater than an integer.
(i) There is an integer such that not every real number is greater than it.
(j) No real number is greater than every integer.
(k) Every real number that is not zero has a reciprocal.
(l) There is a real number that, when multiplied by any real number, produces that num-
ber.
(m) Between every two different real numbers there is an integer.
➋
Using unary predicates T(x) for “x talks” and L(x) for “x listens”, formalize the following
sentences in a first-order language for the domain of all humans.

168
Logic and Discrete Mathematics: A Concise Introduction
(a) Everybody talks or everybody listens.
(b) Everybody talks or listens.
(c) If John talks everybody listens.
(d) If somebody talks everybody listens.
(e) If somebody talks everybody else listens.
(f) Nobody listens if everybody talks.
➌
Translate the following sentences to the first-order language for the structure of all
humans . Remember that the language does not have a unary predicate for “ … is a
child”, but a binary predicate “ … is a child of … ”.
(a) Some men love every woman.
(b) Every woman loves every man who loves her.
(c) Every man loves a woman who does not love him.
(d) Some women love no men who love them.
(e) Some men love only women who do not love them.
(f) No woman loves a man who loves every woman.
(g) Every woman loves her children.
(h) Every child loves his/her mother.
(i) Everyone loves a child. (Note the ambiguity here.)
(j) A mother loves every child. ( … and here.)
(k) Every child is loved by someone.
(l) Some woman loves every child.
➍
Using a first-order language with = only, write:
(a) a sentence 𝜆n saying that the domain has at least n elements;
(b) a sentence 𝜇n saying that the domain has at most n elements;
(c) a sentence 𝜎n saying that the domain has exactly n elements.
➎
Let R be a binary relational symbol. Write a first-order formula, in the language with R
and =, saying that R is functional, i.e. every element of the domain is R-related to a unique
element.
➏
Determine the scope of each quantifier and the free and bound occurrences of variables in
the following formulae (where P is a unary predicate and Q a binary one).
(a) ∃x∀z(Q(z‚ y) ∨¬∀y(Q(y‚ z) →P(x)))
(b) ∃x∀z(Q(z‚ y) ∨¬∀x(Q(z‚ z) →P(x)))
(c) ∃x(∀zQ(z‚ y) ∨¬∀z(Q(y‚ z) →P(x)))

First-Order Logic
169
(d) ∃x(∀zQ(z‚ y) ∨¬∀yQ(y‚ z)) →P(x)
(e) ∃x∀z(Q(z‚ y) ∨¬∀yQ(x‚ z)) →P(x)
(f) ∃x∀zQ(z‚ y) ∨¬(∀yQ(y‚ x) →P(x))
(g) ∃x(∀zQ(z‚ y) ∨¬(∀zQ(y‚ z) →P(x)))
(h) ∃x(∀x(Q(x‚ y) ∨¬∀z(Q(y‚ z) →P(x))))
(i) ∃x(∀y(Q(x‚ y) ∨¬∀xQ(x‚ z))) →P(x)
➐
Rename the bound variables in each of the formulae above to obtain a clean formula.
➑
For each of the following formulae (where P is a unary predicate and Q a binary one)
determine if the indicated term is free for substitution for the indicated variable. If so, do
the substitution.
(a) Formula: ∃x(∀zP(y) ∨¬∀y(Q(y‚ z) →P(x))); term: f(x); variable: z.
(b) Same formula; term: f(z); variable: y.
(c) Same formula; term: f(y); variable: y.
(d) Formula: ∀x((¬∀yQ(x‚ y) ∨P(z)) →∀y¬∃z∃xQ(z‚ y)); term: f(y); variable: z.
(e) Same formula; term: g(x‚ f(z)); variable: z.
(f) Formula: ∀y(¬(∀x∃z(¬P(z) ∧∃yQ(z‚ x))) ∧(¬∀xQ(x‚ y) ∨P(z))); term f(x); variable: z.
(g) Same formula; term: f(y); variable: z.
(h) Formula: (∀y∃z¬P(z) ∧∀xQ(z‚ x)) →(¬∃yQ(x‚ y) ∨P(z)); term: g(f(z)‚ y); variable: z.
(i) Same formula; term: g(f(z)‚ y); variable: x.
➒∗Additional exercises. Recall that a natural number is prime if it has no other positive integer
divisors but 1 and itself. Express the following statements in the language :
(a) The number (denoted by) x is prime.
(b) There are infinitely many primes. (Hint: this is equivalent to saying that for every
natural number there is a greater prime.)
(c) (Goldbach’s conjecture) Every even integer greater than 2 is the sum of two primes.
(d) (The prime twins conjecture) There are infinitely many pairs of primes that differ by 2.
(e) Every natural number n has a prime divisor not greater than
√
n. (Note: the function
√⋅is not in the language.)
(f) The numbers x and y have no common prime divisor.

170
Logic and Discrete Mathematics: A Concise Introduction
Bertrand Arthur William Russell, (18.5.1872–2.2.1970)
Bertrand Russell was a famous British philoso-
pher, logician, mathematician, intellectual and
a political activist with strong pacifist views,
who made seminal contributions to the founda-
tions of mathematics and to the advancement of
modern formal logic. He is also regarded as one
of the founders of modern analytic philosophy.
Russell
studied
mathematics
and
phi-
losophy at Trinity College, Cambridge, from
where he graduated with distinction. He later
held academic positions there with several
interruptions during which he worked for short
periods at several universities in the United
States of America.
Russell’s first major work was his book The Principles of Mathematics published in 1903, where
he presented and discussed his famous paradoxical definition of the set of all sets that are not mem-
bers of themselves, which became known as Russell’s paradox (see the box at the end of Section 2.1
in Chapter 2). That discovery dealt a devastating blow to Cantor’s set theory and to Frege’s for-
malization of logic (see Section 4.1) and played a crucial role in bringing about a major crisis in the
foundations of mathematics at the beginning of the 20th century. In this book and in the follow-
ing three-volume Principia Mathematica, written with Whitehead and published during 1910–1913,
Russell advanced the theory of logicism. The aim of logicism was to base the entire mathematics on
purely logical principles. It was one of the three main philosophical approaches to reforming the
foundations of mathematics, prompted by the foundational crisis. According to the logicistic the-
ory, first put forward by Frege, all mathematical truths can be translated into logical truths and all
mathematical proofs can be transformed into logical proofs, and therefore all mathematical results
are theorems of logic. In Russell’s words, “The fact that all Mathematics is Symbolic Logic is one of
the greatest discoveries of our age; and when this fact has been established, the remainder of the
principles of mathematics consists in the analysis of Symbolic Logic itself.” With these books and
later philosophical works Russell became immensely influential for many prominent philosophers
and mathematicians, including his genius student Wittgenstein.
Russell was a staunch pacifist and shortly after the First World War he was convicted and
imprisoned for 6 months for his antiwar views and speeches, where he wrote his extremely popular
Introduction to Mathematical Philosophy. He pursued his antiwar activities and kept a high political
profile, which brought him worldwide fame well beyond academic circles, until his death in 1970
at the age of 97.
Russell also had a very eventful personal life, with four marriages and a number of intermittent
affairs. His often revolutionary views and writings on marriage, morals and society were contro-
versial and in 1940 caused his appointment at the City College New York to be revoked. However,
10 years later Russell received the Nobel Prize for literature, inter alia, for his book Marriage and
Morals.
In summary, Russell was one of the most influential logicians and philosophers of the 20th
century and one of the most notable intellectual personalities of his time. He said of himself: “Three
passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search
for knowledge, and unbearable pity for the suffering of mankind.”

First-Order Logic
171
4.4.
Truth, logical validity, equivalence and consequence
in ﬁrst-order logic
4.4.1.
More on truth of sentences in structures. Models and countermodels
Recall that a sentence is a formula with no free variables.
As we noted earlier, the truth of a sentence in a given structure does not depend on the variable
assignment. Therefore, for a structure and sentence A we can simply write
⊨A
if ‚ v ⊨A for any (hence, every) variable assignment v.
We then say that is a model of A and that defstyle A is true in or that defstyle A is
satisfied by . Otherwise we write ⊭A and say that defstyle A is false in or that is a
countermodel for A.
Example 4.4.1
True sentences express properties of structures, for example:
• ⊨∀x∀y(x + y = y + x) (commutativity of the addition of real numbers).
⊨∀x∀y∀z((x + y) × z = (x × z) + (y × z)) (distributivity of multiplication over addition of
real numbers).
• ⊨∀x∃y(x < y) (for every natural number there is a larger one), while ⊭∀x∃y(y < x)
(not for every natural number is there a smaller one).
Hence, ⊨¬∀x∃y(y < x).
However, ⊨∀x∃y(y < x).
• ⊨∀x∀y(x < y →∃z(x < z ∧z < y)) (the ordering of the rationals is dense), while
⊭∀x∀y(x < y →∃z(x < z ∧z < y)) (the ordering of the integers is not dense).
• ⊨∃x(3x = 1), but ⊭∃x(3x = 1) (1∕3 is a rational number, but is not an integer).
• ⊨∀x(x > 𝟎→∃y(y2 = x)) (every positive real number is a square of a real number), but
⊭∀x(x > 𝟎→∃y(y2 = x)) (not every positive rational number is a square of a rational
number).
• ⊭∀x∀y(xy > 𝟎→(x > 𝟎∨y > 𝟎)). (Take, for example, x = y = −1.)
• ⊨∃x∀y(xy < 𝟎→y = 𝟎)?
• ⊨∀x∀y(∃z(x = m(z) ∧y = m(z)) →x = y).
What does this sentence mean? Is it only true for this interpretation?
• ⊨(∀x(∀y(y < x →P(y)) →P(x)) →∀xP(x)), where P is any (uninterpreted) unary predi-
cate.
Why is this true? What does this sentence say about ? Is it also true in ?

172
Logic and Discrete Mathematics: A Concise Introduction
4.4.2.
Satisfiability and validity of first-order formulae
A first-order formula A is:
• satisfiable if ‚ v ⊨A for some structure and some variable assignment v in ;
• (logically) valid, denoted ⊨A, if ‚ v ⊨A for every structure and every variable assignment
v in .
If A is a sentence, the variable assignment in these definitions is not relevant and can be
omitted. Actually, validity of any formula can be reduced to a validity of a sentence, as follows.
Definition 4.4.2 Given a first-order formula A with free variables x1‚ …‚ xn, the sentence ∀x1…∀xnA
is called a universal closure of A.
Note that, depending on the order of the quantified variables, a formula can have several
universal closures but, as we will see further, they are all essentially equivalent. The following
is an easy exercise to prove.
Proposition 4.4.3 A formula A is logically valid if and only if any of its universal closures is logically
valid.
Example 4.4.4
Here are some examples of logically valid and non-valid first-order formulae:
• Every first-order instance of a tautology is logically valid.
Thus, for instance, ⊨¬¬(x > 𝟎) →(x > 𝟎) and ⊨P(x) ∨¬P(x), for any unary predicate P.
• If A is a logically valid formula and x is any variable then ∀xA is also valid.
Thus, ⊨∀x(P(x) ∨¬P(x)), as well as ⊨∀x(P(y) ∨¬P(y)).
• ⊨∀x(x = x), because of the very meaning of the equality symbol =.
• ⊨∀x∀y(∃z(x = f(z) ∧y = f(z)) →x = y), where f is any unary functional symbol, because of
the very meaning of the notion of a function.
• The sentence ∃xP(x) is not valid: take for instance P(x) to be interpreted as the empty set in
any nonempty domain. This will give a countermodel for that sentence. However, ∃xP(x) is
satisfiable; a model is any structure where the interpretation of P(x) is nonempty.
• The sentence ∀xP(x) ∨∀x¬P(x) is not valid, but it is satisfiable.
(Find a model and a countermodel.)
• The sentence ∃x(P(x) ∧¬P(x)) is not satisfiable. Why?
• ⊨∃x∀yP(x‚ y) →∀y∃xP(x‚ y).
It is a good exercise to check this from the definition; we will discuss it again later.
• However, ⊭∀y∃xP(x‚ y) →∃x∀yP(x‚ y). Find a countermodel!

First-Order Logic
173
4.4.3.
Logical equivalence in first-order logic
Logical equivalence in first-order logic is based on the same idea as in propositional logic: the
first-order formulae A and B are logically equivalent if always one of them is true if and only
if the other is true. Formally, this is given as follows.
Definition 4.4.5 The first-order formulae A and B are logically equivalent, denoted A ≡B, if for
every structure and variable assignment v in :
‚ v ⊨A
if and only if
‚ v ⊨B.
In particular, if A and B are sentences, A ≡B means that every model of A is a model of B and
every model of B is a model of A.
An equivalent definition: the first-order formulae A and B are logically equivalent,
denoted A ≡B, if A ↔B is logically valid.
Some basic properties of logical equivalence:
1. A ≡A.
2. If A ≡B then B ≡A.
3. If A ≡B and B ≡C then A ≡C.
4. If A ≡B then ¬A ≡¬B, ∀xA ≡∀xB and ∃xA ≡∃xB.
5. If A1 ≡B1 and A2 ≡B2 then A1 ⚬A2 ≡B1 ⚬B2, where ⚬is any of ∧‚ ∨‚ →and ↔.
Example 4.4.6
Here are some examples of logical equivalences between first-order formulae:
• Any first-order instance of a pair of equivalent propositional formulae is a pair of logically
equivalent formulae. For example:
¬¬∃xQ(x‚ y) ≡∃xQ(x‚ y) (being an instance of ¬¬p ≡p) and
∃xP(x) →Q(x‚ y) ≡¬∃xP(x) ∨Q(x‚ y) (an instance of p →q ≡¬p ∨q).
• The result of renaming a variable in a formula is logically equivalent to that formula. For
example:
∃x(𝟓< x ∨x2 + x −𝟐= 𝟎) ≡∃y(𝟓< y ∨y2 + y −𝟐= 𝟎).
Therefore, every formula can be transformed into a logically equivalent clean formula.
• ¬∃xP(x) and ∃x¬P(x) are not logically equivalent. Indeed, “There is no student who passed
the exam” is not equivalent to “There is a student who did not pass the exam”.
• “The integer x is not less than 0” is not logically equivalent to “The integer x is greater than or
equal to 0”. Mathematically these mean the same, because of the mathematical property
of the ordering of integers, called “trichotomy”, which arranges all integers in a line, but
not because of logical reasons. Likewise, 2+2=4 is a mathematical, not a logical, truth. To
put it simply: logic does not know any mathematics. It is important to distinguish logical from
nonlogical truths and logical from nonlogical equivalences.

174
Logic and Discrete Mathematics: A Concise Introduction
4.4.4.
Some logical equivalences involving quantifiers
1. To begin with, the negation changes the quantifiers as follows:
¬∀xA ≡∃x¬A
¬∃xA ≡∀x¬A
For example:
• “Not every student wrote the test” means the same as “There is a student who did not
write the test”.
• “There is no natural number less than 0” means “Every natural number is not less than
0”.
2. By negating both sides of the equivalences above we find that each of the universal
and existential quantifier is definable in terms of the other:
∀xA ≡¬∃x¬A‚
∃xA ≡¬∀x¬A.
3. Universal quantifiers distribute over conjunctions:
∀xP ∧∀xQ ≡∀x(P ∧Q).
4. Existential quantifiers distribute over disjunctions:
∃xP ∨∃xQ ≡∃x(P ∨Q).
5. Assuming that x does not occur free in Q, the following distributive equivalences hold:
(a) ∀xP ∧Q ≡Q ∧∀xP ≡∀x(P ∧Q)‚
(b) ∀xP ∨Q ≡Q ∨∀xP ≡∀x(P ∨Q)‚
(c) ∃xP ∨Q ≡Q ∨∃xP ≡∃x(P ∨Q)‚
(d) ∃xP ∧Q ≡Q ∧∃xP ≡∃x(P ∧Q),
6. Two nested quantifiers of the same type commute:
∀x∀yA ≡∀y∀xA‚
∃x∃yA ≡∃y∃xA.
7. Consequently, every two universal closures of a formula are logically equivalent.
8. The case of two different nested quantifiers is more delicate: while
∃x∀yA →∀y∃xA
is valid (see that for yourself), the converse implication
∀y∃xA →∃x∀yA
is not. For instance,
“For every integer x there is an integer y such that x + y = 0”,

First-Order Logic
175
which is true, certainly does not imply that
“There is an integer y such that for every integer x it holds that x + y = 0”,
which is false. Likewise, “Every man loves a woman” does not imply that “There is a
woman whom every man loves”.
Therefore, ∃x∀yA and ∀y∃xA are not equivalent. It is important to remember which of
these implies the other, and why.
4.4.5.
Negating first-order formulae
Using the first pair of equivalences in Section 4.4.4, in addition to those from propositional
logic, we can now systematically negate not only propositions but any first-order sentences as
well. For example, the sentence
“For every car, there is a driver who, if (s)he can start it, then (s)he can stop it”
can be formalized in a suitable language as
∀x(Car(x) →∃y(Driver(y) ∧(Start(x‚ y) →Stop(x‚ y)))).
Now, we negate:
¬∀x(Car(x) →∃y(Driver(y) ∧(Start(x‚ y) →Stop(x‚ y))))
≡∃x¬(Car(x) →∃y(Driver(y) ∧(Start(x‚ y) →Stop(x‚ y))))
≡∃x(Car(x) ∧¬∃y(Driver(y) ∧(Start(x‚ y) →Stop(x‚ y))))
≡∃x(Car(x) ∧∀y¬(Driver(y) ∧(Start(x‚ y) →Stop(x‚ y))))
≡∃x(Car(x) ∧∀y(¬Driver(y) ∨¬(Start(x‚ y) →Stop(x‚ y))))
≡∃x(Car(x) ∧∀y(¬Driver(y) ∨(Start(x‚ y) ∧¬Stop(x‚ y)))).
Since ¬A ∨B ≡A →B‚ the last formula is equivalent to
∃x(Car(x) ∧∀y(Driver(y) →(Start(x‚ y) ∧¬Stop(x‚ y)))).
Thus, the negation of the sentence above is equivalent to:
“There is a car such that every driver can start it and cannot stop it.”
Note that the restricted quantifiers satisfy the same equivalences (and nonequivalences)
mentioned in Section 4.4.4. In particular,
¬∀x(P(x) →A)
≡
∃x(P(x) ∧¬A)‚
¬∃x(P(x) ∧A)
≡
∀x(P(x) →¬A)‚
and hence:
¬∀x ∈X(A)
≡
∃x ∈X(¬A)‚
¬∃x ∈X(A)
≡
∀x ∈X(¬A).

176
Logic and Discrete Mathematics: A Concise Introduction
Thus, the negation of the definition of a limit of a function:
¬(∀𝜖> 𝟎∃𝛿> 𝟎(𝟎< |x −c| < 𝛿→|f(x) −L| < 𝜖))
is logically equivalent to
∃𝜖> 𝟎∀𝛿> 𝟎(𝟎< |x −c| < 𝛿∧¬|f(x) −L| < 𝜖).
4.4.6.
Logical consequence in first-order logic
The notion of logical consequence is fundamental in logic. In propositional logic we defined
the logical consequence A1‚ …‚ An ⊨B as “preservation of the truth from the premises to the conclu-
sion”. The same idea applies in first-order logic, but instead of truth tables we now use truth
in a structure.
Definition 4.4.7 A first-order formula B is a logical consequence from the formulae A1‚ …‚ An‚
denoted A1‚ …‚ An ⊨B, if for every structure and every variable assignment v in for which the
formulae A1‚ …‚ An are satisfied (equivalently, A1 ∧· · · ∧An is satisfied) in by v, the formula B is
also satisfied in by v. Formally:
‚ v ⊨A1 ∧· · · ∧An
implies
‚ v ⊨A.
In particular, if A1‚ …‚ An‚ B are sentences, then A1‚ …‚ An ⊨B means that B is true in every
structure in which all A1‚ …‚ An are true.
If A1‚ …‚ An ⊨B‚ we say that B follows logically from A1‚ …‚ An or that A1‚ …‚ An logically
imply B.
Note that:
• ∅⊨A iff ⊨A.
• A1‚ …‚ An ⊨B if and only if ⊨A1 ∧· · · ∧An →B.
Thus, the logical consequence in first-order logic is reduced to logical validity.
Example 4.4.8
Some examples and nonexamples of first-order logical consequences are:
1. If A ≡B then A ⊨B and B ⊨A. Why?
2. If A1‚ …‚ An‚ B are propositional formulae such that A1‚ …‚ An ⊨B and A′
1‚ …‚ A′
n‚ B′ are
first-order instances of A1‚ …‚ An‚ B obtained by the same substitution, then A′
1‚ …‚ A′
n ⊨B′.
For instance, ∃xA‚ ∃xA →∀yB ⊨∀yB.
3. ∀xA(x) ⊨A[t∕x] for any formula A and term t free for x in A.
Indeed, if ∀xA(x) is true in a structure , under some assignment, then A is true for every
possible value of x in , including the value of t under that assignment.
To put it in simple words: if everybody is mortal then, in particular, John is mortal and the mother
of Mary is mortal, etc.

First-Order Logic
177
4. ∀x(P(x) →Q(x))‚ ∀xP(x) ⊨∀xQ(x). Why? Note that this is not an instance of a propositional
logical consequence.
5. ∃xP(x) ∧∃xQ(x) ⊭∃x(P(x) ∧Q(x)).
Indeed, the structure ′ obtained from where P(x) is interpreted as “x is even” and
Q(x) is interpreted as “x is odd” is a countermodel:
′ ⊨∃xP(x) ∧∃xQ(x), while ′ ⊭∃x(P(x) ∧Q(x)).
Example 4.4.9
Here we illustrate “semantic reasoning”, based on the formal semantics of first-order formu-
lae, for proving or disproving first-order logical consequences.
1. Show the logical validity of the following argument:
“If Charlie suffers from slyme disease and everyone who suffers from slyme has
pink eyes, then somebody has pink eyes.”
Proof: Let us first formalize the argument in first-order logic by introducing predicates:
P(x) meaning “x suffers from slyme disease”, Q(x) meaning “x has pink eyes”, and a con-
stant symbol c interpreted as “Charlie”.
Now the argument can be formalized as follows:
(1) (P(c) ∧∀x(P(x) →Q(x)) ⊨∃yQ(y).
To show its validity take any structure for the first-order language introduced above
and any variable assignment v in . Now, suppose
(2) ‚ v ⊨(P(c) ∧∀x(P(x) →Q(x)).
We have to show that
(3) ‚ v ⊨∃yQ(y).
From the assumption (2) we have, by the truth definition of ∧, that
(4) ‚ v ⊨P(c) and
(5) ‚ v ⊨∀x(P(x) →Q(x)).
Let v′ be a variable assignment obtained from v by redefining it on x as follows: v′(x) =
c. (Recall that cis the interpretation of the constant symbol c in .) Then:
(6) ‚ v′ ⊨P(x).
According to the truth definition of ∀, it follows from (5) that

178
Logic and Discrete Mathematics: A Concise Introduction
(7) ‚ v′ ⊨P(x) →Q(x).
From (6) and (7) it follows that
(8) ‚ v′ ⊨Q(x).
Now, let v′′ be a variable assignment obtained from v by redefining it on y as follows:
v′′(y) = v′(x) = c. Then we have
(9) ‚ v′′ ⊨Q(y).
According to the truth definition of ∃, it follows from (9) that
(3) ‚ v ⊨∃yQ(y), so we are done.
2. Prove that the following argument is not logically valid:
“If everything is black or white then everything is black or everything is white.”
Proof: Again, we first formalize the argument in first-order logic, by introducing predi-
cates:
B(x) meaning “x is black” and W(x) meaning “x is white”.
Now the argument can be formalized as follows:
∀x(B(x) ∨W(x)) ⊨∀xB(x) ∨∀xW(x).
To falsify this logical consequence it suffices to find any countermodel, i.e. a structure 
and a variable assignment v such that
‚ v ⊨∀x(B(x) ∨W(x)) and ‚ v ⊭∀xB(x) ∨∀xW(x).
Note that the interpretations of the predicates B and W need not have anything to do with
black, white or any colour in that structure. Therefore, we choose to take the structure 
with the domain the set Z of all integers, where the interpretation of B is the predicate
Even, where Even(n) means “n is even”, and the interpretation of W is the predicate Odd,
where Odd(n) means “n is odd”.
We already know that the variable assignment is irrelevant here because there are no free
variables in this argument, but we will nevertheless need it in order to process the truth
definitions of the quantifiers.
Consider any variable assignment v in . Then take any variable assignment v′ that differs
from v possibly only on x. As the integer v′(x) is even or odd, ‚ v′ ⊨B(x) or ‚ v′ ⊨W(x);
hence (by the truth definition of ∨):
(1) ‚ v′ ⊨B(x) ∨W(x).
Thus, by the truth definition of ∀, it follows that
(2) ‚ v ⊨∀x(B(x) ∨W(x)).
On the other hand, consider the variable assignment v1 obtained from v by redefining
it on x as follows: v1(x) = 1. Then
(3) ‚ v1 ⊭B(x).
By the truth definition of ∀, it follows that

First-Order Logic
179
(4) ‚ v ⊭∀xB(x).
Likewise, consider the variable assignment v2 obtained from v by redefining it on x
as follows: v2(x) = 2. Then
(3) ‚ v2 ⊭W(x).
By the truth definition of ∀, it follows that
(4) ‚ v ⊭∀xW(x).
By the truth definition of ∨, it follows that
(5) ‚ v ⊭∀xB(x) ∨∀xW(x).
Therefore, by the truth definition of →, it follows from (2) and (5) that
(6) ‚ v ⊭∀x(B(x) ∨W(x)) →(∀xB(x) ∨∀xW(x)).
A logical consequence in first-order logic satisfies all basic properties of propositional log-
ical consequence. In particular, the following are equivalent:
1. A1‚ …‚ An ⊨B.
2. ⊨A1 ∧· · · ∧An →B.
3. ⊨A1 →(A2 →· · · (An →B) · · · ).
Besides, some important additional properties refer to the quantifiers:
(a) If A1‚ …‚ An ⊨B then ∀xA1‚ …‚ ∀xAn ⊨∀xB.
(b) If A1‚ …‚ An ⊨B and A1‚ …‚ An are sentences, then A1‚ …‚ An ⊨∀xB, and hence
A1‚ …‚ An ⊨B, where B is any universal closure of B.
(c) If A1‚ …‚ An ⊨B[c∕x], where c is a constant symbol not occurring in A1‚ …‚ An, then
A1‚ …‚ An ⊨∀xB(x).
(d) If A1‚ …‚ An‚ A[c∕x] ⊨B, where c is a constant symbol not occurring in any of
A1‚ …‚ An‚ A, or B, then A1‚ …‚ An‚ ∃xA ⊨B.
(e) For any term t free for substitution for x in A:
(a) ∀xA ⊨A[t∕x].
(b) A[t∕x] ⊨∃xA.
A first-order logical consequence can be established by using an extension of any of the
propositional deductive systems with additional rules for the quantifiers, to be introduced in
the next sections.

180
Logic and Discrete Mathematics: A Concise Introduction
Finally, to summarize: logical validity, consequence and equivalence in first-order logic
are related just like in propositional logic, namely the following are equivalent:
1. A ≡B.
2. ⊨A ↔B.
3. A ⊨B and B ⊨A.
4.4.7.
Exercises
In all of the exercises below “semantic reasoning” refers to reasoning based on the formal
semantics introduced in the advanced track. For the basic track, read “informal reasoning”
instead.
➊Use semantic reasoning to decide which of the following first-order formulae are logically
valid. For each of those that are not, give a countermodel, i.e. a structure that falsifies it.
(a) ∀x(P(x) ∨¬P(x))
(b) ∀xP(x) ∨∀x¬P(x)
(c) ∀xP(x) ∨¬∀xP(x)
(d) ∃x(P(x) ∨∃x¬P(x))
(e) ∃xP(x) →∀xP(x)
(f) ∃xP(x) →∃yP(y)
(g) ∃x(P(x) →∀yP(y))
(h) ∃x(P(x) →∀xP(x))
(i) ∀x(P(x) →∃yP(y))
(j) ∀x(P(x) →∀yP(y))
(k) ∀x∃yQ(x‚ y) →∀y∃xQ(x‚ y)
(l) ∀x∃yQ(x‚ y) →∀y∃xQ(y‚ x)
(m) ∀x(∃yQ(x‚ y) →∃yQ(y‚ x))
(n) ∃x¬∃yP(x‚ y) →∀y¬∀xP(x‚ y)
(o) (∀x∃yP(x‚ y) ∧∀x∀y(P(x‚ y) →P(y‚ x))) →∃xP(x‚ x)
➋If x does not occur free in Q, use semantic arguments to show that the following logical
equivalences hold.
(a) ∀x(P ∨Q) ≡∀xP ∨Q
(b) ∃x(P ∧Q) ≡∃xP ∧Q
(c) ∀x(Q →P) ≡Q →∀xP
(d) ∀x(P →Q) ≡∃xP →Q

First-Order Logic
181
(e) ∃x(P →Q) ≡∀xP →Q
(f) ∃x(Q →P) ≡Q →∃xP
➌Use semantic reasoning to decide which of the following logical equivalences hold. For
each one that does not hold give a countermodel, i.e. a structure in which one formula is
true while the other is false.
(a) ∀x(P(x) ∧Q(x)) ≡∀xP(x) ∧∀xQ(x)
(b) ∀x(P(x) ∨Q(x)) ≡∀xP(x) ∨∀xQ(x)
(c) ∀x(P(x) →Q(x)) ≡∀xP(x) →∀xQ(x)
(d) ∃x(P(x) ∧Q(x)) ≡∃xP(x) ∧∃xQ(x)
(e) ∃x(P(x) ∨Q(x)) ≡∃xP(x) ∨∃xQ(x)
(f) ∃x(P(x) →Q(x)) ≡∃xP(x) →∃xQ(x)
(g) ∀xQ(x‚ x) ≡∀x∃yQ(x‚ y)
(h) ∀x∃yQ(x‚ y) ≡∃xQ(x‚ x)
(i) ∃x∀yQ(x‚ y) ≡∃yQ(y‚ y)
(j) ∀x∀yQ(x‚ y) ≡∀x∀yQ(y‚ x)
(k) ∃xP(x) →∀xP(x) ≡∃x¬P(x) →∀x¬P(x)
➍Negate each of the following formulae and import the negations inside all other logical
connectives.
(a) ∀x(x = x2 →x > 0)
(b) ∀x((x = x2 ∧x > 1) →x2 < 1)
(c) ∀x∃y(x > y →x > y2)
(d) ∀x(x = 0 ∨∃y¬(xy = x))
(e) ∀x∃y(¬x = y →x > y)
(f) ∃x∃y(x > y ∨−x > y)
(g) ∃x(P(x) →∀yP(y))
(h) ∀x(P(x) →Q(x)) →(∀xP(x) →∀xQ(x))
(i) (∃xP(x) →∃xQ(x)) →∃x(P(x) →Q(x))
➎Using semantic reasoning, show that the following logical consequences hold.
(a) ∀xA(x) ⊨¬∃x¬A(x)
(b) ¬∃x¬A(x) ⊨∀xA(x)
(c) ∃xA(x) ⊨¬∀x¬A(x)

182
Logic and Discrete Mathematics: A Concise Introduction
(d) ¬∀x¬A(x) ⊨∃xA(x)
(e) ∃x∃yA(x‚ y) ⊨∃y∃xA(x‚ y)
➏Suppose x is not free in Q. Show that the following logical consequences hold by giving
semantic arguments.
(a) ∀x(P(x) ∨Q) ⊨∀xP(x) ∨Q
(b) ∀xP(x) ∨Q ⊨∀x(P(x) ∨Q)
(c) ∃x(P(x) ∧Q) ⊨∃xP(x) ∧Q
(d) ∃xP(x) ∧Q ⊨∃x(P(x) ∧Q)
(e) ∀x(Q →P(x))‚ Q ⊨∀xP(x)
(f) ∃xP(x) →Q ⊨∀x(P(x) →Q)
(g) ∃x(P(x) →Q)‚ ∀xP(x) ⊨Q
(h) ∃x(Q →P(x))‚ Q ⊨∃xP(x)
➐Using semantic reasoning, determine which of the following logical consequences hold. For
those that do not, construct a countermodel, i.e. a structure in which all premises are true,
while the conclusion is false.
(a) ∀xA(x)‚ ∀xB(x) ⊨∀x(A(x) ∧B(x))
(b) ∀x(A(x) ∧B(x)) ⊨∀xA(x) ∧∀xB(x)
(c) ∀xA(x) ∨∀xB(x) ⊨∀x(A(x) ∨B(x))
(d) ∀x(A(x) ∨B(x)) ⊨∀xA(x) ∨∀xB(x)
(e) ∀xA(x) →∀xB(x) ⊨∀x(A(x) →B(x))
(f) ∀x(A(x) →B(x)) ⊨∀xA(x) →∀xB(x)
(g) ∃x(A(x) ∧B(x)) ⊨∃xA(x) ∧∃xB(x)
(h) ∃xA(x)‚ ∃xB(x) ⊨∃x(A(x) ∧B(x))
(i) ∃x(A(x) ∨B(x)) ⊨∃xA(x) ∨∃xB(x)
(j) ∃xA(x) ∨∃xB(x) ⊨∃x(A(x) ∨B(x))
(k) ∃x(A(x) →B(x)) ⊨∃xA(x) →∃xB(x)
(l) ∃xA(x) →∃xB(x) ⊨∃x(A(x) →B(x))
➑Check for each of the following statements whether it logically implies the other, by formal-
izing them in first-order logic and using semantic reasoning.
A: “Not everybody who is a lawyer is greedy.”
B: “There exists a lawyer and not everybody is greedy.”
If either of the logical consequences does not hold, give an appropriate countermodel.

First-Order Logic
183
➒Check for each of the following statements if it logically implies the other, by formalizing
them in first-order logic and using semantic arguments.
A: “No man is happy only when he is drunk.”
B: “There is a happy man and there is a man who is not drunk.”
If either of the logical consequences does not hold, give an appropriate countermodel.
➓Formalize the following arguments in first-order logic (FOL), by introducing suitable pred-
icates. Then, using semantic reasoning, determine which of them is logically correct.
(a) .
All logicians are clever.
All clever people are rich.
All logicians are rich.
(b) .
All natural numbers are integers.
Some integers are odd numbers.
Some natural numbers are odd numbers.
(c) .
All penguins are birds.
Some penguins are white.
Therefore, some white bird is a penguin.
(d) .
No yellow plonks are qlinks.
Some object is a plonk or not a qlink.
Therefore, there is an object that is not a yellow qlink.

184
Logic and Discrete Mathematics: A Concise Introduction
Alfred Tarski, born Alfred Teitelbaum (14.1.1901–26.10.1983)
Alfred Tarski was a Polish-American logician and mathe-
matician, who made seminal contributions to many areas of
mathematics, including set theory, universal algebra, topol-
ogy, geometry, classical and universal algebra and several
branches of mathematical logic, including theories of truth,
logical consequence and definability, algebraic logic, model
theory and metamathematics (proof theory), as well as the
methodology of science.
At the age of 22 Tarski became the youngest student to
be awarded a PhD from the University of Warsaw. It was at that time that he changed his religion
from Jewish to Roman Catholic and his surname from Teitelbaum to Tarski, to reaffirm his Polish
identity, but also to make it possible to get an academic position which, at that time, was almost
impossible for Jews in Poland.
Even though Tarski did not have a university position in Warsaw and taught mostly in high
schools there until 1939, he had already made key contributions to logic and set theory, which
brought him international recognition. In 1933 Tarski published his groundbreaking paper The con-
cept of truth in formalized languages, where he rigorously defined the formal semantics of logical
languages and the notion of truth of a logical formula. In 1936 Tarski published another seminal
work, On the concept of logical consequence, where he precisely defined logical consequence to hold
when the conclusion is true in every model in which all premises are true. Yet another work of fun-
damental importance was A decision method for elementary algebra and geometry, which he essentially
completed around 1930 but only published in the United States in 1948. In it Tarski showed, using
the method of quantifier elimination, that the first-order theory of the real numbers under addition
and multiplication is algorithmically decidable – one of the most important results on decidability
of a mathematical theory. In 1936 he also produced his very popular and influential undergraduate
textbook on logic, Introduction to Logic and to the Methodology of Deductive Sciences.
In 1939, during Tarski’s visit to the United States for a conference, the Nazi army invaded
Poland and started the Second World War, so Tarski could not return to his country and remained
in the United States, where he became a naturalized citizen in 1945. From 1942 Tarski worked as a
lecturer and from 1949 until his retirement as a Professor of Mathematics at the University of Cali-
fornia at Berkeley, where he organized his famous logic seminar and created a very strong research
environment.
Tarski was famous for his extreme productivity and precision, both in his teaching and his sci-
entific writings. He was an energetic and charismatic teacher, whose lectures were meticulously
prepared and presented. He was an inspiring and demanding supervisor of 26 doctoral students,
many of whom became distinguished mathematicians. Tarski was also notorious for his all-night
working sessions with his students in his smoke-filled study in the basement of his home in Berke-
ley. He had a strong and colourful personality: a heavy smoker and drinker, a womanizer, extremely
ambitious and self-righteous, yet very civilized and polite.
With his enormous legacy in scientific works, students, followers and general scientific influ-
ence, Tarski is widely regarded as one of the greatest logicians of all times, along with Aristotle,
Frege and Gödel.

First-Order Logic
185
4.5.
Semantic tableaux for ﬁrst-order logic
Here we extend the system of propositional semantic tableaux to first-order logic by adding
rules for the quantifiers. The resulting deductive system is sound and complete for the valid
logical consequences of first-order logic.
Quantifier rules for semantic tableaux
(∀T)
∀xA(x) ∶T
↓
A[t ⁄ x] ∶T
for any ground term(∗) t
(∃T)
∃xA(x) ∶T
↓
A[c ⁄ x] ∶T
for a new constant symbol c
not yet occurring on this branch(∗∗)
(∃F)
∃xA(x) ∶F
↓
A[t ⁄ x] ∶F
for any ground term(∗) t
(∀F)
∀xA(x) ∶F
↓
A[c ⁄ x] ∶F
for a new constant symbol c
not yet occurring on this branch(∗∗)
(∗) Recall that a ground term is a term with no variables. In order to always enable this rule
we assume that there is at least one constant symbol in the language.
(∗∗) This rule may be applied only once for the given formula on each branch.
The rules are quite natural and their correctness, which will be stated more formally fur-
ther, follows from some semantic properties of quantifiers and logical consequence that we
listed in Section 4.4.6. Still, some discussion is in order. We defer the discussion on the quanti-
fier rules (∀T) and (∃F) to the end of this section. Now, let us explain the proviso (∗∗). It is only
needed to prevent “useless” redundant applications of the rules (∃T) and (∀F). Note that, with-
out that proviso, each of these rules could be applied in principle infinitely many times – once
for every constant symbol in the language that does not occur yet on the current branch. Intu-
itively, however, such applications should be redundant, because we only need one witness of
the truth (respectively of falsity) of the formula assumed to be true in the rule (∃T) (respec-
tively false in (∀F)), if such a witness exists at all. Therefore, we only need to introduce one name
for such a witness in any given branch of the tableau. Thus, if the assumption of the existence
of such a witness can lead to a contradiction and close the branch, then one application of the
rule should suffice; otherwise no repeated applications of the rule can have an effect at all, but
would make it impossible to declare the branch, and the tableau construction, saturated.
The idea of derivation in first-order logic by means of the method of semantic tableaux is
essentially the same as in propositional logic: in order to prove that A1‚ …‚ An ⊨C‚ we search
systematically for a countermodel, i.e. a structure where A1‚ …‚ An and ¬C are satisfied simul-
taneously. Closed and open branches and tableaux are defined as in propositional semantic
tableaux, but with the more refined notion of saturation of a first-order tableau, as discussed
above. A closed tableau with the formulae A1‚ …‚ An‚ ¬C at the root certifies that there cannot

186
Logic and Discrete Mathematics: A Concise Introduction
be such a countermodel; that constitutes a derivation in semantic tableaux of the logical conse-
quence A1‚ …‚ An ⊨C, which will be denoted by A1‚ …‚ An ⊢ST C. On the other hand, a tableau
with an open and saturated branch contains the information needed for the construction of
such a countermodel.
Theorem 4.5.1 The system of semantic tableaux for first-order logic is sound and complete, i.e. for
every first-order formulae A1‚ …‚ An‚ C:
A1‚ …‚ An‚ ⊢ST C
if and only if
A1‚ …‚ An‚ ⊨C.
Unlike propositional logic, where every tableau either closes or saturates and terminates as
open, now a third case is also possible, where the tableau neither closes nor produces an open
and saturated branch. This case will be illustrated in the last example below and termination
will be discussed at the end of the section.
4.5.1.
Some derivations using first-order semantic tableau
Example 4.5.2
Using semantic tableaux, check if ∀x(Q →P(x)) ⊨Q →∀xP(x), where x does not occur free in
Q.
∀x(Q →P(x)) ∶T, Q →∀xP(x) ∶F
↓
∀x(Q →P(x)) ∶T, Q ∶T, ∀xP(x) ∶F
↓
P(c) ∶F
↓
Q →P(c) ∶T
↙
↘
Q ∶F
P(c) ∶T
×
×
The tableau above closes, so ∀x(Q →P(x)) ⊢ST Q →∀xP(x), and hence ∀x(Q →P(x)) ⊨
Q →∀xP(x). Where was the assumption that x is not free in Q used?

First-Order Logic
187
Example 4.5.3
Using semantic tableaux, show that ⊨¬∀x∀y(P(x) ∧¬P(f(y))), where P is a unary predicate
symbol and f is a unary functional symbol.
¬∀x∀y(P(x) ∧¬P(f(y))) ∶F
↓
∀x∀y(P(x) ∧¬P(f(y))) ∶T
↓
∀y(P(f(c)) ∧¬P(f(y))) ∶T
↓
P(f(c)) ∧¬P(f(c)) ∶T
↓
P(f(c)) ∶T, ¬P(f(c)) ∶T
↓
P(f(c)) ∶T, P(f(c)) ∶F
↓
×
The tableau closes, so ⊢ST¬∀x∀y(P(x) ∧¬P(f(y))), and hence ⊨¬∀x∀y(P(x) ∧¬P(f(y))). In
this example we first applied the rule (∀T) in a somewhat artificial way, by introducing a new
constant symbol and guessing the ground term f(c) to substitute for x. Such guessing would
be avoided in the free variable version of the semantic tableaux method, mentioned at the end
of the section.
Example 4.5.4
Using semantic tableaux, check if ∃x(A(x) →B(x))‚ ∃xA(x) ⊨∃xB(x).
∃x(A(x) →B(x)) ∶T, ∃xA(x) ∶T, ∃xB(x) ∶F
↓
A(c1) →B(c1) ∶T
↓
A(c2) ∶T
↓
B(c1) ∶F
↓
B(c2) ∶F
↙
↘
A(c1) ∶F
B(c1) ∶T
○
×

188
Logic and Discrete Mathematics: A Concise Introduction
Note that, due to the proviso (∗), the left-hand branch in this tableau can only be extended
any further by applying the rule ∃F to the signed formula ∃xB(x) ∶F to produce instances
of the type B(c) ∶F for new constant symbols c (as there are no function symbols in the for-
mula), which clearly cannot produce a contradictory pair of formulae, so we can treat such
applications of the rule as redundant. Therefore, the left-hand branch remains open. Thus, the
tableau does not close, so ∃x(A(x) →B(x))‚ ∃xA(x) ⊨∃xB(x) cannot be derived in ST and hence
this consequence is not valid. Indeed, the necessary information for building a countermodel
can be collected from the open branch of the tableau: it must have at least two elements, say
a1 and a2, interpreting respectively c1 and c2, and these should suffice because no other names
of elements are mentioned in the tableau. Then the predicate A must be false for a1 and true
for a2, i.e. its interpretation in the domain {a1‚ a2} is {a2}, while the predicate B must be false
for both a1 and a2, i.e. its interpretation in the domain {a1‚ a2} is ∅. Indeed, it is easy to check
that the resulting model falsifies the logical consequence ∃x(A(x) →B(x))‚ ∃xA(x) ⊨∃xB(x).
Example 4.5.5
Using semantic tableaux, check if ∀x∃yA(x‚ y) ⊨∃xA(x‚ c0).
∀x∃yA(x, y) ∶T, ∃xA(x, c0) ∶F
↓
A(c0, c0) ∶F
↓
∃yA(c0, y) ∶T
↓
A(c0, c1) ∶T
↓
A(c1, c0) ∶F
↓
∃yA(c1, y) ∶T
↓
A(c1, c2) ∶T
↓
A(c2, c0) ∶F
⋮
It should now be evident that this tableau can be extended forever without closing. This
indicates that ∀x∃yA(x‚ y) ⊨∃xA(x‚ c0) cannot be derived in ST and hence this consequence is
not valid. (Indeed, a simple countermodel can be defined in the structure of natural numbers
, where A(x‚ y) is interpreted as x < y and c0 is interpreted as 0.) However, this fact cannot
be formally established at any finite stage of the extension of the tableau. Thus, we see that the
construction of a first-order tableau does not always terminate.

First-Order Logic
189
4.5.2.
Semantic tableaux for first-order logic with equality
The system of Semantic Tableaux presented here did not involve rules for the equality, but
such rules can be added to produce a sound and complete system for first-order logic with
equality.
Semantic tableaux rules for the equality.
(=2 F)
(=1 T)
A[t ⁄ x] ∶T
↓
A[s ⁄x] ∶T
for any terms s, t free for x in A such that
s = t ∶T or t = s ∶T occurs on the branch
A[t ⁄x] ∶F
↓
A[s ⁄x] ∶F
for any terms s, t free for x in A such that
s = t ∶T or t = s ∶T occurs on the branch
In addition, the following condition for closing a branch is added: a branch closes if a
formula t = t ∶F for any term t occurs on it.
Example 4.5.6
Using semantic tableaux with equality, check whether ∀x(P(x) ↔x = c) ⊨P(c) for a constant
symbol c.
Here is the run of the tableau:
∀x(P(x) ↔x = c) ∶T, P(c) ∶F
↓
P(c) ↔c = c) ∶T
↙
↘
P(c) ∶T, c = c ∶T, P(c) ∶F
P(c) ∶F, c = c ∶F, P(c) ∶F
×
×
4.5.3.
Discussion on the quantifier rules and on termination of semantic tableaux
We end this section with some discussion on the quantifier rules (∀T) and (∃F) and on the
termination of the semantic tableaux method for first-order logic.

190
Logic and Discrete Mathematics: A Concise Introduction
1. When the language has at least one constant and one functional symbol there are
infinitely many ground terms that can be instantiated in the rules (∀T) and (∃F). All but
finitely many of these instantiations would be “useless” for the closure of the branch
of the tableau. Therefore, the rules, as they stand, appear to be “wasteful” because of
allowing many “useless” applications. As we saw in some of the examples, this could
lead to unnecessary nontermination, but will not affect the soundness and complete-
ness of the system, stated in Theorem 4.5.1. In automated theorem provers these rules
can be used quite efficiently by employing suitable heuristics and strategies on how to
use them.
2. On the other hand, these rules can be strengthened by allowing instantiation with any
term t that is free for x in A. The resulting rules would still be sound, but even more
“wasteful” in the sense of allowing “useless” applications.
3. The problem of identifying and preventing “useless” applications of the rules (∀T) and
(∃F) is very nontrivial. As we note later, this problem is, in fact, algorithmically unsolv-
able in any sound and complete version of the tableaux method. Intuitively, it may
seem sufficient to only apply these rules for terms that have already appeared on the
branch, if a contradiction is to be reached on that branch. However, such a restriction
would be too strong and can prevent the tableau from closing, e.g. for the unsatisfiable
input formula ∀x∀y(P(x) ∧¬P(f(y))).
4. There is a variation of the quantifiers rules, leading to the so-called free variable tableaux
version of the tableaux method, which defers the term instantiations applied with the
rules (∀T) and (∃F) to a later stage, where it may become clear exactly what instanti-
ations are needed in order to close the branch, if possible. The idea is to modify the
rules (∀T) and (∃F) to instantiate not with ground terms but with new free variables
and also to modify the rules (∀F) and (∃T) to instantiate not with a new constant but
with a term f(v1‚ …‚ vk), where f is a new functional symbol and v1‚ …‚ vk are free vari-
ables on the branch which may have appeared there by applications of the rules (∀T)
and (∃F). The technique behind this modification of the rules is called Skolemization
and will be presented and discussed in Section 4.6.2. In the case when there are no such
free variables, the rules act like the present ones, by instantiating with new constant
symbols.
For example, the guessing in Example 4.5.3 would be avoided in the free variable
tableau version by instantiating x with a new free variable v1, then instantiating y with
another free variable v2 and finally instantiating v1 with f(v2). This is a simple case of
the term unification technique, which we will discuss in detail in Section 4.7.3.
Finally, on termination. We have seen that the system of semantic tableaux presented here
does not always terminate, even in cases where a suitable application of the rules would close

First-Order Logic
191
the tableau. Therefore, the question arises: can the rules of the system be modified so that it
remains sound and complete, but also always terminates? The answer is No! – at least, not if
the rules are to be algorithmically implementable. More precisely, in any sound and complete
system of semantic tableaux it is not possible to determine algorithmically whether the con-
struction of the tableau for any given first-order formula can terminate (as open or closed) or
not. This impossibility is a direct consequence from one of the most profound and important
results in mathematical logic, proved in 1936 by Alonso Church, one of the leading logicians
of the 20th century, viz. the algorithmic undecidability of the validity in first-order logic: there is no
algorithm which can determine whether a given first-order formula is valid.
4.5.4.
Exercises
For each of the following exercises use semantic tableaux.
➊Prove the following logical validities and consequences.
(a) ⊨∀xP(x) →∀yP(y)
(b) ⊨∃xP(x) →∃yP(y)
(c) ∀xA(x) ⊨¬∃x¬A(x)
(d) ¬∃x¬A(x) ⊨∀xA(x)
(e) ∃xA(x) ⊨¬∀x¬A(x)
(f) ¬∀x¬A(x) ⊨∃xA(x)
(g) ⊨∃x∃yQ(x‚ y) →∃y∃xQ(x‚ y)
➋Suppose x is not free in Q. Prove the following logical consequences.
(a) ∀x(P(x) ∨Q) ⊨∀xP(x) ∨Q
(b) ∀xP(x) ∨Q ⊨∀x(P(x) ∨Q)
(c) ∃x(P(x) ∧Q) ⊨∃xP(x) ∧Q
(d) ∃xP(x) ∧Q ⊨∃x(P(x) ∧Q)
(e) ∀x(Q →P(x))‚ Q ⊨∀xP(x)
(f) ∃xP(x) →Q ⊨∀x(P(x) →Q)
(g) ∃x(P(x) →Q)‚ ∀xP(x) ⊨Q
(h) ∃x(Q →P(x))‚ Q ⊨∃xP(x)
➌Check which of the following first-order formulae are logically valid. For each of those
which are not, construct a countermodel, i.e., a structure which falsifies it.
(a) ∃x(P(x) →∀yP(y))
(b) ∀x(P(x) →∃yP(y))
(c) ∀x∃yQ(x‚ y) →∀y∃xQ(x‚ y)

192
Logic and Discrete Mathematics: A Concise Introduction
(d) ∀x∃yQ(x‚ y) →∀y∃xQ(y‚ x)
(e) ∀x∃yQ(x‚ y) →∃y∀xQ(x‚ y)
(f) ∀x∃yQ(x‚ y) →∃xQ(x‚ x)
(g) ∃y∀xQ(x‚ y) →∃xQ(x‚ x)
(h) ∀x(∃yQ(x‚ y) →∃yQ(y‚ x))
(i) ∃x¬∃yP(x‚ y) →∀y¬∀xP(x‚ y)
(j) (∀x∃yP(x‚ y) ∧∀x∀y(P(x‚ y) →P(y‚ x))) →∃xP(x‚ x)
➍Check which of the following logical consequences hold. For those that do not, use the
tableau to construct a countermodel, i.e. a structure and assignment in which all premises
are true, while the conclusion is false.
(a) ∀xA(x)‚ ∀xB(x) ⊨∀x(A(x) ∧B(x))
(b) ∀x(A(x) ∧B(x)) ⊨∀xA(x) ∧∀xB(x)
(c) ∀xA(x) ∨∀xB(x) ⊨∀x(A(x) ∨B(x))
(d) ∀x(A(x) ∨B(x)) ⊨∀xA(x) ∨∀xB(x)
(e) ∀xA(x) →∀xB(x) ⊨∀x(A(x) →B(x))
(f) ∀x(A(x) →B(x)) ⊨∀xA(x) →∀xB(x)
(g) ∀x(A(x) →B(x)) ⊨∃xA(x) →∃xB(x)
(h) ∃x(A(x) ∧B(x)) ⊨∃xA(x) ∧∃xB(x)
(i) ∃xA(x)‚ ∃xB(x) ⊨∃x(A(x) ∧B(x))
(j) ∃x(A(x) ∨B(x)) ⊨∃xA(x) ∨∃xB(x)
(k) ∃xA(x) ∨∃xB(x) ⊨∃x(A(x) ∨B(x))
(l) ∃x(A(x) →B(x)) ⊨∃xA(x) →∃xB(x)
(m) ∃xA(x) →∃xB(x) ⊨∃x(A(x) →B(x))
➎Determine which of the following logical equivalences hold. For each of those that do not
hold, construct a countermodel, i.e. a structure in which one formula is true while the other
false.
(a) ∀x(P(x) ∧Q(x)) ≡∀xP(x) ∧∀xQ(x)
(b) ∀x(P(x) ∨Q(x)) ≡∀xP(x) ∨∀xQ(x)
(c) ∀x(P(x) →Q(x)) ≡∀xP(x) →∀xQ(x)
(d) ∃x(P(x) ∧Q(x)) ≡∃xP(x) ∧∃xQ(x)
(e) ∃x(P(x) ∨Q(x)) ≡∃xP(x) ∨∃xQ(x)
(f) ∃x(P(x) →Q(x)) ≡∃xP(x) →∃xQ(x)

First-Order Logic
193
(g) ∀xQ(x‚ x) ≡∀x∃yQ(x‚ y)
(h) ∀x∃yQ(x‚ y) ≡∃xQ(x‚ x)
(i) ∃x∀yQ(x‚ y) ≡∃yQ(y‚ y)
(j) ∀x∀yQ(x‚ y) ≡∀x∀yQ(y‚ x)
(k) ∃xP(x) →∀xP(x) ≡∃x¬P(x) →∀x¬P(x)
➏In each of the following cases, formalize both statements in first-order logic and check
which, if any, logically implies the other. If any of the logical consequences does not hold,
construct an appropriate countermodel.
(a) A: “Not every lawyer is greedy.”
B: “There exists a lawyer and not everybody is greedy.”
(b) A: “Some men are happy only when they are drunk.”
B: “There is a drunk man or there is a man who is not happy.”
(c) A: “If somebody is talking then everybody is listening.”
B: “There is somebody, such that if he is not listening then nobody is talking.”
➐Formalize the following arguments in FOL, by introducing suitable predicates. Then check
for each of them whether it is logically valid. If not valid, use the tableau to construct a
countermodel.
(a) .
All logicians are clever.
All clever people are rich.
All logicians are rich.
(b) .
All natural numbers are integers.
Some integers are odd numbers.
Some natural numbers are odd numbers.
(c) .
No driver is a pedestrian.
Every child is a pedestrian.
Johnnie is a child.
Therefore somebody is not a driver.
(d) .
All penguins are birds.
Some penguins are white.
No white bird eats butterﬂies.
Therefore, not all penguins eat butterﬂies.

194
Logic and Discrete Mathematics: A Concise Introduction
(e) .
Everybody likes some black gmuck.
Nobody likes any white gmuck.
Therefore no gmuck is black and white.
(f) .
Some bachelors love every woman they know.
Every bachelor is a man.
Eve is a woman whom every man knows.
Some bachelor loves a woman.
(g) . Replace the conclusion in the previous example by
“Every bachelor loves a woman.”
and check again whether the resulting argument is logically valid.
Kurt Friedrich Gödel (28.4.1906–14.1.1978)
Kurt Gödel was an Austrian–American logician, mathematician and
philosopher, regarded as the most influential logician of the 20th cen-
tury.
Gödel’s first interest in logic was sparked when he attended a sem-
inar on Russell’s book Introduction to Mathematical Philosophy. Later, he
attended a lecture by David Hilbert on the completeness and consis-
tency of mathematical systems, where Hilbert posed the question of
whether there is a consistent formal system of axioms of first-order
logic that can derive every valid – that is, true in all models – statement
of first-order logic. Gödel chose this problem as the topic of his doctoral
work and he completed his doctoral dissertation under the supervision
of Hans Hahn in 1929, at the age of 23. In his thesis he proposed an
axiomatic system for the first-order predicate logic and established its
completeness. This was his first famous result, known as Gödel’s com-
pleteness theorem.
In 1931 Gödel published his most important and groundbreaking work, On Formally Undecid-
able Propositions of “Principia Mathematica” and Related Systems, where he proved his famous incom-
pleteness theorems. The first incompleteness theorem states that any axiomatic system of first-order
logic that is consistent (that is, no contradiction can be derived in it) and has an effectively rec-
ognizable (recursive) set of axioms and is expressive enough to describe the arithmetic of the nat-
ural numbers with addition and multiplication must be incomplete; i.e. there are true arithmeti-
cal statements that can be stated in the language of that system but cannot be derived from its
axioms. In particular, this result applies to Peano’s system of axioms for arithmetic (see Section 4.2)
and to the Zermelo–Fraenkel set theory with the Axiom of choice (ZFC). The second incompleteness
theorem states that, in particular, no such consistent system can derive a statement (formalized in
the language of arithmetic) claiming its own consistency. Gödel’s basic idea for the proof of the

First-Order Logic
195
incompleteness theorems was conceptually simple but extremely original: for any given formal
axiomatic system of arithmetic with an effectively enumerable set of axioms he used a specially
developed technique to encode, in the language of the arithmetic itself, the notions of formulae,
axioms and derivations, and eventually constructed a formula of that language that claims, via the
encoding, that it is unprovable in the given formal system. Such a formula cannot be provable in
the system, for this would imply its inconsistency, and therefore what it states must be true.
Gödel’s incompleteness theorems had a shattering effect on the attempts to find an effectively
enumerable set of axioms sufficient to derive all true statements in mathematics, beginning with the
work of Frege half a century earlier and culminating in Principia Mathematica and Hilbert’s program
for the formalization of the mathematics (see the box at the end of Section 3.3 in Chapter 3).
Gödel’s theorems have also had a profound effect on mathematical logic and the foundations
and philosophy of mathematics. They are one of the greatest achievements of 20th century mathe-
matics, of fundamental importance not only for the foundations of mathematics but also for com-
puter science, as they imply that a computer can never be programmed to derive all true mathe-
matical statements, not even all those about the arithmetic of natural numbers.
4.6.
Prenex and clausal normal forms
4.6.1.
Prenex normal forms
Definition 4.6.1 Here we extend some technical concepts from propositional to first-order logic:
• A first-order literal is an atomic formula or a negation of an atomic formula.
• A first-order elementary conjunction/disjunction is a first-order literal or a conjunc-
tion/disjunction of (two or more) first-order literals.
• A first-order disjunctive normal form (DNF) is a first-order elementary conjunction or a disjunc-
tion of (two or more) first-order elementary conjunctions.
• Respectively, a first-order conjunctive normal form (CNF) is a first-order elementary disjunction
or a conjunction of (two or more) first-order elementary disjunctions.
Definition 4.6.2 A first-order formula Q1x1 · · · QnxnA‚ where Q1‚ …‚ Qn are quantifiers and A is an
open formula, is said to be in a prenex form. The quantifier string Q1x1 · · · Qnxn is called the prefix
and the formula A is called the matrix of the prenex form.
If A is a first-order DNF (respectively CNF) then Q1x1 · · · QnxnA is in a prenex disjunctive
normal form (respectively a prenex conjunctive normal form).

196
Logic and Discrete Mathematics: A Concise Introduction
Example 4.6.3
1. The formula ∀x∃y(¬x > 𝟎∨(y > 𝟎∧¬x = y2)) is in a prenex DNF, but not a prenex CNF.
2. ∀x∃y(x > 𝟎→(y > 𝟎∧x = y2)) is in a prenex form but neither in DNF nor in CNF.
3. The formula ∀x(x > 𝟎→∃y(y > 𝟎∧x = y2)) is not in a prenex form.
Theorem 4.6.4 Every first-order formula is equivalent to a formula in a prenex disjunctive normal
form (PDNF) and to a formula in a prenex conjunctive normal form (PCNF).
Proof: Here is an algorithm for construction of these normal forms. Given any formula A:
1. Eliminate all occurrences of →and ↔as in the propositional case.
2. Import all negations inside all other logical connectives, i.e. in front of atomic formulae.
3. Use the equivalences (Section 4.4.4):
(a) ∀xP ∧∀xQ ≡∀x(P ∧Q)‚
(b) ∃xP ∨∃xQ ≡∃x(P ∨Q)‚
to pull some quantifiers outwards and, after renaming the formula wherever neces-
sary, use also the following equivalences from Section 4.4.4, where x does not occur
free in Q:
(c) ∀xP ∧Q ≡Q ∧∀xP ≡∀x(P ∧Q)‚
(d) ∀xP ∨Q ≡Q ∨∀xP ≡∀x(P ∨Q)‚
(e) ∃xP ∨Q ≡Q ∨∃xP ≡∃x(P ∨Q)‚
(f) ∃xP ∧Q ≡Q ∧∃xP ≡∃x(P ∧Q),
to pull all quantifiers in front and thus transform the formula into a prenex form.
4. Finally, transform the matrix in a DNF or CNF just like a propositional formula.
A simplified, but more inefficient procedure for getting the quantifiers out first transforms
the formula into an equivalent clean one by suitable renaming of bound variables. Then it pulls
out all quantifiers, by maintaining the order, tacitly using the last four equivalences above. This
procedure often introduces unnecessary new variables, which makes the result not optimal for
the Skolemization step of the procedure, described in Section 4.6.2.

First-Order Logic
197
Example 4.6.5
Let A = ∃z(∃xQ(x‚ z) ∨∃xP(x)) →¬(¬∃xP(x) ∧∀x∃zQ(z‚ x)).
1. Eliminating →∶A ≡¬∃z(∃xQ(x‚ z) ∨∃xP(x)) ∨¬(¬∃xP(x) ∧∀x∃zQ(z‚ x)).
2. Importing the negation:
A ≡∀z(¬∃xQ(x‚ z) ∧¬∃xP(x)) ∨(¬¬∃xP(x) ∨¬∀x∃zQ(z‚ x)) ≡∀z(∀x¬Q(x‚ z) ∧∀x¬P(x)) ∨
(∃xP(x) ∨∃x∀z¬Q(z‚ x)).
3. Using the equivalences (a) and (b): A ≡∀z∀x(¬Q(x‚ z) ∧¬P(x)) ∨∃x(P(x) ∨∀z¬Q(z‚ x)).
4. Renaming: A ≡∀z∀x(¬Q(x‚ z) ∧¬P(x)) ∨∃y(P(y) ∨∀w¬Q(w‚ y)).
5. Using the equivalences (c) to (f) and pulling the quantifiers in front:
A ≡∀z∀x∃y∀w((¬Q(x‚ z) ∧¬P(x)) ∨P(y) ∨¬Q(w‚ y)).
6. The resulting formula is in a prenex DNF. For a prenex CNF we need to distribute the ∨
over ∧: A ≡∀z∀x∃y∀w((¬Q(x‚ z) ∨P(y) ∨¬Q(w‚ y)) ∧(¬P(x) ∨P(y) ∨¬Q(w‚ y))).
We could have renamed the formula A into a clean formula right from the beginning. That,
however, would have made the resulting prenex formula much larger.
4.6.2.
Skolemization
Skolemization is a procedure (first applied by the Norwegian logician Thoralf Skolem) for
systematic elimination of the existential quantifiers in a first-order formula in a prenex form by
way of uniform replacement of all occurrences of existentially quantified individual variables
with terms, headed by new functional symbols called Skolem functions.
In the traditional version of Skolemization these Skolem functions take as arguments all
variables (if any) that are bound by universal quantifiers in the scope of which the given exis-
tential quantifier sits. In particular, existentially quantified variables that are not in the scope of
any universal quantifiers are replaced by constant symbols. We will explain the Skolemization
procedure by some examples.
Example 4.6.6
1. The result of Skolemization of the formula
∃x∀y∀z(P(x‚ y) →Q(x‚ z))
is ∀y∀z(P(c‚ y) →Q(c‚ z)), where c is a new constant, called a Skolem constant.
2. More generally, the result of Skolemizing the formula
∃x1 · · · ∃xk∀y1 · · · ∀ynA(x1‚ …‚ xk‚ y1‚ …‚ yn)
is ∀y1 · · · ∀ynA(c1‚ …‚ ck‚ y1‚ …‚ yn), where c1‚ …‚ ck are new Skolem constants.
3. The result of Skolemization of the formula
∃x∀y∃z(P(x‚ y) →Q(x‚ z))

198
Logic and Discrete Mathematics: A Concise Introduction
is ∀y(P(c‚ y) →Q(c‚ f(y))), where c is a new Skolem constant and f is a new unary function,
called a Skolem function.
4. More generally, the result of Skolemizing the formula
∀y∃x1 · · · ∃xk∀y1 · · · ∀ynA(y‚ x1‚ …‚ xk‚ y1‚ …‚ yn)
is ∀y∀y1 · · · ∀ynA(y‚ f1(y)‚ …‚ fk(y)‚ y1‚ …‚ yn), where f1‚ …‚ fk are new Skolem functions.
5. The result of Skolemization of the formula
∀x∃y∀z∃uA(x‚ y‚ z‚ u)
is the formula ∀x∀zA(x‚ f(x)‚ z‚ g(x‚ z)), where f is a new unary Skolem function and g is a
new binary Skolem function.
Note. The result of Skolemization of any first-order formula A is a formula that is gener-
ally not logically equivalent to A, but is equally satisfiable with A.13 Therefore, for the purpose
of the theorem proving based on checking (un)satisfiability, Skolemization is an admissible
procedure.
4.6.3.
Clausal forms
Recall that a literal is an atomic formula or a negation of an atomic formula and a clause is a
set of literals (representing their disjunction).
Example:
{P(x)‚ ¬P(f(c‚ g(y)))‚ ¬Q(g(x)‚ y)‚ Q(f(x‚ g(c))‚ g(g(g(y))))}.
Note that all variables in a clause are implicitly assumed to be universally quantified.
A clausal form is a set of clauses (representing their conjunction). For example:
{
{P(x)}‚
{¬P(f(c))‚ ¬Q(g(x‚ x)‚ y)}‚
{¬P(f(y))‚ P(f(c))‚ Q(y‚ f(x))}
}.
Theorem 4.6.7 Every first-order formula A can be transformed to a clausal form {C1‚ …‚ Ck} such
that A is equally satisfiable with the universal closure (C1 ∧· · · ∧Ck) of the conjunction of all clauses
considered as disjunctions.
Here is an algorithm transforming a formula into clausal form:
1. Transform A into a prenex CNF.
2. Skolemize all existential quantifiers.
3. Remove all universal quantifiers.
4. Write the matrix (which is in CNF) as a set of clauses.
13 Assuming the Axiom of choice.

First-Order Logic
199
Example 4.6.8
Consider the formula
A = ∃z(∃xQ(x‚ z) ∨∃xP(x)) →¬(¬∃xP(x) ∧∀x∃zQ(z‚ x))
from Example 4.6.5.
1. Transforming A into a prenex CNF:
A ≡∀z∀x∃y∀w((¬Q(x‚ z) ∨P(y) ∨¬Q(w‚ y)) ∧(¬P(x) ∨P(y) ∨¬Q(w‚ y))).
2. Skolemizing all existential quantifiers:
Skolem(A) = ∀z∀x∀w((¬Q(x‚ z) ∨P(f(z‚ x)) ∨¬Q(w‚ f(z‚ x))) ∧(¬P(x) ∨P(f(z‚ x))
∨¬Q(w‚ f(z‚ x)))).
3. Removing all universal quantifiers and writing the matrix as a set of clauses:
clausal(A) = {¬Q(x‚ z)‚ P(f(z‚ x))‚ ¬Q(w‚ f(z‚ x))}‚ {¬P(x)‚ P(f(z‚ x))‚ ¬Q(w‚ f(z‚ x))}.
4.6.4.
Exercises
➊Transform each of the following formulae into a prenex DNF and a prenex CNF. Then
Skolemize the resulting formula and transform it into clausal form.
(a) ∀x((∃yP(y) ∧∀zQ(z‚ x)) →∃yQ(x‚ y))
(b) ∃z(∃xQ(x‚ z) →(∃xP(x) ∨¬∃zP(z)))
(c) ∀y¬(P(y) ↔∃xQ(y‚ x))
(d) ∀z(∃yP(y) ↔Q(z‚ y))
(e) (∃xP(x) →¬∃xQ(x)) →∀x(P(x) →¬Q(x))
(f) ∀x(¬∀yQ(x‚ y) ∧P(z)) →∃z(∀yQ(z‚ y) ∧¬P(x))
(g) ¬∃x(∀y(∃zQ(y‚ z) ↔P(z)) ∧∀zR(x‚ y‚ z))
(h) ¬(∀y(∀zQ(y‚ z) →P(z)) →∃z(P(z) ∧∀x(Q(z‚ y) →Q(x‚ z))))
(i) ¬(¬∃z(P(z) ∧∀x(Q(z‚ y) →Q(x‚ z))) →¬∀y(∀zQ(y‚ z) →P(z)))
(j) ¬(∀y(¬∃zQ(y‚ z) →P(z)) →∃z((P(z) →Q(z‚ y)) ∧¬∃xR(x‚ y‚ z)))

200
Logic and Discrete Mathematics: A Concise Introduction
Thoralf Albert Skolem (23.5.1887–23.3.1963)
Thoralf Skolem was a Norwegian mathematician and logician who made
seminal contributions to mathematical logic, set theory and algebra.
Skolem was extremely productive and published around 180 papers
on Diophantine equations, mathematical logic, group theory, lattice the-
ory and set theory. However, many of his results were not widely known
and were later rediscovered by others, because they were published in not
widely accessible Norwegian journals.
In 1922 Skolem refined and made precise Zermelo’s axioms for set
theory, essentially in the form in which they are known today. In 1923
he created a formal theory of primitive recursive arithmetic meant to avoid the paradoxes of the
infinite and formally developed a great deal of number theory in it. His system can now be regarded
as a programming language for defining functions on natural numbers, and thus he made an early
contribution to computer science. His other work which later became very important in computer
science and instrumental in resolution-based automated theorem proving was on what later became
known as Skolemization and Skolem normal form.
In 1930 Skolem proved that the subsystem of Peano arithmetic (see Section 4.2) involving only
axioms for multiplication but not addition, now called Skolem arithmetic in his honour, was complete
and decidable, unlike the full system of Peano arithmetic (including both addition and multiplica-
tion), proved to be incomplete by Gödel in 1931 (see Section 4.5) and undecidable by Church in
1936 (see Section 4.7).
The completeness of first-order logic, first published by Gödel in 1930, follows from results that
Skolem obtained in the early 1920s and published in 1928, but he was apparently not aware of that
fact at the time, because the problem of proving completeness of an axiomatic system for first-order
logic was only stated explicitly in 1928, in the first edition of Hilbert and Ackermann’s Principles of
Mathematical Logic.
The most influential and widely recognized work of Skolem was his pioneering research in
model theory – the study of applications of logic to mathematics. His most well-known result is the
Löwenheim – Skolem theorem, an extension of an earlier work by Löwenheim, published in 1920. It
states that if a first-order theory, i.e. a set of sentences of first-order logic, has a model – a structure
that satisfies them all – then it has a countable model. This theorem has some consequences that
sound paradoxical, thus giving rise to what became known as “Skolem’s paradox”: assuming that
the axiomatic system ZFC of set theory is satisfied in some model then it must have one with a
countable universe, despite the fact that it can prove the existence of uncountable sets. Likewise,
the first-order theory of the field of reals, which is uncountable, also has a countable model. On the
other hand, Skolem also showed that if a first-order theory has an infinite model then it has models
of arbitrarily large infinite cardinalities. In particular, the system of Peano arithmetic, as well as
the first-order theory of all true sentences of the arithmetic of natural numbers, have uncountable
models. Thus, Skolem provided some of the first constructions of nonstandard models of arithmetic
and set theory.

First-Order Logic
201
4.7.
Resolution in ﬁrst-order logic
4.7.1.
Propositional resolution rule in first-order logic
The propositional resolution rule, extended to first-order logic reads:
C ∨Q(s1‚ …‚ sn)‚
D ∨¬Q(s1‚ …‚ sn)
C ∨D
.
This rule, however, is not strong enough. For example, the clause set {{P(x)}‚ {¬P(f(y))}} is
not satisfiable, as it corresponds to the unsatisfiable formula ∀x∀y(P(x) ∧¬P(f(y))). However,
the resolution rule above cannot produce an empty clause, because it cannot unify the two
clauses in order to resolve them. Therefore, we need a stronger derivation mechanism that
can handle cases like this. There are two natural solutions:
1. Ground resolution.14 Generate sufficiently many ground instances of every clause (in the
so-called Herbrand universe of the language) and then apply the standard resolution
rule above.
In the example, ground resolution would generate the ground clauses {P(f(c))} and
{¬P(f(c))} for some constant symbol c.
This method is sound and complete but inefficient, as it leads to the generation of too
many unnecessary clauses. It will not be discussed further.
2. Resolution with unification. Introduce a stronger resolution rule, which first tries to
match a pair of clauses by applying a suitable substitution that would enable resolving
that pair.
We will present this method in detail.
4.7.2.
Substitutions of terms for variables revisited
Recall that substitution of a term t for a variable x in a term s, denoted by s[t∕x], is the result
of simultaneous replacements of all occurrences of x in s by t. For instance:
f(g(x)‚ f(y‚ x))[g(a)∕x] = f(g(g(a))‚ f(y‚ g(a))).
This can generalize to simultaneous substitutions of several terms for different variables,
denoted s[t1∕x1‚ …‚ tk∕xk]. For instance:
f(g(x)‚ f(y‚ x))[g(y)∕x‚ f(x‚ b)∕y] = f(g(g(y))‚ f(f(x‚ b)‚ g(y))).
Note that the condition of simultaneity is important: if we first substituted g(y) for x and
then f(x‚ b) for y the result would have been different (and wrong).
One can apply a substitution to several terms simultaneously, e.g. when a substitution acts
on an atomic formula P(t1‚ …‚ tn). For instance:
P(x‚ f(x‚ y)‚ g(y))[g(y)∕x‚ a∕y] = P(g(y)‚ f(g(y)‚ a)‚ g(a)).
Given the substitution 𝜎= [t1∕x1‚ …‚ tk∕xk], the set of variables {x1‚ …‚ xk} is called the
domain of 𝜎, denoted dom(𝜎).
14 Introduced by John Alan Robinson in: A Machine-Oriented Logic Based on the Resolution Principle, JACM,
1965.

202
Logic and Discrete Mathematics: A Concise Introduction
Substitutions can be composed by consecutive application: the composition of substitutions
𝜏and 𝜎is a substitution 𝜏𝜎obtained by applying 𝜏followed by applying 𝜎to the result, i.e.
t𝜏𝜎= (t𝜏)𝜎(note the order). For instance:
f(g(x)‚ f(y‚ x))[f(x‚ y)∕x][g(a)∕x‚ x∕y]
= f(g(f(x‚ y))‚ f(y‚ f(x‚ y)))[g(a)∕x‚ x∕y]
= f(g(f(g(a)‚ x))‚ f(x‚ f(g(a)‚ x))).
The composition of two substitutions 𝜏= [t1∕x1‚ …‚ tk∕xk] and 𝜎can be computed as fol-
lows:
1. Extend dom(𝜏) to cover dom(𝜎) by adding to 𝜏substitutions [x∕x] for every variable x
in dom(𝜎)\dom(𝜏).
2. Apply the substitution 𝜎simultaneously to all terms [t1‚ …‚ tk] to obtain the substitu-
tion [t1𝜎∕x1‚ …‚ tk𝜎∕xk].
3. Remove from the result all cases xi∕xi, if any.
For instance:
[f(x‚ y)∕x‚ x∕y][y∕x‚ a∕y‚ g(y)∕z] = [f(y‚ a)∕x‚ y∕y‚ g(y)∕z] = [f(y‚ a)∕x‚ g(y)∕z].
4.7.3.
Unification of terms
A substitution 𝜎unifies two words s and s′ if 𝜎(s) = 𝜎(s′). A substitution 𝜎that uni-
fies the respective arguments of the literals Q(s1‚ …‚ sn) and Q(t1‚ …‚ tn), i.e. such that
𝜎(s1) = 𝜎(t1)‚ …‚ 𝜎(sn) = 𝜎(tn), is called a unifier of Q(s1‚ …‚ sn) and Q(t1‚ …‚ tn). For instance,
the substitution 𝜎= [f(c)∕x‚ c∕y‚ c∕z] unifies the literals Q(x‚ c‚ f(f(z))) and Q(f(y)‚ z‚ f(x)).
Two terms are unifiable if they have a unifier; otherwise they are nonunifiable.
A unifier 𝜏of two terms (or literals) is more general than a unifier 𝜌if there is a substitution
𝜎such that 𝜌= 𝜏𝜎. For instance, 𝜌= [c∕x‚ f(c)∕y] is a unifier of the literals P(f(x)) and P(y), but
𝜏= [f(x)∕y] is a more general unifier because 𝜌= 𝜏𝜎, where 𝜎= [c∕x].
A unifier of two terms (or literals) is their most general unifier (MGU) if it is more general
than any unifier of these terms (literals).
A most general unifier (if it exists) need not be unique. For instance, in the example above,
𝜏is a most general unifier, as is [z∕x‚ f(z)∕y] for any variable z.
Eventually, we are interested in unifying literals, i.e. (negated) atomic formulae. Note that
two atomic formulae P(t1‚ …‚ tm) and Q(s1‚ …‚ sn) cannot be unified unless P = Q and respec-
tively m = n. If that is the case, in order to unify the formulae we need to unify the respective
pairs of arguments, i.e. we are looking for a (most general) unifier of the system
t1 = s1
⋮
tn = sn.
Informally, we do that by computing a most general unifier (if one exists) of the first pair,
then applying it to both lists of terms, then computing a most general unifier of the next pair
(if there is one) in the resulting lists, applying it to both resulting lists of terms, etc. In order to

First-Order Logic
203
unify the current pair of terms we apply the algorithm recursively to the pair of lists of their
respective arguments. The composition of all most general unifiers computed as above, if they
all exist, is a most general unifier of the two input lists.
Here is a pseudocode of a simple recursive algorithm for computing a most general unifier
of two lists of terms p and q, presented below. (The predicate ‘variable(t)’ is true if the term t
is a variable.)
procedure mgu(p, q)
𝜃:= 𝜀
(the empty substitution).
Scan p and q simultaneously, left-to-right,
and search for the first corresponding subterms
where p and q disagree (mismatch).
If there is no mismatch, return 𝜃.
Else, let s and t be the first respective subterms
in p and q where mismatch occurs.
If variable(s) and s ∉Var(t) then
𝜃:= compose(𝜃,[t/s]);
𝜃:= compose(𝜃, mgu(p𝜃,q𝜃)).
Else, if variable(t) and t ∉Var(s) then
𝜃:= compose(𝜃,[s/t]);
𝜃:= compose(𝜃, mgu(p𝜃,q𝜃)).
Else, return failure.
end
Example 4.7.1
Some examples of unification of atomic formulae using the algorithm above are:
• Literal 1: parents(x, father(x), mother(Bill)),
Literal 2: parents(Bill, father(Bill), y),
Most general unifier: [Bill/x, mother(Bill)/y].
• Literal 1: parents(x, father(x), mother(Bill)),
Literal 2: parents(Bill, father(y), z),
Most general unifier: [Bill/x, Bill/y, mother(Bill)/z].
• Literal 1: parents(x, father(x), mother(Jane)),
Literal 2: parents(Bill, father(y), mother(y)).
The algorithm fails; therefore, a unifier does not exist.
• Term 1: g(x,f(x)),
Term 2: g(f(y),y).
The procedure mgu starts computing: [f(y)/x,…failure].
MGU does not exist. Indeed, any unifier would have to unify f(f(x)) with x, which is impos-
sible.

204
Logic and Discrete Mathematics: A Concise Introduction
4.7.4.
Resolution with unification in first-order logic
The first-order resolution rule is combined with a preceding unification of the clausal set in
order to produce a complementary pair of literals in the resolving clauses:
Res ∶
C ∨Q(s1‚ …‚ sn)‚
D ∨¬Q(t1‚ …‚ tn)
𝜎(C ∨D)
where:
(i) The two clauses have no variables in common (achieved by renaming of variables),
(ii) 𝜎is a most general unifier of the literals Q(s1‚ …‚ sn) and Q(t1‚ …‚ tn).
Note: we require that the unifier applied in the rule is a most general unifier of the respec-
tive literals in order not to weaken the resolvent unnecessarily.
Some examples of resolution with unification are:
{P(x)}‚ {¬P(f(y))}
{}
(MGU ∶[f(y)∕x])‚
{P(a‚ y)‚ Q(y)}{¬P(x‚ b)‚ ¬Q(x)}
{Q(b)‚ ¬Q(a)}
(MGU ∶[a∕x‚ b∕y])‚
{P(a‚ y)‚ Q(y)}{¬P(x‚ f(x))‚ Q(f(x))}
{Q(f(a))}
(MGU ∶[a∕x‚ f(a)∕y]).
Note that both literals in the resolvent become equal.
{P(a‚ y)‚ P(x‚ f(x))}{¬P(x‚ f(a))}
{}
(MGU ∶[a∕x‚ f(a)∕y]).
Note that, after unification, both literals in the first clause become P(a‚ f(a)).
Definition 4.7.2 A resolution-based derivation of a formula C from a list of formulae A1‚ …‚ An,
denoted A1‚ …‚ An‚ ⊢ResC, is a derivation of the empty clause {} from the set of clauses obtained from
A1‚ …‚ An‚ ¬C, by successive applications of the rule Res.
Theorem 4.7.3 The method of first-order resolution is sound and complete, i.e. for any first-order
formulae A1‚ …‚ An‚ C:
A1‚ …‚ An‚ ⊢ResC if and only if A1‚ …‚ An‚ ⊨C.
Unlike propositional resolution, first-order resolution may run forever, i.e. never terminate,
in some cases when the conclusion does not follow logically from the premises.
It may also run forever even when the conclusion does follow logically from the premises,
if an unbounded number of unnecessary resolvents is produced.
To avoid that, special strategies or additional mechanisms for disposal of used-up clauses
need to be applied.

First-Order Logic
205
4.7.5.
Examples of resolution-based derivations
Example 4.7.4
Prove with the method of first-order resolution that
∀x(P(x) →Q(x)) ⊨∀xP(x) →∀xQ(x).
1. Transform
{∀x(P(x) →Q(x))‚ ¬(∀xP(x) →∀xQ(x))}
to clausal form:
{¬P(x)‚ Q(x)}‚
{P(y)}‚
{¬Q(c)}
for some Skolem constant c.
2. Successive applications of Res:
(a) Unify P(x) and P(y) with MGU [y∕x].
Then resolve {¬P(x)‚ Q(x)} and {P(y)} to obtain {Q(y)}.
(b) Unify Q(c) and Q(y) with MGU [c∕y].
Then resolve {¬Q(c)} and {Q(y)} to obtain {}.
Example 4.7.5
Show that if
Everybody loves somebody and
Everybody loves any lover then
Everybody loves everybody.
1. Formalize the assumptions and the goal conclusion, using the predicate L(x‚ y) meaning
“x loves y”:
Everybody loves somebody: ∀x∃yL(x‚ y).
Everybody loves any lover: ∀x(∃yL(x‚ y) →∀zL(z‚ x)).
Everybody loves everybody: ∀x∀yL(x‚ y).
2. Transform the set
{∀x∃yL(x‚ y)‚ ∀x(∃yL(x‚ y) →∀zL(z‚ x))‚ ¬(∀x∀yL(x‚ y))}
to a clausal form:
{L(x‚ f(x))}‚ {¬L(x1‚ y)‚ L(z‚ x1)}‚ {¬L(a‚ b)}
for some Skolem constants a‚ b and a Skolem function f.

206
Logic and Discrete Mathematics: A Concise Introduction
3. Successive applications of Res:
(a) Unify L(z‚ x1) and L(a‚ b) with MGU [b∕x1‚ a∕z] and resolve {¬L(x1‚ y)‚ L(z‚ x1)} and
{¬L(a‚ b)} to obtain {¬L(b‚ y)}.
(b) Unify L(x‚ f(x)) and L(b‚ y) with MGU [b∕x‚ f(b)∕y] and resolve {L(x‚ f(x))} and
{¬L(b‚ y)} to obtain {}.
Example 4.7.6
Check if
∀x∃yR(x‚ y)‚ ∀x∀y∀z((R(x‚ y) ∧R(y‚ z)) →R(x‚ z)) ⊨∃xR(x‚ x).
1. Transform
{∀x∃yR(x‚ y)‚ ∀x∀y∀z((R(x‚ y) ∧R(y‚ z)) →R(x‚ z))‚ ¬(∃xR(x‚ x))}
to a clausal form:
C1 = {R(x‚ f(x))}‚ C2 = {¬R(u‚ y)‚ ¬R(y‚ z)‚ R(u‚ z)}‚ C3 = {¬R(v‚ v)}
for some unary Skolem function f.
2. Successive applications of Res to the clausal set give
C1 = {R(x‚ f(x))}‚ C2 = {¬R(u‚ y)‚ ¬R(y‚ z)‚ R(u‚ z)}‚ C3 = {¬R(v‚ v)}.
(Wherever necessary, we rename variables in the derived clauses to keep all clauses with
disjoint sets of variables.)
(a) Unify R(u‚ z) in C2 and C3, with MGU [v∕u‚ v∕z] and resolve:
C4 = {¬R(v‚ y)‚ ¬R(y‚ v)}.
(b) Unify R(v‚ y) in C4 and R(x‚ f(x)) in C1 with MGU [x∕v‚ f(x)∕y] and resolve:
C5 = {¬R(f(x)‚ x)}.
After renaming x: C5 = {¬R(f(x1)‚ x1)}.
(c) Unify R(u‚ z) in C2 and R(f(x1)‚ x1) in C5 with MGU [f(x)∕u‚ x∕z] and resolve:
C6 = {¬R(f(x)‚ y)‚ ¬R(y‚ x)}.
After renaming: C6 = {¬R(f(x′)‚ y′)‚ ¬R(y′‚ x′)}.
(d) Unify R(f(x′)‚ y′) in C6 and R(x‚ f(x)) in C1 with MGU [f(x′)∕x‚ f(f(x′))∕y′] and resolve:
C7 = {¬R(f(f(x′))‚ f(x′))}. After renaming, C7 = {¬R(f(f(x2))‚ f(x2))}, etc.
Thus, an infinite set of clauses can be generated:
{¬R(f(x1)‚ x1)}‚ {¬R(f(f(x2))‚ f(x2))}‚ {¬R(f(f(f(x3)))‚ f(f(x3)))}‚ …
but the empty clause cannot be derived.
In fact, the logical consequence does not hold. A countermodel is the set of natural num-
bers with R(x‚ y) interpreted as x < y.

First-Order Logic
207
4.7.6.
Resolution for first-order logic with equality
The method of resolution presented here does not involve rules for the equality. Such rules can
be added to produce a sound and complete system for first-order logic with equality. The most
common additional rule sufficient for that equational reasoning is called paramodulation:
Par ∶
C ∨s1 = s2‚
D ∨Q(t‚ t1‚ …‚ tn)
(C ∨D ∨Q(s2‚ t1‚ …‚ tn))𝜎
(𝜎= MGU(s1‚ t)).
4.7.7.
Optimizations of the resolution method for first-order logic
Just like propositional resolution, the method of resolution for first-order logic is amenable to
various optimizations by means of special additional rules and derivation strategies that go
beyond the scope of this book. Such optimizations are much more important for first-order
Resolution because if the search for a derivation of the empty clause is not cleverly organized
it may not terminate, even if such a derivation exists. The techniques of deletion of repeating
literals, tautology deletion, subsumption deletion and removal of clauses with monopolar literals still
apply to first-order resolution. Moreover, they can be combined with each other and with
suitable unification pre-processing, e.g. to produce more specific techniques, such as factoring:
{…P(s)‚ P(t)…}
{…P(s)…}𝜎
(𝜎= MGU(s‚ t)).
For example:
{P(x)‚ P(c)‚ ¬Q(x‚ y)}
{P(c)‚ ¬Q(c‚ y)}
(MGU ∶[c∕x]).
Exercise 4.7.7 Prove that factoring is a logically sound rule.
In addition, widely used additional optimizing techniques are clause ordering, indexing
techniques, etc., as well as strategies for application of the resolution rule, such as unit reso-
lution, set-of-support resolution, hyper-resolution, linear resolution, etc. A special version of the
latter strategy, called selective linear definite clause resolution, or just selective linear definite (SLD)
clause resolution, is the derivation strategy of the logic programming language PROLOG.
4.7.8.
Exercises
For each of the following exercises use first-order resolution with unification.
➊Prove the following logical validities and consequences.
(a) ⊨∀xP(x) →∀yP(y)
(b) ⊨∃xP(x) →∃yP(y)
(c) ⊨∃x(P(x) →∀yP(y))
(d) ∀xA(x) ⊨¬∃x¬A(x)
(e) ¬∃x¬A(x) ⊨∀xA(x)
(f) ∃xA(x) ⊨¬∀x¬A(x)

208
Logic and Discrete Mathematics: A Concise Introduction
(g) ¬∀x¬A(x) ⊨∃xA(x)
(h) ∃x∃yA(x‚ y) ⊨∃y∃xA(x‚ y)
➋Suppose x is not free in Q. Prove the following logical consequences.
(a) ∀x(P(x) ∨Q) ⊨∀xP(x) ∨Q
(b) ∀xP(x) ∨Q ⊨∀x(P(x) ∨Q)
(c) ∃x(P(x) ∧Q) ⊨∃xP(x) ∧Q
(d) ∃xP(x) ∧Q ⊨∃x(P(x) ∧Q)
(e) ∀x(Q →P(x))‚ Q ⊨∀xP(x)
(f) ∃xP(x) →Q ⊨∀x(P(x) →Q)
(g) ∃x(P(x) →Q)‚ ∀xP(x) ⊨Q
(h) ∃x(Q →P(x))‚ Q ⊨∃xP(x)
➌Check which of the following logical consequences hold. For those that do not, construct
a countermodel, i.e. a structure and assignment in which all premises are true, while the
conclusion is false.
(a) ∀xA(x)‚ ∀xB(x) ⊨∀x(A(x) ∧B(x))
(b) ∀x(A(x) ∧B(x)) ⊨∀xA(x) ∧∀xB(x)
(c) ∀xA(x) ∨∀xB(x) ⊨∀x(A(x) ∨B(x))
(d) ∀x(A(x) ∨B(x)) ⊨∀xA(x) ∨∀xB(x)
(e) ∀xA(x) →∀xB(x) ⊨∀x(A(x) →B(x))
(f) ∀x(A(x) →B(x)) ⊨∀xA(x) →∀xB(x)
(g) ∃x(A(x) ∧B(x)) ⊨∃xA(x) ∧∃xB(x)
(h) ∃xA(x)‚ ∃xB(x) ⊨∃x(A(x) ∧B(x))
(i) ∃x(A(x) ∨B(x)) ⊨∃xA(x) ∨∃xB(x)
(j) ∃xA(x) ∨∃xB(x) ⊨∃x(A(x) ∨B(x))
(k) ∃x(A(x) →B(x)) ⊨∃xA(x) →∃xB(x)
(l) ∃xA(x) →∃xB(x) ⊨∃x(A(x) →B(x))
➍Formalize the following logical consequences in first-order logic and check for each of them
whether it is logically correct.
(a) .
All logicians are clever.
All clever people are rich.
All logicians are rich.

First-Order Logic
209
(b) .
All natural numbers are integers.
Some integers are odd numbers.
Some natural numbers are odd numbers.
(c) .
All penguins are birds.
Some penguins are white.
All penguins eat some ﬁsh.
Therefore, there is a white bird that eats some ﬁsh.
(d) .
No yellow plonks are qlinks.
Some object is a plonk or not a qlink.
Therefore, there is an object which is not a yellow qlink.
➎Using the predicates: F(x) for “x is a fairy”’, E(x) for “x is an elf”, G(x) for “x is a goblin”, H(x)
for “x is a hobbit”, T(x) for “x is a troll”, L(x‚ y) for “x likes y”, formalize the following argument
in first-order logic. Then check whether it is logically valid. If it is not valid, give an appropriate
countermodel.
All fairies are elves. Hobbits do not like any elves.
Kermit likes a goblin or a fairy. Everyone who likes any goblins likes no trolls.
Therefore, if Kermit likes any trolls then Kermit is not a hobbit.
➏Formalize the following arguments in first-order logic by using suitable predicates inter-
preted in suitable domains. Then check for each of them whether it is logically valid. If it is
not valid, give an appropriate countermodel.
(a) .
All trolls are elves or goblins. No troll can ﬂy, unless it is an elf. All dragons can ﬂy.
All ugly goblins are trolls. Some goblins are ugly.
Therefore, there is an ugly creature that is not a dragon.
(b) .
Some bachelors love every woman they know.
Every bachelor is a man.
Eve is a woman whom every man knows.
Some bachelor loves a woman.
(c)
Replace the conclusion in the previous example by
“Every bachelor loves a woman.”
and check again whether the resulting argument is logically valid.

210
Logic and Discrete Mathematics: A Concise Introduction
Alonzo Church (14.6.1903–11.8.1995)
Alonzo Church was an American mathematician and logician who
made profound contributions to mathematical logic and the theoretical
foundations of computer science.
Church studied and had his academic career at the Mathemat-
ics Department of Princeton University, where he worked until 1967,
when he formally retired and moved to the University of California,
Los Angeles, as Flint Professor of Philosophy and Mathematics for a
further 23 years, until his final retirement at the age of 87, in 1990, after
63 years of a teaching career.
In the early 1930s Church created the lambda-calculus, as a for-
mal system for defining functions that are effectively computable. The
lambda-calculus is also relevant to his two-part work A Set of Postulates for the Foundations of Logic,
published in 1932–1933, intended to develop a set of axioms that “would lead to a system of math-
ematical logic free of some of the complications entailed by Bertrand Russell’s theory of types, and
would at the same time avoid the well-known paradoxes, in particular the Russell paradox.” While
it later turned out that the original system of lambda-calculus did contain an inconsistency, the idea
flourished further and later became very influential in computer science as the basis of functional
programming.
In 1936 Church published two papers of profound importance for logic and computability
theory. In the first, An Unsolvable Problem of Elementary Number Theory, he defined the notion of
“effective calculability” by identifying it with the notion of recursive functions or, equivalently as it
turned out, with lambda-definable functions of natural numbers. He then proved that the problem
of deciding whether a given first-order formula of the language with addition and multiplication is
true of the arithmetic of natural numbers is not effectively calculable. By equating effective calcula-
bility with algorithmic solvability Church put forward what was later called by Kleene “Church’s
thesis”. Thus, Church essentially proved that the truth in the elementary arithmetic is algorithmi-
cally unsolvable.
In his other historic paper from 1936, A Note on the Entschiedungsproblem (two pages long,
followed by a two-page correction), Church proved what is now called Church’s theorem: the
problem of deciding validity of formulae in first-order logic is not effectively calculable, which
means – assuming Church’s thesis – algorithmically unsolvable.
Church had an extremely long and fruitful scientific career, spanning over more than 70 years
since his first publication as an undergraduate student in 1924 until his last paper, A Theory of the
Meaning of Names, published in 1995. In 1956 he published his classic textbook Introduction to Mathe-
matical Logic, which educated and influenced generations of logicians. Church was also an extremely
popular and successful supervisor and had 31 doctoral students, many of whom became distin-
guished logicians and computer scientists, including Martin Davis, Leon Henkin, John Kemeny,
Steven Kleene, Michael O. Rabin, Nicholas Rescher, Hartley Rogers, J. Barkley Rosser, Dana Scott,
Reymond Smullyan and Alan Turing.

First-Order Logic
211
4.8.
Applications of ﬁrst-order logic to mathematical reasoning
and proofs
In mathematics the truth of a statement is established by proving it. A proof may consist of a
simple argument or of lots of complicated calculations with essentially no logical reasoning.
It may also be a long and intricate argument involving a number of other, already proven,
statements, conjectures, logical inferences, etc.
This section is about logical aspects of mathematical reasoning and proofs. We discuss
strategies and tactics for proofs, essentially based on the rules of the logical system of natural
deduction (which we will not formally present here) and illustrate them with a few examples.
4.8.1.
Proof strategies: direct and indirect proofs
A typical mathematical statement looks like this:
If P1‚ …‚ Pn then C.
where P1‚ …‚ Pn are several (possibly none) premises or assumptions and C is a conclusion.
The logical structure of a proof of such a statement naturally depends on the logical
structure of the premises and of the conclusion. Here we will provide some proof tactics telling
us how to go about specific, local steps of the proof, but we will first discuss possible proof
strategies, telling us how to organize proofs globally.
I. Direct proof
With this proof strategy one assumes that all premises are true and then tries to deduce the
desired conclusion by applying a sequence of correct (logical or mathematical) inference steps.
Schematically, a direct proof looks as follows:
Assume P1‚ …‚ Pn.
⋮
(a sequence of valid inferences)
⋮
Conclude C.

212
Logic and Discrete Mathematics: A Concise Introduction
Example 4.8.1
A direct proof of the statement
If n is an odd integer, then n2 is an odd integer.
Proof:
Suppose n is an odd integer.
Then there is an integer k such that n = 2k + 1.
Therefore, n2 = (2k + 1)(2k + 1) = 4k2 + 4k + 1 = 2(2k2 + 2k) + 1.
Therefore, n2 is odd.
II. Indirect proof
Also known as proof by assumption of the contrary or proof by contradiction. The idea of
the indirect proof strategy is the same as the idea of semantic tableaux: to assume that all
premises are true, while the conclusion is false (hence the negation of the conclusion is true), and
try to reach a contradiction, again by applying only valid inferences. One typically obtains a
contradiction by deducing a statement known to be false (like deducing that 1 + 1 = 3) or by
deducing a statement and its negation. Often one can reach a contradiction by deducing the
negation of some of the premises (see the example below), which have been assumed to be
true. The rationale behind the proof by contradiction is clear: if all our assumptions are true
and we only apply valid inferences, then all our conclusions must also be true. Therefore, by
deducing a false conclusion, we show that, given that all original assumptions are true, the
additional one that we have made – namely, the negation of the conclusion – must have been
wrong, i.e. that the conclusion must be true.
Thus, the scheme of a proof by contradiction is:
Assume P1‚ …‚ Pn.
Assume ¬C.
⋮
(a sequence of valid inferences)
⋮
Derive both A and ¬A
for some proposition A.
Conclude that ¬C cannot be true.
Therefore‚ conclude C.

First-Order Logic
213
Example 4.8.2
A proof by contradiction of the statement
If x and y are integers, x is odd and xy is even, then y is even.
Proof:
Suppose that x‚ y are integers, where x is odd and xy is even.
Suppose also that y is not even.
Therefore, y is odd.
Then there is an integer k such that x = 2k + 1, since x is odd,
and there is an integer m such that y = 2m + 1, since y is odd.
Therefore, xy = (2k + 1)(2m + 1) = · · · = 2(2km + k + m) + 1.
Therefore, xy is odd.
On the other hand, we have assumed that xy is even and, therefore, xy is not odd.
Thus, xy is odd and xy is not odd.
This is a contradiction. It implies that the additional assumption, that y is not even,
is wrong.
Therefore y is even, which completes the proof.
Example 4.8.3
Euclid’s proof by contradiction is that
√
2 is irrational.
Proof:
Suppose it is not the case that
√
2 is irrational.
Therefore,
√
2 is rational.
Hence,
√
2 can be represented as an irreducible fraction, i.e. there are relatively
prime integers m and n such that
√
2 = m∕n.
Therefore, 2 = m2∕n2 and hence 2n2 = m2.
Hence m2 is even.
Therefore, m must be even, since if it were odd, then m2 would have been odd
(see the example of a direct proof).
Thus, there is an integer a such that m = 2a.
Hence, m2 = 4a2.

214
Logic and Discrete Mathematics: A Concise Introduction
Therefore, 2n2 = 4a2 and hence n2 = 2a2.
Thus, n2 is even.
Therefore, n must be even, by the same argument as above.
Thus, there is an integer b such that n = 2b.
Therefore, the fraction m∕n = 2a∕2b is not irreducible, which contradicts the
assumption that m∕n is irreducible.
This contradiction completes the proof.
A variation of proof by contradiction is proof by contraposition. This strategy is usually
applied when the statement to be proved is of the type “If P, then C”, i.e. there is only one
premise.15 This proof strategy is based on the fact that the implication “If P, then C” is logically
equivalent to its contrapositive “If ¬C, then ¬P”. Therefore, if we prove the latter, we have a
proof of the former.
Schematically, the proof by contraposition of “If P, then C” looks as follows:
Assume ¬C.
⋮
(a sequence of valid inferences)
⋮
Derive ¬P.
One can also think of this strategy, as obtained from the proof by contradiction strategy,
by assuming P together with ¬C at the beginning and then proving ¬P to produce the desired
contradiction.
Usually we apply the proof by contraposition when it is easier to prove the contrapositive
of the original implication.
Example 4.8.4
Here is a proof by contraposition of the statement
If n is an integer such that n2 is even, then n is even.
Proof:
Suppose n is not even.
Therefore, n is odd.
Then (see the example of a direct proof) n2 is odd.
Therefore, n2 is not even.
This completes the proof.
15 In fact, it can be applied in the general case, since we can always replace all premises by their conjunctions.

First-Order Logic
215
Lastly, we note that, whereas semantic tableaux and resolution are very convenient and
relatively easy to use systems of deduction, they are only suitable for proofs by contradic-
tion, but not for direct proofs. However, reasoning by contradiction is often unnecessary and
sometimes unnatural. Besides, this kind of reasoning requires that we have a specified goal
(conclusion) to prove and they are of no use if we simply want to derive logical consequences
from the knowledge that we have, possibly plus additional assumptions that we have made.
In such cases, direct reasoning has no good alternative.
4.8.2.
Tactics for logical reasoning
Here we discuss tactics of proof, that are applicable to any of the methods discussed above.
These tactics can be extracted from the rules of a deductive system called Natural Deduction,
not presented here. The choice of tactics depends both on the logical structure of the conclusion
and on the logical structure of the premises. We look at these separately.
Tactics based on the conclusion to be proved
• If the conclusion is a negation, C = ¬A, then one can apply a proof by contradiction, by
assuming A (which is equivalent to the negation of ¬A) and trying to reach a contradiction.
Alternatively, one can import the negation in ¬A inside A and try another tactic.
• If the conclusion is a conjunction, C = A ∧B, one has to prove each of A and B.
• If the conclusion is a disjunction, C = A ∨B, one can try to prove one of A or B. This works
sometimes, but not always. If it does not work, then one can try a proof by contradiction,
i.e. assume ¬C, which is equivalent to ¬A ∧¬B. Hence we assume each of ¬A and ¬B, and
try to reach a contradiction.
Also, one can use the equivalence P ∨Q ≡¬P →Q and transform the disjunction into impli-
cation; then see below.
• If the conclusion is an implication, C = A →B, one assumes A, in addition to all premises,
and tries to prove B.
Alternatively, one can attempt a proof by contraposition, by tackling a conclusion ¬B →¬A
instead.
Lastly, one can try a proof by contradiction, by assuming ¬(A →B), or equivalently, A and
¬B.
• If the conclusion is a biconditional, C = A ↔B, then it is equivalent to the conjunction (A →
B) ∧(B →A) and we follow the tactics mentioned above.
• If the conclusion is a universally quantified statement, C = ∀xA(x), one typically reasons
by saying “Let c be a (name of an) arbitrary object from the domain (e.g. an arbitrary real
number).” Then one tries to prove that A(c) holds with a general argument, without assum-
ing any specific properties of c. In particular, the name c must be a new one, but one that has
not been mentioned in the proof yet, for the argument to be really general.
If one succeeds in proving that A(c) holds in a way independent from c, then that proof will
apply to any object c from the domain, which will produce a proof that A(x) holds for every
object x, i.e. a proof of ∀xA(x).
• If the conclusion is an existentially quantified statement, C = ∃xA(x), then we either try to
find an explicit witness c, such that A(c) holds, or we attempt a proof by contradiction, i.e. a

216
Logic and Discrete Mathematics: A Concise Introduction
proof that it cannot be the case that there does not exist x for which A(x) holds. The latter is called
a nonconstructive proof of existence. One often comes across such nonconstructive proofs in
mathematics.
Tactics based on the premises
We use each premise P according to its logical form as follows:
• If the premise is a negation, P = ¬A, then one can import that negation inside all other logical
connectives in A, if any.
• If the premise is a conjunction, P = A ∧B, one can replace it by two new premises, viz. A
and B.
• If the premise is a disjunction, P = A ∨B, and it is not known which of A and B is true, then
one must reason per cases, i.e. consider separately each of the two possible cases, viz. Case 1:
A is true; Case 2: B is true.
If one succeeds to prove that in each of these cases the conclusion C follows, then this pro-
vides a proof that C follows from A ∨B. (Why?)
• If the premise is an implication, P = A →B, one can try to derive A and then conclude B
and use it further.
Alternatively, one can replace A →B by the equivalent disjunction ¬A ∨B and reason as in
the previous case.
• If the premise is a biconditional, P = A ↔B, then one can replace it by the conjunction (A →
B) ∧(B →A).
• If the premise is a universally quantified statement, P = ∀xA(x), one can obtain from it new
premises (possibly infinitely many) A(c) for each object c from the domain. More generally,
one can assume A(t) for any term that is free for substitution for x in A(x).
• If the premise is an existentially quantified statement, P = ∃xA(x), then one can introduce a
new name, say c, for an object that satisfies A, that is to say, “Well, if there is an object x such
that A(x), then let us take one and give it a name, say c.” Then one can replace the premise
by A(c). Note that the name c must be a new one that has not been mentioned in the proof
yet nor occurs in the target conclusion, and no assumptions about c can be made other than
A(c).
4.8.3.
Exercises
➊For each of the examples of proofs given in this section determine which steps in the proof
above are based on logical inferences and which on substantial (mathematical) arguments.
➋Prove the following statements. Clearly indicate the method of proof and explain the steps.
Distinguish the logical from the substantial steps.
(a) If the sum of two integers is even, then so is their difference.
(b) If a‚ b‚ x are real numbers, a < b and (x −a)(x −b) < 0, then a < x < b.
(c) If a and b are rational numbers and a < b, then there exists a rational number r such that
a < r < b.

First-Order Logic
217
(d) For every two integers m‚ n, if mn is even, then m is even or n is even.
(e) For every natural number n the number n2 + n is even.
(f) For every two integers a‚ b if ab is odd, then a + b is even.
(g) No positive integers m and n exist such that 1∕m + 1∕n > 2.
(h) The number
3√
3 is irrational.
(i) If x + y is an irrational number, then x is an irrational number or y is an irrational num-
ber.
Alan Mathison Turing (23.6.1912–7.6.1954)
Alan Turing was a British mathematician, logician, computer
scientist and crypto-analyst, regarded as one of the founders
of Theoretical Computer Science, for his creation of the uni-
versal model of computations, now called the Turing machine,
and of Artificial Intelligence, for proposing the idea of using a
special test, now known as Turing’s test, for deciding whether
an artificial agent has intelligence. Turing was instrumental
in breaking the German Enigma codes during the Second
World War.
In 1935 Turing studied Gödel’s incompleteness results
(see Section 4.5) and Hilbert’s Entscheidungsproblem (see the
box at the end of Section 3.3 in Chapter 3) – the problem
that asks for an algorithm that takes as input a sentence of
a first-order logic and answers whether it is valid. In the following year he wrote his ground-
breaking paper On Computable Numbers, with an Application to the Entscheidungsproblem, where he
introduced an abstract universal computing device, now called a Turing machine, and argued that
such a machine can perform any conceivable mathematical computation representable as an algo-
rithm. Remarkably, Turing machines described the concept of modern programmable computers
before they were actually invented. Turing described in his 1936 paper the construction of a uni-
versal Turing machine, which can simulate the work of any Turing machine. He then showed that
the halting problem for Turing machines is algorithmically undecidable in a sense that there cannot
exist an algorithm (represented by a Turing machine) that can take the code of any Turing machine
and an input for it and determine as an output whether that Turing machine will eventually halt
for that input. Then Turing concluded that Hilbert’s Entscheidungsproblem has no solution.
Turing completed a doctorate in mathematical logic in Princeton University under Church’s
supervision in 1938. Church (see Section 4.7) and Turing showed that Church’s lambda-calculus
and the Turing machine were equivalent as models of computation and argued that they capture
precisely the intuitive notion of an algorithm. This claim became known as the Church – Turing
thesis.

218
Logic and Discrete Mathematics: A Concise Introduction
In 1938, Turing was invited to work for the British cryptanalytic department, to help with
breaking the secret codes of the German encrypting machines Enigma. Turing was instrumental
in developing methods and constructing special devices, called Bombe, for decrypting messages
sent by Enigma coders, which saved many lives in the course of World War II. At the end of the
war Turing was invited by the National Physical Laboratory in London to design a real, physical
computer and he submitted a report proposing the Automatic Computing Engine (ACE) in 1946.
Turing was homosexual and was arrested and convicted for violating the British antihomo-
sexuality law in 1952. To avoid going to prison he accepted to be subjected to chemical castration.
Turing died in 1954 of cyanide poisoning and it is widely believed that this was a suicide, induced
by his prosecution and treatment. In 2009 the British Prime Minister offered an official apology from
the British Government for Turing’s prosecution and in 2013 Turing was granted posthumously a
royal pardon by the Queen.
In 1966 the Association for Computing Machinery established the Turing Award as the most
prestigious award for scientific contributions in computer science, regarded as the equivalent of
the Nobel Prize.

5
Number Theory
5.1.
The principle of mathematical induction revisited . . . . . . . . . . . . . . . . . . .
220
5.2.
Divisibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
224
5.3.
Computing greatest common divisors. Least common multiples . . . . . . . . . . .
230
5.4.
Prime numbers. The fundamental theorem of arithmetic . . . . . . . . . . . . . . .
236
5.5.
Congruence relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
5.6.
Equivalence classes and residue systems modulo n
. . . . . . . . . . . . . . . . .
248
5.7.
Linear Diophantine equations and linear congruences . . . . . . . . . . . . . . . .
253
5.8.
Chinese remainder theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
257
5.9.
Euler’s function. Theorems of Euler and Fermat . . . . . . . . . . . . . . . . . . . .
261
5.10. Wilson’s theorem. Order of an integer
. . . . . . . . . . . . . . . . . . . . . . . .
266
5.11. Application: public key cryptography . . . . . . . . . . . . . . . . . . . . . . . . .
269
Number theory is one of the oldest (over 2300 years) and most beautiful branches of mathe-
matics, often called “the queen of mathematics”. It studies the arithmetical properties of the
natural numbers, in particular those related to divisibility and prime numbers. Some questions
in number theory were formulated in the early times of that field, yet still remain unanswered
today, like whether any odd perfect number exists. This difficulty in proving relatively simple
statements prompted the great mathematician Karl Friedrich Gauss to say the following about
number theory: “It is just this which gives the higher arithmetic that magical charm which has made
it the favourite science of the greatest mathematicians, not to mention its inexhaustible wealth, wherein
it so greatly surpasses other parts of mathematics.”
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

220
Logic and Discrete Mathematics: A Concise Introduction
Since its inception during the time of Euclid, number theory was largely separate from
the rest of mathematics, but towards the end of the 1800s it became more and more related
with other branches of mathematics. Today number theory plays a fundamental role in the
entire mathematics and is deeply connected with all other branches of it, even with seemingly
distant ones such as complex analysis, where the most prominent currently open problem
in mathematics, the Riemann hypothesis, is intimately related to the distribution of prime
numbers.
The development of computer technology has brought about revolutionary advancement
of number theory, which in turn has provided numerous important applications to informa-
tion theory, coding theory, algorithmic complexity theory, cryptography and, most recently,
to computational biology and bioinformatics. Among the many and various applications of
number theory we will discuss here only one, viz. public key cryptography.
5.1.
The principle of mathematical induction revisited
Here we will extend and generalize the Principle of Mathematical Induction (PMI). We begin
by stating two equivalent principles from which PMI can be deduced.
A fundamental property of the set of natural numbers, which we can take as an axiom, is
the following Principle of Well-Ordering (PWO):
Every nonempty set of natural numbers has a least element.
This is equivalent to the following Principle of Descending Chains (PDC):
There is no infinite strictly descending sequence of natural numbers.
Indeed, assuming the PWO, then every strictly descending sequence of natural numbers,
considered as a set of its members, must have a least element; hence it may not be infinite.
Conversely, assume the PDC and suppose PWO does not hold. Then take any nonempty set
X of natural numbers with no least element. Take any n0 ∈X. Since it is not least in X, there
must be n1 ∈X such that n1 < n0. Again, n1 is not least in X, so there must be n2 ∈X such that
n2 < n1, etc. Thus, we construct an infinite strictly descending sequence of natural numbers,
which contradicts the PDC.
Assuming any of the principles above, we can now prove the PMI.
Theorem 5.1.1 (Principle of Mathematical Induction) Suppose that some property P of natural
numbers holds for some natural number n0 ≥0, and whenever P holds for some natural number k ≥n0,
it also holds for k + 1. Then P holds for every natural number greater than or equal to n0.
Proof: The PMI can be derived from the PWO by assumption of the contrary, as follows. Sup-
pose that there are natural numbers greater than or equal to n0 for which P does not hold. The
collection of such numbers has a least element m. It must be greater than n0 since P holds for
n0. Therefore m −1 is a natural number less than m and greater than or equal to n0, hence P

Number Theory
221
must hold for m −1. Then P must also hold for m since m = (m −1) + 1. This is a contradiction;
therefore our assumption was wrong.
Here is a seemingly stronger, but in fact equivalent, form of the principle of mathematical
induction.
Theorem 5.1.2 (Principle of Complete Mathematical Induction (PCMI)) Suppose a property
P of natural numbers holds for a natural number n0 and also suppose that, for any natural number
k ≥n0, if P holds for all natural numbers greater than or equal to n0 and less than k, then P holds for
k. Then P holds for every natural number greater than or equal to n0.
Proof: Left as Exercise 4.
Thus, when using the PMCI we need to prove the following:
1. P(n0) holds for some natural number n0.
2. For any k ≥n0, assuming that P(k) holds for all natural numbers greater than or equal to
n0 and less than k then P(k) also holds.
Exercise 5.1.3 Show that in the statement of Theorem 5.1.2 the base step, i.e. the assumption that the
property P holds for n0, can be omitted.
Example 5.1.4
Every natural number n ≥1 can be written as a sum of distinct powers of 2.
Solution
Let P(n) be the statement “The natural number n ≥1 can be written as a sum of distinct
powers of 2”. We will use the PMCI to prove this statement. We start with the base step: for
n = 1 we have that 1 = 20.
Now, for any k > 1, we assume that P is true for all natural numbers greater than or equal
to 1 and less than k (the inductive hypothesis, IH). Our goal is to prove that P(k) holds, i.e.
that k can be written as a sum of distinct powers of 2, using the IH. We consider the two
possible cases, of k odd and k even, separately:
Case 1 Suppose k is odd. Then k −1 is even and less than k and therefore by the inductive
hypothesis k −1 can be written as a sum of distinct powers of 2. Note that each power
is at least 1 since k is even and k > 1. Let
k −1 = 2p1 + 2p2 + · · · + 2pm
where 1 ≥p1 < p2 < · · · < pm. Then:
k = (k −1) + 1 = (2p1 + 2p2 + · · · + 2pm) + 20‚
which is a sum of distinct powers of 2, as required.

222
Logic and Discrete Mathematics: A Concise Introduction
Case 2 Suppose k is even. Then k
2 is a natural number less than k and by our inductive hypoth-
esis there exist natural numbers p1 < p2 < · · · < pr such that
k
2 = 2p1 + 2p2 + · · · + 2pr.
Now by multiplying both sides by 2 we get
k = 2(2p1 + 2p2 + · · · + 2pr) = 2p1+1 + 2p2+1 + · · · + 2pr+1‚
which is a sum of distinct powers of 2, as required.
Therefore, by the PMCI, P(n) is true for all natural numbers n ≥1.
5.1.1.
Exercises
➊
Prove that for every natural number n:
(a) 20 + 21 + 22 + · · · + 2n = 2n+1 −1
(b) 1 + 3 + 5 + · · · + (2n −1) = n2
(c) 12 + 22 + · · · + n2 = n(n+1)(2n+1)
6
(d) 13 + 23 + · · · + n3 = n2(n+1)2
4
(e) 1 × 3 + 2 × 4 + · · · + n × (n + 2) = n(n+1)(2n+7)
6
(f)
1
1×3 +
1
2×4 + · · · +
1
n×(n+2) =
n(3n+5)
4(n+1)(n+2)
(g)
1
√
1 +
1
√
2 + · · · +
1
√
n ≤2
√
n
➋
(Bernoulli’s inequality) If x ≥−1 then (1 + x)n ≥1 + nx for every n ∈ℕ.
➌∗Find closed form expressions for the following sums and prove them using the PMI:
(a) 1 × 2 + 2 × 3 + · · · + n × (n + 1)
(b)
1
1×2 +
1
2×3 + · · · +
1
n×(n+1)
➍
Prove the PMCI, as stated in Theorem 5.1.2, using a variation of the proof of the PMI in
Theorem 5.1.1.
➎
Prove the claim in Exercise 5.1.3.
➏∗Show that the PMCI is equivalent to the PMI.
➐∗Prove that the PMCI is equivalent to the following form: “Let a property P of natural num-
bers be such that for any natural number k, if it holds for all natural numbers less than k
then it holds for k. Then P holds for all natural numbers.”

Number Theory
223
Carl Friedrich Gauss (30.4.1777–23.2.1855)
Gauss was a famous German mathematician who made funda-
mental contributions to many fields of mathematics and science,
including number theory, algebra, analysis, differential geome-
try, statistics, geodesy, geophysics, electrostatics, astronomy and
optics – too many even to be listed here. He is sometimes referred
to as “the Prince of Mathematics” and is regarded as one of the
greatest and most influential mathematicians ever.
Gauss was a child prodigy and one anecdote about his early
signs of genius goes as follows. His primary school teacher tried
to keep the pupils busy while he attended to his own affairs, by
making them add the first 100 natural numbers. To his astonish-
ment (and, probably, displeasure) the little Gauss gave the correct answer within seconds. How
did he do it? He realized that pairwise addition of terms equally far from the opposite ends of
the list of numbers always gives the same sum: 1 + 100 = 2 + 99 = 3 + 98 = · · · = 101 which gives
50 × 101 = 5050.
This is how he discovered the general formula for the sum of the first n positive integers. A
good lesson to learn from this story is that when solving mathematical problems a good insight can
replace a lot of hard labour. The picture below gives an insightful graphical proof of the formula
discovered by Gauss:
n+1
n

224
Logic and Discrete Mathematics: A Concise Introduction
5.2.
Divisibility
Divisibility is the most specific arithmetical relation between integers. While very simple to
define, the study of divisibility quickly leads to the most difficult problems of arithmetic, some
of which are extremely easy to formulate, yet have remained unsolved for centuries. However,
let us begin with the basics.
Definition 5.2.1 A nonzero integer a divides the integer b if there is an integer q such that b = aq. If
a divides b we write a ∣b and also say that b is divisible by a, or a is a divisor of b, or b is a multiple
of a. If a does not divide b we write a ∤b.
For instance 3 ∣15 and −3 ∣15, but 3 ∤16, −3 ∤16 and, by definition, 0 ∤b for any integer b,
including b = 0.
Hereafter, whenever we write a ∣b we will assume that a ≠0.
5.2.1.
Basic properties of divisibility
Theorem 5.2.2 (Basic properties of divisibility) The following hold for any integers a‚ b‚ c:
(D1) 1 ∣b.
(D2) a ∣0 and a ∣a.
(D3) If a ∣b then −a ∣b and a ∣−b.
(D4) If a ∣b then a ∣bc.
(D5) If a ∣b and b ∣c then a ∣c.
(D6) If a ∣b and a ∣c then a ∣(mb + nc) for any integers m‚ n; in particular, a ∣b −c and a ∣b + c.
(D7) If a ∣b and b ∣a then a = b or a = −b. In particular, if a and b are natural numbers, then
a = b.
(D8) If a ∣b and a‚ b > 0 then a ≤b.
(D9) If m is a nonzero integer then a ∣b if and only if ma ∣mb.
(D10) If a ∣b and c ∣d then ac ∣bd.
Proof: All these properties are immediate consequences of the definition. Let us show for
instance (D6).
Let a ∣b and a ∣c. Then b = xa for some integer x and c = ya for some integer y. Therefore
mb + nc = mxa + nya = (mx + ny)a and hence a ∣(mb + nc).
We leave the proofs of the remaining properties to the reader. See Exercise 1 at the end of
the section.
5.2.2.
Division with a remainder
Now we can state and prove the most important basic result involving divisibility.

Number Theory
225
Theorem 5.2.3 (The fundamental theorem about division with remainder) Given any inte-
gers a > 0 and b, there exist unique integers q and r such that
b = qa + r
and
0 ≤r < a.
Furthermore, r = 0 if and only if a ∣b.
The numbers q and r are called respectively the quotient and the remainder of the division of b by
a. Thus, the theorem says that every integer b can be divided with a remainder by any positive integer
a in a unique way.
Proof: If b = 0 then b = 0.a + b and b < a. Suppose that b ≠0. Consider the arithmetic sequence
…‚ b −2a‚ b −a‚ b‚ b + a‚ b + 2a‚ …. Notice that 0 belongs to this sequence if and only if b = ka
for some integer k, i.e. if and only if a ∣b. Now suppose that a ∤b; hence 0 does not occur in
the sequence. There are positive terms in the sequence (why?). Let r be the least of them and
r = b −qa. (Why does r exist?) We claim that r < a. Indeed, if r ≥a then r −a ≥0 and r −a =
(b −qa) −a = b −(q + 1)a, so r −a also belongs to the sequence. Furthermore, r −a < r, which
contradicts the choice of r. Thus 0 < r < a, so we have proved the existence of r and q with the
desired properties.
Now let us show that r and q are unique with these properties. Suppose that there are two
such pairs, (q1‚ r1) and (q2‚ r2), and assume that r1 ≥r2. Then r1 −r2 = (b −q1a) −(b −q2a) =
(q2 −q1)a. On the other hand, 0 ≤r1 −r2 < a, which leaves the only possibility for q2 −q1 to be
0, i.e. q2 = q1 from where r2 = r1.
Finally, if r = 0 then a ∣b by definition. Conversely, if a ∣b then a = kb + 0 for some integer
k. Then, by uniqueness of q and r, q must equal k and r must be 0.
5.2.3.
Greatest common divisor
Definition 5.2.4 An integer d is a common divisor of the integers a and b if d ∣a and d ∣b. The
greatest integer amongst the common divisors of a and b (if it exists) is called the greatest common
divisor of a and b, denoted gcd(a‚ b).
Note that gcd(a‚ b) is always positive: if c is also a common divisor of a and b, and c is
negative, then −c is also a common divisor of a and b and is greater than c.
Theorem 5.2.5 (Greatest common divisor) If a and b are integers, at least one of them nonzero,
then
1. gcd(a‚ b) exists and is unique.
2. gcd(a‚ b) = ua + vb for some integers u and v.
3. Moreover, gcd(a‚ b) is the least positive integer that can be represented in this way.
Proof:
1. It follows from Exercise 2 at the end of this section that, unless a = b = 0, a and b have
finitely many common divisors, so there is a greatest among them.

226
Logic and Discrete Mathematics: A Concise Introduction
2. Consider the set L of all integral linear combinations xa + yb, where x and y range over
all integers. There are positive numbers in L (why?). Let d = ua + vb be the least positive
integer in L. (Here we apply again the fundamental property of well-ordering of the nat-
ural numbers.) We will show that d ∣a and d ∣b. Suppose d ∤a. Then, by Theorem 5.2.3,
there are integers q and r such that a = dq + r and 0 < r < d. Hence we have
r = a −qd = a −q(ua + vb) = (1 −qu)a + (qv)b
and thus r belongs to L, which is impossible since r is a positive integer less than d. There-
fore d ∣a. Likewise d ∣b. Thus d is a common divisor of a and b. Let g = (a‚ b). Then a = ga′
and b = gb′ and hence d = (ga′)u + (gb′)v = g(a′u + b′v). Thus g ∣d and hence g ≤d by (D8)
in Theorem 5.2.2 and d ≤g by definition of g. Therefore g = d.
In the next section we will discuss the question, given a and b, of how to find coefficients
u and v such that gcd(a‚ b) = ua + vb. Hereafter, whenever we write gcd(a‚ b) we will assume
that a and b are integers and are not both zero.
Theorem 5.2.6 (Basic properties of the greatest common divisor) For any integers a‚ b‚ c‚ d‚ m ∶
(GCD1) gcd(a‚ b) = gcd(b‚ a).
(GCD2) If a ∣b, then gcd(a‚ b) = |a|. In particular, if a ≠0 and b = 0 then gcd(a‚ b) = |a|.
(GCD3) gcd(a‚ b) = gcd(a‚ −b) = gcd(−a‚ b) = gcd(−a‚ −b).
(GCD4) gcd(a‚ b) = gcd(a‚ b + ac) = gcd(a + bc‚ b).
(GCD5) For any integer m, gcd(ma‚ mb) = m gcd(a‚ b).
(GCD6) If d ∣a and d ∣b then gcd
(
a
d‚ b
d
)
= gcd(a‚ b)
d
. In particular, if d = gcd(a‚ b) then
gcd
(
a
d‚ b
d
)
= 1.
(GCD7) gcd(gcd(a‚ b)‚ c) = gcd(a‚ gcd(b‚ c)).
(GCD8) If a and b are not both 0, then every common divisor of a and b divides gcd(a‚ b).
Proof: We will verify (GCD4), (GCD5) and (GCD6); the rest are left as exercises.
(GCD4) Let g = gcd(a‚ b), h = gcd(a‚ b + ac). Then g ∣b + ac by Theorem 5.2.2, and hence g ≤
h. On the other hand, for some integers u and v, g = au + bv = a(u −cv) + (b + ac)v.
Thus, h ∣g by Theorem 5.2.2, so h ≤q, and therefore g = h, since g and h are both
positive. Likewise gcd(a‚ b) = gcd(a + bc‚ b).
(GCD5) We can assume that m > 0; otherwise we take −m and apply (GCD3). Now
gcd(ma‚ mb) is the least positive value of mua + mvb = m(ua + vy), where u‚ v are
integers, while gcd(a‚ b) is the least positive value of ua + vy, whence the identity.
(GCD6) Again, we can assume that d > 0. Let g = gcd( a
d‚ b
d) and h = gcd(a‚ b). Then a = da′,
b = db′ and, by (GCD5), h = d gcd(a′‚ b′) = dg, hence g = h
d.

Number Theory
227
The definition of greatest common divisor is readily generalized to several integers. We
denote the greatest common divisor of the integers a1‚ a2‚ …‚ ak by gcd(a1‚ a2‚ …‚ ak).
The properties (GCD1) and (GCD7) imply that gcd(a1‚ a2‚ …‚ ak) does not depend on the
order in which the integers are taken, and can be computed step by step, taking only two
numbers at a time.
5.2.4.
Exercises
➊
Prove the remaining properties of Theorem 5.2.2.
➋
Show that every nonzero integer a has only finitely many divisors.
➌
Divide a by b with a remainder, where
(a) a = 93, b = 93.
(b) a = 93, b = 3.
(c) a = 93, b = 17.
➍
How many integers between 100 and 1000 are divisible by 11?
➎
Prove that for any integer n the remainder of the division of n2 by 4 is either 0 or 1.
➏
Show that for any natural number n represented in a decimal system, n is divisible by
(a) 2 if and only if its last digit is divisible by 2.
(b) 4 if and only if the number formed by its last two digits is divisible by 4.
(c) 5 if and only if its last digit is divisible by 5.
➐
Prove that for every natural number k, exactly one of any k consecutive integers is divisible
by k.
➑
Prove that for every natural number n,
(a) if n is odd then 8 ∣n2 −1.
(b) if n is odd then 48 ∣n3 + 3n2 −n −3.
(c) 8 ∣32n −1.
(d) 9 ∣4n + 15n −1.
(e) 25 ∣2n+23n + 5n −4.
➒
Prove that for any positive integers m‚ n ∶if m ∣n then 2m −1 ∣2n −1.
➓
Determine:
(a) gcd(24‚ 42).
(b) gcd(24‚ −35).
(c) gcd(−24‚ −72).
11
Given that gcd(a‚ 4) = 2 and gcd(b‚ 4) = 2 show that gcd(a + b‚ 4) = 4.
12
Let a‚ b‚ n be positive integers such that for any positive integer k such that k ≠b, it holds
that k −b ∣kn −a. Show that a = bn.
13
Prove the remaining properties from Theorem 5.2.6.

228
Logic and Discrete Mathematics: A Concise Introduction
14
Let x and y be integers such that x + y = 1000. Is it possible that gcd(x‚ y) = 3?
15
Using the properties (GCD1) and (GCD7) in Theorem 5.2.6 show that
(a) gcd(a1‚ a2‚ …‚ ak) = gcd(a1‚ gcd(a2‚ …‚ gcd(ak−1‚ ak)).
(b) if b1‚ b2‚ …‚ bk is a rearrangement of a1‚ a2‚ …‚ ak then gcd(b1‚ b2‚ …‚ bk)= gcd(a1‚ a2‚ …‚ ak).
16
Generalize Theorem 5.2.5 for greatest common divisors of several integers by showing
that if a1‚ a2‚ …‚ ak are not all zeros then gcd(a1‚ a2‚ …‚ ak) exists and equals the least positive
integer, which can be represented as an integer linear combination of a1‚ a2‚ …‚ ak, i.e. the
least positive integer d such that
d = u1a1 + u2a2 + · · · + ukak
for some integers u1‚ u2‚ …‚ uk.
17
Show that every common divisor of a1‚ a2‚ …‚ ak divides gcd(a1‚ a2‚ …‚ ak).
18
Generalization of (GCD6): prove that if gcd(a1‚ a2‚ …‚ ak) = d then gcd
(
a1
d ‚ a2
d ‚ …‚ ak
d
)
= 1.
19
Prove that for any integers a and b,
gcd(a‚ b) = gcd(3a + 5b‚ 11a + 18b).
20
If a‚ b and c are odd integers prove that
gcd(a‚ b‚ c) = gcd
(
a + b
2
‚ b + c
2
‚ c + a
2
)
.
21
Prove that for any integers a‚ b and c,
gcd(a‚ b) = gcd(a + bc‚ a + b(c −1)).
22
Prove that the fraction 21n+4
14n+3 is irreducible for any natural number n.1
23
Show that the fraction
a3+2a
a4+3a2+1 is irreducible.
24∗A right-angled triangle has sides with integer lengths. Show that:
(a) The length of one of the two shorter sides of the triangle is divisible by 3.
(b) The length of one of the sides of the triangle is divisible by 5.
25∗Find all three-digit numbers n such that the number formed by the last three digits of any
power of n equals n.
26∗Show that for any natural numbers n and m the following sums are not integers.
(a) N1 = 1
2 + 1
3 + · · · + 1
n
(b) N2 = 1
n +
1
n+1 + · · · +
1
n+m
(c) N3 = 1
3 + 1
5 + · · · +
1
2n+1
27 ∗Prove that if m ∣abn + cn + d for every integer n ≥0 then m ∣c2.
28∗Prove that m ∣abn + cn + d for every integer n ≥0 if and only if m ∣a + d, m ∣(b −1)c and
m ∣a(b −1) + c.
1 This was Problem 1 from the First International Mathematical Olympiad (IMO) in Romania, 1959.

Number Theory
229
29∗Show that the number m4 + m3 + m2 + m + 1, where m is a natural number, is a square only
when m = 3.
30∗If m is a natural number greater than 1, show that every natural number N can be uniquely
represented in the form
N = c0 + c1m + c2m2 + · · · + ckmk
(when k = 0, N = c0), where the coefficients ci are integers satisfying the conditions 0 ≤ci <
m (i = 0‚ 1‚ …‚ k −1) and 0 < ck < m.
This statement means that every natural number can be uniquely represented in a number
system with a base m for every natural m > 1.
31∗Let a‚ b‚ c‚ A‚ B‚ C be integers such that gcd(a‚ b) = c and gcd(A‚ B) = C. Show that
gcd(aA‚ aB‚ Ab‚ AB) = cC.
32∗Let k be any natural number and an = k2n + 1. Show that if m ≠n then gcd(am‚ an) = 1 if k is
even; otherwise gcd(am‚ an) = 2.
33∗Let a > 1 and m be natural numbers. Show that
gcd
(
am −1
a −1 ‚ a −1
)
= gcd(a −1‚ m).
Pythagoras of Samos (c. 570 BC–c. 495 BC)
Pythagoras was an ancient Greek mathematician and philosopher,
founder of the religious movement called Pythagoreanism. He
made important contributions to mathematics, astronomy, religion
and music.
Pythagoras left Samos at the age of 40 and, after years of travel-
ling and religious studies in Egypt and Babilon, settled in Crotona,
a Greek colony in southern Italy, where he founded a philosophi-
cal and religious school and a secret society, engaging in a mix of
mathematics, religion and mysticism. Pythagoras believed that all
things are (positive) integers and proportions between them, that
mathematics is the basis for everything and the physical world can
be understood through mathematics, and that geometry is the highest form of mathematical stud-
ies. He also believed that numbers have personalities, characteristics, strengths and weaknesses.
However, in his time Pythagoras was famous not so much as a mathematician but rather as a magi-
cian and religious leader, who claimed that the soul resides in the brain, is immortal and moves
through a series of reincarnations, sometimes from humans to animals.
Pythagoras and his followers made many discoveries in geometry and arithmetic, including
possibly the discovery of irrational numbers, as the first proof that the length of the diagonal of a
square is not commensurable with the length of its side is attributed to the Pythagorean school, even
though it contradicts their belief that only ratios between integers, i.e. rational numbers, existed.
It is believed that Pythagoras knew the five regular (also known as Platonic) solids: tetrahedron,
cube, octahedron, icosahedron, dodecahedron, and that he knew how to construct the first three of
them. Pythagoras also related music to mathematics and discovered that vibrating strings sounded
harmoniously when the lengths of the strings were proportional to whole numbers, e.g. 2:1, 3:2, 4:3.

230
Logic and Discrete Mathematics: A Concise Introduction
However, Pythagoras is probably most famous with proving, perhaps the first ever, geometric
result – now called Pythagoras theorem but known to the Babylonians more than a 1000 years ear-
lier – that in a right-angled triangle the square of the hypotenuse is equal to the sum of the squares
of the other two sides. Here is a purely pictorial proof of Pythagoras theorem:
a
a
a
a
b
b
b
c
c
c
c
c2
c2 = a2 + b2
a2
b2
5.3.
Computing greatest common divisors. Least common multiples
5.3.1.
Euclid’s algorithm for computing greatest common divisors
Now we know many properties of the greatest common divisor of two integers, but still the
main question remains: how to compute it? Due to properties (GCD1), (GCD2) and (GCD3) in
Theorem 5.2.6 we see that it is sufficient to be able to compute the greatest common divi-
sor for positive integers; then we can do so for any integers. For instance, gcd(−123‚ −321) =
gcd(123‚ 321).
We are going to present a simple and elegant recursive procedure for computing the great-
est common divisor of two integers, going back to Euclid over 2300 years ago, based on the
following property.
Theorem 5.3.1 Let a > b > 0 be integers and r be the remainder of the division of a by b. Then
gcd(a‚ b) = gcd(r‚ b).
Proof: The proof is left as an exercise.
Theorem 5.3.2 (The Euclidean algorithm) Let a and b be positive integers. The following proce-
dure computes gcd(a‚ b).
1. Set X ∶= max(a‚ b) and Y ∶= min(a‚ b).
2. Divide X by Y with a remainder: X = QY + R, where 0 ≤R < Y.
3. If R = 0 then gcd(a‚ b) = Y and the procedure ends.
4. If R > 0 put X ∶= Y, then Y ∶= R, and go to step 2.

Number Theory
231
Before we show why this algorithm works, let us see how it works on a particular example.
Example 5.3.3
To find gcd(30‚ 102) using the Euclidean algorithm we follow the procedure:
Set X ∶= 102 and Y ∶= 30.
Divide X by Y with a remainder: 102 = 3.30 + 12.
The remainder is not 0; hence X ∶= 30 and Y ∶= 12.
Divide X by Y with a remainder: 30 = 2.12 + 6.
The remainder is not 0; hence X ∶= 12 and Y ∶= 6.
Divide X by Y with a remainder: 12 = 2.6 + 0.
The remainder is 0; hence gcd(30‚ 102) = Y = 6.
End of the procedure.
Now let us prove that the Euclidean algorithm works as it should, i.e. to verify its correct-
ness. We must check two things:
1. Partial correctness: for any two positive integers, if the procedure ends the result is
indeed their greatest common divisor.
Let us first observe that at any stage of the execution of the algorithm, gcd(X‚ Y)
remains equal to gcd(a‚ b).2 At the beginning this is trivially so. The only changes
of the values of X and Y occur at step 4. There the pair (X‚ Y) is replaced by (Y‚ R),
where R = X −QY is the remainder of the division of X by Y. Hence we only need to
check that
gcd(X‚ Y) = gcd(Y‚ R)‚
which follows from Theorem 5.3.1 and (GCD1) in Theorem 5.2.6.
Thus, gcd(X‚ Y) is always equal to gcd(a‚ b). It remains to show that whenever the
procedure ends, the result is what we need. The procedure ends only if the remainder
R becomes 0, i.e. the values of X and Y become such that Y ∣X. Then the result is Y,
which is indeed gcd(X‚ Y), due to (GCD2).
2. Termination: for any two natural numbers a‚ b the procedure ends.
Suppose that for some natural numbers a‚ b the procedure never ends. This can only
happen if step 4 (the only one that sends the execution back) is executed infinitely
many times. Let us notice two things:
(a) Each time when step 4 is executed, the value of X strictly decreases, being replaced
by the value of Y. Indeed, X ≥Y is always the case, and if X = Y then R becomes 0.
2 In computer science terms, gcd(X‚ Y) is an invariant of the algorithm.

232
Logic and Discrete Mathematics: A Concise Introduction
(b) The values of X and Y always remain natural numbers. Thus, the consecutive val-
ues of X form an infinite, strictly decreasing sequence of positive integers. Due to
the principle of descending chains of natural numbers, this is impossible because
the set of elements in such a sequence has no least element. Therefore, the proce-
dure must terminate.
Finally, we note that the Euclidean algorithm also produces coefficients u and v such that
gcd(a‚ b) = ua + vb. Indeed, suppose a > b > 0 and the algorithm goes through the steps
(1)
a = q0b + r1,
(2)
b = q1r1 + r2,
…
(k)
rk−1 = qkrk + rk+1,
(k+1)
rk = qk+1rk+1,
so that gcd(a‚ b) = rk+1.
From equation (k) we get rk+1 = rk−1 −qkrk, i.e. obtain gcd(a‚ b) as a linear combination of
rk−1 and rk. Then, from equation (k −1) we find rk = rk−2 −qk−1rk−1 and, eliminating rk, we
obtain gcd(a‚ b) as a linear combination of rk−2 and rk−1, etc. Thus, working backwards we
eventually obtain gcd(a‚ b) in the form ua + vb for some u and v.
For instance, from Example 5.3.3 we find that gcd(30‚ 102) = 6 = 30 −2 × 12 = 30 −2(102 −
3 × 30) = 7 × 30 −2 × 102.
5.3.2.
Least common multiple
Definition 5.3.4 An integer m is a common multiple of the integers a and b if a ∣m and b ∣m. The
least positive number amongst the common multiples of a and b, if it exists, is called the least common
multiple of a and b, denoted lcm(a‚b).
Note that if a and b are nonzero then lcm(a‚b) always exists. Indeed, the collection of pos-
itive common multiples of a and b is nonempty, since |ab| belongs to it. Therefore, by the
principle of well-ordering of natural numbers, there is a least number in that collection.
Theorem 5.3.5 (Basic properties of the least common multiple) For any integers a‚ b‚ c‚ n∶
(LCM1) lcm(a‚b) = lcm(b‚a).
(LCM2) If a ∣b then lcm(a‚b) = ∣b∣.
(LCM3) lcm(a‚b) = lcm(a‚ −b) = lcm(−a‚b) = lcm(−a‚ −b).
(LCM4) lcm(na‚nb) = ∣n∣lcm(a‚b).
(LCM5) lcm(lcm(a‚b)‚ c) = lcm(a‚lcm(b‚c)).
Proof: Verifying these properties is routine and left as an exercise.

Number Theory
233
One can likewise introduce a least common multiple of several integers a1‚ a2‚ …‚ ak,
denoted by lcm(a1‚ a2‚ …‚ ak).
Theorem 5.3.6 For any nonzero integers a1‚ a2‚ …‚ ak, lcm(a1‚ a2‚ …‚ ak) divides each of their common
multiples.
Proof: Let m = lcm(a1‚ a2‚ …‚ ak) and n be a common multiple of a1‚ a2‚ …‚ ak. Let us divide n by
m with a remainder: n = mq + r‚ 0 ≤r < m. Then r = n −mq = 1.n + (−q)m. Hence, by (D5) in
Theorem 5.2.2, r must be a common multiple of a1‚ a2‚ …‚ ak that is less than m. Therefore r = 0
and hence m ∣n.
Theorem 5.3.7 For every pair of positive integers a and b:
gcd(a‚b) =
ab
lcm(a‚b).
Proof: Let g = gcd(a‚ b), m = lcm(a‚b) and d = ab
m . Then a = m
b d and b = m
a d, where m
b and m
a are
integers. Therefore d is a common divisor of a and b. By property (GCD8) in Theorem 5.2.6,
d ∣g , i.e. g = dk for some positive integer k. Then
m
k = md
g = ab
g ‚
which is an integer. Moreover, m
k is a positive common multiple of a and b ∶
m
k = a
gb = b
ga‚
where a
g and b
g are integers. Since m is the least positive common multiple of a and b, it follows
that m ≤m
k ‚ which is possible only if k = 1. Thus g = d.
Example 5.3.8
Find lcm(28‚ 42).
Solution
Using the Euclidean algorithm we find gcd(28‚ 42) = 14; hence lcm(28‚ 42) = 28×42
14
= 84.
5.3.3.
Exercises
➊
Prove Theorem 5.3.1.
➋
Using the Euclidean algorithm, find
(a) gcd(70‚ 112).
(b) gcd(258‚ 801).

234
Logic and Discrete Mathematics: A Concise Introduction
(c) gcd(7469‚ 2464).
(d) gcd(2689‚ 4001).
➌
Show that the product of every
(a) 3 consecutive integers is divisible by 6.
(b) 4 consecutive integers is divisible by 24.
(c) 5 consecutive integers is divisible by 120.
➍
Prove that for every integer n:
(a) 6 ∣n3 −n.
(b) 30 ∣n5 −n.
(c) 120 ∣n5 −5n3 + 4n.
➎
Verify the basic properties of the least common multiple listed in Theorem 5.3.5.
➏
Find:
(a) lcm(70‚ 71).
(b) lcm(630‚ 1344).
➐
Let n be a natural number. Find lcm(n‚n + 1).
➑
Let m and n be natural numbers such that gcd(m‚ n) = lcm(m‚n). Show that m = n.
➒
Show that lcm(a1‚ a2‚ …‚ ak) = lcm(a1‚ lcm(a2‚ …‚ ak)).
➓
Find all pairs of natural numbers m‚ n for which gcd(m‚ n) = 10 and lcm(m‚n) = 100.
11∗Prove that for any natural number n,
lcm(1‚ 2‚ 3‚ ….,2n) = lcm(n + 1‚ n + 2‚ …‚ 2n).
12∗Prove that for any natural numbers m and n,
lcm(1‚ 2‚ …m‚n‚n + 1‚ …‚ n + m −1) = lcm(n‚n + 1‚ …n + m −1).
13∗Let m and n be natural numbers. Show that
gcd(m‚ n) = 1 iff gcd(2m −1‚ 2n −1) = 1.
14∗Let a‚ b‚ m‚ n be natural numbers such that a > 1 and gcd(a‚ b) = 1. Prove that if am + bm
∣an + bn then m ∣n.
15∗Find all pairs of natural numbers ⟨x‚ y⟩satisfying the equation 2x = 3y + 5.

Number Theory
235
Euclid of Alexandria (c. 325 BC–c. 265 BC)
Euclid was the most prominent and influential mathematician of
ancient Greece. He wrote the monumental 13-book work, known as
the Elements, in which he systematically laid the sound foundations of
both geometry and arithmetic. The Elements encompassed the system
of postulates and theorems for what is now called Euclidean geome-
try and is probably the most influential book written in the history of
mathematics, still used as the classic textbook for the study of geome-
try until the end of the 19th century, when David Hilbert revised and
modernized it.
The first book of the Elements contains 5 pos-
tulates for points and lines in the plane. The fifth
postulate is the famous Parallel Postulate, stating
that for every line and for every point that does not
lie on that line there exists a unique line through
the point that is parallel to the given line. Since
it was not as simple to state and obvious as the
other postulates, Euclid himself and many math-
ematicians after him tried for two millennia to
derive it from the other four postulates. However,
all these attempts were futile and only in the early
19th century did Gauss, Lobachevski and Bolyai
show independently that negations of this postu-
late lead to the development of consistent, alter-
native non-Euclidean geometries, like elliptic and
hyperbolic geometries.
The many fundamental contributions to num-
ber theory in the Elements include the study of
prime numbers and Euclid’s celebrated proof of
the infinitude of prime numbers, Euclid’s lemma
on factorization and, of course, the Euclidean pro-
cedure for computing the greatest common divi-
sor of two integers, given in Theorem 5.3.2. This
procedure was one of the first and most famous
instances of what is nowadays called an algorithm.
Here is a copy of the first few definitions and
postulates from an 1838 edition of Euclid’s Ele-
ments, published by Robert Simson in Philadel-
phia, USA:

236
Logic and Discrete Mathematics: A Concise Introduction
5.4.
Prime numbers. The fundamental theorem of arithmetic
5.4.1.
Relatively prime numbers
The integers a and b are called relatively prime if
gcd(a‚ b) = 1.
For instance 8 and 15 are relatively prime, while 9 and 15 are not.
The following theorem will summarize those properties of relatively prime numbers
which will be used further on.
Theorem 5.4.1 (Basic properties of relatively prime numbers) For all integers a‚ b and c:
(RP1) If c ∣a and gcd(a‚ b) = 1 then gcd(c‚ b) = 1.
(RP2) If c ∣ab and gcd(c‚ a) = 1 then c ∣b.
(RP3) If gcd(a‚ b) = 1 then gcd(a‚ bc) = gcd(a‚ c).
(RP4) gcd(a‚ bc) = 1 if and only if gcd(a‚ b) = 1 and gcd(a‚ c) = 1.
(RP5) If gcd(a‚ b) = 1 then ab ∣c if and only if a ∣c and b ∣c.
Proof:
(RP1) Every common divisor of c and b is also a common divisor of a and b.
(RP2) Assume that c ∣ab and gcd(c‚ a) = 1. Then ab = kc for some integer k and 1 = uc + va
for some integers u and v. Multiplying the latter equality by b we get
b = ubc + vab = ubc + vkc = (ub + vk)c;
hence c ∣b.
(RP3) Let gcd(a‚ b) = 1, gcd(a‚ bc) = d1 and gcd(a‚ c) = d2. Then d2 ∣d1 because d2 ∣a and d2 ∣
bc. On the other hand, d1 must be relatively prime to b because d1 ∣a. Hence, by (RP1),
d1 ∣c since d1 ∣bc. Therefore d1 ∣d2 and hence d1 = d2 because d1‚ d2 > 0.
(RP4) If gcd(a‚ bc) = 1 then gcd(a‚ b) = 1 and gcd(a‚ c) = 1 since every divisor of gcd(a‚ b) or
gcd(a‚ c) is a divisor of gcd(a‚ bc). Conversely, if gcd(a‚ b) = 1 and gcd(a‚ c) = 1 then,
by (RP2), gcd(a‚ bc) = gcd(a‚ c) = 1.
(RP5) If ab ∣c then a ∣c and b ∣c. Now, let gcd(a‚ b) = 1 and suppose that a ∣c and b ∣c. Then
c = ak for some integer k and b ∣ak. Therefore, by (RP2), b ∣k and hence ab ∣ak, i.e.
ab ∣c.
Definition 5.4.2 Natural numbers a1‚ …‚ an are said to be:
• relatively prime if gcd(a1‚ …‚ an) = 1;
• relatively prime in pairs if every two of them are relatively prime.
Obviously, if the integers a1‚ …‚ an are relatively prime in pairs then they are relatively
prime. The converse, however, is not generally true (see Exercise 1 at the end of this section).

Number Theory
237
5.4.2.
Prime numbers
Definition 5.4.3 A natural number p > 1 is called a prime number if it has exactly two different
positive divisors: 1 and p (called the trivial divisors of p). Otherwise p is called a composite number.
For instance, 2, 3, 5, 37, 101, 2011 are primes; 4, 189, 1001, 2013 are composite (check that).
Note that 1 is neither prime nor composite by this definition.
Theorem 5.4.4 Every natural number greater than 1 has a prime divisor.
Proof: Assume the contrary: there are natural numbers greater than 1 without any prime divi-
sors. Let m be the least of them. Since m ∣m, m cannot be prime; hence it is composite, i.e. has
a positive divisor n, different from 1 and from m. Then 1 < n < m and hence n must have a
prime divisor p. Thus p ∣n and n ∣m and hence p ∣m, which is a contradiction. Therefore there
is no such m.
Remark 4 In fact, every composite number n has a prime divisor not greater than
√
n. Indeed, let
n = n1n2 where n1‚ n2 > 1. Then at least one of n1 and n2, assume n1, is not greater than
√
n. Now, n1
has a prime divisor, which is of course not greater than n1 and is also a divisor of n.
Theorem 5.4.5 (Euclid, about 2350 years ago) There are infinitely many prime numbers.
Proof: Assume the contrary: there are only finitely many primes and let p1‚ p2‚ …‚ pk be a list of
all of them. Now, consider the number
N = p1p2…pk + 1.
Since N is greater than each of p1‚ p2‚ …‚ pk it must be composite. By the previous theorem,
N has a prime divisor p, which must be some of p1‚ p2‚ …‚ pk, for instance p = pi. Then pi ∣N
and pi ∣p1p2 · · · pk since pi occurs as a factor in p1p2 · · · pk. Hence, by (D5) in Theorem 5.2.2,
pi ∣(N −p1p2 · · · pk), i.e. pi ∣1, which is impossible since every prime is greater than 1. Therefore
we must conclude that there are infinitely many primes.
Theorem 5.4.6 For all positive integers a and b and a prime p:
1. Either p ∣a or gcd(p‚ a) = 1.
2. If p ∣ab then p divides at least one of a and b.
Proof:
1. gcd(p‚ a) can only be either p or 1.
2. If p ∤a then (p‚ a) = 1 and hence, by (RP2) in Theorem 5.4.1, p ∣b.
The last property can easily be generalized by induction to the following theorem.
Theorem 5.4.7 For all natural numbers a1‚ …‚ ak and a prime p, if p ∣a1 · · · ak then p divides at least
one of a1‚ …‚ ak.
Proof: The proof is left as an exercise.

238
Logic and Discrete Mathematics: A Concise Introduction
5.4.3.
The fundamental theorem of arithmetic
The notion of prime number is pivotal in number theory. As we will see from the next theorem,
the prime numbers are like “elementary particles” from which all natural numbers are built.
Theorem 5.4.8 (Fundamental theorem of arithmetic) Every natural number n > 1 can be decom-
posed into a product of primes:
n = p1 · · · pk‚ k ≥1.
Moreover, this decomposition is unique, up to the order of the factors.
Proof: We can apply the principle of (complete) mathematical induction. Assume that the
theorem holds for all natural numbers m such that m < n. We must show that it also holds
for n. If n = 1 nothing is claimed, so that this case is trivially true. Now, let n > 1. Then n has
prime divisors. Let p1 be the least of them. Then n = p1n1 and n1 < n. If n1 = 1 then n = p1 is
prime and this is the decomposition of n; it is unique since p1 cannot be expressed as a prod-
uct of two or more primes. Now, if 1 < n1 then, according to the inductive assumption, n1 is
decomposed into a product of primes: n1 = p2 · · · pk. Then we have a decomposition of n:
n = p1p2 · · · pk.
Now, for the uniqueness. Suppose that besides this decomposition of n there is another one:
n = q1 · · · qm. Then
p1 · · · pk = q1 · · · qm.
Thus p1 ∣q1 · · · qm, and hence p1 divides some of the factors q1‚ …‚ qm, by Theorem 5.4.7. We
may assume (possibly after reordering) that p1 ∣q1. This means that p1 = q1 since q1 is prime.
Then, after cancelling both sides by p1 we obtain:
p2 · · · pk = q2 · · · qm.
Again, the inductive assumption holds for the product p2 · · · pk, so q2‚ …‚ qm must be a reorder-
ing of p2 · · · pk. Hence k = m and q1‚ …‚ qm is a reordering of p1 · · · pk.
This completes the induction; hence the theorem is valid for every n > 1.
The above theorem can also be reformulated as follows.
Corollary 5.4.9 Every natural number n > 1 can be decomposed into a product of powers of different
primes:
n = p𝛼1
1 · · · p𝛼k
k ‚ 𝛼1‚ …‚ 𝛼k‚ k ≥1.
Furthermore, this decomposition is unique up to the order of the factors.
Theorem 5.4.10 Let n = p𝛼1
1 · · · p𝛼k
k and m = p𝛽1
1 · · · p𝛽k
k be decompositions of m and n in products of
primes, where p1‚ p2‚ …‚ pk are different and some of the 𝛼′s and 𝛽′s can be 0. Then:
1. n ∣m iff 𝛼1 ≤𝛽1‚ …‚ 𝛼k ≤𝛽k.
2. gcd(m‚ n) = p𝛾1
1 · · · p𝛾k
k and lcm(m‚n) = p𝛿1
1 · · · p𝛿k
k , where 𝛾i = min(𝛼i‚ 𝛽i) and 𝛿i = max(𝛼i‚ 𝛽i),
for i = 1‚ …‚ k.

Number Theory
239
Proof:
1. If n ∣m then p𝛼i
i ∣m, i.e. p𝛼i
i ∣p𝛽1
1 · · · p𝛽i
i · · · p𝛽k
k . However, gcd(p𝛼i
i ‚ p
𝛽j
j ) = 1 for every j ≠i and
hence p𝛼i
i ∣p𝛽i
i , by repeated application of Theorem 5.4.1 (RP2). Thus, 𝛼i ≤𝛽i.
Conversely, if 𝛼i ≤𝛽i for every i = 1‚ …‚ k, then m = nq where q = p𝛽1−𝛼1
1
· · · p𝛽k−𝛼k
k
; hence
n ∣m.
2. This follows easily from (1) and is left as an exercise.
Example 5.4.11
If n = 9800 = 23 × 52 × 72 and m = 14 742 = 2 × 34 × 7 × 13 then we can represent them as n =
23 × 30 × 52 × 72 × 130 and m = 21 × 34 × 50 × 71 × 131. Then, using Theorem 5.4.10, we obtain
gcd(m‚ n) = 21 × 30 × 50 × 71 × 130 = 14 and lcm(m‚n) = 23 × 34 × 52 × 72 × 131 = 10 319 400.
5.4.4.
On the distribution of prime numbers
Looking at the sequence of primes one can see that they are rather irregularly scattered amidst
the natural numbers. On the one hand, there are many (a hypothesis says infinitely many)
so-called prime twins, i.e. pairs of primes that differ by 2. On the other hand, there are arbi-
trarily large “gaps”, i.e. sequences of natural numbers without any primes.
Proposition 5.4.12 For any positive integer k there is a sequence of k consecutive composite natural
numbers.
Proof: We leave as an exercise to show that for any positive integer k, all numbers (k + 1)! +
2‚ …‚ (k + 1)! + k‚ (k + 1)! + (k + 1) are composite.
Finally, we state without proofs (which are too complex to be presented here) some impor-
tant and very useful facts about the distribution of primes. The first one was conjectured by
Bertrand in 1845 and proved by Tchebychef in 1850.
Theorem 5.4.13 For every integer n ≥4 there is at least one prime p such that n < p < 2n −2.
The second one is credited to Dirichlet.
Theorem 5.4.14 Every arithmetic progression a‚ a + d‚ a + 2d‚ …, where d > 0 and gcd(a‚ d) = 1,
contains infinitely many primes.
The last one, known as “the prime number theorem” and proved independently by
Hadamard and de la Vallée Poussin in 1896, gives an asymptotic estimate of the density of
the primes in the sequence of all natural numbers.

240
Logic and Discrete Mathematics: A Concise Introduction
Theorem 5.4.15 (The prime number theorem)
Let 𝜋(n) be the number of primes amongst
{1‚ …‚ n}. Then 𝜋(n) is asymptotically equal to n∕ln n, i.e.:
lim
n→∞
𝜋(n)
n∕ln n = 1.
Consequently, the probability of a randomly chosen number n to be prime is approxi-
mately
1
ln n.
The proof of the prime number theorem uses Riemann’s 𝜁function and methods of com-
plex analysis, and this links the distribution of the primes with one of the most famous still
unsolved problems in mathematics, the Riemann hypothesis.
5.4.5.
Exercises
➊
.(a) Find three integers that are relatively prime but no two of them are relatively prime.
(b) Find four integers that are relatively prime but no three of them are relatively prime.
(c) Find four integers such that every three but no two of them are relatively prime.
➋
Show that amongst any 5 consecutive integers there is at least one that is relatively prime
to each of the others.
➌
Factor by hand each of the following integers into products of primes:
(a) 128
(b) 129
(c) 728
(d) 1599 (Hint: 1599 = 1600 −1)
(e) 8532
➍
Prove Claim 2 of Theorem 5.4.10.
➎
Using Theorem 5.4.10 determine the following:
(a) gcd(60‚ 144) and lcm(60‚ 144).
(b) gcd(728‚ 8532) and lcm(728‚ 8532).
➏
If p ≥q ≥5 are primes, show that:
(a) 3 ∣p + q or 3 ∣p −q.
(b) 24 ∣p2 −q2.
➐
Prove that if p is prime and 0 < k < p then p ∣
(
p
k
)
.
➑
Without using Dirichlet’s Theorem 5.4.14, show that there are infinitely many primes of
the form
(a) 4n + 3.
(b) 6n + 5.
Hint: assume the contrary and apply an argument similar to the proof of Theorem 5.4.5.

Number Theory
241
➒
Show that if a prime is divided by 30 the remainder is either 1 or a prime. Is this true if 30
is replaced by 60?
➓
For any prime p other than 2 and 5 prove that p divides infinitely many of the integers
11‚ 111‚ … .
11
If pn denotes the nth prime in the sequence of natural numbers, prove the inequality
pn < 22n.
Hint: use the idea of the proof of Theorem 5.4.8.
12
Prove that for every n > 2 there is a prime p such that n < p < n!.
13∗If gcd(a‚ b) = 1 show that gcd(a + b‚ a2 −ab + b2) is either 1 or 3.
14
Show that if the number 2p −1 is a prime then p is a prime.
Prime numbers of the kind 2p −1 are called Mersenne primes.
15
Show that if the number 2n + 1 is a prime then n is a power of 2.
Prime numbers of the kind 22k + 1 are called Fermat primes.
16
Show that for any integers a and b,
gcd(a‚ b) = gcd(a + b‚ lcm(a‚b)).
17
Using Theorem 5.4.10 prove the following identities for any natural numbers a‚ b‚ c.
(a) gcd(a‚lcm(b‚c)) = lcm(gcd(a‚b)‚ gcd(a‚c))
(b) lcm(a‚ gcd(b‚c)) = gcd(lcm(a‚b)‚ lcm(a‚c))
(c) lcm((gcd(a‚b)‚ gcd(b‚c)‚ gcd(c‚a)) = gcd(lcm(a‚b)‚ lcm(b‚c)‚ lcm(c‚a))
(d) lcm(a‚b‚c) =
abc
gcd(ab‚bc‚ca)
(e)
(lcm(a‚b‚c))2
lcm(a‚b)lcm(b‚c)lcm(c‚a) =
(gcd(a‚b‚c))2
gcd(a‚b) gcd(b‚c) gcd(c‚a)
18
Let m1‚ …‚ mn be natural numbers, M = m1 · · · mnand Mi = M
mi , for i = 1‚ 2‚ …, n. Prove that
m1‚ …‚ mn are relatively prime in pairs if and only if gcd(M1‚ …‚ Mn) = 1.
19
A natural number n is a perfect kth power if n = ak for some natural number a. Prove that
if m and n are natural numbers such that gcd(m‚ n) = 1 and mn is a perfect kth power for
some k ≥2 then m and n are perfect kth powers.
20∗Show that the sequence {2n −3 ∣n = 2‚ 3‚ 4‚ …} contains infinitely many numbers relatively
prime in pairs.3
21∗A sequence of natural numbers is defined by the following recurrent equation: t1 = 2 and
tn+1 = t2
n −tn + 1. Show that if m ≠n then gcd(tm‚ tn) = 1.
22∗Prove that amongst any 16 consecutive integers there is one that is relatively prime to each
of the others.
23∗A natural number m is called perfect if it equals the sum of its proper positive divisors (i.e.
all positive divisors of m excluding m itself). For example, 6 = 1 + 2 + 3 and 28 = 1 + 2 + 4
+ 7 + 14 are perfect numbers.
Prove the following theorem (Euclid, Elementa, Book 9):
If 2m −1 is a prime then 2m−1(2m −1) is a perfect number.
3 This was Problem 3 from the 13th IMO in Czechoslovakia, 1971.

242
Logic and Discrete Mathematics: A Concise Introduction
24∗If a‚ m‚ n are natural numbers, a > 1 and gcd(m‚ n) = d, show that
gcd(am −1‚ an −1) = ad −1.
25
Let n and k ≥2 be natural numbers. Show that there exist n consecutive natural numbers
each of which can be factorized in a product of at least k (not necessarily different) prime
divisors.
Primality testing
An important problem in number theory is the detection of primes amongst the natural numbers.
It was perhaps the Greek mathematician Eratosthenes (circa 200 BC) who first introduced a general
method to single out the primes in the sequence of natural numbers, called now the Sieve of Eratos-
thenes. It is very simple and works as follows: in order to list the prime numbers between 1 and n
we take the sequence of all natural numbers from 1 to n and cross out all multiples of 2 except 2,
then all multiples of the next noncrossed number, viz. 3, except 3 itself, and so on, until we have
deleted all numbers divisible by any natural number not greater than
√
n (recall the remark after
Theorem 5.4.4). The remaining numbers are precisely the primes between 1 and n.
Since Eratosthenes, a number of increasingly more efficient methods and algorithms have
been discovered for testing primality. One of the most popular and practically useful is the
Miller – Rabin Randomized Primality Test. Being a probabilistic algorithm, it always gives the
correct answer when the input number is prime, but with a probability that can be made arbitrarily
small it may return an incorrect answer when the input number is not prime. The number theory
behind the algorithm can be understood by everyone who has learned the material covered in this
chapter, and is very short and easy to grasp. Here is a pseudocode of the algorithm (copied from
the Wikipedia article):
Until the early 2000s it was not known whether there is a deterministic algorithm for primal-
ity testing running in polynomial time (i.e. in the number of steps bounded by a polynomial on
the number of digits of the input) and many believed that such an algorithm did not exist. There-
fore, it came as somewhat of a surprise when the first such deterministic algorithm for primality
testing was discovered in 2002 by Manindra Agrawal, Neeraj Kayal and Nitin Saxena. The result
was announced in the paper: PRIMES is in P, Annals of Mathematics, 2004, 160 (2): 781–793. It is
only 9 pages long and most of it is accessible with the knowledge acquired in this chapter. While
this method, being deterministic, is theoretically superior to probabilistic primality testing, as it
always gives the correct result in a time that is considered reasonable, the Miller – Rabin test is still
practically more efficient.

Number Theory
243
5.5.
Congruence relations
Here we will develop a very convenient and powerful method for expressing and solving
problems in number theory.
Definition 5.5.1 Let a‚ b‚ n be integers and n > 0. If n ∣a −b then a and b are said to be congruent
modulo n, denoted
a ≡b (mod n).
An expression like this is called a congruence (modulo n). We also say that b is a residue of a modulo
n.
Lemma 5.5.2 a ≡b (mod n) iff a and b leave the same remainder when divided by n.
Proof: Let a = qan + ra and b = qbn + rb where 0 ≤ra‚ rb < n. Then a −b = (qa −qb)n + (ra −rb).
Therefore, if ra = rb then n ∣a −b, so a ≡b (mod n). Conversely, if a ≡b (mod n) then n ∣a −b;
hence n ∣ra −rb, but |ra −rb| < n, and thus ra −rb = 0, i.e. ra = rb.
In particular, if a ≡b (mod n) and 0 ≤b < n then b is the remainder of the division of a by
n, hereafter called the remainder of a modulo n, also denoted a rem n.
As can be seen, using congruences is just another way to speak about divisibility. Thus
many properties of divisibility can easily be translated into properties of congruences.
Theorem 5.5.3 (Basic properties of congruences)
Let a‚ b‚ c‚ d‚ k‚ m‚ n be integers and n > 0.
Then:
(CON1) a ≡b (mod n) iff a −b ≡0 (mod n).
(CON2) a ≡a (mod n).
(CON3) If a ≡b (mod n) then b ≡a (mod n).
(CON4) If a ≡b (mod n) and b ≡c (mod n) then a ≡c (mod n).
(CON5) If a ≡b (mod n) then a + c ≡b + c (mod n), a −c ≡b −c (mod n) and
ac ≡bc (mod n).
(CON6) If a ≡b (mod n) and c ≡d (mod n) then ak + cm ≡bk + dm (mod n).
In particular, a + c ≡b + d (mod n) and a −c ≡b −d (mod n).
(CON7) If a ≡b (mod n) and c ≡d (mod n) then ac ≡bd (mod n).
(CON8) If a ≡b (mod n) and n ≥0 then ak ≡bk (mod n).
(CON9) If a ≡b (mod n) and d ∣n, d > 0 then a ≡b (mod d).
(CON10) If a ≡b (mod n) and c > 0 then ac ≡bc (mod nc).

244
Logic and Discrete Mathematics: A Concise Introduction
Proof: All these properties are easy consequences from the definition of a congruence and the
basic properties of divisibility. Let us verify just two of them:
(CON6) Let a ≡b (mod n) and c ≡d (mod n). Then n ∣a −b and n ∣c −d. Therefore n ∣ak −
bk and n ∣cm −dm and hence n ∣(ak −bk) + (cm −dm), i.e. n ∣(ak + cm) −(bk + dm),
which means that ak + cm ≡bk + dm (mod n).
(CON7) Again n ∣a −b and n ∣c −d and hence n ∣(a −b)c and n ∣(c −d)b. Therefore n ∣(a −
b)c −(c −d)b, i.e. n ∣ac −bd, so ac ≡bd (mod n).
The proof of the remaining properties are left as an exercise.
Here are some examples demonstrating the power of congruences.
Example 5.5.4
Find the remainder 7 000 000 000 rem 11.
Solution
7 000 000 000 = 7 × 109. Given that 10 ≡−1 (mod 11) we apply (CON8) and obtain
109 ≡(−1)9 = −1 (mod 11); hence 7 × 109 ≡7 × (−1) = −7 ≡4 (mod 11). Thus, the answer
is 4.
Example 5.5.5
Find the last digit of 12344321.
Solution
Firstly, notice that the last digit (in decimal notation) of any natural number is the remainder
of that number modulo 10. Therefore we have to solve for x the congruence
12344321 ≡x (mod 10)‚
0 ≤x < 10.
Since 1234 ≡4 (mod 10), by (CON8) that is equivalent to
44321 ≡x (mod 10).
Let us list the first few powers of 4 modulo 10 ∶
41 ≡4 (mod 10), 42 = 16 ≡6 (mod 10), 43 = 64 ≡4 (mod 10), 44 = 43 × 4 ≡4 × 4 = 6
(mod 10), etc.
We see that the odd powers of 4 leave a remainder 4, while the even powers of 4 leave a
remainder 6 modulo 10. Therefore, 44321 ≡4 (mod 10).

Number Theory
245
Example 5.5.6
Find the last two digits of 7777.
Solution
The last two digits in decimal notation of any natural number form the remainder of that
number modulo 100. Therefore we have to solve for x the congruence
7777
≡x (mod 100)‚
0 ≤x < 100.
The idea is to start with some power of 7 that has a small remainder modulo 100, preferably
1 or −1, and then to raise that congruence to a power close to 7777. We are lucky to find that
74 = 2401 ≡1 (mod 100).
Now we want to raise this congruence to some power x such that (74)x = 74x is as close as
possible to 7777. Then we would get 74x ≡1x = 1 (mod 100) and, supposing that 777 = 4x + y,
then 7777 = 74x × 7y, from where
7777
≡7y (mod 100).
Thus we can reduce our problem to finding the remainder y = (777 rem 4), i.e. solving for y
the congruence
777 ≡y (mod 4)‚
0 ≤y < 4.
We have 7 ≡−1 (mod 4) and hence 777 ≡(−1)77 = −1 ≡3 (mod 4). Therefore
7777
≡73 = 343 ≡43 (mod 100).
Thus, the last two digits of 7777 are 43.
We see that in a way congruences behave like equalities with respect to addition, subtrac-
tion and multiplication. With division, however, the matter is more delicate. Instead of the
usual cancellation law, the following holds.
Theorem 5.5.7 For all integers a‚ x‚ y and n > 0,
ax ≡ay (mod n)
if and only if
x ≡y
(
mod
n
gcd(a‚ n)
)
.
Proof: We may assume that a ≠0 and x ≠y; otherwise the statement is trivial. Now, if
ax ≡ay (mod n) then ax −ay = kn for some integer k ≠0. Therefore,
a
(a‚ n)(x −y) =
n
(a‚ n)k, and
thus
n
(a‚ n) ∣
a
(a‚ n)(x −y). However, gcd
(
n
(a‚ n)‚
a
(a‚ n)
)
= 1 by (GCD6). Therefore
n
(a‚ n) ∣(x −y), so
x ≡y
(
mod
n
gcd(a‚ n)
)
.

246
Logic and Discrete Mathematics: A Concise Introduction
Conversely, if x ≡y
(
mod
n
gcd(a‚ n)
)
then ax ≡ay
(
mod
an
gcd(a‚ n)
)
by (CON10) in Theorem
5.5.3. The number
a
gcd(a‚ n) is an integer and hence n ∣
an
gcd(a‚ n). Therefore ax ≡ay (mod n) by
(CON9).
For instance, 12x ≡12y (mod 30) if and only if x ≡y (mod 5).
As a consequence of Theorem 5.5.7 we obtain the following frequently used fact.
Corollary 5.5.8 If ax ≡ay (mod n) and (a‚ n) = 1, then x ≡y (mod n).
For example, if 45x ≡45y (mod 14) then x ≡y (mod 14).
Theorem 5.5.9 For any integers x‚ y and positive integers n1‚ n2‚ …‚ nk:
x ≡y (mod ni) for i = 1‚ 2‚ …‚ k if and only if x ≡y (mod lcm(n1‚ n2‚ …‚ nk)).
Proof: If x ≡y (mod ni) for i = 1‚ 2‚ …‚ k then ni ∣(x −y) for i = 1‚ 2‚ …‚ k. Thus x −y is a
common multiple of n1‚ n2‚ …‚ nk and hence lcm(n1‚ n2‚ …‚ nk) ∣x −y by Theorem 5.3.6, which
implies x ≡y (mod lcm(n1‚ n2‚ …‚ nk)). Conversely, if x ≡y (mod lcm(n1‚ n2‚ …‚ nk)) then
x ≡y (mod ni) for i = 1‚ 2‚ …‚ k, by (CON9).
5.5.1.
Exercises
➊
Prove all properties of congruences listed in Theorem 5.5.3.
➋
Show that:
(a) Every decimal number that is a square has one of the following for its units digit: 0, 1,
4, 5, 6, 9.
(b) Every decimal number that is a fourth power has one of the following for its units digit:
0, 1, 5, 6.
➌
Find
(a) the possible remainders modulo 8 of any square of an integer.
(b) the possible remainders modulo 7 of any cube of an integer.
➍
Find the last decimal digit of
(a) 2222.
(b) 3333.
(c) 7777.
➎
Prove that the number 3n2 −5, where n is an integer, can never be a perfect square. (Hint:
consider the remainder modulo 4.)
➏
Show that if x ≡y (mod n) then gcd(x‚ n) = gcd(y‚ n). Is the converse true?
➐
Show that any natural number n in decimal representation is divisible by

Number Theory
247
(a) 3 if and only if the sum of its digits is divisible by 3.
(b) 9 if and only if the sum of its digits is divisible by 9.
➑∗Prove that if p is prime and a‚ b are integers, then
(a + b)p ≡ap + bp (mod p).
➒∗Let A be the sum of the digits of the number 44444444 and B be the sum of the digits of A.
Find the sum of the digits of B. (All numbers are decimal.)4
➓∗N is a sum of the eighth powers of 100 consecutive natural numbers. Find the last digit
of N.
11∗Prove that 7 ∣(22225555 + 55552222).
12∗Find the last two digits of 2999 + 3999.
13∗Find the remainder modulo 7 of
1010 + 10(102) + · · · + 10(1010).
Julius Wilhelm Richard Dedekind (6.10.1831–12.2.1916)
Richard Dedekind was a German mathematician who made important con-
tributions to abstract algebra, number theory and the foundations of the real
numbers.
He studied and did his doctoral work under Gauss’ supervision in Göt-
tingen and submitted a thesis on the theory of Eulerian integrals, for which he
received his doctorate in 1852.
Dedekind made many important contributions to mathematics and to the
way that it is presented and studied today. One remarkable piece of work was
his redefinition of irrational numbers by means of Dedekind cuts on the real line. Another seminal
contribution, to abstract algebra, was his introduction of the fundamental notion of an ideal in ring
theory.
Dedekind’s mathematical heritage consists not only in the concepts he introduced and the
results he proved, but also in the new style of precision and rigour in mathematics that has strongly
influenced mathematicians ever since.
Here are two different impressions on how Dedekind cuts may look:
1
2
1
2
2
12
17
5
7
99
70
41
29
403
577
169
239
3
4 This was Problem 4 from the 17th IMO in Bulgaria, 1975.

248
Logic and Discrete Mathematics: A Concise Introduction
5.6.
Equivalence classes and residue systems modulo n
5.6.1.
Equivalence relations and partitions
The properties (CON2), (CON3) and (CON4) in Theorem 5.5.3 respectively say that the relation
“congruence” is:
• reflexive: a ≡a (mod n)‚
• symmetric: if a ≡b (mod n) then b ≡a (mod n)‚
• transitive: if a ≡b (mod n) and b ≡c (mod n) then a ≡c (mod n).
Recall from Section 2.5 that a binary relation on a set X which is reflexive, symmetric and
transitive is called an equivalence relation on X. Most of what follows here is a particular case
of the general relationship between equivalence relations and partitions developed in Section
2.5, but we nevertheless present it here to make this subsection self-contained.
The most common example of an equivalence relation is the equality. Another example, as
the properties (CON1), (CON2) and (CON3) show, is the “congruence modulo n” for any pos-
itive integer n, which is an equivalence relation in ℤ. We will come back to these equivalence
relations later. Before that we need some basic knowledge of equivalence relations.
Definition 5.6.1 A partition of a set X is a family of nonempty and pairwise disjoint subsets of X,
the union of which is X. The sets in a partition are called clusters of the partition.
For instance, {{1}‚ {2‚ 4‚ 6‚ 7}‚ {3‚ 5‚ 9}‚ {8}} is a partition of the set {1‚ 2‚ 3‚ 4‚ 5‚ 6‚ 7‚ 8‚ 9};
the sets of even and odd integers form a partition of the set of all integers.
Note (recall from Section 2.5) that every partition of a set X naturally defines an equiva-
lence relation ∼on X as follows: for every a‚ b ∈X‚ a∼b iff a and b belong to the same cluster
of P. On the other hand, we will show that every equivalence relation ∼in a set X defines a
partition of X.
Definition 5.6.2 Let ∼be an equivalence relation in a set X and x ∈X. The set
[[x]]∼= {y ∈X ∣x ∼y}
is called the equivalence class of x with respect to ∼.
Lemma 5.6.3 Let ∼be an equivalence relation in a set X. Then:
1. If x‚ y ∈X and y ∈[[x]]∼then [[x]]∼= [[y]]∼.
2. The family {[[x]]∼∣x ∈X} is a partition of X.
Proof:
1. Let y ∈[[x]]∼, so x ∼y, and hence y ∼x by symmetry. Moreover, for every z ∈X, if z ∈
[[x]]∼then x ∼z, and hence y ∼z by transitivity, so z ∈[[y]]∼; likewise, if z ∈[[y]]∼then
y ∼z, and hence x ∼z by transitivity, so z ∈[[x]]∼.Thus, [[x]]∼= [[y]]∼.

Number Theory
249
2. [[x]]∼is nonempty because x ∈[[x]]∼. For the same reason, the union of {[[x]]∼∣x ∈X}
is the whole X. It remains to show that every two equivalence classes [[x]]∼and [[y]]∼are
either disjoint or equal. Indeed, suppose that z ∈[[x]]∼∩[[y]]∼. Then [[z]]∼= [[x]]∼and
[[z]]∼= [[y]]∼; hence [[x]]∼= [[y]]∼.
Thus, equivalence relations and partitions are two sides of the same coin.
5.6.2.
Equivalence classes modulo n. Modular arithmetic
We now return to the[[endIndex]] equivalence relation “congruence modulo n” in ℤ,
which we hereafter denote by ≡n. The equivalence class of x with respect to ≡n will be
denoted by [[x]]n and will be called the equivalence class of x modulo n. For instance,
[[3]]5 = {…‚ −7‚ −2‚ 3‚ 8‚ 13‚ …}. Then, the set
ℤn = {[[x]]n ∣x ∈ℤ}
is called the set of integers modulo n.
By Lemma 5.5.2, [[x]]n = [[y]]n iff x and y leave the same remainders modulo n. There are
precisely n possible remainders modulo n: 0‚ 1‚ …‚ n −1. Therefore, ℤn has precisely n different
elements: [[0]]n‚ [[1]]n…‚ [[n −1]]n. Hereafter we will denote them by [0]n‚ [1]n…‚ [n −1]n, i.e.
ℤn = {[0]n‚ [1]n…‚ [n −1]n}.
Thus, [[x]]n = [a]n iff a = x rem n. For example, [[−7]]5 = [3]5 and [[42]]7 = [0]7.
Furthermore, we can define the operations of addition ⊕n and multiplication ⊙n in ℤn as
follows:
[[x]]n ⊕n [[y]]n = [[x + y]]n
and
[[x]]n ⊙n [[y]]n = [[x.y]]n.
For instance, in ℤ6∶[2]6 ⊕6 [5]6 = [[2 + 5]]6 = [[7]]6 = [1]6; [3]6 ⊙6[4]6 = [[3.4]]6 = [[12]]6 =
[0]6.
Hereafter we will omit the index n in ⊕n and ⊙n whenever clear from the context.
Lemma 5.6.4 In every ℤn ∶
1. ⊕is commutative and associative.
2. ⊙is commutative and associative.
3. ⊙is distributive over ⊕, i.e. [a]n ⊙([b]n ⊕[c]n) = ([a]n ⊙[b]n) ⊕([a]n ⊙[c]n).
4. [a]n ⊕[0]n = [a]n.
5. [a]n ⊙[0]n = [0]n.
6. [a]n ⊙[1]n = [a]n.
Proof: The proofs are left as exercises.

250
Logic and Discrete Mathematics: A Concise Introduction
Remark 5 The arithmetic of ℤn with ⊕and ⊙is called arithmetic modulo n, or simply modular
arithmetic.5 Lemma 5.6.4 shows that ⊕and ⊙satisfy most of the usual properties of addition and
multiplication of integers, while [0]n and [1]n behave with respect to these operations much like 0 and
1 in ℤ. On the other hand, unlike ℤ, in ℤn the product of two nonzero elements can be zero, e.g.
[2]4 ⊙[2]4 = [0]4.
5.6.3.
Residue systems
As already discussed, given a positive integer n, the set of all possible remainders modulo
n is {0‚ 1‚ 2‚ …‚ n −1}, i.e. every integer is congruent modulo n to exactly one number from
this set. The sets {1‚ 2‚ …‚ n}‚ {1‚ 3‚ 4‚ …‚ n‚ n + 2}‚ {−1‚ 0‚ …‚ n −2}, and infinitely many others,
have the same property. This observation leads us to the following definition.
Definition 5.6.5 Given a positive integer n, a set of integers {x1‚ …‚ xn} is called a complete residue
system modulo n if for every integer y there is exactly one xi such that xi is a residue of y modulo n,
i.e. y ≡xi (mod n).
The complete residue system modulo n {0‚ 1‚ 2‚ …‚ n −1} is called the primary residue system
modulo n.
Thus, a complete residue system modulo n contains exactly one representative of every
equivalence class modulo n. Of course the numbers x1‚ …‚ xn in a complete residue system
need not be consecutive. For instance, {−25‚ 13‚ 134‚ −1359‚ 2} is a complete residue system
modulo 5.
Lemma 5.6.6 For any positive integer n:
1. A set of n integers forms a complete residue system modulo n if and only if no two integers in the
set are congruent modulo n.
2. If {x1‚ …‚ xn} is a complete residue system modulo n then for any integer a, the set
{x1 + a‚ …‚ xn + a} is also a complete residue system modulo n.
3. If {x1‚ …‚ xn} is a complete residue system modulo n then for any integer a, {ax1‚ …‚ axn} is a
complete residue system modulo n if and only if gcd(a‚ n) = 1.
Proof: The first two claims are quite easy and are left as exercises. For the last one, first suppose
that {ax1‚ …‚ axn} is not a complete residue system modulo n; hence axi ≡axj (mod n) for some
i ≠j. Then n ∣a(xi −xj) and since gcd(a‚ n) = 1, it follows by property (RP2) in Theorem 5.4.1
that n ∣(xi −xj), which contradicts the assumption that {x1‚ …‚ xn} is a complete residue system
modulo n.
Conversely, let gcd(a‚ n) = d > 1. Then d ∣axi for every i = 1‚ …‚ n; hence none of ax1‚ …‚ axn
has a residue 1 modulo n, so {ax1‚ …‚ axn} is not a complete residue system modulo n.
Definition 5.6.7 Given a positive integer n, a reduced residue system modulo n is the subset of any
complete residue system modulo n, consisting only of those integers that are relatively prime to n.
5 Sometimes also called “clock arithmetic”, for one can think of the clock as presenting the time modulo 12 or 24
hours.

Number Theory
251
As we will see further, every two reduced residue systems modulo n have the same num-
ber of elements.
5.6.4.
Multiplicative inverses in ℤn
Note that for element [a]n ∈ℤn, [a]n ⊕[n −a]n = [n −a]n ⊕[a]n = [0]n, i.e. [a]n has an inverse
with respect to the addition in ℤn, called an additive inverse of [a]n. The question of inverses
with respect to ⊙is less trivial.
Definition 5.6.8 The element [b]n is a multiplicative inverse of [a]n in ℤn if [a]n ⊙[b]n = [1]n.
Note that not every element of ℤn has an inverse with respect to ⊙. For instance, [2]4 does
not have one. (Why?)
Theorem 5.6.9 [a]n has a multiplicative inverse in ℤn iff gcd(a‚ n) = 1.
Proof: If [a]n ⊙[b]n = [1]n then ab ≡1 (mod n) and hence ab −1 = qn for some integer q, i.e.
1 = ab + (−q)n. Therefore gcd(a‚ n) = 1.
Conversely, if gcd(a‚ n) = 1 then 1 = au + nv ≡au (mod n) for some integers u‚ v. Then
[[u]]n is the multiplicative inverse of [a]n in Zn.
Corollary 5.6.10 The integer n > 1 is prime iff for every a such that 0 < a < n, the element [a]n ∈ℤn
has a multiplicative inverse.
Proof: If n is prime and 0 < a < n then gcd(a‚ n) = 1; hence 0‚ a‚ 2a‚ …‚ (n −1)a is a complete
residue system modulo n, by Lemma 5.6.6, and thus, for some ca, [[ca]]n = [1]n. Then [c]n is a
multiplicative inverse of [a]n.
Conversely, if n is not prime then n = ab for some a‚ b ∈{2‚ …‚ n −1}. Then [b]n cannot have
a multiplicative inverse, for if [b]n ⊙[c]n = [1]n then [a]n ⊙([b]n ⊙[c]n) = [a]n ⊙[1]n = [a]n,
while, on the other hand, [a]n ⊙([b]n ⊙[c]n) = ([a]n ⊙[b]n) ⊙[c]n = [0]n ⊙[c]n = [0]n and hence
[a]n = [0]n, which is a contradiction.
5.6.5.
Exercises
➊
Using the properties (CON6) and (CON7) show that the operations ⊕n and ⊙n in ℤn are
correctly defined, i.e. the definitions do not depend on the representatives x‚ y of the equiv-
alence classes.
➋
Prove the properties listed in Theorem 5.6.4.
➌
Evaluate:
(a) [[29]]8
(b) [[182]]13
(c) [7]9 ⊕[8]9
(d) [7]9 ⊙[8]9

252
Logic and Discrete Mathematics: A Concise Introduction
➍
Compute the addition and multiplication tables of ℤ4 and ℤ5 and use them to solve the
following equations∶
(a) x ⊕[3]4 = [1]4
(b) x ⊕[4]5 = [3]5
(c) x ⊙[4]5 = [3]5
(d) x ⊙[2]5 = [0]5
(e) x ⊙[2]4 = [0]4
➎
For which n is it possible that the product of two nonzero elements in ℤn is [0]n?
➏
Prove the first two properties of Lemma 5.6.6.
➐∗Show that if m > 2 then {12‚ 22‚ …‚ m2} is not a complete residue system modulo m.
Babylonian mathematics
The civilizations of ancient Mesopotamia – first the Sumerians (2300–2000 BC) and later the Babylo-
nians (2000–1600 BC) – had advanced systems of mathematics, which would later exert a significant
influence on ancient Greek mathematics. A remarkable amount of Sumerian and Babylonian math-
ematics has been preserved, thanks mainly to the practice of writing on wet clay tablets that would
be baked hard in the fire or in the sun. Thousands of these tablets have been found by archeologists.
They are written in a cuneiform script, which is made by indenting the wet clay with the end of a
stylus.
In contrast to our modern base 10 number system, the Babylonians employed a sexagesimal
(base 60) positional number system. We have inherited the division of the day into 24 hours, the
hour into 60 minutes and the minute into 60 seconds from the Babylonians. When we write 5 h 30′
24′′ (5 hours, 30 minutes and 24 seconds) we are in fact writing 5 × 600 + 30 × 60−1 + 24 × 60−2 =
5 + 30∕60 + 24∕3600 = 5 + 1∕2 + 1∕150. The great advantage of this system is the fact that 60 has so
many divisors. In fact, 60 is, what is known as, a superior highly composite number. This facilitates
division and working with fractions, e.g. as in the simplification above.
The Babylonians made use of tables of squares to facilitate the computation of products, much
in the same way that tables of logarithms were used for this purpose before digital calculators
became widely available. This process was based on the following identities, which reduce multi-
plication to addition, subtraction and looking up squares in a table:
ab = (a + b)2 −(a −b)2
4
or
ab = (a + b)2 −a2 −b2
2
.
The Babylonians seem to have been aware of Pythagoras’s theorem and had formulae for calcu-
lating the areas and volumes of many common geometric shapes and solids. They calculated the
circumference of a circle as three times the diameter, which implies that they were using 3 as an
approximation of 𝜋. Astronomical phenomena, like eclipses, the solstices and equinoxes, played an
extremely important role in their culture and a lot of their mathematics was developed for the sake
of astronomical calculations.

Number Theory
253
5.7.
Linear Diophantine equations and linear congruences
5.7.1.
Linear Diophantine equations
Definition 5.7.1 Algebraic equations with integer coefficients, for which only integral solutions are
considered, are called Diophantine equations.
In particular, an equation of the type
ax + by = c‚
(5.1)
where a‚ b‚ c are integers such that neither a nor b are 0, and for which only integral solutions are
considered, is called a linear Diophantine equation of two unknowns.
Theorem 5.7.2 A necessary and sufficient condition for the equation (5.1) to have an integral solution
for x and y is that gcd(a‚ b) ∣c.
Proof: The condition is necessary because gcd(a‚ b) ∣ax + by for any integers x and y. Now, sup-
pose gcd(a‚ b) ∣c. Recall (Theorem 5.2.5) that there are integers u and v such that gcd(a‚ b) =
ua + vb. We will show that the pair
x0 =
uc
gcd(a‚ b)‚ y0 =
vc
gcd(a‚ b)
is a solution of the Definition 5.7.1 equation for any u‚ v such that gcd(a‚ b) = ua + vb. Indeed,
x0 and y0 are integers and
a
uc
gcd(a‚ b) + b
vc
gcd (a‚ b) =
(
au
gcd(a‚ b) +
bv
gcd(a‚ b)
)
c = au + bv
gcd(a‚ b)c = c.
Example 5.7.3
1. The equation 21x −12y = 5 has no integral solutions because gcd(21‚ 12) = 3 and 3 ∤5.
2. The equation 21x −12y = 6 has integral solutions since 3 ∣6. Since 3 = (−1) × 21 + (−2) ×
(−12), one solution is
x0 = (−1) × 6
3
= −2‚ y0 = (−2) × 6
3
= −4.
Theorem 5.7.4 If (x0‚ y0) is a solution of the equation in Definition 5.7.1 then all other integral solu-
tion of that equation can be obtained as
x = x0 +
b
gcd(a‚ b)t‚ y = y0 −
a
gcd(a‚ b)t‚
where t is an arbitrary integer parameter.
Proof: If ax0 + by0 = c and ax + by = c, then (ax + by) −(ax0 + by0) = 0, i.e. a(x −x0) + b(y −y0) =
0, so a(x −x0) = b(y0 −y) and hence
a
gcd(a‚ b)(x −x0) =
b
gcd(a‚ b)(y0 −y). Then
a
gcd(a‚ b) ∣
b
gcd(a‚ b)(y0 −

254
Logic and Discrete Mathematics: A Concise Introduction
y), but gcd
(
a
gcd(a‚ b)‚
b
gcd(a‚ b)
)
= 1 and hence
a
gcd(a‚ b) ∣y0 −y. Let y0 −y =
a
gcd(a‚ b)t for some integer
t. Then y = y0 −
a
gcd(a‚ b)t. Likewise x = x0 +
b
gcd(a‚ b)t.
Conversely, if x = x0 +
b
gcd(a‚ b)t‚ y = y0 −
a
gcd(a‚ b)t. Then:
ax + by = a
(
x0 +
b
gcd(a‚ b)t
)
+ b
(
y0 −
a
gcd(a‚ b)t
)
= ax0 +
ab
gcd(a‚ b)t + by0 −
ab
gcd(a‚ b)t = ax0 + by0 = c.
Example 5.7.5
The general solution of the equation 21x −12y = 6 is given by
x = −2 + −12
3 t = −2 −4t‚
y = −4 −21
3 t = −4 −7t.
For instance, when t = 1 we obtain the solution (−6‚ −11); when t = −1 we obtain (2‚ 3), etc.
5.7.2.
Linear congruences
Definition 5.7.6 A linear congruence is a congruence of the type
ax ≡c (mod n)‚
where a‚ c‚ n are integers and n > 0.
We are interested in the question of whether this congruence has solutions for x and how
to find them.
First, let us observe that if the congruence ax ≡c (mod n) has one solution x0, then it has
infinitely many solutions: x0 + kn, for any integer k. Moreover, note the following theorem.
Theorem 5.7.7 Consider the congruence
ax ≡c (mod n) .
(5.2)
1. This equation has a solution if and only if gcd(a‚ n) ∣c. Then, one solution is x0 =
uc
gcd(a‚ n), where
u is such that gcd(a‚ n) = ua + vn for some integer v.
2. If x0 is a solution of that equation then an integer x is a solution if and only if it satisfies the
congruence
ax ≡ax0 (mod n)‚
and hence, by Theorem 5.5.7, the congruence
x ≡x0
(
mod
n
(a‚ n)
)
.
3. All solutions of the equation are given by the formula
x = x0 +
n
(a‚ n)k‚
where x0 is any solution and k is an integer.

Number Theory
255
Proof:
1. Note that ax ≡c (mod n) if and only if n ∣ax −c iff ax −c = ny for some integer y, if and
only if the equation ax −ny = c has an integer solution iff gcd(a‚ n) ∣c, by Theorem 5.7.2.
2. Exercise.
3. Follows from Theorem 5.7.4.
For instance, the congruence 6x ≡2 (mod 8) has a solution x = 3 and hence all solutions
are the numbers 3 + 4k, for k ∈ℤ.
Often a congruence can be simplified by cancelling according to Theorem 5.5.7.
Example 5.7.8
Solve the congruence
9965x ≡19955 (mod 4950).
Solution
First we reduce the congruence by dividing by 5, using Theorem 5.5.7, to
1993x ≡3991 (mod 990).
Let us compute gcd(1993‚ 990):
1993 = 2 × 990 + 13.
990 = 76 × 13 + 2.
13 = 6 × 2 + 1.
Thus, gcd(1993‚ 990) = 1, so the congruence has solutions.
Now we look for integers u and v such that 1 = 1993u + 990v:
1 = 1 × 13 −6 × 2 = 1 × 13 −6 × (990 −76 × 13) = 457 × 13 −6 × 990 = 457(1993 −
2 × 990) −6 × 990 = 457 × 1993 −920 × 990.
Therefore, one solution is x0 = 457.3991 = 1 823 887.
We can obtain a smaller solution by taking the remainder of the division of x0 by
990∶1 823 887 = 1842 × 990 + 307.
Then, the general solution is x = 307 + 990k.

256
Logic and Discrete Mathematics: A Concise Introduction
5.7.3.
Exercises
➊
Solve the Diophantine equations:
(a) 81x −24y = 18
(b) 28x + 91y = 146
(c) 429x + 154y = 121
➋
Solve the congruences:
(a) 27x ≡12 (mod 15)
(b) 25x ≡5 (mod 16)
(c) 166x ≡18 (mod 38)
(d) 84x ≡24 (mod 35)
(e) 28x ≡42 (mod 49)
(f) 1001x ≡91 (mod 104)
(g) 3700x ≡11 (mod 111)
➌∗Every two of n arithmetic progressions have a common term. Show that all progressions
have a common term.
➍∗Show that for every natural number n, in every arithmetic progression of natural numbers
there are n consecutive terms that are composite numbers.
➎∗Prove that for every positive integer k there exists a prime p such that each of the numbers
p −1‚ p + 1 and p + 2 has at least k different prime divisors.
6 Translation taken from http://mathworld.wolfram.com/DiophantussRiddle.html.

Number Theory
257
Diophantus of Alexandria (c. AD 200–c. AD 285)
Diophantus was an Alexandrian Greek mathematician, sometimes called “the
father of algebra”, for his fundamental contributions to arithmetic and alge-
bra, especially on finding integer solutions to algebraic equations with integer
coefficients, now called Diophantine equations.
Diophantus’ magnum opus was the collection of 13 books called Arith-
metica, of which only six have survived. They contain a collection of 130 prob-
lems requiring integer solutions of Diophantine equations. The methods for
solving such equations, which may have many solutions, are now called Diophantine analysis. Dio-
phantus’ Arithmetica greatly stimulated the advances in number theory for centuries after him and
strongly influenced many generations of mathematicians, including the French lawyer and ama-
teur mathematician Pierre de Fermat (see the end of Section 5.10). Fermat famously claimed that
certain Diophantine equations have no solutions – a claim now called Fermat’s Last Theorem – and
just noted in the margin of his copy of Arithmetica that he had found a “truly marvellous proof of
this proposition”. No one could find such a proof for over 300 years, until 1994.
Diophantus was the first Greek mathematician who recognized fractions as numbers. He also
made significant contributions to the mathematical notation.
Here is a famous riddle6, a poem from Anthologia Palatina, a collection of old Greek poems and
epigrams dating from the 5th to 6th centuries, which encodes a mathematical problem, the solution
of which will give you how many years Diophantus lived (even though the precise years of his
birth and death are not known):
Here lies Diophantus, the wonder behold. Through art algebraic, the stone tells how
old: ‘God gave him his boyhood one-sixth of his life, One twelfth more as youth while
whiskers grew rife; And then yet one-seventh ere marriage begun; In five years there
came a bouncing new son. Alas, the dear child of master and sage after attaining half
the measure of his father’s life chill fate took him. After consoling his fate by the science
of numbers for four years, he ended his life.’
How long did Diophantus live?
5.8.
Chinese remainder theorem
Having solved the problem for one linear congruence, we now proceed to systems of linear
congruences. What follows might appear to be a piece of modern, though elementary, mathe-
matics, but in fact the method for solving such systems was essentially known in China some
2000 years back! The following problem was posed by Sun Tsu Suan-Ching in the 4th century
AD: There are certain things whose number is unknown. Repeatedly divided by 3, the remainder is 2;
by 5 the remainder is 3; and by 7 the remainder is 2. What will be the number?
The method for solving problems of this kind is given by the following theorem.
Theorem 5.8.1 (Chinese remainder theorem) Let m1‚ …‚ mk be positive integers, relatively prime
in pairs, and b1‚ …‚ bk be any integers. Then:

258
Logic and Discrete Mathematics: A Concise Introduction
1. The system of congruences
x ≡b1 (mod m1)
⋮
x ≡bk (mod mk)
has a solution, which is unique modulo M = m1 · · · mk.
2. The least non-negative solution is
x0 = (M1y1 + · · · + Mkyk) rem M
where Mi = M∕mi and yi is a solution of the congruence
Miyi ≡bi (mod mi)
for i = 1‚ 2‚ …‚ k.
3. Moreover, every solution can be obtained as x0 + nM for some integer n.
Proof: Since x0 ≡M1y1 + · · · + Mkyk (mod M), it follows by (CON9) that x0 ≡M1y1 + · · · +
Mkyk (mod mi) for every i = 1‚ 2‚ …‚ k. However, Miyi ≡bi (mod mi) and Mjyj ≡0 (mod mi)
for every j ≠i because mi ∣Mj. Therefore, M1y1 + · · · + Mkyk ≡bi (mod mi) and hence
x0 ≡bi (mod mi) for every i = 1‚ 2‚ …‚ k.
Furthermore, x0 + nM for every integer n is also a solution.
Finally, if x1 and x2 are solutions, then x1 −x2 ≡0 (mod mj) for j = 1‚ …‚ k. Hence x1 −x2 ≡
0 (mod M), i.e. x1 ≡x2 (mod M), by Theorem 5.3.6, because lcm(m1‚ …‚ mk) = M.
The Chinese remainder theorem 5.8.1 gives a direct method of finding a solution of the
system of congruences.
Example 5.8.2
Find a positive integer x that leaves remainders 1, 2, 3, 4 when divided by 2, 3, 5, 7, respec-
tively.
Solution
The problem boils down to solving the system
x ≡1 (mod 2)
x ≡2 (mod 3)
x ≡3 (mod 5)
x ≡4 (mod 7)
We apply the Chinese remainder theorem:
M = 2 × 3 × 5 × 7 = 210‚ M1 = 105‚ M2 = 70‚ M3 = 42‚ M4 = 30.

Number Theory
259
We look for integers y1‚ y2‚ y3 and y4 such that
105y1 ≡1 (mod 2)‚
70y2 ≡2 (mod 3)‚
42y3 ≡3 (mod 5‚
30y4 ≡4 (mod 7).
We find y1 ≡1 (mod 2), y2 ≡2 (mod 3), y3 ≡4 (mod 5) and y4 ≡2 (mod 7). Possible val-
ues are y1 = 1, y2 = 2, y3 = 4 and y4 = 2, from where x0 = (105 × 1 + 70 × 2 + 42 × 4 +
30 × 2) rem 210 = 473 rem 210 = 53. Thus, the least positive solution is x0 = 53. All other
solutions are obtained by the formula x = 53 + 210n.
5.8.1.
Exercises
➊
Solve the following systems of congruences:
(a) x ≡2 (mod 4), x ≡3 (mod 9).
(b) x ≡13 (mod 14), x ≡9 (mod 15).
(c) x ≡3 (mod 4), x ≡5 (mod 9), x ≡10 (mod 35).
(d) x ≡2 (mod 3), x ≡3 (mod 7), x ≡0 (mod 10).
(e) x ≡4 (mod 5), x ≡3 (mod 4), x ≡2 (mod 7), x ≡6 (mod 9).
➋
The following story comes from Brahma-Sphuta-Siddhanta (Brahma’s Correct System) writ-
ten by Brahmagupta (born 598 AD). An old woman goes to market and a horse steps on her basket
and crashes the eggs. The rider offers to pay for the damages and asks her how many eggs she had
brought. She does not remember the exact number, but when she had taken them out two at a time,
there was one egg left. The same happened when she picked them out three, four, five and six at a
time, but when she took them out seven at a time they came out even. What is the smallest number
of eggs she could have had?
➌∗Find a necessary and sufficient condition for the system of congruences
x ≡b1 (mod m1)
…
x ≡bk (mod mk)
to have a solution.

260
Logic and Discrete Mathematics: A Concise Introduction
Ancient Chinese mathematics
The Chinese remainder theorem is only one impressive testimony for the sophistication of the math-
ematics of ancient China. Its development started around the 11th century BC. Unlike the formal
and axiomatic style of ancient Greek mathematics, the Chinese mathematics was mainly oriented
towards solving practical problems, related to trade, taxation, payments and accounting, engineer-
ing, astronomy and agriculture. The positional (value place) decimal system was known in China
at least as far back as the 2nd millennium BC, over a thousand years before it was adopted in
Europe. The digits 1 to 9 were represented with especially arranged small bamboo rods, positioned
in columns representing units, tens, hundreds, thousands, etc. Much of the mathematical knowl-
edge of ancient China was collected in a textbook called Jiuzhang Suanshu, or Nine Chapters on the
Mathematical Art, gradually written by many authors over a period of time starting around 200 BC.
It contained many geometric facts and constructions, including Pythagoras’ theorem, methods for
solving some quadratic and cubic equations, for computing approximate values of 𝜋, as well as a
version of the method of Gaussian elimination for solving systems of linear equations with several
unknowns.
The Chinese mathematicians were fascinated with mathematical patterns, such as magic squares
of numbers where each row, column and diagonal added up to the same sum. They were regarded
as having religious and spiritual meaning.
The Golden Age of Chinese mathematics was around the 13th century AD, when dozens of
strong mathematical schools flourished across China. Perhaps the most famous Chinese math-
ematician of that time was Qin Jiushao, who wrote a book on applied maths, Shiushu Jiuzhang
(Mathemtaical Treatise in Nine Sections) where, among other things, he presented in detail the Chinese
Remainder Theorem and developed an early version of the method of repeated approximations,
only discovered in Europe by Isaac Newton in the 17th century, for computing approximate solu-
tions of algebraic equations of degree as high as 10.
Below on the left is an illustration of the ancient Chinese positional decimal system and on the
right a Chinese version of Pascal’s triangle, known by Shen Kuo some 300 years before Pascal was
born.

Number Theory
261
5.9.
Euler’s function. Theorems of Euler and Fermat
Now we will introduce a function defined on the set of positive integers which plays a very
important role in number theory. It is called Euler’s function, denoted by 𝜙and defined for
all positive integers as follows.
Definition 5.9.1 𝜙(n) is the number of positive integers less than or equal to n and relatively prime
to n.
For instance, 𝜙(1) = 1, 𝜙(11) = 10, 𝜙(12) = 4.
Obviously for large values of n the definition is not convenient for practical computation
of 𝜙(n) and we need a more efficient method. In order to find such a method we will make
several observations about Euler’s function.
Theorem 5.9.2
1. If n is prime then 𝜙(n) = n −1.
2. If n = pk, where p is prime, then 𝜙(n) = pk −pk−1.
3. 𝜙(n) has the following multiplicative property: for every two relatively prime natural numbers m
and n,
𝜙(mn) = 𝜙(m)𝜙(n).
Proof:
1. All n −1 positive integers less than n are relatively prime to n.
2. The numbers between 1 and pk that are not relatively prime to pk are exactly the pk−1
multiples of p∶1 × p‚ 2 × p‚ …‚ pk−1 × p and the remaining pk −pk−1 numbers are relatively
prime to pk.
3. In order to verify that property let us arrange the integers from 1 to mn in a rectangular
table with m rows and n columns as follows:
1
2
…
j
…
n
n + 1
n + 2
…
n + j
…
2n
…
…
…
…
…
…
(i −1)n + 1
(i −1)n + 2
…
(i −1)n + j
…
in
…
…
…
…
…
…
(m −1)n + 1
(m −1)n + 2 …
(m −1)n + j …
mn
We see that the number in the ith row and the jth column of this table is (i −1)n + j. Note
that this number is relatively prime to n if and only if j is relatively prime to n, by (GCD4)
in Theorem 5.2.6. Thus, the numbers from the table that are relatively prime to n are pre-
cisely the elements of those 𝜙(n) columns that correspond to the numbers j relatively
prime to n. Next, {0 × n‚ 1 × n‚ …‚ (m −1)n} is a complete residue system modulo m by
Lemma 5.6.6, since gcd(m‚ n) = 1. Therefore {0 × n + j‚ 1 × n + j‚ …‚ (m −1)n + j} is a com-
plete residue system modulo m for every integer j. Thus, there are 𝜙(m) numbers from
these, which are relatively prime to m.

262
Logic and Discrete Mathematics: A Concise Introduction
Now, the numbers from the table that are relatively prime to mn are those that are
relatively prime both to m and to n, by Theorem 5.4.1. Hence, these are precisely the 𝜙(m)
numbers relatively prime to m from each of the 𝜙(n) columns with numbers relatively
prime to n. Therefore, there are exactly 𝜙(m).𝜙(n) numbers in the table that are relatively
prime to mn, i.e. 𝜙(mn) = 𝜙(m)𝜙(n).
Applying Theorem 5.9.2 several times we can generalize the multiplicative property of
𝜙(n) as follows.
Corollary 5.9.3 If n1‚ …‚ nk are relatively prime in pairs then 𝜙(n1‚ …‚ nk) = 𝜙(n1) · · · 𝜙(nk).
Now we are ready to compute 𝜙(n) for any natural number n. Let n = p𝛼1
1 · · · p𝛼k
k where
p𝛼1
1 ‚ …‚ p𝛼k
k are powers of different primes. Then every two of these powers are relatively prime.
Applying the properties of 𝜙(n) we find:
𝜙(n) = 𝜙(p𝛼1
1 ) · · · 𝜙(p𝛼k
k ) = (p𝛼1
1 −p𝛼1−1
1
) · · · (p𝛼k
k −p𝛼k−1
k
).
In a slightly more concise form:
𝜙(n) = n
(
1 −1
p1
)
· · ·
(
1 −1
pk
)
.
Example 5.9.4
1. 𝜙(2646) = 𝜙(2 × 33 × 72) = (21 −20)(33 −32)(72 −71) = 1512.
2. 𝜙(1000) = 𝜙(23 ⋅53) = 1000 × 1
2 × 4
5 = 400.
5.9.1.
Theorems of Euler and Fermat
Theorem 5.9.5 (Euler’s theorem) For every natural number n and integer a, relatively prime to n,
the following congruence holds:
a𝜙(n) ≡1 (mod n)‚
that is
n ∣a𝜙(n) −1.
Proof: Let x1‚ …‚ x𝜙(n) be the positive integers less than n and relatively prime to n. Now con-
sider ax1‚ …‚ ax𝜙(n). These are 𝜙(n) numbers that are all relatively prime to n, by Theorem 5.4.1,
and no two of them are congruent modulo n (why?), so they form a reduced residue system mod-
ulo n. Therefore, if yi = axi rem n for i = 1‚ …‚ 𝜙(n), then y1‚ …‚ y𝜙(n) are 𝜙(n) different natural

Number Theory
263
numbers less than n and relatively prime to n, so they must be exactly the numbers x1‚ …‚ x𝜙(n),
possibly in another order. Therefore, their products are equal:
x1 · · · x𝜙(n) = y1 · · · y𝜙(n).
Now
axi ≡yi (mod n)
for i = 1‚ …‚ 𝜙(n), hence
(ax1) · · · (ax𝜙(n)) ≡y1 · · · y𝜙(n)(mod n).
However,
(ax1) · · · (ax𝜙(n)) = a𝜙(n)x1 · · · x𝜙(n) = a𝜙(n)y1 · · · y𝜙(n).
Thus,
a𝜙(n)y1 · · · y𝜙(n) ≡y1 · · · y𝜙(n) (mod n).
Furthermore, the product y1 · · · y𝜙(n) is relatively prime to n by Theorem 5.4.1. Therefore,
by Corollary 5.5.8, we may cancel the last congruence by y1 · · · y𝜙(n) and thus we obtain
a𝜙(n) ≡1 (mod n).
Example 5.9.6
Since 𝜙(1000) = 400 and gcd(2003‚ 1000) = 1, it follows that
2003400 ≡1 (mod 1000)‚
i.e. the last three digits of the number 2003400 are 001.
Example 5.9.7
Find the last two digits of 777777.
Solution
We can approach this problem similarly to the one about 7777 in Example 5.5.6, but it could
take a lot of time until we get an appropriate “starting point”. Euler’s theorem comes to help
here: 𝜙(100) = 40, hence 7740 ≡1 (mod 100), etc. The rest is left as an exercise.
The particular case of Euler’s theorem when n is prime is known as Fermat’s little theorem7:
Theorem 5.9.8 For every prime number p and an integer a not divisible by p the following congruence
holds:
ap−1 ≡1 (mod p)‚
that is p ∣ap−1 −1.
7 This to distinguish it from the famous Fermat’s last theorem.

264
Logic and Discrete Mathematics: A Concise Introduction
5.9.2.
Exercises
➊
Evaluate 𝜙(n) for n = 1‚ 2‚ …‚ 16.
➋
Find a complete residue system modulo 7 consisting of multiples of 3.
➌
Calculate 13242 mod 56 without using a calculator (or computer).
➍
Using Fermat’s little theorem, prove that ap ≡a (mod p) for every prime number p and
integer a.
➎
Show that 42 ∣n7 −n for every integer n.
➏
Show that if gcd(n‚ 10) = 1 then 10 ∣n12 −1.
➐
Show that if gcd(n‚ 30) = 1 then 240 ∣n4 −1.
➑∗Find all natural numbers n such that 𝜙(n) = 24.
➒∗Find all natural numbers n such that 𝜙(n) ∣n.
➓∗If d ∣n and 0 < d < n prove that n −𝜙(n) > d −𝜙(d).
11∗For every natural number n > 1 show that
∑
m = n𝜙(n)
2
‚
where the sum ranges over all natural numbers m less than n and relatively prime to n.
12∗Show that 56 786 730 ∣mn(m60 −n60) for any integers m and n.
13∗Prove the congruences:
(a) 211⋅31 ≡2 (mod 11 ⋅31).
(b) 219⋅73 ≡2 (mod 19 ⋅73).
14
8
(a) Find all positive integers n for which 7 ∤2n −1.
(b) Show that for every positive integer n‚ 7 ∣2n + 1.
15∗Let m and n be natural numbers such that n > m ≥1. The last three digits in the decimal
expansion of the number 1978m coincide with the last three digits in the decimal expansion
of the number 1978n. Find m and n such that the sum m + n is minimal.9
16∗Prove that for any integer a and natural number m:
am ≡am−𝜙(m)(mod m).
(This is a generalization of Euler’s theorem.)
8 This was Problem 1 at the 6th IMO in Moscow, 1964.
9 This was Problem 1 at the 20th IMO in Romania, 1978.

Number Theory
265
Pierre de Fermat (17.8.1601–12.1.1665)
Pierre de Fermat was a French lawyer at the Parliament of Toulouse, who
pursued research in mathematics in his spare time, mostly for intellectual
pleasure. He made contributions to several fields of mathematics, including
number theory, analytic geometry, probability and optics, which earned him
the title the prince of amateurs.
Independently of Descartes, Fermat discovered the basic idea of ana-
lytic geometry and developed methods for finding tangents to curves and
their points of local maximum and minimum, which essentially made him an inventor of the differ-
ential calculus. However, Fermat’s main mathematical contributions were in number theory, and
include his “little” theorem (Theorem 5.9.8).
Strangely, Fermat published only one mathematical paper in his life, anonymously as an
appendix to someone else’s book. Most of his results were only found after his death on loose
sheets of paper or in the margins of books that he had read and annotated, mostly without
any proofs, though for most of his claims it was known that he had proofs. However, Fermat’s
immortality was sealed by one such claim, that he wrote in the margin of his copy of Diophantus’
Arithmetica (see Section 5.7): he claimed that he had a proof that the equation an + bn = cn, for any
natural number n > 2, has no integer solutions with a‚ b‚ c all nonzero. He wrote there “I have
discovered a truly marvellous proof of this proposition, which this margin is too small to contain”.
This claim was only discovered after his death and the statement became known as Fermat’s last
theorem. Although the claim is so easy to state, and Fermat did have proofs for the cases n = 3 and
n = 4, the proof in the general case had alluded mathematicians for over 350 years. Many famous
and unknown mathematicians attempted to prove it, especially after some substantial monetary
prizes were offered for it, but with no success. The proof was only completed in 1994 by the British
mathematician Andrew Wiles, who devoted about 30 years of his life to this work. Wiles’ proof,
in a highly condensed form, was over 80 pages long, involving very complex mathematics and
containing many brilliant new ideas in advanced fields like elliptic curves and the theory of ideals.
The mathematics used in the proof did not exist in the time of Fermat, so it is hard to believe that
he really had a correct proof, though this cannot be known for sure.
Here is a photo of Andrew Wiles after concluding his historical lecture in Cambridge in 1993
where he presented the proof of a result implying as a corollary Fermat’s last theorem, and thus
bringing this tantalizing story to an end (after completing a gap in the proof together with his
student Richard Taylor in 1994).

266
Logic and Discrete Mathematics: A Concise Introduction
5.10.
Wilson’s theorem. Order of an integer
5.10.1.
Wilson’s theorem
The following theorem gives an interesting, albeit mostly theoretical, criterion for primality of
a natural number.
Theorem 5.10.1 (Wilson’s theorem) For every positive integer n > 1, n is a prime if and only if
(n −1)! + 1 ≡0 (mod n).
Proof: For n = 2‚ 3‚ 4 the statement is verified by a direct inspection. Now, suppose n > 4.
If (n −1)! + 1 ≡0(mod n) then n must be prime; otherwise n has a prime divisor p < n.
Then p ∣(n −1)! and hence p ∣1 – a contradiction. Conversely, let n be prime. For every k
between 2 and n −2, gcd(k‚ n) = 1; hence {k × 0‚ k × 1‚ …‚ k × (n −1)} is a complete residue sys-
tem modulo n. Therefore, there is exactly one m between 0 and n −1 such that k.m ≡1(mod n).
This m cannot be 0‚ 1 or n −1, otherwise k.m would have been congruent respectively to 0‚ k
and n −k ≠1 modulo n. Moreover, if k1 and k2 are two different numbers between 2 and
n −2 and 1 ≤m ≤n −1 then mk1 ≢mk2(mod n); otherwise n ∣m(k1 −k2), which is impossi-
ble since gcd(n‚ m) = 1 and gcd(n‚ k1 −k2) = 1. Thus, the numbers 2‚ 3‚ …‚ n −2 are grouped
into pairs (k‚ m) such that km ≡1(mod n). Then 2 ⋅3 · · · (n −2) ≡1(mod n) and hence (n −1)! =
1 ⋅2 ⋅3 · · · (n −2)(n −1) ≡n −1 ≡−1(mod n).
5.10.2.
Order of an integer
Note that, for any positive integer n and an integer a such that gcd(n‚ a) = 1, the set S of all pos-
itive integers k for which ak ≡1 (mod n) is nonempty, since – by Euler’s theorem – it contains
𝜙(n). Then, by the well-ordering property of natural numbers, there is a least natural number
in S.
Theorem 5.10.2 Let n be a positive integer and gcd(n‚ a) = 1. The least positive integer k such that
ak ≡1 (mod n) is called the order of a modulo m, denoted by ordna.
Theorem 5.10.3 (Properties of the order of an integer) Let n be a positive integer, gcd(n‚ a) = 1,
and k = ordna. Then:
1. Every positive integer m for which am ≡1 (mod n) is a multiple of k.
2. In particular, k ∣𝜙(n).
3. For any integers u‚ v∶au ≡av (mod n) iff u ≡v (mod k).
4. No two of the integers a‚ a2‚ …‚ ak are congruent modulo n.
5. For any positive integer m, ordnam =
k
gcd(k‚ m).

Number Theory
267
Proof:
1. Let m be any positive integer such that am ≡1 (mod n). By dividing m by k with a remain-
der we get
m = kq + r‚ 0 ≤r < k.
Then
1 ≡akq+r ≡akq × ar ≡(ak)q × ar ≡1q × ar ≡ar (mod n).
Thus, r satisfies ar ≡1 (mod n) and is less than k and hence r = 0.
2. Follows immediately from 1 and Euler’s theorem.
3. Let u ≥v. Since gcd(n‚ a) = 1, au ≡av (mod n) iff au−v ≡1 (mod n) iff k ∣u −v.
4. Follows immediately from 3.
5. Left as a (challenging) exercise.
5.10.3.
Exercises
➊
If n > 4, show that n is composite if and only if
(n −1)! ≡0 (mod n).
➋
Prove that 343 ∣2147 −1.
➌∗Prove Claim 5 of Theorem 5.10.3.
➍∗If p is a prime and h‚ k ≥0 are integers such that h + k = p −1, show that h!k! + (−1)h ≡
(mod p).
➎∗If a and n are natural numbers and p is a prime such that gcd(a‚ p) = 1 and gcd(n‚ p −1) = 1,
show that there is exactly one integer x between 1 and p such that xn ≡a(mod p).
➏∗Let a and n > 1 be integers such that an−1 ≡1(mod n) but ax ≢1(mod n) for every proper
divisor x of n −1. Show that n is a prime.

268
Logic and Discrete Mathematics: A Concise Introduction
Ancient and Medieval Indian and Arabic mathematics
The numeral system used today is known as the Hindu–Arabic numeral system. It started evolving
during the first centuries AD in India and was gradually transmitted to the West through trade and
via Arabic mathematics.
The oldest preserved mathematical records from India are the Sulba Sutras, dated between the
8th century BC and the 2nd century AD. They are appendices to religious texts and give simple rules
for constructing altars of various shapes, thus including some geometry and trigonometry. The
Sulba Sutras also give methods for constructing a circle with approximately the same area as a given
square, using different approximations of the value of 𝜋, compute
√
2 to several decimal places,
list many Pythagorean triples (triples of integer sides of right triangles) and state the Pythagorean
theorem. Much of this knowledge probably came from Babylon.
In the 5th century AD, the Indian mathematician–astronomer Aryabhata wrote the Aryabhatiya,
where the decimal place-value system first appears in Indian mathematics and later made its way
to the West. The use of the the Hindu–Arabic numeral system, and in particular the number 0,
both a placeholder and decimal digit, were first explained in the 7th century by another famous
Indian mathematician–astronomer Brahmagupta, in his main work Brahma-sphuta-siddhanta (Cor-
rectly Established Doctrine of Brahma). In that book, Brahmagupta explained the arithmetic operations
on negative integers and on fractions, assuming that they were well known on positive integers.
Brahmagupta also gave rules for computing the solution of the linear equation of one unknown
ax + b = cx + d and of the quadratic equation ax2 + bx = c. Moreover, he also showed how to solve
systems of simultaneous indeterminate equations by elimination and presented methods for solv-
ing some Diophantine equations, such as x2 + y2 = z2, producing Pythagorean triples and (as it
was called later) Pell’s equation kx2 + 1 = y2, by using the Euclidean algorithm. Brahmagupta’s
book also contains some involved results from geometry and trigonometry and applications to
astronomy.
In the 14th century Madhava of Sangamagrama founded the famous Kerala school of astronomy
and mathematics in Kerala, India, which flourished for over 200 years. Madhava and his followers
developed very advanced mathematics, including power series and series expansion for trigono-
metric functions and essentially used, without making them precise, methods of differentiation
and integration, two centuries before that calculus was systematically developed by Newton and
Leibniz.
The written history of the Arabic maths goes back to the work of the great mathematician
named Muhammad ibn Musa Al-Khwarizmi (c. 780–850 AD). In his fundamental work, Al-Kitab
al-mukhtasar fi hisab al-jabr wa’l-muqabala (Compendious Book on Calculation by Completion and Balanc-
ing), he first systematically presented the methods for solving linear and quadratic equations. The
word “algebra” derives from al-jabr in the title of the book, referring to one of the two operations
he used to solve quadratic equations. These methods came from older Indian or Greek sources but
he was the first to present them as clear sets of mathematical instructions, giving rise to the mod-
ern notion of an algorithm. The word algorithm itself is derived from the name Al-Khwarizmi, via
the Latin translation of his earlier book, Algoritmi de numero Indorum, in which he explained the
Hindu–Arabic numeral system. Both books were extremely influential in medieval Europe, where
Al-Khwarizmi was regarded as the inventor of algebra. Thanks to him, much of the quite advanced
mathematical knowledge of the Ancient and Medieval Indian and Arabic cultures was made widely
accessible in Europe.

Number Theory
269
5.11.
Application: public key cryptography
5.11.1.
About cryptography
Cryptography deals with methods for exchange of secret messages, i.e. messages that can only
be written and read by authorized agents. Such exchange involves two processes:
• encryption of the text of the original message M, by using an encryption function (key) E,
and
• decryption of the encrypted message E(M), by using a decryption function (key) D, so that
the decrypted text D(E(M)) is identical with M.
Note that every message, being represented by a binary string, can be considered as an
integer.
Most of the traditional cryptographic methods use secret keys for both encryption and
decryption. That creates the Catch-22 problem of how to exchange in a secure way the secret
keys needed for the encryption and decryption. After all, the purpose of cryptography is pre-
cisely to provide such a secure channel for exchange of information, and if it already exists then
the encryption becomes unnecessary; otherwise the secret keys themselves can be intercepted
and the whole process compromised.
A solution to that problem is provided by the method of Public key cryptography, intro-
duced in 1976 by W. Diffie and M. Hellman.10
5.11.2.
The idea of public key cryptography
Public key cryptography uses a pair of keys for every user U: a public key EU, i.e. one that is pub-
licly available, and a private key DU, which is only known to the user. These keys essentially
are mutually inverse mappings on (e.g. binary) strings of symbols, which serve as encryption
and decryption functions, DU and EU, i.e.:
DU(EU(M)) = EU(DU(M)) = M
for any (sufficiently short) string M.
The exchange of secret messages using public key cryptography between two agents, e.g.
Alice and Bob, is organized as follows. Suppose Alice wants to send the secret message M to
Bob. For that she uses Bob’s public key EB to encrypt the message and then sends EB(M) to Bob.
Bob then uses his private key DB to decrypt it and thus obtains DB(EB(M)) = M. If the message
is longer than a predefined length (see further), then it is partitioned into blocks, which are
encrypted and sent separately.
Furthermore, Alice can encrypt the message in such a way that Bob can be sure that only
Alice could have sent it, i.e. the message will bear Alice’s digital signature. The idea is, again,
very simple and elegant: Alice first applies her private key DA to the message M and then Bob’s
public key EB to the result, and sends EB(DA(M)) to Bob. On receipt Bob applies his private key
DB to the encrypted message, and then Alice’s public key to the result, and thus obtains
EA(DB(EB(DA(M)))) = EA(DA(M)) = M.
10 W. Diffie and M. Hellman, New Directions in Cryptography, IEEE Transactions of Information Theory, IT-22(6):
644-654, 1976.

270
Logic and Discrete Mathematics: A Concise Introduction
Clearly, only Bob (or a person knowing Bob’s private key) can obtain the string M, and
if it is a meaningful message, then Bob can be practically sure that it could only have been
encrypted by Alice (or a person knowing Alice’s private key).
Theoretically, the method of public key cryptography can be trivially attacked: after all, the
private key DU of a user U is just the inverse of her public key EU. Therefore, for the method
to be practically secure, the public key EU must be a trapdoor function: one that is easy to
compute while its inverse is practically impossible to compute.
5.11.3.
The method RSA
The currently most popular and widely used method for public key cryptography is RSA,
introduced in 1978 by R. Rivest, A. Shamir and L. Adleman.11
The idea of RSA is based on elementary number theory. The pair of keys (E‚ D) is deter-
mined by a pair of very large prime numbers p and q, and a pair of integers d and e such
that
de ≡1 (mod (p −1)(q −1)).
Note that for any chosen d (respectively e) that is relatively prime to (p −1)(q −1), there is
an e (respectively d) satisfying the congruence above.
Let n = pq. Then the public key E consists in the pair (n‚ e) and the private key D consists
in the pair (n‚ d).
Now the encryption function is
E(M) = Me rem n
and the decryption function is
D(P) = Pd rem n.
Note that 𝜙(n) = (p −1)(q −1) and hence de ≡1 (mod 𝜙(n)).
Therefore, for any integer M, (Me)d = Med ≡M (mod n) by Euler’s theorem. Therefore, if
M < n then
D(E(M)) = (Me rem n)d rem n = Med rem n = M rem n = M‚
and likewise
E(D(M)) = (Md rem n)e rem n = Mde rem n = M rem n = M.
Thus, E and D are mutually inverse on all M < n.
Messages M for which M ≥n are partitioned into blocks: M = M1 · · · Mk such that Mi < n
for each i = 1‚ …‚ k, and the encrypted message is E(M1) · · · E(Mk).
Furthermore, notice that, since (n‚ e) is the public key, E(M) is easily computable (using a
computer, of course). To compute D(M), however, one needs to know d, which is not public
knowledge. In order to find d one would have to find p and q, i.e. factorize n, and then solve
the congruence
ex ≡1 (mod (p −1)(q −1)).
11 R. Rivest, A. Shamir and L. Adleman, A Method for Obtaining Digital Signatures and Public key
Crypto-systems, Communication of the ACM, 21(2): 120–126, 1978.

Number Theory
271
Now the point is that p and q are very large, so the factorization of n is prohibitively long
and expensive. Thus, E is a trapdoor function.
Remark 6 All currently known methods for factorization take time exponential in the size (length) of
the input number n, which, measured in bits, is log2n. Thus, the time needed to factorize n is roughly
proportional to n. Therefore, for the currently known methods,12 a 2048-bit long RSA key is safe, because
if p and q are each 1024 bits long, our universe will extinguish before the most powerful computers
presently existing can factor pq with the currently known methods.
On the other hand, however, factorization only requires nondeterministic polynomial time, i.e.
its algorithmic complexity is in the class NP, because once the factors are guessed, the verification is
quick. One of the most important, and perhaps the most popular, open problem in computer science
nowadays is whether there are algorithms that can solve all NP problems in deterministic polynomial
time (See the box at the end of Chapter 3.). It is widely believed that the answer is “NO”, but if such an
algorithm is found, then the method RSA will be endangered, if not compromised.
Example 5.11.1
We want to create an RSA crypto-system for the 8-bit ASCII encoding of characters, i.e. the
block size is 8 bits. Then we need n > 28 = 256. Take p = 13, q = 31, so n = pq = 403, and 𝜙(n) =
12 ⋅30 = 360 = 23 ⋅32 ⋅5.
Choose e = 77 (= 7 × 11). Solving the congruence 77d ≡1 (mod 360) gives a minimal
positive solution d = 173. Thus, the public key is (403‚ 77) and the private key is (403‚ 173).
Then, for example, the word “ONE” represented in ASCII code as (79‚ 78‚ 69) is encrypted as
(7977 rem 403‚ 7877 rem 403‚ 6977 rem 403) = (300‚ 39‚ 49).
Remark 7 In virtually all public key systems, the encryption and decryption times are very lengthy
compared to other block-oriented algorithms. Therefore in most implementations of public key systems, a
temporary, random “session key” of much smaller length than the message is generated for each message
and alone encrypted by the public key algorithm. The message is then actually encrypted using a faster
private key algorithm with the session key. At the receiver side, the session key is decrypted using the
public key algorithms and the recovered “plaintext” key is used to decrypt the message. Thus, the session
key approach blurs the distinction between “keys” and “messages” – in the scheme, the message includes
the key, and the key itself is treated as an encryptable “message”.
5.11.4.
Exercises
➊
Use the crypto-system created in Example 5.11.1 above to:
(a) Encrypt the word “HELP”, encoded in ASCII as (72‚ 69‚ 76‚ 80).
(b) Decrypt
the
ASCII
code
encrypted
as
(45‚ 208‚ 148‚ 148)
and
determine
the
encoded word.
12 At the time of writing this book.

272
Logic and Discrete Mathematics: A Concise Introduction
➋
Consider a crypto-system using the public key (143‚ 11).
(a) Find the minimal positive d such that (143‚ d) is a private key for that crypto-system.
(b) Encrypt the ASCII code of the word “STOP”.
(c) Decrypt the word with the ASCII code encrypted as the string of integers
(111‚ 4‚ 88‚ 57‚ 116‚ 67).
➌
Consider a crypto-system using the public key (43 × 61‚ 143).
(a) Find the minimal positive d such that (43 × 61‚ d) is a private key for that crypto-system.
(b) Encrypt the ASCII code of the word “ONE”.
(c) Decrypt the string of integers encrypted as (2‚ 3‚ 4‚ 5).
➍
Consider a crypto-system using the private key (2701‚ 125).
(a) Find the minimal positive e such that (2701‚ e) is a public key for that crypto-system.
(b) Encrypt the ASCII code of the word “SECRET”.
(c) Decrypt the string of integers encrypted as (1‚ 11‚ 111‚ 1111).
➎
Knowing that 𝜙(8927) = 8736, compute the private key (8927‚ d) of the crypto-system using
a public key (8927‚ 55).
History of codes and ciphers
The word cryptography comes from Greek and means literally “the science of secret writing”. The
use of secret codes and ciphers goes back to ancient times, as the secret exchange of messages was
of crucial importance during wars. Accordingly, code breaking and the decryption of encrypted
messages became extremely important, which is how cryptanalysis emerged.
What is the difference between a code and a cipher? A code is like a dictionary that translates
complete words or phrases into other words or phrases. Reading an encoded text is done with a
codebook. A cipher replaces single letters by other symbols or strings of symbols – letters, numbers,
etc. Ciphers are short and can be memorized, so a codebook is not needed. Often the word code is
used to mean either a code or a cipher.
The ancient Greeks invented a simple cipher that changed letters into numbers, using a 5 × 5
table, where A is written as 11, B is 12, and so on. In this way, the word CODE is encrypted into 13
34 14 15. A version of this code was still used during the First World War.
The Roman Emperor Julius Caesar also invented his own code, by moving each letter of the
alphabet along three places, so that A became D, B became E and so on. Thus, CAESAR in encrypted
into FDHVFU.
In 1838 the American, Samuel Morse, created an entirely new way of sending messages quickly
over long distances, by encoding every letter into a sequence of long and short electromagnetic
signals of “dots” and “dashes” and then encrypting secret messages.
Before the Second World War the Germans designed a special cipher machine called Enigma
to encode their military messages. The Enigma machine could encode a message in more than
150 × 1018 different ways. It looked like a typewriter in a wooden box. The original message was
typed in and the encrypted message came out, by sending electric currents from the keyboard

Number Theory
273
through a set of rotors and a plugboard to light up the “code” alphabet. The Germans changed the
order of the rotors, their starting positions and the plugboard connections every day. Already before
the war, Polish cipher experts secretly began to try to crack the code. When Poland was invaded,
that task was taken over by the British Government Code and Cypher School at Bletchley Park,
where thousands of very clever mathematicians and linguists worked, one of them being Alan Tur-
ing (see the box at the end of Section 4.8 in Chapter 4), who was instrumental in breaking the code
of Enigma. For that purpose Turing and his collaborators designed and used a special decrypting
device called Bombe. It did help a lot that the British naval forces captured a German submarine
with an Enigma machine and codebooks on board in 1941, but when the Germans started using
more modern, four-rotor Enigma machines in February 1942, the code breaking task became enor-
mous. For that, the British team constructed the huge room-sized supercomputer Colossus, which
can now be put into a microprocessor the size of a thumb.
Source: http://archive.iwm.org.uk/upload/package/10/enigma.

6
Combinatorics
6.1.
Two basic counting principles
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
275
6.2.
Combinations. The binomial theorem . . . . . . . . . . . . . . . . . . . . . . . . .
284
6.3.
The principle of inclusion–exclusion . . . . . . . . . . . . . . . . . . . . . . . . . .
293
6.4.
The Pigeonhole Principle
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
299
6.5.
Generalized permutations, distributions and the multinomial theorem . . . . . . .
304
6.6.
Selections and arrangements with repetition; distributions of identical objects
. .
312
6.7.
Recurrence relations and their solution
. . . . . . . . . . . . . . . . . . . . . . . .
318
6.8.
Generating functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
329
6.9.
Recurrence relations and generating functions . . . . . . . . . . . . . . . . . . . .
337
6.10. Application: classical discrete probability . . . . . . . . . . . . . . . . . . . . . . .
343
Combinatorics is a branch of mathematics that studies finite, discrete objects. In this chapter
we will mostly concern ourselves with enumerative combinatorics, which studies ways to
count sets of finite discrete objects that satisfy given constraints. This typically involves
counting the number of ways in which certain patterns can be formed, and enables us to
answer questions like:
• How many possible different outcomes are there in a lottery draw and how many tickets do I need to
buy to stand at least a 1% chance of winning?
• In how many different ways can an amount of 5 euros be made up by coins?
• How many different DNA strands consisting of a hundred nucleotides are there?
• In how many different ways can a telephone call from Sydney to Moscow be routed through the
telephone network?
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

Combinatorics
275
As this list of questions might suggest, combinatorics has a wide variety of applications, both
inside and outside mathematics.
Apart from learning some fundamental and very useful counting techniques, the reader
who masters the content of this chapter will also gain some valuable experience in problem
solving and mathematical modelling: the two skills that mathematicians have that are prob-
ably most valuable for society. This chapter does not contain a lot of theoretical material; it
rather provides some basic principles and methods and shows how they can be applied to
solve a wide variety of problems. The problems are typically “word problems”, i.e. problems
formulated in everyday language, rather than in mathematical symbols. Solving a problem
like this requires first modelling it in some appropriate mathematical way and then finding a
suitable strategy based on combinatorial principles to solve it. For these reasons, solving com-
binatorial problems involves quite a bit of “art”. This is something that comes with experience,
and the exercises therefore take on a central role in this chapter.
6.1.
Two basic counting principles
In this section we first review two principles that lie at the heart of combinatorics, namely the
multiplicative and the additive counting principles. These two principles are so simple and
intuitive that you might, upon first acquaintance, be tempted to consider them rather trivial.
However, as the chapter progresses, it will become clear that almost every counting strategy
and technique we develop is reducible to these two principles in some way.
We first introduce the multiplicative counting principle by way of an example. Consider
the three towns A, B and C pictured below:
A
B
C
There are five roads from A to B and three roads from B to C. In how many ways can I
drive from A to C via B? Each of the five roads from A to B can be combined with each of the
three roads from B to C. Therefore, every such combination corresponds to an ordered pair
(i‚ j) where 1 ≤i ≤5 and 1 ≤j ≤3. Thus there are 5 × 3 = 15 ways to go from A via B to C.
Here is the general counting principle behind this argument.
The multiplicative counting principle (MCP)
Consider a sequence of m > 1 events E1‚ E2‚ E3‚ …‚ Em where E1 can occur in n1 different ways;
then E2 can occur in n2 different ways, e.g. for each 2 ≤k ≤m, Ek can occur in nk different ways
after the preceding events E1‚ E2‚ …‚ Ek−1 have occurred. Then the entire sequence of events
E1‚ E2‚ E3‚ …‚ Em can occur in n1 × n2 × n3 × · · · × nm different ways.

276
Logic and Discrete Mathematics: A Concise Introduction
It is important to note that in the formulation of the multiplicative counting principle
we use the number nj of ways in which event Ej can occur given that E1 to Ej−1 have already
occurred. This is because the number of ways in which Ej can occur might depend on how
the events E1 to Ej−1 have occurred. If for each event Ei, 1 ≤i ≤m, the number of ways in
which Ei can occur is independent of the ways in which E1 to Ej−1 occurred, we call the events
E1‚ E2‚ E3‚ …‚ Em commuting. We now have the following easy corollary of the multiplicative
principle.
The multiplicative counting principle for commuting events
Given a sequence of m commuting events E1‚ E2‚ E3‚ …‚ Em such that Ei can occur in ni ways for
1 ≤i ≤m, then the entire sequence of events E1‚ E2‚ E3‚ …‚ Em can occur in n1 × n2 × n3 × · · · ×
nm ways.
Using the term “event” is just one way of formulating the MCP. When applying the
principle it sometimes seems more appropriate to think in terms of a process that consists of m
steps or tasks E1‚ E2‚ E3‚ …‚ Em, where the step or task Ei can be completed in ni ways, 1 ≤i ≤m.
Thus, in the example of routes between town A to C via B we want to know the number of
different outcomes of the process of putting together such a route. This process consists of two
steps, namely firstly choosing a road from A to B and secondly choosing a road from B to C.
Here are a few simple applications of the multiplication principle.
Example 6.1.1
How many different four-digit natural numbers containing only odd digits are there?
Solution
To answer this question we rephrase it as follows: in how many different ways can we choose
odd digits to fill each of the four positions in the four-digit integer? This choice process is
naturally broken down into four steps corresponding to choosing the digit for the thousands,
hundreds, tens and units positions, respectively. Each of these steps can be completed in 5
different ways, as there are 5 odd digits to choose from, namely 1‚ 3‚ 5‚ 7 and 9:
Thousands
Hundreds
Tens
units
5
choices
5
choices
5
choices
5
choices
Moreover, these steps are independent, since choosing a digit for any position does not
affect the available choices for any other position. Therefore, by the MCP, the number of
different four-digit natural numbers containing only odd digits is 5 × 5 × 5 × 5 = 54.

Combinatorics
277
Example 6.1.2
How many different arrangements of the five letters a‚ b‚ c‚ d‚ e can be made?
Solution
To make an arrangement we need to fill five positions with letters from a‚ b‚ c‚ d‚ e, without
repeating a letter. Starting from the left, this gives five steps that are not independent: the
first position can be filled in five ways as any one of the letters can be used. Any one of
the remaining four letters can be placed second. The third letter is chosen from the remaining
three and the fourth letter from the remaining two. There is only one left to fill the fifth place:
5
choices
4
choices
3
choices
2
choices
1
choice
Position 1
Position 2
Position 3
Position 4
Position 5
Therefore, by the multiplication principle, there are 5 × 4 × 3 × 2 × 1 = 5! = 120 different
arrangements in total.
Example 6.1.3
How many arrangements of n different objects are there?
Solution
This is a direct generalization of the question in Example 6.1.2. Reasoning in the same way,
there are n ways to place the first object, n −1 ways to place the second object, n −2 ways
to place the third object, …, three ways to place the (n −2)nd object, two ways to place the
(n −1)st object and only one way to place the last object. Thus, in total there are n × (n −1) ×
(n −2) × · · · × 3 × 2 × 1 = n! different arrangements.
Example 6.1.4
In how many ways can 10 different books be arranged on a shelf so that two specific books
are next to each other?
Solution
To make sure that these two books end up together we could tie them together with string.
Thus, considering these two books as one, the question becomes: In how many ways can nine
different books be arranged? We know the answer is 9! However, the two books can be tied
together on the shelf in two ways (depending on which one we put on the left and which on
the right) so that there are 2 × 9! possible arrangements with the two always next to each other.

278
Logic and Discrete Mathematics: A Concise Introduction
Permutations
The type of counting problems in Examples 6.1.2–6.1.4 is very common and there is a special
name for it. A permutation of n distinct objects is an arrangement, or ordering, of all n objects.
The number of permutations of n distinct objects is denoted by P(n) and is, as we have seen,
equal to n!.
Example 6.1.5
In how many ways can a first, second and third prize be awarded in a class of 22 students?
Solution
By the multiplicative principle, there are 22 × 21 × 20 ways.
Note that the answer can be written using factorial notation as follows:
22 × 21 × 20 = 22 × 21 × 20 × 19 × · · · × 3 × 2 × 1
19 × · · · × 3 × 2 × 1
= 22!
19! =
22!
(22 −3)!.
r-Permutations and arrangements
The type of problem in Example 6.1.5 occurs very often and is a generalization of the permu-
tation problems in the previous examples. It leads to the following notion. An r-permutation
of n distinct objects is an (ordered) arrangement of r of these n objects. The number of
r-permutations of n distinct objects is denoted by P(n‚ r) and, by the MCP, is equal to
P(n‚ r) = n × (n −1) · · · × (n −r + 1) =
n!
(n −r)!.
In particular, note that P(n) = P(n‚ n) = n!.
We also refer to r-permutations as arrangements. Sometimes they are also called varia-
tions.

Combinatorics
279
Example 6.1.6
How many ways are there to select a committee consisting of a chairperson, a secretary and
a treasurer from a group of 12 people?
Solution
The problem reduces to selecting three people out of a possible 12 and assigning them the
three portfolios of chairperson, secretary and treasurer. If we fix these three portfolios in a cer-
tain order, say chairperson first, secretary second and treasurer third, assigning them to our
chosen three candidates is equivalent to ordering the three candidates, with each candidate
then being assigned to the portfolio corresponding to his/her position in the ordering. So it
becomes clear that we are after ordering 3 objects chosen out of 12. By the discussion above,
the number of ways to do this is given by
P(12‚ 3) =
12!
(12 −3)! = 12!
9! = 12 × 11 × 10 = 1320.
Example 6.1.7
Let A and B be sets of cardinality n and m, respectively, for n‚ m ∈ℕ.
1. How many functions are there from A into B?
2. How many injective (one-to-one) functions are there from A into B?
Solution
1. We will count the number of ways in which a function from A into B can be constructed.
Suppose a1‚ a2‚ …‚ an are the elements of A. For each ai we need to pick an image in B.
As there are m elements in B this can be done in m ways for each ai. Now, by the MCP
(noting the independence of the events) we have (m × m × m × · · · × m)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
n times
= mn functions
from A into B.
2. We begin by noting that if n > m then there can be no injective function from A to B (more
on this later, when we discuss the Pigeonhole Principle in Section 6.4), so we can assume
that n ≤m. We need to restrict the construction in (1) so that no two elements in A are
assigned the same image in B. The number of ways in which an image can be picked now
depends on previous choices for images of elements of A, viz. for a1 there are m possible
choices, then there remain (m −1) choices for a2, (m −2) choices for a3, etc. Applying the
MCP we obtain m(m −1)(m −2) · · · (m −n + 1) = P(m‚ n) injective functions from A into
B.

280
Logic and Discrete Mathematics: A Concise Introduction
When counting a set of objects, it is sometimes convenient to first divide it into subsets,
which are easier to count, and then to add up the results. For this to work, the subsets must
form a partition (recall Definition 2.5.7). This is the gist of the following counting principle.
The additive counting principle (ACP)
Let S1‚ S2‚ …‚ Sm be a partition of a set S, i.e. S = S1 ∪S2 ∪· · · ∪Sm and Si ∩Sj = ∅for all i ≠j.
Further, suppose that |Si| = ni for 1 ≤i ≤m. Then
|S| = |S1| + |S2| + |S3| + · · · + |Sm|.
Example 6.1.8
Suppose you have five different English books, six different Afrikaans books and eight dif-
ferent Zulu books. In how many ways can you pick an (unordered) pair of books in different
languages?
Solution
To count the set of all pairs of books in different languages, a good strategy is to partition
this set into subsets according to the pair of languages involved, count these separately and
then apply the ACP. Thus, we consider the three subsets, consisting of all English–Afrikaans
pairs, all English–Zulu pairs and all Afrikaans–Zulu pairs, respectively. These clearly form
a partition of the set we want to count. To count the English–Afrikaans book pairs we now
apply the MCP: there are 5 options for the English book and 6 for the Afrikaans, giving 5 × 6 =
30 pairs. Similarly there are 5 × 8 = 40 English–Zulu pairs and 6 × 8 = 48 Afrikaans–Zulu
pairs. Thus, by the ACP, there are 30 + 40 + 48 = 118 ways to choose the pair of books.
Example 6.1.9
How many four-digit integers containing exactly three odd digits are there?
Solution
These integers contain three odd digits and one even digit. The number of possibilities for
the even digit depends on the position in which it occurs: in the thousands position there
are 9 options, as 0 is excluded there, while in each of the other three positions there are 10
options. Consequently a natural way to break the problem up is to partition the integers we
want to count into 4 subsets depending on the position in which the even integer occurs.
Denoting the set of four-digit integers containing exactly three odd digits and one even digit
in the ith position by Si we have
|S1| = 4 × 53 and |S2| = |S3| = |S4| = 54.
By the ACP, the total number is 4 × 53 + 54 + 54 + 54 = 4 × 53 + 3 × 54 = 2375.

Combinatorics
281
Counting the complement
Directly counting the number of objects that have a certain property is sometimes more dif-
ficult than counting those that lack the property. Then we can apply a kind of “back door”
approach: instead of counting the number of objects that have the desired property, we count
the number of objects that do not have that property and then subtract them from the total
number of objects under consideration. This strategy is often called “counting the complement”.
Example 6.1.10
How many four-digit natural numbers are there that contain the digit 7 at least once?
Solution
The four-digit natural numbers are those between 1000 and 9999, in total 9000. We can easily
count those that do not contain 7. They are 8 × 9 × 9 × 9 = 5832; hence the ones that do contain
7 are 9000 −5832 = 3168.
Addition or multiplication?
You might sometimes find that you are not sure whether you need to apply the addition prin-
ciple or the multiplication principle. In such cases the following rule of thumb is often useful:
when the numbers represent the outcomes of the steps used to construct the objects you are
counting, multiply them; when the numbers represent the sizes of subsets of complete objects,
add them. As a further aid in making this distinction, you can ask yourself the question: “Am
I constructing the object or am I dealing with sets of complete objects?”
6.1.1.
Exercises
➊An airline has three flights between New York and London and five flights between London
and Moscow. How many flights can it offer from New York to Moscow passing through
London?
➋A restaurant offers 25 different beverages, 6 different starters, 7 different main courses and
4 different desserts.
(a) How many ways are there to order a three course meals with a beverage?
(b) How many three course meals are there if chocolate mousse is selected as a dessert?
(c) How many ways are there to order a three course meal if either fillet steak or grilled
salmon is ordered as a main course?
➌How many four-digit integers have no equal consecutive digits?
➍How many different ways are there for 10 people to form a queue? How many if Rob, Alice
and Lee want to stay together?
➎.(a) How many ways are there to seat 12 people along one side of a long table?
(b) How many ways are there to seat 12 people around a round table, if all rotations of a
given seating arrangement are regarded as the same?

282
Logic and Discrete Mathematics: A Concise Introduction
➏How many ways are there to arrange the letters in the word ISOGRAM so that:
(a) G is not immediately followed by R?
(b) G is immediately followed by either S or M?
➐How many ways are there to seat 5 men and 5 women along one side of a long table with
10 seats? How many ways if men and women must alternate seats?
➑You can travel between the airport and the soccer stadium directly using either the bus,
tram, metro or taxi; between the soccer stadium and the opera house directly using the bus,
tram or taxi; and between the opera house and airport directly using the ferry or taxi.
(a) How many different ways altogether are there to travel from the airport to the opera
house?
(b) How many different ways are there to travel from the airport to the opera house and
back?
(c) How many different ways are there to travel from the airport to the opera house if any
form of transport may be used at most once?
(d) How many different ways are there to travel from the airport to the soccer stadium if
at most two different forms of transport may be used?
➒There are 12 different books and 9 different CDs. In how many ways can Alice pick a book
or a CD and then Bob pick a book and a CD?
➓How many ways are there to roll a pair of dice, one red and one blue, to obtain a sum
divisible by 3?
11 How many different license plates are there if any license plate must consist of three con-
secutive letters (and no vowels (a, e, i, o, u) are allowed) followed by three consecutive
digits?
12 .(a) How many four-letter words (i.e. any sequences of four letters) can be made using only
letters from a, b, c, d, e and f, at most once each?
(b) How many of them contain the letter a?
(c) How many of them contain at least one of the letters a and b?
(d) How many of them contain a but not b?
(e) How many of them contain exactly one of the letters a and b?
(f) How many of them contain both letters a and b?
13 Answer the questions from the previous problem if every letter can be used repeatedly.
14 How many times does the digit 4 occur in a list consisting of all the numbers from 1 to
10 000?
15 How many different numbers can be formed by the product of two or more of the numbers
2, 2, 2, 3, 5, 5, 7?
16 A binary sequence is a sequence consisting of 1’s and 0’s.
(a) How many different n-digit binary sequences are there?
(b) How many of them begin and end with the same digit?
(c) How many begin and end with different digits?
(d) How many have no two consecutive digits the same?

Combinatorics
283
17 A ternary sequence is a sequence consisting of 0’s, 1’s and 2’s.
(a) How many different n-digit ternary sequences are there?
(b) How many of them begin and end with the same digit?
(c) How many begin and end with different digits?
(d) How many have no two consecutive digits the same?
18 Six computers on a network are infected by a virus. Every minute each infected computer
spreads the virus to six uninfected computers and then crashes. After ten minutes, how
many computers have crashed?
Stirling’s approximation of n!
Working out a particular value of n! can require a lot of multiplication. In applications it is often
sufficient to have a good approximation. Stirling’s approximation formula
S(n) =
√
2𝜋n
(n
e
)n
gives a good asymptotic approximation of n!, meaning that
lim
n→∞
n!
S(n) = 1.
The following table lists the values of n! together with those of S(n) and n!∕S(n) for n = 1‚ …‚ 18,
rounded to two decimal places.
Table 6.1 The first 18 factorials and Stirling numbers
n
n!
S(n)
n!
S(n)
1
1
0.92
1.08
2
2
1.92
71.04
3
6
5.84
1.03
4
24
23.51
1.02
5
120
118.02
1.02
6
720
710.08
1.01
7
5 040
4 980.40
1.01
8
40 320
39 902.40
1.01
9
362 880
359 536.87
1.01
10
3 628 800
3 598 695.62
1.01
11
39 916 800
39 615 625.05
1.01
12
479 001 600
475 687 486.47
1.01
13
6 227 020 800
6 187 239 475.19
1.01
14
87 178 291 200
86 661 001 740.60
1.01
15
1 307 674 368 000
1 300 430 722 199.47
1.01
16
20 922 789 888 000
20 814 114 415 223.10
1.01
17
355 687 428 096 000
353 948 328 666 101.00
1.00
18
6 402 373 705 728 000
6 372 804 626 194 310.00
1.00

284
Logic and Discrete Mathematics: A Concise Introduction
6.2.
Combinations. The binomial theorem
In the previous section we considered the number of ways to choose and order objects from a
given set. Very often the order of the selected objects is irrelevant. Such selections, also known
as combinations, are the topic of this section. The numbers of such combinations crop up in
various places in mathematics and, in particular, as the so-called binomial coefficients, which
we will also treat here.
6.2.1.
Counting sheep and combinations
Suppose we have five books A‚ B‚ C‚ D‚ E, of which we want to choose three without taking
into account the order of choices: that is, the choices ABC and BAC are the same as the choice
ACB, etc. Applying the MCP directly does not work here because selecting the books one by
one automatically yields an ordering. To deal with the problem we will use a simple trick,
sometimes called the shepherd’s principle. Here is the story behind its name: a certain shep-
herd had a very large flock of sheep, which he had to count every evening after returning from
pasture. Once someone asked him “How do you manage to count so many sheep?” “Oh, that
is easier than it seems”, replied the shepherd, “for I simply count their legs and then divide
by 4.” Though this sounds like a silly joke, sometimes it is easier, indeed, to count the “legs”
than the “sheep”. In our case, let the “sheep” be the possible three-books selections from the
given five books and let the “legs” of each “sheep” be the possible permutations of the selec-
tion. Consider any choice of “sheep”, say {A‚ B‚ C}. For this choice there are 3! permutations,
namely ABC, ACB, BAC, BCA, CAB and CBA. So each “sheep” has 3! = 6 “legs”. We know
that the total number of “legs” is the number of arrangements of 3 books out of 5, which is
P(5‚ 3). Therefore, applying the shepherd’s trick, we find that the number of all “sheep”, i.e.
all combinations of 3 books out of 5, is
C(5‚ 3) = P(5‚ 3)
3!
=
5!
(5 −3)!3!
= 5 ⋅4
2 ⋅1 = 10
We can easily generalize the argument above by replacing 5 with n and 3 with r, to obtain
the following theorem.
Theorem 6.2.1 The number of combinations, i.e. selections where the order is not taken into account,
of r objects out of n objects is
C(n‚ r) = P(n‚ r)
r!
=
n!
(n −r)!r!.

Combinatorics
285
Example 6.2.2
How many different committees of four people can be selected out of a meeting of seven
people?
Solution
Note that, unlike Example 6.1.6, the order of people in the committee is not important now
as there are no distinguished roles within the committee. So the answer is
C(7‚ 4) =
7!
(7 −4)!4!
= 7 × 5 = 35.
Example 6.2.3
From a meeting of 6 mathematicians and 5 computer scientists, a committee of 5 people has
to be chosen, with the restriction that no more that 3 committee members may be computer
scientists. How many such committees are there?
Solution
The most efficient approach is to count the complement and subtract from the total number
of possible committees.
The total number of possible five-member committees in the meeting is C(11‚ 5) = 462.
Now the committees we do not want (those in the complement) are those that contain exactly
4 or 5 computer scientists. We compute the number of committees with 4 computer scientists
as follows: first pick 4 of the 5 computer scientists (in C(5‚ 4) ways) and then pick one math-
ematician for the fifth member (in C(6‚ 1) ways). Thus, by the multiplication principle, there
are C(5‚ 4) × C(6‚ 1) committees that contain exactly 4 computer scientists. Likewise, there is
C(5‚ 5) = 1 committee containing all 5 computer scientists. Thus, by the addition principle,
there are C(5‚ 4) × C(6‚ 1) + C(5‚ 5) = 31 committees in the complement. Hence the number of
committees we want is 462 −31 = 431.
Another approach would be to count the number of committees we are interested in
directly, i.e. count the committees containing exactly 0, 1, 2 and 3 computer scientists, respec-
tively, and add the results. There are C(6‚ 5) × C(5‚ 0), C(6‚ 4) × C(5‚ 1), C(6‚ 3) × C(5‚ 2) and
C(6‚ 2) × C(5‚ 3) such committees, respectively, and hence there are C(6‚ 5) × C(5‚ 0) + C(6‚ 4) ×
C(5‚ 1) + C(6‚ 3) × C(5‚ 2) + C(6‚ 2) × C(5‚ 3) = 6 × 1 + 15 × 5 + 20 × 10 + 15 × 10 = 431.
Yet another approach one might be tempted to suggest would be the following. The
requirement that there should be no more than 3 computer scientists on the committee
is clearly equivalent to the requirement that there must be at least 2 mathematicians on
that committee. Therefore, begin by picking 2 mathematicians, there are C(6‚ 2) ways, and
then pick the other 3 committee members from the remaining 11 −2 = 9 people, there are
C(9‚ 3) ways. This gives us a total number of C(6‚ 2) × C(9‚ 3) = 1260 committees satisfying
the requirements. This argument, however, is wrong! It counts some committees more than
once. (Think about it!)

286
Logic and Discrete Mathematics: A Concise Introduction
6.2.2.
Some important properties
Now we will establish some important properties of the numbers C(n‚ r).
Theorem 6.2.4 If n,r and s are non-negative integers with r‚ s ≤n then the following hold:
1. C(n‚ 0) = C(n‚ n) = 1.
2. C(n‚ r) = C(n‚ n −r).
3. C(n‚ r) + C(n‚ r −1) = C(n + 1‚ r).
4. If C(n‚ r) = C(n‚ s) and r ≠s, then n = r + s.
Proof: All these follow easily using the definition of C(n‚ r) and some algebraic manipulations,
but we will give more enlightening alternative proofs of Properties 1, 2 and 3, using combina-
torial arguments.
1. There is only one way to choose no objects out of n and there is also only one way to
choose all the objects.
2. C(n‚ r) is equal to the number of ways of choosing a committee of r people from a meeting
of n people. This is the same as choosing the n −r people who will not serve on the
committee, which can be done in C(n‚ n −r) ways.
3. Suppose a committee of r people is to be chosen from a meeting of n + 1 people; there are
C(n + 1‚ r) ways to do this. Further suppose that in the meeting is a certain Mrs Smith.
Now, either Mrs Smith serves on the committee or she does not. So the total number of
possible committees will be the number on which she serves, plus the number of those
on which she does not serve. The number of committees on which she serves is equal to
C(n‚ r −1)–we pick Mrs Smith and then the other r −1 members. The number of those
on which she does not serve is equal to C(n‚ r)–we select the committee of r from the
remaining n people in the meeting. So C(n + 1‚ r) = C(n‚ r) + C(n‚ r −1).
4. If r ≠s then either r < s or s < r. Suppose that r < s. Here we have
n!
(n −r)!r! =
n!
(n −s)!s!
and hence
s!
r! = (n −r)!
(n −s)!.
Thus (recall the assumption that r < s)
s(s −1)(s −2) · · · (r + 1) = (n −r)(n −r −1) · · · (n −s + 1).
The left-hand side and the right-hand side above are both products of s −r factors of
consecutively decreasing integers. Therefore it must be the case that s = n −r, i.e. n =
s + r. The case s < r is completely symmetric.

Combinatorics
287
6.2.3.
Pascal’s triangle
An often used alternative notation for the number C(n‚ r) is
(
n
r
)
, read as “n choose r”.
Properties 1 and 2 of the forgoing theorem illustrate some of the symmetries in the
sequence
(
n
0
)
‚
(
n
1
)
‚ …‚
(
n
n−1
)
‚
(
n
n
)
, and number 3 indicates the relationship of this sequence
with
(
n+1
0
)
‚
(
n+1
1
)
‚ …‚
(
n+1
n
)
‚
(
n+1
n+1
)
. These, and many other relationships, become visually
clear when these sequences are arranged to form the triangular configuration known as
Pascal’s triangle.1 It is formed by listing all numbers:
0
0
1
0
1
1
2
0
2
1
2
2
3
3
3
2
3
1
3
0
4
0
4
1
4
2
4
3
4
4
5
5
5
4
5
3
5
2
5
1
5
0
6
0
6
1
6
2
6
3
6
4
6
5
6
6
Calculating the respective numbers we obtain:
1
1
1
1
1
1
1
1
6
6
15
15
20
···
···
1
5
5
10
10
1
4
4
6
1
3
3
1
2
1
According to the properties in Theorem 6.2.4, this triangle can be constructed as follows:
first, place 1’s on the two sides of the triangle and then compute row-by-row the entries inside
by using Property 3, saying that every number inside the triangle is the sum of the two diag-
onally above it.
6.2.4.
The binomial theorem
The expansion (x + a)2 = x2 + 2xa + a2 is well known to all of us. Here we will generalize it to
an expansion of (x + a)n for any n, to obtain the so-called binomial theorem – an algebraic
identity which we will derive through purely combinatorial arguments using combinations.
We will start by taking a closer look at the expansion of (x + a)3 by simply multiplying out the
1 See the box at the end of this section for more on Pascal’s triangle.

288
Logic and Discrete Mathematics: A Concise Introduction
three equal sums:
(x + a)3 = (x + a)(x + a)(x + a)
= xxx + xxa + xxa + xxa + xaa + xaa + xaa + aaa
Note that each term in the expansion above arises as the product of three factors, one
picked from each pair of brackets. There is only one term xxx, as there is only one way in
which this can arise, namely by multiplying the x’s from each of the three pairs of brackets.
There are C(3‚ 2) = 3 products xxa as these arise by selecting the x’s from any two of the three
pairs of brackets of a from the other. Likewise, there are C(3‚ 2) = 3 terms xaa and C(3‚ 3) = 1
term aaa. Thus, when collecting the equal terms together, we find that
(x + a)3 = C(3‚ 0)x3 + C(3‚ 1)x2a + C(3‚ 2)xa2 + C(3‚ 3)a3.
We can now apply the very same reasoning to the expansion of (x + a)n. This expansion
will be a sum of products of n x’s and a’s, one picked from each of the n factors x + a in (x + a)n.
Thus, all these products are of the type xn−rar for 0 ≤r ≤n. Now, note that xn−rar is obtained
by selecting r of the a’s and then (automatically) n −r of the x’s from the n factors in (x + a)n.
This can be done in C(n‚ r) ways, so the coefficient in front of xn−rar is C(n‚ r). This calculation,
applied for each r, gives the explicit formula of the expansion.
Theorem 6.2.5 Binomial theorem For every pair of real numbers x and a and every natural number
n the following holds:
(x + a)n = C(n‚ 0)xn + C(n‚ 1)xn−1a + C(n‚ 2)xn−2a2 + · · · + C(n‚ n)an
=
n
∑
r=0
C(n‚ r)xn−rar.
Example 6.2.6
Calculate (11)3 using the binomial theorem.
Solution
(11)3 = (10 + 1)3 = 103 + C(3‚ 1)(1)(10)2 + C(3‚ 2)(1)2101 + 13
= 1000 + 3(100) + 3(10) + 1
= 1331.
By replacing a with −a in the binomial formula above we obtain
(x −a)n =
n
∑
r=0
(−1)rC(n‚ r)xn−rar = C(n‚ 0)xn −C(n‚ 1)xn−1a + · · · + (−1)nan.

Combinatorics
289
Example 6.2.7
Expand (x3 −2)4 in powers of x.
Solution
Using the formula above we find
(x3 −2)4 = C(4‚ 0)(x3)4 + C(4‚ 1)(x3)3(−2)1 + C(4‚ 2)(x3)2(−2)2
+C(4‚ 3)(x3)1(−2)3 + C(4‚ 4)(−2)4
= x12 −2 ⋅4x9 + 6 ⋅4x6 −4 ⋅8x3 + 16
= x12 −8x9 + 24x6 −32x3 + 16.
Example 6.2.8
Determine the term that is independent of x and the coefficient of x6 in the expansion of
[
x −2
x
]10
.
Solution
The general term is
tr+1 = C(10‚ r)x10−r
[
−2
x
]r
= C(10‚ r)(−2)rx10−2r.
In the term that is independent of x, x10−2r = x0, so that 10 −2r = 0, r = 5 and the required
term is t6 = (−2)5C(10‚ 5).
Now, given that tr+1 = C(10‚ r)(−2)rx10−2r, for the coefficient of x6 we obtain the equation
10 −2r = 6, with the solution r = 2. The term is therefore t3 = C(10‚ 2)(−2)2x6 and the coeffi-
cient of x6 is C(10‚ 2)(−2)2 = 180.
6.2.5.
Exercises
➊
.(a) A certain engineering firm employs 12 mechanical engineers, 7 civil engineers and 3
electrical engineers. A committee is to be appointed from among the 22 engineers.
(b) How many five-member committees can be appointed?
(c) How many five-member committees containing at least one electrical engineer can be
formed?
(d) How many five-member committees containing at least one engineer of each type can
be formed?
(e) How many committees can be formed in which there are more mechanical engineers
than civil engineers and more civil engineers than electrical engineers?

290
Logic and Discrete Mathematics: A Concise Introduction
➋
In how many ways can a committee of 3 ladies and 4 men be chosen from 8 ladies and 7
men? What is the number of committees if Mrs Smith refuses to serve on the committee
with Mr Jones?
➌
In how many ways can
(a) a female chairperson and a male secretary be chosen from a meeting of 6 men and 5
women?
(b) a chairman, vice-chairman, secretary and treasurer be chosen from a meeting of 15
people?
(c) 3 out of 8 given books be arranged on a shelf?
(d) I make a 4-letter “word” (with or without meaning) with four different letters of the
26-letter Latin alphabet?
(e) I hang my 6 shirts and 4 suits in the cupboard?
(f) I hang my 6 shirts and 4 suits in the cupboard if every shirt must hang on the left of
every suit?
(g) I arrange my 8 math books, 5 physics books and 7 chemistry books on my bookshelf
if all books of each subject must be together?
➍
In how many ways can
(a) 11 books be chosen from 13 different books?
(b) I prepare for a trip by choosing 3 of my 6 shirts and 5 of my 7 pairs of socks?
(c) a girl fill her doll house by choosing 3 dolls from 6, 8 pieces of furniture from 9, 2
carpets from 4 and 2 plants from 5?
(d) a pack of 52 cards be dealt into 4 hands of 13 cards each?
➎
How many ways are there to arrange 7 identical copies of Pride and Prejudice and 8 identical
copies of Sense and Sensibility on a shelf?
➏
How many ways are there to place 8 identical black pawns and 8 identical white pawns
on a standard chess board?
➐
How many different subsets (including the empty set) does an n-element set have?
Compare this with the number of binary (0–1) sequences of n terms.
➑
Let Ω = {𝛼‚ 𝛽‚ 𝛾‚ 𝛿‚ 𝜖‚ 𝜁‚ 𝜂‚ 𝜃}.
(a) How many four-element subsets does Ω have?
(b) How many five-element subsets of Ω can be formed if 𝛽must be in the set?
(c) How many five-element subsets of Ω can be formed if 𝛾may not be in the set?
(d) How many five-element subsets of Ω can be formed containing 𝛾but not containing 𝜁
or 𝛼?
(e) How many subsets of Ω are there that contain at least 4 elements?
(f) How many subsets of Ω are there that contain fewer than 7 elements?

Combinatorics
291
➒
A mathematics department receives 60 applications for 5 vacant PhD positions. Suppos-
ing that every applicant meets the requirements for each of the positions, in how many
different ways can the department allocate the positions if:
(a) the positions are identical?
(b) the positions are all different?
(c) the five positions consist of three identical positions in Functional Analysis and two
identical positions in Universal Algebra?
➓∗If a set S has at least a 100 different subsets of size 5, what is the smallest size S can be?
11∗If one quarter of all subsets of size 5 of the set {1‚ 2‚ 3‚ …‚ m} contains the element 2, deter-
mine m.
12
Expand in powers of x:
(a) (x + 1)7
(b) (x −2)4
(c)
(
3x −1
2
)3
(d)
[
x
4 −4
x
]5
13
Expand in powers of x and y:
(a) (3x −2y)4
(b) (x2 + 3y2)5
14
Determine the coefficient of:
(a) x6 in (x + 1)8
(b) x−4 in
[
2 −1
x
]5
(c) x8y5 in (3x −4y)13
(d) x9y14 in (x3 −3y2)10

292
Logic and Discrete Mathematics: A Concise Introduction
Pascal’s triangle
1
1
1
1
2
1
1
3
3
1
1
4
6
4
1
1
5
10
10
5
1
1
6
15
20
15
6
1
1
7
21
35
35
21
7
1
1
8
28
56
70
56
28
8
1
The table above gives the first nine rows of a simple but remarkable construction of numbers
arranged in a triangle, where all entries on the 2 sides are 1 and all other entries in every row are
obtained by adding the entries in the previous row that are placed diagonally above that entry. This
construction has roots going back more than two thousand years, but is known in the West as Pas-
cal’s triangle after the French mathematician, physicist and philosopher Blaise Pascal (1623–1662)
(see the box at the end of Section 6.6), who published the treatise Trait du Triangle Arithmtique
studying this triangle. The triangle appears in Ancient Greek mathematics and also in the Chan-
dahsastra, a Sanskrit text composed around 200 BC in India. In Persia (now Iran) it was studied by
the poet, astronomer and mathematician Omar Khayyám (1048–1131), so in Iran it is referred to as
the Khayyám–Pascal triangle. Pascal’s triangle appears in the work of the Chinese mathematician
Jia Xian (1010–1070) and again later in that of Yang Hui (1238–1298). In China Pascal’s triangle is
known as Yang Hui’s triangle.
If we start counting at the 0th row, then the nth row consists of the binomial coefficients
(
n
0
)
‚ …‚
(
n
n
)
. The rule of the construction corresponds to the fact that
(
n+1
k
)
=
(
n
k−1
)
+
(
n
k
)
. We
mention just three more of the many fascinating properties of Pascal’s triangle:
• The sum of the entries in row n is equal to 2n, e.g. the entries in row 5 sum to 1 + 5 + 10 +
10 + 5 + 1 = 32 = 25. This corresponds to the fact that a set of n elements has 2n different sub-
sets and the binomial coefficients appearing in row n count the number of subsets of size 0,
size 1, … , size n.
• Taking the numbers in row n as the digits of a number and carrying numbers greater than
9 appropriately, the number obtained is always equal to 11n. For example, row 1 gives 11,
row 2 gives 121, which is 112, row 3 gives 1331 = 113 and row 5 gives 1 × 105 + 5 × 104 + 10 ×
103 + 10 × 102 + 5 × 101 + 1 × 100 = 161 051 = 115.
• If n is a prime number, then all entries in row n are multiples of n.

Combinatorics
293
6.3.
The principle of inclusion–exclusion
The addition principle enables us to count the elements of a set S by counting the elements of
its subsets, if those subsets form a partition of S. However, this is often not the case because the
subsets are not disjoint. In this section we will derive the so-called Inclusion–Exclusion Prin-
ciple (IEP), which will help us to deal with such cases. We will need the following preliminary
result.
Lemma 6.3.1 Let A and B be subsets of some finite set U. Then
1. |A\B| = |A| −|A ∩B|.
2. |Ac| = |U| −|A|.
Proof: These two facts follow from the additive counting principle, by noting, respectively, that
A\B and A ∩B form a partition of A and that A and Ac form a partition of U.
Proposition 6.3.2 (Inclusion – exclusion principle for two sets) Let A and B be finite sets (see
Figure 6.1). Then
|A ∪B| = |A| + |B| −|A ∩B|.
Proof: We note that
A ∪B = (A\B) ∪(B\A) ∪(A ∩B)‚
where (A\B), (B\A) and (A ∩B) are clearly pairwise disjoint sets. Hence, by the addition prin-
ciple,
|A ∪B| = |A\B| + |B\A| + |A ∩B|.
By Lemma 6.3.1 we have |A\B| = |A| −|A ∩B| and |B\A| = |B| −|A ∩B|. Applying this to the
equation above we get, as desired:
|A ∪B| = |A| −|A ∩B| + |B| −|A ∩B| + |A ∩B| = |A| + |B| −|A ∩B|.
Here is a typical and straightforward application.
A
B
Figure 6.1: The inclusion–exclusion principle for two sets

294
Logic and Discrete Mathematics: A Concise Introduction
Example 6.3.3
In a sample of 100 university students 75 take mathematics, 50 take physics and 45 take both.
1. How many take at least one of these subjects?
2. How many take neither subject?
Solution
Let S be the sample set of students, M the subset of those taking mathematics and P the subset
of those taking physics. We are given that |S| = 100, |M| = 75, |P| = 50 and |M ∩P| = 45.
1. We have to determine |M ∪P|, which we do by the IEP:
|M ∪P| = |M| + |P| −|M ∩P| = 75 + 50 −45 = 80.
2. The number of students taking neither subject will be the total number less the number
taking either, i.e.
100 −80 = 20.
Intuitively, we can think of the IEP for two sets as follows: in order to count the elements
in the union of sets A and B we add the number of elements in A and the number of elements
in B. However, if these sets intersect, we have counted the elements in the intersection twice,
so we must subtract the number of those elements. Generalizing this reasoning to three sets
we obtain the three-set IEP:
|A ∪B ∪C| = |A| + |B| + |C| −|A ∩B| −|A ∩C| −|B ∩C| + |A ∩B ∩C|.
Explanation: after we add the sizes of the sets we have counted twice the elements in the
two-set intersections, so we subtract them, but then we have subtracted 3 times the size of the
three-set intersection, so we have to add it back.
The next example uses the formula above and again illustrates that it can sometimes be eas-
ier to count the complement of the set that one is interested in, rather than to count the set itself.
Example 6.3.4
We want to count the number of ternary sequences (sequences consisting of 0’s, 1’s and 2’s)
of length n that contain at least one 0, at least one 1 and at least one 2. Let U be the set of
all ternary sequences of length n. Note that |U| = 3n. Let A0‚ A1 and A2 be the subsets of
U containing all ternary sequences containing no 0’s, 1’s or 2’s, respectively. Clearly, |A0| =
|A1| = |A2| = 2n. We also have |A0 ∩A1| = |A0 ∩A2| = |A1 ∩A2| = 1 and |A0 ∩A1 ∩A2| = 0.
Thus the complement in U of our set consists of all ternary sequences that miss a 0, a 1 or a
2, i.e. A0 ∪A1 ∪A2, the size of which we obtain by the three-set IEP:
|A0 ∪A1 ∪A2| = |A0| + |A1| + |A2| −|A0 ∩A1| −|A0 ∩A2| −|A1 ∩A2| + |A0 ∩A1 ∩A2|
= 3(2n) −3(1) + 0 = 3(2n) −3.
So the number of ternary sequences that contain at least one 0, at least one 1 and at least one
2 is 3n −(3(2n) −3).

Combinatorics
295
Example 6.3.5
A car dealer has 30 cars in stock. Of these cars 20 have immobilizers, 8 have air conditioners
and 25 have fuel injection; 20 have at least two of these features and 6 have all three.
1. How may cars have at least one of the features?
2. How many have none of these features?
3. How many have exactly one?
Solution
Let C be the set of all cars in stock, I the set of cars with immobilizers, A the set of cars
with air conditioners and F the set of cars with fuel injection. The information we are given
amounts to the following: |C| = 30, |I| = 20, |A| = 8, |F| = 25, |(I ∩A) ∪(I ∩F) ∪(A ∩F)| = 20,
|I ∩A ∩F| = 6.
By the three-set IEP:
20 = |(I ∩A) ∪(I ∩F) ∪(A ∩F)|
= |(I ∩A)| + |(I ∩F)| + |(A ∩F)| −|(I ∩A) ∩(I ∩F)| −|(I ∩A) ∩(A ∩F)|
−|(I ∩F) ∩(A ∩F)| + |(I ∩A) ∩(I ∩F) ∩(A ∩F)|.
Each of the last four terms is equal to (I ∩A ∩F), so we get
20 = |(I ∩A)| + |(I ∩F)| + |(A ∩F)| −2|(I ∩A ∩F)|
and hence
|(I ∩A)| + |(I ∩F)| + |(A ∩F)| = 20 + 2(6) = 32.
We are now in a position to answer questions 1 to 3:
1. The number of cars with at least one feature is
|I ∪A ∪F| = |I| + |A| + |F| −|I ∩A| −|I ∩F| −|A ∩F| + |I ∩A ∩F|
= |I| + |A| + |F| −(|I ∩A| + |I ∩F| + |A ∩F|) + |I ∩A ∩F|
= 20 + 8 + 25 −32 + 6 = 27.
2. The number of cars having none these features is the total number of cars in stock minus
the number that have at least one, i.e. 30 −27 = 3.
3. The number of cars with exactly one feature will be the number with at least one minus
the number with at least two, i.e. 27 −20 = 7.
Following the pattern of reasoning for computing the formula of the three-set IEP we can
extend it to any finite family of finite sets. Roughly speaking, to determine the size of the
union A1 ∪A2 ∪· · · ∪An, we add the sizes of all possible intersections of an odd number of
sets among A1‚ A2‚ …‚ An and subtract the sizes of all possible intersections of an even number
of sets among A1‚ A2‚ …‚ An. Here are the formal details.

296
Logic and Discrete Mathematics: A Concise Introduction
Theorem 6.3.6 Inclusion-exclusion for n sets Let A1‚ A2‚ …‚ An be finite sets. Then
|||||
n
⋃
i=1
Ai
|||||
=
∑
I⊆{1‚ 2‚…‚ n}
I≠∅
(−1)|I|+1 |||||
⋂
i∈I
Ai
|||||
.
Proof: The proof is by induction on n. The base case for n = 2 was proven in Proposition 6.3.2.
The induction hypothesis is that the theorem holds for at most n −1 sets. We must now prove
the induction step for n sets. Let A1‚ A2‚ …‚ An be finite sets. In the chain of equations below, the
first equality follows by the associativity of union and the second by the induction hypothesis
applied to the two sets ⋃n−1
i=1 Ai and An. The third equality follows by the induction hypoth-
esis for the n −1 sets A1‚ …‚ An−1 and by the distribution of intersection over union. The last
equality follows by a third application of the induction hypothesis, this time to the n −1 sets
(A1 ∩An)‚ (A2 ∩An)‚ …‚ (An−1 ∩An).
|||||
n
⋃
i=1
Ai
|||||
=
||||||
(n−1
⋃
i=1
Ai
)
∪An
||||||
=
||||||
n−1
⋃
i=1
Ai
||||||
+ |An| −
||||||
(n−1
⋃
i=1
Ai
)
∩An
||||||
=
∑
I⊆{1‚ 2‚…‚ n−1}
I≠∅
(−1)|I|+1 |||||
⋂
i∈I
Ai
|||||
+ |An| −
||||||
n−1
⋃
i=1
(Ai ∩An)
||||||
=
∑
I⊆{1‚ 2‚…‚ n−1}
I≠∅
(−1)|I|+1 |||||
⋂
i∈I
Ai
|||||
+ |An| −
∑
J⊆{1‚ 2‚…‚ n−1}
J≠∅
(−1)|J|+1
||||||
⋂
j∈J
(Aj ∩An)
||||||
The required equality now follows by grouping together the terms that involve the intersection
of the same numbers of sets.
6.3.1.
Exercises
➊
In a sample of 100 households, it was found that 83 subscribe to Time Magazine, 41 subscribe
to The Economist and 32 subscribe to both. Find the number of families that
(a) subscribe to neither.
(b) subscribe to precisely one of the two.
➋
In a class of 200 students, 75 take mathematics, 70 take statistics, 75 take zoology, 35 take
mathematics and zoology, 20 take statistics and zoology, 40 take mathematics and statistics
and 15 take all three subjects.
(a) How many take at least one of the three subjects?
(b) How many take exactly one of the three subjects?
(c) How many take statistics or mathematics but not zoology?

Combinatorics
297
(d) How many do not take exactly two of the three subjects?
(e) How many take neither statistics nor mathematics?
➌
.(a) How many positive four-digit integers miss at least one of the digits 0 or 3?
(b) How many four digit-integers contain at least one of the digits 0 and 3?
➍
In a survey of 250 movie goers it was found that 95 liked action films, 125 liked comedies,
125 liked dramas, 25 liked action and drama, 45 liked comedy and drama, 35 liked action
and comedy and 5 liked all three.
(a) How many liked to watch action but not comedy?
(b) How many liked to watch action or comedy, but not drama?
(c) How many liked to watch action or comedy?
(d) How many do not watch comedy only?
(e) How many watch comedy and drama but not action?
➎
Out of a meeting of mathematicians, 22 like Combinatorics, 14 like Logic and 25 like Num-
ber Theory. Everyone who likes Logic likes Number Theory. There are 9 mathematicians
who like Combinatorics and Number Theory. Lastly, 5 like all three fields. How many
mathematicians at the meeting like at least one of these three subjects?
➏
How many 6-digit integers (with no leading zeros) have 2, 4 or 6 as a digit?
➐
How many positive integers less than or equal to 2013 are divisible by 3 or 4?
➑
How many positive integers less than or equal to 2013 are divisible by 3 or 5, but not by 4?
➒∗A basic computer sold by a computer firm may be supplied with any combination of five
additional features. Of the computers in stock each additional feature is possessed by 10
computers, each pair of additional features by 5 computers, any given triple of additional
features by 3 computers, any given quadruple of additional features by 2 computers and
all 5 additional features by 1 computer. Of the computers in stock 6 computers have no
additional features. How many computers does the company have in stock?
➓∗How many arrangements of the letters in POSTAL are there in which no letter is in its
original position?
11∗How many permutations of the 26 alphabet letters are there that contain none of the
sequences SO, SHE or WINS?
12∗How many permutations of the 26 alphabet letters are there that contain none of the
sequences HE, WAS, SO or BAD?
13∗On a construction line there are 5 workers and 10 different tasks to perform. Every worker is
assigned two tasks and the assignment of the tasks is changed every six months. How many
ways are there to assign two tasks to each worker such that no worker has the same two
tasks during the second six months of the year as he/she had during the first six months
of the year?
14∗If two identical dice are rolled n successive times, how many sequences of outcomes con-
tain all doubles?

298
Logic and Discrete Mathematics: A Concise Introduction
Venn diagrams
Diagrams of intersecting circles or, more generally, closed curves, have been used as graphical rep-
resentations of the relationships between sets for a long time. One of the first mathematicians to
use them was Euler (see the box at the end of Section 7.1 in Chapter 7). The best known method,
however, is due to the British logician and philosopher John Venn (1834–1923). While in Euler’s
diagrams the curves are allowed to intersect in any way so as to show the relationships between
particular sets, in the Venn diagram for n sets the curves must intersect in such a way as to divide
the plane into the 2n possible regions corresponding to relations between the sets.
Here are an Euler diagram and a Venn diagram for four sets:
A
A
B
B
C
C
D
D
The Euler diagram (on the left) is not a Venn diagram, as it does not contain all 24 = 16 regions.
For example, the possibility of a nonempty intersection between sets A and D is excluded by this
diagram, so although four sets could stand in the relationship depicted, it does not cover all logical
possibilities. On the other hand, the Venn diagram (on the right) divides the plane into the required
16 regions.
Notice that the Euler diagram exhibits fourfold rotational symmetry, while the Venn diagram
does not. Of course we can easily draw a Venn diagram for three sets exhibits threefold rotational
symmetry, as follows:
Can this be done for four sets? In fact, it cannot: it has been proven that there exists a Venn
diagram for n sets exhibiting n-fold rotational symmetry, if and only if n is prime.

Combinatorics
299
6.4.
The Pigeonhole Principle
Do you know that there are at least two people in Hong Kong with exactly the same number of
hairs on their heads? You would ask how one can know that? To establish this fact empirically
one would have to count the number of hairs on the head of each inhabitant of Hong Kong – a
rather absurd and very costly procedure. Then how? Very simple: a mixture of little bits of
biology, statistics and trivial mathematics suffices:
• It is known that the number of hairs on the head of any human being is less than 200 000
(biology).
• More than 7 000 000 people live in Hong Kong (population statistics).
• If every two of them had different numbers of hairs on their heads then somebody should
have more than 200 000 hairs on his or her head, because the number of non-negative inte-
gers less than 200 000 is, of course, only 200 000 (trivial mathematics).
Isn’t that convincing?
The argument above is a typical example of the application of an extremely simple math-
ematical principle, which almost magically implies lots of interesting and deep results that
otherwise would require enormous, if not impossible, technical efforts to obtain (as in our
example). This principle is often called the Pigeonhole Principle,2 because a popular version
of it reads:
If more than n pigeons ﬂy into n pigeonholes then at least two pigeons will end up in
the same pigeonhole.
Obvious, isn’t it? So obvious that if you have to prove it you would wonder what actually
is there to be proved. Of course you could object that this is not a precise mathematical state-
ment, and therefore no mathematical (i.e. formal) proof is applicable. Here is a more formal
expression of the same idea, which we will hereafter call the Pigeonhole Principle (PHP for
short).
The Pigeonhole Principle (PHP)
Let P (for pigeons) and H (for pigeonholes) be finite sets such that P has more elements than
H. Then there is no injective mapping from P to H, i.e. every mapping from P to H must send
(at least) two elements of P to the same element of H.
The PHP can be proved by mathematical induction. The question, however, is whether
the principle of mathematical induction is something more obvious or more basic than the PHP,
and whether it itself requires proof. In fact, it turns out that the two principles are equivalent,
in a precise mathematical sense.
Here we will apply the PHP in various situations. The art of successful application of
the PHP consists in an appropriate choice of the “pigeons” and “pigeonholes”. Let us start
2 Also known as Dirichlet’s Principle, after the famous German mathematician Peter Gustav Lejeune Dirichlet,
who first obtained serious mathematical results (in number theory) by applying this principle. See the box at the
end of this section for more on this mathematician.

300
Logic and Discrete Mathematics: A Concise Introduction
with a paraphrase, using our principle, of the opening argument of this section. Consider the
inhabitants of Hong Kong as the “pigeons” and 200 000 pigeonholes labelled by the positive
integers from 0 to 199 999. Then we let every “pigeon” fly in the pigeonhole labelled by the
number of hairs on the “pigeon’s” head. Due to the fact that the number of hairs of every
human is less than 200 000 there will be no “pigeon” without a “pigeonhole”. Then, since the
“pigeons” are more than the “pigeonholes”, according to the PHP at least two “pigeons” will
inevitably end up in the same “pigeonhole”, i.e. two people will turn out to have the same
number of hairs on their heads.
Example 6.4.1
There are 370 students in a course. Show that two of them have birthdays on the same day
of the year.
Solution
Let P (pigeons) be the set of students and let H (pigeonholes) be the days of the year. How-
ever, then |P| = 370 > 366 = |H|, so by the PHP any function from P to H (i.e. assigning each
student to his/her birthday) will associate at least two elements of |P| with the same element
of |H|.
Example 6.4.2
Prove that for every positive integer n, amongst any n + 1 integers m1‚ …‚ mn+1 there are two
numbers, the difference between which is a multiple of n.
Solution
Let P = {m1‚ …‚ mn+1} and let H be the n possible remainders modulo n, i.e. H =
{0‚ 1‚ 2‚ …‚ n −1}. The PHP implies that two numbers must have the same remainder
modulo n, and hence n will divide the difference between them.
Example 6.4.3
Each competitor in a piano competition has to choose and perform two of Beethoven’s 32
piano sonatas. What is the least number of entries that need to be received for the judges to
be sure that at least 2 competitors will play the same selection of two sonatas?
Solution
The competitors are the “pigeons”, who we want to classify according to their choice of
Beethoven sonatas. To be able to apply the PHP there needs to be more competitors than
possible choices of sonatas, i.e. |P| > |H| = C(32‚ 2) = 496. Thus there must be at least 497
entries.

Combinatorics
301
Figure 6.2: Five points in an equilateral triangle. By the Pigeonhole Principle, one of the smaller triangles must contain at
least two points
Example 6.4.4
Five points are placed in an equilateral triangle with sides of length 1. Show that the distance
between two of them is not greater than 0.5.
Solution
Partition the triangle, by connecting the midpoints of its sides, into 4 equilateral triangles
with sides of length 0.5, as shown in Figure 6.2. Then, since there are 5 points and only 4
small triangles, the PHP implies that at least 2 of the points must be in the same small triangle.
Moreover, the maximum distance between any two points in any of the small triangles is 0.5.
A generalization of the PHP, which we call the Congested Pigeonhole Principle, is as
follows:
If more than kn pigeons ﬂy into n pigeonholes then some pigeonhole will have to
accommodate more than k pigeons.
For instance, if 16 pigeons fly into 5 pigeonholes, then at least 4 pigeons must share the
same pigeonhole. Once again the principle is intuitively clear – if no more than k pigeons fly
into each of the n pigeonholes then the total number of pigeons in the pigeonholes would be
no more than nk. We can state this formally as follows.
The Congested Pigeonhole Principle (CPHP)
Let P and H be finite sets with respectively m and n elements and k a positive integer such that
m > kn. Then any mapping from P to H must associate at least k + 1 elements of P with some
element of H.
Note that the PHP is a special case of the CPHP, for k = 1.
Example 6.4.5
Show that in a class of 61 students there are 6 with birthdays in the same month.
Solution
Let P be the set of students and H the set of months. Then, since |P| = 61 > 5 × 12 = 5 × |H|,
the claim follows by the CPHP.

302
Logic and Discrete Mathematics: A Concise Introduction
Example 6.4.6
A thousand men are asked to choose and order their 3 favourite beers from a list of n beers.
What is the largest value of n for which we can be sure that at least 5 men will choose the
same 3 beers in the same order?
Solution
Let P be the set of men and let H be the set of possible ordered selections of 3 beers. In order to
be sure that at least 5 men will make the same ordered selection, we need 1 000 > 4 × P(n‚ 3),
i.e. 250 > P(n‚ 3). The greatest value of n for which this inequality will hold is 7. So there can
be at most 7 beers on the list.
Example 6.4.7
145 points are placed in a rectangle of size 6 cm × 16 cm. Show that there are 7 of these points
all within a distance of less than 3 cm from each other.
Solution
Partition the rectangle into 3 × 8 = 24 squares with sides of length 2 cm. One of these squares
must contain at least 7 of these points, because 145 > 24 × 6. The distance between any two
points in the same square is at most 2
√
2 cm < 3 cm.
6.4.1.
Exercises
➊
How many socks must be chosen from 19 different pairs of socks to ensure that at least
one pair is selected?
➋
How many positive integers not greater than 100 must be selected at random to be sure
that at least one of them is divisible by 7?
➌
Prove that in any group of people there are two who have the same number of friends in
the group.
➍
How many numbers from {1‚ 2‚ …‚ 99} must be chosen to ensure that the sum of two of
them is 100?
➎
Given that more than 4 million people live in (greater) Johannesburg, are there at least 21
people in the city with exactly the same number of hairs on their heads? We may assume
that no person can have more that 200 000 hairs on his or her head.
➏
How many people from a group of people of 7 nationalities must be selected to ensure
that at least 4 of those selected are compatriots?
➐
In a school there are 393 students in 17 classes. Show that either there is a class with at
least 25 students or there are at least two classes with at least 24 students each.
➑
How many words in the (26-letter) Latin alphabet must be chosen, to ensure that at least
3 of them begin with the same letter and end with the same letter?

Combinatorics
303
➒
606 points are placed in a square with a side 1. Show that at least 6 of them can be covered
by a circle of radius 1/15. (Hint: consider partitioning the square into smaller squares that
can be inscribed in a circle of radius 1/15.)
➓
There are 13 blue, 10 red, 8 green and 6 yellow balls in a box. How many of them must be
selected at random so that amongst them there will be:
(a) at least 5 of the same colour;
(b) at least 3 green;
(c) at least one of each colour?
11
In a group of 6 people every two of them either like or hate each other. Show that in that
group there are either three who like one another or three who hate one another.
12∗
Every two of 17 points are connected by a line segment coloured either in red, blue or
green. Prove that there is a triangle with vertices among these points and all sides of the
same colour.
13∗
50 points are placed in a circle of diameter 12. Show that there are two points at a distance
not greater than 2 apart.
14∗
Let P be an infinite set and H be a finite set. Then show that any mapping from P to H
must associate infinitely many elements of P with some element of H.
15∗
Show that amongst any mn + 1 integers there are either n + 1 equal or m + 1 pairwise dif-
ferent.
16∗
Prove that for every positive integer n, any set of n integers {m1‚ …‚ mn} contains a
nonempty subset, the sum of whose elements is a multiple of n.
17 ∗
Prove that if m and n are relatively prime positive integers then there is a positive integer
k such that n divides mk −1.
18** Is there a power of 7 that, when written in decimal notation, ends with 00000001?
19** Show that there is a number of the form 20142014…20140…0 that is divisible by 2013.
20** Prove that amongst n + 1 different integers m1‚ …‚ mn+1, where 1 ≤m1 < m2 < · · · <
mn+1 ≤2n, there are three of which one is equal to the sum of the other two.
21** Let M be an arbitrary set of 10 positive integers not greater than 100. Show that there are
two disjoint (i.e. having no common elements) subsets of M that have the same sum of
their elements.3
22** Let A be a set of 101 positive integers, each of which is not greater than 200. Prove that
there are two numbers in A, one of which is a divisor of the other.
23** Show that in every set of 201 positive integers, each less than 301, there are two numbers,
the ratio of which is a power of 3.
24** Let M be a set of 75 positive integers not greater than 100. Show that for each positive
integer k ≤49 there are two elements of M that differ by k.
25** Let k ≥1 and n ≥1 be positive integers and A be a set of (k −1)n + 1 integers each of which
is not greater than kn. Prove that some element of A can be represented as a sum of k (not
necessarily different) elements of A.
3 This problem is from the XIV International Mathematical Olympiad in Poland, 1972.

304
Logic and Discrete Mathematics: A Concise Introduction
Johann Peter Gustav Lejeune Dirichlet (1805–1859)
Dirichlet was a German mathematician, today remembered for a range of
outstanding contributions. He was the first to apply techniques from analysis
to number theory, thereby founding the field known as analytic number theory.
In the course of his work on number theory he introduced what we know
today as the Pigeonhole Principle, often called Dirichlet’s Principle, under the
name of Drawer Principle (Schubfachprinzip in German). He proved, in his first
published paper, some special cases of Fermant’s last theorem (see the box at
the end of Section 5.9 in Chapter 5), namely that for n = 5 and n = 14 the equation xn + yn = zn has
no nonzero integer solutions. The cases for n = 3 and n = 4 had already been proved by Euler and
Fermat. In analysis Diriclet is mostly remembered for his pioneering work on Fourier analysis. He
is credited as being one of the first mathematicians to introduce the modern definition of a function.
Dirichlet was born in the town of Düren in 1805, where his father was postmaster. From an
early age he had a passion for mathematics and history and was an exemplary, if rather shy, student.
After some initial schooling in Bonn his parents sent him to the Jesuit College in Cologne. Here he
was taught by Georg Ohm, best remembered today for Ohm’s law regarding resistance in electrical
circuits. For his university education Dirichlet went to Paris where he came in contact with some
of the leading mathematicians of the day, including Fourier, Laplace, Legendre and Poisson. After
returning to Germany in 1825 he taught for a while at the university of Breslau, after which he
moved to Berlin where he taught at the university and the military college until 1855. In 1855 he
accepted the Chair of Mathematics at the University of Göttingen left vacant by the death of Gauss.
Dirichlet died in Göttingen in 1859, after having suffered a heart attack the year before. His brain is
preserved, along with that of Gauss, in the department of physiology at the University of Göttingen.
6.5.
Generalized permutations, distributions and the multinomial
theorem
The permutation formula P(n‚ r), given in Section 6.1 after Example 6.1.5, allows us to count
the number of ways to select and arrange different or distinguishable objects. If, however,
some of these objects are indistinguishable from each other, e.g. identical copies of the same
book, the formula is no longer applicable. In this section we will generalize the notion of a
permutation to cover the cases where indistinguishable objects are to be arranged and will
develop appropriate counting techniques for these generalized permutations. We will also
show how to use the reasoning behind these techniques in an apparently different situation,
namely when we want to count the number of ways to distribute different objects to different
recipients, with specified numbers of objects going to each recipient. Using these techniques
we will then generalize the binomial theorem.
6.5.1.
Arranging nondistinct objects
Consider the problem: determine the number of different arrangements of the letters in
the word address. Had we been asked to do this for the word adres (the Dutch or Afrikaans

Combinatorics
305
equivalent of address) the answer would have been immediate: 5!. However, the presence of
2 d’s and 2 s’s causes a problem. One possible approach to solve it is to proceeds as follows.
Think that we need to fill 7 places with the letters from address. We first select 2 places for
the d’s:
d
d
There are
(
7
2
)
ways to do that. Then pick 2 places for the s’s from the remaining 5 places in
(
5
2
)
ways. Then we can place the a in
(
3
1
)
ways, then the r in
(
2
1
)
ways and finally we place
the e in
(
1
1
)
way. Hence, there are
(7
2
) (5
2
) (3
1
) (2
1
) (1
1
)
= 21 × 10 × 3 × 2 × 1 = 1260
ways to perform the whole procedure. As expected this is significantly less than the number
of ways to arrange 7 distinct letters, which is of course 7! = 5040.
We can now generalize the argument above to obtain the following theorem.
Theorem 6.5.1 Given a collection of n objects, consisting of ri indistinguishable objects of type i,
for each 1 ≤i ≤m, such that r1 + r2 + · · · + rm = n, the number of different arrangements of these n
objects is
P(n; r1‚ r2‚ …‚ rm) =
(n
r1
) (n −r1
r2
) (n −r1 −r2
r3
)
…
(n −r1 −r2 −· · · −rm−1
rm
)
.
The above formula is equivalent to
P(n; r1‚ r2‚ …‚ rm) =
n!
r1!r2!r3! · · · rm!.
Proof: There are n places to be filled. First we select r1 places for the objects of type 1, which
can be done in C(n‚ r1) ways. Now (n −r1) places remain open. Out of these we select r2 for the
objects of type 2, which can be done in C(n −r1‚ r2) ways, etc. Similarly, there are C(n −r1 −
· · · −ri−1‚ ri) ways to select places for the objects of type i, for each 1 ≤i ≤m. Then we apply
the multiplication principle and conclude that there are
(n
r1
)
×
(n −r1
r2
)
×
(n −r1 −r2
r3
)
× · · · ×
(n −r1 −r2 −· · · −rm−1
rm
)
ways to perform the entire procedure.
To obtain the second formula in Theorem 6.5.1 we expand the binomial coefficients, bear-
ing in mind that n −r1 −r2 −· · · −rm = 0, and cancelling factors to simplify as follows:

306
Logic and Discrete Mathematics: A Concise Introduction
(n
r1
)
×
(n −r1
r2
)
×
(n −r1 −r2
r3
)
× · · · ×
(n −r1 −r2 −· · · −rm−1
rm
)
=
n!
r1!(n −r1)! ×
(n −r1)!
r2!(n −r1 −r2)! ×
(n −r1 −r2)!
r3!(n −r1 −r2 −r3)! × · · ·
· · · ×
(n −r1 −r2 −· · · −rm−1)!
rm!(n −r1 −r2 −r3 −· · · −rm)!
=
n!
r1!r2!r3! · · · rm!.
Example 6.5.2
How many ways are there to roll a die 7 times to obtain a sequence of outcomes that contains
3 ones, 2 fours and 2 sixes?
Solution
P(7; 3‚ 2‚ 2) =
7!
3!2!2! = 210 ways.
Example 6.5.3
How many ways are there to arrange the letters in the word BANANA so that the two N’s
are not consecutive?
Solution
It is easier to count the complement of what we want, namely the arrangements in which the
N’s are consecutive. We simply “glue” the two N’s together, i.e. we consider NN as one object
and arrange the objects B, A, A, A, NN. There are P(5; 1‚ 3‚ 1) ways to do this. Subtracting this
from the total number of arrangements of the letters in BANANA we find that there are
P(6; 1‚ 3‚ 2) −P(5; 1‚ 3‚ 1) =
6!
1!3!2! −
5!
1!3!1! = 60 −20 = 40
ways to arrange the letters in BANANA so that the two N’s are not consecutive.
6.5.2.
Distributions
Suppose n distinct objects are to be distributed into m distinct boxes. How many ways are there
to do this? We can simply line up the n objects and then decide for each one into which box
it is to go. For each object there are m choices, so there are altogether mn ways of completing
this process.

Combinatorics
307
Now let us add the restriction that ri objects must go into box i, for each 1 ≤i ≤m, where
r1 + r2 + · · · + rm = n. Then we begin by selecting r1 objects for box 1 (in
(
n
r1
)
ways), then select-
ing r2 objects for box 2 (in
(
n−r1
r2
)
ways) and so on. Eventually, we find that there are
(n
r1
) (n −r1
r2
) (n −r1 −r2
r3
)
· · ·
(n −r1 −r2 −· · · −rm−1
rm
)
ways in which to complete this procedure. Notice the similarity with our reasoning in the pre-
vious subsection when we were calculating generalized permutations. Then we were selecting
prescribed numbers of distinguishable positions in which to place objects of the same type,
whereas now we are selecting prescribed numbers of distinct objects to be put in a given box.
Thus, we have proved the following result.
Theorem 6.5.4 The number of ways to distribute n distinct objects into m distinct boxes if ri objects
are to go into box i, for 1 ≤i ≤m, where r1 + r2 + · · · + rm = n, is equal to
C(k; r1‚ r2‚ r3‚ …‚ rm)
=
(n
r1
) (n −r1
r2
) (n −r1 −r2
r3
)
· · ·
(n −r1 −r2 −· · · −rm−1
rm
)
=
n!
r1!r2!r3! · · · rm!.
Note that it is a consequence of Theorem 6.5.4 is that C(k; r1‚ r2‚ r3‚ …‚ rm) = P(k; r1‚ r2‚
r3‚ …‚ rm). We will use both these notations because the situations in which we apply them
(namely distributions and arrangements of nondistinct objects, respectively) are conceptually
different, even though the solutions are calculated using the same formula.
Example 6.5.5
In how many ways can a city council of 30 be divided into 5 committees, with each member
serving on exactly one committee?
In addition, how many ways if each committee must consist of exactly 6 members?
Solution
As stated first, the problem poses no restrictions on the size of the committees, i.e. a com-
mittee may also be empty. Hence, there are 530 ways to distribute the members between the
committees.
With the restriction that each committee must consists of exactly 6 members, according
to Theorem 6.5.4 there are P(30; 6‚ 6‚ 6‚ 6‚ 6) = 30!∕(6!)5 ways to distribute the members into
the 5 committees.

308
Logic and Discrete Mathematics: A Concise Introduction
Example 6.5.6
In how many ways can 7 different books be distributed to 5 people if
1. no restrictions apply?
2. each person must receive at least one book?
Solution
1. For each of the 7 books there are 5 choices as to who gets it. Thus there are 57 ways to
distribute the books.
2. The easiest way to count the distributions in which each person receives at least one book is
to break it down into cases as follows: we can either have one person receiving three books
and the others receiving one each, or we could have two people receiving two books each
and the others receiving one each. Since these cases are disjoint and exhaustive we may
apply the addition principle. In the first case we must first pick the person who will receive
the three books and in the second case we must first pick the two people who will receive
two books each. Thus, the number of ways to do the distribution is equal to
(5
1
)
× C(7; 3‚ 1‚ 1‚ 1‚ 1) +
(5
2
)
× C(7; 2‚ 2‚ 1‚ 1‚ 1)
= 5 ×
7!
3!(1!)4 + 10 ×
7!
(2!)2(1!)3 = 16 800.
(An alternative “solution” one might be tempted to try is the following: give each person
one book to ensure that the condition is met, and then distribute the remaining 2 books
arbitrarily. This gives
((
7
1
)
×
(
6
1
)
× · · · ×
(
3
1
))
× 52 = 7!
2! × 52 = 63 000, which is much
larger that the answer obtained above. This is because we are counting distributions more
than once.)
6.5.3.
The multinomial theorem
The binomial theorem tells us how to expand expressions of the form (x1 + x2)n. We now want
to generalize it to powers of sums of more than two terms, e.g. (x1 + x2 + x3)n. The technique
we developed in the previous subsection for counting distributions now comes to our aid. Let
us begin by considering the particular case of (x1 + x2 + x3)4. Naively multiplying this out we
will get:
(x1 + x2 + x3)4
= (x1 + x2 + x3) × (x1 + x2 + x3) × (x1 + x2 + x3) × (x1 + x2 + x3)
= x1x1x1x1 + x1x1x1x2 + x1x1x1x3 + x1x1x2x1 + x1x1x2x2 + x1x1x2x3 + · · ·
Each term in the last line comes about as the product of exactly one term from each pair
of brackets. Therefore, there are 34 = 81 such four-factor terms. The next step is to collect like

Combinatorics
309
terms together. To do that effectively we need to decide how many four-factor terms equal
any given four-factor term that occurs in this sum. For example, the terms equal to x1x1x2x3
will be exactly those containing two x1’s, one x2 and one x3. The number of ways in which we
can create such a term is equal to the number of ways of selecting the x1 from two of the four
pairs of brackets, then selecting the x2 from one of the two remaining pairs of brackets and
then taking the x3 from the only remaining pair of brackets. This gives
(4
2
)
×
(2
1
)
×
(1
1
)
= C(4; 2‚ 1‚ 1).
Thus, the coefficient of x2
1x1x3 in the expansion of
(
x1 + x2 + x3)
)4 is equal to C(4; 2‚ 1‚ 1). By
similar reasoning the coefficient of xn1
1 xn2
2 xn3
3 in the expansion is given by C(4; n1‚ n2‚ n3) for any
n1‚ n2‚ n3 ∈ℕwith n1 + n2 + n3 = 4.
Thus, we see the number of distributions C(n; r1‚ rn‚ …‚ rn), also equal to the number of gen-
eralized permutations P(n; r1‚ rn‚ …‚ rn), surfaces once again now. By analogy with the coeffi-
cients in the binomial theorem, for the coefficients in its generalization, called the multinomial
theorem, we use the notation
(
n
r1‚ rn‚ …‚ rn
)
=
n!
r1!rn! · · · rn!‚
known as a multinomial coefficient. We will henceforth use this notation interchangeably
with C(n; r1‚ rn‚ …‚ rn) and P(n; r1‚ rn‚ …‚ rn).
We are now ready to state and prove the multinomial theorem in its full generality.
Theorem 6.5.7 Let n and m be positive integers. Then
(x1 + x2 + · · · + xm)n =
∑
r1+r2+···rm=n
(
n
r1‚ r2‚ …‚ rm
)
xr1
1 xr2
2 · · · xrm
m
=
∑
r1+r2+···rm=n
n!
r1!r2! · · · rm!xr1
1 xr2
2 . · · · xnm
m .
Here the notation ∑
r1+r2+···rm=n means that the sum is taken over all non-negative integers r1‚ r2‚ …‚ rm
such that r1 + r2 + · · · + rm = n.
Proof: We give an informal proof that generalizes our argument above for computing the coef-
ficients of (x1 + x2 + x3)4. A more rigourous proof, using induction on m and applying the
binomial theorem, is requested in Exercise 10.
(x1 + x2 + · · · + xm)n
= (x1 + x2 + · · · + xm) × (x1 + x2 + · · · + xm) × · · · × (x1 + x2 + · · · + xm)
⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏟
n times
When multiplying out, each term that arises comes about as the product of exactly one
term from each of the n pairs of brackets. Therefore, there are mn such n-factor terms. After
collecting like terms together, each term will be of the form xr1
1 xr2
2 · · · xrm
m for some non-negative
integers r1‚ r2‚ …‚ rm such that r1 + r2 + · · · + rm = n. Hence, the coefficient of the term contain-
ing xr1
1 xr2
2 · · · xrm
m is equal to the number of ways of selecting the x1 from r1 of the n pairs of

310
Logic and Discrete Mathematics: A Concise Introduction
brackets, then selecting the x2 from r2 of the n −r1 remaining pairs of brackets, and so on, until
we end by selecting the xm from the remaining n −(r1 + r2 + · · · + rm−1) = rm pairs of brackets.
This gives
(n
r1
)
×
(n −r1
r2
)
×
(n −r1 −r2
r3
)
× · · · ×
(n −r1 −r2 −· · · −rm−1
rm
)
=
n!
r1!r2! · · · rm! =
(
n
r1‚ r2‚ …‚ rm
)
.
Example 6.5.8
Let us find the coefficient of x2yz3 in the expansion of (x + y + z)6. According to Theorem
6.5.7, the term in which x2yz3 appears is equal to C(6; 2‚ 1‚ 3)x2yz3 = 60x2yz3.
Now let us find the coefficient of x2yz3 in the expansion of (3x + 4y −7z)6. The term
in which x2yz3 appears is equal to C(6; 2‚ 1‚ 3)(3x)2(4y)(−7z)3 = 60 ⋅9 ⋅4 ⋅(−343)x2yz3 =
−740 880x2yz3.
6.5.4.
Summary
We have seen that the multinomial coefficients provide solution to at least three different
counting problems, namely permutations involving indistinguishable objects, distributions
of distinct objects to distinct recipients in prescribed numbers and in computing expansions
of expressions of the form (x1 + x2 + · · · + xm)n. This is summarized in Table 6.2.
Table 6.2 Summary
Counting problem
Solution
Number of arrangements of n objects,
consisting of ri identical objects of type i, for
each 1 ≤i ≤m, where ∑m
i=1 ri = n
P(n; r1‚ r2‚ r3‚ …‚ rm)
Number of distributions of n distinct objects to
m distinct recipients
mn
Number of distributions of n distinct objects to
m distinct recipients, with ri going to recipient
i, for each 1 ≤i ≤m, where ∑m
i=1 ri = n
C(n; r1‚ r2‚ r3‚ …‚ rm)
Number of partitions of a set of cardinality n
into m subsets Si, with |Si| = ri, for 1 ≤i ≤n
and ∑m
i=1 ri = n
C(n; r1‚ r2‚ r3‚ …‚ rm)
Coefficient of xr1
1 xr2
2 · · · xrm
m , with ∑m
i=1 ri = n in
the expansion of (x1 + x2 + · · · + xm)n
(
n
r1‚ r2‚ r3‚ …‚ rm
)

Combinatorics
311
6.5.5.
Exercises
➊
How many different arrangements are there of the letters in
(a) COMMITTEE?
(b) MISSISSIPPI?
➋
Suppose a bookshop has 18 books, consisting of 6 identical calculus books, 5 identical alge-
bra books, 3 identical logic books and 4 identical combinatorics books. In how many ways
can the 18 books be arranged on a shelf?
➌
During lunch hour 12 people walk into a bakery and each orders a pie. Of these 12 people,
4 always buy steak and kidney pies, 3 always buy cornish pies, 3 always buy chicken pies
and the other two buy any of the three types of pies.
(a) How many different sequences of pies – orders are possible?
(b) How many different (unordered) collections of pies are possible?
➍
How many ways are there to distribute 20 different books to 5 people if
(a) there are no restrictions?
(b) 3 specific people get 6 books each and the other 2 people get 1 book each?
(c) each person gets 4 books?
➎
An urn contains 5 identical purple balls, 7 identical orange balls and 3 identical magenta
balls. In how many ways can the balls be drawn, one at a time, from the urn?
➏
In how many ways can we divide a collection of 40 different CDs into unordered piles if
(a) we make four piles of ten CDs each?
(b) we make four piles of eight CDs each and two piles of four CDs each?
➐∗Suppose we distribute n distinct objects into n distinct boxes. In how many of all possible
such distributions is
(a) no box empty?
(b) exactly one box empty?
(c) at least one box empty?
(d) two boxes empty?
➑
What is the coefficient of x3y6z3 in the expansion of (x + 2y + 3z)12?
➒
What is the coefficient of x3y6z12 in the expansion of (x + 2y2 + 4z3)10?
➓∗Prove the multinomial theorem for (x1 + x2 + · · · + xm)n, using the binomial theorem. (Hint:
use induction on m. Note that the binomial theorem is just the special case of the multino-
mial theorem when m = 2.)

312
Logic and Discrete Mathematics: A Concise Introduction
Braille
Braille is a tactile writing system that is used by blind or visually impaired people. It is embossed
on the page with configurations of zero to six raised dots making up a Braille character, which is
read by feeling it with the fingertips. It can be traced back to a system of night writing developed by
Charles Barbier for Napoleon, who wanted a system that would enable soldiers to communicate
silently and without the need for light. Barbier’s original system, however, was too cumbersome to
be of practical use. This system was later improved by Louis Braille after whom the current system
is named.
Each Braille “cell” consists of six possible dots, of which zero or more can be embossed,
arranged in two columns of three. Braille is thus a binary, six-bit system. In fact, it was historically
the first writing system with a binary encoding and thus a precursor of the binary system used in
modern computers. Here are the first six alphabet letters, which also double up as the numerals
1 to 6, in Braille. The black circles indicate embossed dots while the blank ones indicated the
positions of dots that have not been embossed:
a / 1
b / 2
c / 3
d / 4
e / 5
f / 6
By the multiplication principle there are 26 = 64 different Braille cells, which is more than
enough to represent the 26 alphabet letters as well as the ten digits and punctuation marks. In
practice, however, Braille is more than just a one-to-one correspondence between alphabet letters
and cells, but rather more like shorthand with various abbreviations and contractions employed in
order to speed up the reading process.
6.6.
Selections and arrangements with repetition; distributions
of identical objects
In this section we continue to generalize counting techniques to situations where objects might
be indistinguishable.
6.6.1.
Selections with repetition
Suppose that you want to order 10 ice creams and that three flavours are available, say vanilla,
strawberry and chocolate. An order could be for 5 vanilla, 2 strawberry and 3 chocolate ice
creams, or perhaps for 4 vanilla, 0 strawberry and 6 chocolate ice creams. How many different
such orders are possible? To answer this question, suppose you write down the order on a
form as follows: first you write down a number of X’s representing the number of vanilla

Combinatorics
313
ice creams, then put a vertical line, followed by a number of X’s representing the number of
strawberry ice creams, followed by a vertical line again, and finally a number of X’s for the
chocolate ice creams. The order forms for the two orders mentioned above would look like
XXXXX | XX | XXX
and
XXXX | | XXXX‚
respectively.
Clearly there is a one-to-one correspondence between such order forms and the different
orders that can be placed. Therefore, all we have to do is count the number of possible order
forms. Think of any such form as a 12 place sequence that consists of two |’s and 10 X’s. Picking
10 of the 12 places for the X’s entirely determines the sequence. Clearly there are C(3 + 10 −
1‚ 10) = C(12‚ 10) = 66 ways to do that.
This type of selection, which involves choosing k objects from n types with no restriction on
the number of objects of a certain type is called a k-combination with repetition from n types.
The word “repetition” indicates that objects of the same type may be selected repeatedly.
The reasoning above is generalized in the next theorem.
Theorem 6.6.1 The number of selections with repetition of k objects (k-combinations) chosen from n
types of objects is equal to C(k + n −1‚ k).
Proof: This number is equal to the number of sequences of length k + n −1 consisting of k X’s
and n −1 |’s (order forms!). The number of such sequences is equal to the number of ways in
which k places can be selected for the X’s from the k + n −1 places in all. This, in turn, is equal
to C(k + n −1‚ k).
Corollary 6.6.2 The number of selections with repetition of k objects chosen from n types of objects,
where at least one object of each type is to be selected, is equal to C(k −1‚ k −n).
Proof: Begin by selecting one object of each type. Because the objects of a given type are indis-
tinguishable, there is only one way to do this. Now we still need to select the remaining k −n
objects out of the n types. By Theorem 6.6.1 there are C((k −n) + n −1‚ k −n) = C(k −1‚ k −n)
ways to do that.
Example 6.6.3
How many ways are there to select 12 pieces of fruit if apples, pears and peaches are avail-
able? How many if at least 1 fruit of each type must be selected? If at least 3 peaches have to
be selected? If at least 1 fruit of each type and at least 4 pears have to be selected?
Solution
1. We are selecting 12 objects with repetition from 3 types. Therefore, by Theorem 6.6.1 there
are C(12 + 3 −1‚ 12) = C(14‚ 12) = 91 ways to do that.

314
Logic and Discrete Mathematics: A Concise Introduction
2. Adding the restriction that at least one fruit of each type needs to be selected, we appeal to
Corollary 6.6.2 to conclude that there are C(12 −1‚ 12 −3) = C(11‚ 9) = 55 ways to do that.
3. Under the restriction that at least 3 peaches are to be selected we reason as follows. First
begin by selecting 3 peaches – there is one way to do this. Now we still have to pick 9
pieces of fruit out of 3 types. This can be done in C(9 + 3 −1‚ 9) = C(11‚ 9) = 55 ways. Note
that this is the same answer that we got it the previous case. Why is this no coincidence?
4. If at least one fruit of each type and at least 4 pears have to be selected, we can start
by selecting 4 pears, 1 apple and 1 peach, which can be done in only 1 way. Selecting
the remaining 12 −4 −1 −1 = 6 pieces of fruit can be done in C(6 + 3 −1‚ 6) = C(8‚ 6) = 28
ways.
6.6.2.
Distributions of identical objects
In Section 6.5.2 we considered the problem of distributing distinct objects to distinct recipients,
either with no restrictions or with predetermined numbers going to specific recipients. Now
we consider what happens when the objects to be distributed are identical. Particularly, we ask
the question “How many ways are there to distribute k identical objects to n different recipients?” If we
once again think of this in terms of “order forms”, representing a distribution with a sequence
of k X’s and n −1 |’s, then it is clear that the answer must be C(k + n −1‚ k). If we added the
requirement that each recipient must receive at least one of the objects, we reason as we did
in the proof of Corollary 6.6.2 to conclude that there are C(k −1‚ k −n) ways to do that.
Let us enshrine this as a theorem.
Theorem 6.6.4 There are C(k + n −1‚ k) ways to distribute k identical objects to n distinct recipients.
If, in addition, each recipient must receive at least one object, then there are C(k −1‚ k −n) ways to
distribute the objects.
Example 6.6.5
How many distinct non-negative integer solutions does the equation x1 + x2 + x3 + x4 = 12
have?
Solution
Think of this problem as follows: we have 12 objects (the 12 units) to distribute to 4 dis-
tinct recipients (the variables x1, x2, x3, and x4). By Theorem 6.6.4 there are C(12 + 4 −1‚ 12) =
P(15‚ 12) = 455 ways in which this can be done. If we were asked for the number of positive
integer solutions to the equation, we would be distributing identical objects to distinct recip-
ients, with each recipient receiving at least 1 object. By the second part of Theorem 6.6.1 there
are C(12 −1‚ 12 −4) = C(11‚ 8) = 165 ways to do this.

Combinatorics
315
In general we have the following theorem.
Theorem 6.6.6 Let n and k be positive integers. Then the number of non-negative integer solutions
of the equation x1 + x2 + · · · + xn = k is given by C(k + n −1‚ k), and the number of positive integer
solutions is given by C(k −1‚ k −n).
Example 6.6.7
How many ways are there to distribute 10 identical bones to 4 dogs if each dog must get at
least 1 bone and Fifi may not receive more than 3 bones?
Solution
By Theorem 6.6.4 the number of ways to distribute 10 identical objects (the bones) to 4 distinct
recipients (the dogs) with each recipient receiving at least 1 is C(10 −1‚ 10 −4) = 84. This
includes distributions in which Fifi receives 4 or more bones, so we need to subtract the
number of such distributions. We count the number of distributions in which each dog gets
at least 1 bone and Fifi receives at least 4 as follows: give 4 bones to Fifi and 1 bone to each of
the other dogs – since the bones are identical there is only one way in which to do this. Now
distribute the remaining 3 bones to the 4 dogs – there are C(3 + 4 −1‚ 3) = C(6‚ 3) = 20 ways
to do this. Thus our final answer is C(10 −1‚ 10 −4) −C(3 + 4 −1‚ 3) = 84 −20 = 64.
6.6.3.
Arrangements with repetition
Several times already we have encountered the problem of determining the number of dif-
ferent sequences of length r that can be formed using n different symbols, e.g. the number of
binary sequences of length 3. Order is clearly important here since, for example, the sequence
010 is different from the sequence 001. However, this is not an ordinary permutation, as rep-
etition of symbols is allowed. We reason as follows: we have three positions to fill and there
are two choices for filling each of the positions. Thus, by the multiplication principle there are
2 × 2 × 2 = 23 sequences.
More formally, an r-permutations with repetition of n distinct objects or an
r-permutation with replacement of n distinct objects is an arrangement of r objects
chosen from n objects where each object may be used repeatedly. The proof of the next
theorem is essentially an easy application of the multiplication principle.
Theorem 6.6.8 The number of r-permutations with repetition of n distinct objects is equal to nr.
Example 6.6.9
How many possible 7-digit telephone numbers are available?
Solution
We are dealing with a 7-permutation of 10 distinct objects – the 10 digits. By Theorem 6.6.8
there are 107 possible telephone numbers.

316
Logic and Discrete Mathematics: A Concise Introduction
6.6.4.
Summary
Table 6.3 Summary
Counting problem
Solution
• The number of ways to select k objects from n types
• The number of ways to distribute k identical
objects to n distinct recipients
• The number of non-negative integer solutions to
x1 + x2 + · · · + xn = k
C(k + n −1‚ k)
• The number of ways to select k objects from n types
with at least one object of each type
• The number of ways to distribute k identical
objects to n distinct recipients with each recipient
receiving at least 1
• The number of positive integer solutions to x1 +
x2 + · · · + xn = k
C(k −1‚ k −n)
The number of r-permutations with repetition of n
distinct objects
nr
6.6.5.
Exercises
➊
If we play with a standard deck of 52 cards, how many 13 card hands are there containing
5 hearts, 3 spades, 4 diamonds and a club?
➋
How many ways are there to distribute 26 identical sweets to 12 children if:
(a) there are no restrictions?
(b) each child must get at least one sweet?
(c) each child must get at least one sweet but no child may get more than three sweets?
➌
How many non-negative integer solutions are there to the equation z1 + z2 + z3 + z4 + z5 =
19?
➍
How many positive integer solutions are there to the equation z1 + z2 + z3 + z4 = 17?
➎
How many non-negative integer solutions are there to the equation x1 + x2 + x3 + x4 = 21?
How many if x1 ≥1, x2 ≥2, x3 ≥3 and x4 ≥4?
➏
How many ways are there to compose a 36 member choir out of sopranos, altos, tenors
and bases? How many, if at least 6 singers of each group are required?
➐
An urn contains 12 identical green balls and 12 identical red balls and 12 identical golden
balls. How many different selections of 10 balls from the urn are there?
➑
An urn contains 6 identical green balls, 6 identical red balls and 6 identical golden balls.
How many ways are there to select 6 balls from the urn? How many selections of 10 balls?
(Hint: count what you don’t want.)

Combinatorics
317
➒
I want to wear one of my 3 ties every day for 6 consecutive days. In how many ways can I
do this without wearing any tie more than 3 times?
➓∗How many 10-symbol sequences are there involving exactly 6 different symbols chosen
from {0‚ 1‚ 2‚ 3‚ 4‚ 5‚ 6‚ 7‚ 8‚ 9‚ A‚ B‚ C‚ D‚ E‚ F}. (The base-16 number system that uses these
symbols is known as hexadecimal and is widely used in computer science.)
11∗How many arrangements are possible with 4 letters chosen from SUSURRUS?
12∗A bucket contains 2n identical maroon balls, 2n identical pink balls and 2n identical lilac
balls. How many ways are there to divide the balls into two buckets, each bucket containing
half, i.e. 3n, of the balls?
13∗Consider the functions from the set {1‚ 2‚ …‚ m} to the set {1‚ 2‚ …‚ n}.
(a) How many are they altogether?
(b) How many of them are one-to-one (injective)?
(c) How many map 1 to 1 and 2 to 2?
(d) How many have at least one fixed point (x is a fixed point of f if f(x) = x)?
(e) How many have exactly one fixed point?
(f) How many have exactly k fixed points, for k >?
(g) How many have no fixed points?
Blaise Pascal (1623–1662)
Blaise Pascal was a French mathematician, physicist, inventor, theolo-
gist and philosopher, recognized as one of the founders of the theory
of probability.
Pascal was born in Clermont-Ferrand in France, where his father,
Étienne Pascal, was a judge. His mother, Antoinette Begon, died when
he was three years old, leaving him and his two sisters to be raised by
their father. Pascal was a sickly child and was educated at home by his
father, who quickly realized that he had an exceptionally gifted son. So
as not to cause strain to his delicate constitution, Pascal senior omitted
mathematics from the curriculum at first. Once Pascal got his first taste
of mathematics at the age of twelve, however, he had found his true passion and spent all his time
on it. He took to Euclidean geometry like a fish to water and discovered and proved many of the
basic theorems for himself. At sixteen he wrote a paper on conic section which he sent to Mersenne
in Paris. Descartes could reportedly not believe that it was written by a sixteen year old.
In 1639 the family relocated to Rouen where Étienne had been appointed as commissioner of
taxes by Cardinal Richleau. In order to help his father with the onerous tax calculations, Pascal
constructed the first mechanical calculator, known as the Pascaline, which could perform addition
and subtraction.
In 1653 he published the Trait du Triangle Arithmtique on what is now known as Pascal’s triangle
(see Section 6.2). In 1654 Pascal was consulted by a friend, the Chevalier de Méré, a professional
gambler, regarding a fair method for dividing the stakes in game of dice that had been interrupted

318
Logic and Discrete Mathematics: A Concise Introduction
before the end. This promoted a correspondence with Fermat (see the box at the end of Section 5.9
in Chapter 5) in the course of which Pascal and Fermat founded the field probability theory.
In 1654 Pascal experienced a religious conversion. From this time until his death in 1162 he did
little mathematics. He had become convinced that it was sinful to spend time on, what seemed to
him, the idle pursuits of science and mathematics, when there were much more urgent religious
matters to attend to. He wrote on theological and philosophical subjects and published the now
famous Lettres Provinciales and Pensées, regarded as masterpieces of French literature.
6.7.
Recurrence relations and their solution
Solutions to instances of a counting problem can often be given very simply in terms of solu-
tions for instances involving fewer objects. For example, suppose we wanted to know how
many ways there are of forming a (ordered) row of 1 cent and 2 cent coins, to give a total of
n cents. Let us denote the solution to this problem by an. In the case that n = 0, there is only
one row of coins that meets the requirements, i.e. the row consisting of no coins whatsoever,
and hence a0 = 1. In the case that n = 1, again there is exactly one row of coins that meets the
requirements, namely the row consisting of exactly one 1 cent coin. So a1 = 1. As for a2, there
are two possible rows of coins that add up to 2 cents, namely the row consisting of two 1 cent
coins and the row consisting of one 2 cent coin. Now, for n ≥2, we can construct a row adding
up to n cents in two ways: either construct a row adding up to n −1 cents and then add a 1 cent
coin at the end or construct a row adding up to n −2 cents and then add a 2 cent coin at the
end. The number of such rows is thus the number of rows adding up to n −1 plus the num-
ber of rows adding up to n −2 or, in symbols, an = an−1 + an−2. What we have done is to give
a recursive formula, or recurrence relation, for an. In this section we will be studying recur-
rence relations and ways of transforming recursive formulas for an into nonrecursive ones – a
process known as solving recurrence relations.
6.7.1.
Recurrence relations. Fibonacci numbers
Recall that a sequence a0‚ a1‚ a2‚ …‚ an‚ … is a function with the set of non-negative or positive
integers as domain, and which assigns to every such number n the respective term an. The
solutions to a counting problem with an input parameter n form a sequence indexed with
the parameter n, but the terms of that sequence may not be given explicitly, but only defined
recurrently, in terms of the previous terms, as in the problem discussed above. This leads to
the following notion.
Definition 6.7.1 A recurrence relation for a sequence a0‚ a1‚ a2‚ … is a formula giving an in terms
of one or more of the terms preceding it (i.e. in terms of a0‚ a1‚ a2‚ …‚ an−1), for any n greater than some
initial integer k. The values of the first few terms of the sequence needed to start computing with the
recurrence relation are called the initial values or initial conditions.
The idea of a recurrence relation is that it enables the computation of terms of the sequence
one after another, starting with the given first few, by repeatedly applying the recurrence rela-
tion. For instance, in the example above, where an = an−1 + an−2, we only need to know the

Combinatorics
319
first two terms of the sequence: a0 = a1 = 1. Thereafter, the recurrence relation yields: a2 =
a1 + a0 = 2, a3 = a2 + a1 = 3, a4 = a3 + a2 = 5, etc. This is actually a very famous recursively
defined sequence, as we will see in the next example.
Example 6.7.2 (The Fibonacci numbers)
The following story comes from the medieval Italian mathematician Leonardo Fibonacci
from Pisa (see the box at the end of this section) in his most popular book Liber Abaci:
A certain man put a pair of rabbits in a place surrounded on all sides by a wall. How
many pairs of rabbits can be produced from that pair in a year if it is supposed that
every month each pair begets a new pair which from the second month on becomes
productive?4
Let us denote that number by Fn, for n ≥0. We find that F0 = 1‚ F1 = 1‚ F2 = 2‚ F3 = 3‚ F4 =
5‚ F5 = 8, etc. Furthermore, note that at the end of the nth month new pairs of rabbits will be
born to those and only those Fn−2 pairs that are at least n −2 months old, and there will be
Fn−1 previously born rabbits. Therefore, we find that
Fn = Fn−1 + Fn−2
for all n ≥2. The necessary initial values are F0 = 1‚ F1 = 1.
This sequence is known as the Fibonacci sequence and the terms of the sequence are known
as Fibonacci numbers.
Example 6.7.3 (The Lucas numbers)
The sequence of Lucas5 numbers has initial values L1 = 2 and L2 = 1 and recurrence relation
Ln = Ln−1 + Ln−2. Note that this is the same recursion relation as for the Fibonacci numbers,
but now it generates a different sequence:
2‚ 1‚ 3‚ 4‚ 7‚ 11‚ ….
6.7.2.
Catalan numbers
Consider the following two problems.
Complete binary trees
A compete binary tree is a tree in which each node has either zero or two children. (For more
details on trees, see Section 7.4.) All the possible complete binary trees with 1, 2, 3 or 4 leaves
are given in Figure 6.3. Denoting the number of complete binary trees with n leaves by b −n,
we see that b1 = 1, b2 = 1, b3 = 2 and b4 = 5. Now suppose we know the values of b1 up to
4 Encyclopdia Britannica Online Academic Edition. Encyclopdia Britannica Inc., 2013.
5 After the French mathematician Francois-Éduard-Anatole Lucas (1842–1891).

320
Logic and Discrete Mathematics: A Concise Introduction
Two leaves:
One leaf:
Three leaves:
Four leaves:
Figure 6.3: Complete binary trees with one, two, three and four leaves
bn, and consider the root of a complete binary tree with n + 1 leaves. If the subtree rooted at
the left child has i leaves, then the subtree rooted at the right child must have n + 1 −i leaves,
1 ≤i ≤n. Now, in this case, the left subtree can be constructed in bi ways and the right in bn+1−i
ways. Therefore bn+1 = b1bn + b2bn−1 + · · · + bibn+1−i + · · · + bnb1.
Inserting brackets into associative products
Consider a product x1x2 · · · xn of n numbers. The multiplication operation is applied (n −1)
times here. Accordingly, we could insert (n −1) pairs of brackets to write x1x2 · · · xn as n −1
consecutive products. For two factors there is only one way to do this: (x1x2). For three fac-
tors, there are two ways: (x1(x2x3)) and ((x1x2)x3). For four factors, five ways: (x1(x2(x3x4))),
(x1((x2x3)x4)), ((x1(x2x3))x4), (((x1x2)x3)x4) and ((x1x2)(x3x4)). Let pn denote the number of ways
to insert brackets into a product with n factors. We thus have p2 = 1, p3 = 2 and p4 = 5. For
convenience we include p1 = 1: there is only one way to write the trivial product x1, i.e. by
inserting no brackets. Any product with n + 1 factors can be written as a product of n −i fac-
tors multiplied with one of n + 1 −i factors, 1 ≤i ≤n. Therefore pn+1 = p1pn + p2pn−1 + · · · +
pipn+1−i + · · · + pnp1.
We see that the two quite different problems above have the same solution, i.e. the same
sequence of numbers arises in both cases:
1‚ 1‚ 2‚ 5‚ 14‚ 42‚ 132‚ ….
These numbers are known as the Catalan numbers, after the Belgian mathematician
Eugène Charles Catalan (1814–1894). We will write Cn to denote the nth Catalan number
starting at n = 0. As we have seen, Cn+1 is given recursively in terms of C1‚ …‚ Cn by the
formula
Cn+1 = C1Cn + C2Cn−1 + · · · + CiCn+1−i + · · · + CnC1.
Note that Cn = bn+1 = pn+1. The Catalan numbers also crop up in a variety of other set-
tings. Another example is the number of ways to cut an (n + 2)-sided polygon into triangles by

Combinatorics
321
Figure 6.4: Dividing the square
Figure 6.5: Dividing the pentagon
Two leaves:
Three leaves:
a
a
a
a
a
a
a
a
a
a
a
a
a
a
b
b
b
b
b
b
b
b
b
b
b
b
b
b
c
c
c
c
c
c
c
c
c
c
c
c
Figure 6.6: Complete binary trees with two and three named leaves
connecting its corners with n −1 nonintersecting straight line segments equal to Cn. Figures 6.4
and 6.5 illustrate this for four- and five-sided polygons, respectively.
The disadvantage of the recursive formula for Cn is that we need all values of C1‚ …‚ Cn−1
to compute it. If we need to compute all the Catalan numbers one after the other, this is not
a problem. However, if we only want to find C50, say, it would be much more convenient to
have a nonrecursive formula. To find such a formula consider a variation on the theme of
computing the number of complete binary trees. Suppose we were to give names to the leaves
of our complete binary trees: in that case there would be 2 different complete binary trees with
2 leaves and 12 with 3 leaves, as illustrated in Figure 6.6. How many such trees are there with
n + 1 named leaves? If we have a tree with n leaves named x1‚ x2‚ …‚ xn, we can transform it
into a tree with n + 1 leaves named x1‚ x2‚ …‚ xn+1 as follows: take any vertex (node) in the
tree and replace the subtree rooted there by inserting a new subtree consisting of a root with
xn+1 as the right child and the subtree being replaced rooted at the left child. For example, in
Figure 6.6 the first 3-leaf tree is obtained from the first 2-leaf tree by performing this operation

322
Logic and Discrete Mathematics: A Concise Introduction
at the root, with x3 = c. Of course, this can also be done with xn+1 as the right child. Since the
number of leaves in a complete binary tree is always one more than the number of internal
vertices, a tree with n leaves has n + n −1 = 2n −1 vertices in total. Thus, a given complete
binary tree with n named leaves can be transformed into 2(2n −1) complete binary trees with
n + 1 named leaves. Now, iterating this reasoning, we see that the total number of complete
binary trees with n + 1 named leaves is given by
2(2n −1) ⋅2(2n −3) ⋅2(2n −5) ⋅· · · ⋅2(3) ⋅2(1)
= 2n(2n −1) ⋅(2n −3) ⋅(2n −5) ⋅· · · ⋅3 ⋅1
= 2n
(2n)!
2n(2n −2)(2n −4) · · · 4 ⋅2
= 2n(2n)!
2nn!
= (2n)!
n!
= n!
(2n
n
)
.
This is not yet the value of bn+1 we are after, as bn+1 is equal to the number of complete binary
trees with n + 1 unnamed leaves. However, there are (n + 1)! ways to assign names to the leaves
of an (n + 1)-leaf tree, so we simply need to factor out the number of ways to name leaves by
dividing the equation above by (n + 1)!, thus obtaining
Cn = bn+1 =
(2n)!
(n + 1)!(n!) =
1
n + 1
(2n
n
)
‚
n = 0‚ 1‚ 2‚ ….
6.7.3.
Solving homogeneous linear recurrence relations
The example with the Catalan numbers illustrates an important fact: a function defined recur-
sively may also sometimes be obtained in an explicit “closed form”, i.e. as a function not
referring to previous terms but only involving n, as in the formula for the Catalan numbers
given above. This suggests the following question: Given a recursively defined sequence, determine
a closed form of this sequence. This is known as solving the recurrence relation. We will study the
problem of solving a restricted class of recursive relations here. Being able to choose between
recursive and closed forms is very useful as one of these forms may be more desirable than
the other, depending on the context.
Definition 6.7.4 (Linear recurrence relation) A recurrence relation of the form
an = c1(n)an−1 + c2(n)an−2 + c3(n)an−3 + · · · + cm(n)an−m + f(n)
where c1‚ c2‚ …‚ cm and f are functions of n, is called a linear recurrence relation of order m. In the
case when f(n) = 0 for all n the relation is said to be homogeneous. In the case when the ci’s are all
constant and cm ≠0 the relation is said to have constant coefficients and order m.
In this section we develop methods for solving homogeneous linear recurrence relations
with constant coefficients of order m, i.e. recurrence relations that have the form
an = c1an−1 + c2an−2 + c3an−3 + · · · + cman−m‚ cm ≠0.
Definition 6.7.5 (Characteristic equation) The polynomial equation
xm −c1xm−1 −c2xm−2 −· · · −cm = 0
is called the characteristic equation of the recurrence relation shown above.

Combinatorics
323
The characteristic equation has m (not necessarily distinct) roots, r1‚ r2‚ r3‚ …‚ rm, hence-
forth referred to as characteristic roots of the recurrence relation above. These roots may be
real or complex. Note, however, that since cm ≠0, they are all different from 0.
Theorem 6.7.6 The sequence an = rn is a solution of the recurrence relation above if and only if r is a
root of the characteristic equation in Definition 6.7.5.
Proof: an = rn satisfies the recurrence relation above iff rn = c1rn−1 + c2rn−2 + · · · + cmrn−m (we
simply substituted ri for ai in the recurrence relation) iff rm = c1rm−1 + c2rm−2 + · · · + cm (we
divided both sides by rm−n) iff rm −c1rm−1 −c2rm−2 · · · −cm = 0 iff r is a root of the characteristic
equation.
Let (an) and (bn) be sequences. We define the addition of the sequences component-wise:
(an) + (bn) is (an + bn), i.e. (a1‚ a2‚ a3‚ …) + (b1‚ b2‚ b3‚ …) = (a1 + b1‚ a2 + b2‚ a3 + b3‚ …). We also
define a constant multiple of a sequence (an) to be the sequence k(an) = (ka1‚ ka2‚ ka3‚ …). These
generalize to a linear combination of the sequences (an) and (bn): any sequence of the form
k1(an) + k2(bn).
Theorem 6.7.7 If (an) and (bn) satisfy a homogeneous linear recurrence relation with constant coeffi-
cients, then every linear combination k1(an) + k2(bn) satisfies the same recurrence relation.
Proof: It suffices to prove the claim for (an) + (bn) and for k(an). See Exercise 10.
Note that the set of all linear combinations of sequences is closed under the operations of
sequence addition and constant multiples as defined above, so they form a linear vector space.
Theorem 6.7.7 says that the set of all solutions to a homogeneous linear recurrence relation
with constant coefficients forms a subspace of that space.
Let us now consider again the m roots, r1‚ r2‚ r3‚ …‚ rm, of the characteristic equation in Def-
inition 6.7.5. By Theorem 6.7.6, an = rn
i is a solution of the recurrence relation for each ri. These
solutions are called fundamental solutions of the recurrence relation. By repeated application
of Theorem 6.7.7,
an = k1rn
1 + k2rn
2 + k3rn
3 + · · · + kmrn
m
is a solution of the recurrence relation, for arbitrary constants k1‚ k2‚ k3‚ …‚ km. Using this fact,
together with the initial conditions given for the recurrence relation, we are now ready in
principle to solve that recurrence relation, but just how this is done depends on whether the
characteristic roots are distinct or whether some roots occur repeatedly. We consider these
cases in the following two subsections.
Distinct roots
Theorem 6.7.8 Let the roots r1‚ r2‚ r3‚ …‚ rm of the characteristic equation in Definition 6.7.5 be dis-
tinct. Then an = k1rn
1 + k2rn
2 + k3rn
3 + · · · + kmrn
m is a general solution of the homogeneous linear recur-
rence relation, i.e. every solution of which can be expressed in this form for some choice of constants
k1‚ k2‚ k3‚ …‚ km.

324
Logic and Discrete Mathematics: A Concise Introduction
Proof: It is sufficient to show that for some choice of constants k1‚ k2‚ k3‚ …‚ km the following
system of equations can be satisfied:
k1
+
k2
+
· · ·
+
km
=
b0
k1r1
+
k2r2
+
· · ·
+
kmrm
=
b1
k1r2
1
+
k2r2
2
+
· · ·
+
kmr2
m
=
b2
⋮
⋮
⋮
⋮
k1rm−1
1
+
k2rm−1
2
+
· · ·
+
kmrm−1
m
=
bm−1
where ai = bi, 1 ≤i ≤m, are the initial conditions associated with the recurrence relation. It is
known from linear algebra that the system has a unique solution if and only if the associated
matrix of coefficients has a nonzero determinant. The matrix of coefficients of this system is
known as the Vandermonde matrix and its determinant is nonzero as long as the ri are all
distinct, which is the case by assumption. Therefore, the system has a unique solution.
Furthermore, it follows from well-known facts in linear algebra that the fundamental solu-
tions of a recurrence relation form a basis of the vector space of solutions of that relation. This
completes our description of all these solutions.
Let us now illustrate the use of the method we have developed with a few examples.
Example 6.7.9
Suppose that every year the population of cats in Gotham City doubles and that at the begin-
ning of 2000 there were 30 000 cats. How many cats were there at the beginning of 2005? How
many cats will there be after n years?
Solution
Of course, this is a simple geometric progression, which we know how to solve directly,
but let us do it following our general method. Regard 2000 as the 0th year and let an be the
number of cats after n years. Then a0 = 30 000 and an = 2an−1. The characteristic equation for
this recurrence relation of order 1 is x −2 = 0. This has one root, namely r = 2. Hence we
obtain one fundamental solution, an = 2n, and the general solution an = k12n. Using the ini-
tial condition a0 = 30 000 we obtain 30 000 = k120 and conclude that k1 = 30 000. Thus we
have solved the recurrence relation and we find that the number of cats after n years is
an = 30 000(2n).
Therefore, at the beginning of 2005 there must have been a5 = 30 000(25) = 960 000 cats
in Gotham City!

Combinatorics
325
Example 6.7.10
Recall that Fibonacci numbers were given by the recurrence relation Fn = Fn−1 + Fn−2 with the
initial conditions F0 = 1 and F1 = 1. Let us solve this recurrence relation. The characteristic
equation is x2 −x −1 = 0, which has two distinct roots, namely
(
1
2 +
√
5
2
)
and
(
1
2 −
√
5
2
)
.
We obtain the two fundamental solutions
Fn =
(
1
2 +
√
5
2
)n
and Fn =
(
1
2 −
√
5
2
)n
‚
and the general solution
Fn = k1
(
1
2 +
√
5
2
)n
+ k2
(
1
2 −
√
5
2
)n
.
Using the initial conditions we produce and solve the system of equations
k1 + k2 = 1
k1
(
1
2 +
√
5
2
)
+ k2
(
1
2 −
√
5
2
)
= 1
to obtain k1 = 1∕(
√
5) and k2 = −1∕(
√
5). Hence we have
Fn =
1
√
5
(
1
2 +
√
5
2
)n
−1
√
5
(
1
2 −
√
5
2
)n
.
The roots of the characteristic equation of a real recurrent sequence may turn out to be
complex numbers. Recall that any complex number a + bi can be written in the form 𝜌(cos 𝜃+
i sin 𝜃). The following theorem, which we state without proof, is often useful.
Theorem 6.7.11 If the roots of a characteristic equation of a homogeneous linear recurrence relation of
degree 2 are complex numbers a + bi and a −bi (i.e. the roots are complex conjugates) then the general
solution of the recurrence relation is given by
an = 𝜌n(k1 cos n𝜃+ k2 sin n𝜃)‚
where 𝜌=
√
a2 + b2, cos 𝜃= a∕𝜌and sin 𝜃= b∕𝜌.
Proof: Left as Exercise 11.

326
Logic and Discrete Mathematics: A Concise Introduction
Example 6.7.12
Consider the recurrence relation given by an = 2an−1 −4an−2 with a0 = 1 and a1 = 2. This has
the characteristic equation x2 −2x + 4 = 0. Using the quadratic formula we find that the roots
of this are 1 ±
√
3i. Rewriting this in polar form we find 𝜌=
√
1 + 3 = 2 while sin 𝜃=
√
3
2 and
cos 𝜃= 1
2, which gives 𝜃= 𝜋∕3. Hence, applying Theorem 6.7.11 we get the general solution
an = 2n (
k1 cos n𝜋
3 + k2 sin n𝜋
3
)
.
Now we have
a0 = 1 = 20 (
k1 cos
(
0 ⋅𝜋
3
)
+ k2 sin
(
0 ⋅𝜋
3
))
= k1
and
a1 = 2 = 21 (
k1 cos
(
1 ⋅𝜋
3
)
+ k2 sin
(
1 ⋅𝜋
3
))
= 21 (
(1) cos 𝜋
3 + k2 sin 𝜋
3
)
= 2
(
1
2 + k2
√
3
2
)
= 1 + k2
√
3.
Solving we get
k2 =
1
√
3
and hence
an = 2n
(
cos n𝜋
3 + 1
√
3
sin n𝜋
3
)
.
Repeated roots
We now turn our attention to the case in which the characteristic equation in Definition 6.7.5
has repeated roots, i.e. the m roots of the equation are not all distinct. We say that a char-
acteristic root r has multiplicity j if it appears as a root of the characteristic equation xm −
c1xm−1 −c2xm−2 −· · · −cm = 0 exactly j times. This is equivalent to (x −r)j being a divisor of
the polynomial xm −c1xm−1 −c2xm−2 −· · · −cm but with (x −r)j+1 not being a divisor.
The obvious difficulty that the presence of repeated roots poses with the application of
the method developed so far is that we now do not have m different fundamental solutions.
There is a remedy, however. It can be shown (we will omit the proof) that if r is a characteristic
root of multiplicity j, then an = rn‚ an = nrn‚ an = n2rn‚ …‚ an = nj−1rn are linearly independent
solutions, and hence can be taken as j fundamental solutions corresponding to r.

Combinatorics
327
Example 6.7.13
Consider the recurrence relation an = 10an−1 −25an−2 with initial values a0 = 2 and a1 = 5. The
characteristic equation is x2 −10x + 25 = 0. Factoring we obtain (x −5)2 = 0. This has one root
of multiplicity 2, namely 5. Hence, the fundamental solutions are an = 5n and an = n5n and
the general solution is an = k15n + k2n5n. Using the initial conditions we obtain the system of
equations:
k1 = 2‚
5k1 + 5k2 = 5.
Solving we obtain k1 = 2 and k2 = −1 and hence the solution an = 2 ⋅5n −n ⋅5n.
6.7.4.
Exercises
➊
Find a recurrence relation for the number of ways to distribute n distinct objects to 4 distinct
recipients. Also, state the initial conditions.
➋
Find and solve a recurrence relation for the number of ways to count out coins, with order
taken into account, until n cents are counted, if:
(a) 1 and 2 cent coins are used.
(b) 1, 2 and 5 cent coins are used.
➌
Solve the recurrence relation for the Lucas numbers (see Example 6.7.3).
➍
Find and solve a recurrence relation for the number of ways to make an n centimetre long
row of electronic components on a circuit board. Components of types A, B and C are avail-
able. Components of types A and C take up 1 centimetre each, while those of type B take
up 2 centimetres each.
➎
A ternary sequence is a sequence consisting of the 0’s, 1’s and 2’s.
(a) Find and solve a recurrence relation for the number of n digit ternary sequences with
no equal consecutive digits.
(b) Find and solve a recurrence relation for the number of n digit ternary sequences where
1 does not appear directly to the left of any 2.
➏
Find and solve a recurrence relation for the size an of an insect population in year n, which
obeys the law that the year on year change is always 3 times the previous year on year
change, given that a1 = 1000 and a2 = 1200.
➐
Solve the following recurrence relations:
(a) an = −an−1 + 6an−2 for n > 1, with a0 = 1 and a1 = −2.
(b) an = an−2 for n > 1, with a0 = a1 = 1.
(c) an = 3an−1 + 10an−2 for n > 2, with a1 = 0 and a2 = 3.
(d) an = 6an−1 −9an−2 for n > 2, with a1 = 2 and a2 = −2.

328
Logic and Discrete Mathematics: A Concise Introduction
(e) an = 3an−1 −3an−2 + an−3 for n > 2, with a0 = a1 = 1 and a2 = 2.
(f) an = 11an−1 −39an−2 + 45an−3 for n > 2, with a0 = a1 = a2 = 1.
➑
Solve the following recurrence relations (the solutions involve complex numbers):
(a) an =
√
2an−1 −an−2 for n > 1, with a0 = −1, a1 = 1.
(b) an = −4an−2 for n ≥2, with a0 = 3 and a1 = 4.
(c) an =
√
3an−1 −an−2 for n > 1, with a0 = 0, a1 = 3.
(d) an = an−1 −an−2 for n ≥2, with a0 = 1 and a1 = 2.
(e) an = −16an−2 for n ≥2, with a0 = 4 and a1 = 3.
(f) an = −2
√
2an−1 −4an−2 for n ≥2, with a0 = 1 and a1 = 0.
➒∗Prove that
Cn+1 = 2(2n + 1)
n + 2
Cn
together with the initial condition C0 = 1, which recursively defines the Catalan numbers.
➓∗Prove Theorem 6.7.7.
11∗Prove Theorem 6.7.11.
Fibonacci (c. 1170–c. 1250)
Leonardo Pisano, known as Fibonacci, was a medieval Italian mathemati-
cian. When his father was appointed consul over the community of Pisan
merchants in the North African port of Bugia, now the city of Bejaïa in Alge-
ria, Leonardo had the opportunity to study mathematics under an Arab
master. He went on to pursue his mathematical studies in various cities
around the Mediterranean world. In his book Liber Abaci Fibonacci intro-
duced in Europe the position-based Hindu – Arabian decimal numerical sys-
tem, which we are using nowadays, instead of the awkward Roman numeral
system. The book goes on to explore the advantages of this system both for practical everyday calcu-
lations and for pure mathematics. Very importantly, the Hindu – Arabian system contains a numeral
0, to denote the number zero, unlike the Roman system. The book Liber Abaci also famously intro-
duces the sequence 1‚ 1‚ 2‚ 3‚ 5‚ 8‚ … of Fibonacci numbers to the West. Fibonacci’s achievements
drew the attention of the Holy Roman Emperor, Frederick II, and his entourage of scholars. As a
result Fibonacci was invited to appear before the imperial court. Fibonacci’s book Liber Quadratorum,
which he dedicated to Frederick, is devoted to quadratic diophantine equations, and established
him, in the estimation of some, as the most important number theorist in the one and a half millen-
nium long interval between Diophantus and Fermat.

Combinatorics
329
6.8.
Generating functions
Generating functions represent a very versatile, if rather abstract, counting technique. Once
mastered they can be applied in various situations and can simplify the solution of many
counting problems considerably. Part of the convenience and beauty of modelling counting
problems with generating functions is the way in which combinatorial reasoning is replaced,
and almost automated, by algebraic manipulation.
6.8.1.
Introducing generating functions
One often wants to solve a family of similar counting problems, for instance the number of
selections of i objects chosen in a certain way, for a whole range of possible values of i. If we
denote the solution of the problem for case i = n by an, we obtain the sequence A = a0‚ a1‚ a2‚ …
of solutions for that family of problems.
Definition 6.8.1 With each sequence
A = a0‚ a1‚ a2‚ …
we associate the power series
A(x) = a0 + a1x + a2x2 + a3x3 + · · · .
A(x) is called the generating function of the sequence A.
Note that, in the generating function A(x), ai is the coefficient of xi for each i. The expansion
of the generating function is finite, i.e. a polynomial, just in the case that ai = 0 for all i ≥N
for some number N. We regard generating functions as formal algebraic expressions and do
not consider notions typically of importance to calculus like convergence. Indeed, for our pur-
poses, the role of x in A(x) is not that of a variable ranging over some set of numbers, but rather
that of a place holder: we identify an by looking for the coefficient of xn. By arranging the terms
of the sequence A as the coefficients in a power series in this way, a range of algebraic manip-
ulations are made available that, as hinted above, will mechanize some reasoning about the
combinatorial problem associated with A.
By way of motivation consider (x + 1)n. From the binomial theorem we know that
(x + 1)n = 1 +
(
n
1
)
x +
(
n
2
)
x2 + · · · +
(
n
n
)
xn. Therefore, in the expansion of (x + 1)n, the
coefficient of xi is
(
n
i
)
, that is to say, the number of ways to select i objects out of a possible
n. This means that (x + 1)n = 1 +
(
n
1
)
x +
(
n
2
)
x2 + · · · +
(
n
n
)
xn is the generating function for
the sequence A(x) =
((
n
0
)
‚
(
n
1
)
‚ …‚
(
n
n
))
of solutions to the counting problem of selecting i
objects out of a possible n.
We can add and multiply generating functions by extending the corresponding operations
on polynomials as follows: if
A(x) = a0 + a1x + a2x2 + · · · + aixi + · · ·
and
B(x) = b0 + b1x + b2x2 + · · · + bixi + · · ·
we define their sum as
A + B = (a0 + b0) + (a1 + b1)x + (a2 + b2)x2 + · · · + (ai + bi)xi + · · · .

330
Logic and Discrete Mathematics: A Concise Introduction
Likewise, by analogy with multiplication of polynomials, the Cauchy product, A(x) × B(x), of
A(x) and B(x) is the power series in which the coefficient of xi is a0bi + a1bi−1 + a2bi−2 + · · · + aib0.
Example 6.8.2
Suppose A(x) = 1 + 2x + 4x2 + 8x3 + · · · and B(x) = x + x3 + x5 + x7 + · · ·. Clearly, the coeffi-
cient ai of xi in A(x) is equal to 2i and the coefficient bi of xi in B(x) is equal to 1 if i is odd and
equal to 0 when i is even. From the definition of the Cauchy product, we can compute the
coefficient of any power of x in A(x) × B(x). For instance, the coefficient of x5 in A(x) × B(x) is
a0b5 + a1b4 + a2b3 + a3b2 + a4b1 + a5b0
= 1 ⋅1 + 2 ⋅0 + 22 ⋅1 + 23 ⋅0 + 24 ⋅1 + 25 ⋅0
= 21.
We now give a version of the multiplication principle, which we will need in order to
combine generating functions when solving counting problems.
The multiplication principle for generating functions
Let us consider a procedure that consists of m different steps. Suppose that the number of ways
in which step j can be performed has generating function Aj(x), 1 ≤j ≤m. If the order of the
outcomes is unimportant, the generating function for the number of composite outcomes is
given by A1(x) × A2(x) × · · · × Am(x).
We illustrate the use of generating functions for solving counting problems with several
examples.
Example 6.8.3
A bowl contains 5 identical yellow, 4 identical green and 7 identical white balls. Balls are to
be selected from the bowl subject to the constraints that the number of selected yellow balls
is odd, the number of selected green balls is even and the number of selected white balls is
at least 5. How many different selections of 10 balls from the bowl are there, subject to these
constraints?
Solution
Note that there is 1 way to select 1 yellow ball, 1 way to select 3 yellow balls, 1 way to select
5 yellow balls and 0 ways to select any other number of yellow balls (only the numbers 1, 3
and 5 are allowed). Hence, the generating function for the numbers of ways to select yellow
balls is A1(x) = x + x3 + x5. Similarly, the generating function for the number of ways to select
green balls is A2(x) = x2 + x4 and the generating function for the number of ways to select
white balls is A3(x) = x5 + x6 + x7. Thus the generating function for the number of composite
outcomes is A(x) = A1(x)A2(x)A3(x) = (x + x3 + x5)(x2 + x4)(x5 + x6 + x7). The number of ways
to select 10 balls will then be the coefficient of x10 in A(x), which, as one can easily verify, is 3.

Combinatorics
331
Example 6.8.4
If 25 identical jelly beans are to be distributed among 5 children, how many ways are there
to distribute the jelly beans with
1. each child receiving at least 3 jelly beans?
2. each child receiving at least 3 jelly beans and no child receiving more than 7 jelly beans?
3. each child receiving an even number of jelly beans?
4. the first child receiving either 4 or 5 jelly beans and the other four each receiving an odd
number of jelly beans?
Solution
For now we will only construct a generating function for solving each of these problems. The
final solutions, which will be given by the coefficient of x25 in each case, will be postponed
until the next subsection, where we discuss methods for calculating coefficients in generating
functions.
1. For each of the five children the generating function for the number of ways to receive
jelly beans is x3 + x4 + x5 + · · ·. Indeed, there are 0 ways to receive 0, 1 or 2 jelly beans,
as this is explicitly forbidden, and, since the jelly beans are identical, there is one way to
receive 3 or any other higher number of jelly beans. Hence, by the multiplication principle
for generating functions, the combined generating function is A(x) = (x3 + x4 + x5 + · · ·)5.
Note that our generating function does not stop at x25. This does not matter and, as we
will see, actually simplifies the calculation of coefficients.
2. In this case the generating function for the number of ways to distribute jelly beans to any
particular child is x3 + x4 + x5 + x6 + x7, and hence the generating function for the compos-
ite counting problem becomes A(x) = (x3 + x4 + x5 + x6 + x7)5.
3. A(x) = (1 + x2 + x4 + · · ·)5. Notice, however, that there are 0 ways in which this can be done:
giving an even number of beans to each child we cannot possibly have an odd sum (namely
25). In the next section we will see that the generating function indeed reflects this fact, i.e.
the coefficient of x25 in A(x) will be 0.
4. A(x) = (x4 + x5)(x + x3 + x5 + · · ·)4.

332
Logic and Discrete Mathematics: A Concise Introduction
Example 6.8.5
How many non-negative integer solutions are there to the equation c1 + c2 + c3 + c4 = 25?
Solution
We have to distribute 25 identical units to the four distinct variables c1, c2, c3 and c4. Since
the units are identical, there is exactly one way to distribute n units to variable ci, for every
n ∈ℕ. Hence, the generating function for the number of ways to distribute n units to vari-
able ci is Ai(x) = 1 + x + x2 + · · ·. By the multiplication principle for generating functions, the
generating function for the number of non-negative integer solutions of c1 + c2 + c3 + c4 = n
is A(x) = (1 + x + x2 + · · ·)4. Specifically, the number of non-negative integer solutions to the
equation c1 + c2 + c3 + c4 = 25 will be the coefficient of x25 in A(x).
Notice that we could also have set Ai(x) = 1 + x + x2 + · · · + x25, since we do not intend
to distribute more that 25 units to any variable. However, Ai(x) = 1 + x + x2 + · · · solves the
more general problem of distributing n units to the variables. Moreover, as we will see below,
using infinite power series rather than polynomials typically simplifies the calculation of the
coefficients.
6.8.2.
Computing coefficients of generating functions
In the preceding examples we mostly restricted ourselves to the construction of a generating
function, but did not complete the solutions by actually calculating the required coefficient
in the expansion of the constructed generating function. Here we develop methods for calcu-
lating these coefficients. The following polynomial expansions are useful for computing the
coefficients of generating functions.
Theorem 6.8.6
1 −xm+1
1 −x
= 1 + x + x2 + · · · + xm
1
1 −x = 1 + x + x2 + · · ·
(1 + x)n = 1 +
(n
1
)
x +
(n
2
)
x2 + · · · +
(n
r
)
xr + · · ·
(n
n
)
xn
(1 + xm)n = 1 +
(n
1
)
xm +
(n
2
)
x2m + · · · +
(n
r
)
xrm + · · ·
(n
n
)
xnm
1
(1 −x)n = 1 +
(1 + n −1
1
)
x +
(2 + n −1
2
)
x2 + · · · +
(r + n −1
r
)
xr + · · ·
Proof: It is easy (and left to the reader) to verify by multiplication that
(1 −x)(1 + x + x2 + · · · + xm) = (1 −xm+1)

Combinatorics
333
and
(1 −x)(1 + x + x2 + · · ·) = 1‚
from which the first and second equations immediately follow. The next equation follows from
the binomial theorem, as does the following (second last) one.
It remains to show that the last equation holds. By the second equation we have
1
(1 −x)n =
(
1
1 −x
)n
= (1 + x + x2 + · · ·)n.
We have to determine the coefficient of xr in (1 + x + x2 + · · ·)n. This is the same as the
number of formal products
xe1xe2xe3 · · · xen
whose exponents add up to r. This is turn is the same as the number of non-negative integer
solutions of
e1 + e2 + e3 + · · · + en = r‚
which is equal to C(r + n −1‚ r). This proves the last equation.
Example 6.8.7
We are now able to return to Example 6.8.4 and calculate the coefficient of x25 in the following
generating functions:
1. A(x) = (x3 + x4 + x5 + · · ·)5
2. A(x) = (x3 + x4 + x5 + x6 + x7)5
3. A(x) = (1 + x2 + x4 + · · ·)5
4. A(x) = (x4 + x5)(x + x3 + x5 + · · ·)4
Solution
1. (x3 + x4 + x5 + · · ·)5
= x15(1 + x + x2 + · · ·)5
= x15
1
(1 −x)5
= x15
(
1 +
(1 + 5 −1
1
)
x + · · · +
(r + 5 −1
r
)
xr + · · ·
)
Here the second inequality is justified by the second equation in Theorem 6.8.6 and
the third by the last equation. If we multiply out in the last expression, the term
containing x25 will be obtained by multiplying x15 with the term containing x10 in
(
1 +
(1 + 5 −1
1
)
x + · · · +
(r + 5 −1
r
)
xr + · · ·
)
. Its coefficient is 1 × C(10 + 5 −1‚ 10) =
C(14‚ 10) = 1001.

334
Logic and Discrete Mathematics: A Concise Introduction
2. (x3 + x4 + · · · + x7)5
= x15(1 + x + x2 + · · · + x4)5
= x15
(
1 −x5
1 −x
)5
= x15(1 −x5)5
1
(1 −x)5
= x15(1 −5x5 + 10x10 −10x15 + 5x20 −x25)(1 + · · · + C(r + 5 −1‚ r)xr + · · ·)
Here the second equality follows from the first equation in Theorem 6.8.6 while
the last follows from the last two equations. When multiplying out the last expres-
sion, and before collecting like terms, each term will consist of x15, multiplied
by one term from (1 −5x5 + 10x10 −10x15 + 5x20 −x25), multiplied by a term from
(1 + · · · + C(r + 5 −1‚ r)xr + · · ·). Terms like these in which the exponents of the x’s
add up to 15 will be exactly x15 ⋅1 ⋅C(10 + 5 −1‚ 10)x10, x15 ⋅(−5x5) ⋅C(5 + 5 −1‚ 5)x5
and x15 ⋅(10x10) ⋅C(0 + 5 −1‚ 0)x0. Thus, finally, the coefficient of x25 is equal to
C(10 + 5 −1‚ 10) + (−5)C(5 + 5 −1‚ 5) + 10C(0 + 5 −1‚ 0) = 1 001 −5 ⋅126 + 10 ⋅1 = 381.
3. (1 + x2 + x4 + · · ·)5
=
(
1
1 −x2
)5
=
1
(1 −x2)5
= 1 +
(1 + 5 −1
1
)
(x2)1 +
(2 + 5 −1
2
)
(x2)2 + · · · +
(r + 5 −1
r
)
x2r + · · ·
The first equality is justified by the first equation in Theorem 6.8.6 and the last equality by
the last equation in Theorem 6.8.6. Notice that, as predicted in Example 6.8.4, the coefficient
of x25 is 0.
4. (x4 + x5)(x + x3 + x5 + · · ·)4
= (x4 + x5)x4(1 + x2 + x4 + · · ·)4
= (x8 + x9)
1
(1 −x2)4
= (x8 + x9)
(
1 +
(1 + 4 −1
1
)
x2 + · · · +
(r + 4 −1
r
)
x2r + · · ·
)
The third equality is justified by the second equation in Theorem 6.8.6 and the last
equality by the last equation of Theorem 6.8.6. When multiplying out the last expres-
sion, a term containing x25 arises only when x9 from the first pair of brackets is
multiplied with C(8 + 4 −1‚ 8)x2⋅4 from the second. Hence the coefficient of x25 is
C(8 + 4 −1‚ 8) = 165.

Combinatorics
335
6.8.3.
Exercises
➊
Find the coefficient of x9 in (1 + x + x2 + · · ·)5.
➋
Find the coefficient of x7 in (1 + x)m(1 + x2 + x4 + x6).
➌
Find the coefficient of x12 in (1 + x2)m.
➍
Find the coefficient of xk in (x3 + x4 + x5 + · · ·)6, k ≥18.
➎
Find the coefficient of xk in (x + x3 + x5)(1 + x)n, k ≥5.
➏
Find the coefficient of xk in
(1 + x + x2 + x3 + · · ·)4 ⋅1 −x7
1 −x .
➐
Find a generating function for the number of different selections of r pencils from a pencil
case containing 3 blue, 3 black, 3 red and 3 green pencils. How many different selections
of 5 pencils are there?
➑
Use generating functions to find the number of ways to select r objects from a collection
consisting of
(a) 3 cricket balls, 4 rugby balls and 4 tennis balls. How many ways are there to select 5
balls?
(b) 3 wine glasses, 5 beer glasses and eight liqueur glasses, if at least one of each type of
glass must be selected. How many ways are there to select 4 glasses?
(c) seven types of transistors (in unlimited supply), if an odd number of the first type and
an odd number of the seventh type has to be selected. How many ways are there to
select ten transistors?
➒
Use generating functions to determine the number ar of ways to distribute r identical balls
into:
(a) 10 different boxes with at least one ball in each box.
(b) 5 different boxes with at most 4 balls in each box.
(c) 4 different boxes with between 2 and 7 balls in each box.
(d) 4 different boxes with fewer than 6 balls in each box.
➓∗A board of directors consists of 30 members. Of them 4 members are nominated for the
position of chairperson. Each member must cast one anonymous vote.
(a) Use a generating function to determine the number of possible election outcomes.
(b) If each nominated member votes for himself/herself, use a generating function to
determine the number of possible outcomes.
(c) Use a generating function to determine the number of possible election outcomes if
members are allowed to abstain from voting.
11
Use a generating function to determine the number of ways to buy n pieces of fruit if avo-
cados, bananas and papayas are available, with avocados sold in packs of 2, bananas in
bunches of 6 and papayas are sold loose.
12∗Use a generating function to determine the number of integers, the digits sum of which is
n, if we consider only
(a) integers between 0 and 99 999.

336
Logic and Discrete Mathematics: A Concise Introduction
(b) 5-digit positive integers.
13
Use a generating function to find the number of non-negative integer solutions to the fol-
lowing equations:
(a) z1 + z2 + z3 = n.
(b) z1 + z2 + 2z3 = n.
14
Find a generating function for the number of non-negative integer solutions to the equation
x1 + 2x2 + 3x3 = n.
Combinatorial games: Nim
Combinatorial games are two-player games in which players make alternate moves. Unlike poker,
for example, where a player does not know the hands of others and cards are dealt randomly, play-
ers have complete information in a combinatorial game and there is no chance. In a normal play
of such a game the last player to be able to make a legal move is the winner, while in a so-called
misère play of the game the player forced to make the last move loses. Chess, checkers and Go
are well-known examples of combinatorial games. In the theory of combinatorial games a game
is called “solved” if it can be proved that, in any given play of the game, one of the players has a
winning strategy.
The game of Nim is a simple combinatorial game. It consists of a finite number of finite piles of
identical objects. A move consists of removing any number of objects from any one pile. The player
who makes the last move wins. The simplest version of Nim is played with two heaps of objects. In
this case, if the piles have unequal size, the first player to move has a winning strategy: in her first
move she removes the number of objects from the bigger heap required to make the heaps equal.
Thereafter she simply keeps on equalizing the heaps after every move by her opponent by copying
his last move on the other heap. This will ensure that the game always comes to a point where there
is only one nonempty heap left, whereupon she simply removes all the remaining objects in that
pile and wins. On the other hand, if the game starts with two heaps of equal size, the second player
has a similar winning strategy. In other words, the game is solved for two heaps.
Nim has been solved for any number of heaps, but with three or more heaps the strategy is
a bit more complicated. Consider a Nim game with three heaps, consisting of two, three and four
objects:
The Nim sum of a game is equal to the numbers of objects in the heaps, expressed in binary,
summed using Nim addition. Nim addition, which we will denote by ⊕, is binary addition without
carrying. Thus the Nim sum of the game above is 10 ⊕11 ⊕100 = 101. The winning strategy is to
make the Nim sum 0 after each of your moves. This is possible iff the Nim sum is not already 0.
Thus if the game starts with a Nim sum unequal to zero, the first player has a winning strategy,
otherwise the second player has one. A player with a winning strategy can calculate her next move
a follows: add the Nim sum of the game to the number of objects in each heap using Nim addition.
Take a heap the size of which decreases under this operation and decrease it to that size. In our
example we get 10 ⊕101 = 111, 11 ⊕101 = 110 and 100 ⊕101 = 1. Only the size of the heap with
four objects decreases, namely to one, so the next move is to take three from that heap.

Combinatorics
337
6.9.
Recurrence relations and generating functions
Now we apply generating functions to solve recurrence relations. The theory of generating
functions was treated in the previous section, so the exposition here will consist mainly of a
number of examples. The method we will illustrate can be used to solve any linear homo-
geneous recurrence relations with constant coefficients, even if the technique in Section 6.7
is quicker, but we will see that the method of recurrence relations can also be used to solve
certain inhomogeneous recurrence relations.
Example 6.9.1
Consider the recurrence relation an = 2an−1 −3 for n > 0, with the initial condition a0 = 4. This
yields a sequence a0‚ a1‚ a2‚ …. Let
f(x) = a0 + a1x + a2x2 + · · ·
be the generating function for this sequence. Notice that we have an −2an−1 + 3 = 0 for all
n > 0. We will now use this to rewrite the generating function f(x) into a form from which we
can easily read off a formula for the coefficient an of xn, thus solving the recurrence relation.
From the above equation we obtain
f(x)
=
a0
+
a1x
+
a2x2
+
· · ·
−2xf(x)
=
−
2a0x
−
2a1x2
−
· · ·
3
1−x
=
3
+
3x
+
3x2
+
· · ·
Adding the left-hand sides and the right-hands sides, we obtain
f(x) −2xf(x) +
3
1 −x = (a0 + 3) + (a1 −2a0 + 3)x + (a2 −2a1 + 3)x2 + · · · .
Using the fact that an −2an−1 + 3 = 0 for all n > 0 and that a0 = 4, we have that
f(x) −2xf(x) +
3
1 −x = 4 + 3 = 7‚
i.e.
f(x)(1 −2x) = 7 −
3
1 −x‚
and so
f(x) =
7
1 −2x −
3
(1 −x)(1 −2x).
Now, using partial fraction decomposition, we obtain
3
(1 −x)(1 −2x) =
A
1 −x +
B
1 −2x‚
so
3 = A(1 −2x) + B(1 −x).

338
Logic and Discrete Mathematics: A Concise Introduction
Setting x = 1 we find A = −3 and setting x = 1∕2 we find B = 6. Thus we obtain
f(x) =
7
1 −2x −
[
6
1 −2x −
3
1 −x
]
=
1
1 −2x +
3
1 −x
= (1 + 2x + 22x2 + · · ·) + 3(1 + x + x2 + · · ·)
= (20 + 3) + (21 + 3)x + (22 + 3)x2 + · · ·
Thus the coefficient of xn in f(x) is 2n + 3. Since f(x) is the generating function of the sequence
(an), this means that an = 2n + 3. Thus we have solved the recurrence relation. You can test the
correctness of this solution by checking that it produces the same values of an as the recursive
definition, for a few values of n.
Example 6.9.2
Consider the recurrence relation an = 3an−1 + n for n > 0, with a0 = 1. Let f(x) = a0 + a1x +
a2x2 + · · · be the generating function for (an). We want to exploit the fact that an −3an−1 −n = 0
for all n > 0 to find a closed form for f(x) and solve the recurrence, like we did in Example
6.9.1. Therefore, we begin to manipulate f(x):
f(x)
=
a0
+
a1x
+
a2x2
+
· · ·
−3xf(x)
=
−
3a0x
−
3a1x2
−
· · ·
?
=
0
−
1x
−
2x2
−
· · ·
Adding the right-hand sides above we get exactly what we want: from the second column
onwards the sum of the coefficients is an −3an−1 −n, which is equal to 0. However, we do
not yet have a closed form in the left-hand side for the power series −1x −2x2 −3x3 −· · ·. We
can find it by using the identity in the last of the equations in Theorem 6.8.6 in Section 6.8 for
n = 2:
1
(1 −x)2 = 1 +
(1 + 2 −1
1
)
x +
(2 + 2 −1
2
)
x2 + · · · +
(r + 2 −1
r
)
xr + · · ·
= 1 +
(2
1
)
x +
(3
2
)
x2 + · · · +
(r + 1
r
)
xr + · · ·
= 1 + 2x + 3x2 + · · · + (r + 1)xr + · · · .
This is almost what we want, but the coefficients and exponents are out of sync and we have
+’s where we want −’s. To fix this we simply multiply both sides by −x:
−x
(1 −x)2 = −1x −2x2 −3x3 −· · · −(r + 1)xr+1 −· · · .

Combinatorics
339
Now we can add both sides of the equations above at the beginning of this example to obtain
f(x) −3xf(x) −
x
(1 −x)2 = a0 + (a1 −3a0 −1)x + (a2 −3a1 −2)x2 + · · ·
= a0 + 0x + 0x2 + · · ·
= 1.
Thus
f(x)(1 −3x) = 1 +
x
(1 −x)2
f(x) =
1
1 −3x +
x
(1 −x)2(1 −3x).
In order to find an expansion for the last term of the right-hand side above we decompose it
using partial fractions:
x
(1 −x)2(1 −3x) =
A
1 −3x +
B
1 −x +
C
(1 −x)2 ‚
which gives
x = A(1 −x)2 + B(1 −3x)(1 −x) + C(1 −3x).
First setting x = 1 we find C = −1∕2, then setting x = 1∕3 we find A = 3∕4 and finally using
these values and setting x = 0 we get B = −1∕4. Hence
f(x) =
1
1 −3x + 3
4
1
1 −3x −1
4
1
1 −x −1
2
1
(1 −x)2
= 7
4
1
1 −3x −1
4
1
1 −x −1
2
1
(1 −x)2 .
Now we know that
1
1 −3x = 1 + 3x + 32x2 + · · · + 3nxn + · · · ‚
1
1 −x = 1 + x + x2 + · · · + xn + · · · and
1
(1 −x)2 = 1 + 2x + 3x2 + · · · + (n + 1)xn + · · · .
Hence, from the pair of equations above we find that the coefficient of xn in f(x) is an = 7
4(3n) −
1
4(1) −1
2(n + 1) = 7
43n −1
2n −3
4.

340
Logic and Discrete Mathematics: A Concise Introduction
Example 6.9.3
Consider the recurrence relation ak = 3ak−1 + 4k for k > 0, with a0 = 1. We will be guided by
the fact that ak −3ak−1 −4k = 0 for k > 0. Let f(x) be the generating function of (an). Then we
have
f(x)
=
a0
+
a1x
+
a2x2
+
· · ·
3xf(x)
=
3a0x
+
3a1x2
+
· · ·
1
1−4x
=
1
+
4x
+
42x2
+
· · · .
Adding these equations we get
f(x) −3xf(x) −
1
1 −4x = (a0 −1) + (a1 −3a0 −4)x + (a2 −3a1 −42)x2 + · · ·
= a0 −1 = 1 −1 = 0‚
and thus
f(x)(1 −3x) =
1
1 −4x
f(x) =
1
(1 −4x)(1 −3x).
Using partial fractions we decompose the right-hand side of the las equation:
1
(1 −4x)(1 −3x) =
A
1 −3x +
B
1 −4x
1 = A(1 −4x) + B(1 −3x)
Setting x = 1∕3 we find A = −3 and setting x = 1∕4 we find B = 4. Hence:
f(x) =
4
1 −4x −
3
1 −3x
= 4(1 + 4x + 42x2 + · · · + 4nxn + ⋅) −3(1 + 3x + 32x2 + · · · + 3nxn + · · ·).
Hence we find that the coefficient of xn in f(x) is an = 4(4n) −3(3n) = 4n+1 −3n+1.

Combinatorics
341
Lastly, let us now solve a second-order recurrence relation using generating functions.
Example 6.9.4
Suppose an = 2an−1 + 3an−2 for all n > 1 and that a0 = 8 and a1 = 16. Thus, an −2an−1 −3an−2 =
0 for all n > 1. Let f(x) be the generating function for (an). Then we have
f(x) = a0 + a1x + a2x2 + · · ·
2xf(x) = 2a0x + 2a1x2 + 2a2x3 + · · ·
3x2f(x) = 3a0x2 + 3a1x3 + 3a2x4 + · · ·
and hence
f(x) −2xf(x) −3x2f(x) = a0 + (a1 −2a0)x + (a2 −2a1 −3a0)x2 + (a3 −2a2 −3a1)x3 + · · ·
f(x)(1 −2x −3x2) = a0 + (a1 −2a0)x
= 8 + (16 −2(8))x = 8
f(x) =
8
1 −2x −3x2
=
8
(1 −3x)(1 + x).
Decomposing with partial fractions:
8
(1 −3x)(1 + x) =
A
1 −3x +
B
1 + x
8 = A(1 + x) + B(1 −3x).
Setting x = 1∕3 we find A = 6, and x = −1, B = 2; hence
f(x) =
6
1 −3x +
2
1 −(−x)
= 6(1 + 3x + 32x2 + · · · + 3nxn + · · ·) + 2(1 −x + x2 −· · · + (−1)nxn + · · ·).
Hence we have an = 6(3n) + 2(−1)n.
6.9.1.
Exercises
Solve the following recurrence relations using generating functions.
➊ak = ak−1 + 3 for k > 0 and a0 = 5.
➋ak = ak−1 + 6ak−2 for k > 1, a0 = 1 and a1 = 4.
➌ak = 2ak−1 + k for k > 0 and a0 = 3.
➍ak = 2ak−1 + 3k for k > 0 and a0 = 1.
➎an+1 −an = 3n for n ≥0 and a0 = 0.
➏an −3an−1 = 5n−1 for n > 0 and a0 = 1.
➐an = 4an−1 + 2n for n ≥1 and a0 = 3.
➑an = 7an−1 −10an−2 for n ≥2, a0 = 1 and a1 = 3.
➒an+2 −2an+1 + an = 2n for n ≥0, a0 = 1 and a1 = 2.
➓ak = 6ak−1 −9ak−2 + 2k for k ≥2, a0 = 1 and a1 = 8.

342
Logic and Discrete Mathematics: A Concise Introduction
Fibonacci numbers and the golden ratio
The golden ratio is the ratio 𝜙= a∕b such that
a
b = a + b
a
.
Thus
𝜙= a + b
a
= 1 + b
a = 1 + 1
𝜙
and therefore
𝜙2 −𝜙−1 = 0.
Using the quadratic formula we find that
𝜙= 1 +
√
5
2
.
The golden ratio appears throughout mathematics and nature, and it has been observed that
humans find geometric objects exhibiting this ratio particularly pleasing. For example, if people are
shown different rectangles and asked to choose those that they like the best, they tend to pick ones in
which the side length stands in the golden ratio. The golden ratio can be found in the measurements
of classical architecture and sculptures.
The golden ration appears in the solution of the recurrence relation for the Fibonacci numbers:
Fn =
1
√
5
(
1 +
√
5
2
)n
−
1
√
5
(
1 −
√
5
2
)n
.
The golden spiral is a logarithmic spiral given by a polar equation of the form r = aeb𝜃, where a
is an arbitrary constant and b = 2 ln 𝜙∕𝜋. The golden spiral is seen in nature in the shapes of various
things from Nautilus shells to spiral galaxies. It is approximated by the Fibonacci spiral, illustrated
below, which is obtained by arranging squares with side lengths given by the Fibonacci numbers,
as shown, and drawing the inscribed quarter circles.

Combinatorics
343
6.10.
Application: classical discrete probability
Throughout this chapter we have developed various counting techniques. Counting objects
with a given property is at the heart of computing discrete probabilities. In this section we
will introduce some of the fundamental concepts of discrete probability theory and will
demonstrate how the counting techniques from the previous sections apply for solving
probability problems.
6.10.1.
Common sense probability
Suppose we toss a normal coin. Most people would agree that the likelihood of the coin land-
ing heads is about 50%, because this is a likelihood of one event happening (heads) out of two
possible and equally likely outcomes: heads and tails. If we measure likelihood on a scale of
0 to 1, with 0 representing the likelihood of an event that can never occur and 1 the likelihood
of an a event that is certain to occur, the likelihood of our coin landing heads would be 0.5.
Similarly, consider the toss of a standard six-sided die.6 There are six possible and equally
likely outcomes: one, two, three, four, five and six. The likelihood of any such outcome, e.g.
“three”, is therefore 1 out of 6, i.e. 1
6. The likelihood of the outcome to be a number less than
four is 3 out of 6, or 3
6 = 1
2, as exactly three of the possible six outcomes of the toss (namely one,
two and three) would satisfy this requirement. Likewise, the likelihood of an even number is
also 1
2. Lastly, the likelihood of the outcome to be a number between one and six is 6
6 = 1 and
the likelihood of a number between 7 and 13 is, of course, 0
6 = 0.
Such likelihoods are measured by the notion of probability, the precise meaning of which
we will formally define shortly. Before that, we need some preparation.
6.10.2.
Sample spaces
Now let us abstract some important concepts from these two informal examples. In each case
we considered an experiment or trial and carefully listed all the possible outcomes thereof.
The set of all such outcomes is called sample space. Let us denote the sample space with S.
We will only consider finite sample spaces.
Next, we considered some properties of, or restrictions on, the outcomes of our experi-
ment, e.g. the property of the outcome of the die-toss being an even number. This corresponds
to a subset of the sample space, namely the subset consisting of all outcomes that are even
numbers. One can think of this as the event of the outcome being even, where event is sim-
ply any set of outcomes, i.e. any subset of the sample space S. Events containing exactly one
outcome are called simple events.
Mutually exclusive events are events that have no outcomes in common, i.e. events A‚ B ⊆
S such that A ∩B = ∅. If A ⊆S is an event, then A = S −A is called the complementary event
of A.
Example 6.10.1
Let us return to the case of casting a die. The sample space is the set S = {1‚ 2‚ 3‚ 4‚ 5‚ 6}.
Examples of events are A = {1‚ 3‚ 5}, B = {2‚ 4‚ 6}, C = {1‚ 2‚ 3‚ 5‚ 6}, D = {4} and E = {5}. A
and B are mutually exclusive, and so are C and D. The events D and E are simple, while the
events C and D are complementary.
6 “Die” is the singular of “dice”.

344
Logic and Discrete Mathematics: A Concise Introduction
Example 6.10.2
Consider a lottery draw that consists in a random selection of 6 different numbers between
1 and 49. Thus, the sample space, S, consists of all possible draws of six numbers out of 49.
Hence there are
C(49‚ 6) = 49!
43!6! = 49 × 48 × 47 × 46 × 45 × 44
720
= 10 068 347 520
720
= 13 983 816
outcomes in S. By definition, every subset of S determines an event, but in this case some
events are of much greater interest to players than others. Suppose John has a lottery ticket
with numbers (3‚ 7‚ 19‚ 27‚ 39‚ 42). Let J1 be the event consisting of all draws in which John
has at least one number matching the draw. How many outcomes are there in J1? In order
to count them, we consider the complementary event of J1, that is the event J1 in which John
has no matching numbers:
|J1| = C(49 −6‚ 6) = C(43‚ 6) = 43!
37!6! = 4 389 446 880
720
= 6 096 454.
Thus we have |J1| = |S| −|J1| = 13 983 816 −6 096 454 = 7 887 362.
Let J≥5 be the event in which John has at least five numbers right. Clearly J≥5 = J5 ∪J6,
where J5 and J6 are the events in which John has exactly five numbers right and all six
numbers right, respectively. Now |J5| = C(6‚ 5) × C(43‚ 1) = 6 × 43 = 258 and |J6| = 1 so |J≥5| =
258 + 1 = 259.
Example 6.10.3
Consider a trial in which a coin is tossed and a die is cast. The sample space looks like this:
(Heads, 1)
(Heads, 2)
(Heads, 3)
(Heads, 4)
(Heads, 5)
(Heads, 6)
(Tails, 1)
(Tails, 2)
(Tails, 3)
(Tails, 4)
(Tails, 5)
(Tails, 6)
Each outcome represents a combination of a possible outcome of the tossed coin and the cast
die. Some events of interest may be:
HEADS The coin comes up heads. This consists of all sample points in the first row.
SIX The die lands on a 6. This consists of all sample points in the last column.
ODD The die lands on an even number. This consists of all outcomes in the first, third and
fifth columns.
TAILS ∩EVEN The coin comes up tails and the die lands on an even number. This consists
of all outcomes in the bottom row in the second, fourth and sixth columns.

Combinatorics
345
6.10.3.
Discrete probability
Our reason for introducing sample spaces and events is to define probabilities on them. In the
simplest case, when all events are equally likely, we have the following definition that goes
back to the works of Laplace (see the end of Section 6.10).
Definition 6.10.4 Consider an experiment with a finite number of possible different outcomes, which
are all equally likely. Then the classical probability of an event is defined to be the ratio of the number
of possible favourable outcomes to the total number of possible outcomes of the experiment, where a
favourable outcome is any outcome that belongs to the event.
Example 6.10.5
Returning to Example 6.10.1, it should be clear that the classical probability of the event A,
denoted by P(A), is equal to 3
6 = 1
2. Similarly, P(B) = 1
2, P(C) = 5
6 and P(D) = P(E) = 1
6. Lastly,
P(S) = 1.
Notice that, in Example 6.10.5, P(S) = 1 and that, if E1‚ E2‚ …‚ En are pairwise mutually
exclusive events, P(E1 ∪E2 ∪· · · ∪En) = P(E1) + P(E2) + · · · + P(En). In fact these are exactly the
properties that are used to define the general notion of a probability measure.
Definition 6.10.6 Let S be a finite sample space and P a function from the set (S) of all events over
S to the real interval [0‚ 1]. P is called a probability measure if
(P1) P(S) = 1.
(P2) For any family {Ei ∣1 ≤i ≤n} of pairwise disjoint events it holds that
P
( n
⋃
i=1
Ei
)
=
n
∑
i=1
P(Ei).
The pair (S‚ P) is called a finite probability space.
(P1) requires that the probability of S is 1, as we would expect, since intuitively S is certain
to occur. (P2) is known as the principle of additivity.
Example 6.10.7
In the lottery Example 6.10.2, the lottery draw is supposed to be totally random. Hence, each
selection of 6 numbers out of 49 should be equally likely. We saw that the sample space S
contains 13 983 816 outcomes and, consequently, that there are 13 983 816 simple events. Each
simple event then has probability 1∕13 983 816. This means that the probability that John wins
the jackpot is 1 in 13 983 816. The probability that he has at least one number right is
P(J1) = 7 887 362
13 983 816 ≈0.564.
The probability that he has at least five numbers right is
P(J≥5) =
259
13 983 816 ≈0.0000185.

346
Logic and Discrete Mathematics: A Concise Introduction
Example 6.10.8
Recall the combined experiment in Example 6.10.3, in which a coin is tossed and a die cast.
Assuming that the coin and the die are fair, i.e. each outcome is equally likely, we have P(E) =
1∕12 for each simple event. The probabilities of the events considered are then:
• P(HEADS) = 1∕2.
• P(SIX) = 2∕12 = 1∕6.
• P(ODD) = 6∕12 = 1∕2.
• P(TAILS ∩EVEN) = 3∕12 = 1∕4.
Also,
P(TAILS ∪EVEN) = |TAILS ∪EVEN|
12
= |TAILS| + |EVEN| −|TAILS ∩EVEN|
12
= 6 + 6 −3
12
= 3
4
and
P(TAILS\EVEN) = |TAILS\EVEN|
12
= |TAILS| −|TAILS ∩EVEN|
12
= 6 −3
12
= 1
4.
6.10.4.
Properties of probability measures
We will now draw some consequences from Definition 6.10.6, which will elucidate the nature
of probability spaces and facilitate the computation of probabilities. As a first consequence
of Definition 6.10.6, we have the following proposition, which lists some useful properties of
probability measures.
Proposition 6.10.9 Let (S‚ P) be a finite probability space. Then, for all events A and B and the empty
events ∅we have:
P(∅) = 0
P(A) = 1 −P(A)
P(A\B) = P(A) −P(A ∩B)
P(A ∪B) = P(A) + P(B) −P(A ∩B)
IfA ⊆B‚ then P(A) ≤P(B)
Proof: For the first equation, first note that S ∩∅= ∅. Therefore, by axiom (P2), P(S) + P(∅) =
P(S ∪∅). Further, S ∪∅= S and P(S) = 1 by axiom (P1) and hence 1 + P(∅) = 1, so P(∅) = 0.

Combinatorics
347
For the second equation, note that 1 = P(S) = P(A ∪A) = P(A) + P(A), where the first
equality holds by (P1) and the last equality follows from (P2) and the fact that A ∩A = ∅.
Thus 1 = P(A) + P(A) and hence P(A) = 1 −P(A).
The proof of the third equation is left as Exercise 12.
For the fourth equation, we begin by noting that A ∪B = (A\B) ∪(B\A) ∪(A ∩B)
and that the sets (A\B), (B\A) and (A ∩B) are pairwise disjoint. Hence, we may
apply
the
axiom
of
additivity
and
obtain
P(A ∪B) = P(A\B) + P(B\A) + P(A ∩B) =
P(A) −P(A ∩B) + P(B) −P(B ∩A) + P(A ∩B) = P(A) + P(B) −P(A ∩B),
where
the
second
equality follows from the third equation.
The proof of the fifth equation is left as Exercise 13.
Example 6.10.10
In Example 6.3.3 we considered a sample of 100 university students of which 75 take
mathematics, 50 take physics and 45 take both. From this information, using the inclu-
sion – exclusion principle (Section 6.3), we were able to extrapolate to the following Venn
diagram:
30
45
20
M
P
5
Suppose we want to know how likely it is that a randomly selected student from among
the 100 takes mathematics. The natural way to state this question in terms of the probability
theory would be to take our sample space S to be the set of all 100 students. As we have
no reason to think that any student is more likely to be selected than another, we can use
classical probability, and hence P(Math) =
75
100 = 0.75.
The following proposition allows us to calculate the probability of an event by splitting it
up according to a partition of the probability space.

348
Logic and Discrete Mathematics: A Concise Introduction
Proposition 6.10.11 Let (S‚ P) be a finite probability space and suppose that E1‚ E2‚ …‚ En ⊆S form
a partition of S, i.e. E1‚ E2‚ …‚ En are pairwise disjoint events such that E1 ∪E2 ∪· · · ∪En = S. Then
for any event S ⊆S it holds that
P(A) = P(A ∩E1) + P(A ∩E2) + · · · + P(A ∩En).
Proof: The proof is left as Exercise 14.
6.10.5.
Conditional probability and independent events
We now turn to questions of the type: “What is the probability of event A, given that event B
has occurred”. For example, suppose that two players, Alice and Bob, are playing a card game.
Alice is dealt a card from a standard 52 card deck. The probability that she has been dealt a
heart is, of course, 13
52 = 1
4. Respectively, the probability that her card is the Queen of hearts is
1
52. However, suppose that Bob got a glimpse of the card she was dealt. He did not see enough
to know which card it was, all he can tell was that it was a red card. What probability should
he now assign to the event that she got a heart? Two of the suits, i.e. 13 + 13 of the cards, are
red, so the probability is
13
13+13 = 1
2. Respectively, the probability that Alice’s card is the Queen
of hearts, given that it is red, is 1
26.
What happened? We restricted the sample space to the red cards and calculated the ratio
of the number of suitable outcomes (hearts) which are in the restricted sample space to the
total number of outcomes in this restricted sample space.
Similarly, in Example 6.10.10 we might ask the question: how likely is it that a student
who takes physics also takes mathematics? One way to approach this is to restrict the sample
space to those 50 students who take physics. We are given that 45 of them take mathematics.
Hence, it would be reasonable to assign the probability 45
50 = 0.9 to the event that a (randomly
chosen) student who takes physics, also takes mathematics. The next definition formalizes
these intuitions.
Definition 6.10.12 The conditional probability of an event A relative to an event B is denoted
by P(A|B), and is given by
P(A|B) = P(A ∩B)
P(B)
‚
provided P(B) > 0. In the case that P(B) = 0, the conditional probability P(A|B) is undefined.

Combinatorics
349
Example 6.10.13
Students gain admission to the course Probability Theory B if, and only if, they have passed
Probability Theory A. The probability that a student passes Probability Theory A is 2
3, while
the probability that (s)he passes both A and B is 1
2. What is the probability that a student will
pass Probability Theory B, given the fact that (s)he has passed Probability Theory A?
To model this situation we can construct a probability space (S‚ P) with S = {00‚ 10‚ 11}
containing the three outcomes “pass neither”, “pass only A” and “pass both”. (Note that
“pass only B” is impossible, so we do not list it in S.) Let A and B denote the events “pass
A” and “pass B”, respectively. From the given information we have P(A) = P({10‚ 11}) = 2
3
and P(B) = P({11}) = 1
2. Therefore the probability that a student passes B, given that (s)he
has passed A, is
P(B|A) = P(B ∩A)
P(A)
= P({11})
P(A)
=
1
2
2
3
= 3
4 = 0.75.
The probability of passing B, given that A has not been passed, is
P(B|A) = P(B ∩A)
P(A)
=
P(∅)
1 −P(A) =
0
1 −2
3
= 0‚
as one would expect.
As an immediate consequence of Definition 6.10.12 we have that
P(A ∩B) = P(B) ⋅P(A|B)‚
provided that P(B) > 0. This generalizes to any finite number of events A1‚ A2‚ …‚ An, as fol-
lows.
Proposition 6.10.14 Let (S‚ P) be a finite probability space. Then, for all events A1‚ A2‚ …‚ An such
that P(A1 ∩A2 ∩· · · ∩An) > 0,
P(A1 ∩A2 ∩· · · ∩An)
= P(A1)P(A2|A1)P(A3|A1 ∩A2) · · · P(An|A1 ∩A2 ∩· · · ∩An−1).
Proof: By the last equation in Proposition 6.10.9 we have P(A1) ≥P(A1 ∩A2) ≥· · · ≥
P(A1 ∩A2 ∩· · · ∩An−1) > 0, and hence the conditional probabilities P(A2|A1), P(A3|A1 ∩A2),
…P(An|A1 ∩A2 ∩· · · ∩An−1) are defined. Now
P(A1)P(A2|A1)P(A3|A1 ∩A2) · · · P(An|A1 ∩A2 ∩· · · ∩An−1)
= P(A1)
P(S)
P(A1 ∩A2)
P(A1)
P(A1 ∩A2 ∩A3)
P(A1 ∩A2)
· · · P(A1 ∩A2 ∩· · · ∩An)
P(A1 ∩A2 ∩· · · ∩An−1)
= P(A1 ∩A2 ∩· · · ∩An)
P(S)
= P(A1 ∩A2 ∩· · · ∩An).

350
Logic and Discrete Mathematics: A Concise Introduction
Example 6.10.15
Suppose a box contains a red ball and a blue ball. We consider a procedure of repeatedly
drawing a ball from the box and replacing it back. Moreover, whenever a red ball is drawn it
is replaced and another red ball is added to the box. Let us determine the probability that for
the first 20 rounds only red balls are drawn. In other words, we are looking for P(R1 ∩R2 ∩
· · · ∩R20), where Ri is the event that in round i a red ball is drawn. Then
P(R1 ∩R2 ∩· · · ∩R20)
= P(R1)P(R2|R1)P(R3|R1 ∩R2) · · · P(R20|R1 ∩· · · ∩R19).
Now P(R2|R1) = 2
3, since after R1 has occurred, there are three ball in the box, two of which
are red. Similarly, P(R3|R1 ∩R2) = 3
4 and in general Ri = i∕(i + 1). So the probability we are
looking for is
1
2 ⋅2
3 ⋅3
4 ⋅· · · ⋅20
21 = 20!
21! = 1
21.
All general results on probabilities hold for conditional probabilities, as the following
“conditional” version of Theorem 6.10.9 illustrates.
Proposition 6.10.16 Let (S‚ P) be a finite probability space; then, for all events A, B and C,
P(A|C) = 1 −P(A|C)
P(A\B|C) = P(A|C) −P(A ∩B|C)
P(A ∪B|C) = P(A|C) + P(B|C) −P(A ∩B|C).
Proof: The proof is left as Exercise 19.
Independent events
Intuitively, two events are independent if the occurrence of the one make the occurrence of
the other nor more likely, nor less likely. For example, consider the experiment of drawing a
single card from a standard deck, and the events H and F of the card being a heart and a face
card, respectively. Intuitively, since the face cards are evenly distributed among the suits, these
events should be independent. Indeed notice that
P(H|F) = P(H ∩F)
P(F)
=
3
52
12
52
= 1
4 = 13
52 = P(H)
and
P(F|H) = P(F ∩H)
P(H)
=
3
52
13
52
= 3
13 = 12
52 = P(F).

Combinatorics
351
This is not something particular to this example: saying that P(H|F) = P(H) and (F|H) =
P(F) is the same as saying that P(H) =
P(H∩F)
P(F)
and P(F) = P(F∩H)
P(H) , which is equivalent to saying
that P(H ∩F) = P(H) ⋅P(F). We will turn this observation into a formal definition of indepen-
dence.
Definition 6.10.17 Two events A and B are called independent if P(A ∩B) = P(A) ⋅P(B).
Example 6.10.18
A coin is tossed and a die is cast. What is the probability that the outcome is heads and a six?
Solution
Let A be the event that the coin lands heads and let B be the event that the die lands on six.
We are interested in P(A ∩B), but since the outcome of the coin toss is in no way influenced
by the outcome of the cast of the die and vice versa, these events are independent, and hence
P(A ∩B) = P(A) ⋅P(B) = 1
2 ⋅1
6 =
1
12.
We can generalize the notion of independence to more than two events.
Definition 6.10.19 Events A1‚ …‚ An are independent if for all 2 ≤k ≤n and all families of k sets
Ai1‚ …‚ Aik from among A1‚ …‚ An it holds that
P(Ai1 ∩· · · ∩Aik) = P(Ai1) ⋅· · · ⋅P(Aik).
If this holds only for k = 2, we call the events pairwise independent.
Example 6.10.20
Suppose the 26 letters of the alphabet are written on cards which are placed in a box. Then
cards are drawn, one at a time, with replacement. What is the probability that the first 26
draws produces the sequence of the 26 alphabet letters in order?
Solution
Let Ai be the event that the ith letter of the alphabet is drawn in the ith draw. Since the draws
are with replacement, the outcomes of the subsequent draws do not affect each other, so the
events Ai are independent. Hence
P(A1 ∩A2 ∩· · · ∩A26) = P(A1) ⋅P(A2) ⋅· · · ⋅P(A26) =
(
1
26
)26
≈1.6244 × 10−37.
This is a very small probability and, indeed, one would be very surprised to see the
26 letters of the alphabet appearing in order. Notice, however, that there is nothing special
about this particular sequence: any other sequence of letters has exactly the same probability
of being drawn!

352
Logic and Discrete Mathematics: A Concise Introduction
Suppose now that the drawing proceeded without replacement. Now the events Ai are
no longer independent, so we have to use Proposition 6.10.14:
P(A1 ∩A2 ∩· · · ∩A26)
= P(A1)P(A2|A1)P(A3|A1 ∩A2) · · · P(A26|A1 ∩· · · ∩A25)
= 1
26 ⋅1
25 ⋅1
24 ⋅· · · ⋅1
1
= 1
26! ≈2.4796 × 10−27.
6.10.6.
Exercises
➊A lottery ticket consists of six numbers between 1 and 49. A holder of a ticket wins the
jackpot if the numbers match the six randomly drawn numbers. Any ticket with at least
three matching numbers from the draw also qualifies for some prize money.
(a) How many different lottery tickets are there?
(b) How many different lottery tickets do you have to buy in order to have at least a chance
of one in a million of winning the jackpot?
(c) How many different lottery tickets are there in which at least three numbers match
numbers in the draw?
(d) How many different lottery tickets do you have to buy in order to have at least a chance
of one in a million of winning some prize money?
(e) How many different lottery tickets are there in which no number matches any of the
six in the draw?
➋A patient is tested for deficiencies in vitamins A, B and C. Let E be the event “the patient is
deficient in at least two of the vitamins” and let F be the event “the patient has no deficien-
cies”. Describe the following events in words.
(a) E ∩F
(b) E ∪F
(c) E ∩F
➌What is the probability that an integer between 1 and 10 000 has exactly one 5 and one 4
among its digits? What is the sample space?
➍What is the probability that in a random n-digit binary sequence there are no pairs of con-
secutive digits that are the same?
➎What is the probability that a 5-card poker hand has the following?
(a) A Royal Flush, i.e. an Ace, King, Queen, Jack and Ten of the same suit.
(b) A Flush, i.e. any 5 cards of the same suit.

Combinatorics
353
(c) 4 aces.
(d) 4 of a kind, i.e. 4 cards of the same value, e.g. 4 Eights or 4 Queens.
(e) A Straight, i.e. a set of 5 consecutive values.
(f) A Straight that is not a Flush.
(g) The same number of hearts and diamonds.
(h) More spades than hearts.
➏What is the probability that 2 people out of a meeting of 30 people have the same birthday?
➐What is the probability that an arrangement of the letters in the word ALTITUDE has:
(a) no consecutive vowels?
(b) at least 2 consecutive vowels?
(c) at least 3 consecutive vowels?
➑What is the probability that in an arrangement of 7 letters A, 6 letters B and 5 letters C:
(a) the first A precedes the first B?
(b) the first A precedes the first B and the first B precedes the first C?
(c) all A’s precede all B’s?
➒50 butterflies are captured from a previously unexplored rainforest. 20 of these butterflies
have stripes, 31 have spots and 14 have dots. 16 have stripes and spots, 9 have spots and
dots and 5 have have all three features. 12 of the 50 butterflies have none of these features.
(a) What is the probability that a butterfly randomly selected from the sample has stripes
and dots?
(b) What is the probability that a butterfly randomly selected from the sample has at least
two of these three features?
➓Suppose 12 distinct objects are distributed into 12 different boxes. What is the probabil-
ity that
(a) no box is empty?
(b) exactly one box is empty?
(c) at least one box is empty?
(d) two boxes are empty?
11 What is the probability that, when 26 shirts are distributed into 5 washing machines, that
at least one washing machine contains 6 shirts or more?
12 Prove the third equation from Proposition 6.10.9.
13 Prove the last equation from Proposition 6.10.9.
14 Prove Proposition 6.10.11 and then generalize it to a partition consisting of countably
many sets.

354
Logic and Discrete Mathematics: A Concise Introduction
15 Two archers are shooting at a target. The probability that, with any given shot, the first
archer hits the target is 0.6, while the probability that the second archer hits it is 0.75. A total
of 5 shots are fired, 3 by the first archer and 2 by the second. What is the probability that
(a) all 5 shots hit the target?
(b) no shots hit the target?
(c) at least one shot hits the target?
16 The 20 volumes of an encyclopedia are arranged randomly on a shelf. What is the probabil-
ity that they will be in numerical order?
17 An urn contains 12 identical back balls and 10 identical white balls. Balls are drawn two at
a time, for 10 rounds. What is the probability that in each of the 10 rounds a black and a
white ball will be drawn?
18 I’m trying to guess someone’s age. If I know that she is between 30 and 39 years old, what
is the probability that
(a) I will get it right on the third guess?
(b) I will get it right in three or fewer guesses?
19 Prove the items in all three equations from Proposition 6.10.16.
20 A student passes Discrete Mathematics if he passes Probability Theory or if he passes Propo-
sitional Logic and First-Order Logic. The probability that he will pass Probability Theory
is 0.6, while the probabilities that he will pass Propositional and First-Order Logic are 0.5
and 0.4, respectively. Passing these three topics represents independent events. What is the
probability that the student will pass Discrete Mathematics?
21 In Example 6.10.15 no probability space or probability measure was specified. Under the
assumption that exactly 30 balls are drawn in the experiment, specify a suitable probability
space and define a probability measure on it.

Combinatorics
355
Pierre-Simon de Laplace (1749–1827)
Pierre-Simon
de
Laplace
was
a
French
mathematician
and
astronomer who made fundamental contributions to mathematical
astronomy and statistics.
Pierre-Simon de Laplace’s parents were peasants living in
Beaumont-en-Auge in France. Very little is known about Laplace’s
childhood, mostly because he tried to suppress all details of his
humble beginnings in later life. In Beaumont-en-Auge the young
Laplace’s talent in theological disputations and mathematics gained
him the support of some wealthy residents, which enabled him
to study mathematics at the local military academy. After teach-
ing for a while at this same academy, Laplace travelled to Paris
where he introduced himself to D’Alembert (1717–1783). After ini-
tially receiving him rather coldly, D’Alembert became so impressed
with Laplace that he arranged for him to be appointed as Professor of Mathematics at the Military
School of Paris.
The life’s work that Laplace set himself was to work out the detailed application of Newton’s
laws of motion and gravitation to the solar system. This was a staggeringly complicated problem.
The results were published as the Mècanique Cèleste, Laplace’s masterwork, which appeared in parts
over a period of twenty-six years. The overall aim was to prove that the solar system is stable, i.e.
that the planets will not eventually drift out of their orbits into space or crash into each other or into
the sun. All of his work was subservient to this aim, including his ground breaking and fundamental
work on probability and statistics, published as Thèorie Analytique des Probabilitès (1812).
In 1785 one of the candidates that Laplace had to examine at the Military Academy was
the young Napoleon Bonaparte (1769–1821). This was a fateful encounter: after the revolution
Napoleon granted Laplace not only distinctions and honours for his work in mathematics, but also
influential government positions, and made him a Count of the French Empire. Laplace spent his
last days in comfortable retirement at his country estate at Arcueil outside Paris.

7
Graph Theory
7.1.
Introduction to graphs and digraphs . . . . . . . . . . . . . . . . . . . . . . . . . .
357
7.2.
Incidence and adjacency matrices . . . . . . . . . . . . . . . . . . . . . . . . . . .
370
7.3.
Weighted graphs and path algorithms
. . . . . . . . . . . . . . . . . . . . . . . .
377
7.4.
Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
385
7.5.
Eulerian graphs and Hamiltonian graphs . . . . . . . . . . . . . . . . . . . . . . .
395
7.6.
Planar graphs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
404
7.7.
Graph colourings
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
411
Graph theory is the study of structures called graphs.1 A graph is essentially a (usually finite)
set of objects, called vertices, equipped with a symmetric and irreflexive binary edge relation
between these vertices. Graph are typically visualized in a way similar to the graphical repre-
sentation of binary relations studied in Section 2.3.2, with dots representing vertices and lines
representing edges, for example:
e
b
a
d
c
We do not put directions to the edges because the edge relation is assumed symmetric.
When the assumption of symmetry is dropped, the resulting structures are called directed
graphs or digraphs.
1 These are not to be confused with function plotting graphs, like, for example the graph of a parabola.
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic

Graph Theory
357
Graph theory is closely related to combinatorics. It is a beautiful mathematical field:
graphs are very pleasant objects to work with, being easy to visualize and to apply geometric
intuitions to. The problems studied in graph theory are often relatively easy to formulate
and understand, although these problems can sometimes turn out to be extremely difficult
to solve. Some of the questions that we will be asking and answering in this chapter include:
“when can we find a path along the edges in a given graph which uses all the edges?”, “when can a
graph be drawn in the plane without any of its edges crossing?”, “what is the least number of colours
needed to colour the vertices of a given graph so that no two vertices linked by an edge have the same
colour?” and “what is the relationship between the numbers of edges and vertices in a graph which
does not contain any cycles?”.
Graph theory has many and varied applications across many different fields. Indeed,
graphs and digraphs can be used to model any situation in which pairs objects stand in a rela-
tion to each other, including computers linked in a network, web pages linking to each other,
people being friends on social networking sites, radio transmitters having overlapping ranges
and many more. In this chapter we will be applying the theory of graphs to solve problems
like scheduling clash-free exam timetables, planning cheap and efficient routes through road
or airline networks, and minimizing the number of layers needed in electronic circuit boards.
7.1.
Introduction to graphs and digraphs
In this section we introduce the basic terminology and concepts relating to graphs and
digraphs.
7.1.1.
Graphs
Basic concepts
A graph G consists of a nonempty set of objects called vertices (singular: vertex) together with
a (possibly empty) set of unordered pairs of distinct vertices called edges. In our presentation
the set of vertices (and, hence, also the set of edges) will be assumed finite unless otherwise
specified, but much of the theory presented here also applies to infinite graphs. The set of
vertices (vertex set) of G and the set of edges (edge set) of G are denoted by V(G) and E(G),
respectively. A graph G with vertex set V and edge set E will be denoted by G(V‚ E). If G(V‚ E)
is a graph, then:
• We say the edge e = {u‚ v} joins vertices u and v. Hereafter we will demote the edge {u‚ v}
simply as uv.
• If e = uv is an edge of G, u and v are called adjacent vertices, while u and e (as well as v and
e) are said to be incident.
• If e1 and e2 are distinct edges of G incident with a common vertex they are called adjacent
edges.
• An edge uv will usually be denoted merely by uv.
• The number of vertices is called the order of the graph G, denoted by n(G), or simply by n
if the graph under consideration is clear from the context.

358
Logic and Discrete Mathematics: A Concise Introduction
• The number of edges is called the size of the graph G and denoted by m(G), or simply by m
if the graph under consideration is clear from the context.
• An (n‚ m) graph has order n and size m.
We usually visualize a graph as follows: the vertices are represented by circles or dots and the
edges as lines or arcs connecting these. It follows from the definition of a graph that there can
be at most one edge joining two vertices and that an edge cannot join a vertex to itself.
We illustrate these concepts with an example.
Example 7.1.1
Consider the graph G = (V‚ E) with V = {v1‚ v2‚ v3‚ v4} and E = {v1v2‚ v2v3‚ v3v4‚ v4v1‚ v1v3}.
For simplicity of notation we set v1v2 = e1‚ v2v3 = e2‚ v3v4 = e3‚ v4v1 = e4 and v1v3 = e5. This
graph is sketched in Figure 7.1. Note that n(G) = 4 and m(G) = 5, and hence G is a (4‚ 5) graph;
e1 joins v1 and v2, and hence v1 and v2 are adjacent and e1 is incident with both; e1 and e5 are
adjacent edges.
The degree of a vertex v in a graph G is the number of edges incident with the vertex in
that graph, denoted deg Gv or simply deg v if G is clear from the context.
• A vertex is called even or odd depending on whether its degree is even or odd.
• A vertex with degree 0 is called isolated.
• A vertex with degree 1 is called an end-vertex.
• The minimum degree of a graph G is the minimum among the degrees of the vertices of G,
denoted 𝛿(G). The maximum degree of G, denoted by Δ(G), is defined likewise.
• A graph with order 1 can have no edges. Therefore there is only one graph of order 1, namely
the graph consisting of a single isolated vertex. This graph is called the trivial graph. All
other graphs are nontrivial.
Example 7.1.2
We consider the graph G in Figure 7.2. We have deg v1 = 3 = Δ(G), deg v2 = deg v4 =
deg v5 = 1 and deg v3 = 0 = 𝛿(G). Thus, v2, v4 and v5 are end-vertices while v3 is an isolated
vertex.
e1
e5
v4
v3
v2
v1
e4
e2
e3
Figure 7.1: Example 7.1.1

Graph Theory
359
v4
v5
v3
v2
v1
Figure 7.2: Example 7.1.2
These definitions give us enough of a conceptual framework to formulate and prove our first
simple theorem about graphs.
Theorem 7.1.3 Let G be an (n‚ m) graph with V(G) = {v1‚ v2‚ …‚ vn}. Then
n
∑
i=0
deg vi = 2m
Proof: Each edge is incident with precisely two vertices. Hence, when summing the degrees of
the vertices each edge is counted precisely twice.
Theorem 7.1.3 is often called The First Theorem of Graph Theory. It has the following corol-
lary.
Corollary 7.1.4 Every graph has an even number of odd vertices.
Proof: Let G(V‚ E) be a (n‚ m) graph and let W be the set of odd vertices of G and U the set of
even vertices. By Theorem 7.1.3
2m =
∑
v∈V
deg v =
∑
v∈W
deg v +
∑
v∈U
deg v.
Clearly ∑
v∈U deg v, being a sum of even numbers, must be even. Then, as ∑
v∈U deg v and
∑
v∈W deg v add up to an even number, ∑
v∈W deg v must also be even. This implies that |W|
must be even, giving us an even number of odd vertices.
Subgraphs
A graph H is called a subgraph of a graph G if H is “contained in” G. Formally, H is a subgraph
of G if V(H) ⊆V(G) and E(H) ⊆E(G). Note that we can take any subset of E(G) as the vertex
set of the subgraph, as long as each vertex incident with an edge in this subset is a vertex in
V(H).
H is called a proper subgraph of G if either of the containments V(H) ⊆V(G) or E(H) ⊆
E(G) are proper. If H is a subgraph of G, then G is a supergraph of H. H being a subgraph of
G is denoted by H ⊆G.
If I ⊆V(G), then the subgraph of G induced by I, denoted ⟨I⟩G, is the subgraph of G that
has vertex set I and all the edges in G between vertices in I. In other words, the edges of ⟨I⟩G

360
Logic and Discrete Mathematics: A Concise Introduction
are exactly those edges of G between vertices in I. Similarly, if X ⊆E(G) then the subgraph of G
vertex induced by X, denoted ⟨X⟩G, is the graph with edge set X and all vertices of G incident
with one or more edges from X.
Example 7.1.5
The graph shown in Figure 7.3 is known as the Petersen graph. The graphs shown in
Figures 7.4 and 7.5 are subgraphs of the Petersen graph, but are not subgraphs of each
other. Note that neither is an induced subgraph of the Petersen graph, but that both are
edge induced subgraphs of the Petersen graph. You can check that the graph (called K3) in
Figure 7.6 is not a subgraph of the Petersen graph (so it cannot be a subgraph of any of these
two graphs – why?).
Complete graphs and bipartite graphs
A graph is called complete if there is an edge between every pair of vertices, i.e. the graph has
all the edges it can possibly have. The complete graph with n vertices is denoted by Kn. Note
that Kn has
(
n
2
)
edges. Figure 7.7 shows the complete graphs of order one to four.
A graph G is called bipartite if it is possible to express V(G) as the union of two disjoint
nonempty sets (known as partite sets), say V1 and V2, such that every edge e ∈E(G) joins a
vertex in V1 to a vertex in V2; in other words, there is no edge between two vertices in V1 or
between two vertices in V2.
Figure 7.3: The Petersen graph
Figure 7.4: A subgraph of the Petersen graph

Graph Theory
361
Figure 7.5: Another subgraph of the Petersen graph
Figure 7.6: K3 – the complete graph on three vertices
K1
K2
K3
K4
K5
Figure 7.7: The complete graphs of order one to four.
Example 7.1.6
Consider the graph pictured in Figure 7.8.
This graph is bipartite. We have indicated the vertices in the two partite sets as respec-
tively white and black circles.
A bipartite graph G is called complete if for all u1 ∈V1 and u2 ∈V2 it is the case that
u1u2 ∈E(G). If |V1| = r and V2 = s, then this graph is denoted by Kr‚ s and has r × s edges.

362
Logic and Discrete Mathematics: A Concise Introduction
Figure 7.8: A bipartite graph
Figure 7.9: The complete bipartite graph K3‚ 3
Example 7.1.7
Figure 7.9 shows the complete bipartite graph K3‚ 3. Note that K2 is bipartite but that all com-
plete graphs of order higher that two are not. Indeed, there is no way to split the vertex set
of K3 into two nonempty partite sets. Can you see why?
Paths and distance
In this subsection we introduce and study a number of notions that capture ideas of “moving
around” in a graph from a vertex to a vertex along the edges. This is important for many
applications. For instance, being able to move between two specific vertices a and b along the
edges of the graph might be interpreted as “there is a sequence of hyper links leading from
web page a to web page b”, or “it is possible to get from city a to city b by using only flights of
airline X”, or “there is a sequence of events that will lead from state a to state b of the nuclear
reactor”.
Let G be a graph, u0‚ u1‚ …‚ uk ∈V(G) and e1‚ e2‚ …‚ ek ∈E(G) such that ei = ui−1ui for all
1 ≤i ≤k. Then the sequence
W ∶u0‚ e1‚ u1‚ e2‚ u2‚ …‚ ek‚ uk
is called a walk of length k in G. The vertex u0 is called the initial vertex of the walk and the
vertex uk the terminal vertex. If the edges e1‚ e2‚ …‚ ek in the walk are all distinct, the walk is
called a trail of length k in G, i.e. a trail is a walk in which no edge is repeated. Note, however,
that vertices may still be repeated in a trail.
If the vertices u0‚ u1‚ …‚ uk are all distinct the sequence u0‚ e1‚ u1‚ e2‚ u2‚ …‚ ek‚ uk is called a
path of length k in G. Note that the length of a walk, trail or path is the number of edges it
contains. When writing the sequence representing a walk or path we will usually not include

Graph Theory
363
v4
v5
v3
v2
v1
Figure 7.10: Example 7.1.8
the edges (as this adds no information) but only list the vertices. A path consisting of a single
vertex is called a trivial path. The distance d(u‚ v) between two vertices u and v in a graph is
the length of the shortest path between u and v, if such a path exists.
A walk, trail or path from a vertex v to a vertex u is called a u −v walk, trail or path,
respectively. A u −v walk is called open if u ≠v and closed otherwise. A non-trivial closed
trail is called a circuit. A circuit v1‚ v2‚ …‚ vn‚ v1 whose n vertices v1‚ v2‚ …‚ vn are distinct is
called a cycle. A graph that contains no cycles is called acyclic.
Example 7.1.8
Consider the graph pictured in Figure 7.10.
• W1 ∶v1‚ v2‚ v3‚ v2‚ v5‚ v3‚ v4 is a walk (of length 6) between v1 and v4 but is not a trail, since
the edge v2v3 is repeated. When an edge is repeated in a walk, one or both of the vertices
incident with the edge also get repeated. In W1, when edge v2v3 is repeated vertex v2 is also
repeated. Therefore in general, a walk that fails to be a trail also fails to be a path.
• W2 ∶v1‚ v2‚ v3‚ v5‚ v1‚ v3 is a trail of length 5. It is an open trail, since the initial vertex v1 is
not the same as the terminal vertex v3. Also, W2 is not a path, as the vertices v1 and v3 are
repeated.
• W3 ∶v1‚ v3‚ v4 is a path (of length 2) from v1 to v4. In fact, as you can check, there is no
shorter path from v1 to v4, so d(v1‚ v4) = 2.
• W4 ∶v1‚ v5‚ v2‚ v3‚ v4‚ v2‚ v1 is a closed trail, making it a circuit per definition. It is not a cycle,
however, since the vertex v2 is repeated.
• v1‚ v5‚ v2‚ v1 is a cycle and hence the graph is not acyclic.
Two vertices are said to be connected if there is a path between them. A graph is called
connected if there is a path between every pair of distinct vertices. A maximally connected
subgraph H of a graph G is called a connected component of G. In other words, H is a con-
nected component of G if H ⊆G and H is connected, and if H′ is any connected subgraph of
G such that H ⊆H′, it must be the case that H′ = H.

364
Logic and Discrete Mathematics: A Concise Introduction
Example 7.1.9
Consider the following graph:
The white vertices are all connected and so are the black vertices, but no white vertex is
connected to any black vertex. Therefore, the graph has two connected components, namely
the subgraph induced by the white vertices and the one induced by the black vertices.
The following graph has three connected components:
7.1.2.
Digraphs
The edges in (undirected) graphs have no associated direction, as they are defined as unordered
pairs of vertices. It is often useful in applications to be able to associate a direction with an
edge. For the modelling of situations where the edges have directions we use the concept of a
directed graph (or digraph), which is the topic of this section.
A digraph D consists of a finite nonempty set of objects called vertices together with a
(possibly empty) set of ordered pairs of vertices called arcs or directed edges between different
vertices. A digraph D with vertex set V and arc set E is denoted D(V‚ E). The vertex set of D
will again be denoted by V(D) and the arc set by E(D). Note that it is only possible to have at
most one arc from a vertex u to a vertex v.
Digraphs are graphically represented in much the same way as graphs, with dots repre-
senting the vertices, but with arrows representing arcs, as in Figure 7.11.

Graph Theory
365
If D(V‚ E) is a digraph, then:
• The arc e = (u‚ v) joins vertices u and v; u is the initial vertex of e and v is the terminal vertex.
• The arc e = (u‚ v) is incident from its initial vertex u and incident to its terminal vertex v.
The vertices u and v are also said to be incident on the arc e. Moreover, u is adjacent to v
and v is adjacent from u.
• Two vertices u and v in a digraph are nonadjacent if u is neither adjacent to v nor adjacent
from v.
• The outdegree of a vertex u, denoted out(u), is the number of arcs incident from u (equiv-
alently the number of edges of which u is the initial vertex). Similarly, the indegree of u,
denoted in(u), is the number of edges incident to u (equivalently the number of edges of
which u is the terminal vertex).
• A vertex v such that in(v) = 0 is called a source; a vertex u such that out(u) = 0 is called a
sink.
• The number of vertices in the vertex set V is called the order of the digraph D and denoted
by n(D), or simply by n if the digraph under consideration is clear from the context.
• The number of arcs in the arc set E is called the size of the digraph D and denoted by m(D),
or simply by m if the digraph under consideration is clear from the context.
• An (n‚ m) digraph has order n and size m.
Example 7.1.10
Consider the digraph D in Figure 7.11. Here we have
V(D) = {a‚ b‚ c‚ d‚ e‚ f}
and
E(D) = {(a‚ b)‚ (b‚ c)‚ (c‚ d)‚ (d‚ a)‚ (a‚ c)‚ (c‚ a)‚ (e‚ f)}.
Thus n(D) = 6 and m(D) = 7; (a‚ b) is incident from a to b; b is adjacent to c and c is adja-
cent from b. Looking at the indegrees of the vertices we have in(a) = in(c) = 2, in(b) = in(d) =
in(f) = 1 and in(e) = 0. As for the outdegrees: out(a) = out(c) = 2, out(d) = out(b) = out(e) = 1
and out(f) = 0. Vertex e is a source and f is a sink.
e
f
a
b
d
c
Figure 7.11: A digraph of order 6

366
Logic and Discrete Mathematics: A Concise Introduction
Now we will state and prove the First Theorem of Digraph Theory.
Theorem 7.1.11 If D is a digraph of order n and size m with V(D) = {v1‚ v2‚ …‚ vn} then
n
∑
i=1
in(vi) =
n
∑
i=1
out(vi) = m.
Proof: Straightforward, as every arc contributes with 1 to each of the two sums.
The notion of a subdigraph (or directed subgraph) is just what one would expect. A
digraph D′ is a subdigraph of a digraph D (denoted D′ ⊆D) if V(D′) ⊆V(D) and E(D′) ⊆E(D).
A directed walk in digraph D is a sequence of vertices
W ∶u0‚ u1‚ u2‚ …‚ un
such that (ui−1‚ ui) is an arc of D for i = 1‚ 2‚ …‚ n. A walk in a digraph is just like a walk in
a graph, except that the arcs now have to be followed in the right direction. The notions of
directed trail, directed path, directed circuit and directed cycle are precise analogues of the
corresponding notions for graphs. The length of a directed walk, trail, path, circuit or cycle is,
as one would expect, the number of arcs. Often, when working with digraphs, we will omit
the word “directed” when talking of directed paths, etc.
Example 7.1.12
The digraphs D′ and D′′ in Figures 7.12 and 7.13 are subgraphs of D in Figure 7.11, as you may
check. Further, W ∶a‚ b‚ b‚ c is a directed walk in D′ but not a directed path and W′ ∶a‚ b‚ c is
a directed path (contained in the directed walk W′). Note that D′′ contains an a–a cycle while
D′ does not.
We can transform a digraph into a graph as follows: given a digraph D, replace each arc
(u‚ v) or symmetric pair of arcs (u‚ v) and (v‚ u) by the edge uv. The graph so obtained is called
the underlying graph of D.
We use the concept of an underlying graph to define that of a connected digraph. A
digraph D is said to be connected if its underlying graph is connected. A digraph D is
strongly connected if for every pair of vertices a‚ b ∈V(D) there is a directed path from a to b.
Our definitions of graph and digraph, as already mentioned, do not allow for the possi-
bility of multiple edges or arcs between vertices. If the definition of a graph is altered to allow
multiple edges between vertices the resulting concept is called a multigraph. If we modify
e
f
a
b
c
Figure 7.12: A subdigraph of D (Figure 7.11).

Graph Theory
367
e
f
a
b
c
Figure 7.13: Another subdigraph of D
the definition of a digraph similarly we obtain what is known as a multidigraph or a directed
multigraph. It is sometimes useful to label (or give names to) arcs: this also helps to distin-
guish multiple arcs between the same pair of vertices. Formally a labelled digraph consists of
a set of vertices V, a set of labels L and a set of labelled arcs E ⊆V × L × V.
7.1.3.
Exercises
➊Consider the graph G pictured below:
a
b
c
d
e
f
g
h
i
j
k
l
(a) Determine n(G) and m(G).
(b) For each vertex determine its degree, the vertices adjacent to it and the edges incident
with it. Also state, for each vertex, whether it is even or odd and if it is an isolated vertex
or an end vertex.
(c) Determine 𝛿(G) and Δ(G).
(d) Determine the complete graph of maximum order that forms a subgraph of G.
(e) Is G bipartite? If so, give the two partite sets; if not, explain why not.
(f) Give a path of maximum length in G.
(g) Determine d(a‚ f).
(h) Is G connected?
(i) How many components does G have?

368
Logic and Discrete Mathematics: A Concise Introduction
➋Give an example of a graph such that each vertex is adjacent to four vertices and each edge
is adjacent to six edges.
➌Draw K6 and K4‚ 3.
➍Is there a graph with:
(a) 6 vertices and 6 edges?
(b) 6 vertices and 15 edges?
(c) 6 vertices and 18 edges?
➎Does there exist a graph with five vertices, every vertex incident with at least one edge but
with no two edges being adjacent? Motivate your answer.
➏Must a subgraph of a bipartite graph be bipartite? If yes, motivate, if no, give a counterex-
ample.
➐Must a subgraph of a connected graph be connected? If yes, motivate, if no, give a coun-
terexample.
➑Consider the set of vertices {v1‚ v2‚ …‚ vn}. How many different complete bipartite graphs
may be formed using this vertex set?
➒What is the largest possible number of vertices in a graph with 35 edges, all vertices having
degree at least 3. (Hint: use Theorem 7.1.3.)
➓For the digraph pictured in the figure below, do the following:
a
b
c
d
e
f
g
h
(a) For each vertex write down its indegree as well as its outdegree. Identify any sinks or
sources.
(b) Determine the order and size of the digraph.
(c) Find a path of maximum length in the digraph.
(d) Sketch the underlying graph.
(e) Is the digraph connected?
(f) Is it strongly connected?
(g) Find four different subgraphs.
(h) Find a strongly connected subgraph.
11 In a digraph with n vertices:

Graph Theory
369
(a) What is the maximum indegree of any vertex?
(b) What is the maximum outdegree of any vertex?
(c) What is the maximum number of arcs?
12 Does there exist a digraph with:
(a) Order 5 and size 21? If yes, draw such a digraph, if no, why not?
(b) Three sources, two sinks and size two? If yes, draw such a digraph, if no, why not?
13 Prove Theorem 7.1.11.
14 Give a definition of a directed cycle.
Leonhard Euler (1707–1783)
Leonhard Euler was a Swiss mathematician and physicist who made impor-
tant discoveries in many fields of mathematics, from infinitesimal calculus
to graph theory, which he founded as a branch of mathematics.
Euler was born is Basel in Switzerland. His parents were Paul Euler, a
pastor of the Reformed Church, and Marguerite Brucker, a pastor’s daugh-
ter. Euler’s father intended him to become a pastor like himself, and he
accordingly studied theology and Hebrew at the University of Basel. Paul
was friends with the mathematician Johann Bernoulli (1667–1748), who
gave Euler one private mathematics lesson per week. Bernoulli was able to persuade Paul Euler
that his son was a mathematical genius and that he should be allowed to pursue a career as a
mathematician.
In 1726, after failing to obtain an academic position in Basel, Euler accepted a position at the
Imperial Russian Academy of Sciences in St Petersburg. This position had been arranged with the
help of Johann Bernoulli’s son Daniel who was based at the Academy at that time. Euler quickly
worked his way up through the ranks and was appointed head of the mathematics department
when Daniel Bernoulli resigned in 1733. While in St Petersburg Euler married Katharina Gsell.
They had thirteen children, of whom only five survived infancy. At the Academy Euler was enor-
mously productive: apart from publishing great numbers of mathematical papers and a treatise that
revolutionized mechanics, he also wrote elementary mathematical textbooks for Russian schools,
supervised the geographical department of the government and reformed the Russian weights and
measures.
The political situation in Russia was tense, and in 1741 Euler gladly accepted a position at the
Berlin Academy of Sciences, offered to him by Emperor Frederick the Great of Prussia. Unfortu-
nately Euler was not popular at Frederick’s court, where he was unable to compete with the con-
versational brilliance and wit of philosophers like Voltaire with whom Frederick had surrounded
himself. In 1766 he therefore returned to St Petersburg upon the invitation of Catherine the Great,
who had succeeded to the Russian throne in 1762. He remained in St Petersburg for the rest of
his life.
Euler was probably the most productive mathematician in history – it is estimated that during
certain years he produced an average of one research paper per week. Even during the last years
of his life, while he was completely blind, he continued to work with undiminished vigour. He
made fundamental contributions to analysis, number theory, combinatorics, applied mathematics,
physics and other fields.

370
Logic and Discrete Mathematics: A Concise Introduction
7.2.
Incidence and adjacency matrices
Associated with any graph or digraph there are two matrices, namely the incidence matrix
and the adjacency matrix. These are useful for representing a graph in a form that can be
easily stored in a computer. The matrix representation also lends itself more readily to algo-
rithmic manipulation. We will consider one such algorithm on adjacency matrices, known as
the Warshall algorithm. This algorithm computes the existence of paths in graphs.
Definition 7.2.1 Let G = (V‚ E) be an (n‚ m) graph. Let A be an n × m matrix, the rows of which are
labelled with the vertices of G and the columns of which are labelled with the edges of G. Moreover, the
entry in the ith row and jth column of A, denoted Aij, is 1 if the ith vertex is incident with the jth edge,
and is 0 otherwise. The matrix A is called the incidence matrix of the graph G.
Example 7.2.2
Consider the graph in Figure 7.14. The incidence matrix for this graph is
𝛼
𝛽
𝛾
𝛿
𝜖
𝜁
𝜂
𝜃
a
b
c
d
e
f
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
1
1
0
0
0
1
0
0
0
1
1
0
1
0
0
1
0
0
0
0
0
0
1
1
0
0
1
1
0
1
1
0
1
0
0
1
1
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
.
Notice that in each row of an incidence matrix there are 1s precisely in the columns corre-
sponding to the edges incident with the vertex with which that row is labelled. The degree of
a vertex can then be calculated by summing the entries in its corresponding row. Also notice
that in each column there are precisely two 1s, as each edge is incident with precisely two
vertices.
Definition 7.2.3 Let G = (V‚ E) be an (n‚ m) graph (digraph). Let A be an n × n matrix in which both
the rows and columns are labelled with the vertices of G in the same order. Moreover, the entry in the
ith row and jth column of A, denoted Aij, is 1 if there is an edge (arc) from the vertex labelling row i
to the vertex labelling column j, and 0 otherwise. The matrix A is called the adjacency matrix of the
graph (digraph) G.
e
f
∋
a
b
d
c
Figure 7.14: Incidence and adjacency matrices for this graph are given in Examples 7.2.2 and 7.2.4

Graph Theory
371
Example 7.2.4
The adjacency matrix for the graph in Figure 7.14 is
a
b
c
d
e
f
a
b
c
d
e
f
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
1
0
1
1
0
1
0
1
1
1
0
0
1
0
1
0
0
1
1
1
0
1
0
1
1
0
1
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
.
Example 7.2.5
Here is an example of a digraph with its adjacency matrix:
a
b
c
d
e
f
a
b
c
d
e
f
a
b
c
d
e
f
⎛
⎜
⎜
⎜
⎜
⎜
⎜⎝
0
1
1
0
0
0
0
0
1
0
0
0
1
0
0
1
0
0
1
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟⎠
.
Notice that the adjacency matrix of a graph is symmetric about the main diagonal, which
consists entirely of 0s. The main diagonal of the adjacency matrix of a digraph also consists
entirely of 0s, but the matrix need not be symmetric. Summing all the entries in the adjacency
matrix of a graph, one will get a number equal to twice the size of the graph, and doing so
for the adjacency matrix of a digraph, one will get the size of the digraph.
As we indicated at the beginning of this section, matrix representations of graphs are
amenable to algorithmic manipulation and are quite useful in the computation of graph
parameters. To illustrate this we will now discuss an algorithm, known as the Warshall
algorithm, which computes reachability in (di)graphs. We say that a vertex v of a (di)graph
is reachable from a vertex u if there exists a (directed) walk from u to v. For example, in the

372
Logic and Discrete Mathematics: A Concise Introduction
d
a
b
c
Figure 7.15: In Example 7.2.7 the Warshall algorithm is used to calculate reachability in this digraph
digraph pictured in Figure 7.15 every vertex is reachable from vertex a, while vertex a is only
reachable from itself. Note that every vertex is reachable from itself through a walk of length 0.
Before presenting the Warshall algorithm we need the notion of Boolean addition. Boolean
addition works on 0s and 1s and can be thought of as disjunction, where 0 represents ⊥and 1
represents ⊤Thus, using Boolean addition we have 0 ⊕0 = 0 (analogy: ⊥∨⊥≡⊥), 0 ⊕1 = 1
(analogy: ⊥∨⊤≡⊤∨⊥≡⊤) and 1 ⊕1 = 1 (analogy: ⊤∨⊤≡⊤). We will be adding rows of
the adjacency matrix using Boolean addition.
The Warshall algorithm takes the n × n adjacency matrix A of a graph (digraph) G, and
outputs an n × n matrix A′ such that A′
ij = 1 if the vertex labelling column j is reachable from
the vertex labelling row i, and A′
ij = 0 otherwise. In other words, the output is a matrix where
the entries 1 represent the existence of (directed) walks between vertices. A′ is obtained by
successive transformations of A as follows.
Warshall algorithm
Given an adjacency matrix A, proceed as follows:
1. Change all entries on the diagonal of A to 1s. (Each vertex is reachable from itself, via
a walk of length 0.)
2. Look at column 1 of the matrix obtained in (1). For every row in the matrix where there
is a 1 in that column, add row 1 of the matrix to that row, using Boolean addition.
(Explanation: 1 in column 1 of row i means the vertex labelling row i can reach the
vertex labelling row 1 and, hence, also every vertex reachable from the vertex labelling
row 1.)
3. Then look at column 2 of the matrix obtained in (2). Wherever there is a 1 in a row
of that column, add row 2 of the matrix obtained in (1) to the row in which that 1
occurred, using Boolean addition. (Same explanation: 1 in column 2 of row i means
the vertex labelling row i can reach the vertex labelling row 2, and hence, also every
vertex reachable from the vertex labelling row 2.)
4. Continue this process until all columns have been examined.
Exercise 7.2.6 Prove that the Warshall algorithm is correct.
A more formal pseudo-code specification of the algorithm is given as Algorithm 1. For
working by hand, the informal version of the algorithm proves more convenient. The follow-
ing example demonstrates it in action.

Graph Theory
373
Algorithm 1 Warshall algorithm
for i = 1 to n do
Aii ∶= 1
end for
for i = 1 to n do
for j = 1 to n do
if Aji = 1 then
for k = 1 to n do
Ajk ∶= Ajk ⊕Aik
end for
end if
end for
end for
Example 7.2.7
Consider the digraph in Figure 7.15, and its adjacency matrix A:
a
b
c
d
a
b
c
d
0
1
0
0
0
0
1
0
0
0
0
1
0
1
0
0
First we change all entries on the diagonal to 1s, yielding:
a
b
c
d
a
b
c
d
1
1
0
0
0
1
1
0
0
0
1
1
0
1
0
1
We consider column 1. There is a 1 in the first row of this column, so we must add row 1 to
row 1. This, of course, will not make any change because the addition is Boolean. Bearing
this fact in mind can streamline our computations somewhat.
Now consider column 2. There is a 1 in row 1 of that column, so we add row 2 to row 1
using Boolean addition to obtain the matrix
a
b
c
d
a
b
c
d
1
1
1
0
0
1
1
0
0
0
1
1
0
1
0
1
.

374
Logic and Discrete Mathematics: A Concise Introduction
Row 2 also has a one in column 2, but as before adding row 2 to itself yields the same matrix.
There is another 1 in column 2, namely in the 4th row. Adding row 2 to row 4 we obtain
a
b
c
d
a
b
c
d
1
1
1
0
0
1
1
0
0
0
1
1
0
1
1
1
.
Now consider column 3 of the matrix obtained so far. Every entry in column 3 is one; hence
we have to add row 3 to every row of the matrix. Doing this we obtain the matrix
a
b
c
d
a
b
c
d
1
1
1
1
0
1
1
1
0
0
1
1
0
1
1
1
.
Lastly consider column 4. Once again all the entries in this column are 1s, so we add row 4
to all the rows of the matrix (skipping row 4, as this will make no difference). We obtain
a
b
c
d
a
b
c
d
1
1
1
1
0
1
1
1
0
1
1
1
0
1
1
1
Compare the matrix we have obtained with the graph in Figure 7.15. Notice that all the entries
in column 1, except the first, are 0s, while all the other entries in the matrix are 1s. This
corresponds to the fact that a is reachable only from itself, while every vertex other than
a is reachable from every vertex in the digraph.
7.2.1.
Exercises
➊Determine the incidence and adjacency matrices of the following graphs:
(a) .
a
b
c
d
e
f

Graph Theory
375
(b) .
a
b
c
d
g
h
i
e
f
(c) .
a
b
c
d
e
➋Sketch the following graphs and give incidence and adjacency matrices for each.
(a) G = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f} with edges
e1‚ e2‚ e3‚ …‚ e6 = ab‚ ad‚ bc‚ cd‚ ae‚ ce.
(b) G = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f‚ g} with
edges e1‚ e2‚ e3‚ …‚ e10 = ab‚ ad‚ af‚ bd‚ df‚ cd‚ ce‚ de‚ dg‚ eg.
(c) G = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f} with edges
e1‚ e2‚ e3‚ …‚ e9 = ab‚ ac‚ ae‚ bc‚ bd‚ cf‚ de‚ df‚ ef.
(d) G = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f‚ g‚ i} with edges
e1‚ e2‚ e3‚ …‚ e8 = ab‚ bc‚ bd‚ be‚ cd‚ de‚ df‚ gi.
➌Perform the Warshall algorithm on each of the adjacency matrices obtained in Exercise 2.
➍How would one determine whether the graph is connected from inspecting the matrix
obtained form its adjacency matrix by the Warshall algorithm? For each graph in Exercise
2 determine whether it is connected by inspecting the adjacency matrix obtained for it in
Exercise 3.
➎Sketch the following digraphs and give an adjacency matrix for each.
(a) D = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f} with arcs
e1‚ e2‚ e3‚ …‚ e9 = (a‚ d)‚ (b‚ e)‚ (c‚ a)‚ (c‚ b)‚ (c‚ e)‚ (d‚ b)‚ (d‚ c)‚ (e‚ a)‚ (e‚ d).
(b) D = (V‚ E) with V = {a‚ b‚ c‚ d‚ e} with arcs
e1‚ e2‚ e3‚ …‚ e7 = (a‚ c)‚ (a‚ e)‚ (b‚ a)‚ (c‚ b)‚ (c‚ d)‚ (c‚ e)‚ (d‚ a).
(c) D = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f‚ g‚ h} with arcs
e1‚ e2‚ e3‚ …‚ e6 = (a‚ b)‚ (b‚ f)‚ (f‚ e‚ )‚ (e‚ a)‚ (c‚ d)‚ (d‚ h).
(d) D = (V‚ E) with V = {a‚ b‚ c‚ d‚ e‚ f‚ g‚ h} with arcs
e1‚ e2‚ e3‚ …‚ e9 = (a‚ b)‚ (a‚ d)‚ (b‚ f)‚ (f‚ e‚ )‚ (e‚ a)‚ (c‚ d)‚ (d‚ h)‚ (h‚ g)‚ (g‚ c).

376
Logic and Discrete Mathematics: A Concise Introduction
➏Perform the Warshall algorithm on each of the adjacency matrices obtained in Exercise 5.
➐How would one determine whether a digraph is strongly connected from inspecting the
matrix obtained from its adjacency matrix by the Warshall algorithm? For each digraph in
Exercise 5 determine whether it is strongly connected by inspecting the adjacency matrix
obtained for it in Exercise 6.
➑How would you determine the order and size of a graph from its adjacency matrix?
➒How would you determine the order and size of a digraph from its adjacency matrix?
➓Prove that the Warshall algorithm is correct (Exercise 7.2.6).
11 When capturing an adjacency matrix, especially one for a large graph, it is easy to make mis-
takes. Describe some simple checks you could implement to pick up errors in an adjacency
matrix. How would this differ for graphs and digraphs?
Ramsey theory
Frank P. Ramsey (1903–1930) was a British philosopher, mathematician and economist. In his very
short life – he died at 26 – he made lasting contributions to these fields. He was a friend and trans-
lator of the philosopher Ludwig Wittgenstein and a student and collaborator of the economist John
Maynard Keynes. He founded the field of combinatorics today known as Ramsey theory, the main
gist of which is that in a system large enough, some order must emerge: complete chaos is impos-
sible. Ramsey theory begins with questions like the following:
Is it true that if enough people are gathered in a room there will always be either three
people that are friends or three people among which there are no friends? If so, what is
the least number of people needed to guarantee this?
We can model this situation as a graph, with vertices representing people and edges represent-
ing the friendship relation. The question then becomes: will graphs over a certain order always
contain either K3 as a subgraph or thee mutually nonadjacent vertices? If so, what is the smallest
order for which this is guaranteed? Five vertices is not enough, as the following graph shows:
However, any graph with six vertices will contain K3 or thee mutually nonadjacent vertices.
The proof is an easy exercise.
Denote by R(n) the least integer such that a graph with order R(n) must have Kn as a subgraph
or n mutually nonadjacent vertices. Ramsey’s theorem states that R(n) exists for each n. As we saw
above, R(3) = 6. It is known that R(4) = 18, but for n > 4 exact values of R(n) are not known. Many
years of hard work by mathematicians have produced some bounds, though. For example, it is
known that 43 ≤R(5) ≤49, 102 ≤R(6) ≤165 and 17 885 ≤R(9) ≤9 075 135 299.

Graph Theory
377
7.3.
Weighted graphs and path algorithms
For many applications it is necessary to consider weighted graphs or weighted digraphs.2
These are graphs (or digraphs) in which every edge (or arc) is assigned a number, called its
weight. The weight of an edge can be variously interpreted as its cost, length, capacity, etc.,
depending on the intended application. For example, Figure 7.16 shows a typical example of a
weighted graph. Here the vertices represent different cities in South Africa, the edges represent
roads between the cities, while the weights of the edges represent their length in kilometers.
In general the weight of an edge is intended as the “cost” (in money, time, distance, fuel, etc.)
of traversing that edge. To name but one important application: weighted graphs can be used
by Global Positioning System (GPS) devices as mathematical models of road networks.3
Johannesburg
Heidelberg
Potchefstroom
Bloemfontein – Ladysmith
Pietermaritzburg
Durban
Mthatha
Middelburg
Kimberley
Mdantsane
Port Elizabeth
Knysna
George
Cape Town
Beaufort West
493
436
64
236
425
78
170
548
419
397
359
130
52
305
325
259
294
242
430
461
344
Figure 7.16: A weighted graph representing road links between some South African cities and the associated distances
2 To keep the exposition to a reasonable length we will omit weighed digraphs and consider only weighted
graphs.
3 See, for example, the article: G. Even-Tzur, Graph Theory Applications to GPS Networks, GPS Solutions, 5(1):
31–38, 2001.

378
Logic and Discrete Mathematics: A Concise Introduction
Here is the formal definition of a weighted graph and some other associated terminology.
Definition 7.3.1 A weighted graph is a triple (V‚ E‚ w) such that (V‚ E) is a graph and w ∶E →R∗
is a function assigning a non-negative real number w(uv) to every edge uv ∈E. We call w(uv) the
weight of uv.
The weighted length of a path v0‚ v1‚ …‚ vn in a weighted graph is the sum of the weights of
the edges on the path, i.e. w(v0v1) + w(v1v2) + · · · + w(vn−1vn). The weighted distance between
two vertices u and v, denoted d(u‚ v), is the minimum of the weighted lengths of the paths
between u and v if such paths exist.
For example, in the weighted graph depicted in Figure 7.16, the weighted length of the
path “Johannesburg, Heidelberg, Laydysmith, Bloemfontein”, is 52 + 305 + 419 = 776. How-
ever, the weighted distance between Johannesburg and Bloemfontein is 397.
Given vertices p and q in a weighted digraph, the key problem is to find the shortest path
between p to q. We discuss two algorithms that solve this problem, namely Dijkstra’s algorithm
and the Floyd–Warshall algorithm.
7.3.1.
Dijkstra’s algorithm
We begin with an informal specification of an algorithm for finding the shortest path between
two given vertices in a weighted graph, due to the Dutch computer scientist Edsger Wybe
Dijkstra (1930–2002). The algorithm takes as input a graph G and two specified vertices p and
q. The output is the shortest path between p and q, if such a path exists. It maintains a set of
labels of the form (prevv‚ distv), one for each vertex v ∈V(G). The value of prevv is the name of
the vertex that precedes v in the shortest path from p to v, as calculated so far at the stage of
the computation, and the value of distv is the cost of that path. The algorithm also maintains a
partition of the vertex set into two subsets Perm and Temp. The intention is that Perm contains
those vertices whose labels are permanent and cannot be changed any more, whereas the labels
of vertices in Temp are still subject to possible change.
Algorithm 2 Dijkstra’s algorithm
1. Initially set (prevp‚ distp) = (−‚ 0), and (prevv‚ distv‚ ) = (−‚ ∞) for all vertices v other than
p. Set Perm ∶= {p} and Temp = V −{p}.
2. Repeat the following two steps until q has been moved to Perm or an iteration is reached
in which no vertex is moved to Perm.
(a) Take the last vertex that has been added to Perm, say it is c, and consider all its neigh-
bours (i.e. vertices adjacent to c) in Temp. For each of these neighbours v calculate
the weighted distance from p via c to v, i.e. distc + w(cv), and if distc + w(cv) < distv
update (prevv‚ distv) to become equal to (c‚ distc + w(cv)).
(b) Let v be a vertex in Temp with minimal dist and distv < ∞, if such exists, and transfer
it to Perm, i.e. set Perm ∶= Perm ∪{v} and Temp ∶= Temp −{v}.

Graph Theory
379
Example 7.3.2
Let us apply Dijkstra’s algorithm to the following weighted graph to calculate the shortest
path from p to q:
a
b
q
1
1
2
4
4
p
We track the progress of the solution in the following table, which records the labels of each
vertex after the step has finished, the last vertex transferred to Perm, and also the content of
Perm.
Step
p
a
b
q
Last transfer
Perm
Initial
(−‚ 0)
(−‚ ∞)
(−‚ ∞)
(−‚ ∞)
p
{p}
1
(−‚ 0)
(p‚ 1)
(p‚ 4)
(−‚ ∞)
a
{p‚ a}
2
(−‚ 0)
(p‚ 1)
(a‚ 3)
(a‚ 5)
b
{p‚ a‚ b}
3
(−‚ 0)
(p‚ 1)
(a‚ 3)
(b‚ 4)
q
{p‚ a‚ b‚ q}
When the algorithm terminates the shortest path from p to every vertex can be read off
from the last row of the table. This is done by looking up the desired destination vertex
and then working backwards by reading the prev coordinates. In this example, we begin by
looking at the label of q, namely (b‚ 4): this means that the weighted length of the shortest
path from p to q is 4 and that q is preceded by b in this path. Now look at the label of b: it is
(a‚ 3), so b is preceded by a; looking at the label of a, which is (p‚ 1), we see that a is preceded
by p. Therefore the shortest path from p to q is pabq.

380
Logic and Discrete Mathematics: A Concise Introduction
Here is another example.
Example 7.3.3
We run Dijkstra’s algorithm to the following weighted graph to calculate the shortest path
from p to q:
a
d
b
q
c
1
1
1
1
3
6
4
3
4
2
p
Step
p
a
b
c
d
q
Last transf.
Perm
Init.
(−‚ 0)
(−‚ ∞)
(−‚ ∞)
(−‚ ∞)
(−‚ ∞)
(−‚ ∞)
p
{p}
1
(−‚ 0)
(p‚ 1)
(p‚ 2)
(p‚ 4)
(−‚ ∞)
(−‚ ∞)
a
{p‚ a}
2
(−‚ 0)
(p‚ 1)
(p‚ 2)
(p‚ 4)
(a‚ 2)
(a‚ 7)
d
{p‚ a‚ d}
3
(−‚ 0)
(p‚ 1)
(p‚ 2)
(p‚ 4)
(a‚ 2)
(d‚ 6)
b
{p‚ a‚ d‚ b}
4
(−‚ 0)
(p‚ 1)
(p‚ 2)
(b‚ 3)
(a‚ 2)
(b‚ 5)
c
{p‚ a‚ d‚ b‚ c}
5
(−‚ 0)
(p‚ 1)
(p‚ 2)
(b‚ 3)
(a‚ 2)
(c‚ 4)
q
{p‚ a‚ d‚ b‚ c‚ q}
At termination the labels relevant for the shortest path from p to q are (c‚ 4) (the label of
q) and, working backwards from this label, (b‚ 3) and (p‚ 2). Thus, the shortest path from p to
q is pbcq, which has the weighted length 4. Notice that at the end of step 2, both b and d were
members of Temp with minimal dist, so either of them could have been chosen for transfer to
Perm. We chose to transfer d, but the interested reader could easily compare the computation
that would have resulted from transferring b at this point rather than d.
Theorem 7.3.4 Dijkstra’s algorithm is correct, i.e. given a weighted graph (V‚ E‚ w) and specified
vertices p and q, the algorithm terminates and upon termination, for all v ∈Perm, it holds that distv =
d(p‚ v) and prevv is equal to a vertex preceding v that is some shortest path from p to v.
Proof: We will show that the two properties claimed are in fact invariants of the algorithm.
Before the first iteration of the loop Perm ∶= {p} and (prevp‚ distp) = (−‚ 0), and the conditions
are clearly satisfied. Now suppose that the conditions hold up to some point in the execution of
the algorithm and that now we enter the next iteration of the loop, in which a vertex v is picked
to be transferred from Temp to Perm. Suppose, for the sake of definiteness, that prevv = u. Note
that u ∈Perm, as the algorithm explores the graph only one step far outside the set Perm. We

Graph Theory
381
must show that distv and prevv satisfy the desired properties. It is clear that d(p‚ v) ≤distv. We
need to show that in fact distv = d(p‚ v). Suppose, to the contrary, that d(p‚ v) < distv, i.e. d(p‚ v) <
d(p‚ u) + w(uv). Thus, there exists a different shorter path from p to v. Let u′ be the last vertex
in Perm encountered on this path on the way from p to v and let v′ ∈Temp be the successor
of u′ on this path. Then distv′ = d(p‚ u′) + w(u′v′) < d(p‚ u) + w(uv) = distv. Now there are two
cases. Firstly, if v′ = v, then prevv = prevv′, i.e. prevv′ = u – a contradiction. Secondly, if v′ ≠v,
then it should have been v′ added to Perm and not v′, once again yielding a contradiction. We
conclude that, indeed, distv = d(p‚ v) and that u precedes v on the shortest path from p to v.
7.3.2.
The Floyd–Warshall algorithm
The Floyd–Warshall algorithm is in essence a version of the Warshall algorithm discussed in
Section 7.2. Unlike Dijsktra’s algorithm it does not compute shortest paths from a specified
initial vertex, but computes the weighted distance between every two vertices in a weighted
graph. Informally, the idea behind the Floyd–Warshall algorithm can be described as follows:
suppose we are given a weighted graph G = (V‚ E‚ w) with vertex set V = {v1‚ v2‚ …‚ vn}. We
maintain an n × n matrix of variables dist(i‚ j), 1 ≤i‚ j ≤n, where the value of dist(i‚ j) is an
approximation of d(i‚ j). As the weighted distance from each vertex to itself is 0, we can set
dist(i‚ i) = 0 for each 1 ≤i ≤n. Moreover, if vi and vj are adjacent we can set dist(i‚ j) = w(ij). We
set all other entries in the matrix equal to ∞. At this point the matrix of variables represents
the costs of the paths consisting of 0 or 1 steps between the vertices. Now we incrementally
try to improve on this by checking whether it is not possible to get cheaper paths by going
via vertices in the set {v1}, the set {v1‚ v2}, the set {v1‚ v2‚ v3}, etc. The key idea is the fol-
lowing: suppose I know the cost of the shortest path between every two vertices vi and vj
whose intermediate vertices (i.e. vertices other than the initial vertex vi and terminal vertex
vj) consists only of vertices in {v1‚ v2‚ …‚ vk}. If there were a shorter path with intermedi-
ate vertices contained in {v1‚ v2‚ …‚ vk‚ vk+1} it would necessarily visit vertex vk+1, and would
hence consist of a path from vi to vk+1 followed by a path from vk+1 to vj with their interme-
diate vertices contained in {v1‚ v2‚ …‚ vk}. To see whether such a path exists we need to check
whether dist(i‚ j) > dist(i‚ k + 1) + dist(k + 1‚ j), in which case we update dist(i‚ j) to become equal
to dist(i‚ k + 1) + dist(ik + 1‚ j).
Here is a pseudo code specification of this algorithm:
Algorithm 3 Floyd – Warshall algorithm
The algorithm takes a weighted graph (V‚ E‚ w) with vertex set V = {v1‚ v2‚ …‚ vn} as input. It
maintains an n × n matrix of variables dist(i‚ j), 1 ≤i‚ j ≤n. At each point in the execution of the
algorithm the value of dist(i‚ j) is the approximation of d(i‚ j) at that point. At the termination
of the algorithm dist(i‚ j) = d(i‚ j) for all 1 ≤i‚ j ≤n.
Step 1. The weighted distance between each variable and itself is 0. Set the entries on the
diagonal accordingly:
for i = 1 to n do
dist(i‚ i) ∶= 0
end for

382
Logic and Discrete Mathematics: A Concise Introduction
Algorithm 3 Floyd – Warshall algorithm (continued)
Step 2. Set the weighted distance between any two adjacent nodes to the weight of the
edge between them. All other entries are set to infinity:
for i = 1 to n do
for j = 1 to n do
if there is an edge between vi and vj then
set dist(vi‚ vj) = w(vivj)
else if there no edge between vi and vj and i ≠j
set dist(vi‚ vj) = ∞
end if
end for
end for
Step 3. Now cycle through and look for shorter paths with intermediate vertices contained
in {v1‚ …‚ vk} with k = 1‚ 2‚ …‚ n:
for k = 1 to n do
for i = 1 to n do
for j = 1 do
dist(i‚ j) ∶= min{dist(i‚ j)‚ dist(i‚ k) + dist(k‚ j)}
end for
end for
end for
Let us look at an example.
Example 7.3.5
We run the Floyd–Warshall algorithm on the graph from Example 7.3.2:
a
b
q
1
1
2
4
4
p
Steps 1 and 2 (as specified in the pseudo code description) produce the matrix
p
a
b
q
p
0
1
4
∞
a
1
0
2
4 .
b
4
2
0
1
q
∞
4
1
0

Graph Theory
383
Now consider Step 3. The first iteration of the outer loop (k = 1) checks for
shorter paths via vertex v1 = p, but no such paths can be found. Indeed, 2 = dist(a‚ b) ̸
> dist(a‚ p) + dist(p‚ b) = 1 + 4 = 5;
4 = dist(a‚ q) ̸> dist(a‚ p) + dist(p‚ q) = 1 + ∞= ∞;
1 =
dist(b‚ q) ̸> dist(b‚ p) + dist(p‚ q) = 4 + ∞= ∞. Thus, the matrix remains unchanged.
In the second iteration (k = 2), checking for shorter paths via vertex v2 = a, we find: 4 =
dist(p‚ b) > dist(p‚ a) + dist(a‚ b) = 1 + 2 = 3;
∞= dist(p‚ q) > dist(p‚ a) + dist(a‚ q) = 1 + 4 = 5;
4 = dist(b‚ p) > dist(b‚ a) + dist(a‚ p) = 2 + 1 = 3; ∞= dist(q‚ p) > dist(q‚ a) + dist(a‚ p) = 4 + 1 =
5. This yields the following update matrix:
p
a
b
q
p
0
1
3
5
a
1
0
2
4 .
b
3
2
0
1
q
5
4
1
0
In the second iteration (k = 3), checking for shorter paths via vertex v3 = b, we find:
5 = dist(p‚ q) > dist(p‚ b) + dist(b‚ q) = 3 + 1 = 4,
4 = dist(a‚ q) > dist(a‚ b) + dist(b‚ q) = 2 + 1 =
3, and symmetrically for dist(q‚ p) and dist(q‚ a). Applying the corresponding updates gives
the matrix
p
a
b
q
p
0
1
3
4
a
1
0
2
3 .
b
3
2
0
1
q
4
3
1
0
In the last iteration (k = 4) no shorter paths can be found via v4 = q, so the matrix of
variables remains as it was at the end of the previous iteration.
By comparing the matrix with the graph, it is easy to check that we have indeed found
the weighted lengths of the shortest paths between every two vertices.
7.3.3.
Exercises
➊
Apply Dijkstra’a algorithm as well as the Floyd–Warshall algorithm to the following
graphs:
(a) .
a
d
e
b
c
g
q
f
1
1
2
2
2
3
7
4
1
2
3
4
p

384
Logic and Discrete Mathematics: A Concise Introduction
(b) .
a
d
c
q
1
1
2
2
2
4
4
p
(c) .
a
d
b
f
c
q
6
1
1
2
3
22
17
10
4
15
14
7
p
➋
Apply the Floyd–Warshall algorithm to the graph from Example 7.3.3.
4
6
3
3
1
2
1
1
1
4
p
c
q
a
d
b
➌
Prove that the Floyd–Warshall algorithm is correct. The informal discussion of the algo-
rithm above contains the key ideas needed for this proof.
➍
How would Dijkstra’s algorithm have to be adapted to make it applicable to digraphs?
➎
How would the Floyd–Warshall algorithm have to be adapted to make it applicable to
digraphs?
➏∗.(a) Describe how the Floyd–Warshall algorithm could be optimized by exploiting the sym-
metry in the matrix of variables it maintains.
(b) Would a similar optimization apply to a version of the Floyd–Warshall algorithm for
digraphs?
➐∗Analyse the runtime complexity of Dijskra’s algorithm.
➑∗Analyse the runtime complexity of Dijskra’s algorithm.

Graph Theory
385
Edsger Wybe Dijkstra (1930–2002)
Dijkstra was a Dutch computer scientist. He was born in Rotterdam, the
son of a chemist father and mathematician mother. After studying the-
oretical physics at the University of Leiden, he held a job as a program-
mer at the Mathematisch Centrum in Amsterdam. As a means of giving
public demonstration of Centrum’s newly built computer, Dijkstra pro-
posed programming it to find the shortest route between Dutch cities,
and it was for this purpose that he developed his now famous shortest
path algorithm. He was a member of the team who developed the pro-
gramming language ALGOL-60, starting in 1958. In 1959 he obtained
a PhD from the University of Amsterdam for a Thesis entitled Commu-
nication with an Automatic Computer. In 1962 he was appointed as Pro-
fessor of Mathematics at Eindhoven University of Technology. While in
Eindhoven he developed the “THE” operating system, which was very
influential for later operating systems. In 1984 he was appointed to the
Schlumberger Centennial Chair in Computer Sciences at the University of Texas at Austin, where
he remained until his retirement in 1999. Dijkstra wrote extensively on computer programming,
which he regarded as an activity of the highest intellectual order. His opinions in this regard have
been highly influential. He was also a pioneer in the field of distributed computing.
7.4.
Trees
Graphs that do not contain cycles are very “well behaved” in many respects and are known
as trees. Trees are ubiquitous in the mathematical sciences and in applications. They are used
to organize information in hierarchical fashion and as such form one of the fundamental data
types in computer science. In this section we will first study undirected trees and then move
on to directed trees and their traversal.
7.4.1.
Undirected trees
Definition 7.4.1 An acyclic graph is called a forest. A connected forest is a tree. In a tree, a vertex
with degree 1 is called a leaf while a vertex with a higher degree is an internal vertex.

386
Logic and Discrete Mathematics: A Concise Introduction
Example 7.4.2
The graph above is a forest, as it contains no cycles. Note that it has two connected com-
ponents, which are trees. Indeed, a connected component of a forest, seen as a graph on its
own, is always a tree, as it satisfies the definition by being connected and acyclic. The com-
ponent on the left has 6 leaves and 3 internal vertices, while the component on the right has
4 leaves and 3 internal vertices.
We now explore some of the basic properties of tree in the following lemmas and theorems.
This exploration will culminate in Theorem 7.4.10, which gives a very simple and precise rela-
tionship between the order and size of any tree.
Lemma 7.4.3 Let G be a tree with at least two vertices. Then G has at least two leaves.
Proof: Let P be a path of maximal length in G, say a path from a vertex u to a vertex v. Since
G has at least two vertices and is connected, such a (nontrivial) path exists. Firstly, note that
u cannot be adjacent to any vertex not on the path P, since that would mean that P could be
extended to a longer path, contradicting the maximality of P. Similarly, v cannot be adjacent
to any vertex not on P. Secondly, u cannot be adjacent to any vertex on P other than the one
immediately following it on P, since this would imply the existence of a cycle in G. Similarly
v cannot be adjacent to any vertex on P other than the one immediately preceding it. Putting
this together, we conclude that u and v both have degree 1.
Theorem 7.4.4 A graph G is a tree if and only if there exists a unique u–v path in G for any two
vertices u‚ v ∈V(G).
Proof: Suppose that there is a unique u–v path between every two vertices u‚ v ∈V(G). Then G
is connected. Also, if G were to contain a cycle, then between every two distinct vertices, u and
v, on the cycle there would be two distinct paths, contradicting the hypothesis. We therefore
conclude that G must be a tree.
Conversely, suppose that G is a tree. Since G is connected there is at least one path between
every two vertices u‚ v ∈V(G). If there were two distinct paths between some vertex u and
another vertex v, there would exist a cycle in G consisting of vertices from these paths, contra-
dicting the assumption that G is a tree.
The next theorem provides a precise relationship between the size (number of edges) m(T)
and the order (number of vertices) m(T) of a tree.

Graph Theory
387
Theorem 7.4.5 For every tree T it is the case that n(T) = m(T) + 1.
Proof: Consider any tree T. We proceed by induction on the order n(T). If n(T) = 1, then it must
be the case that m(T) = 0, and hence we have n(T) = 1 = 0 + 1 = m(T) + 1, as desired. Now,
assume that n(T′) = m(T′) + 1 holds for all trees T′ with n(T′) ≤k, and suppose that n(T) =
k + 1. We know from Lemma 7.4.3 that T has at least two leaves. Let v be a leaf of T and T −v
the tree obtained from T by removing v and the edge incident with it. Then m(T −v) = m(T) −1
and n(T −v) = k, and so T −v falls under the inductive hypothesis. Applying the inductive
hypothesis to T −v we get k = n(T −v) = m(T −v) + 1, and hence n(T) = k + 1 = m(T −v) + 1 +
1 = m(T) + 1.
Definition 7.4.6 A tree T is called a spanning tree of a graph G if T is a subgraph of G containing
every vertex of G.
Example 7.4.7
G
T1
T2
A graph G is depicted above together with two of its spanning trees T1 and T2.
Theorem 7.4.8 Every connected graph has a spanning tree.
Proof: If G is acyclic it is itself a tree, and we are done. Suppose that G contains at least one
cycle C. If uv is an edge of C then we may delete it and in the resulting graph G′ there will still
be a path from u to v.
Now let a and b be any vertices of G. Since G is connected there is an a–b path in G. We claim
that there is still an a–b path in G′: if the edge uv occurs on the a–b path in G, we may replace
it by the u–v path in G′, obtaining an a–b path in G′. Hence G′ is connected. If G′ still contains
a cycle we may repeat this procedure to delete another edge. We continue in this fashion until
we obtain an acyclic connected subgraph T of G. As we never delete vertices this subgraph
contains all the vertices of G and is the desired spanning tree.
Putting Theorems 7.4.5 and 7.4.8 together we obtain the following corollary.
Corollary 7.4.9 Every connected graph of order n has at least n −1 edges.
Theorem 7.4.10 Let G be a connected (n‚ m) graph. Then G is a tree if, and only if, n = m + 1.
Proof: Let G be a connected (n‚ m) graph. If G is a tree then, by Theorem 7.4.5, n = m + 1. Con-
versely, suppose that n = m + 1. We need to show that G is a tree. By Corollary 7.4.9 G has

388
Logic and Discrete Mathematics: A Concise Introduction
the least number of edges it can have as a connected graph. Hence G cannot contain a cycle,
for if it did we would be able to remove a cycle edge and still keep the graph connected – a
contradiction. Hence, G is a tree.
7.4.2.
Computing spanning trees: Kruskal’s algorithm
Theorem 7.4.8 tells us that every connected graph has a spanning tree. The proof also gives
a method for constructing a spanning tree for any given connected graph, which works by
repeatedly breaking cycles by removing edges. Another method, known as Kruskal’s algo-
rithm, works by rather choosing which edges to keep. In fact, Kruskal’s algorithm also works
on weighted graphs and computes a spanning tree of minimum weight of any given connected
weighted graph. The weight of the spanning tree is the sum of the weights of its edges. Here
is a pseudocode specification of the algorithm. Recall that if G is a graph and X ⊆E(G), then
⟨X⟩G denotes the subgraph of G edge-induced by X.
Algorithm 4 Kruskal’s algorithm
Input. A connected weighted graph G = (V‚ E‚ w)
Set S = E and X = ∅.
while ⟨X⟩G does not contain every vertex in V do
Let e be an edge in S of minimum weight
if ⟨X ∪{e}⟩G is acyclic then
Set S ∶= S −{e}
X ∶= X ∪{e}
else if ⟨X ∪{e}⟩G contains a cycle
Set S ∶= S −{e}
end if
end while
return ⟨X⟩G

Graph Theory
389
For the proof of the correctness of the algorithm, see Exercise 13.
Example 7.4.11
Let us run Kruskal’s algorithm on the following weighted graph:
4
6
3
3
2
1
1
1
1
4
p
c
q
a
d
b
Note that the algorithm involves some nondeterminism: at each step an edge in S of
minimal weight is chosen and if there is more than one such edge the choice between them
is made randomly. As a result there may be more than one correct execution and more than
one spanning tree of minimal weight.
Stepe S
X
V(⟨X⟩G) = V(G)?
0
- {ab‚ ad‚ ap‚ aq‚ bc‚ bp‚ bq‚ cp‚ cq‚ dq}∅
NO
1
ad{ab‚ ap‚ aq‚ bc‚ bp‚ bq‚ cp‚ cq‚ dq}
{ad}
NO
2
ap{ab‚ aq‚ bc‚ bp‚ bq‚ cp‚ cq‚ dq}
{ad‚ ap}
NO
3
bc {ab‚ aq‚ bp‚ bq‚ cp‚ cq‚ dq}
{ad‚ ap‚ bc}
NO
4
cq {ab‚ aq‚ bp‚ bq‚ cp‚ dq}
{ad‚ ap‚ bc‚ cq}
NO
5
bp{ab‚ aq‚ bq‚ cp‚ dq}
{ad‚ ap‚ bc‚ cq‚ bp}YES
Here is the resulting spanning tree:
2
1
1
1
1
p
c
q
a
d
b
To run Kruskal’s algorithm on unweighted graphs, one can simply assign weight 1 (or any
other constant weight) to every edge in the graph and then run the algorithm.

390
Logic and Discrete Mathematics: A Concise Introduction
7.4.3.
Rooted trees
It is sometimes necessary to distinguish a vertex of a tree and call it the root of the tree. The
root is usually drawn at the top: it is as if the tree has been picked up by the root and is now
dangling from it. Once a root has been determined for a tree it is called a rooted tree. One can
further transform a rooted tree T into a directed tree called a rooted directed tree T′ derived
from T. Directions are assigned to the edges in the direction of the unique path leading from
the root to every other vertex in T, as illustrated in Example 7.4.12.
Example 7.4.12
Consider the following tree:
f
d
b
e
g
k
c
a
r
h
i
j
Let us distinguish r as the root of the tree. Redrawing the tree such that it is “dangling”
from its root and orienting the edges into arcs yield the following rooted tree and derived
rooted directed tree, respectively:
r
b
e
h
k
g
d
a
c
f
i
j
r
b
e
h
k
g
d
a
c
f
i
j

Graph Theory
391
Example 7.4.13
We have encountered trees before in this book: the formula construction and parsing trees
and the semantic tableaux of Chapters 3 and 4 are rooted trees.
Rooted trees are also the structures of choice for representing all kinds of hierarchical
information. They are used, for example, in concept hierarchies like the taxonomic classifi-
cation of animals, as in this subtree of the classification of the vertebrates:
Vertebrata
fish
mammalia
amphibia
reptilia
birds
live bearing
monotremes
proboscidae
carnivora
primates
platypus
elephant
felidae
hominidae
lion
homo
sapiens
Given a rooted tree T with root r, the level of a vertex v in the tree is the length of the path
from r to v. Thus, the root is on level 0. The height of T is the length of the longest path from
the root r to a leaf or, equivalently, the maximum level among the vertex.
In a rooted tree, a vertex v is called an ancestor of a vertex u if v precedes u on the path from
the root to u. In this case u is called a descendant of v. If v is the ancestor of u that immediately
precedes it on the path from the root to u, then v is the parent of u and u is the child of v. The
children of the same parent vertex are siblings.
If the greatest number of children of any given vertex in a rooted tree T is m, then T is
called an m-ary tree. In the case that m = 2 we speak of a binary tree. In a binary tree we may
designate each child of a parent vertex as either the left child or the right child, but not as both.
Example 7.4.14
Consider the rooted tree given in Example 7.4.12. It is rooted at vertex r and has height 4. It
is a 3-ary tree as no vertex has more than 3 children. Vertices g and h occur on level 3 and are
siblings as they are both children of vertex e. The vertex e is an ancestor of vertices g‚ h‚ i‚ j
and k, which are its descendants.

392
Logic and Discrete Mathematics: A Concise Introduction
7.4.4.
Traversing rooted trees
In many applications it is often necessary to visit every vertex in a rooted tree in some sys-
tematic way, e.g. if every member of a family must be read off a family tree or if every concept
needs to be retrieved from a concept hierarchy. Systematically visiting each vertex in this way
is know as traversing the tree. There are two general ways of traversing a rooted tree, known
as depth first and breadth first traversal. We will outline these traversal protocols for binary
trees and will then indicate how they can be generalized to arbitrary rooted trees.
Breadth first traversal
In breadth first traversal the vertices are visited level by level in some predefined order on the
vertices on a given level, say from left to right, given the way the tree is drawn. For example,
the breadth first traversal of the rooted tree
r
b
e
h
k
g
d
a
c
f
i
will visit the vertices in the order
r‚ a‚ b‚ c‚ d‚ e‚ f‚ g‚ h‚ i‚ j‚ k.
Depth first traversal
Depth first traversal explores completely a subtree before moving on to the next subtree. It
starts at the root and visits all vertices (again, depth first) in the subtree rooted at the left child
of the root before doing the same with the subtree rooted at the right child. The depth first
traversal is done in pre-order, in-order or post-order, depending on whether the root of the
(sub)tree is visited respectively before, in between or after the vertices in the subtrees rooted
at the left child and right child are visited. For example, the pre-order depth first traversal of
the tree above visits the vertices in the order
r‚ a‚ c‚ f‚ d‚ b‚ e‚ g‚ i‚ k‚ h.
The in-order depth first traversal of the same tree is
f‚ c‚ a‚ d‚ r‚ b‚ i‚ g‚ k‚ e‚ h.
The post-order depth first traversal of the same tree is
f‚ c‚ d‚ a‚ i‚ k‚ g‚ h‚ e‚ b‚ r.

Graph Theory
393
Exercises 2, 4, 13 and 14 below are intended for the computer science track only.
7.4.5.
Exercises
➊
Consider the following graphs. For each graph:
(i) determine whether it is a tree;
(ii) if it is a tree, use vertex c as the root and draw the rooted tree and the derived rooted
directed tree;
(iii) determine the height of the resulting rooted tree;
(iv) determine the level of vertex e in the resulting rooted tree.
(a) .
j
b
e
h
k
g
d
a
c
l
m
f
i
(b) .
j
b
e
q
s
t h
n
r
k
g
d
a
c
l
m
f
i
(c) .
b
e
d
a
c
(d) .
b
h
f
g
e
d
a
c
j
i
➋
Consider the following rooted trees. For each tree give the order in which the nodes are
visited if the tree is traversed:

394
Logic and Discrete Mathematics: A Concise Introduction
(i) breadth first;
(ii) depth first, pre-order;
(iii) depth first, in-order;
(iv) depth first, post-order.
(a) .
b
h
f
l
k
g
e
d
a
c
j
i
(b) .
b
h
f
l
k
m
n
o
g
e
d
a
c
j
i
➌
For each graph in Exercise 1 that is not itself a tree, determine a spanning tree. Do this
either by inspection or by applying Kruskal’s algorithm.
➍
Run Kruskal’s algorithm on the weighted graphs in Exercise 1 in Section 7.3.3 to compute
spanning trees of minimum weight.
➎
Let T be a tree such that the sum of the degrees of the vertices in T is 22. How many vertices
does T have?
➏
Let T be a tree with 13 vertices. What is the sum of the degrees of all the vertices?
➐
Draw a family tree, starting with yourself as the root and ending with your great grand-
parents as leaves.
➑∗
Prove that every tree with at least two vertices is a bipartite graph.
➒
Show that the assumption in Theorem 7.4.10 that G is connected is essential, i.e. show
that the theorem does not hold for graphs that are not connected. (Hint: find a suitable
counterexample.)
➓
For which values of i ∈ℕwill the complete graph Ki be a tree? Prove your answer.
11
For which values of i‚ j ∈ℕwill the complete bipartite graph Ki‚ j be a tree? Prove your
answer.
12∗
Prove that if F is an (n‚ m) forest with k connected components then m = n −k. (Note that
the formula given in Theorem 7.4.5 is a special case of this formula.)
13∗
Prove that Kruskal’s algorithm returns a spanning tree. This proof can be broken down
into two parts: firstly, prove that the graph returned by the algorithm is indeed a tree and,
secondly, prove that it contains every vertex of the input graph. Proving that the returned
tree is indeed one of minimal weight is more challenging and is deferred to Exercise 14
14** Prove that the spanning tree returned by Kruskal’s algorithm is one of minimum weight
among the spanning trees of the input graph.

Graph Theory
395
Paul Erd˝os (1913–1996)
Paul Erd˝os was one of the most prolific mathematicians of all time,
comparable in his productivity only to Euler (see page Section 7.1).
He had wide mathematical interests, mainly within discrete math-
ematics, where he made contributions to number theory, combina-
torics, graph theory, probability theory and set theory. Erd˝os was
born in Budapest in Hungary, the son of two mathematics teachers.
He became fascinated with mathematics by the age of four, started
publishing mathematical papers in his teens and was awarded a doc-
torate by the University Pázmány Péter in Budapest in 1934 at the
age of 21. In the same year he moved to Manchester to take up a
postdoctoral research position. The anti-Semitic climate in Hungary
at the time made it very difiicult for him to return there and he sub-
sequently took up a temporary position at Princeton. This was the
start of his life as a wanderer: he never held a permanent academic
position. Not that there was a shortage of offers, but he preferred
to travel from one mathematics meeting to the next, staying in the
homes of colleagues and collaborators. It is said that he would often
arrive unannounced at the door of a colleague, stay for a few weeks during which they would
collaborate on some mathematics, and then depart again. All his belongings could fit into a suit-
case. Erd˝os published over 1500 papers in his life (for comparison, 50 to 100 is considered a very
good achievement for the average mathematician), with over 500 collaborators. This has led to
the notion of the Erd˝os number: Erd˝os himself has Erd˝os number 0; anyone who has published
a paper with him has Erd˝os number 1; those who do not have Erd˝os number 1 but have published a
paper with someone with Erd˝os number 1 have number 2, etc. It has been estimated that 90% of the
worlds’ mathematicians have an Erd˝os number smaller than 8. Erd˝os died of a heart attack while
attending a conference in Warsaw.
7.5.
Eulerian graphs and Hamiltonian graphs
A well-known puzzle asks you to draw the following picture of a house without lifting you
pen and without going over the same line more than once:
This is actually an instance of a graph-theoretic problem that has received a lot of serious
mathematical study, namely the problem of determining whether a given graph has a trail
(i.e. a walk without repeating edges) that uses every edge. This problem and the problem of
determining whether a graph has a cycle visiting every vertex are the topics of the current
section.

396
Logic and Discrete Mathematics: A Concise Introduction
Figure 7.17: The bridges of Königsberg
7.5.1.
Eulerian graphs and digraphs
In the 18th century the townsfolk of Königsberg amused themselves by trying to devise a
route through the town that would cross every one of the seven bridges over the Pregel river
precisely once. A map showing the river and the bridges is given in Figure 7.17. Try as they
might, no one was able to come up with such a route and many started to suspect that it fact
no such route existed. This story came to the ears of the Swiss mathematician Leonhard Euler,
who subsequently proved that no such route can exist.
This episode is widely regarded as the beginning of graph theory. Indeed, we can model
the Königsberg bridges as a multigraph. A multigraph is a graph in which we allow multiple
edges between vertices. With vertices a and b representing the islands and vertices c and d
representing the banks, the problem becomes equivalent to asking whether there exists a trail
through the following multigraph, which contains every edge (exactly once):
A
B
C
D
We will not treat multigraphs further, but will rather restrict ourselves to exploring this
type of problem on graph. Here are the key definitions.
Definition 7.5.1 An Eulerian trial of a graph G is an open trial of G containing all the edges and
vertices of G. An Eulerian circuit of G is a circuit containing all the edges and vertices of G. A graph
that has an Eulerian circuit is called an Eulerian graph.

Graph Theory
397
Note that an Eulerian graph must be nontrivial and connected.
Example 7.5.2
b
b
h
f
g
e
e
d
d
a
a
c
c
The graph on the left has an Eulerian trail, namely e‚ b‚ d‚ c‚ b‚ a‚ d‚ e‚ a, but no Eulerian
circuit.
The graph on the right is Eulerian, as a‚ b‚ c‚ e‚ h‚ g‚ f‚ d‚ g‚ e‚ d‚ c‚ a is an Eulerian circuit.
As it turns out, it is quite easy to determine whether a graph is Eulerian or not, thanks to
the following theorem:
Theorem 7.5.3 Let G be a nontrivial connected graph. Then G is Eulerian if and only if every vertex
of G is even.
Proof: Suppose that G has an Eulerian circuit C. Let v be any vertex of G. If v is not the initial
vertex of C, then every time v is encountered on C it enters and leaves via two different edges.
Therefore, each occurrence of v represents a contribution of 2 to its degree, and as all the edges
incident with it occur in C, it must have an even degree. If, on the other hand, v is the initial
vertex of C, the first and last occurrences represent a contribution of 1 each to its degree, while
all other occurrences represent a contribution of 2. Hence, also in this case, v must have even
degree.
To prove the converse we assume that every vertex of G is even and proceed by induction
on the size m of G. The smallest m for which this is possible is 3. The only such graph is K3,
which it obviously Eulerian. Now assume that m ≥4 and that the claim holds for all graphs of
size less that m. Let G be a connected graph of size m such that the degree of each of its vertices
is even.
Let u be any vertex of G and let W be a u–u circuit. To see that such a circuit W exists we
argue as follows. Let W′ be a trail starting at u of maximal length, say a u–v trail. If u ≠v, i.e.
W′ is open, then an odd number of edges of G incident with u are present in W′. However,
we know that u has an even degree and so W′ can be extended to a trail W′′ containing more
edges of G. This is in contradiction with the maximality of W′. Hence the assumption that W′
is open must be incorrect and W′ is the desired u–u circuit W.
If W is an Eulerian circuit for G we are done; otherwise there are edges in G not present in
W. We obtain the subgraph G′ from G by removing from G all the edges present in W. Since
each vertex of W is incident with an even number of edges of W, every vertex in G′ has an
even degree. Hence every component of G′ is a connected graph of which all the vertices have
an even degree and with a size smaller than m, which is then Eulerian by hypothesis. Since G
is connected, every component of G′ has a vertex that also belongs to W. Hence an Eulerian

398
Logic and Discrete Mathematics: A Concise Introduction
circuit for G may be constructed by inserting an Eulerian circuit of each component H of G′
into W at a vertex of H belonging to W.
Theorem 7.5.4 Let G be a nontrivial connected graph. Then G contains an Eulerian trail if and only
if G has exactly two vertices of odd degree. Furthermore, the Eulerian trail begins at one of these odd
vertices and ends at the other.
Proof: See Exercise 11.
The next definition extends the notions of Eulerian trail, Eulerian circuit and Eulerian
graph to digraphs.
Definition 7.5.5 Let D be a digraph. A directed Eulerian trail of D is a directed open trail containing
all the vertices and arcs of D. A directed Eulerian circuit of D is a directed circuit containing all the
vertices and arcs of D. A digraph that contains a directed Eulerian circuit is called an Eulerian digraph.
The proof of the following theorem is left as Exercise 12.
Theorem 7.5.6 Let D be a nontrivial connected digraph. Then D is Eulerian if and only if the indegree
of every vertex is equal to its outdegree.
Example 7.5.7
Consider the following digraph:
b
d
a
c
Since the indegree of every vertex is equal to its outdegree, this digraph should be Eule-
rian according to Theorem 7.5.6. Indeed, a‚ b‚ c‚ a‚ c‚ d‚ a is a directed Eulerian circuit.
7.5.2.
Hamiltonian graphs and digraphs
So far we have considered trails and circuits that traversed every edge in a graph exactly once.
A naturally related question is to ask for a path or cycle that visits every vertex of a graph
exactly once. A graph that contains such a cycle is known as a Hamiltonian graph, after Sir
William Rowan Hamilton, who was one of the first to study this type of problem. In fact, he
invented a game consisting of a solid wooden dodecahedron with a peg at each corner and
a piece of string. The object of the game was to wind the string so that it would form a cycle
through the pegs passing along the edges of the dodecahedron. The dodecahedron can, like
other Platonic solids, be represented as a graph. Here is such a representation, with a cycle
visiting each vertex exactly once, indicated in bold:

Graph Theory
399
The formal definition of a Hamiltonian graph is as follows.
Definition 7.5.8 Let G be a graph. A path containing every vertex of G is called a Hamiltonian path
in G. A cycle in G containing every vertex of G is called a Hamiltonian cycle in G. A graph having
a Hamiltonian cycle is called a Hamiltonian graph.
Thus, the graph of the dodecahedron is Hamiltonian.
Example 7.5.9
Some examples and nonexamples of Hamiltonian graphs:
• Every complete graph of order 3 or greater is Hamiltonian.
• The Petersen graph has a Hamiltonian path, but no Hamiltonian cycle.
• K3‚ 3 is Hamiltonian.
• K3‚ 2 has a Hamiltonian path, but no Hamiltonian cycle.
• K1‚ 3 has neither a Hamiltonian path nor a Hamiltonian cycle.
After the neat characterization of Eulerian graphs (Theorem 7.5.3) in the previous sub-
section, one might expect something similar for Hamiltonian graphs. Alas, no such simple
necessary and sufficient condition for a graph being Hamiltonian is known. Several sufficient
conditions are known, the most famous of which is perhaps Ore’s theorem.
Theorem 7.5.10 Ore’s theorem Let G be an (n‚ m) graph with n ≥3. If
deg u + deg v ≥n‚
for all distinct nonadjacent vertices u and v of G, then G is Hamiltonian.
Proof: The proof is by contradiction. Suppose that G is an (n‚ m) graph with n ≥3 and that
deg u + deg v ≥n for all distinct nonadjacent vertices u and v of G, but that G is not Hamilto-
nian. Since any complete graph on n ≥3 vertices is Hamiltonian, we could make G Hamilto-
nian by adding enough edges to it. Let G′ be a maximal non-Hamiltonian graph obtained from

400
Logic and Discrete Mathematics: A Concise Introduction
G by adding edges, i.e. adding any edge to G′ would turn it into a Hamiltonian graph. Clearly,
for any two nonadjacent vertices u and v of G′ we have that deg G′u + deg G′v ≥deg Gu +
deg Gv ≥n.
Let u and v be any two nonadjacent vertices of G′. From the discussion above G′ + uv (the
graph obtained from G′ by adding edge uv) would be Hamiltonian, i.e. it contains a Hamil-
tonian cycle u = u1‚ u2‚ …‚ un = v‚ u. Now, for every vertex ui, 2 ≤i ≤n, if u is adjacent to ui
then it cannot be the case that ui−1 is adjacent to v, or else u1‚ …‚ ui−1‚ un‚ …‚ ui‚ u1 would be a
Hamiltonian cycle of G′:
u1
ui−1
un−1
υ
υ
un
ui
u2
This means that for every vertex in {u1‚ …‚ un} to which u is adjacent, there is a vertex to
which v is not adjacent. Therefore we have that
deg G′v ≤(n −1) −deg G′u‚
i.e.
deg G′v + deg G′u ≤(n −1)‚
which is a contradiction.
The problem of finding a Hamiltonian cycle in a graph is closely related to the travelling
salesman problem: a salesman needs to visit a number of cities and return to the city he started
from. To save costs he would like to avoid visiting the same city more than once. The travelling
salesman problem is known to be NP-complete, which means that it is very unlikely that an
efficient sequential algorithm (working in the number of steps bounded by a polynomial on
the order of the graph) can exist. It is also related to a variety of scheduling problems and has
been very intensively studied by mathematicians and computer scientists.
7.5.3.
Exercises
➊
For each of the following graphs, determine whether it is Eulerian (and if so, find an Eule-
rian circuit) and whether it contains an Eulerian trail (and if so, find such a trail).
(a) .
(b) .

Graph Theory
401
(c) .
(d) .
(e) .
(f) .
➋
For each digraph below, determine whether it is Eulerian (and if so, find an Eulerian
directed circuit) and whether it contains a directed Eulerian trail (and if so, find such a
trail).
(a) .
a
b
c
d
(b) .
a
b
c

402
Logic and Discrete Mathematics: A Concise Introduction
(c) .
a
b
c
(d) .
a
b
c
d
e
f
g
h
➌
Below are graph representations of the five Platonic solids. The Platonic solids are the
five geometric solids whose faces are identical regular polygons that meet at the same
three-dimensional angles. They are known, respectively, as the tetrahedron, octahedron,
cube (or hexahedron), dodecahedron and icosahedron, and their representations as graphs
are given in the order below. For each of these, determine whether it is Eulerian (and if so,
find an Eulerian circuit) and whether it contains an Eulerian trail (and if so, find such a
trail).
➍
For each graph in Exercise 1 determine whether it is Hamiltonian (in which case give a
Hamiltonian cycle) and whether it has a Hamiltonian path (in which case give a Hamilto-
nian path).

Graph Theory
403
➎
Repeat Exercise 4 for the graphs of the Platonic solids given in Exercise 3.
➏
Let G be a graph with two connected components, each of which has an Eulerian trail.
Show that there is an Eulerian graph G′ that can be obtained by adding two edges to G.
➐
Show that the converse of Ore’s theorem does not hold, by giving an example of a Hamil-
tonian graph that does not satisfy the condition of the theorem.
➑
Characterize the Hamiltonian complete bipartite graphs, i.e. determine for exactly which
values of j and k the complete bipartite graph Kj‚ k will be a Hamiltonian graph. Prove that
your answer is correct.
➒∗Prove that if a graph G is Eulerian, then there exists an Eulerian circuit of G starting and
ending at v, for every vertex v ∈V(G).
➓∗What is the relationship between Eulerian and Hamiltonian graphs? Is every Hamiltonian
graph Eulerian? Is every Eulerian graph Hamiltonian? Justify your answers.
11∗Prove Theorem 7.5.4. The proof is similar to that of Theorem 7.5.3, but with the initial and
terminal vertices of the trail being different and odd.
12∗Prove Theorem 7.5.6.
13∗State and prove an analogue of Theorem 7.5.4 for directed graphs.
Sir William Rowan Hamilton (1805–1865)
William Rowan Hamilton was an Irish physicist, astronomer and
mathematician, who made important contributions to classical
mechanics, optics and algebra.
William Hamilton was born in Dublin, the youngest of three chil-
dren. From a very young age it was clear that he possessed extraor-
dinary intellectual gifts. At the age of three he was sent to live with
and be educated by his uncle, the Reverend James Hamilton in Trim,
about 50 kilometres from Dublin. Uncle James was an accomplished
linguist, and by the age of thirteen Hamilton was fluent in thirteen
languages. When the Persian ambassador visited Dublin, the fourteen
year old Hamilton sent him a flowery letter of welcome, written in Per-
sian. When in 1813 the nine year old American calculating prodigy Zerah Colburn visited Dublin,
a public contest was arranged between him and the local wonder boy, Hamilton, in the expectation
that Hamilton would beat Colburn. In the event Colburn thoroughly trounced Hamilton, which led
Hamilton to devote his attention henceforth mainly to mathematics.
In 1823 Hamilton enrolled at Trinity College, Dublin, where he studied classics and mathemat-
ics. In 1827, before he had even graduated, he was appointed as Professor of Astronomy at Trinity
College, a position that he retained for the rest of his life. At the age of 23 he published the first
part of his A Theory of Systems of Rays on optics. He went on to apply the methods he introduced
there to reformulate classical dynamics in a way that greatly extended the range of problems that
could be solved, and in so doing formulated what has become known as Hamiltonian mechanics. The
later part of his career was devoted to the theory of quaternions, a number system extending the
complex numbers.

404
Logic and Discrete Mathematics: A Concise Introduction
7.6.
Planar graphs
Consider the complete graph on four vertices, K4. Here it is drawn in three different ways:
a
b
c
d
a
b
c
d
a
b
c
d
On the left is K4 as we are used to draw it; in the middle is the same graph with the position-
ing of the vertices a and c adjusted so that no edges cross; on the right K4 has been redrawn
in yet another way to avoid edges crossing, this time by suitably bending the edge ac. This
example motivates the question: can any graph be drawn on the plane so that the edges do
not cross and, if not, which graphs can be drawn in this way?
These questions are interesting in their own right from a purely mathematical perspective,
but the answers are also important from the point of view of applications. For example, con-
sider the problem of laying out components on an electronic circuit board. The connections
between components cannot be allowed to cross as this could cause a short circuit. If crossings
cannot be avoided one or more extra layers need to be created in the circuit board to facilitate
the crossings without short circuits, and this is more expensive. We can model this problem by
representing the components as the vertices of a graph and drawing an edge between two ver-
tices if and only if the corresponding components must be linked. Determining whether this
graph can be drawn without edges crossing answers the question of whether a single layer is
sufficient.
It is now time to introduce the formal definitions that will allow us to study this problem
mathematically.
Definition 7.6.1 A graph G is called a planar graph if it can be drawn in the plane in such a way
that none of its edges cross each other. A planar graph that has been drawn in the plane in such a way
is called a plane graph.

Graph Theory
405
Example 7.6.2
As we saw above, the graph K4 is a planar graph.
You can try to draw the graph K3‚ 3 as a plane graph, but we bet you will fail.
At this stage we can prove that a graph is planar by showing how it can be drawn as a
plane graph, but we have no way of proving that a graph is not planar. Later in this section,
when we have developed the necessary theoretical tools, we will show that K3‚ 3 is indeed
not planar.
A plane graph G divides the plane into a number of regions or faces; these are known as
the faces of G. When drawn as a plane graph in the following way, K4 has 4 faces: 3 internal
faces as well as the rest of the plane representing the 1 external face:
1
2
3
4
Notice that all trees are planar graphs and that any tree dawn as a plane graph has only
one face.
The following theorem shows that there is a precise relationship between the order, size
and number of faces of a connected plane graph.
Theorem 7.6.3 If G is a connected plane graph with n vertices, m edges and f faces, then
n −m + f = 2.
Proof: We proceed by induction on the number of m edges of G. If m = 0, G consists of a single
vertex, i.e. n = 1, m = 0 and f = 1 and hence the equality n −m + f = 2 holds. Now assume
that m ≥1 and that the theorem holds for all connected plane graphs with fewer that m edges.
Suppose that G has m edges. If G is a tree we have n = m + 1 and f = 1 so we have n −m + f =
(m + 1) −m + 1 = 2 and we are done. Suppose that G is not a tree, i.e. that G contains a cycle.
Let e be an edge on this cycle. Then G–e, the graph obtained from G by removing edge e, is still
connected and planar, and it has m–1 edges, n vertices and f −1 faces. (The cycle on which
e lies will necessarily enclose one or more faces, so e is on the border between two faces and
removing e joins these two faces into one new face.) Hence, by the induction hypothesis we
have n −(m −1) + (f −1) = 2, i.e. n −m + f = 2, and the proof is complete.

406
Logic and Discrete Mathematics: A Concise Introduction
Notice that the above theorem says that, if G is a connected plane graph with n vertices,
m edges and f faces, then f = 2 −n + m. In other words, the number of faces of G does not
depend on the particular way in which it is drawn in the plane. Therefore, we are justified in
speaking of the number of faces of a planar graph, as this number will be the same no matter
how the graph is drawn as a plane graph.
Lemma 7.6.4 Let G be a connected planar (n‚ m) graph with n ≥3 vertices. Then
3n −m ≥6.
Proof: If G is acyclic we know that m < n. Also, as n ≥3, we have 2n −6 ≥0. Therefore, m ≤
n + 2n −6 = 3n −6, i.e. 3n −m ≥6.
If G does contain a cycle we sum the number of edges on the boundaries of the faces.
Since each face is bound by at least 3 edges the sum must be at least 3f. As any edge can be on
the boundary of at most two faces the sum can be at most 2m. Therefore 3f ≤2m. However,
2 = n −m + f so 6 = 3n −3m + 3f ≤3n −3m + 2m = 3n −m, i.e. 3n −m ≥6.
The above theorem says that in a planar graph with at least 3 vertices we always have
m ≤3n −6, i.e. it gives an upper bound on the number of edges in terms of the number of
vertices. This makes intuitive sense, since the more edges a graph has in relation to the number
of its vertices, the more likely it is that the edges will have to cross when the graph is drawn.
Theorem 7.6.5 Every planar graph G contains a vertex of degree 5 or less.
Proof: Let G be any planar (n‚ m) graph. If n ≤2 then the maximum degree of the vertices in G
is at most 1, and the theorem holds. Assume that n ≥3. Then we may apply Lemma 7.6.4 and
conclude that 3n −m ≥6, i.e. m ≤3n −6 or 2m ≤6n −12. However, we know that the sum of
the degrees of the vertices of G is equal to 2m. Now if the degree of every vertex in G is at least
6, it must be the case that the sum of the degrees of the vertices is greater than or equal to 6n,
i.e. 6n ≤2m. However, that gives 6n ≤2m ≤6n −12. This cannot be, so there must be a vertex
in G that has degree 5 or less.
We are now able to prove that K3‚ 3 and K5 are not planar.
Theorem 7.6.6 The graph K5 is nonplanar.
Proof: K5 has n = 5 vertices and m = 10 edges. Therefore 3n −m = 15 −10 = 5 < 6, contradict-
ing Lemma 7.6.4. Hence K5 cannot be planar.
Theorem 7.6.7 The graph K3‚ 3 is nonplanar.
Proof: Suppose to the contrary that K3‚ 3 is planar, so we can draw it as a plane graph. Notice that
the shortest length of any cycle in K3‚ 3 is 4, and hence no face is bounded by less than 4 edges.
Let N denote the sum of the number of edges bounding a face, summed over all f faces. Then
N ≥4f. Each edge is counted precisely twice by the sum N as each edge is on the boundary of
exactly 2 regions. Furthermore, there are 9 edges, so we must have N ≤9 × 2 = 18. By Theorem

Graph Theory
407
7.6.3 we have f = 2 −6 + 9 = 5. Therefore we have N ≥4f = 20 and N ≤18 – a contradiction.
Hence, K3‚ 3 cannot be planar.
It is an easy observation that any graph that contains a nonplanar graph as a subgraph
cannot itself be planar (why?). Thus any graph that contains a K5 or K3‚ 3 as a subgraph is
nonplanar. By contraposition, every planar graph may not have K5 or K3‚ 3 as subgraphs. As
we will show further, it turns out that these two conditions are not only necessary but also
essentially sufficient for a graph to be planar. This remarkable result is known as Kuratowski’s
theorem. In order to state that theorem precisely we need one more piece of terminology.
Definition 7.6.8 Let G be a graph. An elementary subdivision of G is a graph obtained from G by
removing from it some edge e = uv and adding to it a new vertex, say w, and 2 new edges, uw and wv.
A subdivision of G is a graph obtained from G by a succession of finitely many (possibly 0) elementary
subdivisions.
Example 7.6.9
The figure below illustrates three subdivisions of K4. The first is obtained by 0 elementary
subdivisions, i.e. it is K4 itself; the second by 2 elementary subdivisions; the third by 4 ele-
mentary subdivisions.
Notice that subdivisions do not allow us to eliminate edge crossings. Indeed, by defini-
tion an elementary subdivision splits a single edge into two new edges through the insertion
of a new vertex and does not allow for the simultaneous splitting of two or more edges by
inserting only one vertex. Thus, for example, the following is not a subdivision of K4:
In the light of the remarks above it is easy to see that a subdivision of a graph is planar if
and only if the original graph is planar. The next theorem now follows from these observations
and Theorems 7.6.6 and 7.6.7.
Proposition 7.6.10 If a graph G contains a subgraph that is a subdivision of K5 or K3‚ 3, then G is
nonplanar.

408
Logic and Discrete Mathematics: A Concise Introduction
This statement is part of Kuratowski’s theorem, which also claims the converse, but which
is substantially more difficult to prove.
Theorem 7.6.11 (Kuratowski’s theorem) A graph G is planar if and only if it contains no subgraph
that is a subdivision of K5 or K3‚ 3.
Example 7.6.12
The following graph is nonplanar as it contains a subdivision of K3‚ 3:
The vertices of the subgraph K3‚ 3 are coloured black.
7.6.1.
Exercises
➊Determine whether each of the following graphs is planar or not. If it is planar, draw it as
a plane graph. If it is nonplanar, apply Kuratowski’s theorem to prove that it is not planar
by identifying a subgraph that is a subdivision of K3‚ 3 or K5.
(a) .
a
b
b
e
d
(b) .
a
c
b
e
d

Graph Theory
409
(c) .
a
c
b
e
f
d
(d) .
a
c
b
e
f
d
g
h
(e) .
a
c
b
e
f
d
g
h
j
i
➋Determine the greatest order a complete planar graph can have.
➌A certain connected planar graph has 6 vertices, each of degree 3. How many edges and
faces does the graph have?
➍A certain connected planar graph has 6 vertices, 1 of degree 2, 4 of degree 3 and 1 of degree
4. How many edges and faces does the graph have?
➎Electronic components A to G need to be connected to each other as indicated in the fol-
lowing table, ✓indicating the presence of a connection and × indicating the absence of a
connection:
B
C
D
E
F
G
A
✓
×
×
×
×
×
B
✓
×
×
×
×
C
✓
✓
✓
✓
D
×
✓
✓
E
✓
✓
F
✓
Model this information as a graph and use it to determine whether these components in
this configuration can be embedded in a single layer on a circuit board.

410
Logic and Discrete Mathematics: A Concise Introduction
➏.(a) What is the maximum number of edges that a connected planar graph of order 6 can
have?
(b) Draw a connected plane graph of order 6 with this number of edges.
➐.(a) What is the maximum number of edges that a connected planar graph of order k, k ≥3,
can have?
(b) Prove that in a plane graph of order k with this number of edges each face is bounded
by exactly 3 edges.
➑Draw two subdivisions of K5, one obtained by 1 elementary subdivision and the other
obtained by 4 elementary subdivisions.
➒Show that the converse of Lemma 7.6.4 does not hold by giving a suitable graph as a coun-
terexample.
➓Give an example of a planar graph in which every vertex has degree 5 or greater.
11 Show that the inequality 3n −m ≥6 given in Lemma 7.6.4 is, in a sense, the best possible,
by giving an example of a connected planer graph with n ≥3 in which 3n −m = 6.
12 Let G be a planar (n‚ m) graph with f faces. Find the values of n −m + f if G has
(a) 2 components,
(b) 3 components,
(c) k components.
13∗Let G be a graph and G′ a subdivision of G. Prove that G is planar if and only if G′ is planar.
14∗Generalize Lemma 7.6.4 to planar graphs that are not necessarily connected, but in which
each component has at least 3 vertices.
Graph theory and Sudoku
In the well-known Sudoku puzzle, players are presented with a 9 × 9 grid partially filled with num-
bers between 1 and 9. The object is to complete the grid by filling in further numbers in such a way
that each of the numbers 1 to 9 appears in each column, each row and each of the 9 smaller 3 × 3
grids.
5
5
5
3
3
3
3
4
4
4
4
4
6
6
6
7
7
7
8
8
8
1
1
1
9
9
9
9
9
2
2
9

Graph Theory
411
This puzzle can be reformulated as a graph colouring problem by representing the grid as a
graph with vertices corresponding to the cells of the grid and edges between vertices corresponding
to cells in the same 3 × 3 grid or in the same column or row. The given numbers in the puzzle
correspond to a partial colouring of the graph, and solving the puzzle corresponds to extending
the partial colouring to a colouring of the graph using 9 colours. Such a graph of the Sudoku grid
is given above. Note that some edges connecting vertices in the same row or in the same column
have been omitted to reduce clutter. The missing edges can be easily inferred.
This graph theoretic modelling can be used to answer all sorts of interesting questions about
Sudoku. It is known that it is possible to construct Sudoku puzzles with unique solutions by spec-
ifying only 17 numbers. Until recently it was unknown whether it is possible to do this using only
16 numbers. There are C(81‚ 16) = 33 594 090 947 249 085 ways to choose 16 vertices to colour and
approximately 2.241 × 1038 partial colourings of the Sudoku graph colouring 16 vertices. Accord-
ingly, going through each possibility by brute force to check if it results in a unique colouring is
not feasible: it would take an estimated 300 000 years on a current supercomputer. However, Gary
McGuire of University College Dublin recast the problem using the graph theoretic notion of “hit-
ting sets”, and in doing so, he was able to formulate a more efficient algorithm. He and his team at
the Irish Centre for High-End Computing in Dublin ran this algorithm on supercomputers for the
whole of 2011, and in 2012 they were able to announce that no colouring of 16 vertices of the Sudoku
graph extends uniquely to a 9-colouring, i.e. no Sudoku puzzle with only 16 numbers given has a
unique solution.
7.7.
Graph colourings
In this section we consider assignments of colours to the vertices of graphs in such a way that
no two adjacent vertices are assigned the same colour. This problem may sound artificial, but
it has a number of real-life applications, e.g. to scheduling, image capturing and segmenta-
tion, clustering, networking, data mining, etc. Here we will formulate the famous four-colour
theorem, which resisted numerous attempts to prove for many decades, and we prove the
weaker five-colour theorem.
7.7.1.
Colourings
Graph colourings are used to solve a wide variety of problems, the classical example being the
following. A radio station is assigned a frequency at which it broadcasts. If two radio stations
with overlapping broadcast areas were to broadcast at the same frequency, or at frequencies
that are not sufficiently different, interference would result. Since only a limited number of
different frequencies are available, broadcast authorities typically have to solve the problem
of having to assign the same frequency to different radio stations, but in such a way that no
interference results. This is where graph theory comes into play: we model the problem by
representing it as a graph where each radio station is represented by a vertex and two ver-
tices are adjacent if and only if the radio stations they represent have overlapping broadcast
areas. Suppose there are N different frequencies available. Solving the problem now becomes
equivalent to finding a way to assign one of the numbers (or colours) 1‚ 2‚ 3‚ …‚ N to each of

412
Logic and Discrete Mathematics: A Concise Introduction
the vertices in such a way that no two adjacent vertices are assigned the same number. Here
are the formal definitions.
Definition 7.7.1 A colouring of a graph G is an assignment of colours to the vertices of G, one colour
to each vertex, so that adjacent vertices are assigned different colours. A colouring using k colours
is called a k-colouring. A graph is k-colourable if there exists an s-colouring of G with s ≤k. The
minimum integer k for which G is k-colourable is called the chromatic number of G and is denoted by
𝜒(G). If 𝜒(G) = k then G is said to be k-chromatic.
Example 7.7.2
Consider the following graph:
1
2
2
3
1
1
Indicated in the sketch is a 3-colouring of the graph using the three colours 1, 2 and 3.
Thus the graph is 3-colourable. As you can check, it is impossible to colour the graph with
2 colours or less. Hence the minimum integer k for which the graph is k-colourable is 3, and
its chromatic number is 3.
Now consider the graph:
1
2
3
1
1
2
2
4
This is 4-colourable, as we have indicated in the sketch. Indeed, the chromatic number
is 4, as every two vertices on the outer square are adjacent to each other (they induce K4
as a subgraph), so using fewer than four colours will result in two adjacent vertices being
coloured the same colour.
In general, the chromatic number of the complete graph Kn is obviously k, since every two
vertices are adjacent, so no colour can be used twice. It is also easy to see that if a graph G has

Graph Theory
413
Figure 7.18: A map of Northern Africa represented as a graph and coloured using four colours
components G1‚ G2‚ …‚ Gk then 𝜒(G) = max{𝜒(G1)‚ 𝜒(G2)‚ …‚ 𝜒(Gk)}. This observation allows
us to consider only the chromatic numbers of connected graphs.
7.7.2.
The four- and five-colour theorems
For many years the most famous unsolved problem in graph theory was the four-colour prob-
lem, formulated as least as early as 1852. It seemed to be the case that any map (say a map of
the countries of the world) could be coloured using only four colours, so that no two countries
sharing a border were coloured using the same colour. What made the four-colour problem
a problem was the fact that no one could come up with either a proof or a counterexample to
this conjecture. The conjecture was at last proved to be true by Kenneth Appel and Wolfgang
Haken in 1976.4 The proof required the checking of a large number of necessary case distinc-
tions using a computer program. To check all the cases required 1200 hours of computer time.
Let us reformulate this statement into more familiar graph theoretic terms. We represent
each country by a vertex and draw edges between any two countries that share a border. Then
clearly the original map can be coloured in the desired way using four colours if and only if the
graph so constructed is 4-colourable. Furthermore, any graph obtained in this way from a map
will be a planar graph, and from every planar graph it is possible to draw a map. Hence there
is a one-to-one correspondence between planar graphs and maps (in the plane). We illustrate
this correspondence in Figure 7.18 with a map of the countries of Northern Africa with the
appropriate graph superimposed.
Via this reformulation the four-colour theorem then becomes as follows.
Theorem 7.7.3 Every planar graph is 4-colourable.
A weaker theorem that is considerably easier to prove, however, is the five-colour theorem.
Theorem 7.7.4 Every planar graph is 5-colourable.
4 K. Appel and W. Haken, Every Planar Map is Four Colorable, Part I. Discharging, Illinois Journal of Mathematics,
21: 429–490, 1977.

414
Logic and Discrete Mathematics: A Concise Introduction
Proof: Let G be any connected plane graph. We proceed by induction on the number n of ver-
tices. If n ≤5 the graph is obviously 5-colourable. We therefore assume that all planar graphs
with fewer than n vertices, n > 5, are 5-colourable, and suppose that G is a plane graph with
n vertices. By Theorem 7.6.5 there is a vertex v in G such that deg v ≤5. We delete v from G to
obtain the plane graph G–v. By the induction hypothesis G–v is 5-colourable. Let a 5-colouring
of G–v with colours 1, 2, 3, 4 and 5 be given. If some colour is not used to colour the vertices
adjacent to v in G then that colour may be used to colour v, producing a 5-colouring of G. If
not, v has degree 5 and all 5 colours are used to colour the 5 vertices adjacent to v.
Assume, without loss of generality, that the vertices adjacent to v in G are v1‚ v2‚ v3‚ v4 and
v5, and that vi is coloured with colour i, 1 ≤i ≤5. We may also assume that v1‚ v2‚ v3‚ v4 and v5
are arranged cyclically around v, in that order.
v4
v
G:
v3
v2
v5
v1
Now consider the vertices v1 and v3 and let H be the subgraph of G–v induced by those
vertices coloured 1 or 3. If v1 and v3 belong to different components of H, then we can inter-
change the colours (1 and 5) assigned to the vertices in the component of H containing v1 and
still have a 5-colouring of G–v (why?). In the 5-colouring obtained in this way none of the
vertices v1‚ v2‚ v3‚ v4 or v5 is coloured 1. We may therefore colour v with therefore colour 1,
producing the desired 5-colouring of G.
Now suppose that v1 and v3 belong to the same component of H. Consequently there is a
v1–v3 path P in G–v, the vertices of which are all coloured 1 and 3. This path P, together with
the path v1‚ v‚ v3 produces a cycle C in G that encloses either v2 or v4 and v5. As G is connected it
must contain a v2–v4 path. This path must cross the cycle C, but as G is a plane graph this must
happen in a vertex, i.e. the v2–v4 path, and the cycle C must share a vertex. Hence there can be
no v2–v4 path in G–v, the vertices of which are all coloured 2 and 4. Denote by F the subgraph
of G–v induced by all vertices coloured 2 or 4. Then v2 and v4 are in different components of F.
Interchange the colours (2 and 4) of the vertices in the component containing v2. This results in
a 5-colouring of G–v in which none of the vertices adjacent to v is coloured 2. Hence colouring
v with 2 results in the desired 5-colouring of G.
7.7.3.
Exercises
➊For each of the following graphs, determine its chromatic number. Give a colouring using
the number of colours equal to the chromatic number and indicate why fewer colours will
not do.

Graph Theory
415
(a) .
(b) .
(c) .
(d) .
(e) .
➋What is the chromatic number of a graph consisting of a single cycle of even length and also
of odd length?
➌What is the chromatic number of the complete bipartite graph K3‚ 3, of the complete bipartite
graph K4‚ 6 and of the complete bipartite graph K101‚ 98?
➍Radio stations in cities A, B, C, D, E, F and G have to be assigned broadcasting frequencies.
Two radio stations can only be assigned the same broadcasting frequencies if they are 500
km or more apart. The distances between the cities are given in the following table:

416
Logic and Discrete Mathematics: A Concise Introduction
A
B
C
D
E
F
G
A
123
773
596
372
373
501
B
787
666
453
321
464
C
372
500
519
393
D
227
546
507
E
419
443
F
146
Determine the least number of different broadcasting frequencies required. Hint: model the
problem as a graph colouring problem by representing cities with nodes and making nodes
adjacent if the corresponding cities are less than 500 km apart.
➎Many scheduling problems can naturally be modelled as graph colouring problems; for
example: Ivy College must schedule exams in such a way that (a) there are no clashes, i.e.
no student must write two or more exams in the same time slot, and (b) as few time slots as
possible are used. There are students taking the following combinations of courses:
• Mathematics, Statistics, Applied Mathematics, Computer Science
• Chemistry, Physics, Mathematics, Statistics
• Zoology, Botany, Statistics, Chemistry
• Philosophy, English, Mathematics, Psychology
Model this problem as a graph colouring problem by representing the courses as vertices
and making two vertices adjacent if and only if there is a student taking both of the corre-
sponding subjects. The time slots are then the colours in a colouring of this graph. What is
the minimum number of different time slots required?
➏The set {0‚ 1‚ 2‚ …‚ 11} must be partitioned in such a way that no two elements in the same
cluster of the partition are congruent modulo 3 (i.e. have the same remainder upon division
by 3). Determine the least number of clusters such a partition can have by modelling the
problem as a graph colouring problem.
➐Mrs Winterbottom has 9 cats. When going out she must put the cats in different rooms of
her house so that no fights break out among the cats. She knows that: (a) Tiger fights with all
the others except Socks; (b) Socks fights with Jack, Nefertiti and Pippin; (c) Jack fights with
Tiger, Socks, Sylvie and Marx; (d) Nefertiti fights with Mopsy and Balthasar; (e) Balthasar
fights with Tiger, Pippin and Marx.
Determine the number of different rooms Mrs Winterbottom requires for the cats, by mod-
elling the situation as a graph colouring problem.
➑True or false: if G is planar then 𝜒(G) = 4. Motivate your answer.
➒True of false: if G contains no subdivision of K5 or K3‚ 3 as a subgraph then G is 4-colourable.
Motivate your answer.
➓Let T be a tree. What are the possible chromatic numbers of T? What are the possible chro-
matic numbers of a forest?
11 .(a) Formulate the converse of the four-colour theorem.
(b) Is the converse of the four-colour theorem true? Motivate.

Graph Theory
417
The four-colour problem
The four-colour problem had a long life before it eventually became the four-colour theorem. In
1852 Francis Gutherie (later Professor of Mathematics at the University of Cape Town) noticed that
a map of the counties of England could be coloured using only four colours. He wondered if four
colours would always suffice for any map. He, or his brother Frederick, proposed the problem to
Augustus De Morgan (see the box at the end of Section 3.5 in Chapter 3) who liked it and suggested
it to other mathematicians. Interest in the problem increased after Arthur Cayley presented it to the
London Mathematical Society in 1878. The next year Alfred Bray Kempe (a British lawyer) gave a
proof of the conjecture. His proof models the problem in terms of graphs and breaks it up into a
number of necessary cases to be checked. Another proof was given by Peter Tait in 1880. It seemed
that the four-colour problem had been settled in the affirmative.
However, in 1890 Percy John Heawood found that Kempe’s proof missed one crucial case, but
that the approach could still be used to prove that five colours are sufficient to colour any map. In
the following year Tait’s proof was also shown to be flawed, this time by Julius Petersen, after whom
the Petersen graph is named. The four-colour problem was therefore again open, and would remain
so for the next 86 years. In that time it attracted a lot of attention from professional mathematicians
and good (and not so good) amateurs alike. In the words of Underwood Dudley:
The four-color conjecture was easy to state and easy to understand, no large amount of
technical mathematics is needed to attack it, and errors in proposed proofs are hard to
see, even for professionals; what an ideal combination to attract cranks!
The four-colour theorem was finally proved in 1976 by Kenneth Appel and Wolfgang Haken
at the University of Illinois. They reduced the problem to a large number of cases, which were then
checked by computer. This was the first mathematical proof that needed computer assistance. In
1997 N. Robertson, D.P. Sanders, P.D. Seymour and R. Thomas published a refinement of Appel on
Haken’s proof, which reduces the number of necessary cases, but which still relies on computer
assistance. The search is still on for a short proof that does not require a computer.


Index
R[X], 36
R−1[X], 36
Δ(G), 358
𝛿(G), 358
cod(f), 28
𝛿(G), 358
dom(f), 28
ℤ, ℤ+, ℚ, ℚ+, ℝ, ℝ+, 1
rng(f), 28
f[X], 28
R‚ ∣B, 37
f‚ ∣X, 30
absorption, 124
acyclic graph, 363
addition in ℤ, 249
Addition principle, 280
Additive counting principle, 280
additive inverse in ℤ, 251
adjacency in a digraph, 365
adjacency matrix, 370
adjacent from, 365
adjacent to, 365
algorithm, 235
antecedent, 91
arc, 364
Aristotle, 100
arithmetic modulo n, 250
Logic and Discrete Mathematics: A Concise Introduction, First Edition. Willem Conradie and Valentin Goranko.
© 2015 John Wiley & Sons, Ltd. Published 2015 by John Wiley & Sons, Ltd.
Companion Website: www.wiley.com/go/conradie/logic
arrangement, 278
nondistinct objects, 304
associativity, 124
assumptions, 102
attribute, 80, 81
auxiliary symbol, 139
axiom of choice, 66, 68
biconditional, 9, 90
bijection, 30
binomial theorem, 288
Boolean algebra, 25
Boolean connectives, 90
Braille, 312
canonical mapping, 53
Cantor, Georg, 35
capture, 166
cardinal number, 72
cardinality, 72
Catalan numbers, 319
Cauchy product, 330
chain, 65
characteristic equation, 322
characteristic roots, 323
chinese remainder theorem, 257
chromatic number of a graph, 412
clausal form, 129, 198

420
Index
clause, 129
empty, 129
first-order, 198
unit, 129
cluster, 52
CNF, 127
co-domain of a function, 6, 28
combinatorial games, 336
common divisor, 225
common multiple, 232
commutativity, 124
complete mathematical induction, the
principle of, 221
complete residue system modulo n, 250
composite number, 237
compound propositions, 9
conclusion, 104
conditional, 9, 90
conditional probability, 348
congruence, 243
congruence relations, 243
congruences, basic properties, 243
conjunction, 9, 90
elementary, 127
conjunctive normal form
first-order, 195
connected component, 363
consequent, 91
constants, 137
construction sequence of a formula,
92
construction tree, 92
continuum hypothesis, 74
contradiction, 121
contradictory formula, 96
countable set, 71
countermodel of a formula, 171
covering relation, 60
CPHP, 301
cryptography, 269
data type, 81
decryption, 269
deductive consequence, 111
deductive system, 111
adequate, 112
complete, 111
sound, 111
definition
inductive, 92
recursive, 92
denumerable set, 71
derivation
resolution-based, 130
first-order, 204
derivative implications, 106
detachment rule, 104
digital signature, 269
digraph, 364
Dijkstra, Edsger Wybe, 385
Diophantine equations, 253
linear, 253
of two unknowns, 253
directed edge, 364
directed graph, 364
Dirichlet’s principle, 299
Dirichlet, Johann Peter Gustav Lejeune,
304
disjunction, 9, 90
elementary, 127
disjunctive normal form
first-order, 195
distance in a graph, 363
distributions
different objects, 306
identical objects, 314
distributivity, 124
divide, 224
divisibility, 224
divisibility, properties of, 224
division of relations, 87
division with remainder, 224
divisor, 224
DNF, 127
domain
of a relation, 36
domain of a function, 6, 28
domain of discourse, 4, 136

Index
421
edge set, 357
edge, 357
edges
adjacent, 357
Erdös, Paul, 395
element, 2
elementary conjunction
first-order, 195
elementary disjunction
first-order, 195
encryption, 269
encryption function, key, 269
equinumerous sets, 69
equivalence class, 52, 248
equivalence classes modulo n, 249
equivalence relation, 46, 52, 248
Euclidean algorithm, 230
Euler’s function, 261
Euler’s theorem, 262
Euler, Leonhard, 369
Eulerian circuit, 396
directed, 398
Eulerian digraph, 398
Eulerian graph, 396
Eulerian trail
directed, 398
Eulerian trial, 396
evaluation game, 156
initial configuration, 156
event, 343
events
complementary, 343
mutually exclusive, 343
existential quantifier, 139
experiment, 343
faces of a plane graph, 405
falsifier, 156
falsifying truth-assignment, 96
Fermat primes, 241
Fibonacci, 328
Fibonacci numbers, 319, 325, 342
Fibonacci spiral, 342
finite probability space, 345
finite set, 71
first-order logic, 89, 135
first-order instance, 143
first-order language, 138
nonlogical symbols, 138
first-order structure, 137
forest, 385
formation rules, 92
formula
first-order, 141
atomic, 141
clean, 165
closed, 164
ground, 141
main connective, 142
open, 164
satisfiable, 172
sentence, 164
subformula, 143
true in a structure, 154
valid, 172
logically valid, 95
propositional, 91
satisfiable, 96
signed, 96
formulae
Boolean, 92
first-order
logically equivalent, 173
logically equivalent, 121
signed
contradictory pair, 114
function, 6, 28, 137
bijective, 30
co-domain, 28
co-domain of, 6
composition, 31
domain, 28
domain of, 6
extension, 30
graph of, 6, 47
image, 28
injective, 30
inverse, 31

422
Index
function, (continued)
pre-image, 28
range, 28
restriction, 30
surjective, 30
target set, 28
value, 28
function:graph, 29
fundamental theorem of arithmetic, 236,
238
fuzzy set, 50
generating function, 329
generating functions:Cauchy product,
330
Golden ratio, 342
graph colouring, 412
graph, 357
bipartite, 360
complete, 360
connected, 363
graph of a function, 6, 47
greatest common divisor, 225
greatest lower bound, 63
Hamilton, Sir William Rowan, 403
Hamiltonian cycle, 399
Hamiltonian graph, 399
Hamiltonian path, 399
Hasse diagram, 61
idempotency, 124
implication, 9, 90
contrapositive, 107
converse, 106
inverse, 107
implication, fallacies, 106
incidence, 357
incidence in a digraph, 365
incidence matrix, 370
inclusion–exclusion principle, 293
indegree, 365
independent events, 351
individual variable, 138
inference rule, 104
instance, 104
logically sound, 104
infimum, 63
infinite set, 71
initial vertex, 362, 365
injection, 30
integers modulo n, 249
integral linear combination, 226
internal vertex, 385
interpretation, 152
standard, 152
inverse
of a relation, 41
k-combination with repetition, 313
kernel equivalence, 56
Laplace, Pierre-Simon de, 355
law of excluded middle, 95
law of noncontradiction, 95
leaf, 385
least common multiple, 232
least upper bound, 63
Leonardo of Pisa, 328
lexicographic order, 66
linear congruence, 254
linear order, 46
literal, 127
first-order, 195, 198
logic
first-order, 89, 136
semantics, 136
syntax, 136
predicate, 89
propositional, 89
logical connectives, 9
logical consequence, 101, 176
logical equivalence, 121
logical law, 95
absorption, 123
associativity, 123
commutativity, 123
De Morgan’s laws, 121

Index
423
distributivity, 123
excluded middle, 121
idempotency, 123
lower bound, 63
Lucas numbers, 319
main connective, 92
main subformula, 92
map, 28
mapping, 28
mathematical induction, the principle
of, 220
maximal element, 64
Mersenne primes, 241
minimal element, 64
model checking game, 156
model of a formula, 171
modular arithmetic, 250
modulo
residue, 243
congruent, 243
remainder, 243
modulo n, equivalence classes, 248
modulo n, residue systems, 248
Modus Ponens, 104
multigraph, 396
multinomial
coefficient, 309
theorem, 308, 309
multiple, 224
multiplication in ℤ, 249
multiplication principle, 275
commuting events, 276
generating functions, 330
multiplicative inverse in ℤ,
251
natural join, 85
necessary, 91
negation, 9, 90
negation normal form, 124
Nim, 336
nontrivial graph, 358
normal form
conjunctive, 127
disjunctive, 127
order
partial, 59
order isomorphism, 75
order of a digraph, 365
order of a graph, 357
order of an integer, 266
order preserving map, 75
ordered pair, 4
ordinal, 76, 77
limit, 77
successor, 77
ordinality of a set, 76, 77
outdegree, 365
paramodulation, 207
parsing tree, 93
partial order, 46, 59
induced, 60
partially ordered set, 59
partite set, 360
partition, 53, 248
cluster, 248
Pascal’s triangle, 292, 287
Pascal, Blaise, 317
path in a graph, 362
Peirce, Charles, 88
perfect kth power, 241
permutation, 278
nondistinct objects, 304
with repetition/replacement, 315
PHP, 299
pigeonhole principle, 299
congested, 301
planar graph, 404
plane graph, 404
poset, 59
powerset, 4
powerset algebra, 25
pre-order, 59
predicate, 137
predicate logic, 89
premise, 104

424
Index
prenex conjunctive normal form, 195
prenex disjunctive normal form, 195
prenex form, 195
matrix, 195
prefix, 195
primary residue system modulo n, 250
prime number, 237
prime numbers distribution, 239
primitive propositions, 9
principle of descending chains, 220
principle of well-ordering, 220
private key, 269
probability
conditional, 348
probability measure, 345
probability space, 345
projection operation, 83
proof
by assumption of the contrary, 212
by contradiction, 212
by contraposition, 214
proposition, 9
propositional argument, 104
propositional arithmetic, 10
propositional connectives, 139
propositional constants, 91
propositional inference, 104
propositional logic, 89
propositional logical consequence, 101
public key, 269
public key cryptography, 269
quantifier, 13
scope, 164
quantifiers, 139
first-order, 139
quotient, 225
quotient set, 53
r-Permutation, 278
Ramsey, Frank Plumpton, 376
range
of a relation, 36
range of a function, 28
reachability in graphs and digraphs, 371
recurrence relation, 318
characteristic equation, 322
characteristic roots, 323
constant coefficients, 322
homogeneous, 322
linear, 322
reduced residue system modulo n, 250
reflexive, 248
regions of a plane graph, 405
relation, 5, 35
antisymmetric, 45
binary, 5
complementation, 39
composition, 41
direct image, 36
domain, 36
inverse, 41
inverse image, 36
irreflexive, 45
range, 36
reflexive, 45
symmetric, 45
transitive, 46
relation schema, 81
relational algebra, 84
relational database model, 80
relational database schema, 81
relatively prime, 236
relatively prime in pairs, 236
remainder, 225
renaming, 165
residue systems, 250
resolution
propositional, 126
resolution-based derivations, 130
resolvent, 126
restricted quantification, 162
restriction of a relation, 37
root of a tree, 390
rooted tree, 390
derived directed, 390
RSA method, 270
Russell’s paradox, 27

Index
425
sample space, 343
selection operation, 83
semantic tableaux, 97, 113
formula-decomposition rules, 113
rules, 94
theorem, 115
sentence
first-order, 164
set, 2
complement, 4
notation, 3
universal, 4
set-builder notation, 3
sets
Cartesian product, 4
difference, 3
disjoint, 3
intersection, 3
operations on, 3
union, 3
sink, 365
size of a digraph, 365
size of a graph, 358
Skolem constant, 197
Skolemization, 197
source, 365
subdivision of a graph, 407
elementary, 407
subformulae, 92
subgraph, 359
induced, 359
vertex-induced, 360
subset, 2
subset, proper, 2
substitution
domain, 201
result, 166
subterm, 140
Sudoku, 410
sufficient, 91
supremum, 63
surjection, 30
syllogism, 101
symmetric, 248
tableau, 114
branch
closed, 114
open, 115
saturated, 115
closed, 115
open, 115
tautology, 95
term, 140
constant, 140
evaluation, 153
ground, 140
value, 153
terminal vertex, 362, 365
terms
nonunifiable, 202
unifiable, 202
theorem, 111
theorems of Euler and Fermat, 262
total order, 46
trial, 343
trail in a graph, 362
transitive, 248
trapdoor function, 270
travelling salesman problem, 400
tree, 385
rooted, 390
trivial divisors, 237
trivial graph, 358
truth tables, 10
truth value, 9, 90
tuple, 5
n-tuple, 5
underlying graph, 366
unifier, 202
more general, 202
most general, 202
universal closure, 172
universal quantifier, 139
upper bound, 63
variable
Boolean, 91

426
Index
variable (continued)
bound, 164
free, 164
free for substitution,
166
individual, 13
propositional, 91
variable assignment, 153
variant, 155
variation, 278
Venn diagrams, 298
Verifier, 156
vertex, 357
degree, 358
end, 358
even/odd, 358
isolated, 358
vertex set, 357
vertices
adjacent, 357
walk in a graph, 362
Warshall algorithm, 371
weight of an edge, 378
weighted graph, 377, 378
weighted length of a path, 378
well defined, 56
well-founded poset, 65
well order, 65
Wilson’s theorem, 266
Zermelo–Fraenkel set theory, 58

WILEY END USER LICENSE AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.

