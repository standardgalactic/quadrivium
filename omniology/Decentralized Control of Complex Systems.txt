
Decentralized Control of Complex Systems 

This is Volume 184 in 
MATHEMATICS IN SCIENCE AND ENGINEERING 
Edited by William F. Ames, Georgia Institute of Technology 
A list of recent titles in this series appears at the end of this volume. 

DECENTRALIZED 
CONTROL OF 
COMPLEX SYSTEMS 
Dragoslau D. Siljak 
SANTA CLARA UNIVERSITY 
SANTA CLARA, CALIFORNIA 
ACADEMIC PRESS, INC. 
Boston San Diego New York 
London Sydney Tokyo Toronto 
Harcourt Bmce Jovanovich, Publashers 

This book is printed on acid-free paper.@ 
COPYRIGHT @ 1991 BY ACADEMIC 
PRESS, INC. 
ALL RIGHTS RESERVED. 
NO PART OF THIS PUBLICATION MAY BE REPRODUCED OR 
TRANSMITTED IN ANY FORM OR BY ANY MEANS, ELECTRONIC 
OR MECHANICAL, INCLUDING PHOTOCOPY, RECORDING, OR 
ANY INFORMATION STORAGE AND RETRIEVAL SYSTEM, WITHOUT 
PERMISSION IN WRITING FROM THE PUBLISHER. 
ACADEMIC PRESS, INC. 
1250 Sixth Avenue, San Diego, CA 92101 
United Kangdon Editaon published by 
ACADEMIC PRESS LIMITED 
24-28 Oval Road. London NW1 7DX 
Library of Congress Cataloging-in-Publication Data 
Siljak, Dragoslav D. 
Decentralized control of complex systems / Dragoslav D. Siljak. 
p. cm.-(Mathematics in science and engineering ; v. 184) 
Includes bibliographical references. 
ISBN 0-12-643430-1 (alk. paper) 
1. System analysis. 2. Control theory. I. Title. 11. Series. 
QA402S48 1990 
0 0 3 4 ~ 2 0  
9C-258 
CIP 
PRINTED IN THE UNITED STATES OF AMERICA 
9 0 9 1 9 2 9 3  9 8 7 6 5 4 3 2 1  

To Ana and Matzja 
for love and fun 

Simple perceptions, or impressions and ideas, are 
such as admit of no distinction nor separation. 
The complex are the contrary to these, and may be 
distinguished into parts. 
David Hume 
“A Treatise of Human Nature” 

Preface 
xi 
Chapter 1 Structured Systems 
1.1 
Graphs and Dynamic Systems 
1.2 
Input and Output Reachability 
1.3 
Partitions and Condensations 
1.4 
Structural Controllability and Observability 
1.5 
Plant and Feedback Structures 
1.6 
Structurally Fixed Modes 
1.7 
Notes and hferences 
Bibliography 
Chapter 2 Stabilization 
2.1 
Connective Stability 
2.2 
Vector Liapunov Functions 
2.3 
Stabilization 
2.4 
Connective Stabilizability 
2.5 
Graph-Theoretic Algorithm 
2.6 
Notes and References 
Bibliography 
Chapter 3 Optimization 
3.1 
Suboptimality 
1 
2 
6 
12 
20 
31 
40 
58 
61 
65 
66 
71 
86 
92 
103 
113 
118 
126 
127 
vii 

viii 
Contents 
3.2 
Complex Systems 
3.3 
Robustness of Suboptimal Control 
3.4 
Optimality and Robustness 
3.5 
Decentrally Optimal Systems 
3.6 
Notes and References 
Bibliography 
Chapter 4 Estimation and Control 
4.1 
4.2 
4.3 
4.4 
4.5 
4.6 
4.7 
4.8 
4.9 
4.10 
An Interconnected Observer 
Decentralized Feedback 
Separation Property 
Decentralized Observer 
Stochastic Control 
Estimation 
Incomplete State Information 
Structural Perturbations 
Degenerate Control 
Notes and References 
Bibliography 
Chapter 5 Output Control 
5.1 
5.2 
5.3 
5.4 
5.5 
5.6 
5.7 
5.8 
Dynamic Output Feedback 
Structured Almost Invariant Subspaces 
Graph-Theoretic Characterization 
Decentral Stabilizability 
Adaptive Control 
Known Subsystems 
Adaptive Output Feedback 
Notes and References 
Bibliography 
Chapter 6 Hierarchical LBT Decompositions 
6.1 
Input Decompositions 
6.2 
Stabilization 
6.3 
Input-Output Decompositions 
6.4 
Sequential Optimization 
6.5 
Notes and References 
Bibliography 
Chapter 7 Nested Epsilon Decompositions 
7.1 
Epsilon Decomposability 
136 
144 
155 
165 
180 
182 
186 
187 
192 
199 
201 
208 
216 
219 
222 
226 
232 
234 
237 
238 
247 
253 
267 
272 
290 
295 
302 
307 
311 
312 
320 
329 
348 
371 
372 
374 
375 

Contents 
ix 
7.2 
Decomposition Algorithm 
7.3 
Control Applications 
7.4 
Nested Connective Stability 
7.5 
Block Diagonal Dominance 
7.6 
Notes and References 
Bibliography 
Chapter 8 Overlapping Decompositions 
8.1 
Preliminaries 
8.2 
The Inclusion Principle 
8.3 
Optimization 
8.4 
Nonlinear Systems 
8.5 
Notes and References 
Bibliography 
Chapter 9 Reliable Control 
9.1 
Multiple Control Systems 
9.2 
Reliability of Control Structures 
9.3 
Design of Reliable Control 
9.4 
Maintained Control Systems 
9.5 
Notes and References 
Bibliography 
Appendix Graph-Theoretic Algorithms 
378 
382 
389 
399 
405 
411 
414 
415 
424 
437 
452 
463 
467 
472 
473 
483 
486 
496 
503 
504 
507 
Index 
521 

This page intentionally left blank

Complexity is a central problem in modern system theory and practice. 
Because of our intensive and limitless desire to build and to control ever 
larger and more sophisticated systems, the orthodox concept of a high 
performance system driven by a central computer has become obsolete. New 
emerging notions are subsystems, interconnections, distributed computing, 
neural networks, parallel processing, and automated factories, to mention 
a few. It is becoming apparent that a “well-organized complexity” is the 
way of the future. 
The notion of complexity is used broadly, in widely different contexts, 
and often with subjective connotations. A great deal of our research in 
modeling and control of complex systems indicates that the fundamental 
characteristics of complexity are dimensionality, uncertainty, and informa- 
tion structure constraints. For us, these three features will be of overriding 
concern and will serve as major motivating factors for development of de- 
centralized control theory for complex systems. 
We regard a dynamic system as an interconnection of subsystems, which 
may be known as physical entities, or are a purely mathematical artifice 
to be identified by a suitable partitioning algorithm. In either case, we can 
take advantage of special structural features of a decomposed system and 
come up with a substantial reduction of dimensionality in control prob- 
lems. Presumably, each subsystem can be considered independently and the 
individual solutions can be combined in some way to get a solution for the 
xi 

xii 
Preface 
overall problem. While this recipe has been around for quite some time, it 
is only recently that the decomposition approach is emerging as a powerful 
design concept. We shall provide for the first time a comprehensive presen- 
tation of this approach to control of complex systems, exposing, at the same 
time, critical conceptual insights and significant numerical simplifications 
available in this context. 
We customarily assume that neither the internal nor external nature of 
complex systems can be described precisely in deterministic or stochastic 
terms. Essential uncertainties of both the structured (parametric) and un- 
structured variety are present in the subsystems and their interconnections 
as well as information channels and controller configurations. For this rea- 
son, we emphasize, and perhaps overemphasize, the superior robustness of 
decentralized control laws with respect to plant and controller uncertain- 
ties and, in particular, unpredictable structural perturbations whereby the 
subsystems are disconnected and again connected in various ways during 
operation. We also include the multiple controller configurations to cope 
with controller failures and to achieve a satisfactory reliability of decentral- 
ized control schemes. Our concern for robustness and reliability is justified 
by the fact that more often than not the normal operating mode of a com- 
plex system is a failure mode! 
Our ability to study and master large complex systems is greatly en- 
hanced by the advent of modern computing machinery. This reliance on 
computing power is likely to increase with our persistent efforts to build 
high-performance control systems at lower costs. Therefore, it is absolutely 
essential that we develop control theory that can accommodate the new and 
decisive trend in computer technology toward distributed parallel comput- 
ing with highly reliable low-cost multiprocessor architectures. In complex 
systems, where databases &re developed around the plants with distributed 
sources of data, a need for fast control action in response to local inputs 
and perturbations dictates use of distributed (that is, decentralized) infor- 
mation and control structures. We require a theory for synthesizing control 
laws under decentralized information structure constraints, which is what 
this book is all about. 
The plan of the book is as follows. Chapter 1 provides a graph-theoretic 
framework for structural modeling of complex systems. This is a natural 
environment for decentralized control problems, because they are primarily 
structural. Furthermore, screening candidate structures for controllability, 
observability, and fixed modes in this context is computationally attractive, 
especially when large systems are involved: the outcomes are generic and 
only binary operations are required. In Chapter 2, we present the results 

... 
Preface 
xiii 
concerning robust stabilization via decentralized state feedback. Optimiza- 
tion is the subject of Chapter 3, where we emphasize robustness in terms 
of gain and phase margins and gain reduction tolerance in each control 
channel. Output feedback is considered in the context of interconnected 
observers (Chapter 4) and directly using controllers of a static or dynamic 
variety (Chapter 5). Manipulative power of graphs is exploited in Chapters 
6 and 7 to discover hidden structures conducive to decentralized control. 
Both lower block triangular and weak coupling forms are considered, which 
offer a considerable savings in computational effort involved in building 
controllers and observers for complex systems. Overlapping decompositions 
and the underlying Inclusion Principle are presented in Chapter 8, which 
enlarge to a great extent the scope and applicability of decentralized con- 
trol. It is in reliability design (Chapter 9) where decentralized control with 
overlapping information constraints is the basic tool for making the mul- 
tiple controller concept work. In this last chapter, a unified synthesis of 
robust decentralized control is achieved with respect to both the plant and 
controller failures. 
At the end of each chapter we include a Notes and References section 
where we provide comments and cite relevant literature to describe the 
evolution of the ideas, as well as to broaden the range of the presented 
results. References for each individual chapter are listed in the Bibliography 
section following the Notes and References section. Omitted references are 
either well known, or are regretfully excluded to keep the list at a resonable 
length. 
Finally, we provide graph algorithms in the Appendix. Depth-first search, 
input and output reachability, structural controllability and observability, 
and lower block triangular and nested epsilon decompositions are all in- 
cluded and explained. Utility of our theoretical results depends a great 
deal on how efficient these computer algorithms are, and we shall provide 
a discussion of their complexity. 
My first thanks go to Masao Ikeda and Erol Sezer for a fruitful, gratifying 
and, above all, exciting collaboration, which provided a wealth of results 
for this book. As if it were not enough, they read the final manuscript and 
offered numerous comments and suggestions. 
I am grateful to Gan Ladde, Rade Krtolica, Yuzo Ohta, Yoshi Hayakawa, 
Paolo Fergola, Lello Tenneriello, Eugene Kaszkurewicz, Srdjan StankoviC, 
as well as my former students Dave White, Magda Metwally, Val Pichai, 
Migdat Hodiid, Don Gavel, and Doug LaMont for exploring with me the 
new avenues as well as the backroads of complex systems. 
My special thanks are due to Fran Karmitz for typing the manuscript in 

xiv 
Preface 
her peerless fashion after deciphering my innumerable and often confusing 
revisions. 
Finally, I wish to gratefully acknowledge the support of the National Sci- 
ence Foundation and the US. Department of Energy. Their continual and 
generous assistance made our ambitious broad-range research in complex 
systems come to fruition. 
Saratoga, California 
December 1990 
Dragoslav D. Siljak 

Chapter 1 
In the mathematical modeling of physical systems, one is invariably con- 
fronted with a dilemma: to use a more accurate model which is harder 
to manage, or to work with a simpler model which is easier to manipulate 
but with less confidence. A hierarchy of models with increasing complexity 
and fidelity is more often than not the best approach. When the number 
of variables is large, it is prudent, if not imperative, to start the analysis 
with simple structural models that offer relatively easy ways to identify 
unsuitable system configurations, causes for lack of desired properties, and 
straightforward remedies. 
“Structure” is a widely used and often misused term in system theory 
and practice. For us, however, a structure is a graph, which is a precise 
mathematical object. In this way, a structural analysis of dynamic systems 
is carried out within the rich and rigorous framework of graph theory. 
Our objective in this chapter is to set up the graph-theoretic approach 
and present basic results concerning the existence of suitable structures 
for decentralized control. The end product is a collection of efficient and 
reliable algorithms for testing candidate schemes for decentralized control 
and estimation. 
Before proceeding to technical developments, let us discuss the intu- 
itive ideas underlying the approach. With a linear system we associate a 
directed graph (digraph) in an obvious way: to each variable we assign 
a vertex of a digraph, and an edge is present whenever the corresponding 
coefficient in the system matrix, which relates a pair of variables, is dif- 
ferent from zero. Then, the central problem is to determine if there is a 
path to every state vertex from at least one input vertex, that is, if the 
system is input reachable. The dual concept is output reachability, which is 
the property that each state reaches at least one output. These concepts 
were formulated as the basic structural requirements for controllability and 
Structured Systems 
1 

2 
1. Structured Systems 
observability. They apply to linear and nonlinear systems alike, they are pa- 
rameter independent, and there are very efficient algorithms to test them. 
A crucial advantage offered by the reachability concepts is their manipula- 
tive power, which can be used in decompositions of large dynamic systems 
(see Chapters 6 and 7). 
When the property of generic rank is added to input reachability, one 
arrives at structural controllability. This notion is a better graph-theoretic 
approximation of controllability than reachability, but it is achieved at the 
price of liability to parameter dependencies of the generic rank condition 
(see Examples 1.33 and 1.34). A way to simplify this problem and, at 
the same time, decrease the computational effort involved in checking the 
rank condition, is to manipulate first the system into hierarchically ordered 
input reachable subsystems using graphs (see Chapter 6 ) .  Then, testing for 
structural controllability of the overall system is reduced to verifying the 
same property of low-order subsystems. 
Finally, we consider structurally f i e d  modes, which were defined to 
study the important existence problem of control laws under arbitrary 
structure constraints including output and decentralized control schemes. 
Again, as expected, the presence of structurally fixed modes, which cannot 
be moved by any choice of system parameters, is determined by a reliable 
algorithm involving only binary computations. This is of special importance 
to us, because unstable structurally fixed modes make stabilization impos- 
sible no matter how we choose the feedback parameters in a decentralized 
control law. 
1.1. Graphs and Dynamic Systems 
Let us consider a linear dynamic system described by the equations 
S: j . = A z + B u ,  
y = cx, 
where z(t) E R" is the state, u(t) E R" is the input, and y ( t )  E Re is the 
output of S at time t E R, and A = (aij), B = (bij), and C = (cij) are 
constant matrices of dimensions n x n, n x m, and I x n, respectively. 
A precise way to represent the structure of S is to use the interconnec- 
tion (adjacency) matrix specified by the following: 
1.1. DEFINITION. The interconnection matrix of S is a binary (n + 

1.1. Graphs and Dynamic Systems 
3 
m + l) x (n + rn + l) matrix E = (eij) defined as 
A
B
O
 
E = O O O ,  
[C 0 u] 
where the matrices A = (iiij), B = ( b i j ) ,  and C = (Gj) have the elements 
The submatrices A, B, C of E are Boolean representations of the origi- 
nal system matrices A, B, C. This conversion of matrix elements to binary 
values makes the interconnection matrix E a useful modeling tool for the 
study of qualitative properties of the system S, which are independent of 
specific numerical values taken by system parameters (Siljak, 1977a). In 
this way, we can also handle parameter uncertainties caused by modeling 
errors or operating failures in the system. 
While the interconnection matrix E is useful in computations because 
only binary operations are involved, for qualitative interpretations of struc- 
tural properties of S the equivalent concept of a directed graph (digraph) 
is often preferred. We recall (Deo, 1974) that a digraph is the ordered pair 
D = (V, E), where V is a nonempty finite set of vertices (points, nodes), 
and E is a relation in V, that is, E is a set of ordered pairs (vj, wi), which 
are the directed edges (lines, arcs) connecting the vertices of D. 
Using Definition 1.1 of the matrix E = (eij), we formulate the following: 
1.2. 
The digraph D = (V, E) of a system S has the vertex 
set V = U U X u Y, where U = {ul, u2, . . . , urn}, X = ( 2 1 ,  x2, . . . , xn}, and 
Y = {yl, y2, . . . , ye} are nonempty sets of input, state, and output vertices 
of D, respectively, and E is the edge set such that (vj, wi) E E if and only 
if eij = 1. 
DEFINITION. 
We notice that digraph D of S contains only the edges (uj, xi), 
(xj, xi), and (xj, yi), which reflects our basic assumption about the sys- 
tem S: there are no connections among inputs, outputs, between inputs 
and outputs, etc. (Siljak, 1977a, b). 

4 
1. Structured Systems 
I 
m 
Fig. 1.1. Pendulum. 
1.3. EXAMPLE. To illustrate how graphs are associated with dynamic 
systems, let us consider the motion of a frictionless pendulum shown in 
Figure 1.1, which is described by the equation 
me4 + mgO = U ,  
(1.4) 
where O ( t )  is the angle from the vertical to the rod at time t, e(t) = 
d20(t)/dt2 is the acceleration of the bob at time t, C is the length of the 
rod (rigid and without mass), and m is the mass of the bob subject to a 
force (input) u(t) at time t. Choosing the state vector z = ( 2 1 ,  Z Z ) ~ ,  
where 
q ( t )  = O(t) and z2(t) = dO(t)/dt, we get the system S representing the 
pendulum as 
s .=[: 
;].+[;I., 
are the system matrices. From (1.5), it is clear that we consider O ( t )  as a 
measurable state of S ,  that is, as the output y ( t )  of S .  
The intercon- 
nection matrix E is given as 

1.1. Graphs and Dynamic Systems 
5 
Fig. 1.2. System digraph. 
where dashed lines delineate the matrices A, B, and C. The corresponding 
digraph D is shown in Figure 1.2. 
It is important to note that if the system parameters m and C are 
changed to ml and C1, the interconnection matrix E and, thus, the digraph 
D, remain the same. That is, E and D represent the structure of S1 as 
well, where 
0
1
 
s1: il = [ Ol 
0 ]  x1 + [ ;l] 
u, 
Y = [ l  
01x1, 
and 01 = -g/tl, PI = l/rnltl. We say that the systems S and S1 are 
stmctumlly equivalent. 
In addition to the variation of system parameters, structural 
equivalence allows for a relabeling of the inputs, states, and outputs by 
permutation matrices. More precisely, let us consider two systems 
and 
(1.10) 
where the state vectors x1 and 2 2  have the same dimension n. We form the 
Boolean triples ( A l ,  &, C1) and (&, &,q) 
and formulate: 
1.4. 
Two systems S1 and S2 are said to be structurally 
equivalent if there exist (nonsingular) pemutation matrices PA, PB, and Pc 
DEFINITION. 

6 
1. Structured Systems 
such that 
1.5. EXAMPLE. On the basis of Definition 1.4, the system 
sz: x 2 ” 1  0 
a 2  
o ] 5 * + [ q u 7  
(1.12) 
where a2 = -g/&, and pZ = l/m2e2, is structurally equivalent to the sys- 
tem S1 of (1.8) independent of the nonzero numerical values al, a 2 ,  01, 02 
taken by the system parameters a and p. The permutation matrices 
(1.13) 
satisfy the relations (1.11) for the two systems S1 and S2. 
The invariance of structural equivalence to parameter variations is the 
underlying feature of graph-theoretic analysis, which is appealing in mod- 
eling of physical systems, especially those having large dimensions where 
uncertainty about system parameter values is always present. The proper- 
ties of a system S established by its interconnection matrix E or digraph D 
are at the same time valid for systems structurally equivalent to S .  This fact 
not only provides a way to cope with uncertainty in the modeling process, 
but also serves as a cornerstone in robust designs of control and estimation 
schemes for large scale systems. This aspect of structural modeling will be 
exploited throughout this book. 
Another appealing aspect of structural modeling of complex systems 
is the binary nature of the interconnection matrices and digraphs. Tests 
of intrinsic characteristics of such systems, when formulated in structural 
terms, are well-posed numerical problems that can be executed with speed 
and reliability by standard computing machinery. This feature of structural 
modeling is of our immediate interest. 
1.2. Input and Output Reachability 
The existence and actual design of control laws for a dynamic system 
depend crucially upon the well-known fundamental properties of complete 

1.2. Input and Output Reachability 
7 
controllability and observability (Kalman, 1963). Complete controllability 
means that any initial state of a given dynamical system can be transferred 
to the zero state in a finite length of time by a suitable input, while com- 
plete observability implies that any state of the system can be determined 
in a finite length of time from subsequent inputs and outputs. In most situ- 
ations, these properties are all one needs to construct controllers for linear 
constant plants. 
For a system S of (l.l), the standard tests for complete controllability 
and observability are 
and 
rank [B AB . . . A"-'B] = 
rank [C CA . . . CA"-'] = n, 
(1.14) 
(1.15) 
where n is the dimension of the state space of S (that is, the order of 
S ) .  In systems of large dimensions, computing the rank conditions (1.14) 
and (1.15) is an ill-posed numerical problem. Furthermore, when the tests 
fail, there is no indication how the rank deficiency can be removed even 
in relatively simple situations. For these reasons, the notions of input and 
output reachability, which represent the crucial ingredients in controllability 
and observability, have been defined by Siljak (1977a, b). The reachability 
properties are numerically attractive, because they can be established by 
binary computations alone. 
To define the concept of input and output reachability, we need 
several well-known notions from the theory of digraphs (Harary, 1969). 
We consider a digraph D = (V, 
E) of S, and recall that if a collection of dis- 
tinct vertices vl, 212, ..., Vk together with the edges (vl, v2), (v2, 
vg), ..., 
(vk-1, vk) are placed in sequence, then the ordered set 
( ( 7 ~ 1 ,  v2), 
(7~2, us), .. ., (vk-1, vk)} is a (directed) path from v1 to Vk. We say 
that vi is reachable from vj if there is a path from vj to vi. A reachable 
set Vi(vj) of a vertex vj is a set Vi of vertices vi reachable from the vertex 
vj E V. Carrying this a step further, we define a reachable set Vi(Vj) of a 
set Vj as a set of vertices vi reachable from at least one vertex vj E Vj. 
Therefore, Vi(Vj) is the union of the sets Vi(vj) for all vj E Vj. An an- 
tecedent set Vj(Vi) of a set Vi is a set of vertices vj from which at least one 
vertex vi E Vi is reachable. 
1.6. 
input reachable if X is a reachable set of U. 
DEFINITION. A system S with a digraph D = (U U X U Y, E) is 

8 
1. Structured Systems 
The "directional dual" of input reachability is the following: 
1.7. DEFINITION. 
output reachable if X is an antecedent set of Y. 
A system S with a digraph D = (U U X U Y, E) is 
Definition 1.6 means that if no component uj of the input vector u can 
reach (influence) a state xi either directly or via other states of S, then there 
is no way to choose an input function u(t) to drive the state xi to zero, 
which implies that the system is uncontrollable independently of numerical 
values of the nonzero system parameters. In a dual manner, Definition 1.7 
means that if a state x j  does not reach (influence) any component yi of the 
output vector y either directly or indirectly by connecting the other states 
of S, then it is impossible to determine the state xj at any given time from 
the future values of the output y and the knowledge of the input u. In this 
case, a structural deficiency (not the values of system parameters) prevents 
observability of S .  
In order to establish input and output reachability of a given system S, 
we start with the digraph D and recall (Harary, 1969) that the reachability 
matria: R = (rij) of D = (V, E) is defined as follows: 
1, 
0, otherwise. 
(1.16) 
1 
if vi is reachable from v j ,  
T i j  = { 
In other words, rij = 1 if and only if there exists a path of nonzero length 
from vj to vi; the length of a path being the number of individual edges 
between vj and v i .  
To determine the reachability matrix for a given digraph, we need the 
following result which was obtained by Festinger et al. (1950): 
1.8. 
Let E = ( e i j )  be the s x s interconnection matrix 
corresponding to a digraph D = (V, E), and let P = ( p i j )  be an s x s 
matrix such that P = Ed where d E (1, 2, . . . , s}. Then, p i j  is the total 
number of distinct sequences (vj, .), . . . , (., q) of length d in D. 
THEOREM. 
P T O O ~  We can prove this theorem by induction (Berztiss, 1975). We 
show that the theorem is true for d = 1, and then show that it is true 
for d + 1 whenever it is true for d. For d = 1, the theorem is actually the 
definition of the matrix E. For d + 1, e i k p k j  = p k j  if ( V k ,  V i )  is an edge of 
D, and e i k p k j  = 0 if it is not. The total number of sequences of length d+ 1 
having the form (vj, .), . . . , (., vk), ( V k ,  v i )  is equal to 
e i k p k j ,  which 
is the ijth element of Ed+'. 
Q.E.D. 

1.2. Input and Output Reachability 
9 
The reachability matrix can be computed by the following corollary to 
Theorem 1.8: 
1.9. COROLLARY. 
and 
If R = (rij) is the s x s reachability matrix of D 
(1.17) 
Q = E + E2 + . . . + E', 
then rij = 1 if and only if qij # 0. 
This corollary does not offer an efficient procedure to compute the reach- 
ability matrix. Instead of algebraic manipulations involved in (1.17), one 
can use the Boolean operations A and V ( l  A 1 = 1, 1 A 0 = 0 A 1 = 0 A 0 = 
0; 0 V 0 = 0, 0 V 1 = 1 V 0 = 1 v 1 = 1) to get the reachability matrix as 
R =  E V E ~ V . . . V E ~ ,  
(1.18) 
where Ek = Ek-l A E. For two s x s binary matrices A = (ai,) and 
B = (bi,), the Boolean operations C = A A B and D = A V B are defined 
by C = (qj) and D = (dij) as 
5 
qj = v (aik A bkj), 
i&j = aij V bij. 
(1.19) 
k= 1 
A more efficient Boolean-type algorithm for computing the matrix R 
was proposed by Warshall (1962): 
1.10. ALGORITHM. 
BEGIN Eo = E 
FOR i t 1 TO s DO 
FOR j t 1 TO s DO 
IF eij = 1 THEN 
FOR k t l T O s D O  
END 
The IF statement means that after the iteration with i = t 5 s, egj = 1 
if and only if there exists a path from j to k that contains only the points 
from the set { j ,  k, 1, 2, . . . , t?}. This algorithm has many useful general- 
izations (Deo, 1974). A still faster algorithm for computing the reachabil- 
ity matrix is provided by the depth-first search on a graph formulated by 
Hopcroft and Tarjan (1971) and subsequently developed by Tarjan (1972). 

10 
1. Structured Systems 
The reachability algorithms are reviewed in Notes and References (Sec- 
tion 1.7), and an efficient graph-theoretic algorithm, which is based upon 
the depth-first search, is described in the Appendix. 
Let us now turn our attention to input and output reachability. We note 
that Ed for the adjacency matrix E of the system S ,  which has the form 
(1.2), can be calculated as 
Ed = 
(1.20) 
Using this expression in (1.18), one gets the reachability matrix as 
R =  
0 0
0
,
 
[: : 
:I 
(1.21) 
where the binary matrices F, G, H ,  and 6 have dimensions obvious from 
(1.20). Of course, the matrix R could have been obtained by the Alge 
rithm 1.10, but the structure of the matrix would not have been explicit in 
terms of the system matrices. 
Fkom (1.21), the following result is automatic: 
1.11. THEOREM. A system S is input reachable if and only if the binary 
matrix G has no zero rows, and it is output reachable if and only if the 
binary matrix H has no zero columns. 
1.12. 
Fkom R of (1.21), one gets for free the additional in- 
formation about reachability properties involving only inputs and outputs. 
In (Siljak, 1978), a system S is considered input-utput 
reachable if Y is a 
reachable set of U, and U, in turn, is an antecedent set of Y. The system has 
this property if and only if the binary matrix 6 of (1.21) has neither zero 
rows nor zero columns. 
REMARK. 

1.2. Input and Output Reachability 
11 
Fig. 1.3. Input and output unreachable digraph. 
1.13. EXAMPLE. To illustrate the application of Theorem 1.11, The 
reachability matrix can be computed by the following corollary to let us 
consider a system digraph shown in Figure 1.3. The interconnection matrix 
E is 
E =  
and the corresponding reachability matrix R is computed as 
R =  
(1.22) 
(1.23) 
By comparing (1.23) with (1.21), we see that there are two zero rows 

12 
1. Structured Systems 
in G of (1.23) and the system is not input reachable. From Figure 1.3, it 
is obvious that the input u does not reach the states 23 and 2 4 .  We also 
see that H has two zero columns and, therefore, the states 2 1  and 22 do 
not reach the output y. It is easy to see what should be done to recover 
input and output reachability of S. A connection should be made from the 
existing input (or a new added input) to either 23 or 2 4  (or both). Similarly, 
the output reachability would be established if either 2 1  or 22 (or both) 
were measured to become new outputs. This type of information makes 
the graph-theoretic methods useful in the design of control and estimation 
schemes, especially for complex systems with a large number of variables. 
1.3. Partitions and Condensations 
Problems involving input and output reachability can be greatly sim- 
plified by partitioning of the given directed graph into subgraphs with as- 
signed reachability properties. By condensing each subgraph to a vertex of 
a new digraph, one can greatly increase the conceptual insight while, at the 
same time, reduce the computational effort required in the graph-theoretic 
analysis of system structures. The process of partitioning and condensing 
large graphs has been effective in diverse fields, especially in communica- 
tion networks, social sciences, and transportation systems. The use of the 
graph-theoretic decompositions in control theory is of a recent interest (see 
Chapters 6 and 7). 
Let us recall several useful notions about a directed graph D = (V,E) 
that are not necessarily related to a dynamic system. When a vertex vi is 
reachable from a vertex vj, we use the notation vjRvi. We note that R is 
a relation, and it is transitive because V j R V k  and V k R V i  imply vjRvi. We 
say that a pair of vertices (vj, vi) is strongly connected if vjRvi and v,Rvj, 
which we denote by vjRvi. It is obvious that R is an equivalence relation 
on V. F’urthermore, we can partition V into equivalence classes under R, 
unless D is strongly connected, that is, every vertex in D is reachable from 
every other vertex, and V is the only equivalence class under R. 
If D = (V,E) is a digraph and v k  is a subset of V, then the digraph Dk = 
[Vk, (Vk X Vk) n E] is a subgraph of D. That is, a subgraph Dk = (Vk, Ek) 
has the vertex set v k  as a subset of V and the edge set Ek which contains 
all the edges of E joining the vertices of v k .  
We also recall that a cycle is a path of length greater than one which 
begins and ends on the same vertex. A special edge (vi, vi) is not considered 
as a cycle and is termed a self-loop. A digraph D = (V, E) is acyclic if it has 
no cycles. 

1.3. Partitions and Condensations 
13 
1.14. 
A subgraph Dk = [Vk, (Vk X Vk) flE] is a strong 
component of D if it is strongly connected and there are no two points 
vi E v k  and wj $! 
v k  which lie on the same cycle in D. 
DEFINITION. 
Equivalence classes and strong components of a digraph are isomorphic 
concepts. They induce a partition in a given digraph and serve as a basis 
for subsequent reductions of the digraph by the process of condensation 
(2. e., clustering, aggregation), which preserves the reachability property of 
the original digraph. 
Let us consider a digraph D = (V, E) and let {Vl, V2, . . . , VN} be the 
equivalence classes of V under R. Obviously, the sets Vk are pairwise disjoint, 
that is, Vi n Vj = 0 for all i, j = 1, 2, . . . , N ,  i # j .  To each equivalence 
class v k  corresponds a strong component Dk of D. Then, we have: 
1.15. DEFINITION. Given a digraph D = (V, E), define 
V* = {Vk: 
v k  equivalence class of D}, 
(1.24) 
E* = {(Vj, Vi): ~j E Vj, vi E Vi, ( ~ j ,  
~
i
)
 
E E, Vj # Vi}. 
The digraph D* = (V*, E*) is the condensation of D. 
In other words, the condensation D* of D is the digraph whose vertices 
vi are the equivalence classes v k  and whose edges (w;, wi) E E* are deter- 
mined by the following rule: there is an edge from the vertex v; E V* to 
the vertex vt E V* in the new digraph D* if and only if there is in D at 
least one edge from a vertex of Vj to a vertex of Vi. In Figure 1.4, a graph 
D is shown together with its strong components D1 and Dz, as well as the 
condensation D*. 
The next step toward a formulation of the desired partition is the fol- 
lowing (Harary et al. 1965): 
1.16. THEOREM. Given any digraph D, its condensation D* is acyclic. 
Proof. Suppose not. Then, there is a cycle (vil, wi2), (w&, wiJ, . . ., 
(wit, wil) in D*. By the construction rule of D*, there exist two vertices 
vi., wii E vk,, i = 1, 2, ..., N ,  such that (wilt vgl), (&, wi!), ..., (wit, 
w;!) E E. Since in each strong component Dki corresponding to the equiv- 
alence class vki, there is a path from wli to vii, we conclude that the original 
digraph 
has a cycle containing the vertices 
{wil, w[', wi., wi2, 

14 
1. Structured Systems 
"I* 
v2* 
1 
i 2 
Fig. 1.4. (a) Digraph; (b) strong components; (c) condensation. 
. . . , v&, vgt}. But this is a contradiction because the vertices {vi,, vi!} and 
{vgj, vLj} belong to two distinct equivalence classes v k i  and Vk, . Q.E.D. 
Now, every acyclic digraph is a partial order because the corresponding 
relation on its vertices is irreflexive, asymmetric, and transitive. This means 
that we can assign an integer ni to each node va of the condensation D* = 
(V*, E*), which are called levels of D*. Furthermore, D* can always be made 
to have an ascending level assignment, as illustrated in Figure 1.4c, where 
n1 = 1 and 122 = 2. In order to establish this fact rigorously, we recall that 
the outdegree of a vertex vi, which is denoted by od(vi), is the number of 
edges from vi. The indegree of vi, written id(vi), is the number of edges to 
vi. We prove the following (Harary et al. 1965): 
1.17. 
An acyclic digraph D = ( V , E )  has at least one vertex 
vi E V such that od(vi) = 0, and at least one vertex vj E V such that 
id(vi) = 0. 
THEOREM. 
Proof. Assume that D has no vertices of outdegree zero. Then, we 
can start at any vertex vk, and form an arbitrarily long sequence of edges 
(vk,, Vkz), ( v k z ,  Vk3), . . . E E. Since the number of vertices of D is finite, 
we must repeat a vertex Vk,, which means that D is not acyclic. This is a 
contradiction. 
Q.E.D. 

1.3. Partitions and Condensations 
15 
Finally, we establish (Harary et al. 1965): 
1.18. 
are equivalent: 
THEOREM. For any digraph D = (V,E), the following statements 
(i) 
D is acyclic. 
(ii) 
(iii) 
There exists an order of the vertices of D so that the corre- 
sponding adjacency matrix E = (eij) is lower triangular. 
There exists a level assignment for D such that if (vj, vi) E V 
then nj < ni. 
ProoJ (i) =+ (ii). Ey Theorem 1.17, D has a vertex of indegree zero. 
One such vertex is labeled v1, and we form a new digraph D - w1 by 
truncating the vertex vl and its edges from D. The digraph D - v1 has no 
cycles because D is acyclic and, therefore, has a vertex 212 with indegree 
zero. By repeating the truncation process to form D - {vl, v2}, and locating 
v3 such that id(v3) = 0, we eventually exhaust all the vertices of D. By 
construction, there is no edge (vj, vi) E E if j 2 i, which implies that 
eij = 0 for j 2 i, and the interconnection matrix E is lower triangular. 
(ii) + (iii). Suppose E of D is lower triangular. We assign to each 
vertex vi, which correspond to the ith row and column of E, the level i. 
Since eij = 0 for j 2 i, there is no edge from any lower level to any of the 
upper levels. 
(iii) =+ (2). Suppose D has a cycle containing vj and vi with level 
assignment j and i such that j < i. Then, there is a path from vj to vi and 
a path from vi to vj, which is a contradiction, because D has an ascending 
level assignment and there are no edges from lower levels to upper levels of 
D. This means that there are no paths from vi to vj, which is a contradiction 
to the assumption that D has a cycle. 
Q.E.D. 
Since by Theorem 1.16 the condensation D* of a digraph D is acyclic, 
we can use the implications of Theorem 1.18 with regard to reachability 
properties of digraphs appearing in dynamic systems. Let us consider the 
digraph D = (UUXUY, E), and define the state truncation D, = (X, A), which 
is obtained from D by removing all the input vertices U and the output 
vertices Y as well as the edges in E connected to the vertices of U and Y. 
The adjacency matrix of D, is the Boolean n x n matrix A = (i%ij) defined 
as a submatrix of E in (1.2). We form the condensation Dj. = (X*, 
A*) and 
the interconnection N x N matrix A* = 
where N is the number of 
strong components of D,. Since Dj is acyclic, its vertices can be ordered 

16 
1. Structured Systems 
so that the interconnection matrix A* is lower triangular: 
- 
A'= 
- 0 
Zi;1 
0 
0 
ti;, 
Ci& 
0 
7Lb1 7Lb2 
... 
0 
................... 
(1.25) 
Partition of the input and output sets U and Y of D is not crucial at 
present and can be done in any convenient way. We assume that U and Y 
are partitioned in M and L pairwise disjoint sets U = {Ul, Uz, . . . , UM} and 
Y = {Yl, Yz, . . . , YL}. We already have the partition X = {XI, Xz, . . . , XN}, 
where Xi corresponds to the ith strong component. Now, we can form a 
condensation D* = (v' U X* U Y*, E*) whose vertices z:, 
uT, and y,' are the 
subsets $, Ui, and Yi. Of course, Ui and Yi are not necessarily equivalence 
classes in D, 
but Xi's are. This fact will be used soon. 
With D* we associate the interconnection matrix 
2 B* 0 
0
0
 
E*= [;* 
0 
01 > 
where the Boolean matrix B* = (b;) has Qj = 1 if and only if there is 
an edge in D from a vertex of Uj to a vertex in the equivalence class Xi. 
Likewise, 
= (qj) and cj = 1 if and only if there is an edge from X j  to 
Yi. The matrix A* is lower triangular as shown in (1.25). 
Finally, we arrive at a simple but important result: 
(1.26) 
1.19. THEOREM. A digraph D = (U U X U Y, E) is input (output) 
reachable if and only if its condensation D* = (U* U X' U Y*, E*) is input 
(output) reachable. 
Proof. We prove only the input reachability part of the theorem, be- 
cause the output reachability part is its directional dual. If D* is input 
reachable then X* is the reachable set of U*, and there is a path to each 
point of X* from a point of U*. Since Df is the condensation of D,, it follows 
from reachability of components that there is a path to each point of X from 
a point of U. That is, X is the reachable set of U and D is input reachable. 
Conversely, if D* is not input reachable, then X* is not the reachable set of 
v', and there are points of X* that cannot be reached by any point of U*. 

1.3. Partitions and Condensations 
17 
Obviously, by the definition of condensation, those points of X that corre- 
spond to the unreachable points of X* cannot be reached by any point of U 
and D is not input reachable. 
Q.E.D. 
With an abuse of Definitions 1.6 and 1.7, we refer to input and output 
reachability of the digraphs D and D* instead of the system S. This removes 
ambiguity arising from the fact that both the digraph D and its condensa- 
tion D* belong to the same system S. This change, however, should cause 
no confusion since input (output) reachability is defined unambiguously in 
a given digraph. 
1.20. EXAMPLE. To illustrate Theorem 1.19 by a simple example, let 
us consider the digraph D of Figure 1.5a. Since D, corresponding to D is 
given in Figure 1.4a, the strong components of D, are D1 and Dz shown in 
Figure 1.4b. The condensation D' of Figure 1.5b indicates that the digraph 
D is input reachable, but it is not output reachable: The two inputs u; 
and uz reach the two super-states z; and z$ of D*, while the super-state 
xz does not reach the output y*. 
We should note here that if we had lumped the two input vertices u1 
and u2 into a single super-vertex u;, 
then the condensation D; would have 
been that of Figure 1.6. Information on input reachability would have heen 
unchanged, but the fact that each super-state has its own independent input 
would have not been obvious as in D* of Figure 1.5b. How to decompose 
best the inputs once the strong components are identified will be explained 
in Chapter 6, when we present the hierarchical decomposition scheme for 
complex systems. 
Results, which are formulated on digraphs, can always be rephrased in 
terms of interconnection matrices, and Theorem 1.19 is no exception. We 
have: 
1.21. COROLLARY. A system S with an aggregate interconnection ma- 
trix E* is input reachable if and only if the composite matrix 
E; = [A* E*] , 
(1.27) 
has no zero rows, and it is output reachable if and only if the composite 
matrix 
(1.28) 
has no zero columns. 

18 
1. Structured Systems 
F 
L 
7 T  

1.3. Partitions and Condensations 
19 
x2* 
Fig. 1.6. Condensation. 
Of course, it is assumed that the matrix A* in (1.27) and (1.28) has 
already a lower triangular form as in (1.25). Then, Corollary 1.21 is obvious 
from Theorem 1.19. For the example of Figure 1.5, this means that the 
matrices Ef and E; are obtained as 
0 o i  1 
c”1 o i  11 
and 
(1.29) 
(1.30) 
As expected, by applying Corollary 1.21 we conclude from (1.29) that the 
system S is input reachable, but it is not output reachable because of a 
zero column in (1.30). 
Algorithms for determining strong components of a graph have a long 
history. Among the pioneers in this area is Harary (1959) who used Boolean 
multiplication of matrices to arrive at the reachability matrix that re- 
veals the strong components of the graph. A way to speed up the cal- 
culation of the reachability matrix is to use the popular Algorithm 1.10 of 
Warshall (1962). Improvements of this algorithm were proposed by Pur- 
dom (1970) and Munro (1971), who solved for strong components as a 
subproblem of the more general problem of transitive closure, which con- 
sists in determining all paths through a directed graph. These improve- 
ments were only slight having O(n2) operations at best, where n is the 
number of the nodes in the digraph. The most efficient algorithm is the 
“depth-first search” of Tarjan (1972), which detects the strong components 

20 
1. Structured Systems 
in O(max{n, e}) time for a graph of n nodes and e edges. Gustavson (1976) 
and Duff and Reid (1978a, b) have implemented Tarjan’s algorithm with 
efficiency superior to existing codes. A version of Tarjan’s algorithm is de- 
scribed in the Appendix. 
In partitioning a system digraph into strong components, our interest 
focused on simplifying the interpretation and computation of input and out- 
put reachability. It is more or less obvious that this type of partition induces 
a decomposition of the associated system into interconnected subsystems 
and, therefore, have potential applications in “piece-by-piece” stabilization 
and control of large systems (Vidyasagar, 1980). The use is limited, how- 
ever, because partitions of this kind ignore the inputs and outputs of the 
system, and the lack of a suitable distribution of inputs and outputs over 
the subsystems may prevent a decentralized control design. More sophisti- 
cated decomposition schemes, with special attention to inputs and outputs, 
are described in Chapters 6 and 7. 
1.4. Structural Controllability and Observability 
For control problems to be properly formulated so that a useful solu- 
tion can be expected, the plant should be controllable and observable. This 
fundamental result of Kalman (1963) has been further strengthened by the 
fact that controllability and observability are robust properties in linear 
constant plants (Lee and Markus, 1961). That is, the set of all controllable 
pairs (A, B) is open and dense in the space of all such pairs. This fact was 
exploited by Lin (1974) in formulating his concept of structural controllabil- 
ity, which states that all uncontrollable systems structurally equivalent to a 
structurally controllable system are atypical. Not only is this concept con- 
sistent with physical reality in the sense that values of system parameters 
are never known precisely, but it is also helpful in testing the properties of 
controllability using only binary computations. It is a well-known fact that 
testing controllability is a difficult numerical problem (Nour-Eldin, 1987), 
and structural controllability offers a computable alternative especially for 
systems of high dimensions. The same facts hold for observability for it is 
the dual of controllability. 
In order to present the concept of structural controllability, let us first 
introduce the notion of a structured matrix a. 
1.22. 
An n x m matrix a*= 
( k i j )  is said to be a struc- 
tured matrix if its elements m i j  are either fixed zeros or independent free 
parameters. 
DEFINITION. 

1.4. Structural Controllability and Observability 
21 
For example, a 2 x 3 structured matrix is 
(1.31) 
To relate a numerical n x m matrix M = (mij) to a structured matrix 
fi = (fhij) we define n = (1, 2, . . . , n}, m = (1, 2, . . . , m} and state the 
following: 
1.23. 
A numerical matrix M is said to be admissible with 
respect to a structured matrix M ,  
that is, M E M, 
if and only if m i j  = 0 
implies mij = 0 for all i E n and j E m. 
DEFINITION. 
The matrix 
.I=[' 
0 0 -1 
(1.32) 
is admissible with respect to fi of (1.31), but neither of the matrices 
O
P
O
 
Q
P
O
 
[- 0 11' [. 
0 01 
(1.33) 
is admissible, where Q and P are independent free parameters. 
us associate with a system 
To state the definition of structural controllability and observability, let 
S k=A~a:+Bu, 
y = cx, 
a structured system S = (A, B, C) so that (A, B, C) E (A, B, C). Struc- 
tural controllability of the system S is defined via the pair (A, a) as in 
(Lin, 1974): 
1.24. 
A pair of matrices (A, B) is said to be structurally 
controllable if there exists a controllable pair (A, B) such that (A, B) E 
DEFINITION. 
(A, B). 
Similarly, 
1.25. 
A pair of matrices (A, C) is said to be structurally 
observable if there exists an observable pair (A, C) such that (A, C) E 
DEFINITION. 
(A, B). 

22 
1. Structured Systems 
In order to state the necessary and sufficient conditions for structural 
controllability and observability of S ,  we need the notion of generic rank (or, 
term runk) of a structured matrix M, 
which we denote by ij(M). Simply, 
the generic rank of it? is the maximal rank that h;r can achieve by choosing 
numerical values for indeterminate elements of #. Therefore, a matrix M 
has full generic rank if and only if there exists a matrix M of full rank such 
that M E M. 
To make the idea of the generic rank precise, we need certain notions 
from algebraic geometry (Wonham, 1979). Let us assume that a matrix M 
has elements in R, there are u indeterminate entries, and the rest of the 
entries are fixed zeros. Then, with M we can associate a parameter space 
R” such that every data point p E R” defines a matrix M E h;r(p), which is 
obtained by replacing the arbitrary entries %ij of M by the corresponding 
elements of p = ( P I ,  p2, . . . , P , ) ~ .  In a physical problem, it is important to 
know that if a matrix M has a certain rank at a nominal parameter vector 
p”, it has the same rank at a vector p close to p”, which corresponds to 
small deviations of the parameters from their nominal values. Most often, 
it turns out that the rank holds true for all p E R” except at the points 
p that lie on an algebraic surface in R” and which are, therefore, atypical. 
An arbitrarily small perturbation of such points restores the rank of M .  
Let us denote by Pk(p1, pz, . . . , pu), k E K, K =  (1, 2, . . . , K } ,  a set 
of K polynomials generated by all the rth order minors of M ,  and consider 
a variety V C R which is the locus of common zeros of the polynomials (Pk: 
V = { P  E R”: (Pk(Pl,?%, . - . , P v ) = O ,  k E K). 
(1.34) 
The variety V is proper if V # R” and nontrivial if V # 0. We say that the 
rank r of the matrix M holds generically relative to V when the parameter 
values, which make the rank of M smaller than r, all lie on a proper variety 
V in R”. In other words, the variety V is either the whole space R” in 
which case P(M) < r; or the complement V“ of V is open and dense in 
R” and, therefore, generic. What this means is that, if the rank condition 
fails at p” E R”, then the condition can be restored by an arbitrarily small 
perturbation of the parameter vector p .  
Conditions for structural controllability of S are stated in terms of the 
matrix pair (A, B). To formulate these conditions, we need the following 
two definitions introduced by Lin (1974): 
1.26. DEFINITION. 
ists an n x n permutation matrix P such that 
A composite matrix [A B] has Form I if there ex- 
P[A B] 
(1.35) 

1.4. Structural Controllability and Observability 
23 
where All is q x q, A 2 2  is (n - q) x (n - q), B2 is (n - q) x m, and 
O<q<n. 
In view of Definition 1.4, we consider a composite matrix [A B] of a 
system S to be in Form I if S is structurally equivalent to a system having 
a composite matrix which appears on the right side of Equation (1.35). 
1.27. DEFINITION. A composite matrix [A B] has Form I1 if 
b([A B]) < n. 
(1.36) 
The following result concerning structural controllability was initiated 
by Lin (1974) and established later by Shields and Pearson (1976) and 
Glover and Silverman (1976): 
1.28. 
if [A B] has neither Form I nor Form 11. 
THEOREM. A pair (A, B) is structurally controllable if and only 
We do not prove this theorem here. It appears as an easy Corollary 1.57 
to Theorem 1.52 which is concerned with a more general problem of struc- 
turally fixed modes. 
An automatic dual to Theorem 1.28 is the following: 
1.29. 
if [AT 67 has neither Form I nor Form 11. 
THEOREM. A pair (A, 6) is structurally observable if and only 
We observe that Forms I and I1 are purely structural forms concerning 
the distribution of fixed zeros and indeterminate elements of the matrices 
A and B, which suggests that they can be tested using graph-theoretic 
concepts. Before we present graph-theoretic conditions for structural con- 
trollability and observability, let us look at several examples. 
1.30. EXAMPLE (Kailath, 1980). Two inverted penduli of lengths !I 
and !z 
having the bobs of mass m are mounted on a cart of mass M as 
shown in Figure 1.7. For small angle deviations O,(t) and &(t) the equations 
of motion are 
S: M v  + mgOl+ mg02 = U ,  
m(v + !,el) - mgOl = 0, 
m(v + c2&) - mgo2 = 0, 
(1.37) 

24 
1. Structured Systems 
m 8 
m 
u +  
M 
Fig. 1.7. Inverted penduli on a cart. 
where v ( t )  is the velocity of the cart and u(t) is the external force acting 
on the cart. Is the system S controllable by u(t)? That is, can the penduli 
be kept in the upright position (81 x 0, 82 x 0) by moving the cart? 
Choosing the state vector x E R4 as x = (81, 41, 82, 4 ~ ) ~  
and eliminat- 
ing 8, we get from (1.37) the state equations as 
S X = A x + h ,  
where 
A =  
and 
1 
0
1
0
0
 
a21 
0 
a23 0 , 
b =  
0
0
0
1
 
:I 0 
b4 
(1.38) 
(1.39) 
(1.40) 

1.4. Structural Controllability and Observability 
25 
*4 
Fig. 1.8. System digraph. 
We compute 
det([b Ab]) = -(a - p)2, 
(1.41) 
where 
Therefore, det( [b Ab]) = 0 if and only if a = p, that is, 
e, = e2. 
(1.43) 
In other words, the system S is uncontrollable when the lengths of the two 
penduli are equal, which is physically difficult, if not impossible, to achieve. 
Controllability of S is generic. The property fails on a proper variety V 
in the space of physical parameters, which is defined by condition (1.43). 
To confirm the above finding in terms of structural controllability, we 
first present the system digraph D on Figure 1.8. It is clear that the system 
S is input reachable, that is, the composite matrix [A i] is not in Form I. 
If we write the structured composite matrix 
(1.44) 

26 
1. Structured Systems 
we observe that the elements €3 guarantee 
b([A i]) = 4, 
(1.45) 
and [A 61 is not in Form 11. The system S is structurally controllable as 
predicted. 
It is important to note, however, that in testing structural controlla- 
bility, we ignored the fact that elements of the matrices A and b of (1.39) 
are not independent. In certain cases, ignoring the parameter dependencies 
may cause errors since a system may be structurally controllable when, in 
fact, it is not controllable (see Example 1.34 and Remark 1.35). 
Let us now go back to Theorem 1.29 and discuss the meaning of Forms I 
and 11. 
1.31. 
It is easy to see that the system S has Form I if and 
only if it is not input reachable. If there is a set x k  of state nodes in D 
which cannot be reached from the input nodes U, we can transform the 
matrix [A B] into the form (1.35) by permuting its rows and columns until 
the first k rows and columns of the transformed matrix correspond to the 
set x k .  Conversely, if [A B] has the form (1.35), then the state nodes cor- 
responding to the submatrix All cannot be reached from any of the input 
nodes of D. Therefore, to test khe system S for Form I is equivalent to 
testing D for input reachability, which is an easy computational problem 
(see Appendix). In case of rank deficiency (1.36), the system S has Form 11, 
which is equivalent to saying that the corresponding digraph D has a dila- 
tion (Lin, 1974): A digraph D = (UUX, E) is said to have a dilation if there 
exists a subset Xk g X such that the number of distinct vertices of D from 
which a vertex in XI, is reachable is less than the number of vertices of x k .  
In matrix terms, this means that the corresponding structured n x (n + m) 
matrix [A B] contains a zero submatrix of order r x (n + m + 1 - r )  for 
some r such that 1 5 r 5 n. A numerical procedure to determine generic 
rank deficiency, that is, the existence of dilation, is given in the Appendix. 
Uncontrollability due to lack of input reachability needs no explanation. 
It is a simple disconnection of inputs from states. Although input unreach- 
ability is a simple cause of uncontrollability, in physical systems, it is the 
basic one. The other is the generic rank deficiency which we illustrate next. 
1.32. EXAMPLE. A very simple example of an uncontrollable system 
due to rank deficiency is 
REMARK. 
A =  [' '1, 
b =  
0
0
 
(1.46) 

1.4. Structural Controllability and Observability 
27 
Fig. 1.9. Dilation. 
Fig. 1.10. No dilation. 
The corresponding matrix 
[A 9 = [ O  o o *  
O *I, 
(1.47) 
has Form 11. The digraph D is shown in Figure 1.9, which proves that we 
have input reachability, but D([A i]) < 2. The digraph D has a dilation. 
It is of interest to note that if we add a self-loop as in Figure 1.10, the 
modified digraph fi has no dilation. 
1.33. 
Figure 1.11, then the state equation is 
EXAMPLE. If L1 and L2 are pure inductors in the network Of 
0
0
 
0 
1IL1 
s: x =  [o 0 
0 
] x +  [ l/L2]u, 
(1.48) 
0 0 -1IRC 
1IRC 

28 
1. Structured Systems 
Fig. 1.11. Electrical network. 
Fig. 1.12. Digraph with dilation. 
and the composite matrix [A &] is obtained as 
resulting in P([A 61) < 3. The digraph D of Figure 1.12 has a dilation, 
because the matrix in (1.49) has a zero submatrix of order 2 x 3. 
On the other hand, if the inductors, L1 and L2 have resistance TI and 
7-2, then the state equation is 

1.4. Structural Controllability and Observability 
29 
Fig. 1.13. Digraph without dilation. 
R 
Fig. 1.14. Electric circuit. 
and 
B
O
O
*
 
(1.51) 
indicating $([A 61) = 3. The corresponding digraph D of Figure 1.13 has 
no dilation. Since D is also input reachable, the system S of (1.50) is 
structurally controllable. 
1.34. EXAMPLE. A notorious cause of uncontrollability is an erroneous 
choice of state variables. For a circuit in Figure 1.14, we select 
(1.52) 
Cl 
CZ 
21 = 01, 
22 = 02 - -01, 

30 
1. Structured Systems 
Fig. 1.15. Digraph D . 
and get the system 
s: x =  
(1.53) 
which is both input unreachable and rank deficient as expected, because 
the choice (1.52) is not appropriate (the circuit has only one state). If we 
choose the states 
5, = 211, 
5 2  = 212, 
(1.54) 
which is also wrong, we get 
Now, the digraph D for the system S in Figure 1.15 is both input reachable 
and has no dilation and, therefore, implies that S is structurally control- 
lable when, in fact, S is an uncontrollable system. The entries in S are 
interdependent, which is the fact that the digraph D ignores and, thus, 
it fails to identify the uncontrollability of the system S. The central issue 
seems to be a suitable choice of the state variables so that the system ma- 
trices contain the fewest generically dependent parameters. Obviously, the 
representation S contains no such parameters, while the representation S 
does. In fact, s has only two independent parameters. The parametrization 
problem has been considered in (Corfmat and Morse, 1976; Anderson and 
Hong, 1982). 

1.5. Plant and Feedback Structures 
31 
1.35. REMARK. From Example 1.34 we learn that parameter depen- 
dencies may invalidate the conclusions obtained by structural analysis, 
which is a drawback of the concept of structural controllability and observ- 
ability. We should note, however, that our primary goal is to use the concept 
of input and output reachability to formulate decomposition schemes for 
large dynamic systems (see Chapters 6 and 7). For this purpose, the manip 
dative capabilities of graphs are superior to any other approach. Equally 
important is the fact that controllability and observability (not necessarily 
structural!) of a decomposed system can be checked via low-order subsys- 
tems. 
It remains to be discussed which algorithms can be used to test generic 
rank of the composite structured matrix [A B]. There has been a long his- 
tory of the problem of finding the maximum number of nonzero elements of 
a matrix, no two of which lie in the same row or column. The permutation 
that puts these nonzero elements on the diagonal has been given various 
names such as selecting the maximum transversal, finding the complete, 
perfect, or maximum matching in bipartite graphs, determining a distinct 
representative, seeking an output set, etc. A survey of the relevant results 
and algorithms is available in a paper by Duff (1977) who provides an algo- 
rithm (Duff, 1981a) and a code in FORTRAN (Duff, 1981b). See also the 
discussion of the computational complexity of various algorithms presented 
by Duff (1981a). A version of Duff’s algorithm is given in the Appendix. 
1.5. Plant and Feedback Structures 
An essential assumption in our studies is that a plant is composed of 
interconnected subsystems. This assumption is made for two distinct rea- 
sons. First, physical plants are made up of parts and by identifying in- 
dividual parts, or groups of parts, as subsystems, we can take advantage 
of the structural features of the system in a control design. Second, we 
may ignore the physical boundaries of components and decompose a large 
system into “mathematical” subsystems which have no obvious physical 
identity. This type of decomposition can bring about a considerable sav- 
ings in computer memory and time when systems of high dimensions are 
involved. Both kinds of partitions of dynamic systems, which are termed 
physical and mathematical decompositions (Siljak, 1978), will be of central 
interest throughout this book. At this point, we only want to identify basic 
structures that are common in modeling of complex systems. 

32 
1. Structured Systems 
Let us consider again the linear constant system 
S: X = A X + B U ,  
y = c x ,  
which we assume to be partitioned into N interconnected subsystems 
N 
y .  
1 - 
- c. 
2x2 +C Cijxj, 
j=1 
with decoupled subsystems identified as 
(1.56) 
i E N, 
Si: Xi = A i ~ i  + Biui, 
(1.57) 
yz = cixi, 
i E N, 
where xi(t) E Rni, ui(t) E Rmi, yi(t) E Rei are the state, input, and 
output of the subsystem Si at a fixed time t E R, and N = (1, 2, . . . , N } .  
At present we are interested in disjoint decompositions, that is, 
R" = R"' x R"' x ... x RnN, 
R"=R"' 
xRmz x . . . x R n N ,  
(1.58) 
Re = Re' x Rez x . . . x ReN 
01, 
N 
N 
N 
n=C nil 
m - x  mi, e=x 
t i  
(1.59) 
i=l 
i=l 
i=l 
and 
T 
T 
x = ( x l ,  xcif, . . . , 2;) , 
T 
T 
21 = ( u l ,  u;, . . . 1 u;) , 
T
T
 
Y = ($7 
&r 
. . ., Y N )  
are the state, input, and output vectors of S. 
(1.60) 

1.5. Plant and Feedback Structures 
33 
m 
1 
m 
m 
Fig. 1.16. Inverted penduli. 
1.36. EXAMPLE. To illustrate a physical decomposition of a dynamic 
system, let us consider two identical penduli that are coupled by a spring 
and subject to two distinct inputs as shown in Figure 1.16. The equations 
of motion are 
me2& = mgeel - ka2(01 - e,) + ul, 
me2& = mgee2 - ka2(02 - 0,) + u,, 
y1 = el, 
I/Z = e2. 
(1.61) 
Choosing the state vector as 2 = (01, el, 62, 82) and denoting u = (u1, ~
2
)
~
~
y = (91, ~ z ) ~ ,  
(1.61) can be rewritten as 
1
o
i
o
o
 
The digraph D of the system S is shown in Figure 1.17. 
(1.62) 

34 
1. Structured Systems 
Fig. 1.17. System digraph. 
A physical decomposition of S along the dashed lines produces a repre- 
sentation (1.56) as 
which is an interconnection of two subsystems 
0
1
 
sz: .2 
= [ 
Q: 0] x 2  + [ ;] 
uz, 
(1.64) 

1.5. Plant and Feedback Structures 
35 
Fig. 1.18. Condensation. 
each representing a single decoupled pendulum. The subsystem state vec- 
tors are obviously x1 = (el, el)T and 2 2  = (02, bJT, and the system param- 
eters are cr = g/e, p = l/mL2, and 7 = a 2 k / d 2 .  The interconnected 
system S of (1.63) can be represented by a condensation digraph D* in an 
obvious way as shown in Figure 1.18. It is important to note that in form- 
ing D' we used the individual penduli as subsystems rather than strong 
components as specified by Definition 1.15. Since the entire state trunca- 
tion D, of the system digraph D of Figure 1.17 is a strong component, no 
decomposition of S in the sense of Section 1.3 is possible. The physical and 
mathematical decompositions are two distinct concepts. More on physical 
decompositions will be said in Chapter 8, while mathematical decomposi- 
tions is the subject of Chapter 6 and 7 of this book. 
An important feature in this example is that the matrices Bij and Cij 
of (1.56) are all zero. According to the terminology introduced by Siljak 
(1978), the fact that Bl2 = 0, B21 = 0 (each input u1 and 212 applies to 
the respective subsystem S1 and Sz only) makes the system S of (1.63) an 
input decentralized system. Since C12 = 0 and C21 = 0, S is also an output 
decentralized system. 
On various occasions it is convenient to use a compact notation for the 
composite system S of (1.56): 
S: X = ADX + BDU + ACX + BCU, 
(1.65) 

36 
1. Structured Systems 
where 
AD = diag(A1, A2, . . . , A N } ,  
30 = diag(B1, B2, . . . , BN}, 
(1.66) 
Cn = diag(C1, c2, . . . , CN}, 
and the coupling block matrices are 
Ac = (Aij), 
Bc = (Bq), 
Cc = (Cij). 
(1.67) 
The collection of N decoupled subsystems is described by 
(1.68) 
which is obtained from (1.65) by setting the coupling matrices to zero. 
S = (AD, BD, CD, 
Ac) is represented by 
An important special class of input and output decentralized systems 
S: X = A ~ x  
+ BDU + ACX, 
(1.69) 
Y = cox, 
where Bc = 0 and Cc = 0. The inverted penduli of Example 1.36 belong 
to this class of models. 
With the notion of a decentralized plant firmly in place, we are ready 
to formulate the decentralized constraints on feedback control laws. We 
step back first and recall the well-known and useful fact that the behavior 
of a linear plant S of (1.1) can be altered efficiently by feedback without 
changing the plant itself. The principle of feedback is to choose the inputs 
of the plant as functions of the outputs or states and achieve stability, 
optimality, robustness, etc., of the closed-loop system (e.g., Kailath, 1980). 
A linear constant control law for the original plant S of (1.1) can be 
chosen as the static output feedback 
u = -Ky, 
(1.70) 
where the constant output gain matrix K = (kij) has dimension m x i! 
and feedback coefficients kij. By applying the control law (1.70) to S ,  we 
obtain the closed-loop system 
S: X = (A - BKC)s. 
(1.71) 

1.5. Plant and Feedback Structures 
37 
The structure of S can be effectively studied by introducing the feedback 
interconnection matrix K = ( & j )  with elements defined as 
(1.72) 
The interconnection matrix E of (1.2) with K included is the interconnec- 
tion matrix E of the closed-loop system S: 
(1.73) 
When a dynamic output feedback is used, we define for each input ui of 
S in (1.1) an index set 
Ji = {j : rcij = l}, 
i E M, 
(1.74) 
where M = (1, 2, . . . , m}, and apply the time-invariant dynamic con- 
trollers of the form 
where zi(t) E RT' is the state of the controller Ci, and Fi, gij, hi, and kij 
are constant matrices, vectors, and scalars. 
A special case of the output feedback constraints is the decentralized 
feedback structure, where the sets U = { U I ,  UZ, . . . , urn} and Y = 
{yl, y2, . . . , ye} are partitioned into N disjoint subsets 
(1.76) 
and where the feedback structure constraint is such that kij = 1 if and only 
if ui E U, and yj E Y, for some r E N. 

38 
1. Structured Systems 
When no decomposition is used, we describe S as 
(1.77) 
yi = C~X, i E N, 
where z(t) E R" is the state of S N ;  ui(t) E Rn' and yi(t) E Reil i E N, 
are the inputs and outputs of S N ;  and A, Bi, Ci are constant matrices of 
appropriate dimensions. By defining the block matrices 
and using the decentralized control law 
or equivalently, 
u = -KDY, 
KD = diag(K1, Kz, . . . , KN}, 
(1.80) 
we obtain the closed-loop system 
SN: X = ( A  - B N K ~ C N ) a :  
. 
(1.81) 
When dynamic output feedback is used with decentralized constraints, 
then controllers of the following type are used: 
Ci: .& = Fizi + Giyi, 
(1.82) 
u. 
z. - 
- -H.z. 
i z - K- 
iYa> 
. 
i E N, 
which can be written in a compact form as a single decentralized controller 
CD = (FD, Go, HD, KD) defined as 

1.5. Plant and Feedback Structures 
39 
and 
F = diag(F1, F2, . . . , FN}, 
H = diag(H1, H2, . . . , H N ) ,  
G = diag(G1, Gz, . . . , G N } ,  
K = diag(K1, Kz, . . . , K N ) .  
(1.85) 
Then, the closed-loop system is defined as a composite system 
We recognize the fact that in case of the open-loop system S N  of (1.77), 
which is characterized by the triple (A, B N , CN), the system is not decom- 
posed into subsystems and the system matrix A is considered as a whole. 
It is only feedback (static or dynamic) that is decentralized. In modeling of 
complex systems this is not enough, and we require total decentralization 
of both the plant and the control. In this way, we are able to capture the 
effects of the essential uncertainty residing in the interconnection structure 
on the behavior of the overall system. Furthermore, decompositions and 
decentralizations, when combined together, can bring about a considerable 
increase in speed of computation (on- and off-line), as well as reliability of 
operation in control of complex systems (see Chapter 9). For these reasons, 
we devote our attention almost entirely to situations when the decentral- 
ized control law (1.80) is applied to the fully decentralized system S of 
(1.69), which is characterized by the quadruple (AD, BD, 
CD, Ac). The 
closed-loop system is described as 
S: 2 = (AD - BDKDCD)X + AGX. 
(1.87) 
In case local dynamic controllers Ci are used, we combine S and C D  to 
get the composite closed-loop system as 
Obviously, a decomposed system with input and output decentralization 
So = (AD, BD, CD, Ac) is a more restrictive structure than the “quasi- 
decentralized system” S N  = (A, B N , C N )  without decompositions, as it is 

40 
1. Structured Systems 
always possible to describe the former class as a special case of the later 
class of systems, but not the other way around. The fully decentralized 
structure with interconnection uncertainties makes the control design more 
difficult involving a variety of conditions (most of them sufficient) for robust 
stabilizability of interconnected systems. There is, however, an essential 
necessary condition for stabilizability of both classes of systems, given in 
terms of structurally fixed modes, which is derived in the following section. 
1.6. Structurally Fixed Modes 
Since the early work of McFadden (1967) and Aoki (1972), the stabi- 
lization problem under decentralized information structure constraints has 
attracted considerable attention. The concept of decentralized fixed modes 
has been introduced by Wang and Davison (1973) to obtain necessary and 
sufficient conditions for stabilizability of decentralized systems, where only 
the feedback is decentralized but the plant is treated as a whole. Later, 
Corfmat and Morse (1976) and Anderson and Clements (1981) achieved a 
more refined characterization of the fixed modes and a deeper insight into 
the problem of decentralized control of the same type of linear systems. A 
number of characterizations of decentralized fixed modes have been later 
proposed by Anderson (1982), Vidyasagar and Viswanadham (1982), and 
Davison and Ozgiiner (1983), which have led to existence conditions in- 
volving difficult numerical problems of rank or eigenvalue computations. 
As in the case of an uncontrollable or unobservable mode, a decen- 
tralized fixed mode can originate from two distinct sources: it is either a 
consequence of a perfect matching of system parameters (in which case, a 
slight change of parameters can eliminate the mode), or it is due to a special 
structure of the system (in which case, the mode remains fixed no matter 
how much the parameters are changed as long as the original structure 
is preserved). From a physical point of view, only the latter type of fixed 
modes are important, not only because it is very unlikely to have an exact 
matching of parameters, but also because it is not possible to know whether 
such a matching occurs or not. This type of structurally f i e d  modes have 
been defined and characterized by Sezer and Siljak (1981a, b) for arbitrary 
feedback patterns including output and decentralized control. 
An obvious advantage offered by the concept of structurally fixed modes 
is numerical. Since existence of such modes is a qualitative structural prop 
erty of the system, it can be characterized in terms of directed graphs 
leading to computationally attractive tests involving binary computations 
only (Pichai et al. 1983, 1984; Linnemann, 1983). 

1.6. Structurally Fixed Modes 
41 
Consider again the system S = (A, B, C )  described by 
S: k = A x + B u ,  
y = c x ,  
and define a set of constant output feedback matrices 
which can be used in the control law 
u = -Ky. 
(1.70) 
By A( 0 )  we denote the set of eigenvalues of a given matrix. 
1.37. DEFINITION. The set 
(1.90) 
is the set of fixed modes of the system S = (A, B, C )  with respect to a 
feedback structure K. 
1.38. REMARK. This definition is a generalization of the notion of de- 
centralized fixed modes given by Wang and Davision (1973) to the case of 
arbitrary feedback structure constraints. The decentralized fixed modes of 
SN is the set 
L ~ ,  
= n A ( A - B N K ~ C N ) ,  
(1.91) 
K
D
~
D
 
where KO is a block diagonal matrix of (1.85) and KD is a class of all such 
matrices. 
Stabilizability of S under arbitrary structure constraints specified by 
the controller C, 
which is the union of the individual controllers 
(1.75) 
i E M, 

42 
1. Structured Systems 
is determined by the following: 
1.39. THEOREM. The system S = (A, B, C) can be stabilized by the 
controller C if and only if the set of fixed modes L, contains no elements 
with nonnegative real parts. 
Proof. Define an N = rn channel system SN = (A, B N ,  CN), where 
A = A, BN = B, CN = (Cr, CT, . . . , Cz)T, 
(1.92) 
and C i  consists of those rows of C with indices in Ji of (1.74). Then, for 
any K E lc, 
m 
= A - C bi 
kijcj 
i=l 
(.i.J. ) 
(1.93) 
where k; = ( k i j l ,  kij2, . . .), j 1 ,  j , ,  . . . , E Ji, i E M, and bi and CT denote 
the ith column of B and jth row of C, 
respectively. From (1.93), it is clear 
that L, = t,,, where &, is the set of decentralized fixed modes of S N ,  
and the proof follows from the main theorem of Wang and Davison (1973) 
on decentral stabilizability of the system S N .  
Q.E.D. 
To complete our consideration of stabilizability of S ,  we give an alge- 
braic characterization of the fixed modes C, of (1.90). For this purpose, we 
define the sets M =  (1, 2, . . . , m}, L = (1, 2, . . . , l } ,  and for an arbitrary 
subset I = (21, iz, . . . , ip} of M, we form a set 
(1.94) 

1.8. Structurally Fixed Modes 
43 
where Ji = {jl, j,, . . . , jq}. For example, if m = 5 and C = 4, 
(1.95) 
and I = (1, 2, 3}, then J = 54 U 5 5  = (1, 4) u (3, 4) = (1, 3, 4). Now, 
introducing the matrices 
BI = (bil7 biz7 * .  ., bi,), c, = (cjl, Cjar . . ., ~
j
,
)
~
 
, 
(1.96) 
and recalling that p( 0 )  denotes the rank of a given matrix, we prove the 
following: 
1.40. 
A complex number X is a fixed mode of the system 
S = (A, B, C) with respect to a feedback structure I? if and only if there 
exists a subset I c M such that 
THEOREM. 
p ([ ' i J X I  "1) 
< n. 
(1.97) 
PTOOf. Consider the system SN defined in the proof of Theorem 1.39. 
By Theorem 4.1 of Anderson and Clements (1981), X E L R ~  
if and only 
if there exists an I c M such that 
A -  XI 
BI 
(1.98) 
p ( [  CMPI 0 1 )  < n ,  
where CMPI = (Cc, Cz, . . . , C&-p)T with {i;, ii, . . . , ik-p} = M - I. 
Noting that any < is a row of CM-I if and only if it is a row of Cj, we 
establish the equivalence of (1.97) and (1.98). The proof follows from the 
fact that LR = Lz., as shown in the proof of Theorem 1.39. 
Q.E.D. 
Although Theorem 1.40 provides a complete characterization of fixed 
modes, in practice it is impossible to identify all such modes because of 
inexact knowledge of the system parameters. For this reason, structurally 
fixed modes are significant because they occur as a result of physical dis- 
connections between the system and some controllers (or parts of a single 
controller), and remain fixed unless the control structure is modified. 

44 
1. Structured Systems 
Given a structured system S = (A, B, c), we call a system S = 
(A, B, C )  admissible if (A, B, C) E (A, B, e). Then we are interested 
in the following: 
1.41. 
A structured system S = (A, 8, 
6) is said to have 
structurally fixed modes with respect to a feedback structure K if every 
admissible system S = (A, B, C )  has fixed modes with respect to K. 
DEFINITION. 
In the spirit of structural controllability and observability (Definitions 
1.24 and 1.25) the above definition can be restated as: A structured system 
S = (A, B, C) has no structurally fixed modes with respect to a feedback 
structure K if there exists an admissible system S = (A, B, C )  which has 
no fixed modes with respect to K. In terms of structural equivalence (Def- 
inition 1.4) this means that a system S = (A, B, c) has structurally fixed 
modes with respect to 
if every system structurally equivalent to S has 
fixed modes with respect to K. 
In this way, the notion of structurally fixed 
modes is concerned with an equivalence class of systems rather than a par- 
ticular member of the class and, therefore, keeps the atypical fixed modes, 
which arise from perfect matching of parameters, out of considerations. 
1.42. EXAMPLE. To illustrate the notion of structurally fixed modes, 
let us consider a system S = (A, B, C )  defined as 
1
2
0
 
0
1
0
 
(1.99) 
which is controllable and observable. Let the feedback structure constraint 
be specified as 
(1.100) 
Then, the matrix 
(1.101) 
" 1  
2 
A - B K C =  
3 - k ~ ~  4 
3-k23 
, 
[ :  
2-kll 
1 
has an eigenvalue at X = 1 independent of the feedback gains kij, which is 
by Definition 1.37 a fixed mode. If, however, the nonzero element a33 = 1 

1.6. Structurally Fixed Modes 
45 
of A in (1.99) is slightly perturbed by a small amount c to obtain the new 
matrix 
0 2 l + €  
(1.102) 
then it is easy to show that the resulting system S, = (Ae, B, C) has no 
fixed modes with respect to the feedback constraints (1.100). Thus, the 
fked mode of S is a result of a perfect matching of some of the nonzero 
elements of the matrix A. If, on the other hand, the matrix A of (1.99) 
were 
A
=
3
4
3
,
 
(1.103) 
then S would have a fixed mode at X = 0 no matter how the nonzero 
elements of the matrices A, B and C were perturbed, although it would 
always remain jointly controllable and observable. In this case, the fixed 
mode X = 0 is caused entirely by the structure of the system, and is inde- 
pendent of the values taken by the nonzero parameters of A, B and C; it 
is a structurally fixed mode. 
[: : :I 
We now prove a theorem of Sezer and Siljak (1981a, b) that provides an 
algebraic characterization of structurally fixed modes. To avoid trivialities, 
we assume that the system S = (A, B, 6) is structurally controllable and 
observable. 
1.43. 
A system S = (A, B, 6) has structurally fixed modes 
with respect to a feedback structure R if and only if either of the following 
conditions holds: 
(i ) There exists a subset I c M and a permutation matrix P such that 
THEOREM. 
A,, 
0 
0 
PTAP= A,, 
A,, 
0 
C;P= [6{ 0 01. 
[ 2 3 1  
2 3 2  
A 3 3  
0 
, 
P'B; = 
0 
[Bi 
(ii) There exists a subset I c M such that 
7 
(1.104) 
(1.105) 

46 
1. Structured Systems 
Before we present a proof of this theorem, we need some preliminary 
considerations. First, by RUA , RUB, and Rw , we denote the parameter spaces 
of structured matrices 2, B, and c, and u,, uB, uc are the number of un- 
specified elements of A, B, and c, respectively. Also, we denote a typical 
point p E R” by p = (p, , pg , 
Next, 
we present a definition and a simple lemma of Davison (1977), which we 
give without proof 
), where R” = RUA x RUB x RW . 
1.44. 
RuA, A has all of its eigenvalues at the origin. 
DEFINITION. A matrix A is said to be degenerate if, for all p, E 
1.45. LEMMA. If a matrix A is nondegenerate, then the set {p, 
E 
RuA: A has repeated nonzero eigenvalues} is contained in a proper va- 
riety VA c RUA. 
We now prove a result established by Hosoe and Matsumoto (1979) 
using a somewhat different approach: 
1.46. 
Let A be nondegenerate, VA be as defined in Lemma 1.45, 
and let VAB c RUA x R”B be a proper variety which contains VA x RUB. 
Suppose that, for all (p,, p,) 4 VAB, there exists a X E C such that X # 0 
and 
/s ([A - X I  BI) < n. 
(1.106) 
LEMMA. 
Then, [A B] is of Form I (Definition 1.26). 
Proof Let VAB be defined by the polynomial cp(p,, b). 
We first claim 
that B has some fixed zero rows. Otherwise, for any p, = pi such that 
cp(p:, b) $ 0, since p(A* - X I )  2 n - 1 for all X # 0, we can choose a 
% = p; such that cp(p:, p i )  # 0 and p([A* - X I  B*]) 2 n for all X # 0, 
contradicting the assumption. Therefore, there exists a permutation matrix 
PI such that 
(1.107) 
A21 
A22 
where &is ni x ni, a = 1, 2, with n1 + n2 = n, and B 2  has no fixed zero 
rows. If A12 = 0, the proof follows. Suppose A12 # 0. If A22 is degenerate, 
fix pAZl pAaa and b such that ‘ ~ ( p , , ,  
7 pA12 
9 
$ 0 and thus 
define a proper variety VA,,A,~ 
in the parameter space of (All, AIZ). Since 
7 P:~~ 
7 

1.6. Structurally Fixed Modes 
47 
- X I  is nonsingular for all X # 0, for all (pAll, pA12) 4 VA11A12, 
ij ([.I,, 
- X I  ~ 1 2 1 )  < n1, 
for some x # 0. 
(1.108) 
If ,422 is nondegenerate, since B 2  contains no zero rows, pAzl, pAZ2 and 
can be fixed such that p ([A;, - XI B;]) 2 n2 for all X # 0, so that again 
(1.108) must hold for all (pAll, pAlz) 4 V A ~ ~ A ~ ~ .  
Obviously, (1.108) also 
implies that A11 is nondegenerate, and that V A ~ ~ A ~ ~  
contains V A ~ ~  
x R”Alz, 
where V A ~ ~  
is defined as in Lemma 1.45. 
We now continue the proof by induction on n. For n = 2, or n > 2, n1 = 
1, the proof is obvious. For n > n1 2 2, the induction hypothesis and 
(1.108) imply that [A,, 1.3121 is of Form I, that is, there exists a permutation 
matrix P 2  which puts [A11 A121 into Form I. Then, the permutation matrix 
P = PI diag(P2, In,} permutes [A BJ into Form I. 
Q.E.D. 
1.47. 
If there exists a p E R” such that the rank of the matrix 
LEMMA. 
(1.109) 
is no less than n for all X E C, then the set P = { p  E R”: ij[n;r(X)] < n 
for some A} is a proper variety in R”. 
Proof. Let %(A; p,) = det(A - X I ) ,  and let cp,(X; p )  denote the sum of 
the squares of all other n x n principal minors of 1\.71(X). Then, the set P 
is exactly the set of p E R” for which q, and ql have common zeros or, 
equivalently, for which the resultant g of % and 
is zero. Since g $ 0 
by assumption, the proof follows. 
Q.E.D. 
1.48. LEMMA. Suppose [A 91 and [AT cT] 
are not of Form I. Let V C 
R” be a proper variety, and let L = {XI, X2, . . . , Xk}, where Xi # 0 for all 
i. Then there exists a p 4 V such that 
(1.110) 
where &(A) is defined in (1.109). 
Proof. We claim that there exists a p 4 V such that ij[fi(A)] 2 n 
for X # 0. If A is degenerate, this is obvious. If A is nondegenerate, let 
VA be as defined in Lemma 1.45, and let the proper variety V U (VA x 

48 
1. Structured Systems 
RVB x Re) be defined by the polynomial &I,, 
b ,  
pc). Fix 
= ?r, such 
that cp(p,, K ,  g) $ 0, and thus define a proper variety VAB c RVA x 
R”B which contains VA x RVB. If the claim were not true, then for all 
(pA, b) 4 UAB there would exist a X # 0 such that F([A - X I  B]) < n; 
and Lemma 1.46 would imply that [A b] has Form I, contradicting the 
assumption. Therefore, the claim must be true. Using the same argument 
as in the proof of Lemma 1.47, we can show that 
where V1 is a proper variety in R”. 
On the other hand, it is easy to show that the set { p  E RVA: det(A - 
X I )  = 0 for some Xi E L} is contained in a - proper 
-. - 
variety Va. Also, 
&(A--XI)-’B $0, for otherwise we would have CAtB = 0 for a = 1, 2, . . . , 
which can easily be shown to imply that both [A b] and [AT 
have 
Form I. Thus, letting Vi = VA x RVB x RW, we can show that { p  4 
V2: &(A - XI)-’B = 0 for some Xi E C} is contained in a proper variety 
V3 c R”. Now, it is obvious that, for all p $ V2 u V3, 
Combining this result with 
condition (1,110) holds. 
(l.lll), weconclude that for allp $ VlUV2UVS 
Q.E.D. 
We need one more lemma before we give the proof of Theorem 1.43. 
1.49. LEMMA. Suppose 
(1.113) 
Then, either the set { p  E R” : p[fi(X)] < n for some A} is contained in 
a proper variety in R”, where f i ( X )  is given by (1.109); or there exists a 
permutation matrix P such that the matrices PTAP, PTB, and CP have 
the form in (1.104). 
Proof. Let U be a proper variety on which D[fi(O)] < n. If A is degen- 
erate, then the set { p  E R”: @[fi(X)] < n for some X E C} is contained in 
V1 and the proof follows. If A is nondegenerate, let UA be as in Lemma 1.45 
and let V = U1 U (VA x RVB x RW). If there exists a p E R” - U such that 

1.6. Structurally Fixed Modes 
49 
PTAP = 
J[fi(X)] 2 n, then the proof follows from Lemma 1.47. Otherwise, for all 
p E R” - V we must have a X # 0 such that p[$f(X)] < n. Using the same 
argument as in the first part of the proof of Lemma 1.48, we can show that 
both [A B] and [AT CT] are of Form I, which in turn implies that there 
exists a permutation P such that 
A,, 
A,, 
0 
0 
, pTB= 
A31 
A32 
A33 
0 
(1.1 14) 
CP=[C1 
0 
C3 
0 1 .  
In particular, P can be chosen such that the pairs 
are not of Form I. In (1.114), let ni x ni matrices & consist of those rows 
and columns of A with indices in Ni c N = (1, 2, . . . , n}, i = 1, 2, 3, 4. 
Note that some Ni might be empty. 
We now claim that N3 = 0. If not, fix all the nonzero elements of A, B, 
and & except those of 
A33, &, and 
C?3 
such that y(p:ll, ---, 
pA33, , p:44; h3, 
pi4; p:, , p:,) $ 0; and thus define a proper variety 
V A ~ ~ B ~ C ~  
in the parameter space of (&3, 
B 3 ,  6 3 ) ,  where cp is the polynomi- 
nal that defines V .  Let L be the set of nonzero eigenvalues of ATl, A&, and 
A&. Since [A33 B3] and [A:3 CT] are not of Form I, Lemma 1.48 implies 
that there exists 
pi4, p:, ) $! VA,~B,C, such that 
Now, for any X # 0, if X $! L, then ATl, AZ2 and A’& are nonsingular; so that 
(1.116) implies pfM*(X)] 2 n. If X E L, then, since p(A;, - X I )  + p(A$, - 
XI) + p(Af4 - XI) = n1+ 122 + 714 - 1, again (1.116) implies p [ M * ( X ) ]  2 n. 
This, however, contradicts the assumption that, for all p $! V ,  @[%!(A)] < n 
for some X # 0. Thus, we must have N3 = 0. 

50 
1. Structured Systems 
Finally, to complete the proof, we claim that NZ # 0. To prove the 
claim, assume the contrary, that is, 
C P =  [C, 01, 
and recall that: (i) A is nondegenerate, (ii) for all p $ V ,  there exists a 
X # 0 such that b[A?(X)] < n, and (iii) [A44 &] and [ATl 6:] are not in 
Form I. If A44 is degenerate, then (i) implies that A11 is nondegenerate; 
and (ii), implies that for all (pAll , p,,), except possibly those values that 
lie on a proper variety in the parameter space of (All, Cl), there exists a 
X # 0 such that P([ATl - X I  6?]) < n1. But then, by Lemma 1.46, [AT, 6?] 
must be of Form I, contradicting (iii). If 2, 
is nondegenerate, then, since 
[&-XI 
&] is not of Form I, Lemma 1.46 implies that P([A44, - X I  &]) 2 
nz for almost all (pAQ4 , h4), 
which, together with (ii) leads to the same 
contradiction. Hence, NZ # 0. 
Q.E.D. 
Proof of Theorem 1.43. If S = (A, B, 6) has structurally fixed modes, 
it follows from Definition 1.41 and Theorem 1.40 that, for all p E RV, 
there exists a X and a subset I c M (both depending on p )  such that 
P[A?,(X)] < n, where MI(X) is the matrix defined by (1.109) with B and 
C replaced by BI and CJl respectively. This, however, is equivalent to 
saying that there exists a particular I c M for which, for all data points 
(p,, w , h ) in the parameter space of (A, A,, 6;) except possibly those 
that lie on a proper variety, there exists a X such that F[&l,(X)] < n, and 
Lemma 1.49 completes the proof of the necessity part of the theorem. 
The suficiency part of the theorem, on the other hand, follows imme- 
diately from Theorem 1.40 on noting that in case (i), A(&z), and in case 
(ii), X = 0, are fixed modes. 
Q.E.D. 
Because of our interest in decentralized control, we shall interpret 
the results of this section in the context of an N-channel system SN = 
(A, BN, C"). To discuss the special case of structurally fixed modes under 
decentralized constraints (Remark 1.38), we start with the following: 
1.50. EXAMPLE. 
0
1
0
 
I
J
 
Let us consider a twGchanne1 system S N  defined as 
A =  [i i y ]  , B1=CT= [i] , Bz=CT= [!I 
, 
(1.118) 

1.6. Structurally Fixed Modes 
51 
which is controllable and observable. For KD = diag{kl, kz}, the matrix 
has an eigenvalue at X = 1 independent of kl and k2, which is by definition 
a fixed mode of S N .  However, if we perturb the coefficient a33 = 1 of A to 
get 
A,= [ 0 1  
1 1 
", 
(1.120) 
0 0 l + €  
where e is an arbitrarily small (but fixed) number, it is easy to see that 
the resulting system S r  = (A,, B N ,  C") 
would have no fixed modes. The 
fixed mode of S N  is caused by a perfect matching of the nonzero elements 
of A. If, on the other hand, the matrix in (1.118) were 
(1.121) 
then the system SN would have a fixed mode at X = 0 no matter how the 
nonzero elements of the triple (Al, BN, C N )  were perturbed, although it 
would always stay centrally controllable and observable. This is the case of 
structurally fixed modes under decentralized constraints. 
To state the corollary to Theorem 1.43 regarding the decentralized ver- 
sion of structurally fixed modes, let us assume that SN = (A, BN, C N )  
defined by 
(1.77) 
pa = ClXl, 
BN = [B1 B2 . .. B N ] ,  
i E N, 
CN = [ci c2 .. . C N ] ,  
and 
(1.78) 
is jointly structurally controllable and observable; that is, the pairs (A, BN) 
and (A, eN) 
are structurally controllable and observable, respectively. We 
also introduce a subset of indices K = {il, i2, . . . , ik} c N to define the 

52 
1. Structured Systems 
block matrices 
BK = [Bi, Bi, . .. Bi,], CK = [CE CE .. . Cc] , 
(1.122) 
and state the following (Sezer and Siljak, 1981a, b): 
1.51. 
modes with respect to the decentralized control 
COROLLARY. A system SN = (2, BN, C N )  has structurally fixed 
u = -KDY~ KD = diag(K1, K2, . . . , K N } ,  
(1.80) 
if and only if either of the following conditions hold: 
(i) There exists a subset K c Nand a permutation matrix P such that 
A,, 
0 
0 
A13 
A32 
A33 
CKP= [C; 
0 01, C N - K ~ =  
~ N - K C N - K  
CN-K 
, 
(1.123) 
I
1
 
3
1
 
(zi) There exists a subset K c N such that 
(1.124) 
We observe that both conditions of Theorem 1.43 and its Corollary 1.51 
are purely structural conditions concerning the distribution of indetermi- 
nate and fixed zero elements of the system matrices, which suggests that 
they can be tested using graph theoretical concepts. This we consider next. 
We need a few notions from graph theory. A digraph Ds = (VS, Es) 
where VS C V and Es C E is called a subgraph of D = (V, E). If Vs = V, Ds 
is said to span D. The union of digraphs D1 = (V,, El) and D2 = (V2, E2) is 
the digraph D1 U D 2  = (V, UV2, El UE2). D1 and D2 are said to be disjoint 
if V1 n V2 = 0. When a constant output feedback 

1.6. Structurally Fixed Modes 
53 
satisfying the constraints specified by a binary matrix K, 
is applied to the 
system S = (A, B, C), we accordingly add feedback edges EK to D to 
obtain the digraph D = (V, E U EK) of the closed-loop system, where 
EK = {(Yj, ui): i E M ,  j E Ji}. 
(1.125) 
The corresponding closed-loop interconnection matrix E is given as 
E = [ ;  ; 3. 
(1.73) 
The following result is a graph-theoretic characterization of structurally 
fixed modes. 
1.52. THEOREM. A system S = (A, B, 6) has no structurally fixed 
modes with respect to a feedback structure K if and only if both of the 
following two conditions hold: 
Each state vertex xk E X is contained in a strong component of 
D which includes an edge from EK. 
There exists a set of mutually disjoint cycles C ,  = (V,, E,), T = 
1, 2, . . . , R, in D such that 
(2) 
(ii) 
R 
X C U  v,. 
(1.126) 
,=I 
We first state a couple of simple lemmas without proofs, which were 
established by Shields and Pearson (1976). 
1.53. LEMMA. Let fi be a p  x q matrix. Then ,5(&f) 2 T, T 5 min{p, q), 
if and only if &f contains at least T nonzero elements located in distinct 
rows and columns. 
1.54. LEMMA. 
min{p, q}, if and only if 
s x ( p  + q - T - s + 1) for some s such that p - T < s 5 p .  
Let a 
be a p x q matrix. Then, p ( ~ )  
< T ,  1 5 T 5 
contains a zero submatrix of order no less than 
We also need the following result which is straightforward consequence 
of Lemma 1.53: 

54 
1. Structured Systems 
Fig. 1.19. Digraph D. 
1.55. LEMMA. Let D be a digraph with n vertices, and let ii? be its 
adjacency matrix. Then, D is spanned by a disjoint union of cycles if and 
only if ~(i?) 
= n. 
Now, we modify the digraph D by adding self-loops at every input 
and output vertex to obtain a new digraph D = (V, E U EK U E), where 
E = { (v, v): v E U u Y}, and proceed to the proof of the theorem. 
Proof of Theorem 1.52. We show that conditions (2) and (ii) of Thee 
rem 1.52 are negations of conditions (2) and (ii) of Theorem 1.43. 
If (i) of Theorem 1.43 holds, then D has a structure shown in Fig- 
ure 1.19, where XI, X2, X 3  are identified by the diagonal blocks ,411, ,422, ,433 
in (1.104). From Figure 1.19, we see that D has at least one strong compo- 
nent with all vertices in X2, which contains no feedback edges. To prove the 
converse, let D k  = (Vk, Ek U Ek), where Vk = Uk U Xk U Yk, 
k = 1, 2, . . . , K ,  
denote the strong components of D ordered so that no vertex in Vk reaches 

1.6. Structurally Fixed Modes 
55 
a vertex in Vj if j < i, i = 2, 3, . . . , n (Theorem 1.18). Let D k  be a strong 
component that includes no feedback edges, that is, one with Ek = 8. Then, 
obviously, Uk = 8 and Yk = 8. Defining X 1  = X' U X2 U . . . U X k - ' ,  
X 2  = 
X k , X 3  = X"' 
U Xk+2 U . . . U X K ,  and U, = Uk+' U Uk+' U . . . U UK, it is 
easy to see that D has the structure shown in Figure 1.19. This completes 
the proof of the first part of the theorem. 
To prove part (ii) of the theorem, we first notice that condition (ii) 
of Theorem 1.43 is equivalent to the modified graph D being spanned by 
a disjoint union of cycles. Due to Lemma 1.55, the latter condition is, in 
turn, equivalent to the structured version of the adjacency matrix of D, 
A
B
o
 
z1 0 
Ip 
E = [ o  f m  "1, 
( 1.127) 
being of full generic rank. Thus, it suffices to prove that part (ii) of Theo- 
rem 1.43 holds for some I c M if and only if P(E) < n + m + C. This means 
that if 
(1.105) 
holds for some I = ( 2 1 ,  22, . . . , ip} and J = {jl, 
j 2 ,  . . . , j,}, then 
Lemma 1.54 implies that the matrix in (1.105) contains a zero submatrix of 
total size no less than n + p  + q + 1, where by total size of a matrix we mean 
the sum of the number of rows and the number of columns. Partitioning E 
in (1.127) as 
- 
E =  
, 
(1.128) 
- 
and noting that KM-,, L- = 0, we observe that E contains a zero submatrix 
of total size no less than n + p + q +  1 + (m - p )  + (C - q) = n +m+C+ 1; 
and Lemma 1.54 implies that P(E) < n + m + l. 
Conversely, if P(2) < n + m + C, then E contains a zero submatrix of 
total size n+m+C+l. Let this submatrix consist of T, rows and c, columns 

56 
1. Structured Systems 
corresponding to the state vertices, T, rows and c, columns corresponding 
to the input vertices with indices in sets R, C M and C,, c M, and T, 
rows and cy columns corresponding to the output vertices with indices in 
sets 4 c L and C, c L. Thus, 
T, + T, + T, + c, + c, + cy 2 n + m + c +  1. 
(1.129) 
Note that by structure of E, 
R,nC,=0, 
&nCa,=O. 
(1.130) 
- 
Let I = C,. Since KRucv = 0, we have J C L - C,. Therefore, 
On the other hand, by (1.130), L - C, 3 R,, so that the (n + C - cy) x 
(n-tc,) matrix on the right side of (1.131) contains a zero submatrix of total 
size at least r, + T, + c, + c,. Using (1.129) and the fact that m 2 T, + c,, 
as implied by (1.130), we have 
T, + r, + c, + c, 2 n + m + e + 1 - r, - cy 
(1.132) 
Q.E.D. 
L n +  ( e -  cy) +c, + 1, 
so that the matrix in (1.131) has generic rank less than n. 
1.56. EXAMPLE. Theorem 1.52 not only provides a very convenient 
graphical test for structurally fixed modes, but may also be useful in de- 
ciding what additional feedback links should be introduced in case the 
existing ones are not sufficient for all the modes. As an example, consider 
a structured system S = (A, B, 6') specified by 
0
0
 
A =  [: '1, 
B =  [ 0  ;I, c= [: HI. 
o * o  
* 
0
0
 
(1.133) 
Let the feedback structure constraints be specified as 
1
0
0
 
K =  [o 1 1 1 '  
that is. 
K = [ *  
0 
O * 01 
* .  
(1.134) 
(1.135) 

1.6. Structurally Fixed Modes 
57 
t 
f 
I 
I 
I 
I 
L 
v 
p y’ 
u2 0 
f 
1 3  
Fig. 1.20. Digraph D. 
The digraph D associated with S is shown in Figure 1.20, where the 
feedback edges of EK are identified by dashed lines. From this figure we find 
that not all state vertices of D can be covered by disjoint cycles, so that 
by condition (ii) of Theorem 1.52, S has a structurally fixed mode. On the 
other hand, a quick inspection of Figure 1.20 shows thatAif the feedback edge 
(yz, u1) were added to D to get a modified structure D’ as in Figure 1.21, 
both conditions of Theorem 1.52 would be satisfied without even using the 
existing edges of EK, indicating that feedback structure constraints such as 
0
1
0
 
0
0
0
 
K ” =  [ 
1, 
(1.136) 
resulting in a digraph D” of Figure 1.22, would suffice to control S in almost 
all cases. 
Finally, we should comment on the implications of our Theorem 1.52 
concerning Theorems 1.28 and 1.29 on structural controllability and observ- 
ability. It is easy to see that under the full output feedback and C = In, 
con- 
dition (i) of Theorem 1.52 is equivalent to system S being input reachable, 
that is, the pair [A B] is not of Form I. Furthermore, from the proof of part 
(ii) of the theorem, it follows that under the same feedback constraints the 
existence of the appropriate cycle family is equivalent to the rank condition 
b([A B]) = n, that is, [A B] not being of Form 11. Therefore, we have the 

58 
1. Structured Systems 
Y \ 
\ 
\ 
I 
I 
I f 
I, / 
i 
-u, 
x3 
Fig. 1.21. Digraph D’. 
following easy corollary (Linnemann, 1983) to Theorem 1.52, which pro- 
vides the known characterization of structural controllability (Lin, 1974; 
Shields and Pearson, 1976; Glover and Silverman, 1976; Hosoe and Mat- 
sumoto, 1979): 
1.57. 
A system S = (A, B, e) has no structurally fixed 
modes with respect to the full state feedback, that is, the pair (2, 
8) is 
structurally controllable if and only if both of the following conditions hold: 
COROLLARY. 
(i) S is input reachable. 
Conditions (i) and (ii) are equivalent to saying that the composite ma- 
trix [A B] has neither Form I nor Form 11, respectively, which is the con- 
dition of Theorem 1.28. The dual of Corollary 1.57 is Theorem 1.29. 
(ii) P([A B]) = 77,. 
1.7. Notes and References 
The basic ingredients in control design of simple and complex systems 
alike are controllability and observability (Kalman, 1963). Yet, even in 
medium size linear systems, numerical tests of these properties are either 
unreliable or require an excessive computational effort. For these reasons, 

1.7. Notes and References 
59 
\ \ * 
\ 
\ 
0 Y1 
I 
I 
/ 
/ 
1 
Y3 
x3 
Fig. 1.22. Digraph D”. 
the graph-theoretic concept of structural controllability (Lin, 1974) is an 
attractive tool which can be used to identify systems where uncontrolla- 
bility is a parameter independent property. What is even more appealing 
is the simplicity of structural controllability tests involving binary calcula- 
tions only (for discussion of numerical problems in testing controllability, 
see Nour-Eldin, 1987). 
Lin’s single-input result was generalized to a multi-input case by Shields 
and Pearson (1976), who introduced an algebraic approach to the problem 
of structural controllability. This approach has been refined by Glover and 
Silverman (1976), who produced a recursive algorithm to solve the problem. 
Further improvements and insights have been provided by many people 
(see, for example, Hosoe and Matsumoto, 1979; Hosoe, 1980; Mayeda, 1981; 
Hayakawa et al. 1984; Linnemann, 1986). 
Among the two parts of structural controllability (Corollary 1.57), input 
reachability was singled out as a topic of special attention (Siljak, 1977a, b) 
because of its physical importance and manipulative power in large-scale 
systems. The concepts of input and output reachability were used to obtain 
hierarchically ordered subsystems with independent inputs and outputs 
(Pichai et al. 1983). The resulting form of a large-scale system allows for 
not only a “piece-by-piece” design of decentralized control and estimation, 
but also breaks down a test for (structural and ordinary) controllability 

60 
1. Structured Systems 
and observability into a number of easier tests involving only low-order 
subsystems (Chapter 6). Besides being the principal ingredient in thee 
rems on structural controllability and observability, the concept of input 
and output reachability has been used in a variety of applications (Siljak, 
1978; Burns and Winstead, 1982a, b; Bossermann, 1983; 1988; Maione and 
Turchiano, 1986, 1988; Evangelatos and Nicholson, 1988; see also Chap 
ters 6 and 7). 
The assumption of parameter independence underlying the structural 
analysis may eliminate some critical cases (Examples 1.33 and 1.34). A lin- 
ear parametrization for structural controllability was considered by Corfmat 
and Morse (1976), Anderson and Hong (1982), and Anderson (1982). The 
gain in precision may be outweighed by the amount of additional com- 
putational effort required to test parametrized systems. Another way to 
attack this problem is to look for structures which are controllable despite 
parameter dependencies-this 
is strong structural controllability (Mayeda 
and Yamada, 1979). The result, however, is disappointingly conservative. 
In this context, the most encouraging result is the simple fact that input 
reachability is independent of parametrization, confirming its importance 
in the structural analysis of control. 
Use of graphs opens up a possibility to consider vulnerability of con- 
trol systems (Siljak, 1978). Imitating the vulnerability concept in graph 
theory (Harary et al. 1965), we consider a control system vulnerable if a 
removal of a line, or a set of lines, from the corresponding digraph destroys 
input reachability (structural controllability). Graph-theoretic procedures 
have been developed (Pichai et al. 1981) to identify the minimal sets of 
lines which are essential for preserving input reachability and structural 
controllability of a given system. 
More often than not, neither the states, nor their estimates, are avail- 
able for control. Then the central problem becomes the existence of fixed 
modes under output or decentralized information constraints. The notion 
of structurally jked modes was introduced in (Sezer and Siljak, 1981a) to 
characterize the existence problem via graphs and interconnection matrices. 
The solution to the problem was given for arbitrary feedback constraints, 
which resulted in simple binary tests (Pichai et al. 1984). Variations of the 
problem and its solution have appeared in (Linnemann, 1983; Momen and 
Evans, 1983; Reinschke, 1984; Trav6 et al. 1987; Murota, 1988; Fanti et al. 
1988). 
The next important and interesting step in the development of graph- 
theoretic concepts in control is the pole assignment problem as formulated 
by Sezer (1983). He showed how to characterize a minimal set of feedback 
links that guarantee generic pole assignability for a linear multivariable sys- 
tem using dynamic compensators. Furthermore, Sezer proposed a procedure 

Bibliography 
61 
to identify at least one such feedback pattern. An optimization approach 
in this context has been presented in (Sezer and Unyelioglu, 1988). 
Bibliography 
Anderson, B. D. 0. (1982). Transfer function matrix description of decentralized fixed 
modes. IEEE Transactions, AC-27, 1176-1182. 
Anderson, B. D. O., and D. J. Clements (1981). Algebraic characterization of fixed modes 
in decentralized control. Automatica, 17, 703-712. 
Anderson, B. D. O., and H. M. Hong (1982). Structural controllability and matrix nets. 
International Journal of Control, 35, 397-416. 
Aoki, M. (1972). On feedback stabilizability of decentralized dynamic systems. Auto- 
matica, 8, 163-173. 
Berztiss, A. T. (1975). Data Structures: Theory and Practice. Academic Press, New 
York. 
Bwerman, R. W. (1983). Flow analysis sensitivities for models of energy or material 
flow. Bulletin of Mathematical Biology, 45, 807-826. 
hserman, R. W. (1988). Ecosystem networks: Measures of structure. Systems and 
Control Encyclopedia, M. G. Singh (ed.), Pergamon Press, Oxford, UK, 1352-1356. 
Bowie, W. S. (1976). Applications of graph theory in computer systems. International 
Journal of Computer and Information Sciences, 5, 9-31. 
Burns, J. R., and W. H. Winstead (1982a). On input-utput 
approach to the structural 
analysis of digraphs. IEEE Transactions, SMC-12, 15-24. 
Burns, J. R., and W. H. Winstead (1982b). Input and output redundancy. IEEE Trans- 
actions, SMC-12, 785-793. 
Corfmat, J. P., and A. S. Morse (1976). Structurally controllable and structurally canon- 
ical systems. IEEE Transactions, AC-21, 129-131. 
Davison, E. J. (1977). Connectability and structural controllability. Automatica, 13, 
109-123. 
Davison, E. J., and U. Ozgiiner (1983). Characterizations of decentralized fixed modes 
for interconnected systems. Automatica, 19, 169-182. 
Deo, N. (1974). Graph Theory with Applications to Engineering and Computer Science. 
Prentice-Hall, Englewood Cliffs, New Jersey. 
Duff, I. S. (1977). A survey of sparse matrix research. Proceeding of the IEEE, 65, 50G 
535. 
Duff, I. S. (1981a). On algorithms for obtaining a maximum transversal. ACM Trans- 
actions on Mathematical Software, 7, 315-330. 
Duff, I. S. (1981b). Algorithm 575. Permutations for a zero-free diagonal. ACM Trans- 
actions on Mathematical Software, 7, 387-390. 
Duff, I. S., and J. K. Reid (1978a). An implementation of Tarjan’s algorithm for the block 
triangularization of a matrix. ACM Journal of Mathematical Software, 4, 137-147. 
Duff, I. S., and J. K. Reid (1978b). Algorithm 529. Permutations to block triangular 
form. A CM Transactions on Mathematical Software, 4, 189-192. 
Evangelatos, D. S., and H. Nicholson (1988). Reachability matrix and relation to large- 
scale systems. International Journal of Control, 47, 1163-1177. 

62 
1. Structured Systems 
Fanti, M. P., B. Maione, and B. Turchiano (1988). Structurally fixed modes of systems 
described by Rosenbrock’s polynomial matrices. International Journal of Control, 
Festinger, L., S. Schachter, and K. Back (1950). Social Pressures in Informal Groups. 
Harper, New York. 
Franksen, 0. I., P. Falster, and F. J. Evans (1979). Structural aspects of controllability 
and observability. Parts I and 11. Journal of the Franklin Institute, 308, 79-124. 
Glover, K., and L. M. Silverman (1976). Characterization of structural controllability. 
IEEE Transactions, AC-21, 534-537. 
Gustavson, F. G. (1976). Finding the block lower triangular form of a sparse matrix. 
Sparse Matrix Computations, J. R. Bunch and D. J. Rose (eds.), Academic Press, 
New York, 275-289. 
Harary, F. (1959). A graph-theoretic method for the complete reduction of a matrix 
with a view toward finding its eigenvalues. Journal of Mathematics and Physics, 38, 
48, 1947-1965. 
104-1 11. 
Harary, F. (1969). Graph Theory. Addison-Wesley, Reading, Massachusetts. 
Harary, F., R. Z. Norman, and D. Cartwright (1965). Structural Models: A n  Introduction 
Hayakawa, Y., and D. D. Siljak (1988). On almost invariant subspaces of structured 
Hayakawa, Y., S. Hosoe, M. Hayashi, and M. Ito (1984). On the structural controllability 
Hopcroft, J. E., and R. Tarjan (1971). Planarity testing in V log V steps. Proceedings 
Hosoe, S. (1980). Determination of generic dimensions of controllable subspaces and its 
Hosoe, S., and K. Matsumoto (1979). On the irreducibility condition in the structural 
Kailath, T. (1980). Linear Systems. Prentice-Hall, Englewood Cliffs, New Jersey. 
Kalman, R. E. (1963). Mathematical description of linear dynamical systems. SIAM 
Lee, E. B., and L. Markus (1961). Foundations of Optimal Control Theory. Wiley, New 
Lehman, S. K. (1986). Comments on “Fixed modes and local feedbacks in interconnected 
Lin, C. T. (1974). Structural controllability. IEEE Transactions, AC-19, 201-208. 
Linnemann, A. (1983). Fixed modes in parametrized systems. International Journal of 
Control, 38, 319-335. 
Linnemann, A. (1986). A further simplification in the proof of the structural controlla- 
bility theorem. IEEE Transactions, AC-31, 638-639. 
Maione, B., and B. Turchiano (1986). Input- and output-decoupling structural zeros of 
linear systems described by Rosenbrock’s polynomial matrices. International Jour- 
nal of Control, 44, 1641-1659. 
Maione, B., and B. Turchiano (1988). Characterization of decoupling structural zeros of 
Rosenbrock’s polynomial matrices. International Journal of Control, 47, 459-476. 
Mayeda, H. (1981). On structural controllability theorem. IEEE Transactions, AC-26, 
795-799. 
Mayeda, H., and T. Yamada (1979). Strong structural controllability. SIAM Journal on 
Control and Optimization, 17, 123-138. 
to the Theory of Directed Graphs. Wiley, New York. 
systems and decentralized control. IEEE Transactions, 33, 931-939. 
of compartmental systems. IEEE Transactions, AC-29, 17-24. 
of the IFIP Congress, Ljubljana, Yugoslavia, Ta-2, 18-23. 
application. IEEE Transactions, AC-25. 1192-1196. 
controllability theorem. IEEE Transactions, AC-24, 963-966. 
Journal on Control, 1, 152-192. 
York. 
systems.” International Journal of Control, 43, 329-333. 

Bibliography 
63 
McFadden, D. (1967). On the controllability of decentralized microeconomic systems. 
The assignment Problem. Mathematical Systems Theory and Economics, 1, H. W. 
Kuhn and G. P. Szego (eds.), Springer, New York, 221-239. 
Momen, S., and F. J. Evans (1983). Structurally fixed modes in decentralized systems. 
Parts I and 11. IEE Proceedings, 130, 313-327. 
Munro, I. (1971). Efficient determination of the transitive closure of a directed graph. 
Information Proceedings Letters, 1, 5658. 
Murota, K. (1987). Systems Analysis by Graphs and Matroids: Structural Solvability 
and Controllability. Springer, Berlin, FRG. 
Murota, K. (1988). A matroid-theoretic approach to structurally fixed modes in decen- 
tralized control. Research Memorandum RMI 88-07, University of Tokyo, Tokyo, 
Japan. 
Nour-Eldin, H. A. (1987). Linear multivariable systems controllability and observabil- 
ity: Numerical aspects. Systems and Control Encyclopedia, M. G. Singh (ed.), Perg- 
amon Press, Oxford, UK, 2816-2827. 
Pichai, V., M. E. Sezer, and D. D. Siljak (1981). Vulnerability of dynamic systems. 
International Journal of Control, 34, 1049-1060. 
Pichai, V., M. E. Sezer, and D. D. Siljak (1983). A graphical test for structurally fixed 
modes. Mathematical Modeling, 4, 339-348. 
Pichai, V., M. E. Sezer, and D. D. Siljak (1984). A graph-theoretic characterization of 
structurally fixed modes. Automatica, 20, 247-250. 
Purdom, P. (1970). A transitive closure algorithm. Nordisk Tidskrift for Informationbe- 
handlung, 10, 76-94. 
Ibinschke, K. (1984). Graph-theoretic characterization of fixed modes in centralized and 
decentralized control. International Journal of Control, 39, 715-729. 
Sezer, M. E. (1983). Minimal essential feedback patterns for pole assignment using dy- 
namic compensation. Proceedings of the 22nd IEEE Conference on Decision and 
Control, San Antonio, Texas, 28-32. 
Sezer, M. E., and D. D. Siljak (1981a). Structurally fixed modes. Systems and Control 
Letters, 1, 6 M 4 .  
Serer, M. E., and D. D. Siljak (1981b). On structurally fixed modes. Proceedings of the 
IEEE International Symposium on Circuits and Systems, Chicago, Illinois, 558-565. 
Sezer, M. E., and K. Unyelioglu (1988). On optimum selection of stabilizing feedback 
structures for multivariable control systems. Proceedings of the IFAC Symposium 
on Distributed Intelligence Systems, Varna, Bulgaria, 145-154. 
Shields, R. W., and J. B. Pearson (1976). Structural controllability of multiinput linear 
systems. IEEE Transactions, AC-21, 203-212. 
Siljak, D. D. (1977a). On pure structure of dynamic systems. Nonlinear Analysis, The- 
ory, Methods, and Applications, 1, 397-413. 
Siljak, D. D. (1977b). On reachability of dynamic systems. International Journal of 
Systems Science, 8, 321-338. 
Siljak, D. D. (1977~). Vulnerability of dynamic systems. Proceedings of the IFAC Work- 
shop on Control and Management of Integrated Industrial Processes, Pergamon 
Press, London, 133-144. 
Siljak, D. D. (1978). Large-Scale Dynamic Systems: Stability and Structure. North- 
Holland, New York. 
Swamy, M. N. S., and K. Thulasiraman (1981). Graphs, Networks, and Algorithms. 
Wiley, New York. 
Tarjan, R. (1972). Depth-first search and linear graph algorithms. SIAM Journal on 
Computing, 1, 146-160. 

64 
1. Structured Systems 
Travb, L., A. M. Tarras, and A. Titli (1987). Minimal feedback structure avoiding struc- 
turally fixed modes. International Journal of Control, 46, 313-325. 
Ulm, M., and H. D. Wend (1986). A concept for parameter independent evaluation of 
decentralized stabilizability. Automatica, 25, 133-136. 
Vidyasagar, M. (1980). Decomposition techniques for large-scale systems with nonaddi- 
tive interactions: Stability and stabilizability. IEEE Transactions, AC-25, 773-779. 
Vidyasagar, M., and N. Viswanadham (1982). Algebraic characterization of decentralized 
fixed modes and pole assignment. Proceedings of the 21st Conference on Decision 
and Control, Orlando, Florida, 501-505. 
Wang, S. H., and E. J. Davidson (1973). On the stabilization of decentralized control 
systems. IEEE Transactions, AC-18, 473478. 
Warshall, S. A. (1962). A theorem on Boolean matrices. Journal of the Association of 
Computing Machinery, 9, 11-12. 
Wend, H. D. (1987). Decomposition and structural properties. Systems and Control 
Encyclopedia, M. G. Singh (ed.), Pergamon Press, Oxford, UK, 948-952. 
Wonham, W. M. (1979). Linear Multivariable Control: A Geometric Approach. Springer, 
New York. 

In the stabilization of complex systems, decentralized schemes arise be- 
cause the centralized designs are either infeasible due to an inherent non- 
classical constraint on the information structure ( e.q., market systems, 
where individual agents do not know what other agents are doing), or they 
are costly because of expensive global information schemes (e.g., power 
systems spread over distant geographic areas). The case of decentralized 
control is further strengthened by the fact that imperfect knowledge of the 
model of interconnections among different parts of a complex system is 
invariably present in all but trivial problems. It has been known for some 
time that, unlike centralized control laws, decentralized control structures 
guarantee robust stability, which tolerates a wide range of nonlinear time- 
varying uncertainties in the interactions among the subsystems. That is, 
closed-loop interconnected systems that are stabilized by local feedback 
laws are connectively stable. 
A natural way to establish connective stability of a complex system 
driven by decentralized control is to apply the Matrosov-Bellman concept 
of vector Liapunov functions. The reason is that each component of a vector 
function can be used independently to show stability of a locally controlled 
subsystem. When a vector function establishes stability of the overall sys- 
tem, autonomy of each subsystem is preserved, and, as expected, connective 
stability follows. Over the years, this simple recipe has achieved a consider- 
able level of sophistication (see Notes and References: Section 2.6). In this 
chapter, we surrender generality of the concept for design-oriented results, 
which are useful in decentralized control of complex systems using local 
state feedback. 
65 

66 
2. Stabilization 
Nonexistence of structurally fked modes is a relatively simple charac- 
terization of potentially successful decentralized control structures. It is 
not sufficient, however, and we use the method of vector Liapunov func- 
tions to confirm that a selected control law stabilizes the system. When 
the method fails, the outcome is inconclusive, which is the case with most 
of Liapunov-type results. For this reason, there has long been a concerted 
effort to delineate classes of decentralized systems that can always be sta- 
bilized by local (state or output) feedback. By describing certain classes of 
linear interconnected systems, which are decentrally stabilizable by state 
feedback, we include in this chapter the basic part of this effort. We shall 
rely on graphs to come up with a simple characterization of stabilizability. 
This is our favorite environment, and similar graph-theoretic conditions 
for stabilizability of linear systems via decentralized output feedback will 
resurface again in Chapter 5. 
2.1. Connective Stability 
To fix certain ideas before we engage in a presentation of the general 
stability results available for interconnected systems, let us consider again 
the two identical penduli of Example 1.36 shown in Figure 1.16. Under the 
usual simplifying assumptions, the equations of motion were obtained as 
Our desire is to keep the penduli in the upright position by using a 
suitable feedback law via the two inputs u1 and u2. A special feature of the 
system is the sliding spring, which can change its position along the length 
of the penduli in an unpredictable way. All we know about the position a of 
the spring is that it is bounded, that is, for some constant value zi E [0, 4, 
The position of the spring determines the degree of coupling among the 
two penduli, and a feedback control law should stabilize the system despite 
uncertain variations in the parameter a. At present, we consider a to be 
unknown but constant. 

2.1. Connective Stability 
67 
r 
0 
1
;
 
0 
0- 
-
0
 ; 
0
-
 
ka2 
0
;
 
I 
ka2 
0 
l
i
o
 
f - m P  
I
Z
 
2 :  
S: 5 = . . . . . . . . . . . . . . . . . . . .  i ___________________ 2 + _________ 4 _______-- 
0 1  
0 
1 
o
i
o
 
'
1
 
0 
By choosing the state vector as 2 = (el, 81, 82, d ~ ) ~ ,  
the interconnected 
penduli have an input decentralized representation, which can be obtained 
from (2.1) as 
U. (2.3) 
- m P  
I 
ka2 
0 
-
0
 is- 
which is an interconnection of two subsystems 
0
1
 
s 1 :  2 1  = [ a 0 ]  2 1  + [ ;] 
'111, 
sz: 5 2  = [ a 0 ]  2 2  + [ ;] 
u2, 
0
1
 
where 2 1  = (01, 8 1 ) ~  
and xz = (02, 6 ~ ) ~  
are states of the subsystems S1 
and S2, and Q = g/e, p = l/me2, y = 7i2k/ml2, and e = (a/a)'. 
Since we want stability of S when the two subsystems are decoupled as 
in (2.5), which occurs when e = 0, we choose decentralized feedback laws 
(2.6) 
T 
T 
U1 = - k , 2 1 ,  
'112 = -k, 5 2 ,  
where the feedback gains kl = (kll, L I Z ) ~  
and kz = ( k z ~ ,  
I c z ~ ) ~  
are selected 
so that the closed-loop decoupled subsystems 
0 
1x2 
[ Q - Pkzl 
-PIC22 
sz: x 2  = 

68 
2. Stabilization 
are stable. Now, the fundamental problem in this context is to show that 
stability of the closed-loop subsystems 91 and 9 2  implies stability of the 
overall closed-loop system 
for some value 7L corresponding to E = 1, and then demonstrate the fact 
that stability achieved by the decentralized control law (2.6) is independent 
of the value of the coupling coefficient e E [0, 11. In other words, S 1 ,  S 2 ,  
and S are simultaneously stable for all e E [0, 11. 
At this point, we recognize the fact that e is an uncertain structural pa- 
rameter that determines the degree of coupling between the subsystems S 1  
and S 2 .  An appropriate framework for stability analysis of systems with un- 
certain structural parameters is provided by the concept of stability under 
structural perturbations, that is, Connective stability. This concept was in- 
troduced by the author and further developed by many people, as discussed 
in Notes and References at the end of this chapter. In this section, we shall 
present only the core of the concept that is essential for the stabilization by 
decentralized feedback. After a general outline of the connective stabiliza- 
tion scheme, we shall return to the above example of interconnected penduli 
to complete the stability analysis. This should provide an illustration of the 
concept and, it is hoped, motivate applications to a much broader class of 
coxltrol systems. 
We start with a general description of a dynamic system S by a differ- 
ential equation 
s: x = f(t, z), 
(2.9) 
where z(t) E R" is the state of S at time t E T, and the function f: T x 
R" -+ 
R" is defined, bounded, and continuous on the domain T x R", so 
that solutions z(t; to, 20) of Equation (2.9) exist for all initial conditions 
(to, zo) E T x R" and t E To, where T = (T, +m), T is a number or a 
symbol -00, and To = [to, +m). 
We assume that 
f ( t l  0) = 0, 
V t  E T, 
(2.10) 

2.1. Connective Stability 
69 
and x = 0 is the unique equilibrium of S. To study stability of the equi- 
librium under structural perturbations, we assume that the system S is 
decomposed as 
S: xi = gi(t, xi) + hi(t, s), 
i E N, 
(2.11) 
which is an interconnection of N subsystems 
Si: 
= gi(t, xi), 
i E N, 
(2.12) 
where xi(t) E Rni is the state of the ith subsystem Si, the function gi: T x 
R"' -+ R"' describes the dynamics of Si, and the function hi: T x R" -+ R"' 
represents the interaction of Si with the rest of the system S .  
To describe the structure of S ,  we represent the interconnection func- 
tions as 
hi@, x) E hi(t, ~ i l x l ,  
~ i 2 2 2 ,  . . . , E ~ N X N ) ,  
i E N, 
(2.13) 
where the binary numbers Eij are elements of the N x N fundamental 
interconnection matrix defined by: 
2.1. DEFINITION. 
( E i j )  of a system S has the elements 
The N x N fundamental interconnection matrix I? = 
1, 
0, 
xj occurs in hi@, x), 
xj does not occur in hi(t, x). 
(2.14) 
The matrix I? is the standard occurrence (interconnection) matrix (Stew- 
ard, 1962): Eij = 1 if Sj acts on Si, or i?ij = 0 if Sj does not act on Si. In 
applications, Eij = 1 if there is a physical interconnection from S j  to Si, 
and Eij = 0 otherwise. 
Structural perturbations of S are described by the interconnection ma- 
trix E T -+ RfXN, which is defined by: 
2.2. DEFINITION. An N x N interconnection matrix E = (eij) with 
elements eij: T -+ [0, 11 is said to be generated by an N x N fundamental 
interconnection matrix E = ( E i j )  such that Eij = 0 if and only if eij(t) = 0. 
The elements eij of E represent the strength of coupling between the 
individual subsystems Si of S at t E T. When, in particular, an eij goes to 
zero, but t?ij = 1, then the subsystem Sj is decoupled from the subsystem 
Si. In this way, the matrix E describes the quantitative as well as qualitative 
changes in the interconnection structure of S .  The fact that E is generated 

70 
2. Stabilization 
by E, we denote by E(t) E El or simply, E E E (note the abuse of 
notation!). 
When E = 0, the system S of (2.11) breaks down into N decoupled 
subsystems Si of (2.12). This means that 
hi(t, 0) = 0, 
V t  E T. 
(2.15) 
Furthermore, we assume that the equilibrium state 2 = 0 of S remains 
invariant under all permissible structural perturbations, that is, for all E E 
E. This implies that when E = 0, we have 
gi(t, 0) = 0, 
V t  E T, 
(2.16) 
and xi = 0 is the unique equilibrium state of Si. 
We also need to comment on the decomposition (2.11) regarding the 
dimensions of the individual state spaces of Si in (2.12). We assume at 
present that 
R” = R”’ x R”* x ... x RnN, 
(2.17) 
and we consider no “overlapping” among the components z2 of 2. This 
means that 
T 
T 
2 = (XI, 
2;, . . . , 25) , 
and 
N 
n = C ni. 
i=l 
(2.18) 
(2.19) 
In Chapter 8, we shall lift this restriction and consider systems composed 
of overlapping interconnected subsystems. 
Now, we associate with S a matrix E and state: 
2.3. 
the sense of Liapunov for all E E E. 
DEFINITION. A system S is connectively stable if it is stable in 
Since connective stability is based upon the Liapunov’s stability con- 
cept, and because there are many types of Liapunov stability, there are 
many types of connective stability. In this chapter, our interest is in global 
asymptotic stability under structural perturbations, and if not stated other- 
wise, when we say “connective stability of s,” we mean “global asymptotic 
stability of the equilibrium z = 0 of S for all E E E.” For more general 
treatment of connective stability, see (Siljak, 1978). 

2.2. Vector Liapunov Functions 
71 
Interconnection matrices E(t), as specified by Definition 2.2, have ele- 
ments eij(t) which are continuous function of time such that eij(t) E [0, 11 
for all t E T. As far as the (vector) Liapunov method is concerned, this is 
an unnecessary restriction, and the theory goes through even if the elements 
eij: T x R" + R are piece-wise continuous functions of t and continuous 
functions of x. The elements may have unknown arbitrary forms provided 
eij(t, z) E [0, 11 for all (t, z) E T x R". In the following developments, 
we shall not insist on the dependence of eij's on time or state, because the 
implications will be either obvious or can be readily derived from the basic 
source (Siljak, 1978). 
2.2. Vector Liapunov Functions 
Analysis of connective stability is based upon the concept of vector Li- 
apunov functions, which was introduced independently by Matrosov (1962) 
and Bellman (1962). Roughly speaking, the concept associates several scalar 
functions with a given dynamic system in such a way that each function 
determines a desired stability property in a part of the state space where 
others do not. These scalar functions are considered as components of a 
vector Liapunov function, each component being an "aggregate" of the 
corresponding piece of the state space in much the same way as a sin- 
gle function in the classical Liapunov stability theory aggregates the state 
space of the entire system. Powerful generalizations of this idea have been 
obtained by many authors cited in Notes and References (Section 2.6). 
We shall present two types of constructions of vector Liapunov func- 
tions. The first construction (Siljak, 1978) is of linear order and uses norm- 
like Liapunov functions for the subsystems. The second approach (Araki, 
1978) utilizes quadratic Liapunov functions on the subsystem level and 
is termed the quadratic order construction. These two constructions have 
been selected because they are easy to use and, under standard conditions, 
they are the least conservative. 
In the linear construction, one associates with each decoupled subsystem 
Si of (2.12) a scalar function 'ui: T x Rn* + R+ such that q(t, xi) is a 
continuous function that satisfies a Lipschitz condition in xi, that is, for 
some rci > 0, 

72 
2. Stabilization 
We assume that the function vi(t, x i )  satisfies the inequalities 
where 1$1i, 
q52i E K,, 43 E K are comparison functions (Hahn, 1967; 
Siljak, 1978), and D+vi(t, ~ i ) ( 2 . ~ 2 )  
denotes the Dini derivative of vi(t, xi) 
computed with respect to (2.12). Inequalities (2.21) mean that we assume 
global asymptotic stability of the equilibrium x i  = 0 in each subsystem Si, 
and that we have a Liapunov function vi(t, xi) to prove it. 
As for the interconnections hi(t, x), we suppose that there are numbers 
<ij such that <ij 2 0 for i # j ,  and 
In order to state the condition for connective stability of S, we define 
the constant N x N matrix @ = ( s i j )  as 
1 - e../+ 
aa 
a 
2%) 
-E. a j  ...<. a 
a j  . 7 
a = j ,  
i # j .  
w i j  = { 
(2.23) 
Matrix @ has nonpositive off-diagonal elements, that is, it belongs to 
the class of matrices N = {W E RNXN: wij I 0, i # j ;  i, j E N). Under 
certain conditions, such a matrix belongs also to the important class M of 
M-matrices introduced by Ostrowski (1937). Because of our frequent use 
of M-matrices, we shall give several characterizations of M .  For compre- 
hensive treatment of M-matrices, see Fiedler and Ptdk (1962) and Siljak 
(1978), where a more general version of the following theorem is given: 
2.4. 
alent: 
THEOREM. Let W E N. 
Then, the following conditions are equiv- 
(i) There exists a vector d E RY, di > 0, i E N, such that the vector 
C =  Wd, 
(2.24) 
c E RY defined as 
is positive, that is, c, > 0 for all i E N. 

2.2. Vector Liapunov Functions 
73 
(ii) All leading principal minors of W are positive, that is, 
w11 
w12 
* .. wlk 
w21 
w22 
* - .  
W2k 
> O ,  
V k  E N. 
(2.25) 
................... 
Wkl 
Wk2 
* .  . Wkk 
(iii) W is a positive quasidominant diagonal matrix, that is, wii > 
0, i E N, 
and there exist numbers di > 0 such that 
N 
diwii > C djlwijl, 
V i  E N. 
(2.26) 
j=1 
j#i 
(iv) There exists a diagonal matrix D = diag{dl, d2, . . . , dN} with 
elements d, > 0, i E N, 
such that the matrix 
c = W ~ D +  
OW, 
(2.27) 
is positive definite. 
Re{&(W)} > 0 for all i E N. 
(v) The real part of each eigenvalue of W is positive, that is, 
(vi) The inverse W-' exists and W-' 2 0 element-by-element. 
Part (iv) was established independently by Tartar (1971) as follows: 
First, from (i) we conclude that the vectors u = W-'e and v = (WT)-'e, 
e = (1, 1, . . . , l)T, are positive element-by-element, and form a positive 
diagonal matrix D 
= 
diag{vl/ul, 
v2/u2, . . . , VN/UN}. We also 
recall that WT + W is positive definite if W is dominant diagonal, that 
is, satisfies inequalities (2.26) when di = 1, i E N. Now, choosing U = 
diag{ul, u2, . . . , UN} and V = diag(v1, v2, . . . , v ~ } ,  
we get WTD+DW = 
which is positive definite because W is dominant diagonal. On the other 
hand, it is easy to see that positive definitness of C implies (vi). 
WTVU-' + U-'vw = U-"(VWUy- + VWUIU-' = U-'(WT + W)U-l, 
At last, we are in a position to prove the basic stability result for com- 
posite systems (Siljak, 1978): 
2.5. THEOREM. A system S is connectively stable if the matrix 
is 
an M-matrix. 

74 
2. Stabilization 
Proof. We compute 
N 
I - c Wijd3j (IlZjlO 1 
j=1 
V ( t , z )  E T x R", 
V E  E E. 
Next, consider the function u: T x R" + R+, 
v(t, Z) = drv(t, z), 
(2.29) 
as a candidate for the Liapunov function of system S, where d E RY is a 
constant vector with positive (yet unspecified) components, and v: T x 
Rn + Rf is a vector Liupunovfunction w = (q, 
VZ, . . . , v ~ ) ~ .  
From (2.28), 
we get 
D+v(t, ~ ) ( 2 . 1 1 )  I - d T m 4 3 ( 2 ) ,  
V ( t ,  Z) E T x R", 
V E  E E, 
(2.30) 
where+3(~) = [ + ~ ~ ( I I z ~ I I ) ,  
+ 3 2 ( 1 1 ~ 2 1 1 ) ,  
. . . , ~ ~ N ( I I z N I I ) ] ~ .  
If W i s a n M -  
matrix, then from (i) of Theorem 2.4, we conclude that there exists a vector 
d > 0 such that (2.29) and (2.30) yield 

2.2. Vet tor Liapunov Functions 
75 
where 41, 411 E K:,, 
$111 E K: are comparison functions defined as 
(2.32) 
N 
(II.II> = C ci43i (IIX~II). 
Inequalities (2.31) are standard conditions for global asymptotic sta- 
bility of the equilibrium 2 = 0 of S .  Since the conditions are valid for all 
E E E, stability is also connective. 
Q.E.D. 
i=l 
2.6. REMARK. This is not the most general formulation of the vector 
Liapunov functions in the context of large-scale interconnected systems 
(Siljak, 1978), but it is all we need in the decentralized control problem. In 
this formulation, it is clear what advantages Theorem 2.5 offers in numeri- 
cal simplifications of stability problems: Liapunov functions are constructed 
for small size subsystems, and stability of the overall system is tested by 
an M-matrix the size of which is equal to the number of the subsystems. 
Although numerically attractive, the method is often criticized for its rel- 
ative conservativeness when compared with the standard single-function 
approach. Much of the recent work has been devoted to the reduction 
of conservativeness of the method by more sophisticated decompositions, 
better choices of subsystem functions, etc., as reported in this chapter and 
Notes and References in Section 2.6. 
2.7. REMARK. From the proof of Theorem 2.5, it follows that the con- 
nective property of stability comes for free when vector Liapunov functions 
are used. That is, whenever stability of the system S is established us- 
ing a specific matrix W E M ,  stability holds for any W E N such that 
W 2 W ,  
where the inequality is taken element-by-element. This is obvi- 
ous from (2.26). By using the interconnection matrices, we define W as 
in (2.23), and have E E E to imply W 2 W ,  
where W and W correspond 
to E and E, respectively. In this way, as pointed out by Lakshmikantham 
(1981), the connective stability concept represents a strengthening of the 
classical global asymptotic stability property, which aims to extract all 
that is available in the results obtained by using standard vector Liapunov 

76 
2. Stabilization 
function methods. As it turns out, this extra information about the con- 
nectivity aspect of stability is an important robustness characterization of 
interconnected systems in a large number of applications (Siljak, 1978). 
2.8. REMARK. We can relax the requirement in (2.22) that the &j's are 
nonnegative for i # j and still have D+v(t, Z ) ( ~ . J ~ )  
negative. From (2.28), 
it is obvious that we can set all negative &j's to zero and test a new matrix 
i?l = (Gij) for the M-matrix properties, where the elements Gij are defined 
as (Siljak, 1980), 
1 - &K.c.. 
aa 
a z a ,  
-EijKi 
max(0, & j } ,  
a = j ,  
i # j. 
Gij = { 
(2.33) 
We note that if any of the &'s is negative, they should be included in 
the corresponding diagonal element 2Tiij of W ,  
because they enhance the 
chance for W to be an M-matrix. To see that, one can use the argument 
of Remark 2.7. 
Let us now present the alternative quadratic construction of Liapunov 
functions proposed by Araki (1975, 1978). Due to our special interest in 
connective stability, we shall modify the original exposition to include struc- 
tural perturbations. 
In the quadratic approach, with each decoupled subsystem Si of (2.12) 
we associate a continuously differentiable function ui: T x R"' --+ 
R,, and 
assume that there exist comparison functions +li, 42i E Ic,, 43i E Ic, and 
a number qi > 0, such that 
where 
+ [grad U i ( 4  4 1 T g , ( t ,  Xi> 
(2.35) 
avi(t, xi) 
at 
GZ(4 4 ( 2 . 1 2 )  = 
is computed with respect to (2.12) as indicated. 

2.2. Vector Liapunov Functions 
77 
As for the interconnections, we assume that there exist numbers tij such 
that <ij 2 0 for i # j, and 
V ( t ,  x) E T x R". 
Finally, we define the N x N test matrix I&' = ( S i j )  as 
77' 1 - e..& 
22 221 
- E .  .<. . 
i = j ,  
i Z j ,  
S i j  = { 
(2.37) 
23 23 7 
and prove the following: 
2.9. THEOREM. 
an M-matrix. 
A system S is connectively stable if the matrix I@ 
is 
Proof Let us select the function v: T x R" -+ 
R+ defined as 
~ ( t ,  
X) = C d i v i ( t ,  x i )  
(2.38) 
to be a candidate for the Liapunov function of S ,  where the existence 
of numbers d i  > 0, i E N, 
is yet to be established. Then, we compute 
N 
i=l 
b(t, 2 ) ( 2 . 1 1 )  as follows: 
(2.39) 

78 
2. Stabilization 
T 
where 4 3  (IIXII) = [@ (IIx111> 
9 4iP (11.211> 
1 . . . > 4 g  (IIXNII)] 
7 and D = 
diag(d1, dz, . . . , d ~ } .  
Now, by (iv) of Theorem 2.4, we conclude from (2.34) 
and (2.39) that there exist comparison functions # I ,  $11 f KW, 4111 E X: 
such that 
and the system S is connectively stable. 
Q. E. D. 
2.10. REMARK. Our presentation of the quadratic construction of vec- 
tor Liapunov functions differs from the original exposition of Araki (1978), 
not only by inclusion of the connective stability aspect, but also by absence 
of a number of unused generalities. We also note that the quadratic con- 
struction demands the Liapunov functions to be continuously differentiable, 
whereas in the linear construction only continuity is required. 
As an illustration of the application of vector Liapunov functions, we 
consider stability of linear systems composed of interconnected subsystems. 
This class of systems is of particular interest in the context of control and 
estimation design. As a by-product of this analysis, we show that, with 
respect to linear systems, the linear and quadratic constructions of the 
Liapunov functions are equivalent. 
Let us consider a linear system S ,  which is described as 
S X=Ax, 
(2.41) 
where z(t) E R" is the state of S at time t E T, and A is a constant n x n 
matrix. We assume that the system 
N 
S: xi = Aixi + 
eijAijxj, 
i E N, 
(2.42) 
j=1 
is an interconnection of N subsystems 
S.4 
z- k. 
z - 
- A.2. 
a 
2 ,  
i E N, 
(2.43) 
with xi(t) E R"t being the state of the subsystem Si at time t E T, and 
Ai, Aij are constant matrices of appropriate dimensions. 

2.2. Vector Liapunov andions 
79 
To determine stability of S by linear construction, we associate with 
each free subsystem Si a norm-like function vi : R"' + R+ defined as 
where Hi is a constant, symmetric, and positive definite ni xni matrix. The 
function .(xi) satisfies the Lipschitz condition (2.20) with I E ~  = X$(Hi), 
where XII,I(H~) 
is the maximum eigenvalue of the matrix Hi. We assume 
that the function vi(xi) satisfies the inequalities 
where X,(Hi) and X,(Gi) are the minimum eigenvalues of the matrices Hi 
and Gi, which appear in the Liapunov matrix equation 
ATHi + H,Ai = -Gi. 
(2.46) 
In fact, we assume that all subsystems Si and, thus, the matrices Ai are 
stable. That is, all eigenvalues of A*, i E N, 
have negative real parts. It is 
a well-known fact (e.g., Hahn, 1967) that Ai is stable if and only if, for any 
symmetric positive definite Gi, there exists a symmetric positive definite 
Hi that is the unique solution of Equation (2.46), and the estimates (2.45) 
of wi and .iri follow. 
To bound the interconnections, we define the numbers 
tij = A$ ( A ; A ~ ~ )  
, 
(2.47) 
and follow the proof of Theorem 2.5 to obtain the test matrix W = (Sij) 
defined as 
1 - 2EiiAM(Hi)X;1(Gi)A$ (AEAii) , 
i = j ,  
i # j .  
w.. 
= 
(2.48) 
-2~ijX$(Hi)X~(Hj)X;1(Gj)X~ 
(A$Aij) , 
-23 { 
By Theorem 2.5, the system S of (2.42) is connectively stable if the 
matrix W is an M-matrix. 

80 
2. Stabilization 
We can simplify the test matrix W if we premultiply and postmultiply 
it by the positive diagonal matrices 
DR = diag{ X ~ / 2 ( H ~ ) X , ( G ~ ) ,  
X2/2(H2)X,(G2), . . . , X 2 ’ 2 ( H ~ ) X , ( G ~ ) } .  
Then, we get the elements wij of the new matrix W = DLWDR as 
(2.49) 
As is well-known (e.g., Siljak, 1978), due to the fact that DL and DR 
of (2.49) have positive elements, we have W E M if and only if W E 
M .  In the new test matrix W ,  however, the subsystem stability matrices 
Hi and Gi appear in the diagonal elements only, while the off-diagonal 
elements of W are solely due to the interconnection terms. This separation 
is convenient for interpretation of the M-matrix conditions in the context 
of overall system stability. 
From Remark 2.7, we know that the larger the diagonal elements ‘wii and 
the smaller the off-diagonal elements wij of W ,  the better are the chances 
for W to be an M-matrix. We recall that the ratio Xm(Gi)/&(Hi) is an 
estimate of the degree of stability of the isolated subsystem Si (see, for ex- 
ample, Kalman and Bertram, 1960; or more recently, Siljak, 1978). Clearly, 
we should choose the stability matrix Gi in (2.46) so as to maximize this 
ratio. Before we attempt to solve this maximization problem, let us show 
that the new matrix W is also a test matrix for the quadratic construction 
of vector Liapunov functions. 
We assume again that the subsystems Si of (2.43) are stable, but use 
the quadratic form 
~ i ( ~ i )  
= z T H ~ z ~ ,  
(2.51) 
as a Liapunov function for Si. Inequalities (2.34) are 
X m ( H i ) l 1 4 1 2  5 %(Xi) 5 XM(Hi)llZil12, 
(2.52) 
‘&(zi)(2,43) 5 - & n ( G i ) ~ ~ ~ i ~ ~ 2 ~  
V Z i  E Rni 7 
where the matrices Hi and Gi are those of Equation (2.46). 

2.2. Vector Liapunov Functions 
81 
As for the constraints on interconnections, we use again the numbers 
&j defined in (2.47), and following the proof of Theorem 2.9, obtain the 
test matrix W = ( ~ ~ i j )  
as 
A,(Gi) - 2EiiA~(Hi)Az (A:Aii) 
a = j ,  
CJij = { 
(2.53) 
-2EijA~(Hi)Az (A5Aij) , 
a # j .  
We immediately recognize the fact that W = DLW, where 
and 
E M if and only if W E M .  Therefore, as far as the linear 
constant systems are concerned, the linear and quadratic constructions of 
vector Liapunov functions are equivalent. 
Let us now return to the problem of choosing the best subsystem Lia- 
punov functions in the context of the M-matrix conditions. This problem 
is obviously important, because these conditions are only sufficient for sta- 
bility of the overall system S .  It is reasonable to solve this problem first for 
linear systems, and we start with the following (Siljak, 1978): 
2.11. PROBLEM. 
(2.55) 
subject to: ATH + HA = -G. 
In order to simplify the notation, the subscript identifying a subsystem 
is omitted, but we bear in mind that this problem should be solved for each 
subsystem separately. 
To solve Problem 2.11, we assume that all eigenvalues of the matrix 
A are distinct and are known numerically. This assumption would be p r e  
hibitive on the level of the overall system S. Presumably, the subsystems 
are relatively small, which is not too much to ask. Furthermore, in the sta- 
bilization problem, which we consider soon, these eigenvalues are assigned 
by local feedback, and conventional poleplacement techniques can be used 
to achieve any desired eigenvalue locations. 
We use first the transformation 
2 = T5, 
(2.56) 

82 
2. Stabilization 
where T is a nonsingular n x n matrix such that the equation 
S X = A X  
(2.57) 
- .  
becomes 
S: 5 = A5, 
(2.58) 
where the n x n matrix A = T-'AT is semisimple, that is, it has the block 
diagonal form 
where the first p blocks correspond to the complex eigenvalues of A, and 
the rest of the diagonal elements of A are the real eigenvalues. By denoting 
G = T ~ G T ,  13 = T ~ H T ,  
(2.60) 
we replace Problem 2.11 by the following: 
2.12. PROBLEM. 
(2.61) 
subject to: ATH + H A  = G. 
The solution to Problem 2.12 is known (Siljak, 1978): 
G = 28 diag {ul, u1, u2, u2, . . . , up, up, ~ 2 ~ + 1 ,  
. . . , an} , 
(2.62) 
H = $I, 
where 8 is an arbitrary positive number, and I is the n x n identity matrix. 
Then, 
where --CM < 0 is the real part of the maximal eigenvalue of the matrix 
A. Thus, the solution (2.62) yields the largest possible value of the ratio 

2.2. Vector Liapunov Functions 
83 
h ( G ) / A ~ ( f i ) ,  which is 2 u ~ ,  
and we can do no better. See (Siljak, 1978) 
for a detailed proof of this result. 
With the choice (2.62), the test matrix (2.50) becomes a new matrix 
We 
= (WE) defined by 
where the interconnection matrices Aij are changed to Aij = 7-lAijq.Y Ti 
is the transformation matrix which is used to get A, from Ai, and uh = 
-maxk{Re[Ak(Ai)]}, k E Ni = (1, 2, . . . , ni}. 
We should note that in transforming the original subsystems Si to Si to 
get the test matrix We, it may very well happen that the gain in the size 
of diagonal elements -uL is overcome by an increase in the off-diagonal 
elements of Wo when we go from Aij to A,j. In that case, it may be better 
to solve Problem 2.11 in the original state space (Pate1 and Toda, 1980). 
This we consider next. 
It is easy to see that the solution to Problem 2.11 is obtained by the 
choice G = 01 for any scalar O > 0. Recall (e.g., Hahn, 1967) that for a given 
symmetric positive definite G, the symmetric positive definite solution H 
of the Liapunov matrix equation (2.55) is 
H = im 
eATt GeAtdt. 
(2.65) 
From (2.65), we have the inequality 
x T H z  2 A,(G)xT (I" eATteAtdt) x = xTHx, 
(2.66) 
which is valid for all x, where k is the unique solution of the Liapunov's 
matrix equation ATH + fiA = -Am(G)I. By denoting G = A,(G)I, from 
(2.66) and the relation A,(G) = A,(G), we get 
(2.67) 
Since the solution of Liapunov matrix equation for 8G is OH for any G 
and 8 > 0, from (2.67) we conclude that the solution of Problem 2.11 is 
obtained for G = OI. Without loss of generality, one can choose O = 1. 
2.13. EXAMPLE. Although we have the largest ratio A,(G)/AM(H) for 
G = I without performing transformations, the resulting value may be far 

84 
2. Stabilization 
off from UM of A. We use a simple example to illustrate this point: 
s: x = [ O 
] z+y(t)z, 
-2 
-3 
(2.68) 
where x(t) E R2, and y: T 4 
R is an uncertain piecewise continuous 
parameter. We should estimate the size of y ( t )  that can be tolerated by 
stability of an otherwise linear constant system. 
Let us first stay in the original state space and get, from the solution 
(2.65) of Problem 2.11, 
514 114 
G = I ,  
H =  [1/4 
1/41 
Thus, 
and 
Iy(t)l 5 0.381, 
V t  E T. 
Alternatively, we transform S applying the transformation 
z=TZ, 
T = [ ’  
-1 
-2 ‘1 ’ 
Using 
we get 
(2.69) 
(2.70) 
(2.71) 
(2.72) 
(2.73) 
(2.74) 
(2.75) 
and the resulting bound is 
which is more than two and a half times better than (2.71). The reason is 
that, in the transformed space, the ratio Arn(G)/2A~(H) = 1 is the exact 

2.2. Vector Liapunov Functions 
85 
estimate of UM = 1, which is a measure of the degree of stability of S when 
the perturbation term is not present. We should note, however, that in this 
particular example, the transformation (2.72) leaves the perturbation term 
unchanged, thus producing the largest bound available in this context. In 
general, this is not the case, and a transformation such as (2.72) affects 
the perturbation function, so that the gain in the estimate of the stabil- 
ity degree may be diminished by the increase of the effective size of the 
transformed perturbation. 
2.14. 
EXAMPLE. At this point, we return to the two penduli of Sec- 
tion 2.1, and apply the method of vector Liapunov functions to establish 
connective stability of the closed-loop system S of (2.8). For given values 
of a and p, we choose the feedback gains kll, k12, kZl, and k22 in (2.6), so 
that the closed-loop subsystems SI, and S 2  of (2.7) are identical and have 
the eigenvalues at -1 and -2. The system S becomes 
Since the subsystem matrices A, and A 2  are the same as the system 
matrix A of S in (2.68), we have the ratio Xm(G)/X~(H) 
for the diagonal 
elements wii of the test matrix W of (2.50), calculated in (2.70). The inter- 
connection bounds are easily computed from (2.47) as A$? (AgAij) = y. 
The test matrix W for S is given as 
0.381 - y 
W =  [ . -7 
o.3iy-y] 
7 
because the fundamental interconnection matrix is 
E = [ ;  ;I. 
(2.78) 
(2.79) 
Applying the M-matrix conditions (2.25) to the matrix W of (2.78), we get 

86 
2. Stabilization 
which produces the bound on the interconnection parameter 
y < 0.19 
(2.81) 
for connective stability of S .  This means that the closed-loop system re- 
mains stable for all values of the interconnection parameter e such that 
e E [0, 11, provided (2.80) holds. It is interesting to note here that a de- 
centralized control law (2.6) can be chosen to stabilize the penduli even 
if the spring is moved all the way to the bobs, that is, when u = .t and 
y = k/m (see Example 2.23). 
2.3. Stabilization 
Armed with the powerful stability conditions of vector Liapunov func- 
tions, we are in a position to attack the problem of decentralized stabi- 
lization of interconnected systems. The control strategy is simple: stabilize 
each subsystem when decoupled, and then check stability of the intercon- 
nected closed-loop subsystems using M-matrix conditions. This is what 
we did to control the inverted penduli in the preceding section. Here, we 
want to provide a general framework for such stabilization practice, which 
proved to be effective in a variety of applications (Siljak, 1978). The fact 
that connective aspect of stability comes for free in this context is most 
gratifying. 
The announced decentralized control strategy will be appended with 
the global control (Siljak and Vuktevit, 1976a,b), the role of which is to 
enhance the dominance of subsystems stability by reducing the effect of the 
interconnections. This two-level control scheme has a considerable flexibil- 
ity, because, as we shall see soon, the global control may be implemented 
partially or not at all depending on the physical constraints of the plant as 
well as the wishes of the designer. 
Let us consider the system 
N 
S: Xi = Aixi + B~u: + C Aijxj + I'&, 
i E N, 
(2.82) 
j=1 
which is an interconnection of N subsystems 
Si: Xi = Aixi + Biuf, 
i E N, 
(2.83) 

2.3. Stabilization 
87 
where xi(t) E Rni and uf(t) E Rma are the state and the local input of 
Si, uf(t) E Re; is the global input to Si, and Ai, Bi, A,, I?, are constant 
matrices of appropriate dimensions. 
For local controls we choose the state feedback 
~f = - K ~ x ~ ,  i E N, 
(2.84) 
with constant gain matrices Ki, and the global control laws are 
N 
us= -c fijKijxj, 
i E N, 
(2.85) 
where the gain matrices Kij are constant and are distributed over the sys- 
tem S according to a binary N x N matrix F = ( f i j ) .  
By applying controls uf and us to system S ,  we get the closed-loop 
system 
j=l 
N 
S: i i  = Aixi + C A,.,. 
a3 
3 ,  
i E N, 
(2.86) 
j=1 
A, = 
- B ~ K ~ ,  
with 
A,. 
z j  - 
- A , .  
a j  - f . r . ~ . .  
zj 
a 
23' 
(2.87) 
We assume that each pair (Ai, Bi) is controllable so that we can always 
choose the gains Ki to place the eigenvalues of Ai at any desired locations 
(Kailath, 1980). The locations of the eigenvalues Ai(Ai) are 
-ui f 
j w i ,  . . . , --up, 
i *jwk,, 
. . . , -un,, 
i 
(2.88) 
which are distinct and such that Re Ai(Ai) < 0, k E N,. With this place- 
ment of subsystem eigenvalues, we can use a linear nonsingular transfor- 
mation 
xi = Ti5 
(2.89) 
to get the system S in the transformed space as 
N 
S: & = +c 
A..S. 
23 3 ,  
i E N, 
(2.90) 
j=l 
where 
Ai = T;'A,T,, 
A.. 
13 - 
- T,-'A..T. 
13 3 ,  
(2.91) 
and Ai is defined in (2.59). 

88 
2. Stabilization 
From the preceding section, we have the norm-like Liapunov function 
Vi(Zi) = ($fiiZi)1'2, 
(2.5 1') 
with Hi replaced by Hi, which is the solution of the Liapunov equation 
ATHi + H i &  = -Gi, 
(2.92) 
obtained as 
With this choice of subsystem Liapunov functions, we produce the test 
matrix W = (2zlij) defined as 
and the system S and, thus, S ,  are stable if W is an M-matrix. 
So far, we did not say how we selected the global gains Kij. From 
Remark 2.7, we know that the smaller the off-diagonal elements 8 i j  of W ,  
the better the chance for W to satisfy the M-matrix conditions. We also 
recall that this fact holds element-by-element, and each individual gain 
matrix K i j  can be chosen to reduce the effect of the interconnection term 
A, independently (Siljak, 1978). 
If fij = 1, then we choose K i j  to get 
(2.95) 
The matrix KG is computed by 
K*. 
v = J?A. 23 7 
(2.97) 
where f': = (f'Tf'i)-lf'T 
is the pseudo-inverse of f'i. In particular, when the 
rank of the composite matrix [f'i Aij] is equal to the rank of the matrix 
f'i itself, the choice (2.97) of the matrix l?G 
produces A i j  = 0. Similar 
cancellation of nonlinear interconnections by a nonlinear global control law 
was applied to a model of Large Space Telescope (Siljak, 1978). 

2.3. Stabilization 
89 
2.15. 
We did not consider the connective aspect of stability, 
because the emphasis was placed on the feedback structure of the global 
control. It is easy to involve the interconnection matrix in this context, by 
REMARK. 
rewriting (2.90) as 
s: 
It is now obvious 1 
N 
j=1 
(2.98) 
iat the concept of connective stability apy. -ies directly, 
save for the fact that any variation in the strength of the effective inter- 
connections 
implies a corresponding variation in the gain K i j  of the 
global control. That is, the interconnection parameters e i i  reflect norm-like 
changes of the effective interconnection matrices A:j = A i j  - fijf'il?;tj. 
2.16. EXAMPLE. To illustrate the proposed stabilization procedure, let 
us consider the interconnected system 
1 
] 
[ :] [ 3.20 
1.981 
21 + 0 
~
1
+
 
-14.72 
0.49 
XZ, 
-8.86 
8.50 9.36 
-7.92 
36.01 
0 
1 
xz = [ 32.32 -1.36 
-7.52 
-5.23 
0.49 
(2.99) 
which has the eigenvalues AI,~ = 0.76fj1.83, A3 = 11.54, A4 = -3.89, A5 = 
-1.16, and is unstable. The two subsystems 
0
0
 
-8.86 
8.50 9.36 
sz: xz = 
are in the companion form and are controllable. 
Using the local control laws 
21: = - I c f ~ 1 ,  
212 = -kz 2 2 ,  
Icl = (1791.14, 458.50, 46.36)T, 
Icz = (33.82, 1.14)T, 
e 
T 
(2.100) 
(2.101) 

90 
2. Stabilization 
the subsystems eigenvalues 
X i  = 0.63, 
X i  = -1.39, 
X i  = 10.12, 
A: = 5.04, 
A; = -6.41 
can be relocated to 
(2.102) 
X i  = -10, 
A; = -12, 
A: = -15, 
A: = -1.5. 
(2.103) 
A2 - -1, 
1 -  
Applying transformation (2.89) to each of the closed-loop subsystems 
S1 and S z ,  we get the closed-loop overall system S in the transformed 
space as 
-23.52 
-43.78 
O] 
21 + [ 40.23 
68.971 22, 
-15.49 
-24.96 
s: i, = 
(2.104) 
- 15 
179.95 
247.53 
-1.5 
-182.58 
-249.03 
-365.95 
From (2.94) and (2.103), we obtain the aggregate matrix 
10 
-98.51 
w =  [ -676.68 
1 
(2.105) 
Since W is not an M-matrix, we cannot establish stability of S. 
feedback structure matrix 
Let us now use the global control as defined in (2.85), with ri = Bi, the 
(2.106) 
and the gains 
f;, = (-238.95, -415.34)T, 
= (90.63, 124.14, 183.33)T, (2.107) 
which are computed from (2.97). This results in a global closed-loop system 
0.37 -2.25 
$1 + 0.40 -0.25 
22, 
s*: " = [ 
l2 21 
[ 0.44 
2.'7,] 
(2.108) 
-1.31 
-0.75 
0.72 
-1.5 
-1.31 
-0.75 
0.72 

2.3. Stabilization 
91 
and the aggregate matrix 
-2.37 
1 1 ’ 
(2.109) 
which is an M-matrix. Therefore, the system S of (2.104) is stable having 
the eigenvalues X1,2 = -1.03 & j  0.16, A3 = -10.27, A4 = -11.99, X g  = 
-15.17. 
It is clear that the system S* is connectively stable, for the 
fundamental interconnection matrix is 
(2.110) 
and the system S* becomes 
-10 
0 
0.37 -2.25 
s*: h - 
21 +El2 
0.40 -0.25 
2 2 ,  
- [ 0 
l2 
[ 0.44 
2.7,] 
-1.31 
-0.75 
0.72 
-1.5 
-1.31 
-0.75 
0.72 
(2.11 1) 
leading to the aggregate matrix 
(2.11 2) 
which is an M-matrix for all E E E. 
It is equally clear that the stabilization procedure, which considers a 
composite system as a whole, most likely would not produce a connectively 
stable closed-loop system. The same example treated in this section was 
considered by Siljak (1978) to demonstrate this fact. 
2.17. 
We must bear in mind that the method of vector Lia- 
punov functions for stabilization of composite systems produces only yes/no 
answers. No solid evidence is provided for the reasons of success or failure, 
although it is obvious that the larger the degree of stability of each subsys- 
tem the better the chances to “beat” the interconnections. Unfortunately, 
the degree of stability and the size of interconnections are not independent 
quantities, and pushing the eigenvalues of the subsystems further to the left 
may not produce a desired effect. This is best illustrated by the following 
example due to Sezer and Hiiseyin (1981). 
REMARK. 

92 
2. Stabilization 
2.18. EXAMPLE. The input-decentralized system 
0
1
 
0
2
 
? 2 =  [o 0 ]  x 2 +  [;I 
u2+ [o *] XI 
has unstable subsystems, but they are controllable and can be stabilized 
by local feedback control 
The closed-loor ystem is obtained as 
0 
l
i
0
 2 
4 1 2  -k11 ; 
0 
0 
0 
2
i
o
 1 
I 
------------------,-----------
I 
0 
0 
j 
-k22 
-k2l 
A necessary condition for S to be stable is 
k12k22 < 0, 
(2.114) 
(2.115) 
[::I 
. 
(2.116) 
which is obtained by considering the determinant of the system matrix 
in (2.115). From this condition it follows that for S to be stable, one of the 
closed-loop subsystems should be unstable! The vector Liapunov function 
method would not succeed in this case independent of the choice of local 
feedback. 
To finish this section on a positive note, we should mention the fact that 
when a system is stabilized via the vector Liapunov method, the closed-loop 
system is robust with respect not only to disconnections of the subsystems, 
but it can also tolerate a wide range of nonlinear and timevarying uncer- 
tainties in the interactions among the subsystems (see Chapter 3). 
2.4. Connective Stabilizability 
Now, we want to identify a class of complex systems which can always 
be connectively stabilized by local feedback. A way to do this is to char- 
acterize the systems for which the method of vector Liapunov functions 

2.4. Connective Stabilizability 
93 
succeeds (Siljak and VukEevik, 1977; Ikeda and Siljak, 1980a,b,c). The ba- 
sic assumption is that a given system 
N 
S: X i  = Aixi + biui + 
eijAijxj, 
i E N, 
(2.117) 
j=1 
is composed of controllable singleinput subsystems 
Si: X i  = A i ~ i  + biui, 
i E N, 
(2.1 18) 
with the state xi(t) E Rn* and the input ui(t) E R. Without loss of 
generality, we also assume that Ai and bi are given in the companion form 
Ai = [ .I 
..... .... .........:. 1 , 
bi = [ 
. 
(2.119) 
TO characterize the ni x nj matrices A, =_(a%) of the interactions 
between the subsystems Si, we follow Ikeda and Siljak (1980a), and define 
the integers mij as 
0 
1 
... 
0 
0 
0 
... 
-a! 
-a! 
.. . -a;, 
{ q - P } ,  
Aij # 0, 
(2.120) 
(p,d : 
#o 
-n, 
Aij = 0. 
The integers mij can be interpreted in terms of the structure of Aij as 
the distance between the main diagonal and a border line of the nonzero 
elements, which is parallel to the main diagonal. The three characteristic 
cases are shown in Figure 2.1, with possible nonzero elements a: appearing 
in shaded areas only. 
To stabilize the system S, we apply the decentralized feedback control 
law 
IJ,. %
-
 - -kTx. %, 
 EN. 
(2.121) 
The resulting closed-loop system is 

94 
2. Stabilization 
ni 2 nj 
m.. 
'I 
(a) mi > 0 
ni I 
nj 
ni b nj 
(b) m.. = 0 
ni I 
n i 
ni 2 nj 
ni I n. 
(c) mij < 0 
Fig. 2.1. Interconnection matrices. 

2.4. Connective Stabilizability 
95 
If we denote by 
Ai = Ai - bik? 
(2.123) 
the closed-loop matrix of the ith subsystem, we can get S in a compact 
form 
S: X = [AD + Ac(E)]z, 
(2.124) 
where z(t) E R" is the state of S ,  and 
AD = diag(A1, A,, . . . , AN}, 
Ac(E) = (eijAij). 
(2.125) 
We are interested in a little more than global connective stability of S: 
2.19. 
The system S is said to be decentrally connectively 
exponentially stabilizable if, for any given positive number T ,  there exists a 
decentralized control law such that the solutions z(t; to, 20) of the system 
S satisfy the inequality 
DEFINITION. 
where ll and T are positive numbers. 
We also need to define a subset I, = {il, i 2 ,  . . . , i,} of the index set N, 
for which il < i 2  < . . . < i,, T 5 N .  By permuting the elements of I,, we 
form a set J, = {jl, j2, . . . , j,}, and state the following: 
2.20. THEOREM. The system S is decentrally connectively stabilizable 
if the inequality 
holds for all subsets I, and J, of N. 
(2.127) 
Proof. This theorem was established in (Ikeda and Siljak, 1980a) by 
following the proof of a less general result (Corollary 2.22) obtained by 
Siljak and VukEeviC (1977). 

96 
2. Stabilization 
First, the gain vectors ki are chosen so that each closed-loop matrix 
A i  = Ai - bik: has a set Ci of distinct real eigenvalues, which is defined as 
(2.128) 
The real eigenvalue assumption is not essential, but is convenient to use in 
the proof. The positive number p is to be determined so that the overall 
system S is exponentially connectively stable. 
G={(x> A ; = - ~ U ; ,  
~
2
1
 
1 u ~ > O ,  C E N i } .  
Then, by the help of transformation 
5 .  - T.-. 
a - ax,, 
we get the system S in the form 
N 
6: i. 
a - 
- A.-. 
axa +C eijAijxj, 
i E N, 
j=1 
where 
Ai = T-'(Ai - bikT)T,, 
Ai = diag{-pui, -pa, . . . , -pubi}. 
Aij = T;'A,,T. 
v 3 ,  
and 
Then, we factorize the matrix Ti as 
Ti = &pi, 
where the matrix R, = &(p) is 
& = diag(1, p, . . . , pn"-'}, 
and 2 
is the Vandermonde matrix 
1 
... 
1 
... 
... 
To measure the magnitude of &, we use the number 
(2.129) 
(2.130) 
(2.131) 
(2.132) 
(2.133) 
(2.134) 
(2.135) 
(2.136) 
(2.137) 
p=l 
q=l 
for which we have 

2.4. Connective Stabilizability 
97 
and IIAijII = Xz(A;Aij). Now, we define two N x N matrices 
P = diag{&, 
c&, 
. . . , ( z M }  
N , 
Q = (pmijP1 c..) 
23 , 
(2.138) 
where OL = mink{cTi}, and form the aggregate matrix 
W = P - Q .  
(2.139) 
We show that the system S is stabilizable if W E M for some p 2 1. 
This amounts to showing that solutions s(t; to, so) satisfy inequality (2.126) 
for some positive numbers II and A. For this purpose, we associate with 
each subsystem Si a scalar function 6i : Rni --+ 
R+ defined as 
Vi(2.i) = kT2. 
a 
a .  
The derivative tji(&)(2,130) is majorized as 
(2.140) 
(2.141) 
As usual, we consider a weighted sum of vi's, 
N 
(2.142) 
i=l 
as a candidate of a Liapunov function for S ,  where di's are all positive num- 
bers yet to be determined. From (2.140) and (2.142), v(2) and fi(2)plm) 
can be estimated as 
where d, = mini{di}, dM = maxi{di}, 
W ~ D  
+ DW = C, 
(2.144) 

98 
2. Stabilization 
and D = diag{dl, d2, . . . , dN}. Since W E M implies the existence of 
D such that C is positive definite, we conclude from (2.143) that the S(F 
lutions z(t; to, zo) of S satisfy inequality (2.126) for II = d $ d i 2  and 
A = pd$X,(C). 
So far we have shown that W E M for some p 2 1 implies stability 
of 8. We should now demonstrate the fact that we can always find a p so 
that W E M .  From the condition of the theorem, we have a possibility of 
expressing the kth leading principal minor (2.25) of W as c&u& . . . cb + 
ck1p-I + ~ k z p - ~  
+ . . . + Ckt, p p e k ,  where the eke's are constants and & is an 
integer. This, in turn, implies that every leading principal minor of W is 
positive for a sufficiently large p .  
Finally, we should show that the above argument goes through for any 
prescribed number A. To see that, we consider the system 
N 
8,: & = (Ai + A&) Zi + C eijAijZj, 
i E N, 
(2.145) 
instead of S ,  where Ini is the ni x ni identity matrix. We note that if the 
solutions of the system S, are bounded, then they satisfy inequality (2.126). 
By redefining the aggregate matrix as 
j=l 
W, = P - ~ - ‘ A I N  - Q, 
(2.146) 
it is easy to show that we can repeat the same argument for W, that 
worked for W ,  and conclude that the solutions of S ,  are bounded. This 
means that, by choosing the gains ki of the decentralized control law (2.122) 
appropriately, we can realize any degree A of stability in the closed-loop 
system S. 
Q.E.D. 
2.21. REMARK. 
“Sufficiently large p” implies that we have to push the 
eigenvalues of the subsystems far enough to the left. This, however, may 
result in a local high-gain feedback which should cause concern in case noise 
or modeling errors are significant. 
An interesting special case (Siljak and VukEeviC, 1977) of Theorem 2.20, 
which is given directly in terms of the matrices A, = (ag), is given by: 
2.22. COROLLARY. The system S is decentrally connectively stabiliz- 
able if 
u;=o, 
p < q ,  
(2.147) 
wherep E Ni, q E Nj, and Nk = (1, 2, .. ., nk}. 

2.4. Connective Stabilizability 
99 
Restriction (2.147) means that the matrices A, of the system S in 
(2.117) have either of the two structures in Figure 2.lb. 
2.23. EXAMPLE. By inspection of the model (2.4) for the inverted pen- 
duli of Section 2.1, we conclude that it belongs to the class of systems 
considered in this section. Let us now apply the proposed stabilization p r e  
cedure and show that no matter what is the strength of coupling between 
the two penduli, there is always a set of local feedback gains which stabilze 
the overall system. In fact, in this simple example we can express explicitly 
the gains in terms of the coupling. 
We first transform the closed-loop system S of (2.8) into the form (2.130) 
where 
A1 = A2 = A = diag{ -pu1, -puz} 
(2.148) 
and 
(2.149) 
Then, we compute the local feedback gains 
in terms of the eigenvalues -pu1 and -pu2 of A, obtaining 
kll = kz1 = P P ( Q 1  + Qz), 
k12 = k22 = p p u1u2 + p a .  
(2.151) 
2 -1 
To calculate the lower bound on p for stability, we factor the matrices 
TI and TZ of (2.149) as in (2.133) to get 
R1 = R2 = diag(1, p}, 
= pz = [ 
' -Lz] . 
- 
Q1 
(2.152) 
Using (2.136) and (2.151), and assuming that (TI < UZ, we compute the 
aggregate matrix 

100 
2. Stabilization 
For this matrix to satisfy the determinantal conditions (2.25) of Theo- 
rem 2.4, that is, to be an M-matrix, we should chose p as 
(2.154) 
Finally, in terms of feedback gains (2.151), we interpret the inequality (2.154) 
as 
kll = kzl > 
Pa1 
101 - 0 2  I1iZ 
(2.155) 
This choice of the local feedback gains guarantees connective stability of 
the two interconnected penduli. 
2.24. 
Examples 2.18 and 2.23 show the importance of as- 
sumptions (2.120) and (2.147) concerning the interconnection structure. 
Although the assumptions are more general than those of Davison (1974), 
Ikeda et al. (1976), Sezer and Hiiseyin (1978), Richter and De Carlo (1984), 
and many others, it is not the best we can do. A broader class of systems 
is considered in the next section, via graph-theoretic methods (Sezer and 
Siljak, 1981). The use of graphs is not surprising in view of the fact that test- 
ing of condition (2.127) is a combinatorial problem which involves checking 
C z l  N ! / ( N  - r)! inequalities. A further development along these lines can 
be found in (Shi and Gaq 1986, 1987). 
REMARK. 
In the rest of this section, we show how Theorem 2.20 can be applied 
to interconnected systems composed of multi-input subsystems (Ikeda and 
Siljak, 1980a). For this purpose, we consider again the system S of (2.82) 
in the form 
N 
S: ki = Aiq + Biui + 
eijAijzj, 
i E N, 
(2.82’) 
j=1 
where we ignore the global control. We again assume that all pairs (Ai, Bi) 
are controllable and, without loss of generality, further assume that the 
decoupled subsystems 
Si: ki = A,zi + Biui, 
i E N, 
(2.83‘) 

2.4. Connective Stabilizability 
101 
are in the Luenberger's canonical form (Luenberger, 1967). Then, each 
decoupled subsystem Si is reducible to a set of singleinput components 
having a companion form, by the use of a preliminary local feedback control 
where w ( t )  E Re* is the new input vector to the ith subsystem, Ki is an 
mi x mi gain matrix, Gi is an mi x .ti constant matrix, and .ti is the number 
of single-input components contained in Si. That is, the closed-loop system 
becomes an input decentralized system with each singleinput component 
having the form (2.117). Now, we can apply Theorem 2.20 to the system 
S of (2.157). This reduction of a multi-input subsystems to single-input 
components is not unique. For more details of the reduction process, see 
Ikeda et al. (1976), and Sezer and Hiiseyin (1978). 
2.25. EXAMPLE. Let us consider a system 
where the subsystems are given in the Luenberger canonical form. To trans- 
form the first subsystem of (2.158) into a single-input subsystem, we im- 
plement the preliminary control 
(2.159) 

102 
2. Stabilization 
leave the second subsystem as is, and get 
3
0
1
5
 
5 2 =  [; 4 
2 2 +  [;I 
u 2 + e 2 1  [ 2  1 4 6] 2 1 .  
We associate integers m i j  with the system S as 
mll = -6, 
m 1 2  = 1, 
m 2 1  = 3, 
m 2 2  = -6. 
(2.161) 
Since 
( m 1 2  - 1) + (ma - 1) = 2 > 0, 
(2.162) 
S of (2.160) violates condition (2.127) of Theorem 2.20, and we cannot 
establish decentral stabilizability of S. 
Next, consider the local control law 
(2.163) 
-2 
-1 
2 -1 
2 
1
0
0
 
u 1  = - 
in order to reduce the first subsystem two single-input components while 
the second subsystem is unchanged. We get 
5 1 2  = [ -1 
O 
-2 ] 2 1 2  + [ y] 2112 + e l 2  [ 
y] 2 2 ,  
Finally, we rename the states ~ 1 1 ,  
2 1 2 ,  and 2 2  as 2 1 ,  2 2 ,  and 2 3  to make 
the system fit the standard form (2.117) of the system S. In order to use 
Theorem 2.20, we compute 
(2.165) 
m.. 
zJ - 
- -6 , 
for all other pairs ( 2 ,  j ) .  

2.5. Graph-Theoretic Algorithm 
103 
Since the integers (2.165) satisfy the condition Theorem 2.20, we con- 
clude that the system S of (2.164) is decentrally stabilizable by local feed- 
back 
T 
T 
(2.166) 
By going back to the original system S of (2.158), we further conclude that 
S is decentrally stabilizable by the feedback 
T 
~ 1 1  
= - k 1 1 ~ 1 1 ,  
' ~ 1 2  = - k 1 2 2 1 2 ,  
'1~2 = - k 2 2 2 .  
1
0
0
 
(2.167) 
To complete the design, we choose the gains kll, k 1 2 ,  and kz by a stan- 
dard single-input eigenvalue-assignment scheme (e.g., Kailath, 1980). 
2.5. Graph-Theoretic Algorithm 
Our solution to the decentralized stabilizability problem turned out to 
be essentially combinatorial, which suggests a use of graphs. This approach 
is further reinforced by the fact that the outcome of the stabilizability test 
depends only on the elements of system matrices being equal or different 
from zero rather than being fixed numerical values. Before we take advan- 
tage of these facts using a graph-theoretic formulation, we will present gen- 
eral stabilizability conditions for decentralized control of complex systems 
(Sezer and siljak, 1981). The conditions are not obtained by the method of 
vector Liapunov functions, but can be interpreted in the context of Small- 
Gain Theorem (Zames, 1966). The connectivity aspect of decentral stabiliz- 
ability is not transparent outside of the Liapunov's framework, and we will 
be content to treat the elements of interconnection matrices as unknown 
but constant. 
Let us again consider the decentrally controlled system 
S: X = [A, + Ac(E)] X ,  
(2.124) 
where E = (eij) is an N x N constant matrix that belongs to the class 
E = { E  E RNxN: -1 5 eij 5 l}, 
(2.168) 
and A, = diag{Al, A 2 ,  . . . , AN}, Ac(E) = (eijAij), Aij = (ag), as be- 
fore. Notice that eij's are permitted to vary in [-1, 11 instead of [0, 11. 

104 
2. Stabilization 
In view of the sign-insensitive constraints (2.22) on the interconnections 
among the subsystems, the added flexibility concerning q j ’ s  can be in- 
cluded in all connective stability and stabilization results obtained so far 
in this chapter. 
The system S is exponentially connectively stable with degree T if 
Re{h[& + A c ( E ) ] }  I 
-T, 
VE E E l  
(2.169) 
where T is a positive number as in Definition 2.19. Since the subsystems 
Si are all in the companion form (2.119), the gain vectors ki of (2.122) can 
always be chosen so that each matrix Ai = Ai - bik: has a set Li of real 
distinct eigenvalues A; defined by 
Li = {A;: 
X i  = -pic:, 
pi > 0, U: > 0, t! E Ni}, 
(2.170) 
where the 0: are arbitrary positive numbers, 
pz = p”’, 
i E N, 
(2.171) 
p and V, are positive numbers, and N, = (1, 2, . . . , n,}. To explain the 
role of the numbers p and u,, we note first that the underlying idea of the 
stabilization scheme is to achieve stability of the overall closed-loop system 
by shifting appropriately the eigenvalues of the decoupled subsystems. The 
number pa represents the size and uz the relative importance of the shift in 
the ith subsystem. 
The result established in (Sezer and Siljak, 1981) is the following: 
4 
2.26. THEOREM. The system S is decentrally connectively stabilizable 
if 
q-1 
.. Pj 
lim n 
ug - 
= o  , 
p++CC 
A 
i E I, 
(2.172) 
j E J, 
for all IT, 
JT7 
T E N, and all (p, q). 
Proof. We claim that for a given T there exists a sufficiently large ij > 0 
such that, whenever p > p, the system S exponentially connectively stable 
with degree T. This is equivalent to saying that there is a ij such that 
(s - T)I - AD - Ac(E)] # 0, 
Vs: Re s 2 0, 
V E  E E. 
(2.173) 

2.5. Graph-Theoretic Algorithm 
105 
Suppose to the contrary that the claim is not true. That is, we assume 
that the determinant in (2.173) is zero for some SO such that Re SO 2 0 and 
some Eo = (e;) E E, or, equivalently, there exists a nonzero vector y E C" 
such that y = (yT, y
:
,
 
. . . , yg)T and 
[(so - 7r)I - AD - Ac(Eo)] Y = 0, 
(2.174) 
which is further equivalent to 
(2.175) 
Using the transformation matrix 2 of (2.135) and 
%(pi) = diag{l, pi, . . . )  p y - ' } )  
(2.176) 
we get 
T-' Rcl (pi) Ai R, (pi) = -pi hi, 
(2.177) 
where 
Ai = diag{af, CT;, . . . , .Ai}. 
(2.178) 
Hence, premultiplying both sides of (2.175) by ~~'R~'(pi) 
and letting zi = 
q-' Rz:' (pi)yi, we obtain 
or, equivalently, 
Taking l, norms of both sides of (2.180), and noting that, for suffi- 
ciently large pa) we have 

106 
2. Stabilization 
where uh = min(ui, ui, . . . , uki}, we obtain 
(2.182) 
Defining L(p) = [4j(p)] and E E RY, 
(2.182) can be written in a compact form as 
[I - L ( p ) ]  z I 0, 
(2.185) 
where inequality is taken element-by-element. 
implies that 
Now, condition (2.172) of the theorem, together with (2.176) and (2.183), 
(2.186) 
for all IT, Jr, T E N. This, in turn, implies that there exists a p > 0 such 
that, for p > p, all principal minors of the matrix I - L ( p )  are positive. 
Since I -  L(p) E N ,  from (vi) of Theorem 2.4, we have [I - L(p)]-' 2 0 for 
p > p. This implies that, for p > p, the system S of (2.124) is exponentially 
connectively stable with degree r, for, otherwise, (2.185) would yield Z 5 0 
contradicting the definition (2.184) of E. 
Q.E.D. 
Now we will do what we promised at the beginning of this section: to 
formulate a graph-theoretic test for decentral stabilizability. For this task, 
we need first to characterize the structure of interconnection matrices Aij. 
For each Aij, we define the integers 

2.5. Graph-Theoretic Algorithm 
107 
Fig. 2.2. Interconnection matrix. 
recursively as 
(a) p y  is the largest integer such that u$ = 0 for all p < p y  and 
(b) q? is the smallest integer such that ag = 0 for all p < p y  + 1 and 
The integers p y ,  qy, C = 1, 2, . . . , kij, define a boundary for nonzero ele- 
ments of the matrix Aij as shown in Figure 2.2. 
ij 
q > qe-l, C = 1, 2, . . . , kij, where q;j = 0; 
ij 
(I>@, C = l , 2  ,..., kij. 
2.27. LEMMA. Condition (2.172) of Theorem 2.26 holds if and only if 
it holds when the matrices Aij = (ug) are replaced by the corresponding 
matrices Aij = (ii$) defined as 
. .  
.. 
1, 
0, otherwise. 
if (p, q) = ( p y ,  qiJ) for some C = 1, 2, . . . , kij, 
(2.188) 
Proof Necessity is obvious. To prove sufficiency first note that for fixed 
T, I,, and J,., (2.172) need be checked only for those (p, q) such that a$ # 0, 
i e . ,  for which p 2 p? and q 5 q? for some C = 1, 2, . . . , kij. The proof 
then follows from the fact that if (2.172) holds for (p;, q;), then it also 
holds for all (p, q) such that p 2 p y  and q 5 q?. 
Q.E.D. 
To construct a digraph D associated with S ,  we first associate a sub- 
graph Di = (Xi, &) with the ith closed-loop subsystem &. Because of the 

108 
2. Stabilization 
Fig. 2.3. Digraph Di. 
special (companion) structure of ai, the digraph D i  has the form shown in 
Figure 2.3. In this analysis, we assign weights to vertices and edges of D i .  
The weighted digraph D = ( X ,  ED U Ec) for the system S is defined by 
N 
N 
x=U xi, 
E D = U  E ~ ,  
(2.189) 
i=l 
i=l 
and EC is a set of edges connecting the vertices belonging to distinct Xi’s, 
so that there is an edge X j q  -+ xip from vertex xjq of D j  to vertex xip of D i  
if and only if (p, q) = ( p y ,  q?) for some C = 1, 2, . . . , kij; that is, each edge 
in Ec corresponds to a corner (nonzero) element in one of Aij in Figure 2.2. 
Zero weights are assigned to the edges in k. 
We define the net-weight of a directed path in D as the sum of the 
weights of the vertices and edges traversed along the path, and prove the 
following: 
2.28. LEMMA. If Pi : xie f xik denotes the shortest path in Di = 
( X i ,  &) from Zit E Xi to xik E X i ,  then w{Pi} = (k -e - l)&, where u{Pi} 
denotes the weight of Pi. 
Proof. The proof follows from the definition of w{Pi} and the fact that 
Pi is given as 
Xie -+ Xi,e-1 -+ . . . -i 
x i k  , 
e >  k, 
(2.190) 
X i [  -+ 
xini -t xi,ni-l ---$ . . . -+ xik , e < k, 
Q.E.D. 
Pi: 
where -i denotes a single edge in &. 

2.5. Graph-Theoretic Algorithm 
109 
Finally, we arrive at: 
2.29. THEOREM. 
having the properties: 
Let C denote the class of all simple cycles C in D 
(i) C contains at least one edge in Q; 
(ii) for any Xi, C contains at most one edge in Ec which emerges from 
(iii) if a path pi : z i t  A X i k  between two vertices z i t ,  X i k  E X, is a part 
xi; and 
of C, then Pi is the shortest path. 
Then, the condition (2.172) of Theorem 2.26 is satisfied if and only if 
there exists no cycle C E C having a nonnegative net-weight. 
Pmob By Lemma 2.27, it suffices to show that 
(2.191) 
j E J r  
for all T, Ir, Jr, and all (p, q) = ( p y ,  qy), C = 1, 2, . . . , k,, if and only if 
there exist no cycles C E C in D with w{C} 2 0. 
To prove necessity, consider a typical cycle C E C in D, which has the 
following structure: 
Using Lemma 2.28, the weight of C can be computed as 
Considering 
(2.194) 
where the left hand side has the form of the expression in (2.191) with 
4 = {ill 223 * 
* 7 i r } ,  
Jr = {jl, j ~ ,  
. . ., 
(2.195) 
it follows that if w{C} 1 0, then (2.191) fails to hold, completing the proof 
of necessity. 

110 
2. Stabilization 
Conversely, if (2.191) fails to hold for some T ,  I,., J,., and some of (p, q) = 
(a) C has the form of (2.192), that is, it contains at least one edge in 
( p y ,  qy), then we can construct a cycle C in D such that: 
Ec, and it follows the shortest paths in D i ,  i E I,.; and 
(b) w{C} L 0. 
If C E 2, 
then the proof follows. If, on the other hand, C @ c^ for it 
contains two or more edges in &, which emerge from the same xi, i E I,, 
then breaking C into two pieces and adding to each piece some edges in &, 
we can construct two cycles C1 and C2, at least one of which satisfies the 
properties (a) and (b) above. Continuing this procedure (if necessary) we 
finally obtain a cycle C E C with w { C }  
0. This completes the proof of 
the sufficiency part and, thus, the proof of the theorem. 
Q.E.D. 
2.30. 
We note that conditions (ii) and (iii) of Theorem 2.29 
are not essential, but are useful in minimizing the number of cycles involved 
in testing condition (2.172). In fact, it is possible to construct the subgraphs 
D i  associated with Si in such a way that there is only one path Pi between 
any two vertices Zip, x i k  E Xi, so that any cycle c satisfying conditions 
(i) and (ii) also satisfies (iii). Moreover, this reconstruction of the system 
digraph can be done without effecting the number and weights of the cycles 
belonging to the class c^. 
REMARK. 
2.31. REMARK. For any cycle C E e, the weight of C is a linear ex- 
pression in ui, i € N. Therefore, the condition of Theorem 2.29 can be 
reformulated as a set of linear inequalities 
(2.196) 
where u = (ul, 
v2, . . . , u ~ ) .  
The matrix M has the elements that are the 
coefficients of ui appearing in the weights of the cycles, with each row 
corresponding to a cycle in C. In (2.196), the N x N identity matrix IN 
is included to ensure positivity of each ui. Therefore, stabilizability of S 
is reduced to solving linear inequalities (2.196), which can be done using 
standard techniques (e.g., Zhukhovitskii and Avdeyeva, 1966). 
2.32. 
In determining the cycles of D, the existing algorithms 
(Deo, 1974) can be modified to account for only those cycles in c^ which are 
REMARK. 

2.5. Graph-Theoretic Algorithm 
111 
required by Theorem 2.29. Certain simplifications can precede the account- 
ing of the cycles in e. First, we should eliminate the cycles arising from the 
self-interconnections, that is, those that are constituted of the edges of & 
which have the form xip + xip. If there exists such an edge with p < q, then 
this edge forms a cycle with a nonnegative weight (q - p - 1)vi and (2.196) 
is violated. On the other hand, if p 2 4, the edge can be eliminated without 
affecting the condition (2.196). Secondly, a decomposition of D into strong 
components (see Section 1.3) can be used to eliminate all edges between the 
strong components, thus reducing the accounting of cycles to the level of 
components. In this way, (2.196) becomes a set of independent inequalities 
corresponding to the strong components of D. 
2.33. 
To illustrate Theorem 2.29 let us show that if Ac = 
(Aj) has the structure as shown in Figure 2.4, then the system S is stabi- 
lizable by decentralized feedback. Choose VN = 1, and Y N - ~ ,  
V N - 2 ,  . . . , v1 
recursively so that 
EXAMPLE. 
N 
Ui> c (nj-2)vj, 
i = N - l , N - 2 ,  ..., 1. 
(2.197) 
It is easy to see that the digraph D = (X, ED U Ec) corresponding to 
the interconnection matrix Ac in Figure 2.4 has the structure shown in 
Figure 2.5. Now consider a cycle C E 6 that passes through the subgraphs 
Djl, D i Z ,  . . . , D i r  in the given order. Letting ir+l = il and io = ir for 
convenience, the index set I, = {il, i 2 ,  . . . , ir} can be partitioned into four 
disjoint subsets: 
j=i+l 
(2.198) 
A typical cycle and the corresponding partitioning of the index set I, is 
illustrated in Figure 2.6. Referring to Figure 2.6 and using Lemma 2.27 the 
weight of C can be computed from (2.198) as 

112 
2. Stabilization 
A c =  I 
0 
I 
Fig. 2.4. Interconnection matrix. 
We also note that if min{ic E IT} = j, then j E .IT1. 
Since 1 5 ei 5 ni, i E 
N, 
(2.199) implies that 
The choice of vi, i E N, 
in (2.197), guarantees that w{C} < 0, and 
stabilizability of S follows from Theorem 2.29. 
A logical extension of Theorem 2.29 is to include the output instead of 

2.6. Notes and References 
113 
r-------- 
1 
h 
D2 
h 
DN 
Fig. 2.5. Interconnection structure. 
state feedback. This problem is considered in Section 5.4 using the concept 
of almost invariant subspaces. 
2.6. Notes and References 
Liapunov’s Direct Method is essentially an aggregation process whereby 
a system of equations involving several state variables is represented by a 
single scalar function, which contains pertinent information about stability 
of the entire system. When a system has a large number of variables, the 
aggregation process based upon a single function may get bogged down in 
a welter of details with increasing liability in the end result. A crucial con- 
tribution to Liapunov’s method in the context of complex systems has been 
made by Matrosov (1962) and Bellman (1962), when they simultaneously, 
but independently, introduced the concept of vector Liapunov functions. 
By a suitable construction, Bailey (1966) showed how the concept applies 
to aggregation of interconnected dynamic systems and, thereby, launched 
the new version of the method in the uncharted area of large-scale dynamic 
systems. 
After a relatively slow start, the vector concept gained momentum and 
is now a rather well established area of research. A wide variety of models 
and equally diversified kinds of stability have been considered. The ob- 

114 
2. Stabilization 
L -------- 
--I 
Fig. 2.6. A typical cycle. 
tained results have been reported in several recent surveys (Voronov, 1982; 
Michel, 1983; Siljak, 1983; Matrosov, 1984; Vidyasagar, 1986; Voronov and 
Matrosov, 1987) and books (Lakshmikantham and Leela, 1969; Martynyuk, 
1975; LaSalle, 1976; Rouche et al. 1977; Michel and Miller, 1977; Siljak, 
1978; Matrosov et al. 1980; Matrosov and Anapolskii, 1980, 1981; Ma- 
trosov, 1981; Jamshidi, 1983; Matrosov and Vasilev, 1984; Voronov, 1985; 
Matrosov and Malikov, 1986; Grujib et al. 1987). We do not plan to review 
this massive amount of information, but rather concentrate on the areas 
that are directly related to our interest in robust (connective) stability of 
decentralized control schemes. 
CONNECTIVE STABILITY 
To capture the effect on stability of the essential uncertainty residing 
in interconnections of complex systems, the concept of connective stabil- 

2.6. Notes and References 
115 
ity was introduced (Siljak, 1972) as a Liapunov stability under structural 
(parametric) perturbations. The concept has been generalized consider- 
ably over the years (see the surveys of Siljak, 1978, 1989) to accommodate 
a wide variety of stability definitions and mathematical models of dynamic 
systems. Connective stability has been redefined to include input-utput 
models (Moylan, 1980; Vidyasagar, 1981, 1986), timedelay and heredi- 
tary systems (Ladde, 1976a, 1977; Anderson, 1979; Lewis and Anderson, 
1980; Sinha, 1980, 1981; Shigui, 1988), stochastic models (Ladde and Siljak, 
1976a, b; Siljak, 1978), the variation of constants method (Aftabizadeh, 
1980), evolution systems (Spiteri, 1986), as well as incompletely known sys 
tems, simplified models, #and symmetric strongly coupled systems (Lunze, 
1983, 1984, 1986), bilinear systems (Loparo and Hsu, 1982), and systems 
under periodic structural perturbations (Burgat and Bernussou, 1978). 
Most of the results obtained for connective stability of continuous sys- 
tems can be carried over to discrete systems (Siljak, 1978). A version of 
Problem 2.11 has been solved recently (Sezer and Siljak, 1988) to generate 
vector Liapunov functions which provide the best estimates of robustness 
bounds for discrete systems under structural perturbations. 
Of our special interest are the nested structural perturbations (Sec- 
tion 7.4), because of their relevance to decompositions of complex systems 
into weakly coupled subsystems. A prime candidate for new research in this 
direction is the block diagonal dominance concept (Ohta and Siljak, 1985), 
which is an attractive alternative to vector Liapunov functions in stability 
analysis of linear systems (Section 7.5). 
Applications of connective stability appear in as diverse fields as model 
ecosystems and arms race, competitive economic analysis, and electric power 
systems (see Siljak, 1978). The most extensive reference to the concept has 
been in biological modeling, as cited in the books by May (1974), Casti 
(1979), Goh (1980), Svkezhev and Logofet (1983), and Boucher (1985), as 
well as the papers by Ladde (1976b, c, d), Andretti (1978), Mazanov (1978), 
Ikeda and Siljak (1980d, 1982), Olesky and van den Driessche (1982), Soli- 
mano and Beretta (1983), Shigesada et al. (1984), Spouge (1986), and Casti 
(1987). Specially interesting are the results in the context of complexity us. 
stability problem (see Siljak, 1987a, and references therein). 
New avenues for future research on stability under structural perturba- 
tions have been opened in a number of areas by new results in Liapunov’s 
stability theory and complex systems. Some of these results are reviewed 
here. Others can be found in the books and survey papers mentioned above, 
as well as in the rest of this book (see, in particular, Chapters 7 and 9). 
An interesting way to reduce the conservativeness of vector Lia.punov 
functions is to use cone-valued functions (Lakshmikantham and Leela, 1977) 
relative to a cone other than RY. The central object in this context is 

116 
2. Stabilization 
the comparison system, which is considered in the framework of large-scale 
systems by Bitsoris (1983), Matrosov (1984), and Martynyuk and Krapivnii 
(1987). An interesting new concept of majorant Liapunov equations has 
been introduced recently by Hyland and Bernstein (1987), which offers a 
new way to improve flexibility of Liapunov’s theory for complex systems. 
Matrix Liapunov functions have been introduced by Martynyuk (1975), 
which offer still another generalization of Liapunov’s theory. The concept 
has been developed in a number of papers to include unstable subsystems 
(Djordjevid, 1983a, b), the Principle of Invariance (Martynyuk, 1984), hy- 
brid systems (Martynyuk, 1985), stochastic systems (Martynyuk, 1987a), 
and absolute stability (Martynyuk, 1987b). We note that matrix Liapunov 
functions have not reached the maturity of its vector counterpart, especially 
in the control applications. 
Other relevant contributions to stability theory of complex systems have 
been made in the areas of partial stability (Bondi et al. 1979), absolute 
stability (Kaszkurewicz and Resende, 1983), limiting equations (Bondi et 
al. 1982), stability regions of multimachine power systems (Saeki et al. 
1980; Araki et al. 1982; Grujid et al. 1987; Tsai, 1987), as well as stochastic 
systems (Socha, 1986; Socha and Popp, 1986; Popp et al. 1988; Jumarie, 
1988), reactiondiffusion systems (Lakshmikantham and Leela, 1988), and 
neural networks (Michel and Farell, 1990). 
DECENTRALIZED STABILIZATION 
Since the size and complexity have been traditionally standard features 
of mathematical models of economic systems, the fact that a decentraliza- 
tion of control and estimation brings about a considerable reduction of in- 
formation processing requirements has been long recognized by economists 
(e.g., Marschak and Radner, 1971; Arrow and Hurwicz, 1977). A similar 
situation has been present, in control of interconnected power areas (e.g., 
Calovid, 1986), where each area is controlled locally by variables available 
in each individual area. Other applications of decentralized control have 
been in areas of process control, large space structures and traffic control 
to mention a few, where the modern distributed computer architectures 
have proven to be effective. 
Motivated by the development of decentralized control technology, a 
considerable number of theoretical results on control with nonclassical (de- 
centralized) information structure constraints were reported in an early 
survey (Sandell et al. 1978). Of special interest has been the problem of 
decentralized control for interconnected systems, which can tolerate a wide 
range of uncertainties in the system structure and subsystems dynamics. 

2.6. Notes and References 
117 
Robust control strategies have been invented (Siljak, 1978, 1989) for sys- 
tem under structural perturbations, and they are the principal subject of 
this book. 
Stabilization of systems under structural perturbations (ie., connective 
stabilization) via decentralized feedback has been reported in a number of 
books (Siljak, 1978; Singh and Titli, 1979; Singh, 1981; Bernussou and Titli, 
1982; VukobratoviC and StokiC, 1982; Jamshidi, 1983; Mahmoud et al. 1985; 
Voronov, 1985; Leondes, 1985, 1986), as well as survey papers (Schmidt, 
1982; Siljak, 1983, 1987b; Singh et al. 1984). Game-theoretic methods were 
used by Mageriou and Ho (1977). Stabilization of large systems by variable 
structure controllers was considered by Khurana et al. (1986). Connective 
stabilizability of systems with time delays was addressed by Ikeda and 
Siljak (1980~) and Bourlks (1987). 
New decentralized schemes have been developed recently in control of 
large space structures (Kida et al. 1984, 1985; Hyland and Collins, 1988), 
flight control systems (VukobratoviC and StojiC, 1986, 1988), and robotics 
(VukobratoviC and StokiC, 1982; Stokid and VukobratoviC, 1984; Vukobra- 
tovii: and KirCanski, 1985; Mills and Goldenberg, 1987; Gavel, 1988). 
UNCERTAIN SYSTEMS 
Since robustness is of a primary concern to us, we should pay special 
attention to the area of uncertain systems. The underlying idea is to design 
feedback in such a way that stability of the closed-loop system can tolerate 
uncertain bounded perturbations. A vast literature exists on this subject 
(for a comprehensive recent survey, see the paper by Corless and Leitmann, 
1988). 
We recall that Liapunov, in his doctoral dissertation, studied robustness 
of stability to additive perturbations. Once we realize that interconnections 
are additive (uncertain) perturbations of the subsystems dynamics, the con- 
cept of connective stability appears as a natural outgrowth of Liapunov’s 
original analysis, which is suitable for robust stability studies of complex 
systems. Then, a decentralized feedback can be conceived as means to build 
connectively stable systems, that is, systems stable under structural per- 
turbations. 
There is an obvious structural similarity between uncertain and inter- 
connected systems (see Siljak, 1989), which can be exploited to get new 
results in both fields. By specializing interconnected systems to a single 
subsystem and treating a self-interconnection as a perturbation, we can 
reproduce a number of basic results obtained in uncertain systems using 
the material of this chapter, sometimes with greater generality-specially 

118 
2. Stabilization 
when “nonmatching conditions” of Sections 2.4 and 2.5 take place. This is 
not to say that the results on uncertain systems cannot be used to produce 
improved results in decentralized stabilization; in particular, when we try 
to reduce the conservativeness of decentralized control strategies (see, for 
example, Chen, 1987, 1989; Yong, 1988). 
Bibliography 
Aftabizadeh, A. R. (1980). Variation of constants, vector Lyapunov functions, and com- 
parison theorem. Applied Mathematics and Computations, 7, 341-352. 
Amemiya, T. (1986). Stability analysis of nonlinearily interconnected systems-applica- 
tion of M-functions. Journal of Mathematical Analysis and Applications, 114, 252- 
277. 
Anderson, B. D. 0. (1979). Time delays in large-scale systems. Proceedings of the 24th 
Conference on Decision and Control, Fort Lauderdale, Florida, 655460. 
Andretti, F. (1978). Interactions among biological systems: An analysis of asymptotic 
stability. Bulletin of Mathematical Biology, 40, 839-851. 
Araki, M. (1975). Application of M-matrices to the stability problems of composite 
dynamical systems. Journal of Mathematical Analysis and Applications, 52, 30% 
321. 
Araki, M. (1978). Stability of largescale nonlinear systems: Quadratic-order theory of 
compositesystem method. ZEEE Transactions, AC-23, 129-142. 
Araki, M., M. M. Metwally, and D. D. Siljak (1982). Generalized decompositions for 
transient stability analysis of multimachine power systems. Large Scale Systems, 3, 
11 1-122. 
Arrow, K. J., and L. Hurwica (1977). Studies in Resource Allocation Processes. Cam- 
bridge University Press, London, UK. 
Bailey, F. N. (1966). The application of Lyapunov’s second method to interconnected 
systems. SZAM Journal of Control, 3, 443-462. 
Bellman, R. (1962). Vector Lyapunov functions. SZAM Journal of Control, 1, 32-34. 
Bernussou, J., and A. Titli (1982). Interconnected Dynamical Systems: Stability, De- 
composition and Decentralization. North-Holland, Amsterdam, The Netherlands. 
Bitsoris, G. (1983). Stability analysis of non-linear dynamical systems. International 
Journal of Control, 38, 699-711. 
Bondi, P., P. Fergola, L. Gambardella, and C. Tenneriello (1979). Partial stability of 
large-scale systems. ZEEE Transactions, AC-24, 94-97. 
Bondi, P., P. Fergola, L. Gambardella, and C. Tenneriello (1982). Stability of large scale 
systems via limiting equations. Large Scale Systems, 3, 27-33. 
Boucher, D. H. (ed.) (1985). The Biology of Mutualism. Oxford University Press, New 
York. 
Bourlb, H. (1987). a-Stability and robustness of largescale interconnected systems. 
International Journal of Control, 45, 2221-2232. 
Burgat, C., and J. Bernussou (1978). On the stability of interconnected systems with p e  
riodic structural perturbations. International Journal of Systems Science, 9, 1133- 
1143. 

Bibliography 
119 
6aloviC M. S. (1986). Recent developments in decentralized control of generation and 
power flows. Proceedings of the 25th Conference on Decision and Control, Athens, 
Greece, 1192-1197. 
Casti, J. (1979). Connectivity, Complexity, and Catastrophe in Large-Scale Systems. 
Wiley, New York. 
Casti, J. (1987). Connective stability. Systems and Control Encyclopedia, M. G. Singh 
(ed.), Pergamon Press, Oxford, UK, 776-777. 
Chen, Y. H. (1987). Deterministic control of large-scale uncertain dynamical systems. 
Journal of the fianklin Institute, 323, 135-144. 
Chen, Y. 
H. (1989). Large-scale uncertain systems under insufficient decentralized con- 
trollers. Journal of Dynamic Systems, Measurement, and Control, 111, 359-363. 
Cheres, E., Z. J. Palmor, and S. Gutman (1989). Quantitative measurea of robustness 
for systems including delayed perturbations. IEEE "hnsactions, AC-34, 1203-1204. 
Corless, M., and G. Leitmann (1988). Controller design for uncertain systems via Lya- 
punov functions. Proceedings of the American Control Conference, Atlanta, Georgia, 
2019-2025. 
Datta, B. N. (1977). Matrices satisfying Siljak's conjecture. ZEEE "hnsactions, AC-22, 
Davison, E. J. (1974). The decentralized stabilization and control of a class of unknown 
nonlinear timevarying systems. Autornatica, 10, 309-316. 
Deo, N. (1974). Graph Theory with Applications to Engineering and Computer Science. 
Prentice-Hall, Englewood Cliffs, New Jersey. 
Djordjevik, M. (1983a). Stability analysis of interconnected systems with poasibly un- 
stable subsystems. Systems and Control Letters, 3, 165169. 
DjordjeviC, M. (1983b). Stability analysis of large scale systems whose subsystems may 
be unstable. Large Scale Systems, 5, 255-262. 
Fiedler, M., and V. Ptaik (1962). On matrices with nonpositive off-diagonal elements 
and principal minors. Czechoslovakian Mathematical Journal, 12, 382400. 
Gavel, D. T., Jr. (1988). Decentralized Adaptive Contml of Large Scale Systems, with 
Application to Robotics. Report No. UCRL-53866, Lawrence Livermore National 
Laboratory, Livermore, California. 
Goh, B. S. (1980). Management and Analysis of Biological Populations. Elsevier, Ams- 
terdam, The Netherlands. 
GrujiC, Lj. T., A. A. Martynyuk, and M. Ebbens-Pavella (1987). Large Scale Systems 
Stability under Structural and Singular Perturbations. Springer, New York. 
Hahn, W. (1967). Stability of Motion. Springer, New York. 
Hyland, D. C., and D. S. Bernstein (1987). The majorant Lyapunov equation: A non- 
negative matrix equation for robust stability and performance of large scale systems. 
IEEE Transactions, AC-32, 1005-1013. 
Hyland, D. C., and E. G. Collins, Jr. (1988). A robust control experiment using an opti- 
cal structure prototype. Proceedings of the Automatic Control Conference, Atlanta, 
Georgia, 2046-2049. 
Ikeda, M., and D. D. Siljak (1980a). On decentrally stabilizable large-scale systems. 
Automatica, 16, 331-334. 
Ikeda, M., and D. D. Siljak (1980b). Decentralized stabilization of linear timevarying 
systems. ZEEE Transactions, AC-25, 1W107. 
Ikeda, M., and D. D. Siljak (1980~). Decentralized stabilization of large scale systems 
with time delay. Large Scale Systems, 1, 273-279. 
132-133. 

120 
2. Stabilization 
Ikeda, M., and D. D. Siljak (198od). Loth-Volterra equations: Decompositions, stability, 
and structure, Part I: Equilibrium analysis. Journal of Mathematical Biology, 9, 65- 
83. 
Ikeda, M., and D. D. Siljak (1982). Loth-Volterra equations: Decomposition, stabil- 
ity, and structure. Part 11. Nonequilibrium analysis. Nonlinear Analysis, Theory, 
Methods and Applications, 6, 487-501. 
Ikeda, M., 0. Umefuji, and S. Kodama (1976). Stabilization of large-scale linear sys- 
tems. Transactions of IECE Japan, 59-D, 355-362 (also in Systems, Computers, 
and Control, 7, 34-41). 
Jamshidi, M. (1983). Large-Scale Systems: Modeling and Control. North-Holland, New 
York. 
Jumarie, G. (1988). Simple general method to analyse the moment stability and sen- 
sitivity of nonlinear stochastic systems with or without delay. Journal of Systems 
Science, 19, 111-124. 
Kailath, T. (1980). Linear Systems. Prentice-Hall, Englewood Cliffs, New Jersey. 
Kalman, R. E., and J. E. Bertram (1960). Control system analysis and design via the 
“second method” of Lyapunov. Part I: Continuous-time systems. Transactions of 
ASME, Series D, 82, 371-393. 
Kaszkurewicz, E., and P. Resende (1983). On the absolute stability of linearly inter- 
connected nonlinear systems. Proceedings of the IFAC Symposium on Large Scale 
Systems, Pergamon Press, Oxford, UK, 309-314. 
Khurana, H., S. I. Ahson, and S. S. Lamba (1986). Stabilization of large-scale control 
systems using variable structure systems theory. IEEE Transactions, AC-31, 17G 
178. 
Kida, T., I. Yamaguchi, and Y. Ohkami (1984). Local output-feedback control for large 
flexible space structures. Proceedings of the 14th International Symposium on Space 
Technology and Science, Tokyo, Japan, 969-974. 
Kida, T., I. Yamaguchi, and Y. Ohkami (1985). An approach to local decentralized 
control for large flexible space structures. AIAA Guidance, Navigation and Control 
Conference, Paper No. 85-1924-C, Snowmass, Colorado. 
Ladde, G. S. (1976a). System of functional differential inequalities and functional differ- 
ential systems. Pacific Journal of Mathematics, 66, 161-171. 
Ladde, G. S. (1976b). Cellular systems-I. Stability of chemical systems. Mathematical 
Biosciences, 29, 309-330. 
Ladde, G. S. (1976~). Cellular systems-11. Stability of compartmental systems. Mathe- 
matical Biosciences, 30, 1-21. 
Ladde, G. S. (1976d). Stability of model ecosystems with time-delay. Journal of Theo- 
retical Biology, 61, 1-13. 
Ladde, G. S. (1977). Competitive processes-I. Stability of hereditary systems. Nonlinear 
Analysis, Theory, Methods and Applications, 6, 607431. 
Ladde, G. S., and D. D. Siljak (1976a). Stability of multispecies communities in randomly 
varying environment. Journal of Mathematical Biology, 2, 165-178. 
Ladde, G. S., and D. D. Siljak (1976b). Connective stability of large-scale stochastic 
systems. International Journal of Systems Science, 6, 713-721. 
Lakshmikantham, V. (1981). Review of “Large-Scale Dynamic Systems: Stability and 
Structure” by D. D. Siljak. IEEE Transactions, AC-26, 976-977. 
Lakshmikantham, V., and S. Leela (1969). Diflerential and Integral Inequalities. Vols. I 
and 11. Academic Press, New York. 
Lakshmikantham, V., and S. Leela (1977). Cone-valued Lyapunov functions. Nonlinear 
Analysis, Theory, Methods and Applications, 1, 215-222. 

Bibliography 
121 
Lakshmikantham, V., and S. Leela (1988). Reactiondiffusion systems and vector Lya- 
punov functions. Differential and Integral Equations, 1, 41-47. 
LaSalle, J. P. (1976). The Stability of Dynamical Systems. SIAM, Philadelphia, Penn- 
sylvania. 
Leela, S. (1988). Method of vector Lyapunov functions for reaction-diffusion systems. 
Proceedings of the International Conference on Theory and Application of Differ- 
ential Equations, Ohio University Press, Columbus, Ohio, 120-124. 
Leondes, C. T. (ed.) (1985). Decentralized-Distributed Control and Dynamic Systems. 
Part I. Academic Press, New York. 
Leondes, C. T. fed.) (1986). Decentralized-Distributed Control and Dynamic Systems. 
Part 11. Academic Press, New York. 
Lewis, R. M., and B. D. 0. Anderson (1980). Necessary and sufficient conditions for 
delay-independent stability of linear autonomous systems. IEEE lhnsactions, AC- 
Loparo, K. A., and C. S. Hsu (1982). Analysis of interconnected systems using bilinear 
models. Large Scale Systems, 3, 237-244. 
Luenberger, D. G. (1967). Canonical forms for linear multivariable systems. ZEEE Truns- 
actions, AC-12, 29Cb293. 
Lunze, J. (1983). A majorization approach to the quantitative analysis of incompletely 
known large scale systems. Zeitschrifl fir elektrische Infomations und Energietech- 
nik, 13, 99-117. 
Lunze, J. (1984). Stability analysis of large scale interconnected systems by means of 
simplified models. System Analysis, Modeling, and Simulation, 1, 381-398. 
Lume, J. (1986). Dynamics of strongly coupled symmetric composite systems. Interna- 
tional Journal of Control, 44, 1617-1640. 
Mageriou, E. F., and Y. C. Ho (1977). Decentralized stabilization via game theoretic 
methods. Autornatica, 13, 393-399. 
Mahmoud, M. S., M. F. Hassan, and M. G. Darwish (1985). Large-Scale Control Systems: 
Theories and Techniques. Marcel Dekker, New York. 
Marschak, J., and R. Radner (1971). The Economic Theory of Teams. Yale University 
Press, New Haven, Connecticut. 
Martynyuk, A. A. (1975). Stability of Motion of Complez Systems (in Russian). Naukova 
Dumka, Kiev, USSR. 
Martynyuk, A. A. (1984). The Lyapunov matrix functions. Nonlinear Analysis, Theory, 
Methods and Applications, 8, 1223-1226. 
Martynyuk, A. A. (1985). Matrix Liapunov functions and stability of hybrid systems. 
Prikladnaia Mekhanika, 21, 89-96. 
Martynyuk, A. A. (1987a). Stochastic matrix-valued Lyapunov function and its appli- 
cation. Stochastic Analysis and Application. 5, 395-404. 
Martynyuk, A. A. (1987b). Absolute stability of singularily-perturbed Lur’e systems and 
matrix Liapunov functions. Prikladnaia Mekhanika, 23, 103-110. 
Martynyuk, A. A., and Yu. N. Krapivnii (1987). Nonlinear comparison systems and 
stability of large-scale systems. Prikladnaia Mekhanika, 23, 75-80. 
Matrosov, V. M. (1962). On the theory of stability of motion. Prikladnaia Maternataka 
i Mekhanika, 26, 992-1000. 
Matrosov, V. M. (ed.) (1981). Algorithms for Theorem Generation in the Method of 
Vector Liapunov Functions (in Russian). Nauka, Novosibirsk, USSR. 
25, 735-739. 

122 
2. Stabilization 
Matrosov, V. M. (1984). Vector Lyapunov functions method in the analysis of dynami- 
cal properties of nonlinear differential equations. Rends in Theory and Pmctice of 
Nonlinear Differential Equations, V. Lakshmikantham (ed.), Marcel Dekker, New 
York, 357-374. 
Matrosov, V. M., and L. Yu. Anapolskii (eds.) (1980). Vector-Functions of Liapunov 
and their Construction (in Russian). Nauka, Novsibirsk, USSR. 
Matrosov, V. M., and L. Yu. Anapolskii (eds.) (1981). Direct Method in Stability Theory 
and Its Applications (in Russian). Nauka, Novosibirsk, USSR. 
Matrosov, V. M., and Yu. E. Boiarintsev (eds.) (1986). Differential Equations and Nu- 
merical Methods (in Russian). Nauka, Novosibirsk, USSR. 
Matrosov, V. M., and A. I. Malikov (eds.) (1986). Liapunou Functions and Their Ap- 
plications (in Russian). Nauka, Novosibirsk, USSR. 
Matrosov, V. M., and S. N. Vasilev (eds.) (1984). Method of Liapunou Functions and 
Its Applications (in Russian). Nauka, Novosibirsk, USSR. 
Matrosov, V. M., L. Yu. Anapolskii, and S. N. Vasilev (1980). Comparison Method in 
MathematicaE Systems Theory (in Russian). Nauka, Novosibirsk, USSR. 
May, R. M. (1974). Stability and Complezity in Model Ecosystems. 2nd ed., Princeton 
University Press, Princeton, New Jersey. 
Mazanov, A. (1978). Acceptor control in model ecesystems. Journal of Theoretical 
Michel, A. N. (1983). On the status of stability of interconnected systems. IEEE Trans- 
actions, CAS-30, 326-340. 
Michel, A. N., and J. A. Farell (1990). Associative memories via artificial neural net- 
works. IEEE Control Systems Magazine, 10, 6-17. 
Michel, A. N., and R. K. Miller (1977). Qualitative Analysis of Large Scale Dynamical 
Systems. Academic Press, New York. 
Mills, J. K., and A. A. Goldenberg (1987). Global connective stability of a class of robotic 
manipulators. Automatica, 24, 83-39, 
Montemayor, J. J., and B. F. Womack (1975). On a conjecture by Siljak. IEEE %ns- 
actions, AC-20, 572-573. 
Montemayor, J. J., and B. F. Womack (1976). More on a conjecture by Siljak. IEEE 
Transactions, AC-21, 805-806. 
Mori, T., and M. Kuwahara (1981). Comments on Siljak’s conjecture. IEEE Transac- 
tions, AC-26, 604-611. 
Moylan, P. (1980). A connective stability result for interconnected passive systems. IEEE 
Transactions, AC-25, 812-813. 
Ohta, Y., and D. D. Siljak (1985). Overlapping block diagonal dominance and existence 
of Liapunov functions. Journal of Mathematical Analysis and Applications, 112, 
396-410. 
Olesky, D. D., and P. van den Driessche (1982). Monotone positive stable matrices. 
Linear Algebra and Its Applications, 48, 381-401. 
Ostrowski, A. (1937). Uber die Derminanten mit iiberwiegender Hauptdiagonale. Com- 
mentarii Mathematici Heluetici, 10, 6S76. 
Patel, R. V., and M. Toda (1980). Quantitative measures of robustness for multivariable 
systems. Proceedings of the JACC, Paper No. TPSA, San Francisco, California. 
Popp, K., L. Socha, and H. Windrich (1988). Moment stability of linear stochastic non- 
triangular large-scale systems. International Journal of Systems Science, 19, 7 3 3  
746. 
Biology, 71, 21-38. 

Bibliography 
123 
Richter, S., and R. DeCarlo (1984). A homotopy method for eigenvalue assignment using 
decentralized state feedback. IEEE Transactions, AC-29, 14s-158. 
Rouche, N., P. Habets, and M. Laloy (1977). Stability Theory by Liapunow’s Direct 
Method. Springer, New York. 
Seeki, M., M. Araki, and B. Kondo (1980). Local stability of composite systems: 
Frequency-domain condition and estimate of the domain of attraction. IEEE Trans- 
actions, AC-25, 936-940. 
Sandell, N. R., Jr., P. Varaiya, M. Athans, and M. G. Safonov (1978). Survey of de- 
centralized control methods for large scale systems. IEEE Transactions, AC-23, 
Schmidt, G. (1982). What are and what is the origin of complex systems, and which spe- 
cific problems do they pose to control engineering? (in German). Regelungstechnik, 
Sezer, M. E., and 0. Hiiseyin (1978). Stabilization of linear interconnected systems using 
local state feedback. IEEE Transactions, SMG8, 751-756. 
Sezer, M. E., and 0. Hiiseyin (1981). Comments on decentralized feedback stabilization. 
IEEE Transactions, AC-26, 547-549. 
Sezer, M. E., and D. D. Siljak (1979). Decentralized stabilization and structure of linear 
large-scale systems. Proceedings of the 13th Asilonear Conference, Pacific Grove, 
California, 176-181. 
Sezer, M. E., and D. D. Siljak (1981). On decentralized stabilization and structure of 
linear large scale systems. Automatica, 17, 641-644. 
Sezer, M. E., and D. D. Siljak (1988). Robust stability of discrete systems. International 
Journal of Control, 48, 2055-2063. 
Sezer, M. E., and D. D. Siljak (1989). A note on robust stability bounds. IEEE Trans- 
actions, AC-34, 1212-1215. 
Shi, Z. C., and W. B. Gao (1986). Stabilization by decentralized control for large scale 
interconnected systems. Large Scale Systems, 10, 147-155. 
Shi, Z. C., and W. B. Gao (1987). On decentralized stabilization of large-scale intercon- 
nected systems. Large Scale Systems, 13, 187-190. 
Shigesada, N., K. Kawasaki, and E. Teramoto (1984). The effects of interference com- 
petition on stability, structure and invasion of a multi-species systems. Journal of 
Mathematical Biology, 21, 97-113. 
Shigui, R. (1988). Connective stability for large scale systems described by functional 
differential equations. IEEE Thnsactions, AC-33, 198-200. 
Siljak, D. D. (1972). Stability of large-scale systems under structural perturbations. 
IEEE Transactions, SMC-2, 657463. 
Siljak, D. D. (1978). Large-Scale Dyqamic Systems: Stability and Structure. North- 
Holland, New York. 
Siljak, D. D. (1980). Reliable control using multiple control systems. International Jour- 
nal of Control, 31, 303-329. 
hjak, D. D. (1983). Complex dynamic systems: Dimensionality, structure, and uncer- 
tainty. Large Scale Systems, 4, 279-294. 
Siljak, D. D. (1987a). Complex ecosystem stability. Systems and Control Encyclopedia, 
M. G. Singh (ed.), Pergamon Press, Oxford, UK, 672475. 
Siljak, D. D. (1987b). Interconnected systems: Decentralized control. Systems and Con- 
trol Encyclopedia, M. G. Singh (ed.), Pergamon Press, Oxford, UK, 2557-2560. 
Siljak, D. D. (1989). Parameter space methods for robust control design: A guided tour. 
IEEE Transactions, AC-34, 674-688. 
108-128. 
30, 331-339. 

124 
2. Stabilization 
Siljak, D. D., and M. VukEeviC (19764. Large-scale systems: Stability, complexity, reli- 
ability. Journal of the Franklin Institute, 301, 4 M 9 .  
Siljak, D. D., and M. VukEeviC (1976b). Decentralization, stabilization, and estimation 
of large-scale systems. IEEE Transactions, AC-21, 363-366. 
Siljak, D. D., and M. VukEeviC (1977). Decentrally stabilizable linear and bilinear large- 
scale systems. International Journal of Control, 26, 28%-305. 
Singh, M. G. (1981). Decentmlised Control. North-Holland, Amsterdam, The Nether- 
lands. 
Singh, M. G., and A. Titli (eds.) (1979). Handbook of Large Scale Systems Engineering 
Applications. North-Holland, Amsterdam, The Netherlands. 
Singh, M. G., A. Titli, and K. Malinowski (1984). Decentralized control design: An 
overview. Proceedings of the IFA C/IFORS Symposium on Large Scale Systems. 
Pergamon Press, Oxford, UK, 1-15. 
Sinha, A. S. C. (1980). Lyapunov functions for a class of large-scale systems. IEEE 
Transactions, AC-25, 558-560. 
Sinha, A. S. C. (1981). Stability of large-scale hereditary systems with infinite retarda- 
tions. International Journal of Systems Science, 12, 111-117. 
Socha, L. (1986). The asymptotic stochastic stability in large of the composite stochastic 
systems. Automatica, 22, 605410. 
Socha, L., and K. Popp (1986). The pmoment global exponential stability of linear large 
scale systems. Large Scale Systems, 10, 75-93. 
Solimano, F., and E. Beretta (1983). Existence of a globally asymptotically stable equi- 
librium in Volterra models with continuous time delay. Journal of Mathematical 
Spiteri, P. (1986). A unified approach to stability conditions of large scale non-linear 
evolution systems. Large Scale Systems, 10, 57-74. 
Spouge, J. L. (1986). Increasing stability with complexity in a system composed of 
unstable subsystems. Journal of Mathematical Analysis and Applications, 118, 502- 
518. 
Steward, D. V. (1962). On an approach to techniques for the analysis of the structure 
of large systems of equations. SIAM Review, 4, 321-342. 
StokiC, D., and M. VukobratoviiC (1984). Practical stabilization of robotic systems by 
decentralized control. Automatica, 20, 353-358. 
Svirezhev, Yu. M., and D. 0. .Logofet (1983). Stability of Biological Communities. Mir, 
Moscow, USSR. 
Tartar, L. (1971). Une nouvelle characterisation des M matrices. Revue Francaise d’Auto- 
matique, Informatique et Recherche Opemtionelle, 5, 127-128. 
Tsai, W. K. (1987). Minimizing the effects of unknown-but-bounded disturbance in 
power plants. Proceedings of the 26th Conference on Decision and Control, Los 
Angeles, California, 6G71. 
Vidyasagar, M. (1981). Input-Output Analysis of Large-Scale Interconnected Systems. 
Springer, New York. 
Vidyasagar, M. (1986). New directions of research in nonlinear system theory. Proceed- 
ings of the IEEE, 74, 1060-1091. 
Voronov, A. A. (1982). Present state and problems of stability theory. Automatika i 
Telemekhanika, 42, 5-28. 
Voronov, A. A. (1985). Introduction to Dynamics of Complex Control Systems (in Rus- 
sian). Nauka, Moscow, USSR. 
Voronov, A. A., and V. M. Matrosov (eds.) (1987). The Method of Vector Liapunou 
Functions in Stability Theory (in Russian). Nauka, Moscow, USSR. 
Biology, 18, 93-102. 

Bibliography 
125 
VukobratoviC, M., and N. KirCanski (1985). An approach to adaptive control of robotic 
manipulators. Automatica, 21, 63-47. 
VukobratoviC, M., and D. StokiC (1982). Control of Manipulation Robots. Springer, 
Berlin, F. R. Germany. 
VukobratoviC, M. K., and R. D. StojiC (1986). A decentralized approach to integrated 
flight control synthesis. Autornatica, 22, 695-704. 
VukobratwiC, M. K., and R. D. StojiC (1988). Modern Aircraft Flight Control. Springer, 
New York. 
Yedavalli, R. K. (1989). Sufficient conditions for the stability of interconnected dynamic 
systems. Information and Decision Technologies, 15, 133-142. 
Yong, J. (1988). Stabilization of nonlinear largescale uncertain dynamical systems. Jour- 
nal of Mathematical Analysis and Applications, 136, 157-177. 
Zames, G. (1966). On input-output stability of timevarying nonlinear systems. Part I: 
Conditions derived using concepts of loop gain, conicity, and positivity. IEEE Trans- 
actions, AC-11, 228-238. 
Zhukhovitskii, S. I., and L. I. Avdeyeva (1966). Linear and Convez Programming. Saun- 
ders, Philadelphia, Pennsylvania. 

Chapter 3 I 
Optimization 
Attempts to formulate decentralized control strategies by extending stan- 
dard optimization concepts and methods have not been successful; the sim- 
ple reason is that nonclassical decentralized information structure does not 
lend itself to a manageable formulation of any kind of optimality principle. 
This fact is responsible for a relatively large gap between theory and prac- 
tice of optimal decentralized control. At present, there are a considerable 
number of ad hoc methods and techniques in this context which have few 
conceptual ingredients in common. 
In complex dynamic systems, the notion of optimality is further com- 
plicated by the presence of essential uncertainties in the interconnections 
among the subsystems, which cannot be described in either deterministic 
or stochastic terms. Unlike standard optimization schemes, where robust- 
ness is a part of the solution, robustness in complex systems is a part of 
the problem; it has to be considered from the outset of the design process. 
By imitating the decentralized structure of competitive market systems 
(e-g., Arrow and Hahn, 1971), but otherwise using entirely different tech- 
niques, methods have been proposed for optimization of complex intercon- 
nected systems (Siljak, 1978). A market is a place where economic agents 
meet to exchange commodities and the central question is:' Under what 
conditions in a fully decentralized exchange economy do the agents, who 
are guided only by their self-interest, reach the state of economy in which 
their independent decisions are mutually compatible? In dynamic models 
of market economy, compatibility is demonstrated by establishing the exis- 
tence of (competitive) equilibrium. Stability of the equilibrium guarantees 
that compatibility of the decentralized decisions made by different agents 
can be reached by following a set of rational rules and procedures. 
By mimicking the market concept, we shall consider a complex system 
126 

3.1. Suboptimality 
127 
as constituted of a number of interconnected subsystems with distinct in- 
puts. Each local input is chosen as a linear state feedback to optimize a 
quadratic performance index with respect to the corresponding subsystem, 
while ignoring the other subsystems. Then, suitability of the decentralized 
Linear-Quadratic (LQ) control law is established by showing stability of 
the overall closed-loop interconnected system. Under certain conditions, 
the proposed LQ control strategy is robust! with respect to modeling un- 
certainties and perturbations in the interconnection structure, that is, the 
overall system is connectively stable. 
A locally optimal decentralized LQ control is obviously not optimal 
(in general) for the interconnected system. When stable, however, it is 
suboptimal and an index of suboptimality is defined, which can be used to 
measure the cost of robustness to structural perturbations. Furthermore, 
we will show that suboptimal closed-loop systems tolerate distortions of the 
LQ control caused by insertion of nonlinearities, gain changes, and phase 
shifts, as do optimal closed-loop systems. 
Inspired by the original paper of Kalman (1964), we will ask: When is an 
LQ decentralized control optimal? To no one’s surprise, we will find that 
there are no simple answers to this question unless we alter the original 
set-up and allow modifications of performance indices and feedback control 
laws. Of course, benefits of solving this type of inverse optimal problem in 
decentralized control are many. First of all, we recover the gain and phase 
margins of optimal systems, which are usually superior to those of subop 
timal LQ controls. Second, we can obtain optimal control by manipulating 
only subsystems matrices. This can produce a welcome reduction of di- 
mensionality in complex systems, where centralized optimal problems are 
likely to turn out to be either impossible or uneconomical to solve even 
with modern computing machinery. 
3.1. Suboptimality 
We shall introduce in this section the concept of suboptimality relying 
on the standard optimization theory of Linear-Quadratic (LQ) regulators. 
This leads to a suitable interpretation of suboptimality in the context of 
optimal control problems with nonclassical decentralized information struc- 
ture constraints. Several results in this section are given without proofs, 
because they appear as straightforward implications of the similar results 
obtained for complex systems in the subsequent sections of this chapter. 
Let us consider a linear system 
S: X=Ax+Bu, 
(3.1) 

128 
3. Optimization 
where z(t) E R” is the state and u(t) E Rm is the input of S at time t E T. 
The matrices A and B are constant and of appropriate dimensions. We 
assume that S is the nominal system with which we associate a quadratic 
performance index 
where zo = z(0) is the initial state, and Q and R are constant symmetric 
matrices with Q being nonnegative and R positive definite. As is common, 
we assume that the pair (A, B) is controllable and the pair (A, Q’/’) is o b  
servable. A system S and a cost J form the standard optimization problem 
( S ,  J ) ,  the solution of which is given by the optimal control law 
where the gain matrix K is 
K = R-‘BTP, 
(3.4) 
and P is the unique symmetric positive definite solution of the Riccati 
equation 
ATP + PA - PBR-’BTP + Q = 0. 
(3.5) 
The optimal closed-loop system is 
So : i = ( A  - BK)z, 
(3.6) 
and the optimal cost J@(zo) = J (zo, u@) is computed as 
(3.7) 
Now, let us consider a perturbation of the nominal system S ,  which may, 
for example, be due to errors committed during the modeling process. We 
assume that we have the system 
Sf : i = ( A  + A+)Z + Bu, 
(3.8) 
where A+ is a constant matrix representing the uncertainty about S .  If we 
apply the same control (3.3) to S+, the closed-loop perturbed system 
S* : h = ( A + A +  -BK)z 
(3.9) 
would produce a cost J@(zo) which is, in general, larger than the optimal 
cost J@(zo). The difference between the costs J@ and J@ measures the 

3.1. Suboptimality 
129 
effect of modeling uncertainty on the performance of the optimal system 
S@. The needed concept is suboptimality, which is formalized as follows: 
3.1. DEFINITION. 
pair (S+, J) if there exists a positive number p such that 
A control law u@ is said to be suboptimal for the 
(3.10) 
-1 0 
J@(zo) 5 p J (zo), VZO E Rn. 
The number p is called the degree of suboptimality of u@. 
3.2. REMARK. 
stabilize the system S+, that is, if the closed-loop matrix 
The cost J@ may be infinite if the control u@ does not 
A+ = A + A+ - BK 
(3.11) 
is not stable. It is obvious, however, that the value of the performance index 
J@ is 
J@(zo) = ZFHZO, 
(3.12) 
where 
+cc 
H = 
exp(AT)Gexp(A+) dt, 
(3.13) 
G = Q + PBR-’BTP, 
and the control u@ is suboptimal for S+ if and only if the symmetric matrix 
H exists. It is a well-known fact (e.g., Kalman and Bertram, 1960) that 
the matrix H is finite whenever the matrix A+ is stable; that is, it has 
all eigenvalues with negative real parts. Then, we can compute H as the 
unique solution of the Liapunov matrix equation 
AyH + HA+ = -G. 
(3.14) 
Therefore, stability implies suboptimality. In fact, from Remark 3.2 we can 
compute the largest (best) value p* of p for which (3.10) holds: 
3.3. 
of suboptimality 
THEOREM. A control law u@ is suboptimal with the (largest) degree 
p* = Ad(kP-1) 
(3.15) 
for the pair ( S + ,  J) if and only if the matrix H is finite. 

130 
3. Optimization 
Proof. The expression (3.15) follows directly from inequality (3.10) and 
the well-known relation 
(3.16) 
which is true if and only if H is finite. Since (3.16) holds for all XO, and 
equality in (3.16) takes place for some 50, the value p* is the largest p for 
which (3.10) is true. 
Q.E.D. 
While by Remark 3.2 stability implies suboptimality, the converse is 
not true in general; without additional conditions, suboptimality does not 
imply stabilizability of the control law uo. 
It is not difficult to guess that 
some kind of observability is needed to establish the converse: 
3.4. THEOREM. A control law u" is stabilizing for the system S+ (that 
is, the matrix A+ is stable) if it is suboptimal and the pair of matrices 
(A+, G112) is observable. 
Proof. Let us assume that the matrix A+ has an unstable eigenvalue A, 
that is, Re X > 0, with the corresponding eigenvector v E C". From (3.13), 
we have 
+m 
vHHv = 1 exp(Xt)vHGv exp(Xt)dt, 
(3.17) 
where the superscript H denotes the conjugate transpose of v. Since u" of 
(3.3) is suboptimal, H and, thus, vHHv are finite. But, 
exp(X*t)exp(Xt) 2 1, 
V t  2 0, 
(3.18) 
and because vHGv is nonzero when (A+, G112) is observable, the right side 
of (3.17) is not finite. This contradiction establishes the theorem. Q.E.D. 
3.5. REMARK. It has been shown (Wonham, 1968) that observability 
of the pair (A+, G'12) is implied by observability of the pair (A+A+, &'I2). 
Therefore, when the system S+ and the performance index J satisfy the 
observability condition, the control law uo is suboptimal if and only if it is 
stabilizing. 
The formula (3.15) provides the largest value of the degree p of subop 
timality, but it does not offer an explicit characterization of the effect of 

3.1. Suboptimality 
131 
perturbations on optimality of the control law uo. 
Such a characterization 
is the following: 
3.6. THEOREM. 
for some positive number p, the matrix 
A control law u" is suboptimal for the pair (S+, J )  if 
F ( p )  = ATP + PA+ - (1 - p)(Q + PBR-'BTP) 
(3.19) 
is nonpositive definite. 
3.7. REMARK. Again, stability of S is not guaranteed by F ( p )  5 0, 
and we must have also detectability of the pair {A,, [-F(0)]'/2}, which 
can be replaced by detectability of the pair ( A  + A+, Q112). 
So far, we established stability of suboptimal regulators in pretty much 
the same way it was done for optimal regulators (Kalman, 1960). Can we 
also show that suboptimal control has the classical robustness properties 
of gain and phase margins, as the optimal control does (e.g., Anderson and 
Moore, 1971)? 
In order to introduce the gain and phase margin and the gain reduction 
tolerance as measures of robustness of suboptimal systems, we focus our 
attention on single-input systems and replace the matrices B, K, and R by 
vectors b, kT, and a scalar C. Denoting the open-loop transfer function of 
S@ by 
g(s) = k T ( d  - A - A+)-'b, 
(3.20) 
we state the following theorem of Sezer and Siljak (1981a), the proof of 
which is similar to the proof of a corresponding result for optimal systems 
(Kalman, 1964): 
3.8. THEOREM. Suppose F ( p )  is nonpositive definite for some positive 
p. Then, 
Inequality (3.21) implies that the polar plot of g ( j w )  lies outside (inside) 
the circle with the center at (p - 2)-l and radius Ip - 21-' when p < 2 
(p > 2). These two cases are illustrated in Figure 3.1. For p = 2, the 
polar plot lies in the right half of the g(s) plane. When compared with the 
similar condition for optimality, the inequality (3.21) has an additional term 
(1 - p)g(jw)g(-jw) on the right side. The effect of this term is to expand 

132 
3. Optimization 
Fig. 3.1. Frequency domain plots. 
or shrink the circle, depending on whether p E (0, 11 or p E (1, +m), 
the latter case being interesting in that the performance of the suboptimal 
regulator is superior to the optimal one! 
The role of p in terms of the gain and phase margin and the gain 
reduction tolerance of the suboptimal system S@ can be formulated as 

3.1. Suboptimality 
133 
a corollary to Theorem 3.8. We assume that S@ is stable, and state the 
following: 
3.9. COROLLARY. 
has: 
Under the condition of Theorem 3.8, the system S@ 
(i) infinite gain margin; 
(ii) at least f cos-l(l - p) phase margin; 
(iii) at least 50p% gain reduction tolerance. 
3.10. REMARK. When p = 1, not only is the suboptimal cost at least 
as good as the optimal, but also the suboptimal system S@ has robustness 
properties (2)-(iii) no worse than the corresponding optimal system S@. 
We also note that, when p E [l, +oo), which occurs when the perturbation 
matrix A+ is “beneficid,” the system S@ has better robustness properties 
than S@. Furthermore, if p 2 2, then the gain reduction tolerance exceeds 
loo%, which corresponds to a “gain reversal.” 
We are not finished yet! To complete the robustness properties Of sub- 
optimal systems, which are germane to LQ regulators, we show that S@ can 
tolerate a large class of nonlinearities in almost the same way as optimal 
systems (e.g., Anderson and Moore, 1971). To show this, we consider the 
system 
(3.22) 
where 4 : R -, R is a continuous function of the scalar input u(t), and, 
choosing ~ ( z )  
= zTHz as a Liapunov function for S:, establish the follow- 
ing: 
S$ : k = ( A  + A+)z + b$(u), 
u = -k T z, 
3.11. THEOREM. Suppose that F ( p )  is nonpositive definite for some 
positive p and that the pair ( A  + A+, Q’l2) is observable. Then, the equi- 
librium 2 = 0 of the system S$ is asymptotically stable in the large for all 
$(u) that belong to the class 
= {$ : I 
u$(u) I 
Eu2, 
v u }  , 
(3.23) 
where 
(3.24) 
1 
t
~
=
 
1 - -(p-Ap), 
2 
ii < +OO, 
- 
and Ap is an arbitrarily small positive number. 
When we recognize the fact that interconnections in complex systems 
represent perturbations of subsystems dynamics, then it is logical to 

134 
3. Optimization 
extend the results of this section to decentralized control of interconnected 
systems. The strong motivating factor for this approach is the robustness 
properties of the resulting control strategies which reinforce the autonomy 
of individual subsystems. Before we pursue this line of research, we should 
introduce still another option available in this context. 
We recall the role of global control, which was to enhance autonomy 
of decentrally stabilized subsystems by minimizing the effect of intercon- 
nections. This motivates a similar modification of the optimal control law, 
which can be used to either establish or improve suboptimality in the pres- 
ence of perturbations. Furthermore, we will delineate the class of perturba- 
tions for which simple magnitude adjustments of the optimal control can 
always be made to ensure a desired suboptimal behavior. 
To introduce feedback gain adjustments, we consider the input u(t) to 
the system S+ as consisting of two components, 
u=u@+u+, 
(3.25) 
where u@ is the optima1 control law (3.3) and u+ is a corrective input chosen 
as a linear control 
U+ = -K+x. 
(3.26) 
The constant gain matrix K+ should be determined to account for pertur- 
bations. For this purpose, we apply the combined linear control law 
u@ = -(K + K+)x 
(3.27) 
to the system S+ and state the following variation of Theorem 3.6: 
3.12. THEOREM. 
pair (S+, 
J) if the matrix 
A control law u@ is suboptimal with degree p for the 
F+(p) = ATP + PA+ + K,TRK+ - (1 - p) [Q + ( K  + K+)TR(K + K+)] 
(3.28) 
is nonpositive definite. 
3.13. REMARK. The suboptimality test provided by Theorem 3.12 is 
only a sufficient condition, and it is difficult to see what to do when the 
test fails. For this reason, we want to delineate the class of perturbation 
matrices A+ for which a choice of perturbation gain matrix K+ can always 
be made to make F+(p) nonpositive definite for some p. If A+ is such that 
it can be factored as 
A+ = BG, 
(3.29) 

3.1. Suboptimality 
135 
where G is any constant m x n matrix, then the system S+ can always 
be stabilized by properly choosing K+. Factorization (3.29) is the so-called 
“matching condition” (see Remark 3.36), and is equivalent to 
Im A, c ImB, 
(3.30) 
where Im denotes the image (range) of the indicated matrix. 
Remembering the stability implications of Theorem 3.6, we proceed to 
wtablish the following: 
3.14. THEOREM. Suppose that the perturbation matrix A+ satisfies 
the matching condition, and the matrix Q is positive definite. Then, there 
exists a positive number p such that, for 
K+ = P K ,  
(3.31) 
the matrix F+(p) is nonpositive definite for some p(p), which implies that 
the system S@ is suboptimal and stable. 
Proof. Substituting (3.29) and (3.31) into (3.28), and rearranging the 
terms, we obtain 
F+(p) = - 7-l (qBTP - RG)T R-’ (qBTP - RG) 
+ vp1GTRG - (1 - p) Q, 
(3.32) 
(3.33) 
Thus, if there exist a positive p and a p such that q > 0. and ~ ( 1  
- 
p) 1 A,(@RG)X;’(Q), 
then F+(p) becomes nonpositive definite. These 
conditions, however, can be satisfied by choosing p sufficiently large and 
p = 
The proof follows from Theorem 3.12. 
Q.E.D. 
An interesting feature of the above theorem is that a stabilizing sub- 
optimal control for the perturbed system is obtained by simply increasing 
the magnitude of the optimal control for the original system. The proof 
of this result hinges on the fact that by choosing p sufficiently large, the 
Liapunov function, which implies stability of the original system, is at the 

136 
3. Optimization 
same time a Liapunov function for the perturbed system-a 
trick we used 
in the preceding chapter when we considered connective stabilization of 
complex systems under arbitrary structural perturbations. 
3.2. Complex Systems 
Our immediate task now is to adapt the concept of suboptimality to 
systems composed of interconnected subsystems. We consider the standard 
model 
N 
S: Xi = A i ~ i  + Biui + C A i j ~ j ,  
i E N, 
(3.34) 
j=1 
in the compact form 
S: X = ADX + BDU + A ~ x .  
(3.35) 
To generate a decentralized control law, we assume that the decoupled 
subsystems 
or 
Si: Xi = A i ~ i  + Biui, 
i E N, 
(3.36) 
So: X = ADZ + BDU, 
(3.37) 
are controllable, that is, (AD, BD) is a controllable pair. With So, we 
associate a quadratic cost 
+cc 
JD(XO, u) = 1 
(X'QDX 
+ U'RDU) dt, 
(3.38) 
where 
QD = diag{Qi, Q2, . . . , QN), 
RD = diag(R1, R2, . . . , RN}, 
QD is symmetric nonnegative definite, and RD is a symmetric positive 
definite matrix. The cost JD can be considered as a sum of N costs 
(3.39) 
each associated with the corresponding subsystem Si. 

3.2. Complex Systems 
137 
A straightforward strategy to control the complex system S is to opti- 
mize each subsystem Si separately, that is, solve the LQ problem (So, JD) 
to get 
D - 
- - K D x ,  
(3.41) 
where KD = diag(K1, K2, . . . , KN} is given as 
KD = RblB:PD, 
(3.42) 
and PD = diag(P1, P2, . . . , PN} is the unique symmetric positive definite 
solution of the Riccati equation 
A;PD + PDAD - PDBDR~’ 
B ~ P D  
+ QD = 0. 
(3.43) 
The control ug, 
when applied to SO, results in the closed-loop system 
Sg: 5 = (AD - BDKD)~, 
(3.44) 
which is optimal and produces the optimal cost 
J,”(xO) = zrPDX0. 
(3.45) 
The most important fact about the locally optimal control ug is that 
it is decentralized. In other words, the components of u” are 
@=-Kixi, 
i E N, 
(3.46) 
and the system S is controlled by driving each individual subsystem Si using 
only the locally available information. Obviously, this strategy is generally 
not optimal, but under certain conditions it is suboptimal and stable. Most 
importantly, the final design is robust to a wide range of uncertainties in 
the interconnections, reinforcing the autonomy of the subsystems. 
The closed-loop system 
S”: j. = (AD - BDKD + Ac)z, 
(3.47) 
produces a cost J,”(zo). The interconnections play the role of perturbations, 
and suboptimality is formulated as in Definition 3.1: 
3.15. DEFINITION. 
optimal for the pair (S, JD) if there exists a positive number p such that 
A decentralized control law ug is said to be sub- 
(3.48) 

138 
3. Optimization 
We can take advantage of the fact that the system S is considered as an 
interconnection of subsystems, and obtain a less conservative result than 
that of Theorem 3.6. We first define an n x n matrix 
where the pi are positive numbers, and In, is the identity matrix of order 
ni . 
3.16. THEOREM. 
trix 
Suppose there exists a matrix MD such that the ma- 
F(MD) = A$M;’PD + M;’ PDAC + ( I  - Mi’) (QD + KZRD KD) (3.50) 
is nonpositive definite. Then, the control ug is suboptimal for S with degree 
p = min {pi}. 
i c N  
(3.51) 
Prooj We note that 
J,”(zo) = )iz iT 
zCT(t) 
( Q D  + K ~ R D K D )  
z(t) dt, 
(3.52) 
where z(t) = z(t, 20) is the solution of S@ in (3.47), which corresponds to 
~ ( 0 )  
= 20. From (3.42), (3.43), and (3.50), we get 
QD 
KZRDKD =F(MD) - ((AD - BDKD + Ac)* Mi’PD 
(3.53) 
+ M ~ ~ P L J  
(AD - BDKD + Ac)]. 
Using (3.53) in (3.52), we compute 
I 
J,”(zo) = lim [iT 
zT(t)F(Mo)z(t) 
dt - Z ~ ( T ) M ~ ~ P D Z ( T )  
T--tlX 
+ xTM;’PDx~. 
Now, the nonpositivity of F(MD) implies that 
(3.54) 
$(zO) 5 zTM6’PDzO 5 P-lzFPDzO, 
(3.55) 
where p is given by (3.51), and inequality (3.48) is established. 
Q.E.D. 

3.2. Complex Systems 
139 
3.17. REMARK. When pi = p for all i E N, 
we have the test matrix 
which would have been obtained by application of Theorem 3.6. Allowing 
different b ’ s  for subsystems, we introduce a possibility for scaling of the in- 
terconnection matrices and, thus, tailoring of the suboptimality conditions. 
It can be verified by simple examples that there are cases where F ( p )  is 
never nonpositive for any p while, at the same time, a matrix MD exists 
such that F(MD) is nonpositive. 
We can strengthen the suboptimality conditions for complex systems 
as suggested by Theorem 3.3, at the expense of the explicit appearance of 
the interconnected matrices. We shall do a little more and consider systems 
that are not input decentralized, that is, have interconnections caused by 
the input matrix. The overall system is described by 
S: X = A ~ x  
+ BDU + ACX + BCU, 
(3.57) 
where the matrix Bc = (Bij) is a block matrix with blocks B, compatible 
with the dimensions of the corresponding subsystem state xi E R”‘ and 
input ui E R”a. 
With the application of the locally optimal control ug to S, we get the 
closed-loop system 
S@: X = (AD - BDKD)X + ACX - BCKDX, 
(3.58) 
and the value of the performance index 
J,”(xo) = XTHXO, 
(3.59) 
where 
+m 
H = 1 
exp(ATt) Gexp(At) dt, 
(3.60) 
GD = QD + PD BD RE’ Bg PO, 
and the closed-loop matrix is 
A = AD - BDKD + Ac - BcKD. 
(3.61) 
We again note that ug is suboptimal for the system S of (3.57) if and 
only if H of (3.60) is finite. Following further the proof of Theorem 3.3, we 
arrive at: 

140 
3. Optimization 
3.18. 
degree of suboptimality 
for the pair ( S ,  JD) if and only if the matrix H is finite. 
3.19. REMARK. 
matrix F(MD) of Theorem 3.16 becomes 
THEOREM. A control law ug is suboptimal with the (largest) 
/A* = AZ(HPi1) 
(3.62) 
It is obvious that, when BC is present in S, the test 
F(MD) 
= (Ac - B c K D ) ~  
MG'PD + ME'PD (Ac - &KD) 
+ (1 - Mi') (QD + P D B D R ~ ~ B ~ P D ) .  
(3.63) 
That is, in the context of Theorem 3.6, the matrix Bc can be interpreted as 
perturbation of the input matrix B, and included in the test matrix F ( p )  
in (3.19). 
3.20. EXAMPLE. To show how suboptimality analysis is carried out, 
we consider a simple system 
(3.64) 
with the cost 
Solving the Riccati equation (3.431, we get 

3.2. Complex Systems 
141 
and the decentralized control law becomes 
Applying this control to S, we get the closed-loop system 
(3.67) 
[::I 
(3.68) 
To determine suboptimality of decentrally driven system S @ ,  we com- 
pute the matrix H of (3.60) and get 
0.48 -0.52 
0.02 -0.02 
(3.69) 
-0.52 
0.63 -0.03 
H =  [ 0.02 -0.03 
0.63 -::!;I 
‘ 
-0.02 
0.03 -0.52 
0.48 
This establishes suboptimality of ug in (3.67). Using Theorem 3.18, we 
compute the suboptimality index as 
p* = 0.95, 
(3.70) 
and obtain the fundamental inequality of suboptimality: 
J,”(Q) 5 1.05 J,”(zo). 
(3.71) 
This means that we are at most 5% off with respect to the performance 
of optimal decoupled subsystems. This is not surprising because the inter- 
connection matrix Ac in (3.64) or (3.68) is relatively weak and does not 
disturb significantly the optimal performance of the subsystems. 

142 
3. Optimization 
Theorem 3.4 can be used to show that the computed local control ug is 
a stabilizing control as well. We only need to note that, in (3.65), we have 
QD = diag{l, 1, 1, 1) and (A, Gg') is an observable pair, with A and Go 
defined by (3.68) and (3.60), respectively. 
When the matrix QD + PDBDRilBgP~ 
is positive definite, we can use 
the test matrix F ( p )  from (3.56) to compute the suboptimality index as 
If pt > 0, then it is a suboptimality index for ug, 
but pt 5 p*. In case of 
ug of (3.67), 
pt = 0.93. 
(3.73) 
Stabilizability in this case is guaranteed, as in Remark 3.7, by the de- 
tectability (observability) of the pair {A, [-F(O)]"'}, where A is given in 
(3.68) and F(0) is computed from (3.56). 
There is still another advantage offered by the concept of suboptimality: 
a reduction of dimensionality. In computing the optimal control ug, 
we ma- 
nipulate only subsystem matrices of lower dimensions than the dimension 
of the overall system. The test matrices, however, involve computations of 
matrices having dimensions equal to that of the overall system, which may 
be prohibitive. To remove this difficulty, we can use a condition for sub 
optimality which closely resembles the stability condition obtained in the 
preceding chapter by the method of vector Liapunov functions. To state 
the condition, we define the numbers 
vi = A, 
(Qi + Pi Bi R," B,TP,) , 
(3.74) 
&j = A? 
[(Aij - BijKj)T P,P, (Aij - BijKj)] . 
With these numbers, we specify the two N x N matrices 
W D  = diag{7]1, 7]z . . . 7 7
]
~
 
1, 
W C  = (&j) 7 
(3.75) 
and prove the following corollary to Theorem 3.16: 
3.21. 
number p the matrix 
COROLLARY. A control law ug is suboptimal if for some positive 
W ( p )  = Wc'+ wc - (1 - p)Wo 
(3.76) 
is nonpositive definite. 

3.2. Complex Systems 
143 
Pmoj It is easy to see that 
ZTF(M~)a: 
5 3'W(p)3, 
V Z  E R", 
(3.77) 
where 3 E RN is defined as 3 = (IIz111 , IIzzll, . . . , ((z, I I ) T ,  
F(MD) is given 
in (3.50), and p in (3.51). The nonpositivity of W ( p )  implies nonpositivity 
of F(MD) and, by Theorem 3.16 and Remark 3.19, we have suboptimality 
of ug. 
Q.E.D. 
Obviously, W ( p )  5 0 is more restrictive than the condition F(MD) 5 
0, and the additional conservativeness in Corollary 3.21 should be judged 
satisfactory to the extent it is outweighed by the numerical simplicity in 
computation of the test matrix W ( p ) .  In the case of Example 3.20, we can 
compute the suboptimality index from (3.76) as 
pw = 1 - AM [Wi' (wc' 
+ wc)] 
, 
(3.78) 
which involves only operations on second order matrices. On the other 
hand, we get 
pw = 0.8, 
(3.79) 
which is significantly smaller than pt and p* of (3.73) and (3.70) obtained 
by Remark 3.17 and Theorem 3.18. 
So far, the reference system for suboptimality has been the collection 
of optimal decoupled subsystems. This choice promotes the autonomy of 
subsystems, and can be used to reduce the dimensionality of the control 
design. If the computation is not a problem and the decentralized infor- 
mation structure is inherent to the system, as is the case with automatic 
generation control in power systems (e.g., Siljak, 1978), then it is worth- 
while to compare the locally optimal performance with that of the centrally 
optimal system (Krtolica and Siljak, 1980). 
Let us consider the system S of (3.57) as 
S: ~ . = A ~ + B u ,  
(3.80) 
where A = AD + Ac and B = BD + Bc, and the performance index 
J(z0, U )  = 1'" (sTQz + u ~ R u )  
dt, 
(3.81) 
from (3.38). We assume again that the pair (A, B )  is controllable and 
the pair (A, 
is observable. It is well known (Kalman, 1960) that the 

144 
3. Optimization 
optimal control law is given by 
and the optimal cost by 
P ( X 0 )  = x;pxo, 
(3.83) 
where P is the unique symmetric positive definite solution of the Riccati 
equation 
ATP + P A  - PBR-'BTP + Q = 0. 
(3.84) 
Suboptimality of the decentralized control law 
ua - 
D - - R,' 
BZ; POX 
(3.85) 
is now defined with respect to the pair (S, J ) ,  and can be evaluated using 
the costs J@(xo) 
of (3.59) and J@(XO) 
of (3.83), where J@(xo) 
is the cost 
produced by the system S of (3.80) when driven by ug. That is, to measure 
the effect of the difference between the control laws u@ and ug, we consider 
the positive number p for which 
J@(xo) 5 p - ' J a ( ~ o ) ,  
V X  E R". 
(3.86) 
It is easily seen that the number p exists if and only if the matrix H of 
(3.60) is finite. In that case, the largest (best) number p* for which (3.86) 
holds is computed as 
p* = A-1 
M ( Hp-1 ) I  
(3.87) 
which is similar to the expression for p* in (3.62). This fact implies that, 
once suboptimality of a control law is established with respect to one ref- 
erence pair, it is suboptimal to another provided that the corresponding 
observability conditions are satisfied. 
3.3. Robustness of Suboptimal Control 
Over the years, control systems evolved from simple servomechanisms to 
sophisticated control schemes for multivariable systems. One of the essen- 
tial roles of feedback has been to achieve a satisfactory control of processes 
having parameters that are either not known exactly due to modeling er- 
rors, or are varying in time during operation. In classical control theory 

3.3. Robustness of Suboptimal Control 
145 
(Bode, 1945; Thaler and Brown, 1960), robustness of feedback control sys- 
tems to parameter uncertainty has been considered by frequency analysis 
whereby the gain and phase margins have served to measure the ability of 
the closed-loop system to withstand gain and phase changes in the open- 
loop dynamics. 
Once it was shown (Kalman, 1964) that optimal LQ regulators satisfy a 
frequency domain condition, the standard robustness measures of gain and 
phase margins became available (Anderson and Moore, 1971) for applica- 
tion to optimal control systems designed to meet time domain performance 
criteria. This opened up a real possibility of establishing these measures as 
performance characteristics of the optimal multivariable feedback system 
(Safonov, 1980), thus increasing considerably the applicability of the LQ 
control design. 
A further increase of complexity has appeared in large-scale systems 
that are characterized by multiplicity of controllers, each associated with 
one of the interconnected subsystems. This nonclassical information and 
control structure constraint leads to decentralized control laws that have to 
be implemented by local feedback loops. The decentralized control schemes 
have been proven to be effective in handling the modeling uncertainties in 
the interconnections among the subsystems (Siljak, 1978), which are invari- 
ably present in the control problems of complex systems. An interesting 
new direction in robustness analysis was taken in a couple of papers (Sezer 
and Siljak, 1981a,b), where suboptimal decentralized control schemes were 
shown to be robust in terms of gain and phase margins and tolerance 
to nonlinearities inside the subsystems. The basic idea was presented in 
Section 3.1 for the special case of centralized control system under pertur- 
bation. We shall now present the generalized results for the decentralized 
structures. 
First, we consider the question: Can S@, for fixed Ac, tolerate distor- 
tions in the suboptimal control ug caused by insertion of nonlinearities into 
the feedback loops? 
Let us consider the system 
S$: k = (AD + Ac)z + B D ~ ( u ) ,  u = -Kz, 
(3.88) 
where the nonlinearity q$: 
R" + R" is of the form 
4(u) = [4T(.l,, 4Tcw>, . . . > 4;(%4' 
7 
(3.89) 
with 4i: R"a -+ R"' being a continuous function of ui. 
3.22. THEOREM. Suppose that F(MD) is nonpositive definite for some 
MD, 
and that the pair ( A D + A ~ ,  QF) is observable. Then, the equilibrium 

146 
3. Optimization 
z = 0 of S4 is asymptotically stable in the large for all nonlinearities 4(u) 
that belong to the class 
CP = {4: /~iuT&ui I ~ y 4 i  
(RT'w) 5 EiuTui, 
i E N }  , (3.90) 
where 
(3.91) 
1 
si = 1 -  -(pi -Ap), 
2 
Ei < +OO, 
and A p  is an arbitrarily small positive number. 
Proof. Let u: R" -+ R+, which is defined as 
u(z) = X T M E ' P D X ,  
(3.92) 
be a candidate for a Liapunov function of S4. Using the optimal gain KO 
of (3.42), Riccati equation (3.43), and the definition of @ in f3.90), by 
straightforward computations we obtain 
which implies that V(z)(3,gg) 5 0. On the other hand, the observability 
assumption together with the fact that +(O) = 0, which is implied by (3.90) 
and the continuity of (6(u), ensure that t j ( ~ ) ( 3 . ~ 8 )  
is not identically zero along 
any trajectory of the system S4 except the equilibrium z = 0. 
Q.E.D. 
Next, we consider the case when the nonlinearities q5i(ui) in (3.89) are 
replaced by stable linear time-invariant systems Li having the states zi, in- 
puts %, and transfer function matrices Li(s). Denoting the resulting system 

3.3. Robustness of Suboptimal Control 
147 
by SL, we prove: 
3.23. THEOREM. Suppose that F ( M )  is nonpositive definite for some 
M, and the pair (AD + Ac, QT) 
is observable. Then, the equilibrium 
z = 0, 
= 0, i E N, of SL is asymptotically stable (in the large) provided 
that 
Lj(jw)R,-1+R,'L'(jw)-(2-pi+Ap)R~' 
2 0, 
V w  E R, 
Vi E N, 
where Ap is an arbitrarily small number. 
(3.94) 
Pmoj Let the collection of the linear systems Ci inserted into the feed- 
back loops be denoted by C, which has the state z = (z:, z;, . . . , 2;) 
, 
the input w = (w:, vr, . . . , w;) 
with wi = -Kizi, i E N, and the block 
diagonal transfer function LD(s) = diag{Ll(s), Lz(s), . . . , LN(s)}. Obvi- 
ously, (z = 0, z = 0) is the equilibrium of SL. For any z(0) = 20, we 
have 
T 
T 
s;M,-'PDzo = zT(r)M,-'PDz(r) - - [zT(t>MElPDz(t)] 
dt. (3.95) 
1' :t 
Using (3.42), (3.50), (3.88), and nonpositive definiteness of F(MD), we 
obtain, from (3.95), 
(3.96) 
- 22T(t)M,-'PoBnu(t)jdt. 
Taking the limit as r + +m, the right hand side of (3.96) can be written, 
using the Parseval's theorem, as 

148 
3. Optimization 
where x(jw) and u(jw) are the Fourier transforms of x ( t )  and u(t). With 
z(0) = 0, u(jw) and x(jw) are related by 
.(jw) = L&AJ)w(jw) = -LD(jw)KDZ(jw). 
(3.98) 
Substituting (3.98) into (3.97), we get the expression 
(3.99) 
which is nonnegative by (3.94). Thus, from (3.96) we obtain 
(3.100) 
which, together with the observability assumption, implies that the soh- 
tions of S, corresponding to the initial condition x(0) = 50, z(0) = zo tend 
to zero as t -P 
+m. Since xo is arbitrary, this is equivalent to saying that the 
poles of the transfer function [d 
- AD - Ac + BDLD(s)KD] 
have negative 
real parts. The proof then follows from the argument in (Safonov, 1980) 
that all poles of 8, that do not appear as poles of this transfer function (if 
there are any) must be poles of L, which are assumed to have negative real 
parts, so that S, is stable. 
Q.E.D. 
Theorems 3.22 and 3.23 can be viewed as generalizations of the well- 
known criteria of gain and phase margin to the interconnected systems with 
multivariable subsystems. To see this, let us consider a special case where 
the subsystems Si have single inputs, that is, mi = 1. Then, the ui and 
4 i ( ~ )  
in (3.89) as well as the Li(s) and R, are scalars, and we obtain the 
following result from Theorems 3.22 and 3.23: 
3.24. 
Suppose that each Si has a single input, F ( M )  is 
nonpositive definite for some M ,  and the pair (AD+Ac, Q1L2) is observable, 
so that S is stable. Then, the ith feedback loop of 8 has: 
COROLLARY. 
(i) infinite gain margin; 

3.3. Robustness of Suboptimal Control 
149 
(ii) at least fcos-‘(l - $pi) phase margin; 
(iii) at least 50pi% gain reduction tolerance. 
Proof. By “the ith feedback loop of S has infinite gain margin” we mean 
as in (Safonov, 1980) that arbitrarily large increases in the gain of the local 
feedback (3.46) do not destroy stability of S. Similar interpretation can be 
given to loop phase margin and loop gain reduction tolerance. 
Under the conditions of the corollary, (3.90) reduces to 
~i I +i(ui)/% I 
jii < +00 
, 
i E N, 
(3.101) 
where ui E R and +i: 
R 4 R are scalars, from which ( i )  and (iii) follow. 
Similarly, (3.94) becomes 
1 
Re{.ti(jw)} 2 1 - j ( p i  - Ap) 
V w  E R, 
i E N, 
(3.102) 
where &(s) is a scalar transfer function, and (ii) is a consequence of 
(3.102) upon choosing & ( j w )  = exp{cpi(jw)}, which implies that Ipi(jw)I 5 
CM-’ [ 1 - (pi - Apt] . 
Q.E.D. 
The results of this section show that suboptimal control is robust in 
pretty much the same way as the optimal control. Furthermore, the simi- 
larity of the conditions (3.90) and (3.94) with the standard such conditions 
for optimal multivariable control systems (Safonov, 1980) suggests a pos- 
sibility that a modification of the suboptimal control might result in an 
interconnected system that is optimal (Sezer and Siljak, 1981b). Once the 
interconnections are recognized as perturbation terms disturbing the opti- 
mality of the subsystems, the idea of an additional control action in the 
spirit of the perturbation control is attractive. In fact, this added effort 
may reshape the locally optimal control into one that is globally optimal, 
that is, optimal for the overall interconnected system. The reward is the 
standard robustness properties of the optimal LQ control, which in the case 
of single input subsystems means that each feedback loop has infinite gain 
margin, f60” phase margin, and 50% gain reduction tolerance. 
Let us assume that F(MD) is nonpositive definite for some matrix MD, 
and modify the weighting matrices f
i
~
 
and QD as 
RD = diag(R1, R z ,  . . . , RN}, 
(3.103) 

150 
3. Optimization 
where 
(3.104) 
with 
QD = Mi' (QD - P D B D R E ' B ~ P ~ )  
+ M i ' P D B D R i l B Z ; ~ D  
- A F M ~ ~ P ~  
- M , - ~ P ~ A ~ ~  
(3.105) 
and prove the following: 
3.25. THEOREM. Suppose that F(MD) is nonpositive definite for some 
MD. Then: 
(i) The matrix QD is nonnegative definite. 
(ii) The decentralized control 
fp - 
- -KDx1 
K D  = R ; ~ B ~ M ~ ~ P D ,  
is optimal for S with respect to the modified cost 
(3.106) 
(3.108) 
is the optimal cost. 
control .ii@ 
stabilizes S. 
(iii) If, in addition, the pair (AD + Ac, Qg2) is observable, then the 
Proof. Using the expressions (3.42) for KD and (3.50) for F(MD) in 
(3.105), we obtain 
and (i) is established by the definition of &!, 
in (3.104) and the fact that Q 
is nonnegative definite and F ( M D )  is nonpositive definite by assumption. 

3.3. Robustness of Suboptimal Control 
151 
Furthermore, it can easily be verified that 
( A D  + A C ) ~ M ~ '  
PO + M-' 
D PO (AD + A C )  - ~ 6 '  
PO BD R;' BD PO M-' +& = 0, 
(3.110) 
proving (ii). Finally, observability of the pair (AD + Ac, QF) 
implies o b  
servability of the pair {AD+Ac-BDKD, (QD + KDRDKD)"~} 
(Wonham, 
1979), from which stability of the modified closed-loop system follows, thus 
(iii) . 
Q.E.D. 
3.26. REMARK. 
nents of the modified optimal control are 
From (3.104) and (3.106), it follows that the compe 
where the UP are the local controls that are optimal for the decoupled sub- 
systems Si with respect to their individual performance measures Ji. The 
critical observation is that once suboptimality of the decentralized control 
ug is established using F(MD), by increasing the gains of the feedback 
loops around the subsystems, we can recover the optimality of the overall 
system, albeit with some modification of the performance index. The ben- 
efit of the gain boost is the improved robustness characteristics, which is 
really why we went for global optimality in the first place, and why we will 
return to this problem in the next section. 
So far, we had a fixed structure for the complex system S, and we 
want now to remove that restriction. Our aim is to provide conditions 
for connective suboptimality, which is a natural outgrowth of connective 
stability in the context of decentralized control. 
Our major (but not irremovable) assumption is that the subsystems Si 
have single inputs, that is, 
Bi = bi, 
i E N, 
(3.112) 
where bi E R"' . The interconnected system is described as 
S: i = [AD + Ac(E)] 2 + Bu, 
(3.113) 
which is the model used in Sections 2.4 and 2.5. In fact, the notation and 
development to the end of this section follows closely those of Section 2.5. 

152 
3. Optimization 
0 
1 ... 
0 
0- 
0 
0 ... 
Ai= [~...~...........:.], 
b i =  [ 0 0 
a; . . . a& 
1- 
3.27. 
A decentralized control law ug is said to be con- 
nectively suboptimal for the pair (S, JD) if there exists a positive number 
,u such that 
DEFINITION. 
J,”(Q) 5 p-lJg(~o), VJZO E Rn, 
V E  E E. 
(3.114) 
. 
(3.115) 
T 
(3.116) 
k=l 
then the interconnected system S of (3.113) is stabilizable by the decentral- 
ized feedback, regardless of what the matrix E is; that is, it is connectively 
stabilizable. This, however, does not imply automatically that the decen- 
tralized control is also suboptimal. In fact, to establish suboptimality via 
Theorem 3.16, we have to choose properly the cost JD(Q, u). For this, we 
first need the following: 
3.29. LEMMA. Suppose that the integers mij satisfy the inequality 
(3.116). Then, there exist numbers ui such that 
ui-uj+l-mij>O, 
‘di, j E N. 
(3.11 7) 

3.3. Robustness of Suboptimal Control 
153 
Proof. This is a combinatorial problem that can be solved by the graph- 
theoretic methods of Section 2.5. Although the proof is straightforward, it 
is rather lengthy and is, therefore, omitted. 
Q.E.D. 
We now choose the blocks Qi of the state weighting matrix QD as 
Qi = Di(h)QiDi(b), 
(3.118) 
where the Qi are arbitrary positive definite matrices, and 
with 6 being a positive number to be determined. Also, keeping in mind 
that, due to the assumption on the dimension of the subsystem inputs, the 
input weighting matrix RD in JD(ZO, u) has the form 
(3.120) 
p. 
1 -  - 
@(vi+ni) , 
 EN. 
(3.121) 
With this choice of JD(ZO, u), we have: 
3.30. THEOREM. Suppose that the numbers mij satisfy inequality 
(3.116), and that the matrices QD and RD of the cost JD(ZO, 
u) are de- 
fined by (3.118)-(3.121). Then, there exists a positive number 8 such that, 
whenever 6 < 8, the control law ug is connectively suboptimal with degree 
p = p(6) for the system S of (3.113), such that p(6) + 1 as 6 + 0, and, at 
the same time, ug connectively stabilizes S. 
Proof. We first show that with Ail bi as in (3.115), Qi as in (3.118), 
and pi as in (3.121), the positive definite solution of the Riccati equation 
ATPi + PiAi - Pr’PibibTP, + Qi = 0 
(3.122) 
has the form 
(3.123) 

154 
3. Optimization 
where e(6) > 0 for any 6 > 0, and lims.+o E(6) = 
> 0. For this, we 
substitute (3.123) into (3.122) and pre- and postmultiply by Dzy'(6) to get 
. 0 
1 
... 
0 
0 
0 
... 
0 
0 
0 
... 
1 
.ha; 6ai .. . 6ah, 
................... . 
(3.125) 
Since the pair [&(6), bi] is controllable, and the pair [Ai(S), Q:'2] is o b  
servable, (3.124) implies that e(6) > 0. Positive definiteness of the limit 
Pin folIows from continuity of Ai(6). 
Now, to prove Theorem 3.30, we introduce D = diag{ D1, Dz, . . . , DN}, 
choose p = pi for all i E N, 
define F ( p )  = pD-'FD-', and use (3.41), 
(3.50), (3.118), (3.121), and (3.123) to get 
F ( p )  = s(D-'AT,DPD 
+ &DA~D-') - (1 - p)(QD + P D B D B D P D ) ,  
(3.126) 
= &(6) = diag{p1(6), Pz(S), 
where QD = diag(Q1, Q z ,  . . . , Q N }  and 
. . . , &(6)}. 
Let us consider the N x N matrix 
6p~DAcD-l = [e&R (6)Di (6)Aij DJT1 (S)] . 
(3.127) 
Since, in each block of the matrix (3.127), we have 
(3.128) 
from the definition of the numbers mij in (2.120) and from (3.117), we 
conclude that the matrix of (3.127) is of the order 6", 
where 
1
1
 
6Di (6)Aij D;1(6) = [ a g 6 v ~  
-vj +l-(q-P) 
(3.129) 
Thus, as 6 + 0, the first term in F ( p )  approaches zero regardless of the 
values of eij. Since QD + PDBDB~PD 
> 0 for all 6 > 0, it follows that for 
sufficiently small 6, there exists a p > 0 arbitrarily close to one such that 
F(p) < o for any E E E. 
Q.E.D. 

3.4. Optimality and Robustness 
155 
We note that the above choice of the cost matrices QD and RD leads 
to high-gain feedback matrices kT = 
. . . , kini6-2] 
which, in turn, result in closed-loop decoupled subsystems having eigen- 
values of the order 6-'. It is, in fact, this high-gain characteristic of the 
suboptimal control, together with the structure of the interconnection ma- 
trix &, that makes the closed-loop system 
S : k = [AD - BDKD + Ac(E)]. 
(3.130) 
connectively suboptimal. Clearly, S also has the sensitivity properties de- 
scr:bed in Corollary 3.24, that is, for sufficiently small 6, each feedback loop 
of S has infinite gain margin, approximately 60" phase margin, and 50% 
gain reduction tolerance. 
3.31. EXAMPLE. We consider a special case of interconnected systems, 
where interconnections enter additively through inputs of the subsystems, 
which was considered by many people (e.g., Davison, 1974; Ikeda et al. 
1976; Sezer and Huseyin, 1978; Saberi and Khalil, 1982). In this case, we 
have 
Aij = bihg, 
V i, j E N, 
(3.131) 
where hj E Rn> are constant vectors. Clearly, for such systems, Aij ma- 
trices have the structure 
(3.132) 
... * 
A , .  - 
a J - [ *  
* 
when Ai, bi are brought to the form (3.115), so that the numbers mij in 
(2.120) are 
(3.133) 
Therefore, (3.116) is satisfied, and Theorem 3.30 ensures the existence of a 
suboptimal decentralized control law. Furthermore, Theorem 3.25 implies 
that, by increasing the gains of the local controls, the closed-loop inter- 
connected system can be made optimal. This fact has been recognized by 
Yasuda et al. (1980), and later generalized by Ikeda and Siljak (1982, 1985) 
and Ikeda et al. (1983). 
m . .  
a3 - 
- n. 
3 - n. 
1 ,  
i E N. 
3.4. Optimality and Robustness 
We would like now to broaden the preceding analysis in an essential 
way and consider optimality of LQ control for nonlinear systems. The LQ 

156 
3. Optimisation 
control law is generated by optimizing the linear part of the system, and 
conditions are explored for the control law to remain optimal when a nonlin- 
ear time-varying perturbation is present in the system. A strong motivation 
for this approach is provided by the fact that, as a by-product, we will es- 
tablish the robustness of the control law for a nonlinear system in terms of 
the classical sensitivity measures of gain and phase margin used for linear 
systems. 
The approach is inspired by the inverse optimal control problem formu- 
lated and solved for linear systems by Kalman (1964), but t,he inclusion of 
nonlinear time-varying perturbations is new and is crucial for our consider- 
ation of decentralized information structure constraints. The interconnec- 
tions will be interpreted as perturbations of subsystems that are controlled 
by decentralized LQ feedback, and robustness in this case is essential be- 
cause the nonlinearity in modeling of interconnections is almost always a 
part of the design problem. 
We first consider LQ optimality in nonlinear systems without decen- 
tralized constraints following the original work of Ikeda and Siljak (1990). 
A decentralized version of the results, which were first stated for the linear 
systems by Ikeda and Siljak (1982) and Ikeda et al. (1983), is postponed 
until the next section. 
Let us consider a nonlinear time-varying system described as 
S : j. = AX + BU + f(t, X ,  u), 
(3.134) 
where x(t) E R" is the state, and ~ ( t )  
E R" is the input of S at time 
t E R. The matrices A and B are constant and constitute a stabilizable 
pair. The function f : R x R" x R" 
-+ 
R" is sufficiently smooth so 
that (3.134) has the unique solution z(t) = x(t; to, X O ,  u) for any initial 
conditions (to, X O )  E R x R" and any fixed piecewise continuous input 
u(-). 
Furthermore, we assume that f(t, 0, 0) = 0 for all t E R, and that 
z = 0 is the unique equilibrium of S when u(t) = 0. 
To obtain the LQ control for S, we consider the linear part of S, 
SL: X = A X + B U ,  
(3.135) 
and a quadratic performance index 
(3.136) 
where Q and R are positive definite matrices. The optimal control for the 
pair (SL, JL) is 
u4;' 
= -Kx, 
K = R-'BTP, 
(3.137) 

3.4. Optimality and Robustness 
157 
where P is the positive definite solution of the Riccati equation 
ATP + P A  - PBR-'BTP + Q = 0. 
(3.138) 
The LQ control law uz is not optimal for the nonlinear system S with 
respect to JL, but it can be made so (Siljak, 1980) by introducing another 
type of performance index that includes the function f(t, 2, u): 
J ( t 0 ,  20, .) 
= 
4 4  2, .) 4 
(3.139) 
Lo* 
where the function A: R x R" x R" -+ R is defined as 
~ ( t ,  
2, u) = zTQ. - 22'Pf(t, 
2, u) + J R u .  
(3.140) 
The basic result is the following: 
3.32. THEOREM. If there exist positive numbers Q and p such that 
~ ( t ,  
2, u) 2 asTQz + Pd'Ru, 
V ( t ,  2, u) E R x R" x Rm, (3.141) 
then the control u? is optimal for the pair (S, J ) .  
Proof. Substituting (3.134) and (3.138) into (3.139), we get 
(3.142) 
+ Lot1 (u + R-'BTPz)TR(u + R-lBTPz) dt]. 
If we use uz, 
we obtain 
Because of inequality (3.141), J(t0, 20, u) is positive in all arguments, which 
implies that the infimum of J(t0, 20, u) 
with respect to u exists and satisfies 
the inequality 
(3.144) 

158 
3. Optimization 
The existence of the infimum of J(t0, 20, u) and inequality (3.141) further 
imply that z(t) + 0 as t + 00, which follows from the inequality 
inf J(t0, 20, u) 2 lom 
( ~ z ~ Q z  
+ puTRu) dt, 
(3.145) 
U 
and the positive definiteness of matrices Q and R. Therefore, if we use the 
LQ control uf, 
we conclude from (3.142) that it is optimal, and 
min J ( t o , ~ ,  
u) = zTPz0 
(3.146) 
is the optimal cost. 
Q.E.D. 
Because of the presence of the nonlinear time-varying function f(t, Z, u) 
in ~ ( t ,  
2, u), 
it is not possible to explain the meaning of the cost functional 
J(t0, 2 0 , ~ )  
in terms of power, energy, or squares of disturbances from an 
equilibrium, as in the case of standard LQ control problems. We note, 
however, that when the condition of Theorem 3.32 is satisfied, J plays the 
role of an upper bound of the quadratic performance index 
so that we expect the optimal control law for J to be suboptimal with 
respect to JL, which, in turn, justifies the use of J .  More importantly, 
optimality of the pair (S, J )  implies robustness of the resulting closed-loop 
system in pretty much the same way as in the case of optimality of the pair 
(SL, JL), which makes Theorem 3.32 potentially useful in applications. 
3.33. 
equivalent to the existence of positive numbers a' and /3' such that 
REMARK. It is obvious that condition (3.141) of Theorem 3.32 is 
~ ( t ,  
Z, u) 2 Q ' Z ~ Z  + @'uTu, 
V(t, z, u) E R x R" x R". 
(3.148) 
This inequality is simpler to establish than (3.141), but may appear inferior 
in the robustness analysis of S .  
In applications, knowledge about the nonlinearity f(t, Z, u) is often 
imprecise, and only sector bounds are available. Then, the following result 
may be useful: 
3.34. 
ity 
COROLLARY. If the nonlinearity f(t, Z, u) satisfies the inequal- 

3.4. Optimality and Robustness 
159 
for positive numbers < and q such that 
(3.150) 
then the LQ control law is optimal for the pair (S, 
J). 
Proof. Inequality (3.150) follows from the inequality 
It is easy to see that (3.150) implies (3.148) for some positive numbers a' 
and p' such that 
Another way to recover optimality of the LQ control law, when applied 
to S, is to increase the feedback gain (Sezer and Siljak, 1981b; Ikeda and 
siljak, 1982,1985). For this approach to work, the function f ( t ,  x, u) should 
be separable as 
f ( t ,  x, .) 
= Bg(4 x, .) + h(t, x), 
(3.153) 
where the functions g :  R x R" x R" + R" and h: R x R" + R" are 
sufficiently smooth, and g(t, z, u) satisfies the sector condition 
with positive numbers <' and q' < XZ'(R)/Xr(R). Then, to reflect the 
increase of feedback gain, we introduce the number p > 1 into the optimal 
LQ control to get 
up = - ~ K x ,  K = R-'BTP. 
(3.155) 

160 
3. Optimization 
At the same time, we modify the cost as 
J p ( k  2, u) = 
np(t, 2, u) dt, 
Lorn 
where nk R x R" x Rm -, R is defined as 
(3.156) 
r,(t, x, u) = x*Qz - 2xTPf(t, x, u) + ( p  - l)xTPBR-'BTPz +p-'uTRu. 
(3.157) 
3.35. THEOREM. 
xTQx - 2xTPh(t, x) 2 y x T q  . V(t, x) E R x R", 
(3.158) 
then a sufficiently large positive number p can be chosen so that the control 
law up is optimal for the pair (S, 
Jp). 
If there exists a positive number y such that 
Proof. We will show first that under the condition of the theorem, there 
exist positive numbers ap and @, 
such that 
n,(t, x, u) 2 a,xTQx + @,uTRu, 
Let us note that the function np(t, x, u) can be rewritten as 
V(t, x, u) E R x R" x R". 
(3.159) 
np(t, 2, U )  = xTQx - 2zTPh(t, x) - ( p  - l)-'g(t, 2, u)Rg(t, Z, u) 
T 
+ ( p  - 1)-l [ ( p  - l)BTPx - Rg(t, 5, 43 
x R-' [ ( p  - l)BTPx - Rg(t, x, u)] + p-lurRu. 
(3.160) 
This expression of np(t, 
2, u) and conditions (3.154) and (3.158) im- 
ply that for sufficiently large positive p, inequality (3.159) holds. Now, we 
substitute the system description (3.134) and Equation (3.157) into the 
performance index Jp to get 
+ p-l lot1 
[u + pR-1BTPxIT [u + pR-'BTPz] dt}. 
(3.161) 

3.4. Optimality and Robustness 
161 
Using the same argument as in the proof of Theorem 3.32, we find 
Q.E.D. 
optimality of the control law up for the pair (S, 
Jp). 
3.36. REMARK. Theorem 3.35 implies that increasing the feedback gain, 
we can recover optimality provided the part of the nonlinearity, which can- 
not be cancelled by any choice of the input u, 
is independent of u and is 
sufficiently small. A special case is the situation when f depends only on t 
and x, satisfies the secalled "matching condition" (Leitmann, 1979) 
and has bounded gain with respect to x. The specialization of condition 
(3.162) to linear systems is (3.29), which was used in Section 3.2. 
3.37. REMARK. We note that the function h(t, x) in the decomposition 
(3.153) of f (t, x, u), is not allowed to depend on u, otherwise the proof 
of Theorem 3.35 cannot go through. This fact implies that although we 
have introduced a modification of the control U L  as well as the index JL, 
the condition for optimality of (S, J) has not been relaxed enough for 
Theorem 3.35 to include the result of Theorem 3.32. 
At this point the question arises: If we recover LQ optimality in the 
nonlinear system S of (3.134), do we get the standard robust stability 
properties of the resulting closed-loop system? In the rest of this section, 
we will provide a positive answer to this question and indicate the extent 
of the robustness of LQ control in this case. 
We investigate the robustness of the closed-loop system 
S: x = (A - BR-'BTP)x + f (t, Z, -R-'BTPx) 
(3.163) 
with respect to distortions of the control law u:. For this purpose, we 
consider the insertion of a smooth memoryless time-varying nonlinearity 
4: R x R" --t R", $(t, 0) = 0, or a linear time-invariant stable element 
having an m x m proper transfer function L(s), in the feedback loop of S .  
The corresponding perturbed versions of S are 
S4: k = AX + B$(t, -R-lBTPx) + f [t, 2, $(t, -R-'BTPx)] 
, (3.164) 
for the nonlinear distortion of u:, and 
SL: X = Ax + B[L * (-R-'BTPx)] 
+ f [t, X, L * (-R-'BTPx)] 
, (3.165) 

162 
3. Optimization 
for the insertion of a linear element, where * denotes the convolution and 
L(t) is the inverse Laplace transform of L(s). 
By 6, we denote a nonnegative number for which 
a& - SPBR-'BTP > 0 ,  
(3.166) 
and prove the following: 
3.38. THEOREM. Under the condition of Theorem 3.32, the equilib- 
rium z = 0 of the system S4 is globally asymptoticdly stable for any 
nonlinearity $(t, u) such that 
V ( t ,  z) E R x R". 
ProoJ The proof is a straightforward application of the Liapunov the- 
ory. We consider the quadratic form 
v(z) = zTPz, 
(3.168) 
and calculate the time derivative C(~)(3,164) with respect to S4 of (3.164), 
using the Riccati equation (3.138) and inequality (3.141) of Theorem 3.32, 
to get 
C(z)(3.164) I - zT(aQ - SPBR-'BTP)z + (I - @)@(t, u?)R$(t, u:) 
- 2@(t, u:)Ruz + (1 - 6)uZTRu:, 
V ( t ,  x) E R x R". 
(3.169) 
Global exponential stability of the equilibrium z = 0 of S4 follows 
from h ( P ) z T z  I 
v(z) 
I 
X M ( P ) ~ ~ ~ ,  
and C(z)pIa) 
5 
-Xm(aQ - SPBR-'BTP)zTz. 
Q.E.D. 
3.39. THEOREM. Under the condition of Theorem 3.32, the equilib 
rium z = 0 of the system SL is globally asymptotically stable for any 
stable linear timeinvariant distortion having a transfer function L(s) such 
that 
[LH(jw) - I]'R[L(jw) -I] I PLH(jw)RL(jw) + SR, 
Vw E R. 
(3.170) 

3.4. Optimality and Robustness 
163 
Proof. We first recall that superscript H means conjugate transpose. 
Then, we consider again the quadratic form (3.168) and compute 
t 
[(l - p)(L * u,”)TR(L * u,”) 
- lo 
- 2(L * u,”)~Ru,” 
+ (1 - S)U,”~RUL] 
dT, 
(3.171) 
using inequality (3.148), the Riccati equation (3.138), and the control u: of 
(3.137). By representing the second integral in the last inequality of (3.171) 
using Parseval’s formula, we can show that it is nonnegative provided in- 
equality (3.170) holds. Then, ~ ( t )  
+ 0 as t 4 00. This fact and stability of 
L implies stability of SL. 
Q.E.D. 
The deeper significance of Theorems 3.38 and 3.39 is that they imply 
the classical robustness properties of the optimal control design: 
3.40. 
fied, then each input channel of the closed-loop system S of (3.163) has: 
COROLLARY. If the condition (3.141) of Theorem 3.32 is satis 
(i) at least 
1 + Je(p - eps + 6) dB 
20 log 
1 - ep 
gain margin; 
(ii) at least 
dB 
1-86 
1 + Je(p - eps + s) 
20 log 
gain reduction tolerance; 
(iii) at least 
8 
f 
C0s-l [ 1 - 5 (p + 6)] deg 
phase margin, where 6 = X,(R)/XM(R). 
(3.172) 
(3.173) 
(3.174) 
Proof. To estimate the gain margin and gain reduction tolerance, we 
consider as usual the nonlinearity +(t, u) channel by channel, that is, 
$(t, u) is described as +(t, u) = [+l(t, ul), 
+z(t, u2), .. . , +m(t, urn)]* and 

164 
3. Optimization 
4i: R x R .+ R. From Theorem 3.38, we find stability of S$ if each compe 
nent c$i(t, ui) of 4(t, u) satisfies the inequality 
V(t, ui) E R x R, 
i E M, (3.175) 
where M = { 1, 2, . . . , m}, or, equivalently, 
V(t, .a) 
E R x R, 
i E M. (3.176) 
This last inequality is solved as 
V(t, ~
i
)
 
E R x R, 
i E M, (3.177) 
so that the left side provides (ii) the gain reduction tolerance, while the 
right side of the inequality gives (i) the gain margin of the ith channel. 
For the linear distortion, we assume that the linear element is described 
by L(s) = diag{Ll(s), Lz(s), 
. . . , LN(s)}. Then, inequality (3.170) is im- 
plied by 
Vw E R, 
i E M. (3.178) 
To estimate the phase margin, we use ILi(jw)I = 1 in (3.178) and get 
(3.179) 
and (iii) follows. 
Q.E.D. 
e 
Re{Li(jw)} 2 1 - z(p+6), 
Vw E R, 
i E M, 

3.5. Decentrally Optimal Systems 
165 
3.41. REMARK. If the matrix R is diagonal, the stability conditions of 
Theorems 3.38 and 3.39 can be written channel by channel in the scalar 
form. Then, inequality (3.148) and, consequently, Corollary 3.40 hold for 
0 = 1, which results in better estimates (2)-(iii) of the robustness proper- 
ties. 
3.42. REMARK. An interesting special case occurs when the nonlinear- 
ity f (t, x ,  u) is independent of the input u and satisfies the inequality 
xTQx - 2xTPf(t, x )  2 axTQx, 
V(t, x )  E R x R", 
(3.180) 
for some positive number a. In this case, condition (3.141) holds for p = 1, 
and if R is diagonal with positive diagonal elements ri, we can replace both 
Xil.r(R) and X,(R) by ~i in (3.178) to have 8 = 1 in (3.172)-(3.174). Then, 
S has: 
(i) infinite gain margin; 
(ii) at least 50% gain reduction tolerance; 
(iii) at least f60" phase margin; 
which are the standard robustness properties of the optimal LQ control 
systems. 
3.43. 
It is more or less obvious that the results of the ro- 
bustness part of this section carry over to the control law modifications 
that were considered in Theorem 3.35. Under the condition (3.158), The- 
orems 3.38 and 3.39 can be rephrased to accommodate the control law 
modification with p = ppP and 6 = p-'6,,, where 6, is a positive number 
such that the matrix apQ-6,,PBR-'BTP is positive definite, and p, a,,, pp 
are positive numbers defined in the proof of Theorem 3.35. 
REMARK. 
3.5. Decentrally Optimal Systems 
We have demonstrated the robustness of suboptimal decentralized LQ 
control for linear interconnected plants. What we want to do now is to 
derive the conditions for optimality of decentralized LQ control when a p  
plied to linear subsystems with nonlinear interconnections. A motivation 
for studying this type of system is the fact that generally the subsystems are 
known to a great extent by the designer, while the essential uncertainty re- 
sides in the interactions among the subsystems. By establishing the global 

166 
3. Optimization 
optimality of the decentralized LQ control, we will be able to apply the 
standard linear robustness measures to the overall nonlinear closed-loop 
system. 
Let us consider a system 
S 
X = ADZ + BDU + fc(t, X, u), 
(3.181) 
which is an interconnection of N linear time-invariant subsystems 
Si: Xi = Aixi+ Biui, 
i E N, 
(3.182) 
where zi(t) E Rni is the state, and ui(t) E Rmi is the input of Si at time 
t E R, and Ai and Bi are constant matrices of appropriate dimensions 
that constitute stabilizable pairs (Ail Bi). In the description of S ,  a new 
element is the function fc: R x R" x R" + R", which describes the inter- 
connections among the subsystems. As usual, we assume that fc(t, x, u) 
is sufficiently smooth so that the solutions x(t) = x(t; to, XO, u) of (3.181) 
exist and are unique for all initial conditions (to, XO) E R x R" and all 
fixed inputs u(.). 
Furthermore, fc(t, 0, 0) = 0, and x = 0 is assumed to be 
the unique equilibrium of S when u(t) = 0. 
An additional assumption in this section is the imposed information 
structure constraint on the control u, 
which is compatible with the subsys- 
tems Si. The constraint restricts the feedback control law to 
U D  = -KDx, 
(3.183) 
where KD = diag(K1, K2, . . . , KN}, and the submatrices Ki are the gains 
of the local state feedback. 
To stabilize the system S using the control law (3.183), we adopt the 
LQ control that is optimal for the decoupled subsystems Si represented as 
So: X = ADX + BDU. 
(3.184) 
This is our standard strategy for control of interconnected systems. With 
SO, we associate a quadratic performance index 
J D ( ~ o ,  50, u) = lom 
(X*QDZ + u ~ R D ~ )  
dt, 
(3.185) 
where QD = diag(Q1, Q 2 , .  . . , Q N }  and RD = diag(R1, R2, . . . , RN} are 
constant , symmetric, and positive definite matrices, with submatrices Qi 
and R, that are compatible with the dimensions of the corresponding sub- 

3.5. Decentrally Optimal Systems 
167 
systems Si. The optimal decentralized control law for S D  is chosen as 
uo 
D - 
- -KDx, 
KD = Ri1B;PD, 
(3.186) 
where the gain matrix KD is computed as usual using the Riccati equation 
Before we consider the optimality of ug for the interconnected system S, 
we note that ug is optimal for SD even when JD is scaled by the weighting 
matrices 
(3.43). 
(3.187) 
DR = diag{dlI,, , d2L2, . . . , dNImN 1, 
where the di's are positive numbers, and Ini and Irni 
are the identity ma- 
trices of order ni and mi, respectively. The scaled index JD is 
and QD = DQQD, RD = DRRD. This is easily seen from the fact that 
&(to, X O ,  u) is a linear combination 
of the subsystem indices 
J,(to, X ~ O ,  
~
i
)
 
= 
( x T Q ~ x ~  
+ uT&u~) dt, 
(3.190) 
where zio E Rni is the initial state of the subsystem Si, and ui E Rmi is 
its input. The corresponding local feedback is chosen as 
Lo- 
u? = -K.x. l ,  
K~=R,-'B;TE, 
(3.191) 
which is optimal for the pair ( S i ,  Ji). In fact, the positive definite solution 
of the Riccati equation 
A',& + &AD - PDBDR,' 
B
~
P
~
 
+ Q D  = 0, 
(3.192) 
for the pair (SD, J D )  is 
PD = DQPD = diag(dlP1, d2P2,. . . , dNPN}, 
(3.193) 

168 
3. Optimization 
and the optimal feedback control ug remains the same after the scaling of 
JD, that is, Ri' BD PD = RE' BE Po. 
Now, to recover optimality of ug on the level of the overall system S, 
we imitate the modification of the performance index introduced in the 
preceding section. We consider the new index 
&(to, 
201 .) 
= lorn 
*c(G 2, .) 
dt, 
(3.194) 
where the function XC: R x R" x R" + R is defined by 
?ic(t, 
2, 
24) = xTQ*2 - ZzTPi&(t, 2, u) + uTR*u, 
(3.195) 
and by a straightforward application of Theorem 3.32 and Remark 3.33, 
we establish: 
3.44. 
the inequality 
THEOREM. If there exist positive numbers di, i E N, 
such that 
?ic(t, 2, U )  2 6'xTx + P'ZL~U, V(t, 2, U )  E R x R" x R", 
(3.196) 
holds for some positive numbers 6' and p', then the decentralized control 
ug is optimal for the pair (S, jc). 
Although inequalities (3.141) and (3.148) are equivalent, in Theorem 3.44 
we used inequality (3.148) because of its easier testability. 
3.45. 
When the system S is linear and fc(t, 
2, u) is replaced 
by Acz, where Ac = (Ail) is a constant block matrix, Theorem 3.44 can be 
considerably simplified (Siljak, 1980; Ikeda and Siljak, 1982). The function 
*c(t, 2, u) becomes 
REMARK. 
*c(t, 2, u) = zTQz + U T R D U ,  
Q = QD - A ~ P D  - P D A ~ ,  
(3.197) 
(3.198) 
where 
and positivity of Q is no longer required. If there exists a positive diagonal 
matrix DQ such that the matrix Q is nonnegative definite and the pair 
(AD + Ac, Q@) is detectable, then the decentralized control ug is optimal 
for the pair (S, &). 

3.5. Decentrally Optimal Systems 
169 
In the context of large-scale systems (Siljak, 1978), it is of interest to 
restate Theorem 3.44 in terms of the decomposition-aggregation framework 
of Section 2.3, as suggested by Ikeda and Siljak (1982). We assume that 
there are nonnegative numbers & and rlij such that the components fi: R x 
R" x R" -+ Rni of the interconnection function fc = (f?, f?, . . . , f;) 
satisfy the inequalities 
T 
N 
IIfi(t, X ,  u)II 5 C (<ijIIxjII +qijIIujII) 7 
j=l 
V(t,,x, u) E R x Rn x R", 
i E N, (3.199) 
where )I -11 denotes the Euclidean norm. 
2 = diag(z1, ZZ, . . . , ZN} as 
We define three N x N aggregate matrices W = (wij), Y = (yij), and 
tAm(Qi) - AM(R)<iir 
i = j ,  
- h 4 ( P z ) < i j ,  
i fj, 
wij = { 
(3.200) 
22 = A"(&). 
Using these matrices, we can get the inequality 
?ic(t, X ,  U )  2 ($', ~ F ) W C ( ? ~ ,  
CT)T, 
V(t, 2, U )  E R x Rn x R", 
(3.201) 
where 
Wc = [ W T D  + DW 
-DY] 
-YTD 
DZ ' 
(3.202) 
and 3 = (11x111, 11x211, " ' 7  
l ~ x N ~ ~ ) T ~  
fi = (I(ulI(, I ( u Z ( l ,  
IIuNll)T. obvi- 
ously, *Ta: = xTx and iiTC = uTu. We also note that the matrix W of 
(3.200) has nonpositive diagonal elements, and the M-matrix conditions of 
Theorem 2.4 can be used to establish positive definiteness of the matrix 
WC. An immediate corollary to Theorem 3.44 is the following: 
3.46. 
If there exists a positive diagonal matrix D such 
that the matrix Wc is positive definite, then the decentralized control law 
ug is optimal for the pair ( S ,  Jc). 
COROLLARY. 

170 
3. Optimization 
3.47. REMARK. The necessary and sufficient condition for the matrix 
WC to be positive definite is 
W ~ D  
+ DW - D Y ( D Z ) - ' Y ~ D  > 0. 
(3.203) 
For (3.203) to hold, W T D  + DW should be positive definite, which in turn 
implies that W E M .  Therefore, to test (3.203) we should first check 
positivity of the leading principal minors of W (see Theorem 2.4) and, if 
they are positive, we should proceed to compute a positive D and then test 
positive definiteness of Wc by checking (3.202). It is more or less obvious 
from (3.202) that if the interconnections fi(t, x, u) are weak and &j and 
q i j  are sufficiently small, then Corollary 3.46 would be satisfied. 
There are several interesting special cases of the interconnection func- 
tion fc(t, x, u). An easy case is when the function is independent of the 
control u, that is, we have fc(t, x). Then, Y = 0 and optimality of the 
control law ug for the pair ( S ,  2,) is guaranteed by W E M .  Another 
case occurs when S is an input-decentralized system (Section 1.5), that is, 
the ith component fi(t, x, ui) of the interconnection function fc depends 
only on the ith component ui of the control u, 
for all i E N. 
In this case, 
Y is diagonal and the left side of (3.203) can be written as 
W ~ D  
+ DW - DY(DZ)-'DY 
= (W - i Y Z - ' Y ) T  D + D (W - zYZ-'Y 
. 
(3.204) 
l
)
 
Using this expression, we get: 
3.48. 
If S is an input-decentralized system and W - 
;YZ-lY E M ,  then the decentralized control law ug is optimal for the 
pair ( S ,  &). 
COROLLARY. 
Finally, we consider again the linear case when fc(t, x, u) = Acz. Then, 
in (3.199), we only need to compute &j = Xz(ATAij) for the matrix W = 
(wij) defined in (3.200). As shown by Ikeda and Siljak (1982), optimality 
of ug is implied by W E M ,  because then Q of (3.198) is positive definite, 
which establishes the required optimality (see Remark 3.45). 
v " 

3.5. Decentrally Optimal Systems 
171 
In the context of decentralized control, the LQ optimality of local feed- 
back control loops implies robustness to variations in open-loop dynamics 
of the subsystems. This fact was first established for linear interconnec- 
tions (Ikeda and Siljak, 1982). The linear restriction has been removed in 
(Ikeda and Siljak, 1985), but the interconnection functions were required 
to depend on time and state only. Here, we remove this last restriction, and 
consider the closed-loop system 
S: j. = (AD - BDR,'B$PD) z + fc (t, z, -R;'B$PDz) , 
(3.205) 
and assume that the nonlinear distortion of u$ has occurred. This fact is 
described by a nonlinear function 4 ~ :  
R x R" 4 RN, which is defined as 
system S becomes 
4 D ( t ,  U )  = [4T(t1 
211)~ @(t, U2)1 ..., &(t, uN)lT7 and 4 D ( t ,  0) 
0. The 
To show robustness, let us introduce the diagonal matrices 
D, = diag{aiIn,, , ~
I n
z
 
, . . . , aNInN}r 
D6 = diag{&I,, , &Ins, . . . , SNI~, 1, 
where the ai's and pi's are positive numbers and the 6i's are nonnegative 
numbers, and assume that these matrices can be taken so that 
iic(t, z, u) 2 zTD,Q~a:+ U ~ D D R D U ,  V(t, z, U )  E R x R" x R", 
D,& 
- Po BD D~ R,' 
B$ pD > 0. 
(3.208) 
The existence of such matrices is obvious by (3.196) of Theorem 3.44. Sim- 
ilarly, as in Theorem 3.38, we obtain: 
3.49. THEOREM. Under the condition (3.208), the equilibrium z = 0 of 
the system S, is globally asymptotically stable for any nonlinear function 
4(t, u) such that 
[4i(t, ui) - uilT R, [4i(t, 
~
i
)
 
- ui] I Pi4T(t, ~ i ) ~ t 4 i ( t ,  
~
i
)
 
+ ~ ~ u T R ~ Q ,  
V(t, U i )  E R x R"a. 
(3.209) 

172 
3. Optimization 
Linear distortions are handled similarly. As in Section 3.4, we introduce 
the matrix LD(s) = diag{ll(s), Lz(s), . . . , LN(s)}, where Li(s) is an mi x 
mi stable transfer function, with the inverse Laplace transform &(t) = 
diag{LI(t), L2(t), . . ., L N ( t ) } .  The linear closed-loop system is described 
bY 
Imitating the proof of Theorem 3.39, we can establish the following: 
3.50. THEOREM. Under the condition (3.208), the equilibrium z = 0 
of the system SL: is globally asymptotically stable for any stable linear 
time-invariant distortion having a transfer function L(s) such that 
With Theorems 3.49 and 3.50 in hand, we can calculate directly the gain 
and phase margin of each input channel using the formulas of Corollary 3.40 
as suggested by Remark 3.41. The numbers ,8, 6, and 0 should be replaced 
by pi, 6i, and &, with Pi and Si being defined by (3.209) and (3.211), and 
The numbers pi and 6i can also be computed in the decomposition- 
aggregation framework of Section 2.3, but the results may be conservative. 
If the computational simplicity of the framework is a deciding factor, then 
we modify the N x N matrices W and Z to get W = (Gij) and 2 = 
diag{zl, 22, . . . , Z N } ,  which are defined as 
02 = L(R?)/hf(&). 
zi = (1 - Pi)Xm(%), 
and form the matrix Wc as Wc of (3.202): 
fit = [ W'D + DW 
-DY] 
-YTD 
DZ 
* 
(3.212) 
(3.2 13) 

3.5. Decentrally Optimal Systems 
173 
Now, stability conditions (3.209) and (3.211) are satisfied by the pos- 
itive numbers ai, pi, and the nonnegative numbers 6i such that W c  is 
nonnegative definite and 
aiQi - 6ipiBiRL'BTpZ > 0. 
(3.2 14) 
An extension of these facts to control law modifications is straightfor- 
ward. We present the results without proofs. Following the approach of 
Ikeda and Siljak (1982), we split the interconnection function as 
fC(t, 2, u) = BDgC(t, 2, u) + hC(t, z), 
(3.2 15) 
where gc = (gy, gF, ..., g g ) ,  gi: R x Rn x R" + R"', 
and hc = 
(h:, h;, . . . , hc)T, hi: R x R" + R"'. We assume that gi(t, z, u) satisfies 
the inequality 
119i(t, 2, .)I1 I 
r,! (1211 + dllull, 
V(t, 2, u) E R x Rn x R", 
(3.216) 
for some positive numbers r,! and 7: such that CEl XM(&)(~:)' 
< 
ELl Am(&). 
The modification of the decentralized control law is similar 
in form to that of the preceding section: 
D - 
- - P,R,'BPDX, 
(3.2 17) 
where p, = diag{p, Zm, , p2 I,, , . . . , pN ImN }, and pi > 1 for ail i E N. 
The performance index is modified accordingly as 
&(to, 20, u) = 
q t ,  2, u)dt, 
(3.2 18) 
LoW 
where %p: R x R" x Rm + R is defined by 
+ z ~ P D B ~ ( ~ ,  
- Z , ) f i ~ ~ B g p ~ a :  
+ u T p, - 1 -  RDU. (3.219) 
3.51. THEOREM. If there exist positive numbers di, i E N, and a 
positive number y' such that 

174 
3. Optimization 
then positive numbers pi can be chosen so that the modified control law 
u; is optimal for the pair ( S ,  j,). 
As in the proof of Theorem 3.35, we first establish the inequality 
?i,(t, 2, U) 2 zT~,Qt,z + uT~&t,u, 
v(t, 2, U )  E R x R" x R ~ ,  
(3.221) 
and then show optimality of uG. 
Again, the interesting case is that of linear interconnections (Ikeda and 
Siljak, 1982) when fc(t, z, u) is replaced by Acz, where Ac = (Aij) is a 
block matrix with blocks represented as 
A , .  
a j  - 
- B.G.. 
a 
a] + H . .  
t ]  > 
(3.222) 
where Gij and Hij are constant matrices of the appropriate dimensions. If 
the splitting is done so that 
Im Bi I 
Im Hij, 
(3.223) 
which is always possible, then the term BiGij can be neutralized by high- 
gain feedback (pi sufficiently large) leaving the matrices Hij (hopefully, 
sufficiently small) for optimality considerations. 
In the context of the system S of (3.181) introduced at the beginning 
of this section, the splitting (3.222) is 
Ac = BDGC + Hc, 
(3.224) 
where Gc = (Gij) and HC = (Hij) are block matrices. In this case, a 
sufficiently large p > 1 can be chosen for ug to be optimal with respect to 
the pair ( S ,  Jt,) if there exists a positive DQ such that the matrix 
Qp = DQQD - H z  Pt, DQ - DQ PB HC 
(3.225) 
is positive definite. 
Positive definiteness of Qp can easily be tested by the decomposition- 
aggregation method (Section 2.2), which we show in the general context of 
nonlinear interactions. We assume that each component hi of the function 
hc satisfies the inequality 

3.5. Decentrally Optimal Systems 
175 
.- 
I 
I 
I 
L 
7 
I 
I I 
Fig. 3.2. Inverted penduli. 
where the -yij are nonnegative numbers. We define the N x N matrix 
W’ = (w&) by 
Then, condition (3.220) holds if W’ E M ,  that is, W’ is an M-matrix, 
which by Theorem 3.51 implies optimality of u& for the pair (S, JD) when 
the gain constant p is chosen sufficiently large. 
3.52. EXAMPLE. To demonstrate the proposed optimization scheme, 
we consider a system of two inverted penduli coupled by a spring. The 
system is shown in Figure 3.2, where the variables are: 
Oi - 
angular displacement of pendulum i, i = 1, 2; 
ri -torque 
input generated by the actuator for pendulum i, i = 
F -spring 
force; 
(3.228) 
q5 -slope 
of the spring to the earth; 
1, 2; 
- 
spring length; 

176 
3. Optimization 
and the constants are: 
l i  -length 
of pendulum i, i = 1, 2; 
-mass 
of pendulum i, i = 1, 2; 
L - 
distance of two penduli; 
k - 
spring constant. 
(3.229) 
The mass of each pendulum is uniformly distributed. The length of the 
spring is chosen so that F = 0 when 81 = 62 = 0, which implies that 
(61, el, 02, &)T = 0 is an equilibrium of the system if 1-1 = 1-2 = 0. For 
simplicity, we assume that the mass of the spring is zero, and restrict the 
movement of the penduli as lei1 < 7r/6, i = 1, 2. 
The equations of motion of the coupled penduli are written as 
(3.230) 
where g is the constant of gravity, and 
F = k (i- [L2 + (l?, - 11)2]1/2) , 
i = [(L + C, sin02 - el sine1)' + (cZ case, - el C O S ~ ~ ) ~ ] ~ / ~ ,  
(3.231) 
el c0s8~ - l2 sin& 
L+C2sin02-t1 sin&' 
4 = tan-' 
We consider each pendulum as one componc 
d 
s: - 
dt 
0 
it, and rewrite (3.230) as 

3.5. Decentrally Optimal Systems 
177 
For the ith decoupled subsystem in (3.232) and the performance index 
(migo: + mid: + T;) dt, 
(3.233) 
we compute the local optimal control, where migo: and mi@ in (3.233) 
are chosen to give a physical meaning to Ji. That is, (1/2)(Ci/2)2migB: 
represents the potential energy and (1/2)(Ci/2)2mid,2 is the kinetic energy, 
for small Oi and d i .  Obviously, the proposed optimization scheme is not 
restricted to this choice of Ji. 
Using the matrices 
(3.234) 
the positive definite solution of the Riccati equation 
A'P, + P,Ai - P,BiRF'B,TP, + Q, = 0, 
(3.235) 
is calculated as 
and we obtain the optimal control law for the ith subsystem as 
Now, we consider optimality of the decentralized control strategy de- 
fined by (3.237) for the overall system S of (3.232). We assume the following 
numerical values: 
11 = l(m), 
C2 = 0.8(m), 
mi = 1(Kg), 
L = 1.2(m), 
k = 0.02(N/m) and 2(N/m); 
m2 = 0.8(Kg), 
(3.238) 
g = 9.8(m/sec2), 

178 
3. Optimization 
and compute the decentralized control law 
9.8 0 
Q i = [  0
1
 1, 
Q 2 =  [ 7r oo8], 
19.901 5.357 
9.857 2.349 
5.357 
1.711 
2.349 0.750 
and the nonlinear term in (3.232) is written as 
0 
9.8(sin61 - 6,) + 2F cos(el - 4) 
0 
9.8(sin 02 - 0,) - 2.5F cos(e2 - 4) 
fC(@ll 62) = 
with 
F = k{[3.08 - 2.4 sine1 + 1.92 sine2 - 1.6 cos(61 - 62)]1/2 
cos el - 0.8 cos O2 
4 = tan-' 1.2 - sin81 + 0.8 sin62 
(3.239) 
(3.240) 
(3.241) 
1.2 17}, 
(3.242) 
We note here that when the nonlinear term fc in (3.181) is independent 
of the input u, 
the condition (3.196) of Theorem 3.44 is reduced to 
xTQDx - 2xTPD fc(t, x) 2 &'ZTZ. 
(3.243) 

3.5. Decentrally Optimal Systems 
179 
We use this fact to show optimality of the decentralized control law of 
(3.239). In the case k = 0.02, we set dl = d2 = 1 and compute 
0 
0 
__________________ 
0 
9.8(sin& - 0,) - 2.5F cos(02 - 4) 
r 5.357(9.811 sin O1 - el I + 21171) 1 
L0.750(9.81 sin02 - e21 + 2.51~1) 
J 
I 
1 
1 
3.118 
-1.067 
-1.366 
-0.171 
-1.067 
1 
-0.265 
0 
-1.366 
-0.265 
i 4.858 
-0.476 
-0.171 
0 
i -0.476 
0.8 
>[pll 
p21 
4 ---____________________ 
- 
- 
> o.05(0: + e:: + e; + e;), 
(3.244) 
where we used the inequalities 
I sinOi - Oil 5 0.04510il, 
(3.245) 
IF[ 5 lc(4.566(811 + 3.87311321), 

180 
3. Optimization 
which hold for [Oil < 7r/6. Thus, the condition (3.243) is satisfied, and the 
decentralized state feedback of (3.239) is the optimal control law for the 
overall system S of (3.232) and the performance index (3.139). In this case, 
as mentioned in Remark (3.42), the resultant closed-loop nonlinear system 
has in each channel: (i) infinite gain margin, (ii) at least 50% gain reduction 
tolerance, and (iii) at least f60" phase margin. 
In the case k = 2(N/m), it can be readily shown that when 3: = (01, 81, 
62, 6
~
)
~
 
= (-7r/9, 1.6, ~ / 9 ,  
-2.1)T, the condition (3.243) does not hold for 
any dl, d2 > 0. This implies that optimality of the decentralized control law 
of (3.239) cannot be restored by modifying only the performance index, and 
an increase of the feedback gains is necessary. Fortunately, in this case, the 
gain increases can eventually restore optimality because the nonlinearity 
fc(61, 62) of (3.241) satisfies the matching condition. To show this fact, we 
write 
0
0
 
4.9(sinOl - 0,) + F cos(O1 - 4) 
3.316(sinO2 - Oz) - 0.8F cos(02 - 4) 
f c ( O 1 , O 2 ) =  [; 
0 3.125 1 [ 
(3.246) 
and note that the nonlinear functions on the right side of (3.246) have finite 
gains with respect to O1 and 02, which are implied by (3.245). Then, the 
condition (3.220) of Theorem 3.51 always holds with h,(t, z) = 0, and by 
increasing the gains p1, pz, the decentralized control 
, 
(3.247) 
becomes optimal for the system S of (3.232) and the performance index j, 
of (3.218). 
3.6. Notes and References 
The suboptimality concept was introduced by Popov (1960) as a per- 
formance deterioration analysis of control systems. Wide classes of con- 
trol systems were subsequently considered by many people (Dorato, 1963; 

3.6. Notes and References 
181 
Durbeck, 1965; Rissanen, 1966; McClamroch and Rissanen, 1967; McClam- 
roch, 1969; Burghart, 1969; Chang and Peng, 1972). Control structure con- 
straints of the output type were introduced in the suboptimality context 
by Kosut (1970). Decentralized constraints in linear autonomous systems 
were considered by Bailey and Ftamapriyan (1973). 
A general approach to suboptimality of nonlinear time-varying systems 
was introduced in (Siljak and Sundareshan, 1976), where the Hamilton- 
Jacobi theory was used to get decentralized connective suboptimality re- 
sults (see also, Siljak, 1978). A stochastic version of the suboptimality con- 
cept, which generalized a number of results and the definition of the concept 
as well, was obtained for the full-blown LQG problem (Krtolica and Siljak, 
1980). Overlapping information structure constraints were solved (Ikeda et 
al. 1981; HodiiC et al. 1983; HodiiC and Siljak, 1986) within the framework 
of the Inclusion Principle (Chapter 8). 
For us, one of the most important implications of suboptimality is the 
robustness in terms of the classical measures of gain and phase margin 
(Sezer and Siljak, 1981a,b). This implication is somewhat surprising since 
the meaning of decentralized suboptimality is quite different from that 
of centralized optimality. Nonlinear distortions of suboptimal control law 
are also tolerated by suboptimal closed-loop systems. This type of results, 
which were presented in Sections 3.1 and 3.3, increase considerably our 
confidence in suboptimal decentralized control. 
If we are willing to modify the performance index, then we can recover 
global optimality from locally optimal LQ control subsystems (Ozguner, 
1975). This we can do even if the interconnections are nonlinear (Siljak, 
1979, 1980). To broaden the class of potentially optimal decentralized con- 
trol systems, we have to allow for modifications of the control laws as well 
(Ikeda and Siljak, 1982; Ikeda et al. 1983; Yasuda, 1986). This is the inverse 
optimal problem of decentralized control which we solved in Sections 3.4 and 
3.5 following (Ikeda and Siljak, 1985, 1990). Other solutions can be found 
in (Ikeda and Siljak, 1982; Young, 1985; Zheng, 1986; Saberi, 1988; Yang 
et al. 1989). 
A very important and useful area of research is the parametric opti- 
mization framework for design of decentralized control laws. Initial results 
were obtained by Levine and Athans (1970) for the output control con- 
straints. Similar methods were used by Geromel and Bernussou (1982) to 
get the best available decentralized control laws. An interesting applica- 
tion of these results to interconnected power systems was described by 
Gopal and Ghodekar (1985). Of special value is the work of Friedlander 
(1985), because he proposed to compute the parameters of decentralized 
controllers using only the locally available information; the communica- 
tion requirements between subsystems are minimized in a significant way. 

182 
3. Optimization 
A comprehensive survey of parameter optimization methods for design of 
decentralized controllers is available in (Geromel and Bernussou, 1987). In 
the context of this chapter, these methods can be used to improve subopti- 
mality of locally optimal LQ control laws; feedback gains can be adjusted 
by gradient algorithms to get the best results. 
Finally, we should comment on the hierarchical control of large-scale 
systems initiated by MesaroviC et al. (1970), and developed by many pee 
ple (see the books by Findeisen et al. 1980; Singh, 1980; and Jamshidi, 
1983; and the recent surveys by Haimes and Li, 1988; and Malinowski, 
1989). The concept is a type of decentralized optimization scheme, where 
a coordinating (centralized) control is introduced to ensure that the local 
controls are properly modified to result in an overall optimal system. De- 
fined in this way, the concept is a mixture of decentralized and centralized 
optimal control, which is hard to justify on both accounts. No one knows 
if the limitations of the hierarchical schemes can be removed by develop 
ing better design procedures, or if these limitations can be attributed to 
the lack of a suitable axiomatic definition of the optimization problem. 
Simply speaking, it has never been clearly demonstrated under reasonable 
assumptions that hierarchical control is superior to centralized or decen- 
tralized alternatives. We regard hierarchical control as a problem for the 
future and shall not consider it here. 
Bibliography 
Anderson, B. D. O., and J. B. Moore (1971). Linear Optimal Control, Prentice-Hall, 
Englewood Cliffs, New Jersey. 
Arrow, K. J., and F. H. Hahn (1971). General Competitive Analysis. Holden-Day, San 
Fkancisco, California. 
Bailey, F. N., and H. K. Ramapriyan (1973). Bounds on suboptimality in the control of 
linear dynamic systems. IEEE Transactions, AC-18, 532-534. 
Bode, H. W. (1945). Network Analysis and Feedback Amplifier Design. Van Nostrand, 
New York. 
Burghart, J. H. (1969). A technique for suboptimal feedback control of nonlinear systems. 
IEEE Transactzons, AC-14, 530-533. 
Chang, S. S. L., and T. K. C. Peng (1972). Adaptive guaranteed cost control of systems 
with uncertain parameters. IEEE Transactions, AC-17, 474-483. 
Davison, E. J. (1974). The decentralized stabilization and control of a class of unknown 
nonlinear time-varying systems. Automatica, 10, 309-316. 
Dorato, P. (1963). On sensitivity of optimal control systems. IEEE Transactions, AC-8, 
25G-257. 
Durbeck, R. (1965). An approximation technique for suboptimal control. IEEE 'Trans- 
actions, AC-10, 144-149. 
Findeisen, W., F. N. Bailey, M. Brdy6, K. Malinowski, P. Tatjewski, and A. Woiniak 
(1980). Control and Coordination in Hierarchical Systems. John Wiley, New York. 

Bibliography 
183 
Friedlander, B. (1985). Decentralized design of decentralized controllers. Control and 
Dynamic Systems, C. T. Leondes (ed.), Academic Press, New York, 22, 165-194. 
Geromel, J. C., and J. Bernussou (1982). Optimal decentralized control of dynamic 
systems. Automatica, 18, 545-557. 
Geromel, J. C., and J. Bernussou (1987). Structure-constrained control: Parametric o p  
timization. Systems and Control Encyclopedia, M. G. Singh (ed.), Pergamon Press, 
Oxford, UK, 4678-4685. 
Gopal, M., and J. G. Ghodekar (1985). On decentralized controllers for interconnected 
power systems. International Journal of Systems Science, 16, 1391-1407. 
Haimes, Y. Y., 
and D. Li (1988). Hierarchical multiobjective analysis for large-scale 
systems: Review and current status. Automatica, 24, 5349. 
HodiiC, M., and D. D. Siljak (1986). Decentralized estimation and control with overlap 
ping information sets. IEEE Transactions, AC-31, 83-86. 
HodiiC, M., R. Krtolica, and D. D. Siljak (1983). A stochastic inclusion principle. Pro- 
ceedings of the 22nd IEEE Conference on Decisaon and Control, San Antonio, Texas, 
Ikeda, M., and D. D. Siljak (1982). When is a linear decentralized control optimal? Anal- 
ysis and Optimization of Systems, A. Bensoussan and J. L. Lions (eds.), Springer, 
Berlin, FRG, 41S431. 
Ikeda, M., and D. D. Siljak (1985). On optimality and robustness of LQ regulators for 
nonlinear and interconnected systems. Proceedings of the IFA C Workshop on Model 
Error Concepts and Compensations, Boston, Massachusetts, 77-82. 
Ikeda, M., and D. D. Siljak (1990). Optimality and robustness of linearquadratic control 
for nonlinear systems. Automatica, 26, 499-511. 
Ikeda, M., 0. Umefuji, and S. Kodama (1976). Stabilization of large-scale linear systems. 
Systems, Computers, and Control, 7, 34-41. 
Ikeda, M., D. D. Siljak, and D. E. White (1981). Decentralized control with overlapping 
information sets. Journal of Optimization Theory and Applications, 34, 279-310. 
Ikeda, M., D. D. Siljak, and K. Yasuda (1983). Optimality of decentralized control for 
large-scale systems. Automatica, 19, 309-316. 
Jamshidi, M. (1983). Large-Scale Systems: Modeling and Control. North-Holland, Am- 
sterdam, The Nederlands. 
Kalman, R. E. (1960). Contributions to the theory of optimal control. Boletin de la 
Sociedad Matematica Mexicana, 5, 102-119. 
Kalman, R. E. (1964). When is a linear control system optimal? Transactions of ASME, 
Journal of Basic Engineering, 86, 1-10, 
Kalman, R. E., and J. E. Bertram (1960). Control system analysis and design via the 
"Second Method" of Lyapunov. Transactions of ASME, Journal of Basic Engineer- 
ing, 82, Part I: 371-393; Part 11: 394-400. 
Kosut, R. L. (1970). Suboptimal control of linear time-invariant systems subject to 
control structure constraints. IEEE Transactions, AC-15, 557-563. 
Krtolica, R., and D. D. Siljak (1980). Suboptimality of decentralized stochastic control 
and estimation. IEEE Transactions, AC-25, 76-83. 
hitmann, G. (1979). Guaranteed asymptotic stability for some linear systems with 
bounded uncertainties. Transactions of ASME, Journal of Dynamic Systems, Mea- 
surements, and Control, 101, 212-216. 
Levine, W. S., and M. Athans (1970). On the determination of the optimal constant 
output feedback gains for linear multivariable systems. IEEE Transactions, AC-15, 
17-22. 
44-48. 

184 
3. Optimization 
Malinowski, K. (1989). Hierarchical control under uncertainty. Preprints of the 5th 
IFAC/IFORS Symposium on Large Scale Systems, Berlin, DDR. 
Mm, C. J., and W. S. Lin (1990). Decentralized control of interconnected systems with 
unmodeled nonlinearity and interaction. Automatica, 26, 263-268. 
McClamroch, N. H. (1969). Evaluation of suboptimality and sensitivity of control and 
filtering processes. IEEE Transactions, AC-13, 282-285. 
McClamroch, N. H., and 3. Rissanen (1967). A result on the performance deterioration 
of optimum systems. IEEE Transactions, AC-12, 209-210. 
MesaroviC, M. D., D. Macko, and Y. Takahara (1970). Theory ofHierarchica1, Multilevel, 
Systems. Academic Press, New York. 
Ozgiiner, U. (1975). Local optimization in large scale composite dynamic systems. Pro- 
ceedings of the 9th Asilomar Conference on Circuits, Systems, and Computers, 
Pacific Grove, California, 87-91. 
Popov, V. M. (1960). Criterion of quality for nonlinear systems. Proceedings of the 5th 
IFAC World Congress, Moscow, USSR, 173-176. 
Rissanen, J. J. (1966). Performance deterioration of optimum systems. IEEE Transac- 
tions, AC-11, 530-532. 
Saberi, A. (1988). On optimality of decentralized control for a class of nonlinear inter- 
connected systems. Automatica, 24, 101-104. 
Saberi, A,, and H. Khalil (1982). Decentralized stabilization of a class of non-linear 
interconnected systems. International Journal of Control, 36, 803-818. 
Safonov, M. G. (1980). Stability and Robustness of Multivariable Feedback Systems, MIT 
Press, Boston,,,Massachusetts. 
Sezer, M. E., and 0. Huseyin (1978). Stabilization of linear interconnected systems using 
local state feedback. IEEE Transactions, SMC-8, 751-756. 
Sezer, M. E., and D. D. Siljak (1981a). Robustness of suboptimal control: Gain and 
phase margin. IEEE Transactions, AC-26, 907-911. 
Sezer, M. E., and D. D. Siljak (1981b). Sensitivity of large-scale control systems. Journal 
of the Franklin Institute, 312, 179-197. 
Siljak, D. D. (1978). Large-Scale Dynamic Systems; Stabality and Structzlre. North- 
Holland, New York. 
Siljak, D. D. (1979). Overlapping decentralized control. Large Scale Systems Engineering 
Applications, M. G. Singh and A. Titli (eds.), North-Holland, Amsterdam, Holland, 
Siljak, D. D. (1980). Reliable control using multiple control systems. International Jour- 
nat of Control, 31, 30g339. 
Siljak, D. D. (1987). Interconnected systems: Decentralized control. Systems and Control 
Encyclopedia, M. G. Singh (ed.), Pergamon Press, Oxford, UK, 2557-2560. 
Siljak, D. D. (1988). Parameter space methods for robust control design: A guided tour. 
IEEE Transactions, AC-34, 674488. 
Siljak, D. D., and M. K. Sundareshan (1976). A multilevel optimization of large-scale 
dynamic systems. IEEE Transactions, AC-21, 79-84. 
Sinai, M. (1986). Suboptimality bounds on decentralized control and estimation of large- 
scale discrete-time linear systems. Control and Dynamic Systems, C. T. Leondes 
(ed.), 24, 67-103. 
Singh, M. G. (1980). Dynamical Hierarchical Control. North-Holland, Amsterdam, The 
Netherlands. 
Thaler, G. J., and R. G. Brown (1960). Analysis and Design of Feedback Control Sys- 
tems. McGraw-Hill, New York. 
145-166. 

Bibliography 
185 
Wonham, W. M. (1968). On a matrix Riccati equation of stochastic control. S A M  
Journal of Control, 6, 681497. 
Wonham, W. M. (1979). Linear Multivariable Control: A Geometric Approach. Springer, 
New York. 
Yang, T. C., N. Munro, and A. Brameller (1989). Improved condition for the optimality 
of decentralized control for large-scale systems. IEE Proceedings, 136-D, 44-46. 
Yasuda, K. (1986). Decentralized optimal control for largescale interconnected systems. 
Control and Dynamic Systems, C .  T. Leondes (ed.), 
Academic Press, New York, 23, 
13S-163. 
Yasuda, K., T. Hikata, and K. Hirai (1980). On decentrally optimizable interconnected 
systems. Proceedings of the 19th IEEE Conference on Decision and Control, Albu- 
querque, New Mexico, 536-537. 
Young, K. D. (1985). On near optimal decentralized control. Automatica, 21, 607410. 
Zheng, D. Z. (1986). Optimization of linearquadratic regulator systems in the presence 
of parameter perturbations. IEEE Transactions, AC-31, 667470. 

Estimation and Control 
Chapter 
1 
Our ability to control an interconnected system by decentralized state 
feedback depends crucially upon the availability of states at each subsys- 
tem. In most practical cases, the states of subsystems are not accessible 
as outputs, and we have to solve the problem of state determination in 
complex systems. The important part of the problem is the constraint that 
the state determination be carried out decentrally; we want to build a de- 
centralized asymptotic observer. In this way, we can provide an observer 
for each subsystem, which makes states available locally to each individual 
controller. 
For a union of subsystem observers to represent an asymptotic observer 
for the overall system, the interconnections among the subsystems should 
appear as inputs to the observers. It is comforting to note that this does 
not mean that the interconnections need to be read as outputs. Such an as- 
sumption would be unrealistic, because the interconnections are almost al- 
ways inaccessible variables inside the plant. We can use the state estimates 
instead and construct the necessary inputs. Unfortunately, this means that 
the observers have to exchange their estimates, thus requiring an excessive 
data communication between the subsystems. This is the first problem we 
must come to grips with in building decentralized regulators for complex 
plants. 
An observer is acceptable only if it is asymptotically stable. At this 
point in our exposition, we do not expect stabilizability of a decentral- 
ized observer to be straightforward. We are glad to find, however, that the 
stabilization problem can be solved via “duality” by the methods of Chap 
ter 2. The decentrally stabilizable structures will reappear in a dual form, 
and high-gain feedback will again be used to make sure that the overall 
observer is asymptotically stable. Most importantly, the decentralized ob- 
server and controller can be designed independently of each other. This is 
186 

4.1. An Interconnected Observer 
187 
the so-called separation property, which has an added significance in solv- 
ing difficult control problems involving decentralized information structure 
constraints. 
In the second part of this chapter, we shall consider the stochastic de- 
centralized control and present a decentralized version of the well-known 
Linear-Quadratic-Gaussian 
(LQG) design. The optimal control strategies 
in this context have been much talked about, but very little has been ac- 
complished. We take a pragmatic approach to this problem, and develop 
suboptimal control laws, which are stochastic versions of the laws obtained 
in the preceding chapter. Actually, this is a rewarding path to take, because 
we are trading the futile optimality quest for the robzlstness of suboptimal 
control laws to a wide variety of parametric (structural) perturbations. 
4.1. An Interconnected Observer 
Our first task is to show how to determine the state of an intercon- 
nected system by building only local observers for the subsystems. Each 
observer produces a state estimate of the subsystem it is attached to, and 
the question arises: When does the union of the local estimates constitute 
an estimate of the overall system? At the time this problem was introduced 
(Siljak and VukEeviC, 1976), it was expected that the design of decentral- 
ized observers is a natural counterpart to the design of the controllers using 
decentralized state feedback. It turned out, however, that to build local 
observers one has to allow for an exchange of state estimates among the 
observers. The exchange is necessary for the separation principle to hold, so 
that one can design the observers independently of the controllers that use 
the estimated states for stabilization purposes. The obvious concern is that 
the exchange of estimates among the subsystems may be costly when, for 
example, the controllers are distributed geographically in mutually distant 
areas. On the other .hand, when decentralized observers are used to sim- 
plify the computations or speed up the observation process using a parallel 
processing scheme, the exchange is not a dominating factor. Furthermore, 
the exchange can be removed altogether by giving up the separation prop 
erty. We start our exposition of decentralized state determination with the 
basic result of Siljak and VukEevik (1976), which requires only the standard 
observer theory (e.g., O’Reilly, 1983). 
Let us consider a linear time invariant system 
yi = taxi, 
i E N, 

188 
4. Estimation and Control 
which is an interconnection of N subsystems 
Si: Xi = A i ~ i  + B ~ u ,  
( 4 4  
yi = cixi, 
i E N, 
where, as usual, zi(t) E Rni is the state, yi(t) E Rei is the output of Si 
and u(t) E R" is the input of S at time t E T. 
In order to estimate the states zi(t), we assume that all pairs (Ai, Ci) 
are observable and build an observer 
i E N, (4.3) 
where 
- 
(4.4) 
A,. - A,. - L..C. 
Ai = Ai - LiCi, 
%.I 
- v 
2.1 
.I 7 
and the gain matrices Li and Lij have appropriate dimensions. 
For the errors in estimation 
hi = xi - P i ,  
i E N, 
(4.5) 
we get the equations 
N 
S: $. 
a -  - A.5. 
a
a
 +C Aijhj, 
i E N. 
(4.6) 
j=1 
To obtain an asymptotic observer from (4.6), we stabilize the dual of S ,  
which is described as 
N 
S*: $i = AThi + C A:Zj, 
i E N. 
(4.7) 
j=1 
Using (4.4), we get S* as 
N 
S*: ki = (AT - C,TLT)hi + C (A: - C,TLjTi)Zj, 
i E N. 
(4.8) 
j=l 
Stabilization of S* can proceed by applying the decentralized scheme of 
Section 2.4. We assume that the pairs (Ai, Ci) are observable, which implies 
that the pairs (AT, C?) are controllable. Then, we can place the eigenvalues 

4.1. An Interconnected Observer 
189 
of AT = AT - CFLT at desired locations by a choice of local gain Li. The 
global gains Lij are selected to minimize the influence of the interactions 
Aij wherever appropriate. Finally, stability of the overall closed-loop system 
S* is tested using the method of vector Liapunov functions. This recipe is 
described first. 
For ease of presentation, we use our standard compact form for S: 
S: j. = ADX + BU + ACX, 
!/ = C O X ,  
(4.9) 
which represents an output-decentralized system, that is, CD = diag(C1 , 
Cz, . . . , CN}. The form of the matrix B is not essential. The interconnected 
observer is 
S: i = A& + LD(Y - Cog) + BU + AcP + Lc(y - CgP), (4.10) 
where 
LD = diag(L1, Lz, . . . , LN}, 
Lc = (Lij), 
(4.11) 
are constant feedback matrices with blocks Li and Lij having appropriate 
dimensions. 
The observation error 
Z = X - P  
(4.12) 
is described by the error system 
-
.
 
S: 5 = (AD - LDCD)Z + (Ac - LcCD)~. 
(4.13) 
For S to be an asymptotic observer, we require that S is globally asymp 
totically stable, that is, 
Z ( t )  ’0, 
as t-t+oo. 
(4.14) 
This may not be completely satisfactory, and we want to say something 
about the speed of (4.14). 
4.1. DEFINITION. 
K for a system S if there exist two positive numbers ll and K such that 
A system S is an exponential observer with degree 
Il w; 
t o ,  .o)ll 
I nllxoll “XPI-dt - t o ) ]  , 
vt E To, 
V(t0, XO) E T x R”, 
(4.15) 
where Z(t; to, 20) is a solution of the system S .  

190 
4. Estimation and Control 
What we want is to find the feedback gains LD and Lc so that (4.15) 
holds for a sufficiently large value of IT. We show first how to do this when 
Lc = 0 and only local feedback gains Lo are used. That is, we consider 
stabilization of 
S*: h = (AT, - CzLT,)Z + AZ5. 
(4.16) 
For LD, we choose 
Lo = SDC;, 
(4.17) 
where SD = diag{S1, 5'2, . . . , SN} is the symmetric positive definite solu- 
tion of the Riccati equation 
(AD + ~ 1 ) s ~  
+ SD(AD + I T I ) ~  
- SDC~CDSD 
+ QD = 0, 
(4.18) 
and QD = diag{Ql, Q2, . . . , QN} is a symmetric nonnegative definite ma- 
trix. 
4.2. THEOREM. A system 
S: $ = AD? + LD(Y - CD?) + BU + Ac? 
(4.19) 
is an exponential observer with degree IT for the system S if 
(4.20) 
Proof. We select the function v: R" + R+ defined as 
to be a candidate for the Liapunov function of the system S*. As usual, we 
calculate 
5 -~ITv(Z), 
V(t, Z) E T x R", 
(4.22) 

4.1. An Interconnected Observer 
191 
using condition (4.20) of the theorem. The last inequality in (4.22) implies 
(4.15) with II = XZ(SD)X-'/*(SD). 
Q.E.D. 
If the interconnections are not sufficiently small, the condition (4.20) is 
not satisfied, and the observer S of (4.19) is useless. A way to make the ob- 
server S work in this case is to use the global control concept of Siljak and 
VukEeviC (1976). Then, instead of the size limitation, the interconnection 
matrix Ac and the output matrix CD are required to satisfy a rank condi- 
tion that makes the perfect neutralization of the interconnections possible. 
4.3. THEOREM. Suppose that 
(i) Im CD = Re; 
(4.23) 
(2) Im 
3 Im A$ 
Then the system 
A
.
 
S: 2 = A o i  + LD(Y - C D ~ )  
+ BU + Ac2 + Lc(y - C D ~ ) ,  (4.24) 
with Lc = ACCS(C~CE)-~, 
is an exponential observer with degree T for 
the system S. 
Proof. The error system is S of (4.13). From the proof of Theorem 4.2, it 
is clear that S is exponentially stable with degree T if the second term (Ac- 
LcCD)I in (4.13) is zero. From the condition (i) of the theorem, it follows 
that CD has full row rank and has the right inverse C$ = Cz(C&$)-'. 
This fact and (ii) imply that Ac can be factored as Ac = L&D, with Lc 
as defined in the theorem. 
Q.E.D. 
4.4. REMARK. Although global feedback in the observation scheme 
(4.23) neutralized the interconnection terms, the price may be too high 
because the local observers have to exchange the observed state 2. The 
price would be reduced if we could use the output y instead of the state 2. 
This possibility is presented by the observation scheme 
S: 
= AD? + BU + LD(Y - C D ~ )  
+ LCY 
(4.25) 
for the system S of (4.9). Then, the observation error I = x-2 is described 
S: I = (AD - L D C D ) ~  
+ (Ac - L c C D ) ~ .  
(4.26) 
bY 
-
.
 

192 
4. Estimation and Control 
Under the conditions (2)-(ii) of Theorem 4.3, the term ( A c  - LcC0)z 
would vanish, and S of (4.25) is an exponential observer for S .  It is crucial, 
however, to recognize the fact that the observer S of (4.25) is not robust 
if the state z(t) of S is not properly bounded, since an imperfection in 
the cancellation of the term Acx by the global output feedback Lcy could 
cause the error system S of (4.26) to blow up. One way to fix this is to 
consider the estimation and control design as a joint problem, as we show 
in Section 4.4. 
4.2. Decentralized Feedback 
Even if global feedback is applied to reduce the size of interconnections, 
the union of local observers may not be an asymptotic observer for the 
overall system, unless the interconnections are completely neutralized. It 
is, therefore, natural to delineate a class of systems for which interconnected 
observers can always be built using only decentralized feedback. This is a 
dual to the problem of decentrally stabilizable composite systems treated in 
Section 2.4, and we are prepared to surrender the generality of the system 
description for the assured success in building an interconnected observer , 
even though it may involve a high-gain feedback (siljak and VukCeviC, 
1978). 
The interconnected system 
T 
yi 
ci xi, 
i E N, 
is a special case of S described by (4.1), because each subsystem Si has 
a single output yi E R, and c, E R"' is a constant vector. We assume 
that all the pairs (Ail G) are observable, which allows us to further assume 
without loss of generality that the subsystem matrices Ai and ci have the 
following form: 
................... 
l o  0 ... 1 -a;, 

4.2. Decentralized Feedback 
193 
The crucial assumption is that the interconnection matrices A, = (u;) 
are such that 
a; 
= O ,  
p >  9, 
p E Ni, 
9 E Nj, 
(4.29) 
where Ni = (1, 2, . . . , ni} and Nj = (1, 2, . . . , nj}. These are the struc- 
tural constraints on the interconnections, which make the local stabilization 
possible. 
To construct an interconnected estimator for the system S of (4.27) that 
uses decentralized feedback only, we need the following: 
4.5. THEOREM. 
ways be selected so that the system 
Given a system S, the local feedback gains l i  can al- 
N 
-
.
 
S: 2. 
a - 
- A.2. 
a 
a +[. aya . + B i . ~ + x  
Aij?j, 
i E N, 
(4.30) 
j=1 
is an asymptotic observer for S. 
Proof. The observation error is described by the dual system 
N 
S*: ii = (A: - c&") 2i +C A&, 
i E N. 
(4.31) 
Each gain l i  can be chosen for the matrix AT -& to have a set of distinct 
real eigenvalues 
j=1 
Li = (Xi: X i  =poi, 
p 2 1, 
0; > 0, 
'dk E N), 
(4.32) 
for any specified value of p. What we want to show is that by choosing a 
sufficiently large p, we can make the error system S exponentially stable 
for a given 7 ~ .  
Applying the nonsingular transformation 
(4.33) 

194 
4. Estimation and Control 
with A, in the diagonal form 
Ai = diag{ -puf, -PI$,, . . . , - p h i  }. 
The transformation matrix Ti can be factored as 
T, =&Z, 
with the factors 
& = diag{l, p, . . . , p"'-'} 
and the Vandermonde matrix 
(4.36) 
(4.37) 
(4.38) 
(4.39) 
1 
... 
1 
... 
Ti = 
... 
With this modification, each error subsystem 
S*, 5. -A,-. 
2 - 2x2 
has a degree of exponential stability 
where 
As in Section 2.5, we choose the Liapunov function 
and 
Gi = 2 diag{pai, pa, . . . , pubi}, 
Hi = Ii. 
(4.40) 
(4.41) 
(4.42) 
(4.43) 
(4.44) 
(4.45) 

4.2. Decentralized Feedback 
195 
Using the function 
N 
(4.46) 
i= 1 
as a Liapunov function for the system S* with the state a: = (ZT, 
3$, 
. . . , %',)', 
we get the N x N aggregate matrix W = (wij) defined by 
- 
i = j ,  
i Z j ,  
(4.47) 
where 
f i j  = X$2(AjiA?J 
(4.48) 
and 
Aji = T;'R;~A;R~?. 
(4.49) 
Now, we note that the diagonal elements Wii = +pi depend linearly 
on the adjustable parameter p .  The off-diagonal elements wij = & j ( p ) ,  
however, are bounded functions of p .  The elements p"-'Jag of the matrices 
l&A;Rj are either zero for p > q due to the assumption (4.291, or they are 
bounded for p I 
q due to nonpositive powers of p .  Therefore, we have 
lim Ril 
A; Rj = Dij, 
(4.50) 
p++M 
where the ni x nj matrix Dij = ( d z )  is defined by 
From (4.49) and (4.50), we define 
and conclude that 
(4.51) 
(4.52) 
(4.53) 

196 
4. Estimation and Control 
j=1 
I 
Y 
T 
I 
Aijij 
I N  
j=1 
Fig. 4.1. Subsystem with observer. 
which implies that the off-diagonal elements wij of the matrix W are 
bounded in p. Therefore, we can always choose local gain vectors ti to 
make W an M-matrix. This implies stability of S' and, thus, S*, via T h e  
orem 2.5. 
Q.E.D. 
The final form of the interconnected observer corresponding to the sys- 
tem S of (4.27) is given as 
The block diagram of the ith subsystem Si and its observer Si are shown in 
Figure 4.1. We note that Si has as input the observed states from all other 
local observers, which prevents S from being a fully decentralized observer 
for S. We shall address this question in Section 4.4. At present, we illustrate 
the design of interconnected observers using the following example. 

4.2. DecentraIized Feedback 
197 
4.6. EXAMPLE. Let us consider the interconnected system 
(4.55) 
2
3
2
 
0 -3 
x 2 =  [ 
-2] 
X 2 + B 2 U +  [ 
l] 21, 
y1 = [ O  0 11 21, 
y 2  = [ O  11 2 2 .  
The open-loop (dual) error system (el = 0, l 2  = 0) is described by the 
equations 
0
1
 
2
0
 
-2 
-1 
-1 
(4.56) 
4
0
0
 
-3 
-2 
5
6
0
 
The eigenvalues of the two decoupled subsystems are 
A; = 1.3532, 
= 0.1766 fj1.2028, 
(4.57) 
A;,, 
= -1 f j1.4142. 
By using the feedback gains 
e: = (4, 10, 5), 
e; = (-1, l), 
(4.58) 
we relocate the eigenvalues (4.57) to the new locations 
where we have used p = 1. 

198 
4. Estimation and Control 
We construct the transformation matrices R1, R2, TI, and T2 for p > 1 
as 
1
0
0
 
1
1
 
(4.60) 
T2= [ 
-1 
-2 '1. 
The numbers r1 and rz are both set at 1. Then, the aggregate matrix I@ 
defined by (4.47) is 
1, 
P 
-1;2(P) 
w =  [ 
- f 2 1 ( P )  
P 
which for p = 1 takes the form 
1 
-17.0011 
W =  [ - 12.2936 
1 
(4.61) 
(4.62) 
where (12 and (21 are computed from 
and AT2 and ATl are defined in (4.56). 
we have to try a higher value of p. From (4.50) and (4.56), we find that 
It is obvious that the test matrix W of (4.62) is not an M-matrix, and 
and, for p > 15, we get & N 32.55, f 2 l  N 18.98. Thus, for p = 25, we get 
l 7  
25 
-32.55 
w =  [ 
-18.98 
25 
(4.65) 

4.3. Separation Property 
199 
which is an M-matrix, and the observer is stable. The eigenvalues of the 
overall closed-loop system S are 
A: = -36.0364, 
A2,3 = -25.9599 f 
j3.5219, 
(4.66) 
X4,5 = -68.5213 f 
j6.0474. 
For the chosen value of p = 25, we have the subsystem eigenvalue sets 
L1 and C2 of (4.32) as 
C1 = {A: = -25, A; = -50, A; = -75}, 
Cz = {A: = -25, A$ = -50). 
(4.67) 
The local gains which produce C1 and Cz are 
l: = (93748, 6874, 149), 
i?; = (1247, 73), 
(4.68) 
which completes the design of the interconnected observer for the system 
s of (4.55). 
4.7. REMARK. We note that the local gains (4.68) are relatively high. 
This is expected, as the local feedback needs to stabilize the observer and, 
at the same time, neutralize the effect of interconnections. By using the 
global feedback, the local gains could be reduced considerably. 
4.8. REMARK. 
The single-output assumption in system S of (4.27) can 
be removed along the lines outlined in Example 2.25. Furthermore, we pre- 
sented only full-order observation schemes. It is relatively straightforward 
to broaden the schemes to include subsystem observers of minimal dimen- 
sions using the standard observer theory (e.g., O’Reilly, 1983). 
4.3. Separation Property 
When an observer is used to provide the state for the control laws, 
the basic question is how to combine a solution of the estimation problem 
with a solution of the control problem that assumes that the states (not 
estimates of the states) are known. In the classical control theory this fact 
does not cause any difficulty, because it is well-known (e.g., Kailath, 1980) 

200 
4. Estimation and Control 
that the observer and the controller can be designed independently of each 
other. This is the so-called separation property of the observer-controller 
(or regulator) design recognized first by Luenberger (1964). 
In the context of complex systems, the separation property has been e s  
tablished for the decentralized observers-controllers design under the con- 
dition that observers exchange the observed states (Siljak and VukEevid, 
1976). As a final product, we obtain a decentralized regulator for each sub- 
system separately. The significance of this fact is that we can build decen- 
tralized regulators "piece-by-piece" for complex systems such as electric 
power systems, chemical plants, etc., using multiprocessors in a parallel 
computing scheme with great advantages of size, speed, robustness, and 
cost. 
In controlling a plant represented by the system S of (4.9), we want to 
use a decentralized feedback. We assume that the system is in the input 
decentralized form, that is, the input matrix B is a block diagonal matrix 
BD = diag(B1, Bz, . . . , BN}. Thus, 
S: j. = ADX + BDU + ACX, 
(4.69) 
y = COX. 
The crucial fact, however, is that in controlling the plant S ,  instead of 
the control law u(t) E R"' defined as 
u = r - K D X ,  
(4.70) 
we want to use the control law 
u = T - K D ~ ,  
(4.71) 
where the true (unavailable) state x(t) E R" of S is replaced by the esti- 
mated state h(t) E R" generated by the observer 
and r(t) E R" is the reference input of S .  For simplicity, we decide not 
to use the global feedback in the systems S and S; it does not affect the 
separation property anyway. Applying the control (4.71) to S, we get 
s: k = ADX - B D K D ~  
+ A@ + B D r ,  
(4.73) 
y = COX. 

4.4. Decentralized Observer 
201 
The joint closed-loop system is 
By applying the nonsingular transformation 
I
0
 
[:I 
= [ I  -11 [;I' 
(4.75) 
we get the joint system, which involves the closed-loop system S and the 
error system S ,  
] [;I.[:] ', 
AD - BDKD + Ac 
0 
BD KD 
AD - LDCD + Ac 
S&S: [;] 
= [ 
(4.76) 
which can be split into two independent systems. Therefore, the controller 
and observer can be designed independently of each other, and the sepa- 
ration property is established. Both designs can be carried out using the 
stabilization methods of Chapters 2 and 3, which is the most important 
consequence of the separation property in the context of decentralized reg- 
ulator theory. 
4.4. Decentralized Observer 
In certain applications, the exchange of the observed states among the 
subsystem observers may cause prohibitive communication costs as well 
as a degradation of the system performance due to transmission delays 
of relevant data between various parts of the system. As pointed out in 
Remark 4.4, it is possible to remove the exchange altogether if we are 
willing to surrender the separation property and build jointly the controller 
and the observer for the overall system. In this section, we consider the n e  
exchange alternative and show how the results in decentralized stabilization 
of Chapter 2 can be carried over to the decentralized observer problem. 
We consider again the output-decentralized system S of (4.9) and use 
the observer S of (4.19) without the term Aci, that is, 

202 
4. Estimation and Control 
The observed state P obtained locally by SD is used in the control law (4.71) 
to control the system S of (4.9). This produces the closed-loop system S 
and the observer SD as 
9: k = ADX - BDKDP + Acx + BDr, 
which can be rewritten as a single joint system 
Using the same transformation (4.77), we get 
-BDKD ] [ :] 
, 
(4.80) 
AD - BDKD + Ac 
S & S :  [;] 
= [ 
Ac 
AD - LDCD 
which cannot be split into two independent systems S and S, and the 
separation property does not hold. For the system SD to be an asymptotic 
observer for S ,  the joint system S & S  should be asymptotically stable. 
Stability of S & S ,  however, can be determined using the standard methods 
of vector Liapunov functions (see Chapter 2). 
Although application of the vector Liapunov function is straightfor- 
ward, there is a disturbing fact that the interconnection term -BDKD in 
(4.80) contains the gain matrix KO, which makes the problem nonstandard: 
increasing the gain KD to stabilize the closed-loop matrix AD - BDKD in- 
creases the interconnection term -BD KD, thus making the vector Liapunov 
function method less effective. We explore this problem further by rewriting 
(4.79) as 
AD - BDKD 
0 
AD - LDCD 
Ac 0 
(4.81) 
This new form suggests that on the subsystem level the separation property 
still holds, but global stability involves the joint interconnection problem 
of the system-bserver combination. 

4.4. Decentralized Observer 
203 
Let us study the problem in some detail. Obviously, the system S&S 
can be viewed as an interconnection of N subsystems, which can be de- 
scribed as 
+? IAi' "1 [ z] 
, i E N. 
(4.82) 
j=1 
A, 
0 
Stabilization can proceed as in Section 2.4. We start with 
Ai - BiKi 
-BiKi 
( S & s ) i :  [:] 
= [ 
] [3 (4.83) 
X i  
0 
Ai - LiCi 
and note that on the level of subsystems, the separation property remains 
valid. Since the pair (Ai, Bi) is controllable, we can choose Ki to produce 
the optimal pair (Hf, G:) of Liapunov matrices for the controller. Observ- 
ability of (Ai, Ci) implies that a selection of Li can be made to obtain the 
optimal pair (Hf, G:) for the observer part of (S & S ) i .  In the transformed 
space defined by the nonsingular matrices T& and T,i, the individual Lia- 
punov functions axe 
V ; ( q  = II32112, 
?If(&) = IIhi112. 
(4.84) 
Following the construction of Section 2.2 , we use the function vi: R2ni -, 
R+, defined as 
~ i ( ~ i )  
= d i l ~ : ( ~ i )  
+ diZV:(gi), 
(4.85) 
for a Liapunov function of ( S & S ) i ,  where zi E RZni is the vector zi = 
(Zr, $ ) T ,  and the positive numbers dil and di2 are yet to be determined. 
We define 
and produce the estimates 
(4.87) 

204 
4. Estimation and Control 
where 2: 
= (IljEi(l, IISiII)T and 
(4.88) 
The interconnections in (4.82) among the subsystems (S&S)i can be 
bounded using the numbers 
(4.89) 
where the interconnection matrix A i j  is defined in the transformed space 
as 
T Z ~ A ~ ~ T , .  
o 
TZ'A~~T,, o 
Aij = [ 
] 
(4.90) 
Finally, we formulate the N x N aggregate matrix W = (wij) for the 
overall system S & 8 of (4.82): 
4.9. THEOREM. A system 
is a decentralized asymptotic observer for a system 
(4.91) 
(4.77) 
(4.69) 
and the closed-loop system S & S is stable if W E M .  

4.4. Decentralized Observer 
205 
0- 
0 
0 
1- 
: 
Proof Straightforward application of the method of vector Liapunov 
Q.E.D. 
functions outlined in Section 2.2. 
, 
c,= 
4.10. REMARK. Stability of the joint system S &  S was established in 
a hierarchical fashion because the subsystems themselves were treated as 
composite subsystems involving the closed-loop subsystems and the local 
error subsystems as components. A considerably more general hierarchi- 
cal stability analysis is available in Section 7.4, which can be applied to 
nonlinear systems as well. 
Of course, when W of Theorem 4.9 fails the M-matrix test, one has to 
redesign the controller and observer on the subsystem level and test the new 
W matrix to see if W E M .  No assurance is given that the process would 
succeed even if the poles of the closed-loop system are pushed further and 
further to the left in the complex plane. It is possible, however, to delineate 
classes of systems for which decentralized observers can always be built by 
high-gain feedback to produce a global asymptotic observer. As expected, 
these classes are duals to those that are decentrally stabilizable in the 
sense of Section 2.4. In the rest of this section, we present the decentralized 
observer scheme of Bachmann (1983), which is based upon the stabilization 
result of Ikeda and Siljak (1980) contained in Theorem 2.20. 
We first specify the interconnected system 
(4.92) 
which has the single-input-single-output subsystems 
Si: X i  = A i ~ i  + biui, 
(4.93) 
yi = ?Xi, 
i E N, 
and xi(t) E RRa, which is standard. The matrices Ai, bi, c, are 
0 1 ... 0 
0 0 ... 0 
0 0 ... 1 
0 0 ... 0 
............ 
(4.94) 
0 ‘j* 
0 

206 
4. Estimation and Control 
A nonstandard feature is the fact that the last row of Ai is zero because it is 
included in Aii. A restrictive assumption, however, is the new requirement 
that in c, only c,l # 0, which makes (4.94) very special, indeed. 
The overall closed-loop system S & S of (4.80) has the following speci- 
fications: 
AD = diag(Al1, A22, . . . , A N N } ,  
AC = (Aij), 
KO = diag{kr, kr, . . . , kg}, 
BD = diag(b1, b2, . . . , h}, 
CD = diag(cy, $, . . . , c',}, 
Lo = diag(l1, 12, . . . , l ~ } ,  
(4.95) 
where the vectors ki, l i  E R"' are 
ki = (ki, kb, . .. , k6JT, 
l i  = (l!, G, .. ., lki), 
(4.96) 
with the components chosen as 
k,. = pni-j+l xci, 
3 
ti, 
3 = p - j + l  ~ 7 ,  
(4.97) 
where C? and Cy are the corresponding sums of the products of D? and 
a:, which are the real and distinct eigenvalues, so that in the transformed 
spaces the subsystems closed-loop matrices are 
A: = diag( -pa?, -PO?, . . . , -paz },  
(4.98) 
A: = diag(-paf, -pa?, . . . , 
The transformations are defined as 
2. 
2
-
 -&T..=j. 
cz 2 1  
3. 
z - 
- KT.5. 
ez 
1 1  
(4.99) 
where R = diag(1, p, . . . , pni-l} depends on p, but T& and Tei are non- 
singular matrices with elements depending on a? and D? only. The trans- 
formed matrices are 
A: = Ti1R2r1(Ai - bilcr)&Te, 
(4.100) 

4.4. Decentralized Observer 
207 
At last, by relying on Theorem 2.20, we establish the following result 
(Bachmann, 1983): 
4.11. THEOREM. A union of disconnected subsystems 
is a decentralized observer for a system 
(4.101) 
(4.102) 
yz = $Xi, 
i E N, 
and the closed-loop system S & 8 is stable if the matrices A, are such that 
the inequality 
T 
(4.103) 
k= 1 
holds for all subsets IT and JT of N, where mij is defined in (2.120). 
Proof We have all we need to define the 2N x 2N aggregate matrix 
PDC - zc 
- PZe 
W'= [ 
where the N x N submatrices are 
-"'I 
PDe 
1 
(4.104) 

208 
4. Estimation and Control 
and 
n1 
n1 
p=l 
q=l 
n; 
n, 
or 
p=l 
q=l 
Using W’ of (4.104) we define a new matrix 
(4.106) 
(4.107) 
Now, W’ E M if and only if W“ E M ,  that is, W E M .  On the 
other hand, we notice that in the split W = D, - Wc, Wc = p-’(ZC - 
DSD;lZe), the N x N matrix WC = (pmij-’[$) has the nonnegative num- 
bers <; 
independent of p, and the theorem follows from the proof of The- 
orem 2.20. 
Q.E.D. 
4.5. Stochastic Control 
Despite a relatively long history, the optimization methods for decen- 
tralized control and estimation of stochastic systems are unsatisfactory. 
Due to nonclassical constraints on information and control structure, the 
standard optimization procedures are ineffective even for simple systems 
of small dimensions. The situation is further complicated by the fact that 
imperfect knowledge of interactions among various components of the sys- 
tem is invariably a part of the problem. No one knows if the limitations 
of the standard methods can be removed by developing better procedures, 
or if these limitations can be attributed to the lack of a precise axiomatic 
definition of the optimization problem. 
To bypass these difficulties, the problem of decentralized stochastic con- 
trol is formulated as a problem of interconnecting subsystems that are o p  
timized by local feedback. The recipe was introduced in Section 3.1: treat 

4.5. Stochastic Control 
209 
interconnections as perturbation terms, and determine suboptimality of lo- 
cally optimal controls when applied to the overall interconnected system. 
The measure of suboptimality is the size of the performance bound of the 
interconnected system relative to the performance of the nominal system, 
be it the disconnected locally optimal subsystems or the overall globally 
optimal system. The most appealing feature of this design is the robustness 
characteristics of the closed-loop system. 
We start our exposition of the suboptimal LQG design with a linear 
stochastic differential equation of the It6 type: 
S: dx = Axdt + Budt +dv, 
(4.109) 
where x(t) E R" is the state of S, u(t) E R" is its input, and A(t) 
and B(t) are n x n and n x m matrices which are continuous in t E 
R. In (4.109), w(t) E R" is the input noise, which is a Wiener process 
independent of the initial state x(t0) = xo with E(dv dv') = I& dt, where 
E denotes mathematical expectation, R, (t) is the incremental covariance 
matrix, which is continuous and uniformly bounded in time, and Edu = 0. 
It is also assumed that the Gaussian statistics &XO = mo, cov(x0, XO) = Ro, 
and &.(t) for the system S are given a priori. 
The system S is decomposed to get 
N 
S: dxi = A i ~ i  
dt + B i ~ i  
dt + C Aijxj dt + dui, 
i E N, (4.110) 
j=1 
which represent an interconnection of N subsystems 
Si: dxi = A i ~ i  
dt + Biui dt + dvi, 
i E N, 
(4.1 11) 
where s ( t )  E Rn*, ui(t) E Rma, vi(t) E R"' are state, input, and noise of 
Si, such that ELl ni = n, ELl mi = m; Ai(t), Bi(t), Aij(t) are matrices 
of appropriate dimensions and continuous in time. 
The fundamental assumption concerning the system S is that the input 
matrix B is a block diagonal matrix, that is, BD = diag(B1, Bar . . . , BN}, 
and S is an input-decentralized system. We assume, however, that the noise 
inputs of the subsystems are mutually correlated. 
We consider the system S in the compact form 
S: dx = ADX dt + BDU dt + A ~ x  
dt + dv. 
(4.112) 

210 
4. Estimation and Control 
With S we associate a quadratic cost 
(4.113) 
and consider the expected value EJ of the cost J as a measure of the system 
performance, where the matrices Qx(t) and QU(t) are uniformly bounded 
and continuous functions oft, and 
where each Qxi is symmetric nonnegative definite and has dimension ni x 
q, 
and Qui is symmetric positive definite and has dimension mi x mi. 
Furthermore, we assume that Q;l (t) is uniformly bounded and continuous. 
In J above, zyPfzf is the terminal cost, where z(tf) = xf, tf > to, is the 
terminal state, and 
Pf = d W P f l ,  Pf2, . * .  7 P f N )  
(4.11 5) 
is a symmetric positive definite matrix. The block diagonal choice of Qz, Qu, 
and Pf is motivated by a decentralized strategy to be used in controlling 
the system S. In fact, this choice implies that to each decoupled subsystem 
Si of (4.111) there corresponds a cost 
It is a well-known result of Kalman (e.g., Astrom, 1970) that the optimal 
control law for the system SD with Ac(t) = 0, 
So: dx = ADX dt + BDU dt + dv, 
(4.117) 
is 
uo - 
D - -KDx, 
where the matrix KD(t, tf) is given by 
(4.118) 
KD = Q;'B$PD. 
(4.119) 
The matrix PD(t; tf, Pj) is the symmetric positive definite solution of the 
Riccati equation 
PD = - A ~ P D  - PDAD + PDBDQ;lBsP~ - Qx, 
(4.120) 

4.5. Stochastic Control 
211 
with t E (to, t f )  and PD(tf; t f ,  Pf) = Pf, provided the pair (AD, Q:'2) 
is 
differentially observable (Weiss, 1966; Anderson and Moore, 1969). 
Due to the fact that the matrices AD, BD, Qz, Qu, and Pf are block 
diagonal, we have also KD = diag(K1, K2, . . . , KN} and PD = 
diag(P1, P2, . . . , PN} block diagonal, so that the optimal control is given 
by a set of local controls 
uy = -Kixi, 
i E N, 
(4.121) 
which result in an optimal decoupled closed-loop system Sg . 
When the decentralized control (4.121) is applied to the interconnected 
system S, the value of the expected cost EJZ is generally different from 
EJ: 
which is computed for decoupled subsystems, that is, when Ac(t) = 0. 
We propose to bound &J$ from above by p-'&JD, where p is a positive 
number. In this way, we provide a measure of suboptimality of the local 
decentralized control when it is applied to the interconnected system S. 
This design policy may be justified by the fact that the uniqueness of the 
optimal decentralized control law that solves the complete LQG problem is 
not guaranteed (Witsenhausen, 1968), and a search for such a control may 
be unreasonable. Furthermore, the suboptimal policy based upon the de- 
coupled subsystems used as reference can preserve autonomy of the subsys- 
tems when interconnected, thus leading to control laws that are suboptimal 
despite structural perturbations (Section 4.8). 
A stochastic version of suboptimality (Definition 3.15) is: 
4.12. DEFINITION. A decentralized control 
uo - 
- -Q;'B;P~X 
(4.122) 
is said to be uniformly suboptimal for the system S and with respect to 
the pair (Sg, JE) if there exists a positive number p such that 
&[J$Ixo] I p - l E I J ~ l ~ ~ ]  
(4.123) 
holds for all to E (0, +m), t f  E (0, +m), and xo E Rn(xO # 0). 
Our immediate interest is to characterize suboptimality in terms of the 
matrix Ac: 
4.13. THEOREM. A decentralized control ug is uniformly suboptimal 
if the matrix 
F(t0, tf; 
= A:(tO)PD(tO; 
tf, pf> -t PDftO; tf, Pf)AC'(tO) 
- (1 - ~ ) P D ( ~ o ;  
t f ,  P ~ ) B D ( ~ o ) Q , ' ( ~ o ) P ~ ( ~ o ;  
t f ,  Pr) + Qz(to) 
(4.124) 

212 
4. Estimation and Control 
is nonpositive definite for some p 5 1, and all to E [0, +m), tf E 
(to, +m). 
ProoJ We represent the performance index &J@ as 
tf 
&JE = &zFPE(to)zo + tr 1 PE(t)&(t) dt, 
(4.125) 
where the symmetric positive definite n x n matrix P,$(t; t f ,  Pf) satisfies 
the differential equation 
with PE(tf; t f ,  Pf) = Pf, and AK = A K ( ~ ,  
t f )  is given as 
A K ( ~ ,  
t f )  = A@) - B D ( ~ ) K D ( ~ ,  
tf). 
Using the Riccati equation (4.120) with (4.126), it is easy to obtain 
(4.127) 
d 
-(& 
- PO) + Ag(pPE - Po) + (pPE - PD)AK + F = 0, 
dt 
(4.128) 
where pPE(tf; t f ,  Pj) - P ~ ( t f ;  
t f ,  Pf) = -(1 -p)Pf. It is obvious that the 
matrix pPE - PD is always nonpositive definite under the conditions of the 
theorem. Since (4.125) implies 
the theorem follows. 
Q.E.D. 
4.14. REMARK. The integrability conditions for the mean-square in- 
tegrals Jg, JE, and s,: 
xTFxdt are obviously satisfied because z(t) is a 
Gaussian process. These integrals are random variables that are Lebesque- 
integrable, and they are defined on the Riesz space which includes the 
case t f  = +oo (see, for example, Gikhman and Skorokhod, 1969). In this 
case, the basic inequality &J@ 5 p-l&J@ implies either &J@ < +ca or 
&J@ = +ca and &J@ = +ca. 

4.5. Stochastic Control 
213 
Remark 4.14 and continuity of F(t0, t j ;  p) in t f  imply that the condi- 
tions of Theorem 4.13 are meaningful for tf = +m. The additional con- 
dition is that the pairs (AD, &:”) 
and (AD, BD) are uniformly observable 
and controllable, respectively. 
It is now of interest to find out whether an analogous statement to 
Theorem 4.13 could be made for a criterion defined as expectation of the 
time average of a quadratic cost function over the infinite time interval. 
This kind of criterion is most often used to obtain a finite performance 
measure of time-invariant control systems over the infinite time interval. 
Therefore, we consider the criterion 
(4.130) 
and establish the following: 
4.15. COROLLARY. A decentralized control ug is suboptimal if the 
matrix F(t0, t j ;  u) is nonpositive definite for some p 5 1 and all to E 
[O, +m), t j  E ( t o ,  +mI. 
Proof. It is clear that Theorem 4.13 applies to 
(4.131) 
for to < t j  < +m. Thus, when F is nonpositive definite on (to, t j ) ,  we have 
E lotf 
(zTQzz + uTQUu) 
dt 
t j  - t o  
In view of Remark 4.14, expectations in (4.133) are well-defined for 

214 
4. Estimation and Control 
t 4 +oo. Therefore, by continuity, 
(xTQZx + uTQUu) 
dt 
1 
lim - 
and, thus, 
€JE 5 p-IEJg, 
which completes the proof. 
(4.135) 
Q.E.D. 
Suboptimality when established by Corollary 4.15 implies exponential 
stability of the unforced closed-loop system 
SK: j. = AK(t)Z, 
(4.136) 
where 
AK(t) = A(t) - BD(t)KD(t), 
(4.137) 
KD(t) = Q,l(t)B$(t)PD(t). 
(4.138) 
and 
In the expression for KD(t), &(t) = lirnt,+, 
PD(t; tj, 0). 
Now, we define 
to prove the following: 
4.16. 
The equilibrium r = 0 of the system S K  is expo- 
nentially stable in the large if the matrix QD(t) is bounded from below by 
a matrix a&, where a0 is a positive number, and for some p > 0, the 
matrix 
(4.141) 
COROLLARY. 
F(t; p )  = A;(t)PD(t) + PD(t)AC(t) - (1 - p)QD(t) 
is nonpositive definite for all t E [0, +m). 

4.5. Stochastic Control 
215 
Proof. To prove uniform asymptotic (exponential) stability of the equi- 
librium state of S K ,  we use the quadratic form 
as a candidate for a Liapunov function of S K .  From uniform and differential 
observability of the pair (AD, Qy2), and uniform controllability of the pair 
(AD, BD), it follows that there are positive numbers a1 and a2 such that 
all" 5 &(t) 5 a21n, 
vt E [o, +m), 
(4.143) 
where &(t) 2 al, denotes, as usual, nonpositive definiteness of the matrix 
&I (t) - al;, . Hence, 
Moreover, by computing the derivative of V(t, z) with respect to (4.136), 
we obtain 
V ( t ,  2)(4.136) = z T F ( t ;  0)z. 
(4.145) 
Since F(t; p) = F(t; 0) + p&D(t), we have 
F(t; 0) 5 -p&D(t), 
vt E [o,+m). 
(4.146) 
F'urt hermore, 
z T F ( t ;  0)x 5 -pao112112. 
(4.147) 
As the upper bound in (4.147) does not depend on the initial time to, 
and the solutions to (4.136) are continuous in the initial state 50, (4.147) 
concludes the proof. 
Q.E.D. 
In case of a time-invariant system S ,  we have F(t; p) = F ( p )  and 
= QD. For this case, it is convenient to compute the largest degree 
of suboptimality p* that is provided by Corollary 4.16, 
p* = 1 - AM[E(l)Q3, 
(4.148) 
where AM( 
0 )  is the maximum eigenvalue of the indicated matrix. 
4.17. 
The restriction p 5 1 in Theorem 4.13 and Corol- 
lary 4.15 can be removed when Pf(t) = 0, which is the case analyzed by 
REMARK. 

216 
4. Estimation and Control 
Krtolica and Siljak (1980). When p > 1, the interconnection matrix Ac(t) 
can be considered as beneficial because it provides an improvement rather 
than deterioration of the overall system performance when compared with 
the performance of the optimal decoupled subsystems for Ac(t) z 0. 
4.6. Estimation 
By duality, the results obtained for suboptimality of decentralized con- 
trol can be applied to the problem of decentralized estimation when the 
subsystem statistics is uncorrelated. To show this, let us consider the state 
estimation problem for the system S with noisy observations: 
S: d x  = ADX dt + BDU dt + A ~ x  
dt + dv, 
dy = COX dt + dw, 
(4.149) 
where c D ( t )  = diag{Cl(t), Cz(t), . . . , CN(t)} is a continuous C x n matrix, 
and Ci(t) is a Ci x ni submatrix of c D ( t ) .  In (4.149), w(t) E Re is the 
observation noise, which is a Wiener process independent of the initial state 
xo and the input noise v(t). Furthermore, &dw = 0, &(dwdwT) = &dt, 
the matrix &(t) is continuous positive definite and uniformly bounded, 
and the matrices R;'(t) and &(t) are uniformly bounded on the time 
interval [0, +m). 
For Ac(t) = 0, the system S becomes 
So: d x  = ADX dt + BDU dt + dw, 
(4.150) 
dy = COX dt + dw, 
which is the union of the decoupled subsystems 
Si: dxi = Aixi dt + B i ~ i  
dt + dwi, 
(4.151) 
It is well known (e.g., htrom, 1970) that the minimum mean-square esti- 
mation error for the decoupled system SD is achieved by the state estimate 
?@ defined by the Kalman-Bucy estimator (filter) 
dyi = Cixidt +dwi, 
i E N. 

4.6. Estimation 
217 
and ?@(to) = zo, where L D ( ~ ,  
to) is given by 
LD = SDCDR, 
T 
-1 . 
(4.153) 
The matrix So(t; to, &) is the symmetric positive definite solution of the 
Riccati equation 
SD = ADSD + S D A ~  
- SDC~R;’CDSD 
+ &, 
(4.154) 
where t E (to, +co) and S~(to;to, 
&) = &, provided the pair (AD, &”) 
is differentially controllable (Bucy and Joseph, 1968). The minimum esti- 
mation error 
(.@)2 = €[aTz(t) - a%@(t)]2 
(4.155) 
is achieved for all weighting vectors a E R”, where z(t) = z(t; to, zo). In 
terms of the covariance matrix SO, 
= aTsDa. 
(4.156) 
When we apply the interconnected filter 
9’: 
d2 = A2dt + BDzLdt f LD(dy - C2dt) 
(4.157) 
to the interconnected system S ,  the resulting state estimate 2@(t; to, $0) 
produces, in general, a different value of the mean-square error 
(.@)2 = E[aTz(t) - aT2@(t)]2. 
(4.158) 
In analogy to the matrix S D ( ~ ;  
to, &) for Ac = 0, we can define a matrix 
SE(t) = SE(t; to, &) for Ac $ 0 as 
SE(t) = €{[z(t) - 2@(t)] [z(t) - 2@(t)I2, 
(4.159) 
which is the error correlation matrix for the interconnected system, and for 
which we have 
(.@)2 = U’PD”.. 
(4.160) 
In the spirit of Definition 4.12, we bound from above o@ by a multiple 
of a u@, and state the following: 
4.18. DEFINITION. An interconnected estimator S@ for the system S 
and with respect to the pair ( S g ,  J,”), is said to be uniformly suboptimal 
if there exists a positive number C such that 
(.@)2 5 <-1(.@)2 
(4.161) 
holds for all to E (--00, 
+-00), 
t E (to, +oo), and all a E R” (a # 0). 

218 
4. Estimation and Control 
We consider the case when & = diag{&l, &,z, . . . , & N }  
and h = 
diag(h1, hz, 
. . . , h ~ } .  
This means that the input noise and obser- 
vation noise of each subsystem are independent. We prove the following 
corollary to Theorem 4.13: 
4.19. COROLLARY. An interconnected estimator S@ is uniformly sub- 
optimal if the matrix 
G(t, to; C) = A d t ) S ~ ( t ;  
t o ,  Ro) + S D ( ~ ;  
t o ,  Ro)Az(t) 
- (1 - C ) [ s D ( t ;  t o ,  Ro)Ci(t)R,'(t)CD(t)SD(t; 
to, &I) + &(t)] 
(4.162) 
is nonpositive definite for some 
5 1 and all to E 
(--00, 
+-00), 
t E 
( t o ,  +m). 
Prooj The dual of the estimation problem defined by S of (4.149) and 
( o @ ) ~  
of (4.155) is to find a deterministic vector function C(-t; -to) that 
minimizes the performance index 
J -t 
constrained by the equation 
dz 
= A ~ z  
+ AZz + CiC, 
(4.163) 
(4.164) 
where -T 
E (-t, -to) and z(-t; -t, a) = a (e.g., Astrom, 1970). This 
problem has a well-known solution for Ac(t) = 0: 
e = -L*z, 
T 
(4.165) 
where LD is given by (4.153). Theorem 4.13, when applied to the determin- 
istic system (4.164), implies that inequality (4.161) of Definition 4.18 holds 
for an arbitrary vector a E R" on any time interval (to, t )  if the matrix 
G(t, to; <) of the corollary is nonpositive definite for all to E (--00, 
+m), 
t E (to, +oo). 
Q.E.D. 
An obvious dual of Corollary 4.16 can be formulated by using Corol- 
lary 4.19 to establish exponential stability of the unforced closed-loop sys- 
tem 
S,: P = AL(t)Z, 
(4.166) 

4.7. Incomplete State Information 
219 
where E(t) = x(t) - ?(t) is the expected estimation error, 
and 
- 
with sD(t) = limt,,+-m sD(t; to, 0). In case of a time-invariant version of 
the system S in (4.149) and infinite observation interval, we have a constant 
matrix 
G(<) = AcSD + SDAC - (1 - <)(SDC~RG'CDSD 
+ I&,). 
(4.169) 
Again, nonpositive definiteness of G(C) guarantees suboptimality of the 
estimator S@. If, in addition, ~DC;R;'CDSD + I&, is positive definite, then 
the unforced suboptimal estimator is also exponentially stable. 
4.7. Incomplete State Information 
By joining the results obtained separately for control and estimation, 
we can provide a suboptimal solution to the decentralized control problem 
with incomplete state information. We consider again the system 
S: dx = ADX dt + BDU dt + ACX dt + dv, 
d y  = COX dt + dw, 
with the cost 
JD = ~YPfzcf + 
(xTQzx + uTQuu) dt, 
Lotf 
(4.149) 
(4.1 13) 
and use 
as a measure of system performance, where Yt = ( ~ ( 7 ) :  
T E (to, t)}. 
We remark that E[JDlyt] depends on the control law, which is a mapping 
from the space of observations y = {y,} into the control space U, 
that is, 
u: (to, t f )  x y + u. 

220 
4. Estimation and Control 
It is well known (e.g., h;strom, 1970) that the optimal control law for 
the system S with Ac(t) = 0 is 
uo - 
- -KDi@, 
(4.171) 
where KD = Qi1B;PD, and Po(t; to, Pf) is the symmetric positive definite 
solution of the Riccati equation 
PD = AgPD - PDAD + P D B D Q ~ ~ B ~ P D  
- Q,, 
(4.120) 
with t E (to, t f )  and P ~ ( t f ;  
t f ,  Pf) = Pf. The optimal state estimate 9 
is defined by 
9:: 
dko = Ao3i.O d t  + BDU@ 
dt + LD(dy - CD~' dt), 
(4.172) 
and 2@(to) = mo, where the matrix Lo(t, t o )  is specified by LD = SDC~R;', 
and So(t; to, &) is the covariance matrix of the estimation error, which is 
governed by the equation 
SD = S D A ~  
+ ADSD - S D C ~ R ~ ~ C D S D  
+ &, 
(4.173) 
where s D ( t 0 ;  to, &) = &. We denote by &J: the optimal value of &JD 
with respect to u E U, 
which is obtained as 
min EJD = € min &[JDlyt], 
(4.174) 
U 
and by €JE the value of &JD when the feedback of the same form as u: is 
applied to the interconnected system S. In the latter case, the suboptimal 
decentralized control is determined by 
U D  = - K D ~ ,  
(4.175) 
In order to formulate an analog to Theorem 4.13, we observe that the 
where the state estimate 2(t; to, mo) is provided by the estimator S@. 
combined closed-loop system S & S can be described as 
S& S: d z  = A z d t  + r d 8 ,  
(4.176) 
where the augmented state vector z E R2" is defined as z = (xT, 5?T)T, 5? = 
2-2, and z(t0; to, 20) = 20. In (4.176), we have the matrices A = A(t; to, t f )  
and 
= r(t; to) as 
A - BD KD 
BD KD 
A =  [ 
. 
(4.177) 
0 
A - LDCD 

4.7. Incomplete State Information 
221 
The Wiener process g ( t )  E RZn and the initial state 
are defined as 
5 = (vT, wT)T and zo = (z:, 
2:)T, 20 = zc - mo, where €g = 0, €20 = 
(mf, 
O)T, and covariance matrices &(t) = cov[fi(t), fi(t)], & = COV(z0, 20) 
are given by 
(4.178) 
& = [  & l o  1, 
& = [  & &  1 .  
O
R
,
 
& &  
When &(t) = 0, we denote the augmented state z of the optimal closed- 
loop system ( S  & S ) D  by €.@, and the corresponding matrix A by AD. 
We introduce the matrix Ac = A - AD = diag{Ac, Ac), and thus reduce 
the problem of suboptimality characterization to the one formulated in 
Section 4.5. In order to state an analog to Theorem 4.13, we note that the 
optimal performance index &J@ may be represented as 
EJ,O = EZ,T@@(tO)ZO + tr 
@@(t)r(t)R,(t)rT(t) 
dt, 
(4.179) 
where the symmetric nonnegative 2n x 2n matrix @@(t; 
t f ,  @f) satisfies 
the differential equation 
-T 
@ 
(4.180) 
with@@(tf; t f ,  @j) = @ f , and the symmetric nonnegative matrices 8(t; t f ) ,  
Phif defined by 
d 
dt 
-a@ +AD@ + @ @ A D  + 8 = o 
Now, we consider the control law ug of (4.171), the system S of (4.149) 
and the cost JD of (4.113), and prove the following: 
4.20. 
matrix 
THEOREM. A decentralized control law ug is suboptimal if the 
Wo, 
tf; p) = A;(to)@@(t; 
tf, af)+@@(to; 
t f ,  @f)Ac(to)-(i-p)e(to, t f )  
(4.182) 
is nonpositive definite for some p 5 1, and all to E [0, +oo), t f  E (to, +oo). 

222 
4. Estimation and Control 
Proof. We observe that in analogy to (4.116), and using (4.180), we can 
write 
&JE = &zF@@(tO)ZO + tr 
@@(t)r(t)&(t)r*(t) 
dt, 
(4.183) 
where the symmetric nonnegative definite 2n x 2n matrix @@(t; 
t f ,  @f) 
satisfies the differential equation 
(4.184) 
d 
dt 
-P + AT@@ + @@A + 0 = 0, 
with @@(tf; 
t f ,  @.p) = @f. Therefore, 
d 
dt 
-(I*.@' 
- @') + AT@@@ 
- a') + (p@@ - @@)A 
+ H = 0, 
(4.185) 
where 
(4.186) 
and 
which proves the theorem. 
Q.E.D. 
4.21. 
Since the matrix F is a principal minor of H ,  Theo- 
rem 4.20 implies the same degree of suboptimality p of the control law ug 
of Theorem 4.13 in the case of complete state estimation. 
REMARK. 
4.8. Structural Perturbations 
We return to our favorite subject of structural perturbations and con- 
sider performance of an interconnected dynamic system driven by locally 
optimal decentralized control and subject to unpredictable changes of the 

4.8. Structural Perturbations 
223 
interconnection structure. Our objective is to present the conditions un- 
der which suboptimality of a stochastic decentralized control strategy is 
invariant to structural perturbations. 
To incorporate changes of the interconnection structure, we modify the 
system description (4.110) to include the elements eij(t) of the N x N 
interconnection matrix E = (eij): 
N 
S: dxi = Aixi dt + Biui dt + 
eijAijzj dt + dvi, 
i E N, (4.188) 
j=1 
where the elements eij(t),of the matrix E(t) are continuous functions of 
time such that eij(t) E [0, 11 for all t E [0, +w). We recall the definition 
of the N x N fundamental interconnection matrix E = ( e i j ) :  
(4.189) 
We state the following: 
4.22. DEFINITION. A decentralized control 
U@ 
D -  - -Q;'B;P~Z 
(4.122) 
is connectively suboptimal with a degree p for the system S and with 
respect to the pair (Sg,J$), if it is suboptimal with the degree p for all 
E E E. 
In order to derive conditions for connective suboptimality, it is conve 
nient to introduce also the n x n matrices & obtained from the matrix 
PDAC = (eijPiAij), where Ac = (eijAij), by setting eij = 1 when i = k, 
j = e, and eij = 0 otherwise. Furthermore, we define the numbers &j and 
7 7 =  
(4.190) 
where 
Wi(ti t / )  = pi@, t f ,  Pr)Bi(t)Q;~(t)B,T(t)P,(t, 
t f ;  Pf) + Qli(t). (4.191) 
We assume 17 > 0, and establish the following result: 

224 
4. Estimation and Control 
4.23. THEOREM. A decentralized control law ug is connectively s u b  
optimal if for some p 5 1, 
N 
(4.192) 
Proof. We note that from the definition of the matrices &j and the 
numbers & j ,  we have 
where we recall Ac = (eijAij). Then, from the condition of the theorem 
and (4.193), we conclude that F(t, t f ;  p )  of Theorem 4.13 is nonpositive 
definite for all t E [0, t f ) ,  tf E (0, +m). Hence, the theorem follows from 
Theorem 4.13. 
Q.E.D. 
Besides suboptimality under structural perturbations, Theorem 4.23 
provides also a simple test for suboptimality of decentralized control strate- 
gies. Although the test is more restrictive than that of Theorem 4.13, it 
involves only subsystem matrices and is a useful computational simplifica- 
tion when the interconnection matrix Ac is large. 
4.24. REMARK. According to Corollary 4.15 the inequality (4.192) of 
Theorem 4.23 implies exponential connective stability of the closed-loop 
deterministic system SK of (4.136), where A K ( ~ )  
is appropriately redefined 
to include the elements eij(t). It follows from the proof of the corollary that 
Ilx(t; to, X 0 ) l l  I ~llxoll exP[-r(t - to)], 
(4.194) 
1/2 - 
where z(t; to, X O )  is a solution to (4.136), II = aUp[Po(t)]X,:”[pb(r)], 
r = -&Xinr[E(t; 
O)] &&[[PD(t)] are both positive numbers, and Asup( 0 )  and 
Xinf( 0 )  denote the least upper bound and the greatest lower bound of the 
maximal and minimal eigenvalues. The fact that &up[&(t)], 
X i n f [ P ~ ( t ) ] ,  
and Xinf[E(t; O)] are all positive numbers follows from the uniform bound- 
edness of the matrix &(t) and inequality (4.192). From this inequality and 

4.8. Structural Perturbations 
225 
a 
v 
I: :I 3 
,:FJ 
[::I 
(b) 
Fig. 4.2. 
structures. 
Structural perturbations: interconnections; (a) basic structure; (b) perturbed 
the proof of Theorem 4.13, it further follows that inequality (4.194) holds 
for all E(t) E E, which implies connective exponential stability in the large 
of the equilibrium x = 0 of the closed-loop system S K .  
In Figure 4.2, we illustrate the meaning of structural perturbations 
which are characterized by Theorem 4.13 for a case of two interconnected 
subsystems. Following Siljak (1978), we describe the basic structure of the 
overall system by the digraph on Figure 4.2a, which corresponds to the 
fundamental interconnection matrix E (feedback loops invoking inputs 
are excluded). The structural perturbations with binary matrices E E E 
are shown in Figure 4.2b. 
4.25. 
Finally, we want to comment on the fact that the 
closed-loop system SK driven by a suboptimal decentralized control is 
robust; it can tolerate a wide range of nonlinearities in the interactions 
among the subsystems. We introduce a modification of SK whereby the 
time-varying matrices A, ( t )  are replaced by nonlinear timevarying matri- 
ces Aij(t, x). The elements aij(t, z) of Aij(t, x) are sufficiently smooth so 
REMARK. 

226 
4. Estimation and Control 
that the solutions x(t; to, XO) of (4.188) exist and are unique for all initial 
conditions (to, ZO) E T x R" and all time t E TO. The [ij are now redefined 
as 
5.. 
$3 - 
- sup 
xA4 { @(t, t f ,  x) +A&, tf, x)] 
t,tf E To 
x-€ R" 
(4.195) 
Under the condition (4.192) of Theorem 4.13, where the &j's of (4.195) 
are used, the decentralized control law ug is connectively suboptimal with 
degree p for the nonlinear version of S in (4.188). It is obvious that by 
duality this conclusion carries over to decentralized estimators. 
4.9. Degenerate Control 
Structural perturbations in the feedback structure are of special interest 
because they can take place not only as a consequence of operational con- 
ditions, but as a means of control design. To come up with a decentralized 
control law, one may design a centralized control strategy and disconnect 
the feedback links to fit a prescribed information structure constraint- 
this is termed the degenerate control (Krtolica and Siljak, 1980). Of course, 
there is no guarantee that the control obtained in this way would be stable, 
let alone optimal in any prescribed way. Our objective here is to present the 
sufficient conditions for suboptimality and stability of degenerate control 
laws. 
We consider again the system S of (4.109), but, in the equation 
S: dx = Axdt + Budt + dv, 
(4.196) 
we do not assume that the matrix B is block diagonal. With S ,  we associate 
the same cost JD of (4.113). The globally optimal control law of Kalman is 
uo - 
- -Kx, 
(4.197) 
where the matrix K(t, t f )  is given as 
K = Q,'BTP, 
(4.198) 
and P(t; t f ,  P f )  is the symmetric positive definite solution of the Riccati 
equation 
P = -ATP - PA + PBQ,'BTP - Q5, 
(4.199) 

4.9. Degenerate Control 
227 
with t E (to, t f )  and P(tf; t f ,  P f )  = Pf, provided the pair (A, Qi’2) is 
differentially observable. The matrices K and P are no longer necessarily 
block-diagonal. The closed-loop system driven by the optimal control law 
u@ is 
So: dx = ( A  - BK)x dt + dv, 
(4.200) 
and the corresponding expected value of the optimal performance index is 
Now, in order to consider disturbances in the control structure, we in- 
troduce the notation 
B=Bo+Bc, 
K = K D + K ~ ,  
(4.202) 
where BD = diag(B1, Bz, . . . , BN}, KD = diag(K1, Kz, . . . , KN}, Bc = 
(Bij), and KC = (Kij) are matrices with blocks Bi(t), Ki(t), Bij(t), and 
Kij(t) that are continuous in time and of appropriate dimensions. Additive 
disturbances -Bc(t) and -Kc(t) of the input and feedback gain matrices 
B(t) and K(t) result in B(t) G Bo(t) and K(t) 5 KD(~), 
as indicated by 
thin lines in Figure 4.3. The resulting (now decentralized) control law is 
U D  = -KDx, 
and the perturbed closed-loop system becomes 
(4.203) 
S@: dx = ( A  - B D K D ) ~  
dt + dv. 
(4.204) 
After the disturbance, the expected value of the performance index is 
A sufficient condition for the basic inequality 
EJE 5 p-lEJg 
is given by the following: 
(4.206) 

228 
4. Estimation and Control 
(b) 
Fig. 4.3. 
ture. 
Structural perturbations: control; (a) basic structure; (b) perturbed struc- 
4.26. THEOREM. A decentralized control law u$ is suboptimal for the 
system S with respect to the pair (So, J,”) if, for some p 5 1, the matrix 
FBK(t1 tf; PI = - m t o ,  tf)B;(to)P(to; tf, Pf) 
+ p[Qz(to) + G ( t o ,  tf)Q.(to)K~(to, 
tf)l 
is nonpositive definite for all to E [0, +oo) and t f  E (to, +m). 

4.9. Degenerate Control 
229 
Proof. In analogy to the proof of Theorem 4.13, we use the representa- 
tion (4.125) of €JE to obtain (4.151), where the matrix pP@(t; t f ,  P f )  - 
P(t; t f ,  P f )  is the solution of the differential equation 
d 
- ( p P  - P )  + A:(@@ - P )  + (pP@ - P)AK + FBK = 0, 
dt 
(4.208) 
with pP@(tf; 
t f ,  P f )  - P(tj; t f ,  P f )  = -(1 - p)Pf, and AK = A - BK. 
Q.E.D. 
Remark 4.14, which is concerned with the case t = +oo, applies to The- 
orem 4.26 directly. Furthermore, a statement analogous to Corollary 4.15 
can also be established. 
An interesting special case arises when the original matrix B is block 
diagonal, and perturbations affect only the feedback control law, that is, the 
gain matrix K. In this case, B = BD, and after perturbation the centralized 
optimal control law U@ is reduced to a decentralized control law U D  that is 
suboptimal with a degree p 5 1. This fact is confirmed by the form of the 
matrix FBK, which becomes 
(4.209) 
From this expression, it is obvious that FK can be nonpositive definite only 
i f p 5  1. 
FK = K c Q Z c  
T 
- (1 - p)(QI + K~Q,KD). 
We now introduce the matrix 
W K ( ~ ,  
t f )  = QZ(t) + G ( t ,  tf)Qu(t)K~(t, 
tr), 
(4.2 10) 
and state the following result: 
4.27. 
A decentralized control law U D  is suboptimal for the 
system S and with respect to the pair (So, J,”) if, for some p 5 1, the 
matrix 
THEOREM. 
G K ( t ,  tf; CL) = Kz(t, tf)Kc(t, t f )  - (1 -P)AG[Qu(t)]W~(t, 
tf) 
(4.211) 
is nonpositive definite for all t E [0, t f )  and t f  E (0, +m). 
Proof. The theorem follows from the fact that the matrix KzQ,Kc - 
Q.E.D. 
X M ( ( Q ~ ) K ~ K C  
is always nonpositive definite. 
The suboptimality condition of Theorem 4.27 can be restated as the 
(4.2 12) 
inequality 
ilKC(t, tf)1I2 5 (1 - C L ) ~ [ W K ( ~ ,  
tf)llA~[Qu(t)l, 

230 
4. Estimation and Control 
which is easy to test. Furthermore, from this inequality we see that subop 
timality of the degenerate decentralized control requires that the pertur- 
bation of the control structure produce “small effects” on the centralized 
optimal control system. This fact leads naturally to connective stability 
investigations of degenerate forms of decentralized control. 
Let us introduce the elements &(t) of the N x N feedback intercon- 
nection matrix A = (6ij) into the description of the optimal control law 
as 
In fact, we redefine the matrix Kc as KC = (SijKij). The elements 6ij(t) E 
[0, 11 of the matrix A(t) are continuous functions of time, and &(t) 5 &j, 
where A = (&) described the fundamental control structure as 
(4.2 14) 
It is evident that continuity in t of the elements of the matrix blocks 
Gij(t)Kij(t, t j )  is preserved. We also redefine the numbers 
(4.2 15) 
We prove the following: 
4.28. THEOREM. A decentralized control law ug is connectively sub- 
optimal with a degree p for the system S with respect to the pair (So, J g )  
if 
N 
~ k i ~ k j ~ i j k  
5 (1 - p)$. 
(4.2 16) 
ij,k=l 

4.9. Degenerate Control 
231 
Proof. From the condition (4.216) of the theorem, it follows that 
We remark that 
and 
Inequalities (4.217) and (4.219) imply that the conditions of Theorem 4.26 
are satisfied for all A(t) E A. 
Q.E.D. 
In analogy to the arguments of Remark 4.24, we conclude that when 
ij > 0, the inequality (4.216) of the above theorem implies exponential 
connective stability of the closed-loop deterministic system 
SK: X=AKX, 
(4.220) 
which corresponds to the use of the optimal control law uo and the absence 
of the input noise on an infinite time interval. That is, 
A K ( ~ )  
= A(t) - B(t)Q,'(t)BT(t)P(t), 
(4.221) 
and p(t) = limtf,+, 
P(t; t f ,  0), where P(t; t f ,  Pj) is the solution of the 
Riccati equation (4.199). Furthermore, we note that the connectivity aspect 
of stability of the system S involves only the perturbations of feedback links 
as illustrated in Figure 4.4. Connective suboptimality corresponding to the 
optimal control law u" includes the suboptimal control UD as a special case 
when A(t) = 0. Indeed, the third digraph of Figure 4.4b is the last digraph 

232 
4. Estimation and Control 
3 3 
(b) 
Fig. 4.4. 
tures. 
Structural perturbations: feedback; (a) basic structure; (b) perturbed struc- 
of Figure 4.2b. However, the condition (4.216) of connective suboptimality 
is more restrictive than nonpositivity of the matrix FK in (4.209), which is 
equivalent to suboptimality of the perturbed control law U D .  
4.10. Notes and References 
The early development of decentralized state determination (Siljak, 
1978) indicated that building observers for complex linear plants requires 
much more effort and ingenuity than solving a decentralized stabilization 
problem via state feedback. One of the first decentralized observers (Weis- 
senberger, 1974) was constructed together with the corresponding control 
law. The separation property (Section 4.3) was established in (Siljak and 
VukEevi6, 1976) at the price of the exchange of state estimates among 
the local observers (see also Sundareshan, 1977; Sundareshan and Huang, 
1984). 

4.10. Notes and References 
233 
Unlike centralized observers, observability is not enough of a guarantee 
that a decentralized observer can be made asymptotically stable using feed- 
back. We had to apply the concept of vector Liapunov functions and the 
M-matrix test to establish stability. One way to assure success of the test is 
to restrict the class of interconnections so that a decentralized observer can 
always be built by high-gain feedback (Siljak and VukEeviC, 1978: Section 
4.2; Bachmann, 1983: Section 4.4; Bachmann and Konik, 1984). 
If we want to avoid the exchange of state estimates among the subsystem 
observers, we should consider the interconnections as unknown inputs and 
reject their influence on the estimation error. This approach was developed 
by Viswanadham and Ramakrishna (1982) using the theory of unknom- 
input observers (Basile and Marro, 1969; see the survey by Viswanadham, 
1987). 
For an unknown-input (or disturbance decoupling) observer to work, the 
interconnections have to satisfy a rather restrictive condition. A remedy is 
to bring back into action the high-gain feedback (Section 4.2) and apply 
almost disturbance decoupling observers (Willems, 1982) as proposed by 
Ikeda and Willems (1986). 
Observers for discrete-time systems were developed by reformulating the 
continuous-time results (Mahmoud and Singh, 1981; Hassan et al. 1983). 
Applications of decentralized observers to mechanical systems (robotics) 
were presented by StokiC and Vukobratovid: (1983). A comprehensive survey 
on decentralized state reconstruction can be found in (Kuhn and Schmidt, 
1984). Suboptimality us. robustness issues in decentralized control using 
observers were considered recently by Shahian (1986). 
In the context of stochastic decentralized problems of estimation and 
control, it has been long recognized that solutions to LQG problems with 
nonclassical (decentralized) information patterns may be nonlinear. Using 
a simple discrete-time LQG problem, Witsenhausen (1968) showed that a 
nonlinear decentralized control law outperforms the best law of the linear 
variety. This important discovery predicted difficulties in searching for opti- 
mal solutions to decentralized stochastic control problems. Over the years, 
many authors have more or less successfully addressed these difficulties, 
but a satisfactory solution to the optimal problem has never been found. 
A suboptimal solution to the decentralized LQG control problem (Kr- 
tolica and Siljak, 1980: Sections 4.5-9) is useful, not only because it pro- 
duces linear control laws, but because it is robust. In controlling complex 
plants, it is natural to assume that the interconnections are uncertain. 
Suboptimal control can cope with unknown perturbations in the intercon- 
nections of a complex plant as well as controller connections. It has also 

234 
4. Estimation and Control 
been shown (HodiiC et al. 1983; Hodkit: and Siljak, 1986a) that the sub- 
optimal scheme can accomodate decentralized estimation and control laws 
with overlapping information sets (see Chapter 8). 
Suboptimal LQG control laws provide a considerable autonomy to the 
subsystems, which opens up a real possibility for distributed parallel com- 
putations of the subsystems estimates (HodiiC and Siljak, 1986b). A study 
of new iterative methods for parallel estimation was initiated (HodiiC and 
Siljak, 1986c), which laid the groundwork for multirate schemes imple- 
mentable by flexible multiprocessor systems. Jacobi and Gauss-Seidel de- 
centralized filters have been introduced, which can exploit a considerable 
wealth of experience present in corresponding numerical methods (Hage- 
man and Young, 1981; Bertsekas and Tsitsiklis, 1989; Kaszkurewicz et 
al. 1989). The iterative estimation schemes are ideally suited for realiza- 
tions via multiprocessor systems with their inherent advantages in response 
time, reliability, program modularity, incremental redundancy, etc., over 
the mainframe computer implementations (Liebowitz and Carson, 1985). 
Bibliography 
Anderson, B. D. O., and J. B. Moore (1969). New results in linear system stability. 
SIAM Journal of Control, 7, 398-414. 
Astrom, K. J. (1970). Introduction to Stochastac Control Theory. Academic Press, New 
York. 
Bachmann, W. (1983). On decentralized output feedback stabilizability. Large Scale 
Systems, 4, 165-176. 
Bachmann, W., and D. Konik (1984). On stabilization of decentralized dynamic output 
feedback systems. Systems and Control Letters, 5, 89-95. 
Basile, G., and G. Marro (1969). On the observability of linear time-invariant systems 
with unknown inputs. Journal of Optzmazation Theory and Applications, 3,41&415. 
Bertsekas, D. P., and J. N. Tsitsiklis (1989). Parallel and Distributed Computation. 
Prentice-Hall, Englewood Cliffs, New Jersey. 
Bucy, R. S., and P. D. Joseph (1968). Filtering for Stochastic Processes with Applications 
to Guidance. Wiley, New York. 
Gikhman, J. J., and A. V. Skorokhod (1969). Introduction to the Theory of Random 
Processes. Sanders, Philadelphia, Pennsylvania. 
Hageman, L. A,, and D. M. Young (1981). Applied Iterative Methods, Academic Press, 
New York. 
Hassan, M. F., M. I. Younis, and M. S. Mahmoud (1983). Linear multilevel estimators 
for stabilization of discrete systems. International Journal of Systems Science, 14, 
HodiiC, M., and D. D. Siljak (1986a). Decentralized estimation and control with over- 
lapping information sets. IEEE Transactaons, AC-31, 83-86. 
HodiiC, M., and D. D. Siljak (1986b). A parallel estimation algorithm. Parallel PTO- 
cessing Techniques for Simulation, M. G. Singh, A. Y. Allidina, and B. K. Daniels 
(eds.). Plenum Press, New York, 113-121. 
73 1-743. 

Bibliography 
235 
HodiiC, M., and D. D. Siljak (1986~). Iterative methods for parallel-multirate estima- 
tion. Preprints of the 4th IFAC/IFORS Symposium on Large Scale Systems, Zurich, 
S witerland , 169- 175. 
HodiiC, M., R. Krtolica, and D. D. Siljak (1983). A stochastic inclusion principle. Pro- 
ceedings of the 22nd IEEE Control and Decision Conference, San Antonio, Texas, 
Ikeda, M., and D. D. Siljak (1980). On decentrally stabilizable large-scale systems. Au- 
Ikeda, M., and J. C. Willems (1986). An observer theory for decentralized control of 
Kailath, T. (1980). Linear Systems. Prentice-Hall, Englewood Cliffs, New Jersey. 
Kaszkurewicz, E., A. Bhaya, and D. D. Siljak (1989). On the convergence of parallel 
asynchronous block-iterative computations. Linear Algebra and Its Applications (to 
appear). 
Krtolica, R., and D. D. Siljak (1980). Suboptimality of decentralized stochastic control 
and estimation. IEEE Transactions, AC-25, 7&83. 
Kuhn, U., and G. Schmidt (1984). Decentralized observation: A unifying presentation 
of five basic schemes. Large Scale Systems, 7, 17-31. 
Liebowitz, B. H., and J. H. Carson (1985). Multiple Processor Systems for Real-Time 
Applications, Prentice-Hall, Englewood Cliffs, New Jersey. 
Luenberger, D. G. (1964). Observing the state of a linear system. IEEE Transactions, 
Mahmoud, M. S., and M. G. Singh (1981). Decentralized state reconstruction of inter- 
O’Reilly, J. (1983). Observers for Linear Systems. Academic Press, New York. 
Shahian, B. (1986). Decentralized control using observers. Control and Dynamic Sys- 
tems, C. T. Leondes (ed.), 24, 105-124. 
Siljak, D. D. (1978). Large-Scale Dynamic Systems: Stability and Structure, North- 
Holland, New York. 
Siljak, D. D., and M. VukEeviC (1976). Decentralization, stabilization, and estimation of 
large-scale linear systems. IEEE Transactions, AC-21, 363-366. 
Siljak, D. D., and M. VukEeviC (1978). On decentralized estimation. International Jour- 
nal of Control, 27, 113-131. 
Stokit, D., and M. VukobratoviC (1983). Decentralized regulator and observer for a class 
of large scale nonlinear mechanical systems. Large Scale Systems, 5, 18S206. 
Sundareshan, M. K. (1977). Decentralized observation in large-scale systems. IEEE 
Transactions, SMC-7, 863-867. 
Sundareshan, M. K., and P. C. K. Huang (1984). On the design of a decentralized 
observation scheme for large-scale systems. IEEE Transactions, AC-29, 274-276. 
Viswanadham, N. (1987). Large-Scale Systems: Observers. Systems and Control Ency- 
clopedia, M. G. Singh (ed.). Pergamon Press, Oxford, UK, 2697-2702. 
Viswanadham, N., and A. Ramakrishna (1982). Decentralized estimation and control 
for interconnected systems. Large Scale Systems, 3, 255-266. 
Weiss, L. (1966). Correction and addendum: The concepts of differential controllability 
and differential observability. Journal of Mathematical Analysis and Applications, 
Weissenberger, S. (1974). Tolerance of decentrally optimal controllers to nonlinearity 
and coupling. Proceedings of the 12th Allerton Conference on Circuit and System 
Theory, University of Illinois, Monticello, Illinois, 87-95. 
17-22. 
tomatica, 16, 331-334. 
large-scale interconnected systems (unpublished paper). 
MIL-8, 74-80. 
connected discrete systems. Large Scale Systems, 2, 151-158. 
13, 577-578. 

236 
4. Estimation and Control 
Willems, J. C. (1982). Almost invariant subspaces: An approach to high-gain feedback 
design; Part 11: Almost conditionally invariant subspaces. IEEE Transactions, AG 
Witsenhausen, H. S. (1968). A counter example in stochastic optimal control. SIAM 
27, 1071-1085. 
Journal of Control, 6 ,  131-147. 

Decentralized control is an appealing concept, because it offers an essential 
reduction in communication requirements without significant , if any, loss of 
performance. Each subsystem is controlled on the basis of locally available 
information, with states of one subsystem being seldom used in control 
of another subsystem. This attractive property disappears when states of 
subsystems are not accessible at the local level. In building observers or 
estimators to reconstruct the states, we may be forced to exchange states 
between the subsystems, and thus violate the information structure con- 
straints of decentralized control laws. A logical way out is to consider static 
or dynamic output feedback satisfying simultaneously the global (decentral- 
ized) and local (output) information constraints. 
We shall first identify a class of interconnected systems that are always 
stabilizable by decentralized output feedback. We hasten to note that the 
conditions do not require that the subsystems are in any kind of canonical 
form. The control strategy is to stabilize each decoupled subsystem using 
dynamic controllers and, at the same time, make sure that the gains of the 
loops in the overall system are sufficiently small, so that stability is retained 
in the presence of interconnections. The same strategy was used in the 
static version of decentralized state feedback for linear plants (Section 2.5), 
where it produced robustly stable closed-loop systems. We shall achieve 
here the same kind of robustness by using output feedback. Furthermore the 
compensated system is nonlinear, consisting of linear plants interconnected 
by memoryless nonlinearities. 
Our recipe for building connectively stable systems is to use decentral- 
ized feedback and treat interconnections as a disturbance of subsystems 
dynamics. If static feedback is our first choice, the geometric concept of 
almost invariant subspaces for disturbance decoupling with stability is an 
appealing alternative to the small gain approach via dynamic controllers. 
237 

238 
5. Output Control 
We shall present graph-theoretic conditions under which an interconnected 
system is connectively stabilizable by static output feedback. Again, the 
subsystems need not be in a canonical form. Furthermore, the conditions 
are generic. Although they are conservative, they should be considered 
satisfactory to the extent that the conservativeness is outweighed by easy 
testability requiring only binary (combinatorial) calculations. 
In the last part of this chapter, we shall give an adaptive version of 
decentralized output feedback. The local feedback gains are adaptively ad- 
justed to the levels necessary to neutralize the interconnections and, at 
the same time, drive the subsystems with unknown parameters toward the 
performance of the locally chosen reference models, as close as desired. It is 
important to note that the resulting adaptive schemes retain the connective 
stability property and robustness to nonlinearities that are enjoyed by the 
fixed-gain decentralized controllers. Furthermore, the adaptive schemes are 
likely to use lower gains, since adaptation extends only to the level that 
is necessary for the required performance, instead of to the conservatively 
high level that may have been determined through a fixed-gain design pro- 
cedure. 
5.1. Dynamic Output Feedback 
We consider an interconnected system S composed of N linear time- 
invariant subsystems Si described as 
where xi@) E Rns is the state, uZ(t) E R is the control input, and yi(t) E R 
is the measured output of Si at time t E R. The matrices Ai, Pi, Qi and 
vectors b,, c, are constant and of appropriate dimensions. In Equation (5.1), 
vi(t) E Rmt and wi(t) E Re* are the interaction inputs and outputs at 
time t E R, which are associated with subsystem Si, and which represent, 
respectively, the effect of other subsystems on Si and the effect of Si on the 
other subsystems. The interaction inputs and outputs are related by 

5.1. Dynamic Output Feedback 
239 
where the nonlinear function fi: 
R‘ 
-+ 
R”a is continuous in w = (w:, 
w,, 
T . . . , tug)T, C = Eel Ci, and satisfies the “conical” condition 
IIfi(w)ll I 
K ~ J I W I I ,  
vw E R‘, 
vi E N, 
(5.3) 
with tci > 0. 
factorization holds: 
We assume that there exists a subset I c N such that the following 
(5.4) 
In other words, we assume that for each subsystem Si either the inter- 
action input wi has the same effect on Si as the control input ui(i € I ) ,  
or the interaction output wi is a reproduction of the measured output 
yi(i E N - I ) .  It should be emphasized that this assumption about the 
interconnection structure is essential in the following development. 
We apply to the interconnected system S a decentralized dynamic con- 
troller 
C.: 2. - F.z. + g. 
z 
a - a 
a 
ZYZ, 
U .  - -hTz. - k .  . 
(5.5) 
z - 
2 
z 
aYz, 
i E N7 
where zi(t) E RTi is the state of Ci, and Fi, gi, hi, and ki are constant and 
of appropriate dimensions. The compensated subsystem S i  = Si & Ci can 
be represented as 
Sz: & = A& + &Ji, 
(5.6) 
wi = Qi&, 
i E N, 
where & = (z:, 
z:)~ is the state of Si, and 
Our goal is to choose the order ri and the parameters Fi, gi, hi, and 
ki of the controllers Ci, such that the null solution ii = 0, i E N, of 
the compensated interconnected system S, consisting of the closed-loop 
subsystems Si of (5.6) and the interconnections in (5.2), is asymptotically 

240 
6. Output Control 
stable in the large for the nonlinearities fi satisfying (5.3); that is, S is 
absolutely stable in the sense of Lur'e-Postnikov (e.g., Siljak, 1969). For 
this purpose, we first investigate the effect of the proper choice of each 
individual controller Ci on the subsystem Si. 
We begin with the analysis of decoupled subsystems. To simplify the 
notation, we drop the subscript i and describe Si of (5.1) as 
where x(t) E R" is the state of Si at t E R. Furthermore, we assume that 
the interaction input w ( t )  and interaction output w(t) of Si are scalars; thus, 
u(t), v(t), y(t), w(t) E R at t E R. We also assume that Si is controllable 
by the control input u(t), and observable from the measured output y(t); 
that is, the triple (A, b, c?) 
is controllable and observable. 
Similarly, we represent a typical controller Ci of (5.5) as 
where z(t) E R' is the state of Ci at t E R. The closed-loop subsystem 
Si = Si & Ci is described by 
A
.
 
1 
Si: i = Ai +$v, 
w = g-2, 
(5.10) 
where i = (xT, z ~ ) ~ ,  
and 
A -  bkcT 
-bhT 
A =  [ 
g F  
F 

5.1. Dynamic Output Feedback 
241 
We define now the following transfer functions: 
GYZL(s) 
= cT(sI - A)-’b, 
Gyv(s) = cT(sI - A)-’p, 
Gwu(s) 
= q T ( d  - A)-’b, 
H ( s )  = k + hT(sl - F)-’g, 
‘ W ( S )  = p ( s 1  -A)-’$. 
If p = b in (5.8), then, by direct computation, we obtain 
Similarly, if q = c in (5.8), then W(s) can be computed as 
(5.12) 
(5.13) 
(5.14) 
Since the transfer functions in (5.13) and (5.14) are of the same form 
(in fact, they have the same poles), the following argument applies to both 
of them equally well. Therefore, from now on, we shall assume that p = b 
in (5.8), so that W(s) is as given in (5.13). 
We begin our development by defining Gyu(s) and Gwu(s) in (5.12) 
explicitly as 
where 0 5 v 5 n - 1, and 
(5.16) 
y(s) - y1sn-l + y 2 F 2  + * .  . + yfl 
sn+a1sn-1+ ... +a, . 
w u s  
( I- a(.) 
We assume that Gyu(s) 
has n - v - 1 zeros. We shall further assume that 
these zeros lie in the open left-half complex plane C-. We choose the order 
of C to be v; that is, T = v. Then, H(s) of (5.12) has the form 
(5.17) 

242 
6. Output Control 
Finally, using (5.15)-(5.17), we can express W(s) in (5.13) as 
(5.18) 
We now choose the parameters of the controller C as follows: 
(u) The coefficients qj, j = 1, 2, . . . , u, in (5.17) are chosen arbi- 
trarily, subject to the condition that ~ ( s )  
has all its zeros in 
C- . 
The coefficients &, j = 1, 2, . . . , u, and 770 in (5.17) are chosen 
(b) 
as 
I. 
3 -  - i. 
3dr 
j = 1 , 2 1 . . . 1 ~ ,  
(5.19) 
- 
U + l  
Po770 =Cv+lP 
I 
where p > 0 is a parameter to be specified, and 
v + 1, are such that the polynomial 
j = 1, 2, . . ., 
i ( s )  = 
+ &SU + i 2 d - l  + . . . + 
(5.20) 
has only distinct zeros and all in C-. 
Denoting by C+ the closed right-half complex plane, we now prove the 
following result (Hiiseyin, et ul. 1982): 
5.1. 
Under the conditions (u) and (b) above, for any t > 0 
there exists a p > 0 such that, whenever p > p ,  the following conditions 
are satisfied: 
LEMMA. 
(2) A has all eigenvalues in C-; 
(ii) IW(s)l < 6 ,  
vs E c+. 
Proof. Let W(s) of (5.18) be written as 
where +j and O j ,  j = 1, 2, . . . , n + u, are functions of the parameter p. 
Comparing (5.18) and (5.21), and using (5.19), we have 
O(s) = s”a(s) + p&s”-’a(s) + . . . + p v ~ U a ( ~ )  
+ p u f l ~ U + l ~ ( s ) ~ ( s ) .  
(5.22) 

5.1. Dynamic Output Feedback 
243 
The proof of the lemma is based upon the following variation of a result 
obtained by Inan (1978): 
As p +. $00, k + 1 zeros of O(s) approach p times the zeros of i ( s )  
in (5.20), while the remaining n - 1 zeros of O(s) approach the zeros of 
p(s)q(s) in the following sense: 
(a) 
Let p be a zero of <(s), which is by assumption simple. Then, 
there exists MI > 0 and P1 > 0 such that an exact zero p(p) of 
6(s) satisfies 
IP(P) - PPI I M1, 
VP > P1. 
(5.23) 
Let X be a zero of p(s)q(s) with multiplicity k. Then, there 
exists M2 > 0 and p, > 0 such that exactly k zeros, Xj(p), j = 
1, 2, . . . , k, of O(s) satisfy 
(b) 
IXj(P) - XI I M2p-llk, 
v p  > P,. 
(5.24) 
Now, let us consider O(s) of (5.22), where p(s) has its zeros in C- by 
assumption, and q(s) and i ( s )  have their zeros in C- by the choice of 
the parameters of the controller C. Then, the above result of Inan (1978) 
ensures that there exists p, > 0 such that O(s) has all of its zeros in C- 
for all p > p,. Since the triple (A, b, cT) is controllable and observable, the 
proof of the first part of the lemma is complete. 
To prove the second part of the lemma, let us denote the zeros of i ( s )  
by pj, j = 1, 2, . . . , v + l ,  and those of p(s)q(s) by Xj, j = 1, 2, . . . , n-1. 
Also, let pj (p), j = 1, 2, . . . , u + 1, and Xj(p), j = 1, 2, . . . , n - 1, denote 
the exact zeros of O(s) which approach ppj and Xj, respectively, as p + +m. 
Let us rewrite W ( s )  in (5.21) as 
(5.25) 

244 
5. Output Control 
Since y(s) has degree n - 1, and A j  E C-, j = 1, 2, . . . , n - 1, we have, 
for some M3 > 0, 
(5.26) 
On the other hand, using the above result of Inan (1978), it is easy to show 
that there exists p, > 0 such that, for p > p,, 
and 
Now, consider the first term on the right-hand side of (5.25), which can 
be expanded into partial fractions as 
where 
(5.28) 
Using (5.19), Rj(p) in (5.28) can be computed as 
k#j 
(5.30) 
so that 
IRj(p)l = Mj4 < +m, 
V j  = 1, 2, . . . , v +  1. 
(5.31) 

5.1. Dynamic Output Feedback 
245 
Since pi E C-, (5.31) implies that 
so that from (5.28) we get 
From (5.25) and inequalities (5.26), (5.27), and (5.33), it follows that if 
P > m = G ,  P4}, then 
Iw(S)l < 2n+”p-1M&, 
vs E c+. 
(5.34) 
Now, for any 6 > 0, letting p, = 2n+u6-1M3M4 and P = ma{&, p,, &}, it 
follows that 
IW(S)l < € 7  
vs E c+, 
v p  > p. 
(5.35) 
Q.E.D. 
The properties of the Lemma 5.1 have already given a clue about the 
mechanism of achieving stability of the closed-loop interconnected system: a 
small-gain version of the circle criterion (Zames, 1966), which we summarize 
below. 
Let us consider the compensated interconnected system S, which can 
be described in compact form as 
$3: 1 = A2 + Pf(w), 
w = &it, 
(5.36) 
where 2(t) E Rn, it = (ity, it:, 
. . . , 
Re -+ 
R”, f(w) = [fT(w), fr(w), 
. . . , f$(w)]‘, 
rn = Ci mi, is the intercon- 
nection function, and 
is the state of S ,  f :  
N 
A = diag{Al, A,, . . . , AN}, 
(5.37) 

246 
5. Output Control 
where 
&[Iy 
O T I T ,  
Oi=[Qi 01 
(5.38) 
are constant matrices of appropriate dimensions. The linear part of S has 
the transfer function 
W(s) = Q(s1- A)-'P, 
(5.39) 
which is in block diagonal form, that is, W(s) = diag{Wl(s), Wz(s), ..., 
WN(S)}, with the diagonal blocks 
W ( S )  
= Qi(s1- Ai)-'fi, 
i E N, 
(5.40) 
corresponding to the compensated subsystem S, of (5.6). 
that it belongs to the class 
As far as the interconnection function f(w) 
is concerned, we require 
F =  {f: Ilf(W)ll 5 4lwll, vw E Re), 
(5.41) 
for some positive number K .  
version of the circle criterion (e.g., Narendra and Taylor, 1973): 
To prove the main result of this section, we need the following small-gain 
5.2. THEOREM. Suppose the matrix A = diag(A1, Aa, . . . , AN} has 
all of its eigenvalues in C-. Then, the equilibrium 2 = 0 of the system S 
is globally asymptotically stable for all f(w) 
E F, 
that is, the system S is 
absolutely stable, if 
(5.42) 
where Xk( 0 )  denotes an eigenvalue of the indicated matrix. 
Using Lemma 5.1 and Theorem 5.2, we arrive at the following (Huseyin 
et al. 1982): 
5.3. THEOREM. Suppose that the subsystem Si = (Ail b,, c:), i E N, 
are controllable and observable and the matrices Ail i E N, have all their 
eigenvalues in C-, and the pairs (Pi, Q i )  can be factored as in (5.4). Then, 
there exists a set of local controllers G,, i E N, defined by (5.5), such that 
the closed-loop interconnected system S is absolutely stable. 

5.2. Structured Almost Invariant Subspaces 
247 
Proof. From the condition (5.4), it follows that the subsystem transfer 
functions have the forms 
Wi(S) = Q&I- AJ-%z$, 
Wi(S) 
= q&y(sI - Az)-lR, 
i E I, 
i E N- I, 
(5.43) 
where Ai is A of (5.11), and hi and 
are obtained from bi and CT by 
augmenting with zeros. Then, from Lemma 5.1 and conditions of the the- 
orem, we conclude that the local controllers C, can be designed so that 
the matrices Ai have all their eigenvalues in C-, 
and for any set of positive 
numbers ~ i ,  
i E N, 
IIWZ(.)Il < fi, 
vs E c+. 
(5.44) 
In particular, (5.44) holds for all s = ju, w E R. Thus, the matrix A 
of (5.36) has all its eigenvalues in C-, and letting ~i = 1 / ~ ' ,  the transfer 
function W(s) in (5.39) satisfies condition (5.42). 
Q.E.D. 
We note that assumptions (5.4) concerning the pairs (8, 
Qi) are the 
same as those used in decentralized stabilization by static state feedback 
discussed in Sections 2.4 and 2.5. These assumptions make it possible to 
design local controllers that can stabilize the interconnected system inde- 
pendently of the size of the interconnections, so long they are bounded. 
They may be too restrictive, however, and one should try to obtain weaker 
constraints by a more detailed analysis of the effect of local controllers on 
the subsystems and their interconnections, as it was done for the case of 
state feedback in Section 2.5. We should also note that these assumptions 
can be a promising starting point for approaching the problem of subopti- 
mal design of local controllers, the state feedback version of which has been 
considered in Section 3.4. 
5.2. Structured. Almost Invariant Subspaces 
By recognizing the fact that interconnections among the subsystems 
can be considered as perturbations, Linneman (1985) and Willems and 
Ikeda (1984) derived conditions for decentralized stabilization using the 
concept of almost disturbance decoupling and small gain theorems in the 
context of almost invariant subspaces formulated by Willems (1981, 1982). 
Although the conditions are of connective stability type, they are parame- 
ter dependent because the relevant subspaces vary as functions of system 
parameters. One way to overcome this dependency is to select the cases in 

248 
6. Output Control 
which the relevant subspaces are invariant under parametric perturbations. 
This leads to investigation of the subspaces in the framework of structured 
systems (Hayakawa’ and Siljak, 1988). 
Our aim here is to present conditions for a structured system to have the 
property that the supremal Lp-almost invariant (controllability) subspace is 
generically the entire state space and that the infimal L,-almost conditional 
invariant (complementary observability) subspace is generically the zero 
space. In the next section, the conditions are reformulated in terms of 
directed graphs, which is consistent with our emphasis on the structural 
approach to decentralized control. 
Let us review first certain well-known results concerning a linear con- 
stant system 
S: j.=Ax+Bu, 
y = c x ,  
(5.45) 
where x(t) E X :  = Rn, u(t) E U :  
= Rm, and y(t) E Y :  = Re are the 
state, input, and output of S at time t E R, and X ,  U, 
and Y are normed 
vector spaces. With S we associate the following almost invariant subspaces 
(Willems, 1981): 
Vl,Ker 
Ri,Ker 
- the supremal Lp-almost invariant subspace ‘‘contained” in 
Ker C; 
- 
the supremal Lp-almost controllability subspace “contained” 
in Ker C; 
S:,Im 
NbIm 
- the infimal Lp-almost conditional invariant subspace “con- 
taining” Im B; 
- 
the infimal Lp-almost complementary observability subspace 
“containing” Im B . 
These spaces can be computed by the well-known algorithms 
Vk+l = Ker C n A-’ (Vk + Im B) , 
&+I = Im B + A(Ker C n &), 
VO = X ,  
SO = {0}, 
(5.46) 
and 
Vbf,,Ker c = V, + ‘%, 
(5.47) 

5.2. Structured Almost Invariant Subspaces 
249 
We recall that the triple (A, B, C), or the system S, is called standard 
when the matrix B has full column rank and C has full row rank, and state 
the following result (Morse, 1973): 
5.4. LEMMA. Let a triple (A, B, C) be standard. Then, the state-space 
X can be decomposed into four independent subspaces X I ,  X2, X3, and X4 
(ie., X = XI @ XZ 
@ X3 @ X4) such that 
(5.48) 
where Vn and Sn are defined in (5.46). Furthermore, there exist three non- 
singular matrices T, H, G and two matrices F, J such that 
IT-’ 
Y ’ J ]  [“In; A :] 
[ T 
O ]  
H 
FT G 
0 
0 
0 
0 
c3 
0 
0 
0 
0 
c 4  
(5.49) 
where the ni x ni matrix Ai corresponds to T-’Alx,T, i = 1, 2, 3, 4, and 
Bz, B4, C3, and C, have dimensions nz x m,, n4 x 9, 
x n3, and 
lp x 724. In (5.49), the matrix A1 is in the rational form, the pairs (A2, Bz) 
and (A;, Cr) are in Brunovsky canonical form, and the triple (C4, A4, B4) 
is in the prime canonical form. 
5.5. REMARK. We note that mp = lp because ((74, A4, B4) is prime. 

250 
5. Output Control 
From the above facts and, in particular, Equations (5.47) and (5.48), 
we can get the relations 
(5.50) 
N<:Im B = xl @ X2. 
By p( a ) ,  we denote-the rank of the indicated matrix, and we prove the 
following: 
5.6. THEOREM. Let the system S be standard. Then, 
(i) Vl,Ker = X if and only if 
(ii) R:,Ker = A' if and only if 
(iii) S& 
= (0) if and only if 
(iv) NbIm = (0) if and only if 
(5.51) 
(5.52) 
(5.53) 
(5.54) 
Proof. 
(i) From (5.50), 
= X is equivalent to saying that 
X, = (0) holds in Lemma 5.4, i.e., 713 = 0 in (5.49). Notice that the 
'In4 - A4 B4] in (5.49) have full row 
submatrices [sInn, - A2 B2] and 
rank for all s E C because (A2, Bz) is controllable and (C4, A4, B4) is 
[ 
c4 
0 

5.2. Structured Almost Invariant Subspaces 
251 
prime. Therefore, a necessary and sufficient condition for Vl,Ker = X to 
hold is that the matrix in the right hand side of (5.49) have full row rank 
for all s E C except at the eigenvalues of Al. From the above fact, and 
also from the nonsingularity of matrices 
assertion (i) is automatic. 
= X is equivalent to saying that XI = X3 = 
(0) holds in Lemma 5.4, i.e., nl = 723 = 0 in (5.49). Therefore the assertion 
(ii) is easy to see by relying on the full row rank of [ sIn2 - A2 Bz] and 
T-' 
T-'J 
[ 0 
H ] and [;* 
illthe 
(ii) From (5.50), Ri,Ker 
[ 5 k ; A 4  71. 
(iii) From (5.50), Si,Im = (0) is equivalent to saying that X2 = (0) 
holds in Lemma 5.4, i.e., 722 = 0 in (5.49). Therefore, the assertion (iii) 
c3 
0
'
 
follows from the full column rank of 
and by using the same argument as used in (i). 
= (0) is equivalent to saying that XI = X2 = 
(0) holds in Lemma 5.4, i.e., 721 = 722 = 0 in (5.49). Therefore, the assertion 
is trivial. 
Q.E.D. 
[ "n3 - 
and [ "7L"C; 
'41 
(iw) From (5.50), 
5.7. REMARK. Even if S is not standard, parts (i) and (ii) of The 
orem 5.6 hold when C = 0. In fact, if C = 0, (i) is trivial because 
Vi,Ker 
= X and (5.51) holds for l = 0. Furthermore, (ii) becomes the 
well-known rank condition for controllability because Ri,Ker is the con- 
trollable subspace. Similarly, (iii) and (iv) hold when B = 0, because (iii) 
becomes a trivial statement and (iv) becomes the rank condition for ob- 
servability, since NbIm is the unobservable subspace. 
Theorem 5.6 establishes the relationships between the almost invari- 
ant subspaces and system matrices for an important special case that is of 
interest in this chapter. In particular, the relationships are useful in for- 
mulating the generic properties of these subspaces in the graph-theoretic 
framework. 
In the context of structural analysis, instead of a system S and a triple 
(A, B, C), we consider a structured system S described by a triple of struc- 
tured matrices (A, B, e), 
each having a number of fixed zero elements while 
the rest of the elements are independent free parameters. The parameter 
space R" has the dimension u equal to the total number of the indeter- 
minate entries of A, B, and 6. When A, B and C are numeric matrices 
obtained from A, B, and 6 by fixing their indeterminates at some specific 
values in a set P c R", we write (A, B, C) E P. We need the following: 

252 
5. Output Control 
5.8. DEFINITION. Given a structured triple (A, B, c), 
we define: 
(i) The suprema1 Lp-almost invariant (controllability) subspace con- 
tained in Ker C is said to be generically equal to the whole state-space K ,  
which is denoted by 
A X ) ,  if there exists a proper 
algebraic variety V c R" such that, for any (A, B, C) E V", we have 
'b:Ker 
C = 
$ X (Ri,Ker 
(Ri,Ker C = 
(ii) The infimal &almost conditionally invariant (complementary o b  
servability) subspace containing Im B is said to be generically equal to 
the zero space {0}, which is denoted by Sl,Im 
(0) (A(&m 
(0)), 
if there exists a proper algebraic variety V c R" such that, for any 
(A, B, C) E V", we have Sl,Im 
Let us recall the notion of generic rank fi( a )  (Section 1.4). For a struc- 
tured matrix &f with the associated parameter space R", j(&f) = T if 
there exists a proper algebraic variety V c R" such that p ( M )  = T for any 
M E V". 
When we consider a structured triple (A, B, 6) with a parameter 
space R", and state that 
= (0) (n/,:], 
= (0)). 
we mean that there exists a proper algebraic variety V c R" such that, for 
any (A, B, C) E V" , we have 
p ( [ " I ;  A :I) 
= T ,  
for almost all s E C. 
(5.56) 
We also say that a triple (A, B, 6), or a system S, is standard if B has 
generic full column rank and 6 has generic full row rank. 
From Theorem 5.6 and Definition 5.8, the following result is automatic: 
5.9. THEOREM. Let a structured system S be standard. Then: 
( 2 )  Vi,Ker 
A X if and only if 
(ii) Ri,Ker A X if and only if 

5.3. Graph-Theoretic Characterization 
253 
(iii) SlqIm (0) if and only if 
6 ( [ ' I ;  A :I) 
= n + m, 
for almost all s E c; 
(5.59) 
( i ~ )  
A (0) if and only if 
ProoJ Obvious from Theorem 5.6, Definition 5.8, and the definition of 
generic rank. 
Q.E.D. 
The fact that the above generic rank conditions are difficult to test mo- 
tivates a derivation of their graph-theoretic interpretation. This we consider 
next. 
5.3. Graph-Theoretic Characterization 
We first introduce some basic notation concerning the system graph. 
With a structured system S ,  we associate a directed graph (digraph) D = 
(V, E), whereV = U x X x Y  isaset ofverticesandu = {ul, 
'112, . . . , urn}, X = 
(21, XZ, . . . , xn}, and Y 
{yl, y2, . . . , ye} are the input, state, and output 
vertices. E = {(uj, xi): bij $ 0) U {(xj, xi): ziij $ 0) U {(xj, yi): Gj $ 0) 
is a set of edges, where ziij, &, and &j are the elements of the structured 
matrices A, B, 
and c. A set of vertices V, and edges E, of a subgraph D, = 
(V,, E,) are denoted by V(D,) and E(D,), respectively. A path from the ver- 
tex w1 to the vertex vk is a subgraph PEf with a set of vertices V(PEf) = 
{wl, 2r2, .. ., q.) and a set of edges E(P;f) 
= {(q, 
u2), (w2, w3), ..., 
( u ~ - ~ ,  
uk)). When the initial vertex u1 or the terminal vertex vk, or both, 
are not essential, we use the notation P ' k ,  P,,, or P, depending on the 
context. The length of a path P is the number of elements in E(P). A 
subgraph is called a cycle c if V(c) = {q, 
v2, . . . , ?+) and E(C) = 
{(VI, u2), (212, 
.. ., ('74-1, uk)r 
(Ukr 211)). Subgraphs D1, D2, . . . , D, are 
mutually disjoint if V(Di) n V(Dj) = 0 for i # j. 
Of special interest in our consideration is the notion of a matching in 
a digraph D = (V, E) (e.g., Chen, 1976). A subgraph is called a matching 
from a set of vertices VJ, = {wil, wia , . . . , vik} to a set of vertices VJ, = 
{q,, 
wj,, . . . , vjk}, which we denote by M(VI,, V J ~ ) ,  
when it consists of k 

254 
5. Output Control 
mutually disjoint paths from VI, to V J , .  The length of a matching is the 
sum of the lengths of the corresponding paths, and we have the shortest 
matching M*(Vlk, V J ~ )  
when we chose the shortest paths. Note that for 
given sets of VI, and V J ~ ,  
the shortest matching and, thus, any matching 
need not be unique. 
The following result provides a graph-theoretic characterization of the 
parts (2) and (iii) of Theorem 5.6: 
5.10. THEOREM. Let a structured system S be standard. Then: 
(2) 
V;,Ker 
X if and only if there exists a matching M(UI,, Y) in D; 
(ii) Si,Ker A (0) if and only if there exists a matching M(U, YJ,) 
in D. 
Prooj (i) Suficiency: Without loss of generality, we can assume that 
there exists a matching M({ul, u2, . . . , ue), Y) in D. Let k be the total 
length of the shortest matching M*({ul, 212, . . . , zit}, Y), and denote a set 
of all the shortest matchings from ('1~1, u2, . . . , ue} to Y by M*. Then it is 
straightforward to verify (Chen, 1976) that 
DS€M* 
where BI is a submatrix of B, which is composed of the first e columns of 
B, 
p denotes the u dimensional vector in the associated parameter space, 
and f( *) denotes the product of all nonfked entries of A, B, 
C? correspond- 
ing to all edges contained in the indicated subgraph. Notice that all the 
f(Ds)'s in (5.61) are monomials of p ,  and it holds that f(Ds,) $ f(Ds,) 
for D,,, D,, E M*, D,, # Ds,. This implies that ao(p) in (5.61) is not 
identically zero as a polynomial of p because M* is not empty by assump 
tion. Therefore, a set V = { p  E R': 
ao(p) = 0) is a proper variety in 
the parameter space, and it follows from (5.61) that for any (A, B, C )  E 
V", 
det 
is not identically zero as a polynomial of s, i e . ,  
1 
s I , - A  
BI 
0 
L 
J 
for any (A, B, C) E V", 
the rank of 
is equal to n + e for 
almost all s E C. From this and Theorem 5.6 (i), we get Vi,Ker 
A X. 

5.3. Graph-Theoretic Characterization 
255 
Necessity: From Theorem 5.6 (i), V& 
4 K implies that there exists 
at least one (A, B, C) E R" such that ["In; A 
has full row rank 
has at least 
for almost all s E C. This fact implies that 
one minor with order n + I that is not identically zero as a polynomial of 
s and p .  Therefore, without loss of generality, assume that the minor that 
consists of the first n1 columns of ["In; '1 
and the first 722 columns of 
[ :] 
(nl + n2 = n + I ,  n1 5 n, 122 2 I )  is not identically zero. In other 
words, det I? f 0, where f' is an (n + m) x (n + m) matrix defined by 
1 
- r = ___ 
(5.62) 
- 0 i  0 
Observe (Chen, 1976) that det f' f 0 if and only if the Coates graph 
Gc(f'), which is associated with the matrix f', has a spanning subgraph 
H = C1 U . . . U C,, where the C2's are mutually disjoint cycles. Notice that 
G,(f') is identical to a digraph that is obtained from D as follows: Add 
(m-I) nodes yt+l, . . . , ym and edges (z2, 2,) for i = 1, . . . , n, ( z ~ ~ + ~ ,  
ye+J) 
for j = I . .  . , m - I ,  (unz+kr ynz+k) for k = 1, . . . , m - n2, to D, and then 
identify u, with yz for i = 1, 2, . . . , m. Therefore, it is easy to verify that the 
existence of the subgraph H in G,(F) implies the existence of a subgraph 
D, = Ptf, U P;;, . . . U Pif, in D, where the Pz3 's are mutually disjoint. 
Notice that the subgraph D, is a matching M(Ulp, Y). 
Q.E.D. 
(ii) We omit the proof because it is similar to that of (2). 
5.11. REMARK. The statement ( i )  implies that the number of inputs 
should be greater than or equal to the number of outputs of S. For (ii) to 
take place, the number of inputs should be less than or equal to the number 
of outputs. 
Before proving the main result of this section, we briefly review some 
results (Matsumoto and Ikeda, 1983; Aoki et al. 1983) on structured con- 
trollability for a linear system in descriptor form 
22 K+(t) = Lp(t) + Mw(t) , 
(5.63) 

256 
5. Output Control 
where cp(t) E R"and w(t) E RP are the descriptor state and input of El 
and K, L, and M are numerical matrices of appropriate dimensions. 
Associated with the system Z and the triple (K, L, M ) ,  consider a 
structured system 3 
described by a triple of structural matrices (I?, i, fi). 
Notice that the generic rank of K is not necessarily equal to T ,  but 'it is 
assumed that s K  - is a regular pencil generically. Let q be the degree of 
det(sk - i) with respect to s. Then, it is easy to verify that there exist 
two permutation matrices Q 1  and Q2 such that 
where fq is a q x q structured diagonal matrix. With the system 3, 
we 
associate a digraph Dc = (Vc, Ex), where the set of vertices Vx is defined 
as Vc = QUO, with CP = {cpl, 9 2 ,  . . . , cpT} and R = { W I ,  w 2 ,  . . . wp}. The 
set of edges Ec is defined as Ex = {(wj, pi): &:j $ 0 )  & {(cpj, cpi): iij $ 0  
or .& f 0}, where ej, ej, and fklj indicate the ( i , j )  entries of K ,  L', and 
M ,  
respectively. With these preliminaries, the following result on structural 
controllability for linear systems in descriptor form has been obtained in 
(Matsumoto and Ikeda, 1983): 
5.12. LEMMA. The following two conditions are equivalent: 
(2) 
~ ( [ S K  
- i 121) 
= r, 
for all s E C. 
(ii) The following two conditions hold: 
( i i l )  P([i fi]) = r; 
( i i 2 )  
the nodes cp1, . . . , cpq among CP = {cpl, . . . , cpql . . . , cpT} are 
reachable from the R-nodes in Dc. 
Next, we prove two more lemmas which we need for our main result 
(Theorem 5.15). 

5.3. Graph-Theoretic Characterization 
257 
5.13. LEMMA. 
if and only if 
= n + t, 
for all s E C. 
(5.66) 
Proof Suficiency: trivial. 
Necessity: (5.66) implies that there exist a quadruple (Eo, Ao, Bo, Co) 
E S : = 
)IE-EoII +IIA-AolJ +IIB-BoJI +IIC-COII < f}, 
and a positive number E such that, for any (E, A, B, C) 
{(E, A, B, C) E 
where R” is the associated parameter space of (A, B, 6) and E is diagonal. 
Therefore, we can always find a quadruple (El, Al, B1, C,) E S with El 
being nonsingular. 
This implies that 
Notice that (ET’A1, ET‘B1, Cl) E R” because E,’ is diagonal. Thus, 
(5.65) follows. 
Q.E.D. 
To prove the following lemma, we need to use a subgraph P, = P,!’ U 
Puj2 U. .UPujp that is a union of mutually disjoint paths from vertices in U 
to arbitrary vertices of X. Similarly, P, = P’al u Pus, u. . -u 
Pya, is defined 
with respect to X and Y. Finally, we need a subgraph C, = ClUC2 U. .U C, 
that is a union of mutually disjoint cycles of D. 
(5.69) 

258 
5. Output Control 
QT 
0 
[ 0 .] [: :] [: 
I(:]= 
if and only if there exists a subgraph D, = P, U C, U M(UI,, Y) in D such 
that V, 2 X and P,, C,, and M(UI,, Y) are mutually disjoint. 
Prooj Necessity: By the same argument which we used in the proof 
of the necessity part of Theorem 5.10 (i), (5.69) implies that graph G,(A) 
has a spanning subgraph H = C1 u . . . U C,, where the Ci’s are mutually 
disjoint cycles, and A is an (n + m) x (n + m) matrix defined by 
-AM 
0 
0 
BM 
0 
0- 
I 
0 
Ap 
0 
i
0
 B p O  
0 
0 
Ac 
j 
0 
0 
0 ’ 
----------------------,-
I 
- C M  0 
0 
\ 
0 
0 
0- 
- 
A =  
(5.70) 
where 
AM = 
Nel 
0 
0 Nee 
, 
b M =  
7 

5.3. Graph-Theoretic Characterization 
259 
1- 
0- 
, 
B P =  
(5.72) 
and Ni, el, e:, and Ni are i x i, i x 1, 1 x i, and i x i matrices defined as 
0 
1
0
 0 
0 
... 
... 
0 
1 
0 
1 0 
I 
0 
1 
0 
(5.73) 
This implies that we have found a triple (A, B, C) E R” such that 
p ([ 
Q.E.D. 
1) = n + l. Thus (5.69) is satisfied. 

260 
5. Output Control 
Finally, we are ready to present the main result of this section, obtained 
by Hayakawa and Siljak (1988): 
5.15. THEOREM. Let a structured system S be standard. Then, 
(i) Ri,Ker 
X if and only if the following two conditions hold: 
(i1) There exists a subgraph D, = P, U C, U M(Ur,, Y) in D such 
( i 2 )  For any vertex z E X - V(M*), there exists a matching M(UI, U 
that V, 3 X and P,, C,, and M(UI,, Y) are mutually disjoint; and 
{u}, 
Y U {z}) in D for some u E U, and M* = M*(Ul,, Y). 
(ii) 
A (0) if and only if the following two conditions hold: 
(221) There exists a subgraph D, = P, U C, U M(U, Y J , )  in D such 
( i i 2 )  For any vertex z E X - V(M*), there exists a matching M(U U 
that V, 2 X, and P,, C,, and M(U, YJ,) 
are mutually disjoint; and 
{z}, Y J ~  
U {y}) for some y E Y, and M* = M*(U, YJ,). 
Proof. Only part (i) will be proved because part (ii) can be derived by 
duality. 
Necessity: Assume that Ri,Ker 2 X. Then, it follows from Theo- 
rem 5.9 (ii) and Lemma 5.13 that a structured system 2, i.e., a triple 
(I?, L, &?), satisfies condition (i) of Lemma 5.12, where 
where B = [BI BII]. Therefore, condition (ii) of Lemma 5.12 follows. 
By Lemma 5.14 it is easy to see that condition (iil) of Lemma 5.12 
implies condition (21) of Theorem 5.15. 
Next, we will prove that condition ( i i 2 )  of Lemma 5.12 implies condition 
(22) of the theorem under condition (iil) of Lemma 5.12. To do this, we 
need to investigate a relationship between the two digraphs Dc and D. 
Recall that condition (iil) of Lemma 5.12 implies condition (il) of the 
theorem. Therefore, without loss of generality, we can assume that there 
exists a matching M((u1, u2, . . . , ut}, Y) in D, and a shortest matching is 
M* = Pi; u . . . U PE', , where the length of P;; is li for i = 1, . . . , !. Let 
q = n - Ef=, 
l i .  Notice that q is the degree of det [& - L] with respect 
to s. Furthermore, without loss of generality, it can be assumed that A, B, 

5.3. Graph-Theoretic Characterization 
261 
and 6 have the following structures: 
B =  
where &, &, and & are l i  x 4, 
t i  x 1, 1 x ei structured matrices for i = 
1, . . . , ! 
defined as 
I 
A.. - 
22 - 
X 
X 
X 
€9 
@ 
0 
@ 
‘ X  
& = [ O  
... 0 
@], 
1 
€9 
& t i =  [ :j 
(5.76) 
where the € 9 ’ ~  represent the nonfixed entries, the 0’s represent the fixed 
(zero) entries, and the X’S represent either the nonfixed or the fixed entries. 
Notice that the 0’s in Aii, &, and Ezi are due to the fact that M’ is the 

262 
5. Output Control 
shortest matching, and &, is a q x q structured matrix. From (5.74) and 
(5.75), we can choose Q1 and Q2 in (5.64) as follows: 
QI = 
Q 2  = 
7 
(5.77) 

5.3. Graph-Theoretic Characterization 
263 
Therefore, by introducing the following notation about X-nodes of D and 
X-nodes of Dx: 
(5.78) 
we get one-to-one correspondence between E: = E U { ( x i ,  xi)li = 1, . . . , n} 
and Ex a~ follows: 
for 15 i 5 C, 
for C + l < i < m ,  
(5.79) 
F’rom the above relation between D and Dc, it is easy to verify that con- 
dition (ii2) of Lemma 5.12 implies condition (i2) of the theorem. 
Suficiency: Omitted because we can use the proof of necessity part in 
the reverse order. 
Q.E.D. 
5.16. REMARK. Condition (i) of the above theorem has two parts that 
correspond to the generic rank and input reachability properties of struc- 
tural controllability (Section 1.4). Similarly, condition (ii) resembles the 

264 
5. Output Control 
-0 0 0 0 0- 
* o o * o  
A = o * * o o ,  
o o o * o  
-0 * 0 0 0- 
Fig. 5.1. Digraph D for Example 5.17. 
‘* 
0- 
0
0
 
B = O O ,  
o *  
-0 0- 
structural observability conditions. It is not surprising, however, that The- 
orem 5.15 is more complex because it deals with both inputs and outputs 
simultaneously. 
We illustrate Theorems 5.10 and 5.15 by several examples. 
5.17. EXAMPLE. Consider a structured system S with the matrices 
- 
[ o o * o  
C =  
L o o 0 0  “1 
* , 
(5.80) 
where as usual * represent an independent real number, and the 0’s are 
“hard zeros.” The corresponding digraph D is shown in Figure 5.1. It is 
easy to see that there exists no matching from U = { u ~ ,  
u2) to Y = {yl, yz} 
and, therefore, we conclude from Theorem 5.10 that 
2 X does not 
hold. An implication of this fact is that the system & has no inverse no 
matter what the values of the free parameters are. 

5.3. Graph-Theoretic Characterization 
265 
5.18. EXAMPLE. Let a system S be specified by 
* 0 0- 
0
0
0
 
o * o  
0
0
0
 
0
0
0
 
0 * *- 
- 
A =  
1 
- 0 0 0 0 0 0  
* o o o o o  
0
0
0
0
0
0
 
o o * o o *  
o * o * o o  
. o o o o o *  
- 
, 
B =  
c=[: ; ," ," 1 ,"I. 
(5.81) 
From digraph D of Figure 5.2, we see that there is a matching M((u1, u2}, 
{yl, 9 2 ) )  
= Pc U PE;, with PE; 
= 
(211, 21, 2 2 ,  y1) and Pg; = 
(uz1 2 3 ,  2 4 ,  2 5 ,  y 2 ) .  By Theorem 5.10, Vl,Ker A X .  However, when we con- 
sider R;,Ker c, we find that condition (i) of Theorem 5.15 is not satisfied. 
Although (21) is satisfied by M({q, uz}, {yl, y2)) and a self-loop at 26, 
condition (iz) fails to hold. In fact, M*({uI, uq}, {yl, yz)) = PGUPE; with 
PEf = (u1, 2 1 ,  Y2) and p;: = (212, z3? 2 4 ,  2 5 , Y i ) ,  and x-V(M*) = ( 2 2 ,  26}, 
{yl, y 2 ,  5 2 ) )  for 2 2  does not exist. 
If we modify the digraph D of Figure 5.2 by moving the input u3 from 
.state 5 6  to 2 2 ,  as shown in Figure 5.3, we can establish the condition 
Rb,Ker 
SO that We have M(('LL1, u 2 ,  US), {Yl, 927 2 6 ) )  for 2 6 1  but M({Ul, 212, u3)r 
2 X .  The new matrix B, which is given as 
- 
B =  
* o o  
o o *  
o * o  
0
0
0
 
0
0
0
 
o * o  
1 
(5.82) 
leaves the set of vertices X - V(M*) = ( 2 2 ,  26) unchanged, but the two 
matchings mentioned above are now present. The reason is that, by moving 
113 to 2 2 ,  we create the path Pz; = (ug, 2 2 ) ,  which provides two required 
matchings in the modified graph D of Figure 5.3. 

266 
4 
5. Output Control 
XI 
Fig. 5.2. Digraph D for Example 5.18. 
Y1 
Y2 
Fig. 5.3. Modified digraph D for Example 5.18. 

5.4. Decentral Stabilizability 
267 
5.19. REMARK. Special properties of almost invariant spaces are es- 
tablished by the existence of shortest matchings in a digraph D. This is 
computationally attractive because there are efficient algorithms for maxi- 
mum flow in transportation networks that apply directly to this task (see, 
for example, Swamy and Thulasiraman, 1981). In fact, first add the source 
vertex s and the sink vertex t to D, then add edges from s to every node in 
U and edges from every vertex in Y to t. Finally, assign capacity 1 to every 
edge of the newly formed digraph, and apply any variant of the well-known 
Ford-Fulkerson’s algorithm to get the desired result. Another way to test 
a directed graph for the existence of appropriate matchings is the generic 
rank test described in the Appendix. 
5.4. Decentral Stabilizability 
We now apply the obtained graph-theoretic conditions to determine 
when structured interconnected systems can be stabilized by decentralized 
controllers. For simplicity in presentation, we consider an input and output 
decentralized system composed of only two subsystems. An extension of 
the results obtained to the general case is obvious, but may involve some 
combinatorial representations (Young, 1985). 
Let us consider an interconnected system 
yz = CZXZ, 
where xi(t) E X,: = Rni, ui(t). E Ui: = Rma, and gi(t) E J’i: = Re* are the 
state, input, and output of the ith subsystem 
Si: Xi = A i ~ i  + B i ~ i ,  
yi = cixi, 
2 = 1, 2. 
By using local controllers with dynamic output feedback 
(5.84) 
(5.85) 

268 
5. Output Control 
we obtain the overall closed-loop system 
(5.86) 
which is an interconnection of two closed-loop subsystems 
Ai + Bi KiCi 
Bi Hi 
sa: [ 3 
= [ 
] [ z:] , 
i = 1, 2. 
(5.87) 
GiCi 
Fi 
In the context of connective stability (Section 2.1), we state the follow- 
ing: 
5.20. DEFINITION. An interconnected system S is said to be decen- 
trally connectively stabilizable if there exist controllers C1 and C2 such 
that the closed-loop system S and subsystems S 1  and S 2  are simultane- 
owly asymptotically stable. 
The following lemma is a direct consequence of the result obtained by 
Willems and Ikeda (1984). In the lemma, we compute almost invariant 
subspaces relative to subsystems Si = (Ai, Bi, Ci). Then, by Ri,KerH 
and 
h
l
b
,
~
~
~
 
w.r.t. Si, we denote the suprema1 &almost controllability subspace 
contained in Ker H computed relative to (Ai, Bi), and the infimal Lo- 
almost complementary observability subspace containing Im G computed 
relative to (Ail Ci), respectively. We also recall that a system S is complete 
if it is controllable and observable, and prove the following: 
5.21. LEMMA. An interconnected system S is decentrally connectively 
stabilizable if one of the following conditions hold: 
( 2 )  S1 is complete and 
(ii) S2 is complete and 

5.4. Decentral Stabilizability 
269 
Proof. &call (Willems and Ikeda, 1984) that an interconnected system 
S is decentrally connectively stabilizable if S1 is stabilizable and detectable, 
S2 is stabilizable, and 
where V:Ker 
A 
is the suprema1 asymptotically stable invariant subspace 
contained in K% A12. Therefore, it is obvious that the system S is decen- 
trally connectively stabilizable if condition ( i )  of the lemma holds. Condi- 
tion (ii) is also derived from Willems and Ikeda (1984). 
Q.E.D. 
With a system S of (5.83), we associate a structured system S defined 
by the corresponding structured matrices. We assume that B 1  and B 2  have 
generic full column rank, and 61 and 6 2  have generic full row rank, and 
state the following: 
5.22. 
A structured interconnected system S is said to be 
decentrally connectively stabilizable if there exists a proper variety V c R” 
such that, for any (Ail Bi, Ci, Aij; i ,  j = 1, 2) E Ve, the system S is 
decentrally connectively stabilizable. 
DEFINITION. 
Before we state the main result of this section, we need to clarify some 
facts regarding the interconnection matrices Aij. Note that, in Lemma 5.21, 
the matrices Aij do not necessarily have full rank. Thus, the structured 
matrices 2, need not have generic full rank either. In order to provide a 
structured version of Lemma 5.21, we have to modify the matrices A, to 
obtain corresponding structured matrices having generic full rank. Let a 
be a p x q matrix such that b(M) = g. Then, A? is an g x q submatrix of 
M with F(A?) = g, which can be obtained by removing p - g rows of M .  
Similarly, we use &P of dimension p x g and b(@) = g columns of M .  For 
example, if 
* o o  
M = [ Z  * 0 :I1 
0
0
0
 
then any of the submatrices 
(5.91) 
[o * 0 0 1 ,  [o * 0 0 1 ,  [o * 0 *I 
(5.92) 
o * o *  
o o o *  
o o o *  

270 
5. Output Control 
is a candidate for I@. 
However, @ is the unique submatrix composed of 
the second and fourth column of k. 
We also use D(A, B, C) to identify 
the digraph D of a structured system S having the triple (A, B, c). 
The main result of Hayakawa and Siljak (1988) is: 
5.23. THEOREM. A structured interconnected system S is decentrally 
connectively stabilizable if one of the following conditions hold: 
(i) S 1  is structurally complete, and the digraphs D(A2, &, &2) and 
D(&, 
6 2 )  satisfy conditions (i) and (ii) of Theorem 5.15, respec- 
tively; 
(ii) SZ is structurally complete, and the digraphs D(A1, &, &l) and 
D(A1, 
81) 
satisfy conditions (i) and (ii) of Theorem 5.15, respec- 
tively. 
Proof. From Lemma 5.21 and Definition 5.22, it is easy to see that the 
structured interconnected system S is decentrally connectively stabilizable 
if one of the following two conditions holds: 
(i) S1 is structurally complete and 
(ii) S2 is structurally complete and 
Notice that (5.93) and (5.94) are characterized in terms of associated sys- 
tem graphs in Theorem 5.15. Therefore, the assertion is trivial. 
Q.E.D. 
5.24. EXAMPLE. To illustrate the application of Theorem 5.23, let us 

5.4. Decentral Stabilisability 
271 
consider a system S described by the following triple (a, B, 6'): 
I 
1 
' 0  0 o i o  0 0 
* 0 
* j *  
0 0 
0 0 o j o  * 01 
(5.95) 
The corresponding digraph D(A, B, 6') is given in Figure 5.4. 
It is easy to see that 
A+[* 
0 * ] ,  &=[!I. 
(5.96) 
Therefore, we get the digraphs D(A1, B1, &) and D(A1, &z, 6.1) as shown 
in Figure 5.5. Since S z  is structurally complete, from Figure 5.5 and con- 
dition (ii) of Theorem 5.23, we conclude that the system S specified by 
(5.95) is decentrally connectively stabilizable. We note that the digraph 
D(a, B, 6') of Figure 5.4 does not satisfy condition (i) of Theorem 5.23. 

272 
5. Output Control 
I 
I 
YI 1 
YlZ 
YZl 
Fig. 5.4. Digraph D(A, B, c) for Example 5.24. 
5.5. Adaptive Control 
We have shown that an effective way to handle uncertainty in com- 
plex systems is to use decentralized feedback. So far, however, feedback 
gains have been constant even though systems have been nonlinear and 
time-varying. Gain settings have been usually high to meet the worst case 
constraints. A considerable improvement in the gain allocation as well as 
performance of the closed-loop system can be achieved using adaptive de- 
centralized feedback. 
Let us consider again the system S composed of N subsystems 

5.5. Adaptive Control 
273 
Y 
Y11 
Fig. 5.5. Digraph for Example 5.24. (a) (&, &, 
(b) D(&, &*, El). 

274 
5. Output Control 
where the interaction function f: R x Re + Rmi is defined now as a function 
of time as well: 
ui = fi(t, w), 
z E N. 
(5.97) 
The overall system S can be written in a compact form 
S: X = A X + B Z L + P U ,  
y = c x ,  
(5.98) 
w = Qx, 
where z(t) E R", u(t) E RN, and y ( t )  E RN are the state 2 = (zy, zf, 
. . ., 
x ; ) ~ ,  input u = (uT, 
uf, 
. . . , u ; ) ~ ,  
and output y = (yr, yr, . . . , yz)T of 
S at time t E R. The constant block diagonal matrices 
A = diag{Al, A2, ..., AN}, 
B = diag{bl, b2, . . . , b ~ } ,  
C = diag{c,, c2, . . . , c;}, 
P = diag{P1, P2, . . . , PN}, 
T
T
 
(5.99) 
Q = diag{Qi, Qz, . . . , QN) 
have appropriate dimensions. The vectors u(t) E R" and w(t) E Re, which 
are defined as u = (u?, u r ,  . .. , uN) and w = (w?, w2, .. . , w;)~, are 
interconnected as 
T T  
21 = f ( t ,  w). 
(5.100) 
The function f :  R x Re ---f R" is continuous and bounded in both ar- 
guments, and sufficiently smooth so that the solution z(t; to, 20) of S is 
unique for all initial conditions (to, Q) E R x R" and all piecewise continu- 
ous inputs u( 
a ) .  In particular, we assume that there exist nonnegative, but 
unknown, numbers Eij such that 

5.5. Adaptive Control 
275 
We assume that the dynamics of the subsystems Si are also unknown. 
That is, the matrices Ai and the vectors bi and q are not specified, save 
for the fact that the pairs (Ail bi) are controllable and the pairs (Ai, ci) are 
observable. This assumption guarantees a choice of the coordinate system 
such that the matrices of the decoupled systems have the companion form 
0 
1 
0 
... 
0 
0- 
(5.102) 
. . . 
. . . . . . . . . 
-ai 
-a; 
-a; 
. . . -a;, 
Ai = 
CT = [CZ; 4 ... CL;] 
The uncertainty about subsystems Si, which is reduced to the unspecified 
coefficients of Ai, bi, and G ,  compounds the essential uncertainty about the 
overall system S caused by our ignorance of the interconnections. 
A measure of performance for S is provided by a set of local reference 
models 
Mi: Xmi = Amixmi i- bmiril 
ymi = c:ixmi, 
(5.103) 
which have the same dimensions as the corresponding subsystems Si, as 
well as stability characteristics we would like the subsystems to have. By 
stacking up the individual models Mi, we obtain a reference model M for 
the overall system S: 
i E N, 
M x, = Amxm + bmrl 
ym 
cgxm, 
(5.104) 
where r(t) E RN is the external (reference) input of M. As in (5.99), we 
have 
Am = diag{Aml, Am27 . . . , AmN), 
B m  = diag{bmi, bm2, . * .  3 bmN}, 
(5.105) 
T
T
 
T 
c m  = diag(cm1, cm2 1 . . . 1 CmN) 
Local coordinates can be chosen so that the triples (Amil bmil Ci) 
are 
in the companion (controller) canonical form as in (5.102). Obviously, in 

276 
5. Output Control 
these coordinate frames we can choose vectors Icf E R"*, k& E R such that 
We do not know these model-matching parameters simply because we 
do not know the subsystems dynamics. All we assume is that we know the 
sign of bi and, without loss of generality, can set k& for all i E N. This is 
all well, because the presence of interconnections makes the ideal settings 
usually higher than those of isolated subsystems. This fact suggests that 
a decoupled set of local models may not be the best model for the overall 
system. Interconnected models were used in an early paper by Yoshikawa 
and Ikeda (1983), and may yet prove to result in a better performance of 
an adaptive system when nominal interconnections are different from zero 
and known a priori. 
In this section, we start with the state regulation problem of a class of 
decentralized stabilizable systems, whose coupling parameters are within 
the range of the control inputs. This means that each matrix Pi can be 
factored as 
P, = hip?, 
i E N, 
(5.107) 
for some constant vector pi E Rma. This is the structural condition (5.4), 
which is essential for decentralized adaptive stabilizability when the size of 
interconnections is unknown. 
To drive the state of S to zero we choose local state control laws 
ui = eixi, 
T 
i E N, 
(5.108) 
where &(t) E R"a is the time-varying adaptation gain vector at time t > to. 
To arrive at a suitable adaptation law for &(t), we choose the Ami's as 
stable matrices, so that for any symmetric positive definite matrix Gi there 
exists the unique symmetric positive definite matrix Hi as the solution of 
the Liapunov's matrix equation 
A ; ~ H ~  
+ H
~
A
~
~
 
= G ~ .  
Then, we define ki E Rn' as 
ki = Hibmi, 
(5.109) 
(5.110) 
and propose to use the local adaptation laws 
ei = -ri (k; x i )  xi, 
(5.11 1) 
where ri is an ni xni constant symmetric positive definite matrix and Oi(t0) 
is finite. 

5.5. Adaptive Control 
277 
Finally, the closed-loop system is described as 
s: i i  = (A,i + bi&)Xi + b. aPi Tf. a )  
& = -ri(i:zi)zil 
(5.112) 
where $i(t) E Rni is the ith parameter adaptation error at time t E R, 
which is defined as 
4. 
a -  - 6. 
1 - Or 
$ 1  
(5.113) 
and 6: = kt with kf choseh as in (5.106). Relying on the decentralized stabi- 
lizability ensured by condition (5.107), which was established in Section 5.1, 
we define 4 = (@, Cpz','. . . , $c)T, 
denote the state of S as (5, $) E R" x R", 
and prove the following: 
5.25. THEOREM. The solutions (x, 4)(t; to, XO, $0) of the system S are 
globally bounded, and x(t; to, 20, 40) -+ 
0 as t -+ 00. 
Proof. We define a function u: R" x R" -+ 
R+ as 
where the number p > 0 is not yet specified. The total time derivative 
i/(x, 4) of the function u(x, $), which is computed with respect to (5.112), 
is obtained as 
fi(x, 4) = -xTGx - 2pxTKTKx + 2xTKTPf, 
G = diag{k&G1, k&Gz, . . . , ~ ~ N G N } ,  
P = diag{p?, P?, * .  ., P',}, 
K = diag{kr, k:, . . . , i',}. 
(5.11 5) 
where 
(5.116) 
Completing the square in (5.115), we get 
fi(x, 4) = - xTGx - pxTKTKx - ~ ( K x  
- p-'pf)T(l?z - p-'pf) 
+p-'fTPTPf. 
(5.117) 

278 
5. Output Control 
By using the boundedness assumption (5.101) concerning f(t, w), we get 
from (5.117) the inequality 
where Am(G) is, as usual, the minimum eigenvalue of G, and < = 
N maxif,N &j. By selecting a sufficiently large number p* so that 
P* > ~&'(G)<zll~l12 
11Q112, 
(5.1 19) 
we get i.(x, 4) 5 0 for all (t, z, 4) E R x R" x R". Using standard arguments 
from the Liapunov's theory (e.g., Rouche et al. 1977), we conclude that the 
solutions (x, 4)(t; to, ZO, 40) are bounded. 
From the boundedness of solutions and definition (5.114) of v(z, c$), we 
conclude that fi(x, 4) is uniformly continuous on R x R" x R". Furthermore, 
the function v(t) = v[z(t), 4(t)] is decreasing and is bounded from below. 
Hence. 
lim v(t) = inf v(t) = vf 2 0. 
(5.120) 
t-oo 
t 
Denoting i.(t) = i.[x(t), +(t)], 
we have 
(5.121) 
where YO = v(x0). Then, from (5.114), (5.118), and uniform continuity 
of fi(t), we have limt+oo b(t) = 0, and limt,, 
x(t; to, 20, 40) 
= 0 for all 
(to, 20, 40) E R x R" x R". 
Q.E.D. 
5.26. REMARK. First, note that we did not use the M-matrix condi- 
tions of Theorem 2.4, because the structural condition (5.107) is all we need 
for stability. Second, it is not necessary to know or choose the p* of (5.119). 
The local gains rise to whatever level is necessary to compensate for the 
effects of fluctuating size of interconnections. These are pleasing facts when 
the size and characterization of interconnections are neither known nor can 
be predicted during the operation of the overall system. 
5.27. REMARK. The boundedness part of Theorem 5.25 provides for 
realizability of the proposed adaptive scheme. 

5.5. Adaptive Control 
279 
In the state tracking problem, it is required that the state x(t) of the 
plant S follows the state of the reference model M despite the fluctuat- 
ing interaction levels among the subsystems Si. Let the tracking error be 
defined as 
e ( t )  = x(t) - zm(t), 
(5.122) 
where e = (ey, e;, . . . , e;)T and e,(t) E Rnz is the tracking error of the 
subsystem Si at t E R. To drive the error toward zero, we use the local 
control laws 
where 
and 
T 
ui = ei w,, 
T 
T T  
vi = (ei , ri ) . 
(5.123) 
(5.124) 
(5.125) 
The gains ki and koi represent the estimates of kf and k&. 
5.28. REMARK. In this scheme, it is crucial to utilize, in the state re- 
gressor vi, the tracking error ei as proposed in (Gavel and Siljak, 1989), 
rather than the state xi, as it was used in centralized (Narendra and Vala- 
vani, 1978) and decentralized (Ioannou, 1986) adaptive control. 
The resulting closed-loop system is 
where we have defined q5i(t) as in (5.113), and 
8,' = (@, k&)? 
(5.127) 
Subtracting (5.104) from (5.126), we can write the error system as 

280 
5. Output Control 
where u > 0. The adaptation law was chosen as 
8, = -ri(LTei)ui - uriei, 
i E N, 
(5.129) 
which incorporates the "u-modification," as originally suggested by Ioan- 
nou and KokotoviC (1984). By (e, 4) E R" x R", we denote the state of Se 
and prove a result of Gavel and Siljak (1989). 
5.29. THEOREM. 
globally ultimately bounded. 
The solutions (el #)(t; to, eo1 40) 
of the system S, are 
Pmof. We use the same type of function v: R" x R" + R+ as in (5.114): 
where 8i = (kT,O) E Rni+l, and p is a positive number. Using (5.128), we 
compute 
where we have used the fact that eTui = LTei. Utilizing the block notation 
(5.116), (5.131) can be written as 
(5.132) 
- 2 4 4  + pQT(@ + pe) - 2 4 4  + @IT(e* - pe), 
where K* = diag{kiT, kzT, . . . , kkT}. Since f(t, w) = f [ t ,  Q(e + x,)] is 
bounded as in (5.101), we can use 
N 
IIfi(t, w)II 5 C<ijIIQjII 
(IIeiII + IIzmiIO 
(5.133) 
j=1 

5.5. Adaptive Control 
281 
in (5.132) to get the inequality 
fi(e, 4) I - eTGe - 2p)lRejJ2 + 2))ke)l JIK'TzCm)J 
+ 2t11 kell I1 PI1 I1 911 (IIeII + llzmll) - 241 4 + d l  ' 
+ 2.114 + pel1 118' - PSI/, 
~ ( t ,  
e, 4) E R x R" x R". 
(5.134) 
After completing the squares involving Re and 4 + pe, and dropping neg- 
ative terms, we obtain 
+ P - l x  (I1 K*ll + rll PI1 I1 Qll) + all 8* - pel1 
V(t, el 4) E R x R" x R", 
(5.135) 
where x = supt 11 z, 
(t) 11 2. 
Equation (5.135) can be written compactly as 
where the constants C and 77 are defined by 
C = L ( G )  - ~ - ~ 5 ' 1 l ~ I l '  
IIQII', 
q=~-~x(lIK'lI + t l l ~ l l  
IIQII)2+41~*-~~I12 
(5.137) 
Selecting p* large enough so that C > 0, we see that (5.136) implies 
fi(e, 4) I 
~ ( e ,  
4) + q, 
V(t, el 4) E R x R" x R", 
(5.138) 
where the positive number p is given by 

282 
5. Output Control 
and r = diag{ri, r2, . . . , I"}. Fkom (5.138), it is clear that v ( e ,  4) de- 
creases monotonically along any solution of S, until the solution reaches 
the compact set 
RJ = { ( e ,  4) E R" x R": v ( e ,  4) I 
vr}, 
(5.140) 
VJ = /J-'T. 
(5.141) 
Therefore, the solutions ( e ,  q5)(t; to, eo, 40) of S, are globally ultimately 
bounded with respect to the bound U J .  
Q.E.D. 
5.30. REMARK. Within St, we find that 
where 
(5.142) 
Now, if we choose u IX pP3 and r IX p3, and let p 4 +m, we find that 
< -+ A,(G), 
7 N p-', and, therefore, UJ N p-'. This implies that the 
upper bound on the steady-state tracking error e(t) can be made as small 
as desired by decreasing u and increasing 
sufficiently. We should note, 
however, that within R, 
and the upper bound on 11 q!~+pOll increases proportionally to the increase of 
p. Thus, making (T small and r large will allow adaptation gains to become 
high, resulting in a trade-off between small tracking errors and large gains 
in the proposed high-gain decentralized adaptive scheme. 
We also note that again, as in Remark 5.26, it is not necessary for 
the designer to know or choose p*. Local gains adjust automatically to 
counter the destabilizing effect of interconnections. The designer need only 
to tune the size of the residual set by adjusting ri and CT as explained in 
Remark 5.30. Of course, these benefits would not be guaranteed without 
the structural restrictions (5.107) placed on the interconnections. 
5.31. EXAMPLE. To illustrate the decentralized adaptive control, we 
consider again the two inverted penduli coupled by a spring (Figure 1.16). 
Choosing g / l  = 1, l/m12 = 1, and k/m = 2, we get the system matrices 

5.5. Adaptive Control 
283 
or, in the block notation (5.98), 
(5.146) 
where y(t) = u2(t)/12 and w = (w1, ~
2
)
~
.
 
The function a(t) is uncertain, 
and all we know is that u ( t ) / l  E [0, 11. 
Since P, = bi, i = 1, 2, the structural condition (5.107) for stabiliz- 
ability of S by fixed decentralized feedback is satisfied. To build adaptive 
controllers, we choose the reference models (5.103) having the matrices 
and 0; = (-2, -2, l)T, 
i = 1, 2. Next, we choose Gi 
and compute Hi and 
& from (5.109) and (5.110) as 
For the adaptation law (5.111), we select 
identity matrix, and set 1.7 = 0.01. 
= 1 3 ,  where I3 is the 3 x 3 

284 
5. Output Control 
2.0 
I 
I 
I 
I 
I 
I 
-'."I 
-1.5 ! 
I 
I 
I 
I 
I 
I 
0 
20 
40 
60 
B 0  
100 
time 
Fig. 5.6. Tracking error with the high-gain algorithm. 
3 ;  
I 
I 
I 
I 
I 
I 
-5 
I 
I 
I 
I 
I 
I 
0 
20 
40 
60 
B 0  
I00 
time 
Fig. 5.7. Adaptive gains of the high-gain algorithm (values for subsystem 1 are shown). 
With the chosen parameter settings, the results of a simulation are 
shown in Figures 5.6 and 5.7. The reference signals were 
q ( t )  = sin 20t + sin 5t + sin t, 
rz(t) = sin 10t + sin 2t + sin 0.5t, 
and a ( t ) / t  = 1 for all time t 2 to = 0. From the plots, we see that 
(5.149) 

5.5. Adaptive Control 
285 
the presence of interconnections prevents the tracking errors from con- 
verging to zero and the feedback gains from converging to the model 
matching values. Instead, the gains tend toward a near steady-state level, 
= (-4.9, -3.2)T, which is higher than the local model-matching gains 
of k; = (-2, -2)T, which is indicative of the high-gain nature of the con- 
troller. 
To contrast the result of Theorem 5.29 with the earlier approach (Ioan- 
nou, 1983) based upon the M-matrix conditions, we compute the 2 x 2 
aggregate matrix W = (wij) as in Section 2.2: 
From the M-matrix conditions (2.25) applied on W ,  we derive the inequal- 
ity 
(5.151) 
Using the definition of &j in (5.101), we have C,j = 2 for i, j = 1, 2. Then, 
from (5.151) we get 
(5.152) 
which means that by the M-matrix approach we guarantee stability only if 
the spring remains connected to the lower 27% of the length of the penduli. 
In our example, we allow a(t)/e = 1 (the spring is moved all the way up to 
the bobs) making the M-matrix test inconclusive with regard to stability. 
A simulation of the system using a controller design based on the M- 
matrix test was also performed in order to see the effect of regressor vectors 
ZJi = (z:, 
rT)T that are different from those of (5.125), vi = (e:, T ? ) ~ ,  
used in our example. The results are shown in Figures 5.8 and 5.9. The 
system appears stable, however, tracking residuals are considerably larger 

286 
5. Output Control 
1 . 5  
1 . 0  
0.5 
0 
- 0 . 5  
-1.0j 
t 
-
1
.
5
5
 
0 
20 
40 
60 
00 
100 
time 
Fig. 5.8. Tracking error with the standard algorithm. 
3 '  
I 
I 
I 
1 
I I c 
-31 
t 
-41 
t 
-5 / 
I 
I 
I 
I 
I 
0 
20 
40 
60 
00 
100 
time 
Fig. 5.9. Adaptive gains with the standard algorithm. 
than before, indicating the fact that the high-gain approach may lead to a 
better-performing adaptive control scheme. 
In another simulation run, we show the effect of a time-varying inter- 
connection on adaptation gains and tracking residuals. We inject the jump 
0 ,  O I t < 5 0 ,  
e 
1 ,  50 5 t 5 100, 
(5.153) 

5.5. Adaptive Control 
287 
-1.01 
t 
-1.5 I 
I 
I 
I 
I 
I 
0 
20 
40 
60 
80 
100 
time 
Fig. 5.10. 
until t = 50, then interconnected. 
Tracking error for the high-gain adaptive controller. Subsystems are isolated 
2 3r---7 
-5 
I 
I 
I 
I 
I 
0 
20 
40 
60 
80 
100 
time 
Fig. 5.11. 
connection strength at t = 50. 
Adaptive gains of the high-gain controller in response to increased inter- 
that is, the penduli are disconnected for the first half, and maximally inter- 
connected for the second half of the experiment. Figures 5.10 and 5.11 show 
the results for the high-gain adaptive controllers, and Figures 5.12 and 5.13 
display the results obtained by the standard adaptive scheme. The high- 
gain controllers maintain a tracking residual of about 0.5 throughout the 
run. As expected, the standard scheme behaves well when the subsystems 
are isolated. However, the residuals become large when the subsystems get 

288 
5. Output Control 
-'."I 
t 
-1.5 1 
I 
I 
I 
I 
I 
8 
20 
40 
60 
E0 
188 
time 
Fig. 5.12. 
t = 50, then interconnected. 
Tracking error with the standard algorithm. Subsystems are isolated until 
a ;  
I 
I 
I 
1 
I I 
-4 
I- 
108 
48 
68 
88 
20 
time 
8 
Fig. 5.13. 
nection strength at t = 50. 
Adaptive gains of the standard controller in response to increased intercon- 
coupled. The high-gain adaptive controllers seem robust to time-varying 
interconnections, with local gains adjusting their values to maintain a con- 
sistent tracking residual. 
Finally, we compare the proposed decentralized scheme to the standard 
centralized adaptive algorithm (Narendra and Valavani, 1978). For this 
purpose, we use the compact notation of the form (5.98) to describe the 

5.5. Adaptive Control 
289 
closed-loop system as 
8: X = A X + B X ,  
u = K X  + Kor, 
(5.154) 
where 
0
1
 0
0
 
0
0
 
A =  [ -: 5 
B =  [z !I, 
(5.155) 
2 0 - 1 0  
and K and KO are the gain matrices of appropriate dimensions. The model- 
matching gains are 
0 
-2 
-2 
K * =  [ -2 
0 
0 -2 
(5.156) 
Defining 8 = ( K ,  KO) and u = (xT, T
~
)
~
,
 
the adaptation law is 
8 = -,,e 
- yKeu, 
(5.157) 
where I? = diag{ir, fc:} as defined by (5.110), e = (er, eF)T, and 
and 
y are positive numbers. For simulation purposes, we choose y = 1, which 
corresponds to r = I3 in our earlier runs. We set u = 0 because there are 
no external disturbances or unmodeled interconnections, so that perfect 
model-matching is possible. Our reference signal is persistently exciting, so 
that 4(t) = [e(t) - 13.1 -, 0 as t 
00. Results are plotted in Figures 5.14 
and 5.15 for 0 5 t 5 100. The convergence rate appears to be roughly the 
same for the centralized and decentralized cases. Residual tracking errors 
are smaller (eventually zero) in the centralized case, which is to be expected 
since exact model-matching will occur. The centralized control law, how- 
ever, requires twelve adaptation gains, compared to six in the decentralized 
case. In general, for the system composed of N interconnected subsystems, 
centralized controllers require N ( n  + N )  adaptation gains, where n is the 
total number of states. Decentralized controllers require only n+ N adapta- 
tion gains, and N sets of gain adaptation equations can be run in parallel. 
We are led to conclude that a decentralized adaptive controller has a far 
simpler algorithm than a centralized one, at the price of a relatively small 
decrease in performance. 

290 
5. Output Control 
el - 
e2 ------ 
-'-"I 
t 
-1.5 ; 
I 
I 
I 
I 
I 
0 
20 
40 
60 
80 
100 
time 
Fig. 5.14. Tracking error with centralized adaptive control. 
2.0 
1 
I 
I 
I 
I I 
1.5j 
1.0 
0.5 
0 
-0.5 
-1.0 
-1.5 
-2.0 
-2.5 
-3.0 ! 
I 
I 
I 
I 
I 
I 
0 
20 
40 
60 
a0 
100 
time 
Fig. 5.15. Adaptive gains of the centralized adaptive controller. 
5.6. Known Subsystems 
In modeling of complex systems, it is standard (and natural!) to do it 
piece-by-piece leaving an essential uncertainty in the interactions among 
the system components or subsystems. Biased by this fact, one may look 
at the ignorance of subsystem dynamics, which was assumed in the pre- 
ceding section, as an artifice to make the centralized algorithms work in 
the new decentralized setting rather than a genuine uncertainty about the 
subsystems. It is far from obvious, however, to see how one should take 

5.6. Known Subsystems 
291 
advantage of the knowledge about subsystem dynamics and come up with 
better adaptive schemes. 
In this section, we outline an adaptive algorithm of (Gavel and Siljak, 
1989) that utilizes the knowledge of the subsystems to broaden the 
approach of the previous section and include Multi-Input-Multi-Output 
(MIMO) subsystems. Furthermore, the new algorithm is simpler to imple- 
ment, requiring only one adaptation parameter per subsystem. 
Consider the collection of MIMO subsystems 
ya = cixi, 
(5.158) 
wi = Q i ~ i ,  
i E N, 
where xi(t) E Rnt, ui(t) E Rpa, and yi(t) E Rqi are the state, input, and 
output of the subsystem Si, and ~ ( t )  
E Rma, and wi(t) E Re, are the 
interconnection inputs and outputs of Si to and from other subsystems S j ,  
j E N, at time t E R. We assume that the pair (Ai, Bi) is controllable, and 
the pair (Ai, Ci) is observable. The interconnection inputs and outputs 2ri 
and wi are related as before by interconnection functions defined in (5.97) 
and (5.101), where the numbers <ij are fixed but unknown. Moreover, we 
assume that the interconnection matrices Pi are factorable as 
(5.159) 
for some constant (but not necessarily known) matrices pzl. Our crucial 
assumption in this section is that the matrices Ai, Bi, and Ci are known. 
Reference models are specified by first selecting local state feedback gain 
matrices Ki E Rpixni that would stabilize the local isolated subsystems. 
That is, 
A,i 
= Ai - BiKi, 
i E N, 
(5.160) 
is a stable matrix. The reference models are then described by 
Mi: xmi = A,ix,i 
+ Biri, 
(5.161) 
where the ri: R + Rpa are bounded, piecewise continuous vector functions 
of time. 
We now proceed with the design of an adaptive control law. The first 
step is to choose any symmetric positive definite ni x ni matrix G,, 
and then 
ymi = Cixmi, 
i E N, 

292 
5. Output Control 
find the symmetric positive definite solution Hi to the matrix Liapunov 
equation 
A:iHi + HiA,i 
= -Gi. 
(5.162) 
A solution is guaranteed to exist since A,i 
is stable. Now, choose a sym- 
metric positive definite pi x pi matrix &, and define Ki as 
Ki = R;~B,TH~. 
(5.163) 
Using Ki of (5.160) and this Ki, we formulate a local feedback control law 
where ai(t) is a scalar adaptation gain at time t > to obeying the adaptation 
law 
&(t) = yieT(t)KTR&ei(t) - aiai(t), 
ai(to) > 0, 
(5.165) 
yi and ai are positive constants, and ei(t) = zi(t) - z,i(t). 
To analyze the stability of the above control scheme, we form an error 
differential equation by subtracting (5.161) from (5.158). Together with 
(5.164), this describes the motion of the entire system: 
Se: di = (A,i - aBiKi)ei + Bie'vi, 
&. - 
- yierKT&Kiei - aiai, 
(5.166) 
i E N. 
Now define e = (e:, er, . . . , e z ) T ,  a = (1111, QZ, . . . , a ~ ) ~ ,  
and denote the 
state of Se as (e, a) E R" x R ~ .  
5.32. 
are globally ultimately bounded. 
THEOREM. The solutions (e, a) (t; to, eo, ao) of the system 8, 
ProoJ Using the Liapunov function 
N 
v(e, a) 
eTHiei + y;'(ai - a*)', 
(5.167) 
we establish the theorem in pretty much the same way as Theorem 5.25. 
Q.E.D. 
i=l 

5.6. Known Subsystems 
293 
-1.5 
I 
I 
I 
I 
I 
I 
0 
20 
40 
60 
80 
100 
time 
Fig. 5.16. Tracking error for the known subsystem scheme. 
5.33. EXAMPLE. We continue Example 5.31, and compute the gain 
matrices 
Ki = [2.0 2.01, 
Ki = [0.5 0.51, 
i = 1, 2, 
(5.168) 
for use in the control law (5.164). The reference signal r(t) is given by 
q ( t )  = sin 0.27rt + sin 7rt + sin 27rt, 
(5.169) 
rz(t) = 0, 
t > to = 0, 
that is, it is desired, starting at t = 0, to move the first pendulum sinu- 
soidally, while holding the second pendulum unmoving in a vertical posi- 
tion. At t = 0, the adapted gain ai is zero. We use y = 100 and (T = 0.01 
in the adaptation law (5.165). 
The simulation results are shown in Figures 5.16 and 5.17. The pendu- 
lum positions closely follow the reference model, with accuracy improving 
over time. The gains ai(t) adjust generally upward during a transient pe- 
riod, and then oscillate around a fixed positive value in steady-state. 
For comparison, we simulated the same system in closed-loop, but with- 
out adaptation. Setting ai(t) = 0, i = (1, 2}, t > 0, we get the results 
shown in Figure 5.18. Notice that, without adaptation, a large amount of 

294 
5. Output Control 
time 
Fig. 5.17. Adaptation gain a! for the known subsystem scheme. 
1.51 
0.5 
t 
t 
-0.54 
L 
-1.01 
-1.5 1 
I 
I 
I 
I 
I 
0 
20 
40 
60 
E0 
100 
time 
Tracking error without adaptation (y = 0). 
Fig. 5.18. 
signal intended to drive the first pendulum couples into the second pendu- 
lum through the connecting spring, whereas with adaptation, local gains 
increase in order to reduce the coupling effect. 
This adaptive control law is the simplest of the ones described so far, 
since only two parameters are adapted in the overall system, as compared 
to six for the decentralized adaptive controller described in the preceding 
section, and twelve for the centralized adaptive controller. For a system 
with N subsystems, there are N adaptation gains, and the N adaptation 
gain equations can be run in parallel. 

5.7. Adaptive Output Feedback 
295 
5.7. Adaptive Output Feedback 
We now remove the assumption that all states of each subsystem are 
available for control and consider local output feedback. A centralized adap 
tive controller using output feedback was proposed by Monopoli (1973) and 
proven stable by Narendra et al. (1980). A decentralized version of this con- 
troller, which was introduced by Ioannou (1983), is suitable for our use. 
Each subsystem controller consists of a precompensator Cg and a feed- 
back compensator C{ leading to the open-loop subsystem description 
wi = Qzxit 
(5.170) 
cf: ~
J
z
 
= KzJz + gz!/z/z, 
i E N, 
where z,(t) E Rna, zp(t) E Rna-l, and zrz(t) E R"'-' are the states of 
S,, Cf and Cf at time t E R, u,(t) E Rpz and yZ(t) E R4' are the input 
and output of the subsystem S,, and v,(t) E R"' 
and w,(t) E Re* are the 
interconnection inputs and outputs of S, to and from other subsystems 
S,, j E N, at time t E R. We assume that the pair (A,, b,) is controllable 
and the pair (A,, I$) is observable. The assumptions about interconnection 
functions remain unchanged. 
To use the stabilizability conditions of Section 5.1, we assume that there 
exists a subset I C N such that 
(5.4) 
for some constant vectors p, E Rmi, qi E Re%. For ease of notation, we 
numberthesubsystemssothat I = { 1 , 2 ,  ..., f}and N - I = { I + l , I +  
An adaptive decentralized control law for the defined class of intercon- 
2, ... , N}. 
nected systems is given by 
ui = 8a T ui, 
(5.171) 
where ui = (&, z;, z:, ~
i
)
~
 
is a vector of available signals and 8, = ( d f i ,  
g, qi, k ~ i ) ~  
is the adaptation gains vector. In vi(t), ri(t) is the external 

296 
5. Output Control 
reference input, which is a uniformly bounded and piecewise continuous 
function of time, and iji = yi - ymi is the model output following error. 
Stable reference models Mi are specified as before: 
Mi: x,, = Amixmi + bmiri, 
ymi = CTmix,i, 
(5.103) 
i E N. 
Now, define the transfer functions 
(5.172) 
i E N, 
which describe the open-loop plant, closed-loop plant, and the reference 
model, respectively. The linear timeinvariant system transfer function 
Gi(s, 8) is defined for fixed values of 9 E R2ni+2. In order for a decentral- 
ized adaptive control design to be feasible, the following conditions must 
be met: 
(i) The plant is minimum phase; that is, the monic polynomial /?i(s) 
is Hurwitz (all zeros have negative real parts). 
(ii) The plant has relative degree one; that is, the degree of Pi(s) is 
ni - 1, where ni is the degree of ai(s). 
(iii) The sign of I E ~  is known. Without loss of generality, we assume 
that ~i > 0. 
In addition to the above conditions on the open-loop plant, we must 
choose reference models that are strictly positive real, which means that 
a,i(s) and Dmi(s) are Hurwitz, and Re {cpmi(jw)} > 0 for all w E [0, cm) 
(Siljak, 1971). 
Under these conditions, it has been established (Narendra and Valavani, 
1978) that there exists a unique 9: = (d;i, c;, cji, k6i)T such that the 
closed-loop isolated subsystem Si has the same input/output behavior as 
the reference model Mi; that is, &(s, 9;) = cp,i(s), 
i E N. 

5.7. Adaptive Output Feedback 
297 
In fact, however, we do not know O:, so we use its estimate &(t) in the 
control law (5.171). The proposed decentralized adaptation law for &(t) is 
ei = -ri(di + vivi), 
i E N, 
(5.173) 
where ri is a constant symmetric positive definite matrix of dimension 
(3ni - 2) x (3ni - 21, and CT is a constant positive scalar. 
With Oi (t) different from Or, the closed-loop isolated subsystem acts 
like the reference model, but with the added disturbance input @(t)vi(t), 
where $i(t) = &(t) - 0:. The closed-loop interconnected system is thus 
described by 
-T .. 
yz = ci xi, 
w. - Q.2. 
a -  
a
a
,
 
 EN 
(5.174) 
(5.175) 
iy = (c?, 0, O ) ,  
i), = (ly, 
0, O)T, 
Q i  = (Qi, 0, 0). 
The triple {Ai(O;), bi, $} is a nonminimal realization of the reference 
model: 
(1.176) 
ymi = tzi2mi, 
i E N. 
The reference model is strictly positive real, so that, from the Kalman- 
Yakubovich Lemma (e.g., Lefschetz, 1965; Siljak, 1969), it follows that 

298 
5. Output Control 
{Ai(O,t), bi, q} 
satisfies the equations 
A:(o;)& + fi&e;) 
= lit? - &, 
(5.177) 
^
^
 
Hibi =&, 
i E N, 
for some constant, symmetric positive definite matrices Hi and Li, some 
constant vector .ti E R3ni-21 and sufficiently small number ~i > 0. 
An equation for the tracking error &(t) = &(t) - &i(t) can be derived 
by subtracting (5.176) from (5.174): 
A
,
.
 
sei: ii = Ai(e,t)ci + i&TUi + 
- $qiymi, 
yi = &, 
(5.178) 
wi = Qi(% + itmi), 
i E N, 
The decentralized stabilizability conditions (5.4) are stated with respect 
to the open-loop system S .  The closed-loop system S with the local dynamic 
compensators is a structurally different large-scale system; thus, we must 
restate the stabilizability conditions in terms of the new structure. The 
condition 
Qi = qit:, 
a E N- I, 
(5.179) 
follows immediately; however, it is not true that pi = hip?, i E I. This 
is because interconnection disturbances, which enter at the input to the 
plant, are not available signals for input to the precompensator as well (see 
Figure 5.19a). We can, however, reflect the disturbances to the input of the 
closed-loop system as shown in Figure 5.19b. 
From (5.169), we calculate the transfer function for the open-loop pre- 
compensator as 
cg: (ppi(s) = C $ ( S l  - F p g z ,  
i E I. 
(5.180) 
When the loop is closed, the precompensator acts as a prefilter for the feed- 
back, reference, and adaptation error signals. The prefilter has the transfer 
function 

5.7. Adaptive Output Feedback 
299 
T 
Pi vi 
(b) 
Fig. 5.19. 
subsystem. 
Reflecting the interconnection disturbance to the input of the closed loop 
In (Narendra and Valavani, 1978), it is shown that 
(5.182) 
therefore, since both Pi(s) and Pmi(s) are assumed Hurwitz, we have that 
@pi(s) and $;'(s) 
are stable transfer functions. 
For each subsystem Sei, i E I, we reflect the interconnection signal p'vi 
to the input of the closed-loop subsystem by disconnecting it from the input 
of the plant, filtering it through the inverse of the prefilter Cy, then feeding 
the resulting filtered signal to the input of the closed-loop subsystem, as 
shown in Figure 5.19b. In doing this, we have introduced I new subsystems 
into the analysis whose transfer functions are $;'(S): 
Fi: .ii = F , z ~  + ~ i p y v i ,  
~ i ( t o )  = 0, 
(5.183) 
i E I, 
*T 
T 
7la = -Cpi za + p i  va, 

300 
5. Output Control 
where zi E R"*-' is the state, p:vi is the input, and qi E R is the output of 
Fi. Since Fi is a stable matrix by design, the subsystems Fi have, associated 
with them, the Liapunov equations 
FTHi+ HlF, = -GI, 
i E I, 
(5.184) 
where both H,! and G: are positive definite (ni - 1) x (ni - 1) matrices. 
described by 
With this modification, the closed-loop error systems S e i ,  i E I, are now 
We are now in a position to fully take advantage of the interconnection 
structure, as originally stated by conditions (5.4). 
In summary, the differential equations for the large-scale, intercon- 
nected, adaptively controlled system are: 
with interconnections given by 
i E I, 
i E I, 
qi = c*Tz . + T 
pt 
pt 
Pi Vi, 
wi = Qi(di + i m i ) ,  
Wl = &(ez 
i E N-I, 
vi = fi(t, w), 
i E N. 
(5.187) 

5.7. Adaptive Output Feedback 
301 
We denote the state of the overall system S, as (6, z, 4) E C, where 
C = R(3n-ZN) x Rk x RZn, 
(5.188) 
T
T
 
T T  
z =  (z1, 2 2 ,  “ ‘ 7  
Z I )  9 
and state the following result obtained by Gavel and Siljak (1989): 
5.34. 
S, are globally ultimately bounded. 
THEOREM. The solutions (6, z ,  4) (t; to, 60, 20, 40) of the system 
Proof. Define the function Y: C -, R+ as 
where the & = (1, 0, . . . , O)T are vectors having the same dimension as 8i 
for i E N, 
and p ,  Si, and S,! are as yet unspecified positive constants. Taking 
the time derivative of ~ ( 6 ,  
z ,  4) with respect to (5.186), the theorem is 
established by a lengthy proof. See (Gavel and Siljak, 1989) for details. 
Q.E.D. 
5.35. REMARK. Again, if we choose ~7 0: p-3 and r 0: p3, and increase 
p, we find that vf - p-’ as before. However, note that this time, a primi 
knowledge of the interconnection bounds is not sufficient to calculate uf, 
and hence the size of the residual set. This is because the constants p and 
p’ depend on fi, the solution to (5.177), and, in order to solve (5.177), 
we would have to know 8’. This is counter to our assumption that the 
subsystem dynamics are unknown. 
5.36. EXAMPLE. 
sume that the only measurable variables are 
We continue with the two penduli example and as- 
yz = [ 1.0 O.l]Zi, 
i = 1, 2. 
(5.190) 

302 
5. Output Control 
time 
Fig. 5.20. Tracking errors using the output feedback adaptive controller. 
We want the penduli to track the motion of the reference model specified 
bY 
0 
A,, = [ -1 -:] 
, 
b,i 
= [ y ]  , 
= [0.5 0.51, 
i = 1, 2. 
(5.191) 
The pre- and post-compensators are given by 
c p :  i . - -2 . + 21. 
i f i  = -2fi + yi, 
z 
P -  
P 
t7 
(5.192) 
ci: 
f 
2 = 1, 2, 
and we apply the reference signal described by (5.169). The results are 
shown in Figures 5.20 and 5.21. Notice that initially, the pendulums begin 
to fall, but as the parameters adjust, the tracking error approaches the low 
magnitudes that were observed with the state feedback algorithm. 
5.8. Notes and References 
If states of interconnected plants are not available for control and, at 
the same time, the communication costs of state reconstruction are pro- 
hibitive, then the only alternative is to build decentralized controllers using 

5.8. Notes and References 
303 
local output feedback. A suitable control strategy is to associate dynamic 
compensators with subsystems and boost the gains, so that the intercon- 
nection effect is neutralized. Of course, this high-gain strategy works only 
if the interconnections satisfy certain structural conditions (Hiiseyin et al. 
1982: Section 5.1). A variety of these conditions (sometimes called “match- 
ing conditions,” e.g., Leitmann, 1979; Siljak, 1989) were used in Chapter 2 
to build decentralized state controllers for interconnected plants. The con- 
ditions work equally well for both static and dynamic output feedback 
(Saberi and Khalil, 1985; see also the survey of high-gain feedback results 
by Saberi and Sannuti, 1988b). 
It was made clear in (Siljak, 1978) that we cannot rely on interconnec- 
tions to produce a stabilization effect when plants are inherently unstable, 
because a loss of interconnections may cause instability: Robust decentral- 
ized control is achieved by considering interconnections as a disturbance of 
subsystems. Both exact (Wonham, 1979) and almost (Willems, 1981, 1982) 
disturbance decoupling methods can be used in this context (Willems and 
Ikeda, 1984; Linneman, 1985; Young, 1985; Saberi and Sannuti, 1988a). The 
stabilizability conditions, however, axe parameter dependent, because the 
relevant subspaces vary as functions of system parameters. A way to over- 
come this dependency is to select the cases in which the relevant subspaces 
are invariant under parameter perturbations. This led to the investigation 
of the almost invariant subspaces of structured systems (Hayakawa and 
Siljak, 1988), as presented in Sections 5.2-4. 
High-gain feedback may become excessive, causing severe noise prob- 

304 
5. Output Control 
lems. Yet, lower gain values may be just as satisfactory for other system 
performance characteristics. This fact makes the decentral-adaptive con- 
trol an attractive design concept. The research in this area (Hmamed and 
Radouane, 1983; Ioannou, 1983, 1986; Ioannou and KokotoviC, 1983; Ioan- 
nou and Reed, 1988) has been directed to applications of model reference 
adaptive controllers (Parks, 1966; Monopoli, 1973; Narendra and Valavani, 
1978; Narendra et al. 1980; Yoshikawa and Ikeda, 1983) to the control of 
unknown subsystems as if they were decoupled from each other. Then (as in 
Chapter 2), the standard M-matrix conditions have been used to establish 
the bounds on interconnections for stability of the overall system. 
There are at least three reasons why the M-matrix approach to de- 
centralized adaptation may be unsuitable for application. First, it may be 
difficult, if not impossible, to predict. and limit the size of the coupling 
among the subsystems within the bounds established by M-matrix condi- 
tions. Second, even if we know the bounds on interconnection strengths, it 
is not clear how the local reference models should be chosen for the overall 
system to satisfy the M-matrix conditions. Third, in the case of tracking 
problems, we would like to have the capability of controlling the size of the 
residual set. For these reasons, a high-gain adaptive scheme was proposed 
(Gavel and Siljak, 1989: Sections 5.5-7), which was based on structural 
conditions (2. e., matching conditions) for decentral stabilizability. Under 
these conditions, the feedback gains are adaptively adjusted to the levels 
necessary to neutralize the interconnections and, at the same time, drive 
the unknown subsystems toward the performance of the locally chosen ref- 
erence models, as close as desired. It is important to note that the resulting 
adaptive schemes retain the connective stability property and robustness to 
nonlinearities that is enjoyed by the fixed-gain decentralized controllers of 
Section 5.1. Furthermore, the adaptive schemes are likely to use lower gains 
than those set by conservative fixed-gain design procedures. This fact was 
confirmed when adaptive decentralized control was used in robotics (Gavel 
and Hsia, 1988; Gavel, 1988; Mills and Goldenberg, 1988). 
FREQUENCY DOMAIN METHODS 
A popular alternative to time domain design of output feedback is to 
use the Nyquist and inverse Nyquist array methods of frequency domain 
variety proposed originally by Rosenbrock (1974). One of the reasons for 
the development of these methods is the fact that the controllers are de- 
signed decentrally, resulting in procedures of outstanding conceptual and 
numerical simplicity. Only a glimpse of a vast number of results in this 
area is offered here, relying on a paper by Ohta et al. (1986), where a short 

5.8. Notes and References 
305 
Fig. 5.22. Feedback system. 
upto-date survey of the design procedures is provided (see also Bennett 
and Baras, 1985). 
Let us consider a feedback system S of Figure 5.22, which consists of 
plant P: y = G(s)v, 
controller C: u = K ( s ) e ,  
(5.193) 
interconnection I v = u + d, 
e = r - y, 
where the matrices G(s), K ( s )  E Mat R(s) have dimensions rn x C and 
d x m, respectively, and belong to the set of real rational matrices. The 
system equation of S is given by 
(5.194) 
Suppose that the feedback system S is well posed, that is, det[I, + 
G(s)K(s)] $ 0. Let H(G, K)(s) be the transfer function matrix of S relat- 
ing (T, d )  to (e, v): 
(5.195) 
We use S(s) to denote the subset of R ( s )  consisting of proper rational 
functions whose poles are all in C-, and say that S is stable if H(G, K)(s) E 
Mat S(s), that is, C stabilizes P. 
The system is decomposed as 
N 
\ 
I vi = ui + di, 
ei = ri - yi, 1 

306 
5. Output Control 
where Gf3(s) and KZ3(s) 
are submatrices of G(s) and K(s) having dimen- 
sions m2 
x eJ and 
The following result was established by Bennett and Baras (1980), which 
is a block-matrix analog of (Rosenbrock, 1974): 
x m], respectively. 
The central question is: Under what conditions does (iii) hold? Using 
the concept of block diagonal dominance introduced by Feingold and Vatga 
(1962) and Fiedler (1961), Bennett and Baras (1980), Limebeer (1982, 
1983), Limebeer and Hung (1983), and Hung and Limebeer (1984) derived 
sufficient conditions for (iii). Ohta et al. (1986) generalized these results 
by applying the quasi block diagonal dominance (Ohta and Siljak, 1985) of 
Definition 7.14: 
5.38. THEOREM. If the Perron-Frobenius root is such that 
where the matrix B = (bij) is defined as 
(5.198) 
(5.199) 

Bibliography 
307 
Although the condition (5.198) is the least restrictive, it is not clear 
how K(s) affects stability of S even if K(s) were a block diagonal matrix. 
A suitable set of conditions is provided by Ohta et al. (1986), under which 
a matrix K(s), when restricted to a diagonal matrix KD(s) = diag{Kll(s), 
K22(s), . . . , K”(s)}, can be chosen “piece-by-piece” to stabilize S, involv- 
ing only the independent choice of each block Kii(s), one at a time. The 
procedure of Ohta et al. (1986) was formulated by generalizing certain re- 
sults of Araki and Nwokah (1975), and using either the characteristic loci 
method (MacFarlane and Belletrutti, 1973) or the Nyquist array technique 
(Rosenbrock, 1974; Araki et al. 1981). 
It is more or less clear that the design procedure of Ohta et al. (1985) 
is basically a loop-shaping by quasi block diagonal dominance. This fact 
opens up a possibility of using H” theory in this context. Wu and Mansour 
(1988,1989) observed this fact and proposed an interesting parametrization 
of the decentralized problem, which leads to a numerically effective design 
method. 
A new emerging frequency-domain approach to decentralized control de- 
sign, which has been advanced recently by Tan and Ikeda (1987), is based 
upon the stable factorization method (Vidyasagar, 1985). The decentral- 
ized control problem is essentially a simultaneous stabilization problem of 
finding a set of controllers that stabilize all individual subsystems and the 
overall system at the same time. Since the stable factorization method 
provides a suitable parametrization of all stabilizing controllers, Tan and 
Ikeda (1987) showed how a decentralized controller set can be obtained 
sequentially using this method. With some care (but with increased con- 
servativeness), their procedure can assure connective stability of the overall 
system (Ikeda and Tan, 1989; Tan and Ikeda, 1990). 
Bibliography 
Aoki, T., S. Hosoe, and Y. Hayakawa (1983). Structural controllability for linear systems 
in descriptor form (in Japanese). Transactions SICE, 19, 628435. 
Araki, M., and 0. I. Nwokah (1975). Bounds for closed-loop transfer functions of mul- 
tivariable systems. IEEE Transactions, AC-20, 666470. 
Araki, M., K. Yamamoto, and B. Kondo (1981). GG-pseudo-band method for the design 
of multivariable control systems. Proceedings of the 8th IFAC World Congress, 3, 
Bennett, W. H., and J. S. Baras (1980). Block diagonal dominance and design of decen- 
tralized compensators. Proceedings of the IFAG Symposium on Large Scale Systems: 
Theory and Applications, Toulouse, France, 93-102. 
Bennett, W. H., and J. S. Baras (1985). Decomposition and decentralized control system 
design: A review of frequency domain methods. Proceedings of the 24th Conference 
on Decision and Control, Fort Lauderdale, Florida, 1828-1835. 
137-142. 

308 
5. Output Control 
Chen, K. W. (1976). Applied Graph Theory. North-Holland, New York. 
Cho, Y. J., and 2. Bien (1989). Reliable control via an additive redundant controller. 
International Journal of Control, 50, 385-398. 
Feingold, D. G., and R. C. Varga (1962). Block diagonally dominant matrices and gen- 
eralizations of the Gerschgorin circle theorem. Pacific Journal of Mathematics, 12, 
Fiedler, M. (1961). Some estimates of spectra of matrices. Proceedings of the Symposium 
on Numerical Treatment of Ordinary Differential Integral, and htegro-Differential 
Equations, Birkhauser-Verlag, Basel, Switzerland, 33-36. 
Gavel, D. T. (1988). Decentralized Adaptive Control of Large Scale Systems, with Ap- 
plication to Robotics. Ph.D. Thesis, Report No. UCRL-53866, Lawrence Livermore 
National Laboratory, Livermore, California. 
Gavel, D. T., and T. C. Hsia (1988). Decentralized adaptive control of robot manipula- 
tors. Proceedings of the ZEEE International Conference on Robotics and Automa- 
tion, Philadelphia, Pennsylvania, 123Ck1235. 
Gavel, D. T., and D. D. Siljak (1989). Decentralized adaptive control: Structural condi- 
tions for stability. ZEEE Transactions, AC-34, 413-426. 
Hayakawa, Y., and D. D. Siljak (1988). On almost invariant subspaces of structured 
systems and decentralized control. ZEEE Transactions, AC-33, 931-939. 
Hmamed, A., and L. Radouane (1983). Decentralized nonlinear adaptive feedback sta- 
bilization of large-scale interconnected systems. ZEE Proceedings, 130-D, 5742. 
Hung, Y. S., and D. J. N. Limebeer (1984). Robust stability of additively perturbed 
interconnected systems. ZEEE Transactions, AC-29, 1069-1075. 
Hiiseyin, O., M. E. Sezer, and D. D. Siljak (1982). Robust decentralized control using 
output feedback. ZEE Proceedings, 129-D, 310-314. 
Ikeda, M., and X. L. Tan (1989). Connective stabilization of large-scale systems: A stable 
factorization approach. Mathematical Theory of Networks and Systems (to appear). 
Inan, K. (1978). Asymptotic Root Loci in Linear Multiua~abZe ControE Systems. Disser- 
tation, Middle East Technical University, Ankara, Turkey. 
Ioannou, P. A. (1983). Design of decentralized adaptive controllers. Proceedings of the 
IEEE Conference on Decision and Control, San Antonio, Texas, 205-210. 
Ioannou, P. A. (1986). Decentralized adaptive control of interconnected systems. IEEE 
Transactions, AC-31, 291-298. 
Ioannou, P. A., and P. V. KokotoviC (1983). Adaptive Systems with Reduced Models. 
Springer, New York. 
Ioannou, P. A., and P. V. KokotoviC (1984). Robust redesign of adaptive control. IEEE 
Transactions, AC-29, 202-211. 
Ioannou, P. A., and J. S. Reed (1988). Discrete-time decentralized adaptive control. 
Autornatica, 24, 419-421. 
Lefschetz, S. (1965). Stability of Nonlinear Control Systems. Academic Press, New York. 
Leitmann, G. (1979). Guaranteed asymptotic stability for some linear systems with 
bounded uncertainties. Transactions of ASME, Journal of Dynamic Systems, Mea- 
surement, and ControZ, 101, 212-216. 
Limebeer, D. J. N. (1982). The application of generalized diagonal dominance to linear 
system stability theory. International Journal of Control, 36, 185-212. 
Limebeer, D. J. N. (1983). An inclusion region for the eigenvalues of partitioned matrices. 
International Journal of Control, 37, 429-436. 
Limebeer, D. J. N., and Y. S. Hung (1983). Robust stability of interconnected systems. 
IEEE Transactions, CAS-30, 397-403. 
1241-1250. 

Bibliography 
309 
Linneman, A (1985). Decentralized stabilization by high gain feedback. Real Time Con- 
trol of Large Scale Systems, G. Schmidt, M. G. Singh, and A. Titli (eds.). Springer, 
New York, 316-325. 
MacFarlane, A. G. J., and J. J. Belletrutti (1973). The characteristic locus design 
method. Automatica, 9, 575-588. 
Matsumoto, T., and M. Ikeda (1983). Structural controllability based on intermediate 
standard form (in Japanese). Transactions SICE, 19, 601-606. 
Mills, J. K., and A. A. Goldenberg (1988). Global connective stability of a class of robotic 
manipulators. Automatica, 24, 835-839. 
Monopoli, R. V. (1973). The Kalman-Yakubovich lemma in adaptive control system 
design. IEEE Transactions, AC-18, 527-529. 
Morse, A. S. (1973). Structural invariants of linear multivariable systems. SIA M Journal 
of Control, 11, 446-465. 
Narendra, K. S., and J. H. Taylor (1973). Frequency Domain Criteria for Absolute 
Stability. Academic Press, New York. 
Narendra, K. S., and L. S. Valavani (1978). Stable adaptive controller designdirect 
control. IEEE Transactions, AC-23, 570-583. 
Narendra, K. S., Y. H. Lin, and L. S. Valavani (1980). Stable adaptive controller design; 
Part 11: Proofs of stability. IEEE Transactions, AC-25, 440-448. 
Ohta, Y., and D. D. Siljak (1985). Overlapping diagonal dominance and existence of 
Lyapunov functions. Journal of Mathematical Analysis and Applications, 112, 396- 
410. 
Ohta, Y . ,  D. D. Siljak, and T. Matsumoto (1986). Decentralized control using quasi- 
block diagonal dominance of transfer function matrices. IEEE Transactions, AC-31, 
42G430. 
Parks, P. C .  (1966). Liapunov redesign of model reference adaptive control systems. 
IEEE Transactions, AC-11, 362-367. 
Radenkovit, M. S., (1989). Decentralized stochastic adaptive control of interconnected 
systems. International Journal of Adaptive Control and Signal Processing, 3 (to 
Radenkovit, M. S., and D. D. Siljak (1989). Robust self-tuning control. Technical Re- 
port EECS-881327304, School of Engineering, Santa Clara University, Santa Clara, 
California. 
Rosenbrock, H. H. (1974). Computer-Aided Control System Design. Academic Press, 
New York. 
Rouche, N., P. Habets, and M. Lalloy (1977). Stability Theory by Liapunov’s Direct 
Method. Springer, New York. 
Saberi, A,, and H. Khalil (1985). Decentralized stabilization of interconnected systems 
using output feedback. International Journal of Control, 41, 1461-1475. 
Saberi, A., and P. Sannuti (1988a). Global stabilization with almost disturbance decou- 
pling of a class of uncertain non-linear systems. International Journal of Control, 
Saberi, A., and P. Sannuti (1988b). Time-scale structure assignment in linear multivari- 
able systems by high-gain feedback. Proceedings of the 27th Conference on Decision 
and Control, Austin, Texas, 423-430. 
Siljak, D. D. (1969). Nonlinear Systems: The Parameter Analysis and Design. Wiley, 
New York. 
Siljak, D. D. (1971). New algebraic criteria for positive realness. Journal of the Franklin 
Institute, 291, 109-120. 
appear). 
47, 717-727. 

310 
5. Output Control 
Siljak, D. D. (1978). Large-Scale Dynamic Systems: Stability and Structure. North- 
Holland, New York. 
Siljak, D. D. (1989). Parameter space methods for robust control design: A guided tour. 
IEEE Transactions, AC-34, 674488. 
Swamy, M. N. S., and K. Thulasirarnan (1981). Graphs, Networks, and Algorithms. 
Wiley, New York. 
Tan, X. L., and M. Ikeda (1987). Decentralized stabilization of large-scale interconnected 
systems: A stable factorization approach. Proceedings of the 26th Conference on 
Decision and Control, Los Angeles, California, 2295-2300. 
Tan, X. L., and M. Ikeda (1990). Decentralized stabilizations for expanding construction 
of large-scale systems. IEEE Transactions, AC-35, 644451. 
Vidyasagar, M. (1985). Control System Synthesis: A Factorization Approach. MIT Press, 
Cambridge, Massachusetts. 
Willems, J. C. (1981). Almost invariant subspaces: An approach to high-gain feedback 
design; Part I: Almost controlled invariant subspaces. IEEE Transactions, AC-26, 
Willems, J. C. (1982). Almost invariant subspaces: An approach to high-gain feedback 
design; Part 11: Almost conditionally invariant subspaces. IEEE Transactions, AC- 
Willems, J. C., and M. Ikeda (1984). Decentralized stabilization of large-scale intercon- 
nected systems. Proceedings of the 6th International Conference on Analysis and 
Optimizations of Systems, Nice, France, 236-244. 
Wonham, W. M. (1979). Linear Multivariable Control: A Geometric Approach. Springer, 
New York. 
Wu, Q. H., and M. Mansour (1988). An application of Hm theory in decentralized 
control. Proceedings of the 27th Conference on Decision and Control, Austin, Texas, 
Wu, Q. H., and M. Mansour (1989). Decentralized robust control using Hw-optimization 
technique. Information and Decision Technologies, 15, 5g76. 
Yoshikawa, T., and M. Ikeda (1983). Decentralized adaptive control of large-scale sys 
tems: A parameter adaptation method. Electronics and Communications in Japan, 
Young, K. D. (1985). A decentralized control synthesis method for large-scale inter- 
connected systems. Proceedings of the American Control Conference, Boston, Mas- 
sachusetts, 574-579. 
Zames, G. (1966). On the inputboutput stability of time-varying nonlinear feedback sys- 
tems; Part I: Conditions derived using concepts of loop gain, conicity, and positivity. 
IEEE Transactions, AC-11, 228-238. 
235-252. 
27, 1071-1085. 
1335-1340. 
66-A, 25-32. 

Chapter 6 
Hierarchical LBT Decompositions 
So far, we have assumed that a system can be decomposed into subsystems 
on the basis of physical insight, intuition, or experience. During the mod- 
eling process, subsystems can be identified as natural parts of the system, 
and the choice where to tear a system is either obvious or can be made 
after a few simple experiments. 
When a system is complex having many states, inputs, and outputs, it 
may be difficult, or impossible, to obtain partitions by physical reasoning. A 
more appealing alternative is to develop systematic methods, which can be 
used to decompose a system by extracting information from the structure 
of the state equations themselves. Decompositions of this type can take 
advantage of the sparseness of the system matrices, and identify hidden 
structures that are conducive to conceptual and numerical simplifications 
of control and estimation design. In this way, decompositions of dynamic 
systems are embedded in the broad and powerful mathematical framework 
of sparse matrix research. 
In this chapter, we shall describe and use a graph-theoretic algorithm for 
partitioning a linear dynamic system into a Lower Block Triangular (LBT) 
form. The resulting system is obtained as a hierarchy of input reachable 
subsystems, and stabilization of the overall system can be accomplished 
by stabilizing decentrally a number of low-order subsystems. By involving 
the outputs in the tearing process, we can produce LBT partitions having 
subsystems with independent inputs and outputs. The subsystems are input 
and output reachable, and we will show how local observers can be built 
for a piece-by-piece stabilization using output feedback. 
We shall demonstrate the utility of LBT decompositions by a sequen- 
tial LQG optimization of hierarchically structured systems. The plant is 
assumed to be a linear discrete-time stochastic system, which is decom- 
posed into an LBT form. With subsystems, we associate quadratic costs, 
311 

312 
6. Hierarchical LBT Decompositions 
and minimize each sequentially, one at a time, assuming that feedback loops 
are closed at higher levels of the hierarchy. A methodology is described for 
deriving optimal control algorithms based on a construction of state mod- 
els for each stage of the optimization process. This approach allows for the 
standard LQG techniques to be used sequentially from top to bottom of 
the hierarchy. 
Finally, we discuss information structures for distributed control of 
LBT forms, and expose the intricate relationship between the physical con- 
straints of the system and the communication capabilities of the computer 
network. Special attention is paid to the sequential information structure 
where fast topdown communication makes data available from upper to 
lower levels of the hierarchy. The structure is contrasted to the standard 
global as well as the totally decentralized structure, which appear at the 
two opposite extremes of communication requirements. 
6.1. Input Decompositions 
We begin a presentation of the LBT design scheme by a description 
of the graph-theoretic procedure for decomposition of linear systems into 
LBT structures (Sezer and Siljak, 1981). The resulting system, being a hi- 
erarchical interconnection of input reachable subsystems, can be stabilized 
by decentralized local feedback applied to each individual subsystem. Be- 
fore stabilization is attempted, the subsystems matrices should be tested 
for full generic rank to make sure that the subsystems are structurally 
controllable (Section 1.4). The fact that input reachability and full generic 
rank of subsystems matrices imply not only structural controllability of the 
subsystems but the overall LBT system as well makes the LBT decomposi- 
tions appealing in stabilization of large-scale systems. When a system is in 
an LBT form, even ordinary controllability is implied by subsystems con- 
trollability; this makes it easy to remove any doubt about controllability of 
the overall system without resor.ting to numerically sensitive controllability 
criteria (Nour-Eldin, 1987) applied to the full-scale matrices of the original 
system. 
Let us consider a linear time-invariant system 
S: X=Ax+Bu, 
(6.1) 
where, as usual, x(t) E R" and u(t) E R" are the state and input of S at 
time t E R. With S, we associate a directed graph D = (U U X, E). The 

6.1. Input Decompositions 
313 
adjacency and input reachability matrices of D have the form 
A
B
 
F
G
 
We consider the problem of decomposing the system into an LBT form 
k 
k 
s Xk = 
A k j x j  + 
B k j U j ,  
k E N, 
(6.3) 
j=1 
j=1 
which is a hierarchical ordering of the subsystems 
S k :  Xk = A k k X k  + B k k U k ,  
k E N, 
(6.4) 
where x k ( t )  E R”” and u k ( t )  E Rmk .are the state and input of s k  at 
N 
N 
time t E R, and n = x k = l  n k ,  m = x k = l  m k ,  N = (1, 2, ..., N } .  
The decomposition (6.3) is obtained by permuting the states of S until 
the matrices A and B are brought into compatible LBT forms. Then, the 
interconnection matrix E has the obvious LBT representation 
, 
E =  
In terms of the digraph D = (U U X, E ) ,  the LBT form of E corresponds 
to an input acyclic partition PI of D into subgraphs D k  = ( u k  U x k ,  E k )  
associated with the block diagonal pairs ( A k k ,  B k k )  of the subsystem s k .  
6.1. DEFINITION. 
to be an input acyclic partition of D if 
A partition PI of a digraph D = (U U X ,  E )  is said 
(i) 
(ii) 
The interconnection matrix E has LBT form. 
Each subgraph D k  = (Uk U X k ,  E k )  is input reachable. 
If, in addition, none of the subgraphs D k  can be further partitioned into 
acyclic subgraphs, the partition PI is said to be irreducible. 
To obtain irreducible partitions PI, we assume that the digraph D is 
input reachable. Our decomposition scheme, however, can easily be modi- 
fied to remove the input unreachable part from D before the beginning of 

314 
6. Hierarchical LBT Decompositions 
decomposition process. To avoid trivial cases, we assume that each input 
vertex of D is adjacent to at least one state vertex. Under these assump 
tions, there always exists an irreducible partition PI, although that might 
be the trivial partition with N = 1. Obviously, we will be interested in 
nontrivial irreducible partitions of D, 
for the existence of which a neces- 
sary condition is that n > 1 and m > 1. Finally, we note that neither the 
irreducible partitions nor the number of subgraphs in such partitions need 
be unique, as we demonstrate by examples in Section 6.3. 
The first result is concerned with the existence of acyclic partitions that 
are not necessarily irreducible: 
6.2. LEMMA. Given a digraph D = (U u X, E) with n > 1 and m > 1. 
Then, D has a nontrivial partition PI if and only if the submatrix G of the 
reachability matrix R contains at least one zero element. 
Proof. Necessity follows by direct computation of R (see Section 1.2). To 
prove sufficiency, we assume that G contains a zero in the (2, j)th position 
and partition the set U into two disjoint subsets 
u1 = u - { U j } ,  
u2 = { U j } .  
(6.6) 
Let X2 be the largest subset of X that is reachable from uj, and let XI = 
X - X2. These subsets have the following properties: 
(i) U2 # 0 by construction and U1 # 0 by the assumption that m > 1. 
(ii) XI # 0 for xi E XI, and X2 # 0 by the assumption that each input 
(iii) By construction, no 21 E X1 is adjacent from uj. 
(2.) 
No xp E X1 is adjacent from some xk E X2, for otherwise $8 would 
be reachable from uj, contradicting the construction of X2. 
The properties (i)-(iv) imply that the chosen subsets of U and X induce 
a decomposition (6.5) of E with N = 2. Furthermore, both subgraphs 
D1 = (Ul U XI, El) and D2 = (U2 U X2, E2) are input reachable; D1 because 
of the properties (iii) and (iv) and D2 by construction. Therefore, D1 and 
D2 constitute a partition PI of the digraph D. 
Q.E.D. 
vertex is adjacent to at least one state vertex. 
The construction of PI described in the proof of Lemma 6.2 is the core 
of the following algorithm proposed by Sezer and Siljak (1981) as Input 
Decomposition (IDEC). 

6.1. Input Decompositions 
315 
6.3. ALGORITHM. 
IDEC 
Assume n > 1, m > 1, and calculate input reachability matrix G. 
IF G(i, j )  # 0, V i ,  j 
Define the index sets 
R E T U R N  
I =  (21, iz, ..., ik} c (1, 2, ..., n} 
J =  { j i , j z ,  ..., j e }  c (1, 2, ..., m} 
(1) rows 21, 22, . . . , zk of G are the same and contain 1 in 
columns jl , j z ,  . . . , j e  of R and 0 in other columns; 
(2) when rows 21, ZZ, . . . , zk and columns j1, 
j 2 ,  . . . , j e  of G are 
deleted, the resulting submatrix contains no zero rows. 
such that 
Define the state and input partitions 
x1 = (&, i E I } ,  xz = x - x1 
Ui=(~j,j E J } ,  Uz=U-U1 
O U T P U T  irreducible partition (U1 , XI} 
E N D  IDEC 
It is clear now that the assumptions on n, m, and G guarantee the 
existence of the index sets I and J. Letting 
x1 = { X i l ,  X i z ,  . . . , %}), 
x2 = x - Xl, 
we prove the following result: 
6.4. THEOREM. The subgraphs D k  = (Uk U Xk, E), k = 1, 2, where Uk 
and x k  are defined by (6.7), constitute a partition PI of D = (U U X, E) 
such that D1 is irreducible. 
p7‘0Oi 
The proof that D k  = (Uk U Xk, E), k = 1, 2, is an acyclic 
input reachable partition is similar to the proof of the sufficiency part of 
Lemma 6.2. Since the submatrix of G consisting of rows 21, iz,. . . , ik and 
columns j,, j 2 ,  . . . , j, is the input reachability matrix of D1 and contains 
no O’s, Lemma 6.2 implies that D1 is irreducible. 
Q.E.D. 
The main feature of the decomposition scheme leading to Theorem 6.4 
is that it can be used recursively to remove an irreducible subgraph from 
D at each step, the existence of which is guaranteed by Theorem 6.4. This 
recursive process produces eventually an irreducible partition PI. F’urther- 
more, if at each step we consider all possible choices of subgraphs to be 
removed, we can generate all irreducible partitions. 
A considerable reduction in the computation which is involved in Algo- 
rithm 6.3 can be achieved if we obtain the condensation D* 
of D first. and 

316 
6. Hierarchical LBT Decompositions 
apply the scheme to D'. For this purpose, we partition the set X of D as 
P 
x = u  x;, 
i=l 
so that each XI is a vertex set of a strong component of the subgraph 
D, = (X, E) which was termed the state truncation of D (Section 1.3). 
This decomposition of D, into strong components induces a partition of 
the input nodes: 
9 
u = u  q. 
i=l 
Each q contains all the input vertices that are adjacent exactly to those 
state vertices that occur in the same strong component of D,. By D* = 
(U' U X*, E'), we denote the condensation of D with respect to the partitions 
of the sets X and U in (6.8) and (6.9), and prove the following: 
6.5. THEOREM. To any irreducible partition PI of D* into N sub 
graphs, there corresponds a unique partition PI of D into the same number 
of subgraphs and vice versa. 
Proof. Consider an irreducible P; of D* = (U* U X*, E*) into subgraphs 
D; = (Ui U X;, Ei), k E N, according to which D* has the interconnection 
matrix 
We define the subsets Ukr x k ,  k E N, of U and X as 
u k  = {
~
i
 
E U: Ui E U; for some 213 E u;}, 
Xk = {xi E x zi E xj' for some $ E xi}, 
(6.11) 

6.1. Input Decompositions 
317 
where 
Xk are uniquely defined subsets satisfying 
and Xj’ are defined in (6.8) and (6.9). It is easy to see that u k  and 
N 
Ui nuj = 0, 
i + j ,  
U u k  = U, 
k=l 
(6.12) 
N 
Xi n xj = 0, 
i # j ,  
so that they induce a partition PI of D = (U U X, E) into D k  = (uk U 
x k ,  Ek), k E N. The subgraphs D k  have the following properties: 
(2) 
No xi E x k  is adjacent to some xj E Xe for k > c, for, otherwise, 
some x: E Xi, for which xi E X:, would be adjacent to some x*, E X;, for 
which xj E X:, contradicting the structure of E’ in (6.10). Similarly, no 
Ui E u k  is adjacent to some uj E Up for k > e. 
(ii) Each subgraph D; of D’ is the condensation of the corresponding 
subgraph D k  of D, where condensation is performed in exactly the same 
way as D is condensed to D’. Since the D;’s are input reachable by the 
construction of P;, it can be shown (Theorem 1.19) that the D k ’ S  are also 
input reachable. 
By the construction of P;, the D;’s are irreducible. Thus, by 
Lemma 6.2, each u,’ E U; reaches all x3f E x k  which, in turn, implies that 
each u, E u k  reaches all x, E x k .  Using Lemma 6.2 once more, we show 
that the D k ’ S  are irreducible. 
U 
x k  = X, 
k= 1 
(iii) 
Properties (2)-(iii) imply that the partition induced by the partitions 
To prove the converse result, consider any irreducible partition PI of 
interconnection matrix of D has the LBT form (6.5). We note that any 
two state vertices that belong to the same strong component of D, should 
occur in the same subgraph D k ,  as well as any two input vertices that are 
adjacent to exactly the same state vertices. Thus, the definition 
of the sets U and X in (6.8) and (6.9) is an irreducible partition PI. 
D = (U U X, E) into D k  = (Uk U Xk, Ek), k E N, 
according to which the 
U; = { ~ r  
E U*: 
C Uk}, 
k E N, 
(6.13) 
of the subsets U; and X; of U* and X’ is consistent, and these subsets induce 
a unique partition P* of D *  = (U’ U X, E*) into D; = (U; U Xi, E;), k E 
N. Moreover, it can be shown that properties (i)-(iii) described above 
X; = {Xr E X*: Xa G Xk}, 
k E N, 

318 
6. Hierarchical LBT Decompositions 
still hold when the roles of Xk, Uk, Dk and Xi, Ui, D; are interchanged. 
Therefore, P' is an irreducible partition P; of D*. 
Q.E.D. 
Simply stated, Theorem 6.5 says that the decomposition problems of 
D and D* are interchangeable. However, D* is usually much smaller than 
D, and decomposition of D* instead of D is an equally smaller computa- 
tional effort. Furthermore, identifying strong components of D makes the 
stabilization scheme applicable to the subsystems sk directly as explained 
in the next section. 
Once a system is obtained in the LBT form with input reachable sub 
systems, we should proceed by testing the generic rank of the subsystems 
to make sure that none of them are of Form I1 (Definition 1.27). If one or 
more subsystems have a deficient generic rank, that is, the corresponding 
subgraphs have a dilation (Remark 1.31), we have to modify the resulting 
partition to eliminate the dilation from the subgraphs. For this purpose, 
we denote by D* = (V*, E*) the condensation of the system digraph D with 
respect to some partition PI, 
where v k  = u k  U x k .  Then, we assign levels 
to the vertices of D* in such a way that any vertex that is not reachable 
from some other vertex has the assigned level 0, and any vertex v,' has 
the assigned level C if the length of the longest path from some vertex at 
level 0 to v,' is C. Since D* is an acyclic digraph by the construction of PI, 
the level assignment procedure is consistent in that every vertex v,' has a 
unique assigned level (see Theorem 1.18). Corresponding to the levels of 
vertices of D*, each subgraph Dk of the partition PI has a unique assigned 
level, which is the same as the level of v; in V*. In Figure 6.1, the level 
assignment is illustrated by eight-vertex condensation. 
Testing of the subgraphs Dk for dilation starts from the lowest level. 
If a subgraph Di is found to have a dilation, that is, the corresponding 
structured matrix [ j i  &] has Form 11, then D, can be combined with 
another subgraph Dj at a lower level (if w,' is adjacent from v;) to obtain 
a composite subgraph 
(6.14) 
of D, where Qj is the set of edges of D that connect vertices of Dj to vertices 
of Di. Since dilations occur due to the lack of edges in Di, additional edges 
E,j may be sufficient to prevent the dilations of Di from appearing in Djj. 
In combining the subgraphs Di and Dj, we should not destroy the acyclic 
property of D*. Therefore, we should merge together with Di and Dj all 
other subgraphs Dk such that v; appears on any path from v; to v,'. For 
example, referring to Figure 6.1, if we combine D7 with D3, then we should 
include D5 as well. Once D3, Dg, and D7 are combined to form D357, we 

6.1. Input Decompositions 
319 
D*: 
"' Y 
LEVEL 0 
LEVEL 1 
LEVEL 2 
LEVEL 3 
Fig. 6.1. Level assignment. 
cbtain another acyclic partition PI with respect to which the condensation 
D* of D is shown in Figure 6.2 together with its level assignment. 
We note that if the dilation in a subgraph cannot be avoided by merging 
it with the adjacent subgraphs, then more complex combinations can be 
tried. For example, if the subgraph D, corresponding to vg in Figure 6.2 
contains a dilation that also appears in &3, 
then we can try the combina- 
tion of 0 6 8  with D 4 .  Provided D contains no dilation, this process leads to 
an acyclic partition PI of D, the subgraph of which has no dilation. The 
corresponding system S is in an LBT form with structurally controllable 
subsystems, and we may proceed to stabilize the system by stabilizing each 
subsystem separately. 
Before closing this section, we should mention an alternative approach 
to graph-theoretic decomposition of systems with inputs, which has been 
proposed by Vidyasagar (1980). After the system digraph is partitioned 
into strong components with respect to states, the inputs are identified 
as attached to the components and included in the subsystems. This sec- 
ondary role of inputs may cause a problem, because after decomposition 
some subsystems may have no inputs of their own or no inputs at all. In 

320 
6. Hierarchical LBT Decompositions 
,* 
D :  
Fig. 6.2. Level assignment. 
LEVEL 0 
LEVEL 1 
LEVEL 2 
LEVEL 3 
the decomposition scheme outlined in this section, the partitioning of the 
system digraph is performed directly in terms of inputs via input reachable 
components, which ensures that each subsystem has its own input, this be- 
ing the crucial requirement in the decomposition approach to stabilization. 
6.2. Stabilization 
When a system S is in an LBT form, stability of each subsystem implies 
stability of the overall system. For this reason, we describe only a subsystem 
stabilization by considering a typical subsystem 
S: X=Ax+Bu, 
(6.15) 
where the subscripts are dropped for simplicity. Controllability of the sub- 
system S implies that there exists a feedback law 
u = -Kx, 
(6.16) 

6.2. Stabilization 
321 
which places the eigenvalues of S at prescribed locations. We recall that 
in the process of obtaining an acyclic decomposition of the overall system, 
the strong components of each subsystem have been identified, and the 
subsystem matrix A in (6.15) is also in an LBT form. Using this fact, we 
can give an efficient procedure to obtain the feedback matrix K in (6.16). 
Let us first assume that the subsystem S in (6.15) has two strong com- 
ponents, so that the A matrix is of the form 
The matrices B and K can be partitioned accordingly as 
(6.17) 
(6.18) 
From (6.17), it follows that controllability of the pair (A, B) implies con- 
trollability of the pair (All, B1). Therefore, there exists a matrix F1 such 
that 
where A(A11 - B1F1) denotes the set of eigenvalues of A11 - B1F1, and C1 
is a symmetric set of prescribed eigenvalues for All - B1F1 such that 
Wb2) 
n el = 0. 
(6.20) 
We let A11 = All - BlFl, and consider the equation 
Equations (6.19) and (6.20) guarantee that (6.21) has a unique solution for 
TI (Gantmacher, 1959). We now have the following: 
6.6. LEMMA. The pair (A22, B2 - T1B1) is controllable. 

322 
6. Hierarchical LBT Decompositions 
Proof Controllability of the pair (A, B )  implies (Rosenbrock, 1970) 
XI - All 
0 
=rank ([ I '1 [ 
-TI 
I 
-A21 
XI -A22 
B2 
F1 
0 I 
where n1 and n2 are the dimensions of the square matrices All and A22, 
and the last equality follows from (6.21). Thus, we have 
rank [XI - A22, B2 - TIB1] = n2, 
VX E C. 
(6.23) 
Q.E.D. 
Lemma 6.6 implies that for any symmetric set 15 of prescribed eigen- 
values, there exists K2 such that 
A[A22 - (B2 - T I B I ) K ~ ]  
= &. 
With K2 chosen as above, we set 
K1 = F1 - K2T1, 
and prove the following: 
6.7. THEOREM. A(A - BK) = L1 U C2. 
Proof. The proof is immediate upon noting that for 
we have, from (6.21) and (6.25), 
.-'(A 
- BK) = 
1 
where A22 = A22 - (B2 - TlBl)K2. 
(6.24) 
(6.25) 
(6.26) 
(6.27) 
Q.E.D. 

6.2. Stabilization 
323 
The argument leading to Theorem 6.7 provides a recursive procedure 
for assigning the eigenvalues of a subsystem having two strong compo- 
nents. Since this procedure requires only transformation of (All, B1) and 
(A22, B2 - T1B1) into suitable forms to satisfy (6.19) and (6.24), and the 
solution of (6.21), it is more efficient than any single step procedure that 
requires a transformation of the whole subsystem. 
To complete our discussion, we consider the general case, where the 
matrices A and B of (6.15) have the form 
0 
... 
0
1
 
= [-B:] 
B1 
. 
(6.29) 
Partitioning the feedback matrix accordingly as 
and noting that the A matrix in (6.28) has the form (6.17), we observe that 
the eigenvalue assignment problem can be solved by following the steps: 
(1) Choose 8'1 so that A(A11 - B1F1) = 121, where L1 is a symmetric 
set of eigenvalues such that A(A!,,) fl C; = 0. 
(2) Solve 
for TI, where A11 = All - B1Fl. 
symmetric set of eigenvalues. 
(3) Choose Kh such that A[A',, - (Bh - TlB1)K;] = C!,, where C!, is a 
(4) Compute K1 = F1 - KhT1. Then, A(A - B K )  = C1 U CL. 

324 
6. Hierarchical LBT Decompositions 
Only steps (2) and (3) may involve operations on relatively large ma- 
trices. However, writing (6.31) explicitly as 
[ :t: 
A33 
O] 
A k 2  
A k 3  . . . 
A k k  
.................... 
Tl "1 k 
we observe that the blocks TIZ, 
T13, . 
recursively the following equations: 
.. T 1 k  of TI can be obtained by solving 
Furthermore, the problem of computing Ki in step (3) is similar to the 
original problem of computing K ,  where A, B, and K ,  are replaced by lower 
dimensional matrices Ah2, Bb -TI&, and Ki, respectively. Thus, the blocks 
K1, K2, . . . , Kk of the gain matrix K can also be obtained recursively by 
solving a set of equations as in (6.33), resulting in a considerable saving of 
the computational effort. 
6.8. EXAMPLE. To illustrate the stabilization procedure let us consider 
the system S described by the equation 
0
0
0
0
0
0
0
0
 
0 
a22 
a23 
0 
a25 
a26 
a27 
a28 
0 
0 
a33 
0 
0 
0 
0 
a38 
0 
0 
0 
a44 
0 
0 
a47 
0 
0
0
0
0
0
0
0
0
 
a61 
a62 
a63 
a64 
a65 
a66 
0 
0 
0 
0 
0 
0 
0 
O
a
7
7
O
 
0 
0 
a83 
0 
a85 
0 
0 
0 

6.2. Stabilization 
325 
+ 
0 
b12 
b13 
0 
b22 
0 
0
0
0
 
0 
b42 
0 
0 
b52 
b53 
b6l 
0 
0 
b71 
0 
0 
0
0
0
 
(6.34) 
where aij's and bij 's denote arbitrary nonzero elements. 
acyclic partitions: 
Applying the input decomposition scheme, we obtain two irreducible 
u: = {u2, u3), 
u; = { U I ) .  
(6.36) 
The partition P: of D is shown in Figure 6.3. It can easily be verified 
that the subgraph Di contains a dilation, that is, the structured matrix 
[A33 B3] does not have the full generic rank. Dilation takes place whenever 
a subgraph Dk = ( u k  u x k ,  E k )  contains a subset of vertices i i  G XI, such 
that the number of distinct vertices of u k  U x k  from which a vertex of %i 
is reachable is less than the number of vertices of %i. From Figure 6.3, we 
conclude by inspection that i i  = (21, 2 5 )  is such a subset. This graphical 
characterization of dilation is equivalent to the generic rank characteriza- 
tion: Dk contains a dilation if and only if the nk x (nk + mk) structured 
matrix [&k 
&k] 
contains a zero submatrix of order T x (nk +mk + 1 - 
T )  for 
some T such that 1 5 T 5 nk (see Lemma 1.54). To eliminate the dilation 
in D;, we can combine the subgraphs Di and D; into a single digraph Di3. 
In this way, we obtain a partition of D into two structurally controllable 
components. 
The other irreducible partition P: of D given in (6.36) has two sub- 
graphs D: and Di that are structurally controllable. Permuting the states 

326 
6. Hierarchical LBT Decompositions 
D: 

6.2. Stabilization 
327 
and inputs of S according to Pf, we obtain the LBT representation of S as 
- 
- 
0
0
 
0
0
 
a 2 2  
a26 
a62 
a 6 6 -  
-
0
0
0
0
 
0
0
0
0
 
0 
0 
a 3 3  
a38 
0 
a 8 5  
a83 
0 
0
0
0
0
 
0
0
0
0
 
0 
a25 
a23 
a28 
- a 6 1  
a 6 5  
a 6 3  
0 
+ 
(6.37) 
To illustrate the eigenvalue assignments for subsystems, let us consider 
the subsystem SZ in (6.37) and assume the following numerical values for 
aij’s and bij ’s: 
l i 0  0 
0 
-3 j-4 
0 
0 
A =  
(6.38) 
Let the set of required eigenvalues for the closed-loop subsystem be 
(6.39) 
\ .  
L = (-1) u {-ll -1 +jl, -1 -jl}, 

328 
8. Hierarchical LBT Decompositions 
and let us partition the feedback matrix to be computed as 
K = [Ki K;]. 
(6.40) 
Following the steps outlined above, we first choose a matrix F1 such 
which can easily be obtained as 
F1 = 2. 
With this Fl, Equation (6.31) becomes 
the solution of which can be computed as 
Ti = [-1 1 1/2]*. 
0 
01 2, 
-1 
At this stage, the problem reduces to computing K; such that 
(6.41) 
(6.42) 
(6.43) 
(6.44) 
(6.45) 
Repeating the entire procedure for Ah2, Bh - T ~ B I ,  
K;, and Lh instead 
of A, B, K ,  and L, we can compute 
K; = [0 0 21. 
(6.48) 
Finally, using (6.25), we obtain K1 in (6.40): 

6.3. Input-Output Decompositions 
329 
The required feedback matrix is 
K = [l 0 0 21. 
(6.50) 
From this example, we conclude that LBT decompositions can be use- 
ful in a number of ways. First, the stabilization problem of the overall 
system is reduced to stabilization of a number of smaller problems associ- 
ated with the subsystems. Second, the special structure of the subsystems 
allows for a "piece-by-piece" computation of the feedback gains, providing 
an additional possibility for dimensionality reduction of the stabilization 
problem. Furthermore, once the block triangular structure is determined, 
the interconnections, which are outside the subsystems, can be identified 
as interconnections that have no effect on stability of the overall closed- 
loop systems, either in the size or sign of their elements. It should also be 
mentioned that the proposed decomposition scheme, being independent of 
the nature of the equations (nonlinear, discrete, etc.), can be used for sta- 
bilization of wider classes of systems than presently considered, provided 
the obtained subsystems can be stabilized by known methods. 
6.3. Input-Output Decompositions 
The output decompositions are obvious duals of input decompositions, 
which can be used in simplifying the state determination problem of large 
sparse systems. If we want to solve simultaneously the state determina- 
tion and control problems in a subsystem-by-subsystem fashion, we need 
the input-utput 
decomposition scheme introduced by Pichai et al. (1983), 
which produces hierarchically ordered subsystems with independent inputs 
and outputs. If such a decomposition is attempted by the inpu and out- 
put decompositions separately, the result may be unsatisfactory because 
the input and output partitions would not be compatible. The subsystems 
would share the inputs and outputs or even the states. The purpose of 
this section is to describe the input-output reachable acyclic decomposi- 
tions, which can be used for an efficient and numerically attractive design 
of decentralized estimators and controllers for large sparse systems. 
it 
Let us consider a linear dynamic system 
S: .z=Ax+Bu, 
(6.51) 
where, as usual, z(t) E R" is the state, u(t) E R" is the input, and 
y ( t )  E Re is the output of S at time t E T, and A, B, and C are constant 
y = c x ,  

330 
6. Hierarchical LBT Decompositions 
matrices of appropriate dimensions. In (6.51), we use ~ ( t )  
E R" to repre- 
sent the change of the state x(t) in time. When ~ ( t )  
= dx(t)/dt, T is the 
nonnegative real line R+, and S is a continuous-time dynamic system. In 
case z(t) = x(t + l), T is a set of nonnegative integers (0, 1, 2, . . . , }, and 
S is a discrete-time system. 
We consider the problem of decomposing the system S into the Input- 
Output LBT form 
i 
a 
j=1 
j=1 
(6.52) 
i 
yi =C C i j ~ j ,  
i E N, 
j=l 
which is a hierarchical interconnection of N subsystems 
(6.53) 
where xi(t) E Rni, ui(t) E Rmi, and yi(t) E Re% are the state, input, and 
output of the subsystem Si at time t E T, and 
ni = n, xEl mi = m, 
and CE1 & = l. 
With the dynamic system S of (6.51), we associate a digraph D = 
(U U X U Y, E) with the interconnection matrix 
E = O O O ,  
[:: : 
:I 
and the reachability matrix 
F
G
O
 
(6.54) 
(6.55) 
which can be computed by Algorithm 1.10. 
The decomposition (6.52) is achieved by a permutation of the variables 
of S, which brings the matrices A, B, C of (6.51) into an LBT form. Ac- 

6.3. Input-Output Decompositions 
331 
cordingly, the interconnection matrix E of (6.54) becomes 
E =  
. (6.56) 
In terms of the associated digraph D = (U U X U Y, E), the above 
decomposition of S corresponds to a partitioning of D into subgraphs Di = 
(Ui U Xi U Yi, &) that identify the triplets ( A i i ,  &, Cii) of (6.53) and, thus, 
the subsystems Si. 
For purposes of control and estimation of S ,  we decompose the system S 
into a hierarchically ordered input-output reachable subsystem. The input- 
output reachability (see Remark 1.12) is the essential for controllability- 
observability of S, and it is the first part of structural controllability and 
observability of S. The other part is the full generic rank of the matrices 
[A b] and [AT ZITIT, which should be tested on the subsystems levels after 
the LBT form of S is obtained for the reasons explained in the context of 
input LBT decompositions in Section 6.1. Thus, we start with: 
6.9. 
said to be an input-output acyclic partition if 
DEFINITION. A partition Pro of a digraph D = (U U X U Y, E) is 
The interconnection matrix E is in an input-output LBT form. 
Each subgraph Di is inputkoutput reachable. 
(i) 
(ii) 
An obvious necessary condition for existence of I 0  reachable partitions 
is that the digraph D itself be I0 reachable. If this is not the case, the 
decomposition procedure can easily be modified to remove the unreachable 
parts of D before the decomposition is started. To avoid trivial cases, we 
assume that each input vertex of D is adjacent to at least one state vertex, 
and each output vertex is adjacent from at least one state vertex. These 

332 
6. Hierarchical LBT Decompositions 
assumptions imply that D itself is a trivial partition PIO with N = 1. TO 
consider nontrivial partitions of D, we assume that n > 1, m > 1, and 
e >  1. 
Let us assume that D = (U U X U Y, E) has an acyclic partition into two 
subgraphs Di = (Ui U Xi U Yi, &), i = 1, 2. Then, the reachability matrix 
R of D can be obtained from the interconnection matrix E of (6.56), with 
N = 2, by direct computation (Algorithm 1.10) as 
F i 1  
0 i G11 
0 
0 0 
F21 
F22 I G21 
G22 1 0 01 
R =  
(6.57) 
where, by assumption, G I 1  and G22 have no zero rows, H 1 1  and H22 have no 
zero columns, and 
and 022 each have at least one nonzero element. From 
(6.57), we observe that a necessary condition for the existence of an acyclic 
I0 reachable partition is that the input-output reachability submatrix e 
contains at least one zero element. Such a simple condition on G was nec- 
essary and sufficient for the existence of acyclic input reachable partitions 
of D, which were described in the preceding section. For I0 reachability, 
this is not even close to sufficiency, and we proceed to consider a Boolean 
OR operation on the rows and columns of R corresponding to U1, U2, Y1, 
and Y2. This yields a reduced reachability matrix 
R =  
F G O  
0
0
0
 
a 0 0  
1 
(6.58) 
where ei = (1, 1, . . . , l)T, 
i = 1, 2, and * denotes submatrices of element; 
that are of no concern at this point. Finally, taking the Boolean AND of G 

6.3. Input-Output Decompositions 
333 
and HT in (6.58), that is, S = G A HT, we can get the matrix 
and state the following: 
(6.59) 
6.10. 
A given digraph D = (U U X U Y, E) has a PIO par- 
tition if and only if U and Y can be partitioned into U1, US, and Y1, Y2 such 
that 6 has the form in (6.58), and the matrix S contains exactly a single 1 
in each row. 
THEOREM. 
Pmoj Necessity is obvious from the construction of the matrices fi 
and S. On the other hand, if the matrix S = (Si,) has exactly a single 1 in 
each row, defining X j  = {xi E X: Sij = 1, i E 3, 
j = 1, 2, we obtain a 
partition of X into X1 and Xz. A permutation of x according to this partition 
puts S into the form of (6.59), which implies that X j  is reachable from Uj 
and reaches YJ. Furthermore, the form of R in (6.58) implies that neither 
U2 reaches X1 nor X2 reaches X1 or Y1. Thus, we obtain a PIO partition of 
D into Dj = {Uj U X j  U Yj, Ej}, j = 1, 2. This completes the sufficiency 
and the proof. 
Q.E.D. 
To get the maximum benefit from the decomposition we would like to 
obtain irreducible PIO partitions of D, in which no subgraph Di can be 
further decomposed into acyclic I 0  reachable subgraphs. For this purpose, 
we need the following definition: 
6.11. 
We say that in the I x m matrix 6 = (&) of (6.55), 
the pth row dominates the 9th row if 6, = 1 whenever eqr = l,, and for at 
least one r, 0, = 1, but O,, = 0, r E M =  (1, 2, .. ., m}. 
DEFINITION. 
The following result is automatic: 
6.12. THEOREM. Under the conditions of Theorem 6.10, the subgraph 
D1 of the PIO partition induced by the matrix S is irreducible if and only 
if no row of the matrix 6 corresponding to Y1 dominates any other row 
corresponding to Y2. 

334 
8. Hierarchical LBT Decompositions 
In other words, if we start the partitioning of the digraph D from those 
rows of 8 that are not dominated by any other row of 8, we guarantee 
irreducibility of the first digraph D1 of the resulting partition PIO, 
provided 
such a partition exists. Once such a partition is obtained, the algorithm 
can be applied successively to the remaining subgraph Dz to generate the 
irreducible partitions of the entire digraph D. 
The following algorithm of Pichai et al. (1983) can be used to generate 
all irreducible acyclic partitions of a given digraph D: 
6.13. ALGORITHM. 
PROCEDURE DECOMP 
Calculate reachability matrix R 
Form I 0  reachability matrix 8 
IF 8 ( p ,  q) # 0 Vp, q, THEN RETURN 
ELSEk=O, j = O  
ELSE i = j + 1 
1 
IF j = e THEN RETURN 
2 
3 
IF 6(i, *) dominates (+) labeled 8 ( p ,  *)Vp 
IF 8(i, *) labeled THEN j = j + 1 GO TO 1 
ELSE continue 
THEN label (+)8(2, *), i = j + 1, GO TO 2 
IF 8(i, *) dominates unlabeled 8 ( p ,  *) Vp 
THEN i = p GO TO 3 
ELSE continue 
Define the index sets 
I =  { p  = 1, 2, . . . , e: 8(i, *) dominates 8 ( p ,  *)} 
J =  { j  = 1 , 2 ,  . . . , m: e(i, j )  = 1) 
Define the input and output partitions 
u1 = {uj: j E 4, u 2  = u - u1 
Y1 = {yj: j E I), Y2 = Y - Y1 
Form reduced reachability matrices R, c, H 
Compute S = 2: A HT 
IF S has one and only one nonzero in each row 
THEN Define sqate partition 
X1 = {zp: S(*, 
1) has nonzero in pth row} 
x 2  = x - x1 
Ic = Ic + 1, OUTPUT {Ui U Xi U Yi} 
label (+) 8(i, *) GO TO 1 
ELSE label (-1 &i, *) GO TO 1 
END DECOMP 
Now. several remarks are in order. 

0.3. Input-Output Decompositions 
335 
6.14. REMARK (Existence and Uniqueness). From the algorithm we see 
that if the I 0  reachability matrix 6 contains no zero elements, then D has 
no acyclic partitions. On the other hand, if D has such partitions, they 
are not necessarily unique. For example, the digraph of Figure 6.4 has two 
distinct decompositions, one having two and the other three components. 
In Algorithm 6.13, k denotes the number of distinct acyclic partitions of 
D. 
6.15. REMARK (Condensations). As in the input reachable decompe 
sitions of Section 6.1, the computations involved in Algorithm 6.13 can 
be considerably reduced by considering a condensation of D instead of D 
itself. For this purpose, we partition the vertex sets of D as 
V 
a 
r 
x = u  x;, 
u = u  q, Y = U  Y;, 
i=l 
i=l 
i=l 
(6.60) 
where X,? are the vertex sets of the strong components of the state truncation 
subgraph D, = (X, E,) defined in Section 1.3, and each U,?(Y,?) 
contains all 
the input (output) vertices that are adjacent to (from) those state vertices 
that occur in the same strong component of D,, but no others. If we denote 
the condensations of D with respect to the above partition by D* = (U* U 
X* U Y*, E*), then it is not difficult to show that, to any irreducible acyclic 
partition of D into N subgraphs, there corresponds a unique irreducible 
acyclic partition of D* into the same number of subgraphs, and conversely. 
Intuitively, this follows from the fact that any two state vertices of D that 
belong to the same strong component of the truncation D, should occur in 
the same subgraph of any irreducible acyclic decomposition of D, as well 
as any two input (output) vertices that are adjacent exactly to (from) the 
same strong component of D,. In case of input decompositions, this result 
has been established by Theorem 6.5. 
The fact outlined above simply states that the decomposition problems 
of D and D* are interchangeable. However, since D* is considerably smaller 
than D, irreducible acyclic partitions of D can be generated much more 
easily by first obtaining D*, and then applying the decomposition scheme 
to D'. An additional advantage of using such an approach is that the strong 
components of each subgraph D; of the decoupled subsystems would also 
be identified as a by-product of the decomposition scheme, allowing for a 
further simplification in the subsequent control design (see Section 6.2). 

336 
6. Hierarchical LBT Decompositions 
Fig. 6.4. Two distinct I 0  partitions. 

6.3. Input-Output Decompositions 
337 
6.16. REMARK (Input and Output Reachable Partitions). In general, 
decompositions of a digraph into I 0  reachable subgraphs are more restric- 
tive than decompositions into only input (output) reachable subgraphs 
without considerations of outputs (inputs). For example, the digraph of Fig- 
ure 6.5a has no I0 reachable partitions, but it does have an input reachable 
partition as shown in Figure 6.5b, as well as an output reachable partition 
BS given in Figure 6.5~. 
This observation suggests that each subgraph Dk of 
an I 0  reachable partition can be further decomposed into input (output) 
reachable subgraphs. This way, we obtain a multilevel partition of D as 
illustrated by the corresponding interconnection matrix of Figure 6.6. 
6.17. REMARK (I0 Decomposition is NP-complete). It was shown by 
Tarjan (1984) that our I0 decomposition scheme is NP-complete. In the 
studies of algorithm design and computational complexity, the NP-complete 
problems are of central interest, and Tarjan’s result calls for an explana- 
tion of what it means in the context of estimation and control designs. We 
start by recognizing the fact that in combinatorial problems one prefers 
polynomial to exponential time algorithms, because the latter type have 
a running time which grows exponentially with the length of the input 
and can rapidly put a problem beyond available computational means. 
For this reason, one is interested in finding a polynomial algorithm for 
a given problem, or showing that no such algorithm is possible and the 
problem is “intractable.” Due to a lack of such strong results, one looks 
for a class of problems that are equally difficult and can serve as a ref- 
erence in evaluating the complexity of a given problem. Such class is the 
set of NP-complete problems (Garey and Johnson, 1979), which are poly- 
nomially transferable into each other, and which are probably intractable. 
Although the NP-complete problems have been difficult to solve, we stress 
the fact that it is not known that there are no polynomial algorithms €or 
their solution. Furthermore, even if they are intractable, the meaning of 
“intractability” should not be taken literally, because the 2n algorithm is 
faster than n5 algorithm for n 5 20. Since our I 0  decomposition involves a 
condensation digraph D* = (U* U X* U Y*, E*), if we assume, for example, 
that each super-state x* E X* represents on the average ten states of the 
strong component of the truncation D, = (X, E,), then it follows that we 
can consider a system S having two hundred states without any concern 
about intractability. We can safely say that the dynamic part of the control 
problems in large-scale systems would saturate numerically well before the 
I 0  decomposition algorithm would experience some difficulties, if any at all 
(Pichai et al. 1984). Finally, we should note that the I 0  decomposition is 
NP-complete because it involves matching of three sets: input, state, and 

338 
6. Hierarchical LBT Decompositions 
D :  
I t - - - -  
1 
(d 
Fig. 6.5. Digraph without I 0  reachable partition. 
output vertices of D*. On the other hand, the input decomposition and 
output decompositions are “two dimensional” problems, and can be solved 
in polynomial time. For this reason, one can use two-stage decompositions 
for building estimators and controllers. First, an output decomposition is 

6.3. Input-Output Decompositions 
339 
E =  
X 
U 
Y 
Fig. 6.6. Interconnection matrix. 
used to build an estimator, and then the variables are permuted into an in- 
put decomposition to design a controller. This two-stage design is possible 
because the separation principle for the estimator-controller combination 
is valid. How this can be done even when there is no I 0  decompositions at 
all, is shown in Example 6.25. 
6.18. REMARK (Structural Controllability and Observability). We re- 
call that the objective of the I0 decomposition is to produce an acyclic 
partition of S into input and output reachable subsystems. After such a 
partition is obtained, the subsystem can be checked for full generic rank 
to ensure that all the subsystems are structurally controllable and observ- 
able (Section 1.4). Of course, the subsystems can be checked for standard 
controllability and observability, which suffice to establish these properties 
for the overall system S ,  because it has the lower block triangular form. 
This should normally be an easy task since the subsystems are of lower 
dimensions. If we discover a lack of full generic rank in any of the subsys- 
tems, the corresponding subsystems can be fused into larger subsystems in 
order to satisfy the full rank condition. This procedure has been explained 
in Example 6.8 which dealt with input reachable partitions. 

340 
8. Hierarchical LBT Decompositions 
s: k(t) = 
6.19. EXAMPLE. To illustrate the application of the I 0  decomposi- 
tions, we consider a dynamic system described by the equations 
- 
all,] 
Y(t) = 
r 
- 
b31 
b12J 
a32 
a72 
a10,3 
b62 
b83 
a15 
a76 
a95 
b15 
b24 
b65 
b95 
c42 
c24 
c47 
(6.61) 

6.3. Input-Output Decompositions 
341 
-1 0 1 0 0- 
0
0
1
0
1
 
6
=
0
0
0
0
1
 
(6.62) 
0
1
0
1
1
 
-1 1 0 1 1, 
- 
O
O
O
O
O
O
O
I
O
O
O
I
T
 
(6.63) 
l
l
l
l
l
l
l
o
l
l
l
o
l
 
1 
S =  [ 
which indicates that the partitions 
yield an acyclic I 0  reachable decomposition of D into two components 
Dt = {Ui U Xi U Yi, Ei}l i = 1, 2, where D: is irreducible. 
Having achieved a decomposition, we label the first row of 8 by (+), 
and check the second row. Since the second row dominates the unlabeled 
third row, which does not dominate any other row, we set a = 3, and define 
I =  {3), J =  (5). This gives 
1 0 0 0 1 O O O 1 O 1 O T  
0
1
1
1
0
1
1
1
0
1
0
1
~
 
s= [ 
] 
(6.65) 
indicating that t,he partitions 
y1 = {Y317 
YZ = {Yl, Y2, Y4, Y5) 

342 
6. Hierarchical LBT Decompositions 
provide another acyclic decomposition of D into D: and DZ, where DT is 
irreducible. We label the third row (+). 
Now, we go back to the second row of 8. Since it dominates the (+) 
labeled third row, we label it (+) also. The fourth and fifth rows of 8 are also 
labeled (+), since they both dominate the third row, and Algorithm 6.13 
stops. This first round of the algorithm produces two distinct acyclic I0 
reachable decompositions, D = Di U Di and D = D: U Dg, where Di 
and DT are irreducible. In the second round, we apply the algorithm to Di 
and Dg, separately, to decompose them further into acyclic I 0  reachable 
components. The process is continued until all components are irreducible. 
Table 6.1 summarizes all possible PIO partitions for the system S of (6.61). 
In Table 6.1, we observe that only the partition Pio has no dilation in 
any of its components, and they are all structurally controllable (SC) and 
observable (SO), which is indicated by the symbol J, while the symbol 
X indicates the lack of these properties. The partition P;o is shown in 
Figure 6.7. Although structural controllability and observability can be 
established by merging components in the other partitions (e.g., by merging 
DX, D:, and Di in Pio), this produces coarser decompositions, resulting in 
a reduction of computational simplification offered by acyclic I 0  partitions. 
Let us show how we can use the acyclic decompositions for a sequential 
design of an observer for the system S of (6.61). Choosing some arbitrary 
numbers for the nonzero elements of the system matrices in (6.61), the 
partition P& of Table 6.1 after permutation yields the system S as 
s: k(t) = 
0 - 1 0 0  
1
0
0
0
 
3 
0
0
0
 
0 
0
1
0
 
0 
0
0
0
 
0 
4
0
0
 
0 
0 
0
0
0
 
0 
3
0
0
 
0 
0
0
0
 
0 
0
0
0
 
0 
0
0
0
 
0 

6.3. Input-Output Decompositions 
343 
+ 
0 
where 
T 
2 = ( 2 5 ,  2 9 ,  21, 211; 2 8 1  24; 212; 2 2 ,  26, 2 7 1  23, 210) I 
'11 = ('115; '113; '111; '1147 '112)TI 
(6.68) 
Y = (y3; Y2; Y1; Y5r Y4)T. 
To explain how the Luenberger observer can be built sequentially for 
the system S of (6.67), let us consider a system 
i-1 
i 
i-1 
(6.69) 
j=l 

344 
6. Hierarchical LBT Decompositions 
Table 6.1. Distinct partitions. 
Ui 
sc 
J 
J 
X 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
- 
X - 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
J 
- 
- 
X 
- 
X 
- 
X 
- 
which has LBT form, and assume that the pairs (Aii, Cii) are observable. 
Treating all the summation terms in (6.69) as inputs, a reduced order 
observer can be designed sequentially as 
(6.70) 

6.3. Input-Output Decompositions 
345 
t 
L- 
1 
I 
I 
xz 
Fig. 6.7. Irreducible partition Pio. 
where i&(t) E RnzPez is the state of the ith component of the observer, 
and &(t) is used to estimate q ( t ) .  The matrices appearing in (6.70) are 
computed in a standard way (e.g., O’Reilly, 1983). The matrices zi and 
Lii are chosen such that [r: CT] is nonsingular, and the equation 
- -  - 
- 
A..T.. 
zz 
aa - T..A.. 
zz 
zz + L..C.. 
zz 
aa - 
- 0 3 
i E N, 
(6.71) 

346 
6. Hierarchical LBT Decompositions 
is satisfied for some matrix Aii with specified eigenvalues. Other matrices 
in (6.71) are then computed as 
With this choice of the matrices and defining ei(t) = 2i - t i x i ,  it takes a 
little matrix algebra to show that 
i-1 
(6.73) 
where the matrices A i j  are defined in terms of i i i ,  M j j ,  C,, j < p 5 
i, j 5 q < i, and &.,, j < r < i. From (6.73) and (6.74) it is clear that 
&(t) + xi(t) as t + +oo. In this way, an observer design is achieved by 
designing small individual observers for the acyclic components of the sys- 
tem. Equation (6.70) indicates that the observer has the same hierarchical 
(LBT) structure as the system itself. 
Now, we go back to our specific system S of (6.67), and assume that it is 
required that the overall observer have all its eigenvalues at -1. Applying 
the above procedure, we obtain the following subsystem observers: 
1 
2 
02: 22 = - 22 + 2x9 - u3 + -y2, 
[ ?] = [ ;] 
$2 + [-;I 
y2; 

6.3. Input-Output Decompositions 
347 
- 1 0 0 1  
- 2 2  - 
0
1
0
 
2 7  
= 
-2 
0 0 
2 4 +  
23 
0
0
1
 
26 
- 0 0 0 -  
- 210 - 
04: Z4 = 
--1/4 
0' 
0
1
 
1/2 
1 
-1/2 
0 
- 1 
0- 
(6.75) 
-3/2 
0 -1/4 
-1 
-1 
0 ] 5 4 +  [ !] 
x 9 +  [ ;] 
u5+ [ ;2] 
'111 
1 
0 -l/2 
1/2 
314 
+ [ -: -;] 
[;;I 
+ [ 1/4 
2 
3/2 
-11 [;] 
1 
With a little manipulation, an overall representation of the dynamic part 
of the observer can be obtained as 

348 
6. Hierarchical LBT Decompositions 
-813 [ 
I .  
-413 i 
0 
(6.76) 
which has the same hierarchical (LBT) structure as S itself, save that the 
expression for $3 is omitted as it is not necessary for the implementation 
of the observer 0. 
6.4. Sequential Optimization 
Optimization of hierarchically structured control systems may proceed 
in several different ways, depending on the choice of information distribu- 
tion among the subsystems. We shall consider the three basic information 
structure constraints: global, local, and sequential. Special attention will be 
given to the sequential information structure where fast topdown commu- 
nication is available for fast data transmission from the upper to the lower 
levels of the hierarchy. The sequential processing and control design will be 
contrasted to the standard global and totally decentralized local structures 
in the context of system performance. 
We shall consider a hierarchically structured plant represented by a 
discrete-time linear stochastic system. With each subsystem, we associate 
a quadratic cost, which we minimize sequentially one at a time assuming 
that feedback control loops are closed at higher levels of the hierarchy. 
Optimal control algorithms are formulated as a scheme (StankoviC and 
Siljak, 1990), which builds state models for each optimization stage allow- 
ing for the standard LQG method to be used sequentially. The scheme 
was introduced by Ozgiiner and Perkins (1978) for control design of LBT 
deterministic continuous-time systems with complete state information. 
A discrete-time system S is hierarchically structured as 
i-1 
i-1 
zi(t + 1) = Aiizi(t) + Bii~i(t) + C A i j z j ( t )  + C Bijuj(t) + wi(t), 
j=1 
j=1 
i-1 
yi(t) = Ciizi(t) + C Cijzj(t) + ~ i ( t ) ,  
j=1 
i = 2, 3, . . . , N ,  (6.78) 

6.4. Sequential Optimization 
349 
where zi(t) E R"C, ui(t) E Rmi, and yi(t) E Rei are the state, input, and 
output of the subsystem Si at time t = 0, 1, 2, .... which is described as 
Si: zi(t + 1) = Aiizi(t) + B i i U i ( t )  + wi(t), 
(6.79) 
p i ( t )  = Ciizi(t) + vi(t), 
i E N. 
The input noise wi (t) E R"a and measurement noise wi (t) E Re' are inde- 
pendent white Gaussian processes with zero mean and covariances RE and 
c, 
respectively. Matrices Aij, Bij, and Cij are constant and of appropriate 
dimensions. 
The system S can be written in a compact form: 
S E ( t  + 1) = Az(t) + Bu(t) + w(t), 
(6.80) 
y ( t )  = W t )  + 44, 
where z(t) E R", u(t) E R", and y ( t )  E Re are the state, input, and 
output of S, w(t) E R" and w ( t )  E Re are the state and measurement 
noise, and the system matrices are 
r All 
0 
...................... 
ANI  AN^ ... ANN 
0 
...................... 
LBN~ B N ~  ... BNN 
..................... 
C N l  
c N 2  ... C N N  
(6.81) 
With each subsystem Si, we associate the performance criterion 
where the constant matrix @: 
is nonnegative definite, and the constant ma- 
trix @: 
is positive definite. Moreover, we assume that each pair [Aii, (Q:)'/2] 
is detectable. 

350 
6. Hierarchical LBT Decompositions 
Optimization of the system S is performed sequentially, going from the 
top to the bottom of the hierarchy. Once the optimal control law for S1 
is determined and implemented, the optimization of S2 is carried out. The 
optimization of S3 is performed after the optimal control law for S2 is 
implemented, and so on until the bottom of the hierarchy is reached. In 
this way, the optimization process takes the advantage of the lower block 
triangular structure of the system. 
The optimal control law for subsystem Si depends crucially upon the 
information structure constraints of the overall system. Let Y,"-' = {yi(O), 
yi(l), . . . , yi(t - 1)) denote the output information of Si at time t. Three 
basic structures are of interest: sequential, local, and global. 
6.20. SEQUENTIAL STRUCTURE. Only the outputs Yj-' from the 
same and higher hierarchical levels ( j  5 i) are available at Si. 
The first step in the sequential algorithm is to find the optimal control 
law u;(t) for S1 that minimizes EJ1 under the assumption that we have 
Yf-', that is, ul(t) is measurable with respect to the a-algebra generated 
by Yip'. Since S1 is decoupled from the rest of the system, we use the 
standard LQG solution 
u;(t) = -K121(tIl), 
(6.83) 
where Pl(tll) = E{q(t)lYf-'}, and K1 = MG'BEP'A11. P' is the solution 
of the Riccati equation 
P' = ATIP'Aii + Qi' 
- AT1P1B11M;,'BT,P1Al1, 
(6.84) 
and M11 = BEP'B11 + Qi'. 
For control law u;(t), Pl(tl1) is generated by 
the Kalman filter 
where L1 is the steady-state optimal gain. Under the standard stabiliz- 
ability and detectability assumption, the closed-loop system driven by the 
optimal control law (6.83) is asymptotically stable (Astrom, 1970; Goodwin 
and Sin, 1984). 
As we announced above, we implement u; (t) and optimize Sz assuming 
the measurements {Yf-', X-'} are at our disposal, that is, the admissible 
controls u2(t) are measurable with respect to the a-algebra generated by 

6.4. Sequential Optimization 
351 
{Y,"-', Yi-'}. At this second stage, we need a model M2 of S2 reflecting 
these assumptions. It is important to note that, after the implementation 
of $(t) in S1, we have to consider the augmented state X2(t) = [iT(tll), 
zT(t), z;(t)lT, and obtain 
+ 
(6.86) 
In a compact form, M:! is 
M2: X2(t + 1) = A2X2(t) + B2u2(t) + N2(t), 
(6.87) 
where the matrices 
(6.88) 
and N2(t) are obvious from (6.87), with A?j2 = A22. We also note that N2(t) 
is a white zero-mean noise independent of X, (t) . 
The output equation, which is compatible with the assumed information 
structure constraints, is 
Y2(t) = C2X2(t) + V2(t), 
where &(t) = [yrft), y?(tflT, 
C2=[p, ;; 
12], 
and h(t) 
= [wT(t), $ @ ) I T .  
The criterion EJ2 is expressed as 
(6.89) 
(6.90) 
T-1 
t=O 

352 
6. Hierarchical LBT Decompositions 
where 
Ql 
= [ O  O 
Qf 
0 1 .  
(6.92) 
The problem of finding the optimal control law u;(t), as formulated 
above, is reduced to the standard LQG problem. The solution is 
u;(t) = -KzX~,(tl2), 
(6.93) 
where X2(t(2) = E{Xz(t)(y:-', J$-'}, and Kz = Mg1(B2)TP2A2. 
The 
matrix P2 is the solution of the Riccati equation 
p2 = (p)Tp2A2 + 
- (A2)Tp2B2M22'(B2)Tp2]i2, 
(6.94) 
where M22 = (B2)*P2B2 + Qt2. 
For this purpose, we decompose P2 as 
Let us analyze the structure of the obtained optimal control law u;(t). 
(6.95) 
where the blocks are compatible with the blocks of A2 delineated in (6.86). 
Then, 
(6.96) 
ul(t) = -M&'B& [s 
PljA;l, %A22 
Xz(tI2). 
Obviously, calculation of uz(t) requires the last row of P2 in (6.95), which 
is obtained by computing 
1 
2 
Pz", = A&P&A22 + Q:2 - A~2P,2,B2zMg1B,T,P22A22, (6.97) 
and 
Pil = AT2 Pz"lA?, + AT2P,2,A;,, 
(6.98) 
where A 2 2  = A22 - B22Mg1B&P12Ar2. 
The Riccati Equation (6.97) corresponds to the local optimization prob- 
lem of S2 when the interconnections are ignored. The solution P,"z exists un- 
der the local stabilizability assumption concerning S2. The Equation (6.98) 
has the unique solution in the case when 
1 - x,(A22)x,(A~l) # 0, 
p = 1, 2, . . . , 2n1; 
q = 1, 2, . . . , 712, 
(6.99) 

6.4. Sequential Optimization 
353 
where Xp(A22) and &(AT1) are the eigenvalues of the indicated matrices 
(Gantmacher, 1959). The matrix Afl is the closed-loop state transition 
matrix of S1 after implementation of u;(t) and is, therefore, a stable matrix 
(that is, all its eigenvalues are inside the unit circle). On the other hand, 
is the state transition matrix of S2 under the same control law ui(t) 
obtained as if the whole state zl(t) of S1 is known, and it is also stable. 
Stability of AT, and A 2 2  implies condition (6.99) which, in turn, implies the 
existence and uniqueness of the solution Pil to (6.98). These facts regarding 
the algebraic Equations (6.97) and (6.98) follow closely those of Ozguner 
and Perkins (1978). 
The estimate Xz(t12) appearing in the control law uf(t) 
can be expressed 
y"z!'}lT. Having in mind that the 0-algebra generated by YE-' is a subset of 
the a-algebra generated by {Yip', Yi-'}, one concludes that €{&(tll)lY;-l, 
Yi-'} = ?1(tll). Computation of the remaining terms of X,(tl2) can pro- 
ceed by using the Kalman filter for .5(t) = [zT(t), z;(t)lT given (Y,"-', 
X-'}, 
to get 
as Ji2(t12) = [E(q(tI1)IY,t-', Yi-'}, E(zT(t)lY;-', Y y } ,  E(z;(t)lY;-l, 
32: &(t + 112) = A2&(t12) + B2U,*(t) + L2[Y2(t) - C2((t12)], 
(6.100) 
where U;(t) = [uTT(t), 
@'(t)lT, 
(6.101) 
and L2 is the optimal steady-state Kalman gain, which produces a stable 
S 2  under the local stabilizability and detectability assumptions, due to the 
lower block triangular structure of the matrices (6.101). 
From the above analysis of the structure of the optimal control law u;(t), 
it follows that it can be broken into two components. The first component 
is the locally optimal control law for S2 with respect to EJ2 when the in- 
terconnection with S1 is ignored. The second component is the feedforward 
control from S1 to S2, which takes into account the interconnection. It is 
crucial to observe that the sequentially optimal control laws stabilize the 
interconnected pair (S1, 
S2) because the pair has a hierarchical structure, 
each closed-loop subsystem is stable, and the feedforward gain is bounded. 
The optimization of the rest of the subsystems S3, Sq, . . . , Si, . . . , SN 
can be performed in an analogous way. The state vector, which is relevant 

354 
0. Hierarchical LBT Decompositions 
for the optimization of Si when the optimal control for S1, SZ, . . . , Si-1 
is implemented, is Xift) 
= [5$(tll), iT(tl2), 5$(tl2), .. ., i?T(tli - 11, ..., 
iT-l(tli-l), zT(t), . . . , zLl(t), zT(t)lT, where 5$(tlq) = &{zp(t)lYi-', Yi-', 
. . ., Yi-'}. Proceeding in the same manner as in the case of the subsystem 
SZ, 
it is possible to construct a state model for Xi(t) 
after putting together 
the models for &(t) and the corresponding Kalman filters generating the 
optimal estimates in Xi(t). The resulting equation has the following form: 
where the matrices 4, and 2i1 have the dimensions [inl + (i - l)nz + . . + 
2ni-11 x [in1 + (i - l)nz + . + 2ni-11 and ni x [inl + (i - 1)nz + . . . +2ni-l], 
respectively, while Biz = Aii, and Ni(t) represents a white noise sequence. 
The corresponding observation equation is 
K ( t )  = d & ( t )  + K(t), 
(6.103) 
which has the same form as (6.89). 
After expressing &Ji in terms of Xi(t) in the same way as &Jz has been 
expressed in terms of Xz(t), it can be shown that the optimal control law 
on the ith level is given as 
zlf(t) = -&X&Ii): 
where 
(6.104) 
Ki = M;'B$ 
P&Ail, P&Aii] , 
(6.105) 
and Xi(t1i) = €{Xi(t)lYi-', 
Yi-', . . . , Y,"-'}. The matrices Pil and Pj2 
are obtained from (6.97) and (6.98) after replacing A22 by Aii and 
by 
&. Obviously, the control law has always the same structure: the local 
feedback and the feedforward part. The estimates hi(tll), . . . , il(tli - l), 
. . . , &-1(tIZ - l), fl(tli), . . . , Pi(tli), which are needed for the control law, 
are generated by a bank of Kalman filters. 
The above optimization procedure can be concisely formulated as fol- 
lows (Stankovid and Siljak, 1989): 
"' 
j=l 
6.21. PROPOSITION. 
A solution to the sequential optimization prob 
lem for the system S, which is composed of hierarchically ordered sub 
systems Si, with performance criteria EJi and the sequential information 

6.4. Sequential Optimization 
355 
structure, exists, is unique, and the entire closed-loop system is asymptot- 
ically stable provided all pairs (Aii, &), [Aii, (Rf)l/z] are stabilizable and 
all pairs (Aii, Cii), [Aii, (&2)'/2] are detectable. 
Let us consider the alternative information structure, which is very 
much in tune with our general approach to decentralized control of complex 
systems: the local information structure constraint. To our disappointment, 
this constraint is not providing us with the usual simplification that was 
suggested by HodiiC and Siljak (1985). 
6.22. LOCAL STRUCTURE. 
Si . 
Only the local output Y,"-' is available at 
If only local output can be used, then we have to modify the sequen- 
tial design. After the first step, is completed, which remains obviously 
unchanged, we consider again the state model M2, but the observation 
equation becomes 
Y 2 ( 9  = [ O  CZl 
CZZ] Xz(t) + wz(t). 
(6.106) 
The solution to the corresponding LQG problem is now given by 
u;(t) = -K2€{X2(t)(Y;-'}, 
(6.107) 
where the matrix Kz is defined as in (6.93). The optimal state estimate, 
which is conditioned by the available measurements, is composed of 
&{ 21 (t 11) IY;-'} , €{ 21 (t ) IYi-'} , and €{ 22 (t) I@-'}. 
In general, the o-algebra 
generated by Y;-' is not contained in the u-algebra generated by x-'. 
Therefore, the estimation algorithm cannot be decomposed in this case into 
two independent Kalman filters 81 and SZ producing &(tll) and &(t12), 
respectively [see (6.85) and (6.lOO)l. Rather, the estimates Xi(tl2) = 
&{Xz(t)lY;-'} have to be obtained directly on the basis of Mz, that is, 
X;(t + 112) = A2X-,.(tl2) + BZu;(t) + L;:{y:!(t) - [ 0 
CZl 
c 2 2 1  X;(tp)}, 
(6.108) 
where L; represents the corresponding steady-state Kalman gain. This gain 
exists and the estimator is stable under appropriate stabilizability and de- 
tectability conditions for the model (6.86) with (6.106) (Goodwin and Sin, 
1984). 

356 
6. Hierarchical LBT Decompositions 
The third and subsequent optimization steps are different from those of 
the sequential algorithm. The state model, which is relevant for the third 
step, defines the state evolution of the first three subsystems in which the 
optimal controls u;(t) and u;(t) are already implemented as (6.83) and 
(6.107). The augmented state is defined as Xi(t) = [?Y(tll), XlT(t12), 
zT(t), zr(t), z:(t)lT, and the corresponding model Mi is obtained by join- 
ing (6.77) with both (6.85) and (6.108). The optimal control for S3 is now 
ug(t) = -K3Xi((t13), 
(6.109) 
where Xi(t13) = €{X;(t)lJ'-'}. 
Owing to the fortunate fact that the state 
model Mi preserves its lower block triangular structure, the matrix Ll 
can still be decomposed into two distinct blocks. The first block defines 
the local feedback when the interconnections are ignored, while the second 
block specifies the feedforward path from the estimate of [liT(tll), XlT(tl2), 
zY(t), z;(t)lT, which is available on the basis of the local measurements. 
Although the gain matrix calculations are similar for all stages, the com- 
plexity of the estimation algorithm becomes prohibitive as the number of 
systems increases. For example, in Mj, dim{Xi(t)} = 3nl + 2n2 + 723 and, 
in general, dim{X;(t)} = in1 + (i - 1)np + . . . + ni. The cause for this 
dimensionality explosion is the lack of information about the outputs at 
higher hierarchical levels. In practice, it might be worthwhile to examine 
the relative importance of the information contained in the outputs at var- 
ious levels, especially when interconnections are relatively weak among the 
individual levels of the hierarchy. 
6.23. 
at each subsystem Si, i E N. 
GLOBAL STRUCTURE. All outputs Yj-', j E N, are available 
We now consider the case when the whole vector yt-l = {Y,"-', Y;-', . . ., 
Y;'} is available at each subsystem Si, 
i E N. Both control and estimation 
algorithms of the sequential optimization have to be altered. At the first 
optimization stage, the optimal control is given as 
u;(t) = -K1&(tlY), 
(6.110) 
where K1 is defined as in (6.83), but &(tly) represents the optimal estimate 
of q ( t )  given all the measurements, that is, 91(t, Y )  = €{zl(t)lYi-l, 
Yip', 
. . . , Y;'}. Owing to the lower block triangular structure of the system, 
one can formulate the following expression representing one part of the 
recursion for the optimal estimate of the whole vector z(t), given yt-l: 
&(t + 1lYt-') = (Ail - Bii~5) 
&(tlY + Qv(tlY), 
(6.11 1) 

6.4. Sequential Optimization 
357 
where v(tly) = y(t) - C?(tly) is the innovation vector for the global 
Kalman filter, while Lr represents the corresponding block of the steady- 
state gain Ly = PyCT(CP~CT 
+ &)-', in which Py is the steady-state 
prediction error covariance matrix. 
The second optimization stage is based on the construction of a state 
model for S1 and S2 when the control (6.110) is implemented. Combining 
(6.111) with the corresponding part of S in (6.80), one obtains 
In (6.112), the sequence {v(t)ly} 
is zeremean and uncorrelated and, 
moreover, satisfies the condition €{v(tly)lY;-', y;-', . . . , Yg'} = 0. These 
are the essential prerequisites for the application of LQG methodology, 
since they allow the construction of the mean-square optimal predictor 
of X$(t) = [?T(tlY), zT(t), z;(t)lT on the basis of the system matrices 
appearing in (6.112) together with the a priori noise statistics (e.g., distrom, 
1970). The resulting optimal control is given by 
u;(t) = -@X$(tly), 
(6.1 13) 
where K$ is the gain matrix obtained by solving the Riccati equation cor- 
responding to (6.112). The structure of the model allows again the decom- 
position of the optimal control law into two parts, the first of which repre- 
sents the stable local feedback, and the second defines the feedforward path 
from the estimates of the states of the subsystems at higher hierarchical 
levels. Consequently, the local feedback results from the Riccati Equation 
(6.97), while the feedforward block is the solution to the Liapunov equation 
analogous to (6.98). The estimate XT(tlY) contains now €(&(t[y)Jy;-', 
. . . , y:'} 
= ?l(tly) and, therefore, the whole vector can be constructed 
by picking up the corresponding components from the estimate generated 
by the global Kalman filter. 
In general, at the ith optimization stage, a model structurally similar 
to (6.112) can be constructed. The state vector is composed'of ?l(tly), 
. . . , ?i-l(t[y), 
zl(t), . . . , zi-l(t), and zi(t), while the corresponding gain 
in the equation analogous to (6.111) becomes LEl, consisting of the first 
i - 1 blocks of Ly related to the first i - 1 subsystems. The gain matrix K," 
is again decomposable; it can be found by solving the corresponding Riccati 

t- 
(0 
; 0
0
0
0
0
0
0
0
0
0
0
0
~
~
 
4 
,= 
0
0
0
0
0
0
0
0
0
0
-
z
o
o
 
9 
I 
t- 
H" 
0
0
0
0
0
0
0
0
9
~
0
0
0
0
 
1 2  
- 
o o 8 0 0 0 0 0 0 0  
H" 
0
0
0
0
 
I 
m 
8 
* 8 
H" 
o
o
o
o
o
o
o
o
o
~
o
o
o
 
8 
I 
H" 
0
0
0
0
0
0
0
0
0
0
0
0
0
0
 
: 
1 
I 
II 
358 

6.4. Sequential Optimization 
359 
- 1 0 0  0 
0
0
0
0
0
0
0
0
0
0
-
 
0
0
1
-
1
0
0
0
0
0
0
0
0
0
0
 
0
0
0
 0 
0
1
1
0
0
0
0
0
0
0
 
0
0
0
 0 
0
0
0
0
0
1
0
0
0
0
 
0
0
0
 0 
0
0
0
0
0
0
0
1
0
0
 
c, = 
- 0 0 0  0 
0
0
0
0
0
0
0
0
0
1
~
 
and Liapunov equations. All the required state estimates in all the stages of 
the optimization procedure can be obtained from the global Kalman filter. 
y1 
yz 
y3 
y4 
y5 
y6 
6.24. COMPLETE STATE INFORMATION. 
~ ( t )  
are known at each Si for every t = 0, 1, 2, . . . . 
All states q ( t ) ,  ~ ( t ) ,  
. . ., 
In this case, which was assumed by Ozgiiner and Perkins (1978), cal- 
culations of the optimal controls are greatly simplified. For details, see 
(StankoviC and Siljak, 1989), where computational aspects of all types of 
the sequential optimization were discussed. 
6.25. EXAMPLE. To illustrate the LBT/LQG sequential design, let us 
consider a 14th order continuous-time model of a ship boiler proposed by 
Chemouil and Wahdan (1980). The model has the form 
where the matrices A,, B,, C,, and r, are given by Equations (6.115)- 
(6.118) : 
0
0
0
0
0
0
0
0
1
0
0
0
0
0
 
111 
J 3 , T = 0 0 0 0 0 0 0 0 0 0 1 0 0 0  
u2 
(6.116) 
0
0
0
0
0
0
0
0
0
0
0
0
1
0
 
u3 
(6.117) 
[ 
1 
I'z = [-0.0044 
0 0 0.004474 
0.00708 0.000415 
0 0 0 0 0 0 0 01, 
(6.118) 


6.4. Sequential Optimization 
361 
To apply the proposed LQG methodology, we need to transform first the 
system S, into an input-output LBT form, if such a form exists. For this 
purpose, we apply Algorithm 6.13 and conclude that such an LBT does 
not exist in this case, but both input and output LBT forms are present, 
although with different numbers of subsystems and incompatible input and 
output structures. For this reason, we build the controllers and estimators 
separately at cost of an inferior performance of the overall system. 
For control design, the system S, is decomposed into three hierarchically 
ordered subsystems with independent inputs resulting in A, and B, given 
in (6.119) and 
All three subsystems and, thus, the overall system, are stabilizable. After 
discretization with sampling period T = 0.25 sec, the matrices A, and B, 
become 
and B d  of (6.121) and (6.122), retaining the LBT form: 

362 
6. Hierarchical LBT Decompositions 
0 
0 
0 
0 
t- 
sl: z 
2 
2 
I 
t- 
t- 
4 
I 
d 
t- 
t- 
I 
m 
9 
m 
m 
m 
4 
4 
o
o
t
-
 
2 
O
Z
%
 
m i ?  
N 
C 6 - i  
0 
0 
0 
0 
0 
d 
m 
Q, 2 
0 
0 
0 
0 
0 
d 
W * 
9 
m 
0 
0 
0 
0 
0 
N 
d 
W 
2 
W 
Q, 
m 
3 
-? 
2 
0 x 
x 
4 
N 
0 
I 
0 
0 
0 
0 s 
3 
W 
m 
(0 
LL? 
4 
e 
m 
? 
3 
N 
3 
3 z 
2 
3 
0 
3 
0 
m 
2 
0 
0 
0 
0 
0 
2 
0 
9 
-l 
m 2 
9 
I 
3 
0 
m 
t- 
N 
N I 
I 
x 
W 
4 
p: 
I 
m 
I 
m 
m 
2 
2 
3 
0 
0 
0 
4 
m 
0 z 
W 
t- 
W 
'9 
-l 
3 
2 
2 
-l 
2 
0 
0 
0 
m 
m 
d 2 
W 
(0 
m 
9 
m 
d 
0 
d 
2 
t- 
0 * 
0 
0 
0 
* 
N 
Q, : 
x 
2 
I 
m 
al 
m 
I 
W 
2 
I 
00 
cy 
W 
N 
'9 

6.4. Sequential Optimization 
363 
2.2120/ 
I 
1.3807 1 
! 
I 
9.08371 
1.0529 1-4.2752 
I 
1----------- 
_---------- 
I 
0 I 
I 
o
j
 0 
I 
I 
0 
2.3791 
a 
-5.18551 
1.9082 
I 
I 8 
2.49231 1.1055 
I I I 
o
!
 0 
I I I 
2.02091 -1.5013 
I 
0 
! 
0 i 
0 
i 2.3027 
-2.09731 I 
1.06161 1.1443 
-1.11601 2.02431 3.6671 
6.5995 1-1.19291-2.1647 
I I 
I 
, 
0 
I 
I 
I 
I 
I I 
I 
I 
I 
(6.122) 
The state noise covariance is l&, = 0.025. 
following matrices: 
The criteria for synthesizing the sequentially optimal control have the 
Q:' = diag(1, 10, loo}, 
Q:' = diag(100, 1, 100, 100, 100, 1, loo}, 
Q$3 = diag(1, 10, 100, loo}, 
(6.123) 
= 1, 
i = 1, 2, 3. 

364 
6. Hierarchical LBT Decompositions 
P 
Algorithm 
Global 
To control the system three control algorithms have been utilized: 
global, sequential, and decentralized. At first, it has been assumed that 
all states are available for control. The global algorithm is the standard 
LQG scheme applied to the pair ( A d ,  &), the sequential algorithm is de- 
scribed above, and the local optimization algorithm of Section 4.5 is the 
LQG scheme for the pair (AD, 8 ) ~ )  
that is obtained from (&, &) by 
neglecting the off-diagonal blocks. 
The figure of merit of the above algorithms is 
1 
10 
100 
7.511710-4 
6.292410-4 
6.331810-4 
J = tr (Qz + KTQuK)Pz, 
(6.124) 
where Q, = diag{Qk', Q:', Q:"), 
Qu = diag{Qt', Qf, Qp}, while P, is 
the steady-state value of €{z(t)zT(t)}. 
The results are presented in the first 
column of Table 6.2. We observe that there is negligible difference between 
the algorithms, which is the consequence of weak interconnections between 
the subsystems. 
Table 6.2. State feedback. 
I 
I 
1 
I 
I 
I 
Sequential 
I 
8.201410-4 
1 
8.220510-4 
I 
1.013310-3 
I 
I 
Decentralized 
I 
8.201910-4 
I 
8.266210W4 
I 
1.470510W3 
I 
In order to compare the algorithms, we introduce a parameter p which 
multiplies the off-diagonal blocks of A, and B d .  Two values of p are used and 
the results are shown in Table 6.2. Superiority of the sequential algorithm 
over the decentralized one increases with the increase of p, as expected. At 
the same time, the inferiority of sequential and decentralized schemes with 
respect to the globally optimal one increases with p. 
To design the output feedback, we use the output LBT form 
(6.125) 
where A d ,  C d ,  and r d  are given in (6.126)-(6.128): 

7.7880 
0 
j 
1.0370 8.82503 
I 
I I 
I 
I 
..................................................................... 
1.0570 
1.79493 3.9171 
0 
0 
0 
0 
I I I 
1.6530 4.1737: 4.5301 9.9955 -7.7774 -5.0177 -6.0547 
I I I 
0 
o
j
 0 
0 
9.9934 
0 
0 
I 
I 
0 
0
;
 0 
0 
0 
9.0484 
0 
I I I 
-1.0183 -3.3739 1-5.3682 -2.3021 
2.3019 
1.4596 8.4642 
2.8995 
4.9351 11-3.0861 -2.0113 
2.0112 
1.2976 1.5658 
I 
----__-----____---- 
,------------------------------------------------- 
I 
0 
o
j
 0 
0 
0 
0 
0 
I 
-4.1278 -1.3720 1-2.1945 -9.5141 
9.5131 
1.6676 3.0091 
..................................................................... 
I 
0 
0
3
 0 
0 
0 
0 
0 
I I 
-4.7878 
1.9764 1 4.1909 2.7319 -2.7317 -1.7624 -2.1275 
-1.2960 -2.1987 14.9410 -4.5407 
4.5404 
3.9968 9.6433 
7.6779 
1.3069 1 4.0970 
2.6848 -2.6146 -2.3589 -5.6924 
I I 
I I 
0 
(6.126) 
(6.127) % 
w 

366 
6. Hierarchical LBT Decompositions 
Estimation 
Control 
1 . (6.128) 
Optimal 
Decentralized 
The matrix B d  is obtained from B d  by permuting the corresponding rows 
and columns, while the output noise covariance is R, = diag{l,O.OO5,0.005, 
0.005, 7 x 
1). 
The performance index for the output control is 
Optimal 
Sequential 
J = t r  { [" 
0 ] .}, 
o 
K ~ Q , K  
6.7536 
6.7620 
6.9438 
6.9527 
(6.129) 
where P, is the steady-state value of E { X ( t ) X T ( t ) }  
where X = (xT, 2i.T)T. 
Table 6.3. Output feedback. 
I 
Decentralized 
I 
7.3535 
I 
7.3631 
I 
Again, the globally optimal LQG algorithm is taken as reference. The 
completely decentralized scheme consists of a decentralized estimator based 
on (6.125) and a decentralized controller derived using 
and B d .  The 
decentralized estimator is made up of five decoupled Kalman filters for the 
five subsystems in (6.125); it provides optimal estimates for the system S,J 
in which the off-diagonal blocks are removed. These estimates have to be 
permuted before they are used for control compatible with ( A d ,  &). 
The sequential LQG algorithm has been adjusted to the two-fold de- 
composition of the system. It consists of the sequential control algorithm in 
conjunction with the globally optimal Kalman filter or the above-described 

6.4. Sequential Optimization 
367 
decentralized estimator. The indices computed using (6.129) are given the 
Table 6.3. Due to weak interconnections and large estimation errors, the 
numbers in Table 6.3 do not show a significant distinction between the per- 
formance of the algorithms. 
The gain matrices for the global, sequential, 
and decentralized control are given in (6.130)-(6.132), and the estimator 
gains for the global and decentralized cases are specified in (6.133) and 
(6.134). This completes the LQG design. 
9.3443 
1.9237 
7.0316 
3.3481 
- 3.5635 
-8.2555 
-8.0873 
3.5604 
-6.9589 
2.4648 
-1.5263 
-6.4563 
-4.5291 
2.2917 
-2.1397 
-8.9103 
7.2500 
-5.1174 
6.3010 
3.4370 
1.3542 
-3.2474 
3.8840 
- 1.4616 
-3.2125 
-1.4102 
-2.8164 
4.8847 
-1.5269 
-6.1934 
3.3662 
4.0812 
1.2643 
-1.2219 
-1.1842 
5.8332 
- 1.1832 
4.1838 
8.9167 
1.4459 
1.9071 
-5.675C 
(6.130) 

368 
6. Hierarchical LBT Decompositions 
9.3250 
1.9156 
7.1933 
__________ 
-5.7876 
- 2.263 1 
6.8756 
- ______ 
-3.3880 
6.3080 
3.4370 
1.3550 
-3.5635 
3.9494 
-1.4876 
- ------ 
0 
-2.8182 
- 1.0995 
3.1401 
- 1.1991 
1.1895 
1.8572 
1.9850 
3.7850 
3.8666 
1.4695 
8.9180 
1.4466 
2.0133 
----------- 
-5.9116 
(6.131) 

6.4. Sequential Optimization 
369 
9.32501 , 
I 
1.91561 
0 
I 
I 
I 
1 6.308( 
I I I I 
1 3.437( 
, 
I I I 
1 1.355C 
I 
I 
, 
1 -3.563: 
! 
I I : 3.9494 
I 
0 I I 
j - 1.4846 
I 
0 
8.9180 
1.4466 
2.0133 
-5.9116- 
(6.132) 

370 
6. Hierarchical LBT Decompositions 
Lopt = 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
-1.0357 
8.7857 -1.3212 
1.2804 -6.3059 
1.5656 
-6.6091 -6.1553 
8.9004 -6.2581 
4.1425 -5.8609 
0 
0 
0 
0 
0 
0 
-8.2594 -9.0875 
1.3367 -9.3070 
6.2484 -9.1714 
-9.5655 
6.3882 -9.2558 
7.1696 -4.3135 
6.3089 
0 
0 
0 
0 
0 
0 
-4.1278 -5.9247 
8.7617 -6.0735 
4.1083 -6.1759 
7.8161 -5.9038 
8.3258 -5.8536 
3.8137 -2.6672 
4.3725 
1.2138 -1.8531 
1.2674 8.9070 3.8450 
6.4483 6.1644 -0.2863 
1.0552 -4.4498 
-7.9434 
5.0446 -7.5885 
5.9504 -3.6231 
.6542 
.0250 
(6.133) 

6.5. Notes and References 
371 
0 
0 
5.8266 -8.7638 
/-1.4511 
2.1467 
0 
0 
j-2.2399 
3.3385 
0 
0 
I 
j 3.8451 
I 
t 
1 7.9666 
, , 
I 
! 1.6725 
. 
(6.134) 
6.5. Notes and References 
Powerful sparsity-oriented methods have been developed over the years 
to solve large systems of linear algebraic equations with considerable re- 
duction of information storage and retrieval, as well as computational sim- 
plifications which decrease liability to errors in the end results. Numerous 
practical applications have been successfully solved in this context (Tewar- 
son, 1973; see the survey and the book by Duff, 1977, 1981). Motivated by 
this development, there has been a number of papers dealing with sparsity 
in dynamic systems. The initial results (Ozguner and Perkins, 1975; Callier 
et al. 1976) introduced decomposition schemes to obtain system models in 
LBT form so that stability and eigenvalues can be determined by consid- 

372 
6. Hierarchical LBT Decompositions 
ering only diagonal blocks. This approach has been extended to nonlinear 
systems as well (Michel et al. 1978; Vidyasagar, 1980; Michel and Miller, 
1983). 
The role of control in the context of LBT systems has been explored by 
several people (Kevorkian, 1975; Vidyasagar, 1980; Ozguner and Perkins, 
1978). An algorithm was proposed by Sezer and Siljak (1981: Section 6.1) 
that produces LBT systems with input reachable subsystems. Input reach- 
ability, being a minimal requirement for controllability, makes the LBT 
form conducive to stabilization by local decentralized control (Sezer and 
Siljak, 1981: Section 6.2; Khurana et al. 1986). 
If inputs and outputs are handled simultaneously during decomposi- 
tion, the resulting LBT system has subsystems with independent inputs 
and outputs (Pichai et al. 1983: Section 6.3). This allows for a bank of 
Kalman filters to be built to estimate the states of subsystems (HodiiC 
and Siljak, 1985), and solve a decentralized LQG problem for the overall 
system. In fact, the decentralized Kalman filtering scheme can be obtained 
by an iterative process that resembles those used to solve linear algebraic 
equations (e.g., Hageman and Young, 1981). Jacobi and Gauss-Seidel es- 
timators have been formulated in this context (HodiiC and Siljak, 1986b), 
which can be implemented by multiprocessor schemes for parallel multirate 
processing (HodiiC and Siljak, 1986a; Sezer and Siljak, 1989). 
The overall performance of the decentralized LQG scheme for LBT 
systems can be improved by a sequential design initiated by Ozgiiner and 
Perkins (1978) for deterministic systems. A stochastic version of the design 
was formulated by StankoviC and Siljak (1989), as described in Section 6.4, 
where the improvement was demonstrated by comparing performances of 
global, local, and sequential schemes 
Bibliography 
Astrom, K. J. (1970). Introduction to Stochastic Control. Academic Press, New York. 
Callier, F. M., W. S. Chan, and C. A. Desoer (1976). Inputboutput stability theory of 
interconnected systems using decomposition techniques. ZEEE Transactions, AC-23, 
Candy, J. C. (1986). 'Signal Processing: The Model-Based Approach. McGraw-Hill, New 
Chemouil, P., and A. M. Wahdan (1980). Output feedback control of systems with slow 
Duff, I. S. (1977). A survey of sparse matrix research. Proceedings of IEEE, 65, 500-535. 
Duff, I. S., Ed. (1981). Sparse Matrices and Their Uses. Academic Press, New York. 
Gantmacher, F. R. (1959). The Theory of Matrices. Chelsea, New York. 
Gardner, W. T., and C. T. Leondes (1990). Gain transfer: an algorithm for decentralized 
714-729. 
York. 
and fast modes. Large Scale Systems, 1, 257-264. 
hierarchical estimation. International Journal of Control, 52, 27S-292. 

Bibliography 
373 
Garey, M. R., and D. S. Johnson (1979). Computers and Intractability: A Guide to the 
Theory of NP-Completeness. Freeman, San Francisco, California. 
Goodwin, G. C., and K. S. Sin (1984). Adaptive Filtering, Prediction and Control. 
Prentice-Hall, Englewood Cliffs, New Jersey. 
Hageman, L. A., and D. M. Young (1981). Applied Iterative Methods. Academic Press, 
New York. 
HodiiC, M., and D. D. Siljak (1985). Estimation and control of large sparse systems. 
Automatica, 21, 277-292. 
HodiiC, M., and D. D. Siljak (1986a). A parallel estimation algorithm. Parallel Pro- 
cessing Techniques for Simulation, M. G. Singh, A. Y. Allidina, and B. K. Daniels 
(eds.), Plenum Press, New York, 113-121. 
Hodiif, M., and D. D. Siljak (1986b). Iterative methods for parallel-multirate estimation. 
Proceedings of the Fourth IFAC/IFOR Symposium on Large Scale Systems, Zurich, 
Switzerland, 169-175. 
Kevorkian, A. K. (1975). Structural aspects of large dynamic systems. Preprints of the 
Sixth IFAC World Congress, Paper No. 19-3, Boston, Massachusetts. 
Khurana, H., S. I. Ahson, and S. S. Lamba (1986). Variable structure control design for 
large-scale systems. IEEE Transactions, SMC-16, 573-576. 
Michel, A. N., and R. K. Miller (1983). On stability preserving mappings. IEEE Tmns- 
actions, CAS-30, 671479. 
Michel, A. N., R. K. Miller, and W. Tang (1978). Lyapunov stability of interconnected 
systems: Decomposition into strongly connected subsystems. IEEE Transactions, 
Nour-Eldin, H. A. (1987). Linear multivariable systems controllability and observability: 
Numerical aspects. Systems and Control Encyclopedia, M. G. Singh (ed.), Pergamon 
Press, Oxford, UK, 2816-2827. 
CAS-25, 79+809. 
O’Reilly, J. (1983). Observers for Linear Systems. Academic Press, New York. 
Ozguner, U., and W. R. Perkins (1975). Graph theory in the analysis of large scale 
composite systems. Proceedings of the International Symposium on Circuits and 
Systems, Boston, Massachusetts, 121-123. 
Ozguner, U., and W. R. Perkins (1978). Optimal control of multilevel large-scale systems. 
International Journal of Control, 28, 967-980. 
Pichai, V., M. E. Sezer, and D. D. Siljak (1983). A graph-theoretic algorithm for hi- 
erarchical decomposition of dynamic systems with applications to estimation and 
control. IEEE Transactions, SMC-13, 197-207. 
Pichai, V., M. E. Sezer, and D. D. Siljak (1984). Reply to “Input-utput 
decomposition 
of dynamic systems is NP-complete.” IEEE Transactions, AC-29, 864. 
Rosenbrock, H. H. (1970). State Space and Multivariable Theory, Nelson, London, UK. 
Sezer, M. E., and D. D. Siljak :1981). On structural decomposition and stabilization of 
Sezer, M. E. and D. D. Siljak (1990). Decentralized multirate control. IEEE Transac- 
Stankovif, S. S., and D. D. Siljak (1989). Sequential LQG optimization of hierarchically 
Tarjan, R. E. (1984). Input-output decomposition of dynamic systems is NP-complete. 
Tewarson, R. P. (1973). Sparse Matrices. Academic Press, New York. 
Vidyasagar, M. (1980). Decomposition techniques for large-scale systems with nonaddi- 
tive interactions: Stability and stabilizability. IEEE Transactions, AC-25, 773-779. 
largescale control systems. IEEE Transactions, AC-26, 43S444. 
tions, AC-34 (to appear). 
structured systems. Automatica, 25, 545-559. 
IEEE Transactions, AC-29, 863-864. 

In the modeling of complex systems with a large number of variables, it 
has long been recognized that most of the variables are weakly coupled, 
if coupled at all. This fact has been observed in fields as diverse as ece 
nomics and electric power systems, social sciences and computer systems, 
where it has been argued that most often the behavior of the overall sys- 
tem is dominated by strongly connected variables. A considerable concep- 
tual insight and numerical simplification can be gained by grouping these 
variables into subsystems, solving the subsystems independently, and re- 
solving subsequently the effects of interconnections to get the overall solu- 
tion. The ultimate success of this recipe depends crucially upon our ability 
to identify groups of strongly coupled variables, cluster the variables to 
form subsystems, and represent the overall system as a weak interconnec- 
tion of the resulting subsystems. It is absolutely essential that, during the 
decomposition-clustering process, there is a considerable freedom in choos- 
ing conveniently the strength of coupling among the subsystems, because it 
is this strength that controls the size and character of the subsystems and, 
ultimately, their dominance in the solution of the overall problem. 
The objective of this chapter is to present a graph-theoretic decomposi- 
tion of large systems into weakly coupled subsystems, which was proposed 
in the context of dynamic systems (Sezer and Siljak, 1986). A full range of 
nested decompositions can be generated by controlling the threshold of the 
interconnection strength among the subsystems. The underlying idea is to 
associate a graph with a given system, disconnect the edges correspond- 
ing to interconnections with strength smaller than a prescribed threshold 
c, and identify the disconnected subgraphs (components) of the resulting 
graph. The obtained components correspond to the subsystems with mu- 
tual coupling smaller than or equal to E .  Since components of a graph can 
be determined in linear time, the epsilon decomposition algorithm has an 
extraordinary simplicity requiring binary computations only. 
374 

7.1. Epsilon Decomposability 
375 
Let us emphasize that the epsilon decomposition is developed for sys- 
tems with inputs and outputs. We are interested in producing weakly 
coupled subsystems, which can be locally stabilized by state or output 
feedback. Weak coupling should ensure that stability of subsystems im- 
plies stability of the overall system. If this is not certain, we should apply 
the method of vector Liapunov functions to establish the implication. In 
other words, epsilon decompositions produce nested hierarchies which, un- 
like “vertical” LBT hierarchies of the preceding chapter, require testing for 
stability. For this purpose, we present a construction of hierarchical Lia- 
punov functions (Ikeda and Siljak, 1985), which is ideally suited for nested 
structures, and can be used to establish nested connective stability. It is 
interesting to note that this kind of “stratified” stability is promoted by 
Simon (1962) and Bronowski (1970) as an essential ingredient in the evolu- 
tion of both the natural and man-made complex systems. Later, in Notes 
and References, we shall say more about epsilon decompositions and nested 
stability, emphasizing a variety of extensions and applications of the idea 
of weak coupling and nested connective stability of dynamic systems. 
7.1. Epsilon Decomposability 
There are three important aspects of epsilon decompositions. First, we 
can prescribe a coupling strength among the subsystems. Second, for dif- 
ferent levels of coupling, decompositions are nested. Third, decompositions 
are identified by graphs. To make these aspects transparent and, at the 
same time, show the extraordinary simplicity of epsilon decomposition for 
partitioning of complex systems, we use the following: 
7.1. EXAMPLE. Let us assume that we are given a matrix 
A =  
1 
2 
0
0
 
0.07 
1.10 
0
0
 
0.02 
-0.01 
1.75 
0.01 
0 
0.03 
0
0
 
0.02 
-0.03 
3 
.0.01 
0.03 
1.70 
0 
0
-
 
-0.02 
0.35 
0 
4 
0 
0 
0.40 
3.00 
-0.01 
0.45 
0.08 
0 
5 
2.15 
-0.06 
0.01 
0 
0.45 
0 
-0.01 
0 
6 
0 
-0.02 
0 
0.07 
0 
0.95 
0.02 - 
0.01 
7
8
 
0.04 
0 
0 
0.25 
0 
0.01 
1.95 
0 
0.01 0.06 
0
0
 
-0.85 
0 
0 
1.35 
1 
2 
3 
4 , 
(7.1) 
5 
6 
7 
8 

376 
7. Nested Epsilon Decompositions 
- 
0.01 
0 
0.04 
0 
0 
-0.01 
0.01 
0 
0.03 
0 
0 
-0.02 
0 
0 
0 
0.01 
1.70 
0.40 
0 
0 
0 
3.00 
1.95 
0.07 
0.35 
0.08 
-0.85 
0.02 
-0.02 
0.45 
0 
0.95 - 
and we are asked to rearrange the rows and columns of A until we identify 
diagonal blocks with couplings no larger than a given threshold. Let us say, 
we choose a threshold €1 = 0.05. Then, all we have to do is associate a 
digraph D with A and disconnect the edges of D with weights less than 
0.05. With this action we obtain from D a digraph 
in Figure 7.la, 
where we identify two disconnected components. Permuting the rows and 
columns of A according to the two components, we get the matrix 
1 
2 
5
8
3
 4 
6 
7  
0.02 
0 
1.10 
0.01 
-0.03 
0 
-0.01 
0.03 
0 
2.15 
-0.06 
0.45 
0 
0.01 
0 
0 
-0.01 
0 
0.25 
0.06 
1.35 
0.01 
0 
0 
0 
- 
0.01 
0 
0.03 
0 
0 
-0.01 
0 
0 
~~~ 
1.70 
0.40 
0 
3.00 
-0.02 
0.45 
0.35 
0.08 
0.07 
1.95 
0.95 
0 
0.02 
-0.85 
1 
2 
5 
8 , (7.2) 
3 
4 
6 
7 
with two diagonal blocks and off-diagonal blocks having no elements larger 
than 0.05 in absolute value. 
Let us now increase the threshold to €2 = 0.1. A pleasing fact is that 
now we need only consider the individual diagonal blocks and not the whole 
matrix A. We see that the first component of 
breaks down further 
into two components of Do.' shown in Figure 7.lb, while the second com- 
ponent of 
of 
Figure 7.lc and conclude that this decomposition stage effects the second 
and third component of Do.'. The final result is the matrix 
remains unchanged. When we select €3 = 0.5, we get 
1
5
 2
8
 
0 
0.01 
0 
0.01 
0.02 
0 
-0.01 
0 
0 
-0.01 
0 
0 
I 
0
0
 0.03 
0 
1 
5 
2 
8 
(7.3) 
l
3
 
I
4
 
I
7
 
6 

7.1. Epsilon Decomposability 
377 
1 
D0.1. 
1 i 
E 
Q Q 
(C) 
Fig. 7.1. Digraphs for Example 7.1. 
It is important to note that at each stage of epsilon decomposition we 
need only to determine components of a digraph, which can be done in poly- 
nomial time (e.g., Mehlhorn, 1984). Due to nestedness of decompositions, 
this process requires less computation at each stage. 

378 
7. Nested Epsilon Decompositions 
- 
- 
A convenient representation of the matrix A is 
where the matrices &, A 1 ,  A 2 ,  and A 3  are obvious from (7.3). 
7.2. 
A matrix A has a K-fold epsilon decomposition if 
there are K > 0 positive numbers €1 > €2 > ... > E K  such that, by 
permutations of rows and columns, the matrix A can be represented as 
DEFINITION. 
where A o  is a block diagonal matrix and A 1 ,  &, . . . , AK are all partitioned 
matrices with compatible blocks, such that each nonzero block appears in 
one and only one matrix A k ,  k = 1, 2, . . . , K, and none of the elements of 
any A k  is larger than one in absolute value. 
Our immediate interest is in epsilon decompositions of systems with 
inputs and outputs, which are conducive to the use of feedback control. 
We will return to decompositions of type (7.5) in Section 7.4, where we 
show stability of a dynamic system on each level of the threshold Ek, that 
is, nested connective stability. 
7.2. Decomposition Algorithm 
Consider now a linear system 
S: l i : = A z + B ~ ,  
y = cx, 
where z(t) E R", u(t) E R", and y(t) E Re are the state, input, and output 
of S at time t E R, and A = (aij), B = (bij), and C = ( q j )  are constant 
matrices of appropriate dimensions. Define a system matrix M = (mij) of 
S as the s x s matrix 
M =  
A
B
O
 
0
0
0
 
c o o  
(7.7) 

7.2. Decomposition Algorithm 
379 
where s = n + rn + t. The matrix M becomes the interconnection matrix 
E = (eij) of Definition 1.1 when nonzero elements of M are replaced by 
ones. 
We state the following: 
7.3. PROBLEM. 
that the matrix 
Given a system S. Find a permutation matrix P such 
= (aw) 
defined by 
A2 = PTMP 
(7.8) 
is epsilon decomposable as 
M = MIJ +€MI, 
(7.9) 
where E is a prescribed positive number. 
If we assume that the matrix &f is an N x N block matrix with Np x N, 
blocks A&, 
= (fir), 
then 
(7.10) 
.
,
 
i E Np, 
j E Np, 
where N =  (1, 2, ..., N } ,  Np = (1, 2, ..., Np}, N, = (1, 2, ..., N,}. In 
other words, Problem 7.3 means that we should identify diagonal square 
blocks M, of 
outside of which all elements are not larger in absolute 
value than a prescribed threshold E .  
To solve Problem 7.3 by a graph-theoretic algorithm, we associate with 
S a directed graph D = (V, E) in the usual way (Definition 1.2), and recall 
that a subgraph Di = (Vi, &) of D is a digraph such that Vi 
V and 
& 2 E. If & includes all the edges in E that connect the vertices in Vi, 
then we say that Di is formed by Vi. If Vi are the equivalent classes de- 
fined by connectedness then the Di formed by Vi are called the connected 
components of D. A partition P of V is a collection {Vl, V2, . . . , VN} of N 
disjoint subsets Vi such that uEl Vi = V. If Di is a subgraph formed by Vi, 
i E N, then the collection P = {Dl, D2, . . . , DN} is a partition of D. A 
condensation of D with respect to a partition P is a digraph D* = (V*, E*), 
where V* = {Y;, Y;, . . . , v&} is a set of super-nodes with v,' representing 
the subset Vi, and (Y;, us) E E* if and only if q # p and at least one vertex 
in the subset V, reaches a vertex in the subset V,. 
If P is a decomposition of an undirected (directed) graph D into its 
connected components (strong components), then a suitable reordering of 
the vertices of D brings its adjacency matrix E into a block diagonal (lower 

380 
7. Nested Epsilon Decompositions 
Fig. 7.2. Nestedness. 
block triangular) form. That is, there exists a permutation matrix P defined 
by P such that PTEP is block diagonal (lower block triangular). 
Now, going back to Problem 7.3, we see that finding a permutation ma- 
trix P for epsilon decomposition of M is equivalent to partitioning D into 
N subgraphs Di, i E N, such that the edges interconnecting the subgraphs 
correspond to the elements of M with magnitude no larger than E. Such a 
partition P' of D is called an epsilon partition of D. It is easy to see (Ex- 
ample 7.1) that if the subgraphs D' = (V, EL) of D are defined by deleting 
all edges corresponding to values weaker than E ,  then an epsilon partition 
is obtained simply by identifying the connected components of D', for it is 
the same partition of V that defines the connected components of D' and 
the €-coupled subgraph of D. 
Observe that since D has s vertices, then there can be at most s distinct 
edecompositions of D. Moreover, if two vertices vi and vj occur in the same 
connected component of D' for some 6 = f k ,  then they occur in the same 
connected component of all D' for E < Q. This implies that there exists a 
finite sequence maxi+j { lmij I} = €1 > €2 > . . . > C K  = 0, K 5 s, such that 
every 6 E [ e k ,  € & I ) ,  k E K = { 1, 2, . . . , K } ,  yields the same partitions Pi, 
k E K, and that these partitions are nested: P; c Pf2 c ... c P;(. The 
partition P; is the finest ( N  = s) and Pk is the coarsest. Nesting of epsilon 
decompositions of matrix M is illustrated in Figure 7.2 for two values of 
- E ,  
namely 6k and 6 k + l .  A numerical example is provided by the matrix A of 
We already noted that one of the most appealing numerical features of 
- 
(7.3). 

7.2. Decomposition Algorithm 
381 
epsilon decomposition is the fact that they are nested: P i f l  is obtained 
from the triple (D;, M i ,  Ek+l) instead of (D, M ,  E k + l ) ,  where D; is the 
condensation of D with respect to Pi, and Mk = (mh) is a condensation 
matrix of M = (mij) defined as 
(7.11) 
vj E v;, 
where Vk and Vt are the subsets of V in the partition Pi. In this way, instead 
of dealing with digraphs of s vertices at each step, digraphs of sizes s = N1, 
Nz, . . . , N K - ~  
are processed, where NK is the number of subgraphs of D 
in P i ,  and N K - ~  < NK-Z < ... < N1 = s, which results in an enormous 
computational saving when large systems are considered. 
On the basis of the above observations, an algorithm of Sezer and Siljak 
(1986) is now presented which can generate all possible epsilon decompe 
sitions of a digraph associated with a matrix M .  
7.4. ALGORITHM. 
(ii) 
Pi is defined as 
Pi: v =  u v;, 
P E Nk 
vp” = {Up: p E Nk}. 
(iii) Define Mk = (mk) as 
and compute 
Ek = max {mw}. 
k 
P 4  
2. 
(2) 
Let D; = (V;, E;) be the digraph associated with Mk, where 
v; = { V ; l ,  u;2, . . ., u;Nk 1. 
(Zi) 
Print k; Ek; Nk; V;, 
p E N. 

382 
7. Nested Epsilon Decompositions 
(iv) Let E = ~k - 6, where S > 0 is an arbitrarily small number and 
obtain an epsilon partition of D; (that is, identify connected 
components of Di): 
(v) 
Pi+l is defined as 
v =  u VF', where 
P E N k + l  
vk+I = {vi: vi E vj" for some vij E v;+~,~}. 
(vi) Compute Mk+l = (m:') 
as 
(vii) Set k = k + 1 and go to 2(ii). 
Note that in Algorithm 7.4, D; is the condensation of D with respect 
to Pi, which is the same as the condensation of DiP1 with respect to Pi. 
Note also that in a computer implementation of the algorithm, there is no 
need to construct DE; P;+l can be obtained from the matrix Mk directly 
(see Appendix). 
7.3. Control Applications 
We turn our attention to control design based on epsilon decomposi- 
tions. Only state feedback is considered, but estimators or dynamic output 
feedback can be designed in pretty much the same way. 

7.3. Control Applications 
383 
A linear system 
S: X=AX+BU, 
(7.12) 
is decomposed by Algorithm 7.4 as 
S': X, = Awxp + BwuP + E 
, 
p E N. (7.13) 
Control objectives may present some problems in using Sc. When the s u b  
graph D' of D = (V, E) is obtained, the partition 
P': v =  u v,, 
v, =x,uup, 
(7.14) 
may have some of the sets X, or Up empty. To consider this type of situation, 
let us define index sets N,, Nu, N,, c N as 
P E N  
N, = { p  E N: X, # 0}, 
Nu = { p  E N: Up # 0}, 
(7.15) 
N,, = N, n Nu. 
Since V, # 0, obviously, N, U N, = N. Five distinct cases may take place: 
7.5. 
In this case, Pc is the required partition, as each 
subgraph Di = (Up U X,, E,) has at least one state and one input vertex 
corresponding to a decoupled subsystem 
CASE N,, = N. 
Si: X, = APpxp + BpPup. 
(7.16) 
At this point, each decoupled subsystem may be checked for controllability. 
If a subsystem fails the test, it can be combined with another subsystem 
to form a single subsystem that has the desired characteristic. 
7.6. 
Now, Up = 0 for p E N - Nu; 
that is, the 
corresponding subgraphs D; contain no input vertices. The decomposition 
should be modified by combining each subgraph with one containing inputs. 
This yields a new partition 
CASE N,, = N, c N. 
Pi: v = u v;, 
v; = x; uu;, 
(7.17) 
P E l y ,  

384 
7. Nested Epsilon Decompositions 
where Ui = Up, and Xk is the union of X, with one or more X,, q E N -  Nu. 
Although the choice of Xp to be combined with an X, is arbitrary, it may be 
desirable to interconnect an X, with that X, with which X, interacts most 
strongly, or to satisfy other criteria (stabilizability, a balanced distribution 
of inputs among the subsystems, etc.). 
7.7. 
CASE N,, = N, c N 
treated similarly. 
This is a dual of Case 7.6, and can be 
7.8. 
In this case, each subgraph contains either only 
state vertices or only input vertices, indicating a poor choice of E .  A smaller 
E should be tried. 
CASE N,, = 0. 
7.9. 
Under this condition, each subgraph Di, 
p E N,,, contains both input and state vertices, and other subgraphs have 
the property N,, = 8 (Case 7.8). The partition is modified as 
CASE N,, # 8, N,, Nu. 
that is, we form a subsystem for each D;, p E N,,, and an additional one 
from the combination of the remaining ones. 
Observe that, in general, Cases 7.6-7.9 may result in rather large sub- 
systems even for relatively high values of 6. Unfortunately, they are more 
likely to occur than the Case 7.5, especially when the elements of the matri- 
ces A and B are of very different order. An improvement can be achieved by 
scaling the matrix B before the decomposition is attempted, which would 
not matter in a control design. This is equivalent to using two different 
values E A  and EB for A and B. To implement this modification, a subgraph 
DEACB = (V, ECA UECB) is obtained from D = (V, E) by removing all the 
edges corresponding to those elements of A and B with laijl I 
E A ,  a # j, 
and lbijl 5 E B .  By fixing E A ,  a state part of DCAEB 
is formed. Then, EB can 
be chosen to maximize the input-state set N,, defined in (7.15). Although 
a better way is to scale each column of B separately, it may be a difficult 
task due to a wide choice of possible combinations of scale factors. 
Once a system is in the form (7.13) with a relatively small value of E ,  
it is obvious that we can stabilize or optimize the system piece-by-piece 
using decentralized feedback. Methods presented in Chapters 2-5 are effi- 
cient when applied to weakly coupled systems. An illustration of the design 
process is given by the following: 

7.3. Control Applications 
385 
Fig. 7.3. System digraph. 
7.10. EXAMPLE. We again consider the model of Example 6.25 with 
matrices A and B given in (6.115) and (6.116). The system digraph D is 
shown in Figure 7.3. From D, it is obvious that the states 2 4  and 25 are 
not input reachable and can be ignored in further considerations. 
Since each input of the system S is associated with only one state vari- 
able, as seen from Figure 7.3, there is no need to consider the inputs in the 
decomposition procedure. Applying Algorithm 7.4 to the state-truncated 
digraph D, = (X, Ez), we get the nested epsilon decompositions listed in Ta- 
ble 7.1. In this table, only those subsets xi that contain more than one state 
vertex are shown. It can be observed that, at every step up to €6 = 0.04, 
either a new subset Xi with at least two vertices is formed, or a new vertex 
is added to one of such existing subsets. However, as c gets smaller, par- 
titioning of X becomes unbalanced in terms of the size of the subsets Xi. 
Therefore, E = 0.04 is the best compromise between the number and size 
of the subsystems; this kind of compromise being a common issue in any 
decomposition met hod. 
With E chosen as €6 = 0.04 the states 21, 2 6 ,  27, and 28 are decoupled 

386 
7. Nested Epsilon Decompositions 
Table 7.1. Nested edecomDositions. 
k 
ck 
X: (Partial listing) 
1 
0.667 
2 
0.5 
3 
0.4 
4 
0.1 
5 
0.767 
6 
0.04 
7 
0.011 
8 
0.00923 
9 
0.0068 
10 
0.00556 
11 
0.00222 
12 
0 
from the inputs (Case 7.6). To make all components of this decomposition 
input reachable, each of these states is combined with one of X: 
listed in 
Table 7.1. The modified decomposition consists of the components 
@ = 1x1, x3i x67 29, 210; ul}r 
(7.19) 
v: = {x?’r 
2 8 1  x13i 214; u3}, 
where now the inputs are also included in V: 
for completeness. The decom- 
position of D according to the partition in (7.19) is illustrated in Figure 7.4. 
The subsystems are connected by lines having weights no larger than 0.04, 
which was the goal of the decomposition. The decomposed system is 
(7.20) 
0 
A12 
0 
+0.04 [ 0 
0 :] 
x, 
A31 
A32 
where the state vectors of the three subsystems S?.O4, 
i = 1, 2, 3, are listed 
in (7.19), and the submatrices A, 
and Bm can be identified from the 
matrices A and B of (7.21). Only nonzero elements are shown save for a 
zero in the first row and column of A. 

7.3. Control Applications 
387 
I 
0 
m 
E 
0 
I 
N 
I 
0 
z 
0 
I 
I 
0 
r- 
(D 
c- 
"? 
8 
0 
I 
L? 
3
0
 
I 
t- 
W g
g
 
I 

388 
7. Nested Epsilon Decompositions 
Fig. 7.4. Epsilon decomposition. 
To design suboptimal decentralized controllers (Section 3.2), we choose 
QD = I12, RD = 13, and compute the gain matrices K1, K2, and K3 for 
KO = diag{KI, K2, K3) as 
K1 = [ 1.0000 -0.3169 
-0.2246 
0.5955 0.16361, 
K2 = [ 0.4521 0.4858 0.28411, 
K3 = [ -0.0490 
0.1480 0.4405 0.19751. 
To determine stability of the closed-loop system 
So.o4: j. = ( A  - B K D ) ~ ,  
(7.22) 
(7.23) 

7.4. Nested Connective Stability 
389 
we use the vector Liapunov method (Section 2.2). Then, the test matrix is 
computed as 
w = [  0 
0.0441 
] . 
(7.24) 
0.0015 -0.0017 
-0.0320 
-0.0045 
0.0032 
Since W is an M-matrix, the system 
The obtained result is trivial if we recognize the fact that A and B 
both have a lower block triangular (LBT) structure. This special form was 
not intended here, but could have been discovered by LBT decomposition 
using Algorithm 6.13. 
To evaluate the performance of the closed-loop system obtained above, 
the degree of suboptimality is computed. First, we take locally optimal 
system as reference, and get from (3.62) the value 
is stable. 
p* = 0.8115. 
(7.25) 
This implies that less than 20% deterioration of locally optimal performance 
is caused by the epsilon coupling terms. When the centrally optimal system 
is taken as reference, the degree of suboptimality is 
p’ = 0.8139, 
(7.26) 
and we conclude that the locally optimal performance is less than 20% 
off of the best possible case we could achieve without decomposition. The 
epsilon terms have minor effects on the overall performance of the system, 
which justifies the epsilon decomposition design of decentralized feedback 
control system. 
7.4. Nested Connective Stability 
It has been argued repeatedly that complexity in systems, be it in bi- 
ology or physics, society or technology, takes the form of a hierarchy. A 
considerable number of examples in these diverse fields have been provided 
by Simon (1962) to show that complex systems evolve by putting together 
stable parts and subassemblies (components and subsystems) on a number 
of levels in a hierarchy. Bronowsky (1970) described the process of creation 
of carbon from helium to demonstrate “a physical model which shows how 
simple units come together to make more domplex configurations; how these 
configurations, if they are stable, serve as units to make higher configura- 

390 
7. Nested Epsilon Decompositions 
tions; and how these configurations again, provided they are stable, serve 
as units to build still more complex ones, and so on." He calls this phenom- 
ena %tratified stability" and argues that it is fundamental in the evolution 
of living systems. 
Inspired by the notion of stratified stability, Ikeda and Siljak (1985) pro- 
posed a concept of hierarchical Liapunov functions. They serve to establish 
stability of nested hierarchies composed of components and subsystems, 
and are especially suitable for the type of nested hierarchies produced by 
epsilon decompositions. 
First, Liapunov functions are constructed to show stability of each indi- 
vidual component (block of A o )  on the zeroth level of the hierarchy. Then, 
the components are interconnected (using the matrix c1Al) to form sub- 
systems. Stability of the subsystems is established on a higher hierarchical 
level by subsystem Liapunov functions composed of the component Lia- 
punov functions. The subsystems can be further interconnected (by Q A ~ )  
into still larger subassemblies, and stability can be shown using the subsys- 
tem Liapunov - 
functions, and so on, until the overall system is integrated 
into a whole (A), and its stability is determined by a single hierarchical 
Liapunov function. 
A remarkable consequence of a hierarchically constructed Liapunov 
function is the fact that it establishes connective stability on each level 
of the hierarchy, that is, nested connective stability. During the process of 
interconnecting stable dynamic elements on any level of a nested hierar- 
chy, the system can fall apart in precisely the way it was constructed and 
stability would be preserved. The evolution of the system can then restart 
immediately towards more complex forms by interconnecting back the sta- 
ble subsystems and subassemblies. In this way, we mimic in the context of 
interconnected dynamic systems what Simon (1962) argues goes on in the 
natural evolution of complex systems, which exhibits inherent reliability 
and robustness to environmental perturbations. 
The notion of nested connective stability is introduced via interconnec- 
tion matrices that describe the nestedness on two levels involving subsys- 
tems and their components. A system is described as 
s: x = f ( t ,  z), 
(7.27) 
where z(t) E R" is the state of S at time t E R, and the function f: R x 
R" + R" is smooth enough so that solutions z(t; to, 20) of (7.27) exist for 
all initial conditions (to, zo) E R x Rn and time t E R. Furthermore, we 
assume that f ( t ,  0) = 0, and that z = 0 is the unique equilibrium state of 
S .  

7.4. Nested Connective Stability 
391 
We assume that the system S can be decomposed as 
s: hi = gi(t, X i )  + hi(t, x ) ,  
i E N, 
(7.28) 
which is an interconnection of N subsystems 
Si: hi = gi(t, xi), 
i E N, 
(7.29) 
where xi@) E Rnt is the state of Si at time t E R, gi: R x Rnz --+ Rnt is 
the subsystem function, hi: R x Rn 4 Rna is the interconnection of Si, 
and xi = 0 is its unique equilibrium. We assume that the subsystems are 
disjoint, that is, 
R" = R"1 x R"' x . . . x R"N. 
(7.30) 
Our crucial assumption is that the system S is nested, that is, each 
subsystem Si is an interconnection 
si: x.. 
2, - 
- P i j ( t ,  Z i j )  +9ij(t, X i ) ,  
j E Mi, 
(7.31) 
of Mi components 
Czj: X z j  =pa,(t, xzj), 
j E Mz, 
(7.32) 
where x,, (t) E RnZ, is the state of the C, at time t E R, p,, : R x R"%J 4 R",J 
is the component function, qa3: R x R". -+ Rna3 is the interconnection, 
x , ~  
= 0 is the unique equilibrium of C2,, and M = (1, 2, . . . , M,}. Again, 
the C,, are disjoint and 
Rnt = Rnal x Rna2 x . . . x R n a M a ,  
(7.33) 
To describe nested structural perturbations, we represent the system S 
of (7.27) as 
S: h = f ( t ,  2; E, L), 
(7.34) 
or, in the decomposed form (7.28), as 
where the N x N interconnection matrix E = (eij) has elements eij: R --+ 
[0, 11 that are piecewise continuous functions of time. The interconnection 
functions have the form 
hi(t, x; E )  z hi@, ei1x1, ei2x2, . . . , e i N x N ) ,  
(7.36) 

392 
7. Nested Epsilon Decompositions 
so that elements eij quantify the strength of interconnections of the sub- 
system Si with the rest of the system S. The nominal interactions are 
described by the system fundamental interconnection matrix E = ( E i j )  
(Definition 2.1). 
When E(t) = 0, the subsystems 
s.. 
z. f .  - 
- d t ,  xi; Li), 
i E N, 
(7.37) 
are decoupled from each other. Each subsystem Si is connected as an in- 
terconnection 
of components 
c..: 
ZJ k . . -  
zj - Pij(t, Z i j ) ,  
j E Mi. 
(7.39) 
The interconnection functions among the components have the form 
where c k :  R -+ [0, 11 are elements of the Mi xMi matrix Li = @ k )  that are 
piecewise continuous functions of time. The matrix L = diag(L1, L2, . . ., 
L N }  defines the interconnection structure of components in S ,  with L, de- 
scribing the interconnections among the components Cij constituting the 
subsystem Si. A critical assumption is the block diagonal structure of L, 
which rules out interconnections between components of two distinct sub- 
systems. These interconnections, if they exist, are a part of the intercon- 
nections among the subsystems. 
The nominal structure describing the interactions among the compe 
nents in each Si is specified by the subsystem fundamental interconnection 
matrix Li = ( q k ) .  The Mi x Mi binary occurrence matrix is defined as 
1, 
0, 
Zik occurs in qij(t, zi; Li), 
Xik does not occur in qij(t, xi; Li). 
q k = {  
(7.41) 
Again, Li(t) 5 Li element-by-element, that is, Li(t) E zi (see Section 2.1), 
and the qk quantify the individual interconnection of components Cij in 
Si relative to a maximal (nominal) interconnection strength. A nominal 
interconnection structure of components in S is, therefore, defined by the 
first-level fundamental interconnection matrix 
= diag(Z1, L 2 ,  . . . , E N } ,  
while the second-level fundamental interconnection matrix E describes a 
nominal structure of interconnections among the subsystems. 

7.4. Nested Connective Stability 
393 
We give a definition of nested connective stability: 
7.11. DEFINITION. A system S is nested connectively stable if 
in the large for all Li(t) E Li, i E N; and 
in the large for all E(t) E E. 
(i) For E(t) = 0, the equilibrium zi = 0 of Si is asymptotically stable 
(ii) For L(t) = L, the equilibrium z = 0 of S is asymptotically stable 
When compared with the standard notion of connective stability (Def- 
inition 2.3), Definition 7.11 introduces two levels of connective stability, 
each level having two distinct types of structural perturbations: one on the 
component level, and the other on the subsystem level. It is crucial to note 
that the two levels are not independent. When a subsystem S, is decoupled 
from the rest of the system S ,  its components C,, can be disconnected and 
again connected in various ways during operation of S,-this 
is part (i) of 
Definition 7.11. When, however, the interconnection structure among the 
subsystems S, is changing, the interactions among all C,, have to stay fixed 
at their nominal strengths-this 
is part (iz) of Definition 7.11. 
In order to establish connective stability of a nested system using mul- 
tilevel Liapunov functions, we start with the assumption that each compo- 
nent C,, is stable and we have a Liapunov function v2,(t, x,,) to prove it. 
Using these functions, we construct a Liapunov function v,(t, 2,) for each 
subsystem S ,  as 
MZ 
j=1 
4 ( t ,  4 = Cdz,uz,(t, &,), 
(7.42) 
where the d,, are all positive numbers. We also assume that each function 
u,,: 
R x R"*J + R+ is continuously differentiable on the domain R x Rn*j, as 
well as positive definite, decrescent, and radially unbounded, and satisfies 
the inequality 
where 7rij is a positive number, and $ij: 
Rni3 .+ R+ is a positive definite 
function. 
We assume that 

394 
7. Nested Epsilon Decompositions 
where the ~ . i j  > 0 are known numbers, and constrain the interconnections 
as 
M i  
IIQij(t, Xi; ' % ) [ I  
5 x q k ( t ) < j k $ i k ( X i k ) ,  
k=l 
V(t, X i )  E R X Rn', 
(7.45) 
where the <jk 2 0 are known numbers. An Mi x Mi test matrix Wi = ( w j k )  
is defined as 
(7.46) 
As in Section 2.2, we conclude connective stability of Si by testing the 
M-matrix property of Wi. Assuming this property of all Si, we construct 
a second level Liapunov function 
N 
V(t, X) = C d i v i ( t ,  xi), 
(7.47) 
i= 1 
where the di are all positive numbers. We have already the functions 
vi(t, X i ) ,  SO that we can compute 
k ( t ,  ~ i ) ( 7 . 3 5 )  I - 2 r i $ f ( ~ i ) ,  
v(t, xi) E R x R"*, 
(7.48) 
Rni -+ 
R+ is a positive definite 
where 7ri is a positive number and $i: 
function. Again, we assume 
IIgrad vi(t, zi)ll I 2 ~ ~ $ ~ ( q ) ,  
V(t, zi) E R x Rn*, 
(7.49) 
with I C ~  > 0, and 
N 
IIhi(t, 
I 
C e i j ( t ) < i j $ j ( z j ) ,  
V(t, X) E R x R", 
(7.50) 
where <ij L 0, and compute the N x N test matrix W(t) = [ w i j ( t ) ]  having 
the elements 
j=1 
(7.51) 

7.4. Nested Connective Stability 
395 
By Wi, 
i E N, and W ,  
we denote the test matrices corresponding to 
the nominal interconnections defined by Ei, i E N, and El and prove the 
following: 
7.12. 
S is nested connectively stable. 
THEOREM. If w,, 
i E N, and W are M-matrices, then the system 
Proof. We start at the component level, use the description (7.38) of 
Si, and from (7.43)-(7.45) compute 
&(t, zi)(7.36) 5 - zF(%)(W:Dz 
+ Di%)zi(zi), 
V(t, z,) E R x R",, 
VL,(t) E L,, 
(7.52) 
where D, = diag{d,l, d22, . . . , d z M , }  and z, : Rn* -+ RY1 is defined as 
zz(z2) = [yhl_(zzi), 
+,2(zL2), . . . , $,M, ( z , ~ , ) ] ~ .  
When W, is an M-matrix, 
the matrix WTDz + D,W, is positive definite for some D (Theorem 2.4), 
and S, is connectively stable with respect to its components Cv, 
j E M,. 
This is part (2) of Definition 7.11. 
Part (ii) of Definition 7.11 is shown by noting that, when L(t) = L, 
all the interconnections among the components are fixed, and we have the 
standard case of connective stability again. The inequality is 
V(t, 2)(734) I -zT(z)(WTD + DW)z(z), 
V(t, z) E R x R", 
V'E(t) E I?, 
(7.53) 
where D = diag{dl, d2, ..., dN} and z :  R" -+ 
RY is z(z) = [+l(zl), 
1/9(22), . . . , + N ( 2 N ) I T .  Since W is an M-matrix, W
T
~
 
+ DW is positive 
definite and S is connectively stable with respect to E. 
Q.E.D. 
Theorem 7.12 is a straightforward consequence of Theorem 2.9, and 
hierarchical Liapunov functions would not be so interesting if it were not 
for the fact that the proposed multilevel construction may show stability 
where a straightforward vector Liapunov function fails. We show this fact 
using a simple example: 
7.13. EXAMPLE. Let us consider a system 
s: x =  
(7.54) 

396 
7. Nested Epsilon Decompositions 
Fig. 7.5. System structure. 
which is decomposed along the solid lines into two subsystems 
-3 
-2 
3 -4 
s1: & =  [ 
] 21, 
(7.55) 
The subsystem S1 is further decomposed into two components along the 
dotted lines as 
c11: 211 = -3211, 
c12: 212 = -4212. 
(7.56) 
The structure of S is shown in Figure 7.5, where single lines denote 
first level interactions among components C11 and C12, while double lines 
denote second level interconnections between subsystems S1 and S2. 
On the component level we choose the functions 
and compute the numbers 
which is an M-matrix. Obviously, the functions 
(7.57) 
(7.58) 
(7.59) 

7.4. Nested Connective Stability 
397 
Fig. 7.6. Structural perturbations: Level I. 
are Liapunov functions for S 1  and S 2 ,  and connective stability under struc- 
tural perturbations on the level of components (Figure 7.6) is established. 
By choosing 
and using the Euclidean vector norm, we calculate the numbers 
7r1 = 8, 
K1 = 3, 
lr2 = 4, 
K2 = 1, 
(7.61) 
511 = 0, 
512 = &, 521 = 3 J z  , 
522 = 0, 
and obtain the matrix 
8 
-3& 
w = [ - 3 J 2  
4 
1
3
 
(7.62) 
which is an M-matrix, and 
V ( 2 )  = 3 4  + 22q2 + z;, 
(7.63) 
is a Liapunov function for S .  This means that S is connectively stable under 
nested structural perturbations affecting subsystems S 1  and S 2  (Figure 7.7) 
and, thus, nested connectively stable. 
We now show that stability of S cannot be established by a single 
level construction based on the component Liapunov functions. In other 
words, the functions w 1 1 ( ~ 1 1 )  and v12(212) have to be combined to get the 
subsystem function v 1 ( 2 1 )  before an overall Liapunov function V(t, 2 )  is 
attempted. If we consider (211, C 1 2 ,  and S 2  as three interconnected subsys- 
tems, then the (standard) function is 
'$2) = d l v l l ( z l 1 )  + d22112(212) + d 3 v 2 ( 2 2 ) -  
(7.64) 
By following the procedure proposed in Theorem 2.9, we obtain 
i/(2)(7.54) I 
-ZT(0)(WTD + DW)Z(Z), 
(7.65) 

398 
7. Nested Epsilon Decompositions 
Fig. 7.7. Structural perturbations: Level 11. 
where z(x) = (1x111, 1 ~ 1 ~ 1 ,  
( z ~ I ) ~ ,  and the test matrix is 
3 
-2 
-2 
w =  
[-3 
4 -:I. 
-3 
-3 
(7.66) 
W is not an M-matrix and we cannot conclude that v(x) is a Liapunov 
function for S. The reason we failed is the fact that the single level con- 
struction could not exploit the beneficial effect of interconnections among 
the components C11 and Clz at the subsystem level. The price we have to 
pay, however, is the hierarchical constraints on allowable structural pertur- 
bations. We cannot allow the interconnections among the components to 

7.5. Block Diagonal Dominance 
399 
Fig. 7.8. Unstable system. 
Fig. 7.9. Stable system. 
be broken when subsystem interactions are present. The system 
0 
s*: x =  [ -; 
-4 :I 
2, 
3 -4 
(7.67) 
which has the structure of Figure 7.8, is unstable. 
We also note that the nested connective stability as stated in Defini- 
tion 7.11 does not capture the totality of stable configurations. An acyclic 
structure shown in Figure 7.9 is stable, yet it is a product of simultaneous 
structural perturbations on both levels of the system S. 
In concluding this section, we note that the hierarchical Liapunov func- 
tions are ideally suited for proving stability of systems having nested epsilon 
decompositions. The functions can take advantage of nestedness in the same 
way they are used to establish stability of the system in Example 7.13. 
7.5. Block Diagonal Dominance 
Epsilon decompositions of a given matrix represent an ideal conditioning 
procedure for application of block diagonal dominance. A brief exposition 
of the main results concerning this property is given here. For more details 
concerning block diagonal dominance, including overlapping blocks, see the 
paper by Ohta and Siljak (1985). 

400 
7. Nested Epsilon Decompositions 
Let us consider a complex matrix A E C""" which is decomposed as 
A=AD+Ac, 
where 
AD = diag(A1, A2, . . . , AN}, 
(7.68) 
(7.69) 
All 
A12 
... A1N 
Ac = [ A21 
A22 
1:: 
, 
(7.70) 
where A, E Cntxnl, Aij E C"%""J 
, i, j E N, n = CiYl 
ni, are submatrices 
of AD and Ac, respectively. 
...................... 
AN1 
AN2 
N 
From (Ohta and Siljak, 1985), we have: 
7.14. DEFINITION. 
inant (QBDD) if 
R = diag{ R1 , R2 , . . . , RN} such that 
A matrix A is said to be quasi-block diagonal dom- 
(i) There exist nonsingular matrices L = diag(L1, L2, . . . , LN} 'and 
Ai = Li&, 
i E N. 
(7.71) 
(ii) There exists a set of matrix norms R = (11 
* ( l i j :  C"axnJ 4 R+; 
i, j E N) such that 
where F = ( E j )  E C""" and Fij E CnaxnJ 
for all i, j E N. 
(iii) The matrix W = (wij) E RNxN with elements 
is an M-matrix. 
(7.73) 
For simplicity, in the following developments, we drop the subscript 
of (1 *llijl and denote the elements of R as (1 *I(. Given a set of matrix 
norms 0, let G: C""" + RNxN be a matrix function G ( F )  = [Gij((Fij)], 
where Gij(F,j) = IIFijII. Note that the matrix W defined by (7.73) can be 

7.5. Block Diagonal Dominance 
401 
represented by W = I - G(Ac), where Ac = L-'AcR-l. For convenience, 
we use the notation A , j  = L,'AijR;' 
and Ac = (Aij). 
Denoting by p( 0 )  the spectral radius and using the properties of M- 
matrices (Theorem 2.4), it is easy to get: 
7.15. THEOREM. The following conditions are equivalent: 
(i) 
there exists a monotone matrix norm (1 *(Im such that IIG(Acl(, 
< 1; 
I - G(Ac) is an M-matrix; 
there exist positive numbers d j ,  j E N, such that 
(4 
p[G(Ac)l < 1; 
(iii) 
(iw) 
(w) there exist positive numbers di, j E N, 
such that 
By I( * [ I r n :  
RNxN + R+ we denote a monotone matrix norm: For any 
two matrices H = (hij), H' = (/L:~), hij 2 lhijl implies llHllrn 2 IIH'llrn. 
We also note that the function 11 *I[+ : C""" + R+ defined by IIFll. = 
IIG(F)II, is a matrix norm (Stewart, 1973), and A = L(I + Ac)R. Then, 
from Theorem 7.15, the following result is automatic (Ohta and Siljak, 
1985): 
7.16. THEOREM. If A is QBDD, then A is nonsingular. 
Now, several remarks are in order: 
7.17. 
If A is partitioned as in (7.70) using an epsilon decom- 
position, we get (7.5) with K = 1, € 1  = c, as A = AD + EAC. Then, (7.74) 
becomes 
€dj'CdiIIAijII < 1, 
vj E N, 
(7.76) 
which means that epsilon decompositions are conducive to the QBDD prop 
erty of A in pretty much the same way they are to stability tests of vector 
REMARK. 
N 
i=l 

402 
7. Nested Epsilon Decompositions 
Liapunov functions: The smaller e is, the better is the chance to establish 
the property of A in question. A similar conclusion holds for stability of A 
via QBDD, which we consider below. 
7.18. 
In Definition 7.14, we allow for an arbitrary choice of 
matrix norms for each individual block Aij of AC = L-lAcR-' separately, 
as long as (7.72) holds. Moreover, it should be stressed that elements of R 
need not be usual operator norms. 
REMARK. 
7.19. REMARK. Conditions (7.74) and (7.75) with di = 1 for all i E N 
define the notion of block diagonal dominance introduced by Robert (1969) 
and Pearce (1974)- Okuguchi (1978) generalized this notion by introduc- 
ing the numbers di. Since basic to the notion of diagonal dominance is 
a normalization of Ac by AD, Robert (1969) and Pearce (1974) adopted 
& = A,'& 
or Ac = AcAi1. In Definition 7.14, we used a more general 
normalization scheme (Ohta and Siljak, 1985) where the normalized matrix 
is Ac = L-'AcR-', and LR = AD. Since L-'AcR-l = R(LR)-'AcR-' = 
R(A,'Ac)R-', Definition 7.14 of QBDD is equivalent to that of Okuguchi 
(1978), save for the additional freedom provided by our definition of the 
set R. Moreover, our normalization scheme turns out to be useful when a 
choice of the matrix norm is fixed. 
7.20. REMARK. Fiedler (1961) defined the notion of block diagonal 
dominance as follows: A matrix A is said to be block diagonally dominant 
if there exist positive numbers di, i E N, such that 
where 11 *[I is a usual operator norm; if strict inequality holds in (7.77), then 
A is strictly block diagonally dominant. In (Feingold and Varga, 1962), di = 
1 for all i E N. Since IIA;'ll 
11 Aijll 2 l[A;'AijIl, this definition of Fiedler is 
more conservative than that of Okuguchi, as long as we are interested in 
nonsingularity of A. However, Fiedler's definition (7.77) is useful when we 
consider stability of A (Ohta and Siljak, 1985). 
To consider stability of a matrix A, we denote by Sp(A) its spectrum, 
and recall that A is stable means that Sp(A) c C+, where C+ denotes the 

7.5. Block Diagonal Dominance 
403 
complement of C+; that is, A - X I  is nonsingular for all X E C+. From 
Theorem 7.16 the following result is automatic: 
7.21. THEOREM. If A - A 1  is QBDD for all C+, then Sp(A) C C+. 
For convenience, we say that a matrix A is QBDDS if A - X I  is QBDD 
for all X = C+ and, hence, A is stable. We should note that this definition 
of QBDDS is not overly restrictive. That is, SP(AD) c C+ and the QBDD 
property of A alone is not sufficient for Sp(A) c C+. For example, the 
matrix 
-2 
-6 \-lo00 
A =  
All = 0, 
A22 = 0, 
(7.78) 
proves the statement. Choosing L = diag{Al, A2} and R = diag{I, l}, 
and using R as a set of spectral norms, we can show that A is QBDD. 
Moreover, Sp(A1), Sp(A2) c C,. However, Sp(A) 
C+. 
When $(AD) c C+, we can factor AD - X I  as 
where L(X) = diag{Ll(X), L2(X), . . . , LN(X)} and R(X) = diag{Rl(X), 
&(A), 
. . . , &(A)} 
are 
nonsingular 
matrices. 
The 
test 
matrix 
W(A) = [wij(A)] E R N x N  has the elements 
1 - ~ ~ L ~ ' ( X ) A ~ ~ R ~ ~ ' ( X ) ~ ~ ,  
2 = j ,  
i Z j ,  
(7.80) 
{ -11 L;l(wijR;l(A) 
II 1 
wij (A) = 
and if W(X) is an M-matrix for all X E C+, 
then A is QBDDS. 
Since W(X) is a function of the parameter A, it may be difficult to test 
if it is an M-matrix. A sufficient condition for W(X) to be an M-matrix 
for all X E C+ is that W(X) is a quasi-dominant diagonal matrix for all 
X E C+, which is condition (iii) of Theorem 2.4. Two types of sufficient 
conditions have been derived in (Ohta and Siljak, 1985). The first is: 
7.22. THEOREM. Assume that AD is Hermitian and negative definite. 
If A is QBDD with L = -R = (-Ao)ll2 and R is a set of spectral 
norms, then A is QBDDS with L(X) = 
+ X(-AD)'/~ and R(X) = 
- ( - A ~ ) - ~ / ~ .  

404 
7. Nested Epsilon Decompositions 
For the second result, we define a comparison matrix A = ( & j )  E R"'" 
as 
Re aii , 
i = j, 
laijl, 
i # j. 
7.23. THEOREM. Assume that L(X) and R(X) are given by 
L(X) = AD - XI, 
R(X) = I 
(7.81) 
(7.82) 
and: 
(i) For each i E N, -A is an M-matrix; 
(ii) The matrix I@ = (Sij) E R N x N  defined as 
is an M-matrix, where Ii is the ni x ni identity matrix. Then, A is QBDDS. 
To establish a relationship between the concepts of QBDDS and vector 
Liapunov functions (Sections 2.2 and 7.4), let us consider a linear time- 
invariant system. 
which is an interconnection of N subsystems 
Si: ki = Aixci, 
i E N, 
(7.85) 
obtained as a product of an epsilon decomposition. We assume that all Ai 
are stable, that is, Sp(Ai) c C,. Then, if in the Liapunov matrix equation 
ATH, + H ~ A ~  
= -Ai, 
i E N, 
(7.86) 
we choose Ai as a symmetric negative definite matrix, the solution Hi of 

7.6. Notes and References 
405 
(7.86) is a symmetric positive definite matrix, and the function wi: R". + 
R+ 7 
(7.87) 
.Z(Zi) = ZZ T HiZi, 
i E N, 
is a Liapunov function for the decoupled subsystems (7.85). 
This process defines an N x N block matrix 
A = A D  + EAC, 
(7.88) 
(7.89) 
where 
A D  = diag(A1, 22, . . . , AN}, Ac = (2HiAij). 
We use the functions vi(~i) of (7.87) as components of a vector Liapunov 
function v = (211, v2, . . . , v ~ ) ~ ,  
and state the following: 
7.24. 
If A is QBDD with respect to i2 consisting of spectral 
norms and the factorization L =  AD)'/^, R = -L, then the equilibrium 
z = 0 of S is asymptotically stable and v ( ~ )  
is a vector Liapunov function 
for S .  
THEOREM. 
Again, the smaller E is, the more likely Theorem 7.24 is to succeed. The 
vector Liapunov approach, however, offers a possibility of replacing the 
constant interconnection matrices A, by matrix functions Aij(t, x), thus 
allowing for robustness consideration of stability to nonlinear timevarying 
perturbations of S (for details, see Ohta and Siljak, 1985). 
7.6. Notes and References 
The idea of weakly coupled systems and the kind of nested hierarchies 
generated by a monotone increase of the coupling threshold was most dis- 
tinctly articulated by Simon (1962) in his study of complexity in natural 
and man-made systems. The study is a generalization of an earlier investi- 
gation of weak coupling and aggregation of dynamic systems in economic 
theory (Simon and Ando, 1961). A similarity between this type of result 
and the decomposition-aggregation idea underlying the method of vector 
Liapunov functions was identified in (Siljak, 1978). Use of graphs in this 
context led to a formulation of the epsilon decomposition scheme (Sezer 
and Siljak, 1986), which is presented in Sections 7.1-7.3. 

406 
7. Nested Epsilon Decompositions 
A natural notion of stability for nested hierarchical systems is strat- 
ified stability formulated by Bronowski (1970) to provide an explanation 
of evolution of complex systems in biology. By mimicking this concept 
in the otherwise entirely different context of dynamic systems, Ikeda and 
Siljak (1985: Section 7.4) proposed the notion of stratified (nested) con- 
nective stability, and provided hierarchical Liapunov functions to prove it. 
The framework fits naturally the hierarchies generated by nested epsilon 
decompositions. 
THREE COMMENTS ON EPSILON DECOMPOSITIONS 
A system with the matrix 
M =  
*
E
O
 
E
*
O
 
*
*
*
 
I 
(7.90) 
where * denotes a relatively large element of MI has a natural decomposi- 
tion into three components, which an epsilon decomposition would miss due 
to the presence of the elements m 3 1  and ~
~
3
2
 
(the matrix M corresponds 
to a connected graph). The reason is Algorithm 7.4 does not distinguish 
between a “hard” zero and a nonzero value smaller than E .  To fix this, 
the original graph should be decomposed into its strong components first, 
which rearranges M into an LBT f o m ,  and then epsilon decomposition 
should be applied to each component separately. 
Suppose now that a system matrix is 
[’ * 
E ‘:I. 
M =  
E-l 
* 
(7.91) 
Then, no epsilon decomposition is possible, as both D and D‘ contain 
a single component. However, a simple scaling of M ,  which consists of 
multiplying the last row by c2 and the last column by E-’, 
modifies the 
matrix M so that all off-diagonal elements are equal to E ,  thus resulting 
in an obvious epsilon decomposition of M into three components. This 
example illustrates the dependency of the decomposition on scaling of the 
matrix M .  How to resolve the scaling problem is an open question. 

7.6. Notes and References 
407 
Finally, let us consider a system matrix 
(7.92) 
which has no epsilon decomposition. If we expand the matrix M to get a 
new matrix 
(7.93) 
which “includes” M ,  then from (7.93) we conclude that M has an overlap- 
ping epsilon decomposition (Arabacioglu et al. 1986). 
BLOCK DIAGONAL DOMINANCE 
Diagonally dominant matrices play an important role in studies of con- 
vergence properties of dynamic processes arising in diverse fields of numer- 
ical solutions of partial differential equations (Hageman and Young, 1981), 
mathematical economics (Nikaido, 1968), and a wide variety of mathemat- 
ical models of complex dynamic systems (Siljak, 1978). The important fact 
in these applications is the classical Hadamard result that a diagonally 
dominant matrix is nonsingular. From this fact, convergence (stability) of 
a dynamic process follows directly via the standard argument involving 
Gerschgorin circles ( e.g., Varga, 1962). 
A significant dimension to the range of applications of diagonal domi- 
nance has been added by the notion of block diagonal dominance introduced 
independently by Fiedler (1961), Feingold and Varga (1962), and Pearce 
(1974). Instead of comparing the size of diagonal elements with the sum 
of magnitudes of the remaining elements in the row or column, the matrix 
is partitioned into a number of blocks, and the blocks on the main diage 
nal dominate in magnitude the respective sums of the off-diagonal blocks. 
Block diagonal dominance implies nonsingularity. With a normalization 
and an additional negative definiteness restriction on the diagonal blocks, 
Pearce (1974) has shown that block diagonal dominance implies negativity 
of the real parts of all eigenvalues of a given matrix, that is, stability of 
the corresponding dynamic process. Further improvements of the concept 
have been offered by Okuguchi (1978), who has introduced scaling of the 

408 
7. Nested Epsilon Decompositions 
blocks and use of alternative matrix norms in the definition of block diag- 
onal dominance, as well as M-matrix properties for the diagonal blocks as 
proposed by Feingold and Varga (1962). A considerable increase in flexibil- 
ity of the block concept has been achieved by introduction of overlapping 
blocks and the notion of overlapping block diagonal dominance (Ohta and 
Siljak, 1985). 
How QBDD can be used in a design of decentralized control in the 
frequency domain, is explained in (Ohta, et al. 1986). An application of 
Hm theory in this context is proposed by Wu and Mansour (1988, 1989). 
DISCRETE SYSTEMS AND ITERATIVE PROCESSES 
Epsilon decompositions apply to discrete systems as well. To see this, 
we should first show the tradeoff between degree of stability and the size 
of perturbations as it was done for continuous systems in Section 2.2. 
Let us consider a linear constant discrete-time system 
S z(t + 1) = Az(t), 
(7.94) 
where z(t) E R" is the state of S at time t E T+ = (0, 1, 2, . . .}, and A is a 
constant n x n matrix. We denote the solution at time t of (7.94) starting 
at zo = z(0) by z(t; 20). We recall (see Kalman and Bertram, 1960) that 
S is asymptotically stable if and only if for any symmetric positive definite 
matrix G there exists a unique symmetric positive definite matrix H that 
satisfies the Liapunov equation 
T 
A H A - H = - G .  
Then (Siljak, 1978), the norm-like function 
~ ( z )  
= ( z T H ~ ) ' ' 2  
is a Liapunov function for S. 
perturbed system 
If S is perturbed by an additive function h T+ x R" 
S: z(t + 1) = Aa:(t) + h[t, z(t)], 
and if the function h[t, z(t)] is bounded as 
(7.95) 
(7.96) 
R", we have a 
(7.97) 
IIW, 4t)lII 5 ,t11~11, vt E T, v x  E R", 
(7.98) 
where < 2 0, we would like to find out under what conditions on < stability 
of the nominal system S implies stability of the perturbed system S. It has 

7.6. Notes and References 
409 
been shown in (Sezer and Siljak, 1988) that stability is preserved whenever 
< < <@, 
where the maximal robustness bound is 
(7.99) 
1 
<@ = 
x ~ M ( H ~ )  
+ X ~ ( H ~ ) A $ ( H @  
- I )  
which is obtained when G in (7.95) is chosen as G@ = I ,  and (7.95) is 
solved to get He. It is interesting that, as in the continuous-time case 
(Section 2.2), the best choice of G for the robustness bound estimate is the 
identity matrix. 
In the context of epsilon decompositions, we are interested in an inter- 
connected system 
S: zi(t + 1) = Aiq(t) + &[t, z(t)], 
i E N, 
(7.100) 
where, instead of the linear coupling term E C,”=, 
Aijxj, we use a nonlinear 
function h: T+ x R” + R”a to capture the relevance of our results to 
gradient algorithms (Ladde and Siljak, 1990). We assume that the inter- 
connections satisfy the inequalities 
j=1 
(7.101) 
for some [ij 2 0. In a linear version of S ,  the numbers <ij are chosen as 
A$ (A~A,). 
Taking the function 
as a Liapunov function for each (stable) subsystem 
Si: zift + 1) = Aixi(t), 
(7.103) 
and using the robustness bound <? computed in (7.99), we arrive at the 
N x N test matrix W@ = (wz) 
defined as 
(7.104) 
Then, as shown by Sezer and Siljak (1988), the system S is asymptotically 
stable in the large if W@ is an M-matrix. 

410 
7. Nested Epsilon Decompositions 
The above stability result is particularly useful in convergence analysis 
of iterative processes arising in solving linear equations 
Ax = b 
(7.105) 
by epsilon decompositions (Sezer and Siljak, 1990), in particular, when 
Jacoby schemes are employed (Kaszkurewicz et al. 1990). We note that, in 
solving the linear problem (7.105), there is a distinct possibility of using 
nested multiprocessors in exactly the same pattern as the corresponding 
epsilon decomposition is formed. Then, the diagonal blocks can be solved 
in parallel with exchange of information between the blocks with frequency 
proportional to the size of epsilon. 
Control applications of the obtained results can be based upon the work 
of KokotoviC et al. (1969), Gajtsgori and Pervozvanski (1979), Peponides 
and KokotoviC (1983), Sezer and Siljak (1986), Molchanov (1987), and Lu 
et al. (1988). 
APPLICATIONS 
The most natural application of epsilon decomposition is in electric 
power systems. Under usual assumptions, a system of n machines in post- 
fault state can be described by the equations 
where bi is the rotor angle of the ith generator in the system, SF is the post- 
fault equilibrium value of &, and mi, di, and cij are the system parameters. 
In this context, it is desirable to identify coherent groups of generators 
which tend to swing together after an initial perturbation from the equi- 
librium. 
A simple approach to coherency identification is to compare the electri- 
cal distances between the generators as measured by the numbers qj: the 
larger the numbers qj, the smaller the distance between the corresponding 
generators. Generators that are close electrically to each other are grouped 
together to form subsystems (Lee and Schweppe, 1973; Chow, 1982). Ob- 
viously, this is a perfect example to which the epsilon decomposition can 
be applied directly (see Brucoli et al. 1986). For alternative decompositions 
and clustering, see (Zaborsky et al. 1982; Kumar et al. 1986; Kusiak and 

Bibliography 
411 
Chow, 1987; Khorasani and Pail 1988). For potential use of epsilon decom- 
positions in stability analysis of multimachine systems via vector Liapunov 
functions, see (Araki et al. 1982). 
Finally, we note that nested epsilon decompositions can be applied to a 
wide variety of clustering problems in a number of disciplines where near- 
decomposability concepts are useful (see Courtois, 1977). In particular, the 
models in economics, queueing networks, and computer systems seem to 
be the most promising candidates. The near-decomposibility in a broad 
range of applications in the natural and man-made systems has been most 
convincingly promoted by Simon 
Bibliography 
Arabacioglu, I. M., M. E. Sezer, and 0 
986). Overlapping decomposition of 
large scale systems into weakly coupled subsystems. Computational and Combinato- 
rial Methods in System Theory, C. I. Byrnes and A. Lindquist (eds.), North-Holland, 
Amsterdam, 135-147. 
Araki, M., M. M. Metwally, and D. D. Siljak (1982). Generalized decompositions for 
transient stability analysis of multimachine power systems. Large Scale Systems, 3, 
111-122. 
Bronowski, J. (1970). New concepts in the evolution of complexity. Syntheses, 21, 228- 
246. 
Brucoli, M., F. Torelli, and M. Trovato (1986). A structural approach for the decom- 
position of interconnected power systems in stability studies. Control Theory and 
Advanced Technology, 2, 273-292. 
Chow, J. H. (1982). Time-Scale Modeling of Dynamic Networks with Applications to 
Power Systems. Springer, New York. 
Courtois, P. J. (1977). Decomposability. Academic Press, New York. 
Feingold, D. G., and R. S. Varga (1962). Block diagonally dominant matrices and gen- 
eralizations of the Gerschgorin circle theorem. Pacific Journal of Mathematics, 12, 
Fiedler, M. (1961). Some estimates of spectra of matrices. Proceedings of the Sympo- 
sium on the Numerical Gatment of Ordinary Differentzal, Integral, and Integro- 
Diflerential Equations, Birkhaiiser, Basel, Switzerland, 33-36. 
Gajtsgori, V. G., and A. A. Pervozvanski (1979). Perturbation method in the optimal 
control problems. Systems Science, 5, 91-102. 
Hageman, L. A,, and D. M. Young (1981). Applied Iterative Methods. Academic Press, 
New York. 
Ikeda, M., and D. D. Siljak (1985). Hierarchical Liapunov functions. Journal of Mathe- 
matical Analysis and Applications, 112, 11Ck128. 
Kalman, R. E., and Bertram (1960). Control system analysis and design via the “Sec- 
ond Method” of Lyapunov, Part 11: Discretetime systems. Transactions of ASME, 
Series D, 82, 394-499. 
Kaszkurewicz, E., A. Bhaya, and D. D. Siljak (1990). On the convergence of parallel 
asynchronous block-iterative computations. Linear Algebra and Its Applications, 
131, 13S160. 
1241-1250. 
1962). 
H. Oral. ( 

412 
'7. Nested Epsilon Decompositions 
Khorasani, K., and M. A. Pai (1988). Two time scale decomposition and stability of 
power systems. IEE Proceedings, 135, 205-212. 
KokotoviC, P. V., W. R. Perkins, and J. B. Cruz (1969). €-coupling method for near- 
optimum design of large-scale linear systems. Proceedings of IEE, 116, 889-892. 
Kumar, K. R., A. Kusiak, and A. Vanelli (1986). Grouping parts and components in 
flexible manufacturing systems. European Journal of Operations Research, 24, 387- 
397. 
Kusiak, A., and W. S. Chow (1987). An efficient cluster identification algorithm. IEEE 
Transactions, SMC-17, 696-699. 
Ladde, G. S., and D. D. Siljak (1989). Convergence and stability of distributed stochastic 
pseudogradient algorithms. IEEE Transactions, AC-35, 665472. 
Lee, S. T. Y., and F. C. Schweppe (1973). Distance measure and coherency recognition 
for transient stability equivalents. IEEE Transactions, PAS-92, 1550-1557. 
Lu, Q., J. Lu, J. Gao, and G. K. F. Lee (1988). Discrete-time decentralized optimal 
controllers for multimachine power systems. International Journal of Control, 48, 
Mehlhorn, K. (1984). Graph Algorithms and NP-Completeness. Springer, Berlin, F. R. 
Germany. 
Molchanov, A. P. (1987). Liapunov functions for nonlinear discrete-time systems. Av- 
tomatica i Telemekhanika, 48, 2G35. 
Nikaido, H. (1968). Convex Structures and Economic Theory. Academic Press, New 
York. 
Ohta, Y . ,  and D. D. Siljak (1985). Overlapping block diagonal dominance and existence 
of Liapunov functions. Journal of Mathematical Analysis and Applications, 112, 
Ohta, Y., D. D. Siljak, and T. Matsumoto (1986). Decentralized control using quasi- 
block diagonal dominance of transfer function matrices. IEEE Transactions, AC-31, 
42G430. 
Okuguchi, K. (1978). Matrices with dominant diagonal blocks and economic theory. 
Journal of Mathematical Economics, 5, 43-67. 
Park, K. C., and C. A. Felippa (1983). Partitioned analysis of coupled systems. Compu- 
tational Methods for Transient Analysis, T. Belytschko and T. J. R. Hughes (eds.), 
Elsevier, New York, 157-219. 
Pearce, I. F. (1974). Matrices with dominated diagonal blocks. Journal of Economic 
Theory, 9, 159-170. 
Peponides, G. M., and P. V. KokotoviC (1983). Weak connections, time scales, and 
aggregation of nonlinear systems. IEEE Transactions, CAS-30, 416-422. 
Petrovic, B., and Z. GajiC (1988). Recursive solution of linear-quadratic Nash games for 
weakly interconnected systems. Journal of Optimization Theory and Applications, 
Robert, F. (1969). Blocs-H-matrices et convergence des methodes iteratives classiques 
par blocs. Linear Algebra and Applications, 2, 223-265. 
Sezer, M. E., and D. D. Sibak (1986). Nested +decomposition and clustering of complex 
systems. Autornatica, 22, 321-331. 
Sezer, M. E., and D. D. Siljak (1988). Robust stability of discrete systems. International 
Journal of Control, 48, 2055-2063. 
Sezer, M. E., and D. D. Siljak (1990). Epsilon decomposition of linear systems: Weakly 
coupled and overlapping blocks. SIAM Journal on Matrix Analysis and Applications 
(to appear). 
9 19-928. 
396-4 10. 
56, 463-477. 

Bibliography 
413 
siljak, D. D. (1978). Large-Scale Dynamic Systems: Stability and Structure. North- 
Holland, New York. 
Simon, H. A. (1962). The architecture of complexity. Proceedings of the American Philo- 
sophical Society, 106, 467-482. 
Simon, H. A., and A. Ando (1961). Aggregation of variables in dynamic systems. Econo- 
metrica, 29, 111-138. 
Stewart, G. W. (1973). Introduction to Matriz Computations. Academic Press, New 
York. 
Varga, R. S. (1962). Matrix Iterative Analysis. Prentice-Hall, Englewood Cliffs, New 
Jersey. 
Wu, Q. H., and M. Mansour (1988). An application of Hm theory in decentralized 
control. Proceedings of the 27th Conference on Decision and Control, Austin, Texas, 
Wu, Q. H., and M. Mansour (1989). Decentralized robust control using Hoo-optimization 
technique. Information and Decision Technologies, 15, 59-76. 
Zaborsky, J., K. W. Whang, G. M. Huang, L. J. Chiang, and S. Y. Lin (1982). A clustered 
dynamic model for a class of linear autonomous systems using simple enumerative 
sorting. IEEE Transactions, CAS-29, 747-758. 
1335-1340. 

In a wide variety of natural and man-made systems, subsystems share 
common parts. For either conceptual or computational reasons, it is ad- 
vantageous to recognize this fact, and build decentralized control and esti- 
mation schemes using overlapping information sets. In certain control prob- 
lems involving traffic regulation, power systems, and large space structures, 
overlapping decentralized control is the only effective way to go. 
It has been known for some time that, by expanding the state space, 
overlapping subsystems appear as disjoint. Then, standard methods can 
be used to design decentralized control laws in the expanded space. At the 
end, the expanded laws are contracted for implementation in the original 
system. To carry out this expansion-contraction process correctly, certain 
conditions have to be satisfied that ensure that solutions of the original 
system are included in solutions of the expanded system. The circle of ideas 
and conditions underlying the process have been organized only recently 
into a general mathematical framework: The Inclusion Principle. 
In our presentation of the Principle, we will use a balanced mixture of 
matrix algebra and geometric concepts to provide a flexible theory that 
is numerically attractive and, at the same time, one that appeals to intu- 
ition. A crucial contribution of the Principle is that it leads to a complete 
and, it is hoped, definite clarification of the overlapping problem. We will 
demonstrate this fact using both linear and nonlinear constant systems, 
but the theory is broad enough to accomodate time-varying, hereditary, 
and stochastic effects. 
Of special interest is the optimization problem with overlapping infor- 
mation sets because of its importance in applications. Expansions and con- 
tractions of relevant performance indices are defined for separable quadratic 
414 

8.1. Preliminaries 
415 
I 
M 
'
4
 
Fig. 8.1. Masspring system. 
criteria and linear constant systems. This allows for standard decentral- 
ized methods (see Chapter 2) to be used in the expanded space to estab 
lish suboptimal, but stable, performance of decentralized local controllers 
obeying the overlapping information structure constraints. These results 
are of central importance for building reliable control using multiple con- 
troller schemes, which is the theme of Chapter 9. Other applications of 
overlapping optimization methods are described in Notes and References 
(Section 8.5). 
8.1. Preliminaries 
To motivate the reader for overlapping decompositions, let us consider 
the mechanical system in Figure 8.1, which consists of two identical mass 
and spring elements attached to a rigid structure. The equations of motion 
are 
By choosing the state vector z = (41, 41, q2, q 2 ,  q3, 43)*, we rewrite the 

416 
8. Overlapping Decompositions 
Equations (8.1) in the matrix form as the system 
0 
0 ;  0 
l g  O
i
m
 
'
a
 
+ 
( y + p o  
O 
'1 
0 
m 
0
-
 
where u = ( U I ,  UZ, 
~
3
)
~
 
is the control vector of S .  
The underlying assumption, which calls for an overlapping decomposi- 
tion of S ,  is that the mass M of the rigid structure is much larger than the 
mass m of the attached elements. Furthermore, the stiffness ,8 is small so 
that the coupling between the elements is weak. Under these assumptions, 
an obvious decomposition of S into three subsystems, where each mass 
corresponds to a subsystem, is not a natural decomposition. The reason is 
that the strong coupling of size a/m of the structure to the elements are 
exposed as interconnections between the subsystems. This makes a decen- 
tralized control strategy, which is based on three independent inputs u1, U Z ,  
and us, unjustified. A better way to partition the system S is to pair the 
structure with each element separately and form two subsystems that share 
the structure as a common part-ibis is an overlapping decomposition. It 
is indicated by dashed lines in (8.2). 
Although the two overlapping subsystems are well defined, the intercon- 
nections between them are not. To identify the interconnections, we expand 
the system S by repeating the two state equations describing the structure. 

8.1. Preliminaries 
417 
This leads to the expanded system 
- s: x =  
+ 
0 
0 
0 
O
T
i
i
 
P
o
 
0 
0 
0 
0 
0 
0 
0
1
 0
0
 
-2% 
0 
2 
0 
% 
0 -+p 
0 
0
0
 0 
1 
- 
X 
(8.3) 
Now, two subsystems can be formed, resulting into a standard disjoint 
decomposition indicated by dashed lines in (8.3). The important fact is that 
in the expanded system the interconnections between the two subsystems 
are well defined as the off-diagonal blocks. Equally important is the obvious 
weakness of the coupling, which contains only the small numbers cr/M 
and P/m; the large connections corresponding to a/m appear inside the 
subsystems, and serve to enhance their autonomy. Before we can exploit 
this weak coupling structure of the expanded system S ,  we should establish 
the relationship between S and the original system S having a smaller 
dimension. This we do next. 
In order to make transparent a conceptual significance of the unortho- 
dox notion of overlapping subsystems, we start our exposition using linear 
constant systems without inputs and outputs. As in the preceding example, 
we consider the basic situation where only two subsystems are involved. 

418 
8. Overlapping Decompositions 
Let us consider a system 
S: 2 = A X ,  
(8.4) 
where x(t) E R" is the state of S .  We assume that x is composed of three 
components, x = (x:, x:, x : ) ~ ,  with each component chosen on the basis 
of some physical or abstract reasoning. The dimensions of the components 
are n1, 722, and 723 so that n = n1 + 712 + 713. This partition of the state x 
induces a partition of the n x n matrix A as 
[Ail T------+------ 
, A12 
A131 
A =  A21 j A22 1 A23 , 
(8.5) 
-------&-----L 
A31 
A32 
A33 
where the submatrices have appropriate dimensions. 
Now, we arrange the three components of the state x into two overlap 
ping components El = ( x y ,  x T ) ~  
and 52 = ( x r ,  x : ) ~ ,  
which we use to form 
a new vector E = (Zy, ZT)', 
and induce an overlapping decomposition of A 
indicated by dashed lines in (8.5). The vector Z is related to x by a linear 
transformat ion 
where V is the fi x n matrix 
and ii = nl + 2n2 + 723. In (8.7), I l l  IZ1 and I3 are identity matrices with 
dimensions corresponding to the vector components 21, x2, and x3 of x. 
Transformation (8.6) defines the expanded system 
with the state Z ( t )  E R' and the ii x ii matrix 
A = VAU + M. 
(8.9) 

8.1. Preliminaries 
419 
The matrix U = (VTV)-lVT is chosen as the pseudoinverse of V :  
I1 
0 
0 
(8.10) 
and UV = I,, which is the identity matrix of order n. The matrix M is 
termed a complementary matrix, and the choice 
(8.11) 
produces a matrix A in the form 
By comparing the original matrix A with the expanded matrix A, we note 
that under the transformation (8.6), the description of the overlapping 
diagonal blocks remained invariant due to the choice (8.11) of the com- 
plementary matrix M .  This invariant property of the expansion is crucial 
because the identity of overlapping subsystems is preserved in A, and they 
now appear as disjoint. 
To take advantage of the form (8.12) of the expanded matrix A, we 
need to establish the relation between the motions z(t; 20) and Z(t; 20) of 
the two systems S and S, which start at t = 0 with xo and 50. 
It is easy to 
show that 20 = VzO implies z(t; 20) = VZ(t; 20) for all t 2 0. This means 
that U is a projection of the motion space of S onto the motion space of 
S. We express this fact by saying that S includes S, or that S is included 
by S. A circle of ideas underlying the concept of inclusion became known 
as the Inclusion Principle (e.g., Ikeda et al. 1984a). Before we engage in 
a formalization of this concept, let us take stock of what we have done 
so far. It is intuitively obvious that the stability of S implies the stability 
of S. What is not so obvious is that proving stability of S may be easier 
than proving stability of the original system S. This fact makes overlapping 
decompositions of dynamic systems attractive indeed. 

420 
8. Overlapping Decompositions 
Let us use a simple example to show that overlapping decompositions 
can be used in the context of vector Liapunov functions to establish stability 
of a system when disjoint decompositions fail. 
8.1. EXAMPLE. Let us consider a stable system 
-1 
-26 
s: x =  [ 3 -20 :] 
x. 
(8.13) 
6 -26 
-1 
To show stability by using vector Liapunov functions (Section 2.3), we use 
first a disjoint decomposition such that 
(8.14) 
t-26 
-1 
where x1 and x2 are the states of the two subsystems 
s,: x, = [ 1;: 
x2. 
(8.15) 
For subsystem Liapunov functions, we choose 
where HZ is a positive definite matrix, which is the solution of the matrix 
eauation 
-20 
-26 
[ 
-J H2+H2 [-20 
"1 =-G2, 
(8.17) 
-26 
-1 
for a symmetric positive definite matrix G,. The derivatives of the func- 
tions (8.16) are computed with respect to the system S written as two 
interconnected subsystems: 
k2 = [ -26 
-20 
-1 31 2 2 +  [ ;] 
xl. 
(8.18b) 

8.1. Preliminaries 
421 
We get 
By choosing the function 
(8.19) 
(8.20) 
as a Liapunov function for S and using (8.19), we compute 
where z = (21, ~
2
)
~
~
 
z1 = Iql, z2 = ( ~ ? Q 2 2 2 ) ~ / ~ ,  
Q2 is any positive definite 
matrix, d = (dl, d2)T is a positive vector, and 
From Section 2.3, we recall that v(z), -fi(z)(8,13) > 0, and S is stable if W 
is an M-matrix (Theorem 2.4), which is equivalent to saying that 
We show, however, that (8.22) does not hold no matter what is the choice 
of G2 and Q2. For this, we need the relation 

422 
8. Overlapping Decompositions 
By denoting the right side of (8.23) by p and using (8.23), we majorize 
the left side of (8.22) as 
(8.24) 
Next, we show that 
Am (G,'12H2Gi'12) > 1/42, 
(8.25) 
which implies that the last expression in (8.24) is negative and (8.22) does 
not hold. For this purpose, we need first to show that if a positive definite 
matrix H is the solution of the Liapunov matrix equation 
ATH + HA = -G, 
(8.26) 
for a stable matrix A and a positive definite matrix G, then 
x , ( G - ~ / ~ H G - ~ / ~ )  
> -- 
1 (tr A)-'. 
(8.27) 
2 
By multiplying (8.26) by H-'l2 from the left and from the right, we get 

8.1. Preliminaries 
423 
Using (8.28), we calculate 
(8.29) 
= -2trA, 
which proves (8.27). Applying (8.27) to our example where A is the matrix 
of system Sz in (8.6), we establish (8.25). This, in turn, implies that for 
the disjoint decomposition in (8.14) and the standard choice of Liapunov 
functions (8.16), the concept of vector Liapunov functions fails to prove 
stability of the system S .  It is easy to show that the three remaining disjoint 
decompositions of the system S lead to the same conclusion. 
Let us now show that using the overlapping decomposition, we can 
demonstrate stability of S. We decompose S along the dashed lines as 
and get the expansion 
which corresponds to the expansion matrix of (8.12). We now choose the 
subsystem Liapunov functions as 

424 
8. Overlapping Decompositions 
where 
178 -377 
845 -377 
(8.33) 
H1 = [ -377 
8451 ’ 
H2 = [ -377 
1781 ’ 
The choice of functions in (8.32) was made using the recipe of Section 2.3, 
which starts by selecting the matrices H I  and H 2  as the identity matrices 
in the transformed space where the subsystem matrices are diagonal. Using 
the function 
F(2) = dIGl(21) + d2G’2(22), 
(8.34) 
we compute 
(8.35) 
1 
b(2)(8,31) 5 -2”W% + D W )  
2, 
where 2 = (21, Z Z ) ~ ,  
51 = (2Tfi1i?1)1/2, 22 = (2rI?222)1/2, and 
(8.36) 
Because W is an M-matrix, stability of the expansion S follows. Since S 
includes S, stability of S implies stability of S. 
When we compare the disjoint decomposition of S in (8.14) with the 
same kind of decomposition of the expansion S in (8.31), we see why the 
latter is successful and the former is not. In (8.14) the large connections 
-26 are exposed in the interconnections among the subsystems, while in 
the expanded system S of (8.31) these connections are located inside the 
subsystems and, for this reason, the subsystems are weakly coupled. This 
fact makes the method of vector Liapunov functions successful in proving 
stability of the expanded system S and, therefore, stability of the original 
system S. 
8.2. The Inclusion Principle 
Now we want to formulate rigorously the Inclusion Principle, which 
provides a proper mathematical framework for the method of overlapping 
decompositions. We narrow our attention to linear time-invariant systems, 
but the formulation of the Principle is given in terms of the motions (solu- 
tions) of dynamical systems rather than in algebraic terms (matrices). This 
way, the Principle can be applied to more general types of systems with 
nonlinearities, timevarying elements, hereditary effects, etc. A balanced 

8.2. The Inclusion Principle 
425 
mixture of matrix algebra and geometric concepts is used to provide a nu- 
merically oriented expansion-contraction framework for dynamic systems 
which, at the same time, offers interpretations and insights of a geometric 
approach. 
We consider two dynamic systems S and S described by the equations 
and 
S: i = A z + B u ,  
y = cx, 
s: i = A 5 + B u ,  
- 
y = c5. 
(8.37) 
(8.38) 
Here, x E X is an n-vector, u E U is an m-vector, y E y is an !-vector; 
X , U ,  and y are the state, input, and output spaces of S, respectively. 
Similarly, 3 E X is an ii-vector, and X, U, 
and y are the state, input, and 
output spaces of S, respectively. We assume that the input u(t) belongs to 
the class of piecewise continuous functions. We say that S is represented 
relative to a given basis of the triplet (A, B, C) of constant matrices having 
appropriate dimensions. For S, we use the triplet (A, B, c). Our crucial 
assumption is n 5 ii; that is, the dimension of S is smaller (or at most 
equal) to that of S. By x(t; 20, u), we denote the unique solution of S for 
the initial time t = 0, the initial state z(0) = 20, and a fixed control input 
u(t) defined on the time interval [0, t]. For brevity, we use the notation 
x(t) to indicate the solution for arbitrary zo E X and admissible u(t), and 
the notation z to indicate the vector x(t) at t 2 0. A similar convention is 
applied to solutions 5(t; 50, u) of S. 
8.2. 
We say that a system S includes a system S (equiv- 
alently, a system S is included by a system S) if there exists an ordered 
pair of matrices (U, V) 
such that UV = I, and for any initial state xo f X 
of S and any fixed input u(t), we have 
DEFINITION. 
z(t; 20, u) = uqt; Vxa, u), 
(8.39) 
y[z(t)l = y[Z(t)], 
vt L 0. 
Condition (8.39) implies that system !?i 
contains all the necessary infor- 
mation about the behavior of system S. More importantly, we can extract 
any property of S from S and, alternatively, evaluate properties of S us- 
ing S as a reduced order model of S. This is the underlying feature of the 
Inclusion Principle. 

426 
8. Overlapping Decompositions 
With an abuse of standard notation, by S 3 S, we mean that S includes 
S; that is, S is included by S. When S 3 S ,  we say that S is a contraction 
of S, or S is an ezpansion of S. 
The inclusion property is topological (independent of the choice of ba- 
sis). This is easily seen by considering an arbitrary change of basis by 
3 = Tx, 3 = T-l2. Then, the choice V = T-lVT-’, U = TU? satisfies 
Z ( t ;  30, u) = Ug(t; V ~ O ,  
u) whenever (8.39) holds. 
Before we proceed to a general treatment of the inclusion concept, we 
consider two important special cases. We first use a matrix V that is monic 
(full column rank) and assume that, for any z g  E X and any fixed u = u(t), 
-
-
 
q t ;  vxo, u) = Vz(t; zo, u), 
(8.40) 
holds. Then, the subspace Im V c x is invariant in the sense that the 
solutions ?(t) of S starting at 2 0  E Im v stay in Im v for any input u(t). 
Such solutions 2(t) are represented by the solutions z(t) of S as in (8.40). 
Since V is monic, there exists a matrix U which is epic (full row rank) such 
that UV = I and we have (8.39), implying that S includes S. Whenever 
the relation (8.40) is satisfied for some monic V ,  we say that the system S 
is a restriction of S to Im V .  The use of this term is natural since in the 
geometric context (Wonham, 1979) it is used to define a map FIS: S + S, 
where S is an F-invariant subspace that has the action of F on S, but is 
not defined off S. The restriction S is the “dynamic” version of the static 
notion of a restriction F(S. 
If we have some epic U such that 
which hold for any 5 0  E X and u(t), then the system S is an aggregation of 
S with respect to the subspace Im UT. This notion was introduced by Aoki 
(1971) as a natural dynamic generalization of the static version of aggrega- 
tion well-known in mathematical economics (e.g., Chipman, 1976). Since 
U is epic, there exists a monic V such that UV = I ,  and the aggregation 
condition (8.41) implies condition (8.39) for inclusion. 
In order to derive explicit relations between S and S, we introduce the 
transform expressions 
A=VAU+M, 
B = V B + N ,  
C = C U + L ,  
(8.42) 

8.2. The Inclusion Principle 
427 
where M ,  N ,  and L are complementary matrices with appropriate dimen- 
sions. The following result can be used to establish the aggregation and 
restriction as duals of each other: 
8.3. THEOREM. S is a restriction of S to Im V if and only if 
MV=O, 
N = 0 ,  
LV=O. 
(8.43) 
S is an aggregation of S with respect to Im UT if and only if 
UM=O, 
UN=O, 
L=O. 
(8.44) 
Proof We establish only condition (8.43) for restriction. The aggrega- 
We note that Z(t; Vxg, u) = Vx(t; xo, u) in (8.40) can be rewritten as 
tion condition (8.44) can be proved by a dual argument. 
t 
VeAtzo + V 1 eA(t-T) Bu(T) d r  = e(vAUfM)t V x  
0 
This is true if and only if MV = 0 and N = 0, as may be seen by taking 
the power series expansion of the exponentials in (8.45). The requirement 
y[Z(t)] = y[z(t)], 
that is, Cx = (CU+ L)S, is equivalent to LZ(t) = LVx = 
0. Therefore, LV = 0. 
Q.E.D. 
We note that (8.43) can be restated algebraically as 
AV=VA, 
B = V B ,  
CV=C, 
or, in geometric terms as 
(8.46) 
KerM II Im V, 
Im N = 0, 
Ker L IJ Im V. 
(8.47) 

428 
8. Overlapping Decompositions 
Furthermore, if we define T = [V W ] ,  
where W is chosen such that Im W = 
Ker U ,  the change of basis it = T-lZ yields an equivalent representation 
(8.48) 
y =  [C *] I, 
whenever (A, B, C) is a restriction of (A, 
B, 6). 
Similarly, the aggregation condition (8.44) is equivalent to 
U A  = AU, 
U B  = B, 
C' = CU, 
(8.49) 
or 
Ker U 2 Im M ,  
Ker U 2 Im N ,  
Im L = 0. 
(8.50) 
In other words, (A, B, C) is an aggregation of (A, l?, C) if and only if S 
can be represented in an appropriate state space by 
s: & [ *  O
A
 
*]I+[;] 
21, 
(8.51) 
y =  [ O  C ]  3. 
We note that aggregation and restriction are mutually exclusive condi- 
tions in that aggregation specifies the behavior of a projection of the state 
trajectory of S for arbitrary initial conditions 2 0 ,  while restriction speci- 
fies the entire state trajectory of S for a limited set of initial conditions 
ZO E Im V c 2. 
In either case, the system S includes all of the information 
concerning the behavior of S .  Inclusion, however, need not imply either of 
these conditions as demonstrated by the following: 
8.4. THEOREM. S 3 S if and only if 
Proof. Using the explicit solution form as in the proof of Theorem 8.3 
and power series expansions of the matrix exponentials, one establishes 
(8.52). For details, see (Ikeda and Siljak, 1980a). 
Q.E.D. 

8.2. The Inclusion Principle 
429 
Relations (8.52) can be restated as 
- _ .  - 
U
~
V
 
= A ~ ,  uAzB = A ~ B ,  C2v = C A ~ ,  CAZB = CA", 
(8.53) 
for i = 0, 1, 2, . . . ; or geometrically as 
Ker U 3 M{MIImV}, 
Ker L 2 {MIIm V}, 
Ker U 3 {MIIm N } ,  
Ker L 3 {MIIm N } .  
(8.54) 
We also note that the first relation above is equivalent to U 2 V  = Ai for 
all i E n = (1, 2, . .. , TI}. 
Now, we show that a contraction S of a given system S can be obtained 
via aggregation and restriction of S ,  that is, contraction is an L'intersection'' 
of aggregation and restriction of S. For this purpose, let us introduce a 
system 
S: &=Aa:+Bu, 
(8.55) 
y = c3, 
and prove the following: 
8.5. THEOREM. S 2 S if and only if there exists S such that 
S > S > S ,  
(8.56) 
where S is a restriction (aggregation) of S and S is an aggregation (restric- 
tion) of S. 
Prooj We assign a pair ( ~ 1 ,  to S 3 S and a pair ( ~ 2 ,  
~ 2 )  
to S 3 S .  
Now, the suficiency is trivial, for restriction and aggregation are special 
cases of inclusion, which is a transitive relation since S 3 S and S 3 S 
implies S 3 S (choose U = U2U1, V = VlV2). 
The necessity proceeds constructively by assuming S 2 S and choosing 
K = [W V], where W = (I - VU)@, and J& 
is any basis matrix for 
{AlIm V} + {AIIm N }  n (Im v)'-. From 
[W V] = [@ V] [-;w ;] 
(8.57) 

430 
8. Overlapping Decompositions 
and UV = I ,  we see that K is monic and Im V1 = {AlIm V }  + {AIIm N } ,  
Ker U 2 Im W .  This fact guarantees the existence of W L  such that the 
choice 
u1= ["I:] 
(8.58) 
implies U1V1 = I .  
Now, let us show that A = UlAVl, B = UlB, and C = 6V1, so that 
S = (A, B, C) is a restriction of S = (A, B, 
C) to Im 6. We first note 
that Im 6 is A invariant and 
A = KAUl + M I ,  
(8.59) 
where MI = A - KAU1 and MIK = AVl - VIA = ( I  - VIUl)AVl = 0. We 
also note that Im B c Im V + Im N c Im V1, which implies 
B = & B +  N1, 
(8.60) 
where N1 = B - V B  = ( I  - KU1)B = 0. We then conclude that 
c = C U l +  L1, 
(8.61) 
where L1 = c - CU1 and L1K = c ( I  - VlU1)K = 0, proving S is a 
restriction of S to Im Vl by Theorem 8.3. 
To show that S = (A, B, C) is an aggregation of S = (A, B, C), we 
choose V, = [0 IIT and U2 = [0 I ] .  Since U k V  = (UjV)i = Ai and 
Ker U 3 {AlIm N } ,  we can show that Ker [UA(I - VU)] 3 {AlIm V }  + 
{AIIm N } ,  which together with {AIIm N }  + {A(Im N }  3 Im W implies 
UAW = U $ I -  VU)r/i/ = 0. Then, we observe that 
A = V,AU2 + M2, 
(8.62) 
where M2 = A - V,AU2 and U2M2 = UA[W V ]  - AIO I ]  = 0. We have 
B = V,B + N2, 
(8.63) 
where Nz = B - QB, and the inclusion relation U B  = B implies U2N2 = 0. 
Finally, from the inclusion relation Ker L 3 {AIIm V }  + {AlIm N }  3 
Im V1 and Ker U 3 Im W ,  we see that 
C = cu2 + L2, 
(8.64) 
and L2 = C - CU2 = (CU + L)[W V ]  - CIO I ]  = 0 which, in turn, implies 
that S is an aggregation of S to Im UF. 
Q.E.D. 

8.2. The Inclusion Principle 
431 
The construction procedure of finding first a restriction (aggregation) 
and then an aggregation (restriction) to get a suitable contraction implies 
that whenever S 2 S ,  the system can be represented in the canonical form 
* 
S: i =  [% f] 5+ 
y = [ O  c *]5, 
* 
B ]  u, 
0 
(8.65) 
using an appropriate coordinate frame. Comparing the canonical form with 
the two previous representations (8.48) and (8.51), we conclude that con- 
tractions arise naturally as “intersections” of restrictions and aggregations. 
This fact is expressed in algebraic terms by the following corollary to The- 
orem 8.5: 
8.6. COROLLARY. S II S if and only if M = M I +  M2 such that 
M1V = 0, 
MiN = 0, 
UM2 = 0, 
LM2 = 0, 
Mi M2 = 0, 
U N  = 0, 
LV = 0, 
LN = 0. 
(8.66) 
Proof Assume S II S, so that by Theorem 8.5 we have U = U1U2 and 
V = KG, that is, S is an aggregation of S and S is a restriction of S. It 
follows that 
A = &AU1+ M, 
c = cu, i- 
L, 
and 
A = KAU2 + M2, 
U2N = 0, 
MV1 = 0, 
B = VlB, 
(8.67) 
Ev, = 0, 
U2M2 = 0, 
B = & B + N ,  
(8.68) 
c = cuz. 
Defining MI = GMU2, and L = LU2, and substituting (8.67) into (8.68), 
we conclude that (8.66) holds. 
The sufficiency follows by the substitution of M = M I +  M2 into (8.52) 
and using (8.66). 
Q.E.D. 

432 
8. Overlapping Decompositions 
Stability in the context of inclusion is obvious from the canonical form 
(8.65): eigenvalues of the matrix A must at the same time be the eigenvalues 
of the matrix 2. 
This fact means that stability of S implies stability of S 
if S 3 S .  The rest of the eigenvalues can be obtained from the following: 
8.7. THEOREM. If S II S, then 
..(A) = n ( ~ ) n ( U ~ V ) ,  
(8.69) 
where n(*) denotes the characteristic polynomial, V is any basis matrix 
for Ker U ,  and U is the unique left inverse of $' such that Ker U = Im V .  
Proof. Define a nonsingular matrix T = [V V ]  and form 
A 
UMV 
UMV UMV 
PAT= [ 
] , 
(8.70) 
where T-l = [ r] . Then, 
det(X1- A) = det(XI - A )  det[XI - UMV - UMV(A1- A)-'UM$'] 
= det(X1- A )  det(XI - 6 M V )  
x det[I - UMV(XI - UMV)-'UMV(XI - A)-']. (8.71) 
But, 
i=O 
(8.72) 
Q.E.D. 
is implied by VU = ( I  - V U )  and UMiV = 0, i E n. 
Finally, we turn our attention to the problem of feedback control in 
the framework of inclusion. Referring back to the expanded system S in 
(8.3), we see that it is in an input-decentralized form. We can use the 
standard decentralized control strategies of Chapter 2 to stabilize S, then 
contract the obtained control law, and implement it in the original system 
S. Alternatively, a model reduction scheme can be used to simplify the 

8.2. The Inclusion Principle 
433 
design of feedback (Skelton, 1988). Then, the control law resulting from a 
reduced order model S must be expanded for implementation in the original 
system S (Sezer and Siljak, 1982). 
We relate the two systems S and S under constant feedback 
- 
u = -Kx + V ,  
u = -K2 + V ,  
(8.73) 
where v E U is a reference input. We assume that the m x fi gain matrix 
K has the form 
K = K u + F ,  
(8.74) 
and define the closed-loop system matrices as 
AF = A - B K ,  
AF = A - BK. 
(8.75) 
The constraints on the feedback complementary matrix F guaranteeing 
that SF = (&, B, 6) includes SF = (AF, B, C )  under any choice of 
feedback gain matrix K are given by the following: 
8.8. THEOREM. SF 3 SF for any feedback gain matrices and for monic 
B if and only if (8.66) holds and 
FV=O, 
FM2=0, 
FN=O. 
Proof. By Theorem 8.4, SF 2 SF is equivalent to 
UMkV = 0, 
UMi-'N = 0, 
LMb-'V = 0, 
for all i E ii, where n = dim 2 and 
MF = M - V B F  - NKU - NF. 
(8.76) 
LM;-'N = 0, 
(8.77) 
(8.78) 
Substituting this expression of MF into (8.77) and noting that B is monic, 
we get the requirements 
F M ~ - ~ V  
= 0, 
FM~-" 
= 0, 
(8.79) 
for all i E n. Now, note that by Corollary 8.6, (8.52) must be equivalent to 
(8.66). Since the requirements (8.79) for F and (8.52) for L are identical, 
we establish (8.76) by Corollary 8.6. 
Q.E.D. 

434 
8. Overlapping Decompositions 
Because the inclusion concept involves singular transformations, the 
systems S and S are not algebraically equivalent. On the other hand, they 
are “pseudo-equivalent.” That is, from Definition 8.2, we see that for all 
fixed inputs u(t) and any initial state 20 of S, there is (at least) one equiv- 
alent initial state 20 of S resulting in identical outputs y[2(t)] and &(t)]. 
An opposite statement is generally not true. 
When we compare the external behavior of the two systems initially at 
rest, then a complete zero-state equivalence can be established whereby two 
systems S and S are considered equivalent if their input-output behavior 
is identical whenever they start at their zero states. We denote the transfer 
functions of S and S by 
G(s) = C ( s 1 -  A)-lB, 
G ( s )  = C ( s 1 -  A)-lB, 
(8.80) 
and prove: 
8.9. THEOREM. If S 3 S, then 
G ( s )  = G(s). 
Proof. The relations 
(8.81) 
- -. - 
CAiB = CA’B, 
i = 0, 1, 2, . . . , 
(8.82) 
Q.E.D. 
in the inclusion condition (8.53) are equivalent to (8.81). 
Condition (8.81), however, does not imply S 3 S. For this we need the 
following: 
8.10. THEOREM. Two systems 
S: 2=A3:+Bu, 
- 
y = c2, 
(8.38) 
with dim X = ii, 
and 
s: k=Aa:+Bu, 
(8.83) 
y = ca:, 
with dim X = fi, are zero-state equivalent if and only if they have a common 
contraction S. 

8.2. The Inclusion Principle 
435 
Proof. We have already established the suficiency by definition of in- 
clusion, for if S and S have a common contraction S ,  then it is obvious 
that they are realizations of the same transfer function. 
To show necessity, we assume that S and S have the same transfer 
function G(s), and S is a minimal realization of G(s). Then, from the 
observability and controllability matrices of S and S, we define the matrices 
T =  
(8.84) 
W = [ B  AB A2B ... Ai"-lB], 
W = [ B  &j 
A 2 B  ... AiL-lB]. 
From relation (8.82), which is necessary and sufficient for zero-state equiv- 
alence, we get 
TAiW = F k W ,  
i = 0, 1, 2, . . . . 
(8.85) 
By the assumption of minimality of S ,  we know that T is epic and W 
is monic, so that the left inverse TL of T and the right inverse W R  of W 
both exist. From (8.85) for i = 0, we see that if V = WWR, then U = T L f  
is a left inverse of V. Then, from (8.85), we further obtain 
U
~
V
 
= ~
i
,
 u
~
B
 
= A ~ B ,  CZv = C A ~ ,  
(8.86) 
for all i = 0, 1, 2, . . . . Noting that these conditions together with (8.82) 
are equivalent to the inclusion condition (8.53), we conclude that S 3 S .  
Similarly, we can show that S 3 S if S is a realization of G(s), that is, S 
and S are zero-state equivalent. 
Q.E.D. 
It is now appropriate to give a general interpretation of overlapping 
decompositions introduced in Section 8.2. When we partition the state 
vector x E R" of the system 
S: f = A x + B u ,  
(8.37) 
y = c x ,  

436 
8. Overlapping Decompositions 
as x = (x:, xif, . . . , x ; ) ~ ,  
we induce a disjoint decomposition of the ma- 
trices A, B, C as 
A =  
c= [C, c2 
... C,], 
BN "I 
(8.87) 
and S can be represented as an interconnection of N subsystems: 
(8.88) 
N 
y = C Cixi, 
i E N. 
i=l 
State trajectories of S are regarded as projections of the solution x(t; 2 0 ,  u) 
on the subspaces Xi, i E N, such that 
x = Xl @ x2 @ . . . @ x,, 
(8.89) 
that is, X is the direct sum of the subspaces Xi. These subspaces are 
uniquely specified by the partitioning of x. Conversely, a specification of 
subspaces corresponds uniquely to a partitioning of the state vector x. 
Now we introduce a partitioning of X as 
x = x, + x2 + * * .  + x,, 
(8.90) 
where X is an ordinary sum of the subspaces Xi, which are not necessarily 
disjoint. Hence, this partitioning cannot be associated with the standard 
disjoint partitioning of the state x. In order to achieve a disjoint decom- 
position, we have to LLexpand" the space X .  With each Xi in (8.90), we 
associate a mapping v: 
X 4 Xi, i E N, and construct an expansion map 
V X 4 X, 
where dim X = 
V:] , which 
is necessarily monic. The underlying decomposition of the space 2 of S is 
N 
T 
dim Xi, as V = [VT KT 
2 = 21 @ 
@ . . . @ 2,, 
(8.91) 

8.3. Optimization 
437 
which is a direct sum of subspaces X i .  It is essential that Xi N Xi, which 
means that the identity of the subsystems is preserved in the expansion 
S; compare (8.2) with (8.3), or (8.5) with (8.12). In this way, we obtain 
a direct sum of subspaces from an ordinary sum preserving isomorphism 
of subspaces, yet allowing for standard disjoint methods to be used for 
the study of overlapping decompositions. The expansion S has the same 
disjoint form as S in (8.88): 
N 
(8.92) 
N 
y =x 
(?iZi, 
i E N. 
i=l 
Now, a control design can be performed in X by using standard methods for 
disjoint decompositions. Then, the resulting control law can be contracted 
to X for implementation in the original system S. 
Finally, we should note that if we want to get, in (8.92), the subsystems 
with independent inputs u i  and outputs yi instead of u and y, we have to 
expand the input and output spaces as well (Ikeda and Siljak, 1986; Iftar, 
1988; Iftar and Ozgiiner, 1990). This additional effort is not necessary if the 
system is input and output decentralized to start with (see Example 8.22). 
8.3. Optimization 
To address optimization problems in the context of overlapping decom- 
positions, we need to define expansions and contractions of performance in- 
dices. We will do this for linear systems with a separable quadratic criterion 
related to overlapping subsystems. Decentralized controllers are designed 
to be locally optimal in the expanded space when the interconnections are 
ignored. Then, the obtained control laws are contracted for implementation 
in the original system. Suboptimality of the decentralized controllers is de- 
termined with respect to the decoupled optimal system as reference (see 
Section 3.1). Most importantly, we can show that, under relatively mild 
conditions, suboptimality implies and is implied by stability of the overall 
closed-loop system. 
We assume that in linear system 
S j.=Ax+Bu, 
(8.37') 

438 
8. Overlapping Decompositions 
we can measure the whole state, and consider the performance index 
m 
J(z0, u) = 1 (xTQx + uTRu) dt, 
(8.93) 
where Q is a nonnegative definite matrix and R is a positive definite matrix. 
With the pair (S, J )  , we associate another pair (g, J ) ,  where 
s: i = A Z + B u ,  
(8.38') 
and 
03 
J(Z.0, u) = 
(ZTQZ + uTRu) dt, 
(8.94) 
with Q being a nonnegative definite matrix. 
8.11. 
We say that a pair (S, J )  includes a pair (S, J )  if 
there exists a pair of matrices (U, V )  such that UV = I and for any initial 
state zo of S and any fixed input u(t), we have 
DEFINITION. 
z(t; 2 0 ,  u) = UZ(t; VZO, u), 
vt 2 0, 
(8.95a) 
(8.95b) 
J(z0, u) = J ( V X 0 ,  u). 
This definition was introduced in (Ikeda et al. 1981a) to establish an o p  
timal control problem (S, J )  in the expanded space that provides a solution 
to the original problem (S, J ) .  If we define the relations 
A = V A U + M ,  
Q = UTQU + MQ, 
B = V B  + N ,  
R = R + N ~ ,  
(8.96) 
where we assume that UV = I ,  then inclusion conditions for (8, J )  and 
(S, J )  are formulated as follows: 
8.12. THEOREM. (S, j) 
3 (S, J )  if either 
(i) 
MV = 0, 
N = 0, 
P M Q V  = 0, 
NR = 0, 
(8.97) 
or 
(ii) 
UMiV = 0, 
MQMi-lN = 0, 
MQM~-'V = 0, 
(8.98) 
UMi-' N = 0, 
NR = 0, 
Vi E n. 

8.3. Optimization 
439 
Prooj We first prove part (2). From the proof of Theorem 8.3, we have 
the first two relations in (8.97), which establish (8.40) and then (8.95a). 
Equation (8.95b) follows from 
ZT(t; VZO, 
u)Q3(t; V X O ,  
U )  = zT(t; 
20, u)Qx(t; 
ZO, u), 
U ~ R U  
= u ~ R u ,  
(8.99) 
which is implied by (8.40) and the rest of part (if. 
To prove part (ii), we note first that (8.95a) is implied by the first 
two Equations of (8.98)see Theorem 8.4. Equation (8.95b) follows from 
(8.99), which is implied by (8.95a), NR = 0, and 
Mg2(t; vzo, u) = 0, 
vt 2 0, 
(8.100) 
for any fixed u(t). This equation follows from MQMZ-'N = 0 and 
MQMi-'N = O for all i E n. 
Q.E.D. 
Parts (i) and (ii) of Theorem 8.12 are independent of each other. They 
are two different sets of conditions for (S, 6) to be an expansion of ( S ,  J ) ,  
that is, for ( S ,  J )  to be a contraction of (S, 6). 
Our basic intention is to choose a linear feedback law 
u = -Kx, 
(8.101) 
and to optimize ( S ,  J )  by choosing appropriately a control law 
- 
u = -K3 
(8.102) 
that optimizes (8, 6) in the expanded space. To do this, we need conditions 
under which the control - K 3  is contractible to -Kx, 
that is, 
Kz(t; 20, 
U )  = K2(t; VZO, u), 
Vt 2 0, 
(8.103) 
for any fixed input u(t). From the proof of Theorem 8.8, we have the fol- 
lowing: 
8.13. 
law -Kx if and only if 
COROLLARY. A control law -K2 is contractible to the control 
FM~-'V = 0, 
F M ~ - ' N  = 0, 
Vi E n. 
(8.104) 
It is important to note that testing of contractibility conditions (8.104) 
can be avoided if S is a restriction of S (Theorem 8.3). 

440 
8. Overlapping Decompositions 
8.14. COROLLARY. If 
M V = 0 ,  
N = 0 ,  
(8.105) 
then any control law - K 2  is contractible to the control law -Kx, 
and 
K = KV. 
(8.106) 
8.15. EXAMPLE. To make transparent the announced control strategy 
involving overlapping decompositions, let us reconsider the system S of 
(8.4) and its expansion S of (8.8) when control is present and a quadratic 
optimization is desired. We start from 
. 
(8.107) 
By choosing V, U ,  and M as in (8.7), (&lo), and (8.11), and N = 0, we 
get 
All 
A12 \ 
0 
A13 
B11 i Bl2 
s: 
A21 
0 1 A22 
A23 
I 
I 
A31 
0 
i A32 
A33 
-B31 
B32 
(8.108) 
Now, S can be represented as two interconnected disjoint subsystems 
where 
A22 
A23 
" = [ t:: t::] ' 
A -  
2 -  [ A32 
A331 ' 
(8.110) 

8.3. Optimization 
441 
are matrices corresponding to the two (decoupled) subsystems 
and 
(8.11 1) 
(8.112) 
are the interconnection matrices. For control purposes, with subsystems S 1  
and S 2  we associate performance indices 
(8.113) 
where 510 and 5.20 are the initial states of S 1  and S 2 ,  and Q1, Rl, Q 2 ,  R 2  
are appropriate matrices. This choice of local indices is consistent with our 
assumption that subsystems are physical units whose autonomy is desirable 
(see Section 3.1). Then, the joint performance index for the overall system 
S is simply 
&(50, U )  = 1 ( Z T Q ~ 5  + U'RDU) dt, 
(8.114) 
diag(Q1, Q 2 }  and RD = diag(k1, &}. By part (i) of Thee 
m 
where QD 
rem 8.12, J is an expansion of 
(8.115) 
when QD = V T Q ~ V  
and RD = RD, and JD is a performance index for the 
original system S .  
A decentralized control law 

442 
8. Overlapping Decompositions 
can now be chosen to optimize the individual overlapping subsystems S 1  
and 8 2  with respect to the indices & and & because they appear in S as 
disjoint. The resulting gain matrix is block diagonal: 
(8.117) 
where 
(8.118) 
and PI, P 2  are solutions of the corresponding Riccati equations. The de- 
centralized control law 
K - - - l - T -  
K 1  = R , ’ B T P l ,  
2 - R2 B2 P2, 
uo 
D - 
- -KDZ 
- 
(8.119) 
is suboptimal with respect to (8, L?D). 
Finally, to get an overlapping decentralized control law 
ti: 
= - KDX 
(8.120) 
of - the same quality for implementation in the original system S, we rewrite 
(8.121) 
to conform with representation (8.108) of S. By using Corollary 8.14, we 
contract r ? ~  
of (8.121) to get the gain matrix 
(8.122) 
for the overlapping decentralized control law (8.120). 
The basic reason 
for expanding a pair (S, JD) into (8, JD) is that the concept of suboptimal- 
ity of Section 3.3 can be directly applied to the pair (8, JD): the overlapping 
subsystems of S appear as disjoint in S. Since the suboptimality index 
is defined for (8, j~), 
it is important to note that the contracted control 
law (8.119) with KD of (8.122) is suboptimal for the pair (S, JD) with the 
same degree of suboptimality ji, where JD is a contraction of j ~ .  
That is, 
the inequality 
(8.123) 
--I -a 
$(Zo) 5 p 
J D ( Z o )  
implies (but is not implied by) the inequality 
(8.124) 
--1 
a 
J,”(xo) 5 p JD(xo), 

8.3. Optimization 
443 
0
1
 
---!-----!I [ ::] 
+ 
-20 
1 
-24 
1 
where JE(z0) denotes the value of JD(ZO, 
u) for S under the control law 
(8.120), which is equal to JE(Vzo), and 
2 :  0 
01 0 [::I 
. 
(8.127) 
- 0 i  2- 
J,”(zo) = J,o(VZO). 
(8.125) 
To illustrate further some of the issues discussed in this example, let us 
consider a numerical version of S in (8.107) g‘ iven as 
1 -24 i 1 
2 j  0 
o i  2 
where the subsystems are indicated by the dashed lines. The expansion of 
With S , we associate a “decentralized” performance index 
The optimization problem (S, JD) was solved in Example 3.20 as a 
disjoint decomposition problem, and a suboptimality index 
fi* = 0.95 
(8.129) 
was achieved for (S, j ~ )  
and, thus, for (S, JD). The decentralized con- 
trol law, calculated by local optimization procedure, was found to be also 
stabilizing. 
8.16. 
In the above example, we used Corollary 8.14 to con- 
struct a contractible control law. When the expansion S is generated using 
part (ii) of Theorem 8.12, not every control law for S is contractible for S .  
A class of contractible laws is defined when 
REMARK. 
U M = 0 ,  
UN=O. 
(8.130) 

444 
8. Overlapping Decompositions 
Then, if KD satisfies the condition 
K D  = KDVu, 
(8.131) 
the control law -KDZ is contractible to -KDX with KD defined in (8.106), 
that is, KO = KDV. 
8.17. EXAMPLE. In the so-called particular case (Ikeda et al. 1981a), 
when the overlapping part in S is not asymptotically stable, S is not asymp 
totically stable even if S is. For instance, if 
then, choosing V, U ,  and M as in Section 8.2, we obtain 
Due to a special structure of the matrices, the expansion S can never be 
stabilized by state feedback; the corresponding closed-loop system matrix 
would always have two identical rows resulting in a fixed zero eigenvalue. 
For this reason, the corresponding matrix H would not exist causing sub- 
optimality to fail. 
To recover suboptimality (and asymptotic stability) in particular cases, 
we have to contract the control and test suboptimality of the closed-loop 
system in the original space. Of course, a contraction requires an additional 
effort that is not required in the standard case. 
Let us assume that a particular case results in a decomposition 
N 
N 
3: &Ai&+BilLi+C A..Z.+C 
2.7 
3 
B-.u. 
z3 3 ,  
i E N, (8.134) 
j = 1  
j=1 
where 2(t) E R' and u(t) E R" are the state and input of S at t E R. A*, 
A i j ,  Bi, Bij are constant matrices of appropriate dimensions. A compact 

8.3. Optimization 
445 
representation of S is 
9: k = A D Z  + B D U  + ACZ + B C U ,  
(8.135) 
which is the standard form adapted for S in (3.57). Following the develop 
ment of Section 3.2, we associate with S a performance index 
A decentralized control 
'ug = -KDZ, 
is provided by optimizing JD with respect to 
(8.136) 
(8.137) 
We get ' 
(8.139) 
(8.140) 
By contracting the control law ug of (8.137) and implementing it in the 
S X = A x + B u , 
(8.37') 
- 1 - T -  
KD = R, BDPD, 
AEPD + F D A D  - PDBDRs'BgPD + Q D  = 0. 
where 
original system 
we get the closed-loop system 
S: X = A x ,  
(8.141) 
A = A  - B K ~ ,  K~ = KDv, 
(8.142) 
where 
and the contracted performance index is computed as 
where 
00 
H = 1 exp(ATt) GD exp(At) dt, 
GD = QD + K ~ R D K D ,  
(8.144) 
QD = VTQDv, 
I 
RD = RD. 

446 
8. Overlapping Decompositions 
Now, we use the notation 
J,(XO) = Jg(vxo), 
and state the following (Ikeda et al. 1981a): 
8.18. DEFINITION. We say that a control law 
(8.145) 
(8.146) 
is suboptimal for the pair (S, J D )  if there exists a positive number p such 
that 
J,”(Xo) 5 p -1 J ~ ( x o ) ,  
0 
VZo E R”. 
(8.147) 
Imitating Theorem 3.18 of Section 3.2, we arrive at the following result: 
8.19. THEOREM. 
suboptimality 
A control law ug is suboptimal with the degree of 
p* = x $ [ H ( V T ~ ~ V ) - l ]  
(8.148) 
for the pair (S, JD) if and only if the matrix H is finite. 
Proof. We note that the matrix V T P ~ V  
is positive definite because 
V is monic (full column rank). Then, using the argument of the proof of 
Theorem 3.3, we establish (8.148). 
Q.E.D. 
8.20. REMARK. The number p* computed by Theorem 8.19 is the 
largest (best) for which (8.147) is satisfied. If A is stable, the matrix H 
can be computed from the Liapunov equation 
ATH + H A  = -Go, 
(8.149) 
and p* is obtained using (8.148). This means that stability implies subop 
timality. The converse result can be established as in Theorem 3.4 if we 
assume that (A, GX2) is observable. 
So far, the reference system for suboptimality was a collection of optimal 
decoupled subsystems. This choice is justified when complete autonomy of 
each subsystem is regarded as an ideal situation. Alternatively, we may 
be interested in comparing the performance of a locally optimal strategy 

0.3. Optimization 
447 
with the centrally optimal system, which is the best one can achieve by LQ 
control. 
Let us consider again the system 
S: x = Ax + Bu, 
with the performance index 
M 
JD(XO, 
u) = 1 ( X ~ Q D X  + U ~ R D U )  
dt. 
(8.37') 
(8.93') 
We assume that the pair (A, B )  is controllable and the pair (A, QX') is 
observable. The optimal control is 
U@ = -RE'B~PX, 
(8.150) 
resulting in the value of the performance index given as 
P ( X 0 )  = x;pxo, 
(8.151) 
where P is the symmetric positive definite solution of the Riccati equation 
ATP+PA- P B R i ' B T P + Q ~  10. 
(8.152) 
If instead of the centrally optimal control u", 
we use the locally optimal 
control from the expanded space, 
uo 
D - 
- -&!,'B;PDVx, 
(8.146) 
suboptimality can be evaluated by computing Jg(x0) defined by (8.143) 
and comparing the obtained value with that of J0(xo) defined by (8.151). 
A positive number p, such that the inequality 
J @  
D (  0) < 
- p 
--I 
@ (xo) 
(8.153) 
holds for all XO, is the suboptimality index. Obviously, p exists if H of 
(8.144) is finite. In this case, the largest number ji* for which inequality 
(8.153) is satisfied can be calculated as 
p* = A-1 
M ( Hp-1 1 1  
(8.154) 
which is a similar expression to that of p* in (8.148). 
8.21. 
The similarity of p* and p' implies that once subopti- 
mality of a control law is established with respect to one reference system, 
it is suboptimal with respect to another provided the corresponding ob- 
servability conditions are satisfied. The degree of suboptimality is of course 
REMARK. 

448 
8. Overlapping Decompositions 
different in general, involving different computations as well. For example, 
to get ji*, we have to compute the centrally optimal control, which may 
be unattractive due to a dimensionality problem. It is usually simpler to 
work with p*, because only optimization of subsystems is required (see 
Section 3.2). 
To illustrate the application of overlapping decentralized control, we 
consider the problem of Automatic Generation Control (AGC). 
8.22. EXAMPLE. Because of the size and complexity of present-day 
power systems, decentralized control schemes for AGC are more attractive 
than alternative centralized designs. The main reason is an excessive in- 
formation requirement imposed by a globally optimal AGC. This has been 
a prime motivation for building AGC schemes of the decentralized type, 
where control is confined to individual power areas employing the standard 
tie-line bias control concept and noninteraction principle, which preserve 
the steady-state area autonomy and economy of operation (CaloviC: et al. 
1978; Siljak, 1978). In this kind of control scheme, the areas are represented 
as overlapping subsystems with the tie-lines being the overlapping parts. 
Let us consider a two-area model described in (CaloviC: et al. 1978) by 
the equation 
+ 
+ 
f l i  0 -  
o i o  
o i o  
0 : o  
I 
:----- 
_____I 
I 
1 
0 b 2 -  
, 
(8.155) 
where the dashed lines identify the two areas; Ax, and Ax2 are the devi- 
ations of states from their nominal values; Av1 and Avz are the variables 
introduced to achieve the integral control; and Ape is the variation of the 
total power exchange between the areas. In (8.155), 211 and '112 are scalar 

8.3. Optimization 
449 
inputs, and z1 and z2 are unmeasurable disturbances. The matrices and 
vectors indicated in (8.155) are numerically specified as follows: 
--0.2 
0 
0 
0 
0 
0 
0 
-4 
4.75 -5 
0 
0 
0 
0
0
 
0 
0 
0.1667 -0.1667 
0 
0 
0
0
 
0 
0
0
 2 
-2 
0 
0
0
 
0 
0 
-0.08 
-0.0747 -0.112 -3.994 
10 -0.928 
-9.1011 
0
0
 0 
0 
0.2 
-0.5 
0 
0 
0
0
 0 
0 
1.3194 
0 -1.3889 -0.2778 
0 
0.01 
0.0093 0.014 -0.0632 
0 
0.1160 -01124 
Az = 
--0.2 
0 
0 
0 
0 
0 
0 
-4 
4.75 -5 
0 
0 
0 
0
0
 
0 
0 
0.1667 -0.1667 
0 
0 
0
0
 
0 
0
0
 2 
-2 
0 
0
0
 
0 
0 
-0.1 
-0.0933 -0.14 
-4.096 
10 -0.7442 -9.107 
0
0
 0 
0 
0.2 
-0.5 
0 
0 
0
0
 0 
0 
1.3194 
0 -1.3889 -0.277 
0 
0.0125 0.0117 0.0175 -0.0506 
0 
0.0928 -0.111 
1 
at1 = at2 = [0, 0, 0, 0, 0.6667, 0, 0, -0.0833IT, 
4 = dif = [O, 0, 0, 0, 0, 0, 0, 101, 
bz = [2, 0, 0, 0, 5, 0, 0, 0IT, 
fl = Ql, 
fz = atz. 
mTz = mf1 = [0, 0, 0, 0, 0, 0, 0, 22.21441, 
bl = [1.6, 0, 0, 0, 6, 0, 0, OIT, 
(8.156) 

450 
8. Overlapping Decompositions 
To achieve autonomy of each power area, we use the performance indices 
= 
[AzTQIAzI + lO(Aw1)' + l0(Ape)' + ~ ' 4 1  dt, 
(8.157) 
where 
Q1 = QZ = diag(1, 1, 1, 1, 1, 1, 1, 10). 
(8.158) 
This is equivalent to associating the performance indices 51 and J 2  with 
the (decoupled) overlapping subsystems delineated by the dashed lines in 
(8.155). 
By following the optimization procedure presented in the preceding sec- 
tion, we expand S, optimize the decoupled subsystems, calculate the local 
feedback gains, and contract the block diagonal gain matrix to get the 
overlapping decentralized control law 
where 
kTl = [1.353, 0.31, 2.47, 0.597, 0.75, 0.021, 6.56, 89.921, 
k z  = [1.631, 0.406, 3.019, 0.792, 0.551, -0.63, 5.501, 94.841, 
(8.160) 
The degree of suboptimality p* is computed, using (8.148), as 
p* = 0.376. 
(8.161) 

8.3. Optimization 
451 
0.00 
-0.02 
-0.04 
-0.06 
I
I
I
I
 
- 
SUBOPTIMAL 
- 
0 
10 
20 
30 
TIME (SEC.) 
Fig. 8.2. Frequency deviation in Area 1. 
When the centrally optimal system is chosen as reference, the degree of 
suboptimality is computed as 
ji* = 0.820. 
(8.162) 
The control law ug of (8.159) is also stabilizing. This follows from the 
fact that &I and Q2 of (8.158) and the rest of the terms in 51 and J2 of 
(8.157), which correspond to the states of S, are all positive definite. 
Finally, we present the results of simulation in Figures 8.2-4, where 
responses to the unit-step disturbance 
(8.163) 
of the frequency deviations Af1 and Af2 (the eighth element of Ax, and 
Ax2, respectively) and the power exchange Ape are shown. Both the cen- 
tralized optimal control with global information and the decentralized sub- 
optimal control with overlapping information sets are represented for com- 
parison. The centralized control produces smoother and somewhat faster 

452 
8. Overlapping Decompositions 
0.00 
-0.02 
-0.04 
-0.06 
-0.08 0 
10 
20 
30 
TIME (SEC.) 
Fig. 8.3. Frequency deviation in Area 2. 
responses, but the overlapping decentralized control should be judged sat- 
isfactory to the extent of distinctly weaker information structure require- 
ments. 
8.4. Nonlinear Systems 
The inclusion concept can be generalized to nonlinear systems with 
similar benefits, but with more constraints than in the linear case. Special 
care has to be taken of the equilibrium states, and inclusion conditions 
are only sufficient. For simplicity, we consider systems with no inputs or 
outputs. 
Let us consider two dynamic systems 
s: j. = f ( t ,  z), 
and 
s: ii = f ( t ,  5), 
(8.164) 
(8.165) 

8.4. Nonlinear Systems 
453 
I
l
l
,
 
I
,
,
,
 
2 
0 
5 
,
,
I
1
 
0.0 
-0.2 
-0.4 
-0.6 
-0.8 
TIME (SEC.) 
Fig. 8.4. Tie-line power deviation. 
where z(t) E R" and d ( t )  E R' are the states of S and S at t E R, and 
n 5 6. The functions f: R x R" -+ 
R" and $: R x R' -+ R' are assumed 
to be sufficiently smooth, so that solutions z(t; to, 20) and Z(t; to, do) of S 
and S exist and are unique for all initial conditions (to, zo) E R x R" and 
(to, 20) E R x R", and all t E To = [to, +co). 
We use linear transformations 
z=vx, 
z = U d ,  
(8.166) 
where V is an ii x n constant matrix with full column rank and U is an 
n x ii constant matrix with full row rank. The inclusion concept is stated 
as follows: 
8.23. DEFINITION. S 3 S if there exists an ordered pair of matrices 
(U, V) such that UV = I ,  and for any (to, zo) E R x R", do = Vzo implies 
z(t; t o ,  $0) = U3(t; to, VZO), 
Vt E To. 
(8.167) 

454 
8. Overlapping Decompositions 
To derive conditions for inclusion, we represent the function f(t, 5) as 
J(t, 5) = Vf(t, 
U 5 )  + &(t, 5), 
(8.168) 
where m :  
include S, m is required to satisfy certain restrictions as in the following: 
R x R" -+ 
R" is called a complementary function. For S to 
8.24. THEOREM. S 2 S if either 
m(t, v x )  = 0, 
U k ( t ,  5) = 0, 
V(t, x) E R x R", 
V(t, 5) E R x R". 
(8.169) 
(8.170) 
or 
Proof. We first prove S 3 S if (8.169) holds. Combining (8.168) and 
(8.169), we get 
i - Vk = V[f(t, 
U 5 )  - f(t, z)] + &(t, 5). 
(8.171) 
It is easy to see that 5 - Vx = 0 is the trivial solution of (8.171). This 
means that 50 = Vxo implies 
5(t; t o ,  50) = Vx(t; 
to, ZO), 
Vt E To, 
(8.172) 
which, in turn, implies that (8.167) holds. 
To prove S 2 S if (8.170) holds, we use (8.168) and (8.169) to get 
ui - k = f(t, V5) - f(t, x). 
(8.173) 
Obviously, the trivial solution of this equation is U 5  - x = 0 and, therefore, 
50 = Vxo implies (8.167). 
Q.E.D. 
8.25. 
The two conditions of Theorem 8.24 are two indepen- 
dent conditions. They correspond to restriction and aggregation in linear 
systems (Theorem 8.3). 
REMARK. 
We turn our attention to stability properties of the two systems S and 
S. Obviously, if S 3 S then stability of S implies stability of S. Unlike 
linear systems, this statement can be used only if the equilibrium of S is 
preserved in S under the linear transformation (8.166). More precisely, if 
f(t, 2,) = 0, 
Vt E R, 
(8.174) 

8.4. Nonlinear Systems 
455 
and 2, is an equilibrium of S ,  then we require that 
f ( t ,  Vx,) = 0, 
Vt E R, 
(8.175) 
so that 2, = Vx, is the corresponding equilibrium of S .  It is easy to see 
that this takes place if and only if 
k ( t ,  VS,) = 0, 
Vt E R. 
(8.176) 
This condition is implied by the inclusion condition (8.169) of Theorem 8.24, 
but is not implied by condition (8.170). 
Stability is resolved by the following: 
8.26. 
equilibrium 2, of S implies stability of the equilibrium x, of S .  
THEOREM. Suppose S 3 S and 2, = Vz,. Then, stability of the 
ProoJ We prove the theorem with respect to global asymptotic stability 
in the sense of Liapunov, which is stated here for an easy reference in the 
proof of the theorem. 
An equilibrium z, of S is globally asymptotically stable if the following 
two conditions hold: 
(i) It is stable, that is, for any initial time to E R and positive number 
E ,  there exists a positive number 6(t0, E) such that 11x0 - x,11 5 6 implies 
and 
(ii) It is attractive in the large, that is, 
lim x(t; to, zo) = z,, 
V(t0, zo) E R x R". 
(8.178) 
When 2, = Vz, is stable in the sense of (i) above, then, for any to and 
t++m 
El > 0, there exists a d(t0, El) > 0 such that 1120 - Vz,II 5 d implies 
IlZ(t; to, 20) - VZ,II 5 El, 
Vt E To. 
(8.179) 
To prove stability (i) of the equilibrium x, of S ,  we note that for any 
E > 0 we can choose 6 = 11 VII -Id, where d = d(t0, El) and El = 11 UII -'c. Then, 
11 zo - x,II 5 6 implies 1) Vxo - Vz,II 5 d. Therefore, 11 2(t; to, Vzo) - Vz,II 5 
El, and Ilx(t; to, 50) - z,11 5 I)UI( Il2(t; to, Vzo) - Vz,II 5 E for all t E TO, 
which implies stability of z,. 

456 
8. Overlapping Decompositions 
The global attractivity (ii) of x, follows directly from the global attrac- 
tivity of Z, = Vz, and the relation x(t; to, zo)-x, = U[a(t; to, VZO) -Vx,]. 
Therefore, if the equilibrium 5, = Vz, of the expansion S is globally asymp 
totically stable, then the equilibrium x, of S is likewise globally asymptot- 
ically stable. 
Q.E.D. 
The above proof can easily be modified to accommodate other types 
of stability in the sense of Liapunov. It should also be noted that the 
converse of Theorem 8.26 is not true in general. It has been shown (Ikeda 
and Siljak, 1980a) that the converse can be established for linear systems 
provided additional conditions hold (see Theorem 8.7). 
In Example 8.1, we applied the Inclusion Principle to show that in linear 
systems overlapping decompositions can be used to show stability where 
disjoint decompositions fail. Now, we show that the nonlinear version of 
the Principle can be utilized for the same purpose. The object is a Loth- 
Volteva model, which is a popular mathematical representation of multi- 
species communities in mathematical biology (e.g., May, 1974; Svirezhev 
and Logofet, 1983). 
Let us consider the Loth-Volterra equations in the vector form 
S: 2 = X ( a +  Ax), 
(8.180) 
where x = (51, 2 2 ,  . . . , x,)~ E R" is the state vector, X = diag(z1, 52, . . ., 
x"}, a E R" is a constant vector, and A = (aij) is an n x n constant matrix. 
The equilibria of the system (8.180) are given as solutions of the algebraic 
equation 
X ( a  + Ax) = 0. 
(8.181) 
If every principal minor of A is different from zero, then (8.181) has 2" 
solutions, which are not necessarily distinct. When it has a positive solution 
x,, the solution is unique and is given by x, = -A-'a. 
We assume the 
existence of the positive equilibrium x,, and consider the global asymptotic 
stability of this equilibrium with respect to the invariant region R: 
and 
t E To = [0, +cQ). 
In order to use the overlapping decompositions, we need an expansion 
of S defined as 
s: i = X ( 6  + AZ), 
(8.182) 
which contains the equilibrium x,. This takes place if the transformation 
matrix V of (8.166) is such that every row contains exactly one unit ele- 

8.4. Nonlinear Systems 
457 
ment. Moreover, 6 and A are given as 
ii=v~, A=VAU+M, 
(8.183) 
where M is an ii x ii constant matrix satisfying MV = 0. To see this, we 
compute from (8.168) 
m(5) = X ( 6  + AZ) - VX(Z)(u 
+ AUZ) 
(8.184) 
= [XV - VX(Z)](u + AUZ) + XMZ, 
and use the condition (8.169) of Theorem 8.24. In (8.184), X ( Z )  is an n x n 
diagonal matrix, which is obtained by substituting the relation x = UZ 
into the corresponding elements of X. 
We note here that once the overlapping parts of the system S are chosen 
as a result of either modeling or computational considerations, the exact 
form of the transformation matrix V is automatic (see Section 8.2). The 
matrix V has the characteristic required after Equation (8.182), which en- 
sures that the positive orthant R: 
of the state space of S is preserved in 
the positive orthant R$ of the state space of S .  This fact is essential, since 
we want to establish stability properties of S with respect to R: 
from the 
same properties of S with respect to R:. 
Let us assume that we have expanded a system S with overlapping 
subsystems into a system 
where the subsystems of S are now subsystems 
-
.
 
Si: Pi = Xi(& +AiZi), 
i E N, 
(8.186) 
which appear as disjoint subsystems of S .  The state &(t) E R: of S i  at 
t E R has the form Zi = {Zil, Zi2, . . . , Z i i ~ ~ ) ~ ,  
Xi = diag(Zi1, Zi2, . . . , Zii~,}, 
6i E RiLi, and &, Aij are matrices of the proper dimensions. We denote 
the positive equilibrium 3, of S as 2, = [(Z;)T, 
(Z;)*, 
. . . , (Z%)*IT, where 
Zf = (Zfl, Zf2, . . . , ZffiL)', which corresponds to the equilibrium x, of S via 
Z, = Vx,. 
From 6 + AZ., = 0, which implies 
N 
6i + &Zf + 
AijZ; = 0, 
Vi E N, 
(8.187) 
j=1 

458 
8. Overlapping Decompositions 
we can rewrite S of (8.185) as 
(8.188) 
To establish stability of the equilibrium Ze using the concept of vector 
Liapunov functions (Section 2.3), we associate with each subsystem S i  a 
Volterra-type function (e.g., Goh, 1980) 
1 
N 
s: hi = x i  AZ(5i - 5;) + c 
A& 
- 5.5, . 
[ 
j=1 
n, 
6i(zi) = c 
&k[Zik - - ?;k h ( % i k / 5 $ ) ] ,  
(8.189) 
where the &k are positive numbers. The function Gi: R? 4 R+ is continu- 
ously differentiable and positive definite on R:: 
and Gi(5:) = 0. The time 
derivative of Gi(2.i) with respect to the system S of (8.188) is 
k=l 
N 
6i(?i)(8.188) = -(5i - 5 t ) T G i ( 5 i  - 5:) + c(5i - z f ) T f i i a i j ( ? j  - ?;), 
j = 1  
(8.190) 
where the fii x fii matrices G i  and D i  are defined by 
1 
2 
G i  = --(AFBi + B i A i ) ,  
Di = diag{&, &, . . . , din,}. 
(8.191) 
We assume that a positive diagonal matrix D i  is available such that 
G i  is positive definite. This assumption means that all the equilibria 2; 
of decoupled subsystems S i  in (8.186) are stable. This fact can be verified 
on the level of subsystems and the question arises: Under what conditions 
does stability of the subsystems S i  implies stability of the overall expanded 
system S? An answer to this question is provided by the vector Liapunov 
function 6: Rn + RY having the form 6 = (61, 
62, . . . , 6 ~ ) ~ .  
Rn -+ R+ 
defined as 
Let us use the function G(5) to form a scalar function 6: 
N 
V(5) = c 
Cii6&). 
(8.192) 
This is our candidate for a Liapunov function for the system S ,  where the 
& are positive (yet unspecified) numbers. Utilizing 6 i ( z i ) ( 8 . 1 8 8 )  of (8.190), 
we compute t ( 5 ) ( 8 , ~ 8 8 )  and majorize the result to get 
i=l 
b( 5) 
(8,188) 5 -GT (5) 
Ga(5) 
(8.193) 

0.4. Nonlinear Systems 
459 
where G is an N x N matrix: 
G - = -(W 
T D + D l v ) .  
2 
The N x N matrix r/i, = (T&) is defined by 
(8.194) 
(8.195) 
where D = diag(21, 22, . . . , JN}. The function .ii: R” + RT is defined as 
q5)=(1]21-2;11, ))22-2;/1, ”., IlZ:N-&II)? 
(8.196) 
Inequality (8.193) implies the following: 
8.27. 
The positive equilibrium Ze of the system S is glob- 
ally asymptotically stable with respect to the region R t  if the matrix r?l is 
an M-matrix. 
THEOREM. 
Prooj 
Due to a special structure of the Loth-Volterra Equation 
(8.180), which gives rise to multiple equilibria and the fact that the so- 
lutions 2(t; &) of S that start from 20 at to = 0 in the positive orthant 
R t  stay there for all time t E To or diverge to infinity in finite time, we 
adopt the following modification (Ikeda and Siljak, 1980c) of the standard 
definition (see the proof of Theorem 8.26): 
A positive equilibrium Ze of the system S is said to be globally asymp- 
totically stable with respect to the region RF if 
(i) Ze is stable with respect to R t ,  that is, for every Z > 0 there exists 
8(Z) > such that (120 - 2e)I I 8 and 50 E R t  imply 
Il?(t; 50) -&[I 5 i
!
 
Vt E To; 
(8.197) 
and 
(ii) Z e  is attractive with respect to R t ,  that is, 20 E R t  implies 
lim Z(t; 50) = & 
VZo E Rt. 
(8.198) 
t++m 
Now, we start the proof of the theorem by defining the region 
R(a) = { 2  E Rt: 6(Z) 5 a}, 
(8.199) 
where 6(Z) is the scalar function defined in (8.192), and a is a positive 
number. We note that a1 < a2 implies n(a1) < n(az). 

460 
8. Overlapping Decompositions 
To establish (i) of the above definition, we show that for any given 
E > 0, the choice 
- 
S = min 
~
~
Z
-
~
e
~
~
 (8.200) 
fi(j.)=n(Z) 
suffices, where 
(8.201) 
We define the region 
r(p) = {Z E Rg: 
- 
5 p}, 
(8.202) 
where p is a positive number, and note that 
r(6) G n[a(~)] 
g r(q. 
(8.203) 
Since W is an M-matrix, from Theorem 2.4 we know that there exists 
a positive diagonal matrix D such that the matrix G is positive definite. 
Then, from (8.193), it follows that b(5)(8.188) < 0 for all k E RZ - {Ze} and, 
therefore, any solution Z(t; 20) that starts in r(6) does not leave n[a(E)] 
and, hence, remains in I'(El) for all t E To. This means that 2, is stable with 
respect to Rt. 
For part (ii) of the above definition, we use (8.193) to get the inequality 
b(2)(8.188) I 
-~rn(G) 115 - zeI12. 
(8.204) 
For any positive E, we can choose 6 as in (8.200). Let us assume that the 
solution Z ( t ;  50) 
that starts in R: 
does not enter r(6). 
Then, from (8.204), 
we get 
From the fact that 2(t; 20) c R t  for all t E To, we conclude from 
(8.205) that F(x) cannot remain nonnegative when t + +oo, which is a 
contradiction of the definition (8.192) of fi(2). Therefore, every solution 
that starts in R: 
outside r(6) must enter r(6) in finite time and stay 
there for all future times. Since C can be chosen arbitrarily small, we have 
q t ;  2 0 )  + ze as t + +oo. 
Q.E.D. 

8.4. Nonlinear Systems 
461 
At this point it is of interest to present an example that demonstrates 
the additional flexibility offered by the overlapping decompositions via the 
Inclusion Principle. 
8.28. EXAMPLE. Let us consider a third order Lotka-Volterra system 
s: [;;I 
= [: 0 ;c", 0 
2 3  :] ([a] + [ r;: 9 2  
[%;I), 
(8.206) 
which has a positive equilibrium 2, = (21/64, 1/16, 21/64)T. We start with 
a disjoint decomposition of S into two subsystems 
(8.207) 
With S1 and S2, we associate scalar functions (8.189) as 
+ [22 - (Ills) - (1/16) ln(16z~)], 
~ ~ ( 2 3 )  
= 2 3  - (21/64) - (21/64) ln(64~/21), 
(8.208) 
where dll is a positive number. Without loss of generality, we set d12 = 
d21 = 1 and choose D1 = diag(d11, l}, D2 = 1. Matrix W is 
(8.209) 
where 
GI = -1 ([ 5" -' ] ['I1 
"1 +. [ '11 
"1 [ -4 
I) . (8.210) 
2 
-12 
0 
1 
0 
1 
-8 
-12 
It is easy to show that &(GI) < 10 for any dll > 0, the matrix W is not 
an M-matrix, and we fail to establish stability. 

462 
8. Overlapping Decompositions 
Now. we expand S as 
s: 
using 
X 
V =  
M =  
+ 
-4 
5 
-8 
-12 
_______ 
-8 
0 
0
0
 
[l 
0 
0 
'1 0 0 
u =  0 1/2 1/2 0 , 
O 1  
,O 
0
1
0
'
 
O ]  
10 
0 
0 
1 
0
0
1
 
'0 
5/2 
-5/2 
0 
(8.212) 
S has a positive equilibrium 2e = (21/64, 1/16, 1/16' 21/64)T correspond- 
ing to the positive equilibrium z, of the original system s. 
Next, we decompose S into two disjoint subsystems S1 and S z r  which are 
indicated by the dashed lines in (8.211). This decomposition corresponds 
to the overlapping decomposition of the state vector z = (XI, 2 2 ,  ~
3
)
~
 
of 
the original system S into two state vectors 51 = (XI, ~
2
)
~
 
= (211, 5 1 ~ ) ~  
and 22 = (z2, ~
3
)
~
 
= (221, 2 ~ 2 ) ~  
of the subsystems S l  and S 2 ,  with z2 as 
the overlapping part. With this choice of decomposition, the form of V in 
(8.212) is automatic. 

8.5. Notes and References 
463 
Finally, we choose the scalar functions 
61(211, 212) = 3[&1 - (21/64) - (21/64) ln(64511/21)] 
+ [512 - (1/16) - (1/16) ln(16512)], 
62(521, 522) = [5zl - (1/16) - (1/16) ln(16521)] 
+ 3[&2 - (21/64) - (21/64) ln(64522/21)], (8.213) 
and we get the matrix 
(8.214) 
which is an M-matrix, and the equilibrium Ze of S is globally asymptotically 
stable with respect to the region R:. 
Since each initial state 20 E R t  of 
the original system S is preserved in the region R: 
of the state space of S 
under the transformation 5 = Vx, we can conclude by Theorem 8.26 that 
the positive equilibrium 2, of S is also globally asymptotically stable with 
respect to the region R t .  
8.29. 
Examples used in this chapter suggest that an overlap 
ping decomposition can succeed where disjoint decompositions fail, when 
critical interconnections can be incorporated inside the overlapping sub- 
systems to enhance stability of the subsystems. In this way, critical in- 
terconnections are integral parts of the subsystems and do not appear as 
interconnections at all; thus, vector Liapunov functions can be used effec- 
tively to show stability of the overall system. 
REMARK. 
8.5. Notes and References 
Overlapping decompositions can be traced back to the work of H. A. 
Schwarz (1890), where he showed that the solutions to Laplace’s equation 
with Dirichlet boundary condition, which are obtained on the two overlap 
ping subregions, are equivalent to solutions to the same problem on the 

464 
8. Overlapping Decompositions 
union of the subregions. Most interestingly, he showed that the solution 
procedure, which alternates from one subregion to the other, converges to 
the solution of the original problem. In the context of this chapter, we de- 
fined an overlapping decomposition of a dynamic (iterative) process and 
established (implicitly) stability of an expanded system. Numerical proce- 
dures based upon the Schwarz’s alternating procedure have been applied 
successfully to more general equations and boundary conditions (Miller, 
1965; Rodrigue and Saylor, 1985). 
A suitable mathematical framework for stability analysis of systems 
with overlapping subsystems has been initiated in the context of vector 
Liapunov functions (Siljak, 1978). The two formulations of the concept, 
proposed independently by Matrosov (1962) and Bellman (1962), are dif- 
ferent in the way the components of a function are defined. While in Bell- 
man’s formulation the components are associated with disjoint subspaces 
of the underlying space, Matrosov allows for overlapping. The significance 
of the difference has remained obscure until, in applications of the concept 
to decentralized control, it has been shown to be essential in dealing with 
overlapping information sets (Siljak, 1979). Expansions and contractions 
of dynamic systems have been formulated for this purpose, and the In- 
clusion Principle has emerged as a powerful formalization of these ideas. 
Our presentation of the Principle in this chapter follows closely several pa- 
pers (Ikeda and Siljak, 1980a, b, c; Ikeda et al. 1981a, b, 1984a, b), where 
additional results, examples, and applications can be found. The Principle 
appears as a natural tool for the design of overlapping decentralized control 
in as diverse fields as economics (Aoki, 1976) and electric power systems 
(Siljak, 1978; CaloviC et al. 1978; CaloviC, 1986), traffic control (Levine and 
Athans, 1966; Athans et al. 1967; Isaksen and Payne, 1973; Papageorgiou, 
1984) and large space structures (Yousuff and Patel, 1987; Yousuff, 1988; 
Young, 1987). 
STOCHASTIC INCLUSION PRINCIPLE 
In order to use the decentralized LQG scheme of Chapter 3 for over- 
lapping decompositions, a stochastic version of the Inclusion Principle was 
formulated in (HodiiC et al. 1983). By expanding the original LQG prob- 
lem into a larger space, the overlapping information sets become disjoint 
and the expanded LQG problem can be solved by standard decentralized 
methods. Under the inclusion conditions, which are given in terms of means 
and covariances of the solution process, the solution of the expanded LQG 
problem can be contracted for implementation into the original system. 

8.5. Notes and References 
465 
The most important part of this procedure is the fact that the contracted 
control law satisfies the overlapping information structure constraints. 
When decentralized estimators and controllers are to be designed for 
overlapping subsystems, both aggregations and restrictions need to be used; 
aggregations for estimators and restrictions for controllers. The entire de- 
sign process is formulated for discrete systems in (Hodiid and Siljak, 1986; 
Salters and Jamshidi, 1986). 
REDUCED-ORDER DESIGN 
The Inclusion Principle can be used in reduced-order design if we reverse 
the direction of the design process to be; contract, formulate the control law 
for the small system, and expand the control law for implementation in the 
original system. While there is an infinite number of ways we can expand a 
given system, the number of contractions is finite. This fact makes reduced- 
order designs different from those of overlapping decentralized control, as 
explained in deterministic terms by Sezer and Siljak (1982). The stochastic 
version of the Inclusion Principle offers a broader scope of model reduction 
by allowing for “imperfect reductions” in a probabilistic sense. 
INPUT-OUTPUT INCLUSION 
A considerable increase of flexibility is provided by allowing for expan- 
sions and contractions of inputs and outputs. For example, by expand- 
ing the input space in a model representing a string of moving vehicles, 
one can obtain the input matrix in a block-diagonal form, that is, input- 
decentralized form. This is not possible to achieve without expanding the 
input space as well. Dynamic output feedback becomes decentralized, too 
(for details, see Ikeda and Siljak, 1986; Iftar, 1988; Iftar and Ozguner, 1990). 
OVERLAPPING DIAGONAL DOMINANCE 
Well-known diagonal dominance conditions (Section 7.5) are reformu- 
lated to consider overlapping diagonal blocks (Ohta and Siljak, 1985). This 
can be useful in diverse fields such as economics (Pearce, 1974; Okuguchi, 
1978) and model ecosystems (May, 1974; Siljak, 1978; Svirezhev and Lc- 
gofet, 1983), iterative numerical schemes (Robert, 1969; Hageman and 
Young, 1981) and computers (Courtois, 1977). We should note that be- 
sides overlapping, the diagonal dominance, as defined by Ohta and Siljak 

466 
8. Overlapping Decompositions 
(1985) , provides additional flexibility by normalization, scaling, and al- 
ternative norm utilization. A link between this new version of diagonal 
dominance and vector Liapunov functions is also established. 
INCLUSION OF TRANSFER FUNCTIONS 
Having formulated a flexible diagonal dominance condition, a natural 
place to use it is in the control design framework of Rosenbrock (1974). 
We were able to produce a generalization of the Nyquist array method to 
blockwise overlapping decompositions (Ohta et al. 1986). In this context, 
it is suitable to synthesize overlapping decentralized controllers via the 
inclusion principle involving transfer functions (see also, Iftar and Ozguner, 
1987a). 
HEREDITARY SYSTEMS 
A more realistic model of AGC in Example 8.22 would be one that 
includes a time delay in power exchange over the tie-line. This is especially 
so if the two power areas are geographically far apart. For such a model, 
we developed an Hereditary Inclusion Principle (Ohta and Siljak, 1984). 
The Principle is formulated for nonlinear functional equations and applied 
to the stability of linear and nonlinear interconnected systems with time- 
delays and overlapping subsystems. The obtained theorems offer added 
flexibility even if the subsystems are disjoint, or the system is considered 
as a whole (Ladde, 1976; Anderson, 1979; Sinha, 1980; Lewis and Anderson, 
1980; Shigui, 1988). Decentralized feedback for systems with time delays 
and overlapping information sets could be developed following the results 
of Ikeda and Siljak (1980d). 
POWER SYSTEMS 
Natural overlapping decompositions appear most prominently in stabil- 
ity analysis of models in electric power engineering. In Example 8.22, the 
tie-line is a logical overlapping part between two power areas. This fact 
has been investigated in some detail in (CaloviC et al. 1978; Siljak, 1978; 
Ikeda, Siljak, and White, 1981a; CaloviC, 1986). In transient stability anal- 
ysis, the reference machine is a natural overlapping part; the fact was first 
noted by Pai and Narayana (1975), and later used in a wide variety of mod- 
els by many people (see, Siljak, 1978; Araki et al. 1982; Ribbens-Pavella 
and Evans, 1985). 

Bibliography 
467 
MECHANICAL SYSTEMS 
The Inclusion Principle has been applied to standard systems in the 
Bogolyubov sense, and general results have been obtained relating the sta- 
bility of the expanded and the original system (Martynyuk, 1984, 1986). 
The Principle has also been generalized for matrix second order systems, 
and used to simplify numerical procedures involving finite elements meth- 
ods (Yousuff and Patel, 1987), as well as controlled component synthesis 
(Young, 1987). Especially interesting are the results of Yousuff (1988) and 
Yousuff and Ikeda (1988) pertaining to approximate versions of aggregation 
and restrictions (see also, Sezer and Siljak, 1982; Lidner and Babendreier, 
1988; Iftar, 1988; Lidner, 1988). 
STRING OF MOVING VEHICLES 
Control of a string of moving vehicles involves overlapping subsystems 
(Levine and Athans, 1966). When the system is expanded into a large 
space, the substring appears as decoupled subsystems. The modes of the 
expanded system, which are not shared by the corresponding contraction, 
are precisely the uncontrollable modes of the subsystems. This means that, 
under the information structure constraint imposed by the overlapping sub- 
systems, we may assign arbitrarily the eigenvalues of the contracted closed- 
loop system. For details, see (Ikeda et al. 1981b; Ikeda and Siljak, 1986). 
Bibliography 
Anderson, B. D. 0. (1979). Time delays in large scale systems. Proceedings of the 18th 
IEEE Conference on Decision and Control, Fort Lauderdale, Florida, 655460. 
Aoki, M. (1971). Aggregation. Optimization Methods for Large-Scale Systems with Ap- 
plications. D. A. Wismer (ed.). McGraw-Hill, New York, 191-232. 
Aoki, M. (1976). On decentralized stabilization and dynamic assignment problems. Jour- 
nal of International Economics, 6, 143-171. 
Araki, M., M. M. Metwally, and D. D. Siljak (1982). Generalized decompositions for 
transient stability analysis of mukimachine power systems. Large Scale Systems, 3, 
111-122. 
Athans, M., M. Levine, and A. H. Levis (1967). A system for the optimal and suboptimal 
position and velocity control for a string of high-speed vehicles. Proceedings of the 
5th A ICA Congress, Lausanne, Switzerland, 1-15. 
Bellman, R. (1962). Vector Lyapunov functions. SIAM Journal of Control, 1, 32-34. 
Benkherouf, A., and A. Y .  Allidina (1987). Sensor fault detection using overlapping 
decomposition. Large Scale Systems, 12, 3-21. 

468 
8. Overlapping Decompositions 
Brucoli, M., M. LaScala, F. Torelli, and M. Trovato (1987). Overlapping decomposition 
for small disturbance stability analysis of interconnected power networks. Large Scale 
Systems, 13, 115-129. 
CaloviC, M. S. (1986). Recent developments in decentralized control of generation and 
power flows. Proceedings of the 25th Conference on Decision and Control, Athens, 
Greece, 1192-1197. 
CaloviC, M., M. DjoroviC, and D. D. Siljak (1978). Decentralized approach to autc- 
matic generation control. Proceedings of the International Conference on Large 
High-Voltage Electric Systems (CIGRE), Paris, 32:06, 1-12. 
Chipman, J. S. (1976). Estimation and aggregation in econometrics: An application of 
the theory of generalized inverses. Generalized Inverses and Applications, M. Z. 
Nashed (ed.), Academic Press, New York, 549-769. 
Courtois, P. J. (1977). Decomposability. Academic Press, New York. 
Erol, Y., and K. A. Loparo (1982). Decentralized deadbeat control of cascaded pro- 
duction-inventory 
systems. IEEE Transactions, SMC-12, 924-927. 
Goh, B. S. (1980). Management and Analysis of Biological Populations. Elsevier, Ams- 
terdam, The Netherlands. 
Hageman, L. A,, and D. M. Young (1981). Applied Iterative Methods. Academic Press, 
New York. 
Hassan, M. F., M. I. Younis, and M. A. Sultan (1989). A decentralized controller for 
cold rolling mills. Information and Decision Technologies, 15, 1-31. 
HodiiC, M., and D. D. Siljak (1986). Decentralized estimation and control with overlap 
ping information sets. IEEE Transactions, AC-31, 83-86. 
HodiiC, M., R. Krtolica, and D. D. Siljak (1983). A stochastic inclusion principle. Pro- 
ceedings of the 22th IEEE Control and Decision Conference, San Antonio, Texas, 
Iftar, A. (1988). Robust controller design for large scale systems. Ph.D. Thesis. The 
Ohio State University, Columbus, Ohio. 
Iftar, A., and F. Khorrami (1989). A comparison of multiply time-scale analysis and 
overlapping decomposition. IEEE Transactions, SMC-19, 1296-1300. 
Iftar, A., and U. Ozgiiner (1984). Closed-loop balanced realizations in the analysis of 
suboptimality and stability of decentralized systems. Proceedings of the 23rd IEEE 
Conference on Decision and Control, Las Vegas, Nevada, 143-148. 
Iftar, A., and U. Ozgiiner (1987a). Decentralized LQG/LTR controller design for inter- 
connected systems. Proceedings of the American Control Conference, Minneapolis, 
Minnesota, 1682-1687. 
Iftar, A., and U. Ozgiiner (1987b). Local LQG/LTR controller design for decentralized 
systems. IEEE Transactions, AC-32, 926-930. 
Iftar, A., and U. Ozgiiner (1990). Contractible controller design and optimal control 
with state and input inclusion. Automatica, 26, 593-597. 
Ikeda, M., and D. D. Siljak (1980a). Overlapping decompositions, expansions, and con- 
tractions of dynamic systems. Large Scale Systems, 1, 29-38. 
Ikeda, M., and D. D. Siljak (1980b). Generalized decompositions and stability of non- 
linear systems. Proceedings of the 18th Allerton Conference, Monticello, Illinois, 
726734. 
Ikeda, M., and D. D. Siljak (1980~). Loth-Volterra equations: Decomposition, stability, 
and structure. Part I: Equilibrium analysis. Journal of Mathematical Biology, 9, 
Ikeda, M., and D. D. Siljak (1980d). Decentralized stabilization of large scale systems 
17-22. 
65-83. 
with time delay. Large Scale Systems, 1, 273-279. 

Bibliography 
469 
Ikeda, M., and D. D. Siljak (1981). Generalized decompositions of dynamic systems and 
vector Liapunov functions. IEEE Transactions, AC-26, 1118-1125. 
Ikeda, M., and D. D. Siljak (1982). Loth-Volterra equations: Decomposition, stabil- 
ity, and structure. Part 11: Nonequilibrium Analysis. Nonlinear Analysis, Theory, 
Methods, and Applications, 6, 487-501. 
Ikeda, M., and D. D. Siljak (1986). Overlapping decentralized control with input, state, 
and output inclusion. Control- Theory and Advanced Technology, 2, 155-172. 
Ikeda, M., and D. D. Siljak (1987). Stability of reduced-order models via vector Li- 
apunov functions. Proceedings of the American Control Conference, Minneapolis, 
Minnesota, 482-489. 
Ikeda, M., D. D. Siljak, and D. E. White (1981a). Decentralized control with overlapping 
information sets. Journal of Optimization Theory and Applications, 34, 279-310. 
Ikeda, M., D. D. Siljak, and D. E. White (1981b). On decentralized control with over- 
lapping information sets. Proceedings of the 8th IFAC Congress, Kyoto, Japan, 9, 
Ikeda, M., D. D. Siljak, and D. E. White (1984a). An inclusion principle for dynamic 
systems. IEEE Transactions, AC-29, 244-249. 
Ikeda, M., D. D. Siljak, and D. E. White (1984b). Overlapping decentralized control of 
linear time-varying systems. Advances in Large Scale Systems, vol. 1, J. B. Cruz, 
Jr. (ed.), JAI Press, Greenwich, Connecticut, 93-116. 
Isaksen, L., and H. J. Payne (1973). Suboptimal control of linear systems by augmen- 
tation with application to freeway traffic regulation. IEEE Tmnsactions, AC-18, 
Zl(t219. 
Ladde, G. S. (1976). Systems of functional differential inequalities and functional differ- 
ential systems. Pacific Journal of Mathematics, 66, 161-171. 
Leela, S. (1984). Large-scale systems, conevalued Lyapunov functions and quasi-solutions. 
Trends in Theory and Practice of Nonlinear Differential Equations, V. Lakshmikan- 
tham (ed.), Marcel Dekker, New York. 
Levine, W. S., and M. Athans (1966). On the optimal error regulation of a string of 
moving vehicles. IEEE Transactions, AC-11, 355-361. 
Lewis, R. M., and B. D. 0. Anderson (1980). Necessary and sufficient conditions for 
delay-independent stability of linear autonomous systems. IEEE Transactions, AC- 
Lidner, D. K. (1988). Near aggregation, the dual GHR and pole-zero cancellation. In- 
Lidner, D. K., and J. Babendreier (1988). A trajectory analysis of near aggregation. 
Malinowski, K., and M. G. Singh (1985). Controllability and observability of expanded 
Martynyuk, A. A. (1984). The inclusion principle for standard systems. Dokladi Academii 
Martynyuk, A. A. (1986). Expansion of the state space of dynamic systems and stability 
Matrosov, V. M. (1962). On the theory of stability of motion. Pnkladnaya Matematika 
May, R. M. (1974). Stability and Complexity in Model Ecosystems, 2nd ed., Princeton 
Miller, K. (1965). Numerical analogs of the Schwarz alternating procedure. Numerische 
32-38. 
25, 735-739. 
ternational Journal of Control, 48, 705-727. 
IEEE Transactions, AC-33, 474477. 
systems with overlapping decompositions. Automatica, 21, 203-208. 
Nauk SSSR, 276, 34-37. 
problems. Prikladnaya Mekhanika, 22, l(t25. 
i Mekhanika, 26, 992-1002. 
University Press, Princeton, New Jersey. 
Mathematik, 7, 91-103. 

470 
8. Overlapping Decompositions 
Ohta, Y., and D. D. Siljak (1984). An inclusion principle for hereditary systems. Journal 
of Mathematical Analysis and Applications, 98, 581-598. 
Ohta, Y., and D. D. Siljak (1985). Overlapping block diagonal dominance and existence 
of Liapunov functions. Journal of Mathematical Analysis and Applications, 112, 
Ohta, Y., D. D. Siljak, and T. Matsumoto (1986). Decentralized control using quasi- 
block diagonal dominance of transfer function matrices. IEEE Transactions, AC-31, 
42Cb430. 
Okuguchi, K. (1978). Matrices with dominant diagonal blocks and economic theory. 
Journal of Mathematics Economics, 5, 43-52. 
Pai, M. A,, and C. I. Narayana (1975). Stability of large scale power systems. Proceedings 
of the 6th IFAC Congress, Boston, Massachusetts, 31.6:l-10. 
Papageorgiou, M. (1984). Multilayer control system design applied to freeway traffic. 
IEEE Transactions, AC-29, 482-490. 
Pearce, I. F. (1974). Matrices with dominant diagonal blocks. Journal of Economic 
Theory, 9, 154-170. 
Ribbens-Pavella, M., and F. J. Evans (1985). Direct methods for studying dynamics of 
large-scale electric power systems: A survey. Autornatica, 21, 1-21. 
Robert, F. (1969) Blocs-H-matrices et convergence des methodes iteratives classiques 
par blocs. Linear Algebra and Its Applications, 2, 223-265. 
Rodrigue, G., and P. Saylor (1985). Inner-outer iterative methods and numerical Schwarz 
algorithm, Part 11. Report UCRL-92077-II, Lawrence Livermore National Labora- 
tory, Livermore, California. 
Rosenbrock, H. H. (1974). Computer-Aided Control System Design. Academic Press, 
New York. 
Salters, R. E., and M. Jamshidi (1986). On the aggregation of large-scale stochastic 
systems with multiplicative noise. Large Scale Systems, 11, 31-42. 
Schwarz, H. A. (1890). Gesammelte Mathematische Abhandlungen. Vol. 2, Springer, 
Berlin, 133-143. 
Sezer, M. E., and D. D. Siljak (1982). Validation of reduced-order models for control 
systems design. Journal of Guidance, Control, and Dynamics, 5, 430-437. 
Shigui, R. (1988). Connective stability for large scale systems described by functional 
differential equations. IEEE Transactions, AC-33, 198-200. 
Siljak, D. D. (1978). Large-Scale Dynamic Systems: Stability and Structure. North- 
Holland, New York. 
Siljak, D. D. (1979). Overlapping decentralized control. Large Scale Systems Engineer- 
ing Applications. M. Singh and A. Titli (eds.), North-Holland, Amsterdam, The 
Netherlands, 145-166. 
Siljak, D. D. (1980). Reliable control using multiple control systems. International Jour- 
nal of Control, 31, 303-329. 
Singh, M., M. F. Hassan, Y. L. Chen, and Q. R. Pan (1983). New approach to failure 
detection in large scale systems. IEE Proceedings, Part. D., 130, 243-249. 
Sinha, A. S. C. (1980). Lyapunov functions for a class of large-scale systems. IEEE 
Transactions, AC-25, 558-560. 
Skelton, R. E. (1988). Dynamic Systems Control. Wiley, New York. 
Svirezhev, Yu. M., and D. 0. Logofet (1983). Stability of Biological Communities. Mir, 
Wonham, W. M. (1979). Linear Multivariable Control: A Geometric Approach. Springer, 
396-4 10. 
Moscow, USSR. 
New York. 

Bibliography 
471 
Young, K. D. (1987). Distributed finite element modeling and controls. Report No. UCID- 
20950-87, 
Lawrence Livermore National Laboratory, Livermore, California, 412-455. 
Yousuff, A. (1988). Application of inclusion principle to mechanical systems. Proceedings 
of the American Control Conference, Atlanta, Georgia, 1516-1520. 
Yousuff, A., and M. Ikeda (1988). Overlapping decomposition and expansion of mechan- 
ical systems. Proceedings of the 1988 AIAA Conference on Guidance, Navigation, 
and Control, Paper No. 88-4169-CP, 958-963. 
Yousuff, A., and N. Patel (1987). Reduction of finite element models employing inclusion 
principle. Proceedings of the 28th IEEE Conference on Decision and Control, Los 
Angeles, California, 486-488. 

Due to increasing complexity of the present-day technology, reliability of 
control has become an essential requirement in the design of large systems. 
It has been recognized that the degree of reliability required in a high- 
performance design cannot be achieved merely by diligent application of 
standard control engineering practice, that is, by using high-quality compo- 
nents in otherwise standard optimization techniques. For this reason, there 
has been a considerable effort to invent new control schemes with some 
form of built-in reliability enhancement. The major objective has been to 
synthesize a control structure so that the system performs satisfactorily 
under faulty conditions. 
In the early developments of reliable control, it was demonstrated that 
decentralized control schemes are superior to their centralized counterparts. 
By now, there are a considerable number of results discussed throughout 
this book that show explicitly a high reliability of decentralized control 
strategies for plants under structural perturbations. The strategies are ro- 
bust to a wide range of nonlinearities in both the subsystems and their 
couplings as well. Reliability of decentralized schemes, however, is not satis- 
factory with regard to perturbations of feedback connections and controller 
failures. If a local controller breaks down, it is quite likely that the whole 
system may do the same. Replacement of a faulty controller by a standby, 
or a disconnection of the corresponding subsystem for the purpose of pre- 
venting a system break-down, may be impossible or equally undesirable 
due to design constraints. From the point of view of reliability theory (e.g., 
Barlow and Proschan, 1975), decentralized control schemes are series con- 
nections of controllers and a control configuration is as reliable as the least 
reliable controller. 
“In building complex computing machines, unreliability of components 
should be overcome not by making the components more reliable, but by 
472 

9.1. Multiple Control Systems 
473 
CONROLLER 
Fig. 9.1. Centralized control. 
organizing them in such a way that the reliability of the whole computer 
is greater than the reliability of its parts,” is the von Neumann’s dictum 
for building reliable computers. The dictum was formulated in the context 
of automata theory (von Neumann, 1956) and was subsequently utilized 
as a major principle in synthesizing reliable circuits (Moore and Shannon, 
1956) and systems (Barlow and Proschan, 1975). It is in the spirit of von 
Neumann’s dictum, but otherwise using entirely different techniques, that 
multiple control schemes have been proposed (Siljak, 1978b) for the design 
of reliable control systems. An essential redundancy has been introduced 
by multiplicity of controllers in a parallel connection, allowing for a highly 
reliable design using less reliable controllers. 
9.1. Multiple Control Systems 
Let us start by contrasting two basic control structures: centralized 
structure in Figure 9.1 and decentralized structure in Figure 9.2. In the 
centralized configuration, one controller monitors two separate but inter- 
connected plants, which may represent two parts of a single large plant. 
When a decentralized structure is used for the same plant, both “sub- 
plants” have a separate controller. A subplant and its controller constitute 
a subsystem. Although systems appear in much more complex form, the 
two generic structures can best illustrate the reliability aspect of control. 
We distinguish two basic failure modes: plant failures and controller 
failures. Plant failures can further be classified as failures of individual in- 
terconnections among the subplants, or total disconnection of a subplant 

474 
9. Reliable Control 
Fig. 9.2. Decentralized control. 
from the rest of the system. Structural perturbations due to plant fail- 
ures are illustrated on Figures 9.3 and 9.4 for centralized and decentralized 
control structures, respectively. We have demonstrated so far a good un- 
derstanding of plant failures. For example, it was demonstrated by a simple 
control system (Siljak, 1978a) that such a failure can cause instability and, 
thus, a breakdown of a centralized system. On the other hand, decentral- 
ized control schemes described in this book display fault-tolerance to plant 
and interconnection failures shown in Figure 9.4. 
Control failures can also be either partial or total failures, that is, either 
some control connections between a controller and a plant fail, or an entire 
controller is disconnected from a subplant. Such disconnections are shown 
in Figure 9.5 for both centralized and decentralized control structures. None 
of the two control schemes have shown to be reliable to controller failures. 
For this reason, multiple control schemes were initiated (Siljak, 1978b), and 
proved to be promising in design of reliable control. 
A way to introduce redundancy in an essential way into control design 
is to assign more than one controller to a plant. A generic case of a multiple 
control system is shown in Figure 9.6, where two controllers control a single 
plant. When a controller failure occurs, as illustrated in Figure 9.7, the 
other controller is able to carry on the plant without any interruption of 
the functioning of the overall system. This is what makes the multiple 
control concept so attractive: Each controller is a hot spare for the other. 

r 
COWROLLER 
To show in quantitative terms how the multiple control schemes can 
improve reliability, we follow the basic concepts of reliability theory (Barlow 
and Proschan, 1975) and assign to each controller a binary number 
I 
CONTROLLER 
1, 
0, 
if the ith controller is functioning, 
if the ith controller is failed,, 
(9.1) 
.={ 
for i E M = (1, 2, . . . , M } ,  where M is t,he number of controllers in 
the system. Assumption (9.1) means that we consider dichotornic control 

476 
9. Reliable Control 
A 
----- 
I SUBSYSTEM 1 
SUBSYSTEM 1 
2 
r--- 
I 
CONROLLER 2 
---- 1 r---- 
CONROLLER 2 
I 
CONTROLLER 1 
I 
I ,  
I 
PLANr 1 
I 
- 
(b) 
Fig. 9.4. Decentralized control: (a) interconnection failure; (b) plant failure. 

9.1. Multiple Control Systems 
477 
structures only, which may appear to be an overly restrictive requirement. 
It is a well-known fact that controllers are capable of a continuous range of 
performance quality; from perfect performance to total failure. At present, 
the assumption (9.1) is a necessary idealization to get us started. It should 
be noted here that some of our results apply to control structures with 
partial performance. 
With the overall control system, we associate a binary indicator 
1, 
0, 
if the control system is functioning, 
if the control system is failed. 
(9.2) 
m = {  
It is essential to define what we mean by “functioning.” If there are no parts 
of an interconnected plant that are not “covered” by a controller, then we 
say that the control system is functioning. For example, in the generic 
case of Figure 9.6, where two on-line controllers C1 and C2 simultaneously 
control a single plant P, there are four possible control configurations as 
shown in Figure 9.8. The loss of a controller is described by decoupling the 
corresponding light circle from the black circle representing the plant. We 
consider the first three structures C1C2, GC2, C1$$ as functioning, while 
the state G$$ 
is considered as failure. This is a reasonable assumption 
because we expect the plant to have unstable elements and, if it is left alone, 
the system becomes unstable and nonfunctioning. On the other hand, we 
will show that one can design controllers C1 and Cz so that the functioning 
structures of Figure 9.8 are all stable. 
States of the controllers are determined by the vector c = 
(cl, c2, . . . , C N ) ~ ,  
and the state of the control system is given by the func- 
tion 
4 = m ( 4  
(9.3) 
which is referred to simply as control structure 4. For example, the system 
in Figure 9.2 has a series control structure 
d(c) = clc2 = min(c1, cz}. 
(9.4) 
In case of N controllers in series, the control structure is described as 
N 
+(c) = 
q = min(c1, c2, . . . , cN}. 
i=l 
19.5) 

478 
9. Reliable Control I 
CONTROLLER 
2- 
(a) 
SUBSYSTEM 2 1 
CONTROLLER 2 
I 
I 
I 
I 
I 
I 
PLANT 2 
1 
(b) 
Fig. 9.5. 
Controller failure: (a) centralized system; (b) decentralized system. 
The multiple control system of Figure 9.6 has a parallel control structure 
@(c) = 1 - (1 - C l ) ( l  - c2) = max(c1, cz). 
(9.6) 
For N controllers in parallel, 
N 
@(c) = 1 - n(1- cz) = max(c1, c2, . . . , CN). 
(9.7) 
i=l 

9.1. Multiple Control Systems 
479 
I 
SUBSYSTEM 1 I 
I 
CONTROLLER 2 
I 
Fig. 9.6. Multiple control system. 
A control system can be designed as a combination of the two generic 
configurations: the decentralized control of Figure 9.2, and the multiple 
control of Figure 9.6; that is, as a combination of controllers connected 
in series and parallel arrangements. In this context, the coherent struc- 
tures emerge as natural objects of reliability analysis, since in these struc- 
tures improvement of reliability on the component level implies a reliability 
improvement on the overall system level. In the deterministic analysis of 
control structures, the coherent systems are described by a monotonically 
increasing function qh(c). Other properties of coherent structures can be 
found in (Barlow and Proschan, 1975). 
We assume now that all controllers of a given system perform or fail 
at random and independently of each other, that is, the state ci of the ith 
controller is a random variable with the probability distribution 

480 
9. Reliable Control 
CONTROLLER 1 
P L A N T  
I 
CONIROLLER 2 
I SUBSYSTEM2 
I 
Fig. 9.7. Controller failure. 
0 
0 
i i !  0 
ClCZ 
!ACZ 
c1$2 
$142 
Fig. 9.8. Control structures. 

9.1. Multiple Control Systems 
481 
where &q denotes the expected value of the random variable ci. We refer 
to pi as the reliability of the ith controller. The reliability of the overall 
control system is 
P{$h(C) = 1) = x = Eq5(c). 
(9.9) 
Since the controllers are independent, the system reliability can be repre- 
sented as a function of controller reliabilities by the reliability function 
x = X ( P ) ,  
(9.10) 
where P = (Pl, p2, . . . , p d T .  
In Figure 9.9 we show three control structures with the following relia- 
bility functions: 
( a )  series structure: 
Xa(P) = p3; 
(b) parallel structure: 
X b b )  = 1 - (1 - PI3; 
(9.11) 
(c) two-out-of-three structure: 
xc(p) = 3p2(1 - p )  + p 3 .  
It is assumed that all controllers have the same reliability p .  The reliability 
functions are plotted in Figure 9.10. The S shaped curve (c) for the two- 
out-of-three structures is most interesting, because it confirms the fact that 
we can achieve a desirable reliability of a control system using a suficient 
number of low quality controllers. This is an exact copy of the fact observed 
by Moore and Shannon (1956) in the context of relay circuits. From curve 
(c) in Figure 9.10, we see that if the controller reliability p is greater than 
1/2, the reliability function x ( p )  is above the diagonal line x(p) = p ,  and 
the overall structure is more reliable than a single controller. 
From Figure 9.10, we see that the purely decentralized structure (a) 
is least reliable with regard to control failures, but it is the most reliable 
structure under perturbations in the plant interconnections, that is, un- 
der plant failures. Therefore, a combination of decentralized and multiple 
controllers may be used to account for both interconnection and controller 
failures. This brings about the problem of optimum redundancy allocation, 
which should be attempted in the proposed framework using the reliability 
theory (e.g., Barlow and Proschan, 1975). 
There are several reasons why the multiple control configurations are 
superior to their alternatives. The most important of all is the recent trend 
of the microprocessors technology, which makes the redundant decentral- 
ized controllers an appealing design concept. When a single centralized 
controller is used instead, duplication is performed on the lower (compo- 

482 
9. Reliable Control 
Q 
(C) 
Fig. 9.9. 
2-out-3 structure. 
Three-controller structure: (a) series structure; (b) parallel structure; (c) 
nent) level, and the failed component cannot be replaced during opera- 
tion. When parallel redundancy is achieved using multiple control schemes, 
the failed controllers can be disconnected, tested, and repaired or replaced 
without any interfering with the functioning of the overall system. Most of 
the present microprocessor designs have built-in functions disconnect-test- 
reconnect in multi-unit configurations. 
Another alternative to multiple controllers is the possibility of imple- 
menting a reconfiguration of the control structure each time a structural 
change occurs and is detected by a failure-detection scheme. This solution 
is usually unattractive because the failure detections and reconfiguration 
schemes are quite complex themselves, which can decrease to an unknown 
degree the reliability of the overall system. 

9.2. Reliability of Control Structures 
483 
0.5 
1 .o 
controller reliability, p 
Fig. 9.10. System reliability. 
Still another possibility to improve reliability of the overall system is to 
use identical controllers in a standby redundant configuration. Generally, 
mechanisms to switch on- and off-line are similarly complex and can fail to 
perform. Furthermore, in many cases, it cannot be assumed that the off-line 
controllers are immune to failure until they are activated to on-line status. 
These and other similar facts are well-known in fault-tolerant computer 
technology and avionics (Bernard, 1980). 
9.2. Reliability of Control Structures 
A widely accepted definition of reliability is: 
“Reliability is the probability of a device performing its purpose 
adequately for the period of time intended under the operating con- 
ditions encountered.” (IEEE Dictionary of Electrical and Electronic 
Terms). 
In order to replicate this definition in the control context, the status of 
the multiple control system should be described by a Markov process as 
proposed in (Siljak, 1981): Each controller failure or recovery results in a 
transition to a new state that depends only on the current state of the con- 
trol structure. The states of the control configuration, which correspond 

484 
9. Reliable Control 
I 
I 
I 
I 
Fig. 9.11. Multiple control system. 
to a stable system, are considered as acceptable. The mean time spent by 
the structure in those states is a measure of system reliability. A Markov 
process is associated with the dynamics of the overall system via connective 
stability: stability of a multiple control system is established for all of its ac- 
ceptable states. In this way, the above reliability definition is approximated 
in a natural way by the new notion of control reliability. 
First, our definition of control reliability is given in probabilistic terms. 
Second, the adequate performance is stability of the overall system. Third, 
the “period of time” is specified by the mean time before a failed (unstable) 
state of the control structure is reached. Fourth, “the operating conditions 
encountered” are assumed as controller and plant failures. These facts open 
up a real possibility of using numerous results of reliability theory (Bernard, 
1980) in building fault-tolerant control schemes for complex dynamic sys- 
tems. 
Structural configurations arising from controller failures are considered 
as states of a Markov process M (e.g., Feller, 1968) formulated as 
M qi=rI$, 
(9.12) 
where 4(t) E RN is the state probability vector at time t E R, and II = (xij) 
is the constant transition rate N x N matrix. For example, in the case of the 
multiple control system of Figure 9.11 with permissible control structures 

9.2. Reliability of Control Structures 
485 
Fig. 9.12. Permissible control structures. 
in Figure 9.12, the matrix n is 
n =  
1 
-3x 
x 
x 
x 
2 
3
4
 
0 
0
0
 
-2x 
0 
0 
0 
-2x 
0 
2x 
2x 
0 
1 
2 
3 
4 
1 
(9.13) 
where by 4 4  we denote the super-state which corresponds to five failed 
states. We have assumed identical constant failure rate A for all three 
controllers which fail independently of each other. We also have assumed 
no maintenance of the failed controllers so that the failed state 4 4  is the 
trapping state. The corresponding transition rate diagram is given in Fig- 
ure 9.13. If we assume that at time t = 0 all controllers are in a work- 
ing order, the initial conditions are 4(0) = (1, 0, 0, O)T. To determine the 
reliability function X ( t )  of the control structure in Figure 9.11, we solve 
Equation (9.12) for the specified 40, and combine the probabilities of being 
an acceptable state to get 
Rft) = ze-2xt - ,-3Xt 
(9.14) 
which is the probability of the control structure surviving at time t. One 
of the standard measures of reliability (e.g., Barlow and Proschan, 1975) 
is the Mean Time To Failure (MTTF), 
(9.15) 
which is the mean time for control system to reach the failure state 4 4  of M 
starting from the structural state $1 when all controllers are functioning. 
2 
R(t) dt = - 
MTTF = r 
3X’ 

486 
9. Reliable Control 
Fig. 9.13. Transition rate diagram. 
We note that no repair of controllers has been considered. To include 
maintenance, all we need is to introduce repair rates of controllers above 
the main diagonal in 11 of (9.13). If the rates are placed in the last column 
of 11, then the failed state 4 4  is no longer a trapping state. Intuitively, this 
seems an acceptable situation provided that the system does not stay “too 
long” in the failed state, because the plant runs open-loop, and instability, 
if present, may destroy the system. This case is considered in Section 9.4. 
9.3. Design of Reliable Control 
In order to design reliable control using multiple controllers, we should 
augment the structural reliability considerations with a formulation of con- 
trol laws that makes the system stable when it has any of the permissible 
structures. For this, we need the overlapping decompositions and the In- 
clusion Principle from the preceding chapter. 
Let us consider the generic case of the multiple control system in Fig- 
ure 9.6, and assume that it is described as 
PLANT: 
j.2 = A 2 1 5 1  + A 2 2 5 2  + -423x3, 
(9.16) 
CONTROLLER 2: 
i 3  = A 3 2 5 2  + A 3 3 5 3  + B 2 ~ 2 ,  
where ~ ( t )  
E Rn2, q ( t )  E R”’, and 2 3 ( t )  E Rn3 are the states of the plant 
P and the controllers C 1  and C 2 ;  ul(t) E Rm’ and u 2 ( t )  E Rm2 are the 
inputs to the controllers; and the matrices in (9.16) are constant and have 

9.3. Design of Reliable Control 
487 
proper dimensions. We can put (9.16) into a matrix form 
S: j . = A z + B u ,  
(9.17) 
where 2 = (z:, 
zf, 
x T ) ~ ,  
and the matrices A and B have the block form 
(9.18) 
I 
-----.I 
0 1 A32 
A33 
i 
The plant is an overlapping part of S. By expanding S as in the Exam- 
ple 8.15, we get an expansion (Section 8.1), 
(9.19) 
which is an interconnection of two subsystems 
(9.20) 
with states 21 = (z:, 
~ c f ) ~  
and 22 = (zcf, z;)'. 
These two subsystems 
correspond to the two middle configurations in Figure 9.8 when one of the 
controllers is failed. The first configuration corresponds to both controllers 
functioning, and is described by (9.19) as 
S: i 1  = A121 + &u1+ elzA1222, 
i 2  = A212 + B2uZ + e21A32122. 
(9.21) 
In (9.19) and (9.21), we introduced the elements of the 2 x2 interconnection 
matrix 
(9.22) 

488 
9. Reliable Control 
which can effectively describe the three permissible structures in Figure 9.8: 
Now, reliable control design is reduced to connective stabilization of S in 
(9.21) under structural perturbations (9.23), which we know how to do. 
We choose the decentralized feedback control law 
and get the closed-loop system 
S F :  i = tlF(E)I, 
where I = (IT, 
IF)T and 
(9.25) 
(9.26) 
If SF is connectively stable, it means that all three permissible control 
structures of Figure 9.8 are simultaneously stable (Siljak, 1980). 
To be more specific, let us consider a “scalar77 version of the multiple 
control system (9.16). 
9.1. EXAMPLE. 
CONTROLLER 1: 
Xi = ~
1
,
 
PLANT: 
X Z  = a 2 1 2 1  + a22xZ + a23237 
(9.27) 
CONTROLLER 2: 
k3 = 212. 
The structure of the system is shown in Figure 9.14, where dashed 
lines indicate the two overlapping subsystems. By defining the state vector 
x = (21, 
2 2 ,  x3)* and the input vector u = (u1, Z L Z ) ~ ,  we rewrite (9.27) as 
the system 
(9.28) 

9.3. Design of Reliable Control 
489 
Fig. 9.14. System structure. 
By using the transformation 
1
0
0
 
3 =  [o 0
1
0
 
01 2, 
0
0
1
 
(9.29) 
we expand the system S to get 
-
.
 
(9.30) 
which is composed of two disjoint subsystems (Figure 9.15): 
(9.31) 
To illustrate simultaneous stabilization, we choose a decentralized con- 
u1 = -[I,, I121 31, 
uz = -[ i21 
I 2 2 1  52. 
(9.32) 
trol law 

490 
9. Reliable Control 
/-, 
Fig. 9.15. Expansion structure. 
The closed-loop system is now described as 
the structure of which is shown in Figure 9.16. This structure corresponds 
to e12 = e21 = 1, which is El of (9.23). After any one of the controllers fail, 
we have E 2  or E 3  in (9.23), which is equivalent to e l 2  = 0 or e21 = 0, that 
is, 
(9.34) 
are decoupled, as shown in Figure 9.17. If we assume for simplicity that 
a22 = a21 = a23 = a, kll = k22 = kl, and k12 = k21 = k 2 ,  the characteristic 
I 
- 
I 
- 

9.3. Design of Reliable Control 
491 
Fig. 9.16. Closed-loop system. 
equations become 
SUBSYSTEMS Sp, Sf: S' + (kl - a ) ~  
+ (Icz - k l ) ~  
= 0, 
SF: (S - a)(s + k1)[s2 + (kl - U)S + (2k2 - kl)a] = 0, 
(9.35) 
SYSTEM 
and the simultaneous stabilization conditions, which are necessary and suf- 
ficient, are 
(9.36) 
1 
2 
a < 0, 
kl > 0, 
k2 < - kl. 
Under these conditions, the system SF is connectively stable. 
From the stability conditions (9.36), we conclude that if the plant is 
unstable (a > 0), then S p  is unstable no matter what we choose for feedback 
gains kl and kz. The system S has a fixed mode at s = a, and we have the 
singular case as in Example 8.17. In this case, we have to contract SF to 
SF using the transformation 
1
0
 0
0
 
x =  [: 
1
:
 
'6 :] 
5, 
(9.37) 

492 
9. Reliable Control 
Fig. 9.17. Controller failure. 
and obtain 
-ki 
-k2 
0 
a
a
a
 
0 
-kg 
-kl 
2. 
(9.38) 
The characteristic equations are 
SUBSYSTEMS Sp, Sc: s2 + (kl - a)s + (k2 - k1)a = 0, 
SF: (s + kl)[s2 + (kl - a)s + (2k2 - kl)a] = 0, 
(9.39) 
SYSTEM 
and S F ,  Sf, and Sg are simultaneously stable if and only if 
a < kl < 2k2, 
where it was assumed that a > 0. 
(9.40) 

9.3. Design of Reliable Control 
493 
9.2. 
and Davison (1973), we may get a closed-loop system 
REMARK. If, in reliability design, we apply the method of Wang 
S F :  x =  
2. 
(9.41) 
which is stabilized by choosing sequentially the gains k11, k12, and k22 for 
the two blocks in (9.41). It is easy to see that when a > 0, the decoupled 
closed-loop subsystem 
sg: k2 = [ a  
a ] z2 
0 
-k22 
(9.42) 
is unstable no matter what we choose for the gain kz2 and the element a. 
This means that the method of Wang and Davison (1973) is not suitable 
when a system is composed of interconnected subsystems and is subject to 
structural perturbations. 
In order to formulate a definition of reliable control, we consider a sys- 
tem 
S i = A z + B u ,  
(9.43) 
with N controllers in a multicontroller configuration. We expand the system 
S to get 
3: h = AD? + BD?k + A&%, 
(9.44) 
which is a system composed of N subsystems. In (9.44), 2(t) E R" and 
~ ( t )  
E R" are the state and input of S at time t E R. The matrices are, as 
usual, 
= diag(A1, &, . . . , AN}, 
BD = diag(B1, B z ,  . . . , BN}, 
(9.45) 
& = (eijAij), 
where the blocks have dimensions corresponding to the decomposition 5 = 
(q, q, .. ., 5;)'. 

494 
9. Reliable Control 
Finally, we consider a multiple control system as a pair E = (SF, M), 
where SF is a contraction of SF and M is a Markov process defined in 
(9.12), and state the following: 
9.3. DEFINITION. 
r if 
A multiple control system E is reliable with degree 
(i) 
(ii) 
The process M has MTTF > T ;  
The equilibrium z = 0 of SF is connectively asymptotically 
stable in the large. 
So far only controller failures have been considered. Plant failures r e p  
resented by disconnections can be included as well. We show this fact by 
the following: 
9.4. 
ure 9.11, which is described as follows 
EXAMPLE. Let us reconsider the multiple control system of Fig- 
PLANT 2: 
x 4  = a 4 2 2 2  + u 3 ,  
CONTROLLER 3: 
~3 = -k324. 
The open-loop system S can be put into a matrix form as 
0
0
0
0
 
1
0
0
 
s x =  
(9.47) 
0 
a42 
0
0
1
 
where the state is z = (21, 
22, 2 3 ,  ~
4
)
~
 
and the input is u = (211, u2, 
~
3
)
~
.
 

9.3. Design of Reliable Control 
Choosing the transformation and complementary matrix as 
we get the expansion 
r o  o / o  o i o  
I
.
 
s: 3 =  
3 +  
495 
(9.48) 
(9.49) 
where the state is 3 = ( 2 1 ,  2 2 ,  2 2 ,  2 3 ,  ~
4
)
~
 
and input remains the same. 
The closed-loop system is 
-
.
 
S F :  3 =  
where, for compatibility of (9.50) with (9.47), we impose e 3 1 e 3 2  = 0. If 
a22 < 0, then connective stability of SF is assured by choosing positive 
values for the feedback gains k 1 1 ,  k 1 2 ,  k 2 1 ,  k 2 2 ,  and k 3 ,  and by verifying the 
inequalities 
Since (9.51) implies that the matrix of (9.50) is diagonally dominant 
[condition (iii) of Theorem 2.4 when di = 1, i E N ] ,  the system SF is 

496 
9. Reliable Control 
Fig. 9.18. Control configurations: (a) controller failures, (b) interconnection failures. 
connectively stable for the fundamental interconnection matrix 
E
=
l
O
O
.
 
[: I a] 
(9.52) 
This simply means that all structural configurations shown in Figure 9.18 
are all stable, with those in Figure 9.18b being the result of interconnection 
failures. We also note that the system includes both dynamic (C, and C,) 
and static (C3) controllers. 
The obvious weakness of Definition 9.3 is that it is suitable only for 
nonmaintained control systems. This limits the scope of reliable control 
considerably, and we turn our attention to systems where controllers are 
repairable after failure. 
9.4. Maintained Control Systems 
To include maintenance of controllers, we have to alter our definition 
of control reliability in a crucial way. We have to allow a control system to 
alternate between operating (stable) and failure (unstable) structures for 

9.4. Maintained Control Systems 
497 
an indefinite period of time. To capture the effect of these transitions, we 
have to redefine reliability in the context of stochastic stability, and use the 
Liapunov-type results of Kats and Krasovskii (1960) to derive conditions 
for stability under Markovian structural perturbations. 
Let us first derive a general result concerning stability of a linear system 
subject to Markovian perturbations. The most interesting feature of our 
stability analysis is the fact that we can treat a system in any of the Markov 
states as a separate subsystem. This opens up the possibility of using the 
stochastic version (Ladde et al. 1974) of vector Liapunov functions and 
establishing reliability of a control law in the framework of interconnected 
systems. 
A stochastic system J2 is described by a pair of equations 
E i = A[q(t)]x ( S ) ,  
p = IIp 
(M), 
(9.53) 
where S is a linear dynamic system with the state x E R", and M describes 
a Markov process q(t) with finite number of states Ek, k E N. The system 
n x n matrix A = ( & j )  is defined by 
iL..(Ek) 
23 
= eij(Ic)crij, 
(9.54) 
where the eij: N + (0, 1) are elements of a binary n x n interconnection 
matrix E(k), and the crij are given numbers. Each state Ek of the Markov 
process q(t) is associated with an interconnection matrix E(k) which, in 
turn, represents a certain structure of the dynamic system S .  In this way, 
M describes a structural dynamics underlying the dynamic process S. In 
(9.53), p E RN is the probability state vector, and II = (.rrij) is a constant 
state intensity matrix of appropriate dimension. 
Let us first explain the role of M via a matrix 

498 
9. Reliable Control 
Fig. 9.19. Transition rate diagram. 
which corresponds to the transition rate diagram shown in Figure 9.19. 
Each state Ei of M corresponds to a distinct linear system S defined in 
(9.53). The system S is jumping like a frog from one state of M to another 
according to the rates Xi and pi. At each state, the dynamics of S evolves 
as determined by the system defined at that state. Intuitively, the longer 
the system S resides at “stable” states of M, the more tendency it has to 
stay stable overall. The question is how long is long enough? 
9.5. 
A system 22 = (S, M) is said to be connectively 
stable if the equilibrium 2 = 0 of S is globally asymptotically stable in the 
mean. 
DEFINITION. 
To derive conditions for stability of S, we introduce a positive definite 
matrix H(Ek) and a matrix G(&) satisfying the equation 
where In is the n x n identity matrix. We also define an nN x nN matrix 
1 
(9.58) 
1 
G(E1) 
-r12H(E1) 
. . . -rl N H(E1) 
-rziH(E2) 
G(E2) 
. . . -r2~H(E2) 
G =  [ 
-rNlH(EN) 
-rN2H(EN) . . . 
G(EN 1 
............................................. 
and prove the following (Ladde and Siljak, 1983): 

9.4. Maintained Control Systems 
499 
9.6. THEOREM. 
positive definite. 
A system E = (S, M) is connectively stable if G is 
Prooj As a candidate for a Liapunov function, we choose V R x R” + 
R+ defined as 
V b : ,  77(t)l = zTH[77(t)1Z, 
(9.59) 
where H[77(t)] is an n x n symmetric positive definite matrix for all Ek, 
lc E N, of M. We define 
(9.60) 
Using (9.57) and (9.58), and choosing 
we compute 
= -XTGX, 
VX E RnN. 
(9.62) 
Positive definiteness of G in (9.62) and Theorem 4.1 of Ladde and Lak- 
shmikantham (1980) imply global asymptotic stability in the mean of the 
equilibrium x = 0 of S and, thus, connective stability of E. 
Q.E.D. 

500 
9. Reliable Control 
Testing positive definiteness of the matrix G in (9.58) may be difficult 
due to the high dimension nN of G. For this reason, an alternative test can 
be derived using the concept of vector Liapunov functions (Section 2.1). 
To show this, we introduce an N x N matrix W = (wke) defined as 
(9.63) 
and say that W is row-sum dominant diagonal if 
N 
k#i 
where A,( 
0 )  denotes the minimum eigenvalue. 
9.7. THEOREM. 
matrix W is row-sum dominant diagonal. 
A system E = (S, M) is connectively stable if the 
Prooj From the second inequality in (9.62), we get 
Vx E R", 
(9.65) 
where ~ ( x ,  
k )  = x'H(Ek)x is considered as the kth component ?& = w(x, k )  
of a vector Liapunov function 21 = (211, 212, . . . , UN)'. 
Now, if the matrix W 
of (9.63) is row-sum dominant diagonal, then, from Theorem 4.1 of Ladde 
and Lakshmikantham (1980), we conclude global asymptotic stability in 
the mean of the equilibrium x = 0 of S. 
Q.E.D. 
This general result is what we need in the analysis of multiple control 
schemes with controller repairs. We illustrate this fact by the following: 

9.4. Maintained Control Systems 
501 
9.8. EXAMPLE. 
The system S is described as in (9.27): 
Let us consider again the generic case of Figure 9.6. 
CONTROLLER 1: 21 = ~
1
,
 
(9.66) 
CONTPOLLER 2: 5 3  = ~
2
,
 
with a21 = a23 = 1.5, and a22 = 0. That is, 
S: j:=Ax+Bu, 
(9.43) 
where 
0
0
0
 
(9.67) 
We choose the overlapping decentralized control as before: 
and get the closed-loop system as 
- k2 
-k2 
-kl 
(9.69) 
Now, because a22 = 0, we have the singular case. This means that the 
structure @% in Figure 9.8 is unstable and represents the failure state. 
We assume, however, that the controllers can be repaired and the failure 
state is not a trapping state. The structural dynamics is described by the 
transition rate diagram of Figure 9.19, that is, by the state intensity matrix 
in (9.55), where XI and A2 are the failure rates of C1 and C2, and p1 and p2 
denote the repair rates of the same controllers. The four system matrices 
corresponding to the four states Ei, i = 1, 2, 3, 4, of the Markov process 

502 
9. Reliable Control 
are 
- k l - X  
-k2 
0 
21 = [ 1.5 
-A 
1.5 ] , 
0 
-k2 
-kl - X 
-kl - f ( A  + p) 
0 
0 
& = [  
0 
-',(A + 
l 7  
A 3  = [ 
1.5 
-;(A 
+ P )  
0 
0 
- k2 
-k1 - f ( X + p )  
(9.70) 
-ki - f ( X + p )  
-k2 
0 
0 
0 
-k1 - $(A + p) 
: 1, 
A*= [ 
0 
-p 
-k1- p 
0 
-k1 - p  
where A1 = A2 = X and p1 = p2 = p. 
The most remarkable fact is that A 4  in (9.70) is stable due to main- 
tenance of controllers (p # 0). Furthermore, in order to satisfy stability 
conditions (9.64), the repair rate p should be greater than the failure rate 
A, that is, p > A. If X = 0.4 and p = 0.55, then with k1 = 2.85 and 
k2 = 0.33 the condition (9.64) can be satisfied by a proper choice of the 
matrices G(Ek). This choice is made as in Section 2.2. We use a suitable 
transformation to get X,{G(Ek)fi-l(Ek)} = 2 a ~ ( A k ) ,  
which is the max- 
imum value that Xm{G(Ek)lT1(Ek)} 
can achieve. Upon returning to the 
original space, we note that X,{G(Ek)W1(Ek)} = X,{G(Ek)fi-'(Ek)}, 
which is the largest possible value for the diagonal elements in the inequal- 
ities (9.64). This choice satisfies the inequalities, and the stochastic system 
C = ( S ,  M) has the equilibrium 2 = 0 which is globally asymptotically 
stable in the mean. 
It is of interest to recognize the important fact that Theorems 9.6 
and 9.7 are general and can be applied to any linear control system with 
closed-loop matrix A(&), where Ek represent sensor or actuator failures. 
In 'other words, we do not have to choose decentralized control (9.68) in 
Example 9.8-any 
linear feedback could be tried. Multiple controllers, how- 
ever, allow for a decentralized reliability design of control that is in tune 

9.5. Notes and References 
503 
with microprocessor technology and modern fail-safe concepts in computer 
and system engineering. 
9.5. Notes and References 
Stability analysis of dynamic systems containing random parameters 
has been initiated by Kats and Krasovskii (1960) in the context of Lia- 
punov’s direct method. Parameter variations were represented by a Markov 
process, which provided a suitable framework for reliability design of con- 
trol systems with random structures (Krasovskii and Lidskii, 1961). The 
design was performed with respect to the expected value of a quadratic per- 
formance index. Wonham (1968) and Sworder (1976) used the Riccati-type 
approach of Kalman to come up with the optimal control law. 
Inspired by von Neumann’s approach to building a reliable computer, 
a multiple control system was invented (Siljak, 1978b) in the context of 
overlapping decentralized control. Multiplicity of controllers provided the 
necessary redundancy and, at the same time, eliminated the need for re- 
configuration of control each time the system enters another state of the 
Markov process which was a drawback of the early Riccati-type designs. By 
considering the dynamic system at each state as a separate subsystem of a 
large system, the concept of vector Liapunov functions was shown (Ladde 
and Siljak, 1983) to be suitable for ensuring stability of the overall control 
system. The use of several Liapunov functions was already suggested by 
Kats (1964) in a somewhat simpler problem. 
Recently, nonswitching optimal control laws have been proposed (Mari- 
ton and Bertrand, 1986) for multiple control systems with and without 
measurable states or modes. The numerical problem is to find a solution of 
interconnected Liapunov and Riccati equations, which is not easy, but can 
be done using homotopy algorithms (Mariton and Bertrand, 1985). Estima- 
tion can be added (Mariton, 1987a, b), but the estimator and control must 
be designed simultaneously, which makes the numerical problem twice as 
hard. For further discussion on the subject, including fault detection and 
isolation schemes with reconfiguration control devices, see the report and 
book by Mariton (1988b, 1990). 
Finally, we should note that reliability design using multiple controllers 
(Siljak, 1978a) is essentially a dual of the simultaneous stabilization prob- 
lem (Vidysagar and Viswanadham, 1982; Saeks and Murray, 1982). Instead 
of having a multiplicity of controllers that are supposed to stabilize a given 
plant, one is interested in determining if a single controller exists, which 
stabilizes simultaneously each member of a family of plants. The reason 

504 
9. Reliable Control 
is that the plants are various versions of a single plant undergoing struc- 
tural perturbations. If one thinks of a set of decentralized controllers as 
constituting a single controller, then connective stabilization of Chapter 2, 
which was initiated back in the early 1970s, is essentially the same concept. 
From this circle of ideas, a purely deterministic design of reliable control 
has evolved (Vidyasagar and Viswanadham, 1985) , whereby two controllers 
can be found that stabilize a single plant individually and acting together. 
All that is required is a strongly stabilizable plant. Initial results in these 
directions were obtained by Youla et al. (1976), who provided an important 
characterization of all controllers that stabilize a given plant. For a review 
of this type of results, see the books by Vidyasagar (1985) and Viswanad- 
ham et al. (1987). 
Bibliography 
Barlow, R. E., and F. Proschan (1975). Statistical Theory of Reliability and Life Testing. 
Bernard, R. (1980). The ‘no-downtime’ computer. Spectrum, 17, 33-37. 
Cho, Y. J., and 2. Bien (1989). Reliable control via an additive redundant controller. 
International Journal of Control, 50, 385-398. 
Feller, W. (1968). A n  Introduction to Probability Theory and Its Applications. Vol. I, 
3rd edition, Wiley, New York. 
Kats, I. Ya. (1964). On the stability of stochastic systems in the large. Prikladnaya 
Matematika i Mekhanika, 28, 36G372. 
Kats, I. Ya., and N. N. Krasovskii (1960). On the stability of systems with random 
parameters. Prikladnaya Matematika i Mekhanika, 24, 809-823. 
Krasovskii, N. N., and E. A. Lidskii (1961). Analytical design of controllers in systems 
with random attributes. Avtomatika i Telemekhanika, 22, 1021-1025, 1141-1146, 
and 1289-1294. 
Krtolica, R. (1984). A singular perturbation model of reliability in system control. Au- 
tomatica, 20, 51-57. 
Ladde, G. S., and V. Lakshmikantham (1980). Random Differential Inequalities. Aca- 
demic Press, New York. 
Ladde, G .  S., and D. D. Siljak (1983). Multiplex control systems: stochastic stability 
and dynamic reliability. International Journal of Control, 38, 515-524. 
Ladde, G. S., and D. D. Siljak (1989). Convergence and stability of distributed stochastic 
pseudogradient algorithms. IEEE Transactions, AC-35, 665472. 
Ladde, G. S., V. Lakshmikantham, and P. T. Liu (1974). Differential inequalities and sta- 
bility and boundedness of stochastic differential equations. Journal of Mathematical 
Analysis and Applications, 48, 341-352. 
Mariton, M. (1987a). Joint estimation and control of jump linear systems with mul- 
tiplicative noises. ASME Transactions, Journal on Dynamics, Measurement, and 
Control, 109, 24-28. 
Mariton, M. (198713). Jump linear quadratic control with random state discontinuities. 
Autornatica, 23, 237-240. 
Holt, Rinehart, and Winston, New York. 

Bibliography 
505 
Mariton, M. (1988a). Almost sure and moments stability of jump linear systems. Systems 
and Control Letters, 11, 393-397. 
Mariton, M. (1988b). Control of nonlinear systems with Markovian parameter changes. 
Laboratoire des Signauz et Systemes, CNRS-ESE, Gif-sur-Yvette, Report No. 86- 
1391. 
Mariton, M. (1989). On systems with non-Markovian regime changes. IEEE Transac- 
tions, AC-34, 346-349. 
Mariton, M. (1990). Jump Linear Systems in Automatic Control. Marcel Dekker, New 
York. 
Mariton, M., and P. Bertrand (1985). A homotopy algorithm for solving coupled Riccati 
equations. Optimal Control Applications and Methods, 6, 351-357. 
Mariton, M., and P. Bertrand (1986). Improved multiplex control systems: dynamic 
reliability and stochastic optimality. International Journat of Control, 44, 219-234. 
Moore, E. F., and C .  E. Shannon (1956). Reliable circuits using less reliable relays. 
Journal of the Franklin Institute, 262, 191-208 and 281-297. 
Mori, K., K. Sano, and H. Ihara (1981). Autonomous controllability of decentralized 
system aiming at fault-tolerance. Proceedings of the 8th IFAC Congress, Kyoto, 
Japan, 12, 129-134. 
Pakshin, P. V. (1983). Stability of discrete systems with random structure under steadily 
acting disturbances. Avtomatica i Telemekhanika, 44, 74-84. 
Saeks, R., and J. Murray (1982). Fractional representation, algebraic geometry and 
simultaneous stabilization problem. IEEE Transactions, AC-27, 895-903. 
Sandler, G. H. (1963). System Reliability Engineering. Prentice-Hall, Englewood Cliffs, 
New Jersey. 
Siljak, D. D. (1978a). Large-Scale Dynamic Systems: Stability and Structure. North- 
Holland, New York. 
Siljak, D. D. (1978b). Dynamic reliability using multiple control systems. Proceedings of 
the 2nd Lawrence Symposium on Systems and Decision Sciences, Berkeley, Califor- 
nia, 173-187. 
Siljak, D. D. (1980). Reliable control using multiple control systems. International Jour- 
nal of Control, 31, 303-329. 
Siljak, D. D. (1981). Dynamic reliability of multiplex control systems. Proceedings of the 
8th IFAC Congress, Kyoto, Japan, 12, 110-115. 
Siljak, D. D. (1987). Reliability of Control. Systems and Control Encyclopedia, M. G. 
Singh (ed.), Pergamon Press, Oxford, UK, 4008-4011. 
Sworder, D. D. (1976). Control of systems subject to sudden change in character. Pro- 
ceedings of the IEEE, 64, 1219-1225. 
Tsui, C. C .  (1989). On the solution to the state failure detection problem. IEEE Trans- 
actions, AC-34, 1017-1018. 
Vidyasagar, M. (1985). Control System Synthesis: A Factorization Approach. MIT Press, 
Cambridge, Massachusetts. 
Vidyasagar, M., and N. Viswanadham (1982). Algebraic design techniques for reliable 
stabilization. IEEE Transactions, AC-27, 1085-1095. 
Vidysagar, M., and N. Viswanadham (1985). Reliable stabilization using multi-controller 
configuration. Automatica, 21, 599-602. 
Viswanadham, N., V. V. S. Sarma, and M. G. Singh (1987). Reliability of computer and 
control systems. North-Holland, Amsterdam, The Netherlands. 
von Neumann, J. (1956). Probabilistic logic and the synthesis of reliable organisms from 
unreliable components. Annals of Mathematics, No. 34, C. E. Shannon and E. F. 
Moore (eds.), Princeton University Press, Princeton, New Jersey, 43-95. 

506 
9. Reliable Control 
Wang, S. H., and E. J. Devison (1973). On the stabilization of decentralized control 
systems. IEEE Transactions, AC-18, 473-478. 
Wonham, W. M. (1966). Liapunov criteria for weak stochastic stability. Journal of Dif- 
ferential Equations, 2, 195-207. 
Wonham, W. M. (1968). On a matrix equation of stochastic control. SIAM Journal of 
Control, 6, 681-697. 
Wonham, W. M. (1970). Random differential equations in control theory. Probabilistic 
Methods in Applied Mathematics, 11, A. T. Bharucha-Reid (ed.), Academic Press, 
New York, 131-212. 
Youla, D. C., H. A. Jabr, and J. J. Bongiorno, Jr. (1976). Modern Wiener-Hopf design 
of optimal controllers. Part 11: The multivariable case. IEEE Transactions, AC-21, 
31S338. 

Appendix 
Graph- T heore t ic Algorithms 
In this appendix, we wish to present a collection of the basic graph-theoretic 
algorithms that underlie our analysis of structured systems throughout the 
book. Our main objective is to demonstrate the inherent efficiency of these 
algorithms and their easy implementation in algol-type languages, such as 
PASCAL and C. We shall also comment on the computational complexity 
of some of these algorithms, because it is this feature that makes the graph- 
theoretic approach to complex systems so attractive in applications. At the 
end of the appendix, we will describe a software package for graph-theoretic 
analysis of dynamic systems, which is presently being developed for control 
design of complex systems. Finally, we should note that, in this section, we 
assume some familiarity of the reader with data structures (e.g., Horowitz 
and Sahni, 1990) and algorithms in the graph-theoretic framework (e.g., 
Swamy and Thulasiraman, 1981). 
Depth-First Search 
In structural analysis and decompositions of complex systems, the fun- 
damental role is played by input and output reachability: can each state 
vertex of a system digraph be reached from at least one input vertex and 
can each state vertex reach at least one output vertex (Section 1.2)? An 
ideal method for verifying these properties is the depth-first search (Tarjan, 
1972; see also Swamy and Thulasiraman, 1981). 
To determine reachability properties of a system digraph D = (V, E) 
by Depth-First Search (DFS), all we have to do is construct so called DFS 
trees rooted at the input vertices and see if they span D. To show how this 
is done, we need some notation. An edge of D is an ordered pair (v, w) of 
vertices, where v is the tail and w is the head of the edge. We also recall 
507 

508 
Appendix. Graph-Theoretic Algorithms 
(e.g., Harary, 1969) that a directed (rooted) tree T is a digraph, which is 
connected (directions of the edges are ignored), has one vertex which is 
the head of no edges called the root, and all other vertices are the head 
of exactly one edge. Specifically, if (v, w) is an edge of T we denote it by 
v + w and call v the father of w and w the son of v. In a path Pk of T from 
v to w, v is an ancestor of w and w is a descendant of v. A tree is a spanning 
tree of D if T is a subgraph of D and T contains all the vertices of D. A 
disjoint set F of trees is called a forest. A collection of trees containing all 
vertices of D is said to be a spanning forest of D. 
To represent a system digraph, we use the adjacency list, which requires 
a minimal storage space; only the existing edges of the digraph are recorded. 
This fact is especially significant in large sparse systems. Furthermore, the 
adjacency list representations are ideal for the use of linked list data struc- 
tures to maximize the speed of the proposed algorithms. As is standard 
(e.g., Horowitz and Sahni, 1990), the nodes in a list are nodes adjacent to 
the head node of the list. Each node contains three fields: CH for the type 
of node, VERTEX for the number of the node, and LINK for the pointer 
to nodes in the list. The head node is used for sequential random access to 
any vertex in the adjacency list of the digraph. 
We do not include the self-loops of D and we start DFS at any vertex 
u, 
which we call a root of DFS tree. This vertex is now visited. We pick any 
edge incident on u and traverse it to visit an adjacent vertex v. The edge 
u + v is now examined and becomes an edge of a DFS tree rooted in u. At 
v we choose an edge incident on v and traverse it to another vertex w. If w 
has not been visited yet, then we continue the search from w. Otherwise, we 
go back to v, the father of w, and try another unexamined edge incident 
on v. If none exists, we go back upstream to the father of v and repeat 
the search. In this way, DFS generates a tree over the digraph D. The 
search from the root terminates when no unvisited vertex can be reached 
from any of the visited ones. Then, the next vertex in the list is selected 
as a root of another DFS tree, and the procedure is repeated. The DFS 
procedure terminates when no vertex of a given digraph is left unsearched 
and a spanning DFS forest of the graph is obtained. 
Whenever a vertex w is visited for the first time, it is included in the 
DFS tree and assigned a depth-first number DFN (w) = i. This number is 
a distinct integer, which indicates that w is the ith vertex of the DFS tree 
(or forest). If w has already been visited, then the edge (v, w) is a forward, 
back, or cross edge. If w is a descendant of v in a DFS tree (there is a 
directed path of the tree from v to w), then (v, w) is a forward edge. If w 
is an ancestor of v (that is, v is a descendant of w), then (v, w) is a back 
edge. If v and w are not related in the DFS forest and DFN(v) > DFN(w), 
then (v w) is a cross edge. 

Strong Components 
509 
A.l. ALGORITHM (DFS). 
BEGIN 
PROCEDURE DFS 
{given a digraph D = (V, E )  with n vertices by the 
adjacency list; initialize Boolean array VISITED to FALSE} 
BEGIN 
INTEGER i 
FORi: = 1 TO n DO 
FOR i: = 1 TO n DO 
VISITED(1): = FALSE; 
BEGIN 
IF VISITED(i) = FALSE; 
THEN SEARCHFROM( i) ; 
END; 
END; {end DFS tree} 
PROCEDURE SEARCHFROM(v); 
{carries out DFS from unvisited vertex v} 
BEGIN 
VISITED(v): = TRUE; 
FOR w in the adjacency list on v DO 
SEARCHFROM(w); 
END; {searchfrom} 
END; {end DFS spanning forest} 
An example of DFS over a digraph is shown in Fig. A.l. DFS numbers 
are shown next to each vertex. The edges of the two trees (a forest) are 
shown as solid lines, while the other three types of edges are drawn as 
dashed lines. 
Strong Components 
All graph-theoretic algorithms for dynamic systems can be greatly sim- 
plified by finding first the strong components of the system digraph. This 
fact was utilized throughout Chapter 1 starting with Section 1.3, where 
strong components were defined, and was subsequently used in decompo- 
sition schemes of Chapters 6 and 7. It was also mentioned there that Tar- 
jan’s version of the depth-first search can detect the strong components in 
O(max{n, e } )  time for a digraph of n vertices and e edges. In this section, 
we describe this algorithm following the original paper of Tarjan (1972). A 
more detailed presentation of the same algorithm can be found in (Swamy 
and Thulasiraman, 1981). 
Let us consider a digraph D = (V, E). Let ZI and w lie in the same 
strong component K. If F is the DFS forest of D, then Y and w have a 

510 
Appendix. Graph-Theoretic Algorithms 
1 
\ 
/ 
/ 
. 
Fig. A.l. DFS tree. 
common ancestor in F. Furthermore, if u is the highest numbered ancestor 
of v and w, then u lies in K. The vertices of K define a subtree in F, 
the root of which is called the root of K. In this way, Tarjan reduced the 
problem of finding the strongly connected components of D to the problem 
of finding the roots of these components. A necessary new notion in this 
context is LOWLINK (v), which is the lowest numbered vertex in the same 
component as v and which is reachable from v by a directed path containing 
at most one back edge or one cross edge. Furthermore, all the edges of such 
a directed path lie necessarily in the same component. Then, as shown by 
Tarjan, the vertex v is the root of some strong component K of D if and 
only if LOWLINK (v) = v. 
Most importantly, LOWLINK can be computed by DFS. For a vertex, 
which has been reached for the first time, we set LOWLINK (v) = DFN 
(v) and store it on a stack. If a cross edge (v, w) is examined, when both 
v and w are in the same strong component, then LOWLINK (v) is set to 
the minimum of its current value and of the DFN (w). When a back edge 
(v, w) is explored, then LOWLINK (v) is set again to the minimum of its 
current value and DFN (w). After the search of the son w of v is completed 
and DFS returns to v, we set LOWLINK (v) equal to the minimum of its 
current value and LOWLINK (w). Forward edges are ignored altogether. 

Reachability 
511 
A.2. ALGORITHM (STRONGCONNECT). 
BEGIN 
INTEGER i; 
PROCEDURESTRONGCONNECT 
BEGIN 
i : = i + l  
LOWLINK (v): = DFN (v): = i; 
put v on stack of points 
FOR w in the adjacency list of v DO 
BEGIN 
IF 20 is not yet numbered THEN 
{ ( v ,  w) is a tree arc} 
STRONGCONNECT(w); 
LOWLINK(v): = min (LOWLINK(v), LOWLINK(w)); 
BEGIN 
END; 
ELSE IF DFN(w) < DFN(v) DO 
BEGIN 
{(v, w) is a back or cross edge} 
IF w is on stack THEN 
LOWLINK (v): = min( LOWLINK ( v )  , DFN( w )) ; 
END; 
END; 
BEGIN 
IF(LOWLINK(v) = DFN(v)) THEN 
{v is the root of as strong component} 
start a new strong component; 
WHILE w on top of stack satisfies 
DFN(w) 2 DFN(v) DO 
delete w from stack and put w in current component; 
END; 
END; 
i : = o  
empty stack of points 
FOR w a vertex IF w is not yet numbered THEN STRONGCONNECT(w); 
END; 
In Fig. A.2, we show the LOWLINK and DFN assignments. The strong 
components are {l}, {2}, (3, 4, 5}, and (6, 7, 8, 9, lo}. 
Reachability 
It is obvious that DFS is ideal for use in testing input and output 
reachability defined in Section 1.2. To determine if a digraph D is input 
reachable, all one has to do is apply DFS to input vertices to see if all state 
vertices can be reached from at least one input vertex. 

512 
Appendix. Graph-Theoretic Algorithms 
(71 
4 
Fig. A.2. DFS tree with LOWLINK numbers. 
A.3. ALGORITHM (INREACH). 
BEGIN 
initialize VISIT-X to FALSE 
VISIT-X(x): = FALSE; 
BEGIN 
FOR all state vertices x DO 
PROCEDURE INREACH 
FOR all input vertices u DO 
DFS (u) 
: 
FOR all state vertices x DO 
IF VISIT-X(x) = FALSE 
THEN GOTO 1; 
BEGIN 
WRITE (’digraph is input reachable’); 
GOTO 2; 
1) 
END; 
FOR all state vertices x DO 
IF VISIT-X(x) = FALSE; 
THEN WRITE (’state x is not input reachable’); 
2) 
END; 

Reachability 
513 
Output reachability can be tested by applying Algorithm A.3 to the 
dual of D at the output vertices. This algorithm is called OUTREACH 
and is easily implemented using an inverse adjacency list for D. 
When, in addition to input and output reachability, DFS is applied to 
unvisited state vertices, then the reachability matrix R of (1.21) can be 
computed with minimal effort. 
A.3. ALGORITHM (MATREACH). 
PROCEDURE MATREACH 
BEGIN 
FOR all input vertices u DO 
{the 'marking' variables VISIT-X & VISIT-Y 
are set FALSE before each search starting from 
an input vertex u }  
FOR all state vertices z DO 
VISIT-X(x) = FALSE; 
FOR all output vertices y DO 
VISIT-Y(y) = FALSE; 
DFS (u) ; 
{establish paths between input & states, that is, matrix G }  
FOR all state vertices z DO 
IF VISIT_X(x) = TRUE 
THEN u -+ x; 
{establish paths between inputs & outputs, that is, matrix 0) 
FOR all output vertices y DO 
IF VISIT-Y(y) = TRUE 
THEN u --t y; 
FOR all state vertices x DO 
END; 
BEGIN 
(the 'marking' variables VISIT-X & VISIT-Y 
are set FALSE before each search starting from 
a state vertex z} 
FOR all state vertices x DO 
VISIT-X(z): = FALSE; 
FOR all ouput vertices y DO 
VISIT_Y(y): = FALSE; 
DFS(x): 
{establish paths between states, that is, matrix F }  
FOR all state vertices x DO 
IF VISIT_X(z) = TRUE 
THEN x -+ x; 
{establish paths between states & outputs, that is, matrix H }  
FOR all output vertices y DO 
IF VISIT_Y(y) = TRUE 
THEN x -+ y; 
END; 
END; 

514 
Appendix. Graph-Theoretic Algorithms 
The reachability matrix R is essential for the hierarchical (LBT) de- 
compositions (Algorithm 6.12). 
Generic Rank 
We recall from Section 1.4 that generic rank of a structured matrix is 
equal to its maximum number of nonzero elements, no two of which lie in 
the same row or column. These nonzeros can be made to appear on the 
diagonal of a permuted matrix to form the maximum transversal. The prob- 
lem of selecting the transversal has been studied for a long time in various 
fields under different names: systems of distinct representatives, maxi- 
mum assignment, an output set, maximum or perfect matching, etc. The 
long history of the problem was reviewed by Duff (1981a), who proposed 
an algorithm to determine the maximum transversal of a given matrix, 
that is, its generic rank. The algorithm, which is based upon DFS, is de- 
scribed in this section. It is used in structural controllability (Section 1.4), 
in structurally fixed modes (Section 1.6, Lemma 1.55), and in Chapter 5 
(Theorem 5.15), when we need a test for the existence of a suitable match- 
ing (see Remarks 5.16 and 19). 
Following Duff (1981a), we obtain the transversal recursively in n steps, 
where n is the order of the matrix. At the kth step we have a transversal 
for a submatrix of order Ic. At each step, Duff associates an unorthodox 
digraph with the matrix in such a way that every vertex corresponds to a 
distinct row of the matrix, and an edge exists from vertex io to vertex il if 
there is a column, say j 1 ,  so that the nonzero element ( i l ,  j l )  is currently 
in the transversal and, in addition, the element (io, j 1 )  is nonzero. When 
the current transversal includes the nonzeros (il, jl), (iz, j z ) ,  . . . , ( i k ,  j k ) ,  
we consider a sequence of nonzeros (io, jl), (21, j z ) ,  . . . , ( i k - 1 ,  j k ) .  If there 
is a nonzero at ( a k ,  j k + l )  and if none of the nonzeros in the ioth row or the 
jk+lth column are in the current transversal, we can perform a reassignment 
in the transversal by replacing the nonzeros (it, jt), ! 
= 1, 2, . . . , k, by the 
nonzeros (it, jt+l), ! 
= 1, 2, . . . , k. The reassignment increases the length 
of the transversal by one. A reassignment chain is illustrated in Fig. A.3, 
where the three nonzeros shown in squares are replaced by the four encircled 
nonzero elements. 
The most interesting part of Duff’s algorithm is the use of DFS with a 
look-ahead technique to find an appropriate reassignment chain. If (iz, jz), 
say, is a present assignment and (21, j 2 )  is a nonzero, we apply DFS to the 
above defined digraph starting at any unassigned row (vertex) 20, regularly 
the next row of the matrix. DFS search along a path terminates when we 
reach a nonzero ( i k ,  jk+l) and when j k + l  is an unassigned column of the 

Generic Rank 
515 
Fig. A.3. A reassignment chain. 
matrix; the vertex ik is a free vertex. By backtracking from ak to io , we 
obtain the reassignment chain and complete the kth step of the transversal 
algorithm. In performing the DFS search it is crucial that at each vertex 
we check all of the unvisited vertices that can be reached from the current 
one, if any are free. If a free vertex is found we got a cheap assignment. 
This short-cut in the Duff’s algorithm is called the look-ahead technique. 
The cheap assignment would have taken place in the chain of Figure A.3 
if the shaded areas had not been all zeros. If e is the number of nonzeros 
of the matrix, then the additional effort due to the look-ahead technique is 
only O(e). This is a small price to pay for a considerable savings in time, 
provided an auxiliary pointer array is used for the cheap assignment phase 
of the algorithm to make sure that no more than e nonzeros are visited 
during each phase. 
For a pseudcxode presentation of Duff’s algorithm, which is termed 
GENRANK, we introduce the variable NUMNX. This variable represents 
the length of the transversal, that is, the generic rank of the matrix. The 
Boolean variable ASSIGN(Z) checks if the row i has been assigned already 
in the DFS search. 
A.4. ALGORITHM (GENRANK). 
BEGIN 
NUMNX: INTEGER 
NUMNX: = 0 
PROCEDURE GENRANK 
BEGIN 
FOR w the next examined row DO 
BEGIN 
1) 
i: = 0; 
REPEAT i: = i + 1 
UNTIL ((A(w, 
i) <> 0) AND 
(ASSIGN(i): = FALSE)) 
OR (i > n); 

516 
Appendix. Graph-Theoretic Algorithms 
IF i 2 n THEN 
BEGIN 
make this first nonzero an assignment 
AND perform reassignment on all rows in path 
ASSIGN(i): = TRUE; 
GENRANK( A); 
END; 
IF there are nonzeros in row w that have not been examined 
THEN 
BEGIN 
FOR v the next nonzero in row w DO 
IF 
THEN 
has not been accessed during this pass THEN 
BEGIN 
put row y with assignment column v on path 
w: = y  
GOTO 1 
END; 
ELSE GOTO 2; 
END; 
BEGIN 
ELSE 
IF there exists a previous row x on path 
THEN 
BEGIN 
5: = w; 
GOTO 2; 
END; 
{the matrix has not full generic rank 
but we continue to maximize assignment} 
GENRANK( A); 
ELSE 
END; {ELSE corresponds to line marked 2) 
END; {FOR w the next unexamined row} 
END; {GENRANK} 
IF NUMNX = n THEN matrix has full generic rank; 
END: 
The worst case bound of this algorithm is O(ne), where n is the order of 
the matrix and e is the number of its nonzero elements. Duff (1981a) claims 
that in realistic examples, the complexity is much better and equals O(n) 
+ O(e). He provides a comparison with other existing algorithms and, in 
a separate paper (Duff, 1981b), gives a code in FORTRAN. 
Decompositions 
The LBT and EPSILON decompositions where described in Chapters 6 
and 7, respectively. The LBT decompositions are suitable for sparse sys- 

Decompositions 
517 
tems, where they can take advantage of zero elements and produce hier- 
archically ordered subsystems with independent inputs and outputs. De- 
centralized controllers and estimators can then be built piece-by-piece with 
assured stability and satisfactory performance. On the other hand, the EP- 
SILON decompositions can be applied to dense matrices as well, but stabil- 
ity of a subsequent decentralized design would depend heavily on the size 
of the chosen value for the threshold epsilon. As explained in Section 7.6, in 
a control .problem of large dimension, both decompositions should be used, 
with the LBT decomposition being applied first. 
The LBT Algorithm (6.12) can be sped up considerably by using the 
condensation of the original digraph, which is obtained by STRONGCON- 
NECT (Algorithm A.2) following Remark 6.14. We also note (Remark 6.15) 
that the algorithm can be used to provide either input or output LBT 
decompositions, which is a much easier task than finding input-output 
decompositions (see Remark 6.16). Finally, we recall (Remark 6.18) that 
structural controllability and observability of the overall system should be 
tested using input and output LBT decompositions. The reason is that 
an LBT reachable decomposition is structurally controllable (observable) 
if and only if the corresponding hierarchical composite matrices of the sub- 
systems have full generic rank. In other words, the generic rank condition 
for the overall system can be tested recursively on the subsystem levels, 
which can reduce considerably the dimensionality of controllability and 
observability tests. 
With regard to the EPSILON decomposition, we provide here additional 
information about the corresponding Algorithm 7.4 and give a pseude 
code. We first note that to identify the weakly coupled subsystems by 
connected (not strongly connected!) components of D', we have to obtain 
the undirected version of the - original digraph D. This we do by forming a 
new interconnection matrix E = ( & j )  from the original matrix E = (eij) 
such that r5i3 = 1 if and only if eij =-1 or eiz = 1. Then, we construct a 
new adjacency list corresponding to E and D. To detect the components 
of D' we identify the strong components of DE 
using STRONGCONNECT 
(Algorithm A.2). 
In Section 7.3, when we considered control applications, only state and 
inputs were involved. If not all states are available for measurement and 
we have an output equation, then epsilon decomposition can be carried out 
with three different values of E ,  namely E A ,  EB, and EC. As in the case of 
hierarchical decompositions, the input and output decompositions can be 
performed independently using the pairs (€A, E B )  and ( E A ,  EC). The output 
decomposition using ( E A ,  E C )  is obviously a dual of the input decomposition 
and the discussion in Section 7.3 applies to observer designs in a straight- 
forward way. All these different options are made available in the program. 
The user chooses different values for E A ,  EB, and EC. At the start, EB and EC 

518 
Appendix. Graph-Theoretic Algorithms 
are set to zero and an E A  decomposition is obtained first. Then, EB and EC 
are chosen to minimize the sets N,, and Nxy , or a set Nuzy = Nun N, n Ny 
if a joint controller-observer design is attempted. 
For every chosen triple ( E A ,  E B ,  E C ) ,  we check the decoupled subsystems 
( € A  = EB = EC = 0) for reachability. If subsystems are not reachable, then 
they would remain unreachable for any larger values of E A ,  E B ,  and E C .  
One can continue to increase these values if reachability can be restored by 
combining unreachable and reachable subsystems. 
After a satisfactory grouping of states is achieved, the values of EB 
and EC can be chosen to minimize the sets N,, and Nxy, while retaining 
reachability. We can also remove some inputs or outputs from state clusters 
that have their own inputs and outputs, and keep them for states that have 
no other inputs and outputs. The procedures that attach the inputs and 
outputs to states are CONDU and CONDY. A pseudcxode for epsilon 
decomposition with fixed E A ,  E B ,  and EC is given by the following: 
A.5. ALGORITHM (EDEC). 
PROCEDUREEDEC 
BEGIN 
{arrays A, B, C have the same dimensions as A, B, C}. 
FOR all i, j DO 
BEGIN 
IF l~ijl 5 
IF Ibijl 5 EB THEN beij = 0 ELSE beij = 1 
IF 1qjJ 5 e c  THEN ccij = 0 ELSE ceij = 1 
THEN ~ c i j  = 0 ELSE ucij = 1 
END; 
{find connected components of states} 
FOR all i, j DO 
IF (Ae[i, j ]  = 1 OR Aeb, i] = 1) 
THEN construct edge (zj, 
q ) ;  
FOR i: = 1 to # of states DO 
STRONGCONNECT(i); 
{insert back the original edges into components and test reachability} 
FOR each connected components DO 
BEGIN 
FOR i and j in component p DO 
(associate inputs and outputs with component p }  
CONDU (U set); 
CONDY (Y set); 
{test reachability of component p }  
INREACH (U set); 
OUTREACH (Y set); 
IF A[i, j ]  # 0 THEN A[i, j ]  = 1; 
END; 
END; 

Graphpack 
519 
Nested epsilon decompositions, which call EDEC, are obtained by the 
following: 
A.6. ALGORITHM (ENEST). 
BEGIN 
REAL 
PROCEDURE ENEST 
BEGIN 
EA: = min la,, 1; CB: = 0.0; EC: = 0.0 
EDEC 
Print out E A ,  E B ,  EC and subsystems; 
IF unreachable 
€A: = € A  -t 6A 
THEN combine unreachable clusters of states with reachable 
cluster of states; 
IF ( ( € A  < max [uijl, i # j )  AND (reachable)) 
{based on size of cluster user reads in value of E A }  
READ ( E A ) ;  
EDEC 
{vary values of E B  and E C }  
THEN GOT0 1; 
E B :  = minIbZJI; EC: = minIGjl; 
EDEC; 
IF reachable THEN 
BEGIN 
Print out € A ,  E B ,  cc and subsystem 
E B :  = EB + 6 8 ;  EC: = EC + 6c; 
END; 
END; 
END; 
It is important to note that the EPSILON decomposition procedure is 
very much user-dependent. Finding the appropriate values for the triple 
( E A ,  E B ,  E C )  may require considerable interactive use of the ENEST algo- 
rithm. 
Graphpack 
An interactive software package (GRAPHPACK) is presently under de- 
velopment (LaMont, 1990), with the objective of integrating the above algo- 
rithms to offer the user a suitable environment for graph-theoretic analysis 
of dynamic systems. The package is menu-driven to allow a casual or new 
user to utilize the package immediately, as well as to enable a serious user 

520 
Appendix. Graph-Theoretic Algorithms 
to monitor various algorithms in a step-by-step fashion. In the interactive 
mode, the central role is played by the supervisor. It is designed to provide 
all the necessary linkage between individual modules in the package, when a 
sequence of operations is executed. The supervisor controls the operation of 
the preprocessors and postprocessors, as well as the individual algorithms, 
thus creating a medium for the optimal utilization of power and speed of 
the graph-theoretic approach to control design of complex systems. 
Bibliography 
Duff, I. S. (1981a). On algorithms for obtaining a maximum transversal. ACM Trans- 
Duff, I. S. (1981b). ALGORITHM 575: Permutations for a zerpfree diagonal [Fl]. ACM 
Harary, F. (1969). Graph Theory. Addison-Wesley, Reading, Massachusetts. 
Horowitz, E., and S. Sahni (1990). Fundamentals of Data Structures in Pascal. Com- 
puter Science Press, New York. 
LaMont, D. (1990). GRAPHPACK: A Software Package for Graph-Theoretic Analysis 
of Control Structures. Ph.D. Thesis, Santa Clara University, Santa Clara, California. 
Swamy, M. N. S., and K. Thulasiraman (1981). Graphs, Networks, and Algorithms, 
Wiley, New York. 
Tarjan, R. (1972). Depth-first search and linear graph algorithms. SIAM Journal on 
Computing, 1, 146-160. 
actions on Mathematical Software, 7, 315-330. 
Transactions on Mathematical Software, 7, 387-390. 

Index 
1 
A 
Absolute stability, 240 
Adaptation gain, 276, 286 
Adaptive control, 276 
centralized, 279, 288 
decentralized, 276, 282, 297 
output, 295 
robotics, 304 
state, 276 
Adjacency matrix, 2 
Aggregation, 426 
Algorithm, 507 
acyclic partitions, 334 
depth-first search, 509 
epsilon decomposition, 381, 518 
generic rank, 515 
input decomposition, 315 
matching, 267, 514 
reachability, 512 
reachability matrix, 9, 513 
strong components, 511 
Warshall’s, 9 
Almost invariant subspace, 248 
Antecedent set, 7 
AsymptotiE observer, 188 
Automatic generation control, 448 
B 
Binary matrix, 2 
Block diagonal dominance, 402 
Boolean operations, 9 
Boolean representation, 3 
Centralized control, 143 
Circle criterion, 131, 245, 246 
Closed-loop system, 90, 92 
Coherent structures, 479 
Companion matrix, 93 
Complementary function, 454 
Complementary matrix, 427 
Complete state information, 359 
Condensation, 13, 19, 335 
Conical condition, 239 
Connected component, 380 
Connective stability, 70, 114 
applications of, 115 
exponential, 95 
nested, 389 
stabilization, 89, 95 
Contraction, 426 
521 

522 
Index 
Control, 41, 128 
adaptive, 276 
centralized, 143 
contractible, 439 
decentralized, 93, 211 
degenerate, 226 
dynamic output, 38, 239 
fault-tolerant, 484 
hierarchical, 182 
LQG, 209 
optimal, 156 
overlapping, 442 
reliable, 493 
Controllability, 7 
Controller, 37, 240 
decentralized, 38, 239 
dynamic, 37, 267 
failure, 475, 478 
hot spare, 474 
maintenance, 495 
multiple, 479 
reliable, 481 
disjoint union, 54 
family of, 57 
mutually disjoint, 53, 255 
spanning, 55 
Cycle, 12 
D 
Decentralized cont.rol 
dynamic, 239 
optimal, 150, 168 
overlapping, 442 
stabilizing, 87, 93 
stochastic, 223 
structure of, 37 
suboptimal, 137 
Decentralized fixed modes, 41 
Decentralized observer, 204 
Decomposition 
disjoint, 32, 417 
epsilon, 378 
input, 314 
input-output, 337 
mathematical, 31 
nested, 380 
overlapping, 416 
physical, 31, 33 
space, 249 
Degenerate control, 226 
Degree of suboptimality, 129 
Depth-first search, 508 
algorithm for, 509 
Diagonal dominance, 495 
block, 402, 407 
overlapping, 465 
quasi, 73 
quasi-block, 306, 400 
transfer function, 306 
Dichotonic control structures, 475 
Digraph, 3 
acyclic, 12 
condensation of, 13 
level assignment of, 318 
level of, 14 
strong component of, 13 
Dilation, 26, 325 
Discrete system, 115, 408 
Disjoint decomposition, 32, 417 
Dynamic output control, 267 
E 
Edge, 3 
Eigenvalue assignment, 323 
Epsilon decomposition, 378 
algorithm for, 381, 519 
nested, 380, 386 
overlapping, 407 
scaling, 384, 406 
Equilibrium, 69 
Equivalence 
classes, 12, 379 
pseudo, 434 
structural, 5 
zero-state, 434 
Estimator, 217 
Expansion, 426 
nonlinear, 456 
F 
Factorization method, 307 
Fault-tolerant control, 484 
Feedback, 36 
adaptive, 295 
decentralized, 93 
dynamic output, 37, 239 
high-gain, 98, 205, 303 

Index 
523 
state, 66, 87 
static output, 36 
structure constraints, 41 
Fixed modes, 41, 44 
Fundamental interconnection matrix, 69, 225 
G 
Gain margin, 133, 148, 163 
Gain reduction tolerance, 133, 149, 163 
Gain reversal, 133 
Gauss-Seidel estimator, 372 
Generic rank, 22 
algorithm for, 516 
full, 22 
Global control, 87, 134, 191 
H 
Hierarchical decomposition, 331 
algorithm for, 334 
input, 314 
input-output, 330 
Hierarchy, 387 
LBT, 313 
nested, 390 
High-gain geedback, 98, 205, 303 
adaptive, 284, 304 
Ha theory, 307, 408 
I 
Inclusion Principle, 419, 425 
hereditary, 466 
input-output, 465 
nonlinear, 453 
stochastic, 464 
transfer functions, 466 
Incomplete state information, 219 
Indegree, 14 
Input decentralized system, 35 
Input decomposition, 314 
algorit,h for, 315 
Input-output decomposition, 331 
algorithm for, 334 
Input reachability, 7 
Interconnected estimator, 217 
Interconnected observer, 189 
Interconnection, 69 
Interconnection matrix, 2, -103 
Iterative process, 408, 410, 464 
fundamental, 69, 225 
J 
Jacobi estimator, 372 
Jacobi iterative scheme. 410 
K 
Kalman-Busy filter (estimator), 216 
Kalman filter, 353 
Kalman gain, 355 
Kalmar-Yakubovich Lemma, 297 
Known subsystems, 291 
L 
LBT (lower block triangular) decomposition, 
313 
algorithm for, 334 
input, 314 
input-output, 331 
Liapunov equation, 79 
Liapunov function, 74 
cone-valued, 115 
hierarchical, 390 
majorant, 116 
matrix, 116 
norm-like, 79, 88 
quadratic, 80 
vector, 74, 113 
Volterra, 458 
Linear system, 410 
Lipschitz condition, 71 
Local control, 87 
Loop-shaping, 307 
Lotki-Volterra equations, 456 
LQG design, 209 
M 
Majorant Liapunov equations, 116 
Matching, 253 
algorithm for, 267, 516 
length of, 254 

524 
Index 
Matching (continued) 
maximum, 514 
perfect, 514 
shortest, 254 
Matching conditions, 135, 161, 304 
Mathematical decomposition, 31 
Matrix 
adjacency, 2 
companion, 93 
complementary, 427 
epic, 426 
generic rank of, 22 
interconnection, 2 
lower triangular, 16 
M-matrix, 72 
monic, 426 
nondegenerate, 46 
occurrence, 69, 392 
QBDD, 400 
QBDDS, 403 
quasi-dominant diagonal, 73 
semisimple, 82 
sparse, 341 
stable, 79 
structured, 20 
term rank of, 22 
Vandermonde, 96 
Mechanical systems, 467, 233 
M-matrix, 72 
Model matching gains, 285 
Moving vehicles, 467 
Mutually disjoint cycles, 53 
Mutually disjoint subgraphs, 253 
Multiple control system, 479 
reliable, 494 
N 
Near-decomposability, 41 1 
Nested decomposition, 380 
Nonlinear interconnections, 69, 166 
NP-complete problem, 337 
0 
Observability, 7 
Observation error, 189 
Observer, 188 
asymptotic, 188 
decentralized, 204 
exponential, 189 
interconnected, 189 
unknown-input, 233 
Occurrence matrix, 69 
Optimal closed-loop system, 128 
Optimal control, 128 
centralized, 144 
decentralized, 168 
sequential, 350 
Optimal cost, 128, 137 
Outdegree, 14 
output 
adaptive control, 295 
controller, 41, 240 
decentralized system, 35 
feedback, 36, 37 
measurable, 240 
reachability, 8 
Output reachability, 8 
Overlapping, 416 
decentralized control, 442 
decomposition, 416 
matrix, 418 
particular case, 444 
subsystems, 416 
P 
Parameter space, 22, 251 
Parametric optimization, 181 
Partial stability, 116 
Partition, 12, 379 
acyclic, 313 
algorithms for, 315, 334 
epsilon, 380 
I0 (input-utput), 331 
irreducible, 313, 331 
Path, 7 
length of, 253 
Perfect matching, 514 
algorithm for, 516 
Performance index, 128 
Phase margin, 133, 149, 163 
Physical decomposition, 31, 33 
Power systems, 410, 466 
automatic generation control, 448 
transient stability of, 466 

Index 
525 
Precompensator, 298 
Prefilter, 298 
inverse of, 299 
Pseudeinverse, 88 
Q 
QBDD matrix, 400 
QBDDS matrix, 403 
Quadratic performance index, 128 
Quasidominant diagonal matrix, 73 
block, 306, 400 
R 
Reachability, 6 
algorithms for, 9, 516 
input, 7 
input-utput, 
10, 331 
matrix, 8, 513 
output, 8 
set, 7 
Reachable set, 7 
Reduction of dimensionality, 142 
Reference model, 275, 291 
Reliability, 483 
strictly positive real, 296 
control system, 494 
measure of, 485 
Reliable control, 493 
Restriction, 426 
Riccati equation, 128, 220 
Robustness, 145 
optimal control, 161 
suboptimal control, 149 
S 
Self-loop, 12 
Separation property, 200 
Ship boiler, 359 
u-modification, 280 
Simultaneous stability, 68 
stabilization, 307, 489 
Small-Gain Theorem, 103, 245 
Spanning subgraphs, 52 
Sparse matrix, 341 
Stability 
absolute, 240 
asymptotic, 70 
union of, 52 
connective, 70 
exponential, 95 
global, 70 
in the mean, 498 
nested, 390 
partial, 116 
stratified, 390 
transient, 466 
Stabilizability, 42 
connective, 95, 103 
decentralized, 95, 103 
connective, 92, 117, 268 
decentralized, 86, 116, 267 
simultaneous, 268, 307, 487 
suboptimal, 131 
Stabilization, 86 
Stable matrix, 79 
State determination, 329 
State feedback, 66, 87 
State regressor, 279 
State regulation, 276 
State tracking, 279 
State truncation, 15 
Static output feedback, 36 
Stratified stability, 390 
Strong components, 73, 509 
algorithm for, 511 
Strong connectedness, 12 
Structural controllability, 21 
Structural equivalence, 5 
Structurally fixed modes, 45 
Structural observability, 21 
Structural perturbations, 69, 225 
strong, 60 
test for, 56 
component level, 393 
Markovian, 497 
nested, 391 
subsystem level, 62, 393 
coherent, 479 
constraints of, 41, 193, 282 
decentralized feedback, 37 
dichotomic control, 475 
feedback, 41 
fixed modes of, 45 
global control, 87 
interconnections, 94, 107, 112 
perturbations, 69, 391 
Structure, 1 
Structured matrix, 20 
Structured system, 21 

526 
Index 
Subgraphs, 12 
disjoint, 52 
matching, 253 
mutually disjoint, 253 
spanning, 52 
union of, 52 
Suboptimal control, 129 
decentralized, 137 
LQG design of, 209 
connective, 151 
index of, 129 
Subspaces, 248, 436 
almost invariant, 248 
direct sum of, 436 
ordinary sum of, 436 
Subsystem, 69 
component of, 392 
disjoint, 440 
known, 291 
MIMO, 291 
overlapping, 416 
with observer, 196 
aggregation of, 428 
contraction of, 431 
decoupled, 67 
descriptor form of, 255 
discrete, 408 
expansion of, 418 
input decentralized, 35 
linear, 410 
multiple control, 479 
optimal, 128 
output decentralized, 35 
restriction of, 428 
standard, 249 
uncertain, 117 
Suboptimality, 137, 180, 129 
System 2, 68 
T 
Term rank, 22 
Tracking error, 279, 282 
Transient stability, 466 
Trapping state, 485 
U 
Uncertain systems, 117 
Uncontrollability, 29 
V 
Vandermonde matrix, 96 
Variety, 22 
Vector Liapunov function, 71, 74, 113 
proper, 22, 254 
linear construction of, 71 
quadratic construction of, 76 
decomposition of, 436 
indegree of, 14 
initial, 253 
outdegree of, 14 
terminal, 253 
Vulnerability, 60 
Vector space, 248 
Vertex, 3 
W 
Warshall’s algorithm, 9 
Z 
Zero-state equivalence, 434 

Mathematics in Science and Engineering 
Edited by William F. Ames, Georgia Institute of Technology 
Recent titles 
John L. Casti, Linear Dynamical Systems 
R. P. Gilbert and J. Buchanan, First Order Elliptic Systems 
J. W. Jerome, Approximation of Nonlinear Evolution Systems 
Anthony V. Fiacco, Introduction to Sensitivity and Stability Analysis in 
Hans Blomberg and Raimo Ylinen, Algebraic Theory for Multivariable Lin- 
T. A. Burton, Volterra Integral and Differential Equations 
C. J. Harris and J. M. E. Valenca, The Stability of Input-Output Dynamical 
George Adomian, Stochastic Systems 
John O’Reilly, Observers for Linear Systems 
Ram P. Kanwal, Generalized Functions: Theory and Technique 
Marc Mangel, Decision and Control in Uncertain Resource Systems 
K. L. Teo and Z. S. Wu, Computational Methods for Optimizing Distributed 
Yoshimasa Matsuno, Bilinear Transportation Method 
John L. Casti, Nonlinear System Theory 
Yoshikazu Sawaragi, Hirotaka Nakayama, apd Tetsuzo Tanino, Theory of 
Edward J. Haug, Kyung K. Choi, and Vadim Komkov, Design Sensitivity 
T. A. Burton, Stability and Periodic Solutions of Ordinary and Functional 
Yaakov Bar-Shalom and Thomas E. Fortmann, Racking and Data Associ- 
V. B. Kolmanovskii and V. R. NOSOV, Stability of Functional Differential 
V. Lakshmikantham and D. Trigiante, The0 ry of Difference Equations: Ap- 
B. D. Vujanovic and S. E. Jones, Variational Methods in Nonconservative 
C. Rogers and W. F. Ames, Nonlinear Boundary Value Problems in Science 
Dragoslav D. Siljak, Decentralized Control of Complex Systems 
Nonlinear Programming 
ear Systems 
Systems 
Systems 
Multiobjective Optimization 
Analysis of Structural Systems 
Differential Equations 
ation 
Equations 
plications to Numerical Analysis 
Phenomena 
and Engineering 
527 

This page intentionally left blank

