 123
10th International Symposium, SAGT 2017
L'Aquila, Italy, September 12–14, 2017
Proceedings
Algorithmic
Game Theory
LNCS 10504
ARCoSS
Vittorio Bilò
Michele Flammini (Eds.)

Lecture Notes in Computer Science
10504
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison, UK
Josef Kittler, UK
Friedemann Mattern, Switzerland
Moni Naor, Israel
Bernhard Steffen, Germany
Doug Tygar, USA
Takeo Kanade, USA
Jon M. Kleinberg, USA
John C. Mitchell, USA
C. Pandu Rangan, India
Demetri Terzopoulos, USA
Gerhard Weikum, Germany
Advanced Research in Computing and Software Science
Subline of Lecture Notes in Computer Science
Subline Series Editors
Giorgio Ausiello, University of Rome ‘La Sapienza’, Italy
Vladimiro Sassone, University of Southampton, UK
Subline Advisory Board
Susanne Albers, TU Munich, Germany
Benjamin C. Pierce, University of Pennsylvania, USA
Bernhard Steffen, University of Dortmund, Germany
Deng Xiaotie, City University of Hong Kong
Jeannette M. Wing, Microsoft Research, Redmond, WA, USA

More information about this series at http://www.springer.com/series/7409

Vittorio Bilò
• Michele Flammini (Eds.)
Algorithmic
Game Theory
10th International Symposium, SAGT 2017
L’Aquila, Italy, September 12–14, 2017
Proceedings
123

Editors
Vittorio Bilò
University of Salento
Lecce
Italy
Michele Flammini
University of L’Aquila
L’Aquila
Italy
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Computer Science
ISBN 978-3-319-66699-0
ISBN 978-3-319-66700-3
(eBook)
DOI 10.1007/978-3-319-66700-3
Library of Congress Control Number: 2017950086
LNCS Sublibrary: SL3 – Information Systems and Applications, incl. Internet/Web, and HCI
© Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This volume contains the papers presented at the 10th International Symposium on
Algorithmic Game Theory (SAGT 2017), which was held on September 12–14, 2017,
in L’Aquila, Italy.
This year, we received a record number of 66 submissions. Each submission was
reviewed by at least three Program Committee members. After a careful reviewing
process, the committee decided to accept 30 papers. The program also included three
invited talks by distinguished researchers in Algorithmic Game Theory: Michal Feld-
man (Tel-Aviv University), Martin Hoefer (Goethe University), and Nicole Immorlica
(Microsoft Research).
To accommodate the publishing traditions of different ﬁelds, the authors of accepted
papers could request that only a one-page abstract of the paper appears in the pro-
ceedings. Among the 30 accepted papers, the authors of 4 papers opted to publish a
one-page abstract. The accepted submissions cover various important aspects of
algorithmic game theory, such as auctions, computational aspects of games, congestion
games, network and opinion formation, mechanism design, incentives and regret
minimization, and resource allocation. The best paper award, generously supported by
Springer, has been shared between the papers Tight Welfare Guarantees for Pure Nash
Equilibria of the Uniform Price Auction by Georgios Birmpas, Evangelos Markakis,
Orestis Telelis and Artem Tsikiridis, and Online Random Sampling for Budgeted
Settings by Alon Eden, Michal Feldman and Adi Vardi.
We would like to thank all authors who submitted their research work, the Program
Committee members, and the external reviewers who assisted them, for their wonderful
work. We are indebted to the Gran Sasso Science Institute of L’Aquila, Fondazione
Cassa di Risparmio della Provincia dell’Aquila, the Department of Mathematics and
Physics “Ennio De Giorgi” of the University of Salento, EATCS, and Springer for their
generous support. We thank Anna Kramer and Alfred Hoffmann at Springer for helping
with the proceedings. We are grateful for the use of the EasyChair paper management
system.
July 2017
Vittorio Bilò
Michele Flammini

Organization
Program Committee
Elliot Anshelevich
Rensselaer Polytechnic Institute (RPI), USA
Vittorio Bilò (Co-chair)
University of Salento, Italy
Ioannis Caragiannis
University of Patras, Greece
George Christodoulou
University of Liverpool, UK
Xiaotie Deng
Shanghai Jiao Tong University, China
Angelo Fanelli
CNRS, France
Michele Flammini
(Co-chair)
University of L’Aquila and Gran Sasso Science Institute
(GSSI), Italy
Dimitris Fotakis
National Technical University of Athens, Greece
Martin Gairing
University of Liverpool, UK
Paul Goldberg
University of Oxford, UK
Tobias Harks
Augsburg University, Germany
Thomas Kesselheim
TU Dortmund, Germany
Elias Koutsoupias
University of Oxford, UK
Stefano Leonardi
University of Rome “La Sapienza”, Italy
Marios Mavronicolas
University of Cyprus, Cyprus
Gianpiero Monaco
University of L’Aquila, Italy
Luca Moscardelli
University of Chieti-Pescara, Italy
Giuseppe Persiano
University of Salerno, Italy
Guido Proietti
University of L’Aquila and Institute for Systems Analysis
and Computer Science (IASI-CNR), Italy
Amin Saberi
Stanford University, USA
Rahul Savani
University of Liverpool, UK
Guido Schaefer
CWI Amsterdam, The Netherlands
Alexander Skopalik
Heinz Nixdorf Institute and Paderborn University,
Germany
Nicolas Stier-Moses
Torcuato Di Tella University, Argentina
Chaitanya Swamy
University of Waterloo, Canada
Vasilis Syrgkanis
Microsoft Research, USA
Marc Uetz
University of Twente, The Netherlands
Adrian Vetta
McGill University, Canada
Steering Committee
Elias Koutsoupias
University of Oxford, UK
Marios Mavronicolas
University of Cyprus, Cyprus
Dov Monderer
Technion, Israel
Burkhard Monien
Paderborn University, Germany
Christos Papadimitriou
UC Berkeley, USA

Giuseppe Persiano
University of Salerno, Italy
Paul Spirakis (Chair)
University of Liverpool, UK
Organizing Committee
Vittorio Bilò (Co-chair)
University of Salento, Italy
Michele Flammini
(Co-chair)
University of L’Aquila and Gran Sasso Science Institute
(GSSI), Italy
Gianlorenzo D’Angelo
Gran Sasso Science Institute (GSSI), Italy
Mattia D’Emidio
Gran Sasso Science Institute (GSSI), Italy
Gianpiero Monaco
University of L’Aquila, Italy
Luca Moscardelli
University of Chieti-Pescara, Italy
Cosimo Vinci
Gran Sasso Science Institute (GSSI), Italy
Additional Reviewers
Amanatidis, Georgios
Baumeister, Dorothea
Bhaskar, Umang
Bilò, Davide
Birmpas, Georgios
Biro, Peter
Carosi, Raffaello
Colini Baldeschi,
Riccardo
Cord-Landwehr, Andreas
Cseh, Ágnes
de Jong, Jasper
De Keijzer, Bart
Deligkas, Argyrios
Drees, Maximilian
Duetting, Paul
Eden, Alon
Epitropou, Markos
Fearnley, John
Feldkord, Björn
Feldotto, Matthias
Ferraioli, Diodato
Filos-Ratsikas, Aris
Fischer, Felix
Freeman, Rupert
Giannakopoulos, Yiannis
Greco, Gianluigi
Gualà, Luciano
Gur, Yonatan
Hajiaghayi,
Mohammadtaghi
Hamada, Koki
Hoeksma, Ruben
Igarashi, Ayumi
Jabbari, Shahin
Kern, Walter
Kliemann, Lasse
Kodric, Bojana
Krimpas, George
Krysta, Piotr
Kyropoulou, Maria
Lazos, Philip
Lenzner, Pascal
Leucci, Stefano
Lianeas, Thanasis
Liu, Zhengyang
Lykouris, Thodoris
Maillé, Patrick
Malladi, Suraj
Mandal, Debmalya
Manlove, David
Markakis, Evangelos
Peters, Dominik
Schroder, Marc
Schwiegelshohn, Chris
Sgouritsa, Alkmini
Shameli, Ali
Skochdopoloe, Nolan
Tufﬁn, Bruno
Tönnis, Andreas
Vegh, Laszlo
Ventre, Carmine
von Stengel, Bernhard
Voudouris, Alexandros
Xiao, Tao
Yukun, Cheng
Zick, Yair
VIII
Organization

Abstracts

Position Ranking and Auctions for Online
Marketplaces
Leon Yang Chu, Hamid Nazerzadeh, and Heng Zhang
Data Sciences and Operations Department, University of Southern California,
Los Angeles, CA, USA, 90089
{leonyzhu,hamidnz,Heng.Zhang.2019}@marshall.usc.edu
Abstract. E-commerce platforms such as Amazon, Ebay, Taobao, and Google
Shopping connect thousands of sellers and consumers everyday. When a con-
sumer enters a search keyword related to a product of interest, the platform’s
search engine returns a list. Typically, the consumer looks for a desired item by
searching downward in the list. With a large volume of returned results, con-
sumers rarely consider all of the items because examining each option is costly.
Therefore, the ranking of items is an important decision that determines the
welfare of sellers, consumers and the platform. In this work, we study how such
platforms should rank products displayed, and utilize the top and most salient
slots. Building on the optimal sequential search theory, we present a model that
considers consumers’ search costs and the externalities sellers impose on each
other. This model allows us to study a multi-objective optimization, whose
objective includes consumer and seller surplus, as well as the sales revenue, and
derive the optimal ranking decision. One of the challenges in obtaining a sat-
isfactory solution in practice is information asymmetry. The platform may be
unaware of sellers’ private beneﬁts of each consumer purchase, for example,
proﬁts, brand effects, and so on. We show that an uninformed decision, one in
which sellers’ private valuations are unknown to the platform, can lead to an
arbitrary loss of average welfare. We propose selling the platform’s top slots to
extract private information, using the surplus-ordered ranking (SOR) mecha-
nism. This mechanism is motivated in part by Amazon’s sponsored search
program. We study this mechanism in a mechanism design framework, and
show that it is a near-optimal solution. In addition, when the platform sells all
slots, we show that our mechanism can be implemented as a Nash equilibrium in
a modiﬁed generalized second price (GSP) auction.
Full paper available online at: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2926176.

Asymptotic Existence of Fair Divisions
for Groups
Pasin Manurangsi1 and Warut Suksompong2
1 Department of Computer Science, UC Berkeley
253 Cory Hall, Berkeley, CA 94720, USA
pasin@berkeley.edu
2 Department of Computer Science, Stanford University, 353 Serra Mall,
Stanford, CA 94305, USA
warut@cs.stanford.edu
The problem of dividing resources fairly occurs in many practical situations and is
therefore an important topic of study in economics. In this paper, we investigate
envy-free divisions in the setting where there are multiple players in each party. While
all players in a party share the same set of resources, each player has her own pref-
erences. In this generalized setting, we consider a division to be envy-free if every
player values the set of items assigned to her group at least as much as that assigned to
any other group.
We show that under additive valuations drawn randomly from probability distri-
butions, when all groups contain an equal number of players, an envy-free division is
likely to exist if the number of goods exceeds the total number of players by a
logarithmic factor, no matter whether the players are distributed into several groups of
small size or few groups of large size. In particular, any allocation that maximizes
social welfare is likely to be envy-free. A similar result holds when there are two
groups with possibly unequal numbers of players and the distribution on the valuation
of each item is symmetric.
To complement our existence results, we show on the other hand that we cannot get
away with a much lower number of items and still have an envy-free division with high
probability. In particular, if the number of items is less than the total number of players
by a superconstant factor, or if the number of items is less than the total number of
players and the number of groups is large, the probability that an envy-free division
exists is low. This leaves the gap between asymptotic existence and non-existence of
envy-free divisions at a mere logarithmic factor.
Finally, we tackle the issue of truthfulness and show that a simple truthful mech-
anism, namely the random assignment mechanism, is a-approximate envy-free with
high probability for any constant a ϵ [0,1). Approximate envy-freeness means that even
though a player may envy another player in the resulting division, the values of the
The full version of this paper is available at http://arxiv.org/abs/1706.08219.

player for her own allocation and for the other player’s allocation differ by no more
than a multiplicative factor of a. Our result shows that it is possible to achieve
truthfulness and approximate envy-freeness simultaneously in a wide range of random
instances, and improves upon the previous result for the setting with one player per
group in several ways.
Asymptotic Existence of Fair Divisions for Groups
XIII

Approximate Maximin Shares for Groups
of Agents
Warut Suksompong
Department of Computer Science, Stanford University, 353 Serra Mall, Stanford,
CA 94305, USA
warut@cs.stanford.edu
We consider the problem offairly allocating indivisible goods to interested agents. Several
notions of fairness have been proposed, including envy-freeness and proportionality.
However, the existence of allocations satisfying these notions, or even a multiplicative
approximation of them, cannot be guaranteed. A notion that was designed to ﬁx this
problem and has been a subject of much interest in the last few years is the maximin share.
In this paper, we apply the concept of maximin share to a more general setting of
fair division in which goods are allocated not to individual agents, but rather to groups
of agents who can have varying preferences on the goods. Several practical situations
involving fair division ﬁt into this model. For instance, an outcome of a negotiation
between countries may have to be approved by members of the cabinets of each
country who have different opinions on the outcome. Another example is a large
company or university that needs to divide its resources among competing groups of
agents (e.g., departments in a university). The agents in each group have different and
possibly misaligned interests; the professors who perform theoretical research may
prefer more whiteboards and open space in the department building, while those who
engage in experimental work are more likely to prefer laboratories.
We extend the maximin share to groups in a natural way by calculating the max-
imin share for each agent using the number of groups instead of the number of agents.
When there are two groups, we completely characterize the cardinality of agents in the
groups for which it is possible to approximate the maximin share within a constant
factor regardless of the number of goods. In particular, an approximation is possible
when one of the groups contain a single agent, when both groups contain two agents, or
when the groups contain three and two agents respectively. In all other cases, no
approximation is possible in a strong sense: There exists an instance with only four
goods in which some agent with positive maximin share necessarily gets zero utility.
We then generalize to the setting with several groups of agents. On the positive
side, we show that a constant factor approximation is possible if only one group
contains more than a single agent. On the other hand, we show on the negative side that
when all groups contain at least two agents and one group contains at least ﬁve agents,
it is possible that some agent with positive maximin share will be forced to get zero
utility, which means that there is no hope of obtaining an approximation in this case.
The full version of this paper is available at http://arxiv.org/abs/1706.09869.

On Black-Box Transformations
in Downward-Closed Environments
Warut Suksompong
Department of Computer Science, Stanford University, 353 Serra Mall, Stanford,
CA 94305, USA
warut@cs.stanford.edu
A major line of work in algorithmic mechanism design involves taking a setting where
the optimization problem is computationally intractable, and designing computationally
tractable mechanisms that yield a good global outcome and such that the agents have a
truth-telling incentive. The widespread success of designing such mechanisms has raised
the question of whether there exists a “black-box transformation” for transforming any
computationally tractable algorithm into a computationally tractable mechanism without
degrading the approximation guarantee. Chawla et al. showed that no fully general
black-box transformation exists for single-parameter environments.
Despite this negative result, it is still conceivable that there are transformations that
work for certain large subclasses of single-parameter environments. One important
subclass is that of downward-closed environments, which occur in a wide variety of
settings in mechanism design. In this paper, we consider such settings and assume,
crucially, that the black-box transformation is aware that the feasible set is
downward-closed. We investigate the potentials and limits of black-box transformations
when they are endowed with this extra power.
We begin by showing the limits of black-box transformations in downward-closed
environments. We prove that such transformations cannot preserve the full welfare at
every input, even when the private valuations can take on only two arbitrary values.
Preserving a constant fraction of the welfare pointwise is impossible if the ratio
between the two values Ɩ < h is sublinear, i.e., h/Ɩ ϵ O(na) for a ϵ [0,1), where n is the
number of agents, while preserving the approximation ratio is also impossible if the
values are within a constant factor of each other and the transformation is restricted to
querying inputs of Hamming distance o(n) away from its input.
Next, we show the powers of black-box transformations in downward-closed envi-
ronments. We prove that when the private valuations can take on only a constant number
of values, each pair of values separated by a ratio of X(n), it becomes possible for a
transformation to preserve a constant fraction of the welfare pointwise, and therefore of the
approximation ratio as well. The same is also true if the private valuations are all within a
constant factor of each other. Combined with the negative results, this gives us a complete
picture of constant-fraction welfare-preserving transformations for multiple input values.
Not only are these results interesting in their own right, but they also demonstrate the
borders of the negative results that we can hope to prove.
The full version of this paper is available at http://arxiv.org/abs/1707.00230.

Contents
Auctions
Liquid Price of Anarchy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Yossi Azar, Michal Feldman, Nick Gravin, and Alan Roytman
Tight Welfare Guarantees for Pure Nash Equilibria of the Uniform
Price Auction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
Georgios Birmpas, Evangelos Markakis, Orestis Telelis,
and Artem Tsikiridis
Online Random Sampling for Budgeted Settings. . . . . . . . . . . . . . . . . . . . .
29
Alon Eden, Michal Feldman, and Adi Vardi
Liquid Welfare Maximization in Auctions with Multiple Items . . . . . . . . . . .
41
Pinyan Lu and Tao Xiao
Computational Aspects of Games
On the Nucleolus of Shortest Path Games . . . . . . . . . . . . . . . . . . . . . . . . .
55
Mourad Baïou and Francisco Barahona
Earning Limits in Fisher Markets with Spending-Constraint Utilities . . . . . . .
67
Xiaohui Bei, Jugal Garg, Martin Hoefer, and Kurt Mehlhorn
Robustness Among Multiwinner Voting Rules . . . . . . . . . . . . . . . . . . . . . .
80
Robert Bredereck, Piotr Faliszewski, Andrzej Kaczmarczyk,
Rolf Niedermeier, Piotr Skowron, and Nimrod Talmon
Computing Constrained Approximate Equilibria in Polymatrix Games . . . . . .
93
Argyrios Deligkas, John Fearnley, and Rahul Savani
Group Activity Selection on Graphs: Parameterized Analysis . . . . . . . . . . . .
106
Sushmita Gupta, Sanjukta Roy, Saket Saurabh, and Meirav Zehavi
The Real Computational Complexity of Minmax Value
and Equilibrium Refinements in Multi-player Games . . . . . . . . . . . . . . . . . .
119
Kristoffer Arnsfelt Hansen
Conditional Value-at-Risk: Structure and Complexity of Equilibria . . . . . . . .
131
Marios Mavronicolas and Burkhard Monien

Congestion Games, Network and Opinion Formation Games
Reconciling Selfish Routing with Social Good . . . . . . . . . . . . . . . . . . . . . .
147
Soumya Basu, Ger Yang, Thanasis Lianeas, Evdokia Nikolova,
and Yitao Chen
Selfish Network Creation with Non-uniform Edge Cost . . . . . . . . . . . . . . . .
160
Ankit Chauhan, Pascal Lenzner, Anna Melnichenko, and Louise Molitor
Opinion Formation Games with Aggregation and Negative Influence. . . . . . .
173
Markos Epitropou, Dimitris Fotakis, Martin Hoefer,
and Stratis Skoulakis
The Efficiency of Best-Response Dynamics . . . . . . . . . . . . . . . . . . . . . . . .
186
Michal Feldman, Yuval Snappir, and Tami Tamir
Efficient Best Response Computation for Strategic Network Formation
Under Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
199
Tobias Friedrich, Sven Ihde, Christoph Keßler, Pascal Lenzner,
Stefan Neubert, and David Schumann
Path Deviations Outperform Approximate Stability in Heterogeneous
Congestion Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
212
Pieter Kleer and Guido Schäfer
Mechanism Design, Incentives and Regret Minimization
Agent Incentives of Strategic Behavior in Resource Exchange . . . . . . . . . . .
227
Zhou Chen, Yukun Cheng, Xiaotie Deng, Qi Qi, and Xiang Yan
A 3-Player Protocol Preventing Persistence in Strategic Contention
with Limited Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
240
George Christodoulou, Martin Gairing, Sotiris Nikoletseas,
Christoforos Raptopoulos, and Paul Spirakis
Hedging Under Uncertainty: Regret Minimization Meets Exponentially
Fast Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
252
Johanne Cohen, Amélie Héliou, and Panayotis Mertikopoulos
Resource Allocation
Tradeoffs Between Information and Ordinal Approximation
for Bipartite Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
267
Elliot Anshelevich and Wennan Zhu
Group Strategyproof Pareto-Stable Marriage with Indifferences
via the Generalized Assignment Game. . . . . . . . . . . . . . . . . . . . . . . . . . . .
280
Nevzat Onur Domaniç, Chi-Kit Lam, and C. Gregory Plaxton
XVIII
Contents

The Spectrum of Equilibria for the Colonel Blotto and the Colonel
Lotto Games. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
292
Marcin Dziubiński
On Proportional Allocation in Hedonic Games . . . . . . . . . . . . . . . . . . . . . .
307
Martin Hoefer and Wanchote Jiamjitrak
Stable Marriage with Covering Constraints–A Complete
Computational Trichotomy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
320
Matthias Mnich and Ildikó Schlotter
Fairly Allocating Contiguous Blocks of Indivisible Items . . . . . . . . . . . . . . .
333
Warut Suksompong
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
345
Contents
XIX

Auctions

Liquid Price of Anarchy
Yossi Azar1, Michal Feldman1, Nick Gravin2, and Alan Roytman3(B)
1 Tel Aviv University, Tel Aviv, Israel
{azar,mfeldman}@tau.ac.il
2 Massachusetts Institute of Technology, Cambridge, USA
ngravin@mit.edu
3 University of Copenhagen, Copenhagen, Denmark
alanr@di.ku.dk
Abstract. Incorporating budget constraints into the analysis of auc-
tions has become increasingly important, as they model practical set-
tings more accurately. The social welfare function, which is the standard
measure of eﬃciency in auctions, is inadequate for settings with budgets,
since there may be a large disconnect between the value a bidder derives
from obtaining an item and what can be liquidated from her. The Liquid
Welfare objective function has been suggested as a natural alternative
for settings with budgets. Simple auctions, like simultaneous item auc-
tions, are evaluated by their performance at equilibrium using the Price
of Anarchy (PoA) measure – the ratio of the objective function value of
the optimal outcome to the worst equilibrium. Accordingly, we evaluate
the performance of simultaneous item auctions in budgeted settings by
the Liquid Price of Anarchy (LPoA) measure – the ratio of the optimal
Liquid Welfare to the Liquid Welfare obtained in the worst equilibrium.
For pure Nash equilibria of simultaneous ﬁrst price auctions, we obtain
a bound of 2 on the LPoA for additive buyers. Our results easily extend
to the larger class of fractionally-subadditive valuations. Next we show
that the LPoA of mixed Nash equilibria for ﬁrst price auctions with addi-
tive bidders is bounded by a constant. Our proofs are robust, and can
be extended to achieve similar bounds for Bayesian Nash equilibria. To
derive our results, we develop a new technique in which some bidders
deviate (surprisingly) toward a non-optimal solution. In particular, this
technique goes beyond the smoothness-based approach.
Y. Azar—Supported in part by the Israel Science Foundation (grant No. 1506/16),
by the I-CORE program (Center No. 4/11), and by the Blavatnik Fund.
M. Feldman—This work was partially supported by the European Research Council
under the European Union’s Seventh Framework Programme (FP7/2007-2013)/ERC
grant agreement number 337122.
A. Roytman—This work was partially supported by the European Research Council
under the European Union’s Seventh Framework Programme (FP7/2007-2013)/ERC
grant agreement number 337122, by Thorup’s Advanced Grant DFF-0602-02499B
from the Danish Council for Independent Research, by grant number 822/10 from
the Israel Science Foundation, and by the Israeli Centers for Research Excellence
(ICORE) program.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 3–15, 2017.
DOI: 10.1007/978-3-319-66700-3 1

4
Y. Azar et al.
1
Introduction
Budget constraints have become an important practical consideration in most
existing auctions, as reﬂected in recent literature (see, e.g., [4,6,20,37]), because
they model reality more accurately. The issue of limited liquidity of buyers arises
when transaction amounts are large and may exhaust bidders’ liquid assets, as is
the case for privatization auctions in Eastern Europe and FCC spectrum auctions
in the U.S. (see, e.g., [5]). As another example, advertisers in Google Adword
auctions are instructed to specify their budget even before specifying their bids
and keywords. Many other massive electronic marketplaces have a large number
of participants with limited liquidity, which impose budget constraints. Buyers
would not borrow money from a bank to partake in multiple auctions on eBay,
and even with available credit, they only have a limited amount of attention, so
that in aggregate they cannot spend too much money by participating in every
auction online. Finally, budget constraints also arise in small scale systems, such
as the reality TV show Storage Wars, where people participate in cash-only
auctions to win the content of an expired storage locker with an unknown asset.
Maximizing social welfare is a classic objective function that has been exten-
sively studied within the context of resource allocation problems, and auctions
in particular. The social welfare of an allocation is the sum of agents’ valuations
for their allocated bundles. Unfortunately, in settings where agents have limited
budgets (hereafter, budgeted settings), the social welfare objective fails to accu-
rately capture what happens in practice. Consider, for example, an auction in
which there are two bidders and one item to be allocated among the bidders.
One bidder has a high value but a very small budget, while the second bidder has
a medium value along with a medium budget. In this case, a high social welfare
is achieved by allocating the item to the bidder who values the item highly. In
contrast, most Internet advertising and electronic marketplaces (such as Google
and eBay) would allocate the item in the opposite way, namely to the bidder
with a medium value and budget. Indeed, it seems reasonable to favor partici-
pants with substantial investments and engagement in the economical system to
maintain a healthy economy regardless of the marketplace intermediary’s per-
sonal gains. Hence, the social welfare objective is a poor model for how auctions
are executed in reality.
In this work, we study the eﬃciency of simultaneous ﬁrst price auctions
in budgeted settings. Following Dobzinski and Leme [21] (see also [11,23,32,
38]), we measure the eﬃciency of outcomes in budgeted settings according to
their Liquid Welfare objective, motivated as follows. In the mechanism design
literature, a buyer i with additive values for items vij (where vij denotes buyer
i’s value for item j) and a budget cap Bi is usually modeled with budget additive
valuations vi(S) = min(Bi, 
j∈S vij), where S is the set of items that player
i receives (see, e.g., Lehmann et al. [31] and many follow-up works). Budget
additive valuations are convenient to work with (they form a simple subclass
of submodular valuations) and, from the designer’s perspective, are a natural
proxy for the contribution of each bidder to the economical system.

Liquid Price of Anarchy
5
However, in reality such valuations do not capture the real preferences of the
buyers, since each buyer usually prefers to get as many items of high value as
possible vi(S) = 
j∈S vij, with the only concern being that her total payments
for the received set of items S, denoted by pi(S), should not exceed her budget
constraint pi(S) ≤Bi. To reconcile this discrepancy, Dobzinski and Leme [21]
proposed to evaluate the welfare of buyers in budgeted settings according to
their admissibility-to-pay; that is, the minimum between the buyer’s value for
the allocated bundle and the buyer’s budget. The aggregate welfare according
to this deﬁnition is termed the Liquid Welfare (LW). Hence, the Liquid Welfare
objective can be seen as a natural analogue to social welfare in budgeted set-
tings, as it simultaneously captures the health of an economic system while still
modeling buyers as preferring items of high value, despite budget constraints.
For simultaneous ﬁrst price auctions, we use the following natural item-
clearing mechanism for each individual item. Each player submits a bid they
are willing to pay for the whole item, along with the maximal fraction of the
item they are willing to purchase. Then, in decreasing order of the bids and as
long as some fraction of the item remains to be allocated, each buyer receives
their requested fraction of the item (or whatever remains), and pays their bid
multiplied by the fraction they received. In the context of additive values, we
model players’ utilities for each item as their value for the item minus their sub-
mitted bid (both of which are scaled by the fraction of the item they receive).
Our model is closely related to a prominent simultaneous item auction format
with heterogeneous items, which has been extensively studied recently. In such
auctions, buyers submit bids simultaneously on all items, and the allocation and
prices are determined separately for each individual item, based only on the bids
submitted for that item. This format is similar to auctions used in practice (e.g.,
eBay auctions). The standard measure for quantifying eﬃciency in such settings
is the Price of Anarchy (PoA) [29,35,38], deﬁned as the ratio of the optimal social
welfare to the social welfare of the worst equilibrium. In budgeted settings, it
is thus natural to quantify the eﬃciency of such auctions by the Liquid Price
of Anarchy (LPoA), deﬁned as the ratio of the optimal Liquid Welfare to the
Liquid Welfare of the worst equilibrium.
New Techniques. The most common framework for analyzing the Price of Anar-
chy of games and auctions is the smoothness framework (see, e.g., [35,38]). Such
techniques usually involve a thought experiment in which each player deviates
toward some strategy related to the optimal solution, and hence the total util-
ity of all players can be bounded appropriately. One important and necessary
condition for applying the smoothness framework is that the objective function
must dominate the sum of utilities (which holds for social welfare). However, this
technique falls short in the case of Liquid Welfare, since a bidder’s utility can be
arbitrarily higher than their admissibility-to-pay, and in aggregate, bidders may
achieve a total utility that is much larger than the Liquid Welfare at equilib-
rium. To overcome this issue, we develop new techniques to bound the LPoA in
budgeted settings. Our techniques include a novel type of hypothetical deviation
that is used to upper bound the aggregate utility of bidders (in addition to the

6
Y. Azar et al.
traditional deviation that is used to lower bound it), and the consideration of a
special set of carefully chosen bidders to engage in these hypothetical deviations
(see more details in the full version of our paper [3]). To the best of our knowl-
edge, most prior techniques, including those that depart from the smoothness
framework (e.g., [25]), examine the utility derived when every player deviates
toward the optimal solution.
With our new techniques at hand, we address the following question: What is
the Liquid Price of Anarchy of simultaneous ﬁrst price item auctions in settings
with budgets?
Clarifying Remarks and Examples
Settings where agents have additive valuations and are constrained by budgets
(as in our setting) should not be confused with settings with budget additive
valuations. The latter assumes quasilinear utilities, while the former does not1.
The class of budget additive valuations is a proper subclass of submodular val-
uations, a setting for which the Price of Anarchy of simultaneous combinatorial
auctions is well understood, and known to be bounded by a constant2. However,
these results do not apply to the budgeted setting, since a bidder’s perspective
and consequently their behavior at equilibrium is very diﬀerent from the budget
additive setting (see the full version of our paper [3] for an example and a more
detailed discussion).
The budgeted simultaneous item bidding setting has also been studied by [38],
where a diﬀerent approach was taken. They measured the social welfare at
equilibrium against the optimal Liquid Welfare. Note that according to their
measure, the benchmark (i.e., optimal Liquid Welfare) may be lower than the
measured welfare. Please see the full version of our paper [3] for an example
illustrating the diﬀerence between their measure and our LPoA measure.
Our Contributions
We show that simultaneous ﬁrst price item auctions achieve nearly optimal per-
formance, i.e., a constant Liquid Price of Anarchy. Our main result concerns the
case in which agent valuations are additive (i.e., agent i’s value for item j is vij
and the value for a set of items is the sum of the individual valuations, each of
which is scaled by the corresponding fraction received).
Main Theorem: For simultaneous ﬁrst price auctions with additive bidders and
divisible items, the LPoA with respect to mixed Nash equilibria and Bayesian
Nash equilibria is constant.
We also show that for pure Nash equilibria in simultaneous ﬁrst price auctions,
our results hold for more general settings.
1 The diﬀerence is also pointed out in the literature on the design of truthful combi-
natorial auctions [20,21].
2 In particular, there are tight PoA bounds of
e
e−1 for submodular bidders, and 2 for
subadditive bidders.

Liquid Price of Anarchy
7
Theorem: For fractionally-subadditive bidders, the LPoA of pure Nash equilib-
ria in simultaneous ﬁrst price auctions is 2. Moreover, this bound is tight.
The following remarks are in order:
1. In settings without budgets, simultaneous ﬁrst price item auctions for addi-
tive bidders reduce to m independent auctions (where m is the number of
items). In contrast, when agents have budget constraints, the separate auc-
tions exhibit non-trivial dependencies even under additive valuations.
2. Since fractionally-subadditive valuations are not typically deﬁned over divisi-
ble items, we discretize the bidding space so that requested fractions of items
can only be multiples of a ﬁxed small size in our fractionally-subadditive
results. This essentially induces an indivisible setting with discrete items,
and hence fractionally-subadditive valuations are well-deﬁned.
Related Work
There is a vast literature in algorithmic game theory that incorporates budgets
into the design of incentive compatible mechanisms. The paper of [6] showed that,
in the case of one divisible good, the adaptive clinching auction is incentive com-
patible under some assumptions. Moreover, the work of [37] initiated the design
of incentive compatible mechanisms in the context of reverse auctions, where the
payments of the auctioneer cannot exceed a hard budget constraint (follow-up
works include [1,4,12,15,22]). A great deal of work focused on designing incentive
compatible mechanisms that approximately maximize the auctioneer’s revenue
in various settings with budget-constrained bidders [9,13,30,33,34]. Some works
analyzed how budgets aﬀect markets and non-truthful mechanisms [5,14].
Earlier work on multi-unit auctions with budgets deals with designing incen-
tive compatible mechanisms that always produce Pareto-optimal allocations [20].
The results in this line of work are mostly negative with a notable exception of
mechanisms based on Ausubel’s adaptive clinching auction framework [2].
Some recent results concern the design of incentive compatible mechanisms
with respect to the Liquid Welfare objective, introduced by [21]. They gave a
constant approximation for the auction that sells a single divisible good to addi-
tive buyers with budgets. In a follow-up work, [32] gave an O(1)-approximation
for bidders with general valuations in the single-item setting. The work of [23]
extended the notion of a combinatorial Walrasian equilibrium (see [26]) to set-
tings with budgets. They showed that their generalization, termed a lottery
pricing equilibrium, achieves high Liquid Welfare. They also argued how to eﬃ-
ciently compute randomized allocations that have near-optimal Liquid Welfare
for large classes of valuation functions (including subadditive valuations).
A large body of literature is concerned with simultaneous item bidding auc-
tions. These simple auctions have been studied from a computational perspec-
tive [10,19]. There is also extensive work addressing the Price of Anarchy of
such simple auctions (see [36] for more general Price of Anarchy results). The
work of [16] initiated the study of simultaneous item auctions within the Price
of Anarchy framework. The authors showed that, for second price auctions, the

8
Y. Azar et al.
social welfare of every Bayesian Nash equilibrium is a 2-approximation to the
optimal social welfare, even for players with fractionally-subadditive valuation
functions. A large amount of follow-up work [7,8,17,24,25,28,38] made signiﬁ-
cant progress in understanding simultaneous item auctions, but all of these works
measure ineﬃciency only with respect to the social welfare objective.
Much less is known about the Price of Anarchy in auctions for objectives
other than social welfare. In fact, we are aware of only one such work [27],
which studies the revenue of simultaneous auctions with reserve prices for single-
parameter bidders with regular distributions. This work essentially reduces the
revenue maximization problem to the welfare maximization problem for virtual
values in single-parameter settings and then employs smoothness analysis to
bound virtual value welfare. We note that this approach fails for multi-parameter
settings such as simultaneous multi-item auctions with additive valuations.
The work of [38] considered Liquid Welfare when measuring the ineﬃciency
of equilibria. They gave various Price of Anarchy results, developed a smooth-
ness framework for broad solution concepts such as correlated and Bayesian
Nash equilibria, and explored composition properties of various mechanisms.
They extended their results to the setting where players are budget-constrained,
achieving similar approximation guarantees when comparing the social welfare
achieved at equilibrium to the optimal Liquid Welfare. In particular, their results
imply an
e
e−1-approximation for simultaneous ﬁrst price auctions, and a 2-
approximation for all-pay auctions and simultaneous second price auctions under
the no-overbidding assumption. While [38] show that the social welfare at equi-
librium cannot be much worse than the optimal Liquid Welfare, one should note
that the social welfare at equilibrium can be arbitrarily better than the opti-
mal Liquid Welfare (e.g., if all budgets are small, the optimal Liquid Welfare is
small). It is useful to note that, in general, the ratio between the Liquid Welfare
at equilibrium and the social welfare at equilibrium can be arbitrarily bad (if
all budgets are small, then the Liquid Welfare of any allocation is small, while
players’ values for received goods can be arbitrarily large).
The works of [11,18] also considered the setting where players have budgets
and studied the same ratio we consider, namely the Liquid Welfare at equilib-
rium to the optimal Liquid Welfare. In [11], they studied the proportional alloca-
tion mechanism, which concerns auctioning oﬀone divisible item proportionally
according to the bids that players submit. They showed that, assuming players
have concave non-decreasing valuation functions, the Liquid Welfare at coarse-
correlated equilibria and Bayesian Nash equilibria achieve at least a constant
fraction of the optimal Liquid Welfare. It should be noted that, for random allo-
cations, they measure the benchmark at equilibrium ex-ante over the randomness
of the allocation, i.e., n
i=1 min{Ev-i,B-i[vi(xi)], Bi}, where vi is player i’s val-
uation, Bi is player i’s budget, and xi denotes the allocation player i receives.
In contrast, for random allocations, we use the stronger ex-post measure of the
expected Liquid Welfare at equilibrium given by n
i=1 E[min{vi(xi), Bi}]. The
work of [18] studied a similar setting, except that multiple divisible items were
considered. They gave improved bounds for coarse-correlated equilibria even with

Liquid Price of Anarchy
9
multiple items and also an improved bound for Bayesian Nash equilibria with one
item. In addition, they studied the polyhedral environment and showed an exact
bound of 2 for pure Nash equilibria when agents have subadditive valuations.
2
Model and Preliminaries
We consider simultaneous ﬁrst price item auctions, in which m heterogeneous
items are sold to n bidders (or players) in m independent auctions. We ﬁrst
describe our notation in the context of indivisible items, and then describe
the divisible model. A bidder’s strategy is a bid vector bi ∈Rm
≥0, where
bij represents player i’s bid for item j. We use b to denote the bid proﬁle
b = (b1, . . . , bn), and we will often use the notation b = (bi, b-i) to denote the
strategy proﬁle where player i bids bi and the remaining players bid according
to b-i = (b1, . . . , bi−1, bi+1, . . . , bn).
The outcome of an auction consists of an allocation rule x and payment
rule p. The allocation rule x maps bid proﬁles to an allocation vector for each
bidder i, where xi(b) = (xi1, . . . , xim) denotes the set of items won by player i
(xij = 1 ⇔player i wins item j). In a simultaneous ﬁrst price auction, each item
is allocated to the highest bidder (breaking ties according to some rule) and the
winner pays their bid. The total payment of bidder i is pi(b) = 
j∈xi(b) bij.
Each player i has a valuation function vi, which maps sets of items to R≥0
(vi captures how much player i values item bundles), and a budget Bi. We
assume that all valuations are normalized and monotone, i.e., vi(∅) = 0 and
vi(S) ≤vi(T) for any i ∈[n] and S ⊆T ⊆[m]. We mostly consider bidders
with additive valuations, i.e., vi(S) = 
j∈S vij (where vij denotes agent i’s
value for item j). The utility ui(xi(b)) of each player i is vi(xi(b)) −pi(b) =

j vij · xij −pi(b) if pi(b) ≤Bi; and ui(xi(b)) = −∞if pi(b) > Bi. Buyers
select their bids strategically in order to maximize utility.
For divisible items, agent’s i bid bij consists of two parameters for each item
j: a price bij and a desired fraction δij. For each item j, in decreasing order
of bij, and as long as some fraction of item j remains, each buyer i receives a
fraction of item j given by xij = δij (or whatever remains). If the agent receives
an xij-fraction of item j, then their value is given by vi(xij) = vij · xij and they
pay bij · xij. We write all individual bids bij on item j as a vector b·j and bids
for all items as b.
Deﬁnition 1 (Pure Nash Equilibrium). A bid proﬁle b is a Pure Nash Equi-
librium if, for any player i and any deviating bid b′
i: ui(bi, b-i) ≥ui(b′
i, b-i).
A mixed Nash equilibrium is deﬁned similarly, except that bidding strategies
can be randomized bi ∼si and utility is measured in expectation over the joint
bid distribution s = s1 × · · · × sn.
Deﬁnition 2 (Mixed Nash Equilibrium). A bid proﬁle s is a mixed Nash
equilibrium if, for any player i and any deviating bid b′
i: Eb∼s[ui(bi, b-i)] ≥
Eb-i∼s-i[ui(b′
i, b-i)].

10
Y. Azar et al.
Note that, in general, we assume the bidding space is discretized (i.e., each player
can only bid in multiples of a suﬃciently small value ε). This is done to ensure
that there always exists a mixed Nash equilibrium, as otherwise we do not have
a ﬁnite game.
Deﬁnition 3 (Liquid Welfare). The Liquid Welfare, denoted by LW, of an
allocation x is given by LW(x) = 
i∈[n] min{vi(xi), Bi}. For random alloca-
tions, we use the measure given by LW(x) = 
i∈[n] E[min{vi(xi), Bi}].
For a given vector of valuations v = (v1, . . . , vn), we use OPT(v) to denote
the Liquid Welfare of an optimal outcome given by the expression OPT(v) =
maxx1,...,xn

i min{vi(xi), Bi}, where the bundles xi form a fractional partition
of [m] (i.e., 
i xij = 1 for any j). We often use OPT instead of OPT(v) when
the context is clear.
Deﬁnition 4 (Liquid Price of Anarchy). Given a ﬁxed valuation proﬁle v,
the Liquid Price of Anarchy (LPoA) is the worst-case ratio between the optimal
Liquid Welfare and the expected Liquid Welfare at an equilibrium (pure, mixed,
or Bayesian Nash) and is given by LPoA(v) = sups

OPT(v)
LW(s(v))
 s ∈Equilibria

.
3
Simultaneous First Price Auctions
In this section, we prove our main theorem that, for mixed Nash equilibria, the
Liquid Price of Anarchy of simultaneous ﬁrst price auctions is constant. In what
follows we build up notation and intuition toward the proof. Recall that agents
have additive valuations and submit separate bids on each item. We assume that
the buyers bid according to a mixed Nash equilibrium b ∼s. For all items we
can deﬁne an “expected price per item” at equilibrium or just a “price per item”
as p = (p1, . . . , pm), where pj = n
i=1 Eb∼s[bij · xij(b·j)].
Each bidder i has a good chance of winning a particular item if they bid
above the expected price of this item. To this end we deﬁne boosted prices
p = (p1, . . . , pm), where pj = αpj for some α > 1 (α = 2 will be suﬃcient for
us). One simple observation about p is the following:
Observation 1. Revenue is related to prices, namely: REV(s) =
1
α
m
j=1 pj,
where REV(s) denotes the expected revenue at the equilibrium proﬁle s.
We next show that if players bid on a fraction of an item j according to pj, then
they win a large fraction of j in expectation. The proof is in the full version of
our paper [3].
Proposition 1. For any item j, if a player bids on a δ-fraction of item j at
price pj, then the player receives in expectation at least a δ ·

1 −1
α

-fraction of
item j.
When relating prices to Liquid Welfare we notice that

Liquid Price of Anarchy
11
Observation 2. Revenue is bounded by the Liquid Welfare: REV(s) ≤LW(s),
where LW(s) denotes the expected Liquid Welfare at the equilibrium proﬁle s.
We consider the following Linear Program for the allocation problem with
the goal of optimizing Liquid Welfare.
Maximize
n

i=1
m

j=1
vij · zij
Liquid linear program (LLP)
Subject to

j
vij · zij ≤Bi
∀i;

i
zij ≤1
∀j;
zij ≥0
∀i, j.
We denote by y = (yij) the optimal solution to LLP. Notice that the solution
for the Liquid Welfare never beneﬁts from allocating a set of items to a player
such that their value for the set exceeds their budget. Thus
Observation 3. The solution to LLP is equal to the optimal allocation, namely:
n
i=1
m

j=1
vij · yij = OPT.
We now deﬁne some notation that will be useful in order to obtain our
result. We let qij
def
= Eb∼s[xij(b·j)] be the expected fraction of item j that
player i receives at an equilibrium strategy s. In addition, for each agent i,
we consider a set of high value items Ji
def
=
	
j | vij ≥pj

. In particular, in
our deviations, we ensure that each player i only bids on items in Ji, since this
guarantees that they attain nonnegative utility if they win such items. We further
deﬁne Qi
def
= Prb∼s[vi(xi(b)) ≥Bi] to be the probability that vi(xi) ≥Bi at
equilibrium (recall that xi denotes the random set that player i receives in the
mixed Nash equilibrium). We also deﬁne two sets of bidders, the ﬁrst one is
for budget feasibility reasons and the second is for bidders that often fall under
their budget in equilibrium (these sets need not be disjoint). In particular, for a
ﬁxed parameter γ > 1 (γ = 4 will be suﬃcient for us), we deﬁne sets I1 and I2:
I1
def
=

i
 γ 
j∈Ji pj · qij ≤Bi

and I2
def
=

i
 Qi ≤
1
2γ

.
Throughout our proof, we focus on bidders in the set I
def
= I1 ∩I2. As men-
tioned, the way we achieve our main result is to consider two types of deviations
for all players in I, the ﬁrst of which is a deviation towards an optimal solution,
and the second of which is a γ-boosting deviation (where players essentially bid
on a larger fraction of items by a factor γ relative to what they receive at equi-
librium, namely γ · qij). We only consider deviations for players in set I for the
following reasons. Players in I1 are guaranteed to respect their budgetary con-
straints in our γ-boosting deviation. Players that do not belong to I2 have the
property that the value they receive at equilibrium often exceeds their budgets,
and hence such players already contribute a lot to the Liquid Welfare at equilib-
rium. In particular, whenever a player receives a value that exceeds their budget,
their contribution to the Liquid Welfare at equilibrium is at least as much as
their contribution in the optimal Liquid Welfare, which is always bounded above
by their budget. Hence, we need only consider players in I2 as far as deviations

12
Y. Azar et al.
are concerned. We deﬁne sets I1
def
= [n] \ I1, I2
def
= [n] \ I2, and I
def
= [n] \ I. To
this end, we relate the total budget of bidders outside of the set I to the revenue
at equilibrium s. The proof is in the full version of our paper [3].
Proposition 2. The total budget of players in I is small: 
i∈I Bi < α · γ ·
REV(s) + 
i∈I2 Bi.
To achieve our result, we essentially consider two main ideas for player devi-
ations in set I. The ﬁrst idea is to use the solution to LLP as guidance to claim
that players can extract a large amount of value relative to the optimal solution.
Deﬁne the ﬁrst LLP deviation to be b1 = (b′
i, b-i), where in b′
i buyer i bids on a
yij-fraction of each item j ∈Ji with price pj. We note that the LLP deviation
b1 is feasible, since vij ≥pj for every j ∈Ji, and 
j vij · yij ≤Bi as y is a
solution to LLP.
Lemma 1 (LLP deviations). Buyers in I at equilibrium s derive large value:

i∈I

j
vij · qij ≥

1 −1
α
 ⎛
⎝OPT −α (1 + γ) REV(s) −

i∈I2
Bi
⎞
⎠.
We defer the proof of Lemma 1 to the full version of our paper [3]. We now
turn to our second type of deviation, but we need to further restrict the set of
items that players bid on. In particular, we let Γi =

j
 qij ≤1
γ

, and deﬁne
Gi = Ji∩Γi. The set Γi is deﬁned to ensure that each player i that deviates never
bids on a fraction of an item j that exceeds 1. We now deﬁne the γ-boosting
deviation as b2 = (b′
i, b-i), where in b′
i buyer i bids on a γ · qij-fraction of each
item j ∈Gi with price pj, where γ > 1 is a constant. Note that each b2 deviation
for every i ∈I is feasible since I ⊆I1.
Lemma 2 (γ-boosting deviation). The value derived by buyers in I is com-
parable to the Liquid Welfare obtained at equilibrium:

1 −
α
γ(α −1)
 
i∈I

j
vij · qij ≤α · REV(s) + 2 · LW(s) −1
γ

i∈I2
Bi.
We defer the proof of Lemma 2 to the full version of our paper [3]. Now we have
all necessary components to conclude the proof of our main theorem and show
that the Liquid Price of Anarchy of any mixed Nash equilibrium is bounded.
The proof is given in the full version of our paper [3].
Theorem 1. For mixed Nash equilibria, the Liquid Price of Anarchy of simul-
taneous ﬁrst price auctions is constant (at most 26).
The above reasoning also extends to Bayesian Nash equilibria with the same
LPoA bound.
Theorem 2. For Bayesian Nash equilibria, the Liquid Price of Anarchy of
simultaneous ﬁrst price auctions is constant (at most 26).

Liquid Price of Anarchy
13
We omit the proof as it is very similar to the proof of Theorem 1. We also study
pure Nash equilibria of simultaneous ﬁrst price auctions. The proof of the next
theorem is given in the full version of our paper [3].
Theorem 3. Consider a simultaneous ﬁrst price auction where budgeted bidders
have fractionally-subadditive valuations3. If b is a pure Nash equilibrium, then
LW(b) ≥OPT
2 .
A complementary tightness result for Theorem 3 is given in the full version of our
paper [3]. Unfortunately, this result is not quite satisfying compared to mixed
Nash equilibria, as pure Nash equilibria might not even exist (see the full version
of our paper [3]).
References
1. Anari, N., Goel, G., Nikzad, A.: Mechanism design for crowdsourcing: an optimal
1–1/e competitive budget-feasible mechanism for large markets. In: FOCS, pp.
266–275 (2014)
2. Ausubel, L.M.: An eﬃcient ascending-bid auction for multiple objects. Am. Econ.
Rev. 94(5), 1452–1475 (2004)
3. Azar, Y., Feldman, M., Gravin, N., Roytman, A.: Liquid price of anarchy. CoRR
abs/1511.01132 (2015)
4. Bei, X., Chen, N., Gravin, N., Lu, P.: Budget feasible mechanism design: From
prior-free to bayesian. In: STOC, pp. 449–458 (2012)
5. Benoit, J.P., Krishna, V.: Multiple-object auctions with budget constrained bid-
ders. Rev. Econ. Stud. 68(1), 155–179 (2001)
6. Bhattacharya, S., Conitzer, V., Munagala, K., Xia, L.: Incentive compatible budget
elicitation in multi-unit auctions. In: SODA, pp. 554–572 (2010)
7. Bhawalkar, K., Roughgarden, T.: Welfare guarantees for combinatorial auctions
with item bidding. In: SODA, pp. 700–709 (2011)
8. Bhawalkar, K., Roughgarden, T.: Simultaneous single-item auctions. In: Goldberg,
P.W. (ed.) WINE 2012. LNCS, vol. 7695, pp. 337–349. Springer, Heidelberg (2012).
doi:10.1007/978-3-642-35311-6 25
9. Borgs, C., Chayes, J., Immorlica, N., Mahdian, M., Saberi, A.: Multi-unit auctions
with budget-constrained bidders. In: EC, pp. 44–51 (2005)
10. Cai, Y., Papadimitriou, C.: Simultaneous Bayesian auctions and computational
complexity. In: EC, pp. 895–910 (2014)
11. Caragiannis, I., Voudouris, A.A.: Welfare guarantees for proportional allocations.
In: Lavi, R. (ed.) SAGT 2014. LNCS, vol. 8768, pp. 206–217. Springer, Heidelberg
(2014). doi:10.1007/978-3-662-44803-8 18
12. Chan, H., Chen, J.: Truthful multi-unit procurements with budgets. In: Liu, T.-Y.,
Qi, Q., Ye, Y. (eds.) WINE 2014. LNCS, vol. 8877, pp. 89–105. Springer, Cham
(2014). doi:10.1007/978-3-319-13129-0 7
13. Chawla, S., Malec, D., Malekian, A.: Bayesian mechanism design for budget-
constrained agents. In: EC, pp. 253–262 (2011)
3 Valuation v is fractionally-subadditive or equivalently XOS if there is a set of additive
valuations A = {a1, . . . , aℓ} such that vi(S) = maxa∈A a(S) for every S ⊆[m]. XOS
is a super class of submodular and additive valuations.

14
Y. Azar et al.
14. Che, Y.K., Gale, I.: Standard auctions with ﬁnancially constrained bidders. Rev.
Econ. Stud. 65(1), 1–21 (1998)
15. Chen, N., Gravin, N., Lu, P.: On the approximability of budget feasible mecha-
nisms. In: SODA, pp. 685–699 (2011)
16. Christodoulou, G., Kov´acs, A., Schapira, M.: Bayesian combinatorial auctions.
In: Aceto, L., Damg˚ard, I., Goldberg, L.A., Halld´orsson, M.M., Ing´olfsd´ottir, A.,
Walukiewicz, I. (eds.) ICALP 2008. LNCS, vol. 5125, pp. 820–832. Springer, Hei-
delberg (2008). doi:10.1007/978-3-540-70575-8 67
17. Christodoulou, G., Kov´acs, A., Sgouritsa, A., Tang, B.: Tight bounds for the price
of anarchy of simultaneous ﬁrst price auctions. CoRR abs/1312.2371 (2013)
18. Christodoulou, G., Sgouritsa, A., Tang, B.: On the eﬃciency of the propor-
tional allocation mechanism for divisible resources. In: Hoefer, M. (ed.) SAGT
2015. LNCS, vol. 9347, pp. 165–177. Springer, Heidelberg (2015). doi:10.1007/
978-3-662-48433-3 13
19. Dobzinski, S., Fu, H., Kleinberg, R.: On the complexity of computing an equilib-
rium in combinatorial auctions. In: SODA, pp. 110–122 (2015)
20. Dobzinski, S., Lavi, R., Nisan, N.: Multi-unit auctions with budget limits. In:
FOCS, pp. 260–269 (2008)
21. Dobzinski, S., Leme, R.P.: Eﬃciency guarantees in auctions with budgets.
In: Esparza, J., Fraigniaud, P., Husfeldt, T., Koutsoupias, E. (eds.) ICALP
2014. LNCS, vol. 8572, pp. 392–404. Springer, Heidelberg (2014). doi:10.1007/
978-3-662-43948-7 33
22. Dobzinski, S., Papadimitriou, C., Singer, Y.: Mechanisms for complement-free pro-
curement. In: EC, pp. 273–282 (2011)
23. Dughmi, S., Eden, A., Feldman, M., Fiat, A., Leonardi, S.: Lottery pricing equi-
libria. In: EC, pp. 401–418 (2016)
24. D¨utting, P., Henzinger, M., Starnberger, M.: Valuation compressions in VCG-based
combinatorial auctions. In: Chen, Y., Immorlica, N. (eds.) WINE 2013. LNCS, vol.
8289, pp. 146–159. Springer, Heidelberg (2013). doi:10.1007/978-3-642-45046-4 13
25. Feldman, M., Fu, H., Gravin, N., Lucier, B.: Simultaneous auctions are (almost)
eﬃcient. In: STOC, pp. 201–210 (2013)
26. Feldman, M., Gravin, N., Lucier, B.: Combinatorial walrasian equilibrium. In:
STOC, pp. 61–70 (2013)
27. Hartline, J., Hoy, D., Taggart, S.: Price of anarchy for auction revenue. In: EC, pp.
693–710 (2014)
28. Hassidim, A., Kaplan, H., Mansour, Y., Nisan, N.: Non-price equilibria in markets
of discrete goods. In: EC, pp. 295–296 (2011)
29. Koutsoupias, E., Papadimitriou, C.: Worst-case equilibria. In: Meinel, C., Tison,
S. (eds.) STACS 1999. LNCS, vol. 1563, pp. 404–413. Springer, Heidelberg (1999).
doi:10.1007/3-540-49116-3 38
30. Laﬀont, J.J., Robert, J.: Optimal auction with ﬁnancially constrained buyers.
Econ. Lett. 52(2), 181–186 (1996)
31. Lehmann, B., Lehmann, D., Nisan, N.: Combinatorial auctions with decreasing
marginal utilities. Games Econ. Behav. 55(2), 270–296 (2006)
32. Lu, P., Xiao, T.: Improved eﬃciency guarantees in auctions with budgets. In: EC,
pp. 397–413 (2015)
33. Malakhov, A., Vohra, R.V.: Optimal auctions for asymmetrically budget con-
strained bidders. Rev. Econ. Des. 12(4), 245–257 (2008)
34. Pai, M., Vohra, R.V.: Optimal auctions with ﬁnancially constrained bidders. Dis-
cussion papers, Northwestern University, Center for Mathematical Studies in Eco-
nomics and Management Science, August 2008

Liquid Price of Anarchy
15
35. Roughgarden, T.: Intrinsic robustness of the price of anarchy. In: STOC, pp. 513–
522 (2009)
36. Roughgarden, T., Tardos, E.: Introduction to the ineﬃciency of equilibria. In:
Nisan, N., Roughgarden, T., Tardos, E., Vazirani, V.V. (eds.) Algorithmic Game
Theory. Cambridge University Press, New York (2007)
37. Singer, Y.: Budget feasible mechanisms. In: FOCS, pp. 765–774 (2010)
38. Syrgkanis, V., Tardos, E.: Composable and eﬃcient mechanisms. In: STOC, pp.
211–220 (2013)

Tight Welfare Guarantees for Pure Nash
Equilibria of the Uniform Price Auction
Georgios Birmpas1, Evangelos Markakis1, Orestis Telelis2(B),
and Artem Tsikiridis1
1 Department of Informatics, Athens University of Economics and Business,
Athens, Greece
{gebirbas,markakis,tsikiridis15}@aueb.gr
2 Department of Digital Systems, University of Piraeus, Piraeus, Greece
telelis@gmail.com
Abstract. We revisit the ineﬃciency of the uniform price auction, one
of the standard multi-unit auction formats, for allocating multiple units
of a single good. In the uniform price auction, each bidder submits a
sequence of non-increasing marginal bids, one for each additional unit.
The per unit price is then set to be the highest losing bid. We focus on
the pure Nash equilibria of such auctions, for bidders with submodular
valuation functions. Our result is a tight upper and lower bound on the
ineﬃciency of equilibria, showing that the Price of Anarchy is bounded
by 2.188. This resolves one of the open questions posed in previous works
on multi-unit auctions.
1
Introduction
The Uniform Price Auction is one of the standard multi-unit auction formats, for
allocating multiple units of a single good, at a uniform price per unit. Multi-unit
auctions have been in use for a long time, with important applications, such
as the auctions oﬀerred by the U.S. and U.K. Treasuries for selling bonds to
investors. They are also being deployed in various platforms, including several
online brokers [9,10]. In the literature, multi-unit auctions have been a subject
of study ever since the seminal work of Vickrey [13], and some formats were
conceived even earlier, by Friedman [6]. The quantiﬁcation of their ineﬃciency
at equilibrium has been the subject of recent works [4,7,8,12], via derivation
of upper and lower bounds on the Price of Anarchy, in the full and incomplete
information models. The outcomes of these works are quite encouraging, as they
establish that the ineﬃciency is bounded by a small constant.
In this work we derive tight bounds for the Price of Anarchy of pure Nash
equilibria of the uniform price auction. For such an auction on k units, each
bidder is required to submit a sequence of non-increasing bids, one for each
additional unit. Among all submitted bids the k highest win the auction and
This work has been partly supported by the University of Piraeus Research Center,
and by a research program of the Athens University of Economics and Business.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 16–28, 2017.
DOI: 10.1007/978-3-319-66700-3 2

Tight Welfare Guarantees for Pure Nash Equilibria
17
each bidder receives as many units of the good as the number of his winning bids.
The highest losing bid is then chosen as the uniform price that each bidder pays,
per unit won. The simplicity of this auction format is counterbalanced however
by the fact that it does not support truthful bidding in dominant strategies,
thus encouraging strategic behavior. The underlying strategic game induced by
the auction is known to possess pure Nash equilibria, and a polynomial time
algorithm for computing such an equilibrium is developed in [8]. However, [8]
derives a tight bound for the Price of Anarchy of only a strict subset of such
equilibria (in undominated strategies). For the full set of pure Nash equilibria,
the results of [7] show that the Price of Anarchy is between 2 −1
k and 3.146.
The source of ineﬃciency in the uniform price auction is partly due to a demand
reduction eﬀect discussed in [1], where bidders may have incentives to understate
their demand, so as to receive less units at a lower price per unit, and partly due
to the use of dominated strategies. These eﬀects motivate the further study and
quantiﬁcation of the ineﬃciency for this auction format.
Contribution. We focus on the pure Nash equilibria of the uniform price auction,
for bidders with submodular valuation functions. Our results are tight upper
and lower bounds on the ineﬃciency of pure equilibria for submodular bidders,
showing that the Price of Anarchy is bounded by 2.188. This resolves one of
the questions left open from [7,8]. The proof of the upper bound is based on
carefully analyzing the performance of equilibria with respect to bidders who
receive less units than in the optimal assignment. Our lower bound is obtained
by an explicit construction, which matches our upper bound as the number of
units becomes large enough.
2
Model and Deﬁnitions
We consider a multi-unit auction, involving the allocation of k units of a single
item, to a set N of n bidders, N = {1, . . . , n}. Each bidder i ∈N has a private
valuation function vi : {0, 1, . . . , k} →R+, deﬁned over the quantity of units
that he receives, with vi(0) = 0. In this work, we assume that each function vi
is a non-decreasing submodular function.
Deﬁnition 1. A valuation function f : {0, 1, . . . , k} →R+ is called submod-
ular, if for every x < y, f(x) −f(x −1) ⩾f(y) −f(y −1).
A valuation function can also be speciﬁed through a sequence of marginal
values, corresponding to the value that each additional unit yields for the bidder.
For the j-th additional unit, the bidder obtains marginal value vi(j) −vi(j −1),
which we denote by mij. Then, the function vi can be determined by the vector
mi = (mi1, . . . , mik). For submodular functions, mi1 ⩾. . . ⩾mik, by deﬁnition.
We will often use the representation of vi by mi in the sequel. We will also use
the following well known properties of submodular functions:

18
G. Birmpas et al.
Proposition 1. Given x, y ∈{0, 1, . . . , k} with x ⩽y, any non-decreasing sub-
modular function f, with f(0) = 0, satisﬁes yf(x) ⩾xf(y). Moreover, when
x < y, for any j = 1, . . . , y −x the function f satisﬁes: (f(x + j) −f(x))/j ⩾
(f(y) −f(x))/(y −x).
The standard Uniform Price Auction requires that bidders submit their non-
increasing marginal value for each additional unit; every bidder i is asked to
declare his valuation curve, as a bid vector bi = (bi1, bi2, . . . , bik), satisfying bi1 ⩾
bi2 ⩾. . . ⩾bik. Thus, bij is the declared marginal bid of i, for obtaining the j-th
unit of the item. Note that each bij may diﬀer from the bidder’s actual marginal
value, mij. Given a bidding proﬁle b = (b1, . . . , bn), the auction allocates the
k units to the k highest marginal bids. We denote this allocation by x(b) =
(x1(b), x2(b), . . . , xn(b)), where xi(b) is the number of units allocated to bidder
i. Each bidder pays a uniform price p(b) per received unit, which equals the
highest rejected marginal bid, i.e., the (k +1)-th highest marginal bid. The total
payment of bidder i is then xi(b) · p(b), and his utility for the allocation is:
ui(b) = vi(xi(b)) −xi(b) · p(b).
The (utilitarian) Social Welfare achieved under a bidding proﬁle b is deﬁned
as the sum of utilities of all interacting parties, inclusively of the auctioneer’s
revenue. This sum equals the sum of the bidders’ values for their allocations:
SW(b) =
n

i=1
vi(xi(b))
Our goal is to derive upper and lower bounds on the Price of Anarchy (PoA) of
pure Nash equilibria of the Uniform Price Auction. This is the worst-case ratio
of the optimal welfare, over the welfare achieved at a pure Nash equilibrium. If
x∗denotes an optimal allocation, then
PoA = sup
b
SW(x∗)
SW(b)
where the supremum is taken over pure equilibrium proﬁles.
Finally, following previous works on equilibrium analysis of auctions, e.g., [2,
3,8], we focus on non-overbidding proﬁles b, wherein no bidder ever outbids his
value, for any number of units. That is, for any ℓ⩽k, we assume ℓ
j=1 bij ⩽
vi(ℓ). Note that, this does not necessarily imply bij ⩽mij, except for when j = 1:
i.e., bi1 ⩽mi1 = vi(1). In our analysis, we refer to non-overbidding vectors, bi,
and proﬁles, b, as feasible.
3
Ineﬃciency Upper Bound
In this section we develop tight welfare guarantees for feasible (non-overbidding)
pure Nash equilibrium proﬁles of the uniform price auction, when the bidders
have submodular valuation functions. By the results of [7], it is already known
that for submodular valuations on k units, 2−1
k ⩽PoA ⩽3.146. We show that:

Tight Welfare Guarantees for Pure Nash Equilibria
19
Theorem 1. The Price of Anarchy of non-overbidding pure Nash equilibria of
the Uniform Price Auction with submodular bidders is at most:
2 + W0(−e−2)
1 + W0(−e−2) ≈2.188
where W0 is the ﬁrst branch of the Lambert W function.
The Lambert W function is the multi-valued inverse function of f(W) =
WeW . For more on the properties of this function, see [5].
Before we continue, we introduce ﬁrst some notation to be used throughout
the section. Let b denote a feasible bidding proﬁle. We denote the k winning
marginal bids under b by βj(b), j = 1, . . . , k, so that βj(b) is the j-th lowest
winning bid under b, thus, β1(b) ⩽β2(b) ⩽. . . ⩽βk(b). We will often apply
this notation to proﬁles of the form b−i, for some bidder i ∈N. For a proﬁle of
valuation functions (v1, v2, . . . , vn), we denote the socially optimal – i.e., welfare
maximizing – allocation by x∗= (x∗
1, . . . , x∗
n). If there are multiple such alloca-
tions, we ﬁx one for the remainder of the analysis. We deﬁne a partition of the
set of bidders, N, with reference to x∗and any arbitrary allocation x, into two
subsets, O and U, as follows:
N = O ∪U,
O = {i ∈N : xi ⩾x∗
i },
U = {i ∈N : xi < x∗
i }.
The set O contains the “overwinners”, i.e., bidders that receive in x at least
as many units as in x∗. The set U contains respectively the “underwinners”. In
our analysis, the allocations we refer to are determined by some proﬁle b, i.e.,
x ≡x(b). Consequently, the sets O and U will depend on b; for simplicity, we
omit this dependence from our notation. The following lemma states that, under
a feasible bidding proﬁle b, every bidder i ∈O retains value at least equal to a
convex combination of her socially optimal value, vi(x∗
i ), and of the sum of her
winning bids.
Lemma 1. Let b be a feasible bidding proﬁle, and let O be the set of overwinners
with respect to the allocation x(b). For every λ ∈[0, 1], and every bidder i ∈O:
vi(xi(b)) ⩾λ · vi(x∗
i ) + (1 −λ) ·
xi(b)

j=1
bij
(1)
Proof. Indeed, for every i ∈O: vi(xi(b)) = λvi(xi(b)) + (1 −λ)vi(xi(b)), which
is at least equal to λvi(x∗
i )+(1−λ)vi(xi(b)), by deﬁnition of O. Then, (1) follows
by our no-overbidding assumption on b.
⊓⊔
By deﬁnition, each overwinner is capable of “covering” her socially optimal
value. Conversely, the underwinners are the cause of social ineﬃciency. We will
bound the total ineﬃciency by transforming the leftover fractions of winning bids
of bidders in O, i.e., the term (1−λ)·xi(b)
j=1 bij for each bidder i ∈O in (1), into
fractions of the value attained by bidders in U in the optimal allocation. In this

20
G. Birmpas et al.
manner, we will quantify the value that the underwinners are missing (due to
their strategic bidding), and determine the worst-case scenario that can arise at
a pure Nash equilibrium. The following claim can be inferred from [8], and will
be used to facilitate this transformation. We present the proof for completeness.
Claim 1. Let b be any bidding proﬁle. Then it holds that:

i∈U
x∗
i −xi(b)

j=1
βj(b) ⩽

i∈O
xi(b)

j=x∗
i +1
bij.
(2)
Proof. For every unit missed under b by any bidder i ∈U (with respect to the
units won by i in the optimal allocation), there must exist some bidder ℓ∈O
that obtains this unit. If i missed x∗
i −xi(b) > 0 units under b, there are at least
as many bids issued by bidders in O who obtained collectively these units. The
sum of these bids cannot be less than the sum x∗
i −xi(b)
j=1
βj(b) of the x∗
i −xi(b)
lowest winning bids in b. Summing over i ∈U yields the desired inequality.
⊓⊔
Next, we develop a characterization of upper bounds on the Price of Anarchy.
To this end, let us ﬁrst deﬁne the following set, Λ(b), for any bidding proﬁle b.
Λ(b) =

λ ∈[0, 1] : vi(xi(b)) + (1 −λ)
x∗
i −xi(b)

j=1
βj(b) ⩾λvi(x∗
i ), ∀i ∈U

(3)
Notice that, for every b, Λ(b) ̸= ∅, because λ = 0 ∈Λ(b). The following lemma
helps us understand how one can obtain upper bounds on the Price of Anarchy.
Lemma 2. If there exists λ ∈[0, 1] such that λ ∈Λ(b), for every feasible pure
Nash equilibrium proﬁle b of the Uniform Price Auction, then the Price of Anar-
chy of feasible pure Nash equilibria is at most λ−1.
Proof. Fix a feasible pure Nash equilibrium proﬁle b and consider any λ ∈Λ(b).
Then, we can apply consecutively the partition N = O ∪U with respect to b,
Lemma 1, Claim 1 and, ﬁnally, the deﬁnition of Λ(b), to obtain:
SW(b) =

i∈O
vi(xi(b)) +

i∈U
vi(xi(b))
⩾λ

i∈O
vi(x∗
i ) + (1 −λ)

i∈O
xi(b)

j=1
bij +

i∈U
vi(xi(b))
⩾λ

i∈O
vi(x∗
i ) + (1 −λ)

i∈O
xi(b)

j=x∗
i +1
bij +

i∈U
vi(xi(b))
⩾λ

i∈O
vi(x∗
i ) +

i∈U

(1 −λ)
x∗
i −xi(b)

j=1
βj(b) + vi(xi(b))

⩾λ

i∈O
vi(x∗
i ) +

i∈U
λ · vi(x∗
i ) = λ · SW(x∗)
⊓⊔

Tight Welfare Guarantees for Pure Nash Equilibria
21
Using λ = 0 with Lemma 2, yields the trivial upper bound of ∞. To obtain
better upper bounds, Lemma 2 shows that we need to understand better the sets
Λ(b), and whether underwinners can extract at equilibrium a good fraction of
their value under the optimal assignment. By the deﬁnition of these sets, the next
step towards this is to derive lower bounds on every βℓ(b) for each underwinner
i ∈U, and every value ℓ= 1, . . . , x∗
i −xi(b). The lower bound that we will use
is formally expressed below.
Lemma 3. Let b be a pure Nash equilibrium of the Uniform Price Auction and
x∗be a socially optimal allocation. For every underwinning bidder i ∈U under
b and for every ℓ= 1, . . . , x∗
i −xi(b):
βℓ(b) ⩾
1
xi(b) + ℓ·

vi(xi(b) + ℓ) −vi(xi(b))

(4)
We defer the proof of this statement, in order to explain ﬁrst how – along with
Lemma 2 – it leads to the proof of Theorem 1.
Proof (of Theorem 1). Using Lemma 2, we identify values of λ that belong
to every Λ(b). Fix any feasible pure Nash equilibrium proﬁle b and, for every
bidder i ∈U, let qi(b) = x∗
i −xi(b). To simplify the notation, we use hereafter
xi for xi(b), p for p(b), qi for qi(b), and βj for βj(b), (always with respect to
the Nash equilibrium b).
Consider an arbitrary λ ∈[0, 1] and, keeping everything else ﬁxed, deﬁne
h(λ) = vi(xi) + (1 −λ) · qi
j=1 βj. We can now have the following implications.
h(λ) = vi(xi) + (1 −λ) ·
qi

j=1
βj
⩾vi(xi) + (1 −λ) ·
qi

j=1
1
j + xi
·

vi(xi + j) −vi(xi)

(5)
= vi(xi) + (1 −λ) ·
qi

j=1

j
j + xi
· vi(xi + j) −vi(xi)
j
	
⩾vi(xi) + (1 −λ) · vi(x∗
i ) −vi(xi)
x∗
i −xi
·
qi

j=1
j
j + xi
.
(6)
In the derivation above, inequality (5) follows by applying (4) from Lemma 3,
for every βj, j = 1, . . . , qi. Inequality (6) follows by application of the second
statement of Proposition 1, which yields vi(xi+j)−vi(xi)
j
⩾vi(x∗
i )−vi(xi)
x∗
i −xi
, for any
j = 1, . . . , qi.
Suppose now that under the equilibrium b, there exists i ∈U such that xi =
0. In order for some λ to belong to Λ(b), we would need to have h(λ) ⩾λvi(x∗
i ).
Using (6), for the underwinners with xi = 0, and substituting vi(xi) = 0, we

22
G. Birmpas et al.
obtain: h(λ) ⩾(1 −λ)vi(x∗
i ). If we now impose that (1 −λ)vi(x∗
i ) ⩾λvi(x∗
i ), we
obtain λ ⩽1/2. Thus, any value of λ in [0, 1/2] satisﬁes the constraint in the
deﬁnition of Λ(b) for bidders in U with xi = 0. It remains to consider the more
interesting case, which is for bidders in U with xi > 0. We continue from (6) to
bound h(λ) as follows:
h(λ) ⩾λvi(xi) + (1 −λ) ·
⎛
⎝vi(xi) + vi(x∗
i ) −vi(xi)
x∗
i −xi
·
qi

j=1
j
j + xi
⎞
⎠
⩾λ · vi(xi) + (1 −λ) ·
⎛
⎝
x∗
i

j=xi+1
mij
⎞
⎠·
⎛
⎝1 +
xi
x∗
i −xi
·
⎛
⎝1 −
qi

j=1
1
j + xi
⎞
⎠
⎞
⎠
⩾λ · vi(xi) + (1 −λ) ·
⎛
⎝
x∗
i

j=xi+1
mij
⎞
⎠·

1 +
xi
x∗
i −xi
·

1 −
 x∗
i
xi
1
y dy

⩾λ · vi(xi) + (1 −λ) ·
⎛
⎝
x∗
i

j=xi+1
mij
⎞
⎠·

1 +
xi
x∗
i −xi
·

1 + ln xi
x∗
i
		
= λ · vi(xi) + (1 −λ) ·
⎛
⎝
x∗
i

j=xi+1
mij
⎞
⎠·

1 +
xi
x∗
i
1 −xi
x∗
i
·

1 + ln xi
x∗
i
	
The second inequality follows from the fact that vi(xi(b)) ⩾
xi
x∗
i −xi ·x∗
i
j=xi+1 mij,
which is an implication of the ﬁrst statement of Proposition 1. We have bounded
the sum of harmonic terms by using n
k=m f(k) ⩽
 n
m−1 f(x)dx, which holds for
any monotonically decreasing positive function.
To continue, we minimize the function f(y) = 1 +
y
1−y · (1 + ln y) over (0, 1),
since xi/x∗
i belongs to this interval.
Fact 1. The minimum of the function f(y) = 1 +
y
1−y · (1 + ln y) over (0, 1),
is achieved at y = −W0(−e−2), where W0 is the ﬁrst branch of the Lambert W
function.
By substituting, we obtain a new lower bound on h(λ) as follows:
h(λ) ⩾λ · vi(xi(b)) + (1 −λ) ·
⎛
⎝
x∗
i

j=xi+1
mij
⎞
⎠·

1 + W0(−e−2)

If we now set the right hand side of the above to be greater than or equal to
λvi(x∗
i ), we can check which values of λ can belong to Λ(b). In particular, we
notice that by using λ∗= (1 + W0(−e−2))/(2 + W0(−e−2)) ≈0.457, we have
that h(λ∗) ⩾λ∗vi(x∗
i ) for every bidder i ∈U with xi > 0. Since for bidders with
xi = 0, we found earlier that λ ⩽1/2 suﬃces, and since λ∗< 1/2, we conclude
that λ∗∈Λ(b). Hence, the theorem follows by Lemma 2.
⊓⊔

Tight Welfare Guarantees for Pure Nash Equilibria
23
To complete our analysis, we provide the proof of Lemma 3.
Proof (of Lemma 3). Let b denote a feasible pure Nash equilibrium proﬁle
and p(b) be the uniform price under b. Fix an underwinning bidder i ∈U. We
explore whether i is able to deviate from b feasibly and unilaterally to obtain ℓ
additional units for ℓ= 1, . . . , x∗
i −xi(b). Consider the following deviation b′
i,
for bidder i, and for any such ℓ.
b′
i =

bi1, · · · , bir



r bids
, βℓ(b−i) + ϵ, βℓ(b−i) + ϵ, . . . , βℓ(b−i) + ϵ



xi(b) + ℓ−r bids
, 0, 0, . . . , 0

,
where 0 ⩽r ⩽xi(b) is the index of the last bid in bi, up to position xi(b),
that is strictly greater than βℓ(b−i) + ϵ, and ϵ > 0 is any suﬃciently small
positive constant. The last index of b′
i with a value of βℓ(b−i)+ϵ is the (xi +ℓ)-
th bid. All subsequent bids are set to 0. Observe that such a bidding vector
(should it be feasible) would grant bidder i exactly xi(b)+ℓunits in total in the
proﬁle (b′
i, b−i): the ﬁrst r bids of b′
i were already winning bids in b and each
of the next xi(b) + ℓ−r bids exceed the ℓ-th lowest winning bid of the other
bidders, βℓ(b−i). Moreover, the price at (b′
i, b−i) would be βℓ(b−i); this is now
the highest losing bid (issued by some other bidder in the auction).
Note that b′
i may not always be a feasible deviation, since it may not obey
the no-overbidding assumption. We continue by examining two cases separately.
Case 1: The bidding vector b′
i is a feasible deviation. Then bidder i obtains
ℓadditional units by deviating. But since b is a pure Nash equilibrium, the
utility of the bidder at (b′
i, b−i) cannot be higher than the utility obtained by
the bidder at b, i.e.:
vi(xi(b) + ℓ) −(xi(b) + ℓ) · βℓ(b−i) ⩽vi(xi(b)) −xi(b) · p(b)
Thus, for a bidder that may feasibly perform such a deviation, a lower bound
for βℓis, for ℓ= 1, . . . , x∗
i −xi(b):
βℓ(b−i) ⩾
1
ℓ+ xi(b) ·

vi(xi(b) + ℓ) −vi(xi(b)) + xi(b) · p(b)

By dropping the non-negative term xi(b) · p(b) and since βℓ(b) ⩾βℓ(b−i) for
every ℓ= 1, . . . , x∗
i −xi(b), we obtain (4).
Before continuing to examine the second case, we identify ﬁrst a useful inequality
pertaining to the feasibility of b′
i, given the initial feasible proﬁle b.
Claim 2. For ℓ= 1, . . . , x∗
i −xi(b), the vector b′
i is feasible if and only if
vi(xi(b) + ℓ) ⩾
xi(b)+ℓ

j=1
b′
ij

24
G. Birmpas et al.
Proof. If b′
i is a feasible deviation, the inequality holds, by deﬁnition of no-
overbidding. For the reverse direction, we will show that if b′
i is not feasible, i.e.,
it violates the no-overbidding assumption, then vi(xi(b) + ℓ) < xi(b)+ℓ
j=1
b′
ij.
When b′
i is not feasible, we know there exists an index t ⩽xi(b) + ℓ, such that
vi(t) < t
j=1 b′
ij. Note also that t > r, because b′
ij = bij for j ⩽r and b is a
feasible bidding vector. Assume that t < xi(b)+ℓsince, otherwise, we are done.
We can decompose the sum of bids in our inequality as:
vi(t) <
t

j=1
b′
ij =
r

j=1
b′
ij +
t

j=r+1
b′
ij =
r

j=1
bij + (t −r)(βℓ(b−i) + ϵ)
By rearranging the terms we obtain:
(t −r)(βℓ(b−i) + ϵ) > vi(t) −
r

j=1
bij = vi(t) −vi(r) + vi(r) −
r

j=1
bij
⩾vi(t) −vi(r) =
t

j=r+1
mi(j)
This means that there exists an index s ∈{r + 1, . . . , t} such that mis <
βℓ(b−i) + ϵ. Then, by deﬁnition of b′
i and by the non-increasing marginal
values of the submodular valuation function, we derive that mij < b′
ij, for
j = s + 1, . . . , xi(b) + ℓ. Hence, since the no-overbidding assumption was vio-
lated at index t, it will continue to be violated if we include all the non-zero
bids of b′
i, up until the index xi(b) + ℓ. Thus, vi(xi(b) + ℓ) < xi(b)+ℓ
j=1
b′
ij, as
claimed.
⊓⊔
Case 2: Suppose b′
i is not feasible, i.e., it involves overbidding. Then we can
still infer a lower bound on βℓ(b), by exploiting Claim 2, as follows:
vi(xi(b) + ℓ) <
xi(b)+ℓ

j=1
b′
ij =
r

j=1
bij + (xi(b) + ℓ−r) ·

βℓ(b−i) + ϵ

⩽
xi(b)

j=1
bij + (xi(b) + ℓ) ·

βℓ(b−i) + ϵ

⩽vi(xi(b)) + (xi(b) + ℓ) ·

βℓ(b−i) + ϵ

where the last inequality holds because b is feasible. By rearranging, we obtain:
βℓ(b−i) >
1
ℓ+ xi(b) ·

vi(xi(b) + ℓ) −vi(xi(b))

−ϵ.
Observe that the above strict inequality holds for any suﬃciently small constant
ϵ > 0. Since also βℓ(b−i) ⩽βℓ(b), inequality (4) follows.
⊓⊔

Tight Welfare Guarantees for Pure Nash Equilibria
25
4
A Matching Lower Bound
We now present a lower bound, establishing that our upper bound is tight1.
Theorem 2. For any k ⩾8, the Price of Anarchy of the Uniform Price Auction
for pure Nash equilibria and submodular bidders is at least
1 +
(1 −1
k)(1 + W0(−e−2))
1
k−1 + 1 + (−(1 −1
k)W0(−e−2) −1
k) ln(−W0(−e−2) + 1
k)
and approaches (2 + W0(−e−2))/(1 + W0(−e−2)) ≈2.188 as k grows.
Proof. We construct an instance of the auction with two bidders and k ⩾8
units. Let x ∈{1, 2, . . . , k −2} be a parameter that we will set later on. The
valuation function of bidder 1 assigns value only for the ﬁrst unit and equals
m11 = k −1 −x
k −1
+
k−1−x

i=1
i
x + i
For the remaining units, we have m1j = 0, for any j ⩾2.
The valuation function of bidder 2 is given by the following marginal values:
m2j =

1,
j = 1, . . . , k −1
0,
j = k
Hence, the optimal allocation is for bidder 1 to obtain 1 unit and for bidder 2
to obtain k −1 units. Consider a bidding proﬁle b = (b1, b2) deﬁned as follows:
b1j =
⎧
⎪
⎨
⎪
⎩
1 −
x
k−1,
j = 1
1 −
x
k−j+1,
j = 2, . . . , k −x
0,
otherwise
⎫
⎪
⎬
⎪
⎭
and
b2j =

ϵ,
j = 1, . . . , x
0,
j > x
 
.
Here, ϵ > 0 is any small positive quantity no larger than 1.
We will see that this construction yields better lower bounds than the previ-
ously known bound of 2 −1
k, when k ⩾11. For example, for k = 11 and x = 2
we obtain the following instance:
m1 = (5.942, 0, 0, . . . , 0, 0, 0), b1 =
 8
10, 8
10, 7
9, 6
8, 5
7, . . . , 1
3, 0, 0
	
m2 = (1, 1, . . . , 1, 1, 0), b2 = (ϵ, ϵ, 0, 0, . . . , 0, 0)
It is easy to verify that this instance already yields a lower bound of 2.007,
on the Price of Anarchy. Coming back now to the analysis for general k and x,
we will ﬁrst ensure that both bidding vectors b1, b2 adhere to no-overbidding.
For the vector b1, it suﬃces to note that
k−x

j=1
b1j = k −1 −x
k −1
+
k−x

j=2
k −j + 1 −x
k −j + 1
= k −1 −x
k −1
+
k−1−x

i=1
i
x + i = m11
1 We note that Theorem 2 holds for any deterministic tie-breaking rule.

26
G. Birmpas et al.
where the last equality holds by changing indices and setting i = k −j + 1 −x.
Therefore, we have that k−x
j=1 b1j = v1(k −x). And this directly implies that
for any ℓ< k −x, we have ℓ
j=1 b1j < v1(ℓ). It is also straightforward that for
ℓ> k −x, the no-overbidding assumption cannot be violated. Similarly, for the
vector b2, it is easy to check that it complies to no-overbidding.
Under b, bidder 1 obtains k −x units and bidder 2 obtains x units. Notice
that in this proﬁle the uniform price is 0, as there is no contest for any unit;
bidder 1 bids for exactly k −x units, while bidder 2 bids for x units. All other
bids are 0. We also note that b1 is a weakly dominated strategy.
We now argue that b is a pure Nash equilibrium. Bidder 1 clearly has no
incentive to deviate. She is interested only in the ﬁrst unit, and there is no
incentive to win more units, since that would increase the price. She is also not
interested in deviating to receive less units than in the current proﬁle. Such a
deviation, would either grant her zero units, and thus no utility, or would grant
her at least one unit with the same utility as in b.
Let us examine the case of bidder 2. Since bidder 2 is not interested in the
last unit, we can consider only deviation vectors b′
2 with b′
2k = 0. Note that
under b, u2(b) = x. Hence, bidder 2 does not have an incentive to obtain less
than x units, since the price will then still remain 0, and she will only have a
lower utility. It therefore suﬃces to consider what happens when she tries to
obtain ℓadditional units, where ℓ= 1, . . . , k −x −1. To do so, bidder 2 must
outbid some of the winning bids of b1. In particular, to obtain ℓadditional units
at the minimum possible price, she must outbid the bid b1t of bidder 1, where
t is the index t = k −x −(ℓ−1). If she issues a bid b′
2, where the ﬁrst x + ℓ
coordinates outbid b1t and the remaining bids are 0, then she will obtain exactly
x + ℓunits, and the new price (i.e., the new highest losing bid) will be precisely
b1t. However, any such attempt will grant bidder 2 utility equal to u2(b), since
u2(b1, b′
2) = v(x + ℓ) −(x + ℓ) · b1t
= x + ℓ−(x + ℓ) · (1 −
x
x + ℓ) = x = u2(b).
We conclude that the proﬁle b is a pure Nash Equilibrium. The ratio of the
optimal Social Welfare to the one in b is at least:
SW(x∗)
SW(b) = v1(1) + v2(k −1)
v1(k −x) + v2(x)
= 1 +
k −1 −x
k−1−x
k−1
+ k−1−x
i=1
i
x+i + x
= 1 +
k −1 −x
k−1−x
k−1
+ k −1 −x k−1
i=x+1
1
i
⩾1 +
k −1 −x
k−1−x
k−1
+ k −1 −x
 k
x+1
1
ydy
⩾1 +
k −1 −x
k−1−x
k−1
+ k −1 −x ln
k
x+1
(7)
At this point we set x = ⌊−(k −1)W0(−e−2)⌋, where W0 is the ﬁrst branch
of the Lambert W function. To continue from (7), we will need to ensure

Tight Welfare Guarantees for Pure Nash Equilibria
27
that −W0(−e−2)(k −1) −1 > 0, which holds for k ⩾8. Substitution of x in (7)
and standard algebraic manipulations yield a lower bound for (7) equal to:
f(k) = 1 +
(1 −1
k)(1 + W0(−e−2))
1
k−1 + 1 + (−(1 −1
k)W0(−e−2) −1
k) ln(−W0(−e−2) + 1
k)
So far, we have shown that SW(x∗)/SW(b) ⩾f(k). The theorem follows by
observing that, as k goes to ∞:
lim
k→∞f(k) = 1 +
1 + W0(−e−2)
1 −W0(−e−2) · ln(−W0(−e−2)) = 2 + W0(−e−2)
1 + W0(−e−2),
where we use that ln(−W0(y)) = −W0(y)+ln(−y), for y ∈[−e−1, 0). This stems
from the deﬁnition of the Lambert W function, particularly of W0 [5].
⊓⊔
5
Conclusions
We presented a tight bound for the Price of Anarchy of pure Nash equilibria
and for bidders with submodular valuation functions. There are still several
intriguing open questions for future research in multi-unit auctions. First, it
is not clear to us if our proof can be recast into the smoothness framework
of [11,12]. Second, when going beyond submodular valuations to the superclass
of subadditive functions, the bounds are not tight. It still remains elusive to
produce lower bounds tailored for subadditive functions, and the best known
upper bound is 4, due to [7]. Finally, a major open problem is to tighten the
known gaps for the set of Bayes-Nash equilibria.
References
1. Ausubel, L., Cramton, P.: Demand reduction and ineﬃciency in multi-unit auc-
tions. Techincal report, University of Maryland (2002)
2. Bhawalkar, K., Roughgarden, T.: Welfare guarantees for combinatorial auctions
with item bidding. In: Proceedings of the Twenty-Second Annual ACM-SIAM
Symposium on Discrete Algorithms (SODA), pp. 700–709 (2011)
3. Christodoulou, G., Kov´acs, A., Schapira, M.: Bayesian combinatorial auctions.
J. ACM 63(2), 11:1–11:19 (2016). (Preliminary version appeared at ICALP(1)
2008:820–832)
4. Christodoulou, G., Kov´acs, A., Sgouritsa, A., Tang, B.: Tight bounds for the price
of anarchy of simultaneous ﬁrst-price auctions. ACM Trans. Econ. Comput. 4(2),
9:1–9:33 (2016)
5. Corless, R.M., Gonnet, G.H., Hare, D.E.G., Jeﬀrey, D.J., Knuth, D.E.: On the
Lambert W function. Adv. Comput. Math. 5, 329–359 (1996)
6. Friedman, M.: A Program for Monetary Stability. Fordham University Press,
New York (1960)
7. de Keijzer, B., Markakis, E., Sch¨afer, G., Telelis, O.: Ineﬃciency of standard multi-
unit auctions. In: Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013. LNCS, vol.
8125, pp. 385–396. Springer, Heidelberg (2013). doi:10.1007/978-3-642-40450-4 33.
(Extended version available at arXiv:1303.1646)

28
G. Birmpas et al.
8. Markakis, E., Telelis, O.: Uniform price auctions: equilibria and eﬀciency.
Theor. Comput. Syst. 57(3), 549–575 (2015). (Preliminary version appeared at
SAGT2012:227–238)
9. Milgrom, P.: Putting Auction Theory to Work. Cambridge University Press,
Cambridge (2004)
10. Ockenfels, A., Reiley, D.H., Sadrieh, A.: Economics and Information Systems.
Handbooks in Information Systems, vol. 1, chap. 12, pp. 571–628. Online Auc-
tions, Emerald Group Publishing Limited (2006)
11. Roughgarden, T.: Intrinsic robustness of the price of anarchy. J. ACM 62(5), 32:1–
32:42 (2015). (Preliminary version appeared at ACM STOC 2009:513–522)
12. Syrgkanis, V., Tardos, E.: Composable and eﬃcient mechanisms. In: Proceedings
of the 45th ACM Symposium on the Theory of Computing (STOC 2013), pp.
211–220 (2013). (Extended version available at arXiv:1213.1325)
13. Vickrey, W.: Counterspeculation, auctions, and competitive sealed tenders. J.
Finan. 16(1), 8–37 (1961)

Online Random Sampling for Budgeted Settings
Alon Eden1(B), Michal Feldman1,2, and Adi Vardi1
1 Computer Science Department, Tel Aviv University, Tel Aviv-Yafo, Israel
alonarden@gmail.com, michal.feldman@cs.tau.ac.il, adi.vardi@gmail.com
2 Microsoft Research Israel, Herzliya, Israel
Abstract. We study online multi-unit auctions in which each agent’s
private type consists of the agent’s arrival and departure times, valua-
tion function and budget. Similarly to secretary settings, the diﬀerent
attributes of the agents’ types are determined by an adversary, but the
arrival process is random. We establish a general framework for devising
truthful random sampling mechanisms for online multi-unit settings with
budgeted agents. We demonstrate the applicability of our framework by
applying it to diﬀerent objective functions (revenue and liquid welfare),
and a range of assumptions about the agents’ valuations (additive or
general) and the items’ nature (divisible or indivisible). Our main result
is the design of mechanisms for additive bidders with budget constraints
that extract a constant fraction of the optimal revenue, for divisible and
indivisible items (under a standard large market assumption). We also
show a mechanism that extracts a constant fraction of the optimal liquid
welfare for general valuations over divisible items.
1
Introduction
In a typical setting of sales of online ad slots, advertisers arrive at diﬀerent
times, each with her own preferences. The auctioneer (e.g., cnn.com) decides
about the allocation of the ad slots to the advertisers and how much to charge
them. Scenario of this type have inspired the study of mechanism design in online
settings, and random sampling has been proposed as a useful approach for the
design of truthful mechanisms in online settings [19].
The random sampling framework was ﬁrst introduced in the context of selling
identical items in oﬄine settings [18]. The basic idea of random sampling is to
divide the agents into two sets of roughly equal size. Then, sell half of the items to
each set at a price calculated according to the counterpart set. Random sampling
mechanisms diﬀer from each other in the allocation and pricing functions they
apply, but they all operate according to the principle described above. The use of
random sampling became widespread due to its desired properties: It is simple,
trivially truthful and achieves good guarantees for a wide variety of settings. Our
This work was partially supported by the European Research Council under the
European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant
agreement number 337122.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 29–40, 2017.
DOI: 10.1007/978-3-319-66700-3 3

30
A. Eden et al.
goal in this paper is to generalize the random sampling approach to settings in
which agents arrive in an online fashion and have budgets.
Random sampling mechanisms have been previously proposed for online set-
tings without budgets and for oﬄine settings with budgets. Hajiaghayi et al.
[19] applied the random sampling approach to online settings without budgets,
and devised truthful mechanisms that approximate the auctioneer’s revenue and
the social welfare up to constant factors. While this was a major progress in the
applicability of random sampling, their techniques are restricted to unit-demand
valuations and quasi-linear utilities.
Borgs et al. [7] applied the random sampling approach to oﬄine settings
with budgets. Budget constraints impose major challenges on auction design
since utilities are no longer quasi-linear. For example, the seminal VCG mech-
anism cannot work in non quasi-linear settings. In fact, it was shown that no
truthful mechanism can give a non-trivial approximation to the social welfare
in such settings [13].1 Borgs et al. [7] were able to overcome these challenges in
oﬄine settings, and designed a truthful mechanism that gives constant approxi-
mation to revenue in oﬄine settings with budgets (under a standard large market
assumption).
The scenarios described above address either the budget constraints or the
online nature of arrival. It might seem that we already have all the necessary
ingredients to address the combination of both. Not surprisingly, however, it is
not at all clear how to combine the existing techniques for our setting. First, some
of the techniques above are tailored to unit-demand valuations, whereas we are
interested in mechanisms for additive (or even general) valuations. Like in other
problems in the literature on revenue approximation, the transition from unit-
demand valuations to additive valuations requires entirely new techniques (e.g.,
pricing mechanisms for revenue maximization, [4,8,10]). Second, the combina-
tion of online arrival and budgets imposes new challenges that require new ideas.
In what follows, we present our model followed by our results and techniques.
1.1
Model
We consider a setting with a set N = {1, . . . , n} of n agents, who arrive in an
online fashion. Each agent i has a private type, represented by the following
parameters: (i) ai and di: The respective arrival and departure times of agent i
(clearly, di ≥ai). The interval [ai, di] is referred to as agent i’s time frame. (ii)
ti = (vi, bi): The utility type of the agent, which contains the agent’s valuation
function vi : R≥0 →R≥0 (which maps a given amount of items to a non-negative
value) and the agent’s budget, bi. There are m identical items (either divisible
or indivisible). An allocation function determines an allocation xi for agent i.
The utility of agent i for obtaining an allocation xi within her real time frame
for a payment of pi is:
ui(xi, pi) =

vi(xi) −pi
pi ≤bi
−∞
pi > bi
.
(1)
1 This impossibility holds even if budgets are public.

Online Random Sampling for Budgeted Settings
31
We consider an online auction with a secretary “ﬂavor.” An adversary states
a vector of time frames ([a1, d1] , [a2, d2] , . . . , [an, dn]) such that ai < aj for
every i < j, and a vector of utility types (t1, t2, . . . , tn). A random permutation
is used to match time frames with utility types. That is, a permutation π :
N →N is sampled uniformly at random and agent i’s type is given by the
tuple

ai, di, tπ(i)

. As in [19]2, we assume that arrival times are distinct, but
the results also extend to non-distinct arrival times if agents cannot bid before
their real arrival times3.
Agents report their type upon arrival, and can manipulate any component
of it. In particular, they can report earlier or later arrival and departure times,
and arbitrary utility types. We consider mechanisms that satisfy the following
properties: (i) Feasibility: The mechanism does not sell more items than are
available. (ii) Ex-ante Individual Rationality: An agent’s expected utility from
an allocation and payment is non-negative. (iii) Incentive Compatibility: An
agent’s expected utility is maximized when she reports her true type.
We consider two natural objective for budgeted settings: revenue and liquid
welfare. The revenue obtained by the mechanism is simply the sum of payments
of the agents to the mechanism.
The liquid welfare objective is deﬁned as follows. Since the items are iden-
tical and divisible, it is without loss of generality to consider a single divisible
item. Each agent has a non-decreasing valuation function vi : [0, 1] →R+ and
a budget bi. The liquid welfare of an agent i from allocation xi is deﬁned as
the minimum between her valuation for xi and her budget, and is denoted
by vi(xi) = min(vi(xi), bi). The liquid welfare of an allocation vector x is
W(x) = 
i vi(xi). Let OPT = maxx W(x) be the optimal liquid welfare. In
the full version we design a mechanism for the allocation of divisible items to
agents with hard budget constraints and monotonically non-decreasing valuation
functions with the goal of approximating the optimal liquid welfare.
1.2
Previous Techniques and Their Limitations
Hajiaghayi et al. [19] suggested the following scheme for online settings with unit-
demand valuations (and no budget constraints): Set the ﬁrst (roughly) half of the
arriving agents as the sampling set, and the remaining ones as the performance
set. All the revenue guarantees are obtained from the agents in the performance
set; the agents in the sampling set are used merely for learning the valuations
in the market. Induce the agents in the sampling set to reveal their true type
by applying the VCG mechanism4, and use this information to extract revenue
2 Based on personal communication with the authors, this is essentially what is
assumed for the correctness of Mechanism RMk in Sect. 6 in [19].
3 A description of the tie-breaking rule for this case appears in the full version.
4 While VCG is deﬁned and analyzed for oﬄine settings, it is shown in [19] that it can
also be applied in online settings by invoking it at the time where last agent arrives,
serving only the agents that haven’t departed yet. While this method does not give
any revenue guarantees, it is only used to extract truthful information from agents
in the sampling set.

32
A. Eden et al.
from the agents in the performance set. The proposed mechanism is truthful
and obtains a constant factor approximation to revenue for unit-demand agents.
Borgs et al. [7] devised allocation and payment functions that, when applied to
a random sampling scheme, give good approximation to the revenue obtained in
oﬄine settings with budgets.
A natural approach for devising mechanisms for our setting is to combine the
techniques of Hajiaghayi et al. [19] and Borgs et al. [7]. In particular, use the
scheme of the former (to address the online nature of arrival) with the alloca-
tion and payments of the latter (to handle budgets). However, there are several
obstacles to such an approach. First, the scheme proposed by [19] is restricted to
agents with unit-demand valuations. In particular, agents cannot beneﬁt from
reporting a later arrival time (thereby being considered in the performance set)
since the scheme ensures that the price in the sampling set never exceeds the
price in the performance set. This is indeed suﬃcient for unit-demand agents,
but does not extend beyond this class of valuations (in particular, to additive
valuations). Second, while VCG can be used to encourage truthfulness in settings
without budgets, it is well known that VCG is limited to quasi-linear settings,
thus cannot work for settings with budgets.
1.3
Our Results and Techniques
We establish a general framework for devising truthful random sampling mech-
anisms for online multi-unit settings with budgeted agents. We demonstrate the
applicability of our framework by applying it to diﬀerent objective functions
(revenue and liquid welfare), and a range of assumptions about the agents’ val-
uations (additive or general) and the items’ nature (divisible or indivisible).
Our framework splits the agents into sampling and performance sets of roughly
the same size, based on the arrival time. In order to induce agents in the sam-
pling set to report their type truthfully, we invoke random sampling at the time
where the last agent in the sampling set arrives (recall VCG cannot be used due
to budget constraints). In order to ensure that an agent cannot gain by delaying
her arrival time, we use an impersonation technique. Namely, we treat an agent in
the performance set as if she were in the sampling set. In particular, an agent in
the performance set receives at most the allocation she would have received had
she been in the sampling set, and at the same price. The impersonation techniques
guarantees truthfulness; it remains to design the allocation and payment functions
so that they do not lead to a high loss in revenue. We devise such functions for two
cases of interest. Our main result is the following:
Theorem: We devise truthful mechanisms for the allocation of divisible and
indivisible items among budgeted agents with additive valuations in online set-
tings. These mechanisms give a constant approximation to the optimal revenue,
under a large market assumption.
The proposed mechanism combines our general framework with the allocation
and payment functions of [7]. We ﬁrst show that the impersonation technique

Online Random Sampling for Budgeted Settings
33
does not lead to a high loss in revenue. In particular, we have to prove that when
the allocation of an agent from the performance set is limited by the allocation
she would have gotten in the sampling set, the approximation guarantee is not
signiﬁcantly hurt. An additional challenge that arises in the case of indivisible
items is the need to sell items in their entirety. The use of lotteries is limited
since the realization must be carried out in an online manner. To address this
challenge, we provide an online rounding procedure which rounds the allocation
in a way that loses only a constant factor in the approximation. As in [7], we
apply a large market assumption. Without this assumption, no truthful mecha-
nism can achieve a constant approximation to the optimal revenue. In addition
to the setting above, we demonstrate the applicability of our framework in a
diﬀerent setting with budgets:
Theorem: We devise a truthful mechanism for the allocation of divisible items
among budgeted agents with general (monotone) valuation functions in online
settings. This mechanism gives a constant approximation to the optimal liquid
welfare.
This setting imposes new challenges, since the valuations are general and no
large market assumption is invoked. While we apply our framework to settings
with budgets, it is general enough to be applied to other non quasi-linear settings.
1.4
Additional Related Work
Online auctions have been the subject of a vast body of work. [22] introduced an
online model in which agents have decreasing marginal valuations over identical
indivisible items. While in there model the agent’s value is private, her arrival
time is public. A wide variety of additional online auction settings, such as
digital goods [5,6] and combinatorial auctions [2], have been studied under the
assumption of private values and public arrival times.
Similarly to our model and the model of [19], online settings in which agents
arrive in a random order were also considered in [3,21]. Friedman and Parkes
[16] considered the case where an agent’s arrival time is also part of her private
information, and thus can also be manipulated. Additional auction settings were
studied under the assumption that an agent’s arrival and departure times are
private [20,23,26].
Oﬄine mechanisms for budgeted agents have been considered, both for rev-
enue maximization and welfare maximization. In the context of revenue maxi-
mization, Abrams [1] also considered the model of Borgs et al. [7] where indivis-
ible and identical items are sold to additive agents with hard budget constrains.
Abrams establishes the relation between the revenue achieved by an optimal
uniform-price mechanism and an optimal mechanism with heterogeneous prices.
Maximizing revenue was also considered in Bayesian settings [9] and with the
goal of approximating the optimal envy free revenue [11,14].
As stated above, in general budgeted settings it is impossible to approximate
the optimal social welfare using a truthful mechanism. Therefore, previous works

34
A. Eden et al.
that seeks to maximizing eﬃciency ensure that the outcome is Pareto Optimal
[12,15,17]. The most related works to our model are [7,13,19,24], which are
discussed in great detail throughout the paper.
2
Online Implementation of Random Sampling Based
Mechanisms
In this section we present a general framework for adjusting oﬄine random sam-
pling based mechanisms to online settings. Proofs of this section are deferred
to the full version. Our template mechanism Online-RS is speciﬁed in Fig. 2.
It receives as input a set of agents N, number of items m, an oﬄine pricing
function P, and an oﬄine allocation function Allocation.
The price function P receives a set of agents S and computes a per-item
price. The allocation function Allocation receives a set of agents S, a per-item
price p, total number of items k, and a cap per agent ℓ(where the cap per agent
limits the number of items an individual agent can get). It outputs an allocation
vector, where Allocationi denotes the number of items allocated to agent i.
Before we give a formal deﬁnition of Mechanism Online-RS, we provide a
non-formal description.
Step (a) [splitting]: We split the agents into two sets A and B, such that
roughly the ﬁrst n/2 arriving agents are placed in set A and the rest in set
B (see Fig. 1a).
Step (b) [sampling set]: We apply an (oﬄine) random sampling mechanism
on set A. In particular, once the last agent of set A arrives, we divide the
agents into two sets, A1 and A2, uniformly at random. We set a per-item
price p1 by applying P on set A1 and sell m/4 items to agents in A2. We
apply an analogous procedure to agents in set A2 (see Fig. 1b).
Step (c) [performance set]: Upon the arrival of an agent in set B, she is
placed in one of sets B1 or B2 uniformly at random. An agent i in B1 is
treated as if she were in A1, with the additional limitation determined by the
actual number of remaining items. Therefore, the price is calculated based
on A2. An agent in B2 is treated analogously, with allocation and payments
according to sets A1 and A2, respectively (see Fig. 1c).
The repositioning of an agent from set B in set A pushes the last agent in A
toward B, thereby altering the set A. This issue is addressed by a careful spec-
iﬁcation of the sets by which the allocation and price are determined to agents
from B. Let j denote the last agent to arrive to A (as deﬁned in Online-RS)
and let N ′ = N −{j}. The following observation is useful in our analysis.
Observation 1. Sets A1, A2 −j, B1 or B2 form a uniform partition of the
agents in N ′.
Recall that while ai and di are the real arrival and departure time of agent
i, an agent may misreport its type. We denote the reported arrival and depar-
ture time of agent i by ˆai, ˆdi, respectively. A formal deﬁnition of Mechanism
Online-RS is provided in Fig. 2.

Online Random Sampling for Budgeted Settings
35
Fig. 1. The diﬀerent steps of Online-RS.
Fig. 2. A template online random sampling mechanism.

36
A. Eden et al.
2.1
Truthfulness and Feasibility
An allocation is said to be feasible if the total number of allocated items does
not exceed the limitation and the number of items allocated to every individual
agent does not exceed the cap per agent. Let’s consider the oﬄine mechanism
M, that determines allocation based on Allocation and payment based on price
per item P(·).
The main result in this section is that mechanism Online-RS is truthful and
feasible as long as mechanism M satisﬁes incentive compatibility (IC), individual
rationality (IR), feasibility and cap monotonicity: The expected utility of an
agent is non-decreasing in the cap per agent.
Theorem 1. Mechanism Online-RS is truthful and feasible if: (i) Mechanism
M is IC, IR, feasible and cap monotone. (ii) Agent’s valuations are monotoni-
cally non-decreasing.
3
Revenue Maximization for Additive Agents
with Budgets
In this section we study a mechanism for the allocation of identical and divisible
items for agents with hard budget constraints and additive valuation functions.
The utility of agent i for obtaining an allocation xi within her time frame for a
payment of pi is:
ui(xi, pi) =

vi · xi −pi
pi ≤bi
−∞
pi > bi
.
(2)
Our goal in this section is to devise a truthful mechanism that approximates
the optimal revenue. Some of the proofs of this section are omitted and appear
in the full version.
In the full version we extend our results and analysis to the case of indivisible
items. The design of mechanisms for the indivisible case is similar, but it requires
new ideas for transforming fractional allocations into integral ones. To this end,
we devise an online rounding procedure, which leads to a constant loss in the
approximation ratio.
Let S be a set of agents and k a number of items. We deﬁne Pk(S) to be the
price that maximizes the revenue of selling at most k items to agents in S at a
uniform price: Pk(S) = argmaxp min
 
i∈S,vi≥p
bi
p , k

· p. Let OPT(S, k) be the
optimal revenue from selling at most k items to agent in S at a uniform price:
OPT(S, k) = min

i∈S,vi≥Pk(S)
bi
p , k

· Pk(S). Let OPT ∗(S, k) be the optimal
revenue from selling at most k items to agents in S at non-uniform prices (i.e.,
where the seller can discriminate between the agents).
The following theorem implies that it is suﬃcient to bound the performance
of our mechanism with respect to OPT ∗(S, k).
Theorem 2 [1].
For every set of agents S and k items, OPT(S, k)
≥
OP T ∗(S,k)
2
.

Online Random Sampling for Budgeted Settings
37
3.1
The Mechanism
Our mechanism, Rev-RS is an implementation of mechanism Online-RS
with the following allocation and payment functions. The allocation function,
Rev-Allocation (see Fig. 3) approaches the agents sequentially, allocates the
items in a greedy manner, and veriﬁes that none of the agents exceeds the cap
limitation. The payment function is Pm/4(·).
Rev-Allocation (S, p, k, ℓ)
1. Initialize k′ ←k, xi ←0 for every i ∈S.
2. For each i ∈S approached in the order of the random renaming (see ﬁrst line
in Online-RS):
– If vi ≥p:
xi ←min{bi/p, k′}
k′ ←k′ −xi
3. For every i, if xi > ℓ, set xi ←ℓ.
4. Return x.
Fig. 3. A procedure for the allocation of divisible items.
Recall that without a large market assumption, no truthful mechanism can
achieve a constant approximation to the revenue [7]. Adopting the parameter
used in Borgs et al. [7], we deﬁne ϵ(S, k) = max{bi}i∈S
OP T (S,k) . Intuitively, a smaller ϵ
implies a larger market. The main result of this section is:
Theorem 3. Rev-RS is a truthful mechanism that allocates divisible items and
gives an 8-approximation to the optimal revenue as ϵ tends to 0.
3.2
A Constant Loss Due to the Impersonation Technique
Our mechanism uses an impersonation technique. Speciﬁcally, it calculates the
allocation for each agent in set B1 as if she were in a random permutation
in set A1, and for each agent in B2 as if she were in A2 −j. According to
Observation 1, the sets A1 and B1 are equally distributed. Therefore, one can
view the impersonation technique as follows. We are given a set N1 = A1 ∪B1.
Then, the sets are partitioned uniformly at random into sets A1 and B1, and
each agent in B1 gets the same price and allocation as if she were placed in set
A1. The same holds for N2 = (A2 −j) ∪B2. With this interpretation in mind,
we prove that we lose at most a factor 2 in the revenue due to the impersonation
technique.
Let Oﬄine-Sale(S, p, k) be a mechanism that allocates k items to agents
in set S according to the allocation returned by Rev-Allocation(S, p, k, ∞),
and charges a price p per item. Impersonation-Sale(S, p, k) (see Fig. 4) is a
mechanism that sells according to the impersonation technique described above.

38
A. Eden et al.
I.e., it divides S into sets S1 and S2 uniformly at random. It then sells items to
agents in set S1 in a random order at a ﬁxed price p per item. The allocation for
each agent is calculated as if the agent was in a random permutation in set S2.
Impersonation-Sale (S, p, k)
1. Initialize ℓ←k.
2. For each agent i ∈S: With probability of 1
2 place i in set S1 and with probability
of 1
2 in set S2.
3. Let πS1 : {1, 2, . . . , |S1|} →S1 be a random permutation of the agents of S1.
4. For i = 1, 2, . . . , |S1| :
(a) Let j ←πS1(i), and let x be the allocation returned by
Rev-Allocation (S2 ∪{j}, p, k, ℓ).
(b) Allocate to agent j xj items at a price of p per item.
(c) Update ℓ←ℓ−xj.
Fig. 4. A mechanism deﬁned for the analysis of the impersonation technique.
Observation 2. Let T and S be two sets of agents such that T ⊆S and let k
be a number of items. For every agent i ∈T, E[Rev-Allocationi(T, p, k, ∞)] ≥
E[Rev-Allocationi(S, p, k, ∞)].
Lemma 1. For every set S, price p and a fraction of items k, the expected
revenue from mechanism Impersonation-Sale(S, p, k) is at least half of the
expected revenue from mechanism Oﬄine-Sale(S, p, k).
Proof. Let r be the expected revenue from mechanism Oﬄine-Sale(S, p, k). For
the sake of the analysis, assume that Oﬄine-Sale begins by placing each agent
i ∈S in S1 and S2 uniformly at random. Since each agent has a probability
of 1
2 to be placed in S1, the expected revenue extracted from agents in S1 is
r
2. Therefore, it is suﬃcient to show that for each partition of S into S1 and
S2, the expected revenue Impersonation-Sale(S, p, k) extracts from agents in
S1 is at least the expected revenue Oﬄine-Sale(S, p, k) extracts from agents
in S1. There are two cases. If Impersonation-Sale(S, p, k) allocates the entire
fraction of the item, then it collects the maximal revenue possible from price p
from agents in S1 and the claim is obviously true.
Otherwise, for each agent i ∈S1, xi < ℓ, where xi is the allocation agent i
receives in Impersonation-Sale. Therefore, the allocation of every agent i ∈S1
is not bounded by ℓin Rev-Allocation(S2 ∪{i}, p, k, ℓ), i.e., the agent receives
the same allocation she would receive in Rev-Allocation(S2 ∪{i}, p, k, ∞).
Let ¯x be the allocation returned by Rev-Allocation(S, p, k, ∞). According to
Observation 2, E[xi] ≥E[¯xi]. Since the revenue extracted out of agent i in
Impersonation-Sale is xi · p while the revenue extracted out of agent i in
Oﬄine-Sale is ¯xi · p, we get the desired result.
■
Therefore, it is suﬃcient to bound the performance of Oﬄine-Sale(S, p, k).

Online Random Sampling for Budgeted Settings
39
3.3
Analysis of Our Mechanism
Theorem 4. Mechanism Rev-RS is a truthful and feasible mechanism.
In order to prove that our mechanism approximates the optimal revenue, we
relate the revenue of our online mechanism to an oﬄine sale Oﬄine-Sale(S, p, k)
using Lemma 1. Then, we use Theorems from Borgs et al. [7] in order to prove
the oﬄine sale performs well. Speciﬁcally, they are used to prove that the random
partitions of agents to sets, as done by our mechanism, do not incur a high loss for
the revenue guarantees of our mechanism. Due to lack of space, the description
of the speciﬁc theorems we use from [7] appears in the full version.
Recall that N ′ = N −j and let OPT = OPT(N, m), OPT ′ = OPT(N ′, m).
Lemma 2. Pr [OPT ′ ≥OPT/2] ≥1 −1/n.
The following is the main technical lemma of this section, and its proof
appears in the full version.
Lemma 3. For every δ ∈[0, 1
3], the probability that the expected revenue
obtained from mechanism Rev-RS(N, m) is greater than (1−3δ)OP T ′
8
is at least

1 −2e−1/16ϵ′ 
1 −4e−δ2/(16ϵ′)
.
Let OPT ∗= OPT ∗(N, m), ϵ = ϵ(N, m) we now use Theorem 2 and Lemma 2,
to bound the expected revenue from mechanism Rev-RS with respect to OPT ∗.
Theorem 5. For every δ ∈[0, 1
3], the probability that the expected revenue
obtained from mechanism Rev-RS(N, m) is greater than (1−3δ)OP T ∗
32
is at least
(1 −1/n)

1 −2e−1/32ϵ 
1 −4e−δ2/(32ϵ)
.
The proof of Theorem 3 now follows directly:
Proof of Theorem 3: By deﬁnition, when ϵ tends to 0, OPT ′ approaches OPT.
Therefore, the bound from Lemma 3 becomes: for every δ ∈[0, 1
3], the probability
that the expected revenue obtained from mechanism Rev-RS(N, m) is greater
than (1−3δ)OP T ∗
16
is at least

1 −2e−1/32ϵ 
1 −4e−δ2/(32ϵ)
. When ϵ tends to 0,
for every δ this probability tends to 1. Therefore, the current analysis gives a
16-approximation.
In the full version we show how to improve the approximation factor to be
arbitrarily close to 8.
■
References
1. Abrams, Z.: Revenue maximization when bidders have budgets. In: SODA, pp.
1074–1082. SIAM (2006)
2. Awerbuch, B., Azar, Y., Meyerson, A.: Reducing truth-telling online mechanisms
to online optimization. In: STOC, pp. 503–510. ACM (2003)
3. Babaioﬀ, M., Immorlica, N., Kleinberg, R.: Matroids, secretary problems, and
online mechanisms. In: SODA, pp. 434–443. SIAM (2007)

40
A. Eden et al.
4. Babaioﬀ, M., Immorlica, N., Lucier, Weinberg, S.M.: A simple and approximately
optimal mechanism for an additive buyer. In: FOCS (2014)
5. Bar-Yossef, Z., Hildrum, K., Wu, F.: Incentive-compatible online auctions for dig-
ital goods. In: SODA, pp. 964–970. SIAM (2002)
6. Blum, A., Hartline, J.D.: Near-optimal online auctions. In: SODA, pp. 1156–1163.
SIAM (2005)
7. Borgs, C., Chayes, J., Immorlica, N., Mahdian, M., Saberi, A.: Multi-unit auctions
with budget-constrained bidders. In: EC, pp. 44–51. ACM (2005)
8. Chawla, S., Hartline, J.D., Malec, D.L., Sivan, B.: Multi-parameter mechanism
design and sequential posted pricing. In: STOC. ACM (2010)
9. Chawla, S., Malec, D.L., Malekian, A.: Bayesian mechanism design for budget-
constrained agents. In: EC, pp. 253–262. ACM (2011)
10. Chawla, S., Malec, D.L., Sivan, B.: The power of randomness in Bayesian optimal
mechanism design. Games Econ. Behav. 91, 297–317 (2015)
11. Devanur, N.R., Ha, B.Q., Hartline, J.D.: Prior-free auctions for budgeted agents.
In: EC, pp. 287–304. ACM (2013)
12. Dobzinski, S., Lavi, R., Nisan, N.: Multi-unit auctions with budget limits. Games
Econ. Behav. 74(2), 486–503 (2012)
13. Dobzinski, S., Leme, R.P.: Eﬃciency guarantees in auctions with budgets.
In: Esparza, J., Fraigniaud, P., Husfeldt, T., Koutsoupias, E. (eds.) ICALP
2014. LNCS, vol. 8572, pp. 392–404. Springer, Heidelberg (2014). doi:10.1007/
978-3-662-43948-7 33
14. Feldman, M., Fiat, A., Leonardi, S., Sankowski, P.: Revenue maximizing envy-free
multi-unit auctions with budgets. In: EC, pp. 532–549. ACM (2012)
15. Fiat, A., Leonardi, S., Saia, J., Sankowski, P.: Single valued combinatorial auctions
with budgets. In: EC, pp. 223–232. ACM (2011)
16. Friedman, E.J., Parkes, D.C.: Pricing WiFi at starbucks: issues in online mecha-
nism design. In: EC, pp. 240–241. ACM (2003)
17. Goel, G., Mirrokni, V., Leme, R.P.: Clinching auctions with online supply. In:
SODA, pp. 605–619. SIAM (2013)
18. Goldberg, A.V., Hartline, J.D., Karlin, A.R., Saks, M., Wright, A.: Competitive
auctions. Games Econ. Behav. 55, 242–269 (2006). Elsevier
19. Hajiaghayi, M.T., Kleinberg, R., Parkes, D.C.: Adaptive limited-supply online auc-
tions. In: EC, pp. 71–80. ACM (2004)
20. Hajiaghayi, M.T., Kleinberg, R.D., Mahdian, M., Parkes, D.C.: Online auctions
with re-usable goods. In: EC, pp. 165–174. ACM (2005)
21. Kleinberg, R.: A multiple-choice secretary algorithm with applications to online
auctions. In: SODA, pp. 630–631. SIAM (2005)
22. Lavi, R., Nisan, N.: Competitive analysis of incentive compatible on-line auctions.
In: EC, pp. 233–241. ACM (2000)
23. Lavi, R., Nisan, N.: Online ascending auctions for gradually expiring items. In:
SODA, pp. 1146–1155. SIAM (2005)
24. Lu, P., Xiao, T.: Improved eﬃciency guarantees in auctions with budgets. In: EC
2015, Portland, OR, USA, 15–19 June 2015, pp. 397–413 (2015)
25. Parkes, D.C.: Online Mechanisms (2007)
26. Parkes, D.C., Singh, S.P.: An MDP-based approach to online mechanism design.
In: NIPS (2003)

Liquid Welfare Maximization in Auctions
with Multiple Items
Pinyan Lu1(B) and Tao Xiao2
1 ITCS, Shanghai University of Finance and Economics, Shanghai, China
lu.pinyan@mail.shufe.edu.cn
2 Department of Computer Science, Shanghai Jiaotong University, Shanghai, China
xt 1992@sjtu.edu.cn
Abstract. Liquid welfare is an alternative eﬃciency measure for auc-
tions with budget constrained agents. Previous studies focused on auc-
tions of a single (type of) good. In this paper, we initiate the study of
general multi-item auctions, obtaining a truthful budget feasible auction
with constant approximation ratio of liquid welfare under the assump-
tion of large market.
Our main technique is random sampling. Previously, random sam-
pling was usually used in the setting of single-parameter auctions. When
it comes to multi-dimensional settings, this technique meets a number
of obstacles and diﬃculties. In this work, we develop a series of analysis
tools and frameworks to overcome these. These tools and frameworks are
quite general and they may ﬁnd applications in other scenarios.
1
Introduction
Let us consider the following auction environment: there is one auctioneer, who
has m heterogeneous divisible items and wants to distribute them among n
agents. Since the items are divisible, W.L.O.G we assume that each item is
of one unit. Each agent i has a value per unit vij for item j. Each agent i is
also constrained by a budget Bi, which is the maximum amount of money i is
able to pay during the auction. An allocation rule A = (xij)n×m speciﬁes the
fraction of items everyone is allocated in an auction, where xij denotes that i is
allocated xij fraction of item j. We say an allocation is feasible if for each item
j, 
i xij ≤1. A feasible payment rule p = (p1, . . . , pn) speciﬁes the amount
of money each agent needs to pay, while satisfying budget constraint pi ≤Bi.
Basically, an auction is an algorithm that takes all agents’ bids as inputs, and
outputs a feasible allocation and payment rule. We say an auction is truthful if
it is every agent’s dominant strategy to bid her/his true private proﬁle (here it
means value and budget). We say an auction is universally truthful if this auction
is a distribution over deterministic truthful auctions. Put it more precisely, agent
i’s utility is xijvij −pi if pi ≤Bi and −∞if pi ≥Bi. We also assume that the
agents are risk-neutral.
Liquid Welfare. Due to the budget constraints, it is impossible to get any
reasonable guarantee for the social welfare objective, even in the simplest setting
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 41–52, 2017.
DOI: 10.1007/978-3-319-66700-3 4

42
P. Lu and T. Xiao
of single item auction. The main obstacle is that we cannot allocate item(s) to
an agent with very high value but low budget truthfully. To overcome this, an
alternative measure called liquid welfare was proposed in [16]. Basically, each
agent’s contribution to the liquid welfare is her/his valuation for the allocated
bundle, capped by her/his budget. A precise deﬁnition is given as follows.
Deﬁnition 1. The liquid welfare of an assignment A = (xij)n×m in the multi-
item setting is
LW(A) =
n

i=1
min{
m

j=1
vijxij, Bi}.
Just like social welfare is the maximum amount of money an omniscient auction-
eer can obtain in a budget-free setting, the liquid welfare measure is actually the
maximum amount of money an omniscient auctioneer would be able to extract
from agents in the budget setting. Therefore, this measure is a quite reason-
able eﬃciency measure in the budget setting. More justiﬁcation about the liquid
welfare can be found in [16]. Our goal is to design a universally truthful, bud-
get feasible mechanism that guarantees some good approximation towards this
liquid welfare objective.
For the simplest setting of single item environment, the problem was ﬁrst
studied in [16], where an O(log n) approximation mechanism was obtained. In a
previous work [25], we improved the result to O(1) approximation. Nothing was
previously known for multi-item setting. Although the valuation for each item
is additive, the total budget for each agent is shared by diﬀerent items. This
fact makes the multi-item setting much more complicated and challenging than
single item setting.
Large Market. Generally speaking, the large market assumption says that
a single agent’s contribution (power) to the total market is very small. There
is a number of recent works which are based on this assumption [2,21]. From
practical point of view, this is a very realistic assumption especially in the age
of internet economy; from theoretical point of view, this assumption is a very
interesting mathematical framework to overcome some impossibility results or
get better results than general setting.
In this paper, we study the above liquid welfare maximization problem also
with the assumption of large market. It is crucial to give a good characterization
of this large market assumption. There are a number of alternative deﬁnitions
characterizing this. We choose the following one:
∀i, Bi ≤OPT
m · c ,
where OPT is the liquid welfare for an optimal allocation and c is some large
constant. The quantity of OP T
m
represents the average contribution of each item
to the total market. Basically, the above assumption says that each agent does
not have enough budget to make a signiﬁcant interference to a typical item in
the market.

Liquid Welfare Maximization in Auctions with Multiple Items
43
Results and Techniques. We get the ﬁrst constant approximation budget
feasible truthful mechanism for liquid welfare maximization problem under the
large market assumption. Notice that the liquid welfare is an upper bound for
revenue obtained in any individual rational auction. From our proof of liquid
welfare guarantee by our auction, what we indeed prove is that the revenue from
our auction is a constant fraction of the optimal liquid welfare. As a corollary,
our mechanism also guarantees a constant approximation in terms of revenue.
The main technique used in designing our auction is random sampling. Ran-
dom sampling is a very powerful tool in designing truthful mechanisms, which
is widely applied in various of diﬀerent settings [4–7,23,24]. A typical random
sampling mechanism follows the following routine: ﬁrst divides the agents into
two groups randomly, then gathers information from one group and uses this
information as a guide to design mechanism for the agents in other group. This
approach is usually seen to be applied on single item setting. However, for the
multi-item setting, there could be a number of equally optimal solutions for the
sample set of agents, but the allocations in these diﬀerent optimal solutions can
be quite diﬀerent for the same item. Such fragility of optimal solutions brings
in diﬃculty in directly applying random sampling: from the sampling set, one
can get good estimation of the total welfare of the set, but does not necessary
give stable and useful information for individual items. To overcome this, we
use a greedy solution rather than the optimal solution as the guidance. The
greedy solution has certain robustness and monotonicity properties which are
very helpful to get useful information for every single item.
To argue that a random sampling algorithm does give a good guarantee to
some objective, the analysis usually has two steps. In the ﬁrst step, one proves
that with a constant probability, the sampling set is a good estimation of the
remaining set. Then, in the second step, one proves that under the condition
that it is a good sampling, one can get a good allocation from the remaining
set. But in the multi-item setting, there are obstacles in proving both steps.
With the large market assumption, one can prove that for a single item, with a
constant probability, it is a good sampling. But to show that a sampling indeed
gives a good estimation for a constant fraction of items, it is not suﬃcient to
apply union bound and it is not clear if applying any other tool from probability
theory would work, since the correlation between diﬀerent items could be very
complicated. We still do not know how to prove that this is true. Instead, we are
able to bypass this with a very subtle and direct estimation of the performance
without conditioning that the sampling is a good one. Our analysis has some
similarities with that in [12].
Related Work. As budget is becoming an important issue that cannot be
neglected in practice, many theoretical investigations have been devoted to ana-
lyzing auctions for budget constrained agents. One of the important directions
leads to optimal auction design which tries to maximize revenue for the auc-
tioneer [1,8,10,14,20]. Another direction focus on maximizing social eﬃciency.
In particular, there are a number of previous works focusing on a solution con-
cept of Pareto Eﬃciency [15,22]. Note that the liquid welfare is not the only

44
P. Lu and T. Xiao
quantiﬁable measure for eﬃciency for budget constrained agents. There are sim-
ilar alternatives for this measure, studied in [14,27], but for diﬀerent solution
concepts.
Beyond designing auctions that maximize liquid welfare itself, there are other
interesting works that follow this liquid welfare notion. For example [3,9,13,18,
27] focus on the liquid welfare guarantee at equilibrium. [19] focused on an online
version of auctions with budget constraints.
Another line of research is devoted to study budget feasible mechanism design
for reversal auction, in which the budget constrained buyer becomes the auction-
eer rather than bidder. This model was ﬁrst proposed and studied by Singer [26].
Since then, several improvements have been obtained [7,11,17].
For random sampling technique applied on mechanism design, there are also
a long line of research focusing on it [4–7,23–25]. Most of them are for single item
setting. Some of them [4–6] also applied random sampling techniques on multi-
item setting. But unlike our setting, they have constraints on solution space,
number of agents and value proﬁle.
Open Problems and Discussions. Here, we consider the simplest valuation
function, which is linear for each item and additive across diﬀerent items. It is
natural to extend them to more complicated ones. We conjecture that a similar
mechanism can be applied to concave (for each item) and sub-modular (across
items) functions and leave it to future work.
Theoretically, the most important and interesting open question is whether
we can remove the large market assumption and obtain a constant approximation
mechanism in general multi item setting. It is easy to see that one can combine
the random sampling mechanism with the modiﬁed ground bundle second price
auction to get an O(m) approximation mechanism. So, it is a constant approxi-
mation when the number of items is a constant. But if m is not a constant, the
problem remains open.
2
Greedy Algorithm
If all valuations and budgets are common knowledge, the oﬀline liquid welfare
maximization problem can be solved by a simple linear program. However, due
to the dedication of linear programming, we do not really have much structural
understanding or nice properties about this optimal solution. This is in contrast
to the single item setting where the optimal solution can be obtained by a simple
greedy algorithm.
To overcome this, we propose the following natural greedy algorithm for the
multi-item setting. A high level idea of this algorithm is the following: traverse
entry (i, j) in decreasing order of value (per unit). At entry (i, j), let agent i buy
some fraction of item j at price vij per unit, so that this fraction is constrained
by remaining supply and budget. A detailed formulation can be referred in the
following.
Unlike in the single item case, this greedy algorithm is not necessarily opti-
mal but gives a good guarantee towards the optimal. We shall prove that the

Liquid Welfare Maximization in Auctions with Multiple Items
45
Algorithm 1. Greedy Algorithm
input : n agents with valuations (vij)n×m and corresponding budgets
B1, . . . , Bn
output: An allocation (xij)n×m
begin
for each i ∈[n] do
Ci ←Bi;
for each j ∈[m] do
sj ←1;
for each i ∈[n] and j ∈[m] do
xij ←0;
for each vij > 0 in decreasing order do
if Ci > vijsj then
xij ←sj;
Ci ←Ci −vijsj;
sj ←0;
else
xij ←Ci
vij ;
sj ←sj −Ci
vij ;
Ci ←0;
greedy solution is a 2-approximation to optimal liquid welfare, implying that
this solution is good enough to serve as a reference to design mechanism. Most
importantly, this greedy solution enjoys a number of nice monotonicity proper-
ties which are very essential for the analysis of our mechanism in Sect. 3.
In the algorithm, if there are ties among diﬀerent vijs, we break them arbi-
trary but in ﬁxed order (a simple way is to break ties by the index of agents
and items). The tie breaking rule gives a total order on vij’s, thus making the
algorithm outputs solution deterministically.
Before we analyze the properties of the algorithm, we introduce a few more
necessary notations. Let A = (xij)n×m be some allocation. We say an allocation
is budget compatible if for every i we have m
j=1 vijxij ≤Bi. It is obvious that
the allocation derived from the above greedy algorithm is budget compatible. For
a feasible allocation that is not budget compatible, we can get a new allocation
that is budget compatible while achieving the same liquid welfare by just cutting
oﬀsome fraction of items given to this agent in order to make the value equals
to the budget. Thus we can also assume that the optimal allocation given by
linear programming is budget compatible. For budget compatible allocations, the
liquid welfare is the same as social welfare. For convenience we denote vi(A) =
m
j=1 vijxij, v(Aj) = n
i=1 vijxij and v(A) = 
i

j vijxij respectively. In this
paper, unless otherwise speciﬁed, we always use A = (xij)n×m to denote the
allocation outputted by the above greedy algorithm. For any subset T ⊆[n], we

46
P. Lu and T. Xiao
use AT to denote the allocation when running the greedy algorithm only on the
subset of agents in T. We use A∗= (x∗
ij)n×m to denote a budget compatible
optimal allocation.
We ﬁrst prove that greedy algorithm with full information guarantees at least
half of optimal liquid welfare.
Lemma 1. v(A) ≥1
2OPT.
Proof. In the greedy algorithm, by decreasing order of vijs, we always allocate
fraction of item j to agent i until agent i’s budget is exhausted or item j is sold
out. Up to the termination of the algorithm, we denote by D ⊆[n] the subset of
agents who exhaust their budgets (Ci = 0), and by F ⊆[m] the subset of items
which are sold out (sj = 0). It is clear that we have vij = 0 if i /∈D and j /∈F.
A lower bound of greedy algorithm’s liquid welfare is as follows:
2v(A) ≥

i∈D
vi(A) +

j∈F
v(Aj) =

i∈D
Bi +

j∈F
v(Aj)
For i, j such that i /∈D and j ∈F, we can see that in greedy algorithm,
after the algorithm go through this entry (i, j), item j is already sold out. This
implies vij ≤v(Aj) since every fraction of item j is sold at a price of at least vij.
To bound optimal liquid welfare, we also divide all the agents into two groups:
D and the rest. We note that these sets D and F are deﬁned with respect to the
greedy solution rather than the optimal solution. We have
OPT = v(A∗) =

i∈D
vijx∗
ij +

i/∈D
vijx∗
ij =

i∈D
vijx∗
ij +

i/∈D

j∈F
vijx∗
ij,
where the last equality uses the fact that vij = 0 for i /∈D and j /∈F. We can
further bound this by
OPT =

i∈D
vijx∗
ij +

i/∈D

j∈F
vijx∗
ij ≤

i∈D
Bi +

i/∈D

j∈F
vijx∗
ij
≤

i∈D
Bi +

j∈F
v(Aj)

i/∈D
x∗
ij
≤

i∈D
Bi +

j∈F
v(Aj) ≤2v(A),
where the ﬁrst inequality is from the budget compatibility of optimal allocation,
the second inequality uses the fact that vij ≤v(Aj) for i /∈D and j ∈F while the
third inequality uses that fact that 
i/∈D x∗
ij ≤1 since it is a feasible allocation.
This completes the proof.
⊓⊔
Not only greedy algorithm is a good approximation, we shall also prove that
it has a nice monotonicity property when running on a subset of the agents. This
is crucial for our random sampling mechanism to work.
Lemma 2. (monotonicity of greedy). Let T ⊆[n] be a subset of agents, A
and AT be the greedy solutions running on the total set [n] and its subset T
respectively. Then ∀i ∈T and j, we have vi(AT ) ≥vi(A) and v(AT
j ) ≤v(Aj).

Liquid Welfare Maximization in Auctions with Multiple Items
47
The intuition is clear that when there are less agents, each remaining agent
can get more and each item generates less welfare. Notice that this property does
not necessary hold for every single agent and item if we use optimal solution
rather than greedy solution.
Proof. We prove this by coupling every step of greedy algorithm for the inputs
[n] and T. When generating assignments A and AT , the entries (i, j)s traversed
in the algorithm keep the order in vij, except for [n] it experiences some extra
entries (i, j) when i ̸∈T. For these cases, we couple them with empty steps.
For i ∈T, we denote the remaining budget for agent i by Ci and CT
i respec-
tively. We also denote remaining supply for item j by sj and sT
j respectively. We
inductively prove that after each step, ∀i ∈T we have Ci ≥CT
i , and ∀j ∈[m]
we have sj ≤sT
j .
Initially, Ci = Bi = CT
i and sj = 1 = sT
j . Now, we assume that the property
holds before the algorithm processes entry (i, j). Notice that after going through
an entry (i, j), ∀k ∈T\{i} both CT
k and Ck remain the same. Similarly, ∀l ∈
[m]\{j} both sT
l and sl remain the same. Thus we only need to consider the
changes in Ci, CT
i , sj and sT
j at step (i, j). There are three cases.
i /∈T. In this case, the only possible change is that sj may decrease by some
certain amount. So, the monotonicity property remains to hold.
i ∈T and CT
i ≥sT
j vij. In this case, Ci ≥CT
i ≥vijsT
j ≥vijsj, thus after step
(i, j), ˆsT
j = ˆsj = 0, and ˆCT
i = CT
i −sT
j vij ≤Ci −sjvij = ˆCi, which shows that
after this step, the two properties still hold.
i ∈T and CT
i
< sT
j vij. In this case ˆCT
i
= 0 ≤ˆCi. Also ˆsT
j = sT
j −CT
i
vij ≥
max{sj −Ci
vij , 0} = ˆsj, which shows that after this step, the two properties still
hold.
From the above argument, when both algorithms terminate, ∀i ∈T, Ci ≥
CT
i , thus ∀i ∈T, vi(AT ) = Bi −CT
i ≥Bi −Ci ≥vi(A).
We further prove that v(AT
j ) ≤v(Aj). Since ∀j, sj ≤sT
j at every step of
greedy algorithm, which indicates that each fraction of unit in A is allocated
with a price no less than in AT (if not allocated the price of that fraction is 0).
Thus v(AT
j ) ≤v(Aj).
⊓⊔
3
The Random Sampling Mechanism
The greedy algorithm has some nice properties but is obviously not truthful.
To design truthful mechanism that has good guarantee, we combine this greedy
algorithm with random sampling. The idea is very simple, we randomly divide
all the agents into two groups T and R. For agents in T, they do not get any
allocation in the auction. We run the greedy algorithm on set T, and use this
result as a guide for pricing for agents in R. From the solution of the greedy
algorithm, we have a rough idea of how to set the price for each item. Then, we
simply sell the items to agents in R at ﬁxed prices which are determined by the
output of greedy algorithm. A formal description of the auction is as follows.
We present our main theorem in the following.

48
P. Lu and T. Xiao
Algorithm 2. Random Sampling Mechanism
input : n agents with valuations (vij)n×m and corresponding budgets
B1, . . . , Bn
output: An allocation and payments
begin
Randomly divide all agents with equal probability into group T and R
AT ←the greedy solution running on group T.
for j ∈[m] do
pj = 1
6v(AT
j );
Each agent i ∈R comes in a given ﬁxed order and buy the most proﬁtable
part with respect to price vector {pj} under budget feasibility and unit item
supply constraint.
Theorem 1. The random sampling mechanism is a universal truthful budget
feasible mechanism which guarantees a constant fraction of the liquid welfare
under the large market assumption.
The truthfulness and budget feasibility of this auction is obvious. In the
following two subsections, we analyse its approximation ratio. Before that, we
introduce one more notion: for a subset of agents T ⊆[n], denote v(Aj ∩T) =

i∈T vijxij.
3.1
Random Sampling and Large Market
We divide all the items into two groups. Let H be the set of easily samplable
items consists of item j that satisﬁes condition PrT ( 1
3v(Aj) ≤v(Aj ∩T) ≤
2
3v(Aj)) ≥3
4. We also denote the remaining set as G.
Firstly, we provide a simple technical concentration lemma.
Lemma 3.
[12]
Let a1 ≥a2 ≥· · · ≥al be positive real numbers such that
the sum a = l
i=1 ai satisﬁes a > 36a1. We select each number a1, · · · , al inde-
pendently at random with probability 1/2 each and let b be a random variable
representing the sum of these selected numbers. Then
Pr[a
3 < b < 2a
3 ] ≥3
4.
The key lemma in this subsection is as follows. It basically says that the
items in group G do not contribute too much in the greedy solution. This is also
the only place we use the assumption of large market throughout this paper.
Lemma 4. 
j∈G v(Aj) ≤1
6v(A)
Proof. Lemma 3 provides a suﬃcient condition for an item to be in H, namely,
Bi ≤v(Aj)
36 , ∀i ∈[n]. So, for j ∈G, there exist i ∈[n] such that Bi > v(Aj)
36 . By
the large market assumption, we have that Bi ≤OP T
m·c . As a result, we have that
v(Aj) < 36OP T
m·c
≤72v(A)
m·c
for all j ∈G. Since there are at most m items in G, we
get 
j∈G v(Aj) ≤72
c v(A). By choosing c = 432 in the large market assumption,
we get the claimed result.
⊓⊔

Liquid Welfare Maximization in Auctions with Multiple Items
49
3.2
Approximation Ratio
In the above section, we already show that items in G do not contribute much.
Thus, if our auction do get a good guarantee on items in H, then we are done. In
this subsection we will prove this. Before that we introduce a few more necessary
deﬁnitions. For an item j ∈H, we denote by Πj the set of T such that for
T ∈Πj, 1
3v(Aj) ≤v(Aj ∩T) ≤2
3v(Aj). Then, from the deﬁnition, we know that
for j ∈H, Pr(T ∈Πj) ≥3
4. For convenience, we also abuse the notation Πj to
denote the conditional distribution of T over the subset Πj. We use Π to denote
the distribution of T in the mechanism.
The following lemma shows that even if we restrict to the agents in T and
only count these T in Πj, the contribution from items in H is still signiﬁcant.
Lemma 5.

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j ) ≥1
8v(A).
Proof. We give both lower bound and upper bound for the term 
j ET ∼Πv(AT
j ).
On one hand, we have

j
ET ∼Πv(AT
j ) =

i
ET ∼Πvi(AT ) ≥

i
Pr(i ∈T)vi(A) = 1
2

i
vi(A) = 1
2v(A),
where the inequality uses the fact that vi(AT ) ≥vi(A) for any subset T and
i ∈T.
On the other hand, we have

j
ET ∼Πv(AT
j ) =

j∈G
ET ∼Πv(AT
j ) +

j∈H
ET ∼Πv(AT
j )
=

j∈G
ET ∼Πv(AT
j ) +

j∈H
[Pr(T ∈Πj)ET ∼Πjv(AT
j )
+ Pr(T /∈Πj)ET ∼Π\Πjv(AT
j )]
≤

j∈G
ET ∼Πv(Aj) +

j∈H
[Pr(T ∈Πj)ET ∼Πjv(AT
j ) + 1
4v(Aj)]
= 1
4v(A) + 3
4

j∈G
v(Aj) +

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j )
≤1
4v(A) + 1
8v(A) +

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j )
= 3
8v(A) +

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j )
where the ﬁrst inequality uses the fact that Pr(T /∈Πj) ≤1
4 and v(AT
j ) ≤v(Aj)
for all item j, while the last inequality uses Lemma 4.

50
P. Lu and T. Xiao
Connecting the lower and upper bounds for 
j ET ∼Πv(AT
j ), we have that

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j ) ≥1
8v(A).
⊓⊔
Up to this point, we have not talked about the allocation of our random
sampling algorithm but only the property of greedy solution under random sam-
pling. The following lemma gives the last piece of the analysis which connects
liquid welfare of our mechanism to the above quantity.
Lemma 6. The liquid welfare obtained from the random sampling algorithm is
at least
1
12

j∈H
Pr(T ∈Πj)ET ∼Πjv(AT
j ).
Proof. We note that the allocation outputted by our mechanism may not be
budget compatible. However, the liquid welfare is always lower bounded by the
revenue obtained by a truthful auction (note that the payment of each agent is
also bounded by both value and budget), so we only need to bound the revenue
obtained by our mechanism.
In our auction, we denote by D ⊆R the subset of agents who exhaust their
budgets, and by F ⊆[m] the subset of items which are sold out. Both sets are
random which depend on the random set T. One key observation is that for all
j /∈F and i ∈R \ D, we have vij ≤1
6v(AT
j ). For j /∈F and i ∈R \ D, agent
i did not exhaust his/her budget and item j is not sold out. The only possible
reason why agent i did not buy item j is that the price of 1
6v(AT
j ) is higher than
his/her value vij, thus we have vij ≤1
6v(AT
j ).
On one hand, the revenue (and thus the liquid welfare) is bounded by

i∈D Bi. We further have that

i∈D
Bi ≥

i∈D

j /∈F
vijxij =

j /∈F

i∈D
vijxij =

j /∈F
⎛
⎝
i∈R
vijxij −

i∈R\D
vijxij
⎞
⎠
≥

j /∈F
max

0, (v(Aj ∩R) −1
6v(AT
j ))
	
.
We note that the allocation A and xij in the above calculation are from
the greedy solution rather than the allocation given by the random sampling
mechanism. According to the above argument, this quantity does give a lower
bound for the liquid welfare of the random sampling mechanism.
On the other hand, we can also bound the revenue (and thus the liquid
welfare) from the item point of view. It is bounded by 
j∈F
1
6v(AT
j ) as the item
j ∈F is sold out at a price 1
6v(AT
j ) per unit.
Let Yj be a random variable that
Yj := 1j∈F
v(AT
j )
6
+ 1j /∈F max

0, (v(Aj ∩R) −1
6v(AT
j ))
	
.

Liquid Welfare Maximization in Auctions with Multiple Items
51
Then the above argument showed that the expected liquid welfare of our
mechanism is bounded by 1
2

j ET ∼ΠYj. We further have that

j
ET ∼ΠYj ≥

j∈H
ET ∼ΠYj ≥

j∈H
Pr(T ∈Πj)ET ∼ΠjYj,
where the inequalities use the simple fact that Yj ≥0 and one simply throw
away some terms in the summation for computing expectation.
For j ∈H and T ∈Πj, we have a better bound for Yj. If j ∈F, we directly
have Yj ≥1
6v(AT
j ). For j /∈F we have Yj ≥v(Aj ∩R) −1
6v(AT
j ). Since j ∈H
and T ∈Πj, we have
v(Aj ∩R) −1
6v(AT
j ) ≥1
3v(Aj) −1
6v(AT
j ) ≥1
3v(AT
j ) −1
6v(AT
j ) = 1
6v(AT
j ).
Thus ∀j
∈H and T
∈Πj, we have Yj
≥
1
6v(AT
j ). Therefore, the
expected liquid welfare obtained by our mechanism is at least
1
12

j∈H Pr(T ∈
Πj)ET ∼Πjv(AT
j ). This completes the proof.
⊓⊔
Put Lemmas 1, 5 and 6 together, we know that the liquid welfare of random
sampling mechanism is at least
1
192 of the optimal one. This completes the proof
of the main theorem.
References
1. Abrams, Z.: Revenue maximization when bidders have budgets. In: Proceedings
of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithm, pp.
1074–1082. Society for Industrial and Applied Mathematics (2006)
2. Anari, N., Goel, G., Nikzad, A.: Mechanism design for crowdsourcing: an optimal 1-
1/e competitive budget-feasible mechanism for large markets. In: 2014 IEEE 55th
Annual Symposium on Foundations of Computer Science (FOCS), pp. 266–275.
IEEE (2014)
3. Azar, Y., Feldman, M., Gravin, M., Roytman, A.: Liquid price of anarchy. arXiv
preprint arXiv:1511.01132 (2015)
4. Balcan, M.-F., Blum, A., Hartline, J.D., Mansour, Y.: Mechanism design via
machine learning. In 46th Annual IEEE Symposium on Foundations of Computer
Science, FOCS 2005, pp. 605–614. IEEE (2005)
5. Balcan, M.-F., Blum, A., Hartline, J.D., Mansour, Y.: Reducing mechanism design
to algorithm design via machine learning. J. Comput. Syst. Sci. 74(8), 1245–1270
(2008)
6. Balcan, M.-F., Devanur, N., Hartline, J.D., Talwar, K.: Random sampling auctions
for limited supply. Manuscript (2007, submitted)
7. Bei, X., Chen, N., Gravin, N., Lu, P.: Budget feasible mechanism design: from
prior-free to Bayesian. In: STOC, pp. 449–458 (2012)
8. Borgs, C., Chayes, J.T., Immorlica, N., Mahdian, M., Saberi, A.: Multi-unit auc-
tions with budget-constrained bidders. In: EC, pp. 44–51 (2005)
9. Caragiannis, I., Voudouris, A.A.: Welfare guarantees for proportional allocations.
Theory Comput. Syst. 59(4), 581–599 (2016)

52
P. Lu and T. Xiao
10. Chawla, S., Malec, D.L., Malekian, A.: Bayesian mechanism design for budget-
constrained agents. In: EC, pp. 253–262 (2011)
11. Chen, N., Gravin, N., Lu, P.: On the approximability of budget feasible mecha-
nisms. In: SODA, pp. 685–699 (2011)
12. Chen, N., Gravin, N., Lu, P.: Truthful generalized assignments via stable matching.
Math. Oper. Res. 39(3), 722–736 (2013)
13. Christodoulou, G., Sgouritsa, A., Tang, B.: On the eﬃciency of the proportional
allocation mechanism for divisible resources. Theory Comput. Syst. 59(4), 600–618
(2016)
14. Devanur, N.R., Ha, B.Q., Hartline, D.: Prior-free auctions for budgeted agents. In:
EC, pp. 287–304 (2013)
15. Dobzinski, S., Lavi, R., Nisan, N.: Multi-unit auctions with budget limits. Games
Econ. Behav. 74(2), 486–503 (2012)
16. Dobzinski, S., Leme, R.P.: Eﬃciency guarantees in auctions with budgets.
In: Esparza, J., Fraigniaud, P., Husfeldt, T., Koutsoupias, E. (eds.) ICALP
2014. LNCS, vol. 8572, pp. 392–404. Springer, Heidelberg (2014). doi:10.1007/
978-3-662-43948-7 33
17. Dobzinski, S., Papadimitriou, C.H., Singer, Y.: Mechanisms for complement-free
procurement. In: EC, pp. 273–282 (2011)
18. Dughmi, S., Eden, A., Feldman, M., Fiat, A., Leonardi, S.: Lottery pricing equilib-
ria. In: Proceedings of the 2016 ACM Conference on Economics and Computation,
pp. 401–418. ACM (2016)
19. Eden, A., Feldman, M., Vardi, A.: Truthful secretaries with budgets. arXiv preprint
arXiv:1504.03625 (2015)
20. Feldman, M., Fiat, A., Leonardi, S., Sankowski, P.: Revenue maximizing envy-free
multi-unit auctions with budgets. In: EC, pp. 532–549 (2012)
21. Feldman, M., Immorlica, M., Lucier, B., Roughgarden, T., Syrgkanis, V.: The price
of anarchy in large games. In: Proceedings of the 48th Annual ACM SIGACT
Symposium on Theory of Computing, pp. 963–976. ACM (2016)
22. Fiat, A., Leonardi, S., Saia, J., Sankowski, P.: Single valued combinatorial auctions
with budgets. In: EC, pp. 223–232 (2011)
23. Goldberg, A.V., Hartline, J.D., Karlin, A.R., Saks, M., Wright, A.: Competitive
auctions. Games Econ. Behav. 55(2), 242–269 (2006)
24. Gravin, N., Lu, P.: Competitive auctions for markets with positive externali-
ties. In: Fomin, F.V., Freivalds, R., Kwiatkowska, M., Peleg, D. (eds.) ICALP
2013. LNCS, vol. 7966, pp. 569–580. Springer, Heidelberg (2013). doi:10.1007/
978-3-642-39212-2 50
25. Lu, P., Xiao, T.: Improved eﬃciency guarantees in auctions with budgets. In: Pro-
ceedings of the Sixteenth ACM Conference on Economics and Computation, pp.
397–413. ACM (2015)
26. Singer, Y.: Budget feasible mechanisms. In: FOCS, pp. 765–774 (2010)
27. Syrgkanis, V., Tardos, ´E.: Composable and eﬃcient mechanisms. In: STOC, pp.
211–220 (2013)

Computational Aspects of Games

On the Nucleolus of Shortest Path Games
Mourad Ba¨ıou1 and Francisco Barahona2(B)
1 CNRS and Universit´e Clermont II,
Campus des C´ezeaux BP 125, 63173 Aubi`ere Cedex, France
2 IBM T.J. Watson Research Center, Yorktown Heights, NY 10589, USA
barahon@us.ibm.com
Abstract. We study a type of cooperative games introduced in [8] called
shortest path games. They arise on a network that has two special nodes
s and t. A coalition corresponds to a set of arcs and it receives a reward
if it can connect s and t. A coalition also incurs a cost for each arc that
it uses to connect s and t, thus the coalition must choose a path of min-
imum cost among all the arcs that it controls. These games are relevant
to logistics, communication, or supply-chain networks. We give a poly-
nomial combinatorial algorithm to compute the nucleolus. This vector
reﬂects the relative importance of each arc to ensure the connectivity
between s and t. Our development is done on a directed graph, but it
can be extended to undirected graphs and to similar games deﬁned on
the nodes of a graph.
Keywords: Cooperative games · Shortest path games · Nucleolus
1
Introduction
Shortest path games arise on a network, a coalition corresponds to a set of arcs
and it receives a reward if it can connect two ﬁxed nodes s and t. A coalition
also incurs a cost for each arc that it uses to connect s and t, thus the coalition
must choose a path of minimum cost among all the arcs that it controls. Shortest
path games have been introduced in [8], this type of games is useful to determine
the most critical links to ensure connectivity between two distinguished nodes
s and t in a network. This analysis is relevant to logistics, communication, or
supply-chain networks.
Our Results. We give a polynomial combinatorial algorithm to compute the
nucleolus of a shortest path game. This vector reﬂects the relative importance
of the diﬀerent arcs in the network that ensure the connectivity between s and
t. Our development is done on a directed graph, but it can be extended to
undirected graphs and to similar games deﬁned on the nodes of a graph.
Related Work. The core and the Shapley Value of shortest path games were
studied in [8], also the least core was studied in [2]. Flow games were introduced
in [12]. Polynomial combinatorial algorithms for computing the nucleolus of sim-
ple ﬂow games were given in [4,16]. Algorithms for computing the nucleolus of
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 55–66, 2017.
DOI: 10.1007/978-3-319-66700-3 5

56
M. Ba¨ıou and F. Barahona
several other combinatorial games have been found, see [7] for path cooperative
games, see [15] for cost allocation games in a tree, [18] for assignment games,
[13] for cardinality matching games, [5] for weighted voting games. On the other
hand computing the nucleolus is NP-Hard for minimum spanning tree games [6],
and general ﬂow games [4].
This paper is organized as follows. In Sect. 2 we give some basic deﬁnitions
and mention some basic results of Network Flows and Linear Programming. In
Sect. 3 we study the core. Section 4 contains the basics for the computation of
the nucleolus. In Sect. 5 we give an algorithm to compute the nucleolus when
the core is non-empty. In Sect. 6 we extend the algorithm to the case when the
core is empty. In Sect. 7 we study the time complexity of the algorithm.
2
Preliminaries
Here we give some deﬁnitions and mention some basic results on Network Flows
and Linear Programming. Throughout this paper we assume that we are working
with a directed graph G = (V, A). We use n to denote |V |, and m to denote
|A|. Given two distinguished nodes s and t. An st-path is a sequence of arcs
(u1, v1), (u2, v2), . . . , (uk, vk), where s = u1, vk = t, and vi = ui+1 for i =
1, . . . , k −1. A cycle is a sequence of arcs (u1, v1), (u2, v2), . . . , (uk, vk), where
u1 = vk, and vi = ui+1 for i = 1, . . . , k −1. Consider a partition of V into U and
V \ U, with s ∈U and t ∈V \ U. Then the arc-set {(u, v) | u ∈U, v ∈V \ U} is
called an st-cut. For a function w : A →R, and S ⊆A, we use w(S) to denote
w(S) = 
a∈S w(a). For S ⊆A, we use V (S) to denote the set of nodes covered
by S, i.e., V (S) = ∪(u,v)∈S{u, v}.
Shortest path games have been introduced in [8], and they are deﬁned as
follows. The graph has two distinguished vertices s and t, and there is a cost
function c : A →R+, that gives the costs for using diﬀerent arcs. There is also a
reward r obtained if s and t are connected by a path, then for a coalition S ⊆A
the value function is
v(S) =

r −m(S) if m(S) < ∞,
0
otherwise,
(1)
where m(S) = min

c(P) | P ⊆S, P is an st-path and c(P) ≤r

.
2.1
Shortest Paths
For a cost function c : A →R, a shortest st-path is an st-path of minimum
cost. The cost of a path is the sum of the costs of the arcs in the path. If the
costs are non-negative, a shortest path can be found in O(m+n log n) time with
Dijkstra’s algorithm, see [1].

On the Nucleolus of Shortest Path Games
57
2.2
Minimum Ratio Cycles
Assume that there is a cost function c : A →R, and a “time” function τ : A →
Z+, then the cost to time ratio of a cycle D is c(D)/τ(D). An algorithm to ﬁnd
a cycle that minimizes the cost to time ratio was given in [11]. In our case we
require the function τ to take the values 0 or 1, so the algorithm of [11] takes
O(nm + n2 log n) time.
2.3
Network Flows and Linear Programming
A reference for Minimum Cost Network Flows and Maximum Cost Circulations
is [1]. We just mention that the algorithm of [10] runs in O(n2m3 log n) time.
Consider the following network ﬂow problem.
max

(u,v)∈A
c(u, v)x(u, v)

(u,v)∈A
x(u, v) −

(v,u)∈A
x(v, u) = 0,
for v ∈V,
x(u, v) ≥0,
for all (u, v) ∈A.
The dual problem is
min

v∈V
0 · π(v);
π(v) −π(u) ≥c(u, v)
for all (u, v) ∈A.
Here we have a variable π for each node in V . The dual problem has a solution
if and only if there is no cycle with positive cost. The cost of a cycle is the sum
of the costs of its arcs.
In the following sections we use the following basic result on linear program-
ming. Let g(ϵ) be the value of the linear program min{cx | Ax = b + ϵd, x ≥0},
then g is a convex piecewise linear function of ϵ, cf. [3].
3
The Core
Here we study some basic properties of the core. A vector x : A →R is called an
allocation if x(A) = v(A). Here x(a) represents the amount paid to the player
a. The core is a concept introduced in [9], it is based on the following stability
condition: No subgroup of players does better if they break away from the joint
decision of all players to form their own coalition. Thus an allocation x is in the
core if x(S) ≥v(S) for each coalition S ⊆A. Therefore the core is the polytope
below.
{x ∈RA | x(A) = v(A), x(S) ≥v(S), for S ⊆A}.
(2)
Let λ be the cost of a shortest st-path in G. If λ ≥r then the core consists
of only the vector x = 0. If λ < r, the following lemma gives a description of the
core that is useful for our purposes.

58
M. Ba¨ıou and F. Barahona
Lemma 1. If λ < r, the core is also deﬁned by
x(A) = r −λ,
(3)
x(P) ≥r −c(P)
for each st-path P with c(P) ≤r,
(4)
x ≥0.
(5)
Proof. Consider an arc a, if a does not go from s to t, we have x(a) ≥0. If a
goes from s to t then we have x(a) ≥max{0, r −c(a)}. Thus either we have an
inequality (4) or an inequality (5).
If P is an st-path with c(P) ≤r, then its associated inequality (4) is among
the inequalities in (2).
Now assume that S ⊆A is not an st-path, but it contains an st-path with cost
at most r. We have m(S) = c( ¯P) where ¯P ⊆S is an st-path. Then x(S) ≥v(S)
can be written as x(S \ ¯P) + x( ¯P) ≥r −c( ¯P). This last inequality is implied by
x(a) ≥0 for a ∈S \ ¯P, and x( ¯P) ≥r −c( ¯P) that is one of the inequalities (4).
Finally if S ⊆A does not contain an st-path with cost at most r, then
x(S) ≥0 is implied by x(a) ≥0 for a ∈S.
To understand the core, we look at the set of solutions of the linear program
below.
min x(A),
x(P) ≥r −c(P), for each st-path P,
x ≥0.
(6)
Notice that the minimum above is at least max{0, r−λ}. If it is exactly this value,
then the core is nonempty, and it corresponds to the set of optimal solutions of
this linear program. If we look at r as a parameter, we have that the optimal
value is a convex piecewise linear function of r. Then there is a value ¯r such that
the core is non-empty if and only if r ≤¯r. See Fig. 1.
Fig. 1. Optimal value.
Consider now the dual of (6), this is
max

P
(r −c(P))yP ;

{yP | a ∈P} ≤1,
for each arc a; y ≥0.
There is a variable yP for each st-path P, and its associated cost is r −c(P).
Each arc has capacity one, and the sum of the variables y for the paths using a

On the Nucleolus of Shortest Path Games
59
particular arc is at most one. We can reduce this to a network ﬂow problem as
follows. We add an artiﬁcial arc from t to s with cost coeﬃcient r and inﬁnite
capacity. To every other arc a we give cost −c(a) and capacity one. Then we
look for a circulation of maximum cost.
Recall that λ is the value of a shortest st-path. We need the optimal value
to be r −λ, for this we should have one optimal solution consisting of exactly
one shortest path. The value ¯r is the maximum value of r so that there is an
optimal solution consisting of exactly one path.
Notice that the graph could contain more than one st-path with cost equal
to λ. Let A′ be the set of arcs that belong to a shortest path, and assume
that the core is non-empty. Then the graph should not contain two arc-disjoint
shortest paths. Thus the subgraph G′ = (V, A′) contains an st-cut consisting
of exactly one arc. Such an arc is called a veto-player, because every shortest
path contains it. Let P1 and P2 be two shortest st-paths. If x is an element of
the core, we have x(P1) = x(P2) = r −λ, and since x(A) = r −λ, we have
x(P1 \ P2) = x(P2 \ P1) = 0. Thus if A′′ is the set of veto-players, we have
x(a) = 0, for a ∈A\A′′. This had already been established in [8], using diﬀerent
techniques.
4
The Nucleolus
For a coalition S and a vector x ∈RA, their excess is e(x, S) = x(S) −v(S).
The nucleolus has been introduced in [17] trying to minimize dissatisfaction
of players, more precisely, the nucleolus is the allocation that lexicographically
maximizes the vector of non-decreasingly ordered excesses, cf. [17]. Thus in some
sense, it is the fairest allocation. The nucleolus can be computed with a sequence
of linear programs as follows, cf. [14]. First solve
max ϵ
x(S) ≥v(S) + ϵ,
∀S ⊂A
x(A) = v(A).
Let ϵ1 be the optimal value of this, and P1(ϵ1) be the polytope deﬁned above,
with ϵ = ϵ1, i.e., P1(ϵ1) is the set of optimal solutions of the linear program
above. For a polytope P ⊂RA let
F(P) = {S ⊆A | x(S) = y(S), ∀x, y ∈P}
(7)
denote the set of coalitions ﬁxed for P. In general given ϵr−1 we have to solve
max ϵ
(8)
x(S) ≥v(S) + ϵ, ∀S /∈F(Pr−1(ϵr−1))
(9)
x ∈Pr−1(ϵr−1).
(10)
We denote by ϵr the optimal value of this, and Pr(ϵr) the polytope above with
ϵ = ϵr. We continue for r = 2, ..., |A|, or until Pr(ϵr) is a singleton. Notice that

60
M. Ba¨ıou and F. Barahona
each time the dimension of Pr(ϵr) decreases by at least one, so it takes at most
|A| steps for Pr(ϵr) to be a singleton.
In general the diﬃculty in computing the nucleolus resides in having to solve
a sequence of linear programs with an exponential number of inequalities. In
our case we shall see that most of the inequalities are redundant, and only a
polynomial number of them is needed. Moreover these linear programs can be
solved in a combinatorial way.
5
The Nucleolus When the Core is Non-empty
In this section we study the nucleolus under the assumption that the core is non-
empty. In that case the dual of (6) should have an optimal solution consisting
of exactly one path. Thus if there are several shortest st-paths, no two of them
should be arc-disjoint. The only arcs a for which x(a) can take a non-zero value,
are the arcs that belong to the intersection of all shortest paths. To compute the
nucleolus, we have to solve the sequence of linear programs described in Sect. 4,
for that we need some changes of variables as follows.
5.1
An Alternative Description of the Core
For x in the core, deﬁne z = x + c, where c is the vectors of costs. We ﬁx one
shortest st-path P, then the following should be satisﬁed: z(a) = c(a), if a /∈P;
z(a) ≥c(a), if a ∈P; z(P) = r; z(P) ≥r, if P is an st-path; z(P) = c(P) ≥r,
if P is an st-path not containing arcs in P.
Now we use a change of variables similar to the one used in [16]. For two
nodes a and b in P we denote by Pab the sub-path of P going from a to b. Given
z as deﬁned above, for each node u in P, let pz(u) = z(Psu). Therefore we have
pz(s) = 0,
pz(t) = r,
(11)
pz(v) −pz(u) ≥c(u, v), for (u, v) ∈P.
(12)
For two nodes u and v in P, a jump Juv is a path from u to v, such that all
nodes in Juv diﬀerent from u and v are not in P, this notion was used in [16]. If
there is an arc a = (u, v) with a /∈P, then we have a jump consisting of one arc.
Consider an st-path P consisting of the sub-path Psu from s to u, then a jump
Juv from u to v, and a sub-path Pvt from v to t. Then the inequality z(P) ≥r
can be written as pz(u) + c(Juv) + r −pz(v) ≥r, or
pz(u) −pz(v) ≥−c(Juv).
(13)
Now we show that (11), (12) and (13) are suﬃcient to describe the core. We
need the lemma below.
Lemma 2. Inequalities associated with paths with more than one jump are
redundant.

On the Nucleolus of Shortest Path Games
61
Proof. Consider an st-path P with two jumps. Thus assume that P consists of
the following segments: a sub-path Psa from s to a, a jump Jab from a to b, a sub-
path Pbd from b to d, a jump Jde from d to e, and a sub-path of Pet from e to t.
Then the inequality z(P) ≥r, can be written as z(P) = pz(a) + c(Jab)+pz(d)−
pz(b)+c(Jde)+r−pz(e) ≥r, or pz(a)−pz(b)+c(Jab)+pz(d)−pz(e)+c(Jde) ≥0.
This is implied by pz(a) −pz(b) + c(Jab) ≥0 and pz(d) −pz(e) + c(Jde) ≥0.
These two inequalities correspond to st-paths with one jump. Paths with more
than two jumps can be treated in a similar way.
On the other hand, let ¯V = V (P), the set of nodes spanned by P. Consider
any function p : ¯V →R satisfying (11), (12) and (13), we can deﬁne ¯z(u, v) =
p(v) −p(u) for each arc (u, v) ∈P, ¯z(u, v) = c(u, v) for each arc (u, v) ∈A \ P,
and ¯x = ¯z −c. It is easy to see that ¯x is an element of the core. Thus there is a
bijection between the vectors in the core and the functions p : ¯V →R satisfying
(11), (12) and (13).
5.2
The Nucleolus
To compute the nucleolus we have to solve the sequence of linear programs
deﬁned in Sect. 4. The development above suggests the following procedure.
We create an auxiliary graph G′ = ( ¯V , A′) as follows. First we include in
A′ each arc (u, v) ∈P with cost d(u, v) = c(u, v). Then for every pair of nodes
u and v in ¯V , we ﬁnd the cost of a shortest path in G from u to v using only
arcs not in P and going only through nodes in V \ ¯V . Let ρ be the value of this
shortest path, we add an arc (v, u) to A′ with cost d(v, u) = −ρ. Finally we add
the arcs (s, t) and (t, s) to A′, with costs d(s, t) = r and d(t, s) = −r. Then we
impose the inequalities
p(v) −p(u) ≥d(u, v)
for all (u, v) ∈A′.
(14)
These inequalities come from the following conditions.
– For an arc (u, v) ∈P they correspond to x(u, v) ≥0.
– For an arc (u, v) /∈P, (u, v) ̸= (s, t), (t, s) they correspond to x(P) ≥r−c(P),
where P is the path consisting of Psv, a jump Jvu, and Put.
– The inequalities for (s, t) and (t, s) imply x(P) + c(P) = p(t) −p(s) = r.
Thus from a vector p satisfying (14) we can derive a vector in the core.
Moreover, as mentioned in Subsect. 2.3, the system (14) has a solution if and
only if the graph G′ has no cycle of positive weight.
Now we can describe the computation of the nucleolus. We set k = 0, ¯ϵ = 0,
and we call the arcs (s, t) and (t, s) ﬁxed. We have to solve
max μ
(15)
p(v) −p(u) ≥d(u, v)
if (u, v) ∈A′ is ﬁxed,
(16)
p(v) −p(u) ≥d(u, v) + μ
if (u, v) ∈A′ is not ﬁxed,
(17)
μ ≥0.
(18)

62
M. Ba¨ıou and F. Barahona
Inequalities (17) come from x(u, v) ≥μ for (u, v) ∈P, or x(P) ≥r −c(P) + μ
if P is an st-path with one jump. To prove that these inequalities are suﬃcient
we need the following lemma, its proof is similar to the one of Lemma 1.
Lemma 3. The inequalities x(S) ≥v(S) + ϵ, for S ⊆A, are implied by
x(P) ≥r −c(P) + ϵ,
for each st-path P; x(a) ≥ϵ; ϵ ≥0.
As seen in Subsect. 2.3, when solving (15)–(18) we are looking for the maxi-
mum value of μ so that when we increase the costs of the non-ﬁxed arcs by this
amount, the graph has no positive cycle. Thus we need d(C) + μ n(C) ≤0, for
each cycle C, where n(C) is the number of non-ﬁxed arcs in the cycle C. Then
we have to compute
¯μ = min
C
−d(C)
n(C) ,
(19)
where the minimum is taken over all cycles in G′. Here we are looking for a cycle
that minimizes a “cost to time” ratio. As mentioned in Subsect. 2.2, this can
be solved with the algorithm of [11]. Once the value ¯μ is obtained in (19), we
update the arcs costs as d(u, v) ←d(u, v) + ¯μ, for each non-ﬁxed arc (u, v) ∈A′.
Let ¯C be a cycle giving the minimum in (19), we declare ﬁxed all arcs in ¯C. We
update ¯ϵ ←¯ϵ + ¯μ, k ←k + 1, and set ϵk = ¯ϵ. As long as there is an arc in A′
that is not ﬁxed we solve (15)–(18) and continue. Since at each iteration at least
one new arc in A′ becomes ﬁxed, this procedure takes at most |A′| iterations.
6
The Nucleolus When the Core Is Empty
Here we assume that the core is empty, thus for the ﬁrst linear program deﬁned
in Sect. 4, we have ϵ1 < 0. First we have to prove that its set of optimal solutions
P1(ϵ1), is in the non-negative orthant.
Lemma 4. P1(ϵ1) ⊂RA
+.
Proof. Assume that (¯x, ϵ1) is a solution of
max ϵ
x(A) = v(A)
x(S) ≥v(S) + ϵ, for S ⊂A,
and ¯x(a0) < 0 for some arc a0 ∈A.
First we prove that if ¯x(S) = v(S) + ϵ1, then a0 ∈S. Suppose a0 /∈S. We
have two cases:
– S ∪{a0} ̸= A. Then ¯x(S ∪{a0}) < ¯x(S) = v(S) + ϵ1 ≤v(S ∪{a0}) + ϵ1. This
contradicts the feasibility of (¯x, ϵ1).

On the Nucleolus of Shortest Path Games
63
– S ∪{a0} = A. Then ¯x(A) = ¯x(S)+ ¯x(a0) = v(S)+ϵ1 + ¯x(a0) < v(S) ≤v(A).
Again this contradicts the feasibility of (¯x, ϵ1).
Then we can deﬁne x′(a0) = ¯x(a0) + β, and x′(a) = ¯x(a) −β/(m −1), for
a ∈A \ {a0}, for a small number β > 0, m = |A|. Since x′ is a better solution
we have a contradiction.
As in the previous section, we have to see that when computing the nucleolus
most inequalities are redundant. This is in the lemma below, its proof is similar
to the one of Lemma 1.
Lemma 5. Inequalities x(S) ≥v(S) + ϵ, for S ⊂A, are implied by x(P) ≥
r −c(P) + ϵ, for each st-path P, and x ≥0.
Then to compute ϵ1, we can look for the maximum value of the parameter
ϵ < 0, so that the value of the linear program below is r −λ.
min x(A); x(P) ≥r + ϵ −c(P), for each st-path P; x ≥0.
(20)
The dual of (20), is
max

P
(r + ϵ −c(P))yP ;

{yP | a ∈P} ≤1, for each arc a; y ≥0. (21)
As before, we can reduce this to a network ﬂow problem. We add an artiﬁcial
arc from t to s with cost coeﬃcient r + ϵ and inﬁnite capacity. To every other
arc a we give cost −c(a) and capacity one. Then we look for a circulation of
maximum cost. Notice that a solution of this ﬂow problem corresponds to a
set of arc-disjoint st-paths of minimum cost. Recall that m = |A|. For a non-
negative integer k, 0 ≤k ≤m, let f(k) be the value of a minimum cost set of k
arc-disjoint st-paths. Denote by g(ϵ) the value of (20), then
g(ϵ) = max
k {k(r + ϵ) −f(k)}.
(22)
Here the maximum is taken over all possible values of k so that G has k arc-
disjoint st-paths. The function g(·) is convex and piece-wise linear. One evalua-
tion of g(·) is done by solving a network ﬂow problem. In what follows we discuss
how to ﬁnd the value ϵ1 so that g(ϵ1) = r −λ, this is done with the algorithm
below.
Step 0. We set ϵ−= −r and ϵ+ = 0, thus g(ϵ−) < r −λ and g(ϵ+) > r −λ. We
denote by k(ϵ) a value of k giving the maximum in (22).
Step 1. Let k−= k(ϵ−), k+ = k(ϵ+). If k−= k+, then ϵ1 is the solution of
g(ϵ−)+k−(ϵ−ϵ−) = r−λ, and we Stop. Otherwise let ˜ϵ be the solution
of g(ϵ−) + k−(ϵ −ϵ−) = g(ϵ+) + k+ (ϵ −ϵ+).
Step 2. If g(˜ϵ) < r −λ set ϵ−= ˜ϵ. Otherwise set ϵ+ = ˜ϵ and go to Step 1.
Notice that at each iteration, either k−increases or k+ decreases, thus this
algorithm takes at most 2m iterations.

64
M. Ba¨ıou and F. Barahona
Now we assume that the value ϵ1 has been found. An optimal solution of (21)
corresponds to a set of k arc-disjoint st-paths S = {P1, . . . , Pk}. We set P =
∪iPi. Let ¯x be a solution of (20), then the complementary slackness conditions
imply ¯x(a) = 0 if a ∈A \ P, and ¯x(Pi) = r + ϵ1 −c(Pi), i = 1, . . . , k.
Let ¯z(a) = ¯x(a) + c(a), for each a ∈A, then ¯z(a) ≥c(a), for a ∈P; ¯z(a) =
c(a), if a ∈A\P; ¯z(Pi) = r+ϵ1, i = 1, . . . , k; ¯z(P) ≥r+ϵ1, for every st-path P.
Let ¯V = V (P). Before the next change of variables, we need the lemma below.
Lemma 6. Let v ∈¯V , and assume that there are two paths Pi and Pj going
through v. Then ¯z(Pi
sv) = ¯z(Pj
sv).
Proof. We have ¯z(Pi
sv) + z(Pi
vt) = ¯z(Pj
sv) + ¯z(Pj
vt) = r + ϵ1. If ¯z(Pi
sv) < ¯z(Pj
sv),
then ¯z(Pi
sv) + z(Pj
vt) < r + ϵ1. This leads to a contradiction because for the
st-path Pi
sv ∪Pj
vt we should have ¯z(Pi
sv) + z(Pj
vt) ≥r + ϵ1.
Based on Lemma 6, for any u ∈¯V we can deﬁne pz(u) = z(Pi
su), where Pi is
any path in S going through u. We have
pz(s) = 0,
pz(t) = r,
(23)
pz(v) −pz(u) ≥c(u, v), for (u, v) ∈P.
(24)
Now we use the same notion of a jump used in the last section. Consider an
st-path P consisting of the sub-path Pi
su from s to u, then a jump Juv from u
to v, and a sub-path Pj
vt from v to t. Then the inequality z(P) ≥r + ϵ1 can be
written as pz(u) + c(Juv) + r + ϵ1 −pz(v) ≥r + ϵ1, or pz(u) −pz(v) ≥−c(Juv).
Below we have the analogue of Lemma 2, its proof is similar.
Lemma 7. Inequalities associated with paths with more than one jump are
redundant.
As in Sect. 5, we create an auxiliary graph G′ = ( ¯V , A′) as follows. First we
include in A′ each arc (u, v) ∈P with cost d(u, v) = c(u, v). Then for every pair
of nodes u and v in ¯V , we ﬁnd the cost of a shortest path in G from u to v using
arcs not in P and going only through nodes in V \ ¯V . Let ρ be the value of this
shortest path, we add an arc (v, u) to A′ with cost d(v, u) = −ρ. Finally we add
the arcs (s, t) and (t, s) to A′, with costs d(s, t) = r + ϵ1 and d(t, s) = −r −ϵ1.
Then we impose the inequalities
p(v) −p(u) ≥d(u, v)
for all (u, v) ∈A′.
(25)
For a vector p satisfying (25) we can deﬁne z(u, v) = p(v) −p(u) for (u, v) ∈P,
and z(u, v) = c(u, v) for (u, v) ∈A \ P. Then x = z −c satisﬁes x(A) = r −λ
and the inequalities of (20). As before, there is a bijection between vectors x
satisfying x(A) = r −λ and the inequalities in (20), and vectors p satisfying
p(s) = 0 and (25). Now we can proceed to the computation of the nucleolus.
6.1
Computation of the Nucleolus
Recall that ϵ1 < 0. As seen in Sect. 4, we have to solve a sequence of linear
programs where we maximize a parameter ϵ. We divide this into two phases.
The case when ϵ ≤0 is treated ﬁrst, and then we continue with the case when
ϵ > 0.

On the Nucleolus of Shortest Path Games
65
The Case When ϵ ≤0. We set ¯ϵ = ϵ1, k = 0, we call ﬁxed the arcs (s, t) and
(t, s), and we have to solve
max μ
(26)
p(v) −p(u) ≥d(u, v)
if (u, v) ∈A′ is ﬁxed or (u, v) ∈P
(27)
p(v) −p(u) ≥d(u, v) + μ
if (u, v) ∈A′ \ P, and (u, v) is not ﬁxed, (28)
0 ≤μ ≤−¯ϵ.
(29)
After solving this, the new value for ϵ will be ¯ϵ + μ. For (u, v) ∈P inequalities
(27) correspond to x(u, v) ≥0. Inequalities (28) correspond to x(P) ≥r−c(P) +
¯ϵ + μ, if P is an st-path with one jump. We need the inequality μ ≤−¯ϵ in (29)
because the new value of ϵ should be non-positive.
When solving (26)–(29) we are looking for the maximum value of μ so that
the graph has no positive cycle, if we increase the costs of the non-ﬁxed arcs in
A′ \ P by this amount. Thus we need d(C) + μ n(C) ≤0 for each cycle C. Here
n(C) is the number of arcs in A′ \ P that are non-ﬁxed, in the cycle C. Then we
have to compute
α = min
C
−d(C)
n(C) .
(30)
Here the minimum is taken over all cycles in G′. As before this can be found
with the algorithm of [11].
Once the value α is obtained in (30), we set μ = min{α, −¯ϵ}. Then we update
the arcs costs as
d(u, v) ←d(u, v) + μ,
for each non-ﬁxed arc (u, v) ∈A′ \ P. If μ < −¯ϵ, let ¯C be a cycle giving the
minimum in (30). We declare ﬁxed all arcs in ¯C ∩(A′ \ P). We also update
¯ϵ ←¯ϵ + μ, k ←k + 1, ϵk = ¯ϵ. Notice that at the ﬁrst iteration we obtain μ = 0,
because at this point ¯ϵ = ϵ1. So this iteration just gives a set of arcs that should
be ﬁxed.
If ¯ϵ < 0 and there is an arc in A′ \ P that is not ﬁxed we solve (26)–(29) and
continue. Otherwise ¯ϵ = 0, or all arcs in A′ \ P are ﬁxed, in this case we should
have ϵ ≥0, this is treated below.
The Case When ϵ ≥0. Here the arcs that have been ﬁxed remain ﬁxed. We
have to impose x(a) ≥ϵ for a ∈P, this corresponds to inequalities (33) for
a ∈P. Thus we have to solve
max μ
(31)
p(v) −p(u) ≥d(u, v)
if (u, v) ∈A′ is ﬁxed,
(32)
p(v) −p(u) ≥d(u, v) + μ
if (u, v) ∈A′ is not ﬁxed,
(33)
μ ≥0.
(34)
Then we proceed as in Subsect. 5.2.

66
M. Ba¨ıou and F. Barahona
7
Complexity
For space reasons we do not discuss the complexity of the algorithms given in
each section. We just mention that the time complexity is dominated by the
computation of ϵ1 in Sect. 6, that requires solving 2 m network ﬂow problems.
Then we have the theorem below.
Theorem 8. The nucleolus of a shortest path game can be computed in
O(n2m4 log n) time.
All the development was done on a directed graph, undirected graphs can be
treated in an analogous way. Similar games deﬁned on the nodes of a graph can
also be treated with this approach.
References
1. Ahuja, R.K., Magnanti, T.L., Orlin, J.B.: Network Flows: Theory, Algorithms, and
Applications. Prentice hall, Upper Saddle River (1993)
2. Aziz, H., Sørensen, T.B.: Path coalitional games, arXiv preprint arXiv:1103.3310
(2011)
3. Chvatal, V.: Linear Programming. Macmillan, London (1983)
4. Deng, X., Fang, Q., Sun, X.: Finding nucleolus of ﬂow game. J. Comb. Optim. 18,
64–86 (2009)
5. Elkind, E., Pasechnik, D.: Computing the nucleolus of weighted voting games. In:
Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algo-
rithms, Society for Industrial and Applied Mathematics, pp. 327–335 (2009)
6. Faigle, U., Kern, W., Kuipers, J.: Note computing the nucleolus of min-cost span-
ning tree games is NP-hard. Int. J. Game Theory 27, 443–450 (1998)
7. Fang, Q., Li, B., Shan, X., Sun, X.: The least-core and nucleolus of path cooperative
games. In: Xu, D., Du, D., Du, D. (eds.) COCOON 2015. LNCS, vol. 9198, pp.
70–82. Springer, Cham (2015). doi:10.1007/978-3-319-21398-9 6
8. Fragnelli, V., Garcia-Jurado, I., Mendez-Naya, L.: On shortest path games. Math.
Methods Oper. Res. 52, 251–264 (2000)
9. Gillies, D.B.: Solutions to general non-zero-sum games. Contrib. Theory Games 4,
47–85 (1959)
10. Goldberg, A.V., Tarjan, R.E.: Finding minimum-cost circulations by canceling
negative cycles. J. ACM (JACM) 36, 873–886 (1989)
11. Hartmann, M., Orlin, J.B.: Finding minimum cost to time ratio cycles with small
integral transit times. Networks 23, 567–574 (1993)
12. Kalai, E., Zemel, E.: Generalized network problems yielding totally balanced
games. Oper. Res. 30, 998–1008 (1982)
13. Kern, W., Paulusma, D.: Matching games: the least core and the nucleolus. Math.
Oper. Res. 28, 294–308 (2003)
14. Kopelowitz, A.: Computation of the kernels of simple games and the nucleolus of
n-person games. Technical report, DTIC Document (1967)
15. Megiddo, N.: Computational complexity of the game theory approach to cost allo-
cation for a tree. Math. Oper. Res. 3, 189–196 (1978)
16. Potters, J., Reijnierse, H., Biswas, A.: The nucleolus of balanced simple ﬂow net-
works. Games Econ. Behav. 54, 205–225 (2006)
17. Schmeidler, D.: The nucleolus of a characteristic function game. SIAM J. Appl.
Math. 17, 1163–1170 (1969)
18. Solymosi, T., Raghavan, T.E.: An algorithm for ﬁnding the nucleolus of assignment
games. Int. J. Game Theory 23, 119–143 (1994)

Earning Limits in Fisher Markets
with Spending-Constraint Utilities
Xiaohui Bei1, Jugal Garg2, Martin Hoefer3(B), and Kurt Mehlhorn4
1 Nanyang Technological University, Singapore, Singapore
xhbei@ntu.edu.sg
2 University of Illinois at Urbana-Champaign, Champaign, USA
jugal@illinois.edu
3 Goethe University Frankfurt, Frankfurt, Germany
mhoefer@cs.uni-frankfurt.de
4 MPI Informatik, Saarbr¨ucken, Germany
mehlhorn@mpi-inf.mpg.de
Abstract. Earning limits are an interesting novel aspect in the classic
Fisher market model. Here sellers have bounds on their income and can
decide to lower the supply they bring to the market if income exceeds
the limit. Beyond several applications, in which earning limits are nat-
ural, equilibria of such markets are a central concept in the allocation of
indivisible items to maximize Nash social welfare.
In this paper, we analyze earning limits in Fisher markets with linear
and spending-constraint utilities. We show a variety of structural and
computational results about market equilibria. The equilibrium price
vectors form a lattice, and the spending of buyers is unique in non-
degenerate markets. We provide a scaling-based algorithm that com-
putes an equilibrium in time O(n3ℓlog(ℓ+ nU)), where n is the number
of agents, ℓ≥n a bound on the segments in the utility functions, and U
the largest integer in the market representation. Moreover, we show how
to reﬁne any equilibrium in polynomial time to one with minimal prices,
or one with maximal prices (if it exists). Finally, we discuss how our
algorithm can be used to obtain in polynomial time a 2-approximation
for Nash social welfare in multi-unit markets with indivisible items that
come in multiple copies.
1
Introduction
Fisher markets are a fundamental model to study competitive allocation of goods
among rational agents. In a Fisher market, there is a set B of buyers and a set
G of divisible goods. Each buyer i ∈B has a budget mi > 0 of money and a
utility function ui that maps any bundle of goods to a non-negative utility value.
Each good j ∈G is assumed to come in unit supply and to be sold by a separate
seller. A competitive or market equilibrium is an allocation vector of goods and a
vector of prices, such that (1) every buyer spends his budget to buy an optimal
bundle of goods, and (2) supply equals demand.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 67–79, 2017.
DOI: 10.1007/978-3-319-66700-3 6

68
X. Bei et al.
Fisher markets have been studied intensively in algorithmic game theory.
For many strictly increasing and concave utility functions, market equilibria
can be described by convex programs [10,15]. There are a variety of algorithms
for computing market equilibria [7,8,12,19]. For linear markets, there are algo-
rithms that run in strongly polynomial time [14,18], and proportional response
dynamics that converge to equilibrium quickly [4,20].
A common assumption in all this work is that utility functions are non-
satiated, that is, the utility of every buyer i strictly increases with amount of
good allocated, and the utility of every seller j strictly increases with the money
earned. Consequently, when buyers and sellers are price-taking agents, it is in
their best interest to spend their entire budget and bring all supply to the market,
resp. In this paper, we study new variants of linear Fisher markets with satiated
utility functions recently proposed in [5]. In these markets, each seller has an
earning limit, which gives him an incentive to possibly reduce the supply that
he brings to the market. This is a natural property in many domains, e.g.,
when sellers have revenue targets. Many properties of such markets are not
well-understood.
Interestingly, equilibria in Fisher markets with earning limits also relate
closely to fair allocations of indivisible items. There has been a surge of inter-
est in allocating indivisible items to maximize Nash social welfare. Very recent
work [1,6] has provided the ﬁrst constant-factor approximation algorithms for
this important problem. The algorithms ﬁrst compute and then cleverly round a
market equilibrium of a Fisher market with earning limits. The tools and tech-
niques for computing market equilibria are a key component in this approach.
In this paper, we consider algorithmic and structural properties of markets
with earning limits and spending-constraint utilities. Spending-constraint utili-
ties are a natural generalization of linear utilities with many additional appli-
cations [8,16]. We show structural properties of equilibria and provide new
and improved polynomial-time algorithms for computation. Moreover, we show
how these algorithms can be used to approximate Nash social welfare in mar-
kets where each item j is provided in dj copies (where dj is a given integer).
We obtain the ﬁrst polynomial-time approximation algorithms for multi-unit
markets.
Contribution and Outline. After formal discussion of the market model, we
discuss some preliminaries in Sect. 2, including a formal condition for existence of
equilibrium. In Sect. 3, we show that the set of equilibrium price vectors forms a
lattice. While there always exists an equilibrium with pointwise smallest prices,
an equilibrium with largest prices might not exist. Moreover, in non-degenerate
markets (for a formal deﬁnition see Sect. 2) the spending of buyers in every
equilibrium is unique.
In Sect. 4 we outline a novel algorithm to compute an equilibrium in time
O(n3ℓlog(ℓ+ nU)), where n is the total number of agents, ℓis the maximum
number of segments in the description of the utility functions that is incident
to any buyer or any good, and U is the largest integer in the representation of

Earning Limits in Fisher Markets with Spending-Constraint Utilities
69
utilities, budgets, and earning limits. For linear markets, the running time sim-
pliﬁes to O(n4 log nU)). Our algorithm uses a scaling technique with decreasing
prices and maintains assignments in which buyers overspend their money. A
technical challenge is to maintain rounded versions of the spending restrictions
in the utility functions. The algorithm runs until the maximum overspending
of all buyers becomes tiny and then rounds the outcome to an exact equilib-
rium. Given an arbitrary equilibrium, we show how to ﬁnd in polynomial time
an equilibrium with smallest prices, or one with largest prices (if it exists).
Finally, in Sect. 5 we round a market equilibrium in linear markets with
earning caps to an allocation in indivisible multi-unit markets to approximate
the Nash social welfare. In these markets, the representation is given by the set
of items and for each item j a number dj of the available copies. The direct
application of existing algorithms [1,6] would require pseudo-polynomial time.
Instead, we show how to adjust the rounding procedure in [6] to run in strongly
polynomial time. The resulting algorithm yields a 2-approximation and runs in
time O(n4 log(nU)), which is polynomial in the input size.
Due to spatial constraints, all missing details and proofs are deferred to the
full version.
Related Work. For Fisher markets we focus on some directly related work
about computation of market equilibria. For markets with linear utilities a num-
ber of polynomial-time algorithms have been derived [7,12,19], including ones
that run in strongly polynomial time [14,18]. For spending-constraint utilities in
exchange markets [8] a polynomial-time algorithm was recently obtained [2]. For
Fisher markets with spending-constraint utilities, the algorithm by V´egh [18]
runs in strongly polynomial time.
Linear markets with either utility or earning limits were studied only
recently [3,5]. The equilibria solve standard convex programs. The Shmyrev pro-
gram for earning limits also applies to spending-constraint utilities. Our paper
complements our previous results [3] on linear markets with utility limits, where
we proved that (1) equilibria form a lattice, (2) an equilibrium with maximum
prices can be computed in time O(n8 log(nU)), (3) it can be reﬁned in poly-
nomial time to an equilibrium with minimum prices, and (4) several related
problem variants are NP- or PPAD-hard. The framework of [17] provides an
(arbitrary) equilibrium in time O(n5 log(nU)). For earning limits, our algorithm
runs in time O(n3ℓlog(ℓ+ nU)) for spending-constraint and O(n4 log(nU)) for
linear utilities. It computes an approximate solution that can be rounded to
an exact equilibrium. An approximate solution could also be obtained with
classic algorithms for separable convex optimization [11,13]. These algorithms
seem slower – the algorithm of [13] obtains the required precision only in time
O(n3ℓ2 log(ℓ) log(ℓ+ nU)).
An interesting open problem are strongly polynomial-time algorithms for
arbitrary earning limits. A non-trivial challenge in adjusting [14] is the preci-
sion of intermediate prices. For the framework of [18] it appears challenging to
generalize the Error-method to markets with earning limits.

70
X. Bei et al.
Approximating optimal allocations of indivisible items that maximize Nash
social welfare has been studied recently for markets with additive [5,6] and sep-
arable concave valuations [1]. Here equilibria of markets with earning limits can
be rounded to yield a 2-approximation. We extend this approach to markets with
multi-unit items, where each item j comes in dj copies (and the input includes
dj in standard logarithmic coding). In contrast to the direct, pseudo-polynomial
extensions of previous work, we show how to obtain a 2-approximation in poly-
nomial time.
2
Preliminaries
In a spending-constraint Fisher market with earning limits, there is a set B
of buyers and a set G of goods. Every buyer i ∈B has a budget mi > 0 of
money. The utility of buyer i is a spending-constraint function given by non-
empty sets of segments Kij = {(i, j, k) | 1 ≤k ≤ℓij} for each good j ∈G.
Each segment (i, j, k) ∈Kij comes with a utility value uijk and a spending limit
cijk > 0. We assume that the utility function is piecewise linear and concave,
i.e., uijk > uij,k+1 > 0 for all ℓij −2 ≥k ≥1. W.l.o.g. we assume that the last
segment has uijℓij = 0 and cijk = ∞.
Buyer i can spend at most an amount of cijk of money on segment (i, j, k).
We use f = (fijk)(i,j,k)∈Kij to denote the spending of money on segments. f
is termed money ﬂow. A segment is closed if fijk ≥cijk, otherwise open. For
notational convenience, we let fij = 
(i,j,k)∈Kij fijk.
Given a vector p = (pj)j∈G of strictly positive prices for goods, a money
ﬂow results in an allocation xij = 
k fijk/pj of good j. The bang-per-buck ratio
of segment (i, j, k) is αijk = uijk/pj. To maximize his utility, buyer i spends
his budget mi on segments in non-increasing order of bang-per-buck ratio, while
respecting the spending limits. A bundle xi = (xij)j∈G that results from this
approach is termed a demand bundle and denoted by x∗
i . The corresponding
money ﬂow on the segments is termed demand ﬂow f ∗
i .
Demand bundles and ﬂows might not be unique, but they diﬀer only on
the allocated segments with smallest bang-per-buck ratio. This smallest ratio
is termed maximum bang-per-back (MBB) ratio and denoted by αi. Note that
αi is unique given p. All segments with αijk ≥αi are termed MBB segments.
The segments with αijk = αi are termed active segments. We assume w.l.o.g.
mi ≤
j,k:uijk>0 cijk, since no buyer would spend more, and we can assume
there is no allocation on segments with uijk = 0. Therefore, we assume buyers
always spend all their money.
In this paper, we study a natural condition on seller supplies. Each good is
owned by a diﬀerent seller, and the seller has a maximum endowment of 1. Seller
j comes with an earning limit dj. He only brings a supply ej ≤1 that suﬃces to
reach this earning limit under the given prices. Intuitively, while each seller has
utility min{dj, ejpj}, we also assume that he has tiny utility for unsold parts of
his good. Hence, he only brings a supply to earn dj.

Earning Limits in Fisher Markets with Spending-Constraint Utilities
71
More formally, the active price of good j is given by pa
j = min(dj, pj). His
good is capped if pa
j = dj and uncapped otherwise. A thrifty supply is ej = pa
j /pj,
which guarantees ejpj ≤dj, i.e., the earning limit holds when market clears.
The goal is to ﬁnd a thrifty equilibrium.
Deﬁnition 1. A pair (f, p) is a thrifty equilibrium if (1) fi is a demand ﬂow
for prices p for every i ∈B, and (2) 
i,k fijk = pa
j , for every j ∈G.
Proposition 1. Across all thrifty equilibria: (1) the seller incomes are unique;
(2) there is a unique set of uncapped goods, and their prices are unique; and (3)
uncapped goods are available in full supply, capped goods in thrifty supply.
These uniqueness properties are a direct consequence of the fact [5] that
thrifty equilibria are the solutions of the following convex program.
Max.

i∈B

j∈G

(i,j,k)∈Kij
fijk log uijk −

j∈G
(qj log qj −qj)
s.t.

j∈G

(i,j,k)∈Kij
fijk = mi
∀i ∈B

i∈B

(i,j,k)∈Kij
fijk = qj
∀j ∈G
fijk ≤cijk ∀(i, j, k) ∈Kij
qj ≤dj
∀j ∈G
fijk ≥0
∀i ∈B, j ∈G, (i, j, k) ∈Kij
(1)
The incomes of sellers and, consequently, the sets of capped and uncapped
goods are unique in all thrifty equilibria. The money ﬂow, allocation, and prices
of capped goods might not be unique.
Buyers always spend all their budget, but this can be impossible when every
seller must not earn more than its limit1. Then a thrifty equilibrium does not
exist. This, however, turns out to be the only obstruction to nonexistence.
Let ˆB ⊆B be a set of buyers, and N( ˆB) = {j ∈G | uij1 > 0, i ∈ˆB} be
the set of goods such that there is at least one buyer in ˆB with positive utility
on its ﬁrst segment for the good. The following money clearing condition states
that buyers can spend their money without violating the earning limits.
Deﬁnition 2 (Money Clearing). A market is money clearing if for every
subset of buyers ˆB ⊆B there is a ﬂow f such that
fij ≤
k+

k=1
cijk, ∀i ∈ˆB, ∀j ∈N( ˆB), k+ = max{k | uijk > 0}

i∈ˆ
B
fij ≤dj,
∀j ∈N( ˆB)
and

j∈N( ˆ
B)
fij ≥mi,
∀i ∈ˆB .
(MC)
1 Consider the example of a linear market with one buyer and one good. The utility
is u11 > 0, the buyer has a budget m1 = 2, the good has an earning limit d1 = 1.

72
X. Bei et al.
Money clearing is clearly necessary for the existence of a thrifty equilibrium. It
is also suﬃcient since, e.g., our algorithm in Sect. 4 will successfully compute an
equilibrium iﬀmoney clearing holds. Alternatively, it can be veriﬁed that this is
the unique necessary and suﬃcient feasibility condition for convex program (1).
It is easy to check condition (MC) by a max-ﬂow computation. We therefore
assume that our market instance satisﬁes it.
Lemma 1. A thrifty equilibrium exists iﬀthe market is money clearing.
Let us deﬁne some more useful concepts for the analysis. For any pair (f, p)
the surplus of buyer i is given by s(i) = 
j∈G fij −mi, and the surplus of good
j is s(j) = pa
j −
i∈B fij. The active-segment graph G(p) is a bipartite graph
(B ∪G, E) which contains edge {i, j} iﬀthere is some active segment (i, j, k).
Note that there can be at most one active segment (i, j, k) for an (i, j). A market
is called non-degenerate if the active segment graph for any non-zero p is a forest.
3
Structure of Thrifty Equilibria
Some Intuition. We start by providing some intuition for the structural results
in the case where all utility functions are linear, i.e., with a single segment in
every Kij. Consider a thrifty equilibrium (f, p). Call an edge (i, j) p-MBB if
uij/pj = αi. The active-segment graph here simpliﬁes to an MBB graph G(p).
Let C be any connected component of the MBB graph. The buyers in C
spend all budget on the goods in C, and no other buyer spends money on the
goods in C. Thus

i∈C∩B
mi =

j∈C∩G
pa
j =

j∈C∩Gu
pj +

j∈C∩Gc
dj,
where Gc and Gu are the sets of capped and uncapped goods, resp. First, assume
all goods in C are capped. Let r be a positive real and consider the pair (f, p′),
where p′
j = r · pj if j ∈C ∩Gc and p′
j = pj otherwise.
Note that the allocations for any good j ∈C ∩Gc are scaled by 1/r. The
pair (f, p′) is an equilibrium provided that all edges with positive allocation are
also p′-MBB and p′
j ≥dj for all j ∈C ∩Gc. This certainly holds for r > 1
and r −1 suﬃciently small. If pj > dj for all j ∈C this also holds for r < 1
and 1 −r suﬃciently small. Thus, there is some freedom in choosing the prices
in components containing only capped goods even for a ﬁxed MBB graph. For
non-degenerate instances, the money ﬂow is unique (but not the allocation).
Now assume that there is at least one uncapped good in C, and let ju be such
an uncapped good. The price of any other good j in the component is linearly
related to the price ju, i.e., pj = γjpju, where γj is a rational number whose
numerator and denominator is a product of utilities. Thus,

i∈C∩B
mi =

j∈C∩G
pa
j =

j∈C∩Gu
γjpju +

j∈C∩Gc
dj,

Earning Limits in Fisher Markets with Spending-Constraint Utilities
73
and the reference price is uniquely determined. All prices in the component
are uniquely determined. For a non-degenerate instance the money ﬂow and
allocation are also uniquely determined.
Suppose in a component C containing only capped goods we increase the
prices by a common factor r > 1. We raise r continuously until a new MBB edge
arises. If we can raise r indeﬁnitely, no buyer in the component is interested in
any good outside the component. Otherwise, a new MBB edge arises, and then C
is united with some other component. At this moment, the money ﬂow over the
new MBB edge is zero. If the newly formed component contains an uncapped
good, prices in the component are ﬁxed and money ﬂow is exactly as in the
moment of joining the components. Otherwise, we raise all prices in the newly
formed component, and so on. If the market is non-degenerate, then money ﬂow
is unique, and money will never ﬂow on the new MBB edge.
If the component contains only capped goods j with pj > dj, we can decrease
prices continuously by a common factor r < 1 until a new MBB edge arises. If
no MBB edge ever arises, no buyer outside the component is interested in any
good in the component, which allows to argue as above.
We have so far described how the prices in a component of the MBB graph
of an equilibrium are determined if at least one good is uncapped, and how the
prices can be scaled by a common factor if all goods are capped. We have also
discussed how components are merged and that the new MBB edge arising in a
merge will never carry nonzero ﬂow. Components can also be split if they contain
an edge with zero ﬂow.
Consider an equilibrium (f, p) and assume fij = 0 for some edge (i, j) of
the MBB graph w.r.t. p. Let C be the component containing (i, j) and let C1
and C2 be the components of C \ {i, j}. Let the instance be non-degenerate.
Hence, the MBB graph is a forest. If we want to retain all MBB edges within
C1 and C2 and only drop (i, j), we have to either increase all prices in the
subcomponent containing j or decrease all prices in the subcomponent containing
i. Both options are infeasible if both components contain a good with price
strictly below its earning limit. The ﬁrst option is feasible if the component
containing j contains only goods with prices at least their earning limits. The
latter option is feasible if the component containing i contains only goods with
prices strictly larger than their earning limits. The split does not aﬀect the money
ﬂow.
If the above described changes allow to change any equilibrium into any other
equilibrium, then money ﬂow should be unique across all equilibria. Moreover,
the set of edges carrying ﬂow should be the same in all equilibria. The MBB
graph for an equilibrium contains these edges, and maybe some more edges that
do not carry ﬂow. Next, we prove that this intuition captures the truth, even for
the general case of spending-constraint utility functions.
Lattice Structure. We characterize the set of price vectors of thrifty equilibria,
which we denote by P = {p | ∃f s.t. (f, p) is a thrifty equilibrium}. For money
clearing markets, we establish two results: (1) the set of equilibrium price vectors

74
X. Bei et al.
forms a lattice, and (2) the money ﬂow is unique in nondegenerate markets. For
the ﬁrst result, we consider the coordinate-wise comparison, i.e., p ≥p′ iﬀ
pj ≥p′
j, ∀j ∈G.
Theorem 1. The pair (P, ≥) is a lattice.
The proof relies on the following structural properties. Given p and p′, we parti-
tion the set of goods into sets Sr = {j | p′
j = r · pj}, for r > 0. For a price vector
p, let segment (i, j, k) be p-MBB if uijk/pj ≥αi, and p-active if uijk/pj = αi.
For a set T of goods and an equilibrium (f, p), let
K(T, p) = {(i, j, k) | segment is p-MBB for some j ∈T},
Ka(T, p) = {(i, j, k) | fijk > 0 for some j ∈T and some equilibrium (f, p)},
where the sets denote the set of p-MBB segments for goods in T and the ones
on which some good in T is allocated. Note that Ka(T, p) ⊆K(T, p).
Lemma 2. For any two thrifty equilibria E = (f, p) and E′ = (f ′, p′):
1. Ka(Sr, p) = Ka(Sr, p′) for every r > 0, i.e., the goods in Sr are allocated on
the same set of segments in both equilibria.
2. Ka(Sr, p) = Ka(Sr, p′) ⊆K(Sr, p′) ⊆K(Sr, p) for r > 1. Similarly,
Ka(Sr, p′) = Ka(Sr, p) ⊆K(Sr, p) ⊆K(Sr, p′) for r < 1. For r = 1,
Ka(Sr, p′) = Ka(Sr, p).
3. If fijk > 0 for (i, j, k) ∈Ka(Sr, p) with r > 1, then (i, j, k) is p′-MBB. If
f ′
ijk > 0 for (i, j, k) ∈Ka(Sr, p′) with r < 1, then (i, j, k) is p-MBB.
Corollary 1. There exists a thrifty equilibrium with coordinate-wise lowest
prices. Among all thrifty equilibria, it yields the largest supply in the market
and the maximum utility for every buyer.
Theorem 2. In a non-degenerate market, all thrifty equilibria have the same
money ﬂow.
The convex program implies that there is a unique income for each seller.
This is consistent with our observation that a good can have diﬀerent prices in
two equilibria only when income equals its earning limit.
While existence of an equilibrium with smallest prices is guaranteed, we might
or might not have an equilibrium with coordinate-wise largest prices (e.g., when
all goods are capped in equilibrium, prices can be raised indeﬁnitely).
4
Algorithms to Compute Thrifty Equilibria
Scaling Algorithm. We ﬁrst propose and discuss a polynomial-time scaling
algorithm to compute a thrifty equilibrium. We begin with deﬁning some useful
tools and concepts. The active-segment network N(p) = ({s, t} ∪B ∪G, E)
contains a node for each buyer and each good, along with two additional nodes
s and t. It contains every edge (s, i) for i ∈B with capacity mi −cc
i, where cc
i =

Earning Limits in Fisher Markets with Spending-Constraint Utilities
75

(i,j,k) closed cijk. Also, it contains every (j, t) for j ∈G with capacity pa
j −cc
j,
where cc
j = 
(i,j,k) closed cijk. It contains edge (i, j) with inﬁnite capacity iﬀ
there is some active segment (i, j, k). Finally, the active-residual network Gr(f, p)
contains a node for each buyer and each good. It contains forward edge (i, j) iﬀ
there is some active segment (i, j, k) with fijk < cijk and contains backward edge
(j, i) iﬀthere is some active segment (i, j, k) with fijk > 0. Moreover, Gr(f, p, i)
is the subgraph of Gr(f, p) induced by the set of all buyers i′ ∈Gr(f, p) such
that there is an augmenting path from i′ to i.
Our algorithm uses Δ-discrete capacities ˆcijk = ⌈cijk/Δ⌉·Δ for all i ∈B, j ∈
G and (i, j, k) ∈Kij, where we iteratively decrease Δ. Initially, the algorithm
overestimates the budget of buyer i, where it assumes the buyer has rΔ money
and every segment has Δ-discrete capacities. Then fi is a (Δ, r)-discrete demand
for buyer i iﬀit is a demand ﬂow for buyer i under these conditions.
We also adjust the deﬁnitions of MBB ratio, active segments, active-segment
graph, network, and residual network to the case of Δ-discrete capacities. We
denote these adjusted versions by ˆα, ˆG(p), ˆN(p), ˆGr(f, p) and ˆGr(f, p, j) resp.
Finally, we make a number of assumptions to simplify the stated bound on
the running time. We assume w.l.o.g. that |B| = |G| (by adding dummy buyers
and/or goods) and deﬁne n = |B| + |G|. Moreover, we let Ki = 
j∈G Kij and
Kj = 
i∈B Kij and assume w.l.o.g. that ℓ= |Ki| = |Kj| ≥n for every buyer i
and every good j (by adding dummy segments with 0 utility).
Algorithm 1 computes a thrifty equilibrium in polynomial time. It uses
descending prices and maintains a money ﬂow on closed and open MBB seg-
ments with increasing precision and decreasing surplus. We call a run of the
outer while-loop a Δ-phase. The algorithm runs until the precision parameter
Δ is decreased to exponentially small size. A ﬁnal rounding procedure (similar
to [9] and deferred to the full version) then rounds the solution to an exact
equilibrium.
For the analysis, we use the following notion of Δ-feasible solution.
Deﬁnition 3. Given a value Δ > 0, a pair (f, p) of ﬂow and prices with p ≥0
and f ≥0 is a Δ-feasible solution if
– ℓΔ ≤s(i) ≤(ℓ+ 1)Δ, ∀i ∈B.
– ∀j ∈G: If pj < p0
j, then 0 ≤s(j) ≤Δ. If pj = p0
j, then −∞< s(j) ≤Δ.
– f is Δ-integral, and fijk > 0 only if (i, j, k) is a closed or open MBB segment
w.r.t. Δ-discretized capacities.
For the running time, note that prices are non-increasing. Once a capped good
becomes uncapped, it remains uncapped. We refer to an execution of the repeat
loop in Algorithm 1 as an iteration. After the initialization, there may be goods
j for which dj is smaller than the initial value of Δ and which receive ﬂow from
some buyer. As long as their surplus is negative, these goods keep their initial
price. The following observations are useful to prove a bound on the running
time. We also observe that the precision of prices and ﬂow values is always
bounded.

76
X. Bei et al.
Algorithm 1. Scaling Algorithm for Markets Ms with Earning Limits
Input
: Fisher market M with spending constraint utilities and earning limits
Budget mi, earning limits dj, and parameters uijk, cijk
Output: Thrifty equilibrium (f, p)
1 Δ ←U n+1 
i∈B mi; p0
j ←n(ℓ+ 1)Δ, ∀j ∈G; p ←p0
2 fi ←(Δ, ℓ+ 1)-discrete demand for buyer i
3 while Δ > 1/(2ℓ(2nU)4n) do
4
Δ ←Δ/2;
5
for each closed segment (i, j, k) do fijk ←⌈cijk/Δ⌉· Δ
6
for each i ∈B with s(i) > (ℓ+ 1)Δ do
7
Pick any active segment (i, j, k) with fijk > 0 and set fijk ←fijk −Δ
8
while there is a good j′ with s(j′) > Δ do
// Δ-phase
9
repeat
// iteration
10
( ˆB, ˆG) ←Set of (buyers, goods) in ˆGr(f, p, j′)
11
x ←1; Deﬁne pj ←xpj, ∀j ∈ˆG
// active prices & surpluses
12
change, too
13
Decrease x continuously down from 1 until one of the following
14
events occurs
15
Event 1: s(j′) = Δ
16
Event 2: s(j) ≤0 for a j ∈ˆG
17
P ←path from j to j′ in ˆGr(f, p, j′)
// Δ-augmentation
18
Update f : fijk =
⎧
⎨
⎩
fijk + Δ if (i, j) is a forward arc in P
fijk −Δ if (i, j) is a backward arc in P
fijk
otherwise
19
Event 3: A capped good becomes uncapped
20
Event 4: New active segment (i, j, k) with i ̸∈ˆB, j ∈ˆG, fijk < ˆcijk
21
until Event 1 or 2 occurs
22 (f, p) ←Rounding(f, p)
Lemma 3. Once the surplus of a good is non-negative, it stays non-negative. If
the surplus of a good is negative, its price is the initial price.
Lemma 4. The ﬁrst run of the outer while-loop in Algorithm 1 takes O(n3ℓ)
time, every subsequent one takes O(n2ℓ) time. At the end of each Δ-phase, the
pair (f, p) is a Δ-feasible solution.
Lemma 5. If all budgets, earning limits and utility values are integers bounded
by U, then all ﬂow values and prices at the end of each iteration are rational
numbers whose denominators are at most poly(1/Δ, n, U n).
Finally, for correctness of the algorithm, it maintains the following condition
resulting from (MC) for active prices.
Lemma 6. Let ˆB ⊆B be a set of buyers and let N( ˆB) be the goods having
positive utility for some buyer in ˆB. At all times 
j∈N( ˆ
B) pa
j −
i∈ˆ
B mi ≥0.

Earning Limits in Fisher Markets with Spending-Constraint Utilities
77
Algorithm 2. MinPrices
Input
: Market parameters and any thrifty equilibrium (f, p)
Output: Thrifty equilibrium with smallest prices
1 E(f) ←{(i, j, k) | fijk > 0}; Gc ←Set of capped goods at (f, p)
2 Solve an LP in qj and λi:
min 
i λi
qj ≤uijkλi, for segment (i, j, k) ∈E(f)
qj = pj,
∀j ∈G \ Gc
qj ≥dj,
∀j ∈Gc
λi, qj ≥0
∀i ∈B, j ∈G
return (f, q)
Algorithm 3. MaxPrices
Input
: Market parameters and any thrifty equilibrium (f, p)
Output: Thrifty equilibrium with largest prices
1 Initialize active price pa
j ←min{dj, pj} for every good j
2 S ←{j | pj > 0 and j is not connected to any uncapped good in G(p)}
3 while S ̸= ∅do
4
x ←1; Set prices pj ←xpj, ∀j ∈S
5
Increase x continuously from 1 until a new active segment appears
6
Recompute S
7 return (f, p)
Lemma 7. Let (f, p) be the ﬂow and price vector computed by the outer while-
loop in Algorithm 1. The pair is Δ-feasible for Δ = 1/(2ℓ(2nU)4n) and −n(ℓ+1)
Δ ≤s(j) ≤Δ for all j ∈G.
Theorem 3. Algorithm 1 computes a thrifty equilibrium for money-clearing
markets Ms with earning limits in O(n3ℓlog (ℓ+ nU)) time.
Extremal Prices. Given an arbitrary thrifty equilibrium, Algorithm 2 com-
putes a thrifty equilibrium with smallest prices. Algorithm 3 computes a thrifty
equilibrium with largest prices if it exists. Otherwise, it yields a set S of goods
for which prices can be raised indeﬁnitely.
Theorem 4. Algorithm 2 computes a thrifty equilibrium with smallest prices.
Theorem 5. Algorithm 3 computes a thrifty equilibrium with largest prices if it
exists.
5
Nash Social Welfare in Additive Multi-unit Markets
Using our algorithm to compute a thrifty equilibrium in linear markets with
earning limits, we can approximate the optimal Nash social welfare for additive
valuations, indivisible items, and multiple copies for each item. Here there are n

78
X. Bei et al.
agents and m items. For item j, there are dj ∈N copies. The valuation of agent i
for an assignment x of goods is vi(x) = 
j vijxij, where xij denotes the number
of copies of item j that agent i receives. The goal is to ﬁnd an assignment such
that the Nash social welfare (
i vi(x))1/n is maximized.
When all dj = 1, the algorithm of [6] provides a 2-approximation [5]. It ﬁnds
an equilibrium for a linear market, where each agent i is a buyer with mi = 1,
and each item j is a good with earning limit dj = 1. Then it rounds the alloca-
tion to an integral assignment. The direct adjustment to handle dj ≥1 copies is
to represent each copy of item j by a separate auxiliary item with unit supply
(all valued exactly the same way as item j) and run the algorithm from [6]. A
similar approach is used by [1] to provide a 2-approximation for separable con-
cave utilities. This, however, yields a running time polynomial in maxj dj, which
is only pseudo-polynomial for multi-unit markets (due to standard logarithmic
coding of dj’s). We make the algorithm eﬃcient.
Proposition 2. There is a polynomial-time 2-approximation algorithm for max-
imizing Nash social welfare in multi-unit markets with additive valuations.
References
1. Anari, N., Mai, T., Gharan, S.O., Vazirani, V.: Nash social welfare for indi-
visible items under separable, piecewise-linear concave utilities (2016). CoRR
abs/1612.05191
2. Bei, X., Garg, J., Hoefer, M.: Ascending-price algorithms for unknown markets. In:
Proceedings of 17th Conference Economics and Computation (EC), p. 699 (2016)
3. Bei, X., Garg, J., Hoefer, M., Mehlhorn, K.: Computing equilibria in markets with
budget-additive utilities. In: Proceedings of 24th European Symposium Algorithms
(ESA), pp. 8:1–8:14 (2016)
4. Birnbaum, B., Devanur, N., Xiao, L.: Distributed algorithms via gradient descent
for Fisher markets. In: Proceedings of 12th Conference Electronic Commerce (EC),
pp. 127–136 (2011)
5. Cole, R., Devanur, N., Gkatzelis, V., Jain, K., Mai, T., Vazirani, V., Yazdanbod, S.:
Convex program duality, Fisher markets, and Nash social welfare. In: Proceedings
of 18th Conference Economics and Computation (EC) (2017, to appear)
6. Cole, R., Gkatzelis, V.: Approximating the Nash social welfare with indivisible
items. In: Proceedings of 47th Symposium Theory of Computing (STOC), pp.
371–380 (2015)
7. Devanur, N., Papadimitriou, C., Saberi, A., Vazirani, V.: Market equilibrium via
a primal-dual algorithm for a convex program. J. ACM 55(5), 22:1–22:18 (2008)
8. Devanur, N., Vazirani, V.: The spending constraint model for market equilibrium:
algorithmic, existence and uniqueness results. In: Proceedings of 36th Symposium
Theory of Computing (STOC), pp. 519–528 (2004)
9. Duan, R., Mehlhorn, K.: A combinatorial polynomial algorithm for the linear
Arrow-Debreu market. Inf. Comput. 243, 112–132 (2015)
10. Eisenberg, E., Gale, D.: Consensus of subjective probabilities: the Pari-Mutuel
method. Ann. Math. Stat. 30(1), 165–168 (1959)
11. Hochbaum, D., Shanthikumar, G.: Convex separable optimization is not much
harder than linear optimization. J. ACM 37(4), 843–862 (1990)

Earning Limits in Fisher Markets with Spending-Constraint Utilities
79
12. Jain, K.: A polynomial time algorithm for computing the Arrow-Debreu market
equilibrium for linear utilities. SIAM J. Comput. 37(1), 306–318 (2007)
13. Karzanov, A., McCormick, T.: Polynomial methods for separable convex optimiza-
tion in unimodular linear spaces with applications. SIAM J. Comput. 26(4), 1245–
1275 (1997)
14. Orlin, J.: Improved algorithms for computing Fisher’s market clearing prices.
In: Proceedings of 42nd Symposium Theory of Computing (STOC), pp. 291–300
(2010)
15. Shmyrev, V.: An algorithm for ﬁnding equilibrium in the linear exchange model
with ﬁxed budgets. J. Appl. Indust. Math. 3(4), 505–518 (2009)
16. Vazirani, V.: Spending constraint utilities with applications to the adwords market.
Math. Oper. Res. 35(2), 458–478 (2010)
17. V´egh, L.: Concave generalized ﬂows with applications to market equilibria. Math.
Oper. Res. 39(2), 573–596 (2014)
18. V´egh, L.: Strongly polynomial algorithm for a class of minimum-cost ﬂow problems
with separable convex objectives. SIAM J. Comput. 45(5), 1729–1761 (2016)
19. Ye, Y.: A path to the Arrow-Debreu competitive market equilibrium. Math. Prog.
111(1–2), 315–348 (2008)
20. Zhang, L.: Proportional response dynamics in the Fisher market. Theoret. Comput.
Sci. 412(24), 2691–2698 (2011)

Robustness Among Multiwinner Voting Rules
Robert Bredereck1, Piotr Faliszewski2, Andrzej Kaczmarczyk3(B),
Rolf Niedermeier3, Piotr Skowron3, and Nimrod Talmon4
1 University of Oxford, Oxford, UK
2 AGH University, Krakow, Poland
3 TU Berlin, Berlin, Germany
a.kaczmarczyk@tu-berlin.de
4 Weizmann Institute of Science, Rehovot, Israel
Abstract. We investigate how robust are results of committee elections
to small changes in the input preference orders, depending on the voting
rules used. We ﬁnd that for typical rules the eﬀect of making a single
swap of adjacent candidates in a single preference order is either that
(1) at most one committee member can be replaced, or (2) it is possible
that the whole committee can be replaced. We also show that the prob-
lem of computing the smallest number of swaps that lead to changing
the election outcome is typically NP-hard, but there are natural FPT
algorithms. Finally, for a number of rules we assess experimentally the
average number of random swaps necessary to change the election result.
1
Introduction
We study how multiwinner voting rules (i.e., procedures used to select ﬁxed-size
committees of candidates) react to (small) changes in the input votes. We are
interested both in the complexity of computing the smallest modiﬁcation of the
votes that aﬀects the election outcome, and in the extent of the possible changes.
We start by discussing our ideas informally in the following example.
Consider a research-funding agency that needs to choose which of the sub-
mitted project proposals to support. The agency asks a group of experts to
evaluate the proposals and to rank them from the best to the worst one. Then,
the agency uses some formal process—here modeled as a multiwinner voting
rule—to aggregate these rankings and to select k projects to be funded. Let us
imagine that one of the experts realized that instead of ranking some proposal
A as better than B, he or she should have given the opposite opinion. What
are the consequences of such a “mistake” of the expert? It may not aﬀect the
results at all, or it may cause only a minor change: Perhaps proposal A would
be dropped (to the beneﬁt of B or some other proposal) or B would be selected
(at the expense of A or some other proposal). We show that while this indeed
would be the case under a number of multiwinner voting rules (e.g., under the
k-Borda rule; see Sect. 2 for deﬁnitions), there exist other rules (e.g., STV or the
Chamberlin–Courant rule) for which such a single swap could lead to selecting a
completely disjoint set of proposals. The agency would prefer to avoid situations
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 80–92, 2017.
DOI: 10.1007/978-3-319-66700-3 7

Robustness Among Multiwinner Voting Rules
81
where small changes in the experts’ opinions lead to (possibly large) changes
in the outcomes; so the agency would want to be able to compute the smallest
number of swaps that would change the result. In cases where this number is too
small, the agency might invite more experts to gain conﬁdence in the results.
More formally, a multiwinner voting rule is a function that, given a set of
rankings of the candidates and an integer k, outputs a family of size-k subsets of
the candidates (the winning committees). We consider the following three issues
(for simplicity, below we assume to always have a unique winning committee):
1. We say that a multiwinner rule R is ℓ-robust if (1) swapping two adjacent
candidates in a single vote can lead to replacing no more than ℓcandidates in
the winning committee, and (2) there are examples where exactly ℓcandidates
are indeed replaced; we refer to ℓas the robustness level of R.1 Notably, the
robustness level is between 1 and k, with 1-robust being the strongest form
of robustness one could ask for. We ask for the robustness levels of several
multiwinner rules.
2. We say that the robustness radius of an election E (for committee size k)
under a multiwinner rule R is the smallest number of swaps (of adjacent
candidates) which are necessary to change the election outcome. We ask
for the complexity of computing the robustness radius (referred to as the
Robustness Radius problem) under a number of multiwinner rules (this
problem is strongly related to the Margin of Victory [4,7,20,26] and
Destructive Swap Bribery problems [13,25]; in particular, it follows up
on the study of robustness of single-winner rules of Shiryaev et al. [25])
3. We ask how many random swaps of adjacent candidates are necessary, on
average, to move from a randomly generated election to one with a diﬀerent
outcome. Doing experiments, we assess the practical robustness of our rules.
There is quite a number of multiwinner rules. We consider only several of
them, selected to represent a varied set of ideas from the literature (ranging
from variants of scoring rules, through rules inspired by the Condorcet criterion,
to the elimination-based STV rule). We ﬁnd that all these rules are either 1-
robust (a single swap can replace at most one committee member) or are k-
robust (a single swap can replace the whole committee of size k).2 Somewhat
surprisingly, this phenomenon is deeply connected to the complexity of winner
determination. Speciﬁcally, we show (under mild assumptions) that if a rule has
a constant robustness level, then it has a polynomial-time computable reﬁnement
(that is, it is possible to compute one of its outcomes in polynomial time). Since
for many rules the problem of computing such a reﬁnement is NP-hard, we get
a quick way of ﬁnding out that such rules have non-constant robustness levels.
The Robustness Radius problem tends to be NP-hard (sometimes even for
a single swap) and, thus, we seek ﬁxed-parameter tractability (FPT) results. For
example, we ﬁnd several FPT algorithms parametrized by the number of voters
1 Indeed, the formal deﬁnition is more complex due to taking care of ties.
2 We also construct somewhat artiﬁcial rules with robustness levels between 1 and k.

82
R. Bredereck et al.
(useful, e.g., for scenarios with few experts, such as our introductory example).
See Table 1 for an overview on our theoretical results.
We complement our work with an experimental evaluation of how robust are
our rules with respect to random swaps. On the average, to change the outcome
of an election, one needs to make the most swaps under the k-Borda rule. All
the omitted proofs are present in the long version of our paper [5].
Table 1. Summary of our results. Together with each rule, we provide the complexity of
its winner determination. The parameters m, n, and B mean, respectively, the number
of candidates, voters, and the robustness radius; NP-hard(B) means NP-hard even for
constant B. (♣) For STV there is a polynomial-time algorithm for computing a single
winning committee but deciding if a given committee wins is NP-hard [10].
Voting rule
Robustness level Complexity of Robustness Radius
SNTV, Bloc, k-Borda (P)
1
P
k-Copeland (P)
1
NP-hard, FPT(m)
NED (NP-hard [1])
k
NP-hard, FPT(m)
STV (P) (♣)
k
NP-hard(B), FPT(m), FPT(n)
β-CC (NP-hard [3,19,23]) k
NP-hard(B), FPT(m), FPT(n)
2
Preliminaries
Elections.
An election E = (C, V ) consists of a set of candidates C =
{c1, . . . , cm} and of a collection of voters V = (v1, . . . , vn). We consider the
ordinal election model, where each voter v is associated with a preference order
≻v, that is, with a ranking of the candidates from the most to the least desirable
one (according to this voter). A multiwinner voting rule R is a function that,
given an election E = (C, V ) and a committee size k, outputs a set R(E, k)
of size-k subsets of C, referred to as the winning committees (each of these
committees ties for victory).
(Committee) Scoring Rules. Given a voter v and a candidate c, by posv(c)
we denote the position of c in v’s preference order (the top-ranked candidate
has position 1 and the following candidate has position 2, and so on). A scor-
ing function for m candidates is a function γm : [m] →R that associates each
candidate-position with a score. Examples of scoring functions include (1) the
Borda scoring functions, βm(i) = m−i; and (2) the t-Approval scoring functions,
αt(i) deﬁned so that αt(i) = 1 if i ≤t and αt(i) = 0 otherwise (α1 is typically
referred to as the Plurality scoring function). For a scoring function γm, the
γm-score of a candidate c in an m-candidate election E = (C, V ) is deﬁned as
γm-scoreE(c) = 
v∈V γm(posv(c)).
For a given election E and a committee size k, the SNTV score of a size-k
committee S is deﬁned as the sum of the Plurality scores of its members. SNTV

Robustness Among Multiwinner Voting Rules
83
outputs the committee(s) with the highest score (i.e., the rule outputs the com-
mittees that consist of k candidates with the highest plurality scores; there may
be more than one such committee due to ties). Bloc and k-Borda rules are
deﬁned analogously, but using k-Approval and Borda scoring functions, respec-
tively. The Chamberlin–Courant rule [8] (abbreviated as β-CC) also outputs the
committees with the highest score, but computes these scores in a diﬀerent way:
The score of committee S in a vote v is the Borda score of the highest-ranked
member of S (the score of a committee is the sum of the scores from all voters).
SNTV, Bloc, k-Borda, and β-CC are examples of committee scoring rules [12,
14]. However, while the ﬁrst three rules are polynomial-time computable, winner
determination for β-CC is well-known to be NP-hard [3,19,23].
Condorcet-Inspired Rules. A candidate c is a Condorcet winner (resp. a
weak Condorcet winner) if for each candidate d, more than (at least) half of the
voters prefer c to d. In the multiwinner case, a committee is Gehrlein strongly-
stable (resp. weakly-stable) if every committee member is preferred to every non-
member by more than (at least) half of the voters [15], and a multiwinner rule is
Gehrlein strongly-stable (resp. weakly-stable) if it outputs exactly the Gehrlein
strongly-stable (weakly-stable) committees whenever they exist. For example, let
the NED score of a committee S be the number of pairs (c, d) such that (i) c is a
candidate in S, (ii) d is a candidate outside of S, and (iii) at least half of the voters
prefer c to d. Then, the NED rule [9], deﬁned to output the committees with
the highest NED score, is Gehrlein weakly-stable. In contrast, the k-Copeland0
rule is Gehrlein strongly-stable but not weakly-stable (the Copelandα score of
a candidate c, where α ∈[0, 1], is the number of candidates d such that a
majority of the voters prefer c to d, plus α times the number of candidates e such
that exactly half of the voters prefer c to e; winning k-Copelandα committees
consist of k candidates with the highest scores). Detailed studies of Gehrlein
stability mostly focused on the weak variant of the notion [2,17]. Very recent
ﬁndings, as well as results from this paper, suggest that the strong variant is more
appealing [1,24]; for example, all Gehrlein weakly-stable rules are NP-hard to
compute [1], whereas there are strongly-stable rules (such as k-Copeland0) that
are polynomial-time computable.
STV. For an election with m candidates, the STV rule executes up to m rounds
as follows. In a single round, it checks whether there is a candidate c who is
ranked ﬁrst by at least q = ⌊
n
k+1⌋+ 1 voters and, if so, then it (i) includes c
into the winning committee, (ii) removes exactly q voters that rank c ﬁrst from
the election, and (iii) removes c from the remaining preference orders. If such a
candidate does not exist, then a candidate d that is ranked ﬁrst by the fewest
voters is removed. Note that this description does not specify which q voters to
remove or which candidate to remove if there is more than one that is ranked
ﬁrst by the fewest voters. We adopt the parallel-universes tie-breaking model
and we say that a committee wins under STV if there is any way of breaking
such internal ties that leads to him or her being elected [10].

84
R. Bredereck et al.
We can compute some STV winning committee by breaking the internal ties
in some arbitrary way, but it is NP-hard to decide if a given committee wins [10].
Parametrized Complexity. We assume familiarity with basic notions of para-
metrized complexity, such as parametrized problems, FPT-algorithms, and W[1]-
hardness. For details, we refer to the textbook of Cygan et al. [11].
3
Robustness Levels of Multiwinner Rules
In this section we identify the robustness levels of our multiwinner rules. We
start by deﬁning this notion formally; note that the deﬁnition below has to take
into account that a voting rule can output several tied committees.
Deﬁnition 1. The robustness level of a multiwinner rule R for elections with
m candidates and committee size k is the smallest value ℓsuch that for each
election E = (C, V ) with |C| = m, each election E′ obtained from E by making
a single swap of adjacent candidates in a single vote, and each committee W ∈
R(E, k), there exists a committee W ′ ∈R(E′, k) such that |W ∩W ′| ≥k −ℓ.
All rules that we consider belong to one of two extremes: Either they are
1-robust (i.e., they are very robust) or they are k-robust (i.e., they are possibly
very non-robust). We start with a large class of rules that are 1-robust.
Proposition 1. Let R be a voting rule that assigns points to candidates and
selects those with the highest scores. If a single swap in an election aﬀects the
scores of at most two candidates (decreases the score of one and increases the
score of the other), then the robustness level of R is equal to one.
The proof uses the observation that, after a single swap, either the candidate
whose score increases can push out a single (lowest-scoring) member of the win-
ning committee W, or a member of W who loses score can be replaced by the
highest-scoring candidate outside W. This suﬃces to deal with four of our rules.
Corollary 1. SNTV, Bloc, k-Borda, and k-Copelandα (for each α) are 1-robust.
In contrast, Gehrlein weakly-stable rules are k-robust.
Proposition 2. The robustness level of each Gehrlein weakly-stable rule is k.
Proof. Consider the following election, described through its majority graph (in
a majority graph, each candidate is a vertex and there is a directed arc from
candidate u to candidate v if more than half of the voters prefer u to v; the
classic McGarvey’s theorem says that each majority graph can be implemented
with polynomially many votes [22]). We form an election with candidate set
C = A ∪B ∪{c}, where A = {a1, . . . , ak} and B = {b1, . . . , bk}, and with the
following majority graph: The candidates in A form one cycle, the candidates
in B form another cycle, and there are no other arcs (i.e., for all other pairs

Robustness Among Multiwinner Voting Rules
85
of candidates (x, y) the same number of voters prefers x to y as the other way
round). We further assume that there is a vote, call it v, where c is ranked
directly below a1 (McGarvey’s theorem easily accommodates this need).
In the constructed election, there are two Gehrlein weakly-stable committees,
A and B. To see this, note that if a Gehrlein weakly-stable contains some ai
then it must also contain all other members of A (otherwise there would be a
candidate outside of the committee that is preferred by a majority of the voters
to a committee member). An analogous argument holds for B.
If we push c ahead of a1 in vote v, then a majority of the voters prefers c
to a1. Thus, A is no longer Gehrlein weakly-stable and B becomes the unique
winning committee. Since (1) A and B are disjoint, (2) A is among the winning
committees prior to the swap, and (3) B is the unique winning committee after
the swap; we have that every Gehrlein weakly-stable rule is k-robust.
⊓⊔
To conclude this section we show that the robustness levels of β-CC and STV
are k. Such negative results seem unavoidable among rules that—like β-CC and
STV—provide diversity or proportionality (we discuss this further in Sect. 4).
Proposition 3. Both β-CC and STV are k-robust.
One may wonder whether there exist any voting rules with robustness level
between 1 and k. Although we could not identify any classical rules with this
property, we found natural hybrid multi-stage rules which satisfy it. For example,
the rule which ﬁrst elects half of the committee as k-Borda does and then the
other half as β-CC does has robustness level of roughly k/2.
Proposition 4. For each ℓ, there is an ℓ-robust rule.
4
Computing Reﬁnements of Robust Rules
It turns out that the dichotomy between 1-robust and k-robust rules is strongly
connected to the one between polynomial-time computable rules and those that
are NP-hard. To make this claim formal, we need the following deﬁnition.
Deﬁnition 2. A multiwinner rule R is scoring-eﬃcient if the following holds:
1. For each three positive integers n, m, and k (k ≤m) there is a polynomial-
time computable election E with n voters and m candidates, such that at least
one member of R(E, k) can be computed in polynomial time.
2. There is a polynomial-time computable function fR that for each election E,
committee size k, and committee S, associates score fR(E, k, S) with S, so
that R(E, k) consists exactly of the committees with the highest fR-score.
The ﬁrst condition from Deﬁnition 2 is satisﬁed, e.g., by weakly unanimous rules.
Deﬁnition 3 (Elkind et al. [12]). A rule R is weakly unanimous if for each
election E = (C, V ) and each committee size k, if each voter ranks the same
set W of k candidates on top (possibly in diﬀerent order), then W ∈R(E, k).

86
R. Bredereck et al.
All voting rules which we consider in this paper are weakly unanimous
(indeed, voting rules which are not weakly unanimous are somewhat “suspi-
cious”). Further, all our rules, except STV, satisfy the second condition from
Deﬁnition 2. For example, while winner determination for β-CC is indeed NP-
hard, computing the score of a given committee can be done in polynomial time.
We are ready to state and prove the main theorem of this section.
Theorem 1. Let R be a 1-robust scoring-eﬃcient multiwinner rule. Then there
is a polynomial-time computable rule R′ such that for each election E and com-
mittee size k we have R′(E, k) ⊆R(E, k).
Proof. We will show a polynomial-time algorithm that, given an election E and
committee size k, ﬁnds a committee W ∈R(E, k); we let R′(E, k) output {W}.
Let E = (C, V ) be our input election and let k be the size of the desired
committee. Let E′ = (C, V ′) be an election with |V ′| = |V |, whose existence is
guaranteed by the ﬁrst condition of Deﬁnition 2, and let S′ be a size-k R-winning
committee for this election, also guaranteed by Deﬁnition 2.
Let E0, E1 . . . , Et be a sequence of elections such that E0 = E′, Et = E, and
for each integer i ∈[t], we obtain Ei from Ei−1 by (i) ﬁnding a voter v and two
candidates c and d such that in Ei−1 voter v ranks c right ahead of d, but in E
voter v ranks d ahead of c (although not necessarily right ahead of c), and (ii)
swapping c and d in v’s preference order. We note that at most |C||V |2 swaps
suﬃce to transform E′ into E (i.e., t ≤|C||V |2).
For each i ∈{0, 1, . . . , t}, we ﬁnd a committee Si ∈R(Ei, k). We start
with S0 = S′ (which satisﬁes our condition) and for each i ∈[t], we obtain Si
from Si−1 as follows: Since R is 1-robust, we know that at least one commit-
tee S′′ from the set {S′′ | |Si−1 ∩S′′| ≥k −1} is winning in Ei. We try each
committee S′′ from this set (there are polynomially many such committees) and
we compute the fR-score of each of them (recall Condition 2 of Deﬁnition 2). The
committee with the highest fR-score must be winning in Ei and we set Si to be
this committee (by Deﬁnition 2, computing the fR-scores is a polynomial-time
task).
Finally, we output St. By our arguments, we have that St ∈R(E, k).
⊓⊔
Theorem 1 generalizes to the case of r-robust rules for constant r: Our algo-
rithm simply has to try more (but still polynomially many) committees S′′.
Let us note how Theorem 1 relates to single-winner rules (that can be seen as
multiwinner rules for k = 1). All such rules are 1-robust, but for those with NP-
hard winner determination, even computing the candidates’ scores is NP-hard
(see, e.g., the survey of Caragiannis et al. [6]), so Theorem 1 does not apply.
5
Complexity of Computing the Robustness Radius
In the Robustness Radius problem we ask if it is possible to change the election
result by performing a given number of swaps of adjacent candidates. Intuitively,
the more swaps are necessary, the more robust a particular election is.

Robustness Among Multiwinner Voting Rules
87
Deﬁnition 4. Let R be a multiwinner rule. In the R Robustness Radius
problem we are given an election E = (C, V ), a committee size k, and an inte-
ger B. We ask if it is possible to obtain an election E′ by making at most B swaps
of adjacent candidates within the rankings in E so that R(E′, k) ̸= R(E, k).
This problem is strongly connected to some other problems studied in the
literature. Speciﬁcally, in the Destructive Swap Bribery problem [13,16,25]
(DSB for short) we ask if it is possible to preclude a particular candidate from
winning by making a given number of swaps. DSB was already used to study
robustness of single-winner election rules by Shiryaev et al. [25]. We decided to
give our problem a diﬀerent name, and not to refer to it as a multiwinner variant
of DSB, because we feel that in the latter the goal should be to preclude a given
candidate from being a member of any of the winning committees, instead of
changing the outcome in any arbitrary way. In this sense, our problem is very
similar to the Margin of Victory problem [4,7,20,26], which has the same
goal, but instead of counting single swaps, counts how many votes are changed.
We ﬁnd that Robustness Radius tends to be computationally challenging.
Indeed, we ﬁnd polynomial-time algorithms only for the following simple rules.
Theorem 2. Robustness Radius is computable in polynomial time for
SNTV, Bloc, and k-Borda.
The rules in Theorem 2 are all 1-robust, but not all 1-robust rules have
eﬃcient Robustness Radius algorithms. In particular, a simple modiﬁcation
of a proof of Kaczmarczyk and Faliszewski [16, Theorem 3] shows that for k-
Copelandα rules (which are 1-robust) we obtain NP-hardness. We also obtain a
general NP-hardness for all Gehrlein weakly-stable rules.
Corollary 2. k-Copeland Robustness Radius is NP-hard.
Theorem 3. Robustness Radius is NP-hard for Gehrlein weakly-stable rules.
Without much surprise, we ﬁnd that Robustness Radius is also NP-hard
for STV and for β-CC. For these rules, however, the hardness results are, in
fact, signiﬁcantly stronger. In both cases it is NP-hard to decide if the election
outcome changes after a single swap, and for STV the result holds even for
committees of size one (β-CC with committees of size one is simply the single-
winner Borda rule, for which the problem is polynomial-time solvable [25]).
Theorem 4. Robustness Radius is NP-hard both for STV and for β-CC,
even if we can perform only a single swap; for STV this holds even for committees
of size 1. For β-CC, the problem is W[1]-hard with respect to the committee size.
For the case of β-CC, the proof of Theorem 4 gives much more than stated in
the theorem. Indeed, our construction shows that the problem remains NP-hard
even if we are given a current winning committee as part of the input. Further,
the same construction gives the following corollary (whose ﬁrst part is sometimes
taken for granted in the literature, but has not been shown formally yet).

88
R. Bredereck et al.
Corollary 3. The problem of deciding if a given candidate belongs to some
β-CC winning committee (for a given election and committee size) is both NP-
hard and coNP-hard.
We conclude this section by providing FPT algorithms for Robustness
Radius. An FPT algorithm for a given parameter (e.g., the number of candi-
dates or the number of voters) must have running time of the form f(k)|I|O(1),
where k is the value of the parameter and |I| is the length of the encoding of
the input instance. Using the standard approach of formulating integer linear
programs and invoking the algorithm of Lenstra [18], we ﬁnd that Robustness
Radius is in FPT when parametrized by the number of candidates.
Proposition 5. Robustness Radius for k-Copeland, NED, STV, and β-CC
is in FPT (parametrized by the number of candidates).
For STV and β-CC we also get algorithms parametrized by the number of
voters. For the case of STV, we assume that the value of k is such that we
never need to “delete non-existent voters” and we refer to committee sizes, k,
where such deleting is not necessary as normal. For example, k is not normal
if k > n. Another example is to take n = 12 and k = 5: We need to delete
q = ⌊12
5+1⌋+ 1 = 3 voters for each committee member, which requires deleting
15 out of 12 voters.
Theorem 5. STV Robustness Radius is in FPT when parametrized by the
number n of voters (for normal committee sizes).
Proof. Let E = (C, V ) be an input election and k be the size of the desired com-
mittee. For each candidate c, we defnie “rank of c” as rank(c) = minv∈V (posv(c)).
First, we prove that a candidate with a rank higher than n cannot be a
member of a winning committee. Let us assume towards a contradiction that
there exists a candidate c with rank(c) > n who is a member of some winning
committee W. When STV adds some candidate to the committee (this happens
when the number of voters who rank such a candidate ﬁrst exceeds the quota
⌊
n
k+1⌋+ 1), it removes this candidate and at least one voter from the election.
Thus, before c were included in W, STV must have removed some candidate c′
from the election without adding it to W (since c had to be ranked ﬁrst by some
voter to be included in the committee; for c to be ranked ﬁrst, STV had to delete
at least n candidates, so by the assumption that the committee size is normal,
not all of them could have been included in the committee). Since STV always
removes a candidate with the lowest Plurality score, and at the moment when c′
was removed the Plurality score of c was equal to zero, the Plurality score of c′
also must have been zero. Thus, removing c′ from the election did not aﬀect the
top preferences of the voters, and STV, right after removing c′, removed another
candidate with zero Plurality score. By repeating this argument suﬃciently many
times, we conclude that c must have been eventually eliminated, and so could
not have been added to W. This gives a contradiction and proves our claim.
The same reasoning also shows that the number of committees winning
according to STV is bounded by a function of n: In each step either one of

Robustness Among Multiwinner Voting Rules
89
at most n voters is removed, or all candidates who are not ranked ﬁrst by any
voter are removed from the election (which leaves at most n candidates in the
election).
Second, we observe that the robustness radius for our election is at most n2.
Indeed, we can take any winning candidate, and with at most n2 swaps we can
push him or her to have rank at least n + 1. Such a candidate will no longer be
a member of W and, so, the outcome of the election will change.
Third, we observe that in order to change the outcome of an election, we
should only swap such candidates that at least one of them has rank at most
n2 + n + 1. Indeed, consider a candidate c with rank(c) > n2 + n + 1. After
n2 swaps, the rank of this candidate would still be above n, so he or she still
would not belong to any winning committee. Thus, a swap of any two candidates
with ranks higher than n2 + n + 1 does not belong to any of the sequences of at
most n2 swaps that change the election result (the exact positions of these two
candidates would have no inﬂuence on the STV outcome).
As a result, it suﬃces to focus on the candidates with ranks at most n2+n+1.
There are at most n(n2+n+1) such candidates. Consequently, there are at most
(2n3 + 2n2 + 2n)n2 possible n2-long sequences of swaps which we need to check
in order to ﬁnd the optimal one. This completes the proof.
⊓⊔
The algorithm for the case of β-CC is more involved. Brieﬂy put, it relies on
ﬁnding either the unique winning committee or two committees tied for victory.
In the former case, it combines brute-force search with dynamic programming,
and in the latter either a single swap or a clever greedy algorithm suﬃce.
Theorem 6. β-CC Robustness Radius is in FPT for the number of voters.
6
Beyond the Worst Case: An Experimental Evaluation
In this section we present results of experiments, in which we measure how many
randomly-selected swaps are necessary to change election results.3
We perform a series of experiments using four distributions of rankings
obtained from PrefLib [21], a library that contains both real-life preference data
and tools for generating synthetic elections. We use three artiﬁcial distributions:
(i) Impartial Culture (IC), (ii) Mallows Model with parameter φ between 0 and
1 drawn uniformly, and (iii) the mixture of two Mallows Models with separate
parameters φ chosen identically to the previous model. (Intuitively, in the Mal-
lows model there is a single most probable preference order r0, and the more
swaps are necessary to modify a given order r to become r0, the less probable it
is to draw r; in the IC model, drawing each preference order is equally likely.)
Additionally, we use one dataset describing real-life preferences over sushi sets
(we treat this dataset as a distribution selecting votes from this dataset uniformly
3 We found STV to be computationally too intensive for our experiments, so we used a
simpliﬁed variant where all internal ties are broken lexicographically. We omit NED
for similar reasons (but we expect the results to be similar as for k-Copeland).

90
R. Bredereck et al.
at random). For each of these four distributions, and for every investigated rule
(for k-Copeland we took α = 0.5), we perform 200 simulations. In each simula-
tion we draw an election containing 10 candidates and 50 voters from the given
distribution. Then we repeatedly draw a pair of adjacent candidates uniformly
at random and perform a swap, until the outcome of the election changes or
1000 swaps are done (taking 1000 for the following computations). The average
number of swaps required to change the outcome of an election for diﬀerent
rules and for diﬀerent datasets is depicted in Fig. 1. We present the results for
committee size k = 3; simulations for k = 5 led to analogous conclusions.
Among our rules, k-Borda is the most robust one (k-Copeland holds second
place), whereas rules that achieve either diversity (β-CC and, to some extent,
SNTV) or proportionality (STV) are more vulnerable to small changes in the
input. This is aligned with what we have seen in the theoretical part of the paper
(with a minor exception of SNTV). As expected, the robustness radius decreases
with the increase of randomness in the voters’ preferences. Indeed, one needs to
make more swaps to change the outcome of elections which are highly biased
towards the resulting winners. Thus we conclude that preferences in the sushi
datasets are not highly centered, as the radiuses of these elections are small.
Fig. 1. Experimental results showing the average number of swaps needed to change
the outcome of random elections obtained according to the description in Sect. 6.
7
Conclusions
We formalized the notion of robustness of multiwinner rules and studied the
complexity of assessing the robustness/conﬁdence of collective multiwinner deci-
sions. Our theoretical and experimental analysis indicates that k-Borda is the
most robust among our rules, and that proportional rules, such as STV and the
Chamberlin–Courant rule, are on the other end of the spectrum.
Acknowledgments. We are grateful to anonymous SAGT reviewers for their use-
ful comments. R. Bredereck was supported by the DFG fellowship BR 5207/2.
P. Faliszewski was supported by the NCN, Poland, under project 2016/21/B/
ST6/01509. A. Kaczmarczyk was supported by the DFG project AFFA (BR 5207/1
and NI 369/15). P. Skowron was supported by a Humboldt Fellowship. N. Talmon was
supported by an I-CORE ALGO fellowship.

Robustness Among Multiwinner Voting Rules
91
References
1. Aziz, H., Elkind, E., Faliszewski, P., Lackner, M., Skowron, P.: The Condorcet prin-
ciple for multiwinner elections: from shortlisting to proportionality. arXiv preprint
arXiv:1701.08023 (2017)
2. Barber`a, S., Coelho, D.: How to choose a non-controversial list with k names. Soc.
Choice Welf. 31(1), 79–96 (2008)
3. Betzler, N., Slinko, A., Uhlmann, J.: On the computation of fully proportional
representation. J. Artif. Intell. Res. 47, 475–519 (2013)
4. Blom, M., Stuckey, P., Teague, V.: Towards computing victory margins in STV
elections. arXiv preprint arXiv:1703.03511 (2017)
5. Bredereck, R., Faliszewski, P., Kaczmarczyk, A., Niedermeier, R., Skowron,
P., Talmon, N.: Robustness among multiwinner voting rules. arXiv preprint
arXiv:1707.01417 (2017)
6. Caragiannis, I., Hemaspaandra, E., Hemaspaandra, L.: Dodgson’s rule and Young’s
rule. In: Brandt, F., Conitzer, V., Endriss, U., Lang, J., Procaccia, A.D.
(eds.) Handbook of Computational Social Choice. Cambridge University Press,
Cambridge (2016)
7. Cary, D.: Estimating the margin of victory for instant-runoﬀvoting. Presented at
EVT/WOTE-2011, August 2011
8. Chamberlin, B., Courant, P.: Representative deliberations and representative deci-
sions: proportional representation and the Borda rule. Am. Polit. Sci. Rev. 77(3),
718–733 (1983)
9. Coelho, D.: Understanding, evaluating and selecting voting rules through games
and axioms. Ph.D. thesis, Universitat Aut`onoma de Barcelona (2004)
10. Conitzer, V., Rognlie, M., Xia, L.: Preference functions that score rankings and
maximum likelihood estimation. In: Proceedings of IJCAI-2009, pp. 109–115, July
2009
11. Cygan, M., Fomin, F.V., Kowalik, L., Lokshtanov, D., Marx, D., Pilipczuk, M.,
Pilipczuk, M., Saurabh, S.: Parameterized Algorithms. Springer, Heidelberg (2015)
12. Elkind, E., Faliszewski, P., Skowron, P., Slinko, A.: Properties of multiwinner vot-
ing rules. Social Choice Welf. 48(3), 599–632 (2017)
13. Elkind, E., Faliszewski, P., Slinko, A.: Swap bribery. In: Mavronicolas, M.,
Papadopoulou, V.G. (eds.) SAGT 2009. LNCS, vol. 5814, pp. 299–310. Springer,
Heidelberg (2009). doi:10.1007/978-3-642-04645-2 27
14. Faliszewski, P., Skowron, P., Slinko, A., Talmon, N.: Committee scoring rules:
axiomatic classiﬁcation and hierarchy. In: Proceedings of IJCAI-2016, pp. 250–256
(2016)
15. Gehrlein, W.: The Condorcet criterion and committee selection. Math. Soc. Sci.
10(3), 199–209 (1985)
16. Kaczmarczyk, A., Faliszewski, P.: Algorithms for destructive shift bribery. In: Pro-
ceedings of AAMAS-2016, pp. 305–313 (2016)
17. Kamwa, E.: On stable voting rules for selecting committees. J. Math. Econ. 70,
36–44 (2017)
18. Lenstra Jr., H.: Integer programming with a ﬁxed number of variables. Math. Oper.
Res. 8(4), 538–548 (1983)
19. Lu, T., Boutilier, C.: Budgeted social choice: from consensus to personalized deci-
sion making. In: Proceedings of IJCAI-2011, pp. 280–286 (2011)
20. Magrino, T., Rivest, R., Shen, E., Wagner, D.: Computing the margin of victory
in IRV elections. Presented at EVT/WOTE-2011, August 2011

92
R. Bredereck et al.
21. Mattei, N., Walsh, T.: Preﬂib: a library for preferences. In: Proceedings of the 3rd
International Conference on Algorithmic Decision Theory, pp. 259–270 (2013)
22. McGarvey, D.: A theorem on the construction of voting paradoxes. Econometrica
21(4), 608–610 (1953)
23. Procaccia, A., Rosenschein, J., Zohar, A.: On the complexity of achieving propor-
tional representation. Soc. Choice Welf. 30(3), 353–362 (2008)
24. Sekar, S. Sikdar., Xia, L.: Condorcet consistent bundling with social choice. In:
Proceedings of AAMAS-2017, May 2017
25. Shiryaev, D., Yu, L., Elkind, E.: On elections with robust winners. In: Proceedings
of AAMAS-2013, pp. 415–422 (2013)
26. Xia, L.: Computing the margin of victory for various voting rules. In: Proceedings
of EC-2012, pp. 982–999, June 2012

Computing Constrained Approximate Equilibria
in Polymatrix Games
Argyrios Deligkas1(B), John Fearnley2, and Rahul Savani2
1 Technion, Haifa, Israel
argyris@technion.ac.il
2 University of Liverpool, Liverpool, UK
Abstract. This paper studies constrained approximate Nash equilibria
in polymatrix games. We show that is NP-hard to decide if a polymatrix
game has a constrained approximate equilibrium for 9 natural constraints
and any non-trivial ϵ. We then provide a QPTAS for polymatrix games
with bounded treewidth and logarithmically many actions per player that
ﬁnds constrained approximate equilibria for a wide family of constraints.
1
Introduction
In this paper we study polymatrix games, which provide a succinct representation
of a many-player game. In these games, each player is a vertex in a graph, and
each edge of the graph is a bimatrix game. Every player chooses a single strategy
and plays it in all of the bimatrix games that he is involved in, and his payoﬀis
the sum of the payoﬀs that he obtains from each individual edge game.
A fundamental problem in algorithmic game theory is to design eﬃcient
algorithms for computing Nash equilibria. Unfortunately, even in bimatrix games,
this is PPAD-complete [12,17], which probably rules out eﬃcient algorithms. Thus,
attention has shifted to approximate equilibria. There are two natural notions
of an approximate equilibrium. An ϵ-Nash equilibrium (ϵ-NE) requires that each
player has an expected payoﬀthat is within ϵ of their best response payoﬀ. An
ϵ-well-supported Nash equilibrium (ϵ-WSNE) requires that all players only play
pure strategies whose payoﬀis within ϵ of the best response payoﬀ.
Constrained Approximate Equilibria. Sometimes, it is not enough to ﬁnd
an approximate NE, but instead we want to ﬁnd one that satisﬁes certain con-
straints, such as having high social welfare. For bimatrix games, the algorithm
of Lipton, Markakis, and Mehta (henceforth LMM) can be adapted to provide
a quasi-polynomial time approximation scheme (QPTAS) for this task [31]: we
can ﬁnd in mO( ln m
ϵ2 ) time an ϵ-NE whose social welfare is at least as good as any
ϵ′-NE where ϵ′ < ϵ.
A sequence of papers [1,11,21,29] has shown that polynomial time algorithms
for ﬁnding ϵ-NEs with good social welfare are unlikely to exist, subject to various
This work was supported by ISF grant 2021296 and EPSRC grant EP/P020909/1.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 93–105, 2017.
DOI: 10.1007/978-3-319-66700-3 8

94
A. Deligkas et al.
hardness assumptions such as ETH. These hardness results carry over to a range
of other properties, and apply for all ϵ < 1
8 [21].
Our Contribution. We show that deciding whether there is an ϵ-NE with
good social welfare in a polymatrix game is NP-complete for all ϵ ∈[0, 1]. We
then study a variety of further constraints (Table 1). For each one, we show that
deciding whether there is an ϵ-WSNE that satisﬁes the constraint is NP-complete
for all ϵ ∈(0, 1). Our results hold even when the game is a planar bipartite graph
with degree at most 3, and each player has at most 7 actions.
To put these results into context, let us contrast them with the known lower
bounds for bimatrix games, which also apply directly to polymatrix games. Those
results [1,11,21,29] imply that one cannot hope to ﬁnd an algorithm that is
better than a QPTAS for polymatrix games when ϵ < 1
8. In comparison, our
results show a stronger, NP-hardness, result, apply to all ϵ in the range (0, 1),
and hold even when the players have constantly many actions.
We then study the problem of computing constrained approximate equilibria
in polymatrix games with restricted graphs. Although our hardness results apply
to a broad class of graphs, bounded treewidth graphs do not fall within their
scope. A recent result of Ortiz and Irfan [33,34] provides a QPTAS for ﬁnding
ϵ-NEs in polymatrix games with bounded treewidth where every player has at
most logarithmically many actions. We devise a dynamic programming algorithm
for ﬁnding approximate equilibria in polymatrix games with bounded treewidth.
Much like the algorithm in [33], we discretize both the strategy and payoﬀspaces,
and obtain a complexity result that matches theirs. However, our algorithm
works directly on the game, avoiding the reduction to a CSP used in their result.
The main beneﬁt is that this algorithm can be adapted to provide a QPTAS
for constrained approximate Nash equilibria. We introduce one variable decom-
posable (OVD) constraints, which are a broad class of optimization constraints,
covering many of the problems listed in Table 1. We show that our algorithm can
be adapted to ﬁnd good approximate equilibria relative to an OVD constraint.
Initially, we do this for the restricted class of k-uniform strategies: we can ﬁnd a
k-uniform 1.5ϵ-NE whose value is better than any k-uniform ϵ/4-NE. Note that
this is similar to the guarantee given by the LMM technique in bimatrix games.
We extend this beyond the class of k-uniform strategies for constraints that are
deﬁned by a linear combination of the payoﬀs, such as social welfare. In this
case, we ﬁnd a 1.5ϵ-NE whose value is within O(ϵ) of any ϵ/8-NE.
Related Work. Barman et al. [4] have provided a randomised QPTAS for poly-
matrix games played on trees. Their algorithm is also a dynamic programming
algorithm that discretizes the strategy space using the notion of a k-uniform
strategy. Their algorithm is a QPTAS for general polymatrix games on trees
and when the number of pure strategies for every player is bounded by a con-
stant they get an expected polynomial-time algorithm (EPTAS).
The work of Ortiz and Irfan [33] applies to a much wider class of games that
they call graphical multi-hypermatrix games. They provide a QPTAS for the

Computing Constrained Approximate Equilibria in Polymatrix Games
95
case where the interaction hypergraph has bounded hypertreewidth. This class
includes polymatrix games that have bounded treewdith and logarithmically
many actions per player. For the special cases of tree polymatrix games and
tree graphical games they go further and provide explicit dynamic programming
algorithms that work directly on the game, and avoid the need to solve a CSP.
Gilboa and Zemel [27] showed that it is NP-complete to decide whether there
exist Nash equilibria in bimatrix games with certain properties, such as high
social welfare. Conitzer and Sandholm [13] extended the list of NP-complete prob-
lems of [27]. Bil`o and Mavronicolas [5] extended these results to win-lose bima-
trix games. Bonifaci et al. [9] showed that it is NP-complete to decide whether a
win-lose bimatrix game possesses a Nash equilibrium where every player plays
a uniform strategy over their support. Recently, Garg et al. [26] and Bil`o and
Mavronicolas [6,7] extended these results to many-player games and provided
analogous ETR-completeness results.
Elkind et al. have given a polynomial time algorithm for ﬁnding exact Nash
equilibria in two-action path graphical games [23]. They have also extended this
to ﬁnd good constrained exact equilibria in certain two-action tree graphical
games [24]. Greco and Scarcello provide further hardness results for constrained
equilibria in graphical games [28].
Computing approximate equilibria in bimatrix games has been well stud-
ied [10,14,18,19,25,30,36], but there has been less work for polymatrix games [3,
20,22]. Rubinstein [35] has shown that there is a small constant ϵ such that ﬁnd-
ing an ϵ-NE of a polymatrix game is PPAD-complete. For constrained ϵ-NE, the
only positive results were for bimatrix games and gave algorithms for ﬁnding
ϵ-NE with constraints on payoﬀs [15,16].
2
Preliminaries
We start by ﬁxing some notation. We use [k] to denote the set of integers
{1, 2, . . . , k}, and when a universe [k] is clear, we will use ¯S = {i ∈[k] : i /∈S}
to denote the complement of S ⊆[k]. For a k-dimensional vector x, we use x−S
to denote the elements of x with indices ¯S, and in the case where S = {i} has
only one element, we simply write x−i for x−S.
An n-player polymatrix game is deﬁned by an undirected graph G = (V, E)
with n vertices, where each vertex is a player. The edges of the graph specify
which players interact with each other. For each i ∈[n], we use N(i) = {j
:
(i, j) ∈E} to denote the neighbors of player i. Each edge (i, j) ∈E speciﬁes a
bimatrix game to be played between players i and j. Each player i ∈[n] has a
ﬁxed number of pure strategies m, so the bimatrix game on edge (i, j) ∈E is
speciﬁed by an m × m matrix Aij, which gives the payoﬀs for player i, and an
m × m matrix Aji, which gives the payoﬀs for player j. We allow the individual
payoﬀs in each matrix to be an arbitrary rational number. We make the standard
normalisation assumption that the maximum payoﬀeach player can obtain under
any strategy proﬁle is 1 and the minimum is zero, unless speciﬁed otherwise. This
can be achieved for example by using the procedure described in [22]. A subgame

96
A. Deligkas et al.
of a polymatrix game is obtained by ignoring edges that are not contained within
a given subgraph of the game’s interaction graph G.
A mixed strategy for player i is a probability distribution over player i’s pure
strategies. A strategy proﬁle speciﬁes a mixed strategy for every player. Given a
strategy proﬁle s = (s1, . . . , sn), the pure strategy payoﬀs, or the payoﬀvector,
of player i under s, where only s−i is relevant, is the sum of the pure strategy
payoﬀs that he obtains in each of the bimatrix games that he plays. Formally,
we deﬁne: pi(s) := 
j∈N(i) Aijsj. The expected payoﬀof player i under the
strategy proﬁle s is deﬁned as si · pi(s). The regret of player i under s the is
diﬀerence between i’s best response payoﬀagainst s−i and between i’s payoﬀ
under s. If a strategy has regret ϵ, we say that the strategy is an ϵ-best response.
A strategy proﬁle s is an ϵ-Nash equilibrium, or ϵ-NE, if no player can increase
his utility more than ϵ by unilaterally switching from s, i.e., if the regret of
every player is at most ϵ. Formally, s is an ϵ-NE if for every player i ∈[n] it
holds that si · pi(s) ≥max pi(s) −ϵ. A strategy proﬁle s is an ϵ-well-supported
Nash equilibrium, or ϵ-WSNE, if if the regret of every pure strategy played
with positive probability is at most ϵ. Formally, s is an ϵ-WSNE if for every
player i ∈[n] it holds that for all j ∈supp(si) = {k ∈[m] | (si)k > 0} we have
(pi(s))j ≥max pi(s) −ϵ.
3
Decision Problems for Approximate Equilibria
In this section, we show NP-completeness for nine decision problems related to
constrained approximate Nash equilibria in polymatrix games. Table 1 contains
the list of the problems that we study1. For Problem 1, we show hardness for
all ϵ ∈[0, 1]. For the remaining problems, we show hardness for all ϵ ∈(0, 1),
i.e., for all approximate equilibria except exact equilibria (ϵ = 0), and trivial
approximations (ϵ = 1). All of these problems are contained in NP because a
“Yes” instance can be witnessed by a suitable approximate equilibrium (or two
in the case of Problem 5). The starting point for all of our hardness results is
the NP-complete problem Monotone 1-in-3 SAT.
Deﬁnition 1 (Monotone 1-in-3 SAT). Given a monotone boolean CNF for-
mula φ with exactly 3 distinct variables per clause, decide if there exists a sat-
isfying assignment in which exactly one variable in each clause is true. We call
such an assignment a 1-in-3 satisfying assignment.
Every formula φ, with variables V = {x1, . . . , xn} and clauses C = {y1, . . . , ym},
can be represented as a bipartite graph between V and C, with an edge between
xi and yj if and only if xi appears in clause yj. We assume, without loss of gener-
ality, that this graph is connected. We say that φ is planar if the corresponding
graph is planar. Recall that a graph is called cubic if the degree of every vertex
is exactly three. We use the following result of Moore and Robson [32].
1 Given probability distributions x and x′, the TV
distance between them is
maxi{|xi −x′
i|}. The TV distance between strategy proﬁles s = (s1, . . . , sn) and
s′ = (s′
1, . . . , s′
n) is the maximum TV distance of si and s′
i over all i.

Computing Constrained Approximate Equilibria in Polymatrix Games
97
Table 1. The decision problems that we consider. All problems take as input an n-
player polymatrix game with m actions for each player and an ϵ ∈[0, 1].
Problem description
Problem deﬁnition
Problem 1: Large total payoﬀ
u ∈(0, n]
Is there an ϵ-NE s such that

i∈[n] pi(s) ≥u?
Problem 2: Small total payoﬀ
u ∈[0, n)
Is there an ϵ-WSNE s such that

i∈[n] pi(s) ≤u?
Problem 3: Small payoﬀu ∈[0, 1)
Is there an ϵ-WSNE s such that
mini pi(s) ≤u?
Problem 4: Restricted support S ⊂[n]
Is there an ϵ-WSNE s with supp(s1) ⊆S?
Problem 5: Two ϵ-WSNE d ∈(0, 1]
apart in Total Variation (TV) distance
Are there two ϵ-WSNE with TV distance
≥d?
Problem 6: Small largest probability
p ∈(0, 1)
Is there an ϵ-WSNE s with
maxj s1(j) ≤p?
Problem 7: Large total support size
k ∈[n · m]
Is there an ϵ-WSNE s such that

i∈[n] |supp(si)| ≥k?
Problem 8: Large smallest support
size k ∈[n]
Is there an ϵ-WSNE s such that
mini |supp(si)| ≥k?
Problem 9: Large support size k ∈[n]
Is there an ϵ-WSNE s such that
|supp(s1)| ≥k?
Theorem 2 (Sect. 3.1 [32]). Monotone 1-in-3 SAT is NP-complete even when
the formula corresponds to a planar cubic graph.
From now on, we assume that φ is a monotone planar cubic formula. We say
that φ is a “Yes” instance if φ admits a 1-in-3 satisfying assignment.
Large Total Payoﬀfor ϵ-NEs. We show that Problem 1 is NP-complete for
every ϵ ∈[0, 1], even when the interaction graph for the polymatrix game is
planar, bipartite, cubic, and each player has at most three pure strategies.
Construction. Given a formula φ, we construct a polymatrix game G with
m + n players as follows. For each variable xi we create a player vi and for each
clause yj we create a player cj. We now use V to denote the set of variable players
and C to denote the clause players. The interaction graph is the bipartite graph
between V and C described above. Each edge game has the same structure.
Every player in V has two pure strategies called True and False, while every
player in C has three pure strategies that depend on the three variables in the
clause. If clause yj contains variables xi, xk, xl, then player cj has pure strategies
i, k and l. The game played between vi and cj is shown on the left in Fig. 1. The
bimatrix games for vk and vl are deﬁned analogously.

98
A. Deligkas et al.
@
@
Player cj
Player vi
i
k
l
True
False
1
0
0
-1
−1
0
0
0
−1
0
0
0
@
@
@
Player cj
Player vi
i
k
l
Out
True
False
Out
κ
c · κ
0
1
3 −ϵ
3
0
1
3
0
c · κ
0
0
1
3 −ϵ
3
1
3
0
c · κ
0
0
1
3 −ϵ
3
1
3
1
3
1
3
1
3
0
0
1
3
Fig. 1. Left: the game between clause player cj and variable player vi for Problem 1.
Right: the game between cj and vi for Problems 2–9.
Correctness. The constructed game is not normalised. We prove our result for
all ϵ, and thus in the normalised game the result will hold for all ϵ ∈[0, 1]. We
show that for every ϵ, there is an ϵ-NE with social welfare m if and only if φ
is a “Yes” instance. We begin by showing that if there is a solution for φ, then
there is an exact NE for G with social welfare m, and therefore there is also an
ϵ-NE for all ϵ with social welfare m. We start with a simple observation about
the maximum and minimum payoﬀs that players can obtain in G.
Lemma 3. In G, the total payoﬀfor every variable player is at most 0, and the
total payoﬀfor every clause player cj is at most 1. Moreover, if cj gets payoﬀ1,
then cj and the variable players connected to cj play pure strategies.
Lemma 4. If φ is a “Yes” instance, there is an NE for G with social welfare m.
Lemma 5. If there is a strategy proﬁle for G with social welfare m, then φ is a
“Yes” instance.
Together, Lemmas 4 and 5 show that for all possible values of ϵ, it is NP-
complete to decide whether there exists an ϵ-NE for G with social welfare m.
When we normalise the payoﬀs in [0, 1], this holds for all ϵ ∈[0, 1].
Theorem 6. Problem 1 is NP-complete for all ϵ ∈[0, 1], even for degree-3 bipar-
tite planar polymatrix games in which each player has at most 3 pure strategies.
Hardness of Problems 2–9. To show the hardness Problems 2–9, we modify
the game constructed in the previous section. We use G′ to denote the new
polymatrix game. The interaction graph for G′ is exactly the same as for the

Computing Constrained Approximate Equilibria in Polymatrix Games
99
game G. The bimatrix games are extended by an extra pure strategy for each
player, the strategy Out, and the payoﬀs are adapted. If variable xi is in clause
yj, then the bimatrix game between clause player cj and vi is shown on the right
in Fig. 1. To ﬁx the constants, given ϵ ∈(0, 1), we choose c to be in the range
(max(1 −3ϵ
2 , 0), 1), and we set κ =
1−ϵ
1+2c. Observe that 0 < c < 1, and that
κ + 2c · κ = 1 −ϵ. Furthermore, since c > 1 −3ϵ
2 we have 0 < κ < 1
3.
Lemma 7. If φ is a “Yes” instance, then G′ possesses an ϵ-WSNE such that
no player uses strategy Out.
Lemma 8. If φ is a “No” instance, then G′ possesses a unique ϵ-WSNE where
every player plays Out.
The combination of these two properties allows us to show that Problems 2–5
are NP-complete. For example, for Problem 4, we can ask whether there is an
ϵ-WSNE of the game in which player one does not player Out.
Theorem 9. Problems 2–5 are NP-complete for all ϵ ∈(0, 1), even on degree-3
planar bipartite polymatrix games where each player has at most 4 pure strategies.
Duplicating Strategies. To show hardness for Problems 6–9, we slightly mod-
ify the game G′ by duplicating every pure strategy except Out for all of the
players. Since each player cj ∈C has the pure strategies i, k, l and Out, we
give player cj pure strategies i′, k′ and l′, which each have identical payoﬀs as
the original strategies. Similarly for each player vi ∈V we add the pure strate-
gies True′ and False′. Let us denote the game with the duplicated strategies by
G. Then, if φ is a “Yes” instance, we can construct an ϵ-WSNE in which no
player plays Out, where each player places at most 0.5 probability on each pure
strategy, and where each player uses a support of size 2. These properties are
suﬃcient to show that Problems 6–9 are NP-complete.
Theorem 10. Problems 6–9 are NP-complete for all ϵ ∈(0, 1), even on degree-3
planar bipartite polymatrix games where each player has at most 7 pure strategies.
4
Constrained Equilibria in Bounded Treewidth Games
In this section, we show that some constrained equilibrium problems can be
solved in quasi-polynomial time if the input game has bounded treewidth and
at most logarithmically many actions per player. We ﬁrst present a dynamic
programming algorithm for ﬁnding approximate Nash equilibria in these games,
and then show that it can be modiﬁed to ﬁnd constrained equilibria.
Tree Decompositions. A tree decomposition of a graph G = (V, E) is a pair
(X, T), where T = (I, F) is a tree and X = {Xi|i ∈I} is a family of subsets
of V such that (1) 
i∈I Xi = V (2) for every edge (u, v) ∈E there exists an
i ∈I such that {u, v} ∈Xi, and (3) for all i, j, k ∈I if j is on the path from

100
A. Deligkas et al.
i to k in T, then Xi ∩Xk ⊆Xj. The width of a tree decomposition (X, T) is
maxi |Xi| −1. The treewidth of a graph is the minimum width over all possible
tree decompositions of the graph. In general, computing the treewidth of a graph
is NP-hard, but there are ﬁxed parameter tractable algorithms for the problem.
In particular Bodlaender [8] has given an algorithm that runs in O(f(w) · n)
time, where w is the treewidth of the graph, and n is the number of nodes.
4.1
An Algorithm to Find Approximate Nash Equilibria
Let G be a polymatrix game and let (X, T) be a tree decomposition of G’s
interaction graph. We assume that an arbitrary node of T has been chosen as
the root. Then, given some node v in T, we deﬁne G(Xv) to be the subgame
that is obtained when we only consider the players in the subtree of v. More
formally, this means that we only include players i that are contained in some
set Xu where u is in the subtree of v in the tree decomposition. Furthermore,
we will use G(Xv) to denote the players in G(Xv) \ Xv. For every player i ∈Xv,
we will use Ni(Xv) to denote the neighbours of i in G(Xv).
k-Uniform Strategies. A strategy s is said to be k-uniform if there exists a
multi-set S of k pure strategies such that s plays uniformly over the pure strate-
gies in S. These strategies naturally arise when we sample, with replacement, k
pure strategies from a distribution, and play the sampled strategies uniformly.
The following is a theorem of [2].
Theorem 11. Every n-player m-action game has a k-uniform ϵ-NE whenever
k ≥8 · ln m+ln n−ln ϵ+ln 8
ϵ2
.
Candidates and Witnesses. For each node v in the tree decomposition, we
compute a set of witnesses, where each witness corresponds to an ϵ-NE in G(Xv).
Our witnesses have two components: s provides a k-uniform strategy proﬁle for
the players in Xv, while p contains information about the payoﬀthat the players
in Xv obtain from the players in G(Xv). By summarising the information about
the players in G(Xv), we are able to keep the number of witnesses small.
There is one extra complication, however, which is that the number of pos-
sible payoﬀvectors that can be stored in p depends on the number of diﬀerent
strategies for the players in G(Xv), which is exponential, and will cause our
dynamic programming table to be too large. To resolve this, we round the entries
of p to a suitably small set of rounded payoﬀs.
Formally, we ﬁrst deﬁne P = {x ∈[0, 1] : x =
ϵ
2n · k for some k ∈N}, to be
the set of rounded payoﬀs. Then, given a node v in the tree decomposition, we
say that a tuple (s, p) is a k-candidate if:
– s is a set of strategies of size |Xv|, with one strategy for each player in Xv.
– Every strategy in s is k-uniform.
– p is a set of payoﬀvectors of size |Xv|. Each element pi ∈p is of the form
P m, and assigns a rounded payoﬀto each pure strategy of player i.

Computing Constrained Approximate Equilibria in Polymatrix Games
101
The set of candidates gives the set of possible entries that can appear in our
dynamic programming table. Every witness is a candidate, but not every candi-
date is a witness. The total number of k-candidates for each tree decomposition
node v can be derived as follows. Each player has mk possible k-uniform strate-
gies, and so there are mkw possibilities for s. We have that |P| = 2n
ϵ , and that
p contains m · w elements of P, so the total number of possibilities for p is
(2 · n
ϵ )mw. Hence, the total number of candidates for v is mkw · (2 · n
ϵ )mw.
Next, we deﬁne what it means for a candidate to be a witness. We say that
a k-candidate is an ϵ, k, r-witness if there exists a proﬁle s′ for G(Xv) where
– s′ agrees with s for the players in Xv.
– Every player in G(Xv) is ϵ-happy, which means that no player in G(Xv) can
increase their payoﬀby more than ϵ by unilaterally deviating from s′. Note
that this does not apply to the players in Xv.
– Each payoﬀvector p ∈p is within r of the payoﬀthat player i obtains from
the players in G(Xv). More accurately, for every pure strategy l of player i
we have that: |pl −
j∈
G(Xv)(Aij · s′
j)l| ≤r. Note that p does not capture
the payoﬀobtained from players in Xv, only those in the subtree of v.
The Algorithm. Our algorithm computes a set of witnesses for each tree
decomposition node by dynamic programming. At every leaf, the algorithm
checks every possible candidate to check whether it is a witness. At internal
nodes in the tree decomposition, if a vertex is forgotten, that is, if it appears in
a child of a node, but not in the node itself, then we use the set of witnesses
computed for the child to check whether the forgotten node is ϵ-happy. If this
is the case, then we create a corresponding witness for the parent node. The
complication here is that, since we use rounded payoﬀvectors, this check may
declare that a player is ϵ-happy erroneously due to rounding errors. So, during
the analysis we must be careful to track the total amount of rounding error that
can be introduced.
Once a set of witnesses has been computed for every tree decomposition node,
a second phase is then used to ﬁnd an ϵ-NE of the game. This phase picks an
arbitrary witness in the root node, and then unrolls it by walking down the tree
decomposition and ﬁnding the witnesses that were used to generate it. These
witnesses collectively assign a k-uniform strategy proﬁle to each player, and this
strategy proﬁle will be the ϵ-NE that we are looking for.
Lemma 12. There is a dynamic programming algorithm that runs in time
O(n · m2kw · ( n
ϵ )2mw) that, for each tree decomposition node v, computes a set
of candidates C(v) such that: (1) Every candidate (s, p) ∈C(v) is an ϵv, k, rv-
witness for v for some ϵv ≤1.5ϵ and rv ≤ϵ
4. (2) If s is a k-uniform ϵ/4-NE
then C(v) will contain a witness (s′, p) such that s′ agrees with s for all players
in Xv.
The running time bound arises from the total number of possible candidates
for each tree decomposition node. The ﬁrst property ensures that the algorithm

102
A. Deligkas et al.
always produces a 1.5ϵ-NE of the game, provided that the root node contains a
witness. The second property ensures that the root node will contain a witness
provided that game has a k-uniform ϵ/4-NE. Theorem 11 tells us how large k
needs to be for this to be the case. These facts yields the following theorem.
Theorem 13. Let ϵ > 0, G be a polymatrix game with treewidth w, and k =
128 · ln m+ln n−ln ϵ+ln 8
ϵ2
. There is an algorithm that ﬁnds a 1.5ϵ-NE of G in in
O(n · m2kw + ( n
ϵ )2mw) time.
Note that if m ≤ln n (and in particular if m is constant), this is a QPTAS.
Corollary 14. Let ϵ > 0, and G be a polymatrix game with treewidth w, and
m ≤ln n. There is an algorithm that ﬁnds a 1.5ϵ-NE of G in ( n
ϵ )O( w·ln n
ϵ2
) time.
4.2
Constrained Approximate Nash Equilibria
One Variable Decomposable Constraints. We now adapt the algorithm to
ﬁnd a certain class of constrained approximate Nash equilibria. As a motivating
example, consider Problem 1, which asks us to ﬁnd an approximate NE with high
social welfare. Formally, this constraint assigns a single rational number (the
social welfare) to each strategy proﬁle, and asks us to maximize this number.
This constraint also satisﬁes a decomposability property: if a game G consists of
two subgames G1 and G2, and if there are no edges between these two subgames,
then we can maximize social welfare in G by maximizing social welfare in G1 and
G2 independently. We formalise this by deﬁning a constraint to be one variable
decomposable (OVD) if the following conditions hold.
– There is a polynomial-time computable function g such that maps every strat-
egy proﬁle in G to a rational number.
– Let s be a strategy for game G, and suppose that we want to add vertex v
to G. Let s be a strategy choice for v, and s′ be an extension of s that
assigns s to v. There is a polynomial-time computable function add such that
g(s′) = add(G, v, s, g(s)).
– Let G1 and G2 be two subgames that partition G, and suppose that there
are no edges between G1 and G2. Let s1 be a strategy proﬁle in G1 and s2
be a strategy proﬁle in G2. If s is the strategy proﬁle for G that corresponds
to merging s1 and s2, then there is a polynomial-time computable function
merge such that g(s) = merge(G1, G2, g(s1), g(s2)).
Intuitively, the second condition allows us to add a new vertex to a subgame, and
the third condition allows us to merge two disconnected subgames. Moreover,
observe that the functions add and merge depend only on the value that g assigns
to strategies, and not the strategies themselves. This allows our algorithm to only
store the value assigned by g, and forget the strategies themselves.

Computing Constrained Approximate Equilibria in Polymatrix Games
103
Examples of OVD Constraints. Many of the problems in Table 1 are OVD
constraints. Problems 1 and 2 refer to the total payoﬀof the strategy proﬁle, and
so g is deﬁned to be the total payoﬀof all players, while the functions add and
merge simply add the total payoﬀof the two strategy proﬁles. Problems 3 and 6
both deal with minimizing a quantity associated with a strategy proﬁle, so for
these problems the functions add and merge use the min function to minimize the
relevant quantities. Likewise, Problems 7, 8, and 9 seek to maximize a quantity,
and so the functions add and merge use the max function. In all cases, proving
the required properties for the functions is straightforward.
Finding OVD k-Uniform Constrained Equilibria. We now show that, for
every OVD constraint, the algorithm presented in Sect. 4.1 can be modiﬁed to
ﬁnd a k-uniform 1.5ϵ-NE that also has a high value with respect to the constraint.
More formally, we show that the value assigned by g to the 1.5ϵ-NE is greater
than the value assigned to g to all k-uniform ϵ/4-NE in the game.
Given an OVD constraint deﬁned by g, add, and merge, we add an extra ele-
ment to each candidate to track the variable from the constraint: each candidate
has the form (s, p, x), where s and p are as before, and x is a rational number.
The deﬁnition of an ϵ, k, r, g-witness is extended by adding the condition:
– Recall that s′ is a strategy proﬁle for G(Xv) whose existence is asserted by
the witness. Let s′′ be the restriction of s′ to G(Xv). We have x = g(s′′).
We then modify the algorithm to account for this new element in the witness. At
each stage we track the correct value for x. At the leaves, we use g to compute the
correct value. At internal nodes, we use add and merge to compute the correct
value using the values stored in the witnesses of the children.
If at any point two witnesses are created that agree on s and p, but disagree
on x, then we only keep the witness whose x value is higher. This ensures that
we only keep witnesses corresponding to strategy proﬁles that maximize the
constraint. When we reach the root, we choose the strategy proﬁle with maximal
value for x to be unrolled in phase 2. The fact that we only keep one witness for
each pair s and p means that the running time of the algorithm is unchanged.
Theorem 15. For every ϵ > 0 let k = 128 · ln m+ln n−ln ϵ+ln 8
ϵ2
. If G is a poly-
matrix game with treewidth w, then there is an algorithm that runs in O(n ·
m2kw + ( n
ϵ )2mw) time and ﬁnds a k-uniform 1.5ϵ-NE s such that g(s) ≥g(s′)
for every strategy proﬁle s′ that is an ϵ/4-NE.
Results for Non-k-Uniform Strategies. The guarantee given by Theorem 15
is given relative to the best value achievable by a k-uniform ϵ/4-NE. It is also
interesting to ask whether we can drop the k-uniform constraint. In the following
theorem, we show that if g is deﬁned to be a linear function of the payoﬀs in
the game, then a guarantee can be given relative to every ϵ/8-NE of the game.
Note that this covers Problems 1, 2, and 3.
Theorem 16. Suppose that, for a given a OVD constraint, the function g is a
linear function of the payoﬀs. Let s be the 1.5ϵ-NE found by our algorithm when
For every ϵ/8-NE s′ we have that g(s) ≥g(s′) −O(ϵ).

104
A. Deligkas et al.
References
1. Austrin, P., Braverman, M., Chlamtac, E.: Inapproximability of NP-complete vari-
ants of Nash equilibrium. Theory Comput. 9, 117–142 (2013)
2. Babichenko, Y., Barman, S., Peretz, R.: Simple approximate equilibria in large
games. In: Proceedings of the EC, pp. 753–770 (2014)
3. Barman, S., Ligett, K.: Finding any nontrivial coarse correlated equilibrium is
hard. In: Proceedings of EC, pp. 815–816 (2015)
4. Barman, S., Ligett, K., Piliouras, G.: Approximating Nash equilibria in tree poly-
matrix games. In: Hoefer, M. (ed.) SAGT 2015. LNCS, vol. 9347, pp. 285–296.
Springer, Heidelberg (2015). doi:10.1007/978-3-662-48433-3 22
5. Bil`o, V., Mavronicolas, M.: The complexity of decision problems about Nash
equilibria in win-lose games. In: Serna, M. (ed.) SAGT 2012. LNCS, pp. 37–48.
Springer, Heidelberg (2012). doi:10.1007/978-3-642-33996-7 4
6. Bil`o, V., Mavronicolas, M.: A catalog of ∃R-complete decision problems about
Nash equilibria in multi-player games. In: Proceedings of STACS, pp. 17:1–17:13
(2016)
7. Bil`o, V., Mavronicolas, M.: ∃R-complete decision problems about symmetric Nash
equilibria in symmetric multi-player games. In: Proceedings of STACS, pp. 13:1–
13:14 (2017)
8. Bodlaender, H.L.: A linear-time algorithm for ﬁnding tree-decompositions of small
treewidth. SIAM J. Comput. 25(6), 1305–1317 (1996)
9. Bonifaci, V., Di Iorio, U., Laura, L.: The complexity of uniform Nash equilibria
and related regular subgraph problems. Theor. Comput. Sci. 401(1–3), 144–152
(2008)
10. Bosse, H., Byrka, J., Markakis, E.: New algorithms for approximate Nash equilibria
in bimatrix games. Theor. Comput. Sci. 411(1), 164–173 (2010)
11. Braverman, M., Kun-Ko, Y., Weinstein, O.: Approximating the best Nash equi-
librium in no(logn)-time breaks the exponential time hypothesis. In: Proceedings of
SODA, pp. 970–982 (2015)
12. Chen, X., Deng, X., Teng, S.-H.: Settling the complexity of computing two-player
Nash equilibria. J. ACM 56(3), 57 (2009). Article No. 14
13. Conitzer, V., Sandholm, T.: New complexity results about Nash equilibria. Games
Econ. Behav. 63(2), 621–641 (2008)
14. Czumaj, A., Deligkas, A., Fasoulakis, M., Fearnley, J., Jurdzi´nski, M., Savani,
R.: Distributed methods for computing approximate equilibria. In: Cai, Y., Vetta,
A. (eds.) WINE 2016. LNCS, vol. 10123, pp. 15–28. Springer, Heidelberg (2016).
doi:10.1007/978-3-662-54110-4 2
15. Czumaj, A., Fasoulakis, M., Jurdzi´nski, M.: Approximate Nash equilibria with near
optimal social welfare. In: Proceedings of IJCAI, pp. 504–510 (2015)
16. Czumaj, A., Fasoulakis M., Jurdzi´nski, M.: Approximate plutocratic and egalitar-
ian Nash equilibria. In: Proceedings of AAMAS, pp. 1409–1410 (2016)
17. Daskalakis, C., Goldberg, P.W., Papadimitriou, C.H.: The complexity of computing
a Nash equilibrium. SIAM J. Comput. 39(1), 195–259 (2009)
18. Daskalakis, C., Mehta, A., Papadimitriou, C.H.: Progress in approximate Nash
equilibria. In: Proceedings of EC, pp. 355–358 (2007)
19. Daskalakis, C., Mehta, A., Papadimitriou, C.H.: A note on approximate Nash
equilibria. Theor. Comput. Sci. 410(17), 1581–1588 (2009)
20. Deligkas, A., Fearnley, J., Igwe, T.P., Savani, R.: An empirical study on computing
equilibria in polymatrix games. In: Proceedings of AAMAS, pp. 186–195 (2016)

Computing Constrained Approximate Equilibria in Polymatrix Games
105
21. Deligkas, A., Fearnley, J., Savani, R.: Inapproximability results for approximate
Nash equilibria. In: Cai, Y., Vetta, A. (eds.) WINE 2016. LNCS, vol. 10123, pp.
29–43. Springer, Heidelberg (2016). doi:10.1007/978-3-662-54110-4 3
22. Deligkas, A., Fearnley, J., Savani, R., Spirakis, P.G.: Computing approximate Nash
equilibria in polymatrix games. Algorithmica 77(2), 487–514 (2017)
23. Elkind, E., Goldberg, L.A., Goldberg, P.W.: Nash equilibria in graphical games on
trees revisited. In: Proceedings of EC, pp. 100–109 (2006)
24. Elkind, E., Goldberg, L.A., Goldberg, P.W.: Computing good Nash equilibria in
graphical games. In: Proceedings of EC, pp. 162–171 (2007)
25. Fearnley, J., Goldberg, P.W., Savani, R., Sørensen, T.B.: Approximate well-
supported Nash equilibria below two-thirds. In: Serna, M. (ed.) SAGT 2012. LNCS,
pp. 108–119. Springer, Heidelberg (2012). doi:10.1007/978-3-642-33996-7 10
26. Garg, J., Mehta, R., Vazirani, V.V., Yazdanbod, S.: ETR-completeness for deci-
sion versions of multi-player (symmetric) Nash equilibria. In: Halld´orsson, M.M.,
Iwama, K., Kobayashi, N., Speckmann, B. (eds.) ICALP 2015. LNCS, vol. 9134,
pp. 554–566. Springer, Heidelberg (2015). doi:10.1007/978-3-662-47672-7 45
27. Gilboa, I., Zemel, E.: Nash and correlated equilibria: some complexity considera-
tions. Games Econ. Behav. 1(1), 80–93 (1989)
28. Greco, G., Scarcello, F.: On the complexity of constrained Nash equilibria in graph-
ical games. Theor. Comput. Sci. 410(38–40), 3901–3924 (2009)
29. Hazan, E., Krauthgamer, R.: How hard is it to approximate the best Nash equi-
librium? SIAM J. Comput. 40(1), 79–91 (2011)
30. Kontogiannis, S.C., Spirakis, P.G.: Well supported approximate equilibria in bima-
trix games. Algorithmica 57(4), 653–667 (2010)
31. Lipton, R.J., Markakis, E., Mehta, A.: Playing large games using simple strategies.
In: Proceedings of EC, pp. 36–41 (2003)
32. Moore, C., Robson, J.M.: Hard tiling problems with simple tiles. Discrete Comput.
Geom. 26(4), 573–590 (2001)
33. Ortiz, L.E., Irfan, M.T.: FPTAS for mixed-strategy Nash equilibria in tree graph-
ical games and their generalizations. CoRR, abs/1602.05237 (2016)
34. Ortiz, L.E., Irfan, M.T.: Tractable algorithms for approximate Nash equilibria in
generalized graphical games with tree structure. In: Proceedings of AAAI, pp.
635–641 (2017)
35. Rubinstein, A.: Inapproximability of Nash equilibrium. In: Proceedings of STOC,
pp. 409–418 (2015)
36. Tsaknakis, H., Spirakis, P.G.: An optimization approach for approximate Nash
equilibria. Internet Math. 5(4), 365–382 (2008)

Group Activity Selection on Graphs:
Parameterized Analysis
Sushmita Gupta1, Sanjukta Roy2(B), Saket Saurabh1,2, and Meirav Zehavi1
1 University of Bergen, Bergen, Norway
{sushmita.gupta,meirav.zehavi}@uib.no
2 The Institute of Mathematical Sciences, HBNI, Chennai, India
{sanjukta,saket}@imsc.res.in
Abstract. In varied real-life situations, ranging from carpooling to
workload delegation, several activities are to be performed, to which end
each activity should be assigned to a group of agents. These situations
are captured by the Group Activity Selection Problem (GASP). Notably,
relevant relations among agents, such as acquaintanceship or physical dis-
tance, can often be modeled naturally using graphs. To exploit this mod-
eling ability, Igarashi, Peters and Elkind [AAAI 17] introduced gGASP.
Speciﬁcally, it is required that each group would correspond to a con-
nected set of the underlying graph. In addition, to enforce the execu-
tion of the activities in practice, no individual should desire to desert
its group in favor of joining another group. In other words, the assign-
ment should be Nash stable. In this paper, we study gGASP with Nash
stability (gNSGA), whose objective is to compute such an assignment.
This problem is computationally hard even on such restricted topologies
as paths and stars, which naturally led Igarashi, Bredereck, Peters and
Elkind [AAAI 17, AAMAS 17] to the study gNSGA in the framework
of parameterized complexity. We take this line of investigation forward,
signiﬁcantly advancing the state-of-the-art. First, we show that gNSGA
is NP-hard even when merely one activity is present. In fact, this spe-
cial case remains NP-hard when we further restrict the graph to have
maximum degree Δ = 5. Consequently, gNSGA is not ﬁxed-parameter
tractable (FPT), or even XP, when parameterized by p + Δ, where p is
the number of activities. However, we are able to design a parameter-
ized algorithm for gNSGA on general graphs with respect to p + Δ + t,
where t is the maximum size of a group. Finally, we develop an algo-
rithm that solves gNSGA on graphs of bounded treewidth tw in time
4p · (n + p)O(tw). Here, Δ + t can be arbitrarily large. Along the way,
we resolve several open questions regarding gNSGA.
1
Introduction
Division of labor is required in varied real-world situations. For a task to be
accomplished, be it the construction of a building or the development of a prod-
uct, it is necessary to assign agents (such as people or companies) to appropriate
activities, and those agents must be willing to contribute towards the common
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 106–118, 2017.
DOI: 10.1007/978-3-319-66700-3 9

Group Activity Selection on Graphs: Parameterized Analysis
107
goal. Though workload delegation is perhaps the ﬁrst example that comes to
mind, management of cooperation—or more precisely, formation of groups by
agents participating in speciﬁc activities—is ubiquitous in almost all aspects of
life. Indeed, other examples range from carpooling and seating arrangements to
hobbies such as tennis or basketball. All such situations are neatly captured by
the Group Activity Selection Problem (GASP) introduced in [4].
An instance of GASP is given by a ﬁnite set of agents N, where |N| = n,
a ﬁnite set of activities A = A⋆∪{a∅}, where A⋆= {a1, . . . , ap} and a∅is
a void activity, and a proﬁle (⪰v)v∈N of complete and transitive preference
relations over the set of alternatives X = (A⋆× {1, 2, . . . , n}) ∪{(a∅, 1)}.1 The
void activity a∅is introduced to allow agents to avoid undertaking activities,
which also enables agents to be independent. For example, in the case of the
development of a product, the set N may consist of employees of some company,
each activity in the set A may correspond to the design of a certain component
of the product, and the proﬁle (⪰v)v∈N may be constructed according to the
skills/personal preferences of the employees and their abilities/willingness to
function in groups of varied sizes. The void activity would allow to exclude
employees from the current project in case no suitable activities can be assigned
to them.
The outcome of GASP is deﬁned as an assignment, which is a simply function
π : N →A. Clearly, an arbitrary assignment is extremely undesirable unless the
proﬁle (⪰v)v∈N is completely meaningless. To take the proﬁle into account, it is
ﬁrst natural to request that π would at least be individually rational (IR), which
means that for every agent v ∈N with π(v) = a (̸= a∅), we have (a, |πa|) ⪰v
(a∅, 1), where πa = π−1(a) = {v ∈N : π(v) = a}.2 That is, no agent v would
rather “being alone” than being part of a group of size |πv| that performs activity
a = π(v), where πv = πa (that is, πv is the set of all those agents that have been
assigned the same activity as v). In addition, to enforce the execution of the
activities in practice, no individual should desire to act on its own by deserting
its group in favor of joining another group. In other words, we would like the
assignment to be Nash stable. Formally, an agent v ∈N is said to have an NS-
deviation to an activity a ∈A⋆if a ̸= π(v) and (a, |πa| + 1) ≻v (π(v), |πv|), that
is, v prefers to join the activity a, given every one else plays the same activity
as before. Accordingly, π is said to be Nash stable if it is individually rational
and no agent has an NS-deviation.
Let us take a step back and observe that if an assignment π is Nash stable,
then the only implication is that no agent has an alternative more preferred
than the situation assigned to it by π. However, we do not ensure by any means
that the agent would actually be able/willing to cooperate with other members
in its group, so that the assignment can actually be executed in a satisfactory
manner. Notably, relevant relations among agents, such as acquaintanceship,
compatibility or geographical distance, can often be modeled naturally using
1 For the sake of consistency, we follow the notations and deﬁnitions of [14].
2 As we would always work with IR assignments, when specifying preference proﬁles,
we would only explicitly state the alternatives that are preferred more than a∅.

108
S. Gupta et al.
graphs. To exploit this modeling ability, Igarashi et al. [14] introduced gGASP.
Speciﬁcally, it is required that each group would correspond to a connected set of
the underlying graph. For a deeper understanding of the rationale underlying this
requirement, let us consider the case where the graph is a social network. Then,
by ensuring that each group is a connected set, we ensure that each individual in
the group would be acquainted with at least one other person in the group. The
desirability of such property is clear when discussing activities such as carpooling,
seating arrangements or sports as it is conceivable that people would prefer to
share a taxi/sit next to/play with at least one other person whom they know.
In the context of workload delegation, apart from a social aspect, it is likely
that agents who are familiar with each other would also be able to work more
eﬃciently with each other, with each agent having at least one other agent as a
comfortable communication link or a source to “count on”.
Formally, an instance of gGASP [14] consists of an instance (N, (⪰v)v∈N, A)
of GASP and a set of communication links between agents, L ⊆{{u, v} | u, v ∈
N, u ̸= v}. Thus, we assume that we are also given a graph G with vertex set
V (G) = N and E(G) = L. Here, G is called underlying network (or graph)
of gGASP. A set S ⊆N of agents is said to be a coalition, and it is a feasible
coalition if G[S] is connected where G[S] is the graph induced on the vertices in
S. Now, an NS-deviation by an agent v to an activity a ∈A⋆is called a feasible
NS-deviation if πa∪{v} is a feasible coalition. Thus, in the context of gGASP, an
assignment π is said to be Nash stable if it is individually rational and no agent
has a feasible NS-deviation. We would be interested in the following question.
Nash Stable gGASP (gNSGA)
Input: An instance I = (N, (⪰v)v∈N, A, G) of gGASP.
Question: Does I have a feasible Nash stable assignment (fNsa) ?
Igarashi et al. [14] showed that gNSGA is NP-complete even when the under-
lying graph is a path, a star, or if the size of each connected component is
bounded by a constant. In addition, they exhibit FPT algorithms (for the same
graph classes) when parameterized by the number of activities. In a more recent
work by Igarashi et al. [12], the authors show that when parameterized by the
number of players, gNSGA is W[1]-hard on cliques (the classical setting of GASP),
but admits an XP-algorithm for the same graph classes. Furthermore, when the
underlying graph is a clique, gNSGA is W[1]-hard when parameterized by the
number of activities. They also give an FPT algorithm for acyclic graphs, para-
meterized by the number of activities. Speciﬁcally, Igarashi et al. [14] posed the
following open question.
For general graphs, the exact parameterized complexity of determining the
existence of stable outcomes is unknown. . . for other networks, including
trees, it is not even clear whether our problem is in XP with respect to
the number of activities.

Group Activity Selection on Graphs: Parameterized Analysis
109
Our Contribution. Given that gNSGA is NP-hard even on paths and stars [14],
and as this problem inherently encompasses parameters that can be often
expected to be small in practice, it is indeed very natural to examine it from
the viewpoint of parameterized complexity.3 In this context, we take the line of
investigation initiated by the studies [12,14] several steps forward, signiﬁcantly
advancing the state-of-the-art. In fact, as we explain below, we push some bound-
aries to their limits, and along the way, we give answer to questions posed by
Igarashi et al. [14] that are even stronger than requested.
Hardness: Firstly, we consider p = |A⋆|, the number of activities, as the para-
meter. Here, we show that gNSGA is NP-hard even when merely one activity is
present, that is, p = 1. More precisely, we prove the following theorem. Here, Δ
is the maximum degree of the graph G.
Theorem 1. The gNSGA problem is NP-hard even when p = 1 and Δ = 5.
Recall that Igarashi et al. [14] contemplated whether gNSGA is ﬁxed-parameter
tractable (FPT) with respect to p. We show that even if p = 1, the problem
is already NP-hard, and in fact it remains NP-hard even on graphs where the
maximum degree Δ is as small as 5! In particular, we derive that gNSGA is
para-NP-hard when the parameter is p + Δ. That is, Theorem 1 implies that we
do not expect to have an FPT algorithm, or even merely an XP algorithm, on
general graphs with respect to both p and Δ together. Indeed, the existence of
an XP algorithm, that is, an algorithm with running time nf(p,Δ), where n = |N|
and f is any function depending only on p and Δ, would contradict Theorem 1.
FPT Algorithm on General Graphs: In light of Theorem 1, we consider an
additional parameter t—the maximum size of any group that can form a feasible
coalition. Having this parameter at hand, we are able to design an FPT algorithm
that handles general graphs. Before we state our theorem formally, note that t is
a natural choice for a parameter. Indeed, sport teams/matches usually involve
only few players, a taxi or a table have only limited space, and certain tasks are
clearly suitable, or best performed, when only few people undertake them. We
remark that Δ can also often be expected to be small. For example, when most
people in an event (say, a donation evening) do not know each other well, this
would indeed be the case when planning a seating arrangement. In addition,
when new participants sign-up to organized sport activities, they might only
know those friends that are also interested in those exact activities. Moreover,
when a company operating across diﬀerent countries would like to undertake
some task, while employees generally know only those other employees with
whom they share the same ﬂoor, we again arrive at a situation where Δ is small.
Theorem 2. gNSGA on general graphs is solvable in time O((Δp)O(tp)·n log n).
The proof of Theorem 2 uses the idea of an n-p⋆-q⋆-lopsided-universal family,
introduced in [7], to “separate” agents that are assigned non-void activities from
3 For standard deﬁnitions concerning parameterized complexity, see [3].

110
S. Gupta et al.
their neighbors. Once this is done, a non-trivial dynamic programming algorithm
is developed to test whether there exists an fNsa.
FPT Algorithm for Graphs of Bounded Treewidth: Igarashi [14] designed
FPT algorithms for gNSGA on paths, stars and graphs whose connected com-
ponents are restricted to have constant size. In a more recent article, Igarashi
et al. [12] designed an FPT algorithm with running time O(pp · (n + p)O(1)) for
gNSGA on acyclic graphs (i.e. forests). We generalize this result to a substan-
tially wider class of graphs that includes all the above classes of graphs, namely,
graphs of bounded treewidth. This class includes graphs that have an unbounded
number of cycles, and in fact it even generalizes the class of all graphs whose
feedback vertex set number is small. Formally, we derive the following theorem.
Theorem 3. The gNSGA problem on graphs treewidth tw is solvable in time
O(4p · (n + p)O(tw)).
Notably, our algorithm solves gNSGA on trees (where tw = 1) in time O(4p ·
(n+p)O(1)), that is, signiﬁcantly faster than the specialized algorithm by Igarashi
et al. [12]. In fact, its running time also matches the running time of the even
more specialized algorithm by Igarashi et al. [12] for paths.
Related Works. Papers [12,14] that speciﬁcally solve gNSGA on restricted
classes of graphs were discussed in some details earlier. Here, we give a brief
(non-comprehensive) survey of a few results related to problems of ﬂavor similar
to that of gGASP, so as to understand the well established roots of this gNSGA.
The literature on graph based cooperative games, to which gGASP is a new
addition, can be traced back to Myerson’s seminal paper [16] which introduced
the graph theoretic model of cooperation, where vertices represent agents par-
ticipating in the game and edges between pairs of vertices represent cooperative
relationship between agents corresponding to the vertices. In cooperative games,
there are two basic notions of stability, one based on the individual and the other
on the group. The latter notion corresponds to what is known as core stability.
Hedonic games [1,8,9] form a domain similar to that of GASP where agents have
preferences over other agents, but also groups of agents that include themselves.
The primary challenges of designing eﬃcient algorithms in hedonic games is that
the space requirement for just storing/representing the preference proﬁle is (in
general) exponential in the number of agents in the game. Consequently, people
have studied the problem in sparse graphs such as trees, or those with a small
number of connected components, Igarashi and Elkind’s [13] is a recent work in
this direction. Papers such as [2,6,13] explore stability in diﬀerent kinds of coop-
erative games; but the central ﬁndings of these papers are in stark contrast with
that of [14] showing that restricted graph classes, such as paths, trees, stars etc.,
are amenable for algorithms that eﬃciently compute stable solutions. Building
on the work of [14], Igarashi et al. [12] studied the parameterized complexity
of Nash stability, core stability, as well as individual stability in gGASP with
respect to parameters such as the number of activities and the number of play-
ers. Finally, we conclude our discussion by pointing the reader to a vast array of

Group Activity Selection on Graphs: Parameterized Analysis
111
literature on coalition formation games. Due to lack of space, we refer the reader
to [15, pg. 222–223, 330] for an extensive discussion on the topic.
Preliminaries. For standard graph theoretic notation we refer to [5]. For a
detailed deﬁnition of (nice) tree decomposition, see [3, pg. 161].
2
Hardness
In this section, we show that gNSGA is NP-complete even when there is only one
activity and the maximum degree of the underlying graph is at most 4. Towards
this, we give a polynomial time many-to-one reduction from the Steiner Tree⋆
problem (deﬁned below) on graphs of maximum degree at most 4 [11] to gNSGA.
Steiner Tree⋆
Input: An undirected graph G⋆on n vertices, K ⊆V (G⋆) (called terminals)
and a positive integer ℓ.
Question: Does there exist H ⊆V (G⋆) such that G⋆[H] is a tree, K ⊆H
and |H| = ℓ?
Steiner Tree⋆diﬀers from the usual Steiner Tree problem as follows: here
we demand the size of |H| to be exactly equal to ℓrather than at most ℓ. A
simple reduction from Steiner Tree (on graphs of maximum degree 4) that
maps an instance to itself shows that Steiner Tree⋆(on graphs of maximum
degree 4) is NP-complete as well. We ﬁrst give our construction.
Construction. We ﬁrst show how to construct the underlying graph G from G⋆.
To this end, we take a copy of G⋆and make the following additions to construct
G. For every w ∈K, we construct a path Pw on n + 1 dummy vertices and add
an edge between some end-point of the path and the terminal vertex w. Now,
for each vertex u ∈V (G⋆) \ K, we add a new vertex u′ and connect u′ to u. The
vertex u′ will act as a stalker for the vertex u. A vertex x ∈V (G) is called (i)
a terminal vertex if x ∈K, (ii) a non-terminal vertex if x ∈V ⋆= V (G⋆) \ K,
(iii) a dummy vertex if x ∈Dummy = ∪w∈KPw, and (iv) a stalker vertex if
x ∈Stalker = {u′ | u ∈V ⋆}. This completes the construction of G.
Having constructed G, the instance I of gNSGA is deﬁned as follows:
– The set of agents is N = V (G) and the set of activities is A = {a}. That is,
we only have one activity (in addition to the void activity a∅).
– Now we deﬁne the preference proﬁles (⪰v)v∈N of the agents. Let |K| = t and
γ = (n + 2)t + (ℓ−t). For an agent v ∈N, the preference proﬁle is
⪰v:=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
⟨(a, γ), (a∅, 1)⟩
if v ∈K
⟨(a, γ), (a, 1), (a∅, 1)⟩
if v ∈V ⋆
⟨(a, γ), (a, γ + 1), (a∅, 1)⟩
if v ∈Dummy
⟨(a, 2), (a∅, 1)⟩
if v ∈Stalker

112
S. Gupta et al.
Fig. 1. The construction of the underlying graph G.
This completes the description of the instance of gNSGA.
Correctness. For correctness we show the following equivalence.
Lemma 1. (G⋆, K, ℓ) is a Yes-instance of Steiner Tree⋆if and only if I is
a Yes-instance of gNSGA.
Proof. For the forward direction, assume that there exists H ⊆V (G⋆) such that
G⋆[H] is connected, K ⊆H and |H| = ℓ. Using the solution graph H, we deﬁne
an assignment π : N →A as follows. For an agent v ∈N,
π(v) :=

a
if v ∈(H ∪Dummy)
a∅
otherwise
Next, we prove that π is an fNsa; with that the forward direction is proved.
Claim. (⋆)4 π is an fNsa.
Now we will show the reverse direction of the proof. Let π : N →A be an
fNsa. We ﬁrst derive properties about π.
Property 1: For every vertex v′ ∈Stalker, π(v′) = a∅. For a contradiction
assume that π(v′) = a. Since v′ would not join the activity a alone, the vertex
v in V ⋆joins the activity a. That is, π(v) = a. But (a∅, 1) ≻v (a, 2). Hence, v
wants to deviate to the void activity a∅, a contradiction to the stability of π.
Property 2: πa ̸= ∅. For a contradiction assume that no vertex is assigned
activity a. Let v ∈V ⋆,5 then (a, 1) ≻v (a∅, 1). That is, v has an NS-deviation
to the activity a, again contradicting the stability of π.
Property 3: If there exists a vertex v ∈V ⋆such that v ∈πa, then |πa| > 1. For
a contradiction assume that |πa| = 1 (by Property 2 we know that πa ̸= ∅).
Then, the stalker vertex v′ has an NS-deviation to the activity a as (a, 2) ≻w′
(a∅, 1).
4 Results labeled with ⋆can be found in the full version.
5 Note that, wlog, we can assume V ⋆is non empty, otherwise solving Steiner Tree⋆
instance reduces to checking if G⋆is connected.

Group Activity Selection on Graphs: Parameterized Analysis
113
Property 4: |πa| ∈{γ, γ + 1}. By Properties 1 and 2, we know that there is a
vertex v ∈V ⋆∪K ∪Dummy such that v ∈πa. Thus, if there exists a vertex
v ∈(K ∪Dummy) ∩πa, then since (a, γ) ≻v (a∅, 1) or (a, γ + 1) ≻v (a∅, 1)
(if v ∈Dummy) we have that |πa| ∈{γ, γ + 1}. Furthermore, by Property 3,
we know that if v ∈V ⋆∩πa then |πa| > 1. However, (a, γ) ≻v (a∅, 1), thus
|πa| ∈{γ, γ + 1}.
Property 5: For every v ∈K, π(v) = a and |πa| = γ. For a contradiction
assume that there exists a vertex v ∈K such that π(v) ̸= a. Then, since
G[πa] is connected, we have that all the dummy vertices in the path Pv is
not in πa. This implies that |πa| ≤(|V ⋆| + |K| −1 + (|K| −1)(n + 1) < γ.
This contradicts Property 5. Finally, since a vertex v ∈K ∩πa (in fact every
vertex of K is in πa) and (a, γ) ≻v (a∅, 1), we have that |πa| = γ.
Property 6: For every v ∈Dummy, π(v) = a. Indeed, otherwise consider a
vertex v ∈Dummy such that it has a neighbor in πa (the fact that K ⊆πa
ensures an existence of such a vertex). Then the fact that (a, γ +1) ≻v (a∅, 1)
together with Property 5 imply that π is not stable, a contradiction.
Now we are ready to show the reverse direction of the proof. Let W = πa ∩
(V ⋆∪K). Since G[πa] is connected, we have that G[W] is connected. The last
assertion follows from the fact that if we take a spanning tree L of G[πa], then
the paths hanging from the vertices of K can be thought of as “long leaves” and
by removing leaves we do not disconnect a tree. Furthermore, since G[V ⋆∪K]
is same as G⋆, we have that G⋆[W] is connected and contains all the terminals.
Finally, for our proof the only thing that remains to show is that |W| = ℓ. This
follows from the fact that |πa| = γ and while constructing W we have removed
exactly (n + 1)t dummy vertices. This concludes the proof.
♦
Notice that G has maximum degree bounded by 5. We started with a graph G⋆
of maximum degree 4 and we have not added more than one new neighbor to
any vertex. So the degree of any vertex in G is at most 5. Thus, our construction
and Lemma 1 imply the proof of Theorem 1.
Our proof of Theorem 1 is robust in the sense that one can start with a family
of graphs on which the Steiner Tree⋆problem is NP-complete and then do the
reduction in a way that we remain inside the family of graphs we started with.
For example, it is known that Steiner Tree⋆remains NP-complete on planar
graphs of maximum degree 4 [10], and thus our reduction would imply that
gNSGA is NP-complete even when there is only one activity and the underlying
network is a planar graph of max degree 5.
3
An FPT Algorithm for General Graphs
In the last section we established that gNSGA remains NP-complete even when
the number of activities is one and the maximum degree of the underlying net-
work is at most 5. As discussed in the introduction this immediately implies that
we can not even have an XP algorithm parameterized by p and the maximum
degree Δ of the underlying network. However, with an additional parameter t

114
S. Gupta et al.
– the maximum size of any group that can form in an fNsa—we are able to
design an FPT algorithm. We use this notation, let f : A →B be some function.
Given A′ ⊆A, the notation f(A′) = b indicates that for all a ∈A′, it holds that
f(a) = b.
Let I = (N, (⪰v)v∈N, A, G) be an instance of gNSGA where the maximum
degree of G is at most Δ. Our algorithm has two phases: (a) Separation Phase and
(b) Validation Phase. We ﬁrst outline the phases. We start with the Separation
Phase.
Let π : N →A be a hypothetical fNsa for the given input I. For our algorithm
we would like to have a function f from N = V (G) to {1, 2} with the following
property:
(P1) Let N ′ ⊆N be the set of agents who are assigned a non-void activity
(that is an activity in A⋆) by π. Then, f labels 1 to every agent in N ′ and
labels 2 to all the agents in NG(N ′) (neighbors of N ′ in G that are not in
N ′).
A function f that satisﬁes the property (P1) with respect to a fNsa π is called
nice with respect to π. Furthermore, a function f from V (G) to {1, 2} is called
nice if f satisﬁes the property (P1) for some fNsa π′ for I.
In the validation phase, given a nice function f, we construct a fNsa (if it
exists), π : N →A, such that all the agents that have been labeled 2 are assigned
void activity a∅. In other words, the only agents that get assigned an activity
from A⋆are those which are labeled 1 by f. It is possible that π assigns a∅to
some agent that have been labeled 1 by f. To construct an assignment π, if it
exists, we employ a dynamic programming procedure. Now we describe both the
phases in details.
Separation Phase. We ﬁrst show the existence of a small sized family of func-
tions such that given an instance of gNSGA on n agents such that it has a fNsa,
then there exists a function that is nice with respect to this. Towards this we
ﬁrst introduce the notion of n-p⋆-q⋆-lopsided-universal family. Given a universe
U and an integer ℓby
U
ℓ

we denote all the ℓ-sized subsets of U. We say that
a family F of sets over a universe U of size n is an n-p⋆-q⋆-lopsided-universal
family if for every A ∈
 U
p⋆

and B ∈
U\A
q⋆

there is an F ∈F such that A ⊆F
and B ∩F = ∅. An alternative deﬁnition that is easily seen to be equivalent is
that F is n-p⋆-q⋆-lopsided-universal family if for every subset A ∈

U
p⋆+q⋆

and
every subset A′ ∈
 A
p⋆

, there is an F ∈F such that F ∩A = A′.
Lemma 2 [7]. There is an algorithm that given n, p⋆and q⋆constructs an n-
p⋆-q⋆-lopsided-universal family F of cardinality
p⋆+q⋆
p⋆

· 2o(p⋆+q⋆) · log n in time
O(
p⋆+q⋆
p⋆

· 2o(p⋆+q⋆) · n log n).
We now show that there exists a family of functions, H(I), from N to {1, 2}
such that if I has a fNsa, π, then there exists a function f ∈H(I) such that
f is nice with respect to π. We call the family of functions H(I), a nice family

Group Activity Selection on Graphs: Parameterized Analysis
115
C1
C2
C5
C4
C3
Fig. 2. Depiction of how a nice function f assigns {1, 2} to the vertices of G. Orange
colored parts are assigned 1 by f and the white enclosed parts are assigned 2 by f.
C1, C2, . . . , C5 are the components of G[f −1(1)]. For i ∈[5], the concentric circle outside
Ci is N(Ci). It is guaranteed that f assigns 2 to those vertices.
with respect to I. Let the vertex set N = V (G) of the graph G be denoted by
{v1, . . . , vn}. We identify the vertex vi with an integer i and thus we can view
the vertex set as [n]. To construct the function f, we use Lemma 2. We apply
Lemma 2 with universe U = {1, 2, . . . , n}, p⋆= tp and q⋆= Δtp = Δp⋆and
obtain a n-p⋆-q⋆-lopsided-universal family F of size
p⋆+q⋆
p⋆

· 2o(p⋆+q⋆) · log n in
time O(
p⋆+q⋆
p⋆

·2o(p⋆+q⋆)·n log n). Given F, we deﬁne H(I) as follows. For every
set X ∈F, fX is deﬁned as follows: fX(x) =

1
if x ∈X
2
otherwise.
Thus, H(I) := {fX | X ∈F}. Now we show that H(I) is a nice family.
Suppose I has a fNsa π. Let N ′ be the set of agents that are assigned non-void
activity by π and W = NG(N ′). Since the size of any group is upper bounded by
t we have that |N ′| ≤tp and since the maximum degree of G is upper bounded by
Δ we have that |W| ≤Δtp. Now by the property of n-p⋆-q⋆-lopsided-universal
family F, we know that there exists a set X ∈F such that N ′ ⊆X and
W ∩X = ∅. By construction the function fX is nice with respect to π. This
brings us to the following lemma.
Lemma 3. Let I be an instance of gNSGA. Then, in time O(
p⋆+q⋆
p⋆

·2o(p⋆+q⋆)·
n log n) we can construct a nice family H(I) of size
p⋆+q⋆
p⋆

· 2o(p⋆+q⋆) · log n.
Here, p⋆= tp and q⋆= Δp⋆.
Validation Phase. Now, we give an algorithm that given a function f : N →
{1, 2} tests whether f is a nice function. In other words either it correctly con-
cludes that f is not a nice function or outputs a fNsa, π : N →A, such that f
is nice with respect to π.
Lemma 4 (⋆). Let I be an instance of gNSGA and f : N →{1, 2} be a func-
tion. Then in time, O(n4p(p+1)tp), we can test whether or not f is nice. More-
over, if f is nice, then in the same time we can output an fNsa, witness to the
property that f is nice.

116
S. Gupta et al.
Using Lemma 4 we can complete the proof of Theorem 2.
4
FPT Algorithm for Networks of Bounded Treewidth
In this section, we prove Theorem 3. First, recall in time 2tw · n we can obtain
a nice tree decomposition of the network G whose width is η = O(tw). In
what follows, we let (T, β) denote such a decomposition. For v ∈V (T), we say
that β(v) is the bag of v, and γ(v) denotes the union of the bags of v and
the descendants of v in T. We apply the method of dynamic programming as
described in the following subsections.
The DP Table. Let us begin by describing our DP table, which we denote
by M. Each entry of this table is of the form [x, B, 	B, fact, ftot, fcur, P] for any
choice of arguments as follows.
– A node x ∈V (T), which indicates that the partial solutions corresponding
to the current entry would only assign activities only to those vertices that
belong to γ(x).
– A subset of activities B ⊆A such that a∅∈B, which indicates that only
activities from B can be assigned to those vertices that belong to γ(x). Let
us denote B⋆= B \ {a∅}.
– A subset of activities 	B ⊆B such that a∅∈	B, which indicates that each
activity in 	B⋆= 	B \ {a∅} has been assigned to at least one vertex in γ(x).
– A function fact : β(x) →	B, which speciﬁes exactly how to assign activities
to those vertices that belong to β(x).
– A function ftot : β(x) →[n], which speciﬁes exactly, for every vertex v in
β(x), how many vertices in total (i.e. in V (G)) should participate in the
same activity as v. Here, the void activity is an exception as for any vertex
v assigned to the void activity, we would demand that ftot(v) is set to 1,
irrespective of how many vertices participate in this activity.
– A function fcur : β(x) →[n], which speciﬁes exactly, for every vertex v in
β(x), how many vertices have so far (i.e. in γ(x)) have been determined to
participate in the same activity as v. Here, the void activity is an exception
in the same sense as the one speciﬁed for ftot.
– A partition P of β(x), which is interpreted as follows. For the sake of clarity,
we let fP : β(x) →2β(x) denote the function that, for every vertex v in β(x),
assigns the set in P to which v belongs. Then, the information captured by P
is the speciﬁcation that for every pair of (distinct) vertices in β(x), u and v,
satisfying fP (u) = fP (v), u and v participate in the same non-void activity,
and there exists a path in G[γ(x)] between u and v such that all of the vertices
of this path participate in the same activity as u and v.
We would say that an entry M[x, B, 	B, fact, ftot, fcur, P] is legal if the follow-
ing conditions are satisﬁed.

Group Activity Selection on Graphs: Parameterized Analysis
117
1. For all u, v ∈β(x) such that fact(u) = fact(v), it holds that ftot(u) = ftot(v)
and fcur(u) = fcur(v).
2. For all v ∈β(x), it holds that fcur(v) ≤ftot(v).
3. For all (distinct) u, v ∈β(x) such that fP (u) = fP (v), it holds that fact(u) =
fact(v) ̸= a∅.
4. For all u, v ∈β(x) such that fcur(u) = ftot(u) and fact(u) = fact(v), it holds
that fP (u) = fP (v).
5. For all v ∈β(x) such that fact(v) = a∅, it holds that ftot(v) = 1.
6. For all v ∈β(x) such that fact(v) ̸= a∅, it holds that (fact(v), ftot(v)) ≻v
(a∅, 1).
7. For all v ∈β(x), it holds that (fact(v), ftot(v)) ≻v (a, 1) for every a ∈A \ B.
8. For all v ∈β(x), there does not exist u ∈NG[β(x)](v) such that fact(v) ̸=
fact(u), fact(u) ̸= a∅and (fact(u), f π
tot(u) + 1) ≻v (π(v), f π
tot(v)).
Formally, we would say that the table M has been computed correctly if each
of its entries [x, B, 	B, fact, ftot, fcur, P] stores either 0 or 1, and it stores 1 if
and only if this entry is legal and there exists an assignment π : γ(x) →B
that satisﬁes the following conditions. Here, for all v ∈γ(x), we would deﬁne
f π
tot(v) = |πv| if πv ∩β(x) = ∅, and f π
tot(v) = ftot(u) for any u ∈πv ∩β(x)
otherwise. Since the entry is legal and in particular satisﬁes Condition 4, this
notation is well deﬁned.
I. For all a ∈B⋆, there exists v ∈γ(x) such that π(v) = a.
II. For all v ∈β(x), it holds that π(v) = fact(v).
III. For all v ∈β(x), it holds that |πv| = fcur(v).
IV. For all v ∈γ(x) such that π(v) ̸= a∅, it holds that (π(v), f π
tot(v)) ≻v (a∅, 1).
V. For all v ∈γ(x), it holds that (π(v), f π
tot(v)) ⪰v (a, 1) for every a ∈A \ B.
VI. For all v ∈γ(x), there does not exist u ∈NG[γ(x)](v) such that fact(v) ̸=
fact(u), fact(u) ̸= a∅and (fact(u), f π
tot(u) + 1) ≻v (π(v), f π
tot(v)).
VII. For all u, v ∈β(x) such that fP (u) = fP (v), it holds that there exists a
path in G[πv] between v and u.
VIII. For all v ∈γ(x) such that πv ∩β(x) = ∅, it holds that πv is a feasible
coalition.
We call an assignment as speciﬁed above a witness for [x, B, 	B, fact, ftot, fcur, P].
The details about how to ﬁll the table M and its correctness are in the full version.
References
1. Aziz, H., Savani, R., Moulin, H.: Hedonic Games. In: Handbook of Computational
Social Choice, pp. 356–376. Cambridge University Press (2016). Chap. 15
2. Chalkiadakis, G., Greco, G., Markakis, E.: Characteristic function games with
restricted agent interactions: core-stability and coalition structures. Artif. Intell.
232, 76–113 (2016)
3. Cygan, M., Fomin, F.V., Kowalik, L., Lokshtanov, D., Marx, D., Pilipczuk, M.,
Pilipczuk, M., Saurabh, S.: Parameterized Algorithms. Springer, Cham (2015)

118
S. Gupta et al.
4. Darmann, A., Elkind, E., Kurz, S., Lang, J., Schauer, J., Woeginger, G.: Group
activity selection problem. In: Goldberg, P.W. (ed.) WINE 2012. LNCS, vol. 7695,
pp. 156–169. Springer, Heidelberg (2012). doi:10.1007/978-3-642-35311-6 12
5. Diestel, R.: Graph Theory. Springer, Heidelberg (2000)
6. Elkind, E.: Coalitional games on sparse social networks. In: Liu, T.-Y., Qi, Q.,
Ye, Y. (eds.) WINE 2014. LNCS, vol. 8877, pp. 308–321. Springer, Cham (2014).
doi:10.1007/978-3-319-13129-0 25
7. Fomin, F.V., Lokshtanov, D., Panolan, F., Saurabh, S.: Eﬃcient computation of
representative families with applications in parameterized and exact algorithms. J.
ACM 63(4), 29:1–29:60 (2016)
8. Gairing, M., Savani, R.: Computing stable outcomes in hedonic games. In: Kon-
togiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.) SAGT 2010. LNCS, vol. 6386,
pp. 174–185. Springer, Heidelberg (2010). doi:10.1007/978-3-642-16170-4 16
9. Gairing, M., Savani, R.: Computing stable outcomes in hedonic games with voting-
based deviations. In: AAMAS 2011, pp. 559–566 (2011)
10. Garey, M.R., Johnson, D.S.: The rectilinear steiner tree problem is NP-complete.
SIAM J. Appl. Math. 32, 826–834 (1977)
11. Garey, M.R., Johnson, D.S.: Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman, New York (1979)
12. Igarashi, A., Bredereck, R., Elkind, E.: On parameterized complexity of group
activity selection problems on social networks. In: AAMAS 2017 (2017)
13. Igarashi, A., Elkind, E.: Hedonic games with graph-restricted communication. In:
AAMAS 2016, pp. 242–250 (2016)
14. Igarashi, A., Elkind, E., Peters, D.: Group activity selection on social network. In:
AAAI 2017, pp. 565–571 (2017)
15. Manlove, D.F.: Algorithmics of Matching Under Preferences, vol. 2. WorldScien-
tiﬁc, Singapore (2013)
16. Myerson, R.B.: Graphs and cooperation games. Math. Oper. Res. 2, 225–229
(1977)

The Real Computational Complexity of Minmax
Value and Equilibrium Reﬁnements
in Multi-player Games
Kristoﬀer Arnsfelt Hansen(B)
Aarhus University, Aarhus, Denmark
arnsfelt@cs.au.dk
Abstract. We show that for several solution concepts for ﬁnite n-player
games, where n ≥3, the task of simply verifying its conditions is compu-
tationally equivalent to the decision problem of the existential theory of
the reals. This holds for trembling hand perfect equilibrium, proper equi-
librium, and CURB sets in strategic form games and for (the strategy
part of) sequential equilibrium, trembling hand perfect equilibrium, and
quasi-perfect equilibrium in extensive form games. For obtaining these
results we ﬁrst show that the decision problem for the minmax value in
n-player games, where n ≥3, is also equivalent to the decision problem
for the existential theory of the reals.
Our results thus improve previous results of NP-hardness as well as
Sqrt-Sum-hardness of the decision problems to completeness for ∃R, the
complexity class corresponding to the decision problem of the existential
theory of the reals. As a byproduct we also obtain a simpler proof of a
result by Schaefer and ˇStefankoviˇc giving ∃R-completeness for the prob-
lem of deciding existence of a probability constrained Nash equilibrium.
1
Introduction
From a computational point of view, ﬁnite games with three or more players
present unique challenges compared to ﬁnite 2-player games. This is already
indicated by the example due to Nash of a 3-player game with no rational Nash
equilibrium [25], but even more strikingly so by constructions of Bubelis [6] and
Datta [14]. More precisely, Bubelis constructs a 3-player game with a unique
Nash equilibrium giving as equilibrium payoﬀan arbitrary algebraic number to
some player, and Datta shows that any real algebraic variety is isomorphic to
the set of fully mixed Nash equilibria in a 3-player game.
The problem of computing a Nash equilibrium in ﬁnite strategic form
games was characterized in seminal work by Daskalakis et al. [13] and Chen
and Deng [10] as PPAD-complete for 2-player games and by Etessami and
Yannakakis [16] as FIXP-complete for n-player games, when n ≥3.
While a Nash equilibrium is guaranteed to exist, one might be interested in
Nash equilibria satisfying certain properties, e.g. having at least a certain social
welfare. The corresponding decision problems were characterized as NP-complete
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 119–130, 2017.
DOI: 10.1007/978-3-319-66700-3 10

120
K.A. Hansen
for 2-player games by Gilboa and Zemel [19] and by Conitzer and Sandholm [11].
For the analogous problems in games with three or more players a precise charac-
terization was only obtained very recently. Schaefer and ˇStefankoviˇc [28] obtained
the ﬁrst such result giving ∃R-completeness for deciding the existence of a prob-
ability constrained Nash equilibrium. Subsequent work by Garg et al. [17] and
Bil`o and Mavronicolas [3] extended this to ∃R-completeness for all the analo-
gous decision problems studied for two players. Thus these problems are not only
to be considered computationally intractable, as implied by the corresponding
results for 2-player games, but are in fact computationally equivalent to each
other. Prior to obtaining ∃R-completeness this was an open problem.
In this paper we are interested in several standard reﬁnements of Nash equi-
librium, all guaranteed to exist. We will not be concerned with the task of
actually computing these, but rather with the task of verifying their conditions.
Note that verifying the conditions of a Nash equilibrium is computationally
a trivial task. In contrast to this Hansen et al. [22] showed both NP-hardness
and Sqrt-Sum-hardness for verifying the conditions of the standard reﬁnements
we consider here in n-player games, where n ≥3. Here NP-hardness indicates
that each of the veriﬁcation problems are computationally intractable, whereas
Sqrt-Sum-hardness indicate that the problems might not even be contained in
NP. Here we show that the problems are ∃R-complete, thus computationally
equivalent to each other and to the decision problem for the existential theory
of the reals. The complexity of the corresponding problems for 2-player games
is not completely settled, but the results that exist so far give polynomial time
algorithms [2,18,31].
Like the earlier NP-hardness and Sqrt-Sum-hardness results, we prove ∃R-
hardness by reduction from the decision problem for computing the minmax
value in 3-player games. Thus we ﬁrst establish ∃R-completeness for this prob-
lem. As a byproduct we are able to obtain a simpler and more direct proof
of ∃R-completeness of deciding the existence of a probability constrained Nash
equilibrium compared to the original proof of Schaefer and ˇStefankoviˇc.
1.1
The Existential Theory of the Reals
The decision problem for the existential theory of the reals, ETR, is that of
deciding validity of sentences of the form ∃x1, . . . , xn ∈R : φ(x1, . . . , xn), where
φ is a quantiﬁer free formula with real polynomial inequalities and equalities as
atoms. It is easy to see that ETR is NP-hard (cf. [8]); on the other hand, the
decision procedure by Canny [9] shows that ETR belongs to PSPACE.
The view of the decision problem of the existential theory of the reals as a
complexity class existed only implicitly in the literature, e.g. [8,30], until being
studied more extensively under the name NPR by B¨urgisser and Cucker [7] and
then under the name ∃R by Schaefer and ˇStefankoviˇc [26,28]. In this paper we
shall adopt the naming ∃R. We shall also denote co∃R by ∀R.
B¨urgisser and Cucker deﬁned the class as the constant-free Boolean part
BP0(NPR) of the analogue class NPR to NP in the Blum-Shub-Smale model of
computation. They showed a large number of problems to be complete for ∃R

The Real Complexity of Minmax Value and Equilibrium Reﬁnements
121
or ∀R. Interestingly, the corresponding problems with real-valued inputs are not
known to be NPR-complete, but rather complete for classes derived from NPR
with additional “exotic” quantiﬁers. Schaefer and ˇStefankoviˇc simply deﬁned the
class ∃R as the closure of ETR under polynomial time many-one reductions, and
proved in particular ∃R-completeness for deciding the existence of a probability
constrained Nash equilibrium in 3-player games.
2
∃R-Completeness of Minmax Value in 3-Player Games
It is well-known that the problem of deciding whether a system of quadratic
equations over the reals has a solution is complete for ∃R. By results of
Grigor’Ev and Vorobjov [20,32], whenever a polynomial system has a solution,
it has a solution whose coordinates are bounded in magnitude by a doubly-
exponential function in the size of the encoding of the system. Combining this
with repeated squaring, Schaefer [27] noted that deciding whether a system of
quadratic equations has a solution remains ∃R-hard even with a promise that a
possible solution can be assumed to be contained in a constant bounded region.
Proposition 1 (Schaefer).
It is ∃R-hard to decide if a system of quadratic
equations has a solution under the promise that either the system has no solutions
or a solution exists in the unit ball B(0, 1).
Starting from this result we will show ∃R hardness for computing the minmax
value in 3-player games in a few steps. First we will convert the quadratic system
into a homogeneous bilinear system over the standard simplex. Then each poly-
nomial of the resulting system is translated into a pair of strategies for Player 1,
and a minmax strategy proﬁle for Player 2 and Player 3 obtaining minmax value
0 will correspond to a solution to system of equations. We denote the standard
n-simplex {x ∈Rn+1 | x ≥0 ∧n
i=0 xi = 1} by Δn and the standard corner
n-simplex {x ∈Rn | x ≥0 ∧n
i=1 xi ≤1} by Δn
c .
Proposition 2. It is ∃R-complete to decide if a system of homogeneous bilinear
equations Qk(x, y) = 0 has a solution x, y ∈Δn. It remains ∃R-hard under the
promise that either the system has no such solution or a solution (x, y) exists
such that x = y and where x and y belong to the relative interior of Δn.
Proof. Containment in ∃R is straightforward. We will show hardness by reduc-
tion from the problem of deciding whether a system of quadratic equations
has a solution. Let n > 1 and let p1(x1, . . . , xn), . . . , pm(x1, . . . , xn) be a sys-
tem of quadratic equations. By Proposition 1 we will assume that the sys-
tem either has no solution or has a solution in the unit ball Bn(0, 1). Deﬁne
new quadratic polynomials q1(y1, . . . , yn), . . . , qm(y1, . . . , yn) by qk(y1, . . . , yn) =
pk(2ny1 −1, . . . , 2nyn −1), for k = 1, . . . , m. Suppose x ∈B(0, 1), and deﬁne
yi = (xi + 1)/2n, all i. It follows that yi > 0 for all i and furthermore by the
triangle inequality and the Cauchy–Schwarz inequality we have
∥y∥1 ≤1
2n∥x∥1 + 1
2 ≤1
2n
√n∥x∥2 + 1
2 < 1.

122
K.A. Hansen
It follows that y belongs to the interior of the standard corner simplex Δn
c , and
qk(y) = 0 if and only if pk(x) = 0.
Write qk(y1, . . . , yn) = 
i≤j a(k)
ij yiyj + 
i b(k)
i
yi + c(k) and deﬁne the homo-
geneous bilinear form Qk(x0, x1, . . . , xn, y0, y1, . . . , yn) by
Qk(x, y) =

1≤i≤j
a(k)
ij xiyj +
n

i=1
n

j=0
b(k)
i
xiyj +
n

i=0
n

j=0
c(k)xiyj.
Additionally, for j = 1, . . . , n, deﬁne Qm+j(x, y) = n
i=0 xiyj −xjyi. Essentially
we just have introduced the slack variable y0 = 1 −n
i=1 yi, replaced quadratic
terms yiyj by bilinear quadratic terms xiyj, homogenized using the equality
n
i=0 yi = 1, and ﬁnally ensured that x = y. If (y1, . . . , yn) belongs to the interior
of Δn
c , then extending with the slack variable y0 we have that (y0, . . . , yn) belongs
to the relative interior of Δn, and furthermore Qk(y0, . . . , yn, y0, . . . , yn) = 0
whenever qk(y1, . . . , yn) = 0 for all k = 1, . . . , m+n. Conversely, if x, y ∈Δn and
Qk(x, y) = 0 for all k = 1, . . . , m + n we must have xj = yj using Qm+j(x, y) =
0 for j = 1, . . . , n. Then removing the slack variable from y again we have
qk(y1, . . . , yn) = 0 for all k = 1, . . . , m, using Qk(y, y) = 0 for k = 1, . . . , m.
⊓⊔
Theorem 3. It is ∃R-complete to decide for a given 3-player game in strategic
form if the minmax value for Player 1 is at most 0. It remains ∃R-hard under
the promise that either the minmax value for Player 1 is strictly greater than 0
or the minmax value for Player 1 is equal to 0 and Player 2 and Player 3 can
enforce this using a fully mixed strategy proﬁle (x, y), where x = y, and against
which all strategies of Player 1 yield payoﬀ0.
Proof. Containment in ∃R is straightforward. Namely, the question to decide is
existence of x ∈Δn2−1 and y ∈Δn3−1 such that 
i,j u1(k, i, j)xiyj ≤0 for all k,
where u1 is the payoﬀfunction of Player 1. We will show hardness by reduction
from the promise problem given by Proposition 2. Let Q1(x, y), . . . , Qm(x, y)
be homogeneous bilinear polynomials in variables x = (x0, . . . , xn) and y =
(y0, . . . , yn). We form a 3-player game where Player 2 and Player 3 each have
n + 1 strategies given by the set {0, . . . , n} and Player 1 has 2m strategies given
by the set {1, . . . , 2m}. Let Qk(x, y) = n
i=0
n
j=0 a(k)
ij xiyj for k = 1, . . . , m. The
payoﬀto Player 1 is simply given by u1(2k −1, i, j) = −u1(2k, i, j) = a(k)
ij . It
follows that if (x, y) is a strategy proﬁle for Player 2 and Player 3, or equivalently
x, y ∈Δn, then
E
i∼x,j∼y[u1(2k −1, i, j)] = −
E
i∼x,j∼y[u1(2k, i, j, )] = Qk(x, y).
If (x, y) is a fully mixed strategy proﬁle such that maxk Ei∼x,j∼y[u1(k, i, j)] ≤0
and x = y this means that Qk(x, y) ≤0 and −Qk(x, y) ≤0 for all k, implying
Qk(x, y) = 0 for all k, and x and y belong to the relative interior of Δn, as well
as maxk Ei∼x,j∼y[u1(k, i, j)] = 0. Conversely, if Qk(x, y) = 0 for all k with x and
y being in the relative interior of Δn and x = y, we have that (x, y) is a fully
mixed strategy proﬁle and Ei∼x,j∼y[u1(k, i, j)] = 0 for all k, which in particular
means that maxk Ei∼x,j∼y[u1(k, i, j)] = 0.
⊓⊔

The Real Complexity of Minmax Value and Equilibrium Reﬁnements
123
2.1
∃R-Completeness of Constrained Nash Equilibrium
The decision problem NashInABall is the following: Given a game G in strate-
gic form and a rational r, decide whether G has a Nash equilibrium strategy
proﬁle in which all pure strategies of all players are played with probability at
most r.
Schaefer and ˇStefankoviˇc [28] showed that NashInABall is ∃R-complete for
3-player games. Their hardness proof goes via Brouwer functions and uses the
rather involved transformation of Etessami and Yannakakis [16] of Brouwer func-
tions into 3-player games using an intermediate construction of 10-player games.
Here we give a simpler and more direct proof of ∃R-hardness of NashInABall
as a consequence of Theorem 3.
Theorem 4 (Schaefer and ˇStefankoviˇc). NashInABall ∃R-complete.
Proof. We show ∃R-hardness by reduction from the minmax problem in 3-player
games. Let G be the 3-player game given by Theorem 3 where all strategies of
Player 2 and Player 3 are duplicated. This duplication has the eﬀect that in case
the minmax value of Player 1 is 0, then the minmax strategy proﬁle of Player 2
and Player 3 can be assumed to use only probabilities of magnitude at most 1
2.
We next give each player an additional strategy ⊥. The payoﬀs are as follows.
The payoﬀto all players is 0 when at least one player plays ⊥. For the strategy
combinations where no player plays ⊥, the payoﬀto Player 1 is the same as it
would have been in G, and the payoﬀs to Player 2 and Player 3 is the negative
of the payoﬀto Player 1.
Suppose ﬁrst that the minmax value of Player 1 in G is 0. Let (τ2, τ3) be a
minmax strategy proﬁle for Player 2 and Player 3 in which each strategy is played
with probability at most 1
2, and against which all strategies of Player 1 yield
payoﬀ0. Let τ1 be the uniform strategy proﬁle for Player 1 in G. We claim that
τ = (τ1, τ2, τ3) is a Nash equilibrium. Indeed, since Player 1 plays uniformly, all
players receive payoﬀ0 regardless of the strategies of Player 2 and Player 3, since
in G we have u1(2k −1, i, j) = −u1(2k, i, j, ) for all k = 1, . . . , m. Furthermore,
since Player 2 and Player 3 play the minmax strategy proﬁle (τ2, τ3), all players
receive payoﬀ0 regardless of the strategy of Player 1. In other words, no player
can gain from deviating which means that τ is a Nash equilibrium.
Suppose now that τ = (τ1, τ2, τ3) is a Nash equilibrium proﬁle in which
all strategies of all players is played with probability at most 1
2. In particular
each player plays ⊥with probability at most
1
2. Let τ ′ = (τ ′
1, τ ′
2, τ ′
3) be the
strategy proﬁle where τ ′
j is the conditional distribution obtained from τj given
that Player j does not play the strategy ⊥. We claim that (τ ′
2, τ ′
3) is a minmax
strategy proﬁle in G ensuring minmax value 0 for Player 1. Indeed, since for a
strategy combination where no player plays ⊥, Player 1 receives the negative
payoﬀof Player 2 and Player 3, the strategy proﬁle τ ′, which is played with
nonzero probability, must give all players payoﬀ0, since otherwise either Player 1
or Player 2 and Player 3 would gain from playing ⊥with probability 1. Also,
Player 1 does not have a best reply in G to (τ ′
2, τ ′
3) ensuring payoﬀstrictly greater
than 0, which proves the claim.
⊓⊔

124
K.A. Hansen
3
∃R-Completeness of Equilibrium Reﬁnements
In this section we prove ∃R-completeness for decision problems associated with
several equilibrium reﬁnements. These results directly improve NP-hardness and
Sqrt-Sum-hardness results obtained by Hansen et al. [22], and thereby settles
their complexity exactly. The previous NP-hardness and Sqrt-Sum-hardness
results were proved by reduction from the minmax value problem we considered
in Sect. 2. These reductions do not work directly for our purposes however, since
they actually reduced from a gap version of the minmax value problem, deciding
whether the minmax value is either strictly less or strictly greater than a given
number r. A gap version of the problem is NP-hard even with any inverse poly-
nomial gap [5,21]. Sqrt-Sum-hardness of the gap problem follows directly from
the fact that a sum of square-roots can be compared for equality to a rational in
polynomial time as shown by Bl¨omer [4]1. For ∃R-hardness it is not possible to
ensure such a gap; fortunately we are able to modify the reductions to circum-
vent this, instead relying on our ability to directly assume fully mixed minmax
strategy proﬁles of Player 2 and Player 3.
We very brieﬂy give the deﬁnitions of the solution concepts we consider before
each theorem, and refer to Hansen et al. [22] and references therein for more
details.
In contrast to the hardness results of Hansen, Miltersen and Sørensen we
obtain completeness results. Showing that the problems that arise from Nash
equilibrium reﬁnements are contained in ∃R is not straightforward and hinges
on the fact that one may construct a virtual inﬁnitesimal by means of repeated
squaring. As shown by B¨urgisser and Cucker [7, Theorem 9.2] and Schaefer [27,
Lemma 3.12] (cf. [28, Lemma 4.1]) this extends the power of the existential
theory of the reals with universal quantiﬁcation over an arbitrarily small ε > 0.
Lemma 5. The problem of deciding validity of the sentence
∃ϵ0 > 0 ∀ε ∈(0, ε0) ∃x : ϕ(ε, x)
when given a quantiﬁer-free formula over the reals ϕ(ε, x) belongs to ∃R.
The Nash equilibrium reﬁnements concepts we consider can all be expressed as
being limit points x of a sequence x(ε) of points that can be expressed by an
existentially quantiﬁed formula, which in many of the cases is straightforward
to derive. Then containment in ∃R follows from Lemma 5.
3.1
Trembling Hand Perfect and Proper Equilibrium of Games
in Strategic Form
We ﬁrst consider the concept of trembling hand perfect equilibrium, introduced
by Selten [29]. We state an equivalent deﬁnition due to Myerson [24].
1 This crucial point of the reduction by Hansen et al. was unfortunately omitted in
the paper [22].

The Real Complexity of Minmax Value and Equilibrium Reﬁnements
125
Deﬁnition 6 (Trembling hand perfect equilibrium). Let G be a m-player
game in strategic form. A strategy proﬁle σ for G is an ε-perfect equilibrium
if and only if it is fully mixed and only pure strategies that are best replies get
probability more than ε. A strategy proﬁle σ for G is a trembling hand perfect
equilibrium if and only if it is the limit point of a sequence of ε-perfect equilibria
with ε →0+.
Theorem 7. For any m ≥3 it is ∃R-complete to decide if a given pure strategy
Nash equilibrium of a given m-player game in strategic form is trembling hand
perfect.
Proof. It is not hard to express that a given strategy proﬁle in a m-player game
is a trembling hand perfect equilibrium by a ﬁrst-order formula over the reals.
We reproduce below such a formulation by Etessami et al. [15] for completeness
and illustration. Suppose that player i has ni strategies. A strategy proﬁle is
thus a tuple x ∈Δn1−1 × · · · × Δnm−1 ⊆Rn, n = n1 + · · · + nm. Deﬁne
Ri(x \ k) =

a−i
ui(k; a−i)

j̸=i
xj,aj.
Let EPS-PE(x′, ε) be the quantiﬁer-free formula deﬁned by the conjunction of
the following formulas, together expressing that x′ is an ε-perfect equilibrium.
x′
i,k > 0, for i = 1, . . . , m and k = 1, . . . , ni
x′
i,1 + · · · + x′
i,ni = 1, for i = 1, . . . , m
(Ri(x′ \ k) ≥Ri(x′ \ ℓ)) ∨(x′
i,k ≤ε), for i = 1, . . . , m and k, ℓ= 1, . . . , ni
We can now express that x is a trembling hand perfect equilibrium by
∀ε > 0 ∃x′ : EPS-PE(x′, ε) ∧∥x −x′∥2
2 ≤ε.
Thus deciding whether a given strategy proﬁle x is a trembling hand perfect
equilibrium is contained in ∃R by Lemma 5.
In order to show hardness for ∃R we reduce from the promise minmax prob-
lem given by Theorem 3. Let G be the given 3-player game in strategic form.
We deﬁne a new game G′ from G where each player is given an additional pure
strategy ⊥. The payoﬀs to Player 2 and Player 3 are 0 for all strategy combi-
nations. The payoﬀto Player 1 is 0 when at least one player plays ⊥. For the
strategy combinations where no player plays ⊥the payoﬀto Player 1 is the same
as it would have been in G.
Clearly, in G′ the strategy proﬁle μ = (⊥, ⊥, ⊥) is a Nash equilibrium. We
claim that the minmax value for Player 1 in G is 0 precisely when μ is a trembling
hand perfect equilibrium in G′.
Suppose ﬁrst that the minmax value for Player 1 in G is 0 and let (τ2, τ3) be
a minmax strategy proﬁle of Player 2 and Player 3, which we by assumption can
assume is fully mixed and against which all strategies of Player 1 yield payoﬀ0.

126
K.A. Hansen
Let τ1 be the uniform strategy for Player 1 in G, and let τ = (τ1, τ2, τ3). Deﬁne
for k ≥1
σ(k) = (1 −1
k )μ + 1
k τ.
By assumption and construction σ(k) is a fully mixed strategy proﬁle of G′
converging to μ as k increases. Note that all strategies of all players are best
replies to σ(k). Thus μ is trembling hand perfect.
Suppose next that the minmax value for Player 1 in G is strictly greater
than 0. Suppose σ(k) = (σ(k)
1 , σ(k)
2 , σ(k)
3 ) is a sequence of fully mixed strategy
proﬁles converging to μ. Since σ(k)
2
and σ(k)
3
do not place probability 1 on ⊥,
Player 1 has a reply to (σ(k)
2 , σ(k)
3 ) with an expected payoﬀstrictly larger than 0.
Thus ⊥is not a best reply of Player 1 to (σ(k)
2 , σ(k)
3 ). Since this holds for all
sequences σ(k) it follows that μ is not trembling hand perfect.
⊓⊔
With minimal changes we obtain the same result for the concept of proper
equilibrium of Myerson [24] that further reﬁnes that of a trembling hand perfect
equilibrium.
Deﬁnition 8 (Proper equilibrium). Let G be a m-player game in strategic
form. A strategy proﬁle σ for G is an ε-proper equilibrium if and only if is fully
mixed, and the following condition holds: Given two pure strategies, pk and pℓ,
of the same player, if pk is a worse reply against σ than pℓ, then σ must assign
a probability to pk that is at most ε times the probability it assign to pℓ. A
strategy proﬁle σ for G is a proper equilibrium if and only if is the limit point of
a sequence of ε-proper equilibria with ε →0+.
Theorem 9. For any m ≥3 it is ∃R-complete to decide if a given pure strategy
Nash equilibrium of a given m-player game in strategic form is proper.
Proof. We can show containment in ∃R exactly in the same way as the proof of
Theorem 7 by replacing the last set of formulas making up EPS-PE by
(Ri(x \ k) ≥Ri(x \ ℓ)) ∨(xi,k ≤εxi,ℓ), for i = 1, . . . , m and k, ℓ= 1, . . . , ni.
For establishing ∃R-hardness we can simply observe that this follows already
from the proof of Theorem 7. When the minmax value in G is 0, the sequence
σ(k) establishes that μ is even a proper equilibrium, since all strategies of all
players are best replies to σ(k). When the minmax value in G is strictly greater
than 0, since μ is not trembling hand perfect μ is not proper as well.
⊓⊔
3.2
Sequential Equilibrium of Games in Extensive Form
For extensive form games we ﬁrst consider the concept of sequential equilibrium,
introduced by Kreps and Wilson [23]. Kreps and Wilson deﬁned a sequential
equilibrium to be a pair (b, μ), which is called an assessment, consisting of a
behavior strategy proﬁle b together with a belief proﬁle μ. The belief proﬁle

The Real Complexity of Minmax Value and Equilibrium Reﬁnements
127
μ speciﬁes for each information set I a probability distribution on the nodes
contained in I. Here we will only be concerned with the strategy part b of
a sequential equilibrium. For this reason we will adopt an alternative deﬁni-
tion of (the strategy part of) a sequential equilibrium, also given by Kreps and
Wilson [23, Proposition 6]. Kreps and Wilson used the terminology weakly perfect
equilibrium for this.
Deﬁnition 10 (Sequential equilibrium). Let G be a m-player game in exten-
sive form with imperfect information but having perfect recall and let u be the
tuple of utilities of G. A behavior strategy b is (the strategy part of) a sequential
equilibrium if there is a sequence (b(k), u(k)), where b(k) is a fully mixed behavior
strategy proﬁle and u(k) is a tuple of utilities with limk→∞(b(k), u(k)) = (b, u)
and for every k and j, b(k)
j
is a best reply to b(k)
−j with respect to utilities u(k)
j .
Theorem 11. For any m ≥3 it is ∃R-complete to decide if a given pure strat-
egy proﬁle of a given m-player game in extensive form is part of a sequential
equilibrium.
Proof. We ﬁrst sketch the proof for containment in ∃R. Let u be the tuple of
utilities of G. First we express by a quantiﬁer free formula ϕ(b′, u′) that b′ is a
fully mixed behavior strategy proﬁle and that b′
j is a best response to b′
−j with
respect to u′
j for all j. We can now express that b is (the strategy part of) a
sequential equilibrium by
∀ε > 0 ∃b′, u′ : ϕ(b′, u′) ∧∥b −b′∥2
2 ≤ε ∧∥u −u′∥2
2 ≤ε.
Thus by Lemma 5 it follows that deciding whether a given behavior strategy
proﬁle b is (the strategy part of) a sequential equilibrium is contained in ∃R.
For establishing ∃R hardness we again reduce from the promise minmax
problem given by Theorem 3. Let G be the given 3-player game in strategic
form. We deﬁne an extensive form game G′ from G as follows. The players each
get to choose an action of G in turn, without revealing the choice to the other
players. Player 2 chooses ﬁrst, then Player 3, and ﬁnally Player 1. In G′ each
player has a single information set thus making G′ strategically equivalent to G.
The payoﬀs to Player 2 and Player 3 are 0 for all combinations of actions. The
payoﬀto Player 1 is inherited from G. We now give each player an additional
pure action ⊥in their respective information set. Choosing this action results in
the game ending immediately with all players receiving payoﬀ0.
Clearly, in G′ the behavior strategy proﬁle b = (⊥, ⊥, ⊥) is a Nash equilib-
rium. We claim that the minmax value for Player 1 in G is 0 precisely when b is
(the strategy part of) a sequential equilibrium.
Suppose ﬁrst that the minmax value for Player 1 in G is 0 and let (τ2, τ3) be
a minmax strategy proﬁle of Player 2 and Player 3, which we by assumption can
assume is fully mixed and against which all strategies of Player 1 yield payoﬀ0.
Let τ1 be the uniform strategy for Player 1 in G and let τ = (τ1, τ2, τ3). We now
deﬁne for k ≥1
b(k) = (1 −1
k )b + 1
k τ.

128
K.A. Hansen
By assumption and construction b(k) is a fully mixed behavior strategy proﬁle
converging to b as k increases. For the sequence of utilities we simply let u(k) = u
for all k. Note that in b(k) all players are playing a best reply, and it follows that
b is (the strategy part of) a sequential equilibrium.
Suppose next that the minmax value for Player 1 in G is strictly greater
then 0. Thus let ε > 0 be such that the minmax value for Player 1 in G is at
least ε. Let (b(k), u(k)) be a sequence of of pairs of fully mixed behavior strategy
proﬁles b(k) and tuples of utilities u(k) with limk→∞(b(k), u(k)) = (b, u). Let k be
such that ∥u −u(k)∥∞< ε/2 and let I denote the information set of Player 1.
Since b(k) is fully mixed, I is reached with non-zero probability. Conditioned on
reaching I, the action ⊥gives Player 1 payoﬀ0, whereas the best reply gives
payoﬀat least ε. Since ∥u −u(k)∥∞< ε/2 the payoﬀto Player 1 conditioned on
reaching I with respect to u(k) diﬀers by less than ε/2 to the payoﬀwith respect
to u. Thus, conditioned on reaching I, the action ⊥gives Player 1 payoﬀstrictly
less than ε/2, whereas the best reply gives payoﬀat least ε/2. But b(k) is fully
mixed and therefore is Player 1 not playing a best reply. Since this holds for all
sequences (b(k), u(k)) is follows that b is not (the strategy part of) a sequential
equilibrium.
⊓⊔
We also obtain analogous ∃R-completeness results for trembling hand perfect
equilibrium for extensive form games as deﬁned by Selten [29] and for quasi-
perfect equilibrium of van Damme [12]. Here the main work consists in showing
containment in ∃R, since ∃R-hardness essentially follows from the proof of Theo-
rem 11. These results are omitted in this version of the paper due to space
constraints.
3.3
CURB Sets in Games in Strategic Form
Here we consider the set valued solution concept of Closed Under Rational
Behavior (CURB) strategy sets by Basu and Weibull [1].
Deﬁnition 12 (CURB set). In a m-player game, a family of sets of pure
strategies, S1, S2, . . . , Sm with Si being a subset of the strategy set of player i, is
closed under rational behavior (CURB) if and only if for all pure strategies k of
Player i so that k is a best reply to a product distribution x on S1 × S2 × · · · ×
Si−1 × Si+1 × · · · × Sm, we have that k ∈Si.
Theorem 13. For any m ≥3 it is ∀R-complete to decide whether a family
of sets of pure strategies S1, S2, . . . , Sm is CURB in a given m-player game in
strategic form.
Proof. We show that the problem of deciding whether a family of sets of pure
strategies S1, S2, . . . , Sm is not CURB is complete for ∃R. Containment in ∃R
is straightforward. We existentially quantify over a mixed strategy proﬁle x and
have a disjunction for all i and all k /∈Si over inequalities expressing that k is a
best reply to x.

The Real Complexity of Minmax Value and Equilibrium Reﬁnements
129
In order to show hardness for ∃R we reduce from the promise minmax prob-
lem given by Theorem 3. Let G be the given 3-player game in strategic form.
We deﬁne a new game G′ from G where Player 1 is given an additional strategy
⊥. The payoﬀs to Player 2 and Player 3 are 0 for all strategy combinations. The
payoﬀto Player 1 is 0 if he plays ⊥and otherwise is the same as it would have
been in G.
By construction we now have that the minmax value of Player 1 in G is 0 if
and only if the set of all pure strategies except ⊥is not CURB in G′. Namely,
if the minmax value of G is 0, then ⊥is a best reply for Player 1 to the min-
max strategy proﬁle of Player 2 and Player 3, and the set of all pure strategies
except ⊥is not CURB. On the other hand, if the minmax value of G is strictly
greater than 0, then ⊥is never a best reply in G′, and the set of all pure strategies
except ⊥is therefore CURB.
⊓⊔
References
1. Basu, K., Weibull, J.W.: Strategy subsets closed under rational behavior. Econ.
Lett. 36(2), 141–146 (1991)
2. Benisch, M., Davis, G.B., Sandholm, T.: Algorithms for rationalizability and
CURB sets. In: Proceedings of the Twenty-First National Conference on Artiﬁ-
cial Intelligence, pp. 598–604. AAAI Press (2006)
3. Bil`o, V., Mavronicolas, M.: A catalog of ∃R-complete decision problems about Nash
equilibria in multi-player games. In: Ollinger, N., Vollmer, H. (eds.) STACS 2016.
LIPIcs, vol. 47, p. 17:1–17:13. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik
(2016)
4. Bl¨omer, J.: Computing sums of radicals in polynomial time. In: 32nd Annual Sym-
posium on Foundations of Computer Science (FOCS 1991), pp. 670–677. IEEE
Computer Society Press (1991)
5. Borgs, C., Chayes, J., Immorlica, N., Kalai, A.T., Mirrokni, V., Papadimitriou, C.:
The myth of the folk theorem. Games Econ. Behav. 70(1), 34–43 (2010)
6. Bubelis, V.: On equilibria in ﬁnite games. Int. J. Game Theor. 8(2), 65–79 (1979)
7. B¨urgisser, P., Cucker, F.: Exotic quantiﬁers, complexity classes, and complete prob-
lems. Found. Comput. Math. 9(2), 135–170 (2009)
8. Buss, J.F., Frandsen, G.S., Shallit, J.O.: The computational complexity of some
problems of linear algebra. J. Comput. Syst. Sci. 58(3), 572–596 (1999)
9. Canny, J.F.: Some algebraic and geometric computations in PSPACE. In: Simon,
J. (ed.) Proceedings of the 20th Annual ACM Symposium on Theory of Computing
(STOC 1988), pp. 460–467. ACM (1988)
10. Chen, X., Deng, X.: Settling the complexity of two-player Nash equilibrium. In:
47th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2006),
pp. 261–272. IEEE Computer Society Press (2006)
11. Conitzer, V., Sandholm, T.: New complexity results about Nash equilibria. Games
Econ. Behav. 63(2), 621–641 (2008)
12. van Damme, E.: A relation between perfect equilibria in extensive form games and
proper equilibria in normal form games. Int. J. Game Theor. 13, 1–13 (1984)
13. Daskalakis, C., Goldberg, P.W., Papadimitriou, C.H.: The complexity of computing
a Nash equilibrium. SIAM J. Comput. 39(1), 195–259 (2009)

130
K.A. Hansen
14. Datta, R.S.: Universality of Nash equilibria. Math. Oper. Res. 28(3), 424–432
(2003)
15. Etessami, K., Hansen, K.A., Miltersen, P.B., Sørensen, T.B.: The complexity of
approximating a trembling hand perfect equilibrium of a multi-player game in
strategic form. In: Lavi, R. (ed.) SAGT 2014. LNCS, vol. 8768, pp. 231–243.
Springer, Heidelberg (2014). doi:10.1007/978-3-662-44803-8 20
16. Etessami, K., Yannakakis, M.: On the complexity of Nash equilibria and other
ﬁxed points. SIAM J. Comput. 39(6), 2531–2597 (2010)
17. Garg, J., Mehta, R., Vazirani, V.V., Yazdanbod, S.: ETR-completeness for deci-
sion versions of multi-player (symmetric) Nash equilibria. In: Halld´orsson, M.M.,
Iwama, K., Kobayashi, N., Speckmann, B. (eds.) ICALP 2015. LNCS, vol. 9134,
pp. 554–566. Springer, Heidelberg (2015). doi:10.1007/978-3-662-47672-7 45
18. Gatti, N., Panozzo, F.: New results on the veriﬁcation of Nash reﬁnements for
extensive-form games. In: Proceedings of the 11th International Conference on
Autonomous Agents and Multiagent Systems (AAMAS 2012), pp. 813–820. Inter-
national Foundation for Autonomous Agents and Multiagent Systems (2012)
19. Gilboa, I., Zemel, E.: Nash and correlated equilibria: some complexity considera-
tions. Games Econ. Behav. 1(1), 80–93 (1989)
20. Grigor’Ev, D.Y., Vorobjov, N.: Solving systems of polynomial inequalities in subex-
ponential time. J. Symb. Comput. 5(1–2), 37–64 (1988)
21. Hansen, K.A., Hansen, T.D., Miltersen, P.B., Sørensen, T.B.: Approximability and
parameterized complexity of minmax values. In: Papadimitriou, C., Zhang, S. (eds.)
WINE 2008. LNCS, vol. 5385, pp. 684–695. Springer, Heidelberg (2008). doi:10.
1007/978-3-540-92185-1 74
22. Hansen, K.A., Miltersen, P.B., Sørensen, T.B.: The computational complexity of
trembling hand perfection and other equilibrium reﬁnements. In: Kontogiannis, S.,
Koutsoupias, E., Spirakis, P.G. (eds.) SAGT 2010. LNCS, vol. 6386, pp. 198–209.
Springer, Heidelberg (2010). doi:10.1007/978-3-642-16170-4 18
23. Kreps, D.M., Wilson, R.: Sequential equilibria. Econometrica 50(4), 863–894
(1982)
24. Myerson, R.B.: Reﬁnements of the Nash equilibrium concept. Int. J. Game Theor.
15, 133–154 (1978)
25. Nash, J.: Non-cooperative games. Ann. Math. 2(54), 286–295 (1951)
26. Schaefer, M.: Complexity of some geometric and topological problems. In: Epp-
stein, D., Gansner, E.R. (eds.) GD 2009. LNCS, vol. 5849, pp. 334–344. Springer,
Heidelberg (2010). doi:10.1007/978-3-642-11805-0 32
27. Schaefer, M.: Realizability of graphs and linkages. In: Pach, J. (ed.) Thirty Essays
on Geometric Graph Theory, pp. 461–482. Springer, Heidelberg (2013). doi:10.
1007/978-1-4614-0110-0 24
28. Schaefer, M., ˇStefankoviˇc, D.: Fixed points, Nash equilibria, and the existential
theory of the reals. Theor. Comput. Syst. 60(2), 172–193 (2017)
29. Selten, R.: A reexamination of the perfectness concept for equilibrium points in
extensive games. Int. J. Game Theor. 4, 25–55 (1975)
30. Shor, P.W.: Stretchability of pseudolines is NP-hard. In: Gritzmann, P., Sturm-
fels, B. (eds.) Applied Geometry And Discrete Mathematics. DIMACS Series in
Discrete Mathematics and Theoretical Computer Science, vol. 4, pp. 531–554.
DIMACS/AMS (1990)
31. van Damme, E.: Stability and Perfection of Nash Equilibria, 2nd edn. Springer,
Heidelberg (1991)
32. Vorob’ev, N.N.: Estimates of real roots of a system of algebraic equations. J. Sov.
Math. 34(4), 1754–1762 (1986)

Conditional Value-at-Risk: Structure
and Complexity of Equilibria
Marios Mavronicolas1(B) and Burkhard Monien2
1 Department of Computer Science, University of Cyprus, 1678 Nicosia, Cyprus
mavronic@ucy.ac.cy
2 Faculty of Electrical Engineering, Computer Science and Mathematics,
University of Paderborn, 33102 Paderborn, Germany
bm@upb.de
Abstract. Conditional Value-at-Risk, denoted as CVaRα, is becoming
the prevailing measure of risk over two paramount economic domains: the
insurance domain and the ﬁnancial domain; α ∈(0, 1) is the conﬁdence
level. In this work, we study the strategic equilibria for an economic
system modeled as a game, where risk-averse players seek to minimize
the Conditional Value-at-Risk of their costs. Concretely, in a CVaRα-
equilibrium, the mixed strategy of each player is a best-response. We
establish two signiﬁcant properties of CVaRα at equilibrium: (1) The
Optimal-Value property: For any best-response of a player, each mixed
strategy in the support gives the same cost to the player. This follows
directly from the concavity of CVaRα in the involved probabilities, which
we establish. (2) The Crawford property: For every α, there is a 2-player
game with no CVaRα-equilibrium. The property is established using the
Optimal-Value property and a new functional property of CVaRα, called
Weak-Equilibrium-for-VaRα, we establish. On top of these properties,
we show, as one of our two main results, that deciding the existence of
a CVaRα-equilibrium is strongly NP-hard even for 2-player games. As
our other main result, we show the strong NP-hardness of deciding the
existence of a V-equilibrium, over 2-player games, for any valuation V
with the Optimal-Value and the Crawford properties. This result has a
rich potential since we prove that the very signiﬁcant and broad class of
strictly quasiconcave valuations has the Optimal-Value property.
1
Introduction
1.1
Conditional Value-at-Risk and its Equilibria
Risk management is a principal component of any volatile economy; it amounts
to deﬁning and analyzing risk metrics in order to evaluate and minimize its
adverse impacts. Starting with the Markowitz’s Mean-Variance model [13], where
Partially supported by the German Research Foundation (DFG) within the Collab-
orative Research Centre “On-the-Fly-Computing” (SFB 901), and by funds for the
promotion of research at University of Cyprus.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 131–143, 2017.
DOI: 10.1007/978-3-319-66700-3 11

132
M. Mavronicolas and B. Monien
risk is identiﬁed with the Variance of loss, there is an extensive literature on
formulating and optimizing risk valuations—see, e.g., [12,26].
We shall focus on a prominent risk measure: Conditional Value-at-Risk,
denoted as CVaRα; α ∈(0, 1) is the conﬁdence level, and values of α close to 1,
such as 90%, 95% or 99%, are of interest. CVaRα is closely related to Value-at-
Risk, denoted as VaRα. Stated simply, VaRα is an upper percentile of a given
loss distribution: it is the lowest amount which, with probability at least α, the
loss will not exceed. VaRα attracted the interest of practitioners as a conceptu-
ally simple and intuitive quantiﬁcation of risk, and prevailed as a benchmark. In
spite of its success, VaRα lacks an important property: by not looking beyond the
α-percentile, VaRα does not account for losses exceeding it; hence, it provides
an inadequate picture of risks by failing to capture “tail risks”.
In the discrete setting, CVaRα is a weighted average of VaRα and the expected
losses strictly above VaRα. CVaRα is computationally attractive as it can be
optimized using Linear Programming and it is expressible as a minimization
formula [20,21]; it is continuous in α and convex in the variables (cf. [29]).
CVaRα is recognized as a suitable model of risk in volatile economic circum-
stances; it is widely used for modeling and optimizing hedge and credit risks.
There were recently two quite notable developments in the insurance domain
and the ﬁnancial domain, namely the issue of the Solvency II Directive in the
issurance domain, and of Basel III Rules in the ﬁnancial domain, which enforce
a tremendous increase to the role and applicability of CVaRα.
To model the strategic interactions incurred in the management of risk, we
adopt the game-theoretic framework from [15, Sect. 2] with risk-averse players
seeking to minimize their costs. Each player is using a mixed strategy: a prob-
ability distribution over her strategies; her cost is evaluated by CVaRα, which
is a particular case of a valuation V, mapping a tuple of mixed strategies to
reals. We are interested in the strategic equilibria incurred by CVaRα, call them
CVaRα-equilibria, where no player could unilaterally decrease her CVaRα cost.
The ﬁrst counterxample game with no equilibrium for a certain valuation
was given by Crawford [5, Sect. 4]; more counterexamples appeared in [14]. Nat-
urally, the properties of a valuation bear a signiﬁcant impact on the existence
of an equilbrium. The most prominent valuation considered in Game Theory is
Expectation, denoted as E; although inadequate to accomodate risk, it guaran-
tees the existence of a Nash equilibrium [16,17]. Stated for maximization games,
equilibrium existence is still guaranteed for concave valuations [6,8].
Concave valuations like Variance (Var) are well-suited to model risk; so, for
a concave V, a V-equilibrium is the proper generalization of Nash equilibrium
to risk-aversion. The seminal Markowitz’s Mean-Variance approach [13] to port-
folio maximization is built around Var. Deciding the existence of an (E + Var)-
equilibrium is strongly NP-hard [15, Theorem 5.12] for 2-player games. This was
the ﬁrst concrete instance of the strong NP-hardness of ∃V-EQUILIBRIUM: decid-
ing, given a game, the existence of a V-equilibrium, for 2-player games; it assumed
that V has the Weak-Equilibrium-for-Expectation property [15, Deﬁnition 3.1]
and fulﬁlls a few technical conditions [15, Theorem 5.1]. Weak-Equilibrium-
for-Expectation means that all strategies supported in a player’s best-response

Conditional Value-at-Risk: Structure and Complexity of Equilibria
133
mixed strategy induce the same expectation. Towards proving hardness results
for ∃CVaRα-EQUILIBRIUM, we shall explore corresponding properties for CVaRα.
1.2
Results and Signiﬁcance
We shall focus on (E+R)-valuations [15], combining expected cost and a measure
of risk, where R has the Risk-Positivity property: its value is always non-negative,
and 0 only if no risk is incurred. So, V being an (E+R)-valuation means that V can
be written as V = E+R, for some R with the Risk-Positivity property. An example
of an (E + R)-valuation where R appears explicitly is E + Var, which was ﬁrst
explicitly proposed in the seminal paper of Markowitz [13]; Var is known to have
the Risk-Positivity property [14]. There are examples of (E+R)-valuations where
R appears implicitly, such as CVarα and Extended Sharpe Ratio ESR (Theorems 1
and 10, respectively). An (E + R)-valuation is an example of an approach to
combine two diﬀerent optimization goals, namely expectation and riskiness, into
a single formula; the Sharpe Ratio [24,25] is another successful example.
We show ﬁve interesting properties of CVaRα, falling into two classes. The
ﬁrst class addresses CVaRα as a mathematical function.
– CVaRα is an (E + R)-valuation, where R has the Risk-Positivity property
(Theorem 1).
– CVaRα is concave in the probabilities (Theorem 2). The concavity of CVaRα
is of independent interest and may ﬁnd applications in Convex Optimization.
The second class includes properties of CVaRα in reference to equilibria of games:
– A signiﬁcant consequence of the concavity of CVaRα, following from [15,
Proposition 3.1], is that it has the Optimal-Value property: For every game,
every convex combination of strategies in the support of a player’s best-
response mixed strategy yields the same minimum cost. The Optimal-Value
property gives necessary conditions on best-response mixed strategies.
– We show, using a counterexample, that CVaRα lacks the Weak-Equilibrium-
for-Expectation property (Theorem 5). Since CVaRα has the Optimal-Value
property, this implies a separation between the two properties. Nevertheless,
we identify a new functional property of CVaRα, termed Weak-Equilibrium-
for-VaRα: all strategies supported in a player’s CVaRα-best response mixed
strategy induce the same VaRα unless some strong condition holds.
– We show that CVaRα has the Crawford property: there is a so called Crawford
game with no CVaRα-equilibrium (Theorem 6). The Crawford property for a
valuation V implies that the problem ∃V-EQUILIBRIUM is non-total. We adopt
the Crawford game GC(δ) from [15], which involves a parameter δ. We use
Weak-Equilibrium-for-VaRα to prove the Crawford property.
As one of our two main results, we show the generic result (Theorem 7) that
∃V-EQUILIBRIUM is strongly NP-hard when V is an (E + R)-valuation with the
Optimal-Value property, provided that there is a parameter δ, with 0 < δ ≤1
4,
such that three additional conditions hold; δ has to be a rational number since

134
M. Mavronicolas and B. Monien
it explicitly enters the reduction. The Optimal-Value property is very crucial
for the reduction. The ﬁrst two such conditions ((2/a) and (2/b)) stipulate two
natural analytical properties of V. We give an existential proof that Condition
(2/a) holds under some very mild continuity assumptions on the risk valuation
R (Lemma 4). The third condition (2/c) requires that for the chosen value of
δ, the Crawford game GC(δ); has no V-equilibrium. So, Theorem 7 addresses
a very broad class of (E + R)-valuations with three natural properties: Risk-
Positivity of R, Optimal-Value and Crawford; hence, Theorem 7 can be used as a
recipe for proving NP-hardness results for other valuations. Indeed, we explicitly
determine a parameter δ for which CVaRα fulﬁlls both additional conditions (2/a)
and (2/b) in Theorem 7. Hence our other main result: ∃CVaRα-EQUILIBRIUM is
strongly NP-hard for 2-player games (Theorem 8).
Recall that the Optimal-Value property of CVaRα followed directly from its
concavity. Since the proof of the NP-hardness of ∃CVaRα-EQUILIBRIUM used
the Optimal-Value property, it is natural to ask how crucial concavity is to the
NP-hardness of ∃V-EQUILIBRIUM in general. Does NP-hardness extend beyond
concave valuations? Towards this end, we consider quasiconcave valuations [7,9,
18], a broad generalization of concave valuations, and their proper subclass of
strictly quasiconcave valuations [19]. As a nice historical survey in [11] shows, the
notion of quasiconcavity emerged from the works of three authors, namely von
Neumann [18], DeFinetti [7] and Fenchel [9], in Economics and Mathematics,
and started the research ﬁeld of generalized convexity. Quasiconcave functions
make a very rich class with many applications in Mathematical Economics; for
example, in Microeconomics, the convexity of customers’ preference relations is
a very desirable feature, implying the quasiconcavity of their utilities [22].
A strictly quasiconcave valuation incurs to a player mixing two particular
mixed strategies a cost larger than the minimum of the individual costs incurred
by the two mixed strategies when the two costs are not equal. A signiﬁcant
property of strictly quasiconcave valuations, making them interesting to con-
sider in the context of equilibrium computation, is that they do not exclude
the existence of mixed equilibria, whereas strictly concave valuations do (cf. [15,
Sect. 1.5]); this is because the notion of strictness is weaker for strictly quasicon-
cave valuations than for strictly concave valuations. We show that every strictly
quasiconcave valuation has the Optimal-Value property (Theorem 9).
To test the applicability of the Optimal-Value property of strictly quasicon-
cave valuations to deriving concrete NP-hardness, we consider the Extended
Sharpe Ratio ESR :=
M · E
M −Var; M is a constant. ESR is inspired from the
famous Sharpe Ratio [24,25], applying to revenue maximization, which mea-
sures how well an asset’s return compensates the investor for the risk; ESR
is an adjustment of Sharpe Ratio to minimization games. We prove that ESR
is an (E + R)-valuation. The strict quasiconcavity of ESR (Theorem 11) fol-
lows from the new result that the ratio of a concave over a convex function
is strictly quasiconcave (Lemma 6). Further we prove that ESR has the Weak-
Equilibrium-for-Expectation property; it is used for proving that GC(δ) has no
ESR-equilibrium (Theorem 12). Hence, the strong NP-hardness of deciding the

Conditional Value-at-Risk: Structure and Complexity of Equilibria
135
existence of an ESR-equilibrium follows (Theorem 13), settling an open problem
from [15, Sect. 6]. This witnesses that Theorem 7 is applicable beyond concave
valuations.
1.3
Related Work and Comparison
This work falls into the research ﬁeld of computing equilibria for games where
players are not expectation-maximizers, started by Fiat and Papadimitriou
in [10].
Theorem 7 extends the strong NP-hardness from valuations with the Weak-
Equilibrium-for-Expectation property in [15, Theorem 5.1] to ones with Optimal-
Value property, encompassing, by Theorem 9, the much broader class of strictly
quasiconcave valuations. The extra conditions for Theorem 7 and [15, Theorem
5.1] are quite similar; Risk-Positivity is used for both. Like the reduction in [15,
Theorem 5.1], the reduction in Theorem 7 uses ideas from the reduction in [4],
used for the NP-hardness proof of decision problems about Nash equilibria.
Concrete strong NP-hardness results for 2-player games followed from [15,
Theorem 5.1], for concave valuations like E + Var [15, Theorem 5.12]; other
concrete results for 2-strategies games, and for many signiﬁcant choices of V, are
given in [15, Theorem 4.6]. Further complexity results had appeared in [14].
To the best of our knowledge, there are in the literature only three hardness
results about VaRα, which, however, are not related to equilibrium computa-
tion: (1) Maximizing the expectation of portfolio return of an investment, for
a given α and a given threshold on VaRα, is NP-complete [2]. (2) In the dis-
crete setting, maximizing the expectation of expected return over all scenaria
is NP-complete [1]. (A scenario is a set of options with potential investment
losses.) (3) For a given α, minimizing VaR, subject to the constraints that (i)
the “scenario-weighted” portfolio price is no more than the initial endowment,
and (ii) the loss exceeds VaR with probability no more than α, is NP-hard [30].
2
(E + R)-Valuations
A valuation is a special case of a function, which maps probability vectors to
reals. In this work, we shall focus on an (E + R)-valuation [15, Deﬁnition 2.1],
which is a valuation of the form V = E + R, where E is the expectation valuation
with E(p) = 
k∈[ℓ] pkak, and R is the risk valuation, a continuous valuation with
the Risk-Positivity property: For each probability vector p, (C.1) R(p) ≥0, and
(C.2) R(p) = 0 if and only if the corresponding random variable P is constant.
A function f : D →R on a convex set D ⊆Rn is concave if for every pair of
points x, y ∈D, for all λ ∈[0, 1], f(λ y + (1 −λ) x) ≥λ f(y) + (1 −λ) f(x); f is
strictly concave if the inequality is strict for all λ ∈(0, 1). A function f : D →R
on a convex set D is (strictly) convex if −f is (strictly) concave.
Quasiconcavity generalizes concavity: A function f : D →R is quasicon-
cave if for every pair of points x, y ∈D, for all λ ∈(0, 1), f(λy + (1 −λ)x) ≥
min{f(y), f(x)}. A function f : D →R on a convex set D ⊂Rn is quasiconvex if

136
M. Mavronicolas and B. Monien
−f is quasiconcave. A quasiconcave function need not be concave. Thus, these
functions miss many signiﬁcant properties of concave functions. For example, a
quasiconcave function is not necessarily continuous, while a concave function on
an open interval is also continuous on it.
A quasiconcave function f : D →R is strictly quasiconcave [19] if for every
pair of points x, y ∈D, f(x) ̸= f(y) implies that for all λ ∈(0, 1), f(λy+(1−λ)x) >
min{f(y), f(x)}; f is strictly quasiconvex if −f is strictly quasiconcave. The notion
of strictness for strictly quasiconcave functions is weaker than for strictly concave
functions: for the former, strictness allows that f(λx+(1−λ)y) = min{f(x), f(y)},
with λ ∈(0, 1), in the case f(x) = f(y), whereas the equality is excluded for the
latter. A notable property of a strictly quasiconcave function is a property of
concave functions: a local maximum is also a global maximum [19, Theorem 2].
3
Conditional Value-at-Risk (CVaRα)
Our presentation draws from [20,21]. Fix throughout a conﬁdence level α ∈[0, 1).
Some of the tools to study the properties of CVaRα come from Value-at-Risk,
denoted as VaRα; they are both examples of a valuation: a function from prob-
ability distributions to reals. We consider a random variable P, representing a
distribution of loss; the cumulative distribution function of P may be continuous
or discontinuous. A discrete random variable P has a discrete distribution func-
tion, making a special case of a discontinuous cumulative distribution function:
it takes on values 0 ≤a1 < a2 < . . . < aℓwith probabilities pj := P(P = aj),
1 ≤j ≤ℓ; the values a1, a2, . . . , aℓare called scenaria in the risk literature. In
this case, we shall identify P with the probability vector p. Note that in deﬁn-
ing VaRα(p) and CVaRα(p), the values a1, . . . , aℓhave to be ﬁxed. Denote the
cumulative distribution function of p as Π(p, z) = 
k∈[ℓ]|ak≤z pk.
3.1
Value-at-Risk (VaRα)
The Value-at-Risk of P at conﬁdence level α ∈[0, 1), denoted as VaRα(P), is
deﬁned as VaRα(P) = inf {ζ | P [P ≤ζ] ≥α}; this deﬁnition applies to both con-
tinuous and discontinuous distributions. So, P [P ≤VaRα(P)] ≥α, with equality
holding when the cumulative distribution function is continuous at VaRα(P)—
put in other words, when there is no probability atom at VaRα(P). When P is a
discrete random variable, VaRα(p) = min

ak | k
j=1 pj ≥α

; note that VaRα
is a discontinuous function of α. In this case, denote as κα = κα(p) the unique
index such that 
k∈[κα] pk ≥α > 
k∈[κα−1] pk; so, aκα = VaRα(p). In the
full version of the paper, we give an example establishing that VaRα is not an
(E + R)-valuation. We shall later use an interesting property of VaRα (cf. [3,
Exercise 3.24 (f)]), for which we provide a new proof.
Lemma 1. With α ∈(0, 1), VaRα(p) is quasiconcave and quasiconvex in the
probabilities, but neither strictly quasiconcave nor strictly quasiconvex.

Conditional Value-at-Risk: Structure and Complexity of Equilibria
137
3.2
Conditional Value-at-Risk (CVaRα)
CVaRα accounts for losses no smaller than VaRα. For random variables with
a continuous cumulative distribution function, the Conditional Value-at-Risk
of P, denoted as CVaRα(P), is the conditional expectation of P subject to
P ≥VaRα(P) [23, Deﬁnition 2]; so, CVaRα(P) = E (P | P ≥VaRα(P)). Note
that α = 0 is a degenerate case with CVaR0(P) = E(P). The general def-
inition of CVaRα for random variables with a possibly discontinuous cumu-
lative distribution function is obtained as follows (cf. [21, Proposition 6]):
Denote as CVaR+
α(P) the conditional expectation of P subject to P > VaRα(P);
CVaR+
α(P) is also called the Condtional Tail Expectation or Upper CVaR [23].
Set λα(P) := P [P ≤VaRα(P)] −α
1 −α
. Note that λα(P) provides for the possibility
that there is a probability atom (that is, the cumulative distribution function is
discontinuous) at VaRα(P). The numerator of λα(P) is the “excess” probability
mass at VaRα(P), i.e., the probability mass beyond α; the denominator 1 −α is
the support size of Pα, the α-tail distribution of P, denoted as Pα and deﬁned
as follows: Pα [P ≤ζ] = 0 if ζ < VaRα(P), and Pα [P ≤ζ] = P [P ≤ζ] −α
1 −α
if
ζ ≥VaRα(P); thus, λα(P) = Pα [P ≤VaRα(P)]. Hence, we obtain the weighted
average formula for CVaRα(P) [21, Proposition 6]:
CVaRα(P) := λα(P) · VaRα(P) + (1 −λα(P)) · CVaR+
α(P) ;
so, CVaRα is the weighted average of VaRα and the expectation of losses strictly
exceeding VaRα. Note that CVaRα(P) = VaRα(P) when λα(P) = 1; note also that
for continuous cumulative distributions, λα(P) = 0 and CVaRα(P) = CVaR+
α(P),
the expected loss strictly exceeding VaRα. For a discrete random variable P,
identiﬁed with the probability vector p, the weighted average formula reduces
to the discrete weighted average formula (cf. [21, Proposition 8]):
CVaRα(p) =
1
1 −α
⎛
⎝
⎛
⎝
k∈[κα]
pk −α
⎞
⎠aκα +

k≥κα+1
pkak
⎞
⎠.
Recall the minimization function Fα(p, z) := z+
1
1 −α

k∈[n]|ak>z(ak−z)pk,
for a probability vector p and a number z ∈R, from [20, Sect. 2]. Note that Fα is
linear in its ﬁrst argument. The continuity of Fα in z follows from its convexity (in
z) [21, Theorem 10]. We provide a direct and simple proof, bypassing convexity,
for the discrete setting.
Lemma 2. The function Fα(p, z) is continuous in z.
We now prove some monotoniciy properties of Fα(p, z) in z, drawing on
the continuity of Fα (Lemma 2); they oﬀer reﬁnements of properties from [21,
Proposition 5], which will be needed later. In order to take into account the
possibility that some probabilities may be 0, denote, for an index j ∈[ℓ],
next(p, j) := min{k > j | pk ̸= 0}; next(p, j) := ℓ+ 1 when pk = 0 for all
j < k ≤ℓ.
Lemma 3. The following implications hold:

138
M. Mavronicolas and B. Monien
(1) If Π (p, VaRα(p)) > α, then:
(1/a) Fα (p, z) increases strictly monotone in z for z ≥VaRα(p).
(1/b) Fα (p, z) decreases strictly monotone in z for z ≤VaRα(p).
(2) If Π (p, VaRα(p)) = α, then:
(2/a) Fα (p, z) increases strictly monotone for z ≥anext(p,κα(p)).
(2/b) Fα (p, z) is constant for VaRα(p) ≤z ≤anext(p,κα(p)).
(2/c) Fα (p, z) decreases strictly monotone for z ≤VaRα(p).
By Lemmas 2, 3 immediately implies a result from [21, Theorem 10]:
Corollary 1. CVaRα(p) = minz Fα(p, z) = Fα(p, VaRα(p)).
We continue to show two signiﬁcant properties:
Theorem 1. With α ∈(0, 1), CVaRα is an (E + R)-valuation.
Theorem 2. With α ∈(0, 1), CVaRα is concave in the probabilities.
We continue with a characterization of the cases where CVaRα is constant
over all convex combinations of probability vectors p and q; interestingly, one
of the two cases requires that VaRα(p) = VaRα(q). We use the quasiconcavity
and quasiconvexity of VaRα in the probabilities (Lemma 1) to prove:
Theorem 3. Fix a conﬁdence level α ∈(0, 1) and consider probability vec-
tors p and q with VaRα(p) ≤VaRα(q) and CVaRα(p) = CVaRα(q). Then,
CVaRα (λ · p + (1 −λ) · q) is constant for λ ∈[0, 1] if and only if:
(1) VaRα(p) = VaRα(q), or:
(2) α = Π (p, VaRα(p)) and κα(q) ≤next(p, κα(p)).
4
Properties of CVaRα at Equilibrium
Our deﬁnitions and notation for the game-theoretic framework are standard;
they are patterned after those in [15, Sects. 2 and 3].
For a player i ∈[n], a valuation function, or valuation for short, Vi is a
real-valued function, yielding a value Vi(p) to each mixed proﬁle p, so that in
the special case when p is a proﬁle s, Vi(s) = μi(s). The expectation valua-
tion Ei(p) = 
s∈S p(s) μi(s), with i ∈[n]. A valuation V = ⟨V1, . . . , Vn⟩is
a tuple of valuations, one per player; GV denotes G together with V. We shall
view each valuation Vi, with i ∈[n], as a function of the mixed strategy pi,
for a ﬁxed partial mixed proﬁle p−i; this view incurs corresponding deﬁnitions
in the game-theoretic framework for Risk-Positivity and (strict) concavity and
quasiconcavity, which we now provide. We shall assume that V is an (E + R)-
valuation. By Condition (C.2) in the Risk-Positivity property, it follows that for
each player i ∈[n] and mixed proﬁle p, Ri(p) = 0 if and only if for each proﬁle
s ∈S with p(s) > 0, μi(s) is constant over all choices of strategies by the other
players; in such case, Vi(p) = Ei(p) = μi(s) for any proﬁle s ∈S with p(s) > 0.
The valuation V is concave (resp., (strictly) quasiconcave) if the following holds

Conditional Value-at-Risk: Structure and Complexity of Equilibria
139
for every game G: For each player i ∈[n], the valuation Vi (pi, p−i) is concave
(resp., (strictly) quasiconcave) in pi, for a ﬁxed p−i.
A mixed strategy pi of player i is a Vi-best response to p−i if pi minimizes
Vi (., p−i) over Δi; so, Vi (pi, p−i) = min {Vi (p′
i, p−i) | p′
i ∈Δ(Si)}. The mixed
proﬁle p is a V-equilibrium if for each player i ∈[n], the mixed strategy pi is
a Vi-best response to p−i; so, no player could unilaterally deviate to another
mixed strategy to reduce her cost. Denote as ∃V-EQUILIBRIUM the problem of
deciding, given a game G, the existence of a V-equilibrium for GV.
The valuation V has the Optimal-Value property if the following condition
holds for every game G: For each player i ∈[n], if pi is a Vi-best response to a
partial mixed proﬁle p−i, then, for any mixed strategy qi with σ (qi) ⊆σ (pi),
Vi (qi, p−i) = Vi (pi, p−i). By a suﬃcient condition from [15, Proposition 3.1],
every concave valuation has the Optimal-Value property; hence, by the concav-
ity of CVaRα (Theorem 2), CVaRα has the Optimal-Value property. Here is an
immediate implication of the Optimal-Value property for CVaRα-best responses:
all strategies supported in a player’s CVaRα-best response mixed strategy induce
the same (conditional) VaRα (unless some other, strong condition holds).
Theorem 4 (Weak-Equilibrium-for-VaRα Property).
Fix a conﬁdence
level α ∈(0, 1). Take a CVaRα-best response pi of player i ∈[n] to the partial
mixed proﬁle p−i, where p1, p2 ∈σ(pi) with VaRα(⟨p1, p−i⟩) ≤VaRα(⟨p2, p−i⟩).
Then:
(1) VaRα(⟨p1, p−i⟩) = VaRα(⟨p2, p−i⟩), or:
(2) α = Π

⟨p1, p−i⟩, VaRα(⟨p1, p−i⟩)

and κα(⟨p2, p−i⟩) ∈

κα

⟨p1, p−i⟩

, next

p, κα

⟨p1, p−i⟩
	
.
The (E + R)-valuation V has the Weak-Equilibrium-for-Expectation prop-
erty [15, Deﬁnition 3.1] if the following condition holds for every game G: For
each player i ∈[n], the Weak-Equilibrium-for Expectation property for player i
holds: If pi is a Vi-best response to a partial mixed proﬁle p−i, then for each
pair of strategies j, k ∈σ(pi), Ei

pj
i, p−i

= Ei

pk
i , p−i

. We show:
Theorem 5. For a ﬁxed conﬁdence level α ∈(0, 1), CVaRα does not have the
Weak-Equilibrium-for-Expectation property.
For 0 < δ < 1, the Crawford game GC(δ) is the 2-player game with bimatrix
⟨1 + δ, 1 + δ⟩⟨1, 1 + 2δ⟩
⟨1, 1 + 2δ⟩
⟨1 + 2δ, 1⟩

from [15]; it is a generalization of a game from [5,
Sect. 4]. GC(δ) has no pure equilibrium [15, Lemma 5.11]. We show:
Theorem 6. With α ∈

1
3, 1

and δ > 0, GC(δ) has no mixed CVaRα-
equilibrium.
5
N P-Hardness from Optimal-Value Property
We ﬁrst recall some notation from [15, Sect. 2.2]. For an (E + R)-valuation V,
we shall deal with the so called bivalued cases where for a player i ∈[n] and

140
M. Mavronicolas and B. Monien
a mixed proﬁle p, {μi(s) | p(s) > 0} = {a, b} with a < b, so that Ri(p) is a
function of the three parameters a, b and q with q = 
s∈S|μi(s)=b p(s). Then,
denote Ri(a, b, q) := Ri(p) and Vi(a, b, q) := a + q(b −a) + Ri(a, b, q). We show:
Theorem 7. Fix an (E + R)-valuation V such that:
(1) V has the Optimal-Value property.
(2) There is a rational number δ, with 0 < δ ≤1
4, such that:
(2/a) R(1, 1 + ϱ, q) < 1
2 for each probability q ∈[0, 1], with 0 < ϱ ≤2δ.
(2/b) V(1, 1 + ϱ, r) < V(1, 2, q) for each pair of probabilities 0 ≤r ≤q ≤1,
with 0 < ϱ ≤2δ.
(2/c) The Crawford game GC(δ) has no V-equilibrium.
Then, ∃V-EQUILIBRIUM is strongly NP-hard for 2-player games.
We present a proof with a general reduction involving the parameter δ from
Condition (2), which is a rational number. The reduction uses the Crawford
game GC(δ), with 0 < δ ≤1
4, as a “gadget”; so, δ enters the reduction through
GC(δ). We employ a reduction from SAT. An instance of SAT is a propositional
formula φ in the form of a conjunction of clauses C = {c1, . . . , ck} over a set of
variables V = {v1, . . . , vm}. Denote as L = {ℓ1, ℓ1, . . . , ℓm, ℓm} the set of literals
corresponding to the variables in V. We shall use lower-case letters c, c1, c2, . . .,
v, v1, v2, . . ., and ℓ, ℓ1, ℓ2, . . . to denote clauses from C, variables from V and
literals from L, respectively. Denote Λ := C ∪V ∪L. We shall use the Crawford
set F = {f1, f2} with the two strategies f1 and f2 from GC(δ); f denotes f1 or f2.
Proof. From an instance φ of SAT, form G = G(φ) = ⟨[2], {Si}i∈[2], {μi}i∈[2]⟩
with: For i ∈[2], Si := Λ ∪F; see the cost functions {μi}i∈[2] are given in
Fig. 1. For a player i ∈[2], denote pi(F) := 
f∈F pi(f), pi(L) := 
ℓ∈L pi(ℓ)
and pi(Λ) := 
λ∈Λ pi(λ); note that pi(F) + pi(Λ) = 1. We ﬁrst prove that in a
V-equilibrium ⟨p1, p2⟩for G, p1(Λ) · p2(Λ) > 0; further, we prove that p1(Λ) =
p2(Λ) = 1. We ﬁnally establish some stronger properties for a V-equilibrium from
which strong NP-hardness follows.
□
Condition (2/a) in Theorem 7 is fulﬁlled under some very mild conditions on
R:
Lemma 4. Consider a function R(1, 1+ϱ, q) with the following properties: (C.1)
R(1, 1, q) = 0 for q ∈[0, 1]. (C.2) R is continuous in ϱ and in q. Then, there is
a rational number δ, 0 < δ ≤1
4, such that R(1, 1 + ϱ, q) fulﬁlls Condition (2/a).
We now use Theorem 7 to derive a concrete strong NP-hardness result for
CVaRα, with α ∈

1
3, 1

. Condition (1) from Theorem 7 is fulﬁlled since CVaRα
has the Optimal-Value property. We continue to prove:
Lemma 5. For 0 < δ < 1
4 · (1 −α), CVaRα fulﬁlls (2/a) and (2/b) from
Theorem 7.

Conditional Value-at-Risk: Structure and Complexity of Equilibria
141
Fig. 1. The cost functions for the game G(φ). For a proﬁle ⟨s1, s2⟩not in the table, set
μi(s1, s2) := μi(s2, s1), with i ∈[2] and i ̸= i; so, i is the opponent player.
By Theorem 6, CVaRα with α ∈

1
3, 1

fulﬁlls Condition (2/c) from Theo-
rem 7. Thus, we obtain:
Theorem 8. With α ∈

1
3, 1

, ∃CVaRα-EQUILIBRIUM is strongly NP-hard for
2-player games.
In the full version of the paper, we improve Theorem 8 to cover all α ∈(0, 1).
6
Strict Quasiconcavity and Extended Sharpe Ratio
We extend the Optimal-Value property to any strictly quasiconcave valuation:
Theorem 9. A strictly quasiconcave valuation has the Optimal-Value property.
So Theorem 9 extends Theorem 7 by replacing the Optimal-Value property
in Theorem 7 (Condition (2/a)) with the strict quasiconcavity property.
Given a mixed proﬁle p and a player i ∈[n], the Extended Sharpe Ratio is
ESRi(p) =
M · Ei(p)
M −Vari(p), where M is a constant independent of p, with M >

maxi∈[n],s∈S μi(s)
2. We prove:
Theorem 10. ESR is an (E + R)-valuation.
It was known that the ratio of a concave function and a convex function is
strictly quasiconcave (cf. [3, Example 3.38]). We present a new, simple proof to
get a stronger result with quasiconcavity replaced by strict quasiconcavity.
Lemma 6. Consider a pair of a concave function g : D →R+ and a convex
function h : D →R+. Then, the function f := g
h is strictly quasiconcave.
Since M · E is concave and M −Var is convex, Lemma 6 implies:

142
M. Mavronicolas and B. Monien
Theorem 11. ESR is strictly quasiconcave.
By Theorems 9 and 11 sets the Optimal-Value property for ESR. We prove:
Lemma 7. For δ with 0 < δ ≤1
4, ESR fulﬁlls (2/a) and (2/b) from Theorem 7.
We now show the Crawford property for ESR:
Theorem 12. For δ > 0, the game GC(δ) has no mixed ESR-equilibrium.
By the Optimal-Value property, Lemma 7 and Theorems 7, 12 implies:
Theorem 13. ∃ESR-EQUILIBRIUM is strongly NP-hard for 2-player games.
7
Conclusion and Open Problems
This work presents the ﬁrst complexity results for the equilibrium computation
problem about CVaRα; these are shown using signiﬁcant mathematical proper-
ties for CVaRα, such as concavity in the probabilities, we establish. The strong
NP-hardness of ∃CVaRα-EQUILIBRIUM (Theorem 8) follows from two signiﬁcant
properties of CVaRα: (i) the Optimal-Value property and (ii) the Crawford prop-
erty (Theorem 6), shown using its Weak-Equilibrium-for-VaRα property. Using a
few additional technical conditions, we prove that for any 2-player game with a
valuation V with the Optimal-Value and the Crawford properties, it is strongly
NP-hard to decide if the game has a V-equilibrium (Theorem 7).
Theorems 7 and 9 show together the NP-hardness of deciding the existence
of equilibria for valuations with the strict quasiconcavity property from [19],
fulﬁlling some extra conditions. Since a wide spectrum of functions from Mathe-
matical Economics are quasiconcave, this is a very general result. So it is rather
likely that we have to cope with NP-hardness when we want to model risk, and
this is the most signiﬁcant insight following from our NP-hardness results. The
ﬁeld of Operations Research has done this successfully in the last 40 years. In
Algorithmic Game Theory, we now have to seek for positive results in the direc-
tions of (i) special classes of games, (ii) approximate equilibria and (iii) other
solution concepts, such as correlated equilibria. A spectrum of concrete open
questions remain. Since CVaRα is becoming the prevailing measure of risk in
contemporary ﬁnancial engineering, it would be interesting to design algorithms
to compute approximate CVaRα-equilibria, or to prove inapproximability results.
References
1. Benati, S.: The computation of the worst conditional expectation. Eur. J. Oper.
Res. 155, 414–425 (2004)
2. Benati, S., Rizzi, R.: A mixed integer linear programming formulation of the opti-
mal mean/value-at-risk portfolio problem. Eur. J. Oper. Res. 176, 423–434 (2007)
3. Boyd, S., Vandenberghe, L.: Convex Optimization. Cambridge University Press,
Cambridge (2004)

Conditional Value-at-Risk: Structure and Complexity of Equilibria
143
4. Conitzer, V., Sandholm, T.: New complexity results about Nash equilibria. Games
Econ. Behav. 63(2), 621–641 (2008)
5. Crawford, V.P.: Equilibrium without independence. J. Econ. Theory 50(1), 127–
154 (1990)
6. Debreu, G.: A social equilibrium existence theorem. Proc. Nat. Acad. Sci. U.S.A.
38, 886–893 (1952)
7. DeFinetti, B.: Sulle stratiﬁcazioni convesse. Annal. Mat. 30, 173–183 (1949)
8. Fan, K.: Fixed point and minimax theorems in locally convex topological linear
spaces. Proc. Nat. Acad. Sci. 38, 121–126 (1952)
9. Fenchel, W.: Convex Cones, Sets and Functions. Lecture Notes, Department of
Mathematics, Princeton University (1953)
10. Fiat, A., Papadimitriou, C.H.: When the players are not expectation maximizers.
In: Kontogiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.) SAGT 2010. LNCS,
vol. 6386, pp. 1–14. Springer, Heidelberg (2010). doi:10.1007/978-3-642-16170-4 1
11. Guerraggio, A., Molho, E.: The origins of quasi-concavity: a development between
mathematics and economics. Hist. Math. 31, 62–75 (2004)
12. Krokhmal, P., Zabarankin, M., Uryasev, S.: Modeling and optimization of risk.
Surv. Oper. Res. Manag. Sci. 16, 49–66 (2011)
13. Markowitz, H.: Portfolio selection. J. Finan. 7, 77–91 (1952)
14. Mavronicolas, M., Monien, B.: Minimizing expectation plus variance. Theory Com-
put. Syst. 57, 617–654 (2015)
15. Mavronicolas, M., Monien, B.: The complexity of equilibria for risk-modeling val-
uations. Theor. Comput. Sci. 634, 67–96 (2016)
16. Nash, J.F.: Equilibrium points in n-person games. Proc. Nat. Acad. Sci. U.S.A.
36, 48–49 (1950)
17. Nash, J.F.: Non-cooperative games. Ann. Math. 54, 286–295 (1951)
18. von Neumann, J.: Zur theorie der gesellschaftsspiele. Math. Ann. 100, 295–320
(1928)
19. Ponstein, J.: Seven kinds of convexity. SIAM Rev. 9, 115–119 (1967)
20. Rockafellar, R.T., Uryasev, S.: Optimization of conditional value-at-risk. J. Risk
2, 21–42 (2000)
21. Rockafellar, R.T., Uryasev, S.: Conditional value-at-risk for general loss distribu-
tions. J. Bank. Finan. 26, 1443–1471 (2002)
22. Rubinstein, A.: Lecture Notes in Microeconomic Theory. Princeton University
Press, Princeton (2006)
23. Sarykalin, S., Serraino, G., Uryasev, S.: Value-at-risk vs. conditional value-at-risk
in risk management and optimization. In: Tutorials in Operations Research, Chap.
13 (2008)
24. Sharpe, W.F.: A simpliﬁed model for portfolio analysis. Manag. Sci. 9, 277–293
(1963)
25. Sharpe, W.F.: Mutual fund performance. J. Bus. 39, 119–138 (1966)
26. Steinbach, M.C.: Markowitz revisited: mean-variance models in ﬁnancial portfolios.
SIAM Rev. 43, 31–85 (2001)
27. Stoyanov, S.V., Rachev, S.T., Fabozzi, F.: Optimal ﬁnancial portfolios. Appl.
Math. Fin. 14, 401–436 (2007)
28. Uryasev, S.: Conditional value-at-risk: optimization algorithms and applications.
In: Financial Engineering News, no. 14, February 2000
29. Uryasev, S.: Optimization Using CV@R – Algorithms and Applications. Lecture
Notes, Notes 7, Stochastic Optimization ESI 6912, University of Florida
30. Yang, X., Tao, S., Liu, R., Cai, M.: Complexity of scenario-based portfolio optimiza-
tion problem with VaR objective. Int. J. Found. Comput. Sci. 13, 671–679 (2002)

Congestion Games, Network and
Opinion Formation Games

Reconciling Selﬁsh Routing with Social Good
Soumya Basu(B), Ger Yang, Thanasis Lianeas, Evdokia Nikolova,
and Yitao Chen
The University of Texas at Austin, Austin, USA
basusoumya@utexas.edu
Abstract. Selﬁsh routing is a central problem in algorithmic game
theory, with one of the principal applications being that of routing in
road networks. Inspired by the emergence of routing technologies and
autonomous driving, we revisit selﬁsh routing and consider three pos-
sible outcomes of it: (i) θ-Positive Nash Equilibrium ﬂow, where every
path that has non-zero ﬂow on all of its edges has cost no greater than
θ times the cost of any other path, (ii) θ-Used Nash Equilibrium ﬂow,
where every used path that appears in the path ﬂow decomposition has
cost no greater than θ times the cost of any other path, and (iii) θ-Envy
Free ﬂow, where every path that appears in the path ﬂow decomposi-
tion has cost no greater than θ times the cost of any other path in the
path ﬂow decomposition. We ﬁrst examine the relations of these out-
comes among each other and then measure their possible impact on the
network’s performance. Right after, we examine the computational com-
plexity of ﬁnding such ﬂows of minimum social cost and give a range
for θ for which this task is easy and a range of θ for which this task is
NP-hard for the concepts of θ-Used Nash Equilibrium ﬂow and θ-Envy
Free ﬂow. Finally, we propose strategies which, in a worst-case approach,
can be used by a central planner in order to provide good θ-ﬂows.
1
Introduction
Two Sides of the Coin: Social Welfare vs Selﬁshness. A fundamental
problem arising in the management of road-traﬃc and communication networks
is routing traﬃc to optimize network performance. In the setting of road-traﬃc
networks the average delay incurred by a unit of ﬂow quantiﬁes the cost of a
routing assignment. From a collective perspective minimizing the average cost
translates to maximizing the welfare obtained by society. Starting from the sem-
inal works of Wardrop [24] and Beckman et al. [2], the literature on network
games has diﬀerentiated between (1) the objective of a central planner to min-
imize average cost and thus ﬁnd a socially optimal (SO) ﬂow, and (2) the self-
ish objectives of users minimizing their respective costs. In the latter case, the
network users acting in their own interest are assumed to converge to a Nash
Equilibrium (NE) ﬂow as further rerouting fails to improve their own objective.
The tension between the central planner and individual users has been an
object of intense study and solutions such as toll placement or Stackelberg rout-
ing (e.g., [2,15,19]) have been proposed in the past, each facing criticism in terms
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 147–159, 2017.
DOI: 10.1007/978-3-319-66700-3 12

148
S. Basu et al.
of implementation and fairness towards various users. To mitigate this tension
in a way that is more fair to the users, we set out to explore the properties of
alternative solution concepts where users under some reasonable incentive con-
dition adopt a more “socially desirable” routing of traﬃc in between the Nash
equilibrium (which has high social cost) and the social optimum (which may
be undesirable/unfair to users on the longer paths) [20]. The advent of routing
applications and the growing dependence of users on these applications places
us at an epoch when such new ideas in mechanism design may be more relevant
and also more readily integrated to practice.
Consider the scenario where some routing application presents the unin-
formed users with routes alongside the guarantees of “relative fairness” and
“reasonable delay” and the users adopt the paths. In this scenario, one may nat-
urally bring forth the questions of whether there exist solutions (ﬂows) where
good social welfare is achieved under an appropriate incentive condition for the
users and if such solutions can be eﬃciently computed. An example of such a
solution could be enforcing a θ-approximate Nash equilibrium of low social cost,
where users are guaranteed to get assigned a path of cost no greater than θ times
the cost of the shortest path and as such, the solution is “relatively fair”.1 Yet,
other solution concepts seem to arise naturally and are introduced below.
Selﬁshness and Envy. To achieve the coveted middle ground between the
social optimum and Nash equilibrium, by combining good social welfare with
satisﬁed users, we consider equilibria notions related to: (1) selﬁshness and (2)
envy. First, we consider selﬁshness where users tend to selﬁshly improve their
own cost. Here we make the distinction between positive paths, i.e. paths that
have positive ﬂow in all of their edges (note, this is independent of the path
ﬂow decomposition), and used paths, i.e. paths that appear in the path ﬂow
decomposition with positive ﬂow. With these deﬁnitions we deﬁne a θ-Positive
Nash Equilibrium (θ-PNE)2 to be a ﬂow in which the length of any positive path
in the network is less than or equal to θ times the length of any other path,
and a θ-Used Nash Equilibrium (θ-UNE) to be a ﬂow in which the length of
any used path in the network is less than or equal to θ times the length of any
other path. As we shall see, the set of θ-PNE ﬂows is in general a strict subset
of the set of θ-UNE ﬂows, though for θ = 1 these sets coincide. The deﬁnition
of θ-approximate Nash equilibrium [9] corresponds to that of θ-UNE.
Next, we consider the notion of envy where for the same source and desti-
nation a user experiences envy against another user if the latter incurs smaller
delay compared to the former under a given path ﬂow. Similarly to the approxi-
mate Nash equilibrium ﬂow we can consider a notion of approximately envy free
ﬂows where in a θ-Envy Free (θ-EF) ﬂow, the ratio of any two used paths in
1 The concept of fairness in selﬁsh routing has been considered in the past, with the
two main approaches deﬁning fairness as: (1) the ratio of the maximum path delay
in a given ﬂow to the average delay under Nash equilibrium [20] and (2) the ratio of
the maximum path delay to the minimum path delay in a given ﬂow [11].
2 In the literature, PNE is typically used for abbreviating Pure Nash Equilibrium, but
we always use it to denote Positive Nash Equilibrium, as deﬁned here.

Reconciling Selﬁsh Routing with Social Good
149
the network is upper bounded by θ, for some θ ≥1. Note, the diﬀerence from
the θ-UNE deﬁnition is that a used path’s cost is compared only to other used
paths’ costs. Envy free ﬂows arise naturally once we consider the routing appli-
cations setup where users only collect information about the routes provided by
the application. On the one hand, the possible costs for the current users in some
sense compare to the costs of the users that have already used the network. On
the other hand, routes for which there is no (suﬃcient) information, i.e., routes
that have not been chosen in the past (suﬃciently many times), potentially may
never appear as an option. Another motivation for a θ-EF ﬂow arises from the
literature on imitation games, e.g. [14], where users imitate other users with
lower delay and jointly reach a ﬁxed point which is a 1-EF ﬂow.
An example of how the concepts of θ-PNE, θ-UNE, and θ-EF may diﬀer from
each other is illustrated in Fig. 1, with the details discussed in Sect. 3, where these
notions are formally introduced.
Related Work. Starting from the seminal work of Koutsoupias and Papad-
mitriou [18], quantifying the worst case ineﬃciency of various non-cooperative
games, including routing games, quickly became an intense area of research. In
a routing game with arbitrary latency functions the ratio between the cost of
a Nash equilibrium (NE) ﬂow to the cost of a socially optimal (SO) ﬂow may
grow unbounded, as shown by Roughgarden and Tardos [22]. A series of papers
have focused on developing techniques for bounding the ineﬃciency of the NE
ﬂow (e.g., [12,16,22]).
Considering the generalization to approximate NE ﬂows, Caragiannis
et al. [5–7] provided existential and computational results regarding approxi-
mate equilibria in weighted and unweighted atomic congestion games. Feldmann
et al. [13] also considered computational issues for approximate equilibria and
applied the method of randomized rounding to analyze which approximation
guarantees can be achieved for atomic congestion games with latency functions in
speciﬁc classes. Chen and Sinclair [8], focusing again on atomic congestion games,
studied questions related to convergence times to approximate Nash equilibria.
Christodoulou et al. [9] studied the performance of approximate Nash equilibria
for atomic and non-atomic congestion games with polynomial latency functions
by considering how much the price of anarchy worsens and how much the price
of stability improves as a function of the approximation factor θ.
In a related thread of research, Jahn et al. [17] formalized the notion of con-
strained system optimal, where additional constraints were added along with the
ﬂow feasibility constraints. The additional constraints were introduced to reduce
the unfairness of the resulting ﬂow. Further, useful insights were obtained by
Schulz and Stier-Moses [23] about the social welfare and fairness of these con-
strained system optimal ﬂows. Recently, there have been eﬀorts [3,4] in quan-
tifying the ineﬃciency needed to guarantee fairness among users. The authors
there deﬁned the ‘price of fairness’ as the proportional decrease of utility under
fair resource allocation. As mentioned earlier, in routing games the fairness of
socially optimal ﬂows under diﬀerent but related deﬁnitions has been studied by
Roughgarden [20] and Correa et al. [10]. Further, Correa et al. [11] considered

150
S. Basu et al.
the fairness and eﬃciency of min-max ﬂows, where the objective is to minimize
the maximum length of any used path in the network and noted how diﬀerent
path ﬂows aﬀect the fairness in the network even when the induced edge ﬂows
are identical.
Contribution. When users ask their routing devices for good origin to destina-
tion paths, they care about the end-to-end delay on their paths without (directly)
caring about local (subpath) optimality conditions. This highlights that the path
ﬂows may play a key role in achieving the full potential for route planning mech-
anisms. On the conceptual side, through the study of the proposed solution
concepts, i.e., the θ-PNE, θ-UNE and θ-EF, we clearly diﬀerentiate path ﬂows
from edge ﬂows and study their varied eﬀects in the balance between fairness
and social cost.
On the technical side, we start by observing that the 1-UNE and the 1-
PNE are indeed identical, which explains why the ‘used’ and the ‘positive’ paths
have not been explicitly diﬀerentiated before this work. Beyond the case of θ =
1, we notice that θ-PNE, θ-UNE and θ-EF ﬂows are progressively larger sets,
each containing the previous one, with promise of better tradeoﬀbetween the
social welfare and fairness. In order to grasp the large separation between these
concepts note that for some networks the θ-UNE is not contained in Ω(nθ)-PNE,
where n is the number of nodes in the network (Lemma 1).
Motivated from the classical study of the price of anarchy (PoA) of equilib-
rium ﬂows we investigate the PoA of θ-UNE and θ-EF. In general we expect that
as we move from θ-PNE to θ-EF ﬂows, from a worst case perspective, we will
encounter ﬂows with larger social cost. As a worst case example we show that
the PoA can be unbounded for 1-EF ﬂows. However, the PoA upper bounds for
both θ-PNE and θ-UNE turn out to be identical (Lemma 3). Our PoA bound
generalizes the PoA bound of 1-PNE from [16]. Through a similar reasoning we
show that the price of stability is non increasing from θ-PNE to θ-EF ﬂows.
We next focus on computing a θ-PNE, a θ-UNE or a θ-EF ﬂow with low
social cost. The convex optimization approach for computing a socially optimal
ﬂow fails due to the non-convexity of the sets of θ-PNE, θ-UNE and θ-EF ﬂows
for θ > 1 (Proposition 1). Formally, we prove (Theorem 1) that obtaining the
best θ-UNE or the best θ-EF ﬂow is NP-hard. Indeed given a socially optimal
ﬂow it is NP-hard to decide whether it admits a path ﬂow decomposition which
is θ-UNE (θ-EF) for arbitrarily large θ (assuming arbitrary latency functions).
However, we leave open the complexity of ﬁnding the best θ-PNE ﬂow (θ > 1).
In the positive direction, we provide an approximation algorithm, based on a
modiﬁed potential function, for designing a θ-PNE ﬂow—which generates θ-EF
and θ-UNE ﬂows—with social cost guarantees. We explicitly derive the approx-
imation ratio upper bound for solving minimization of social cost under the
solution concepts for θ ≥1 for two classes of latency functions which are used
in congestion networks, namely (1) polynomials with positive coeﬃcients, (2)
M/M/1 delay function (Theorem 3). This modiﬁed function approach was used
by Christodoulou et al. [9] to derive upper bound for PoS(θ-UNE) with polyno-
mial latency functions.

Reconciling Selﬁsh Routing with Social Good
151
2
Preliminaries
Network and Flows. Consider a directed graph G = (V, E) and a set of com-
modities K with K = |K|. Each commodity k ∈K is associated with a source
sk, a sink tk, and a demand dk > 0. Each edge e ∈E is given a latency function
ℓe(x), assumed to be standard, i.e. nonnegative, diﬀerentiable, and nondecreas-
ing. We consider the standard nonatomic network congestion game, where each
user routes an inﬁnitesimal amount of ﬂow. Let Pk be the set of simple paths
from sk to tk, and denote P = ∪k∈KPk. A feasible ﬂow can be represented as
a path ﬂow vector f = (fπ)π∈P that satisﬁes all demands, i.e. 
π∈Pk fπ = dk
for all k ∈K. The set of feasible path ﬂow vectors is denoted by Dp. A feasible
path ﬂow vector f, induces a feasible edge ﬂow vector in the network given as
x = (xk
e = 
π∈Pk:e∈π fπ)e∈E,k∈K. The congestion through edge e is the aggre-
gate ﬂow xe = 
k∈K xk
e, for all e ∈E. There may exist multiple feasible path
ﬂows, denoted as the set Dp(x), that give the same edge ﬂow x. We denote the
set of feasible edge ﬂows by DE.
Used and Positive Paths. Given a commodity k ∈K and an edge ﬂow vector
x, path π ∈Pk is positive for commodity k if for all edges e ∈π, xk
e > 0.
(Edge ﬂow xe is insuﬃcient for this deﬁnition.) Given a commodity k ∈K and
a path ﬂow vector f, path π ∈Pk is used by commodity k if fπ > 0 and unused
otherwise. For each commodity k ∈K, we deﬁne the set of positive paths under
edge ﬂow x as Pk
+(x) and the set of used paths under path ﬂow f as Pk
u(f).
Note that a used path is always positive but a positive path may be unused.
Costs and Socially Optimal Flow. Under a path ﬂow f ∈Dp, the cost
(latency) of a path π is deﬁned to be the sum of latencies of edges along the
path: ℓπ(f) = ℓπ(x) = 
e∈π ℓe(xe) for f ∈Dp(x). The social cost (SC) of an
edge ﬂow x ∈DE is SC(x) = 
e∈E xeℓe(xe). The social cost of a path ﬂow is the
social cost of its corresponding edge ﬂow. The socially optimal edge/path ﬂow is
the ﬂow that minimizes social cost among all feasible edge/path ﬂows. The set
of socially optimal edge/path ﬂows is denoted by SOE = {x ∈arg min SC(x)}
and SOp = {f ∈arg min SC(f)}, respectively.
Nash Equilibrium and Eﬃciency. A path ﬂow f is a Nash Equilibrium if
for any commodity k ∈K and any used path p ∈Pk
u(f) we have ℓp(f) ≤ℓq(f),
for all paths q ∈Pk. The eﬃciency of an equilibrium is often measured via the
price of anarchy and the price of stability. Here we generalize them for arbitrary
set of ﬂows as in the following deﬁnitions. Given a set of path ﬂows F and
socially optimal edge ﬂow x∗∈SOE, the price of anarchy (PoA) and the price
of stability (PoS) are deﬁned as
PoA(F) = max
 SC(f)
SC(x∗) : f ∈F

,
PoS(F) = min
 SC(f)
SC(x∗) : f ∈F

.
3
Solution Concepts
Here we give the formal deﬁnition of the solution concepts we introduced in
Sect. 1. We also provide an example to illustrate their diﬀerences, and prove

152
S. Basu et al.
that each solution concept may correspond to a non-convex set of ﬂows. We
begin with the deﬁnitions of the solution concepts:
Deﬁnition 1 (θ-PNE, θ-UNE, and θ-EF).
1. An edge ﬂow x is a θ-Positive Nash Equilibrium (θ-PNE) ﬂow if for any
commodity k ∈K, any positive path p ∈Pk
+(x), and all paths q ∈Pk, we
have ℓp(x) ≤θℓq(x).
2. A path ﬂow f is a θ-Used Nash Equilibrium (θ-UNE) ﬂow if for any com-
modity k ∈K, any used path p ∈Pk
u(f), and all paths q ∈Pk, we have
ℓp(f) ≤θℓq(f).
3. A path ﬂow f is θ-Envy Free (θ-EF) if for any commodity k ∈K, any used
path p ∈Pk
u(f), and all used paths q ∈Pk
u(f), we have ℓp(f) ≤θℓq(f).
For simplicity, we use θ-PNE, θ-UNE or θ-EF to describe the set of θ-PNE,
θ-UNE or θ-EF ﬂows, respectively. Also, we refer to them as θ-fair ﬂows. To see
how these concepts may diﬀer from each other, we give an example in Fig. 1.
1
1
x
x
s
t
π1
π2
(a) Paths π1 and π2 have 1/2 unit of
ﬂow. This path ﬂow assignment is a so-
cial optimum.
1
1
x
x
s
t
Any used path 
has length 1.5
(b) The path ﬂow assignment in Fig-
ure 1(a) is 1-EF but not 1-UNE.
1
1
x
x
s
t
Any used path 
has length 1.5
Shortest path
has length 1
(c) The path ﬂow assignment in Fig-
ure 1(a) is 1.5-UNE but not 1.5-PNE.
1
1
x
x
s
t
Longest positive 
path has length 2
Shortest path
has length 1
(d) The path ﬂow assignment in Fig-
ure 1(a) is 2-PNE.
Fig. 1. Example illustrating the three solution concepts θ-UNE, θ-PNE and θ-EF.
Our goal is to examine the properties of θ-fair ﬂows and provide ways to
obtain such ﬂows with good social cost. Regarding the second direction, in gen-
eral, the sets of θ-PNE, θ-UNE, and θ-EF ﬂows may not be convex and may
contain multiple path ﬂows, which raises the level of diﬃculty for computing
good or optimal such ﬂows. Next, we present an example that demonstrates the
non-convexity of these sets (Fig. 2).
Proposition 1 (Non-convexity of θ ﬂows). There exists an instance such
that the sets θ-PNE, θ-UNE, and θ-EF are not convex, for some θ > 1.

Reconciling Selﬁsh Routing with Social Good
153
x
x
u
s
t
v
s-u-v-t
f1:
with flow 1
s-u-t
f2:
with flow 2/3
s-v-t
with flow 1/3
f3: s-u-v-t with flow 1/2
s-u-t
with flow 1/3
s-v-t
with flow 1/6
Fig. 2. Non-convexity of θ-ﬂows. Both f1 and f2 are 3/2-PNE/UNE/EF, but their
convex combination (with even weights) f3 is not.
The following two lemmas establish the hierarchy among the proposed solu-
tion concepts by showing a crisp containment of various ﬂows. Due to space
constraints, the proofs are presented in the full version [1], Sect. 4.
Lemma 1 (Hierarchy of θ-ﬂows). Given a multi-commodity network, for
θ′ > θ ≥1, F ∈{PNE, UNE, EF} satisﬁes θ-F ⊆θ′-F. Further, for any
θ ≥1, θ-PNE ⊆θ-UNE ⊆θ-EF holds. On the other hand, for any θ ≥1, there
exists a network such that 1-EF ̸⊂θ-UNE.
In the following lemma, we further demonstrate the relationship between the
θ-UNE and θ-PNE. We can see that 1-UNE and 1-PNE both coincide with the
familiar Nash equilibrium.
Lemma 2 (θ-UNE and θ-PNE). Given a multi-commodity network with n
nodes, for any path ﬂow f and its induced edge ﬂow x, f ∈1-UNE if and only
if x ∈1-PNE. Further, for any θ > 1, θ-UNE ⊂((n −1)θ)-PNE holds. On
the other hand, for any θ ≥1.5, there exists a network such that θ-UNE ̸⊂
((n −3)θ/3)-PNE.
We next analyze the cost of the θ-ﬂows. Note that the θ ﬂows are not unique
for θ > 1 and this implies that potentially under each solution concept we can
have a range of attainable costs. From the containment relations of the θ ﬂows
(Lemma 1, Part 2), it follows that for any θ ≥1,
PoA(θ-EF) ≥PoA(θ-UNE) ≥PoA(θ-PNE),
PoS(θ-EF) ≤PoS(θ-UNE) ≤PoS(θ-PNE).
Further, we present upper bounds on the PoA for θ-UNE and θ-PNE ﬂows,
and show that the PoA for 1-EF ﬂow is unbounded. In that eﬀort, we generalize
techniques presented in [16] which was used for bounding PoA(1-PNE). We need
the following deﬁnitions in order to bound PoA:
ω(L, λ) = sup
ℓ∈L
sup
x,x′≥0
(ℓ(x) −λℓ(x′)) x′
xℓ(x)
,
Λ(θ) = {λ ∈R+ : ω(L, λ) ≤1/θ}.
The following lemma summarizes the PoA results for the solution hierarchies.
For the proof refer to the full version [1], Sect. 5.

154
S. Basu et al.
Lemma 3 (PoA of θ-ﬂows). For latency functions in class L, PoA(θ-UNE)
≤infλ∈Λ(θ) θλ(1 −θω(L, λ))−1. On the other hand, there exists a network with
linear latency functions for which the PoA(1-EF) is unbounded.
4
Optimal θ-Flows: Complexity and Approximation
In this section, we ﬁrst discuss the possibility of designing a ﬂow that balances
the fairness and the social cost in the network under the new solution concepts.
The standard convex optimization approaches fail to ﬁnd socially optimal θ ﬂow
as the sets of θ-PNE, θ-UNE and θ-EF ﬂows are all non-convex. We formally
prove that ﬁnding socially optimal θ-UNE or θ-EF ﬂows is NP hard. Then, using
a modiﬁed potential function technique we provide approximation guarantees for
two common classes of latency functions used in congestion network modeling,
namely (1) polynomial and (2) M/M/1.
Consider the instance in Fig. 3. The next proposition states that though the
socially optimal ﬂow—uniquely determined by the edge ﬂow—is unfair in the
worst case, there exist path ﬂows which are fair or almost fair under the concepts
of UNE and EF ﬂows. The proof is in the full version [1], Sect. 7.1.
SO ﬂow:
On each stage, 
•
ﬂow in upper link.
•
ﬂow in lower link. 
Fig. 3. Improved balance: example.
Proposition 2 (Balanced path ﬂows). For the n-stage instance depicted in
Fig. 3 with nϵ = 2, the socially optimal edge ﬂow is a 2-PNE. Moreover, the
socially optimal ﬂow admits path ﬂows which are 1-EF or (1 + 1/n)-UNE.
4.1
Existence and Complexity
The previous motivating example naturally leads to the following computational
problems given a θ ≥1.
– (P1) Find a θ-EF path ﬂow with the minimal social cost.
– (P2) Find a θ-UNE path ﬂow with the minimal social cost.
– (P3) Find a θ-PNE edge ﬂow with the minimal social cost.
Existence of Polynomial-Size Solutions. An observation to Problem (P1)
and (P2) is that the outputs of these two problems are path ﬂow vectors, which
are potentially of exponential size relative to the problem instances. The follow-
ing lemma proves the existence of polynomial sized path ﬂows, in absence of
which there is no hope to ﬁnd a polynomial time algorithm for these problems.

Reconciling Selﬁsh Routing with Social Good
155
Lemma 4 (Existence of polynomial-size solutions). Given a θ-EF (or a
θ-UNE) path ﬂow f, there exists a θ-EF (resp., a θ-UNE) path ﬂow f ′ that uses
at most |E| paths for each source-sink pair and has the same edge ﬂow as f.
Computational Complexity. We show that for large θ, the socially opti-
mal ﬂow is guaranteed to be contained in those θ-ﬂows, and hence the optimal
θ-ﬂows can be computed eﬃciently. However, for small θ, we will show that solv-
ing Problem (P1) and Problem (P2) is NP-hard, while it remains open whether
Problem (P3) can be computed eﬃciently. More precisely, for a latency class
L, this particular threshold is γ(L) = min{γ : ℓ∗(x) ≤γℓ(x), ∀ℓ∈L, ∀x ≥0},
where ℓ∗(x) = ℓ(x) + xℓ′(x). The main result of this section is:
Theorem 1 (Computational Complexity of (P1)–(P3)). For any multi
commodity instance with latency functions in any class L, there is a polynomial
time algorithm for solving Problem (P1)–(P3) for θ ≥γ(L). On the other hand,
it is NP-hard to solve Problem (P1) for θ ∈[1, γ(L)) and Problem (P2) for
θ ∈(1, γ(L)), for arbitrary single commodity instances with latency functions in
an arbitrary class L.
The ﬁrst part of Theorem 1 follows easily from the following lemma in [11].
Lemma 5 (P1)–(P3) for θ ≥γ(L) are easy [11]). For an instance with
latency functions in L, any socially optimal path ﬂow f ∈SOp is γ(L)-PNE.
For the proof of the second part of Theorem 1, we consider the class of poly-
nomial functions of degree at most p, denoted by Lp. We note that γ(Lp) = p+1.
We show that when the latency functions are in Lp, then the related decision
problems we state in Theorem 2, stated below, have polynomial-time reductions
from the NP-complete problem PARTITION.
Theorem 2 (NP-hardness of (P1) and (P2)). For an arbitrary single com-
modity instance with latency functions in class Lp for p ≥1, it is NP-hard to
1. decide whether a socially optimal ﬂow has a θ-UNE path ﬂow decomposition
for θ ∈(1, p + 1).
2. decide whether a socially optimal ﬂow has a θ′-EF path ﬂow decomposition
for θ′ ∈[1, p + 1).
Proof. (Proof Sketch) For lack of space we present a proof sketch mentioning
the ﬂow of key ideas behind the proof. The proof is divided into two parts.
For the ﬁrst part, we show the NP-hardness for 1.5-UNE and 1-EF path ﬂow
decompositions under the social optimum in Lemma 6, based on the construction
in Theorem 3.3 in Correa et al. [11]. Then, in the second part, we propose a novel
way to generalize the construction to the entire range of θ and θ′ speciﬁed in
Theorem 2.

156
S. Basu et al.
Construction. Let G(q) be the two-link parallel network with the top link eu
having latency ℓu(x) = q and the bottom link eb having latency ℓb(x) = qx.
Given an instance of the PARTITION problem, q1, . . . , qn, n
i=1 qi = 2B, we
now construct a single commodity network as the two-link n-stage network G,
shown in Fig. 4. In stage i we connect G(qi−1) to G(qi) to the right for i = 2 to
n. A unit demand has to be routed from the source in G(q1) to the destination
in G(qn). Finally, we augment to the right of G a two-link parallel network G′.
For G′ the top link latency is ℓu,(n+1)(x) = axp + b and bottom link latency is
ℓd,(n+1)(x) = cxp. We set a =
αB
(1−3/8B)p , b = βB(p + 1), and c = (α+β)B
(3/8B)p , where
α, β > 0 are appropriate parameters (speciﬁed in the proof of Theorem 1 in the
full version [1]). We call the entire network H.
c
SO ﬂow: 
1) On each stage of , 
•
ﬂow in upper link.
•
ﬂow in lower link.
2) On the last stage, 
,
•
ﬂow in upper link.
•
ﬂow in lower link.
Fig. 4. An instance of congestion game constructed from a given instance of PARTI-
TION.
Lemma 6 states that it is NP-hard to ﬁnd 1.5-UNE and 1-EF path ﬂow
decompositions under the social optimum.
Lemma 6 (Hardness Result in G).
For single commodity instances with
linear latency functions it is NP-hard to decide whether a social optimum ﬂow
has a 1.5-UNE ﬂow decomposition or a 1-EF ﬂow decomposition.
Ampliﬁcation of Hardness. The next step is to amplify the hardness result
to all θ ∈(1, p + 1) for UNE and to all θ′ ∈[1, p + 1) for EF ﬂows. The key
observation that facilitates this ampliﬁcation is the following claim.
Claim 1. If the answer to PARTITION is NO then in the sub-network G any
path decomposition of the socially optimal ﬂow o routes at least
1
2B amount of
ﬂow through paths of length strictly greater than 3
2B.
Through careful combination of the paths it is shown that the socially optimal
ﬂow is a c1-UNE and c2-EF ﬂow if and only if the given PARTITION instance
has a YES answer. Here c1 and c2 are constants given by
c1 = α + β + βp + 3
2
1 + α + β
= 1 +
1
2 + βp
1 + α + β ,
c2 = α + β + βp + 3
2
2 + α + β
= 1 + −1
2 + βp
2 + α + β .

Reconciling Selﬁsh Routing with Social Good
157
4.2
Approximation Using Modiﬁed Potential Functions
In this section, we provide a modiﬁed potential function based approximation
algorithm to problems (P1), (P2) and (P3). The idea of modiﬁed potential func-
tions was introduced for bounding the PoS of approximate Nash equilibria in [9].
For a given θ this approach produces a θ-PNE and, due to containment, any fea-
sible path ﬂow corresponding to the edge ﬂow will be in θ-UNE and θ-EF.
Algorithm 1. Modiﬁed Potential Algorithm
Input: Multi-commodity network G, θ.
Output: Edge ﬂow xA ∈θ-PNE and path ﬂow fA ∈θ-UNE ∩θ-EF .
1: For all e ∈E choose φe(x) ∈[ℓe(s)/θ, ℓe(x)] (Speciﬁed later.)
2: Compute xA = argminx∈F

e∈E
 xe
x=0 φe(x)dx.
3: Compute any path decomposition fA of xA.
Theorem 3 characterizes the performance of Algorithm 1 for two important
classes of latency functions which are used for modeling congestion networks—
(1) Polynomial latency with positive coeﬃcients, and (2) M/M/1 latency.
Theorem 3 (Performance of Algorithm 1). Given a multi-commodity net-
work G and θ ≥1 the algorithm produces an edge ﬂow that is θ-PNE and a path
ﬂow that is both θ-UNE and θ-EF.
(1) Polynomial Latency: Additionally, let the latency function ℓe(x) =
p
k=0 ae,kxk, ae,k ≥0, for all e ∈E and some ﬁnite p. Algorithm 1 with
φe(x) = p
k=0 ζkae,kxk, ζk = (1 + min{k, θ −1})/θ for all e ∈E, k ≤p, is
a

θ

1 −
p
1+p

θ
1+p
1/p−1
-approximation algorithm for the problems (P1),
(P2) and (P3).
(2) M/M/1 Latency: Additionally, let the latency function ℓe(x) = 1/(ue−
x) with ue > 0, ρe = dtot/ue and ρmax = maxe∈E ρe < 1, for all e ∈E. Algo-
rithm 1 with φe(x) = 1/(aeue −x), ae = {0, 1 −θ(1 −ρ)}/ρ for all e ∈E, is a
1
2

1 +
1
√
1−ρmax(θ)

-approximation algorithm for the problems (P1), (P2) and
(P3), where ρmax(θ) = max{0, 1 −θ(1 −ρmax)}.
The ﬁrst part of Theorem 3 (i.e., the output being θ ﬂows) follows from the
idea, that a 1-PNE ﬂow under the modiﬁed potential is a θ-PNE ﬂow under the
original latency functions. To prove the second part, we bound the ineﬃciency of
the ﬂow xA as the PoA(1-PNE) under the modiﬁed potential functions, which in
turn serves as an approximation ratio for the minimization of social cost under
θ-PNE (P3), θ-UNE (P2) and θ-EF (P1). Using proper functions φe(·) along
with the λ-μ smoothness framework [21] we strictly improve the approximation
ratio from PoA(1-PNE). Recall the trivial solution—1-PNE ﬂow which can be
computed eﬃciently gives an approximation ratio of PoA(1-PNE). The choice of
φe(·) and the subsequent bounds for polynomial latencies were presented in [9],

158
S. Basu et al.
but for upper bounding PoS(θ-UNE). The detailed proofs are presented in the
full version [1], Sect. 7.2.
Acknowledgements. This work was supported in part by NSF grant numbers CCF-
1216103, CCF-1350823 and CCF-1331863. Part of the research was performed while a
subset of the authors were at the Simons Institute in Berkeley, CA in Fall 2015.
References
1. Basu, S., Yang, G., Lianeas, T., Nikolova, E., Chen, Y.: Reconciling selﬁsh routing
with social good. arXiv:1707.00208 (2017)
2. Beckmann, M., McGuire, C., Winsten, C.B.: Studies in the economics of trans-
portation. Technical report (1956)
3. Bertsimas, D., Farias, V.F., Trichakis, N.: The price of fairness. Oper. Res. 59(1),
17–31 (2011)
4. Bertsimas, D., Farias, V.F., Trichakis, N.: On the eﬃciency-fairness trade-oﬀ.
Manag. Sci. 58(12), 2234–2250 (2012)
5. Caragiannis, I., Fanelli, A., Gravin, N., Skopalik, A.: Computing approximate pure
nash equilibria in congestion games. ACM SIGecom Exch. 11(1), 26–29 (2012)
6. Caragiannis, I., Fanelli, A., Gravin, N., Skopalik, A.: Approximate pure nash equi-
libria in weighted congestion games: existence, eﬃcient computation, and structure.
ACM Trans. Econ. Comput. 3(1), 2 (2015)
7. Caragiannis, I., Flammini, M., Kaklamanis, C., Kanellopoulos, P., Moscardelli,
L.: Tight bounds for selﬁsh and greedy load balancing. In: Bugliesi, M., Preneel,
B., Sassone, V., Wegener, I. (eds.) ICALP 2006. LNCS, vol. 4051, pp. 311–322.
Springer, Heidelberg (2006). doi:10.1007/11786986 28
8. Chien, S., Sinclair, A.: Convergence to approximate nash equilibria in congestion
games. In: SODA (2007)
9. Christodoulou, G., Koutsoupias, E., Spirakis, P.G.: On the performance of approx-
imate equilibria in congestion games. Algorithmica 61(1), 116–140 (2011)
10. Correa, J.R., Schulz, A.S., Stier Moses, N.E.: Computational complexity, fairness,
and the price of anarchy of the maximum latency problem. In: Bienstock, D.,
Nemhauser, G. (eds.) IPCO 2004. LNCS, vol. 3064, pp. 59–73. Springer, Heidelberg
(2004). doi:10.1007/978-3-540-25960-2 5
11. Correa, J.R., Schulz, A.S., Stier-Moses, N.E.: Fast, fair, and eﬃcient ﬂows in net-
works. Oper. Res. 55(2), 215–225 (2007)
12. Correa, J.R., Schulz, A.S., Stier-Moses, N.E.: A geometric approach to the price
of anarchy in nonatomic congestion games. Games Econ. Behav. 64(2), 457–469
(2008)
13. Feldmann, A.E., R¨oglin, H., V¨ocking, B.: Computing approximate nash equilibria
in network congestion games. In: Shvartsman, A.A., Felber, P. (eds.) SIROCCO
2008. LNCS, vol. 5058, pp. 209–220. Springer, Heidelberg (2008). doi:10.1007/
978-3-540-69355-0 18
14. Fischer, S., V¨ocking, B.: On the evolution of selﬁsh routing. In: Albers, S., Radzik,
T. (eds.) ESA 2004. LNCS, vol. 3221, pp. 323–334. Springer, Heidelberg (2004).
doi:10.1007/978-3-540-30140-0 30
15. Fleischer, L., Jain, K., Mahdian, M.: Tolls for heterogeneous selﬁsh users in mul-
ticommodity networks and generalized congestion games. In: FOCS (2004)

Reconciling Selﬁsh Routing with Social Good
159
16. Harks, T.: On the price of anarchy of network games with nonatomic and atomic
players. Technical report, available at Optimization Online (2007)
17. Jahn, O., M¨ohring, R.H., Schulz, A.S., Stier-Moses, N.E.: System-optimal routing
of traﬃc ﬂows with user constraints in networks with congestion. Oper. Res. 53(4),
600–616 (2005)
18. Koutsoupias, E., Papadimitriou, C.: Worst-case equilibria. In: Meinel, C., Tison,
S. (eds.) STACS 1999. LNCS, vol. 1563, pp. 404–413. Springer, Heidelberg (1999).
doi:10.1007/3-540-49116-3 38
19. Roughgarden, T.: Stackelberg scheduling strategies. In: STOC (2001)
20. Roughgarden, T.: How unfair is optimal routing? In: SODA (2002)
21. Roughgarden, T.: Intrinsic robustness of the price of anarchy. J. ACM (JACM)
62(5), 32 (2015)
22. Roughgarden, T., Tardos, ´E.: How bad is selﬁsh routing? J. ACM (JACM) 49(2),
236–259 (2002)
23. Schulz, A.S., Stier-Moses, N.E.: Eﬃciency and fairness of system-optimal routing
with user constraints. Networks 48(4), 223–234 (2006)
24. Wardrop, J.G.: Some Theoretical Aspects of Road Traﬃc Research (1952)

Selﬁsh Network Creation with Non-uniform
Edge Cost
Ankit Chauhan, Pascal Lenzner(B), Anna Melnichenko, and Louise Molitor
Algorithm Engineering Group, Hasso Plattner Institute, Potsdam, Germany
{ankit.chauhan,pascal.lenzner,anna.melnichenko,louise.molitor}@hpi.de
Abstract. Network creation games investigate complex networks from
a game-theoretic point of view. Based on the original model by Fabrikant
et al. [PODC’03] many variants have been introduced. However, almost
all versions have the drawback that edges are treated uniformly, i.e. every
edge has the same cost and that this common parameter heavily inﬂu-
ences the outcomes and the analysis of these games.
We propose and analyze simple and natural parameter-free network
creation games with non-uniform edge cost. Our models are inspired by
social networks where the cost of forming a link is proportional to the
popularity of the targeted node. Besides results on the complexity of
computing a best response and on various properties of the sequential
versions, we show that the most general version of our model has con-
stant Price of Anarchy. To the best of our knowledge, this is the ﬁrst
proof of a constant Price of Anarchy for any network creation game.
1
Introduction
Complex networks from the Internet to various (online) social networks have
a huge impact on our lives and it is thus an important research challenge to
understand these networks and the forces that shape them. The emergence of the
Internet was one of the driving forces behind the rise of Algorithmic Game The-
ory [26] and it has also kindled the interdisciplinary ﬁeld of Network Science [6],
which is devoted to analyzing and understanding real-world networks. Game-
theoretic models for network creation lie in the intersection of both research
directions and yield interesting insights into the structure and evolution of com-
plex networks. In these models, agents are associated to nodes of a network and
choose their neighbors selﬁshly to minimize their cost. Many such models have
been proposed, most prominently the models of Jackson and Wolinsky [16], Bala
and Goyal [5] and Fabrikant et al. [14], but almost all of them treat edges equally,
that is, they assume a ﬁxed price for establishing any edge which is considered
as a parameter of these games. This yields very simple models but has severe
inﬂuence on the obtained equilibria and their properties.
We take a radical departure from this assumption by proposing and analyzing
a variant of the Network Creation Game [14] in which the edges have non-uniform
cost which solely depends on the structure of the network. In particular, the cost
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 160–172, 2017.
DOI: 10.1007/978-3-319-66700-3 13

Selﬁsh Network Creation with Non-uniform Edge Cost
161
of an edge between agent u and v which is bought by agent u is proportional
to v’s degree in the network, i.e. edge costs are proportional to the degree of
the other endpoint involved in the edge. Thus, we introduce individual prices for
edges and at the same time we obtain a simple model which is parameter-free.
Our model is inspired by social networks in which the nodes usually have
very diﬀerent levels of popularity which is proportional to their degree. In such
networks connecting to a celebrity usually is expensive. Hence, we assume that
establishing a link to a popular high degree node has higher cost than con-
necting to an unimportant low degree node. Moreover, in social networks links
are formed mostly locally, e.g. between agents with a common neighbor, and
it rarely happens that links are removed, on the contrary, such networks tend
to get denser over time [20]. This motivates two other extensions of our model
which consider locality and edge additions only.
1.1
Model and Notation
Throughout the paper we will consider unweighted undirected networks G =
(V, E), where V is the set of nodes and E is the set of edges of G. Since edges
are unweighted, the distance dG(u, v) between two nodes u, v in G is the number
of edges on a shortest path between u and v. For a given node u in a network
G let Nk(u) be the set of nodes which are at distance at most k from node u in
G and let Bk(u) be the set of nodes which are at exactly distance k from node
u (the distance-k ball around u). We denote the diameter of a network G by
D(G), the degree of node u in G, which is the number of edges incident to u, by
degG(u). We will omit the reference to G whenever it is clear from the context.
We investigate a natural variant of the well-known Network Creation Game
(NCG) by Fabrikant et al. [14] which we call the degree price network creation
game (degNCG). In a NCG the selﬁsh agents correspond to nodes in a network
and the strategies of all agents determine which edges are present. In particular,
the strategy Su of an agent u is any subset of V , where v ∈Su corresponds to
agent u owning the undirected edge {u, v}. For v ∈Su we will say that agent u
buys the edge {u, v}. Any strategy vector s which speciﬁes a strategy for each
agent then induces the network G(s), where
G(s) =

V,

u∈V

v∈Su
{u, v}

.
Here we assume that G(s) does not contain multi-edges, which implies that
every edge has exactly one owner. Since edge-ownership is costly (see below)
this assumption trivially holds in any equilibrium network. Moreover, any net-
work G together with an ownership function, which assigns a unique owner for
every edge, determines the corresponding strategy vector. Hence, we use strategy
vectors and networks interchangeably and we assume that the owner of every
edge is known. In our illustrations we indicate edge ownership by directing the
edges away from their owner. We will draw undirected edges if the ownership
does not matter.

162
A. Chauhan et al.
The cost function of agent u in network G(s) consists of the sum of edge
costs for all edges owned by agent u and the distance cost, which is deﬁned as
the sum of the distances to all other nodes in the network if it is connected and
∞otherwise. The main novel feature which distinguishes the degNCG from the
NCG is that each edge has an individual price which is proportional to the degree
of the endpoint which is not the owner. That is, if agent u buys the edge {u, v}
then u’s cost for this edge is proportional to node v’s degree. For simplicity we
will mostly consider the case where the price of edge {u, v} for agent u is exactly
v’s degree without counting edge {u, v}. Thus the cost of agent u in network
G(s) is
costu(G(s)) =

v∈Su
(degG(s)(v) −1) + distG(s)(u).
Note that in contrast to the NCG our variant of the model does not depend
on any parameter and the rather unrealistic assumption that all edges have the
same price is replaced with the assumption that buying edges to well-connected
nodes is more expensive than connecting to low degree nodes.
Given any network G(s), where agent u has chosen strategy Su. We say that
Su is a best response strategy of agent u, if Su minimizes agent u’s cost, given
that the strategies of all other agents are ﬁxed. We say that a network G(s)
is in pure Nash equilibrium (NE), if no agent can strictly decrease her cost by
unilaterally replacing her current strategy with some other strategy. That is, a
network G(s) is in NE if all agents play a best response strategy.
Observe that in the degNCG we assume that agents can buy edges to every
node in the network. Especially in modeling large social networks, this assump-
tion seems unrealistic. To address this, we also consider a restricted version of
the model which includes locality, i.e. where only edges to nodes in distance at
most k, for some ﬁxed k ≥2, may be bought. We call this version the k-local
degNCG (degkNCG) and its pure Nash equilibria are called k-local NE (kNE).
We will mostly consider the case strongest version where k = 2.
We measure the quality of a network G(s) by its social cost, which is simply
the sum over all agents’ costs, i.e. cost(G(s)) = 
u∈V costu(G(s)). Let worstn
and bestn denote the social cost of a (k)NE network on n nodes which has the
highest and lowest social cost, respectively. Moreover, let optn be the minimum
social cost of any network on n nodes. We measure the deterioration due to
selﬁshness by the Price of Anarchy (PoA) which is the maximum over all n of
the ratio worstn
optn . Moreover, the more optimistic Price of Stability (PoS) is the
maximum over all n of the ratio bestn
optn .
The use case of modeling social networks indicates another interesting ver-
sion of the degNCG, which we call the degree price add-only game (degAOG)
and its k-local version degkAOG. In these games, agents can only add edges to
the network whereas removing edges is impossible. This mirrors social networks
where an edge means that both agents know each other.

Selﬁsh Network Creation with Non-uniform Edge Cost
163
1.2
Related Work
Our model is a variant of the well-known Network Creation Game (NCG) pro-
posed by Fabrikant et al. [14]. The main diﬀerence to our model is that in [14]
it is assumed that every edge has price α > 0, where α is some ﬁxed parame-
ter of the game. This parameter heavily inﬂuences the game, e.g. the structure
of the equilibrium networks changes from a clique for very low α to trees for
high α. For diﬀerent regimes of α diﬀerent proof techniques yield a constant
PoA [1,13–15,21,23] but it is still open whether the PoA is constant for all α.
In particular, constant upper bounds on the PoA are known for α < n1−ε, for
any ﬁxed ε >
1
log n [13], and if α > 65n [21]. The best general upper bound is
2O√log n [13]. The dynamics of the NCG have been studied in [17] where it was
shown that there cannot exist a generalized ordinal potential function for the
NCG. Also the complexity of computing a best response has been studied and
its NP-hardness was shown in [14]. If agents resort to simple strategy changes
then computing a best response can trivially be done in polynomial time and
the obtained equilibria approximate Nash equilibria well [19].
Removing the parameter α by restricting the agents to edge swaps was pro-
posed and analyzed in [2,24]. The obtained results are similar, e.g. the best
known upper bound on the PoA is 2O√log n, there cannot exist a potential func-
tion [18] and computing a best response is NP-hard. However, allowing only
swaps leads to the unnatural eﬀects that the number of edges cannot change
and that the sequential version heavily depends on the initial network.
Several versions for augmenting the NCG with locality have been proposed
and analyzed recently. It was shown that the PoA may deteriorate heavily if
agents only know their local neighborhood or only a shortest path tree of the
network [7,8]. In contrast, a global view with a restriction to only local edge-
purchases yields only a moderate increase of the PoA [11].
The idea of having nodes with diﬀerent popularity was also discussed in the
so called celebrity games [3,4]. There, nodes have a given popularity and agents
buy ﬁxed-price edges to get highly popular nodes within some given distance
bound. Hence, this model diﬀers heavily from our model.
To the best of our knowledge, there are only two related papers which analyze
a variant of the NCG with non-uniform edge price. In [12] agents can buy edges
of diﬀerent quality which corresponds to their length and the edge price depends
on the edge quality. Distances are then measured in the induced weighted net-
work. Closer to our model is [22] where heterogeneous agents, important and
unimportant ones, are considered and both classes of agents have diﬀerent edge
costs. Here, links are formed with bilateral agreement [10,16] and important
nodes have a higher weight, which increases their attractiveness.
1.3
Our Contribution
We introduce and analyze the ﬁrst parameter-free variants of Network Creation
Games [14] which incorporate non-uniform edge cost. In almost all known ver-
sions the outcomes of the games and their analysis heavily depend on the edge

164
A. Chauhan et al.
cost parameter α. We depart from this by assuming that the cost of an edge solely
depends on structural properties of the network, in particular, on the degree of
the endpoint to which the edge is bought. Essentially, our models incorporate
that the cost of an edge is proportional to the popularity of the node to which it
connects. This appears to be a realistic feature, e.g. for modeling social networks.
On the ﬁrst glance, introducing non-uniform edge cost seems to be detri-
mental to the analysis of the model. However, in contrast to this, we give a
simple proof that the PoA of the degNCG is actually constant. To the best of
our knowledge, our model is the ﬁrst version of the NCG for which this strong
statement could be established. A constant PoA is widely conjectured for the
original NCG [14] but its proof is despite serious eﬀorts of the community still
an open question. Besides this strongest possible bound on the PoA, which we
also generalize to arbitrary linear functions of a node’s degree and to the 4-local
version, we prove a PoA upper bound of O(√n) for the deg2NCG, where agents
are restricted to act within their 2-neighborhood and we show for this version
that computing a best response strategy is NP-hard. Moreover, we investigate
the dynamic properties of the deg(2)NCG and prove that improving response
dynamics may not converge to an equilibrium, that is, there cannot exist a gen-
eralized ordinal potential function.
We contrast these negative convergence results by analyzing a version where
agents can only add edges, i.e. the deg(2)AOG, where convergence of the sequen-
tial version is trivially guaranteed, and by analyzing the speed of convergence
for diﬀerent agent activation schemes. The restriction to only edge additions
has severe impact on the PoA, yielding a Θ(n) bound, but we show that the
impact on the social cost is low, if round-robin dynamics starting from a path
are considered, where agents buy their best possible single edge in each step.
Due to space constraints, all omitted details can be found in [9].
2
Hardness
In this section we investigate the computational hardness of computing a cost
minimizing strategy, i.e. a best response, in the deg2NCG and in the deg2AOG.
Theorem 1. Computing the best response in the deg2NCG and the deg2AOG
is NP-hard.
3
Analysis of Equilibria
We start with the most fundamental statement about equilibria which is their
existence. We use the center sponsored spanning star Sn, see Fig. 1(a), for the
proof and provide some other examples of NE and 2NE networks in Fig. 1.
Theorem 2. The star Sn is a (k)NE for the deg(k)NCG and the deg(k)AOG
for any k.

Selﬁsh Network Creation with Non-uniform Edge Cost
165
(a) The
NE
network Sn
(b) A NE in the
degAOG/degNCG
with D = 3.
(c) A
2NE
in
the
deg2NCG with D = 4.
(d)
A
2NE
in
the
deg2AOG with D = 5.
Fig. 1. Examples of NE and 2NE networks
3.1
Bounding the Diameter of Equilibrium Networks
We investigate the diameter of (2)NE networks. Analogously to the original
NCG [14], bounding the diameter plays an important role in bounding the PoA.
Theorem 3. Consider variants of the degAOG and the degNCG where the price
of any edge {u, v} bought by agent u is any linear function of v’s degree in G,
that is, priceu({u, v}) = β · degG(s)(v) + γ, where β, γ ∈R. Then the diameter
of any NE network in the degAOG and the degNCG is constant.
Proof. We consider a NE network G = (V, E) and assume that the diameter
D of G is at least 4. Then there exist nodes a, b ∈V , such that dG(a, b) =
D. Therefore, the distance cost of a agent a in G is at least D + |B1(b)|(D −
1) + |N2(a)|. Thus, if agent a buys the edge {a, b} then this improves agent a’s
distance cost by at least D −1 + |B1(b)|(D −3). Since the network G is in NE,
the distance cost improvement must be less than agent u’s cost for buying the
edge {a, b}:
D −1 + |B1(b)|(D −3) ≤β · degG(b) + γ
⇐⇒D −1 + (D −3) · degG(b) ≤β · degG(b) + γ.
Solving for D under the assumption degG(b) ≥1 yields
D ≤(β + 3)degG(b) + γ + 1
degG(b) + 1
< β + 3 +
γ + 1
degG(b) + 1 ∈O(1).
⊓⊔
Using β = 1 and γ = −1 yields the edge price for our version of the degNCG
and the degAOG. This, and the NE example in Fig. 1(b) yields the following:
Corollary 1. The diameter of any NE network in the degAOG and the degNCG
is at most 3 and this upper bound is tight.
Since in the proof of Theorem 3 in the case of β = 1 and γ = −1 buying an edge
to a node in distance 4 suﬃces, we get the following statement.

166
A. Chauhan et al.
Corollary 2. Any 4NE network has diameter at most 3.
Note that the examples in Fig. 1(c) and (d) show that the diameter in the 2-local
version, i.e. in the deg2NCG and the deg2AOG, can exceed 3. We prove a higher
upper bound on the diameter for the 2-local versions.
Theorem 4. The diameter of any 2NE network is in O(√n).
Proof. Consider a 2NE network G = (V, E) with |V | = n and let D denote its
diameter. Consider two nodes a, b ∈V such that dG(a, b) = D and a shortest-
path tree Ta = (V, Ea) which is rooted at node a (see Fig. 2).
c
b
a
Tc
L0
L1
L2
LD−1
LD
LD−2
Fig. 2. The shortest-path tree Ta. Dashed lines denote edges of G which are not in the
tree, i.e. the non-tree edges.
The height of Ta is D and there must be a subtree Tc which contains node b and
which has node c as root, where c is chosen such that dG(a, c) = 2 and c belongs
to the path from a to b in Ta. Since the height of Tc is D −2 it follows that the
number of nodes in Tc must be at least D −1. Let |Tx| denote the number of
nodes in the subtree of Ta rooted at node x. Hence, we have |Tc| ≥D −1.
Note that if agent a buys any edge {a, x} in network G then this improves
a’s distance cost by at least |Tx|. Since G is in 2NE, we know that buying the
edge {a, c} is not an improving move for agent a which implies that |Tc| is at
most the cost of the edge {a, c} which is equal to degG(c). Since |Tc| ≥D −1 it
follows that degG(c) ≥D −1.
Let Li denote the set of nodes which are in distance i from the root a in the
tree Ta. For example L0 = {a}, c ∈L2 and b ∈LD. Thus, we have D −1 ≤
degG(c) ≤|L1| + (|L2| −1) + |L3|.
Analogously, since G is in 2NE, we have that no agent vi in layer Li on the
c −b path in Ta can decrease her cost by buying an edge to a node in layer Li+2
which is a neighbor of a neighbor in Ta. With analogue reasoning as above we
get D −(i −1) ≤degG(vi) ≤|Li−1| + (|Li| −1) + |Li+1|.
Note that not only agents from lower layers cannot improve by buying edges
towards nodes in upper layers but also agents from upper layers cannot improve
by buying edges towards nodes in lower layers. Thus we have

Selﬁsh Network Creation with Non-uniform Edge Cost
167
D −(i −1) ≤degG(vi) ≤|Li−1| + (|Li| −1) + |Li+1|
and
D −(i −1) ≤degG(vD−i) ≤|LD−i−1| + (|LD−i| −1) + |LD−i+1|
for any 2 ≤i ≤
 D
2

−1. Summing up all inequalities yields:
2
⌊D
2 ⌋−1

i=2
	
D −(i −1)

≤3
 D

i=1
|Li| −(D −1)

.
For the left side we have
3D2
4
−4D −3 <
D
2

−2
 
2D + 1 −
D
2

= 2
⌊D
2 ⌋−1

i=2
	
D −(i −1)

and the right side gives 3
D
i=1 |Li| −(D −1)

≤3n −3D + 3, which yields
3D2
4
−4D −3 < 3n −3D + 3 ⇒D < 2
3
	
1 +
√
9n + 19

∈O(√n).
⊓⊔
3.2
Price of Stability
For analyzing the Price of Stability, we have to investigate the network which
has the minimum possible social cost.
Lemma 1. The center sponsored spanning star Sn is an optimal solution of the
deg(k)NCG and the deg(k)AOG for any k.
We have shown in the proof of Theorem 2 that the center sponsored spanning
star Sn is in (k)NE for any k. With Lemma 1 this yields the following for k ≥2.
Corollary 3. The Price of Stability of the deg(k)NCG and the deg(k)AOG is 1.
3.3
Price of Anarchy
For investigating the quality of the equilibria of our games, we ﬁrst adapt an
important lemma by Fabrikant et al. [14] to our setting.
Lemma 2. If a (k)NE network G in the deg(k)NCG has diameter D, then its
social cost is at most O(D) times the minimum possible social cost.
From Corollaries 1 and 2 we know that the diameter of any NE in the degNCG
and any 4NE in the deg4NCG is at most 3. Also, from the Lemma 2 we know
that the social cost of any NE network G is at most O(D(G)) times the minimum
possible social cost. This implies the following statement.

168
A. Chauhan et al.
Theorem 5. The Price of Anarchy of the degNCG and the deg4NCG is in O(1).
A straightforward adaptation of Lemma 2 together with Theorem 3 yields:
Corollary 4. The Price of Anarchy of variants of the degNCG where the price
of any edge {u, v} bought by agent u is linear in v’s degree in G, is constant.
Using Theorem 4 and Lemma 2 yields the following statement.
Corollary 5. The Price of Anarchy of the deg2NCG is in O(√n).
We conclude with analyzing the PoA in the deg(k)AOG. The upper bound is
trivially in O(n), the matching lower bound holds, since a clique is in (k)NE for
the deg(k)AOG for any k.
Observation 6. The Price of Anarchy of deg(k)AOG is in Θ(n) for any k.
4
Dynamics
In this section we consider the dynamic properties of the sequential version of
the deg(k)NCG and the deg(k)AOG. The sequential version corresponds to an
iterative process, called improving response dynamics (IRD), which starts with
some initial strategy vector s and its corresponding initial network G(s) and
then agents are activated one at a time according to some activation scheme,
e.g. a random or adversarially chosen move order or round-robin activation, and
active agents are allowed to myopically update their current strategy. They will
do so only if the new strategy yields strictly less cost than their current strategy.
For the deg(2)AOG we will also consider the best single edge dynamics, which is
a special case of the improving response dynamics, in which active agents buy
the best possible single edge, if this strictly decreases their current cost.
The most important dynamic property of a game is the ﬁnite improvement
property (FIP) [25], which states that any sequence of improving moves must
be ﬁnite. The seminal paper [25] established that having the FIP is equivalent
to being a generalized ordinal potential game. Thus, games having the FIP are
guaranteed to converge to an equilibrium under improving move dynamics.
4.1
Dynamics in the deg(k)NCG
We investigate the convergence properties of the deg(k)NCG and prove that the
deg(k)NCG may not converge under improving move dynamics.
Theorem 7. The deg(k)NCG does not have the FIP for any k, which implies
that these games cannot have a generalized ordinal potential function.
Proof (Sketch). See Fig. 3 for an improving response cycle.
Remark 1. The presented improving response cycle in Fig. 3 is not a best
response cycle for the deg(k)NCG since in network G3 agent j has a strictly
better local move: Buying the edge to agent h and swapping her edge from i
to e.

Selﬁsh Network Creation with Non-uniform Edge Cost
169
a
b
c
d
f
g
e
h
i
a
b
c
d
f
g
j
e
h
i
a
c
d
f
g
j
e
h
i
b
a
c
d
f
g
e
h
i
b
j
a
c
d
f
g
e
h
i
b
j
a
c
d
f
g
e
h
i
b
j
j
G1 :
G2 :
G3 :
G4 :
G5 :
G6 :
e swaps from h to i
b swaps from i to h
j swaps from i to h
e swaps from i to h
b swaps from h to i
j swaps from h to i
Fig. 3. Example of an improving response cycle for the deg(k)NCG.
4.2
Dynamics in the Add-Only Model
We consider dynamics in the deg(k)AOG. First of all, since agents can only
add edges, the deg(k)AOG trivially has the FIP, i.e. it is an ordinal potential
game with the number of bought edges serving as a generalized ordinal potential
function.
Since convergence is guaranteed, we focus on investigating the speed of con-
vergence and the quality of the obtained networks. For the latter, Observation 6
yields a devastating result. However, we contrast this for the deg2AOG by prov-
ing that if round-robin best single edge dynamics starting on a path as initial
network are used, then the social cost is actually close to the best possible
achievable social cost.
Theorem 8. Let Pn = {v1 · · · vn} be the path of length n, with v1 and vn as leaf
nodes, as a initial graph for the deg(k)AOG:
1. If in any step the active agent is chosen uniformly at random then IRD in
the deg(k)AOG converge in O(n3) steps in expectation.
2. If in any step the active agent and her improving response is chosen adver-
sarially then IRD in the deg(k)AOG converge in Θ(n2) steps.
3. If round-robin best single edge dynamics are used in the deg2AOG, the process
converges in at most O(n log n) steps to a network with diameter O(1).
We contrast the upper bounds by showing that convergence in O(n) many
improving responses is possible.
Theorem 9. Let Pn be the initial network then there exists a sequence of
improving responses which takes

170
A. Chauhan et al.
1. n −2 + n−7
3
steps to obtain a NE network in the degAOG;
2. n −1 steps to obtain a 2NE network in the deg2AOG.
Finally, we investigate the quality of the (2)NE networks which can be obtained
by improving move dynamics starting from the path Pn. For this, we introduce
a measure which is similar to the Price of Anarchy. Let G0 be any initial con-
nected network and let Z(G0) be the set of networks which can be obtained via
improving response dynamics in the deg(2)AOG. Let Best(G0) ∈Z(G0) be the
reachable network with minimum social cost among all networks in Z(G0). We
can now measure the quality of any network G ∈Z(G0) by investigating the
ratio ρ(G, G0) =
cost(G)
cost(Best(G0)).
Theorem 10.
1. Let G be any network in Z(G0) then ρ(G, G0) ∈O(n).
2. There is a network G ∈Z(Pn) for the deg(2)AOG with ρ(G, Pn) ∈Θ(n).
3. Let G∗be the network obtained by the round-robin best single edge dynamics
in the deg2AOG, then we have ρ(G∗, Pn) ∈O(log n).
5
Conclusion
We have introduced natural variants of the well-known NCG by Fabrikant
et al. [14], which have the distinctive features that they are parameter-free and
at the same time incorporate non-uniform edge costs. Besides proving that com-
puting a best response is NP-hard and that improving response dynamics may
never converge to an equilibrium, we have also established that the degNCG
has a constant Price of Anarchy. This strong statement holds whenever the edge
price is any linear function of the degree of the non-owner endpoint of the edge
or if agents are allowed to buy edges to nodes in their 4-neighborhood. For the
version which includes stronger locality, i.e. the deg2NCG, we have shown that
the PoA is in O(√n) and, as a contrast, for the add-only version the PoA is
in Θ(n). We also demonstrate how to circumvent the latter negative result by
using suitable activation schemes on a sparse initial network.
Studying the bilateral version of our model, where both endpoints of the
edge have to agree and pay proportionally to the degree of the other endpoint
for establishing an edge, is an obvious future research direction. For this version,
we have already established that most of our proofs can be easily adapted, which
implies that our results, with minor modiﬁcations, still hold. Another interesting
extension would be to consider an edge price function which depends on the
degree of both involved nodes. This could be set up such that edges between
nodes of similar degree are cheap and edges become expensive when the degree
of both nodes diﬀers greatly.
References
1. Albers, S., Eilts, S., Even-Dar, E., Mansour, Y., Roditty, L.: On Nash equilibria
for a network creation game. ACM TEAC 2(1), 2 (2014)

Selﬁsh Network Creation with Non-uniform Edge Cost
171
2. Alon, N., Demaine, E.D., Hajiaghayi, M.T., Leighton, T.: Basic network creation
games. SIAM J. Discret. Math. 27(2), 656–668 (2013)
3. `Alvarez, C., Blesa, M.J., Duch, A., Messegu´e, A., Serna, M.: Celebrity games.
Theor. Comput. Sci. 648, 56–71 (2016)
4. `Alvarez, C., Messegu`e, A.: Max celebrity games. In: Bonato, A., Graham, F.C.,
Pralat, P. (eds.) WAW 2016. LNCS, vol. 10088, pp. 88–99. Springer, Cham (2016).
doi:10.1007/978-3-319-49787-7 8
5. Bala, V., Goyal, S.: A noncooperative model of network formation. Econometrica
68(5), 1181–1229 (2000)
6. Barab´asi, A.-L.: Network Science. Cambridge University Press, Cambridge (2016)
7. Bil`o, D., Gual`a, L., Leucci, S., Proietti, G.: Locality-based network creation games.
In: SPAA 2014, pp. 277–286. ACM, New York (2014)
8. Bil`o, D., Gual`a, L., Leucci, S., Proietti, G.: Network creation games with
traceroute-based strategies. In: Halld´orsson, M.M. (ed.) SIROCCO 2014. LNCS,
vol. 8576, pp. 210–223. Springer, Cham (2014). doi:10.1007/978-3-319-09620-9 17
9. Chauhan, A., Lenzner, P., Melnichenko, A., Molitor, L.: Selﬁsh network creation
with non-uniform edge cost (2017). arXiv preprint arXiv:1706.10200
10. Corbo, J., Parkes, D.: The price of selﬁsh behavior in bilateral network formation.
In: PODC 2005, pp. 99–107. ACM, New York (2005)
11. Cord-Landwehr, A., Lenzner, P.: Network creation games: think global – act local.
In: Italiano, G.F., Pighizzini, G., Sannella, D.T. (eds.) MFCS 2015. LNCS, vol.
9235, pp. 248–260. Springer, Heidelberg (2015). doi:10.1007/978-3-662-48054-0 21
12. Cord-Landwehr, A., M¨acker, A., auf der Heide, F.M.: Quality of service in network
creation games. In: Liu, T.-Y., Qi, Q., Ye, Y. (eds.) WINE 2014. LNCS, vol. 8877,
pp. 423–428. Springer, Cham (2014). doi:10.1007/978-3-319-13129-0 34
13. Demaine, E.D., Hajiaghayi, M.T., Mahini, H., Zadimoghaddam, M.: The price of
anarchy in network creation games. ACM Trans. Algorithms 8(2), 13 (2012)
14. Fabrikant, A., Luthra, A., Maneva, E., Papadimitriou, C.H., Shenker, S.: On a
network creation game. In: PODC 2003, pp. 347–351. ACM, New York (2003)
15. Graham, R., Hamilton, L., Levavi, A., Loh, P.-S.: Anarchy is free in network cre-
ation. ACM Trans. Algorithms (TALG) 12(2), 15 (2016)
16. Jackson, M.O., Wolinsky, A.: A strategic model of social and economic networks.
J. Econ. Theory 71(1), 44–74 (1996)
17. Kawald, B., Lenzner, P.: On dynamics in selﬁsh network creation. In: SPAA 2013,
pp. 83–92. ACM (2013)
18. Lenzner, P.: On dynamics in basic network creation games. In: Persiano, G. (ed.)
SAGT 2011. LNCS, vol. 6982, pp. 254–265. Springer, Heidelberg (2011). doi:10.
1007/978-3-642-24829-0 23
19. Lenzner, P.: Greedy selﬁsh network creation. In: Goldberg, P.W. (ed.) WINE
2012. LNCS, vol. 7695, pp. 142–155. Springer, Heidelberg (2012). doi:10.1007/
978-3-642-35311-6 11
20. Leskovec, J., Kleinberg, J., Faloutsos, C.: Graphs over time: densiﬁcation laws,
shrinking diameters and possible explanations. In: SIGKDD 2005, pp. 177–187.
ACM (2005)
21. Mamageishvili, A., Mihal´ak, M., M¨uller, D.: Tree Nash equilibria in the net-
work creation game. In: Bonato, A., Mitzenmacher, M., Pralat, P. (eds.) WAW
2013. LNCS, vol. 8305, pp. 118–129. Springer, Cham (2013). doi:10.1007/
978-3-319-03536-9 10
22. Meirom, E.A., Mannor, S., Orda, A.: Network formation games with heterogeneous
players and the internet structure. In: EC 2014, pp. 735–752. ACM (2014)

172
A. Chauhan et al.
23. Mihal´ak, M., Schlegel, J.C.: The price of anarchy in network creation games is
(mostly) constant. In: Kontogiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.)
SAGT 2010. LNCS, vol. 6386, pp. 276–287. Springer, Heidelberg (2010). doi:10.
1007/978-3-642-16170-4 24
24. Mihal´ak, M., Schlegel, J.C.: Asymmetric swap-equilibrium: a unifying equilibrium
concept for network creation games. In: Rovan, B., Sassone, V., Widmayer, P.
(eds.) MFCS 2012. LNCS, vol. 7464, pp. 693–704. Springer, Heidelberg (2012).
doi:10.1007/978-3-642-32589-2 60
25. Monderer, D., Shapley, L.S.: Potential games. Games Econ. Behav. 14(1), 124–143
(1996)
26. Papadimitriou, C.H.: Algorithms, games, and the internet. In: Proceedings on 33rd
Annual ACM Symposium on Theory of Computing, pp. 749–753 (2001)

Opinion Formation Games with Aggregation
and Negative Inﬂuence
Markos Epitropou1, Dimitris Fotakis2(B), Martin Hoefer3,
and Stratis Skoulakis2
1 Department of Electrical and Systems Engineering, University of Pennsylvania,
Philadelphia, USA
mep@seas.upenn.edu
2 School of Electrical and Computer Engineering, NTU Athens, Zografou, Greece
fotakis@cs.ntua.gr, sskoul@corelab.ntua.gr
3 Institut F¨ur Informatik, Goethe-Universit¨at Frankfurt/Main, Frankfurt, Germany
mhoefer@cs.uni-frankfurt.de
Abstract. We study continuous opinion formation games with aggrega-
tion aspects. In many domains, expressed opinions of people are not only
aﬀected by local interaction and personal beliefs, but also by inﬂuences
that stem from global properties of the opinions in the society. To cap-
ture the interplay of such global and local eﬀects, we propose a model of
opinion formation games with aggregation, where we concentrate on the
average public opinion as a natural way to represent a global trend in
the society. While the average alone does not have good strategic prop-
erties as an aggregation rule, we show that with a reasonable inﬂuence
of the average public opinion, the good properties of opinion formation
models are preserved. More formally, we prove that a unique equilib-
rium exists in average-oriented opinion formation games. Simultaneous
best-response dynamics converge to within distance ε of equilibrium in
O(n2 ln(n/ε)) rounds, even in a model with outdated information on the
average public opinion. For the Price of Anarchy, we show a small bound
of 9/8+o(1), almost matching the tight bound for games without aggre-
gation. Moreover, some of the results apply to a general class of opinion
formation games with negative inﬂuences, and we extend our results to
the case where expressed opinions come from a restricted domain.
1
Introduction
The formation and dynamics of opinions are an important aspect in society
and have been studied extensively for decades (see e.g., [16]). Opinion forma-
tion is based on information exchange, which is often local in the sense that
socially connected people (e.g., family, friends, colleagues) interact more often
and aﬀect each other’s opinion more strongly. Moreover, opinion formation is
often dynamic in the sense that discussions and interactions lead to changes in
This work was supported by DFG Cluster of Excellence MMCI at Saarland Univer-
sity. Stratis Skoulakis is supported by a scholarship from the Onassis Foundation.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 173–185, 2017.
DOI: 10.1007/978-3-319-66700-3 14

174
M. Epitropou et al.
the expressed opinions. With the advent of the internet and social media, local
and dynamic aspects of opinion formation have become ever more dominant. To
capture opinion formation on a formal level, several models have been proposed
(see e.g., [4,6,9,12,13,15] for continuous opinions and [5,10,20] for discrete ones).
Motivation and Opinion Formation Model. We build on the inﬂuential
model of Friedkin and Johnsen (FJ) [12] for continuous opinion formation,
following the game-theoretic viewpoint of [6]. Each agent i holds an intrinsic
belief si ∈[0, 1], which is private and invariant over time, and a public opinion
zi ∈[0, 1]. Agent i selects her opinion so as to minimize the total (weighted)
disagreement of zi to her belief and to the opinions in her social neighborhood.
In a dynamic setting, the agents start with their beliefs and in each round t ≥1,
update their opinion zi(t) to the minimizer of their disagreement cost, given
the opinions of the others in round t −1. The FJ model is extensively stud-
ied and has nice algorithmic properties. It admits a unique equilibrium [6,12],
which is approached quickly by the simultaneous best-response dynamics [13].
The Price of Anarchy (PoA) is 9/8 for undirected social networks and Ω(n) for
general directed networks [6]. Moreover, tight PoA bounds can be obtained by
an elegant local smoothness argument both for undirected [4] and for directed [8]
networks.
Despite these favorable properties, the FJ model disregards inﬂuences from
global properties of the opinions, and also the nature of the dynamics of consen-
sus formation. In many domains, public opinions are not only aﬀected by local
interaction and personal beliefs, as in e.g., [4,6,7,9,12,13], but also by inﬂuences
that stem from global properties of the opinions in the society. People are getting
exposed to global trends, societal norms, results from voting and polling, etc.,
which are usually interpreted as the consensus view of the society and may aﬀect
opinion formation. Furthermore, groups of people (or networks of agents) often
need to agree on a common action, even if their beliefs and/or their expressed
opinions are totally diﬀerent. This happens, e.g., when networked devices need
to implement a common action, when people vote over a set of alternatives, or
when a wisdom-of-the-crowd opinion is formed in a social network. In similar
situations, an aggregation rule maps the public opinions to a global opinion that
represents the consensus view on the issue at hand. E.g., in the FJ model, the
global opinion might be the average or the median of the equilibrium opinions.
In presence of aggregation, an agent can also anticipate the impact of its
chosen public opinion on the global one and might incorporate it in its choice.
Hence, the disagreement cost should also reﬂect the distance of an agent’s intrin-
sic belief to the global opinion. To address these issues, we consider a variant of
the opinion formation game of [6,12,13] with opinion aggregation. Each agent i
selects her opinion zi so as to minimize:
Ci(z) = wi(si −zi)2 +

j̸=i
wij(zj −zi)2 + αi(aggr(z) −si)2.
(1)

Opinion Formation Games with Aggregation and Negative Inﬂuence
175
In (1), z = (z1, . . . , zn) ∈Rn is the public opinion vector, si ∈[0, 1] is the belief
of agent i, and aggr(z) maps z to a global opinion aggr(z). The weights wij ≥0
quantify how much the public opinion of agent j inﬂuences i, wi > 0 quantiﬁes
i’s self-conﬁdence, and αi > 0 quantiﬁes the appeal of aggr(z) to i.
Motivated by previous work on the wisdom of the crowd (see e.g., [16,
Sect. 8.3], [14]), we concentrate on average-oriented opinion formation games,
where the aggregation rule aggr(z) maps z to its average avg(z) = n
j=1 zj/n.
Then, the best response of each agent i to a public opinion vector z is:
zi =

wi + αi
n

si + 
j̸=i

wij −αi
n2

zj
wi + αi
n2 + 
j̸=i wij
.
(2)
Contribution. The aggregation rule in (1) might signiﬁcantly aﬀect the dynam-
ics and the equilibrium of opinion formation. This becomes evident in (2), where
i’s inﬂuence from some opinions zj can be negative. Negative inﬂuence models
agent competition for dragging the average public opinion close to their intrin-
sic beliefs. An important side-eﬀect is that the best-response (and equilibrium)
opinions may become polarized and be pushed towards opposite directions, far
away from the agent intrinsic beliefs. This is a signiﬁcant departure from the FJ
model, where the equilibrium opinions lie between the minimum and maximum
intrinsic beliefs of the agents. Interestingly, we prove that the nice algorithmic
properties of the FJ model are not aﬀected – neither by negative inﬂuence nor
by outdated information on the average opinion.
We show (Lemma 1) that average-oriented games admit a unique equilibrium,
and simultaneous best-response dynamics converges to it within distance ε > 0 in
O(n2 ln(n/ε)) rounds. For this result, all agents have access to the average public
opinion in each round. Since the average is global information and thus diﬃcult
to monitor in large networks, we consider average-oriented opinion dynamics
with outdated information. Here the average public opinion is announced to all
the agents simultaneously every few rounds (e.g., a polling agency publishes this
information every now and then). We prove (Theorem 1) that opinion dynamics
with outdated information about the average converges to the unique equilibrium
within distance ε > 0 after O(n2 ln(n/ε)) updates on the average. Both these
results are proven for a more general setting with negative inﬂuence between the
agents and with partially outdated information about the agent public opinions.
The main point here is that negative inﬂuence and outdated information do not
introduce undesirable oscillating phenomena to opinion dynamics.
In Sect. 4, we bound the PoA of average-oriented opinion formation games.
We consider symmetric games, where wij = wji ≥0 for all agent pairs i ̸= j, all
agents have the same self-conﬁdence w and the same inﬂuence α from the average
(for non-symmetric games the PoA is Ω(n), even without aggregation, see [6,
Fig. 2]). We show (Theorem 2) that the PoA is at most 9/8 + O(α/(wn2)). In
general, this bound cannot be improved since for α = 0, 9/8 is a tight bound for
the PoA under the FJ model [6]. While the proof builds on [4], local smoothness
cannot be directly applied to symmetric average-oriented games, because the

176
M. Epitropou et al.
function (avg(z) −si)2 is not locally smooth. To overcome this diﬃculty, we
combine local smoothness with the fact that the average opinion at equilibrium
is equal to the average belief, a consequence of symmetry (Proposition 1).
A frequent assumption on continuous opinion formation is that agent beliefs
and opinions take values in a ﬁnite interval of non-negative real numbers. By
scaling, one can then treat beliefs and opinions as numbers in [0, 1]. Here, we
also assume that agent beliefs si ∈[0, 1]. However, due to negative inﬂuence, the
equilibrium opinions in our model may become polarized and end up far away
from [0, 1]. We believe that such opinion polarization is natural and should be
allowed under negative inﬂuence. Therefore, in Sects. 3 and 4, we assume that
public opinions can take arbitrary real values. Then, in Sect. 5, we also consider
restricted average-oriented games with public opinions restricted to [0, 1], and
study how convergence properties and price of anarchy are aﬀected.
Existence and uniqueness of equilibrium for restricted games follow from [18].
We prove (Theorem 3) that the convergence rate of opinion dynamics with neg-
ative inﬂuence and with outdated information is not aﬀected by restriction of
public opinions to [0, 1]. As for the PoA of restricted symmetric games, we con-
sider the special case where wi = αi = 1, for all agents i, and show that the PoA
does not exceed (
√
2 + 2)2/2 + O( 1
n) (Theorem 4). A technical challenge is that
partial derivatives of the agent cost functions in the local smoothness inequality
do not need to be 0 at equilibrium, due to the opinion restriction to [0, 1]. So,
we ﬁrst show that if wij = 0 for all i ̸= j, the PoA is at most 1 + 1/n2. Then
we combine the PoA of this simpler game with the local smoothness inequality
of [4] and obtain an upper bound on the PoA of the restricted game. Due to lack
of space, some proofs are omitted from this extended abstract.
Clearly, there are many alternative ways to model aggregation, which oﬀer
interesting directions for future research. For example, a possible aggregation is
the median instead of the average. The median aggregation rule is prominent in
Social Choice (see e.g., [3,17]). However, it turns out that the FJ model with
median aggregation has signiﬁcantly less favorable properties. There are exam-
ples where median-oriented games lack exact equilibria (and, hence, convergence
of best-response dynamics), but they can be shown to have approximate equi-
libria. A study of the median rule is beyond the scope of this paper.
Further Related Work. To the best of our knowledge, this is the ﬁrst work
to analyze the convergence of simultaneous best-response dynamics of the FJ
model with negative inﬂuence and outdated information, or the price of anar-
chy of the FJ model with average opinion aggregation. However, there is some
recent work on properties of opinion formation either with global information,
or with negative inﬂuence, or where consensus is sought. We concentrate here
on related previous work most relevant to ours. Discrete opinion formation is
considered in [11] in the binary voter model, where each agent i has a certain
probability of adopting the opinion of an agent outside i’s local neighborhood
(this is conceptually equivalent to estimating the average opinion with random
sampling). The authors analyze the convergence time and the probability that

Opinion Formation Games with Aggregation and Negative Inﬂuence
177
consensus is reached. Necessary and suﬃcient conditions under which local inter-
action in social networks with positive and negative inﬂuence reaches consensus
are derived in [1]. Recently, a model of discrete opinion formation was intro-
duced in [2] with generalized social relations, which include positive and negative
inﬂuence. The authors show that generalized discrete opinion formation games
admit a potential function, and thus, best-response dynamics converge to a Nash
equilibrium.
2
Model and Preliminaries
Notation and Conventions. We deﬁne [n] ≡{1, . . . , n}. For a vector z, z−i
is z without its i-th coordinate and (z, z−i) is the vector obtained from z if we
replace zi with z. Let 0 ≡(0, . . . , 0) and I be the n × n identity matrix. We use
capital letters for matrices and lowercase letters for their elements such that,
e.g., aij is the (i, j) element of a matrix A.
∥A∥and ∥z∥denote the inﬁnity norms of matrix A and vector z, resp.
We repeatedly use the standard properties of matrix norms without explicitly
referring to them, i.e., (i) for any matrices A and B, ∥AB∥≤∥A∥∥B∥and
∥A + B∥≤∥A∥+ ∥B∥; (ii) for any matrix A and any λ ∈R, ∥λA∥≤|λ| ∥A∥;
and (iii) for any matrix A and any integer ℓ, ∥Aℓ∥≤∥A∥ℓ. Moreover, we use
that for any n × n real matrix A with ∥A∥< 1, ∞
ℓ=0 Aℓ= (I −A)−1.
Average-Oriented Opinion Formation. We consider average-oriented opin-
ion formation games with n agents as introduced in Sect. 1. Wlog., we assume
that agent beliefs s ∈[0, 1]n. For the public opinions z, we initially assume val-
ues in R. In Sect. 5, we explain what changes if we restrict them to [0, 1]. An
average-oriented game G is symmetric if wij = wji for all i ̸= j, and wi = w and
αi = α for all agents i. G is nonsymmetric otherwise. If G is symmetric, we let
w = 1, by scaling other weights accordingly. Our convergence results hold for
nonsymmetric games, our PoA bounds hold only for symmetric ones.
A vector z∗is an equilibrium of an opinion formation game G if for any
agent i and any opinion z, Ci(z∗) ≤Ci(z, z∗
−i), i.e., the agents cannot improve
their individual cost at z∗by unilaterally changing their opinions. The social
cost C(z) of G is C(z) = 
i∈N Ci(z). An opinion vector o is optimal if for any
z, C(o) ≤C(z). An optimal vector exists because the social cost function is
proper. The Price of Anarchy of G (PoA(G)) is C(z∗)/C(o), where z∗is the
unique equilibrium and o an optimal vector.
It will be convenient to write (2) in matrix form. Let Si = wi+ αi
n2 +
j̸=i wij.
We always assume that Si > 0 so that Ci(z) is strictly convex in zi. We deﬁne
two n × n matrices A and B. Matrix A has aii = 0, for all i ∈N, and aij =
(wij −αi
n2 )/Si, for all j ̸= i. Matrix B is diagonal and has bii = (wi + αi
n )/Si, for
all i ∈N, and bij = 0, for all j ̸= i.
We assume that αi ≤Si ≤nwi, for all agents i (i.e., the agents neither are
overwhelmed by the average opinion nor have extremely low self-conﬁdence).
This implies ∥A∥≤1 −2
n2 , which is crucial for the convergence of best response

178
M. Epitropou et al.
dynamics. We term a matrix similar to A (i.e., with inﬁnity norm less than 1
and 0s in its diagonal) inﬂuence matrix, and a matrix similar to B (i.e., diagonal
one with positive elements) self-conﬁdence matrix.
The simultaneous best-response dynamics of an average-oriented game G
starts with z(0) = s and proceeds in rounds. In each round t ≥1, the public
opinion vector z(t) is:
z(t) = Az(t −1) + Bs
(3)
We refer to (3) and similar equations as opinion formation processes. An opinion
formation process {z(t)}t∈N converges to a stable state z∗if for all ε > 0, there
is a t∗(ε), such that for all t ≥t∗(ε), ∥z(t) −z∗∥≤ε. Iterating (3) over t (see
also [13, Sect. 2]) implies that for all rounds t ≥1,
z(t) = Az(t −1) + Bs = · · · = Ats +
t−1

ℓ=0
AℓBs.
(4)
Outdated Information of the Average Opinion. We study opinion forma-
tion when the agents have outdated information about the average public opin-
ion. There is an inﬁnite increasing sequence of rounds 0 = τ0 < τ1 < τ2 < · · ·
that describes an update schedule for the average opinion. At the end of round
τp, the average avg(z(τp)) is announced to the agents. We refer to the rounds
between two updates as an epoch, where rounds τp + 1, . . . , τp+1 comprise epoch
p. The length of each epoch p, denoted by kp = τp+1 −τp ≥1, is assumed to be
ﬁnite. The update schedule is the same for all agents, but the agents might not
be aware of it. They are only assumed to be aware of the most recent value of
the average public opinion provided to them.
In this case, we need to distinguish in (2) and (3) between the inﬂuence from
social neighbors, for which the most recent opinions z(t −1) are used, and the
inﬂuence from the average public opinion, where possibly outdated information
is used. As such, we now rely on three diﬀerent n×n matrices D, E and B. Self-
conﬁdence matrix B is deﬁned as before. Inﬂuence matrix D has dii = 0, for all
i ∈[n], and dij = wij/Si, for all j ̸= i, and accounts for the inﬂuence from social
neighbors. Inﬂuence matrix E has eii = 0, for all i ∈[n], and eij = −αi/(n2Si),
for all j ̸= i, and accounts for the inﬂuence from the average public opinion. By
deﬁnition, A = D + E. Moreover, ∥D∥≤1 −1/n and that ∥E∥≤(n −1)/n2.
At the beginning of the opinion formation process, z(0) = s. For each round
t in epoch p, τp + 1 ≤t ≤τp+1, the agent opinions are updated according to:
z(t) = Dz(t −1) + Ez(τp) + Bs
(5)
Note that at the beginning of each epoch p, every agent i can subtract zi(τp)
from n avg(z(τp)) and compute the term Ez(τp) as −αi
n2Si (n avg(z(τp))−zi(τp)).
Opinion Formation with Negative Inﬂuence. An interesting aspect of
average-oriented games is that the inﬂuence matrix A may contain negative

Opinion Formation Games with Aggregation and Negative Inﬂuence
179
elements. Motivated by this observation, we prove our convergence results for
a general domain of opinion formation games that may have negative weights
wij. Similarly to [6,13], the individual cost function of each agent i is Ci(z) =
wi(zi −si)2 + 
j̸=i wij(zi −zj)2, and i’s best response to z−i is
zi =
wisi + 
j̸=i wijzj
wi + 
j̸=i wij
.
(6)
The important diﬀerence is that now some wij may be negative. We require that
for each agent i, wi > 0 and Si = wi + 
j̸=i wij > 0 (and thus, Ci(z) is strictly
convex in zi). The matrices A and B are deﬁned as before. Namely, aij = wij/Si,
for all i ̸= j, and B has bii = wi/Si for all i. We always require that ∥A∥< 1−β,
for some β > 0 (β may depend on n). Simultaneous best-response dynamics is
again deﬁned by (3).
3
Convergence of Average-Oriented Opinion Formation
For any nonnegative inﬂuence matrix A with largest eigenvalue at most 1 −β,
[13, Lemma 5] shows that (3) converges to z∗= (I−A)−1Bs within distance ε in
O(ln( ∥B∥
εβ )/β) rounds. We generalize [13, Lemma 5] to average-oriented games,
where A may contain negative elements. Thus, we show the following lemma for
generalized opinion formation games with negative inﬂuence between the agents.
Lemma 1. Let A be any inﬂuence matrix, possibly with negative elements, with
∥A∥≤1 −β, for some β > 0. Then, for any self-conﬁdence matrix B, any
s ∈[0, 1]n and any ε > 0, the opinion formation process z(t) = Az(t −1) + Bs
converges to z∗= (I −A)−1Bs within distance ε in O(ln( ∥B∥
εβ )/β) rounds.
Since I−A is nonsingular, z∗is the unique vector that satisﬁes z∗= Az∗+Bs.
Thus, z∗is the unique equilibrium of the corresponding opinion formation game.
Moreover, since for average-oriented games ∥A∥≤1 −2/n2, Lemma 1 implies
that any average-oriented game admits a unique equilibrium z∗= (I −A)−1Bs,
and for any ε > 0, (3) converges to z∗within distance ε in O(n2 ln(n/ε)) rounds.
We next extend Lemma 1 to the case where the agents use possibly outdated
information about the average public opinion in each round. In fact, we establish
convergence for a general domain with negative inﬂuence between the agents,
which includes average-oriented opinion formation processes as a special case.
Theorem 1. Let D and E be inﬂuence matrices, possibly with negative ele-
ments, such that ∥D∥≤1 −β1, ∥E∥≤1 −β2, for some β1, β2 ∈(0, 1) with
β1 + β2 > 1. Then, for any self-conﬁdence matrix B, any s ∈[0, 1]n, any update
schedule 0 = τ0 < τ1 < τ2 < · · · and any ε > 0, the opinion formation process
(5) converges to z∗= (I −(D + E))−1Bs within distance ε in O(ln( ∥B∥
εβ )/β)
epochs, where β = β1 + β2 −1 > 0.

180
M. Epitropou et al.
Proof. We observe that z∗= (I −(D + E))−1Bs is the unique solution of z∗=
Dz∗+Ez∗+Bs (as in Lemma 1, since ∥E +D∥≤1−β, with β > 0, the matrix
I−(D +E) is non-singular). Hence, if (5) converges, it converges to z∗. To show
convergence, we bound the distance of z(t) to z∗by a decreasing function of t
and show an upper bound on t∗(ε) = min{t : e(t) ≤ε}.
As in the proof of Lemma 1, for each round t ≥1, we deﬁne e(t) = ∥z(t)−z∗∥
as the distance of the opinions at time t to z∗. For convenience, we also deﬁne
f(β1, β2, k) = (1 −β1)k + (1 −β2)1 −(1 −β1)k
β1
.
For any ﬁxed value of β1, β2 ∈(0, 1) with β1 +β2 > 1, f(β1, β2, k) is a decreasing
function of k. Indeed, the derivative of f with respect to k is equal to ln(1−β1)(1−
β1)k(1 −1−β2
β1 ), which is negative, because 1 > (1 −β2)/β1, since β1 + β2 > 1.
We next show that (i) for any epoch p ≥0 and any round k, 0 ≤k ≤kp,
in epoch p, e(τp + k) ≤f(β1, β2, k)e(τp); and (ii) that in the last round τp+1 =
τp + kp of each epoch p ≥0, e(τp+1) ≤(1 −β)e(τp). The ﬁrst claim shows that
the distance to equilibrium decreases from each round to the next within each
epoch, while the second claim shows that the distance to equilibrium decreases
geometrically from the last round of each epoch to the last round of the next
epoch. Combining the two claims, we obtain that for any epoch p ≥0 and any
round k, 0 ≤k ≤kp, in epoch p, e(τp + k) ≤f(β1, β2, k)(1 −β)pe(0). Therefore,
for any update schedule τ0 < τ1 < τ2 < · · · , the opinion formation process (5)
converges to (I −(D + E))−1Bs in O(ln(e(0)/ε)/β) epochs.
To prove (i), we ﬁx any epoch p ≥0 and apply induction on k. The basis,
where k = 0, holds because f(β1, β2, 0) = 1. For any round k, with 1 ≤k ≤kp,
in p, we have that:
e(τp + k) = ∥Dz(τp + k −1) + Ez(τp) + Bs −(Dz∗+ Ez∗+ Bs)∥
≤∥D∥∥z(τp + k −1) −z∗∥+ ∥E∥∥z(τp) −z∗∥
≤(1 −β1)e(τp + k −1) + (1 −β2)e(τp)
≤(1 −β1)f(β1, β2, k −1)e(τp) + (1 −β2)e(τp) = f(β1, β2, k)e(τp).
The ﬁrst inequality follows from the properties of matrix norms. The second
inequality holds because ∥D∥≤1 −β1 and ∥E∥≤1 −β2. The third inequality
follows from the induction hypothesis. Finally, we use that for any k ≥1, (1 −
β1)f(β1, β2, k −1) + 1 −β2 = f(β1, β2, k).
To prove (ii), we ﬁx any epoch p ≥0 and apply claim (i) to the last round
τp+1 = τp + kp, with kp ≥1, of epoch p. Hence, e(τp+1) = ∥z(τp + kp) −z∗∥≤
f(β1, β2, kp)e(τp).
We next show that f(β1, β2, kp) ≤2 −(β1 + β2) = 1 −β, which concludes
the proof of the claim. The inequality holds because for any integer k ≥1,
f(β1, β2, k) is a convex function of β1. For a formal proof, we ﬁx any k ≥1 and
any β2 ∈(0, 1), and consider the functions g(x) = (1−x)k+ 1−(1−x)k
x
(1−β2) and
h(x) = 2−β2−x, where x ∈[1−β2, 1] (since we assume that β1 ∈(0, 1) and that
β1 > 1−β2). For any ﬁxed value of β2 ∈(0, 1), h(x) is a linear function of x with

Opinion Formation Games with Aggregation and Negative Inﬂuence
181
h(1−β2) = 1 and h(1) = 1−β2. For any ﬁxed value of k ≥1 and β2 ∈(0, 1), g(x)
is a convex function of x with g(1−β2) = 1 = h(1−β2) and g(1) = 1−β2 = h(1).
Therefore, for any β1 ∈[1 −β2, 1], g(β1) ≤h(β1) = 2 −(β1 + β2).
To obtain an upper bound on e(0) = ∥s −z∗∥, we work as in the proof of
Lemma 1, using the fact that ∥D + E∥≤1 −β, and show ﬁrst that ∥(I −(D +
E))−1∥≤1/β and then that ∥z∗∥≤∥B∥/β. Since z(0) = s, we have that
e(0) = ∥s −z∗∥≤1 + ∥B∥/β. Using the fact that for each epoch p ≥0 and for
every round k, 0 ≤k ≤kp, in p, e(τp + k) ≤f(β1, β2, k)(1 −β)pe(0), we obtain
that t∗(ε) = O(ln( ∥B∥
εβ )/β) epochs.
⊓⊔
For average-oriented games, D+E = A, ∥D∥≤1−1/n and ∥E∥≤(n−1)/n2.
Hence, applying Theorem 1 with β ≥1/n2, we conclude that for any ε > 0,
the opinion formation process (5) with outdated information about avg(z(t))
converges to z∗= (I −A)−1Bs within distance ε in O(n2 ln(n/ε)) epochs.
4
The PoA of Symmetric Average-Oriented Games
We proceed to bound the PoA of average-oriented opinion formation games.
We now concentrate on the most interesting case of symmetric games, since
nonsymmetric opinion formation games can have a PoA of Ω(n), even if α = 0
(see e.g., [6, Fig. 2]). We recall that for symmetric games, wij = wji for all agent
pairs i, j, and wi = 1 and αi = α, for all agents i.
Our analysis generalizes a local smoothness argument put forward in [4,
Sect. 3.1]. A function C(z) is (λ, μ)-locally smooth [19] if there exist λ > 0 and
μ ∈(0, 1), such that for all z, x ∈Rn,
C(z) + (x −z)T C′(z) ≤λC(x) + μC(z),
(7)
where C′(z) = ( ϑC1(z)
ϑz1
, ϑC2(z)
ϑz2
, · · · , ϑCn(z)
ϑzn
) is the vector with the partial deriv-
ative of Ci(z) with respect to zi, for each agent i. At the equilibrium z∗,
C′(z∗) = 0. Hence, applying (7) for the equilibrium z∗and for the optimal
solution o, we obtain that PoA ≤λ/(1 −μ). For symmetric games with-
out aggregation, [4, Sect. 3.1] shows that for any s ∈[0, 1]n, the cost func-
tion n
i=1(zi −si)2 + 
i∈N

j̸=i wij(zi −zj)2 is (λ, μ)-locally smooth for any
λ ≥max{1/(4μ), 1/(μ+1)}. Using λ = 3/4 and μ = 1/3, we obtain that the PoA
of symmetric opinion formation games without aggregation is at most 9/8 [4],
which is tight [6, Fig. 1].
This elegant approach cannot be directly generalized to symmetric average-
oriented games, because the function 
i∈N(avg(z) −si)2 is not (λ, μ)-locally
smooth for any μ < 1. So, instead of trying to ﬁnd λ, μ so that (7) holds for all
z ∈Rn, we identify values of λ, μ such that (7) holds for all opinion vectors z
with avg(z) = avg(s). This suﬃces for bounding the PoA, since we need to apply
(7) only for the optimal opinion vector o and the equilibrium opinion vector z∗.
Moreover, the following proposition shows that for the equilibrium vector z∗, we
have that avg(z∗) = avg(s).

182
M. Epitropou et al.
Proposition 1. Let z∗be the equilibrium and s the agent belief vector of any
symmetric average-oriented opinion formation game. Then, avg(z∗) = avg(s).
Based on Proposition 1, we show that the PoA of symmetric average-oriented
games tends to 9/8, which is the PoA of symmetric opinion formation games
without aggregation.
Theorem 2. Let G be any symmetric average-oriented opinion formation game
with n agents and inﬂuence α ≥0 from the average public opinion. Then,
PoA(G) ≤9
8 + O( α
n2 ).
Proof. We ﬁnd appropriate parameters λ > 0 and μ ∈(0, 1) such that (7) holds
for any x ∈Rn and any z ∈Rn with avg(z) = avg(s). Since the equilibrium z∗of
any symmetric average-oriented game G has avg(z∗) = avg(s), by Proposition 1,
PoA(G) ≤λ/(1 −μ).
We divide agent’s i personal cost Ci(z) into three parts Ci(x) = Fi(z) +
Ii(z) + Ai(z), where Fi(z) = 
j̸=i wij(zi −zj)2, Ii(z) = (xi −si)2 and Ai(z) =
(avg(z) −si)2. Following the previous notation:
F(z) =

i∈N
Fi(z) =

i∈N

j̸=i
wij(zi −zj)2 = 2

i,j:i̸=j
wij(zi −zj)2
I(z) =

i∈N
Ii(z) =

i∈N
(zi −si)2 = (z −s)T (z −s)
A(z) =

i∈N
Ai(z) = α

i∈N
(avg(z) −si)2 = α(avg(z) −s)T (avg(z) −s).
Hence, the social cost is C(z) = F(z)+I(z)+A(z). We let F ′(z) = ( ϑF1(z)
ϑz1 , · · · ,
ϑFn(z)
ϑzn ), I′(z) = ( ϑI1(z)
ϑz1 , · · · , ϑIn(z)
ϑzn ) and A′(z) = ( ϑA1(z)
ϑz1
, · · · , ϑAn(z)
ϑzn
) be the
vectors with the partial derivatives of Fi(z), Ii(z) and Ai(z), respectively, with
respect to zi, for each agent i. Note that A′(z) = (2α/n)(avg(z) −s). The
following two propositions are proven in [4, Sect. 3.1].
Proposition 2 [4]. For any symmetric matrix W = (wij), any z, x ∈Rn, and
any λ > 0 and μ ∈(0, 1) with λ ≥1/(4μ),
F(z) + (x −z)T F ′(z) ≤λF(x) + μF(z).
Proposition 3 [4]. For any z, x, s ∈Rn, λ > 0 and μ ∈(0, 1) with λ ≥
1/(μ + 1), it holds that I(z) + (x −z)T I′(z) ≤λI(x) + μI(z).
Using Proposition 1 and increasing the right-hand side by a small fraction of
I(x) and I(z), we can prove an upper bound on A(z) + (x −z)T A′(z).
Proposition 4. For any α > 0, any z, x, s ∈Rn with avg(z) = avg(s), any
δ ≥0, and any λ > 0 and μ ∈(0, 1) such that λμ ≥α/n2,
A(z) + (x −z)T A′(z) ≤δA(x) + μI(x) + (1 −δ + 2λ)A(z) + μI(z).
(8)

Opinion Formation Games with Aggregation and Negative Inﬂuence
183
Applying Propositions 2 and 3 with λ = 3/4 and μ = 1/3, and Proposition 4,
and summing up the corresponding inequalities, we obtain that for any δ ≥0,
and any λ > 0 and μ ∈(0, 1) with λμ ≥α/n2,
PoA(G) ≤
max{3/4, δ} + μ
1 −max{1/3, 1 −δ + 2λ} −μ
(9)
If α/n2 is small enough, e.g., if α/n2 ≤1/2400, we use δ = 3/4, λ = 1/24 and
μ = 24α/n2 in (9) and obtain that PoA(G) ≤9/8 + O( α
n2 ). Otherwise, we use
μ = 1/3, λ = 3α/n2 and δ = 6α/n2 + 2/3, and obtain that PoA(G) = O( α
n2 ). ⊓⊔
5
Average-Oriented Games with Restricted Opinions
A frequent assumption in the literature on opinion formation is that agent beliefs
come from a ﬁnite interval of nonnegative real numbers. Then, by scaling we can
assume beliefs si ∈[0, 1]. If the inﬂuence matrix A is nonnegative, then since
bii + n
j=1 aij = 1 for all i ∈[n], we have that the equilibrium opinions are
z∗= (I −A)−1Bs ∈[0, 1]n. In contrast, for the more general domain we treat
here, an important side-eﬀect of negative inﬂuence is that the best-response (and
equilibrium) opinions may not belong to [0, 1]. Motivated by this observation,
we consider a restricted variant of opinion formation games, where the (best-
response and equilibrium) opinions are restricted to [0, 1].
To distinguish restricted opinion formation processes from their unrestricted
counterparts, we use y(t) to denote the opinion vectors restricted to [0, 1]n. For
restricted average-oriented games and restricted games with negative inﬂuence,
the best-response opinion yi of each agent i to y−i is computed by (2) and (6),
respectively. But now, if the resulting value is yi < 0, we increase it to yi = 0,
while if yi > 1, we decrease it to yi = 1. Since the individual cost Ci(y) is a
strictly convex function of yi, the restriction of yi to [0, 1] results in a minimizer
y∗∈[0, 1] of Ci(y, y−i). So, the restricted opinion formation process is
y(t) = [Ay(t −1) + Bs ][0,1],
(10)
where [·][0,1] is the restriction of opinions y(t) to [0, 1]n. The inﬂuence matrix A
(and the inﬂuence matrices D and E for processes with outdated information)
and the self-conﬁdence matrix B are deﬁnes as in unrestricted opinion formation.
We show a general result for restricted opinion formation processes that is
equivalent to Theorem 1. As in Sect. 3, we prove our result for the more gen-
eral setting of negative inﬂuence. Using Theorem 3, we can immediately bound
the convergence time for restricted average-oriented processes. The proof of the
following is similar to the proof of Theorem 1.
Theorem 3. Let D and E be inﬂuence matrices, possibly with negative ele-
ments, such that ∥D∥≤1 −β1, ∥E∥≤1 −β2, for some β1, β2 ∈(0, 1) with
β1 + β2 > 1. Then, for any self-conﬁdence matrix B, any s ∈[0, 1]n, any update
schedule 0 = τ0 < τ1 < τ2 < · · · , the restricted opinion formation process

184
M. Epitropou et al.
y(t) = [Dy(t −1) + Ey(τp) + Bs ][0,1] converges to the unique equilibrium point
y∗of y′(t) = [(D + E)y′(t −1) + Bs ][0,1]. For any ε > 0, y(t) is within distance
ε to y∗after O(ln( 1
ε)/β) epochs, where β = β1 + β2 −1.
We also bound the PoA of restricted symmetric average-oriented games. Due
to opinion restriction to [0, 1], the average opinion at equilibrium may be far
from avg(s). Therefore, we cannot rely on Proposition 4 anymore. Moreover, the
PoA of restricted games increases fast with α (e.g., if s = (0, . . . , 0, 1/n), wij = 0
for all i ̸= j, and α = n2, PoA = Ω(n)). Therefore, we restrict our attention
to the case where α = w = 1 and show that the PoA of restricted symmetric
average-oriented games remains constant. An interesting intermediate result of
our analysis is that if all agents only value the distance of their opinion to their
belief and to the average, i.e., if wij = 0 for all i ̸= j, the PoA of such games is
at most 1 + 1/n2.
Theorem 4. Let G be any symmetric average-oriented opinion formation game
with n ≥2 agents, w = α = 1, and opinions restricted to [0, 1]. Then, PoA(G) ≤
(
√
2 + 2)2/2 + O( 1
n), where (2 +
√
2)2/2 < 5.8285.
References
1. Altaﬁni, C.: Consensus problems on networks with antagonistic interactions. IEEE
Trans. Autom. Control 58(4), 935–946 (2013)
2. Auletta, V., Caragiannis, I., Ferraioli, D., Galdi, C., Persiano, G.: Generalized
discrete preference games. In: Proceedings of 25th International Joint Conference
on Artiﬁcial Intelligence (IJCAI 2016), pp. 53–59 (2016)
3. Barber`a, S.: An introduction to strategy proof social choice functions. Soc. Choice
Welf. 18, 619–653 (2001)
4. Bhawalkar, K., Gollapudi, S., Munagala, K.: Coevolutionary opinion formation
games. In: Proceedings of 45th ACM Symposium on Theory of Computing (STOC
2013), pp. 41–50 (2013)
5. Bil`o, V., Fanelli, A., Moscardelli, L.: Opinion formation games with dynamic social
inﬂuences. In: Cai, Y., Vetta, A. (eds.) WINE 2016. LNCS, vol. 10123, pp. 444–458.
Springer, Heidelberg (2016). doi:10.1007/978-3-662-54110-4 31
6. Bindel, D., Kleinberg, J.M., Oren, S.: How bad is forming your own opinion? In:
Proceeding of 52nd IEEE Symposium on Foundations of Computer Science (FOCS
2011), pp. 57–66 (2011)
7. Chazelle, B., Wang, C.: Inertial Hegselmann-Krause systems. IEEE Trans. Autom.
Control (2017, to appear)
8. Chen, P.-A., Chen, Y.-L., Lu, C.-J.: Bounds on the price of anarchy for a more
general class of directed graphs in opinion formation games. Oper. Res. Lett. 44(6),
808–811 (2016)
9. DeGroot, M.H.: Reaching a consensus. J. Am. Stat. Assoc. 69, 118–121 (1974)
10. Ferraioli, D., Goldberg, P.W., Ventre, C.: Decentralized dynamics for ﬁnite opinion
games. In: Serna, M. (ed.) SAGT 2012. LNCS, pp. 144–155. Springer, Heidelberg
(2012). doi:10.1007/978-3-642-33996-7 13
11. Fotouhi, B., Rabbat, M.G.: The eﬀect of exogenous inputs and deﬁant agents on
opinion dynamics with local and global interactions. IEEE J. Sel. Top. Sig. Process.
7(2), 347–357 (2013)

Opinion Formation Games with Aggregation and Negative Inﬂuence
185
12. Friedkin, N.E., Johnsen, E.C.: Social inﬂuence and opinions. J. Math. Sociol. 15(3–
4), 193–205 (1990)
13. Ghaderi, J., Srikant, R.: Opinion dynamics in social networks with stubborn agents:
equilibrium and convergence rate. Automatica 50, 3209–3215 (2014)
14. Golub, B., Jackson, M.O.: Na¨ıve learning in social networks and the wisdom of
crowds. Am. Econ. J.: Microecon. 2(1), 112–149 (2010)
15. Hegselmann, R., Krause, U.: Opinion dynamics and bounded conﬁdence models,
analysis, and simulation. J. Artif. Soc. Soc. Simul. 5, 2 (2002)
16. Jackson, M.O.: Social and Economic Networks. Princeton University Press,
Princeton (2008)
17. Moulin, H.: On strategy-proofness and single-peakedness. Publ. Choice 35, 437–
455 (1980)
18. Rosen, J.B.: Existence and uniqueness of equilibrium points in concave n-person
games. Econometrica 33, 520–534 (1965)
19. Roughgarden, T., Schoppmann, F.: Local smoothness and the price of anarchy in
splittable congestion games. J. Econ. Theory 156, 317–342 (2015)
20. Yildiz, E., Ozdaglar, A., Acemoglu, D., Saberi, A., Scaglione, A.: Binary opin-
ion dynamics with stubborn agents. ACM Trans. Econ. Comput. 1(4), 19:1–19:30
(2013)

The Eﬃciency of Best-Response Dynamics
Michal Feldman1, Yuval Snappir1(B), and Tami Tamir2
1 School of Computer Science, Tel-Aviv University, Tel Aviv, Israel
yuval.snappir@gmail.com
2 School of Computer Science, The Interdisciplinary Center, Herzliya, Israel
Abstract. Best response (BR) dynamics is a natural method by which
players proceed toward a pure Nash equilibrium via a local search
method. The quality of the equilibrium reached may depend heavily on
the order by which players are chosen to perform their best response
moves. A deviator rule S is a method for selecting the next deviating
player. We provide a measure for quantifying the performance of diﬀer-
ent deviator rules. The ineﬃciency of a deviator rule S with respect to
an initial strategy proﬁle p is the ratio between the social cost of the
worst equilibrium reachable by S from p and the social cost of the best
equilibrium reachable from p. The ineﬃciency of S is the maximum such
ratio over all possible initial proﬁles. This ineﬃciency always lies between
1 and the price of anarchy.
We study the ineﬃciency of various deviator rules in network forma-
tion games and job scheduling games (both are congestion games, where
BR dynamics always converges to a pure NE). For some classes of games,
we compute optimal deviator rules. Furthermore, we deﬁne and study a
new class of deviator rules, called local deviator rules. Such rules choose
the next deviator as a function of a restricted set of parameters, and
satisfy a natural independence condition called independence of irrele-
vant players. We present upper bounds on the ineﬃciency of some local
deviator rules, and also show that for some classes of games, no local
deviator rule can guarantee ineﬃciency lower than the price of anarchy.
Keywords: Congestion games · Best-response dynamics · Deviator
rules · Price of anarchy
1
Introduction
Nash equilibrium (NE) is perhaps the most popular solution concept in games.
It is a strategy proﬁle from which no individual player can beneﬁt by a unilateral
deviation. However, a Nash equilibrium is a declarative notion, not an algorith-
mic one. To justify equilibrium analysis, we have to come up with a natural
This work was partially supported by the European Research Council under the
European Union’s Seventh Framework Programme (FP7/2007-2013)/ERC grant
agreement number 337122.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 186–198, 2017.
DOI: 10.1007/978-3-319-66700-3 15

The Eﬃciency of Best-Response Dynamics
187
behavior model that leads the players of a game to a Nash equilibrium. Oth-
erwise, the prediction that players play an equilibrium is highly questionable.
Best response (BR) dynamics is a simple and natural method by which players
proceed toward a NE via the following local search method: as long as the strat-
egy proﬁle is not a NE, an arbitrary player is chosen to improve her utility by
deviating to her best strategy given the proﬁle of others.
Work on BR dynamics advanced in two main avenues: The ﬁrst studies
whether BR dynamics converges to a NE, if one exists [17,21]. The second
explores how fast it takes until BR dynamics converges to a NE [11,13,18,25].
It is well known that BR dynamics does not always converge to a NE, even
if one exists. However, for the class of ﬁnite potential games [22,24], a pure
NE (PNE) always exists, and BR dynamics is guaranteed to converge to one
of the equilibria of the game. A potential game is one that admits a potential
function—a function that assigns a real value to every strategy proﬁle, and has
the miraculous property that for any unilateral deviation, the change in the util-
ity of the deviating player is mirrored accurately in the potential function. This
mirroring, combined with the fact that the game is ﬁnite, guarantees that any
BR sequence must terminate and this happens at some (local) minimum of the
potential function, which is a NE by deﬁnition. While BRD is guaranteed to
converge, convergence may take an exponential number of iterations, even in a
potential game [3].
Our focus in this work is diﬀerent than the directions mentioned above. The
description of BR dynamics leaves the choice of the deviating player unspeciﬁed.
Thus, BR dynamics is essentially a large family of dynamics, diﬀering from one
another in the choice of who would be the next player to perform her best
response move. In this paper, we study how the choice of the deviating player
(henceforth a deviator rule) aﬀects the eﬃciency of the equilibrium reached via
BR dynamics. Our contribution is the following: (i) We introduce a new measure
for quantifying the ineﬃciency of deviator rules, (ii) we introduce a natural
class of simple and local deviator rules, and (iii) we analyze the ineﬃciency of
deviator rules in network formation games and job scheduling games. Our results
distinguish between games where local deviator rules can lead to good outcomes
and games for which any local deviator rule performs poorly.
1.1
Model and Problem Statement
A game G has a set N of n players. Each player i has a strategy space Pi, and the
player chooses a strategy pi ∈Pi. A strategy proﬁle is a vector of strategies for
each player, p = (p1, . . . , pn). The strategy proﬁle of all players except player i is
denoted by p−i, and it is convenient to denote a strategy proﬁle p as p = (pi, p−i).
Similarly, for a set of players I, we denote by pI and p−I the strategy proﬁle
of players in I and in N \ I, respectively, and we write p = (pI, p−I). Each
player has a cost function ci : P →R≥0, where ci(p) denotes player i’s cost in
the strategy proﬁle p. Every player wishes to minimize her cost. There is also a
social objective function, mapping each strategy proﬁle to a social cost.

188
M. Feldman et al.
Given a strategy proﬁle p, the best response of player i is the set of strategies
that minimize player i’s cost, ﬁxing the strategies of all other players, formally
BRi(p) = arg minp′
i∈Pici(p′
i, p−i). Player i is said to be suboptimal in p if the
player can reduce her cost by a unilateral deviation, i.e., if pi ̸∈BRi(p). If no
player is suboptimal in p, then p is a Nash equilibrium (NE) (in this paper we
restrict attention to pure NE; i.e., an equilibrium in pure strategies).
Given an initial strategy proﬁle p0, a best response (BR) sequence from p0
is a sequence ⟨p0, p1, . . .⟩in which for every T = 0, 1, . . . there exists a player
i ∈N s.t pT +1 = (BRi(pT
−i), pT
−i). In this paper we restrict attention to games
in which every BR sequence is guaranteed to converge to a NE.
Deviator Rules and Their Ineﬃciency. A deviator rule is a function
S : P →N that given a proﬁle p, chooses a deviator among all suboptimal
players in p. The chosen player then performs a best response move (breaking
ties arbitrarily). Given an initial strategy proﬁle p0 and a deviator rule S we
denote by NES(p0) the set of NE that can be obtained as the ﬁnal proﬁle of a
BR sequence ⟨p0, p1, . . .⟩, where for every T ≥0, pT +1 is a proﬁle resulting from
a deviation of S(pT ) (recall that players break ties arbitrarily, thus this is a set
of possible Nash equilibria).
Given an initial proﬁle p0, let NE(p0) be the set of Nash equilibria reachable
from p0 via a BR sequence, and let p⋆(p0) be the best NE reachable from p0 via
a BR sequence, that is, p⋆(p0) = arg minp∈NE(p0)SC(p), where SC : P →R is
some social cost function.
The ineﬃciency of a deviator rule S in a game G, denoted αG
S , is deﬁned as
the worst ratio, among all initial proﬁles p0, and all NE in NES(p0), between
the social cost of the worst NE reachable by S (from p0) and the social cost of
the best NE reachable from p0. I.e., αG
S = supp0 maxp∈NES(p0)
SC(p)
SC(p⋆(p0)). For a
class of games G, the ineﬃciency of a deviator rule S with respect to G is deﬁned
as the worst case ineﬃciency over all games in G: αG
S = supG∈G{αG
S }. A deviator
rule with ineﬃciency 1 is said to be optimal, i.e., an optimal deviator rule is
one that for every initial proﬁle reaches a best equilibrium reachable from that
initial proﬁle.
The following observation shows that the ineﬃciency of every deviator rule
is bounded from above by the price of anarchy (PoA) [20,23]. Recall that the
PoA is the ratio between the cost of the worst NE and the cost of the social
optimum, and is used to quantify the loss incurred due to selﬁsh behavior.
Observation 1. For every game G and for every deviator rule S it holds that
the ineﬃciency of S is at least 1 and bounded from above by the PoA.
Local Deviator Rules. We deﬁne and study a class of simple deviator rules,
called local deviator rules. Local deviator rules are deﬁned with respect to state
vectors, that represent the state of the players in a particular proﬁle. Given a
proﬁle p, every player i is associated with a state vector vi, consisting of several
parameters that describe her state in p and in the strategy proﬁle obtained by her
best response. The speciﬁc parameters may vary from one application to another.

The Eﬃciency of Best-Response Dynamics
189
A vector proﬁle is a vector v = (v1, . . . , vn), consisting of the state vectors of
all players. A deviator rule is said to be local if it satisﬁes the independence of
irrelevant players condition, deﬁned below.
Deﬁnition 1. A deviator rule S satisﬁes independence of irrelevant players
(IIP) if for every two state vectors vi1, vi2, and every two vector proﬁles v, v′
such that v = (vi1, vi2, v−{i1,i2}), and v′ = (vi1, vi2, v′
−{i1,i2})1, if S(v) = i1,
then S(v′) ̸= i2.
The IIP condition means that if the deviator rule chooses a state vector vi
over a state vector vj in one proﬁle, then, whenever these two state vectors exist,
the deviator rule would not choose vector vj over vi. Note that this condition
should hold even across diﬀerent game instances and even when the number of
players is diﬀerent. Many natural deviator rules satisfy the IIP condition. For
example, suppose that the state vector of a player contains her cost in the current
proﬁle and her cost in the proﬁle obtained by her best response; then, both (i)
max-cost, which chooses the player with the maximum current cost, and (ii)
max-improvement, which chooses the player with the maximum improvement,
are local deviator rules.
Congestion Games. A congestion game has a set E of m resources, and the
strategy space of every player i is a collection of sets of resources; i.e., Pi ⊆2E.
Every resource e ∈E has a cost function fe : IN →IR, where fe(ℓ) is the cost of
resource e if ℓplayers use resource e. The cost of player i in a strategy proﬁle p is
ci(p) = 
e∈pi fe(ℓe(p)), where ℓe(p) is the number of players that use resource
e in the proﬁle p. Every congestion game is a potential game [22], thus admits
a pure NE, and moreover, every BR sequence converges to a pure NE. In this
paper we study the eﬃciency of deviator rules in the following congestion games:
Network Formation Games [3]: There is an underlying graph, and every player
is associated with a pair of source and target nodes si, ti. The strategy space of
every player i is the set of paths from si to ti. The resources are the edges of
the graph, every edge e is associated with some ﬁxed cost ce, which is evenly
distributed by the players using it. That is, the cost of an edge e in a proﬁle p is
fe(p) = ce/ℓ(p). In network formation games the cost of a resource decreases in
the number of players using it. We also consider a weighted version of network
formation games on parallel edge networks, where players have weights and the
cost of an edge is shared proportionally by its users. The social cost function
here is the sum of the players’ costs; that is SC(p) = 
i∈N ci(p).
The state vector of a player in a network formation game, in a proﬁle p,
consists of: (1) player i’s cost in p: ci(p), (2) the cost of player i’s path: 
e∈pi ce,
(3) player i’s cost in the proﬁle obtained from a best response of i: ci(p′(i))
(where p′(i) = (p−i, BRi(p−i)) is the proﬁle obtained from a best response of i),
and (4) the cost of player i’s path in the proﬁle p′(i): 
e∈BRi(p−i) ce. In weighted
instances, the state vector includes player i’s weight as well.
1 Note that the vectors v and v′ may correspond to diﬀerent sets of players.

190
M. Feldman et al.
Job Scheduling Games [26]: The resources are machines, and players are jobs that
need to be processed on one of the machines. Each job has some length, and the
strategy space of every player is the set of the machines. The load on a machine
in a strategy proﬁle p is the total length of the jobs assigned to it. The cost of
a job is the load on its chosen machine. We also consider games with conﬂicting
congestion eﬀect [7,14], where jobs have unit length and in addition to the cost
associated with the load, every machine has an activation cost B, shared by
the jobs assigned to it. The social cost function here is the makespan, that is
SC(p) = maxi∈N ci(p). The state vector of a job (player) in a job scheduling
game, in a proﬁle p, consists of the job’s length, the job’s current machine and
the loads on the machines.
1.2
Our Results
In Sect. 2 we present our results for network formation games. We ﬁrst study
symmetric games, where all the players share the same source and target nodes.
We observe that the local Min-Path deviator rule, which chooses the player with
the cheapest best response path, is optimal. In contrast, the local Max-Cost
deviator rule has the worst possible ineﬃciency, n (which matches the PoA for
this game). We then consider asymmetric network formation games. Unfortu-
nately, the optimality of Min-Path does not carry over to asymmetric network
formation games, even when played on series of parallel paths (SPP) networks.
In particular, the ineﬃciency of Min-Path in single-source multi-target instances
is θ(|V |), and for multi-source multi-target instances, it further grows to θ(2|V |).
On the positive side, we show poly(n, |V |) dynamic-programming algorithms for
ﬁnding an optimal BR sequence for network formation games played on SPP
networks, for single-source multi-target instances, and for multi-source multi-
target instances with proper intervals (i.e., where no player’s strategy is a subset
of another player’s strategy). The speciﬁcation of these algorithms is deferred to
the full version due to space constraints. For network formation games played
on extension-parallel networks we show that every local deviator rule has an
ineﬃciency of Ω(n).
In Sect. 2.4 we study network formation games with weighted players. It turns
out that weighted players lead to quite negative results. We show that even in
the simplest case of parallel-edge networks, it is NP-hard to ﬁnd an optimal BR-
sequence, and no local deviator rule can ensure a constant ineﬃciency. Moreover,
the Min-Path deviator rule has ineﬃciency Ω(n), even in symmetric games on
series-parallel graphs, and even if the ratio between the maximal and minimal
weights approaches 1.
The analysis of job scheduling games is deferred to the dull version. A job’s
(= player’s) state vector in job scheduling games includes the job’s lengths
and the machines’ loads. Local deviator rules capture many natural rules, such
as Longest-Job, Max-Cost, Max-Improvement, and more. We show that in an
instance with m identical machines, no local deviator rule can guarantee ineﬃ-
ciency better than the PoA, which is
2m
m+1. In contrast, for job scheduling games
with conﬂicting congestion eﬀects [14], we present an optimal local deviator rule.

The Eﬃciency of Best-Response Dynamics
191
Positive results on local deviator rules imply that a centralized authority that
can control the order of deviations can lead the population to a good outcome,
by considering merely local information captured in the close neighborhood of
the current state. In contrast, negative results for local deviator rules imply that
even if a centralized authority can control the order of deviations, in order to
converge to a good outcome, it cannot rely only on local information; rather,
it must be able to perform complex calculations and to consider a large search
space.
1.3
Related Work
Congestion games have been widely studied from a game theoretic perspective.
The questions that are most commonly analyzed are the existence of a pure NE,
the convergence of BRD to a NE, and the loss incurred due to selﬁsh behavior
– commonly quantiﬁed by the price of anarchy [20,23] and price of stability [3].
Our work addreses congestion games and some variants thereof. It is well
known that every congestion game is a potential game [22,24] and therefore
admits a PNE and possesses the ﬁnite improvement property (FIP). In partic-
ular, every BRD converges to a PNE. However, the convergence time may, in
general, be exponentially long. It is shown in [3,13] that ﬁnding a PNE in net-
work formation games is PLS-complete. Examples for exponential convergence
of job scheduling games are presented in [10]. It has been shown in [9] that in
random potential games with n players in which every player has at most a
strategies, the worst case convergence time is n · an−1.
The observation that the convergence of BRD can be exponentially long has
led to a large amount of work aiming to identify special classes of congestion
games for which BRD converges to a PNE in polynomial time (or even linear
time). Examples include [3] for games with positive congestion eﬀects, and [10,16]
for games with negative congestion eﬀects. For resource selection games (i.e.,
where feasible strategies are composed of singletons), polynomial convergence
has been proven in [18].
Variants of congestion games such as weighted network formation games
and resource selection games with player-speciﬁc cost functions have been also
considered in the literature [8,17,21]. Some classes of cost functions that always
admit PNE or the FIP were identiﬁed in [17]. It was also shown that singleton
weighted congestion games that always admit a PNE do not always have the FIP.
[4,12] present variants of network formation games in which computing a player’s
best response is NP-hard. A cost-sharing game on unrelated machines has been
studied in [5], where it was shown that a PNE exists only for instances with
unit-cost machines. Moreover, even when a PNE exists and BRD is guaranteed
to converge, the implementation of BRD can be computationally hard.
BRD has been studied also in games that do not converge to a PNE. The
notion of dynamic ineﬃciency was deﬁned in [6] as the average social cost in
a BR inﬁnite sequence (for games that do not possess the ﬁnite improvement
property), and diﬀerent deviator rules are analyzed with respect to the dynamic
ineﬃciency measure.

192
M. Feldman et al.
The eﬀect of the deviator rule on the convergence time of job scheduling
games was studied in [10]. This paper considered the convergence time under
the Max-Weight-Job, Min-Weight-Job, FIFO and random deviator rules. The
Max-Cost deviator rule was considered also in [15] for conﬂicting congestion
games [7,14], and in [19] for swap-games [2]. In both cases Max-Cost signiﬁcantly
improves convergence time to O(n).
2
Network Formation Games
In this section we study network formation games. We consider two natural local
deviator rules, namely Max-Cost and Min-Path. The Max-Cost deviator rule
chooses a suboptimal player that currently incurs the highest cost, i.e., Max −
Cost(p) ∈arg max{i∈N|pi̸∈BRi(p)}ci(p). The Min-Path deviator rule chooses a
suboptimal player whose path in the proﬁle obtained from a best response move
is cheapest, i.e., Min −Path(p) ∈arg min{i∈N|pi̸∈BRi(p)}

e∈BRi(p) ce.
2.1
Warmup: Symmetric Network Formation Games
A network-formation game is symmetric if all the players have the same source
and target nodes. Recall that the ineﬃciency of any deviator rule is upper
bounded by the price of anarchy (PoA) of the game. It is well known that the
PoA of network formation games is n.
We ﬁrst show that the Max-Cost rule may perform as poorly as the PoA,
even in symmetric games on parallel-edge networks.
Observation 2. The ineﬃciency of Max-Cost in symmetric network formation
games on parallel-edge networks is n.
On the other hand, we show that Min-Path is an optimal deviator rule, i.e.,
it always reaches the best NE reachable from any initial proﬁle. Our analysis of
Min-Path is based on the following Lemma:
Lemma 1. In symmetric network formation games, the path chosen by the ﬁrst
deviator is the unique path that will be chosen by all subsequent players, regardless
of the order in which they deviate.
Lemma 1 directly implies the optimality of Min-Path:
Theorem 1. Min-Path is an optimal deviator rule for symmetric network for-
mation games.
Proof. By Lemma 1 the ﬁrst deviation dictates the NE to be reached. Thus, the
set of reachable NE is the set of BR paths in p0 (i.e, {BRi(p0)|i is suboptimal
in N}). Clearly choosing the cheapest one among them is optimal.
⊓⊔

The Eﬃciency of Best-Response Dynamics
193
2.2
Series of Parallel Paths (SPP) Networks
In this section we study NFGs played on SPP networks. An SPP network consists
of m segments, where each segment is a parallel-edge network. Let {u0, . . . , um}
denote the vertex set, and for every j ≤m, let Ej denote the set of edges in
segment j (i.e., the parallel edges connecting uj−1 and uj). For a player i, let
E(i) = ∪si<k≤tiEk, denote the set of edges player i may choose.
Note that in an SPP network, a player’s choice of an edge in Ej is independent
of any other segment in her path. This implies that a NFG on an SPP network
consists of a sequence of symmetric games, where the set of players participating
in each game varies. Combining this observation with Lemma 1 implies:
Lemma 2. In every network formation game played on an SPP network with m
segments, for every 1 ≤j ≤m, and every BR sequence, let i be the ﬁrst player
in the sequence such that Ej ∈E(i), and let e be the edge in Ej chosen by player
i. Then e is the unique edge in Ej players deviate to.
Based on the above lemma, it is possible to develop polynomial-time algo-
rithms, based on dynamic programming, for ﬁnding optimal BR sequences
for SPP networks, for both single-source multi-targets games and multi-source
multi-target games with proper intervals. Due to space constraints, the algo-
rithms are omitted.
The Performance of Min-Path in SPP Networks. Recall that Min-Path
was shown to be optimal for symmetric NFGs. We now analyze its ineﬃciency
for SPP networks. Given an SPP network and a BR-sequence, we say that a
segment is unresolved if there are at least two players whose intervals include
the segment, and each of them will select a diﬀerent edge in the segment if chosen
to perform a BR next. The other segments are denoted resolved. By Lemma 2,
after player i performs her best response, all the segments in her interval are
resolved. Thus, no player migrates more than once. The reachable NEs have the
same edges in the resolved segments and can only diﬀer in unresolved segments.
Therefore, the migrations of players who use only resolved segments does not
inﬂuence the reachable NEs and in the following analyses we ignore them. Thus,
all the deviations we consider resolve at least one segment. We denote by Ri the
resolved segments after i such deviations. Let OPT denote the minimal cost of
a NE reachable from p0 by some BR sequence. Formally, OPT = SC(p⋆(p0)).
Lemma 3. For any BR sequence of an SPP network instance, as long as there
are unresolved segments, there exists a suboptimal player whose interval includes
unresolved segments, and if this player is chosen next, then the cost of the unre-
solved segments she would set is at most OPT.
Proof. Let p be an intermediate strategy proﬁle in the BR sequence. Consider
the players according to the order they deviate in some optimal BR sequence.
Let i′ be the ﬁrst player in this order who is suboptimal in p. Since no player
prior to i′ in the optimal sequence is suboptimal, the segments that i′ would

194
M. Feldman et al.
resolve by a deviation from p are a subset of the segments she resolves in the
optimal sequence. In the optimal sequence she obviously resolves these segments
such that the selected edges are of total cost at most OPT, and therefore this
is an upper bound on the total cost of unresolved segments she would set by
deviating from p.
⊓⊔
Using the above lemma, we provide tight analysis on the performance of
Min-Path for SPPs with multi-targets and single or multiple sources. Note that
in a single-source instance, every player resolves the preﬁx of the network corre-
sponding to her interval.
Theorem 2. The ineﬃciency of Min-Path in SPP NFGs with single-source and
multi-targets is θ(m).
Proof. We show that the total cost determined for the segments resolved in
every iteration is at most OPT. Since at least one segment is resolved in each
iteration, the whole network’s cost is bounded by m · OPT. Let i be the i-th
player chosen to deviate by Min-Path and assume i has unresolved segments.
Let i′ be the player guaranteed by Lemma 3. It may be that i = i′. Both players
have the same BR path in the resolved segments and therefore diﬀer only in
their unresolved segments. Since Min-Path chose i, the cost of her unresolved
segments is at most the cost of i′’s unresolved segments, which is at most OPT
by Lemma 3.
Fig. 1. A network on which Min-Path has ineﬃciency Ω(m)
We show that the analysis is tight: Consider the network depicted in Fig. 1.
There are n = m players, where ti is the target of player i. In the initial strategy
proﬁle for every 1 ≤i ≤n, p0
i = ⟨e1, e2, . . . , ei−1, e′
i⟩. Note that in every segment,
Ei, connecting ti−1 and ti, the upper edge costs n −i and is used by the n −i
players i + 1, . . . , n and the lower edge costs 1 + ϵ and is used only by player i.
In every segment, the players using the upper edge will beneﬁt from deviating
to the lower one and the player using the lower edge will beneﬁt from deviating to
the upper one. By Lemma 2, the ﬁrst deviation will determine the edge that will
be used in the NE reached. Therefore, a ﬁrst deviation of player n to ⟨e′
1, . . . , e′
n⟩
will result in the NE corresponding to that path and has a social cost n · (1 + ϵ).
Player i’s BR path’s cost is

1≤t≤i−1
(1+ϵ)+(n−i) = (i−1)·(1+ϵ)+(n−i) =
(n−1)+(i−1)·ϵ. Therefore, Min-Path chooses Player 1 to deviate ﬁrst. After her
deviation all the rest of the players would use e1 in their BR and treating t1 as

The Eﬃciency of Best-Response Dynamics
195
source shows that the next Player to deviate will be Player 2 and then Player 3
etc. Min-Path’s BR sequence’s NE will consist of ⟨e1, . . . en−1, e′
n⟩and therefore
its ineﬃciency for this strategy proﬁle is (n−1) n
2 +1+ϵ
n(1+ϵ)
→
ϵ→0
(n−1) n
2 +1
n
≈n
2 . Since
n = m, we conclude that the ineﬃciency of Min-Path in SPP networks with
single-source and multi-targets is θ(m).
⊓⊔
We next show that Min-Path performs poorly on more general instances.
Theorem 3. The ineﬃciency of Min-Path in SPP network formation games
with multi-sources and multi-targets is θ(2m).
Proof. Let c(Ri) denote the total cost of resolved segments after i deviations of
players whose deviation resolved at least one segment. Since the initially resolved
segments has to be included in the NE reached, it holds that c(R0) ≤OPT. We
prove that c(Ri)−c(Ri−1) ≤c(Ri−1)+OPT for every i; i.e., c(Ri) ≤2c(Ri−1)+
OPT. This implies that the total network’s cost is c(Rm) ≤2m+1 · OPT.
Let i be the ith player chosen to deviate by Min-Path that has some unre-
solved segments. The total cost of the unresolved segments that i resolves is
c(Ri) −c(Ri−1). Let i′ be a player guaranteed by Lemma 3. Since i was chosen
by Min-Path, the cost of i’s BR path is lower than the cost of i′’s BR path.
But the cost of i’s BR path is at least the cost of the unresolved segments in
i’s BR path. On the other hand, the cost of i′’s BR path equals the sum of the
cost of her resolved segments, which is bounded by c(Ri−1) and the cost she
would set to her unresolved segments, bounded by OPT (by Lemma 3). Putting
it all together, we get c(Ri) −c(Ri−1) ≤c(Ri−1) + OPT, as required. In the full
version, we present a matching lower bound.
⊓⊔
2.3
Local Rules for Extension Parallel (EP) Graphs
We now show that the ineﬃciency of any local deviator rule is Ω(n), even in the
restricted class of EP networks. Recall that the state vector of a player consists of
the player’s cost in her current proﬁle and in the proﬁle obtained by a deviation
of the player, and the total cost of the path used by the player in the two proﬁles.
Theorem 4. For the class of single-source network formation games played on
extension-parallel networks, the ineﬃciency of every local deviator rule is Ω(n).
Proof. Consider the network depicted in Fig. 2(a). There are n players, all shar-
ing the source s, and the targets are as depicted in the ﬁgure. Consider the
following proﬁle: (i) Player 1 uses the path ⟨e1⟩. (ii) Player 2 uses the path
⟨e1, e2⟩. (iii) Players 3, 4 use the path ⟨e3⟩. (iv) Players 5 to n use the path ⟨e5⟩.
Recall that the state vector of player i consists of her current cost, the
total cost of her current path, her post-deviation cost, and the total cost of
her post-deviation path. Consider player 2, who uses the path ⟨e1, e2⟩. Her cur-
rent cost is 22 (she shares the cost of edge e1 with player 1 and pays fully
for edge e2), the total cost of her path is 34, her post-deviation cost is 10

196
M. Feldman et al.
Fig. 2. A local deviator rule fails (a) if v2 is preferred, and (b) if v3 is preferred. Every
edge is labelled by the edge cost and the number of players using it in the initial strategy
proﬁle. E.g., the edge e1 costs 24 and is used by 2 players in the initial strategy proﬁle.
(obtained by deviating to e3, and sharing this cost with players 3, 4), and the
total cost of her post-deviation path is 30. Thus, the state vector of player 2 is
v2 = (22, 34, 10, 30). Similarly, one can verify that the state vector of player 3 (or
layer 4) is v3 = (15, 30, 13, 34) (obtained by deviating to the path ⟨e1, e2⟩). The
suboptimal players in this proﬁle are players 2 and 3 (or 4). If the deviator rule
chooses the state vector v2 over v3, then player 2 will deviate to e3, reaching a
NE whose social cost is 54 + 7.4(n −4). On the other hand, if the deviator rule
chooses the state vector v3 over v2, then player 3 will deviate to ⟨e1, e2⟩, and
from this point on all players will deviate to ⟨e1, e2⟩, reaching a NE whose social
cost is 34. We conclude that a deviator rule that prefers v2 over v3 reaches an
ineﬃciency of 54+7.4(n−4)
34
= Ω(n).
Consider next the network depicted in Fig. 2(b). There are n players, all
sharing the source s, with targets as depicted in the ﬁgure. Consider the following
proﬁle: (i) Player 1 uses the path ⟨e1, e2⟩. (ii) Player 2 uses the path ⟨e1, e6⟩.
(iii) Players 3, 4 use the path ⟨e3⟩. (iv) Players 5 to n use the path ⟨e5⟩.
One can verify in a similar analysis to the one showed for the game in Fig. 2(a)
that if a deviator rule prefer v3 over v2 then it has ineﬃciency of 34+6.5(n−4)
30
=
Ω(n). We conclude that any local deviator rule has ineﬃciency of Ω(n).
⊓⊔
2.4
Weighted Symmetric Network Formation Games
In this section we consider network formation games with weighted players
[1,8,17], where every player is associated with a cost wi. If an edge of cost ce is
shared by k players with weights w1, w2, . . . , wk, then player i pays
wi
k
j=1 wj · ce.
For weighted NFGs on parallel-edge graphs, we prove the following.
Theorem 5. In weighted network formation games on parallel edge networks:
(a) it is NP-hard to calculate the social cost of an optimal reachable NE from a
given proﬁle; (b) ﬁnding a reachable NE that approximates the social optimum
by factor 3
2 is NP-hard; (c) any local deviator rule has ineﬃciency Ω(√n).
A direct corollary of the last theorem (part (a)) is that the problem of ﬁnding
an optimal BR sequence is NP-hard.

The Eﬃciency of Best-Response Dynamics
197
Weighted symmetric network formation games with strategies consisting of
two resources (i.e., a 2-segment SPP) are potential games [3]. Theorem 1 shows
that in unweighted symmetric games, the Min-Path deviator rule ensures con-
vergence to the optimal reachable NE. Here we show that in weighted games
the eﬃciency of Min-Path can be as poor as the PoA, even if the weights are
arbitrarily close to each other, and the strategies are sets of two resources.
Theorem 6. In weighted network formation games on a 2-segment SPP, the
Min-Path deviator rule has ineﬃciency Ω(n). This bound is valid even if the
ratio maxi wi/ mini wi is arbitrarily close to 1.
References
1. Ackermann, H., R¨oglin, H., V¨ocking, B.: Pure Nash equilibria in player-speciﬁc
and weighted congestion games. Theor. Comput. Sci. 410(17), 1552–1563 (2009)
2. Alon, N., Demaine, E.D., Hajiaghayi, M., Leighton, T.: Basic network creation
games. In: Proceedings of the 22nd ACM Symposium on Parallelism in Algorithms
and Architectures, pp. 106–113 (2010)
3. Anshelevich, E., Dasgupta, A., Kleinberg, J., Tardos, E., Wexler, T., Roughgarden,
T.: The price of stability for network design with fair cost allocation. SIAM J.
Comput. 38(4), 1602–1623 (2008)
4. Avni, G., Kupferman, O., Tamir, T.: Network-formation games with regular objec-
tives. J. Inf. Comput. 251, 165–178 (2016)
5. Avni, G., Tamir, T.: Cost-sharing scheduling games on restricted unrelated
machines. Theor. Comput. Sci. 646, 26–39 (2016)
6. Berger, N., Feldman, M., Neiman, O., Rosenthal, M.: Dynamic ineﬃciency: anarchy
without stability. In: Persiano, G. (ed.) SAGT 2011. LNCS, vol. 6982, pp. 57–68.
Springer, Heidelberg (2011). doi:10.1007/978-3-642-24829-0 7
7. Chen, B., G¨urel, S.: Eﬃciency analysis of load balancing games with and without
activation costs. J. Sched. 15(2), 157–164 (2011)
8. Chen, H., Roughgarden, T.: Network design with weighted players. Theory Com-
put. Syst. 45(2), 302–324 (2009)
9. Durand, S., Gaujal, B.: Complexity and optimality of the best response algorithm
in random potential games. In: Gairing, M., Savani, R. (eds.) SAGT 2016. LNCS,
vol. 9928, pp. 40–51. Springer, Heidelberg (2016). doi:10.1007/978-3-662-53354-3 4
10. Even-Dar, E., Kesselman, A., Mansour, Y.: Convergence time to Nash equilib-
ria. In: Baeten, J.C.M., Lenstra, J.K., Parrow, J., Woeginger, G.J. (eds.) ICALP
2003. LNCS, vol. 2719, pp. 502–513. Springer, Heidelberg (2003). doi:10.1007/
3-540-45061-0 41
11. Even-Dar, E., Mansour, Y.: Fast convergence of selﬁsh rerouting. In: Proceedings
of SODA, pp. 772–781 (2005)
12. Fabrikant, A., Luthra, A., Maneva, E., Papadimitriou, C., Shenker, S.: On a net-
work creation game. In: Proceedings of PODC, pp. 347–351 (2003)
13. Fabrikant, A., Papadimitriou, C., Talwar, K.: The complexity of pure Nash equi-
libria. In: Proceedings of STOC, pp. 604–612 (2004)
14. Feldman, M., Tamir, T.: Conﬂicting congestion eﬀects in resource allocation games.
J. Oper. Res. 60(3), 529–540 (2012)
15. Feldman, M., Tamir, T.: Convergence of best-response dynamics in games with
conﬂicting congestion eﬀects. Inf. Process. Lett. 115(2), 112–118 (2015)

198
M. Feldman et al.
16. Fotakis, D.: Congestion games with linearly independent paths: convergence time
and price of anarchy. Theory Comput. Syst. 47(1), 113–136 (2010)
17. Harks, T., Klimm, M.: On the existence of pure Nash equilibria in weighted con-
gestion games. Math. Oper. Res. 37(3), 419–436 (2012)
18. Ieong, S., Mcgrew, R., Nudelman, E., Shoham, Y., Sun, Q., Fast, C.: A simple
class of congestion games. In: Proceedinhgs of AAAI, pp. 489–494 (2005)
19. Kawald, B., Lenzner, P.: On dynamics in selﬁsh network creation. In: Proceedings
of SPAA, pp. 83–92 (2013)
20. Koutsoupias, E., Papadimitriou, C.: Worst-case equilibria. Comput. Sci. Rev. 3(2),
65–69 (1999)
21. Milchtaich, I.: Congestion games with player speciﬁc payoﬀfunctions. Games Econ.
Behav. 13, 111–124 (1996)
22. Monderer, D., Shapley, L.S.: Potential games. Games Econ. Behav. 14, 124–143
(1996)
23. Papadimitriou, C.H.: Algorithms, games, and the internet. In: Proceedings of 33rd
STOC, pp. 749–753 (2001)
24. Rosenthal, R.W.: A class of games possessing pure-strategy Nash equilibria. Int.
J. Game Theory 2, 65–67 (1973)
25. Syrgkanis, V.: The complexity of equilibria in cost sharing games. In: Saberi, A.
(ed.) WINE 2010. LNCS, vol. 6484, pp. 366–377. Springer, Heidelberg (2010).
doi:10.1007/978-3-642-17572-5 30
26. V¨ocking, B.: Selﬁsh load balancing (Chap. 20). In: Algorithmic Game Theory.
Cambridge University Press, Cambridge (2007)

Eﬃcient Best Response Computation
for Strategic Network Formation Under Attack
Tobias Friedrich, Sven Ihde, Christoph Keßler, Pascal Lenzner(B),
Stefan Neubert, and David Schumann
Algorithm Engineering Group, Hasso Plattner Institute, Potsdam, Germany
pascal.lenzner@hpi.de
Abstract. Inspired by real world examples, e.g. the Internet, research-
ers have introduced an abundance of strategic games to study natural
phenomena in networks. Unfortunately, almost all of these games have
the conceptual drawback of being computationally intractable, i.e. com-
puting a best response strategy or checking if an equilibrium is reached is
NP-hard. Thus, a main challenge in the ﬁeld is to ﬁnd tractable realistic
network formation models. We address this challenge by investigating
a very recently introduced model by Goyal et al. [14] which focuses on
robust networks in the presence of a strong adversary who attacks (and
kills) nodes in the network and lets this attack spread virus-like through
the network via neighboring nodes.
Our main result is to establish that this natural model is one of the
few exceptions which are both realistic and computationally tractable.
In particular, we answer an open question of Goyal et al. by provid-
ing an eﬃcient algorithm for computing a best response strategy, which
implies that deciding whether the game has reached a Nash equilibrium
can be done eﬃciently as well. Our algorithm essentially solves the prob-
lem of computing a minimal connection to a network which maximizes
the reachability while hedging against severe attacks on the network
infrastructure and may thus be of independent interest.
1
Introduction
Many of today’s important networks, most prominently the Internet, are essen-
tially the outcome of an unsupervised decentralized network formation process
among many selﬁsh entities [22]. In the case of the Internet these selﬁsh entities
are Autonomous Systems (AS) which interconnect via peering agreements and
thereby create a connected network of networks. Each AS can be understood
as a selﬁsh player who strategically chooses a subset of other ASs to directly
connect with. Each inter-AS-connection is costly and yields a beneﬁt and a risk.
The beneﬁt is a reliable direct link towards the other AS. However, such a con-
nection may be used by malicious software and thus harbors the risk of collateral
damage if a neighboring AS is attacked.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 199–211, 2017.
DOI: 10.1007/978-3-319-66700-3 16

200
T. Friedrich et al.
The ﬁeld of strategic network formation, started by the seminal works of
Jackson and Wolinsky [15], Bala and Goyal [2] and Fabrikant et al. [11], stud-
ies the global structure and properties of networks formed by individual players
making decentralized local strategic choices. In all considered models there are
players trying to optimize their own beneﬁt, while minimizing their individual
cost. It is far from obvious why a collection of individual selﬁsh strategies eventu-
ally results in useful and reliable network topologies like the Internet. Studying
the properties of such models aims for revealing insights about properties of
existing naturally grown networks and inspiring methods to improve them.
Required features of any Internet-like communication network are reacha-
bility and robustness. Such networks have to ensure that even in case of cas-
cading edge or node failures caused by technical defects or malicious attacks,
e.g. DDoS-attacks or viruses, most participating nodes can still communicate.
This important focus on network robustness has long been neglected and is now
a very recent endeavor in the strategic network formation community, see e.g.
[6,14,17,20]. We contribute to this endeavor by proving that the very recently
introduced natural model by Goyal et al. [13,14] is one of the few exceptions
of a tractable network formation model. In particular, we provide an eﬃcient
algorithm for computing a utility maximizing strategy for their elegant model,
which can be used to eﬃciently decide whether a network is in Nash equilibrium.
Thus, our algorithm allows the model of Goyal et al. to be used to predict real
world phenomena in large scale simulations and to analyze real world networks.
Related Work: We focus on the model for strategic network formation with
attack and immunization recently proposed by Goyal et al. [13,14]. This model
essentially augments the well-known reachability model by Bala and Goyal [2]
with robustness considerations. In particular, diﬀerent types of adversaries are
introduced which attack (and destroy) a node of the network. This attack then
spreads virus-like to neighboring nodes and destroys them as well. Besides decid-
ing which links to form, players also decide whether they want to buy immuniza-
tion against eventual attacks. The model is the ﬁrst model which incorporates
network formation and immunization decisions at the same time.
The authors of [13,14] provide beautiful structural results for their model.
For example, showing that equilibrium networks are much more diverse than in
the non-robust version, that the amount of edge overbuilding due to robustness
concerns is small and that equilibrium networks generally achieve very high social
welfare. Besides this, the authors raise the intriguing open problem of settling
the complexity of computing a best response strategy in their model1.
Computing a best response in network formation games can be done in poly-
nomial time for the non-robust reachability model [2] and if the allowed strat-
egy changes are very simple [16,19]. However, these examples are exceptions.
The existence of an eﬃcient best response algorithm for a network formation
game is in general a rare gem. For almost all related network formation models,
e.g. [4–6,8,10,11,21], where players strive for a central position in the network,
1 This question was raised in [13] for the maximum carnage adversary and is replaced
in [14] with a reference to our preprint [12] of the present paper.

Eﬃcient Best Response Computation for Strategic Network Formation
201
it has been shown that the problem is indeed NP-hard. The model by Goyal
et al. [13,14] seems on the ﬁrst glance computationally easier than the above
mentioned centrality models since players only strive for reaching all other play-
ers. However, the presence of a strong adversary and the possibility of immu-
nization renders ﬁnding a best possible strategy a non-trivial problem.
To the best of our knowledge, besides the model by Goyal et al. [13,14] there
are only a few other models which combine selﬁsh network formation with robust-
ness considerations and all of them consider a much weaker adversary which can
only destroy a single edge. The earliest are models by Bala and Goyal [3] and
Kliemann [17], both essentially augment the model by Bala and Goyal [2] with
single edge failures. Other related models are by Meirom et al. [20] and Chauhan
et al. [6]. Both latter models consider players who try to be as central as pos-
sible in the created networks but at the same time want to protect themselves
against single edge failures. In [20] heterogeneous players are considered whereas
in [6] all players are homogeneous. The complexity of computing a best response
was only settled for the model by Chauhan et al. [6] where it was proven to be
NP-hard.
Apart from network formation games, also vaccination games, e.g. [1,7,18,23],
are related. There the network is ﬁxed and the selﬁsh nodes only have to decide if
the want to immunize or not. Computing a best response in these models is trivial
(there are only two strategies) but pure Nash equilibria may not exist.
Our Contribution: We establish that the natural model by Goyal et al. [13,14]
is one of the few examples of a tractable realistic model for strategic network
formation and thereby answer an open question by these authors. In particular,
we provide an eﬃcient algorithm for computing a best response strategy for their
main model, i.e. the “maximum carnage” adversary which tries to kill as many
nodes as possible, and for the natural variant which employs the even stronger
random attack adversary.
Due to space constraints, we refer to [12] for all omitted details.
2
Model
We consider the model proposed by Goyal et al. [13,14] and mostly use their
notation. In this model the n nodes of a network G = (V, E) correspond to
individual players v1, . . . , vn. We will thus use the terms node, vertex and player
interchangeably. The edge set E is determined by the players’ strategic behavior
as follows. Each player vi ∈V can decide to buy undirected edges to a subset of
other players, paying α > 0 per edge, where α is some ﬁxed parameter.
If player vi decides to buy the edge to node vj, then we say that the edge
{vi, vj} is owned and paid for by player vi. Buying an undirected edge entails
connectivity beneﬁts and risks for both participating endpoints. In order to cope
with these risks, each player can also decide to buy immunization against attacks
at a cost of β > 0, which is also a ﬁxed parameter of the model. We call a player
immunized if this player decides to buy immunization, and vulnerable otherwise.

202
T. Friedrich et al.
The strategy si = (xi, yi) of player vi consists of the set xi ⊆V \ {vi} of the
nodes to buy an edge to, and the immunization choice yi ∈{0, 1}, where yi = 1 if
and only if player vi decides to immunize. The strategy proﬁle s = (s1, . . . , sn) of
all players then induces an undirected graph G(s) =

V, 
vi∈V

vj∈xi{vi, vj}

.
The immunization choices y1, . . . , yn in s partition V into the set of immunized
players I ⊆V and vulnerable players U = V \I. The components in the induced
subgraph G[U] are called vulnerable regions and the set of those regions is RU.
The vulnerable region of any player vi ∈U is RU(vi). Immunized regions RI
are deﬁned analogously as the components of the induced subgraph G[I].
After the network G(s) is built, we assume that an adversary attacks one
vulnerable player according to a strategy known to the players. We consider
mostly the maximum carnage adversary [13,14] which tries to destroy as many
nodes of the network as possible. To achieve this, the adversary chooses a vul-
nerable region of maximum size and attacks some player in that region. If there
is more than one such region with maximum size, then one of them is chosen
uniformly at random. If a player vi ∈U is attacked, then vi will be destroyed
and the attack spreads to all vulnerable neighbors of vi, eventually destroying
all players in RU(vi). Let tmax = maxR∈RU {|R|} be the number of nodes in the
vulnerable region of maximum size and T = {vi ∈U | |RU(vi)| = tmax} be the
corresponding set of nodes which may be targeted. The set of targeted regions
is RT = {R ∈RU | |R| = tmax}, and RT (vi) is the targeted region of a player
vi ∈T . Thus, if vi ∈T is attacked, then all players in RT (vi) will be destroyed.
The utility of a player vi in network G(s) is deﬁned as the expected number
of nodes reachable by vi after the adversarial attack on network G(s) (zero in
case vi was destroyed) less vi’s expenditures for buying edges and immunization.
More formally, let CCi(t) be the connected component of vi after an attack to
node vt ∈T and let |CCi(t)| denote its number of nodes. Then the utility (or
proﬁt) ui(s) of vi in the strategy proﬁle s is
ui(s) =
1
|T |
 
vt∈T
|CCi(t)|

−|xi| · α −yi · β.
Fixing the strategies of all other players, the best response of a player vi is a strat-
egy s∗
i = (x∗
i , y∗
i ) which maximizes vi’s utility ui

(s1, . . . , si−1, s∗
i , si+1, . . . , sn)

.
We will call the strategy change to s∗
i a best response for player vi in the network
G(s), if changing from strategy si ∈s to strategy s∗
i is the best possible strategy
for player vi if no other player changes her strategy.
Consider what happens if we remove node vi from the network G(s) = (V, E)
and we call the obtained network G(s) \ vi. In this case, G(s) \ vi consists of
connected components C1, . . . , Cℓ. The edge-set x∗
i can thus be partitioned into
ℓsubsets x∗
i (C1), . . . , x∗
i (Cℓ), where x∗
i (Cz) denotes the set of nodes in Cz to
which vi buys an edge under best response strategy s∗
i . We will say that x∗
i (Cz)
is an optimal partner set for component Cz. Therefore, x∗
i is the union of optimal
partner sets for all connected components in G(s) \ vi.

Eﬃcient Best Response Computation for Strategic Network Formation
203
A best response is calculated for one arbitrary but ﬁxed player va, which we
call the active player. Furthermore let C be the set of connected components
which exist in G(s) \ va. Let CU = {C ∈C | C ∩I = ∅}, CI = C \ CU and
Cinc = {C ∈C | ∃u ∈C : {u, v} ∈E}, where CU is the set of components in
which all vertices are vulnerable, CI is the set of components which contain at
least one immunized vertex and Cinc is the set of components to which player va
is connected through incoming edges bought by some other player.
3
The Best Response Algorithm
A naive approach to calculate the best response for player va would consider all
2n possible strategies and select one that yields the best utility. This is clearly
infeasible for a larger number of players.
3.1
Key Observations
Our algorithm exploits three observations to reduce the complexity from expo-
nential to polynomial:
Observation 1: The network G(s) \ va may consist of ℓconnected components
that can be dealt with independently for most decisions. As long as the set of
possible targets of the adversary does not change, the best response of va can
be constructed by ﬁrst choosing components to which a connection is proﬁtable
and then choosing for each of those components an optimal set of nodes within
the respective component to build edges to.
Observation 2: Homogeneous components in G(s) \ va, which consist of only
vulnerable or only immunized nodes, provide the same beneﬁt no matter whether
va connects to them with one or with more than one edge. Thus the connection
decision is a binary decision for those components.
Observation 3: Mixed components in G(s)\va, which contain both immunized
and vulnerable nodes, consist of homogeneous regions that again have the prop-
erty that at most one edge per homogeneous region can be proﬁtable. Merging
those regions into block nodes forms an auxilliary tree, called Meta Tree, which
we use in an eﬃcient dynamic programming algorithm to compute the most
proﬁtable subset of regions to connect with.
3.2
Main Algorithm
Our algorithm, called BestResponseComputation, is described in Algo-
rithm 1 and a schematic overview can be found in Fig. 1.

204
T. Friedrich et al.
Our algorithm solves the problem of ﬁnding a best response strategy by con-
sidering both options of buying or not buying immunization and computing for
both cases the best possible set of edges to buy. Thus, the ﬁrst step of BestRe-
sponseComputation is to drop the current strategy of the active player va and
to replace it with the empty strategy s∅= (∅, 0) in which player va does not buy
any edge and does not buy immunization. Then the resulting strategy proﬁle
s′ = (s1, . . . , sa−1, s∅, sa+1, . . . , sn) and the set of connected components CU and
CI with respect to network G(s′) \ va is considered.
Fig. 1. Schematic overview of the best response algorithm.

Eﬃcient Best Response Computation for Strategic Network Formation
205
The subroutine SubsetSelect determines the optimal sets of components
of CU to connect to if va does not immunize. This is done by solving an adjusted
Knapsack problem which involes only small numbers. Two such sets of com-
ponents, called At and Av, are computed depending on player va becoming
targeted or not by connecting to these components. Additionally the subroutine
GreedySelect greedily computes a best possible subset of components of CU
to connect with in case va buys immunization.
The challenging part of the problem is to cope with the connected components
in CI which also contain immunized nodes. For such components our algorithm
detects and merges equivalent nodes and thereby simpliﬁes these components to
an auxiliary tree structure, which we call the Meta Tree. This tree is then used
in a dynamic programming fashion to eﬃciently compute the best possible set of
edges to buy towards nodes within the respective component. Thus, our approach
for handling components containing immunized nodes can be understood as ﬁrst
performing a data-reduction similar to many approaches for kernelization in the
realm of Parameterized Algorithmics [9] and then solving the reduced problem
via dynamic programming.
The subroutine PossibleStrategy, see Algorithm 2, obtains the best set
of nodes in components in CI. As this set depends on the number of targeted
regions, it has to be determined for several cases independently. These cases are
va not being immunized and not being targeted, va not being immunized but
being targeted, and va being immunized. The correctness of this is guaranteed
by the following lemma.
Lemma 1. Player va can deal with distinct components from CI independently,
if T and RU(va) do not change.
For each case, PossibleStrategy ﬁrst chooses an arbitrary single edge to buy
into the previously selected components from CU. This is correct since we have:
Lemma 2. Buying at most one edge into any component C ∈CU yields maxi-
mum proﬁt for player va.
Then the best set of edges to buy into components in CI is computed indepen-
dently for each component C ∈CI via the subroutines PartnerSetSelect,
MetaTreeConstruct and MetaTreeSelect. The union of the obtained
sets is then returned. Finally, the algorithm compares the empty strategy and
the individually obtained best possible strategies for the above mentioned cases
and selects the one which maximizes player va’s utility. All in all we get:
Theorem 1. The algorithm BestResponseComputation is correct and runs
in polynomial time.
The run time of our best response algorithm heavily depends on the size of the
largest obtained Meta Tree and we achieve a worst-case run time of O(n4 + k5)
for the maximum carnage adversary and O(n4 + nk5) for the random attack
adversary, where n is the number of nodes in the network and k is the number
of blocks in the largest Meta Tree. In the worst case, this yields a run time

206
T. Friedrich et al.
of O(n5) and O(n6), respectively. To contrast this worst-case bound, we also
provide in [12] empirical results showing that k is usually much smaller than n,
which emphasizes the eﬀectiveness of our data-reduction and thereby shows that
our algorithm is expected to be much faster than the worst-case upper bound.
3.3
Partner Selection for Components in CI
Let C1, . . . , Cc ∈CI be the components va might buy edges into. By deﬁni-
tion, each of those components contains at least one immunized node. The next
statement ensures that we only need to consider buying edges to such nodes.
Lemma 3. Player va has an optimal partner set for C ∈CI which only buys
edges to immunized players.
For computing an optimal partner set for a component C ∈CI, we consider the
expected contribution of C to va’s proﬁt given that va buys edges to all nodes
in a set Δ, and denote this proﬁt by ˆuva(C | Δ).
PartnerSetSelect. For each component C ∈CI we compute three candidate
sets of players to buy edges to and ﬁnally select the candidate set that yields the
highest proﬁt contribution for the considered component C for player va. The
three candidate sets for component C are obtained as follows:
Case 1: The player considers buying no additional edges into C. In this case
the resulting player set is empty.
Case 2: The player considers buying one additional edge into C. The resulting
player set contains the immunized partner that maximizes the proﬁt for C.
Case 3: The player considers buying at least two edges. An optimal set of at
least two immunized partners is obtained via the algorithm MetaTreeSelect.
As all possible cases are covered, the most proﬁtable set of those three can-
didate solutions must be the optimal partner set for component C. This optimal
partner set is returned. We refer to this subroutine as PartnerSetSelect.
The ﬁrst two cases, buying either no or exactly one edge into component
C are easily solved: if no edge is purchased by va, then the expected proﬁt
contribution is ˆuva(C | ∅). If exactly one edge is bought then the expected proﬁt
contribution is ˆuva(C | {w}), where w is the vertex in C which maximizes va’s
expected proﬁt for component C.
Case 3 is much more diﬃcult to handle. It is the main point where we need
to employ algorithmic techniques to avoid a combinatorial explosion. To ease the
strategy selection, for each component C ∈CI we create an auxiliary graph to
identify sets of nodes which oﬀer equivalent beneﬁts with respect to connection.
This graph is a bipartite tree which we call the Meta Tree of C. Figure 2 shows a
conversion of a graph component into its Meta Tree by merging adjacent nodes
of the same type into regions and collapsing regions into blocks. So called Bridge
Blocks (orange) of the Meta Tree represent targeted regions of C that would, if

Eﬃcient Best Response Computation for Strategic Network Formation
207
destroyed, decompose C into at least two components. If the adversary however
chooses to attack a player in a so-called Candidate Block (blue or violet), C
would remain connected. Details of the Meta Tree are discussed in [12]. An
important property is guaranteed by the following lemma.
Lemma 4. All leaves of the Meta Tree are Candidate Blocks.
vulnerable
targeted
mixed
immunized
Fig. 2. A graph component (left), the corresponding Meta Graph (middle), which is
an intermediate step in the construction, and the obtained Meta Tree (right). (Color
ﬁgure online)
We now use the Meta Tree for maximizing the expected component proﬁt
for va.
Solving Case 3 of PARTNERSETSELECT. In the following let M be the Meta
Tree of component C. Moreover, we assume that M has at least two Candidate
Blocks, since otherwise, by Lemma 3 buying at most one edge suﬃces.
Idea of the MetaTreeSelect Algorithm. The following two lemmas imply that
we only have to consider to buy single edges into leaves of the Meta Tree which
are Candidate Blocks. Thus, we only have to ﬁnd the optimal combination of
leaves of M to which to buy an edge.
Lemma 5. Buying more than 1 edge to a Candidate Block is never beneﬁcial.
Lemma 6. Let M be the Meta Tree of component C. If player va has an optimal
partner set for C which contains buying at least two edges, then va also has an
optimal partner set for C which contains only leaves of M.
Probing all possible combinations of leaves of M yields exponential runtime. We
use the following two observations to compute the best possible combination of
leaves eﬃciently. Both observations are based on the assumption that player va
buys an edge to some leaf r of M and we consider the tree M rooted at r. Later
we ensure this assumption by rooting M at each possible leaf. Let w be any
vertex of M.
Observation 1: If player va has an edge to w, then it can be decided eﬃciently
whether it is beneﬁcial to buy exactly one or no edge into a subtree of w, as
the inﬂuence of any additional edges into M does not propagate over w. Hence
decisions are independent for subtrees.

208
T. Friedrich et al.
Observation 2: Let the children of w in M be x1, . . . , xℓ. Consider that va
has an edge to w and it has already been decided for each subtree rooted at
x1, . . . , xℓwhether or not to buy an edge into that subtree. If there exists at
least one edge between va and any of those subtrees, then it cannot be beneﬁcial
to buy additional edges into the subtree rooted at w. Either w is destroyed,
and the previous edge-buy decisions apply to the disconnected subtrees, or w
survives, and va is connected to all subtrees via node w.
These observations provide us with the foundation for a dynamic program-
ming algorithm which decides bottom-up whether it is beneﬁcial to buy at most
one edge into a given subtree by reusing the edge buy decisions of its subtrees.
Note that the algorithm never has to compare combinations of bought edges,
as the only decision to make is, whether or not to buy exactly one edge into a
subtree in combination with iteratively shifting the presumed edge to the parent
node of the leaves to the root r.
The MetaTreeSelect Algorithm: The MetaTreeSelect algorithm can be
found in Algorithm 3. It roots M at every leaf and assumes buying an edge
towards some immunized node within the root Candidate Block. Then the sub-
routine RootedMetaTreeSelect, see Algorithm 4, gets the rooted Meta Tree
M(r) and some vertex rT (which initially is the only child of the currently con-
sidered root leaf) as input and recursively computes the expected proﬁt contri-
bution of one additional edge from va to a block in the subtree T rooted at rT
under the assumption that va is already connected to the parent block p(rT ) of
rT in M(r). Let |T| denote the number of players represented by the union of
all blocks in T and opt(rT ) will be the set of blocks in T the algorithm decided
to buy an edge to.

Eﬃcient Best Response Computation for Strategic Network Formation
209
After processing all subtrees of rT (Algorithm 4 lines 2–3), the algorithm
distinguishes three cases (Algorithm 4 line 4):
Case 1: rT is a Bridge Block. Then, as M is bipartite, p(rT ) must be a Candidate
Block. As the algorithm assumes the existence of an edge from va to p(rT ),
there also exists a path from va to rT via p(rT ) in all attack scenarios. Thus, no
additional edge is needed (Algorithm 4 line 5).
Case 2: There exists an edge between va and some node x in T, either through
an edge va buys according to the results of the recursive invocations, or through
a preexisting edge bought by player x. Then, depending on the attack target,
there either exists a path from va to rT via x or via p(rT ). Hence, no additional
edge is needed (Algorithm 4 line 5).
Case 3: Player va can get disconnected from rT by an attack on p(rT ). Then
the algorithm considers each leaf l of T as possible partner (Algorithm 4 line 6),
computes the proﬁt contribution of an edge to l (Algorithm 4 line 7) and selects
a leaf that maximizes this proﬁt contribution (Algorithm 4 line 8).
The additional proﬁt of an edge to l is computed as follows: An edge to l
only yields proﬁt, if a Bridge Block t is attacked which either belongs to T or
t = p(rT ), and l is located in a subtree of t. In this case, the proﬁt contribution
equals the size of this subtree. Therefore let proﬁt(l | t) be the additional proﬁt
an edge to l contributes to the utility of va in case t is attacked and let B be the
set of all Bridge Blocks in T. Thus proﬁt(l) = |p(rT )|
|T | |T| + 
t∈B
|t|
|T |proﬁt(l | t),
with
proﬁt(l | t) =
	
0,
if l is not in any subtree of t
|Y |,
if Y is a subtree of t and l is in Y.
Finally, If the additional proﬁt of the best possible leaf exceeds the edge costs,
l is added to the set of partners of va (Algorithm 4 line 10).
The correctness of MetaTreeSelect is based in the following statement:
Lemma 7. If va has an edge to p(rT ) and opt(rT ) is returned by RootedMe-
taTreeSelect(M(r), rT ), then there exists an optimal partner set for compo-
nent C which contains r∗and opt(rT ).
Theorem 2. If there is an optimal partner set with at least two nodes for com-
ponent C, then MetaTreeSelect algorithm outputs such a set.
Proof. Assume that there exists an optimal partner set with at least two nodes
for component C and assume that the Meta Tree M of component C is rooted
at some leaf r. Since the algorithm compares all possibilities to root M at a leaf
and by Lemma 6, at least one of those leaves must be contained in an optimal
partner set. Assume that r is indeed such a leaf.
Thus, by buying r we satisfy the assumption needed for RootedMeta-
TreeSelect. By Lemma 7, RootedMetaTreeSelect returns a set of nodes,
which together with r∗yields an optimal partner set for C. Hence, the algorithm
MetaTreeSelect is correct.
⊓⊔

210
T. Friedrich et al.
4
Conclusion
For most models of strategic network formation computing a utility maximizing
strategy is known to be NP-hard. In this paper, we have proven that the model
by Goyal et al. [13,14] is a notable exception to this rule. The presented eﬃcient
algorithm for computing a best response for a player circumvents a combinator-
ial explosion essentially by simplifying the given network and thereby making it
amenable to a dynamic programming approach. An eﬃcient best response com-
putation is the key ingredient for using the model in large scale simulations and
for analyzing real world networks. Moreover, our algorithm can be adapted to a
signiﬁcantly stronger adversary and we are conﬁdent that further modiﬁcations
for coping with other variants of the model are possible.
Future Work: Settling the complexity of computing a best response strategy
with respect to the maximum disruption adversary is left as an open problem.
Besides this, it seems worthwhile to consider a variant with directed edges, orig-
inally introduced by Bala and Goyal [2]. Directed edges would more accurately
model the diﬀerences in risk and beneﬁt which depend on the ﬂow direction.
Using the analogy of the WWW, a user who downloads information beneﬁts
from it, but also risks getting infected. In contrast, the user providing the infor-
mation is exposed to little or no risk.
References
1. Aspnes, J., Chang, K., Yampolskiy, A.: Inoculation strategies for victims of viruses
and the sum-of-squares partition problem. J. Comput. Syst. Sci. 72(6), 1077–1093
(2006)
2. Bala, V., Goyal, S.: A noncooperative model of network formation. Econometrica
68(5), 1181–1229 (2000)
3. Bala, V., Goyal, S.: A strategic analysis of network reliability. Rev. Econ. Des.
5(3), 205–228 (2000). doi:10.1007/s100580000019. ISSN 1434-4750
4. Bil`o, D., Gual`a, L., Leucci, S., Proietti, G.: Locality-based network creation games.
In: SPAA 2014, pp. 277–286 (2014)
5. Bil`o, D., Gual`a, L., Proietti, G.: Bounded-distance network creation games. ACM
TEAC 3(3), 16:1–16:20 (2015)
6. Chauhan, A., Lenzner, P., Melnichenko, A., M¨unn, M.: On selﬁsh creation of robust
networks. In: Gairing, M., Savani, R. (eds.) SAGT 2016. LNCS, vol. 9928, pp. 141–
152. Springer, Heidelberg (2016). doi:10.1007/978-3-662-53354-3 12
7. Chen, P.-A., David, M., Kempe, D.: Better vaccination strategies for better people.
In: EC 2010, pp. 179–188. ACM (2010)
8. Cord-Landwehr, A., Lenzner, P.: Network creation games: think global - act local.
In: MFCS 2015, pp. 248–260 (2015)
9. Downey, R.G., Fellows, M.R.: Fundamentals of Parameterized Complexity. Texts
in Computer Science. Springer, Heidelberg (2013)
10. Ehsani, S., Fadaee, S.S., Fazli, M., Mehrabian, A., Sadeghabad, S.S., Safari, M.A.,
Saghaﬁan, M.: A bounded budget network creation game. ACM Trans. Algorithms
11(4), 34 (2015)

Eﬃcient Best Response Computation for Strategic Network Formation
211
11. Fabrikant, A., Luthra, A., Maneva, E.N., Papadimitriou, C.H., Shenker, S.: On a
network creation game. In: PODC 2003, pp. 347–351 (2003)
12. Friedrich, T., Ihde, S., Keßler, C., Lenzner, P., Neubert, S., Schumann, D.: Eﬃcient
best-response computation for strategic network formation under attack. CoRR,
abs/1610.01861 (2016)
13. Goyal, S., Jabbari, S., Kearns, M., Khanna, S., Morgenstern, J.: Strategic Network
Formation with Attack and Immunization. arXiv preprint arXiv:1511.05196 (2015)
14. Goyal, S., Jabbari, S., Kearns, M., Khanna, S., Morgenstern, J.: Strategic net-
work formation with attack and immunization. In: Cai, Y., Vetta, A. (eds.) WINE
2016. LNCS, vol. 10123, pp. 429–443. Springer, Heidelberg (2016). doi:10.1007/
978-3-662-54110-4 30
15. Jackson, M.O., Wolinsky, A.: A strategic model of social and economic networks.
J. Econ. Theory 71(1), 44–74 (1996)
16. Kawald, B., Lenzner, P.: On dynamics in selﬁsh network creation. In: SPAA 2013,
pp. 83–92. ACM (2013)
17. Kliemann, L.: The price of anarchy for network formation in an adversary model.
Games 2(3), 302–332 (2011)
18. Kumar, V.A., Rajaraman, R., Sun, Z., Sundaram, R.: Existence theorems and
approximation algorithms for generalized network security games. In: ICDCS 2010,
pp. 348–357. IEEE (2010)
19. Lenzner, P.: Greedy selﬁsh network creation. In: WINE 2012, pp. 142–155 (2012)
20. Meirom, E.A., Mannor, S., Orda, A.: Formation games of reliable networks. In:
INFOCOM 2015, pp. 1760–1768 (2015)
21. Mihal´ak, M., Schlegel, J.C.: The price of anarchy in network creation games is
(mostly) constant. In: Kontogiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.)
SAGT 2010. LNCS, vol. 6386, pp. 276–287. Springer, Heidelberg (2010). doi:10.
1007/978-3-642-16170-4 24
22. Papadimitriou, C.H.: Algorithms, games, and the internet. In: STOC 2001, pp.
749–753 (2001)
23. Saha, S., Adiga, A., Vullikanti, A.K.S.: Equilibria in epidemic containment games.
In: AAAI, pp. 777–783 (2014)

Path Deviations Outperform Approximate
Stability in Heterogeneous Congestion Games
Pieter Kleer1 and Guido Sch¨afer1,2(B)
1 Centrum Wiskunde & Informatica (CWI), Networks and Optimization Group,
Amsterdam, The Netherlands
{kleer,schaefer}@cwi.nl
2 Department of Econometrics and Operations Research,
Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
Abstract. We consider non-atomic network congestion games with het-
erogeneous players where the latencies of the paths are subject to some
bounded deviations. This model encompasses several well-studied exten-
sions of the classical Wardrop model which incorporate, for example,
risk-aversion, altruism or travel time delays. Our main goal is to analyze
the worst-case deterioration in social cost of a deviated Nash ﬂow (i.e.,
for the perturbed latencies) with respect to an original Nash ﬂow.
We show that for homogeneous players deviated Nash ﬂows coincide
with approximate Nash ﬂows and derive tight bounds on their ineﬃ-
ciency. In contrast, we show that for heterogeneous populations this
equivalence does not hold. We derive tight bounds on the ineﬃciency
of both deviated and approximate Nash ﬂows for arbitrary player sen-
sitivity distributions. Intuitively, our results suggest that the negative
impact of path deviations (e.g., caused by risk-averse behavior or latency
perturbations) is less severe than approximate stability (e.g., caused by
limited responsiveness or bounded rationality).
We also obtain a tight bound on the ineﬃciency of deviated Nash
ﬂows for matroid congestion games and homogeneous populations if the
path deviations can be decomposed into edge deviations. In particular,
this provides a tight bound on the Price of Risk-Aversion for matroid
congestion games.
1
Introduction
In 1952, Wardrop [17] introduced a simple model, also known as the Wardrop
model, to study outcomes of selﬁsh route choices in traﬃc networks which are
aﬀected by congestion. In this model, there is a continuum of non-atomic play-
ers, each controlling an inﬁnitesimally small amount of ﬂow, whose goal is to
choose paths in a given network to minimize their own travel times. The latency
(or delay) of each edge is prescribed by a non-negative, non-decreasing latency
function which depends on the total ﬂow on that edge. Ever since its introduc-
tion, the Wardrop model has been used extensively, both in operations research
and traﬃc engineering studies, to investigate various aspects of selﬁsh routing
in networks.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 212–224, 2017.
DOI: 10.1007/978-3-319-66700-3 17

Path Deviations Outperform Approximate Stability
213
More recently, the classical Wardrop model has been extended in various ways
to capture more complex player behaviors. Examples include the incorporation
of uncertainty attitudes (e.g., risk-aversion, risk-seeking), cost alterations (e.g.,
latency perturbations, road pricing), other-regarding dispositions (e.g., altruism,
spite) and player biases (e.g., responsiveness, bounded rationality).
Several of these extensions can be viewed as deﬁning some modiﬁed cost
for each path which combines the original latency with some ‘deviation’ (or
perturbation) along that path. Such deviations are said to be β-bounded if the
total deviation along each path is at most β times the latency of that path. The
player objective then becomes to minimize the combined cost of latency and
deviation along a path (possibly using diﬀerent norms). An equilibrium outcome
corresponds to a β-deviated Nash ﬂow, i.e., a Nash ﬂow with respect to the
combined cost. The deviations might be given explicitly (e.g., as in the altruism
model of Chen et al. [1]) or be deﬁned implicitly (e.g., as in the risk-aversion
model of Nikolova and Stier-Moses [13]). Further, diﬀerent fractions of players
might perceive these deviations diﬀerently, i.e., players might be heterogeneous
with respect to the deviations.
Another extension, which is closely related to the one above, is to incorporate
diﬀerent degrees of ‘responsiveness’ of the players. For example, each player
might be willing to deviate to an alternative route only if her latency decreases
by at least a certain fraction. In this context, an equilibrium outcome corresponds
to an ϵ-approximate Nash ﬂow for some ϵ ≥0, i.e., for each player the latency
is at most (1 + ϵ) times the latency of any other path. Here, ϵ is a parameter
which reﬂects the responsiveness of the players. An analogue deﬁnition can be
given for populations with heterogeneous responsiveness parameters.
To illustrate the relation between deviated and approximate Nash ﬂows, sup-
pose we are given a β-deviated Nash ﬂow f for some β ≥0, where the latency
ℓP (f) of each path P is perturbed by an arbitrary β-bounded deviation δP (f)
satisfying 0 ≤δP (f) ≤βlP (f). Intuitively, the deviations inﬂate the latency on
each path by at most a factor of (1 + β). Further, assume that the population is
homogeneous. From the Nash ﬂow conditions (see Sect. 2 for formal deﬁnitions),
it follows trivially that f is also an ϵ-approximate Nash ﬂow with ϵ = β. But does
the converse also hold? That is, can every ϵ-approximate Nash ﬂow be induced
by a set of bounded path deviations? More generally, what about the relation
between deviated and approximate Nash ﬂows for heterogenous populations?
Can we bound the ineﬃciency of these ﬂows?
In this paper, we answer these questions by investigating the relation between
the two equilibrium notions. Our main goal is to quantify the ineﬃciency of
deviated and approximate Nash ﬂows, both for homogeneous and heterogeneous
populations. To this aim, we study the (relative) worst-case deterioration in
social cost of a β-deviated Nash ﬂow with respect to an original (unaltered)
Nash ﬂow; we use the term β-deviation ratio to refer to this ratio. This ratio has
recently been studied in the context of risk aversion [9,13] and in the more general
context of bounded path deviations [6]. Similarly, for approximate Nash ﬂows we
are interested in bounding the ϵ-stability ratio, i.e., the worst-case deterioration
in social cost of an ϵ-approximate Nash ﬂow with respect to an original Nash ﬂow.

214
P. Kleer and G. Sch¨afer
Note that these notions diﬀer from the classical price of anarchy notion [8],
which refers to the worst-case deterioration in social cost of a β-deviated (respec-
tively, ε-approximate) Nash ﬂow with respect to an optimal ﬂow. While the
price of anarchy typically depends on the class of latency functions (see, e.g.,
[1,2,6,13] for results in this context), the deviation ratio is independent of the
latency functions but depends on the topology of the network (see [6,13]).
Our Contributions. The main contributions of this paper are as follows:
1. We show that for homogeneous populations the set of β-deviated Nash ﬂows
coincides with the set of ϵ-approximate Nash ﬂows for β = ϵ. Further, we
derive an upper bound on the ϵ-stability ratio (and thus also on the ϵ-deviation
ratio) which is at most (1 + ϵ)/(1 −ϵn), where n is the number of nodes, for
single-commodity networks. We also prove that the upper bound we obtain
is tight for generalized Braess graphs. These results are presented in Sect. 4.
2. We prove that for heterogenous populations the above equivalence does not
hold. We derive tight bounds for both the β-deviation ratio and the ϵ-stability
ratio for single-commodity instances on series-parallel graphs and arbitrary
sensitivity distributions of the players. To the best of our knowledge, these
are the ﬁrst ineﬃciency results in the context of heterogenous populations
which are tight for arbitrary sensitivity distributions. Our bounds show that
both ratios depend on the demands and sensitivity distribution γ of the het-
erogenous players (besides the respective parameters β and ϵ). Further, it
turns out that the β-deviation ratio is always at most the ϵ-stability ratio for
ϵ = βγ. These results are given in Sect. 3.
3. We also derive a tight bound on the β-deviation ratio for single-commodity
matroid congestion games and homogeneous populations if the path devia-
tions can be decomposed into edge deviations. To the best of our knowledge,
this is the ﬁrst result in this context which goes beyond network congestion
games. In particular, this gives a tight bound on the Price of Risk-Aversion
[13] for matroid congestion games. This result is of independent interest and
presented in Sect. 4.
In a nutshell, our results reveal that for homogeneous populations there
is no quantitative diﬀerence between the ineﬃciency of deviated and approx-
imate Nash ﬂows in the worst case. In contrast, for heterogenous populations
the β-deviation ratio is always at least as good as the ϵ-stability ratio with
ϵ = βγ. Intuitively, our results suggest that the negative impact of path devia-
tions (e.g., caused by risk-averse behavior or latency perturbations) is less severe
than approximate stability (e.g., caused by limited responsiveness or bounded
rationality).
Related Work. We give a brief overview of the works which are most related
to our results. Christodoulou et al. [2] study the ineﬃciency of approximate
equilibria in terms of the price of anarchy and price of stability (for homogeneous
populations). Generalized Braess graphs were introduced by Roughgarden [14]

Path Deviations Outperform Approximate Stability
215
and are used in many other lower bound constructions (see, e.g., [3,6,14]). Chen
et al. [1] study an altruistic extension of the Wardrop model and, in particular,
also consider heterogeneous altruistic populations. They obtain an upper bound
on the ratio between an altruistic Nash ﬂow and a social optimum for parallel
graphs, which is tight for two sensitivity classes. It is mentioned that this bound
is most likely not tight in general. Meir and Parkes [11] study player-speciﬁc cost
functions in a smoothness framework [15]. Some of their ineﬃciency results are
tight, although none of their bounds seems to be tight for arbitrary sensitivity
distributions. Matroids have also received some attention in the Wardrop model.
In particular, Fujishige et al. [5] show that matroid congestion games are immune
against the Braess paradox (and their analysis is tight in a certain sense). We
refer the reader to [6] for additional references and relations of other models to
the bounded path deviation model considered here.
2
Preliminaries
Let I = (E, (le)e∈E, (Si)i∈[k], (ri)i∈[k]) be an instance of a non-atomic congestion
game. Here, E is the set of resources (or edges, or arcs) that are equipped with a
non-negative, non-decreasing, continuous latency function le : R≥0 →R≥0. Each
commodity i ∈[k] has a strategy set Si ⊆2E and demand ri ∈R>0. Note that in
general the strategy set Si of player i is deﬁned by arbitrary resource subsets. If
each strategy P ∈Si corresponds to an si, ti-path in a given directed graph, then
the corresponding game is called a network congestion game.1 We slightly abuse
terminology and use the term path also to refer to a strategy P ∈Si of player i
(which does not necessarily correspond to a path in a graph); no confusion shall
arise. We denote by S = ∪iSi the set of all paths.
An outcome of the game is a (feasible) ﬂow f i : Si →R≥0 satisfying

P ∈Si f i
P = ri for every i ∈[k]. We use F(S) to denote the set of all feasible
ﬂows f = (f 1, . . . , f k). Given a ﬂow f = (f i)i∈[k] ∈F(S), we use f i
e to denote
the total ﬂow on resource e ∈E of commodity i ∈[k], i.e., f i
e = 
P ∈Si:e∈P f i
P .
The total ﬂow on edge e ∈E is deﬁned as fe = 
i∈[k] f i
e.
The latency of a path P ∈S with respect to f is deﬁned as lP (f) :=

e∈P le(fe). The cost of commodity i with respect to f
is Ci(f)
=

P ∈Si fP lP (f). The social cost C(f) of a ﬂow f is given by its total aver-
age latency, i.e., C(f) = 
i∈[k] Ci(f) = 
e∈E fele(fe). A ﬂow that minimizes
C(·) is called (socially) optimal.
If the population is heterogenous, then each commodity i ∈[k] is further
partitioned in hi sensitivity classes, where class j ∈[hi] has demand rij such
that ri = 
j∈[hi] rij. Given a path P ∈Si, we use fP,j to refer to the amount
of ﬂow on path P of sensitivity class j (so that 
j∈[hi] fP,j = fP ).
1 If a network congestion game with a single commodity is considered (i.e., k = 1), we
omit the commodity index for ease of notation.

216
P. Kleer and G. Sch¨afer
Deviated Nash ﬂows. We consider a bounded deviation model similar to the one
introduced in [6].2 We use δ = (δP )P ∈S to denote some arbitrary path deviations,
where δP : F(S) →R≥0 for all P ∈S. Let β ≥0 be ﬁxed. Deﬁne the set of
β-bounded path deviations as Δ(β) = {(δP )P ∈S | 0 ≤δP (f) ≤βlP (f) for all f ∈
F(S)}.
Every commodity i ∈[k] and sensitivity class j ∈[hi] has a non-negative sen-
sitivity γij with respect to the path deviations. The population is homogeneous
if γij = γ for all i ∈[k], j ∈[hi] and some γ ≥0; otherwise, it is heterogeneous.
Deﬁne the deviated latency of a path P ∈Si for sensitivity class j ∈[hi] as
qj
P (f) = lP (f) + γijδP (f).
We say that a ﬂow f is a β-deviated Nash ﬂow if there exist some β-bounded
path deviations δ ∈Δ(β) such that
∀i ∈[k], ∀j ∈[hi], ∀P ∈Si, fP,j > 0 :
qj
P (f) ≤qj
P ′(f) ∀P ′ ∈Si.
(1)
We deﬁne the β-deviation ratio β-DR(I) as the maximum ratio C(f β)/C(f 0)
of an β-deviated Nash ﬂow f β and an original Nash ﬂow f 0. Intuitively, the
deviation ratio measures the worst-case deterioration in social cost as a result
of (bounded) deviations in the path latencies. Note that here the comparison
is done with respect to an unaltered Nash ﬂow to measure the impact of these
deviations.
The set Δ(β) can also be restricted to path deviations which are deﬁned
as a function of edge deviations along that path. Suppose every edge e ∈E
has a deviation δe : R≥0 →R≥0 satisfying 0 ≤δe(x) ≤βle(x) for all
x ≥0. For example, feasible path deviations can then be deﬁned by the L1-
norm objective δP (f) = 
e∈P δe(x) (as in [6,13]) or the L2-norm objective
δP (f) =

e∈P δe(x)2) (as in [9,13]). The Price of Risk-Aversion introduced
by Nikolova and Stier-Moses [13] is technically the same ratio as the deviation
ratio for the L1- and L2-norm (see [6] for details).
Approximate Nash Flows. We introduce the notion of an approximate Nash
ﬂow. Also here, each commodity i ∈[k] and sensitivity class j ∈[hi] has a non-
negative sensitivity ϵij. We say that the population is homogeneous if ϵij = ϵ for
all i ∈[k], j ∈[hi] and some ϵ ≥0; otherwise, it is heterogeneous.
A ﬂow f is an ϵ-approximate Nash ﬂow with respect to sensitivities ϵ =
(ϵij)i∈[k],j∈[hi] if
∀i ∈[k], ∀j ∈[hi], ∀P ∈Si, fP,j > 0 :
lP (f) ≤(1+ϵij)lP ′(f) ∀P ′ ∈Si (2)
Note that a 0-approximate Nash ﬂow is simply a Nash ﬂow. We deﬁne the ϵ-
stability ratio ϵ-SR(I) as the maximum ratio C(f ϵ)/C(f 0) of an ϵ-approximate
Nash ﬂow f ϵ and an original Nash ﬂow f 0.
Some of the proofs are missing in the main text below and can be found in
[7].
2 In fact, in [6] more general path deviations are introduced; the path deviations
considered here correspond to (0, β)-path deviations in [6].

Path Deviations Outperform Approximate Stability
217
3
Heterogeneous Populations
We ﬁrst elaborate on the relation between deviated and approximate Nash ﬂows
for general congestion games with heterogeneous populations.
Proposition 1. Let I be a congestion game with heterogeneous players. If f is
a β-deviated Nash ﬂow for I, then f is an ϵ-approximate Nash ﬂow for I with
ϵij = βγij for all i ∈[k] and j ∈[hi] (for the same demand distribution r).
Discrete Sensitivity Distributions. Subsequently, we show that the reverse of
Proposition 1 does not hold. We do this by providing tight bounds on the β-
deviation ratio and the ϵ-stability ratio for instances on (single-commodity)
series-parallel graphs and arbitrary discrete sensitivity distributions.
Theorem 1. Let I be a single-commodity network congestion game on a series-
parallel graph with heterogeneous players, demand distribution r = (ri)i∈[h] nor-
malized to 1, i.e., 
j∈[h] ri = 1, and sensitivity distribution γ = (γi)i∈[h], with
γ1 < γ2 < · · · < γh. Let β ≥0 be ﬁxed and deﬁne ϵ = (βγi)i∈[h]. Then the
ϵ-stability ratio and the β-deviation ratio are bounded by:
ϵ-SR(I) ≤1 + β
h

j=1
rjγj
and
β-DR(I) ≤1 + β · max
j∈[h]

γj

h

p=j
rp

.
(3)
Further, both bounds are tight for all distributions r and γ.
It is not hard to see that the bound on the β-deviation ratio is always smaller
than the bound on the ϵ-stability ratio.3 Our bound on the β-deviation ratio also
yields tight bounds on the Price of Risk-Aversion [13] for series-parallel graphs
and arbitrary heterogeneous risk-averse populations, both for the L1-norm and
L2-norm objective.4
We need the following technical lemma for the proof of the β-deviation ratio.
Lemma 1. Let 0 ≤τk−1 ≤· · · ≤τ1 ≤τ0 and ci ≥0 for i = 1, . . . , k be given.
We have c1τ0 + k−1
i=1 (ci+1 −ci)τi ≤τ0 · maxi=1,...,k{ci}.
Proof (Theorem 1, β-deviation ratio). Let x = f β be a β-deviated Nash ﬂow
with path deviations (δP )P ∈S ∈Δ(β) and let z = f 0 be an original Nash ﬂow.
Let X = {a ∈A : xa > za} and Z = {a ∈A : za ≥xa and za > 0} (arcs with
xa = za = 0 may be removed without loss of generality).
In order to analyze the ratio C(x)/C(z) we ﬁrst argue that we can assume
without loss of generality that the latency function la(y) is constant for values
y ≥xa for all arcs a ∈Z. To see this, note that we can replace the function la(·)
with the function ˆla deﬁned by ˆla(y) = la(xa) for all y ≥xa and ˆla(y) = la(y)
3 This follows from Markov’s inequality: for a random variable Y , P(Y ≥t) ≤E(Y )/t.
4 Observe that we show tightness of the bound on parallel arcs, in which case these
objectives coincide.

218
P. Kleer and G. Sch¨afer
for y ≤xa. In particular, this implies that the ﬂow x is still a β-deviated Nash
ﬂow for the same path deviations as before. This holds since for any path P the
latency lP (x) remains unchanged if we replace the function la by ˆla.
By deﬁnition of arcs in Z, we have xa ≤za and therefore ˆla(za) = la(xa) ≤
la(za). Let z′ be an original Nash ﬂow for the instance with la replaced by ˆla.
Then we have C(z′) ≤C(z) using the fact that series-parallel graphs are immune
to the Braess paradox, see Milchtaich [12, Lemma 4]. Note that, in particular,
we ﬁnd C(x)/C(z) ≤C(x)/C(z′). By repeating this argument, we may without
loss of generality assume that all latency functions la are constant between xa
and za for a ∈Z. Afterwards, we can even replace the function ˆla by a function
that has the constant value of la(xa) everywhere.
In the remainder of the proof, we will denote Pj as a ﬂow-carrying arc for sen-
sitivity class j ∈[h] that maximizes the path latency amongst all ﬂow-carrying
path for sensitivity class j ∈[h], i.e., Pj = argmaxP ∈P:xP,j>0{lP (x)}. Moreover,
there also exists a path P0 with the property that za ≥xa and za > 0 for all
arcs a ∈P0 (see, e.g., Lemma 2 [12]).
For ﬁxed a < b ∈{1, . . . , h}, the Nash conditions imply that (these steps are
of a similar nature as Lemma 1 [4])
lPa(x) + γa · δPa(x) ≤lPb(x) + γa · δPb(x)
lPb(x) + γb · δPb(x) ≤lPa(x) + γb · δPa(x).
Adding up these inequalities implies that (γb−γa)δPb(x) ≤(γb−γa)δPa(x), which
in turn yields that δPb(x) ≤δPa(x) (using that γa < γb if a < b). Furthermore,
we also have
lP1(x) + γ1δP1(x) ≤lP0(x) + γ1δP0(x),
(4)
and lP0(x) = lP0(z) ≤lP1(z) ≤lP1(x), which can be seen as follows. The equality
follows from the fact that la is constant for all a ∈Z and, by choice, P0 only
consists of arcs in Z. The ﬁrst inequality follows from the Nash conditions of the
original Nash ﬂow z, since there exists a ﬂow-decomposition in which the path
P0 is used (since the ﬂow on all arcs of P0 is strictly positive in z). The second
inequality follows from the fact that

e∈P1
le(ze) =

e∈P1∩X
le(ze) +

e∈P1∩Z
le(ze) ≤

e∈P1∩X
le(xe) +

e∈P1∩Z
le(xe)
using that ze ≤xe for e ∈X and the fact that latency functions for e ∈Z
are constant. In particular, we ﬁnd that lP0(x) ≤lP1(x). Adding this inequality
to (4), we obtain γ1δP1(x) ≤γ1δP0(x) and therefore δP1(x) ≤δP0(x). Thus
δPh(x) ≤δPh−1(x) ≤· · · ≤δP1(x) ≤δP0(x). Moreover, by using induction it can
be shown that
lPj(x) ≤lP0(x) + γ1δP0(x) +
	 j−1

g=1
(γg+1 −γg)δPg(x)

−γjδPj(x).
(5)

Path Deviations Outperform Approximate Stability
219
Using (5), we then have
C(x) ≤
h

j=1
rjlPj(x)
(by choice of the paths Pj)
≤
h

j=1
rj

lP0(x) + γ1δP0(x) +
	 j−1

g=1
(γg+1 −γg)δPg(x)

−γjδPj(x)

= lP0(x) + γ1δP0(x) +
h

j=1
(rj+1 + · · · + rh)(γj+1 −γj)δPj(x) −rjγjδPj(x)
≤lP0(x) + γ1δP0(x)
+
h−1

j=1
	
(rj+1 + · · · + rh)γj+1 −(rj + rj+1 + · · · + rh)γj

δPj(x)
In the last inequality, we leave out the last negative term −rhγhδPh(x). Note
that γ1 = (r1 + · · · + rh)γ1 since we have normalized the demand to 1. We can
then apply Lemma 1 with τi = δPi(x) for i = 0, . . . , h −1 and ci = γi · h
p=i rp
for i = 1, . . . , k. Continuing the estimate, we get
C(x) ≤lP0(x) + max
j∈[h]

γj ·
h

p=j
rp

· δP0(x) ≤
	
1 + β · max
j∈[h]

γj

h

p=j
rp

C(z)
where for the second inequality we use that δP0(x) ≤βlP0(x), which holds by
deﬁnition, and lP0(x) = lP0(z) = C(z), which holds because z is an original Nash
ﬂow and all arcs in P0 have strictly positive ﬂow in z (and because of the fact
that all arcs in P0 have a constant latency functions).
To prove tightness, ﬁx j ∈[h] and consider the following instance on two
arcs. We take (l1(y), δ1(y)) = (1, β) and (l2(y), δ2(y)) with δ2(y) = 0 and l2(y)
a strictly increasing function satisfying l2(0) = 1 + ϵ and l2(rj + rj+1 + · · · +
rh) = 1 + γjβ, where ϵ < γjβ. The (unique) original Nash ﬂow is given by
z = (z1, z2) = (1, 0) with C(z) = 1. The (unique) β-deviated Nash ﬂow x
is given by x = (x1, x2) = (r1 + r2 + · · · + rj−1, rj + rj+1 + · · · + rh) with
C(x) = 1 + β · γj(rj + · · · + rh). Since this construction holds for all j ∈[h], we
ﬁnd the desired lower bound.
⊓⊔
Continuous Sensitivity Distributions. We obtain a similar result for more gen-
eral (not necessarily discrete) sensitivity distributions. That is, we are given a
Lebesgue integrable sensitivity density function ψ : R≥0 →R≥0 over the total
demand. Since we can normalize the demand to 1, we have the condition that
 ∞
0
ψ(y)dy = 1. We then ﬁnd the following natural generalizations of our upper
bounds:
1. ϵ-SR(I) ≤1 + β
 ∞
0
y · ψ(y)dy, and
2. β-DR(I) ≤1 + β · supt∈R≥0

t ·
 ∞
t
ψ(y)dy

.
These bounds are both asymptotically tight for all distributions. Details are
given the full version [7].

220
P. Kleer and G. Sch¨afer
4
Homogeneous Population
The reverse of Proposition 1 also holds for homogeneous players in single-
commodity instances. As a consequence, the set of β-deviated Nash ﬂows and
the set of ϵ-approximate Nash ﬂows with ϵ = βγ coincide in this case.
Recall that for homogeneous players we have γij = γ for all i ∈[k], j ∈[hi]
and some γ ≥0.
Proposition 2. Let I be a single-commodity congestion game with homoge-
neous players. f is an ϵ-approximate Nash ﬂow for I if and only if f is a
β-deviated Nash ﬂow for I with ϵ = βγ.
Upper Bound on the Stability Ratio. Our main result in this section is an upper
bound on the ϵ-stability ratio. Given the above equivalence, this bound also
applies to the β-deviation ratio with ϵ = βγ.
The following concept of alternating paths is crucial. For single-commodity
instances an alternating path always exists (see, e.g., [13]) (Fig. 1).
Z1
C11
C21
C22
X11
Z2
X21
X22
D11
D21
D22
Z3
Fig. 1. Sketch of the situation in the proof of Theorem 2 with q1 = 1 and q2 = 2.
Deﬁnition 1 (Alternating path [10,13]). Let I be a single-commodity net-
work congestion game and let x and z be feasible ﬂows. We partition the
edges E = X ∪Z such that Z = {a ∈E : za ≥xa and za > 0} and
X = {a ∈E : za < xa or za = xa = 0}. We say that π is an alternating
s, t-path if the arcs in π ∩Z are oriented in the direction of t, and the arcs in
π ∩X are oriented in the direction of s. We call the number of backward arcs
on π the backward length of π and refer to it by q(π) = |π ∩X|.
Theorem 2. Let I be a single-commodity network congestion game. Let ϵ ≥0 be
ﬁxed and consider an arbitrary alternating path π with backward length q = q(π).
If ϵ < 1/q, then the ϵ-stability ratio is bounded by
ϵ-SR(I) ≤
1 + ϵ
1 −ϵ · q ≤
1 + ϵ
1 −ϵ · n.
Note that the restriction on ϵ stated in the theorem always holds if ϵ < 1/n. In
particular, for ϵ ≪1/n we roughly get ϵ-SR(I) ≤1+ϵn. The proof of Theorem 2
is inspired by a technique of Nikolova and Stier-Moses [13], but technically more
involved.

Path Deviations Outperform Approximate Stability
221
Proof. Let x = f ϵ be an ϵ-approximate Nash ﬂow and let z = f 0 an original
Nash ﬂow. Let π = Z1X1Z2X2 . . . Zη−1Xη−1Zη be an alternating path for x
and z, where Zi and Xi are maximal sections consisting of consecutive arcs,
respectively, in Z and X (i.e., Zi ⊆Z and Xi ⊆X for all i). Furthermore, we
let qi = |Xi| and write Xi = (Xiqi, . . . , Xi2, Xi1), where Xij are the arcs in the
section Xi. By deﬁnition, for every arc Xij there exists a path CijXijDij that
is ﬂow-carrying for x.5
For convenience, we deﬁne C01 = Dη,0 = ∅. Furthermore, we denote P max as
a path maximizing lP (x) over all paths P ∈S. For convenience, we will abuse
notation, and write Q = Q(x) = 
a∈Q la(x) for Q ⊆E.
Note that for all i, j:
Cij(x) + Xij(x) + Dij(x) ≤P max(x).
(6)
Fix some i ∈{1, . . . , η−1}. Then we have Ci1+Xi1+Di1 ≤(1+ϵ)(Ci−1,qi−1+
Zi +Di1) by deﬁnition of an ϵ-approximate Nash ﬂow. This implies that (leaving
out Di1 on both sides) Ci1 + Xi1 ≤(1 + ϵ)Zi + Ci−1,qi−1 + ϵ(Ci−1,qi−1 + Di1).
Furthermore, for all j ∈{2, . . . , qi}, we have Cij+Xij+Dij ≤(1+ϵ)(Ci,j−1+Dij)
which implies (again leaving out Dij on both sides)
Cij + Xij ≤Ci,j−1 + ϵ(Ci,j−1 + Dij).
Adding up these inequalities for j ∈{1, . . . , qi} and subtracting qi−1
j=1 Cij from
both sides, we obtain for all i ∈{1, . . . , η −1}
Ci,qi +
qi

j=1
Xij ≤Ci−1,qi−1 + (1 + ϵ)Zi + ϵ
 qi

j=1
Dij + Ci−1,qi−1 +
qi−1

j=1
Cij

. (7)
Moreover, we also have
P max ≤(1 + ϵ)(Cη−1,η−1 + Zη) = Cη−1,η−1 + (1 + ϵ)Zη + ϵCη−1,η−1.
(8)
Adding up the inequalities in (7) for all i ∈{1, . . . , η −1}, and the inequality in
(8), we obtain
P max +
η−1

i=1
Ci,qi +
η−1

i=1
qi

j=1
Xij ≤
η−1

i=1
Ci,qi +(1+ϵ)
η

i=1
Zi +ϵ
 η−1

i=1
qi

j=1
Cij +Dij

which simpliﬁes to
P max +
η−1

i=1
qi

j=1
Xij ≤(1 + ϵ)
η

i=1
Zi + ϵ
 η−1

i=1
qi

j=1
Cij + Dij

.
(9)
5 Note that for a Nash ﬂow one can assume that there is a ﬂow-carrying path traversing
all arcs Xiqi, . . . , Xi1; but this cannot be done for an approximate Nash ﬂow.

222
P. Kleer and G. Sch¨afer
Using (6), we obtain
η−1

i=1
qi

j=1
Cij + Dij ≤
η−1

i=1
qi

j=1
P max −Xij =
 η−1

i=1
qi

P max −
η−1

i=1
qi

j=1
Xij.
Combining this with (9), and rearranging some terms, we get
(1 −ϵ · q)P max ≤(1 + ϵ)
	
η

i=1
Zi −
η−1

i=1
qi

j=1
Xij

= (1 + ϵ)
	 
e∈Z∩π
le(xe) −

e∈X∩π
le(xe)

where q = q(π) = η−1
i=1 qi is the backward length of π.
Similarly (see also [13, Lemma 4.5]), it can be shown that
lQ(z) ≥

e∈Z∩π
le(ze) −

e∈X∩π
le(ze)
(10)
for any path Q with zQ > 0 (these all have the same latency, since z is an original
Nash ﬂow). Using a similar argument as in [13, Theorem 4.6], we obtain
(1 −ϵ · q)lP max(x) ≤(1 + ϵ)
	 
e∈Z∩π
le(xe) −

e∈X∩π
le(xe)

≤(1 + ϵ)
	 
e∈Z∩π
le(ze) −

e∈X∩π
le(ze)

≤(1 + ϵ)lQ(z).
By multiplying both sides with the demand r, we obtain (1 −ϵ · q)C(x) ≤
(1 −ϵ · q)r · lP max(x) ≤(1 + ϵ)r · lQ(z) = (1 + ϵ)C(z) for ϵ < 1/q, which proves
the claim.
⊓⊔
Tight Bound on the Stability Ratio. In this section, we consider instances for
which all backward sections of the alternating path π consist of a single arc.,
i.e., qi = 1 for all i = 1, . . . , η −1. We then have q = η−1
i=1 qi ≤⌊n/2⌋−1 since
every arc in X must be followed directly by an arc in Z (and we can assume
w.l.o.g. that the ﬁrst and last arc are contained in Z). By Theorem 2, we obtain
ϵ-SR(I) ≤(1+ϵ)/(1−ϵ·(⌊n/2⌋−1)) for all ϵ < 1/(⌊n/2⌋−1). We show that this
bound is tight. Further, we show that there exist instances for which ϵ-SR(I) is
unbounded for ϵ ≥1/(⌊n/2⌋−1). This completely settles the case of qi = 1 for
all i.
Our construction is based on the generalized Braess graph [14]. By construc-
tion, alternating paths for these graphs satisfy qi = 1 for all i. See the full version
[7] for details.
Theorem 3. Let n = 2m be ﬁxed and let Bm be the set of all instances on the
generalized Braess graph with n nodes. Then
sup
I∈Bm ϵ-SR(I) =

1+ϵ
1−ϵ·(⌊n/2⌋−1)
if ϵ <
1
⌊n/2⌋−1,
∞
otherwise.

Path Deviations Outperform Approximate Stability
223
Non-symmetric Matroid Congestion Games. In the previous sections, we con-
sidered (symmetric) network congestion games only. It is interesting to consider
other combinatorial strategy sets as well. In this section we make a ﬁrst step in
this direction by focusing on the bases of matroids as strategies.
A matroid congestion game is given by J = (E, (le)e∈E, (Si)i∈[k], (ri)i∈[k]),
and matroids Mi = (E, Ii) over the ground set E for every i ∈[k].6 The strategy
set Si consists of the bases of the matroid Mi, which are the independent sets of
maximum size, e.g., spanning trees in an undirected graph. We refer the reader
to Schrijver [16] for an extensive overview of matroid theory.
As for network congestion games, it can be shown that in general the ϵ-
stability ratio can be unbounded (see Theorem 5 [7] in the appendix of [7]);
this also holds for general path deviations because the proof of Proposition 2
in the appendix holds for arbitrary strategy sets. However, if we consider path
deviations induced by the sum of edge deviations (as in [6,13]), then we can
obtain a more positive result for general matroids.
Recall that for every resource e ∈E we have a deviation function δe : R≥0 →
R≥0 satisfying 0 ≤δe(x) ≤βle(x) for all x ≥0. The deviation of a basis B is
then given by δB(f) = 
e∈B δe(fe).
Theorem 4. Let J = (E, (le)e∈E, (Si)i∈[k], (ri)i∈[k]) be a matroid congestion
game with homogeneous players. Let β ≥0 be ﬁxed and consider β-bounded
basis deviations as deﬁned above. Then the β-deviation ratio is upper bounded
by β-DR(J ) ≤1 + β. Further, this bound is tight already for 1-uniform matroid
congestion games.
Acknowledgements. We thank the anonymous referees for their very useful com-
ments, and one reviewer for pointing us to Lemma 1 [4].
References
1. Chen, P.-A., Keijzer, B.D., Kempe, D., Sch¨afer, G.: Altruism and its impact on
the price of anarchy. ACM Trans. Econ. Comput. 2(4), 17:1–17:45 (2014)
2. Christodoulou, G., Koutsoupias, E., Spirakis, P.G.: On the performance of approx-
imate equilibria in congestion games. Algorithmica 61(1), 116–140 (2011)
3. Englert, M., Franke, T., Olbrich, L.: Sensitivity of Wardrop equilibria. In: Monien,
B., Schroeder, U.-P. (eds.) SAGT 2008. LNCS, vol. 4997, pp. 158–169. Springer,
Heidelberg (2008). doi:10.1007/978-3-540-79309-0 15
4. Fleischer, L.: Linear tolls suﬃce: new bounds and algorithms for tolls in single
source networks. Theoret. Comput. Sci. 348(2), 217–225 (2005)
5. Fujishige, S., Goemans, M.X., Harks, T., Peis, B., Zenklusen, R.: Matroids are
immune to braess paradox. CoRR, abs/1504.07545 (2015)
6. Kleer, P., Sch¨afer, G.: The impact of worst-case deviations in non-atomic network
routing games. CoRR, abs/1605.01510 (2016)
6 A matroid over E is given by a collection I ⊆2E of subsets of E (called independent
sets). The pair M = (E, I) is a matroid if the following three properties hold: (i)
∅∈I; (ii) If A ∈I and B ⊆A, then B ∈I. (iii) If A, B ∈I and |A| > |B|, then
there exists an a ∈A \ B such that B + a ∈I.

224
P. Kleer and G. Sch¨afer
7. Kleer, P., Sch¨afer, G.: Path deviations outperform approximate stability in hetero-
geneous congestion games. CoRR, abs/1707.01278 (2017)
8. Koutsoupias, E., Papadimitriou, C.: Worst-case equilibria. In: Meinel, C., Tison,
S. (eds.) STACS 1999. LNCS, vol. 1563, pp. 404–413. Springer, Heidelberg (1999).
doi:10.1007/3-540-49116-3 38
9. Lianeas, T., Nikolova, E., Stier-Moses, N.E.: Asymptotically tight bounds for
ineﬃciency in risk-averse selﬁsh routing. In: Proceedings of the Twenty-Fifth
International Joint Conference on Artiﬁcial Intelligence. IJCAI 2016, NY, USA,
New York, pp. 338–344 (2016)
10. Lin, H., Roughgarden, T., Tardos, ´E., Walkover, A.: Stronger bounds on Braess’s
paradox and the maximum latency of selﬁsh routing. SIAM J. Discrete Math.
25(4), 1667–1686 (2011)
11. Meir, R., Parkes, D.C.: Playing the wrong game: smoothness bounds for congestion
games with risk averse agents. CoRR, abs/1411.1751 (2017)
12. Milchtaich, I.: Network topology and the eﬃciency of equilibrium. Games Econ.
Behav. 57(2), 321–346 (2006)
13. Nikolova, E., Stier-Moses, N.E.: The burden of risk aversion in mean-risk self-
ish routing. In: Proceedings of the Sixteenth ACM Conference on Economics and
Computation, EC 2015, pp. 489–506. ACM, New York (2015)
14. Roughgarden, T.: On the severity of Braess’s paradox: designing networks for selﬁsh
users is hard. J. Comput. Syst. Sci. 72(5), 922–953 (2006)
15. Roughgarden, T.: Intrinsic robustness of the price of anarchy. J. ACM 62(5), 32
(2015)
16. Schrijver, A.: Combinatorial Optimization: Polyhedra and Eﬃciency Vol. B
Matroids Trees Stable Sets Algorithms and Combinatorics. Springer, Heidelberg
(2003). Chaps. 39–69
17. Wardrop, J.G.: Some theoretical aspects of road traﬃc research. In: Proceedings
of the Institution of Civil Engineers, vol. 1, pp. 325–378 (1952)

Mechanism Design, Incentives and
Regret Minimization

Agent Incentives of Strategic Behavior
in Resource Exchange
Zhou Chen1, Yukun Cheng2(B), Xiaotie Deng3, Qi Qi1, and Xiang Yan3
1 Department of Industrial Engineering and Logistics Management,
Hong Kong University of Science and Technology, Kowloon, Hong Kong
zchenaq@connect.ust.hk, kaylaqi@ust.hk
2 School of Data Science, Zhejiang University of Finance and Economics,
Hangzhou, China
ykcheng@amss.ac.cn
3 Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China
deng-xt@cs.sjtu.edu.cn, xyansjtu@163.com
Abstract. In a resource exchange system, resources are shared among
multiple interconnected peers. Peers act as both suppliers and customers
of resources by making a certain amount of their resources directly avail-
able to other network participants. Their utilities are determined by the
total amount of resources received from all neighbors. According to a
preset mechanism, the allocation of the shared resources depends on
the information that agents submit to the mechanism. The participat-
ing agents, however, may try to strategically manipulate its submitted
information to inﬂuence the allocation with the expectation of its utility
improvement. In this paper, we consider the tit-for-tat popular propor-
tional response mechanism and discuss the incentives an agent may lie,
by a vertex splitting strategy. We apply the concept of incentive ratio to
characterize the multiplication factor by which utility of an agent can
be increased with the help of the vertex splitting strategy. Because of
the bounded rationality in the decentralized resource exchange system,
a smaller incentive ratio makes the agents have the less incentive to play
strategically. However the incentive ratio is proved to be unbounded in
linear exchange market recently. In this paper we focus on the setting on
trees, our linear exchange market proves to have the incentive ratio of
exact two under the proportional response mechanism against the vertex
splitting strategic behaviors of participating agents.
1
Introduction
The rapid growth of wireless and mobile Internet has led to wide applications of
exchanging resources over networks. Participants in such networks act as both
suppliers and customers of resources (such as processing power, disk storage
or network bandwidth), and make their resources directly available to others
according to preset rules [14]. To motivate sharing, [9] pioneered the use of
incentive techniques to drive cooperation and to promote voluntary contributions
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 227–239, 2017.
DOI: 10.1007/978-3-319-66700-3 18

228
Z. Chen et al.
by participating agents. Taking this approach, the BitTorrent protocol, created
by Cohen in 2001, has been well recognized as an Internet success that changed
“the entertainment industry and the interchange of information in Web” [8]. In
the past couple of years, the widespread applications of mobile technologies have
further made sharing, together with the rising of mobile enabled companies such
as Uber, a focal point in the interface of computer science and economics [15].
To capture the success of BitTorrent, Wu and Zhang [17] introduced the
proportional response protocol, under which each peer contributes its resource
to each neighbor in proportion to the amount received from its neighbors. They
showed its economic eﬃciency by its convergence to the market equilibrium of a
pure exchange economy. In recent works, [6,7] proved the incentive advantage of
this protocol against strategic behavior of mis-reporting connectivity and agent
capacities. In this paper, we further exploring its resistance to manipulative
behavior by considering a setting where an agent disguises itself by creating
several copied false nodes with its resources split among them, such as one may
take new IP addresses in the network environment.
The problem is modeled by an undirected graph G, where each vertex v
represents an agent with wv units of divisible resources (or weight) for sharing
among its neighbors. The utility Uv is the sum of resources obtained from its
neighbors. The proportional response mechanism will send out each vertex’s
resource to its neighbors in proportion to the amount it receives from all its
neighbors. The concern is associated with a cheating strategy of an agent v who
splits itself into a subset of nodes such that each is connected to some of its
original neighbors and is assigned a certain amount of resource of v (summing
up to its original amount of resource) to manipulate the proportional response
mechanism. The new utility of this agent is calculated by summing over all its
copied nodes’. Conveniently, we name this strategic behavior as vertex splitting.
Example 1. Consider graph G of 4 vertices in Fig. 1(a). At equilibrium, v3 gets
its utility 5 from v4. In Fig. 1(b), v3 splits itself into two copied nodes v1
3 and
v2
3, and assigns resource 1 to each node respectively. The new utility of v3 is
20/3, which is larger than its original utility 5. (In Sect. 2 we will explain how
to compute the utility from the proportional response mechanism in details.)
Fig. 1. Numbers in cycles are weights; dashed arrows indicate resource exchange
amounts in the proportional sharing mechanism.
Example 1 exhibits a vulnerability of the proportional response mechanism
against the vertex splitting strategy. The next immediate question is its level of

Agent Incentives of Strategic Behavior in Resource Exchange
229
signiﬁcance for which is characterized by the concept of incentive ratio, intro-
duced in [5], deﬁned as the ratio of the largest possible utility that an agent can
gain by cheating and its utility in honest behavior under a given mechanism. In
the resource exchange environment, all agents only have limited knowledge due
to the decentralization of the system. Therefore they need an incredible eﬀort to
know the full information of the game and do complicated computation as well.
Thus a smaller incentive ratio implies that an agent has less incentive to play
strategically as ﬁnding the optimal splitting strategy is too diﬃcult.
Related Work. The automated process through information and communica-
tion technology for Internet applications has made their successes relied on the
voluntary cooperations of participating agents. [9] pioneered the study of such
incentive techniques in mechanism design and in performance analysis for such
peer-to-peer resource sharing systems. The proportional response model for the
BitTorrent protocol for resource exchange was shown to be equivalent to the
market equilibrium solution in [17]. Agent strategic behavior in market equi-
librium has been analyzed in the Fisher market equilibrium for linear markets
[1] and for constant elasticity of substitution markets [3]. For the proportional
response sharing protocol, focusing on two types of strategic behaviors for each
agent: cheating on its connectivity with the rest of network and misreporting its
own resource amount, the system is known to be stable [6,7].
The vertex splitting behavior considered here is motivated by and similar
to false-name bid [19]. That is, the agent misrepresents itself by creating sev-
eral ﬁctitious identities. It is known that the VCG mechanism is not incentive
compatible against the false-name bidding, as a result of the study on the false-
name-proof auction mechanisms design [11,18], and on the eﬃciency guarantee
of the VCG mechanism [2].
The concept of incentive ratio [5] is motivated by the concept of price of
anarchy [12,16]. The former measures individual gains one may acquire in devi-
ation from truthful behavior, but the latter models the loss of social eﬃciency
in selﬁsh Nash equilibrium in comparison to social optimality.
Main Results. We analyze incentive ratio to quantitatively measure the maxi-
mal magnitude of utility gain by vertex splitting followed a proportional response
mechanism. We prove that the incentive ratios are exactly 2 on trees by propos-
ing proper examples for lower bound and characterizing the worst case network
structure for upper bound.
While the incentive ratio was known for the Fisher market with well charac-
terized matching bound of two for linear utilities [4,5], it is not applicable to our
setting of exchange market, a special case of the exchange economy. A recent
result [13] claims an unbounded incentive ratios in linear exchange economy. Our
results of bounded incentive ratio places the practical network sharing economy
with a market equilibrium solution more rational in terms of truthful behavior.

230
Z. Chen et al.
2
Preliminary
Our resource exchange system is based on a connected and undirected network
G = (V, E). Each vertex v ∈V represents an agent with an upload resource
amount (weight) wv > 0 for exchange with its neighbors, where Γ(v) = {u :
(v, u) ∈E} is the neighborhood of v. Let xvu be the amount of resource v
allocates to neighbor u (0 ≤xvu ≤wv) and X = {xuv} be an allocation. The
utility of agent v is deﬁned as Uv(X) = 
u∈Γ (v) xuv, i.e. all received resource
from its neighbors. In the resource exchange environment, one of critical issues
is how to design an allocation mechanism to maintain the agents participation,
i.e., ensuring that agents will share their resources in a fair fashion. Wu and
Zhang [17] pioneered the concept of “proportional response” inspired by the
idea of “tit-for-tat” for the consideration of fairness.
Proportional Response. A mechanism is called proportional response if an
allocation X from this mechanism satisﬁes xvu =
xuv

k∈Γ (v) xkv wv, that is the
allocation of each agent’s resource is proportional to what it receives from its
neighbors.
To achieve a proportional response mechanism, a combinatorial structure,
called bottleneck decomposition is derived in [17]. For set S ⊆V , deﬁne w(S) =

v∈S wv and Γ(S) = ∪v∈SΓ(v). It is possible that S ∩Γ(S) ̸= ∅. Denote
α(S) =
w(Γ (S))
w(S)
to be the inclusive expansion ratio of S, or the α-ratio of S
for short. A set B ⊆V is called a bottleneck of G if α(B) = minS⊆V α(S). A
bottleneck with the maximal size is called the maximal bottleneck.
Bottleneck Decomposition. Given G = (V, E; w). Start with V1 = V , G1 = G
and i = 1. Find the maximal bottleneck Bi of Gi and let Gi+1 be the induced
subgraph on the vertex set Vi+1 = Vi −(Bi ∪Ci), where Ci = Γ(Bi) ∩Vi, the
neighbor set of Bi in Gi. Repeat if Gi+1 ̸= ∅and set k = i if Gi+1 = ∅. Then we
call B = {(B1, C1), · · · , (Bk, Ck)} the bottleneck decomposition of G, (Bi, Ci)
the i-th bottleneck pair and αi = w(Ci)/w(Bi) the α-ratio of (Bi, Ci).
Proposition 1 (Wu and Zhang [17]). Given a graph G, the bottleneck decom-
position of G is unique and
(1) 0 < α1 < α2 < · · · < αk ≤1;
(2) if αi = 1, then i = k and Bi = Ci; otherwise Bi is an independent set and
Bi ∩Ci = ∅;
(3) there is no edge between Bi and Bj, i ̸= j ∈{1, · · · , k};
(4) if there is an edge between Bi and Cj, then j ≤i.
B-class and C-class. Given B = {(B1, C1), · · · , (Bk, Ck)}. For pair (Bi, Ci)
with αi < 1, each vertex in Bi (or Ci) is called a B-class (or C-class) vertex. For
the special case Bk = Ck = Vk, i.e., αk = 1, all vertices in Bk are categorized as
both B-class and C-class.
BD Mechanism. Given the bottleneck decomposition B, an allocation (Wu
and Zhang [17]) can be determined by distinguishing three cases. We name it as
BD Mechanism for short.

Agent Incentives of Strategic Behavior in Resource Exchange
231
• For (Bi, Ci) with αi < 1, consider the bipartite graph G = (Bi, Ci; Ei) with
Ei = Bi × Ci. Construct a network N = (VN, EN) with VN = {s, t} ∪Bi ∪Ci
and directed edges (s, u) with capacity wu for u ∈Bi, (v, t) with capacity
wv/αi for v ∈Ci and (u, v) with capacity +∞for (u, v) ∈Ei. The max-ﬂow
min-cut theorem ensures a maximal ﬂow {fuv}, u ∈Bi and v ∈Ci, such that

v∈Γ (u)∩Ci fuv = wu and 
u∈Γ (v)∩Bi fuv = wv/αi. Let the allocation be
xuv = fuv and xvu = αifuv implying 
u∈Γ (v)∩Bi xvu = 
u∈Γ (v)∩Bi αi·fvu =
wv.
• For αk = 1 (i.e., Bk = Ck), construct a bipartite graph G = (Bk, B′
k; E′
k)
where B′
k is a copy of Bk, there is an edge (u, v′) ∈E′
k if and only if (u, v) ∈
E[Bk]. Construct a network by the above method, for any edge (u, v′) ∈E′
k,
there exists ﬂow fuv′ such that 
v′∈Γ (u)∩B′
k fuv′ = wu. Let the allocation be
xuv = fuv′.
• For any other edge (u, v) ̸∈Bi × Ci, i = 1, 2, · · · , k, deﬁne xuv = 0.
Proposition 2 [17]. BD Mechanism is a proportional response mechanism.
On the other hand the resource exchange system can be modeled as a pure
exchange economy, for which an eﬃcient allocation is the market equilibrium.
Market Equilibrium. In the exchange economy, price vector p = (pv)v∈V
together with an allocation X is called a market equilibrium if for any agent
v ∈V
the following holds, 1. 
u∈Γ (v) xvu = wv (market clearance); 2.

u∈Γ (v) pu
xuv
wu ≤pv (budget constraint); 3. X = (xvu) maximizes the utility
Uv = 
u∈Γ (v) xuv subject to the budget constraint (individual optimality).
BD Mechanism is not only fair as stated above but also eﬃcient, since the
proportional response allocation from it is also a market equilibrium. Given a
bottleneck decomposition, if a price vector p is well deﬁned as: pu = αiwu, if
u ∈Bi; and pu = wu otherwise, then
Proposition 3 [17]. (p, X) is a market equilibrium. Furthermore, each agent
u’s utility is Uu = wu · αi if u ∈Bi; Uu = wu
αi if u ∈Ci.
Note that Uu ≥wu if u is in Ci and Uu ≤wu if u is in Bi, as αi ≤1 by
Proposition 1-(1). For convenience, we let αu be the α-ratio of u where αu = αi,
if u ∈Bi ∪Ci. Recall Example 1. The bottleneck decompositions, α-ratios and
utilities before and after vertex splitting are listed in the following table.
B1 = {v2, v4}, C1 = {v1, v3} αv3 = 2
5
Uv3 = 5
B′
1 = {v4}, C′
1 = {v2
3}
α′
v2
3 = 1
5
U ′
v2
3 = 5
B′
2 = {v2}, C′
2 = {v1
3}
α′
v1
3 = 3
5
U ′
v1
3 = 5
3
From a system design point of view, although BD Mechanism shall allo-
cate resource among interconnected participants fairly and eﬃciently, a problem

232
Z. Chen et al.
occurs that, an agent may or may not follow BD Mechanism at the execution
level. Can agents make strategic moves for gains in their utilities? We call such a
problem with incentive compatibility consideration the resource exchange game.
In this paper, we consider a strategic move, called vertex splitting strategy,
that is one agent may split itself into several copied nodes, and assign a weight
to each node. Formally, in a resource exchange network G, the collection w =
(w1, · · · , wn) ∈Rn is referred as the weight proﬁle. For agent v, let w−v be the
weight proﬁle without v. Since the utility of agent v depends on G and w, it is
written as Uv(G; w). After splitting into m nodes, 1 ≤m ≤dv (dv is the degree
of v), and assigning an amount of resource to each node, agent v’s new utility
is denoted by U ′
v(G′; wv1, · · · , wvm, w−v), where G′ is the resulting graph after
vertex splitting and wvi ∈[0, wv] is the amount of resource assigned to node vi
with m
i=1 wvi = wv.
Deﬁnition 1 (Incentive Ratio). In a resource exchange game, the incentive
ratio of agent v under BD Mechanism for the vertex splitting strategy is
ζv =
max
1≤m≤dv
max
wvi ∈[0,wv],m
i=1 wvi =wv;w−v;G′
U ′
v(G′; wv1, · · · , wvm, w−v)
Uv(G; wv)
.
The incentive ratio of BD mechanism in resource exchange game is deﬁned to
be ζ = maxv∈V ζv.
There is a special case that a strategic agent v splits itself into dv nodes and each
node is connected to one of neighbors. The following proposition shows that this
cheating way would not reduce the generality of the result.
Proposition 4. In a resource exchange game, the incentive ratio of BD mech-
anism with respect to vertex splitting strategy can be achieved by splitting dv
nodes and each node is connected to one neighbor for any vertex v, where dv is
the degree of agent v.
The proof of Proposition 4 is left in the full version. Therefore we only consider
the cheating way that v splits dv nodes. Conveniently, let the copied nodes set
be Λ(v) = {v1, · · · , vdv} and the neighborhood be Γ(v) = {u1, · · · , udv}, where
vj is adjacent to uj in G′.
3
Incentive Ratios of BD Mechanism on Trees
In this section, we focus on the resource exchange game in which the underlying
network is a tree. Our main result in this paper is the following.
Theorem 1. If the network G of resource exchange system is a tree, then the
incentive ratio of BD Mechanism for the vertex splitting strategy is exactly 2.
Before providing the details of discussion, let us introduce some additional
notations. Recall neighborhood is Γ(v) = {u1, u2, · · · , udv}. In the original net-
work G with weight proﬁle w, the resource allocation from BD Mechanism is

Agent Incentives of Strategic Behavior in Resource Exchange
233
X = (xvu) and the bottleneck decomposition is B. we partition neighborhood
Γ(v) into two disjoint subsets: Γ1(v) = {ui|xvui > 0} and Γ2(v) = {ui|xvui = 0}.
Hence, v only exchanges the resource with the neighbors in Γ1(v). W.l.o.g., let
index sets I1(v) = {i|ui ∈Γ1(v)} and I2(v) = {i|ui ∈Γ2(v)}.
If agent v plays the vertex splitting strategy, then the original network G shall
be decomposed into dv connected subtrees, because G is a tree and the degree
of v is dv. Likewise, we label all subtrees as G1, · · · , Gdv, each containing one
copied node vi and its unique neighbor ui, i = 1, · · · , dv. For any given weight
assignment (wv1, · · · , wvdv ) among all copied nodes, the utility of vi depends on
the structure of Gi and its weight wvi. So we denote it by U i(wvi). In addition,
based on the partition of index set, the subtrees {Gi}, copied node set Λ(v) and
weights {wvi} are also divided into corresponding two subsets.
Recently Cheng et al., raised the issue of agent deviation from the BD Mech-
anism by the acts of cheating on the resource amount it owns [7]. They con-
ﬁrmed the incentive compatibility of BD Mechanism with respect to such a so
called weight misreporting manipulative move. A mechanism is called incentive
compatible if truthful revelation is a best response for each agent under such a
mechanism, irrespective of what is reported by the other agents.
Proposition 5 [7]. For any agent u in a resource exchange game, the utility
of u is continuous and monotonically nondecreasing on it reported value x. As
x ≤wu, the dominant strategy of agent u is to report it true weight.
Since the bottleneck decomposition of G, the utility and α-ratio of agent v
depend on its reported weight x given the other agents’ weights, we can view its
utility and α-ratio as functions on x, denoted by Uv(x) and αv(x). In [7], Cheng
et al. characterized αv(x) as follows.
Proposition 6 [7]. For any agent v and any other agents’ reported weights, let
αv(x) be v’s α-function of its reported weight x ∈[0, wv]. Then there exist three
cases
(1). αv(x) is non-decreasing and v is in C-class for all x ∈[0, wv];
(2). αv(x) is non-increasing and v is in B-class for all x ∈[0, wv];
(3). there is a number x∗∈(0, wv] with αv(x∗) = 1, and
(3.1). αv(x) is non-decreasing and v is in C-class if 0 ≤x ≤x∗;
(3.2). αv(x) is non-increasing and v is in B-class if x∗≤x ≤wv.
From Proposition 6, we note that if v is in B-class when its report weight x = 0,
then it must keep to be a B-class vertex and αv(x) is non-increasing. But if v is
in C-class when x = 0, then it may be in C-class or B-class during x ∈[0, wv].
In the following, we ﬁrst show the lower bound of the incentive ratio is equal
to 2 by proposing an example.
Example 2. There is a path G containing 5 vertices, shown in Fig. 2(a). The
weights of all vertices are wv1 = wv3 = M/4, wv2 = M, wv4 = 2 and wv5 =
1, where M is a large enough number. The bottleneck decomposition of G is

234
Z. Chen et al.
{(B1, C1)}, where B1 = {v2, v4} and C1 = {v1, v3, v5} with α1 = 1/2. The
utility of v4 is Uv4 = 2α1 = 1.
Now vertex v4 strategically splits itself into v1
4 and v2
4 and assigns 2 −ε and
ε resources to each node, respectively, where ε is an arbitrarily small positive
number as shown in Fig. 2(b). The new bottleneck decomposition changes to be
{(B′
1, C′
1), (B′
2, C′
2)}, where B′
1 = {v5}, C′
1 = {v2
4} and B′
2 = {v2, v1
4}, C′
2 =
{v1, v3}. The α-ratios are α′
1 = ε and α′
2 =
M/2
M+2−ε, respectively. At this time
limM→∞U
′
v1
4 = 1 and limM→∞U
′
v2
4 = 1 which means limM→∞U
′
v4 = 2.
Fig. 2. An example that v4 can improve twice of its utility by vertex splitting strategy.
Hence to obtain Theorem 1, we only need to prove that the upper bound of
incentive ratio is 2, too. For this purpose, we discuss this issue from two-fold
aspects corresponding to the partition of Γ(v). On the one hand, by applying
the property of proportional response from BD Mechanism and the monotonic
property of α-function in Proposition 6, we prove the upper bound of the sum
of utilities of all nodes {vi}i∈I1 is (1 + δ)Uv, where δ = (
i∈I1 wvi)/wv and Uv
is the utility of v in G.
Lemma 1. If G is a tree and the other agents’ weight proﬁle w−v is given, then
the sum of utilities of vi, i ∈I1, satisﬁes 
i∈I1 U i(wvi) ≤(1 + δ)Uv, for any
weight assignment (wv1, · · · , wvdv ), where δ = (
i∈I1 wvi)/wv.
On the other hand, by applying the bottleneck decomposition of Gi, i ∈I2, and
the monotonic property of α-function, we show the upper bound of the utility
of each copied node vi, i ∈I2.
Lemma 2. If the underlying network G is a tree and the other agents’ weight
proﬁle w−v is given, then utility U i(wvi) ≤wvi
wv Uv, i ∈I2, for any weight assign-
ment (wv1, · · · , wvdv ).
Combining above two lemmas, the upper bound of 2 can be deduced directly.
Theorem 2. If the underlying network G is a tree, then the incentive ratio of
BD Mechanism for the vertex splitting strategy is at most 2, i.e. ζ ≤2.

Agent Incentives of Strategic Behavior in Resource Exchange
235
Proof. Since δ = (
i∈I1 wvi)/wv, then (
i∈I2 wvi)/wv = 1 −δ. For any weight
assignment (wv1, · · · , wvdv ),
U ′
v(wv1, · · · , wvdv ) =

i∈I1
U i(wvi) +

i∈I2
U i(wvi) ≤(1 + δ)Uv +

i∈I2
wvi
wv
Uv
= (1 + δ)Uv + (1 −δ)Uv = 2Uv.
Because of the arbitrariness of (wv1, · · · , wvdv ) and w−v, we conclude ζ ≤2.
This completes the proof.
Discussion for Lemma 1. Before proceeding with the proof of Lemma 1, some
other notations and propositions are necessary to introduce. In this subsection,
we are interested in another ratio βv, named as exchange ratio [10] of vertex v,
which quantiﬁes the aggregate amount of resource that vertex v receives per unit
of resource that oﬀers to its neighbors, i.e., βv = Uv/wv. From Proposition 3, we
know βv = αv, if v is in B-class, and βv = 1/αv, if v is in C-class. Based on this
relationship of βv and αv, β-ratio also can be written as a function on x, the
reported weight by v given the other agents’ weights. That is βv(x) = Uv(x)/x.
By the monotonicity of α-function in Proposition 6, βv(x) has the property as
Proposition 7. For any agent v and any other agents’ reported weights, the
exchange ratio function βv(x) = Uv(x)/x is non-increasing with x ∈[0, wv].
Now let us pay attention to an initial state in which the weight assignment
is wvi = xvui, i = 1, 2, · · · , dv. As stated before, xvui is the amount of resource
allocated from v to ui under BD Mechanism in original network G. Further,
because X = (xvu) obtained from BD Mechanism has the property of propor-
tional response (Proposition 2), then xvui
wv =
xuiv
dv
l=1 xulv = xuiv
Uv . Hence
Proposition 8. For any vertex v, its exchange ratio βv satisﬁes
βv = Uv
wv
= xuiv
xvui , i ∈I1,
(1)
If vertex v splits itselt with weight assignment (xvu1, · · · , xvudv ), it is not
hard to see that the allocation in subtree Gi is the same as the sub-allocation of
X = (xvu) restricted in Gi, and the exchange ratio of each copied node vi in Gi
is also equal to βv. In addition, vi is a leaf in Gi, which makes its utility only
be from its unique neighbor ui. Thus the utility of vi when its weight is xvui is
U i(xvui) = xuiv = βv · xvui.
On the other hand, let us focus on the connected subtree Gi, i ∈I1, which
can be viewed as a sub-resource exchange system. So all results for original G
are suitable for each Gi. Suppose all vertex weights are given. Because Gi only
contains one copied node vi, the β-ratio of vi only depends on wvi for any weight
assignment (wv1, · · · , wvdv ). So such a ratio can be written as a function of wvi,
i.e., βvi(wvi) = U i(wvi)/wvi. It is observed that βvi(xvui) = βv.

236
Z. Chen et al.
Proof of Lemma 1: For any weight assignment (wv1, · · · , wvdv ), in which

i∈I1 wvi = δwv,

i∈I1
U i(wvi) −Uv =

i∈I1
U i(wvi) −

i∈I1
U i(xvui)
=

wvi≤xvui

U i(wvi)−U i(xvui)

+

wvi>xvui

U i(wvi)−U i(xvui)

≤

wvi>xvui

U i(wvi) −U i(xvui)

=

wvi>xvui
[wvi · βvi(wvi) −xvui · βv]
=

wvi>xvui
[xvui(βvi(wvi) −βv) + (wvi −xvui)βvi(wvi)]
≤

wvi>xvui
(wvi −xvui)βv ≤

i∈I1
wviβv = δUv
in which, the ﬁrst equality comes from Uv = 
i∈I1 xuiv = 
i∈I1 U i(xvui); the
monotonically nondecreasing property of utility function on weight in Proposi-
tion 5 promises the ﬁrst inequality and the second inequality is right since the
β-function is non-increasing on weight in Proposition 7.
⊓⊔
Discussion for Lemma 2. To prove Lemma 2, some additional notations and
propositions are necessary to be introduced. As deﬁned before, w is the weight
proﬁle and B = {(B1, C1), · · · , (Bk, Ck)} is the bottleneck decomposition of G.
For each subtree Gi, the vertex set of Gi is denoted by V (Gi) and vertex set V of
G can be decomposed in another way that V = ∪dv
i=1

V (Gi) −{vi}

∪{v}. For
convenience, we denote V i = V (Gi)−{vi}. Let us focus on the sub-decomposition
Bi obtained by restricting B into subset V i, i ∈I2. W.l.o.g., Bi is written as
Bi = {(Bi
1, Ci
1), · · · , (Bi
ki, Ci
ki)}. By the acyclic structure of G, we have the
following proposition whose proof will be in the full version.
Proposition 9. For each pair (Bi
h, Ci
h) in Bi, h = 1, · · · , ki and i ∈I2, there is
a pair (Bf, Cf) in B, such that either (Bf, Cf) = (Bi
h, Ci
h) or Bi
h ⊂Bf, Ci
h ⊂Cf
and w(Ci
h)
w(Bi
h) = w(Cf )
w(Bf ) = αf.
Now let us focus on the bottleneck decomposition of Gi, i ∈I2. Of course, its
decomposition depends on wvi, if the weights of other vertices in Gi are ﬁxed.
W.l.o.g, we denote it by Bi(wvi), wvi ∈[0, wv]. Similarly, we start our discussion
from the initial state that wvi = xvui, i = 1, · · · , dv, where xvui = 0, for each
i ∈I2. Please pay attention that Bi(0) is the bottleneck decomposition of Gi
when wvi = 0 and Bi is the sub-decomposition of B restricted in Gi −{vi}.
Because vi is a leaf in Gi with unique neighbor ui and wvi = 0, we can derive
Bi(0) from Bi directly as the following.

Agent Incentives of Strategic Behavior in Resource Exchange
237
(Bi
h(0), Ci
h(0)) =
⎧
⎨
⎩
(Bi
h, Ci
h ∪{vi}),
if ui ∈Bi
h;
(Bi
h ∪{vi}, Ci
h),
if ui ∈Ci
h;
(Bi
h, Ci
h),
otherwise.
(2)
Further, the condition of wvi = 0 makes αi
h(0) = αi
h, h = 1, · · · , ki.
Proof of Lemma 2: W.l.o.g., we suppose v ∈Bj ∪Cj, ui ∈Bf ∪Cf in B and
ui ∈Bi
h ∪Ci
h in Bi. So (Bi
h, Ci
h) is the pair obtained by restricting (Bf, Cf)
in to V i and αi
h = αf by Proposition 9. Moreover, vi ∈Bi
h(0) ∪Ci
h(0). Then its
α-ratio is αvi(0) = αi
h(0) = αi
h = αf.
If v ∈Bj, then ui must be in Cf (also in Ci
h) with f ≤j by Property 1.
Under this case, αf ≤αj = αv = βv = Uv
wv . The fact ui ∈Cf makes ui ∈Ci
h,
inducing ui ∈Ci
h(0) and vi ∈Bi
h(0) by (2). Proposition 6 tells us if vi is a B-class
vertex when its weight is zero, then vi must always be in B-class and αvi(wvi)
is non-increasing for all wvi ∈[0, wv]. Hence, for any wvi ∈[0, wv]
U i(wvi) = wvi · αvi(wvi) ≤wvi · αvi(0) = wvi · αf ≤wvi · αj = wvi
wv
Uv.
If v ∈Cj, then Uv
wv = βv =
1
αj ≥1 and ui may be in Bf or Cf. If u ∈Cf (also
in Ci
h), then vi must be a B-class vertex when wvi = 0. By the same reason, we
know vi is a B-class vertex for all wvi ∈[0, wv] and
U i(wvi) ≤wvi ≤wvi 1
αj
= wvi
wv
Uv.
(3)
If ui ∈Bf (also in Bi
h), then vi ∈Ci
h(0). By Proposition 6, it is possible that
there is x∗∈(0, wv], such that αvi(x∗) = 1. In addition, vi is in B-class when
wvi ∈[x∗, wv] and v is in C-class with αvi(wvi) non-decreasing when 0 ≤x ≤x∗.
Clearly, if wvi ∈[x∗, wv], then the fact that vi is a B-class vertex results in
U i(wvi) ≤wvi
wv Uv by (3). If wvi ∈[0, x∗], then vi is in C-class and
U i(wvi) = wvi ·
1
αvi(wvi) ≤wvi ·
1
αvi(0) = wvi · 1
αf
= wvi
wv
Uv,
(4)
where the inequality comes from the non-decreasing property of αvi(wvi) when
wvi ∈[0, x∗]. If x∗does not exist, then there is only one situation that v is
in C-class for all wvi ∈[0, wv]. Under this situation, we know αvi(wvi) is non-
decreasing in [0, wv] by Proposition 6. Applying the above deduction in (4), we
conclude U i(wvi) ≤wvi
wv Uv for all wvi ∈[0, wv]. This completes the lemma.
⊓⊔
4
Conclusion
This paper discusses the issue of possible strategic manipulations of agents with
respect to a resource allocation mechanism, BD Mechanism, for the application of
resource exchange. We study the incentives of a vertex splitting strategy of agents
and characterize how much utility can be increased by such plays for resource

238
Z. Chen et al.
exchange game, establishing new understandings on the strategic stability of BD
Mechanism from the mechanism design perspective. We prove that the incentive
ratios of BD Mechanism for the vertex splitting strategy on trees are exactly
2. Compared with a recent work [13] proving that the incentive ratio for the
linear exchange economy in Arrow-Debreu markets is unbounded, our results
of bounded incentive ratio place the practical resource exchange with a market
equilibrium solution more rational in terms of truthful behavior.
Fig. 3. The numerical experiment results on random graphs.
Though we have completed the study of incentive ratio on trees, there is a
space left that how to explore the incentive ratio of BD Mechanism on general
graphs. Fig. 3 shows the average incentive ratio among 1000 numerical exper-
iments on random graphs, in which each edge is generated with probability
p ∈{0.1, 0.2, · · · , 0.9}. Further, in our all simulations, the incentive ratio of
BD Mechanism for the vertex splitting strategy on any graph never exceeds 2.
Inspired by these simulation results, we conjecture the incentive ratio is no more
than 2 for any graph which will be left as future work.
Acknowledgments. This research was partially supported by the National Nature
Science Foundation of China (Nos. 11301475, 11426026, 61632017, 61173011), by a
Project 985 grant of Shanghai Jiao Tong University, and by the Research Grant Coun-
cil of Hong Kong (ECS Project No. 26200314, GRF Project No. 16213115 and GRF
Project No. 16243516).
References
1. Adsul, B., Babu, C.S., Garg, J., Mehta, R., Sohoni, M.: Nash equilibria in
ﬁsher market. In: Kontogiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.) SAGT
2010. LNCS, vol. 6386, pp. 30–41. Springer, Heidelberg (2010). doi:10.1007/
978-3-642-16170-4 4
2. Alkalay, C., Vetta, A.: False-name bidding and economic eﬃciency in combinatorial
auctions. In: AAAI, pp. 538–544 (2014)
3. Braanzei, S., Chen, Y.L., Deng, X.T., Filos-Ratsikas, A., Kristoﬀer, S., Frederiksen,
S., Zhang, J.: The ﬁsher market game: equilibrium and welfare. In: AAAI (2014)

Agent Incentives of Strategic Behavior in Resource Exchange
239
4. Chen, N., Deng, X., Zhang, H., Zhang, J.: Incentive ratios of ﬁsher mar-
kets. In: Czumaj, A., Mehlhorn, K., Pitts, A., Wattenhofer, R. (eds.) ICALP
2012. LNCS, vol. 7392, pp. 464–475. Springer, Heidelberg (2012). doi:10.1007/
978-3-642-31585-5 42
5. Chen, N., Deng, X., Zhang, J.: How proﬁtable are strategic behaviors in a market?
In: Demetrescu, C., Halld´orsson, M.M. (eds.) ESA 2011. LNCS, vol. 6942, pp.
106–118. Springer, Heidelberg (2011). doi:10.1007/978-3-642-23719-5 10
6. Cheng, Y., Deng, X., Pi, Y., Yan, X.: Can bandwidth sharing be truthful? In:
Hoefer, M. (ed.) SAGT 2015. LNCS, vol. 9347, pp. 190–202. Springer, Heidelberg
(2015). doi:10.1007/978-3-662-48433-3 15
7. Cheng, Y., Deng, X., Qi, Q., Yan, X.: Truthfulness of a proportional sharing mech-
anism in resource exchange. In: IJCAI, pp. 187–193 (2016)
8. Dalakov, G.: History of Computers and Computing, Internet, Internet conquers the
world, BitTorrent. http://historycomputer.com/Internet/Conquering/BitTorrent.
html
9. Feldman, M., Lai, K., Stoica, I., et al.: Robust incentive techniques for peer-to-peer
networks. In: Proceedings of the 5th ACM conference on Electronic commerce, pp.
102–111. ACM (2004)
10. Georgiadis, L., Iosiﬁdisy, G., Tassiulas, L.: Exchange of services in networks: com-
petition, cooperation, and fairness. In: Proceedings of the 2015 ACM International
Conference on Measurement and Modeling of Computer Systems (SIGMETRICS
2015), pp. 43–56 (2015)
11. Iwasaki, A., Conitzer, V., Omori, Y., et al.: Worst-case eﬃciency ratio in false-
name-proof combinatorial auction mechanisms. In: Proceedings of the 9th Interna-
tional Conference on Autonomous Agents and Multiagent Systems, vol. 1. Interna-
tional Foundation for Autonomous Agents and Multiagent Systems, pp. 633–640
(2010)
12. Koutsoupias, E., Papadimitriou, C.: Worst-case equilibria. In: Meinel, C., Tison,
S. (eds.) STACS 1999. LNCS, vol. 1563, pp. 404–413. Springer, Heidelberg (1999).
doi:10.1007/3-540-49116-3 38
13. Polak, I.: The incentive ratio in exchange economies. In: Chan, T.-H.H., Li, M.,
Wang, L. (eds.) COCOA 2016. LNCS, vol. 10043, pp. 685–692. Springer, Cham
(2016). doi:10.1007/978-3-319-48749-6 49
14. Schollmeier, R.: A deﬁnition of peer-to-peer networking for the classiﬁcation of
peer-to-peer architectures and applications. In: 2001 Proceedings of First Interna-
tional Conference on Peer-to-Peer Computing, pp. 101–102. IEEE (2001)
15. Schor, J.: Debating the sharing economy. J. Self-Gov. Manag. Econ. 4(3), 7–22
(2016)
16. Roughgarden, T., Tardos, E.: How bad is selﬁsh routing. J. ACM 49(2), 236–259
(2002)
17. Wu, F., Zhang, L.: Proportional response dynamics leads to market equilibrium.
In: STOC, pp. 354–363 (2007)
18. Yokoo, M.: False-name bids in combinatorial auctions. ACM SIGecom Exchanges
7(1), 1–4 (2007)
19. Yokoo, M., Sakurai, Y., Matsubara, S.: The eﬀect of false-name bids in combina-
torial auctions: new fraud in Internet auctions. Games Econ. Behav. 46, 174–188
(2004)

A 3-Player Protocol Preventing Persistence
in Strategic Contention with Limited Feedback
George Christodoulou1, Martin Gairing1, Sotiris Nikoletseas2,3,
Christoforos Raptopoulos2,3(B), and Paul Spirakis1,2,3
1 Department of Computer Science, University of Liverpool, Liverpool, UK
{G.Christodoulou,gairing,P.Spirakis}@liverpool.ac.uk
2 Computer Engineering and Informatics Department,
University of Patras, Patras, Greece
nikole@cti.gr, raptopox@ceid.upatras.gr
3 Computer Technology Institute and Press “Diophantus”, Patras, Greece
Abstract. In this paper, we study contention resolution protocols from
a game-theoretic perspective. In a recent work [8], we considered ac-
knowledgment-based protocols, where a user gets feedback from the chan-
nel only when she attempts transmission. In this case she will learn
whether her transmission was successful or not. One of the main results
of [8] was that no acknowledgment-based protocol can be in equilibrium.
In fact, it seems that many natural acknowledgment-based protocols fail
to prevent users from unilaterally switching to persistent protocols that
always transmit with probability 1. It is therefore natural to ask how
powerful a protocol must be so that it can beat persistent deviators.
In this paper we consider age-based protocols, which can be described
by a sequence of probabilities of transmitting in each time step. Those
probabilities are given beforehand and do not change based on the trans-
mission history. We present a 3-player age-based protocol that can pre-
vent users from unilaterally deviating to a persistent protocol in order
to decrease their expected transmission time. It is worth noting that the
answer to this question does not follow from the results and proof ideas
of [8]. Our protocol is non-trivial, in the sense that, when all players use
it, ﬁnite expected transmission time is guaranteed. In fact, we show that
this protocol is preferable to any deadline protocol in which, after some
ﬁxed time, attempt transmission with probability 1 in every subsequent
step. An advantage of our protocol is that it is very simple to describe,
and users only need a counter to keep track of time. Whether there exist
n-player age-based protocols that do not use counters and can prevent
persistence is left as an open problem for future research.
Keywords: Contention resolution · Age-based protocol · Persistent
deviator · Game theory
1
Introduction
A fundamental problem in networks is contention resolution in multiple access
channels. In such a setting there are multiple users that want to communicate
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 240–251, 2017.
DOI: 10.1007/978-3-319-66700-3 19

A 3-Player Protocol Preventing Persistence in Strategic Contention
241
with each other by sending messages into a multiple access channel (or broadcast
channel). The channel is not centrally controlled, so two or more users can trans-
mit their messages at the same time, in which case there is a collision and no
transmission is successful. The objective in contention resolution is the design of
distributed protocols for resolving such conﬂicts, while simultaneously optimizing
some performance measure, like channel utilization or average throughput.
Following the standard assumption in this area, we assume that time is dis-
crete and messages are broken up into ﬁxed sized packets, which ﬁt exactly into
one time slot. In fact, we consider one of the simplest possible scenarios where
each user only needs to send a single packet through the channel. Most studies
on distributed contention resolution protocols (see Sect. 1.2) are based on the
assumption that users will always follow the algorithm. In this paper, follow-
ing [10] we drop this assumption, and we assume that a player will only obey a
protocol if it is in her best interest, given the other players stick to the protocol.
Therefore, we model the situation from a game-theoretic perspective, i.e. as a
stochastic game with the users as selﬁsh players.
One of the main results of Fiat et al. [10] was the design of an incentive-
compatible transmission protocol which guarantees that (with high probability)
all players will transmit successfully in time linear in the number of players n.
The authors assume a ternary feedback channel, i.e. each player receives feedback
of the form 0/1/2+ after each time step, indicating whether zero, one, or more
than one transmission was attempted. In a related paper, Christodoulou et al. [9]
designed eﬃcient ϵ-equilibrium protocols under a stronger assumption that each
player receives as feedback the number of players that attempted transmission;
this is called multiplicity feedback. They also assume non-zero transmission costs,
in which case the protocols of [10] do not apply.
All of the protocols deﬁned in the above two works belong to the class of
full-sensing protocols [14], in which the channel feedback is broadcasted to all
sources. However, in wireless channels, there are situations where full-sensing
is not possible because of the hidden-terminal problem [24]. In a previous work
[8], we considered acknowledgment-based protocols, which use a more limited
feedback model – the only feedback that a user gets is whether her transmis-
sion was successful or not. A user that does not transmit cannot “listen” to
the channel and therefore does not get any feedback. In other words, the only
information that a user has is the history of her own transmission attempts.
Acknowledgment-based protocols have been extensively studied in the literature
(see e.g. [14] and references therein).
Our main concern in [8] was the existence of acknowledgment-based proto-
cols that are in equilibrium. For n = 2 players, we showed that there exists such
a protocol, which guarantees ﬁnite expected transmission time. Even though
the general question for more than 2 players was left open in [8], we ruled out
that such a protocol can be age-based. Age-based protocols are a special case of
acknowledgment-based protocols and can be described by a sequence of probabil-
ities (one for each time-step) of transmitting in each time step. Those probabil-
ities are given beforehand and do not change based on the transmission history.

242
G. Christodoulou et al.
The well known ALOHA protocol [1] is a special age-based protocol, where –
except for the ﬁrst round – users always transmit with the same probability. Since
an age-based protocol P cannot be in equilibrium, it is beneﬁcial for players to
deviate from P to some other protocol. In fact, most natural acknowledgment-
based protocols fail to prevent users from unilaterally switching to the persistent
protocol that always transmits with probability 1. It is therefore natural to ask
how powerful a protocol must be with respect to memory (and feedback) in order
to be able to prevent persistent deviators.
1.1
Our Contribution
The question that we consider in this paper is whether there exist age-based
protocols that can prevent users from unilaterally deviating to a persistent pro-
tocol (in which they attempt a transmission in every step until they successfully
transmit) in order to decrease their expected transmission time. In particular,
such protocols should be non-trivial, in the sense that using the protocol should
guarantee a ﬁnite expected transmission time for the users. It is worth noting
that the answer to this question does not follow from the results and proof ideas
of [8]. We give a positive answer for the case of 3 players (users), by presenting
and analyzing such a protocol (see deﬁnition below). In particular, we show that
this protocol is preferable to any deadline protocol in which, after some ﬁxed
time, attempt transmission with probability 1 in every subsequent step.
Let c ≥1 and p ∈[0, 1] be constants. We deﬁne the protocol P = P(c, p)
as follows: the transmission probability Pt at any time t is equal to p if t =
k
j=0⌊2cj⌋, for some k = 0, 1, . . . and it is equal to 1 otherwise. The intuition
behind this protocol is that with every collision it is increasingly harder for
remaining users to successfully transmit, and thus “aggressive” protocols are
suboptimal.
Our main result is the following:
Theorem 1. Assume there are 3 players in the system, two of which use protocol
P(1.1, 0.75). Then, the third player will prefer using protocol P(1.1, 0.75) over
any deadline protocol D.
In addition, we show that the expected transmission time of a ﬁxed player
when all players use P(1.1, 0.75) is upper bounded by 2759 and is thus ﬁnite.
We believe that our ideas can be used to give a positive answer also for the case
of n > 3 players, but probably not for too large values of n.
An advantage of our protocol is that it is very simple to describe, and users
only need a counter to keep track of time. Whether there exist n-player age-
based protocols using ﬁnite memory that can prevent persistence is left as an
open problem for future research.
Due to lack of space some proofs are omitted but can be found in the complete
version of our paper [7].

A 3-Player Protocol Preventing Persistence in Strategic Contention
243
1.2
Other Related Work
Perhaps the most famous multiple-access communication protocol is the (slotted)
ALOHA protocol [1,22]. Follow-up papers study the eﬃciency of multiple-access
protocols for packets that are generated by some stochastic process (see e.g.
[12,13,21]), or worst-case scenarios of bursty inputs [5].
The main focus of many contention resolution protocols is on actual conﬂict
resolution. In such a scenario, it is assumed that there are n users in total, and k
of them collide. In such an event, a resolution algorithm is called, which ensures
that all the colliding packets are successfully transmitted [6,16,25]. There is
extensive study on the eﬃciency of protocols under various information models
(see [14] for an overview). When k is known, [11] provides an O(k + log k log n)
acknowledgment-based algorithm, while [19] provides a matching lower bound.
For the ternary model, [15] provides a bound of Ω(k(log n/ log k)) for all deter-
ministic algorithms.
There are various game theoretic models of slotted ALOHA that have been
studied in the literature, apart from the ones mentioned in the introduction;
see for example [2,3,18]. However, in most of these models only transmission
protocols that always transmit with the same probability are considered. There
has been also research on pricing schemes [26] as well as on cases in which the
channel quality changes dynamically with time and players must choose their
transmission levels accordingly [4,20,27]. An interesting game-theoretic model
that lies between the contention and congestion model was studied in [17]; where
decisions of when to submit is part of the action space of the players.
2
Model
Game Structure. Let N = {1, 2, . . . , n} be the set of agents, each one of which
has a single packet that he wants to send through a common channel. All players
know n. We assume time is discretized into slots t = 1, 2, . . .. The players that
have not yet successfully transmitted their packet are called pending and initially
all n players are pending. At any given time slot t, a pending player i has two
available actions, either to transmit his packet or to remain quiet. In a (mixed)
strategy, a player i transmits his packet at time t with some probability that
potentially depends on information that i has gained from the channel based on
previous transmission attempts. If exactly one player transmits in a given slot t,
then his transmission is successful, the successful player exits the game (i.e. he is
no longer pending), and the game continues with the rest of the players. On the
other hand, whenever two or more agents try to access the channel (i.e. transmit)
at the same slot, a collision occurs and their transmissions fail, in which case
the agents remain in the game. Therefore, in case of collision or if the channel
is idle (i.e. no player attempts to transmit) the set of pending agents remains
unchanged. The game continues until all players have successfully transmitted
their packets.
Transmission Protocols. Let Xi,t be the indicator variable that indicates
whether player i attempted transmission at time t. For any t ≥1, we denote

244
G. Christodoulou et al.
by Xt the transmission vector at time t, i.e. Xt = (X1,t, X2,t, . . . , Xn,t). An
acknowlegment-based protocol, uses very limited channel feedback. After each
time step t, only players that attempted a transmission receive feedback, and
the rest get no information. In fact, the information received by a player i who
transmitted during t is whether his transmission was successful (in which case he
gets an acknowledgement and exits the game) or whether there was a collision.
Let hi,t be the vector of the personal transmission history of player i up to
time t, i.e. hi,t = (Xi,1, Xi,2, . . . , Xi,t). We also denote by ht the transmis-
sion history of all players up to time t, i.e. ht = (h1,t, h2,t, . . . , hn,t). In an
acknowledgement-based protocol, the actions of player i at time t depend only
(a) on his personal history hi,t−1 and (b) on whether he is pending or not at
t. A decision rule fi,t for a pending player i at time t, is a function that maps
hi,t−1 to a probability Pr(Xi,t = 1|hi,t−1). For a player i ∈N, a (transmission)
protocol fi is a sequence of decision rules fi = {fi,t}t≥1 = fi,1, fi,2, · · · .
A transmission protocol is anonymous if and only if the decision rule assigns
the same transmission probability to all players with the same personal history.
In particular, for any two players i ̸= j and any t ≥0, if hi,t−1 = hj,t−1, it
holds that fi,t(hi,t−1) = fj,t(hj,t−1). In this case, we drop the subscript i in the
notation, i.e. we write f = f1 = · · · = fn.
We call a protocol fi for player i age-based if and only if, for any t ≥1,
the transmission probability Pr(Xi,t = 1|hi,t−1) depends only (a) on time t and
(b) on whether player i is pending or not at t. In this case, we will denote the
transmission probability by pi,t
def
= Pr(Xi,t = 1|hi,t−1) = fi,t(hi,t−1).
We call a transmission protocol fi non-blocking if and only if, for any
t ≥1 and any transition history hi,t−1, the transmission probability Pr(Xi,t =
1|hi,t−1) is always smaller than 1. A protocol fi for player i is a deadline protocol
with deadline t0 ∈{1, 2, . . .} if and only if fi,t(hi,t−1) = 1, for any player i, any
time slot t ≥t0 and any transmission history hi,t−1. A persistent player is one
that uses the deadline protocol with deadline 1.
Individual Utility. Let f = (f1, f2, . . . , fn) be such that player i uses protocol
fi, i ∈N. For a given transmission sequence X1, X2, . . ., which is consistent
with f, deﬁne the latency or success time of agent i as Ti
def
= inf{t : Xi,t =
1, Xj,t = 0, ∀j ̸= i}. That is, Ti is the time at which i successfully transmits.
Given a transmission history ht, the n-tuple of protocols f induces a probabil-
ity distribution over sequences of further transmissions. In that case, we write
Cf
i (ht)
def
= E[Ti|ht, f] = E[Ti|hi,t, f] for the expected latency of agent i incurred
by a sequence of transmissions that starts with ht and then continues based on
f. For anonymous protocols, i.e. when f1 = f2 = · · · = fn = f, we will simply
write Cf
i (ht) instead1.
Equilibria. The objective of every agent is to minimize her expected latency.
We say that f = {f1, f2, . . . , fn} is in equilibrium if for any transmission history
1 Abusing notation slightly, we will also write Cf
i (h0) for the unconditional expected
latency of player i induced by f.

A 3-Player Protocol Preventing Persistence in Strategic Contention
245
ht the agents cannot decrease their expected latency by unilaterally deviating
after t; that is, for all agents i, for all time slots t, and for all decision rules f ′
i
for agent i, we have
Cf
i (ht) ≤C
(f −i,f ′
i)
i
(ht),
where (f −i, f ′
i) denotes the protocol proﬁle2 where every agent j ̸= i uses pro-
tocol fj and agent i uses protocol f ′
i.
3
A 3-Player Protocol that Prevents Persistence
In this section we prove that there is an anonymous age-based protocol P(c, p) for
3 players that has ﬁnite expected latency and prevents players from unilaterally
switching to any deadline protocol. In what follows, Alice is one of the three
players in the system.
For some parameters c ≥1 and p ∈[0, 1], which will be speciﬁed later, we
deﬁne the protocol P = P(c, p) as follows:
Pt =

p,
if t = k
j=0⌊2cj⌋, for some k = 0, 1, . . .
1,
otherwise.
(1)
For k = 0, 1, 2, . . ., deﬁne the k-th non-trivial transmission time sk to be the
time step on which the decision rule for a pending player using P is to transmit
with probability p. In particular, sk
def
= k
j=0⌊2cj⌋, by deﬁnition of the protocol.
For technical reasons, we set sk = 0, for any k < 0. Furthermore, for k = 1, 2, . . .,
deﬁne the k-th (non-trivial) inter-transmission time xk as the time between the
k-th and (k −1)-th non-trivial transmission time, i.e. xk
def
= sk −sk−1 = ⌊2ck⌋.
The following elementary result will be useful for the analysis of the protocol.
The proof can be found in [7].
Lemma 1. For any k, k′, j ∈{0, 1, . . .}, such that k′ > k, and any c ∈[1, 2], we
have that
ck′−k−1(c −1)xk+j ≤xk′+j ≤ck′−k−1(c + 1)xk+j.
3.1
Expected Latency for a Persistent Player
Assume that Alice is a persistent player, i.e. she uses the deadline protocol g
with deadline 1, i.e. gt = 1, for all t ≥1, while both other players use protocol
P. For n ∈{1, 2, 3}, k ∈{0, 1, . . .}, let Y ′
n,k be the additional time after sk−1
that Alice needs to successfully transmit when there are n pending players. It is
evident that Alice will be the ﬁrst player to successfully transmit, so there will
be no need to calculate E[Y ′
2,k] or E[Y ′
1,k].
The proof of the following Theorem can be found in [7].
2 For an anonymous protocol f, we denote by (f−i, f ′
i) the proﬁle where agent j ̸= i
uses protocol f and agent i uses protocol f ′
i.

246
G. Christodoulou et al.
Theorem 2. If
1
1−(1−p)2 < c ≤2, then E[Y ′
3,0] = ∞. That is, the expected
latency for Alice when she is persistent and both other players use protocol P(c, p)
is inﬁnity.
Remark 1. At ﬁrst glance, the above result may seem surprising. Indeed, let Z
denote the number of times that the persistent player has a collision whenever the
other players transmit with probability p (i.e. we do not count collissions when
the other two players transmit with probability 1, which causes certain collision).
It is easy to see that Z + 1 is a geometric random variable with probability of
success (1 −p)2. Therefore, E[Z + 1] =
1
(1−p)2 is ﬁnite! On the other hand, it
is not hard to see that the (actual) time Y ′
3,0 needed for the persistent player
to successfully transmit is given by Y ′
3,0 = Z
j=0⌊2cj⌋. In particular, Y ′
3,0 is a
strictly convex function of Z, for any c > 1, and so, by Jensen’s inequality (see
e.g. [23]) E[Y ′
3,0] > E[Z]
j=0 ⌊2cj⌋.
3.2
Expected Latency When All Players Use P(c, p)
Assume that all three players use protocol P. For n ∈{1, 2, 3}, k ∈{0, 1, . . .}, let
Yn,k be the additional time after sk−1 that Alice needs to successfully transmit,
when there are n pending players. The following corollary, which is a direct
consequence of Lemma 1, will be useful for our analysis.
Corollary 1. For any n ∈{1, 2, 3}, any k, k′ ∈{0, 1, . . .} with k′ > k, and
c ∈[1, 2] we have that
ck′−k−1(c −1)E[Yn,k] ≤E[Yn,k′] ≤ck′−k−1(c + 1)E[Yn,k].
The main purpose of this section is to prove Theorem 3. To do this, we need
to consider E[Yn,k], for all values of n ∈{1, 2, 3}, k ∈{0, 1, . . .}.
The Case n = 1. When only Alice is pending, we have
E[Y1,k] = ⌊2ck⌋p +
⎛
⎝
k+1

j=k
⌊2cj⌋
⎞
⎠p(1 −p) + . . .
=
∞

ℓ=k
⎛
⎝
⎛
⎝
ℓ

j=k
⌊2cj⌋
⎞
⎠p(1 −p)ℓ−k
⎞
⎠
≤
∞

ℓ=k
⎛
⎝
⎛
⎝
ℓ

j=k
2cj
⎞
⎠p(1 −p)ℓ−k
⎞
⎠
=
∞

ℓ=k
		
2cℓ+1 −ck
c −1

p(1 −p)ℓ−k

≤
2cp
(c −1)(1 −p)k
∞

ℓ=k

cℓ(1 −p)ℓ
.
(2)
In particular, by the above inequality, we have the following:

A 3-Player Protocol Preventing Persistence in Strategic Contention
247
Lemma 2. If 1 < c <
1
1−p, then E[Y1,k] is ﬁnite, for any (ﬁnite) k.
The Case n = 2. Fix k′
1 > 0 and assume c ∈[1, 2] (so that we can apply
Corollary 1). When two players are pending (i.e. Alice and one other player), we
have, for all i = 0, 1, 2, . . . , k′
1 −1,
E[Y2,i] = ⌊2ci⌋+ p(1 −p)E[Y1,i+1] + (1 −2p(1 −p))E[Y2,i+1]
Set δ = 1 −2p(1 −p). Multiplying the corresponding equation for E[Y2,i] by
δi, for each i = 0, 1, 2, . . . , k′
1 −1 and adding up, we get
E[Y2,0] =
k′
1−1

i=0
δi⌊2ci⌋+ p(1 −p)
k′
1−1

i=0
δiE[Y1,i+1] + δk′
1E[Y2,k′
1].
(3)
By the second inequality of Corollary 1 for n = 2 and k = 0, we get
E[Y2,0] ≤
k′
1−1

i=0
δi⌊2ci⌋+ p(1 −p)
k′
1−1

i=0
δiE[Y1,i+1] + δk′
1ck′
1−1(c + 1)E[Y2,0].
(4)
Observe now that, if we have 1 < c <
1
1−p, then, by Lemma 2, the terms
k′
1−1
i=0 δi⌊2ci⌋+ p(1 −p) k′
1−1
i=0 δiE[Y1,i+1] in the above inequality are ﬁnite and
strictly positive. Therefore, E[Y2,0] (which is also strictly positive), will be ﬁnite
if, in addition to c <
1
1−p and c ∈[1, 2], the following inequality holds:
δk′
1ck′
1−1(c + 1) < 1.
(5)
Taking k′
1 →∞(in fact, given p, c, we can choose a minimum, ﬁnite value for
k′
1 so that the above inequality holds, see also [7]), we have that, if c satisﬁes
c <
1
1−2p(1−p), and also c <
1
1−p (so that E[Y1,i] is ﬁnite for all ﬁnite i), and
c ∈(0, 2] (so that we can apply Corollary 1), then E[Y2,0] is ﬁnite. In fact, we
can prove the following more general result:
Lemma 3. If 1 < c < min

1
1−p,
1
1−2p(1−p), 2

, then E[Y2,k] is ﬁnite, for any
(ﬁnite) k.
Proof. By the above arguments, when 1 < c < min

1
1−p,
1
1−2p(1−p), 2

, E[Y2,0]
is ﬁnite. But, by the second inequality of Corollary 1, we also have that E[Y2,k] ≤
ck−1(c + 1)E[Y2,0], which completes the proof.
⊓⊔
The Case n = 3. Fix k′
2 > 0 and assume c ∈[1, 2]. When all three players are
pending, we have, for all i = 0, 1, 2, . . . , k′
2 −1,
E[Y3,i] = ⌊2ci⌋+ 2p(1 −p)2E[Y2,i+1] + (1 −3p(1 −p)2)E[Y3,i+1].

248
G. Christodoulou et al.
Set β = 1−3p(1−p)2. Multiplying the corresponding equation for E[Y3,i] by βi,
for all i = 0, 1, 2, . . . , k′
2 −1 and adding up, we get
E[Y3,0] =
k′
2−1

i=0
βi⌊2ci⌋+ 2p(1 −p)2
k′
2−1

i=0
βiE[Y2,i+1] + βk′
2E[Y3,k′
2].
By the second inequality of Corollary 1 for n = 3 and k = 0, we get
E[Y3,0] ≤
k′
2−1

i=0
βi⌊2ci⌋+2p(1−p)2
k′
2−1

i=0
βiE[Y2,i+1]+βk′
2ck′
2−1(c+1)E[Y3,0]. (6)
Observe now that, if we have 1 < c < min

1
1−p,
1
1−2p(1−p), 2

, then, by
Lemma 3, the terms k′
2−1
i=0 βi⌊2ci⌋+ 2p(1 −p)2 k′
2−1
i=0 βiE[Y2,i+1] in the above
inequality are ﬁnite and strictly positive. Therefore, E[Y3,0] (which is also strictly
positive), will be ﬁnite if, in addition to 1 < c < min

1
1−p,
1
1−2p(1−p), 2

, the
following inequality holds:
βk′
2ck′
2−1(c + 1) < 1.
(7)
Taking k′
2 →∞(in fact, given p, c, we can choose a minimum, ﬁnite value for
k′
2 so that the above inequality holds, see also [7]), we have that, if c satisﬁes
c <
1
1−3p(1−p)2 , and also c < min

1
1−p,
1
1−2p(1−p), 2

(so that E[Y2,i] is ﬁnite
for all ﬁnite i), then E[Y3,0] is ﬁnite. Similarly to the proof of Lemma 3, we can
prove the following more general result:
Theorem 3. If 1 < c < min

1
1−p,
1
1−2p(1−p),
1
1−3p(1−p)2 , 2

, then E[Y3,k] is
ﬁnite, for any (ﬁnite) k. In particular, the expected latency of Alice when all
players (including Alice herself) use protocol P(c, p) is ﬁnite.
3.3
Feasibility
We ﬁrst show that there are values for p and c, such that the following inequalities
hold at the same time:
1 < c < min

1
1 −p,
1
1 −2p(1 −p),
1
1 −3p(1 −p)2

and
1
1 −(1 −p)2 < c ≤2.
By Theorems 2 and 3, if all the above inequalities hold, then E[Y3,0] is ﬁnite,
while E[Y ′
3,0] is inﬁnite.

A 3-Player Protocol Preventing Persistence in Strategic Contention
249
For p = 3/4, the above inequalities become: 1 < c < min{4, 8/5, 64/55} ≈
1.163 and 1.066 ≈16/15 < c ≤2. Therefore, selecting p = 3/4 and c = 1.1, we
have an anonymous age-based protocol that has ﬁnite expected latency and that
prevents players from unilaterally switching to a persistent protocol. In fact we
prove a slightly more general result:
Theorem 4 (restatement of Theorem 1). Assume there are 3 players in the
system, two of which use protocol P(1.1, 0.75). Then, the third player will prefer
using protocol P(1.1, 0.75) over any deadline protocol D.
Proof. Extending the notation used in the previous sections, let Y D
3,0 (respectively
Y3,0) be the time needed for the third player to successfully transmit when
she uses protocol D (respectively protocol P(1.1, 0.75)). Furthermore, let Y ′
3,k,
k ∈{0, 1, . . .}, be the additional time after sk−1 (i.e. the (k −1)-th non-trivial
transmission time) that the third player needs to successfully transmit when she
uses a deadline protocol with deadline 1.
Since c = 1.1 and p = 0.75, we have that 1 < c < min

1
1−p,
1
1−2p(1−p),
1
1−3p(1−p)2

and
1
1−(1−p)2 < c ≤2. Therefore, by Theorems 2 and 3, we have
that E[Y3,0] is ﬁnite and E[Y ′
3,0] = ∞, which means that the third player prefers
using P(1.1, 0.75) over a deadline protocol with deadline 1.
We now prove that the third player prefers using P(1.1, 0.75) over any dead-
line protocol D with deadline t0 = t0(D) as well. Let E be the event that none
of the ﬁrst two players has successfully transmitted before t0. Let also ξ = ξ(t0)
be the number of times t such that P(1.1, 0.75)t = p = 0.75 (i.e. the protocol
P(1.1, 0.75) suggests transmitting with probability less than 1) before time t0
(i.e. ξ(t0) is the number of non-trivial transmissions before t0). We can see that
Pr(E) ≥(1 −2p(1 −p))ξ.
In fact, this lower bound is quite crude, since it does not take into account
the third player, so the probability that one of the ﬁrst two players succesﬀully
transmits during a non-trivial transmission time step when both are pending is
2p(1 −p). We now have the following:
E

Y D
3,0

=
∞

t=0
t Pr

Y D
3,0 = t

≥Pr(E)
∞

t=τ
t Pr

Y D
3,0 = t|E

= Pr(E)
∞

t=τ
t Pr(Y ′
3,ξ = t)
≥Pr(E)
∞

t=0
t Pr(Y ′
3,ξ = t) −t2
0 = Pr(E)E[Y ′
3,ξ] −t2
0
≥Pr(E)cξ−1(c −1)E[Y ′
3,0] −t2
0 = ∞
where in the last inequality we used the ﬁrst inequality of Corollary 1. Therefore,
the third player prefers using P(1.1, 0.75) over D as well. Since D is arbitrary,
the proof is complete.
⊓⊔

250
G. Christodoulou et al.
In [7], we show that when all three players use the protocol P(1.1, 0.75), the
expected latency of a ﬁxed player is upper bounded by 2759. It is worth noting
that a naive protocol where each player transmits with constant probability, say
1
3, at any time t, has a better expected latency than that of P(c, p), but on
the other hand it does not prevent players from unilaterally switching to some
deadline protocol.
References
1. Abramson, N.: The ALOHA system: another alternative for computer communi-
cations. In: Proceedings of the Fall Joint Computer Conference, 17–19 November
1970, pp. 281–285. ACM New York (1970)
2. Altman, E., El Azouzi, R., Jim´enez, T.: Slotted aloha as a game with partial
information. Comput. Netw. 45(6), 701–713 (2004)
3. Altman, E., Barman, D., Benslimane, A., Azouzi, R.: Slotted aloha with priori-
ties and random power. In: Boutaba, R., Almeroth, K., Puigjaner, R., Shen, S.,
Black, J.P. (eds.) NETWORKING 2005. LNCS, vol. 3462, pp. 610–622. Springer,
Heidelberg (2005). doi:10.1007/11422778 49
4. Auletta, V., Moscardelli, L., Penna, P., Persiano, G.: Interference games in wireless
networks. In: Papadimitriou, C., Zhang, S. (eds.) WINE 2008. LNCS, vol. 5385,
pp. 278–285. Springer, Heidelberg (2008). doi:10.1007/978-3-540-92185-1 34
5. Bender, M., Farach-Colton, M., He, S., Kuszmaul, B., Leiserson, C.: Adversarial
contention resolution for simple channels. In: SPAA 2005, pp. 325–332. ACM (2005)
6. Capetanakis, J.: Tree algorithms for packet broadcast channels. IEEE Trans. Inf.
Theory 25(5), 505–515 (1979)
7. Christodoulou, G., Gairing, M., Nikoletseas, S.E., Raptopoulos, C., Spirakis, P.G.:
A 3-player protocol preventing persistence in strategic contention with limited
feedback. arXiv:1707.01439 [cs.GT]
8. Christodoulou, G., Gairing, M., Nikoletseas, S.E., Raptopoulos, C., Spirakis, P.G.:
Strategic contention resolution with limited feedback. In: Proceedings of the 24th
Annual European Symposium on Algorithms (ESA), pp. 30:1–30:16 (2016)
9. Christodoulou, G., Ligett, K., Pyrga, E.: Contention resolution under selﬁshness.
Algorithmica 70(4), 675–693 (2014)
10. Fiat, A., Mansour, Y., Nadav, U.: Eﬃcient contention resolution protocols for
selﬁsh agents. In: SODA 2007, pp. 179–188. SIAM, Philadelphia (2007)
11. Ger´eb-Graus, M., Tsantilas, T.: Eﬃcient optical communication in parallel com-
puters. In: SPAA 1992, pp. 41–48. ACM, New York (1992)
12. Goldberg, L.A., MacKenzie, P.D.: Analysis of practical backoﬀprotocols for con-
tention resolution with multiple servers. J. Comput. Syst. Sci. 58(1), 232–258
(1999)
13. Goldberg, L.A., Mackenzie, P.D., Paterson, M., Srinivasan, A.: Contention resolu-
tion with constant expected delay. J. ACM 47(6), 1048–1096 (2000)
14. Goldberg, L.A.: Notes on contention resolution (2002). http://www.cs.ox.ac.uk/
people/leslieann.goldberg/contention.html
15. Greenberg, A., Winograd, S.: A lower bound on the time needed in the worst case
to resolve conﬂicts deterministically in multiple access channels. J. ACM 32(3),
589–596 (1985)
16. Hayes, J.: An adaptive technique for local distribution. IEEE Trans. Commun.
26(8), 1178–1186 (1978)

A 3-Player Protocol Preventing Persistence in Strategic Contention
251
17. Koutsoupias, E., Papakonstantinopoulou, K.: Contention issues in congestion
games. In: Czumaj, A., Mehlhorn, K., Pitts, A., Wattenhofer, R. (eds.) ICALP
2012. LNCS, vol. 7392, pp. 623–635. Springer, Heidelberg (2012). doi:10.1007/
978-3-642-31585-5 55
18. Ma, R.T., Misra, V., Rubenstein, D.: Modeling and analysis of generalized slotted-
aloha MAC protocols in cooperative, competitive and adversarial environments.
In: ICDCS 2006, p. 62. IEEE, Washington, DC, USA (2006)
19. MacKenzie, P.D., Plaxton, C.G., Rajaraman, R.: On contention resolution proto-
cols and associated probabilistic phenomena. J. ACM 45(2), 324–378 (1998)
20. Menache, I., Shimkin, N.: Eﬃcient rate-constrained nash equilibrium in collision
channels with state information. In: INFOCOM 2008, pp. 403–411 (2008)
21. Raghavan, P., Upfal, E.: Stochastic contention resolution with short delays. Tech-
nical report, Weizmann Science Press of Israel, Jerusalem, Israel (1995)
22. Roberts, L.: Aloha packet system with and without slots and capture. SIGCOMM
Comput. Commun. Rev. 5(2), 28–42 (1975)
23. Sheldon, R.: A First Course in Probability. Pearson, London (2012)
24. Tobagi, F.A., Kleinrock, L.: Packet switching in radio channels: part II-the hidden
terminal problem in carrier sense multiple-access and the busy-tone solution. IEEE
Trans. Commun. 23(12), 1417–1433 (1975)
25. Tsybakov, B.S., Mikhailov, V.A.: Free synchronous packet access in a broadcast
channel with feedback. Probl. Inf. Transm. 14(4), 259–280 (1978)
26. Wang, D., Comaniciu, C., Tureli, U.: Cooperation and fairness for slotted aloha.
Wirel. Pers. Commun. 43(1), 13–27 (2007)
27. Zheng, D., Ge, W., Zhang, J.: Distributed opportunistic scheduling for ad-hoc
communications: an optimal stopping approach. In: MobiHoc 2007, pp. 1–10. ACM
(2007)

Hedging Under Uncertainty: Regret
Minimization Meets Exponentially Fast
Convergence
Johanne Cohen1, Am´elie H´eliou2,3, and Panayotis Mertikopoulos4(B)
1 LRI-CNRS, Universit´e de Paris-Sud, Universit´e Paris-Saclay, Orsay, France
johanne.cohen@lri.fr
2 AMIB Project, Inria Saclay, 91120 Palaiseau, France
3 LIX CNRS UMR 7161, Ecole Polytechnique, Universit´e Paris-Saclay, 91120
Palaiseau, France
amelie.heliou@polytechnique.edu
4 Univ. Grenoble Alpes, CNRS, Grenoble INP, Inria, LIG, 38000 Grenoble, France
panayotis.mertikopoulos@imag.fr
Abstract. This paper examines the problem of multi-agent learning in
N-person non-cooperative games. For concreteness, we focus on the so-
called “hedge” variant of the (EW) algorithm, one of the most widely
studied algorithmic schemes for regret minimization in online learning. In
this multi-agent context, we show that (a) dominated strategies become
extinct (a.s.); and (b) in generic games, pure Nash equilibria are attract-
ing with high probability, even in the presence of uncertainty and noise of
arbitrarily high variance. Moreover, if the algorithm’s step-size does not
decay too fast, we show that these properties occur at a quasi-exponential
rate – that is, much faster than the algorithm’s O(1/
√
T) worst-case
regret guarantee would suggest.
Keywords: Dominated
strategies ·
Exponential
weights ·
Nash
equilibrium · No-regret learning
1
Introduction
In its most basic form, the prototypical framework of online learning can be
summarized as follows: at each instance t = 1, 2, . . . of a repeated decision
process, a player selects an action αt from some ﬁnite set A, and they obtain
a reward ut(αt) based on an a priori unknown payoﬀfunction ut : A →R.
Subsequently, the player observes some problem-speciﬁc feedback (for instance,
the resulting payoﬀvector or some estimate thereof), and selects a new action
seeking to mazimize their reward over time. In the absence of any other consid-
erations, this objective is usually quantiﬁed by asking that the player’s regret
Reg(T) ≡maxα∈A
T
t=1 [ut(α) −ut(αt)] grow sublinearly in T, a property
known as “no regret”.
Game-theoretic learning is a multi-agent extension of the above in which
every player’s payoﬀs are determined by the actions of all players via a ﬁxed
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 252–263, 2017.
DOI: 10.1007/978-3-319-66700-3 20

Hedging Under Uncertainty: Regret Minimization
253
mechanism – the game. Of course, in many applications, this mechanism may
be unknown and/or opaque to the players (who, conceivably, might not even
know that they are playing a game). As a result, we are led to the following key
questions: if the players of a repeated game agnostically update their strategies
following an algorithm that minimizes their individual regret, does the induced
sequence of play converge to a Nash equilibrium (or some other rationally jus-
tiﬁable solution concept)? And if so, does this still hold true if the players’
observations are contaminated by noise and/or uncertainty?
On the positive side, under no-regret learning, the players’ empirical frequen-
cies of play converge to the game’s Hannan set [12], also known as the set of
coarse correlated equilibria (CCE) [13].1 As such, a partial answer to the ﬁrst
question is that coarse correlated equilibria are indeed learnable via no-regret
learning. In general however, the Hannan set may contain highly non rationaliz-
able outcomes, so the real answer to this question is “no”. For instance, Viossat
and Zapechelnyuk [26] recently constructed an example of a 4 × 4 symmetric
game with a coarse correlated equilibrium that assigns positive weight only on
strictly dominated strategies – an “equilibrium” in name only.
In view of this, our aim in this paper is to examine when no-regret learning
leads to a set of rationally justiﬁable strategies – such as the game’s Nash set
or the set of undominated strategies. To that end, we focus on the widely used
“hedge” variant [9] of the exponential weights (EW) algorithm [19,27], where
the probability of choosing an action is proportional to the exponential of its
cumulative payoﬀover time (so better-performing actions are employed expo-
nentially more often). As is well known, “hedging” is min-max optimal in terms
of the achieved regret minimization rate [5]. Nonetheless, beyond Hannan con-
sistency, few conclusions can be drawn from this property in a game-theoretic
environment where ﬁner convergence criteria apply.
A further complication that arises in game-theoretic learning is that it is
often important to establish the convergence of the actual sequence of play gen-
erated by a learning process – as opposed to its time average. In online learning,
averaging comes up naturally because the focus is on the player’s regret. In
a game-theoretic context however, even if time averages converge, the actual
sequence of play may fail to converge altogether (or may do so at a completely
diﬀerent rate), so the players’ actual behavior (and the payoﬀs they obtain) could
be drastically diﬀerent in the two regimes. Indeed, regret-based results oﬀer little
insight on the “last iterate” of the process, so the analysis of the latter requires
a completely diﬀerent set of tools and techniques.
1.1
Our Results
In their recent paper, Viossat and Zapechelnyuk [26] showed that, in general,
the set of coarse correlated equilibria may contain non rationalizable strate-
gies supported exclusively on strictly dominated strategies. Nevertheless, by
1 As the second name suggests, this set contains the game’s set of correlated equilibria
(CE) – and hence, the game’s set of Nash equilibria as well.

254
J. Cohen et al.
leveraging the consistent negative reinforcement of actions that perform badly
in past instances of play, we show that hedging eliminates dominated strate-
gies with probability 1. Moreover, we show that the rate of elimination is
O(exp(−c T
t=1 γt)) for some positive constant c > 0, where γt is a variable
step-size parameter; in other words, dominated strategies become extinct expo-
nentially fast if γt decays slower than 1/t.
With respect to equilibrium convergence, we show that hedging in generic
games converges locally to pure Nash equilibria with high probability, and the
convergence is global with probability 1 if the game’s equilibrium satisﬁes a
certain variational inequality. The only added caveat for this result is that the
algorithm’s step-size parameter must satisfy a summability condition which pre-
cludes the use of very aggressive step-size policies. Nevertheless, the algorithm
still achieves an exponential O(e−cT 1−b) convergence rate for step-size sequences
of the form γt ∼1/tb, b ∈(1/2, 1).
To account for the fact that players may not have access to perfect payoﬀ
observations, we assume throughout that players can only estimate their payoﬀ
vectors up to a possibly unbounded error with arbitrarily high variance. This
uncertainty is countered by means of a judicious choice of the algorithm’s step-
size parameter γt which can be used to control the weight with which new obser-
vations enter the algorithm at a given stage. This is made possible by exploiting
results from martingale limit theory and the theory of stochastic approximation.
1.2
Related Work
Algorithms and dynamics for learning in games have received considerable atten-
tion over the last few decades. Such procedures can be divided into two broad
categories, depending on whether they evolve in continuous or discrete time:
the former includes the numerous dynamics for learning and evolution (see [23]
for a survey), whereas the latter focuses on learning algorithms for inﬁnitely
iterated games (such as ﬁctitious play and its variants). In this paper, we focus
exclusively on discrete-time algorithms.
In this framework, it is natural to consider agents who learn from their expe-
rience by small adjustments in their behavior based on local – and possibly
imperfect – information. Several such approaches in the literature can be viewed
as decentralized no-regret dynamics – for example the multiplicative/exponential
weights algorithm and its variants [9,19,27], Follow the Regularized/Perturbed
Leader [14,21], etc. Indeed, regret bounds can be used to guarantee that each
player’s utility approaches long-term optimality in adversarial environments, a
natural ﬁrst step towards long-term rational behavior. For example, it has been
shown in [2,22] that the sum of utilities approaches an approximate optimum,
and there is convergence of time averages towards an equilibrium in two-player
zero-sum games [3,7,9]. In all these examples, the players’ average regret van-
ishes at the worst-case rate of O(1/
√
T) where T denotes the play horizon. This
convergence rate was recently improved by Syrgkanis et al. [24] for a wide class
of N-player normal form games using a natural class of regularized learning
algorithms. However, the convergence results established in [24] concerned (a)

Hedging Under Uncertainty: Regret Minimization
255
the set of coarse correlated equilibria (which may contain highly non rationaliz-
able strategies); and (b) the “long-run average” ¯xT = T −1 T
t=1 xt of the actual
sequence of play. By contrast, our paper focuses squarely on the algorithm’s
“last iterate” (which determines the players’ rewards at each stage), and ﬁner
rationality properties (such as the elimination of dominated strategies or conver-
gence to pure Nash equilibria) that cannot be deduced from coarse equilibrium
convergence results.
The HEDGE algorithm received much attention in various ﬁelds such as opti-
mization [1], multi-armed bandit problems [4], and in general algorithmic game
theory. In particular, the number of payoﬀqueries needed to compute approxi-
mate correlated equilibria has been studied in [10]: upper and lower bounds have
been derived, as well as reductions between problems, such as the reduction of
the problem of verifying an approximate well supported Nash equilibrium to the
problem of computing a well supported Nash equilibrium under some assump-
tions.
Kleinberg et al. [15] studied the behavior of the dynamic of the HEDGE
algorithm for some particular load balancing games (the so-called atomic load
balancing games) in the “bulletin board” model. In this latter model, players
know the actual payoﬀof each strategy according to the actual strategies played.
They proved that if all players play according to the same mixed strategy, the
dynamics of the history of play converge, and the limit is necessarily a stable
distribution over states, such as a mixed Nash or a correlated equilibrium. Fur-
thermore, the average performance of the dynamics has been analyzed in atomic
load balancing games. Recently, in a similar spirit, Foster et al. [8] showed that
some variants of HEDGE algorithms are such that the average of the outcome
converge rapidly to an approximation of the optimum in smooth games. In par-
allel, Krichene et al. [16] extended the result to congestion games, and proved
that a discounted variant of the HEDGE algorithm converges to the set of Nash
equilibria in the sense of Ces`aro means (time averages), while strong conver-
gence can be guaranteed with some additional conditions. Their proof is based
on the so-called Kullback–Leibler (KL) divergence. Finally, Coucheney et al. [6]
also showed that a “penalty-regulated” variant of the HEDGE algorithm with
bandit feedback converges to logit equilibria in congestion games, but their tech-
niques do not extend to actual Nash equilibria. In the current paper, we do not
restrict ourselves to congestion games; instead, we consider generic games that
admit a Nash equilibrium in pure strategies, of which congestion and potential
games are a special case.
2
Preliminaries
Throughout the paper, we focus on games that are played by a (ﬁnite) set
N = {1, . . . , N} of N players (or agents). Each player i ∈N is assumed to
have a ﬁnite set of actions (or pure strategies) Ai, and the players’ preferences
for one action over another are represented by each action’s utility (or payoﬀ).
Speciﬁcally, as players interact with each other, the individual payoﬀof each
player is given by a function ui : A ≡
i Ai →R of all players’ actions, and each

256
J. Cohen et al.
agent seeks to maximize the utility ui(αi; α−i) of their chosen action αi ∈Ai
against the action proﬁle α−i of his opponents.2 A game is then called (weakly)
generic if there are no unilateral payoﬀties, i.e. if ui(αi; α−i) ̸= ui(βi; α−i) for
all αi, βi ∈Ai, i ∈N.
Players can also use mixed strategies by playing probability distributions
xi = (xiαi)αi∈Ai ∈Δ(Ai) over their action sets Ai. The resulting probability
vector xi is called the mixed strategy of the i-th player and the set Xi = Δ(Ai)
is the corresponding mixed strategy space of player i; aggregating over players,
we also write X = 
i Xi for the game’s strategy space, i.e. the space of all mixed
strategy proﬁles x = (xi)i∈N .
In this context (and in a slight abuse of notation), the expected payoﬀof the
i-th player in the mixed strategy proﬁle x = (x1, . . . , xN) is
ui(x) =

α1∈A1
· · ·

αN∈AN
ui(α1, . . . , αN) x1α1 · · · xNαN .
(1)
Accordingly, if player i plays the pure strategy αi ∈Ai, we will write
viαi(x) = ui(αi; x−i) = ui(x1, . . . , αi, . . . , xN)
(2)
for the payoﬀcorresponding to αi, and vi(x) = (viαi(x))αi∈Ai for the resulting
payoﬀvector of player i. A player’s expected payoﬀmay thus be written as
ui(x) =

αi∈Ai
xiαiviαi(x) = ⟨vi(x)|xi⟩,
(3)
where ⟨vi|xi⟩denotes the canonical bilinear pairing between vi and xi.
A fundamental rationality principle in game theory is that, assuming full
knowledge of the game, a player would have no incentive to play an action
that always yields suboptimal payoﬀs with respect to another. To formalize this,
αi ∈Ai is called (strictly) dominated by βi (and we write αi ≺βi) if
ui(αi; α−i) < ui(βi; α−i)
for all α−i ∈A−i ≡
j̸=i Aj, i ∈N.
(4)
Extending the notion of strategic dominance, the most widely used solution
concept in game theory is that of a Nash equilibrium (NE), i.e. a state x∗∈X
which is unilaterally stable in the sense that
ui(x∗
i ; x∗
−i) ≥ui(xi; x∗
−i)
for all xi ∈Xi, i ∈N,
(NE)
or, equivalently, writing supp(x) for the support of x:
viαi(x∗) ≥viβi(x∗)
for all αi ∈supp(x∗
i ) and all βi ∈Ai, i ∈N.
(5)
If equilibrium x∗is pure (i.e. supp(x∗
i ) = {α∗
i } for some α∗
i ∈Ai and all i ∈N),
then it is called a pure equilibrium. In generic games, a pure equilibrium satisﬁes
(5) as a strict inequality for all βi /∈supp(x∗
i ), i ∈N, so we sometimes refer to
2 In the above (αi; α−i) is shorthand for (α1, . . . , αi, . . . , αN), used here to highlight
the action of player i against that of all other players.

Hedging Under Uncertainty: Regret Minimization
257
pure equilibria in generic games as strict. Such equilibria will play a key role in
our analysis, so we provide a convenient variational characterization below:
Proposition 1. In generic games, x∗is a pure equilibrium if and only if
⟨v(x)|x −x∗⟩≤−1
2μ∥x −x∗∥
for some μ > 0 and for all x near x∗,
(6)
where ∥x∥= 
i

α∈Ai|xiαi| denotes the L1-norm of x.
There are two remarks to be made here. First, if (6) holds for all x ∈X, then
x∗is the unique Nash equilibrium of the game: indeed, if x′ ̸= x∗is another Nash
equilibrium of the game, we would have 0 ≤⟨v(x′)|x′ −x∗⟩≤−1
2μ∥x′ −x∗∥
< 0, a contradiction. On the other hand, (6) does not imply that x∗is in any
way “dominant”, locally otherwise: for instance, it is easy to verify that the
unique Nash equilibrium of the Prisoner’s Dilemma satisﬁes (6), even though it
is not Pareto eﬃcient (let alone dominant). In general, (6) could seen as a “ﬁnite
games” variant of the notion of evolutionary stability in population games [23];
as such, it is easy to verify that (6) is satisﬁed in the Prisoner’s Dilemma and its
variants, generic competition games, potential games with a unique equilibrium,
etc.
3
Hedging Under Uncertainty
The algorithm that we examine is the so-called “hedge” variant of the exponen-
tial weights algorithm [9]. In a nutshell, the main idea of the algorithm is as
follows: At each stage t = 1, 2, . . . of the process, players maintain and update
a “performance score” for each of their actions (pure strategies) based on each
action’s cumulative payoﬀup to stage t. These scores are then converted to
mixed strategies by assigning exponentially higher probability to actions with
higher scores, and a new action is drawn based on these mixed strategies.
More precisely, this iterative process can be encoded as follows:
Algorithm 1.1. HEDGE with variable step-size γt
1
Each player i ∈N chooses an initial score vector yi(0)
2
for each round t
3
Each player i ∈N plays xi(t) = Λi(yi(t −1)) where the logit map Λi is deﬁned
as
Λi(yi) =
1

α∈Ai exp(yiα)(exp(yiα))α∈Ai.
(7)
4
Each player i ∈N draws a pure strategy αi(t) according to xi(t)
5
Each player i ∈N gets an estimate ˆvi(t) of their payoﬀvector vi(α(t))
6
Each player i ∈N updates their score vectors as
yi(t) = yi(t −1) + γtˆvi(t),
(8)
end for

258
J. Cohen et al.
Mathematically, the above algorithm can be expressed as
xi(t) = Λi(yi(t −1)),
yi(t) = yi(t −1) + γtˆv(t),
(HEDGE)
with yi(0) initialized arbitrarily. Motivated by practical implementation issues
(especially in large networks and telecommunication systems), this formulation
further assumes that players have imperfect knowledge of their payoﬀvectors
vi(α(t)) at each iteration of the algorithm – for instance, contaminated by mea-
surement errors or other uncertainty factors. To formalize this, we will consider
a general feedback model of the form
ˆvi(t) = vi(α(t)) + ξi(t),
(9)
where the error process ξ = (ξi)i∈N is a L2-bounded martingale diﬀerence
sequence with respect to the history Ft of the process (x(t), α(t), ˆv(t), y(t)).
In other words, we assume that ξ(t) satisﬁes the statistical hypotheses
1. Zero-mean:
E[ξ(t) | Ft−1] = 0
for all t = 1, 2, . . . (a.s.);
(H1)
2. Finite mean squared error: there exists some σ > 0 such that
E[∥ξ(t)∥2
∞| Ft−1] ≤σ2
for all t = 1, 2, . . . (a.s.).
(H2)
Put diﬀerently, Hypotheses (H1) and (H2) simply mean that the payoﬀvector
estimates ˆvi are conditionally unbiased and bounded in mean square, i.e.
E[ˆv(t) | Ft−1] = v(x(t)),
(10a)
E[∥ˆv(t)∥2
∞| Ft−1] ≤V 2,
(10b)
where V > 0 is a ﬁnite positive constant (in the noiseless case ξ = 0 the con-
stant V is simply a bound on the players’ maximum absolute payoﬀ).3 Thus,
Hypotheses (H1) and (H2) allow for a broad range of noise distributions, includ-
ing all compactly supported, (sub-)Gaussian, (sub-)exponential and log-normal
distributions.
3 Note here that (10a) is phrased in terms of the players’ mixed strategy proﬁle x(t),
not the action proﬁle α(t) = (αi(t); α−i(t)) which is chosen based on x(t) at stage t.
To see that (H1) indeed implies (10a), simply recall that xi(t) = Λi(yi(t −1)) so
E[ˆviαi(t) | Ft−1] =

α−i∈A−i

ui(αi; α−i)xα−i(t) + E[ξiαi(t) | Ft−1]

= ui(αi; x−i(t)) = viαi(x(t)).
(11)
.

Hedging Under Uncertainty: Regret Minimization
259
4
Rationality Analysis and Results
In this section, we present our main convergence results for (HEDGE). We begin
with the fact that hedging bypasses the negative result of Viossat and Zapachel-
nyuk [26], and does not lead to non-rationalizable, strategically dominated out-
comes:
Theorem 1. Suppose that (HEDGE) is run with a step-size sequence of the
form γt ∝1/tb for some b ≤1 (not necessarily positive), and noisy payoﬀ
observations satisfying Hypotheses (H1) and (H2). If αi ∈Ai is dominated,
there exists some c > 0 such that
xiαi(T + 1) = O(exp(−c T
t=1 γt))
with probability 1.
(12)
In particular, if b < 1, αi becomes extinct exponentially fast (a.s.).
Proof. Suppose that αi ≺βi for some βi ∈Ai. Then, suppressing the player
index i for simplicity, we get
yβ(T) −yα(T) = cβα +
T

t=1
γt [ˆvβ(t) −ˆvα(t)]
= cβα +
T

t=1
γt [vβ(x(t)) −vα(x(t))] +
T

t=1
γtζt,
(13)
where we set cβα = yβ(0) −yα(0) and ζt = ˆvβ(t) −vβ(x(t)) −[ˆvα(t) −vα(x(t))].
Since α ≺β, there exists some μ > 0 such that vβ(x) −vα(x) ≥μ for all x ∈X.
Then, (13) yields
yβ(T) −yα(T) ≥cβα + θT

μ +
T
t=1 γtζt
θT

,
(14)
with θT = T
t=1 γt.
Since E[ζt | Ft−1] = 0 and supt E[ζ2
t | Ft−1] < ∞by the reformulation (10a)
and (10b) of Hypotheses (H1) and (H2) respectively, the law of large numbers
for martingale diﬀerence sequences [11, Theorem 2.18] gives θ−1
T
T
t=1 γtζt →0
(a.s.), provided that ∞
t=1(γt/θt)2 < ∞and ∞
t=1 γt = ∞. This last assumption
is satisﬁed for all b ≤1, so we readily get θ−1
T
T
t=1 γtζt →0 with probability 1.
As a result, for all c ∈(0, μ), there exists some random (but a.s. ﬁnite) T0 such
that if T ≥T0, then yβ(T) −yα(T) ≥cθT . Thus, with xα(T + 1) = Λα(y(T)) by
deﬁnition, we get
xα(T + 1) =
eyα(T )

κ eyκ(T ) ≤eyα(T )
eyβ(T ) = eyα(T )−yβ(T ) ≤e−c T
t=1 γt
(a.s.),
(15)
and our proof is complete.
⊓⊔

260
J. Cohen et al.
Remark 1. It should be noted here that the elimination of dominated strategies
with imperfect knowledge of the game’s payoﬀs is by no means a given.4 For
instance, if players play a greedy best response scheme at each round and the
payoﬀobservation errors are not supported on a small, compact set, dominated
strategies will be played inﬁnitely often (simply because at each round, any
strategy could be erroneously perceived as a best response).5 With this in mind,
the fact that the rate of elimination (12) improves with more aggressive – even
increasing – step-size sequences γt is somewhat surprising because it suggests
that players can employ (HEDGE) in a very greedy fashion and achieve fast
dominated strategy extinction rates, even in the presence of arbitrarily high
estimation errors.
Remark 2. Regarding the number of players and actions per player, our proof
reveals that c depends only on the player’s payoﬀs – speciﬁcally, we can take
c = 1
2 minα−i∈A−i[ui(βi; α−i) −ui(αi; α−i)] > 0. In other words, the algorithm’s
half-life is asymptotically independent of the size of the game, and only depends
on the players’ relative payoﬀdiﬀerences.
Remark 3. Finally, we should note that Theorem 1 also extends to the case of
iteratively dominated strategies.6 As such, Theorem 1 implies that the sequence
of play induced by (HEDGE) actually converges to the set of iteratively undom-
inated strategies of the game.
We now turn to the convergence properties of (HEDGE) in generic games
that admit pure Nash equilibria:
Theorem 2. Fix a conﬁdence level ε > 0 and suppose that (HEDGE) is run
with a small enough (depending on ε) step-size γt satisfying ∞
t=1 γ2
t < ∞and
∞
t=1 γt = ∞, and imperfect payoﬀobservations satisfying Hypotheses (H1) and
(H2). If x∗is a pure equilibrium of a generic game and (HEDGE) is initialized
not too far from x∗, we have
P

∥x(T + 1) −x∗∥≤C′e−c T
t=1 γt for all t

≥1 −ε,
(16)
where c > 0 is a constant that only depends on the game and C′ > 0 is a
(random) constant that depends on the initialization of (HEDGE). In particular,
under the stated assumptions, x(t) →x∗with probability at least 1 −ε.
Corollary 1. With assumptions as above, if (HEDGE) is run with a step-size
of the form γt = γ/tb for some suﬃciently small γ > 0 and b ∈(1/2, 1), we have
P

∥x(T + 1) −x∗∥= O

e−cγ
1−b T 1−b
≥1 −ε
(17)
for some positive constant c > 0.
4 To the best of our knowledge, the closest result is the elimination of dominated
strategies under exponential learning in continuous time [20]; for a survey of the
relevant literature, see [25].
5 Recall also the counterexample of [26] discussed in the introduction.
6 This can be shown by an induction argument on the rounds of elimination of domi-
nated strategies as in [18].

Hedging Under Uncertainty: Regret Minimization
261
Relegating the (somewhat involved) proof of Theorem 2 to the long version of
the paper, we note here that, in contrast to Theorem 1, the “L2−L1” summability
requirement ∞
t=1 γ2
t < ∞and ∞
t=1 γt = ∞constrains the admissible step-size
policies that lead to pure equilibrium (for instance, constant step-size policies are
no longer admissible). In particular, the most aggressive step-size that satisﬁes
the assumptions of Theorem 2 is γt ∝t−b for some b close (but not equal) to
1/2, leading to a convergence rate of λt1−b for some real λ < 1 (cf. Corollary 1).
This bound on b is due to the second moment growth bound required by Doob’s
maximal inequality; if there is ﬁner control on the moments of the noise process
ξ (for instance, if the noise is sub-exponential), the lower bound b > 1/2 can be
pushed all the way down to b > 0, implying a quasi-linear convergence rate.
As was hinted above, the main idea behind the proof of Theorem 2 is to use
Doob’s maximal inequality for martingales to show that the probability of x(t)
escaping the basin of attraction of a pure Nash equilibrium x∗can be made
arbitrarily small if the algorithm’s step-size is chosen appropriately. Building
on this, if x∗satisﬁes the variational inequality (6) throughout X, we have the
stronger result:
Theorem 3. Suppose that (HEDGE) is run with a step-size sequence γt such
that ∞
t=1 γ2
t < ∞and ∞
t=1 γt = ∞and imperfect payoﬀobservations satisfying
Hypotheses (H1) and (H2). If x∗satisﬁes (6) for all x ∈X, then:
1. limT →∞x(T) = x∗(a.s.).
2. There exists a (deterministic) constant c > 0 such that
∥x(T + 1) −x∗∥= O
	
e−c T
t=1 γt
.
(18)
Corollary 2. With assumptions as above, if (HEDGE) is run with a step-size
of the form γt = γ/tb some b ∈(1/2, 1), we have
∥x(T + 1) −x∗∥= O(e−μγ
1−b T 1−b).
(19)
In contrary to Theorems 1 and 2, the proof of Theorem 3 relies heavily on
the so-called Kullback–Leibler (KL) divergence [17], deﬁned here as
DKL(x∗, x) =

i∈N

αi∈Ai
x∗
iαi log x∗
iαi
xiαi
for all x ∈X ◦.
(20)
The KL divergence is a positive-deﬁnite, asymmetric distance measure that is
tailored to the analysis of the replicator dynamics [18,23,28]. By using this
divergence as a discrete-time Lyapunov function, we show that x∗is a recurrent
point of the process x(t), i.e. x(t) visits any neighborhood of x∗inﬁnitely many
times. We then use a stochastic approximation argument to show that the process
actually converges to x∗at an asymptotic rate of O(e−c T
t=1 γt).

262
J. Cohen et al.
The step-size assumption in the statement of Theorem 3 is key in achieving
this, but it is important to note it can be relaxed to T
t=1 γ2
t
 T
t=1 γt →0 if the
players’ feedback noise is bounded (for instance, if players have access to their
actual pure payoﬀinformation). When this is the case, it is possible to achieve
an O(e−cT 1−b) convergence rate for any b > 0 by using a step-size sequence of
the form γt ∝1/tb.
5
Conclusions
Our main goal is to analyse the convergence properties of the “hedge” variant
of the exponential weights algorithm [9] in generic N-player games that admit a
Nash equilibrium in pure strategies. Using techniques drawn from the theory of
stochastic approximation and martingale limit theory, we showed that (i) dom-
inated strategies become extinct (a.s.); (ii) pure equilibria are locally attracting
with high probability; and (iii) pure equilibria that satisfy a certain variational
stability condition are globally attracting with probability 1. Moreover, despite
the uncertainty in the players’ payoﬀobservations, we showed that the elimi-
nation of dominated strategies is exponentially fast – in stark contrast to more
unreﬁned best response schemes which, under uncertainty, may lead to playing
dominated strategies inﬁnitely often. Using the theory of stochastic approxi-
mation and discrete-time martingale processes, we showed that the algorithm’s
convergence (local or global, depending on the context) to a pure Nash equi-
librium is also exponentially fast, even in the presence of uncertainty and noise
of arbitrary magnitude. These results apply to all generic games that admit a
Nash equilibrium in pure strategies, and not only to the class of coordination
and anti-coordination (or congestion) games that have been the traditional focus
of the game-theoretic learning literature.
Acknowledgment. This work was partially supported from the French National
Research Agency (ANR) under grant no. ANR–16–CE33–0004–01 (ORACLESS) and
the Huawei HIRP FLAGSHIP project ULTRON.
References
1. Arora, S., Hazan, E., Kale, S.: The multiplicative weights update method: a meta-
algorithm and applications. Theory Comput. 8(1), 121–164 (2012)
2. Blum, A., Hajiaghayi, M.T., Ligett, K., Roth, A.: Regret minimization and the
price of total anarchy. In: STOC 2008: Proceedings of the 40th Annual ACM
Symposium on the Theory of Computing, pp. 373–382. ACM (2008)
3. Blum, A., Mansour, Y.: Learning, regret minimization, and equilibria (Chap. 4). In:
Nisan, N., Roughgarden, T., Tardos, E., Vazirani, V.V. (eds.) Algorithmic Game
Theory. Cambridge University Press, Cambridge (2007)
4. Bubeck, S., Cesa-Bianchi, N.: Regret analysis of stochastic and nonstochastic multi-
armed bandit problems. Found. Trends Mach. Learn. 5(1), 1–122 (2012)
5. Cesa-Bianchi, N., Lugosi, G.: Prediction, Learning, and Games. Cambridge Uni-
versity Press, Cambridge (2006)

Hedging Under Uncertainty: Regret Minimization
263
6. Coucheney, P., Gaujal, B., Mertikopoulos, P.: Penalty-regulated dynamics and
robust learning procedures in games. Math. Oper. Res. 40(3), 611–633 (2015)
7. Foster, D., Vohra, R.V.: Calibrated learning and correlated equilibrium. Games
Econ. Behav. 21(1), 40–55 (1997)
8. Foster, D.J., Lykouris, T., Sridharan, K., Tardos, E.: Learning in games: robustness
of fast convergence. In: Advances in Neural Information Processing Systems, pp.
4727–4735 (2016)
9. Freund, Y., Schapire, R.E.: Adaptive game playing using multiplicative weights.
Games Econ. Behav. 29, 79–103 (1999)
10. Goldberg, P.W., Roth, A.: Bounds for the query complexity of approximate equi-
libria. ACM Trans. Econ. Comput. 4(4), 24:1–24:25 (2016)
11. Hall, P., Heyde, C.C.: Martingale Limit Theory and Its Application. Probability
and Mathematical Statistics. Academic Press, New York (1980)
12. Hannan, J.: Approximation to Bayes risk in repeated play. In: Dresher, M., Tucker,
A.W., Wolfe, P. (eds.) Contributions to the Theory of Games. Annals of Mathe-
matics Studies, vol. 39, pp. 97–139. Princeton University Press, Princeton (1957)
13. Hart, S., Mas-Colell, A.: A simple adaptive procedure leading to correlated equi-
librium. Econometrica 68(5), 1127–1150 (2000)
14. Kalai, A., Vempala, S.: Eﬃcient algorithms for online decision problems. J. Com-
put. Syst. Sci. 71(3), 291–307 (2005)
15. Kleinberg, R., Piliouras, G., Tardos, ´E.: Load balancing without regret in the
bulletin board model. Distrib. Comput. 24(1), 21–29 (2011)
16. Krichene, W., Drigh`es, B., Bayen, A.M.: Learning Nash equilibria in congestion
games. arXiv preprint arXiv:1408.0017 (2014)
17. Kullback, S., Leibler, R.A.: On information and suﬃciency. Ann. Math. Stat. 22(1),
79–86 (1951)
18. Laraki, R., Mertikopoulos, P.: Higher order game dynamics. J. Econ. Theory
148(6), 2666–2695 (2013)
19. Littlestone, N., Warmuth, M.K.: The weighted majority algorithm. Inf. Comput.
108(2), 212–261 (1994)
20. Mertikopoulos, P., Moustakas, A.L.: The emergence of rational behavior in the
presence of stochastic perturbations. Ann. Appl. Probab. 20(4), 1359–1388 (2010)
21. Mertikopoulos, P., Sandholm, W.H.: Learning in games via reinforcement and reg-
ularization. Math. Oper. Res. 41(4), 1297–1324 (2016)
22. Roughgarden, T.: Intrinsic robustness of the price of anarchy. J. ACM (JACM)
62(5), 32 (2015)
23. Sandholm, W.H.: Population Games and Evolutionary Dynamics. Economic Learn-
ing and Social Evolution. MIT Press, Cambridge (2010)
24. Syrgkanis, V., Agarwal, A., Luo, H., Schapire, R.E.: Fast convergence of regularized
learning in games. In: Advances in Neural Information Processing Systems, pp.
2989–2997 (2015)
25. Viossat, Y.: Evolutionary dynamics and dominated strategies. Econ. Theory Bull.
3(1), 91–113 (2015)
26. Viossat, Y., Zapechelnyuk, A.: No-regret dynamics and ﬁctitious play. J. Econ.
Theory 148(2), 825–842 (2013)
27. Vovk, V.G.: Aggregating strategies. In: COLT 1990: Proceedings of the 3rd Work-
shop on Computational Learning Theory, pp. 371–383 (1990)
28. Weibull, J.W.: Evolutionary Game Theory. MIT Press, Cambridge (1995)

Resource Allocation

Tradeoﬀs Between Information and Ordinal
Approximation for Bipartite Matching
Elliot Anshelevich and Wennan Zhu(B)
Rensselaer Polytechnic Institute, Troy, NY, USA
eanshel@cs.rpi.edu, zhuw5@rpi.edu
Abstract. We study ordinal approximation algorithms for maximum-
weight bipartite matchings. Such algorithms only know the ordinal pref-
erences of the agents/nodes in the graph for their preferred matches,
but must compete with fully omniscient algorithms which know the
true numerical edge weights (utilities). Ordinal approximation is all
about being able to produce good results with only limited informa-
tion. Because of this, one important question is how much better the
algorithms can be as the amount of information increases. To address
this question for forming high-utility matchings between agents in X
and Y, we consider three ordinal information types: when we know the
preference order of only nodes in X for nodes in Y, when we know the
preferences of both X and Y, and when we know the total order of the
edge weights in the entire graph, although not the weights themselves.
We also consider settings where only the top preferences of the agents
are known to us, instead of their full preference orderings. We design new
ordinal approximation algorithms for each of these settings, and quantify
how well such algorithms perform as the amount of information given to
them increases.
1
Introduction
Many important settings involve agents with preferences for diﬀerent out-
comes. Such settings include, for example, social choice and matching problems.
Although the quality of an outcome to an agent may be measured by a numeri-
cal utility, it is often not possible to obtain these exact utilities when forming a
solution. This can occur because eliciting numerical information from the agents
may be too diﬃcult, the agents may not want to reveal this information, or
even because the agents themselves do not know the exact numerical values.
On the other hand, eliciting ordinal information (i.e., the preference ordering of
each agent over the outcomes) is often much more reasonable. Because of this,
there has been a lot of recent work on ordinal approximation algorithms: these
are algorithms which only use ordinal preference information as their input, and
yet return a solution provably close to the optimum one (e.g., [3–5,9–12,17]).
This work was partially supported by NSF award CCF-1527497.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 267–279, 2017.
DOI: 10.1007/978-3-319-66700-3 21

268
E. Anshelevich and W. Zhu
In other words, these are algorithms which only use limited ordinal informa-
tion, and yet can compete in the quality of solution produced with omniscient
algorithms which know the true (possibly latent) numerical utility information.
Ordinal approximation is all about being able to produce good results with
only limited information. Because of this, it is important to quantify how well
algorithms can perform as more information is given. If the quality of solutions
returned by ordinal algorithms greatly improves when they are provided more
information, then it may be worthwhile to spend a lot of resources in order to
acquire such more detailed information. If, on the other hand, the improvement is
small, then such an acquisition of more detailed information would not be worth
it. Thus the main question we consider in this paper is: How does the quality of
ordinal algorithms improve as the amount of information provided increases?
In this paper, we speciﬁcally consider this question in the context of com-
puting a maximum-utility matching in a metric space. Matching problems, in
which agents have preferences for which other agents they want to be matched
with, are ubiquitous. The maximum-weight metric matching problem speciﬁcally
provides solutions to important applications, such as forming diverse teams and
matching in friendship networks (see [4,5] for much more discussion of this). For-
mally, there exists a complete undirected bipartite graph for two sets of agents
X and Y of size N, with an edge weight w(x, y) representing how much utility
x ∈X and y ∈Y derive from their match; these edge weights satisfy the trian-
gle inequality. The algorithms we consider, however, do not have access to such
numerical edge weights: they are only given ordinal information about the agent
preferences. The goal is to form a perfect matching between X and Y, in order
to approximate the maximum weight matching as much as possible using only
the given ordinal information. We compare the weight of the matching returned
by our algorithms with the true maximum-weight perfect matching in order to
quantify the performance of our ordinal algorithms.
Types of Ordinal Information. Ordinal approximation algorithms for max-
imum weight matching have been considered before in [4,5], although only for
complete graphs; algorithms for bipartite graphs require somewhat diﬀerent tech-
niques. Our main contribution, however, lies in considering many types of ordinal
information, forming diﬀerent algorithms for each, and quantifying how much
better types of ordinal information improve the quality of the matching formed.
Speciﬁcally, we consider the following types of ordinal information.
– The most restrictive model we consider is one-sided preferences. That is, only
preferences for agents in X over agents in Y are given to our algorithm. These
preferences are assumed to be consistent with the (hidden) agent utilities,
i.e., if x prefers y1 to y2, then it must be that w(x, y1) ≥w(x, y2). Such one-
sided preferences may occur, for example, when X represents people and Y
represents houses. People have preferences over diﬀerent houses, but houses
do not have preferences over people. These types of preferences also apply to
settings in which both sides have preferences, but we only have access to the
preferences of X, e.g., because the agents in Y are more secretive.

Tradeoﬀs Between Information and Ordinal Approximation
269
– The next level of ordinal information we consider is two-sided preferences,
that is, both preferences for agents in X over Y and agents in Y over X are
given. This setting could apply to the situation that two sets of people are
collaborating, and they have preferences over each other, or of a matching
between job applicants and possible employers. As we consider the model in
a metric space, the distance (weight) between two people could represent the
diversity of their skills, and a person prefers someone with most diverse skills
from him/her in order to achieve the best results of collaboration.
– The most informative model which we consider in this paper is that of total-
order. That is, the order of all the edges in the bipartite graph is given to us,
instead of only local preferences for each agent. In this model, global ordinal
information is available, compared to the preferences of each agent in the
previous two models. Studying this setting quantiﬁes how much eﬃciency is
lost due to the fact that we only know ordinal information, as opposed to the
fact that we only know local information given to us by each agent.
Comparing the results for the above three information types allows us to
answer questions like: “Is it worth trying to obtain two-sided preference infor-
mation or total order information when only given one-sided preferences?” How-
ever, above we always assumed that for an agent x, we are given their entire
preferences for all the agents in Y. Often, however, an agent would not give
their preference ordering for all the agents they could match with, and instead
would only give an ordered list of their top preferences. Because of this, in addi-
tion to the three models described above, we also consider the case of partial
ordinal preferences, in which only the top α fraction of a preference list is given
by each agent of X. Thus for α = 0 no information at all is given to us, and for
α = 1 the full preference ordering of an agent is given. Considering partial pref-
erences tells us when, if there is a cost to buying information, we might choose
to buy only part of the ordinal preferences. We establish tradeoﬀs between the
percentage of available preferences and the possible approximation ratio for all
three models of information above, and thus quantify when a speciﬁc amount of
ordinal information is enough to form a high-quality matching.
Our Contributions. We show that as we obtain more ordinal information
about the agent preferences, we are able to form better approximations to
the maximum-utility matching, even without knowing the true numerical edge
weights. Our main results are shown in Fig. 1.
Using only one-sided preference information, with only the order of top αN
preferences given for agents in X, we are able to form a (3 −(2 −
√
2)α)-
approximation. We do this by combining random serial dictatorship with purely
random matchings. When α = 1, the algorithm yields a (
√
2+1)-approximation.
This is the ﬁrst non-trivial analysis for the performance of RSD on maximum
bipartite matching in a metric space, and this analysis is one of our main con-
tributions.
Given two-sided information, with the order of top αN preferences for agents
in both X and Y, we can do signiﬁcantly better. When α ≥1
2, adopting an exist-

270
E. Anshelevich and W. Zhu
Fig. 1. α vs. approximation ratio for partial information. As we obtain more informa-
tion about the agent preferences (α increases), we are able to form better approxima-
tion to the maximum-weight matching. The tradeoﬀfor one-sided preferences is linear,
while it is more complex for two-sided and total order.
ing framework in [4], by mixing greedy and random algorithms, and adjusting
it for bipartite graphs, we get a (3−2α)(3−α)
2α2−3α+3 -approximation. When α ≤1
2, the
framework would still work, but would not produce a good approximation. We
instead design a diﬀerent algorithm to get better results. Inspired by RSD, we
take advantage of the information of preferences from both sets of agents, adjust
RSD to obtain “undominated” edges in each step, and ﬁnally combine it with
random matchings to get a (3 −α)-approximation. When α ≥3
4, the algorithm
yields a 1.8-approximation.
For the total-ordering model, the order of top αN 2 heaviest edges in the
bipartite graph is given. We use the framework in [4] again to obtain a 2+√1−α
2−√1−α-
approximation. Here we must re-design the framework to deal with the cases
that α ≤3
4N, which is not a straight-forward adjustment. When α ≥3
4N the
algorithm yields a 5
3-approximation.
Finally, in Sect. 6 we analyze the case when edge weights cannot be too
diﬀerent: the highest weight edge is at most β times the lowest weight edge in
one-sided model. When the edge weights have this relationship, we can extend
our analysis to give a (

β −3
4 + 1
2)-approximation, even without assuming that
edge weights form a metric.
Discussion and Related Work. Previous work on forming good matchings
can largely be classiﬁed into the following classes. First, there is a large body
of work assuming that numerical weights or utilities don’t exist, only ordinal
preferences. Such work studies many possible objectives, such as forming stable
matchings (see e.g., [15,16]), or maximizing objectives determined only by the
ordinal preferences (e.g., [2,8]). Second, there is work assuming that numerical
utilities or weights exist, and are known to the matching designer. Unlike the
above two settings, we consider the case when numerical weights exist, but are

Tradeoﬀs Between Information and Ordinal Approximation
271
latent or unknown, and yet the goal is to approximate the true social welfare, i.e.,
maximum weight of a perfect matching. Note that although some previous work
assumes that all numerical utilities are known, they often still use algorithms
which only require ordinal information, and thus ﬁt into our framework; we
discuss some of these results below.
Similar to our one-sided model, house allocation [1] is a popular model of
assigning n agents to n items. [6] studied the ordinal welfare factor and the linear
welfare factor of RSD and other ordinal algorithms. [14] studied both maximum
matching and maximum vertex weight matching using an extended RSD algo-
rithm. These either used objectives depending only on ordinal preferences, such
as the size of the matching formed, or used node weights (as opposed to edge
weights). [9,11] assumed the presence of numerical agent utilities and studied the
properties of RSD. Crucially, this work assumed normalized agent utilities, such
as unit-sum or unit-range. This allowed [9,11] to prove approximation ratios of
Θ(√n) for RSD. Instead of assuming that agent utilities are normalized, we con-
sider agents in a metric space; this diﬀerent correlation between agent utilities
allows us to prove much stronger results, including a constant approximation
ratio for RSD. Kalyanasundaram et al. studied serial dictatorship for maximum
weight matching in a metric space [13], and gave a 3-approximation for RSD in
this, while we are able to get a tighter bound of 2.41-approximation.1
Besides maximizing social welfare, minimizing the social cost of a matching
is also popular. [7] studied the approximation ratio of RSD and augmentation
of serial dictatorship (SD) for minimum weight matching in a metric space.
Their setting is very similar to ours, except that we consider the maximization
problem, which has diﬀerent applications [4,5], and allows for a much better
approximation factor (constant instead of linear in n) using diﬀerent techniques.
Another area studying ordinal approximation algorithms is social choice,
where the goal is to decide a single winner in order to maximize the total social
welfare. This is especially related to our work when the hidden utilities of voters
are in a metric space (see e.g., [3,10,12,17]).
The work most related to ours is [4,5]. As mentioned above, we use an exist-
ing framework [4] for the two-sided and the total-order model. While the goal
is the same: to approximate the maximum weight matching using ordinal infor-
mation, this paper is diﬀerent from [4] in several aspects. [4] only considered
approximating the true maximum weight matching for non-bipartite complete
graphs. We instead focus on bipartite graphs, and especially on considering dif-
ferent levels of ordinal information by analyzing three models with increasing
amount of information, and also consider partial preferences. Although we use
similar techniques for parts of two-sided and total-order model analysis, they
need signiﬁcant adjustments to deal with bipartite graphs and partial prefer-
1 Note that many of the papers mentioned here speciﬁcally attempt to form truthful
algorithms. While RSD is certainly truthful, in this paper we attempt to quantify
what can be done using ordinal information in the presence of latent numerical
utilities, and leave questions of truthfulness to future work.

272
E. Anshelevich and W. Zhu
ences; moreover, the method used for analyzing the one-sided model is quite
diﬀerent from [4].
2
Model and Notation
For all the problems studied in this paper, we are given as input two sets of
agents X and Y with |X| = |Y| = N. G = (X, Y, E) is an undirected complete
bipartite graph with weights on the edges. We assume that the agent preferences
are derived from a set of underlying hidden edge weights w(x, y) for each edge
(x, y), x ∈X, y ∈Y. w(x, y) represents the utility of the match between x
and y, so if x prefers y1 to y2, then it must be that w(x, y1) ≥w(x, y2). Let
OPT(G) denote the complete bipartite matching that gives the maximum total
edge weights. w(G) of any bipartite graph G is the total edge weight of the graph,
and w(M) of any matching M is the total weight of edges in the matching.
The agents lie in a metric space, by which we will only mean that, ∀x1, x2 ∈
X, ∀y1, y2 ∈Y, w(x1, y1) ≤w(x1, y2) + w(x2, y1) + w(x2, y2). We assume this
property in all sections except for Sect. 6.
For the setting of one-sided preferences, ∀x ∈X, we are given a strict pref-
erence ordering Px over the agents in Y. When dealing with partial preferences,
only top αN agents in Px are given to us in order. We assume αN is an integer,
α ∈[0, 1]. Of course, when α = 0, nothing can be done except to form a com-
pletely random matching. For two-sided partial preferences, we are given both
the top α fraction of preferences Px of agents x in X over those in Y, and vice
versa. For the total order setting, we are given the order of the highest-weight
αN 2 edges in the complete bipartite graph G = (X, Y, E).
3
One-Sided Ordinal Preferences
For one-sided preferences, our problem becomes essentially a house allocation
problem to maximize social welfare, see e.g., [9,11,14]. Before we proceed, it
is useful to establish a baseline for what approximation factor is reasonable.
Simply picking a matching uniformly at random immediately results in a 3-
approximation (see Theorem 2), and there are examples showing that this bound
is tight. Other well-known algorithms, such as Top Trading Cycle, also cannot
produce better than a 3-approximation to the maximum weight matching for
our setting. Serial Dictatorship, which uses only one-sided ordinal information,
is also known to give a 3-approximation to the maximum weight matching for our
problem [13]. Serial Dictatorship simply takes an arbitrary agent from x ∈X,
assigns it x’s favorite unallocated agent from Y, and repeats. Unfortunately, it
is not diﬃcult to show that this bound of 3 is tight. Our ﬁrst major result in
this paper is to prove that Random Serial Dictatorship always gives a (
√
2 + 1)-
approximation in expectation, no matter what the true numerical weights are,
thus giving a signiﬁcant improvement to all the algorithms mentioned above.

Tradeoﬀs Between Information and Ordinal Approximation
273
Algorithm 1. Random Serial Dictatorship (RSD) Given bipartite graph G =
(X, Y, E), initialize a matching M = ∅. Pick an agent x uniformly at random
from X. Let y denote x’s most preferred agent in Y, take e = (x, y) from E and
add it to M. Remove x, y, and all edges containing x or y. Repeat until no agent
is left, return M.
Theorem 1. Suppose G = (X, Y, E) is a complete bipartite graph on the set
of nodes X, Y with |X| = |Y| = N. Then, the expected weight of the perfect
matching M returned by Algorithm 1 is E[w(M)] ≥
1
√
2+1w(OPT(G)).
Proof Sketch We give a proof sketch here; full proofs for all our results can be
found in the full version of this paper at http://www.cs.rpi.edu/∼eanshel/. Let
Min(G) denote a minimum weight perfect matching on G, and RSD(G) denote
the expected weight returned by Algorithm 1 on graph G. For any x ∈X, we
use λ(x) to denote the edge between x and its most preferred agent in Y. Deﬁne
R(x) as the remaining graph after removing x, x’s most preferred agent, and
all the edges containing x or x’s most preferred agent from G. We now state
the main technical lemma which allows us to prove the result. This lemma gives
a bound on the maximum weight matching in terms of the quantities deﬁned
above.
Lemma 1. For any given graph G = (X, Y, E), one of the following two cases
must be true:
Case 1: w(OPT(G)) ≤
1
|X|

x∈X w(OPT(R(x))) +
√
2+1
|X|

x∈X w(λ(x))
Case 2: w(OPT(G)) ≤(
√
2 + 1)w(Min(G))
We will prove this lemma below, but ﬁrst we discuss how the rest of the proof
proceeds. When Case 1 above holds, we know that at any step of the algorithm,
the change in the weight of the optimum solution in the remaining graph is not
that diﬀerent from the weight of the edge selected by our algorithm. This allows
us to compare the weight of OPT with the weight of the matching returned
by our algorithm. In fact, this is the technique used in a previous paper [5] to
analyze RSD for complete graphs (i.e., non-bipartite graphs), and show that
RSD gives a 2-approximation for perfect matching on complete graphs. It is
important to note here that this does not work for bipartite graphs. In bipartite
matching, there are examples in which using only this method will not give an
approximation ratio better than 3. We get around this problem by adding Case
2 to our lemma, and then using this to prove the theorem.
Proof Sketch of Lemma 1. For any ﬁxed x ∈X, denote x’s most preferred agent
in Y as y (so λ(x) = (x, y)). In OPT(G), suppose x is matched to b ∈Y, and
y is matched to a ∈X. In Min(G), suppose b is matched to m ∈X. ∀x ∈X,
there exist y, a, b, m as described above. Denote edge (x, y) by λ(x), (x, b) by
P(x), (a, y) by ¯P(x), and (a, b) by D(x).
We’ll prove Lemma 1 by showing that if Case 2 is not true, then Case 1 must
be true. Suppose Case 2 is not true, i.e., w(OPT(G)) > (
√
2 + 1)w(Min(G)).

274
E. Anshelevich and W. Zhu
Suppose that random serial dictatorship picks x ∈X. Then OPT(R(x)) is at
least as good as the matching obtained by removing P(x) and ¯P(x), and adding
D(x) to OPT(G) (the rest stay the same):
w(OPT(R(x))) ≥w(OPT(G)) −w(P(x)) −w( ¯P(x)) + w(D(x))
Summing this up over all nodes x, we obtain:
1
|X ′|

x∈X ′
w(OPT(R(x))) ≥(1 −
1
|X ′|)w(OPT(G)) −
1
|X ′|

x∈X ′
(w( ¯P(x)) −w(D(x)))
(1)
By the triangle inequality, we know that w(a, y) ≤w(a, b)+w(m, b)+w(m, y)
Because λ(m) is the edge to m’s most preferred agent, w(m, y) ≤w(λ(m)), and
thus w( ¯P(x)) ≤w(D(x)) + w(m, b) + w(λ(m))).
Summing this up for all x ∈X, note that each x is matched to a unique b in
OPT(G), and each b is matched to a unique m in Min(G), so each agent in Y
appears as b exactly once and each agent in X appears as m exactly once.

x∈X
(w( ¯P(x)) −w(D(x))) ≤w(Min(G)) +

x∈X
w(λ(x)))
(2)
Combining Inequalitys 1 and 2,
1
|X|

x∈X
w(OPT(R(x))) ≥(1−1
|X|)w(OPT(G))−1
|X|[w(Min(G))+

x∈X
w(λ(x))]
(3)
w(P(x)) ≤w(λ(x)) since λ(x) is the most preferred edge of x, so it is obvious
that w(OPT(G)) ≤
x∈X w(λ(x)). Combining this with our assumption about
Min(G), we obtain the desired result. For detailed proof, see the full version. ⊓⊔
Partial One-Sided Ordinal Preferences
In this section, we consider the case when we are given even less information
than in the previous one, i.e., only partial preferences. We begin by establishing
the following easy result for the completely random algorithm.
Theorem 2. The uniformly random perfect matching is a 3-approximation to
the maximum-weight matching.
Algorithm 2. Run Algorithm 1, stop when |M| = αN, then form random
matches until all agents are matched. Return M.
Theorem 3. Suppose G = (X, Y, E) is a complete bipartite graph on the set of
nodes X, Y with |X| = |Y| = N. There is a strict preference ordering Px over
the agents in Y for each agent x ∈X. We are only given top αN agents in
Px in order. Then, the expected weight of the perfect matching M returned by
Algorithm 2 is E[w(M)] ≥
1
3−(2−
√
2)αw(OPT(G)), as shown in Fig. 1.

Tradeoﬀs Between Information and Ordinal Approximation
275
Proof Sketch. We establish a linear tradeoﬀas α increases. Note that this would
not work for combining any two arbitrary algorithms. The key insight which
makes this proof work is that, at every step, the expected weight of RSD is
higher than in the following step, and that RSD always produces an edge weight
which is better than random in expectation.
⊓⊔
4
Two-Sided Ordinal Preferences
For two-sided preferences, we give separate algorithms for the cases when α ≥1
2
and when α ≤1
2, as these require somewhat diﬀerent techniques.
α ≥1
2 While for the case when α < 1
2 new techniques are necessary to obtain
a good approximation, the approach for the case when α ≥1
2 is essentially the
same as the one used in [4]. We adopt this approach to deal with bipartite graphs
and with partial preferences, giving us a 1.8-approximation for α = 1. To do this,
we re-state the deﬁnition of Undominated Edges from [4], and a standard greedy
algorithm for forming a matching of size k.
Deﬁnition 1. (Undominated Edges) Given a set E of edges, (x, y) ∈E is said
to be an undominated edge if for all (x, a) and (y, b) in E, w(x, y) ≥w(x, a) and
w(x, y) ≥w(y, b).
Note that an undominated edge must always exist: either there are two nodes
x and y such that they are each other’s top preferences (and so (x, y) is undom-
inated), or there is a cycle x1, x2, . . . in which xi+1 is the top preference of xi,
in which case all edges in the cycle must be the same weight, and thus all edges
in the cycle are undominated. This also gives us an algorithm for determining
if an edge (x, y) is undominated: either x and y prefer each other over all other
agents, or it is part of such a cycle of top preferences.
Algorithm 3 (Undominated Greedy). Given bipartite graph G = (X, Y, E),
initialize a matching M = ∅. Pick an arbitrary undominated edge e = (x, y) from
E and add it to M. Remove x, y, and all edges containing x or y from E. Repeat
until |M| = k. Return M.
Algorithm 4. Given bipartite graph G = (X, Y, E), and top αN of P(X), top
αN of P(Y). Let M0 be the output returned by Algorithm 3 for E, k = αN.
Let M1 = M0∪(Uniformly random matching on the rest of the agents). We get
M2 in the following way: randomly choose (2α −1)N edges from M0 that stay
matched, and unmatch all other agents in M0. Then form a random bipartite
matching between all the agents which were not matched in M0, and the nodes
which we chose from M0 to become unmatched. Return M1 with probability
3−2α
3−α and M2 with probability
α
3−α.
Note that for α > 3
4 this algorithm does not seem to provide better guarantees
than for α = 3
4. Because of this, for α > 3
4, we simply run the same algorithm
for α = 3
4.

276
E. Anshelevich and W. Zhu
Theorem 4. Algorithm
4
returns
a
(3−2α)(3−α)
2α2−3α+3 -approximation
to
the
maximum-weight perfect matching given two-sided ordering when 1
2 ≤α ≤3
4.
α ≤1
2 Unlike the case for α ≥1
2, this case requires diﬀerent techniques than in
[4]. While the techniques above would still work, they will not give us a bound as
good as the one we form below. The idea in this section is to do something similar
to our one-sided algorithm for partial preferences: run the greedy algorithm for
a while, and then switch to random. Unfortunately, if we simply run the greedy
Algorithm 3 and then switch to random, this will not form a good approximation.
The reason why this is true is that an undominated edge which is picked by the
greedy algorithm may be much worse than the average weight of an edge, and
so the approximation factor of the random algorithm will dominate, giving only
a 3-approximation. Even taking an undominated edge uniformly at random has
this problem. We can ﬁx this, however, by picking each undominated edge with
an appropriate probability, as described below. Such an algorithm results in
matchings which are guaranteed to be better than either RSD or Random, thus
allowing us to prove the result.
Algorithm 5. Given bipartite graph G = (X, Y, E), and top αN of P(X),
top αN of P(Y). Pick an agent x uniformly at random from X, let x’s most
preferred agent be y in Y. We choose an undominated edge by the following
method: if (x, y) is an undominated edge, take it and continue to pick the next
agent. Otherwise check whether the edge between y and its most preferred node
is undominated, keep doing this until we ﬁnd an undominated edge (x1, y1) and
add it to M. Remove x1, y1, and all edges containing x1 or y1. Repeat until
|M| = αN. Form a uniformly random matching for the remaining graph G, add
the edges returned by the algorithm to M, and return M.
This algorithm guarantees that an undominated edge is chosen for any x in
any bipartite graph G. Now, before we reach an undominated edge, the weights
of edges are non-decreasing in the order they are checked. Thus whenever a node
x is picked, the algorithm adds an undominated edge (x1, y1) to the matching
which is guaranteed to have higher weight than all edges leaving x.
Theorem 5. Algorithm 5 returns a (3 −α)-approximation to the maximum-
weight perfect matching given two-sided ordering when 0 ≤α ≤1
2.
Proof Sketch. We use a similar method and the same notation as in Sect. 3
to proof this theorem. Essentially, because we are always picking undominated
edges, we can form a linear interpolation between a factor of 2 and a factor of 3
for random matching, instead of between factors
√
2 + 1 and 3 as for one-sided
preferences. The reason why we are able to form such an interpolation is entirely
because of the probabilities with which we choose the undominated edges; if we
simply chose arbitrary undominated edges or choose them uniformly at random,
then there are examples where the random edge weights will dominate and result
in a poor approximation, since undominated edges are only guaranteed to be
within a factor of 3 of the average edge weight.
⊓⊔

Tradeoﬀs Between Information and Ordinal Approximation
277
5
Total Ordering of Edge Weights
For the setting in which we are given the top αN 2 edges of G in order, we prove
that for α = 3
4, we can obtain an approximation of 5
3 in expectation. For larger
α, however, more information does not seem to help, and so we simply use the
algorithm for α = 3
4 for any α > 3
4.
Algorithm 6. Given bipartite graph G = (X, Y, E), initialize a matching M =
∅. Pick the heaviest edge e = (x, y) from E and add it to M. Remove x, y, and
all edges containing x or y from E. Repeat until |M| = k. Return M.
The algorithm for bipartite matching with partial ordinal information is sim-
ilar to that with partial two-sided ordinal information, except that we only need
to consider the case that k ≤1
2N, α ≤3
4.
Algorithm 7. Given bipartite graph G = (X, Y, E), and order of the top αN 2
edges in the graph. Let M0 be the output returned by Algorithm 6 for E, k =
(1 −√1 −α)N. Let M1 = M0∪(Uniformly random matching on the rest of the
agents). We get M2 in the following way: let B denote the complete bipartite
graph on the set of nodes not matched in M0. Randomly choose (2√1 −α−1)N
nodes from both sets of agents in B, get the perfect matching output by random
Algorithm and add to M2, then unmatched all agents in M0, form a random
bipartite matching between agents in M0 and the agents not chosen in B and add
to M2. Return M1 with probability
2
2+√1−α and M2 with probability
√1−α
2+√1−α.
Theorem 6. Algorithm 7 returns a
2+√1−α
2−√1−α-approximation to the maximum-
weight matching in expectation for α ≤3
4, as shown in Fig. 1.
6
One-Sided Preferences with Restricted Edge Weights
In previous sections, we made the assumption that the agents lie in a metric
space, and thus the edge weights, although unknown to us, must follow the
triangle inequality. In this section we once again consider the most restrictive
type of agent preferences—that of one-sided preferences—but now instead of
assuming that agents lie in a metric space, we instead consider settings where
edges weights cannot be inﬁnitely diﬀerent from each other. This applies to
settings where the agents are at least somewhat indiﬀerent and the items are
somewhat similar; the least-preferred agent and the most-preferred items diﬀer
only by a constant factor to any agent. Indeed, when for example purchasing a
house in a reasonable market (i.e., once houses that almost no one would buy
have been removed from consideration), it is unlikely that any agent would like
house x so much more than house y that they would be willing to pay hundreds
of times more for x than for y.
More formally, for each agent i ∈X, we are given a strict preference ordering
Pi over the agents in Y. In this section we assume that the highest weight edge
emax is at most β times of the lowest weight edge emin. We normalize the lowest

278
E. Anshelevich and W. Zhu
weight edge emin in the graph to w(emin) = 1; then for any edge e ∈E, w(e) ≤β.
We use similar analysis as in Sect. 3, except that instead of getting bounds by
using the triangle inequality, the relationships among edge weights are bounded
by our assumption of the highest and lowest weight edge ratio. As stated above,
we no longer assume the agents lie in a metric space in this section.
Theorem 7. Suppose G = (X, Y, E) is a complete bipartite graph on the set
of nodes X, Y with |X| = |Y| = N. w(emin) = 1, ∀e ∈E, w(e) ≤β. The
expected weight of the perfect matching returned by Algorithm 1 is w(M) ≥
1
√
β−3
4 + 1
2
w(OPT) (see plot and proof in the full version).
References
1. Abdulkadiro˘glu, A., S¨onmez, T.: Random serial dictatorship and the core from
random endowments in house allocation problems. Econometrica 66(3), 689–701
(1998)
2. Abraham, D.J., Irving, R.W., Kavitha, T., Mehlhorn, K.: Popular matchings.
SIAM J. Comput. 37(4), 1030–1045 (2007)
3. Anshelevich, E., Bhardwaj, O., Postl, J.: Approximating optimal social choice
under metric preferences. In: AAAI (2015)
4. Anshelevich, E., Sekar, S.: Blind, greedy, and random: algorithms for matching and
clustering using only ordinal information. In: AAAI (2016)
5. Anshelevich, E., Sekar, S.: Truthful mechanisms for matching and clustering in an
ordinal world. In: Cai, Y., Vetta, A. (eds.) WINE 2016. LNCS, vol. 10123, pp.
265–278. Springer, Heidelberg (2016). doi:10.1007/978-3-662-54110-4 19
6. Bhalgat, A., Chakrabarty, D., Khanna, S.: Social welfare in one-sided matching
markets without money. In: Goldberg, L.A., Jansen, K., Ravi, R., Rolim, J.D.P.
(eds.) APPROX/RANDOM -2011. LNCS, vol. 6845, pp. 87–98. Springer, Heidel-
berg (2011). doi:10.1007/978-3-642-22935-0 8
7. Caragiannis, I., Filos-Ratsikas, A., Frederiksen, S.K.S., Hansen, K.A., Tan, Z.:
Truthful facility assignment with resource augmentation: an exact analysis of serial
dictatorship. In: Cai, Y., Vetta, A. (eds.) WINE 2016. LNCS, vol. 10123, pp. 236–
250. Springer, Heidelberg (2016). doi:10.1007/978-3-662-54110-4 17
8. Chakrabarty, D., Swamy, C.: Welfare maximization and truthfulness in mechanism
design with ordinal preferences. In: ITCS (2014)
9. Christodoulou, G., Filos-Ratsikas, A., Frederiksen, S.K.S., Goldberg, P.W., Zhang,
J., Zhang, J.: Social welfare in one-sided matching mechanisms. In: Osman, N.,
Sierra, C. (eds.) AAMAS 2016. LNCS (LNAI), vol. 10002, pp. 30–50. Springer,
Cham (2016). doi:10.1007/978-3-319-46882-2 3
10. Feldman, M., Fiat, A., Golomb, I.: On voting and facility location. In: EC (2016)
11. Filos-Ratsikas, A., Frederiksen, S.K.S., Zhang, J.: Social welfare in one-sided
matchings: random priority and beyond. In: Lavi, R. (ed.) SAGT 2014. LNCS,
vol. 8768, pp. 1–12. Springer, Heidelberg (2014). doi:10.1007/978-3-662-44803-8 1
12. Goel, A., Krishnaswamy, A.K., Munagala, K.: Metric distortion of social choice
rules: lower bounds and fairness properties. In: EC (2017)
13. Kalyanasundaram, B., Pruhs, K.: On-line weighted matching. In: SODA, vol. 91,
pp. 234–240 (1991)
14. Krysta, P., Manlove, D., Rastegari, B., Zhang, J.: Size versus truthfulness in the
house allocation problem. In: EC (2014)

Tradeoﬀs Between Information and Ordinal Approximation
279
15. Rastegari, B., Condon, A., Immorlica, N., Leyton-Brown, K.: Two-sided matching
with partial information. In: EC (2013)
16. Roth, A.E., Sotomayor, M.: Two-sided matching. Handb. Game Theory Econ.
Appl. 1, 485–541 (1992)
17. Skowron, P., Elkind, E.: Social choice under metric preferences: scoring rules and
STV. In: AAAI (2017)

Group Strategyproof Pareto-Stable Marriage
with Indiﬀerences via the Generalized
Assignment Game
Nevzat Onur Domani¸c(B), Chi-Kit Lam(B), and C. Gregory Plaxton(B)
University of Texas at Austin, Austin, TX 78712, USA
{onur,geocklam,plaxton}@cs.utexas.edu
Abstract. We study the variant of the stable marriage problem in which
the preferences of the agents are allowed to include indiﬀerences. We
present a mechanism for producing Pareto-stable matchings in stable
marriage markets with indiﬀerences that is group strategyproof for one
side of the market. Our key technique involves modeling the stable mar-
riage market as a generalized assignment game. We also show that our
mechanism can be implemented eﬃciently. These results can be extended
to the college admissions problem with indiﬀerences.
1
Introduction
The stable marriage problem was ﬁrst introduced by Gale and Shapley [13]. The
stable marriage market involves a set of men and women, where each agent has
ordinal preferences over the agents of the opposite sex. The goal is to ﬁnd a dis-
joint set of man-woman pairs, called a matching, such that no other man-woman
pair prefers each other to their partners in the matching. Such matchings are said
to be stable. When preferences are strict, a unique man-optimal stable matching
exists and can be computed by the man-proposing deferred acceptance algo-
rithm of Gale and Shapley [13]. A mechanism is said to be group strategyproof
for the men if no coalition of men can be simultaneously matched to strictly pre-
ferred partners by misrepresenting their preferences. Dubins and Freedman [8]
show that the mechanism that produces man-optimal matchings is group strate-
gyproof for the men when preferences are strict. In our work, we focus on group
strategyproofness for the men, since no stable mechanism is strategyproof for
both men and women [19].
We remark that the notion of group strategyproofness used here assumes
no side payments within the coalition of men. It is known that group strat-
egyproofness for the men is impossible for the stable marriage problem with
strict preferences when side payments are allowed [21, Chap. 4]. This notion of
group strategyproofness is also diﬀerent from strong group strategyproofness,
in which at least one man in the coalition gets matched to a strictly preferred
partner while the other men in the coalition get matched to weakly preferred
This research was supported by NSF Grant CCF–1217980.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 280–291, 2017.
DOI: 10.1007/978-3-319-66700-3 22

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
281
partners. It is known that strong group strategyproofness for the men is impos-
sible for the stable marriage problem with strict preferences [8, attributed to
Gale].
Indiﬀerences in the preferences of agents arise naturally in real-world applica-
tions such as school choice [1,10,11]. For the marriage problem with indiﬀerences,
Sotomayor [24] argues that Pareto-stability is an appropriate solution concept.
A matching is said to be weakly stable if no man-woman pair strictly prefers each
other to their partners in the matching. A matching is said to be Pareto-optimal
if there is no other matching that is strictly preferred by some agent and weakly
preferred by all agents. If a matching is both weakly stable and Pareto-optimal,
it is said to be Pareto-stable.
Weakly stable matchings, unlike strongly stable or super-stable match-
ings [14], always exist. However, not all weakly stable matchings are Pareto-
optimal [24]. Pareto-stable matchings can be obtained by applying successive
Pareto-improvements to weakly stable matchings. Erdil and Ergin [10,11] show
that this procedure can be carried out eﬃciently. Pareto-stable matchings also
exist and can be computed in strongly polynomial time for many-to-many match-
ings [2] and multi-unit matchings [3]. Instead of using the characterization of
Pareto-improvement chains and cycles, Kamiyama [15] gives another eﬃcient
algorithm for many-to-many matchings based on rank-maximal matchings. How-
ever, none of these mechanisms addresses strategyproofness.
We remark that the notion of Pareto-optimality here is diﬀerent from man-
Pareto-optimality, which only takes into account the preferences of the men. It
is known that man-Pareto-optimality is not compatible with strategyproofness
for the stable marriage problem with indiﬀerences [10,16]. The notion of Pareto-
optimality here is also diﬀerent from Pareto-optimality in expected utility, which
permits Pareto-domination by non-pure outcomes. A result of Zhou [25] implies
that Pareto-optimality in expected utility is not compatible with strategyproof-
ness for the stable marriage problem with indiﬀerences.
Until recently, it was not known whether a strategyproof Pareto-stable mech-
anism exists. In our recent workshop paper [7], we present a generalization of
the deferred acceptance mechanism that is Pareto-stable and strategyproof for
the men. If the market has n agents, our implementation of this mechanism
runs in O(n4) time, matching the time bound of the algorithm of Erdil and
Ergin [10,11]1. The proof of strategyproofness relies on reasoning about a cer-
tain threshold concept in the stable marriage market, and this approach seems
diﬃcult to extend to address group strategyproofness.
In this paper, we introduce a new technique useful for investigating incentive
compatibility for coalitions of men. We present a Pareto-stable mechanism for the
stable marriage problem with indiﬀerences that is provably group strategyproof
1 The algorithm of Erdil and Ergin proceeds in two phases. In the ﬁrst phase, ties are
broken arbitrarily and the deferred acceptance algorithm is used to obtain a weakly
stable matching. In the second phase, a sequence of Pareto-improvements are applied
until a Pareto-stable matching is reached. In App. A in the full version of [7], we
show that this algorithm does not provide a strategyproof mechanism.

282
N.O. Domani¸c et al.
for the men, by modeling the stable marriage market as an appropriate form of
the generalized assignment game. In Sect. 4 and the full version [6, App. B and C]
of this paper, we show that this mechanism coincides with the generalization of
the deferred acceptance mechanism presented in [7]. Thus we obtain an O(n4)-
time group strategyproof Pareto-stable mechanism.
The Generalized Assignment Game. The assignment game, introduced by
Shapley and Shubik [22], involves a two-sided matching market with monetary
transfer in which agents have unit-slope linear utility functions. This model has
been generalized to allow agents to have continuous, invertible, and increasing
utility functions [4,5,18]. Some models that generalize both the assignment game
and the stable marriage problems have also been developed, but their models
are not concerned with the strategic behavior of agents [12,23]. The formulation
of the generalized assignment game in this paper follows the presentation of
Demange and Gale [5].
In their paper, Demange and Gale establish various elegant properties of
the generalized assignment game, such as the lattice property and the exis-
tence of one-sided optimal outcomes. (One-sided optimality or man-optimality
is a stronger notion than one-sided Pareto-optimality or man-Pareto-optimality.)
These properties are known to hold for the stable marriage market in the case
of strict preferences [17, attributed to Conway], but fail in the case of weak pref-
erences [21, Chap. 2]. Given the similarities between stable marriage markets
and generalized assignment games, it is natural to ask whether stable marriage
markets can be modeled as generalized assignment games. Demange and Gale
discuss this question and state that “the model of [Gale and Shapley] is not a
special case of our model”. The basic obstacle is that it is unclear how to model
an agent’s preferences within the framework of a generalized assignment game:
on the one hand, even though ordinal preferences can be converted into numeric
utility values, such preferences are expressed in a manner that is independent of
any monetary transfer; on the other hand, the framework demands that there
is an amount of money that makes an agent indiﬀerent between any two agents
on the other side of the market.
In Sect. 2, we review key concepts in the work of Demange and Gale, and
introduce the tiered-slope market as a special form of the generalized assignment
game in which the slopes of the utility functions are powers of a large ﬁxed num-
ber. Then, in Sect. 3, we describe our approach for converting a stable marriage
market with indiﬀerences into an associated tiered-slope market. While these are
both two-sided markets that involve the same set of agents, the utilities achieved
under an outcome in the associated tiered-slope market may not be equal to the
utilities under a corresponding solution in the stable marriage market. Neverthe-
less, we are able to establish useful relationships between certain sets of solutions
to these two markets.
Our ﬁrst such result, Theorem 2, shows that Pareto-stability in the stable
marriage market with indiﬀerences follows from stability in the associated tiered-
slope market, even though it does not follow from weak stability in the stable
marriage market with indiﬀerences. This can be seen as a partial analogue to

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
283
the case of strict preferences, in which stability in the stable marriage market
implies Pareto-stability [13]. This also demonstrates that, in addition to using
the deferred acceptance procedure to solve the generalized assignment game [4],
we can use the generalized assignment game to solve the stable marriage problem
with indiﬀerences.
In Lemma 5, we establish that the utility achieved by any man in a man-
optimal solution to the associated tiered-slope market uniquely determines the
tier of preference to which that man is matched in the stable marriage market
with indiﬀerences. Another consequence of this lemma is that any matched man
in a man-optimal outcome of the associated tiered-slope market receives at least
one unit of money from his partner. We can then deduce that if a man strictly
prefers his partner to a woman, then the woman has to oﬀer a large amount of
money in order for the man to be indiﬀerent between her oﬀer and that of his
partner. Since individual rationality prevents any woman from oﬀering such a
large amount of money, this explains how we overcome the obstacle of any man
being matched with a less preferred woman in exchange for a suﬃciently large
payment.
A key result established by Demange and Gale is that the man-optimal mech-
anism is group strategyproof for the men. Using this result and Lemma 5, we
are able to show in Theorem 3 that group strategyproofness for the men in
the stable marriage market with indiﬀerences is achieved by man-optimality in
the associated tiered-slope market, even though it is incompatible with man-
Pareto-optimality in the stable marriage market with indiﬀerences [10,16]. This
can be seen as a partial analogue to the case of strict preferences, in which
man-optimality implies group strategyproofness [8].
Extending to the College Admissions Problem. We also consider the set-
tings of incomplete preference lists and one-to-many matchings, in which eﬃ-
cient Pareto-stable mechanisms are known to exist [2,3,10,11,15]. Preference
lists are incomplete when an agent declares another agent of the opposite sex to
be unacceptable. Our mechanism is able to support such incomplete preference
lists through an appropriate choice of the reserve utilities of the agents in the
associated tiered-slope market. In fact, our mechanism also supports indiﬀerence
between being unmatched and being matched to some partner.
The one-to-many variant of the stable marriage problem with indiﬀerences
is the college admissions problem with indiﬀerences. In this model, students and
colleges play the roles of men and women, respectively, and colleges are allowed
to be matched with multiple students, up to their capacities. We provide the
formal deﬁnition of the model in the full version [6, App. D] of this paper. By
a simple reduction from college admissions markets to stable marriage markets,
our mechanism is group strategyproof for the students2 and produces a Pareto-
stable matching in polynomial time.
2 A stable mechanism can be strategyproof only for the side having unit demand,
namely the students [20].

284
N.O. Domani¸c et al.
Organization of this Paper. In Sect. 2, we review the generalized assignment
game and deﬁne the tiered-slope market. In Sect. 3, we introduce the tiered-
slope markets associated with the stable marriage markets with indiﬀerences,
and use them to obtain a group strategyproof, Pareto-stable mechanism. In
Sect. 4 and the full version [6, App. B and C] of this paper, we discuss eﬃcient
implementations of the mechanism and its relationship with the generalization
of the deferred acceptance algorithm presented in [7]. Due to space limitations,
some of the proofs are omitted from this paper. See the full version [6] for all of
the proof details.
2
Tiered-Slope Market
The generalized assignment game studied by Demange and Gale [5] involves two
disjoint sets I and J of agents, which we call men and women respectively. We
assume that the sets I and J do not contain the element 0, which we use to denote
being unmatched. For each man i ∈I and woman j ∈J, the compensation
function fi,j(ui) represents the compensation that man i needs to receive in
order to attain utility ui when he is matched to woman j. Similarly, for each
man i ∈I and woman j ∈J, the compensation function gi,j(vj) represents the
compensation that woman j needs to receive in order to attain utility vj when
she is matched to man i. Moreover, each man i ∈I has a reserve utility ri and
each woman j ∈J has a reserve utility sj.
In this paper, we assume that the compensation functions are of the form
fi,j(ui) = uiλ−ai,j
and
gi,j(vj) = vj −(bi,jN + πi)
and the reserve utilities are of the form
ri = πiλai,0
and
sj = b0,jN,
where
π ∈ZI;
N ∈Z;
λ ∈Z;
a ∈ZI×(J∪{0});
b ∈Z(I∪{0})×J
such that N > max
i∈I πi ≥min
i∈I πi ≥1 and
λ ≥
max
(i,j)∈(I∪{0})×J(bi,j + 1)N ≥
min
(i,j)∈(I∪{0})×J(bi,j + 1)N ≥N.
We denote this tiered-slope market as M = (I, J, π, N, λ, a, b). When ai,j = 0
for every man i ∈I and woman j ∈J ∪{0}, this becomes a unit-slope market
(I, J, π, N, λ, 0, b). Notice that the compensation functions in a unit-slope mar-
ket coincide with those in the assignment game [22] where buyer j ∈J has a
valuation of bi,jN + πi on house i ∈I. For better readability, we write expλ(ξ)
to denote λξ.

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
285
A matching is a function μ: I →J ∪{0} such that for any woman j ∈J,
we have μ(i) = j for at most one man i ∈I. Given a matching μ and a woman
j ∈J, we denote
μ(j) =

i
if μ(i) = j
0
if there is no man i ∈I such that μ(i) = j
An outcome is a triple (μ, u, v), where μ is a matching, u ∈RI is the utility vector
of the men, and v ∈RJ is the utility vector of the women. An outcome (μ, u, v)
is feasible if the following conditions hold for every man i ∈I and woman j ∈J.
1. If μ(i) = j, then fi,j(ui) + gi,j(vj) ≤0.
2. If μ(i) = 0, then ui = ri.
3. If μ(j) = 0, then vj = sj.
A feasible outcome (μ, u, v) is individually rational if ui ≥ri and vj ≥sj for
every man i ∈I and woman j ∈J. An individually rational outcome (μ, u, v) is
stable if fi,j(ui) + gi,j(vj) ≥0 for every man i ∈I and woman j ∈J.
A stable outcome (μ, u, v) is man-optimal if for any stable outcome (μ′, u′, v′)
we have ui ≥u′
i for every man i ∈I. It has been shown that man-optimal
outcomes always exist [5, Property 2]. Theorem 1 below provides a useful group
strategyproofness result for man-optimal outcomes.
Theorem 1. Let (μ, u, v) and (μ′, u′, v′) be man-optimal outcomes of tiered-
slope markets (I, J, π, N, λ, a, b) and (I, J, π, N, λ, a′, b), respectively. If a ̸= a′,
then there exists a man i0 ∈I and a woman j0 ∈J ∪{0} with ai0,j0 ̸= a′
i0,j0
such that ui0 ≥u′
i0 expλ(ai0,μ′(i0) −a′
i0,μ′(i0)).
Proof. This follows directly from [5, Theorem 2], which establishes group strat-
egyproofness for the men in the generalized assignment game with no side pay-
ments. Notice that the value u′
i0 expλ(ai0,μ′(i0) −a′
i0,μ′(i0)) is the true utility of
man i0 under matching μ′ as deﬁned in their paper, both in the case of being
matched to μ′(i0) ̸= 0 with compensation u′
i0 expλ(−a′
i0,μ′(i0)) and in the case
of being unmatched.
⊓⊔
3
Stable Marriage with Indiﬀerences
The stable marriage market involves a set I of men and a set J of women. We
assume that the sets I and J are disjoint and do not contain the element 0,
which we use to denote being unmatched. The preference relation of each man
i ∈I is speciﬁed by a binary relation ⪰i over J ∪{0} that satisﬁes transitivity
and totality. To allow indiﬀerences, the preference relation is not required to
satisfy anti-symmetry. Similarly, the preference relation of each woman j ∈J
is speciﬁed by a binary relation ⪰j over I ∪{0} that satisﬁes transitivity and
totality. We denote this stable marriage market as (I, J, (⪰i)i∈I, (⪰j)j∈J).

286
N.O. Domani¸c et al.
A matching is a function μ: I →J ∪{0} such that for any woman j ∈J,
we have μ(i) = j for at most one man i ∈I. Given a matching μ and a woman
j ∈J, we denote
μ(j) =

i
if μ(i) = j
0
if there is no man i ∈I such that μ(i) = j
A matching μ is individually rational if j ⪰i 0 and i ⪰j 0 for every man i ∈I and
woman j ∈J such that μ(i) = j. An individually rational matching μ is weakly
stable if for any man i ∈I and woman j ∈J, either μ(i) ⪰i j or μ(j) ⪰j i.
(Otherwise, such a man i and woman j form a strongly blocking pair.)
For any matchings μ and μ′, we say that the binary relation μ ⪰μ′ holds if
μ(i) ⪰i μ′(i) and μ(j) ⪰j μ′(j) for every man i ∈I and woman j ∈J. A weakly
stable matching μ is Pareto-stable if for any matching μ′ such that μ′ ⪰μ, we
have μ ⪰μ′. (Otherwise, the matching μ is not Pareto-optimal because it is
Pareto-dominated by the matching μ′.)
A mechanism is an algorithm that, given a stable marriage market (I, J,
(⪰i)i∈I, (⪰j)j∈J), produces a matching μ. A mechanism is said to be group
strategyproof (for the men) if for any two diﬀerent preference proﬁles (⪰i)i∈I
and (⪰′
i)i∈I, there exists a man i0 ∈I with preference relation ⪰i0 diﬀerent from
⪰′
i0 such that μ(i0) ⪰i0 μ′(i0), where μ and μ′ are the matchings produced by
the mechanism given (I, J, (⪰i)i∈I, (⪰j)j∈J) and (I, J, (⪰′
i)i∈I, (⪰j)j∈J) respec-
tively. (Such a man i0 belongs to the coalition but is not matched to a strictly
preferred woman by expressing preference relation ⪰′
i0 instead of his true pref-
erence relation ⪰i0.)
3.1
The Associated Tiered-Slope Market
We construct the tiered-slope market M = (I, J, π, N, λ, a, b) associated with
stable marriage market (I, J, (⪰i)i∈I, (⪰j)j∈J) as follows. We take N ≥|I| + 1
and associate with each man i ∈I a ﬁxed and distinct priority πi ∈{1, 2, . . . , |I|}.
We convert the preference relations (⪰i)i∈I of the men to integer-valued (non-
transferable) utilities a ∈ZI×(J∪{0}) such that for every man i ∈I and women
j1, j2 ∈J ∪{0}, we have j1 ⪰i j2 if and only if ai,j1 ≥ai,j2. Similarly, we
convert the preference relations (⪰j)j∈J of the women to integer-valued (non-
transferable) utilities b ∈Z(I∪{0})×J such that for every woman j ∈J and men
i1, i2 ∈I ∪{0}, we have i1 ⪰j i2 if and only if bi1,j ≥bi2,j ≥1. Finally, we take
λ =
max
i∈I∪{0}
j∈J
(bi,j + 1)N.
In order to achieve group strategyproofness, we require that N and π should
not depend on the preferences (⪰i)i∈I of the men. We further require that b
does not depend on the preferences (⪰i)i∈I of the men, and that ai0,j0 does not
depend on the other preferences (⪰i)i∈I\{i0} for any man i0 ∈I and woman
j0 ∈J ∪{0}. In other words, a man i0 ∈I is only able to manipulate his own

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
287
utilities (ai0,j)j∈J∪{0}. One way to satisfy these conditions is by taking ai0,j0 to
be the number of women j ∈J ∪{0} such that j0 ⪰i0 j for every man i0 ∈I and
woman j0 ∈J ∪{0}, and taking bi0,j0 to be the number of men i ∈I ∪{0} such
that i0 ⪰j0 i for every man i0 ∈I ∪{0} and woman j0 ∈J. (These conditions
are not used until Sect. 3.3, where we prove group strategyproofness.)
Intuitively, each woman has a compensation function with the same form as
a buyer in the assignment game [22]. The valuation bi,jN + πi that woman j
assigns to man i has a ﬁrst-order dependence on the preferences over the men
and a second-order dependence on the priorities of the men, which are used to
break any ties in her preferences. From the perspective of man i, if he highly
prefers a woman j, he assigns a large exponent ai,j in the slope associated with
woman j, and thus expects only a small amount of compensation.
3.2
Pareto-Stability
In this subsection, we study the Pareto-stability of matchings in the stable mar-
riage market that correspond to stable outcomes in the associated tiered-slope
market. We ﬁrst show that individual rationality in the associated tiered-slope
market implies individual rationality in the stable marriage market (Lemmas 1
and 2). Then, we show that stability in the associated tiered-slope market implies
weak stability in the stable marriage market (Lemma 3). Finally, we show that
stability in the associated tiered-slope market is suﬃcient for Pareto-stability in
the stable marriage market (Lemma 4 and Theorem 2). The proof of Lemma 4
is given in [6, App. A].
Lemma 1. Let (μ, u, v) be an individually rational outcome in tiered-slope mar-
ket M = (I, J, π, N, λ, a, b). Let i ∈I be a man and j ∈J be a woman. Then
0 < expλ(ai,0) ≤ui < expλ(ai,μ(i) +1)
and
0 ≤b0,jN ≤vj < (bμ(j),j +1)N.
Proof. The lower bounds
ui ≥πi expλ(ai,0) ≥expλ(ai,0) > 0
and
vj ≥b0,jN ≥0
follow directly from individual rationality. If μ(i) = 0, then feasibility implies
ui = πi expλ(ai,0) < expλ(ai,0 + 1). If μ(j) = 0, then feasibility implies vj =
b0,jN < (b0,j + 1)N. It remains to show that the upper bounds hold when
μ(i) ̸= 0 and μ(j) ̸= 0. Without loss of generality, we may assume that μ(i) = j,
so feasibility implies
ui expλ(−ai,j) −(bi,jN + πi −vj) ≤0.
Since ui ≥0 and vj ≥0, we have
ui expλ(−ai,j) −(bi,jN + πi) ≤0
and
−(bi,jN + πi −vj) ≤0.
Since πi < N and bi,jN + πi < λ, we have
ui expλ(−ai,j) −λ < 0
and
−(bi,jN + N −vj) < 0.
Thus ui < expλ(ai,μ(i) + 1) and vj < (bμ(j),j + 1)N.
⊓⊔

288
N.O. Domani¸c et al.
Lemma 2 (Individual Rationality). Let (μ, u, v) be an individually rational
outcome in the tiered-slope market M = (I, J, π, N, λ, a, b) associated with sta-
ble marriage market (I, J, (⪰i)i∈I, (⪰j)j∈J). Then μ is an individually rational
matching in the stable marriage market.
Proof. Let i ∈I be a man and j ∈J be a woman. Then, by Lemma 1, we have
expλ(ai,0) < expλ(ai,μ(i) + 1)
and
b0,jN < (bμ(j),j + 1)N.
Thus ai,μ(i) + 1 > ai,0 and bμ(j),j + 1 > b0,j, and hence ai,μ(i) ≥ai,0 and
bμ(j),j ≥b0,j. We conclude that μ(i) ⪰i 0 and μ(j) ⪰j 0.
⊓⊔
Lemma 3 (Stability).
Let (μ, u, v) be a stable outcome in the tiered-slope
market M = (I, J, π, N, λ, a, b) associated with stable marriage market (I, J,
(⪰i)i∈I, (⪰j)j∈J). Then μ is a weakly stable matching in the stable marriage
market.
Proof. Since the outcome (μ, u, v) is individually rational in market M, Lemma 2
implies that the matching μ is individually rational in the stable marriage mar-
ket. It remains to show that there is no strongly blocking pair.
For the sake of contradiction, suppose there exists a man i ∈I and a woman
j ∈J such that neither μ(i) ⪰i j nor μ(j) ⪰j i. Then ai,j > ai,μ(i) and bi,j >
bμ(j),j. Hence ai,j ≥ai,μ(i) + 1 and bi,j ≥bμ(j),j + 1. Since (μ, u, v) is a stable
outcome in M, we have
0 ≤ui expλ(−ai,j) −(bi,jN + πi −vj)
< expλ(ai,μ(i) + 1) expλ(−ai,j) −(bi,jN + πi −(bμ(j),j + 1)N)
≤1 −πi,
where the second inequality follows from Lemma 1. Thus, πi < 1, a contradiction.
⊓⊔
Lemma 4. Let (μ, u, v) be a stable outcome in the tiered-slope market M =
(I, J, π, N, λ, a, b). Let μ′ be an arbitrary matching. Then

i∈I

ui expλ(−ai,μ′(i)) −πi

≥

j∈J

bμ′(j),jN −vj

.
Furthermore, the inequality is tight if and only if the outcome (μ′, u, v) is stable.
Theorem 2 (Pareto-stability). Let (μ, u, v) be a stable outcome in the tiered-
slope market M = (I, J, π, N, λ, a, b) associated with stable marriage market
(I, J, (⪰i)i∈I, (⪰j)j∈J). Then μ is a Pareto-stable matching in the stable mar-
riage market.
Proof. Since the outcome (μ, u, v) is stable in market M, Lemma 3 implies that
the matching μ is weakly stable in the stable marriage market. It remains to
show that the matching μ is not Pareto-dominated.

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
289
Let μ′ be a matching of the stable marriage market such that μ′ ⪰μ. Then
μ′(i) ⪰i μ(i) and μ′(j) ≥j μ(j) for every man i ∈I and woman j ∈J. Hence
ai,μ′(i) ≥ai,μ(i) and bμ′(j),j ≥bμ(j),j for every man i ∈I and woman j ∈J.
Since ai,μ′(i) ≥ai,μ(i) for every man i ∈I, we have

i∈I

ui expλ(−ai,μ′(i)) −πi

≤

i∈I

ui expλ(−ai,μ(i)) −πi

.
Applying Lemma 4 to both sides, we get

j∈J

bμ′(j),jN −vj

≤

j∈J

bμ(j),jN −vj

.
Since bμ′(j),j ≥bμ(j),j for every woman j ∈J, the inequalities are tight. Hence
ai,μ′(i) = ai,μ(i) and bμ′(j),j = bμ(j),j for every man i ∈I and woman j ∈J.
Thus μ(i) ⪰i μ′(i) and μ′(j) ⪰j μ(j) for every man i ∈I and woman j ∈J. We
conclude that μ ⪰μ′.
⊓⊔
3.3
Group Strategyproofness
In this subsection, we study the group strategyproofness of matchings in the sta-
ble marriage market that correspond to man-optimal outcomes in the associated
tiered-slope market. We ﬁrst show that the utilities of the men in man-optimal
outcomes in the associated tiered-slope market reﬂect the utilities of the men in
the stable marriage market (Lemma 5). Then we prove group strategyproofness
in the stable marriage market using group strategyproofness in the associated
tiered-slope market (Theorem 3).
Lemma 5. Let (μ, u, v) be a man-optimal outcome in the tiered-slope market
M = (I, J, π, N, λ, a, b) associated with stable marriage market (I, J, (⪰i)i∈I,
(⪰j)j∈J). Then expλ(ai,μ(i)) ≤ui < expλ(ai,μ(i) + 1) for every man i ∈I.
The proof of Lemma 5 is given in [6, App. A]. Since the compensation received
by a man i ∈I matched with a woman μ(i) ̸= 0 is given by ui expλ(−ai,μ(i)),
Lemma 5 implies that the amount of compensation in man-optimal outcomes is
at least 1 and at most λ. In fact, no woman is willing to pay more than λ under
any individual rational outcome.
Theorem 3 (Group strategyproofness).
If a mechanism produces match-
ings that correspond to man-optimal outcomes of the tiered-slope markets asso-
ciated with the stable marriage markets, then it is group strategyproof and
Pareto-stable.
Proof. We have shown Pareto-stability in the stable marriage market in Theorem
2. It remains only to show group strategyproofness.
Let (I, J, (⪰i)i∈I, (⪰j)j∈J) and (I, J, (⪰′
i)i∈I, (⪰j)j∈J) be stable marriage
markets where (⪰i)i∈I and (⪰′
i)i∈I are diﬀerent preference proﬁles. Let (I, J,

290
N.O. Domani¸c et al.
π, N, λ, a, b) and (I, J, π, N, λ, a′, b) be the tiered-slope markets associated with
stable marriage markets (I, J, (⪰i)i∈I, (⪰j)j∈J) and (I, J, (⪰′
i)i∈I, (⪰j)j∈J),
respectively. Let (μ, u, v) and (μ′, u′, v′) be man-optimal outcomes of the tiered-
slope markets (I, J, π, N, λ, a, b) and (I, J, π, N, λ, a′, b), respectively.
Since the preference proﬁles (⪰i)i∈I and (⪰′
i)i∈I are diﬀerent, we have a ̸= a′.
So, by Theorem 1, there exists a man i0 ∈I and a woman j0 ∈J ∪{0} with
ai0,j0 ̸= a′
i0,j0 such that ui0 ≥u′
i0 expλ(ai0,μ′(i0) −a′
i0,μ′(i0)). Hence
expλ(ai0,μ(i0) + 1) > ui0
≥
u′
i0
expλ(a′
i0,μ′(i0)) expλ(ai0,μ′(i0))
≥expλ(ai0,μ′(i0)),
where the ﬁrst and third inequalities follow from Lemma 5. This shows that
ai0,μ(i0) + 1 > ai0,μ′(i0). Hence ai0,μ(i0) ≥ai0,μ′(i0), and we conclude that
μ(i0) ⪰i0 μ′(i0). Also, since ai0,j0 ̸= a′
i0,j0, the preference relations ⪰i0 and
⪰′
i0 are diﬀerent. Therefore, the mechanism is group strategyproof.
⊓⊔
4
Eﬃcient Implementation
The implementation of our group strategyproof Pareto-stable mechanism for
stable marriage with indiﬀerences amounts to computing a man-optimal outcome
for the associated tiered-slope market. Since all utility functions in the tiered-
slope market are linear functions, we can perform this computation using the
algorithm of D¨utting et al. [9], which was developed for multi-item auctions. If we
model each woman j as a non-dummy item in the multi-item auction with price
given by utility vj, then the utility function of each man on each non-dummy
item is a linear function of the price with a negative slope. Using the algorithm of
D¨utting et al., we can compute a man-optimal (envy-free) outcome using O(n5)
arithmetic operations, where n is the total number of agents. Since poly(n)
precision is suﬃcient, our mechanism admits a polynomial-time implementation.
For the purpose of solving the stable marriage problem, it is actually suﬃcient
for a mechanism to produce the matching without the utility vectors u and
v of the associated tiered-slope market. In [6, App. B and C], we show that
the generalization of the deferred acceptance algorithm presented in [7] can be
used to compute a matching that corresponds to a man-optimal outcome for the
associated tiered-slope markets. The proof of Theorem 4 is given in [6, App. C.3].
Theorem 4. There exists an O(n4)-time algorithm that corresponds to a group
strategyproof Pareto-stable mechanism for the stable marriage market with indif-
ferences, where n is the total number of men and women.
References
1. Abdulkadiroˇglu, A., Pathak, P.A., Roth, A.E.: Strategy-proofness versus eﬃciency
in matching with indiﬀerences: redesigning the NYC high school match. Am. Econ.
Rev. 99, 1954–1978 (2009)

Group Strategyproof Pareto-Stable Marriage with Indiﬀerences
291
2. Chen, N.: On computing Pareto stable assignments. In: Proceedings of the 29th
International Symposium on Theoretical Aspects of Computer Science, pp. 384–
395 (2012)
3. Chen, N., Ghosh, A.: Algorithms for Pareto stable assignment. In: Proceedings of
the Third International Workshop on Computational Social Choice, pp. 343–354
(2010)
4. Crawford, V.P., Knoer, E.M.: Job matching with heterogeneous ﬁrms and workers.
Econometrica 49, 437–450 (1981)
5. Demange, G., Gale, D.: The strategy structure of two-sided matching markets.
Econometrica 53, 873–888 (1985)
6. Domani¸c, N.O., Lam, C.K., Plaxton, C.G.: Group strategyproof Pareto-stable mar-
riage with indiﬀerences via the generalized assignment game, July 2017. https://
arxiv.org/abs/1707.01496
7. Domani¸c, N.O., Lam, C.K., Plaxton, C.G.: Strategyproof Pareto-stable mecha-
nisms for two-sided matching with indiﬀerences. In: Fourth International Workshop
on Matching under Preferences, April 2017. https://arxiv.org/abs/1703.10598
8. Dubins, L.E., Freedman, D.A.: Machiavelli and the Gale-Shapley algorithm. Am.
Math. Mon. 88, 485–494 (1981)
9. D¨utting, P., Henzinger, M., Weber, I.: An expressive mechanism for auctions on
the web. ACM Trans. Econ. Comput. 4, 1:1–1:34 (2015)
10. Erdil, A., Ergin, H.: What’s the matter with tie-breaking? Improving eﬃciency in
school choice. Am. Econ. Rev. 98, 669–689 (2008)
11. Erdil, A., Ergin, H.: Two-sided matching with indiﬀerences (2015). working paper
12. Eriksson, K., Karlander, J.: Stable matching in a common generalization of the
marriage and assignment models. Discrete Math. 217, 135–156 (2000)
13. Gale, D., Shapley, L.S.: College admissions and the stability of marriage. Am.
Math. Mon. 69, 9–15 (1962)
14. Irving, R.W.: Stable marriage and indiﬀerence. Discrete Appl. Math. 48, 261–272
(1994)
15. Kamiyama, N.: A new approach to the Pareto stable matching problem. Math.
Oper. Res. 39, 851–862 (2014)
16. Kesten, O.: School choice with consent. Q. J. Econ. 125, 1297–1348 (2010)
17. Knuth, D.: Marriages Stables. Montreal University Press, Montreal (1976)
18. Quinzii, M.: Core and competitive equilibria with indivisibilities. Int. J. Game
Theory 13, 41–60 (1984)
19. Roth, A.E.: The economics of matching: stability and incentives. Math. Oper. Res.
7, 617–628 (1982)
20. Roth, A.E.: The college admissions problem is not equivalent to the marriage
problem. J. Econ. Theory 36, 277–288 (1985)
21. Roth, A.E., Sotomayor, M.: Two-sided Matching: A Study in Game-Theoretic
Modeling and Analysis. Cambridge University Press, New York (1990)
22. Shapley, L.S., Shubik, M.: The assignment game I: the core. Int. J. Game Theory
1, 111–130 (1971)
23. Sotomayor, M.: Existence of stable outcomes and the lattice property for a uniﬁed
matching market. Math. Soc. Sci. 39, 119–132 (2000)
24. Sotomayor, M.: The Pareto-stability concept is a natural solution concept for dis-
crete matching markets with indiﬀerences. Int. J. Game Theory 40, 631–644 (2011)
25. Zhou, L.: On a conjecture by gale about one-sided matching problems. J. Econ.
Theory 52, 123–135 (1990)

The Spectrum of Equilibria for the Colonel
Blotto and the Colonel Lotto Games
Marcin Dziubi´nski(B)
Institute of Informatics, University of Warsaw, Banacha 2, 02-097 Warsaw, Poland
m.dziubinski@mimuw.edu.pl
Abstract. We study Nash equilibria of a symmetric Colonel Blotto and
Colonel Lotto games. In these game two players, with N ≥1 units of
resources each, distribute their resources simultaneously across K ≥2
battleﬁelds. We introduce a characteristic of equilibria in this game called
spectrum which stands for the fraction of battleﬁelds receiving given
numbers of units. We provide complete characterization of spectra of
Nash equilibria in Colonel Lotto game as well as necessary conditions on
spectra of Nash equilibria in Colonel Blotto game for the case of K |N.
1
Introduction
The Colonel Blotto game, introduced by Borel [5], is a prime example of a
conﬂict with multiple battleﬁelds [13], where two parties distribute their limited
resources across a number of fronts aiming to beat the opponent at every front.
A player wins a battleﬁeld if the number of her resources is strictly larger than
the number of resources of the opponent. This is a natural problem that arises in
numerous applications, such as military conﬂicts [4], political competition [14],
or network security [7]. Examples of conﬂicts with multiple battleﬁelds include
security games [12,18], duelling algorithms [11], and chopstick auctions [17].
This paper addresses the problem of how to distribute the available resources in
a competitive setting. This should be seen as a more complex set up than the
one used in conﬂicts on networks (c.f. [2,6,8]), where the users decide whether
they use or do not use a single protection resource (for instance, an antivirus
software) to prevent, potentially contagious, attacks on the network.
A continuous variant of the game, where each party can assign any fraction
of her total resources to a battleﬁeld, was solved by Gross and Wagner in [9]
(the symmetric variant) and by Roberson [16] (asymmetric variant).1 In addi-
tion, a complete characterization of Nash equilibria of the continuous variant on
two battleﬁelds was obtained by Macdonell and Mastronardi [15]. The discrete
variant is much less understood (for many cases of the asymmetric variant we do
not even know the value of the game). The most comprehensive results for this
This work was supported by Polish National Science Centre through grant
nr 2014/13/B/ST6/01807.
1 Colonel Blotto game is symmetric when both players have the same amount of
resources and it is asymmetric otherwise.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 292–306, 2017.
DOI: 10.1007/978-3-319-66700-3 23

The Spectrum of Equilibria for the Colonel Blotto
293
variant were obtained by Hart [10]. Hart found Nash equilibria for the symmet-
ric variant of the game, as well as for some cases of the asymmetric variant. To
obtain these results, Hart introduces a new game, called Colonel Lotto, where
the players choose partitions of their resources only and then one part from
each partition is drawn equilprobably and then the chosen parts are matched.
He shows that equilibria in this game correspond to equilibria in Colonel Blotto
game which are symmetric across battleﬁelds, i.e. are invariant under battleﬁelds
relabelling.
This paper considers the symmetric variant of the Colonel Blotto game and
the Colonel Lotto game. Strategies are probability distributions over the set of
distributions of resources across the battleﬁelds. We introduce a characteristic of
such strategies called spectrum. It stands for a fraction of battleﬁelds receiving
given numbers of units of resources. We provide full characterization of spectra
of equilibrium strategies for the case where the number of battleﬁelds divides the
number of units of resources. To achieve this goal, in particular, we construct
new, previously unknown, equilibrium strategies of the game. The notion of
spectrum is more general and can be used to characterize equilibria in other
models of conﬂict with multiple battleﬁelds. Our work builds on [10], but we
extend it towards providing full characterization of a non-trivial characteristic of
equilibria in Colonel Lotto game and we provide necessary conditions for spectra
of all equilibrium strategies in Colonel Blotto game (not only those which are
symmetric across battleﬁelds). To our knowledge, this is the ﬁrst result of this
sort for the discrete variant of the game.
It should be noted that although explicit characterization of Nash equilibria
in discrete Colonel Blotto is known only partially, the computational side of the
problem is understood much better. In recent papers, [1,3] eﬃcient, polynomial
time, algorithms to compute Nash equilibria are proposed for a more general
variant of the Colonel Blotto and the Colonel Lotto games, where both the
players budgets as well as the battleﬁelds values may be heterogeneous.
To summarize, the contributions of this paper are as follows: (i) we introduce
the notion of spectrum of mixed strategies for conﬂicts with multiple battleﬁelds,
(ii) we provide full characterization of Nash equilibria (in terms of spectrum) in
symmetric Colonel Lotto game and provide necessary conditions on spectrum
of equilibria in symmetric Colonel Blotto game, both for the case where the
number of battleﬁelds divides the number of units of resources each player has,
(iii) we construct new equilibria for the game and we develop a notation for
representing complex equilibria. The ﬁrst contribution is a general concept which
is applicable to other games of conﬂict with multiple battleﬁelds. The second
contribution allows for an eﬃcient veriﬁcation of whether a given strategy is an
equilibrium strategy in the game or not (in the case of Colonel Lotto game) or
for partial veriﬁcation of optimality of given strategies (in the case of Colonel
Blotto game). Notice that using the algorithm of Ahmedinejad et al. [1] for that
purpose is not straightforward, because, in particular, it only ﬁnds a subset of
equilibria in the games (all the equilibria it computes have support of polynomial
size). It may also be useful when the problem of ﬁnding equilibria satisfying

294
M. Dziubi´nski
additional constraints is considered (e.g. equilibria which provide best expected
payoﬀs against all strategies). The third contribution extends the set of equilibria
constructed in [10].
1.1
Spectrum: Informal Introduction
Before deﬁning the game and the concept of spectrum formally, we provide an
informal deﬁnition and discuss its more general usefulness. A conﬂict with mul-
tiple battleﬁelds requires the players to distribute their limited resources across
a number of battleﬁelds. Hence a pure strategy in any such game is a vector that
speciﬁes the number of units of resources received by each battleﬁeld. A typical
feature of such conﬂicts is that optimal strategies involve using mixed strate-
gies to ‘confuse’ the opposition. Characterizing such strategies, especially ﬁnding
their full characterization, is challenging, because the number of allocations they
could randomize over is exponential. One way forward is to fully characterize
non-trivial characteristics of such strategies. One such characteristic is spectrum
and it can be applied to any conﬂict with multiple battleﬁelds where players
distribute diﬀerent numbers of resources across a number of battleﬁelds (c.f. [13]
for an overview of such games).
Spectrum of a mixed strategy for a conﬂict with multiple battleﬁelds is a
probability distribution on the set of possible numbers of units of resources,
{0, . . . , N} that a player can use. Given a number of units M it provides the
fraction of battleﬁelds that receive M under the given mixed strategy. For exam-
ple, given a mixed strategy where one of allocations [2, 0, 1], [0, 3, 0] and [1, 0, 2]
is used with probability 1/3 in a conﬂict with K = 3 battleﬁelds by a player with
3 units, the spectrum is ( 4
9, 2
9, 2
9, 1
9), that is on average, 4/9 of battleﬁelds receive
0 units, 2/9 of battleﬁelds receive 1 unit, 2/9 of battleﬁelds receive 2 units, and
1/9 of battleﬁelds receives 3 units.
In this paper, we demonstrate usefulness of spectrum by providing full char-
acterization, in terms of it, of equilibria in symmetric Colonel Blotto game where
K |N. Such characterization is useful when the problem of ﬁnding equilibria sat-
isfying additional constraints is considered (e.g. equilibria which provide best
expected payoﬀs against all strategies). It can also be used to verify algorithms
for computing equilibria for the game. Spectrum could also be useful to obtain
some information about equilibria for conﬂicts with multiple battleﬁelds where
ﬁnding any equilibria is an open problem, e.g. chopstick auctions [17]. Obtaining
spectra of equilibrium strategies could help in ﬁnding the actual strategies.
2
Colonel Blotto, Colonel Lotto, and General Lotto
Games
In this section we introduce three games that are useful in the analysis of Colonel
Blotto game (but are also of interest on their own). These are Colonel Blotto,
Colonel Lotto and General Lotto games. Since the focus of this paper are sym-
metric variants of these games, where both players have the same strength, for

The Spectrum of Equilibria for the Colonel Blotto
295
the remaining part of the paper we restrict attention to symmetric variants of
the games only (and simplify the deﬁnitions accordingly).
Given two natural numbers, N ≥1 and K ≥2, the Colonel Blotto game,
B(N, K), is deﬁned as follows. There are two players A and B having N units
of resources (or army), each, to distribute simultaneously over K battleﬁelds. A
pure strategy of a player is an ordered K-partition, x = (x1, . . . , xK), of N, so
that x1 + . . . + xK = N and each xi is a natural number. The set of strategies
of each player is
S =

x ∈ZK
+ :
K

i=1
xi = N

.
(1)
A mixed strategy, ξ, of B(N, K) is a probability distribution on S. Let Π(K) be
the set of all permutations on {1, . . . , K}. Any permutation π ∈Π(k) gives rise
to a bijection on S which maps any ordered partition x = (x1, . . . , xK) ∈S to
π(x) = (xπ(1), . . . , xπ(K)). A mixed strategy ξ is symmetric across battleﬁelds if
for any permutation π ∈Π(K), ξ = ξ ◦π.
After the units are distributed, the payoﬀof each player is determined as
follows. For each battleﬁeld where a player has a strictly larger number of units
of resources placed she receives the score 1, while for each battleﬁeld where a
player has a strictly smaller number of units of resources placed, he receives the
score −1. The score on the tied battleﬁelds is 0 for each player. The overall payoﬀ
is the average of payoﬀs obtained for all battleﬁelds, that is, given the strategies
x and y of A and B, respectively, it is
hB(x, y) = 1
K
K

i=1
sign(xi −yi).
Colonel Blotto is a zero-sum game.
In this paper we follow the approach of [10]. To study the Colonel Blotto
game, [10] proposed a symmetrized-across-battleﬁelds variant of this game called
the Colonel Lotto game. In this game, denoted by L(N, K), the battleﬁelds are
indistinguishable and players simultaneously divide their units into K groups,
which are then randomly paired. A pure strategy of each player A is an unordered
K-partition, x = ⟨x1, . . . , xK⟩, of N. The payoﬀof each player is an average over
all possible pairings, that is, given the strategies x and y of A and B, respectively,
it is
hL(x, y) =
1
K2
K

i=1
K

j=1
sign(xi −yj).
To see the connection between the Colonel Blotto and Colonel Lotto games,
given a pure strategy x of player A in B(N, K), let σ(x) denote a mixed strategy
that assigns equal probability,
1
K!, to each permutation of x. Similarly, given
a mixed strategy ξ of player A, let σ(ξ) denote a mixed strategy obtained
by replacing each pure strategy x in the support of ξ by σ(x). The strate-
gies σ(x) and σ(ξ) are symmetric across battleﬁelds. As was observed by [10],
hB(σ(ξ), y) = hL(ξ, y), for any pure strategy y of player B. Consequently,

296
M. Dziubi´nski
hB(σ(ξ), η) = hL(ξ, η), for any mixed strategy η of player B. Analogously for
the strategies of player B. Hence the following observation can be made
Observation 1 [10]. The Colonel Blotto game B(N, K) and the Colonel Lotto
game L(N, K) have the same value. Moreover, the mapping σ maps the optimal
strategies in the Colonel Lotto game onto the optimal strategies in the Colonel
Blotto game that are symmetric across battleﬁelds.
Following [10], we deﬁne yet another game called General Lotto. Given a
positive rational number n ∈Q++, the General Lotto game G(n) is deﬁned
as follows. There are two players, A and B, who simultaneously choose discrete
probability distributions over non-negative natural numbers such that the expec-
tations under the distributions proposed must be n. This restriction could be
seen as a budget constraint, restricting the average amount of resources that can
be assigned to a single battleﬁeld. The set of strategies of a player
T =

p ∈[0, 1]Z+ :
+∞

i=0
pi = 1 and
+∞

i=0
ipi = n

.
Let X and Y be integer valued random variables distributed according to the
distributions x and y, proposed by A and B, respectively (i.e. Pr(X = i) = xi
and Pr(Y = i) = yi, for all i ∈Z+). Then the payoﬀof player A is
H(X, Y ) = Pr(X > Y ) −Pr(X < Y ) =
+∞

i=0
xi(Pr(Y < i) −Pr(Y > i)).
(2)
General Lotto is a zero sum game.
[10] provided full characterization of equilibria in this game. We start with
introducing some useful strategies. Given m ≥1, let U m
O , U m
E , and U m be vectors
deﬁned as follows:2
U m
O = [0, 1, . . . , 0, 1, 0



2m+1
]T ,
U m
E = [1, 0, . . . , 1, 0, 1



2m+1
]T ,
U m = [1, 1, . . . , 1, 1, 1



2m+1
]T .
Given m ≥1, let um
O, um
E , and um, be stochastic vectors deﬁned as follows:
um
O =
	 1
m

U m
O , um
E =
	
1
m + 1

U m
E , um =
	
1
2m + 1

U m.
Notice that probability distribution represented by um is a uniform distrib-
ution on the set {0, . . . , 2m}. Similarly, the probability distribution represented
by um
O is a uniform distribution on the set of odd numbers from {0, . . . , 2m}
and um
E is a uniform distribution on the set of even numbers from {0, . . . , 2m}.
Clearly, um is a convex combination of um
O and um
E ,
um =
	
m
2m + 1

um
O +
	 m + 1
2m + 1

um
E .
(3)
2 For convenience reasons, throughout the paper we number the rows of matrices
starting for 0 and we number the columns starting from 1.

The Spectrum of Equilibria for the Colonel Blotto
297
We will use conv(um
O, um
E ) to denote the set of all convex combinations of um
O
and um
E . The following theorem characterizes equilibrium strategies of General
Lotto games.
Theorem 1 [10].
Let n > 0 be an integer. Then the value of General Lotto
game, val G(n) = 0. Moreover, a strategy x is an equilibrium strategy of player
A or B iﬀx ∈conv(un
O, un
E).
Equilibria of General Lotto game can be used to construct equilibria of
Colonel Lotto game and, consequently, symmetric across battleﬁelds equilib-
ria of Colonel Blotto game. To see that, notice that any K-partition ⟨z1, . . . , zK⟩
of a natural number C can be seen as a discrete random variable Z with val-
ues in the set {z1, . . . , zK} and the distribution obtained by assigning to each
z1, . . . , zK the probability
1
K . The expected value of Z is then Ex(Z) =
C
K ,
which is the average number of units per battleﬁeld. This construction links the
pure strategies x and y of players A and B in Colonel Lotto game with discrete
integer valued random variables X and Y . The strategies of players A and B
in Colonel Lotto game could be seen as non-negative, integer valued random
variables bounded by N and having expectations N/K. The payoﬀhL(x, y) can
be then written as
hL(x, y) = H(X, Y ) = Pr(X > Y ) −Pr(X < Y ).
(4)
General Lotto game could be seen as a modiﬁcation of Colonel Lotto game
where, on one hand, the strategies of the players are unbounded random vari-
ables, and on the other hand, the units of resources are distributed on the con-
tinuum of battleﬁelds. In a strategy x of General Lotto the probability, xi cor-
responds to the fraction of battleﬁelds that receive i units and this fraction can
be any number in the interval [0, 1]. A mixed strategy ξ of Colonel Lotto game
could be represented in a similar way, by providing the fraction of battleﬁelds
each number of units of resources is assigned to. The fact that there are ﬁnitely
many battleﬁelds restricts the set of fractions that can appear in such a strategy.
Thus every mixed strategy ξ in the Colonel Lotto game L(N, K) corresponds
to a strategy x in the General Lotto game G(N/K). In this case we say that ξ
(N, K)-implements x. A strategy in G(N/K) for which an (N, K)-implementing
strategy exists is called (N, K)-feasible. Every equilibrium strategy in a Gen-
eral Lotto game G(N/K) which is (N, K)-feasible is an equilibrium strategy
in Colonel Lotto game L(N, K). Using this approach, [10] found equilibrium
strategies in Colonel Lotto game. [10] gave necessary and suﬃcient conditions
for (N, K)-feasibility of some of the equilibrium strategies in General Blotto
game G(N/K).
Proposition 1 [10]. Let N ≥1 and K ≥2 be natural numbers such that K |N
and let n = N/K
1. un
O is (N, K)-feasible if and only if N ≡K (mod 2).
2. un
E is (N, K)-feasible if and only if N is even.

298
M. Dziubi´nski
Proof of this proposition is constructive. Hart constructs strategies in Colonel
Lotto games which (N, K)-implement the corresponding vectors in the proposi-
tion, thus providing equilibrium strategies for Colonel Lotto game and symmetric
across battleﬁelds equilibrium strategies for Colonel Blotto game.
3
Analysis
We start with some key deﬁnitions. Given a mixed strategy ξ in B(N, K) and
a battleﬁeld i ∈{1, . . . , K}, a marginal distribution of ξ corresponding to i is
the probability distribution ξi such that for each number of units of resources
y ∈{0, . . . , N},
ξi
y = Pr(i gets y units under ξ) =

x∈S
ξ(x)[xi = y],
(5)
where, given a condition ϕ, [ϕ] is the Iverson bracket that takes value 1 when
ϕ holds and value 0 otherwise. The concept of spectrum of a mixed strategy in
B(N, K) is deﬁned as follows.
Deﬁnition 1 (Spectrum). Let ξ be a mixed strategy in B(N, K). A spectrum
of ξ is the probability distribution spec(ξ) over the set of possible numbers of units
of resources such that for each number of units of resources y ∈{0, . . . , N},
specy(ξ) =
	 1
K

 K

i=1

x∈S
ξ(x)[xi = y] =
	 1
K

 K

i=1
ξi
y,
(6)
i.e. it is the probability that an equiprobably picked battleﬁeld is allocated y units
of resources under ξ.
Marginal distributions and spectrum of mixed strategies in Colonel Lotto
game are deﬁned analogously. Notice that in the case of mixed strategies sym-
metric across battleﬁelds in B(N, K) as well as mixed strategies in L(N, K), all
marginal distributions are the same and are equal to the spectrum of the distri-
bution. Notice also that spectrum spec(ξ) of a mixed strategy ξ in Colonel Lotto
game L(N, K) is a strategy in G(N/K) (N, K)-implemented by ξ and hence it
is (N, K)-feasible.
In this section we provide a full characterization of spectra of equilibrium
strategies in Colonel Blotto game B(N, K) and of marginal distributions of equi-
librium strategies in Colonel Lotto game L(N, K). We start with the following
observation, which implies that the two objects are the same (the proof is moved
to the Appendix).
Observation 2. For any equilibrium strategy ξ in B(N, K), σ(ξ) is an equilib-
rium strategy in B(N, K) as well. Moreover, spec(ξ) = spec(σ(ξ)).
It follows from Observation 2 that to characterize spectra of equilibrium
strategies in B(N, K) we can restrict attention to equilibrium strategies which are

The Spectrum of Equilibria for the Colonel Blotto
299
symmetric across battleﬁelds. Clearly spectrum of such strategies is the same as
their marginal distributions. Hence spectra of equilibrium strategies of B(N, K)
are the same as marginal distributions of equilibrium strategies in L(N, K).
We start with providing full characterization of the equilibrium strategies in
the General Lotto game G(N/K) that are (N, K)-implementable by strategies
in Colonel Lotto game L(N, K), for K | N. In further analysis we will use the
strategies deﬁned by [10] to prove Proposition 1 along with new strategies intro-
duced below. To allow for representation of more complex strategies given in the
remaining part of the paper, we develop some auxiliary notation.
A pure strategy in Colonel Lotto game L(N, K) can be represented as a
1 × K row vector of natural numbers that sum up to N. A mixed strategy
r
i=1 λiXi, where probability of each partition in the support is a rational num-
ber, λi = ni/di, can be represented as a l × K matrix, where l = r
i=1 li =
r
i=1 q lcm(d1, . . . , dr) ni
di , q ≥1 is a natural number, and each row representing
partition Xi is repeated li times.3
Given a r×c matrix of natural numbers, X, and a natural number i ∈Z+, let
#X(i) be the number of appearances of i in X. A vector x such that xi = #X(i)
is called the cardinality vector of X and a vector z such that zi = #X(i)/(rc) is
called the spectrum of X. We use card(X) and spec(X) to denote the cardinality
vector and the spectrum, respectively, for a matrix X. As we observed above,
a mixed strategy (matrix) X of a player in Colonel Lotto game L(N, K) gives
rise to a strategy x = spec(X) in General Lotto game G(N/K). In this case
we say that X (N, K)-implements x. We use the same terminology with regard
to cardinality vectors. Given an optimal strategy x of a player in G(N/K),
any mixed strategy X that (N, K)-implements x is an optimal strategy for a
player in L(N, K). Hence to ﬁnd optimal strategies (and values) of Colonel
Lotto game L(N, K) we need to try to (N, K)-implement an optimal strategy
from General Lotto game G(N/K). As it turns out, all (N, K)-feasible corner
strategies in General Lotto game can be implemented by mixed strategies in
Colonel Lotto game for which all the probabilities are rational numbers. To ﬁnd
such rational (N, K)-implementations we need to solve the following problem:
Given a spectrum x and numbers N and K ﬁnd a l × K matrix X such that
l ≥1, every row of X sums up to N, and spec(X) = x. If such a matrix exists
for given x, N and K, then x is (N, K)-feasible.
Matrices representing equilibrium strategies will be constructed from simpler
matrices by means of horizontal and vertical composition. Given a r × c1 matrix
X and a r × c2 matrix Y, X|Y = [X|Y] denotes a r × (c1 + c2) matrix being the
horizontal composition of matrices X and Y. Similarly, given a r1 × c matrix X
and a r2 × c matrix Y, we use
X//Y =
 X
Y

to denote a (r1 + r2) × c matrix being the vertical composition of X and Y.
We will also use the standard generalizations of these operators to multiple
3 Given natural numbers c1, . . . , cr, lcm(c1, . . . , cm) is their least common multiple.

300
M. Dziubi´nski
arguments, |z
i=1Xi and //z
i=1Xi, where Xi are matrices satisfying the required
dimensional constraints. Clearly card(X|Y) = card(X) + card(Y) as well as
card(X//Y)
=
card(X) + card(Y). Similarly, spec(|z
i=1X)
=
spec(X) and
spec(//z
i=1X) = spec(X).
Given a natural number m ≥1, let E(m) be (m + 1) × 2 matrix deﬁned as
follows:
E(m) =
⎡
⎢⎢⎢⎣
0,
2m
2, 2m −2
...
...
2m,
0
⎤
⎥⎥⎥⎦,
that is the i’th row, ei =

2i, 2(m −i)

. Each row of matrix E(m) represents a
bipartition, a strategy in Colonel Lotto game with K = 2 battleﬁelds and 2m
units. The whole matrix represents a mixed strategy, where each partition (row)
is chosen with probability 1/(m + 1).
Given an even natural number m ≥2, let RE(m) = REI(m)//REII(m) be
a (m + 1) × 3 matrix consisting of two blocks, REI(m) and REII(m), where
REI(m) =
⎡
⎢⎢⎢⎣
0,
m,
2m
2, m + 2, 2m −4
...
...
...
m,
2m,
0
⎤
⎥⎥⎥⎦,
REII(m) =
⎡
⎢⎢⎢⎣
0,
m + 2, 2m −2
2,
m + 4, 2m −6
...
...
...
m −2,
2m,
2
⎤
⎥⎥⎥⎦,
that is the i’th row, reI
i =

2i, m + 2i, 2m −4i

, and the i’th row reII
i
=

2i, m + 2i + 2, 2m −4i −2

.
Similarly, given m ≥2, let O(m) be a m × 2 matrix deﬁned as O(m) =
E(m −1) + 1, that is row oi =

2i + 1, 2(m −i −1) + 1

, and, given an odd
m ≥3, let RO(m) = RE(m −1) + 1.
Notice that card(E(m)) = 2U m
E and card

|l
i=1E(m)

= 2lU m
E , for all l ∈Z+.
Clearly spec

|l
i=1E(m)

= um
E , for all l ∈Z+. Thus |
K
2
i=1E(m) (mK, K)-
implements
um
E
in
the
case
of
K
being
even.
It
can
be
easily
checked that card (RE(m))
=
3U m
E
and spec (RE(m))
=
um
E . Hence
spec

RE(m)|

|l
i=1E(m)

= um
E , for all l ∈Z+. Thus

RE(m)|

|
K−3
2
i=1 E(m)

(mK, K)-implements um
E in the case of K being odd. The cardinality vector for
O(m) is the cardinality vector for E(m −1), 2U m−1
E
, ‘shifted up’ by one place,
which is exactly 2U m
O . Similarly, card(RO(m)) = 3U m
O . Thus |
K
2
i=1O(m) (mK, K)-
implements um
O in the case of K being even and

RO(m)|

|
K−3
2
i=1 O(m)

(mK, K)-implements um
O in the case of K being odd.
Proposition 1 implies that in the case of K |N and K being even both U n
O and
U n
E, where n = N/K, are (N, K)-feasible. Thus any convex combination of these
vectors is (N, K)-feasible as well, as it is a spectrum of convex combinations of
strategies implementing un
O and un
E. Proposition below provides the complete

The Spectrum of Equilibria for the Colonel Blotto
301
characterization of (N, K)-feasible General Lotto equilibrium strategies in the
case of K |N and K being odd.4
Proposition 2. Let N ≥1 and K ≥2 be natural numbers such that K |N and
let n = N/K.
1. If K is odd and N is odd, then λun
O +(1−λ)un
E is (N, K)-feasible if and only
if λ ∈
 1
K , 1

.
2. If K is odd and N is even, then (1 −λ)un
O + λun
E is (N, K)-feasible if and
only if λ ∈
 1
K , 1

.
Proof. For point 1, suppose that K is odd and N is odd (in this case n is odd
as well). For the left to right implication notice that any K-partition of N must
contain at least one odd number. This, together with the fact that un
E puts
positive probabilities on even numbers only implies that λ ∈[1/K, 1]. For the
right to left notice that, by point 1 of Proposition 1, un
O is (N, K)-feasible. Thus
it is enough to show that z =
1
K un
O + K−1
K un
E is (N, K)-feasible. Vector z can
be rewritten as z = r +
 K−3
K

un
E, where
r =
	
1
n(n + 1)K

((n + 1)U n
O + 2nU n
E) .
(7)
Let R(n) be a n(n + 1) × 3 matrix consisting of four blocks, R(n)
=
RI(n)//RII(n)//RIII(n)//RIV(n), deﬁned below.
RI(n) =
⎡
⎢⎢⎢⎣
{
0,
2n −1, n + 1 }n−1
{
2,
2n −5, n + 3 }n−1
...
...
...
{ n −1,
1,
2n
}n−1
⎤
⎥⎥⎥⎦,
RII(n) =
⎡
⎢⎢⎢⎣
{
2,
2n −3, n + 1 }n−1
{
4,
2n −7, n + 3 }n−1
...
...
...
{ n −1,
3,
2n −2 }n−1
⎤
⎥⎥⎥⎦,
RIII(n) =
⎡
⎢⎢⎢⎣
{
2,
n −2, 2n }2
{
4,
n −4, 2n }2
...
...
...
{ n −1,
1,
2n }2
⎤
⎥⎥⎥⎦,
RIV(n) =
⎡
⎢⎢⎢⎣
{ 0, 2n −1, n + 1 }2
{ 0, 2n −3, n + 3 }2
...
...
...
{ 0,
n,
2n
}2
⎤
⎥⎥⎥⎦,
(in the deﬁnitions, the notation

{ a1, . . . , al }t 
means that row

a1, . . . , al

is
repeated t times). RI(n) is a (n+1)(n−1)
2
× 3 block with the i’th part of the form
2i, 2n −4i −1, n + 2i + 1
. RII(n) is a (n−1)2
2
× 3 block with the i’th part of
the form
2i + 2, 2n −4i −3, n + 2i + 1
. RIII(n) is a (n −1) × 3 block with
the i’th part of the form
2i + 2, n −2i −2, 2n
. RIV(n) is a (n + 1) × 3 block
with the i’th part of the form
0, 2n −2i −1, n + 2i + 1
.
Each row of R(n) sums up to 3n. Moreover, it is easy to verify that
card(R(n)) = Z(n) where Z(n) = (n + 1)U n
O + 2nU n
E = [2n, n + 1, 2n, . . . , n +
1, 2n], that is z2i = 2n and z2i+1 = n+1. Let T(n) = R(n)|

|(K−3)/2
i=1
//n
j=1E(n)

.
4 If K | N and K is even, then N must be even as well, so K being odd is the only
remaining case.

302
M. Dziubi´nski
T(n) is a n(n+1)×K matrix with each row summing up to nK. By observations
above, card(T(n)) = (n + 1)U n
O + (K −1)nU n
E and spec(T(n)) = z. This shows
that T(n) (N, K)-implements z and so z is (N, K)-feasible.
For point 2, suppose that K is odd and N is even (in this case n is even).
For the left to right implication notice that any K-partition of N must contain
at least one even number. This, together with the fact that un
O puts positive
frequencies on odd numbers only implies that λ ∈[1/K, 1]. For the right to left
notice that, by point 1 or Proposition 1, un
E is (N, K)-feasible. Thus it is enough
to show that z =
1
K un
E + K−1
K un
O is (N, K)-feasible. Vector z can be rewritten
as z = s +
 K−3
K

un
O, where
s =
	
1
n(n + 1)K

(nU n
E + 2(n + 1)U n
O) .
(8)
Let S(n) be a n(n + 1) × 3 matrix consisting of three blocks, S(n)
=
SI(n)//SII(n)//SIII(n), deﬁned below.
SII(n) =
⎡
⎢⎢⎢⎣
{
1,
n −1, 2n }2
{
3,
n −3, 2n }2
...
...
...
{ n −1,
1,
2n }2
⎤
⎥⎥⎥⎦,
SIII(n) =
⎡
⎢⎢⎢⎣
{ 0, 2n −1, n + 1 }2
{ 0, 2n −1, n + 3 }2
...
...
...
{ 0, n + 1, 2n −1 }2
⎤
⎥⎥⎥⎦,
A n(n −1) × 3 block SI(n) = R(n −1) + 1. A n × 3 block SII(n) with the i’th
part of the form

2i + 1, n −2i −1, 2n

. A n × 3 block SIII(n) with i’th part of
the form

0, 2n −2i −1, n + 2i + 1

.
Each row of S(n) sums up to 3n. Moreover, it is easy to verify that
card(SII(n)//SIII(n)) = Y (n) where Y (n) = [n, 4, 0, . . . , 4, n], that is y0 = y2n =
n, z2i = 0 and z2i−1 = 4. The cardinality vector for SI(n) is the cardinality vector
for R(n −1), Z(n), shifted up by one position. Adding it to Y (n) we obtain the
vector W(n) = 2(n+1)U n
O + nU n
E = [n, 2(n+1), n, . . . , 2(n+1), n], that is w2i = n
and w2i+1 = 2(n + 1). Hence card(S(n)) = card(SI(n)) + card(SII(n)//SIII(n)) =
W(n).
Let T(n) = S(n)|

|(K−3)/2
i=1
//n+1
j=1 O(n)

. T(n) is a n(n + 1) × K matrix with
each row summing up to nK. By observations above, card(T(n)) = nU n
E +(K−1)
(n + 1)U n
O and spec(T(n)) = z. This shows that T(n) (N, K)-implements z and
so z is (N, K)-feasible.
⊓⊔
As a corollary of Propositions 1 and 2, we have that the strategy un is (N, K)-
feasible if K |N and n = N/K (the proof is moved to the Appendix).
Corollary 1. Let N ≥1 and K ≥2 be natural numbers such that K |N and let
n = N/K. Strategy un is (N, K)-feasible.
Propositions 1 and 2 provide a full characterization of equilibrium strate-
gies in the General Lotto game, G(N/K), that are implementable by equilib-
rium strategies in Colonel Lotto game L(N, K). It turns out that every equilib-
rium strategy of Colonel Lotto game L(N, K) (N, K)-implements an equilibrium

The Spectrum of Equilibria for the Colonel Blotto
303
strategy of General Lotto game G(N/K). Hence we have the following theorem,
providing full characterization of equilibrium marginal distributions in Colonel
Lotto game.
Theorem 2. Let N ≥1, K ≥3, and K | N, and let n = N/K. A (mixed)
strategy ξ of L(N, K) is an equilibrium strategy in L(N, K) if and only if for all
i ∈{1, . . . , K}, ξi = ˆξ where
1. ˆξ ∈conv(un
O, un
E) (in the case of K even).
2. ˆξ ∈{λun
O + (1 −λ)un
E : λ ∈[1/K, 1]} (in the case of K odd and N odd).
3. ˆξ ∈{(1 −λ)un
O + λun
E : λ ∈[1/K, 1]} (in the case of K odd and N even).
Proof. Fix N ≥1 and K ≥3 such that K | N. It is enough to show that
every equilibrium strategy in Colonel Lotto game L(N, K) (N, K)-implements
an equilibrium strategy of General Lotto game G(N/K). Then, by Proposition 2,
the result follows.
Take any equilibrium strategy ξ in L(N, K) and let X be the strategy in
G(N/K) that ξ (N, K)-implements, so that spec(ξ) = X. It is enough to show
that X ∈conv(un
O, un
E). Let pi = Pr(X = i). By Eq. (2) and by Ex(X) =
+∞
i=1 Pr(X ≥i),
H(X, un) = −Pr(X ≥2n + 1)
2n + 1
−
	
2
2n + 1

+∞

i=2n+2
Pr(X ≥i).
(9)
Since ξ is an equilibrium strategy and, by Corollary 1, un is (N, K)-feasible so
hL(ξ, υ) = 0, where υ is a strategy in L(N, K) that (N, K)-implements un.
Hence, by Eq. (4), H(X, un) = 0. Thus it must be that Pr(X ≥2n + 1) = 0
and so pi = 0 for all i ≥2n + 1. This implies that X can be represented by a
(2n + 1)-dimensional stochastic vector with mean n. Notice that in the case of
n = N/K = 1, any (2n+1)-dimensional stochastic vector with mean n is a convex
combination of u1
O = [0, 1, 0] and u1
E = [1/2, 0, 1/2]. Hence X ∈conv

u1
O, u1
E

.
Assume that n ≥2. We will construct (N, K)-feasible strategies such that
any strategy yielding payoﬀgreater or equal to 0 against them in G(N/K) must
be a convex combination of un
O and un
E. Let
Si =
	 1
2K

((K −1)1n−i + 21n + (K −1)1n+i) ,
i ∈{0, . . . , n},
Li =
	 1
2K

((K −3)1n−i + 21n−i+1 + 21n−1 + (K −1)1n+i) ,
i ∈{2, . . . , n},
Ri =
	 1
2K

((K −1)1n−i + 21n+1 + 21n+i−1 + (K −3)1n+i) ,
i ∈{2, . . . , n}.
be strategies in G(N/K) where, given j ∈Z+, 1j is the degenerate probabil-
ity distribution on Z+ assigning probability 1 to j. Let S(K, n) = {Si}n
i=0 ∪
{Li, Ri}n
i=2. The following lemma is needed (the proof is moved to the
Appendix).

304
M. Dziubi´nski
Lemma 1. For all integer K ≥3 and n ≥2, and any Y ∈S(K, n)
1. Y is (nK, K)-feasible, and
2. There exists λ ∈(0, 1) and a (nK, K)-feasible strategy T in G(n) such that
un = λY + (1 −λ)T .
By Corollary 1, un is (N, K)-feasible and, by Lemma 1, Si is (N, K)-feasible
(for any i ∈{0, . . . , n}), and there exists λ > 0 and (N, K)-feasible T such that
that un = λSi + (1 −λ)T . Let υ be a strategy that (N, K)-implements un and
θ be a strategy that (N, K)-implements T . Since ξ is an equilibrium strategy
in L(N, K) and the value of the game is 0 so is must be that hL(ξ, si) ≥0,
hL(ξ, θ) ≥0, and hL(ξ, υ) ≥0. On the other hand, υ is an equilibrium strategy,
so hL(ξ, υ) = 0. Hence hL(ξ, si) = 0 and, by Eq. (4), H(X, Si) = 0. Similarly,
H(X, Li) = 0 and H(X, Ri) = 0, for all i = {2, . . . , n}. Let wi = H(X, 1i).
Since H(X, S0) = 0 and H(X, S1) = 0 so
wn = 0 and wn−1 = −wn+1.
(10)
Since H(X, Si) = H(X, Li) so
wn−i + wn = wn−i+1 + wn−1,
fori ∈{2, . . . , n}.
(11)
Similarly, since H(X, Si) = H(X, Ri) so
wn + wn+i = wn+1 + wn+i−1,
fori ∈{2, . . . , n}.
(12)
By Eqs. (10) and (12),
wi+1 −wi = wn+1,
fori ∈{0, . . . , 2n −1}.
(13)
Since wi+1 −wi = −(pi + pi+1) so, by (13), pi + pi+1 = pi+1 + pi+2 and,
consequently, pi = pi+2, for all i ∈{0, . . . , 2n −2}. Hence X ∈conv(un
O, un
E). ⊓⊔
An immediate corollary from Theorem 2 and Observation 2 is the following
result providing a necessary property of equilibrium strategies in Colonel Blotto
game in terms of their spectra.
Corollary 2. Let N ≥1, K ≥3, and K | N, and let n = N/K. If a (mixed)
strategy ξ of B(N, K) is an equilibrium strategy of B(N, K) then
1. spec(ξ) ∈conv(un
O, un
E) (in the case of K even).
2. spec(ξ) ∈{λun
O + (1 −λ)un
E : λ ∈[1/K, 1]} (in the case of K odd and N
odd).
3. spec(ξ) ∈{(1 −λ)un
O + λun
E : λ ∈[1/K, 1]} (in the case of K odd and N
even).
In particular, it follows from Corollary 2 that a probability that an equiprob-
ably picked battleﬁeld receives a given number of units of resources must the
same for all even numbers in {0, . . . , 2N/K} and must be the same for all odd
numbers in {0, . . . , 2N/K}. Moreover, the maximal number of units of resources

The Spectrum of Equilibria for the Colonel Blotto
305
assigned with positive probability to a battleﬁeld by an equilibrium strategy is
2N/K. Given a strategy, checking whether this criteria is satisﬁed can be done
in linear time (with respect to the size of the strategy). Moreover, in the case
of Colonel Lotto game, the criteria is both suﬃcient and necessary. Hence, in
this case, we have a simple method for deciding whether a given strategy is an
equilibrium strategy in the game. Notice that such a method is not provided by
the algorithm of Ahmedinejad et al. [1], because the algorithm ﬁnds only some
equilibria of the game (in particular, their support must be polynomial). Hence
to use the algorithm for this purpose, we would have to ﬁnd the equilibrium
strategies, use them to compute the value of the game, and then check whether
the given strategy guarantees the payoﬀnot less than the value against all the
strategies of the opponent.
4
Conclusions
This paper studied equilibrium strategies of (symmetric and discrete) Colonel
Blotto game. We introduced the notion of spectrum of strategies in this game and
provided complete characterization of spectra of equilibria for the cases where
the number of battleﬁelds divides the number of units of resources a player has.
We showed that the spectra are suitable convex combinations of two extreme
distributions: one, that mixes uniformly on odd numbers of units of resources
and another one, that mixes uniformly on even numbers.
References
1. Ahmadinejad, A., Dehghani, S., Hajiaghayi, M., Lucier, B., Mahini, H., Seddighin,
S.: From duels to battleﬁelds: computing equilibria of Blotto and other games.
In: Schuurmans, D., Wellman, M.P. (eds.) Proceedings of the Thirtieth AAAI
Conference on Artiﬁcial Intelligence, 12–17 February 2016, Phoenix, Arizona, USA,
pp. 376–382. AAAI Press (2016)
2. Aspnes, J., Chang, K., Yampolskiy, A.: Inoculation strategies for victims of viruses
and the sum-of-squares partition problem. J. Comput. Syst. Sci. 72(6), 1077–1093
(2006)
3. Behnezhad, S., Dehghani, S., Derakhshan, M., HajiAghayi, M., Seddighin, S.:
Faster and simpler algorithm for optimal strategies of blotto game. In: Singh, S.P.,
Markovitch, S. (eds.) Proceedings of the Thirty First AAAI Conference on Artiﬁ-
cial Intelligence, 4–9 February 2017, San Francisco, California, USA, pp. 369–375.
AAAI Press (2017)
4. Blackett, D.: Some blotto games. Naval Res. Logist. Q. 1(1), 55–60 (1954)
5. Borel, ´E.: La Th´eorie du Jeu et les ´Equations Int´egrales `a Noyau Sym´etrique.
Comptes Rendus de l’Acad´emie des Sci. 173, 1304–1308 (1921). Translated by
Savage, L.J.: The theory of play and integral equations with skew symmetric ker-
nels. Econometrica 21 97–100 (1953)
6. Cerdeiro, D., Dziubi´nski, M., Goyal, S.: Individual security and network design.
In: Proceedings of the Fifteenth ACM Conference on Economics and Computation,
EC 2014, pp. 205–206. ACM, New York (2014)

306
M. Dziubi´nski
7. Chia, P.H., Chuang, J.: Colonel Blotto in the phishing war. In: Baras, J.S., Katz,
J., Altman, E. (eds.) GameSec 2011. LNCS, vol. 7037, pp. 201–218. Springer,
Heidelberg (2011). doi:10.1007/978-3-642-25280-8 16
8. Dziubi´nski, M., Goyal, S.: How do you defend a network? Theor. Econ. 12(1),
331–376 (2017)
9. Gross, O., Wagner, A.: A continuous Colonel Blotto game. RM-408, RAND Cor-
poration, Santa Monica, CA (1950)
10. Hart, S.: Discrete Colonel Blotto and General Lotto games. Int. J. Game Theory
36, 441–460 (2008)
11. Immorlica, N., Kalai, A., Lucier, B., Moitra, A., Postlewaite, A., Tennenholtz, M.:
Dueling algorithms. In: Proceedings of the Forty-Third Annual ACM Symposium
on Theory of Computing, STOC 2011, pp. 215–224. ACM, New York (2011)
12. Kiekintveld, C., Jain, M., Tsai, J., Pita, J., Ord´o˜nez, F., Tambe, M.: Comput-
ing optimal randomized resource allocations for massive security games. In: Pro-
ceedings of the 8th International Conference on Autonomous Agents and Multi-
agent Systems, AAMAS 2009, vol. 1, pp. 689–696. International Foundation for
Autonomous Agents and Multiagent Systems, Richland, SC (2009)
13. Kovenock, D., Roberson, B.: Conﬂicts with multiple battleﬁelds. In: Garﬁnkel, M.,
Skaperdas, S. (eds.) Oxford Handbook of the Economics of Peace and Conﬂict.
Oxford University Press, Oxford (2012)
14. Laslier, J.F., Picard, N.: Distributive politics and electoral competition. J. Econ.
Theory 103(1), 106–130 (2002)
15. Macdonell, S., Mastronardi, N.: Waging simple wars: a complete characterization
of two-battleﬁeld blotto equilibria. Econ. Theor. 58(1), 183–216 (2015)
16. Roberson, B.: The Colonel Blotto game. Econ. Theor. 29(1), 1–24 (2006)
17. Szentes, B., Rosenthal, R.: Three-object two-bidder simultaneous auctions: chop-
sticks and tetrahedra. Games Econ. Behav. 44(1), 114–133 (2003)
18. Tambe, M.: Security and Game Theory: Algorithms, Deployed Systems, Lessons
Learned. Cambridge University Press, Cambridge (2011)

On Proportional Allocation in Hedonic Games
Martin Hoefer1 and Wanchote Jiamjitrak2(B)
1 Institute for Computer Science, Goethe University Frankfurt, Frankfurt, Germany
mhoefer@cs.uni-frankfurt.de
2 Department of Computer Science, Aalto University, Espoo, Finland
wanchote.jiamjitrak@aalto.fi
Abstract. Proportional allocation is an intuitive and widely applied
mechanism to allocate divisible resources. We study proportional allo-
cation for proﬁt sharing in coalition formation games. Here each agent
has an impact or reputation value, and each coalition represents a joint
project that generates a total proﬁt. This proﬁt is divided among the
agents involved in the project based on their reputation. We study exis-
tence, computational complexity, and social welfare of core-stable states
with proportional sharing.
Core-stable states always exist and can be computed in time O(m log
m), where m is the total number of projects. Moreover, when proﬁts have
a natural monotonicity property, there exists a reputation scheme such
that the price of anarchy is 1, i.e., every core-stable state is a social opti-
mum. However, these schemes exhibit a strong inequality in reputation
of agents and thus imply a lacking fairness condition. Our main results
show a tradeoﬀbetween reputation imbalance and the price of anarchy.
Moreover, we show lower bounds and computational hardness results on
the reputation imbalance when prices of anarchy and stability are small.
1
Introduction
Proﬁt sharing is a central domain in game theory and has attracted a large
amount of interest, mostly as cooperative transferable-utility (TU) games. Usu-
ally, there are n agents, and a characteristic function speciﬁes the proﬁt for each
subset of agents. The goal is to divide the proﬁt of the grand coalition in a fair
and stable way. There has been particular interest in TU games resulting from
combinatorial optimization problems. For example, in the matching game [20]
each agent is a node in an edge-weighted graph, and the proﬁt of a subset of
agents is the max-weight matching in the induced subgraph. For these games,
there is a large variety of stability and fairness concepts, most prominently vari-
ants of the core. In fact, the core of a matching game might be empty, and the
(approximate) core enjoys a close connection to the natural integer program of
max-weight matching [9].
An underlying assumption is that (deviating) subsets of agents can freely
negotiate shares and distribute proﬁt. In many application contexts, however,
This work was done while the authors were at Saarland University. Supported by
DFG Cluster of Excellence MMCI at Saarland University.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 307–319, 2017.
DOI: 10.1007/978-3-319-66700-3 24

308
M. Hoefer and W. Jiamjitrak
proﬁt shares are less directly negotiable, e.g., when allocating credit for joint
work. For example, in scientiﬁc publishing, credit is assigned based on a variety
of aspects and rules, such as reputation, visibility, previous achievements, etc.
Moreover, collaborative online platforms (recommendation systems, Wikis, etc.)
can design and implement centralized rules for credit allocation among the users.
In this paper, we study natural and simple proportional allocation rules to
distribute proﬁt or credit among agents that engage in joint projects. Propor-
tional allocation is a central approach in a variety of contexts and has been stud-
ied, e.g., for allocating divisible goods in mechanism design [6,8,15]. It can be
used to express consequences of rich-get-richer-phenomena (also termed Matthew
eﬀect), was studied to distribute proﬁts in stable matching [1], or appeared in
probabilistic models for allocating scientiﬁc credit [16]. Moreover, proportional
response dynamics are a successful method to compute market equilibria [4,22].
We study the properties of the proportional allocation mechanism in match-
ing and coalition formation games. In this scenario, coalitions represent joint
projects that agents can engage in. Each project yields a proﬁt value, which is
shared among the involved agents in proportion to an agent-speciﬁc parameter
ru. Intuitively, this parameter speciﬁes the inﬂuence of the agent. Depending on
the application context, it captures its, e.g., importance, visibility, or reputation.
It might result from previous achievements (e.g., by reputation in societies) or
be subject to design (e.g., by assignment in collaborative online systems).
Given such a proﬁt sharing scheme, agents strategically choose the projects
to engage in. More formally, a given set projects, proﬁt values, and agent reputa-
tions constitutes a hedonic coalition formation game [10], where the proportional
allocation mechanism yields the agent utilities. Our goal is to shed light on the
equilibria of such games, i.e., existence, structure and social welfare of core-stable
states. More precisely, we are interested in the structure of reputation values and
the resulting prices of anarchy and stability.
Contribution and Overview. In Sect. 2, we observe that in our games, a core-
stable state always exists. This is mostly a consequence of earlier work on stable
matching [1]. Let k and kmin be the size of the largest and smallest project with
non-zero proﬁt in the game, respectively. For equal sharing (all inﬂuences the
same), prices of anarchy and stability are Θ(k). In fact, if proﬁts and inﬂuences
are misaligned in a worst-case fashion, it is known that prices of anarchy and
stability can be unbounded, even for the special case of matching [1].
In Sect. 3, we consider games with a natural monotonicity condition (termed
inclusion-monotone), where we ﬁnd an interesting trade-oﬀbetween the required
diﬀerence in inﬂuence and price of anarchy. When the ratio of maximum and
minimum inﬂuence is bounded by α, there are reputations such that the price of
anarchy is bounded by max{1, k2/(k−1+αkmin/n)}, where kmin is the size of the
smallest project with non-zero proﬁt in the game. When α = (k2 −k + 1)n/kmin,
the price of anarchy drops to – with a suitable assignment of inﬂuence, we can
eliminate any ineﬃciency in the game. For environments, in which assigning
inﬂuence values is possible, we also provide an eﬃcient algorithm that, given an

On Proportional Allocation in Hedonic Games
309
optimum state S∗, computes inﬂuence values that achieve this bound on the price
of anarchy. While ﬁnding an optimum solution can be NP-hard, our algorithm
can also work with an arbitrary ρ-approximative state S, and the price of anarchy
bound increases by a factor ρ. Note that the natural representation of our games
is linear in the number of agents n and the number of projects/coalitions m,
since we must specify a possibly arbitrary positive proﬁt value for each possible
project. Our algorithm runs in time polynomial in n and m. Consequently, it is
strongest if m = poly(n) (which is often the case, e.g., for matching games).
On the downside, when approaching a price of anarchy of 1, the society
becomes extremely hierarchical – the maximum diﬀerence in inﬂuences grow
exponentially large. In Sect. 4 we show that for inclusion-monotone games a
factor diﬀerence of n−1 in inﬂuences can be required to obtain a price of stability
of 1. If the proﬁts of projects in a core-stable optimum should be shared equally,
we strengthen this to an exponential lower bound of (k + 1)n/kmin−1. Moreover,
for games that are not inclusion-monotone, ineﬃciency of all core-stable states
can be unavoidable.
Finally, in Sect. 5 we discuss computational hardness results. For a given
optimal state S∗and a given upper bound α on the ratio of inﬂuences, it is
NP-hard to decide whether we can make S∗stable, even if every project has
size k = 2. Note that this hardness does not stem from computing S∗, since S∗
is a max-weight matching when k = 2, which can be computed in polynomial
time. We also show lower bounds and hardness results for the case with inﬂuence
values in {1, x} with x > 1, where agents have either “low” or “high” inﬂuence.
Due to space constraints, further proofs can be found in the appendix of the
full version of this paper.
Further Related Work. Computing stability concepts in hedonic coalition
formation games is a recent line of research [7,12,17–19]. Many stability concepts
are NP- or PLS-hard to compute. This holds even in the case of additive-separable
coalition proﬁts, which can be interpreted by an underlying graph structure with
weighted edges, and the proﬁt of a coalition is measured by the total edge weights
covered by the coalition [3,11,21]. The price of anarchy was studied, e.g., in [5].
Our work is inspired by proportional allocation mechanisms. The model we
study was proposed for stable matching in [1] under the name Matthew-eﬀect
sharing. We study general hedonic coalition formation games. While the results
in [1] bound prices of anarchy and stability for worst-case proﬁt and inﬂuence
values, our approach here is to study the necessary inherent trade-oﬀs in social
welfare in equilibrium and inequality of inﬂuence in the population. In this sense,
our paper is closely related to [14], who study the trade-oﬀs between social
welfare and diﬀerence in proﬁt shares. A drawback of [14] is that it allows to
design arbitrary proﬁt shares for every coalition and every agent. Thus, it allows a
designer an unnatural amount of freedom when assigning credit to stabilize good
states. In contrast, our approach with proportional sharing based on inﬂuence
and reputation represents a more restricted, structured and arguably realistic
way of how credit from joint projects might be allocated to agents.

310
M. Hoefer and W. Jiamjitrak
2
Model and Preliminaries
A proportional coalition formation game is a hedonic coalition formation game
based on a weighted hypergraph G = (V, C, w). There is a set V of agents (or
vertices) and a set of weighted coalitions (or hyperedges) C ⊆2V , where |c| ≥2
for every c ∈C. Let w : C →R+ represent the positive weight or total proﬁt
of each coalition c ∈C. Unless stated otherwise, we use n = |V |, m = |C|,
k = maxc∈C |c| (the maximum size of any coalition in C), and kmin = minc∈C |c|
(the minimum size of any coalition in C).
Each agent v ∈V has a reputation rv > 0, which we scale throughout to
satisfy minv∈V rv = 1. When a coalition c ∈C is formed, the proﬁt w(c) is
shared among the v ∈c proportionally to rv. We deﬁne a reputation scheme as
a vector of reputations for the agents R = (rv)v∈V .
A coalition structure or state S ⊆C is a collection of pairwise disjoint coali-
tions c from C, i.e., for each v ∈V we have |{c | c ∈S, v ∈c}| ≤1. For each
coalition c ∈S, the proﬁt of agent u ∈c is a proportional share of weight w(c):
pu(S) = pu(c) =
ru

v∈c rv
· w(c)
(1)
Note that pu(c) > 0 for all c ∈C and u ∈c by deﬁnition. For every agent u ∈V
such that S contains no coalition that includes u, we assume pu(S) = 0.
For a coalition structure S, a blocking coalition c ∈C \ S is a coalition
such that, for each v ∈c, pv(c) > pv(S). Every agent in c gains strictly more
proﬁt than he currently obtains in S if they deviate to c instead. In the case
of matching and k = 2, we speak of a blocking pair. A coalition structure S is
termed core-stable if there is no blocking coalition in1 C \ S.
To assess the quality of reputation schemes, we quantify the social welfare
of the resulting core-stable coalition structures. The social welfare of a coalition
structure S is w(S) := 
c∈S w(c). We call the coalition structure S∗with the
highest social welfare the optimal coalition structure. We measure the quality of
reputation schemes using the prices of anarchy (PoA) and stability (PoS) of core-
stable coalition structures. While the core-stable coalition structures depend on
reputations, the optimal coalition structures (and hence, optimal social welfare)
do not. Consequently, our goal is to measure the quality of reputation schemes
based on PoA and PoS. In particular, we strive to design reputations to maximize
social welfare of the resulting core-stable coalition structures.
It turns out that we can obtain very small PoA and PoS using a hierarchy
of reputations with extremely large diﬀerences, which is often undesirable due
to reasons of fairness and equality. As a consequence, we try to limit unequal
reputations and, in particular, strive to quantify the tension between eﬃciency
and equality. We measure the degree of equality using a parameter as follows. A
reputation scheme R is α-bounded if α ≥maxv∈V rv
minv∈V rv = maxv∈V rv. Intuitively, a
smaller α indicates that reputation is more uniform reputation.
1 Core-stability usually means that no subset of agents wants to deviate. We recover
this interpretation when we assume all coalitions c ∈2V \ C have proﬁt w(c) = −1.

On Proportional Allocation in Hedonic Games
311
A simple solution to achieve perfect equality is when every agent has the
same reputation. This results in equal sharing, and it results in PoA (and PoS)
of at most k, where k is the size of the largest coalition. The following result is
shown, e.g., in [2, Theorem 2.9, Corollary 8.2]. In the full version of this paper,
we include a proof for completeness and discuss an example game.
Proposition 1. The PoA and the PoS in hedonic coalition formation games
with equal sharing is exactly k.
Some of our results apply to instances with an additional property. A game
G = (V, C, w) is inclusion monotone if for any c, c′ ∈C with c′ ⊊c, we have
w(c)
|c|
>
w(c′)
|c′| . Note that, trivially, every instance of matching with k = 2 is
inclusion monotone.
3
Existence and Computation
Let us ﬁrst discuss our existence and computational results. We deﬁne an
improvement step for a coalition structure S by adding a blocking coalition to S
while removing all coalitions that intersect with it from S. It can be seen rather
directly that every game has a (strong) lexicographical potential function. As a
consequence, a core-stable coalition structure exists in every game and for every
reputation scheme, and every sequence of improvement steps always converges.
By considering coalitions in non-increasing order of
w(c)

u∈c ru , it is possible to
arrive at a core-stable structure from any initial structure in at most n steps.
The proof is a rather direct extension of [1, Theorem 8], and we include it in the
full version of this paper for completeness.
Proposition 2. For any game G = (V, C, w) and proportional sharing based on
reputation scheme R, there always exists a core-stable coalition structure. Given
any initial coalition structure, we need at most O(n) improvement steps to reach
a core-stable coalition structure.
Hence, for any game and any reputation scheme we have both existence and
convergence, but it might be the case that every core-stable coalition structure
has small social welfare or reputations are extremely diﬀerent. The subsequent
algorithm shows how reputation schemes can provide a trade-oﬀbetween α-
boundedness and the PoA. For a given inclusion-monotone instance and a para-
meter α > 1, the algorithm provides a reputation scheme that is α-bounded and
guarantees a PoA of strictly better than k.
When α = 1, we have equal sharing, the price of anarchy is at most k (due
to Proposition 1) and a greedy procedure computes the O(n) improvement steps
to reach a core-stable state (due to Proposition 2). Algorithm 1 generalizes this
approach to obtain improved bounds for α > 1. It uses a similar structure as a
corresponding algorithm in [14]. In each iteration, we choose one coalition to be
a part of our solution and assign the reputation to each agent in this coalition,
then remove the agents from consideration. Let c be a coalition with the largest
ratio of
w(c)
|c|−1+x, where x = αkmin/n. There are three cases in the ith iteration:

312
M. Hoefer and W. Jiamjitrak
Algorithm 1. Computing a reputation scheme for given α
Input: Inclusion monotone G = (V, C, w), optimal structure S∗, bound α
Output: α-bounded reputation scheme R, core-stable coalition structure S
1 Initialize i ←0, C0 ←C, S ←∅, x ←αkmin/n and rv ←0 for all v ∈V
2 while Ci ̸= ∅do
3
c ←arg maxc∈Ci(
w(c)
|c|−1+x)
4
if c ∈S∗then s∗
i ←c
5
else if c /∈S∗and
w(c)
|c|−1+x < w(c′)
|c′|
for some c′ ∈S∗that c′ ∩c ̸= ∅then
6
c′ ←arg maxc′∈S∗( w(c′)
|c′| )
7
s∗
i ←c′
8
else s∗
i ←c
9
for u ∈s∗
i do ru ←xi
10
S ←S ∪s∗
i
11
Ci+1 ←Ci
12
for c ∈Ci with c ∩s∗
i ̸= ∅do Ci+1 ←Ci+1 \ {c}
13
i ←i + 1
14 for v ∈V with rv = 0 do rv ←xi
1. If c is a part of the optimal coalition structure S∗, we call it s∗
i .
2. If c is not in S∗and is overlapping with some coalitions in S∗, then we consider
c′ in S∗such that c′ has the highest ratio of
w(c′)
|c′|
among all overlapping
coalitions. If c′ is large enough to stabilize, we will choose c′ instead of c in
order to make our solution closest to S∗as much as possible. So we call c′
as s∗
i .
3. If c is not in S∗, but c has a high ratio of
w(c)
|c|−1+x so that we should stabilize
c instead of stabilizing a coalition from the optimal coalition structure, then
we choose c to be s∗
i .
Then, we stabilize s∗
i by assigning the same reputation to each included agent.
This reputation increases by the factor of x in the next iteration. Then we
remove all the agents in s∗
i and their incident coalitions from consideration. The
algorithm terminates when there is no coalition left to consider.
Theorem 1. For a given inclusion-monotone instance, and given α > 1 and
any optimal coalition structure S∗, Algorithm 1 computes in polynomial time an
α-bounded reputation scheme R with PoA at most max{1, k2/(k −1 + αkmin/n)}
and a core-stable coalition structure S that achieves both bounds.
Proof. We ﬁrst consider the running time. The algorithm sorts all coalitions by
the ratio of
w(c)
|c|−1+x, which takes O(m log m) time. Then, in each iteration we
only consider one coalition and its overlapping coalitions, which can be done
in O(m) time. In total, the running time is bounded by O(m2). Recall from
the discussion in the introduction that the input size is Ω(n + m), hence the
algorithm runs in polynomial time.

On Proportional Allocation in Hedonic Games
313
We now show core-stability of S. As the invariant of the algorithm we main-
tain that coalitions dropped from consideration will never form any blocking
coalition. This holds since we assign reputations that increase by a factor of x
in every iteration. Consider three cases as in the algorithm,
1. In the ﬁrst case, since c is the coalition that has the maximum ratio of
w(c)
|c|−1+x,
we assign the same reputation to each agent in c, and each agent gets a proﬁt
of w(c)
|c| . Consider an overlapping coalition c′, and let u ∈c′ ∩c. There are
two subcases: (1) c′ is a proper subset of c. Since the instance is inclusion
monotone and we share proﬁt equally in the coalition, we have
pu(c′) = w(c′)
|c′|
< w(c)
|c|
= pu(c).
(2) There is an agent v ∈c′ \ c who has a reputation rv ≥xru. Then the
proﬁt u ∈c ∩c′ gains from c′ is
pu(c′) ≤
w(c′)
|c′| −1 + x ≤
w(c)
|c| −1 + x < w(c)
|c|
= pu(c).
This shows that every u ∈c ∩c′ gains more proﬁt by staying with c.
2. In the second case, we choose c′ that is in S∗instead of c, each agent in c′
gains a proﬁt of w(c′)
|c′| . Consider an overlapping coalition c′′, and let u ∈c′′∩c′.
There are two subcases: (1) c′′ is a proper subset of c′. We apply the same
argument as in the ﬁrst subcase of the ﬁrst case. (2) There is an agent in
v ∈c′′ \ c′ who has a reputation rv ≥xru. Then, the proﬁt u ∈c′ ∩c′′ gains
from c′′ is
pu(c′′) ≤
w(c′′)
|c′′| −1 + x ≤
w(c)
|c| −1 + x < w(c′)
|c′|
= pu(c′).
This shows that every u ∈c′ ∩c′′ gains more proﬁt by staying with c.
3. In the third case, we can use the same analysis as in the ﬁrst case because we
choose the coalition that has the maximum ratio of
w(c)
|c|−1+x.
This concludes that the resulting state S is core-stable.
Now consider any arbitrary core-stable state S′ and coalition c added to S
in the ﬁrst round of the algorithm. Then agents u with ru = 1 are exactly the
ones in c, so every overlapping c′ ∈S′ is either a subset of c or has at least one
v ∈c′ \ c with rv ≥xru and no agent with reputation less than 1. Hence, the
strict inequalities above apply to all agents in c and imply that c is blocking.
Now suppose all coalitions added to S by our algorithm up to round i are in
S′, but c added in round i+1 is not. Then the agents with smaller reputation are
exactly the ones in the coalitions added in the ﬁrst i rounds. As such, they are
part of S and do not overlap with c. Hence, every overlapping coalition c′ ∈S′
is either a subset of c or has only agents with same or higher reputation and at
least one agent with rv ≥xru. Therefore, the strict inequalities above apply to

314
M. Hoefer and W. Jiamjitrak
all agents in c and imply that c is blocking. By induction, every core-stable state
must contain all coalitions of S, and S is the unique core-stable state.
For α-boundedness, observe that the minimum reputation in R is always 1.
In each iteration, we add one coalition to S with size at least kmin, so there are
at most n/kmin iterations. As a consequence, the maximum reputation is at most
xn/kmin = α, i.e., R is α-bounded.
Finally, for the PoA, we see that the solution S of Algorithm 1 deviates from
S∗only in iterations that apply the third case, when c /∈S∗and
w(c)
|c|−1+x ≥w(c′)
|c′|
for all c′ ∈S∗. c can intersect at most |c| other coalitions c′ ∈S∗, hence
PoA ≤|c| · w(c′)
w(c)
≤
|c| · w(c′)
(|c| −1 + x) · w(c′)
|c′|
=
|c| · |c′|
|c| −1 + x ≤
k2
k −1 + αkmin/n .
This proves the theorem.
⊓⊔
The algorithm reveals a trade-oﬀbetween α and PoA. By increasing α, the
guaranteed PoA decreases and vice-versa. While the algorithm itself runs in
polynomial time, it uses S∗as input, which is NP-hard to compute (ﬁnding S∗
trivially generalizes, e.g., the standard Set-Packing problem). Hence, the above
trade-oﬀmostly applies in terms of existence.
Interestingly, the algorithm also yields a trade-oﬀin terms of (overall) eﬃcient
computation. Our analysis of the social welfare of the output structure applies
w.r.t. to the social welfare of the input structure. Consequently, if Algorithm 1
is given any input structure S′, it will output a core-stable coalition structure S
with social welfare at least w(S) ≥w(S′) · (k −1 + αkmin/n)/k2.
Corollary 1. If Algorithm 1 is applied using any coalition structure S′ that rep-
resents a ρ-approximation to the optimal social welfare, it computes an α-bounded
reputation scheme with PoA at most ρ · max{1, k2/(k −1 + αkmin/n)}.
4
Lower Bounds
In this subsection, we will show a number of lower bounds. Algorithm 1 applies
to games that are inclusion monotone, and it shows that we can always reduce
PoA to 1 if α is chosen large enough. Next, we will show that there are instances
that are not inclusion monotone, where for arbitrarily large α we cannot stabilize
an optimal coalition structure.
Proposition 3. There are classes of non-inclusion monotone instances such
that (1) every reputation scheme yields a PoS of at least 2 −
4
n+2; (2) every
α-bounded reputation scheme yields a PoS of at least (n −1 + α)/(1 + α).
The previous proposition shows that the trade-oﬀshown in Theorem 1 does not
apply in instances that are not inclusion monotone. The next result complements
the bound on α in Theorem 1 when PoS is 1.

On Proportional Allocation in Hedonic Games
315
1
1
2 + ϵ
Fig. 1. An instance that requires α ≥n −1 whenever PoS is 1 (in this case, n = 12)
Proposition 4. There is a class of inclusion-monotone instances where every
reputation scheme with PoS of 1 has α ≥n −1.
Proof. Consider an instance of the type depicted in Fig. 1. The instance G =
(V, C, w) consists of a clique of size n
2 (denoted by Kn/2). Every coalition/edge c
in Kn/2 has w(c) = 1. For each agent, we create an additional agent (called “leaf
agent”) and include a coalition with a clique agent of weight 1
2 + ϵ. The optimal
social welfare is n
2 ( 1
2 + ϵ), and S∗is composed of exactly the n/2 coalitions with
leaf agents. For PoS 1, we need to maximize the proﬁt of clique agents in S∗,
since they are the only ones with deviations. Hence, we can w.l.o.g. assign the
minimum reputation of ru = 1 to all leaf agents.
Let r1, r2, . . . , rn/2 be the reputations of clique agents. Consider ri and rj;
in order to avoid a blocking coalition with agents i and j, at least one of them
must gain at least as much proﬁt as in S∗. Assume i is such an agent, then
( 1
2 + ϵ) ·
ri
ri+1 ≥1 ·
ri
ri+rj . For ϵ →0, this implies rj ≥ri + 2. Since an inequality
of this form must hold for every pair {i, j} of clique agents, we have
max
i,j∈[ n
2 ]{ri −rj} ≥2(n/2 −1) = n −2.
Since ri ≥1 for all i = 1, . . . , n, this implies α = maxi ri ≥n −1.
⊓⊔
This lower bound for α is linear in n, but if we apply Algorithm 1 with k = kmin =
2 and postulate a PoA of 1, then we can only guarantee α ≤3n/2. Hence, in
general, our results leave signiﬁcant room for improvement. Note that the output
of Algorithm 1 has the property that in some (in fact, the unique) core-stable
coalition structure the proﬁts in each coalition are shared equally. For schemes
with this property we can show a drastically improved lower bound, which is

316
M. Hoefer and W. Jiamjitrak
asymptotically tight for constant k. Hence, to show existence and computation
of schemes with smaller inequality, we need substantially diﬀerent techniques.
A scheme R has equal sharing in stability if there is a core-stable coalition
structure S such that for every c ∈S we have ri = rj, for every i, j ∈c.
Proposition 5. There is a class of inclusion-monotone instances where every
scheme R with equal sharing in stability and PoS of 1 requires α ≥(k+1)
n
kmin −1.
5
Hardness Results
In this section, we consider computational hardness results that complement
our upper bounds in Sect. 3. Even in games with k = 2, in which an optimum
coalition structure S∗is a maximum-weight matching that can be computed in
polynomial time, there is no eﬃcient algorithm for computing R that makes S∗
core-stable and minimizes the inequality α.
Theorem 2. Given an optimal coalition structure S∗and given α ≥1, it is
NP-hard to decide whether there is an α-bounded reputation scheme such that
S∗is core-stable. It remains NP-hard even if every coalition has size exactly k,
for any k ≥2.
Proof. We will show a reduction from the Graph Coloring problem. First
consider the case when k = 2. For an instance of Graph Coloring given by an
unweighted graph G = (V, E) with V = {v1, . . . , vn}, we construct a game G′ =
(V ′, E′, w) as follows. Let V ′ = V1 ∪V2 with V1 = V and V2 = {vn+1, . . . , v2n},
and E′ = E1 ∪E2 with E1 = E and E2 = {{vi, vn+i} | i = 1, . . . , n}. We set
w(e) = 1 if e ∈E1 and w(e) = 1
2 + ϵ if e ∈E2, for an arbitrarily small constant
ϵ > 0. Hence, G′ is similar in spirit to Fig. 1 except we replace the clique by the
coloring instance G. The optimal coalition structure S∗= E2.
First assume G is ℓ-colorable. We show that there is an (2ℓ−1)-bounded
reputation scheme that can stabilize S∗in G′. By Proposition 4, any two adjacent
vertices in V1 must have a diﬀerence in reputations of at least 2, otherwise the
edge will be a blocking pair. So, if a vertex has ith color class in G, then assign
the corresponding agent a reputation of 2i−1 in G′. Finally, assign reputation 1
to all agents in V2. This reputation scheme makes S∗core-stable, and the proof
is identical to the one in Proposition 4.
Now assume there is a α∗-bounded reputation scheme R that makes S∗core-
stable. We show that G is α∗+1
2
-colorable. First, we convert R as follows:
1. Normalize all the reputations to satisfy mini ri = 1.
2. Change the reputations of all the leaf nodes to be 1.
3. For every normalized reputation value, if it is not an odd integer, decrease it
down to next lower odd integer.
It is obvious that after these three conversions, the scheme is still α∗-bounded.
Let us argue that the conversion also keeps S∗core-stable. Step 1 does not change
anything because scaling all reputations does not change any proﬁt shares. After

On Proportional Allocation in Hedonic Games
317
step 2, agents in V1 receive more proﬁt in S∗, so S∗remains core-stable. In step
3, any two agents that have a diﬀerence in their reputations of at least two, the
diﬀerence still remains at least two. Thus, S∗remains core-stable.
After the conversion, every agent in V1 has an odd integer as reputation.
Now, we just identify each odd integer with a color class. Since S∗is core-stable,
adjacent vertices in G must diﬀer in reputation by at least 2, i.e., belong to
diﬀerent color classes. Hence, G is α∗+1
2
-colorable. The result follows for k = 2.
To show that it remains NP-hard even if every coalition in the instance has
size exactly k, we reduce the coloring problem on graph G to hypergraph G′ as in
the previous reduction. Here, however, for each coalition in G′ we add k−2 more
agents that only belong to that coalition. Every coalition has the same weight
as in previous case. To stabilize S∗, we need ( 1
2 + ϵ) ·
ri
ri+k−1 ≥1 ·
ri
ri+rj+k−2 for
every vi, vj ∈V1. This leads to rj ≥ri + k for any j > i. So, any two adjacent
vertices in V must have the diﬀerence in reputations of at least k (instead of 2
as above). Applying the reduction as above, we can stabilize S∗in G′ with an
α∗-bounded reputation scheme if and only if G is ( α∗+k−1
k
)-colorable.
⊓⊔
It shows that even approximating α∗is extremely hard, since the reduction
preserves the well-known approximation hardness of Graph Coloring [13].
Corollary 2. For any constant ϵ > 0, α∗cannot be eﬃciently approximated
within n1−ϵ unless NP = ZPP.
Let us also examine an interesting special case reputation scheme where we
are allowed only to assign “high” and “low” reputations. More formally, let
R ∈{1, x}n for some x > 1, where we call such schemes “restricted reputations”.
Unfortunately, the next theorem shows that ﬁnding a scheme with optimal α
remains NP-hard when we are given a bound W on social welfare of a core-stable
coalition structure (but not the exact optimum S∗). This is a weaker assumption
than providing an optimal coalition structure directly as in the previous theorem.
However, the result applies even for matching with k = 2, where existence of a
solution with welfare at least W can be decided in polynomial time. Hence, the
diﬃculty does not lie in ﬁnding a good coalition structure but it is again inherent
to the correct assignment of reputations.
Theorem 3. Given a positive rational number x > 1 and a bound on social
welfare W > 0, it is NP-hard to decide whether there exist restricted reputations
that results in a core-stable coalition structure S with w(S) ≥W. This holds
even for instances with k = 2.
Corollary 3. For both restricted and general reputations, the following problems
are NP-hard: (1) Given W > 0, ﬁnd the α-bounded core-stable coalition structure
S with minimum α such that w(S) ≥W; and (2) given α > 0, ﬁnd the α-bounded
core-stable coalition structure with maximum social welfare.
For restricted reputations, we might not be able to stabilize the optimal coalition
structure. The ﬁnal result lower bounds the PoS in terms of parameter x.

318
M. Hoefer and W. Jiamjitrak
Proposition 6. For x > 1, there are classes of instances such that for every
restricted reputation scheme R ∈{1, x}n (1) the PoS is at least
4
x+1; and (2)
the PoS is at least 2 −
4
x+3.
References
1. Anshelevich, E., Bhardwaj, O., Hoefer, M.: Friendship and stable matching. In:
Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013. LNCS, vol. 8125, pp. 49–60.
Springer, Heidelberg (2013). doi:10.1007/978-3-642-40450-4 5
2. Anshelevich, E., Hoefer, M.: Contribution games in networks. Algorithmica 63(1–
2), 51–90 (2012)
3. Aziz, H., Brandt, F., Seedig, H.G.: Computing desirable partitions in additively
separable hedonic games. Artif. Intell. 195, 316–334 (2013)
4. Birnbaum, B., Devanur, N., Xiao, L.: Distributed algorithms via gradient descent
for ﬁsher markets. In: Proceedings of 12th Conference Electronic Commerce (EC),
pp. 127–136 (2011)
5. Branzei, S., Larson, K.: Coalitional aﬃnity games and the stability gap. In: Pro-
ceedings of 21st International Joint Conference on Artiﬁcial Intelligence (IJCAI),
pp. 79–84 (2009)
6. Caragiannis, I., Voudouris, A.: Welfare guarantees for proportional allocations.
Theory Comput. Syst. 59(4), 581–599 (2016)
7. Cechl´arova, K.: Stable partition problem. In: Kao, M.-Y. (ed.) Encyclopedia of
Algorithms, pp. 1–99. Springer, New York (2008)
8. Christodoulou, G., Sgouritsa, A., Tang, B.: On the eﬃciency of the proportional
allocation mechanism for divisible resources. Theory Comput. Syst. 59(4), 600–618
(2016)
9. Deng, X., Ibaraki, T., Nagamochi, H.: Algorithmic aspects of the core of combina-
torial optimization games. Math. Oper. Res. 24(3), 751–766 (1999)
10. Dreze, J., Greenberg, J.: Hedonic coalitions: optimality and stability. Econometrica
48(4), 987–1003 (1980)
11. Gairing, M., Savani, R.: Computing stable outcomes in hedonic games. In:
Kontogiannis, S., Koutsoupias, E., Spirakis, P.G. (eds.) SAGT 2010. LNCS, vol.
6386, pp. 174–185. Springer, Heidelberg (2010). doi:10.1007/978-3-642-16170-4 16
12. Hajdukov´a, J.: Coalition formation games: a survey. Int. Game Theory Rev. 8(4),
613–641 (2006)
13. H˚astad, J.: Clique is hard to approximate within n1−ε. Acta Math. 182(1), 105–142
(1999)
14. Hoefer, M., Wagner, L.: Designing proﬁt shares in matching and coalition formation
games. In: Chen, Y., Immorlica, N. (eds.) WINE 2013. LNCS, vol. 8289, pp. 249–
262. Springer, Heidelberg (2013). doi:10.1007/978-3-642-45046-4 21
15. Johari, R., Tsitsiklis, J.: Eﬃciency loss in a resource allocation game. Math. Oper.
Res. 29(3), 407–435 (2004)
16. Kleinberg, J., Oren, S.: Mechanisms for (mis)allocating scientiﬁc credit. In: Pro-
ceedings of 43rd Symposium on Theory of Computing (STOC), pp. 529–538 (2011)
17. Peters, D.: Graphical hedonic games of bounded treewidth. In: Proceedings of 23rd
Conference on Artiﬁcial Intelligence (AAAI), pp. 586–593 (2016)
18. Peters, D.: Towards structural tractability in hedonic games. In: Proceedings of
23rd Conference on Artiﬁcial Intelligence (AAAI), pp. 4252–4253 (2016)

On Proportional Allocation in Hedonic Games
319
19. Peters, D., Elkind, E.: Simple causes of complexity in hedonic games. In Proceed-
ings of 24th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp.
617–623 (2015)
20. Shapley, L., Scarf, H.: On cores and indivisibility. J. Math. Econ. 1(1), 23–37 (1974)
21. Sung, S.-C., Dimitrov, D.: Computational complexity in additive hedonic games.
Eur. J. Oper. Res. 203(3), 635–639 (2010)
22. Zhang, L.: Proportional response dynamics in the ﬁsher market. Theor. Comput.
Sci. 412(24), 2691–2698 (2011)

Stable Marriage with Covering Constraints–A
Complete Computational Trichotomy
Matthias Mnich1,2 and Ildik´o Schlotter3(B)
1 Universit¨at Bonn, Bonn, Germany
mmnich@uni-bonn.de
2 Maastricht University, Maastricht, The Netherlands
3 Budapest University of Technology and Economics, Budapest, Hungary
ildi@cs.bme.edu
Abstract. We consider Stable Marriage with Covering Con-
straints (SMC): in this variant of Stable Marriage, we distinguish
a subset of women as well as a subset of men, and we seek a matching
with fewest number of blocking pairs that matches all of the distin-
guished people. We investigate how a set of natural parameters, namely
the maximum length of preference lists for men and women, the num-
ber of distinguished men and women, and the number of blocking pairs
allowed determine the computational tractability of this problem.
Our main result is a complete complexity trichotomy that, for each
choice of the studied parameters, classiﬁes SMC as polynomial-time solv-
able, NP-hard and ﬁxed-parameter tractable, or NP-hard and W[1]-hard.
We also classify all cases of one-sided constraints where only women may
be distinguished.
1
Introduction
The Stable Marriage (SM) problem is a fundamental problem ﬁrst studied
by Gale and Shapley [16] in 1962. An instance of SM consists of a set M of men,
a set W of women, and a preference list for each person ordering members of the
opposite sex. We aim to ﬁnd a stable matching, i.e., a matching for which there
exists no pair of a man and a woman who prefer each other to their partners
given by the matching; such a pair is called a blocking pair.
We consider a problem that we call Stable Marriage with Covering
Constraints (SMC). Here, a set W⋆of women and a set M⋆of men are
distinguished, and a feasible matching is one where each person in W⋆∪M⋆
gets matched. By the Rural Hospitals Theorem [17] we know that the set of
unmatched men and women is the same in all stable matchings, so clearly, feasi-
ble stable matchings may not exist. Thus, we deﬁne the task in SMC as ﬁnding
a feasible matching with a minimum number of blocking pairs. Somewhat sur-
prisingly, this natural extension of SM has not been considered before.
M. Mnich—Supported by ERC Starting Grant 306465 (BeyondWorstCase).
I. Schlotter—Supported by the Hungarian National Research Fund (OTKA grants
no. K-108383 and no. K-108947).
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 320–332, 2017.
DOI: 10.1007/978-3-319-66700-3 25

Stable Marriage with Covering Constraints
321
Motivation. Our main motivation for studying SMC—apart from its nat-
ural deﬁnition—is its close relationship with the Hospitals/Residents with
Lower Quota (HRLQ) problem, modelling a situation where medical residents
apply for jobs in hospitals: residents rank hospitals and vice versa, and hospitals
declare both lower and upper quotas which bound the number of residents they
can accept; the task is to ﬁnd an assignment with a minimum number of blocking
pairs. By “cloning” hospitals, HRLQ reduces to the case where each hospital has
unit upper quota. In fact, this is equivalent to the special case of SMC where
only women (or, equivalently, men) are distinguished. We refer to this problem
with one-sided covering constraints, linking SMC and HRLQ, as SMC-1.
The HRLQ problem and its variants have recently gained quite some inter-
est from the algorithmic community
[4,7,13,18,20,21,25,33,37]. In his book,
Manlove [29, Chap. 5.2] devotes an entire chapter to the algorithmics of HRLQ.
The reason for this interest in HRLQ is explained by its importance in several
real-world matching markets [14,15,35] such as school admission systems, cen-
tralized assignment of residents to hospitals, or of cadets to military branches.
Lower quotas are a common feature of such admission systems. Their purpose
is often to remedy the eﬀects of understaﬃng that are explained by the well-
known Rural Hospitals Theorem [17]: as an example, governments usually want
to assign at least a small number of medical residents to each rural hospital to
guarantee a minimum service level. Minimum quotas also appear in controlled
school choice programs [11,28,36] where students belong to a small number of
types; schools set lower bounds for each type enact aﬃrmative actions, such
as admitting a certain number of minority students [11]. Another example is
the German university admission system for admitting students to highly over-
subscribed subjects, where a certain percentage of study places are assigned
according to high school grades or waiting time [36]. But lower quotas may also
arise due to ﬁnancial considerations: for instance, a business course with too few
(tuition-paying) attendees may not be proﬁtable. Certain aspects of airline pref-
erences for seat upgrade allocations can be also modelled by lower quotas [28].
Another motivation for studying SMC comes from the following scenario that
we dub Control for Stable Marriage. Consider a two-sided market where each
participant of the market expresses its preferences over members of the other
party, and some central agent (e.g., a government) performs the task of ﬁnding
a stable matching in the market. It might happen that this central agency wishes
to apply a certain control on the stable matching produced: it may favour some
participants by trying to assign them a partner in the resulting matching. Such a
behaviour might be either malicious (e.g., the central agency may accept bribes
and thus favour certain participants) or beneﬁcial (e.g., it may favour those who
are at disadvantage, like handicapped or minority participants). However, there
might not be a stable matching that covers all participants the agency wants to
favour; thus arises the need to produce a matching that is as stable as possible
among those that fulﬁll our constraints—the most natural aim in such a case is
to minimize the number of blocking pairs in the produced matching, which yields
exactly the SMC problem. Similar control problems for voting systems have been

322
M. Mnich and I. Schlotter
extensively studied in social choice following the work initiated by Bartholdi
III. [3], but have not yet been considered in connection to stable matchings.
Our Results. We provide an extensive algorithmic analysis of the SMC prob-
lem, and its special case SMC-1. In our analysis, we examine the inﬂuence of
diﬀerent aspects on the tractability of these problems. The aspects we consider
are
– the number b of blocking pairs allowed,
– the number |W⋆| of women with covering constraint,
– the number |M⋆| of men with covering constraint,
– the maximum length ΔW of women’s preference lists, and
– the maximum length ΔM of men’s preference lists.
To investigate how these aspects aﬀect the complexity of SMC, we use the
framework of parameterized complexity, which deals with computationally hard
problems and focuses on how certain parameters of a problem instance inﬂuence
its tractability. We aim to design ﬁxed-parameter algorithms, which perform well
in practice if the value of the parameter on hand is small1.
The choice of the above aspects (or parameters) is motivated by the afore-
mentioned applications. For instance, we seek matchings where ideally no block-
ing pairs at all or at least only few of them appear, to ensure stability of the
matching and happiness of those getting matched. The number of women/men
with covering constraints corresponds, for instance, to the number of rural hos-
pitals for which a minimum quota speciﬁcally must be enforced, which we can
expect to be small among the set of all hospitals accepting medical residents.
Finally, preference lists of hospitals and residents can be expected to be small,
as each hospital might not rank many more candidates than positions it has to
ﬁll, whereas residents might rank only their top choices of hospitals. Hence, it is
reasonable to assume that these parameters take small values in certain appli-
cations, and thus suitable ﬁxed-parameter algorithms may be highly eﬃcient in
practice.
We draw a detailed landscape of the inﬂuence of each aspect, and all their
combinations, on the complexity of the SMC problem. To this end, we consider all
choices of aspects in A = {b, |W⋆|, |M⋆|, ΔM, ΔW} as either being restricted to
some constant integer, or regarded as a parameter, or left unbounded. Intuitively,
these diﬀerent choices for elements of A correspond to their expected “range” in
applications, from very small to mid-range to large (compared to the size of the
entire system). By considering all combinations, we can model all applications.
Our main result classiﬁes the SMC problem for all such combinations into
one of three cases, as being either “easy”, “moderate”, or “hard” to solve:
1 For background on parameterized complexity, we refer to the recent monograph [9].

Stable Marriage with Covering Constraints
323
Theorem 1. For each choice of aspects in A = {b, |W⋆|, |M⋆|, ΔM, ΔW}, SMC
is in P, or NP-hard and ﬁxed-parameter tractable, or NP-hard and W[1]-hard with
the given parameterization2, and is covered by one of the results in Table 1.
In particular, SMC is W[1]-hard parameterized by b + |W⋆|, even if there are
no distinguished men (i.e., |M⋆| = 0), ΔM = 3, ΔW = 3 and each distinguished
woman ﬁnds only a single man acceptable.
Table 1 summarizes our results on the complexity of SMC. Note that some results
are implied directly by the symmetrical roles of men and women in SMC, and
thus are not stated explicitly. Proofs marked by (⋆), as well as a decision diagram
showing that the presented results indeed cover all restrictions of SMC with
respect to {b, |W⋆|, |M⋆|, ΔM, ΔW}, can be found in the full version [32].
Table 1. Summary of our results for Stable Marriage with Covering Con-
straints. Here, Δ⋆denotes the maximum length of the preference list of any dis-
tinguished person.
Constants
Parameters
Complexity
|M⋆| = 0, |W⋆| = 0
P (Gale-Shapley alg.)
|M⋆| = 0, |W⋆|, ΔM
P (Theorem 8)
|M⋆|, |W⋆|, ΔM, ΔW
P (Theorem 8)
|M⋆| = 0, ΔM ≤2
P (Theorem 9)
ΔW ≤2, ΔM ≤2
P (Observation 11)
b
P (Observation 5)
|M⋆| = 0, ΔW ≤2, ΔM ≥3
NP-hard (Theorem 10)
|W⋆| = 1, ΔW ≤2, ΔM ≥3
NP-hard (Theorem 12)
|M⋆| = 0, ΔW ≥3, ΔM ≥3, Δ⋆= 1
b + |W⋆|
W[1]-hard (Theorem 2)
|M⋆| = 0, |W⋆| ≥1, ΔW ≥3, Δ⋆= 1
b + ΔM
W[1]-hard (Theorem 6)
ΔW ≤2
|W⋆| + |M⋆| FPT (Theorem 13)
ΔW ≤2
b
FPT (Corollary 2)
As a special case, we answer a question by Hamada et al. [20] who gave an
exponential-time algorithm that in time O(|I|b+1) decides for a given instance I
of HRLQ whether it admits a feasible matching with at most b blocking pairs3;
the authors asked whether HRLQ is ﬁxed-parameter tractable parameterized
by b. As shown by Theorem 1, SMC-1 and therefore also HRLQ is W[1]-hard
when parameterized by b, already in a very restricted setting. Thus, the answer
to the question by Hamada et al. [20] is negative: SMC-1, and hence HRLQ,
admits no ﬁxed-parameter algorithm with parameter b unless FPT = W[1].
2 Restrictions without parameters are classiﬁed as polynomial-time solvable or NP-
hard.
3 Hamada et al. claim only a run time O((|W||M|)b+1), but their algorithm can easily
be implemented to run in time O(|I|b+1).

324
M. Mnich and I. Schlotter
Related Work. There is a fast-growing body of literature on matching mar-
kets with lower quotas [4,7,13–15,18,20,21,25,33,37]. These papers study sev-
eral variants of HRLQ, adapting the general model to the various specialties
of practical problems. However, there are only a few papers which consider the
problem of minimizing the number of blocking pairs [14,20]. The most closely
related work to ours is that of Hamada et al. [20]: they prove that the HRLQ
problem is NP-hard and give strong inapproximability results; they also consider
the SMC-1 problem directly and propose an O(|I|b+1) time algorithm for it.
A diﬀerent line of research connected to SMC is the problem of arranged
marriages, an early extension of SM suggested by Knuth [26] in 1976. Here,
a set Q⋆of man-woman pairs is distinguished, and we seek a stable matching
that contains Q⋆as a subset. Thus, as opposed to SMC, we not only require
that each distinguished person is assigned some partner, but instead prescribe
its partner exactly. Initial work on arranged marriages [19,26] was extended by
Dias et al. [10] to consider also forbidden marriages, and was further generalized
by Fleiner et al. [12] and Cseh and Manlove [8]. Despite the similar ﬂavour, none
of these papers have a direct consequence on the complexity of SMC.
Our work also ﬁts the research line that addresses computationally hard
stable matching problems by focusing on instances with bounded preference
lists [6,22,24,27,34] or by studying their parameterized complexity [1,2,5,30,31].
2
Preliminaries
An instance I of the Stable Marriage (SM) problem consists of a set M
of men and a set W of women. Each person x ∈M ∪W has a preference
list L(x) that strictly orders the members of the other party acceptable for x.
We thus write L(x) as a vector L(x) = (y1, . . . , yt), denoting that yi is (strictly)
preferred by x over yj for each i and j with 1 ≤i < j ≤t. A matching M
for I is a set of man-woman pairs appearing in each other’s preference lists
such that each person is contained in at most one pair of M; some persons may
be left unmatched by M. For each person x we denote by M(x) the person
assigned by M to x. For a matching M, a man m and a woman w included in
each other’s preference lists form a blocking pair if (i) m is either unmatched or
prefers w to M(m), and (ii) w is either unmatched or prefers m to M(w). In the
Stable Marriage with Covering Constraints (SMC) problem, we are
given additional subsets W⋆⊆W and M⋆⊆M of distinguished people that
must be matched; a matching M is feasible if it matches everybody in W⋆∪M⋆.
The objective of SMC is to ﬁnd a feasible matching for I with minimum number
of blocking pairs. If only people from one gender are distinguished, then w.l.o.g.,
we assume these to be women; this special case will be denoted by SMC-1.
The many-to-one extension of SMC-1 is the Hospitals/Residents with
Lower Quotas (HRLQ) problem whose input consists of a set R of residents
and a set H of hospitals that have ordered preferences over the acceptable mem-
bers of the other party. Each hospital h ∈H has a quota lower bound q(h)
and a quota upper bound q(h). One seeks an assignment M that maps a subset

Stable Marriage with Covering Constraints
325
of the residents to hospitals that respects acceptability and is feasible, that is,
q(h) ≤|M(h)| ≤q(h) for each hospital h. Here, M(h) is the set of residents
assigned to some h ∈H by M. We say that a hospital h is under-subscribed if
|M(h)| < q(h). For an assignment M of an instance of HRLQ, a pair {r, h} of a
resident r and a hospital h is blocking if (i) r is unassigned or prefers h to the
hospital assigned to r by M, and (ii) h is under-subscribed or prefers r to one of
the residents in M(h). The task in HRLQ is to ﬁnd a feasible assignment with
minimum number of blocking pairs.
Some instances of SMC may admit a master list over women, which is a
total ordering LW of all women, such that for each man m ∈M, the preference
list L(m) is the restriction of LW to those women that m ﬁnds acceptable.
Similarly, we consider master lists over men.
With each instance I of SMC (or HRLQ) we can naturally associate a bipar-
tite graph GI whose vertex partitions correspond to M and W (or R and H,
respectively), and there is an edge between a man m ∈M and a woman w ∈W
(or between a resident r ∈R and a hospital h ∈H, respectively) if they appear
in each other’s preference lists. We may refer to entities of I as vertices, or a
pair of entities as edges, without mentioning GI explicitly.
3
Strong Parameterized Intractability of SMC
This section shows parameterized intractability and inapproximability results
for ﬁnding feasible matchings with minimum number of blocking pairs. A funda-
mental hypothesis about the complexity of NP-hard problems is the Exponential
Time Hypothesis (ETH), which stipulates that algorithms solving all Satisfia-
bility instances in subexponential time cannot exist [23].
Theorem 2 (⋆). SMC-1 is W[1]-hard parameterized by b + |W⋆|, and cannot
be solved in time f ′(b) · no(
√
b) for any computable function f ′ unless ETH fails,
even if there is a master list over men as well as one over women, all preference
lists are of length at most 3, and |L(w)| = 1 for each woman w ∈W⋆.
4
Polynomial-Time Approximation
Theorem 3 (⋆). Let I be an instance I of HRLQ, qΣ the sum of lower quota
bounds taken over all hospitals in I, and ΔR the maximum length of residents’
preference lists. There is an algorithm that in polynomial time either outputs a
feasible assignment for I with at most (ΔR −1)qΣ blocking pairs, involving only
qΣ residents, or concludes that no feasible assignment exists.
If both ΔR and qΣ are constant, then Theorem 3 implies that HRLQ
becomes polynomial-time solvable: if b ≥(ΔR −1)qΣ, then we apply Theorem 3
directly; if b < (ΔR −1)qΣ, then we use the algorithm by Hamada et al. [20]
running in time O(|I|b+1) which is polynomial, since b is upper-bounded by a
constant.

326
M. Mnich and I. Schlotter
Corollary 1. HRLQ with both the maximum length ΔR of residents’ prefer-
ence lists and the total sum qΣ of all lower quotas constant, is polynomial-time
solvable.
Another application of Theorem 3 is an approximation algorithm that works
regardless of whether ΔR or qΣ is a constant. In fact, the algorithm of Theorem 3
can be turned into a (ΔR−1)qΣ-factor approximation algorithm as follows. First,
ﬁnd a stable assignment Ms for I in polynomial time using the extension of the
Gale-Shapley algorithm for the Hospitals/Residents problem. If Ms is not
feasible, then by the Rural Hospitals Theorem [17], any feasible assignment for I
must admit at least one blocking pair; hence, the algorithm of Theorem 3 yields
an approximation with (multiplicative and also additive) factor (ΔR −1)qΣ.
We also state an analogue of Theorem 3 that deals with SMC: it handles
covering constraints on both sides, but assumes that all quota upper bounds
are 1:
Theorem 4 (⋆). There is an algorithm that in polynomial time either outputs a
feasible matching for an instance I of SMC with at most (ΔW −1)|M⋆|+(ΔM−
1)|W⋆| blocking pairs, or concludes that no feasible matching exists for I.
5
SMC with Bounded Number of Distinguished Persons
or Blocking Pairs
In Theorem 2 we proved W[1]-hardness of SMC-1 for the case where ΔM =
ΔW = 3, with parameter b + |W⋆|. Here we investigate those instances of SMC
and SMC-1 where the length of preference lists may be unbounded, but either b,
or the number of distinguished persons is constant.
First, if the number b of blocking pairs allowed is constant, then SMC can
be solved by simply running the extended Gale-Shapley algorithm after guess-
ing and deleting all blocking pairs. This complements the result by Hamada
et al. [20].
Observation 5. SMC can be solved in time O(|I|b+1), where b denotes the num-
ber of blocking pairs allowed in the input instance I.
In Theorem 6 we prove hardness of SMC-1 even if only one woman must be
covered. If we require preferences to follow master lists, then a slightly weaker
version of Theorem 6, where |W⋆| = 2, still holds.
Theorem 6 (⋆). SMC-1 is W[1]-hard parameterized by b + ΔM, even if W⋆=
{s}, ΔW = 3, and |L(s)| = 1.
Theorem 7 (⋆). SMC-1 is W[1]-hard parameterized by b + ΔM, even if there
is a master list over men as well as one over women, |W⋆| = 2, ΔW ≤3, and
|L(w)| = 1 for each w ∈W⋆.

Stable Marriage with Covering Constraints
327
To contrast our intractability results, we show next that if each of |W⋆|,
|M⋆|, ΔW, and ΔM is constant, then SMC becomes polynomial-time solvable.
Our algorithm relies on the observation that in this case, the number of blocking
pairs in an optimal solution is at most (ΔM −1)|W⋆| + (ΔW −1)|M⋆| by
Theorem 4. Note that for instances of SMC-1, Theorem 8 yields a polynomial-
time algorithm already if both |W⋆| and ΔM are constant.
Theorem 8 (⋆). SMC can be solved in time O(|I|(ΔM−1)|W⋆|+(ΔW−1)|M⋆|+1).
Importantly, restricting only three of the values |W⋆|, |M⋆|, ΔW, and ΔM to
be constant does not yield tractability for SMC, showing that Theorem 8 is tight.
Indeed, Theorem 6 implies that restricting the maximum length of the preference
lists on only one side still results in a hard problem: SMC remains W[1]-hard
with parameter b + ΔM, even if ΔW = 3, |W⋆| = 1, and |M⋆| = 0. Similarly,
Theorem 2 shows that the problem remains hard even if ΔW = ΔM = 3 and
|M⋆| = 0.
6
SMC with Preference Lists of Length at Most Two
We show that the restriction of SMC where the maximum length of preference
lists is bounded by 2 on one side leads to polynomial-time algorithms and ﬁxed-
parameter algorithms for various parameterizations.
Let I be an instance of SMC with underlying graph G. Let Ms be a stable
matching in I, and let M⋆
0 and W⋆
0 denote the set of distinguished men and
women, respectively, unmatched by Ms. Furthermore, let M0 and W0 denote
the set of all men and women, respectively, unmatched by Ms. A path P in G
is called an augmenting path, if MsΔP is a matching, and either both endpoints
of P are in M⋆
0 ∪W⋆
0, or one endpoint of P is in M⋆
0 ∪W⋆
0, and its other
endpoint is not distinguished. We will call an augmenting path P masculine or
feminine if it contains a man in M⋆
0 or a woman in W⋆
0, respectively; if P is
both masculine and feminine, then we call it neutral. If P is not neutral, we say
that it starts at the (unique) person from M⋆
0 ∪W⋆
0 it contains, and ends at its
other endpoint.
Covering Constraints on One Side. We give a polynomial-time algorithm
for SMC-1 when each man ﬁnds at most two women acceptable, and show NP-
hardness of SMC-1 even if each woman ﬁnds at most two men acceptable.
Theorem 9. There is a polynomial-time algorithm for the special case of SMC-1
where each man ﬁnds at most two women acceptable.
The main observation behind Theorem 9 is that if ΔM ≤2, then any two
augmenting paths starting from diﬀerent women in W⋆
0 can only intersect at their
endpoints. Thus, we can modify the stable matching Ms by selecting augmenting
paths starting from each woman in W⋆
0 in an almost independent fashion: intu-
itively, we simply need to take care not to choose paths sharing an endpoint—a

328
M. Mnich and I. Schlotter
task which can be managed by ﬁnding a bipartite matching in certain auxiliary
graph G′. To ensure that the number of blocking pairs in the output is mini-
mized, we will assign costs to the augmenting paths. The cost of an augmenting
path P roughly determines the number of blocking pairs introduced when mod-
ifying Ms along P (though certain special edges need not be counted); hence,
our problem reduces to ﬁnding a min-weight bipartite matching in G′.
To present the algorithm of Theorem 9 in detail, we start with the following
properties of augmenting paths which are easy to prove assuming that ΔM ≤2:
Proposition 1. Let P1 and P2 be augmenting paths starting at w1 and w2, resp.
If w1 ̸= w2, then P1 and P2 are either vertex-disjoint, or they both end at some
m ∈M0, with V (P1) ∩V (P2) = {m}. If there is an edge {m, w} of G (with
m ∈M and w ∈W) connecting P1 and P2, then m ∈M0 and P1 or P2 must
end at m. If w1 = w2 and P is the maximal common subpath of P1 and P2
starting at w1, then either V (P1) ∩V (P2) = V (P), or P1 and P2 both end at
some m ∈M0 and V (P1) ∩V (P2) = V (P) ∪{m}.
With a set P of edges (typically a set of augmenting paths) where Ms △P is a
matching, we associate a cost, which is the number of blocking pairs that Ms △P
admits. A pair {m, w} for some m ∈M and w ∈W is special, if m ∈M0 and w
is the second (less preferred) woman in L(m). As it turns out, such edges can be
ignored during certain steps of the algorithm; thus, we let the special cost of P
be the number of non-special blocking pairs in Ms △P.
Lemma 1 (⋆). For vertex-disjoint augmenting paths P1 and P2 with costs c1
and c2, resp., the cost of P1 ∪P2 is at most c1 +c2. Further, if the cost of P1 ∪P2
is less than c1+c2, then the following holds for {i1, i2} = {1, 2}: there is a special
edge {m, w} with Pi1 ending at m and w appearing on Pi2; moreover, {m, w} is
blocking in Ms △Pi2, but not in Ms △(P1 ∪P2).
We are ready to provide the algorithm, in a sequence of four steps.
• Step 1: Computing all augmenting paths. By Proposition 1, if we delete
M0 from the union of all augmenting paths starting at some w ∈W⋆
0, then we
obtain a tree. Furthermore, these trees are mutually vertex-disjoint for diﬀer-
ent starting vertices of W⋆
0. This allows us to compute all augmenting paths in
linear time, e.g., by an appropriately modiﬁed version of the DFS algorithm
(so that only augmenting paths are considered). During this process, we can
also compute the special cost of each augmenting path in a straightforward
way.
• Step 2: Constructing an auxiliary graph. Using the results of the compu-
tation of Step 1, we construct an edge-weighted single bipartite graph Gpath as
follows. The vertex set of Gpath is the union of W⋆
0 and M0 ∪{w′ | w ∈W⋆
0},
so for each woman w ∈W⋆
0 we create a corresponding new vertex w′. We
add an edge between w ∈W⋆
0 and m ∈M0 with weight c if there exists an
augmenting path with endpoints w and m having special cost c (and no such

Stable Marriage with Covering Constraints
329
path with lower special cost exists). Further, for each w ∈W⋆
0 we compute
the minimum special cost cmin
w
of any augmenting path starting at w and not
ending in M0, and add an edge between w and w′ with weight cmin
w
in Gpath.
• Step 3: Computing a minimum weight matching. We compute a match-
ing MP in Gpath covering W⋆
0 and having minimum weight. Observe that such
a matching corresponds to a set of augmenting paths P = {Pw | w ∈W⋆
0}
that are mutually vertex-disjoint by Proposition 1. Recall that the special cost
of Pw is the weight of the edge in MP incident to w.
• Step 4: Eliminating blocking special edges. In this step, we modify P
iteratively. We start by setting Pact = P. At each iteration we modify Pact as
follows. We check whether there exists a special edge {m∗, w∗} that is block-
ing in Ms △Pact. If yes, then notice that m∗is not matched in Ms △Pact,
because {m∗, w∗} is special and thus m∗∈M0. Let P be the path of Pact
containing w∗. We modify Pact by truncating P to its subpath between its
starting vertex and w∗, and appending to it the edge {m∗, w∗}. This way,
{m∗, w∗} becomes an edge of the matching Ms △Pact. The iteration stops
when there is no special edge blocking Ms △Pact. Note that once a special
edge ceases to be blocking in Ms △Pact, it cannot become blocking again dur-
ing this process, so the algorithm performs at most |M0| iterations. For each
w ∈W⋆
0, let P ∗
w denote the augmenting path in Pact covering w at the end of
Step 4; we deﬁne P∗= {P ∗
w | w ∈W⋆
0} and output the matching Ms △P∗.
This completes the description of the algorithm; we now provide its analysis.
Lemma 2 (⋆). Msol := Ms △P∗is a feasible matching for I, and the number
of blocking pairs for Msol is at most the weight of MP .
To show that our algorithm is correct and Msol is optimal, by Lemma 2 it
suﬃces to prove that the weight of MP is at most the number of blocking pairs
in M opt, an optimal solution in I. To this end, we deﬁne a matching covering W⋆
0
in Gpath whose weight is at most the number of blocking pairs in M opt.
Clearly, Ms △M opt contains an augmenting path Qw covering w for each
w ∈W⋆
0. If some Qw ends at a man m ∈M0, then clearly no other path
in Ms △M opt can end at m. Take the matching MQ in Gpath that includes all
pairs {m, w} where Qw ends at m ∈M0 for some w ∈W⋆
0. Also, we put {w, w′}
into MQ if Qw does not end at a man of M0. Note that MQ is indeed a matching.
It remains to show that the weight of MQ is at most the number of blocking
pairs in M opt. By deﬁnition, the weight of MQ is at most the sum of the special
costs of the paths Qw for every w ∈W⋆
0. By Lemma 1, any non-special blocking
pair in Ms △Qw remains a blocking pair in Ms △(
w∈W⋆
0 Qw), and hence in
M opt as well. Hence, there is a matching in Gpath with weight at most the
number of blocking pairs in an optimal solution, implying the correctness of our
algorithm. As the algorithm runs in polynomial time, Theorem 9 follows.
Contrasting Theorem 9, if men may have preference lists of length 3, SMC-1
(and hence SMC) is NP-hard even if each woman ﬁnds at most two men
acceptable.

330
M. Mnich and I. Schlotter
Theorem 10 (⋆). SMC-1 is NP-hard even if ΔW = 2 and ΔM = 3.
Covering Constraints on Both Sides. If max(ΔW, ΔM) ≤2, the graph
underlying the instance is a collection of paths and cycles, and therefore:
Observation 11. SMC with max(ΔW, ΔM) ≤2 is polynomial-time solvable.
Recall that the case where ΔW = 2 and ΔM = 3 is NP-hard by Theorem 10,
even if there are no distinguished men to be covered. However, switching the role
of men and women, Theorem 9 shows that if there are no women to be covered,
then ΔW ≤2 guarantees polynomial-time solvability for SMC. This raises the
natural question whether SMC with ΔW ≤2 can be solved eﬃciently if the
number of distinguished women is bounded. Next we show that this is unlikely,
as the problem turns out to be NP-hard for |W⋆| = 1.
Theorem 12 (⋆). SMC is NP-hard, even if ΔW = 2, ΔM = 3 and |W⋆| = 1.
Contrasting Theorem 12, we establish ﬁxed-parameter tractability of the case
ΔW ≤2. The relevant cases (whose tractability or intractability does not follow
from our results obtained so far) are as follows (assuming ΔW ≤2 throughout).
First, we can take the number of distinguished persons as parameter (note that
we know NP-hardness of the cases where |W⋆| = 1 or |M⋆| = 0). Second, we can
consider the number of blocking pairs as the parameter. We show the following:
Theorem 13 (⋆).
There is a ﬁxed-parameter algorithm for the special case
of SMC where each woman ﬁnds at most two men acceptable (i.e., ΔW ≤2),
with parameter the number |W⋆
0| + |M⋆
0| of distinguished men and women left
unmatched by some stable matching (and hence by any stable matching).
As each augmenting path contains at least one edge that blocks M opt, the
number of blocking pairs admitted by M opt is at least (|W⋆
0| + |M⋆
0|)/2. Thus:
Corollary 2 (⋆).
There is a ﬁxed-parameter algorithm with parameter b for
the special case of SMC where each woman ﬁnds at most two men acceptable.
References
1. Arulselvan, A., Cseh, ´A., Groß, M., Manlove, D.F., Matuschke, J.: Matchings with
lower quotas: algorithms and complexity. Algorithmica (2016)
2. Aziz, H., Seedig, H.G., von Wedel, J.K.: On the susceptibility of the deferred
acceptance algorithm. In: Proceedings of AAMAS 2015, pp. 939–947 (2015)
3. Bartholdi III, J.J., Tovey, C.A., Trick, M.A.: How hard is it to control an election?
Math. Comput. Modell. 16(8–9), 27–40 (1992)
4. Bir´o, P., Fleiner, T., Irving, R.W., Manlove, D.F.: The college admissions problem
with lower and common quotas. Theoret. Comput. Sci. 411(34–36), 3136–3153
(2010)
5. Bir´o, P., Irving, R.W., Schlotter, I.: Stable matching with couples: an empirical
study. ACM J. Exp. Algorithmics 16, 1–2 (2011)

Stable Marriage with Covering Constraints
331
6. Bir´o, P., Manlove, D.F., McDermid, E.J.: “Almost stable” matchings in the room-
mates problem with bounded preference lists. Theoret. Comput. Sci. 432, 10–20
(2012)
7. Cechl´arov´a, K., Fleiner, T.: Pareto optimal matchings with lower quotas. In: Pro-
ceedings of COMSOC 2016 (2016)
8. Cseh, ´A., Manlove, D.F.: Stable marriage and roommates problems with restricted
edges: complexity and approximability. Discret. Optim. 20, 62–89 (2016)
9. Cygan, M., Fomin, F.V., Kowalik, L., Lokshtanov, D., Marx, D., Pilipczuk, M.,
Pilipczuk, M., Saurabh, S.: Parameterized Algorithms. Springer, Cham (2015)
10. Dias, V.M., da Fonseca, G.D., de Figueiredo, C.M., Szwarcﬁter, J.L.: The stable
marriage problem with restricted pairs. Theoret. Comput. Sci. 306(1–3), 391–405
(2003)
11. Ehlers, L., Hafalir, I.E., Yenmez, M.B., Yildirim, M.A.: School choice with con-
trolled choice constraints: hard bounds versus soft bounds. J. Econ. Theory 153,
648–683 (2014)
12. Fleiner, T., Irving, R.W., Manlove, D.F.: Eﬃcient algorithms for generalised stable
marriage and roommates problems. Theor. Comput. Sci. 381, 162–176 (2007)
13. Fleiner, T., Kamiyama, N.: A matroid approach to stable matchings with lower
quotas. Math. Oper. Res. 41(2), 734–744 (2016)
14. Fragiadakis, D., Iwasaki, A., Troyan, P., Ueda, S., Yokoo, M.: Strategyproof match-
ing with minimum quotas. ACM Trans. Econ. Comput. 4(1), 6 (2016)
15. Fragiadakis, D., Troyan, P.: Improving matching under hard distributional con-
straints. Theoret. Econ. 12, 864–908 (2017)
16. Gale, D., Shapley, L.S.: College admissions and the stability of marriage. Amer.
Math. Mon. 69(1), 9–15 (1962)
17. Gale, D., Sotomayor, M.: Some remarks on the stable matching problem. Discret.
Appl. Math. 11(3), 223–232 (1985)
18. Goto, M., Iwasaki, A., Kawasaki, Y., Kurata, R., Yasuda, Y., Yokoo, M.: Strate-
gyproof matching with regional minimum and maximum quotas. Artif. Intell. 235,
40–57 (2016)
19. Gusﬁeld, D., Irving, R.W.: The Stable Marriage Problem: Structure and Algo-
rithms. MIT Press, Cambridge (1989)
20. Hamada, K., Iwama, K., Miyazaki, S.: The hospitals/residents problem with lower
quotas. Algorithmica 74(1), 440–465 (2016)
21. Huang, C.-C.: Classiﬁed stable matching. In: Proceedings of SODA 2010, pp. 1235–
1253 (2010)
22. Immorlica, N., Mahdian, M.: Marriage, honesty, and stability. In: Proceedings of
SODA 2005, pp. 53–62 (2005)
23. Impagliazzo, R., Paturi, R., Zane, F.: Which problems have strongly exponential
complexity? J. Comput. System Sci. 63(4), 512–530 (2001)
24. Irving, R.W., Manlove, D., O’Malley, G.: Stable marriage with ties and bounded
length preference lists. J. Discret. Algorithms 7, 213–219 (2009)
25. Kamiyama, N.: A note on the serial dictatorship with project closures. Oper. Res.
Lett. 41(5), 559–561 (2013)
26. Knuth, D.E.: Mariages stables et leurs relations avec d’autres probl`emes combina-
toires. Les Presses de l’Universit´e de Montr´eal, Montreal (1976)
27. Kojima, F., Pathak, P.A., Roth, A.E.: Matching with couples: stability and incen-
tives in large markets. Q. J. Econ. 128(4), 1585–1632 (2013)
28. Kominers, S.D., S¨onmez, T.: Matching with slot-speciﬁc priorities: theory. Theoret.
Econ. 11(2), 683–710 (2016)

332
M. Mnich and I. Schlotter
29. Manlove, D.F.: Algorithmics of Matching Under Preferences. Series on Theoretical
Computer Science, vol. 2. World Scientiﬁc, Singapore (2013)
30. Marx, D., Schlotter, I.: Parameterized complexity and local search approaches for
the stable marriage problem with ties. Algorithmica 58(1), 170–187 (2010)
31. Marx, D., Schlotter, I.: Stable assignment with couples: parameterized complexity
and local search. Discret. Optim. 8, 25–40 (2011)
32. Mnich, M., Schlotter, I.: Stable marriage with covering constraints: a complete
computational trichotomy (2017). https://arxiv.org/abs/1602.08230
33. Monte, D., Tumennasan, N.: Matching with quorums. Econ. Lett. 120(1), 14–17
(2013)
34. Roth, A.E., Peranson, E.: The redesign of the matching market for american physi-
cians: some engineering aspects of economic design. Amer. Econ. Rev. 89, 748–780
(1999)
35. Veskioja, T.: Stable marriage problem and college admission. Ph.D. thesis, Depart-
ment of Informatics, Tallinn University of Technology (2005)
36. Westkamp, A.: An analysis of the German University admissions system. Econ.
Theory 53(3), 561–589 (2013)
37. Yokoi, Y.: A generalized polymatroid approach to stable matchings with lower
quotas. Math. Oper. Res. 42(1), 238–255 (2017)

Fairly Allocating Contiguous Blocks
of Indivisible Items
Warut Suksompong(B)
Department of Computer Science, Stanford University,
353 Serra Mall, Stanford, CA 94305, USA
warut@cs.stanford.edu
Abstract. In this paper, we study the classic problem of fairly allocat-
ing indivisible items with the extra feature that the items lie on a line.
Our goal is to ﬁnd a fair allocation that is contiguous, meaning that the
bundle of each agent forms a contiguous block on the line. While allo-
cations satisfying the classical fairness notions of proportionality, envy-
freeness, and equitability are not guaranteed to exist even without the
contiguity requirement, we show the existence of contiguous allocations
satisfying approximate versions of these notions that do not degrade as
the number of agents or items increases. We also study the eﬃciency loss
of contiguous allocations due to fairness constraints.
1
Introduction
We consider the classic problem in economics of fair division: How can we divide
a set of resources among interested agents in such a way that the resulting
division is fair? This is an important issue that occurs in a variety of situations,
including students splitting the rent of an apartment, couples dividing their
properties after a divorce, and countries staking claims in disputed territory.
The fair division literature often distinguishes between two types of resources.
Some resources, such as cake and land, are said to be divisible since they can
be split arbitrarily among agents. Other resources, like houses and cars, are
indivisible—each house or car must be allocated as a whole to one agent.
To reason about fairness, we must deﬁne what it means for an allocation
of resources to be fair. Several notions of fairness have been proposed, three
of the oldest and best-known of which are proportionality, envy-freeness, and
equitability. An allocation is said to be proportional if the utility that each
agent gets from the bundle she receives is at least a 1/n fraction of her utility
for the whole set of resources, where n is the number of agents among whom we
divide the resources. The allocation is called envy-free if every agent thinks that
her bundle is at least as good as the bundle of any other agent, and equitable if
all agents have the same utility for their own bundle. It turns out that there is a
signiﬁcant distinction between the two types of resources with respect to these
notions. On the one hand, when resources are divisible, allocations that satisfy
The full version of this paper is available at http://arxiv.org/abs/1707.00345.
c
⃝Springer International Publishing AG 2017
V. Bil`o and M. Flammini (Eds.): SAGT 2017, LNCS 10504, pp. 333–344, 2017.
DOI: 10.1007/978-3-319-66700-3 26

334
W. Suksompong
the three notions simultaneously always exist [1]. On the other hand, a simple
example with two agents who both positively value a single item already shows
that the existence of a fair division cannot be guaranteed for any of the notions
when we deal with indivisible items.
In this paper, we study the problem of allocating indivisible items with the
added feature that the items lie on a line. We are interested in ﬁnding a fair
allocation that moreover satisﬁes the requirement of contiguity, i.e., the bundle
that each agent receives forms a contiguous block on the line. Several practical
applications ﬁt into this model. For instance, when we divide oﬃces between
research groups on the same ﬂoor, it is desirable that each research group get a
contiguous block of oﬃces in order to facilitate communication within the group.
Likewise, when we allocate retail units on a street, the retailers often prefer to
have a contiguous block of units in order to operate a larger store. The contiguity
condition can also be interpreted in the temporal sense, as opposed to the spatial
sense described thus far. An example is a situation where various organizers wish
to use the same conference center for their conferences. Not surprisingly, the
organizers typically want to schedule a conference in a contiguous block of time
rather than during several separate periods.
Since allocations that satisfy any of the three fairness notions do not always
exist in general, the same is necessarily true when we restrict our attention
to contiguous allocations. Nevertheless, we show that in light of the contiguity
requirement, the existence of allocations that satisfy approximate versions of
the notions can still be guaranteed. More precisely, for each notion we deﬁne
an approximate version that depends on an additive factor ϵ ≥0. An allocation
is said to be ϵ-proportional if the utility of each agent is at most ϵ away from
her “proportional share”, ϵ-envy-free if each agent envies any other agent by
at most ϵ, and ϵ-equitable if the utilities of any two agents diﬀer by at most
ϵ. Denoting the maximum utility of an agent for an item by umax, we estab-
lish the existence of a contiguous umax-proportional allocation and a contiguous
umax-equitable allocation for any number of agents, a contiguous umax-envy-free
allocation for two agents, and a contiguous 2umax-envy-free allocation for any
number of agents. Importantly, the approximation factors do not degrade as the
number of agents or items grows. We also prove that our approximation factor is
the best possible for proportionality and equitability with any number of agents
as well as for envy-freeness with two agents. Finally, for proportionality the fac-
tor can be improved to n−1
n
· umax if we know the number n of agents, and we
show that this is again tight.
Our results suggest that adding the contiguity requirement does not entail
extra costs in terms of the approximation guarantees. Indeed, the approximation
factors for proportionality and equitability with any number of agents and for
envy-freeness with two agents remain tight even if we allow arbitrary allocations.
This can be seen as somewhat surprising, since the space of contiguous alloca-
tions is signiﬁcantly smaller than that of arbitrary allocations. Indeed, when
there are n agents and m items, the number of arbitrary allocations is nm, while
the number of contiguous allocations for a ﬁxed order of items on a line is at

Fairly Allocating Contiguous Blocks of Indivisible Items
335
most
m+n−1
n−1

n!. The latter quantity is much less than the former if m is large
compared to n.
In addition, we investigate the eﬃciency loss of contiguous allocations due to
fairness constraints using the price of fairness concept initiated by Caragiannis
et al. [8]. The price of fairness quantiﬁes the loss of social welfare that is necessary
if we impose a fairness constraint on the allocation. A low price of fairness means
that we can get fairness at virtually no extra cost on social welfare, while a high
price of fairness implies that even the most eﬃcient “fair” allocation has social
welfare far below that of the most eﬃcient allocation overall. Caragiannis et al.
studied the price of fairness for the three notions of fairness using utilitarian
welfare for both divisible and indivisible items. Later, Aumann and Dombb [2]
focused on contiguous allocations of divisible items and considered both utilitar-
ian and egalitarian welfare. In this paper, we complete the picture by providing
tight or almost tight bounds on the price of fairness for contiguous allocations of
indivisible items, again for all three classical notions of fairness and with respect
to both utilitarian and egalitarian welfare. Our results are summarized in Table 1
along with a comparison to results from previous work.
Table 1. Comparison of our results on the price of fairness to previous results in [2,8].
The bounds with an asterisk hold for inﬁnitely many values of n.
Indivisible
Contiguous (this work)
Non-contiguous ([8])
Utilitarian
Egalitarian
Utilitarian
Lower
Upper
Lower
Upper
Proportionality n −1 + 1
n
1
n −1 + 1
n
Equitability
3
2 for n = 2
1 for n = 2
2 for n = 2
∞for n > 2
∞for n > 2 ∞for n > 2
Envy-freeness
⌊√n⌋
2
√n
2 + 1 −o(1)
n
2
3n+7
9
−O
 1
n

n −1
2
Divisible
Contiguous ([2])
Non-contiguous ([8])
Proportionality
√n
2
∗
√n
2 + 1 −o(1) 1
Ω(√n)
O(√n)
Equitability
n −1 + 1
n
n
1
(n+1)2
4n
n
Envy-freeness
√n
2
∗
√n
2 + 1 −o(1)
n
2
Ω(√n)
n −1
2
1.1
Related Work
The contiguity condition has been studied with respect to the three classical
fairness notions in the context of divisible items, often represented by a cake,
with the motivation that one wants to avoid giving an agent a “union of crumbs”.
In particular, Dubins and Spanier [13] exhibited a moving-knife algorithm that
guarantees a contiguous proportional allocation. Cechl´arov´a et al. [10] showed
that for any ordering of the agents, a contiguous equitable allocation that assigns

336
W. Suksompong
contiguous pieces to the agents in that order exists. Stromquist [17,18] proved
that a contiguous envy-free allocation always exists, but cannot be found by a
ﬁnite algorithm. Su [19] used techniques involving Sperner’s lemma to establish
the existence of a contiguous envy-free allocation and moreover considered the
related problem of rent partitioning.
Recently, Bouveret et al. [7] studied the allocation of indivisible items on
a line with the contiguity condition and showed that determining whether a
contiguous fair allocation exists is NP-hard when the fairness notion considered
is either proportionality or envy-freeness. They also considered a more general
model of the relationship between items where the items are vertices of an undi-
rected graph. Aumann et al. [3] investigated the problem of ﬁnding a contiguous
allocation that maximizes welfare for both divisible and indivisible items. They
showed that while it is NP-hard to ﬁnd the optimal contiguous allocation, there
exists an eﬃcient algorithm that yields a constant factor approximation. Bei et al.
[5] and Cohler et al. [11] also considered the objective of maximizing welfare,
but under the additional fairness constraint of proportionality and envy-freeness,
respectively.
Additively approximating fairness notions using umax, the highest utility of
an agent for an item, has been studied before. Lipton et al. [15] showed that
without the contiguity requirement, a umax-envy-free allocation exists even for
general monotone valuations. Caragiannis et al. [9] used the term “envy-freeness
up to one good” (EF1) to refer to a closely related property of an allocation.
Besides the allocation of goods, the price of fairness has also been investigated
for the allocation of chores. In particular, Caragiannis et al. [8], who initiated
this line of research, studied the notion for both divisible and indivisible chores.
Heydrich and van Stee [14] likewise considered the setting of divisible chores
but, similarly to our work and that of Aumann and Dombb [2], focused on
contiguous allocations. Finally, Bil`o et al. [6] applied this concept to machine
scheduling problems.
2
Preliminaries
Let N = {1, 2, . . . , n} denote the set of agents, and M = {1, 2, . . . , m} the set of
items to be allocated. We assume that the items lie on a line in this order.
Each agent i ∈N has some nonnegative utility ui(j) for item j ∈M. For
an agent i, deﬁne ui,max := maxj∈M ui(j) to be the highest utility of i for an
item. Let umax := maxi∈N ui,max be the highest utility of any agent for an item.
As is very common, we assume for most of the paper that utilities are additive.
Additivity means that ui(M ′) = 
j∈M ′ ui(j) for any agent i and any subset
of items M ′ ⊆M. An allocation M = (M1, . . . , Mn) is a partition of all items
into bundles for the agents so that agent i receives bundle Mi. The utilitarian
welfare of M is 
i∈N ui(Mi) and the egalitarian welfare of M is mini∈N ui(Mi).
We call the allocation contiguous if each bundle Mi forms a contiguous block
of items on the line. Furthermore, we refer to a setting with agents, items, and
utility functions as an instance.

Fairly Allocating Contiguous Blocks of Indivisible Items
337
We are now ready to deﬁne the fairness notions that we will consider in this
paper. We use additive versions of approximation; this is much stronger than
multiplicative versions as the number of items grows.
Deﬁnition 1. An allocation M = (M1, . . . , Mn) is said to be proportional if
ui(Mi) ≥
1
n · ui(M) for all i ∈N. For ϵ ≥0, the allocation is said to be ϵ-
proportional if ui(Mi) ≥1
n · ui(M) −ϵ for all i ∈N. We refer to 1
n · ui(M) as
the proportional share of agent i.
Deﬁnition 2. An allocation M = (M1, . . . , Mn) is said to be envy-free if
ui(Mi) ≥ui(Mj) for all i, j ∈N. For ϵ ≥0, the allocation is said to be ϵ-
envy-free if ui(Mi) ≥ui(Mj) −ϵ for all i, j ∈N.
Deﬁnition 3. An allocation M = (M1, . . . , Mn) is said to be equitable if
ui(Mi) = uj(Mj) for all i, j ∈N. For ϵ ≥0, the allocation is said to be ϵ-
equitable if |ui(Mi) −uj(Mj)| ≤ϵ for all i, j ∈N.
There is a strong relation between proportionality and envy-freeness, as the
following proposition shows.
Proposition 1. Any ϵ-envy-free allocation is ϵ-proportional.
The proof of Proposition 1 can be found in the full version of this paper. In
particular, when ϵ = 0, the proposition reduces to the well-known fact that any
envy-free allocation is proportional. When there are two agents, proportional
allocations are also envy-free (and in fact, more generally, ϵ-proportional allo-
cations are 2ϵ-envy-free.) This is, however, not necessarily the case if there are
at least three agents. An example is when an agent values her own bundle 1/n
of the whole set of items and values the bundle of another agent the remaining
(n −1)/n of the whole set of items. On the other hand, equitability neither
implies nor is implied by proportionality or envy-freeness.
For each of the three (non-approximate) fairness notions deﬁned above, the
set of instances for which a contiguous allocation satisfying the notion exists
is strictly smaller than the corresponding set when contiguity is not required.
Indeed, suppose that there are three items and two agents who share a common
utility function u with u(1) = u(3) = 1 and u(2) = 2. An allocation in which
one agent gets items 1 and 3 while the other agent gets item 2 is proportional,
envy-free, and equitable. In contrast, no contiguous allocation satisﬁes any of
the three properties.
We end this section by giving the deﬁnition of the various forms of the price
of fairness.
Deﬁnition 4. Given an instance (along with a set of allocations considered), its
utilitarian price of proportionality (resp., utilitarian price of equitability, utili-
tarian price of envy-freeness) is deﬁned as the ratio of the utilitarian welfare of
the optimal allocation over the utilitarian welfare of the best proportional (resp.,
equitable, envy-free) allocation. If a proportional (resp., equitable, envy-free) allo-
cation does not exist, the utilitarian price of proportionality (resp., equitability,

338
W. Suksompong
envy-freeness) is not deﬁned for that instance. The (overall) utilitarian price of
proportionality (resp., utilitarian price of equitability, utilitarian price of envy-
freeness) is then the supremum utilitarian price of proportionality (resp., utili-
tarian price of equitability, utilitarian price of envy-freeness) over all instances.
The egalitarian price of proportionality, egalitarian price of equitability, and
egalitarian price of envy-freeness are deﬁned analogously.
3
Proportionality
We begin with proportionality. Our ﬁrst result shows the existence of a contigu-
ous allocation in which every agent receives at least her proportional share less
n−1
n
times her utility for her highest-valued item.
Theorem 1. Given any instance, there exists a contiguous allocation M such
that ui(Mi) ≥1
n · ui(M) −n−1
n
· ui,max for all agents i ∈N. In particular, there
exists a contiguous n−1
n
· umax-proportional allocation.
Proof. We process the items from left to right using the following algorithm.
1. Set the current block to the empty block.
2. If the current block yields utility at least
1
n · ui(M) −n−1
n
· ui,max to some
agent i, give the block to the agent. (If several agents satisfy this condition,
choose one arbitrarily.)
– If all agents have received a block as a result of this, allocate the leftover
items arbitrarily and terminate.
– Otherwise, if some agent receives a block in this step, remove that agent
from consideration and return to Step 1.
3. Add the next item to the current block and return to Step 2.
If an agent i receives a block of items from this algorithm, she obtains utility
at least
1
n · ui(M) −n−1
n
· ui,max. Hence it suﬃces to show that the algorithm
allocates a block to every agent. To this end, we show by (backward) induction
that when there are k agents who have not been allocated a block, each agent i
among them has utility at least k
n ·ui(M)−n−k
n ·ui,max for the remaining items.
This will imply that the last agent has utility at least 1
n · ui(M) −n−1
n
· ui,max
left, which is enough to satisfy our condition.
The base case k = n trivially holds. For the inductive step, assume that the
statement holds when there are k + 1 agents left, and consider an agent i who
is not the next one to receive a block. When there are k + 1 agents left, her
utility for the remaining items is at least k+1
n · ui(M) −n−k−1
n
· ui,max. Since she
does not receive the next block, her utility for the block excluding its last item
is less than 1
n · ui(M) −n−1
n
· ui,max. This means that her utility for the block is
less than 1
n · ui(M) + 1
n · ui,max. Hence her utility for the remaining items is at
least
 k+1
n
· ui(M) −n−k−1
n
· ui,max

−
 1
n · ui(M) + 1
n · ui,max

, which is equal
to k
n · ui(M) −n−k
n
· ui,max, as desired.
⊓⊔

Fairly Allocating Contiguous Blocks of Indivisible Items
339
The algorithm in Theorem 1 is similar to the Dubins-Spanier algorithm for
proportional cake-cutting [13] and runs in time O(mn), which is the best possible
since the input also has size O(mn). It can also be implemented as a mechanism
that does not elicit the full utility functions from the agents, but instead asks
them to indicate when the value of the current block reaches their threshold.
While the mechanism is not truthful, a truthful agent always receives no less
than her proportional share minus n−1
n
times her utility for the item she values
most.
As the next example shows, the additive approximation factor n−1
n
· umax is
the best possible in the sense that the existence of a contiguous α · n−1
n
· umax-
proportional allocation is not guaranteed for any α < 1. In fact, this is the case
even if we remove the contiguity requirement.
Example 1. Suppose that there are m = n −1 items any of which each agent
has a utility of 1. The proportional share of every agent is n−1
n . On the other
hand, in any (not necessarily contiguous) allocation, some agent does not receive
an item and therefore has a utility of 0. For any ﬁxed α < 1, the utility of this
agent is less than her proportional share minus α · n−1
n
· umax.
Even though a contiguous umax-proportional allocation always exists, in some
cases we might also want to choose the ordering on the line in which the agents
are allocated blocks of items, in addition to imposing the contiguity requirement.
For instance, the owner of a conference center could have a preferred lineup of
the conferences, and a building manager might want to assign oﬃces in certain
parts of the ﬂoor to certain research groups. Nevertheless, the following exam-
ple shows that for approximate proportionality, the ordering cannot always be
chosen arbitrarily.
Example 2. Suppose that there are two agents and m ≥6 items. The ﬁrst agent
has utility 1 for the last three items and 0 otherwise, while the second agent has
utility 1 for every item. The proportional share of the two agents less half of the
utility for their highest-valued item is 1 and m−1
2 , respectively. If we want to
give a left block to the ﬁrst agent and the remaining right block to the second
agent, the left block needs to include up to item m −2. But this means that the
second agent gets utility at most 2, which is less than the required m−1
2 .
By increasing m and the number of items for which the ﬁrst agent has utility
1, we can extend the example to show that the existence of a contiguous allo-
cation with a ﬁxed ordering of agents is not guaranteed even if we weaken the
approximation factor umax to kumax for any k > 1.
4
Equitability
We next consider equitability. As with proportionality, we show that a contigu-
ous allocation in which the values of diﬀerent agents for their own block diﬀer by
no more than umax always exists. Unlike for proportionality, however, for equi-
tability we can additionally choose the order in which the agents receive blocks
on the line.

340
W. Suksompong
Theorem 2. Given any instance and any ordering of the agents, there exists a
contiguous umax-equitable allocation in which the agents are allocated blocks of
items on the line according to the ordering.
Note that in order to ensure that all agents are treated equally, one should
normalize the utilities across agents before applying Theorem 2, for example by
rescaling the utilities so that ui,max = 1 for all i ∈N.
Proof. Assume without loss of generality that the required ordering of agents
is 1, 2, . . . , n from left to right. Start with an arbitrary allocation satisfying the
ordering. For any allocation M, let max(M) = maxn
i=1 ui(Mi) and min(M) =
minn
i=1 ui(Mi). In each iteration, as long as the allocation does not satisfy the
approximate equitability, we will move an item at the end of a block to the block
that the item is adjacent to. Here is the description of the algorithm.1
1. Choose a block Mi such that ui(Mi) = max(M). If there are many such
blocks, choose one arbitrarily.
2. If max(M) ≤min(M) + umax, stop and return the current allocation.
3. Choose a block Mj such that uj(Mj) = min(M). If there are many such
blocks, choose arbitrarily from the ones that minimize |j −i|.
4. Let Mk be the block between Mi and Mj that is next to Mj, i.e., k = j −1
if j > i and k = j + 1 if j < i. (It is possible that k = i.) The block Mk must
be non-empty; otherwise we would have chosen Mk instead of Mj. Move the
item in Mk that is adjacent to Mj to Mj.
(a) If k = i and the moved item has nonzero utility for agent i, go to Step 1.
(b) Else, go to Step 2.
If the algorithm terminates, then as the ordering of the agents for the blocks
never changed, the algorithm returns a umax-equitable allocation with the desired
ordering. Hence it remains to show that the algorithm terminates.
To this end, observe that when an item is moved in Step 4 of the algorithm,
no new block with utility max(M) or more to the block owner is created. Indeed,
the block that gets an additional item now yields utility at most min(M)+umax
to its owner, which is less than max(M) since the condition in Step 2 is not
yet satisﬁed. Moreover, since items are only being moved farther away from the
main block Mi, we must eventually reach a point where k = i; formally, the
quantity n
z=1 |i −z||Mz| strictly increases, where |Mz| denotes the number of
items in Mz. Since the quantity is bounded from above, after a ﬁnite number of
moves we will have k = i and meet the condition of Step 4(a).
The argument in the previous paragraph shows that the number of blocks
with utility max(M) decreases during the course of the algorithm. When this
number reaches zero, the value max(M) decreases. Since there are only a ﬁnite
number of allocations, the algorithm must terminate, as claimed.
⊓⊔
1 The algorithm is inspired by work on block partitions of sequences [4].

Fairly Allocating Contiguous Blocks of Indivisible Items
341
The algorithm in Theorem 2 runs in time O(n2m4). For each iteration, com-
puting the maximum and minimum blocks takes O(m). There are O(m2) possible
blocks. Each block cannot be used as the block Mi in Step 1 more than once for
each of the n agents, since no new blocks with utility max(M) is created during
an execution of the algorithm. Finally, once the block Mi is ﬁxed, the quantity
n
z=1 |i−z||Mz| can increase at most O(mn) times, yielding the claimed running
time.
Example 1 shows that for any number of agents, the approximation fac-
tor umax for equitability cannot be improved even if we remove the contiguity
requirement (and hence also the ordering). On the other hand, using the same
algorithm, we can generalize Theorem 2 to any monotonic, not necessarily addi-
tive utility function with zero utility for the empty set. In particular, a umax-
equitable allocation can be found when agents are endowed with such utility
functions, where the generalized deﬁnition of umax is the highest marginal utility
of any agent for a single item, i.e., umax = maxi∈N,j∈M,S⊆M(ui(S∪{j})−ui(S)).
Although the algorithm in Theorem 2 guarantees that an approximate equi-
table allocation exists, such an allocation can be “equally bad” rather than
“equally good” for the agents. Indeed, if we start with an allocation that yields
zero utility to every agent, then the algorithm will terminate immediately despite
the possible existence of an equitable allocation with positive utility for all
agents. If we insist on choosing the ordering of the agents, then the next example
shows that a situation that leaves some agent unhappy may be unavoidable.
Example 3. Suppose that there are two items and two agents with u1(2) =
u2(1) = 1 and u1(1) = u2(2) = 0. The allocation that gives item 1 to agent 2
and item 2 to agent 1 yields a utility of 1 to both agents. If we require that
agent 1 receive a left block and agent 2 a right block, however, some agent is
necessarily left with no utility.
Nevertheless, we show next that if we allow the freedom of choosing the
ordering of the agents, then an allocation with a better eﬃciency guarantee
for the agents can always be found. In particular, we can ﬁnd an allocation
whose egalitarian welfare equals the highest egalitarian welfare over all contigu-
ous allocations of the instance. The proof mirrors that of the analogous result for
divisible items by Aumann and Dombb [2] and can be found in the full version
of this paper.
Theorem 3. Given any instance, there exists a contiguous umax-equitable allo-
cation whose egalitarian welfare equals the highest egalitarian welfare over all
contiguous allocations of the instance.
As is the case for Theorem 2, the result can be generalized to monotonic, not
necessarily additive utility functions with zero utility for the empty set, where
umax is again deﬁned as the highest marginal utility of any agent for a single
item. A similar argument also shows that for any ordering of the agents, there
exists a contiguous umax-equitable allocation whose egalitarian welfare equals
the highest egalitarian welfare over all contiguous allocations with that ordering

342
W. Suksompong
of the agents for the instance. However, the proof of Theorem 3 does not give
rise to an eﬃcient algorithm for computing a desired allocation.
5
Envy-Freeness
We now turn to envy-freeness. If we remove the contiguity requirement, it is well-
known that a simple algorithm yields an ϵ-envy-free allocation for any number
of agents and items: Let the agents pick their favorite item in a round-robin
manner from the remaining items until all items are allocated. We show in this
section that an ϵ-envy-free allocation exists when there are two agents, and a
2ϵ-envy-free allocation exists for an arbitrary number of agents.
For two agents, Theorem 1 directly implies the following.
Theorem 4. Given any instance with two agents, there exists a contiguous allo-
cation such that agent i has envy at most ui,max toward the other agent. In
particular, there exists a contiguous umax-envy-free allocation.
Tightness of the approximation factor umax follows from Example 1 with
n = 2. Moreover, an example similar to Example 2 shows that the result does
not hold if we ﬁx the ordering of the agents, even when we replace umax by kumax
for some k > 1.
To tackle the general setting with an arbitrary number of agents, we model
the items as divisible items. Since a contiguous envy-free allocation always exists
for divisible items [17], we can round such an allocation to obtain an approximate
envy-free allocation for indivisible items.
Theorem 5. Given any instance, there exists a contiguous allocation such that
agent i has envy at most 2ui,max toward any other agent. In particular, there
exists a contiguous 2umax-envy-free allocation.
Proof. Consider a cake represented by the interval [0, m]. For j ∈M, agent i
has uniform utility ui(j) for the interval [j −1, j]. Take any contiguous envy-free
allocation of the cake. We round the allocation as follows: Allocate each item j
to the agent who owns point j of the cake.
The resulting allocation is contiguous; we show that each agent i has envy
at most 2ui,max. The agent has no envy before the rounding. As a result of the
rounding, she loses utility at most ui,max, and any other agent gains utility at
most ui,max from her point of view. Hence agent i has envy at most 2ui,max, as
claimed.
⊓⊔
6
Price of Fairness
In this section, we quantify the price of fairness for contiguous allocations of
indivisible items with respect to the three notions of fairness and the two types
of welfare. We derive tight or almost tight bounds for each of the six resulting
combinations. Previous work has studied the problem for the setting of arbitrary

Fairly Allocating Contiguous Blocks of Indivisible Items
343
(i.e., not necessarily contiguous) allocations of divisible and indivisible items [8]
as well as contiguous allocations of divisible items [2]; our results therefore close
the remaining gap. The comparison of our results to previous work is shown in
Table 1. In fact, for several of the results we will be able to adjust arguments
from previous work to our setting. We state our results below and leave the
proofs to the full version of this paper.
Theorem 6. The utilitarian price of proportionality for contiguous allocations
of indivisible items is n −1 + 1
n.
Theorem 7. The utilitarian price of equitability for contiguous allocations of
indivisible items is 3
2 for n = 2 and inﬁnite for n > 2.
Theorem 8. The utilitarian price of envy-freeness for contiguous allocations of
indivisible items is in the interval

⌊√n⌋
2
,
√n
2 + 1 −o(1)

.
Theorem 9. The egalitarian price of proportionality for contiguous allocations
of indivisible items is 1.
Theorem 10. The egalitarian price of equitability for contiguous allocations of
indivisible items is 1 for n = 2 and inﬁnite for n > 2.
Theorem 11. The egalitarian price of envy-freeness for contiguous allocations
of indivisible items is n
2 .
7
Conclusion and Future Work
In this paper, we study the problem of fairly allocating indivisible items on a
line in such a way that each agent receives a contiguous block of items. This can
be used to model a variety of practical situations, including allocating oﬃces to
research groups, retail units to retailers, and time slots for using a conference
center to conference organizers. We show that we can ﬁnd contiguous allocations
that satisfy approximate versions of classical fairness notions. Notably, these
approximation guarantees do not degrade as the number of agents or items
grows. We also quantify the loss of eﬃciency that occurs when we impose fairness
constraints on contiguous allocations.
We conclude the paper by presenting some directions for future work.
– For envy-freeness with an arbitrary number of agents, can we close the approx-
imation factor gap between umax and 2umax? Can we obtain similar guaran-
tees if we also require Pareto optimality?
– Can we show the asymptotic existence or non-existence of contiguous alloca-
tions satisfying proportionality or envy-freeness if we assume that the utilities
are drawn from certain distributions? This has been shown for non-contiguous
allocations [12,16,20].
– Does there exist an eﬃcient algorithm that computes an approximate equi-
table allocation with a nontrivial welfare guarantee?
– How do the prices of fairness change if we deﬁne them with respect to approx-
imate fair allocations (which always exist) instead of non-approximate fair
allocations (which do not always exist)?

344
W. Suksompong
References
1. Alon, N.: Splitting necklaces. Adv. Math. 63(3), 247–253 (1987)
2. Aumann, Y., Dombb, Y.: The eﬃciency of fair division with connected pieces.
ACM Trans. Econ. Comput. 3(4), 23 (2015)
3. Aumann, Y., Dombb, Y., Hassidim, A.: Computing socially-eﬃcient cake divisions.
In: Proceedings of the 12th International Conference on Autonomous Agents and
Multiagent Systems, pp. 343–350 (2013)
4. B´ar´any, I., Grinberg, V.S.: Block partitions of sequences. Isr. J. Math. 206(1),
155–164 (2015)
5. Bei, X., Chen, N., Hua, X., Tao, B., Yang, E.: Optimal proportional cake cutting
with connected pieces. In: Proceedings of the 26th AAAI Conference on Artiﬁcial
Intelligence, pp. 1263–1269 (2012)
6. Bil`o, V., Fanelli, A., Flammini, M., Monaco, G., Moscardelli, L.: The price of
envy-freeness in machine scheduling. Theor. Comput. Sci. 613, 65–78 (2016)
7. Bouveret, S., Cechl´arov´a, K., Elkind, E., Igarashi, A., Peters, D.: Fair division of
a graph. In: Proceedings of the 26th International Joint Conference on Artiﬁcial
Intelligence (2017, forthcoming)
8. Caragiannis, I., Kaklamanis, C., Kanellopoulos, P., Kyropoulou, M.: The eﬃciency
of fair division. Theory Comput. Syst. 50, 589–610 (2012)
9. Caragiannis, I., Kurokawa, D., Moulin, H., Procaccia, A.D., Shah, N., Wang, J.:
The unreasonable fairness of maximum Nash welfare. In: Proceedings of the 17th
ACM Conference on Economics and Computation, pp. 305–322 (2016)
10. Cechl´arov´a, K., Doboˇs, J., Pill´arov´a, E.: On the existence of equitable cake divi-
sions. Inf. Sci. 228, 239–245 (2013)
11. Cohler, Y.J., Lai, J.K., Parkes, D.C., Procaccia, A.D.: Optimal envy-free cake
cutting. In: Proceedings of the 25th AAAI Conference on Artiﬁcial Intelligence,
pp. 626–631 (2011)
12. Dickerson, J.P., Goldman, J., Karp, J., Procaccia, A.D., Sandholm, T.: The com-
putational rise and fall of fairness. In: Proceedings of the 28th AAAI Conference
on Artiﬁcial Intelligence, pp. 1405–1411 (2014)
13. Dubins, L.E., Spanier, E.H.: How to cut a cake fairly. Am. Math. Mon. 68(1), 1–17
(1961)
14. Heydrich, S., van Stee, R.: Dividing connected chores fairly. Theor. Comput. Sci.
593, 51–61 (2015)
15. Lipton, R.J., Markakis, E., Mossel, E., Saberi, A.: On approximately fair allocations
of indivisible goods. In: Proceedings of the 5th ACM Conference on Economics and
Computation, pp. 125–131 (2004)
16. Manurangsi, P., Suksompong, W.: Asymptotic existence of fair divisions for groups.
Math. Soc. Sci. (Forthcoming)
17. Stromquist, W.: How to cut a cake fairly. Am. Math. Mon. 87(8), 640–644 (1980)
18. Stromquist, W.: Envy-free cake divisions cannot be found by ﬁnite protocols. Elec-
tron. J. Comb. 15, 11 (2008)
19. Su, F.E.: Rental harmony: Sperner’s lemma in fair division. Am. Math. Mon.
106(10), 930–942 (1999)
20. Suksompong, W.: Asymptotic existence of proportionally fair allocations. Math.
Soc. Sci. 81, 62–65 (2016)

Author Index
Anshelevich, Elliot
267
Azar, Yossi
3
Baïou, Mourad
55
Barahona, Francisco
55
Basu, Soumya
147
Bei, Xiaohui
67
Birmpas, Georgios
16
Bredereck, Robert
80
Chauhan, Ankit
160
Chen, Yitao
147
Chen, Zhou
227
Cheng, Yukun
227
Christodoulou, George
240
Cohen, Johanne
252
Deligkas, Argyrios
93
Deng, Xiaotie
227
Domaniç, Nevzat Onur
280
Dziubiński, Marcin
292
Eden, Alon
29
Epitropou, Markos
173
Faliszewski, Piotr
80
Fearnley, John
93
Feldman, Michal
3, 29, 186
Fotakis, Dimitris
173
Friedrich, Tobias
199
Gairing, Martin
240
Garg, Jugal
67
Gravin, Nick
3
Gupta, Sushmita
106
Hansen, Kristoffer Arnsfelt
119
Héliou, Amélie
252
Hoefer, Martin
67, 173, 307
Ihde, Sven
199
Jiamjitrak, Wanchote
307
Kaczmarczyk, Andrzej
80
Keßler, Christoph
199
Kleer, Pieter
212
Lam, Chi-Kit
280
Lenzner, Pascal
160, 199
Lianeas, Thanasis
147
Lu, Pinyan
41
Markakis, Evangelos
16
Mavronicolas, Marios
131
Mehlhorn, Kurt
67
Melnichenko, Anna
160
Mertikopoulos, Panayotis
252
Mnich, Matthias
320
Molitor, Louise
160
Monien, Burkhard
131
Neubert, Stefan
199
Niedermeier, Rolf
80
Nikoletseas, Sotiris
240
Nikolova, Evdokia
147
Plaxton, C. Gregory
280
Qi, Qi
227
Raptopoulos, Christoforos
240
Roy, Sanjukta
106
Roytman, Alan
3
Saurabh, Saket
106
Savani, Rahul
93
Schäfer, Guido
212
Schlotter, Ildikó
320
Schumann, David
199
Skoulakis, Stratis
173
Skowron, Piotr
80
Snappir, Yuval
186
Spirakis, Paul
240
Suksompong, Warut
333
Talmon, Nimrod
80
Tamir, Tami
186

Telelis, Orestis
16
Tsikiridis, Artem
16
Vardi, Adi
29
Xiao, Tao
41
Yan, Xiang
227
Yang, Ger
147
Zehavi, Meirav
106
Zhu, Wennan
267
346
Author Index

