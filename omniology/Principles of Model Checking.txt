Principles of Model Checking
Christel Baier and Joost-Pieter Katoen

Principles of Model Checking
i


Principles of
Model Checking
Christel Baier
Joost-Pieter Katoen
The MIT Press
Cambridge, Massachusetts
London, England

c⃝Massachusetts Institute of Technology
All rights reserved. No part of this book may be reproduced in any form by any elec-
tronic of mechanical means (including photocopying, recording, or information storage
and retrieval) without permission in writing from the publisher.
MIT Press books may be purchased at special quantity discounts for business or sales
promotional use.
For information, please email special sales@mitpress.mit.edu or
write to Special Sales Department, The MIT Press, 55 Hayward Street, Cambridge, MA
02142.
This book was set in Aachen and Dresden by Christel Baier and Joost-Pieter Katoen.
Printed and bound in the United States of America.
Library of Congress Cataloging-in-Publication Data
Baier, Christel.
Principles of model checking / Christel Baier and Joost-Pieter Katoen ; foreword by Kim
Guldstrand Larsen.
p. cm.
Includes bibliographical references and index.
ISBN 978-0-262-02649-9 (hardcover : alk. paper) 1. Computer systems–Veriﬁcation. 2.
Computer software–Veriﬁcation. I.
Katoen, Joost-Pieter. II. Title.
QA76.76.V47B35 2008
004.2’4–dc22
2007037603
10 9 8 7 6 5 4 3 2 1

To Michael, Gerda, Inge, and Karl
To Erna, Fons, Joost, and Tom
v


Contents
Foreword
xiii
Preface
xv
1
System Veriﬁcation
1
1.1
Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.2
Characteristics of Model Checking
. . . . . . . . . . . . . . . . . . . . . . .
11
1.2.1
The Model-Checking Process . . . . . . . . . . . . . . . . . . . . . .
11
1.2.2
Strengths and Weaknesses . . . . . . . . . . . . . . . . . . . . . . . .
14
1.3
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2
Modelling Concurrent Systems
19
2.1
Transition Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.1.1
Executions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.1.2
Modeling Hardware and Software Systems . . . . . . . . . . . . . . .
26
2.2
Parallelism and Communication . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.2.1
Concurrency and Interleaving . . . . . . . . . . . . . . . . . . . . . .
36
2.2.2
Communication via Shared Variables . . . . . . . . . . . . . . . . . .
39
2.2.3
Handshaking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
2.2.4
Channel Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
2.2.5
NanoPromela . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
2.2.6
Synchronous Parallelism . . . . . . . . . . . . . . . . . . . . . . . . .
75
2.3
The State-Space Explosion Problem
. . . . . . . . . . . . . . . . . . . . . .
77
2.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
2.5
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
2.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3
Linear-Time Properties
89
3.1
Deadlock
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.2
Linear-Time Behavior
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
3.2.1
Paths and State Graph
. . . . . . . . . . . . . . . . . . . . . . . . .
95
3.2.2
Traces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
3.2.3
Linear-Time Properties
. . . . . . . . . . . . . . . . . . . . . . . . . 100
vii

viii
CONTENTS
3.2.4
Trace Equivalence and Linear-Time Properties
. . . . . . . . . . . . 104
3.3
Safety Properties and Invariants
. . . . . . . . . . . . . . . . . . . . . . . . 107
3.3.1
Invariants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
3.3.2
Safety Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
3.3.3
Trace Equivalence and Safety Properties . . . . . . . . . . . . . . . . 116
3.4
Liveness Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
3.4.1
Liveness Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
3.4.2
Safety vs. Liveness Properties . . . . . . . . . . . . . . . . . . . . . . 122
3.5
Fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
3.5.1
Fairness Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
3.5.2
Fairness Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
3.5.3
Fairness and Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
3.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
3.7
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
3.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
4
Regular Properties
151
4.1
Automata on Finite Words
. . . . . . . . . . . . . . . . . . . . . . . . . . . 151
4.2
Model-Checking Regular Safety Properties . . . . . . . . . . . . . . . . . . . 159
4.2.1
Regular Safety Properties . . . . . . . . . . . . . . . . . . . . . . . . 159
4.2.2
Verifying Regular Safety Properties . . . . . . . . . . . . . . . . . . . 163
4.3
Automata on Inﬁnite Words . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
4.3.1
ω-Regular Languages and Properties . . . . . . . . . . . . . . . . . . 170
4.3.2
Nondeterministic B¨uchi Automata . . . . . . . . . . . . . . . . . . . 173
4.3.3
Deterministic B¨uchi Automata . . . . . . . . . . . . . . . . . . . . . 188
4.3.4
Generalized B¨uchi Automata . . . . . . . . . . . . . . . . . . . . . . 192
4.4
Model-Checking ω-Regular Properties
. . . . . . . . . . . . . . . . . . . . . 198
4.4.1
Persistence Properties and Product . . . . . . . . . . . . . . . . . . . 199
4.4.2
Nested Depth-First Search . . . . . . . . . . . . . . . . . . . . . . . . 203
4.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
4.6
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
4.7
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
5
Linear Temporal Logic
229
5.1
Linear Temporal Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
5.1.1
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
5.1.2
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
5.1.3
Specifying Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
5.1.4
Equivalence of LTL Formulae . . . . . . . . . . . . . . . . . . . . . . 247
5.1.5
Weak Until, Release, and Positive Normal Form
. . . . . . . . . . . 252
5.1.6
Fairness in LTL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
5.2
Automata-Based LTL Model Checking . . . . . . . . . . . . . . . . . . . . . 270

CONTENTS
ix
5.2.1
Complexity of the LTL Model-Checking Problem . . . . . . . . . . . 287
5.2.2
LTL Satisﬁability and Validity Checking . . . . . . . . . . . . . . . . 296
5.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
5.4
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
5.5
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
6
Computation Tree Logic
313
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
6.2
Computation Tree Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
6.2.1
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
6.2.2
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
6.2.3
Equivalence of CTL Formulae . . . . . . . . . . . . . . . . . . . . . . 329
6.2.4
Normal Forms for CTL
. . . . . . . . . . . . . . . . . . . . . . . . . 332
6.3
Expressiveness of CTL vs. LTL . . . . . . . . . . . . . . . . . . . . . . . . . 334
6.4
CTL Model Checking
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
6.4.1
Basic Algorithm
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
6.4.2
The Until and Existential Always Operator . . . . . . . . . . . . . . 347
6.4.3
Time and Space Complexity . . . . . . . . . . . . . . . . . . . . . . . 355
6.5
Fairness in CTL
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
6.6
Counterexamples and Witnesses
. . . . . . . . . . . . . . . . . . . . . . . . 373
6.6.1
Counterexamples in CTL
. . . . . . . . . . . . . . . . . . . . . . . . 376
6.6.2
Counterexamples and Witnesses in CTL with Fairness . . . . . . . . 380
6.7
Symbolic CTL Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . 381
6.7.1
Switching Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
6.7.2
Encoding Transition Systems by Switching Functions . . . . . . . . . 386
6.7.3
Ordered Binary Decision Diagrams . . . . . . . . . . . . . . . . . . . 392
6.7.4
Implementation of ROBDD-Based Algorithms
. . . . . . . . . . . . 407
6.8
CTL∗
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422
6.8.1
Logic, Expressiveness, and Equivalence . . . . . . . . . . . . . . . . . 422
6.8.2
CTL∗Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . . 427
6.9
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
6.10 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
6.11 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
7
Equivalences and Abstraction
449
7.1
Bisimulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
7.1.1
Bisimulation Quotient . . . . . . . . . . . . . . . . . . . . . . . . . . 456
7.1.2
Action-Based Bisimulation
. . . . . . . . . . . . . . . . . . . . . . . 465
7.2
Bisimulation and CTL∗Equivalence
. . . . . . . . . . . . . . . . . . . . . . 468
7.3
Bisimulation-Quotienting Algorithms . . . . . . . . . . . . . . . . . . . . . . 476
7.3.1
Determining the Initial Partition . . . . . . . . . . . . . . . . . . . . 478
7.3.2
Reﬁning Partitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 480

x
CONTENTS
7.3.3
A First Partition Reﬁnement Algorithm . . . . . . . . . . . . . . . . 486
7.3.4
An Eﬃciency Improvement . . . . . . . . . . . . . . . . . . . . . . . 487
7.3.5
Equivalence Checking of Transition Systems . . . . . . . . . . . . . . 493
7.4
Simulation Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 496
7.4.1
Simulation Equivalence
. . . . . . . . . . . . . . . . . . . . . . . . . 505
7.4.2
Bisimulation, Simulation, and Trace Equivalence . . . . . . . . . . . 510
7.5
Simulation and ∀CTL∗Equivalence . . . . . . . . . . . . . . . . . . . . . . . 515
7.6
Simulation-Quotienting Algorithms . . . . . . . . . . . . . . . . . . . . . . . 521
7.7
Stutter Linear-Time Relations . . . . . . . . . . . . . . . . . . . . . . . . . . 529
7.7.1
Stutter Trace Equivalence . . . . . . . . . . . . . . . . . . . . . . . . 530
7.7.2
Stutter Trace and LTL\⃝Equivalence . . . . . . . . . . . . . . . . . 534
7.8
Stutter Bisimulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536
7.8.1
Divergence-Sensitive Stutter Bisimulation . . . . . . . . . . . . . . . 543
7.8.2
Normed Bisimulation . . . . . . . . . . . . . . . . . . . . . . . . . . . 552
7.8.3
Stutter Bisimulation and CTL∗
\⃝Equivalence . . . . . . . . . . . . . 560
7.8.4
Stutter Bisimulation Quotienting . . . . . . . . . . . . . . . . . . . . 567
7.9
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579
7.10 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 580
7.11 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582
8
Partial Order Reduction
595
8.1
Independence of Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 598
8.2
The Linear-Time Ample Set Approach . . . . . . . . . . . . . . . . . . . . . 605
8.2.1
Ample Set Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . 606
8.2.2
Dynamic Partial Order Reduction
. . . . . . . . . . . . . . . . . . . 619
8.2.3
Computing Ample Sets
. . . . . . . . . . . . . . . . . . . . . . . . . 627
8.2.4
Static Partial Order Reduction . . . . . . . . . . . . . . . . . . . . . 635
8.3
The Branching-Time Ample Set Approach . . . . . . . . . . . . . . . . . . . 650
8.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 661
8.5
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 661
8.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 663
9
Timed Automata
673
9.1
Timed Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 677
9.1.1
Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 684
9.1.2
Time Divergence, Timelock, and Zenoness . . . . . . . . . . . . . . . 690
9.2
Timed Computation Tree Logic . . . . . . . . . . . . . . . . . . . . . . . . . 698
9.3
TCTL Model Checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 705
9.3.1
Eliminating Timing Parameters . . . . . . . . . . . . . . . . . . . . . 706
9.3.2
Region Transition Systems
. . . . . . . . . . . . . . . . . . . . . . . 709
9.3.3
The TCTL Model-Checking Algorithm . . . . . . . . . . . . . . . . . 732
9.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 738

CONTENTS
xi
9.5
Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 739
9.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 740
10 Probabilistic Systems
745
10.1 Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 747
10.1.1 Reachability Probabilities . . . . . . . . . . . . . . . . . . . . . . . . 759
10.1.2 Qualitative Properties . . . . . . . . . . . . . . . . . . . . . . . . . . 770
10.2 Probabilistic Computation Tree Logic
. . . . . . . . . . . . . . . . . . . . . 780
10.2.1 PCTL Model Checking
. . . . . . . . . . . . . . . . . . . . . . . . . 785
10.2.2 The Qualitative Fragment of PCTL
. . . . . . . . . . . . . . . . . . 787
10.3 Linear-Time Properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 796
10.4 PCTL∗and Probabilistic Bisimulation . . . . . . . . . . . . . . . . . . . . . 806
10.4.1 PCTL∗
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 806
10.4.2 Probabilistic Bisimulation . . . . . . . . . . . . . . . . . . . . . . . . 808
10.5 Markov Chains with Costs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 816
10.5.1 Cost-Bounded Reachability . . . . . . . . . . . . . . . . . . . . . . . 818
10.5.2 Long-Run Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 827
10.6 Markov Decision Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 832
10.6.1 Reachability Probabilities . . . . . . . . . . . . . . . . . . . . . . . . 851
10.6.2 PCTL Model Checking
. . . . . . . . . . . . . . . . . . . . . . . . . 866
10.6.3 Limiting Properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . 869
10.6.4 Linear-Time Properties and PCTL∗
. . . . . . . . . . . . . . . . . . 880
10.6.5 Fairness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 883
10.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 894
10.8 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 896
10.9 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 899
A Appendix: Preliminaries
909
A.1 Frequently Used Symbols and Notations . . . . . . . . . . . . . . . . . . . . 909
A.2 Formal Languages
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 912
A.3 Propositional Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 915
A.4 Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 920
A.5 Computational Complexity
. . . . . . . . . . . . . . . . . . . . . . . . . . . 925
Bibliography
931
Index
965


Foreword
Society is increasingly dependent on dedicated computer and software systems to assist
us in almost every aspect of daily life. Often we are not even aware that computers and
software are involved. Several control functions in modern cars are based on embedded
software solutions, e.g., braking, airbags, cruise control, and fuel injection. Mobile phones,
communication systems, medical devices, audio and video systems, and consumer electron-
ics in general are containing vast amounts of software. Also transport, production, and
control systems are increasingly applying embedded software solutions to gain ﬂexibility
and cost-eﬃciency.
A common pattern is the constantly increasing complexity of systems, a trend which is
accelerated by the adaptation of wired and wireless networked solutions: in a modern
car the control functions are distributed over several processing units communicating over
dedicated networks and buses. Yet computer- and software-based solutions are becom-
ing ubiquitous and are to be found in several safety-critical systems. Therefore a main
challenge for the ﬁeld of computer science is to provide formalisms, techniques, and tools
that will enable the eﬃcient design of correct and well-functioning systems despite their
complexity.
Over the last two decades or so a very attractive approach toward the correctness of
computer-based control systems is that of model checking. Model checking is a formal
veriﬁcation technique which allows for desired behavioral properties of a given system to
be veriﬁed on the basis of a suitable model of the system through systematic inspection
of all states of the model. The attractiveness of model checking comes from the fact that
it is completely automatic – i.e., the learning curve for a user is very gentle – and that it
oﬀers counterexamples in case a model fails to satisfy a property serving as indispensable
debugging information. On top of this, the performance of model-checking tools has long
since proved mature as witnessed by a large number of successful industrial applications.
xiii

xiv
Foreword
It is my pleasure to recommend the excellent book Principles of Model Checking by Chris-
tel Baier and Joost-Pieter Katoen as the deﬁnitive textbook on model checking, providing
both a comprehensive and a comprehensible account of this important topic. The book
contains detailed and complete descriptions of ﬁrst principles of classical Linear Temporal
Logic (LTL) and Computation Tree Logic (CTL) model checking. Also, state-of-the art
methods for coping with state-space explosion, including symbolic model checking, ab-
straction and minimization techniques, and partial order reduction, are fully accounted
for. The book also covers model checking of real-time and probabilistic systems, important
new directions for model checking in which the authors, being two of the most industrious
and creative researchers of today, are playing a central role.
The exceptional pedagogical style of the authors provides careful explanations of con-
structions and proofs, plus numerous examples and exercises of a theoretical, practical
and tool-oriented nature. The book will therefore be the ideal choice as a textbook for
both graduate and advanced undergraduate students, as well as for self-study, and should
deﬁnitely be on the bookshelf of any researcher interested in the topic.
Kim Guldstrand Larsen
Professor in Computer Science
Aalborg University, Denmark
May 2007

Preface
It is fair to state, that in this digital era
correct systems for information processing
are more valuable than gold.
(H. Barendregt. The quest for correctness.
In: Images of SMC Research 1996, pages 39–58, 1996.)
This book is on model checking, a prominent formal veriﬁcation technique for assess-
ing functional properties of information and communication systems.
Model checking
requires a model of the system under consideration and a desired property and system-
atically checks whether or not the given model satisﬁes this property. Typical properties
that can be checked are deadlock freedom, invariants, and request-response properties.
Model checking is an automated technique to check the absence of errors (i.e., property
violations) and alternatively can be considered as an intelligent and eﬀective debugging
technique. It is a general approach and is applied in areas like hardware veriﬁcation and
software engineering. Due to unremitting improvements of underlying algorithms and data
structures together with hardware technology improvements, model-checking techniques
that two decades ago only worked for simple examples are nowadays applicable to more
realistic designs. It is fair to say that in the last two decades model checking has developed
as a mature and heavily used veriﬁcation and debugging technique.
Aims and Scope
This book attempts to introduce model checking from ﬁrst principles, so to speak, and is
intended as a textbook for bachelor and master students, as well as an introductory book
for researchers working in other areas of computer science or related ﬁelds. The reader
is introduced to the material by means of an extensive set of examples, most of which
are examples running throughout several chapters. The book provides a complete set of
basic results together with all detailed proofs. Each chapter is concluded by a summary,
xv

xvi
Preface
bibliographic notes, and a series of exercises, of both a theoretical and of a practical nature
(i.e., experimenting with actual model checkers).
Prerequisites
The concepts of model checking have their roots in mathematical foundations such as
propositional logic, automata theory and formal languages, data structures, and graph
algorithms. It is expected that readers are familiar with the basics of these topics when
starting with our book, although an appendix is provided that summarizes the essentials.
Knowledge on complexity theory is required for the theoretical complexity considerations
of the various model-checking algorithms.
Content
This book is divided into ten chapters. Chapter 1 motivates and introduces model check-
ing. Chapter 2 presents transition systems as a model for software and hardware systems.
Chapter 3 introduces a classiﬁcation of linear-time properties into safety and liveness,
and presents the notion of fairness. Automata-based algorithms for checking (regular)
safety and ω-regular properties are presented in Chapter 4. Chapter 5 deals with Linear
Temporal Logic (LTL) and shows how the algorithms of Chapter 4 can be used for LTL
model checking. Chapter 6 introduces the branching-time temporal logic Computation
Tree Logic (CTL), compares this to LTL, and shows how to perform CTL model check-
ing, both explicitly and symbolically. Chapter 7 deals with abstraction mechanisms that
are based on trace, bisimulation, and simulation relations. Chapter 8 treats partial-order
reduction for LTL and CTL. Chapter 9 is focused on real-time properties and timed au-
tomata, and the monograph is concluded with a chapter on the veriﬁcation of probabilistic
models. The appendix summarizes basic results on propositional logic, graphs, language,
and complexity theory.
How to Use This Book
A natural plan for an introductory course into model checking that lasts one semester
(two lectures a week) comprises Chapters 1 through 6. A follow-up course of about a
semester could cover Chapters 7 through 10, after a short refresher on LTL and CTL
model checking.

Preface
xvii
Acknowledgments
This monograph has been developed and extended during the last ﬁve years. The following
colleagues supported us by using (sometimes very) preliminary versions of this monograph:
Luca Aceto (Aalborg, Denmark and Reykjavik, Iceland), Henrik Reif Andersen (Copen-
hagen, Denmark), Dragan Boshnacki (Eindhoven, The Netherlands), Franck van Breughel
(Ottawa, Canada), Jos´ee Desharnais (Quebec, Canada), Susanna Donatelli (Turin, Italy),
Stefania Gnesi (Pisa, Italy), Michael R. Hansen (Lyngby, Denmark), Holger Hermanns
(Saarbr¨ucken, Germany), Yakov Kesselman (Chicago, USA), Martin Lange (Aarhus, Den-
mark), Kim G. Larsen (Aalborg, Denmark), Mieke Massink (Pisa, Italy), Mogens Nielsen
(Aarhus, Denmark), Albert Nymeyer (Sydney, Australia), Andreas Podelski (Freiburg,
Germany), Theo C. Ruys (Twente, The Netherlands), Thomas Schwentick (Dortmund,
Germany), Wolfgang Thomas (Aachen, Germany), Julie Vachon (Montreal, Canada), and
Glynn Winskel (Cambridge, UK). Many of you provided us with very helpful feedback
that helped us to improve the lecture notes.
Henrik Bohnenkamp, Tobias Blechmann, Frank Ciesinski, Marcus Gr¨osser, Tingting Han,
Joachim Klein, Sascha Kl¨uppelholz, Miriam Nasﬁ, Martin Neuh¨ausser, and Ivan S. Zapreev
provided us with many detailed comments, and provided several exercises. Yen Cao is
kindly thanked for drawing a part of the ﬁgures and Ulrich Schmidt-G¨ortz for his assistance
with the bibliography.
Many people have suggested improvements and pointed out mistakes. We thank everyone
for providing us with helpful comments.
Finally, we thank all our students in Aachen, Bonn, Dresden, and Enschede for their
feedback and comments.
Christel Baier
Joost-Pieter Katoen


Chapter 1
System Veriﬁcation
Our reliance on the functioning of ICT systems (Information and Communication Tech-
nology) is growing rapidly. These systems are becoming more and more complex and are
massively encroaching on daily life via the Internet and all kinds of embedded systems
such as smart cards, hand-held computers, mobile phones, and high-end television sets.
In 1995 it was estimated that we are confronted with about 25 ICT devices on a daily
basis. Services like electronic banking and teleshopping have become reality. The daily
cash ﬂow via the Internet is about 1012 million US dollars. Roughly 20% of the product
development costs of modern transportation devices such as cars, high-speed trains, and
airplanes is devoted to information processing systems. ICT systems are universal and om-
nipresent. They control the stock exchange market, form the heart of telephone switches,
are crucial to Internet technology, and are vital for several kinds of medical systems. Our
reliance on embedded systems makes their reliable operation of large social importance.
Besides oﬀering a good performance in terms like response times and processing capacity,
the absence of annoying errors is one of the major quality indications.
It is all about money. We are annoyed when our mobile phone malfunctions, or when
our video recorder reacts unexpectedly and wrongly to our issued commands.
These
software and hardware errors do not threaten our lives, but may have substantial ﬁnancial
consequences for the manufacturer. Correct ICT systems are essential for the survival of
a company. Dramatic examples are known. The bug in Intel’s Pentium II ﬂoating-point
division unit in the early nineties caused a loss of about 475 million US dollars to replace
faulty processors, and severely damaged Intel’s reputation as a reliable chip manufacturer.
The software error in a baggage handling system postponed the opening of Denver’s airport
for 9 months, at a loss of 1.1 million US dollar per day. Twenty-four hours of failure of
1

2
System Veriﬁcation
Figure 1.1: The Ariane-5 launch on June 4, 1996; it crashed 36 seconds after the launch
due to a conversion of a 64-bit ﬂoating point into a 16-bit integer value.
the worldwide online ticket reservation system of a large airplane company will cause its
bankruptcy because of missed orders.
It is all about safety: errors can be catastrophic too. The fatal defects in the control
software of the Ariane-5 missile (Figure 1.1), the Mars Pathﬁnder, and the airplanes of
the Airbus family led to headlines in newspapers all over the world and are notorious by
now. Similar software is used for the process control of safety-critical systems such as
chemical plants, nuclear power plants, traﬃc control and alert systems, and storm surge
barriers. Clearly, bugs in such software can have disastrous consequences. For example, a
software ﬂaw in the control part of the radiation therapy machine Therac-25 caused the
death of six cancer patients between 1985 and 1987 as they were exposed to an overdose
of radiation.
The increasing reliance of critical applications on information processing leads us to state:
The reliability of ICT systems is a key issue
in the system design process.
The magnitude of ICT systems, as well as their complexity, grows apace. ICT systems
are no longer standalone, but are typically embedded in a larger context, connecting
and interacting with several other components and systems.
They thus become much
more vulnerable to errors – the number of defects grows exponentially with the number
of interacting system components.
In particular, phenomena such as concurrency and
nondeterminism that are central to modeling interacting systems turn out to be very hard
to handle with standard techniques. Their growing complexity, together with the pressure
to drastically reduce system development time (“time-to-market”), makes the delivery of
low-defect ICT systems an enormously challenging and complex activity.

System Veriﬁcation
3
Hard- and Software Veriﬁcation
System veriﬁcation techniques are being applied to the design of ICT systems in a more
reliable way. Brieﬂy, system veriﬁcation is used to establish that the design or product
under consideration possesses certain properties. The properties to be validated can be
quite elementary, e.g., a system should never be able to reach a situation in which no
progress can be made (a deadlock scenario), and are mostly obtained from the system’s
speciﬁcation.
This speciﬁcation prescribes what the system has to do and what not,
and thus constitutes the basis for any veriﬁcation activity. A defect is found once the
system does not fulﬁll one of the speciﬁcation’s properties.
The system is considered
to be “correct” whenever it satisﬁes all properties obtained from its speciﬁcation.
So
correctness is always relative to a speciﬁcation, and is not an absolute property of a
system. A schematic view of veriﬁcation is depicted in Figure 1.2.
Design Process
bug(s) found
no bugs found
product or
prototype
properties
speciﬁcation
system
Veriﬁcation
Figure 1.2: Schematic view of an a posteriori system veriﬁcation.
This book deals with a veriﬁcation technique called model checking that starts from a
formal system speciﬁcation.
Before introducing this technique and discussing the role
of formal speciﬁcations, we brieﬂy review alternative software and hardware veriﬁcation
techniques.
Software Veriﬁcation
Peer reviewing and testing are the major software veriﬁcation
techniques used in practice.
A peer review amounts to a software inspection carried out by a team of software engineers
that preferably has not been involved in the development of the software under review. The

4
System Veriﬁcation
uncompiled code is not executed, but analyzed completely statically. Empirical studies
indicate that peer review provides an eﬀective technique that catches between 31 % and
93 % of the defects with a median around 60%. While mostly applied in a rather ad hoc
manner, more dedicated types of peer review procedures, e.g., those that are focused at
speciﬁc error-detection goals, are even more eﬀective. Despite its almost complete manual
nature, peer review is thus a rather useful technique. It is therefore not surprising that
some form of peer review is used in almost 80% of all software engineering projects. Due
to its static nature, experience has shown that subtle errors such as concurrency and
algorithm defects are hard to catch using peer review.
Software testing constitutes a signiﬁcant part of any software engineering project. Between
30% and 50% of the total software project costs are devoted to testing. As opposed to peer
review, which analyzes code statically without executing it, testing is a dynamic technique
that actually runs the software. Testing takes the piece of software under consideration
and provides its compiled code with inputs, called tests. Correctness is thus determined
by forcing the software to traverse a set of execution paths, sequences of code statements
representing a run of the software. Based on the observations during test execution, the
actual output of the software is compared to the output as documented in the system
speciﬁcation. Although test generation and test execution can partly be automated, the
comparison is usually performed by human beings. The main advantage of testing is that
it can be applied to all sorts of software, ranging from application software (e.g., e-business
software) to compilers and operating systems. As exhaustive testing of all execution paths
is practically infeasible; in practice only a small subset of these paths is treated. Testing
can thus never be complete. That is to say, testing can only show the presence of errors,
not their absence. Another problem with testing is to determine when to stop. Practically,
it is hard, and mostly impossible, to indicate the intensity of testing to reach a certain
defect density – the fraction of defects per number of uncommented code lines.
Studies have provided evidence that peer review and testing catch diﬀerent classes of de-
fects at diﬀerent stages in the development cycle. They are therefore often used together.
To increase the reliability of software, these software veriﬁcation approaches are comple-
mented with software process improvement techniques, structured design and speciﬁcation
methods (such as the Uniﬁed Modeling Language), and the use of version and conﬁgura-
tion management control systems. Formal techniques are used, in one form or another, in
about 10 % to 15% of all software projects. These techniques are discussed later in this
chapter.
Catching software errors: the sooner the better. It is of great importance to locate soft-
ware bugs. The slogan is: the sooner the better. The costs of repairing a software ﬂaw
during maintenance are roughly 500 times higher than a ﬁx in an early design phase (see
Figure 1.3). System veriﬁcation should thus take place early stage in the design process.

System Veriﬁcation
5
Analysis
Conceptual
Design
Programming
Unit Testing
Operation
0
Time (non-linear)
errors
errors
detected
cost of
correction
per error
50%
40%
30%
20%
10%
0%
2.5
5
7.5
10
12.5
(in %)
introduced
(in %)
System Testing
(in 1,000 US $)
Figure 1.3: Software lifecycle and error introduction, detection, and repair costs [275].
About 50% of all defects are introduced during programming, the phase in which actual
coding takes place. Whereas just 15% of all errors are detected in the initial design stages,
most errors are found during testing. At the start of unit testing, which is oriented to
discovering defects in the individual software modules that make up the system, a defect
density of about 20 defects per 1000 lines of (uncommented) code is typical. This has
been reduced to about 6 defects per 1000 code lines at the start of system testing, where
a collection of such modules that constitutes a real product is tested. On launching a new
software release, the typical accepted software defect density is about one defect per 1000
lines of code lines1.
Errors are typically concentrated in a few software modules – about half of the modules
are defect free, and about 80% of the defects arise in a small fraction (about 20%) of
the modules – and often occur when interfacing modules. The repair of errors that are
detected prior to testing can be done rather economically. The repair cost signiﬁcantly
increases from about $ 1000 (per error repair) in unit testing to a maximum of about
$ 12,500 when the defect is demonstrated during system operation only. It is of vital
importance to seek techniques that ﬁnd defects as early as possible in the software design
process: the costs to repair them are substantially lower, and their inﬂuence on the rest
of the design is less substantial.
Hardware Veriﬁcation
Preventing errors in hardware design is vital.
Hardware is
subject to high fabrication costs; ﬁxing defects after delivery to customers is diﬃcult, and
quality expectations are high.
Whereas software defects can be repaired by providing
1For some products this is much higher, though. Microsoft has acknowledged that Windows 95 contained
at least 5000 defects. Despite the fact that users were daily confronted with anomalous behavior, Windows
95 was very successful.

6
System Veriﬁcation
users with patches or updates – nowadays users even tend to anticipate and accept this –
hardware bug ﬁxes after delivery to customers are very diﬃcult and mostly require refab-
rication and redistribution. This has immense economic consequences. The replacement
of the faulty Pentium II processors caused Intel a loss of about $ 475 million. Moore’s
law – the number of logical gates in a circuit doubles every 18 months – has proven to
be true in practice and is a major obstacle to producing correct hardware.
Empirical
studies have indicated that more than 50% of all ASICs (Application-Speciﬁc Integrated
Circuits) do not work properly after initial design and fabrication. It is not surprising
that chip manufacturers invest a lot in getting their designs right. Hardware veriﬁcation
is a well-established part of the design process. The design eﬀort in a typical hardware
design amounts to only 27% of the total time spent on the chip; the rest is devoted to
error detection and prevention.
Hardware veriﬁcation techniques. Emulation, simulation, and structural analysis are the
major techniques used in hardware veriﬁcation.
Structural analysis comprises several speciﬁc techniques such as synthesis, timing analysis,
and equivalence checking that are not described in further detail here.
Emulation is a kind of testing. A reconﬁgurable generic hardware system (the emulator) is
conﬁgured such that it behaves like the circuit under consideration and is then extensively
tested. As with software testing, emulation amounts to providing a set of stimuli to the
circuit and comparing the generated output with the expected output as laid down in
the chip speciﬁcation. To fully test the circuit, all possible input combinations in every
possible system state should be examined. This is impractical and the number of tests
needs to be reduced signiﬁcantly, yielding potential undiscovered errors.
With simulation, a model of the circuit at hand is constructed and simulated. Models are
typically provided using hardware description languages such as Verilog or VHDL that
are both standardized by IEEE. Based on stimuli, execution paths of the chip model are
examined using a simulator. These stimuli may be provided by a user, or by automated
means such as a random generator. A mismatch between the simulator’s output and the
output described in the speciﬁcation determines the presence of errors. Simulation is like
testing, but is applied to models. It suﬀers from the same limitations, though: the number
of scenarios to be checked in a model to get full conﬁdence goes beyond any reasonable
subset of scenarios that can be examined in practice.
Simulation is the most popular hardware veriﬁcation technique and is used in various
design stages, e.g., at register-transfer level, gate and transistor level. Besides these error
detection techniques, hardware testing is needed to ﬁnd fabrication faults resulting from
layout defects in the fabrication process.

Model Checking
7
1.1
Model Checking
In software and hardware design of complex systems, more time and eﬀort are spent on
veriﬁcation than on construction. Techniques are sought to reduce and ease the veriﬁcation
eﬀorts while increasing their coverage. Formal methods oﬀer a large potential to obtain an
early integration of veriﬁcation in the design process, to provide more eﬀective veriﬁcation
techniques, and to reduce the veriﬁcation time.
Let us ﬁrst brieﬂy discuss the role of formal methods. To put it in a nutshell, formal
methods can be considered as “the applied mathematics for modeling and analyzing ICT
systems”. Their aim is to establish system correctness with mathematical rigor. Their
great potential has led to an increasing use by engineers of formal methods for the ver-
iﬁcation of complex software and hardware systems.
Besides, formal methods are one
of the “highly recommended” veriﬁcation techniques for software development of safety-
critical systems according to, e.g., the best practices standard of the IEC (International
Electrotechnical Commission) and standards of the ESA (European Space Agency). The
resulting report of an investigation by the FAA (Federal Aviation Authority) and NASA
(National Aeronautics and Space Administration) about the use of formal methods con-
cludes that
Formal methods should be part of the education of every computer scientist
and software engineer, just as the appropriate branch of applied maths is a
necessary part of the education of all other engineers.
During the last two decades, research in formal methods has led to the development of
some very promising veriﬁcation techniques that facilitate the early detection of defects.
These techniques are accompanied by powerful software tools that can be used to automate
various veriﬁcation steps. Investigations have shown that formal veriﬁcation procedures
would have revealed the exposed defects in, e.g., the Ariane-5 missile, Mars Pathﬁnder,
Intel’s Pentium II processor, and the Therac-25 therapy radiation machine.
Model-based veriﬁcation techniques are based on models describing the possible system
behavior in a mathematically precise and unambiguous manner. It turns out that – prior
to any form of veriﬁcation – the accurate modeling of systems often leads to the discov-
ery of incompleteness, ambiguities, and inconsistencies in informal system speciﬁcations.
Such problems are usually only discovered at a much later stage of the design. The system
models are accompanied by algorithms that systematically explore all states of the system
model. This provides the basis for a whole range of veriﬁcation techniques ranging from an
exhaustive exploration (model checking) to experiments with a restrictive set of scenarios
in the model (simulation), or in reality (testing). Due to unremitting improvements of un-

8
System Veriﬁcation
derlying algorithms and data structures, together with the availability of faster computers
and larger computer memories, model-based techniques that a decade ago only worked for
very simple examples are nowadays applicable to realistic designs. As the startingpoint
of these techniques is a model of the system under consideration, we have as a given fact
that
Any veriﬁcation using model-based techniques is only
as good as the model of the system.
Model checking is a veriﬁcation technique that explores all possible system states in a
brute-force manner. Similar to a computer chess program that checks possible moves, a
model checker, the software tool that performs the model checking, examines all possible
system scenarios in a systematic manner. In this way, it can be shown that a given system
model truly satisﬁes a certain property. It is a real challenge to examine the largest possible
state spaces that can be treated with current means, i.e., processors and memories. State-
of-the-art model checkers can handle state spaces of about 108 to 109 states with explicit
state-space enumeration. Using clever algorithms and tailored data structures, larger state
spaces (1020 up to even 10476 states) can be handled for speciﬁc problems. Even the subtle
errors that remain undiscovered using emulation, testing and simulation can potentially
be revealed using model checking.
Model Checking
Modeling
satisﬁed
counterexample
requirements
Formalizing
speciﬁcation
property
Simulation
location
error
system model
system
violated +
Figure 1.4: Schematic view of the model-checking approach.
Typical properties that can be checked using model checking are of a qualitative nature:
Is the generated result OK?, Can the system reach a deadlock situation, e.g., when two

Model Checking
9
concurrent programs are waiting for each other and thus halting the entire system? But
also timing properties can be checked: Can a deadlock occur within 1 hour after a system
reset?, or, Is a response always received within 8 minutes? Model checking requires a
precise and unambiguous statement of the properties to be examined. As with making
an accurate system model, this step often leads to the discovery of several ambiguities
and inconsistencies in the informal documentation. For instance, the formalization of all
system properties for a subset of the ISDN user part protocol revealed that 55% (!) of the
original, informal system requirements were inconsistent.
The system model is usually automatically generated from a model description that is
speciﬁed in some appropriate dialect of programming languages like C or Java or hard-
ware description languages such as Verilog or VHDL. Note that the property speciﬁcation
prescribes what the system should do, and what it should not do, whereas the model
description addresses how the system behaves. The model checker examines all relevant
system states to check whether they satisfy the desired property. If a state is encountered
that violates the property under consideration, the model checker provides a counterex-
ample that indicates how the model could reach the undesired state. The counterexample
describes an execution path that leads from the initial system state to a state that violates
the property being veriﬁed. With the help of a simulator, the user can replay the violating
scenario, in this way obtaining useful debugging information, and adapt the model (or the
property) accordingly (see Figure 1.4).
Model checking has been successfully applied to several ICT systems and their applications.
For instance, deadlocks have been detected in online airline reservation systems, modern e-
commerce protocols have been veriﬁed, and several studies of international IEEE standards
for in-house communication of domestic appliances have led to signiﬁcant improvements
of the system speciﬁcations.
Five previously undiscovered errors were identiﬁed in an
execution module of the Deep Space 1 spacecraft controller (see Figure 1.5), in one case
identifying a major design ﬂaw.
A bug identical to one discovered by model checking
escaped testing and caused a deadlock during a ﬂight experiment 96 million km from
earth. In the Netherlands, model checking has revealed several serious design ﬂaws in the
control software of a storm surge barrier that protects the main port of Rotterdam against
ﬂooding.
Example 1.1.
Concurrency and Atomicity
Most errors, such as the ones exposed in the Deep Space-1 spacecraft, are concerned
with classical concurrency errors. Unforeseen interleavings between processes may cause
undesired events to happen. This is exempliﬁed by analysing the following concurrent
program, in which three processes, Inc, Dec, and Reset, cooperate. They operate on the
shared integer variable x with arbitrary initial value that can be accessed (i.e., read), and

10
System Veriﬁcation
Figure 1.5: Modules of NASA’s Deep Space-1 space-craft (launched in October 1998) have
been thoroughly examined using model checking.
modiﬁed (i.e., written) by each of the individual processes. The processes are
proc Inc
=
while true do if x < 200 then x := x + 1 ﬁod
proc Dec
=
while true do if x > 0 then x := x −1 ﬁod
proc Reset
=
while true do if x = 200 then x := 0 ﬁod
Process Inc increments x if its value is smaller than 200, Dec decrements x if its value is at
least 1, and Reset resets x once it has reached the value 200. They all do so repetitively.
Is the value of x always between (and including) 0 and 200? At ﬁrst sight this seems to
be true. A more thorough inspection, though, reveals that this is not the case. Suppose
x equals 200.
Process Dec tests the value of x, and passes the test, as x exceeds 0.
Then, control is taken over by process Reset. It tests the value of x, passes its test, and
immediately resets x to zero. Then, control is returned to process Dec and this process
decrements x by one, resulting in a negative value for x (viz. -1). Intuitively, we tend to
interpret the tests on x and the assignments to x as being executed atomically, i.e., as a
single step, whereas in reality this is (mostly) not the case.

Characteristics of Model Checking
11
1.2
Characteristics of Model Checking
This book is devoted to the principles of model checking:
Model checking is an automated technique that, given
a ﬁnite-state model of a system and a formal property,
systematically checks whether this property holds
for (a given state in) that model.
The next chapters treat the elementary technical details of model checking. This section
describes the process of model checking (how to use it), presents its main advantages and
drawbacks, and discusses its role in the system development cycle.
1.2.1
The Model-Checking Process
In applying model checking to a design the following diﬀerent phases can be distinguished:
• Modeling phase:
– model the system under consideration using the model description language of
the model checker at hand;
– as a ﬁrst sanity check and quick assessment of the model perform some simu-
lations;
– formalize the property to be checked using the property speciﬁcation language.
• Running phase: run the model checker to check the validity of the property in the
system model.
• Analysis phase:
– property satisﬁed? →check next property (if any);
– property violated? →
1. analyze generated counterexample by simulation;
2. reﬁne the model, design, or property;
3. repeat the entire procedure.
– out of memory? →try to reduce the model and try again.

12
System Veriﬁcation
In addition to these steps, the entire veriﬁcation should be planned, administered, and
organized.
This is called veriﬁcation organization.
We discuss these phases of model
checking in somewhat more detail below.
Modeling
The prerequisite inputs to model checking are a model of the system under
consideration and a formal characterization of the property to be checked.
Models of systems describe the behavior of systems in an accurate and unambiguous
way.
They are mostly expressed using ﬁnite-state automata, consisting of a ﬁnite set
of states and a set of transitions. States comprise information about the current values
of variables, the previously executed statement (e.g., a program counter), and the like.
Transitions describe how the system evolves from one state into another. For realistic
systems, ﬁnite-state automata are described using a model description language such as
an appropriate dialect/extension of C, Java, VHDL, or the like. Modeling systems, in
particular concurrent ones, at the right abstraction level is rather intricate and is really
an art; it is treated in more detail in Chapter 2.
In order to improve the quality of the model, a simulation prior to the model checking
can take place. Simulation can be used eﬀectively to get rid of the simpler category of
modeling errors. Eliminating these simpler errors before any form of thorough checking
takes place may reduce the costly and time-consuming veriﬁcation eﬀort.
To make a rigorous veriﬁcation possible, properties should be described in a precise and
unambiguous manner. This is typically done using a property speciﬁcation language. We
focus in particular on the use of a temporal logic as a property speciﬁcation language,
a form of modal logic that is appropriate to specify relevant properties of ICT systems.
In terms of mathematical logic, one checks that the system description is a model of
a temporal logic formula. This explains the term “model checking”. Temporal logic is
basically an extension of traditional propositional logic with operators that refer to the
behavior of systems over time. It allows for the speciﬁcation of a broad range of relevant
system properties such as functional correctness (does the system do what it is supposed
to do?), reachability (is it possible to end up in a deadlock state?), safety (“something
bad never happens”), liveness (“something good will eventually happen”), fairness (does,
under certain conditions, an event occur repeatedly?), and real-time properties (is the
system acting in time?).
Although the aforementioned steps are often well understood, in practice it may be a
serious problem to judge whether the formalized problem statement (model + properties)
is an adequate description of the actual veriﬁcation problem. This is also known as the
validation problem. The complexity of the involved system, as well as the lack of precision

Characteristics of Model Checking
13
of the informal speciﬁcation of the system’s functionality, may make it hard to answer this
question satisfactorily. Veriﬁcation and validation should not be confused. Veriﬁcation
amounts to check that the design satisﬁes the requirements that have been identiﬁed, i.e.,
veriﬁcation is “check that we are building the thing right”. In validation, it is checked
whether the formal model is consistent with the informal conception of the design, i.e.,
validation is “check that we are verifying the right thing”.
Running the Model Checker
The model checker ﬁrst has to be initialized by ap-
propriately setting the various options and directives that may be used to carry out the
exhaustive veriﬁcation.
Subsequently, the actual model checking takes place.
This is
basically a solely algorithmic approach in which the validity of the property under consid-
eration is checked in all states of the system model.
Analyzing the Results
There are basically three possible outcomes: the speciﬁed
property is either valid in the given model or not, or the model turns out to be too large
to ﬁt within the physical limits of the computer memory.
In case the property is valid, the following property can be checked, or, in case all properties
have been checked, the model is concluded to possess all desired properties.
Whenever a property is falsiﬁed, the negative result may have diﬀerent causes. There may
be a modeling error, i.e., upon studying the error it is discovered that the model does not
reﬂect the design of the system. This implies a correction of the model, and veriﬁcation
has to be restarted with the improved model. This reveriﬁcation includes the veriﬁcation
of those properties that were checked before on the erroneous model and whose veriﬁcation
may be invalidated by the model correction! If the error analysis shows that there is no
undue discrepancy between the design and its model, then either a design error has been
exposed, or a property error has taken place. In case of a design error, the veriﬁcation
is concluded with a negative result, and the design (together with its model) has to be
improved. It may be the case that upon studying the exposed error it is discovered that the
property does not reﬂect the informal requirement that had to be validated. This implies
a modiﬁcation of the property, and a new veriﬁcation of the model has to be carried out.
As the model is not changed, no reveriﬁcation of properties that were checked before has
to take place. The design is veriﬁed if and only if all properties have been checked with
respect to a valid model.
Whenever the model is too large to be handled – state spaces of real-life systems may be
many orders of magnitude larger than what can be stored by currently available memories
– there are various ways to proceed. A possibility is to apply techniques that try to exploit

14
System Veriﬁcation
implicit regularities in the structure of the model. Examples of these techniques are the
representation of state spaces using symbolic techniques such as binary decision diagrams
or partial order reduction. Alternatively, rigorous abstractions of the complete system
model are used. These abstractions should preserve the (non-)validity of the properties
that need to be checked. Often, abstractions can be obtained that are suﬃciently small
with respect to a single property. In that case, diﬀerent abstractions need to be made for
the model at hand. Another way of dealing with state spaces that are too large is to give
up the precision of the veriﬁcation result. The probabilistic veriﬁcation approaches explore
only part of the state space while making a (often negligible) sacriﬁce in the veriﬁcation
coverage. The most important state-space reduction strategies are discussed in Chapters
7 through 9 of this monograph.
Veriﬁcation Organization
The entire model-checking process should be well orga-
nized, well structured, and well planned. Industrial applications of model checking have
provided evidence that the use of version and conﬁguration management is of particular
relevance. During the veriﬁcation process, for instance, diﬀerent model descriptions are
made describing diﬀerent parts of the system, various versions of the veriﬁcation mod-
els are available (e.g., due to abstraction), and plenty of veriﬁcation parameters (e.g.,
model-checking options) and results (diagnostic traces, statistics) are available. This in-
formation needs to be documented and maintained very carefully in order to manage a
practical model-checking process and to allow the reproduction of the experiments that
were carried out.
1.2.2
Strengths and Weaknesses
The strengths of model checking:
• It is a general veriﬁcation approach that is applicable to a wide range of applications
such as embedded systems, software engineering, and hardware design.
• It supports partial veriﬁcation, i.e., properties can be checked individually, thus
allowing focus on the essential properties ﬁrst. No complete requirement speciﬁcation
is needed.
• It is not vulnerable to the likelihood that an error is exposed; this contrasts with
testing and simulation that are aimed at tracing the most probable defects.
• It provides diagnostic information in case a property is invalidated; this is very useful
for debugging purposes.

Characteristics of Model Checking
15
• It is a potential “push-button” technology; the use of model checking requires neither
a high degree of user interaction nor a high degree of expertise.
• It enjoys a rapidly increasing interest by industry; several hardware companies have
started their in-house veriﬁcation labs, job oﬀers with required skills in model check-
ing frequently appear, and commercial model checkers have become available.
• It can be easily integrated in existing development cycles; its learning curve is not
very steep, and empirical studies indicate that it may lead to shorter development
times.
• It has a sound and mathematical underpinning; it is based on theory of graph algo-
rithms, data structures, and logic.
The weaknesses of model checking:
• It is mainly appropriate to control-intensive applications and less suited for data-
intensive applications as data typically ranges over inﬁnite domains.
• Its applicability is subject to decidability issues; for inﬁnite-state systems, or reason-
ing about abstract data types (which requires undecidable or semi-decidable logics),
model checking is in general not eﬀectively computable.
• It veriﬁes a system model, and not the actual system (product or prototype) itself;
any obtained result is thus as good as the system model. Complementary techniques,
such as testing, are needed to ﬁnd fabrication faults (for hardware) or coding errors
(for software).
• It checks only stated requirements, i.e., there is no guarantee of completeness. The
validity of properties that are not checked cannot be judged.
• It suﬀers from the state-space explosion problem, i.e., the number of states needed
to model the system accurately may easily exceed the amount of available computer
memory. Despite the development of several very eﬀective methods to combat this
problem (see Chapters 7 and 8), models of realistic systems may still be too large to
ﬁt in memory.
• Its usage requires some expertise in ﬁnding appropriate abstractions to obtain smaller
system models and to state properties in the logical formalism used.
• It is not guaranteed to yield correct results: as with any tool, a model checker may
contain software defects.2
2Parts of the more advanced model-checking procedures have been formally proven correct using theo-
rem provers to circumvent this.

16
System Veriﬁcation
• It does not allow checking generalizations: in general, checking systems with an ar-
bitrary number of components, or parameterized systems, cannot be treated. Model
checking can, however, suggest results for arbitrary parameters that may be veriﬁed
using proof assistants.
We believe that one can never achieve absolute guaranteed correctness for systems of
realistic size. Despite the above limitations we conclude that
Model checking is an eﬀective technique
to expose potential design errors.
Thus, model checking can provide a signiﬁcant increase in the level of conﬁdence of a
system design.
1.3
Bibliographic Notes
Model checking. Model checking originates from the independent work of two pairs in
the early eighties: Clarke and Emerson [86] and Queille and Sifakis [347].
The term
model checking was coined by Clarke and Emerson. The brute-force examination of the
entire state space in model checking can be considered as an extension of automated
protocol validation techniques by Hajek [182] and West [419, 420]. While these earlier
techniques were restricted to checking the absence of deadlocks or livelocks, model checking
allows for the examination of broader classes of properties. Introductory papers on model
checking can be found in [94, 95, 96, 293, 426]. The limitations of model checking were
discussed by Apt and Kozen [17]. More information on model checking is available in the
earlier books by Holzmann [205], McMillan [288], and Kurshan [250] and the more recent
works by Clarke, Grumberg, and Peled [92], Huth and Ryan [219], Schneider [365], and
B´erard et al. [44]. The model-checking trajectory has recently been described by Ruys
and Brinksma [360].
Software veriﬁcation. Empirical data about software engineering is gathered by the Cen-
ter for Empirically Based Software Engineering (www.cebase.org); their collected data
about software defects has recently been summarized by Boehm and Basili [53]. The dif-
ferent characterizations of veriﬁcation (“are we building the thing right?”) and validation
(“are we building the right thing?”) originate from Boehm [52]. An overview of software
testing is given by Whittaker [421]; books about software testing are by Myers [308] and
Beizer [36]. Testing based on formal speciﬁcations has been studied extensively in the area
of communication protocols. This has led to an international standard for conformance

Bibliographic Notes
17
testing [222]. The use of software veriﬁcation techniques by the German software industry
has been studied by Liggesmeyer et al. [275]. Books by Storey [381] and Leveson [269]
describe techniques for developing safety-critical software and discuss the role of formal
veriﬁcation in this context. Rushby [359] addresses the role of formal methods for devel-
oping safety-critical software. The book of Peled [327] gives a detailed account of formal
techniques for software reliability that includes testing, model checking, and deductive
methods.
Model-checking software. Model-checking communication protocols has become popular
through the pioneering work of Holzmann [205, 206]. An interesting project at Bell Labs
in which a model-checking team and a traditional design team worked on the design of
part of the ISDN user part protocol has been reported by Holzmann [207]. In this large
case study, 112 serious design ﬂaws were discovered while checking 145 formal properties in
about 10,000 veriﬁcation runs. Errors found by Clarke et al. [89] in the IEEE Futurebus+
standard (checking a model of more than 1030 states) has led to a substantial revision of
the protocol by IEEE. Chan et al. [79] used model checking to verify the control software
of a traﬃc control and alert system for airplanes. Recently, Staunstrup et al. [377] have
reported the succesful model checking of a train model consisting of 1421 state machines
comprising a state space of 10476 states. Lowe [278], using model checking, discovered a
ﬂaw in the well-known Needham-Schroeder authentication algorithm that remained un-
detected for over 17 years. The usage of formal methods (that includes model checking)
in the software development process of a safety-critical system within a Dutch software
house is presented by Tretmans, Wijbrans, and Chaudron [393]. The formal analysis of
NASA’s Mars Pathﬁnder and the Deep Space-1 spacecraft are addressed by Havelund,
Lowry, and Penix [194], and Holzmann, Najm, and Serhrouchini [210], respectively. The
automated generation of abstract models amenable to model checking from programs
written in programming languages such as C, C++, or Java has been pursued, for instance,
by Godefroid [170], Dwyer, Hatcliﬀ, and coworkers [193], at Microsoft Research by Ball,
Podelski, and Rajamani [33] and at NASA Research by Havelund and Pressburger [195].
Model-checking hardware. Applying model checking to hardware originates from Browne
et al. [66] analyzing some moderate-size self-timed sequential circuits. Successful appli-
cations of (symbolic) model checking to large hardware systems have been ﬁrst reported
by Burch et al. [75] in the early nineties. They analyzed a synchronous pipeline circuit
of approximately 1020 states. Overviews of formal hardware veriﬁcation techniques can
be found in works by Gupta [179], and the books by Yoeli [428] and Kropf [246]. The
need for formal veriﬁcation techniques for hardware veriﬁcation has been advocated by,
among others, Sangiovanni-Vincentelli, McGeer, and Saldanha [362]. The integration of
model-checking techniques for error ﬁnding in the hardware development process at IBM
has been recently described by Schlipf et al. [364] and Abarbanel-Vinov et al. [2]. They
conclude that model checking is a powerful extension of the traditional veriﬁcation pro-

18
System Veriﬁcation
cess, and consider it as complementary to simulation/emulation. The design of a memory
bus adapter at IBM showed, e.g., that 24% of all defects were found with model checking,
while 40% of these errors would most likely not have been found by simulation.

Chapter 2
Modelling Concurrent Systems
A prerequisite for model checking is a model of the system under consideration. This
chapter introduces transition systems, a (by now) standard class of models to represent
hardware and software systems. Diﬀerent aspects for modeling concurrent systems are
treated, ranging from the simple case in which processes run completely autonomously
to the more realistic setting where processes communicate in some way. The chapter is
concluded by considering the problem of state-space explosion.
2.1
Transition Systems
Transition systems are often used in computer science as models to describe the behavior of
systems. They are basically directed graphs where nodes represent states, and edges model
transitions, i.e., state changes. A state describes some information about a system at a
certain moment of its behavior. For instance, a state of a traﬃc light indicates the current
color of the light. Similarly, a state of a sequential computer program indicates the current
values of all program variables together with the current value of the program counter that
indicates the next program statement to be executed. In a synchronous hardware circuit,
a state typically represents the current value of the registers together with the values of
the input bits. Transitions specify how the system can evolve from one state to another.
In the case of the traﬃc light a transition may indicate a switch from one color to another,
whereas for the sequential program a transition typically corresponds to the execution of a
statement and may involve the change of some variables and the program counter. In the
case of the synchronous hardware circuit, a transition models the change of the registers
and output bits on a new set of inputs.
19

20
Modelling Concurrent Systems
In the literature, many diﬀerent types of transition systems have been proposed.
We
use transition systems with action names for the transitions (state changes) and atomic
propositions for the states.
Action names will be used for describing communication
mechanisms between processes. We use letters at the beginning of the Greek alphabet
(such as α, β, and so on) to denote actions. Atomic propositions are used to formalize
temporal characteristics. Atomic propositions intuitively express simple known facts about
the states of the system under consideration. They are denoted by arabic letters from the
beginning of the alphabet, such as a, b, c, and so on. Examples of atomic propositions are
“x equals 0”, or “x is smaller than 200” for some given integer variable x. Other examples
are “there is more than a liter of ﬂuid in the tank” or “there are no customers in the
shop”.
Deﬁnition 2.1.
Transition System (TS)
A transition system TS is a tuple (S, Act, →, I, AP, L) where
• S is a set of states,
• Act is a set of actions,
• −→⊆S × Act × S is a transition relation,
• I ⊆S is a set of initial states,
• AP is a set of atomic propositions, and
• L : S →2AP is a labeling function.
TS is called ﬁnite if S, Act, and AP are ﬁnite.
For convenience, we write s
α
−−→s′ instead of (s, α, s′) ∈−→. The intuitive behavior of a
transition system can be described as follows. The transition system starts in some initial
state s0 ∈I and evolves according to the transition relation −→. That is, if s is the
current state, then a transition s
α
−−→s′ originating from s is selected nondeterministically
and taken, i.e., the action α is performed and the transition system evolves from state
s into the state s′. This selection procedure is repeated in state s′ and ﬁnishes once a
state is encountered that has no outgoing transitions. (Note that I may be empty; in that
case, the transition system has no behavior at all as no initial state can be selected.) It
is important to realize that in case a state has more than one outgoing transition, the
“next” transition is chosen in a purely nondeterministic fashion. That is, the outcome of
this selection process is not known a priori, and, hence, no statement can be made about

Transition Systems
21
the likelihood with which a certain transition is selected. Similarly, when the set of initial
states consists of more than one state, the start state is selected nondeterministically.
The labeling function L relates a set L(s) ∈2AP of atomic propositions to any state s.1
L(s) intuitively stands for exactly those atomic propositions a ∈AP which are satisﬁed
by state s. Given that Φ is a propositional logic formula, then s satisﬁes the formula Φ if
the evaluation induced by L(s) makes the formula Φ true; that is:
s |= Φ
iﬀ
L(s) |= Φ.
(Basic principles of propositional logic are explained in Appendix A.3, see page 915 ﬀ.)
Example 2.2.
Beverage Vending Machine
We consider an (somewhat foolish) example, which has been established as standard in the
ﬁeld of process calculi. The transition system in Figure 2.1 models a preliminary design
of a beverage vending machine. The machine can either deliver beer or soda. States are
represented by ovals and transitions by labeled edges. State names are depicted inside the
ovals. Initial states are indicated by having an incoming arrow without source.
pay
select
soda
beer
insert coin
τ
τ
get soda
get beer
Figure 2.1: A transition system of a simple beverage vending machine.
The state space is S
= { pay, select, soda, beer }.
The set of initial states consists of
only one state, i.e., I = { pay }. The (user) action insert coin denotes the insertion of a
coin, while the (machine) actions get soda and get beer denote the delivery of soda and
beer, respectively. Transitions of which the action label is not of further interest here,
e.g., as it denotes some internal activity of the beverage machine, are all denoted by the
distinguished action symbol τ. We have:
Act = { insert coin, get soda, get beer, τ }.
Some example transitions are:
pay
insert coin
−−−−−−−−→select
and
beer
get beer
−−−−−−→pay.
1Recall that 2AP denotes the power set of AP.

22
Modelling Concurrent Systems
It is worthwhile to note that after the insertion of a coin, the vending machine nondeter-
ministically can choose to provide either beer or soda.
The atomic propositions in the transition system depend on the properties under con-
sideration.
A simple choice is to let the state names act as atomic propositions, i.e.,
L(s) = { s } for any state s. If, however, the only relevant properties do not refer to the
selected beverage, as in the property
“The vending machine only delivers a drink after providing a coin”,
it suﬃces to use the two-element set of propositions AP = { paid, drink } with labeling
function:
L(pay) = ∅,
L(soda) = L(beer) = { paid, drink },
L(select) = { paid }.
Here, the proposition paid characterizes exactly those states in which the user has already
paid but not yet obtained a beverage.
The previous example illustrates a certain arbitrariness concerning the choice of atomic
propositions and action names. Even if the formal deﬁnition of a transition system requires
determining the set of actions Act and the set of propositions AP, the components Act
and AP are casually dealt with in the following. Actions are only necessary for modeling
communication mechanisms as we will see later on.
In cases where action names are
irrelevant, e.g., because the transition stands for an internal process activity, we use a
special symbol τ or, in cases where action names are not relevant, even omit the action
label. The set of propositions AP is always chosen depending on the characteristics of
interest. In depicting transition systems, the set of propositions AP often is not explicitly
indicated and it is assumed that AP ⊆S with labeling function L(s) = { s } ∩AP.
Crucial for modeling hard- or software systems by transition systems is the nondetermin-
ism, which in this context is by far more than a theoretical concept. Later in this chapter
(Section 2.2), we will explain in detail how transition systems can serve as a formal model
for parallel systems. We mention here only that nondeterministic choices serve to model
the parallel execution of independent activities by interleaving and to model the conﬂict
situations that arise, e.g., if two processes aim to access a shared resource. Essentially,
interleaving means the nondeterministic choice of the order in which order the actions of
the processes that run in parallel are executed. Besides parallelism, the nondeterminism
is also important for abstraction purposes, for underspeciﬁcation, and to model the inter-
face with an unknown or unpredictable environment (e.g., a human user). An example of
the last is provided by the beverage vending machine where the user resolves the nonde-
terministic choice between the two τ-transitions in state ”select” by choosing one of the
two available drinks. The notion “underspeciﬁcation” refers to early design phases where

Transition Systems
23
a coarse model for a system is provided that represents several options for the possible
behaviors by nondeterminism. The rough idea is that in further reﬁnement steps the de-
signer realizes one of the nondeterministic alternatives, but skips the others. In this sense,
nondeterminism in a transition system can represent implementation freedom.
Deﬁnition 2.3.
Direct Predecessors and Successors
Let TS = (S, Act, →, I, AP, L) be a transition system. For s ∈S and α ∈Act, the set of
direct α-successors of s is deﬁned as:
Post(s, α)
=

s′ ∈S |
s
α
−−→s′ 
,
Post(s) =

α∈Act
Post(s, α).
The set of α-predecessors of s is deﬁned by:
Pre(s, α) =

s′ ∈S |
s′
α
−−→s

,
Pre(s) =

α∈Act
Pre(s, α).
Each state s′ ∈Post(s, α) is called a direct α-successor of s.
Accordingly, each state
s′ ∈Post(s) is called a direct successor of s. The notations for the sets of direct successors
are expanded to subsets of S in the obvious way (i.e., pointwise extension): for C ⊆S, let
Post(C, α) =

s∈C
Post(s, α),
Post(C) =

s∈C
Post(s).
The notations Pre(C, α) and Pre(C) are deﬁned in an analogous way:
Pre(C, α) =

s∈C
Pre(s, α),
Pre(C) =

s∈C
Pre(s).
Terminal states of a transition system TS are states without any outgoing transitions.
Once the system described by TS reaches a terminal state, the complete system comes to
a halt.
Deﬁnition 2.4.
Terminal State
State s in transition system TS is called terminal if and only if Post(s) = ∅.
For a transition system modeling a sequential computer program, terminal states occur
as a natural phenomenon representing the termination of the program. Later on, we will

24
Modelling Concurrent Systems
see that for transition systems modeling parallel systems, such terminal states are usually
considered to be undesired (see Section 3.1, page 89 ﬀ.).
We mentioned above that nondeterminism is crucial for modeling computer systems. How-
ever, it is often useful to consider transition systems where the ”observable” behavior is
deterministic, according to some notion of observables. There are two general approaches
to formalize the visible behavior of a transition system: one relies on the actions, the
other on the labels of the states.
While the action-based approach assumes that only
the executed actions are observable from outside, the state-based approach ignores the
actions and relies on the atomic propositions that hold in the current state to be visible.
Transition systems that are deterministic in the action-based view have at most one out-
going transition labeled with action α per state, while determinism from the view of state
labels means that for any state label A ∈2AP and any state there is at most one outgoing
transition leading to a state with label A. In both cases, it is required that there be at
most one initial state.
Deﬁnition 2.5.
Deterministic Transition System
Let TS = (S, Act, →, I, AP, L) be a transition system.
1. TS is called action-deterministic if | I | ⩽1 and | Post(s, α) | ⩽1 for all states s
and actions α.
2. TS is called AP-deterministic if | I | ⩽1 and |Post(s) ∩{ s′ ∈S | L(s′) = A }| ⩽1
for all states s and A ∈2AP.
2.1.1
Executions
So far, the behavior of a transition system has been described at an intuitive level. This
will now be formalized using the notion of executions (also called runs). An execution of a
transition system results from the resolution of the possible nondeterminism in the system.
An execution thus describes a possible behavior of the transition system. Formally:
Deﬁnition 2.6.
Execution Fragment
Let TS = (S, Act, →, I, AP, L) be a transition system. A ﬁnite execution fragment ϱ of
TS is an alternating sequence of states and actions ending with a state
ϱ = s0 α1 s1 α2 . . . αn sn such that si
αi+1
−−−−→si+1 for all 0 ⩽i < n,

Transition Systems
25
where n ⩾0. We refer to n as the length of the execution fragment ϱ. An inﬁnite execution
fragment ρ of TS is an inﬁnite, alternating sequence of states and actions:
ρ = s0 α1 s1 α2 s2 α3 . . . such that si
αi+1
−−−−→si+1 for all 0 ⩽i.
Note that the sequence s with s ∈S is a legal ﬁnite execution fragment of length n=0. Each
preﬁx of odd length of an inﬁnite execution fragment is a ﬁnite execution fragment. From
now on, the term execution fragment will be used to denote either a ﬁnite or an inﬁnite
execution fragment. Execution fragments ϱ = s0 α1 . . . αn sn and ρ = s0 α1 s1 α2 . . . will
be written respectively as
ϱ = s0
α1
−−→. . .
αn
−−→sn
and
ρ = s0
α1
−−→s1
α2
−−→. . . .
An execution fragment is called maximal when it cannot be prolonged:
Deﬁnition 2.7.
Maximal and Initial Execution Fragment
A maximal execution fragment is either a ﬁnite execution fragment that ends in a terminal
state, or an inﬁnite execution fragment. An execution fragment is called initial if it starts
in an initial state, i.e., if s0 ∈I.
Example 2.8.
Executions of the Beverage Vending Machine
Some examples of execution fragments of the beverage vending machine described in Ex-
ample 2.2 (page 21) are as follows. For simplicity, the action names are abbreviated, e.g.,
sget is a shorthand for get soda and coin for insert coin.
ρ1
=
pay
coin
−−−−→select
τ
−→soda
sget
−−−→pay
coin
−−−−→select
τ
−→soda
sget
−−−→. . .
ρ2
=
select
τ
−→soda
sget
−−−→pay
coin
−−−−→select
τ
−→beer
bget
−−−→. . .
ϱ
=
pay
coin
−−−−→select
τ
−→soda
sget
−−−→pay
coin
−−−−→select
τ
−→soda .
Execution fragments ρ1 and ϱ are initial, but ρ2 is not. ϱ is not maximal as it does not
end in a terminal state. Assuming that ρ1 and ρ2 are inﬁnite, they are maximal.
Deﬁnition 2.9.
Execution
An execution of transition system TS is an initial, maximal execution fragment.

26
Modelling Concurrent Systems
In Example 2.8, ρ1 is an execution, while ρ2 and ϱ are not. Note that ρ2 is maximal but
not initial, while ϱ is initial but not maximal.
A state s is called reachable if there is some execution fragment that ends in s and that
starts in some initial state.
Deﬁnition 2.10.
Reachable States
Let TS = (S, Act, →, I, AP, L) be a transition system. A state s ∈S is called reachable in
TS if there exists an initial, ﬁnite execution fragment
s0
α1
−−→s1
α2
−−→. . .
αn
−−→sn = s .
Reach(TS) denotes the set of all reachable states in TS.
2.1.2
Modeling Hardware and Software Systems
This section illustrates the use of transition systems by elaborating on the modeling of
(synchronous) hardware circuits and sequential data-dependent systems – a kind of simple
sequential computer programs. For both cases, the basic concept is that states represent
possible storage conﬁgurations (i.e., evaluations of relevant “variables”), and state changes
(i.e., transitions) represent changes of “variables”. Here, the term “variable” has to be
understood in the broadest sense. For computer programs a variable can be a control
variable (like a program counter) or a program variable. For circuits a variable can, e.g,
stand for either a register or an input bit.
Sequential Hardware Circuits
Before presenting a general recipe for modeling sequential hardware circuits as transition
systems we consider a simple example to clarify the basic concepts.
Example 2.11.
A Simple Sequential Hardware Circuit
Consider the circuit diagram of the sequential circuit with input variable x, output variable
y, and register r (see left part of Figure 2.2). The control function for output variable y
is given by
λy = ¬(x ⊕r)

Transition Systems
27
XOR
OR
y
NOT
x
r
x r y
x
0 r
0
x
0 r
1
x
1 r
0
x
1 r
1
r
x
y
Figure 2.2: Transition system representation of a simple hardware circuit.
where ⊕stands for exclusive or (XOR, or parity function). The register evaluation changes
according to the circuit function
δr = x ∨r .
Note that once the register evaluation is [r = 1], r keeps that value. Under the initial
register evaluation [r = 0], the circuit behavior is modeled by the transition system TS
with state space
S = Eval(x, r)
where Eval(x, r) stands for the set of evaluations of input variable x and register variable
r. The initial states of TS are I = { ⟨x = 0, r = 0⟩, ⟨x = 1, r = 0⟩}. Note that there are
two initial states as we do not make any assumption about the initial value of the input
bit x.
The set of actions is irrelevant and omitted here. The transitions result directly from the
functions λy and δr. For instance, ⟨x = 0, r = 1⟩−→⟨x = 0, r = 1⟩if the next input bit
equals 0, and ⟨x = 0, r = 1⟩−→⟨x = 1, r = 1⟩if the next input bit is 1.
It remains to consider the labeling L. Using the set of atomic propositions AP = { x, y, r },
then, e.g., the state ⟨x = 0, r = 1⟩is labeled with { r }. It is not labeled with y since the
circuit function ¬(x ⊕r) results in the value 0 for this state. For state ⟨x = 1, r = 1⟩we
obtain L(⟨x = 1, r = 1⟩) = { x, r, y }, as λy yields the value 1. Accordingly, we obtain:
L(⟨x = 0, r = 0⟩) = { y }, and L(⟨x = 1, r = 0⟩) = { x }. The resulting transition system
(with this labeling) is depicted in the right part of Figure 2.2.
Alternatively, using the set of propositions AP′ = { x, y } – the register evaluations are
assumed to be “invisible” – one obtains:
L′(⟨x = 0, r = 0⟩)
=
{ y }
L′(⟨x = 0, r = 1⟩)
=
∅
L′(⟨x = 1, r = 0⟩)
=
{ x }
L′(⟨x = 1, r = 1⟩)
=
{ x, y }
The propositions in AP′ suﬃce to formalize, e.g., the property “the output bit y is set
inﬁnitely often”. Properties that refer to the register r are not expressible.

28
Modelling Concurrent Systems
The approach taken in this example can be generalized toward arbitrary sequential hard-
ware circuits (without “don’t cares”) with n input bits x1, . . . , xn, m output bits y1, . . . , ym,
and k registers r1, . . . , rk as follows. The states of the transition system represent the eval-
uations of the n+k input and register bits x1, . . . , xn, r1, . . . , rk. The evaluation of output
bits depends on the evaluations of input bits and registers and can be derived from the
states. Transitions represent the behavior, whereas it is assumed that the values of in-
put bits are nondeterministically provided (by the circuit environment). Furthermore, we
assume a given initial register evaluation
[r1 = c0,1, . . . , rk = c0,k]
where c0,i denotes the initial value of register i for 0 < i ⩽k. Alternatively, a set of
possible initial register evaluations may be given.
The transition system TS = (S, Act, →, I, AP, L) modeling this sequential hardware circuit
has the following components. The state space S is determined by
S = Eval(x1, . . . , xn, r1, . . . , rk).
Here, Eval(x1, . . . , xn, r1, . . . , rk) stands for the set of evaluations of input variables xi and
registers rj and can be identiﬁed with the set { 0, 1 }n+k.2 Initial states are of the form
(. . . , c0,1, . . . , c0,k) where the k registers are evaluated with their initial value. The ﬁrst
n components prescribing the values of input bits are arbitrary. Thus, the set of initial
states is
I =

(a1, . . . , an, c0,1, . . . , c0,k) | a1, . . . , an ∈{ 0, 1 }

.
The set Act of actions is irrelevant, and we choose Act = { τ }. For simplicity, let the set
of atomic propositions be
AP = { x1, . . . , xn, y1, . . . , ym, r1, . . . , rk } .
(In practice, this could be deﬁned as any subset of this AP). Thus, any register, any
input bit, and any output bit can be used as an atomic proposition. The labeling function
assigns to any state s ∈Eval(x1, . . . , xn, r1, . . . , rk) exactly those atomic propositions xi,
rj which are evaluated to 1 under s. If for state s, output bit yi is evaluated to 1, then
(and only then) the atomic proposition yi is part of L(s). Thus,
L(a1, . . . , an, c1, . . . , ck)
=
{ xi | ai = 1 } ∪{ rj | cj = 1 }
∪{ yi | s |= λyi(a1, . . . , an, c1, . . . , ck) = 1 }
2An evaluation s ∈Eval(·) is a mapping which assigns a value s(xi) ∈{ 0, 1 } to any input bit xi.
Similarly, every register rj is mapped onto a value s(rj) ∈{ 0, 1 }. To simplify matters, we assume every
element s ∈S to be a bit-tuple of length n+k.
The ith bit is set if and only if xi is evaluated to 1
(0 < i ⩽n). Accordingly, the n+jth bit indicates the evaluation of rj (0 < j ⩽k).

Transition Systems
29
where λyi : S →{0, 1} is the switching function corresponding to output bit yi that results
from the gates of the circuit.
Transitions exactly represent the behavior. In the following, let δrj denote the transition
function for register rj resulting from the circuit diagram. Then:
( a1, . . . , an



input evaluation
,
c1, . . . , ck



register evaluation
)
τ
−→(a′
1, . . . , a′
n, c′
1, . . . , c′
k)
if and only if c′
j = δrj(a1, . . . , an, c1, . . . , ck). Assuming that the evaluation of input bits
changes nondeterministically, no restrictions on the bits a′
1, . . . , a′
n are imposed.
It is left to the reader to check that applying this recipe to the example circuit in the left
part of Figure 2.2 indeed results in the transition system depicted in the right part of that
ﬁgure.
Data-Dependent Systems
The executable actions of a data-dependent system typically result from conditional branch-
ing, as in
if x%2 = 1 then x := x + 1 else x := 2·x ﬁ.
In principle, when modeling this program fragment as a transition system, the conditions
of transitions could be omitted and conditional branchings could be replaced by nonde-
terminism; but, generally speaking, this results in a very abstract transition system for
which only a few relevant properties can be veriﬁed. Alternatively, conditional transitions
can be used and the resulting graph (labeled with conditions) can be unfolded into a tran-
sition system that subsequently can be subject to veriﬁcation. This unfolding approach is
detailed out below. We ﬁrst illustrate this by means of an example.
Example 2.12.
Beverage Vending Machine Revisited
Consider an extension of the beverage vending machine described earlier in Example 2.2
(page 21) which counts the number of soda and beer bottles and returns inserted coins if the
vending machine is empty. For the sake of simplicity, the vending machine is represented
by the two locations start and select. The following conditional transitions
start
true : coin

→select
and
start
true : reﬁll

→start
model the insertion of a coin and reﬁlling the vending machine. Labels of conditional
transitions are of the form g : α where g is a Boolean condition (called guard), and α is
an action that is possible once g holds. As the condition for both conditional transitions

30
Modelling Concurrent Systems
above always holds, the action coin is always enabled in the starting location. To keep
things simple, we assume that by reﬁll both storages are entirely reﬁlled. Conditional
transitions
select
nsoda > 0 : sget

→start
and
select
nbeer > 0 : bget

→start
model that soda (or beer) can be obtained if there is some soda (or beer) left in the vending
machine. The variables nsoda and nbeer record the number of soda and beer bottles in the
machine, respectively. Finally, the vending machine automatically switches to the initial
start location while returning the inserted coin once there are no bottles left:
select
nsoda = 0 ∧nbeer = 0: ret coin

→start
Let the maximum capacity of both bottle repositories be max. The insertion of a coin
(by action coin) leaves the number of bottles unchanged. The same applies when a coin
is returned (by action ret coin). The eﬀect of the other actions is as follows:
Action
Eﬀect
reﬁll
nsoda := max; nbeer := max
sget
nsoda := nsoda −1
bget
nbeer := nbeer −1
The graph consisting of locations as nodes and conditional transitions as edges is not
a transition system, since the edges are provided with conditions. A transition system,
however, can be obtained by “unfolding” this graph. For instance, Figure 2.3 on page 31
depicts this unfolded transition system when max equals 2. The states of the transition
system keep track of the current location in the graph described above and of the number
of soda- and beer bottles in the vending machine (as indicated by the gray and black dots,
respectively, inside the nodes of the graph).
The ideas outlined in the previous example are formalized by using so-called program
graphs over a set Var of typed variables such as nsoda and nbeer in the example.
Essen-
tially, this means that a standardized type (e.g., boolean, integer, or char) is associated
with each variable. The type of variable x is called the domain dom(x) of x. Let Eval(Var)
denote the set of (variable) evaluations that assign values to variables. Cond(Var) is the
set of Boolean conditions over Var, i.e., propositional logic formulae whose propositional
symbols are of the form “x ∈D” where x = (x1, . . . , xn) is a tuple consisting of pairwise
distinct variables in Var and D is a subset of dom(x1) × . . . × dom(xn).
The proposition
(−3 < x −x′ ⩽5) ∧(x ⩽2·x′) ∧(y = green),
for instance, is a legal Boolean condition for integer variables x and x′, and y a variable
with, e.g., dom(y) = { red, green }. Here and in the sequel, we often use simpliﬁed notations

Transition Systems
31
start
select
start
start
select
select
start
start
start
select
select
select
start
start
select
select
start
select
coin
coin
coin
bget
sget
coin
coin
coin
bget
sget
coin
coin
sget
bget
soda
beer
bget
sget
bget
sget
coin
ret coin
reﬁll
reﬁll
reﬁll
Figure 2.3: Transition system modeling the extended beverage vending machine.

32
Modelling Concurrent Systems
for the propositional symbols such as “3 < x −x′ ⩽5” instead of “(x, x′) ∈{ (n, m) ∈
IN2 | 3 < n −m ⩽5 }”.
Initially, we do not restrict the domains. dom(x) can be an arbitrary, possibly inﬁnite,
set. Even if in real computer systems all domains are ﬁnite (e.g., the type integer only
includes integers n of a ﬁnite domain, like −216 < n < 216), then the logical or algorithmic
structure of a program is often based on inﬁnite domains. The decision which restrictions
on domains are useful for implementation, e.g., how many bits should be provided for
representation of variables of type integer is delayed until a later design stage and is
ignored here.
A program graph over a set of typed variables is a digraph whose edges are labeled with
conditions on these variables and actions. The eﬀect of the actions is formalized by means
of a mapping
Eﬀect : Act × Eval(Var) →Eval(Var)
which indicates how the evaluation η of variables is changed by performing an action. If,
e.g., α denotes the action x := y+5, where x and y are integer variables, and η is the
evaluation with η(x) = 17 and η(y) = −2, then
Eﬀect(α, η)(x) = η(y) + 5 = −2 + 5 = 3,
and Eﬀect(α, η)(y) = η(y) = −2.
Eﬀect(α, η) is thus the evaluation that assigns 3 to x and −2 to y.
The nodes of a
program graph are called locations and have a control function since they specify which
of the conditional transitions are possible.
Deﬁnition 2.13.
Program Graph (PG)
A program graph PG over set Var of typed variables is a tuple (Loc, Act, Eﬀect, 
→, Loc0, g0)
where
• Loc is a set of locations and Act is a set of actions,
• Eﬀect : Act × Eval(Var) →Eval(Var) is the eﬀect function,
• 
→⊆Loc × Cond(Var) × Act × Loc is the conditional transition relation,
• Loc0 ⊆Loc is a set of initial locations,
• g0 ∈Cond(Var) is the initial condition.

Transition Systems
33
The notation ℓ
g:α

→ℓ′ is used as shorthand for (ℓ, g, α, ℓ′) ∈
→. The condition g is also
called the guard of the conditional transition ℓ
g:α

→ℓ′. If the guard is a tautology (e.g.,
g = true or g = (x < 1) ∨(x ⩾1)), then we simply write ℓ
α

→ℓ′.
The behavior in location ℓ∈Loc depends on the current variable evaluation η. A non-
deterministic choice is made between all transitions ℓ
g:α

→ℓ′ which satisfy condition g in
evaluation η (i.e., η |= g). The execution of action α changes the evaluation of variables
according to Eﬀect(α, ·). Subsequently, the system changes into location ℓ′. If no such
transition is possible, the system stops.
Example 2.14.
Beverage Vending Machine
The graph described in Example 2.12 (page 29) is a program graph. The set of variables
is
Var = { nsoda,
nbeer }
where both variables have the domain { 0, 1, . . . , max }. The set Loc of locations equals
{ start, select } with Loc0 = { start }, and
Act = { bget, sget, coin, ret coin, reﬁll } .
The eﬀect of the actions is deﬁned by:
Eﬀect(coin, η)
=
η
Eﬀect(ret coin, η)
=
η
Eﬀect(sget, η)
=
η[nsoda := nsoda−1]
Eﬀect(bget, η)
=
η[nbeer := nbeer−1]
Eﬀect(reﬁll, η)
=
[nsoda := max, nbeer := max]
Here, η[nsoda := nsoda−1] is a shorthand for evaluation η′ with η′(nsoda) = η(nsoda)−1
and η′(x) = η(x) for all variables diﬀerent from nsoda. The initial condition g0 states that
initially both storages are entirely ﬁlled, i.e., g0 = (nsoda = max ∧nbeer = max).
Each program graph can be interpreted as a transition system. The underlying transition
system of a program graph results from unfolding. Its states consist of a control component,
i.e., a location ℓof the program graph, together with an evaluation η of the variables.
States are thus pairs of the form ⟨ℓ, η⟩. Initial states are initial locations that satisfy the
initial condition g0. To formulate properties of the system described by a program graph,
the set AP of propositions is comprised of locations ℓ∈Loc (to be able to state at which
control location the system currently is), and Boolean conditions for the variables. For
example, a proposition like
(x ⩽5) ∧(y is even) ∧(ℓ∈{ 1, 2 })

34
Modelling Concurrent Systems
can be formulated with x, y being integer variables and with locations being naturals.
The labeling of states is such that ⟨ℓ, v⟩is labeled with ℓand with all conditions (over
Var) that hold in η. The transition relation is determined as follows. Whenever ℓ
g:α
−−−→ℓ′
is a conditional transition in the program graph, and the guard g holds in the current
evaluation η, then there is a transition from state ⟨ℓ, η⟩to state ⟨ℓ′, Eﬀect(α, η)⟩. Note
that the transition is not guarded. Formally:
Deﬁnition 2.15.
Transition System Semantics of a Program Graph
The transition system TS(PG) of program graph
PG = (Loc, Act, Eﬀect, 
→, Loc0, g0)
over set Var of variables is the tuple (S, Act, −→, I, AP, L) where
• S = Loc × Eval(Var)
• −→⊆S × Act × S is deﬁned by the following rule (see remark below):
ℓ
g:α

→ℓ′
∧
η |= g
⟨ℓ, η⟩
α
−−→⟨ℓ′, Eﬀect(α, η)⟩
• I = {⟨ℓ, η⟩| ℓ∈Loc0, η |= g0}
• AP = Loc ∪Cond(Var)
• L(⟨ℓ, η⟩) = {ℓ} ∪{g ∈Cond(Var) | η |= g}.
The deﬁnition of TS(PG) determines a very large set of propositions AP. But generally,
only a small part of AP is necessary to formulate the relevant system properties. In the
following, we exploit the degrees of freedom in choosing the set of propositions of TS(PG)
and only use the atomic propositions needed in the context at hand.
Remark 2.16.
Structured Operational Semantics
In Deﬁnition 2.15, the transition relation is deﬁned using the so-called SOS-notation
(Structured Operational Semantics).
This notation will be frequently used in the re-
mainder of this monograph. The notation
premise
conclusion

Parallelism and Communication
35
should be read as follows. If the proposition above the “solid line” (i.e., the premise) holds,
then the proposition under the fraction bar (i.e., the conclusion) holds as well. Such “if
. . ., then . . .” propositions are also called inference rules or simply rules. If the premise is
a tautology, it may be omitted (as well as the “solid line”). In the latter case, the rule is
also called an axiom.
Phrases like “The relation →is deﬁned by the following (axioms and) rules” have the
meaning of an inductive deﬁnition where the relation →is deﬁned as the smallest relation
satisfying the indicated axioms and rules.
2.2
Parallelism and Communication
In the previous section, we have introduced the notion of transition systems and have
shown how sequential hardware circuits and data-dependent systems (like simple sequen-
tial computer programs) can be eﬀectively modeled as transition systems.
In reality,
however, most hard- and software systems are not sequential but parallel in nature. This
section describes several mechanisms to provide operational models for parallel systems
by means of transition systems. These mechanisms range from simple mechanisms where
no communication between the participating transitions systems takes place, to more ad-
vanced (and realistic) schemes in which messages can be transferred, either synchronously
(i.e., by means of “handshaking”) or asynchronously (i.e., by buﬀers with a positive ca-
pacity). Let us assume that the operational (stepwise) behavior of the processes that run
in parallel are given by transition systems TS1, . . . , TSn. The goal is to deﬁne an operator
∥, such that:
TS = TS1 ∥TS2 ∥. . . ∥TSn
is a transition system that speciﬁes the behavior of the parallel composition of transition
systems TS1 through TSn. Here, it is assumed that ∥is a commutative and associative
operator. The nature of the operator ∥will, of course, depend on the kind of communica-
tion that is supported. We will for instance see that some notions of parallel composition
do not yield an associative operator. In the remainder of this section, several variants of
∥will be considered and illustrated by means of examples. Note that the above scheme
may be repeated for TSi, i.e., TSi may again be a transition system that is composed of
several transition systems:
TSi = TSi,1 ∥TSi,1 ∥. . . ∥TSi,ni .

36
Modelling Concurrent Systems
By using parallel composition in this hierarchical way, complex systems can be described
in a rather structured way.
2.2.1
Concurrency and Interleaving
A widely adopted paradigm for parallel systems is that of interleaving. In this model,
one abstracts from the fact that a system is actually composed of a set of (partly) inde-
pendent components. That is to say, the global system state – composed of the current
individual states of the components – plays a key role in interleaving.
Actions of an
independent component are merged (also called weaved), or “interleaved”, with actions
from other components. Thus, concurrency is represented by (pure) interleaving, that is,
the nondeterministic choice between activities of the simultaneously acting processes (or
components). This perspective is based on the view that only one processor is available
on which the actions of the processes are interlocked. The “one-processor view” is only a
modeling concept and also applies if the processes run on diﬀerent processors. Thereby,
(at ﬁrst) no assumptions are made about the order in which the diﬀerent processes are
executed. If there are, e.g., two nonterminating processes P and Q, say, acting completely
independent of each other, then
P
Q
P
Q
P
Q
Q
Q
P
. . .
P
P
Q
P
P
Q
P
P
Q
. . .
P
Q
P
P
Q
P
P
P
Q
. . .
are three possible sequences in which the steps (i.e., execution of actions) of P and Q can
be interlocked. (In Chapter 3, certain restrictions will be discussed to ensure that each
participating processor is treated in a somewhat “fair” manner. In particular, execution
sequences like P, P, P, . . ., where Q is completely ignored, are ruled out. Unless stated
otherwise, we accept all possible interleavings, including the unfair ones.)
The interleaving representation of concurrency is subject to the idea that there is a sched-
uler which interlocks the steps of concurrently executing processes according to an a priori
unknown strategy. This type of representation completely abstracts from the speed of
the participating processes and thus models any possible realization by a single-processor
machine or by several processors with arbitrary speeds.
Example 2.17.
Two Independent Traﬃc Lights
Consider the transition systems of two traﬃc lights for nonintersecting (i.e., parallel)
roads. It is assumed that the traﬃc lights switch completely independent of each other.
For example, the traﬃc lights may be controlled by pedestrians who would like to cross the
road. Each traﬃc light is modeled as a simple transition system with two states, one state

Parallelism and Communication
37
TrLight1
red
green
TrLight2
red
green
TrLight1 ||| TrLight2
red red
green red
green green
red green
Figure 2.4: Example of interleaving operator for transition systems.
modeling a red light, the other one modeling a green light (see upper part of Figure 2.4).
The transition system of the parallel composition of both traﬃc lights is sketched at the
bottom of Figure 2.4 where ||| denotes the interleaving operator. In principle, any form
of interlocking of the “actions” of the two traﬃc lights is possible. For instance, in the
initial state where both traﬃc lights are red, there is a non-deterministic choice between
which of the lights turns green. Note that this nondeterminism is descriptive, and does
not model a scheduling problem between the traﬃc lights (although it may seem so).
An important justiﬁcation for interleaving is the fact that the eﬀect of concurrently ex-
ecuted, independent actions α and β, say, is identical to the eﬀect when α and β are
successively executed in arbitrary order. This can symbolically be stated as
Eﬀect(α ||| β, η) = Eﬀect((α ; β) + (β ; α), η)
where the operator semicolon ; stands for sequential execution, + stands for nondetermin-
istic choice, and ||| for the concurrent execution of independent activities. This fact can
be easily understood when the eﬀect is considered from two independent value assignments

38
Modelling Concurrent Systems
x := x + 1



=α
||| y := y −2



=β
.
When initially x = 0 and y = 7, then x has the value 1 and y the value 5 after executing α
and β, independent of whether the assignments occur concurrently (i.e., simultaneously)
or in some arbitrary successive order. This is depicted in terms of transition systems as
follows:
x=0
x=1
α
|||
y=7
y=5
β
=
x=1, y=7
x=0, y=7
x=0, y=5
x=1, y=5
α
β
α
β
Note that the independence of actions is crucial.
For dependent actions, the order of
actions is typically essential: e.g., the ﬁnal value of variable x in the parallel program
x := x+1 ||| x := 2·x (with initial value x=0, say) depends on the order in which the
assignments x := x+1 and x := 2·x take place.
We are now in a position to formally deﬁne the interleaving (denoted ||| ) of transition
systems.
The transition system TS1 ||| TS2 represents a parallel system resulting from
the weaving (or merging) of the actions of the components as described by TS1 and
TS2.
It is assumed that no communication and no contentions (on shared variables)
occur at all. The (“global”) states of TS1 ||| TS2 are pairs ⟨s1, s2⟩consisting of “local”
states si of the components TSi.
The outgoing transitions of the global state ⟨s1, s2⟩
consist of the outgoing transitions of s1 together with those of s2. Accordingly, whenever
the composed system is in state ⟨s1, s2⟩, a nondeterministic choice is made between all
outgoing transitions of local state s1 and those of local state s2.
Deﬁnition 2.18.
Interleaving of Transition Systems
Let TSi
= (Si, Acti, →i, Ii, APi, Li) i=1, 2, be two transition systems. The transition
system TS1 ||| TS2 is deﬁned by:
TS1 ||| TS2 =
(S1 × S2, Act1 ∪Act2, →, I1 × I2, AP1 ∪AP2, L)
where the transition relation →is deﬁned by the following rules:
s1
α
−−→1 s′
1
⟨s1, s2⟩
α
−−→⟨s′
1, s2⟩
and
s2
α
−−→2 s′
2
⟨s1, s2⟩
α
−−→⟨s1, s′
2⟩
and the labeling function is deﬁned by L(⟨s1, s2⟩) = L(s1) ∪L(s2).

Parallelism and Communication
39
Example 2.19.
Consider the two independent traﬃc lights described in Example 2.17 (page 36). The
depicted transition system is actually the transition system
TS = TrLight1 ||| TrLight2
that originates from interleaving.
For program graphs PG1 (on Var1) and PG2 (on Var2) without shared variables (i.e.,
Var1 ∩Var2 = ∅), the interleaving operator, which is applied to the appropriate transition
systems, yields a transition system
TS(PG1) ||| TS(PG2)
that describes the behavior of the simultaneous execution of PG1 and PG2.
2.2.2
Communication via Shared Variables
The interleaving operator ||| can be used to model asynchronous concurrency in which the
subprocesses act completely independent of each other, i.e., without any form of message
passing or contentions on shared variables. The interleaving operator for transition systems
is, however, too simplistic for most parallel systems with concurrent or communicating
components. An example of a system whose components have variables in common—
shared variables so to speak—will make this clear.
Example 2.20.
The Interleaving Operator for Concurrent Processes
Regard the program graph for the instructions α and β of the parallel program
x := 2·x



action α
||| x := x + 1



action β
where we assume that initially x = 3. (To simplify the picture, the locations have been
skipped.) The transition system TS(PG1) ||| TS(PG2) contains, e.g., the inconsistent state
⟨x=6, x=4⟩and, thus, does not reﬂect the intuitive behavior of the parallel execution of
α and β:
x=3
x=6
α
|||
x=3
x=4
β
=
x=6, x=3
x=3, x=3
x=3, x=4
x=6, x=4
α
β
α
β

40
Modelling Concurrent Systems
The problem in this example is that the actions α and β access the shared variable x
and therefore are competing. The interleaving operator for transition systems, however,
“blindly” constructs the Cartesian product of the individual state spaces without consid-
ering these potential conﬂicts. Accordingly, it is not identiﬁed that the local states x=6
and x=4 describe exclusive events.
In order to deal with parallel programs with shared variables, an interleaving operator will
be deﬁned on the level of program graphs (instead of directly on transition systems). The
interleaving of program graphs PG1 and PG2 is denoted PG1 ||| PG2. The underlying
transition system of the resulting program graph PG1 ||| PG2, i.e., TS(PG1 ||| PG2) (see
Deﬁnition 2.15, page 34) faithfully describes a parallel system whose components communi-
cate via shared variables. Note that, in general, TS(PG1 ||| PG2) ̸= TS(PG1) ||| TS(PG2).
Deﬁnition 2.21.
Interleaving of Program Graphs
Let PGi = (Loci, Acti, Eﬀecti, 
→i, Loc0,i, g0,i), for i=1, 2 be two program graphs over the
variables Vari. Program graph PG1 ||| PG2 over Var1 ∪Var2 is deﬁned by
PG1 ||| PG2 = (Loc1 × Loc2, Act1 ⊎Act2, Eﬀect, 
→, Loc0,1 × Loc0,2, g0,1 ∧g0,2)
where 
→is deﬁned by the rules:
ℓ1
g:α

→1 ℓ′
1
⟨ℓ1, ℓ2⟩
g:α

→⟨ℓ′
1, ℓ2⟩
and
ℓ2
g:α

→2 ℓ′
2
⟨ℓ1, ℓ2⟩
g:α

→⟨ℓ1, ℓ′
2⟩
and Eﬀect(α, η) = Eﬀecti(α, η) if α ∈Acti.
The program graphs PG1 and PG2 have the variables Var1 ∩Var2 in common. These are
the shared (sometimes also called “global”) variables. The variables in Var1 \Var2 are the
local variables of PG1, and similarly, those in Var2 \ Var1 are the local variables of PG2.
Example 2.22.
Interleaving of Program Graphs
Consider the program graphs PG1 and PG2 that correspond to the assignments x := x+1
and x := 2·x, respectively. The program graph PG1 ||| PG2 is depicted in the bottom
left of Figure 2.5.
Its underlying transition system TS(PG1 ||| PG2) is depicted in the
bottom right of that ﬁgure where it is assumed that initially x equals 3. Note that the
nondeterminism in the initial state of the transition system does not represent concurrency
but just the possible resolution of the contention between the statements x := 2·x and
x := x+1 that both modify the shared variable x.
The distinction between local and shared variables has also an impact on the actions of the
composed program graph PG1 ||| PG2. Actions that access (i.e., inspect or modify) shared

Parallelism and Communication
41
ℓ′
1
ℓ1
ℓ1 ℓ2
ℓ1 ℓ2
ℓ1 ℓ′
2
ℓ′
1 ℓ′
2
ℓ′
1 ℓ2
ℓ′
1 ℓ2
ℓ′
1 ℓ′
2
ℓ1 ℓ′
2
ℓ′
1 ℓ′
2
x := 2 · x
x := x + 1
x := 2 · x
x := x + 1
x = 3
x = 7
x = 6
x = 4
x = 8
PG1 ||| PG2 :
TS(PG1 ||| PG2)
PG1 :
PG2 :
x := 2 · x
ℓ′
2
ℓ2
x := x + 1
Figure 2.5: Interleaving of two example program graphs.

42
Modelling Concurrent Systems
variables may be considered as “critical”; otherwise, they are viewed to be noncritical.
(For the sake of simplicity, we are a bit conservative here and consider the inspection of
shared variables as critical.) The diﬀerence between the critical and noncritical actions
becomes clear when interpreting the (possible) nondeterminism in the transition system
TS(PG1 ||| PG2). nondeterminism in a state of this transition system may stand either for
(i) an “internal” nondeterministic choice within program graph PG1 or PG2,
(ii) the interleaving of noncritical actions of PG1 and PG2, or
(iii) the resolution of a contention between critical actions of PG1 and PG2 (concurrency).
In particular, a noncritical action of PG1 can be executed in parallel with critical or
noncritical actions of PG2 as it will only aﬀect its local variables. By symmetry, the same
applies to the noncritical actions of PG2. Critical actions of PG1 and PG2, however, cannot
be executed simultaneously as the value of the shared variables depends on the order of
executing these actions (see Example 2.20). Instead, any global state where critical actions
of PG1 and PG2 are enabled describe a concurrency situation that has to be resolved by
an appropriate scheduling strategy. (Simultaneous reading of shared variables could be
allowed, however.)
Remark 2.23.
On Atomicity
For modeling a parallel system by means of the interleaving operator for program graphs
it is decisive that the actions α ∈Act are indivisible. The transition system representation
only expresses the eﬀect of the completely executed action α. If there is, e.g., an action α
with its eﬀect being described by the statement sequence
x := x + 1; y := 2x + 1; if x < 12 then z := (x −z)2 ∗y ﬁ,
then an implementation is assumed which does not interlock the basic substatements x :=
x+1, y := 2x+1, the comparison “x < 12”, and, possibly, the assignment z := (x−z)2 ∗y
with other concurrent processes. In this case,
Eﬀect(α, η)(x)
=
η(x) + 1
Eﬀect(α, η)(y)
=
2(η(x) + 1) + 1
Eﬀect(α, η)(z)
=
	 (η(x) + 1 −η(z))2 ∗2(η(x) + 1) + 1
if η(x) + 1 < 12
η(z)
otherwise
Hence, statement sequences of a process can be declared atomic by program graphs when
put as a single label to an edge. In program texts such multiple assignments are surrounded
by brackets ⟨. . .⟩.

Parallelism and Communication
43
wait1
crit1
noncrit1
y := y+1
y := y−1
y > 0 :
wait2
crit2
noncrit2
y := y + 1
y := y −1
y > 0 :
PG1 :
PG2 :
Figure 2.6: Individual program graphs for semaphore-based mutual exclusion.
Example 2.24.
Mutual Exclusion with Semaphores
Consider two simpliﬁed processes Pi, i=1, 2 of the form:
Pi
loop forever
...
(* noncritical actions *)
request
critical section
release
...
(* noncritical actions *)
end loop
Processes P1 and P2 are represented by the program graphs PG1 and PG2, respectively,
that share the binary semaphore y. y=0 indicates that the semaphore—the lock to get
access to the critical section—is currently possessed by one of the processes. When y=1,
the semaphore is free. The program graphs PG1 and PG2 are depicted in Figure 2.6.
For the sake of simplicity, local variables and shared variables diﬀerent from y are not
considered. Also, the activities inside and outside the critical sections are omitted. The
locations of PGi are noncriti (representing the noncritical actions), waiti (modeling the
situation in which Pi waits to enter its critical section), and criti (modeling the critical
section). The program graph PG1 ||| PG2 consists of nine locations, including the (unde-
sired) location ⟨crit1, crit2⟩that models the situation where both P1 and P2 are in their
critical section, see Figure 2.7.
When unfolding PG1 ||| PG2 into the transition system TSSem = TS(PG1 ||| PG2) (see
Figure 2.8 on page 45), it can be easily checked that from the 18 global states in TSSem

44
Modelling Concurrent Systems
⟨wait1, noncrit2⟩
⟨noncrit1, wait2⟩
⟨noncrit1, noncrit2⟩
⟨wait1, wait2⟩
⟨crit1, noncrit2⟩
⟨noncrit1, crit2⟩
⟨crit1, wait2⟩
⟨wait1, crit2⟩
⟨crit1, crit2⟩
y > 0 :
y := y−1
y := y+1
y := y+1
y := y+1
y := y+1
y := y−1
y := y−1
y > 0 :
y > 0 :
y := y+1
PG1 ||| PG2 :
Figure 2.7: PG1 ||| PG2 for semaphore-based mutual exclusion.
only the following eight states are reachable:
⟨noncrit1, noncrit2, y = 1⟩
⟨noncrit1, wait2, y = 1⟩
⟨wait1, noncrit2, y = 1⟩
⟨wait1, wait2, y = 1⟩
⟨noncrit1, crit2, y = 0⟩
⟨crit1, noncrit2, y = 0⟩
⟨wait1, crit2, y = 0⟩
⟨crit1, wait2, y = 0⟩
States ⟨noncrit1, noncrit2, y = 1⟩, and ⟨noncrit1, crit2, y = 0⟩stand for examples of sit-
uations where both P1 and P2 are able to concurrently execute actions.
Note that in
Figure 2.8 n stands for noncrit, w for wait, and c for crit. The nondeterminism in these
states thus stand for interleaving of noncritical actions. State ⟨crit1, wait2, y = 0⟩, e.g.,
represents a situation where only PG1 is active, whereas PG2 is waiting.
From the fact that the global state ⟨crit1, crit2, y = . . .⟩is unreachable in TSSem, it follows
that processes P1 and P2 cannot be simultaneously in their critical section. The parallel
system thus satisﬁes the so-called mutual exclusion property.
In the previous example, the nondeterministic choice in state ⟨wait1, wait2, y = 1⟩rep-
resents a contention between allowing either P1 or P2 to enter its critical section. The
resolution of this scheduling problem—which process is allowed to enter its critical section
next?—is left open, however. In fact, the parallel program of the previous example is
“abstract” and does not provide any details on how to resolve this contention. At later
design stages, for example, when implementing the semaphore y by means of a queue of
waiting processes (or the like), a decision has to be made on how to schedule the processes
that are enqueued for acquiring the semaphore. At that stage, a last-in ﬁrst-out (LIFO),

Parallelism and Communication
45
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 2.8: Mutual exclusion with semaphore (transition system representation).
ﬁrst-in ﬁrst-out (FIFO), or some other scheduling discipline can be chosen. Alternatively,
another (more concrete) mutual exclusion algorithm could be selected that resolves this
scheduling issue explicitly. A prominent example of such algorithm has been provided in
1981 by Peterson [332].
Example 2.25.
Peterson’s Mutual Exclusion Algorithm
Consider the processes P1 and P2 with the shared variables b1, b2, and x. b1 and b2 are
Boolean variables, while x can take either the value 1 or 2, i.e., dom(x) = { 1, 2 }. The
scheduling strategy is realized using x as follows.
If both processes want to enter the
critical section (i.e., they are in location waiti), the value of variable x decides which of
the two processes may enter its critical section: if x = i, then Pi may enter its critical
section (for i = 1, 2). On entering location wait1, process P1 performs x := 2, thus giving
privilege to process P2 to enter the critical section. The value of x thus indicates which
process has its turn to enter the critical section.
Symmetrically, P2 sets x to 1 when
starting to wait. The variables bi provide information about the current location of Pi.
More precisely,
bi = waiti ∨criti .
bi is set when Pi starts to wait. In pseudocode, P1 performs as follows (the code for process
P2 is similar):

46
Modelling Concurrent Systems
wait1
crit1
noncrit1
b1 := true; x := 2
b1 := false
x=1 ∨¬b2
wait1
crit1
noncrit1
b2 := true; x := 1
b2 := false
x=2 ∨¬b1
PG1 :
PG2 :
Figure 2.9: Program graphs for Peterson’s mutual exclusion algorithm.
P1
loop forever
...
(* noncritical actions *)
⟨b1 := true; x := 2⟩;
(* request *)
wait until (x = 1 ∨¬b2)
do critical section od
b1 := false
(* release *)
...
(* noncritical actions *)
end loop
Process Pi is represented by program graph PGi over Var = { x, b1, b2 } with locations
noncriti, waiti, and criti, see Figure 2.9 above. The reachable part of the underlying tran-
sition system TSPet = TS(PG1 ||| PG2) has the form as indicated in Figure 2.10 (page 47),
where for convenience ni, wi, ci are used for noncriti, waiti, and criti, respectively. The
last digit of the depicted states indicates the evaluation of variable x. For convenience, the
values for bi are not indicated. Its evaluation can directly be deduced from the location
of PGi. Further, b1 = b2 = false is assumed as the initial condition.
Each state in TSPet has the form ⟨loc1, loc2, x, b1, b2⟩. As PGi has three possible locations
and bi and x each can take two diﬀerent values, the total number of states of TSPet is 72.
Only ten of these states are reachable. Since there is no reachable state with P1 and P2
being in their critical section, it can be concluded that Peterson’s algorithm satisﬁes the
mutual exclusion property.
In the above program, the multiple assignments b1 := true; x := 2 and b2 := true; x := 1
are considered as indivisible (i.e., atomic) actions. This is indicated by the brackets ⟨

Parallelism and Communication
47
⟨n1, n2, x = 2⟩
⟨w1, n2, x = 2⟩
⟨w1, w2, x = 1⟩
⟨c1, w2, x = 1⟩
⟨n1, n2, x = 1⟩
⟨n1, w2, x = 1⟩
⟨w1, w2, x = 2⟩
⟨w1, c2, x = 2⟩
⟨c1, n2, x = 2⟩
⟨n1, c2, x = 1⟩
Figure 2.10: Transition system of Peterson’s mutual exclusion algorithm.
and ⟩in the program text, and is also indicated in the program graphs PG1 and PG2.
We like to emphasize that this is not essential, and has only been done to simplify the
transition system TSPet. Mutual exclusion is also ensured when both processes perform
the assignments bi := true and x := . . . in this order but in a nonatomic way. Note that, for
instance, the order “ﬁrst x := . . ., then bi := true” does not guarantee mutual exclusion.
This can be seen as follows. Assume that the location inbetween the assignments x := . . .
and bi := true in program graph Pi is called reqi. The state sequence
⟨noncrit1,
noncrit2,
x = 1,
b1 = false,
b2 = false⟩
⟨noncrit1,
req2,
x = 1,
b1 = false,
b2 = false⟩
⟨req1,
req2,
x = 2,
b1 = false,
b2 = false⟩
⟨wait1,
req2,
x = 2,
b1 = true,
b2 = false⟩
⟨crit1,
req2,
x = 2,
b1 = true,
b2 = false⟩
⟨crit1,
wait2,
x = 2,
b1 = true,
b2 = true⟩
⟨crit1,
crit2,
x = 2,
b1 = true,
b2 = true⟩
is an initial execution fragment where P1 enters its critical section ﬁrst (as b2 = false)
after which P2 enters its critical section (as x = 2).
As a result, both processes are
simultaneously in their critical section and mutual exclusion is violated.
2.2.3
Handshaking
So far, two mechanisms for parallel processes have been considered: interleaving and
shared-variable programs.
In interleaving, processes evolve completely autonomously

48
Modelling Concurrent Systems
• interleaving for α /∈H:
s1
α
−−→1 s′
1
⟨s1, s2⟩
α
−−→⟨s′
1, s2⟩
s2
α
−−→2 s′
2
⟨s1, s2⟩
α
−−→⟨s1, s′
2⟩
• handshaking for α ∈H:
s1
α
−−→1 s′
1
∧
s2
α
−−→2 s′
2
⟨s1, s2⟩
α
−−→⟨s′
1, s′
2⟩
Figure 2.11: Rules for handshaking.
whereas according to the latter type processes “communicate” via shared variables. In
this subsection, we consider a mechanism by which concurrent processes interact via hand-
shaking. The term “handshaking” means that concurrent processes that want to interact
have to do this in a synchronous fashion. That is to say, processes can interact only if
they are both participating in this interaction at the same time—they “shake hands”.
Information that is exchanged during handshaking can be of various nature, ranging from
the value of a simple integer, to complex data structures such as arrays or records. In
the sequel, we do not dwell upon the content of the exchanged messages. Instead, an
abstract view is adopted and only communication (also called synchronization) actions
are considered that represent the occurrence of a handshake and not the content.
To do so, a set H of handshake actions is distinguished with τ ̸∈H.
Only if both
participating processes are ready to execute the same handshake action, can message
passing take place. All actions outside H (i.e., actions in Act \ H) are independent and
therefore can be executed autonomously in an interleaved fashion.
Deﬁnition 2.26.
Handshaking (Synchronous Message Passing)
Let TSi = (Si, Acti, →i, Ii, APi, Li), i=1, 2 be transition systems and H ⊆Act1 ∩Act2
with τ ̸∈H. The transition system TS1 ∥H TS2 is deﬁned as follows:
TS1 ∥H TS2 =
(S1 × S2, Act1 ∪Act2, →, I1 × I2, AP1 ∪AP2, L)
where L(⟨s1, s2⟩) = L1(s1) ∪L2(s2), and where the transition relation →is deﬁned by
the rules shown in Figure 2.11.
Notation: TS1 ∥TS2 abbreviates TS1 ∥H TS2 for H = Act1 ∩Act2.

Parallelism and Communication
49
Remark 2.27.
Empty Set of Handshake Actions
When the set H of handshake actions is empty, all actions of the participating processes
can take place autonomously, i.e., in this special case, handshaking reduces to interleaving
TS1 ∥∅TS2
=
TS1 ||| TS2.
The operator ∥H deﬁnes the handshaking between two transition systems. Handshaking
is commutative, but not associative in general. That is, in general we have
TS1 ∥H (TS2 ∥H′ TS3) ̸= (TS1 ∥H TS2) ∥H′ TS3
for H ̸= H′.
However, for a ﬁxed set H of handshake actions over which all processes synchronize, the
operator ∥H is associative. Let
TS = TS1 ∥H TS2 ∥H . . . ∥H TSn,
denote the parallel composition of transition systems TS1 through TSn where H ⊆Act1 ∩
. . . ∩Actn is a subset of the set of actions Acti of all transition systems. This form of
multiway handshaking is appropriate to model broadcasting, a communication form in
which a process can transmit a datum to several other processes simultaneously.
In many cases, processes communicate in a pairwise fashion over their common actions.
Let TS1∥. . . ∥TSn denote the parallel composition of TS1 through TSn (with n > 0) where
TSi and TSj (0 < i ̸= j ⩽n) synchronize over the set of actions Hi,j = Acti ∩Actj such
that Hi,j ∩Actk = ∅for k /∈{ i, j }. It is assumed that τ ̸∈Hi,j. The formal deﬁnition
of TS1∥. . . ∥TSn is analogous to Deﬁnition 2.26. The state space of TS1∥. . . ∥TSn results
from the Cartesian product of the state spaces of TSi. The transition relation →is deﬁned
by the following rules:
• for α ∈Acti \ ( 
0<j⩽n
i̸=j
Hi,j) and 0 < i ⩽n:
si
α
−−→i s′
i
⟨s1, . . . , si, . . . , sn⟩
α
−−→⟨s1, . . . , s′
i, . . . sn⟩
• for α ∈Hi,j and 0 < i < j ⩽n:
si
α
−−→i s′
i
∧
sj
α
−−→j s′
j
⟨s1, . . . , si, . . . , sj, . . . , sn⟩
α
−−→⟨s1, . . . , s′
i, . . . , s′
j, . . . , sn⟩

50
Modelling Concurrent Systems
According to the ﬁrst rule, components can execute actions that are not subject to hand-
shaking in a completely autonomous manner as in interleaving. The second rule states that
processes TSi and TSj (i ̸= j) have to perform every handshaking action in Acti ∩Actj
together. These rules are in fact just generalizations of those given in Figure 2.11.
Example 2.28.
Mutual Exclusion by Means of an Arbiter
An alternative solution to the mutual exclusion problem between processes P1 and P2
(as before) is to model the binary semaphore that regulates access to the critical section
by a separate parallel process that interacts with P1 and P2 by means of handshaking.
For simplicity, we ignore the waiting phase and assume that Pi simply alternates inﬁnitely
often between noncritical and critical sections. Assume (much simpliﬁed) transition system
representations TS1 and TS2 with just two states: criti and noncriti. The new process,
named Arbiter, mimics a binary semaphore (see Figure 2.12). P1 and P2 communicate
with the Arbiter via handshaking over the set H = { request, rel }. Accordingly, the actions
request (requesting to access the critical section) and rel (to leave the critical section) have
to be executed synchronously with the Arbiter. The complete system
TSArb = (TS1 ||| TS2) ∥Arbiter
guarantees mutual exclusion since there are no states of TSArb where both P1 and P2 are
in their critical section (see bottom part of Figure 2.12). Note that in the initial state of
TS1 ||| TS2, the Arbiter determines which process will enter the critical section next.
Example 2.29.
Booking System
Consider a (strongly simpliﬁed) booking system at a cashier of a supermarket. The system
consists of three processes: the bar code reader BCR, the actual booking program BP,
and the printer Printer. The bar code reader reads a bar code and communicates the
data of the just scanned product to the booking program. On receiving such data, the
booking program transmits the price of the article to the printer that prints the article Id
together with the price on the receipt. The interactions between the bar code reader and
the booking program, and between the booking program and the printer is performed by
handshaking. Each process consist of just two states, named 0 and 1 (see Figure 2.13 for
the transitions systems of BCR, BP, and Printer).
The complete system is given by:
BCR ∥BP ∥Printer.
The transition system of the overall system is depicted in Figure 2.14 on page 52. The
initial global state of this system is ⟨0, 0, 0⟩, or in short, 000. In global state 010, e.g., the

Parallelism and Communication
51
T1
T2
Arbiter :
unlock
lock
noncrit1 noncrit2
crit1 noncrit2
noncrit1 crit2
T1
T2 :
Arbiter:
crit1 crit2
request
release
noncrit1 noncrit2 unlock
crit1 noncrit2 lock
noncrit1 crit2 lock
request
request
release
release
Figure 2.12: Mutual exclusion using handshaking with arbiter process.
nondeterminism stands for the concurrent execution of the actions scanning the bar code
and the synchronous transfer of the price to the printer.
Example 2.30.
Railroad Crossing
For a railroad crossing a control system needs to be developed that on receipt of a signal
indicating that a train is approaching closes the gates, and only opens these gates after the
train has sent a signal indicating that it crossed the road. The requirement that should be
met by the control system is that the gates are always closed when the train is crossing the
road. The complete system consists of the three components Train, Gate, and Controller:
Train ∥Gate ∥Controller.
Figure 2.15 depicts the transition systems of these components from left (modeling the
Train) to right (modeling the Gate). For simplicity, it is assumed that all trains pass
the relevant track section in the same direction—from left to right. The states of the
transition system for the Train have the following intuitive meaning: in state far the train
is not close to the crossing, in state near it is approaching the crossing and has just sent a
signal to notify this, and in state in it is at the crossing. The states of the Gate have the
obvious interpretation. The state changes of the Controller stand for handshaking with

52
Modelling Concurrent Systems
0
1
scan
store
0
1
store
prt cmd
0
1
prt cmd
print
Figure 2.13: The components of the book keeping example.
100
000
001
101
010
110
111
011
scan
print
print
scan
store
print
prt cmd
scan
print
store
scan
prt cmd
Figure 2.14: Transition system representation of the booking system.
the trains (via the actions approach and exit) and the Gate (via the actions lower and
raise via which the Controller causes the gate to close or to open, respectively).
Figure 2.16 (above) illustrates the transition system of the overall system. A closer in-
spection of this transition system reveals that the system suﬀers from a design ﬂaw. This
can be seen from the following initial execution fragment:
⟨far, 0, up⟩
approach
−−−−−−→⟨near, 1, up⟩
enter
−−−−→⟨in, 1, up⟩
in which the gate is about to close, while the train is (already) at the crossing.
The
nondeterminism in global state ⟨near, 1, up⟩stands for concurrency: the train approaches
the crossing, while the gate is being closed.
In fact, the basic concept of the design
is correct if and only if closing the gate does not take more time than the train needs
to get to the crossing once it signals—“I am approaching”. Such real-time constraints
cannot be formulated by the concepts introduced so far. The interleaving representation
for parallel systems is completely time-abstract. In Chapter 9, concepts and techniques
will be introduced to specify and verify such real-time aspects.

Parallelism and Communication
53
far
near
in
approach
enter
exit
0
1
3
2
approach
lower
exit
raise
up
down
lower
raise
Train
Controller
Gate
Figure 2.15: The components of the railroad crossing.
2.2.4
Channel Systems
This section introduces channel systems, parallel systems where processes communicate
via so-called channels, i.e., ﬁrst-in, ﬁrst-out buﬀers that may contain messages. We con-
sider channel systems that are closed. That is to say, processes may communicate with
other processes in the system (via channels), but not with processes outside the system.
Channel systems are popular for describing communication protocols and form the basis
of Promela, the input language of the Spin model checker.
Intuitively, a channel system consists of n (data-dependent) processes P1 through Pn.
Each Pi is speciﬁed by a program graph PGi which is extended with communication
actions. Transitions of these program graphs are either the usual conditional transitions
(labeled with guards and actions) as before, or one of the communication actions with
their respective intuitive meaning:
c!v
transmit the value v along channel c,
c?x
receive a message via channel c and assign it to variable x.
When considering channel c as buﬀer, the communication action c!v puts value v (at the
rear of) the buﬀer whereas c?x retrieves an element from (the front of) the buﬀer while
assigning it to x. It is assumed implicitly that variable x is of the right type, i.e., it has a
type that is compatible to that of the messages that are put into channel c. Let
Comm =

c!v, c?x | c ∈Chan, v ∈dom(c), x ∈Var with dom(x) ⊇dom(c)

denote the set of communication actions where Chan is a ﬁnite set of channels with typical
element c.

54
Modelling Concurrent Systems
⟨far, 0, up⟩
⟨near, 0, up⟩
⟨far, 1, up⟩
⟨near, 1, up⟩
⟨in, 1, up⟩
⟨far, 2, down⟩
⟨near, 2, down⟩
⟨in, 2, down⟩
⟨far, 3, down⟩
⟨near, 3, down⟩
⟨in, 3, down⟩
approach
approach
approach
enter
enter
enter
exit
exit
exit
lower
lower
lower
raise
approach
⟨in, 0, up⟩
enter
exit
raise
exit
Figure 2.16: Transition system for the railroad crossing.

Parallelism and Communication
55
A channel c has a (ﬁnite or inﬁnite) capacity indicating the maximum number of messages
it can store, and a type (or domain) specifying the type of messages that can be transmitted
over c. Each channel c has a capacity cap(c) ∈IN ∪{ ∞}, and a domain dom(c). For a
channel c that can only transfer bits, dom(c) = { 0, 1 }. If complete texts (of maximum
length of 200, say) need to be transmitted over channel c, then another type of channel
has to be used such that dom(c) = Σ⩽200, where Σ is the alphabet that forms the basis of
the texts, e.g., Σ is the set of all letters and special characters used in German texts.
The capacity of a channel deﬁnes the size of the corresponding buﬀer, i.e., the number of
messages not yet read that can be stored in the buﬀer. When cap(c) ∈IN, c is a channel
with ﬁnite capacity; cap(c) = ∞indicates that c has an inﬁnite capacity. Note that the
special case cap(c) = 0 is permitted. In this case, channel c has no buﬀer. Communication
via such a channel c corresponds to handshaking (simultaneous transmission and receipt,
i.e., synchronous message passing) plus the exchange of some data. When cap(c) > 0,
there is a “delay” between the transmission and the receipt of a message, i.e., sending and
reading of the same message take place at diﬀerent moments. This is called asynchronous
message passing. Sending and reading a message from a channel with a nonzero capacity
can never appear simultaneously. By means of channel systems, both synchronous and
asynchronous message passing can thus be modeled.
Deﬁnition 2.31.
Channel System
A program graph over (Var, Chan) is a tuple
PG = (Loc, Act, Eﬀect, 
→, Loc0, g0)
according to Deﬁnition 2.13 (page 32) with the only diﬀerence that

→
⊆
Loc × (Cond(Var) × (Act ∪Comm) × Loc.
A channel system CS over (Var, Chan) consists of program graphs PGi over (Vari, Chan)
(for 1 ⩽i ⩽n) with Var = 
1⩽i⩽n Vari. We denote
CS = [PG1 | . . . | PGn] .
The transition relation 
→of a program graph over (Var, Chan) consists of two types
of conditional transitions.
As before, conditional transitions ℓ
g:α

→ℓ′ are labeled with
guards and actions. These conditional transitions can happen whenever the guard holds.
Alternatively, conditional transitions may be labeled with communication actions. This
yields conditional transitions of type ℓ
g:c!v

→ℓ′ (for sending v along c) and ℓ
g:c?x

→ℓ′ (for
receiving a message along c).
When can such conditional transitions happen? Stated

56
Modelling Concurrent Systems
diﬀerently, when are these conditional transitions executable? This depends on the current
variable evaluation and the capacity and content of the channel c. For the sake of simplicity
assume in the following that the guard is satisﬁed.
• Handshaking. If cap(c) = 0, then process Pi can transmit a value v over channel c
by performing
ℓi
c!v

→ℓ′
i
only if another process Pj, say, “oﬀers” a complementary receive action, i.e., can
perform
ℓj
c?x

→ℓ′
j.
Pi and Pj should thus be able to perform c!v (in Pi) and c?x (in Pj) simultaneously.
Then, message passing can take place between Pi and Pj. The eﬀect of message
passing corresponds to the (distributed) assignment x := v.
Note that when handshaking is only used for synchronization purposes and not for
data transfer, the name of the channel as well as the value v are not of any relevance.
• Asynchronous message passing.
If cap(c) > 0, then process Pi can perform the
conditional transition
ℓi
c!v

→ℓ′
i
if and only if channel c is not full, i.e., if less than cap(c) messages are stored in c.
In this case, v is stored at the rear of the buﬀer c. Channels are thus considered as
ﬁrst-in, ﬁrst-out buﬀers. Accordingly, Pj may perform
ℓj
c?x

→ℓ′
j
if and only if the buﬀer of c is not empty. In this case, the ﬁrst element v of the
buﬀer is extracted and assigned to x (in an atomic manner). This is summarized in
Table 2.1.
executable if . . .
eﬀect
c!v
c is not “full”
Enqueue(c, v)
c?x
c is not empty
⟨x := Front(c) ; Dequeue(c)⟩;
Table 2.1: Enabledness and eﬀect of communication actions if cap(c) > 0.

Parallelism and Communication
57
receiver
timer
sender
channel d
unreliable channel c
synchronous
Figure 2.17: Schematic view of the alternating bit protocol.
Channel systems are often used to model communication protocols.
One of the most
elementary and well-known protocols is the alternating bit protocol.
Example 2.32.
Alternating Bit Protocol (ABP)
Consider a system essentially consisting of a sender S and a receiver R that communicate
with each other over channels c and d, see Figure 2.17. It is asssumed that both channels
have an unlimited buﬀer, i.e., cap(c) = cap(d) = ∞.
Channel c is unreliable in the
sense that data may get lost when being transmitted from the sender S to channel c.
Once messages are stored in the buﬀer of channel c, they are neither corrupted nor lost.
Channel d is assumed to be perfect. The goal is to design a communication protocol that
ensures any distinct transmitted datum by S to be delivered to R. To ensure this in the
presence of possible message losses, sender S resorts to retransmissions. Messages are
transmitted one by one, i.e., S starts sending a new message once the transmission of the
previous message has been successful. This is a simple ﬂow control principle, known as
“send-and-wait”.
We abstract from the real activities of S and R and, instead, concentrate on a simpliﬁed
representation of the communication structure of the system.
S sends the successive
messages m0, m1, . . . together with control bits b0, b1, . . . over channel c to R. Transmitted
messages are thus pairs:
⟨m0, 0⟩, ⟨m1, 1⟩, ⟨m2, 0⟩, ⟨m3, 1⟩, . . .
On receipt of ⟨m, b⟩(along channel c), R sends an acknowledgment (ack) consisting of
the control bit b just received.
On receipt of ack ⟨b⟩, S transmits a new message m′
with control bit ¬b. If, however, S has to wait “too long” for the ack, it timeouts and
retransmits ⟨m, b⟩. The program graphs for S and R are sketched in Figure 2.18 and 2.19.
For simplicity, the data that is transmitted is indicated by m instead of mi.

58
Modelling Concurrent Systems
snd msg(0)
st tmr(0)
wait(0)
chk ack(0)
snd msg(1)
st tmr(1)
wait(1)
chk ack(1)
c!⟨m, 0⟩
lost
tmr on!
d?x
timeout?
x = 1
x = 0 :
tmr oﬀ!
c!⟨m, 1⟩
lost
tmr on!
timeout?
d?x
x = 0
x = 1 :
tmr oﬀ!
Figure 2.18: Program graph of ABP sender S.
wait(0)
pr msg(0)
snd ack(0)
wait(1)
pr msg(1)
snd ack(1)
c?⟨m, y⟩
y = 1
y = 0
d!0
c?⟨m, y⟩
y = 0
y = 1
d!1
oﬀ
on
tmr on?
timeout!
tmr oﬀ?
Figure 2.19: Program graph of (left) ABP receiver R and (right) Timer.
Control bit b—also called the alternating bit—is thus used to distinguish retransmissions
of m from transmissions of subsequent (and previous) messages. Due to the fact that
the transmission of a new datum is initiated only when the last datum has been received
correctly (and this is acked), a single bit is suﬃcient for this purpose and notions like, e.g.,
sequence numbers, are not needed.
The timeout mechanism of S is modeled by a Timer process. S activates this timer on
sending a message (along c), and it stops the timer on receipt of an ack. When raising
a timeout, the timer signals to S that a retransmission should be initiated. (Note that
due to this way of modeling, so-called premature timeouts may occur, i.e., a timeout may
occur whereas an ack is still on its way to S.) The communication between the timer and
S is modeled by means of handshaking, i.e., by means of channels with capacity 0.

Parallelism and Communication
59
The complete system can now be represented as the following channel system over Chan =
{ c, d, tmr on, tmr oﬀ, timeout } and Var = { x, y, mi }:
ABP = [S | Timer | R ] .
The following deﬁnition formalizes the successive behavior of a channel system by means
of a transition system.
The basic concept is similar to the mapping from a program
graph onto a transition system. Let CS = [PG1 | . . . | PGn] be a channel system over
(Chan, Var). The (global) states of TS(CS) are tuples of the form
⟨ℓ1, . . . , ℓn, η, ξ⟩
where ℓi indicates the current location of component PGi, η keeps track of the current
values of the variables, and ξ records the current content of the various channels (as se-
quences). Formally, η ∈Eval(Var) is an evaluation of the variables (as we have encountered
before), and ξ is a channel evaluation, i.e., a mapping from channel c ∈Chan onto a se-
quence ξ(c) ∈dom(c)∗such that the length of the sequence cannot exceed the capacity of c,
i.e., len(ξ(c)) ⩽cap(c) where len(·) denotes the length of a sequence. Eval(Chan) denotes
the set of all channel evaluations. For initial states, the control components ℓi ∈Loc0,i
must be initial and variable evaluation η must satisfy the initial condition g0. In addition,
every channel is initially assumed to be empty, denoted ε.
Before providing the details of the semantics of a transition system, let us introduce some
notations. Channel evaluation ξ(c) = v1 v2 . . . vk (where cap(c) ⩾k) denotes that v1 is at
the front of the buﬀer of c, v2 is the second element, etc., and vk is the element at the rear
of c. len(ξ(c)) = k in this case. Let ξ[c := v1, . . . , vk] denote the channel evaluation where
sequence v1, . . . , vk is assigned to c and all other channels are unaﬀected, i.e.,
ξ[c := v1 . . . vk](c′) =
	 ξ(c′)
if c ̸= c′
v1 . . . vk
if c = c′.
The channel evaluation ξ0 maps any channel to the empty sequence, denoted ε, i.e., ξ0(c) =
ε for any channel c. Let len(ε) = 0. The set of actions of TS(CS) consists of actions
α ∈Acti of component PGi and the distinguished symbol τ representing all communication
actions in which data is exchanged.
Deﬁnition 2.33.
Transition System Semantics of a Channel System
Let CS = [PG1 | . . . | PGn] be a channel system over (Chan, Var) with
PGi = (Loci, Acti, Eﬀecti, 
→i, Loc0,i, g0,i) ,
for 0 < i ⩽n.
The transition system of CS, denoted TS(CS), is the tuple (S, Act, →, I, AP, L) where:

60
Modelling Concurrent Systems
• S = (Loc1 × . . . × Locn) × Eval(Var) × Eval(Chan),
• Act = 
0<i⩽n Acti ⊎{ τ },
• →is deﬁned by the rules of Figure 2.20 (page 61),
• I =

⟨ℓ1, . . . , ℓn, η, ξ0⟩| ∀0 < i ⩽n. (ℓi ∈Loc0,i ∧η |= g0,i)

,
• AP = 
0<i⩽n Loci ⊎Cond(Var),
• L(⟨ℓ1, . . . , ℓn, η, ξ⟩) = { ℓ1, . . . , ℓn } ∪{ g ∈Cond(Var) | η |= g }.
This deﬁnition is a formalization of the informal description of the interpretation of a
channel system given before. Note that the labeling of the atomic propositions is similar
to that for program graphs (see Deﬁnition 2.15). For the sake of simplicity, the above
deﬁnition does not allow for propositions on channels. This could be accommodated by
allowing for conditions on channels such as, e.g., “the channel c is empty” or “the channel
c is full”, and checking these conditions on the channel evaluation ξ in a state.
Example 2.34.
Alternating Bit Protocol (Revisited)
Consider the alternating bit protocol that was modeled as a channel system in Exam-
ple 2.32.
The underlying transition system TS(ABP) has, despite various simplifying
assumptions, inﬁnitely many states. This is, e.g., due to the fact that the timer may sig-
nal a timeout on each transmission of a datum by S resulting in inﬁnitely many messages
in channel c.
To clarify the functionality of the alternating bit protocol, consider two execution frag-
ments represented by indicating the states of the various components (sender S, receiver
R, the timer, and the contents of channels c and d). The ﬁrst execution fragment shows
the loss of a message. Here, R does not execute any action at all as it only acts if channel
c contains at least one message:
sender S
timer
receiver R
channel c
channel d
event
snd msg(0)
oﬀ
wait(0)
∅
∅
st tmr(0)
oﬀ
wait(0)
∅
∅
loss of message
wait(0)
on
wait(0)
∅
∅
snd msg(0)
oﬀ
wait(0)
∅
∅
timeout
...
...
...
...
...

Parallelism and Communication
61
• interleaving for α ∈Acti:
ℓi
g:α

→ℓ′
i
∧
η |= g
⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩
α
−−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓn, η′, ξ⟩
where η′ = Eﬀect(α, η).
• asynchronous message passing for c ∈Chan, cap(c) > 0:
– receive a value along channel c and assign it to variable x:
ℓi
g:c?x

→ℓ′
i ∧η |= g ∧len(ξ(c)) = k > 0 ∧ξ(c) = v1 . . . vk
⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩
τ
−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓn, η′, ξ′⟩
where η′ = η[x := v1] and ξ′ = ξ[c := v2 . . . vk].
– transmit value v ∈dom(c) over channel c:
ℓi
g:c!v

→ℓ′
i ∧η |= g ∧len(ξ(c)) = k < cap(c) ∧ξ(c) = v1 . . . vk
⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩
τ
−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓn, η, ξ′⟩
where ξ′ = ξ[c := v1 v2 . . . vk v].
• synchronous message passing over c ∈Chan, cap(c) = 0:
ℓi
g1:c?x

→ℓ′
i ∧η |= g1 ∧η |= g2 ∧ℓj
g2:c!v

→ℓ′
j ∧i ̸= j
⟨ℓ1, . . . , ℓi, . . . , ℓj, . . . , ℓn, η, ξ⟩
τ
−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓ′
j, . . . , ℓn, η′, ξ⟩
where η′ = η[x := v].
Figure 2.20: Rules for the transition relation of a channel system.

62
Modelling Concurrent Systems
When the receiver R is in location wait(0) and receives a message, it anticipates receiving
a message with either control bit 0 (as it expects) or with control bit 1, see left side of
Figure 2.19. Symmetrically, in location wait(1) also the possibility is taken into account
to receive the (unexpected) ack with control bit 0.
The following execution fragment
indicates why this unexpected possibility is essential to take into consideration.
In a
nutshell, the execution fragment shows that it may happen that R receives ⟨m, 0⟩, notiﬁes
this by means of sending an ack (with control bit 0), and switches to “mode 1”—waiting
to receive a message with control bit 1. In the meanwhile, however, sender S has initiated
a retransmission of ⟨m, 0⟩(as it timed out). On receipt of this (unexpected) message,
receiver R should act accordingly and ignore the message. This is exactly what happens.
Note that if this possibility would not have been taken into consideration in the program
graph of R, the system would have come to a halt.
sender S
timer
receiver R
channel c
channel d
event
snd msg(0)
oﬀ
wait(0)
∅
∅
st tmr(0)
oﬀ
wait(0)
⟨m, 0⟩
∅
message with bit 0
transmitted
wait(0)
on
wait(0)
⟨m, 0⟩
∅
snd msg(0)
oﬀ
wait(0)
⟨m, 0⟩
∅
timeout
st tmr(0)
oﬀ
wait(0)
⟨m, 0⟩⟨m, 0⟩
∅
retransmission
st tmr(0)
oﬀ
pr msg(0)
⟨m, 0⟩
∅
receiver reads
ﬁrst message
st tmr(0)
oﬀ
snd ack(0)
⟨m, 0⟩
∅
st tmr(0)
oﬀ
wait(1)
⟨m, 0⟩
0
receiver changes
into mode-1
st tmr(0)
oﬀ
pr msg(1)
∅
0
receiver reads
retransmission
st tmr(0)
oﬀ
wait(1)
∅
0
and ignores it
...
...
...
...
...
We conclude this example by pointing out a possible simpliﬁcation of the program graph of
the sender S. Since the transmission of acks (over channel d) is reliable, it is unnecessary
(but not wrong) for S to verify the control bit of the ack in location chk ack(·). If S is in
location wait(0) and channel d is not empty, then the (ﬁrst) message in d corresponds to
the expected ack 0, since R acknowledges each message m exactly once regardless of how
many times m is received. Therefore, the program graph of S could be simpliﬁed such
that by the action sequence d?x ; timer oﬀ, it moves from location wait(0) to location
gen msg(1). Location chk ack(0) may thus be omitted. By similar arguments, location
chk ack(1) may be omitted. If, however, channel d would be unreliable (like channel c),
these locations are necessary.

Parallelism and Communication
63
Remark 2.35.
Open Channel Systems
The rule for synchronous message passing is subject to the idea that there is a closed
channel system that does not communicate with the environment. To model open channel
systems, only the rule for handshaking has to be modiﬁed. If there is a channel c with
cap(c) = 0 over which the channel system is communicating with the environment, the
rules
ℓi
c!v

→ℓ′
i
⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩
c!v
−−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓn, η, ξ⟩
and
ℓi
c?x

→ℓ′
i
∧
v ∈dom(c)
⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩
c?x
−−−→⟨ℓ1, . . . , ℓ′
i, . . . , ℓn, η[x := v], ξ⟩
have to be used. The receipt of value v for variable x along channel c is modeled by means
of nondeterminism that is resolved by the environment. That is to say, the environment
selects value v ∈dom(c) in a purely nondeterministic way.
2.2.5
NanoPromela
The concepts that have been discussed in the previous sections (program graphs, parallel
composition, channel systems) provide the mathematical basis for modeling reactive sys-
tems. However, for building automated tools for verifying reactive systems, one aims at
simpler formalisms to specify the behavior of the system to be analyzed. On the one hand,
such speciﬁcation languages should be simple and easy to understand, such that nonex-
perts also are able to use them. On the other hand, they should be expressive enough to
formalize the stepwise behavior of the processes and their interactions. Furthermore, they
have to be equipped with a formal semantics which renders the intuitive meaning of the
language commands in an unambiguous manner. In our case, the purpose of the formal
semantics is to assign to each program of the speciﬁcation language a transition system
that can serve as a basis for the automated analysis, e.g., simulation or model checking
against temporal logical speciﬁcations.
In this section, we present the core features of the language Promela, the input language
for the prominent model checker SPIN by Holzmann [209]. Promela is short for “process
metalanguage”. Promela programs P consist of a ﬁnite number of processes P1, . . . , Pn
to be executed concurrently. Promela supports communication over shared variables and
message passing along either synchronous or buﬀered FIFO-channels. The formal seman-
tics of a Promela-program can be provided by means of a channel system, which then
can be unfolded into a transition system, as explained in Section 2.2.4.
The stepwise
behavior of the processes Pi is speciﬁed in Promela using a guarded command language

64
Modelling Concurrent Systems
[130, 18] with several features of classical imperative programming languages (variable as-
signments, conditional and repetitive commands, sequential composition), communication
actions where processes may send and receive messages from the channels, and atomic
regions that avoid undesired interleavings. Guarded commands have already been used as
labels for the edges of program graphs and channel systems. They consist of a condition
(guard) and an action. Promela does not use action names, but speciﬁes the eﬀect of
actions by statements of the guarded command language.
Syntax of nanoPromela
We now explain the syntax and semantics of a fragment of
Promela, called nanoPromela, which concentrates on the basic elements of Promela, but
abstracts from details like variable declarations and skips several “advanced” concepts
like abstract data types (arrays, lists, etc.) or dynamic process creation. A nanoPromela
program consists of statements representing the stepwise behavior of the processes P1, . . . ,
Pn together with a Boolean condition on the initial values of the program variables. We
write nanoPromela programs as:
P = [P1| . . . |Pn].
The main ingredients of the statements that formalize the stepwise behavior of the pro-
cesses Pi are the atomic commands skip, variable assignments x := expr, communica-
tion actions c?x (reading a value for variable x from channel c) and c!expr (sending the
current value of an expression over channel c), conditional commands (if-then-else) and
(while)loops. Instead of the standard if-then-else constructs or whileloops, nanoPromela
supports nondeterministic choices and allows specifying a ﬁnite number of guarded com-
mands in conditional and repetitive commands.
Variables, Expressions and Boolean Expressions
The variables in a nanoPromela
program P may be typed (integer, Boolean, char, real, etc.) and either global or local to
some process of Pi. Similarly, data domains have to be speciﬁed for the channels and they
have to be declared to be synchronous or ﬁfo-channels of a predeﬁned capacity. We skip
the details of variable and channel declarations, as they are irrelevant for the purposes
of this chapter. As local variables can be renamed in case they occur in more than one
process or as the name of a global variable, we may treat all variables as global variables.
Thus, we assume that Var is a set of variables occurring in P and that for any a variable
name x the domain (type) of x is given as the set dom(x). Furthermore, in the declaration
part of a Promela program, the type of a channel is speciﬁed. We simply write here dom(c)
for the type (domain) of channel c and cap(c) for its capacity. In addition, we assume
that the variable declaration of program P contains a Boolean expression that speciﬁes
the legal initial values for the variables x ∈Var.

Parallelism and Communication
65
stmt
::=
skip | x := expr | c?x | c!expr |
stmt1 ; stmt2 | atomic{assignments} |
if
:: g1 ⇒stmt1
. . .
:: gn ⇒stmtn
ﬁ
|
do
:: g1 ⇒stmt1
. . .
:: gn ⇒stmtn
do
Figure 2.21: Syntax of nanoPromela-statements.
The intuitive meaning of an assignment x := expr is obvious: variable x is assigned the
value of the expression expr given the current variable evaluation.
The precise syntax
of the expressions and Boolean expressions is not of importance here. We may assume
that the expressions used in assignments for variable x are built by constants in dom(x),
variables y of the same type as x (or a subtype of x), and operators on dom(x), such as
Boolean connectives ∧, ∨, ¬, etc. for dom(x) = { 0, 1 } and arithmetic operators +, ∗,
etc. for dom(x) = R.3 The guards are Boolean expressions that impose conditions on the
values of the variables, i.e., we treat the guards as elements of Cond(Var).
Statements
The syntax of the statements that specify the behavior of the nanoPromela-
processes is shown in Figure 2.21 on page 65.
Here, x is a variable in Var, expr an
expression, and c is a channel of arbitrary capacity. Type consistency of the variable x
and the expression expr is required in assignments x := expr. Similarly, for the message-
passing actions c?x and c!expr we require that dom(c) ⊆dom(x) and that the type of expr
corresponds to the domain of c. The gi’s in if–ﬁ- and do–od-statements are guards. As
mentioned above, we assume that gi ∈Cond(Var). The body assignments of an atomic
region is a nonempty sequential composition of assignments, i.e., assignments has the form
x1 := expr1 ; x2 := expr2 ; . . . ; xm := exprm
where m ⩾1, x1, . . . , xm are variables and expr1, . . . , exprm expressions such that the types
of xi and expri are compatible.
Intuitive Meaning of the Commands
Before presenting the formal semantics, let
us give some informal explanations on the meaning of the commands. skip stands for
a process that terminates in one step, without aﬀecting the values of the variables or
contents of the channels. The meaning of assignments is obvious. stmt1 ; stmt2 denotes
sequential composition, i.e., stmt1 is executed ﬁrst and after its termination stmt2 is ex-
ecuted. The concept of atomic regions is realized in nanoPromela by statements of the
3For simplicity, the operators are supposed to be total. For operators that require special arguments
(e.g., division requires a nonzero second argument) we assume that the corresponding domain contains a
special element with the meaning of “undeﬁned”.

66
Modelling Concurrent Systems
form atomic{stmt}. The eﬀect of atomic regions is that the execution of stmt is treated
as an atomic step that cannot be interleaved with the activities of other processes. As a
side eﬀect atomic regions can also serve as a compactiﬁcation technique that compresses
the state space by ignoring the intermediate conﬁgurations that are passed during the
executions of the commands inside an atomic region. The assumption that the body of an
atomic region consists of a sequence of assignments will simplify the inference rules given
below.
Statements build by if–ﬁor do–od are generalizations of standard if-then-else commands
and whileloops. Let us ﬁrst explain the intuitive meaning of conditional commands. The
statement
if :: g1 ⇒stmt1 . . . :: gn ⇒stmtn ﬁ
stands for a nondeterministic choice between the statements stmti for which the guard gi
is satisﬁed in the current state, i.e., gi holds for the current valuation of the variables. We
assume a test-and-set semantics where the evaluation of the guards, the choice between
the enabled guarded commands and the execution of the ﬁrst atomic step of the selected
statement, are performed as an atomic unit that cannot be interleaved with the actions of
concurrent processes. If none of the guards g1, . . . , gn is fulﬁlled in the current state, then
the if–ﬁ–command blocks. Blocking has to be seen in the context of the other processes
that run in parallel and that might abolish the blocking by changing the values of shared
variables such that one or more of the guards may eventually evaluate to true. For instance,
the process given by the statement
if :: y > 0 ⇒x := 42 ﬁ
in a state where y has the value 0 waits until another process assigns a nonzero value to
y. Standard if-then-else commands, say “if g then stmt1 else stmt2 ﬁ”, of imperative
programming languages can be obtained by:
if :: g ⇒stmt1 :: ¬g ⇒stmt2 ﬁ,
while statements “if g then stmt1 ﬁ” without an else option are modeled by:
if :: g ⇒stmt1 :: ¬g ⇒skip ﬁ.
In a similar way, the do–od-command generalizes whileloops. These specify the repetition
of the body, as long as one of the guards is fulﬁlled. That is, statements of the form:
do :: g1 ⇒stmt1 . . . :: gn ⇒stmtn od
stand for the iterative execution of the nondeterministic choice among the guarded com-
mands gi ⇒stmti where guard gi holds in the current conﬁguration. Unlike conditional
commands, do–od-loops do not block in a state if all guards are violated. Instead, if

Parallelism and Communication
67
g1, . . . , gn do not hold in the current state, then the whileloop is aborted. In fact, a single
guarded loop do :: g ⇒stmt od has the same eﬀect as an ordinary whileloop “while
g do stmt od” with body stmt and termination condition ¬g. (As opposed to Promela,
loops are not terminated by the special command “break”.)
Example 2.36.
Peterson’s Mutual Exclusion Algorithm
Peterson’s mutual exclusion algorithm for two processes (see Example 2.25 on page 45)
can be speciﬁed in nanoPromela as follows. We deal with two Boolean variables b1 and
b2 and the variable x with domain dom(x) = {1, 2} and two Boolean variables crit1 and
crit2. The activities of the processes inside their noncritical sections are modeled by the
action skip. For the critical section, we use the assignment criti := true. Initially, we
have b1 = b2 = crit1 = crit2 = false, while x is arbitrary. Then the nanoPromela-code of
process P1 is given by the statement
do
::
true ⇒
skip;
atomic{b1 := true; x := 2};
if
:: (x = 1) ∨¬b2 ⇒crit1 := true ﬁ
atomic{crit1 := false; b1 := false}
od
The statement for modeling the second process is similar. The inﬁnite repetition of the
three phases “noncritical section”, “waiting phase” and “critical section” is modeled by the
do–od-loop with the trivial guard true. The request action corresponds to the statement
atomic{b1 := true; x := 2} and the release action to the statement atomic{crit1 :=
false; b1 := false}.
The waiting phase where process P1 has to await until x = 1 or
b2 = false is modeled by the if–ﬁ-command.
The use of atomic regions is not necessary, but serves here as a compactiﬁcation technique.
As we mentioned in Example 2.25, the request action can also be split into the two
assignments b1 := true and x := 2. As long as both assignments are inside an atomic
region the order of the assignments b1 := true and x := 2 is irrelevant. If, however, we
drop the atomic region, then we have to use the order b1 := true; x := 2, as otherwise the
mutual exclusion property cannot be ensured. That is, the process
do
::
true ⇒
skip;
x := 2;
b1 := true;
if
:: (x = 1) ∨¬b2 ⇒crit1 := true ﬁ
atomic{crit1 := false; b1 := false}
od
for P1 together with the symmetric protocol for P2 constitutes a nanoPromela program
where the mutual exclusion property “never crit1 = crit2 = true” cannot be guaranteed.

68
Modelling Concurrent Systems
Example 2.37.
Vending Machine
In the above example there are no nondeterministic choices caused by a conditional or
repetitive command. For an example where nondeterminism arises through simultaneously
enabled guarded commands of a loop, consider the beverage vending machine of Example
2.14 (page 33). The following nanoPromela program describes its behavior:
do
::
true ⇒
skip;
if
::
nsoda > 0
⇒
nsoda := nsoda −1
::
nbeer > 0
⇒
nbeer := nbeer −1
::
nsoda = nbeer = 0 ⇒skip
ﬁ
::
true ⇒
atomic{nbeer := max; nsoda := max}
od
In the starting location, there are two options that are both enabled. The ﬁrst is the
insertion of a coin by the user, modeled by the command skip. The ﬁrst two options of
the if–ﬁ-command represent the cases where the user selects soda or beer, provided some
bottles of soda and beer, respectively, are left. The third guarded command in the if–ﬁ
substatement applies to the case where neither soda nor beer is available anymore and the
machine automatically returns to the initial state. The second alternative that is enabled
in the starting location is the reﬁll action whose eﬀect is speciﬁed by the atomic region
where the variables nbeer and nsoda are reset to max.
Semantics
The operational semantics of a nanoPromela-statement with variables and
channels from (Var, Chan) is given by a program graph over (Var, Chan).
The pro-
gram graphs PG1, . . ., PGn for the processes P1, . . . , Pn of a nanoPromela program P =
[P1| . . . |Pn] constitute a channel system over (Var, Chan). The transition system seman-
tics for channel systems (Deﬁnition 2.31 on page 55) then yields a transition system TS(P)
that formalizes the stepwise behavior of P.
The program graph associated with a nanoPromela-statement stmt formalizes the control
ﬂow when executing stmt. That is, the substatements play the role of the locations. For
modeling termination, a special location exit is used.
Roughly speaking, any guarded
command g ⇒stmt corresponds to an edge with the label g : α where α stands for the
ﬁrst action of stmt. For example, for the statement
cond cmd
=
if
::
x > 1
⇒
y := x + y
::
true
⇒
x := 0; y := x
ﬁ

Parallelism and Communication
69
from cond cmd – viewed as a location of a program graph – there are two edges: one with
the guard x > 1 and action y := x + y leading to exit, and one with the guard true and
action x := 0 yielding the location for the statement y := x. Since y := x is deterministic
there is a single edge with guard true, action y := x leading to location exit.
As another example, consider the statement
loop
=
do
::
x > 1
⇒
y := x + y
::
y < x
⇒
x := 0; y := x
od
Here, the repetition semantics of the do–od-loop is modeled by returning the control to
stmt whenever the body of the selected alternative has been executed. Thus, from location
loop there are three outgoing edges, see Figure 2.22 on page 69. One is labeled with the
guard x > 1 and action y := x + y and leads back to location loop. The second edge has
the guard y < x and action x := 0 and leads to the statement y := x ; loop. The third
edge covers the case where the loop terminates. It has the guard ¬(x > 1) ∧¬(y < x) and
an action without any eﬀect on the variables and leads to location exit.
y := x ; loop
loop
exit
¬(x > 1) ∧¬(y < x)
y < x : x := 0
true : y := x
x > 1 : y := x+y
Figure 2.22: Program graph for a loop
The goal is now to formalize the ideas sketched above. We start with a formal deﬁnition of
substatements of stmt. Intuitively, these are the potential locations of intermediate states
during the execution of stmt.
Notation 2.38.
Substatement
The set of substatements of a nanoPromela-statement stmt is recursively deﬁned. For
statements stmt ∈{skip, x := expr, c?x, c!expr} the set of substatements is sub(stmt) =
{stmt, exit}. For sequential composition let
sub(stmt1 ; stmt2) =
{ stmt′ ; stmt2 | stmt′ ∈sub(stmt1) \ {exit} } ∪sub(stmt2).
For conditional commands, the set of substatements is deﬁned as the set consisting of the
if–ﬁ-statement itself and substatements of its guarded commands. That is, for cond cmd

70
Modelling Concurrent Systems
being if :: g1 ⇒stmt1 . . . :: gn ⇒stmtn ﬁwe have
sub(cond cmd)
=
{ cond cmd } ∪

1⩽i⩽n
sub(stmti).
The substatements of a loop loop given by do :: g1 ⇒stmt1 . . . :: gn ⇒stmtn od are
deﬁned similarly, but taking into account that control moves back to loop when guarded
commands terminate. That is:
sub(loop)
=
{ loop, exit } ∪

1⩽i⩽n
{ stmt′ ; loop | stmt′ ∈sub(stmti) \ {exit} }.
For atomic regions let sub(atomic{stmt}) = { atomic{stmt}, exit }.
The deﬁnition of sub(loop) relies on the observation that the eﬀect of a loop with a single
guarded command, say “do :: g ⇒stmt od”, corresponds to the eﬀect of
if g then stmt ; do :: g ⇒stmt od else skip ﬁ
An analogous characterization applies to loops with two or more guarded commands.
Thus, the deﬁnition of the substatements of loop relies on combining the deﬁnitions of the
sets of substatements for sequential composition and conditional commands.
The formal semantics of nanoPromela program P = [P1| . . . |Pn] where the behavior of the
process Pi is speciﬁed by a nanoPromela statement is a channel system [PG1| . . . |PGn]
over (Var, Chan) where Var is the set of variables and Chan the set of channels that
are declared in P. As mentioned before, a formal syntax for the variable and channel
declarations will not be provided, and global and local variables will not be distinguished.
We assume that the set Var of typed variables and the set Chan of channels (together
with a classiﬁcation of the channels into synchronous and FIFO-channels of some capacity
cap(·)) are given. Hence, local variable and channel declarations for the processes Pi are
not considered. It is assumed that they are given by a nanoPromela-statement over some
ﬁxed tuple (Var, Chan).
We now provide inference rules for the nanoPromela constructs. The inference rules for the
atomic commands (skip, assignment, communication actions) and sequential composition,
conditional and repetitive commands give rise to the edges of a “large” program graph
where the set of locations agrees with the set of nanoPromela-statements. Thus, the edges
have the form
stmt
g:α

→stmt′
or
stmt
g:comm

→stmt′
where stmt is a nanoPromela statement, stmt′ a substatement of stmt, and g a guard, α
an action, and comm a communication action c?x or c!expr. The subgraph consisting of

Parallelism and Communication
71
the substatements of Pi then yields the program graph PGi of process Pi as a component
of the program P.
The semantics of the atomic statement skip is given by a single axiom formalizing that
the execution of skip terminates in one step without aﬀecting the variables
skip
true: id

→exit
where id denotes an action that does not change the values of the variables, i.e., Eﬀect(id, η)
= η for all variable evaluations η. Similarly, the execution of a statement consisting of an
assignment x := expr has the trivial guard and terminates in one step:
x := expr
true : assign(x, expr)

→exit
where assign(x, expr) denotes the action that changes the value of x according to the
assignment x := expr and does not aﬀect the other variables, i.e., if η ∈Eval(Var) and
y ∈Var then Eﬀect(assign(x, expr), η)(y) = η(y) if y ̸= x and Eﬀect(assign(x, expr), η)(x)
is the value of expr when evaluated over η. For the communication actions c!expr and c?x
the following axioms apply:
c?x
c?x

→exit
c!expr
c!expr

→exit
The eﬀect of an atomic region atomic{x1 := expr1; . . . ; xm := exprm} is the cumulative
eﬀect of the assignments xi := expri. It can be deﬁned by the rule:
atomic{x1 := expr1; . . . ; xm := exprm}
true : αm

→exit
where α0 = id, αi = Eﬀect(assign(xi, expri), Eﬀect(αi−1, η)) for 1 ⩽i ⩽m.
Sequential composition stmt1; stmt2 is deﬁned by two rules that distinguish whether or
not stmt1 terminates in one step. If the ﬁrst step of stmt1 leads to a location (statement)
diﬀerent from exit, then the following rule applies:
stmt1
g:α

→stmt′
1 ̸= exit
stmt1; stmt2
g:α

→stmt′
1; stmt2
If the computation of stmt1 terminates in one step by executing action α, then control of
stmt1; stmt2 moves to stmt2 after executing α:
stmt1
g:α

→exit
stmt1; stmt2
g:α

→stmt2

72
Modelling Concurrent Systems
The eﬀect of a conditional command cond cmd = if :: g1 ⇒stmt1 . . . :: gn ⇒stmtn ﬁis
formalized by means of the following rule:
stmti
h:α

→stmt′
i
cond cmd
gi∧h:α

→stmt′
i
This rule relies on the test-and-set semantics where choosing one of the enabled guarded
commands and performing its ﬁrst action are treated as an atomic step. The blocking of
cond cmd when none of its guards is enabled needs no special treatment. The reason is
that cond cmd has no other edges than the ones speciﬁed by the rule above. Thus, in a
global state s = ⟨ℓ1, . . . , ℓn, η, ξ⟩where the location ℓi of the ith process is ℓi = cond cmd
and all guards g1, . . . , gn evaluate to false, then there is no action of the ith process that is
enabled in s. However, actions of other processes might be enabled. Thus, the ith process
has to wait until the other processes modify the variables appearing in g1, . . . , gn such that
one or more of the guarded commands gi ⇒stmti become enabled.
For loops, say loop = do :: g1 ⇒stmt1 . . . :: gn ⇒stmtn od, we deal with three rules. The
ﬁrst two rules are similar to the rule for conditional commands, but taking into account
that control moves back to loop after the execution of the selected guarded command has
been completed. This corresponds to the following rules:
stmti
h:α

→stmt′
i ̸= exit
loop
gi∧h:α

→stmt′
i; loop
stmti
h:α

→exit
loop
gi∧h:α

→loop
If none of the guards g1, . . . , gn holds in the current state then the do–od-loop will be
aborted. This is formalized by the following axiom:
loop
¬g1∧...∧¬gn

→exit
Remark 2.39.
Test-and-Set Semantics vs. Two-Step Semantics
The rules for if–ﬁ- and do–od-statements formalize the so-called test-and-set semantics of
guarded commands. This means that evaluating guard gi and performing the ﬁrst step of
the selected enabled guarded command gi ⇒stmti are performed atomically. In contrast,
SPIN’s interpretation of Promela relies on a two-step-semantics where the selection of an
enabled guarded command and the execution of its ﬁrst action are split into two steps.
The rule for a conditional command is formalized by the axiom
if :: g1 ⇒stmt1 . . . :: gn ⇒stmtn ﬁ
gi : id

→stmti

Parallelism and Communication
73
where id is an action symbol for an action that does not aﬀect the variables. Similarly,
the ﬁrst two rules for loops have to be replaced for the two-step semantics by the following
rule:
loop
gi : id

→stmti; loop
The rule for terminating the loop remains unchanged.
As long as we consider the statements in isolation, the test-and-set semantics and the
two-step semantics are equal. However, when running several processes in parallel, the
interleaving might cause undesired side eﬀects. For example, consider the semaphore-based
solution of the mutual exclusion problem, modeled by a nanoPromela program where the
behavior of Pi is given by the following nanoPromela-statement:
do :: true ⇒
skip;
if :: y > 0 ⇒
y := y −1;
criti := true
ﬁ;
y := y + 1
od
The initial value of the semaphore y is zero. Under the two-step semantics the mutual
exclusion property is not guaranteed as it allows the processes to verify that the guard
y > 0 of the if–ﬁ-statement holds, without decreasing the value of y, and moving control
to the assignment y := y−1. But from there the processes can enter their critical sections.
However, the protocol works correctly for the test-and-set semantics since then checking
y > 0 and decreasing y is an atomic step that cannot be interleaved by the actions of the
other process.
Remark 2.40.
Generalized Guards
So far we required that the guards in conditional or repetitive commands consist of Boolean
conditions on the program variables. However, it is also often useful to ask for interaction
facilities in the guards, e.g., to specify that a process has to wait for a certain input along
a FIFO-channel by means of a conditional command if :: c?x ⇒stmt ﬁ. The intuitive
meaning of the above statement is that the process has to wait until the buﬀer for c is
nonempty. If so, then it ﬁrst performs the action c?x and then executes stmt. The use
of communication actions in the guards leads to a more general class of program graphs
with guards consisting of Boolean conditions on the variables or communication actions.
For the case of an asynchronous channel the rules in Figure 2.20 on page 61 then have to
be extended by:
ℓi
c?x:α

→ℓ′
i ∧len(ξ(c)) = k > 0 ∧ξ(c) = v1v2 . . . vk
⟨. . . , ℓi, . . . , η, ξ⟩
τ
−→⟨. . . , ℓ′
i, . . . , η′, ξ′⟩

74
Modelling Concurrent Systems
where η′ = Eﬀect(α, η[x := v1]) and ξ[c := v2 . . . vk], and
ℓi
c!v:α

→ℓ′
i ∧len(ξ(c)) = k < cap(c) ∧ξ(c) = v1 . . . vk
⟨. . . , ℓi, . . . , η, ξ⟩
τ
−→⟨. . . , ℓ′
i, . . . , η′, ξ′⟩
where η′ = Eﬀect(α, η) and ξ[c := v1 . . . vkv].
Another convenient concept is the special guard else which speciﬁes conﬁgurations where
no other guarded command can be taken. The intuitive semantics of:
if
::
g1
⇒
stmt1
...
::
gn
⇒
stmtn
::
else
⇒
stmt′
ﬁ
is that the else option is enabled if none of the guards g1, . . . gn evaluates to true. In
this case, the execution evolves to a state in which the statement stmt′ is to be executed.
Here, the gi’s can be Boolean expressions on the variables or communication guards. For
example,
if :: d?x ⇒stmt :: else ⇒x := x + 1 ﬁ
increases x unless a message is obtained from channel d. The else option used in loops
leads to nonterminating behaviors.
Remark 2.41.
Atomic Regions
The axiom for atomic regions yields that if s = ⟨ℓ1 . . . , ℓn, η, ξ⟩is a state in the transition
system for the channel system associated with P = [P1| . . . |Pn] and ℓi = atomic{x1 :=
expr1; . . . ; xm := exprm}; . . . then in state s the ith process can perform the sequence of
assignments x1 := expr1; . . . ; xm := exprm in a single transition. With this semantics we
abstract from the intermediate states that are passed when having performed the ﬁrst i
assignments (1 ⩽i < m) and avoid that other processes can interleave their activities with
these assignments.
This concept can be generalized for atomic regions atomic{stmt} where the body stmt is
an arbitrary statement. The idea is that any terminating execution of stmt is collapsed
into a single transition, leading from a state with location stmt to a state with location
exit. For this more general approach, the semantic rule for atomic regions operates on
execution sequences in the transition system rather than just edges in the program graph.
This is not problematic as one could provide the meaning of the statements on the level
of transition systems rather than program graph level.
However, the semantics is less

Parallelism and Communication
75
obvious for, e.g., inﬁnite executions inside atomic regions, synchronous communication
actions inside atomic regions and blocking conditional commands inside atomic regions.
One possibility is to insert transitions to a special deadlock state. Another possibility is to
work with a semantics that represents also the intermediate steps of an atomic region (but
avoids interleaving) and to abort atomic regions as soon as a synchronous communication
is required or blocking conﬁgurations are reached.
As we mentioned in the beginning of the section, Promela provides many more features
than nanoPromela, such as atomic regions with more complex statements than sequences
of assignments, arrays and other data types, and dynamic process creation. These concepts
will not be explained here and we refer to the literature on the model checker SPIN (see,
e.g., [209]).
2.2.6
Synchronous Parallelism
When representing asynchronous systems by transition systems, there are no assumptions
concerning the relative velocities of the processors on which the components are executed.
The residence time of the system in a state and the execution time of the actions are
completely ignored. For instance, in the example of the two independent traﬃc lights
(see Example 2.17), no assumption has been made concerning the amount of time a light
should stay red or green. The only assumption is that both time periods are ﬁnite. The
concurrent execution of components is time-abstract.
This is opposed to synchronous systems where components evolve in a lock step fashion.
This is a typical computation mechanism in synchronous hardware circuits, for example,
where the diﬀerent components (like adders, inverters, and multiplexers) are connected to
a central clock and all perform a (possibly idle) step on each clock pulse. As clock pulses
occur periodically with a ﬁxed delay, these pulses may be considered in a discrete manner,
and transition systems can be adequately used to describe these synchronous systems.
Synchronous composition of two transition systems is deﬁned as follows.
Deﬁnition 2.42.
Synchronous Product
Let TSi
= (Si, Act, →i, Ii, APi, Li), i=1, 2, be transition systems with the same set of
actions Act. Further, let
Act × Act →Act,
(α, β) →α ∗β

76
Modelling Concurrent Systems
r1
NOT
y
OR
r2
y′
x
0
1
00
01
10
11
TS2 :
TS1 :
000
100
010
101
001
111
011
110
TS1 ⊗TS2 :
Figure 2.23: Synchronous composition of two hardware circuits.
be a mapping4 that assigns to each pair of actions α, β, the action name α ∗β.
The
synchronous product TS1 ⊗TS2 is given by:
TS1 ⊗TS2 =
(S1 × S2, Act, →, I1 × I2, AP1 ∪AP2, L),
where the transition relation is deﬁned by the following rule
s1
α
−−→1 s′
1
∧
s2
β
−−→2 s′
2
⟨s1, s2⟩
α∗β
−−−→⟨s′
1, s′
2⟩
and the labeling function is deﬁned by: L(⟨s1, s2⟩) = L1(s1) ∪L2(s2).
Action α∗β denotes the synchronous execution of actions α and β. Note that compared to
the parallel operator ∥where components perform actions in common synchronously, and
other action autonomously (i.e., asynchronously), in TS1 ⊗TS2, both transition systems
have to perform all steps synchronously. There are no autonomous transitions of either
TS1 or TS2.
4Operator ∗is typically assumed to be commutative and associative.

The State-Space Explosion Problem
77
Example 2.43.
Synchronous Product of Two Circuits
Let C1 be a circuit without input variables and with output variable y and register r. The
control functions for output and register transitions are
λy = r1,
δr1 = ¬ r1.
Circuit C2 has input variable x′, output variable y′, and register variable r2 with the
control functions
λy′ = δr2 = x′ ∨r2.
The transition system TSC1 ⊗TSC2 is depicted in Figure 2.23 on page 76. Since action
names are omitted for transition systems of circuits, action labels for TSC1 ⊗TSC2 are
irrelevant. TSC1 ⊗TSC2 is thus the transition system of the circuit with input variable x′,
output variables y and y′, and registers r1 and r2, whose control functions are λy, λy′, δr1,
and δr2.
2.3
The State-Space Explosion Problem
The previous two sections have shown that various kinds of systems can be modeled using
transition systems. This applies to program graphs representing data-dependent systems,
and hardware circuits. Diﬀerent communication mechanisms can be modeled in terms
of appropriate operators on transition systems. This section considers the cardinality of
the resulting transition systems, i.e., the number of states in these models. Veriﬁcation
techniques are based on systematically analyzing these transition systems. The runtimes
of such veriﬁcation algorithms are mainly determined by the number of states of the
transition system to be analyzed. For many practical systems, the state space may be
extremely large, and this is a major limitation for state-space search algorithms such as
model checking. Chapter 8, Section 6.7, and Chapter 7 introduce a number of techniques
to combat this problem.
Program Graph Representation
Transition systems generated by means of “un-
folding” a program graph may be extremely large, and in some cases—e.g., if there are
inﬁnitely many program locations or variables with inﬁnite domains—even have inﬁnitely
many states.
Consider a program graph over the set of variables Var with x ∈V ar.
Recall that states of the unfolded transition system are of the form ⟨ℓ, η⟩with location
ℓand variable evaluation η. In case all variables in Var have a ﬁnite domain, like bits,
or bounded integers, and the number of locations is ﬁnite, the number of states in the
transition system is
| Loc | ·

x∈Var
| dom(x) | .

78
Modelling Concurrent Systems
The number of states thus grows exponentially in the number of variables in the program
graph: for N variables with a domain of k possible values, the number of states grows up
to kN. This exponential growth is also known as the state-space explosion problem.
It is important to realize that for even simple program graphs with just a small number
of variables, this bound may already be rather excessive. For instance, a program graph
with ten locations, three Boolean variables and ﬁve bounded integers (with domain in
{ 0, . . . , 9 }) has 10·23·105 = 8, 000, 000 states. If a single bit array of 50 bits is added to
this program graph, for example, this bound grows even to 800,000·250! This observation
clearly shows why the veriﬁcation of data-intensive systems (with many variables or com-
plex domains) is extremely hard. Even if there are only a few variables in a program, the
state space that must be analyzed may be very large.
If dom(x) is inﬁnite for some x ∈Var, as for reals or integers, the underlying transition
system has inﬁnitely many states as there are inﬁnitely many values for x. Such pro-
gram graphs usually yield undecidable veriﬁcation problems. This is not to say that the
veriﬁcation of all transition systems with an inﬁnite state space is undecidable, however.
It should be remarked that not only the state space of a transition system, but also the
number of atomic propositions to represent program graphs (see Deﬁnition 2.15, page 34)
may in principle be extremely large. Besides, any location, any condition on the variables
in the program graph is allowed as an atomic proposition. However, in practice, only a
small fragment of the possible atomic propositions is needed. An explicit representation
of the labeling function is mostly not necessary, as the truth-values of the atomic formulae
are typically derived from the state information. For these reasons, the number of atomic
propositions plays only a secondary role.
For sequential hardware circuits (see page 26), states in the transition system are deter-
mined by the possible evaluations of the input variables and the registers. The size of the
transition system thus grows exponentially in the number of registers and input variables.
For N input variables and K registers, the total state space consists of 2N+K states.
Parallelism
In all variants of parallel operators for transition systems and program
graphs, the state space of the complete system is built as the Cartesian product of the
local state spaces Si of the components.
For example, for state space S of transition
system
TS = TS1 ||| . . . ||| TSn
we have S = S1 × . . . × Sn where Si denotes the state space of transition system TSi.
The state space of the parallel composition of a system with n states and a system with

The State-Space Explosion Problem
79
k states yields n·k states. The total state space S is thus
|S1| · . . . · |Sn|.
The number of states in S is growing (at most) exponentially in the number of components:
the parallel composition of N components of size k each yields kN states. Even for small
parallel systems this may easily run out of control.
Additionally, the variables (and their domains) represented in the transition system essen-
tially inﬂuence the size of the state space. If one of the domains is inﬁnite, then the state
space is inﬁnitely large. If the domains are ﬁnite, then the size of the state space grows
exponentially in the number of variables (as we have seen before for program graphs).
The “exponential blowup” in the number of parallel components and the number of vari-
ables explains the enormous size of the state space of practically relevant systems. This
observation is known under the heading state explosion and is another evidence for the
fact that veriﬁcation problems are particularly space-critical.
Channel Systems
For the size of transition systems of channel systems, similar observa-
tions can be made as for the representation of program graphs. An important additional
component for these systems is the size of the channels, i.e., their capacity. Clearly, if
one of these channels has an inﬁnite capacity, this may yield inﬁnitely many states in
the transition system. If all channels have ﬁnite capacity, however, the number of states
is bound in the following way.
Let CS = [PG1 | . . . |PGn] be a channel system over
Var = Var1 ∪. . . ∪Varn and channels Chan. The state space of CS is of cardinality
n

i=1
| PGi | ·

c∈Chan
| dom(c) |cp(c),
which can be rewritten as
n

i=1
⎛
⎝| Loci | ·

x∈Vari
| dom(x) |
⎞
⎠·

c∈Chan
| dom(c) |cp(c).
For L locations per component, K bit channels of capacity k each, and M variables x with
| dom(x) | ⩽m totally, the total number of states in the transition system is Ln·mM·2K·k.
This is typically enormous.
Example 2.44.
State-Space Size of the Alternating Bit Protocol
Consider a variant of the alternating bit protocol (see Example 2.32, page 57) where the

80
Modelling Concurrent Systems
channels c and d have a ﬁxed capacity, 10 say. Recall that along channel d, control bits are
sent, and along channel c, data together with a control bit. Let us assume that data items
are also simply bits. The timer has two locations, the sender eight, and the receiver six.
As there are no further variables, we obtain that the total number of states is 2·8·6·410·210,
which equals 3·235. This is around 1011 states.
2.4
Summary
• Transition systems are a fundamental model for modeling software and hardware
systems.
• An execution of a transition system is an alternating sequence of states and actions
that starts in an initial state and that cannot be prolonged.
• Interleaving amounts to represent the evolvement of “simultaneous” activities of
independent concurrent processes by the nondeterministic choice between these ac-
tivities.
• In case of shared variable communication, parallel composition on the level of tran-
sition systems does not faithfully reﬂect the system’s behavior. Instead, composition
on program graphs has to be considered.
• Concurrent processes that communicate via handshaking on the set H of actions
execute actions outside H autonomously whereas they execute actions in H syn-
chronously.
• In channel systems, concurrent processes communicate via FIFO-buﬀers (i.e., chan-
nels).
Handshaking communication is obtained when channels have capacity 0.
For channels with a positive capacity, communication takes place asynchronous-
ly—sending and receiving a message takes place at diﬀerent moments.
• The size of transition system representations grows exponentially in various com-
ponents, such as the number of variables in a program graph or the number of
components in a concurrent system.
This is known as the state-space explosion
problem.
2.5
Bibliographic Notes
Transition systems. Keller was one of the ﬁrst researchers that explicitly used transition
systems [236] for the veriﬁcation of concurrent programs. Transition systems are used

Bibliographic Notes
81
as semantical models for a broad range of high-level formalisms for concurrent systems,
such as process algebras [45, 57, 203, 298, 299], Petri nets [333], and statecharts [189]. The
same is true for hardware synthesis and analysis, in which variants of ﬁnite-state automata
(Mealy and Moore automata) play a central role; these variants can also be described by
transition systems [246]. Program graphs and their unfolding into transition systems have
been used extensively by Manna and Pnueli in their monograph(s) on temporal logic
veriﬁcation [283].
Synchronization paradigms.
Shared variable “communication” dates back to the mid-
sixties and is due to Dijkstra [126]. He also coined the term interleaving in 1971 [128].
Handshaking communication has been the main interaction paradigm in process algebras
such as ACP [45], CCS [298, 299], CSP [202, 203], and LOTOS [57].
For a detailed
account of process algebra we refer to [46]. The principle of synchronized parallelism has
been advocated in Milner’s synchronous variant of CCS, SCCS [297], and is used by Arnold
to model the interaction between ﬁnite transition systems [19]. Synchronous parallelism is
also at the heart of Lustre [183], a declarative programming language for reactive systems,
and is used in many other hardware-oriented languages.
The interaction between concurrent processes by means of buﬀers (or channels) has ﬁrst
been considered by Dijkstra [129]. This paradigm has been adopted by speciﬁcation lan-
guages for communication protocols, such as SDL (Speciﬁcation and Description Lan-
guage [37]) which is standardized by the ITU. The idea of guarded command languages
goes back to Dijkstra [130]. The combination of guarded command languages in combina-
tion with channel-based communication is also used in Promela [205], the input language
of the model checker SPIN [208]. The recent book by Holzmann [209] gives a detailed
account of Promela and SPIN. Structured operational semantics has been introduced by
Plotkin [334, 336] in 1981. Its origins are described in [335]. Atomic regions have been ﬁrst
discussed by Lipton [276], Lamport [257] and Owicki [317]. Further details on semantic
rules for speciﬁcation languages for reactive systems can be found, e.g., in [15, 18].
The examples. Most examples that have been provided in this chapter are rather classical.
The problem of mutual exclusion was ﬁrst proposed in 1962 by Dekker together with an
algorithm that guarantees two-process mutual exclusion. Dijkstra’s solution [126] was the
ﬁrst solution to mutual exclusion for an arbitrary number of processes. He also introduced
the concept of semaphores [127] and their use for solving the mutual exclusion problem.
A simpler and more elegant solution has been proposed by Lamport in 1977 [256]. This
was followed up by Peterson’s mutual exclusion protocol [332] in 1981. This algorithm is
famous by now due to its beauty and simplicity. For other mutual exclusion algorithms,
see e.g. [283, 280]. The alternating bit protocol stems from 1969 and is one of the ﬁrst ﬂow
control protocols [34]. Holzmann gives a historical account of this and related protocols
in his ﬁrst book [205].

82
Modelling Concurrent Systems
2.6
Exercises
Exercise 2.1.
Consider the following two sequential hardware circuits:
r1
AND
x1
r2
OR
x2
AND
OR
NOT
y1
y2
Questions:
(a) Give the transition systems of both hardware circuits.
(b) Determine the reachable part of the transition system of the synchronous product of these
transition systems. Assume that the initial values of the registers are r1=0 and r2=1.
Exercise 2.2.
We are given three (primitive) processes P1, P2, and P3 with shared integer
variable x. The program of process Piis as follows:
Algorithm 1 Process Pi
for ki = 1, . . . , 10 do
LOAD(x);
INC(x);
STORE(x);
od
That is, Pi executes ten times the assignment x := x+1. The assignment x := x+1 is realized
using the three actions LOAD(x), INC(x) and STORE(x). Consider now the parallel program:
Algorithm 2 Parallel program P
x := 0;
P1 || P2 || P3
Question: Does P have an execution that halts with the terminal value x = 2?
Exercise 2.3.
Consider the following street junction with the speciﬁcation of a traﬃc light as
outlined on the right.

Exercises
83
A1
A3
A1
A2
A2
Ai :
red
green
yellow
red/yellow
(a) Choose appropriate actions and label the transitions of the traﬃc light transition system
accordingly.
(b) Give the transition system representation of a (reasonable) controller C that switches the
green signal lamps in the following order: A1, A2, A3, A1, A2, A3, . . ..
(Hint: Choose an appropriate communication mechanism.)
(c) Outline the transition system A1∥A2∥A3∥C.
Exercise 2.4.
Show that the handshaking operator ∥that forces two transition systems to
synchronize over their common actions (see Deﬁnition 2.26 on page 48) is associative. That is,
show that
(TS1∥TS2)∥TS3
=
TS1∥(TS2∥TS3)
where TS1, TS2, TS3 are arbitrary transition systems.
Exercise 2.5.
The following program is a mutual exclusion protocol for two processes due to
Pnueli [118]. There is a single shared variable s which is either 0 or 1, and initially 1. Besides,
each process has a local Boolean variable y that initially equals 0. The program text for process
Pi (i = 0, 1) is as follows:
l0: loop forever do
begin
l1: Noncritical section
l2: (yi, s) := (1, i);
l3: wait until ((y1−i = 0) ∨(s ̸= i));
l4: Critical section
l5: yi := 0
end.
Here, the statement (yi, s) := (1, i); is a multiple assignment in which variable yi := 1 and s := i
is a single, atomic step.

84
Modelling Concurrent Systems
Questions:
(a) Deﬁne the program graph of a process in Pnueli’s algorithm.
(b) Determine the transition system for each process.
(c) Construct their parallel composition.
(d) Check whether the algorithm ensures mutual exclusion.
(e) Check whether the algorithm ensures starvation freedom.
The last two questions may be answered by inspecting the transition system.
Exercise 2.6.
Consider a stack of nonnegative integers with capacity n (for some ﬁxed n).
(a) Give a transition system representation of this stack. You may abstract from the values on
the stack and use the operations top, pop, and push with their usual meaning.
(b) Sketch a transition system representation of the stack in which the concrete stack content is
explicitly represented.
Exercise 2.7.
Consider the following generalization of Peterson’s mutual exclusion algorithm
that is aimed at an arbitrary number n (n ⩾2) processes. The basic concept of the algorithm
is that each process passes through n “levels” before acquiring access to the critical section. The
concurrent processes share the bounded integer arrays y[0..n−1] and p[1..n] with y[i] ∈{ 1, . . . , n }
and p[i] ∈{ 0, . . . , n−1 }. y[j] = i means that process i has the lowest priority at level j, and
p[i] = j expresses that process i is currently at level j. Process i starts at level 0. On requesting
access to the critical section, the process passes through levels 1 through n−1. Process i waits at
level j until either all other processes are at a lower level (i.e., p[k] < j for all k ̸= i) or another
process grants process i access to its critical section (i.e., y[j] ̸= i). The behavior of process i is in
pseudocode:
while true do
. . . noncritical section . . .
forall j = 1, . . . , n−1 do
p[i] := j;
y[j] := i;
wait until (y[j] ̸= i) ∨

0<k⩽n,k̸=i p[k] < j

od
. . . critical section . . .
p[i] := 0;
od
Questions:

Exercises
85
(a) Give the program graph for process i.
(b) Determine the number of states (including the unreachable states) in the parallel composition
of n processes.
(c) Prove that this algorithm ensures mutual exclusion for n processes.
(d) Prove that it is impossible that all processes are waiting in the for-iteration.
(e) Establish whether it is possible that a process that wants to enter the critical section waits
ad inﬁnitum.
Exercise 2.8. In channel systems, values can be transferred from one process to another process.
As this is somewhat limited, we consider in this exercise an extension that allows for the transfer
of expressions. That is to say, the send and receive statements c!v and c?x (where x and v are of
the same type) are generalized into c!expr and c?x, where for simplicity it is assumed that expr
is a correctly typed expression (of the same type as x). Legal expressions are, e.g., x ∧(¬y ∨z)
for Boolean variables x, y, and z, and channel c with dom(c) = { 0, 1 }. For integers x, y, and an
integer-channel c, |2x + (x −y)div17| is a legal expression.
Question: Extend the transition system semantics of channel systems such that expressions are
allowed in send statements.
(Hint: Use the function η such that for expression expr, η(expr) is the evaluation of expr under
the variable valuation η.)
Exercise 2.9.
Consider the following mutual exclusion algorithm that uses the shared variables
y1 and y2 (initially both 0).
Process P1:
while true do
. . . noncritical section . . .
y1 := y2 + 1;
wait until (y2 = 0) ∨(y1 < y2)
. . . critical section . . .
y1 := 0;
od
Process P2:
while true do
. . . noncritical section . . .
y2 := y1 + 1;
wait until (y1 = 0) ∨(y2 < y1)
. . . critical section . . .
y2 := 0;
od
Questions:
(a) Give the program graph representations of both processes. (A pictorial representation suf-
ﬁces.)
(b) Give the reachable part of the transition system of P1 ∥P2 where y1 ⩽2 and y2 ⩽2.
(c) Describe an execution that shows that the entire transition system is inﬁnite.
(d) Check whether the algorithm indeed ensures mutual exclusion.

86
Modelling Concurrent Systems
(e) Check whether the algorithm never reaches a state in which both processes are mutually
waiting for each other.
(f) Is it possible that a process that wants to enter the critical section has to wait ad inﬁnitum?
Exercise 2.10.
Consider the following mutual exclusion algorithm that was proposed 1966 [221]
as a simpliﬁcation of Dijkstra’s mutual exclusion algorithm in case there are just two processes:
1 Boolean array b(0;1) integer k, i, j,
2 comment
This is the program for computer i, which may be
either 0 or 1, computer j =/= i is the other one, 1 or 0;
3 C0: b(i) := false;
4 C1: if k != i then begin
5 C2: if not b(j) then go to C2;
6
else k := i; go to C1 end;
7
else critical section;
8
b(i) := true;
9
remainder of program;
10
go to C0;
11
end
Here C0, C1, and C2 are program labels, and the word “computer” should be interpreted as process.
Questions:
(a) Give the program graph representations for a single process. (A pictorial representation
suﬃces.)
(b) Give the reachable part of the transition system of P1 ∥P2.
(c) Check whether the algorithm indeed ensures mutual exclusion.

Exercises
87
Exercise 2.11.
Consider the following two sequential hardware circuits C1 and C2:
NOT
x
y
AND
AND
AND
NOT
AND
AND
NOT
OR
OR
C1 :
r1
r2
C2 :
y
r1
(a) Give the transition system representation TS(C1) of the circuit C1.
(b) Let TS(C2) be the transition system of the circuit C2. Outline the transition system TS(C1)⊗
TS(C2).
Exercise 2.12.
Consider the following leader election algorithm: For n ∈N, n processes
P1, . . . , Pn are located in a ring topology where each process is connected by an unidirectional
channel to its neighbor in a clockwise manner.
To distinguish the processes, each process is assigned a unique identiﬁer id ∈{1, . . . , n}. The aim
is to elect the process with the highest identiﬁer as the leader within the ring. Therefore each
process executes the following algorithm:
send (id);
initially set to process’ id
while (true) do
receive (m);
if (m = id) then stop;
process is the leader
if (m > id) then send (m);
forward identiﬁer
od
(a) Model the leader election protocol for n processes as a channel system.
(b) Give an initial execution fragment of TS([P1|P2|P3]) such that at least one process has
executed the send statement within the body of the whileloop. Assume for 0 < i ⩽3, that
process Pi has identiﬁer idi = i.


Chapter 3
Linear-Time Properties
For veriﬁcation purposes, the transition system model of the system under consideration
needs to be accompanied with a speciﬁcation of the property of interest that is to be
veriﬁed.
This chapter introduces some important, though relatively simple, classes of
properties. These properties are formally deﬁned and basic model-checking algorithms
are presented to check such properties in an automated manner. This chapter focuses on
linear-time behavior and establishes relations between the diﬀerent classes of properties
and trace behavior. Elementary forms of fairness are introduced and compared.
3.1
Deadlock
Sequential programs that are not subject to divergence (i.e., endless loops) have a terminal
state, a state without any outgoing transitions. For parallel systems, however, computa-
tions typically do not terminate—consider, for instance, the mutual exclusion programs
treated so far. In such systems, terminal states are undesirable and mostly represent a
design error. Apart from “trivial” design errors where it has been forgotten to indicate
certain activities, in most cases such terminal states indicate a deadlock. A deadlock oc-
curs if the complete system is in a terminal state, although at least one component is in a
(local) nonterminal state. The entire system has thus come to a halt, whereas at least one
component has the possibility to continue to operate. A typical deadlock scenario occurs
when components mutually wait for each other to progress.
89

90
Linear-Time Properties
red
green
red
green
α
β
β
α
TrLight1
TrLight2
TrLight1 || TrLight2
⟨red, red⟩
Figure 3.1: An example of a deadlock situation.
Example 3.1.
Deadlock for Fault Designed Traﬃc Lights
Consider the parallel composition of two transition systems
TrLight1 ∥TrLight2
modeling the traﬃc lights of two intersecting roads. Both traﬃc lights synchronize by
means of the actions α and β that indicate the change of light (see Figure 3.1).
The
apparently trivial error to let both traﬃc lights start with a red light results in a deadlock.
While the ﬁrst traﬃc light is waiting to be synchronized on action α, the second traﬃc
light is blocked, since it is waiting to be synchronized with action β.
Example 3.2.
Dining Philosophers
This example, originated by Dijkstra, is one of the most prominent examples in the ﬁeld
of concurrent systems.

Deadlock
91
P0
P1
P2
P3
P4
Stick0
Stick1
Stick2
Stick3
Stick4
Five philosophers are sitting at a round table with a bowl of rice in the middle. For the
philosophers (being a little unworldly) life consists of thinking and eating (and waiting,
as we will see). To take some rice out of the bowl, a philosopher needs two chopsticks.
In between two neighboring philosophers, however, there is only a single chopstick. Thus,
at any time only one of two neighboring philosophers can eat. Of course, the use of the
chopsticks is exclusive and eating with hands is forbidden.
Note that a deadlock scenario occurs when all philosophers possess a single chopstick.
The problem is to design a protocol for the philosophers, such that the complete system is
deadlock-free, i.e., at least one philosopher can eat and think inﬁnitely often. Additionally,
a fair solution may be required with each philosopher being able to think and eat inﬁnitely
often. The latter characteristic is called freedom of individual starvation.
The following obvious design cannot ensure deadlock freedom. Assume the philosophers
and the chopsticks are numbered from 0 to 4. Furthermore, assume all following calcula-
tions be “modulo 5”, e.g., chopstick i−1 for i=0 denotes chopstick 4, and so on.
Philosopher i has stick i on his left and stick i−1 on his right side. The action requesti,i
express that stick i is picked up by philosopher i. Accordingly, requesti−1,i denotes the
action by means of which philosopher i picks up the (i−1)th stick. The actions releasei,i
and releasei−1,i have a corresponding meaning.
The behavior of philosopher i (called process Phili) is speciﬁed by the transition system
depicted in the left part of Figure 3.2. Solid arrows depict the synchronizations with the
i-th stick, dashed arrows refer to communications with the i−1th stick. The sticks are
modeled as independent processes (called Stick i) with which the philosophers synchronize
via actions request and release; see the right part of Figure 3.2 that represents the process
of stick i.
A stick process prevents philosopher i from picking up the ith stick when
philosopher i+1 is using it.

92
Linear-Time Properties
wait for
left stick
left stick
right stick
wait for
right stick
return the
return the
think
eat
requesti i
releasei i
requesti 1 i
requesti 1 i
requesti i
releasei 1 i
releasei 1 i
releasei i
available
occupied
occupied
reqi i
reqi i 1
reli i reli i 1
Figure 3.2: Transition systems for the ith philosopher and the ith stick.
The complete system is of the form:
Phil4 ∥Stick 3 ∥Phil3 ∥Stick 2 ∥Phil2 ∥Stick 1 ∥Phil 1 ∥Stick 0 ∥Phil0 ∥Stick 4
This (initially obvious) design leads to a deadlock situation, e.g., if all philosophers pick
up their left stick at the same time. A corresponding execution leads from the initial state
⟨think 4, avail3, think 3, avail 2, think 2, avail 1, think 1, avail 0, think 0, avail 4⟩
by means of the action sequence request4, request3, request2, request1, request0 (or any
other permutation of these 5 request actions) to the terminal state
⟨wait4,0, occ4,4, wait3,4, occ3,3, wait2,3, occ2,2, wait1,2, occ1,1, wait0,1, occ0,0⟩.
This terminal state represents a deadlock with each philosopher waiting for the needed
stick to be released.
A possible solution to this problem is to make the sticks available for only one philosopher
at a time. The corresponding chopstick process is depicted in the right part of Figure 3.3.
In state availablei,j only philosopher j is allowed to pick up the ith stick. The above-
mentioned deadlock situation can be avoided by the fact that some sticks (e.g., the ﬁrst,
the third, and the ﬁfth stick) start in state availablei,i, while the remaining sticks start in
state availablei,i+1. It can be veriﬁed that this solution is deadlock- and starvation-free.

Deadlock
93
wait for
left stick
left stick
right stick
wait for
right stick
return the
return the
think
eat
reqi i
reli i
reqi 1 i
reqi 1 i
reqi i
reli 1 i
reli 1 i
reli i
availablei
occupied
occupied
reqi i
reqi i 1
reli i 1
availablei 1
reli i
Figure 3.3: Improved variant of the ith philosopher and the ith stick.
A further characteristic often required for concurrent systems is robustness against failure
of their components. In the case of the dining philosophers, robustness can be formulated
in a way that ensures deadlock and starvation freedom even if one of the philosophers is
“defective” (i.e., does not leave the think phase anymore).1 The above-sketched deadlock-
and starvation-free solution can be modiﬁed to a fault-tolerant solution by changing the
transition systems of philosophers and sticks such that philosopher i+1 can pick up the ith
stick even if philosopher i is thinking (i.e., does not need stick i) independent of whether
stick i is in state availablei,i or availablei,i+1. The corresponding is also true when the roles
of philosopher i and i+1 are reversed. This can be established by adding a single Boolean
variable xi to philosopher i (see Figure 3.4).
The variable xi informs the neighboring
philosophers about the current location of philosopher i. In the indicated sketch, xi is a
Boolean variable which is true if and only if the ith philosopher is thinking. Stick i is
made available to philosopher i if stick i is in location availablei (as before), or if stick i
is in location availablei+1 while philosopher i+1 is thinking.
Note that the above description is at the level of program graphs. The complete system is
a channel system with request and release actions standing for handshaking over a channel
of capacity 0.
1Formally, we add a loop to the transition system of a defective philosopher at state think i.

94
Linear-Time Properties
think
wait
wait
reqi i
reqi 1 i
...
...
xi :
false
xi :
true
xi :
true
availablei
occupied
occupied
reqi i
reqi i 1
availablei 1
falls xi
reqi i 1
xi 1
Figure 3.4: Fault-tolerant variant of the dining philosophers.
3.2
Linear-Time Behavior
To analyze a computer system represented by a transition system, either an action-based or
a state-based approach can be followed. The state-based approach abstracts from actions;
instead, only labels in the state sequences are taken into consideration.
In contrast,
the action-based view abstracts from states and refers only to the action labels of the
transitions.
(A combined action- and state-based view is possible, but leads to more
involved deﬁnitions and concepts. For this reason it is common practice to abstract from
either action or state labels.) Most of the existing speciﬁcation formalisms and associated
veriﬁcation methods can be formulated in a corresponding way for both perspectives.
In this chapter, we mainly focus on the state-based approach. Action labels of transitions
are only necessary for modeling communication; thus, they are of no relevance in the
following chapters. Instead, we use the atomic propositions of the states to formulate
system properties. Therefore, the veriﬁcation algorithms operate on the state graph of a
transition system, the digraph originating from a transition system by abstracting from
action labels.

Linear-Time Behavior
95
3.2.1
Paths and State Graph
Let TS = (S, Act, →, I, AP, L) be a transition system.
Deﬁnition 3.3.
State Graph
The state graph of TS, notation G(TS), is the digraph (V, E) with vertices V = S and
edges E = {(s, s′) ∈S × S | s′ ∈Post(s)}.
The state graph of transition system TS has a vertex for each state in TS and an edge
between vertices s and s′ whenever s′ is a direct successor of s in TS for some action α. It
is thus simply obtained from TS by omitting all state labels (i.e., the atomic propositions),
all transition labels (i.e., the actions), and by ignoring the fact whether a state is initial
or not. Moreover, multiple transitions (that have diﬀerent action labels) between states
are represented by a single edge. This seems to suggest that the state labels are no longer
of any use; later on, we will see how these state labels will be used to check the validity of
properties.
Let Post∗(s) denote the states that are reachable in state graph G(TS) from s. This notion
is generalized toward sets of states in the usual way (i.e., pointwise extension): for C ⊆S
let
Post∗(C) =

s∈C
Post∗(s).
The notations Pre∗(s) and Pre∗(C) have analogous meaning. The set of states that are
reachable from some initial state, notation Reach(TS), equals Post∗(I).
As explained in Chapter 2, the possible behavior of a transition system is deﬁned by an
execution fragment. Recall that an execution fragment is an alternating sequence of states
and actions. As we consider a state-based approach, the actions are not of importance and
are omitted. The resulting “runs” of a transition system are called paths. The following
deﬁnitions deﬁne path fragments, initial and maximal path fragments, and so on. These
notions are easily obtained from the same notions for executions by omitting the actions.
Deﬁnition 3.4.
Path Fragment
A ﬁnite path fragment π of TS is a ﬁnite state sequence s0 s1 . . . sn such that si ∈Post(si−1)
for all 0 < i ⩽n, where n ⩾0. An inﬁnite path fragment π is an inﬁnite state sequence
s0 s1 s2 . . . such that si ∈Post(si−1) for all i > 0.
We adopt the following notational conventions for inﬁnite path fragment π = s0 s1 . . .. The
initial state of π is denoted by ﬁrst(π) = s0. For j ⩾0, let π[j] = sj denote the jth state of

96
Linear-Time Properties
π and π[..j] denote the jth preﬁx of π, i.e., π[..j] = s0 s1 . . . sj. Similarly, the jth suﬃx of
π, notation π[j..], is deﬁned as π[j..] = sj sj+1 . . .. These notions are deﬁned analogously
for ﬁnite paths. Besides, for ﬁnite path π = s0 s1 . . . sn, let last(π) = sn denote the last
state of π, and len(π) = n denote the length of π. For inﬁnite path π these notions are
deﬁned by len(π) = ∞and last(π) = ⊥, where ⊥denotes “undeﬁned”.
Deﬁnition 3.5.
Maximal and Initial Path Fragment
A maximal path fragment is either a ﬁnite path fragment that ends in a terminal state, or
an inﬁnite path fragment. A path fragment is called initial if it starts in an initial state,
i.e., if s0 ∈I.
A maximal path fragment is a path fragment that cannot be prolonged: either it is inﬁnite
or it is ﬁnite but ends in a state from which no transition can be taken. Let Paths(s) denote
the set of maximal path fragments π with ﬁrst(π) = s, and Pathsﬁn(s) denote the set of
all ﬁnite path fragments π with ﬁrst(π) = s.
Deﬁnition 3.6.
Path
A path of transition system TS is an initial, maximal path fragment.2
Let Paths(TS) denote the set of all paths in TS, and Pathsﬁn(TS) the set of all initial,
ﬁnite path fragments of TS.
Example 3.7.
Beverage Vending Machine
Consider the beverage vending machine of Example 2.2 on page 21. For convenience, its
transition system is repeated in Figure 3.5. As the state labeling is simply L(s) = { s }
for each state s, the names of states may be used in paths (as in this example), as well as
atomic propositions (as used later on). Example path fragments of this transition system
are
π1
=
pay select soda pay select soda . . .
π2
=
select soda pay select beer . . .
π
=
pay select soda pay select soda .
These path fragments result from the execution fragments indicated in Example 2.8 on
page 25. Only π1 is a path. The inﬁnite path fragment π2 is maximal but not initial.
π is initial but not maximal since it is ﬁnite while ending in a state that has outgoing
2It is important to realize the diﬀerence between the notion of a path in a transition system and the
notion of a path in a digraph. A path in a transition system is maximal, whereas a path in a digraph in
the graph-theoretical sense is not always maximal. Besides, paths in a digraph are usually required to be
ﬁnite whereas paths in transition systems may be inﬁnite.

Linear-Time Behavior
97
pay
select
soda
beer
insert coin
τ
τ
get soda
get beer
Figure 3.5: A transition system of a simple beverage vending machine.
transitions. We have that last(π) = soda, ﬁrst(π2) = select, π1[0] = pay, π1[3] = pay,
π1[..5] = π, π[..2] = π[3..], len(π) = 5, and len(π1) = ∞.
3.2.2
Traces
Executions (as introduced in Chapter 2) are alternating sequences consisting of states
and actions.
Actions are mainly used to model the (possibility of) interaction, be it
synchronous or asynchronous communication. In the sequel, interaction is not our prime
interest, but instead we focus on the states that are visited during executions. In fact, the
states themselves are not “observable”, but just their atomic propositions. Thus, rather
than having an execution of the form s0
α0
−−→s1
α1
−−→s2 . . . we consider sequences of the
form L(s0) L(s1) L(s2) . . . that register the (set of) atomic propositions that are valid along
the execution. Such sequences are called traces.
The traces of a transition system are thus words over the alphabet 2AP. In the following
it is assumed that a transition system has no terminal states. In this case, all traces are
inﬁnite words. (Recall that the traces of a transition system have been deﬁned as traces
induced by its initial maximal path fragments. See also Appendix A.2, page 912). This
assumption is made for simplicity and does not impose any serious restriction. First of all,
prior to checking any (linear-time) property, a reachability analysis could be carried out to
determine the set of terminal states. If indeed some terminal state is encountered, the sys-
tem contains a deadlock and has to be repaired before any further analysis. Alternatively,
each transition system TS (that probably has a terminal state) can be extended such that
for each terminal state s in TS there is a new state sstop, transition s −→sstop, and sstop is
equipped with a self-loop, i.e., sstop −→sstop. The resulting “equivalent” transition system
obviously has no terminal states.3
3A further alternative is to adapt the linear-time framework for transition systems with terminal states.
The main concepts of this chapter are still applicable, but require some adaptions to distinguish nonmax-

98
Linear-Time Properties
Deﬁnition 3.8.
Trace and Trace Fragment
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states. The trace
of the inﬁnite path fragment π = s0 s1 . . . is deﬁned as trace(π) = L(s0) L(s1) . . .. The trace
of the ﬁnite path fragment π = s0 s1 . . . sn is deﬁned as trace(π) = L(s0) L(s1) . . . L(sn).
The trace of a path fragment is thus the induced ﬁnite or inﬁnite word over the alphabet
2AP, i.e., the sequence of sets of atomic propositions that are valid in the states of the
path.
The set of traces of a set Π of paths is deﬁned in the usual way:
trace(Π) = { trace(π) | π ∈Π }.
A trace of state s is the trace of an inﬁnite path fragment π with ﬁrst(π) = s. Accordingly,
a ﬁnite trace of s is the trace of a ﬁnite path fragment that starts in s. Let Traces(s) denote
the set of traces of s, and Traces(TS) the set of traces of the initial states of transition
system TS:
Traces(s) = trace(Paths(s))
and
Traces(TS) =

s∈I
Traces(s).
In a similar way, the ﬁnite traces of a state and of a transition system are deﬁned:
Tracesﬁn(s) = trace(Pathsﬁn(s))
and
Tracesﬁn(TS) =

s∈I
Tracesﬁn(s).
Example 3.9.
Semaphore-Based Mutual Exclusion
Consider the transition system TSSem as depicted in Figure 3.6. This two-process mutual
exclusion example has been described before in Example 2.24 (page 43).
Assume the available atomic propositions are crit1 and crit2, i.e.,
AP = { crit1, crit2 }.
The proposition crit1 holds in any state of the transition system TSSem where the ﬁrst
process (called P1) is in its critical section. Proposition crit2 has the same meaning for
the second process (i.e., P2).
Consider the execution in which the processes P1 and P2 enter their critical sections in
an alternating fashion. Besides, they only request to enter the critical section when the
imal and maximal ﬁnite paths.

Linear-Time Behavior
99
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 3.6: Transition system of semaphore-based mutual exclusion algorithm.
other process is no longer in its critical section. Situations in which one process is in its
critical section whereas the other is moving from the noncritical state to the waiting state
are impossible.
The path π in the state graph of TSSem where process P1 is the ﬁrst to enter its critical
section is of the form
π
=
⟨n1, n2, y = 1⟩→⟨w1, n2, y = 1⟩→⟨c1, n2, y = 0⟩→
⟨n1, n2, y = 1⟩→⟨n1, w2, y = 1⟩→⟨n1, c2, y = 0⟩→. . .
The trace of this path is the inﬁnite word:
trace(π) = ∅∅{ crit1 } ∅∅{ crit2 } ∅∅{ crit1 } ∅∅{ crit2 } . . . .
The trace of the ﬁnite path fragment
π
=
⟨n1, n2, y = 1⟩→⟨w1, n2, y = 1⟩→⟨w1, w2, y = 1⟩→
⟨w1, c2, y = 0⟩→⟨w1, n2, y = 1⟩→⟨c1, n2, y = 0⟩
is trace(π) = ∅∅∅{ crit2 } ∅{ crit1 }.

100
Linear-Time Properties
3.2.3
Linear-Time Properties
Linear-time properties specify the traces that a transition system should exhibit. Infor-
mally speaking, one could say that a linear-time property speciﬁes the admissible (or
desired) behavior of the system under consideration. In the following we provide a formal
deﬁnition of such properties. This deﬁnition is rather elementary, and gives a good basic
understanding of what a linear-time property is. In Chapter 5, a logical formalism will be
introduced that allows for the speciﬁcation of linear-time properties.
In the following, we assume a ﬁxed set of propositions AP. A linear-time (LT) property is
a requirement on the traces of a transition system. Such property can be understood as a
requirement over all words over AP, and is deﬁned as the set of words (over AP) that are
admissible:
Deﬁnition 3.10.
LT Property
A linear-time property (LT property) over the set of atomic propositions AP is a subset
of (2AP)ω.
Here, (2AP)ω denotes the set of words that arise from the inﬁnite concatenation of words
in 2AP. An LT property is thus a language (set) of inﬁnite words over the alphabet 2AP.
Note that it suﬃces to consider inﬁnite words only (and not ﬁnite words), as transition
systems without terminal states are considered. The fulﬁllment of an LT property by a
transition system is deﬁned as follows.
Deﬁnition 3.11.
Satisfaction Relation for LT Properties
Let P be an LT property over AP and TS = (S, Act, →, I, AP, L) a transition system
without terminal states. Then, TS = (S, Act, →, I, AP, L) satisﬁes P, denoted TS |= P,
iﬀTraces(TS) ⊆P. State s ∈S satisﬁes P, notation s |= P, whenever Traces(s) ⊆P.
Thus, a transition system satisﬁes the LT property P if all its traces respect P, i.e., if all
its behaviors are admissible. A state satisﬁes P whenever all traces starting in this state
fulﬁll P.
Example 3.12.
Traﬃc Lights
Consider two simpliﬁed traﬃc lights that only have two possible settings: red and green.
Let the propositions of interest be
AP = { red1, green1, red2, green2 }

Linear-Time Behavior
101
red1
green1
α
α
green2
red2
α
α
⟨red1, green2⟩
⟨green1, red2⟩
α
α
Figure 3.7: Two fully synchronized traﬃc lights (left and middle) and their parallel com-
position (right).
We consider two LT properties of these traﬃc lights and give some example words that
are contained by such properties. First, consider the property P that states:
“The ﬁrst traﬃc light is inﬁnitely often green”.
This LT property corresponds to the set of inﬁnite words of the form A0 A1 A2 . . . over
2AP, such that green1 ∈Ai holds for inﬁnitely many i.
For example, P contains the
inﬁnite words
{ red1, green2 } { green1, red2 } { red1, green2 } { green1, red2 } . . . ,
∅{ green1 } ∅{ green1 } ∅{ green1 } ∅{ green1 } ∅. . .
{ red1, green1 } { red1, green1 } { red1, green1 } { red1, green1 } . . .
and
{ green1, green2 } { green1, green2 } { green1, green2 } { green1, green2 } . . .
The inﬁnite word { red1, green1 } { red1, green1 } ∅∅∅∅. . . is not in P as it contains only
ﬁnitely many occurrences of green1.
As a second LT property, consider P ′:
“The traﬃc lights are never both green simultaneously”.
This property is formalized by the set of inﬁnite words of the form A0 A1 A2 . . . such that
either green1 /∈Ai or green2 /∈Ai, for all i ⩾0. For example, the following inﬁnite words
are in P ′:
{ red1, green2 } { green1, red2 } { red1, green2 } { green1, red2 } . . . ,
∅{ green1 } ∅{ green1 } ∅{ green1 } ∅{ green1 } ∅. . .
and
{ red1, green1 } { red1, green1 } { red1, green1 } { red1, green1 } . . . ,
whereas the inﬁnite word { red1 green2 } { green1, green2 }, . . . is not in P ′.
The traﬃc lights depicted in Figure 3.7 are at intersecting roads and their switching is
synchronized, i.e., if one light switches from red to green, the other switches from green to

102
Linear-Time Properties
red. In this way, the lights always have complementary colors. Clearly, these traﬃc lights
satisfy both P and P ′. Traﬃc lights that switch completely autonomously will neither
satisfy P—there is no guarantee that the ﬁrst traﬃc light is green inﬁnitely often—nor
P ′.
Often, an LT property does not refer to all atomic propositions occurring in a transition
system, but just to a relatively small subset thereof.
For a property P over a set of
propositions AP′ ⊆AP, only the labels in AP′ are relevant.
Let π be a ﬁnite path
fragment of TS.
We write traceAP′(π) to denote the ﬁnite trace of π where only the
atomic propositions in AP′ are considered. Accordingly, traceAP′(π) denotes the trace of
an inﬁnite path fragment π by focusing on propositions in AP′ Thus, for π = s0 s1 s2 . . .,
we have
traceAP′(π)
=
L′(s0) L′(s1) . . . = (L(s0) ∩AP′) (L(s1) ∩AP′) . . .
Let TracesAP′(TS) denote the set of traces traceAP′(Paths(TS)). Whenever the set AP′ of
atomic propositions is clear from the context, the subscript AP′ is omitted. In the rest of
this chapter, the restriction to a relevant subset of atomic propositions is often implicitly
made.
Example 3.13.
The Mutual Exclusion Property
In Chapter 2, several mutual exclusion algorithms have been considered. For specifying the
mutual exclusion property—always at most one process is in its critical section—it suﬃces
to only consider the atomic propositions crit1 and crit2. Other atomic propositions are
not of any relevance for this property. The formalization of the mutual exclusion property
is given by the LT property
Pmutex = set of inﬁnite words A0 A1 A2 . . . with { crit1, crit2 } ̸⊆Ai for all 0 ⩽i.
For example, the inﬁnite words
{ crit1 } { crit2 } { crit1 } { crit2 } { crit1 } { crit2 } . . . ,
and
{ crit1 } { crit1 } { crit1 } { crit1 } { crit1 } { crit1 } . . . ,
and
∅∅∅∅∅∅∅. . .
are all contained in Pmutex. However, this does not apply to words of the form
{ crit1 } ∅{ crit1, crit2 } . . .
The transition system TSArb = (TS1 ||| TS2) ∥Arbiter described in Example 2.28 (page 50)
fulﬁlls the mutex property, i.e.,
TSArb |= Pmutex.

Linear-Time Behavior
103
It is left to the reader to check that the mutex property is also fulﬁlled by the semaphore-
based mutual exclusion algorithm (see Figure 3.6 on page 99) and Peterson’s algorithm
(see Example 2.25 on page 45).
Example 3.14.
Starvation Freedom
Guaranteeing mutual exclusion is a signiﬁcant property of mutual exclusion algorithms,
but is not the only relevant property. An algorithm that never allows a process to enter
its critical section will do, but is certainly not intended. Besides, a property is imposed
that requires a process that wants to enter the critical section to be able to eventually do
so. This property prevents a process from waiting ad inﬁnitum and is formally speciﬁed
as the LT property Pﬁnwait = set of inﬁnite words A0 A1 A2 . . . such that
∀j.lwaiti ∈Aj ⇒∃k ⩾j.waiti ∈Ak for each i ∈{ 1, 2 }.
Here, we assumed the set of propositions to be:
AP = { wait1, crit1, wait2, crit2 }.
Property Pﬁnwait expresses that each of the two processes enters its critical section eventu-
ally if they are waiting. That is, a process has to wait some ﬁnite amount before entering
the critical section. It does not express that a process that waits often, is often entering
the critical section.
Consider the following variant. The LT property Pnostarve = set of inﬁnite words A0 A1 A2 . . .
such that:
(∀k ⩾0. ∃j ⩾k. waiti ∈Aj ) ⇒(∀k ⩾0. ∃j ⩾k. criti ∈Aj )
for each i ∈{ 1, 2 }.
In abbreviated form we write:
∞
∃j. waiti ∈Aj

⇒
∞
∃j. criti ∈Aj

for each i ∈{ 1, 2 }
where
∞
∃stands for “there are inﬁnitely many”.
Property Pnostarve expresses that each of the two processes enters its critical section in-
ﬁnitely often if they are waiting inﬁnitely often. This natural requirement is, however, not
satisﬁed for the semaphore-based solution, since
∅({ wait2 } { wait1, wait2 } { crit1, wait2 } )ω
is a possible trace of the transition system but does not belong to Pnostarve. This trace
represents an execution in which only the ﬁrst process enters its critical section inﬁnitely
often. In fact, the second process waits inﬁnitely long to enter its critical section.
It is left to the reader to check that the transition system modeling Peterson’s algorithm
(see Example 2.25, page 45) does indeed satisfy Pnostarve.

104
Linear-Time Properties
3.2.4
Trace Equivalence and Linear-Time Properties
LT properties specify the (inﬁnite) traces that a transition system should exhibit.
If
transition systems TS and TS′ have the same traces, one would expect that they satisfy
the same LT properties. Clearly, if TS |= P, then all traces of TS are contained in P, and
when Traces(TS) = Traces(TS′), the traces of TS′ are also contained in P. Otherwise,
whenever TS ̸|= P, there is a trace in Traces(TS) that is prohibited by P, i.e., not included
in the set P of traces. As Traces(TS) = Traces(TS′), also TS′ exhibits this prohibited trace,
and thus TS′ ̸|= P. The precise relationship between trace equivalence, trace inclusion,
and the satisfaction of LT properties is the subject of this section.
We start by considering trace inclusion and its importance in concurrent system design.
Trace inclusion between transition systems TS and TS′ requires that all traces exhibited
by TS can also be exhibited by TS′, i.e., Traces(TS) ⊆Traces(TS′). Note that transition
system TS′ may exhibit more traces, i.e., may have some (linear-time) behavior that TS
does not have. In stepwise system design, where designs are successively reﬁned, trace
inclusion is often viewed as an implementation relation in the sense that
Traces(TS) ⊆Traces(TS′) means TS “is a correct implementation of” TS′.
For example, let TS′ be a (more abstract) design where parallel composition is modeled by
interleaving, and TS its realization where (some of) the interleaving is resolved by means
of some scheduling mechanism. TS may thus be viewed as an “implementation” of TS′,
and clearly, Traces(TS) ⊆Traces(TS′).
What does trace inclusion have to do with LT properties? The following theorem shows
that trace inclusion is compatible with requirement speciﬁcations represented as LT prop-
erties.
Theorem 3.15.
Trace Inclusion and LT Properties
Let TS and TS′ be transition systems without terminal states and with the same set of
propositions AP. Then the following statements are equivalent:
(a) Traces(TS) ⊆Traces(TS′)
(b) For any LT property P: TS′ |= P
implies TS |= P.
Proof: (a) =⇒(b): Assume Traces(TS) ⊆Traces(TS′), and let P be an LT property such
that TS′ |= P. From Deﬁnition 3.11 it follows that Traces(TS′) ⊆P. Given Traces(TS) ⊆

Linear-Time Behavior
105
Traces(TS′), it now follows that Traces(TS) ⊆P.
By Deﬁnition 3.11 it follows that
TS |= P.
(b) =⇒(a): Assume that for all LT properties it holds that: TS′ |= P implies TS |= P.
Let P = Traces(TS′). Obviously, TS′ |= P, as Traces(TS′) ⊆Traces(TS′). By assumption,
TS |= P. Hence, Traces(TS) ⊆Traces(TS′).
This simple observation plays a decisive role for the design by means of successive re-
ﬁnement.
If TS′ is the transition system representing a preliminary design and TS
is a transition system originating from a reﬁnement of TS′ (i.e., a more detailed de-
sign), then it can immediately—without explicit proof—be concluded from the relation
Traces(TS) ⊆Traces(TS′) that any LT property that holds in TS′ also holds for TS.
Example 3.16.
Reﬁning the Semaphore-Based Mutual Exclusion Algorithm
Let TS′ = TSSem, the transition system representing the semaphore-based mutual exclu-
sion algorithm (see Figure 3.6 on page 99) and let TS be the transition system obtained
from TS′ by removing the transition
⟨wait1, wait2, y = 1⟩−→⟨wait1, crit2, y = 0⟩.
Stated in words, from the situation in which both processes are waiting, it is no longer
possible that the second process (P2) acquires access to the critical section. This thus yields
a model that assigns higher priority to process P1 than to process P2 when both processes
are competing to access the critical section. As a transition is removed, it immediately
follows that Traces(TS) ⊆Traces(TS′). Consequently, by the fact that TS′ ensures mutual
exclusion, i.e., TS′ |= Pmutex, it follows by Theorem 3.15 that TS |= Pmutex.
Transition systems are said to be trace-equivalent if they have the same set of traces:
Deﬁnition 3.17.
Trace Equivalence
Transition systems TS and TS′ are trace-equivalent with respect to the set of propositions
AP if TracesAP(TS) = TracesAP(TS′). 4
Theorem 3.15 implies equivalence of two trace-equivalent transition systems with respect
to requirements formulated as LT properties.
4Here, we assume two transition systems with sets of propositions that include AP.

106
Linear-Time Properties
Corollary 3.18.
Trace Equivalence and LT Properties
Let TS and TS′ be transition systems without terminal states and with the same set of
atomic propositions. Then:
Traces(TS) = Traces(TS′)
⇐⇒
TS and TS′ satisfy the same LT properties.
There thus does not exist an LT property that can distinguish between trace-equivalent
transition systems. Stated diﬀerently, in order to establish that the transition systems TS
and TS′ are not trace-equivalent it suﬃces to ﬁnd one LT property that holds for one but
not for the other.
Example 3.19.
Two Beverage Vending Machines
Consider the two transition systems in Figure 3.8 that both model a beverage vending
pay
select
soda
beer
τ
τ
pay
select1
select2
soda
beer
τ
τ
Figure 3.8: Two beverage vending machines.
machine. For simplicity, the observable action labels of transitions have been omitted.
Both machines are able to oﬀer soda and beer.
The left transition system models a
beverage machine that after insertion of a coin nondeterministically chooses to either
provide soda or beer. The right one, however, has two selection buttons (one for each
beverage), and after insertion of a coin, nondeterministically blocks one of the buttons. In
either case, the user has no control over the beverage obtained—the choice of beverage is
under full control of the vending machine.
Let AP = { pay, soda, beer }. Although the two vending machines behave diﬀerently, it
is not diﬃcult to see that they exhibit the same traces when considering AP, as for both
machines traces are alternating sequences of pay and either soda or beer. The vending
machines are thus trace-equivalent.
By Corollary 3.18 both vending machines satisfy
exactly the same LT properties. Stated diﬀerently, it means that there does not exist an
LT property that distinguishes between the two vending machines.

Safety Properties and Invariants
107
3.3
Safety Properties and Invariants
Safety properties are often characterized as “nothing bad should happen”. The mutual
exclusion property—always at most one process is in its critical section—is a typical safety
property. It states that the bad thing (having two or more processes in their critical section
simultaneously) never occurs. Another typical safety property is deadlock freedom. For
the dining philosophers (see Example 3.2, page 90), for example, such deadlock could be
characterized as the situation in which all philosophers are waiting to pick up the second
chopstick. This bad (i.e., unwanted) situation should never occur.
3.3.1
Invariants
In fact, the above safety properties are of a particular kind: they are invariants. Invariants
are LT properties that are given by a condition Φ for the states and require that Φ holds
for all reachable states.
Deﬁnition 3.20.
Invariant
An LT property Pinv over AP is an invariant if there is a propositional logic formula5 Φ
over AP such that
Pinv =

A0A1A2 . . . ∈(2AP)ω | ∀j ⩾0. Aj |= Φ

.
Φ is called an invariant condition (or state condition) of Pinv.
Note that
TS |= Pinv
iﬀ
trace(π) ∈Pinv for all paths π in TS
iﬀ
L(s) |= Φ for all states s that belong to a path of TS
iﬀ
L(s) |= Φ for all states s ∈Reach(TS).
Thus, the notion ”invariant” can be explained as follows: the condition Φ has to be fulﬁlled
by all initial states and satisfaction of Φ is invariant under all transitions in the reachable
fragment of the given transition system. The latter means that if Φ holds for the source
state s of a transition s
a
−→s′, then Φ holds for the target state s′ too.
Let us return to the examples of mutual exclusion and deadlock freedom for the dining
philosophers. The mutual exclusion property can be described by an invariant using the
5The basic principles of propositional logic are treated in Appendix A.3.

108
Linear-Time Properties
propositional logic formula
Φ = ¬crit1 ∨¬crit2.
For deadlock freedom of the dining philosophers, the invariant ensures that at least one
of the philosophers is not waiting to pick up the chopstick. This can be established using
the propositional formula:
Φ = ¬wait0 ∨¬wait1 ∨¬wait2 ∨¬wait3 ∨¬wait4.
Here, the proposition waiti characterizes the state(s) of philosopher i in which he is waiting
for a chopstick.
How do we check whether a transition system satisﬁes an invariant?
As checking an
invariant for the propositional formula Φ amounts to checking the validity of Φ in every
state that is reachable from some initial state, a slight modiﬁcation of standard graph
traversal algorithms like depth-ﬁrst search (DFS) or breadth-ﬁrst search (BFS) will do,
provided the given transition system TS is ﬁnite.
Algorithm 3 on page 109 summarizes the main steps for checking the invariant condition
Φ by means of a forward depth-ﬁrst search in the state graph G(TS). The notion for-
ward search means that we start from the initial states and investigate all states that are
reachable from them. If at least one state s is visited where Φ does not hold, then the
invariance induced by Φ is violated. In Algorithm 3, R stores all visited states, i.e., if
Algorithm 3 terminates, then R = Reach(TS) contains all reachable states. Furthermore,
U is a stack that organizes all states that still have to be visited, provided they are not
yet contained in R. The operations push, pop, and top are the standard operations on
stacks. The symbol ε is used to denote the empty stack. Alternatively, a backward search
could have been applied that starts with all states where Φ does not hold and calculates
(by a DFS or BFS) the set 
s∈S,s̸|=Φ Pre∗(s).
Algorithm 3 could be slightly improved by aborting the computation once a state s is
encountered that does not fulﬁll Φ. This state is a “bad” state as it makes the transition
system refute the invariant and could be returned as an error indication.
Such error
indication, however, is not very helpful.
Instead, an initial path fragment s0 s1 s2 . . . sn in which all states (except the last one)
satisfy Φ and sn ̸|= Φ would be more useful. Such a path fragment indicates a possible
behavior of the transition system that violates the invariant. Algorithm 3 can be easily
adapted such that a counterexample is provided on encountering a state that violates
Φ. To that end we exploit the (depth-ﬁrst search) stack U. When encountering sn that
violates Φ, the stack content, read from bottom to top, contains the required initial path
fragment. Algorithm 4 on page 110 thus results.

Safety Properties and Invariants
109
Algorithm 3 Na¨ıve invariant checking by forward depth-ﬁrst search
Input: ﬁnite transition system TS and propositional formula Φ
Output: true if TS satisﬁes the invariant ”always Φ”, otherwise false
set of state R := ∅;
(* the set of visited states *)
stack of state U := ε;
(* the empty stack *)
bool b := true;
(* all states in R satisfy Φ *)
for all s ∈I do
if s /∈R then
visit(s)
(* perform a dfs for each unvisited initial state *)
ﬁ
od
return b
procedure visit (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
(* mark s as reachable *)
repeat
s′ := top(U);
if Post(s′) ⊆R then
pop(U);
b := b ∧(s′ |= Φ);
(* check validity of Φ in s′ *)
else
let s′′ ∈Post(s′) \ R
push(s′′, U);
R := R ∪{ s′′ };
(* state s′′ is a new reachable state *)
ﬁ
until (U = ε)
endproc

110
Linear-Time Properties
Algorithm 4 Invariant checking by forward depth-ﬁrst search
Input: ﬁnite transition system TS and propositional formula Φ
Output: ”yes” if TS |= ”always Φ”, otherwise ”no” plus a counterexample
set of states R := ∅;
(* the set of reachable states *)
stack of states U := ε;
(* the empty stack *)
bool b := true;
(* all states in R satisfy Φ *)
while (I \ R ̸= ∅∧b) do
let s ∈I \ R;
(* choose an arbitrary initial state not in R *)
visit(s);
(* perform a DFS for each unvisited initial state *)
od
if b then
return(”yes”)
(* TS |= ”always Φ” *)
else
return(”no”, reverse(U))
(* counterexample arises from the stack content *)
ﬁ
procedure visit (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
(* mark s as reachable *)
repeat
s′ := top(U);
if Post(s′) ⊆R then
pop(U);
b := b ∧(s′ |= Φ);
(* check validity of Φ in s′ *)
else
let s′′ ∈Post(s′) \ R
push(s′′, U);
R := R ∪{ s′′ };
(* state s′′ is a new reachable state *)
ﬁ
until ((U = ε) ∨¬ b)
endproc

Safety Properties and Invariants
111
The worst-case time complexity of the proposed invariance checking algorithm is domi-
nated by the cost for the DFS that visits all reachable states. The latter is linear in the
number of states (nodes of the state graph) and transitions (edges in the state graph),
provided we are given a representation of the state graph where the direct successors
s′ ∈Post(s) for any state s can be encountered in time Θ(|Post(s)|). This holds for a
representation of the sets Post(s) by adjacency lists. An explicit representation of adja-
cency lists is not adequate in our context where the state graph of a complex system has
to be analyzed. Instead, the adjacency lists are typically given in an implicit way, e.g.,
by a syntactic description of the concurrent processes, such as program graphs or higher-
level description languages with a program graph semantics such as nanoPromela, see
Section 2.2.5, page 63). The direct successors of a state s are then obtained by the axioms
and rules for the transition relation for the composite system. Besides the space for the
syntactic descriptions of the processes, the space required by Algorithm 4 is dominated by
the representation of the set R of visited states (this is typically done by appropriate hash
techniques) and stack U. Hence, the additional space complexity of invariant checking is
linear in the number of reachable states.
Theorem 3.21.
Time Complexity of Invariant Checking
The time complexity of Algorithm 4 is O( N ∗(1+|Φ|)+M ) where N denotes the number
of reachable states, and M = 
s∈S |Post(s)| the number of transitions in the reachable
fragment of TS.
Proof: The time complexity of the forward reachability on the state graph G(TS) is
O(N + M). The time needed to check s |= Φ for some state s is linear in the length
of Φ.6
As for each state s it is checked whether Φ holds, this amounts to a total of
N + M + N ∗(1 + |Φ|) operations.
3.3.2
Safety Properties
As we have seen in the previous section, invariants can be viewed as state properties and
can be checked by considering the reachable states. Some safety properties, however, may
impose requirements on ﬁnite path fragments, and cannot be veriﬁed by considering the
reachable states only. To see this, consider the example of a cash dispenser, also known
as an automated teller machine (ATM). A natural requirement is that money can only be
withdrawn from the dispenser once a correct personal identiﬁer (PIN) has been provided.
This property is not an invariant, since it is not a state property. It is, however, considered
6To cover the special case where Φ is an atomic proposition, in which case |Φ| = 0, we deal with 1 + |Φ|
for the cost to check whether Φ holds for a given state s.

112
Linear-Time Properties
to be a safety property, as any inﬁnite run violating the requirement has a ﬁnite preﬁx
that is “bad”, i.e., in which money is withdrawn without issuing a PIN before.
Formally, safety property P is deﬁned as an LT property over AP such that any inﬁnite
word σ where P does not hold contains a bad preﬁx. The latter means a ﬁnite preﬁx σ
where the bad thing has happened, and thus no inﬁnite word that starts with this preﬁx
σ fulﬁlls P.
Deﬁnition 3.22.
Safety Properties, Bad Preﬁxes
An LT property Psafe over AP is called a safety property if for all words σ ∈(2AP)ω \Psafe
there exists a ﬁnite preﬁx σ of σ such that
Psafe ∩

σ′ ∈(2AP)ω | σ is a ﬁnite preﬁx of σ′
= ∅.
Any such ﬁnite word σ is called a bad preﬁx for Psafe. A minimal bad preﬁx for Psafe
denotes a bad preﬁx σ for Psafe for which no proper preﬁx of σ is a bad preﬁx for Psafe.
In other words, minimal bad preﬁxes are bad preﬁxes of minimal length. The set of all
bad preﬁxes for Psafe is denoted by BadPref(Psafe), the set of all minimal bad preﬁxes by
MinBadPref(Psafe).
Let us ﬁrst observe that any invariant is a safety property. For propositional formula Φ
over AP and its invariant Pinv, all ﬁnite words of the form
A0 A1 . . . An ∈(2AP)+
with A0 |= Φ, . . . , An−1 |= Φ and An ̸|= Φ constitute the minimal bad preﬁxes for
Pinv. The following two examples illustrate that there are safety properties that are not
invariants.
Example 3.23.
A Safety Property for a Traﬃc Light
We consider a speciﬁcation of a traﬃc light with the usual three phases “red”, “green”,
and “yellow”. The requirement that each red phase should be immediately preceded by a
yellow phase is a safety property but not an invariant. This is shown in the following.
Let red, yellow, and green be atomic propositions. Intuitively, they serve to mark the
states describing a red (yellow or green) phase. The property “always at least one of the
lights is on” is speciﬁed by:
{ σ = A0 A1 . . . | Aj ⊆AP ∧Aj ̸= ∅}.
The bad preﬁxes are ﬁnite words that contain ∅. A minimal bad preﬁx ends with ∅. The
property “it is never the case that two lights are switched on at the same time” is speciﬁed

Safety Properties and Invariants
113
by
{ σ = A0 A1 . . . | Aj ⊆AP ∧|Aj| ⩽1 }.
Bad preﬁxes for this property are words containing sets such as { red, green }, { red, yellow },
and so on. Minimal bad preﬁxes end with such sets.
Now let AP′ = { red, yellow }. The property “a red phase must be preceded immediately
by a yellow phase” is speciﬁed by the set of inﬁnite words σ = A0 A1 . . . with Ai ⊆
{ red, yellow } such that for all i ⩾0 we have that
red ∈Ai implies i > 0 and yellow ∈Ai−1.
The bad preﬁxes are ﬁnite words that violate this condition. An example of bad preﬁxes
that are minimal is:
∅∅{ red }
and
∅{ red }.
The following bad preﬁx is not minimal:
{ yellow } { yellow } { red } { red } ∅{ red }
since it has a proper preﬁx { yellow } { yellow } { red } { red } which is also a bad preﬁx.
The minimal bad preﬁxes of this safety property are regular in the sense that they consti-
tute a regular language. The ﬁnite automaton in Figure 3.9 accepts precisely the minimal
bad preﬁxes for the above safety property.7 Here, ¬yellow should be read as either ∅or
{ red }. Note the other properties given in this example are also regular.
s1
s0
s2
red
yellow
¬yellow
yellow
∅
Figure 3.9: A ﬁnite automaton for the minimal bad preﬁxes of a regular safety property.
Example 3.24.
A Safety Property for a Beverage Vending Machine
For a beverage vending machine, a natural requirement is that
“The number of inserted coins is always at least the number of dispensed drinks.”
7The main concepts of a ﬁnite automaton as acceptors for languages over ﬁnite words are summarized
in Section 4.1.

114
Linear-Time Properties
Using the set of propositions { pay, drink } and the obvious labeling function, this property
could be formalized by the set of inﬁnite words A0 A1 A2 . . . such that for all i ⩾0 we have
| { 0 ⩽j ⩽i | pay ∈Aj } | ⩾|{ 0 ⩽j ⩽i | drink ∈Aj } |
Bad preﬁxes for this safety property are, for example
∅{ pay } { drink } { drink }
and
∅{ pay } { drink } ∅{ pay } { drink } { drink }
It is left to the interested reader to check that both beverage vending machines from
Figure 3.8 satisfy the above safety property.
Safety properties are requirements for the ﬁnite traces which is formally stated in the
following lemma:
Lemma 3.25.
Satisfaction Relation for Safety Properties
For transition system TS without terminal states and safety property Psafe:
TS |= Psafe
if and only if Tracesﬁn(TS) ∩BadPref(Psafe) = ∅.
Proof: ”if”: By contradiction. Let Tracesﬁn(TS) ∩BadPref(Psafe) = ∅and assume that
TS ̸|= Psafe. Then, trace(π) /∈Psafe for some path π in TS. Thus, trace(π) starts with a
bad preﬁx σ for Psafe. But then, σ ∈Tracesﬁn(TS) ∩BadPref(Psafe). Contradiction.
”only if”: By contradiction.
Let TS |= Psafe and assume that σ ∈Tracesﬁn(TS) ∩
BadPref(Psafe). The ﬁnite trace σ = A1 . . . An ∈Tracesﬁn(TS) can be extended to an
inﬁnite trace σ = A1 . . . An An+1 An+2 . . . ∈Traces(TS).
Then, σ /∈Psafe and thus,
TS ̸|= Psafe.
We conclude this section with an alternative characterization of safety properties by means
of their closure.
Deﬁnition 3.26.
Preﬁx and Closure
For trace σ ∈(2AP)ω, let pref(σ) denote the set of ﬁnite preﬁxes of σ, i.e.,
pref(σ) = { σ ∈(2AP)∗| σ is a ﬁnite preﬁx of σ }.

Safety Properties and Invariants
115
that is, if σ = A0 A1 . . . then pref(σ) = {ε, A0, A0A1, A0A1A2, . . . } is an inﬁnite set of
ﬁnite words. This notion is lifted to sets of traces in the usual way. For property P over
AP:
pref(P) =

σ∈P
pref(σ).
The closure of LT property P is deﬁned by
closure(P) = {σ ∈(2AP)ω | pref(σ) ⊆pref(P)}.
For instance, for inﬁnite trace σ = ABABAB . . . (where A, B ⊆AP) we have pref(σ) =
{ ε, A, AB, ABA, ABAB, . . . } which equals the regular language given by the regular ex-
pression (AB)∗(A + ε).
The closure of an LT property P is the set of inﬁnite traces whose ﬁnite preﬁxes are also
preﬁxes of P. Stated diﬀerently, inﬁnite traces in the closure of P do not have a preﬁx
that is not a preﬁx of P itself. As we will see below, the closure is a key concept in the
characterization of safety and liveness properties.
Lemma 3.27.
Alternative Characterization of Safety Properties
Let P be an LT property over AP. Then, P is a safety property iﬀclosure(P) = P.
Proof: “if”: Let us assume that closure(P) = P. To show that P is a safety property,
we take an element σ ∈(2AP)ω \ P and show that σ starts with a bad preﬁx for P. Since
σ /∈P = closure(P) there exists a ﬁnite preﬁx σ of σ with σ /∈pref(P). By deﬁnition of
pref(P), none of the words σ′ ∈(2AP)ω where σ ∈pref(σ′) belongs to P. Hence, σ is a
bad preﬁx for P, and by deﬁnition, P is a safety property.
“only if”:
Let us assume that P is a safety property.
We have to show that P =
closure(P).
The inclusion P ⊆closure(P) holds for all LT properties.
It remains to
show that closure(P) ⊆P. We do so by contradiction. Let us assume that there is some
σ = A1 A2 . . . ∈closure(P) \ P. Since P is a safety property and σ ̸∈P, σ has a ﬁnite
preﬁx
σ = A1 . . . An ∈BadPref(P).
As σ ∈closure(P) we have σ ∈pref(σ) ⊆pref(P). Hence, there exists a word σ′ ∈P of
the form
σ′ = A1 . . . An



bad preﬁx
Bn+1 Bn+2 . . .
This contradicts the fact that P is a safety property.

116
Linear-Time Properties
3.3.3
Trace Equivalence and Safety Properties
We have seen before that there is a strong relationship between trace inclusion of transition
systems and the satisfaction of LT properties (see Theorem 3.15, page 104):
Traces(TS) ⊆Traces(TS′)
if and only if
for all LT properties P:
TS′ |= P implies TS |= P
for transition systems TS and TS′ without terminal states. Note that this result considers
all inﬁnite traces. The above thus states a relationship between inﬁnite traces of transition
systems and the validity of LT properties. When considering only ﬁnite traces instead of
inﬁnite ones, a similar connection with the validity of safety properties can be established,
as stated by the following theorem.
Theorem 3.28.
Finite Trace Inclusion and Safety Properties
Let TS and TS′ be transition systems without terminal states and with the same set of
propositions AP.
Then the following statements are equivalent:
(a) Tracesﬁn(TS) ⊆Tracesﬁn(TS′),
(b) For any safety property Psafe: TS′ |= Psafe
implies TS |= Psafe.
Proof:
(a) =⇒(b): Let us assume that Tracesﬁn(TS) ⊆Tracesﬁn(TS′) and let Psafe be a safety
property with TS′ |= Psafe. By Lemma 3.25, we have Tracesﬁn(TS′)∩BadPref(Psafe) = ∅,
and hence, Tracesﬁn(TS)∩BadPref(Psafe) = ∅. Again by Lemma 3.25, we get TS |= Psafe.
(b) =⇒(a): Assume that (b) holds. Let Psafe = closure(Traces(TS′)). Then, Psafe is a
safety property and we have TS′ |= Psafe (see Exercise 3.9, page 147). Hence, (b) yields
TS |= Psafe, i.e.,
Traces(TS) ⊆closure(Traces(TS′)).
From this, we may derive
Tracesﬁn(TS)
=
pref(Traces(TS))
⊆
pref(closure(Traces(TS′))
=
pref(Traces(TS′))
=
Tracesﬁn(TS′).
Here we use the property that for any P it holds that pref(closure(P)) = pref(P) (see
Exercise 3.10, page 147).

Safety Properties and Invariants
117
Theorem 3.28 is of relevance for the gradual design of concurrent systems. If a preliminary
design (i.e., a transition system) TS′ is reﬁned to a design TS such that
Traces(TS) ̸⊆Traces(TS′),
then the LT properties of TS′ cannot be carried over to TS. However, if the ﬁnite traces
of TS are ﬁnite traces of TS′ (which is a weaker requirement than full trace inclusion of
TS and TS′), i.e.,
Tracesﬁn(TS) ⊆Tracesﬁn(TS′),
then all safety properties that have been established for TS′ also hold for TS.
Other
requirements for TS, i.e., LT properties that fall outside the scope of safety properties,
need to be checked using diﬀerent techniques.
Corollary 3.29.
Finite Trace Equivalence and Safety Properties
Let TS and TS′ be transition systems without terminal states and with the same set AP
of atomic propositions. Then, the following statements are equivalent:
(a) Tracesﬁn(TS) = Tracesﬁn(TS′),
(b) For any safety property Psafe over AP: TS |= Psafe ⇐⇒TS′ |= Psafe.
A few remarks on the diﬀerence between ﬁnite trace inclusion and trace inclusion are in
order. Since we assume transition systems without terminal states, there is only a slight
diﬀerence between trace inclusion and ﬁnite trace inclusion. For ﬁnite transition systems
TS and TS′ without terminal states, trace inclusion and ﬁnite trace inclusion coincide.
This can be derived from the following theorem.
Theorem 3.30.
Relating Finite Trace and Trace Inclusion
Let TS and TS′ be transition systems with the same set AP of atomic propositions such
that TS has no terminal states and TS′ is ﬁnite. Then:
Traces(TS) ⊆Traces(TS′)
⇐⇒
Tracesﬁn(TS) ⊆Tracesﬁn(TS′).
Proof: The implication from left to right follows from the monotonicity of pref(·) and the
fact that Tracesﬁn(TS) = pref(Traces(TS)) for any transition system TS.
It remains to consider the proof for the implication ⇐=. Let us assume that Tracesﬁn(TS) ⊆
Tracesﬁn(TS′). As TS has no terminal states, all traces of TS are inﬁnite. Let A0A1 . . . ∈

118
Linear-Time Properties
Traces(TS). To prove that A0A1 . . . ∈Traces(TS′) we have to show that there exists a
path in TS′, say s0 s1 . . ., that generates this trace, i.e., trace(s0 s1 . . .) = A0 A1 . . ..
Any ﬁnite preﬁx A0 A1 . . . Am of the inﬁnite trace A0A1 . . . is in Tracesﬁn(TS), and as
Tracesﬁn(TS) ⊆Tracesﬁn(TS′), also in Tracesﬁn(TS′). Thus, for any natural number m,
there exists a ﬁnite path πm = sm
0 sm
1 . . . sm
m in TS′ such that
trace(πm) = L(sm
0 )L(sm
1 ) . . . L(sm
m) = A0A1 . . . Am
where L denotes the labeling function of TS′. Thus, L(sm
j ) = Aj for all 0 ⩽j ⩽m.
Although A0 . . . Am is a preﬁx of A0 . . . Am+1, it is not guaranteed that path πm is a
preﬁx of πm+1. Due to the ﬁniteness of TS′, however, there is an inﬁnite subsequence
πm0 πm1 πm2 . . . of π0 π1 π2 . . . such that πmi and πmi+1 agree on the ﬁrst i states. Thus,
πm0 πm1 πm2 . . . induces an inﬁnite path π in TS′ with the desired property.
This is formally proven using a so-called diagonalization technique. This goes as follows.
Let I0, I1, I2, . . . be an inﬁnite series of inﬁnite sets of indices (i.e., natural numbers) with
In ⊆{ m ∈IN | m ⩾n } and s0, s1, . . . be states in TS′ such that for all natural numbers
n it holds that
(1) n ⩾1 implies In−1 ⊇In,
(2) s0 s1 s2 . . . sn is an initial, ﬁnite path fragment in TS′,
(3) for all m ∈In it holds that s0 . . . sn = sm
0 . . . sm
n .
The deﬁnition of the sets In and states sn is by induction on n.
Base case (n = 0): As { sm
0 | m ∈IN } is ﬁnite (since it is a subset of the ﬁnite set of initial
states of TS′), there exists an initial state s0 in TS′ and an inﬁnite index set I0 such that
s0 = sm
0 for all m ∈I0.
Induction step n =⇒n+1. Assume that the index sets I0, . . . , In and states s0, . . . , sn are
deﬁned. Since TS′ is ﬁnite, Post(sn) is ﬁnite. Furthermore, by the induction hypothesis
sn = sm
n for all m ∈In, and thus
{ sm
n+1 | m ∈In, m ⩾n+1 } ⊆Post(sn).
Since In is inﬁnite, there exists an inﬁnite subset In+1 ⊆{ m ∈In | m ⩾n+1 } and a
state sn+1 ∈Post(sn) such that sm
n+1 = sn+1 for all m ∈In+1. It follows directly that the
above properties (1) through (3) are fulﬁlled.

Safety Properties and Invariants
119
We now consider the state sequence s0 s1 . . . in TS′. Obviously, this state sequence is a
path in TS′ satisfying trace(s0 s1 . . .) = A0 A1 . . .. Consequently, A0 A1 . . . ∈Traces(TS′).
Remark 3.31.
Image-Finite Transition Systems
The result stated in Theorem 3.30 also holds under slightly weaker conditions: it suﬃces
to require that TS has no terminal states (as in Theorem 3.30) and that TS′ is AP image-
ﬁnite (rather than being ﬁnite).
Let TS′ = (S, Act, →, I, AP, L). Then, TS′ is called AP image-ﬁnite (or brieﬂy image-
ﬁnite) if
(i) for all A ⊆AP, the set { s0 ∈I | L(s0) = A } is ﬁnite and
(ii) for all states s in TS′ and all A ⊆AP, the set of successors { s′ ∈Post(s) | L(s′) = A }
is ﬁnite.
Thus, any ﬁnite transition system is image-ﬁnite. Moreover, any transition system that is
AP-deterministic is image-ﬁnite. (Recall that AP-determinism requires { s0 ∈I | L(s0) =
A } and { s′ ∈Post(s) | L(s′) = A } to be either singletons or empty sets; see Deﬁnition
2.5, page 24.)
In fact, a careful inspection of the proof of Theorem 3.30 shows that (i) and (ii) for
TS′ are used in the construction of the index sets In and states sn.
Hence, we have
Traces(TS) ⊆Traces(TS′) iﬀTracesﬁn(TS) ⊆Tracesﬁn(TS′), provided TS has no terminal
states and TS′ is image-ﬁnite.
Trace and ﬁnite trace inclusion, however, coincide neither for inﬁnite transition systems
nor for ﬁnite ones which have terminal states.
Example 3.32.
Finite vs. Inﬁnite Transition System
Consider the transition systems sketched in Figure 3.10, where b stands for an atomic
proposition. Transition system TS (on the left) is ﬁnite, whereas TS′ (depicted on the
right) is inﬁnite and not image-ﬁnite, because of the inﬁnite branching in the initial state.
It is not diﬃcult to observe that
Traces(TS) ̸⊆Traces(TS′)
and
Tracesﬁn(TS) ⊆Tracesﬁn(TS′).
This stems from the fact that TS can take the self-loop inﬁnitely often and never reaches
a b-state, whereas TS′ does not exhibit such behavior. Moreover, any ﬁnite trace of TS is

120
Linear-Time Properties
of the form (∅)n for n ⩾0 and is also a ﬁnite trace of TS′. Consequently, LT properties of
TS′ do not carry over to TS (and those of TS may not hold for TS′). For example, the LT
property “eventually b” holds for TS′, but not for TS. Similarly, the LT property “never
b” holds for TS, but not for TS′.
Although these transition systems might seem rather artiﬁcial, this is not the case: TS
could result from an inﬁnite loop in a program, whereas TS′ could model the semantics
of a program fragment that nondeterministically chooses a natural number k and then
performs k steps.
{ b }
{ b }
{ b }
{ b }
Figure 3.10: Distinguishing trace inclusion from ﬁnite trace inclusion.
3.4
Liveness Properties
Informally speaking, safety properties specify that “something bad never happens”. For
the mutual exclusion algorithm, the “bad” thing is that more than one process is in its
critical section, while for the traﬃc light the “bad” situation is whenever a red light phase
is not preceded by a yellow light phase. An algorithm can easily fulﬁll a safety property
by simply doing nothing as this will never lead to a “bad” situation. As this is usually
undesired, safety properties are complemented by properties that require some progress.
Such properties are called “liveness” properties (or sometimes “progress” properties). In-
tuitively, they state that ”something good” will happen in the future. Whereas safety
properties are violated in ﬁnite time, i.e., by a ﬁnite system run, liveness properties are
violated in inﬁnite time, i.e., by inﬁnite system runs.

Liveness Properties
121
3.4.1
Liveness Properties
Several (nonequivalent) notions of liveness properties have been deﬁned in the literature.
We follow here the approach of Alpern and Schneider [5, 6, 7]. They provided a formal
notion of liveness properties which relies on the view that liveness properties do not con-
strain the ﬁnite behaviors, but require a certain condition on the inﬁnite behaviors. A
typical example for a liveness property is the requirement that certain events occur in-
ﬁnitely often. In this sense, the ”good event” of a liveness property is a condition on the
inﬁnite behaviors, while the ”bad event” for a safety property occurs in a ﬁnite amount
of time, if it occurs at all.
In our approach, a liveness property (over AP) is deﬁned as an LT property that does not
rule out any preﬁx. This entails that the set of ﬁnite traces of a system are of no use at
all to decide whether a liveness property holds or not. Intuitively speaking, it means that
any ﬁnite preﬁx can be extended such that the resulting inﬁnite trace satisﬁes the liveness
property under consideration. This is in contrast to safety properties where it suﬃces to
have one ﬁnite trace (the “bad preﬁx”) to conclude that a safety property is refuted.
Deﬁnition 3.33.
Liveness Property
LT property Plive over AP is a liveness property whenever pref(Plive) = (2AP)∗.
Thus, a liveness property (over AP) is an LT property P such that each ﬁnite word can be
extended to an inﬁnite word that satisﬁes P. Stated diﬀerently, P is a liveness property
if and only if for all ﬁnite words w ∈(2AP)∗there exists an inﬁnite word σ ∈(2AP)ω
satisfying wσ ∈P.
Example 3.34.
Repeated Eventually and Starvation Freedom
In the context of mutual exclusion algorithms the natural safety property that is required
ensures the mutual exclusion property stating that the processes are never simultaneously
in their critical sections. (This is even an invariant.) Typical liveness properties that are
desired assert that
• (eventually) each process will eventually enter its critical section;
• (repeated eventually) each process will enter its critical section inﬁnitely often;
• (starvation freedom) each waiting process will eventually enter its critical section.
Let’s see how these liveness properties are formalized as LT properties and let us check that

122
Linear-Time Properties
they are liveness properties. As in Example 3.14, we will deal with the atomic propositions
wait1, crit1, wait2, crit2 where waiti characterizes the states where process Pi has requested
access to its critical section and is in its waiting phase, while criti serves as a label for
the states where Pi has entered its critical section. We now formalize the three properties
by LT properties over AP = {wait1, crit1, wait2, crit2}. The ﬁrst property (eventually)
consists of all inﬁnite words A0 A1 . . . with Aj ⊆AP such that
(∃j ⩾0. crit1 ∈Aj) ∧(∃j ⩾0. crit2 ∈Aj)
which requires that P1 and P2 are in their critical sections at least once.
The second
property (repeated eventually) poses the condition
(∀k ⩾0. ∃j ⩾k. crit1 ∈Aj) ∧(∀k ⩾0. ∃j ⩾k. crit2 ∈Aj)
stating that P1 and P2 are inﬁnitely often in their critical sections. This formula is often
abbreviated by
∞
∃j ⩾0. crit1 ∈Aj

∧
∞
∃j ⩾0. crit2 ∈Aj

.
The third property (starvation freedom) requires that
∀j ⩾0. (wait1 ∈Aj ⇒(∃k > j. crit1 ∈Ak)) ∧
∀j ⩾0. (wait2 ∈Aj ⇒(∃k > j. crit2 ∈Ak)) .
It expresses that each process that is waiting will acquire access to the critical section
at some later time point. Note that here we implicitly assume that a process that starts
waiting to acquire access to the critical section does not “give up” waiting, i.e., it continues
waiting until it is granted access.
All aforementioned properties are liveness properties, as any ﬁnite word over AP is a preﬁx
of an inﬁnite word where the corresponding condition holds. For instance, for starvation
freedom, a ﬁnite trace in which a process is waiting but never acquires access to its critical
section can always be extended to an inﬁnite trace that satisﬁes the starvation freedom
property (by, e.g., providing access in an strictly alternating fashion from a certain point
on).
3.4.2
Safety vs. Liveness Properties
This section studies the relationship between liveness and safety properties. In particular,
it provides answers to the following questions:
• Are safety and liveness properties disjoint?, and

Liveness Properties
123
• Is any linear-time property a safety or liveness property?
As we will see, the ﬁrst question will be answered aﬃrmatively while the second question
will result in a negative answer. Interestingly enough, though, for any LT property P an
equivalent LT property P ′ does exist which is a combination (i.e., intersection) of a safety
and a liveness property. All in all, one could say that the identiﬁcation of safety and
liveness properties thus provides an essential characterization of linear-time properties.
The ﬁrst result states that safety and liveness properties are indeed almost disjoint. More
precisely, it states that the only property that is both a safety and a liveness property is
nonrestrictive, i.e., allows all possible behaviors. Logically speaking, this is the equivalent
of “true”.
Lemma 3.35.
Intersection of Safety and Liveness Properties
The only LT property over AP that is both a safety and a liveness property is (2AP)ω.
Proof: Assume P is a liveness property over AP. By deﬁnition, pref(P) = (2AP)∗. It
follows that closure(P) = (2AP)ω. If P is a safety property too, closure(P) = P, and
hence P = (2AP)ω.
Recall that the closure of property P (over AP) is the set of inﬁnite words (over 2AP)
for which all preﬁxes are also preﬁxes of P. In order to show that an LT property can
be considered as a conjunction of a liveness and a safety property, the following result is
helpful. It states that the closure of the union of two properties equals the union of their
closures.
Lemma 3.36.
Distributivity of Union over Closure
For any LT properties P and P ′:
closure(P) ∪closure(P ′) = closure(P ∪P ′).
Proof: ⊆: As P ⊆P ′ implies closure(P) ⊆closure(P ′), we have P ⊆P ∪P ′ implies
closure(P) ⊆closure(P ∪P ′). In a similar way it follows that closure(P ′) ⊆closure(P ∪P ′).
Thus, closure(P) ∪closure(P ′) ⊆closure(P ∪P ′).
⊇: Let σ ∈closure(P ∪P ′). By deﬁnition of closure, pref(σ) ⊆pref(P ∪P ′). As pref(P ∪
P ′) = pref(P) ∪pref(P ′), any ﬁnite preﬁx of σ is in pref(P) or in pref(P ′) (or in both).

124
Linear-Time Properties
As σ ∈(2AP)ω, σ has inﬁnitely many preﬁxes.
Thus, inﬁnitely many ﬁnite preﬁxes
of σ belong to pref(P) or to pref(P ′) (or to both). W.l.o.g., assume pref(σ) ∩pref(P)
to be inﬁnite.
Then pref(σ) ⊆pref(P), which yields σ ∈closure(P), and thus σ ∈
closure(P)∪closure(P ′). The fact that pref(σ) ⊆pref(P) can be shown by contraposition.
Assume σ ∈pref(σ) \ pref(P). Let |σ| = k. As pref(σ) ∩pref(P) is inﬁnite, there exists
σ′ ∈pref(σ) ∩pref(P) with length larger than k. But then, there exists σ′ ∈P with
σ′ ∈pref(σ′). It then follows that σ ∈pref(σ′) (as both σ and σ′ are preﬁxes of σ) and as
pref( σ′) ⊆pref(P), it follows that σ ∈pref(P). This contradicts σ ∈pref(σ) \ pref(P).
Consider the beverage vending machine of Figure 3.5 (on page 97), and the following
property:
“the machine provides beer inﬁnitely often
after initially providing soda three times in a row”
In fact, this property consists of two parts.
On the one hand, it requires beer to be
provided inﬁnitely often. As any ﬁnite trace can be extended to an inﬁnite trace that
enjoys this property it is a liveness property. On the other hand, the ﬁrst three drinks it
provides should all be soda. This is a safety property, since any ﬁnite trace in which one
of the ﬁrst three drinks provided is beer violates it. The property is thus a combination
(in fact, a conjunction) of a safety and a liveness property. The following result shows
that every LT property can be decomposed in this way.
Theorem 3.37.
Decomposition Theorem
For any LT property P over AP there exists a safety property Psafe and a liveness property
Plive (both over AP) such that
P = Psafe ∩Plive.
Proof: Let P be an LT property over AP. It is easy to see that P ⊆closure(P). Thus:
P = closure(P) ∩P, which by set calculus can be rewritten into:
P = closure(P)



=Psafe
∩

P ∪

(2AP)ω \ closure(P)




=Plive
By deﬁnition, Psafe = closure(P) is a safety property. It remains to prove that Plive =
P ∪

(2AP)ω \ closure(P)

is a liveness property. By deﬁnition, Plive is a liveness property
whenever pref(Plive) = (2AP)∗. This is equivalent to closure(Plive) = (2AP)ω. As for any

Liveness Properties
125
LT property P, closure(P) ⊆(2AP)ω holds true, it suﬃces to showing that (2AP)ω ⊆
closure(Plive). This goes as follows:
closure(Plive)
=
closure

P ∪((2AP)ω \ closure(P))

Lemma 3.36
=
closure(P) ∪closure

(2AP)ω \ closure(P)

⊇
closure(P) ∪

(2AP)ω \ closure(P)

=
(2AP)ω
where in the one-but-last step in the derivation, we exploit the fact that closure(P ′) ⊇P ′
for all LT properties P ′.
The proof of Theorem 3.37 shows that Psafe = closure(P) is a safety property and
Plive = P ∪((2AP)ω \ closure(P)) a liveness property with P = Psafe ∩Plive. In fact,
this decomposition is the ”sharpest” one for P since Psafe is the strongest safety property
and Plive the weakest liveness property that can serve for a decomposition of P:
Lemma 3.38.
Sharpest Decomposition
Let P be an LT property and P = Psafe ∩Plive where Psafe is a safety property and Plive
a liveness property. We then have
1. closure(P) ⊆Psafe,
2. Plive ⊆P ∪((2AP)ω \ closure(P)).
Proof: See Exercise 3.12, page 147.
A summary of the classiﬁcation of LT properties is depicted as a Venn diagram in Fig-
ure 3.11. The circle denotes the set of all LT properties over a given set of atomic propo-
sitions.
Remark 3.39.
Topological Characterizations of Safety and Liveness
Let us conclude this section with a remark for readers who are familiar with basic notions
of topological spaces. The set (2AP)ω can be equipped with the distance function given by
d(σ1, σ2) = 1/2n if σ1, σ2 are two distinct inﬁnite words σ1 = A1A2 . . . and σ2 = B1B2 . . .
and n is the length of the longest common preﬁx. Moreover, we put d(σ, σ) = 0. Then,
d is a metric on (2AP)ω, and hence induces a topology on (2AP)ω. Under this topology,

126
Linear-Time Properties
liveness properties
neither liveness
nor safety properties
invariants
safety properties
safety and liveness property
(2AP)ω
Figure 3.11: Classiﬁcation of linear-time properties.
the safety properties are exactly the closed sets, while the liveness properties agree with
the dense sets. In fact, closure(P) is the topological closure of P, i.e., the smallest closed
set that contains P. The result stated in Theorem 3.37 then follows from the well-known
fact that any subset of a topological space (of the kind described above) can be written
as the intersection of its closure and a dense set.
3.5
Fairness
An important aspect of reactive systems is fairness. Fairness assumptions rule out inﬁnite
behaviors that are considered unrealistic, and are often necessary to establish liveness
properties. We illustrate the concept of fairness by means of a frequently encountered
problem in concurrent systems.
Example 3.40.
Process Fairness
Consider N processes P1, . . . , PN which require a certain service.
There is one server
process Server that is expected to provide services to these processes. A possible strategy
that Server can realize is the following. Check the processes starting with P1, then P2,
and so on, and serve the ﬁrst thus encountered process that requires service. On ﬁnishing
serving this process, repeat this selection procedure once again starting with checking P1.

Fairness
127
Now suppose that P1 is continuously requesting service. Then this strategy will result
in Server always serving P1.
Since in this way another process has to wait inﬁnitely
long before being served, this is called an unfair strategy. In a fair serving strategy it is
required that the server eventually responds to any request by any one of the processes.
For instance, a round-robin scheduling strategy where each process is only served for a
limited amount of time is a fair strategy: after having served one process, the next (in the
round-robin order) is checked and, if needed, served.
When verifying concurrent systems one is often only interested in paths in which enabled
transitions (statements) are executed in some “fair” manner. Consider, for instance, a
mutual exclusion algorithm for two processes. In order to prove starvation freedom, the
situation in which a process that wants to enter its critical section has to wait inﬁnitely
long, we want to exclude those paths in which the competitor process is always being
selected for execution. This type of fairness is also known as process fairness, since it
concerns the fair scheduling of the execution of processes. If we were to consider unfair
paths when proving starvation freedom, we would usually fail, since there always exists an
unfair strategy according to which some process is always neglected, and thus can never
make progress. One might argue that such unfair strategy is unrealistic and should be
avoided.
Example 3.41.
Starvation Freedom
Consider the transition systems TSSem and TSPet for the semaphore-based mutual exclu-
sion algorithms (see Example 2.24 on page 43) and Peterson’s algorithm. The starvation
freedom property
“Once access is requested, a process does not have to wait inﬁnitely long before
acquiring access to its critical section”
is violated by transition system TSSem while it permits only one of the processes to pro-
ceed, while the other process is starving (or only acquiring access to the critical section
ﬁnitely often). The transition system TSPet for Peterson’s algorithm, however, fulﬁlls this
property.
The property
“Each of the processes is inﬁnitely often in its critical section”
is violated by both transition systems as none of them excludes the fact that a process
would never (or only ﬁnitely often) request to enter the critical section.

128
Linear-Time Properties
Process fairness is a particular form of fairness. In general, fairness assumptions are needed
to prove liveness or other properties stating that the system makes some progress (“some-
thing good will eventually happen”). This is of vital importance if the transition system to
be checked contains nondeterminism. Fairness is then concerned with resolving nondeter-
minism in such a way that it is not biased to consistently ignore a possible option. In the
above example, the scheduling of processes is nondeterministic: the choice of the next pro-
cess to be executed (if there are at least two processes that can be potentially selected) is
arbitrary. Another prominent example where fairness is used to “resolve” nondeterminism
is in modeling concurrent processes by means of interleaving. Interleaving is equivalent to
modeling the concurrent execution of two independent processes by enumerating all the
possible orders in which activities of the processes can be executed (see Chapter 2).
Example 3.42.
Independent Traﬃc Lights
Consider the transition system
TS = TrLight1 ||| TrLight2
for the two independent traﬃc lights described in Example 2.17 (page 36). The liveness
property
“Both traﬃc lights are inﬁnitely often green”
is not satisﬁed, since
{ red1, red2 } { green1, red2 } { red1, red2 } { green1, red2 } . . .
is a trace of TS where only the ﬁrst traﬃc light is inﬁnitely often green.
What is wrong with the above examples? In fact, nothing. Let us explain this. In the
traﬃc light example, the information whether each traﬃc light switches color inﬁnitely
often is lost by means of interleaving. The trace in which only the ﬁrst traﬃc light is
acting while the second light seems to be completely stopped is formally a trace of the
transition system TrLight1 ||| TrLight2. However, it does not represent a realistic behavior
as in practice no traﬃc light is inﬁnitely faster than another.
For the semaphore-based mutual exclusion algorithm, the diﬃculty is the degree of ab-
straction. A semaphore is not a willful individual that arbitrarily chooses a process which
is authorized to enter its critical section. Instead, the waiting processes are administered
in a queue (or another “fair” medium). The required liveness can be proven in one of the
following reﬁnement steps, in which the speciﬁcation of the behavior of the semaphore is
suﬃciently detailed.

Fairness
129
3.5.1
Fairness Constraints
The above considerations show that we—to obtain a realistic picture of the behavior of a
parallel system modeled by a transition system—need a more alleviated form of satisfaction
relation for LT properties, which implies an “adequate” resolution of the nondeterministic
decisions in a transition system. In order to rule out the unrealistic computations, fairness
constraints are imposed.
In general, a fair execution (or trace) is characterized by the fact that certain fairness
constraints are fulﬁlled. Fairness constraints are used to rule out computations that are
considered to be unreasonable for the system under consideration. Fairness constraints
come in diﬀerent ﬂavors:
• Unconditional fairness: e.g.,“Every process gets its turn inﬁnitely often.”
• Strong fairness: e.g., “Every process that is enabled inﬁnitely often gets its turn
inﬁnitely often.”
• Weak fairness: e.g., “Every process that is continuously enabled from a certain time
instant on gets its turn inﬁnitely often.”
Here, the term “is enabled” has to be understood in the sense of “ready to execute (a
transition)”. Similarly, “gets its turn” stands for the execution of an arbitrary transition.
This can, for example, be a noncritical action, acquiring a shared resource, an action in
the critical section, or a communication action.
An execution fragment is unconditionally fair with respect to, e.g., “a process enters its
critical section” or “a process gets its turn”, if these properties hold inﬁnitely often. That
is to say, a process enters its critical section inﬁnitely often, or, in the second example,
a process gets its turn inﬁnitely often.
Note that no condition (such as “a process is
enabled”) is expressed that constrains the circumstances under which a process gets its
turn inﬁnitely often. Unconditional fairness is sometimes referred to as impartiality.
Strong fairness means that if an activity is inﬁnitely often enabled—but not necessarily
always, i.e., there may be ﬁnite periods during which the activity is not enabled—then it
will be executed inﬁnitely often. An execution fragment is strongly fair with respect to
activity α if it is not the case that α is inﬁnitely often enabled without being taken beyond
a certain point. Strong fairness is sometimes referred to as compassion.
Weak fairness means that if an activity, e.g., a transition in a process or an entire pro-
cess itself, is continuously enabled—no periods are allowed in which the activity is not

130
Linear-Time Properties
enabled—then it has to be executed inﬁnitely often. An execution fragment is weakly fair
with respect to some activity, α say, if it is not the case that α is always enabled beyond
some point without being taken beyond this point. Weak fairness is sometimes referred
to as justice.
How to express these fairness constraints? There are diﬀerent ways to formulate fairness
requirements. In the sequel, we adopt the action-based view and deﬁne strong fairness for
(sets of) actions. (In Chapter 5, also state-based notions of fairness will be introduced and
the relationship between action-based and state-based fairness is studied in detail.) Let A
be a set of actions. The execution fragment ρ is said to be strongly A-fair if the actions in
A are not continuously ignored under the circumstance that they can be executed inﬁnitely
often. ρ is unconditionally A-fair if some action in A is inﬁnitely often executed in ρ. Weak
fairness is deﬁned in a similar way as strong fairness (see below).
In order to formulate these fairness notions formally, the following auxiliary notion is
convenient. For state s, let Act(s) denote the set of actions that are executable in state
s, that is,
Act(s) = {α ∈Act | ∃s′ ∈S. s
α
−−→s′ }.
Deﬁnition 3.43.
Unconditional, Strong, and Weak Fairness
For transition system TS = (S, Act, →, I, AP, L) without terminal states, A ⊆Act, and
inﬁnite execution fragment ρ = s0
α0
−−→s1
α1
−−→. . . of TS:
1. ρ is unconditionally A-fair whenever
∞
∃j. αj ∈A.
2. ρ is strongly A-fair whenever
 ∞
∃j. Act(sj) ∩A ̸= ∅

=⇒
 ∞
∃j. αj ∈A

.
3. ρ is weakly A-fair whenever
 ∞
∀j. Act(sj) ∩A ̸= ∅

=⇒
 ∞
∃j. αj ∈A

.
Here,
∞
∃j stands for “there are inﬁnitely many j” and
∞
∀j for “for nearly all j” in the
sense of “for all, except for ﬁnitely many j”. The variable j, of course, ranges over the
natural numbers.

Fairness
131
To check whether a run is unconditionally A-fair it suﬃces to consider the actions that
occur along the execution, i.e., it is not necessary to check which actions in A are enabled
in visited states. However, in order to decide whether a given execution is strongly or
weakly A-fair, it does not suﬃce to only consider the actions actually occurring in the
execution. Instead, also the enabled actions in all visited states need to be considered.
These enabled actions are possible in the visited states, but do not necessarily have to be
taken along the considered execution.
Example 3.44.
A Simple Shared-Variable Concurrent Program
Consider the following two processes that run in parallel and share an integer variable x
that initially has value 0:
proc Inc
=
while ⟨x ⩾0 do x := x + 1 ⟩od
proc Reset
=
x := −1
The pair of brackets ⟨. . .⟩embraces an atomic section, i.e., process Inc performs the check
whether x is positive and the increment of x (if the guard holds) as one atomic step. Does
this parallel program terminate? When no fairness constraints are imposed, it is possible
that process Inc is permanently executing, i.e., process Reset never gets its turn, and the
assignment x = −1 is not executed. In this case, termination is thus not guaranteed, and
the property is refuted. If, however, we require unconditional process fairness, then every
process gets its turn, and termination is guaranteed.
An important question now is: given a veriﬁcation problem, which fairness notion to
use? Unfortunately, there is no clear answer to this question. Diﬀerent forms of fairness
do exist—the above is just a small, though important, fragment of all possible fairness
notions—and there is no single favorite notion. For veriﬁcation purposes, fairness con-
straints are crucial, though. Recall that the purpose of fairness constraints is to rule out
certain “unreasonable” computations.
If the fairness constraint is too strong, relevant
computations may not be considered. In case a property is satisﬁed (for a transition sys-
tem), it might well be the case that some reasonable computation that is not considered
(as it is ruled out by the fairness constraint) refutes this property. On the other hand,
if the fairness constraint is too weak, we may fail to prove a certain property as some
unreasonable computations (that are not ruled out) refute it.
The relationship between the diﬀerent fairness notions is as follows. Each unconditionally
A-fair execution fragment is strongly A-fair, and each strongly A-fair execution fragment
is weakly A-fair. In general, the reverse direction does not hold. For instance, an execution
fragment that solely visits states in which no A-actions are possible is strongly A-fair (as
the premise of strong A-fairness does not hold), but not unconditionally A-fair. Besides,

132
Linear-Time Properties
an execution fragment that only visits ﬁnitely many states in which some A-actions are
enabled but never executes an A-action is weakly A-fair (as the premise of weak A-fairness
does not hold), but not strongly A-fair. Summarizing, we have
unconditional A-fairness =⇒strong A-fairness =⇒weak A-fairness
where the reverse implication in general does not hold.
Example 3.45.
Fair Execution Fragments
Consider the transition system TSSem for the semaphore-based mutual exclusion solution.
We label the transitions with the actions reqi, enteri (for i=1, 2), and rel in the obvious
way, see Figure 3.12.
In the execution fragment
⟨n1, n2, y = 1⟩req1
−−−−→⟨w1, n2, y = 1⟩enter1
−−−−−→⟨c1, n2, y = 0⟩rel
−−−→⟨n1, n2, y = 1⟩req1
−−−−→. . .
only the ﬁrst process gets its turn. This execution fragment is indicated by the dashed
arrows in Figure 3.12. It is not unconditionally fair for the set of actions
A = { enter2 }.
It is, however, strongly A-fair, since no state is visited in which the action enter2 is
executable, and hence the premise of strong fairness is vacuously false. In the alternative
execution fragment
⟨n1, n2, y = 1⟩req2
−−−−→⟨n1, w2, y = 1⟩req1
−−−−→⟨w1, w2, y = 1⟩enter1
−−−−−→
⟨c1, w2, y = 0⟩rel
−−−→⟨n1, w2, y = 1⟩req1
−−−−→. . .
the second process requests to enter its critical section but is ignored forever. This ex-
ecution fragment is indicated by the dotted arrows in Figure 3.12.
It is not strongly
A-fair: although the action enter2 is inﬁnitely often enabled (viz. every time when visiting
the state ⟨w1, w2, y = 1⟩or ⟨n1, w2, y = 1⟩), it is never taken.
It is, however, weakly
A-fair, since the action enter2 is not continuously enabled—it is not enabled in the state
⟨c1, w2, y = 0⟩.
A fairness constraint imposes a requirement on all actions in a set A. In order to enable
diﬀerent fairness constraints to be imposed on diﬀerent, possibly nondisjoint, sets of ac-
tions, fairness assumptions are used. A fairness assumption for a transition system may
require diﬀerent notions of fairness with respect to several sets of actions.

Fairness
133
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
req1
req2
enter1
req2
req1
enter2
req2
enter1
enter2
req1
rel
rel
rel
rel
Figure 3.12: Two examples of fair execution fragments of the semaphore-based mutual
exclusion algorithm.
Deﬁnition 3.46.
Fairness Assumption
A fairness assumption for Act is a triple
F = (Fucond, Fstrong, Fweak)
with Fucond, Fstrong, Fweak ⊆2Act. Execution ρ is F-fair if
• it is unconditionally A-fair for all A ∈Fucond,
• it is strongly A-fair for all A ∈Fstrong, and
• it is weakly A-fair for all A ∈Fweak.
If the set F is clear from the context, we use the term fair instead of F-fair.
Intuitively speaking, a fairness assumption is a triple of sets of (typically diﬀerent) action
sets, one such set of action sets is treated in a strongly fair manner, one in a weakly fair
manner, and one in an unconditionally fair way. This is a rather general deﬁnition that
allows imposing diﬀerent fairness constraints on diﬀerent sets of actions. Quite often, only
a single type of fairness constraint suﬃces. In the sequel, we use the casual notations
for these fairness assumptions. For F ⊆2Act, a strong fairness assumption denotes the
fairness assumption (∅, F, ∅). Weak, and unconditional fairness assumptions are used in
a similar way.

134
Linear-Time Properties
The notion of F-fairness as deﬁned on execution fragments is lifted to traces and paths
in the obvious way. An inﬁnite trace σ is F-fair if there is an F-fair execution ρ with
trace(ρ) = σ. F-fair (inﬁnite) path fragments and F-fair paths are deﬁned analogously.
Let FairPathsF(s) denote the set of F-paths of s (i.e., inﬁnite F-fair path fragments that
start in state s), and FairPathsF(TS) the set of F-fair paths that start in some initial
state of TS.
Let FairTracesF(s) denote the set of F-fair traces of s, and FairTracesF(TS)
the set of F-fair traces of the initial states of transition system TS:
FairTracesF(s)
=
trace(FairPathsF(s))
and
FairTracesF(TS)
=

s∈I
FairTracesF(s).
Note that it does not make much sense to deﬁne these notions for ﬁnite traces as any ﬁnite
trace is fair by default.
Example 3.47.
Mutual Exclusion Again
Consider the following fairness requirement for two-process mutual exclusion algorithms:
“process Pi acquires access to its critical section inﬁnitely often”
for any i ∈{ 1, 2 }.
What kind of fairness assumption is appropriate to achieve this?
Assume each process Pi has three states ni (noncritical), wi (waiting), and ci (critical).
As before, the actions reqi, enteri, and rel are used to model the request to enter the
critical section, the entering itself, and the release of the critical section. The strong-
fairness assumption
{ {enter1, enter2} }
ensures that one of the actions enter1 or enter2, is executed inﬁnitely often. A behavior
in which one of the processes gets access to the critical section inﬁnitely often while the
other gets access only ﬁnitely many times is strongly fair with respect to this assumption.
This is, however, not intended. The strong-fairness assumption
{ { enter1 }, { enter2 } }
indeed realizes the above requirement. This assumption should be viewed as a requirement
on how to resolve the contention when both processes are awaiting to get access to the
critical section.
Fairness assumptions can be veriﬁable properties whenever all inﬁnite execution fragments
are fair. For example, it can be veriﬁed that the transition system for Peterson’s algorithm

Fairness
135
satisﬁes the strong-fairness assumption
Fstrong = { { enter1 }, { enter2 } }.
But in many cases it is necessary to assume the validity of the fairness conditions to verify
liveness properties.
A transition system TS satisﬁes the LT property P under fairness assumption F if all
F-fair paths fulﬁll the property P. However, no requirements whatsoever are imposed on
the unfair paths. This is formalized as follows.
Deﬁnition 3.48.
Fair Satisfaction Relation for LT Properties
Let P be an LT property over AP and F a fairness assumption over Act. Transition
system TS = (S, Act, →, I, AP, L) fairly satisﬁes P, notation TS |=F P, if and only if
FairTracesF(TS) ⊆P.
For a transition system that satisﬁes the fairness assumption F (i.e., all paths are F-fair),
the satisfaction relation |= without fairness assumptions (see Deﬁnition 3.11, page 100)
corresponds with the fair satisfaction relation |=F. In this case, the fairness assumption
does not rule out any trace. However, in case a transition system has traces that are not
F-fair, then in general we are confronted with a situation
TS |=F P
whereas
TS ̸|= P.
By restricting the validity of a property to the set of fair paths, the veriﬁcation can be
restricted to “realistic” executions.
Before turning to some examples, a few words on the relationship between unconditional,
strong, and weak fairness are (again) in order. As indicated before, we have that the set
of unconditional A-fair executions is a subset of all strong A-fair executions. In a similar
way, the latter set of executions is a subset of all weak A-fair executions. Stated diﬀer-
ently, unconditional fairness rules out more behaviors than strong fairness, and strong
excludes more behaviors than weak fairness.
For F = { A1, . . . , Ak }, let fairness as-
sumption Fucond = (F, ∅, ∅), Fstrong = (∅, F, ∅), and Fweak = (∅, ∅, F). Then for any
transition system TS and LT property P it follows that:
TS |=Fweak P ⇒TS |=Fstrong P ⇒TS |=Fucond P.

136
Linear-Time Properties
Example 3.49.
Independent Traﬃc Lights
Consider again the independent traﬃc lights. Let action switch2green denote the switching
to green. Similarly switch2red denotes the switching to red. The fairness assumption
F = { { switch2green1, switch2red1 }, { switch2green2, switch2red2 } }
expresses that both traﬃc lights inﬁnitely often switch color. In this case, it is irrelevant
whether strong, weak, or unconditional fairness is required.
Note that in this example F is not a veriﬁable system property (as it is not guaranteed
to hold), but a natural property which is satisﬁed for a practical implementation of the
system (with two independent processors). Obviously,
TrLight1 ||| TrLight2 |=F “each traﬃc light is green inﬁnitely often”
while the corresponding proposition for the nonfair relation |= is refuted.
Example 3.50.
Fairness for Mutual Exclusion Algorithms
Consider again the semaphore-based mutual exclusion algorithm, and assume the fairness
assumption F consists of
Fweak = {{ req1 }, { req2 }}
and
Fstrong = {{ enter1 }, { enter2 }}
and Fucond = ∅. The strong fairness constraint requires each process to enter its critical
section inﬁnitely often when it inﬁnitely often gets the opportunity to do so. This does not
forbid a process to never leave its noncritical section. To avoid this unrealistic scenario,
the weak fairness constraint requires that any process inﬁnitely often requests to enter
the critical section. In order to do so, each process has to leave the noncritical section
inﬁnitely often. It follows that TSSem |=F
P where P stands for the property “every
process enters its critical section inﬁnitely often”.
Weak fairness is suﬃcient for request actions, as such actions are not critical: if reqi is
executable in (global) state s, then it is executable in all direct successor states of s that
are reached by an action that diﬀers from reqi.
Peterson’s algorithm satisﬁes the strong fairness property
“Every process that requests access to the critical section
will eventually be able to do so”.
We can, however, not ensure that a process will ever leave its noncritical section and
request the critical section. That is, the property P is refuted. This can be “repaired”
by imposing the weak fairness constraint Fweak
=
{ { req1 }, { req2 } }. We now have
TSPet |=Fweak P.

Fairness
137
3.5.2
Fairness Strategies
The examples in the previous section indicate that fairness assumptions may be necessary
to verify liveness properties of transition system TS. In order to rule out the “unrealistic”
computations, fairness assumptions are imposed on the traces of TS, and it is checked
whether TS |=F P as opposed to checking TS |= P (without fairness). Which fairness as-
sumptions are appropriate to check P? Many model-checking tools provide the possibility
to work with built-in fairness assumptions. Roughly speaking, the intention is to rule out
executions that cannot occur in a realistic implementation. But what does that exactly
mean? In order to give some insight into this, we consider several fairness assumptions for
synchronizing concurrent systems. The aim is to establish a fair communication mecha-
nism between the various processes involved. A rule of thumb is: Strong fairness is needed
to obtain an adequate resolution of contentions (between processes), while weak fairness
suﬃces for sets of actions that represent the concurrent execution of independent actions
(i.e., interleaving).
For modeling asynchronous concurrency by means of transition systems, the following rule
of thumb can be adopted:
concurrency
=
interleaving (i.e., nondeterminism) + fairness
Example 3.51.
Fair Concurrency with Synchronization
Consider the concurrent transition system:
TS = TS1 ∥TS2 ∥. . . ∥TSn
,
where TSi = (Si, Acti, →i, Ii, APi, Li), for 1 ⩽i ⩽n, is a transition system without
terminal states. Recall that each pair of processes TSi and TSj (for i̸=j) has to synchronize
on their common sets of actions, i.e., Syni,j = Acti ∩Actj. It is assumed that Syni,j ∩
Actk = ∅for any k ̸= i, j. For simplicity, it is assumed that TS has no terminal states.
(In case there are terminal states, each ﬁnite execution is considered to be fair.)
We consider several fairness assumptions on the transition system TS. First, consider the
strong fairness assumption
{Act1, Act2, . . . , Actn}
which ensures that each transition system TSi executes an action inﬁnitely often, provided
the composite system TS is inﬁnitely often in a (global) state with a transition being
executable in which TSi participates. This fairness assumption, however, cannot ensure
that a communication will ever occur—it is possible for each TSi to only execute local
actions ad inﬁnitum.

138
Linear-Time Properties
In order to force a synchronization to take place every now and then, the strong fairness
assumption
{ { α } | α ∈Syni,j, 0 < i < j ⩽n }
(3.1)
could be imposed. It forces every synchronization action to happen inﬁnitely often. Alter-
natively, a somewhat weaker fairness assumption can be imposed by requiring every pair of
processes to synchronize—regardless of the synchronization action—inﬁnitely often. The
corresponding strong fairness assumption is
{ Syni,j | 0 < i < j ⩽n }.
(3.2)
Whereas (3.2) allows processes to always synchronize on the same action, (3.1) does not
permit this. The strong fairness assumption:
{

0<i<j⩽n
Syni,j }
goes even one step further as it only requires a synchronization to take place inﬁnitely
often, regardless of the process involved.
This fairness assumption does not rule out
executions in which always the same synchronization takes place or in which always the
same pair of processes synchronizes.
Note that all fairness assumptions in this example so far are strong. This requires that
inﬁnitely often a synchronization is enabled. As the constituting transition systems TSi
may execute internal actions, synchronizations are not continuously enabled, and hence
weak fairness is in general inappropriate.
If the internal actions should be fairly considered, too, then we may use, e.g., the strong
fairness assumption
{ Act1 \ Syn1, . . . , Actn \ Synn } ∪{ { α } | α ∈Syn },
where Syni
=

j̸=i Syni,j denotes the set of all synchronization actions of TSi and
Syn = 
i Syni.
Under the assumption that in every (local) state either only internal actions or only
synchronization actions are executable, it suﬃces to impose the weak fairness constraint
{ Act1 \ Syn1, . . . , Actn \ Synn }.
Weak fairness is appropriate for the internal actions α ∈Acti \ Syni, as the ability to
perform an internal action is preserved until it will be executed.

Fairness
139
As an example of another form of fairness we consider the following sequential hardware
circuit.
Example 3.52.
Circuit Fairness
For sequential circuits we have modeled the environmental behavior, which provides the
input bits, by means of nondeterminism. It may be necessary to impose fairness assump-
tions on the environment in order to be able to verify liveness properties, such as “the
values 0 and 1 are output inﬁnitely often”. Let us illustrate this by means of a concrete ex-
ample. Consider a sequential circuit with input variable x, output variable y, and register
r. Let the transition function and the output function be deﬁned as
λy = δr = x ↔¬r.
That is, the circuit inverts the register and output evaluation if and only if the input bit
is set. If x=0, then the register evaluation remains unchanged. The value of the register
is output. Suppose all transitions leading to a state with a register evaluation of the form
[r = 1, . . .] are labeled with the action set. Imposing the unconditional fairness assumption
{{ set }} ensures that the values 0 and 1 are output inﬁnitely often.
3.5.3
Fairness and Safety
While fairness assumptions may be necessary to verify liveness properties, they are irrele-
vant for verifying safety properties, provided that they can always be ensured by means of
an appropriate scheduling strategy. Such fairness assumptions are called realizable fairness
assumptions. A fairness assumption cannot be realized in a transition system whenever
there exists a reachable state from where no fair path begins. In this case, it is impossible
to design a scheduler that resolves the nondeterminism such that only fair paths remain.
Example 3.53.
A Nonrealizable Fairness Assumption
Consider the transition system depicted in Figure 3.13, and suppose the unconditional
fairness assumption { { α } } is imposed. As the α-transition can only be taken once, it is
evident that the transition system can never guarantee this form of fairness. As there is
a reachable state from which no unconditional fair path exists, this fairness assumption is
nonrealizable.
Deﬁnition 3.54.
Realizable Fairness Assumption
Let TS be a transition system with the set of actions Act and F a fairness assumption for
Act. F is called realizable for TS if for every reachable state s: FairPathsF(s) ̸= ∅.

140
Linear-Time Properties
∅
a
α
Figure 3.13: Unconditional fairness.
Stated in words, a fairness assumption is realizable in a transition system TS whenever in
any reachable state at least one fair execution is possible. This entails that every initial
ﬁnite execution fragment of TS can be completed to a fair execution. Note that there is
no requirement on the unreachable states.
The following theorem shows the irrelevance of realizable fairness assumptions for the
veriﬁcation of safety properties. The suﬃx property of fairness assumptions is essential for
its proof. This means the following. If
ρ = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . .
is an (inﬁnite) execution fragment, then ρ is fair if and only if every suﬃx
sj
αj+1
−−−−→sj+1
αj+2
−−−−→sj+2
αj+3
−−−−→. . .
of ρ is fair too. Conversely, every fair execution fragment ρ (as above) starting in state s0
can be preceded by an arbitrary ﬁnite execution fragment
s′
0
β1
−−→s′
1
β2
−−→. . .
βn
−−→s′
n = s0
ending in s0. Proceeding in s0 by execution ρ yields the fair execution fragment:
s′
0
β1
−−→s′
1
β2
−−→. . .
βn
−−→s′
n



arbitrary starting fragment
= s0
α1
−−→s1
α2
−−→s2
α3
−−→. . .



fair continuation
Theorem 3.55.
Realizable Fairness is Irrelevant for Safety Properties
Let TS be a transition system with set of propositions AP, F a realizable fairness assump-
tion for TS, and Psafe a safety property over AP. Then:
TS |= Psafe
if and only if
TS |=F Psafe.
Proof: “⇒”: Assume TS |= Psafe. Then, by deﬁnition of |= and the fact that the fair
traces of TS are a subset of the traces of TS, we have
FairTracesF(TS) ⊆Traces(TS) ⊆Psafe.

Summary
141
Thus, by deﬁnition of |=F it follows that TS |=F Psafe.
“⇐”: Assume TS |=F Psafe. It is to be shown TS |= Psafe, i.e., Traces(TS) ⊆Psafe.
This is done by contraposition. Let σ ∈Traces(TS) and assume σ /∈Psafe. As σ ̸∈Psafe,
there is a bad preﬁx of σ, σ say, for Psafe. Hence, the set of properties that has σ as a
preﬁx, i.e.,
P =

σ′ ∈

2APω
| σ ∈pref(σ′)

,
satisﬁes P ∩Psafe = ∅. Further, let π = s0 s1 . . . sn be a ﬁnite path fragment of TS with
trace(π) = σ.
Since F is a realizable fairness assumption for TS and sn ∈Reach(TS), there is an F-fair
path starting in sn. Let
sn sn+1 sn+2 . . . ∈FairPathsF(sn).
The path π = s0 . . . sn sn+1 sn+2 . . . is in FairPathsF(TS) and thus,
trace(π) = L(s0) . . . L(sn) L(sn+1) L(sn+2) . . . ∈FairTracesF(TS) ⊆Psafe.
On the other hand, σ = L(s0) . . . L(sn) is a preﬁx of trace(π). Thus, trace(π) ∈P. This
contradicts P ∩Psafe = ∅.
Theorem 3.55 does not hold if arbitrary (i.e., possibly nonrealizable) fairness assumptions
are permitted. This is illustrated by the following example.
Example 3.56.
Nonrealizable Fairness may harm Safety Properties
Consider the transition system TS in Figure 3.14 and suppose the unconditional fairness
assumption F = { { α } } is imposed. F is not realizable for TS, as the noninitial state
(referred to as state s1), is reachable, but has no F-fair execution. Obviously, TS has
only one fair path (namely the path that never leaves the initial state s0). In contrast,
paths of the form s0 . . . s0 s1 s1 s1 . . . are not fair, since α is only executed ﬁnitely often.
Accordingly, we have that
TS |=F “never a”
but
TS ̸|= “never a”.
3.6
Summary
• The set of reachable states of a transition system TS can be determined by a search
algorithm on the state graph of TS.

142
Linear-Time Properties
∅
{ a }
α
β
Figure 3.14: Unconditional fairness may be relevant for safety properties.
• A trace is a sequence of sets (!) of atomic propositions. The traces of a transition
system TS are obtained from projecting the paths to the sequence of state labels.
• A linear-time (LT, for short) property is a set of inﬁnite words over the alphabet
2AP.
• Two transition systems are trace-equivalent (i.e., they exhibit the same traces) if
and only if they satisfy the same LT properties.
• An invariant is an LT property that is purely state-based and requires a propositional
logic formula Φ to hold for all reachable states. Invariants can be checked using
a depth-ﬁrst search where the depth-ﬁrst search stack can be used to provide a
counterexample in case an invariant is refuted.
• Safety properties are generalizations of invariants. They constrain the ﬁnite behav-
iors. The formal deﬁnition of safety properties can be provided by means of their
bad preﬁxes in the sense that each trace that refutes a safety property has a ﬁnite
preﬁx, the bad preﬁx, that causes this.
• Two transition systems exhibit the same ﬁnite traces if and only if they satisfy the
same safety properties.
• A liveness property is an LT property if it does not rule out any ﬁnite behavior. It
constrains inﬁnite behavior.
• Any LT property is equivalent to an LT property that is a conjunction of a safety
and a liveness property.
• Fairness assumptions serve to rule out traces that are considered to be unrealistic.
They consist of unconditional, strong, and weak fairness constraints, i.e., constraints
on the actions that occur along inﬁnite executions.
• Fairness assumptions are often necessary to establish liveness properties, but they
are—provided they are realizable—irrelevant for safety properties.

Bibliographic Notes
143
3.7
Bibliographic Notes
The dining philosophers example discussed in Example 3.2 has been developed by Dijk-
stra [128] in the early seventies to illustrate the intricacies of concurrency. Since then it
has become one of the standard examples for reasoning about parallel systems.
The depth-ﬁrst search algorithm that we used as a basis for the invariance checking al-
gorithm goes back to Tarjan [387]. Further details about graph traversal algorithms can
be found in any textbook on algorithms and data structures, e.g.
[100], or on graph
algorithms [188].
Traces. Traces have been introduced by Hoare [202] to describe the linear-time behavior
of transition systems and have been used as the initial semantical model for the pro-
cess algebra CSP. Trace theory has further been developed by, among others, van de
Snepscheut [403] and Rem [354] and has successfully been used to design and analyze
ﬁne-grained parallel programs that occur in, e.g., asynchronous hardware circuits. Sev-
eral extensions to traces and their induced equivalences have been proposed, such as fail-
ures [65] where a trace is equipped with information about which actions are rejected after
execution of such trace. The FDR model checker [356] supports the automated checking
of failure-divergence reﬁnement and the checking of safety properties. A comprehensive
survey of these reﬁned notions of trace equivalence and trace inclusion has recently been
given by Bruda [68].
Safety and liveness. The speciﬁcation of linear-time properties using sets of inﬁnite se-
quences of states (and their topological characterizations) goes back to Alpern and Schnei-
der [5, 6, 7]. An earlier approach by Gerth [164] was based on ﬁnite sequences. Lam-
port [257] categorized properties as either safety, liveness, or properties that are neither.
Alternative characterizations have been provided by Rem [355] and Gumm [178]. Sub-
classes of liveness and safety properties in the linear-time framework have been identiﬁed
by Sistla [371], and Chang, Manna, and Pnueli [80]. Other deﬁnitions of liveness proper-
ties have been provided by Dederichs and Weber [119] and Naumovich and Clarke [312]
(for linear-time properties), and Manolios and Treﬂer [285, 286] (for branching-time prop-
erties). A survey of safety and liveness has been given by Kindler [239].
Fairness.
Fairness has implicitly been introduced by Dijkstra [126, 127] by assuming
that one should abstract from the speed of processors and that each process gets its turn
once it is initiated.
Park [321] studied the notion of fairness in providing a semantics
to data-ﬂow languages.
Weak and strong fairness have been introduced by Lehmann,
Pnueli, and Stavi [267] in the context of shared variable concurrent programs. Queille and
Sifakis [348] consider fairness for transition systems. An overview of the fairness notions
has been provided by Kwiatkowska [252]. An extensive treatment of fairness can be found

144
Linear-Time Properties
in the monograph by Francez [155].
A recent characterization of fairness in terms of
topology, language theory, and game theory has been provided by V¨olzer, Varacca, and
Kindler [415].
3.8
Exercises
Exercise 3.1.
Give the traces on the set of atomic propositions { a, b } of the following transition
system:
{ a }
∅
{ a, b }
{ a }
Exercise 3.2.
On page 97, a transformation is described of a transition system TS with possible
terminal states into an “equivalent” transition system TS∗without terminal states. Questions:
(a) Give a formal deﬁnition of this transformation TS →TS∗
(b) Prove that the transformation preserves trace-equivalence, i.e., show that if TS1, TS2 are
transition systems (possibly with terminal states) such that Traces(TS1) = Traces(TS2),
then Traces(TS∗
1) = Traces(TS∗
2).8
Exercise 3.3.
Give an algorithm (in pseudocode) for invariant checking such that in case
the invariant is refuted, a minimal counterexample, i.e., a counterexample of minimal length, is
provided as an error indication.
Exercise 3.4.
Recall the deﬁnition of AP-deterministic transition systems (Deﬁnition 2.5 on
page 24). Let TS and TS′ be transition systems with the same set of atomic propositions AP.
Prove the following relationship between trace inclusion and ﬁnite trace inclusion:
(a) For AP-deterministic TS and TS′:
Traces(TS) = Traces(TS′) if and only if Tracesﬁn(TS) = Tracesﬁn(TS′).
8If TS is a transition system with terminal states, then Traces(TS) is deﬁned as the set of all words
trace(π) where π is an initial, maximal path fragment in TS.

Exercises
145
(b) Give concrete examples of TS and TS′ where at least one of the transition systems is not
AP-deterministic, but
Traces(TS) ̸⊆Traces(TS′) and Tracesﬁn(TS) = Tracesﬁn(TS′).
Exercise 3.5.
Consider the set AP of atomic propositions deﬁned by AP = { x = 0, x > 1 }
and consider a nonterminating sequential computer program P that manipulates the variable x.
Formulate the following informally stated properties as LT properties:
(a) false
(b) initially x is equal to zero
(c) initially x diﬀers from zero
(d) initially x is equal to zero, but at some point x exceeds one
(e) x exceeds one only ﬁnitely many times
(f) x exceeds one inﬁnitely often
(g) the value of x alternates between zero and two
(h) true
(This exercise has been adopted from [355].) Determine which of the provided LT properties are
safety properties. Justify your answers.
Exercise 3.6.
Consider the set AP = { A, B } of atomic propositions. Formulate the following
properties as LT properties and characterize each of them as being either an invariance, safety
property, or liveness property, or none of these.
(a) A should never occur,
(b) A should occur exactly once,
(c) A and B alternate inﬁnitely often,
(d) A should eventually be followed by B.
(This exercise has been inspired by [312].)
Exercise 3.7.
Consider the following sequential hardware circuit:

146
Linear-Time Properties
XOR
XOR
AND
x
y
r
r
1
2
AND
OR
OR
The circuit has input variable x, output variable y, and registers r1 and r2 with initial values
r1 = 0 and r2 = 1. The set AP of atomic propositions equals { x, r1, r2, y }. Besides, consider the
following informally formulated LT properties over AP:
P1 : Whenever the input x is continuously high (i.e., x=1), then the output y is inﬁnitely often
high.
P2 : Whenever currently r2=0, then it will never be the case that after the next input, r1=1.
P3 : It is never the case that two successive outputs are high.
P4 : The conﬁguration with x=1 and r1=0 never occurs.
Questions:
(a) Give for each of these properties an example of an inﬁnite word that belongs to Pi. Do the
same for the property

2APω \ Pi, i.e., the complement of Pi.
(b) Determine which properties are satisﬁed by the hardware circuit that is given above.
(c) Determine which of the properties are safety properties. Indicate which properties are in-
variants.
(i) For each safety property Pi, determine the (regular) language of bad preﬁxes.
(ii) For each invariant, provide the propositional logic formula that speciﬁes the property
that should be fulﬁlled by each state.
Exercise 3.8.
Let LT properties P and P ′ be equivalent, notation P ∼= P ′, if and only if
pref(P) = pref(P ′). Prove or disprove: P ∼= P ′ if and only if closure(P) = closure(P ′).

Exercises
147
Exercise 3.9.
Show that for any transition system TS, the set closure(Traces(TS)) is a safety
property such that TS |= closure(Traces(TS)).
Exercise 3.10.
Let P be an LT property. Prove: pref(closure(P)) = pref(P).
Exercise 3.11.
Let P and P ′ be liveness properties over AP. Prove or disprove the following
claims:
(a) P ∪P ′ is a liveness property,
(b) P ∩P ′ is a liveness property.
Answer the same question for P and P ′ being safety properties.
Exercise 3.12.
Prove Lemma 3.38 on page 125.
Exercise 3.13.
Let AP = { a, b } and let P be the LT property of all inﬁnite words σ =
A0A1A2 . . . ∈

2AP ω such that there exists n ⩾0 with a ∈Ai for 0 ⩽i < n, { a, b } = An and
b ∈Aj for inﬁnitely many j ⩾0. Provide a decomposition P = Psafe ∩Plive into a safety and a
liveness property.
Exercise 3.14.
Let TSSem and TSPet be the transition systems for the semaphore-based mutual
exclusion algorithm (Example 2.24 on page 43) and Peterson’s algorithm (Example 2.25 on page
45), respectively. Let AP = { waiti, criti | i = 1, 2 }. Prove or disprove:
Traces(TSSem) = Traces(TSP et).
If the property does not hold, provide an example trace of one transition system that is not a trace
of the other one.
Exercise 3.15.
Consider the transition system TS outlined on the right and the sets of actions
B1 = { α }, B2 = { α, β }, and B3 = { β }.
Further, let Eb, Ea and E′ be the following LT
properties:

148
Linear-Time Properties
• Eb = the set of all words A0A1 · · · ∈

2{a,b}ω with
Ai ∈{{a, b}, {b}} for inﬁnitely many i
(i.e., inﬁnitely often b).
• Ea = the set of all words A0A1 · · · ∈

2{a,b}ω with
Ai ∈{{a, b}, {a}} for inﬁnitely many i
(i.e., inﬁnitely often a).
• E′ = set of all words A0A1 · · · ∈

2{a,b}ω for which
there does not exist an i ∈N s.t. Ai = {a}, Ai+1 =
{a, b} and Ai+2 = ∅.
∅
s1
s3 {b}
s2
{a}
s4
{a, b}
γ
γ
γ
α
α
β
α
Questions:
(a) For which sets of actions Bi (i ∈{ 1, 2, 3 }) and LT properties E ∈{ Ea, Eb, E′ } it holds
that TS |=Fi E? Here, Fi is a strong fairness condition with respect to Bi that does not
impose any unconditional or weak fairness conditions (i.e., Fi = (∅, { Bi }, ∅)).
(b) Answer the same question in the case of weak fairness (instead of strong fairness, i.e., Fi =
(∅, ∅, { Bi })).
Exercise 3.16.
Let TSi (for i=1, 2) be the transition system (Si, Act, →i, Ii, APi, Li) and
F = (Fucond, Fstrong, Fweak) be a fairness assumption with Fucond = ∅. Prove or disprove (i.e.,
give a counterexample for) the following claims:
(a) Traces(TS1) ⊆Traces(TS1 ∥TS2) where Syn ⊆Act
(b) Traces(TS1) ⊆Traces(TS1 ||| TS2)
(c) Traces(TS1 ∥TS2) ⊆Traces(TS1) where Syn ⊆Act
(d) Traces(TS1) ⊆Traces(TS2) ⇒FairTracesF(TS1) ⊆FairTracesF(TS2)
(e) For liveness property P with TS2 |=F P we have
Traces(TS1) ⊆Traces(TS2)
⇒
TS1 |=F P.
Assume that in items (a) through (c), we have AP2 = ∅and that TS1 ∥TS2 and TS1 ||| TS2,
respectively, have AP = AP1 as atomic propositions and L(⟨s, s′⟩) = L1(s) as labeling function.
In items (d) and (e) you may assume that AP1 = AP2.
Exercise 3.17.
Consider the following transition system TS with the set of atomic propositions
{ a }:

Exercises
149
{a}
s1
s2
s3
s6
s4
s5
α
α
α
γ
β
β
β
β
α
Let the fairness assumption
F = (∅, {{α}, {β}} , {{β}}) .
Determine whether TS |=F “eventually a”. Justify your answer!
Exercise 3.18.
Consider the following transition system T S (without atomic propositions):
s0
s1
s2
s4
α
β
α
α
δ
β
δ
s3
β
α
Decide which of the following fairness assumptions Fi are realizable for TS. Justify your answers!
(a) F1 = ({{α}} , {{δ}} , {{α, β}})
(b) F2 = ({{δ, α}} , {{α, β}} , {{δ}})
(c) F3 = ({{α, δ}, {β}} , {{α, β}} , {{δ}})
Exercise 3.19.
Let AP = { a, b }.
(a) P1 denotes the LT property that consists of all inﬁnite words σ = A0A1A2 . . . ∈

2AP ω
such that there exists n ⩾0 with
∀j < n. Aj = ∅
∧
An = {a}
∧
∀k > n. (Ak = { a } ⇒Ak+1 = { b }) .
(i) Give an ω–regular expression for P1.
(ii) Apply the decomposition theorem and give expressions for Psafe and Plive.

150
Linear-Time Properties
(iii) Justify that Plive is a liveness and that Psafe is a safety property.
(b) Let P2 denote the set of traces of the form σ = A0A1A2 . . . ∈

2AP ω such that
∞
∃k. Ak = { a, b }
∧
∃n ⩾0. ∀k > n.

a ∈Ak ⇒b ∈Ak+1

.
Consider the following transition system TS:
s0
{ a }
s1 { b }
s2
{ a, b }
s3 ∅
s4 { a, b }
δ
η
γ
α
β
α
γ
α
α
β
β
Consider the following fairness assumptions:
(a) F1 =

{α}

,

{β}, {δ, γ}, {η}

, ∅

. Decide whether TS |=F1 P2.
(b) F2 =

{α}

,

{β}, {γ}

,

{η}

. Decide whether T S |=F2 P2.
Justify your answers.
Exercise 3.20.
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states
and let A1, . . . , Ak, A′
1, . . . , A′
l ⊆Act.
(a) Let F be the fairness assumption F = (∅, Fstrong, Fweak) where
Fstrong = {A1, . . . , Ak} and Fweak = {A′
1, . . . , A′
l}.
Provide a sketch of a scheduling algorithm that resolves the nondeterminism in TS in an
F-fair way.
(b) Let Fucond = {A1, . . . , Ak}, viewed as an unconditional fairness assumption for TS. Design
a (scheduling) algorithm that checks whether Fucond for TS is realizable, and if so, generates
an Fucond-fair execution for TS.

Chapter 4
Regular Properties
This chapter treats some elementary algorithms to verify important classes of safety prop-
erties, liveness properties, and a wide range of other linear-time properties.
We ﬁrst
consider regular safety properties, i.e., safety properties whose bad preﬁxes constitute a
regular language, and hence can be recognized by a ﬁnite automaton. The algorithm to
check a safety property Psafe for a given ﬁnite transition system TS relies on a reduction
to the invariant-checking problem in a certain product construction of TS with a ﬁnite
automaton that recognizes the bad preﬁxes of Psafe.
We then generalize this automaton-based veriﬁcation algorithm to a larger class of linear-
time properties, the so-called ω-regular properties. This class of properties covers regular
safety properties, but also many other relevant properties such as various liveness prop-
erties. ω-regular properties can be represented by so-called B¨uchi automata, a variant of
ﬁnite automata that accept inﬁnite (rather than ﬁnite) words. B¨uchi automata will be the
key concept to verify ω-regular properties via a reduction to persistence checking. The
latter is a variant of invariant checking and aims to show that a certain state-condition
holds continuously from some moment on.
4.1
Automata on Finite Words
Deﬁnition 4.1.
Nondeterministic Finite Automaton (NFA)
A nondeterministic ﬁnite automaton (NFA) A is a tuple A = (Q, Σ, δ, Q0, F) where
151

152
Regular Properties
• Q is a ﬁnite set of states,
• Σ is an alphabet,
• δ : Q × Σ →2Q is a transition function,
• Q0 ⊆Q is a set of initial states, and
• F ⊆Q is a set of accept (or: ﬁnal) states.
The size of A, denoted |A|, is the number of states and transitions in A, i.e.,
|A| = |Q| +

q∈Q

A∈Σ
|δ(q, A)|.
Σ deﬁnes the symbols on which the automaton is deﬁned. The (possibly empty) set Q0
deﬁnes the states in which the automaton may start. The transition function δ can be
identiﬁed with the relation →⊆Q × Σ × Q given by
q
A
−−→q′ iﬀq′ ∈δ(q, A).
Thus, often the notion of transition relation (rather than transition function) is used for
δ. Intuitively, q
A
−−→q′ denotes that the automaton can move from state q to state q′ when
reading the input symbol A.
Example 4.2.
An Example of a Finite-State Automaton
An example of an NFA is depicted in Figure 4.1. Here, Q = { q0, q1, q2 }, Σ = { A, B },
Q0 = { q0 }, F = { q2 }, and the transition function δ is deﬁned by
δ(q0, A)
=
{ q0 }
δ(q0, B)
=
{ q0, q1 }
δ(q1, A)
=
{ q2 }
δ(q1, B)
=
{ q2 }
δ(q2, A)
=
∅
δ(q2, B)
=
∅
This corresponds to the transitions q0
A
−−→q0, q0
B
−−→q0, q0
B
−−→q1, q1
A
−−→q2, and q1
B
−−→q2.
The drawing conventions for an NFA are the same as for labeled transition systems. Accept
states are distinguished from other states by drawing them with a double circle.
The intuitive operational behavior of an NFA is as follows. The automaton starts in one
of the states in Q0, and then is fed with an input word w ∈Σ∗. The automaton reads this

Automata on Finite Words
153
q0
q1
q2
A
B
B
A
B
Figure 4.1: An example of a ﬁnite-state automaton.
word character by character from the left to the right. (The reader may assume that the
input word is provided on a tape from which the automaton reads the input symbols from
the left to the right by moving a cursor from the current position i to the next position
i+1 when reading the ith input symbol. However, the automaton can neither write on the
tape nor move the cursor in another way than one position to the right.) After reading an
input symbol, the automaton changes its state according to the transition relation δ. That
is, if the current input symbol A is read in the state q, the automaton chooses one of the
possible transitions q
A
−−→q′ (i.e., one state q′ ∈δ(q, A)) and moves to q′ where the next
input symbol will be consumed. If δ(q, A) contains two or more states, then the decision
for the next state is made nondeterministically. An NFA cannot perform any transition
when its current state q does not have an outgoing transition that is labeled with the
current input symbol A. In that case, i.e., if δ(q, A) = ∅, the automaton is stuck and no
further progress can be made. The input word is said to be rejected. When the complete
input word has been read, the automaton halts. It accepts whenever the current state is
an accept state, and it rejects otherwise.
This intuitive explanation of the possible behaviors of an NFA for a given input word
w = A1 . . . An is formalized by means of runs for w (see Deﬁnition 4.3 below). For any
input word w there might be several possible behaviors (runs); some of them might be
accepting, some of them might be rejecting. Word w is accepted by A if at least one of
its runs is accepting, i.e., succeeds in reading the whole word and ends in a ﬁnal state.
This relies on the typical nondeterministic acceptor criterion which assumes an oracle
for resolving the nondeterminism such that, whenever possible, an accepting run will be
generated.
Deﬁnition 4.3.
Runs, Accepted Language of an NFA
Let A = (Q, Σ, δ, Q0, F) be an NFA and w = A1 . . . An ∈Σ∗a ﬁnite word. A run for w in
A is a ﬁnite sequence of states q0 q1 . . . qn such that
• q0 ∈Q0 and

154
Regular Properties
• qi
Ai+1
−−−−→qi+1 for all 0 ⩽i < n.
Run q0 q1 . . . qn is called accepting if qn ∈F. A ﬁnite word w ∈Σ∗is called accepted by
A if there exists an accepting run for w.
The accepted language of A, denoted L(A), is
the set of ﬁnite words in Σ∗accepted by A, i.e.,
L(A) = {w ∈Σ∗| there exists an accepting run for w in A }.
Example 4.4.
Runs and Accepted Words
Example runs of the automaton A in Figure 4.1 are q0 for the empty word ε, q0 q1 for
the word consisting of the symbol B, q0 q0 q0 q0 for, e.g., the words ABA and BBA and
q0 q1 q2 for the words BA, and BB. Accepting runs are runs that ﬁnish in the ﬁnal state
q2. For instance, the runs q0 q1 q2 for BA and BB and q0 q0 q1 q2 for the words ABB, ABA,
BBA, and BBB are accepting. Thus, these words belong to L(A). The word AAA is not
accepted by A since it only has single run, namely q0 q0 q0 q0, which is not accepting.
The accepted language L(A) is given by the regular expression (A + B)∗B(A + B). Thus,
L(A) is the set of words over { A, B } where the last but one symbol is B.
The special cases Q0 = ∅or F = ∅are allowed. In both cases, L(A) = ∅. If F = ∅,
then there are no accepting runs. If there are no initial states, then there are no runs at
all. Intuitively, the automaton rejects any input word immediately.
An equivalent alternative characterization of the accepted language of an NFA A is as
follows. Let A be an NFA as above. We extend the transition function δ to the function
δ∗: Q × Σ∗→2Q as follows: δ∗(q, ε) = { q }, δ∗(q, A) = δ(q, A), and
δ∗(q, A1A2 . . . An) =

p∈δ(q,A1)
δ∗(p, A2 . . . An).
Stated in words, δ∗(q, w) is the set of states that are reachable from q for the input word
w. In particular, 
q0∈Q0 δ∗(q0, w) is the set of all states where a run for w in A can end.
If one of these states is ﬁnal, then w has an accepting run. Vice versa, if w /∈L(A), then
none of these states is ﬁnal. Hence, we have the following alternative characterization of
the accepted language of an NFA by means of the extended transition function δ∗:

Automata on Finite Words
155
Lemma 4.5.
Alternative Characterization of the Accepted Language
Let A be an NFA. Then:
L(A) = {w ∈Σ∗| δ∗(q0, w) ∩F ̸= ∅for some q0 ∈Q0}.
It can be shown that the language accepted by an NFA constitutes a regular language.
In fact, there are algorithms that for a given NFA A generate a regular expression for
the language L(A). Vice versa, for any regular expression E, an NFA can be constructed
that accepts L(E). Hence, the class of regular languages agrees with the class of languages
accepted by an NFA.
An example of a language that is nonregular (but context-free) is { AnBn | n ⩾0 }. There
does not exist an NFA that accepts it. The intuitive argument for this is that one needs
to be able to count the number of A’s so as to be able to determine the number of B’s
that are to follow.
Since NFAs serve to represent (regular) languages we may identify those NFA that accept
the same language:
Deﬁnition 4.6.
Equivalence of NFAs
Let A and A′ be NFAs with the same alphabet.
A and A′ are called equivalent if
L(A) = L(A′).
A fundamental issue in automata theory is to decide for a given NFA A whether its
accepted language is empty, i.e., whether L(A) = ∅. This is known as the emptiness
problem. From the acceptance condition, it follows directly that L(A) is nonempty if and
only if there is at least one run that ends in some ﬁnal state. Thus, nonemptiness of L(A)
is equivalent to the existence of an accept state q ∈F which is reachable from an initial
state q0 ∈Q0. This can easily be determined in time O(|A|) using a depth-ﬁrst search
traversal that encounters all states that are reachable from the initial states and checks
whether one of them is ﬁnal.
For state q ∈Q, let Reach(q) = 
w∈Σ∗δ∗(q, w); that is,
Reach(q) is the set of states q′ that are reachable via an arbitrary run starting in state q.
Theorem 4.7.
Language Emptiness is Equivalent to Reachability
Let A = (Q, Σ, δ, Q0, F) be an NFA. Then, L(A) ̸= ∅if and only if there exists q0 ∈Q0
and q ∈F such that q ∈Reach(q0).

156
Regular Properties
Regular languages exhibit some interesting closure properties, e.g., the union of two reg-
ular languages is regular.
The same applies to concatenation and Kleene star (ﬁnite
repetition). This is immediate from the deﬁnition of regular languages as those languages
that can be generated by regular expressions. They are also closed under intersection and
complementation, i.e., if L, L1, L2 are regular languages over the alphabet Σ, then so are
L = Σ∗\ L and L1 ∩L2.
Let us brieﬂy sketch the proofs for this. In both cases, we may proceed on the basis of
ﬁnite automata and assume a representation of the given regular languages by NFA A,
A1, and A2 with the input alphabet Σ that accept the regular languages L, L1, and L2,
respectively. Intersection can be realized by a product construction A1 ⊗A2 which can
be viewed as a parallel composition with synchronization over all symbols A ∈Σ. In
fact, the formal deﬁnition of ⊗is roughly the same as the synchronization operator ∥; see
Deﬁnition 2.26 on page 48. The idea is simply that for the given input word, we run the
two automata in parallel and reject as soon as one automaton cannot read the current
input symbol, but accept if the input word is fully consumed and both automata accept
(i.e., are in a ﬁnal state).
Deﬁnition 4.8.
Synchronous Product of NFAs
For NFA Ai = (Qi, Σ, δi, Q0,i, Fi), with i=1, 2, the product automaton
A1 ⊗A2 = (Q1 × Q2, Σ, δ, Q0,1 × Q0,2, F1 × F2)
where δ is deﬁned by
q1
A
−−→1 q′
1 ∧q2
A
−−→2 q′
2
(q1, q2)
A
−−→(q′
1, q′
2)
.
It follows that this product construction of automata corresponds indeed to the intersection
of their accepting languages, i.e., L(A1 ⊗A2) = L(A1) ∩L(A2).
Let us now consider the complementation operator.
Given an NFA A with the input
alphabet Σ, we aim to construct an NFA for the complement language Σ∗\ L(A). The
main step to do so is ﬁrst to construct an equivalent deterministic ﬁnite automaton Adet
which can be complemented in a quite simple way.
Deﬁnition 4.9.
Deterministic Finite Automaton (DFA)
Let A = (Q, Σ, δ, Q0, F) be an NFA. A is called deterministic if |Q0| ⩽1 and |δ(q, A)| ⩽1
for all states q ∈Q and all symbols A ∈Σ. We will use the abbreviation DFA for a
deterministic ﬁnite automaton.

Automata on Finite Words
157
DFA A is called total if |Q0| = 1 and |δ(q, A)| = 1 for all q ∈Q and all A ∈Σ.
Stated in words, an NFA is deterministic if it has at most a single initial state and if for each
symbol A the successor state of each state q is either uniquely deﬁned (if |δ(q, A)| = 1) or
undeﬁned (if δ(q, A) = ∅). Total DFAs provide unique successor states, and thus, unique
runs for each input word. Any DFA can be turned into an equivalent total DFA by simply
adding a nonﬁnal trap state, qtrap say, that is equipped with a self-loop for any symbol
A ∈Σ. From any state q ̸= qtrap, there is a transition to qtrap for any symbol A for which
q has no A-successor in the given nontotal DFA.
Total DFA are often written in the form A = (Q, Σ, δ, q0, F) where q0 stands for the unique
initial state and δ is a (total) transition function δ : Q × Σ →Q. Also, the extended
transition function δ∗of a total DFA can be viewed as a total function δ∗: Q × Σ∗→Q,
which for given state q and ﬁnite word w returns the unique state p = δ∗(q, w) that is
reached from state q for the input word w. In particular, the accepted language of a total
DFA A = (Q, Σ, δ, q0, F) is given by
L(A) = {w ∈Σ∗| δ∗(q0, w) ∈F}.
The observation that total DFAs have exactly one run for each input word allows comple-
menting a total DFA A by simply declaring all states to be ﬁnal that are nonﬁnal in A and
vice versa. Formally, if A = (Q, Σ, δ, q0, F) is a total DFA then A = (Q, Σ, δ, q0, Q \ F) is
a total DFA with L(A) = Σ∗\L(A). Note that the operator A →A applied to a nontotal
DFA (or NFA with proper nondeterministic choices) fails to provide an automaton for the
complement language (why?).
It remains to explain how to construct for a given NFA A = (Q, Σ, δ, Q0, F) an equivalent
total DFA Adet. This can be done by a powerset construction, also often called a subset
construction, since the states of Adet are the subsets of Q. This allows Adet to simulate
A by moving the preﬁxes A1 . . . Ai of the given input word w = A1 . . . An ∈Σ to the
set of states that are reachable in A for A1 . . . Ai. That is, Adet starts in Q0, the set
of initial states in A.
If Adet is in state Q′ (which is a subset of A’s state space Q),
then Adet moves the input symbol A to Q′′ = 
q∈Q′ δ(q, A). If the input word has been
consumed and Adet is in a state Q′ that contains a state in A’s set of accept states, then
Adet accepts. The latter means that there exists an accepting run in A for the given input
word w that ends in an accept state, and hence, w ∈L(A). The formal deﬁnition of Adet
is Adet = (2Q, Σ, δdet, Q0, Fdet) where
Fdet = {Q′ ⊆Q | Q′ ∩F ̸= ∅}
and where the total transition function δdet : 2Q × Σ →2Q is deﬁned by
δdet(Q′, A) =

q∈Q′
δ(q, A).

158
Regular Properties
Clearly, Adet is a total DFA and, for all ﬁnite words w ∈Σ∗, we have
δ∗
det(Q0, w) =

q0∈Q0
δ∗(q0, w).
Thus, by Lemma 4.5, L(Adet) = L(A).
Example 4.10.
Determinizing a Nondeterministic Finite Automaton
Consider the NFA depicted in Figure 4.1 on page 153. This automaton is not deterministic
as on input symbol B in state q0 the next state is not uniquely determined. The total
DFA that is obtained through the powerset construction is depicted in Figure 4.2.
{ q0 }
{ q0, q1 }
{ q0, q2 }
{ q0, q1, q2 }
A
B
B
A
B
A
A
B
Figure 4.2: A DFA accepting L((A + B)∗B(A + B)).
The powerset construction yields a total DFA that is exponentially larger than the orig-
inal NFA. In fact, although DFAs and NFAs have the same power (both are equivalent
formalisms for regular languages), NFAs can be much more eﬃcient. The regular language
given by the regular expression Ek = (A + B)∗B(A + B)k (where k is a natural number)
is accepted by an NFA with k+2 states (namely?), but it can be shown that there is no
equivalent DFA with less than 2k states. The intuitive argument for the latter is that each
DFA for L(Ek) needs to “remember” the positions of the symbol B among the last k input
symbols which yields Ω(2k) states.
We ﬁnally mention that for any regular language L there is a unique DFA A with L = L(A)
where the number of states is minimal under all DFAs for L. Uniqueness is understood
up to isomorphism, i.e., renaming of the states. (This does not hold for NFA. Why?)
There is an algorithm to minimize a given DFA with N states into its equivalent minimal
DFA which is based on partition reﬁnement and takes O(N· log N) time in the worst case.
The concepts of this minimization algorithm are outside the scope of this monograph and
can be found in any textbook on automata theory. However, in Chapter 7 a very similar
partitioning-reﬁnement algorithm will be presented for bisimulation minimization.

Model-Checking Regular Safety Properties
159
4.2
Model-Checking Regular Safety Properties
In this section, it will be shown how NFAs can be used to check the validity of an important
class of safety properties. The main characteristic of these safety properties is that all their
bad preﬁxes constitute a regular language. The bad preﬁxes of these so-called regular
safety properties can thus be recognized by an NFA. The main result of this section is
that checking a regular safety property on a ﬁnite transition system can be reduced to
invariant checking on the product of TS and an NFA A for the bad preﬁxes.
Stated
diﬀerently, if one wants to check whether a regular safety property holds for TS, it suﬃces
to perform a reachability analysis in the product TS⊗A to check a corresponding invariant
on TS ⊗A.
4.2.1
Regular Safety Properties
Recall that safety properties are LT properties, i.e., sets of inﬁnite words over 2AP, such
that every trace that violates a safety property has a bad preﬁx that causes a refutation
(cf. Deﬁnition 3.22 on page 112). Bad preﬁxes are ﬁnite, and thus the set of bad preﬁxes
constitutes a language of ﬁnite words over the alphabet Σ = 2AP. That is, the input
symbols A ∈Σ of the NFA are now sets of atomic propositions. For instance, if AP =
{ a, b }, then Σ = { A1, A2, A3, A4 } consists of the four input symbols A1 = {}, A2 = { a },
A3 = { b }, and A4 = { a, b }.1
Deﬁnition 4.11.
Regular Safety Property
Safety property Psafe over AP is called regular if its set of bad preﬁxes constitutes a regular
language over 2AP.
Every invariant is a regular safety property. If Φ is the state condition (propositional
formula) of the invariant that should be satisﬁed by all reachable states, then the language
of bad preﬁxes consists of the words A0 A1 . . . An such that Ai ̸|= Φ for some 0 ⩽i ⩽n.
Such languages are regular, since they can be characterized by the (casually written)
regular notation
Φ∗(¬ Φ) true∗.
Here, Φ stands for the set of all A ⊆AP with A |= Φ, ¬Φ for the set of all A ⊆AP with
A ̸|= Φ, while true means the set of all subsets A of AP. For instance, if AP = { a, b } and
Φ = a ∨¬b, then
1The symbol {} denotes the empty subset of AP which serves as symbol in the alphabet Σ = 2AP. It
must be distinguished from the regular expression ∅representing the empty language.

160
Regular Properties
• Φ stands for the regular expression {} + { a } + { a, b },
• ¬Φ stands for the regular expression consisting of the symbol { b },
• true stands for the regular expression {} + { a } + { b } + { a, b }.
The bad preﬁxes of the invariant over condition a∨¬b are given by the regular expression:
E = ({} + { a } + { a, b })∗



Φ∗
{ b }

¬Φ
({} + { a } + { b } + { a, b })∗



true∗
.
Thus, L(E) consists of all words A1 . . . An such that Ai = { b } for some 1 ⩽i ⩽n. Note
that, for A ⊆AP = { a, b }, we have A ̸|= a ∨¬b if and only if A = { b }. Hence, L(E)
agrees with the set of bad preﬁxes for the invariant induced by the condition Φ.
q0
q1
Φ
¬ Φ
true
Figure 4.3: NFA accepting all bad preﬁxes of the invariant over the condition Φ.
In fact, for any invariant Pinv, the language of all bad preﬁxes can be represented by an
NFA with two states, as shown in Figure 4.3. Here and in the sequel, we use symbolic
notations in the pictures for NFAs over the alphabet 2AP. We use propositional formulae
over AP as labels for the edges. Thus, an edge leading from state q to state q′ labeled
with formula Ψ means that there are transitions q
A
−−→q′ for all A ⊆AP where A |= Ψ.
E.g., if AP = { a, b } and Φ = a ∨¬b, then Figure 4.3 is a representation for an NFA with
two states q0, q1 and the transitions
q0
{}
−−→q0,
q0
{a}
−−−→q0,
q0
{a,b}
−−−−→q0,
q0
{b}
−−−→q1
and
q1
{}
−−→q1,
q1
{a}
−−−→q1,
q1
{b}
−−−→q1,
q1
{a,b}
−−−−→q1.
For the invariant over AP = { a, b } induced by the condition Φ = a ∨¬b, the minimal
bad preﬁxes are described by the regular expression ({} + { a } + { a, b })∗{ b }. Hence, the
minimal bad preﬁxes constitute a regular language too. An automaton that recognizes all
minimal bad preﬁxes, which are given by the regular expression Φ∗(¬Φ), is obtained from
Figure 4.3 by omitting the self-loop of state q1. In fact, for the deﬁnition of regular safety
properties it is irrelevant whether the regularity of the set of all bad preﬁxes or of the set
of all minimal bad preﬁxes is required:

Model-Checking Regular Safety Properties
161
Lemma 4.12.
Criterion for Regularity of Safety Properties
The safety property Psafe is regular if and only if the set of minimal bad preﬁxes for Psafe
is regular.
Proof: “if”: Let A = (Q, 2AP, δ, Q0, F) be an NFA for MinBadPref(Psafe).
Then, an
NFA for BadPref(Psafe) is obtained by adding self-loops q
A
−−→q for all states q ∈F and
all A ⊆AP. It is easy to check that the modiﬁed NFA accepts the language consisting of
all bad preﬁxes for Psafe. Thus, BadPref(Psafe) is regular, which yields the claim.
“only if”: Let A = (Q, 2AP, δ, Q0, F) be a DFA for BadPref(Psafe). For MinBadPref(Psafe),
a DFA is obtained by removing all outgoing transitions from the accept states in A. Let
A′ be the modiﬁed DFA and let us check that L(A′) = MinBadPref(Psafe).
If we are given a word w = A1 . . . An ∈L(A′), then w ∈L(A) since the run q0q1 . . . qn in
A′ for w is also an accepting run in A. Therefore, w is a bad preﬁx for Psafe. Distinguish
two cases.
Assume w is not a minimal bad preﬁx. Then there exists a proper preﬁx A1 . . . Ai of w
that is a bad preﬁx for Psafe. Thus, A1 . . . Ai ∈L(A). Since A is deterministic, q0q1 . . . qi
is the (unique) run for A1 . . . Ai in A and qi ∈F. Since i < n and qi has no outgoing
transitions in A′, q0 . . . qi . . . qn cannot be a run for A1 . . . Ai . . . An in A′. This contradicts
the assumption and shows that A1 . . . An is a minimal bad preﬁx for Psafe.
Vice versa, if w is a minimal bad preﬁx for Psafe, then
(1) A1 . . . An ∈BadPref(Psafe) = L(A) and
(2) A1 . . . Ai /∈BadPref(Psafe) = L(A) for all 1 ⩽i < n.
Let q0 . . . qn be the unique run for w in A. Then, (2) yields qi /∈F for 1 ⩽i < n, while
qn ∈F by (1). Thus, q0 . . . qn is an accepting run for w in A′ which yields w ∈L(A′).
Example 4.13.
Regular Safety Property for Mutual Exclusion Algorithms
Consider a mutual exclusion algorithm such as the semaphore-based one or Peterson’s
algorithm. The bad preﬁxes of the safety property Pmutex (“there is always at most one
process in its critical section”) constitute the language of all ﬁnite words A0 A1 . . . An such
that
{ crit1, crit2 } ⊆Ai

162
Regular Properties
for some index i with 0 ⩽i ⩽n. If i=n is the smallest such index, i.e., { crit1, crit2 } ⊆An
and { crit1, crit2 } ̸⊆Aj for 0 ⩽j < n, then A0 . . . An is a minimal bad preﬁx.
The
language of all (minimal) bad preﬁxes is regular. An NFA recognizing all minimal bad
preﬁxes is depicted in Figure 4.4.
q0
q1
¬ (crit1 ∧crit2)
crit1 ∧crit2
Figure 4.4: Minimal bad preﬁxes that refute the mutual exclusion property.
Example 4.14.
Regular Safety Property for the Traﬃc Light
Consider a traﬃc light with three possible colors: red, yellow and green. The property
“a red phase must be preceded immediately by a yellow phase” is speciﬁed by the set of
inﬁnite words σ = A0 A1 . . . with Ai ⊆{ red, yellow } such that for all i ⩾0 we have that
red ∈Ai implies i > 0 and yellow ∈Ai−1.
The bad preﬁxes are ﬁnite words that violate this condition. Examples of bad preﬁxes
that are minimal are
{} {} { red }
and
{} { red }.
In general, the minimal bad preﬁxes are words of the form A0 A1 . . . An such that n > 0,
red ∈An, and yellow ̸∈An−1. The NFA in Figure 4.5 accepts these minimal bad preﬁxes.
Recall the meaning of the edge labels in the pictorial representations of an NFA over the
q1
q0
q2
red
¬red ∧yellow
¬yellow
yellow
¬red ∧¬yellow
Figure 4.5: Minimal bad preﬁxes in which red is not preceded by yellow.
alphabet Σ = 2AP where AP = { yellow,red }. For instance, the edge-label yellow in the
self-loop of state q1 denotes a formula, namely the positive literal yellow ∈AP. This
stands for all sets A ⊆AP = { yellow,red } where the literal yellow holds, that is, the sets
{ yellow } and { yellow, red }. Hence, the self-loop of q1 in the picture stands for the two

Model-Checking Regular Safety Properties
163
transitions:
q1
{yellow}
−−−−−−→q1 and q1
{yellow,red}
−−−−−−−−−→q1.
Similarly, the edge label ¬yellow in the transition from q1 to q0 stands for the negative
literal ¬yellow, and thus represents the transitions:
q1
{red}
−−−−→q0
and
q1
{}
−−→q0.
In the same way the label red of the transition from q0 to q2 represents two transitions (with
the labels { red } and { red, yellow }), while the edge labels ¬red∧yellow and ¬red∧¬yellow
denote only a single symbol in 2AP, namely { yellow } and {}, respectively.
Example 4.15.
A Nonregular Safety Property
Not all safety properties are regular.
As an example of a nonregular safety property,
consider:
“The number of inserted coins is always at least the number of dispensed drinks.”
(See also Example 3.24 on page 113). Let the set of propositions be { pay, drink }. Minimal
bad preﬁxes for this safety property constitute the language
{ payn drinkn+1 | n ⩾0 }
which is not a regular, but a context-free language. Such safety properties fall outside the
scope of the following veriﬁcation algorithm.
4.2.2
Verifying Regular Safety Properties
Let Psafe be a regular safety property over the atomic propositions AP and A an NFA
recognizing the (minimal) bad preﬁxes of Psafe. (Recall that by Lemma 4.12 on page 161
it is irrelevant whether A accepts all bad preﬁxes for Psafe or only the minimal ones.) For
technical reasons, we assume that ε /∈L(A). In fact, this is not a severe restriction since
otherwise all ﬁnite words over 2AP are bad preﬁxes, and hence, Psafe = ∅. In this case,
TS |= Psafe if and only if TS has no initial state.
Furthermore, let TS be a ﬁnite transition system without terminal states with correspond-
ing set of propositions AP. In this section, we aim to establish an algorithmic method
for verifying whether TS satisﬁes regular safety property Psafe, i.e., to check whether

164
Regular Properties
TS |= Psafe holds. According to Lemma 3.25 on page 114 we have
TS |= Psafe
if and only if
Tracesﬁn(TS) ∩BadPref(Psafe) = ∅
if and only if
Tracesﬁn(TS) ∩L(A) = ∅.
Thus, it suﬃces to check whether Tracesﬁn(TS) ∩L(A) = ∅to establish TS |= Psafe.
To do so, we adopt a similar strategy as for checking whether two NFAs intersect. Recall
that in order to check whether the NFAs A1 and A2 do intersect, it suﬃces to consider
their product automaton, so
L(A1) ∩L(A2) = ∅
if and only if
L(A1 ⊗A2) = ∅.
The question whether two automata do intersect is thus reduced to a simple reachability
problem in the product automaton.
This is now exploited as follows. In order to check whether Tracesﬁn(TS) ∩L(A) = ∅,
we ﬁrst build a product of transition system TS and NFA A in the same vein as the
synchronous product of NFA. This yields the transition system TS⊗A. For this transition
system, an invariant can be given using a propositional logic formula Φ –derived from the
accept states of A– such that Tracesﬁn(TS)∩L(A) = ∅if and only if TS⊗A |= “always Φ”.
In this way, the veriﬁcation of a regular safety property is reduced to invariant checking.
Recall that for checking invariants, Algorithm 4 (see page 110) can be exploited.
We start by formally deﬁning the product between a transition system TS and an NFA
A, denoted TS ⊗A.
Let TS = (S, Act, →, I, AP, L) and A = (Q, 2AP, δ, Q0, F) with
Q0 ∩F = ∅. Recall that the alphabet of A consists of sets of atomic proposition in TS.
Transition system TS ⊗A has state space S × Q and a transition relation such that each
path fragment π = s0 s1 . . . sn in TS can be extended to a path fragment
⟨s0, q1⟩⟨s1, q2⟩. . . ⟨sn, qn+1⟩
in TS ⊗A which has an initial state q0 ∈Q0 for which
q0
L(s0)
−−−−→q1
L(s1)
−−−−→q2
L(s2)
−−−−→. . .
L(sn)
−−−−→qn+1
is a run—not necessarily accepting—of NFA A that generates the word
trace(π) = L(s0) L(s1) . . . L(sn).
Finally, labels of states are state names of A. These considerations lead to the following
deﬁnition:

Model-Checking Regular Safety Properties
165
Deﬁnition 4.16.
Product of Transition System and NFA
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states and A =
(Q, Σ, δ, Q0, F) an NFA with the alphabet Σ = 2AP and Q0 ∩F = ∅.
The product
transition system TS ⊗A is deﬁned as follows:
TS ⊗A = (S′, Act, →′, I′, AP′, L′)
where
• S′ = S × Q,
• →′ is the smallest relation deﬁned by the rule
s
α
−−→t ∧q
L(t)
−−−→p
⟨s, q⟩
α
−−→′ ⟨t, p⟩
,
• I′ = { ⟨s0, q⟩| s0 ∈I ∧∃q0 ∈Q0. q0
L(s0)
−−−−→q },
• AP′ = Q, and
• L′ : S × Q →2Q is given by L′(⟨s, q⟩) = { q }.
Remark 4.17.
Terminal States
For the deﬁnition of LT properties (and thus of invariants) we have assumed transition
systems to have no terminal states. It is, however, not guaranteed that TS ⊗A possesses
this property, even if TS does. This stems from the fact that in NFA A there may be a state
q, say, that has no direct successor states for some set A of atomic propositions, i.e., with
δ(q, A) = ∅. This technical problem can be treated by either requiring δ(q, A) ̸= ∅for all
states q ∈Q and A ⊆AP or by extending the notion of invariants to arbitrary transition
systems. Note that imposing the requirement δ(q, A) ̸= ∅is not a severe restriction, as
any NFA can be easily transformed into an equivalent one that satisﬁes this property by
introducing a state qtrap and adding transition q
A
−−→qtrap to A whenever δ(q, A) = ∅or
q = qtrap. We ﬁnally remark that for the algorithm for invariant checking, it is not of any
relevance whether terminal states exist or not.
Example 4.18.
A Product Automaton
The language of the minimal bad preﬁxes of the safety property “each red light phase

166
Regular Properties
red
yellow
red/yellow
green
q0
q1
qF
red
yellow ∧¬red
¬yellow
¬red ∧¬yellow
⟨green, q0⟩
⟨red/yellow, q0⟩
⟨yellow, q1⟩
⟨red, q0⟩
yellow
Figure 4.6: German traﬃc light (left upper ﬁgure), an NFA (right upper ﬁgure), and their
product (lower ﬁgure).
is preceded by a yellow light phase” is accepted by the DFA A indicated in Example
4.14 (page 162).
We consider a German traﬃc light, which besides the usual possible
colors red, green, and yellow, has the possibility to indicate red and yellow simultaneously
indicating “green light soon”. The transition system GermanTrLight thus has four states
with the usual transitions red →red+yellow, red+yellow →green, green →yellow,
and yellow →red. Let AP = { red, yellow } indicating the corresponding light phases.
The labeling is deﬁned as follows: L(red) = { red }, L(yellow) = { yellow }, L(green) =
∅= L(red+yellow). The product transition system GermanTrLight ⊗A consists of four
reachable states (see Figure 4.6). As action labels are not relevant here, they are omitted.
The following theorem shows that the veriﬁcation of a regular safety property can be
reduced to checking an invariant in the product.
Let TS and A be as before. Let Pinv(A) be the invariant over AP′ = 2Q which is deﬁned
by the propositional formula

q∈F
¬ q.
In the sequel, we often write ¬ F as shorthand for 
q∈F ¬ q. Stated in words, ¬F holds
in all nonaccept states.

Model-Checking Regular Safety Properties
167
Theorem 4.19.
Veriﬁcation of Regular Safety Properties
For transition system TS over AP, NFA A with alphabet 2AP as before, and regular safety
property Psafe over AP such that L(A) equals the set of (minimal) bad preﬁxes of Psafe,
the following statements are equivalent:
(a) TS |= Psafe
(b) Tracesﬁn(TS) ∩L(A) = ∅
(c) TS ⊗A |= Pinv(A)
Proof: Let TS = (S, Act, →, I, AP, L) and A = (Q, 2AP, δ, Q0, F).
The equivalence of (a) and (b) follows immediately by Lemma 3.25 (page 114). To establish
the equivalence of (a), (b), and (c), we show
(c) =⇒(a) : TS ̸|= Psafe
implies
TS ⊗A ̸|= Pinv(A)
and
(b) =⇒(c) : TS ⊗A ̸|= Pinv(A)
implies
Tracesﬁn(TS) ∩L(A) ̸= ∅.
Proof of “(c) =⇒(a)”: If TS ̸|= Psafe, then there is a ﬁnite initial path fragment π =
s0 s1 . . . sn in TS with
trace(π)
=
L(s0) L(s1) . . . L(sn) ∈L(A).
Since trace(π) ∈L(A), there exists an accepting run q0 q1 . . . qn+1 of A for trace(π).
Accordingly
q0 ∈Q0 and qi
L(si)
−−−−→qi+1 for all 0 ⩽i ⩽n, and qn+1 ∈F.
Thus, ⟨s0, q1⟩⟨s1, q2⟩. . . ⟨sn, qn+1⟩is an initial path fragment in TS ⊗A with
⟨sn, qn+1⟩̸|= ¬F.
It thus follows that TS ⊗A ̸|= Pinv(A).
Proof of “(b) =⇒(c)”: Let TS ⊗A ̸|= Pinv(A). Then there exists an initial path fragment
⟨s0, q1⟩. . . ⟨sn, qn+1⟩
in TS ⊗A with qn+1 ∈F, and q1, . . . , qn ̸∈F.
Besides, s0 s1 . . . sn is an initial path
fragment in TS. Further,

168
Regular Properties
qi
L(si)
−−−−→qi+1 for all 0 ⩽i ⩽n.
Since ⟨s0, q1⟩is an initial state of TS ⊗A, there is an initial state q0 in A such that
q0
L(s0)
−−−−→q1. Sequence q0 q1 . . . qn+1 is thus an accepting run for trace(s0 s1 . . . sn). Thus,
trace(s0 s1 . . . sn) ∈Tracesﬁn(TS) ∩L(A)
which yields Tracesﬁn(TS) ∩L(A) ̸= ∅.
Stated in words, Theorem 4.19 yields that in order to check the transition system TS
versus the regular safety property Psafe, it suﬃces to check whether no state ⟨s, q⟩in
TS ⊗A is reachable where the A-component q is an accept state in A. This invariant
“visit never an accept state in A” (formally given by the invariant condition Φ = ¬F)
can be checked using a depth-ﬁrst search approach as described in detail in Algorithm 4
(page 110). Note that in case the safety property is refuted, the invariant checking algo-
rithm provides a counterexample. This counterexample is in fact a ﬁnite path fragment
⟨s0, q1⟩⟨s1, q2⟩. . . ⟨sn, qn+1⟩in the transition system TS ⊗A that leads to an accept state.
The projection to the states in TS yields an initial ﬁnite path fragment s0 s1 . . . sn in TS
where the induced trace trace(s0s1 . . . sn) ∈(2AP)∗is accepted by A (since it has an ac-
cepting run of the form q0 q1 . . . qn+1). Thus, trace(s0 s1 . . . sn) is a bad preﬁx for Psafe.
Hence, s0 s1 . . . sn yields a useful error indication since trace(π) /∈Psafe for all paths π in
TS that start with the preﬁx s0 s1 . . . sn.
Corollary 4.20.
Let TS, A, and Psafe be as in Theorem 4.19. Then, for each initial path fragment ⟨s0, q1⟩. . .
⟨sn, qn+1⟩of TS ⊗A:
q1, . . . , qn ̸∈F and qn+1 ∈F
implies
trace(s0 s1 . . . sn) ∈L(A).
As a result, the skeleton in Algorithm 5 can be used to check a regular safety property
against a transition system and to report a counterexample (i.e., ﬁnite initial path fragment
in TS inducing a bad preﬁx) as diagnostic feedback if the safety property does not hold
for TS.
Example 4.21.
Checking a Regular Safety Property for the Traﬃc Light
Consider again the German traﬃc light system and the regular safety property Psafe

Model-Checking Regular Safety Properties
169
Algorithm 5 Model-checking algorithm for regular safety properties
Input: ﬁnite transition system TS and regular safety property Psafe
Output: true if TS |= Psafe. Otherwise false plus a counterexample for Psafe.
Let NFA A (with accept states F) be such that L(A) = bad preﬁxes of Psafe
Construct the product transition system TS ⊗A
Check the invariant Pinv(A) with proposition ¬F = 
q∈F ¬q on TS ⊗A.
if TS ⊗A |= Pinv(A) then
return true
else
Determine an initial path fragment ⟨s0, q1⟩. . . ⟨sn, qn+1⟩of TS ⊗A with qn+1 ∈F
return (false, s0 s1 . . . sn)
ﬁ
that each red light phase should be immediately preceded by a yellow light phase. The
transition system of the traﬃc light, the NFA accepting the bad preﬁxes of the safety
property, as well as their product automaton, are depicted in Figure 4.6 (page 166). To
check the validity of Psafe, only the second component of the states ⟨s, q⟩is relevant. The
fact that no state of the form ⟨. . . , qF ⟩is reachable ensures the invariant ¬qF to hold in
all reachable states. Thus GermanTrLight |= Psafe.
If the traﬃc light is modiﬁed such that the state “red” is the initial state (instead of
“green”), then we obtain a transition system that violates Psafe. Actually, in this case
the invariant ¬qF is already violated in the initial state of the resulting product transition
system that has the following form:
⟨red, δ(q0, {red})⟩= ⟨red, qF ⟩.
We conclude this part by considering the worst-case time and space complexity of the
automata-based algorithm for checking regular safety properties.
Theorem 4.22.
Complexity of Verifying Regular Safety Properties
The time and space complexity of Algorithm 5 is in O(|TS|·|A|) where |TS| and |A| denote
the number of states and transitions in TS and A, respectively.
Assuming an generation of the reachable states of TS from a syntactic description of the
processes, the above bound also holds if |TS| denotes the size of the reachable fragment
of TS.

170
Regular Properties
Proof: Follows directly from the fact that the number of states in the product automaton
TS⊗A is in O(|S|·|Q|) (where S and Q denote the state space of TS and A, respectively)
and the fact that the time and space complexity of invariant checking is linear in the
number of states and transitions of the transition system TS ⊗A. (Thus, we can even
establish the bound O(|S|·|Q| + | →|·|δ|) for the runtime where | →| denotes the number
of transitions in TS and |δ| the number of transitions in A.)
4.3
Automata on Inﬁnite Words
Finite-state automata accept ﬁnite words, i.e., sequences of symbols of ﬁnite length, and
yield the basis for checking regular safety properties. In this and the following sections,
these ideas are generalized toward a more general class of LT properties. These include
regular safety, various liveness properties, but also many other properties that are relevant
to formalize the requirements for “realistic” systems. The rough idea is to consider variants
of NFAs, called nondeterministic B¨uchi automata (NBAs), which serve as acceptors for
languages of inﬁnite words. It will be established that if we are given a nondeterministic
B¨uchi automaton A that speciﬁes the “bad traces” (i.e., that accepts the complement
of the LT property P to be veriﬁed), then a graph analysis in the product of the given
transition system TS and the automaton A suﬃces to either establish or disprove TS |= P.
Whereas for regular safety properties a reduction to invariant checking (i.e., a depth-ﬁrst
search) is possible, the graph algorithms needed here serve to check a so-called persistence
property. Such properties state that eventually for ever a certain proposition holds.
We ﬁrst introduce the “ω-counterpart” to regular languages, both by introducing ω-regular
expressions (Section 4.3.1) and nondeterministic B¨uchi automata (see Section 4.3.2). Vari-
ants of nondeterministic B¨uchi automata will be discussed in Sections 4.3.3 and 4.3.4.
4.3.1
ω-Regular Languages and Properties
Inﬁnite words over the alphabet Σ are inﬁnite sequences A0 A1 A2 . . . of symbols Ai ∈Σ.
Σω denotes the set of all inﬁnite words over Σ. As before, the Greek letter σ will be
used for inﬁnite words, while w, v, u range over ﬁnite words. Any subset of Σω is called a
language of inﬁnite words, sometimes also called an ω-language. In the sequel, the notion
of a language will be used for any subset of Σ∗∪Σω. Languages will be denoted by the
symbol L.

Automata on Inﬁnite Words
171
To reason about languages of inﬁnite words, the basic operations of regular expressions
(union, concatenation, and ﬁnite repetition) are extended by inﬁnite repetition, denoted
by the Greek letter ω.2 For instance, the inﬁnite repetition of the ﬁnite word AB yields
the inﬁnite word ABABABABAB . . . (ad inﬁnitum) and is denoted by (AB)ω. For the
special case of the empty word, we have εω = ε. For an inﬁnite word, inﬁnite repetition
has no eﬀect, that is, σω = σ if σ ∈Σω. Note that the ﬁnite repetition of a word results
in a language of ﬁnite words, i.e., a subset of Σ∗, whereas inﬁnite repetition of a (ﬁnite or
inﬁnite) word results in a single word.
Inﬁnite repetition can be lifted to languages as follows. For language L ⊆Σ∗, let Lω be
the set of words in Σ∗∪Σω that arise from the inﬁnite concatenation of (arbitrary) words
in Σ, i.e.,
Lω = {w1w2w3 . . . | wi ∈L, i ⩾1}.
The result is an ω-language, provided that L ⊆Σ+, i.e., L does not contain the empty
word ε.
However, in the sequel, we only need the ω-operator applied to languages of
ﬁnite words that do not contain the empty word. In this case, i.e., for L ⊆Σ+, we have
Lω ⊆Σω.
In the following deﬁnition, the concatenation operator L1.L2 is used that combines a
language L1 of ﬁnite words with a language L2 of inﬁnite words. It is deﬁned by L1.L2 =
{wσ | w ∈L1, σ ∈L2}.
Deﬁnition 4.23.
ω-Regular Expression
An ω-regular expression G over the alphabet Σ has the form
G = E1.Fω
1 + . . . + En.Fω
n
where n ⩾1 and E1, . . . , En, F1, . . . , Fn are regular expressions over Σ such that ε /∈L(Fi),
for all 1 ⩽i ⩽n.
The semantics of the ω-regular expression G is a language of inﬁnite words, deﬁned by
Lω(G) = L(E1).L(F1)ω ∪. . . ∪L(En).L(Fn)ω
where L(E) ⊆Σ∗denotes the language (of ﬁnite words) induced by the regular expression
E (see page 914).
Two ω-regular expressions G1 and G2 are equivalent, denoted G1 ≡G2, if Lω(G1) = Lω(G2).
2The symbol ω denotes the ﬁrst inﬁnite ordinal. It already appeared in the notation Σω for the set of
inﬁnite words over the alphabet Σ.

172
Regular Properties
Examples for ω-regular expressions over the alphabet Σ = { A, B, C } are
(A + B)∗A(AAB + C)ω
or
A(B + C)∗Aω + B(A + C)ω.
If E is a regular expression with ε /∈L(E), then also Eω can be viewed as an ω-regular
expression since it can be identiﬁed with E.Eω or ε.Eω.
Note that we have L(E)ω =
L(E.Eω) = L(ε.Eω).
Deﬁnition 4.24.
ω-Regular Language
A language L ⊆Σω is called ω-regular if L = Lω(G) for some ω-regular expression G over
Σ.
For instance, the language consisting of all inﬁnite words over {A, B} that contain inﬁnitely
many A’s is ω-regular since it is given by the ω-regular expression (B∗A)ω. The language
consisting of all inﬁnite words over {A, B} that contain only ﬁnitely many A’s is ω-regular
too. A corresponding ω-regular expression is (A+B)∗Bω. The empty set is ω-regular since
it is obtained, e.g., by the ω-regular expression ∅ω. More generally, if L ⊆Σ∗is regular
and L′ is ω-regular, then Lω and L.L′ are ω-regular.
ω-Regular languages possess several closure properties: they are closed under union, inter-
section, and complementation. The argument for union is obvious from the deﬁnition by
ω-regular expressions. The proof for the intersection will be provided later; see Corollary
4.60 on page 198. The more advanced proof for complementation is not provided in this
monograph. We refer the interested reader to [174] that covers also other properties of
ω-regular languages and various other automata models.
The concepts of ω-regular languages play an important role in veriﬁcation since most
relevant LT properties are ω-regular:
Deﬁnition 4.25.
ω-Regular Properties
LT property P over AP is called ω-regular if P is an ω-regular language over the alphabet
2AP.
For instance, for AP = { a, b }, the invariant Pinv induced by the proposition Φ = a ∨¬b
is an ω-regular property since
Pinv
=

A0A1A2 . . . ∈(2AP)ω | ∀i ⩾0. (a ∈Ai or b /∈Ai)

=

A0A1A2 . . . ∈(2AP)ω | ∀i ⩾0. (Ai ∈{{}, {a}, {a, b}}


Automata on Inﬁnite Words
173
is given by the ω-regular expression E = ({}+{a}+{a, b})ω over the alphabet Σ = 2AP =
{{}, {a}, {b}, {a, b}}. In fact, any invariant over AP is ω-regular (the set AP of atomic
propositions is arbitrary) as it can be described by the ω-regular expression Φω where Φ
denotes the underlying propositional formula (that has to hold for all reachable states)
and is identiﬁed with the regular expression given by the sum of all A ⊆AP with A |= Φ.
Also, any regular safety property Psafe is an ω-regular property. This follows from the fact
that the complement language
(2AP)ω \ Psafe = BadPref(Psafe)



regular
.(2AP)ω
is an ω-regular language. The result that ω-regular languages are closed under comple-
mentation (stated above, in the end of Section 4.3.1 on page 172) yields the claim.
Example 4.26.
Mutual Exclusion
Another example of an ω-regular property is the property given by the informal statement
“process P visits its critical section inﬁnitely often” which, for AP = { wait, crit }, can be
formalized by the ω-regular expression:
(( {} + { wait }



negative literal ¬crit
)∗.({ crit } + { wait, crit }



positive literal crit
))ω.
When allowing a somewhat sloppy notation using propositional formulae, the above ex-
pression may be rewritten into ((¬crit)∗.crit)ω.
Starvation freedom in the sense of “whenever process P is waiting then it will enter its
critical section eventually later” is an ω-regular property as it can be described by
((¬wait)∗.wait.true∗.crit)ω + ((¬wait)∗.wait.true∗.crit)∗.(¬wait)ω
which is a short form for the ω-regular expression over AP = { wait, crit } that results by
replacing ¬wait with {} + {crit}, wait with {wait} + {wait, crit}, true with {} + {crit} +
{wait} + {wait, crit}, and crit with {crit} + {wait, crit}. Intuitively, the ﬁrst summand in
the above expression stands for the case where P requests and enters its critical section
inﬁnitely often, while the second summand stands for the case where P is in its waiting
phase only ﬁnitely many times.
4.3.2
Nondeterministic B¨uchi Automata
The issue now is to provide a kind of automaton that is suited for accepting ω-regular
languages. Finite automata are not adequate for this purpose as they operate on ﬁnite

174
Regular Properties
words, while we need an acceptor for inﬁnite words. Automata models that recognize
languages of inﬁnite words are called ω-automata. The accepting runs of an ω-automaton
have to “check” the entire input word (and not just a ﬁnite preﬁx thereof), and thus have
to be inﬁnite. This implies that acceptance criteria for inﬁnite runs are needed.
In this monograph, the simplest variant of ω-automata, called nondeterministic B¨uchi
automata (NBAs), suﬃces. The syntax of NBAs is exactly the same as for nondeterministic
ﬁnite automata (NFAs). NBAs and NFAs diﬀer, however, in their semantics: the accepted
language of an NFA A is a language of ﬁnite words, i.e., L(A) ⊆Σ∗, whereas the accepted
language of NBA A (denoted Lω(A) is an ω-language, i.e., Lω(A) ⊆Σω. The intuitive
meaning of the acceptance criterion named after B¨uchi is that the accept set of A (i.e., the
set of accept states in A) has to be visited inﬁnitely often. Thus, the accepted language
Lω(A) consists of all inﬁnite words that have a run in which some accept state is visited
inﬁnitely often.
Deﬁnition 4.27.
Nondeterministic B¨uchi Automaton (NBA)
A nondeterministic B¨uchi automaton (NBA) A is a tuple A = (Q, Σ, δ, Q0, F) where
• Q is a ﬁnite set of states,
• Σ is an alphabet,
• δ : Q × Σ →2Q is a transition function,
• Q0 ⊆Q is a set of initial states, and
• F ⊆Q is a set of accept (or: ﬁnal) states, called the acceptance set.
A run for σ = A0A1A2 . . . ∈Σω denotes an inﬁnite sequence q0 q1 q2 . . . of states in A such
that q0 ∈Q0 and qi
Ai
−−→qi+1 for i ⩾0.
Run q0 q1 q2 . . . is accepting if qi ∈F for inﬁnitely
many indices i ∈IN.
The accepted language of A is
Lω(A) = { σ ∈Σω | there exists an accepting run for σ in A }.
The size of A, denoted |A|, is deﬁned as the number of states and transitions in A.
As for an NFA, we identify the transition function δ with the induced transition relation
→⊆Q × Σ × Q which is given by
q
A
−−→p if and only if p ∈δ(q, A).

Automata on Inﬁnite Words
175
Since the state space Q of an NBA A is ﬁnite, each run for an inﬁnite word σ ∈Σω is
inﬁnite, and hence visits some state q ∈Q inﬁnitely often. Acceptance of a run depends
on whether or not the set of all states that appear inﬁnitely often in the given run contains
an accept state. The deﬁnition of an NBA allows for the special case where F = ∅, which
means that there are no accept states. Clearly, in this case, no run is accepting. Thus
Lω(A) = ∅if F = ∅. There are also no accepting runs whenever, Q0 = ∅as in this case,
no word has a run.
Example 4.28.
Consider the NBA of Figure 4.7 with the alphabet Σ = {A, B, C}. The word Cω has only
A
B
C
B
B
q3
q2
q1
Figure 4.7: An example of an NBA.
one run in A, namely q1 q1 q1 q1 . . ., or in short, qω
1 . Some other runs are q1 q2 qω
3 for the
word ABω, (q1 q1 q2 q3)ω for the word (CABB)ω, and (q1 q2 q3)n qω
1 for the word (ABB)nCω
where n ⩾0.
The runs that go inﬁnitely often through the accept state q3 are accepting. For instance,
q1 q2 qω
3 and (q1 q1 q2 q3)ω are accepting runs. qω
1 is not an accepting run as it never visits
the accept state q3, while runs of the form (q1 q2 q3)n qω
1 are not accepting as they visit the
accept state q3 only ﬁnitely many times. The language accepted by this NBA is given by
the ω-regular expression:
C∗AB

B+ + BC∗AB
ω
Later in this chapter (page 198 ﬀ.), NBAs are used for the veriﬁcation of ω-regular prop-
erties – in the same vein as NFAs were exploited for the veriﬁcation of regular safety
properties. In that case, Σ is of the form Σ = 2AP. As explained on page 159, proposi-
tional logic formulae are used as a shorthand notation for the transitions of such NBAs.
For instance, if AP = { a, b }, then the label a ∨b for an edge from q to p means that there
are three transitions from q to p: one for the symbol { a }, one for the symbol { b }, and
one for the symbol { a, b }.

176
Regular Properties
Example 4.29.
Inﬁnitely Often Green
Let AP = { green, red } or any other set containing the proposition green. The language of
words σ = A0 A1 . . . ∈2AP satisfying the LT property “inﬁnitely often green” is accepted
by the NBA A depicted in Figure 4.8.
q0
q1
green
¬green
¬green
green
Figure 4.8: An NBA accepting “inﬁnitely often green”.
The automaton A is in the accept state q1 if and only if the last input set of symbols
(i.e., the last set Ai) contains the propositional symbol green. Therefore, Lω(A) is exactly
the set of all inﬁnite words A0 A1 . . . with inﬁnitely many sets Ai with green ∈Ai. For
example, for the input word
σ = { green } { } { green } { } { green } { } . . .
we obtain the accepting run q0 q1 q0 q1 . . .. The same run q0 q1 q0 q1 . . . is obtained for the
word
σ′ = ({ green, red } { } { green } { red })ω
or any other word A0 A1 A2 . . . ∈(2AP)ω with green ∈A2j and green /∈A2j+1 for all
j ⩾0.
Example 4.30.
Request Response
Many liveness properties are of the form
“Whenever some event a occurs,
some event b will eventually occur in the future”
For example, the property “once a request is provided, eventually a response occurs” is of
this form. An associated NBA with propositions req and resp is indicated in Figure 4.9.
It is assumed that { req, resp } ⊆AP, i.e., we assume the NBA to have alphabet 2AP with
AP containing at least req and resp. It is not diﬃcult to see that this NBA accepts exactly
those sequences in which each request is always eventually followed by a response. Note
that an inﬁnite trace in which only responses occur, but never a request (or ﬁnitely many
requests) is also accepting.

Automata on Inﬁnite Words
177
q0
q1
req ∧¬resp
resp
¬req ∨resp
¬resp
Figure 4.9: An NBA accepting “on each request, eventually a response is provided”.
Remark 4.31.
NBA and Regular Safety Properties
In Section 4.2, we have seen that there is a strong relationship between bad preﬁxes of
regular safety properties and NFAs. In fact, there is also a strong relationship between
NBAs and regular safety properties. This can be seen as follows. Let Psafe be a regular
safety property over AP and A = (Q, 2AP, δ, Q0, F) an NFA recognizing the language of
all bad preﬁxes of Psafe. Each accept state qF ∈F may be assumed to be a trapping state,
i.e., qF
A
−−→qF for all A ⊆AP. This assumption is justiﬁed since each extension of a bad
preﬁx is a bad preﬁx. (As a bad preﬁx contains a ”bad” event that causes the violation
of Psafe, each extension of this preﬁx contains this event.)
When interpreting A as an NBA, it accepts exactly the inﬁnite words σ ∈(2AP)ω that
violate Psafe, i.e.,
Lω(A) = (2AP)ω \ Psafe.
Here, it is important that A accepts all bad preﬁxes, and not just the minimal ones (see
Exercise 4.18).
If A is a total deterministic automaton, i.e., in each state there is a single possible transition
for each input symbol, then the NBA obtained by
A =

Q, 2AP, δ, Q0, Q \ F

accepts the language Lω

A

= Psafe.
This is exempliﬁed by means of a concrete case.
Consider again the property “a red
light phase should be immediately preceded by a yellow light phase” for a traﬃc light
system. We have seen before (see Example 4.13 on page 161) that the bad preﬁxes of
this safety property constitute a regular language and are accepted by the NFA shown
in Figure 4.10.
Note that this NFA is total.
Applying the procedure described just
above to this automaton yields the NBA depicted in Figure 4.11. It is easy to see that
the inﬁnite language accepted by this NBA consists exactly of all sequences of the form
σ = A0 A1 A2 . . . such that red ∈Aj implies j > 0 and yellow ∈Aj−1.
The accepted languages of the NBA examples have so far been ω-regular. It is now shown

178
Regular Properties
q1
q0
q2
red
¬red ∧yellow
¬yellow
yellow
¬red ∧¬yellow
true
Figure 4.10: An NFA for the set of all bad preﬁxes of Psafe.
q1
q0
q2
red
¬red ∧yellow
¬yellow
yellow
¬red ∧¬yellow
true
Figure 4.11: An NBA for the LT property “red should be preceded by yellow”.
that this holds for any NBA. Moreover, it will be shown that any ω-regular language can
be described by an NBA. Thus, NBAs are as expressive as ω-regular languages.
This
result is analogous to the fact that NFAs are as expressive as regular languages, and thus
may act as an alternative formalism to describe regular languages. In the same spirit,
NBAs are an alternative formalism for describing ω-regular languages. This is captured
by the following theorem.
Theorem 4.32.
NBAs and ω-Regular Languages
The class of languages accepted by NBAs agrees with the class of ω-regular languages.
The proof of Theorem 4.32 amounts to showing that (1) any ω-regular language is rec-
ognized by an NBA (see Corollary 4.38 on page 182) and (2) that the language Lω(A)
accepted by the NBA A is ω-regular (see Lemma 4.39 on page 183).
We ﬁrst consider the statement that ω-regular languages are contained in the class of
languages recognized by an NBA. The proof of this fact is divided into the following
three steps that rely on operations for NBAs to mimic the building blocks of ω-regular
expressions:
(1) For any NBA A1 and A2 there exists an NBA accepting Lω(A1) ∪Lω(A2).
(2) For any regular language L (of ﬁnite words) with ε /∈L there exists an NBA accepting
Lω.

Automata on Inﬁnite Words
179
(3) For regular language L and NBA A′ there exists an NBA accepting L.Lω(A′).
These three results that are proven below form the basic ingredients to construct an
NBA for a given ω-regular expression G = E1.Fω
1 + . . . + En.Fω
n with ε ̸∈Fi. This works as
follows. As an initial step, (2) is exploited to construct NBA A′
1, . . . , A′
n for the expressions
Fω
1 , . . . , Fω
n. Then, (3) is used to construct an NBA for the expressions Ei.Fω
i , for 1 ⩽i ⩽n.
Finally, these NBA are combined using (1) to obtain an NBA for G.
Let us start with the union operator on two NBAs. Let A1 = (Q1, Σ, δ1, Q0,1, F1) and
A2 = (Q2, Σ, δ2, Q0,2, F2) be NBAs over the same alphabet Σ. Without loss of generality,
it may be assumed that the state spaces Q1 and Q2 of A1 and A2 are disjoint, i.e.,
Q1 ∩Q2 = ∅. Let A1 + A2 be the NBA with the joint state spaces of A1 and A2, and
with all transitions in A1 and A2. The initial states of A are the initial states of A1 and
A2, and similarly, the accept states of A are the accept states of A1 and A2. That is,
A1 + A2 = (Q1 ∪Q2, Σ, δ, Q0,1 ∪Q0,2, F1 ∪F2)
where δ(q, A) = δi(q, A) if q ∈Qi for i=1, 2. Clearly, any accepting run in Ai is also an
accepting run in A1 + A2, and vice versa, each accepting run in A1 + A2 is an accepting
run in either A1 or A2. This yields Lω(A1 + A2) = Lω(A1) ∪Lω(A2). We thus obtain:
Lemma 4.33.
Union Operator on NBA
For NBA A1 and A2 (both over the alphabet Σ) there exists an NBA A such that:
Lω(A) = Lω(A1) ∪Lω(A2)
and
|A| = O(|A1| + |A2|).
Now consider (2). We will show that for any regular language L ⊆Σ∗there exists an NBA
over the alphabet Σ that accepts the ω-regular language Lω. To do so, we start with a
representation of L by an NFA A.
Lemma 4.34.
ω-Operator for NFA
For each NFA A with ε /∈L(A) there exists an NBA A′ such that
Lω(A′) = L(A)ω
and
|A′| = O(|A|).
Proof: Let A = (Q, Σ, δ, Q0, F) be an NFA with ε /∈L(A). Without loss of generality, we
may assume that all initial states in A have no incoming transitions and are not accepting.

180
Regular Properties
Any A that does not possess this property, can be modiﬁed into an equivalent NFA as
follows. Add a new initial (nonaccept) state qnew to Q with the transitions qnew
A
−−→q if
and only if q0
A
−−→q for some initial state q0 ∈Q0. All other transitions, as well as the
accept states, remain unchanged. The state qnew is the single initial state of the modiﬁed
NFA, is not accept, and, clearly, has no incoming transitions. This modiﬁcation neither
aﬀects the accepted language nor the asymptotic size of A.
In the sequel, we assume that A = (Q, Σ, δ, Q0, F) is an NFA such that the states in
Q0 do not have any incoming transitions and Q0 ∩F = ∅. We now construct an NBA
A′ = (Q, Σ, δ′, Q′
0, F ′) with Lω(A′) = L(A)ω. The basic idea of the construction of A′ is
to add for any transition in A that leads to an accept state new transitions leading to the
initial states of A. Formally, the transition relation δ′ in the NBA A′ is given by
δ′(q, A) =
	 δ(q, A)
if δ(q, A) ∩F = ∅
δ(q, A) ∪Q0
otherwise.
The initial states in the NBA A′ agree with the initial states in A, i.e., Q′
0 = Q0. These
are also the accept states in A′, i.e., F ′ = Q0.
Let us check that Lω(A′) = L(A)ω. This is proven as follows.
⊆: Assume that σ ∈Lω(A′) and let q0q1q2 . . . be an accepting run for σ in A′. Hence,
qi ∈F ′ = Q0 for inﬁnitely many indices i. Let i0 = 0 < i1 < i2 < . . . be the strictly
increasing sequence of natural numbers with { qi0, qi1, qi2, . . . } ⊆Q0 and qj /∈Q0 for all
j ∈IN \ { i0, i1, i2, . . . }. The word σ can be divided into inﬁnitely many nonempty ﬁnite
subwords wi ∈Σ∗yielding σ = w1w2w3 . . . such that qik ∈δ′∗(qik−1, wk) for all k ⩾1.
(The extension of δ′ to a function δ′∗: Q × Σ∗→2Q is as for an NFA, see page 154.) By
deﬁnition of A′ and since the states qik ∈Q0 do not have any predecessor in A, we get
δ∗(qik−1, wk) ∩F ̸= ∅. This yields wk ∈L(A) for all k ⩾1, which gives us σ ∈L(A)ω.
⊇: Let σ = w1w2w3 . . . ∈Σω such that wk ∈L(A) for all k ⩾1. For each k, we choose an
accepting run qk
0qk
1 . . . qk
nk for wk in A. Hence, qk
0 ∈Q0 and qk
nk ∈F. By deﬁnition of A′,
we have qk+1
0
∈δ′∗(qk
0, wk) for all k ⩾1. Thus,
q1
0 . . . q1
n1−1q2
0 . . . q2
n2−1q3
0 . . . q3
n3−1 . . .
is an accepting run for σ in A′. Hence, σ ∈Lω(A′).
Example 4.35.
ω-Operator for an NFA
Consider the NFA depicted in the left upper part of Figure 4.12. It accepts the language
A∗B. In order to obtain an NBA recognizing (A∗B)ω, we ﬁrst apply the transformation

Automata on Inﬁnite Words
181
q1
q0
B
A
qnew
q0
q1
A
A
B
B
qnew
q0
A
A
q1
B
B
B
B
Figure 4.12: From an NFA accepting A∗B to an NBA accepting (A∗B)ω.
as described in the proof of Lemma 4.34 to remove initial states that have an incoming
transition. This yields the NFA depicted in the right upper part of Figure 4.12. This
automaton can now be used to apply the construction of the required NBA as detailed in
the proof of Lemma 4.34. This yields the NBA depicted in the lower part of Figure 4.12.
It remains to provide a construction for task (3) above. Assume that we have NFA A for
the regular language L(A) and a given NBA A′ at our disposal. The proof of the following
lemma will describe a procedure to obtain an NBA for the ω-language L(A).Lω(A′).
Lemma 4.36.
Concatenation of an NFA and an NBA
For NFA A and NBA A′ (both over the alphabet Σ), there exists an NBA A′′ with
Lω(A′′) = L(A).Lω(A′)
and
|A′′| = O(|A| + |A′|).
Proof: Let A = (Q, Σ, δ, Q0, F) be an NFA and A′ = (Q′, Σ, δ′, Q′
0, F ′) an NBA with
Q ∩Q′ = ∅.
Let A′′ = (Q′′, Σ, δ′′, Q′′
0, F ′′) be the following NBA. The state space is
Q′′ = Q ∪Q′. The set of initial and accept states are given by
Q′′
0 =
	 Q0
if Q0 ∩F = ∅
Q0 ∪Q′
0
otherwise,

182
Regular Properties
and F ′′ = F ′ (set of accept state in the NBA A′). The transition function δ′′ is given by
δ′′(q, A) =
⎧
⎨
⎩
δ(q, A)
if q ∈Q and δ(q, A) ∩F = ∅
δ(q, A) ∪Q′
0
if q ∈Q and δ(q, A) ∩F ̸= ∅
δ′(q, A)
if q ∈Q′
It is now easy to check that A′′ fulﬁlls the desired conditions.
Example 4.37.
Concatenation of an NFA and an NBA
Consider the NFA A and the NBA A′ depicted in the left and right upper part of Fig-
ure 4.13, respectively. We have L(A) = (AB)∗and L(A′) = (A+B)∗BAω. Applying the
transformation as described in Lemma 4.36 yields the NBA depicted in the lower part of
Figure 4.13. It is not diﬃcult to assess that this NBA accepts indeed the concatenated
language (AB)∗(A+B)∗BAω.
A
B
B
A
A
B
A
B
B
A
A
B
B
Figure 4.13: Concatenation of an NFA and an NBA.
By Lemmas 4.33, 4.34, and 4.36 we obtain the ﬁrst part for the proof of Theorem 4.32:
Corollary 4.38.
NBA for ω-Regular Languages
For any ω-regular language L there exists an NBA A with Lω(A) = L.

Automata on Inﬁnite Words
183
The proof of the following lemma shows that the languages accepted by NBA can be
described by an ω-regular expression.
Lemma 4.39.
NBAs Accept ω-Regular Languages
For each NBA A, the accepted language Lω(A) is ω-regular.
Proof: Let A = (Q, Σ, δ, Q0, F) be an NBA. For states q, p ∈Q, let Aqp be the NFA
(Q, Σ, δ, { q }, { p }).
Then, Aqp recognizes the regular language consisting of all ﬁnite
words w ∈Σ∗that have a run in A leading from q to p, that is,
Lqp
def
= L(Aqp) = { w ∈Σ∗| p ∈δ∗(q, w) }.
Consider a word σ ∈Lω(A) and an accepting run q0q1 . . . for σ in A. Some accept state
q ∈F appears inﬁnitely often in this run. Hence, we may split σ into nonempty ﬁnite
subwords w0, w1, w2, w3, . . . ∈Σ∗such that w0 ∈Lq0q and wk ∈Lqq for all k ⩾1 and
σ =
w0

∈Lq0q
w1

∈Lqq
w2

∈Lqq
w3

∈Lqq
. . . . . .
On the other hand, any inﬁnite word σ which has the form σ = w0w1w2 . . . where
the wk’s are nonempty ﬁnite words with w0 ∈Lq0q for some initial state q0 ∈Q0 and
{w1, w2, w3, . . .} ⊆Lqq for some accept state q ∈F has an accepting run in A. This yields
σ ∈Lω(A)
if and only if
∃q0 ∈Q0 ∃q ∈F. σ ∈Lq0q (Lqq \ {ε})ω .
Hence, Lω(A) agrees with the language

q0∈Q0,q∈F
Lq0q. (Lqq \ {ε})ω
which is ω-regular.
Example 4.40.
From NBA to ω-Regular Expression
For the NBA A shown in Figure 4.7 on page 175, a corresponding ω-regular expression is
obtained by
Lq1q3.(Lq3q3 \ {ε})ω
since q1 is the unique initial state and q3 the unique accept state in A.
The regular
language Lq3q3 \ {ε} can be described by the expression (B+ + BC∗AB)+, while Lq1q3 is
given by (C∗AB(B∗+BC∗AB)∗B)∗C∗AB. Hence, Lω(A) = Lω(G) where G is the ω-regular
expression:
G =
(C∗AB(B∗+ BC∗AB)∗B)∗C∗AB



Lq1q3
((B+ + BC∗AB)+)ω



(Lq3q3\{ε})ω
.

184
Regular Properties
The thus obtained expression G can be simpliﬁed to the equivalent expression:
C∗AB(B+ + BC∗AB)ω.
The above lemma, together with Corollary 4.38, completes the proof of Theorem 4.32
stating the equivalence of the class of languages accepted by NBAs and the class of all
ω-regular languages. Thus, NBAs and ω-regular languages are equally expressive.
A fundamental question for any type of automata model is the question whether for a given
automaton A the accepted language is empty.
For nondeterministic B¨uchi automata,
an analysis of the underlying directed graph by means of standard graph algorithms is
suﬃcient, as we will show now.
Lemma 4.41.
Criterion for the Nonemptiness of an NBA
Let A = (Q, Σ, δ, Q0, F) be an NBA. Then, the following two statements are equivalent:
(a) Lω(A) ̸= ∅,
(b) There exists a reachable accept state q that belongs to a cycle in A. Formally,
∃q0 ∈Q0 ∃q ∈F ∃w ∈Σ∗∃v ∈Σ+. q ∈δ∗(q0, w) ∩δ∗(q, v).
Proof: (a) =⇒(b): Let σ = A0 A1 A2 . . . ∈Lω(A) and let q0 q1 q2 . . . be an accepting
run for σ in A. Let q ∈F be an accept state with q = qi for inﬁnitely many indices
i. Let i and j be two indices with 0 ⩽i < j and qi = qj = q. We consider the ﬁnite
words w = A0A1 . . . Ai−1 and v = AiAi+1 . . . Aj−1 and obtain q = qi ∈δ∗(q0, w) and
q = qj ∈δ∗(qi, v) = δ∗(q, v). Hence, (b) holds.
(b) =⇒(a): Let q0, q, w, v be as in statement (b). Then, the inﬁnite word σ = wvω has a
run of the form q0 . . . q . . . q . . . q . . . that inﬁnitely often contains q. Since q ∈F this run
is accepting which yields σ ∈Lω(A), and thus, Lω(A) ̸= ∅.
By the above lemma, the emptiness problem for NBAs can be solved by means of graph
algorithms that explore all reachable states and check whether they belong to a cycle. One
possibility to do so is to calculate the strongly connected components of the underlying
directed graph of A and to check whether there is at least one nontrivial strongly con-

Automata on Inﬁnite Words
185
nected component3 that is reachable (from at least one of the initial states) and contains
an accept state. Since the strongly connected components of a (ﬁnite) directed graph can
be computed in time linear in the number of states and edges, the time complexity of this
algorithm for the emptiness check of NBA A is linear in the size of A. An alternative
algorithm that also runs in time linear in the size of A, but avoids the explicit compu-
tation of the strongly connected components, can be derived from the results stated in
Section 4.4.2.
Theorem 4.42.
Checking Emptiness for NBA
The emptiness problem for NBA A can be solved in time O(|A|).
Since NBAs serve as a formalism for ω-regular languages, we may identify two B¨uchi
automata for the same language:
Deﬁnition 4.43.
Equivalence of NBA
Let A1 and A2 be two NBAs with the same alphabet. A1 and A2 are called equivalent,
denoted A1 ≡A2, if Lω(A1) = Lω(A2).
Example 4.44.
Equivalent NBA
As for other ﬁnite automata, equivalent NBAs can have a totally diﬀerent structure. For
example, consider the NBA shown in Figure 4.14 over the alphabet 2AP where AP =
{ a, b }. Both NBAs represent the liveness property “inﬁnitely often a and inﬁnitely often
b”, and thus, they are equivalent.
Remark 4.45.
NFA vs. NBA Equivalence
It is interesting to consider more carefully the relationship between the notions of equiv-
alence of NFAs and NBAs. Let A1 and A2 be two automata that we can regard as either
NFA or as NBA. To distinguish the equivalence symbol ≡for NFAs from that for NBAs we
will write in this example ≡NFA to denote the equivalence relation for NFA and the symbol
≡NBA to denote the equivalence relation for NBA, i.e., A1 ≡NFA A2 iﬀL(A1) = L(A2)
and A1 ≡NBA A2 iﬀLω(A1) = Lω(A2).
1. If A1 and A2 accept the same ﬁnite words, i.e., A1 ≡NFA A2, then this does not
mean that they also accept the same inﬁnite words. The following two automata
examples show this:
3A strongly connected component is nontrivial if it contains at least one edge. In fact, any cycle is
contained in a nontrivial strongly connected component, and vice versa, any nontrivial strongly connected
component contains a cycle that goes through all its states.

186
Regular Properties
q0
q2
q1
true
a
b
p0
p2
p3
b
true
¬b
¬a
true
true
p1
a
true
Figure 4.14: Two equivalent NBA.
A
A
A
A
A2
A1
We have L(A1) = L(A2) = { An | n ⩾1 }, but Lω(A1) = { Aω } and Lω(A2) = ∅.
Thus, A1 ≡NFA A2 but A1 ̸≡NBA A2.
2. If A1 and A2 accept the same inﬁnite words, i.e., A1 ≡NBA A2, then one might
expect that they would also accept the same ﬁnite words. This also turns out not
to be true. The following example shows this:
A
A
A2
A
A
A1
We have Lω(A1) = Lω(A2) = { Aω }, but L(A1) = { A2n | n ⩾0 } and L(A2) =
{ A2n+1 | n ⩾0 }.
3. If A1 and A2 are both deterministic (see Deﬁnition 4.9 on page 156), then A1 ≡NFA
A2 implies A1 ≡NBA A2. The reverse is, however, not true, as illustrated by the
previous example.

Automata on Inﬁnite Words
187
For technical reasons, it is often comfortable to assume for an NBA that for each state q
and for each input symbol A, there is a possible transition. Such an NBA can be seen to be
nonblocking since no matter how the nondeterministic choices are resolved, the automaton
cannot fail to consume the current input symbol.
Deﬁnition 4.46.
Nonblocking NBA
Let A = (Q, Σ, δ, Q0, F) be an NBA. A is called nonblocking if δ(q, A) ̸= ∅for all states
q and all symbols A ∈Σ.
Note that for a given nonblocking NBA A and input word σ ∈Σω, there is at least one
(inﬁnite) possibly nonaccepting run for σ in A. The following remark demonstrates that
it is not a restriction to assume a nonblocking NBA.
Remark 4.47.
Nonblocking NBA
For each NBA A there exists a nonblocking NBA trap(A) with |trap(A)| = O(|A|) and
A ≡trap(A).
Let us see how such a nonblocking NBA can be derived from A. NBA trap(A) is obtained
from A by inserting a nonaccept trapping state qtrap equipped with a self-loop for each
symbol in the alphabet Σ. For every symbol A ∈Σ for which state q in A does not have
an outgoing transition, a transition to qtrap is added. Formally, if A = (Q, Σ, δ, Q0, F),
then trap(A) = (Q′, Σ, δ′, Q′
0, F ′) as follows. Here, Q′ = Q ∪{ qtrap } where qtrap is a new
state (not in Q) that will be reached in A′ whenever A does not have a corresponding
transition. Formally, the transition relation δ′ of trap(A) is deﬁned by:
δ′(q, A) =
	 δ(q, A)
if q ∈Q and δ(q, A) ̸= ∅
{ qtrap }
otherwise
The initial and accept states are unchanged, i.e., Q′
0 = Q0 and F ′ = F. By deﬁnition,
trap(A) is nonblocking and – since the new trap state is nonaccepting – is equivalent to
A.
We conclude this subsection on automata over inﬁnite words with a few more comments
on B¨uchi automata and ω-regular languages. We ﬁrst study the subclass of deterministic
B¨uchi automata (Section 4.3.3 below) and then in Section 4.3.4 the class of NBA with a
more general acceptance condition consisting of several acceptance sets that have to be
visited inﬁnitely often.

188
Regular Properties
4.3.3
Deterministic B¨uchi Automata
An important diﬀerence between ﬁnite-state automata and B¨uchi automata is the ex-
pressive power of deterministic and nondeterministic automata. While for languages of
ﬁnite words, DFAs and NFAs have the same expressiveness, this does not hold for B¨uchi
automata.
The deﬁnition of a deterministic B¨uchi automaton is the same as for a DFA:
Deﬁnition 4.48.
Deterministic B¨uchi Automaton (DBA)
Let A = (Q, Σ, δ, Q0, F) be an NBA. A is called deterministic, if
|Q0| ⩽1
and
|δ(q, A)| ⩽1
for all q ∈Q and A ∈Σ. A is total if |Q0| = 1 and |δ(q, A)| = 1 for all q ∈Q and A ∈Σ.
Obviously, the behavior of a DBA for a given input word is deterministic: either eventually
the DBA will get stuck in some state as it fails to consume the current input symbol or
there is a unique (inﬁnite) run for the given input word. Total DBAs rule out the ﬁrst
alternative and ensure the existence of a unique run for every input word σ ∈Σω.
Example 4.49.
DBA for LT Properties
Figure 4.15 shows the DBA A′ (on the left) and the NBA A (on the right) over the alphabet
Σ = 2AP where AP = { a, b }. These automata are equivalent since both represent the LT
property ”always b and inﬁnitely often a”. Let δ be the transition function of A and δ′
q0
q1
a ∧b
¬a ∧b
¬a ∧b
a ∧b
r0
r1
b
a ∧b
b
a ∧b
Figure 4.15: An equivalent DBA A′ (left) and NBA A (right).
the transition function of A′. The NBA A is not deterministic since for all input symbols
containing a b, there is the possibility to move to either state r0 or r1. The DBA A′ is

Automata on Inﬁnite Words
189
deterministic. Note that both A′ and A are blocking, e.g., any state is blocking on an
input symbol containing ¬b.
As for deterministic ﬁnite automata, the usual notation is q′ = δ(q, A) (instead of {q′} =
δ(q, A)) and δ(q, A) = ⊥(undeﬁned), if δ(q, A) = ∅. Thus, the transition relation of a
DBA is understood as partial function δ : Q × Σ →Q. Total DBAs are often written
in the form (Q, Σ, δ, q0, F) where q0 is the unique initial state and δ is viewed as a total
function Q × Σ →Q. Since DBA can always be extended by a nonaccept trapping state
without changing the accepting language, it can be assumed without restriction that the
transition relation is total. For instance, Figure 4.16 shows an equivalent total DBA for
the DBA A′ in Figure 4.15 that is obtained by adding such a trapping state.
q0
q1
a ∧b
¬a ∧b
¬a ∧b
a ∧b
qtrap
¬b
¬b
true
Figure 4.16: A total DBA for ”always b and inﬁnitely often a”.
The transition function δ of a total DBA can be expanded to a total function δ∗: Q×Σ∗→
Q in the obvious way; see also page 157 for the transition function of a total DFA. That
is, let δ∗(q, ε) = q, δ∗(q, A) = δ(q, A) and
δ∗(q, A1A2 . . . An) = δ∗( δ(q, A1), A2 . . . An).
Then, for every inﬁnite word σ = A0 A1 A2 . . . ∈Σω, the run q0 q1 q2 . . . in A belonging to
σ is given by qi+1 = δ∗(q0, A0 . . . Ai) for all i ⩾0, where q0 is the unique initial state of A.
In particular, for total DBA A = (Q, Σ, δ, q0, F) the accepted language is given by
Lω(A) = { A0 A1 A2 . . . ∈Σω | δ∗(q0, A0 . . . Ai) ∈F for inﬁnitely many i }
As we have seen before, NFAs are as expressive as deterministic ones. However, NBAs
are more expressive than deterministic ones. That is, there do exist NBA for which there

190
Regular Properties
does not exist an equivalent deterministic one. Stated diﬀerently, while any ω-language
accepted by a DBA is ω-regular, there do exist ω-regular languages for which there does
not exist a DBA accepting it. An example of such ω-regular language is the language
given by the expression (A+B)∗Bω.
q0
q1
B
A
B
B
Figure 4.17: NBA for the ω-regular expression (A + B)∗Bω.
In fact, the language Lω( (A+B)∗Bω ) is accepted by a rather simple NBA, shown in Figure
4.17. The idea of this NBA is that given an input word σ = wBω where w ∈{A, B}∗the
automaton may stay in q0 and guess nondeterministically when the suﬃx consisting of B’s
starts and then moves to the accept state q1. This behavior, however, cannot be simulated
by a DBA as formally shown in the following theorem.
Theorem 4.50.
NBAs are More Powerful than DBAs
There does not exist a DBA A such that Lω(A) = Lω((A + B)∗Bω).
Proof: By contradiction. Assume that Lω((A + B)∗Bω) = Lω(A) for some DBA A =
(Q, Σ, δ, q0, F) with Σ = { A, B }. Note that since A is deterministic, δ∗can be considered
as a function of type Q × Σ∗→Q.
Since the word σ1 = Bω belongs to Lω((A + B)∗Bω) = Lω(A), there exists an accepting
state q1 ∈F and a n1 ∈IN⩾1 such that
(1)
δ∗(q0, Bn1) = q1 ∈F
.
(Since A is deterministic, q1 is uniquely determined.)
Now consider the word σ2 =
Bn1ABω
∈Lω((A + B)∗Bω) = Lω(A). Since σ2 is accepted by A, there exists an ac-
cepting state q2 ∈F and n2 ∈IN⩾1, such that
(2)
δ∗(q0, Bn1ABn2) = q2 ∈F
.
The word Bn1ABn2ABω is in Lω((A + B)∗Bω), and, thus, is accepted by A. So, there is
an accepting state q3 ∈F and n3 ∈IN⩾1 with

Automata on Inﬁnite Words
191
(3)
δ∗(q0, Bn1ABn2ABn3) = q3 ∈F.
Continuing this process, we obtain a sequence n1, n2, n3, . . . of natural numbers ⩾1 and
a sequence q1, q2, q3, . . . of accepting states such that
δ∗(q0, Bn1ABn2A . . . Bni−1ABni) = qi ∈F,
i ⩾1 . . .
Since there are only ﬁnitely many states, there exist i < j such that
δ∗(q0, Bn1A . . . ABni) = δ∗(q0, Bn1A . . . ABni . . . ABnj)
Thus A has an accepting run on
Bn1A . . . ABni (ABni+1A . . . ABnj)ω .
But this word has inﬁnitely many occurrences of A, and thus does not belong to Lω((A +
B)∗Bω). Contradiction.
Example 4.51.
The Need for Nondeterminism
In Examples 4.29 and 4.30, we provided DBAs for LT properties. To represent liveness
properties of the form “eventually forever”, the concept of nondeterminism is, however,
necessary. Consider the property “eventually forever a”, where a is some atomic proposi-
tion. Let { a } = AP, i.e., 2AP = {A, B} where A = {} and B = {a}. Then, the linear-time
property ”eventually forever a” is given by the ω-regular expression
(A + B)∗Bω = ({} + {a})∗{a}ω.
By Theorem 4.50, there is no DBA for ”eventually forever a”. On the other hand, this
property can be described by the NBA A depicted in Figure 4.18. (Note that state q2
could be omitted, as there is no accepting run that starts in q2.) Intuitively, A nondeter-
ministically decides (by means of an omniscient oracle) from which instant the proposition
a is continuously true. This behavior cannot be mimicked by a DBA.
q0
q1
q2
a
¬a
true
a
true
Figure 4.18: An NBA accepting “eventually forever a”.
The reader might wonder why the powerset construction known for ﬁnite automata (see
page 157) fails for B¨uchi automata. The deterministic automaton Adet obtained through

192
Regular Properties
the powerset construction allows simulating the given nondeterministic automaton A by
keeping track of the set Q′ of states that are reachable in A for any ﬁnite preﬁx of the given
input word. (This set Q′ is a state in Adet.) What is problematic here is the acceptance
condition: while for NFAs the information whether an accept state is reachable is suﬃcient,
for inﬁnite words we need one single run that passes an accept state inﬁnitely often. The
latter is not equivalent to the requirement that a state Q′ with Q′ ∩F ̸= ∅is visited
inﬁnitely often, since there might be inﬁnitely many possibilities (runs) to enter F at
diﬀerent time points, i.e., for diﬀerent preﬁxes of the input word. This, in fact, is the
case for the NBA in Figure 4.17.
For the input word σ = ABABA . . . = (AB)ω, the
automaton in Figure 4.17 can enter the accept state q1 after the second, fourth, sixth,
etc., symbol by staying in q0 for the ﬁrst 2n−1 symbols and moving with the nth B to
state q1 (for n = 1, 2, . . .). Thus, at inﬁnitely many positions there is the possibility to
enter F, although there is no run that visits q1 inﬁnitely often, since whenever q1 has
been entered the automaton A rejects when reading the next A. In fact, the powerset
construction applied to the NBA A in Figure 4.17 yields a DBA Adet with two reachable
states (namely {q0} and {q0, q1}) for the language consisting of all inﬁnite words with
inﬁnitely many B’s, but not for the language given by (A + B)∗Bω.
Another example that illustrates why the powerset construction fails for B¨uchi automata
is provided in Exercise 4.16 (page 225).
4.3.4
Generalized B¨uchi Automata
In several applications, other ω-automata types are useful as automata models for ω-
regular languages.
In fact, there are several variants of ω-automata that are equally
expressive as nondeterministic B¨uchi automata, although they use more general acceptance
conditions than the B¨uchi acceptance condition ”visit inﬁnitely often the acceptance set
F”. For some of these ω-automata types, the deterministic version has the full power of
ω-regular languages. These automata types are not relevant for the remaining chapters of
this monograph and will not be treated here. 4
For the purposes of this monograph, it suﬃces to consider a slight variant of nondeter-
ministic B¨uchi automata, called generalized nondeterministic B¨uchi automata, or GNBA
for short. The diﬀerence between an NBA and a GNBA is that the acceptance condition
for a GNBA requires to visit several sets F1, . . . , Fk inﬁnitely often. Formally, the syntax
of a GNBA is as for an NBA, except that the acceptance condition is a set F consisting
of ﬁnitely many acceptance sets F1, . . . , Fk with Fi ⊆Q. That is, if Q is the state space of
the automaton then the acceptance condition of a GNBA is an element F of 22Q. Recall
4In Chapter 10, deterministic Rabin automata will be used for representing ω-regular properties.

Automata on Inﬁnite Words
193
that for an NBA, it is an element F ∈2Q. The accepted language of a GNBA G consists
of all inﬁnite words which have an inﬁnite run in G that visits all sets Fi ∈F inﬁnitely
often. Thus, the acceptance criterion in a generalized B¨uchi automaton can be understood
as the conjunction of a number of B¨uchi acceptance conditions.
Deﬁnition 4.52.
Generalized NBA (GNBA)
A generalized NBA is a tuple G = (Q, Σ, δ, Q0, F) where Q, Σ, δ, Q0 are deﬁned as for an
NBA (see Deﬁnition 4.27 on page 174) and F is a (possibly empty) subset of 2Q.
The elements F ∈F are called acceptance sets. Runs in a GNBA are deﬁned as for an
NBA. That is, a run in G for the inﬁnite word A0 A1 . . . ∈Σω is an inﬁnite state sequence
q0 q1 q2 . . . ∈Qω such that q0 ∈Q0 and qi+1 ∈δ(qi, Ai) for all i ⩾0.
The inﬁnite run q0 q1 q2 . . . is called accepting if
∀F ∈F.
 ∞
∃j ∈IN. qj ∈F

.
The accepted language of G is:
Lω(G) = { σ ∈Σω | there exists an accepting run for σ in G }.
Equivalence of GNBAs and the size of a GNBA are deﬁned as for NBAs. Thus, GNBA G
and G′ are equivalent if Lω(G) = Lω(G′).
The size of GNBA G, denoted |G|, equals the
number of states and transitions in G.
Example 4.53.
GNBA
Figure 4.19 shows a GNBA G over the alphabet 2AP where AP = { crit1, crit2 } with the
acceptance sets F1 = { q1 } and F2 = { q2 }. That is, F = {{ q1 }, { q2 }}. The accepted
language is the LT property Plive consisting of all inﬁnite words A0 A1 A2 . . . ∈(2AP)ω
such that the atomic propositions crit1 and crit2 hold inﬁnitely often (possibly at diﬀerent
positions), i.e.,
∞
∃j ⩾0. crit1 ∈Aj
and
∞
∃j ⩾0. crit2 ∈Aj.
Thus, Plive formalizes the property ”both processes are inﬁnitely often in their critical
section”. Let us justify that indeed Lω(G) = Plive. This goes as follows.
”⊆”: Each accepting run has to pass inﬁnitely often through the edges (labeled with crit1
or crit2) leading to the states q1 and q2. Thus, in every accepted word σ = A0A1A2 . . . ∈

194
Regular Properties
q0
q1
q2
true
crit2
true
crit1
true
Figure 4.19: GNBA for “inﬁnitely often processes 1 and 2 are in their critical section”.
Lω(G) the atomic propositions crit1 and crit2 occur inﬁnitely often as elements of the sets
Ai ∈2AP. Thus, σ ∈Plive.
”⊇”: Let σ = A0 A1 A2 . . . ∈Plive. Since both propositions crit1 and crit2 occur inﬁnitely
often in the symbols Ai, the GNBA G can behave for the input word σ as follows. G remains
in state q0 until the ﬁrst input symbol Ai with crit1 ∈Ai appears. The automaton then
moves to state q1. From there, G consumes the next input symbol Ai+1 and returns to q0.
It then waits in q0 until a symbol Aj with crit2 ∈Aj occurs, in which case the automaton
moves to state q2 for the symbol Aj and returns to q0 on the next symbol Aj+1. Now the
whole procedure restarts, i.e., G stays in q0 while reading the symbols Aj+1, . . . , Aℓ−1 and
moves to q1 as soon as the current input symbol Aℓcontains crit1. And so on. In this
way, G generates an accepting run of the form
qk1
0 q1 qk2
0 q2 qk3
0 q1 qk4
0 q2 qk5
0 . . .
for the input word σ. These considerations show that Plive ⊆Lω(G).
Remark 4.54.
No Acceptance Set
The set F of acceptance sets of a GNBA may be empty. If F = ∅then σ ∈Lω(G) if
and only if there exists an inﬁnite run for σ in G. We like to stress the diﬀerence with
NBA with an empty set of accepting states. For an NBA A = (Q, Σ, δ, Q0, ∅) there are no
accepting runs. Therefore, the language Lω(A) is empty. Contrary to that, every inﬁnite
run of a GNBA G = (Q, Σ, δ, Q0, ∅) is accepting.
In fact, every GNBA G is equivalent to a GNBA G′ having at least one acceptance set.
This is due to the fact that the state space Q can always be added to the set F of the
acceptance sets without aﬀecting the accepted language of the GNBA. Formally, for GNBA
G = (Q, Σ, δ, Q0, F) let GNBA G′ = (Q, Σ, δ, Q0, F ∪{Q}). Then it easily follows that:
Lω(G) = Lω(G′).

Automata on Inﬁnite Words
195
Remark 4.55.
Nonblocking GNBA
As for NBAs, each GNBA G can be replaced with an equivalent GNBA G′, in which all
possible behaviors for a given inﬁnite input word yield an inﬁnite run. Such a GNBA
G′ can be constructed by inserting a nonaccept trapping state, as we did for NBA in the
remark on page 187.
Obviously, every NBA can be understood as a GNBA with exactly one acceptance set.
Conversely, every GNBA can be transformed into an equivalent NBA:
Theorem 4.56.
From GNBA to NBA
For each GNBA G there exists an NBA A with Lω(G) = Lω(A) and |A| = O(|G| · |F|)
where F denotes the set of acceptance sets in G.
Proof: Let G = (Q, Σ, δ, Q0, F) be a GNBA. According to the remark on page 194, we may
assume without loss of generality that F ̸= ∅. Let F = {F1, . . . , Fk} where k ⩾1. The
basic idea of the construction of A is to create k copies of G such that the acceptance set Fi
of the ith copy is connected to the corresponding states of the (i+1)th copy. The accepting
F1
Q0
F2
Fk
...
Figure 4.20: Idea for transforming a GNBA into an NBA.
condition for A consists of the requirement that an accepting state of the ﬁrst copy is visited
inﬁnitely often. This ensures that all other accepting sets Fi of the k copies are visited
inﬁnitely often too, see Figure 4.20 on page 195.
Formally, let A = (Q′, Σ, δ′, Q′
0, F ′)
where:
Q′ = Q × { 1, . . . , k },
Q′
0 = Q0 × { 1 } = { ⟨q0, 1⟩| q0 ∈Q0 }, and
F ′ = F1 × { 1 } = { ⟨qF , 1⟩| qF ∈F1 }.

196
Regular Properties
The transition function δ′ is given by
δ′(⟨q, i⟩, A) =

{ ⟨q′, i⟩| q′ ∈δ(q, A) }
if q ̸∈Fi
{ ⟨q′, i+1⟩| q′ ∈δ(q, A) }
otherwise.
We thereby identify ⟨q, k+1⟩and ⟨q, 1⟩. It is not diﬃcult to check that A can be con-
structed in time and space O(|G| · |F|) where |F| = k is the number of acceptance sets in
G. The fact Lω(G) = Lω(A) can be seen as follows.
⊇: For a run of A to be accepting it has to visit some state ⟨q, 1⟩inﬁnitely often, where
q ∈F1. As soon as a run reaches ⟨q, 1⟩, the NBA A moves to the second copy. From the
second copy the next copy can be reached by visiting ⟨q′, 2⟩with q′ ∈F2. NBA A can only
return to ⟨q, 1⟩if it goes through all k copies. This is only possible if it reaches an accept
state in each copy since that is the only opportunity to move to the next copy. So, for a
run to visit ⟨q, 1⟩inﬁnitely often it has to visit some accept state in each copy inﬁnitely
often.
⊆: By a similar reasoning it can be deduced that every word in Lω(G) is also accepting
in A.
Example 4.57.
Transformation of a GNBA into an NBA
Consider the GNBA G described in Example 4.53 on page 193. The construction indicated
in the proof of Theorem 4.56 provides an NBA consisting of two copies (as there are two
accept sets) of G, see Figure 4.21. For example,
δ′(⟨q0, 1⟩, { crit1 }) = { ⟨q0, 1⟩, ⟨q1, 1⟩},
since q0 /∈F1 = { q1 } and δ′(⟨q2, 2⟩, A) = { ⟨q0, 1⟩}, since F2 = { q2 }. Thereby, A ⊆
{ crit1, crit2 } is arbitrary.
Any NBA can be considered as a GNBA by simply replacing the acceptance set F of
the NBA with the singleton set F = { F } for the corresponding GNBA. Using this fact,
together with the result that NBAs are equally expressive as ω-regular languages (see
Theorem 4.32 on page 178), we obtain by Theorem 4.56:
Corollary 4.58.
GNBA and ω-Regular Languages
The class of languages accepted by GNBAs agrees with the class of ω-regular languages.
As we have seen before, ω-regular languages are closed under union. This is immediate
from the deﬁnition of ω-regular expressions and can also simply be proven by means of

Automata on Inﬁnite Words
197
⟨q0, 1⟩
⟨q1, 1⟩
⟨q2, 1⟩
true
crit2
true
crit1
⟨q1, 2⟩
⟨q0, 2⟩
⟨q2, 2⟩
true
true
crit1
true
crit2
true
Figure 4.21: Example for the transformation of a GNBA into an equivalent NBA.
NBA representations (see Lemma 4.33 on page 179). We now use GNBAs to show that
ω-regular languages are closed under intersection too.
Lemma 4.59.
Intersection of GNBA
For GNBA G1 and G2 (both over the alphabet Σ), there exists a GNBA G with
Lω(G) = Lω(G1) ∩Lω(G2)
and
|G| = O(|G1| · |G2|).
Proof: Let G1 = (Q1, Σ, δ1, Q0,1, F1) and G2 = (Q2, Σ, δ2, Q0,2, F2) where without loss of
generality Q1∩Q2 = ∅. Let G be the GNBA that results from G1 and G2 by a synchronous
product construction (as for NFA) and “lifts” the acceptance sets F ∈F1∪F2 to acceptance
sets in G. Formally,
G = G1 ⊗G2 = (Q1 × Q2, Σ, δ, Q0,1 × Q0,2, F)
where the transition relation δ is deﬁned by the rule
q1
A
−−→1 q′
1 ∧q2
A
−−→2 q′
2
(q1, q2)
A
−−→(q′
1, q′
2)
.
The acceptance condition in G is given by
F = {F1 × Q2 | F1 ∈F1} ∪{Q1 × F2 | F2 ∈F2}.

198
Regular Properties
It is now easy to verify that G has the desired properties.
The same result also holds for union, that is, given two GNBAs G1 and G2 with the same
alphabet Σ there is a GNBA G with Lω(G) = Lω(G1)∪Lω(G2) and |G| = O(|G1|+|G2|). The
argument is the same as for NBA (Lemma 4.33): we simply may take the disjoint union
of the two GNBAs and decide nondeterministically which of them is chosen to “scan” the
given input word.
Since GNBA yield an alternative characterization of ω-regular languages, we obtain by
Lemma 4.59:
Corollary 4.60.
Intersection of ω-Regular Languages
If L1 and L2 are ω-regular languages over the alphabet Σ, then so is L1 ∩L2.
4.4
Model-Checking ω-Regular Properties
The examples provided in Section 4.3.2 (see page 176 ﬀ.) illustrated that NBAs yield a
simple formalism for ω-regular properties. We now address the question how the automata-
based approach for verifying regular safety properties can be generalized for the veriﬁcation
of ω-regular properties.
The starting point is a ﬁnite transition system TS = (S, Act, →, I, AP, L) without terminal
states and an ω-regular property P. The aim is to check algorithmically whether TS |= P.
As we did for regular safety properties, the veriﬁcation algorithm we present now attempts
to show that TS ̸|= P by providing a counterexample, i.e., a path π in TS with trace(π) /∈
P. (If no such path exists, then P holds for TS.) For this, we assume that we are given an
automata-representation of the “bad traces” by means of an NBA A for the complement
property P = (2AP)ω \ P. The goal is then to check whether Traces(TS) ∩Lω(A) ̸= ∅.
Note that:
Traces(TS) ∩Lω(A) ̸= ∅
if and only if
Traces(TS) ∩P ̸= ∅
if and only if
Traces(TS) ∩(2AP)ω \ P ̸= ∅
if and only if
Traces(TS) ̸⊆P
if and only if
TS ̸|= P.

Model-Checking ω-Regular Properties
199
The reader should notice the similarities with regular safety property checking. In that
case, we started with an NFA for the bad preﬁxes for the given safety property Psafe
(the bad behaviors). This can be seen as an automata-representation of the complement
property Psafe, see Remark 4.31 on page 177. The goal was then to ﬁnd a ﬁnite, initial
path fragment in TS that yields a trace accepted by the NFA, i.e., a bad preﬁx for Psafe.
Let us now address the problem to check whether Traces(TS) ∩Lω(A) ̸= ∅. For this,
we can follow the same pattern as for regular safety properties and construct the product
TS ⊗A which combines paths in TS with the runs in A.
We then perform a graph
analysis in TS ⊗A to check whether there is a path that visits an accept state of A
inﬁnitely often, which then yields a counterexample and proves TS ̸|= P. If no such path
in the product exists, i.e., if accept states can be visited at most ﬁnitely many times on
all paths in the product, then all runs for the traces in TS are nonaccepting, and hence
Traces(TS) ∩Lω(A) = ∅and thus TS |= P
In the sequel, we will explain these ideas in more detail. For doing so, we ﬁrst introduce
the notion of a persistence property.
This is a simple type of LT property that will
serve to formalize the condition stating that accept states are only visited ﬁnitely many
times. The problem of verifying ω-regular properties is then shown to be reducible to
the persistence checking problem.
Recall that the problem of verifying regular safety
properties is reducible to the invariant checking problem, see Section 4.2.
4.4.1
Persistence Properties and Product
Persistence properties are special types of liveness properties that assert that from some
moment on a certain state condition Φ holds continuously. Stated in other words, ¬Φ is
required to hold at most ﬁnitely many times. As for invariants, we assume a representation
of Φ by a propositional logic formula over AP.
Deﬁnition 4.61.
Persistence Property
A persistence property over AP is an LT property Ppers ⊆(2AP)ω “eventually forever Φ”
for some propositional logic formula Φ over AP. Formally,
Ppers =

A0A1A2 . . . ∈(2AP)ω |
∞
∀j. Aj |= Φ

where
∞
∀j is short for ∃i ⩾0. ∀j ⩾i. Formula Φ is called a persistence (or state) condition
of Ppers.
Intuitively, a persistence property “eventually forever Φ” ensures the tenacity of the state

200
Regular Properties
property given by the persistence condition Φ. One may say that Φ is an invariant after a
while; i.e., from a certain point on all states satisfy Φ. The formula “eventually forever Φ”
is true for a path if and only if almost all, i.e., all except for ﬁnitely many, states satisfy
the proposition Φ.
Our goal is now to show that the question whether Traces(TS) ∩Lω(A) = ∅holds can be
reduced to the question whether a certain persistence property holds in the product of TS
and A. The formal deﬁnition of the product TS ⊗A is exactly the same as for an NFA.
For completeness, we recall the deﬁnition here:
Deﬁnition 4.62.
Product of Transition System and NBA
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states and A =
(Q, 2AP, δ, Q0, F) a nonblocking NBA. Then, TS ⊗A is the following transition system:
TS ⊗A = (S × Q, Act, →′, I′, AP′, L′)
where →′ is the smallest relation deﬁned by the rule
s
α
−−→t ∧q
L(t)
−−−→p
⟨s, q⟩
α
−−→′ ⟨t, p⟩
and where
• I′ = { ⟨s0, q⟩| s0 ∈I ∧∃q0 ∈Q0. q0
L(s0)
−−−−→q },
• AP′ = Q and L′ : S × Q →2Q is given by L′(⟨s, q⟩) = { q }.
Furthermore, let Ppers(A) be the persistence property over AP′ = Q given by
”eventually forever ¬F”
where ¬F denotes the propositional formula 
q∈Q
¬q over AP′ = Q.
We now turn to the formal proof that the automata-based approach for checking ω-regular
properties relies on checking a persistence property for the product transition system:
Theorem 4.63.
Veriﬁcation of ω-Regular Properties
Let TS be a ﬁnite transition system without terminal states over AP and let P be an ω-
regular property over AP. Furthermore, let A be a nonblocking NBA with the alphabet
2AP and Lω(A) = (2AP)ω \ P. Then, the following statements are equivalent:

Model-Checking ω-Regular Properties
201
(a) TS |= P
(b) Traces(TS) ∩Lω(A) = ∅
(c) TS ⊗A |= Ppers(A)
Proof: Let TS = (S, Act, →, I, AP, L) and A = (Q, 2AP, δ, Q0, F). The equivalence of (a)
and (b) was shown on page 198. Let us now check the equivalence of (b) and (c). For this
we show
Traces(TS) ∩Lω(A) ̸= ∅if and only if TS ⊗A ̸|= Ppers(A).
”⇐”: Assume TS ⊗A ̸|= Ppers(A). Let π′ = ⟨s0, q1⟩⟨s1, q2⟩. . . be a path in TS ⊗A such
that
π′ ̸|= Ppers(A).
Then there are inﬁnitely many indices i with qi ∈F. The projection of π′ to the states in
TS yields a path π = s0 s1 s2 . . . in TS.
Let q0 ∈Q0 be an initial state of A such that q0
L(s0)
−−−−→q1. Such a state q0 exists, since
⟨s0, q1⟩is an initial state of TS ⊗A. The state sequence q0 q1 q2 . . . is a run in A for the
word
trace(π) = L(s0) L(s1) L(s2) . . . ∈Traces(TS).
Since there are inﬁnitely many i with qi ∈F, the run q0 q1 q2 . . . is accepting. Hence,
trace(π) ∈Lω(A).
This yields trace(π) ∈Traces(TS) ∩Lω(A), and thus Traces(TS) ∩Lω(A) ̸= ∅.
”⇒”: Assume that Traces(TS) ∩Lω(A)
̸=
∅.
Then there exists a path in TS, say
π = s0 s1 s2 . . . with
trace(π)
=
L(s0) L(s1) L(s2) . . . ∈Lω(A).
Let q0 q1 q2 . . . be an accepting run in A for trace(π). Then
q0 ∈Q0
and
qi
L(si)
−−−−→qi+1
for all i ⩾0.
Furthermore, qi ∈F for inﬁnitely many indices i. Thus, we can combine π and the run
q0 q1 . . . to obtain a path in the product
π′ = ⟨s0, q1⟩⟨s1, q2⟩. . . ∈Paths(TS ⊗A).

202
Regular Properties
{ green }
{ red }
q0
q2
true
q1
¬green
green
true
¬green
{ q0 }
⟨s0, q0⟩
{ q1 }
⟨s0, q1⟩
{ q2 }
⟨s0, q2⟩
⟨s1, q0⟩
{ q0 }
{ q1 }
⟨s1, q1⟩
{ q2 }
⟨s1, q2⟩
Figure 4.22: A simple traﬃc light (upper left), an NBA corresponding to Ppers (upper
right), and their product (below).
Since qi ∈F for inﬁnitely many i, we have π′ ̸|= Ppers(A). This yields TS ⊗A ̸|= Ppers(A).
Example 4.64.
Checking a Persistence Property
Consider a simple traﬃc light as one typically encounters at pedestrian crossings. It only
has two possible modes: red or green. Assume that the traﬃc light is initially red, and
alternates between red and green, see the transition system PedTrLight depicted in the
upper left part of Figure 4.22. The ω-regular property P to be checked is “inﬁnitely often
green”. The complement property P thus is “eventually always not green”. The NBA
depicted in the upper right part of Figure 4.22 accepts P.
To check the validity of P, we ﬁrst construct the product automaton PedTrLight ⊗A, see
the lower part of Figure 4.22. Note that the state ⟨s1, q1⟩is unreachable and could be
omitted. Let Ppers(A) = “eventually forever ¬q1”. From the lower part of Figure 4.22 one
can immediately infer that there is no run of the product automaton that goes inﬁnitely
often through a state of the form ⟨·, q1⟩. That is, transition system PedTrLight and NBA
A do not have any trace in common. Thus we conclude:
PedTrLight ⊗A |= “eventually forever” ¬q1
and consequently (as expected):
PedTrLight |= “inﬁnitely often green”.

Model-Checking ω-Regular Properties
203
As a slight alternative, we now consider a pedestrian traﬃc light that may automatically
switch oﬀto save energy. Assume, for simplicity, that the light may only switch oﬀwhen
it is red for some undeﬁned amount of time. Clearly, this traﬃc light cannot guarantee
the validity of P = “eventually forever ¬green” as it exhibits a run that (possibly after
a while) alternates between red and oﬀinﬁnitely often. This can be formally shown as
follows. First, we construct the product automaton, see Figure 4.23 (lower part). For
instance, the path ⟨s0, q0⟩(⟨s2, q1⟩⟨s0, q1⟩)ω goes inﬁnitely often through the accept state
q1 of A and generates the trace
{ red } ∅{ red } ∅{ red } ∅. . . . . .
That is, Traces(PedTrLight’) ∩Lω(A) ̸= ∅, and thus
PedTrLight’ ⊗A ̸|= “eventually forever” ¬q1
and thus
PedTrLight′ ̸|= “inﬁnitely often green”.
More concretely, the path π = s0 s1 s0 s1 . . . generating the trace
trace(π) = { red } ∅{ red } ∅{ red } ∅. . .
has an accepting run q0 (q1)ω in A.
According to Theorem 4.63, the problem of checking an arbitrary ω-regular property can
be solved with algorithms that check a simple type of ω-regular liveness property, namely
persistence properties. An algorithm for the latter will be provided in the following section
where the transition system under consideration results from the product of the original
transition system and an NBA for the undesired behaviors.
4.4.2
Nested Depth-First Search
The next problem that we need to tackle is how to establish whether for a given ﬁnite
transition system TS:
TS ̸|= Ppers
where Ppers is a persistence property. Let Φ be the underlying propositional formula that
speciﬁes the state condition which has to hold ”eventually forever”.
The following result shows that answering the question ”does TS ̸|= Ppers hold?” amounts
to checking whether TS contains a reachable state violating Φ that is on a cycle in TS.

204
Regular Properties
s1
{ green }
s0
{ red }
⟨s0, q0⟩{ q0 }
⟨s0, q1⟩{ q1 }
⟨s0, q2⟩{ q2 }
⟨s1, q0⟩
{ q0 }
⟨s1, q1⟩
{ q1 }
⟨s1, q2⟩
{ q2 }
s2
∅
{ q0 }
⟨s2, q0⟩
{ q1 }
⟨s2, q1⟩
{ q2 }
⟨s2, q2⟩
Figure 4.23: A simple traﬃc light that can switch oﬀ(upper part) and its product (lower
part).

Model-Checking ω-Regular Properties
205
Φ
Φ
Φ
Φ
Φ
Φ
Φ
¬Φ
¬Φ
s
∈Q0
Figure 4.24: An example of a run violating “eventually always” Φ.
This can be justiﬁed intuitively as follows. Suppose s is a state that is reachable from an
initial state in TS and s ̸|= Φ. As s is reachable, TS has an initial path fragment that
ends in s. If s is on a cycle, then this path fragment can be continued by an inﬁnite
path that is obtained by traversing the cycle containing s inﬁnitely often. In this way,
we obtain a path in TS that visits the ¬Φ-state s inﬁnitely often. But then, TS ̸|= Ppers.
This is exempliﬁed in Figure 4.24 where a fragment of a transition system is shown; for
simplicity the action labels have been omitted. (Note that – in contrast to invariants – a
state violating Φ which is not on a cycle does not cause the violation of Ppers.)
The reduction of checking whether TS |= Ppers to a cycle detection problem is formalized
by the following theorem.
Theorem 4.65.
Persistence Checking and Cycle Detection
Let TS be a ﬁnite transition system without terminal states over AP, Φ a propositional
formula over AP, and Ppers the persistence property ”eventually forever Φ”. Then, the
following statements are equivalent:
(a) TS ̸|= Ppers,
(b) There exists a reachable ¬Φ-state s which belongs to a cycle. Formally:
∃s ∈Reach(TS). s ̸|= Φ ∧s is on a cycle in G(TS) .5
Before providing the proof, let us ﬁrst explain how to obtain an error indication whenever
TS ̸|= Ppers. Let π = u0 u1 u2 . . . uk be a path in the graph induced by TS, i.e., G(TS),
such that k > 0 and s = u0 = uk. Assume s ̸|= Φ. That is, π is a cycle in G(TS) containing
5Recall that G(TS) denotes the underlying directed graph of TS.

206
Regular Properties
a state violating Φ. Let s0 s1 s2 . . . sn be an initial path fragment of TS such that sn = s.
Then the concatenation of this initial path fragment and the unfolding of the cycle
π = s0 s1 s2 . . . sn

=s
u1 u2 . . . uk

=s
u1 u2 . . . uk

=s
. . .
is a path in TS. As state s ̸|= Φ is visited by π inﬁnitely often, it follows that π does not
satisfy “eventually always Φ”. The preﬁx
s0 s1 s2 . . . sn

=s
u1 u2 . . . uk

=s
can be used as diagnostic feedback as it shows that s may be visited inﬁnitely often.
Proof: Let TS = (S, Act, →, I, AP).
(a) =⇒(b): Assume TS ̸|= Ppers, i.e., there exists a path π = s0 s1 s2 . . . in TS such that
trace(π) /∈Ppers. Thus, there are inﬁnitely many indices i such that si ̸|= Φ. Since TS is
ﬁnite, there is a state s with s = si ̸|= Φ for inﬁnitely many i. As s appears on a path
starting in an initial state we have s ∈Reach(TS). A cycle π is obtained by any fragment
si si+1 si+2 . . . si+k of π where si = si+k = s and k > 0.
(b) =⇒(a): Let s and π = u0u1 . . . uk be as indicated above, i.e., s ∈Reach(TS) and π is
a cycle in TS with s = u0 = uk. Since s ∈Reach(TS), there in an initial state s0 ∈I and
a path fragment s0 s1 . . . sn with sn = s. Then:
π = s0 s1 s2 . . . sn

=s
u1 u2 . . . uk

=s
u1 u2 uk

=s
. . .
is a path in TS. Since s ̸|= Φ, it follows that π does not satisfy “eventually forever Φ”,
and thus TS ̸|= Ppers.
Example 4.66.
Pedestrian Traﬃc Lights Revisited
Consider the transition system model of the simple traﬃc light that one typically encoun-
ters at pedestrian crossings (see Figure 4.22) and the persistence property “eventually
forever” ¬q1 where q1 is the accept state of the NBA A. As there is no reachable cycle in
the product transition system that contains a state violating ¬q1, i.e., a cycle that contains
a state labeled with q1, it follows that
PedTrLight ⊗A |= “eventually forever” ¬q1.
For the traﬃc light that has the possibility to automatically switch oﬀ, it can be inferred
directly from the product transition system (see the lower part of Figure 4.23) that there

Model-Checking ω-Regular Properties
207
is a reachable state, e.g., ⟨s2, q1⟩̸|= ¬q1, that lies on a cycle. Thus:
PedTrLight’ ⊗A ̸|= “eventually forever” ¬q1.
Thus, persistence checking for a ﬁnite transition system requires the same techniques as
checking emptiness of an NBA, see page 184. In fact, the algorithm we suggest below can
also be used for checking emptiness in an NBA.
A Naive Depth-First Search
Theorem 4.65 entails that in order to check the validity
of a persistence property, it suﬃces to check whether there exists a reachable cycle con-
taining a ¬Φ-state. How to check for such reachable cycles? A possibility is to compute
the strongly connected components (SCCs, for short) in G(TS) – this can be done in a
worst-case time complexity that is linear in the number of states and transitions – and to
check whether one such SCC is reachable from an initial state, contains at least one edge,
and, moreover, contains a ¬Φ-state. If indeed such a SCC does exist, Ppers is refuted;
otherwise the answer is aﬃrmative.
Although this SCC-based technique is optimal with respect to the asymptotic worst-case
time complexity, it is more complex and less adequate for an on-the-ﬂy implementation.
In that respect, pure cycle-check algorithms are more appropriate. Therefore, in the sequel
we will detail the standard DFS-based cycle detection algorithm.
Let us ﬁrst recall how for a ﬁnite directed graph G and node v, it can be checked with
a DFS-based approach whether v belongs to a cycle. For this, one may simply start a
depth-ﬁrst search in node v and check for any visited node w whether there is an edge from
w to v. If so, a cycle has been found: it starts in v and follows the path to node w given
by the current stack content and then takes the edge from w to v. Vice versa, if no such
edge is found, then v does not belong to a cycle. To determine whether G has a cycle, a
similar technique can be exploited: we perform a depth-ﬁrst search to visit all nodes in G.
Moreover, on investigating the edge from w to v it is checked whether v has already been
visited and whether v is still on the DFS stack. If so, then a so-called backward edge has
been found which closes a cycle. Otherwise, if no backward edge has been found during
the DFS in G then G is acyclic. (A detailed description of this DFS-based cycle detection
technique can be found in textbooks on algorithms and data structures, e.g., [100].)
We now DFS-based cycle checks (by searching for backward edges) for persistence checking.
The naive approach works in two phases, as illustrated in Algorithm 6:
1. In the ﬁrst step, all states satisfying ¬Φ that are reachable from some initial state
are determined. This is performed by a standard depth-ﬁrst search.

208
Regular Properties
2. In the second step, for each reachable ¬Φ-state s, it is checked whether it belongs to
a cycle. This algorithm (called cycle check, see Algorithm 7) relies on the technique
sketched above: we start a depth-ﬁrst search in s (with initially empty DFS stack
V and initially empty set T of visited states) and check for all states reachable from
s whether there is an outgoing backward edge leading to s.
This yields an algorithm for checking the validity of the persistence property with quadratic
worst-case running time. More precisely, its time complexity is in O(N·(|Φ| + N+M))
where N is the number of reachable states in TS and M the number of transitions between
these reachable states. This can be seen as follows. Visiting all states that are reachable
from some initial state takes O(N+M+N·|Φ|) as a depth-ﬁrst search over all states suﬃces
and in each reachable state the validity of Φ is checked (which is assumed to be linear
in the size of Φ). In the worst case, all states refute Φ, and a depth-ﬁrst search takes
place (procedure cycle check) for all these states. This takes O(N·(N+M)). Together
this yields O(N·(|Φ| + N+M)).
Several simple modiﬁcations of the suggested technique are possible to increase eﬃciency.
For instance, cycle check(s′) can be invoked inside visit(s) immediately before or after s′ is
inserted into R¬Φ, in which case the whole persistence checking algorithm can abort with
the answer ”no” if cycle check(s′) returns true. However, the quadratic worst-case running
time cannot be avoided if the cycle check algorithm for the ¬Φ-states relies on separate
depth-ﬁrst searches.
The problem is that certain fragments of TS might be reachable
from diﬀerent ¬Φ-states. These fragments are (re-)explored in the depth-ﬁrst searches
(cycle check) invoked by several ¬Φ-states. To obtain linear running time, we aim at a
cycle detection algorithm that searches for backward edges leading to one of the ¬Φ-states
and ensures that any state is visited at most once in the depth-ﬁrst searches for the cycle
detection. This will be explained in the following subsection.
A Nested Depth-First Search Algorithm
The rough idea of the linear-time cy-
cle detection-based persistence checking algorithm is to perform two depth-ﬁrst searches
(DFSs) in TS in an interleaved way. The ﬁrst (outer) depth-ﬁrst search serves to encounter
all reachable ¬Φ-states. The second (inner) depth-ﬁrst search seeks backward edges lead-
ing to a ¬Φ-state. The inner depth-ﬁrst search is nested in the outer one in the following
sense: whenever a ¬Φ-state s has been fully expanded by the outer depth-ﬁrst search,
then the inner depth-ﬁrst search continues with state s and visits all states s′ that are
reachable from s and that have not yet been visited in the inner depth-ﬁrst search before.
If no backward edge has been found when treating s in the inner DFS, then the outer DFS
continues until the next ¬Φ-state t has been fully expanded, in which case the inner DFS
proceeds with t.

Model-Checking ω-Regular Properties
209
Algorithm 6 Naive persistence checking
Input: ﬁnite transition system TS without terminal states, and proposition Φ
Output: ”yes” if TS |= ”eventually forever Φ”, otherwise ”no”.
set of states R := ∅; R¬Φ := ∅;
(* set of reachable states resp. ¬Φ-states *)
stack of states U := ε;
(* DFS stack for ﬁrst DFS, initial empty *)
set of states T := ∅;
(* set of visited states for the cycle check *)
stack of states V := ε;
(* DFS stack for the cycle check *)
for all s ∈I \ R do visit(s); od
(* a DFS for each unvisited initial state *)
for all s ∈R¬Φ do
T := ∅; V := ε;
(* initialize set T and stack V *)
if cycle check(s) then return ”no”
(* s belongs to a cycle *)
od
return ”yes”
(* none of the ¬Φ-states belongs to a cycle *)
procedure visit (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
(* mark s as reachable *)
repeat
s′ := top(U);
if Post(s′) ⊆R then
pop(U);
if s′ ̸|= Φ then R¬Φ := R¬Φ ∪{ s′ }; ﬁ
else
let s′′ ∈Post(s′) \ R
push(s′′, U);
R := R ∪{ s′′ };
(* state s′′ is a new reachable state *)
ﬁ
until (U = ε)
endproc

210
Regular Properties
Algorithm 7 Cycle detection
Input: ﬁnite transition system TS and state s in TS with s ̸|= Φ
Output: true if s lies on a cycle in TS, otherwise false
(* T organizes the set of states that have been visited, V serves as DFS stack.
*)
(* In the standard approach to check whether there is a backward edge to s,
*)
(* T and V are initially empty.
*)
procedure boolean cycle check(state s)
boolean cycle found := false;
(* no cycle found yet *)
push(s, V );
(* push s on the stack *)
T := T ∪{ s };
repeat
s′ := top(V );
(* take top element of V *)
if s ∈Post(s′) then
cycle found := true;
(* if s ∈Post(s′), a cycle is found *)
push(s, V );
(* push s on the stack *)
else
if Post(s′) \ T ̸= ∅then
let s′′ ∈Post(s′) \ T ;
push(s′′, V );
(* push an unvisited successor of s′ *)
T := T ∪{ s′′ };
(* and mark it as reachable *)
else
pop(V );
(* unsuccessful cycle search for s′ *)
ﬁ
ﬁ
until ((V = ε) ∨cycle found)
return cycle found
endproc

Model-Checking ω-Regular Properties
211
Algorithm 8 Persistence checking by nested depth-ﬁrst search
Input: transition system TS without terminal states, and proposition Φ
Output: ”yes” if TS |= ”eventually forever Φ”, otherwise ”no” plus counterexample
set of states R := ∅;
(* set of visited states in the outer DFS *)
stack of states U := ε;
(* stack for the outer DFS *)
set of states T := ∅;
(* set of visited states in the inner DFS *)
stack of states V := ε;
(* stack for the inner DFS *)
boolean cycle found := false;
while (I \ R ̸= ∅∧¬cycle found) do
let s ∈I \ R;
(* explore the reachable *)
reachable cycle(s);
(* fragment with outer DFS *)
od
if ¬cycle found then
return (”yes”)
(* TS |= ”eventually forever Φ” *)
else
return (”no”, reverse(V.U))
(* stack contents yield a counterexample *)
ﬁ
procedure reachable cycle (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
repeat
s′ := top(U);
if Post(s′) \ R ̸= ∅then
let s′′ ∈Post(s′) \ R;
push(s′′, U);
(* push the unvisited successor of s′ *)
R := R ∪{ s′′ };
(* and mark it reachable *)
else
pop(U);
(* outer DFS ﬁnished for s′ *)
if s′ ̸|= Φ then
cycle found := cycle check(s′);
(* proceed with the inner *)
(* DFS in state s′ *)
ﬁ
ﬁ
until ((U = ε) ∨cycle found)
(* stop when stack for the outer *)
(* DFS is empty or cycle found *)
endproc

212
Regular Properties
This algorithm is called nested depth-ﬁrst search.
Algorithm 8 shows the pseudocode
for the outer depth-ﬁrst search (called reachable cycle) which invokes the inner depth-ﬁrst
search (cycle check, cf. Algorithm 7 on page 210). Later we will explain that it is important
that cycle check(s) is called immediately after the outer depth-ﬁrst search has visited all
successors of s.
The major diﬀerence from the naive approach is that cycle check(s)
reuses the information of previous calls of cycle check(·) and ignores all states in T. When
cycle check(s) is invoked then T consists of all states that have been visited in the inner
DFS before, i.e., during the execution of cycle check(u) called prior to cycle check(s).
An interesting aspect of this nested depth-ﬁrst strategy is that once a cycle is determined
containing a ¬Φ-state s, then a path to s can be computed easily: stack U for the outer
DFS contains a path fragment from the initial state s0 ∈I to s (in reversed order),
while stack V for the inner DFS — as maintained by the procedure cycle check(·) —
contains a cycle from state s to s (in reversed order). Concatenating these path fragments
thus provides an error indication in the same vein as described before in the proof of
Theorem 4.65 on page 205.
Example 4.67.
Running the Nested DFS Algorithm
Consider the transition system depicted in Figure 4.25 and assume that s0 |= Φ, s3 |= Φ,
whereas s1 ̸|= Φ and s2 ̸|= Φ. Consider the scenario in which s2 is considered as a ﬁrst
successor of s0, i.e., s2 is considered in the outer depth-ﬁrst search prior to considering
state s1. This means that the order in which the states are put by Algorithm 8 on the
stack U equals ⟨s1, s3, s2, s0⟩where we write the stack content from the top to the bottom,
i.e., s1 is the top element (the last element that has been pushed on the stack). Besides,
R = S. Thus, the outer DFS takes s1 as the top element of U and veriﬁes Post(s1) ⊆R.
As s1 ̸|= Φ, the invocation cycle check(s1) takes place and s1 is deleted from stack U for the
outer DFS. This yields that s1 is put on the stack V for the inner DFS, followed by its only
successor s3. Then the cycle s1 →s3 →s1 is detected, cycle check(s1) yields true, and
as a result, reachable cycle(s0) terminates with the conclusion that Ppers on Φ is refuted.
An error indication is obtained by ﬁrst concatenating the content of V = ⟨s1, s3, s1⟩and
U = ⟨s3, s2, s0⟩and then reversing the order. This yields the path s0 s2 s3 s1 s3 s1, which
is indeed a preﬁx of a run refuting “eventually always Φ”.
The soundness of the nested depth-ﬁrst search is no longer trivial because – by the
treatment of T as a global variable – not all states reachable from s are explored in
cycle check(s), but only those states that have not been visited before in the inner depth-
ﬁrst search. Thus, we could imagine that there is a cycle with ¬Φ-states which will not
be found with the nested depth-ﬁrst search: this cycle might have been explored during
cycle check(u) where u does not belong to this or any other cycle. Then, none of the
following procedure calls of cycle check(·) will ﬁnd this cycle. The goal is now to show

Model-Checking ω-Regular Properties
213
s0
s2
s3
s1
Figure 4.25: An example of a transition system for nested DFS.
that this cannot happen, i.e., if there is a reachable cycle with ¬Φ-states, then the nested
depth-ﬁrst search will ﬁnd such a cycle.
In fact, things are more tricky than it seems. In Algorithm 8 it is important that the
invocations to the procedure cycle check(s) for s ∈Reach(TS) and s ̸|= Φ occur in ap-
propriate order. Let s ̸|= Φ. Then cycle check(s) is only invoked if Post(s) ⊆R, i.e.,
when all states reachable from s have been encountered and visited.6 So, the invocation
cycle check(s) is made immediately once all states that are reachable from s have been
visited and expanded in the outer depth-ﬁrst search. As a result, Algorithm 8 satisﬁes the
following property: if s′ is a successor of state s in the visit-order of the outer depth-ﬁrst
search and s ̸|= Φ and s′ ̸|= Φ, then the invocation cycle check(s′) occurs prior to the
invocation cycle check(s).
Example 4.68.
Modifying the Nested DFS
Let us illustrate by an example that the nested depth-ﬁrst search algorithm would be
wrong if the outer and inner DFS are interleaved in an arbitrary way. We consider again
the transition system in Figure 4.25 on page 213. We start the outer DFS with the initial
state s0 and assume that state s2 is visited prior to s1. Let us see what happens if we
do not wait until s2 has been fully expanded in the outer DFS and start cycle check(s2)
immediately. Then, cycle check(s2) visits s3 and s1 and returns false, since there is no
backward edge leading to state s2.
Thus, cycle check(s2) yields T = {s2, s3, s1} (and
V = ε). Now the outer DFS proceeds and visits s3 and s1. It calls cycle check(s1) which
fails to ﬁnd the cycle s1s3s1. Note that cycle check(s1) immediately halts and returns
false since s1 ∈T = {s2, s3, s1}. Thus, the nested depth-ﬁrst search would return the
wrong answer ”yes”.
6For a recursive formulation of the outer depth-ﬁrst search, this is the moment where the depth-ﬁrst
search call for s terminates.

214
Regular Properties
Theorem 4.69.
Correctness of the Nested DFS
Let TS be a ﬁnite transition system over AP without terminal states, Φ a propositional
formula over AP, and Ppers the persistence property ”eventually forever Φ”. Then:
Algorithm 8 returns the answer ”no” if and only if TS ̸|= Ppers.
Proof:
⇒: This follows directly from the fact that the answer “false” is only obtained when an
initial path fragment of the form s0 . . . s . . . s has been encountered for some s0 ∈I and
s ̸|= Φ. But then, TS ̸|= Ppers.
⇐: To establish this direction, we ﬁrst prove that the following condition holds:
(*) On invoking cycle check(s), there is no cycle s′
0 s′
1 . . . s′
k in TS such that:
{ s′
0, s′
1, . . . , s′
k } ∩T ̸= ∅
and
s ∈{ s′
0, . . . , s′
k }.
So, on invoking cycle check(s), there is no cycle containing s and a state in T. Statement
(*) ensures that in the inner DFS, all already visited states in T—the states that were
visited during an earlier cycle detection—can be safely ignored during the next cycle
search. In other words, if s belongs to a cycle then cycle check(s) has to ﬁnd one such cycle.
We prove the statement (*) by contradiction.
Consider the invocation cycle check(s).
Assume there exists a cycle s′
0 s′
1 . . . s′
k such that
s′
0 = s′
k = s
and
s ̸|= Φ
and
{ s′
0, s′
1, . . . , s′
k } ∩T ̸= ∅.
Without loss of generality we assume that s is the ﬁrst state for which this condition holds
on invoking cycle check(s). More precisely, we assume:
(+) For all states s with s ̸|= Φ where cycle check(s) has been invoked prior to cy-
cle check(s), there is no cycle containing s and a state in T, on invoking cycle check(s).
Let t ∈{ s′
0, . . . , s′
k } ∩T, i.e., t is a state on a cycle with state s. Since t ∈T on the
invocation cycle check(s), there must be a state, u say, for which cycle check(·) has been
invoked earlier and during this search t has been encountered (and added to T). Thus, we
have u ̸|= Φ and the following conditions (4.1) and (4.2):
cycle check(u) was invoked prior to cycle check(s)
(4.1)

Model-Checking ω-Regular Properties
215
as a result of cycle check(u), t was visited and added to T
(4.2)
Obviously, from (4.2), it follows that state t is reachable from u. As the states s and t are
on a cycle, and t is reachable from u, we have that s is reachable from u. This situation
is sketched in the following ﬁgure:
t ∈Rin
¬Φ
s
u
¬Φ
Φ
Now consider the outer depth-ﬁrst search, i.e., reachable cycle(·), and discuss the following
cases 1 and 2:
1. u has been visited prior to s in the outer DFS, i.e., s has been pushed on stack U
after u.
Since s is reachable from u, state s is visited during the expansion of u in the outer
DFS and taken from stack U before u. Hence, cycle check(s) is invoked prior to
cycle check(u) which contradicts (4.1).
2. u has been visited after s in the outer DFS, i.e., s has been pushed on stack U before
u.
By (4.1), s is still in stack U when cycle check(u) is invoked. This yields that u is
reachable from s. But as s is reachable from u, this means that s and u are on a
cycle. This cycle or another cycle with state u would have been encountered dur-
ing cycle check(u) because of (+) and Algorithm 8 would have terminated without
invoking cycle check(s).
It remains to discuss the complexity of the nested depth-ﬁrst search algorithm. Since T
is increasing during the execution of the nested depth-ﬁrst search (i.e., we insert states in
T, but never take them out) any state in TS is visited at most once in the inner depth-
ﬁrst search, when ranging over all procedure calls of cycle check(·). The same holds for
the outer depth-ﬁrst search since it is roughly a standard depth-ﬁrst search. Thus, each
reachable state s′ in TS is taken

216
Regular Properties
• at most once7 as the top element of stack U in the outer depth-ﬁrst search;
• at most once as the top element of stack V in the inner depth-ﬁrst search (when
ranging over all calls of cycle check).
In particular, this observation yields the termination of Algorithm 8. The cost caused by
the top-element s′ for the body of the repeat loop in cycle check (inner depth-ﬁrst search)
and in reachable cycle (outer depth-ﬁrst search) is O(|Post(s′)|). Thus, the worst-case
time complexity of Algorithm 8 is linear in the size of the reachable fragment of TS, but
has the chance to terminate earlier when a cycle has been found. In the following theorem
we also take into account that Φ might be a complex formula and evaluating the truth
value of Φ for a given state (by means of its label) requires O(|Φ|) steps.
Theorem 4.70.
Time Complexity of Persistence Checking
The worst-case time complexity of Algorithm 8 is in O((N+M) + N·| Φ |) where N is the
number of reachable states, and M the number of transitions between the reachable states.
The space complexity is bounded above by O(|S| + | →|) where S is the state space of
TS and | →| the number of transitions in TS. This is an adequate bound if we assume
a representation of TS by adjacency lists.
However, in the context of model checking
the starting point is typically not an explicit representation of the composite transition
system, but a syntactic description of the concurrent processes, e.g., by high-level modeling
languages with a program graph or channel system semantics. Such syntactic descriptions
are typically much smaller than the resulting transition system. (Recall the state explosion
problem which appears through parallel composition and the unfolding of program graphs
into transition systems, see page 77 ﬀ.) In the persistence checking algorithm, we may
assume that the elements in Post(s′) are generated on the ﬂy by means of the semantic
rules for the transition relation. Ignoring the space required for the syntactic descriptions
of the processes, the additional space requirements for the presented persistence checking
algorithm is O(N) for the sets T and R and the stacks U and V , where N is the number of
reachable states in TS. In fact, the representation of T and R is the most (space-)critical
aspect when implementing the nested depth-ﬁrst search and running it on large examples.
Typically, T and R are organized using appropriate hash techniques. In fact, T and R can
even be represented by a single hash table where the entries are pairs ⟨s, b⟩with b ∈{0, 1}.
The meaning of ⟨s, 0⟩is that s is in R, but not in T (i.e., s has been visited in the outer,
but not yet in the inner DFS). The pair ⟨s, 1⟩means that s has been visited in both the
outer and the inner DFS. The single bit b is suﬃcient to cover all possible cases, since T
is always a subset of R.
7exactly once, if Algorithm 8 does not abort with the answer ”no”.

Summary
217
Another simple observation can speed up the nested depth-ﬁrst search in case the persis-
tence property is violated: whenever the inner DFS cycle check(s) reaches a state t which
is on the stack U (the DFS stack for the outer DFS), then the upper part of U yields a path
fragment from t to s, while the content of the DFS stack V for the inner DFS describes a
path fragment from s to t. Thus, a cycle has been found which visits s inﬁnitely often and
the nested DFS may abort with a counterexample. To support checking whether state t
is contained in stack U, a further bit can be added to the entries in the hash table for
representing T and R. I.e., we then have to deal with a hash table for triples ⟨s, b, c⟩with
s ∈R and b, c ∈{0, 1} depending on whether s is in T (in which case b = 1) and whether
s is in U (in which case c = 1). This leads to a slight variant of Algorithm 8 which is often
faster and generates smaller counterexamples than the original version.
4.5
Summary
• NFAs and DFAs are equivalent automata models for regular languages and can serve
to represent the bad preﬁxes of regular safety properties.
• Checking a regular safety property on a ﬁnite transition system is solvable by check-
ing an invariant on a product automaton, and thus amounts to solving a reachability
problem.
• ω-Regular languages are languages of inﬁnite words that can be described by ω-
regular expressions.
• NBAs are acceptors for inﬁnite words. The syntax is as for NFAs. The accepted
language of an NBA is the set of all inﬁnite words that have a run where an accept
state is visited inﬁnitely often.
• NBAs can serve to represent ω-regular properties.
• The class of languages that are recognized by NBAs agrees with the class of ω-regular
languages.
• DBAs are less powerful than NBAs and fail, for instance, to represent the persistence
property ”eventually forever a”.
• Generalized NBAs are deﬁned as NBAs, except that they require repeated visits for
several acceptance sets. Their expressiveness is the same as for NBAs.
• Checking an ω-regular property P on a ﬁnite transition system TS can be reduced to
checking the persistence property “eventually forever no accept state” in the product
of TS and an NBA for the undesired behaviors (i.e., the complement property P).

218
Regular Properties
• Persistence checking requires checking the existence of a reachable cycle containing
a state violating the persistence condition. This is solvable in linear time by a nested
depth-ﬁrst search (or by analyzing the strongly connected components). The same
holds for the nonemptiness problem for NBAs which boils down to checking the
existence of a reachable cycle containing an accept state.
• The nested depth-ﬁrst search approach consists of the interleaving of two depth-ﬁrst
searches: one for encountering the reachable states, and one for cycle detection.
4.6
Bibliographic Notes
Finite automata and regular languages. The ﬁrst papers on ﬁnite automata were pub-
lished in the nineteen ﬁfties by Huﬀman [217], Mealy [291], and Moore [303] who used
deterministic ﬁnite automata for representing sequential circuits. Regula r expressions
and their equivalence to ﬁnite automata goes back to Kleene [240]. Rabin and Scott [350]
presented various algorithms on ﬁnite automata, including the powerset construction. The
existence of minimal DFAs relies on results stated by Myhill [309] and Nerode [313]. The
O(N log N) minimization algorithm we mentioned at the end of Section 4.1 has been sug-
gested by Hopcroft [213]. For other algorithms on ﬁnite automata, a detailed description
of the techniques sketched here and other aspects of regular languages, we refer to the
text books [272, 363, 214, 383] and the literature mentioned therein.
Automata over inﬁnite words. Research on automata over inﬁnite words (and trees) started
in the nineteen sixties with the work of B¨uchi [73], Trakhtenbrot [392], and Rabin [351]
on decision problems for mathematical logics.
At the same time, Muller [307] studied
a special type of deterministic ω-automata (today called Muller automata) in the con-
text of asynchronous circuits. The equivalence of nondeterministic B¨uchi automata and
ω-regular expressions has been shown by McNaughton [290]. He also established a link be-
tween NBAs and deterministic Muller automata [307] by introducing another acceptance
condition that has been later formalized by Rabin [351]. (The resulting ω-automata type is
today called Rabin automata.) An alternative transformation from NBA to deterministic
Rabin automata has been presented by Safra [361]. Unlike B¨uchi automata, the nondeter-
ministic and deterministic versions of Muller and Rabin automata are equally expressive
and yield automata-characterizations of ω-regular languages. The same holds for several
other types of ω-automata that have been introduced later, e.g., Streett automata [382]
or automata with the parity condition [305].
The fact that ω-regular languages are closed under complementation (we stated this result
without proof) can be derived easily from deterministic automata representations. The
proof of Theorem 4.50 follows the presentation given in the book by Peled [327]. Various

Exercises
219
decision problems for ω-automata have been addressed by Landweber [261] and later by
Emerson and Lei [143] and Sistla, Vardi, and Wolper [373]. For a survey of automata on
inﬁnite words, transformations between the several classes of ω-automata, complementa-
tion operators and other algorithms on ω-automata, we refer to the articles by Choueka
[81], Kaminsky [229], Staiger [376], and Thomas [390, 391]. An excellent overview of the
main concepts of and recent results on ω-automata is provided by the tutorial proceedings
[174].
Automata and linear-time properties. The use of B¨uchi automata for the representation
and veriﬁcation of linear-time properties goes back to Vardi and Wolper [411, 412] who
studied the connection of B¨uchi automata with linear temporal logic. Approaches with
similar automata models have been developed independently by Lichtenstein, Pnueli, and
Zuck [274] and Kurshan [250]. The veriﬁcation of (regular) safety properties has been
described by Kupferman and Vardi [249]. The notion of persistence property has been
introduced by Manna and Pnueli [282] who provided a hierarchy of temporal properties.
The nested depth-ﬁrst algorithm (see Algorithm 8) originates from Courcoubetis et al. [102]
and its implementation in the model checker SPIN has been reported by Holzmann, Peled,
and Yannakakis [212].
The Murϕ veriﬁer developed by Dill [132] focuses on verifying
safety properties. Variants of the nested depth-ﬁrst search have been proposed by several
authors, see, e.g., [106, 368, 161, 163]. Approaches that treat generalized B¨uchi conditions
(i.e., conjunctions of B¨uchi conditions) are discussed in [102, 388, 184, 107].
Further
implementation details of the nested depth-ﬁrst search approach can be found in the book
by Holzman [209].
4.7
Exercises
Exercise 4.1.
Let AP = { a, b, c }. Consider the following LT properties:
(a) If a becomes valid, afterward b stays valid ad inﬁnitum or until c holds.
(b) Between two neighboring occurrences of a, b always holds.
(c) Between two neighboring occurrences of a, b occurs more often than c.
(d) a ∧¬b and b ∧¬a are valid in alternation or until c becomes valid.
For each property Pi (1 ⩽i ⩽4), decide if it is a regular safety property (justify your answers) and
if so, deﬁne the NFA Ai with L(Ai) = BadPref(Pi). (Hint: You may use propositional formulae
over the set AP as transition labels.)

220
Regular Properties
Exercise 4.2.
Let n ⩾1. Consider the language Ln ⊆Σ∗over the alphabet Σ = { A, B } that
consists of all ﬁnite words where the symbol B is on position n from the right, i.e., L contains
exactly the words A1A2 . . . Ak ∈{A, B}∗where k ⩾n and Ak−n+1 = B. For instance, the word
ABBAABAB is in L3.
(a) Construct an NFA An with at most n+1 states such that L(An) = Ln.
(b) Determinize this NFA An using the powerset construction algorithm.
Exercise 4.3.
Consider the transition system TSSem for the two-process mutual exclusion with
a semaphore (see Example 2.24 on page 43) and TSPet for Peterson’s algorithm (see Example 2.25
on page 45).
(a) Let Psafe be the regular safety property “process 1 never enters its critical section from its
noncritical section (i.e., process 1 must be in its waiting location before entering the critical
section)” and AP = { wait1, crit1 }.
(i) Depict an NFA for the minimal bad preﬁxes for Psafe.
(ii) Apply the algorithm in Section 4.2 to verify TSSem |= Psafe.
(b) Let Psafe be the safety property “process 1 never enters its critical section from a state where
x = 2” and AP = { crit1, x = 2 }.
(i) Depict an NFA for the minimal bad preﬁxes for Psafe.
(ii) Apply the algorithm in Section 4.2 to verify TSPet ̸|= Psafe. Which counterexample is
returned by the algorithm?
Exercise 4.4.
Let Psafe be a safety property. Prove or disprove the following statements:
(a) If L is a regular language with MinBadPref(Psafe) ⊆L ⊆BadPref(Psafe), then Psafe is
regular.
(b) If Psafe is regular, then any L for which MinBadPref(Psafe) ⊆L ⊆BadPref(Psafe) is regular.
Exercise 4.5.
Let AP = { a, b, c }. Consider the following NFA A (over the alphabet 2AP) and
the following transition system TS:

Exercises
221
A :
q0
q1
q2
a
¬b ∧¬c
¬b ∧¬c
b ∧¬c
b ∧¬c
¬a
c
q3
c
T S :
s1
∅
s2
{b, c}
s4
{b}
s3
{a}
α
γ
β
γ
γ
α
β
Construct the product TS ⊗A of the transition system and the NFA.
Exercise 4.6.
Consider the following transition system TS
s0
{ a, b }
s1
{ a, b, c }
s2
{ b, c }
s3
{ a, c }
s4
{ a, c }
s5
{ a, b }
α
γ
β
γ
β
α
β
γ
α
and the regular safety property
Psafe = “always if a is valid and b ∧¬c was valid somewhere before,
then a and b do not hold thereafter at least until c holds”
As an example, it holds:
{ b }∅{ a, b }{ a, b, c }
∈pref(Psafe)
{ a, b }{ a, b }∅{ b, c }
∈pref(Psafe)
{ b }{ a, c }{ a }{ a, b, c }
∈BadPref(Psafe)
{ b }{ a, c }{ a, c }{ a }
∈BadPref(Psafe)
Questions:
(a) Deﬁne an NFA A such that L(A) = MinBadPref(Psafe).
(b) Decide whether TS |= Psafe using the TS ⊗A construction.
Provide a counterexample if TS ̸|= Psafe.
Exercise 4.7.
Prove or disprove the following equivalences for ω-regular expressions:

222
Regular Properties
(a) (E1 + E2).Fω
≡
E1.Fω + E2.Fω
(b) E.(F1 + F2)ω
≡
E.Fω
1 + E.Fω
2
(c) E.(F.F∗)ω
≡
E.Fω
(d) (E∗.F)ω
≡
E∗.Fω
where E, E1, E2, F, F1, F2 are arbitrary regular expressions with ε /∈L(F) ∪L(F1) ∪L(F2).
Exercise 4.8.
Generalized ω-regular expressions are built from the symbols ∅(to denote the
empty language), ε (to denote the language {ε} consisting of the empty word), the symbols A for
A ∈Σ (for the singleton sets {A}) and the language operators “+” (union), “.” (concatenation),
“∗” (Kleene star, ﬁnite repetition), and “ω”(inﬁnite repetition). The semantics of a generalized
ω-regular expression G is a language Lg(G) ⊆Σ∗∪Σω, which is deﬁned by
• Lg(∅) = ∅,
Lg(ε) = {ε},
Lg(A) = {A},
• Lg(G1 + G2) = Lg(G1) ∪Lg(G2) and Lg(G1.G2) = Lg(G1).Lg(G2),
• Lg(G∗) = Lg(G)∗, and Lg(Gω) = Lg(G)ω.
Two generalized ω-regular expressions G and G′ are called equivalent iﬀLg(G) = Lg(G′).
Show that for each generalized ω-regular expression G there exists an equivalent generalized ω-
regular expression G′ of the form
G′ = E + E1.Fω
1 + . . . En.Fω
n
where E, E1, . . . , En, F1, . . . , Fn are regular expressions and ε /∈L(Fi), i = 1, . . . , n.
Exercise 4.9.
Let Σ = { A, B }. Construct an NBA A that accepts the set of inﬁnite words σ
over Σ such that A occurs inﬁnitely many times in σ and between any two successive A’s an odd
number of B’s occur.
Exercise 4.10.
Let Σ = { A, B, C } be an alphabet.
(a) Construct an NBA A that accepts exactly the inﬁnite words σ over Σ such that A occurs
inﬁnitely many times in σ and between any two successive A’s an odd number of B’s or an
odd number of C’s occur. Moreover, between any two successive A’s either only B’s or only
C’s are allowed. That is, the accepted words should have the form
wAv1Av2Av3 . . .
where w ∈{ B, C }∗, vi ∈{ B2k+1 | k ⩾0 } ∪{ C2k+1 | k ⩾0 } for all i > 0. Give also an
ω-regular expression for this language.

Exercises
223
(b) Repeat the previous exercise such that any accepting word contains only ﬁnitely many C’s.
(c) Change your automaton from part (a) such that between any two successive A’s an odd
number of symbols from the set { B, C } may occur.
(d) Same exercise as in (c), except that now an odd number of B’s and an odd number of C’s
must occur between any two successive A symbols.
Exercise 4.11.
Depict an NBA for the language described by the ω-regular expression
(AB + C)∗((AA + B)C)ω + (A∗C)ω.

224
Regular Properties
Exercise 4.12.
Consider the following NBA A1 and A2 over the alphabet { A, B, C }:
q0
q1
q2
A
A, B, C
A, B, C
C
A1 :
A2 :
q0
q1
q3
A
B
B
A
q2
B
C
B, C
A
C
Find ω-regular expressions for the languages accepted by A1 and A2.
Exercise 4.13.
Consider the NFA A1 and A2:
A1:
p0
p1
p3
p4
p2
A
B
C
A
A, B
C
A
B
C
A2 :
q0
q1
q2
q3
q4
C
B
A
B
A
C
B
Construct an NBA for the language L(A1).L (A2)ω.
Exercise 4.14.
Let AP = { a, b }. Give an NBA for the LT property consisting of the inﬁnite
words A0A1A2 . . .

2APω such that
∞
∃j ⩾0. (a ∈Aj ∧b ∈Aj)
and
∃j ⩾0. (a ∈Aj ∧b /∈Aj).
Provide an ω-regular expression for Lω(A).
Exercise 4.15.
Let AP = {a, b, c}. Depict an NBA for the LT property consisting of the inﬁnite
words A0A1A2 . . .

2APω such that
∀j ⩾0. A2j |= (a ∨(b ∧c))

Exercises
225
Recall that A |= (a ∨(b ∧c)) means a ∈A or {b, c} ⊆A, i.e., A ∈{ { a }, { b, c }, { a, b, c } }.
Exercise 4.16.
Consider NBA A1 and A2 depicted in Figure 4.26. Show that the powerset
construction applied to A1 and A2 (viewed as NFA) yields the same deterministic automaton,
while Lω(A1) ̸= Lω(A2). (This exercise is taken from [408].)
A
A
A
A
A
(b)
(a)
Figure 4.26: NBA A1 (a) and A2 (b).
Exercise 4.17.
Consider the following NBA A with the alphabet Σ = 2AP where AP =
{ a1, . . . , an } for n > 0.
q0
q1
q2
qn
true
a1
an
a2
an−1
¬a1
¬a2
¬an
(a) Determine the accepted language Lω(A).
(b) Show that there is no NBA A′ with Lω(A) = Lω(A′) and less than n states.
(This exercise is inspired by [149].)

226
Regular Properties
Exercise 4.18.
Provide an example for a regular safety property Psafe over AP and an NFA A
for its minimal bad preﬁxes such that
Lω(A) ̸=

2APω \ Psafe
when A is viewed as an NBA.
Exercise 4.19.
Provide an example for a liveness property that is not ω-regular. Justify your
answer.
Exercise 4.20.
Is there a DBA that accepts the language described by the ω-regular expression
(A + B)∗(AB + BA)ω? Justify your answer.
Exercise 4.21.
Provide an example for an ω-regular language L = Lk that is recognizable for a
DBA such that the following two conditions are satisﬁed:
(a) There exists an NBA A with |A| = O(k) and Lω(A) = L.
(b) Each DBA A′ for L is of the size |A′| = Ω(2k).
Hint: There is a simple answer to this question that uses the result that the regular language for
the expression (A + B)∗B(A + B)k is recognizable by an NFA of size O(k), while any DFA has
Ω(2k) states.
Exercise 4.22.
Show that the class of languages that are accepted by DBAs is not closed under
complementation.
Exercise 4.23.
Show that the class of languages that are accepted by DBAs is closed under
union. To do so, prove the following stronger statement:
Let A1 and A2 be two DBAs both over the alphabet Σ. Show that there exists a DBA A with
|A| = O(|A1| · |A2|) and Lω(A) = Lω(A1) ∪Lω(A2).
Exercise 4.24.
Consider the GNBA outlined on the right with acceptance
sets F1 = { q1 } and F2 = { q2 }. Construct an equivalent
NBA.
q0
q1
q2
A
B
B
B
B

Exercises
227
Exercise 4.25. Provide NBA A1 and A2 for the languages given by the expressions (AC+B)∗Bω
and (B∗AC)ω and apply the product construction to obtain a GNBA G with Lω(G) = Lω(A1) ∩
Lω(A2). Justify that Lω(G) = ∅.
Exercise 4.26.
A nondeterministic Muller automaton is a quintuple A = (Q, Σ, δ, Q0, F)
where Q, Σ, δ, Q0 are as for NBA and F ⊆2Q.
For an inﬁnite run ρ of A, let lim(ρ) :=

q ∈Q |
∞
∃i ≥0. ρ[i] = q

. Let α ∈Σω.
A accepts α ⇐⇒
ex. inﬁnite run ρ of A on α s.t. lim(ρ) ∈F
(a) Consider the following Muller automaton A with F = {{q2, q3}, {q1, q3}, {q0, q2}}:
q1
q2
q0
q3
A
A
B
B
C
C
Deﬁne the language accepted by A by means of an ω-regular expression.
(b) Show that every GNBA G can be transformed into a nondeterministic Muller automaton A
such that Lω(A) = Lω(G) by deﬁning the corresponding transformation.
Exercise 4.27.
Consider the transition systems TSSem and TSPet for mutual exclusion with a
semaphore and the Peterson algorithm, respectively. Let Plive be the following ω-regular property
over AP = { wait1, crit1 }:
“whenever process 1 is in its waiting location then it will eventually enter its critical section”
(a) Depict an NBA for Plive and an NBA ¯
A for the complement property ¯Plive =

2AP ω \Plive.
(b) Show that TSSem ̸|= Plive by applying the techniques explained in Section 4.4:
(i) Depict the reachable fragment of the product TSSem ⊗¯
A
(ii) Sketch the main steps of the nested depth-ﬁrst search applied to TSSem ⊗¯
A for the
persistence property “eventually forever ¬F” where F is the acceptance set of
¯
A.
Which counterexample is returned by Algorithm ?8
(c) Apply now the same techniques (product construction, nested DFS) to show that TSPet |=
Plive.
Exercise 4.28. The nested depth-ﬁrst search approach can also be reformulated for an emptiness
check for NBA. The path fragment returned by Algorithm 8 in case of a negative answer then yields
a preﬁx of an accepting run.

228
Regular Properties
Consider the automaton shown in Exercise 4.24 as an NBA, i.e., the acceptance set is F = { q1, q2 }.
Apply the nested depth-ﬁrst search approach to verify that Lω(A) ̸= ∅.

Chapter 5
Linear Temporal Logic
This chapter introduces (propositional) linear temporal logic (LTL), a logical formalism
that is suited for specifying LT properties. The syntax and semantics of linear temporal
logic are deﬁned. Various examples are provided that show how linear temporal logic
can be used to specify important system properties. The second part of the chapter is
concerned with a model-checking algorithm—based on B¨uchi automata—for LTL. This
algorithm can be used to answer the question: given a transition system TS and LTL-
formula ϕ, how to check whether ϕ holds in TS?
5.1
Linear Temporal Logic
For reactive systems, correctness depends on the executions of the system—not only on
the input and output of a computation—and on fairness issues.
Temporal logic is a
formalism par excellence for treating these aspects. Temporal logic extends propositional
or predicate logic by modalities that permit to referral to the inﬁnite behavior of a reactive
system. They provide a very intuitive but mathematically precise notation for expressing
properties about the relation between the state labels in executions, i.e., LT properties.
Temporal logics and related modal logics have been studied in ancient times in diﬀerent
areas such as philosophy. Their application to verifying complex computer systems was
proposed by Pnueli in the late seventies.
In this monograph, we will focus our attention on propositional temporal logics, i.e., exten-
sions of propositional logic by temporal modalities. These logics should be distinguished
from ﬁrst- (or higher-) order temporal logics that impose temporal modalities on top of
229

230
Linear Temporal Logic
predicate logic. Throughout this monograph we assume some familiarity with the basic
principles of propositional logic. A brief introduction and summary of our notations can
be found in Appendix A.3. The elementary temporal modalities that are present in most
temporal logics include the operators:
♦
“eventually” (eventually in the future)
□
“always” (now and forever in the future)
The underlying nature of time in temporal logics can be either linear or branching. In
the linear view, at each moment in time there is a single successor moment, whereas
in the branching view it has a branching, tree-like structure, where time may split into
alternative courses. This chapter considers LTL (Linear Temporal Logic), a temporal logic
that is based on a linear-time perspective. Chapter 6 introduces CTL (Computation Tree
Logic), a logic that that is based on a branching-time view. Several model-checking tools
use LTL (or a slight variant thereof) as a property speciﬁcation language. The model
checker SPIN is a prominent example of such an automated veriﬁcation tool. One of the
main advantages of LTL is that imposing fairness assumptions (such as strong and weak
fairness) does not require the use of any new machinery: the typical fairness assumptions
can all be speciﬁed in LTL. Verifying LTL-formulae under fairness constraints can be done
using the algorithm for LTL. This does not apply to CTL.
Before introducing LTL in more detail, a short comment on the adjective “temporal” is in
order to avoid any possible confusion. Although the term temporal suggests a relationship
with the real-time behavior of a reactive system, this is only true in an abstract sense. A
temporal logic allows for the speciﬁcation of the relative order of events. Some examples
are “the car stops once the driver pushes the brake”, or “the message is received after
it has been sent”. It does however not support any means to refer to the precise timing
of events. The fact that there is a minimal delay of at least 3 μs between braking and
the actual halting of the car cannot be speciﬁed. In terms of transition systems, neither
the duration of taking a transition nor state residence times can be speciﬁed using the
elementary modalities of temporal logics. Instead, these modalities do allow for specifying
the order in which state labels occur during an execution, or to assess that certain state
labels occur inﬁnitely often in a (or all) system execution. One might thus say that the
modalities in temporal logic are time-abstract.
As will be discussed in this chapter, LTL may be used to express the timing for the class
of synchronous systems in which all components proceed in a lock-step fashion. In this
setting, a transition corresponds to the advance of a single time-unit. The underlying
time domain is thus discrete, i.e., the present moment refers to the current state and
the next moment corresponds to the immediate successor state. Stated diﬀerently, the
system behavior is assumed to be observable at the time points 0, 1, 2, . . .. The treatment

Linear Temporal Logic
231
of real-time constraints in asynchronous systems by means of a continuous-time domain
will be discussed in Chapter 9 where a timed version of CTL, called Timed CTL, will be
introduced. Table 5.1 summarizes the distinguishing features of the main temporal logics
considered in this monograph.
logic
linear-time
branching-time
real-time requirements
(path-based)
(state-based)
(continuous-time domain)
LTL
√
CTL
√
Timed CTL
√
√
Table 5.1: Classiﬁcation of the temporal logics in this monograph.
5.1.1
Syntax
This subsection describes the syntactic rules according to which formulae in LTL can
be constructed.
The basic ingredients of LTL-formulae are atomic propositions (state
labels a ∈AP), the Boolean connectors like conjunction ∧, and negation ¬, and two
basic temporal modalities ⃝(pronounced “next”) and U (pronounced “until”).
The
atomic proposition a ∈AP stands for the state label a in a transition system. Typically,
the atoms are assertions about the values of control variables (e.g., locations in program
graphs) or the values of program variables such as ”x > 5” or ”x ⩽y”. The ⃝-modality
is a unary preﬁx operator and requires a single LTL formula as argument. Formula ⃝ϕ
holds at the current moment, if ϕ holds in the next “step”. The U -modality is a binary
inﬁx operator and requires two LTL formulae as argument. Formula ϕ1 U ϕ2 holds at the
current moment, if there is some future moment for which ϕ2 holds and ϕ1 holds at all
moments until that future moment.
Deﬁnition 5.1.
Syntax of LTL
LTL formulae over the set AP of atomic proposition are formed according to the following
grammar:1
ϕ ::= true
   a
   ϕ1 ∧ϕ2
   ¬ϕ
   
⃝ϕ
   ϕ1 U ϕ2
where a ∈AP.
1The Backus Naur form (BNF) is used in a somewhat liberal way. More concretely, nonterminals are
identiﬁed with derived words (formulae) and indices in the rules. Moreover, brackets will be used, e.g. in
a ∧(b U c), which are not shown in the grammar. Such simpliﬁed notations for grammars to determine the
syntax of formulae of some logic (or terms of other calculi) are often called abstract syntax.

232
Linear Temporal Logic
We mostly abstain from explicitly indicating the set AP of propositions as this follows
either from the context or can be deﬁned as the set of atomic propositions occurring in
the LTL formula at hand.
The precedence order on the operators is as follows. The unary operators bind stronger
than the binary ones.
¬ and ⃝bind equally strong. The temporal operator U takes
precedence over ∧, ∨, and →. Parentheses are omitted whenever appropriate, e.g., we write
¬ϕ1 U ⃝ϕ2 instead of (¬ϕ1) U (⃝ϕ2). Operator U is right-associative, e.g., ϕ1 U ϕ2 U ϕ3
stands for ϕ1 U (ϕ2 U ϕ3).
Using the Boolean connectives ∧and ¬, the full power of propositional logic is obtained.
Other Boolean connectives such as disjunction ∨, implication →, equivalence ↔, and the
parity (or: exclusive or) operator ⊕can be derived as follows:
ϕ1 ∨ϕ2
def
=
¬(¬ϕ1 ∧¬ϕ2)
ϕ1 →ϕ2
def
=
¬ϕ1 ∨ϕ2
ϕ1 ↔ϕ2
def
=
(ϕ1 →ϕ2) ∧(ϕ2 →ϕ1)
ϕ1 ⊕ϕ2
def
=
(ϕ1 ∧¬ϕ2) ∨(ϕ2 ∧¬ϕ1)
...
The until operator allows to derive the temporal modalities ♦(“eventually”, sometimes
in the future) and □(“always”, from now on forever) as follows:
♦ϕ
def
= true U ϕ
□ϕ
def
= ¬♦¬ϕ
As a result, the following intuitive meaning of ♦and □is obtained. ♦ϕ ensures that ϕ
will be true eventually in the future. □ϕ is satisﬁed if and only if it is not the case that
eventually ¬ϕ holds. This is equivalent to the fact that ϕ holds from now on forever.
Figure 5.1 sketches the intuitive meaning of temporal modalities for the simple case in
which the arguments of the modalities are just atomic propositions from { a, b }. On the
left-hand side, some LTL formulae are indicated, whereas on the right hand side sequences
of states (i.e., paths) are depicted.
By combining the temporal modalities ♦and □, new temporal modalities are obtained.
For instance, □♦a (“always eventually a”) describes the (path) property stating that at
any moment j there is a moment i ⩾j at which an a-state is visited. This thus amounts
to assert that an a-state is visited inﬁnitely often. The dual modality ♦□a expresses that
from some moment j on, only a-states are visited. So:
□♦ϕ
“inﬁnitely often ϕ”
♦□ϕ
“eventually forever ϕ”

Linear Temporal Logic
233
a
atomic prop. a
arbitrary
arbitrary
arbitrary
arbitrary
. . .
arbitrary
next step ⃝a
a
arbitrary
arbitrary
arbitrary
. . .
a ∧¬b
until a U b
a ∧¬b
a ∧¬b
b
arbitrary
. . .
¬a
eventually ♦a
¬a
¬a
a
arbitrary
. . .
a
always □a
a
a
a
a
. . .
Figure 5.1: Intuitive semantics of temporal modalities.
Before proceeding with the formal semantics of LTL, we present some examples.
Example 5.2.
Properties for the Mutual Exclusion Problem
Consider the mutual exclusion problem for two concurrent processes P1 and P2, say. Pro-
cess Pi is modeled by three locations: (1) the noncritical section, (2) the waiting phase
which is entered when the process intends to enter the critical section, and (3) the critical
section. Let the propositions waiti and criti denote that process Pi is in its waiting phase
and critical section, respectively.
The safety property stating that P1 and P2 never simultaneously have access to their
critical sections can be described by the LTL-formula:
□( ¬ crit1 ∨¬ crit2).
This formula expresses that always (□) at least one of the two processes is not in its critical
section (¬criti).
The liveness requirement stating that each process Pi is inﬁnitely often in its critical

234
Linear Temporal Logic
section is described by the LTL formula:
(□♦crit1) ∧(□♦crit2).
The weakened form that every waiting process will eventually enter its critical section
(i.e., starvation freedom) can—by using the additional proposition waiti—be formulated
as follows:
(□♦wait1 →□♦crit1) ∧(□♦wait2 →□♦crit2).
These formulae only refer to the locations (i.e., values of the program counters) by the
atomic propositions waiti and criti. Propositions can however also refer to program vari-
ables.
For instance, for the solution of the mutual exclusion problem using a binary
semaphore y, the formula:
□((y = 0) →crit1 ∨crit2)
states that whenever the semaphore y has the value 0, one of the processes is in its critical
section.
Example 5.3.
Properties for the dining philosophers
For the dining philosophers (see Example 3.2 on page 90) deadlock freedom can be de-
scribed by the LTL formula
□¬(

0⩽i<n
waiti
∧

0⩽i<n
occupiedi).
We assume here that there are n philosophers and chop sticks, indexed from 0 to n−1.
The atom waiti means that philosopher i waits for one of the sticks on his left or right,
but keeps the other one in his hand. Similarly, occupiedi indicates that stick i is in use.
Example 5.4.
Properties for a Traﬃc Light
For a traﬃc light with the phases ”green”, ”red” and ”yellow”, the liveness property
□♦green expresses that the traﬃc light is inﬁnitely often green. A speciﬁcation of the
traﬃc light cycles and their chronological order can be provided by means of a conjunction
of LTL-formulae stating the predecessor phase of any phase. For instance, the requirement
“once red, the light cannot become green immediately” can be expressed by the LTL
formula
□(red →¬ ⃝green).
The requirement “once red, the light always becomes green eventually after being yellow
for some time” is expressed by
□(red →⃝(red U (yellow ∧⃝(yellow U green)))).

Linear Temporal Logic
235
A progress property like “every request will eventually lead to a response” can be described
by the following formula of the type
□(request →♦response).
Remark 5.5.
Length of a Formula
Let | ϕ | denote the length of LTL formula ϕ in terms of the number of operators in ϕ.
This can easily be deﬁned by induction on the structure of ϕ. For instance, the length
of the formula true and a ∈AP is 0. Formulae ⃝a ∨b and a ∨¬b have length 2, and
(⃝a) U (a ∧¬b) has length 4. Throughout this monograph, mostly the asymptotic size
Θ(| ϕ |) is needed. For this purpose, it is irrelevant whether or not the derived Boolean
operators ∨, →, and so on, and the derived temporal modalities ♦and □are taken into
account in determining the length.
5.1.2
Semantics
LTL formulae stand for properties of paths (or in fact their trace). This means that a
path can either fulﬁll an LTL-formula or not. To precisely formulate when a path satisﬁes
an LTL formula, we proceed as follows. First, the semantics of LTL formula ϕ is deﬁned
as a language Words(ϕ) that contains all inﬁnite words over the alphabet 2AP that satisfy
ϕ. That is, to every LTL formula a single LT property is associated. Then, the semantics
is extended to an interpretation over paths and states of a transition system.
Deﬁnition 5.6.
Semantics of LTL (Interpretation over Words)
Let ϕ be an LTL formula over AP. The LT property induced by ϕ is
Words(ϕ) =

σ ∈(2AP)ω | σ |= ϕ

where the satisfaction relation |= ⊆
(2AP)ω × LTL is the smallest relation with the
properties in Figure 5.2.
Here, for σ = A0 A1 A2 . . . ∈(2AP)ω, σ[j . . .] = Aj Aj+1 Aj+2 . . . is the suﬃx of σ starting
in the (j+1)st symbol Aj.
Note that in the deﬁnition of the semantics of LTL-formulae the word fragment σ[j . . .]
cannot be replaced with Aj. For the formula ⃝(a U b), e.g., the suﬃx A1 A2 A3 . . . has to

236
Linear Temporal Logic
σ
|=
true
σ
|=
a
iﬀ
a ∈A0
(i.e., A0 |= a)
σ
|=
ϕ1 ∧ϕ2
iﬀ
σ |= ϕ1 and σ |= ϕ2
σ
|=
¬ ϕ
iﬀ
σ ̸|= ϕ
σ
|=
⃝ϕ
iﬀ
σ[1 . . .] = A1A2A3 . . . |= ϕ
σ
|=
ϕ1 U ϕ2
iﬀ
∃j ⩾0. σ[j . . .] |= ϕ2 and σ[i . . .] |= ϕ1, for all 0 ⩽i < j
Figure 5.2: LTL semantics (satisfaction relation |=) for inﬁnite words over 2AP.
be regarded in order to be able to refer to the truth-value of the subformula a U b in the
“next step”.
For the derived operators ♦and □the expected result is:
σ
|=
♦ϕ
iﬀ
∃j ⩾0. σ[j . . .] |= ϕ
σ
|=
□ϕ
iﬀ
∀j ⩾0. σ[j . . .] |= ϕ.
The statement for ♦is immediate from the deﬁnition of ♦and the semantics of U . The
statement for □follows from:
σ |= □ϕ = ¬♦¬ϕ
iﬀ
¬∃j ⩾0. σ[j . . .] |= ¬ϕ
iﬀ
¬∃j ⩾0. σ[j . . .] ̸|= ϕ
iﬀ
∀j ⩾0. σ[j . . .] |= ϕ.
The semantics of the combinations of □and ♦can now be derived:
σ
|=
□♦ϕ
iﬀ
∞
∃j. σ[j . . .] |= ϕ
σ
|=
♦□ϕ
iﬀ
∞
∀j. σ[j . . .] |= ϕ.
Here,
∞
∃j means ∀i ⩾0. ∃j ⩾i, “for inﬁnitely many j ∈IN”, while
∞
∀j stands for
∃i ⩾0. ∀j ⩾i, “for almost all j ∈IN”. Let us verify the ﬁrst statement. The argument
for the second statement is similar.
σ |= □♦ϕ
iﬀ
∀i ⩾0. σ[i . . .] |= ♦ϕ
iﬀ
∀i ⩾0. ∃j ⩾i. σ[j . . .] |= ϕ
iﬀ
∞
∃j. σ[j . . .] |= ϕ.
As a subsequent step, we determine the semantics of LTL-formulae with respect to a

Linear Temporal Logic
237
transition system. According to the satisfaction relation for LT properties (see Deﬁnition
3.11 on page 100), the LTL formula ϕ holds in state s if all paths starting in s satisfy ϕ.
The transition system TS satisﬁes ϕ if TS satisﬁes the LT property Words(ϕ), i.e., if all
initial paths of TS—paths starting in an initial state s0 ∈I—satisfy ϕ.
Recall that we may assume without loss of generality that transition system TS has no
terminal states (if it has such states, a trap state can be introduced. Thus, we may assume
that all paths and traces are inﬁnite. This assumption is made for the sake of simplicity; it
is also possible to deﬁne the semantics of LTL for ﬁnite paths. Note that for the semantics
it is irrelevant whether or not TS is ﬁnite. Only for the model-checking algorithm later
on in this chapter, is the ﬁniteness of TS required.
As for the LT properties, when deﬁning TS |= ϕ for transition system TS over AP′, it
is assumed that ϕ is an LTL-formula with atomic propositions in AP = AP′. (Here, one
could be more liberal and allow for AP ⊆AP′.)
Deﬁnition 5.7.
Semantics of LTL over Paths and States
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states, and let ϕ
be an LTL-formula over AP.
• For inﬁnite path fragment π of TS, the satisfaction relation is deﬁned by
π |= ϕ
iﬀ
trace(π) |= ϕ.
• For state s ∈S, the satisfaction relation |= is deﬁned by
s |= ϕ
iﬀ
(∀π ∈Paths(s). π |= ϕ).
• TS satisﬁes ϕ, denoted TS |= ϕ, if Traces(TS) ⊆Words(ϕ).
From this deﬁnition, it immediately follows that
TS |= ϕ
iﬀ
(* Deﬁnition 5.7 *)
Traces(TS) ⊆Words(ϕ)
iﬀ
(* Deﬁnition of |= for LT properties *)
TS |= Words(ϕ)
iﬀ
(* Deﬁnition of Words(ϕ) *)
π |= ϕ for all π ∈Paths(TS)
iﬀ
(* Deﬁnition 5.7 of |= for states *)
s0 |= ϕ for all s0 ∈I.

238
Linear Temporal Logic
Thus, TS |= ϕ if and only if s0 |= ϕ for all initial states s0 of TS.
{ a, b }
s1
{ a, b }
s2
{ a }
s3
Figure 5.3: Example for semantics of LTL.
Example 5.8.
Semantics of LTL
Consider the transition system TS depicted in Figure 5.3 with the set of propositions
AP = { a, b }. For example, we have that TS |= □a, since all states are labeled with a,
and hence, all traces of TS are words of the form A0 A1 A2 . . . with a ∈Ai for all i ⩾0.
Thus, si |= □a for i = 1, 2, 3. Moreover:
s1 |= ⃝(a ∧b) since s2 |= a ∧b and s2 is the only successor of s1
s2 ̸|= ⃝(a ∧b) and s3 ̸|= ⃝(a ∧b) as s3 ∈Post(s2), s3 ∈Post(s3) and s3 ̸|= a ∧b.
This yields TS ̸|= ⃝(a ∧b) as s3 is an initial state for which s3 ̸|= ⃝(a ∧b). As another
example:
TS |= □(¬b →□(a ∧¬b)),
since s3 is the only ¬b state, s3 cannot be left anymore, and a ∧¬b in s3 is true. However,
TS ̸|= b U (a ∧¬b),
since the initial path (s1s2)ω does not visit a state for which a ∧¬b holds. Note that the
initial path (s1s2)∗sω
3 satisﬁes b U (a ∧¬b).
Remark 5.9.
Semantics of Negation
For paths, it holds π |= ϕ if and only if π ̸|= ¬ϕ. This is due to the fact that
Words(¬ϕ) = (2AP)ω \ Words(ϕ).
However, the statements TS ̸|= ϕ and TS |= ¬ϕ are not equivalent in general. Instead, we
have TS |= ¬ϕ implies TS ̸|= ϕ. Note that
TS ̸|= ϕ
iﬀTraces(TS) ̸⊆Words(ϕ)
iﬀTraces(TS) \ Words(ϕ) ̸= ∅
iﬀTraces(TS) ∩Words(¬ϕ) ̸= ∅.

Linear Temporal Logic
239
Thus, it is possible that a transition system (or a state) satisﬁes neither ϕ nor ¬ϕ. This
is caused by the fact that there might be paths π1 and π2 in TS such that π1 |= ϕ and
π2 |= ¬ϕ (and therefore π2 ̸|= ϕ). In this case, TS ̸|= ϕ and TS ̸|= ¬ϕ holds.
To illustrate this eﬀect, consider the transition system depicted in Figure 5.4. Let AP =
{ a }. It follows that TS ̸|= ♦a, since the initial path s0(s2)ω ̸|= ♦a. On the other hand,
TS ̸|= ¬♦a also holds, since the initial path s0(s1)ω |= ♦a, and thus, s0(s1)ω ̸|= ¬♦a.
{ a }
s1
∅
s0
∅
s2
Figure 5.4: A transition system for which TS ̸|= ♦a and TS ̸|= ¬♦a.
5.1.3
Specifying Properties
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 5.5: Transition system of semaphore-based mutual exclusion algorithm.
Example 5.10.
Semaphore-Based Mutual Exclusion Revisited
Consider the transition system TSSem depicted in Figure 5.5 which represents a semaphore-
based solution to the mutual exclusion problem; see also Example 3.9 on page 98. Each

240
Linear Temporal Logic
state of the form ⟨c1, ·, ·⟩is labeled with proposition crit1 and each state of the form ⟨·, c2, ·⟩
is labeled with crit2. It follows that
TSSem |= □( ¬ crit1 ∨¬ crit2)
and
TSSem |= □♦crit1 ∨□♦crit2,
where the ﬁrst LTL-formula stands for the mutual exclusion property and the second
LTL-formula for the fact that at least one of the two processes enters its critical section
inﬁnitely often. However,
TSSem ̸|= □♦crit1 ∧□♦crit2,
since—in the absence of any fairness assumption—it is not ensured that process P1 is
enabled inﬁnitely often. It may not be able to acquire access to its critical section once.
(A similar argument applies to process P2.) The same argument applies to show that
TSSem ̸|= □♦wait1 →□♦crit1
as in principle process P1 may not get its turn once it starts to wait.
Example 5.11.
Modulo 4 Counter
A modulo 4 counter can be represented by a sequential circuit C, which outputs 1 in
every fourth cycle, otherwise 0. C has no input bits, one output bit y, and two registers
r1 and r2. The register evaluation [r1 = c1, r2 = c2] can be identiﬁed with the number
i = 2 · r1 + r2. In every cycle, the value of i is increased by 1 (modulo 4). We construct
C in a way such that the output bit y is set exactly for i = 0 (hence, r1 = r2 = 0). The
transition relation and output function are given by
δr1 = r1 ⊕r2,
δr2 = ¬r1,
λy = ¬r1 ∧¬r2.
Figure 5.6 illustrates the diagram (on the left) and the transition system TSC (on the
right). Let AP = { r1, r2, y }. The following statement can be directly inferred from TSC:
TSC
|=
□( y ↔¬r1 ∧¬r2 )
TSC
|=
□( r1 →
(⃝y ∨⃝⃝y) )
TSC
|=
□( y →(⃝¬y ∧⃝⃝¬y) )
If it is assumed that only the output variable y (and not the register evaluations) can be
perceived by an observer, then an appropriate choice for AP is AP = { y }. The property
that at least during every four cycles the output 1 is obtained holds for TSC, i.e., we have
TSC |= □( y ∨⃝y ∨⃝⃝y ∨⃝⃝⃝y ).

Linear Temporal Logic
241
NOT
r1
XOR
NOT
r2
AND
y
00
01
11
10
y
r1 r2
r2
r1
Figure 5.6: A modulo 4 counter.
The fact that these outputs are produced in a periodic manner where every fourth cycle
yields the output 1 is expressed as
TSC |= □( y −→(⃝¬y ∧⃝⃝¬y ∧⃝⃝⃝¬y) ).
Example 5.12.
A Communication Channel
Consider an unidirectional channel between two communicating processes, a sender S and
a receiver R. Sender S is equipped with an output buﬀer S.out and recipient R with an
input buﬀer R.in. If sender S sends a message m to R it inserts the message into its
output buﬀer S.out. The output buﬀer S.out and the input buﬀer R.in are connected via
an unidirectional channel. The receiver R receives messages by deleting messages from its
input buﬀer R.in. The capacity of the buﬀers is not of importance here.
A schematic view of the system under consideration is:
channel
Sender S
S.out
R.in
Receiver R
In the following LTL-speciﬁcations, we use the atoms “m ∈S.out” and “m ∈R.in” where
m is an arbitrary message.
We formalize the following informal requirements by LTL
formulae:
• “Whenever message m is in the out-buﬀer of S, then m will eventually be consumed
by the receiver.”
□(m ∈S.out −→♦(m ∈R.in))

242
Linear Temporal Logic
The above property is still satisﬁed for paths s1s2s3 . . . where s1 |= m ∈S.out,
s2 |= m /∈S.out, s2 |= m /∈R.in, and s3 |= m ∈R.in. However, such paths stand
for a mysterious behavior where message m in the output buﬀer for S (state s1)
gets lost (state s2), but still arrives in the input buﬀer of R (state s3). In fact, such
a behavior is impossible for a reliable FIFO channel which satisﬁes the following
stronger condition
□(m ∈S.out −→(m ∈S.out U m ∈R.in))
stating that message m stays in S.out until the receiver R consumes m. Since writing
and reading in a FIFO channel cannot happen at the same moment, we can even
use the formula
□(m ∈S.out −→⃝(m ∈S.out U m ∈R.in)).
• If we assume that no message occurs twice in S.out then the asynchronous behavior
of a FIFO channel ensures that the property “message m cannot be in both buﬀers
at the same time”. This is formalized by the LTL formula:
□¬ (m ∈S.out ∧m ∈R.in).
• The characteristic of FIFO-channels is that they are “order-preserving” according to
the “ﬁrst in, ﬁrst out principle” stating that if message m is oﬀered ﬁrst by S to its
output buﬀer S.out and subsequently m′, then m will be received by R before m′:
□

m ∈S.out ∧¬ m′ ∈S.out ∧♦(m′ ∈S.out)
−→♦(m ∈R.in ∧¬ m′ ∈R.in ∧♦(m′ ∈R.in))

.
Note that in the premise the conjunct ¬ m′ ∈S.out is needed in order to specify
that m′ is put in S.out after m. ♦(m′ ∈S.out) on its own does not exclude that m′
is already in the sender’s buﬀer when message m is in S.out.
The above formulae refer to ﬁxed messages m and m′. In order to state the above properties
for all messages, we have to take the conjunction over all messages m, m′. As long as the
message alphabet is ﬁnite we still obtain an LTL formula.
Example 5.13.
Dynamic Leader Election
(This example has been taken from [69].) In current distributed systems several ser-
vices are oﬀered by some dedicated process(es) in the system.
Consider, for example,
address assignment and registration, query coordination in a distributed database system,

Linear Temporal Logic
243
clock distribution, token regeneration after token loss in a token ring network, initiation
of topology updates in a mobile network, load balancing, and so forth. Usually many
processes in the system are potentially capable of providing these services. However, for
consistency reasons it is usually the case that at any time only one process is allowed to
actually provide a given service. This process – called the “leader” – is in fact elected.
Sometimes it suﬃces to elect an arbitrary process, but for other services it is important to
elect the process with the best capabilities for performing that service. Here we abstract
from speciﬁc capabilities and use ranking on the basis of process identities. The idea is
therefore that the higher the process’ identity, the better its capabilities.
Assume we have a ﬁnite number N > 0 of processes connected via some communication
means. The communication between processes is asynchronous, as in the previous example.
Pictorially,
P1
Communication Network
P2
PN
. . . . . . .
Each process has a unique identity, and it is assumed that a total ordering exists on these
identities. Processes behave dynamically in the sense that they are initially inactive, i.e.,
not participating in the election, and may become active, i.e., participating in the election,
at arbitrary moments. In order to have some progress we assume that a process cannot be
inactive indeﬁnitely; that is, each process becomes active at some time. (This corresponds
to a fairness condition.) Once a process participates it continues to do so, i.e., it does not
become inactive anymore. For a given set of active processes a leader will be elected; if
an inactive process becomes active, a new election takes place if this process has a higher
identity than the current leader.
To give an idea of using LTL as speciﬁcation formalism we formulate several properties
by LTL formulae. We will use i, j as process identities. Let the set of atomic propositions
be { leaderi, activei | 1 ⩽i, j ⩽N }, where leaderi means that process i is a leader, activei
means that process i is active. An inactive process cannot be a leader.
• The property “There is always one leader” can be formalized by
□
 !
1⩽i⩽N
leaderi ∧

1⩽j⩽N
j̸=i
¬ leaderj

.

244
Linear Temporal Logic
Although this formula expresses the informally stated property, it will not be satisﬁed
by any realistic protocol. One reason is that processes may be initially inactive, and
thus no leader is guaranteed to exist initially. Besides, in a distributed system with
asynchronous communication, switching from one leader to another can hardly be
made atomic. So, it is more realistic to allow the temporary absence of a leader. As
a ﬁrst attempt to do so, one could modify the above formula into
ϕ
=
□♦
 !
1⩽i⩽N
leaderi ∧

1⩽j⩽N
j̸=i
¬ leaderj

.
Problematic, though, is that this allows there to be more than one leader at a time
temporarily – it is only stated that inﬁnitely often there should be exactly one
leader, but no statement is made about the moments at which this is not the case.
For consistency reasons this is not desired. We therefore replace the above formula
ϕ with ϕ1 ∧ϕ2 where ϕ1 and ϕ2 correspond to the following two properties.
• “There must always be at most one leader”:
ϕ1
=
□

1⩽i⩽N

leaderi →

1⩽j⩽N
j̸=i
¬ leaderj

• “There will be enough leaders in due time”:
ϕ2
=
□♦
!
1⩽i⩽N
leaderi
ϕ2 does not imply that there will be inﬁnitely many leaders. It only states that
there are inﬁnitely many states at which a leader exists. This requirement classiﬁes
a leader election protocol that never elects a leader to be wrong.
In fact, such
a protocol would fulﬁll the previous requirement, but is not desired for obvious
reasons.
• “In the presence of an active process with a higher identity the leader will resign at
some time”:
□


1⩽i,j⩽N
i<j
((leaderi ∧¬ leaderj ∧activej) →♦¬ leaderi)

For reasons of eﬃciency it is assumed not to be desirable that a leader eventually
resigns in the presence of an inactive process that may participate at some unknown
time in the future. Therefore we require j to be an active process.

Linear Temporal Logic
245
• “A new leader will be an improvement over the previous one”. This property requires
that successive leaders have an increasing identity.
In particular, a process that
resigns once will not become a leader anymore.
□


1⩽i,j⩽N
(leaderi ∧¬ ⃝leaderi ∧⃝♦leaderj) →(i < j)

Here, we use ”i < j” as an atomic proposition that compares the identiﬁers of
processes Pi and Pj and evaluates to true if and only if the process identiﬁer of Pi
is smaller than that of Pj. Assuming that the identity of Pi is i (for i = 1, . . . , N),
the above property can also be speciﬁed by the LTL formula
□¬


1⩽i,j⩽N
i⩾j
(leaderi ∧¬ ⃝leaderi ∧⃝♦leaderj)

.
Example 5.14.
Specifying the Input/Output Behavior of Sequential Programs
The typical requirements on sequential programs such as partial correctness and termina-
tion can “in principle” be represented in LTL. Let us brieﬂy describe what termination
and partial correctness mean. Assume that a sequential program Prog computes a function
of the type f : Inp →Outp, i.e., Prog takes as input a value i ∈Inp and terminates either
by reporting an output value o ∈Outp or does not terminate. Prog is called terminating
if the computation of Prog halts for each input value i ∈Inp. Prog is partially correct if
for any input value i ∈Inp, whenever Prog terminates then the output value o equals f(i).
How can termination and partial correctness be expressed by means of LTL formulae?
Termination can be speciﬁed by a formula of the form init →♦halt where init is the
labeling for the initial states and halt is an atomic proposition characterizing exactly
those states that stand for termination. (Without loss of generality it can be assumed
that transition systems have no terminal states, i.e., this means terminating states either
are equipped with a self-loop, or have a transition leading to a trap-state with a self-loop
and no other outgoing transitions.)
Partial correctness can be represented by a formula of the form
□( halt −→♦(y = f(x)))
where y is the output variable and x the input variable which is assumed not to change
during program execution. Additional initial conditions such as expressed by the formula
init can be added as premise as follows:
init −→□(halt −→♦(y = f(x))).

246
Linear Temporal Logic
It should be stressed that this is an extremely simpliﬁed representation.
In practice,
predicate logic concepts are needed to precisely formulate partial correctness. And even in
cases where propositional logic formulae of the above form can be used to exactly describe
termination and partial correctness, the algorithmic proof of the LTL formulae is very
diﬃcult or even impossible. (Recall the undecidability of the halting problem.)
Remark 5.15.
Specifying Timed Properties with LTL for Synchronous Systems
For synchronous systems, LTL can be used as a formalism to specify “real-time” properties
that refer to a discrete time scale.
Recall that in synchronous systems, the involved
processes proceed in a lock step fashion, i.e., at each discrete time instance each process
performs a (sometimes idle) step. In this kind of system, the next-step operator ⃝has a
“timed” interpretation: ⃝ϕ states that “at the next time instant ϕ holds”. By putting
applications of ⃝in sequence, we obtain, e.g.:
⃝k ϕ
def
= ⃝⃝. . . ⃝



k-times
ϕ
“ϕ holds after (exactly) k time instants”.
Assertions like “ϕ will hold within at most k time instants” are obtained by
♦⩽k ϕ
=
!
0⩽i⩽k
⃝i ϕ.
Statements like “ϕ holds now and will hold during the next k instants” can be represented
as follows:
□⩽kϕ
=
¬ ♦⩽k ¬ ϕ
= ¬
!
0⩽i⩽k
⃝i ¬ ϕ.
For the modulo 4 counter of Example 5.11 (page 240) we in fact already implicitly used
LTL-formulae as real-time speciﬁcations. For example, the formula expressing that once
the output is y=1, the next three steps the output is y=0:
□( y −→(⃝¬y ∧⃝⃝¬ y ∧⃝⃝⃝¬ y) )
can be abbreviated as □(y −→⃝□⩽2 ¬ y).
It should, however, be noted that the temporal interpretation of the next-step operator
is only appropriate for synchronous systems. Every transition in these systems represents
the cumulative eﬀect of the actions possible within a single time instant. For asynchronous
systems (for which the transition system representation is time-abstract), the next-step
operator cannot be interpreted as a real-time modality. In fact, for asynchronous systems
the next-step operator should be used with care. The phase changes of a traﬃc light, for
example, can be described by
ϕ = □(green →⃝yellow)
∧□(yellow →⃝red) ∧. . .

Linear Temporal Logic
247
For the interleaving of two independent traﬃc lights (Example 2.17 on page 36) and the
formulae ϕ1, ϕ2 (where the indexed atomic propositions greeni, yellowi, etc., are used),
TrLight1 ||| TrLight2 ̸|= ϕ1 ∧ϕ2.
This stems from the fact that, e.g., the ﬁrst traﬃc light does not change its location when
the second traﬃc light changes its phase. To avoid this problem, the until operator can
be used instead, e.g.,
ϕ′ = □(green →(green U yellow))
∧□(yellow →(yellow U red)) ∧. . .
This diﬀers from the synchronous product operator ⊗, where
TrLight1 ⊗TrLight2 |= ϕ.
Remark 5.16.
Other Notations and Variants of LTL
Many variants and notations have been introduced for LTL. Alternative notations for
the temporal modalities are X for ⃝(neXt), F for ♦(Finally), and G for □(Globally).
All operators from LTL refer to the future (including the current state). Consequently,
operators are known as future operators. LTL can, however, also be extended with past
operators. This can be useful for specifying some properties more easily (and succinctly)
in terms of the past than in terms of the future. For instance, □−1 a (“always in the past”)
means that a is valid now and in any state in the past. ♦−1 a (“sometime in the past”)
means that either a is valid in the current state or in some state in the past and ⃝−1 a
means that a holds in the previous state, provided such state exists. For example, the
property “every red light phase is preceded by a yellow one” can be described by
□(red →⃝−1 yellow).
The main reason for introducing past operators is to simplify the speciﬁcation of several
properties. The expressive power of the logic is, however, not aﬀected by the addition of
past operators when a discrete notion of time is taken (as we do). Thus, for any property
which contains one or more past operators, an LTL-formula with only future temporal
operators exists expressing the same thing. More information is described in Section 5.4.
5.1.4
Equivalence of LTL Formulae
For any type of logic, a clear separation between syntax and semantics is an essential
aspect. On the other hand, two formulae are intuitively identiﬁed whenever they have the

248
Linear Temporal Logic
duality law
idempotency law
¬ ⃝ϕ
≡
⃝¬ϕ
♦♦ϕ
≡
♦ϕ
¬♦ϕ
≡
□¬ϕ
□□ϕ
≡
□ϕ
¬□ϕ
≡
♦¬ϕ
ϕ U (ϕ U ψ)
≡
ϕ U ψ
(ϕ U ψ) U ψ
≡
ϕ U ψ
absorption law
expansion law
♦□♦ϕ
≡
□♦ϕ
ϕ U ψ
≡
ψ
∨
(ϕ ∧⃝(ϕ U ψ))
□♦□ϕ
≡
♦□ϕ
♦ψ
≡
ψ
∨
⃝♦ψ
□ψ
≡
ψ
∧
⃝□ψ
distributive law
⃝(ϕ U ψ)
≡
(⃝ϕ) U (⃝ψ)
♦(ϕ ∨ψ)
≡
♦ϕ ∨♦ψ
□(ϕ ∧ψ)
≡
□ϕ ∧□ψ
Figure 5.7: Some equivalence rules for LTL.
same truth-value under all interpretations. For example, it seems useless to distinguish
between ¬¬a and a, although both formulae are syntactically diﬀerent.
Deﬁnition 5.17.
Equivalence of LTL Formulae
LTL formulae ϕ1, ϕ2 are equivalent, denoted ϕ1 ≡ϕ2, if Words(ϕ1) = Words(ϕ2).
As LTL subsumes propositional logic, equivalences of propositional logic also hold for LTL,
e.g., ¬¬ϕ ≡ϕ and ϕ ∧ϕ ≡ϕ. In addition, there exist a number of equivalence rules for
temporal modalities. They include the equivalence laws indicated in Figure 5.7.
We
explain some of these equivalence laws. The duality rule ¬ ⃝ϕ ≡⃝¬ϕ shows that the
next-step operator ⃝is dual to itself. It results from the observation that
A0 A1 A2 . . . |= ¬ ⃝ϕ
iﬀ
A0 A1 A2 . . . ̸|= ⃝ϕ
iﬀ
A1 A2 . . . ̸|= ϕ
iﬀ
A1 A2 . . . |= ¬ϕ
iﬀ
A0 A1 A2 . . . |= ⃝¬ϕ.
The ﬁrst absorption law is explained by the fact that “inﬁnitely often ϕ” is equal to “from

Linear Temporal Logic
249
a certain point of time on, ϕ is true inﬁnitely often”.
The distributive laws for ♦and disjunction, or □and conjunction, respectively, are dual
to each other. They can be regarded as the temporal logic analogon to the distributive
laws for ∃and ∨or ∀and ∧in predicate logic. It should be noted, however, that ♦does
not distribute over conjunction (as existential quantiﬁcation), and □does not distribute
over disjunction (like universal quantiﬁcation):
♦(a ∧b) ̸≡♦a ∧♦b
and
□(a ∨b) ̸≡□a
∨
□b.
The formula ♦(a ∧b) ensures that a state will be reached for which a and b hold, while
♦a ∧♦b ensures that eventually an a-state and eventually a b-state will be reached. Ac-
cording to the latter formula, a and b need not to be satisﬁed at the same time. Figure
5.8 depicts a transition system that satisﬁes ♦a ∧♦b, but not ♦(a ∧b).
{ a }
{ b }
Figure 5.8: TS ̸|= ♦(a ∧b) and TS |= ♦a ∧♦b.
The expansion laws play an important role. They describe the temporal modalities U , ♦,
and □by means of a recursive equivalence. These equivalences all have the same global
structure: they assert something about the current state, and about the direct successor
state. The assertion about the current state is done without the need to use temporal
modalities whereas the assertion about the next state is done using the ⃝operator. The
expansion law for until, for instance, can be considered as follows. Formula φ U ψ is a
solution of the equivalence
κ
≡
ψ
∨
(ϕ ∧⃝κ).
↖↗
↑
current state
ﬁrst suﬃx
Let us explain the expansion law for the until operator in more detail. Let A0 A1 A2 . . . be
an inﬁnite word over the alphabet 2AP, such that A0 A1 A2 . . . |= ϕ U ψ. By the deﬁnition
of “until”, there exists a k ⩾0, such that
Ai Ai+1 Ai+2 . . . |= ϕ,
for all 0 ⩽i < k
and
Ak Ak+1 Ak+2 . . . |= ψ.
Distinguish between k = 0 and k > 0.
If k = 0, then A0 A1 A2 . . . |= ψ and thus
A0 A1 A2 . . . |= ψ ∨. . .. If k > 0, then

250
Linear Temporal Logic
A0 A1 A2 . . . |= ϕ
and
A1 A2 . . . |= ϕ U ψ.
From this it immediately follows that
A0 A1 A2 . . . |= ϕ ∧⃝(ϕ U ψ).
Gathering the results for k = 0 and k > 0 yields
A0 A1 A2 . . . |= ψ ∨(ϕ ∧⃝(ϕ U ψ)).
For the reverse direction, a similar argument can be provided.
The expansion law for ♦ψ is a special case of the expansion law for until:
♦ψ = true U ψ ≡ψ ∨(true ∧⃝(true U ψ))



≡⃝(true U ψ) = ⃝♦ψ
≡ψ ∨⃝♦ψ.
The expansion law for □ψ now results from the duality of ♦and □, the duality of ∨and
∧(i.e., de Morgan’s law) and from the duality law for ⃝
□ψ
=
(* deﬁnition of □*)
¬♦¬ψ
≡
(* expansion law for ♦*)
¬(¬ψ ∨⃝♦¬ψ)
≡
(* de Morgan’s law *)
¬¬ψ ∧¬ ⃝♦¬ψ
≡
(* self-duality of ⃝*)
ψ ∧⃝¬♦¬ψ
≡
(* deﬁnition of □*)
ψ ∧⃝□ψ
It is important to realize that none of the indicated expansion laws represents a complete
recursive characterization of the temporal operator at hand. For example, the formulae
ϕ = false and ϕ = □a both satisfy the recursive “equation” ϕ ≡a ∧⃝ϕ since false ≡
a ∧⃝false and □a
≡
a ∧⃝□a.
However, ϕ U ψ and ♦ϕ are the least solutions of
the expansion law indicated for “until” and“eventually”, respectively. Similarly, □ϕ is
the greatest solution of the expansion law for “always”.
The precise meaning of these
statements will be explained by considering the until operator as example:

Linear Temporal Logic
251
Lemma 5.18.
Until is the Least Solution of the Expansion Law
For LTL formulae ϕ and ψ, Words(ϕ U ψ) is the least LT property P ⊆(2AP)ω such that:
Words(ψ) ∪{A0 A1 A2 . . . ∈Words(ϕ) | A1 A2 . . . ∈P} ⊆P
(*)
Moreover, Words(ϕ U ψ) agrees with the set
Words(ψ) ∪{A0 A1 A2 . . . ∈Words(ϕ) | A1 A2 . . . ∈Words(ϕ U ψ)}.
The formulation “least LT property satisfying condition (*)” means that the following
conditions hold:
(1) P = Words(ϕ U ψ) satisﬁes (*).
(2) Words(ϕ U ψ) ⊆P for all LT properties P satisfying condition (*).
Proof: Condition (1) follows immediately from the expansion law ϕ U ψ
≡
ψ ∨(ϕ ∧
⃝(ϕ U ψ)).
In fact, the expansion law even yields that ⊆in (*) can be replaced by
equality, i.e., Words(ϕ U ψ) agrees with
Words(ψ) ∪{A0 A1 A2 . . . ∈Words(ϕ) | A1 A2 . . . ∈Words(ϕ U ψ)}.
To prove condition (2), P is assumed to be an LT property that satisﬁes (*). We show
that Words(ϕ U ψ) ⊆P. Since P fulﬁlls (*), we have:
(i) Words(ψ) ⊆P,
(ii) If B0 B1 B2 . . . ∈Words(ϕ) and B1 B2 . . . ∈P then B0 B1 B2 . . . ∈P.
Let A0 A1 A2 . . . ∈Words(ϕ U ψ). Then, there exists an index k ⩾0 such that
(iii) Ai Ai+1 Ai+2 . . . ∈Words(ϕ),
for all 0 ⩽i < k,
(iv) Ak Ak+1 Ak+2 . . . ∈Words(ψ).
We now derive

252
Linear Temporal Logic
Ak Ak+1 Ak+2 Ak+3 . . . ∈P
due to (iv) and (i)
=⇒
Ak−1 Ak Ak+1 Ak+2 . . . ∈P
due to (ii) and (iii)
=⇒
Ak−2 Ak−1 Ak Ak+1 . . . ∈P
due to (ii) and (iii)
...
=⇒
A0 A1 A2 A3 . . . ∈P
due to (ii) and (iii).
5.1.5
Weak Until, Release, and Positive Normal Form
Any LTL formula can be transformed into a canonical form, the so-called positive normal
form (PNF). This canonical form is characterized by the fact that negations only occur
adjacent to atomic propositions. PNF formulae in propositional logic are constructed from
the constants true and false, the literals a and ¬a, and the operators ∧and ∨. For instance,
¬a ∧((¬b ∧c) ∨¬a) is in PNF, while ¬(a ∧¬b) is not. The well-known disjunctive and
conjunctive normal forms are special cases of the PNF for propositional logic.
In order to transform any LTL formula into PNF, for each operator a dual operator needs
to be incorporated into the syntax of PNF formulae. The propositional logical primitives of
the positive normal form for LTL are the constant true and its dual constant false = ¬true,
as well as conjunction ∧and its dual, ∨. De Morgan’s rules ¬(ϕ ∨ψ) ≡¬ϕ ∧¬ψ and
¬(ϕ ∧ψ) ≡¬ϕ ∨¬ψ yield the duality of conjunction and disjunction. According to the
duality rule ¬ ⃝ϕ
≡
⃝¬ϕ, the next-step operator is a dual of itself. Therefore, no
extra operator is necessary for ⃝. Now consider the until operator. First we observe that
¬(ϕ U ψ)
≡
((ϕ ∧¬ψ) U (¬ϕ ∧¬ψ)) ∨□(ϕ ∧¬ψ).
The ﬁrst disjunct on the right-hand side asserts that ϕ stops to hold “too early”, i.e.,
before ψ becomes valid. The second disjunct states that ϕ always holds but never ψ.
Clearly, in both cases, ¬(ϕ U ψ) holds.
This observation provides the motivation to introduce the operator W (called weak until
or unless) as the dual of U . It is deﬁned by:
ϕ W ψ
def
= (ϕ U ψ) ∨□ϕ.
The semantics of ϕ W ψ is similar to that of ϕ U ψ, except that ϕ U ψ requires a state to
be reached for which ψ holds, whereas this is not required for ϕ W ψ.
Until U and weak
until W are dual in the following sense:
¬(ϕ U ψ)
≡
(ϕ ∧¬ψ) W (¬ϕ ∧¬ψ)
¬(ϕ W ψ)
≡
(ϕ ∧¬ψ) U (¬ϕ ∧¬ψ)

Linear Temporal Logic
253
The reason that weak until is not a standard operator for LTL is that U and W have the
same expressiveness, since
□ψ
≡
ψ W false,
ϕ U ψ
≡
(ϕ W ψ) ∧
♦ψ

≡¬□¬ψ
.
That is to say, weak until is relevant only if restrictions are imposed on the occurrence
of negation (as in PNF). It is interesting to observe that W and U satisfy the same
expansion law:
ϕ W ψ
≡
ψ
∨
(ϕ ∧⃝(ϕ W ψ)).
For ψ = false this results in the expansion law for □ϕ:
□ϕ = ϕ W false
≡
false
∨
(ϕ ∧⃝(ϕ W false))
≡
ϕ ∧⃝□ϕ.
The semantic diﬀerence between U and W is shown by the fact that ϕ W ψ is the greatest
solution of
κ ≡ψ
∨
(ϕ ∧⃝κ).
This result is proven below.
Recall ϕ U ψ is the least solution of this equivalence, see
Lemma 5.18 on page 251.
Lemma 5.19.
Weak-Until is the Greatest Solution of the Expansion Law
For LTL formulae ϕ and ψ, Words(ϕ W ψ) is the greatest LT property P ⊆(2AP)ω such
that:
Words(ψ) ∪{A0A1A2 . . . ∈Words(ϕ) | A1A2 . . . ∈P} ⊇P
(*)
Moreover, Words(ϕ W ψ) agrees with the LT property
Words(ψ) ∪{A0A1A2 . . . ∈Words(ϕ) | A1A2 . . . ∈Words(ϕ W ψ)}.
The formulation “greatest LT property with the indicated condition (*) is to be understood
in the following sense:
(1) P ⊇Words(ϕ W ψ) satisﬁes (*).
(2) Words(ϕ W ψ) ⊇P for all LT properties P satisfying condition (*).

254
Linear Temporal Logic
Proof: The fact that condition (1) is satisﬁed, even with equality rather than ⊇, i.e.,
Words(ϕ W ψ) agrees with
Words(ψ) ∪{A0A1A2 . . . ∈Words(ϕ) | A1A2 . . . ∈Words(ϕ W ψ)},
is an immediate conclusion from the expansion law ϕ W ψ ≡ψ ∨(ϕ ∧⃝(ϕ W ψ)).
For proving condition (2), P is assumed to be an LT property satisfying (*). In particular,
for all words B0 B1 B2 B3 . . . ∈(2AP)ω \ Words(ψ) we have:
(i) If B0 B1 B2 B3 . . . /∈Words(ϕ), then B0 B1 B2 B3 . . . /∈P.
(ii) If B1 B2 B3 . . . /∈P, then B0 B1 B2 B3 . . . /∈P.
Now we demonstrate that
(2AP)ω \ Words(ϕ W ψ) ⊆(2AP)ω \ P.
Let A0 A1 A2 . . . ∈(2AP)ω \ Words(ϕ W ψ). Then A0 A1 A2 . . . ̸|= ϕ W ψ and thus
A0 A1 A2 . . . |= ¬(ϕ W ψ) ≡(ϕ ∧¬ψ) U (¬ϕ ∧¬ψ).
Thus there exists k ⩾0, such that:
(iii) Ai Ai+1 Ai+2 . . . |= ϕ ∧¬ψ,
for all 0 ⩽i < k,
(iv) Ak Ak+1 Ak+2 . . . |= ¬ϕ ∧¬ψ.
In particular, none of the words Ai Ai+1 Ai+2 . . . belongs to Words(ψ) for 0 ⩽i ⩽k. We
obtain:
Ak Ak+1 Ak+2 Ak+3 . . . /∈P
due to (i) and (iv)
=⇒
Ak−1 Ak Ak+1 Ak+2 . . . /∈P
due to (ii) and (iii)
=⇒
Ak−2 Ak−1 Ak Ak+1 . . . /∈P
due to (ii) and (iii)
...
=⇒
A0 A1 A2 A3 . . . /∈P
due to (ii) and (iii) .
Thus, (2AP)ω \ Words(ϕ W ψ) ⊆(2AP)ω \ P, or equivalently, Words(ϕ W ψ) ⊇P.
We are now ready to introduce the positive normal form for LTL which permits negation
only on the level of literals and – to ensure the full expressiveness of LTL – uses the dual
Boolean connectors ∧and ∨, the self-dual next-step operator ⃝, and U and W :

Linear Temporal Logic
255
Deﬁnition 5.20.
Positive Normal Form for LTL (Weak-Until PNF)
For a ∈AP, the set of LTL formulae in weak-until positive normal form (weak-until PNF,
for short, or simply PNF) is given by:
ϕ ::= true
   false
   a
   ¬a
   ϕ1 ∧ϕ2
   ϕ1 ∨ϕ2
   ⃝ϕ
   ϕ1 U ϕ2
   ϕ1 W ϕ2.
Due to the law □ϕ ≡ϕ W false, □can also be considered as permitted operator of the
W -positive normal form. As before, ♦ϕ = true U ϕ. An example LTL formula in PNF is
♦(a U □b) ∨(a ∧¬c) W (♦(¬a U b)).
The LTL formulae ¬(a U b) and c ∨¬(a ∧♦b) are not in weak-until PNF.
The previous considerations were aimed to rewrite any LTL formula into weak-until PNF.
This is done by successively “pushing” negations “inside” the formula at hand. This is
facilitated by the following transformations:
¬true
⇝
false
¬false
⇝
true
¬¬ϕ
⇝
ϕ
¬(ϕ ∧ψ)
⇝
¬ϕ ∨¬ψ
¬ ⃝ϕ
⇝
⃝¬ϕ
¬(ϕ U ψ)
⇝
(ϕ ∧¬ψ) W (¬ϕ ∧¬ψ).
These rewrite rules are lifted to the derived operators as follows:
¬(ϕ ∨ψ) ⇝¬ϕ ∧¬ψ
and
¬♦ϕ ⇝□¬ϕ
and
¬□ϕ ⇝♦¬ϕ.
Example 5.21.
Positive Normal Form
Consider the LTL formula ¬□((a U b) ∨⃝c). This formula is not in PNF, but can be
transformed into an equivalent LTL formula in weak-until PNF as follows:
¬□((a U b) ∨⃝c)
≡
♦¬((a U b) ∨⃝c)
≡
♦(¬(a U b) ∧¬ ⃝c)
≡
♦((a ∧¬b) W (¬a ∧¬b) ∧⃝¬c)

256
Linear Temporal Logic
Theorem 5.22.
Existence of Equivalent Weak-Until PNF Formulae
For each LTL formula there exists an equivalent LTL formula in weak-until PNF.
The main drawback of the rewrite rules introduced above is that the length of the resulting
LTL formula (in weak-until PNF) may be exponential in the length of the original nonPNF
LTL formula. This is due to the rewrite rule for until where ϕ and ψ are duplicated.
Although this can be slightly improved by adopting the law:
¬(ϕ U ψ) ≡(¬ψ) W (¬ϕ ∧¬ψ)
an exponential growth in length is not avoided here too due to the duplication of ψ in the
right-hand side.
To avoid this exponential blowup in transforming an LTL formula in PNF, another tempo-
ral modality is used that is dual to the until operator: the so-called binary release-operator,
denoted R .
It is deﬁned by
ϕ R ψ
def
=
¬(¬ϕ U ¬ψ).
Its intuitive interpretation is as follows. Formula ϕ R ψ holds for a word if ψ always holds,
a requirement that is released as soon as ϕ becomes valid. Thus, the formula false R ϕ is
valid if ϕ always holds, since the release condition (false) is a contradiction. Formally, for
a given word σ = A0 A1 . . . ∈(2AP)ω:
σ |= ϕ R ψ
iﬀ
(* deﬁnition of R *)
¬∃j ⩾0. (σ[j..] |= ¬ψ ∧∀i < j. σ[i..] |= ¬ϕ)
iﬀ
(* semantics of negation *)
¬∃j ⩾0. (σ[j..] ̸|= ψ ∧∀i < j. σ[i..] ̸|= ϕ)
iﬀ
(* duality of ∃and ∀*)
∀j ⩾0. ¬

σ[j..] ̸|= ψ ∧∀i < j. σ[i..] ̸|= ϕ

iﬀ
(* de Morgan’s law *)
∀j ⩾0.

¬(σ[j..] ̸|= ψ) ∨¬∀i < j. σ[i..] ̸|= ϕ

iﬀ
(* semantics of negation *)
∀j ⩾0.

σ[j..] |= ψ ∨∃i < j. σ[i..] |= ϕ

iﬀ
∀j ⩾0. σ[j..] |= ψ
or
∃i ⩾0. (σ[i..] |= ϕ) ∧∀k ⩽i. σ[k..] |= ψ).
The always operator is obtained from the release operator by:
□ϕ ≡false R ϕ.

Linear Temporal Logic
257
The weak-until and the until operator are obtained by:
ϕ W ψ ≡(¬ϕ ∨ψ) R (ϕ ∨ψ),
ϕ U ψ ≡¬(¬ϕ R ¬ψ).
Vice versa, ϕ R ψ ≡(¬ϕ ∧ψ) W (ϕ ∧ψ). The expansion law (see Exercise 5.8) for release
reads as follows:
ϕ R ψ ≡ψ ∧(ϕ ∨⃝(ϕ R ψ)).
We now revisit the notion of PNF, which is deﬁned using the R -operator rather than W :
Deﬁnition 5.23.
Positive Normal Form (release PNF)
For a ∈AP, LTL formulae in release positive normal form (release PNF, or simply PNF)
are given by
ϕ ::= true
   false
   a
   ¬a
   ϕ1 ∧ϕ2
   ϕ1 ∨ϕ2
   ⃝ϕ
   ϕ1 U ϕ2
   ϕ1 R ϕ2.
The following transformation rules push negations inside and serve to transform a given
LTL formula into an equivalent LTL formula in PNF:
¬true
⇝
false
¬¬ϕ
⇝
ϕ
¬(ϕ ∧ψ)
⇝
¬ϕ ∨¬ψ
¬ ⃝ϕ
⇝
⃝¬ϕ
¬(ϕ U ψ)
⇝
¬ϕ R ¬ψ
In each rewrite rule the size of the resulting formula increases at most by an additive
constant.
Theorem 5.24.
Existence of Equivalent Release PNF Formulae
For any LTL formula ϕ there exists an equivalent LTL formula ϕ′ in release PNF with
|ϕ′| = O(|ϕ|).
5.1.6
Fairness in LTL
In Chapter 3, we have seen that typically some fairness constraints are needed to verify
liveness properties. Three types of fairness constraints (for sets of actions) have been dis-
tinguished, namely unconditional, strong, and weak fairness. Accordingly, the satisfaction

258
Linear Temporal Logic
relation for LT properties (denoted |=) has been adapted to the fairness assumption F
(denoted |=F), where F is a triple of (sets of) fairness constraints. This entails that only
fair paths are considered while determining the satisfaction of a property. In this section,
this approach is adopted in the context of LTL. That is to say, rather than determining for
transition system TS and LTL formula ϕ whether TS |= ϕ, we focus on the fair executions
of TS. The main diﬀerence with the action-based fairness assumptions (and constraints)
is that we now focus on state-based fairness.
Deﬁnition 5.25.
LTL Fairness Constraints and Assumptions
Let Φ and Ψ be propositional logic formulae over AP.
1. An unconditional LTL fairness constraint is an LTL formula of the form
ufair = □♦Ψ.
2. A strong LTL fairness condition is an LTL formula of the form
sfair = □♦Φ −→□♦Ψ.
3. A weak LTL fairness constraint is an LTL formula of the form
wfair = ♦□Φ −→□♦Ψ.
An LTL fairness assumption is a conjunction of LTL fairness constraints (of any arbitrary
type).
For instance, a strong LTL fairness assumption denotes a conjunction of strong LTL
fairness constraints, i.e., a formula of the form
sfair =

0<i⩽k
(□♦Φi −→□♦Ψi)
for propositional logical formulae Φi and Ψi over AP. Weak and unconditional LTL fairness
assumptions are deﬁned in a similar way.

Linear Temporal Logic
259
In their most general form, LTL fairness assumptions are (as in Deﬁnition 3.46, page 133)
a conjunction of unconditional, strong, and weak fairness assumptions:
fair = ufair ∧sfair ∧wfair.
where ufair, sfair, and wfair are unconditional, strong, and weak LTL fairness assump-
tions, respectively.
As in the case of action-based fairness assumptions, the rule of thumb
for imposing fairness assumptions is: strong (or unconditional) fairness assumptions are
useful for solving contentions, and weak fairness is often suﬃcient for resolving the non-
determinism that results from interleaving.
In the sequel, we adopt the same notations as for action-based fairness assumptions. Let
FairPaths(s) denote the set of all fair paths starting in s and FairTraces(s) the set of all
traces induced by fair paths starting in s. Formally, for ﬁxed formula fair,
FairPaths(s)
=
{ π ∈Paths(s) | π |= fair },
FairTraces(s)
=
{ trace(π) | π ∈FairPaths(s) }.
These notions can be lifted to transition systems in the obvious way yielding FairPaths(TS)
and FairTraces(TS). To identify the fairness assumption fair, we may write FairPathsfair(·)
or FairTracesfair(·).
Deﬁnition 5.26.
Satisfaction Relation for LTL with Fairness
For state s in transition system TS (over AP) without terminal states, LTL formula ϕ,
and LTL fairness assumption fair let
s |=fair ϕ
iﬀ
∀π ∈FairPaths(s). π |= ϕ
and
TS |=fair ϕ
iﬀ
∀s0 ∈I. s0 |=fair ϕ.
TS satisﬁes ϕ under the LTL fairness assumption fair if ϕ holds for all fair paths that
originate from some initial state.
Example 5.27.
Mutual Exclusion with Randomized Arbiter (Fairness)
Consider the following approach to two-process mutual exclusion. A randomized arbiter,
see the program graphs in Figure 5.9, decides which process is acquiring access to the
critical section.
It does so by tossing coins.
We abstract from the probabilities, and
model the coin tossing by a nondeterministic choice between the alternatives “heads” and
“tails”. It is assumed that the two contending processes communicate with the arbiter
via the actions enter1 and enter2. The critical section is released by synchronizing over

260
Linear Temporal Logic
noncrit1
wait1
crit1
req1
enter1
rel
noncrit2
wait2
crit2
req2
enter2
rel
unlock
tails
lock
enter2
rel
heads
enter1
Figure 5.9: Mutual exclusion with a randomized arbiter.
the action release. For the sake of simplicity, we refrain from indicating which process is
releasing the critical section.
The property “process P1 is in its critical section inﬁnitely often” cannot be established,
since, for instance, the underlying transition system representation does not exclude an
execution in which only the second process may perform an action while P1 is entirely
ignored. Thus:
TS1 ∥Arbiter ∥TS2 ̸|= □♦crit1.
If a coin is assumed to be fair enough such that both events “heads” and “tails” occur with
positive probability, the unrealistic case of one of the two alternatives never happening
can be ignored by means of the unconditional LTL fairness assumption:
fair = □♦heads ∧□♦tails.
It is not diﬃcult to check that now:
TS1 ∥Arbiter ∥TS2 |=fair □♦crit1 ∧□♦crit2.
Example 5.28.
Communication Protocol (Fairness)
Consider the alternating bit protocol as described in Example 2.32 (page 57). For the sake
of convenience, the program graph of the sender of the alternating bit protocol is repeated
in Figure 5.10. The liveness property □♦start states that the protocol returns inﬁnitely
often to its initial state. In this initial state the action snd msg(0) is enabled. It follows
that
ABP ̸|= □♦start

Linear Temporal Logic
261
snd msg(0)
st tmr(0)
wait(0)
chk ack(0)
snd msg(1)
st tmr(1)
wait(1)
chk ack(1)
c!⟨m, 0⟩
lost
tmr on
d?x
timeout
x = 1
x = 0 :
tmr oﬀ
c!⟨m, 1⟩
lost
tmr on
timeout
d?x
x = 0
x = 1 :
tmr oﬀ
Figure 5.10: Program graph of ABP sender S.
since the unrealistic scenario in which (after some ﬁnite time) each message with alternat-
ing bit 1 is lost cannot be excluded. This corresponds to the path
. . . . . . si
lost
−−−→si+1
tmr on
−−−−−→si+2
timeout
−−−−−→si+3
lost
−−−→. . . . . .
Suppose we impose the strong LTL fairness assumption
sfair =

b=0,1

k
k<cap(c)
(□♦(send(b) ∧|c| = k) →□♦|c| = k + 1).
Here, |c| = n stands for the atomic proposition that holds in the states ⟨ℓ, η, ξ⟩in which
channel c contains exactly n elements, i.e., the length of the word ξ(c) equals n. Thus,
sfair describes (from the state-based point of view) that the loss of a transmitted message
is not continuously possible. We now obtain
ABP |=sfair □♦start.
Note that it is essential to impose a strong fairness assumption on send(b); as this action
is not continuously enabled, a weak fairness assumption is insuﬃcient.
In Section 3.5 (page 126 ﬀ.), fairness was introduced using sets of actions; e.g., an execution
is unconditionally A-fair for a set of actions A, whenever each action α ∈A occurs inﬁnitely
often. LTL-fairness, however, is deﬁned on atomic propositions, i.e., from a state-based
perspective. Is there any relationship between these two—at ﬁrst sight, rather diﬀerent—
approaches toward fairness?
The advantage of the action-based formulation of fairness assumptions is that many use-
ful (and realizable) fairness assumptions can easily be expressed. Using the state-based

262
Linear Temporal Logic
perspective, this may be less intuitive. For instance, the enabling of a process (or, more
generally, of a certain action) is not necessarily a property that can be determined from
the (atomic propositions in a) state. This discrepancy is, however, not always present.
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
req1
req2
enter1
req2
req1
enter2
req2
enter1
enter2
req1
rel
rel
rel
rel
Figure 5.11: Semaphore-based mutual exclusion algorithm.
Example 5.29.
State-Based vs. Action-Based Fairness
To exemplify this, consider the semaphore-based two-process mutual exclusion protocol
(see Figure 5.11) together with the action-based strong-fairness assumption
Fstrong = { { enter1 }, { enter2 } }.
Let us try to state the same constraint by means of a (state-based) LTL fairness assump-
tion. Observe ﬁrst that the action enter1 is executable if and only if process P1 is in the
local state wait1 and process P2 is not in its critical section. Besides, on executing action
enter1, process P1 moves to its critical section. Thus, strong fairness for { enter1 } can be
described by the LTL fairness assumption:
sfair1 = □♦(wait1 ∧¬crit2) →□♦crit1.
The assumption sfair2 is deﬁned analogously. It now follows that sfair = sfair 1 ∧sfair 2
describes Fstrong.
Fstrong requires each process to enter its critical section inﬁnitely often when it inﬁnitely
often gets the opportunity to do so. This does not forbid a process to never leave its
noncritical section. To avoid this unrealistic scenario, the weak fairness constraint
Fweak = {{ req1 }, { req2 }}

Linear Temporal Logic
263
requires that any process inﬁnitely often requests to enter the critical section when it con-
tinuously is able to do so. This (action-based) weak fairness constraint can be formulated
as (state-based) LTL fairness assumption in a similar way as above. Observe that the
request action of Pi is executable if and only if process Pi is in the local state noncriti.
Weak fairness for { reqi } thus correponds to the LTL fairness assumption:
wfair i = ♦□noncriti →□♦waiti.
Let fair = sfair ∧wfair where wfair = wfair1 ∧wfair2. It then follows that
TSSem |=fair □♦crit1 ∧□♦crit2.
In many cases, it is possible to replace action-based fairness by state-based LTL fairness
assumptions. This, however, requires the possibility to deduce from the state label the
possible enabled actions and the last executed action.
It turns out that action-based
fairness assumptions can always be “translated” into analogous LTL fairness assumptions.
This works as follows. The intuition is to make a copy of each noninitial state s such that
it is recorded which action was executed to enter state s. Such copy is made for every
possible action via which the state can be entered. The copied state ⟨s, α⟩indicates that
state s has been reached by performing α as last action.
Formally, this works as follows. For transition system TS = (S, Act, →, I, AP, L) let
TS′ = (S′, Act′, →′, I′, AP′, L′)
where Act′ = Act ⊎{ begin }, I′ = I × { begin } and S′ = I′ ∪(S × Act). The transition
relation in TS′ is deﬁned by the rules:
s
α
−−→s′
⟨s, β⟩
α
−−→′ ⟨s′, α⟩
and
s0
α
−−→s s0 ∈I
⟨s0, begin⟩
α
−−→′ ⟨s, α⟩
The state labeling is deﬁned as follows. Let
AP′ = AP ∪{ enabled(α), taken(α) | α ∈Act }
with the labeling function
L′(⟨s, α⟩) = L(s) ∪{ taken(α) } ∪{ enabled(β) | β ∈Act(s) }
for ⟨s, α⟩∈S × Act and
L′(⟨s0, begin⟩) = L(s0) ∪{enabled(β) | β ∈Act(s0) }.

264
Linear Temporal Logic
It can easily be established that
TracesAP(TS) = TracesAP(TS′).
Strong fairness for a set of actions A ⊆Act can now be described by the strong LTL
fairness assumption:
sfairA = □♦enabled(A) →□♦taken(A)
where
enabled(A) = "
α∈A
enabled(α)
and
taken(A) = "
α∈A
taken(α).
Unconditional and weak action-based fairness assumptions for TS can be transformed into
LTL fairness assumptions for TS′ in a similar way. For action-based fairness assumption
F for TS and fair the corresponding LTL fairness assumption for TS′, it follows that the
set of fair traces coincides:
{traceAP(π) | π ∈Paths(TS), π is F-fair}
= {traceAP(π′) | π′ ∈Paths(TS′), π′ |= fair}.
Stated diﬀerently, FairTracesF(TS) = FairTracesfair(TS′) where in TS′ only atomic propo-
sitions in AP are considered. In particular, for every LT property P over AP,
TS |=F P
iﬀTS′ |=fair P.
Conversely, a (state-based) LTL fairness assumption cannot always be represented as
action-based fairness assumption.
This fact follows from the fact that strong or weak
LTL fairness assumptions need not be realizable, while any action-based strong or weak
fairness assumptions can be realized by a scheduler. In this sense, state-based LTL fairness
assumptions are more general than action-based fairness assumptions.
The following theorem shows that the satisfaction relation |=fair as deﬁned in Deﬁni-
tion 5.26 has a strong relation to the usual satisfaction relation |=.
Theorem 5.30.
Reduction of |=fair to |=
For transition system TS without terminal states, LTL formula ϕ, and LTL fairness as-
sumption fair:
TS |=fair ϕ
if and only if
TS |= (fair →ϕ).

Linear Temporal Logic
265
Proof: ⇒: Assume TS |=fair ϕ. Then, for any path π ∈Paths(TS) either π |= fair ∧ϕ or
π |= ¬fair. Thus, π |= (fair →ϕ), and consequently TS |= (fair →ϕ).
⇐: by a similar reasoning.
Example 5.31.
On-The-Fly Garbage Collection
An important characteristic of pointer-manipulating programs is that certain parts of the
dynamically changing data structure, such as a list or a tree, may become inaccessible.
That is to say, this part of the data structure is not “reachable” by dereferencing one
of the program variables. In order to be able to recycle these inaccessible memory cells,
so-called garbage collecting algorithms are employed. These algorithms are key parts of
operating systems, and play a major role in compilers. In this example, we focus on on-
the-ﬂy garbage collection algorithms. These algorithms attempt to identify and recycle
inaccessible memory cells concurrently with the running programs that may manipulate
the dynamically changing data structure. Typical requirements for such garbage collection
algorithms are
Safety: An accessible (i.e., reachable) memory cell is never collected.
Liveness: Any unreachable storage cell is eventually collected.
The memory cells. The memory is considered to consist of a ﬁxed number N of memory
cells. The number of memory cells is static, i.e., the dynamic allocation and deallocation
of cells (as in the C-statement malloc) is not considered. The memory cells are organized
in a directed graph, whose structure may change during the computation; this happens,
e.g., when carrying out an assignment v := w where v and w point to a memory cell. For
the sake of simplicity, it is assumed that each cell (= vertex) has at most one pointer (=
edge) to another cell. Let son(i) denote the immediate successor of cell i. Cells that do not
have an outgoing reference are equipped with a self-reference. Thus, each cell has exactly
one outgoing edge in the graph representation. Vertices are numbered. There is a ﬁxed set
of root vertices. Root cells are never considered as garbage. A memory cell is reachable if
it is reachable in the graph from a root vertex. Cells that are not reachable from a root
vertex are garbage cells. The memory is partitioned into three fragments: the accessible
cells (i.e., cells that are reachable by the running processes), the free cells (i.e., cells that
are unused and that can be assigned to running processes), and the unreachable cells. As
for the garbage collection algorithm, it is only of importance which cells are unreachable.
The distinction between free and accessible cells is of no importance, and will be neglected
in the remainder.

266
Linear Temporal Logic
Modeling the garbage collector. The entire system is modeled as the parallel composition
of the garbage collector (process Collector), and a process that models the behaviour of
the running processes manipulating the shared data structure. Thus:
Mutator ∥Collector
For simplicity, we abstain from a detailed transition system representation and describe the
mutator and the collector by pseudocode algorithms. As the garbage collecting algorithm
should work correctly for any arbitrary set of concurrently running processes, the mutator
is modeled by means of a single process that can nondeterministically choose two arbitrary
reachable cells i and k and change the current reference i →j into i →k. This corresponds
to the assignment “son(i) := k”. Note that if i was the only cell pointing to j, then after
the assignment son(i) := k, the memory cell j has become garbage.
Algorithm 9 Mutator and garbage collector (naive version)
(* mutator *)
while true do
Nondeterministically choose two reachable nodes i and k;
son(i) := k
od
(* garbage collector *)
while true do
label all reachable cells;
(* e.g., by depth-ﬁrst search *)
for all cells i do
if i is not labeled then collect i
od
add the collected cells to the list of free memory cells
od
Now let us consider the garbage collector. A naive technique could be based on a DFS
or BFS which labels cells and, subsequently, collects all unlabeled cells as garbage (see
Algorithm 9). The collected cells are added to the list of free memory cells, and thus
are turned into reachable cells. This simple idea works correctly when the actions of the
mutator are not interlocked with those of the garbage collector. As an on-the-ﬂy algorithm,
however, this naive idea fails due to the possible interleavings between the mutator and the
collector. This is illustrated in Figure 5.12 where six memory conﬁgurations are depicted.
Circles denote memory cells and edges represent the pointer structure. Nonshaded cells
are not visited, gray ones are visited, and cells with a thick border have been completely
processed. Due to the changes made by the mutator during the garbage collection phase,
one of the memory cells remains unlabeled although it is accessible. The collector would
now collect the unlabeled but accessible cell.

Linear Temporal Logic
267
Collector
Mutator
Mutator
Collector
Collector
Figure 5.12: Failure of the naive garbage collector.
An alternative is to use a labeling algorithm that successively passes through all cells and
labels their sons if the appropriate cell is labeled itself. Initially, only root cells are labeled.
This technique is iterated as long as the number of labeled cells does not change anymore.
The auxiliary variables M and Mold are used to this purpose. M counts the number of
labeled cells in the current stage of labeling. Mold stands for the number of labeled cells
in the previous stage of labeling. Additionally, the mutator supports the labeling process
by labeling cell k as soon as a reference is redirected to k (see Algorithm 10). It is not
diﬃcult to show that the participation of the mutator is necessary to obtain a correct
garbage collection algorithm. If it does not participate, there can always be found some
interference pattern between the mutator and the collector such that reachable cells are
made inaccessible by the mutator, causing a ﬂaw in the garbage collection. Figure 5.13
demonstrates the functioning of the collector for four linearly linked reachable cells, where
it is assumed that the labeling steps of the collector are not interrupted by the mutator.
The shading represents the labeling by the collector. The thick border of a node indicates
that this node was considered in the for loop. Thus, in the last step, all four nodes were
processed in the for loop. Therefore, the result of the ﬁrst iteration is Mold = 1 (number
of root cells) and M = 3, since exactly three cells were labeled. The labels arising at the
end of the subsequent iterations are indicated in Figure 5.14.
Figure 5.15 shows an example that indicates that the mutator has to label cells, as oth-
erwise it cannot be ensured that the collector identiﬁes all reachable cells. The leftmost
ﬁgure indicates the starting memory conﬁguration. The situation after the collector has
labeled the root cell and has processed the top left node in the FOR loop is depicted in

268
Linear Temporal Logic
Algorithm 10 Ben Ari’s on-the-ﬂy garbage collection algorithm
(* mutator *)
while true do
let i and k be reachable memory cells;
label k;
son(i) := k
od
(* garbage collector *)
while true do
label all root cells;
M := number of root cells;
repeat
Mold := M;
for all node i do
if i is labeled then
if son(i) is unlabeled then label son(i); M := M+1; ﬁ
ﬁ
od
until M = Mold;
for all cell i do
if i is labeled then delete label for cell i
else collect cell i
(* cell i is garbage *)
ﬁ
od
add the collected cells to the list of free cells
od

Linear Temporal Logic
269
1
4
3
2
1
4
3
2
1
4
3
2
1
4
3
2
1
4
3
2
1
4
3
2
Figure 5.13: Example of Ben Ari’s on-the-ﬂy garbage collector (one iteration).
1
4
3
2
1
4
3
2
1
4
3
2
1
4
3
2
Mold = 1
M = 3
Mold = 3
M = 4
Mold = M = 4
Figure 5.14: Example of Ben-Ari’s on-the-ﬂy garbage collector (all iterations).
the next ﬁgure. The third and fourth ﬁgures show a possible modiﬁcation of the pointer
structure by the mutator. The collector then would investigate the upper cell on the right
and label it. Since this cell does not have an unlabeled successor, the ﬁrst round of the
collector is ﬁnished. As the obtained memory conﬁguration is symmetric to the initial one,
the whole procedure might be repeated, which leads to the initial conﬁguration of Figure
5.15. In the second round, the collector also just labels the two upper cells. Since the
number of labeled cells has not increased and assuming that the mutator does not label
the lower cell, this cell would be wrongly regarded as garbage (and thus be collected).
The examples illustrate the functioning of the algorithm but are by no means meant as
proof of correctness. Due to the enormous size of the state space and the extremely high
degree of nondeterminism, the analysis of the garbage collection algorithm is extremely
diﬃcult. Note that the states of the transition system, which results from the parallel
composition of mutator and collector, consist of control components plus a representation
of the current labels and of another component that gives information about the current

270
Linear Temporal Logic
Collector
Mutator
Mutator
Figure 5.15: Labeling memory cells by the mutator is necessary.
memory conﬁguration.
For N nodes, there exist 2N possible labels and N N possible
graphs. The high degree of nondeterminism results from the mutator that can change an
arbitrary pointer. It is not useful to restrict the mutator (and thus reducing the degree of
nondeterminism), since this would impose restrictions on the applicability of the garbage
collecting algorithm.
To conclude, we will formalize the requirements on the concurrent garbage collection
algorithm. To that end, let atomic proposition collect(i) hold for cell i in a state if and
only if cell i has been collected in that state. Similarly, accessible(i) holds in those states
in which cell i is reachable from a root cell. Given these atomic propositions, the safety
property “an accessible memory cell is never collected” can be speciﬁed as

0<i⩽N
□( collect(i) →¬accessible(i) ).
The liveness property “any unreachable storage cell is eventually collected” is described
as LTL formula

0<i⩽N
□( ¬accessible(i) →♦collect(i) ).
It turns out that Ben Ari’s concurrent garbage collection algorithm satisﬁes the safety
property, but refutes the liveness property. The latter happens, e.g., in the pathological
case where only the mutator acts inﬁnitely often. To rule out this unrealistic behavior,
weak process fairness can be imposed.
5.2
Automata-Based LTL Model Checking
In this section we address the model-checking problem for LTL. The starting point is a
ﬁnite transition system TS and an LTL formula ϕ that formalizes a requirement on TS.
The problem is to check whether TS |= ϕ. If ϕ is refuted, an error trace needs to be
provided for debugging purposes. The considerations in Section 2.1 show that transition

Automata-Based LTL Model Checking
271
systems are typically huge. Therefore, a manual proof of TS |= ϕ is extremely diﬃcult.
Instead, veriﬁcation tools are desirable, which enable a fully automated analysis of the
transition system.
In general, not just a single requirement but several requirements are relevant. These
requirements can be represented by separate formulae, such as ϕ1, . . . , ϕk, and be com-
bined into ϕ1 ∧. . . ∧ϕk to obtain a speciﬁcation of all requirements. Alternatively, the
requirements ϕi can be treated separately. This is often more eﬃcient than considering
them together. Moreover, the decomposition of the entire requirement speciﬁcation into
several requirements is advised if errors are to be expected or if the validity of ϕi is known
by a prior analysis.
An LTL model-checking algorithm is a decision procedure which for a transition system TS
and LTL formula ϕ returns the answers “yes” if TS |= ϕ, and “no” (plus a counterexample)
if TS ̸|= ϕ. The counterexample consists of an appropriate ﬁnite preﬁx of an inﬁnite path
in TS where ϕ does not hold. Theorem 5.30 shows that special measures to handle fairness
assumptions are unnecessary as fairness assumptions can be encoded in the LTL formula
to be checked. (For reasons of eﬃciency, however, it is advised to use special algorithms
to treat fairness assumptions.)
Throughout this section, TS is assumed to be ﬁnite and to have no terminal states. The
model-checking algorithm presented in the following is based on the automata-based ap-
proach as originally suggested by Vardi and Wolper (1986). This approach is based on the
fact that each LTL formula ϕ can be represented by a nondeterministic B¨uchi automaton
(NBA). The basic idea is to try to disprove TS |= ϕ by “looking” for a path π in TS with
π |= ¬ϕ. If such a path is found, a preﬁx of π is returned as error trace. If no such path
is encountered, it is concluded that TS |= ϕ.
The essential steps of the model-checking algorithm as summarized in Algorithm 11 and
Figure 5.16, rely on the following observations:
TS |= ϕ
iﬀ
Traces(TS) ⊆Words(ϕ)
iﬀ
Traces(TS) ∩((2AP)ω \ Words(ϕ)) = ∅
iﬀ
Traces(TS) ∩Words(¬ϕ) = ∅.
Hence, for NBA A with Lω(A) = Words(¬ϕ) we have
TS |= ϕ
if and only if
Traces(TS) ∩Lω(A) = ∅.
Thus, to check whether ϕ holds for TS one ﬁrst constructs an NBA for the negation of
the input formula ϕ (representing the ”bad behaviors”) and then applies the techniques
explained in Chapter 4 for the intersection problem.

272
Linear Temporal Logic
Algorithm 11 Automaton-based LTL model checking
Input: ﬁnite transition system TS and LTL formula ϕ (both over AP)
Output: “yes” if TS |= ϕ; otherwise, “no” plus a counterexample
Construct an NBA A¬ϕ such that Lω(A¬ϕ) = Words(¬ϕ)
Construct the product transition system TS ⊗A
if there exists a path π in TS ⊗A satisfying the accepting condition of A then
return “no” and an expressive preﬁx of π
else
return “yes”
ﬁ
It remains to explain how a given LTL formula can be represented by an NBA and how
such an NBA can be constructed algorithmically. First observe that for the LTL formula
ϕ, the LTL semantics provided in Deﬁnition 5.6 on page 235 yields a language Words(ϕ) ⊆
(2AP)ω. Thus, the alphabet of NBA for LTL formulae is Σ = 2AP. The next step is to
show that Words(ϕ) is ω-regular, and hence, representable by a nondeterministic B¨uchi
automaton.
Example 5.32.
NBA for LTL Formulae
Before treating the details of transforming an LTL formula into an NBA, we provide
some examples. As in Chapter 4, propositional logic formulae are used (instead of the set
notations) for a symbolic representation of the edges of an NBA. These formulae are built
by the symbols a ∈AP, the constant true, and the Boolean connectors, and thus they
can be interpreted over sets of atomic propositions, i.e., the elements A ∈Σ = 2AP. For
instance, if AP = { a, b } then q
a∨b
−−−→q′ is a short notation for the three transitions:
q
{a}
−−−→q′, q
{b}
−−−→q′, and q
{a,b}
−−−−→q′.
The language of all words σ = A0 A1 . . . ∈2AP satisfying the LTL formula □♦green
(“inﬁnitely often green”) is accepted by the NBA A shown in Figure 5.17. Here, AP is
a set of atomic propositions containing green. Note that A is in the accept state q1 if
and only if the last consumed symbol (the last set Ai of the input word A0 A1 A2 . . . ∈
(2AP)ω) contains the propositional symbol green. Therefore, the accepted language Lω(A)
is exactly the set of all inﬁnite words A0 A1 A2 . . . with inﬁnitely many indices i where
green ∈Ai. Thus,
Lω(A) = Words(□♦green).
The accepting run that generates the word σ = { green }∅{ green }∅. . . is (q0 q1)ω.

Automata-Based LTL Model Checking
273
model checker
LTL-formula ¬ϕ
TS ⊗A |= Ppers(A)
TS ⊗A¬ϕ
‘No’ (counter-example)
Product transition system
Model of system
Transition system TS
Negation of property
Generalised B¨uchi automaton
B¨uchi automaton A¬ϕ
System
‘Yes’
Figure 5.16: Overview of LTL model checking.
q0
q1
green
¬green
¬ green
green
Figure 5.17: NBA for □♦green.
As a second example consider the liveness property: “whenever event a occurs, event b
will eventually occur”. For example, the property given by the LTL formula □(request →
♦response) is of this form. An associated NBA over the alphabet 2{a,b} where a = request
and b = response is shown in Figure 5.18.
The automata in Figures 5.17 and 5.18 are deterministic, i.e., they have exactly one run
for each input word. To represent temporal properties like “eventually forever (from some
moment on)”, the concept of nondeterminism is, however, necessary.
The NBA A shown in Figure 5.19 accepts the language Words(♦□a). Here, AP ⊇{ a } and
Σ = 2AP; see also Example 4.51 (page 191). Intuitively, the NBA A nondeterministically
decides (by means of an omniscient oracle) when a continuously holds. Note that state q2
may be omitted, as there is no accepting run beginning in q2. (The reader should bear in
mind that DBA and NBA are not equally expressive; see Section 4.3.3 on page 188.)

274
Linear Temporal Logic
q0
q1
a ∧¬b
b
¬a ∨b
¬b
Figure 5.18: NBA for □(a →♦b).
q0
q1
q2
a
¬a
true
a
true
Figure 5.19: NBA for ♦□a.
A key ingredient to the model-checking algorithm for LTL is the construction of an NBA
A satisfying
Lω(A) = Words(ϕ)
for the LTL formula ϕ. In order to do so, ﬁrst a generalized NBA is constructed for ϕ,
which subsequently is transformed into an equivalent NBA. For the latter step we employ
the recipe as provided in Theorem 4.56 on page 195. For the sake of convenience we recall
the deﬁnition of generalized NBA; see also Deﬁnition 4.52 on page 193.
Deﬁnition 5.33.
Generalized NBA (GNBA)
A generalized NBA
is a tuple G = (Q, Σ, δ, Q0, F) where Q, Σ, δ, Q0 are deﬁned as for
NBA (i.e., Q is a ﬁnite state space, Σ an alphabet, Q0 ⊆Q the set of initial states, and
δ : Q × Σ →2Q the transition relation) and F is a (possibly empty) subset of 2Q. The
elements of F are called acceptance sets.
The accepted language Lω(G) consists of all
inﬁnite words in (2AP)ω that have at least one inﬁnite run q0 q1 q2 . . . in G such that for
each acceptance set F ∈F there are inﬁnitely many indices i with qi ∈F.
A GNBA for which F is a singleton set can be regarded as an NBA. If the set F of
acceptance sets in G is empty, the language Lω(G) consists of all inﬁnite words that have
an inﬁnite run in G. Hence, if F = ∅, then G can be viewed as an NBA for which all
states are accepting.
Let us consider how to construct a GNBA over the alphabet 2AP for a given LTL formula
ϕ (over AP), i.e., a GNBA Gϕ with Lω(Gϕ) = Words(ϕ). Assume ϕ only contains the
operators ∧, ¬, ⃝and U , i.e., the derived operators ∨, →, ♦, □, W , and so on are
assumed to be expressed in terms of the basic operators. Since the special case ϕ = true
is trivial, it may be assumed that ϕ ̸= true.

Automata-Based LTL Model Checking
275
The basic idea for the construction of Gϕ is as follows. Let σ = A0 A1 A2 . . . ∈Words(ϕ).
The sets Ai ⊆AP are expanded by subformulae ψ of ϕ such that an inﬁnite word ¯σ =
B0 B1 B2 . . . with the following property arises:
ψ ∈Bi
if and only if
Ai Ai+1 Ai+2 . . .



σi
|= ψ.
For technical reasons, the subformulae ψ of ϕ are considered as well as their negation ¬ψ.
Consider, e.g.,
ϕ = a U (¬a ∧b)
and
σ = { a } { a, b } { b } . . . .
In this case, Bi is a subset of the set of formulae
{ a, b, ¬a, ¬a ∧b, ϕ }



subformulae of ϕ
∪{ ¬b, ¬(¬a ∧b), ¬ϕ }



their negation
.
The set A0 = { a } is extended with the formulae ¬b, ¬(¬a ∧b), and ϕ, since all these
formulae hold in σ0 = σ, and all other subformulae in the above set are refuted by σ. We
thus obtain
B0 = { a, ¬b, ¬(¬a ∧b), ϕ }.
The set A1 = { a, b } is extended with ¬(¬a ∧b) and ϕ, as these are the only subformulae
in the above set that hold in σ1 = { a, b } { b } . . .. The A2 = { b } is extended with ¬a,
¬a ∧b and ϕ as they hold in σ2 = { b } . . .. This yields a word of the form:
¯σ = { a, ¬b, ¬(¬a ∧b), ϕ } { a, b, ¬(¬a ∧b), ϕ } { ¬a, b, ¬a ∧b, ϕ } . . .
As σ is inﬁnite, this procedure is of course not eﬀective. The example is just meant to
explain the intuition behind the construction of the states in the GNBA.
The GNBA Gϕ is constructed such that the sets Bi constitute its states. Moreover, the
construction ensures that ¯σ = B0 B1 B2 . . . is a run for σ = A0 A1 A2 . . . in Gϕ.
The
accepting conditions for Gϕ are chosen such that the run ¯σ is accepting if and only if σ |= ϕ.
Thus, we have to encode the meaning of the logical operators into the states, transitions,
and acceptance sets of Gϕ. The meaning of propositional logic operators ∧, ¬, and the
constant true will be encoded in the states by requiring consistent formula sets Bi. The
semantics of the next-step operator relies on a nonlocal condition and will be encoded in the
transition relation. The meaning of the until operator is split according to the expansion
law into local conditions (encoded in the states) and a next-step condition (encoded in the
transitions). Since the expansion law does not provide a full characterization of until, a
further condition is imposed which expresses the fact that the meaning of until yields the
least solution of the expansion law (see Lemma 5.18 on page 251). This will be encoded
by the acceptance sets of Gϕ.

276
Linear Temporal Logic
As explained above, the formula sets are subsets of subformulae of ϕ and their negation.
Deﬁnition 5.34.
Closure of ϕ
The closure of LTL formula ϕ is the set closure(ϕ) consisting of all subformulae ψ of ϕ
and their negation ¬ψ (where ψ and ¬¬ψ are identiﬁed).
For instance, for ϕ = a U (¬a ∧b), the set closure(ϕ) consists of the formulae
a, b, ¬a, ¬b, ¬a ∧b, ¬(¬a ∧b), ϕ, ¬ϕ.
It is not diﬃcult to assess that |closure(ϕ)| ∈O(|ϕ|). A set of formulae B ⊆closure(ϕ)
is called elementary if B is the set of all formulae ψ ∈closure(ϕ) with π |= ψ for a path
π. For this, B should not contain propositional logic contradictions and it must be locally
consistent with respect to the until operator. Since for any path π and formula ψ, either
π |= ψ or π |= ¬ψ, it is additionally required that elementary sets of formulae are maximal.
The precise deﬁnition of these three conditions is provided in Figure 5.20 on page 277.
Deﬁnition 5.35.
Elementary Sets of Formulae
B ⊆closure(ϕ) is elementary if it is consistent with respect to propositional logic, maxi-
mal, and locally consistent with respect to the until operator.
The requirements for local consistency result from the expansion law
ϕ1 U ϕ2 ≡ϕ2 ∨(ϕ1 ∧⃝(ϕ1 U ϕ2)).
Due to the required maximality and propositional logic consistency, we have
ψ ∈Bif and only if
¬ψ ̸∈B
for all elementary sets B and subformulae ψ of ϕ. Further, due to maximality and local
consistency, we have
ϕ1, ϕ2 ̸∈B
implies
ϕ1 U ϕ2 /∈B.
Hence, if ϕ1, ϕ2 ̸∈B then { ¬ϕ1, ¬ϕ2, ¬(ϕ1 U ϕ2) } ⊆B; here, it is assumed that ϕ1 U ϕ2
is a subformula of ϕ.
Example 5.36.
Elementary Sets of Formulae
Let ϕ = a U (¬a ∧b). The set B = { a, b, ϕ } ⊆closure(ϕ) is consistent with respect to
propositional logic and locally consistent with respect to the until operator. It is, however,
not maximal, since for ¬a ∧b ∈closure(ϕ):
¬a ∧b /∈B
and
¬(¬a ∧b) /∈B.

Automata-Based LTL Model Checking
277
1. B is consistent with respect to propositional logic, i.e., for all
ϕ1 ∧ϕ2, ψ ∈closure(ϕ):
• ϕ1 ∧ϕ2 ∈B ⇔ϕ1 ∈B and ϕ2 ∈B
• ψ ∈B ⇒¬ψ ̸∈B
• true ∈closure(ϕ) ⇒true ∈B.
2. B is locally consistent with respect to the until operator, i.e.,
for all ϕ1 U ϕ2 ∈closure(ϕ):
• ϕ2 ∈B ⇒ϕ1 U ϕ2 ∈B
• ϕ1 U ϕ2 ∈B and ϕ2 ̸∈B ⇒ϕ1 ∈B.
3. B is maximal, i.e., for all ψ ∈closure(ϕ):
• ψ /∈B
⇒
¬ψ ∈B.
Figure 5.20: Properties of elementary sets of formulae.
The set of formulae { a, b, ¬a∧b, ϕ } contains the propositional logic “contradiction” a and
¬a ∧b and therefore is not elementary. The set
{¬a, ¬b, ¬(¬a ∧b), ϕ}
is consistent with respect to propositional logic but contains a local inconsistency with
respect to the until operator U , since a U (¬a ∧b) ∈B and ¬a ∧b ̸∈B, but a ̸∈B. This
means that
π |= ¬a,
π |= ¬(¬a ∧b),
and
π |= ϕ
are impossible for any path π.
The following sets are elementary:
B1
=
{
a,
b,
¬(¬a ∧b),
ϕ },
B2
=
{
a,
b,
¬(¬a ∧b),
¬ϕ },
B3
=
{
a,
¬b,
¬(¬a ∧b),
ϕ },
B4
=
{
a,
¬b,
¬(¬a ∧b),
¬ϕ },
B5
=
{
¬a,
¬b,
¬(¬a ∧b),
¬ϕ },
B6
=
{
¬a,
b,
¬a ∧b,
ϕ }.
The proof of the following theorem shows how to construct for an arbitrary LTL formula ϕ
a GNBA Gϕ with Lω(Gϕ) = Words(ϕ). This construction is one of the initial steps of the

278
Linear Temporal Logic
LTL model checking algorithm; see Figure 5.16 (page 273). Subsequently, the resulting
GNBA Gϕ is transformed into an NBA Aϕ by means of the technique indicated in the
proof of Theorem 4.56 (page 195).
Theorem 5.37.
GNBA for LTL Formula
For any LTL formula ϕ (over AP) there exists a GNBA Gϕ over the alphabet 2AP such
that
(a) Words(ϕ) = Lω(Gϕ).
(b) Gϕ can be constructed in time and space 2O(|ϕ|).
(c) The number of accepting sets of Gϕ is bounded above by O(|ϕ|).
Proof: Let ϕ be an LTL formula over AP. Let Gϕ = (Q, 2AP, δ, Q0, F) where
• Q is the set of all elementary sets of formulae B ⊆closure(ϕ),
• Q0 = { B ∈Q | ϕ ∈B },
• F = { Fϕ1 U ϕ2 | ϕ1 U ϕ2 ∈closure(ϕ)} where
Fϕ1 U ϕ2 = { B ∈Q | ϕ1 U ϕ2 ̸∈B or ϕ2 ∈B }.
The transition relation δ : Q × 2AP →2Q is given by:
• If A ̸= B ∩AP, then δ(B, A) = ∅.
• If A = B∩AP, then δ(B, A) is the set of all elementary sets of formulae B′ satisfying
(i) for every ⃝ψ ∈closure(ϕ): ⃝ψ ∈B
⇔
ψ ∈B′, and
(ii) for every ϕ1 U ϕ2 ∈closure(ϕ):
ϕ1 U ϕ2 ∈B
⇔
(ϕ2 ∈B ∨(ϕ1 ∈B ∧ϕ1 U ϕ2 ∈B′)).
The constraints (i) and (ii) reﬂect the semantics of the next-step and the until operator,
respectively. Rule (ii) is justiﬁed by the expansion law:
ϕ1 U ϕ2
≡
ϕ2 ∨(ϕ1 ∧⃝(ϕ1 U ϕ2)).

Automata-Based LTL Model Checking
279
To model the semantics of U , an acceptance set Fψ is introduced for every subformula
ψ = ϕ1 U ϕ2 of ϕ. The underlying idea is to ensure that in every run B0 B1 B2 . . . for which
ψ ∈B0, we have ϕ2 ∈Bj (for some j ⩾0) and ϕ1 ∈Bi for all i < j. The requirement
that a word σ satisﬁes ϕ1 U ϕ2 only if ϕ2 will actually eventually become true is ensured
by the accepting set Fϕ1 U ϕ2.
Let us ﬁrst consider the claim (b). States in the GNBA Gϕ are elementary sets of formulae
in closure(ϕ). Let subf(ϕ) denote the set of all subformulae of ϕ. The number of states in
Gϕ is bounded by 2|subf(ϕ)|, the number of possible formula sets. (The elementary formula
sets B can be represented by bit vectors containing a single bit per subformula ψ of ϕ
which indicates whether ψ or ¬ψ belongs to B.) As |subf(ϕ)| ⩽2·|ϕ|, the number of states
in the GNBA Gϕ is bounded by 2O(|ϕ|). Claim (c) follows directly from the fact that the
number of accept sets is equal to the number of until-subformulae in ϕ.
It remains to show that (a) Lω(Gϕ) = Words(ϕ). We prove set inclusion in both directions.
⊇: Let σ = A0 A1 A2 . . . ∈Words(ϕ). Then, σ ∈(2AP)ω and σ |= ϕ. The elementary set
Bi of formulae is deﬁned as follows:
Bi = { ψ ∈closure(ϕ) | AiAi+1 . . . |= ψ }
(5.1)
Obviously, Bi is an elementary set of formulae, i.e., Bi ∈Q. We now prove that B0 B1 B2 . . .
is an accepting run for σ. Observe that Bi+1 ∈δ(Bi, Ai) for all i ⩾0, since for all i:
• Ai = Bi ∩AP
• for ⃝ψ ∈closure(ϕ):
⃝ψ ∈Bi
iﬀ
(* equation (5.1) for Bi *)
Ai Ai+1 . . . |= ⃝ψ
iﬀ
(* semantics of ⃝*)
Ai+1 Ai+2 . . . |= ψ
iﬀ
(* equation (5.1) for Bi+1 *)
ψ ∈Bi+1

280
Linear Temporal Logic
• for ϕ1 U ϕ2 ∈closure(ϕ):
ϕ1 U ϕ2 ∈Bi
iﬀ
(* equation (5.1) for Bi *)
Ai Ai+1 . . . |= ϕ1 U ϕ2
iﬀ
(* semantics of until *)
Ai Ai+1 . . . |= ϕ2 or
Ai Ai+1 . . . |= ϕ1 and (Ai+1 Ai+2 . . . |= ϕ1 U ϕ2
)
iﬀ
(* equation (5.1) for Bi and Bi+1 *)
ϕ2 ∈Bi or (ϕ1 ∈Bi and ϕ1 U ϕ2 ∈Bi+1)
.
This shows that B0 B1 B2 . . . is a run of Gϕ. It remains to prove that this run is accepting,
i.e., for each subformula ϕ1,j U ϕ2,j in closure(ϕ), Bi ∈Fj for inﬁnitely many i.
By
contraposition. Assume there are ﬁnitely many i such that Bi ∈Fj. We have:
Bi /∈Fj = Fϕ1,j U ϕ2,j ⇒ϕ1,j U ϕ2,j ∈Bi and ϕ2,j /∈Bi.
As Bi = { ψ ∈closure(ϕ) | Ai Ai+1 . . . |= ψ }, it follows that if Bi ̸∈Fj, then:
Ai Ai+1 . . . |= ϕ1,j U ϕ2,j
and
Ai Ai+1 . . . ̸|= ϕ2,j.
Thus, Ak Ak+1 . . . |= ϕ2,j for some k > i. By deﬁnition of the formula sets Bi, it then
follows that ϕ2,j ∈Bk, and by deﬁnition of Fj, Bk ∈Fj. Thus, Bi ∈Fj for ﬁnitely many
i, then Bk ∈Fj for inﬁnitely many k. Contradiction.
Thus, B0 B1 B2 . . . is an accepting run of Gϕ, and hence, A0 A1 A2 . . . ∈Lω(Gϕ).
⊆: Let σ = A0 A1 A2 . . . ∈Lω(Gϕ), i.e., there is an accepting run B0 B1 B2 . . ., say, for σ
in Gϕ. Since
δ(B, A) = ∅
for all pairs (B, A) with A ̸= B ∩AP,
it follows that Ai = Bi ∩AP for i ⩾0. Thus
σ
=
(B0 ∩AP) (B1 ∩AP) (B2 ∩AP) . . .
Our proof obligation now becomes (B0 ∩AP) (B1 ∩AP) (B2 ∩AP) . . . |= ϕ. We prove
the following more general proposition:

Automata-Based LTL Model Checking
281
For B0B1B2 . . . a sequence with Bi ∈Q satisfying
(i) for all i ⩾0 : Bi+1 ∈δ(Bi, Ai), and
(ii) for all F ∈F :
∞
∃j ⩾0. Bj ∈F,
we have for all ψ ∈closure(ϕ):
ψ ∈B0
⇔
A0 A1 A2 . . . |= ψ.
The proof of this claim is by structural induction on the structure of ψ.
Base case: The statement for ψ = true or ψ = a with a ∈AP follows directly from
equation (5.1) and the deﬁnition of closure.
Induction step: Based on the induction hypothesis that the claim holds for ψ′, ϕ1, ϕ2 ∈
closure(ϕ), it is proven that for the formulae
ψ = ⃝ψ′, ψ = ¬ψ′, ψ = ϕ1 ∧ϕ2 and ψ = ϕ1 U ϕ2
the claim also holds. We provide the detailed proof for ψ = ϕ1 U ϕ2. Let A0 A1 A2 . . . ∈
(2AP)ω and B0 B1 B2 . . . ∈Qω satisfying the constraints (i) and (ii). It is now shown that:
ψ ∈B0
iﬀ
A0 A1 A2 . . . |= ψ.
This goes as follows.
⇐: Assume A0 A1 A2 . . . |= ψ where ψ = ϕ1 U ϕ2. Then, there exists j ⩾0 such that
Aj Aj+1 . . . |= ϕ2
and
Ai Ai+1 . . . |= ϕ1 for 0 ⩽i < j.
From the induction hypothesis (applied to ϕ1 and ϕ2) it follows that
ϕ2 ∈Bj
and
ϕ1 ∈Bi
for 0 ⩽i < j.
By induction on j we obtain: ϕ1 U ϕ2 ∈Bj, Bj−1 . . . , B0.
⇒: Assume ϕ1 U ϕ2 ∈B0. Since B0 is elementary, ϕ1 ∈B0 or ϕ2 ∈B0.
Distinguish
between ϕ2 ∈B0 and ϕ2 ̸∈B0.
If ϕ2 ∈B0, it follows from the induction hypothesis
A0 A1 . . . |= ϕ2, and thus A0 A1 . . . |= ϕ1 U ϕ2. This remains the case ϕ2 ̸∈B0. Then
ϕ1 ∈B0 and ϕ1 U ϕ2 ∈B0.
Assume ϕ2 ̸∈Bj for all j ⩾0.
From the deﬁnition of
the transition relation δ, we obtain using an inductive argument (successively applied to
ϕ1 ∈Bj, ϕ2 /∈Bj and ϕ1 U ϕ2 ∈Bj for j ⩾0):
ϕ1 ∈Bj
and
ϕ1 U ϕ2 ∈Bj
for all j ⩾0.

282
Linear Temporal Logic
{ a, ⃝a }
B1
{ a, ¬ ⃝a }
B2
{ ¬a, ⃝a }
B3
{ ¬a, ¬ ⃝a }
B4
a
¬a
a
a
¬a
¬a
¬a
a
Figure 5.21: A generalised B¨uchi automaton for the LTL formula ⃝a.
As B0 B1 B2 . . . satisﬁes constraint (ii), it follows that
Bj ∈Fϕ1 U ϕ2for inﬁnitely many j ⩾0.
On the other hand, we have
ϕ2 ̸∈Bj
and
ϕ1 U ϕ2 ∈Bj



iﬀ
Bj̸∈Fϕ1 U ϕ2
for all j. Contradiction! Thus, ϕ2 ∈Bj for some j ⩾0. Without loss of generality, assume
ϕ2 ̸∈B0, . . . , Bj−1, i.e., let j be the smallest index such that ϕ2 ∈Bj. The induction
hypothesis for 0 ⩽i < j yields
ϕ1 ∈Bi
and
ϕ1 U ϕ2 ∈Bi
for all 0 ⩽i < j.
From the induction hypothesis applied to ϕ1 and ϕ2 it follows that
Aj Aj+1 . . . |= ϕ2
and
Ai Ai+1 . . . |= ϕ1 for 0 ⩽i < j.
We conclude that A0 A1 A2 . . . |= ϕ1 U ϕ2.
Example 5.38.
Construction of a GNBA (Next Step)
Consider ϕ = ⃝a. The GNBA Gϕ (see Figure 5.21) is obtained as indicated in the proof of
Theorem 5.37, . The states of the automaton are the elementary sets of formulae contained
in
closure(ϕ) = { a, ⃝a, ¬a, ¬ ⃝a }.

Automata-Based LTL Model Checking
283
The state space Q consists of the following elementary sets
B1
=
{ a, ⃝a },
B2
=
{ a, ¬⃝a },
B3
=
{ ¬a, ⃝a },
B4
=
{ ¬a, ¬⃝a }.
The initial states of Gϕ are the elementary sets B ∈Q with ϕ = ⃝a ∈B. Thus Q0 =
{ B1, B3 }.
Let us justify some of the transitions.
For state B1, B1 ∩{ a } = { a }, so
δ(B1, ∅) = ∅. In addition, δ(B1, { a }) = { B1, B2 } since ⃝a ∈B1 and B1 and B2 are
the only states that contain a. As B2 ∩{ a } = { a }, we get δ(B2, ∅) = ∅. Moreover,
δ(B2, { a }) = { B3, B4 }. This follows from the fact that for ¬⃝ψ ∈closure(ϕ), and any
direct successor B′ of B we have
̸=⃝ψ ∈B if and only if ψ ̸∈B′.
(This follows by the deﬁnition of δ, local consistency and maximality.) Since ¬⃝a ∈B2,
and B3 and B4 are the only states that do not contain a, we have δ(B2, { a }) = { B3, B4 }.
Hence, δ(B4, { a }) = ∅since B4∩{ a } = ∅̸= { a }. Using a similar reasoning as above, we
obtain δ(B4, ∅) = { B3, B4 }. The outgoing transitions of B3 are determined analogously.
The set F is empty as ϕ = ⃝a does not contain an until operator. Since F = ∅, every
inﬁnite run in the GNBA Gϕ is accepting.
As each inﬁnite run is either of the form
B1 B1 . . ., B1 B2 . . ., B3 B1 . . ., or B3 B2 . . ., and ϕ = ⃝a ∈B1, B2, it follows that indeed
all runs satisfy ⃝a.
Example 5.39.
Construction of a GNBA (Until)
Consider ϕ = a U b and let AP = { a, b }. Then
closure(ϕ) = { a, b, ¬a, ¬b, a U b, ¬(a U b) }.
The construction in the proof of Theorem 5.37 yields the GNBA Gϕ illustrated in Fig-
ure 5.22. In order not to blur the ﬁgure, transition labels have been omitted. (The label
of transition B →B′ equals the propositional logic formula characterising the set B∩AP.)
The states correspond to the elementary sets of closure(ϕ)
B1
=
{ a,
b,
ϕ },
B2
=
{ ¬a,
b,
ϕ },
B3
=
{ a,
¬b,
ϕ },
B4
=
{ ¬a,
¬b,
¬ϕ },
B5
=
{ a,
¬b,
¬ϕ }.
The initial states are the sets Bi ∈Q with ϕ ∈Bi; thus, Q0 = { B1, B2, B3 }. The set
F = { Fϕ } of the accepting sets is a singleton, since ϕ contains a single until operator.

284
Linear Temporal Logic
The set Fϕ is given by
Fϕ = { B ∈Q | ϕ /∈B ∨b ∈B } = { B1, B2, B4, B5 }.
Since the accepting set is a singleton set, the GNBA Gϕ can be understood as an NBA
with the accepting set Fϕ.
Let us justify some of the transitions. We have B1 ∩AP = { a, b } and a U b ∈B1. As:
b ∈B1 ∨(a ∈B1 ∧a U b ∈B′)
holds for any elementary set B′ ⊆closure(a U b), we have that δ(B1, { a, b }) contains all
states. These are the only outgoing transitions of state B1. A similar reasoning applies
to δ(B2, { b }). Consider state B3. Then B3 ∩AP = { a }. The states B′ that are possible
direct successors of B3 under { a } are those satisfying
a ∈B3 ∧a U b ∈B′.
Thus, δ(B3, { a }) = { B1, B2, B3 }. Finally, consider state B5. This state only has succes-
sors for input symbol B5 ∩AP = { a }. For any ϕ1 U ϕ2 ∈closure(ϕ) it can be shown that
for any successor B′ of B:
ϕ1 U ϕ2 ̸∈B
iﬀ
ϕ2 ̸∈B ∧(ϕ1 ̸∈B ∨ϕ1 U ϕ2 ̸∈B′).
(The proof of this fact is left as an exercise.) Applying this to the state B5 yields that all
states not containing ϕ are possible successors of B5. For example, the run B3 B3 B1 Bω
4
is accepting. This run corresponds to the word { a }{ a }{ a, b }∅ω which indeed satisﬁes
a U b. The word { a }ω does not satisfy a U b. It has exactly one run in Gϕ, namely Bω
3 . As
B3 is not a ﬁnal state, this run is not accepting, i.e., { a }ω /∈Lω(Gϕ).
Remark 5.40.
Simpliﬁed Representation of the Automata States
Any state of the GNBA for an LTL formula ϕ contains either ψ or its negation ¬ψ for
every subformula ψ of ϕ.
This is somewhat redundant.
It suﬃces to represent state
B ∈closure(ϕ) by the propositional symbols a ∈B ∩AP, and the formulae ⃝ψ or
ϕ1 U ϕ2 ∈B.
Having constructed a GNBA Gϕ for a given LTL formula ϕ, an NBA for ϕ can be obtained
by the transformation “GNBA ⇝NBA” described in Theorem 4.56 on page 195. Recall
that this transformation for GNBA with two or more acceptance sets generates a copy of
Gϕ for each acceptance set of Gϕ. In our case, the number of copies that we need is given
by the number of until subformulae of ϕ. We obtain the following result:

Automata-Based LTL Model Checking
285
{ a, b, a U b }
B1
{ ¬a, ¬b, ¬(a U b) }
B4
{ a, ¬b, ¬(a U b) }
B5
{ ¬a, b, a U b }
B2
{ a, ¬b, a U b }
B3
Figure 5.22: A generalised B¨uchi automaton for a U b.
Theorem 5.41.
Constructing an NBA for an LTL Formula
For any LTL formula ϕ (over AP) there exists an NBA Aϕ with Words(ϕ) = Lω(Aϕ)
which can be constructed in time and space 2O(|ϕ|).
Proof: From Theorem 5.37 (page 278), it follows that a GNBA Gϕ can be constructed
which has at most 2|ϕ| states. As the number of accepting states in Gϕ equals the number
of until-subformulas in ϕ, GNBA Gϕ has at most |ϕ| accepting states. Transforming the
GNBA into an equivalent NBA (as described in the proof of Theorem 4.56, page 195),
yields an NBA with at most |ϕ| copies of the state space of Gϕ. Thus, the number of states
in the NBA is at most 2|ϕ|·|ϕ| = 2|ϕ|+log |ϕ| states. This yields the claim.
There are various algorithms in the literature for associating an automaton for inﬁnite
words to an LTL formula. The presented algorithm is one of the conceptually simplest al-
gorithms, but often yields unnecessarily large GNBAs. For example, for the LTL formulae
⃝a and a U b, an NBA with two states suﬃces. (It is left to the reader to provide these
NBAs.) Several optimizations are possible to improve the size of the resulting GNBA,
but the exponential blowup cannot be avoided. This is formally stated in the following
theorem:

286
Linear Temporal Logic
Theorem 5.42.
Lower Bound for NBA from LTL Formulae
There exists a family of LTL formulae ϕn with |ϕn| = O(poly(n)) such that every NBA
for ϕn has at least 2n states.
Proof: Let AP be an arbitrary nonempty set of atomic propositions, that is, |2AP| ⩾2.
Consider the family of languages:
Ln = { A1 . . . An A1 . . . An σ | Ai ⊆AP ∧σ ∈(2AP)ω },
for n ⩾0.
It is not diﬃcult to check that Ln = Words(ϕn) where
ϕn =

a∈AP

0⩽i<n
(⃝ia ←→⃝n+i a).
Here, ⃝j stands for the j-fold application of the next-step operator ⃝, i.e., ⃝1ϕ = ⃝ϕ
and ⃝n+1ϕ = ⃝⃝nϕ. It follows that ϕn is an LTL formula of polynomial length. More
precisely, |ϕn| ∈
O(|AP| · n).
However, any NBA A with Lω(A) = Ln has at least 2n states. Essentially, this is justiﬁed
by the following consideration. Since the words
A1 . . . An A1 . . . An ∅∅∅. . .
are accepted by A, A contains for every word A1 . . . An of length n, a state q(A1 . . . An),
which can be reached from an initial state by consuming the preﬁx A1 . . . An. Starting
from q(A1 . . . An) it is possible to visit an accept state inﬁnitely often by accepting the
suﬃx A1 . . . An ∅∅∅. . .. If A1 . . . An ̸= A′
1 . . . A′
n then
A1 . . . An A′
1 . . . A′
n ∅∅∅. . . /∈Ln = Lω(A).
Therefore, the states q(A1 . . . An) are all pairwise diﬀerent. As there are |2AP| possible
combinations for A1 . . . An, A has at least (|2AP|)n ⩾2n states.
Remark 5.43.
B¨uchi Automata are More Expressive Than LTL
The results so far show that for every LTL formula ϕ an NBA can be constructed that
accepts exactly the inﬁnite sequences satisfying ϕ. We state without proof that the reverse,
however, is not true. It can be shown that for, e.g., the LT property
P =

A0 A1 A2 . . . ∈(2{ a })ω | a ∈A2i for i ⩾0

,
which requires a to hold in every even position, there is no LTL formula ϕ with Words(ϕ) =
P. On the other hand, there exists an NBA A with Lω(A) = P. (It is left to the reader
to provide such an NBA.)

Automata-Based LTL Model Checking
287
5.2.1
Complexity of the LTL Model-Checking Problem
Let us summarize the results of the previous sections in order to provide an overview of
LTL model checking. Subsequently, we discuss the complexity of the LTL model-checking
problem.
As explained before, the essential idea behind the automata-based model-checking algo-
rithm for LTL is based upon the following relations:
TS |= ϕ
iﬀTraces(TS) ⊆Words(ϕ)
iﬀTraces(TS) ⊆(2AP)ω \ Words(¬ϕ)
iﬀTraces(TS) ∩Words(¬ϕ)



Lω(A¬ϕ)
= ∅
iﬀTS ⊗A¬ϕ |= ♦□¬F.
Here, NBA A¬ϕ accepts Words(¬ϕ) and F is its set of accept states. The algorithm to
transform an LTL formula ϕ into an NBA may give rise to an NBA whose state space size
is exponential in the length of ϕ. The NBA A¬ϕ can thus be constructed in exponential
time:
O(2|ϕ| · |ϕ|) = O(2|ϕ|+ log |ϕ|).
This complexity bound, together with the fact that the state space of A is exponential in
|ϕ|, yields an upper bound for the time- and space-complexity of LTL model checking (see
Algorithm 11, page 272):
O( |TS| · 2|ϕ| ).
Remark 5.44.
LTL Model Checking with Fairness
As a consequence of Theorem 5.30 (see page 264), the model-checking problem for LTL
with fairness assumptions can be reduced to the model-checking problem for plain LTL.
So, in order to check the formula ϕ under fairness assumption fair, it suﬃces to verify
the formula fair →ϕ with an LTL model-checking algorithm. This approach, however,
has as its main drawback that the length |fair| can have an exponential inﬂuence on the
run-time of the algorithm. This is due to the construction of an NBA for the negated
formula, i.e., ¬(fair →ϕ), whose size is exponential in |¬(fair →ϕ)| = |fair| + |ϕ|. To
avoid this additional exponential blowup, a modiﬁed persistence check (see Algorithm 8
on page 211) can be exploited to analyze the product transition system TS⊗A¬ϕ (instead
of TS ⊗A¬(fair→ϕ)). This can be done using standard graph algorithms. The reader is
referred to Exercise 5.22 (on page 308) for more details.

288
Linear Temporal Logic
An interesting aspect of the LTL model-checking algorithm is that it can be executed on-
the-ﬂy, i.e., while constructing the NBA A¬ϕ. This may avoid the need for constructing the
entire automaton A¬ϕ. This on-the-ﬂy procedure works as follows. Suppose we are given a
high-level description of the transition system TS, e.g., by means of a syntactic description
of the concurrent processes (as in Spin’s input language Promela). The generation of
the reachable states of TS can proceed in parallel with the construction of the relevant
fragment of A¬ϕ. Simultaneously, the reachable fragment of the product transition system
TS ⊗A¬ϕ is constructed in a DFS-manner. (This, in fact, yields the outermost DFS in
the nested DFS for checking persistence in TS ⊗A¬ϕ.) So the entire LTL model-checking
procedure can be interleaved with the generation of the relevant fragments of TS and A¬ϕ.
In this way, the product transition system TS ⊗A¬ϕ is constructed “on demand”, so to
speak. A new vertex is only considered if no accepting cycle has been encountered yet
in the partially constructed product transition system TS ⊗A¬ϕ. When generating the
successors of a state in A¬ϕ, it suﬃces to only consider the successors matching the current
state TS (rather than all possible successors). It is thus possible that an accepting cycle
is found, i.e., a violation of ϕ (with corresponding counterexample), without the need for
generating the entire automaton A¬ϕ.
This on-the-ﬂy generation of Reach(TS), A¬ϕ, and TS ⊗A¬ϕ is adopted in practical
LTL model checkers (such as Spin) and for many examples yields an eﬃcient veriﬁcation
procedure. From a theoretical point of view, though, the LTL model-checking problem
remains computationally hard and is ”probably” not eﬃciently solvable. It is shown in
the sequel of this section that the LTL model-checking problem is PSPACE-complete.
We assume some familiarity with basic notions of complexity theory and the complexity
classes coNP and PSPACE; see, e.g., the textbooks [160, 320] and the Appendix.
Before proving the PSPACE-hardness of the LTL model-checking problem, a weaker result
is provided. To that end, let us recall the so-called Hamiltonian path problem. Consider a
ﬁnite directed graph G = (V, E) with set V of vertices and set E ⊆V × V of edges. The
Hamiltonian path problem is a decision problem that yields an aﬃrmative answer when G
has a Hamiltonian path, i.e., a path which passes through every vertex in V exactly once.
The next ingredient needed for the following result is the complement of the LTL model-
checking problem. This decision problem takes as input a ﬁnite transition system TS and
an LTL formula ϕ and asks whether TS ̸|= ϕ. Thus, whenever the LTL model-checking
problem provides an aﬃrmative answer, its complement yields “no”, and whenever the
result of the LTL model-checking problem is negative, its complement yields “yes”.
Lemma 5.45.
The Hamiltonian path problem is polynomially reducible to the complement of the LTL
model-checking problem.

Automata-Based LTL Model Checking
289
Proof: To establish a polynomial reduction from the Hamiltonian path problem to the
complement of the LTL model-checking problem, a mapping is needed from instances of
the Hamiltonian path problem onto instances for the complement model-checking problem.
That is, we need to map a ﬁnite directed graph G onto a pair (TS, ϕ) where TS is a ﬁnite
transition system and ϕ is an LTL formula, such that
(i) G has a Hamiltonian path if and only if TS ̸|= ϕ, and
(ii) the transformation G ⇝(TS, ϕ) can be performed in polynomial time.
The basic concept of the mapping is as follows. Essentially, TS corresponds to G, i.e., the
states of TS are the vertices in G and the transitions in TS correspond to the edges in
G. For technical reasons, G is slightly modiﬁed to ensure that TS has no terminal states.
More precisely, the state graph of TS arises from G by inserting a new vertex b to G, which
is reachable from every vertex v via an edge and which is only equipped with a self-loop
b →b (i.e., b has no further outgoing edges). Formally, for G = (V, E) the associated
transition system is
TS = (V ⊎{ b }, { τ }, →, V, V, L)
where L(v) = { v } for any vertex v ∈V and L(b) = ∅. The atomic propositions for TS
are thus obtained by taking the identities of the vertices in G. The transition relation →
is deﬁned as follows:
(v, w) ∈E
v
τ
−→w
and
v ∈V ∪{ b }
v
τ
−→b
.
This completes the mapping of directed graph G onto transition system TS. It remains to
formalize the negation of the existence (i.e., the absence) of a Hamiltonian path by means
of an LTL formula. Let
ϕ = ¬

v∈V
( ♦v
∧
□(v →⃝□¬v) ).
Stated in words, ϕ asserts that it is not the case that each vertex v ∈V is eventually
visited and never visited again. Note that the conjunction does not quantify over b ̸∈V .
It is evident that TS and ϕ can be constructed in polynomial time for a given directed
graph G. As a last step, we need to show that G has a Hamiltonian path if and only if
TS ̸|= ϕ.
⇐: Assume TS ̸|= ϕ. Then there exists a path π in TS such that
π |=

v∈V
( ♦v
∧
□(v →⃝□¬v) ).

290
Linear Temporal Logic
As π |= 
v∈V ♦v, each vertex v ∈V occurs at least once in the path π. Since
π |=

v∈V
□(v →⃝□¬v),
there is no vertex that occurs more than once in π. Thus, π is of the form v1 . . . vnb b b . . .
where V = { v1, . . . , vn } and |V | = n. In particular, v1 . . . vn is a Hamiltonian path in G.
⇒: Each Hamiltonian path v1 . . . vn in G can be extended to a path π = v1 . . . vnb b b . . .
in TS. Thus, π ̸|= ϕ and, hence, TS ̸|= ϕ.
Since the Hamiltonian path problem is known to be NP-complete, it follows from the previ-
ous lemma that the LTL model-checking problem is coNP-hard. The following complexity
result states that the LTL model-checking problem is PSPACE-hard.
Theorem 5.46.
Lower Bound for LTL Model Checking
The LTL model-checking problem is PSPACE–hard.
Proof: Let TS be a ﬁnite transition system and ϕ an LTL formula. As a ﬁrst observation,
note that it suﬃces to show the PSPACE-hardness of the existential variant of the LTL
model-checking problem. This existential decision problem takes as input TS and ϕ and
yields “yes” if π |= ϕ for some (initial, inﬁnite) path π in TS, and “no” otherwise. Given
that
TS |= ϕ
if and only if
π |= ϕ for all paths π
if and only if
not (π |= ¬ϕ for some path π)
it follows that the output for the instance (TS, ϕ) of the LTL model-checking problem
yields ”yes” if and only if the output for the instance (TS, ¬ϕ) of the existential vari-
ant of the LTL model-checking problem yields ”no”.
Thus, the PSPACE-hardness of
the existential variant of the LTL model-checking problem yields the PSPACE-hardness
of the complement of the existential variant of the LTL model checking problem which
again induces the PSPACE-hardness of the LTL model-checking problem. Recall that
PSPACE = coPSPACE, thus, the complement of any PSPACE-hard problem is PSPACE-
hard.
In the remainder of the proof we concentrate on showing the PSPACE–hardness of the
existential LTL model-checking problem. This is established by providing a polynomial
reduction from any decision problem K ∈PSPACE to the existential LTL model-checking
problem. Let M be a polynomial space-bounded deterministic Turing machine that ac-
cepts exactly the words w ∈K. The goal is now to transform (M, w) by a deterministic

Automata-Based LTL Model Checking
291
polynomial-time bounded procedure into a pair (TS, ϕ) such that M accepts w if and only
if TS contains a path π with π |= ϕ.
The following proof, adopted from [372], has some similarities with Cook’s theorem stating
the NP-completeness of the satisﬁability problem for propositional logic. The rough idea
is to encode the initial conﬁgurations, possible transitions, and accepting conﬁgurations
of a given Turing machine M by LTL formulae. In the sequel, let M be a deterministic
single-tape Turing machine with state-space Q, starting state q0 ∈Q, the set F of accept
states, the tape alphabet Σ, and the transition function δ : Q × Σ →Q × Σ × { L, R, N }.
The intuitive meaning of δ is as follows. Suppose δ(q, A) = (p, B, L). Then, whenever the
current state is q and the current symbol in cell i under the cursor is A, then M changes
to state p, overwrites the symbol A by B in cell i, and moves the cursor one position to
the left, i.e., it positions the cursor under cell i−1. For R or N, the cursor moves one
position to the right, or does not move at all, respectively. (For our purposes, there is no
need to distinguish between the input and the tape alphabet.)
For technical reasons, it is required that the accept states are absorbing, i.e., δ(q, A) =
(q, A, N) for all q ∈F. Moreover, it is assumed that M is polynomially space-bounded,
i.e., there is a polynomial P such that the computation for an input word A1 . . . An ∈Σ∗
of length n visits at most the ﬁrst P(n) cells on the tape. Without loss of generality, the
coeﬃcients of P are assumed to be natural numbers and P(n) ⩾n.
To encode M’s possible behaviors by LTL formulae for an input word of length n, the
Turing machine is transformed into a transition system TS = TS(M, n) with the following
state space:
S = {0, 1, . . . , P(n)} ∪{(q, A, i) | q ∈Q ∪{ ∗}, A ∈Σ, 0 < i ⩽P(n)}.
The structure of TS is shown in Figure 5.23. TS consists of P(n) copies of “diamonds”.
The ith copy starts in state i−1, ends in state i, and contains the states (q, A, i) where
q ∈Q ∪{ ∗} and A ∈Σ “between” state i−1 and state i. Intuitively, the ﬁrst component
q ∈Q∪{ ∗} of state (q, A, i) in the ith copy indicates whether the cursor points to cell i (in
which case q ∈Q is the current state) or to some other tape cell (in which case q = ∗). The
symbol A ∈Σ in state (q, A, i) stands for the current symbol in cell i. The path fragments
from state 0 to state P(n) serve to represent the possible conﬁgurations of M. More
precisely, the conﬁguration in which the current content of the tape is A1 A2 . . . AP (n), the
current state is q, and the cursor points to cell i is encoded by the path fragment:
0 (∗, A1, 1) 1 (∗, A2, 2) 2 . . . i−1 (q, Ai, i) i (∗, Ai+1, i+1) i+1 . . . P(n)
Accordingly, the computation of M for an input word of length n can be described by the
concatenation of such path fragments.

292
Linear Temporal Logic
0
1
2
P(n)
Figure 5.23: Transition system TS(M, n) for Turing machine M and input length n.
We use the state identities as atomic propositions. In addition, proposition begin is used
to identify state 0, while proposition end is used for state P(n). That is, AP = S ∪
{ begin, end } with the obvious labeling function. Let ΦQ denote the disjunction over all
atoms (q, A, i) where q ∈Q (i.e., q ̸= ∗) and A ∈Σ, 0 < i ⩽P(n). The LTL formulae:
ϕConf
=
□

begin −→ϕ1
Conf ∧ϕ2
Conf

where
ϕ1
Conf
=
"
1⩽i⩽P (n)
⃝2i−1ΦQ
ϕ2
Conf
=

1⩽i⩽P (n)

⃝2i−1ΦQ
−→

1⩽j⩽P (n)
j̸=i
⃝2j−1¬ΦQ

characterize any path π in TS such that all path fragments of π that lead from 0 via
1, . . . , P(n−1) to P(n) encode a conﬁguration of M. Note that ϕ1
Conf∧ϕ2
Conf ensures that the
cursor points exactly to one of the positions 1, . . . , P(n). Thus, any path π in TS such that
π |= ϕConf can be viewed as a sequence of conﬁgurations in M. However, this sequence need
not be a computation of M, since the conﬁgurations might not be consecutive according
to M’s operational behavior. For this, we need additional constraints that formalize M’s
stepwise behavior.
The transition relation δ of M can be encoded by an LTL formula ϕδ that arises through
a conjunction of formulae ϕq,A describing the semantics of δ(q, A). Here, q ranges over all
states in Q and A over the tape-symbols in Σ. For instance, if δ(q, A) = (p, B, L) then
ϕq,A = □

1⩽i⩽P (n)

⃝2i−1(q, A, i) −→ψ(q,A,i,p,B,L)


Automata-Based LTL Model Checking
293
where ψ(q,A,i,p,B,L) is deﬁned as

1⩽j⩽P (n)
j̸=i,C∈Σ
(⃝2j−1C ↔⃝2j−1+2P (n)+1C



content of all cells j ̸= i unchanged
) ∧⃝2i−1+2P (n)+1B



overwrite A by B in cell i
∧⃝2i−1+2P (n)+1−2 p



move to state p
and cursor to cell i−1
.
Here, C denotes the disjunction of the atoms (r, C, j) where r ∈Q∪{ ∗} and 1 ⩽j ⩽P(n),
and p for the disjunction of all atoms (p, D, j) where D ∈Σ and 1 ⩽j ⩽P(n).
The starting conﬁguration of M for a given input word w = A1 . . . An ∈Σ∗is given by
the formula
ϕw
start = ⃝q0 ∧

1⩽i⩽n
⃝2i−1Ai ∧

n<i⩽P (n)
⃝2i−1 ⊔.
The ﬁrst conjunct ⃝q0 asserts that M starts in its starting state; the other conjuncts
assert that A1 . . . An⊔P (n)−n is the content of the tape where ⊔denotes the blank symbol.
The accepting conﬁgurations are formalized by the formula
ϕaccept = ♦
!
q∈F
q.
For a given input word w = A1 . . . An of length n for M, let
ϕw = ϕw
start ∧ϕConf ∧ϕδ ∧ϕaccept.
Note that the length of ϕw is polynomial in the size of M and the length n of w. Thus,
TS = TS(M, n) and ϕw can be constructed from (M, w) in polynomial time. Moreover,
it also follows that there exists a path π |= ϕw in TS if and only if M accepts the input
word w.
For real applications, the aforementioned theoretical complexity result is less dramatic
than it seems at ﬁrst sight, since the complexity is linear in the size of the transition
system and exponential in formula length. In practice, typical requirement speciﬁcations
yield short LTL formulae. In fact, the exponential growth in the length of the formula
is not decisive for the practical application of LTL model checking. Instead, the linear
dependency on the size of the transition system is the critical factor. As has been discussed
at the end of Chapter 2 (page 77), the size of transition systems may be huge even
for relatively simple systems—the state-space explosion problem.
In later chapters of
this monograph, various techniques will be treated to combat this state-space explosion
problem.
We mentioned before that the LTL model-checking problem is PSPACE-complete. The
previous result showed PSPACE-hardness.
It remains to show that it belongs to the
complexity class PSPACE.

294
Linear Temporal Logic
To prove that the LTL model-checking problem is in PSPACE, we resort (again) to the
existential variant of the LTL model-checking problem. This is justiﬁed by the fact that
PSPACE – as any other deterministic complexity class – is closed under complementation.
That is, the LTL model-checking problem is in PSPACE iﬀits complement is in PSPACE.
This is equivalent to the statement that the existential variant of the LTL model-checking
problem is solvable by a polynomial space-bounded algorithm.
By Savitch’s theorem
(PSPACE agrees with NPSPACE), it suﬃces to provide a nondeterministic polynomial
space-bounded algorithm that solves the existential LTL model-checking problem.
Lemma 5.47.
The existential LTL model-checking problem is solvable by a nondeterministic space-boun-
ded algorithm.
Proof: In the sequel, let ϕ be an LTL formula and TS = (S, Act, →, I, AP, L) a ﬁnite
transition system. The goal is to check nondeterministically whether TS has a path π
with π |= ϕ, while the memory requirements are bounded by O( poly(size(TS), |ϕ|) ). The
techniques discussed in Section 5.2 (page 270 ﬀ) suggest to build an NBA Aϕ for ϕ,
construct the product transition system TS⊗Aϕ and check whether this product contains
a reachable cycle containing an accept state of Aϕ.
We now modify this approach to
obtain an NPSPACE algorithm. Instead of an NBA for ϕ, we deal here with the GNBA
Gϕ for ϕ. Recall that states in this automaton are elementary subsets of the closure of ϕ
(see Deﬁnition 5.34 on page 276). The goal is to guess nondeterministically a ﬁnite path
u0 u1 . . . un−1 v0 v1 . . . vm−1 in TS ⊗Gϕ and to check whether the components of Gϕ in
the inﬁnite path
u0 u1 . . . un−1 (v0 v1 . . . vm−1)ω
constitute an accepting run in Gϕ. This, of course, requires that v0 is a successor of vm−1.
The states ui, vj in the inﬁnite path in TS ⊗Gϕ are pairs consisting of a state in TS
and an elementary set of formulae. For the lengths of the preﬁx u0 . . . un−1 and the cycle
v0 v1 . . . vm−1 vm we can deal with n ⩽k and m ⩽k·|ϕ| where k is the number of reachable
states in TS ⊗Gϕ. (Note that |ϕ| is an upper bound for the number of acceptance sets in
Gvarphi.) An upper bound for the value k is given by
K = NTS · 2Nϕ
where NTS denotes the number of states in TS and Nϕ = |closure(ϕ)|. Note that
K = O( size(TS) · exp(|ϕ|) ).
The algorithm now works as follows. We ﬁrst nondeterministically choose two natural
numbers n, m with n ⩽K and m ⩽K · |ϕ| (by guessing ⌈log K⌉= O(log(size(TS)) · |ϕ|)

Automata-Based LTL Model Checking
295
bits for n and ⌈log K⌉+⌈log |ϕ|⌉= O(log(size(TS)) · |ϕ|) bits for m). Then the algorithm
guesses nondeterministically a sequence u0 . . . un−1, un . . . un+m where the ui’s are pairs
⟨si, Bi⟩consisting of a state si in TS and a subset Bi of closure(ϕ). For each such state
ui = ⟨si, Bi⟩, the algorithm checks whether
1. si is a successor of si−1, provided that i ⩾1,
2. Bi is elementary,
3. Bi ∩AP = L(si),
4. Bi ∈δ(Bi−1, L(si)), provided that i ⩾1.
For i = 0, the algorithm checks whether s0 ∈I is an initial state of TS and whether B0 ∈
δ(B, L(s0)) for some elementary set B which contains ϕ. Here, δ denotes the transition
relation of the GNBA Gϕ. (Recall that the sets B where ϕ ∈B are the initial states in
the GNBA for ϕ.) Conditions 1-4 are local and simple to check. If one of these four
conditions is violated for some i, the algorithm rejects and halts. Otherwise u0 . . . un+m
is a ﬁnite path in TS ⊗Gϕ.
We ﬁnally check whether un agrees with the last state
un+m. Again, the algorithm rejects and halts if this condition does not hold. Otherwise,
u0 . . . un−1(un . . . un+m−1)ω is an inﬁnite path in TS ⊗Gϕ, and it ﬁnally amounts to check
whether the acceptance condition of Gϕ is fulﬁlled. This means we have to verify that
whenever ψ1 U ψ2 ∈Bi for some i ∈{n, . . . , n + m −1}, then there is some j ∈{n, . . . , n +
m −1} such that ψ2 ∈Bj. If this condition holds, then the algorithm terminates with the
answer “yes”.
This algorithm is correct since if TS has a path where ϕ holds, then there is a computation
of the above algorithm that returns “yes”. Otherwise, i.e., if TS does not have a path
where ϕ holds, then all computations of the algorithm are rejecting.
It remains to explain how the sketched algorithm can be realized such that the memory
requirements are polynomial in the size of TS and length of ϕ. Although the length n+m
of the path u0 . . . un+m might be exponentially in the length of ϕ (note that, e.g., n = K
is possible and that K grows exponentially in the length of ϕ), this procedure can be
realized with only polynomial space requirements. This is due to the observation that for
checking the above conditions 1-4 for ui = ⟨si, Bi⟩, we only need state ui−1 = ⟨si−1, Bi−1⟩.
Thus, there is no need to store all states uj for 0 ⩽j ⩽n + m. Instead, the actual and
previous states are suﬃcient. Moreover, to verify that Gϕ’s acceptance condition holds,
we only need to remember the subformulae ψ1 U ψ2 of ϕ that are contained in some of the
sets Bn, . . . Bn+m−1, and the subformulae ψ2 that appear on the right hand side of an until
subformula of ϕ and are contained in some of the sets Bn, . . . Bn+m−1. This additional

296
Linear Temporal Logic
information requires O(|ϕ|) space. Thus, the above nondeterministic algorithm can be
realized in a polynomially space-bounded way.
By Lemma 5.47 and Theorem 5.46 we get:
Theorem 5.48.
The LTL model-checking problem is PSPACE-complete.
5.2.2
LTL Satisﬁability and Validity Checking
The last section of this chapter considers the satisﬁability problem and the validity problem
for LTL. The satisﬁability problem is: for a given LTL formula ϕ, does there exist a model
for which ϕ holds? That is, do we have Words(ϕ) ̸= ∅? Satisﬁability can be solved by
constructing an NBA Aϕ for LTL formula ϕ. In this way, the existence of an inﬁnite word
σ ∈Words(ϕ) = Lω(Aϕ) can be established. The emptiness problem for NBA A , i.e.,
whether Lω(A) = ∅or not, can be solved by means of a technique similar to persistence
checking, see Algorithm 12. In addition to an aﬃrmative response, a preﬁx of a word
σ ∈Lω(A) = Words(ϕ) can be provided similar to a counterexample for model checking
LTL.
Algorithm 12 Satisﬁability checking for LTL
Input: LTL formula ϕ over AP
Output: “yes” if ϕ is satisﬁable. Otherwise “no”.
Construct an NBA A = (Q, 2AP, δ, Q0, F) with Lω(A) = Words(ϕ)
(* Check whether Lω(A) = ∅. *)
Perform a nested DFS to determine whether there exists a state q ∈F reachable from
q0 ∈Q0 and that lies on a cycle
If so, then return “yes”. Otherwise, “no”.
Given that satisﬁability for LTL can be tackled using similar techniques as for model
checking LTL, let us now consider the validity problem. Formula ϕ is valid whenever ϕ
holds under all interpretations, i.e., ϕ ≡true. For LTL formula ϕ over AP we have ϕ is
valid if and only if Words(ϕ) = (2AP)ω. The validity of ϕ can be established by using the

Automata-Based LTL Model Checking
297
observation that ϕ is valid if and only if ¬ϕ is not satisﬁable. Hence, to algorithmically
check whether ϕ is obtained, one constructs an NBA for ¬ϕ and applies the satisﬁablity
algorithm (see Algorithm 12) to ¬ϕ.
The outlined LTL satisﬁability algorithm has a runtime that is exponential in the length
of ϕ. The following result shows that an essentially more eﬃcient technique cannot be
achieved as both the validity and satisﬁability problems are PSPACE-hard. In fact, both
problems are even PSPACE-complete. Membership to PSPACE for the LTL satisﬁability
problem can be shown by providing a nondeterministic polynomially space-bounded algo-
rithm that guesses a ﬁnite run in the GNBA Gϕ for the given formula ϕ and checks whether
this ﬁnite run is a preﬁx of an accepting run in Gϕ. The details are skipped here since
they are very similar to the algorithm we provided for the existential LTL model checking
problem (see Lemma 5.47 on page 294). The fact that the LTL validity problem belongs
to PSPACE can be derived from the observations that ϕ is valid iﬀ¬ϕ is not satisﬁable
and that PSPACE is closed under complementation. We now focus on the proof for the
PSPACE-hardness.
Theorem 5.49.
LTL Satisﬁability and Validity (Lower Bound)
The satisﬁability and validity problems for LTL are PSPACE-hard.
Proof: Since satisﬁability and validity are complementary in the sense that ϕ is satisﬁable
if and only if ¬ϕ is not valid, and vice versa, it suﬃces to show the PSPACE-hardness
of the satisﬁability problem. This is done by providing a polynomial reduction from the
existential variant of the LTL model-checking problem (see the proof of Theorem 5.46 on
page 290) to the satisﬁability problem for LTL.
Let TS = (S, Act, →, I, AP, L) be a ﬁnite transition system and ϕ an LTL formula over
AP. The goal is to construct an LTL formula ψ such that ψ is satisﬁable if and only if
there is a path π in TS with π |= ϕ. Besides, ψ should be constructed in polynomial time.
The atomic propositions in ψ are elements in AP′ = AP ⊎S. For any state s ∈S let
Φs =

a∈L(s)
a ∧

a/∈L(s)
¬a.
The formula Φs can be viewed as a characteristic formula for the labeling of s, since
s′ |= Φs if and only if L(s) = L(s′), for any s′ ∈S. However, for the LTL satisﬁability
problem, there is no ﬁxed transition system and Φs can hold also for other states (in
another transition system). For s ∈S and T ⊆S, let ΨT = "
t∈T t be the characteristic
formula for the set T. Let
ψs = s →(Φs ∧⃝ΨP ost(s))

298
Linear Temporal Logic
assert that in state s, the labels L(s) hold, and that transitions exist to any of its immediate
successors Post(s). Let
Ξ =
!
s∈S
(s ∧

t∈S\{ s }
¬t).
Stated in words, Ξ asserts that exactly one of the atomic propositions s ∈AP′ holds.
These deﬁnitions constitute the ingredients for the deﬁnition of ψ. For set I of initial
states, let
ψ = ΨI ∧□Ξ ∧□ΨS ∧

s∈S
□ψs ∧ϕ.
It follows directly that ψ can be derived from TS and ϕ in polynomial time. It remains
to show that
∃π ∈Paths(TS). π |= ϕ
if and only if
ψ is satisﬁable.
⇒: Let π = s0 s1 s2 . . . be an initial, inﬁnite path in TS with π |= ϕ. Now consider π as
a path in the transition system TS′ that agrees with TS but uses the extended labeling
function L′(s) = L(s) ∪{ s }. Then, π |= ΨI, since s0 ∈I. In addition, π |= □Ξ and
π |= □ψs since Ξ and ψs hold in all states of TS′. Thus, π |= ψ. Hence, π is a witness for
the satisﬁability of ψ.
⇐: Assume ψ is satisﬁable. Let A0 A1 A2 . . . be an inﬁnite word over the alphabet 2AP′
with A0 A1 A2 . . . ∈Words(ψ). Since
A0 A1 A2 . . . |= □Ξ
there is a unique state sequence π = s0 s1 s2 . . . in TS with si ∈Ai for all i ⩾0. Since
A0 A1 A2 . . . |= ΨI, we get s0 ∈I. As
A0 A1 A2 . . . |= □

s∈S
ψs,
we have Ai ∩AP = L(si) and si+1 ∈Post(si) for all i ⩾0. This yields that π is a path in
TS and π |= ϕ.
5.3
Summary
• Linear Temporal Logic (LTL) is a logic for formalizing path-based properties.
• LTL formulae can be transformed algorithmically into nondeterministic B¨uchi au-
tomata (NBA). This transformation can cause an exponential blowup.

Bibliographic Notes
299
• The presented algorithm for the construction of an NBA for a given LTL formula
ϕ relies on ﬁrst constructing a GNBA for ϕ, which is then transformed into an
equivalent NBA.
• The GNBA for ϕ encodes the semantics of propositional logic and the semantics of
the next-step operator in its transitions. Based on the expansion law, the meaning
of until is split into local requirements (encoded by the states of a GNBA), next-step
requirements (encoded by the transitions of the GNBA), and a fairness condition
(encoded by the acceptance sets of the GNBA).
• LTL formulae describe ω-regular LT properties, but do not have the same expres-
siveness as ω-regular languages.
• The LTL model-checking problem can be solved by a nested depth-ﬁrst search in the
product of the given transition system and an NBA for the negated formula.
• The time complexity of the automata-based model-checking algorithm for LTL is
linear in the size of the transition system and exponential in the length of the formula.
• Fairness assumptions can be described by LTL formulae. The model-checking prob-
lem for LTL with fairness assumptions is reducible to the standard LTL model-
checking problem.
• The LTL model-checking problem is PSPACE-complete.
• Satisﬁability and validity of LTL formulae can be solved via checking emptiness
of nondeterministic B¨uchi automata. The emptiness check can be determined by a
nested DFS that checks the existence of a reachable cycle containing an accept state.
Both problems are PSPACE-complete.
5.4
Bibliographic Notes
Linear temporal logic.
Based on prior work on modal logics and temporal modalities
[270, 345, 244, 230], Pnueli introduced (linear) temporal logics for reasoning about re-
active systems in the late seventies in his seminal paper [337]. Since then, a variety of
variants and extensions of LTL have been investigated, such as Lamport’s Temporal Logic
of Actions (TLA) [260] and LTL with past operators [159, 274, 262]. LTL forms the basis
for the recently standardized industrial property speciﬁcation language PSL [136]. The
past extension of LTL does not change the expressiveness of LTL, but can be helpful for
speciﬁcation convenience and modular reasoning. For several properties, the use of past
operators may lead to (exponentially) more succinct formulae than in ordinary LTL. To

300
Linear Temporal Logic
cover the full class of ω-regular LT properties, Vardi and Wolper introduced an extension
of LTL by automata formulae [424, 425, 411, 412].
LTL model checking. Vardi and Wolper also developed the automata-based model checking
algorithm for LTL presented in this chapter. The presented algorithm to construct an NBA
from a given LTL formula is, in our opinion, the simplest and most intuitive one. In the
meantime, various alternative techniques have been developed that generate more compact
NBAs or that attempt to minimize a given NBA, see e.g. [166, 110, 148, 375, 162, 149,
167, 157, 389, 369]. Alternative LTL model-checking algorithms that do not use B¨uchi
automata, but a so-called tableau for the LTL formula, were presented by Lichtenstein and
Pnueli [273] and Clarke, Grumberg, and Hamaguchi [88]. The results about the complexity
of LTL model checking and the satisﬁability problem are due to Sistla and Clarke [372].
There is a variety of surveys and textbooks; see, e.g.,[245, 138, 173, 283, 158, 284, 92, 219,
379, 365], where several other aspects of LTL and related logics, such as deductive proof
systems, alternative model-checking algorithms, or more details about the expressiveness,
are treated.
Examples. The garbage collection algorithm presented in Example 5.31 is due to Ben-Ari
[41]. Several leader election protocols that ﬁt into the shape of Example 5.13 have been
suggested; see, e.g., [280].
LTL model checkers.
SPIN is the most well-known LTL model checker and has been
developed by Holzmann [209]. Transition systems are described in the modeling language
Promela, and LTL formulae are checked using the algorithm advocated by Gerth et al.
[166]. LTL model checking using a tableau construction is supported by NuSMV [83].
5.5
Exercises
Exercise 5.1. Consider the following transition system over the set of atomic propositions { a, b }:
s2
{ a }
s1
{ a }
s3
{ a, b }
s4
{ b }
Indicate for each of the following LTL formulae the set of states for which these formulae are

Exercises
301
fulﬁlled:
(a) ⃝a
(b) ⃝⃝⃝a
(c) □b
(d) □♦a
(e) □(b U a)
(f) ♦(a U b)
Exercise 5.2.
Consider the transition system TS over the set of atomic propositions AP =
{ a, b, c }:
s1
{a}
s3
{b, c}
s2
{c}
s5
{a, b, c}
s4
{b}
Decide for each of the LTL formulae ϕi below, whether T S |= ϕi holds. Justify your answers! If
TS ̸|= ϕi, provide a path π ∈Paths(TS) such that π ̸|= ϕi.
ϕ1
= ♦□c
ϕ2
= □♦c
ϕ3
= ⃝¬c →⃝⃝c
ϕ4
= □a
ϕ5
= a U □(b ∨c)
ϕ6
= (⃝⃝b) U (b ∨c)
Exercise 5.3.
Consider the sequential circuit in Figure 5.24 and let AP = { x, y, r1, r2 }. Provide
LTL formulae for the following properties:
r_1,r_2
x
y
Figure 5.24: Circuit for Exercise 5.3.

302
Linear Temporal Logic
(a) “It is impossible that the circuit outputs two successive 1s.”
(b) “Whenever the input bit is 1, in at most two steps the output bit will be 1.”
(c) “Whenever the input bit is 1, the register bits do not change in the next step.”
(d) “Register r1 has inﬁnitely often the value 1.”
Determine which of these properties are satisﬁed for the initial register evaluation where r1 = 0
and r2 = 0? Justify your answers.
Exercise 5.4.
Suppose we have two users, Peter and Betsy, and a single printer device Printer.
Both users perform several tasks, and every now and then they want to print their results on the
Printer. Since there is only a single printer, only one user can print a job at a time. Suppose we
have the following atomic propositions for Peter at our disposal:
• Peter.request ::= indicates that Peter requests usage of the printer;
• Peter.use ::= indicates that Peter uses the printer;
• Peter.release ::= indicates that Peter releases the printer.
For Betsy, similar predicates are deﬁned. Specify in LTL the following properties:
(a) Mutual exclusion, i.e., only one user at a time can use the printer.
(b) Finite time of usage, i.e., a user can print only for a ﬁnite amount of time.
(c) Absence of individual starvation, i.e., if a user wants to print something, he/she eventually
is able to do so.
(d) Absence of blocking, i.e., a user can always request to use the printer
(e) Alternating access, i.e., users must strictly alternate in printing.
Exercise 5.5.
Consider an elevator system that services N > 0 ﬂoors numbered 0 through
N−1. There is an elevator door at each ﬂoor with a call-button and an indicator light that signals
whether or not the elevator has been called. For simplicity consider N = 4. Present a set of
atomic propositions – try to minimize the number of propositions – that are needed to describe
the following properties of the elevator system as LTL formulae and give the corresponding LTL
formulae:
(a) The doors are “safe”, i.e., a ﬂoor door is never open if the elevator is not present at the given
ﬂoor.
(b) A requested ﬂoor will be served sometime.

Exercises
303
(c) Again and again the elevator returns to ﬂoor 0.
(d) When the top ﬂoor is requested, the elevator serves it immediately and does not stop on the
way there.
Exercise 5.6.
Which of the following equivalences are correct? Prove the equivalence or provide
a counterexample that illustrates that the formula on the left and the formula on the right are not
equivalent.
(a) □ϕ →♦ψ
≡
ϕ U (ψ ∨¬ϕ)
(b) ♦□ϕ →□♦ψ
≡
□

ϕ U (ψ ∨¬ϕ)

(c) □□(ϕ ∨¬ψ) ≡¬♦(¬ϕ ∧ψ)
(d) ♦(ϕ ∧ψ) ≡♦ϕ ∧♦ψ
(e) □ϕ ∧⃝♦ϕ ≡□ϕ
(f) ♦ϕ ∧⃝□ϕ ≡♦ϕ
(g) □♦ϕ →□♦ψ ≡□

ϕ →♦ψ

(h) ¬(ϕ1 U ϕ2) ≡¬ϕ2 W (¬ϕ1 ∧¬ϕ2)
(i) ⃝♦ϕ1 ≡♦⃝ϕ2
(j) (♦□ϕ1) ∧(♦□ϕ2) ≡♦(□ϕ1 ∧□ϕ2)
(k) (ϕ1 U ϕ2) U ϕ2 ≡ϕ1 U ϕ2
Exercise 5.7.
Let ϕ and ψ be LTL formulae. Consider the following new operators:
(a) “At next” ϕ N ψ: at the next time where ψ holds, ϕ also holds.
(b) “While” ϕ W ψ: ϕ holds as least as long as ψ does.
(c) “Before” ϕ B ψ: if ψ holds sometime, ϕ does so before.
Make the deﬁnitions of these informally explained operators precise by providing LTL formulae
that formalize their intuitive meanings.
Exercise 5.8.
We consider the release operator R which was deﬁned by ϕ R ψ
def
= ¬(¬ϕ U ¬ψ);
see Section 5.1.5 on page 252 ﬀ.
(a) Prove the expansion law ϕ1 R ϕ2 ≡ϕ2 ∧(ϕ1 ∨⃝(ϕ1 ∧ϕ2)).

304
Linear Temporal Logic
(b) Prove that ϕ R ψ ≡(¬ϕ ∧ψ) W (ϕ ∧ψ).
(c) Prove that ϕ1 W ϕ2 ≡(¬ϕ1 ∨ϕ2) R (ϕ1 ∨ϕ2).
(d) Prove that ϕ1 U ϕ2 ≡¬(¬ϕ1 R ¬ϕ2).
Exercise 5.9.
Consider the LTL formula
ϕ
=
¬

(□a) →

(a ∧¬c) U ¬(⃝b)

∧¬(¬a ∨⃝♦c).
Transform ϕ into an equivalent LTL formula in PNF
(a) using the weak-until operator W ,
(b) using the release operator R .
Exercise 5.10.
Provide an example for a sequence (ϕn) of LTL formulae such that the LTL
formula ψn is in weak-until PNF, ϕn ≡ψn, and ψn is exponentially longer than ϕn. Use the
transformation rules in Section 5.1.5
{ a, b }
s0
{ b }
s1
{ a }
s2
{ a, b }
s3
{ b }
s4
∅
s5
Figure 5.25: Transition system for Exercise 5.11.
Exercise 5.11.
Consider the transition system TS in Figure 5.25 with the set AP = { a, b, c } of
atomic propositions. Note that this is a single transition system with two initial states. Consider
the LTL fairness assumption
fair =

□♦(a ∧b) →□♦¬c

∧

♦□(a ∧b) →□♦¬b

.
Questions:
(a) Determine the fair paths in TS, i.e., the initial, inﬁnite paths satisfying fair
(b) For each of the following LTL formulae:
ϕ1
=
♦□a
ϕ2
=
⃝¬a −→♦□a
ϕ3
=
□a
ϕ4
=
b U □¬b
ϕ5
=
b W □¬b
ϕ6
=
⃝⃝b U □¬b

Exercises
305
determine whether TS |=fair ϕi. In case TS ̸|=fair ϕi, indicate a path π ∈Paths(TS) for
which π ̸|= ϕi.
Exercise 5.12.
Let ϕ = (a →⃝¬b) W (a ∧b) and P = Words(ϕ) where AP = { a, b }.
(a) Show that P is a safety property.
(b) Deﬁne an NFA A with L(A) = BadPref(P).
(c) Now consider P ′ = Words

(a →⃝¬b) U (a∧b)

. Decompose P ′ into a safety property Psafe
and a liveness property Plive such that
P ′ = Psafe ∩Plive.
Show that Psafe is a safety and that Plive is a liveness property.
s0
{ a, b }
s2
{ a }
s1
∅
s3
{ a }
Figure 5.26: Transition system for Exercise 5.14.
Exercise 5.13.
Provide an NBA for each of the following LTL formulae:
□(a ∨¬ ⃝b)
and
♦a ∨□♦(a ↔b)
and
⃝⃝(a ∨♦□b).
Exercise 5.14.
Consider the transition system TS in Figure 5.26 with the atomic propositions
{ a, b }. Sketch the main steps of the LTL model-checking algorithm applied to TS and the LTL
formulae
ϕ1 = □♦a →□♦b
and
ϕ2 = ♦(a ∧⃝a).
To that end, carry out the following steps:
(a) Depict an NBA Ai for ¬ϕi.
(b) Depict the reachable fragment of the product transition system TS ⊗Ai.
(c) Explain the main steps of the nested DFS in TS ⊗Ai by illustrating the order in which the
states are visited during the “outer” and “inner” DFS.

306
Linear Temporal Logic
q0
q1
q2
q3
true
a
a ∧b
a ∧b
true
¬a
a ∧b
a
Figure 5.27: GNBA for Exercise 5.15.
(d) If TS ̸|= ϕi, provide the counterexample resulting from the nested DFS.
Exercise 5.15.
Consider the GNBA G in Figure 5.27 with the alphabet Σ = 2{ a,b } and the set
F =

{ q1, q3 }, { q2 }

of accepting sets.
(a) Provide an LTL formula ϕ with Words(ϕ) = Lω(G). Justify your answer.
(b) Depict the NBA A with Lω(A) = Lω(G).
Exercise 5.16.
Depict a GNBA G over the alphabet Σ = 2{ a,b,c } such that
Lω(G) = Words

(□♦a →□♦b) ∧¬a ∧(¬a W c)

.
Exercise 5.17.
Let ψ = □(a ↔⃝¬a) and AP = { a }.
(a) Show that ψ can be transformed into the following equivalent basic LTL formula
ϕ = ¬
#
true U

¬ (a ∧⃝¬a) ∧¬ (¬a ∧¬ ⃝¬a)
$
.
The basic LTL syntax is given by the following context-free grammar:
ϕ ::= true | a | ϕ1 ∧ϕ2 | ¬ϕ | ⃝ϕ | ϕ1 U ϕ2.
(b) Compute all elementary sets with respect to closure(ϕ) (Hint: There are six elementary
sets.)
(c) Construct the GNBA Gϕ with Lω(Gϕ) = Words(ϕ). To that end:
(i) Deﬁne its set of initial states and its acceptance component.
(ii) For each elementary set B, deﬁne δ(B, B ∩AP).
Exercise 5.18.
Let AP = { a } and ϕ = (a ∧⃝a) U ¬a an LTL formula over AP.

Exercises
307
(a) Compute all elementary sets with respect to ϕ.
(Hint: There are ﬁve elementary sets.).
(b) Construct the GNBA Gϕ such that Lω(Gϕ) = Words(ϕ).
Exercise 5.19.
Consider the formula ϕ
=
a U (¬a ∧b) and let G be the GNBA for ϕ that
is obtained through the construction explained in the proof of Theorem 4.56.
What are the
initial states in G?
What are the accept states in G?
Provide an accepting run for the word
{a}{a}{a, b}{b}ω. Explain why there are no accepting runs for the words {a}ω and {a}{a}{a, b}ω.
(Hint: The answers to these questions can be given without depicting G.)
Exercise 5.20.
We consider the LTL formula ϕ = □(a →(¬b U (a ∧b))) over the set
AP = { a, b } of atomic propositions and we want to check TS |= ϕ
for TS outlined on the right.
(a) To check TS |= ϕ, convert ¬ϕ into an equivalent LTL formula
ψ which is constructed according to the following grammar:
Φ ::= true | false | a | b | Φ ∧Φ | ¬Φ | ⃝Φ | Φ U Φ.
Then construct closure(ψ).
s0
∅
{ b }
s1
s3
{ a }
s2
{ a, b }
(b) Give the elementary sets w.r.t. closure(ψ)!
(c) Construct the GNBA Gψ.
(d) Construct an NBA A¬ϕ directly from ¬ϕ, i.e., without relying on Gψ. (Hint: Four states
suﬃce.)
(e) Construct TS ⊗A¬ϕ.
(f) Use the nested DFS algorithm to check TS |= ϕ. Therefore, sketch the algorithm’s main
steps and interpret its outcome!
Exercise 5.21.
The construction of a G from a given LTL formula in the proof of Theorem
4.56 assumes an LTL formula that only uses the basic temporal modalities ⃝and U .
The
derived operators ♦, □, W and R can be treated by syntactic replacements of their deﬁnitions.
Alternatively, and more eﬃcient, is to treat them as basic modalities and to allow for formulae ♦ψ,
□ψ, ϕ1 W ϕ2 and ϕ1 R ϕ2 as elements of elementary sets of formulae and redeﬁne the components
of the constructed GNBA.
Explain which modiﬁcations are necessary for such a ”direct” treatment of ♦(eventually), □
(always), W (weak-until), and R (release). That is, which additional conditions do the elementary
sets, the transition function δ, and the set F of accepting sets have to fulﬁll?

308
Linear Temporal Logic
Exercise 5.22.
Let TS = (S, Act, →, S0, AP, L) be a ﬁnite transition system without terminal
states and let wfair = ♦□b1 →□♦b2 be a weak LTL fairness assumption with b1, b2 ∈AP. Explain
how the nested DFS can be modiﬁed to check directly whether TS |=wfair ♦□a (where a ∈AP),
that is, without using the transformation TS |=wfair ♦□a iﬀTS |= (wfair →♦□a).
Exercise 5.23.
Which of the following LTL formulae ϕi are representable by a deterministic
B¨uchi automaton?
ϕ1 = □(a →♦b),
ϕ2 = ¬ϕ1.
Explain your answer.
Exercise 5.24.
Check for the following LTL formula whether they are (i) satisﬁable, and/or (ii)
valid:
(a) ⃝⃝a ⇒⃝a
(b) ⃝(a ∨♦a) ⇒♦a
(c) □a ⇒¬ ⃝( ¬ a ∧□¬ a)
(d) (□a) U (♦b) ⇒□(a U ♦b)
(e) ♦b ⇒(a U b)
Practical Exercises
Exercise 5.25.
Consider an arbitrary, but ﬁnite, number of identical processes2, that execute in
parallel. Each process consists of a noncritical part and a critical part, usually called the critical
section. In this exercise we are concerned with the veriﬁcation of a mutual exclusion protocol, that
is, a protocol that should ensure that at any moment of time at most one process (among the N
processes in our conﬁguration) is in its critical section. There are many diﬀerent mutual exclusion
protocols developed in the literature. In this exercise we are concerned with Szymanski’s protocol
[384]. Assume there are N processes for some ﬁxed N > 0. There is a global variable, referred to
as ﬂag, which is an array of length N, such that ﬂag[i] is a value between 0 and 4 (for 0 ⩽i < N).
The idea is that ﬂag[i] indicates the status of process i. The protocol executed by process i looks
as follows:
l0: loop forever do
begin
l1: Noncritical section
l2: ﬂag[i] := 1;
2Only the identity of a process is unique.

Exercises
309
l3: wait until (ﬂag[0] < 3 and ﬂag[1] < 3 and . . . and ﬂag[N-1] < 3)
l4: ﬂag[i] := 3;
l5: if (ﬂag[0] = 1 or ﬂag[1] = 1 or . . . or ﬂag[N-1] = 1)
then begin
l6: ﬂag[i] := 2;
l7: wait until (ﬂag[0] = 4 or ﬂag[1] = 4 or . . . or ﬂag[N-1] = 4)
end
l8: ﬂag[i] := 4;
l9: wait until (ﬂag[0] < 2 and ﬂag[1] < 2 and . . . and ﬂag[i-1] < 2)
l10: Critical section
l11: wait until (ﬂag[i+1] ∈{ 0, 1, 4 }) and . . . and (ﬂag[N-1] ∈{ 0, 1, 4 })
l12: ﬂag[i] := 0;
end.
Before doing any of the exercises listed below, try ﬁrst to informally understand what the protocol
is doing and why it could be correct in the sense that mutual exclusion is ensured. If you are
convinced of the fact that the correctness of this protocol is not easy to see — otherwise please
inform me — then start with the following questions.
1. Model Szymanski’s protocol in Promela. Assume that all tests on the global variable ﬂag
(such as the one in statement l3) are atomic. Look carefully at the indices of the variable ﬂag
used in the tests. Make the protocol description modular such that the number of processes
can be changed easily.
2. Check for several values of N (N ⩾2) that the protocol indeed ensures mutual exclusion.
Report your results for N equal to 4.
3. The code that a process has to go through before reaching the critical section can be divided
into several segments. We refer to statement l4 as the doorway, to segments l5, l6, and l7, as
the waiting room and to segments l8 through l12 (which contains the critical section) as the
inner sanctum. You are requested to check the following basic claims using assertions. Give
for each case the changes to your original Promela speciﬁcation for Szymanski’s protocol
and present the veriﬁcation results. In case of negative results, simulate the counterexample
by means of guided simulation.
(a) Whenever some process is in the inner sanctum, the doorway is locked, that is, no
process is at location l4.
(b) If a process i is at l10, l11 or l12, then it has the least index of all the processes in the
waiting room and the inner sanctum.
(c) If some process is at l12, then all processes in the waiting room and in the inner sanctum
must have ﬂag value 4.
Exercise 5.26.
We assume N processes in a ring topology, connected by unbounded queues.
A process can only send messages in a clockwise manner. Initially, each process has a unique
identiﬁer ident (which is assumed to be a natural number). A process can be either active or

310
Linear Temporal Logic
relaying. Initially a process is active. In Peterson’s leader election algorithm (1982) each process
in the ring carries out the following task:
active:
d := ident;
do forever
begin
/* start phase */
send(d);
receive(e);
if e = ident then announce elected;
if d > e then send(d) else send(e);
receive(f);
if f = ident then announce elected;
if e ⩾max(d, f) then d := e else goto relay;
end
relay:
do forever
begin
receive(d);
if d = ident then announce elected;
send(d)
end
Solve the following questions concerning the leader election protocol:
1. Model Peterson’s leader election protocol in Promela (avoid invalid end states).
2. Verify the following properties:
(a) There is always at most one leader.
(b) Eventually always a leader will be elected.
(c) The elected leader will be the process with the highest number.
(d) The maximum total amount of messages sent in order to elect a leader is at most
2N⌊log2 N⌋+ N.
Exercise 5.27.
This exercise deals with a simple fault-tolerant communication protocol in which
processes can fail. A failed process is still able to communicate, i.e., it is able to send and receive
messages, but the content of its transmitted messages is unreliable. More precisely, a failed process
can send messages with arbitrary content. A failed process is therefore also called unreliable.
We are given N reliable processes (i.e., processes that have not failed and that are working as
expected) and K unreliable processes, where N is larger than 3·K and K is at least 0. There is no
way, a priori, to distinguish the reliable and the unreliable processes. All processes communicate

Exercises
311
by means of exchanging messages. Each process has a local variable, which initially has a value, 0
or 1. The following informally described protocol is aimed to be followed by the reliable processes,
such that at the end of round K+1 we have
• eventually every reliable process has the same value in its local variable, and
• if all reliable processes have the same initial value, then their ﬁnal value is the same as their
common initial value.
The diﬃculty of this protocol is to establish these constraints in the presence of the K unreliable
processes!
Informal description of the protocol
The following protocol is due to Berman and Garay
[47]. Let the processes be numbered 1 through N+K. Processes communicate with each other in
“rounds”. Each round consists of two phases of message transmissions: In round i, i > 0, in the
ﬁrst phase, every process sends its value to all processes (including itself); in the second phase,
process i sends the majority value it received in the ﬁrst phase (for majority to be well-deﬁned we
assume that N+K is odd) to all processes. If a process receives N, or more, instances of the same
value in its ﬁrst phase of the round, it sets its local variable to this value; otherwise, it sets its
local variable to the value received (from process i) in the second phase of this round.
1. Model this protocol in Promela. Make the protocol description modular such that the num-
ber of reliable and unreliable processes can be changed easily. As the state space of your
protocol model could be very large, instantiate your model with a single unreliable process
and four reliable processes.
First hint: One of the main causes for the large state space is the model for the unreliable
process, so try to keep this model as simple as possible. This can be achieved by, for in-
stance, assuming that an unreliable process can only transmit arbitrary 0 or 1 values (and
not any other value) and that a process always starts with a ﬁxed initial value (and not with
a randomly selected one). In addition, use atomic broadcast for message transmissions.
Second hint: It might be convenient (though not necessary) to use a matrix of size (N+K) ·
(N+K) of channels for the communication structure. As Promela does not support multi-
dimensional arrays, you could use the following construct (where M equals N+K):
typedef Arraychan {
chan ch[M] = [1] of {bit};
/* M channels of size 1 */
}
Arraychan A[M];
/* a matrix A of MxM channels of size 1 */
Statement A[i].ch[j]!0 denotes an output of value 0 over the channel directed process
from i to j. Similarly, statement A[i].ch[j]?b denotes the receipt of a bit value stored in
variable b via the channel directed from process i to j.
2. Formalize the two constraints of the protocol in LTL and convert these into never claims.

312
Linear Temporal Logic
3. Check the two temporal logic properties by Spin and hand in the veriﬁcation output gener-
ated by Spin.
4. Show that the requirement N > 3 · K is essential, by, for instance, changing the conﬁg-
uration of your system such that N ⩽3 · K and checking that for this conﬁguration the
ﬁrst aforementioned constraint is violated. Create the shortest counterexample (select the
shortest trail in the advanced veriﬁcation options) and perform a guided simulation of this
undesired scenario. Hand in the counterexample you found and give an explanation of it.

Chapter 6
Computation Tree Logic
This chapter introduces Computation Tree Logic (CTL), a prominent branching temporal
logic for specifying system properties. In particular, the syntax and semantics of CTL
are presented, a comparison to Linear Temporal Logic (LTL) is provided, and the issue
of fairness in CTL is treated. CTL model checking is explained in detail. First, the core
recursive algorithm is presented that is based on a bottom-up traversal of the parse tree of
the formula at hand. The foundations of this algorithm are discussed and the adaptations
needed to incorporate fairness are detailed.
This is followed by an algorithm for the
generation of counterexamples. The chapter is concluded by presenting a model-checking
algorithm for CTL∗, a branching-time logic that subsumes both LTL and CTL.
6.1
Introduction
Pnueli [337] has introduced linear temporal logic for the speciﬁcation and veriﬁcation of
reactive systems. LTL is called linear, because the qualitative notion of time is path-based
and viewed to be linear: at each moment of time there is only one possible successor state
and thus each time moment has a unique possible future. Technically speaking, this follows
from the fact that the interpretation of LTL formulae is deﬁned in terms of paths, i.e.,
sequences of states.
Paths themselves, though, are obtained from a transition system that might be branching:
a state may have several, distinct direct successor states, and thus several computations
may start in a state. The interpretation of LTL-formulae in a state requires that a formula
ϕ holds in state s if all possible computations that start in s satisfy ϕ. The universal
313

314
Computation Tree Logic
quantiﬁcation over all computations that is implicit in the LTL semantics can also be
made explicit in the formula, e.g.:
s |= ∀ϕ if and only if π |= ϕ for all paths π starting in s
In LTL, we thus can state properties over all possible computations that start in a state,
but not easily about some of such computations. To some extent this may be overcome
by exploiting the duality between universal and existential quantiﬁcation. For instance, to
check whether there exists some computation starting in s that satisﬁes ϕ we may check
whether s |= ∀¬ ϕ; if this formula is not satisﬁed by s, then there must be a computation
that meets ϕ, otherwise they should all refute ϕ.
For more complicated properties, like “for every computation it is always possible to return
to the initial state”, this is, however, not possible. A naive attempt would be to require
□♦start for every computation, i.e., s |= ∀□♦start, where the proposition start uniquely
identiﬁes the initial state. This is, however, too strong as it requires a computation to
always return to the initial state, not just possibly. Other attempts to specify the intended
property also fail, and it even turns out to be the case that the property cannot be speciﬁed
in LTL.
To overcome these problems, in the early eighties another strand of temporal logics for
speciﬁcation and veriﬁcation purposes was introduced by Clarke and Emerson [86]. The
semantics of this kind of temporal logic is not based on a linear notion of time—an inﬁnite
sequence of states—but on a branching notion of time—an inﬁnite tree of states. Branching
time refers to the fact that at each moment there may be several diﬀerent possible futures.
Each moment of time may thus split into several possible futures. Due to this branching
notion of time, this class of temporal logic is known as branching temporal logic. The
semantics of a branching temporal logic is deﬁned in terms of an inﬁnite, directed tree
of states rather than an inﬁnite sequence. Each traversal of the tree starting in its root
represents a single path. The tree itself thus represents all possible paths, and is directly
obtained from a transition system by “unfolding” at the state of interest. The tree rooted
at state s thus represents all possible inﬁnite computations in the transition system that
start in s. Figure 6.1 depicts a transition system and its unfolding. (For convenience, each
node in the tree consists of a pair indicating the state and the level of the node in the
tree.)
The temporal operators in branching temporal logic allow the expression of properties of
some or all computations that start in a state. To that end, it supports an existential
path quantiﬁer (denoted ∃) and a universal path quantiﬁer (denoted ∀). For instance, the
property ∃♦Φ denotes that there exists a computation along which ♦Φ holds. That is,
it states that there is at least one possible computation in which a state that satisﬁes Φ

Introduction
315
(s0, 0)
(s1, 1)
(s2, 2)
(s3, 2)
(s3, 3)
(s2, 3)
(s3, 3)
(s2, 4)
(s3, 4) (s3, 4)(s2, 4)
(s3, 4)
(b)
s0
s1
s2
s3
(a)
{ x = 0 }
{ x = 0 }
{ x ̸= 0 }
{ x = 1, x ̸= 0 }
Figure 6.1: (a) A transition system and (b) a preﬁx of its inﬁnite computation tree
is eventually reached. This does not, however, exclude the fact that there can also be
computations for which this property does not hold, for instance, computations for which
Φ is always refuted. The property ∀♦Φ, in contrast, states that all computations satisfy
the property ♦Φ.
More complicated properties can be expressed by nesting universal
and existential path quantiﬁers.
For instance, the aforementioned property “for every
computation it is always possible to return to the initial state” can be faithfully expressed
by ∀□∃♦start: in any state (□) of any possible computation (∀), there is a possibility (∃)
to eventually return to the start state (♦start).
This chapter considers Computation Tree Logic (CTL), a temporal logic based on proposi-
tional logic with a discrete notion of time, and only future modalities. CTL is an important
branching temporal logic that is suﬃciently expressive for the formulation of an impor-
tant set of system properties. It was originally used by Clarke and Emerson [86] and (in
a slightly diﬀerent form) by Queille and Sifakis [347] for model checking. More impor-
tantly, it is a logic for which eﬃcient and—as we will see—rather simple model-checking
algorithms do exist.
Anticipatory to the results presented in this chapter, we summarize the major aspects of
the linear-vs-branching-time debate and provide arguments that justify the treatment of
model checking based on linear or branching time logics:
• The expressiveness of many linear and branching temporal logics is incomparable.
This means that some properties that are expressible in a linear temporal logic
cannot be expressed in certain branching temporal logics, and vice versa.

316
Computation Tree Logic
Aspect
Linear time
Branching time
“behavior”
path-based:
state-based:
in a state s
trace(s)
computation tree of s
temporal
LTL: path formulae ϕ
CTL: state formulae
logic
s |= ϕ
iﬀ
existential path quantiﬁcation ∃ϕ
∀π ∈Paths(s). π |= ϕ
universal path quantiﬁcation: ∀ϕ
complexity of the
PSPACE–complete
PTIME
model checking
problems
O (|TS| · exp(|ϕ|))
O(|TS| · |Φ|)
implementation-
trace inclusion and the like
simulation and bisimulation
relation
(proof is PSPACE-complete)
(proof in polynomial time)
fairness
no special techniques needed
special techniques needed
Table 6.1: Linear-time vs. branching-time in a nutshell.
• The model-checking algorithms for linear and branching temporal logics are quite
diﬀerent. This results, for instance, in signiﬁcantly diﬀerent time and space com-
plexity results.
• The notion of fairness can be treated in linear temporal logic without the need for
any additional machinery since fairness assumptions can be expressed in the logic.
For various branching temporal logics this is not the case.
• The equivalences and preorders between transition systems that “correspond” to
linear temporal logic are based on traces, i.e., trace inclusion and equality, whereas
for branching temporal logic such relations are based on simulation and bisimulation
relations (see Chapter 7).
Table 6.1 summarizes the main diﬀerences between the linear-time and branching-time
perspective in a succinct way.

Computation Tree Logic
317
6.2
Computation Tree Logic
This section presents the syntax and the semantics of CTL. The following sections will
discuss the relation and diﬀerences between CTL and LTL, present a model-checking
algorithm for CTL, and introduce some extensions of CTL.
6.2.1
Syntax
CTL has a two-stage syntax where formulae in CTL are classiﬁed into state and path
formulae. The former are assertions about the atomic propositions in the states and their
branching structure, while path formulae express temporal properties of paths. Compared
to LTL formulae, path formulae in CTL are simpler: as in LTL they are built by the
next-step and until operators, but they must not be combined with Boolean connectives
and no nesting of temporal modalities is allowed.
Deﬁnition 6.1.
Syntax of CTL
CTL state formulae over the set AP of atomic proposition are formed according to the
following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   ∃ϕ
   ∀ϕ
where a ∈AP and ϕ is a path formula.
CTL path formulae are formed according to the
following grammar:
ϕ ::= ⃝Φ
   Φ1 U Φ2
where Φ, Φ1 and Φ2 are state formulae.
Greek capital letters will denote CTL state formulae (CTL formulae, for short), whereas
lowercase Greek letters will denote CTL path formulae.
CTL distinguishes between state formulae and path formulae. Intuitively, state formulae
express a property of a state, while path formulae express a property of a path, i.e., an
inﬁnite sequence of states. The temporal operators ⃝and U have the same meaning as
in LTL and are path operators. Formula ⃝Φ holds for a path if Φ holds at the next
state in the path, and Φ U Ψ holds for a path if there is some state along the path for
which Ψ holds, and Φ holds in all states prior to that state. Path formulae can be turned
into state formulae by preﬁxing them with either the path quantiﬁer ∃(pronounced “for
some path”) or the path quantiﬁer ∀(pronounced “for all paths”). Note that the linear

318
Computation Tree Logic
temporal operators ⃝and U are required to be immediately preceded by ∃or ∀to obtain
a legal state formula. Formula ∃ϕ holds in a state if there exists some path satisfying ϕ
that starts in that state. Dually, ∀ϕ holds in a state if all paths that start in that state
satisfy ϕ.
Example 6.2.
Legal CTL Formulae
Let AP = { x = 1, x < 2, x ⩾3 } be a set of atomic propositions. Examples of syntactically
correct CTL formulae are
∃⃝(x = 1), ∀⃝(x = 1), and x < 2 ∨x = 1
and ∃((x < 2) U (x ⩾3)) and ∀(true U (x < 2)).
Some examples of formulae that are
syntactically incorrect are
∃(x = 1 ∧∀⃝(x ⩾3)) and ∃⃝(true U (x = 1)).
The ﬁrst is not a CTL formula since x = 1 ∧∀⃝(x ⩾3) is not a path formula and thus
must not be preceded by ∃. The second formula is not a CTL formula since true U (x = 1)
is a path formula rather than a state formula, and thus cannot be preceded by ⃝. Note
that
∃⃝(x = 1 ∧∀⃝(x ⩾3)) and ∃⃝∀(true U (x = 1))
are, however, syntactically correct CTL formulae.
The Boolean operators true, false, ∧, →and ⇔are deﬁned in the usual way.
The
temporal modalities “eventually”, “always”, and “weak until” can be derived—similarly
as for LTL—as follows:
eventually:
∃♦Φ
=
∃(trueU Φ)
∀♦Φ
=
∀(trueU Φ)
always:
∃□Φ
=
¬∀♦¬Φ
∀□Φ
=
¬∃♦¬Φ
∃♦Φ is pronounced “Φ holds potentially” and ∀♦Φ is pronounced “Φ is inevitable”. ∃□Φ
is pronounced “potentially always Φ”, ∀□Φ is pronounced “invariantly Φ”, and ∀⃝Φ is
pronounced “for all paths next Φ”.

Computation Tree Logic
319
Note that “always” Φ cannot be obtained from the “equation” □Φ = ¬♦¬Φ (as in LTL),
since propositional logic operators cannot be applied to path formulae.
In particular,
∃¬♦¬Φ is not a CTL formula. Instead, we exploit the duality of existential and universal
quantiﬁcation:
• there exists a path with the property E if and only if the state property “not all
paths violate property E” is satisﬁed, and
• all paths satisfy property E if and only if the state property “there is a path without
property E” is violated.
Accordingly, ∃□Φ is not deﬁned as ∃¬♦¬Φ, but rather as ¬∀♦¬Φ.
Example 6.3.
CTL Formulae
To give a feeling about how simple properties can be formalized in CTL we treat some
intuitive examples. The mutual exclusion property can be described in CTL by the formula
∀□(¬crit1 ∨¬crit2).
CTL formulae of the form ∀□∀♦Φ express that Φ is inﬁnitely often true on all paths.
(This fact will be formally proven later; see Remark 6.8 on page 326.) The CTL formula
(∀□∀♦crit1) ∧(∀□∀♦crit2)
thus requires each process to have access to the critical section inﬁnitely often. In case
of a traﬃc light, the safety property “each red light phase is preceded by a yellow light
phase” can be formulated in CTL by
∀□(yellow ∨∀⃝¬red)
depending on the precise meaning of a “phase”. The liveness property “the traﬃc light is
inﬁnitely often green” can be formulated as
∀□∀♦green
.
Progress properties such as “every request will eventually be granted” can be described
by
∀□(request −→∀♦response).
Finally, the CTL formula
∀□∃♦start
expresses that in every reachable system state it is possible to return (via 0 or more
transitions) to (one of) the starting state(s).

320
Computation Tree Logic
6.2.2
Semantics
CTL formulae are interpreted over the states and paths of a transition system TS. For-
mally, given a transition system TS, the semantics of CTL formulae is deﬁned by two
satisfaction relations (both denoted by |=TS, or brieﬂy |=): one for the state formulae and
one for the path formulae. For the state formulae, |= is a relation between the states in TS
and state formulae. We write s |= Φ rather than (s, Φ) ∈|=. The intended interpretation
is: s |= Φ if and only if state formula Φ holds in state s. For the path formulae, |= is
a relation between maximal path fragments in TS and path formulae. We write π |= Φ
rather than (π, Φ) ∈|=. The intended interpretation is: π |= ϕ if and only if path π
satisﬁes path formula ϕ.
Deﬁnition 6.4.
Satisfaction Relation for CTL
Let a ∈AP be an atomic proposition, TS = (S, Act, →, I, AP, L) be a transition system
without terminal states, state s ∈S, Φ, Ψ be CTL state formulae, and ϕ be a CTL path
formula. The satisfaction relation |= is deﬁned for state formulae by
s |= a
iﬀ
a ∈L(s)
s |= ¬ Φ
iﬀ
not s |= Φ
s |= Φ ∧Ψ
iﬀ
(s |= Φ) and (s |= Ψ)
s |= ∃ϕ
iﬀ
π |= ϕ for some π ∈Paths(s)
s |= ∀ϕ
iﬀ
π |= ϕ for all π ∈Paths(s)
For path π, the satisfaction relation |= for path formulae is deﬁned by
π |= ⃝Φ
iﬀ
π[1] |= Φ
π |= Φ U Ψ
iﬀ
∃j ⩾0. (π[j] |= Ψ ∧(∀0 ⩽k < j. π[k] |= Φ))
.
where for path π = s0 s1 s2 . . . and integer i ⩾0, π[i] denotes the (i+1)th state of π, i.e.,
π[i] = si.
The interpretations for atomic propositions, negation, and conjunction are as usual, where
it should be noted that in CTL they are interpreted over states, whereas in LTL they are
interpreted over paths. state formula ∃ϕ is valid in state s if and only if there exists some
path starting in s that satisﬁes ϕ. In contrast, ∀ϕ is valid in state s if and only if all
paths starting in s satisfy ϕ. The semantics of the path formulae is identical (although
formulated slightly more simply) to that for LTL.1 For instance, ∃⃝Φ is valid in state s if
1The semantics of the CTL path formulae is formulated more simply than for LTL, since in CTL each

Computation Tree Logic
321
and only if there exists some path π starting in s such that in the next state of this path,
state π[1], the property Φ holds. This is equivalent to the existence of a direct successor
s′ of s such that s′ |= Φ. ∀(Φ U Ψ) is valid in state s if and only if every path starting in s
has an initial ﬁnite preﬁx (possibly only containing s) such that Ψ holds in the last state
of this preﬁx and Φ holds in all other states along the preﬁx. ∃(Φ U Ψ) is valid in s if and
only if there exists a path starting in s that satisﬁes Φ U Ψ. As for LTL, the semantics of
CTL here is nonstrict in the sense that the path formula Φ U Ψ is valid if the initial state
of the path satisﬁes Ψ.
Deﬁnition 6.5.
CTL Semantics for Transition Systems
Given a transition system TS as before, the satisfaction set SatTS(Φ), or brieﬂy Sat(Φ),
for CTL-state formula Φ is deﬁned by:
Sat(Φ) = { s ∈S | s |= Φ }.
The transition system TS satisﬁes CTL formula Φ if and only if Φ holds in all initial states
of TS:
TS |= Φ
if and only if
∀s0 ∈I. s0 |= Φ
.
This is equivalent to I ⊆Sat(Φ).
The semantics of the derived path operators “always” and “eventually” is similar to that
in LTL. For path fragment π = s0 s1 s2 . . .:
π |= ♦Φ
if and only if
sj |= Φ for some j ⩾0.
From this it can be derived that:
s |= ∃□Φ
iﬀ
∃π ∈Paths(s). π[j] |= Φ for all j ⩾0,
s |= ∀□Φ
iﬀ
∀π ∈Paths(s). π[j] |= Φ for all j ⩾0.
Therefore, □Φ can be understood as CTL path formula with the semantics:
π = s0 s1 s2 . . . |= □Φ
if and only if
sj |= Φ for all j ⩾0.
In particular, ∀□Φ corresponds to the invariant over the invariant condition Φ.
In a similar way, one can derive that ∃□Φ is valid in state s if and only if there exists
some path starting at s such that for each state on this path the formula Φ holds. The
formula ∃♦Φ is valid in state s if and only if Φ holds eventually along some path that
starts in s, and ∀♦Φ is valid if and only if this property holds for all paths that start in s.
A schematic overview of the validity of ∃□, ∃♦, ∀♦, and ∀□is given in Figure 6.2, where

322
Computation Tree Logic
∃□black
∀□black
∃♦black
∀♦black
∃(gray U black)
∀(gray U black)
Figure 6.2: Visualization of semantics of some basic CTL formulae.

Computation Tree Logic
323
s3,1
s2,1
s1,1
s0,1
s0,0
up0
up2
up1
up3
down
Figure 6.3: A transition system of the TMR system.
Property
Formalization in CTL
Possibly the system never goes down
∃□¬ down
Invariantly the system never goes down
∀□¬ down
It is always possible to start as new
∀□∃♦up3
The system always eventually goes down
and is operational until going down
∀((up3 ∨up2) U down)
Table 6.2: Some properties for the TMR system and their formalization in CTL.
black-colored states satisfy the proposition black, gray states are labeled with gray, and
all other states are labeled neither with black nor with gray.
Example 6.6.
A Triple Modular Redundant System
Consider a triple modular redundant (TMR) system with three processors and a single
voter. As each component of this system can fail, the reliability is increased by letting
all processors execute the same program. The voter takes a majority vote of the outputs
of the three processors. If a single processor fails, the system can still produce reliable
outputs. Each component can be repaired. It is assumed that only one component at a
time can fail and only one at a time can be repaired. On failure of the voter, the entire
system fails. On repair of the voter, it is assumed that the system starts as being new,
i.e., with three processors and a voter. The transition system of this TMR is depicted in
Figure 6.3. States are of the form si,j where i denotes the number of processors that is
currently up (0 < i ⩽3) and j the number of operational voters (j = 0, 1). We consider the
TMR system to be operational if at least two processors are functioning properly. Some
interesting properties of this system and their formulation in CTL are listed in Table 6.2
on page 323. We consider each of the formulae in isolation:
temporal operator has to be immediately followed by a state formula.

324
Computation Tree Logic
• state formula ∃□¬ down holds in state s3,1, as there is a path, e.g., (s3,1 s2,1)ω,
starting in that state and that never reaches the down state, i.e., (s3,1 s2,1)ω |=
□¬ down.
• Formula ∀□¬ down, however, does not hold in state s3,1, as there is a path starting
from that state, such as (s3,1)+ s0,0 . . ., that satisﬁes ¬ □¬ down, or, equivalently,
♦down.
• Formula ∀□∃♦up3 holds in state s3,1, as in any state of any of its paths it is possible
to return to the initial state, e.g., by ﬁrst moving to state s0,0 and then to s3,1. For
instance, the path s3,1 (s2,1)ω |= □∃♦up3 since s2,1 |= ∃♦up3,1.
This property
should not be confused with the CTL formula ∀♦up3, which expresses that each
path eventually will visit the initial state. (Note that this formula is trivially valid
for state s3,1 as it satisﬁes up3.)
• The last property of Table 6.2 does not hold in state s3,1 as there exists a path,
such as s3,1 s2,1 s1,1 s0,0 . . ., for which the path formula (up3 ∨up2) U down does
not hold. The formula is refuted since the path visits state s1,1, a state that satisﬁes
neither down nor up3 nor up2.
Example 6.7.
CTL Semantics
Consider the transition system depicted at the top (a) of Figure 6.4.
Just below the
transition system the validity of several CTL formulae is indicated for each state. (For
simplicity, the initial states are not indicated.) A state is colored black if the formula is
valid in that state; otherwise, it is white. The following formulae are considered:
• The formula ∃⃝a is valid for all states since all states have some direct successor
state that satisﬁes a.
• ∀⃝a is not valid for state s0, since a possible path starting at s0 goes directly to
state s2 for which a does not hold. Since the other states have only direct successors
for which a holds, ∀⃝a is valid for all other states.
• For all states except state s2, it is possible to have a computation that leads to state
s3 (such as s0 s1 sω
3 when starting in s0) for which a is globally valid. Therefore, ∃□a
is valid in these states. Since a ̸∈L(s2) there is no path starting at s2 for which a is
globally valid.
• ∀□a is only valid for s3 since its only path, sω
3 , always visits a state in which a
holds. For all other states it is possible to have a path which contains s2 that does
not satisfy a. So for these states ∀□a is not valid.

Computation Tree Logic
325
∃(a U ( ¬ a ∧∀( ¬ a U b)))
∃⃝a
∀⃝a
∃□a
∀□a
∃♦(∃□a)
∀(a U b)
TS
s1
s0
{ a }
{ a }
s3
{ b }
{ a, b }
s2
(a)
Figure 6.4: Interpretation of several CTL formulae.

326
Computation Tree Logic
• ∃♦(∃□a) is valid for all states since from each state another state (either s0, s1, or
s3) can be eventually reached from which some computation can start along which
a is globally valid.
• ∀(a U b) is not valid in s3 since its only computation (sω
3 ) never reaches a state for
which b holds. In state s0 proposition a holds until b holds, and in states s1 and s2
proposition b holds immediately. So, for these states the formula is true.
• Finally, ∃(a U ( ¬ a ∧∀( ¬ a U b))) is not valid in s3, since from s3 a b-state can never
be reached. For the states s0 and s1 the formula is valid, since state s2 can be reached
from these states via an a-path; ¬ a is valid in s2, and from s2 all possible paths
satisfy ¬ a U b, since s2 is a b-state. For instance, for state s0 the path (s0 s2 s1)ω
satisﬁes a U ( ¬ a ∧∀( ¬ a U b)) since a ∈L(s0), a ̸∈L(s2), and b ∈L(s1). For state
s2 the property is valid since a is invalid in s2 and for all paths starting at s2 the
ﬁrst state is a b-state.
Remark 6.8.
Inﬁnitely Often
For a better comprehension of the semantics of CTL, let us prove that:
s |= ∀□∀♦a
if and only if
∀π ∈Paths(s). π[i] |= a for inﬁnitely many i .
⇒: Let s be a state, such that s |= ∀□∀♦a. The proof obligation is to show that every
inﬁnite path fragment π starting in s passes through an a-state inﬁnitely often.
Let
π = s0 s1 s2 . . . ∈Paths(s) and j ⩾0. We demonstrate that there exists an index i ⩾j
with si |= a. Since s |= ∀□∀♦a, we have
π |= □∀♦a.
In particular, sj |= ∀♦a. From π[j..] = sj sj+1 . . . ∈Paths(sj) it follows that
sj sj+1 sj+2 . . . |= ♦a.
Thus, there exists an index i ⩾j with si |= a. As this reasoning applies to any index j,
path π visits an a-state inﬁnitely often.
⇐: Let s be a state such that every inﬁnite path fragment starting in s visits inﬁnitely
many a-states. Let π = s0 s1 s2 . . . ∈Paths(s). To show that s |= ∀□∀♦a, it has to be
proven that π |= □∀♦a, i.e.:
sj |= ∀♦a,
for any j ⩾0.

Computation Tree Logic
327
Let j ⩾0 and π′ = s′
j s′
j+1 s′
j+2 . . . ∈Paths(sj). To show that sj |= ∀♦a, it suﬃces to
prove that π′ visits at least one a-state. It is not diﬃcult to infer that
π′′ = s0 s1 s2 . . . sj



preﬁx of π
s′
j+1 s′
j+2 . . .



π′ ∈Paths(sj)
∈Paths(s)
.
By assumption, π′′ visits inﬁnitely many a-states. In particular, there is an i > j such
that s′
i |= a. It now follows that
π′ = sj s′
j+1 . . . s′
i−1 s′
i s′
i+1, . . . |= ♦a
and, as this holds for any path π′ ∈Paths(sj), thus sj |= ∀♦a. This yields π |= □∀♦a for
all paths π ∈Paths(s). Thus, we have s |= ∀□∀♦a.
Remark 6.9.
Weak Until
As for LTL (see Section 5.1.5), a slight variant of the until operator can be deﬁned, viz.
the weak-until operator, denoted W. The intuition behind this operator is that path π
satisﬁes Φ W Ψ, for state formulae Φ and Ψ, if either Φ U Ψ or □Φ holds. That is, the
diﬀerence between until and weak until is that the latter does not require a Ψ-state to be
reached eventually.
The weak-until operator in CTL cannot be deﬁned directly starting from the LTL deﬁnition
ϕ W ψ = ϕ U ψ ∨□ϕ,
since ∃(ϕ U ψ ∨□ϕ) is not a syntactically correct CTL formula. However, using the LTL
equivalence law ϕ W ψ ≡¬((ϕ ∧¬ψ) U (¬ϕ ∧¬ψ)) and the duality between universal and
existential quantiﬁcation, the weak-until operator can be deﬁned in CTL by
∃(Φ W Ψ)
=
¬∀((Φ ∧¬Ψ) U (¬Φ ∧¬Ψ)),
∀(Φ W Ψ)
=
¬∃((Φ ∧¬Ψ) U (¬Φ ∧¬Ψ)).
Let us now check the semantics of ∃W . From the above-deﬁned duality, it follows that
s |= ∃(Φ W Ψ) if and only if there exists a path π = s0 s1 s2 . . . that starts in s (i.e., s0 = s)
such that
π ̸|= (Φ ∧¬Ψ) U (¬Φ ∧¬Ψ).
Such path exists if and only if
• either sj |= Φ ∧¬Ψ for all j ⩾0, i.e., π |= □(Φ ∧¬Ψ), or
• there exists an index j such that

328
Computation Tree Logic
– sj ̸|= Φ ∧¬Ψ and sj ̸|= ¬Φ ∧¬Ψ, i.e., sj |= Ψ, and
– si |= Φ ∧¬Ψ for all 0 ⩽i < j.
This is equivalent to π |= Φ U Ψ.
Gathering these results yields
π |= Φ W Ψ
if and only if
π |= Φ U Ψ or π |= □(Φ ∧¬Ψ),
if and only if
π |= Φ U Ψ or π |= □Φ.
Thus, the CTL formula ∃(Φ W Ψ) is equivalent to ∃(Φ U Ψ) ∨∃□Φ. In the same way, one
can check that the meaning of ∀(Φ W Ψ) is as expected, i.e., s |= ∀(Φ W Ψ) if and only if
all paths starting in s fulﬁll Φ W Ψ according to the LTL semantics of W .
Remark 6.10.
The Semantics of Negation
For state s, we have s ̸|= Φ if and only if s |= ¬Φ. This, however, does not hold in general
for transition systems. That is to say, it is possible that the statements TS ̸|= Φ and
TS ̸|= ¬Φ both hold. This stems from the fact that there might be two initial states, s0
and s′
0, say, such that s0 |= Φ and s′
0 ̸|= Φ. Furthermore:
TS ̸|= ¬∃ϕ iﬀthere exists a path π ∈Paths(TS) with π |= ϕ.
This—at ﬁrst glance surprising—equivalence is justiﬁed by the fact that the interpretation
of CTL state formulae over transition systems is based on a universal quantiﬁcation over
the initial states. The statement TS ̸|= ¬∃ϕ thus holds if and only if there exists an initial
state s0 ∈I with s0 ̸|= ¬∃ϕ, i.e., s0 |= ∃ϕ. On the other hand, TS |= ∃ϕ requires that
s0 |= ∃ϕ for all s0 ∈I. Consider the following transition system:
s0
{ a }
s′
0
∅
It follows that s0 |= ∃□a, whereas s′
0 ̸|= ∃□a. Accordingly, TS ̸|= ¬∃□a and TS ̸|= ∃□a.
The semantics of CTL has been deﬁned for a transition system without terminal states.
This has the (technically) pleasant eﬀect that all paths are inﬁnite and simpliﬁes the

Computation Tree Logic
329
deﬁnition of |= for paths. In the following remark it is shown how to adapt the path
semantics in case transition systems are considered with terminal states, i.e., when ﬁnite
paths are possible.
Remark 6.11.
CTL Semantics for Transition Systems with Terminal States
For ﬁnite maximal path fragment π
=
s0 s1 s2 . . . sn of length n, i.e., sn is a terminal
state, let
π
|=
⃝Φ
iﬀ
n > 0 and s1 |= Φ,
π
|=
Φ U Ψ
iﬀ
there exists an index j ∈IN with j ⩽n, and
si |= Φ,
for i = 0, 1, . . . , j−1, and sj |= Ψ.
Then, s |= ∀⃝false if and only if s is a terminal state. For the derived operators ♦and □
we obtain
π
|=
♦Φ
iﬀ
there exists an index j ⩽n with sj |= Φ,
π
|=
□Φ
iﬀ
for all j ∈IN with j ⩽n we have sj |= Φ.
6.2.3
Equivalence of CTL Formulae
CTL formulae Φ and Ψ are called equivalent whenever they are semantically identical,
i.e., when for any state s it holds that2 s |= Φ if and only if s |= Ψ.
Deﬁnition 6.12.
Equivalence of CTL Formulae
CTL formulae Φ and Ψ (over AP) are called equivalent, denoted Φ ≡Ψ, if Sat(Φ)
=
Sat(Ψ) for all transition systems TS over AP.
Accordingly, Φ ≡Ψ if and only if for any transition system TS we have:
TS |= Φ
if and only if
TS |= Ψ
.
Besides the standard equivalence laws for the propositional logic fragment of CTL, there
exist a number of equivalence rules for temporal modalities in CTL. An important set of
equivalence laws is indicated in Figure 6.5.
To understand the expansion laws, let us
reconsider the expansion law for the until operator in LTL:
ϕ U ψ ≡ψ ∨(ϕ ∧⃝(ϕ U ψ)).
2Recall that the notion CTL formula is used for a CTL state formula.

330
Computation Tree Logic
duality laws for path quantiﬁers
∀⃝Φ
≡
¬∃⃝¬Φ
∃⃝Φ ≡¬∀⃝¬Φ
∀♦Φ
≡
¬∃□¬Φ
∃♦Φ ≡¬∀□¬Φ
∀(Φ U Ψ)
≡
¬∃(¬Ψ U (¬Φ ∧¬Ψ)) ∧¬∃□¬Ψ
≡
¬∃((Φ ∧¬Ψ) U (¬Φ ∧¬Ψ)) ∧¬∃□(Φ ∧¬Ψ)
≡
¬∃((Φ ∧¬Ψ) W (¬Φ ∧¬Ψ))
expansion laws
∀(Φ U Ψ)
≡
Ψ ∨(Φ ∧∀⃝∀(Φ U Ψ))
∀♦Φ
≡
Φ ∨∀⃝∀♦Φ
∀□Φ
≡
Φ ∧∀⃝∀□Φ
∃(Φ U Ψ)
≡
Ψ ∨(Φ ∧∃⃝∃(Φ U Ψ))
∃♦Φ
≡
Φ ∨∃⃝∃♦Φ
∃□Φ
≡
Φ ∧∃⃝∃□Φ
distributive laws
∀□(Φ ∧Ψ)
≡
∀□Φ ∧∀□Ψ
∃♦(Φ ∨Ψ)
≡
∃♦Φ ∨∃♦Ψ
Figure 6.5:
Some equivalence rules for CTL.

Computation Tree Logic
331
In CTL, similar expansion laws for ∃(Φ U Ψ) and ∀(Φ U Ψ) exist. For instance, we have
that ∃(Φ U Ψ) is equivalent to the fact that the current state either satisﬁes Ψ, or it satisﬁes
Φ, and for some direct successor state, ∃(Φ U Ψ) holds. The expansion laws for ∃♦Φ and
∃□Φ can be simply derived from the expansion laws for ∃U. The basic idea behind these
laws—as for LTL—is to express the validity of a formula by a statement about the current
state (without the need to use temporal operators) and a statement about the direct
successors of this state (using either ∃⃝or ∀⃝depending on whether an existential or
a universally quantiﬁed formula is treated). For instance, ∃□Φ is valid in state s if Φ is
valid in s (a statement about the current state) and Φ holds for all states along some path
starting at s (a statement about the successor states).
Not any law in LTL can be easily lifted to CTL. Consider, for example, the following
statement:
♦(ϕ ∨ψ) ≡♦ϕ ∨♦ψ,
which is valid for any path. The same is true for:
∃♦(Φ ∨Ψ) ≡∃♦Φ ∨∃♦Ψ.
This can be seen as follows.
⇐: Assume that s |= ∃♦Φ ∨∃♦Ψ. Then, without loss of generality, we may assume
that s |= ∃♦Φ.
This means that there is some state s′ (possibly s = s′), reachable
from state s, such that s′ |= Φ. But then s′ |= Φ ∨Ψ. This means that there exists a
reachable state from s which satisﬁes Φ ∨Ψ. By the semantics of CTL it now follows
that s |= ∃♦(Φ ∨Ψ).
⇒: Let s be an arbitrary state such that s |= ∃♦(Φ ∨Ψ). Then there exists a state s′
(possibly s = s′) such that s′ |= Φ ∨Ψ. Without loss of generality we may assume that
s′ |= Φ. But then we can conclude that s |= ∃♦Φ, as s′ is reachable from s. Therefore we
also have s |= ∃♦Φ ∨∃♦Ψ.
However, ∀♦(Φ ∨Ψ) ̸≡∀♦Φ ∨∀♦Ψ since ∀♦(Φ ∨Ψ) ⇒∀♦Φ ∨∀♦Ψ is invalid as
shown by the following transition system:

332
Computation Tree Logic
{ a }
{ b }
s′′
s′
s
For each path that starts in state s we have that ♦(a ∨b) holds, so s |= ∀♦(a ∨b). This
follows directly from the fact that each path visits either state s′ or state s′′ eventually,
and s′ |= a ∨b and the same applies to s′′. However, state s does not satisfy ∀♦a ∨∀♦b.
For instance, path s (s′′)ω |= ♦a but s (s′′)ω ̸|= ♦b. Thus, s ̸|= ∀♦b. By a similar reasoning
applied to path s (s′)ω it follows that s ̸|= ∀♦a. Thus, s ̸|= ∀♦a ∨∀♦b. Stated in words,
not all computations that start in state s eventually reach an a-state nor do they all
eventually reach a b-state.
6.2.4
Normal Forms for CTL
The duality law for ∀⃝Φ shows that ∀⃝can be treated as a derived operator of ∃⃝.
That is to say, the basic operators ∃⃝, ∃U, and ∀U would have been suﬃcient to deﬁne the
syntax of CTL. The following theorem demonstrates that we can even omit the universal
path quantiﬁer and deﬁne all temporal modalities in CTL using the basic operators ∃⃝,
∃U, and ∃□.
Deﬁnition 6.13.
Existential Normal Form (for CTL)
For a ∈AP, the set of CTL state formulae in existential normal form (ENF, for short) is
given by
Φ
::=
true
   a
   Φ1 ∧Φ2
   ¬Φ
   ∃⃝Φ
   ∃(Φ1 U Φ2)
   ∃□Φ.
Theorem 6.14.
Existential Normal Form for CTL
For each CTL formula there exists an equivalent CTL formula in ENF.

Computation Tree Logic
333
Proof: The following duality laws allow elimination of the universal path quantiﬁer and
thus provide a translation of CTL formulae into equivalent ENF formulae:
∀⃝Φ
≡
¬∃⃝¬Φ,
∀(Φ U Ψ)
≡
¬∃(¬Ψ U(¬Φ ∧¬Ψ)) ∧¬∃□¬Ψ.
Recall that the basis syntax of CTL only uses ∃⃝, ∃U and ∀⃝and ∀U. Thus, the two
rules used in the proof of Theorem 6.14 allow the removal of all universal quantiﬁers from
a given CTL formula. However, when implementing the translation from CTL formulae
to ENF formulae one might use analogous rules for the derived operators, such as
∀♦Φ
≡
¬ ∃□¬ Φ,
∀□Φ
≡
¬ ∃♦¬ Φ = ¬ ∃(true U Φ).
Since the rewrite rule for ∀U triples the occurrences of the right formula Ψ, the translation
from CTL to ENF can cause an exponential blowup.
Another normal form of importance is the positive normal form. A CTL formula is said
to be in positive normal form (PNF, for short) whenever negations only occur adjacent
to atomic propositions. That is, e.g., ¬∀(a U ¬b) is not in PNF, whereas ∃(¬a ∧¬b U a) is
in PNF. To ensure that every CTL formula is equivalent to a formula in PNF, for each
operator a dual operator is necessary. We have that conjunction and disjunction are dual,
and that ⃝is dual to itself. As for LTL, we adopt the weak until operator W as a dual
operator of U.
Deﬁnition 6.15.
Positive Normal Form (for CTL)
The set of CTL state formulae in positive normal form (PNF, for short) is given by
Φ
::=
true
   false
   a
   ¬a
   Φ1 ∧Φ2
   Φ1 ∨Φ2
   ∃ϕ
   ∀ϕ
where a ∈AP and the path formulae are given by
ϕ
::=
⃝Φ
   Φ1 U Φ2
   Φ1 W Φ2.
Theorem 6.16.
Existence of Equivalent PNF Formulae
For each CTL formula there exists an equivalent CTL formula in PNF.

334
Computation Tree Logic
Proof: Any CTL formula can be transformed into PNF by successively “pushing” negations
“inside” the formula at hand. This is facilitated by the following equivalence laws:
¬true
≡
false
¬¬Φ
≡
Φ
¬(Φ ∧Ψ)
≡
¬Φ ∨¬Ψ
¬∀⃝Φ
≡
∃⃝¬Φ
¬∃⃝Φ
≡
∀⃝¬Φ
¬∀(Φ U Ψ)
≡
∃((Φ ∧¬Ψ) W (¬Φ ∧¬Ψ))
¬∃(Φ U Ψ)
≡
∀((Φ ∧¬Ψ) W (¬Φ ∧¬Ψ)).
Due to the fact that in the rules for ∀U and ∃U the number of occurrences of Ψ (and Φ)
is doubled, the length of an equivalent CTL formula may be exponentially longer than the
original CTL formula.
3 The same phenomenon appeared in deﬁning the PNF for LTL
when using the weak-until operator. As for LTL, this exponential blowup can be avoided by
using the release operator, which in CTL can be deﬁned by: ∃(Φ R Ψ) = ¬∀((¬Φ) U (¬Ψ))
and ∀(Φ R Ψ) = ¬∃((¬Φ) U (¬Ψ)).
6.3
Expressiveness of CTL vs. LTL
Although many relevant properties of reactive systems can be speciﬁed in LTL and CTL,
the logics CTL and LTL are incomparable according to their expressiveness. More pre-
cisely, there are properties that one can express in CTL, but that cannot be expressed in
LTL, and vice versa.
Let us ﬁrst deﬁne what it means for CTL and LTL formulae to be equivalent. Intuitively
speaking, equivalent means “express the same thing”. More precisely:
Deﬁnition 6.17.
Equivalence between CTL- and LTL Formulae
CTL formula Φ and LTL formula ϕ (both over AP) are equivalent, denoted Φ ≡ϕ, if for
any transition system TS over AP:
TS |= Φ
if and only if
TS |= ϕ.
3Although
the
rewrite
rules
for
¬∀U
and
¬∃U
could
be
simpliﬁed
by
¬∀(Φ U Ψ)
≡
∃
“
(¬Ψ) W (¬Φ ∧¬Ψ)
”
and ¬∃(Φ U Ψ) ≡∀
“
(¬Ψ) W (¬Φ ∧¬Ψ)
”
, there is still a duplication of formula
Ψ.

Expressiveness of CTL vs. LTL
335
The LTL formula ϕ holds in state s of a transition system whenever all paths starting in
s satisfy ϕ. Given this (semantical) universal quantiﬁcation over paths, it seems natural
that, e.g., the LTL formula ♦a is equivalent to the CTL formula ∀♦a. This seems to
suggest that for a given CTL formula, an equivalent LTL formula is obtained by simply
omitting all universal path quantiﬁers (as these are implicit in LTL). The following result
by Clarke and Draghicescu [85] (for which the proof is omitted) shows that dropping all
(universal and existential) quantiﬁers is a safe way to generate an equivalent LTL formula,
provided there are equivalent LTL formulae:
Theorem 6.18.
Criterion for Transforming CTL Formulae into Equivalent
LTL Formulae
Let Φ be a CTL formula, and ϕ the LTL formula that is obtained by eliminating all path
quantiﬁers in Φ. Then:
Φ ≡ϕ or there does not exist any LTL formula that is equivalent to Φ.
For the following CTL formulae, an equivalent LTL formula is obtained by simply omitting
all path quantiﬁers: a, ∀⃝a, ∀(a U b), ∀♦a, ∀□a, and ∀□∀♦a. The fact that the CTL
formula ∀□∀♦a is equivalent to the LTL formula □♦a has been established earlier in
Remark 6.8 (326). However, ∀♦∀□a and ♦□a are not equivalent. The LTL formula ♦□a
ensures that a will eventually forever (i.e., continuously from some point on) hold. The
semantics of ∀♦∀□a is diﬀerent, however. The CTL formula ∀♦∀□a asserts that on any
computation, eventually some state, s say, is reached such that s |= ∀□a. Note that
s |= ∀♦∀□a

Φ
if and only if for any path π = s0 s1 s2 . . . ∈Paths(s), sj |= Φ for some j. For Φ = ∀□a,
this entails that for any such path π there is some state sj such that all reachable states
from sj satisfy the atomic proposition a.
Lemma 6.19.
Persistence
The CTL formula ∀♦∀□a and the LTL formula ♦□a are not equivalent.
Proof: Consider the following transition system TS over AP = { a }:

336
Computation Tree Logic
∅
{ a }
s0
s1
s2
{ a }
The initial state s0 satisﬁes the LTL formula ♦□a, since each path starting in s0 eventually
remains forever in one of the two states s0 or s2, which are both labeled with a. The CTL
formula ∀♦∀□a, however, does not hold in s0, since we have sω
0 ̸|= ♦∀□a (as s0 ̸|= ∀□a).
This is due to the fact that the path s∗
0 s1 sω
2 passes through the ¬a-state s1. Thus, sω
0
is a path starting in s0 which will never reach a state satisfying ∀□a, i.e., sω
0 ̸|= ♦∀□a.
Accordingly, it follows that
s0 ̸|= ∀♦∀□a.
Given that the CTL formulae ∀♦∀□a and the LTL formula ♦□a are not equivalent and
the fact that ♦□a is obtained from ∀♦∀□a by eliminating the universal path quantiﬁers,
it follows from Theorem 6.18 that there does not exist an LTL formula that is equivalent
to ∀♦∀□a.
In a similar way, it can be shown that the CTL formulae ∀♦(a ∧∀⃝a)
and ♦(a ∧⃝a) are not equivalent, and thus, the requirement ∀♦(a ∧∀⃝a) cannot be
expressed in LTL.
Lemma 6.20.
Eventually an a-State with only direct a-Successors
The CTL formula ∀♦(a ∧∀⃝a) and the LTL formula ♦(a ∧⃝a) are not equivalent.
Proof: Consider the transition system depicted in Figure 6.6. All paths that start in the
initial state s0 have either as preﬁx the path fragment s0 s1 or s0 s3 s4. Clearly, all such
paths satisfy the LTL formula ♦(a ∧⃝a), and so, s0 |= ♦(a ∧⃝a). On the other
hand, however, s0 ̸|= ∀♦(a ∧∀⃝a) as the path s0 s1 (s2)ω does not satisfy ♦(a ∧∀⃝a).
This follows from the fact that state s0 has the non-a-state s3 as direct successor, i.e.,
s0 ̸|= a ∧∀⃝a.
These examples show that certain requirements that can be expressed in CTL, cannot
be expressed in LTL.
The following theorem provides, in addition, some examples of
LTL formulae for which no equivalent CTL formula exists.
This establishes that the
expressiveness of the temporal logics LTL and CTL are incomparable.

Expressiveness of CTL vs. LTL
337
s1
s2
{ a }
∅
{ a }
∅
s0
s3
s4
{ a }
Figure 6.6: Transition system for ∀♦(a ∧∀⃝a).
s0
∅
t0
{ a }
s′
0
∅
t′
0
{ a }
Figure 6.7: The base transition systems: TS0 (left) and TS′
0 (right).
Theorem 6.21.
Incomparable Expressiveness of CTL and LTL
(a) There exist LTL formulae for which no equivalent CTL formula exists. This holds
for, for instance
♦□a
or
♦(a ∧⃝a).
(b) There exist CTL formulae for which no equivalent LTL formula exists. This holds
for, for instance
∀♦∀□a
and
∀♦(a ∧∀⃝a)
and
∀□∃♦a.
Proof:
(a) Consider the formula ♦□a. The proof for ♦(a ∧⃝a) goes along similar lines and
is omitted here. Consider the two series of transition systems TS0, TS1, TS2, . . . and
TS′
0, TS′
1, TS′
2, . . . that are inductively deﬁned as follows (see Figures 6.7 and 6.8).

338
Computation Tree Logic
sn
∅
tn
{ a }
s′
n
∅
t′
n
{ a }
TS′
n−1
TS′
n−1
Figure 6.8: Inductive construction of TSn (upper) and TS′
n (lower).
For all transition systems, AP = { a }, and the action labels are not important. Let,
for n ⩾0,
TSn = (Sn, { τ }, →n, { sn }, { a }, Ln)
and
TSn = (S′
n, { τ }, →′
n, { s′
n }, { a }, L′
n)
where S0 = { s0, t0 }, S′
0 = { s′
0, t′
0 }, and for n > 0:
Sn = S′
n−1 ∪{ sn, tn }
and
S′
n = S′
n−1 ∪{ s′
n, t′
n }.
The labeling functions are deﬁned such that all states ti are labeled with { a } and
all states si are labeled with ∅. Thus, L0(s0) = ∅and L0(t0) = { a }, and for n > 0,
the labels of all states in TS′
n−1 remain the same and are extended with
Ln(sn) = L′
n(s′
n) = ∅
and
Ln(tn) = L′
n(t′
n) = { a }.
Finally, the transition relations →n and →′
n contain →′
n−1 (where →−1= ∅), as well
as the transitions
TSn :
sn →n tn,
tn →n tn,
tn →n s′
n−1,
tn →n sn
TS′
n :
s′
n →′
n t′
n,
t′
n →′
n t′
n,
t′
n →′
n s′
n−1
where the action labels are omitted for simplicity.
Thus, the only diﬀerence between TSn and TS′
n is the fact that TSn includes the
edge tn →sn, whereas this edge is absent in TS′
n. Some example instantiations of
TSn and TS′
n are indicated in Figure 6.9.

Expressiveness of CTL vs. LTL
339
s1
∅
t1
{ a }
s′
0
∅
t′
0
{ a }
s′
1
∅
t′
1
{ a }
s′
0
∅
t′
0
{ a }
Figure 6.9: The transition systems TS1 (upper) and TS′
1 (lower).
It follows from the construction of TSn and TS′
n that
TSn ̸|= ♦□a
and
TS′
n |= ♦□a
for all n ⩾0.
This can be proven as follows. TSn contains the initial path (sn tn)ω that visits sn
and tn in an alternating fashion. We have that
trace((sn tn)ω) = ∅{ a } ∅{ a } ∅. . .
thus
trace((sn tn)ω) ̸|= ♦□a.
As the considered path is initial, it follows that TSn ̸|= ♦□a. On the other hand, as
TS′
n has no opportunity to inﬁnitely often return to an ¬a-state, each initial path
in TS′
n is of the following form:
π′
i = s′
n t′
n . . . s′
i (t′
i)ω
for some i. Due to the fact that
trace(π′
i) = ∅{ a } ∅. . . ∅({ a })ω
it follows that trace(π′
i) |= ♦□a. As this applies to any initial path of TS′
n, we have
TS′
n |= ♦□a.
By means of induction on n, it can be proven that TSn and TS′
n cannot be distin-
guished by any CTL formula of length at most n. That is to say, for all n ⩾0,
∀CTL formula Φ with |Φ| ⩽n : TSn |= Φ
if and only if
TS′
n |= Φ.
(The proof of this fact is left to the interested reader.)

340
Computation Tree Logic
s
∅
s′
(a)
{ a }
(b)
s
∅
Figure 6.10: Two transition systems for ∀□∃♦a.
The ﬁnal step of the proof is now as follows. Assume there is a CTL formula Φ that
is equivalent to ♦□a. Let n = |Φ| be the length of the formula Φ and
TS = TSn,
TS′ = TS′
n.
On the one hand, it follows from TS ̸|= ♦□a and TS′ |= ♦□a that
TS ̸|= Φ and TS′ |= Φ.
On the other hand, it results from the fact that TSn and TS′
n cannot be distinguished
by a CTL formula (of length at most n) that Φ has the same truth-value under TS
and under TS′. This yields a contradiction.
(b) We concentrate on the proof that there does not exist an equivalent formulation of
the CTL formula ∀□∃♦a in LTL. The fact that there do not exist equivalent LTL
formulations of the CTL formulae ∀♦∀□a and ∀♦(a ∧∀⃝a) follows directly from
Lemmas 6.19 and 6.20 respectively, and Theorem 6.18. The proof for ∀□∃♦a is by
contraposition. Let ϕ be an LTL formula that is equivalent to ∀□∃♦a. Consider the
transition system TS depicted in Figure 6.10(a). As TS |= ∀□∃♦a, and ϕ ≡∀♦∃♦a,
it follows that TS |= ϕ, and therefore
Traces(TS) ⊆Words(ϕ).
Since π = sω is a path in TS, it follows that
trace(π) = ∅∅∅∅. . . ∈Traces(TS) ⊆Words(ϕ).
Now consider the transition system TS′ depicted in Figure 6.10(b). Note that TS′ is
part of transition system TS. The paths starting in s in TS′ are also paths starting
from s in TS, so we have s |= ϕ in TS′ and thus TS′ |= ϕ. However, s ̸|= ∀□∃♦a,
since ∃♦a is never valid along the only path sω, and thus TS′ ̸|= ∀□∃♦a. This is a
contradiction.

CTL Model Checking
341
Note that the CTL formula ∀□∃♦a is of signiﬁcant practical use, since it expresses the
fact that it is possible to reach a state for which a holds irrespective of the current state.
If a characterizes a state where a certain error is repaired, the formula expresses the fact
that it is always possible to recover from that error.
6.4
CTL Model Checking
This section is concerned with CTL model checking, which means a decision algorithm that
checks whether TS |= Φ for a given transition system TS and CTL formula Φ. Throughout
this section, it is assumed that TS is ﬁnite, and has no terminal states.
We will see
that CTL-model checking can be performed by a recursive procedure that calculates the
satisfaction set for all subformulae of Φ and ﬁnally checks whether all initial states belong
to the satisfaction set of Φ.
Throughout this section, we consider CTL formulae in ENF, i.e., CTL formulae built by
the basic modalities ∃⃝, ∃U, and ∃□. This requires algorithms that generate Sat(∃⃝Φ),
Sat(∃(Φ U Ψ)), and Sat(∃□Φ) when Sat(Φ) and Sat(Ψ) are given. Although each CTL for-
mula can be transformed algorithmically into an equivalent ENF formula, for an implemen-
tation of the CTL model-checking algorithm it is recommended to use similar techniques
to handle universal quantiﬁcation, i.e., to design algorithms that generate Sat(∀⃝Φ),
Sat(∀(Φ U Ψ)), and Sat(∀□Φ) directly from Sat(Φ) and Sat(Ψ).
(The same holds for
other derived operators such as W or R .)
6.4.1
Basic Algorithm
The model-checking problem for CTL is to verify for a given transition system TS and
CTL formula Φ whether TS |= Φ. That is, we need to establish whether the formula Φ is
valid in each initial state s of TS. The basic procedure for CTL model checking is rather
straightforward:
• the set Sat(Φ) of all states satisfying Φ is computed recursively, and
• it follows that TS |= Φ if and only if I ⊆Sat(Φ)
where I is the set of initial states of TS. Note that by computing Sat(Φ) a more general
problem than just checking whether TS |= Φ is solved. In fact, it checks for any state
s in S whether s |= Φ, and not just for the initial states.
This is sometimes referred

342
Computation Tree Logic
to as a global model-checking procedure. The basic idea of the algorithm is sketched in
Algorithm 13 where Sub(Φ) is the set of subformulae of Φ. In the sequel of this section it
is assumed that TS is ﬁnite and has no terminal states.
Algorithm 13 CTL model checking (basic idea)
Input: ﬁnite transition system TS and CTL formula Φ (both over AP)
Output: TS |= Φ
(* compute the sets Sat(Φ) = { s ∈S | s |= Φ } *)
for all i ⩽| Φ | do
for all Ψ ∈Sub(Φ) with | Ψ | = i do
compute Sat(Ψ) from Sat(Ψ′)
(* for maximal genuine Ψ′ ∈Sub(Ψ) *)
od
od
return I ⊆Sat(Φ)
The recursive computation of Sat(Φ) basically boils down to a bottom-up traversal of
the parse tree of the CTL state formula Φ. The nodes of the parse tree represent the
subformulae of Φ. The leaves stand for the constant true or an atomic proposition a ∈AP.
All inner nodes are labeled with an operator. For ENF formulae the labels of the inner
nodes are ¬, ∧, ∃⃝, ∃U, or ∃□.
For each node of the parse tree, i.e., for each subformula Ψ of Φ, the set Sat(Ψ) of states
is computed for which Ψ holds. This computation is carried out in a bottom-up fashion,
starting from the leaves of the parse tree and ﬁnishing at the root of the tree, the (unique)
node in the parse tree that corresponds to Φ. At an intermediate node, the results of the
computations of its children are used and combined in an appropriate way to establish the
states of its associated subformula. The type of computation at such node, v say, depends
on the operator (e.g., ∧, ∃⃝, or ∃U) that is at the “top level” of the subformula treated.
The children of node v stand for the maximal genuine subformulae of the formula Ψv that is
represented by v. As soon as Sat(Ψ) is computed, subformula Ψ is (theoretically) replaced
by a new atomic proposition aΨ, and the labeling function L is adjusted as follows: aΨ is
added to L(s) if and only if s ∈Sat(Ψ). Once the bottom-up computations continue with
the father, w say, of node v, Ψ = Ψv is a maximal genuine subformula of Ψw, and all states
that are labeled with aΨ are known to satisfy Ψ. In fact, one might say that Ψ is replaced
in the formula by the atomic proposition aΨ. This technique will be of importance when
treating the model checking of CTL with fairness.

CTL Model Checking
343
Example 6.22.
Consider the following state formula over AP = { a, b, c }:
Φ = ∃⃝a
  
Ψ
∧∃(b U ∃□¬c)
  
Ψ′′



Ψ′
.
The indicated formulae Ψ and Ψ′ are the maximal proper subformulae of Φ, while Ψ′′ is
a maximal proper subformula of Ψ. The syntax tree for Φ is of the following form:
∧
Sat(Φ)
∃⃝
Sat(Ψ)
∃U
Sat(Ψ′)
a
b
∃□
Sat(Ψ′′)
¬
c
The satisfaction sets for the leaves result directly from the labeling function L. The treat-
ment of subformula ¬c only needs the satisfaction set for Sat(c) to be complemented. Using
Sat(¬c), the set Sat(∃□¬c) can be computed. The subformula Ψ′′ can now be replaced
by the fresh atomic proposition a3 where a3 ∈L(s) if and only if s ∈Sat(∃□¬c). The
computation now continues with determining Sat(∃(b U a3)). In a similar way, Sat(∃⃝a)
can be computed by means of Sat(a).
Once the subformulae Ψ and Ψ′ are treated, they can be replaced by the atomic proposi-
tions a1, a2, respectively, such that
a1 ∈L(s)
iﬀ
s |= ∃⃝a
and
a2 ∈L(s)
iﬀ
s |= ∃(b U a3).
The formula that is to be treated for the root node simply thus is: Φ′ = a1 ∧a2. Sat(Φ′)
results from intersecting Sat(a1) = Sat(Ψ) and Sat(a2) = Sat(Ψ′). Note that a1, a2, and
a3 are fresh atomic propositions, i.e., { a1, a2, a3 } ∩AP = ∅. The above procedure thus
is considered over AP′ = AP ∪{ a1, a2, a3 }.
Theorem 6.23.
Characterization of Sat(·) for CTL formulae in ENF
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states. For all CTL
formulae Φ, Ψ over AP it holds that

344
Computation Tree Logic
(a) Sat(true) = S,
(b) Sat(a) = { s ∈S | a ∈L(s) }, for any a ∈AP,
(c) Sat(Φ ∧Ψ) = Sat(Φ) ∩Sat(Ψ),
(d) Sat(¬Φ) = S \ Sat(Φ),
(e) Sat(∃⃝Φ) = { s ∈S | Post(s) ∩Sat(Φ) ̸= ∅},
(f) Sat(∃(Φ U Ψ)) is the smallest subset T of S, such that
(1) Sat(Ψ) ⊆T and (2) s ∈Sat(Φ) and Post(s) ∩T ̸= ∅implies s ∈T,
(g) Sat(∃□Φ) is the largest subset T of S, such that
(3) T ⊆Sat(Φ) and (4) s ∈T implies Post(s) ∩T ̸= ∅.
In the clauses (f) and (g), the terms “smallest” and “largest” should be interpreted with
respect to the partial order induced by set inclusion.
Proof: The validity of the claims indicated in (a) through (e) is straightforward. We only
prove the propositions (f) and (g):
Proof of (f): The proof of this claim consists of two parts:
(i) Show that T = Sat(∃(Φ U Ψ)) satisﬁes (1) and (2). From the expansion law
∃(Φ U Ψ)
≡
Ψ
∨
(Φ ∧∃⃝∃(Φ U Ψ)),
it directly follows that T satisﬁes the properties (1) and (2).
(ii) Show that for any T satisfying properties (1) and (2) we have
Sat(∃(Φ U Ψ)) ⊆T.
This is proven as follows. Let s ∈Sat(∃(Φ U Ψ)). Distinguish between s ∈Sat(Ψ)
and s ̸∈Sat(Ψ). If s ∈Sat(Ψ), it follows from (1) that s ∈T. In case s /∈Sat(Ψ),
there exists a path π
=
s0 s1 s2 . . . starting in s=s0, such that π |= Φ U Ψ. Let
n > 0, such that si |= Φ, 0 ⩽i < n, and sn |= Ψ. Then:
• sn ∈Sat(Ψ) ⊆T,
• sn−1 ∈T, since sn ∈Post(sn−1) ∩T and sn−1 ∈Sat(Φ),
• sn−2 ∈T, since sn−1 ∈Post(sn−2) ∩T and sn−2 ∈Sat(Φ),

CTL Model Checking
345
• . . . . . .,
• s1 ∈T, since s2 ∈Post(s1) ∩T and s1 ∈Sat(Φ), and ﬁnally
• s0 ∈T, since s1 ∈Post(s0) ∩T and s0 ∈Sat(Φ).
It thus follows that s = s0 ∈T.
Proof of (g): The proof of this claim consists of two parts:
(i) Show that T = Sat(∃□Φ) satisﬁes (3) and (4). From the expansion law
∃□Φ
≡
Φ ∧∃⃝∃□Φ,
it directly follows that T satisﬁes the properties (3) and (4).
(ii) Show that for any T satisfying properties (3) and (4)
T ⊆Sat(∃□Φ).
This proof goes as follows. Let T ⊆S satisfy (3) and (4) and s ∈T. Let π =
s0 s1 s2 . . . be a path starting in s=s0. (As TS has no terminal states, such a path
exists.) Then we derive
• s0 = s.
• Since s0 ∈T, there exists a state s1 ∈Post(s0) ∩T.
• Since s1 ∈T, there exists a state s2 ∈Post(s1) ∩T.
• . . . . . .
Here, property (4) is exploited in every step. From property (3), it follows that
si ∈T ⊆Sat(Φ),
i ⩾0.
Thus, π = s0 s1 s2 . . . satisﬁes □Φ. It follows that
s ∈Sat(∃□Φ).
As this reasoning applies to any s ∈T, it follows that T ⊆Sat(∃□Φ).
Remark 6.24.
Alternative Formulation of Sat(∃(Φ U Ψ) and Sat(∃□Φ)
The characterizations of the sets Sat(∃(Φ U Ψ)) and Sat(∃□Φ) indicated in Theorem 6.23

346
Computation Tree Logic
are based upon the ﬁxed-point equation induced by the expansion laws for ∃(Φ U Ψ) and
∃□Φ, respectively. Consider, for instance, the expansion law
∃(Φ U Ψ)
≡
Ψ
∨
(Φ ∧∃⃝∃(Φ U Ψ)).
The recursive nature of this law suggests to considering the CTL formula ∃(Φ U Ψ) as a
ﬁxed point of the logical equation
F ≡Ψ ∨(Φ ∧∃⃝F).
By the expansion law F = ∃(Φ U Ψ) is a solution, but there are also other solutions that are
not equivalent to ∃(Φ U Ψ), such as F = ∃(Φ W Ψ) (see Remark 6.25). However, a unique
characterization of ∃(Φ U Ψ) is obtained by the fact that ∃(Φ U Ψ) is the least solution
of F
≡Ψ ∨(Φ ∧∃⃝F). Using a set-theoretical counterpart by means of Sat(·), we
obtain the following equivalent formulation of constraint (f) in Theorem 6.23:
(f′) Sat(∃(Φ U Ψ)) is the smallest set T ⊆S satisfying
Sat(Ψ) ∪{ s ∈Sat(Φ) | Post(s) ∩T ̸= ∅} ⊆T.
In fact, “⊆” may be replaced by “=”.
In a similar way, ∃□Φ can be considered as the greatest ﬁxed point of the logical equation
F = Φ ∧∃⃝F.
Using a set-theoretical counterpart of this equation we obtain the following equivalent
formulation of constraint (g) in Theorem 6.23:
(g′) Sat(∃□Φ) is the largest set T ⊆S satisfying
T ⊆{ s ∈Sat(Φ) | Post(s) ∩T ̸= ∅}.
Also in this characterization “⊆” may be replaced by “=”.
Characterizations of the satisfaction sets for universally quantiﬁed CTL formulae can be
obtained using the result in Theorem 6.23. This yields
(h) Sat(∀⃝Φ) = { s ∈S | Post(s) ⊆Sat(Φ) }.

CTL Model Checking
347
(i) Sat(∀(Φ U Ψ)) is the smallest set T ⊆S satisfying
Sat(Ψ) ∪{ s ∈Sat(Φ) | Post(s) ⊆T } ⊆T.
(j) Sat(∀□Φ) is the largest set T ⊆S satisfying
T ⊆{ s ∈Sat(Φ) | Post(s) ⊆T }.
Remark 6.25.
Weak Until
The weak-until operator satisﬁes the same expansion laws as the until operator.
∃(Φ W Ψ)
≡
Ψ
∨
(Φ ∧∃⃝∃(Φ W Ψ)),
∀(Φ W Ψ)
≡
Ψ
∨
(Ψ ∧∀⃝∀(Φ W Ψ)).
The diﬀerence, however, is that the weak-until operator represents the largest solution
(i.e., ﬁxed point) of the expansion law, whereas the until operator denotes the smallest
solution. The satisfaction sets for weak until are characterized as follows:
(k) Sat(∃(Φ W Ψ)) is the largest set T ⊆S satisfying
T ⊆Sat(Ψ) ∪{ s ∈Sat(Φ) | Post(s) ∩T ̸= ∅}.
(l) Sat(∀(Φ W Ψ)) is the largest set T ⊆S satisfying
T ⊆Sat(Ψ) ∪{ s ∈Sat(Φ) | Post(s) ⊆T }.
Without loss of generality, we may assume that the CTL formula Φ to be veriﬁed is in
ENF (see Theorem 6.14, page 332). That is, the model-checking algorithm is supposed to
be preceded by transforming the CTL formula at hand into ENF. The characterizations
of the satisfaction sets indicated in Theorem 6.23 are exploited to compute the sets Sat(·).
The essential steps for computing the satisfaction sets are summarized in Algorithm 14
on page 348.
6.4.2
The Until and Existential Always Operator
To treat constrained reachability properties, given by CTL formulae of the form ∃(Φ U Ψ),
the characterization in Theorem 6.23 is exploited. Recall that Sat(∃(Φ U Ψ)) is character-

348
Computation Tree Logic
Algorithm 14 Computation of the satisfaction sets
Input: ﬁnite transition system TS with state set S and CTL formula Φ in ENF
Output: Sat(Φ) = { s ∈S | s |= Φ }
(* recursive computation of the sets Sat(Ψ) for all subformulae Ψ of Φ *)
switch(Φ):
true
:
return S;
a
:
return { s ∈S | a ∈L(s) };
Φ1 ∧Φ2
:
return Sat(Φ1) ∩Sat(Φ2);
¬Ψ
:
return S \ Sat(Ψ);
∃⃝Ψ
:
return { s ∈S | Post(s) ∩Sat(Ψ) ̸= ∅};
∃(Φ1 U Φ2)
:
T := Sat(Φ2); (* compute the smallest ﬁxed point *)
while { s ∈Sat(Φ1) \ T | Post(s) ∩T ̸= ∅} ̸= ∅do
let s ∈{ s ∈Sat(Φ1) \ T | Post(s) ∩T ̸= ∅};
T := T ∪{ s };
od;
return T ;
∃□Φ
:
T := Sat(Φ);
(* compute the greatest ﬁxed point *)
while { s ∈T | Post(s) ∩T = ∅} ̸= ∅do
let s ∈{ s ∈T | Post(s) ∩T = ∅};
T := T \ { s };
od;
return T ;
end switch
ized as the smallest set T ⊆S, where S is the set of states in the transition system under
consideration, such that
(1) Sat(Ψ) ⊆T and (2) (s ∈Sat(Φ) and Post(s) ∩T ̸= ∅) ⇒s ∈T.
(6.1)
This characterization suggests adopting the following iterative procedure to compute
Sat(∃(Φ U Ψ)):
T0 = Sat(Ψ)
and
Ti+1 = Ti ∪{ s ∈Sat(Φ) | Post(s) ∩Ti ̸= ∅}.
Intuitively speaking, the set Ti contains all states that can reach a Ψ-state in at most i
steps via a Φ-path. This is to be understood as follows. From the fact that Sat(∃(Φ U Ψ))
satisﬁes the conditions (1) and (2) in (6.1), it can be demonstrated by induction on j that
T0 ⊆T1 ⊆T2 ⊆. . . ⊆Tj ⊆Tj+1 ⊆. . . ⊆Sat(∃(Φ U Ψ)).
Since we assume a ﬁnite transition system TS, there exists a j ⩾0 such that
Tj = Tj+1 = Tj+2 = . . .
.

CTL Model Checking
349
Therefore
Tj = Tj ∪{ s ∈Sat(Φ) | Post(s) ∩Tj ̸= ∅}
and, hence:
{ s ∈Sat(Φ) | Post(s) ∩Tj ̸= ∅} ⊆Tj.
Hence, Tj satisﬁes property (2). Further,
Sat(Ψ) = T0 ⊆Tj.
These considerations show that Tj possesses the properties (1) and (2). Since Sat(∃(Φ U Ψ))
is the smallest set of states satisfying the properties (1) and (2), it follows that
Sat(∃(Φ U Ψ)) ⊆Tj
and thus Sat(∃(Φ U Ψ)) = Tj. Hence, for any j ⩾0 we have
T0 ⫋T1 ⫋T2 ⫋. . . ⫋Tj = Tj+1 = . . . = Sat(∃(Φ U Ψ)).
Algorithm 15 (see page 351) shows a more detailed version of the backward search indicated
earlier in Algorithm 14 (see page 348).
As each Ψ-state obviously satisﬁes ∃(Φ U Ψ),
all states in Sat(Ψ) are initially considered to satisfy ∃(Φ U Ψ)). This conforms to the
initialization to the variable E. An iterative procedure is subsequently started that can
be considered to systematically check the state space in a “backward” manner. In each
iteration, all Φ-states are determined that can move by a single transition to (one of) the
states of which we already know to satisfy ∃(Φ U Ψ)). Thus, in the ith iteration of the
procedure, all Φ-states are considered that can move to a Ψ-state in at most i steps. This
corresponds to the set Ti. Termination of the algorithm intuitively follows, as the number
of states in the transition system is ﬁnite. Note that the algorithm assumes a transition
system representation (or its state graph) by means of “inverse” adjacency lists, i.e., list
representations for the sets of predecessors Pre(s′) = { s ∈S | s′ ∈Post(s) }.
Example 6.26.
Consider the transition system depicted in Figure 6.11, and suppose we are interested in
checking the formula ∃♦Φ with Φ = ((a = c) ∧(a ̸= b)). Recall that ∃♦Φ = ∃(true U Φ).
To check ∃♦Φ we invoke Algorithm 14 (see page 348). This algorithm recursively computes
Sat(true) and Sat((a = c) ∧(a ̸= b)).
This corresponds to the situation depicted in
Figure 6.12(a), where all states in the set T are colored black, and white otherwise. In the
ﬁrst iteration, we select and delete s5 from E, but as Pre(s5) = ∅, T remains unaﬀected.
On considering s4 ∈E, Pre(s4) = { s6 } is added to T (and E), see Figure 6.12(b).
During the next iteration, the only predecessor of s6 is added, yielding the snapshot in
Figure 6.12(c). After the fourth iteration, the algorithm terminates as there are no new
predecessors of Φ-states encountered, i.e., E = ∅(see Figure 6.12(d)).

350
Computation Tree Logic
{ a, b }
s1
s2
s3
s4
s5
s6
s7
{ a, b, c }
{ b, c }
{ b }
{ c }
∅
{ a }
{ a, c }
s0
Figure 6.11: An example of a transition system.
(a)
(b)
(d)
(c)
Figure 6.12: Example of backward search for ∃(true U (a=c) ∧(a̸=b)).

CTL Model Checking
351
Algorithm 15 Enumerative backward search for computing Sat(∃(Φ U Ψ))
Input: ﬁnite transition system TS with state set S and CTL formula ∃(Φ U Ψ)
Output: Sat(∃(Φ U Ψ)) = { s ∈S | s |= ∃(Φ U Ψ) }
E := Sat(Ψ);
(* E administers the states s with s |= ∃(Φ U Ψ) *)
T := E;
(* T contains the already visited states s with s |= ∃(Φ U Ψ) *)
while E ̸= ∅do
let s′ ∈E;
E := E \ { s′ };
for all s ∈Pre(s′) do
if s ∈Sat(Φ) \ T then E := E ∪{ s }; T := T ∪{ s } ﬁ
od
od
return T
Let us now consider the computation of Sat(∃□Φ) for the transition system TS. As for the
until-operator, the algorithm for ∃□Φ is based on the characterization in Theorem 6.23,
i.e., Sat(∃□Φ) is the largest set T ⊆S satisfying
T ⊆Sat(Φ)
and
(s ∈T implies T ∩Post(s) ̸= ∅).
The basic idea is to compute Sat(∃□Φ) by means of the iteration
T0 = Sat(Φ)
and
Ti+1 = Ti ∩{ s ∈Sat(Φ) | Post(s) ∩Ti ̸= ∅}.
Then, for all j ⩾0, it holds that
T0 ⫌T1 ⫌T2 ⫌. . . ⫌Tj = Tj+1 = . . . = T = Sat(∃□Φ).
The above iteration can be realized by means of a backward search starting with
T = Sat(Φ)
and
E = S \ Sat(Φ).
Here T equals T0 and E contains all states that refute ∃□Φ. During the backward search,
states are iteratively removed from T, for which it has been established that they refute
∃□Φ. This applies to any s ∈T satisfying
Post(s) ∩T = ∅.
Although s |= Φ (as it is in T), all its successors refute ∃□Φ (as they are not in T), and
therefore s refutes ∃□Φ. Once such states are encountered, they are inserted in E to
enable the possible removal of other states in T.

352
Computation Tree Logic
Algorithm 16 Enumerative backward search to compute Sat(∃□Φ)
Input: ﬁnite transition system TS with state set S and CTL formula ∃□Φ
Output: Sat(∃□Φ) = { s ∈S | s |= ∃□Φ }
E := S \ Sat(Φ);
(* E contains any not visited s′ with s′ ̸|= ∃□Φ *)
T := Sat(Φ);
(* T contains any s for which s |= ∃□Φ has not yet been disproven *)
for all s ∈Sat(Φ) do count[s] := | Post(s) |; od
(* initialize array count *)
while E ̸= ∅do
(* loop invariant: count[s] = | Post(s) ∩(T ∪E) | *)
let s′ ∈E;
(* s′ ̸|= Φ *)
E := E \ { s′ };
(* s′ has been considered *)
for all s ∈Pre(s′) do
(* update counters count[s] for all predecessors s of s′ *)
if s ∈T then
count[s] := count[s] −1;
if count[s] = 0 then
T := T \ { s };
(* s does not have any successor in T *)
E := E ∪{ s };
ﬁ
ﬁ
od
od
return T
The resulting computational procedure is detailed in Algorithm 16 on page 352. In order
to support the test whether Post(s) ∩T = ∅, a counter count[s] is exploited that keeps
track of the number of direct successors of s in T ∪E:
count[s] = | Post(s) ∩(T ∪E) |.
Once count[s] = 0, we have that Post(s)∩(T ∪E) = ∅, and hence Post(s)∩T = ∅. Thus,
state s is not in Sat(∃□Φ) and therefore can be safely removed from T. On termination,
E = ∅, and thus count[s] = | Post(s) ∩T |. It follows that any state s ∈Sat(Φ) for which
count[s] > 0 satisﬁes the CTL formula ∃□Φ.
It is left to the interested reader to consider how the outlined approach can be modiﬁed
to compute Sat(∃(Φ W Ψ)).

CTL Model Checking
353
Example 6.27.
Consider the transition system depicted in Figure 6.11 and the formula ∃□b. Initially,
T0 = { s0, s1, s2, s4 }
and
E = { s3, s5, s6, s7 }
and
count = [1, 1, 2, 1, 2, 2, 1, 2].
Suppose state s3 ∈E is selected in the ﬁrst iteration.
As s1 ∈Pre(s3) and s1 ∈T,
count[s1] := 0. Accordingly, s1 is deleted from T and added to E. This yields
T1 = { s0, s2, s4 }
and
E = { s1, s5, s6, s7 }
and
count = [1, 0, 2, 1, 2, 2, 1, 2].
We also have s7 ∈Pre(s3), but as s7 ̸∈T, this aﬀects neither count[s7], T nor E.
Suppose s6 and s7 are selected in the second and third iteration, respectively. None of
these states has a predecessor in T1, so we obtain
T3 = { s0, s2, s4 }
and
E = { s1, s5 }
and
count = [1, 0, 2, 1, 2, 2, 1, 2].
Now select s1 ∈E in the next iteration. As Pre(s1) ∩T3 = { s2, s4 }, the counters for s2
and s4 are decremented. This yields
T4 = { s0, s2, s4 }
and
E = { s5 }
and
count = [1, 0, 1, 1, 1, 2, 1, 2].
As Pre(s5) = ∅, T and count are unaﬀected in the subsequent iteration. As E = ∅, the
algorithm terminates and returns T = { s0, s2, s4 } as the ﬁnal outcome.
This section is concluded by outlining an alternative algorithm for computing Sat(∃□Φ).
Since the computation of the satisfaction sets takes place by means of a bottom-up traversal
through the parse tree of the formula at hand, it is assumed that Sat(Φ) is at our disposal.
A possibility to compute Sat(∃□Φ) is to only consider the Φ-states of transition system TS
and ignore all ¬Φ-states. The justiﬁcation of this modiﬁcation to TS is that all removed
states will not satisfy ∃□Φ (as they violate Φ) and therefore can be safely removed.
For TS = (S, Act, →, I, AP, L) let TS[Φ] = (S′, Act, →′, I′, AP, L′) with S′ = Sat(Φ),
→′ = →∩(S′ × Act × S′), I′ = I ∩S′ and L′(s) = L(s) for all s ∈S′.
Then, all
nontrivial strongly connected components (SCCs) 4 in the state graph induced by TS[Φ]
are computed. All states in each such SCC C satisfy ∃□Φ, as any state in C is reachable
from any other state in C, and—by construction—all states in C satisfy Φ. Finally, all
states in TS[Φ] are computed that can reach such SCC. If state s ∈S′ and there exists such
a path, then—by construction of TS[Φ]—the property ∃□Φ is satisﬁed by s; otherwise, it
is not. This can be done by a backward search. The worst-case time complexity of this
4A strongly connected component (SCC) of a digraph G is a maximal, connected subgraph of G. Stated
diﬀerently, the SCCs of a graph are the equivalence classes of vertices under the “are mutually reachable”
relation. A nontrivial SCC is an SCC that contains at least one transition.

354
Computation Tree Logic
(a)
(d)
(b)
(c)
{ b, c }
{ a, b, c }
{ a, b }
{ a, c }
{ a }
{ b }
{ c }
∅
TS[b]
non-trivial SCC in TS[b]
Figure 6.13: Computing Sat(∃□b) using strongly connected components in TS[Φ].
alternative algorithm is the same as for Algorithm 16. This approach is illustrated by the
following example.
Example 6.28.
Alternative Algorithm for ∃□Φ
Consider the transition system of Figure 6.11 and CTL formula ∃□b.
The modiﬁed
transition system TS[b] consists of the four states that are labeled with b, see the gray
states in Figure 6.13(a). The only nontrivial SCC of this structure is indicated by the
black states, see Figure 6.13(b). As there is only a single b-state (that is not in the SCC)
that can reach the nontrivial SCC, this state satisﬁes ∃□b, and the computation ﬁnishes,
see Figure 6.13(c).
Theorem 6.29.
For state s in transition system TS and CTL formula Φ:
s |= ∃□Φ iﬀs |= Φ and there is a nontrivial SCC in TS[Φ] reachable from s.
Proof: ⇒: Suppose s |= ∃□Φ. Clearly, s is a state in TS[Φ]. Let π be a path in TS
starting in s such that π |= □Φ. As TS is ﬁnite, π has a suﬃx ρ = s1 s2 . . . sk for k > 1,
representing a cycle that is traversed inﬁnitely often. As π is also a path in TS[Φ], the

CTL Model Checking
355
states s1 through sk are all in TS[Φ]. Since π is traversed inﬁnitely often, it represents
a cycle, and thus any pair of states si and sj is mutually reachable. Stated diﬀerently,
{ s1, . . . , sk } is either an SCC or contained in some SCC in TS[Φ]. As π is a path starting
in s, these states are reachable from s.
⇐: Suppose s is a state in TS[Φ] and there exists an SCC in TS[Φ] reachable from s. Let
s′ be a state in such SCC. As the SCC is nontrivial, s′ is reachable from itself by a path
of length at least one. Repeating this cycle inﬁnitely often yields an inﬁnite path π with
π |= □Φ. The path from s to s′ followed by π[1..] now satisﬁes □Φ and starts in s. Thus,
s |= ∃□Φ.
6.4.3
Time and Space Complexity
The time complexity of the CTL model-checking algorithm is determined as follows. Let
TS be a ﬁnite transition system with N states and K transitions. Under the assumption
that the sets of predecessors Pre(·) are represented as linked lists, the time complexity of
Algorithms 15 and 16 lies in O(N+K). Given that the computation of the satisfaction
sets Sat(Φ) is a bottom-up traversal over the parse tree of Φ and thus linear in | Φ |, the
time complexity of Algorithm 14 (see page 348) is in
O((N+K) · | Φ |).
When the initial states of TS are administrated in, e.g., a linked list, checking whether
I ⊆Sat(Φ) can be done in O(N0) where N0 is the cardinality of the set I. Recall that the
CTL model-checking algorithm requires the CTL formula to be checked to be in existential
normal form. As the transformation of any CTL formula into an equivalent CTL formula
in ENF may yield an exponential blowup of the formula, it is recommended to treat
the modalities such as ∀U, ∀♦, ∀□, ∃♦, ∀W , and ∃W , analogous to the introduced
approaches for ∃U and ∃□, by exploiting the characterizations of Sat(∀□Φ), Sat(∃♦Φ),
and so on. The resulting algorithms are all linear in N and K. Thus, we obtain the
following theorem:
Theorem 6.30.
Time Complexity of CTL Model Checking
For transition system TS with N states and K transitions, and CTL formula Φ, the CTL
model-checking problem TS |= Φ can be determined in time O ((N+K) · | Φ |).
Let us compare this complexity bound with that for LTL model checking. Recall that LTL
model checking is exponential in the size of the formula. Although the diﬀerence in time
complexity with respect to the length of the formula seems drastic (exponential for LTL vs.

356
Computation Tree Logic
linear for CTL), this should not be interpreted as “CTL model checking is more eﬃcient
than LTL model checking”. From Theorem 6.18 it follows that whenever ϕ ≡Φ for LTL
formula ϕ and CTL formula Φ, then ϕ is obtained by removing all path quantiﬁers in Φ.
Thus, CTL formulae are at least as long as their equivalent counterparts in LTL (if these
exist). In fact, if P ̸= NP, then there exist LTL formulae ϕn with | ϕn | ∈O(poly(n)) for
which CTL-equivalent formulae do exist, but not of polynomial length. LTL formulae may
be exponentially shorter than any of their equivalent formulation in CTL. The latter eﬀect
is illustrated in the following example. From Lemma 5.45, it follows that the Hamiltonian
path problem for digraphs with n nodes can be encoded in LTL formula ϕn whose length
is polynomial in n. More precisely, given a digraph G with nodeset { 1, . . . , n } there is an
LTL formula ϕn such that (1) G has a Hamiltonian path if and only if ¬ϕn does not hold
for the transition system associated with G and (2) ¬ϕn has an equivalent CTL formula.
To express the existence of a Hamiltonian path in CTL requires a CTL formula of expo-
nential length, unless P = NP: if it is assumed that ¬ϕn ≡¬Φn for CTL formulae Φn
of polynomial length, then the Hamiltonian path problem could be solved by CTL model
checking, and thus in polynomial time. Since, however, the Hamiltonian path problem is
NP-complete, this is only possible for the case of PTIME = NP.
Example 6.31.
The Hamiltonian Path Problem
Consider the NP-complete problem of ﬁnding a Hamiltonian path in an arbitrary, con-
nected, directed graph G = (V, E) where V denotes the set of vertices and E ⊆V × V ,
the set of edges. Let V = { v1, . . . , vn }. A Hamiltonian path is a (ﬁnite) path through the
graph G which visits each state exactly once. Starting from graph G, a transition system
TS(G) is derived as well as a CTL formula Φn, such that
G contains a Hamiltonian path if and only if TS ̸|= ¬Φn.
The transition system TS is deﬁned as follows
TS = (V ∪{ b }, { τ }, →, V, V, L)
with L(vi) = { vi }, L(b) = ∅. The transition relation →is deﬁned by
(vi, vj) ∈E
vi
τ
−→vj
and
vi ∈V ∪{ b }
vi
τ
−→b
.
All vertices of G are states in the transition system TS. A new state b is introduced
that is a direct successor of any state (including b). Figure 6.14 shows (a) an example
of a directed graph G and (b) its transition system TS(G). The sole purpose of the new
state b is to ensure that the transition system has no terminal states. Note that TS(G)
is deﬁned as in the proof for the existence of a polynomial reduction of the Hamiltonian

CTL Model Checking
357
v1
v2
v3
v4
(a)
v1
v2
v3
v4
b
(b)
{v1}
{v2}
{v4}
{v3}
{b}
Figure 6.14: Example of encoding the Hamiltonian path problem as a transition system.
path problem onto the complement of the LTL model-checking problem; see Lemma 5.45
on page 288.
It remains to give a recipe for the construction of Φn, a CTL formula that captures the
existence of a Hamiltonian path. Let Φn be deﬁned as follows:
Φn =
!
(i1,...,in)
permutation of (1, . . . , n)
Ψ(vi1, vi2, . . . , vin)
such that Ψ(vi1, . . . , vin) is a CTL formula that is satisﬁed if and only if vi1, vi2,. . . , vin is
a Hamiltonian path in G. The formulae Ψ(vi1, . . . , vin) are inductively deﬁned as follows:
Ψ(vi)
=
vi
Ψ(vi1, vi2, . . . , vin)
=
vi1 ∧∃⃝Ψ(vi2, . . . , vin)
if n > 1.
Stated in words, Ψ(vi1, . . . , vin) holds if there exists a path on which vi1, vi2, vi3 successively
hold. Since each state has a transition to the b state, the trace { vi1 } { vi2 } . . . { vin } can
be extended with { b }ω. An example of an instantiation of Ψn is
Φ2 = (v1 ∧∃⃝v2) ∨(v2 ∧∃⃝v1)
and
Φ3
=
(v1 ∧∃⃝(v2 ∧∃⃝v3))
∨
(v1 ∧∃⃝(v3 ∧∃⃝v2))
∨(v2 ∧∃⃝(v1 ∧∃⃝v3))
∨
(v2 ∧∃⃝(v3 ∧∃⃝v1))
∨(v3 ∧∃⃝(v1 ∧∃⃝v2))
∨
(v3 ∧∃⃝(v2 ∧∃⃝v1)).
It is not diﬃcult to infer that
Sat( Ψ(vi1, . . . , vin) ) =

{ vi1 }
if vi1, . . . , vin is a Hamiltonian path in G
∅
otherwise.
Thus:

358
Computation Tree Logic
TS ̸|= ¬Φn
iﬀ
there is an initial state s of TS for which s ̸|= ¬Φn
iﬀ
there is an initial state s of TS for which s |= Φn
iﬀ
∃v in G and a permutation i1, . . . , in of 1, . . . , n with
v ∈Sat(Ψ(vi1, . . . , vin)),
iﬀ
∃v in G and a permutation i1, . . . , in of 1, . . . , n,
such that v = vi1 and vi1, . . . , vin is a Hamiltonian path in G
iﬀ
G has a Hamiltonian path.
Thus, G contains a Hamiltonian path if and only if TS ̸|= ¬Φn.
By the explicit enumeration of all possible permutations we obtain a formula with a length
that is exponential in the number of vertices in the graph. This does not prove that there
does not exist an equivalent, but shorter, CTL formula which describes the Hamiltonian
path problem. Actually, shorter formalizations in CTL cannot be expected, since the CTL
model-checking problem is polynomially solvable whereas the Hamiltonian path problem
is NP-complete.
6.5
Fairness in CTL
Recall that fairness assumptions (see Section 3.5) are used to rule out certain computations
that are considered to be unrealistic for the system under consideration. These unreason-
able computations that ignore certain transition alternatives forever are the “unfair” ones;
the remaining computations are thus the “fair” ones. As there are diﬀerent notions of fair-
ness, various distinct forms of fairness can be imposed: unconditional, strong, and weak
fairness constraints.
An important distinction between LTL and CTL is that fairness assumptions can be
incorporated into LTL without any speciﬁc changes while a special treatment of fairness
is required for CTL. That is to say, fairness assumptions can be added as premise to the
LTL formula to be veriﬁed. The LTL model-checking problem where only fair paths are
considered (i.e., considering the fair satisfaction relation |=fair) can thus be reduced to
the traditional LTL model-checking problem, i.e., with respect to the common satisfaction
relation |=. In this case, the LTL formula ϕ to be veriﬁed is replaced by fair →ϕ:
TS |=fair ϕ
if and only if
TS |= (fair →ϕ).5
5This observation is mainly of theoretical interest since it is more eﬃcient to design special LTL model-

Fairness in CTL
359
For more details we refer to Section 5.1.6 (see page 257).
An analogous approach is not possible for CTL.
This stems from the fact that most
fairness constraints cannot be encoded in a CTL formula. An indication of this is the fact
that persistence properties ♦□a are inherent in, e.g., strong fairness conditions □♦b →
□♦c ≡♦□¬b ∨□♦c and cannot be expressed in CTL. To be a bit more precise: fairness
constraints operate on the path level and replace the standard meaning “for all paths”
of universal quantiﬁcation with “for all fair paths” and existential quantiﬁcation “there
exists a path” with “there exists a fair path”. Thus, if fair expresses the fairness condition
on the path level, then CTL formulae that encode the intuitive meaning of ∀(fair →ϕ)
and ∃(fair ∧ϕ) would be needed. However, these are not legal CTL formulae since (1) the
Boolean connectives →and ∧are not allowed on the level of CTL path formulae and (2)
fairness conditions cannot be described by CTL path formulae.
Therefore, an alternative approach is taken to treat fairness in CTL. In order to deal with
fairness constraints in CTL, the semantics of CTL is slightly modiﬁed such that the state
formulae ∀ϕ and ∃ϕ are interpreted over all fair paths rather than over all possible paths.
A fair path is a path that satisﬁes a set of fairness constraints. It is assumed that the
given ﬁxed fairness constraint is described by a formula as in LTL.
Deﬁnition 6.32.
CTL Fairness Assumptions
A strong CTL fairness constraint (over AP) is a term of the form
sfair =

1⩽i⩽k
(□♦Φi →□♦Ψi)
where Φi and Ψi (for 1 ⩽i ⩽k) are CTL formulae over AP.
Weak and unconditional
CTL fairness constraints are deﬁned analogously by conjunctions of terms of the form
(♦□Φi →□♦Ψi) and □♦Ψi, respectively. A CTL fairness assumption is a conjunction
of strong, weak, and unconditional CTL fairness constraints.
Note that CTL fairness assumptions are not CTL path formulae, but they can be viewed
as LTL formulae using CTL state formulae instead of atomic propositions. For instance,
imposing the strong fairness constraint

1⩽i⩽k
(□♦Φi →□♦Ψi) on paths means that a
path must either have only ﬁnitely many states satisfying Φi or inﬁnitely many states
satisfying Ψi, for any 1 ⩽i ⩽k (or both).
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states, π be an
inﬁnite path fragment in TS, and fair a ﬁxed CTL fairness assumption. π |= fair denotes
checking algorithms when dealing with fairness assumptions than to apply the reduction to the standard
semantics |=.

360
Computation Tree Logic
that π satisﬁes the formula fair, where |= should be read as the LTL semantics. Consider,
for example, strong fairness. For an inﬁnite path π = s0 s1 s2 . . ., we have
π |=

1⩽i⩽k
(□♦Φi →□♦Ψi)
if and only if for every i ∈{ 1, . . . , k } either sj |= Φi for ﬁnitely many indices j, or
sj |= Ψi for inﬁnitely many j (or both). Here, the statement sj |= Φi should be interpreted
according to the CTL semantics, that is, the semantics without taking any fairness into
account.
The semantics of CTL under fairness assumption fair is identical to the semantics given
earlier (see Deﬁnition 6.4), except that the path quantiﬁcations range over all fair paths
rather than over all paths. The fair paths starting in state s are deﬁned as
FairPaths(s) = {π ∈Paths(s) | π |= fair}.
Let FairPaths(TS) denote the set of all fair paths in TS, i.e.:
FairPaths(TS) =

s0∈I
FairPaths(s0).
The fair interpretation of CTL is deﬁned in terms of the satisfaction relation |=fair. We
have s |=fair Φ if and only if Φ is valid in state s under the fairness assumption fair.
Deﬁnition 6.33.
Satisfaction Relation for CTL with Fairness
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states and s ∈
S. The satisfaction relation |=fair for CTL fairness assumption fair is deﬁned for state
formulae by
s |=fair a
iﬀ
a ∈L(s)
s |=fair ¬ Φ
iﬀ
not s |=fair Φ
s |=fair Φ ∧Ψ
iﬀ
(s |=fair Φ) and (s |=fair Ψ)
s |=fair ∃ϕ
iﬀ
π |=fair ϕ for some π ∈FairPaths(s)
s |=fair ∀ϕ
iﬀ
π |=fair ϕ for all π ∈FairPaths(s)
Here, a ∈AP, Φ, Ψ are CTL state formulae, and ϕ a CTL path formula. For path π, the
satisfaction relation |=fair for path formulae is deﬁned as in Deﬁnition 6.4:
π |=fair ⃝Φ
iﬀ
π[1] |=fair Φ
π |=fair Φ U Ψ
iﬀ
∃j ⩾0. (π[j] |=fair Ψ ∧(∀0 ⩽k < j. π[k] |=fair Φ))

Fairness in CTL
361
where for path π = s0 s1 s2 . . . and integer i ⩾0, π[i] denotes the (i+1)-th state of π, i.e.,
π[i] = si.
Whereas for LTL, fairness constraints can be speciﬁed as part of the formula to be checked,
for CTL similar constraints are imposed on the underlying model of the system under
consideration, i.e., the transition system.
Deﬁnition 6.34.
CTL Semantics with Fairness for Transition Systems
For CTL-state formula Φ, and CTL fairness assumption fair, the satisfaction set Satfair(Φ)
is deﬁned by
Satfair(Φ) = { s ∈S | s |=fair Φ }.
The transition system TS satisﬁes CTL formula Φ under fairness assumption fair if and
only if Φ holds in all initial states of TS:
TS |=fair Φ
if and only if
∀s0 ∈I. s0 |=fair Φ.
This is equivalent to I ⊆Satfair(Φ).
Example 6.35.
CTL Fairness Assumption
Consider the transition system TS depicted in Figure 6.15 and suppose we are interested in
establishing whether or not TS |= ∀□(a ⇒∀♦b). This formula is invalid since the path
s0 s1 (s2 s4)ω never goes through a b-state. The reason that this property is not valid is as
follows. At state s2 there is a nondeterministic choice between moving either to state s3
or to s4. By continuously ignoring the possibility of going to s3 we obtain a computation
for which ∀□(a ⇒∀♦b) is invalid, hence:
TS ̸|= ∀□(a ⇒∀♦b).
Usually, though, the intuition is that if there is inﬁnitely often a choice of moving to s3,
then s3 should be visited in some fair way.
Let us impose the unconditional fairness assumption:
fair ≡□♦a ∧□♦b.
We now check ∀□(a ⇒∀♦b) under fair, i.e., consider the veriﬁcation problem TS |=fair
∀□(a ⇒∀♦b). Due to the fairness assumption, paths like s0 s1 (s2 s4)ω are excluded,
since s3 is never visited along this path. It can now easily be established that
TS |=fair ∀□(a ⇒∀♦b)
.

362
Computation Tree Logic
s1
s2
s3
s4
s0
{a}
{a}
{a}
{b}
{a}
Figure 6.15: An example of a transition system.
Example 6.36.
Mutual Exclusion
Consider the semaphore-based solution to the two-process mutual exclusion problem. The
transition system of this concurrent program is denoted TSsem. The CTL formula
Φ = (∀□∀♦crit1) ∧(∀□∀♦crit2)
describes the liveness property that both processes inﬁnitely often have access to the
critical section. It follows that TSsem ̸|= Φ. We ﬁrst impose the weak fairness assumption
wfair = (♦□noncrit1 →□♦wait1) ∧(♦□noncrit2 →□♦wait2)
and the strong fairness assumption
sfair = (□♦wait1 →□♦crit1) ∧(□♦wait1 →□♦crit1) .
It then follows that TSsem |=fair Φ where fair = wfair ∧sfair.
As a second example, consider the arbiter-based solution to the two-process mutual exclu-
sion problem, see Example 5.27 on page 259. The decision as to which process will acquire
access to the critical section is determined by coin ﬂipping by the arbiter. Consider the
unconditional fairness assumption
ufair = □♦head ∧□♦tail.
This fairness assumption can be considered to require a fair coin such that the events
“heads” and “tails” occur inﬁnitely often with probability 1. Apparently, it follows that
TS1 ∥Arbiter ∥TS2 ̸|= Φ,
and
TS1 ∥Arbiter ∥TS2 |=ufair Φ.

Fairness in CTL
363
As explained before, fairness is treated in CTL by considering a fair satisfaction relation,
denoted |=fair where fair is the fairness assumption considered. In the remainder of this
section, algorithms will be provided in order to check whether
TS |=fair Φ
for CTL formula Φ and CTL-fairness assumption fair.
As before, TS is supposed to
be ﬁnite and have no terminal states and Φ is a CTL formula in ENF. Note that the
assumption that Φ is in ENF does not impose any restriction as any CTL formula can be
transformed into an equivalent (with respect to |=fair) CTL formula in ENF. This can be
established in the same way as Theorem 6.14 (page 332).
The basic idea is to exploit the CTL model-checking algorithms (without fairness) to
compute Satfair(Φ) = { s ∈S | s |=fair Φ }.
Suppose fair is the strong CTL fairness
constraint:
fair =

0<i⩽k
(□♦Φi →□♦Ψi)
where Φi and Ψi are CTL formulae over AP.
Recall that Φi and Ψi are interpreted
according to the standard CTL semantics, i.e., without taking any fairness assumptions
into account. By applying the CTL model-checking algorithm, ﬁrst the sets Sat(Φi) and
Sat(Ψi) are determined. The formulae Φi and Ψi can thus be replaced by (fresh) atomic
propositions ai and bi, say. It thus suﬃces to consider strong fairness assumptions of the
form
fair =

0<i⩽k
(□♦ai →□♦bi) .
Once the fairness assumption is simpliﬁed, the sets Satfair(Ψ) are determined for all subfor-
mulae Ψ of Φ using the standard CTL model-checking algorithm (i.e., without fairness),
together with an algorithm to compute Satfair(∃□a) for a ∈AP. The outcome of the
model-checking procedure is “yes” if I ⊆Satfair(Φ), and “no” otherwise.
The essential ideas are outlined in Algorithm 17 (page 364).
The subformulae of Φ are treated as in the CTL model-checking routine. Based on the
syntax tree of Φ, a bottom-up computation is initiated. It is essential that during the
computation of Satfair(Ψ), the maximal genuine subformulae of Ψ have been already
processed and replaced by atomic propositions.
For the propositional logic fragment,

364
Computation Tree Logic
Algorithm 17 CTL model checking with fairness (basic idea)
Input: ﬁnite transition system TS, CTL formula Φ in ENF, and CTL fairness assumption fair over
k CTL state formulae Φi and Ψi
Output: TS |=fair Φ
for all 0 < i ⩽k do
determine Sat(Φi) and Sat(Ψi)
if s ∈Sat(Φi) then L(s) := L(s) ∪{ ai }; ﬁ
if s ∈Sat(Ψi) then L(s) := L(s) ∪{ bi }; ﬁ
od
compute Satfair(∃□true) = { s ∈S | FairPaths(s) ̸= ∅};
forall s ∈Satfair(∃□true) do L(s) := L(s) ∪{ afair; } od
(* compute Satfair(Φ) *)
for all i ⩽| Φ | do
for all Ψ ∈Sub(Φ) with | Ψ | = i do
switch(Ψ):
true
:
Satfair(Ψ) := S;
a
:
Satfair(Ψ) := { s ∈S | a ∈L(s) };
a ∧a′
:
Satfair(Ψ) := { s ∈S | a, a′ ∈L(s) };
¬a
:
Satfair(Ψ) := { s ∈S | a ̸∈L(s) };
∃⃝a
:
Satfair(Ψ) := Sat(∃⃝(a ∧afair));
∃(a U a′)
:
Satfair(Ψ) := Sat(∃(a U (a′ ∧afair)));
∃□a
:
compute Satfair(∃□a)
end switch
replace all occurrences of Ψ in Φ by the atomic proposition aΨ;
forall s ∈Satfair(Ψ) do L(s) := L(s) ∪{ aΨ } od
od
od
return I ⊆Satfair(Φ)

Fairness in CTL
365
the approach is straightforward:
Satfair(true)
=
S
Satfair(a)
=
{ s ∈S | a ∈L(s) }
Satfair(¬a)
=
S \ Satfair(a)
Satfair(a ∧a′)
=
Satfair(a) ∩Satfair(a′).
For all nodes of the syntax tree that are labeled with either ∃⃝or ∃U (i.e, nodes that
represent a subformula of the form Ψ = ∃⃝a or of the form Ψ = ∃(a U a′)), the following
observation is used. For any inﬁnite path fragment π in TS, π is fair if and only if one (or
all) suﬃx(es) of π is (are) fair:
π |= fair
iﬀ
π[j..] |= fair for some j ⩾0
iﬀ
π[j..] |= fair for all j ⩾0.
The following two lemmas provide the ingredients for checking subformulae of the “type”
∃⃝and ∃U.
Lemma 6.37.
Next Step for Fair Satisfaction Relation
s |=fair ∃⃝a if and only if ∃s′ ∈Post(s) with s′ |= a and FairPaths(s′) ̸= ∅.
Proof: ⇒: Assume s |=fair ∃⃝a.
Then there exists a fair path π = s0 s1 s2 s3 . . . ∈
Paths(s) with s1 |= a. Since π is fair, the path π[1..] = s1 s2 s3 . . . is fair too. Thus,
s′ = s1 ∈Post(s) satisﬁes the indicated property.
⇐: Assume s′ |= a and FairPaths(s′) ̸= ∅for some s′ ∈Post(s). Thus there exists a fair
path
π′ = s′ s′
1 s′
2 s′
3 . . .
starting in s′. Therefore, π = s s′ s′
1 s′
2 s′
3 . . . is a fair path starting s such that π |= ⃝a.
Thus, s |=fair ∃⃝a.
Using analogous arguments we obtain:
Lemma 6.38.
Until for Fair Satisfaction Relation
s |=fair ∃(a1 U a2) if and only if there exists a ﬁnite path fragment
s0 s1 s2 s3 . . . sn ∈Pathsﬁn(s)
with n ⩾0
such that si |= a1 for 0 ⩽i < n, sn |= a2, and FairPaths(sn) ̸= ∅.
The results of the previous two lemmas lead to the following approach. As a ﬁrst step,
the set
Satfair(∃□true) = { s ∈S | FairPaths(s) ̸= ∅}

366
Computation Tree Logic
is computed. (The algorithmic way to do so is explained later in this chapter.) That is,
all states are determined for which it is guaranteed that at least one fair path emanates.
Once such a state is visited, it is thus guaranteed that a fair continuation is possible. The
labels of the thus computed states are extended with the new atomic proposition afair,
i.e.:
afair ∈L(s)
if and only if
s ∈Satfair(∃□true).
The sets Satfair(∃⃝a) and Satfair(∃(a U a′)) result from
Satfair(∃⃝a)
=
Sat (∃⃝(a ∧afair)) ,
Satfair(∃(a U a′))
=
Sat (∃(a U (a′ ∧afair))) .
As a result, these satisfaction sets can be computed using an ordinary CTL model checker.
These considerations lead to Algorithm 17 on page 364 and provide the basis for the
following result:
Theorem 6.39.
Model-Checking CTL with Fairness
The model-checking problem for CTL with fairness can be reduced to
• the model-checking problem for CTL (without fairness), and
• the problem of computing Satfair(∃□a) for the atomic proposition a.
Note that the set Satfair(∃□true) corresponds to Satfair(∃□a) whenever every state is
labeled with a. Thus, an algorithm to compute Satfair(∃□a) can also be used to compute
Satfair(∃□true).
In the following, we explain how to compute the satisfaction set Satfair(∃□a) for a ∈AP
in case fair is a strong CTL fairness assumption.
Weak fairness assumptions can be
treated in an analogous way. As we will see, unconditional fairness assumptions are a
special case. Arbitrary fairness assumptions with unconditional, strong, and weak fairness
constraints can be treated by using algorithms in which the corresponding techniques are
appropriately combined.
Consider the strong CTL fairness assumption over the atomic propositions ai and bi (0 <
i ⩽k):
sfair =

0<i⩽k
(□♦ai →□♦bi).
The following lemma provides a graph-theoretical characterization of the fair satisfaction
set Satsfair(∃□a) where a is an atomic proposition.

Fairness in CTL
367
Lemma 6.40.
Characterization of Satsfair(∃□a)
s |=sfair ∃□a if and only if there exists a ﬁnite path fragment s0 s1 . . . sn and a cycle
s′
0 s′
1 . . . s′
r such that
(1) s0 = s
and
sn = s′
0 = s′
r,
(2) si |= a, for any 0 ⩽i ⩽n, and s′
j |= a, for any 0 < j ⩽r, and
(3) Sat(ai) ∩{ s′
1, . . . , s′
r } = ∅or Sat(bi) ∩{ s′
1, . . . , s′
r } ̸= ∅for all 1 ⩽i ⩽k.
Proof: ⇐: Assume there exists a ﬁnite path fragment s0 s1 . . . sn and a cycle s′
0 s′
1 . . . s′
r
such that the conditions (1) through (3) hold for state s.
Consider the inﬁnite path
fragment π = s0 s1 . . . sn s′
1 . . . s′
r s′
1 . . . s′
r . . . ∈Paths(s) which is obtained by traversing
the cycle s′
0 s′
1 . . . s′
r inﬁnitely often. From constraints (1) and (3), it follows that π is fair,
i.e., π |= sfair. From (2), it follows that π |= □a. Thus, s |=sfair ∃□a.
⇒: Assume s |=sfair ∃□a. Since s |=sfair ∃□a, there exists an inﬁnite path fragment
π = s0 s1 s2 . . . with π |= □a and π |= sfair. Let i ∈{ 1, . . . , k }. Distinguish between
two cases:
1. π |= □♦ai. Since π |= sfair, there is a state s′ ∈Sat(bi) which is inﬁnitely often
visited in π . Let n ∈IN such that sn = s′ and s′ ̸∈{ s0, s1, . . . , sn−1 }. That is,
sn is the ﬁrst occurrence of s′ in π. Further, let r > n such that sn = sr. Then
sn sn+1 . . . sr−1 sr = sn is a cycle with
sn ∈Sat(bi) ∩{ sn, sn+1, . . . , sr−1, sr }.
2. π ̸|= □♦ai. Then there exists an index n such that sn, sn+1, sn+2 . . . ̸∈Sat(ai). As-
sume without loss of generality that sn occurs inﬁnitely often in π. Since there are
ﬁnitely many states, there exists an r > n such that sn = sr. Thus, sn sn+1 . . . sr−1 sr =
sn is a cycle with Sat(ai) ∩{ sn, sn+1, . . . , sr−1, sr } = ∅.
From both cases it follows that there exists a ﬁnite path fragment s0 s1 . . . sn and a cycle
s′
0 . . . s′
r satisfying the constraints (1) through (3).
This characterization is used to compute Satsfair(∃□a) in the following way. Consider the
directed graph G[a] = (S, Ea) whose set of edges Ea is deﬁned as
(s, s′) ∈Ea
if and only if
s′ ∈Post(s) ∧s |= a ∧s′ |= a.

368
Computation Tree Logic
Stated in words, G[a] is obtained from the state graph GTS by eliminating all edges (s, s′)
for which either s ̸|= a or s′ ̸|= a. (Thus, G[a] is the state graph of the transition system
TS[a].) Apparently, each inﬁnite path in G[a] (that starts in s ∈I) corresponds to an
inﬁnite path in the transition system TS satisfying □a. Conversely, each inﬁnite path
fragment π of TS with π |= □a is a path in G[a]. In particular,
s |=sfair ∃□a
if and only if there exists a nontrivial, strongly connected set of nodes D in G[a] that is
reachable from s, such that for all 1 ⩽i ⩽k:
D ∩Sat(ai) = ∅
or
D ∩Sat(bi) ̸= ∅.
Let T be the union of all nontrivial strongly connected components C in the graph G[a]
such that sfair is realizable in C, i.e., there exists a nontrivial strongly connected subset
D of C satisfying D ∩Sat(ai) = ∅or D ∩Sat(bi) ̸= ∅, for all 1 ⩽i ⩽k. It then follows
that
Satsfair(∃□a) = { s ∈S | ReachG[a](s) ∩T ̸= ∅}.
Here, ReachG[a](s) is the set of states that is reachable from s in G[a]. Note that as SCC
D is contained in SCC C, D can be reached from any state in C; reachability of C is thus
of relevance.
The key part of the model-checking algorithm is now the computation of the set T. This
amounts to investigating the SCCs C of G[a] and checking for which SCC sfair is realizable.
As the computation of T for the general case is slightly involved, we ﬁrst consider two
special (and simpler) cases: ai = true for all i, i.e., unconditional fairness, and the case
for which k=1, i.e., a single strong fairness constraint.
In the sequel, each set C of nodes in G[a] is identiﬁed with the subgraph (C, EC) where
EC results from the edge relation in G[a] by removing all edges with starting or target
vertex not in C.
Unconditional Fairness
Let ai = true for all 1 ⩽i ⩽k. In this case
sfair ≡

1⩽i⩽k
□♦bi.
Obviously, s |=sfair ∃□a if and only if there exists a nontrivial SCC C in G[a] that is
reachable from s, such that C contains at least one bi-state for any i. In that case, □♦bi
is realizable in SCC C, for any i. Let T be the set union of all nontrivial SCCs C of G[a]
satisfying C ∩Sat(bi) ̸= ∅for all 1 ⩽i ⩽k. It now follows that
s |=sfair ∃□a
if and only if
ReachG[a](s) ∩T ̸= ∅.

Fairness in CTL
369
The following example illustrates this.
Example 6.41.
Consider the transition systems TS (upper) and TS′ (lower) in which it is implicitly as-
sumed that all states are labeled with the atomic proposition a:
s1
s0
s2
{ b1 }
s3
s4
{ b2 }
s′
1
{ b1 }
s′
0
s′
2
s′
3
s′
4
{ b2 }
(Due to this assumption, TS[a] = TS and TS′[a] = TS′.) Consider the unconditional
fairness assumption:
sfair = □♦b1 ∧□♦b2.
The transition system TS contains the reachable nontrivial SCC C = { s2, s3, s4 } such
that C ∩Sat(b1) ̸= ∅and C ∩Sat(b2) ̸= ∅. We thus have s0 |=sfair ∃□a, and hence
TS |=sfair ∃□a. On the other hand, TS′ contains two non-trivial SCCs, but none that
contains a b1-state and a b2-state. Therefore s′
0 ̸|=sfair ∃□a and hence TS′ ̸|=sfair ∃□a.
Strong Fairness with a Single Fairness Constraint
Assume k=1.
i.e., sfair is
assumed to be of the form
sfair = □♦a1 →□♦b1.
We have that s |=sfair ∃□a if and only if there exists a nontrivial strongly connected
component C of G[a] with C ⊆ReachG[a](s) such that at least one of the following two
conditions (1) or (2) holds:
(1) C ∩Sat(b1) ̸= ∅, or
(2) D ∩Sat(a1) = ∅for some nontrivial SCC D of C.

370
Computation Tree Logic
Algorithm 18 Computation of Satsfair(∃□a)
Input: A ﬁnite TS without terminal states, a ∈AP and fair = 
0<i⩽k sfair i with sfair i = □♦ai →
□♦bi
Output: { s ∈S | s |=fair ∃□a }
compute the SCCs of the state graph G[a] of TS[a];
T := ∅;
for all nontrivial SCCs C in G[a] do
(* check whether the fairness assumption sfair can be realized in C *)
if CheckFair(C, k, sfair 1, . . . , sfair k) then
T := T ∪C;
ﬁ
od
return { s ∈S | ReachG[a](s) ∩T ̸= ∅}
(* e.g., backwards reachability *)
Intuitively, in case (1) C stands for a cyclic set of states that realizes □♦b1, while D in (2)
represents a cyclic set of states for which ¬a1 continuously holds. The SCCs D of C that
do not contain any a1-state can easily be computed by determining the nontrivial SCCs
in the graph that is obtained from C by eliminating all a1-states. (Stated diﬀerently, C
realizes the unconditional fairness constraint □♦b1, while D realizes the unconditional
fairness constraint □♦true in the transition system induced by C after eliminating all a1-
states. This characterization is helpful to understand the general algorithm below.) Every
path that has a suﬃx consisting of the inﬁnite repetition of a cycle that runs through all
states of C (case (1)) or that eventually reaches D and stays there forever satisﬁes the
fairness assumption sfair. Accordingly, we may deﬁne T as the union of all nontrivial
SCCs C of G[a] satisfying the above constraints (1) and (2). Then, s |=sfair ∃□a if and
only if ReachG[a](s) ∩T ̸= ∅.
Strong Fairness with k > 1 Fairness Constraints
In this case, sfair is deﬁned for
k > 1 by
sfair =

1⩽i⩽k
sfairi
with
sfair i = □♦ai →□♦bi.
As for the other cases, the initial step is to determine G[a] and its set of SCCs. We have
to compute all nontrivial SCCs C such that for some cyclic subset D of C all fairness
constraints □♦ai →□♦bi are realizable in D, i.e., for 1 ⩽i ⩽k:
D ∩Sat(ai) = ∅
or
D ∩Sat(bi) ̸= ∅.
Algorithm 18 on page 370 provides the schema for the computation of Satsfair(∃□a). It
uses the recursive procedure CheckFair (see Algorithm 19, page 372) to check the real-

Fairness in CTL
371
izability of sfair in SCC C of G[a]. The inputs of CheckFair are a cyclic strongly con-
nected subgraph D of G[a], index j, and j strong fairness assumptions sfair i1, . . . , sfair ij.
CheckFair(D, j, sfair i1, . . . , sfair ij) returns true if 
1⩽ℓ⩽j sfair iℓis realizable in D. Thus,
the invocation CheckFair(C, k, sfair 1, . . . , sfair k) yields an aﬃrmative answer whether
C ⊆T by returning true if and only if the fairness assumption sfair = 
1⩽i⩽k sfairi is
realizable in C.
The idea of Algorithm 19, CheckFair(C, k, sfair 1, . . . , sfair k), is as follows.
First, it is
checked whether C ∩Sat(bi) ̸= ∅for each fairness constraint sfairi = □♦ai →□♦bi.
• If yes, then sfair =

0<i⩽k
sfairi is realizable in C.
• Otherwise, there exists an index j ∈{ 1, . . . , k } such that C ∩Sat(bj) = ∅. The goal
is then to realize the condition

0<i⩽k
i̸=j
sfair i ∧□¬aj
in C. For this, we investigate the subgraph C[¬aj] of C that arises by removing all
states where aj holds and their incoming and outgoing edges. The goal is to check
the existence of a cyclic subgraph of C[¬aj] such that the remaining k −1 fairness
constraints sfair 1, . . . , sfair j−1, sfair j+1, . . . , sfair k are realizable in this subgraph.
This is done by analyzing the nontrivial SCCs D of C[¬aj].
– If there is no nontrivial SCC D of C[¬aj], then sfair is not realizable in C.
– Otherwise, invoke CheckFair(D, k−1, . . .) for each of these nontrivial SCCs D
of C[¬aj] to check whether the remaining k−1 fairness constraints are realizable
in D.
The main steps of this procedure are summarized in Algorithm 19 on page 372. Note that
in each recursive call one of the fairness constraints is removed, and thus the recursion
depth is at most k, in which case k = 0 and the condition “∀i ∈{1, . . . , k}.C∩Sat(bj) ̸= ∅”
of the ﬁrst ifstatement is obviously fulﬁlled.
The cost function for CheckFair(C, k, sfair 1, . . . , sfair k), is given by the recurrence equa-
tion:
T(n, k) = O(n) + max{

1⩽ℓ⩽r
T(nℓ, k−1) | n1, . . . , nr ⩾1, n1 + . . . + nr ⩽n}
where n is the size (number of vertices and edges) of the subgraph C of G[a]. The values
n1, . . . , nr denote the sizes of the nontrivial strongly connected components D1, . . . , Dr of
C[¬aj]. It is easy to see that the solution of this recurrence is O(n·k). This yields:

372
Computation Tree Logic
Algorithm 19 Recursive algorithm CheckFair(C, k, sfair 1, . . . , sfair k)
Input: nontrivial SCC C in G[a], and strong fairness constraints sfair i = □♦ai →□♦bi, i =
1, . . . , k.
Output: true if 
1⩽i⩽k sfair i is realizable in C. Otherwise false.
if ∀i ∈{ 1, . . . , k }. C ∩Sat(bj) ̸= ∅then
return true
(*

1⩽i⩽k
□♦bi is realizable in C *)
else
choose an index j ∈{1, . . . , k} with C ∩Sat(bj) = ∅;
if C[¬aj] is acyclic (or empty) then
return false
else
compute the nontrivial SCCs of C[¬aj];
for all nontrivial SCC D of C[¬aj] do
if CheckFair(D, k −1, sfair 1, . . . , sfair j−1, sfair j+1, . . . , sfair k) then
return true
ﬁ
od
ﬁ
ﬁ
return false

Counterexamples and Witnesses
373
Theorem 6.42.
Time Complexity of Verifying ∃□a under Fairness
For transition system TS with N states and K transitions, and CTL strong fairness as-
sumption fair with k conjuncts, the set Satfair(∃□a) can be computed in O ((N+K) · k).
The time complexity is thus linear in the size of the transition system and the number
of imposed fairness constraints. The set T resulting from all SCCs C of G[a], for which
CheckFair(C, 1) returns the value true, can be computed (with appropriate implementa-
tion) in time O(size(G[a]) · k). A reachability analysis (by, e.g., depth-ﬁrst search) results
in the set
Satfair(∃□a)
=
{ s ∈S | ReachG[a](s) ∩T ̸= ∅}.
Gathering these results yields that CTL model checking under strong fairness constraints
and for CTL formulae in ENF can be done in time linear in the size of the transition
system, the length of the formula, and the number of (strong) fairness constraints. This,
in fact, also holds for arbitrary CTL formulae (with universal quantiﬁcation which can
be treated by techniques similar as the ones we presented for existential quantiﬁcation)
and weak fairness constraints, or any mixture of unconditional, strong, and weak fairness
constraints. We thus obtain:
Theorem 6.43.
Time Complexity of CTL Model Checking with Fairness
For transition system TS with N states and K transitions, CTL formula Φ, and CTL
fairness assumption fair with k conjuncts, the CTL model-checking problem TS |=fair Φ
can be determined in time O((N+K) · |Φ| · k).
6.6
Counterexamples and Witnesses
A major strength of model checking is the possibility of generating a counterexample in
case a formula is refuted. Let us ﬁrst explain what is meant by a counterexample. In the
case of LTL, a counterexample for TS ̸|= ϕ is a suﬃciently long preﬁx of a path π that
indicates why π refutes ϕ. For instance, a counterexample for the LTL formula ♦a is a
ﬁnite preﬁx of just ¬a-states that ends with a single cycle traversal. Such counterexample
suggests that there is a □¬a-path. Similarly, a counterexample for ⃝a consists of a path
π for which π[1] violates a.
For CTL the situation is somewhat more involved due to the existential path quantiﬁ-
cation.
For CTL formulae of the form ∀ϕ a suﬃciently long preﬁx of π with π ̸|= ϕ
provides—as in LTL—suﬃcient information about the source of the refutation. In the

374
Computation Tree Logic
case of a path formula of the form ∃ϕ, it is unclear what a counterexample will be: if
TS ̸|= ∃ϕ, then all paths violate ϕ and no path satisﬁes ϕ. However, if one checks the
formula ∃ϕ for a transition system TS, then it is quite natural that for the answer “yes,
TS |= ∃ϕ” one aims at an initial path where ϕ holds, while the answer “no” might be
suﬃcient.6 Therefore, CTL model checking supports the system diagnosis by providing
counterxamples or witnesses. Intuitively, counterexamples indicate the refutation of uni-
versally quantiﬁed path formulae, while witnesses indicate the satisfaction of existentially
quantiﬁed path formulae. From a path-based view, the concepts are counterexamples and
witnesses can be explained as follows:
• a suﬃciently long preﬁx of a path π with π ̸|= ϕ is a counterexample for the CTL
path formula ∀ϕ, and
• a suﬃciently long preﬁx of a path π with π |= ϕ is a witness of the CTL path formula
∃ϕ.
To exemplify the idea of generating a witness, consider the following well-known combi-
natorial problem.
Example 6.44.
The Wolf-Goat-Cabbage Problem
Consider the problem of bringing a ferryman (f), a goat (g), a cabbage (c) and a wolf
(w) from one side of a river to the other side. The only available means to go from one
riverside to another is a small boat that is capable of carrying at most two occupants. In
order for the boat to be steered, one of the occupants needs to be the ferryman. Of course,
the boat does not need to be fully occupied, and the ferryman can cross the river alone.
For obvious reasons, neither the goat and the cabbage nor the goat and the wolf should
be left unobserved by the ferryman. The question is whether there exists a series of boat
movements such that all three items can be carried by the ferryman to the other side of
the river.
This problem can be represented as a CTL model-checking problem in a rather natural
way.
The behavior of the goat, wolf, and cabbage is provided by a simple two-state
transition system depicted in Figure 6.16. The state identiﬁers indicate the position of
each of the items: 0 stands for the current (i.e., starting) riverside, and 1 for the other side
6Since the standard CTL model-checking procedure calculates the set of states where the given (state)
formula Φ holds, also some information extracted from Sat(Φ) could be returned to the user. For instance,
if TS ̸|= ∃ϕ, then the model checker might return the set of initial states s0 where s0 ̸|= ∃ϕ.
This
information could be understood as a counterexample and used for debugging purposes. This issue will
not be addressed here. Instead we will discuss the concept of path-based counterexamples (also often called
“error traces”) and their duals, i.e., computations that provide a proof for the existence of computations
with certain properties.

Counterexamples and Witnesses
375
w0
w1
g0
g1
c0
c1
f0
f1
β
α
β
β
τ
α
α
τ
β
α
Figure 6.16: Transition systems for the wolf, goat, cabbage, and ferryman.
(i.e., the goal). The synchronization actions α and β are used to describe the boat trips
that are taking place together with the ferryman. The ferryman behaves very similarly,
but has in addition the possibility to cross the river alone. This corresponds to the two
τ-labeled transitions. The resulting transition system representing the entire “system”
TS =
(wolf ||| goat ||| cabbage) ∥ferryman,
has 24 = 16 states. The resulting transition system is depicted in Figure 6.17. Note that
the transitions are all bidirectional as each boat movement can be reversed. The existence
of a sequence of boat movements to bring the two animals and the cabbage to the other
riverbank can be expressed as the CTL state formula ∃ϕ where
ϕ =
 
i=0,1
(wi ∧gi →fi) ∧(ci ∧gi →fi)

U (c1 ∧f1 ∧g1 ∧w1).
Here, the left part of the until formula forbids the scenarios in which the wolf and the
goat, or the cabbage and the goat are left unobserved. A witness of the CTL path formula
ϕ is an initial ﬁnite path fragment which leads from
initial state ⟨c0, f0, g0, w0⟩to target state ⟨c1, f1, g1, w1⟩
and which does not pass through any of the (six) states in which the wolf and the goat
or the goat and the cabbage are left alone on one riverbank. That is, e.g., the states
⟨c0, f0, g1, w1⟩and ⟨c1, f0, g1, w0⟩should be avoided. An example witness for ϕ is:
⟨c0, f0, g0, w0⟩
goat to riverbank 1
⟨c0, f1, g1, w0⟩
ferryman comes back to riverbank 0
⟨c0, f0, g1, w0⟩
cabbage to riverbank 1
⟨c1, f1, g1, w0⟩
goat back to riverbank 0
⟨c1, f0, g0, w0⟩
wolf to riverbank 1
⟨c1, f1, g0, w1⟩
ferryman comes back to riverbank 0
⟨c1, f0, g0, w1⟩
goat to riverbank 1
⟨c1, f1, g1, w1⟩

376
Computation Tree Logic
⟨c0, f0, g0, w0⟩
⟨c0, f1, g0, w0⟩
⟨c1, f1, g0, w0⟩
⟨c0, f1, g0, w1⟩
⟨c0, f1, g1, w0⟩
⟨c0, f0, g1, w0⟩
⟨c0, f1, g1, w1⟩
⟨c1, f1, g1, w0⟩
⟨c0, f0, g1, w1⟩
⟨c1, f0, g1, w0⟩
⟨c0, f0, g0, w1⟩
⟨c1, f0, g0, w0⟩
⟨c1, f1, g0, w1⟩
⟨c1, f0, g0, w1⟩
⟨c1, f1, g1, w1⟩
⟨c1, f0, g1, w1⟩
Figure 6.17: Transition system of the wolf-goat-cabbage problem.
6.6.1
Counterexamples in CTL
Now we explain how to generate counterexamples or witnesses for CTL (path) formulae.
We consider here path formulae of the form ⃝Φ, Φ U Ψ, and □Φ. (Techniques for other
operators, such as W or R , can be derived. Alternatively, corresponding considerations
can be made for them.)
In the sequel, let TS = (S, Act, →, I, AP, L) be a ﬁnite transition system without terminal
states.

Counterexamples and Witnesses
377
The Next Operator
A counterexample of ϕ = ⃝Φ is a pair of states (s, s′) with s ∈I
and s′ ∈Post(s) such that s′ ̸|= Φ. A witness of ϕ = ⃝Φ is a pair of states (s, s′) with
s ∈I and s′ ∈Post(s) with s′ |= Φ. Thus, counterexamples and witnesses for the next-step
operator result from inspecting the immediate successors of the initial states of TS.
The Until Operator
A witness of ϕ = Φ U Ψ is an initial path fragment s0 s1 . . . sn for
which
sn |= Ψ
and
si |= Φ for 0 ⩽i < n.
Witnesses can be determined by a backward search starting in the set of Ψ-states.
A counterexample is an initial path fragment that indicates a path π for which either:
π |= □(Φ ∧¬Ψ)
or
π |= (Φ ∧¬Ψ) U (¬Φ ∧¬Ψ).
For the ﬁrst case, a counterexample is an initial path fragment of the form
s0 s1 . . . sn−1 sn s′
1 . . . s′
r



cycle



satisfy Φ ∧¬Ψ
with sn = s′
r.
For the second case, an initial path fragment of the form
s0 s1 . . . sn−1



satisfy Φ ∧¬Ψ
sn
with sn |= ¬Φ ∧¬Ψ
does suﬃce as counterexample. Counterexamples can be determined by an analysis of the
digraph G = (S, E) where
E = { (s, s′) ∈S × S | s′ ∈Post(s) ∧s |= Φ ∧¬Ψ }.
Then the SCCs of G are determined. Each path in G that starts in an initial state s0 ∈S
and leads to a nontrivial SCC C in G provides a counterexample of the form
s0 s1 . . . sn s′
1 . . . s′
r
  
∈C
with
sn = s′
r.
Each path in G that leads from an initial state s0 to a trivial terminal SCC
C = { s′ }
with
s′ ̸|= Ψ
provides a counterexample of the form s0 s1 . . . sn with sn |= ¬Φ ∧¬Ψ.

378
Computation Tree Logic
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 6.18: Transition system of semaphore-based mutual exclusion algorithm.
The Always Operator
A counterexample for the formula ϕ = □Φ is an initial path
fragment s0 s1 . . . sn such that si |= Φ for 0 ⩽i < n and sn ̸|= Φ. Counterexamples may
be determined by a backward search starting in ¬Φ-states.
A witness of ϕ = □Φ consists of an initial path fragment of the form
s0 s1 . . . sn s′
1 . . . s′
r



satisfy Φ
with
sn = s′
r.
Witnesses can be determined by a simple cycle search in the digraph G = (S, E) where
the set of edges E is obtained from the transitions emanating from Φ-states, i.e., E
=
{ (s, s′) | s′ ∈Post(s) ∧s |= Φ }.
Example 6.45.
Counterexamples and Semaphore-Based Mutual Exclusion
Recall the two-process mutual exclusion algorithm that exploits a binary semaphore y to
resolve contention (see Eaxmple 3.9 on page 98). For convenience, the transition system
TSSem of this algorithm is depicted in Figure 6.18. Consider the CTL formula over AP =
{ c1, c2, n1, n2, w1, w2 }:
∀(((n1 ∧n2) ∨w2)



Φ
U c2

Ψ
).
It expresses that process P2 acquires access to the critical section once it starts waiting to
enter it.
Note that the state labeling of TSSem can be directly obtained from the information in

Counterexamples and Witnesses
379
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 6.19: Graph to detect counterexamples for ∀(((n1 ∧n2) ∨w2) U c2).
the states. Evidently, the CTL formula is refuted by TSSem. Counterexamples can be
established as follows.
First, the graph G is determined by only allowing edges that
emanate from states satisfying Φ ∧¬Ψ. This entails that all edges emanating from s with
s |= ¬((n1 ∧n2) ∨w2) ∨c2 are eliminated. This yields the graph depicted in Figure 6.19.
The graph G contains a single nontrivial SCC C that is reachable from the initial state in
TSSem. The initial path fragment:
⟨n1, n2, y=1⟩⟨n1, w2, y=1⟩⟨w1, w2, y=1⟩⟨c1, w2, y=0⟩



∈C
is a counterexample as it shows that there is a path π in TSSem satisfying □(((n1 ∧n2) ∨
w2) ∧¬c2), i.e., a path for which c2 is never established.
Alternatively, any path from the initial state to the trivial terminal SCC satisfying ¬c2 is
a counterexample as well. This only holds for the terminal SCC { ⟨w1, n2, y=1⟩}.
Theorem 6.46.
Time Complexity of Counterexample Generation
Let TS be a transition system TS with N states and K transitions and ϕ a CTL- path
formula.
If TS ̸|= ∀ϕ, then a counterexample for ϕ in TS can be determined in time
O(N+K). The same holds for a witness for ϕ, provided that TS |= ∃ϕ.

380
Computation Tree Logic
6.6.2
Counterexamples and Witnesses in CTL with Fairness
In the case CTL fairness assumptions are imposed, witnesses and counterexamples can be
provided in a similar way as for CTL. Suppose fair is the fairness assumption of interest.
The Next Operator
A witness for π |=fair ⃝a originates from a witness for π |=
⃝(a ∧afair). Note that the latter is obtained as for CTL, as no fairness is involved. A
counterexample to ⃝a is a preﬁx of a fair path π = s0 s1 s2 . . . in TS with π ̸|= ⃝a. As
π is fair and π ̸|= ⃝a, it follows that s1 |= afair and s1 ̸|= a. So, s1 ̸|= afair →a. A
counterexample to ⃝a with respect to |=fair thus results from a counterexample to the
formula ⃝(afair →a) for CTL without fairness.
The Until Operator
A witness of a U a′ with respect to the fair semantics is a witness
of a U (a′ ∧afair) with respect to the standard CTL semantics. A counterexample for a U a′
with respect to the fair semantics is either a witness of (a ∧a′) U (¬a ∧¬a′ ∧afair) under
the common semantics |= or a witness of □(a ∧¬a′) with respect to the fair semantics
(explained below).
The Always Operator
For a formula of the form □a, a counterexample with respect
to the fair semantics is an initial path fragment s0 s1 . . . sn such that:
sn |= ¬a ∧afair
and
si |= a for 0 ⩽i < n.
Consider the strong fairness assumption of the form:
sfair =

0<i⩽k
(□♦ai →□♦bi).
A witness of □a under sfair is an initial path fragment
s0 s1 . . . sn s′
1 s′
2 . . . s′
r



|= a
with sn = s′
r
such that for all 0 < i ⩽k it holds that
Sat(ai) ∩{ s′
1, . . . , s′
r } = ∅or Sat(bi) ∩{ s′
1, . . . , s′
r } ̸= ∅.
A witness can be computed by means of an analysis of the SCCs of a digraph that originates
from the state graph of TS after some slight modiﬁcations. The costs are (multiplicatively)
linear in the number of fairness conditions and in the size of the state graph.

Symbolic CTL Model Checking
381
Theorem 6.47.
Time Complexity of Fair Counterexample Generation
For transition system TS with N states and K transitions, CTL path formula ϕ and CTL
fairness assumption fair with k conjuncts such that TS ̸|=fair ∀ϕ, a counterexample for
ϕ in TS can be determined in time O((N+K)·k). The same holds for a witness for ϕ if
TS |= ∃ϕ.
Example 6.48.
Consider the transition system depicted in Figure 6.11 (page 350) and assume the formula
of interest is:
∃□(a ∨(b = c))
under fairness constraint
sfair = □♦(q ∧r) →□♦¬(q ∨r).
The strong CTL fairness constraint asserts that in case either state s0 or s2 is visited
inﬁnitely often, then also state s3 or s7 needs to be visited inﬁnitely often. The path
s1 s3 s0 s2 s0 is a witness of ∃□(a ∨(b = c)) in the absence of any fairness constraint. It
is, however, no witness under sfair as it visits s0 (and s2) inﬁnitely often, but not s3 or
s7. On the other hand, the path s1 s3 s0 s2 s1 is a witness under sfair.
6.7
Symbolic CTL Model Checking
The CTL model-checking procedure described so far relies on the assumption that the
transition system has an explicit representation by the predecessor and successor lists per
state. Such an enumerative representation is not adequate for very large transition sys-
tems. To attack the state explosion problem, the CTL model-checking procedure can be
reformulated in a symbolic way where sets of states and sets of transitions are represented
rather than single states and transitions. This set-based approach is very natural for CTL,
since its semantics and model-checking algorithm rely on satisfaction sets for subformulae.
There are several possibilities to realize the CTL model checking algorithm in a purely
set-based stetting. The most prominent ones rely on a binary encoding of the states, which
permits identifying subsets of the state space and the transition relation with switching
functions. To obtain compact representations of switching functions, special data struc-
tures have been developed, such as ordered binary decision diagrams. Other forms for the
representation of switching functions, such as conjunctive normal forms, could be used as
well. They are widely used in the context of so-called SAT-based model checking where the
model-checking problem is reduced to the satisﬁability problem for propositional formulae
(SAT). The SAT-based techniques will not be described in this book. Instead we will
explain the main ideas of the approach with binary decision diagrams.

382
Computation Tree Logic
We ﬁrst explain the general ideas behind symbolic approaches which operate on sets of
states rather than single states and rely on a representation of transition systems by
switching functions.
In the sequel, let TS = (S, →, I, AP, L) be a “large”, but ﬁnite
transition system. The set of actions is irrelevant here and has been skipped. That is,
the transition relation →is a subset of S × S. Let n ⩾⌈log |S|⌉. (Since we suppose
a large transition system, we can safely assume that |S| ⩾2.) We choose an arbitrary
(injective) encoding enc : S →{0, 1}n of the states by bit vectors of length n. Although
enc might not be surjective, it is no restriction to suppose that enc(S) = {0, 1}n, since all
elements (b1, . . . , bn) ∈{0, 1}n \ enc(S) can be treated as the encoding of pseudo states
that cannot be reached from any proper state s ∈S. The transitions of these pseudo
states are arbitrary. The idea is now to identify the states s ∈S = enc−1({0, 1}n) with
their encoding enc(s) ∈{0, 1}n and to represent any subset T of S by its characteristic
function χT : {0, 1}n →{0, 1}, which evaluates to true exactly for the (encodings of the)
states s ∈T. Similarly, the transition relation →⊆S ×S can be represented by a Boolean
function Δ : {0, 1}2n →{0, 1} that assigns 1 to exactly those pairs (s, s′) of bit vectors of
length n each where s →s′.
On the basis of this encoding, the CTL model-checking procedure can be reformulated to
an algorithm that operates on the representation of TS by binary decision diagrams for Δ
and the characteristic functions χSat(a) for the satisfaction sets of the atomic propositions
a ∈AP. The remainder of this section is concerned with explanations on this approach.
Section 6.7.1 summarizes our notations for switching functions and operations on them.
The encoding of transition systems by switching functions and a corresponding reformu-
lation of the CTL model-checking algorithm will be presented in Section 6.7.2. The main
concepts of (ordered) binary decision diagrams are summarized in Section 6.7.3.
6.7.1
Switching Functions
For technical reasons, it is more appropriate to consider switching functions as mappings
from evaluations for certain Boolean variables to the values 0 or 1 rather than functions
{0, 1}n →{0, 1}. This permits simpler deﬁnitions of composition operators as we just
have to identify the common variables, rather than refer to common arguments via their
positions in bit tuples. Furthermore, the reference of the arguments of a switching function
by means of variable names is also central for binary decision diagrams.
Let z1 . . . , zm be Boolean variables and Var = {z1, . . . , zm}. Let Eval(z1, . . . , zm) denote
the set of evaluations for z1, . . . , zm, i.e., functions η : Var →{0, 1}.
Evaluations are
written as [z1 = b1, . . . , zm = bm]. We often use tuple-notations such as z for the variable
tuple (z1, . . . , zm), b for a bit tuple (b1, . . . , bm) ∈{0, 1}m, and [z = b] as a shorthand for
the evaluation [z1 = b1, . . . , zm = bm].

Symbolic CTL Model Checking
383
Notation 6.49.
Switching Function
A switching function for Var = {z1, . . . , zm} is a function f : Eval(Var) →{0, 1}. The
special case m = 0 (i.e., Var = ∅) is allowed. The switching functions for the empty
variable set are just constants 0 or 1.
To indicate the underlying set of variables of a switching function we often write f(z) or
f(z1, . . . , zm) rather than f. When an enumeration of the variables in Var is clear from
the context, say z1, . . . , zm, then we often simply write f(b1, . . . , bm) or f(b) instead of
f([z1 = b1, . . . , zm = bm]) (or f([z = b])).
Disjunction, conjunction, negation and other Boolean connectives are deﬁned for switching
functions in the obvious way. For example, if f1 is a switching function for {z1, . . . , zn, . . . zm}
and f2 a switching function for {zn, . . . zm, . . . , zk}, where the zi’s are supposed to be pair-
wise distinct and 0 ⩽n ⩽m ⩽k, then f1 ∨f2 is a switching function for {z1, . . . , zk} and
the values of f1 ∨f2 are given by
(f1 ∨f2)([z1 = b1, . . . , zk = bk])
= max{ f1([z1 = b1, . . . , zm = bm]), f2([zn = bn, . . . , zk = bk]) }.
We often simply write zi for the projection function przi : Eval(z) →{0, 1}, przi([z = b]) =
bi and 0 or 1 for the constant switching functions. With these notations, switching func-
tions can be represented by Boolean connections of the variables zi (viewed as projection
functions) and constants. For instance, z1 ∨(z2 ∧¬z3) stands for a switching function.
Notation 6.50.
Cofactor and Essential Variable
Let f : Eval(z, y1, . . . , ym) →{0, 1} be a switching function. The positive cofactor of f for
variable z is the switching function f|z=1 : Eval(z, y1, . . . , ym) →{0, 1} given by
f|z=1(c, b1, . . . , bm) = f(1, b1, . . . , bm)
where the bit tuple (c, b1, . . . , bm) ∈{0, 1}m+1 is short for the evaluation [z = c, y1 =
b1, . . . , ym = bm]. Similarly, the negative cofactor of f for variable z is the switching func-
tion f|z=0 : Eval(z, y1, . . . , ym) →{0, 1} given by f|z=0(c, b1, . . . , bm) = f(0, b1, . . . , bm).
If f is a switching function for {z1, . . . , zk, y1, . . . , ym}, then we write f|z1=b1,...,zk=bk for
the iterated cofactor, also simply called cofactor of f, given by
f|z1=b1,...,zk=bk = (. . . (f|z1=b1)|z2=b2 . . .)|zk=bk.
Variable z is called essential for f if f|z=0 ̸= f|z=1.
The values of f|z1=b1,...,zk=bk for f = f(z1, . . . , zk, y1, . . . , ym) are given by
f|z1=b1,...,zk=bk(c1, . . . , ck, a1, . . . , am) = f(b1, . . . , bk, a1, . . . , am)

384
Computation Tree Logic
where (c1, . . . , ck, a1, . . . , am) is identiﬁed with the evaluation [z1 = c1, . . . , zk = ck, y1 =
a1, . . . , ym = am]. As a consequence, the deﬁnition of (iterated) cofactors does not depend
on the order in which the cofactors for single variables are considered, i.e.:
f|z1=b1,...,zk=bk = (. . . (f|zi1=bi1)|zi2=bi2 . . .)|zik =bik
for each permutation (i1, . . . , ik) of (1, . . . , k).
Obviously, variable z is not essential for the cofactors f|z=0 and f|z=1. Thus, at most the
variables in Var\{z1, . . . , zk} are essential for f|z1=b1,...,zk=bk, provided that f is a switching
function for Var.
Example 6.51.
Cofactors and Essential Variables
Consider the switching function f(z1, z2, z3) given by (z1 ∨¬z2) ∧z3. Then, f|z1=1 = z3
and f|z1=0 = ¬z2 ∧z3. In particular, variable z1 is essential for f.
When we ﬁx the variable set {z1, z2, z3}, then variables z2 and z3 are not essential for the
projection function prz1 = z1. In fact, we have z1|z2=0 = z1|z2=1 = z1. On the other hand,
z1 is essential for the projection function z1 as we have z1|z1=1 = 1 ̸= 0 = z1|z1=0.
For another example, variables z1 and z2 are essential for f(z1, z2, z3) = z1 ∨¬z2 ∨(z1 ∧z2 ∧
¬z3), while variable z3 is not, as f|z3=1 = z1 ∨¬z2 agrees with f|z3=0 = z1 ∨¬z2 ∨(z1 ∧z2).
The following lemma yields a decomposition of f into its cofactors. This simple observation
relies on the fact that for any evaluation where z is assigned to 0 the value of f(z, y) agrees
with the value of f|z=0 under the same evaluation for y. And similarly, f([z = 1, y = b]) =
f|z=1([y = b]).
Lemma 6.52.
Shannon Expansion
If f is a switching function for Var , then for each variable z ∈Var:
f = (¬z ∧f|z=0) ∨(z ∧f|z=1).
A simple consequence of the Shannon expansion is that z is not essential for f if and only
if f = f|z=0 = f|z=1.

Symbolic CTL Model Checking
385
z1
z2
z2
z3
z3
z3
z3
1
0
1
1
0
0
0
0
Figure 6.20: Binary decision tree for z1 ∧(¬z2 ∨z3).
Remark 6.53.
Binary Decision Trees
The Shannon expansion is inherent in the representation of switching functions by binary
decision trees. Given a switching function f for some variable set Var, one ﬁrst ﬁxes an
arbitrary enumeration z1, . . . , zm for the variables in Var and then represents f by a binary
tree of height m such that the two outgoing edges of the inner nodes at level i stand for
the cases zi = 0 (depicted by a dashed line) and zi = 1 (depicted by a solid line). Thus, the
paths from the root to a leaf in that tree represent the evaluations and the corresponding
value. The leaves stand for the function values 0 or 1 of f. That is, given the evaluation
s = [z1 = b1, . . . , zm = bm], then f(s) is the value of the terminal node that is reached
by traversing the tree from the root using the branch zi = bi for the node at level i. The
subtree of node v of the binary decision tree for f and the variable ordering z1, . . . , zm
yields a representation of the iterated cofactor f|z1=b1,...,zi−1=bi−1 (viewed as a switching
function for {zi, . . . , zm}) where z1 = b1, . . ., zi−1 = bi−1 is the sequence of decisions made
along the path from the root to node v.
An example of a binary decision tree for f(z1, z2, z3) = z1 ∧(¬z2 ∨z3) is given in Figure
6.20. We use dashed lines for the edges from an inner node for variable z representing the
case z = 0 and solid edges for the case z = 1.
Further operators on switching functions that will be needed later are existential quantiﬁ-
cation over variables and renaming of variables.
Notation 6.54.
Existential and Universal Quantiﬁcation
Let f be a switching function for Var and z ∈Var. Then, ∃z.f is the switching function
given by:
∃z.f = f|z=0 ∨f|z=1.

386
Computation Tree Logic
If z = (z1, . . . , zk) and zi ∈Var for 1 ⩽i ⩽k, then ∃z.f is a short-form notation for
∃z1.∃z2. . . . ∃zk.f. Similarly, universal quantiﬁcation is deﬁned by
∀z.f = f|z=0 ∧f|z=1
and ∀z.f = ∀z1.∀z2. . . . ∀zk.f.
For example, if f(z, y1, y2) is given by (z ∨y1) ∧(¬z ∨y2), then
∃z.f = f|z=0 ∨f|z=1 = y1 ∨y2
and ∀z.f = f|z=0 ∧f|z=1 = y1 ∧y2.
The rename operator simply replaces certain variables with other ones. E.g., renaming
variable z into y in f(z, x) = ¬z ∨x yields the switching function ¬y ∨x. Formally:
Notation 6.55.
Rename Operator
Let z = (z1, . . . , zm), y = (y1, . . . , ym) be variable tuples of the same length and let x =
(x1, . . . , xk) be a variable tuple such that none of the variables yi or zi is contained in x. For
the evaluation s = [y = b] ∈Eval(y, x), s{y ←z} denotes the evaluation in Eval(z, x) that
is obtained by composing the variable renaming function yi →zi, for 1 ⩽i ⩽m with the
evaluation s. That is, s{y ←z} agrees with s for the variables in x and s{y ←z} assigns
the same value b ∈{0, 1} to variable zi as s to variable yi. Given a switching function
f : Eval(z, x) →{0, 1}, then the switching function f{z ←y} : Eval(y, x) →{0, 1} is
given by
f{z ←y}(s) = f( s{y ←z} ),
i.e., f{z ←y}([y = b, x = c]) = f([z = b, x = c]). If it is clear from the context which
variables have to be renamed, then we simply write f(y, x) rather than f{z ←y}.
6.7.2
Encoding Transition Systems by Switching Functions
After this excursus on switching functions, we return to the question of a symbolic
representation of a transition system TS = (S, →, I, AP, L). As mentioned above (see
page 382), the action set is irrelevant for our purposes and therefore omitted. For the
encoding of the states s ∈S we use n Boolean variables x1, . . . , xn and identify any
evaluation [x1 = b1, . . . , xn = bn] ∈Eval(x) with the unique state s ∈S such that
enc(s) = (b1, . . . , bn).
In the sequel, we suppose S = Eval(x).
Given a subset B of
S, then the characteristic function χB : S →{0, 1} of B assigns 1 to all states s ∈B

Symbolic CTL Model Checking
387
and 0 to all states s /∈B. As we assume S = Eval(x), the characteristic function is the
switching function given by
χB : Eval(x) →{0, 1},
χB(s) =
	 1
if s ∈B
0
otherwise.
In particular, for any atomic proposition a ∈AP, the satisfaction set Sat(a) = {s ∈S |
s |= a} can be represented by the switching function fa = χSat(a) for x. This yields a
symbolic representation of the labeling function by means of a family (fa)a∈AP of switching
functions for x.
The symbolic representation of the transition relation →⊆S×S relies on the same idea: we
identify →with its characteristic function S × S →{0, 1} where truth-value 1 is assigned
to the state pair (s, t) if and only if s →t. Formally, we deal with the variable tuple
x = (x1, . . . , xn) to encode the starting state s of a transition and a copy x ′ = (x ′
1, . . . , x ′
n)
of x to encode the target state. That is, for each of the variables xi we introduce a new
variable x ′
i. The original (unprimed) variables xi serve to encode the current state, while
the primed variables x ′
i are used to encode the next state. Then, we identify the transition
relation →of TS with the switching function
Δ : Eval(x, x ′) →{0, 1},
Δ(s, t{x ′ ←x}) =
	 1
if s →t
0
otherwise
where s and t are elements of the state space S = Eval(x) and the second argument
t{x ′ ←x} in Δ(s, t{x/x ′}) is the evaluation for x ′ that assigns the same value (1 or 0) to
variable x ′
i as t assigns to variable xi (cf. Notation 6.55).
Example 6.56.
Symbolic Representation of Transition Relation
Suppose that TS has two states s0 and s1 and the transitions s0 →s0, s0 →s1 and
s1 →s0, then we need a single Boolean variable x1 = x for the encoding. Say we identify
state s0 by 0 and state s1 by 1. The transition relation →is represented by the switching
function Δ : Eval(x, x ′) →{0, 1},
Δ = ¬x ∨¬x ′.
Let us check why. The satisfying assignments for Δ are [x = 0, x ′ = 0], [x = 0, x ′ = 1] and
[x = 1, x ′ = 0]. The ﬁrst two evaluations (where x = 0 = 0) represent the two outgoing
transitions from state s0 = 0, while [x = 1, x ′ = 0] stands for the transition s1 →s0.
Example 6.57.
Symbolic Representation of a Ring
Consider a transition system TS with states {s0, . . . , sk−1} where k = 2n that are organized
in a ring, i.e., TS has the transitions
si →s(i + 1) mod k

388
Computation Tree Logic
for 0 ⩽i < k. We use the encoding that identiﬁes any state si with the binary encoding
of its index i. E.g., if k = 16, then n = 4 and state s1 is identiﬁed with 0001, state s10
with 1010, and state s15 with 1111. We use the Boolean variables x1, . . . , xn where xn
represents the most signiﬁcant bit (i.e., the evaluation [xn = bn, . . . , x1 = b1] stands for
state 
1⩽i⩽n bi2i−1). Then, Δ is a function with 2n variables, namely x1, x2, . . . , xn and
their copies x ′
1, x ′
2, . . . x ′
n. The values of the switching function Δ(x, x ′) are given by

1⩽i<n

x1 ∧. . . ∧xi ∧¬xi+1 →x ′ ∧. . . ∧x ′
i ∧x ′
i+1 ∧

j<i⩽n
(xj ↔x ′
j)

∧(x1 ∧. . . ∧xn →¬x ′
1 ∧. . . ∧¬x ′
n).
The set B = { s2i | 0 ⩽i < 2n−1 } is given by the switching function χB(x) = x1.
Given the switching function Δ and a state s ∈S = Eval(x), then the successor set
Post(s) = {s′ ∈S | s →s′} arises from Δ by ﬁxing evaluation s for x. More precisely, if
s = [x1 = b1, . . . , xn = bn], then a switching function χPost(s) for Post(s) is obtained from
Δ by building the cofactor for the variables x1, . . . , xn and the values b1, . . . , bn:
χPost(s) = Δ|s{x ←x ′}
where Δ|s stands for the iterated cofactor Δ|x1=b1,...,xn=bn. As Δ|s is a switching function
for {x ′
1, . . . , x ′
n}, the renaming operator {x ←x ′} yields a representation of Post(s) by the
variables x1, . . . , xn.
Example 6.58.
The successor set Post(s0) = { s0, s1 } for the simple system in Example 6.56 is obtained
symbolically by
Δ|x=0{x ←x′} = (¬x ∨¬x′)|x=0



=1
{x ←x′} = 1,
which reﬂects the fact that after identifying state s0 with the evaluation [x = 0] and state
s1 with [x = 1] the successor set of s0 is Eval(x) = {s0, s1}, and its characteristic function
is the constant 1. For state s1 = [x = 1], a symbolic representation of the successor set
Post(s1) = {s0} = {[x = 0]} is obtained by
Δ|x=1{x ←x′} = (¬x ∨¬x′)|x=1



=¬x′
{x ←x′} = ¬x

Symbolic CTL Model Checking
389
Remark 6.59.
Symbolic Composition Operators
As we explained in Chapter 2, a crucial aspect for the feasibility of any algorithmic veriﬁca-
tion technique is the automatic construction of “large” transition systems to be analyzed
by means of operators that compose several “small” transition systems TS1, . . . , TSm
representing the processes to be executed in parallel. Let us suppose that we have ap-
propriate representations for the switching functions Δ1, . . . , Δm for transition systems
TS1, . . . , TSm at our disposal.
If TS arises by TS1, . . . , TSm through the synchronous
product operator of TS, then the transition relation of TS is given by
Δ(x 1, . . . , x m, x ′
1, . . . , x ′
m) =

1⩽i⩽n
Δi(x i, x ′
i)
where x i denotes the variable tuple that is used to encode the states in TSi. The jus-
tiﬁcation for the above equation is that each transition ⟨s1, . . . , sm⟩→⟨s′
1, . . . , s′
m⟩of
TS = TS1 ⊗. . . ⊗TSm is composed of individual transitions si →s′
i in TSi for each of
the transition systems TSi. For the other extreme, suppose that TS = TS1 ||| . . . ||| TSm
arises by the interleaving operator of the TSi’s (without any synchronization or commu-
nication). Then,
Δ(x 1, . . . , x m, x ′
1, . . . , x ′
m) =
!
1⩽i⩽n

Δi(x i, x ′
i) ∧

1⩽j⩽m
i̸=j
x j = x ′
j

where for x j = (x1,j, . . . , xnj,j) and x ′
j = (x ′
1,j, . . . , x ′
nj,j) notation x j = x ′
j abbreviates

1⩽k⩽nj( xk,j ↔x ′
k,j ). The justiﬁcation for the above equation for Δ is that each transition
in TS has the form
⟨s1, . . . , si−1, si, si+1, . . . , sm⟩→⟨s1, . . . , si−1, s′
i, si+1, . . . , sm⟩
where exactly one transition system makes a move si →s′
i, while the others do not change
their local state. For the parallel operator ∥H which relies on an interleaving semantics for
actions outside H and synchronization over the actions in H, we need a combination of
the above formulae for Δ. Here, in fact, we need a reﬁned representation of the transition
relation in TSi with actions for the transitions by means of a switching function Δi(x i, z, x ′
i)
where the variable tuple z serves to encode the action names. In case m = 2, the switching
function Δ(x 1, x 2, x ′
1, x ′
2) for the transition relation in TS = TS1∥H TS2 is given by
∃z.

(
χH(z)
∧Δ1(x 1, z, x ′
1) ∧Δ2(x 1, z, x ′
2)
)
∨
(
¬χH(z)
∧Δ1(x 1, z, x ′
1) ∧x 2 = x ′
2
)
∨
(
¬χH(z)
∧Δ2(x 2, z, x ′
2) ∧x 1 = x ′
1
)

.
In case TS is the transition system of a program graph or channel system then the Boolean
variables xi serve to encode the locations, the potential values of the variables, and the

390
Computation Tree Logic
channel contents. The eﬀect of the actions has then to be rewritten in terms of these
variables.
Given the switching function Δ(x, x ′) and the characteristic function χB(x) for some set B
of states, we can now describe the backward BFS-based reachability analysis to compute
all states in Pre∗(B) = {s ∈S | s |= ∃♦B} on the basis of switching functions. Initially,
we start with the switching function f0 = χB that characterizes the set T0 = B. Then, we
successively compute the characteristic functions fj+1 = χTj+1 of
Tj+1 = Tj ∪{s ∈S | ∃s′ ∈S s.t. s′ ∈Post(s) ∧s′ ∈Tj }
The set of states s where the condition ∃s′ ∈S s.t. s′ ∈Post(s) and s′ ∈Tj holds is given
by the switching function:
∃x ′. ( Δ(x, x ′)



s′ ∈Post(s)
∧fj(x ′)
  
s′∈Tj
).
Recall that fj(x ′) is just a short notation for fj{x ′ ←x}, i.e., arises from fj by renaming
the unprimed variables xi into their primed copies x ′
i for 1 ⩽i ⩽n. This BFS-based
technique can easily be adapted to treat constrained reachability properties ∃(C U B) for
subsets B, C of S, as shown in Algorithm 20 on page 390.
Algorithm 20 Symbolic computation of Sat(∃(C U B))
f0(x) := χB(x);
j := 0;
repeat
fj+1(x) := fj+1(x) ∨( χC(x) ∧∃x ′. ( Δ(x, x ′) ∧fj(x ′) ) );
j := j + 1
until fj(x) = fj−1(x);
return fj(x).
If we are just interested in the one-step predecessors, i.e., properties of the form ∃⃝B,
then no iteration is needed and the characteristic function of the set of states s ∈S with
Post(s) ∩B ̸= ∅is obtained by
∃x′. ( Δ(x, x ′)



s′ ∈Post(s)
∧χB(x ′)
  
s′∈B
).
In a similar way, the set Sat(∃□B) of all states s that have an inﬁnite path consisting of
states in a given set B can be computed symbolically. Here, we mimic the computation
of the largest set T ⊆B with Post(t) ∩T ̸= ∅for all t ∈T by the iteration T0 = B and
Tj+1 = Tj ∩{s ∈S | ∃s′ ∈S s.t. s′ ∈Post(s) ∧s′ ∈Tj }

Symbolic CTL Model Checking
391
Algorithm 21 Symbolic computation of Sat(∃□B)
f0(x) := χB(x);
j := 0;
repeat
fj+1(x) := fj+1(x) ∧∃x ′. ( Δ(x, x ′) ∧fj(x ′) );
j := j + 1
until fj(x) = fj−1(x);
return fj(x).
in a symbolic way, as shown in Algorithm 21 on page 391.
These considerations show that the CTL model checking problem “Does CTL formula
Φ hold for TS?” can be solved symbolically by means of switching functions fΨ that
represent the satisfaction sets Sat(Ψ) of the subformulae Ψ of Φ. The satisfaction sets fa
for the atomic propositions a ∈AP are supposed to be given. Union, intersection, and
complementation of sets of states correspond to disjunction, conjunction, and negation on
the level of switching functions. E.g., the satisfaction set for Ψ1∧¬Ψ2, is obtained by fΨ1∧
¬fΨ2. The treatment of formulae ∃(Ψ1 U Ψ2) and ∃□Ψ relies on the techniques sketched
in Algorithms 20 and 21. To treat full CTL, we can either transform any CTL formula
into an equivalent CTL formula in existential normal form or use analogous symbolic
algorithms for universally quantiﬁed formulae such as ∀(Φ U Ψ).
The major challenge is to ﬁnd an appropriate data structure for the switching functions.
Besides yielding compact representations of the satisfaction sets and the transition rela-
tion, this data structure has to support the Boolean connectives (disjunction, conjunction,
complementation) and the comparison of two switching functions. The latter is needed in
the termination criteria for the repeat loops in Algorithms 20 and 21.
Before presenting the deﬁnition of binary decision diagrams that have proven to be very
eﬃcient in many applications, let us ﬁrst discuss other potential data structures. Truth
tables can be ruled as they always have the size 2n for switching functions with n vari-
ables. The same holds for binary decision trees since they always have 2n+1 −1 nodes.
Conjunctive or disjunctive normal forms for the representation of switching functions by
propositional logic formulae yield the problem that checking equivalence (i.e., equality for
the represented switching functions) is expensive, namely coNP-complete. Furthermore,
there are switching functions fm with m essential variables where the length of any rep-
resentation by a conjunctive normal form formula grows exponentially in m. The same
holds for disjunctive normal forms. However, the latter is no proper argument against
conjunctive or disjunctive normal forms, because there is no data structure that ensures
representations of polynomial size for all switching functions. The reason for this is that the

392
Computation Tree Logic
number of switching functions for m variables z1, . . . , zm is double exponential in m. Note
that |Eval(z1, . . . , zm)| = 2m, and hence, the number of functions Eval(z1, . . . , zm) →{0, 1}
is 22m. Suppose we are given a universal data structure for switching functions (i.e., a
data structure that can represent any switching function) such that Km is the number of
switching functions for z1, . . . , zm that can be represented by at most 2m−1 bits. Then:
Km ⩽
2m−1

i=0
2i = 22m−1+1 −1
<
22m−1+1.
But then there are at least
22m −22m−1+1 = 22m−1+1 ·

22m−2m−1−1 −1

= 22m−1+1 ·

22m−1−1 −1

switching functions for z1, . . . , zm where the representation requires more than 2m−1 bits.
This calculation shows that we cannot expect a data structure which is eﬃcient for all
switching functions. Nevertheless there are data structures which yield compact repre-
sentations for many switching functions that appear in practical applications.
A data
structure that has been proven to be very successful for model checking purposes, in par-
ticular in the area of hardware veriﬁcation, is ordered binary decision diagrams (OBDDs).
Besides yielding compact representation for many “realistic” transition systems, they en-
joy the property that the Boolean connectives can be realized in time linear in the size
of the input OBDDs and that (with appropriate implementation techniques) equivalence
checking can even be performed in constant time.
In the remainder of this section, we explain those aspects of ordered binary decision
diagrams that are relevant to understanding the main concepts of symbolic model checking
with these data structures. Further theoretical aspects on binary decision diagrams, their
variants and applications, can be found, e.g., in the textbooks [134, 180, 292, 300, 418].
For details on OBDD-based symbolic model checking we refer to [74, 92, 288, 374].
6.7.3
Ordered Binary Decision Diagrams
Ordered binary decision diagrams (OBDDs for short), originally proposed by Bryant [70],
yield a data structure for switching functions that relies on a compactiﬁcation of binary
decision trees. The rough idea is to skip redundant fragments of a binary decision tree.
This means collapsing constant subtrees (i.e., subtrees where all terminal nodes have the
same value) into a single node and identifying nodes with isomorphic subtrees. In this
way, we obtain a directed acyclic graph of outdegree 2 where – as in binary decision trees
– the inner nodes are labeled by variables and their outgoing edges stand for the possible
evaluations of the corresponding variable. The terminal nodes are labeled by the function
value.

Symbolic CTL Model Checking
393
z1
z2
z3
1
0
z1
z2
z3
1
0
1
0
Figure 6.21: Binary decision diagram for z1 ∧(¬z2 ∨z3).
Example 6.60.
From Binary Decision Tree to OBDD
Before presenting the formal deﬁnition of binary decision diagrams, we explain the main
ideas by means of the function f(z1, z2, z3) = z1 ∧(¬z2 ∨z3). A binary decision tree for f
has been shown in Figure 6.20 on page 385. Since all terminal nodes in the right subtree
of the root have value 0 (which reﬂects the fact that the cofactor f|z1=0 agrees with the
constant function 0), the inner tests for variables z2 and z3 in that subtree are redundant
and the whole subtree can be replaced by a terminal node with value 0. Similarly, the
subtree of the z3-node representing the cofactor f|z1=1,z2=0 = 1 can be replaced with a
terminal node for the value 1. This leads to the graph shown on the left of Figure 6.21.
Finally, we may identify all terminal nodes with the same value, which yields the graph
shown on the right of Figure 6.21.
Example 6.61.
From Binary Decision Tree to OBDD
As another example, consider the switching function f = (z1 ∧z3) ∨(z2 ∧z3). The upper
part of Figure 6.22 on page 394 shows a binary decision tree for f. The subtree of the z3
node on the right is constant and can be replaced by a terminal node. The three subtrees
of the z3-nodes for the cofactors f|z1=0,z2=1, f|z1=1,z2=0, and f|z1=1,z2=1 are isomorphic
and can thus be collapsed. This yields the decision graph shown in the middle part of
Figure 6.22. But now the z2-node for the cofactor f|z1=1 becomes redundant, as regardless
whether z2 = 0 or z2 = 1, the same node will be reached. This permits removing this z2-
node and redirecting its incoming edge. This yields the binary decision diagram depicted
in the lower part of Figure 6.22.

394
Computation Tree Logic
z1
z2
z2
z3
z3
z3
z3
1
0
1
0
1
0
0
0
z1
z2
z2
z3
1
0
z1
z2
z3
1
0
Figure 6.22:
Binary decision diagrams for f = (z1 ∧z3) ∨(z2 ∧z3).

Symbolic CTL Model Checking
395
Notation 6.62.
Variable Ordering
Let Var be a ﬁnite set of variables. A variable ordering for Var denotes any tuple ℘=
(z1, . . . , zm) such that Var = {z1, . . . , zm} and zi ̸= zj for 1 ⩽i < j ⩽m. We write <℘for
the induced total order on Var. I.e., for ℘= (z1, . . . , zm) the binary relation <℘on Var is
given by zi <℘zj if and only if i < j. We write zi ⩽℘zj iﬀeither zi <℘zj or i = j.
Deﬁnition 6.63.
Ordered Binary Decision Diagram (OBDD)
Let ℘be a variable ordering for Var. An ℘-ordered binary decision diagram (℘-OBDD for
short) is a tuple
B = (V, VI, VT , succ0, succ1, var, val, v0)
consisting of
• a ﬁnite set V of nodes, disjointly partitioned into VI and VT where the nodes in VI
are called inner nodes, while the nodes in VT are called terminal nodes or drains;
• successor functions succ0, succ1 : VI →V
that assign to each inner node v a
0-successor succ0(v) ∈V and a 1-successor succ1(v) ∈V ;
• a variable labeling function var : VI →Var that assigns to each inner node v a
variable var(v) ∈Var;
• a value function val : VT →{ 0, 1 } that assigns to each drain a function value 0 or
1;
• a root (node) v0 ∈V .
Consistency of the variable labeling function with the variable ordering ℘is required in
the following sense. If ℘= (z1, . . . , zm), then for each inner node v: if var(v) = zi and
w ∈{succ0(v), succ1(v)}∩VI, then var(w) = zj for some j > i. Furthermore, it is required
that each node v ∈V \{v0} has at least one predecessor, i.e., v = succb(w) for some w ∈V
and b ∈{0, 1}.
The underlying digraph of a ℘-OBDD is obtained by using V as node set and estab-
lishing an edge from node v to w if and only if w is an successor of v, i.e., if w ∈
{succ0(v), succ1(v)}. The last condition in Deﬁnition 6.63, which states that each node
of an OBDD, except for the root, has a predecessor, is equivalent to the condition that
all nodes of an OBDD are reachable from the root. The size of an OBDD B, denoted
size(B), is the number of nodes in B.

396
Computation Tree Logic
An equivalent formulation for the order consistency of B (i.e., the condition stating that
the variable of an inner node appears in ℘before the variables of its successors, provided
they are inner nodes) is the requirement that for each path v0 v1 . . . vn in (the underlying
graph of) B we have vi ∈VI for 1 ⩽i < n and
var(v0) <℘var(v1) <℘. . . <℘var(vn),
where for the drains we put var(v) = ⊥(undeﬁned) and extend <℘by z <℘⊥for all
variables z ∈Var. That is, we regard <℘as a total order on Var ∪{⊥} and consider
the variable labeling function as a function var : V →Var ∪{⊥}. This yields that the
underlying graph of an OBDD is acyclic. In particular, v ̸= succb(v) for all inner nodes v
and b ∈{0, 1}.
Examples of OBDDs are the binary decision trees and graphs shown in Figures 6.20, 6.21,
and 6.22. All these OBDDs rely on the variable ordering ℘= (z1, z2, z3).
In the sequel, we often refer to an inner node v with var(v) = z as a z-node. As the pictures
for OBDDs suggest, we may think of the node set V of an OBDD to be partitioned into
levels. Dealing with the ordering ℘= (z1, . . . , zm), then the zi-nodes constitute the nodes
at level i. The drains yields the bottom level, while the top level consists of the root node.
Deﬁnition 6.64.
Semantics of OBDDs
Let B be an ℘-OBDD as in Deﬁnition 6.63. The semantics B is the switching function fB
for Var where fB([z1 = b1, . . . , zm = bm]) is the value of the drain that will be reached when
traversing the graph starting in the root v0 and branching according to the evaluation
[z1 = b1, . . . , zm = bm]. That is, if the current node v is a zi-node, then the traversal
continues with the bi-successor of v.
Deﬁnition 6.65.
Sub-OBDD, Switching Function for the Nodes
Let B be a ℘-OBDD. If v is a node in B, then the sub-OBDD induced by v, denoted
Bv arises from B by declaring v as the root node and removing all nodes that are not
reachable from v. The switching function for node, denoted fv, is the switching function
for Var that is given by the sub-OBDD Bv.
Clearly, at most the variables x with var(v) ⩽℘x can be essential for fv, since none of the
variables z with z <℘var(v) appear in the sub-OBDD. Hence, fv could also be viewed
as a switching function for the whole variable set Var or as a switching function for the
variables x with var(v) ⩽℘x, but this is irrelevant here. In particular, if v is a z-node,
then the order condition z = var(v) <℘var(succb(v)) yields that fsuccb(v)|z=c = fsuccb(v),

Symbolic CTL Model Checking
397
since variable z is not essential for fsuccb(v). But then:
fv|z=0
=
(¬z ∧fsucc0(v))|z=0 ∨(z ∧fsucc1(v))|z=0



=0
=
fsucc0(v)|z=0
=
fsucc0(v)
and, similarly, fv|z=1 = fsucc1(v).
Thus, the Shannon expansion yields the following
bottom-up characterization of the functions fv:
Lemma 6.66.
Bottom-up Characterization of the Functions fv
Let B be a ℘-OBDD. The switching functions fv for the nodes v ∈V are given as follows:
• If v is a drain, then fv is the constant switching function with value val(v).
• If v is a z-node, then fv = (¬z ∧fsucc0(v)) ∧(z ∧fsucc1(v)).
Furthermore, fB = fv0 for the root v0 of B.
This yields that fv = fB|z1=b1,...,zi=bi where [z1 = b1, . . . , zi = bi] is an evaluation which
leads from the root v0 of B to node v. In fact, all concepts of OBDD-based approaches
rely on the decomposition of switching functions into their cofactors. However, only the
cofactors are relevant that arise from f by assigning values to the ﬁrst i variables of ℘for
some i.
Notation 6.67.
℘-Consistent Cofactor
Let f be a switching function for Var and ℘= (z1, . . . , zm) a variable ordering for Var.
A switching function f ′ for Var is called a ℘-consistent cofactor of f if there exists some
i ∈{0, 1, . . . , m} such that f ′ = f|z1=b1,...,zi=bi. (Including the case i = 0 means that we
regard f as a cofactor of itself.)
For instance, if f = z1 ∧(z2 ∨¬z3) and ℘= (z1, z2, z3), then the ℘-consistent cofactors of
f are the switching functions f, f|z1=1 = z2 ∨¬z3, f|z1=1,z2=0 = ¬z3 and the constants
0 and 1. The cofactors f|z3=0 = z1 and f|z2=0 = z1 ∧¬z3 are not ℘-consistent. Since
it is possible that some cofactors of f arise by several evaluations, it is possible that
cofactors f|zi1=b1,...,zik =bk are ℘-consistent for the variable ordering ℘= (z1, . . . , zm), even
if (zi1, . . . , zik) is not a permutation of (z1, . . . , zk). For example, for f = z1 ∧(z2 ∨¬z3)
and ℘= (z1, z2, z3) the cofactor f|z2=0,z3=1 is ℘-consistent as it agrees with the cofactors
fz1=0 or f|z1=1,z2=0,z3=1. (They all agree with the constant function 0.)

398
Computation Tree Logic
The observation made above can now be rephrased as follows:
Lemma 6.68.
Nodes in OBDDs and ℘-Consistent Cofactors
For each node v of an ℘-OBDD B, the switching function fv is a ℘-consistent cofactor of
fB. Vice versa, for each ℘-consistent cofactor f ′ of fB there is at least one node v in B
such that fv = f ′.
However, given a ℘-OBDD B and a ℘-consistent cofactor f ′ of fB there could be more
than one node in B representing f ′. This, for instance, applies to the binary decision tree
shown in Figure 6.20 on page 385, viewed as ℘-OBDD for ℘= (z1, z2, z3), where we have
fB = z1 ∧(¬z2 ∨z3) and the ℘-consistent cofactors represented by the nodes in the left
subtree of the root agree as we have
f|z1=0 = f|z1=0,z2=b = f|z1=0,z2=b,z3=c = 0
for all b, c ∈{0, 1}. For the ℘-OBDD shown on the left of Figure 6.21 on page 393, all
inner nodes represent diﬀerent switching functions. However, the two drains with value
0 represent the same cofactors of fB. The same holds for the two drains with value 1.
However, in the ℘-OBDD shown on the right of Figure 6.21, every ℘-conistent cofactor
is represented by a single node. In this sense, this ℘-OBDD is free of redundancies, and
therefore called reduced:
Deﬁnition 6.69.
Reduced OBDD
Let B be a ℘-OBDD. B is called reduced if for every pair (v, w) of nodes in B: v ̸= w
implies fv ̸= fw. Let ℘-ROBDD denote a reduced ℘-OBDD.
Thus, in reduced ℘-OBDDs any ℘-consistent cofactor is represented by exactly one node.
This is the key property to prove that reduced OBDDs yield a universal and canonical
data structure for switching functions. Universality means that any switching function
can be represented by an OBDD. Canonicity means that any two ℘-OBDDs for the same
function agree up to isomorphism, i.e., renaming of the nodes.
Theorem 6.70.
Universality and Canonicity of ROBDDs
Let Var be a ﬁnite set of Boolean variables and ℘a variable ordering for Var. Then:
(a) For each switching function f for Var there exists a ℘-ROBDD B with fB = f.
(b) Given two ℘-ROBDDs B and C with fB = fC, then B and C are isomorphic, i.e.,
agree up to renaming of the nodes.

Symbolic CTL Model Checking
399
Proof: ad (a). Clearly, the constant functions 0 and 1 can be represented by a ℘-ROBDD
consisting of a single drain.
Given a nonconstant switching function f for Var and a
variable ordering ℘for Var, we construct a reduced ℘-OBDD B for f as follows. Let V
be the set of ℘-consistent cofactors of f. The root of B is f. The constant cofactors are
the drains with the obvious values. For f ′ ∈V , f ′ /∈{0, 1}, let
var(f ′) = min{ z ∈Var | z is essential for f ′ }
be the ﬁrst essential variable where the minimum is taken according to the total order <℘
induced by ℘. (We use here the trivial fact that any nonconstant switching function has
at least one essential variable.) The successor functions are given by
succ0(f ′) = f ′|z=0,
succ1(f ′) = f ′|z=1
where z = var(f ′). The deﬁnition of var(·) yields that B is a ℘-OBDD. By the Shannon
expansion we get that the semantics of f ′ ∈V (i.e., the switching function of f ′ as a node
of B) is f ′. In particular, this yields that fB = f (the function for the root f) and the
reducedness of B (as any two nodes represent diﬀerent cofactors of f).
To prove the statement in (b), it suﬃces to show that any reduced ℘-OBDD C with fC = f
is isomorphic to the ℘-ROBDD B constructed above. Let V C be the node set of C, vC
0
the root of C, varC the variable labeling function, and succC
0, succC
1 the successor functions
in C. Let function ı : V C →V be given by ı(v) = fv. (Recall that the functions fv are
℘-consistent cofactors of fC = f. This ensures that fv ∈V .) Since C is reduced, ı is a
bijection. It remains to show that ı preserves the variable labeling of inner nodes and
maps the successors of an inner node v of C to the successors of fv = ı(v) in B.
Let v be an inner node of C, say a z-node, and let w0 and w1 be the 0- and 1-successors
of v in C. Then, the cofactor fv|z=0 agrees with fw0, and similarly, fw1 = fv|z=1. (This
holds in any OBDD.) As C is reduced, fv is nonconstant (since otherwise fv = fw0 = fw1).
Variable z must be the ﬁrst essential variable of fv according to <℘, i.e., z = var(fv). Let
us see why. Let y = var(fv). The assumption z <℘y yields that z is not essential for
fv, and therefore fw0 = fv|z=0 = f = fv|z=1 = fw1. But then w0, w1 and v represent
the same function. Since w0 ̸= v and w1 ̸= v, this contradicts the assumption that C is
reduced. The assumption y <℘z is also impossible since then no y-node would appear in
the sub-OBDD Cv, which is impossible as y = var(fv) is essential for fv by deﬁnition.
But then var(ı(v)) = z = varC(v) and, for b ∈{0, 1}:
succb(ı(v)) = fv|z=b = fsuccC
b (v) = ı(succC
b (v))
Hence, ı is an isomorphism.

400
Computation Tree Logic
Theorem 6.70 permits speaking about “the ℘-ROBDD” for a given switching function f
for Var. The ℘-ROBDD-size of f denotes the size (i.e., number of nodes) in the ℘-ROBDD
for f.
Corollary 6.71.
Minimality of Reduced OBDDs
Let B be a ℘-OBDD for f. Then, B is reduced if and only if size(B) ⩽size(C) for each
℘-OBDD C for f.
Proof: This follows from the facts that (i) each ℘-consistent confactor of f is represented
in any ℘-OBDD C for f by at least one node, and (ii) a ℘-OBDD B for f is reduced if and
only if the nodes of B stand in one-to-one-correspondence to the ℘-consistent cofactors of
f.
Reduction rules.
When the variable ordering ℘for Var is ﬁxed, then reduced ℘-OBDDs
provide unique representations of switching functions for Var. (Of course, uniqueness is
up to isomorphism.) Although reducedness is a global condition for an OBDD, there are
two simple local reduction rules (see Figure 6.23), which can successively be applied to
transform a given nonreduced ℘-OBDD into an equivalent ℘-ROBDD.
Elimination rule: If v is an inner node of B with succ0(v) = succ1(v) = w, then remove
v and redirect all incoming edges u →v to w.
Isomorphism rule: If v, w are nodes in B with v ̸= w and either v, w are drains with
val(v) = val(w) or v, w are inner nodes with
⟨var(v), succ1(v), succ0(v)⟩= ⟨var(w), succ1(w), succ0(w)⟩,
then remove node v and redirect all incoming edges u →v to node w.
Both rules delete node v. The redirection of the incoming edges u →v to node w means
the replacement of the edges u →v which u →w. Formally, this means that we deal with
the modiﬁed successor functions given by
succ′
b(u) =
	 succb(u)
if succb(u) ̸= v
w
if succb(u) = v
for b = 0, 1. The transformations described in Examples 6.60 and 6.61 rely on the appli-
cation of the isomorphism and elimination rule.

Symbolic CTL Model Checking
401
u
u′
v
becomes
w
u
u′
w
becomes
1
v
0
v′
0
w′
1
w
0
w′
1
w
v
w
0
1
becomes
w
0
1
Figure 6.23: Reduction rules for OBDDs.

402
Computation Tree Logic
Both reduction rules are sound in the sense that they do not aﬀect the semantics, i.e., if
C arises from a ℘-OBDD B by applying the elimination or isomorphism rule, then C is
again a ℘-OBDD and fB = fC. This is due to the fact that both rules simply collapse
two nodes v and w with fv = fw. For the elimination rule applied to a z-node v with
w = succ0(v) = succ1(v), we have
fv = (¬z ∧fsucc0(v)) ∧(z ∧fsucc1(v)) = (¬z ∧fw) ∧(z ∧fw) = fw.
Similarly, if the isomorphism rule is applied to z-nodes v and w then
fv = (¬z ∧fsucc0(v)) ∧(z ∧fsucc1(v)) = (¬z ∧fsucc0(w)) ∧(z ∧fsucc1(w)) = fw.
Since the application of the reduction rules decreases the number of nodes, the process to
generate an equivalent ℘-OBDD by applying the reduction rules as long as possible always
terminates. In fact, the resulting OBDD is reduced:
Theorem 6.72.
Completeness of Reduction Rules
℘-OBDD B is reduced if and only if no reduction rule is applicable to B.
Proof: ⇒: The applicability of a reduction rule implies the existence of at least two nodes
representing the same switching function. Thus, if B is reduced, then no reduction rule
is applicable.
⇐: We prove the other direction by induction on the number of variables. More precisely,
suppose that we are given a ℘-OBDD B for the variable ordering ℘= (z1, . . . , zm) such
that neither the elimination nor the isomorphism rule is applicable and show by induction
on i that
fv ̸= fw for all nodes v, w ∈Vi where v ̸= w.
Here, Vi denotes the set of all nodes v ∈V on level i or lower. Formally, Vi is the set of all
nodes v in B such that zi ⩽℘var(v). Recall that var(v) = ⊥(undeﬁned) for each drain v
and that z <℘⊥for all variables z.
We start the induction with the bottom level i = m + 1. The statement fv ̸= fw for all
drains v, w where v ̸= w is trivial since the nonapplicability of the isomorphism rule yields
that there is at most one drain with value 0 and at most one drain with value 1. In the
induction step i + 1 =⇒i (m ⩾i ⩾0) we suppose that fv ̸= fw for all nodes v, w ∈Vi+1
with v ̸= w (induction hypothesis). Suppose there are two nodes v, w ∈Vi with v ̸= w
and fv = fw. At least one of the nodes v or w must be on level i. Say v ∈Vi \Vi+1. Then,
var(v) = zi.

Symbolic CTL Model Checking
403
Let us ﬁrst suppose that w ∈Vi+1. Then, either w is a drain or a zj-node for some j > i.
In either case, variable zi is not essential for fv = fw. As v is a zi-node this yields that
fv agrees with the switching functions fv0 and fv1 of its successors v0 = succ0(v) and
v1 = succ1(v). But then v0, v1 ∈Vi+1 and fv0 = fv1. The induction hypothesis yields that
v0 = v1. But then the elimination rule would be applicable. Contradiction.
Suppose now that w is a zi-node too. Let v0 = succ0(v), v1 = succ1(v) and w0 = succ0(w),
w1 = succ1(w). The assumption fv = fw yields that
fv0 = fv|zi=0 = fw|zi=0 = fw0
and fv1 = fw1. As v0, v1, w0, w1 ∈Vi+1 the induction hypothesis yields that v0 = w0 and
v1 = w1. But then the ismorphism rule is applicable. Contradiction.
Theorem 6.70 suggests a reduction algorithm which takes as input a nonreduced ℘-OBDD
B and constructs an equivalent ℘-OBDD by applying the reduction rules as long as pos-
sible.
According to the inductive proof of the completeness of the reduction rules in
Theorem 6.72, this technique is complete if the candidate nodes for the reduction rules are
considered in a bottom-up manner. That is, initially we identify all drains with the same
value. Then, for the levels m, m −1, . . . , 1 (in this order) we apply the elimination and
isomorphism rule. At level i, we ﬁrst remove all nodes with identical successors (elimina-
tion rule) and then check the pairs of zi-nodes where the isomorphism rule is applicable.
To support the isomorphism rule a bucket technique can be used that groups together (1)
all zi-nodes with the same 0-successor and (2) splits all buckets consisting of zi-nodes with
the same 0-successor into buckets consisting of zi-nodes with exactly the same successors.
Then, application of the isomorphism rule simply means that the nodes in the buckets
resulting from step (2) have to be collapsed into a single node. The time complexity of this
algorithm is in O(size(B)). In particular, given two ℘-OBDDs B and C, the equivalence
problem “Does fB = fC hold?” can be solved by applying the reduction algorithm to
both and then checking isomorphism for the reduced ℘-ROBDDs (see Exercise 6.12 on
page 436). We will see later that with tricky implementation techniques, which integrate
the steps of the reduction algorithm in the synthesis algorithms for ROBDDs and thus en-
sure that at any time the decision graph is reduced, the equivalence problem for ROBDDs
can even be solved in constant time.
The Variable Ordering Problem
The result stating the canonicity of reduced OB-
DDs crucially depends on the fact that the variable ordering ℘is assumed to be ﬁxed.
Varying the variable ordering can lead to totally diﬀerent ROBDDs, possibly ranging from
ROBDDs of linear size to ROBDDs of exponential size. The results established before yield
that the size (i.e., number of nodes) in the ℘-ROBDD for a switching function f agrees

404
Computation Tree Logic
z1
1
0
y1
z2
y2
z3
y3
Figure 6.24: ROBDD for the function f3 = (z1 ∧y1) ∨(z2 ∧y2) ∨(z3 ∧y3)
for the variable ordering ℘= (z1, y1, z2, y2, z3, y3).
with the number of ℘-consistent cofactors of f. Thus, reasoning about the memory re-
quirements of ROBDD-based approaches relies on counting the number of order-consistent
cofactors.
Example 6.73.
A Function with Small and Exponential-Size ROBDDs
To illustrate how the size of ROBDDs can be determined by analyzing the cofactors we
consider a simple switching function which has both ROBDDs of linear size and ROBDDs
with exponentially many nodes. Let m ⩾1 and
fm = (z1 ∧y1) ∨(z2 ∧y2) ∨. . . ∨(zm ∧ym).
For the variable ordering ℘= (zm, ym, zm−1, ym−1, . . . , z1, y1), the ℘-ROBDD for fm has
2m + 2 nodes, while Ω(2m) nodes are required for the ordering ℘′ = (z1, z2, . . . , zm,
y1, . . . , ym). Figures 6.25 and 6.24 show the ROBDDs for the linear-size and exponential-
size variable orderings for m=3. We ﬁrst consider the ordering ℘which groups the variables
zi and yi that appear in the same clause. In fact, the variable ordering ℘is optimal for
fm as the ℘-ROBDD for fm contains one node for each variable. (This is the best we can
hope to have as all 2n variables are essential for fm and must appear in any ROBDD for

Symbolic CTL Model Checking
405
z1
0
1
z2
z2
z3
z3
z3
z3
y1
y1
y1
y1
y2
y2
y3
Figure 6.25: ROBDD for the function f3 = (z1 ∧y1) ∨(z2 ∧y2) ∨(z3 ∧y3)
for the variable ordering ℘= (z1, z2, z3, y1, y2, y3).
fm.) Note that for 1 ⩽i ⩽m:
fm|zm=am,zm=bm,...,zi=ai,zi=bi =
⎧
⎨
⎩
1
if aj = bj = 1
for some j ∈{i, . . . , m}
fi−1
otherwise
fm|zm=am,zm=bm,...,zi+1=ai+1,zi+1=bi+1,zi=ai ∈{ 1, yi ∨fi−1 }
where f0 = 0. Hence, the ℘-ROBDD for fm has exactly one zi-node representing the
function fi, exactly one yi-node for the function yi ∨fi−1 (for 1 ⩽i ⩽m), and two drains.
To see why the variable ordering ℘′ leads to a ℘′-ROBDD of exponential size, we consider
the ℘′-consistent cofactors
fb = fm|z1=b1,...,zm=bm =
!
i∈Ib
yi
where b = (b1, . . . , bn) and Ib = {i ∈{1, . . . , m} | bi = 1. The set of essential variables of
fb is {yi | i ∈Ib}. As f b, c ∈{0, 1}m, b ̸= c the index sets Ib and Ic are diﬀerent, the fb
and fc have diﬀerent essential variables. Therefore, fb ̸= fc if b ̸= c. But then the number
of ℘′-consistent cofactors is at least 2m. This yields that the ℘′-ROBDD for fm has at
most 2m nodes.

406
Computation Tree Logic
Since for many switching functions the ROBDD sizes for diﬀerent variable ordering can
vary enormously, the eﬃciency of BDD-based computations crucially relies on the use
of techniques that improve a given variable ordering. Although the problem to ﬁnd an
optimal variable ordering is known to be computationally hard (already the problem to
decide whether a given variable ordering is optimal is NP-hard [56, 386]), there are several
eﬃcient heuristics for improving the current ordering. Most promiment is the so-called
sifting algorithm [358] which relies on a local search for the best position for each variable,
when the ordering of the other variables is supposed to be ﬁxed. Explanations on such
variable reordering algorithms and further discussions on the variable ordering problem
are beyond the scope of this monograph. We refer the interested reader to the textbooks
[292, 418] and conclude the comments on the inﬂuence of the variable ordering by the
remark that there are also types of switching functions with ROBDDs of polynomial size
under all variable orderings and types of switching functions where any variable ordering
leads to a ROBDD of exponential size. An example of the latter is the middle bit of
the multiplication function [71].
Examples of switching functions where each variable
ordering leads to a ROBDD of at most quadratic size are symmetric functions. These are
switching functions where the function values just depend on the number of variables that
are assigned to 1. Stated diﬀerently, f ∈Eval(z1, . . . , zm) is symmetric if and only if
f([z1 = b1, . . . , zm = bm]) = f([z1 = bi1, . . . , zm = bim])
for each permutation (i1, . . . , im) of (1, . . . , m).
Examples of symmetric functions for
Var = {z1, . . . , zm} are z1∨z2∨. . .∨zm, z1∧z2∧. . .∧zm, the parity function z1⊕z2⊕. . .⊕zm
(which returns 1 iﬀthe number of variables that are assigned to 1 is odd), and the majority
function (which returns 1 iﬀthe number of variables that are assigned to 1 is greater than
the number of variables that are assigned to 0). The ROBDDs for symmetric functions
have the same topological structure for all variable orderings. This follows from the fact
that the ℘-ROBDD for a symmetric function can be transformed into the ℘′-ROBDD by
just modifying the variable labeling function.
Lemma 6.74.
ROBDD-Size for Symmetric Functions
If f is a symmetric function with m essential variables, then for each variable ordering ℘
the ℘-ROBDD has size O(m2).
Proof: Given a symmetric function f for m variables and a variable ordering ℘, say
℘= (z1, . . . , zm), then the ℘-consistent cofactors f|z1=b1,...,zi=bi and f|z1=c1,...,zi=ci agree
for all bit tuples (b1, . . . , bi) and (c1, . . . , ci) that contain the same number of 1’s. Thus,
there are at most i + 1 diﬀerent ℘-consistent cofactors of f that arise by assigning values
to the ﬁrst i variables. Hence, the total number of ℘-consistent cofactors is bounded above
by m
i=0(i + 1) = O(m2).

Symbolic CTL Model Checking
407
ROBDDs vs. CNF/DNF
Both the parity and the majority function provide examples
for switching functions with small ROBDD representations, while any representation of
them by conjunctive or disjunctive normal forms (CNF, DNF) requires formulae of expo-
nential length. Vice versa, there are also switching functions with short conjunctive or
disjunctive normal forms, while the ROBDD under any variable ordering has exponential
length (see, e.g., [418]). In fact, ROBDDs yield a totally diﬀerent picture for complexity
theoretic considerations than CNF or DNF. For example, given a CNF representation for
a switching function f, the task to generate a CNF for ¬f is expensive, as f might be
expressible by a CNF of polynomial length, while any CNF for ¬f has at least exponen-
tially many clauses. For ROBDDs, however, negation is trivial as we may simply swap
the values of the drains. In particular, for any variable ordering ℘, the ℘-ROBDDs for f
and ¬f have the same size. For another example, regard the satisﬁability problem, which
is known to be NP-complete for CNF, but again trivial for ROBDDs, since f ̸= 0 if and
only if the ℘-ROBDD for f does not contain a 0-drain. Similarly, the question whether
two CNFs are equivalent is computationally hard (coNP-complete), but can be solved for
℘-ROBDDs B and C by checking isomorphism. The latter can be performed by a simul-
taneous traversal of the ℘-OBDDs in time linear in the sizes of B and C. See Exercise
6.12, page 436. Note that these results do not contradict the complexity theoretic lower
bounds, since “linear time” for a ROBDD-based algorithm means linear in the size of the
input ROBDDs, which could be exponentially larger than equivalent input formulae (e.g.,
CNF).
6.7.4
Implementation of ROBDD-Based Algorithms
The eﬃciency of ROBDD-based algorithms to manipulate switching functions crucially
relies on appropriate implementation techniques.
In fact, with tricky implementation
techniques, equivalence checking for ROBDDs can even be realized in constant time. In
the sequel, we will explain the main ideas of such techniques, which provide the basis
for most BDD packages and serve as a platform for an eﬃcient realization of synthesis
algorithms on ROBDDs. The purpose of synthesis algorithms is to construct a ℘-ROBDD
for a function f1 op f2 (where op is a Boolean connective such as disjunction, conjunction,
implication, etc.), when ℘-ROBDDs for f1 and f2 are given. Recall that the symbolic
realization of the CTL model-checking procedure relies on such synthesis operations.
The idea, originally proposed in [301], is to use a single reduced decision graph with one
global variable ordering ℘to represent several switching functions, rather than using sep-
arate ℘-ROBDDs for each of the switching functions. All computations on these decision
graphs are interleaved with the reduction rules to guarantee redundance-freedom at any
time. Thus, the comparison of two represented functions simply requires checking equality
of the nodes for them, rather than analyzing their sub-OBDDs.

408
Computation Tree Logic
Figure 6.26: Example of a shared OBDD.
We start with the formal deﬁnition of a shared ℘-OBDD which is the same as a ℘-ROBDD,
the only diﬀerence being that we can have more than more root node.
Deﬁnition 6.75.
Shared OBDD
Let Var be a ﬁnite set of Boolean variables and ℘a variable ordering for Var. A shared
℘-OBDD (℘-SOBDD for short) is a tuple B = (V, VI, VT , succ0, succ1, var, val, v0)
where V , VI, VT , succ0, succ1, var, and val are as in ℘-OBDDs (see Deﬁnition 6.63 on
page 395). The last component is a tuple v0 = (v1
0, . . . , vk
0) of roots. The requirements are
as in ℘-ROBDDs, i.e., for all nodes v, w ∈V , (1) var(v) <℘var(succb(v)) if v ∈VI and
b ∈{0, 1} and (2) v ̸= w implies fv ̸= fw, where the switching function fv for the nodes
v ∈V is deﬁned as for OBDDs.
Figure 6.26 shows a shared OBDD with four root nodes that represent the functions
z1 ∧¬z2, ¬z2, z1 ⊕z2 and ¬z1 ∨z2.
If v is a node in a ℘-SOBDD B, then the sub-OBDD Bv is the ℘-ROBDD that results from
B by removing all nodes that are not reachable from v and declaring v to be the root node.
In fact, Bv is the ℘-ROBDD for fv, and thus, the size Nv of Bv is with the ℘-ROBDD
size of fv. Thus, an alternative view of an SOBDD is the combination of several ROBDDs
for the same variable ordering ℘by sharing nodes for common ℘-consistent cofactors. In
particular, an SOBDD has exactly two drains for the constant functions 0 and 1 (where we
ignore the pathological case of an SOBDD with a single root node representing a constant
function). Thus, if f1, . . . , fk are the functions for the root nodes v1
0, . . . , vk
0 of B, then the
size (i.e., total number of nodes) of B is often smaller than but at most Nf1 + . . . + Nfk
where Nf denotes the ℘-ROBDD size of f.
For the symbolic representation of a transition system by means of switching functions
Δ(x, x ′) for the transition relation and switching functions fa(x), a ∈AP, for the satis-
faction sets of the atomic propositions (see page 386), one might use a shared OBDD with
z1
z1
z1
z2
z2

Symbolic CTL Model Checking
409
root nodes for Δ and the fa’s. As we mentioned before, the chosen variable ordering ℘can
be crucial for the size of the SOBDD representing a transition system. Experimental stud-
ies have shown that typically good variable orderings are obtained when grouping together
the unprimed variables xi and their copies x ′
i. Later we will give some formal arguments
why such interleaved variable orderings, like ℘= (x1, x ′
1, . . . , xn, x ′
n), are advantageous.
To perform the CTL model-checking procedure in a symbolic way, the shared OBDD B
with root nodes for Δ and the fa’s has to be extended by new root nodes representing the
characteristic functions of the satisfaction sets Sat(Ψ) for the state subformulae Ψ of the
CTL formula Φ to be checked. For instance, if Φ = a ∧¬b with atomic propositions a, b,
then we ﬁrst have to insert a root node for the characteristic function f¬b = ¬fb for Sat(¬b)
and then a root node for the switching function fa ∧f¬b. The treatment of formulae of the
form, e.g., ∃♦Ψ or ∃□Ψ by means of Algorithms 20 or 21, requires creating additional root
nodes for the functions fi representing the current approximations of satisfaction sets. Of
course, adding a new root node for some switching function f also means that we have to
add nodes for all order-consistent cofactors of f that are not yet represented by a node in
B.
To support such dynamic changes of the set of switching functions to be represented, the
realization of shared OBDDs typically relies on the use of two tables: the unique table,
which contains the relevant information about the nodes and serves to keep the diagram
reduced during the execution of synthesis algorithms, and a computed table, which is
needed for eﬃciency reasons. Let us ﬁrst explain the ideas behind the use of the unique
table. The implementation of synthesis algorithms and the use of the computed table will
be explained later.
The Unique Table
The entries of the unique table are triples of the form
info(v) = ⟨var(v), succ0(v), succ0(v)⟩
for each inner node v. Note that these info-triples contain the relevant information which
is necessary for the applicability of the isomorphism rule. Accessing the unique table is
supported by a ﬁnd or add-operation which takes as argument a triple ⟨z, v1, v0⟩consisting
of a variable z and two nodes v1 and v0 with v1 ̸= v0.
The task of the ﬁnd or add-
operation is to check whether there exists a node v in the shared OBDD B such that
info(v) = ⟨z, v1, v0⟩. If so, then it returns node v, otherwise it creates a new z-node v
with 1-successor v1 and 0-successor v0, and makes a corresponding entry in the unique
table. Thus, the ﬁnd or add operation can be viewed as the SOBDD realization of the
isomorphism rule. In most BDD packages, the unique table is organized using appropriate
hashing techniques. We skip such details here and assume constant expected time to access
the into-triple for any node, and to perform the ﬁnd or add-operation.

410
Computation Tree Logic
Boolean Operators
Let us now consider how synthesis algorithms can be realized on
SOBDDs, using the unique table. An elegant, but also very eﬃcient way is to support a
ternary operator, called ITE for “if-then-else”, that covers all Boolean connectives. The
ITE operator takes as arguments three switching functions g, f1, f2 and composes them
according to “if g then f1 else f2”. Formally:
ITE(g, f1, f2)
=
(g ∧f1) ∨(¬ g ∧f2)
For the special case where g is constant we have ITE(0, f1, f2) = f2 and ITE(1, f1,
f2) = f1. The ITE operator ﬁts very well with the representation of the SOBDD nodes in
the unique table by their info-triples as we have:
fv = ITE( z, fsucc1(v), fsucc0(v) ).
The negation operator is obtained by ¬f = ITE(f, 0, 1). Also all other Boolean connec-
tives can be expressed by the ITE-operator. For example:
f1 ∨f2
=
ITE(f1, 1, f2)
f1 ∧f2
=
ITE(f1, f2, 0)
f1 ⊕f2
=
ITE(f1, ¬f2, f2)
=
ITE(f1, ITE(f2, 0, 1), f2)
f1 →f2
=
ITE(f1, f2, 1)
The realization of the ITE operator on an SOBDD B requires a procedure that takes
as input three nodes u, v1, v2 of B and returns a possibly new node w such that fw =
ITE(fu, fv1, fv2), by reusing existing nodes whenever possible and adding new nodes to
B if necessary. For this, the sub-OBDDs for the input nodes u, v1, and v2 are traversed
simultaneously in a top-down fashion, while the synthesis of the sub-ROBDD for w (and
generation of new nodes) is performed in a bottom-up manner. This method relies on the
following observation.
Lemma 6.76.
Cofactors of ITE(·)
If g, f1, f2 are switching functions for Var, z ∈Var and b ∈{0, 1}, then
ITE(g, f1, f2)|z=b = ITE(g|z=b, f1|z=b, f2|z=b).
Proof: For simplicity, let us assume that g, f1, f2 are switching functions for the same
variable set Var = {z, y1, . . . , ym}.
This, in fact, is no proper restriction as we may
simply take the union of the variable sets of g, f1 and f2 and regard all three functions as
switching functions for the resulting variable sets. Let (a, c) be a short-form notation for

Symbolic CTL Model Checking
411
the evaluation [z = a, y = c] ∈Eval(Var). Then, we have
ITE(g, f1, f2)|z=b(a, c)
=
ITE(g, f1, f2)(b, c)
=
( g(b, c) ∧f1(b, c) ) ∨( ¬g(b, c) ∧f2(b, c) )
=
( g|z=b(a, c) ∧f1|z=b(a, c) ) ∨( ¬g|z=b(a, c) ∧f2|z=b(a, c) )
=
ITE(g|z=b, f1|z=b, f2|z=b)(a, c).
Thus, a node in a ℘-SOBDD for representing ITE(g, f1, f2) is a node w such that info(w) =
⟨z, w1, w0⟩where
• z is the minimal essential variable of ITE(g, f1, f2) according to <℘,
• w1, w0 are SOBDD nodes with:
fw1 = ITE(g|z=1, f1|z=1, f2|z=1)
and
fw0 = ITE(g|z=0, f1|z=0, f2|z=0).
This observation suggests a recursive algorithm which determines z and then recursively
computes the nodes for ITE applied to the cofactors of g = fu, f1 = fv1, f2 = fv2 for
variable z. Since the explicit computation of z can be hard, we use the decomposition into
cofactors for the minimal variable z that is essential for fu, fv1 or fv2:
z = min{var(u), var(v1), var(v2)}
where the minimum is taken according to the total order <℘on Var ∪{⊥}.
(Recall
that we put var(v) = ⊥for any drain v and that x <℘⊥for all x ∈Var.)
If z ′ is
the ﬁrst essential variable of ITE(fu, fv1, fv2), then z ⩽℘z ′, since no variable y <℘z
appears in the sub-OBDDs of nodes u, v1, v2, and hence, no such variable y can be
essential for ITE(fu, fv1, fv2). The case z <℘z ′ is possible, if accidentally the cofactors
ITE(fu, fv1, fv2)|z=0 and ITE(fu, fv1, fv2)|z=1 agree. In this case, however, we are in the
situation of the elimination rule and the ITE algorithm returns the node representing
ITE(fu, fv1, fv2)|z=0. Otherwise, i.e., if the nodes w0 and w1 that have been recursively
determined for ITE(fu, fv1, fv2)|z=0 and ITE(fu, fv1, fv2)|z=1, respectively, are diﬀerent,
then z ′ = z and a node for representing ITE(fu, fv1, fv2) is obtained by the ﬁnd or add-
operation applied to the info-triple ⟨z, w1, w0⟩.

412
Computation Tree Logic
The question remains how to obtain the cofactors fu|z=b, fv1|z=b, and fv2|z=b. Nodes that
represent these functions are obtained easily since (by choice of variable z) nodes u, v1,
and v2 are on the z-level or below, i.e., z ⩽℘var(v) for v ∈{u, v1, v2}. If var(v) = z, then
fv|z=b is represented by the b-successor of v. If z <℘var(v), then z is not essential for fv
and we have fv|z=b = fv. Thus, if we deﬁne
v|z=b =
	 succb(v)
if var(v) = z
u
if z <℘var(v),
then v|z=b is the node in B representing fv|z=b. Hence, a node representing the function
ITE(fu, fv1, fv2)|z=b is obtained by a recursive call of the ITE algorithm with the arguments
u|z=b, v1|z=b and v2|z=b (Lemma 6.76). Note that these are already existing nodes in the
SOBDD B.
The steps to realize the ITE-operator on a shared OBDD by means of a DFS-based
traversal of the sub-OBDDs of u, v1, and v2 to determine the relevant cofactors (where
recursive calls of the ITE-algorithm are required) have been summarized in Algorithm 22
on page 412.
Algorithm 22 ITE(u, v1, v2) (ﬁrst version)
if u is terminal then
if val(u) = 1 then
w := v1
(* ITE(1, fv1, fv2) = fv1 *)
else
w := v2
(* ITE(0, fv1, fv2) = fv2 *)
ﬁ
else
z := min{var(u), var(v1), var(v2)};
w1 := ITE(u|z=1, v1|z=1, v2|z=1);
w0 := ITE(u|z=0, v1|z=0, v2|z=0);
if w0 = w1 then
w := w1;
(* elimination rule *)
else
w := ﬁnd or add(z, w1, w0);
(* isomorphism rule (?) *)
ﬁ
ﬁ
return w
Before discussing the complexity of the ITE algorithms, we will ﬁrst study how the size of
the SOBDD can change through performing the ITE algorithm. The size of the sub-OBDD
for the (possibly new) node w representing ITE(u, v1, v2) is bounded by Nu·Nv1·Nv2 where
Nv denotes the number of the nodes in the sub-OBDD Bv for node v. This follows from

Symbolic CTL Model Checking
413
the fact that each node w′ in the generated sub-OBDD for ITE(u, v1, v2) corresponds to
one or more triples (u′, v′
1, v′
2), where u′ is a node in Bu and v′
i a node in Bvi Formally:
Lemma 6.77.
ROBDD Size of ITE(g, f1, f2)
The size of the ℘-ROBDD for ITE(g, f1, f2) is bounded by Ng ·Nf1 ·Nf2 where Nf denotes
the size of the ℘-ROBDD for f.
Proof: Let ℘= (z1, . . . , zm) and let Bf denote the ℘-ROBDD for f where the nodes are
the ℘-consistent cofactors of f (see the proof of part (a) of Theorem 6.70). We write Vf
for the node set of Bf, i.e.,
Vf = { f|z1=b1,...,zi=bi | 0 ⩽i ⩽m, b1, . . . , bi ∈{0, 1} }.
Note that several of the cofactors f|z1=b1,...,zi=bi might agree, and hence, they stand for the
same element (node) of Vf. By Lemma 6.76, the node set VITE(g, f1, f2) of the ℘-ROBDD
BITE(g, f1, f2) for ITE(g, f1, f2) agrees with the set of switching functions
ITE(g|z1=b1,...,zi=bi, f1|z1=b1,...,zi=bi, f2z1 = b1, . . . , zi = bi)
where 0 ⩽i ⩽m, b1, . . . , bi ∈{0, 1}. Thus, the function
ı : Vg × Vf1 × Vf2 →VITE(g, f1, f2),
ı(g′, f ′
1, f ′
2) = ITE(g′, f ′
1, f ′
2)
that maps any triple (g′, f ′
1, f ′
2) where g′ is a node in Bg (i.e., a ℘-consistent cofactor of
g) and f ′
i a node in Bfi (i.e., a ℘-consistent cofactor of fi) to the node ITE(g′, f ′
1, f ′
2)
of BITE(g, f1, f2) yields a surjective mapping from Vg × Vf1 × Vf2 to some superset of
VITE(g, f1, f2). Hence:
NITE(g, f1, f2) = |VITE(g, f1, f2)| ⩽|Vg × Vf1 × Vf2| = Ng · Nf1 · Nf2
Observe that only the triples (g′, f ′
1, f ′
2) ∈Vg ×Vf1 ×Vf2 where g′, f ′
1, f ′
2 arise from g, f1, f2
by the same evaluation [z1 = b1, . . . , zi = bi] are mapped via ı to nodes of BITE(g, f1, f2).
Furthermore, ITE(g′, f ′
1, f ′
2) = ITE(g′′, f ′′
1 , f ′′
2 ) is possible for (g′, f ′
1, f ′
2) ̸= (g′′, f ′′
1 , f ′′
2 ).
Therefore, NITE(g, f1, f2) can be much smaller than Ng · Nf1 · Nf2.
As a consequence of Lemma 6.77, the size of the ℘-ROBDD for f1∨f2 is bounded above by
the product of the sizes of the ℘-ROBDDs for f1 and f2. Recall that f1∨f2 = ITE(f1, 1, f2)
and hence
Nf1∨f2 ⩽Nf1 · N1 · Nf2 = Nf1 · Nf2.
The same holds for conjunction and even for any other binary Boolean connective. This
also applies to operators like ⊕(xor, parity) where f ⊕g = ITE(f, ¬g, g), i.e., negation

414
Computation Tree Logic
is needed to express f ⊕g by ITE, f and g. Lemma 6.77 yields the bound Nf · N 2
g for
the ℘-ROBDD size for f ⊕g. However, since the ℘-ROBDDs for g and ¬g are isomorphic
up to exchanging the values of the drains, the recursive calls in the ITE-algorithms have
the form ITE(u, v, w) where fv = ¬fw. Hence, the number of nodes in the ℘-ROBDD for
f ⊕g is bounded by the number of triples (f ′, ¬g′, g′) where f ′ is a ℘-consistent cofactor
of f and g′ a ℘-consistent cofactor of g. This yields the upper bound Nf · Ng for the size
of the ℘-ROBDD of f ⊕g.
Computed Table
The problem with Algorithm 22 is that its worst-case running time
is exponential.
The reason for this is that, if there are several paths that lead from
(u, v1, v2) to (u′, v′
1, v′
2), then ITE(u′, v′
1, v′
2) is invoked several times and the whole sub-
OBDDs of these nodes u′, v′
1, v′
2 are traversed in each of these recursive invocations. To
avoid such redundant recursive invocations one uses a computed table that stores the tuples
(u, v1, v2), where ITE(u, v1, v2) has already been executed, together with the result, i.e.,
the SOBDDD-node w with fw = ITE(fu, fv1, fv2). Thus, we may reﬁne the ITE-algorithm
as shown in Algorithm 23 on page 414.
Algorithm 23 ITE(u, v1, v2)
if there is an entry for (u, v1, v2, w) in the computed table then
return node w
else
(* no entry for ITE(u, v1, v2) in the computed table *)
if u is terminal then
if val(u) = 1 then w := v1 else w := v2 ﬁ
else
z := min{var(u), var(v1), var(v2)};
w1 := ITE(u|z=1, v1|z=1, v2|z=1);
w0 := ITE(u|z=0, v1|z=0, v2|z=0);
if w0 = w1 then w := w1 else w := ﬁnd or add(z, w1, w0) ﬁ;
insert (u, v1, v2, w) in the computed table;
return node w
ﬁ
ﬁ
The number of recursive calls in Algorithm 23 for the input-nodes u, v1, v2 agrees with the
℘-ROBDD size of ITE(fu, fv1, fv2), which is bounded by Nu · Nv1 · Nv2, where Nv = Nfv
denotes the number of nodes in the sub-OBDD of node v. The cost per recursive call
is constant when the time to access the computed table and to perform the ﬁnd or add-
operation is assumed to be constant. This is an adequate assumption if suitable hashing
techniques are used to organize both tables. However, in practice the running time of the
ITE algorithm is often much better than this upper bound. First, only in extreme cases

Symbolic CTL Model Checking
415
is the size of the ℘-ROBDD for ITE(fu, fv1, fv2) roughly Nu · Nv1 · Nv2. Second, the use of
the ITE operator yields the advantage that all synthesis algorithms that are expressible
via ITE rely on the same computed table. This increases the hit rate and makes it possible
that the computation aborts due to an entry in the computed table that has been made
during the synthesis of another function. Moreover, there are several tricks to intensify
this phenomenon. One simple trick is to make use of equivalence rules, such as
f1 ∨f2 = ITE(f1, 1, f2) = ITE(f2, 1, f1) = ITE(f1, f1, f2) = . . . ,
and to transform the arguments of ITE into so-called standard triples. Furthermore, the
ITE-algorithm can be reﬁned by terminating the traversal in certain special cases. E.g.,
we have ITE(g, f, f) = f and ITE(g, 1, 0) = g, which allows aborting the computation if
either the last two arguments agree or they equal the pair consisting of the 1- and 0-drains.
Remark 6.78.
The Negation Operator
We noticed above that the negation operator can be realized as an instance of the ITE
operator as we have ¬f = ITE(f, 0, 1). However, applying the ITE algorithm seems to be
unnecessarily complicated since the ℘-ROBDDs for f and ¬f just diﬀer in the values of
the drains. In fact, swapping the values of the drains is an adequate technique to realize
negation on ROBDDs, but it is not for shared OBDDs (since changing the values of the
drains also aﬀects the functions of all other root nodes). However, there is a simple trick
to perform negation in SOBDDs in constant time. It relies on the use of complement bits
for the edges. This permits the representation of f and ¬f by a single node. Negation
then just means swapping the value of the complement bit of the incoming edge. Besides
leading to smaller SOBDD sizes, the use of complement bits also tightens the eﬀect of
standard triples, since now more equivalence rules can be used to identify the input triples
for ITE or for early termination. E.g., we have
ITE(f1, 1, f2) = f1 ∨f2 = ¬(¬f1 ∧¬f2) = ¬ITE(¬f1, ¬f2, 0)
and ITE(g, 0, 1) = ¬g. However, to ensure canonicity some extra requirements are needed.
For instance, the constant function 0 could be represented by the 0-drain (with unnegated
complement bit) or the 1-drain with negated complement bit. To guarantee the uniqueness,
one could require that only the 1-drain be used and that complement bits be used only
for the 0-edges (i.e., edges from the inner nodes to their 0-successors) and the pointers
to the root nodes. For more information on such advanced implementation techniques,
further theoretical considerations on OBDDs and variants thereof, we refer to textbooks
on BDDs, such as [134, 292, 300, 418].
Other Operators on OBDDs
Although all Boolean connectives can be expressed by
the ITE operator, some more operators are required to perform, e.g., the CTL model

416
Computation Tree Logic
checking procedure with an SOBDD representation of the transition system. Recall that
in the symbolic computation of Sat(∃♦B) and Sat(∃□B) (see Algorithms 20 and 21 on
page 391) we use iterations of the form
fj+1(x) := fj(x) op ∃x′.( Δ(x, x ′) ∧fj(x ′) )
where op ∈{∨, ∧} and fj = χT is the characteristic function of some set T. Thus, fj+1 is
the characteristic function of T ∩Pre(T) (if op = ∧) and T ∪Pre(T) (if op = ∨). (For the
treatment of constrained reachability properties like ∃(C U B), we have an additional con-
junction with χC, but this is just a technical detail.) Besides disjunction and conjunction,
these iterations use existential quantiﬁcation and renaming. The major diﬃculty is the
preimage computation, i.e., the computation of the symbolic representation of Pre(T) by
means of the expression ∃x ′.(Δ(x, x ′) ∧fj(x ′)), which is often called a relational product.
Let us start with the rename operator which is inherent in fj(x ′) since fj is a switching
function for the variables in x and fj(x ′) = fj{x ′ ←x} means the function that results
from fj when renaming the unprimed variables xi into their primed copies x ′
i. At ﬁrst
glance, the renaming operator appears to be trivial as we simply may modify the variable
labeling function by replacing xi with x ′
i.
This operation certainly transforms a given
ROBDD for f(x) into a ROBDD for f(x ′). However, if we are given an arbitrary variable
ordering ℘where the relative order of the unprimed variables can be diﬀerent from the
relative order of the primed variables (i.e., xi <℘xj while x ′
j <℘x ′
i) then this renaming
operator is no longer adequate, since the resulting ROBDD for f(x ′) would rely on another
ordering than ℘. Furthermore, for an implementation with shared OBDDs, modifying
existing nodes is not appropriate since then the functions for all root nodes might be
aﬀected. In fact, it is not possible to design a general rename operator which runs in time
polynomial in the size of the input ROBDD. To see why, consider the function
f = (z1 ∧y1) ∨(z2 ∧y2) ∨. . . ∨(zm ∧ym)
of Example 6.73 (page 404).
Suppose Var = {zi, yi, z ′
i, y′
i | 1 ⩽i ⩽m} and ℘=
(zm, ym, . . . , z1, y1, z ′
1, . . . , z ′
m, y′
1, . . . , y′
m) and that we are given the ℘-ROBDD Bf for f in
the form of a root node v of a ℘-SOBDD. The goal is now to rename zi into z ′
i and yi into
y′
i in f, i.e., to compute the ℘-ROBDD representation of
f{z ′
i ←zi, y′
i ←yi | 1 ⩽i ⩽m} = (z ′
1 ∧y′
1) ∨. . . ∨(z ′
m ∧y′
m).
By the results of Example 6.73: while the ℘-ROBDD size of f is 2m + 2, the ℘-ROBDD
size of f{. . .} is Ω(2m). This observation shows that there is no linear-time algorithm that
realizes the rename operator for arbitrary variable orderings. However, if we suppose that
xi and x ′
i are neighbors in the ordering ℘, e.g., xi <℘x ′
i and there is no variable z with xs <℘
z <℘x ′
i, then renaming xi into x ′
i for a function f(x) is simple. As for the ITE operator, we
can work with a DFS-based traversal of the sub-OBDD for the node representing f(x) and

Symbolic CTL Model Checking
417
generate the ROBDD for f(x′) in a bottom-up manner; see Algorithm 24. The algorithm
takes as input a node v of a π-SOBDD and tuples x = (x1, . . . , xn), x ′ = (x ′
1, . . . , x ′
n), of
pairwise distinct variables such that x ′
1, . . . , x ′
n are not essential for fv and xi und x ′
i are
neighbors in π. The output is a node w such that fw = fv{x ←x ′}. To avoid multiple
invocations of the algorithms with the same input node v, we use a computed table that
stores all nodes v where Rename(v, x ←x ′) has already been executed together with the
output node w, i.e., the node w with fw = fv{x ←x ′}.
Algorithm 24 Rename(v, x ←x ′)
if there is an entry (v, w) in the computed table then
return w
else
if v ist terminal then
w := v
else
w0 := Rename(succ0(v), x ←x ′);
w1 := Rename(succ1(v), x ←x ′);
if var(v) = zj for some j ∈{1, . . . , n} then
z := z ′
j
(* replace zj with z ′
j *)
else
z := var(v)
ﬁ
w := ﬁnd or add(z, w1, w0);
ﬁ
insert (u, w) in the computed table;
return w
ﬁ
Remark 6.79.
Interleaved Variable Orderings for Transition Systems
We noticed before (page 409) that interleaved variable orderings, such as (x1, x ′
1, . . . , xn, x ′
n),
are favorable for the representation of transition systems. The rename operator yields one
reason, as interleaved variable orderings permit use of the renaming that is inherent in the
OBDD algorithms for the preimage computation by the above algorithm. Another formal
argument for interleaved variable orderings is that they are beneﬁcial for the construction
of the ROBDD representation for the transition relation of a composite transition system.
In Remark 6.59 (page 389) we saw that if TS arises from the synchronous product of
transition systems TS1, . . . , TSm, then the switching function Δ(x 1, . . . , x n, x ′
1, . . . , x ′
n) for
TS’s transition relation is obtained by the conjunction of the switching functions Δi(x i, x ′
i)
for the transition relations in TSi, i = 1, . . . , m. Since the Δi’s do not have common
variables the ℘-ROBDD size of Δ is bounded by
NΔ ⩽NΔ1 + . . . + NΔm

418
Computation Tree Logic
whenever ℘is an interleaved variable ordering where all variables in x i and x ′
i are grouped
together. Thus, there is no exponential blowup for the ROBDD sizes! Although Lemma
6.77 yields the upper bound NΔ1 · . . . · NΔm for any variable ordering, for such interleaved
variable orderings ℘at most linear growth of the ℘-ROBDD sizes is guaranteed. This is due
to the fact that the ℘-ROBDD for Δ arises by linking the ℘-ROBDDs for Δ1, . . . , Δm. E.g.,
if we suppose that all variables in x i, x ′
i appear after the variables in x 1, x ′
1, . . . , x i−1, x ′
i−1
in ℘, then we may simply redirect any edge to the 1-drain in the ℘-ROBDD for Δi−1 to
the root of the ℘-ROBDD for Δi (for 1 ⩽i < m). This yields the ℘-ROBDD for Δ.
A slightly more involved argument applies to the interleaving TS = TS1 ||| . . . ||| TSm
where Δ arises by the disjunction of the Δi’s together with the side conditions x j = x ′
j
for i ̸= j. With an interleaved variable ordering where the variables for TSi appear before
the variables of TSi+1, . . . , TSm, we can guarantee that the ℘-ROBDD size NΔ is bounded
by O( (NΔ1 + . . . + NΔm) · n2 ) where the n is the total number of variables in TS. The
additional factor O(n2) stands for the representation of the conditions x i = x ′
i.
Existential quantiﬁcation is reducible to ITE and the cofactor operator, as we have ∃x.f =
f|x=0 ∨f|x=1. As we mentioned in the explanations for the ITE operator, the cofactor
operator f →f|x=b is trivial if x ⩽℘z for the ﬁrst essential variable z of f in the
given variable ordering ℘, since then f|z=b is represented by the b-successor of the node
representing f, if x = z, and f|x=b = f, if x <℘z or f is constant. If a representation for
f|x=b is required where z <℘x, then we may use the fact that (f|x=b)|z=c = (f|z=c)|x=b
and apply the cofactor-operator recursively to the successors of the node representing f.
This leads to Algorithm 25 on 419. Here, again, we use a computed table that organizes
all pairs (v, w) where the cofactor fv|x=b is known to be represented by node w.
The time complexity of the renaming algorithm, as well as the algorithm for obtaining
cofactors is bounded by O(size(Bv)) as both rely on a DFS-based traversal of the sub-
OBDD Bv, assuming constant time for accessing the entries in the unique and computed
table. The ℘-ROBDD size of f agrees with the ℘-ROBDD size of f{x ←x ′} under the
assumptions we made for x, x ′ and ℘. The ℘-ROBDD size of f|x=b is at most the ℘-
ROBDD size of f. This follows from the fact that given the ℘-ROBDD Bf for f, an
℘-ROBDD for f|x=b is obtained by redirecting any edge w →u that leads to an x-node
u to the b-successor of u and then removing all x-nodes.7
In summary, the preimage
computation via the relational product
∃x.(Δ ∧f{x ′ ←x})
– which is required for, e.g., the symbolic computation of Sat(∃□B) – could be performed
by ﬁrst applying the rename operator to f, then the conjunction operator (as an instance of
7Although this yields a correct operator for constructing the ℘-ROBDD for f|x=b from the ℘-ROBDD
for f, the redirection of edges is not adequate for an implementation with shared OBDDs.

Symbolic CTL Model Checking
419
Algorithm 25 Cof(v, x, b)
if there is an entry (v, w) in the computed table then
return w
else
if v ist terminal then
w := v
else
if x ⩽℘var(v) then
w := v|x=b
else
z := var(v);
w1 := Cof(succ1(v), x, b);
w0 := Cof(succ0(v), x, b);
if w0 = w1 then w := w1 else w := ﬁnd or add(z, w1, w0) ﬁ
ﬁ
ﬁ
insert (u, w) in the computed table;
return node w
ﬁ
ITE operator) to the nodes representing Δ and f(x′), and ﬁnally computing the existential
quantiﬁcations by cofactors and disjunctions. This naive approach is very time-consuming
as it relies on several top-down traversals in the shared OBDD. It also yields the problem
that the ROBDD representation for Δ ∧f{x ′ ←x} could be very large.
A more elegant approach for a BDD-based preimage computation by means of the rela-
tional product ∃x′. ( Δ ∧f{x ′ ←x} ) is to realize the existential quantiﬁcations, renaming
and conjunction simultaneously by a single DFS traversal of the sub-OBDDs of the nodes
representing Δ and f, with intermediate calls of the ITE operator to realize the dis-
junctions that are inherent in the existential quantiﬁcation. Algorithm 26 on page 420
summarizes the main steps of this approach.
The input of Algorithm 26 are two nodes u and v of a ℘-SOBDD such that fu = Δ(x, x ′)
and fv = f(x ′).
The assumptions about the variable tuples x, x ′ are as above, i.e.,
x = (x1, . . . , xn) and x ′ = (x ′
1, . . . , x ′
n) are tuples consisting of pairwise distinct variables
such that the unprimed variables xi and their primed copies x ′
i are neighbours in ℘. For
simplicity, let us suppose that ℘interleaves the unprimed and primed variables, say
x1 <℘x ′
1 <℘x2 <℘x ′
2 <℘. . . <℘xn <℘x ′
n.
The output of Algorithm 26 is a (possibly new) node w with fw = ∃x ′. ( Δ(x, x ′)∧f(x ′) ) =
∃x′.(fu ∧fv). The termination condition of Algorithm 26 is given by the cases: (i) there
exists an entry in the computed table, or (ii) Δ = 0 or f = 0 in which case ∃x ′.(Δ∧f) = 0,

420
Computation Tree Logic
Algorithm 26 Relational product RelProd(u, v)
if there exists an entry (u, v, w) in the computed table then return w ﬁ;
if u or v is the 0-drain then return the 0-drain ﬁ;
if u and v are the 1-drain then return the 1-drain ﬁ;
y := min{var(u), var(v)}, say y ∈{xi, x ′
i}
if y = xi then
w1,0 := RelProd(u|xi=1,x ′
i=0, v|xi=0);
w1,1 := RelProd(u|xi=1,x ′
i=1, v|xi=1);
w1 := ITE(w1,0, 1, w1,1);
w0,0 := RelProd(u|xi=0,x ′
i=0, v|xi=0, x, x ′);
w0,1 := RelProd(u|xi=0,x ′
i=1, v|xi=1, x, x ′);
w0 := ITE(w0,0, 1, w0,1);
if w1 = w0 then
w := w1
(* elimination rule *)
else
w := ﬁnd or add(xi, w1, w0)
ﬁ
else
w0 := RelProd(u|x ′
i=0, v);
w1 := RelProd(u|x ′
i=1, v);
w := ITE(w0, 1, w1)
ﬁ
insert (u, v, w) in the computed table;
return w

Symbolic CTL Model Checking
421
or (iii) Δ = f = 1 in which case ∃x ′.(Δ ∧f) = 1. In the remaining cases, the traversal of
the sub-OBDDs of u and v relies on the expansion rule:
∃x ′
1∃x ′
2 . . . ∃x ′
n. ( Δ ∧f{x ′
1 ←x1, x ′
2 ←x2, . . . , x ′
n ←xn} ) )|x1=b
=
∃x ′
2 . . . ∃x ′
n. ( Δ|x1=b,x ′
1=0 ∧f|x1=0{x ′
2 ←x2, . . . , x ′
n ←xn} )
∨
∃x ′
2 . . . ∃x ′
n. ( Δ|x1=b,x ′
1=1 ∧f|x1=1{x ′
2 ←x2, . . . , x ′
n ←xn} )
In the literature, several techniques have been proposed that serve to improve the image
or preimage computation. These range from techniques that rely on partitionings of the
variables that attempt to perform the existential quantiﬁcation as soon as possible (as they
decrease the number of essential variables and often lead to smaller ROBDD sizes). Other
techniques rely on so-called input- or output splitting (which use alternative expansion
rules), and special ROBDD operators that attempt to replace, e.g., Δ with other switching
functions ˜Δ such that Δ ∧f = ˜Δ ∧f and such that the ℘-ROBDD for Δ is smaller than
the ℘-ROBDD for Δ. In the case of an iterated preimage computation by T0 = B and
Tj+1 = Tj ∪Pre(Tj) for the symbolic computation of Pre∗(B), one might also switch from
Tj to any set ˜T such that Tj \Tj−1 ⊆˜T ⊆Tj and compute Tj ∪Pre( ˜T). For such advanced
techniques, we refer the interested reader to [92, 292, 374] and the literature mentioned
there.
Summary
We now have all ingredients for a symbolic realization of the standard CTL
model-checking approach which recursively computes the satisfaction sets of the subformu-
lae by means of shared OBDDs. Initially, one has to construct the ROBDD representation
of the transition system to be analyzed. This can be done in a compositional way by
means of synthesis operators (disjunction, conjunction, etc.)
as mentioned in Remark
6.59. Furthermore, we assume that ROBDD representations of the satisfaction sets for
the atomic propositions are given.
This assumption is justiﬁed since often the atomic
propositions can serve as variables for the encoding of the states. (And in this case their
satisfaction set is just given by a projection function.) The CTL model-checking procedure
can then be performed by means of the ITE algorithm (to treat the propositional logic
fragment of CTL) and the symbolic BFS-based algorithms sketched in Algorithms 20 and
21. Both rely on an iterative preimage computation. Techniques to do this eﬃciently have
been discussed above. The termination condition requires checking the equality of two
switching functions. This, in fact, is trivial for shared OBDDs since it simply amounts to
the comparison of the corresponding nodes and can be performed in constant time.

422
Computation Tree Logic
6.8
CTL∗
We saw in Theorem 6.21 on page 337 that CTL and LTL have incomparable expressiveness.
An extension of CTL, proposed by Emerson and Halpern, called CTL∗, combines the
features of both logics, and thus is more expressive than either of them.
6.8.1
Logic, Expressiveness, and Equivalence
CTL∗is an extension of CTL as it allows path quantiﬁers ∃and ∀to be arbitrarily nested
with linear temporal operators such as ⃝and U. In contrast, in CTL each linear temporal
operator must be immediately preceded by a path quantiﬁer. As in CTL, the syntax of
CTL∗distinguishes between state and path formulae. The syntax of CTL∗state formulae
is roughly as in CTL, while the CTL∗path formulae are deﬁned as LTL formulae, the only
diﬀerence being that arbitrary CTL∗state formulae can be used as atoms. For example,
∀⃝⃝a is a legal CTL∗formula, but does not belong to CTL. The same applies to the
CTL∗formulae ∃□♦a and ∀□♦a. (However, ∀□♦a is equivalent to the CTL formula
∀□∀♦a.)
Deﬁnition 6.80.
Syntax of CTL∗
CTL∗state formulae over the set AP of atomic propositions, brieﬂy called CTL∗formulae,
are formed according to the following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   ∃ϕ
where a ∈AP and ϕ is a path formula. The syntax of CTL∗path formulae is given by
the following grammar:
ϕ ::= Φ
   ϕ1 ∧ϕ2
   ¬ϕ
   
⃝ϕ
   ϕ1 U ϕ2
where Φ is a state formula, and ϕ, ϕ1, and ϕ2 are path formulae.
As for LTL or CTL, we use derived propositional logic operators like ∨, →, . . . and let
♦ϕ = true U ϕ
and
□ϕ = ¬♦¬ϕ.
The universal path quantiﬁer ∀can be deﬁned in CTL∗by existential quantiﬁcation and
negation:
∀ϕ = ¬∃¬ϕ.
(Note that this is not the case for CTL.)

CTL∗
423
For example, the following formulae are syntactically correct CTL∗formulae:
∀□( ⃝♦a ∧¬(b U □c) )
and
∀⃝□¬a
∧
∃♦□(a ∨∀(b U a)).
Note that these formulae are not CTL formulae.
Deﬁnition 6.81.
Satisfaction Relation for CTL∗
Let a ∈AP be an atomic proposition, TS = (S, Act, →, I, AP, L) be a transition system
without terminal states, state s ∈S, Φ, Ψ be CTL∗state formulae, and ϕ, ϕ1 and ϕ2 be
CTL∗path formulae. The satisfaction relation |= is deﬁned for state formulae by
s |= a
iﬀ
a ∈L(s),
s |= ¬ Φ
iﬀ
not s |= Φ,
s |= Φ ∧Ψ
iﬀ
(s |= Φ) and (s |= Ψ),
s |= ∃ϕ
iﬀ
π |= ϕ for some π ∈Paths(s).
For path π, the satisfaction relation |= for path formulae is deﬁned by:
π |= Φ
iﬀ
s0 |= Φ,
π |= ϕ1 ∧ϕ2
iﬀ
π |= ϕ1 and π |= ϕ2,
π |= ¬ϕ
iﬀ
π ̸|= ϕ,
π |= ⃝ϕ
iﬀ
π[1..] |= ϕ,
π |= ϕ1 U ϕ2
iﬀ
∃j ⩾0. (π[j..] |= ϕ2 ∧(∀0 ⩽k < j. π[k..] |= ϕ1))
where for path π = s0 s1 s2 . . . and integer i ⩾0, π[i..] denotes the suﬃx of π from index
i on.
Deﬁnition 6.82.
CTL∗Semantics for Transition Systems
For CTL∗-state formula Φ, the satisfaction set Sat(Φ) is deﬁned by
Sat(Φ) = { s ∈S | s |= Φ }.
The transition system TS satisﬁes CTL∗formula Φ if and only if Φ holds in all initial
states of TS:
TS |= Φ
if and only if
∀s0 ∈I. s0 |= Φ.

424
Computation Tree Logic
Thus, TS |= Φ if and only if all initial states of TS satisfy the formula Φ.
LTL formulae are CTL∗path formulae in which the elementary state formulae Φ are re-
stricted to atomic propositions. Apparently, the interpretation of LTL over the paths of a
transition system (see Deﬁnition 5.7, page 237) corresponds to the semantics of LTL ob-
tained as a sublogic of CTL∗. The following theorem demonstrates that the corresponding
claim also holds for states. Thereby, every LTL formula ϕ is identiﬁed with the CTL∗
formula ∀ϕ, and the semantics of LTL over states is taken as a reference. Recall that
according to the LTL semantics in paths, s |= ϕ if and only if π |= ϕ for all π ∈Paths(s).
Theorem 6.83.
Embedding of LTL in CTL∗
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states. For each
LTL formula ϕ over AP and for each s ∈S:
s |= ϕ
  
LTL semantics
if and only if
s |= ∀ϕ



CTL∗semantics
.
In particular, TS |= ϕ (with respect to the LTL semantics) if and only if TS |= ∀ϕ (with
respect to the CTL∗semantics)
As a result, it is justiﬁed to understand LTL (with interpretation over the states of a
transition system) as a sublogic of CTL∗. Theorem 6.21 (page 337) stated that the expres-
sivenesses of LTL and CTL are incomparable. Since LTL is a sublogic of CTL∗, it now
follows that CTL∗subsumes LTL and CTL, i.e., there exist CTL∗formulae which can be
expressed neither in LTL nor in CTL.
Theorem 6.84.
CTL∗is More Expressive Than LTL and CTL
For the CTL∗formula over AP = { a, b },
Φ = (∀♦□a) ∨(∀□∃♦b),
there does not exist any equivalent LTL or CTL formula.
Proof: This follows directly from the fact that ∀□∃♦b is a CTL formula that cannot be
expressed in LTL, whereas ♦□a is an LTL formula that cannot be expressed in CTL.
Both these facts follow from Theorem 6.21 (page 337).
The relationship between LTL, CTL, and CTL∗is depicted in Figure 6.27.

CTL∗
425
♦(a ∧⃝a)
□♦a
♦(a ∧⃝a)
∀□∃♦a
LTL
CTL
CTL∗
∨
∀□∃♦a
Figure 6.27: Relationship between LTL CTL and CTL∗.
One of the consequences of this fact, is that—as in LTL—fairness assumptions can be
expressed syntactically in CTL∗. For instance, for fairness assumption fair, formulae of
the form
∀(fair →ϕ)
or
∃(fair ∧ϕ)
are legal CTL∗formulae. As for CTL or LTL, semantic equivalence ≡can be deﬁned for
CTL∗formulae. Apart from the equivalence laws for CTL and the laws resulting from the
equivalence laws for LTL, there exists a series of other important laws that are speciﬁc to
CTL∗. This includes, among others, the laws listed in Figure 6.28.
Example instances of the duality laws for the path quantiﬁers are
¬∀□♦a ≡∃♦□¬a
and
¬∃□♦a ≡∀♦□¬a.
As usual, universal quantiﬁcation does not distribute over disjunction, and the same ap-
plies to existential quantiﬁcation and conjunction:
∀(ϕ ∨ψ) ̸≡∀ϕ ∨∀ψ
and
∃(ϕ ∧ψ) ̸≡∃ϕ ∧∃ψ.
Path quantiﬁer elimination should also be considered with care. For instance,
∀♦□ϕ ̸≡∀♦∀□ϕ
and
∃□♦Φ ̸≡∃□∃♦ϕ.
Finally, we remark that for CTL∗-state formula Φ we have that
∃Φ ≡Φ
and
∀Φ ≡Φ.
This is illustrated by means of an example.
Consider the CTL∗formula ∃∀♦a.
This
formula holds in state s whenever there exists an inﬁnite path fragment π = s0 s1 s2 . . . ∈
Paths(s), such that π |= ∀♦a. Since π |= ∀♦a holds if and only if s = s0 |= ∀♦a, the
formula ∃∀♦a is equivalent to ∀♦a.

426
Computation Tree Logic
duality laws for path quantiﬁers
¬∀ϕ
≡
∃¬ϕ
¬∃ϕ
≡
∀¬ϕ
distributive laws
∀(ϕ1 ∧ϕ2)
≡
∀ϕ1 ∧∀ϕ2
∃(ϕ1 ∨ϕ2)
≡
∃ϕ1 ∨∃ϕ2
quantiﬁer absorption laws
∀□♦ϕ
≡
∀□∀♦ϕ
∃♦□ϕ
≡
∃♦∃□ϕ
Figure 6.28: Some equivalence laws for CTL∗.
Remark 6.85.
Extending CTL with Boolean Connectors for Path Formulae (CTL+)
Consider the following fragment, called CTL+, of CTL∗, which extends CTL by allowing
Boolean operators in path formulae.
CTL+ state formulae over the set AP of atomic
proposition are formed according to the following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   ∃ϕ
   ∀ϕ
where a ∈AP and ϕ is a path formula. CTL+ path formulae are formed according to the
following grammar:
ϕ ::= ϕ1 ∧ϕ2
   ¬ϕ
   
⃝Φ
   Φ1 U Φ2
where Φ, Φ1, and Φ2 are state formulae, and ϕ1, ϕ2 are path formulae. Surprisingly, CTL+
is as expressive as CTL, i.e., for any CTL+ state formula Φ+ there exists an equivalent
CTL formula Φ. For example:
∃(a W b)



CTL formula
≡∃( (a U b) ∨□a )



CTL+ formula
or
∃(♦a ∧♦b)



CTL+ formula
≡∃♦(a ∧∃♦b) ∧∃♦(b ∧∃♦a)



CTL formula
.

CTL∗
427
We do not provide here a full proof for transforming CTL+ formulae into equivalent CTL
formulae. The transformation relies on equivalence laws such as
∃(¬ ⃝Φ)
≡
∃⃝¬Φ
∃(¬(Φ1 U Φ2))
≡
∃( (Φ1 ∧¬Φ2) U (¬Φ1 ∧¬Φ2) )
∨
∃□¬Φ2
∃(⃝Φ1 ∧⃝Φ2)
≡
∃⃝(Φ1 ∧Φ2)
∃(⃝Φ ∧(Φ1 U Φ2))
≡
(Φ2 ∧∃⃝Φ)
∨
(Φ1 ∧∃⃝(Φ ∧∃(Φ1 U Φ2)))
∃((Φ1 U Φ2) ∧(Ψ1 U Ψ2))
≡
∃((Φ1 ∧Ψ1) U (Φ2 ∧∃(Ψ1 U Ψ2))) ∨
∃((Φ1 ∧Ψ1) U (Ψ2 ∧∃(Φ1 U Φ2)))
...
Thus, CTL can be expanded by means of a Boolean operator for path formulae without
changing the expressiveness.
However, CTL+ formulae can be much shorter than the
shortest equivalent CTL formulae.
6.8.2
CTL∗Model Checking
This section treats a model-checking algorithm for CTL∗.
The CTL∗model-checking
problem is to establish whether TS |= Φ holds for a given ﬁnite transition system TS
(without terminal states) and the CTL∗state formula Φ. As we will see, an appropriate
combination of the model-checking algorithms for LTL and CTL suﬃces.
As for CTL, the model-checking algorithm for CTL∗is based on a bottom-up traversal
of the syntax tree of the formula Φ to be checked. Due to the bottom-up nature of the
algorithm, the satisfaction set Sat(Ψ) for any state sub formulae Ψ of Φ has been computed
before, and can be used to determine Sat(Φ). This holds in particular for the maximal
proper state subformulae of Φ.
Deﬁnition 6.86.
Maximal Proper State Subformula
State formula Ψ is a maximal proper state subformula of Φ whenever Ψ is a subformula of
Φ that diﬀers from Φ and that is not contained in any other proper state subformula of
Φ.
The basic concept is to replace all maximal proper state subformulae of Φ by fresh atomic
propositions a1, . . . , ak, say.
These propositions do not occur in Φ and are such that
ai ∈L(s) if and only if s ∈Sat(Ψi), the ith maximal state subformula of Φ. For state

428
Computation Tree Logic
subformulae whose “top-level” operator is a Boolean operator (such as negation or con-
junction), the treatment is obvious. Let us consider the more interesting case of Ψ = ∃ϕ.
By replacing all maximal state subformulae in ϕ, an LTL formula results! Since
s |= ∃ϕ
iﬀ
s ̸|= ∀¬ϕ



CTL∗semantics
iﬀ
s ̸|= ¬ϕ



LTL semantics
,
it suﬃces to compute the satisfaction set
SatLTL(¬ϕ) = { s ∈S | s |=LTL ¬ϕ }
by means of an LTL model checker. (Here, the notations SatLTL(·) and |=LTL are used to
emphasize that the basis is the LTL satisfaction relation.) The satisfaction set for Φ = ∃ϕ
is now obtained by complementation:
SatCTL∗(∃ϕ) = S \ SatLTL(¬ϕ).
For CTL∗formulae where the outermost operator is an universal quantiﬁcation we simply
may deal with
SatCTL∗(∀ϕ) = SatLTL(ϕ)
where, as before, it is assumed that ϕ is an LTL formula resulting from the replacement
of the maximal state subformula with fresh atomic propositions.
The main steps of the CTL∗model-checking procedure are presented in Algorithm 27 on
page 429.
Example 6.87.
Abstract Example of CTL∗Model Checking
The CTL∗model-checking approach is illustrated by considering the CTL∗formula:
∃ϕ
where
ϕ = ⃝(∀□∃♦a) ∧♦□∃(⃝a ∧□b).
The maximal proper state subformulae of ϕ are
Φ1 = ∀□∃♦a
and
Φ2 = ∃(⃝a ∧□b).
Thus:
ϕ = ⃝(∀□∃♦a)



Φ1
∧♦□∃(⃝a ∧□b)



Φ2
= ⃝Φ1 ∧♦□Φ2.
According to the model-checking algorithm for CTL∗, the satisfaction sets Sat(Φi) are
computed recursively. Subsequently, Φ1 and Φ2 are replaced with the atomic propositions
a1 and a2, say. This yields the following LTL formula over the set of propositions AP′ =
{ a1, a2 }:
ϕ′
=
⃝a1 ∧♦□a2.

CTL∗
429
Algorithm 27 CTL∗model checking algorithm (basic idea)
Input: ﬁnite transition system TS with initial states I, and CTL∗formula Φ
Output: I ⊆Sat(Φ)
for all i ⩽| Φ | do
for all Ψ ∈Sub(Φ) with | Ψ | = i do
switch(Ψ):
true
:
Sat(Ψ) := S;
a
:
Sat(Ψ) := { s ∈S | a ∈L(s) };
a1 ∧a2
:
Sat(Ψ) := Sat(a1) ∩Sat(a2);
¬a
:
Sat(Ψ) := S \ Sat(a);
∃ϕ
:
determine SatLTL(¬ϕ) by means of an LTL model-checker;
:
Sat(Ψ) := S \ SatLTL(¬ϕ)
end switch
AP := AP ∪{ aΨ };
(* introduce fresh atomic proposition *)
replace Ψ with aΨ
forall s ∈Sat(Ψ) do L(s) := L(s) ∪{ aΨ }; od
od
od
return I ⊆Sat(Φ)
The labeling function L′ : S →2AP′ is given by:
ai ∈L′(s)
if and only if
s ∈Sat(Φi)
for i ∈{ 1, 2 }.
Applying the LTL model-checking algorithm to the formula ¬ϕ′ yields the set of states
satisfying (with respect to the LTL semantics) ¬ϕ′, i.e., SatLTL(¬ϕ′). The complement of
SatLTL(¬ϕ′) provides the set SatCTL∗(ϕ).
Evidently, the time complexity of the CTL∗model-checking algorithm is dominated by
the LTL model-checking phases. The additional eﬀort that is necessary for CTL∗model
checking is polynomial in the size of the transition system and the length of the formula.
Hence, a time complexity is obtained which is exponential in the length of the formula
and linear in the size of the transition system.
Theorem 6.88.
Time Complexity of CTL∗Model Checking
For transition system TS with N states and K transitions, and CTL∗formula Φ, the
CTL∗model-checking problem TS |= Φ can be determined in time O((N+K)·2|Φ|).
Note that CTL∗model checking can be solved by any LTL model-checking algorithm.
These considerations show that there is a polynomial reduction of the CTL∗model-

430
Computation Tree Logic
CTL
LTL
CTL∗
model checking
PTIME
PSPACE-complete
PSPACE-complete
without fairness
size(TS) · |Φ|
size(TS) · exp(|Φ|)
size(TS) · exp(|Φ|)
with fairness
size(TS) · |Φ| · |fair|
size(TS) · exp(|Φ|) · |fair|
size(TS) · exp(|Φ|) · |fair|
for ﬁxed speciﬁcations
size(TS)
size(TS)
size(TS)
(model complexity)
satisﬁability check
EXPTIME
PSPACE-complete
2EXPTIME
best known technique
exp(|Φ|)
exp(|Φ|)
exp(exp(|Φ|))
Figure 6.29: Complexity of the model-checking algorithms and satisﬁability checking.
checking problem to the LTL model-checking problem. As a result, the theoretical com-
plexity results for LTL also apply to CTL∗. Table 6.29 summarizes the complexity results
for model checking CTL, CTL∗, and LTL.
Theorem 6.89.
Theoretical Complexity of CTL∗Model Checking
The CTL∗model-checking problem is PSPACE-complete.
6.9
Summary
• Computation Tree Logic (CTL) is a logic for formalizing properties over computation
trees, i.e., the branching structure of the states.
• The expressivenesses of LTL and CTL are incomparable.
• Although fairness constraints cannot be encoded in CTL formulae, fairness assump-
tions can be incorporated in CTL by adapting the CTL semantics such that quan-
tiﬁcation is over fair paths, rather than over all paths.
• The CTL model-checking problem can be solved by a recursive descent procedure
over the parse tree of the state formula to be checked. The set of states satisfying
∃(Φ U Ψ) can be determined using a smallest ﬁxed-point procedure; for ∃□Φ this is
a largest ﬁxed-point procedure.

Bibliographic Notes
431
• The time complexity of the CTL model-checking algorithm is linear in the size of
the transition system and the length of the formula. In case fairness constraints are
considered, an additional multiplicative factor that is proportional to the number of
fairness constraints needs to be taken into account.
• Counterexamples and witnesses for CTL path formulae can be determined using a
standard graph analysis.
• The CTL model-checking procedure can be realized symbolically by means of ordered
binary decision diagrams. These provide a universal and canonical data structure
for switching functions.
• Extended Computation Tree Logic (CTL∗) is more expressive than either CTL and
LTL.
• The CTL∗model-checking problem can be solved by an appropriate combination of
the recursive descent procedure (as for CTL) and the LTL model-checking algorithm.
• The CTL∗model-checking problem is PSPACE-complete.
6.10
Bibliographic Notes
Branching temporal logics.
Various types of branching temporal logic have been pro-
posed in the literature. We mention a few important ones in increasing expressive power:
Hennessy-Milner logic (HML [197]), Uniﬁed System of Branching-Time Logic [42], Compu-
tation Tree Logic (CTL [86]), Extended Computation Tree Logic (CTL∗[86]), and modal
μ-Calculus [243]. The modal μ-calculus is the most expressive among these languages,
and HML is the least expressive. CTL has been extended with fairness by Emerson and
Halpern [140] and by Emerson and Lei [143].
Not treated in this textbook is the task of proving satisﬁability of formulae by means
of algorithms or deductive techniques. The satisﬁability problems for CTL, CTL∗, and
other temporal logics have been addressed by many researchers and used, e.g., in the
context of synthesis problems where the goal is to design a system model from a given
temporal speciﬁcation. Emerson [138] has shown that checking CTL satisﬁability is in
the complexity class EXPTIME. This means that the time complexity of checking CTL
satisﬁability is exponential in the length of the formula. For CTL∗this problem is double
exponential [141] in the length of the formula. A complete axiomatization of CTL has
been given by Ben-Ari, Manna and Pnueli [42] and Emerson and Halpern [139].
Branching vs. linear temporal logics. The discussion of the relative merits of linear- vs.
branching-time logics goes back to the early eighties. Pnueli [338] established that linear

432
Computation Tree Logic
and branching temporal logics are based on two distinct notions of time.
Various pa-
pers [85, 140, 259] show that the expressivenesses of LTL and CTL are incomparable. A
somewhat more practical view on comparing the usefulness of LTL vs. CTL was recently
given by Vardi [410]. The logic CTL∗that encompasses LTL and CTL was deﬁned by
Clarke and Emerson [86].
CTL model checking. The ﬁrst algorithms for CTL model checking were presented by
Clarke and Emerson [86] in 1981 and (for a logic similar to CTL) by Queille and Sifakis [347]
in 1982. The algorithm by Clarke and Emerson was polynomial in both the size of the tran-
sition system and the length of the formula, and could handle fairness. Clarke, Emerson,
and Sistla [87] presented an eﬃciency improvement using the detection of strongly con-
nected components and backward breadth-ﬁrst search, yielding an algorithm that is linear
in both the size of the system and the length of the formula. CTL model checking based
on a forward search has been proposed by Iwashita, Nakata, and Hirose [224]. Emerson
and Lei [143] showed that CTL∗can be checked with essentially the same complexity as
LTL, using a combination of the algorithms for LTL and CTL. The same authors consider
in [142] CTL model checking under a broad class of fairness assumptions. Practical aspects
of CTL∗model checking have been reported by Bhat, Cleaveland, and Grumberg [50], and
more recently by Visser and Barringer [414]. Algorithms for generating counterexamples
and witnesses originate from the works by Clarke et al. [91] and Hojati, Brayton, and
Kurshan [204]. More recent developments are the use of satisﬁability solvers for proposi-
tional logic or quantiﬁed Boolean formulae to ﬁnd counterexamples up to certain length,
as proposed by Clarke et al. [84], and the use of tree-like counterexamples as opposed to
linear ones by Clarke [93].
CTL model checkers. Clarke and Emerson [86] reported the ﬁrst (fair) CTL model checker,
called EMC. About the same time, Queille and Sifakis [347] announced CESAR, a model
checker for a branching logic very similar to CTL. EMC was improved in [87] and con-
stituted the basis for SMV (Symbolic Model Veriﬁer), an eﬃcient CTL model checker by
McMillan based on a symbolic OBDD-based representation of the state space [288]. The
concept of ordered binary decision diagrams has been proposed by Bryant [70]. The mile-
stone for symbolic model checking with OBDDs is the paper by Burch et al.[74]. Further
references for OBDD-based approaches have been given in Section 6.7. Recent variants
of SMV are NuSMV [83] developed by the teams of Cimatti et al., and SMV by McMil-
lan and colleagues at Cadence Berkeley Laboratories that is focused on compositionality.
Both tools are freely available. Another symbolic CTL model checker is VIS [62].

Exercises
433
6.11
Exercises
Exercise 6.1.
Consider the following transition system over AP = { b, g, r, y }:
4
{ r }
{ y }
{ g }
{ b }
1
2
3
The following atomic propositions are used: r (red), y (yellow), g (green), and b (black). The
model is intended to describe a traﬃc light that is able to blink yellow. You are requested to
indicate for each of the following CTL formulae the set of states for which these formulae hold:
(a)
∀♦y
(g)
∃□¬ g
(b)
∀□y
(h)
∀(b U ¬ b)
(c)
∀□∀♦y
(i)
∃(b U ¬ b)
(d)
∀♦g
(j)
∀( ¬ b U ∃♦b)
(e)
∃♦g
(k)
∀(g U ∀(y U r))
(f)
∃□g
(l)
∀( ¬ b U b)
Exercise 6.2.
Consider the following CTL formulae and the transition system TS outlined on
the right:
Φ1
= ∀(a U b) ∨∃⃝(∀□b)
Φ2
= ∀□∀(a U b)
Φ3
= (a ∧b) →∃□∃⃝∀(b W a)
Φ4
= (∀□∃♦Φ3)
s0
∅
s4
{ b }
s1
{ a }
s2
{ a, b }
s3
{ b }
Determine the satisfaction sets Sat(Φi) and decide whether TS |= Φi (1 ⩽i ⩽4).
Exercise 6.3. Which of the following assertions are correct? Provide a proof or a counterexample.
(a) If s |= ∃□a, then s |= ∀□a.
(b) If s |= ∀□a, then s |= ∃□a.
(c) If s |= ∀♦a ∨∀♦b, then s |= ∀♦(a ∨b).
(d) If s |= ∀♦(a ∨b), then s |= ∀♦a ∨∀♦b.

434
Computation Tree Logic
(e) If s |= ∀(a U b), then s |= ¬ (∃(¬b U (¬a ∧¬b)) ∨∃□¬b).
Exercise 6.4.
Let Φ and Ψ be arbitrary CTL formulae. Which of the following equivalences for
CTL formulae are correct?
(a) ∀⃝∀♦Φ ≡∀♦∀⃝Φ
(b) ∃⃝∃♦Φ ≡∃♦∃⃝Φ
(c) ∀⃝∀□Φ ≡∀□∀⃝Φ
(d) ∃⃝∃□Φ ≡∃□∃⃝Φ
(e) ∃♦∃□Φ ≡∃□∃♦Φ
(f) ∀□(Φ ⇒(¬Ψ ∧∃⃝Φ)) ≡(Φ ⇒¬∀♦Ψ)
(g) ∀□(Φ ⇒Ψ) ≡(∃⃝Φ ⇒∃⃝Ψ)
(h) ¬∀(Φ U Ψ) ≡∃(Φ U ¬Ψ)
(i) ∃((Φ ∧Ψ) U (¬Φ ∧Ψ)) ≡∃(Φ U (¬Φ ∧Ψ))
(j) ∀(Φ W Ψ) ≡¬∃(¬Φ W ¬Ψ)
(k) ∃(Φ U Ψ) ≡∃(Φ U Ψ) ∧∃♦Ψ
(l) ∃(Ψ W ¬Ψ) ∨∀(Ψ U false) ≡∃⃝Φ ∨∀⃝¬Φ
(m) ∀□Φ ∧(¬Φ ∨∃⃝∃♦¬Φ) ≡∃X¬Φ ∧∀⃝Φ
(n) ∀□∀♦Φ ≡Φ ∧(∀⃝∀□∀♦Φ) ∨∀⃝(∀♦Φ ∧∀□∀♦Φ)
(o) ∀□Φ ≡Φ ∨∀⃝∀□Φ
Exercise 6.5.
Consider an elevator system that services N > 0 ﬂoors numbered 0 through N−1.
There is an elevator door at each ﬂoor with a call button and an indicator light that signals whether
or not the elevator has been called. In the elevator cabin there are N send buttons (one per ﬂoor)
and N indicator lights that inform to which ﬂoor(s) is going to be sent. For simplicity consider
N = 4. Present a set of atomic propositions—try to minimize the number of propositions—that
are needed to describe the following properties of the elevator system as CTL formulae and give
the corresponding CTL formulae:
(a) The doors are “safe”, i.e., a ﬂoor door is never open if the cabin is not present at the given
ﬂoor.
(b) The indicator lights correctly reﬂect the current requests. That is, each time a button is
pressed, there is a corresponding request that needs to be memorized until fulﬁllment (if
ever).
(c) The elevator only services the requested ﬂoors and does not move when there is no request.

Exercises
435
(d) All requests are eventually satisﬁed.
Exercise 6.6.
Consider the single pulser circuit, a hardware circuit that is part of a set of
benchmark circuits for hardware veriﬁcation. The single pulser has the following informal speci-
ﬁcation: “For every pulse at the input inp there appears exactly one pulse of length 1 at output
outp, independent of the length of the input pulse”. Thus, the single pulser circuit is required to
generate an output pulse between two rising edges of the input signal. The following questions
require the formulation of the circuit in terms of CTL. Suppose we have the proposition rise edge
at our disposal which is true if the input was low (0) at time instant n−1 and high (1) at time
instant n (for natural n > 0). It is assumed that input sequences of the circuit are well behaved,
i.e., more that the rising edge appears in the input sequence.
Questions: specify the following requirements of the circuit in CTL:
(a) A rising edge at the inputs leads to an output pulse.
(b) There is at most one output pulse for each rising edge.
(c) There is at most one rising edge for each output pulse.
(This exercise is taken from [246].)
Exercise 6.7.
Transform the following CTL formulae into ENF and PNF. Show all intermediate
steps.
Φ1
=
∀

(¬a) W (b →∀⃝c)

Φ2
=
∀⃝

∃((¬a) U (b ∧¬c))
∨
∃□∀⃝a

Exercise 6.8.
Provide two ﬁnite transition systems TS1 and TS2 (without terminal states,
and over the same set of atomic propositions) and a CTL formula Φ such that Traces(TS1) =
Traces(TS2) and TS1 |= Φ, but TS2 ̸|= Φ.
Exercise 6.9.
Consider the CTL formula
Φ = ∀□

a →∀♦(b ∧¬a)

and the following CTL fairness assumption:
fair = ∀♦∀⃝(a ∧¬b) →∀♦∀⃝(b ∧¬a) ∧♦□∃♦b →□♦b.
Prove that TS |=fair Φ where transition system TS is depicted below.

436
Computation Tree Logic
s0
∅
s1
{a}
s3
{ a }
s4
{ a, b }
s2
{ b }
Exercise 6.10.
Let ℘= (z1, z2, z3, z4, z5, z6). Depict the ℘-ROBDD for the majority function
MAJ([z1 = b1, z2 = b2, . . . , z6 = b6]) =
	
1
if b1 + b2 + . . . + b6 ⩾4
0
otherwise.
Exercise 6.11.
Consider the function
F(x0, . . . , xn−1, a0, . . . , ak−1) = xm
where n = 2k, and m = k−1
j=0 aj2j. Let k=3. Questions:
(a) Depict the ℘-ROBDD for ℘= (a0, . . . , ak−1, x0, . . . , xn−1).
(b) Depict the ℘-ROBDD for ℘= (a0, x0, . . . , ak−1, xk−1, xk, . . . , xn−1).
Exercise 6.12.
Let B and C be two ℘-ROBDDs. Design an algorithm that checks whether
fB = fC and runs in time linear in the sizes of B and C.
(Hint: It is assumed that B and C are given as separate graphs (and not by nodes of a shared
OBDD).)
Exercise 6.13.
Let TS be a ﬁnite transition system (over AP) without terminal states, and Φ
and Ψ be CTL state formulae (over AP). Prove or disprove
TS |= ∃(Φ U Ψ)
if and only if
TS′ |= ∃♦Ψ
where TS′ is obtained from TS by eliminating all outgoing transitions from states s such that
s |= Ψ ∨¬Φ.
Exercise 6.14.
Check for each of the following formula pairs (Φi, ϕi) whether the CTL formula
Φi is equivalent to the LTL formula ϕi. Prove the equivalence or provide a counterexample that
illustrates why Φi ̸≡ϕi.

Exercises
437
(a) Φ1 = ∀□∀⃝a. and ϕ1 = □⃝a
(b) Φ2 = ∀♦∀⃝a and ϕ2 = ♦⃝a.
(c) Φ3 = ∀♦(a ∧∃⃝a) and ϕ3 = ♦(a ∧⃝a).
(d) Φ4 = ∀♦a
∨
∀♦b and ϕ4 = ♦(a ∨b).
(e) Φ5 = ∀□(a →∀♦b) and ϕ5 = □(a →♦b).
(f) Φ6 = ∀(b U (a ∧∀□b)) and ϕ6 = ♦a ∧□b.
Exercise 6.15.
(a) Prove, using Theorem 6.18, that there does not exist an equivalent LTL formula for the CTL
formula Φ1 = ∀♦(a ∧∃⃝a).
(b) Now prove directly (i.e. without Theorem 6.18), that there does not exist an equivalent LTL
formula for the CTL formula Φ2 = ∀♦∃⃝∀♦¬a. (Hint: Argument by contraposition.)
Exercise 6.16.
Consider the following CTL formulae
Φ1 = ∃♦∀□c
and
Φ2 = ∀(a U ∀♦c)
and the transition system TS outlined on the right.
Decide
whether TS |= Φi for i = 1, 2 using the CTL model-checking
algorithm. Sketch its main steps.
s0 { a }
s1 { a, b }
s3
{ b, c }
s4
{ c }
s2
{ c }
Exercise 6.17.
Provide an algorithm in pseudo code to compute Sat(∀(Φ U Ψ)) in a direct
manner, i.e., without transforming the formula into ENF.
Exercise 6.18.
(a) Prove that Sat(∃(Φ W Ψ)) is the largest set T such that
T ⊆Sat(Ψ) ∪

s ∈Sat(Φ) | Post(s) ∩T ̸= ∅

.
(b) Prove that Sat(∀(Φ W Ψ)) is the largest set T such that
T ⊆Sat(Ψ) ∪

s ∈Sat(Φ) | Post(s) ⊆T

.

438
Computation Tree Logic
Use the above characterizations to provide eﬃcient algorithms for computing the sets Sat(∃(Φ W Ψ))
and Sat(∀(Φ W Ψ)) in a direct manner.
Exercise 6.19.
Consider the fragment ECTL of CTL which consists of formulae built according
to the following grammar:
Φ
::= a | ¬a | Φ ∧Φ | ∃ϕ
ϕ
::= ⃝Φ | □Φ | Φ U Φ
For two transition systems TS1 = (S1, Act, →1, I1, AP, L1) and TS2 = (S2, Act, →2, I2, AP, L2),
let TS1 ⊆TS2 iﬀS1 ⊆S2, →1 ⊆→2, I1 = I2 and L1(s) = L2(s) for all s ∈S1.
(a) Prove that for all ECTL formulae Φ and all transition systems TS1, TS2 with TS1 ⊆TS2,
it holds:
TS1 |= Φ
=⇒
TS2 |= Φ.
(b) Give a CTL formula which is not equivalent to any other ECTL formula.
Justify your
answer.
Exercise 6.20.
In CTL, the release operator is deﬁned by
∃(Φ R Ψ) = ¬∀((¬Φ) U (¬Ψ))
and
∀(Φ R Ψ) = ¬∃((¬Φ) U (¬Ψ)).
(a) Provide expansion laws for ∃(Φ R Ψ) and ∀(Φ R Ψ).
(b) Give a pseudo code algorithm for computing Sat(∃(Φ R Ψ)) and do the same for computing
Sat(∀(Φ R Ψ)).
Exercise 6.21.
Consider the CTL formula Φ and the strong fairness assumption sfair:
Φ
= ∀□∀♦a
sfair
= □♦(b ∧¬a)



Φ1
→□♦∃(b U (a ∧¬b))



Ψ1
and transition system TS over AP = { a, b } which is given by

Exercises
439
s2 { b }
s0
{ a, b }
s3
{ b }
s1
∅
s5 { a }
s4
∅
Questions:
(a) Determine Sat(Φ1) and Sat(Ψ1) (without fairness).
(b) Determine Satsfair(∃□true).
(c) Determine Satsfair(Φ).
Exercise 6.22.
Let TS = (S, Act, →, I, AP, L) be a transition system without terminal states,
a, b ∈AP and s ∈S. Furthermore, let fair be a CTL fairness assumption and afair ∈AP an
atomic proposition with afair ∈L(s) iﬀs |=fair ∃□true.
Which of the following assertions are correct? Give a proof or counterexample.
(a) s |=fair ∀(a U b)
iﬀ
s |= ∀(a U (b ∧afair)).
(b) s |=fair ∃(a W b)
iﬀ
s |= ∃(a W (b ∧afair)).
(c) s |=fair ∀(a W b)
iﬀ
s |= ∀(a W (afair →b)).
Exercise 6.23.
Consider the following transition system TS over AP = { a1, . . . , a6 }.
s1
∅
s3
s2
s4
s5
s7
s6
s8
{ a1, a3 }
{ a4, a2 }
{ a1, a5 }
{ a1 }
{ a1, a2 }
{ a3, a2, a5 }
{ a2, a4 }

440
Computation Tree Logic
Let Φ = ∃⃝

a1 →∃(a1 U a2)

and sfair
= sfair 1 ∧sfair 2 ∧sfair 3 a strong CTL fairness
assumption where
sfair 1
=
□♦∀♦(a1 ∨a3) −→□♦a4
sfair 2
=
□♦(a3 ∧¬a4) −→□♦a5
sfair 3
=
□♦(a2 ∧a5) −→□♦a6
Sketch the main steps for computing the satisfaction sets Satsfair(∃□true) and Satsfair(Φ).
Exercise 6.24.
Consider the CTL∗formula over AP = { a, b }:
Φ = ∀♦□∃⃝

a U ∃□b

and the transition system TS outlined below:
s6
{ a, b }
s3
{ a }
s7
{ a, b }
s4 { b }
s1 ∅
s2
{ a, b }
s5
∅
s0
{ b }
Apply the CTL∗model-checking algorithm to compute Sat(Φ) and decide whether TS |= Φ. (Hint:
You may infer the satisfaction sets for LTL formulae directly.)
Exercise 6.25.
The model-checking algorithm presented in Section 6.5 treats CTL with strong
fairness assumptions. Explain which modiﬁcations are necessary to deal with weak CTL fairness
assumptions:
wfair =

1⩽i⩽k

♦□ai −→□♦bi

.
You may assume that ai, bi ∈{ true } ∪AP.
Exercise 6.26.
Which of the following equivalences for CTL∗are correct? Provide a proof or a
counterexample.

Exercises
441
(a) ∀⃝∀□Φ
≡
∀⃝□Φ
(b) ∃⃝∃□Φ
≡
∃⃝□Φ
(c) ∀(ϕ ∧ψ)
≡
∀ϕ ∧∀ψ
(d) ∃(ϕ ∧ψ)
≡
∃ϕ ∧∃ψ
(e) ¬∀(ϕ →ψ)
≡
∃(ϕ ∧¬ψ)
(f) ∃□∃⃝Φ ∧¬∀⃝¬Φ
≡∃□(¬ ⃝¬Φ)
(g) ∀(♦Ψ ∧□Φ) ≡∀♦(Ψ ∧∀□Φ) ∧∀□(Φ ∧∀♦Ψ)
(h) ∃(♦Ψ ∧□Φ) ≡∃♦(Ψ ∧∃□Φ)
Here, Φ, Ψ are arbitrary CTL∗state formulae and ψ, ϕ are CTL∗path formulae.
Exercise 6.27.
Consider the transition system TS and the CTL∗formula
Φ = ∃

⃝(a ∧¬b) ∧⃝∀(b U □a)

.
Apply
the
CTL∗
model-checking
algorithm to
check
whether TS |= Φ and sketch its main steps as well as its
output. (Hint: You may compute the LTL satisfaction sets
directly.)
s0
{ b }
s1
{ a, b }
s2
{ a }
s3
{ a }
s4
{ a, b }
Exercise 6.28.
Consider the transition system TS depicted below and the CTL∗formula
Φ = ∃(□♦b ∧□∃♦⃝a) ∧∀□♦⃝c.
s1
{b, c}
s2
s3
s5
s4
∅
∅
{ a }
{ c }
Sketch the main steps that the CTL∗model checking algorithm performs for checking whether
TS |= Φ.

442
Computation Tree Logic
Exercise 6.29.
Provide an example of a CTL∗formula which is not a CTL+ formula, but there
exists an equivalent CTL formula.
Exercise 6.30. Provide equivalent CTL formulae for the CTL+ formulae ∀(♦a∧□b) and ∀(⃝a∧
¬(a U (□b))).
Practical Exercises
The remaining exercises are modeling and veriifcation exercises using the CTL model checker
NuSMV [83].
Exercise 6.31.
The following program is a mutual exclusion protocol for two processes due to
Pnueli (taken from [118]). There is a single shared variable s which is either 0 or 1, and initially
equals 1. Besides, each process has a local Boolean variable y that initially equals 0. The program
text for process Pi (i = 0, 1) is as follows:
l0: loop forever do
begin
l1: Noncritical section
l2: (yi, s) := (1, i);
l3: wait until ((y1−i = 0) ∨(s ̸= i));
l4: Critical section
l5: yi := 0
end.
Here, the statement (yi, s) := (1, i) is a multiple assignment in which variable yi := 1 and s := i is
a single, atomic step.
The intuition behind this protocol is as follows. The variables y0 and y1 are used by each process to
signal the other process of active interest in entering the critical section. On leaving the noncritical
section, process Pi sets its own local variable yi to 1. In a similar way this variable is reset to 0
once the critical section is left. The global variable s is used to resolve a tie situation between the
processes. It serves as a logbook in which each process that sets its y variable to 1 signs at the
same time. The test at line l3 says that P0 may enter its critical section if either y1 equals 0 –
implying that its competitor is not interested in entering its critical section – or if s diﬀers from
0 – implying that the competitor process P1 performed its assignment to y1 after p0 assigned 1 to
y0.
Questions concerning this mutual exclusion protocol:
(a) Model this protocol in NuSMV; formulate the property of mutual exclusion in CTL and
check this property.

Exercises
443
(b) Check whether Pnueli’s protocol ensures absence of unbounded overtaking, i.e., when a
process wants to enter its critical section, it eventually will be able to do so. Provide a
counterexample (and an explanation thereof) in case this property is violated.
(c) Add the fairness constraint FAIRNESS running to the process speciﬁcation in your NuSMV
model of the mutual exclusion program, and check again the property of absence of un-
bounded overtaking. Compare the obtained results with the results obtained in the previous
question without using the fairness constraint.
(d) Express in CTL that each process will occupy its critical section inﬁnitely often. Check the
property (use again the FAIRNESS running).
(e) A practical problem with this mutual exclusion protocol is that it is too demanding in the
sense that it enforces performing the assignments to yi and s (in line l2) in a single step.
Most existing hardware systems cannot perform such assignments in one step. Therefore,
it is requested to investigate whether any of the four possible realizations of this protocol
– in which the aforementioned assignments are not atomic anymore – is a correct mutual
exclusion protocol.
(I) Report for each possible implementation your results, including possible counterexam-
ples and their explanation.
(II) Compare your results with the results of your Promela experiments with this exercise
in the previous exercise series.
Exercise 6.32.
In this exercise you are confronted with a nonstandard example for model
checking. The purpose of this exercise is to present the model checker as a solver for combinatorial
problems rather than a tool for correctness analysis. These problems involve a search (involving
backtracking) of optimal or cost-minimizing strategies such as schedulers or puzzle solutions. The
exercise is concerned with Loyd’s puzzle that consists of an N · K grid in which there are N · K−1
numbered tiles and a single blank space. The goal of the puzzle is to achieve a predetermined order
on the tiles. The initial and ﬁnal conﬁguration of the tiles for N = 3 and K = 3 is as follows:
initial configuration
final configuration
1
2
5
3
4
7
8
6
8
7
6
2
1
5
4
3
Note that there are approximately 4 · (N · K)! possible moves in this puzzle. For N = 3 and K = 3
this already amounts to about 1.45 106 possible conﬁgurations.
Questions concerning Loyd’s puzzle:

444
Computation Tree Logic
(a) Complete the (partial) model of Loyd’s puzzle in NuSMV that is given below. In this model,
there is an array h that keeps track of the horizontal positions of the tiles and an array v
that records the vertical positions of the tiles such that the position of tile i is given by the
pair h[i], v[i]. Tile 0 represents the blank tile. Position h[i] = 1 and v[i] = 1 is the
lowest left corner of the puzzle.
MODULE main
DEFINE N := 3; K := 3;
VAR move: {u, d, l, r};
-- the possible tile-moves
h: array 0..8 of 1..3;
-- the horizontal positions of all tiles
v: array 0..8 of 1..3;
-- .... and their vertical positions
ASSIGN -- the initial horizontal and vertical positions of all tiles
init(h[0]) := 1;
init(v[0]) := 3;
init(h[1]) := 2;
init(v[1]) := 3;
init(h[2]) := 3;
init(v[2]) := 3;
init(h[3]) := 1;
init(v[3]) := 2;
init(h[4]) := 2;
init(v[4]) := 2;
init(h[5]) := 3;
init(v[5]) := 2;
init(h[6]) := 1;
init(v[6]) := 1;
init(h[7]) := 2;
init(v[7]) := 1;
init(h[8]) := 3;
init(v[8]) := 1;
ASSIGN
-- determine the next positions of the blank tile
next(h[0]) :=
-- horizontal position of the blank tile
case
-- one position right
-- one position left
1 : h[0];
-- keep the same horizontal position
esac;
next(v[0]) :=
-- vertical position of the blank tile
case
-- one position down
-- one position up
1 : v[0];
-- keep the same vertical position
esac;
-- determine the next positions of all non-blank tiles
next(h[1]) :=
-- horizontal position of tile 1
case
esac;

Exercises
445
next(v[1]) :=
-- vertical position of tile 1
case
esac;
-- and similar for all remaining tiles
A possible way to proceed is as follows:
(i) First, consider the possible moves of the blank tile (i.e., the blank space). Notice that
the blank space cannot be moved to the left in all positions. The same applies to moves
upward, downward and to the right.
(ii) Then try to ﬁnd the possible moves of tile [1]. The code for tiles [2] through [8] are
obtained by simply copying the code for tile [1] while replacing all references to [1]
with references of the appropriate tile number.
(iii) Test the possible moves by running a simulation.
(b) Deﬁne an atomic proposition goal that describes the desired goal conﬁguration of the puzzle.
Add this deﬁnition to your NuSMV speciﬁcation by incorporating the following line(s) in
your NuSMV model:
DEFINE goal :=
.............. ;
where the dotted lines contain your description of the goal conﬁguration.
(c) Find a solution to the puzzle by imposing the appropriate CTL formula to the NuSMV
speciﬁcation, and running the model checker on this formula.
This exercise has been taken from [95].
Exercise 6.33.
Consider the mutual exclusion algorithm by the Dutch mathematician Dekker.
There are two processes P1 and P2, two Boolean-valued variables b1 and b2 whose initial values
are false, and a variable k which may take the values 1 and 2 and whose initial value is arbitrary.
The ith process (i=1, 2) may be described as follows, where j is the index of the other process:
while true do
begin bi := true;
while bj do
if k = j then begin
bi := false;
while k = j do skip;
bi := true
end;
⟨critical section ⟩;
k := j;
bi := false
end

446
Computation Tree Logic
Questions:
(a) Model Dekker’s algorithm in NuSMV.
(b) Verify whether this algorithm satisﬁes the following properties:
(c) Mutual exclusion: two processes cannot be in their critical section at the same time.
(d) Absence of individual starvation: if a process wants to enter its critical section, it is eventually
able to do so.
(Hint: use the FAIRNESS running statement in your NuSMV speciﬁcation for proving the latter
property in order to prohibit unfair executions that might trivially violate these requirements.)
Exercise 6.34.
In the original mutual exclusion protocol by Dijkstra in 1965 (another Dutch
mathematician), it is assumed that there are n ⩾2 processes, and global variables b, c : array [1 . . . n]
of Boolean and an integer k. Initially all elements of b and of c have the value true and the value
of k belongs to 1, 2, . . . , n. The ith process may be represented as follows:
var j : integer;
while true do
begin b[i] := false;
Li : if k ̸= i then begin c[i] := true;
if b[k] then k := i;
goto Li
end;
else begin c[i] := false;
for j := 1 to n do
if (j ̸= i ∧¬ (c[j])) then goto Li
end
⟨critical section ⟩;
c[i] := true;
b[i] := true
end
Questions:
(a) Model this algorithm in NuSMV.
(b) Check the mutual exclusion property (at most one process can be in its critical section at
any point in time) in two diﬀerent ways: by means of a CTL formula using SPEC and by
using invariants. Try to check this property for n=2 through n=5 by increasing the number
of processes gradually and compare the sizes of the state spaces and the runtime needed for
the two ways of verifying the mutual exclusion property.
(c) Check the absence of individual starvation property: if a process wants to enter its critical
section, it is eventually able to do so.

Exercises
447
Exercise 6.35.
In order to ﬁnd a fair solution for N processes, Peterson proposed in 1981 the
following protocol. Let Q[1 . . . N] (Q for queue) and T [1 . . .N] (T for turn), be two shared arrays
which are initially 0 and 1, respectively. The variables i and j are local to the process with i
containing the process number. The code of process i is as follows:
while true do
for j := 1 to N −1 do
begin
Q[i] := j;
T [j] := i;
wait until (T [j] ̸= i ∨(forall k ̸= i. Q[k] < j))
end;
⟨critical section ⟩;
Q[i] := 0
end
Questions:
(a) Model Peterson’s algorithm in NuSMV.
(b) Verify whether this algorithm satisﬁes the following properties:
(i) Mutual exclusion.
(ii) Absence of individual starvation.


Chapter 7
Equivalences and Abstraction
Transition systems can model a piece of software or hardware at various abstraction levels.
The lower the abstraction level, the more implementation details are present. At high
abstraction levels, such details are deliberately left unspeciﬁed. Binary relations between
states (henceforth implementation relations) are useful to relate or to compare transition
systems, possibly at diﬀerent abstraction levels. When two models are related, one model
is said to be reﬁned by the other, or, reversely, the second is said to be an abstraction of
the ﬁrst. If the implementation relation is an equivalence, then it identiﬁes all transition
systems that cannot be distinguished; such models fulﬁll the same observable properties
at the relevant abstraction level.
Implementation relations are predominantly used for comparing two models of the same
system. Given a transition system TS that acts as an abstract system speciﬁcation, and
a more detailed system model TS′, implementation relations allow checking whether TS′
is a correct implementation (or: reﬁnement) of TS. Alternatively, for system analysis
purposes, implementation relations provide ample means to abstract from certain system
details, preferably details that are irrelevant for the analysis of the property, ϕ say, at
hand. In this way, a transition system TS′ comprising very many, maybe even inﬁnitely
many, states can be abstracted by a smaller model TS. Provided the abstraction preserves
the property to be checked, the analysis of the (hopefully small) abstract model TS suﬃces
to decide the satisfaction of the properties in TS′. Formally, from TS |= ϕ we may safely
conclude TS′ |= ϕ.
This chapter will introduce several implementation relations, ranging from very strict ones
(“strong” relations) that require transition systems to mutually mimic each transition, to
more liberal ones (“weak” relations) in which this is only required for certain transitions.
449

450
Equivalences and Abstraction
In fact, in this monograph we have already encountered implementation relations that
were aimed at comparing transition systems by considering their linear-time behavior,
i.e., (ﬁnite or inﬁnite) traces. Examples of such relations are trace inclusion and trace
equivalence.
Linear-time properties or LTL formulae are preserved by trace relations
based on inﬁnite traces; for trace-equivalent TS and TS′ and linear-time property P, we
have TS′ |= P whenever TS |= P. A similar result is obtained when replacing P by an
LTL formula.
Besides the introduction of a weak variant of trace equivalence, the goal of this chapter is
primarily to study relations that respect the branching-time behavior. Classical represen-
tatives of such relations are bisimulation equivalences and simulation preorder relations.
Whereas bisimulation relates states that mutually mimic all individual transitions, simu-
lation requires that one state can mimic all stepwise behavior of the other, but not the
reverse. Weak variants of these relations only require this for certain (“observable”) transi-
tions, and not for other (“silent”) transitions. This chapter will formally deﬁne strong and
weak variants of (bi)simulation, and will treat their relationship to trace-based relations.
The preservation of CTL and CTL∗formulae is shown; for bisimulation the truth value
of all such formulae is preserved, while for simulation this applies to a (large) fragment
thereof. These results provide us with the tools to simplify establishing TS′ |= ϕ, for CTL
(or CTL∗) formula ϕ by checking whether TS |= ϕ.
This provides the theoretical underpinning of exploiting bisimulation and simulation re-
lations for the purpose of abstraction. The remaining issue is how to obtain the more
abstract TS from the (larger, and more concrete) transition system TS′. This chapter will
treat polynomial-time algorithms for several notions of (bi)simulation. These algorithms
allow checking whether two given transition systems are (bi)similar, and can be used to
generate an abstract transition system from a more concrete one in an automated manner.
As in the previous chapters, we will follow the state-based approach. This means that
we consider branching-time relations that refer to the state labels, i.e., the atomic propo-
sitions that hold in the states. Action labels of the transitions are not considered. All
concepts (deﬁnitions, theorems, algorithms) treated in this chapter can, however, easily
be reformulated for the approach that is focused on action labels rather than state labels.
This connection is discussed in Section 7.1.2.
Throughout this chapter, the transition systems under consideration may have terminal
states, and hence, may exhibit both ﬁnite and inﬁnite paths and traces. When considering
temporal logics, though, transition systems without terminal states (thus only having
inﬁnite behaviors) are assumed.

Bisimulation
451
7.1
Bisimulation
Bisimulation equivalence aims to identify transition systems with the same branching
structure, and which thus can simulate each other in a stepwise manner. Roughly speak-
ing, a transition system TS′ can simulate transition system TS if every step of TS can
be matched by one (or more) steps in TS′. Bisimulation equivalence denotes the pos-
sibility of mutual, stepwise simulation. We ﬁrst introduce bisimulation equivalence as a
binary relation between transition systems (over the same set of atomic propositions);
later on, bisimulation is also treated as a relation between states of a single transition
system. Bisimulation is deﬁned coinductively, i.e., as the largest relation satisfying certain
properties.
Deﬁnition 7.1.
Bisimulation Equivalence
Let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, 2, be transition systems over AP. A bisimulation
for (TS1, TS2) is a binary relation R ⊆S1 × S2 such that
(A) ∀s1 ∈I1 (∃s2 ∈I2. (s1, s2) ∈R) and ∀s2 ∈I2 (∃s1 ∈I1. (s1, s2) ∈R)
(B) for all (s1, s2) ∈R it holds:
(1) L1(s1) = L2(s2)
(2) if s′
1 ∈Post(s1) then there exists s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R
(3) if s′
2 ∈Post(s2) then there exsist s′
1 ∈Post(s1) with (s′
1, s′
2) ∈R.
TS1 and TS2 are bisimulation-equivalent (bisimilar, for short), denoted TS1 ∼TS2, if
there exists a bisimulation R for (TS1, TS2).
Condition (A) asserts that every initial state of TS1 is related to an initial state of TS2,
and vice versa. According to condition (B.1), the states s1 and s2 are equally labeled.
This can be considered as ensuring the “local” equivalence of s1 and s2. Condition (B.2)
states that every outgoing transition of s1 must be matched by an outgoing transition of
s2; the reverse is stated by (B.3). Figure 7.1 summarises the latter two conditions.
Example 7.2.
Two Beverage Vending Machines
Let AP = { pay, beer, soda }.
Consider the transition systems depicted in Figure 7.2.
These model a beverage vending machine, but diﬀer in the number of possibilities for
supplying beer. The fact that the right-hand transition system (TS2) has an additional
option to deliver beer is not observable by a user. This suggests an equivalence between

452
Equivalences and Abstraction
s1
R
s2
s1
R
s2
↓
can be complemented to
↓
↓
s′
1
s′
1
R
s′
2
s1
R
s2
s1
R
s2
↓
can be complemented to
↓
↓
s′
2
s′
1
R
s′
2
Figure 7.1: Conditions (B.2) and (B.3) of bisimulation equivalence.
s0
s1
s2
s3
t0
t1
t2
t4
t3
{ pay }
{ pay }
∅
∅
{ beer }
{ soda }
{ beer }
{ soda }
{ beer }
Figure 7.2: Two bisimilar beverage vending machines
the transition systems. Indeed, the equivalence of TS1 and TS2 follows from the fact that
the relation
R = {(s0, t0), (s1, t1), (s2, t2), (s2, t3), (s3, t4)}
is a bisimulation for (TS1, TS2). It can easily be veriﬁed that R indeed satisﬁes all re-
quirements of Deﬁnition 7.1.
Now consider an alternative model (TS3) of the vending machine where the user selects
the drink on inserting a coin, see Figure 7.3, depicting TS1 (left) and TS3 (right). AP
is as before. It follows that TS1 and TS3 are not bisimilar, since the state s1 in TS1
cannot be mimicked by a state in TS3. This can be seen as follows. Due to the labeling
condition (B.1), the only candidates for mimicking state s1 are the states u1 and u2 in
TS3. However, neither of these states can mimic all transitions of s1 in TS1: either the
possibility for soda or for beer is missing. Thus, TS1 ̸∼TS3 for AP = { pay, beer, soda }.

Bisimulation
453
s0
s1
s2
s3
u0
u1
u4
u3
{ pay }
{ pay }
∅
∅
{ beer }
{ soda }
{ beer }
{ soda }
∅
u2
Figure 7.3: Nonbisimulation-equivalent beverage vending machines.
As a ﬁnal example, reconsider TS1 and TS3 for AP = { pay, drink }. The labelings of the
transition systems are obvious: L(s0) = L(u0) = { pay }, L(s1) = L(u1) = L(u2) = ∅, and
all remaining states are labeled with { drink }. It can now be established that the relation
{ (s0, u0), (s1, u1), (s1, u2), (s2, u3), (s2, u4), (s3, u3), (s3, u4) }
is a bisimulation for (TS1, TS3). Henceforth, TS1 ∼TS3 for AP = { pay, drink }.
Remark 7.3.
The Relevant Set of Atomic Propositions
The ﬁxed set AP plays a crucial role in comparing transition systems using bisimulation.
Intuitively, AP stands for the set of all “relevant” atomic propositions. All other atomic
propositions are understood as negligible and are ignored in the comparison. In case TS is
a reﬁnement of TS′, e.g., TS is obtained from TS′ by incorporating some implementation
details, then the set AP of atomic propositions of TS generally is a proper superset of
the set AP′ of propositions of TS′. To compare TS and TS′, the set of common atomic
propositions, AP′, is a reasonable choice.
In this way, it is possible to check whether
the branching structure of TS agrees with that of TS′ when considering all observable
information in AP′. If we are only interested in checking the equivalence of TS and TS′
with respect to the satisfaction of a temporal logic formula Φ, it suﬃces to consider AP
as the atomic propositions that occur in Φ.
Lemma 7.4.
Reﬂexivity, Transitivity, and Symmetry of ∼
For a ﬁxed set AP of atomic propositions, the relation ∼is an equivalence relation.
Proof: Let AP be a set of atomic propositions.
We show reﬂexivity, symmetry, and
transitivity of ∼:

454
Equivalences and Abstraction
• Reﬂexivity: For transition system TS with state space S, the identity relation R =
{ (s, s) | s ∈S } is a bisimulation for (TS, TS).
• Symmetry: Sssume that R is a bisimulation for (TS1, TS2). Consider
R−1 = {(s2, s1) | (s1, s2) ∈R}
that is obtained by swapping the states in any pair in R. Clearly, relation R−1
satisﬁes conditions (A) and (B.1). By symmetry of (B.2) and (B.3), we immediately
conclude that R−1 is a bisimulation for (TS2, TS1).
• Transitivity: Let R1,2 and R2,3 be bisimulations for (TS1, TS2) and (TS2, TS3),
respectively. The relation R = R1,2 ◦R2,3, given by
R = {(s1, s3) | ∃s2 ∈S2. (s1, s2) ∈R1,2 ∧(s2, s3) ∈R2,3 },
is a bisimulation for (TS1, TS3) where S2 denotes the set of states in TS2. This can
be seen by checking all conditions for a bisimulation.
(A) Consider the initial state s1 of TS1. Since R1,2 is a bisimulation, there is an
initial state s2 of TS2 with (s1, s2) ∈R1,2. As R2,3 is a bisimulation, there is
an initial state s3 of TS3 with (s2, s3) ∈R2,3. Thus, (s1, s3) ∈R. In the same
way we can check that for any initial state s3 of TS3, there is an initial state
s1 of TS1 with (s1, s3) ∈R.
(B.1) By deﬁnition of R, there is a state s2 in TS2 with (s1, s2) ∈R1,2 and (s2, s3) ∈
R2,3. Then, L1(s1) = L2(s2) = L3(s3).
(B.2) Assume (s1, s3) ∈R. As (s1, s2) ∈R1,2, it follows that if s′
1 ∈Post(s1) then
(s′
1, s′
2) ∈R1,2 for some s′
2 ∈Post(s2). Since (s2, s3) ∈R2,3, we have (s′
2, s′
3) ∈
R2,3 for some s′
3 ∈Post(s3). Hence, (s′
1, s′
3) ∈R.
(B.3) Similar to the proof for (B.2).
Bisimulation is deﬁned in terms of the direct successors of states. By using an inductive
argument over states, we obtain a relation between (ﬁnite or inﬁnite) paths.
Lemma 7.5.
Bisimulation on Paths
Let TS1 and TS2 be transition systems over AP, R a bisimulation for (TS1, TS2), and
(s1, s2) ∈R. Then for each (ﬁnite or inﬁnite) path π1 = s0,1 s1,1 s2,1 . . . ∈Paths(s1) there
exists a path π2 = s0,2 s1,2 s2,2 . . . ∈Paths(s2) of the same length such that (sj,1, sj,2) ∈R
for all j.

Bisimulation
455
s1
−R−
s2
↓
s1,1
↓
s2,1
↓
...
can be
completed to
s1
−R−
s2
↓
↓
s1,1
−R−
s1,2
↓
↓
s2,1
−R−
s2,2
↓
↓
...
...
Figure 7.4: Construction of statewise bisimilar paths.
Proof: Let π1 = s0,1 s1,1 s2,1 . . . ∈Paths(s1) be a maximal path fragment in TS1 starting
in s1 = s0,1 and assume (s1, s2) ∈R. We successively deﬁne a “corresponding” maximal
path fragment in TS2 starting in s2 = s0,2, where the transitions si,1 →1 si+1,1 are matched
by transitions si,2 →2 si+1,2 such that (si+1,1, si+1,2) ∈R. This is done by induction on
i, see Figure 7.4 on page 455. For each case we distinguish between si being a terminal
state or not.
• Base case: i = 0. In case s1 is a terminal state, it follows directly from (s1, s2) ∈R
(by condition (B.3)) that s2 is a terminal state too. Thus s2 = s0,2 is a maximal path
fragment in TS2. If s1 is not a terminal state, it follows from (s0,1, s0,2) = (s1, s2) ∈R
that the transition s1 = s0,1 →1 s1,1 can be matched by a transition s2 →2 s1,2 such
that (s1,1, s1,2) ∈R. This yields the path fragment s2 s1,2 in TS2.
• Induction step: Assume i ⩾0 and that the path fragment s2 s1,2 s2,2 . . . si,2 is already
constructed with (sj,1, sj,2) ∈R for j = 1, . . . , i.
If π1 has length i, then π1 is maximal and si,1 is a terminal state. By condition
(B.3), si,2 is terminal too. Thus, π2 = s2 s1,2 s2,2 . . . si,2 is a maximal path fragment
in TS2 which is statewise related to π1 = s1 s1,1 s2,1 . . . si,1.
Now assume that si,1 is not terminal. We consider the step si,1 →1 si+1,1 in π1. Since
(si,1, si,2) ∈R, there exists a transition si,2 →2 si+1,2 with (si+1,1, si+1,2) ∈R. This
yields a path fragment s2 s1,2 . . . si,2 si+1,2 which is statewise related to the preﬁx
s1 s1,1 . . . si,1 si+1,1 of π1.
By symmetry, for each path π2 ∈Paths(s2) there exists a path π1 ∈Paths(s1) of the same
length which is statewise related to π2. As one can construct statewise bisimilar paths,
bisimilar transition systems are trace-equivalent.
It is mostly easier to prove that two
transition systems are bisimilar rather than prove their trace equivalence. The intuitive

456
Equivalences and Abstraction
reason for this discrepancy is that proving bisimulation equivalence just requires “local”
reasoning about state behavior instead of considering entire paths. The following result is
thus of importance in checking trace equivalence as well.
Theorem 7.6.
Bisimulation and Trace Equivalence
TS1 ∼TS2 implies Traces(TS1) = Traces(TS2).
Proof: Let R be a bisimulation for (TS1, TS2). By Lemma 7.5, any path π1 = s0,1 s1,1 s2,1 . . .
in TS1 can be lifted to a path π2 = s0,2 s1,2 s2,2 . . . in TS2 such that (si,1, si,2) ∈R
for all indices i.
According to condition (B.1), L1(si,1) = L2(si,2) for all i.
Thus,
trace(π1) = trace(π2). This shows Traces(TS1) ⊆Traces(TS2). By symmetry, one ob-
tains that TS1 and TS2 are trace equivalent.
As trace-equivalent transition systems fulﬁll the same linear-time properties, it thus now
follows that bisimilar transition systems fulﬁll the same linear-time properties.
7.1.1
Bisimulation Quotient
So far, bisimulation has been deﬁned as a relation between transition systems.
This
enables comparing diﬀerent transition systems. An alternative perspective is to consider
bisimulation as a relation between states within a single transition system. By considering
the quotient transition system under such a relation, smaller models are obtained. This
minimization recipe can be exploited for eﬃcient model checking. In the following, we
deﬁne bisimulation as a relation on states, relate it to the notion of bisimulation between
transition systems, and deﬁne the quotient transition system under such relation.
Deﬁnition 7.7.
Bisimulation Equivalence as Relation on States
Let TS = (S, Act, →, I, AP, L) be a transition system.
A bisimulation for TS is a binary
relation R on S such that for all (s1, s2) ∈R:
1. L(s1) = L(s2).
2. If s′
1 ∈Post(s1), then there exists an s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R.
3. If s′
2 ∈Post(s2), then there exists an s′
1 ∈Post(s1) with (s′
1, s′
2) ∈R.
States s1 and s2 are bisimulation-equivalent (or bisimilar), denoted s1 ∼TS s2, if there
exists a bisimulation R for TS with (s1, s2) ∈R.

Bisimulation
457
Thus, a bisimulation (on states) for TS is a bisimulation (on transition systems) for the
pair (TS, TS), except that condition (A) is not required. This condition could be ensured
by adding the pairs (s, s) to R for any state s. Moreover, for all states s1 and s2 in TS it
holds that
s1 ∼TS s2



as states of TS (Def. 7.7)
iﬀ
TSs1 ∼TSs2,



in the sense of Def. 7.1
where TSsi denotes the transition system obtained from TS by declaring si as the unique
initial state. Vice versa, the deﬁnition of bisimulation between transition systems (Deﬁni-
tion 7.1) arises from Deﬁnition 7.7 as follows. Take transition systems TS1 and TS2 over
AP, and combine them in a single transition system TS1 ⊕TS2, which basically results
from the disjoint union of state spaces (see below). We then subsequently “compare” the
initial states of TS1 and TS2 as states of the composite transition system TS1 ⊕TS2 to
ensure condition (A).
The formal deﬁnition of TS1 ⊕TS2 is as follows. For TSi = (Si, Acti, →i, Ii, AP, Li),
i = 1, 2:
TS1 ⊕TS2
=
(S1 ⊎S2, Act1 ∪Act2, →1 ∪→2, I1 ∪I2, AP, L)
where ⊎stands for disjoint union and where L(s) = Li(s) if s ∈Si. Then TS1 ∼TS2 if
and only if, for every initial state s1 of TS1, there exists a bisimilar initial state s2 of TS2,
and vice versa. That is, s1 ∼TS1⊕TS2 s2. Stated in terms of equivalence classes, TS1 ∼TS2
if and only if
∀C ∈(S1 ⊎S2)/ ∼TS1⊕TS2 . I1 ∩C ̸= ∅
iﬀ
I2 ∩C ̸= ∅
.
Here, (S1 ⊎S2)/∼TS1⊕TS2denotes the quotient space with respect to ∼TS1⊕TS2, i.e., the set
of all bisimulation equivalence classes in S1 ⊎S2. The latter observation is based on the
fact that ∼TS1⊕TS2 is an equivalence relation, see the ﬁrst part of the following lemma.
Lemma 7.8.
Coarsest Bisimulation
For transition system TS = (S, Act, →, I, AP, L) it holds that:
1. ∼TS is an equivalence relation on S.
2. ∼TS is a bisimulation for TS.
3. ∼TS is the coarsest bisimulation for TS.
Proof: The ﬁrst claim follows directly from the characterization of ∼TS in terms of ∼,
and Lemma 7.4 on page 453. The last claim states that each bisimulation R for TS is

458
Equivalences and Abstraction
ﬁner than ∼TS; this immediately follows from the deﬁnition of ∼TS. It remains to prove
that ∼TS is a bisimulation for TS. We show that ∼TS satisﬁes conditions (1) and (2) of
Deﬁnition 7.7. Condition (3) follows by symmetry. Let s1 ∼TS s2. Then, there exists a
bisimulation R that contains (s1, s2). From condition (1), it follows that L(s1) = L(s2).
Condition (2) yields that for any transition s1 →s′
1 there is a transition s2 →s′
2 with
(s′
1, s′
2) ∈R. Hence, s′
1 ∼TS s′
2.
Stated diﬀerently, the relation ∼TS is the coarsest equivalence on the state space of TS
such that equivalent states are equally labeled and can simulate each other as shown in
Figure 7.5.
s1
∼TS
s2
s1
∼TS
s2
↓
can be complemented to
↓
↓
s′
1
s′
1
∼TS
s′
2
Figure 7.5: Condition (2) for bisimulation equivalence ∼TS on states.
Remark 7.9.
Union of Bisimulations
For ﬁnite index set I and (Ri)i∈I a family of bisimulation relations for TS, 
i∈I Ri is a
bisimulation for TS too (see Exercise 7.2). Since ∼TS is the coarsest bisimulation for TS,
∼TS coincides with the union of all bisimulation relations for TS.
As stated before, bisimilar transition systems satisfy the same linear-time properties. Such
properties—and, as we will see later, all temporal formulae that can be expressed in
CTL∗—can thus be checked on the quotient system instead of on the original (and possibly
much larger) transition system.
Before providing the deﬁnition of quotient transition
systems with respect to ∼TS, let us ﬁrst ﬁx some notations.
Notation 7.10.
Equivalence Classes, Quotient Space
Let S be a set and R an equivalence on S.
For s ∈S, [s]R denotes the equivalence
class of state s under R, i.e., [s]R = { s′ ∈S | (s, s′) ∈R }. Note that for s′ ∈[s]R we
have [s′]R = [s]R. The set [s]R is often referred to as the R-equivalence class of s. The
quotient space of S under R, denoted by S/R = { [s]R | s ∈S }, is the set consisting of
all R-equivalence classes.

Bisimulation
459
Deﬁnition 7.11.
Bisimulation Quotient
For transition system TS = (S, Act, →, I, AP, L) and bisimulation ∼TS, the quotient
transition system TS/ ∼TS is deﬁned by
TS/ ∼TS = (S/ ∼TS, { τ }, →′, I′, AP, L′)
where:
• I′ = { [s]∼| s ∈I },
• →′ is deﬁned by
s
α
−−→s′
[s]∼
τ
−→[s′]∼
,
• L′ ([s]∼) = L(s).
In the sequel, TS/ ∼TS is referred to as the bisimulation quotient of TS. For the sake of
simplicity, we write TS/∼rather than TS/ ∼TS.
The state space of TS/ ∼is the quotient of S under ∼. The initial states in TS/ ∼are
the ∼-equivalence classes of the initial states in TS. Each transition s →s′ in TS induces
a transition [s]∼→′ [s′]∼. As the action label is irrelevant, these labels are omitted from
now on; this is reﬂected in the deﬁnition by replacing any action α ∈Act by an arbitrary
action, τ say. The state-labeling function L′ is well-deﬁned, since all states in [s]∼are
equally labeled (see the deﬁnition of bisimulation). According to the deﬁnition of →′ it
follows for any B, C ∈S/∼:
B →′ C
if and only if
∃s ∈B. ∃s′ ∈C. s →s′
By condition (2) of Deﬁnition 7.7, this is equivalent to
B →′ C
if and only if
∀s ∈B. ∃s′ ∈C. s →s′.
The following two examples show that enormous state-space reductions may be obtained
by considering the bisimulation quotient. In some cases, it even allows obtaining a ﬁnite
quotient transition system for inﬁnite transition systems.

460
Equivalences and Abstraction
Example 7.12.
Many Printers
Consider a system consisting of n printers, each represented as extremely simpliﬁed by
two states, ready and print. The initial state is ready, and once started, each printer
alternates between being ready and printing. The entire system is given by
TSn = Printer ||| . . . ||| Printer



n times
.
Assume the states of TSn are labeled with atomic propositions from the set AP =
{ 0, 1, . . . , n }. Intuitively, L(s) denotes the number of printers available in state s, i.e.,
which are in the local state ready. The number of states of TSn is exponential in n (it is
2n); for n=3, TSn is depicted in Figure 7.6, where r denotes ready, and p denotes print.
The quotient transition system TSn/ ∼, however, only contains n+1 states. For n=3,
TSn/ ∼is depicted in Figure 7.7.
⟨r, r, r⟩
⟨p, r, r⟩
⟨r, p, r⟩
⟨r, r, p⟩
⟨p, p, r⟩
⟨p, p, p⟩
⟨r, p, p⟩
⟨p, r, p⟩
{3}
{2}
{2}
{1}
{0}
{1}
{2}
{1}
Figure 7.6: Transition system TS3 for three independent printers
3
2
1
0
Figure 7.7: Bisimulation quotient TS3/∼.

Bisimulation
461
Example 7.13.
The Bakery Algorithm
We consider a mutual exclusion algorithm, originally proposed by Lamport, which is known
as the Bakery algorithm. Although the principle of the Bakery algorithm allows guaran-
teeing mutual exclusion for an arbitrary number of processes, we consider the simpler
setting with two processes. Let P1 and P2 be two processes, and x1 and x2 be two shared
variables that both initially equal zero, see the following program text:
Process 1:
. . . . . .
while true
{
. . . . . .
n1 :
x1 := x2 + 1;
w1 :
wait until (x2 = 0 ||x1 < x2 ) {
c1 :
. . . critical section . . .}
x1 := 0;
. . . . . .
}
Process 2:
. . . . . .
while true
{
. . . . . .
n2 :
x2 := x1 + 1;
w2 :
wait until (x1 = 0 || x2 < x1) {
c2 :
. . . critical section . . .}
x2 := 0;
. . . . . .
}
These variables are used to resolve a conﬂict if both processes want to enter the critical
section.
(One might consider the value of a variable as a ticket, i.e., a number that
one typically gets upon entering a bakery. The holder of the lowest number is the next
customer to be served.) If process Pi is waiting, and xi < xj or xj=0, then it may enter
the critical section. We have xi > 0 whenever process Pi is either waiting to acquire access
to the critical section, or is in the critical section. On requesting access to the critical
section, process Pi sets xi to xj+1, where i ̸= j. Intuitively, process Pi gives priority to
its opponent, process Pj.
As the value of x1 and x2 may grow unboundedly, the underlying transition system of
the parallel composition of P1 and P2 is inﬁnite; a fragment of the transition system is
depicted in Figure 7.8. An example of a path fragment that visits inﬁnitely many diﬀerent
states is:

462
Equivalences and Abstraction
process P1
process P2
x1
x2
eﬀect
noncrit1
noncrit2
0
0
P1 requests access to critical section
wait1
noncrit2
1
0
P2 requests access to critical section
wait1
wait2
1
2
P1 enters the critical section
crit1
wait2
1
2
P1 leaves the critical section
noncrit1
wait2
0
2
P1 requests access to critical section
wait1
wait2
3
2
P2 enters the critical section
wait1
crit2
3
2
P2 leaves the critical section
wait1
noncrit2
3
0
P2 requests access to critical section
wait1
wait2
3
4
P2 enters the critical section
. . .
. . .
..
..
. . .
Although algorithmic analysis, such as LTL model checking, is impossible due to the
inﬁnity of the transition system, it is not diﬃcult to check that the Bakery algorithm
suﬀers neither from deadlock nor starvation:
• A deadlock only occurs whenever none of the processes can enter the critical section,
i.e., if x1=x2 > 0. It is easy to see, however, that apart from the initial situation,
we always have x1 ̸= x2.
• Starvation only occurs if a process that wants to enter the critical section is never
able to do so. Such situation, however, can never occur: in case both processes want
to enter the critical section, it is impossible that a process acquires access to the
critical section twice in a row.
Alternatively, the correctness of the Bakery algorithm can also be established algorith-
mically. This is done by considering an abstraction of the inﬁnite transition system such
that, instead of the concrete values of x1 and x2, it is only recorded whether
x1 > x2 > 0
or
x2 > x1 > 0
or
x1 = 0
or
x2 = 0
Note that this information is suﬃcient to determine which process may acquire access
to the critical section. By means of this data abstraction, we obtain a ﬁnite transition
system TSabstract
Bak
, e.g., the inﬁnite set of states for which x1 and x2 exceed 0 is mapped
onto the single abstract state ⟨wait1, wait2, x1 > x2 > 0⟩. When considering the atomic
propositions
{ noncriti, waiti, criti | i = 1, 2 } ∪{ x1 > x2 > 0, x2 > x1 > 0, x1 = 0, x2 = 0 }
the ﬁnite transition system TSabstract
Bak
(with the obvious state labeling) is trace-equivalent
to the original inﬁnite transition system TSBak. Due to the fact that trace-equivalent
transition systems satisfy the same LT properties, it follows that each LT property that is

Bisimulation
463
shown to hold for the ﬁnite (abstract) transition system also holds for the original inﬁnite
transition system! The following LT properties, expressed as LTL formulae, indeed hold
for TSabstract
Bak
:
□(¬crit1 ∨¬crit2)
and
(□♦wait1 ⇒□♦crit1) ∧(□♦wait2 ⇒□♦crit2) .
n1 n2
x1
0
x2
0
n1 c2
x1
0
x2
1
n1 w2
x1
0
w1 w2
x1
2
x2
1
c1 w2
x1
1
x2
2
c1 n2
x1
1
x2
0
w1 n2
x1
1
x2
0
w1 c2
n1 c2
x1
0
n1 w2
x1
0
x1
3
c1 n2
x2
0
x2
0
x2
3
x1
0
x2
0
x2
1
w1 w2
x1
1
x2
2
x1
2
x2
1
x2
2
x2
2
w1 w2
x2
2
c1 w2
w1 c2
n1 w2
w1 n2
w1 w2
x1
2
w1 n2
x1
2
x1
2
c1 n2
x1
3
n1 c2
x2
3
Figure 7.8: Fragment of the inﬁnite transition system of the Bakery algorithm.
Transition systems TSBak and TSabstract
Bak
are bisimilar. This can be easily proven by in-
dicating a bisimulation relation. The data abstraction described above is formalized by
means of the function f : S →S′ where S and S′ denote the set of reachable states of
TSBak and TSabstract
Bak
, respectively. The function f associates to any reachable state s of
TSBak, an (abstract) state f(s) of TSabstract
Bak
. Let s = ⟨ℓ1, ℓ2, x1 = b1, x2 = b2⟩be a state
of TSBak with ℓi ∈{ noncriti, waiti, criti } and bi ∈IN for i = 1, 2. Then, we deﬁne
f(s) =
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
⟨ℓ1, ℓ2, x1 = 0, x2 = 0⟩
if b1 = b2 = 0
⟨ℓ1, ℓ2, x1 = 0, x2 > 0⟩
if b1 = 0 and b2 > 0
⟨ℓ1, ℓ2, x1 > 0, x2 = 0⟩
if b1 > 0 and b2 = 0
⟨ℓ1, ℓ2, x1 > x2 > 0⟩
if b1 > b2 > 0
⟨ℓ1, ℓ2, x2 > x1 > 0⟩
if b2 > b1 > 0
.

464
Equivalences and Abstraction
n1 n2
x1 = 0
x2 = 0
n1 w2
x1 = 0
x2 > 0
w1 n2
x1 > 0
x2 = 0
n1 c2
x1 = 0
x2 > 0
c1 n2
x1 > 0
x2 = 0
w1 w2
x1 > x2 > 0
w1 w2
x2 > x1 > 0
c1 w2
x2 > x1 > 0
w1 c2
x1 > x2 > 0
Figure 7.9: Bisimulation quotient transition system of the Bakery algorithm
It follows by straightforward reasoning that R = { (s, f(s)) | s ∈S } is a bisimulation
for (TSBak, TSabstract
Bak
) for any subset of AP
= { noncriti, waiti, criti | i = 1, 2 }.
The
transition system TSabstract
Bak
in Figure 7.9 above is the bisimulation quotient system
TSabstract
Bak
=
TSBak/∼
for
AP = { crit1, crit2 }.
Whereas the original transition system is inﬁnite, its bisimulation quotient is ﬁnite.
Theorem 7.14.
Bisimulation Equivalence of TS and TS/∼
For any transition system TS it holds that TS ∼TS/∼.
Proof: Follows immediately from the fact that { (s, s′) | s′ ∈[s]∼, s ∈S } is a bisimulation
for (TS, TS/R) in the sense of Deﬁnition 7.1 (page 451).

Bisimulation
465
In general, the quotient transition system TS/R with respect to a bisimulation R contains
more states than TS/∼since ∼is the coarsest bisimulation relation. It is often simple to
manually indicate a (meaningful) bisimulation, while the computation of the quotient
space S/∼requires an algorithmic analysis of the complete transition system (see Section
7.3 on page 476 and further). Therefore, it may be advantageous to generate the quotient
system TS/R instead of TS/∼.
7.1.2
Action-Based Bisimulation
As the prime interest of this monograph is model checking, the notions of bisimulation
are all focused on the state labelings; labels of transitions are simply ignored. In other
contexts, most notably process algebras, analogous notions of bisimulation are considered
that do the reverse—these notions ignore state labelings and are focused on transitions
labels, i.e. actions. The aim of this subsection is to relate these notions.
Deﬁnition 7.15.
Action-Based Bisimulation Equivalence
Let TSi = (Si, Act, →i, Ii, APi, Li), i=1, 2, be transition systems over the set Act of
actions. An action-based bisimulation for (TS1, TS2) is a binary relation R ⊆S1 ×S2 such
that
(A) ∀s1 ∈I1 ∃s2 ∈I2. (s1, s2) ∈R and ∀s2 ∈I2 ∃s1 ∈I1. (s1, s2) ∈R
(B) for any (s1, s2) ∈R it holds that
(2’) if s1
α
−−→1 s′
1, then s2
α
−−→2 s′
2 with (s′
1, s′
2) ∈R for some s′
2 ∈S2
(3’) if s2
α
−−→2 s′
2, then s1
α
−−→1 s′
1 with (s′
1, s′
2) ∈R, for some s′
1 ∈S′
1.
TS1 and TS2 are action-based bisimulation equivalent (or action-based bisimilar), denoted
TS1 ∼Act TS2, if there exists an action-based bisimulation R for (TS1, TS2).
Action-based bisimulation diﬀers from the variant for state labels (see Deﬁnition 7.1) in
the following way: the state-labeling condition (B.1) is reformulated by means of the
transition labels, and thus is encoded by conditions (B.2’) and (B.3’). All results and
concepts presented for ∼can be adapted for ∼Act in a straightforward manner.
For
instance, ∼Act is an equivalence and can be adapted to an equivalence ∼Act
TS
for the states
of a single transition system TS in a similar way as before. The action-based bisimulation
quotient system TS/ ∼Act is deﬁned as TS/ ∼except that we deal with an empty set of
atomic propositions and lift any transition s
α
−−→s′ to an equally labeled transition B
α
−−→B′

466
Equivalences and Abstraction
where B and B′ denote the action-based bisimulation equivalence classes of states s and
s′, respectively.
In the context of process calculi, an important aspect of bisimulation is whether it enjoys
a substitutivity property with respect to syntactic operators in the process calculus, such
as parallel composition. The following result states that action-based bisimulation is a
congruence for the parallel composition ∥H with synchronization over handshaking actions
, see Deﬁnition 2.26 on page 48.
Lemma 7.16.
Congruence w.r.t. Handshaking
For transition systems TS1, TS′
1 over Act1, TS2, TS′
2 over Act2, and H ⊆Act1 ∩Act2 it
holds that
TS1 ∼Act TS′
1
and
TS2 ∼Act TS′
2
implies TS1∥HTS2 ∼Act TS′
1∥HTS′
2.
Proof: Let TSi = (Si, Acti, →i, Ii, AP, Li) and TS′
i = (S′
i, Acti, →′
i, I′
i, AP, L′
i) and let
Ri ⊆Si × S′
i be an action-based bisimulation for (TSi, TS′
i), i=1, 2. Then, the relation:
R = { (⟨s1, s2⟩, ⟨s′
1, s′
2⟩) | (s1, s′
1) ∈R1 ∧(s2, s′
2) ∈R2 }
is an action-based bisimulation for (TS1∥HTS2, TS′
1∥HTS′
2). This can be seen as follows.
The fulﬁllment of condition (A) is obvious. To check condition (B.2’), assume that (1) there
is a transition ⟨s1, s2⟩
α
−−→⟨t1, t2⟩in TS1∥HTS2, and (2) (⟨s1, s2⟩, ⟨t1, t2⟩) in R. Distinguish
two cases.
1. α ∈Act \ H. Then ⟨s1, s2⟩
α
−−→⟨t1, t2⟩arises by an individual move of either TS1
or TS2. By symmetry, we may assume that s1
α
−−→1 t1 and s2 = t2. Since (s1, s′
1)
belongs to bisimulation R1, there exists a transition s′
1
α
−−→′
1 t′
1 in TS′
1 with (t1, t′
1) ∈
R1. Thus, ⟨s′
1, s′
2⟩
α
−−→⟨t′
1, s′
2⟩is a transition in TS′
1∥HTS′
2 and (⟨t1, s2⟩, ⟨t′
1, s′
2⟩) ∈R.
2. α ∈H. Then ⟨s1, s2⟩
α
−−→⟨t1, t2⟩arises by synchronizing transitions in TS1 and TS2.
That is, s1
α
−−→1 t1 is a transition in TS1 and s2
α
−−→2 t2 a transition in TS2. Since
(si, s′
i) ∈Ri, there exists a transition s′
i
α
−−→′
i t′
i in TS′
i (for i = 1, 2) with (ti, t′
i) ∈Ri.
Thus, ⟨s′
1, s′
2⟩
α
−−→⟨t′
1, t′
2⟩is a transition in TS′
1∥HTS′
2 and (⟨t1, t2⟩, ⟨t′
1, t′
2⟩) ∈R.
The fulﬁllment of condition (B.3’) follows by a symmetric argument.
Let us now consider the relation between state-based and action-based bisimulation in
more detail.
We ﬁrst discuss how an action-based bisimulation can be obtained from

Bisimulation
467
a state-based bisimulation, and the reverse.
This is done for transition system TS =
(S, Act, →, I, AP, L).
Consider the bisimulation ∼TS on S. The intention is to deﬁne a transition system
TSact = (Sact, Act, →act, Iact, APact, Lact)
such that ∼TS and the action-based bisimulation ∼Act
TS
coincide. As our interest is in action-
based bisimulation on TSact, APact and Lact are irrelevant, and can be taken as AP and
L, respectively. Let Sact = S ∪{ t } where t is a new state (i.e., t /∈S). TSact has the same
initial states as TS, i.e., Iact = I, and is equipped with the action set Act = 2AP ∪{ τ }.
The transition relation →act is given by the rules:
s −→s′
s
L(s)
−−−→act s′
and
s is a terminal state in TS
s
τ
−→act t
Thus, the new state t serves to characterize the terminal states in TS. For bisimulation
R for TS, Ract = R ∪{ (t, t) } is an action-based bisimulation for TSact. Vice versa, for
action-based bisimulation Ract for TSact, Ract ∩(S × S) is a bisimulation for TS. Thus,
for all states s1, s2 ∈S:
s1 ∼TS s2
if and only if
s1 ∼Act
TSact s2.
Let us now consider the reverse direction. Consider the action-based bisimulation ∼Act
TS
on S. The intention is to deﬁne a transition system
TSstate = (Sstate, Actstate, →state, Istate, APstate, Lstate)
such that ∼Act
TS
and the bisimulation ∼TSstate coincide. As our interest is in a state-based
bisimulation, the action-set Actstate is not of importance.
Let Sstate = S ∪(S × Act)
where it is assumed that S ∩(S × Act) = ∅. (Such construction is also used to compare
action-based vs. state-based fairness on page 263) Take Istate = I. The actions of TS serve
as atomic propositions in TSstate, i.e., APstate = Act. The labeling function of Lstate is
deﬁned by L(s) = ∅and L(⟨s, α⟩) = { α }. The transition relation →state is deﬁned by
the rules:
s
α
−−→s′
s −→state ⟨s′, α⟩
and
s
α
−−→s′,
β ∈Act
⟨s, β⟩−→state ⟨s′, α⟩
That is, state ⟨s, α⟩in TSstate serves to simulate state s in TS.
In fact, the second
component α indicates the action via which s is entered. It now follows that for all states
s1, s2 ∈S (see Exercise 7.5):
s1 ∼Act
TS
s2
if and only if
s1 ∼TSstate s2.

468
Equivalences and Abstraction
7.2
Bisimulation and CTL∗Equivalence
This section considers the equivalence relations induced by the temporal logics CTL and
CTL∗and discusses their connection to bisimulation equivalence. As in the chapters on
temporal logic, this section is restricted to transition systems that do not have any terminal
states. These transition systems thus only have inﬁnite paths.
States in a transition system are equivalent with respect to a logic whenever these states
cannot be distinguished by the truth value of any of such formulae. Stated diﬀerently,
whenever there is a formula in the logic that holds in one state, but not in the other, these
states are not equivalent.
Deﬁnition 7.17.
CTL∗Equivalence
Let TS, TS1, and TS2 be transition systems over AP without terminal states.
1. States s1, s2 in TS are CTL∗-equivalent, denoted s1 ≡CTL∗s2, if
s1 |= Φ
iﬀ
s2 |= Φ
for all CTL∗state formulae over AP.
2. TS1 and TS2 are CTL∗-equivalent, denoted TS1 ≡CTL∗TS2, if
TS1 |= Φ
iﬀ
TS2 |= Φ
for all CTL∗state formulae over AP.
States s1 and s2 are CTL∗equivalent if there does not exist a CTL∗state formula that
holds in s1 and not in s2, or, vice versa, holds in s2, but not in s1. This deﬁnition can easily
be adapted to any subset of CTL∗, e.g., s1 and s2 are CTL equivalent, denoted s1 ≡CTL s2,
if for all CTL formulae Φ over AP, { s1, s2 } ⊆Sat(Φ) or { s1, s2 }∩Sat(Φ) = ∅. Similarly,
s1 and s2 are LTL-equivalent, denoted s1 ≡LTL s2, if s1 and s2 satisfy the same LTL
formula over AP.
The fact that trace-equivalent transition systems satisfy the same LTL formulae (see The-
orem 3.15 on page 104) can now be stated as follows:
Theorem 7.18.
Trace Equivalence is Finer Than LTL Equivalence
≡trace ⊆≡LTL.

Bisimulation and CTL∗Equivalence
469
Remark 7.19.
Distinguishing Nonequivalent States by Formulae
Let TS be a transition system without terminal states and s1, s2 states in TS. If s1 ̸≡CTL
s2, then there exists a CTL state formula Φ with s1 |= Φ and s2 ̸|= Φ. This follows from
the deﬁnition of CTL equivalence which yields the existence of a formula Φ with (i) s1 |= Φ
and s2 ̸|= Φ or (ii) s1 ̸|= Φ and s2 |= Φ. In case (ii), one may switch from Φ to ¬Φ and
obtain s1 |= ¬Φ and s2 ̸|= ¬Φ.
A corresponding result holds for CTL∗, but not for LTL. This can be seen as follows.
Assume that s1 ̸≡LTL s2 and Traces(s1) is a proper subset of Traces(s2). Then, all LTL
formulae that hold for s2 also hold for s1. However, since there are traces in Traces(s2)
that are not in Traces(s1), there exists an LTL formula ϕ (e.g., characterizing such trace)
with s2 |= ϕ, but s1 ̸|= ϕ.
The main result of this section is stated in Theorem 7.20 (see below). It asserts that CTL
equivalence, CTL∗equivalence, and bisimulation equivalence coincide. This theorem has
various important consequences. First, and for all, it relates the notion of bisimulation
equivalence to logical equivalences.
As a result, bisimulation equivalence preserves all
formulae that can be formulated in CTL∗or CTL. In principle this result allows performing
model checking on the bisimulation quotient transition system—assuming that we can
obtain this in an algorithmic manner—while preserving both aﬃrmative and negative
outcomes of the model checking. If a CTL∗formula holds for the quotient, it also holds
for the original transition system. Moreover, if the formula is refuted by the quotient, the
original transition system refutes it too. On the other hand, it indicates that a single CTL∗
formula that holds for one but not for the other state suﬃces to show the nonbisimilarity
of the states.
Secondly, the fact that CTL and CTL∗equivalence coincide is perhaps surprising as CTL∗
is strictly more expressive than CTL as CTL∗subsumes LTL, but the expressivenesses
of CTL and LTL are incomparable, see Theorem 6.21 on page 337.
So, although the
expressiveness of CTL∗is strictly larger than that of CTL, their logical equivalence is the
same. In particular, to show CTL∗equivalence it suﬃces to show CTL equivalence!
Theorem 7.20.
CTL∗/CTL and Bisimulation Equivalence
For ﬁnite transition system TS without terminal states:
∼TS
=
≡CTL
=
≡CTL∗.
Proof: The proof of this central result is divided into three steps. First, it is shown that
CTL equivalence is ﬁner than bisimulation equivalence, i.e., ≡CTL ⊆∼TS; see Lemma

470
Equivalences and Abstraction
7.21 below. Subsequently, it is proven that bisimulation equivalence is ﬁner than CTL∗
equivalence, i.e., ∼TS ⊆≡CTL∗; see Lemma 7.26 on page 473. The obvious fact that CTL∗
equivalence is ﬁner than CTL equivalence (since CTL∗subsumes CTL) completes the
proof. Summarizing, we have:
∼TS ⊆≡CTL∗



Lemma 7.26
and
≡CTL∗⊆≡CTL
and
≡CTL ⊆∼TS



Lemma 7.21
Lemma 7.21.
CTL Equivalence is Finer Than Bisimulation
For ﬁnite transition system TS without terminal states, and s1, s2 states in TS:
s1 ≡CTL s2
implies
s1 ∼TS s2 .
Proof: It suﬃces to show that the relation:
R = { (s1, s2) ∈S × S | s1 ≡CTL s2 }
is a bisimulation for TS. This is proven by checking the conditions of being a bisimulation
(see Deﬁnition 7.7 on page 456). As R is, by deﬁnition, an equivalence relation, it suﬃces
to consider the ﬁrst two conditions. Let (s1, s2) ∈R, i.e., s1 ≡CTL s2.
1. Consider the following CTL state formula Φ over AP:
Φ
=

a∈L(s1)
a
∧

a∈AP\L(s1)
¬a.
Clearly, s1 |= Φ. Since s1 ≡CTL s2, it follows that s2 |= Φ. As Φ characterizes
the labeling of state s1, we immediately get L(s1) = L(s2). Thus, condition (1) of
Deﬁnition 7.7 holds.
2. For any equivalence class C ∈S/R, let CTL formula ΦC be such that
(∗)
Sat (ΦC) = C.
ΦC is obtained as follows. For every pair (C, D) of equivalence classes C, D ∈S/R
with C ̸= D, let CTL formula ΦC,D be such that Sat (ΦC,D) ⊇C and Sat (ΦC,D) ∩
D = ∅. Since TS is ﬁnite, there are only ﬁnitely many equivalence classes under R.
Hence, ΦC can be deﬁned as the conjunction of all formulae ΦC,D:

Bisimulation and CTL∗Equivalence
471
ΦC
=

D∈S/R
D̸=C
ΦC,D .
Clearly, condition (∗) is satisﬁed.
Let B ∈S/R and s1, s2 ∈B, i.e., (s1, s2) ∈R and B is the equivalence class of
s1, s2 with respect to R. Further, let s′
1 ∈Post(s1) and C be the equivalence class
of s′
1 with respect to R, i.e., C = [s′
1]R. Now we show the existence of a transition
s2 →s′
2 with (s′
1, s′
2) ∈R.
Due to s′
1 ∈Post(s1) ∩C and (∗), we have s1 |= ∃⃝ΦC. Since s1 ≡CTL s2, we
get s2 |= ∃⃝ΦC. Thus, there is a state s′
2 ∈Post(s2) with s′
2 |= ΦC. But then
equation (∗) yields s′
2 ∈C. Since C = [s′
1]R, we obtain (s′
1, s′
2) ∈R.
Remark 7.22.
Master Formulae
The proof of Lemma 7.21 relies on establishing so-called master formulae ΦC for equiva-
lence class C such that Sat(ΦC) = C. To indicate how to obtain such master formulae,
consider the bisimulation quotient of the Bakery algorithm (see Figure 7.9 on page 464),
and let AP = { crit1, crit2 }. Instead of considering the conjunction of formulae ΦC,D,
master formulae can be obtained by inspecting the transition system. The equivalence
class C = ⟨wait1, wait2, x1 > x2 > 0⟩is, given the atomic propositions in AP, uniquely
characterized by the fact that none of the processes is currently in the critical section and
the second process acquires access to the critical section immediately. A master formula
ΦC for C thus is
ΦC = ¬crit1 ∧¬crit2 ∧∀⃝crit2 .
A master formula for the equivalence class D = ⟨wait1, crit2, −−⟩is
ΦD = crit2 ∧∀⃝¬crit2 .
It is easy to check that none of the other equivalence classes under bisimulation satisﬁes
ΦD.
Remark 7.23.
Logical Characterization by a Sublogic of CTL
We stress that the proof of Lemma 7.21 only exploits the propositional fragment of CTL,
i.e., atomic propositions, conjunction, and negation, and the modal operator ∃⃝. It does
not, however, rely on the presence of the until operator. Thus, bisimulation equivalence
(and CTL∗equivalence) agrees with the equivalence induced by a simple logic that only
contains atomic propositions, negation, conjunction and ∃⃝.
In particular, any two

472
Equivalences and Abstraction
nonbisimilar states can be distinguished by a CTL formula that does contain neither the
until operator U nor one of the derived operators ♦, □, W or R .
Remark 7.24.
Inﬁnite Transition Systems
Lemma 7.21 is restricted to ﬁnite transition systems. This restriction is reﬂected in the
proof as follows. The master formula for equivalence class C, formula ΦC is deﬁned as
the conjunction of CTL formulae for the form ΦC,D with C ̸= D. As CTL only allows for
ﬁnite conjunctions, there should only be ﬁnitely many equivalence classes D ̸= C. This is
guaranteed, of course, if the transition system is ﬁnite. An extension of CTL with inﬁnite
conjunctions would be needed to obtain a similar result for inﬁnite transition systems.
An example of an inﬁnite transition system TS where CTL equivalence is not ﬁner than
bisimulation equivalence is as follows. Assume the set AP of atomic propositions is inﬁnite.
The states in TS are s1, s2 and the states tA where A is a subset of AP. States s1, s2 are
labelled with ∅, while the label of state tA is A. State s1 has a transition to all states tA
where A ̸= AP, while state s2 has transitions to all states tA, including A = AP. Thus,
Post(s1) = {tA | A ⊆AP, A ̸= AP} and Post(s2) = {tA | A ⊆AP}. States tA have
a single outgoing transition which leads to s1. Clearly, s1 and s2 are not bisimulation-
equivalent as s2 has a transition to state tAP but there is no successor of s1 with the
label L(tAP) = AP. On the other hand, s1 and s2 are CTL equivalent with respect to
AP. This follows from the fact that (1) the set of atomic propositions that appear in
a given CTL formula over AP is ﬁnite and (2) s1, s2 are bisimulation-equivalent when
shrinking the set AP′ of atomic propositions to any ﬁnite subset of AP. Note that then
R = {(s1, s2)} ∪{(tA, tB) : A ∩AP′ = B ∩AP′} is a bisimulation. But then Lemma 7.26
yields that s1, s2 satisfy the same CTL formulae over AP′.
However, the result stated in Lemma 7.21 can also be established for (possibly inﬁnite)
transition systems that are ﬁnitely branching. This is shown in the following lemma.
Recall that a transition system is ﬁnitely branching if (i) the set of initial states is ﬁnite
and (ii) for each state s the set of successors (i.e., the set Post(s)) is ﬁnite.
Lemma 7.25.
CTL Equivalence is Finer Than Bisimulation (Revisited)
Let TS = (S, Act, →, I, AP, L) be a ﬁnitely branching transition system without terminal
states, and s1, s2 states in TS. Then s1 ≡CTL s2 implies s1 ∼TS s2.
Proof: As in the proof of Lemma 7.25 we show that
R = { (s1, s2) ∈S × S | s1 ≡CTL s2 }

Bisimulation and CTL∗Equivalence
473
is a bisimulation for TS. Let (s1, s2) ∈R. These states are equally labeled, since for any
atomic proposition a we have s1 |= a iﬀs2 |= a, i.e., a ∈L(s1) if and only if a ∈L(s2).
Condition (2) is proven by contraposition. Let (s1, s2) ∈R and s′
1 ∈Post(s1). Assume
there is no s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R. Since TS is ﬁnitely branching, the set Post(s2)
is ﬁnite, say it agrees with { t1, . . . , tk }. The assumption (s′
1, tj) /∈R and the deﬁnition of
R yields the existence of a CTL formula Ψj such that
s′
1 |= Ψj
and
tj ̸|= Ψj for 0 < j ⩽k.
Now consider the formula
Φ = ∃⃝(Ψ1 ∧. . . ∧Ψk).
Clearly, we have s′
1 |= Ψ1 ∧. . .∧Ψk. Hence, s1 |= Φ. On the other hand, tj ̸|= Ψ1 ∧. . .∧Ψk
for 0 < j ⩽k. This yields s2 ̸|= Φ. But then (s1, s2) /∈R. Contradiction.
The following lemma asserts that bisimilar states are CTL∗equivalent, and is not restricted
to ﬁnite transition systems. Let π1 ∼TS π2 denote that the path fragments π1 and π2 are
statewise bisimilar, i.e., for π1
=
s0,1 s1,1 s2,1 . . . and π2
=
s0,2 s1,2 s2,2 . . ., we have
sj,1 ∼TS sj,2 for all j ⩾0.
Lemma 7.26.
Bisimulation is Finer Than CTL∗Equivalence
Let TS be a transition system TS (over AP) without terminal states, s1, s2 be states in
TS, and π1, π2 inﬁnite path fragments in TS. Then:
(a) If s1 ∼TS s2, then for any CTL∗formula Φ: s1 |= Φ if and only if s2 |= Φ.
(b) If π1 ∼TS π2, then for any CTL∗path formula ϕ: π1 |= ϕ if and only if π2 |= ϕ.
Proof: We simultaneously prove (a) and (b) by means of induction over the structure of
the formula.
Induction basis.
Let s1 ∼TS s2.
For Φ = true, statement (a) obviously holds.
Since
L(s1) = L(s2), it follows that for Φ = a ∈AP:
s1 |= a iﬀa ∈L(s1) iﬀa ∈L(s2) iﬀs2 |= a .
Induction step
(a) Assume Φ1, Φ2, Ψ are CTL∗state formulae for which proposition (a) holds, and ϕ
to be a CTL∗path formula for which proposition (b) holds. Let s1 ∼TS s2. The
proof is by structural induction on Φ:

474
Equivalences and Abstraction
Case 1: Φ = Φ1 ∧Φ2. The induction hypothesis for Φ1 and Φ2 provides
s1 |= Φ1 ∧Φ2
iﬀ
s1 |= Φ1 and s1 |= Φ2
iﬀ
s2 |= Φ1 and s2 |= Φ2
iﬀ
s2 |= Φ1 ∧Φ2.
Case 2: Φ = ¬Ψ. By applying the induction hypothesis for Ψ, one obtains
s1 |= ¬Ψ
iﬀ
s1 ̸|= Ψ
iﬀ
s2 ̸|= Ψ
iﬀ
s2 |= ¬Ψ.
Case 3: Φ = ∃ϕ. For symmetry reasons, it suﬃces to show
s1 |= ∃ϕ
=⇒
s2 |= ∃ϕ.
Assume s1 |= ∃ϕ. Then there exists π1 = s0,1 s1,1 s2,1 . . . ∈Paths(s1) starting
in s1 = s0,1, with π1 |= ϕ. According to the path-lifting lemma (Lemma 7.5
on page 454) there exists a path π2 = s0,2 s1,2 s2,2 . . . ∈Paths(s2) starting in
s2 = s0,2, such that π1 ∼TS π2. From the induction hypothesis (on part (b)), it
follows that π2 |= ϕ. Thus, s2 |= ∃ϕ.
(b) Assume statement (a) holds for CTL∗state formula Φ, and (b) holds for CTL∗path
formulae ϕ1, ϕ2, and ψ.
Let π1 ∼TS π2.
Recall that πi[j . . .] denotes the suﬃx
sj,i sj+1,i sj+2,i . . . of πi. The proof proceeds by structural induction on ϕ:
Case 1: ϕ = Φ. It follows from the CTL∗semantics and the induction hypothesis
on Φ that
π1 |= ϕ iﬀs0,1 |= Φ iﬀs0,2 |= Φ iﬀπ2 |= ϕ.
Case 2: ϕ = ϕ1 ∧ϕ2. By applying the induction hypothesis to ϕ1 and ϕ2 we obtain
π1 |= ϕ1 ∧ϕ2
iﬀ
π1 |= ϕ1 and π1 |= ϕ2
iﬀ
π2 |= ϕ1 and π2 |= ϕ2
iﬀ
π2 |= ϕ1 ∧ϕ2.
Case 3: ϕ = ¬ψ. We apply the induction hypothesis to ψ and obtain
π1 |= ¬ψ
iﬀ
π1 ̸|= ψ
iﬀ
π2 ̸|= ψ
iﬀ
π2 |= ¬ψ.
Case 4: ϕ = ⃝ψ. The induction hypothesis for ψ and the path fragments πl[1 . . .],
l = 1, 2, provides
π1 |= ⃝ψ
iﬀ
π1[1 . . .] |= ψ
iﬀ
π2[1 . . .] |= ψ
iﬀ
π2 |= ⃝ψ.

Bisimulation and CTL∗Equivalence
475
Case 5: ϕ = ϕ1 U ϕ2. The induction hypothesis for ϕ1 and ϕ2 and the path frag-
ments πl[i . . .], l = 1, 2, i = 0, 1, 2, . . ., provides
π1 |= ϕ1 U ϕ2
iﬀ
there exists an index j ∈IN with
π1[j . . .] |= ϕ2 and
π1[i . . .] |= ϕ1, i = 0, 1, . . . , j−1
iﬀ
there exists an index j ∈IN with
π2[j . . .] |= ϕ2 and
π2[i . . .] |= ϕ1, i = 0, 1, . . . , j−1
iﬀ
π2 |= ϕ1 U ϕ2.
Corollary 7.27.
CTL∗/CTL- vs. Bisimulation Equivalence
For ﬁnite transition systems TS1, TS2 (over AP) without terminal states, the following
three statements are equivalent:
(a) TS1 ∼TS2
(b) TS1 ≡CTL TS2, i.e., TS1 and TS2 satisfy the same CTL formulae.
(c) TS1 ≡CTL TS2, i.e., TS1 and TS2 satisfy the same CTL∗formulae.
Thus, bisimilar transition systems are equivalent with respect to all formulae that can be
expressed in CTL∗. The fact that CTL equivalence is ﬁner than bisimulation equivalence
proves that bisimulation equivalence is the coarsest equivalence which preserves all CTL
formulae. Stated diﬀerently, a relation which is strictly coarser than ∼may yield a smaller
quotient transition system, but cannot guarantee the preservation of all CTL formulae.
The fact that CTL equivalence is ﬁner than ∼is useful to prove that two ﬁnite transition
systems are not bisimilar—it suﬃces to indicate a single CTL formula which holds for one
transition system, but not for the other.
Example 7.28.
Distinguishing Nonbisimilar Systems by CTL Formulae
Consider the beverage vending machines TS1 and TS2 in Figure 7.3 on page 453. For
AP = { pay, beer, soda }, we have TS1 ̸∼TS TS2. In fact, they can be distinguished by the
CTL formula
Φ = ∃⃝(∃⃝beer ∧∃⃝soda)
as TS1 |= Φ, but TS2 ̸|= Φ.

476
Equivalences and Abstraction
7.3
Bisimulation-Quotienting Algorithms
This section presents algorithms for obtaining the bisimulation quotient for a ﬁnite tran-
sition system TS. Such an algorithm serves two purposes. First, it can be used to verify
the bisimilarity of two ﬁnite transition systems TS1 and TS2 by considering the quotient
of TS1 ⊕TS2 (see page 457). Since bisimulation is ﬁner than trace equivalence, algorithms
that verify whether TS1 ∼TS2 can also be used as a sound, though incomplete, proof
technique for proving the trace equivalence of TS1 and TS2. Secondly, such algorithms
can be used to obtain the abstract (and thus smaller) transition system TS/∼in a fully
automated manner.
As TS ∼TS/∼(see Theorem 7.14 on page 464), it follows from
Corollary 7.27 on page 475 that any veriﬁcation result for TS/∼—either being negative or
positive—carries over to TS. This applies to any formula expressed in either LTL, CTL,
or CTL∗.
This section treats two algorithms for computing the bisimulation quotient TS/∼. Both
algorithms rely on a partition reﬁnement technique. Roughly speaking, the ﬁnite state
space S is partitioned in blocks, i.e., pairwise disjoint sets of states.
Starting from a
straightforward initial partition where, e.g., all equally labeled states form a partition,
the algorithm successively reﬁnes these partitions such that ultimately partitions only
contain bisimilar states.
This strategy strongly resembles minimization algorithms for
deterministic ﬁnite automata (DFA).
In the sequel, let TS = (S, Act, →, I, AP, L) be a ﬁnite transition system with S ̸= ∅.
Deﬁnition 7.29.
Partition, Block, Superblock
A partition for S is a set Π = {B1, . . . , Bk} such that Bi ̸= ∅(for 0 < i ⩽k), Bi ∩Bj = ∅
(for 0 < i, j ⩽k and i ̸= j), and S = 
0<i⩽k Bi.
Bi ∈Π is called a block. C ⊆S is a superblock of Π if C
=
Bi1 ∪. . . ∪Biℓfor some
Bi1, . . . , Biℓ∈Π.
Let [s]Π denote the unique block of partition Π containing s. For partitions Π1 and Π2 of
S, Π1 is called ﬁner than Π2, or Π2 is called coarser than Π1, if:
∀B1 ∈Π1 ∃B2 ∈Π2. B1 ⊆B2.
In this case, every block of Π2 can be written as a disjoint union of blocks in Π1. Π1
is strictly ﬁner than Π2 (and Π2 is strictly coarser than Π1) if Π1 is ﬁner than Π2 and
Π1 ̸= Π2.

Bisimulation-Quotienting Algorithms
477
Remark 7.30.
Partitions and Equivalences
There is a close connection between equivalence relations and partitions. For equivalence
relation R on S, the quotient space S/R is a partition for S. Vice versa, partition Π for
S induces the equivalence relation:
RΠ
=
{ (s1, s2) | ∃B ∈Π. s1 ∈B ∧s2 ∈B }
=
{ (s1, s2) | [s1]Π = [s2]Π }
such that S/RΠ corresponds to Π. For equivalence relation R, the equivalence relation
RΠ induced by Π = S/R corresponds to R.
The partition reﬁnement algorithm works with a representation of equivalences by means
of the induced partition (i.e., the quotient space).
In the initial partition Π0 = ΠAP,
each group of equally labeled states forms a block. Subsequently, the current partition Πi
is successively replaced with a ﬁner partition Πi+1, (for details, see Section 7.3.2). This
iterative reﬁnement procedure is halted as soon as Πi cannot be further reﬁned, i.e., when
Πi = Πi+1. Such situation is guaranteed to occur as S is ﬁnite. The resulting partition
Πi is the bisimulation quotient space. The main steps are outlined in Algorithm 28.
Algorithm 28 Partition reﬁnement algorithm (basic idea)
Input: ﬁnite transition system TS with state space S
Output: bisimulation quotient space S/∼
Π0 := ΠAP;
(* see Section 7.3.1 *)
i := 0;
(* loop invariant: Πi is coarser than S/∼and ﬁner than ΠAP *)
repeat
Πi+1 := Reﬁne(Πi);
i := i + 1;
until Πi = Πi−1
(* no further reﬁnement possible *)
return Πi
The termination of the partition reﬁnement procedure is clear, as the partition Πi+1 is
strictly ﬁner than Πi. Thus, for the induced equivalence relations RΠi we have
S × S ⊇RΠ0 ⫌RΠ1 ⫌RΠ2 ⫌. . . ⫌RΠi = ∼TS .
Due to the fact that S is ﬁnite, a partition Πi with Πi = Πi−1 is reached after at most
|S| iterations. After |S| proper reﬁnements, any block in Πi is a singleton, and a further
reﬁnement is thus impossible.

478
Equivalences and Abstraction
7.3.1
Determining the Initial Partition
Since bisimilar states are equally labeled, it is rather natural to use this in determining
the initial partition Π0 = ΠAP.
Deﬁnition 7.31.
The AP Partition
The AP partition of TS, denoted ΠAP, is the quotient space S/RAP induced by RAP =
{ (s1, s2) ∈S × S | L(s1) = L(s2) }.
The initial partition Π0 = ΠAP can be computed as follows. The basic idea is to generate
a decision tree for a ∈AP. For AP = { a1, . . . , ak }, the height of the decision tree for
AP is k. The vertices at depth i < k represent the decision “is ai+1 ∈L(s)?”. The left
branch of vertex v at depth i < k represents the case “ai+1 /∈L(s)”, while the right branch
represents “ai+1 ∈L(s)”. The full decision tree for, e.g., k = 2, a1 = a, and a2 = b is fo
the form:
a
L s
a
L s
b
L s
b
L s
b
L s
Leaf v represents a set of states. More precisely, states(v) contains the states s ∈S for
which L(s) is represented by the path from the root to v. The decision tree for AP is
constructed successively by considering all states in S separately. The initial decision tree
consists only of the root v0. On considering state s, the tree is traversed in a top-down
manner, and new vertices are inserted when necessary, i.e., when s is the ﬁrst encountered
state with labeling L(s). Once the tree traversal for state s reaches leaf w, states(w) is
extended with s. The essential steps are outlined in Algorithm 29.
Example 7.32.
Determining the Initial Partition
Consider the transition system TS over AP = { a, b } in Figure 7.10. We assume that
L(s0) = L(s2) = L(s5) = L(s6) = { a }, L(s1) = { a, b }, and L(s3) = L(s4) = ∅. The
ﬁrst three steps for generating the initial partition and the resulting decision tree are
indicated in Figure 7.11.
The resulting partition ΠAP consists of three blocks.
Block
B1 = {s0, s2, s5, s6} represents all states labeled with { a }. The two other blocks stand
for the states labeled with { a, b } or ∅.

Bisimulation-Quotienting Algorithms
479
Algorithm 29 Computing the initial partition ΠAP
Input: TS = (S, Act, →, I, AP, L) over AP = {a1, . . . , ak} and ﬁnite S
Output: partition ΠAP
new(v0);
(* create a root vertex *)
for all s ∈S do
v := v0;
(* start a top-down traversal *)
for i = 1, . . . , k−1 do
if ai ∈L(s) then
if right(v) = nil then new(right(v));
(* create a right child of v *)
v := right(v);
else
if left(v) = nil then new(left(v));
(* create a left child of v *)
v := left(v);
ﬁ
od
(* v is a vertex at depth k *)
if ak ∈L(s) then
if right(v) = nil then new(right(v));
(* create a right child of v *)
states(right(v)) := states(right(v)) ∪{ s };
else
if left(v) = nil then new(left(v));
(* create a left child of v *)
states(left(v)) := states(left(v)) ∪{ s };
ﬁ
od
return {states(w) | w is a leaf}

480
Equivalences and Abstraction
s0
s2
s6
s1
s3
s4
s5
{ a }
{ a }
{ a }
{ a, b }
∅
∅
{ a }
Figure 7.10: Transition system TS over AP = { a, b }.
We conclude this section by considering the time complexity of computing the initial
partition. For each state s in S, the decision tree has to be traversed from root to leaf.
This takes Θ(|AP|) time. The overall time complexity is now given as follows.
Lemma 7.33.
Time Complexity of Computing the Initial Partition
The initial partition ΠAP can be computed in time Θ(|S|·|AP|).
7.3.2
Reﬁning Partitions
Since any partition Πi (i ⩾0) is ﬁner than the initial partition ΠAP, each block in Πi is
guaranteed to contain only equally labeled states. The initial partition, however, does not
consider the one-step successors of states. This is taken care of in the successive reﬁnement
steps.
Lemma 7.34.
Coarsest Partition
The bisimulation quotient space S/∼is the coarsest partition Π for S such that
(i) Π is ﬁner than ΠAP.
a
¬b
a
¬b
b
¬a
¬b
a
¬b
b
¬a
¬b
a
¬b
b
⇝
⇝
⇝
⇝
{s0}
{s0}
{s1}
{s3}
{s0}
{s1}
{s3, s4} {s0, s2, s5, s6}
{s1}
...
Figure 7.11: Generating the Partition ΠAP.

Bisimulation-Quotienting Algorithms
481
(ii) for all B, C ∈Π: B ∩Pre(C) = ∅or B ⊆Pre(C).
Moreover, if partition Π fulﬁlls (ii), then B ∩Pre(C) = ∅or B ⊆Pre(C) for all B ∈Π
and all superblocks C of Π.
Recall that Pre(C) = { s ∈S | Post(s) ∩C ̸= ∅} denotes the set of states in S, which
have at least one successor in C. Thus, for every block B, we have that B ∩Pre(C) = ∅
if and only if no state of B has an immediate successor in C, and B ⊆Pre(C) if and only
if all states in B have an immediate successor in C.
Proof: Let Π be a partition of S and RΠ the equivalence relation on S induced by Π. The
proof is carried out in two steps. We ﬁrst show that RΠ is a bisimulation if and only if
the conditions (i) and (ii) are satisﬁed. Then, we show that S/ ∼is the coarsest partition
satisfying (i) and (ii).
⇐: Assume that Π satisﬁes (i) and (ii). We prove that RΠ induced by Π is a bisimulation.
Let (s1, s2) ∈RΠ and B = [s1]Π = [s2]Π.
1. Since Π is ﬁner than ΠAP (condition (i)), there exists a block B′ of ΠAP containing
B. Thus, s1, s2 ∈B ⊆B′ ∈ΠAP, and, therefore, L(s1) = L(s2).
2. Let s′
1 ∈Post(s1) and C = [s′
1]Π. Then, s1 ∈B ∩Pre(C). By condition (ii), we
obtain B ⊆Pre(C). Hence, s2 ∈Pre(C). So, there exists a state s′
2 ∈Post(s2) ∩C.
Since s′
2 ∈C = [s′
1]Π, it follows that (s′
1, s′
2) ∈RΠ.
⇒: Assume RΠ is a bisimulation. The proof obligation is to show that the conditions (i)
and (ii) are satisﬁed.
(i) By contraposition. Assume that Π is not ﬁner than ΠAP. Then, there exist a block
B ∈Π and states s1, s2 ∈B with [s1]ΠAP ̸= [s2]ΠAP. Then, L(s1) ̸= L(s2). Hence,
RΠ is not a bisimulation. Contradiction.
(ii) Let B, C be blocks of Π.
We assume that B ∩Pre(C)
̸=
∅and show that
B ⊆Pre(C). As B ∩Pre(C) ̸= ∅, there exists a state s1 ∈B with Post(s1)∩C ̸= ∅.
Let s′
1 ∈Post(s1) ∩C and s2 be an arbitrary state of B. We demonstrate that
s2 ∈Pre(C). Since s1, s2 ∈B, we get that (s1, s2) ∈RΠ. Due to s1 →s′
1, there
exists a transition s2 →s′
2 with (s′
1, s′
2) ∈RΠ. But then s′
1 ∈C yields s′
2 ∈C.
Hence, s′
2 ∈Post(s2) ∩C. Thus, s2 ∈Pre(C).

482
Equivalences and Abstraction
Assume Π satisﬁes (ii). We show that B ∩Pre(C) = ∅or B ⊆Pre(C) for any B ∈Π and
superblocks C of Π. The proof is by contraposition. Let B ∈Π and C a superblock, i.e., C
is of the form C = C1 ∪. . . ∪Cℓfor blocks C1, . . . , Cℓof Π. Assume that B ∩Pre(C) ̸= ∅
and B ̸⊆Pre(C).
Then, there exists an index i ∈{1, . . . , ℓ} with B ∩Pre(Ci) ̸= ∅.
Further, it is clear that B ̸⊆Pre(Ci), since otherwise B ⊆Pre(Ci) ⊆Pre(C). Thus,
condition (ii) is not satisﬁed for block Ci ∈Π. Contradiction.
It remains to show that the bisimulation partition Π = S/∼is the coarsest partition of S
satisfying the conditions (i) and (ii). This immediately follows from the fact that ∼TS is
the coarsest bisimulation (Lemma 7.8 on page 457).
Let us now consider how partitions are successively reﬁned. Every reﬁnement aims at
satisfying condition (ii). To that end, a superblock C of Π is considered and every block
B of the current partition Πi is decomposed (“splitted”) into the subblocks B ∩Pre(C)
and B \ Pre(C), provided that these subblocks are nonempty. If one of the subblocks is
empty, then B satisﬁes condition (ii) and no decomposition takes place.
Deﬁnition 7.35.
The Reﬁnement Operator
Let Π be a partition for S and C be a superblock of Π. Then:
Reﬁne(Π, C) =

B∈Π
Reﬁne(B, C)
where Reﬁne(B, C) = {B ∩Pre(C), B \ Pre(C)} \ {∅}.
block B
superblock C
B\Pre(C)
B∩Pre(C)
Figure 7.12: Reﬁnement operator.
The basic scheme of the reﬁnement operator is depicted in Figure 7.12. Reﬁne(B, C) =
{ B }, i.e., B is not decomposed with respect to C, if all states in B have a direct C-
successor or if no state in B has a direct C-successor. In case some states in B have a
direct C-successor, while others have not, B is reﬁned accordingly.

Bisimulation-Quotienting Algorithms
483
The following result shows that successive reﬁnements, starting with partition ΠAP, yield
a series of partitions Π0 = ΠAP, Π1, Π2, Π3, . . ., which become increasingly ﬁner and which
all are coarser than S/∼. This property is essential for establishing the correctness of the
iterative approach for as outlined in Algorithm 28 (see page 477).
Lemma 7.36.
Correctness of the Reﬁnement Operator
Let Π be a partition of S, which is ﬁner than ΠAP and coarser than S/∼. Further, let C
be a superblock for Π. Then:
(a) Reﬁne(Π, C) is ﬁner than Π.
(b) Reﬁne(Π, C) is coarser than S/∼.
Proof:
(a) This follows directly from the deﬁnition of Reﬁne, since every block B ∈Π is either
contained in Reﬁne(Π, C) or is decomposed into B ∩Pre(C) and B \ Pre(C).
(b) Let B ∈S/∼. We show that B is contained in a block of Reﬁne(Π, C). Since Π
is coarser than S/∼, there exists a block B′ ∈Π with B ⊆B′. B′ is of the form
B′ = B ∪D where D is a (possibly empty) superblock of S/∼. If B′ ∈Reﬁne(Π, C),
then B ⊆B′ ∈Reﬁne(Π, C).
Otherwise, i.e., if B′ /∈Reﬁne(Π, C), then B′ is
decomposed into the subblocks B′ ∩Pre(C) and B′ \ Pre(C). We now show that
B is contained in one of these two new subblocks. Condition (ii) of Lemma 7.34
implies that either B ∩Pre(C) = ∅(thus, B \Pre(C) = B) or B \Pre(C) = ∅(thus,
B ∩Pre(C) = B). Since B′ = B ∪D, B is either contained in block
• B′ \ Pre(C) = (B \ Pre(C)) ∪(D \ Pre(C))
• or in B′ ∩Pre(C) = (B ∩Pre(C)) ∪(D ∩Pre(C)).
Deﬁnition 7.37.
Splitter, Stability
Let Π be a partition for S and C a superblock of Π.
1. C is a splitter for Π if there exists a block B ∈Π with B ∩Pre(C) ̸= ∅and
B \ Pre(C) ̸= ∅.

484
Equivalences and Abstraction
2. Block B is stable with respect to C if B ∩Pre(C) = ∅or B \ Pre(C) = ∅.
3. Π is stable with respect to C if each block B ∈Π is stable wrt. C.
C is thus a splitter for Π if and only if Π ̸= Reﬁne(Π, C), that is, if and only if Π is not
stable for C. B is stable with respect to C whenever { B } = Reﬁne(B, C). Note that S/∼
is the coarsest stable partition that is ﬁner than ΠAP.
Algorithm 30 Algorithm for computing the bisimulation quotient space
Input: ﬁnite transition system TS over AP with state space S
Output: bisimulation quotient space S/∼
Π := ΠAP;
while there exists a splitter for Π do
choose a splitter C for Π;
Π := Reﬁne(Π, C);
(* Reﬁne(Π, C) is strictly ﬁner than Π *)
od
return Π
The reﬁne operator and the concept of a splitter can be eﬀectively exploited in computing
S/∼, see Algorithm 30. Its correctness follows from Lemmas 7.34 and 7.36, Termination
follows from the following result.
Lemma 7.38.
Termination Criterion of Algorithm 30
Let Π be a partition for S, which is ﬁner than ΠAP and coarser than S/∼. Then, Π is
strictly coarser than S/∼if and only if there exists a splitter for Π.
Proof: Follows immediately from Lemma 7.34 on page 480.
Example 7.39.
Partition Reﬁnement Algorithm
Figure 7.13 illustrates the principle of the partition reﬁnement algorithm on a small ex-
ample. The initial partition ΠAP identiﬁes all equally labeled states:
Π0 = ΠAP = {{ s1, s2, s3 }, { t1, t2, t3 }, { u1, u2 }, { v1, v2 }}
In the ﬁrst step, consider C1 = { v1, v2 }. This leaves the blocks { s1, s2, s3 }, { u1, u2 } and
{ v1, v2 } unaﬀected, but splits block of the t-states into { t1 } = { t1, t2, t3 } \ Pre(C1) and

Bisimulation-Quotienting Algorithms
485
{ t2, t3 } = { t1, t2, t3 } ∩Pre(C1). Thus, we obtain the partition
Π1 = {{ s1, s2, s3 }, { t1 }, { t2, t3 }, { u1, u2 }, { v1, v2 }}.
In the second reﬁnement step, consider C2 = { t1 }. This splitter divides the s-block into
s1
s2
s3
t1
t2
t3
u1
v1
u2
v2
{a, b}
{a, b}
{a, b}
{b}
{b}
{b}
∅
{a}
∅
{a}
s1
s2
s3
t1
t2
t3
u1
v1
u2
v2
s1
s2
s3
t1
t2
t3
u1
v1
u2
v2
s1
s2
s3
t1
t2
t3
u1
v1
u2
v2
reﬁne
for C = { v1, v2 }
reﬁne
for C = { t2, t3 }
reﬁne
for C = { t1 }
Figure 7.13: Execution of the partition reﬁnement algorithm for a small example.
{ s1, s2 } = { s1, s2, s3 } ∩Pre(C2) and { s3 } = { s1, s2, s3 } \ Pre(C2), yielding
Π2 = {{ s1, s2 }, { s3 }, { t1 }, { t2, t3 }, { u1, u2 }, { v1, v2 }}.
In the third reﬁnement step, consider C3 = { t2, t3 }. This splitter distinguishes states s1
and s2—s1 has no transition to C3, while s2 does—and yields the partition
Π3 = {{ s1 }, { s2 }, { s3 }, { t1 }, { t2, t3 }, { u1, u2 }, { v1, v2 }}.
No further reﬁnements are possible, and Π3 thus agrees with the bisimulation quotient of
the original transition system.
A possible implementation of the operator Reﬁne(Π, C) is based on a list representation
of the sets of predecessors Pre(s′), s′ ∈S. For any state s′ ∈C, the list of predecessors
Pre(s′) is traversed, and s ∈Pre(s′) is “moved” from the (data structure representing the)
current block B = [s]Π to the block
[s]Reﬁne(Π,C) = B ∩Pre(C).

486
Equivalences and Abstraction
The states remaining in B form the subblock B \ Pre(C). In case all states s ∈B are
moved from B to B ∩Pre(C), the set of states in the data structure representing block B
is empty and we have B ∩Pre(C) = B and B \ Pre(C) = ∅. In case no state is moved
from B to B ∩Pre(C), we have, B = B \ Pre(C) and B ∩Pre(C) = ∅.
By means of the above-described technique, every state s′ ∈C causes the costs O(|Pre(s′)|+
1), provided appropriate data structures are used to represent TS (or its state graph), and
the partition Π. (The summand 1 in the complexity bound reﬂects the case Pre(s′) = ∅;
although these summands can be omitted when considering the complexity per state, they
might be relevant when considering the complexity over all states.) Examples of such data
structures are, e.g., an adjacency list representation for Pre(·), and a bit-vector represen-
tation of the satisfaction sets Sat(a) = { s ∈S | a ∈L(s) } to represent the labeling
function. Furthermore, list representations of partition Π and of the blocks B ∈Π can be
used. Using the fact that
O
& 
s′∈C
(|Pre(s′)| + 1)
'
= O (|Pre(C)| + |C|)
we obtain for the time complexity of the reﬁnement operator:
Lemma 7.40.
Time Complexity of the Reﬁnement Operator
Reﬁne(Π, C) can be computed in time O (|Pre(C)| + |C|).
7.3.3
A First Partition Reﬁnement Algorithm
So far we presented the partition reﬁnement algorithm without specifying any search
strategy for the splitters. Such search strategy prescribes how to determine a splitter C
for a given partition Πi+1. A simple strategy that will be pursued in this section, is to
use the blocks of the previous partition Πi (where Π−1 = { S }) as splitter candidates for
Πi+1, see Algorithm 31. In every outermost iteration, the reﬁne operator causes for a state
s ∈S (as part of Πold), the cost O(|Pre(s)| + 1), see page 486. The outermost iteration
is traversed maximally |S| times; this occurs when in every iteration exactly one state is
separated, i.e., constitutes a separate (singleton) block. This yields for the total costs of
the iteration:
O
(
|S| ·

s′∈S
(|Pre(s′)| + 1)
)
=
O (|S|·(M + |S|))
where
M =

s′∈S
|Pre(s′)|

Bisimulation-Quotienting Algorithms
487
Algorithm 31 A ﬁrst partition reﬁnement algorithm
Input: ﬁnite transition system TS with the state space S
Output: bisimulation quotient space S/∼
Π := ΠAP;
(* see Algorithm 29, page 479 *)
Πold := { S };
(* Πold is the previous partition *)
(* loop invariant: Π is coarser than S/∼and ﬁner than ΠAP and Πold *)
repeat
Πold := Π;
for all C ∈Πold do
Π := Reﬁne(Π, C);
od
until Π = Πold
return Π
denotes the number of edges in the state graph G(TS). Assuming M ⩾|S|, this can be
simpliﬁed to O(|S|·M). To obtain the total time complexity of Algorithm 31, it remains
to consider the cost of computing ΠAP, which is Θ(|S|·|AP|), as stated in Lemma 7.33 on
page 480. This yields:
Theorem 7.41.
Time Complexity of Algorithm 31
The bisimulation quotient space of TS can be computed by Algorithm 31 with time com-
plexity O(|S| · (|AP| + M)), under the assumption that M ⩾|S|, where M is the number
of edges in the state graph G(TS).
Computing the bisimulation quotient is thus linear in the number of states of TS. In the
next section, a strategy is presented that improves this such that the time complexity is
logarithmic in |S|.
7.3.4
An Eﬃciency Improvement
The crucial observation that allows for an improvement of the time complexity is that it
is not necessary to reﬁne with respect to all blocks C ∈Πold as in Algorithm 31. Instead,
it suﬃces to only consider roughly half of them, viz. the smaller subblocks of a previous
reﬁnement. More precisely, if a block C′ of the current partition Π is decomposed into
subblocks C1 = C′ ∩Pre(D) and C2 = C′ \ Pre(D), only the smaller subblock is used as a
splitter candidate in the following iteration. Now, let C ∈{ C1, C2 } such that
|C| ⩽|C′|/2,
thus |C| ⩽|C′ \ C|.

488
Equivalences and Abstraction
The decomposition of the blocks B ∈Reﬁne(Π, D) with respect to C and C′ \ C is now
slightly modiﬁed by combining the reﬁnement steps with respect to C and C′ \ C. To
make such “simultaneous” reﬁnement possible, the algorithm exploits a ternary (instead
of the previous binary) reﬁnement operator:
Reﬁne(Π, C, C′ \ C) = Reﬁne( Reﬁne(Π, C), C′ \ C )
where it is assumed that |C| ⩽|C′ \ C|. This modiﬁcation of the reﬁnement operator is
necessary to ensure that the decomposed blocks are stable with respect to C and C′ \ C.
As before, the ternary reﬁnement operator decomposes each block into subblocks:
Reﬁne(Π, C, C′ \ C) =

B∈Π
Reﬁne(B, C, C′ \ C)
The eﬀect of the reﬁnement operator Reﬁne(B, C, C′ \ C) is schematically depicted for
B ⊆Pre(C′) in Figure 7.14. Thus, every block B ∈Π with B ⊆Pre(C′) is decomposed
block B
B3
B1
B2
C
C′ \C
Figure 7.14: Ternary reﬁnement operator.
into maximally three subblocks: states in B that only have direct successors in C, those
that only have such direct successors in C′, and the rest, i.e., states that have direct
successors in both C and C′. Formally:
Reﬁne(B, C, C′ \ C) = { B1, B2, B3 } \ { ∅},
where
B1
=
B ∩Pre(C) ∩Pre(C′ \ C),
B2
=
(B ∩Pre(C)) \ Pre(C′ \ C),
B3
=
(B ∩Pre(C′ \ C)) \ Pre(C).
Note that the blocks B1, B2, B3 are stable with respect to C and C′ \ C.
If B ∩Pre(C′) = ∅, then B is stable with respect to C and C′ \ C, in which case
Reﬁne(B, C, C′ \ C) = { B }. This suggests as loop invariant of the algorithm:
each block B ∈Π is stable with respect to all blocks in Πold

Bisimulation-Quotienting Algorithms
489
From this invariant it follows that only the two cases B ∩Pre(C′) = ∅and B ⊆Pre(C′)
are possible.
Algorithm 32 outlines the main steps of the improved partition reﬁnement algorithm.
To establish the aforementioned loop invariant, the initial partition is Reﬁne(ΠAP, S),
i.e., each block only contains equally-labeled states that are all either terminal or not.
This is based on the observation that Pre(S) = { s ∈S | s is nonterminal }.
Instead
of ﬁrst computing ΠAP and then applying the reﬁnement operator, Reﬁne(ΠAP, S) can
be obtained by executing Algorithm 29 with AP extended with a special symbol which
identiﬁes nonterminal states. The initial partition can thus (as before) be determined in
time Θ(|S| · |AP|).
Algorithm 32 An improved partition reﬁnement algorithm
Input: ﬁnite transition system TS with state space S
Output: bisimulation quotient space S/∼
Πold := { S };
Π := Reﬁne(ΠAP, S);
(* similar to Algorithm 29, page 479 *)
(* loop invariant: Π is coarser than S/∼and ﬁner than ΠAP and Πold, *)
(* and Π is stable with respect to any block in Πold *)
repeat
Πold := Π;
choose block C′ ∈Πold \ Π and block C ∈Π with C ⊆C′ and |C| ⩽|C′|
2 ;
Π := Reﬁne(Π, C, C′ \ C);
until Π = Πold
return Π
Example 7.42.
Abstract Example of Algorithm 32
Consider the quotienting of the transition system in Figure 7.15. Since all black states are
terminal, and all white states are not, we have ΠAP = Reﬁne(ΠAP, S).
In the ﬁrst iteration, one may split with respect to the white or the black states.
As
|{ u1, . . . , u8, w1, w2, w3 }| > |S|
2 , the set of white states is not a suitable splitter. In fact,
the only splitter candidate is block C = { v1, v2 }.
Reﬁne(ΠAP, { v1, v2 }



C
, { u1, u2, . . . , u8, w1, w2, w3 }



C′\C
)

490
Equivalences and Abstraction
AP
w1
u1
u2
u6
v1
w2
u7
v2
w3
u8
Figure 7.15: Example of a transition system.
(with C′ = S), decomposes block B = { u1, u2, . . . , u6, u7, u8, w1, w2, w3 } into
B1
=
B ∩Pre(C) ∩Pre(C′ \ C)
=
{ u7 },
B2
=
(B ∩Pre(C)) \ Pre(C′ \ C)
=
{ u1, u2, . . . , u6 } ∪{ u8 },
B3
=
(B ∩Pre(C′ \ C)) \ Pre(C)
=
{ w1, w2, w3 }.
This yields Πold = { C, C′ \ C } and Π = { C, B1, B2, B3 }.
In the second iteration, the blocks B1 = { u7 } and B3 = { w1, w2, w3 } are potential
splitters. C is not considered as C ̸∈Πold \Π. Block B2 is not considered as splitter, since
it is too large with respect to its superblock in Πold: |B2| = 7 > 11/2 = |C′\C|
2
. Suppose
B1 (called D) is selected as splitter; its superblock in Πold equals D′ = C′ \ C ∈Πold.
Figure 7.16 illustrates the partition obtained by
Reﬁne(Π, { u7 }
  
=D
, { u1, . . . , u6, u8, w1, w2, w3 }



=D′\D
).
The blocks C = { v1, v2 } and B2 remain unchanged, since they do not have any direct
successor in D′ \ D. Block B3 is reﬁned as follows:
Reﬁne({ w1, w2, w3 }, { u7 }, { u1, . . . , u6, u8, w1, w2, w3 }) = { { w1 }, { w2 }, { w3 } }
since w1 has only direct successors in D′ \ D, w2 can only move to D, and w3 can move

Bisimulation-Quotienting Algorithms
491
w1
u1
u2
u6
v1
w2
u7
v2
w3
u8
Figure 7.16: Example for Algorithm 32.
to D as well as to D′ \ D. Thus, at the end of the second iteration:
Π
=
{{ v1, v2 }, { u7 }, { u1, . . . , u6, u8 }, { w1 }, { w2 }, { w3 }},
Πold
=
{{ v1, v2 }



=C
, { u7 }
  
=D
, { u1, . . . , u6, u8, w1, w2, w3 }



=D′\D
}.
The next reﬁnement does not impose any further splittings, and Π = S/∼.
Reﬁne(Π, C, C′ \C) can be realized with time complexity O(|Pre(C)|+|C|) provided every
state s′ ∈Pre(C) causes the costs O(|Pre(s′)|+1). This can be established as follows. For
every pair (s, C′) with s ∈Pre(C′), C′ ∈Πold, a counter δ(s, C′) is introduced that keeps
track of the number of direct successors of s in C′:
δ(s, C′) = |Post(s) ∩C′| .
During the execution of Reﬁne(Π, C, C′ \ C), the values δ(s, C) and δ(s, C′ \ C) are com-
puted for any s ∈Pre(C) as follows:
for all s′ ∈C do
for all s ∈Pre(s′) do
δ(s, C) := δ(s, C) + 1;
od
od
for all s ∈Pre(C) do
δ(s, C′ \ C) := δ(s, C′) −δ(s, C);
od
where it is assumed that initially δ(s, C) = 0.

492
Equivalences and Abstraction
Let B ∈Π be a block with B ⊆Pre(C′), which should be decomposed into B1, B2, B3 by
means of Reﬁne(B, C, C′ \ C). Then B1, B2, and B3 are obtained as follows:
B1
=
B ∩Pre(C) ∩Pre(C′ \ C)
=
{ s ∈B | δ(s, C) > 0, δ(s, C′ \ C) > 0 }
B2
=
B ∩Pre(C) \ Pre(C′ \ C)
=
{ s ∈B | δ(s, C) > 0, δ(s, C′ \ C) = 0 }
B3
=
B ∩Pre(C′ \ C) \ Pre(C)
=
{ s ∈B | δ(s, C) = 0, δ(s, C′ \ C) > 0 }
The decomposition of block B ∈Π is realized by ”moving” the states s ∈Pre(C) from
block B to block B1 or B2. The states remaining in B represent block B3.
The initial values δ(s, C) and δ(s, C′\C) need only be determined for the states in Pre(C).
The initial values of counters for s ∈Pre(C′)\Pre(C) are derived by δ(s, C′\C) = δ(s, C′),
and δ(s, C) = 0. For these states, the variable δ(s, C) is not needed. Variable δ(s, C′) for
state s ∈Pre(C′) \ Pre(C) and block C′ can be identiﬁed with variable δ(s, C′ \ C) for the
new block C′ \ C. These considerations lead to the following lemma:
Lemma 7.43.
Time Complexity of the Ternary Reﬁnement Operator
The time complexity of Reﬁne(Π, C, C′ \ C) is in O(|Pre(C)| + |C|).
As asserted by the following theorem, the time complexity of the improved quotienting
algorithm (see Algorithm 32) is logarithmic in the number of states.
Theorem 7.44.
Time Complexity of Algorithm 32
The bisimulation quotient of a ﬁnite transition system TS = (S, Act, →, I, AP, L) can be
computed with Algorithm 32 in O (|S|·|AP| + M· log |S|).
Proof: The time complexity of Algorithm 32 is bounded above by
O

|S| · |AP| +

s∈S
K(s) · (|Pre(s)| + 1)

where K(s′) denotes the number of blocks C containing s′ for which Reﬁne(Π, C . . .) is
invoked.
The ﬁrst summand represents the asymptotic time needed to compute the initial partition
Reﬁne(ΠAP, S). This partition can be computed in the same way as ΠAP by extending
the set of atomic propositions with a new label that indicates the terminal states. Recall
from Lemma 7.33 (page 480) that ΠAP can be computed in Θ(|S|·|AP|). The fact that an
additional atomic proposition is needed is not relevant.

Bisimulation-Quotienting Algorithms
493
The second summand stands for the cost of the reﬁnement steps; recall that state s ∈C
induces the costs O(|Pre(s)| + 1) on executing Reﬁne(Π, C, C′ \ C), see Lemma 7.43 (page
492). This summand can be bounded from above as follows. We ﬁrst observe that
K(s) ⩽log |S| + 1
for any state s.
This is proven as follows. Let s ∈S and Ci be the ith block with s ∈Ci, for which
Reﬁne(Π, Ci, . . .) is executed. Then:
|Ci+1| ⩽|Ci|
2
and
|C1| ⩽|S|.
Let K(s) = k. Then:
1 ⩽|Ck| ⩽|Ck−1|
2
⩽|Ck−2|
4
⩽. . . ⩽|Ck−i|
2i
⩽. . . ⩽|C1|
2k−1 ⩽|S|
2k−1
From this, we conclude 2k−1 ⩽|S|, or equivalently k−1 ⩽log |S|. This yields K(s) =
k ⩽log |S| + 1.
Let M = 
s∈S |Pre(s)| and assume that a representation of the sets Pre(·) can be obtained
in time O(M). Thus:

s′∈S
K(s′) · (|Pre(s′)| + 1)
⩽
(log |S| + 1)

s′∈S
(|Pre(s′)| + 1)
=
(log |S| + 1) · (M + |S|)
⩽
2 · (log |S| + 1) · M
=
O(M · log |S|)
7.3.5
Equivalence Checking of Transition Systems
The partition reﬁnement algorithms can be used to verify the bisimilarity of the ﬁnite
transition systems TS1 and TS2.
To that end, the bisimulation quotient space of the
composite transition system TS = TS1 ⊕TS2 (see page 457) is computed. Subsequently,
it is checked whether
C ∩I1 = ∅
if and only if
C ∩I2 = ∅
for each bisimulation equivalence class C of the composite system TS. Here, Ii denotes
the set of initial states of TSi, i = 1, 2.

494
Equivalences and Abstraction
Corollary 7.45.
Complexity of Checking Bisimulation Equivalence
Checking whether TS1 ∼TS2 for ﬁnite transition systems TS1 and TS2 over AP with the
state spaces S1 and S2, respectively, can be performed in time
O ((|S1|+|S2|)·|AP| + (M1+M2)· log(|S1|+|S2|)) .
Here, Mi denotes the number of edges in G(TSi) and is assumed to be at least |Si| (i = 1, 2).
Checking whether two transition systems are trace-equivalent is much harder.
In the
following theorem, the problem which asks whether two ﬁnite transition systems are trace
equivalent is shown to be complete for the complexity class PSPACE. This means that
the trace equivalence problem belongs to PSPACE, i.e., is solvable by a polynomial space-
bounded algorithm, and is PSPACE-hard.
Theorem 7.46.
Lower Bound on Checking Trace Equivalence
Let TS1 and TS2 be ﬁnite transition systems over AP. Then:
(a) The problem whether Tracesﬁn(TS1) = Tracesﬁn(TS2) is PSPACE-complete.
(b) The problem whether Traces(TS1) = Traces(TS2) is PSPACE-complete.
Proof: We ﬁrst prove membership of PSPACE. We prove that problems (a) and (b) are
in PSPACE by providing a polynomial reduction from these problems to the equivalence
problem for nondeterministic ﬁnite automata (NFA). As the latter problem is in PSPACE,
the existence of this reduction implies that problems (a) and (b) are in PSPACE. The
equivalence problem for NFA A1 and A2 is whether L(A1) = L(A2).
The main proof idea is to deﬁne NFA ATS for transition system TS such that L(ATS) can be
obtained from Traces(TS), and vice versa. For ﬁnite transition system TS = (S, Act, →,
I, AP, L), let NFA ATS = (Q, Σ, δ, Q0, F) be deﬁned as follows:
• Q = S ∪{ t } with t /∈S (state t identiﬁes terminal states in TS)
• Σ = 2AP ∪{ τ } with τ ̸∈2AP

Bisimulation-Quotienting Algorithms
495
• The transition relation δ in ATS is given by
δ(s, A) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Post(s)
if s ∈S, Post(s) ̸= ∅and L(s) = A
{ t }
if (s ∈S ∧Post(s) = ∅∧L(s) = A)
∨(s = t ∧A = τ)
∅
otherwise
• Q0 = I
• F = Q
It now follows that Traces(TS) is the set consisting of all ﬁnite, nonempty words A0 A1 . . . An
where A0 A1 . . . Anτ ∈L(ATS) and all inﬁnite words A0 A1 A2 . . . ∈(2AP)ω where all pre-
ﬁxes A0 . . . An belong to L(ATS). Hence, Traces(TS) can be derived from L(ATS), and vice
versa.
For ﬁnite transition systems TS1 and TS2 we have
Traces(TS1) = Traces(TS2)
if and only if
L(ATS1) = L(ATS2).
As the NFA ATS are obtained in polynomial time, this yields a polynomial reduction from
problem (b) to the equivalence problem for NFA.
A polynomial reduction from (a) to the equivalence problem for NFA is obtained by
considering a similar transformation TS →A′
TS where A′
TS agrees with ATS, except that the
self-loop at state t is omitted. State t is thus the only terminal in A′
TS. Then, Tracesﬁn(TS)
agrees with the set of all nonempty words accepted by A′
TS, i.e., Tracesﬁn(TS) = L(A′
TS) \
{ ε }. Thus:
Tracesﬁn(TS1) = Tracesﬁn(TS2)
if and only if
L(A′
TS1) = L(A′
TS2).
It remains to show the PSPACE-hardness.
This is shown by a polynomial reduction
from the language-equivalence problem for NFA, a problem that is PSPACE-complete.
PSPACE-hardness of this problem follows from the fact that the (universality) problem
whether L(E) = Σ∗for regular expression E over Σ is PSPACE-hard; see e.g. [383]. Since
there are polynomial transformations from regular expressions to NFA and there is a single-
state NFA for Σ∗, the universality problem is polynomial reducible to the equivalence
problem for NFA.
The main idea is to map an NFA A = (Q, Σ, δ, Q0, F) to a ﬁnite transition system TSA =
(S, { τ }, →, I, AP, L) such that Traces(TSA) encodes L(A). As a preprocessing step we
delete all states q in A with δ∗(q, w) ∩F = ∅for any w ∈Σ∗, as from these states it is
impossible to reach a ﬁnal state. TSA is deﬁned as

496
Equivalences and Abstraction
• S = Q0 ∪(Q × Σ) ∪{ accept } with Q0 ∩(Q × Σ) = ∅and accept ̸∈Q ∪(Q × Σ)
• →is deﬁned by the following rules:
q0 ∈Q0 ∧p ∈δ(q0, A)
q0
τ
−→⟨p, A⟩
q ∈Q ∧B ∈Σ ∧p ∈δ(q, A)
⟨q, B⟩
τ
−→⟨p, A⟩
and
q ∈F ∧B ∈Σ
⟨q, B⟩
τ
−→accept
accept
τ
−→accept
• I = Q0
• AP = Σ ∪{ accept } with accept /∈Σ
• L(q0) = ∅for any q0 ∈Q0, L(⟨q, A⟩) = { A }, and L(accept) = { accept }
It is not diﬃcult to establish that Tracesﬁn(TSA) consists of all preﬁxes of words of the
form ∅{ A1 } . . . { An }{ accept }m with m ⩾0 and A1 . . . An ∈L(A). L(A) can be derived
from Traces(TSA) as follows:
A1 . . . An ∈L(A)
iﬀ
∅{ A1 } . . . { An }{ accept } ∈Tracesﬁn(TSA)
Thus, for NFA A1 and A2 over the alphabet Σ:
L(A1) = L(A2)
iﬀ
Tracesﬁn(TSA1) = Tracesﬁn(TSA2)
iﬀ
Traces(TSA1) = Traces(TSA2)
The equivalence of ﬁnite trace inclusion and trace inclusion follows from Theorem 3.30 on
page 117 as the transition systems TSAi are ﬁnite and do not have terminal states. Since
TSA is obtained in time O(|A|) from A, the above yields a polynomial reduction from the
equivalence problem for NFA to problems (a) and (b).
7.4
Simulation Relations
Bisimulation relations are equivalences requiring two bisimilar states to exhibit identical
stepwise behavior. On the contrary, simulation relations are preorders on the state space
requiring that whenever s ⪯s′ (s′ simulates s), state s′ can mimic all stepwise behavior

Simulation Relations
497
of s; the reverse, i.e., s′ ⪯s is not guaranteed, so state s′ may perform transitions that
cannot be matched by state s.
Thus, if s′ simulates s then every successor of s has
a corresponding, i.e., related successor of s′, but the reverse does not necessarily hold.
Simulation can be lifted to entire transition systems by comparing (according to ⪯) their
initial states. Simulation relations are often used for veriﬁcation purposes to show that
one system correctly implements another, more abstract system. One of the interesting
aspects of simulation relations is that they allow a veriﬁcation by “local” reasoning. The
transitivity of ⪯allows a stepwise veriﬁcation in which the correctness is established
via several intermediate systems. Simulation relations are therefore used as a basis for
abstraction techniques where the rough idea is to replace the model to be veriﬁed by a
smaller abstract model and to verify the latter instead of the original one.
The simulation order ⪯induces an equivalence which is coarser than bisimulation equiv-
alence, and hence yields a better abstraction (i.e., a smaller quotient space), while still
preserving a wide range of logical formulae in LTL and CTL. As bisimulation equivalence
is the coarsest equivalence that preserves CTL and CTL∗, the simulation order ⪯preserves
a fragment of these logics. The use of simulation thus relies on the preservation of certain
classes of formulae, not of all formulae. For instance, if s ⪯s′, then for any safety property
∀ϕ it follows that s′ |= ∀ϕ implies s |= ∀ϕ, since any path starting in s is mimicked by
a similar path that starts in s′. The reverse, s′ ̸|= ∀ϕ, cannot be used to deduce that ∀ϕ
does not hold in the simulated state s; the paths starting in s′ that violate ϕ might be
behaviors that s cannot perform at all.
As for bisimulation relations, the formal deﬁnition of the simulation order relies on a
coinductive approach which deﬁnes the simulation order as the greatest relation satisfying
certain conditions:
Deﬁnition 7.47.
Simulation Order
Let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, 2, be transition systems over AP. A simulation
for (TS1, TS2) is a binary relation R ⊆S1 × S2 such that
(A) ∀s1 ∈I1 . (∃s2 ∈I2. (s1, s2) ∈R)
(B) for all (s1, s2) ∈R it holds that:
(1) L1(s1) = L2(s2)
(2) if s′
1 ∈Post(s1), then there exists s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R.
TS1 is simulated by TS2 (or, equivalently, TS2 simulates TS1), denoted TS1 ⪯TS2, if
there exists a simulation R for (TS1, TS2).

498
Equivalences and Abstraction
Condition (A) requires that all initial states in TS1 are related to an initial state of TS2.
As the reverse is not required, there might be initial states of TS2 that are not matched
by an initial state of TS1. Conditions (B.1) and (B.2) are as for bisimulations; note that
the symmetric counterpart of (B.2)—as for bisimulation—is not required.
Example 7.48.
Two Beverage Vending Machines
Consider the transition systems in Figure 7.17.
Let AP = { pay, beer, soda } with the
obvious labeling functions. The relation
R = { (s0, t0), (s1, t1), (s2, t1), (s3, t2), (s4, t3) }
is a simulation for (TS1, TS2). Since R contains the pair of initial states (s0, t0), TS1 ⪯
TS2. The reverse does not hold, i.e., TS2 ̸⪯TS1, since there is no state in TS1 that can
mimic state t1. This is due to the fact that the options “beer” and “soda” are possible in
state t1, but in no state in TS1.
t0
{ pay }
t1
∅
t2
{ beer }
t3 { soda }
s1
∅
s4
{ soda }
s3
{ beer }
s2
∅
s0
{ pay }
Figure 7.17: The vending machine on the right simulates the one on the left.
Consider now AP = { pay, drink }, and assume states s3, s4, t2 and t3 equals { drink }.
Relation R is again a simulation for (TS1, TS2), and thus TS1 ⪯TS2. Its inverse,
R−1 = { (t0, s0), (t1, s1), (t1, s2), (t2, s3), (t3, s4) },
is a simulation for (TS2, TS1). We thus also obtain TS2 ⪯TS1.
The simulation relation ⪯is a preorder, i.e., it is reﬂexive and transitive. As the conditions
of simulation relations are not symmetric, the simulation preorder is not an equivalence.

Simulation Relations
499
Lemma 7.49.
Reﬂexivity and Transitivity of ⪯
For a ﬁxed set AP of atomic propositions, the relation ⪯is reﬂexive and transitive.
Proof: Similar to the proof of reﬂexivity and transitivity of ∼; see Lemma 7.4 (page 453).
TS1 ⪯TS2 holds if TS1 originates from TS2 by deleting transitions from TS2, e.g., in
case of a nondeterministic choice in TS1, only one alternative is retained. In such cases,
TS1 can be understood as a reﬁnement of TS2, since TS1 resolves some nondeterminism
in TS2. TS1 ⪯TS2 also holds when TS2 arises from TS1 by means of an abstraction.
In fact, abstraction is a fundamental concept that permits the analysis of large or even
inﬁnite transition systems.
Abstraction is identiﬁed by a set of abstract states S; an
abstraction function f, which associates to each (concrete) state s of the transition system
TS the abstract state f(s) which represents it; and a set AP of atomic propositions which
label the concrete and abstract states.
Abstractions diﬀer in the choice of the set S
of abstract states, the abstraction function f, and the relevant propositions AP.
The
concept of abstraction functions has, in fact, already been used in several examples in this
monograph. For instance, an abstraction function was used for the Bakery algorithm in
order to prove that the inﬁnite transition system TSBak has a ﬁnite bisimulation quotient,
see Example 7.13 (page 461).
Due to the special structure of the transition system,
here a bisimulation-equivalent transition system results. Typically, however, an abstract
transition system results that simulates TS.
We brieﬂy outline the essential ideas of abstractions that are obtained by aggregating
disjoint sets of concrete states into single abstract states.
Abstraction functions map
concrete states onto abstract ones, such that abstract states are associated with equally
labeled concrete states only.
Deﬁnition 7.50.
Abstraction Function
Let TS = (S, Act, →, I, AP, L) be a transition system, and S be a set of (abstract) states.
f : S →S is an abstraction function if for any s, s′ ∈S: f(s) = f(s′) implies L(s) = L(s′).
The abstract transition system TSf originates from TS by identifying all states that are
represented by the same abstract state under abstraction function f. An abstract state
is initial whenever it represents an initial concrete state. Similarly, there is a transition
from abstract state f(s) to state f(s′) if there is a transition from s to s′.

500
Equivalences and Abstraction
Deﬁnition 7.51.
Abstract Transition System
Let TS = (S, Act, →, I, AP, L) be a (concrete) transition system, S a set of (abstract)
states, and f : S →S an abstraction function. The abstract transition system TSf =
(S, Act, →f, If, AP, Lf) induced by f on TS is deﬁned by:
• →f is deﬁned by the rule:
s
α
−−→s′
f(s)
α
−−→f f(s′)
• If = { f(s) | s ∈I }
• Lf(f(s)) = L(s) for all states s ∈S
Lemma 7.52.
Let TS = (S, Act, →, I, AP, L) be a (concrete) transition system, S a set of (abstract)
states, and f : S →S an abstraction function. Then TS ⪯TSf.
Proof: Follows from the fact that R = { (s, f(s)) | s ∈S } is a simulation for (TS, TSf).
Example 7.53.
An Automatic Door Opener
Consider an automatic door opener as modeled by the (concrete) transition system in
Figure 7.18; for simplicity, the action labels are omitted from the transitions. Let AP =
{ alarm, open }. The door opener requires a three-digit code d1 d2 d3 as input with di ∈
{ 0, . . . , 9 }. It allows an erroneous digit to be entered, but this may happen at most twice.
The variable error keeps track of the number of wrong digits that have been provided, and
is initially zero. In case error exceeds two, the door opener issues an alarm signal. On a
successful input of the door code, the door is opened. Once locked again, it returns to its
initial state. Location ℓi (for i = 0, 1, 2) indicates that the ﬁrst i digits of the code have
been correctly entered; the second component of a state indicates the value of the variable
error (if applicable).
Consider the following two abstractions. In the ﬁrst abstraction, the concrete states are
aggregated as indicated by the dashed ovals in Figure 7.18. In fact, this is a data abstrac-
tion in which the domain of the variable error is restricted to { ⩽1, 2 }, i.e., the values 0 and
1 are not distinguished in the abstract transition system. The corresponding abstraction

Simulation Relations
501
function f is deﬁned by
f(⟨ℓ, error = k⟩) =

⟨ℓ, error ⩽1⟩
if k ∈{ 0, 1 }
⟨ℓ, error = 2⟩
if k = 2
For all other concrete states, f is the identity function. It immediately follows that f
is indeed an abstraction function, as only equally labeled states are mapped onto the
same abstract state. The abstract transition system TSf is depicted in Figure 7.19; by
construction we have TS ⪯TSf.
⟨ℓ0, 0⟩
⟨ℓ1, 0⟩
⟨ℓ2, 0⟩
⟨ℓ0, 1⟩
⟨ℓ1, 1⟩
⟨ℓ2, 1⟩
⟨ℓ0, 2⟩
⟨ℓ1, 2⟩
⟨ℓ2, 2⟩
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.18: Transition system of the door opener
⟨ℓ0, ⩽1⟩
⟨ℓ1, ⩽1⟩
⟨ℓ2, ⩽1⟩
⟨ℓ0, 2⟩
⟨ℓ1, 2⟩
⟨ℓ2, 2⟩
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.19: Abstract transition system of the door opener (under abstraction function f)
Now consider an abstraction in which we completely abstract from the value of the variable
error. The concrete states that are aggregated are indicated by the dashed ovals in Figure

502
Equivalences and Abstraction
7.20. The corresponding abstraction function g is deﬁned by g(⟨ℓ, error = k⟩) = ℓ, for any
location ℓ∈{ ℓ0, ℓ1, ℓ2 }; g is the identity function otherwise. This yields the transition
system TSg in Figure 7.21. As g is indeed an abstraction function, it follows that TS ⪯
TSg.
⟨ℓ0, 0⟩
⟨ℓ1, 0⟩
⟨ℓ2, 0⟩
⟨ℓ0, 1⟩
⟨ℓ1, 1⟩
⟨ℓ2, 1⟩
⟨ℓ0, 2⟩
⟨ℓ1, 2⟩
⟨ℓ2, 2⟩
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.20: Alternative aggregation of states for the door opener.
ℓ0
ℓ1
ℓ2
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.21: Abstract transition system of the door opener (under abstraction function
g).
The abstract transition systems in the previous example have been obtained by choosing
for the variable error in the system an abstract domain that is smaller than its original
domain { 0, 1, 2 }. Let us illustrate what such a type of abstraction (also known as data
abstraction) means for program graphs.
The essential idea of abstraction in program
graphs is to abstract from concrete values of certain program variables or locations, i.e.,
program counters. Rather than keeping track of the concrete and precise value of variables,
only abstract values are considered. For instance, a possible abstraction of an integer x
could be a three-valued variable which is −1 whenever x < 0, 0 whenever x=0, and 1 if
x > 1. Such abstraction is useful when only the sign of x is of importance.

Simulation Relations
503
Example 7.54.
Data Abstraction applied to a Simple Sequential Program
Consider the following program fragment on the nonnegative integer variables x and y:
ℓ0
while x > 0 do
ℓ1
x := x −1;
ℓ2
y := y + 1;
od;
ℓ3
if even(y) then return “1” else return “0” ﬁ;
ℓ4
...
Let PG be the program graph of this program, and TS its underlying transition system
TS(PG). Each state of TS is of the form s = ⟨ℓ, x = n, y = m⟩, where ℓis a program
location and m and n are natural numbers. By means of abstraction one of the variables
may be completely ignored or the variable domains are restricted. We exemplify the second
kind of abstraction and restrict x and y to the domains
domabstract(x) = {gzero, zero}
and
domabstract(y) = {even, odd}.
Stated in words, we only keep track of whether x > 0 or x=0, and whether y is even or
odd. The precise values of x and y are not explicitly administered.
The abstraction function f which maps a concrete state ⟨ℓ, x = n, y = m⟩(with m, n ∈IN)
onto an abstract state ⟨ℓ, x = V, y = W⟩(with V ∈{gzero, zero} and W ∈{even, odd}) is
deﬁned as follows:
f(⟨ℓ, x = v, y = w⟩) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
⟨ℓ, x = gzero, y = even⟩
if x > 0 ∧y is even
⟨ℓ, x = gzero, y = odd⟩
if x > 0 ∧y is odd
⟨ℓ, x = zero, y = even⟩
if x = 0 ∧y is even
⟨ℓ, x = zero, y = odd⟩
if x = 0 ∧y is odd
To obtain an abstract transition system TSf with TS ⪯TSf, the operations in TS (e.g.,
incrementing y) have to be replaced with corresponding abstract operations that yield
values from the abstract domains. Accordingly, the statement y := y + 1 is replaced with
the abstract operation:
y →
	 even
if y = odd
odd
if y = even
The outcome of the statement x := x −1 depends on the value of x. In the abstract
setting, the precise value of x is, however, not known. Thus, x := x −1 corresponds to
the abstract nondeterministic statement:
x := gzero
or
x := zero

504
Equivalences and Abstraction
(If the guard of the while loop would be x > 1, then there would be no reason for
nondeterminism in the abstract program.)
The abstract transition system TSf results from the following piece of program:
ℓ0
while (x = gzero) do
ℓ1
x := gzero
or
x := zero;
ℓ2
if y = even then y := odd else y := even ﬁ;
od;
ℓ3
if y = even then return “1” else return “0” ﬁ;
ℓ4
...
Note that the abstract program originates from syntactic transformations which can be
completely automated. The previous considerations show that
R = { (s, f(s)) | s ∈Loc × Eval(x ∈IN, y ∈IN) }
is a simulation for (TS, TSf), provided that the initial values of the abstract variables are
chosen in accordance with the initial values of the concrete variables, and the set of atomic
propositions is (a subset of)
AP = { ℓ0, ℓ1, ℓ2, ℓ3, ℓ4, x > 0, x = 0, even(y), odd(y) }
used with the obvious labeling function.
If R is a simulation and (s1, s2) ∈R then each path fragment π1 of s1 can be lifted to a
path fragment π2 of s2 such that π1 and π2 are statewise related via R, see Figure 7.22.
Lemma 7.55.
Simulation on Path Fragments
Let TS1 and TS2 be transition systems over AP, R a simulation for (TS1, TS2), and
(s1, s2) ∈R Then for each (ﬁnite or inﬁnite) path fragment π1 = s0,1 s1,1 s2,1 . . . starting
in s0,1 = s1 there exists a path fragment π2 = s0,2 s1,2 s2,2 . . . from state s0,2 = s2 of the
same length such that (sj,1, sj,2) ∈R for all j.
Proof: The proof is similar to Lemma 7.5 (page 454).
Hence, whenever R is a simulation that contains (s1, s2) and π1 an inﬁnite path from state
s1 then there exists an inﬁnite path from s2 such that π1 and π2 are statewise R-related.
The labeling condition ensures that the traces of π1 and π2 agree. This yields that all
inﬁnite traces of s1 are at the same time inﬁnite traces of s2. If, however, π1 is a ﬁnite

Simulation Relations
505
s1
−R−
s2
↓
s1,1
↓
s2,1
↓
...
↓
sn,1
can be
completed to
s1
−R−
s2
↓
↓
s1,1
−R−
s1,2
↓
↓
s2,1
−R−
s2,2
↓
↓
...
...
↓
↓
sn,1
−R−
sn,2
Figure 7.22: Path fragment lifting for simulations.
path from s1 then π2 is a ﬁnite path fragment from s2, but possibly not maximal (i.e., the
last state of π2 might be nonterminal). Hence, state s1 can have ﬁnite traces, which are
trace fragments, but not traces of s2.
7.4.1
Simulation Equivalence
The simulation relation ⪯is transitive and reﬂexive, but not symmetric. An example
where TS1 ⪯TS2, but TS2 ̸⪯TS1, was provided in Example 7.48 (page 498). However,
as any preorder, ⪯induces an equivalence relation, the so-called kernel of ⪯, which is
deﬁned by ≃= ⪯∩⪯−1. It consists of all pairs (TS1, TS2) of transition systems that
can mutually simulate each other. The relation ≃is called simulation equivalence.
Deﬁnition 7.56.
Simulation Equivalence
Transition systems TS1 and TS2 (over AP) are simulation-equivalent, denoted TS1 ≃TS2,
if TS1 ⪯TS2 and TS2 ⪯TS1.
Example 7.57.
Simulation Equivalent Transition Systems
The transition systems TS1 (left) and TS2 (right) in Figure 7.23 are simulation-equivalent.
This can be seen as follows. Since TS1 is a subgraph of TS2 (up to isomorphism, i.e., state
identities), it is clear that TS1 ⪯TS2. Consider now the reverse direction. The transition
t1 →t2 in TS2 is simulated by s1 →s2. Formally,
R = { (t1, s1), (t2, s2), (t3, s2), (t4, s3) }
is a simulation for (TS2, TS1). From this, we derive TS2 ⪯TS1 and obtain TS1 ≃TS2.

506
Equivalences and Abstraction
s1
{ a }
s2
∅
s3
{ b }
t1
{ a }
t2
∅
t3
∅
t4
{ b }
Figure 7.23: Simulation-equivalent transition systems.
The beverage vending machines described in Example 7.48 (page 498) are not simulation-
equivalent if (as before) the set of propositions AP = { pay, beer, soda } is used. However,
TS1 ≃TS2 holds for AP = { pay } or for AP = { pay, drink }.
The simulation preorder ⪯and its induced equivalence may also be adopted to compare
states of a single transition system.
Deﬁnition 7.58.
Simulation Order as a Relation on States
Let TS = (S, Act, →, I, AP, L) be a transition system. A simulation for TS is a binary
relation R ⊆S × S such that for all (s1, s2) ∈R:
1. L(s1) = L(s2).
2. If s′
1 ∈Post(s1), then there exists an s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R.
State s1 is simulated by s2 (or s2 simulates s1), denoted s1 ⪯TS s2, if there exists a
simulation R for TS with (s1, s2) ∈R. States s1 and s2 of TS are simulation-equivalent,
denoted s1 ≃TS s2, if s1 ⪯TS s2 and s2 ⪯TS s1.
For state s, let SimTS(s) denote the simulator set of s, i.e., the set of states that simulate
s. Formally:
SimTS(s) = { s′ ∈S | s ⪯TS s′ } .
For convenience, the branching-time relations introduced so far are summarized in Figure
7.24.
As stated on page 457 for bisimulations, the relation ⪯TS on S × S results from ⪯via
s1 ⪯TS s2
if and only if
TSs1 ⪯TSs2

Simulation Relations
507
simulation order
s1 ⪯TS s2
:⇔
there exists a simulation R for TS with (s1, s2) ∈R
simulation equivalence
s1 ≃TS s2
:⇔
s1 ⪯TS s2 and s2 ⪯TS s1
bisimulation equivalence
s1 ∼TS s2
:⇔
there exists a bisimulation R for TS with (s1, s2) ∈R
Figure 7.24: Summary of the relations ⪯TS, ∼TS, and ≃TS.
where TSs arises from TS by declaring s as the unique initial state. Vice versa, TS1 ⪯TS2
if each initial state s1 of TS1 is simulated by an initial state of TS2 in the transition
system TS1 ⊕TS2. Analogous observations hold for the simulation equivalence. These
observations allow us to say that a state s1 in a transition system TS1 is simulated by a
state s2 of another transition system TS2, provided that the pair (s1, s2) is contained in
some simulation for (TS1, TS2).
In analogy to Lemma 7.8, ⪯TS is the coarsest simulation. Moreover, the simulation order
on TS is a preorder (i.e., transitive and reﬂexive) on TS’s state space and is the union of
all simulations on TS.
Lemma 7.59.
⪯TS is a Preorder and the Coarsest Simulation
For transition system TS = (S, Act, →, I, AP, L) it holds that:
1. ⪯TS is a preorder on S.
2. ⪯TS is a simulation on TS.
3. ⪯TS is the coarsest simulation for TS.
Proof: The ﬁrst claim follows from Lemma 7.49 (page 453). To prove the second statement
we show ⪯TS fulﬁlls conditions (1) and (2) of simulations on TS (Deﬁnition 7.58). Let
s1 ⪯TS s2 for s1, s2 states in TS. Then, there exists a simulation R that contains (s1, s2).
Since conditions (1) and (2) of Deﬁnition 7.58 hold for all pairs in R, L(s1) = L(s2) and
for any transition s1 →s′
1, there exists a transition s2 →s′
2 with (s′
1, s′
2) ∈R. Hence,
s′
1 ⪯TS s′
2. Thus, ⪯TS is a simulation on TS.

508
Equivalences and Abstraction
The third claim follows immediately from the second statement (⪯TS is a simulation) and
the fact that s1 ⪯TS s2 if there exists some simulation containing (s1, s2). Hence, each
simulation R is contained in ⪯TS.
Let us now deﬁne the quotient transition system under simulation equivalence for tran-
sition system TS = (S, Act, →, I, AP, L). For simplicity, we omit the subscript TS and
simply write ⪯rather than ⪯TS and ≃rather than ≃TS.
Deﬁnition 7.60.
Simulation Quotient System
For transition system TS = (S, Act, →, I, AP, L), the simulation quotient transition system
TS/≃is deﬁned as follows:
TS/≃= (S/≃, { τ }, →≃, I≃, AP, L≃)
where I≃= { [s]≃| s ∈I }, L≃([s]≃) = L(s), and
→≃is deﬁned by:
s
α
−−→s′
[s]≃
τ
−→≃[s′]≃
Note that the transition relation in Deﬁnition 7.60 is similar to that of the bisimula-
tion quotient of TS, but considers equivalence classes under ≃rather than ∼. From the
deﬁnition of →≃it follows that
B −→≃C
if and only if
∃s ∈B. ∃s′ ∈C. s −→s′.
In contrast to the bisimulation quotient, this is not equivalent to
B −→≃C
if and only if
∀s ∈B. ∃s′ ∈C. s −→s′.
Stated in words, B −→≃C does not imply that Post(s) ∩C ̸= ∅for any s ∈B. Thus, in
general, we have TS ̸∼TS/≃. However, simulations can be established for TS and TS/≃
in both directions. That is to say, TS and TS/≃are simulation equivalent:
Theorem 7.61.
Simulation equivalence of TS and TS/≃
For any transition system TS it holds that TS ≃TS/≃.
Proof: TS ⪯TS/≃follows directly from the fact that the relation R = { (s, [s]≃) | s ∈S }
is a simulation for (TS, TS/≃). We show that TS/≃⪯TS by establishing a simulation

Simulation Relations
509
R′ for (TS/≃, TS). First, observe that R′ = R−1 = { ([s]≃, s) | s ∈S } is not adequate,
as it is possible that s′ ≃s, s′ →t′, but [t′]≃∩Post(s) = ∅. Instead,
R′ = { ([s]≃, t) | s ⪯t }
is a simulation for (TS/≃, TS). This is proven as follows. Each initial state [s0]≃in TS/≃
is simulated by an initial state in TS, since [s0]≃⪯s0 and s0 ∈I. In addition, [s]≃and t are
equally labeled as s ⪯t and all states in the simulator set SimTS(s) = { s′ ∈S | s ⪯TS s′ }
of s are equally labeled. It remains to check whether each transition of [s]≃is mimicked
by a transition of t for s ⪯t. Let B ∈S/≃, (B, t) ∈R′, and B −→≃C be a transition in
TS/≃. By deﬁnition of −→≃, there exists a state s ∈B and a transition s →s′ in TS such
that C = [s′]≃. As (B, t) ∈R′, t simulates some state u ∈B, i.e., u ⪯t for some u ∈B.
Since s, u ∈B, and all states in B are simulation-equivalent, we get u ⪯t and s ⪯u (and
u ⪯s). By transitivity of ⪯, we have s ⪯t. There is thus a transition t −→t′ in TS with
s′ ⪯t′. By deﬁnition of R′, (C, t′) = ([s′]≃, t′) ∈R′.
Remark 7.62.
Alternative Deﬁnition of the Simulation Quotient System
Let us consider the following alternative deﬁnition of the simulation quotient system. Let
TS be a transition system as before and
TS/≃′ = (S/≃, {τ}, →′
≃, I≃, AP, L≃)
where I≃and L≃are as in Deﬁnition 7.60 and where the transitions in TS/ ≃′ arise by
the rule
B, B′ ∈S/ ≃
∧∀s ∈B ∃s′ ∈B′. s −→s′
[s]≃−→′
≃[s′]≃
(where the action labels are omitted since they are not of importance here).
Clearly,
TS/ ≃′ is simulated by TS as R = {([s]≃, s) | s ∈S} is a simulation for (TS/ ≃′, TS).
However, we cannot guarantee that the reverse holds, i.e., that TS is simulated by TS/≃′.
Let us illustrate this by means of an example. Assume that TS has two initial states s1
and s2 with Post(s1) = {2i + 1 | i ⩾0} and Post(s2) = {2i | i ⩾0}. Moreover, assume
that
1 ⪯2 ⪯3 ⪯. . .
while state n+1 ̸⪯n for all n ∈IN. For instance, the state space of TS could be {s1, s2} ∪
IN∪{tn | n ∈IN} with sj −→2i+j for all i ⩾0, j = 1, 2, n −→tn and tn+1 −→tn for all n ⩾0,
while state t0 is terminal. Moreover, we deal with AP = { a, b } and L(s1) = L(s2) = { a },
L(n) = { b } and L(tn) = ∅for all n ⩾0. Then ti ⪯TS tj if and only if i < j which yields
i ⪯TS j if and only if i < j

510
Equivalences and Abstraction
and s1 ≃TS s2. In the quotient system TS/≃′, states s1 and s2 are collapsed into their sim-
ulation equivalence class B = { s1, s2 }. Since the states in IN are pairwise not simulation-
equivalent and since s1 and s2 do not have any common direct successor, B is a terminal
state in TS/ ≃′. In particular, the reachable fragment of TS/ ≃′ just consists of the ini-
tial state B and does not have any transition. Thus, TS/ ≃′ and TS are not simulation
equivalent.
In the above example, TS is inﬁnite. If, however, we are given a ﬁnite transition system,
then TS/≃′ simulates TS, which yields the simulation equivalence of TS and TS/≃′. To
see why it suﬃces to establish a simulation for (TS, TS/≃′). Let
R′ = {(s, [t]≃) | s ⪯t}
and show that R′ is a simulation for (TS, TS/≃′). Conditions (A) and (B.1) are obvious.
Let us check condition (B.2). We use the following claim:
Claim. If B ∈S/ ≃, t ∈B and t −→t′, then there exists a transition t −→t′
max such that
t′ ⪯t′
max and B −→′
≃[t′
max]≃.
Proof of the claim. Let t′
max be such that t′
max is ”maximal” in the sense that for any
transition t −→v where t′
max ⪯v we have t′
max ≃v. (Such ”maximal” elements exist since
TS is ﬁnite.) For each state u ∈B, we have t ≃u. Since t ⪯u, there exists a transition
u −→u′ with t′
max ⪯u′. And vice versa, since u ⪯t, there exists a transition t −→v with
u′ ⪯v.
But then t′
max ⪯v by the transitivity of ⪯.
The maximality of t′
max yields
t′
max ≃v. Since t′
max ⪯u′ ⪯v we get t′
max ≃u′. We conclude that all states u ∈B have
an outgoing transition leading to a state in [t′
max]≃. This yields B −→′
≃[t′
max]≃.
We now use the above claim to show (B.2) for R′ when TS is ﬁnite. Let us now suppose
that (s, B) ∈R′ and that s −→s′ is a transition in TS. We take an arbitrary representative
t ∈B. By deﬁnition of R′, state t simulates s. Thus, there exists a transition t −→t′ with
s′ ⪯t′. The above claim yields the existence of a transition t −→t′
max with t′ ⪯t′
max and
B −→′
≃C where C = [t′
max]≃. But then s′ ⪯t′
max and hence, (s′, C) ∈R′.
7.4.2
Bisimulation, Simulation, and Trace Equivalence
In this monograph, various equivalences and preorder relations have been deﬁned on tran-
sition systems. This section compares bisimulation, simulation, and (inﬁnite and ﬁnite)
trace equivalence as well as the simulation preorder and trace inclusion. In the sequel of
this section, let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, 2, be transition systems over AP.
We ﬁrst observe that bisimulation equivalence implies simulation equivalence. This simply

Simulation Relations
511
follows by the symmetry of the conditions required for bisimulations. However, there are
simulation equivalent transition systems which are not bisimulation equivalent. Note that
bisimulation equivalence requires that whenever s1 ∼s2, then every transition s1 →s′
1
can be mimicked by a transition s2 →s′
2 such that s′
1 ∼s′
2.
Simulation equivalence,
however, requires that whenever s1 ≃s2, then s1 →s′
1 can be mimicked by s2 →s′
2 such
that s′
1 ⪯s′
2 (but not necessarily s′
1 ≃s′
2!). The fact that TS1 ≃TS2 does not always
imply TS1 ∼TS2 is illustrated by the following example.
Example 7.63.
Similar but not Bisimilar Transition Systems
Consider the transition systems TS1 (left) and TS2 (right) in Figure 7.25. TS1 ̸∼TS2, as
there is no bisimilar state in TS2 that mimics state s2; the only candidate would be t2,
but s2 cannot mimic t2 →t4. TS1 and TS2 are, however, simulation-equivalent. As TS2
is a subgraph (up to isomorphism) of TS1, we obtain TS2 ⪯TS1. In addition, TS1 ⪯TS2
as
R = { (s1, t1), (s2, t2), (s3, t2), (s4, t3), (s5, t4) }
is a simulation relation for (TS1, TS2).
s1
{ a }
s2
∅
s3
∅
s4
{ b }
s5
{ c }
t1
{ a }
t2
∅
t3
{ b }
t4
{ c }
Figure 7.25: Simulation-, but not bisimulation-equivalent transition systems.
Theorem 7.64.
Bisimulation is Strictly Finer than Simulation Equivalence
TS1 ∼TS2 implies TS1 ≃TS2, but TS1 ̸∼TS2 and TS1 ≃TS2 is possible.
Proof: Suppose TS1 ∼TS2.
Then, there exists a bisimulation R for (TS1, TS2).
It
follows directly that R is a simulation for (TS1, TS2), and that R−1 is a simulation for
(TS2, TS1). Hence, TS1 ≃TS2. Example 7.63 provides transition systems TS1 and TS2
such that TS1 ≃TS2, but TS1 ̸∼TS2.
Recall the notion of AP-determinism (see Deﬁnition 2.5 on page 24).

512
Equivalences and Abstraction
Deﬁnition 7.65.
AP-Deterministic Transition System
Transition system TS = (S, Act, →, I, AP, L) is AP-deterministic if
1. for A ⊆AP: |I ∩{ s | L(s) = A }| ⩽1, and
2. for s ∈S: if s
α
−−→s′ and s
α
−−→s′′ and L(s′) = L(s′′), then s′ = s′′.
The diﬀerence between ∼and ≃crucially relies on AP-determinism, e.g., transition system
TS1 in Figure 7.25 (left) is not AP-deterministic as its initial state has two distinct ∅-
successors.
Theorem 7.66.
AP-Determinism Implies ∼and ≃Coincide
If TS1 and TS2 are AP-deterministic, then TS1 ∼TS2 if and only if TS1 ≃TS2.
Proof: see Exercise 7.3.
This completes the comparison between bisimulation and simulation equivalence. To en-
able the comparison with trace equivalence, we ﬁrst consider the relation between ⪯and
(ﬁnite and inﬁnite) trace inclusion.
Theorem 7.67.
Simulation Order vs. Finite Trace Inclusion
TS1 ⪯TS2 implies Tracesﬁn(TS1) ⊆Tracesﬁn(TS2).
Proof: Assume TS1 ⪯TS2.
Let *
π1 be s1 = s0,1 s1,1 s2,1 . . . sn,1 ∈Pathsﬁn(s1) where
s1 ∈I1, i.e., s1 is an initial state in TS1. Since TS1 ⪯TS2, there exists s2 ∈I2 such that
s1 ⪯s2. As ⪯can be lifted to ﬁnite path fragments (see Lemma 7.55 on page 504), it
follows that there exists *
π2 ∈Pathsﬁn(s2), say, of the form s2 = s0,2 s1,2 s2,2 . . . s2,n such
that *
π1 ⪯*
π2, i.e., sj,1 ⪯sj,2 for 0 ⩽j ⩽n. But then L(sj,1) = L(sj,2) for 0 ⩽j ⩽n, that
is, trace(π1) = trace(π2).
Corollary 7.68.
Simulation Preserves Safety Properties
Let Psafe be a safety LT property and TS1 and TS2 transition systems (all over AP) without
terminal states. Then:
TS1 ⪯TS2
and
TS2 |= Psafe
implies
TS1 |= Psafe.

Simulation Relations
513
Proof: Follows directly from Theorem 7.67 and the fact that Tracesﬁn(TS2) ⊇Tracesﬁn(TS1)
implies that if TS2 |= Psafe, then TS1 |= Psafe (see Corollary 3.15 on page 104).
Theorem 7.67 relates simulation preorder and ﬁnite trace inclusion, and cannot be obtained
for trace inclusion. That is, in general, TS1 ⪯TS2 does not imply that Traces(TS1) ⊆
Traces(TS2). This is illustrated by the following example.
Example 7.69.
Simulation Preorder Does Not Imply Trace Inclusion
Consider the transition systems TS1 (left) and TS2 (right) depicted in Figure 7.26. We
have TS1 ⪯TS2, but Traces(TS1) ̸⊆Traces(TS2) since { a } ∅∈Traces(TS1) but { a } ∅̸∈
Traces(TS1). This is due to the fact that s2 ⪯t2, but whereas s2 is a terminal state, t2 is
s1
{ a }
s2
∅
s3
∅
t1
{ a }
t2
∅
t3
{ b }
s4
{ b }
Figure 7.26: TS1 ⪯TS2, but Traces(TS1) ̸⊆Traces(TS2).
not. (Note that terminal states are simulated by any equally labeled state, be it terminal
or not). As a result, a trace in TS1 may end in s2, but a trace in TS2 cannot end in t2.
The example indicates that terminal states are an essential factor of not preserving trace
inclusion. Indeed, if terminal states are absent in TS1 and TS1 ⪯TS2 then all paths in
TS1 are inﬁnite and the path fragment lifting for simulations yields that each path of TS1
can be lifted to an inﬁnite path in TS2. This yields:
Theorem 7.70.
Simulation Order and Trace Inclusion
If TS1 ⪯TS2 and TS1 does not have terminal states then Traces(TS1) ⊆Traces(TS2).
Thus, for transition systems without terminal states, the result stated in Corollary 7.68
holds for all LT properties and not just the safety properties.

514
Equivalences and Abstraction
For the class of AP-deterministic transition systems one obtains a similar result. Here,
however, we have to deal with simulation equivalence and trace equivalence (rather than
the simulation preorder and trace inclusion).
Theorem 7.71.
Simulation in AP-Deterministic Systems
If TS1 ≃TS2 and TS1 and TS2 are AP-deterministic then Traces(TS1) = Traces(TS2).
Proof: See Exercise 7.3.
Corollary 7.72.
Simulation and (Finite) Trace Equivalence
For transition systems TS1 and TS2 over AP:
(a) If TS1 ≃TS2, then Tracesﬁn(TS1) = Tracesﬁn(TS2).
(b) If TS1 and TS2 do not have terminal states and TS1 ≃TS2, then
Traces(TS1) = Traces(TS2).
(c) If TS1 and TS2 are AP-deterministic, then TS1 ≃TS2 if and only if Traces(TS1) =
Traces(TS2).
Proof: Claim (a) follows from Theorem 7.67, claim (b) from Theorem 7.70. Claim (c)
follows from (and only if) Theorem 7.71 and (if) Exercise 7.3.
Simulation equivalent transition systems without terminal states satisfy the same LT prop-
erties, and hence, the same LTL formulae. Claim (c) together with Theorem 7.66 yield
that for AP-deterministic transition systems, ∼, ≃, and trace equivalence coincide. (Fi-
nite) Trace equivalence does not imply simulation equivalence. This is illustrated by the
two beverage vending machines described in Example 7.48 on page 498.
Remark 7.73.
Bisimulation and Trace Equivalence
Since ∼is ﬁner than ≃, it follows from Theorem 7.67 (page 512) that ∼is ﬁner than ﬁnite
trace equivalence:
TS1 ∼TS2 implies Tracesﬁn(TS1) = Tracesﬁn(TS2).
However, bisimulation equivalent transition systems are even trace eqivalent.
That is,
TS1 ∼TS2 implies Traces(TS1) = Traces(TS2). This applies to any transition system

Simulation and ∀CTL∗Equivalence
515
simulation equivalence
bisimulation equivalence
trace equivalence
Traces(T1) = Traces(TS2)
TS1 ∼TS2
ﬁnite trace inclusion
ﬁnite trace equivalence
Tracesﬁn(T1) = Tracesﬁn(TS2)
Tracesﬁn(T1) ⊆Tracesﬁn(T2)
TS1 ≃TS2
TS1 ⪯TS2
simulation order
trace inclusion
Traces(T1) ⊆Traces(TS2)
Figure 7.27: Relation between equivalences and preorders on transition systems.
TS1, i.e., the absence of terminal states (as in Theorem 7.70 on page 513) is not required.
This stems from the fact that a terminal state cannot be bisimilar to a nonterminal state,
while terminal states are simulated by any state with the same label.
Figure 7.27 summarizes the relationship between bisimulation, simulation, and (ﬁnite and
inﬁnite) trace equivalence as well as simulation order and trace inclusion in the form of
a Hasse diagram. The vertices of the diagram are relations, and an edge from R to R′
means that R is strictly ﬁner than R′, that is to say, R is more distinctive than R′. Recall
that for AP-deterministic transition systems, ∼, ≃and trace equivalence coincide.
7.5
Simulation and ∀CTL∗Equivalence
The aim of this section is to provide a logical characterization of the simulation order ⪯.
This amounts establishing an analogous result to the theorem stating that bisimulation
equivalence coincides with CTL∗(and CTL) equivalence for ﬁnite transition systems with-
out terminal states. That is to say, given two transition systems TS1 and TS2, the aim
is to characterize the relation ⪯in terms of the satisfaction relations on TS1 and TS2 for
some temporal logic. In fact, from the results of the previous section, it can be inferred
that for transition systems without terminal states, TS1 ⪯TS2 implies trace inclusion of
TS1 and TS2, and thus whenever TS2 |= ϕ for a LTL formula ϕ, it follows TS1 |= ϕ. In
this section, it is shown that this not only applies to any LTL formula, but for a fragment

516
Equivalences and Abstraction
of CTL∗that includes LTL.
Since ⪯is not symmetric, it cannot be expected that ⪯can be characterized by a sublogic
of CTL∗which allows negation of arbitrary state formulae. This can be seen as follows.
Let L be a fragment of CTL∗which is closed under negation, i.e., Φ ∈L implies ¬Φ ∈L,
such that for any transition system TS without terminal states and states s1, s2 of TS:
s1 ⪯TS s2
iﬀ
for all state formulae Φ of L: s2 |= Φ =⇒s1 |= Φ.
Let s1 ⪯TS s2. Note that s2 |= ¬Φ implies s1 |= ¬Φ, i.e., s1 ̸|= ¬Φ implies s2 ̸|= ¬Φ. Then,
for any state formula Φ of L:
s1 |= Φ
=⇒
s1 ̸|= ¬Φ
=⇒
s2 ̸|= ¬Φ
=⇒
s2 |= Φ.
Hence, s2 ⪯TS s1. Thus, a logic that characterizes ⪯TS cannot be closed under negation,
as that would require ⪯TS to be symmetric which, however, is not the case.
The proof of the path-lifting lemma (Lemma 7.55 on page 504) informally explains why
for every LTL formula ϕ such that s2 |= ϕ we have s1 |= ϕ. This observation can be
generalized for CTL∗formulae of the form ∀ϕ, provided that the state formulae in ϕ
contain neither negation nor existential quantiﬁcation. These considerations motivate the
deﬁnition of the universal fragment of CTL∗, denoted ∀CTL∗.
Deﬁnition 7.74.
Universal Fragment of CTL∗
The universal fragment of CTL∗, denoted ∀CTL∗, consists of the state formulae Φ and
path formulae ϕ given, for a ∈AP, by
Φ
::=
true
   false
   a
   ¬a
   Φ1 ∧Φ2
   Φ1 ∨Φ2
   ∀ϕ
ϕ
::=
Φ
   
⃝ϕ
   
ϕ1 ∧ϕ2
   ϕ1 ∨ϕ2
   ϕ1 U ϕ2
   ϕ1 R ϕ2.
State formulae in ∀CTL∗are required to be in positive normal form, (negations may only
occur adjacent to atomic propositions) and do not contain existential path quantiﬁers.
Due to the positive normal form (PNF, for short), the release operator R is considered as
a basic operator in the logic. The universal fragment of CTL, denoted ∀CTL, is obtained
from the deﬁnition of ∀CTL∗by restricting the path formulae to
ϕ ::= ⃝Φ
   Φ1 U Φ2
   Φ1 R Φ2.

Simulation and ∀CTL∗Equivalence
517
The eventually and always operators are obtained by the ∀CTL∗path formulae ♦ϕ =
true U ϕ and □ϕ = false R ϕ. Similarly, in ∀CTL these modalities are obtained by ∀♦Φ =
∀(true U Φ) and ∀□Φ = ∀(false R Φ).
∀CTL∗covers all safety properties that can be expressed in CTL∗. The following result
shows that for any LTL formula there exists an equivalent ∀CTL∗formula.
Lemma 7.75.
∀CTL∗Includes LTL
For every LTL formula ϕ there exists an equivalent ∀CTL∗formula.
Proof: It follows from Theorem 5.24 (page 257) that for any LTL formula ϕ there exists
an equivalent LTL formula in PNF. From the deﬁnition of ∀CTL∗and positive normal
form LTL, it follows directly that any LTL formula in PNF can be regarded as a ∀CTL∗
formula.
Vice versa, the universal fragment of CTL∗is more expressive than LTL, as, e.g., ∀♦∀□a
is a ∀CTL∗formula that has no equivalent LTL formula. The following theorem indicates
a temporal logic characterization of the simulation order by ∀CTL∗and ∀CTL.
Theorem 7.76.
Simulation Order and ∀CTL∗/∀CTL
Let TS be a ﬁnite transition system without terminal states and s1, s2 be states of TS. The
following statements are equivalent:
(a) s1 ⪯TS s2.
(b) For all ∀CTL∗formulae Φ: s2 |= Φ implies s1 |= Φ.
(c) For all ∀CTL formulae Φ: s2 |= Φ implies s1 |= Φ.
Proof: The proof technique is analogous to Theorem 7.20 (page 469).
(a) =⇒(b) follows from the following claims that hold for arbitrary (i.e., not necessarily
ﬁnite) transition system TS with state space S:
(i) if s1 ⪯TS s2, then for all ∀CTL∗state formulae Φ: s2 |= Φ implies s1 |= Φ.
(ii) if π1 ⪯TS π2, then for all ∀CTL∗path formulae ϕ: π2 |= ϕ implies π1 |= ϕ.

518
Equivalences and Abstraction
The proof of these claims is by structural induction, similar to Lemma 7.26 (page 473),
and is omitted here. See also Exercise 7.14. For the treatment of formulas ∀ϕ in the step
induction for (i), the assumption that the given transition system does not have terminal
states is crucial, since it permits path lifting rather than just path fragment lifting.
(b) =⇒(c) is obvious since ∀CTL is a sublogic of ∀CTL∗.
(c) =⇒(a). Let S be the state space of the ﬁnite transition system TS. It suﬃces to show
that
R = { (s1, s2) ∈S × S | ∀Φ ∈∀CTL∗. s2 |= Φ ⇒s1 |= Φ }
is a simulation for TS. This is proven by checking the conditions of a simulation relation.
Let (s1, s2) ∈R.
1. If AP is ﬁnite, then we can argue by means of the formula
Φ =

a∈L(s2)
a ∧

a∈AP\L(s2)
¬a.
Note that Φ is a propositional formula in PNF, and hence a ∀CTL formula. Since
s2 |= Φ and (s1, s2) ∈R, we obtain s1 |= Φ. As Φ uniquely characterizes the labeling
of s1, we have L(s1) = L(s2).
If AP is inﬁnite we need a slightly diﬀerent argument. Let a ∈AP. If a ∈L(s2),
then s2 |= a. Since the atomic proposition a is a ∀CTL formula, we get s1 |= a (by
deﬁnition of R), and therefore a ∈L(s1). Similarly, if a /∈L(s2), then s2 |= ¬a.
Again, as ¬a is a ∀CTL formula and by deﬁnition of R, we get s1 |= ¬a, and hence
a /∈L(s1). This yields L(s1) = L(s2).
2. The idea for establishing the condition (2) of simulation relations is to deﬁne a ∀CTL
master formula Φu for the downward closure of state u with respect to R, i.e.,
Sat(Φu) = u↓= { t ∈S | (t, u) ∈R }.
The deﬁnition of Φu is as follows. If u, t are states in TS with t /∈u↓then, according
to the deﬁnition of u↓and R, there exists a ∀CTL formula Φu,t such that u |= Φu,t
and t ̸|= Φu,t. Let Φu be the conjunction of all formulae Φu,t where t ̸∈u↓:
Φu =

t∈S
(t,u)̸∈R
Φu,t
As TS is ﬁnite, Φu arises by a ﬁnite conjunction, and thus, it is a ∀CTL formula. In
fact, Φu is a master formula for u↓:
Sat(Φu) = u↓

Simulation and ∀CTL∗Equivalence
519
Let us check this. If v /∈u↓then (v, u) /∈R and Φu has the form . . . ∧Φu,v ∧. . ..
Hence, v ̸|= Φu (as v ̸|= Φu,v), and therefore v /∈Sat(Φu). Vice versa, if v ∈u↓then
(v, u) ∈R. As u |= Φu we get v |= Φu (by deﬁnition of R). Hence, v ∈Sat(Φu).
It remains to prove that whenever (s1, s2) ∈R and s1 →s′
1, we have that s2 →s′
2
such that (s′
1, s′
2) ∈R. Since TS is ﬁnite, the set of direct successors of s2 is ﬁnite, say
Post(s2) = { u1, . . . , uk }. Let Φi = Φui be the master formula for ui↓, for 0 < i ⩽k.
From ui ∈ui↓, it follows ui |= Φi. Hence:
s2 |= ∀⃝
!
0<i⩽k
Φi
Since (s1, s2) ∈R and ∀⃝
"
0<i⩽k
Φi is a ∀CTL formula, we have:
s1 |= ∀⃝
!
1⩽i⩽k
Φi
Since s′
1 ∈Post(s1), s′
1 ∈Sat(Φi) for some i ∈{ 1, . . . , k }. Hence, s′
1 ∈ui↓, i.e.,
(s′
1, ui) ∈R. Taking s′
2 = ui, we obtain s2 →s′
2 and (s′
1, s′
2) ∈R.
Theorem 7.76 can be reformulated for the simulation order between transition systems.
This yields
TS1 ⪯TS2
if and only if
TS2 |= Φ ⇒TS1 |= Φ
for any ∀CTL∗(or ∀CTL) formula Φ. As the proof of Theorem 7.76 does not exploit the
until operator, this result applies to the fragment of CTL∗that consists of literals (i.e.,
atomic propositions and their negations), conjunction, disjunction, and the modality ∀⃝.
Example 7.77.
Distinguishing Nonsimilar Transition Systems
Consider the transition systems TS1 (left) and TS2 (right) in Figure 7.28. TS1 is simulated
by TS2, but due to the self-loop in the initial state, TS2 ̸⪯TS1. This can also be established
by providing a ∀CTL formula Φ such that, e.g., TS1 |= Φ whereas TS2 ̸|= Φ. Such a ∀CTL
formula is
Φ = ∀⃝(∀⃝¬a ∨∀⃝a).
An alternative logical characterization of ⪯is obtained by replacing the universal quantiﬁer
∀by the existential quantiﬁer ∃using the CTL∗duality rule: ∀ϕ ≡¬∃¬ϕ. Theorem 7.76
yields:
s1 ⪯TS s2 iﬀ
for all formulae ∃ϕ: s1 |= ∃ϕ implies s2 |= ∃ϕ.

520
Equivalences and Abstraction
s1
{ a }
v1
∅
t1
{ a }
s2
{ a }
v2
∅
t2
{ a }
Figure 7.28: TS1 ⪯TS2, but TS2 ̸⪯TS1.
Here, ϕ is an arbitrary CTL∗path formula that does not contain universal path quantiﬁers,
and is in PNF. Such formulae are ∃CTL∗formulae.
Deﬁnition 7.78.
Existential Fragment of CTL∗
The existential fragment of CTL∗, denoted ∃CTL∗, consists of the state formulae Φ and
path formulae ϕ given, for a ∈AP, by
Φ
::=
true
   false
   a
   ¬a
   Φ1 ∧Φ2
   Φ1 ∨Φ2
   ∃ϕ
ϕ
::=
Φ
   
⃝ϕ
   
ϕ1 ∧ϕ2
   ϕ1 ∨ϕ2
   ϕ1 U ϕ2
   ϕ1 R ϕ2.
The existential fragment of CTL, denoted ∃CTL, is obtained by restricting the path
formulae in the above deﬁnition to
ϕ ::= ⃝Φ
   Φ1 U Φ2
   Φ1 R Φ2.
The modalities eventually and always can be derived as for ∀CTL∗and ∀CTL.
Theorem 7.79.
Simulation Order and ∃CTL∗/∃CTL
Let TS be a ﬁnite transition system without terminal states, and s1, s2 states of TS. Then,
the following statements are equivalent:
(a) s1 ⪯TS s2.
(b) For all ∃CTL∗formulae Φ: s1 |= Φ implies s2 |= Φ.
(c) For all ∃CTL formulae Φ: s1 |= Φ implies s2 |= Φ.

Simulation-Quotienting Algorithms
521
Proof: Directly from Theorem 7.76, as statements (b) and (c) here are the duals to state-
ments (b) and (c) in Theorem 7.76.
Corollary 7.80.
Characterizations of Simulation Equivalence
Let TS be a ﬁnite transition system without terminal states and s1, s2 be states in TS.
Then the following ﬁve statements are equivalent:
(a) s1 ≃TS s2.
(b) s1 and s2 satisfy the same ∀CTL∗formulae.
(c) s1 and s2 satisfy the same ∀CTL formulae.
(d) s1 and s2 satisfy the same ∃CTL∗formulae.
(e) s1 and s2 satisfy the same ∃CTL formulae.
Proof: From Theorems 7.76 and 7.79.
In fact, this result can be strengthened as the listed equivalences coincide with the logical
equivalence on the sublogic of CTL that just contains atomic propositions and their nega-
tions, conjunction, disjunction, and the next-step operator ⃝, with either a universal or
existential path quantiﬁer.
7.6
Simulation-Quotienting Algorithms
This section presents algorithms for obtaining the simulation quotient TS/≃for ﬁnite
transition system TS. Such algorithms serve two purposes. First, they can be used to
verify whether TS1 ≃TS2 by considering the simulation quotient of TS1 ⊕TS2 (see page
457). Secondly, such algorithms can be used to obtain the abstract (and thus smaller)
transition system TS/≃in a fully automated manner. As TS ≃TS/≃, it follows that
any veriﬁcation result for TS/≃, either being negative or positive, carries over to TS.
This applies to any formula expressed in either the universal or existential fragment of
CTL or CTL∗. Since simulation equivalence is coarser than bisimulation equivalence, the
quotient TS/≃is at most as large as—but maybe signiﬁcantly smaller than—TS/∼. The
bisimulation quotient of a given inﬁnite state transition system might be inﬁnite whereas
its simulation quotient is ﬁnite.

522
Equivalences and Abstraction
The goal of this section is to present an algorithm which takes as input a ﬁnite transition
system TS = (S, Act, →, I, AP, L), possibly with terminal states, and computes the simu-
lation order ⪯TS. Clearly, this algorithm yields at the same time an automatic approach
to check whether one ﬁnite transition system simulates another one and a sound, but
incomplete technique for proving ﬁnite trace inclusion. The basic scheme for computing
the simulation order is sketched in Algorithm 33.
Algorithm 33 Computation of the simulation order (basic idea)
Input: ﬁnite transition system TS over AP with state space S
Output: simulation order ⪯TS
R := { (s1, s2) | L(s1) = L(s2) };
while R is not a simulation do
choose (s1, s2) ∈R such that s1 →s′
1, but there is no s′
2 such that s2 →s′
2 and
(s′
1, s′
2) ∈R;
R := R \ { (s1, s2) }
od
return R
The number of iterations is bounded above by |S|2, since
S × S ⊇R0 ⫌R1 ⫌R2 ⫌. . . ⫌Rn = ⪯
where Ri denotes the relation R at the start of the (i+1)st iteration.
In the following, we discuss some details that permit an eﬃcient implementation of this
algorithm. Instead of explicitly representing R, we use
SimR(s1) = { s2 ∈S | (s1, s2) ∈R }.
Note that SimR(s1) is a superset of SimTS(s1). This yields Algorithm 34.
A straightforward implementation of Algorithm 34 yields a time complexity O(M · |S|3),
where M, the number of edges in the state graph G(TS), is assumed to be at least |S|. Let
us brieﬂy sketch how this time complexity is established. In every iteration, it is checked
for each transition s1 →s′
1, whether there exists a state s2 ∈Sim(s1) that cannot simulate
this transition. Let counter δ(s′
1, s2) denote the number of successors of s2 that belong to
the current simulator set of s′
1, i.e.,
δ(s′
1, s2) = |Post(s2) ∩Sim(s′
1)|.
The initialization of these counters can be done in O(M·|S|) by setting δ(s′
1, s2) = |Post(s2)|
for each s2 ∈Sim(s1) and s′
1 ∈Post(s1). Checking Post(s2) ∩Sim(s′
1) = ∅reduces to
check whether δ(s′
1, s2) = 0. Given a matrix representation of δ, this takes O(1). Consider
now the operations during an iteration. On removing state s2 from Sim(s1), we set

Simulation-Quotienting Algorithms
523
Algorithm 34 Computation of the simulation order (ﬁrst reﬁnement)
Input: ﬁnite transition system TS over AP with state space S
Output: simulation order ⪯TS
for all s1 ∈S do
Sim(s1) := { s2 ∈S | L(s1) = L(s2) };
(* initialization *)
od
while ∃(s1, s2) ∈S × Sim(s1). ∃s′
1 ∈Post(s1) with Post(s2) ∩Sim(s′
1) = ∅do
choose such a pair of states (s1, s2);
(* s1 ̸⪯TS s2 *)
Sim(s1) := Sim(s1) \ { s2 };
od
(* Sim(s) = SimTS(s) for any s *)
return { (s1, s2) | s2 ∈Sim(s1) }
δ(s1, v2) := δ(s1, v2) −1 for all v2 ∈Pre(s2).
(The number of direct successors of v2 that can simulate s1 is reduced by one, viz. states
s2.)
Assuming a list presentation of the sets Pre(·) and bit vector representations of
the simulator sets Sim(·), the total time complexity of the body of the while-loop (when
ranging over all iterations) is in O(M · |S|). Note that each state s2 is removed from
Sim(s1) at most once. Hence, the total number of steps performed in the body of the
while-loop is bounded by
O
 
s1∈S

s2∈S
|Pre(s2)|



=M

= O(M · |S|).
In order to check whether R is a simulation, we may inspect all transitions s1 →s′
1 and all
states s2 and check whether the counter δ(s′
1, s2) is 0. If so and (s1, s2) ∈R, then R is not
a simulation. Otherwise we have found a pair (s1, s2) to be removed from R in the body
of the while-loop. As |S|2 is an upper bound for the number of iterations of the while-loop
and the costs required to check the condition of the while-loop are in O(M·|S|), the total
time complexity of Algorithm 34 is O(M·|S|3).
With a simple trick, the time complexity can be reduced to O(M·|S|2). The idea is to
organize all pairs (s′
1, s2) where δ(s′
1, s2) = 0 in a list and to pick one such pair (s′
1, s2)
per iteration, rather than seeking for a pair (s1, s2) that violates the simulation condition.
In each iteration, we run through the predecessor list of s′
1 and check for each state
s1 ∈Pre(s′
1) whether s2 ∈Sim(s1). If so, then we remove s2 from Sim(s1) and decrement
the counters δ(s1, v2) for all states v2 ∈Pre(s2). In case δ(s1, v2) becomes 0, the pair
(s1, v2) is inserted in the list organizing all pairs where δ(·) is 0.

524
Equivalences and Abstraction
An Eﬃciency Improvement
We now discuss a further reﬁnement of Algorithm 34
that leads to the worst-case time complexity O(M·|S|). The crux of this more eﬃcient
realization is the following observation. Suppose s1 →s′
1 and s2 →s′
2, and we are about
to remove s′
2 from Sim(s′
1). If state s′
2 is the only direct successor of s2 that belongs to
the current simulator set of s′
1, i.e,
s1 ∈Pre(s′
1), s2 ∈Sim(s1) and Sim(s′
1) ∩Post(s2) = { s′
2 },
then there does not exist a transition s2 →s′
2 which can simulate s1 →s′
1. Hence, s2—in
fact, any direct predecessor of s′
2 for which this holds—can be safely removed from Sim(s1).
This observation can be generalized to sets of states. Let Simold(s1) ⊇Sim(s1) denote the
simulator set that preceded the last removal of states from Sim(s1); initially Simold(s1) =
S. On the removal of s′
2 from Sim(s′
1), we consider all direct predecessors of s′
1, and remove
all states in
Remove(s′
1) = Pre

Simold(s′
1)

\ Pre

Sim(s′
1)

from Sim(s1). This is justiﬁed as all the states in this set do not have a successor sim-
ulating s′
1, and thus these states cannot simulate any of the predecessors of s′
1. (Note
that Post(s2) ∩Sim(s′
1) ̸= ∅if and only if s2 ∈Pre(Sim(s′
1)).)
This yields Algo-
rithm 35, which also takes into account that a terminal state cannot be in the sim-
ulator set of a nonterminal state.
Thus, when s′
1 is considered the ﬁrst time, then
Remove(s′
1) consists of Pre (S) \ Pre (Sim(s′
1)) and all terminal states (that is, we deﬁne
Remove(s′
1) = S \ Pre (Sim(s′
1))).
The next observation is that there is no need to explicitly represent the sets Simold(·). The
sets Remove(·) are dynamically adapted on modifying Sim(s1). The termination condition
of the iteration can be replaced by Remove(s′
1) = ∅for all s′
1 ∈S. Intuitively speaking,
this means that there are no states that need to be removed from the sets of simulators
Sim(s1) for s1 ∈Pre(s′
1). Let s′
1 be a state such that Remove(s′
1) ̸= ∅. Now consider all
pairs (s1, s2) ∈S × S such that
s2 ∈Remove(s′
1) = Pre

Simold(s′
1)

\ Pre

Sim(s′
1)

and s1 ∈Pre(s′
1).
Then, s1 →s′
1, but there is no transition in s2 →s′
2 ∈Sim(s′
1).
This yields s1 ̸⪯TS s2. Therefore, s2 can be removed from Sim(s1). Accordingly, the set
Remove(s1) is extended with any state s such that
s ∈Pre(s2) and Post(s) ∩Sim(s1) = ∅.
For these states s, we have: if u →s1, then there is no matching transition s →t with
t ∈Sim(s1). Thus, u ̸⪯TS s. Hence, if in a later iteration of the while-loop, state s1 is

Simulation-Quotienting Algorithms
525
Algorithm 35 Computation of the simulation order (second reﬁnement)
Input: ﬁnite transition system TS over AP with state space S
Output: simulation order ⪯TS
for all s1 ∈S do
Simold(s1) := undeﬁned;
Sim(s1) := { s2 ∈S | L(s1) = L(s2) }
od
while ∃s ∈S with Simold(s) ̸= Sim(s) do
choose s′
1 such that Simold(s′
1) ̸= Sim(s′
1)
if Simold(s′
1) = undeﬁned then
Remove(s′
1) := S \ Pre(Sim(s′
1))
else
Remove(s′
1) := Pre(Simold(s′
1)) \ Pre(Sim(s′
1))
ﬁ
for all s1 ∈Pre(s′
1) do
Sim(s1) := Sim(s1) \ Remove(s′
1)
od
Simold(s′
1) := Sim(s′
1)
od
return { (s1, s2) | s2 ∈Sim(s1) }

526
Equivalences and Abstraction
chosen, then the simulator sets of the predecessors u ∈Pre(s1) are regarded and state s
is to be removed from Sim(u). This yields Algorithm 36.
Algorithm 36 Computation of the simulation order
Input: ﬁnite transition system TS with state space S
Output: simulation order ⪯TS
for all s1 ∈S do
Sim(s1) := { s2 ∈S | L(s1) = L(s2) };
Remove(s1) := S \ Pre(Sim(s1))
od
(* loop invariant: Remove(s′
1) ⊆S \ Pre (Sim(s′
1)) *)
while (∃s′
1 ∈S with Remove(s′
1) ̸= ∅) do
choose s′
1 such that Remove(s′
1) ̸= ∅;
for all s2 ∈Remove(s′
1) do
for all s1 ∈Pre(s′
1) do
if s2 ∈Sim(s1) then
Sim(s1) := Sim(s1) \ { s2 };
(* s2 ∈Simold(s1) \ Sim(s1) *)
for all s ∈Pre(s2) with Post(s) ∩Sim(s1) = ∅do
(* s ∈Pre (Simold(s1)) \ Pre(Sim(s1)) *)
Remove(s1) := Remove(s1) ∪{ s }
od
ﬁ
od
od
Remove(s′
1) := ∅;
(* Simold(s′
1) := Sim(s′
1) *)
od
return { (s1, s2) | s2 ∈Sim(s1) }
Theorem 7.81.
Partial Correctness of Algorithm 36
On termination, Algorithm 36 returns ⪯TS.
Proof: First, observe that the outermost loop (i.e., the while-loop) maintains the following
loop invariant. For all states s1 ∈S:
(a) Remove(s1) ⊆S \ Pre(Sim(s1)).
(b) { s2 ∈S | s1 ⪯TS s2 } ⊆Sim(s1) ⊆{ s2 ∈S | L(s1) = L(s2) }.
(c) For all s2 ∈Sim(s1), one of the following two statements holds:

Simulation-Quotienting Algorithms
527
• ∃s′
1 ∈Post(s1) with Post(s2) ∩Sim(s′
1) = ∅and s2 ∈Remove(s′
1),
• Post(s2) ∩Sim(s′
1) ̸= ∅for all s′
1 ∈Post(s1).
From (c), it follows that whenever Remove(s′
1) = ∅for all s′
1 ∈S, then:
∀s1 ∈S. ∀s2 ∈Sim(s1). ∀s′
1 ∈Post(s1). Post(s2) ∩Sim(s′
1) ̸= ∅.
Therefore, on termination, the relation R = { (s1, s2) | s2 ∈Sim(s1) } is a simulation for
TS. Assertion (b) implies that R agrees with ⪯TS, as ⪯TS is the coarsest simulation for
TS.
Lemma 7.82.
Termination of Algorithm 36
For each pair (s2, s′
1) ∈S×S, state s2 is inserted in (and removed from) the set Remove(s′
1)
at most once.
In particular, Algorithm 36 requires at most O(|S|2) iterations.
Proof: Assume s2 ∈Remove(s′
1) and let s′
1 be the state that is selected in the outermost
iteration. Then s2 /∈Pre(Sim(s′
1)) (by part (a) of the loop invariant established in the proof
of Theorem 7.81). Since the simulator sets are decreasing, s2 /∈Pre(Sim(s′
1)) in all further
iterations: the only possibility to insert s = s2 in Remove(s′
1) is when s ∈Pre(¯s2) for
some state ¯s2 ∈Sim(s′
1) with Post(s) ∩Sim(s′
1) = { ¯s2 }. But then s2 = s ∈Pre(Sim(s′
1)).
Thus, s2 will never be added to Remove(s′
1) once it has been deleted from Remove(s′
1).
This lemma is the starting point for deriving the time complexity of Algorithm 36. Let M
be the number of edges in the state graph of TS and assume M ⩾|S|. Assume that list
representations for the sets of predecessors Pre(·) are available. As for the initial algorithm
to compute ⪯TS, we deal with counters
δ(s1, s) = |Post(s) ∩Sim(s1)|.
Using Algorithm 29 (page 479), the initial simulator sets Sim(s1) = {s2 ∈S | L(s1) =
L(s2)} can be obtained in time O(|S| · |AP|). We then compute the sets Remove(s1) and
the counters δ(s1, s) in time O(M·|S|). In each iteration the counters δ(s1, s) need to
be updated. This is done as follows. On removing s2 from Sim(s1), the list Pre(s2) is
traversed and we set
δ(s1, s) := δ(s1, s) −1
for every s ∈Pre(s1).
The check Post(s) ∩Sim(s1) = ∅boils down to δ(s1, s) = 0 and can be performed in
constant time. The total costs of the outermost iteration can be estimated as follows. For

528
Equivalences and Abstraction
each state s2 and each edge s →s2, the condition ”s2 ∈Remove(s′
1) ∧s2 ∈Sim(s1)” is
satisﬁed at most once. Therefore, the code fragment
if s2 ∈Sim(s1) then
Sim(s1) := Sim(s1) \ { s2 };
for all s ∈Pre(s2) do
if Post(s) ∩Sim(s1) = ∅then
Remove(s1) := Remove(s1) ∪{ s };
ﬁ
od
ﬁ
causes the cost:
O


s2∈S
|Pre(s2)|



M
·

s1∈S
1
  
|S|

=
O(M · |S|),
where we add up the costs over all iterations for which s2 ∈Sim(s1).
The condition
s2 ∈Remove(s′
1) of the outermost for-loop is fulﬁlled at most once (see Lemma 7.82).
Thus, the total costs for all inner loops
for all s2 ∈Remove(s′
1) do
for all s1 ∈Pre(s′
2) do
...
od
od
is bounded by O(M). Under the assumption that M ⩾|S|, we thus obtain:
Theorem 7.83.
Complexity of Algorithm 36
The simulation order ⪯of ﬁnite transition system TS = (S, Act, →, I, AP, L) can be com-
puted with Algorithm 36 in time O(M·|S| + |S|·|AP|).
The simulation equivalence ≃TS and the simulation quotient system TS/ ≃can be com-
puted with the same complexity.

Stutter Linear-Time Relations
529
7.7
Stutter Linear-Time Relations
The equivalence and preorder relations considered so far require that each outgoing tran-
sition of state s is mimicked by an outgoing transition of the related state s′. We now
consider variants of trace equivalence and bisimulation that relax this requirement. Rather
than considering all transitions as “visible”, it is allowed to mimic an outgoing transition
s by a sequence of transitions starting from s′. Such sequences of transitions need to be
“invisible”, that is to say, all state changes (except the last state change) in such sequences
should not change the truth value of the atomic propositions that hold in s′. Such state
changes are called stutter steps. Equivalences and preorders that abstract from these stut-
ter steps, also referred to as internal or nonobservable steps, are called weak. In contrast,
trace equivalence, ∼, ⪯, and ≃are strong implementation relations as these relations
consider stutter steps as any other transition.
Weak implementation relations are im-
portant for system synthesis as well as system analysis. To compare transition systems
that model a given system at diﬀerent abstraction levels, it is often too demanding to
require a statewise equivalence. Instead, an action in a transition system at a high level
of abstraction can be modeled by a sequence of actions in the more concrete transition
system. Establishing, e.g., trace equivalence is then simply impossible. This is illustrated
by the following example.
Example 7.84.
Abstraction of Internal Moves
Consider the abstract program fragment x := y!, and let TSabs be its underlying transition
system. Let TSconc model the concrete program fragment
i := y; z := 1;
while i > 1 do
z := z ∗i; i := i −1;
od
x := z;
that computes the factorial of y iteratively.
Clearly, TSabs and TSconc are not trace-
equivalent. They, however, are related after abstracting from the iteration (and initial
assignments) in the concrete program under the assumption that the iteration (plus initial
assignments) does not aﬀect the truth value of atomic propositions. This is guaranteed
when restricting to atomic propositions that only refer to the values of x and y, and, e.g.,
not to the individual program locations.
Secondly, by abstracting from internal steps, quotient transition systems are obtained that
may be signiﬁcantly smaller than the quotient under the corresponding strong implemen-
tation relation. This is due to the fact that quotienting with respect to a weak relation

530
Equivalences and Abstraction
allows for abstracting from sequences of transitions such that all states on such paths can
be aggregated. Interestingly, though, still a rather rich set of properties is preserved under
such abstractions.
This section is concerned with a weak version of trace inclusion and trace equivalence.
Section 7.8 (from page 536 onward) deals with weak versions of bisimulation.
7.7.1
Stutter Trace Equivalence
Internal steps are transitions that do not aﬀect the state labels of successive states. Thus,
intuitively, an internal step operates on program or control variables that are either not
visible from the outside or viewed to be irrelevant at a certain abstraction level. Such
transitions are called stutter steps.
Deﬁnition 7.85.
Stutter Step
Transition s →s′ in transition system TS = (S, Act, →, I, AP, L) is a stutter step if
L(s) = L(s′).
The notion of stuttering is lifted to paths as follows.
Two paths are called stutter-
equivalent if their traces only diﬀer in their stutter steps, i.e., if there is a sequence
A0A1A2 . . . of sets of atomic propositions Ai ⊆AP such that the traces of both paths
have the form A+
0 A+
1 A+
2 . . ..
Deﬁnition 7.86.
Stutter-Equivalence of Paths
Let TSi = (Si, Acti, →i, Ii, AP, Li) be transition systems without terminal states and
πi ∈Paths(TSi), i = 1, 2. π1 and π2 are stutter-equivalent, denoted π1 ≜π2, if there
exists an inﬁnite sequence A0A1A2 . . . with Ai ⊆AP and natural numbers n0, n1, n2, . . .,
m0, m1, m2, . . . ⩾1 such that
trace(π1)
=
A0 . . . A0



n0-times
A1 . . . A1



n1-times
A2 . . . A2



n2-times
. . .
trace(π2)
=
A0 . . . A0



m0-times
A1 . . . A1



m1-times
A2 . . . A2



m2-times
. . .
Finite path fragments π1 in TS1 and π2 in TS2 are stutter equivalent, denoted π1 ≜π2,
if there exists a ﬁnite sequence A0 . . . An ∈(2AP)+ such that trace(π1) and trace(π2) are
contained in the language given by the regular expression A+
0 A+
1 . . . A+
n .

Stutter Linear-Time Relations
531
Note that it is not required that A0, A1, A2, . . . are distinct. The notion of stutter equiv-
alence can be applied to (ﬁnite or inﬁnite) path fragments of transition system TS by
setting TS1 = TS2 = TS.
Example 7.87.
Stutter-Equivalent Paths
Consider the transition system TSSem depicted in Figure 7.29 and let AP = { crit1, crit2 }.
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
Figure 7.29: Transition system of semaphore-based mutual exclusion algorithm.
All inﬁnite paths in TSSem that agree on the ﬁrst process acquiring access to the critical
section, and in which the two processes acquire access in a strictly alternating fashion, are
stutter-equivalent. For the case that process P1 is the ﬁrst to enter the critical section, all
such paths have a trace of the form
∅. . . ∅{ crit1 } . . . { crit1 }



P1 in cs
∅. . . ∅{ crit2 } . . . { crit2 }



P2 in cs
∅. . . ∅{ crit1 } . . . { crit1 }



P1 in cs
. . .
Consider, for instance, the following two inﬁnite paths in TSSem:
π1
=
⟨n1, n2⟩→⟨w1, n2⟩→⟨w1, w2⟩→⟨c1, w2⟩→⟨n1, w2⟩→
⟨n1, c2⟩→⟨n1, n2⟩→⟨w1, n2⟩→⟨w1, w2⟩→⟨c1, w2⟩→. . .
π2
=
⟨n1, n2⟩→⟨w1, n2⟩→⟨c1, n2⟩→⟨c1, w2⟩→⟨n1, w2⟩→
⟨w1, w2⟩→⟨w1, c2⟩→⟨w1, n2⟩→⟨c1, n2⟩→. . .
where for the sake of simplicity, we omitted the value of variable y in each state. Hence,

532
Equivalences and Abstraction
π1 ≜π2, since for AP = { crit1, crit2 }
trace(π1)
=
∅3 { crit1 } ∅{ crit2 } ∅3 { crit1 } . . .
and
trace(π2)
=
∅2 ({ crit1 })2 ∅2 { crit2 } ∅{ crit1 } . . .
Figure 7.30 indicates trace(π1) and trace(π2) and their stutter equivalence.
n1 n2 w1 n2 w1 w2 c1 w2 n1 w2 n1 c2 n1 n2 w1 n2 w1 w2
n1 n2 w1 n2 c1 n2 c1 w2 n1 w2 w1 w2 w1 c2 w1 n2 c1 n2
/0
/0
/0
/0
/0
/0
/0
c1
c2
/0
/0
/0
/0
/0
c1
c2
c1
c1
Figure 7.30: Stutter-equivalent paths in TSSem.
Notation 7.88.
Stutter Equivalence for Executions and Traces
The notion of stutter equivalence can be adapted to execution fragments and words over
2AP in the obvious way. Two execution fragments ρ1 and ρ2 of TS1 and TS2 are stutter-
equivalent, denoted ρ1 ≜ρ2, if the induced path fragments are stutter-equivalent. Accord-
ingly, traces σ1 and σ2 over 2AP are stutter-equivalent, denoted σ1 ≜σ2, if they are both
of the form A+
0 A+
1 A+
2 . . . for A0, A1, A2, . . . ⊆AP.
Transition systems TS1 and TS2 are stutter-equivalent whenever each trace of TS1 can be
mimicked by a stutter equivalent trace in TS2, and vice versa.
Deﬁnition 7.89.
Stutter Equivalence of Transition Systems
Transition systems TSi over AP, i=1, 2, are stutter trace equivalent, denoted TS1 ≜TS2,
if TS1 ⊴TS2 and TS2 ⊴TS1, where ⊴is deﬁned by:
TS1 ⊴TS2
iﬀ
∀σ1 ∈Traces(TS1)

∃σ2 ∈Traces(TS2). σ1 ≜σ2

.
Evidently, it follows that Traces(TS1) ⊆Traces(TS)2 implies TS1 ⊴TS2.

Stutter Linear-Time Relations
533
Example 7.90.
Stutter Trace Inclusion
Consider the transition systems TS1 (left), TS2 (middle) and TS3 (right) in Figure 7.31.
It follows:
Traces(TS1)
=
{ (a∅)ω, (a∅)∗aω }
Traces(TS2)
=
{ (a+∅)ω, (a+∅)∗aω }
Traces(TS3)
=
{ aω, a+ (∅a)ω }.
We have TS1 ⊴TS2 since Traces(TS1) ⊆Traces(TS2), and TS2 ⊴TS1 as trace (a+∅)ω
is stutter-equivalent to (a∅)ω and trace (a+∅)∗aω is stutter-equivalent to (a∅)∗aω. Ac-
cordingly,
TS1 ≜TS2.
Note that Traces(TS2) ̸⊆Traces(TS1), as e.g., a2∅. . . ∈Traces(TS2) but is not a trace of
TS1. It follows that
TS1 ̸ ⊴TS3 and TS2 ̸ ⊴TS3,
as TS1 and TS2 have traces of the form (a+ ∅)+aω whereas there is no trace in TS3 that
contains ∅and ends with aω. Since Traces(TS3) ⊆Traces(TS2), it follows TS3 ⊴TS2.
TS3 ⊴TS1 since aω is a trace of both transition systems, and a+ (∅a)ω of TS3 is stutter-
equivalent to (a∅)ω.
s1
{ a }
s0
{ a }
s2
∅
t0
{ a }
t1
∅
u0
{ a }
u1
∅
u2
{ a }
Figure 7.31: Three transition systems.

534
Equivalences and Abstraction
7.7.2
Stutter Trace and LTL\⃝Equivalence
In analogy to the result stating that trace equivalence is ﬁner than LTL equivalence, we now
consider the fragment of LTL that is preserved by stutter trace equivalence. To that end,
we ﬁrst determine the properties that are preserved by stutter-equivalent paths and words
over 2AP, respectively. Let us discuss why a restriction to logics without the next operator
is necessary. Consider, e.g., the traces σ1 = A B B B . . . and σ2 = A A A B B B B . . . with
A, B ⊆AP and A ̸= B. Clearly,
σ1 ≜σ2
but
σ1 |= ⃝b
and
σ2 ̸|= ⃝b for b ∈B \ A.
Stated in words: stutter equivalence does not preserve the truth value of formulae with
the next operator. In fact, it turns out that this is the only modal operator that is not
preserved.
Notation 7.91.
LTL without Next Step
LTL\⃝denotes the class of LTL formulae without the next step operator ⃝.
Theorem 7.92.
Stutter Equivalence and LTL\⃝Equivalence
For σ1, σ2 ∈(2AP)ω:
σ1 ≜σ2 ⇒(σ1 |= ϕ if and only if σ2 |= ϕ)
for any LTL\⃝formula ϕ over AP.
Proof: The proof is by structural induction over the formula ϕ. Let A0A1A2 . . . be an
inﬁnite word over 2AP and
σ1 = An0
0 An1
1 An2
2 . . .
and
σ2 = Am0
0
Am1
1
Am2
2
. . .
where n0, n1, n2, . . . and m0, m1, m2, . . . are positive natural numbers. Hence: σ1 ≜σ2.
Basis: For ϕ = true the proposition is clear. For ϕ = a ∈AP, we have
σ1 |= a
iﬀ
a ∈A0
iﬀ
σ2 |= a.
Induction step: For ϕ = ϕ1 ∧ϕ2 or ϕ = ¬ϕ′, the claim follows immediately from the
induction hypothesis applied to ϕ1 and ϕ2 or ϕ′, respectively.
The remaining case is
ϕ = ϕ1 U ϕ2. Assume σ1 |= ϕ. From the semantics of LTL\⃝, it follows that there exists
a natural number j such that

Stutter Linear-Time Relations
535
σ1[j..] |= ϕ2
and
σ1[i..] |= ϕ1 for all 0 ⩽i < j.
Recall that for σ = B0 B1 B2 . . . and h ⩾0, the suﬃx BhBh+1 . . . of σ is denoted by σ[h..].
Let r ⩾0 be such that
n0 + . . . + nr−1 < j ⩽n0 + . . . + nr−1 + nr.
Stated in words, r is the index of the A-block in σ1 that contains σ1[j]. Then, σ1[j..] is
obtained from σ1 by eliminating the preﬁx An0
0 . . . Anr−1
r−1 An
r where n = n0 + . . . + nr−1 +
nr −j. Note that 0 ⩽n < nr. Thus, σ1[j..] is of the form A+
r A+
r+1A+
r+2 . . .. Since σ1 ≜σ2,
it follows that for:
k = m0 + . . . + mr−1 + 1,
σ2[k..] is of the form A+
r A+
r+1A+
r+2 . . .. More precisely, we have
1. σ1[j..] ≜σ2[k..] since both words are of the form A+
r A+
r+1A+
r+2 . . ., and
2. for all 0 ⩽h < k, there is an index 0 ⩽i < j such that σ1[i..] ≜σ2[h..].
As σ1[j..] |= ϕ2 and σ1[i..] |= ϕ1, for all i < j, applying the induction hypothesis yields
σ2[k..] |= ϕ2 and σ2[h..] |= ϕ1, for h < k. Hence, σ2 |= ϕ1 U ϕ2.
By symmetry, we get the equivalence of σ1 and σ2 for LTL\⃝.
Corollary 7.93.
Stutter Trace Relations and LTL\⃝
For transition systems TS1, TS2 (over AP) without terminal states:
(a) TS1 ≜TS2 implies TS1 ≡LTL\⃝TS2.
(b) if TS1 ⊴TS2, then for any LTL\⃝formula ϕ: TS2 |= ϕ implies TS1 |= ϕ.
A slightly more general preservation result can be established for stutter trace equivalence
and inclusion.
Deﬁnition 7.94.
Stutter-Insensitive LT property
LT property P is stutter-insensitive if [σ] ≜⊆P, for any σ ∈P.

536
Equivalences and Abstraction
Stated in words, P is stutter-insensitive if it is closed under stutter equivalence, i.e., for
any σ ∈P all stutter-equivalent words are also contained in P. It follows immediately
that stutter trace equivalent transition systems satisfy the same stutter-insensitive LT
properties. Moreover, for any stutter-insensitive LT property P:
TS1 ⊴TS2 and TS2 |= P
implies
TS1 |= P.
This is, in fact, a more general statement than Corollary 7.93 since for any LTL\⃝formula
ϕ the induced LT property Words(ϕ) is stutter-insensitive.
On the other hand, there
exist stutter-insensitive LT properties that cannot be expressed in LTL\⃝. For instance,
consider the set P of words over { a, b } that contain an odd number of occurrences of
the subword a b. The LT property that is stutter-insensitive and contains P, cannot be
expressed in LTL\⃝.
However, if ϕ is an LTL formula such that Words(ϕ) is stutter
insensitive, then ϕ is equivalent to some LTL\⃝formula ψ; see Exercise 7.20.
7.8
Stutter Bisimulation
This section is concerned with stutter bisimulation. Stutter bisimulation is deﬁned in a
coinductive manner, as bisimulation. Whereas bisimulation requires for equivalent states
s1 and s2 that each transition s1 →t1 (with s1 inequivalent to t1) is matched by some
transition s2 →t2, stutter bisimulation allows s1 →t1 to be matched by a path fragment
s2 u1 u2 . . . un t2 (for n ⩾0) such that t1 and t2 are equivalent, and ui is equivalent to s2.
That is, single transitions may be matched by (suitable) path fragments.
The following deﬁnition considers the notion of a stutter bisimulation for a single transition
system. Later on, this notion will be adapted for pairs of transition systems.
Deﬁnition 7.95.
Stutter Bisimulation
Let TS = (S, Act, →, I, AP, L) be a transition system. A stutter bisimulation for TS is
a binary relation R on S such that for all (s1, s2) ∈R:
1. L(s1) = L(s2).
2. If s′
1 ∈Post(s1) with (s′
1, s2) ̸∈R, then there exists a ﬁnite path fragment s2 u1 . . . un s′
2
with n ⩾0 and (s1, ui) ∈R, i = 1, . . . , n and (s′
1, s′
2) ∈R.
3. If s′
2 ∈Post(s2) with (s1, s′
2) ̸∈R, then there exists a ﬁnite path fragment s1 v1 . . . vn s′
1
with n ⩾0 and (vi, s2) ∈R, i = 1, . . . , n and (s′
1, s′
2) ∈R.

Stutter Bisimulation
537
s1, s2 are stutter bisimulation equivalent (stutter-bisimilar, for short), denoted s1 ≈TS s2,
if there exists a stutter bisimulation R for TS with (s1, s2) ∈R.
Condition (1) is standard, and requires equivalent states to be equally labeled. According
to condition (2), every outgoing transition s1 →t1 (where s1 is not equivalent to t1) must
be matched by a path fragment that leads from s2 to t2 such that t1 and t2 are equivalent,
and all intermediate states in the path fragment are equivalent to s2. Roughly speaking,
if s1 changes its equivalence class and moves to t1, this must be mimicked by s2, but only
after some transitions that are internal to the equivalence class of s2. Condition (3) is the
symmetric counterpart of condition (2).
Lemma 7.96.
Coarsest Stutter Bisimulation
For transition system TS with state space S:
1. ≈TS is an equivalence relation on S.
2. ≈TS is a stutter bisimulation for TS.
3. ≈TS is the coarsest stutter bisimulation for TS and coincides with the union of all
stutter bisimulations for TS.
Proof: Similar to the case for bisimulation; see Exercise 7.26.
(Note that ≈TS is an equivalence, but this does not hold for any stutter bisimulation
relation.)
Since ≈TS is a stutter bisimulation, condition (2) of Deﬁnition 7.95 can be
rephrased by means of ≈TS, as illustrated in Figure 7.32.
Example 7.97.
Stutter Bisimulation in Semaphore-Based Mutual Exclusion
Consider the semaphore-based solution to the mutual exclusion problem; see the transition
system TSSem in Figure 5.5 (page 239). Let AP = { crit1, crit2 }. Relation R that induces
the following partitioning of the state space is a stutter bisimulation:
{ { ⟨n1, n2⟩, ⟨n1, w2⟩, ⟨w1, n2⟩, ⟨w1, w2⟩}, { ⟨c1, n2⟩, ⟨c1, w2⟩}, { ⟨c2, n1⟩, ⟨w1, c2⟩} } .
This can be checked by verifying the conditions in Deﬁnition 7.95. For instance, ⟨n1, n2⟩≈TS
⟨w1, w2⟩, since ⟨w1, w2⟩→⟨w1, c2⟩can be mimicked by the path fragment ⟨n1, n2⟩→
⟨n1, w2⟩→⟨n1, c2⟩, and ⟨w1, w2⟩→⟨c1, w2⟩is matched by path fragment ⟨n1, n2⟩→
⟨w1, n2⟩→⟨c1, n2⟩. As ⟨n1, n2⟩does not have any direct successor that is inequivalent to

538
Equivalences and Abstraction
s1
≈TS
s2
↓
s1
≈TS
u1
↓
s1
≈TS
s2
s1
≈TS
u2
↓
can be completed to
↓
s′
1
...
(with s1 ̸≈TS s′
1)
↓
s1
≈TS
un
↓
↓
s′
1
≈TS
s′
2
Figure 7.32: Condition (2) for stutter bisimulation equivalence.
it, no requirements are imposed on ⟨w1, w2⟩. In a similar way, the stutter-bisimilarity of
other pairs of states can be checked.
Example 7.98.
Stutter Bisimulation in Peterson’s Mutual Exclusion Algorithm
Consider the transition system TSPet for Peterson’s mutual exclusion algorithm (see Figure
7.33 on page 539) and let AP = { crit1, crit2 }. The initial states
s0,1 = ⟨n1, n2, x=1⟩
and
s0,2 = ⟨n1, n2, x=2⟩
are stutter-bisimilar. All other states represent separate stutter bisimulation equivalence
classes. Essentially, this is due to the fact that
⟨c1, n2, x=2⟩



s1
̸≈TS
⟨c1, w2, x=1⟩



s2
.
This follows from the fact that s1 can move to one of the initial states, whereas s2 cannot
mimic this by a series of stutter steps. In state s1, it is possible that process 1 reenters the
critical section next, whereas in state s2, process 2 is always granted access to the critical
section next. For the other states, a similar reasoning applies.
Stutter bisimulation for pairs of transition systems is deﬁned as follows.
Deﬁnition 7.99.
Stutter-Bisimilar Transition Systems
Let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, 2, be transition systems over AP. TS1 and

Stutter Bisimulation
539
⟨n1, n2, x = 2⟩
⟨w1, n2, x = 2⟩
⟨w1, w2, x = 1⟩
⟨c1, w2, x = 1⟩
⟨n1, n2, x = 1⟩
⟨n1, w2, x = 1⟩
⟨w1, w2, x = 2⟩
⟨w1, c2, x = 2⟩
⟨c1, n2, x = 2⟩
⟨n1, c2, x = 1⟩
Figure 7.33: Transition system for Peterson’s mutual exclusion algorithm.
TS2 are stutter bisimulation equivalent (stutter-bisimilar, for short), denoted TS1 ≈TS2,
if there exists a stutter bisimulation R on (S1 × S2) ∪(S1 × S2) such that
∀s1 ∈I1. (∃s2 ∈I2. (s1, s2) ∈R) and ∀s2 ∈I2. (∃s1 ∈I1. (s1, s2) ∈R).
The connection between Deﬁnitions 7.95 and 7.99 is as for ordinary bisimulation. We have
TS1 ≈TS2 if and only if for every initial state of TS1 there exists a stutter-bisimilar initial
state of TS2, and vice versa, where stutter bisimulation equivalence of states s1 in TS1 and
s2 in TS2 thereby refers to the stutter bisimulation equivalence ≈TS1⊕TS2. Recall that the
operation ⊕on transition systems amounts to the union of transition systems, see page
457). Vice versa, stutter bisimulation equivalence ≈TS of a single transition system can be
obtained from Deﬁnition 7.99 by the observation that s1 ≈TS s2 if and only if TSs1 ≈TSs2,
where TSs is obtained from TS by declaring s as the unique initial state.
Figure 7.34 surveys the stutter implementation relations in this monograph. Stutter bisim-
ulation equivalence with divergence is a variant of stutter bisimulation and will be intro-
duced in Section 7.8.1 (page 543 and further).
Example 7.100.
Door Opener
Consider an automatic door opener as modeled by the (concrete) transition system in
Figure 7.35; for simplicity, the action labels are omitted from the transitions. Let AP =
{ alarm, open }. The door opener requires a three-digit code d1 d2 d3 as input with di ∈

540
Equivalences and Abstraction
stutter trace inclusion:
TS1 ⊴TS2
iﬀ
∀σ1 ∈Traces(TS1) ∃σ2 ∈Traces(TS2). σ1 ≜σ2
stutter trace equivalence:
TS1
≜
TS2
iﬀ
TS1 ⊴TS2 and TS2 ⊴TS1
stutter bisimulation equivalence:
TS1 ≈TS2
iﬀ
there exists a stutter bisimulation for (TS1, TS2)
stutter bisimulation equivalence with divergence:
TS1 ≈div TS2
iﬀ
there exists a divergence-sensitive
stutter bisimulation for (TS1, TS2)
Figure 7.34: Stutter implementation relations.
{ 0, . . . , 9 }. It allows an erroneous digit to be entered, but this may happen at most twice.
Location ℓi (for i = 0, 1, 2) indicates that the ﬁrst i digits of the code have been correctly
entered.
⟨ℓ0, 0⟩
⟨ℓ1, 0⟩
⟨ℓ2, 0⟩
⟨ℓ0, 1⟩
⟨ℓ1, 1⟩
⟨ℓ2, 1⟩
⟨ℓ0, 2⟩
⟨ℓ1, 2⟩
⟨ℓ2, 2⟩
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.35: Transition system of the door opener
The transition system in Figure 7.36 is stutter-bisimilar to the transition system in Figure
7.35.
The quotient transition system under stutter bisimulation ≈TS is deﬁned as the quotient
under bisimulation.
As a stutter bisimulation is not guaranteed to be transitive, the

Stutter Bisimulation
541
ℓ0
ℓ3
{ open }
ℓ4
{ alarm }
Figure 7.36: Stutter-bisimilar transition system for the door opener.
quotient under the equivalence ≈TS is considered. Note that, of course, states are now
equivalence classes under ≈TS If s →s′ and s ̸≈s′, there is a transition from [s]≈to [s′]≈.
As a result, TS/≈contains no self-loops.
Deﬁnition 7.101.
Stutter Bisimulation Quotient System
For transition system TS = (S, Act, →, I, AP, L), the stutter bisimulation quotient transi-
tion system TS/≈is deﬁned as follows:
TS/≈= (S/≈TS, { τ }, →≈, I≈, AP, L≈)
where
• I≈= { [s]≈| s ∈I },
• →≈is deﬁned by s
α
−−→s′ ∧s ̸≈s′
[s]≈
τ
−→≈[s′]≈
,
• L≈([s]≈) = L(s).
Theorem 7.102.
Stutter Bisimulation Equivalence of TS and TS/≈
For any transition system TS, we have TS ≈TS/≈.
Proof: Follows from the fact that R = { (s, s′) | s′ ∈[s]≈, s ∈S } is a stutter bisimulation
for (TS, TS/≈).

542
Equivalences and Abstraction
Example 7.103.
Semaphore-Based Mutual Exclusion
Consider again the transition system TSSem for the semaphore-based solution to the mu-
tual exclusion problem (see Figure 5.5 on page 239). Let AP = { crit1, crit2 }. Recall that
R inducing the following partitioning of the state space is a stutter bisimulation:
{ { ⟨n1, n2⟩, ⟨n1, w2⟩, ⟨w1, n2⟩, ⟨w1, w2⟩}, { ⟨c1, n2⟩, ⟨c1, w2⟩}, { ⟨c2, n1⟩, ⟨w1, c2⟩} } .
In fact, this is the coarsest stutter bisimulation, i.e., R equals ≈TS. It is not diﬃcult to
see that the quotient under bisimulation, i.e., TSSem/ ∼does not yield any state space
reduction. The quotient transition system under ≈, i.e., TSSem/≈, is depicted in Figure
7.37 and does yield a substantial reduction of the state space.
s0
∅
s1
{ crit1 }
s2
{ crit2 }
Figure 7.37: The stutter bisimulation quotient system of TSSem.
Let us now discuss the relationship between stutter trace equivalence and stutter bisim-
ulation. Obviously, for transition systems that do not have any stutter steps, ∼and ≈
coincide. The same applies to trace equivalence and stutter trace equivalence ( ≜). There-
fore, in general, stutter trace equivalent transition systems are not stutter-bisimilar. As
an example, consider trace equivalent transition systems without stutter steps, which are
not bisimilar. As we have seen, TS1 ∼TS2 implies that TS1 and TS2 are trace equivalent,
see Theorem 7.6 (page 456). Based on this fact, one is tempted to assume that stutter
bisimulation is ﬁner than stutter trace equivalence. This is, however, not true, as stutter
bisimulation does not impose any restrictions on paths that just consist of stutter steps.
Only paths that “switch” equivalence class have to be matched, but pure stutter paths
not—condition (2) of Deﬁnition 7.95 (page 536) only requires that, if s1 and s2 are stutter-
bisimilar, then every transition s1 →s′
1 with s1 ̸≈s′
1 can be simulated by a path fragment
s2 →. . . →s′
2. For stutter steps s1 →s′
1, within the stutter bisimulation equivalence class
of s1 (i.e., s1 ≈s′
1), no conditions are imposed. That is, it is possible that
s1 ≈s2
while
∃π1 ∈Paths(s1). ∀π2 ∈Paths(s2). π1 ̸≜π2.

Stutter Bisimulation
543
Theorem 7.104.
Stutter Trace vs. Stutter Bisimulation Equivalence
≜and ≈are incomparable.
∅
{ a }
{ a }
{ b }
{ c }
∅
{ a }
{ b }
{ c }
≜
̸≈
∅
{ a }
∅
{ a }
̸≜
≈
TS1
TS2
TS3
TS4
Figure 7.38: Stutter trace vs. stutter bisimulation equivalence.
Proof: see Figure 7.38. For the two leftmost transition systems TS1 and TS2, we have
TS1 ≜TS2, but TS1 ̸≈TS2.
(In fact, we have Traces(TS1) = Traces(TS2) and TS1 ̸∼TS2.) For the two rightmost
transition systems, we have TS3 ≈TS4, while TS3 ̸≜TS4. The fact that the transition
systems are not stutter trace equivalent follows from the fact that TS3 exhibits the trace
∅ω, whereas TS4 cannot generate this trace. Note that the trace ∅ω just consists of stutter
steps.
As a consequence, stutter bisimulation does not preserve the truth value of all LTL\⃝
formulae. This is illustrated by the following example.
Example 7.105.
Stutter Bisimulation Equivalence vs. LTL\⃝Equivalence
Consider the transition systems TS1 (left) and TS2 (right) in Figure 7.39. Then TS1 ≈TS2
and TS2 |= ♦a. However, TS1 ̸|= ♦a since the path sω
0 violates ♦a. This is due to the fact
that the path sω
0 just consists of stutter steps, and by deﬁnition of ≈is not required to
have a stutter-equivalent path starting in t0.
7.8.1
Divergence-Sensitive Stutter Bisimulation
The fact that stutter trace equivalence ( ≜) and stutter bisimulation (≈) are incomparable
is caused by stutter paths, i.e., paths that only consists of stutter steps. The existence of

544
Equivalences and Abstraction
t0
∅
t1
{ a }
s0
∅
s1
{ a }
Figure 7.39: Stutter bisimulation, but not LTL\⃝equivalent systems.
these paths is also the reason that ≈does not imply LTL\⃝equivalence. Stutter paths
stay forever in an equivalence class without performing any visible step. This behavior is
called divergent.
The topic of this section is to adapt stutter bisimulation such that states may only be
related if they both exhibit divergent paths or none of them has a divergent path. This
yields a variant of stutter bisimulation that will be shown to coincide with CTL∗
\⃝equiv-
alence, i.e., equivalence with respect to CTL∗formulae that do not contain the next-step
operator. (Note that CTL∗
\⃝includes LTL\⃝.) This divergence-sensitive variant of stutter
bisimulation is the coarsest equivalence that preserves all CTL∗
\⃝formulae. Besides, in
contrast to ≈, this variant is strictly ﬁner that stutter trace equivalence.
Deﬁnition 7.106.
R-Divergent State, Divergence Sensitivity
Let TS be a transition system and R an equivalence relation on S.
• s ∈S is R-divergent if there exists an inﬁnite path fragment π = s s1 s2 . . . ∈
Paths(s) such that (s, sj) ∈R for all j > 0.
• R is divergence-sensitive if for any (s1, s2) ∈R: if s1 is R-divergent, then s2 is
R-divergent.
Stated in words, a state is R-divergent if there is an inﬁnite path starting in s that only
visits states in [s]R. As R is an equivalence, for (s1, s2) ∈R we have s1 is R-divergent
if and only if s2 is R-divergent. Equivalence R is thus divergence-sensitive if in any R
equivalence class, either all states are R-divergent or none is R-divergent.
Example 7.107.
Divergence Sensitivity
For the transition system in Figure 7.40, we have s0 ≈TS s1 ≈TS s2. States s0 and s1 are

Stutter Bisimulation
545
≈TS-divergent as in both states it is possible to inﬁnitely often alternate between s0 and
s1, i.e., stay forever in [s0]≈. As state s2 is not ≈TS-divergent, it follows that ≈TS is not
divergence-sensitive. Equivalence R = { (s0, s1), (s1, s0) } ∪Id is divergence-sensitive.
s3
∅
s2
{ a }
s0
{ a }
s1
{ a }
Figure 7.40: s0 and s1 are ≈TS-divergent, but s2 is not.
Example 7.108.
Alternating Bit Protocol
Consider the alternating bit protocol as introduced in Chapter 2; see Example 2.32 on
page 57. Recall that messages from the sender to the receiver are equipped with a bit
that toggles between transmissions of new messages and stays constant on retransmissions.
Accordingly, the sender can be either in a “0-mode” to transmit a message with bit 0, or
in the “1-mode”. Similarly, the receiver can be either expecting a message with bit 0 or
with bit 1. Let
AP = { s mode = 0, s mode = 1, r mode = 0, r mode = 1 }
where s mode indicates the mode of the sender, and r mode that of the receiver. The
state space of the underlying TSABP of the alternating bit protocol consists of hundreds of
states for a channel capacity of one (for both channels). The stutter bisimulation quotient
just consists of four states; see Figure 7.41 where the state labeling (i, j) is a shorthand
for s mode = i and r mode = j, i, j ∈{ 0, 1 }.
By deﬁnition, no state in TSABP/ ≈
{ (0, 0) }
{ (0, 1) }
{ (1, 0) }
{ (1, 1) }
Figure 7.41: Stutter bisimulation quotient of the alternating bit protocol.
is ≈-divergent.
However, TSABP contains (various) states that are ≈-divergent, as in
these states it is possible to continuously lose a message. For instance, in states in the
equivalence class { (0, 0) } it is possible that the transmitted message with bit 0 as sent by
the sender is lost inﬁnitely often. Thus:
TSABP ̸|= ∀□♦(s mode = 0)
∧
∀□♦(s mode = 1),

546
Equivalences and Abstraction
but
TSABP/≈|= ∀□♦(s mode = 0)
∧
∀□♦(s mode = 1).
This conﬁrms our earlier observation that ≈does not guarantee the preservation of LTL\⃝
formulae.
Deﬁnition 7.109.
Stutter Bisimulation with Divergence
States s1, s2 in transition system TS are divergent stutter bisimilar, denoted s1 ≈div
TS
s2, if
there exists a divergence-sensitive stutter bisimulation R on TS such that (s1, s2) ∈R.
It is not diﬃcult to show that ≈div
TS is an equivalence on S, and the coarsest divergence-
sensitive stutter bisimulation for TS which is obtained by the union of all divergence-
sensitive stutter bisimulations for TS.
Example 7.110.
Stutter Bisimulation with Divergence
Consider the transition system TS in Figure 7.40 (page 545). Its equivalence classes under
≈div
TS are { s0, s1 }, { s2 } and { s3 }. State s2 is ≈div
TS -divergent whereas s0 and s1 are not.
Thus, s2 ̸≈div
TS s0 and s2 ̸≈div
TS s1.
As a second example, consider the transition system in Figure 7.42 where the state labeling
is indicated by the grey scale. s1 ̸≈div
TS s2 as u3 and u1, u2 are not equivalent under ≈div
TS
(since only u3 is divergent) and only s2 (but not s1) has a transition to u3.
s1
{ a }
{ b } u1
u2
{ b }
v1
∅
∅
v2
s2
{ a }
u3
{ b }
v3
∅
Figure 7.42: s1 ̸≈div
TS s2.
TS1 ≈div
TS2 if and only if each initial state of TS1 is divergence stutter bisimilar
(according to ≈div
TS1⊕TS2) to an initial state in TS2, and vice versa. The quotient transition

Stutter Bisimulation
547
system with respect to stutter bisimulation ≈div
TS
is deﬁned as usual with equivalence
classes under ≈div
TS as states. In addition to the usual transitions, every equivalence class
C consisting of divergent states is equipped with a self-loop. This self-loop indicates the
divergence. (Recall that TS/R for stutter bisimulation R does not contain any self-loop.)
That is, the transition relation of TS/≈div is deﬁned by
s
α
−−→s′ ∧s ̸≈div s′
[s]div
τ
−→div [s′]div
and
s is ≈div-divergent
[s]div
τ
−→div [s]div
where [s]div denotes the equivalence class of s under ≈div.
s3
∅
s2
{ a }
s0
{ a }
s1
{ a }
transition system TS
[s3]≈
∅
[s0]≈
{ a }
transition system TS/≈
[s3]div
∅
[s2]div
{ a }
[s0]div
{ a }
transition system TS/≈div
Figure 7.43: Transition system TS, TS/≈, and TS/≈div.
Example 7.111.
Quotient Transition System under ≈and ≈div
Consider the transition system TS in Figure 7.43 (upper part). Its quotient under stutter
bisimulation, TS/≈, is depicted in the left lower part of the ﬁgure. States s0, s1, and s2
are all stutter-bisimilar. Note that, by deﬁnition, no self-loops occur in TS/ ≈; only the
transitions that change equivalence class are of importance. TS/ ≈div is depicted in the
right lowerpart of Figure 7.43. State s2 is not equivalent to s0 and s1 as it is not divergent,
whereas s0 and s1 are divergent.
Theorem 7.112.
TS and TS/≈div are Divergence Stutter Bisimilar
For any transition system TS, we have TS ≈div TS/≈div.
Proof: Follows from the fact that R = {(s, [s]div) | s ∈S} is a divergence-sensitive stutter
bisimulation for

TS, TS/≈div
.

548
Equivalences and Abstraction
Since divergence-sensitive stutter bisimulations are special cases of arbitrary stutter bisim-
ulations, stutter bisimulation with divergence ≈div is strictly ﬁner than stutter bisimulation
≈. In the example of Figure 7.40 on page 545, s0 ≈TS s2 but s0 ̸≈div
TS s2.
Lemma 7.113.
≈div is Strictly Finer Than ≈
For transition systems TS1 and TS2:
TS1 ≈div TS2



stutter bisimulation equivalence
with divergence
implies
TS1 ≈TS2



stutter bisimulation equivalence
(without divergence)
while the reverse does not hold in general.
Remark 7.114.
Terminal and Purely Divergent States
State s is purely divergent if all paths starting in s are inﬁnite and completely consist of
stutter steps. Since ≈imposes no restrictions on transitions inside equivalence classes, any
purely divergent state is stutter-bisimilar to any equally labeled state which is terminal.
However, ≈div distinguishes terminal states and purely divergent states. Thus,
st ≈TS spd,
while st ̸≈div
TS spd
where st is a terminal state and spd a purely divergent state and L(st) = L(spd).
Both ≈TS and ≈div
TS identify any terminal state st with any state s with L(s) = L(st) and
for which Paths(s) consists of ﬁnite stutter paths only. In other words, all reachable states
from s have the same labeling as s and there is no inﬁnite path starting in s. In fact, there
are no other states that are divergence stutter bisimilar to st. That is, if st is terminal
and st ≈div
TS s, then L(s) = L(st) and each path of s is ﬁnite and only consists of stutter
steps.
Remark 7.115.
Divergence-Sensitive Transition Systems
Transition system TS is called divergence-sensitive if ≈TS on TS is divergence-sensitive.
Clearly, for divergence-sensitive transition systems, ≈TS corresponds to ≈div
TS . For instance,
the transition system shown in Figure 7.40 on page 545 is not divergence-sensitive.
Recall that ≜(stutter trace equivalence) and ≈(stutter bisimulation) are incomparable,
see Theorem 7.104 (page 543). This is due to the fact that ≈ignores divergent paths,
whereas ≜does not. In the sequel, it will be shown that ≈div is strictly ﬁner than ≜. The
proof technique is rather similar to proving that bisimulation is ﬁner than trace equivalence
and is based on a lifting of ≈div to paths.

Stutter Bisimulation
549
Deﬁnition 7.116.
Divergence Stutter-Bisimilar Paths
Let TS be a transition system.
1. For inﬁnite path fragments πi = s0,i s1,i s2,i . . ., i = 1, 2, in TS:
π1 ≈div
TS
π2
if and only if there exists an inﬁnite sequence of indices 0 = j0 < j1 < j2 < . . . and
0 = k0 < k1 < k2 < . . . with:
sj,1 ≈div
TS
sk,2 for all jr−1 ⩽j < jr and kr−1 ⩽k < kr with r = 1, 2, . . ..
2. For ﬁnite paths fragments π1 = s0,i s1,i . . . sKi,i, i = 1, 2, in TS:
π1 ≈div
TS
π2
if and only if there exists a ﬁnite sequence of indices 0 = j0 < j1 < . . . < jℓ= K1 +1
and 0 = k0 < k1 < . . . < kℓ= K2 + 1 with sj,1 ≈div
TS
sk,2 for all jr−1 ⩽j < jr and
kr−1 ⩽k < kr with r = 1, 2, . . . , ℓ.
Paths π1 and π2 are stutter-bisimilar with divergence if both paths can be divided into
segments sjr,1 sjr+1,1 sjr+2,1 . . . sjr+1,1 and skr,2 skr+1,2 skr+2,2 . . . skr+1,2, respectively, that
are statewise bisimilar (under ≈div).
The following lemma follows directly from the deﬁnition of ≈div on paths and ≜on paths;
see Deﬁnition 7.86 on page 530.
Lemma 7.117.
Equivalences ≈div and ≜for Paths
For all inﬁnite paths π1 and π2, we have π1 ≈div
TS
π2 implies π1 ≜TS π2.
Divergence stutter bisimilar states have divergence stutter bisimilar paths:
Lemma 7.118.
Path Lifting for Divergence Stutter Bisimilar States
Let TS = (S, Act, →, I, AP, L) be a transition system, s1, s2 ∈S. Then:
s1 ≈div
TS
s2
implies
∀π1 ∈Paths(s1).

∃π2 ∈Paths(s2). π1 ≈div
TS
π2

.

550
Equivalences and Abstraction
Proof: Let π1 = s0,1 s1,1 s2,1 . . . ∈Paths(s1). The proof technique is to successively deﬁne
a statewise stutter-bisimilar path π2 starting in s2 by “lifting” the transitions si,1 →si+1,1
with si,1 ̸≈div
TS si+1,1 to ﬁnite path fragments si,2 ui,1 . . . ui,ni si+1,2 such that si+1,1 ≈div
TS
si+1,2 and si,2 ≈div
TS ui,1 ≈div
TS . . . ≈div
TS ui,ni.
The proof is by induction on i. The base case i=0 is straightforward and omitted. Assume
i ⩾0 and that the path fragment:
s2 = s0,2 u0,1, . . . , u0,n0 s1,2 u1,1 . . . u1,n1 s2,2 . . . si,2(∗)
is already constructed. In particular, si,1 ≈div
TS si,2. If si,1 is a terminal state, then there
exists a ﬁnite path fragment si,2 v1 . . . vm consisting of stutter steps such that vm is a
terminal (see Remark 7.114 on page 548). Hence, the path π2 resulting by concatenating
the above path fragment (∗) from s2 to si,2 and the path fragment si,2 v1 . . . vm fulﬁlls the
desired conditions. In the sequel, we assume that si,1 is not a terminal state, and, hence,
π1 does not end in state si,1. Distinguish two cases:
1. si,1 ̸≈div
TS
si+1,1.
Since si,1 ≈div
TS
si,2 and si,1 →si+1,1, there exists a ﬁnite path
fragment si,2 ui,1 . . . ui,nisi+1,2 such that:
si+1,1 ≈div
TS
si+1,2
and
si,2 ≈div
TS ui,1 ≈div
TS . . . ≈div
TS ui,ni.
Concatenating the path (∗) with the path fragment si,2 ui,1 . . . ui,nisi+1,2 yields a
path fragment that fulﬁlls the desired conditions.
2. si,1 ≈div
TS si+1,1. Distinguish between si,1 is divergent and not divergent:
(a) si,1 is not divergent, i.e, there exists an index j > i+1 with si,1 ̸≈div
TS
sj,1.
Without loss of generality, assume that j is minimal, i.e., si,1, si+1,1, . . . , sj−1,1
are pairwise equivalent under ≈div. In particular,
si,2 ≈div
TS
sj−1,1
and
sj−1,1 ̸≈div
TS
sj,1.
As si,2
≈div
TS
sj−1,1 and sj−1,1 →sj,1, there exists a ﬁnite path fragment
si,2 ui,1 . . . ui,ni si+1,2 such that
sj,1 ≈div
TS
si+1,2
and
si,2 ≈div
TS ui,1 ≈div
TS . . . ≈div
TS ui,ni.
Concatenation of the path fragment (∗) with si,2 ui,1 . . . ui,ni si+1,2 yields a path
that fulﬁlls the desired conditions.

Stutter Bisimulation
551
TS1 ⊴TS2
bisimulation equivalence
TS1 ∼TS2
stutter bisimulation equivalence
divergence-sensitive
TS1 ≈div TS2
stutter bisimulation equivalence
TS1 ≈TS2
trace equivalence
Traces(T1) = Traces(TS2)
stutter trace equivalence
TS1 ≜TS2
Traces(T1) ⊆Traces(TS2)
trace inclusion
stutter trace inclusion
Figure 7.44: Relation between weak equivalences and preorders on transition systems.
(b) si,1 is divergent, i.e., si,1 ≈div
TS sj,1 for all j ⩾i. As si,1 ≈div
TS si,2, and si,1 is
divergent, si,2 is divergent.
That is, there is a path si,2 si+1,2 si+2,2 . . . with
si,2 ≈div
TS si+1,2 ≈div
TS si+2,2 ≈div
TS . . .. Concatenation of the path fragment (∗)
with si,2 si+1,2 si+2,2 . . . yields a path that fulﬁlls the desired conditions.
The thus resulting path fragment π2 is divergence stutter bisimilar to π1.
The fact that ≈div can be lifted from states to paths enables to establish that ≈div on
transition systems is strictly ﬁner than ≜, i.e., stutter trace-equivalence.
Theorem 7.119.
Stutter Trace vs. Divergence Stutter Bisimulation
Let TS1 and TS2 be transition systems over AP. Then:
TS1 ≈div TS2



stutter bisimulation equivalence
with divergence
implies
TS1 ≜TS2



stutter trace equivalence
,
whereas the reverse implication does not hold in general.
Proof: Assume TS1 ≈div TS2. Consider the transition system TS1 ⊕TS2, and let (s1, s2)
be a pair of initial states of TS1 and TS2 such that s1 ≈div
TS s2. From Lemma 7.118, it
follows that for every π1 ∈Paths(s1), there exists π2 ∈Paths(s2) such that π1 ≈div
TS π2. By
Lemma 7.117, π1 ≜π2. Thus, TS1 ≜TS2. The reverse direction does not apply in general.
Let TS1, TS2 be trace equivalent but not bisimilar, and neither contains any stutter steps.
The absence of stutter steps yields TS1 ≜TS2, but TS1 ̸≈div TS2.

552
Equivalences and Abstraction
The relationship between the various stutter equivalences and stutter trace preorder re-
lations are summarized in Figure 7.44. An arrow from relation R to R′ denotes that R
is strictly ﬁner than R′. Note that for AP-deterministic transition systems, trace equiva-
lence coincides with bisimulation, and stutter trace equivalence coincides with divergence-
sensitive stutter bisimulation. The latter fact is stated without proof, and is left as an
exercise for the reader.
7.8.2
Normed Bisimulation
This section introduces the notion of normed bisimulation. These bisimulations are deﬁned
using so-called norm functions. Normed bisimulation turns out to be strictly ﬁner than
≈div. As norm functions allow establishing a bisimulation by just local reasoning about the
states—only considering their direct successors—means that it is often simpler to establish
a normed bisimulation than a divergence-sensitive stutter bisimulation. We introduce a
norm function which yields a suﬃcient (but not necessary) requirement for ≈div. This will
be used in Chapter 8.
Deﬁnition 7.120.
Normed (Bi)Simulation
Let TS1 = (S1, Act1, −→1, I1, AP, L1) and TS2 = (S2, Act2, −→2, I2, AP, L2) be transition
systems over AP.
A normed simulation for (TS1, TS2) is a triple (R, ν1, ν2) consisting of a binary relation
R ⊆S1 × S2 such that:
∀s1 ∈I1.∃s2 ∈I2.(s1, s2) ∈R
and functions ν1, ν2 : S1 × S2 →IN such that for all (s1, s2) ∈R:
(NI) L1(s1) = L2(s2).
(NII) For all s′
1 ∈Post(s1), at least one of the following three conditions holds:
(N1) There exists s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R.
(N2) (s′
1, s2) ∈R and ν1(s′
1, s2) < ν1(s1, s2).
(N3) There exists s′
2 ∈Post(s2) with (s1, s′
2) ∈R and ν2(s1, s′
2) < ν2(s1, s2).
A normed bisimulation for (TS1, TS2) is a normed simulation (R, ν1, ν2) for (TS1, TS2)
such that (R−1, ν−
2 , ν−
1 ) is a normed simulation for (TS2, TS1).
Here, ν−
i
denotes the
function S2 × S1 →IN that results from νi by swapping the arguments, i.e., ν−
i (u, v) =
νi(v, u) for all u ∈S2 and v ∈S1.

Stutter Bisimulation
553
TS1 and TS2 are normed-bisimilar, denoted TS1 ≈n TS2, if there exists a normed bisim-
ulation for (TS1, TS2).
For transition system TS, a normed bisimulation for TS is a normed bisimulation for
(TS, TS). States s1 and s2 of TS are called normed-bisimilar, denoted s1 ≈n
TS s2, if there
exists a normed bisimulation (R, ν1, ν2) for TS such that (s1, s2) ∈R.
ν1 and ν2 are norm functions. The values νi(s1, s2) for (s1, s2) /∈R are irrelevant. Hence,
νi could have been deﬁned as function R →IN. The intuitive meaning of ν1(s1, s2) for
(s1, s2) ∈R is as follows. ν1(s1, s2) serves as a count down for the number “allowed”
stutter steps from s1 that cannot be mimicked by transitions of s2. Similarly, ν2(s1, s2)
can be regarded as a counter for the number of stutter steps that s2 may perform to reach
a state where the visible (nonstutter) steps of s1 can be simulated.
Example 7.121.
Normed Bisimulation Equivalence
Consider the transition system TS in Figure 7.40 on page 545. The coarsest equivalence
R which identiﬁes s0 and s1 together with ν1(s0, s1) = ν2(s1, s0) = 1 and ν2(s1, s2) = 1,
ν1(s, s) = ν2(s, s) = 0 for all s ∈{ s0, s1, s2, s3 } (and arbitrary values for ν1 and ν2 for the
remaining cases) is a normed bisimulation. This is checked as follows. It suﬃces to only
consider (s0, s1), (s1, s0) ∈R and their outgoing transitions.
• For s0 →s1, case (N1) applies as s0 →s1 and (s0, s1) ∈R.
• For s1 →s0, case (N1) applies as s1 →s0 and (s0, s1) ∈R.
• For s0 →s2, case (N3) applies as s1 →s0, (s0, s0) ∈R and 0 = ν2(s0, s0) <
ν2(s0, s1) = 1.
• For s1 →s3, case (N3) applies as s0 →s1, (s1, s1) ∈R and 0 = ν2(s1, s1) <
ν2(s1, s0).
Thus, s0 ≈n
TS s1.
We have s1 ̸≈n
TS s2. This can be seen as follows. Assume there is normed bisimulation
(R, ν1, ν2) for TS with (s1, s2) ∈R. Neither case (N1) nor (N3) applies to s1 →s0 since
L(s3) ̸= L(s0), and thus s3 ̸≈n
TS s0. In order for case (N2) to apply to s1 →s0 and s2 →s3,
we should have
s0 ≈n
TS s2
and ν1(s0, s2) < ν1(s1, s2).
But for s0 ≈n
TS s2, neither case (N1) nor (N3) applies to s0 →s1, as s2 can only move to
a state that is not labeled with { a }. Thus, case (N2) applies to s0 →s1. This yields
ν1(s1, s2) < ν1(s0, s2)

554
Equivalences and Abstraction
and contradicts the condition ν1(s0, s2) < ν1(s1, s2).
It is not diﬃcult to prove that ≈n
TS is an equivalence. Moreover, ≈n
TS can be equipped with
norm functions ν1, ν2 such that (≈n
TS, ν1, ν2) is a normed bisimulation; see Exercise 7.24.
Lemma 7.122.
≈n
TS is Finer Than ≈div
TS
If s1, s2 are states in a transition system TS, then s1 ≈n
TS s2 implies s1 ≈div
TS s2.
Proof: Let (R, ν1, ν2) be a normed bisimulation. We show that the symmetric, reﬂexive,
and transitive closure of R—the coarsest equivalence that contains R—is a divergence-
sensitive stutter bisimulation. This amounts showing that R fulﬁlls the conditions of a
stutter bisimulation and that R is divergence-sensitive.
1. As normed bisimulation requires states to be equally labeled, it suﬃces to ﬁrst prove
condition (2) of a stutter bisimulation (see Deﬁnition 7.95 on page 536).
Let (s1, s2) ∈R and s′
1 ∈Post(s1) with (s′
1, s2) /∈R. It is to be proven that there
is a path fragment s2 u1 . . . un s′
2 with (s′
1, s′
2) ∈R and (s2, uj) ∈R for j ⩾0. By
(NII), one of the conditions (N1), (N2) or (N3) holds. The assumption (s′
1, s2) /∈R
rules out case (N2). If (N1) holds then the claim directly follows. Assume case (N3)
applies. Then there exists u1 ∈Post(s2) with
(s1, u1) ∈R and ν2(s1, u1) < ν2(s1, s2).
For state u1 the same argument as for s2 applies: only the cases (N1) and (N3) could
apply. If (N1) holds, then there exists s′
2 ∈Post(u1) with (s′
1, s′
2) ∈R and it follows
that s2 u1 s′
2 is a path that satisﬁes the necessary requirements. Assume case (N3)
applies. Then there exists u2 ∈Post(u1) with
(s1, u2) ∈R and ν2(s1, u2) < ν2(s1, u1).
The reasoning of u1 can now be applied to u2, and if applicable u3, u4, and so on: if
(N1) applies, the claim directly follows; otherwise (N3) applies. Assume that in this
way we obtain a path fragment s2 u1 u2 . . . un with (s1, ui) ∈R, for 0 < i ⩽n and
0 ⩽ν2(s1, un) < ν2(s1, un−1) < . . . < ν2(s1, u1) < ν2(s1, s2).
Since the values of ν2 are natural numbers, case (N3) can only apply ﬁnitely many
times. Assume (N3) does not apply to (s1, un). Then (N1) holds for (s1, un) and
transition s1 →s′
1 for some n ⩽ν2(s1, s2). Hence, there exists a transition un →s′
2
with (s′
1, s′
2) ∈R. This yields a path fragment s2 u1 u2 . . . un s′
2 with (s1, ui) ∈R,
and as R is an equivalence with (s1, s2) ∈R, we have

Stutter Bisimulation
555
(s2, ui) ∈R for 0 < i ⩽n and (s′
1, s′
2) ∈R,
as required in condition (2) of stutter bisimulations.
2. The divergence sensitivity of R is shown as follows. Let (s1, s2) ∈R and assume s1
is R-divergent. We have to prove that s2 is R-divergent. This is done by showing
the existence of a transition s2 →v1 such that (s2, v1) ∈R. We then may repeat
this argument for (s1, v1). This yields the existence of a transition v1 →v2 with
(s1, v2) ∈R. By repeated application, we obtain an inﬁnite path s2 v1 v2 v3 . . . with
(s1, vi) ∈R for all i > 0. Thus s2 is R-divergent.
Let us now consider the proof. Since s1 is R-divergent, there is an inﬁnite path
u0 u1 u2 u3 . . . starting in s1 = u0 for which (s1, u0) ∈R for all i ⩾0. If case (N2)
applies to (ui, s2) ∈R and transitions ui →ui+1, i = 0, 1, . . . , k, then
ν1(s1, s2) = ν1(u0, s2) > ν1(u1, s2) > ν1(u2, s2) > . . . > ν1(uk, s2) ⩾0.
Let k1 ⩾0 be the smallest index such that case (N2) does not apply to (uk1, s2) ∈
R and transition uk1 →uk1+1. If case (N1) holds, then there exists a transition
s2 →v1 where (uk1+1, v1) ∈R and hence (s2, v1) ∈R.
If case (N3) holds for
(uk1, s2) ∈R and uk1 →uk1+1, then there exists v1 ∈Post(s2) with (uk1, v1) ∈R
and ν2(uk1, v1) < ν2(uk1, s2). Thus, s2 →v1 and (s2, v1) ∈R.
Lemma 7.122 can be rewritten for pairs of transition systems as follows:
Corollary 7.123.
Normed and Stutter Bisimulation with Divergence
For all transition systems TS1 and TS2 over AP, we have:
TS1 ≈n TS2 implies TS1 ≈div TS2.
The reverse of Corollary 7.123 does not hold; see Exercise 7.25.
To obtain a suﬃcient and necessary local norm function criterion for stutter bisimulation
equivalence with divergence, a more complex notion of norm functions is needed which
also depends on the transitions to be simulated. We concentrate here on the case of ﬁnite
transition systems where the natural numbers can serve as a range for the norm functions.
(To treat transition systems with inﬁnitely many states, one has to deal with well-founded
sets of arbitrary cardinality.)

556
Equivalences and Abstraction
Deﬁnition 7.124.
Step-Dependent Normed Bisimulation
Let TS = (S, Act, →, I, AP, L) be a transition system. A step-dependent normed bisimu-
lation for TS is a pair (R, ν) where R is an equivalence on S and ν : S × S × S →IN a
function such that for all (s1, s2) ∈R:
(SI) L(s1) = L(s2).
(SII) For all s′
1 ∈Post(s1), at least one of the following three conditions holds:
(S1) There exists s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R.
(S2) (s′
1, s2) ∈R and ν(s′
1, s′
1, s2) < ν(s1, s1, s2).
(S3) There exists s′
2 ∈Post(s2) with (s1, s′
2) ∈R and ν(s′
1, s1, s′
2) < ν(s′
1, s1, s2).
States s1 and s2 are step-dependent normed bisimilar, denoted s1 ≈s
TS s2, if there exists a
step-dependent normed bisimulation (R, ν) for TS such that (s1, s2) ∈R.
For ν(s′
1, s1, s2), the last two arguments denote a pair (s1, s2) ∈R while the s′
1 stands
either for a direct successor of s1 or s1 itself. If s′
1 ∈Post(s1), ν(s′
1, s1, s2) denotes an upper
bound for the number of stutter steps s2 u1 . . . un inside [s2]R that s2 may perform before
taking a matching transition un →s′
2 with (s′
1, s′
2) ∈R. In case s′
1 = s1, ν(s1, s1, s2) is an
upper bound for the stutter steps s1 u1 . . . un inside [s1]R that cannot be matched by s2.
Example 7.125.
Step-Dependent Bisimulation Equivalence
For the transition system TS shown in Figure 7.45, we have s1 ≈s
TS s2. This is justiﬁed
by establishing a step-dependent normed bisimulation for TS that contains (s1, s2).
s1
{ a }
{ b } w1
{ a }
u1
∅
v1
s1
{ a }
{ a } u2
{ a }
u3
∅
v2
w2 { b }
Figure 7.45: s1 ≈s
TS s2.
Let R be the equivalence that identiﬁes states s1, u1, u2, u3, s2, states t1, t2, and states

Stutter Bisimulation
557
w1, w2. Let the step-dependent norm function ν : S3 →IN be deﬁned as follows:
ν(s1, s1, s2)
=
2
ν(u1, u1, s2)
=
1
ν(w1, s1, s2)
=
2
ν(w1, s1, u2)
=
1
ν(w1, u1, s2)
=
2
ν(w1, u1, u2)
=
1
ν(t1, u1, s2)
=
2
ν(t1, u1, u2)
=
1
ν(s2, s2, s1)
=
2
ν(u2, u2, s1)
=
1
ν(u3, u3, s1)
=
1
ν(t2, u3, s1)
=
1
and ν(·) = 0 in all other cases. Then, (R, ν) is a step-dependent normed bisimulation for
TS. Let us check the required conditions. Condition (SI) is obvious since R identiﬁes only
equally labeled states. Consider the pair (s1, s2) ∈R and check whether (SII) holds for
the outgoing transitions of s1.
• For the transition s1 →w1, we consider the transition s2 →u2 and get (s1, u2) ∈R
and ν(w1, s1, u2) = 1 < 2 = ν(w1, s1, s2) Hence, condition (S3) is fulﬁlled.
• For the transition s1 →u1, case (S2) applies as we have (u1, s2) ∈R and ν(u1, u1, s2) =
1 < 2 = ν(s1, s1, s2).
Let us now consider the pair (u1, s2). For the transition u1 →v where v ∈{w1, t1} we
consider the stutter step s2 →u2 and get ν(x, u1, u2) = 1 < 2 = ν(x, u1, s2), which yields
condition (S3). Similarly, for the pair (u1, u2) ∈R and the transitions u1 →x case (S3)
applies as we may take the transition u2 →u3 and get
ν(x, u1, u3) = 0 < 1 = ν(x, u1, u2).
For (u1, u3) and transition u1 →x condition (S1) is fulﬁlled as we may take the corre-
sponding transition from u3.
Let us now prove condition (SII) for the pair (s2, s1) ∈R. We have to regard the transition
s2 →u2. In fact, case (S2) applies since s2 and u2 are R equivalent and
ν(s2, s2, s1) = 2 > 1 = ν(u2, u2, s1).
Similarly, for the pair (u2, s1) ∈R we have to consider the transition u2 →u3 where again
condition (S2) is fulﬁlled as we have
ν(u2, u2, s1) = 1 > 0 = ν(u3, u3, s1).
For (u3, s1) ∈R and transition u3 →w2 condition (S1) holds as we may move from s1 to
w1. For the transition u3 →t2 case (S3) applies for the stutter step s1 →u1 as we have
ν(t2, u3, s1) = 1 > 0 = ν(t2, u3, u1).

558
Equivalences and Abstraction
The following theorem shows that step-dependent norm functions yield a sound and com-
plete criterion for divergence stutter bisimilarity.
Theorem 7.126.
Alternative Characterization of ≈div
TS
Let TS be a ﬁnite transition system and s1 and s2 states in TS. Then:
s1 ≈s
TS s2
if and only if
s1 ≈div
TS s2.
Proof: We show that ≈s
TS is ﬁner than ≈div
TS , and vice versa.
Claim 1. ≈s
TS is ﬁner than ≈div
TS .
Proof of Claim 1. Similar arguments as in the proof of Lemma 7.122 can be used. In fact,
for this direction the cardinality of TS is irrelevant. We take a step-dependent normed
bisimulation (R, ν) and show that R is a divergence-sensitive stutter bisimulation. Let us
ﬁrst check conditions (1) and (2) of stutter bisimulations. (Condition (3) is obtained from
(2) by the symmetry of R.) (1) is immediate from the deﬁnition of normed bisimulations
(see condition (SI)). Let us check condition (2). Let (s1, s2) ∈R and s′
1 ∈Post(s1) with
(s′
1, s2) /∈R. (SII) yields that one of the conditions (S1), (S2), or (S3) holds. (S2) is
impossible as (s′
1, s2) /∈R. If (S1) holds, then (2) is obvious. If (S3) applies, then we pick
a state u1 ∈Post(s2) such that u1 is R-equivalent to s1 and s2 and
ν(s′
1, s1, u1) < ν(s′
1, s1, s2).
Since (s1, u1) ∈R we may apply the same argument: either (S1) applies, i.e., there exists
s′
2 ∈Post(u1) with (s′
1, s′
2) ∈R, or (S3) applies, which yields a state u2 ∈Post(u1) such
that u2 is R-equivalent to s1, s2, u1 and
ν(s′
1, s1, u2) < ν(s′
1, s1, u1).
Repeating this argument yields a path fragment s2 u1 u2 . . . un such that (s1, ui) ∈R,
1 ⩽i ⩽n and
0 ⩽ν(s′
1, s1, un) < ν(s′
1, s1, u2) < . . . < ν(s′
1, s1, u1) < ν(s′
1, s1, s2)
and such that (S3) does not apply to (s1, un) ∈R and the transition s1 →s′
1. Since s′
1 is
not R-equivalent to s1, (S1) applies which yields a transition un →s′
2 with (s′
1, s′
2) ∈R.
Hence, we have a path fragment s2 u1 u2 . . . un s′
2 with (s1, ui) ∈R and (s′
1, s′
2) ∈R, as
required in condition (2).
It remains to show the divergence sensitivity of R. Let (s1, s2) ∈R and let s1 be R-
divergent. We have to prove the R-divergency of s2. For this, we show the existence

Stutter Bisimulation
559
of a transition s2 →v1 such that s2 and v1 are R-equivalent. We then may repeat this
argument for (s1, v1) which yields the existence of a transition v1 →v2 with (s1, v2) ∈R
and the existence of a transition v2 →v3 with (s1, v3) ∈R, and so on.
In this way
we obtain an inﬁnite path s2 v1 v2 v3 . . . with (s1, vi) ∈R for all i ⩾0, and thus, the
R-divergency of s2.
Since s1 is R-divergent there is an inﬁnite path u0 u1 u2 u3 . . . starting in s1 = u0 where
s1 and all states ui are R-equivalent. If case (S2) applies to the pair (ui, s2) ∈R and
transitions ui →ui+1, i = 0, 1, . . . , k, then
ν(s1, s1, s2) > ν(u1, u1, s2) > ν(u2, u2, s2) > . . . > ν(uk, uk, s2) ⩾0.
Let k1 ⩾0 be the smallest index such that case (S2) does not apply to the pair (uk1, s2) ∈R
and transition uk1 →uk1+1. If case (S1) holds, then there is a transition s2 →v1 where
(uk1+1, v1) ∈R. Since all u-states are R-equivalent to s1 and s2, this yields (s2, v1) ∈R,
and we are done. If case (S3) holds for (uk1, s2) ∈R and transition uk1 →uk1+1, then
there exists v1 ∈Post(s2) with (uk1, v1) ∈R and ν(uk1+1, uk1, v1) < ν2(uk1+1, uk1, s2).
Again, we have s2 →v1 and the R-equivalence of s2 and v1.
Claim 2. ≈div
TS is ﬁner than ≈s
TS, provided that TS is ﬁnite.
Proof of Claim 2. We establish a ternary norm function ν that satisﬁes the conditions in
Deﬁnition 7.124 for R = ≈div
TS .
• For s1 ≈div
TS
s2 and s′
1 ∈Post(s1) with s1 ̸≈div
TS
s′
1 we deﬁne ν(s′
1, s1, s2) as the length
of a shortest path fragment s2 u1 u2 . . . un such that
– ui ≈div
TS
s2, i = 1, . . . , n
– [s′
1]div ∩Post(un) ̸= ∅, where [s]div denotes the equivalence class of s under
≈div
TS .
• If s1 ≈div
TS
s2 and s1, s2 are ≈div
TS -divergent then we put ν(s1, s1, s2) = 0.
• If s1 ≈div
TS
s2 and s1, s2 are not ≈div
TS -divergent then we deﬁne ν(s1, s1, s2) as the
length of a longest path fragment s1 v1 v2 . . . vn such that
vi ≈div
TS
s1 for i = 1, . . . , n
and
[s1]div ∩Post(vn) = ∅.
Note that such a longest ﬁnite path fragment exists since TS is ﬁnite and s1 is not
divergent.
We now show that (≈div
TS , ν) is a step-dependent normed bisimulation for TS. Obviously,
≈div
TS is an equivalence on S where (SI) holds. Let us check condition (SII) for states s1, s2
with s1 ≈div
TS
s2 and transition s1 →s′
1.

560
Equivalences and Abstraction
• If s1 ̸≈div
TS
s′
1, then either [s′
1]div ∩Post(s2) ̸= ∅(in which case condition (S1) holds)
or there is a path fragment s2 u1 . . . uns′
2 with n ⩾1 and
ui ≈div
TS
s2, i = 1, . . . , n and s′
1 ≈div
TS
s′
2.
We may assume that n is minimal. Then, s2 →u1 is a transition with (u1, s2) ∈R
and n −1 = ν(s′
1, s1, u1) < ν(s′
1, s1, s2) = n. Hence, condition (S3) holds.
• Let us now consider a stutter step s1 →s′
1 inside the equivalence class of s1, i.e., we
suppose s1 ≈div
TS
s′
1.
– If s1 is divergent, then so is s2 and there is a step s2 →s′
2 where s′
2 is ≈div
TS
equivalent to s1 and s2. Thus, condition (S1) holds.
– Let us now suppose that s1 and s2 are not divergent. For s ≈div
TS
s1 let ℓ(s)
be the length of a longest path fragment s v1 v2 . . . vn such that vi ≈div
TS
s,
i = 1, . . . , n and [s]div ∩Post(vn) = ∅. Clearly, we have
ℓ(s) =
max
s′∈Post(s)∩[s]div
ℓ(s′) + 1.
ν(s, s, s2) = ℓ(s) (by deﬁnition of ν). Hence,
ν(s1, s1, s2) = ℓ(s1) ⩾ℓ(s′
1) + 1 > ν(s′
1, s′
1, s2).
This shows that condition (S2) holds.
7.8.3
Stutter Bisimulation and CTL∗
\⃝Equivalence
Stutter bisimulation (≈) does not preserve LTL\⃝formulae since it does not impose any
restrictions on divergent paths. That is, if TS1 ≈TS2, and TS1 contains a divergent
path violating some LTL\⃝formula ϕ, whereas TS2 does not exhibit such behaviour, then
TS1 ̸|= ϕ whereas TS2 |= ϕ. To avoid the complications induced by stutter paths, we
have considered ≈div that requires two equivalent states to either both have a divergent
path, or both have no divergent paths. The central result in this section is that ≈div
coincides with the logical equivalences for the next-free fragments of CTL∗and CTL.
This entails that any formula in these logics can be checked on a transition system that
is stutter bisimulation-equivalent with divergence, in particular, the quotient under ≈div.
Moreover, to show TS1 ̸≈div TS2 it suﬃces to provide a CTL∗formula Φ that does not
contain ⃝, such that TS1 |= Φ and TS2 ̸|= Φ.

Stutter Bisimulation
561
Notation 7.127.
CTL∗and CTL without Next Step
Let CTL∗
\⃝denote the class of all CTL∗formulae that do not contain any occurrence of
the next step operator ⃝. Similarly, CTL\⃝denotes the sublogic of CTL which does not
permit the next-step operator ⃝.
Theorem 7.128.
CTL∗
\⃝/CTL\⃝Equivalence and ≈div
For ﬁnite transition system TS without terminal states, and states s1, s2 in TS:
s1 ≈div
TS
s2
iﬀ
s1 ≡CTL∗
\⃝s2
iﬀ
s1 ≡CTL\⃝s2.
Proof: The proof strategy is analogous to the proof of Theorem 7.20 (page 469).
1. Lemma 7.129 (see below) asserts that ≈div
TS
is ﬁner than CTL∗
\⃝equivalence for
arbitrary (possibly inﬁnite) transition systems.
2. CTL∗
\⃝equivalence is ﬁner than CTL\⃝equivalence, since CTL\⃝is a sublogic of
CTL∗
\⃝.
3. Lemma 7.130 (see below) asserts that CTL\⃝equivalence is ﬁner than ≈div
TS .
Note that the proof of (3) for CTL equivalence and bisimulation (∼) exploits the next-step
operator (and not the until operator). As this operator is absent in CTL\⃝, an alternative
logical characterization has to be pursued.
Lemma 7.129.
Divergence Stutter Bisimilarity Implies CTL∗
\⃝Equivalence
Let TS be a transition system without terminal states, s1, s2 states in TS, and π1, π2 ∈
Paths(TS). Then:
1. if s1 ≈div
TS s2, then for all CTL∗
\⃝state formulae Φ: s1 |= Φ iﬀs2 |= Φ.
2. if π1 ≈div
TS π2, then for all CTL∗
\⃝path formulae ϕ: π1 |= ϕ iﬀπ2 |= ϕ.
Proof: The proof is provided by structural induction over the CTL∗
\⃝formulae and is
similar to the proof of Lemma 7.26 (page 473). We omit the details and only consider the
case Φ = ∃ϕ, where ϕ is a CTL∗
\⃝path formula satisfying claim 2. Assume s1 ≈div
TS s2

562
Equivalences and Abstraction
and s1∃ϕ. Let π1 ∈Paths(s1) such that π1 |= ϕ. According to Lemma 7.118 (page 549),
there exists π2 ∈Paths(s2) with π1 ≈div
TS
π2. Applying the induction hypothesis to ϕ and
paths π1, π2 yields π2 |= ϕ. Hence, s2 |= ∃ϕ.
Lemma 7.130.
CTL\⃝Equivalence is Finer Than ≈div
TS
For ﬁnite transition system TS without terminal states, and s1, s2 states in TS:
s1 and s2 are CTL\⃝equivalent implies s1 ≈div
TS
s2.
Proof: Let S be the state space of TS. It suﬃces to show that
R = { (s1, s2) ∈S × S | s1 ≡CTL\⃝s2 }
is a divergence-sensitive stutter bisimulation for TS. We show that (1) R is a stutter
bisimulation for TS and (2) R is divergence-sensitive.
Claim 1. R is a stutter bisimulation for TS.
Proof of Claim 1. This is proven by checking the conditions of stutter bisimulation. Let
(s1, s2) ∈R.
1. Consider the propositional logic formula
Φ
=

a∈L(s1)
a
∧

a∈AP\L(s1)
¬a.
Clearly, Φ is a CTL\⃝formula with s1 |= Φ. Hence, by deﬁnition of R, s2 |= Φ. By
construction of Φ, we have L(s1) = L(s2).
2. For each equivalence class C ∈S/R, let CTL\⃝formula ΦC be deﬁned by
ΦC
=

D∈S/R
D̸=C
ΦC,D
where ΦC,D is a CTL\⃝formula such that Sat (ΦC,D) ⊇C and Sat (ΦC,D) ∩D = ∅,
for each pair (C, D) of equivalence classes C, D under R with C ̸= D. This yields
Sat(ΦC) = C.
It remains to prove that for all s′
1 ∈Post(s1) with (s1, s′
1) /∈R, there exists a ﬁnite
path fragment s2 u1 . . . un s′
2 with (s′
1, s′
2) ∈R and (s2, ui) ∈R, i = 1, . . . , n. Let

Stutter Bisimulation
563
B ∈S/R and s1, s2 ∈B, i.e., B = [s1]R = [s2]R. Further, let s′
1 ∈Post(s1) such
that (s1, s′
1) /∈R, say C = [s′
1]R with B ̸= C. Then:
s1 |= ∃(ΦB U ΦC)
as s1 ∈B and s′
1 ∈C
Since (s1, s2) ∈R and ΦB U ΦC is a CTL\⃝formula, we get
s2 |= ∃(ΦB U ΦC).
Thus, there exists a ﬁnite path fragment s2 u1 . . . un s′
2 with s′
2 |= ΦC and s2 |= ΦB,
u1 |= ΦB, . . . , un |= ΦB. Since Sat(ΦC) = C and Sat(ΦB) = B, we obtain s′
2 ∈C and
u1, . . . , un ∈B. As C = [s′
1]R and B = [s1]R = [s2]R, we conclude that (s′
1, s′
2) ∈R
and (s2, ui) ∈R, for i = 1, . . . , n.
Claim 2. R is divergence-sensitive.
Proof of Claim 2. Assume (s1, s2) ∈R and s1 is R-divergent. We have to show that s2 is
R-divergent. As s1 is R-divergent there exists an R-divergent path fragment:
π1 = s1 s1,1 s2,1 s3,1 . . . ∈Paths(s1).
Let C = [s1]R and ΦC be a CTL\⃝formula such that Sat(ΦC) = C. Then sj,1 ∈C, i.e.,
sj,1 |= ΦC for all j > 0. Hence, s1 |= ∃□ΦC. As (s1, s2) ∈R and C = [s1]R, we get
s2 |= ∃□ΦC. Thus, there exists an inﬁnite path fragment:
π2 = s2 s1,2 s2,2 s3,2 . . . ∈Paths(s2)
with sj,2 |= ΦC for j > 0. As Sat(ΦC) = C, we get sj,2 ∈C for j > 0. Since C = [s2]R, π2
is an R-divergent path. Hence, s2 is R-divergent.
A few remarks are in order. ≈div
TS is the coarsest equivalence which preserves all CTL\⃝
formulae. Theorem 7.128 can be reformulated for pairs of transition systems in the usual
way. Thus, for all ﬁnite transition systems TS1, TS2 without terminal states:
TS1 ≈div TS2
iﬀ
TS1 and TS2 satisfy the same CTL∗
\⃝formulae
iﬀ
TS1 and TS2 satisfy the same CTL\⃝formulae.
We ﬁnally remark that in the proof of the logical characterization of ≈div
TS , the until operator
is explicitly used. Thus, whereas bisimulation and simulation can be characterized by a
CTL (or CTL∗) fragment that does not contain the until operator, this is not the case for
≈div
TS . This is not surprising, as ≈div
TS does not preserve the next-step operator and some
modal operator is needed to characterize ﬁnite stutter path fragments.

564
Equivalences and Abstraction
{ (0, 0) }
{ (0, 1) }
{ (1, 1) }
{ (1, 0) }
{ (0, 1) }
{ (1, 0) }
Figure 7.46: TSABP/≈div.
In particular, since TS ≈div TS/≈div, it suﬃces to check CTL∗
\⃝formula Φ on TS/ ≈div
to decide whether TS |= Φ. This is exempliﬁed by the alternating bit protocol.
Example 7.131.
Alternating Bit Protocol
Consider again the alternating bit protocol; see Example 2.32 on page 57. Let
AP = { s mode = 0, s mode = 1, r mode = 0, r mode = 1 }
where s mode indicates the mode of the sender, and r mode that of the receiver.
In
Example 7.108 (page 545), it was concluded that TSABP, the transition system underlying
the ABP, and its stutter bisimulation quotient TSABP/≈, do not satisfy the same CTL∗
\⃝
formulae. This is due to the fact that the transition system
TS
=
(TSABP ⊕TSABP) /≈
is not divergence-sensitive, i.e., there are stutter-bisimilar states in TS such that one of
them is ≈-divergent, while the other is not. In fact, in order to prove a CTL∗
\⃝, CTL\⃝,
or LTL\⃝formula of the ABP, we must consider TSABP/≈div instead of TSABP/≈.
To obtain the quotient under ≈div, each state in TSABP/ ≈for which s mode ̸= r mode
needs to be decomposed in two states. Accordingly, the transition system TSABP/≈div is
obtained as depicted in Figure 7.46. Two of those states are labeled with
A1 = {s mode = 0, r mode = 1},
A2 = {s mode = 1, r mode = 0}.
One of these two states represents the divergent Ai-states in TSABP, while the other
represents the nondivergent Ai-states ⟨chk ack(i), . . . , x = i, . . .⟩in TSABP. The CTL∗
\⃝
safety property
Φ = ∀□

(s mode = 0) −→(s mode = 0) W (r mode = 1)


Stutter Bisimulation
565
expresses that the sender does not leave the 0-mode (in which it only transmits message
with bit 0) before the receiver changes to the 1-mode (in which it expects to receive
messages with bit 1, i.e., before the receiver has acknowledged the correct receipt of the
message with bit 0. It is easy to establish that TSABP/≈div |= Φ. Theorem 7.128 yields
TSABP |= Φ.
Example 7.132.
Producer-Consumer System
Consider a concurrent program that involves a producer and consumer process that shares
a buﬀer of data items of capacity m > 0. The producer repeatedly produces n items and
inserts these data items one by one in the buﬀer. Local variable in indicates the next
buﬀer cell that needs to be written. The producer can only insert an element in cell buﬀer
at index in when this cell is empty. An empty buﬀer cell is indicated by ⊥. The consumer
process successively attempts to get items from the buﬀer.
Producer
in := 0;
while true
{
produce d1, . . . , dn;
for i = 1 to n {
wait until (buﬀer[in] = ⊥) {
buﬀer[in] := di;
in := (in + 1) mod m; }
}
}
Consumer
out := 0;
while true
{
for j = 1 to n {
wait until (buﬀer[out] ̸= ⊥) {
ej := buﬀer[out];
buﬀer[out] := ⊥;
out := (out + 1) mod m; }
}
consume e1, . . . , en
}
Let TS(m, n) denote the transition system underlying this producer-consumer program.
The size of TS(n, m) grows exponentially in the number n of data items generated per
cycle and in the buﬀer capacity m.
Suppose we are interested in the situation in which the producer and the consumer are si-
multaneously in their produce and consume phase, respectively. Let AP = { prod and cons }.
Observe that the content of the buﬀer can be ignored. This also applies to the variables in
and out. In order to keep track of the number of free buﬀer cells, we introduce the bounded
integer variable free with domain { 0, 1, . . . , m }. On completion of the production phase,
variable i indicates the number of data items the producer has already stored in the buﬀer.
Accordingly, j stands for the number of data items the consumer has withdrawn from the
buﬀer. This yields the following abstract programs:

566
Equivalences and Abstraction
Producer
while true
{
produce;
for i = 1 to n {
wait until (free > 0) {
free := free −1;
}
}
Consumer
while true
{
for j = 1 to n {
wait until (free < m) {
free := free + 1;
}
consume
}
Let TSabstract(m, n) denote the transition system that is obtained for this abstract program.
TSabstract(2, 2) is indicated in Figure 7.47, where it is assumed that executing the body
of the for loop is executed atomically. Each state is of the form ⟨ℓi, ℓ′
i, vf, vi, vj⟩where ℓi
and ℓ′
i indicate the program locations of the producer and consumer, respectively; vf is
the value of free, and vi, vj the value of integers i and j. In particular, we have:
ℓ0
:
produce
ℓ1
:
⟨if (free > 0) then i := 1; free−−ﬁ⟩
ℓ2
:
⟨if (free > 0) then i := 0; free−−ﬁ⟩
The labels ℓ′
i are deﬁned for the consumer process in a similar way. Note that the states
with control locations ℓ0 and ℓ′
2 indicate the global states in which the producer and
consumer are in their produce and consume phase, respectively. Thus, all states of the
form ⟨0, 2, −, −, −⟩are labeled with the proposition prod and cons; all other states are
labeled with ∅. The size of TSabstract(n, m) is polynomial in n and m. It follows that
TS(m, n) ≈div TSabstract(m, n) .
Observe that
TSabstract(m, n) ̸|= ∀□∀♦prod and cons .
As this is a CTL\⃝formula, it follows that TS(m, n) refutes it. A counterexample in
TSabstract(m, n) is, e.g.,
⟨ℓ0, ℓ′
0, 2, 0, 0⟩→⟨ℓ1, ℓ′
0, 2, 0, 0⟩→⟨ℓ2, ℓ′
0, 1, 1, 0⟩→⟨ℓ0, ℓ′
0, 0, 0, 0⟩→
⟨ℓ0, ℓ′
1, 1, 0, 1⟩→⟨ℓ1, ℓ′
1, 1, 0, 1⟩→⟨ℓ0, ℓ′
2, 2, 0, 0⟩→⟨ℓ0, ℓ′
0, 2, 0, 0⟩→. . .
The fact that TSabstract(n, m) ̸|= ∀□∀♦prod and cons can easily be shown by considering
its quotient under ≈div; see the self-loop in the initial states in Figure 7.48.

Stutter Bisimulation
567
0, 0, 2, 0, 0
0, 0, 0, 0, 0
2, 1, 2, 1, 1
0, 1, 1, 0, 1
1, 1, 1, 0, 1
2, 1, 0, 1, 1
1, 0, 2, 0, 0
0, 2, 2, 0, 0
1, 2, 2, 0, 0
2, 2, 1, 1, 0
0, 2, 0, 0, 0
1, 2, 0, 0, 0
2, 0, 1, 1, 0
1, 0, 0, 0, 0
Figure 7.47: Transition system TSabstract(2, 2).
7.8.4
Stutter Bisimulation Quotienting
This section is concerned with algorithms to compute the quotient transition system under
the stutter bisimulations ≈and ≈div. Such algorithms serve the following two purposes.
First, they can be used to check whether two transition systems are stutter bisimulation
equivalent. Secondly, the algorithm for ≈div can be used to minimize a transition system
with respect to divergence-sensitive stutter bisimulation. This can be used as a preprocess-
ing phase prior to model checking a CTL∗
\⃝formula. We ﬁrst outline how to compute the
equivalence classes under ≈(i.e., without divergence) and then explain how this algorithm
can be adapted to ≈div.
In the remainder of this section, let TS = (S, Act, →, I, AP, L) be a ﬁnite transition system,
possibly with terminal states. The quotienting algorithms for ≈and ≈div are based on
partition reﬁnement, as for bisimulation. Recall that partition reﬁnement algorithms are
based on successively reﬁning partitions until a stable partition is reached. The reﬁnement
is based on splitting a block in the current partition with respect to a superblock, i.e., a
disjoint union of blocks. The idea of reﬁnement for ≈is to split a given block B according
to another block C into two subblocks: a block of states in B that can reach C via a path
fragment that only visits states in B, and a block that contains all other states in B.

568
Equivalences and Abstraction
s0
∅
s1
{ prod and cons }
Figure 7.48: Quotient transition system TSabstract(2, 2)/≈div.
Notation 7.133.
Constrained Predecessors
For partition Π of S and blocks B, C in Π with s ∈B, we have s ∈Pre∗
Π(C) whenever
there exists a ﬁnite path fragment:
s = s1 s2 . . . sn−1 sn ∈Paths(s) with sn ∈C and si ∈B for all 0 < i < n.
Stated in words, Pre∗
Π(C) contains any state s that can reach a state in C via a (possibly
single-state) path that solely consists of states that are in the same block of Π as s.
Deﬁnition 7.134.
Π-Splitter, C-Stability
Let Π be a partition of S and let C, B ∈Π.
1. C is a Π-splitter for B if and only if
B ̸= C
and
B ∩Pre(C) ̸= ∅
and
B \ Pre∗
Π(C) ̸= ∅.
2. Π is C-stable if there is no block B ∈Π such that C is a Π-splitter for B.
3. Π is stable if Π is C-stable for all blocks C ∈Π.
Let us consider the requirements of C being a Π-splitter of B. As a block cannot be split
by itself, the requirement that B ̸= C is natural. Furthermore, B can only be splitted
according to C when C can be reached in a single transition from at least one state in B.
Finally, the third conjunct asserts that B should contain states that can only reach C via
some state that is neither in B nor in C.

Stutter Bisimulation
569
Algorithm 37 Computing the stutter bisimulation quotient
Input: ﬁnite transition system TS with state space S
Output: stutter bisimulation quotient space S/≈
Π := ΠAP;
(* see Algorithm 29, page 479 *)
while (∃B, C ∈Π. C is a Π-splitter for B) do
choose such B, C ∈Π;
Π := (Π \ { B }) ∪Reﬁne≈(B, C)
od
return Π
Lemma 7.135.
Coarsest Partition
The stutter bisimulation quotient space S/≈is the coarsest partition Π of S such that
(i) Π is ﬁner than ΠAP.
(ii) for all B, C ∈Π: B ∩Pre(C) = ∅or B ⊆Pre∗
Π(C).
Proof: Similar to the proof of Lemma 7.34 on page 480.
That is, S/ ≈is the coarsest partition such that (i) states are equally labeled, and (ii)
either there is no transition between B and C, or in case such transition exists, there are
some states in B that cannot reach C by only visiting states in B. For such states, the
only possibility to reach C is via some other block D ̸= B, C. This lemma suggests the
following reﬁnement operator:
Deﬁnition 7.136.
The Reﬁnement Operator
Let Π be a partition for S and C be a block of Π. Then:
Reﬁne≈(Π, C) =

B∈Π
Reﬁne≈(B, C)
where Reﬁne≈(B, C) = {B ∩Pre∗
Π(C), B \ Pre∗
Π(C)} \ { ∅}.
The essential steps of the partition reﬁnement technique for quotienting with respect to
≈are summarized in Algorithm 37. Note that unlike the partition reﬁnement algorithms
for ordinary bisimulation ∼, Algorithm 37 reﬁnes per iteration just one block B. As C
is a Π-splitter for B, each iteration yields a proper reﬁnement. Therefore, the number of

570
Equivalences and Abstraction
iterations of the while-loop is bounded by the number of states. In the remainder of this
section, some implementation details will be provided to enable an eﬃcient realization of
the reﬁnement operator.
Removal of Stutter Cycles
As a ﬁrst step, the transition system TS is simpliﬁed by
removing all its stutter cycles, i.e., cycles that completely consist of stutter steps. Formally:
Deﬁnition 7.137.
Stutter Cycle
Cycle s0 s1 s2 . . . sn (with s0 = sn) for n > 0 in transition system TS is a stutter cycle
when si si+1 is a stutter step for 0 ⩽i < n.
All states on a stutter cycle belong to the same equivalence class under ≈, and thus belong
to the same block of S/≈. In fact, this even holds for ≈div:
Lemma 7.138.
Stutter Cycle
For stutter cycle s0 s1 s2 . . . sn in transition system TS:
s0 ≈div
TS s1 ≈div
TS
. . . ≈div
TS sn.
Proof: Let R be the smallest equivalence relation on S which identiﬁes the states s0 =
sn, s1, . . . , sn−1 and no other states. That is, R is the equivalence relation that induces
the partition:
S/R = {{ s0, . . . , sn−1 }} ∪{{ s } | s ∈S \ { s0, . . . , sn−1 }}.
All states in { s0, . . . , sn−1 } are stutter-bisimilar as they all lie on the same stutter cycle,
i.e., any visible step by si →s′ can be matched by a path fragment starting in sj (i̸=j) by
ﬁrst traversing the cycle to si and then taking the transition si →s′. Clearly, these states
are all divergent. All singleton partitions are stutter-bisimilar and nondivergent. Hence,
R is a divergence-sensitive stutter bisimulation.
Consequently, all states on a stutter cycle are divergent. Note that for ﬁnite transition
systems it holds that any divergent path must contain a cycle. Since all states on such
cycle are pairwise ≈div equivalent—and thus equally labeled—they form a stutter cycle.

Stutter Bisimulation
571
Corollary 7.139.
Complete Characterization of Divergent States
For ﬁnite transition system TS and state s in TS:
s is ≈div −divergent
iﬀ
a stutter cycle is reachable from s
via a path fragment in [s]≈div.
To simplify the reﬁnement operator, we ﬁrst remove stutter cycles from transition system
TS. This is done in the following way. In the state graph G(TS), determine the strongly
connected components (SCCs) that only contain stutter steps. This can be carried out
using a (standard) depth-ﬁrst search algorithm. Then, any stutter SCC is collapsed into
a single state. This yields a new transition system TS′ where the states are the stutter
SCCs in G(TS), and C →′ C′ with C ̸= C′ whenever s →s′ is a transition in TS with
s ∈C and s′ ∈C′. By construction, TS′ does not contain any stutter cycles. The time
complexity of this step is O(M+|S|). Note that
s1 ≈TS s2 if and only if C1 ≈TS′ C2
where Ci denotes the stutter SCC which contains state si.
Eﬃcient Realization of Reﬁning a Partition
From now on, it is assumed that
transition system TS has no stutter cycles. We now focus our attention on an eﬃcient
realization of the reﬁnement operator and the search for a splitter (see the loop condition
in Algorithm 37). Assume that list representations for the sets Pre(s) and Post(s) are
available for any state s. Let Π be a partition of S that is coarser than S/ ≈and ﬁner
than ΠAP. The goal is to check the instability of Π for a block C by a linear search in the
lists Pre(s) for s ∈C rather than to consider the set Pre∗
Π(C). To that end, we aim at a
characterization of a splitter in terms of direct predecessors of C. An important notion to
enable such characterization is that of an exit state in a block B, say, i.e., a state whose
only outgoing transitions lead to states that are outside B.
Deﬁnition 7.140.
Exit States
Let TS be a ﬁnite transition system without stutter cycles and B be a block of a partition
Π for S, the state space of TS. The exit states of B and partition Π are deﬁned by
Bottom(B) = {s ∈B | Post(s) ∩B = ∅} and Bottom(Π) =

B∈Π
Bottom(B).
Since TS does not have stutter cycles and is ﬁnite, any block B of partition Π that is
ﬁner than ΠAP has at least one exit state. This can be seen by contraposition. Assume
block B ∈Π does not contain an exit state. Then there exists an inﬁnite path s0 s1 s2 . . .
consisting of states in B. Since TS is ﬁnite, there exists a pair of indices i, j such that

572
Equivalences and Abstraction
0 ⩽i < j with si = sj. As Π is ﬁner than ΠAP, all states in B are equally labeled. Hence,
the path fragment si si+1 . . . sj is a stutter cycle. This contradicts TS having no stutter
cycles. Thus, Bottom(B) ̸= ∅for any block B ∈Π where Π reﬁnes ΠAP.
The following lemma is the key for checking whether a block C ∈Π is a Π-splitter by a
linear search in the lists Pre(s) for s ∈C.
Lemma 7.141.
Local Splitter Criterion
Let TS be a ﬁnite transition system without stutter cycles, Π a partition of TS’s state
space S and C, B ∈Π. Then:
C is a Π-splitter for B iﬀ(B ̸= C ∧B ∩Pre(C) ̸= ∅∧Bottom(B) \ Pre(C) ̸= ∅) .
Proof: ⇐: Assume B ̸= C, B ∩Pre(C) ̸= ∅and Bottom(B) \ Pre(C) ̸= ∅.
Then,
there exist states t ∈Bottom(B) \ Pre(C) and s ∈B ∩Pre(C). Since t ∈Exit(B) and
t ̸∈Pre(C), all direct successors of t are outside B ∪C, and thus t ∈B \ Pre∗
Π(C). Thus,
by Deﬁnition 7.134, C is a Π-splitter for B.
⇒: Let C be a Π-splitter for B. By Deﬁnition 7.134 of a Π-splitter, it follows that B ̸= C
and s ∈B ∩Pre(C) for some s.
It remains to show that B \ Pre∗
Π(C) ̸= ∅implies
Bottom(B)\Pre(C) ̸= ∅. This is done by contraposition. Assume Bottom(B)\Pre(C) =
∅, i.e., Bottom(B) ⊆Pre(C).
Let u ∈B.
Since there are no stutter cycles in TS
and TS is ﬁnite, there exists a path fragment u . . . t consisting of B-states only with
t ∈Bottom(B). But, since Bottom(B) ⊆Pre(C), we have t ∈Pre(C), and u ∈Pre∗
Π(C).
Thus, u ∈B ∩Pre∗
Π(C). As this applies to any u ∈B, it follows B ⊆Pre∗
Π(C), which
contradicts that C is a Π-splitter of B.
This result allows checking whether block C of partition Π is a Π-splitter for some B ∈Π,
by investigating the direct predecessors of C.
For any state s ∈C, the list Pre(s) is
traversed and all states s′ ∈Pre(s) and blocks [s′]Π (not all states in the block, just the
block itself) are marked. Then, for each block B ∈Π, B ̸= C, we have
C is a Π-splitter for B
iﬀ
B is marked and Bottom(B)
contains an unmarked state
In this way, the C-stability of Π can be checked in time O(|Pre(C)|) when using appropriate
data structures (such as lists) for Π and Bottom(B) for B ∈Π.
For instance, a list
representation of Π with pointers from Π’s blocks to the states in the blocks and vice versa,
enables generating a list consisting of (pointers to) the marked blocks in time O(|Pre(C)|).

Stutter Bisimulation
573
To check whether there is a marked block B where Bottom(B) contains an unmarked state,
a linear search through the list of marked blocks suﬃces. If B is the current (marked)
block, then we traverse the list representing Bottom(B) until an unmarked state (i.e., a
state t /∈Pre(C)) has been found (or the end of the list has been reached). The time
complexity of this strategy is O(|Pre(C)|), since the number of marked blocks is at most
|Pre(C)| and the total number of elements to be considered when traversing the lists for
the exit states is bounded by |Pre(C)| + 1. (The “+1” covers the case where t /∈Pre(C)
has been reached.) Ranging over all blocks C ∈Π, the stability of Π can be checked in
time O(M) since M = 
C∈Π
|Pre(C)|, where (as before) M denotes the number of edges in
the state graph of TS.
Moreover, if C is a Π-splitter (i.e., Π is not C-stable), then the above technique returns a
block B ∈Π such that C is a Π-splitter for B. It remains to explain how the reﬁnement
of B into the two subblocks:
B1 = B ∩Pre∗
Π(C) and B2 = B \ Pre∗
Π(C)
can be realized in time O(M). For this, we proceed as follows. We start with two new
(variables for the) blocks B1 and B2, which are initially empty. On traversing the list of all
exit states of B, any marked state s ∈Bottom(B) is added to B1 and any unmarked state
s ∈Bottom(B) is added to B2. (Recall that exactly the states in Pre(C) are marked.) We
then apply a standard graph algorithm to determine a reversed topological order s1, . . . , sk
of the nonexit states in B, i.e., B \ Bottom(B) = { s1, . . . , sk } and i > j whenever there
is a transition si →sj. Note that such a topological order exists since TS has no stutter
cycles.
It can be computed in O(M+|S|).
The nonexit states of B are traversed in
reversed topological order. On encountering state s = si for some 0 < i ⩽k, we perform
the following.
If s is unmarked, i.e., s ∈B \ Pre(C), the list Post(s) is traversed.
If
t ∈Post(s) ∩B1 is encountered for some t, then s is added to B1; otherwise, s is added to
B2. This is justiﬁed by the observation that
• either s is marked in which case s ∈B ∩Pre(C),
• or s is unmarked and s →t for some t ∈B1, in which case either t ∈Bottom(B) ∩
Pre(C) or t ∈{ s1, . . . , si−1 } and there exists a path fragment t . . . v consisting of
states in B1 with v ∈Bottom(B) ∩Pre(C).
If all states s ∈{ s1, . . . , sk } = B \ Bottom(B) have been considered, then B1 consists of
all states in B ∩Pre∗
Π(C), while B2 contains all states B \ Pre∗
Π(C).
The above yields that there is an algorithm with time complexity O(M) that checks

574
Equivalences and Abstraction
whether for a given partition Π there is a pair (B, C) of blocks in Π such that C is a
Π-splitter for C, and returns such a pair (B, C), if there is some. Moreover:
Lemma 7.142.
Time Complexity of the Reﬁnement Operator
Reﬁne≈(B, C) can be computed in time O(M).
Hence, each iteration in Algorithm 37 causes the cost O(M). As each iteration yields a
proper reﬁnement of the current partition Π, the number of iterations is at most |S|. We
conclude:
Theorem 7.143.
Time Complexity of Algorithm 37
The stutter bisimulation quotient of TS can be computed with Algorithm 37 in time O( |S|·
(|AP| + M) ), under the assumption that M ⩾|S|, where M is the number of edges in the
state graph G(TS).
Proof: The costs of computing the initial partition are O(|S|·|AP|). At most |S| iterations
take place. Each reﬁnement in an iteration is in O(M). Checking the loop condition can
also be done in O(M).
Although irrelevant for the asymptotic time complexity, the following observation can be
helpful in practice to increase the eﬃciency of the splitter search: it provides a criterion
to skip checking the Π-splitter-condition for certain blocks C.
Lemma 7.144.
Stability Criterion
Let TS be a ﬁnite transition system without stutter cycles and let Π and Π′ partitions such
that Π′ is ﬁner than Π and Bottom(Π) = Bottom(Π′). Then: there is no common block
C of Π and Π′ such that Π is stable for C, while Π′ is not.
Proof: By contraposition. Assume C ∈Π∩Π′ and C is a Π′-splitter for some block B′ ∈Π′,
and Π is stable for C. By Lemma 7.141, C ̸= B′, there exists s ∈B′ ∩Pre(C), and there
exists t ∈Bottom(B′) \ Pre(C). Since Π reﬁnes Π′, there exists a block B ∈Π which
subsumes B′. C ̸= B, since otherwise C = B′ as C ∈Π ∩Π′, and s ∈B ∩Pre(C). From
Bottom(Π) = Bottom(Π′), we derive that t ∈Bottom(B′) ⊆Bottom(B). By Lemma
7.141, C is a Π-splitter for B. This, however, contradicts the assumption that Π is stable
for C.

Stutter Bisimulation
575
Quotienting for Divergence-Sensitive Stutter Bisimulation
The computation of
the equivalence classes under ≈div is essentially based on the following steps. Let TS =
(S, Act, →, I, AP, L) be a ﬁnite transition system. As an initial step, TS is transformed
into a divergence-sensitive transition system TS such that the equivalence classes under ≈
in TS coincide with the equivalence classes under ≈div in TS. (Recall that TS is divergence-
sensitive if ≈TS is divergence-sensitive, and hence coincides with ≈div
TS .) Applying Algorithm
37 to TS then provides the quotient space S/≈div of TS.
The divergence-sensitive transition system TS is obtained as follows. TS is extended with
a new state sdiv that is not stutter-bisimilar to any other state in TS. This is established
by equipping sdiv with a unique label, div say. The goal is to deﬁne the transitions in TS
such that the ≈div
TS -divergent states of TS have a path fragment of the form s v1 . . . vm sdiv
in TS such that
s ≈div
TS
v1 ≈div
TS
. . . ≈div
TS
vm.
That is to say, the new state sdiv can only be reached from a ≈div
TS -divergent state. Since
TS is ﬁnite, every ≈div
TS -divergent path contains a cycle containing only states that are
equivalent under ≈div
TS . By Lemma 7.138 on page 570, these are exactly the stutter cycles!
So, TS is obtained from TS by inserting transitions from s to sdiv for any state s that lies
on a stutter cycle.
Deﬁnition 7.145.
Divergence-Sensitive Expansion TS
The divergence-sensitive expansion of ﬁnite transition system TS = (S, Act, →, I, AP, L)
is:
TS
= (S ∪{ sdiv }, Act ∪{ τ }, →, I, AP ∪{ div }, L)
where sdiv ̸∈S, →extends the transition relation of TS by the transitions sdiv
τ→sdiv and
s
τ→sdiv for every state s ∈S on a stutter cycle in TS, and L(s) = L(s) if s ∈S and
L(sdiv) = { div }.
Example 7.146.
Divergence-Sensitive Expansion
Consider the transition system TS over AP = { a } in Figure 7.49 (upper part).
Its
divergence-sensitive expansion is depicted below it. It is not diﬃcult to establish that
S/≈div
TS = { { s0, s1 }, { s2 }, { s3 } } = S/≈TS .
Hence, the ≈equivalence classes of TS with respect to AP = { a, div } correspond to the
equivalence classes of TS under ≈div for AP = { a }. Note that we ignored the stutter
bisimulation equivalence class { sdiv } in TS.
The following theorem shows that ≈div in TS coincides with ≈in TS.

576
Equivalences and Abstraction
s3
∅
s2
{ a }
s0
{ a }
s1
{ a }
s3
∅
s2
{ a }
s0
{ a }
s1
{ a }
sdiv
{ div }
Figure 7.49: Transition system TS (upper) and its divergence-sensitive expansion TS
(lower).
Theorem 7.147.
Connection between TS and TS
For ﬁnite transition system TS:
1. TS is divergence-sensitive, and
2. for all states s1, s2 ∈S: s1 ≈div
TS
s2
if and only if
s1 ≈TS s2.
Proof: We ﬁrst show that
R = {(s1, s2) ∈S × S | s1 ≈div
TS
s2 } ∪{ (sdiv, sdiv) }
is a stutter bisimulation for TS. Clearly, all states in R are equally labeled. It remains to
check that for (s1, s2) ∈R we have that s2 simulates transitions of s1. This is evident for
(sdiv, sdiv) ∈R; consider the remaining cases.
Let (s1, s2) ∈R and s′
1 ∈PostTS(s1) such that (s1, s′
1) ̸∈R. Distinguish two cases:
• If s′
1 ∈S (i.e., s′
1 ̸= sdiv), then s′
1 ∈PostTS(s1) and s1 ̸≈div
TS
s′
1. Since s1 ≈div
TS
s2,
there exists a path fragment s2 u1 . . . un s′
2 in TS with
s2 ≈div
TS
u1 ≈div
TS
. . . ≈div
TS
un
and
s′
1 ≈div
TS
s′
2.
Thus, s2 u1 . . . un s′
2 is a path fragment satisfying the property (s2, uj) ∈R, for
0 < j ⩽n, and (s′
1, s′
2) ∈R.

Stutter Bisimulation
577
• If s′
1 = sdiv, then s1 is on a stutter cycle in TS, and thus s1 is divergent.
As
s1 ≈div
TS
s2, state s2 is divergent. Since TS is ﬁnite, there exists a path fragment
s2 u1 . . . un such that
s2 ≈div
TS
u1 ≈div
TS
. . . ≈div
TS
un
where un is on a stutter cycle.
Therefore, un →sdiv is a transition in TS and
s2 u1 . . . un sdiv is a path fragment in TS that matches s1 →s′
1.
As a next step, we show that R = {(s1, s2) ∈S ×S | s1 ≈TS s2 } is a divergence-sensitive
stutter bisimulation for TS. Obviously, R only contains equally labeled states; condition
(2) of being a stutter bisimulation follows from the following reasoning:
• Let (s1, s2) ∈R and s′
1 ∈PostTS(s1) such that (s1, s′
1) /∈R. Then, s1 ≈TS s2,
s′
1 ∈PostTS(s1), and s1 ̸≈TS s′
1. Thus, there exists a path fragment s2 u1 . . . un s′
2 in
TS with
s2 ≈TS u1 ≈TS . . . ≈TS un
and
s′
1 ≈TS s′
2.
As s′
1 ̸= sdiv, we have s′
2 ̸= sdiv. Therefore, s2 u1 . . . un s′
2 is a path fragment in TS
that matches s1 →s′
1.
It remains to check the divergence sensitivity of R.
Let (s1, s2) ∈R such that s1 is
R-divergent. Then, there exists a path fragment s1 v1 . . . vm s′
1 u1 . . . un s′
1 such that:
s1 ≈TS v1 ≈TS . . . ≈TS vm ≈TS s′
1 ≈TS u1 ≈TS . . . ≈TS un
In particular, s′
1 is on a stutter cycle. Therefore, s′
1 →sdiv is a transition in TS. As
(s1, s2) ∈R, s1 ≈TS s2.
Together with s1 ≈TS
s′
1, we get s′
1 ≈TS
s2.
Moreover,
sdiv ∈PostTS(s′
1), and s′
1 ̸≈TS sdiv. Hence, there exists a path fragment s2 w1 . . . wk s′
2 sdiv
such that
s2
≈TS w1 ≈TS . . . ≈TS wk ≈TS s′
2
and
s′
2 →sdiv.
Note, since only state sdiv is labeled with div, if s ≈TS sdiv then s = sdiv.
Since s′
2 →sdiv is a transition in TS, s′
2 belongs to a stutter cycle s′
2 t1 . . . tℓs′
2. By Lemma
7.138 (page 570), s′
2 ≈TS t1 ≈TS . . . ≈TS tℓ. As s2 ≈TS s′
2, it follows that s2 is R-divergent.
Finally, we consider the divergence sensitivity of TS. By deﬁnition, TS is divergence-
sensitive if ≈TS is divergence-sensitive. This follows from the fact that ≈TS coincides with
≈div
TS .
Theorem 7.147 shows that the quotient space S/ ≈of transition system TS can be com-
puted by applying Algorithm 37 to the divergence-sensitive expansion TS. In order to

578
Equivalences and Abstraction
construct TS, all states on a stutter cycle must be determined, as these states need to
be equipped with a transition to sdiv.
This can be done by generating the nontrivial
SCCs in the digraph that is obtained from G(TS) by only considering stutter steps. Let
Gstutter(TS) = (V, E) with V = S, the state space of TS and E = { (s, t) ∈S × S | L(s) =
L(t) }.
Summarizing, the required steps to compute the quotient transition system TS/≈div are:
1. Construct the expansion TS by determining the SCCs in Gstutter(TS), and inserting
transitions s →sdiv and sdiv →sdiv for any state s in a nontrivial SCC of Gstutter.
2. Apply Algorithm 37 to TS to obtain the quotient space
S/≈div
TS = S/ ≈TS .
The transition system TS/≈is constructed as follows. Any C ∈S/≈div that contains
an initial state of TS is identiﬁed as initial state. The labeling of C ∈S/≈div equals
the labeling of any s ∈C.
All transitions s →s′ with s ̸≈div
TS
s′ are lifted to
transitions of the corresponding state classes.
3. TS/ ≈div is obtained from TS/ ≈as follows. The transitions s →sdiv in TS are
replaced by self-loops [s]div →[s]div, and the state sdiv is deleted.
Example 7.148.
Consider again the transition system TS over AP = { a } in Figure 7.49 (upper part) and
its divergence-sensitive expansion TS (see lower part of the same ﬁgure). The quotient
transition system TS/ ≈is depicted in Figure 7.50 (upper part).
The corresponding
transition system TS/ ≈is obtained by turning all transitions to [s]div into self-loops at
the source state, and deleting [s]div. This yields the transition system depicted in the
lower part of Figure 7.50.
The costs of the described technique are dominated by the costs of Algorithm 37 and the
computation of the SCCs in digraph Gstutter. Theorem 7.143 on page 574 yields:
Theorem 7.149.
Time Complexity of Constructing TS/≈div
The quotient space of TS under ≈div can be computed in time O( (|S|+M) + |S|·(|AP|+
M) ), under the assumption that M ⩾|S|, where M denotes the number of edges in the
state graph G(TS).

Summary
579
[s3]≈
∅
[s2]≈
{ a }
[s0]≈
{ a }
transition system TS/≈
[sdiv]≈
{ div }
[s3]≈
∅
[s2]≈
{ a }
[s0]≈
{ a }
transition system TS/≈div
Figure 7.50: Example of computing the quotient system under ≈div.
7.9
Summary
• A bisimulation equivalence only relates a pair of states if both states are equally
labeled and can mutually mimic their outgoing transitions. In a simulation preorder
it suﬃces that one state can mimic the other, but not necessarily the reverse.
• Bisimulation is strictly ﬁner than simulation equivalence and trace equivalence.
• In general, simulation and trace equivalence are incomparable. For transition sys-
tems without terminal states, simulation equivalence is strictly ﬁner than trace equiv-
alence.
• For AP-deterministic transition systems, bisimulation, simulation, and trace equiv-
alence coincide.
• Bisimulation equivalence and the simulation order can be computed for ﬁnite transi-
tion systems in polynomial time. The problem of checking trace equivalence or trace
inclusion is PSPACE-complete.
• For ﬁnite transition systems without terminal states, bisimulation equivalence cor-
responds to CTL∗and CTL equivalence. (This result is considerable, since CTL∗
includes the two incomparable logics CTL and LTL.)
• A logical characterization of the simulation preorder can be provided by the universal
or the existential fragments of CTL∗and CTL.
• Stutter trace equivalence is a variant of trace equivalence that abstracts from stut-
ter steps, i.e, transitions between equally labeled states. It coincides with LTL\⃝
equivalence.

580
Equivalences and Abstraction
• Stutter bisimulation is a variant of bisimulation where transitions can be mimicked
by path fragments (rather than by single transitions). It is incomparable to stutter
trace equivalence.
• A state is divergent if a path consisting only of stutter steps emanates from it.
Divergence-sensitive stutter bisimulation is a stutter bisimulation that distinguishes
divergent from nondivergent states.
• Divergence-sensitive stutter bisimulation is strictly ﬁner than stutter trace equiva-
lence and coincides with CTL∗
\⃝- and CTL\⃝equivalence.
• Divergence-sensitive bisimulation can be computed for ﬁnite transition systems in
polynomial time.
Figure 7.51 on page 580 summarizes the results concerning the treated notions of bisim-
ulation. For the sake of simplicity, the costs of the initialization phase of the quotienting
algorithms have been omitted.
bisimulation
simulation
stutter
trace
equivalence
order
equivalence
equivalence
with divergence
preservation of
CTL∗
∀CTL∗/∃CTL∗
CTL∗
\⃝
LTL
temporal-logical
CTL
∀CTL/∃CTL
CTL\⃝
(LT properties)
properties
checking
PTIME
PTIME
PTIME
PSPACE-
equivalence
complete
graph
PTIME
PTIME
PTIME
—
minimization
O(M· log |S|)
O(M·|S|)
O(M·|S|)
Figure 7.51: Overview of equivalences on transition systems.
7.10
Bibliographic Notes
Bisimulation and simulation. The notions of bisimulation and simulation in this chapter
are state-based versions of the action-based bisimulation and simulation. Action-based

Bibliographic Notes
581
bisimulation has been brought up independently by Milner [296] and Park [322]. Action-
based simulation originates from Milner [295]. Milner [296] also introduced observational
bisimulation, a weak bisimulation that abstracts away from internal steps (i.e., τ-labeled
transitions). (Exercise 7.22 considers a state-based variant of observational equivalence.)
Stutter bisimulation is the state-based variant of branching bisimulation introduced by van
Glabbeek and Weijland [406]. As noticed by Groote and Vaandrager [176], divergence-
sensitive stutter bisimulation coincides with stutter equivalence introduced by Browne,
Clarke and Grumberg [67]. The alternative characterizations of stutter bisimulation by
norm functions for ﬁnite and inﬁnite transition systems is due to Namjoshi [311]. (The-
orem 7.126 treats only ﬁnite transition systems.) Griﬃoen and Vaandrager [175] apply a
(slightly) diﬀerent notion of norm functions to deﬁne simulation relations. A comprehen-
sive comparison of various trace-based and (bi)simulation relations has been provided by
van Glabbeek [404, 405]. The concept of bisimulation and simulation relations has been
reﬁned and studied in various directions (such as axiomatization, reﬁnement, coinduction,
domain theoretic approaches); see, e.g., [298, 1, 4, 279, 397, 101]. The use of simulation
relations for abstraction has been studied in, e.g., [90, 277, 133, 109, 105].
Logical characterizations.
The ﬁrst logical characterization of bisimulation equivalence
has been provided in the action-based setting by Hennessy and Milner [197] for a modal
logic, called Hennessy-Milner logic, with an action-labeled next step operator. Browne,
Clarke and Grumberg [67] showed that state-based bisimulation coincides with CTL- and
CTL∗equivalence; see Theorem 7.20, and the analogous result for divergence-sensitive
stutter bisimulation and CTL\⃝/CTL∗
\⃝; see Theorem 7.128. Kucera and Schnoebelen
[247] recently presented a reﬁnement of the latter result. De Nicola and Vaandrager [314]
studied the connection between temporal logics and variants of stutter bisimulation in
the action- and state-based setting. The logical characterizations of the simulation order
by means of the existential and universal fragment of CTL and CTL∗is due to Clarke,
Grumberg and Long [90]. The observation that any LTL formula which induces a stutter-
insensitive LT property can be expressed in LTL\⃝(see Exercise 7.20) is by Peled and
Wilke [329]; see also Etessami [147].
Etessami [146] deﬁned a variant LTL that is as
expressive as stutter-invariant ω-regular languages.
Quotienting algorithms. The ﬁrst partition reﬁnement algorithm for bisimulation is due
to Kanellakis and Smolka [231]. The reﬁned version with the ternary reﬁnement oper-
ator (see Algorithm 32) originates from Paige and Tarjan [318]. Kanellakis and Smolka
[231] also showed that the trace equivalence problem is PSPACE-complete; see Theorem
7.46. The initial algorithm for calculating the simulation order has been suggested by
Cleaveland, Parrow, and Steﬀen [97]. Henzinger, Henzinger, and Kopke [198] developed a
more eﬃcient algorithm; see Algorithm 36. Other algorithms for computing the simulation
order have been suggested by, among others, Tan and Cleaveland [385] and Bustan and
Grumberg [76]. A survey of bisimulation- and simulation-quotienting algorithms has been

582
Equivalences and Abstraction
given by Cleaveland and Sokolsky [98]. The quotienting algorithms for stutter bisimulation
quotient (see Algorithm 37) go back to Groote and Vaandrager [176]. Moller and Smolka
[302] discuss the computational complexity of checking the bisimilarity of several classes
of processes. Thanks to extensive studies by Fisler and Vardi [152, 153, 154], it is known
that bisimulation minimization for LTL model checking and invariant veriﬁcation leads
to drastic state space reductions (up to logarithmic savings) but at a time penalty: the
time to minimize and model-check the resulting quotient signiﬁcantly exceeds the time to
verify the original transition system. In this monograph, we considered quotienting algo-
rithms for ﬁnite transition systems. Semialgorithms for bisimulation quotienting of inﬁnite
transition systems (provided the bisimulation quotient is ﬁnite) have been presented by
Bouajjani, Fernandez, and Halbwachs [60] and Lee and Yannakakis [266]. Henzinger, Hen-
zinger, and Kopke [198] introduced a semialgorithmic approach for the simulation order to
treat inﬁnite state spaces. A classiﬁcation and algorithms for inﬁnite systems with ﬁnite
quotients for other equivalences have been given by Henzinger, Majumdar, and Raskin
[199].
For further reading we refer to the Handbook of Process Algebra [46] (and the literature
mentioned therein) which treats many aspects of (bi)simulations and other implementation
relations.
7.11
Exercises
Exercise 7.1.
Consider the four transition systems in Figure 7.52. Determine for each pair
(TSi, TSj) for 0 < i ̸= j ⩽4 of these transition systems whether they are bisimilar. Justify your
answer by either providing the bisimulation relation for (TSi, TSj) or a CTL formula Φ such that
TSi |= Φ and TSj ̸|= Φ.
Exercise 7.2.
Let TS be a transition system.
(a) Show that the union of bisimulation relations for TS is a bisimulation for TS.
(b) Show that the union of simulation relations for TS is a simulation for TS.
Exercise 7.3.
The goal of this exercise is to discuss the role of AP-determinism (see Deﬁnition
7.65) for the connection between (bi)simulation and trace relations. In particular, this exrecise
completes the proofs for Theorem 7.64 on page 511 and Corollary 7.72 on page 514.
Suppose that TS1 and TS2 are transition systems over AP that are both AP-deterministic.

Exercises
583
s1
{ a }
s2
{ a, b }
s3
{ a, b }
s4
{ a, b }
s5
∅
s6
∅
transition system TS1
t1
{ a }
t3
{ a, b }
t4
∅
transition system TS2
t2
{ a, b }
u1
{ a }
u4
{ a, b }
u6
∅
u2
{ a }
u5
{ a, b }
u7
∅
transition system TS3
u3
{ a, b }
v5
∅
v6
{ a, b }
v7
{ a }
v8
{ a }
transition system TS4
v4
{ a, b }
v1
{ a }
v3
∅
v2
{ a, b }
Figure 7.52: Four transition systems for Exercises 7.1, 7.11, 7.17, 7.21 and 7.22.
(a) Prove the equivalence of the following statements (1), (2), (3) and (4):
(1) TS1 ∼TS2
(2) TS1 ≃TS2
(3) Tracesﬁn(TS1) = Tracesﬁn(TS2)
(4) Traces(TS1) = Traces(TS2)
(b) Prove or disprove: If Tracesﬁn(TS1) ⊆Tracesﬁn(TS2) then TS1 ⪯TS2.
(c) Prove or disprove: If TS1 ⪯TS2 then Traces(TS1) ⊆Traces(TS2).
(d) Prove or disprove: If Tracesﬁn(TS1) ⊆Tracesﬁn(TS2) then Traces(TS1) ⊆Traces(TS2).
Exercise 7.4.
Let TS = (S, Act, →, I, AP, L) be a transition system. The relations ∼n⊆S × S
are inductively deﬁned by:

584
Equivalences and Abstraction
(a) s1 ∼0 s2 iﬀL(s1) = L(s2).
(b) s1 ∼n+1 s2 iﬀ
(i) L(s1) = L(s2),
(ii) for all s′
1 ∈Post(s1) there exists s′
2 ∈Post(s2) with s′
1 ∼n s′
2,
(iii) for all s′
2 ∈Post(s2) there exists s′
1 ∈Post(s1) with s′
1 ∼n s′
2.
Show that for ﬁnite TS it holds that ∼TS =
+
n⩾0
∼n, i.e.,
s1 ∼TS s2 if and only if s1 ∼n s2 for all n ⩾0.
Does this also hold for inﬁnite transition systems?
Exercise 7.5.
(a) Consider transition system TS shown in Figure 7.53. Apply the transformation TS →TSact
(see page 467) and check that ∼TS coincides with action-based bisimulation ∼Act
TSact on TSact.
s0
{a}
s2
s1
s4
s3
s5
s7
s6
∅
{b}
∅
{b}
∅
{b}
{a}
Figure 7.53: Transition system TS for Exercise 7.5.
(b) Prove that for all states s1, s2 in TS,
s1 ∼Act
TS
s2 if and only if s1 ∼TSstate s2
where TSstate is obtained from TS by the transformation deﬁned on page 467.

Exercises
585
Exercise 7.6.
(a) Give a transition system TS without terminal states and containing states s1, s2 of TS such
that s1 ̸≡LTL s2 and there is no LTL formula ϕ with s2 |= ϕ and s1 ̸|= ϕ. (See the remark
on page 469.)
(b) Let TS1 and TS2 be transition systems over AP without terminal states such that TS1 ̸≡CLT
TS2. Prove or disprove the claim: there exists a CTL formula Φ over AP such that TS1 |= Φ
and TS2 ̸|= Φ.
s1
s2
s3
s4
s5
s6
s7
s8
s9
s10
s11
s12
s13
{a}
{a}
{a}
{a}
{a}
{a, b}
{a, b}
{a, b}
{a, b}
{a, b}
{a, b}
∅
∅
Figure 7.54: Transition system TS for Exercises 7.7, 7.8 and 7.23.
Exercise 7.7.
Consider the transition system TS over AP = { a, b } shown in Figure 7.54.
(a) Determine the bisimulation equivalence ∼TS and depict the bisimulation quotient system
TS/∼.
(b) Provide CTL master formulae ΦC for each bisimulation equivalence class C.
Exercise 7.8.
Consider again the transition system TS with state space S = {s1, s2, . . . , s13}
shown in Figure 7.54. Apply Algorithms 31 and 32 to compute the bisimulation quotient S/ ∼TS.
Exercise 7.9.
Let TS be a ﬁnite transition system over AP without terminal states. Provide an
algorithm that computes for each bisimulation equivalence class C a CTL master formula (i.e., a
CTL formula ΦC with Sat(ΦC) = C).
(Hint: There is a simple algorithm which relies on an extension of the partition reﬁnement tech-
nique).
Exercise 7.10.
Consider the transition systems TS1 and TS2 shown in Figure 7.55. Apply
Algorithms 31 (page 487) and 32 (page 489) to check whether TS1 ∼TS2.

586
Equivalences and Abstraction
s1
∅
s2
s3
s4
s5
s6
u1
u2
u3
u4
u5
u6
∅
∅
∅
{a}
{a}
{a}
{a}
{a}
{a}
{a}
{a}
Figure 7.55: Are TS1 (left) and TS2 (right) bisimilar (Exercise 7.10)?
Exercise 7.11.
Consider the four transition systems TS1, TS2, TS3, TS4 in Figure 7.52 on page
583. Check whether TSi ⪯TSj and TSi ≃TSj for all indices i, j. Justify your answer by either
establishing a simulation for (TSi, TSj) or by providing a ∀CTL formula Φ with TSj |= Φ and
TSi ̸|= Φ (if TSi ̸⪯TSj).
Exercise 7.12.
Consider the transition systems TS1 (left) and TS2 (right) in Figure 7.56.
(a) Show that TS2 ⪯TS1 by providing a simulation relation for (TS2, TS1).
(b) Show that TS1 ̸⪯TS2 by providing a ∀CTL formula Φ∀and a ∃CTL formula Φ∃such that
TS1 ̸|= Φ∀, but TS2 |= Φ∀and TS1 |= Φ∃, but TS2 ̸|= Φ∃.
∅
{a}
s1
t1
v1
s2
t2
v2
∅
∅
∅
{a}
TS2 :
TS1 :
Figure 7.56: TS2 ⪯TS1, but TS1 ̸⪯TS2 (Exercise 7.12).
Exercise 7.13.
Consider the transition systems TS1 (left) and TS2 (right) in Figure 7.57.
(a) Check whether TS1 ⪯TS2, TS2 ⪯TS1 or TS1 ≃TS2.

Exercises
587
∅
{a}
s1
t1
t′
1
u1
v1
v′
1
s2
t2
u2
v2
∅
∅
{a}
{a}
{a}
{a}
{c}
{c}
Figure 7.57: Transition systems TS1 (left) and TS2 (right) for Exercise 7.13.
(b) Consider the composite transition system TS = TS1 ⊕TS2. Depict the simulation quotient
system TS/⪯and verify that TS/⪯and TS are simulation equivalent, but not bisimilar.
Exercise 7.14.
Complete the proof of Theorem 7.76 by showing the correctness of the following
two statements (a) and (b):
(a) If s1 and s2 are states in TS with s1 ⪯TS s2 then for all ∀CTL∗state formulae Φ: s2 |= Φ
implies s1 |= Φ.
(b) If π1 = s0,1 s1,1 s2,i . . . and π1 = s0,2 s1,2 s2,2 . . . inﬁnite path fragments in TS such that
sj,1 ⪯TS sj,2 for all j ⩾0 then for all ∀CTL∗path formulae ϕ: π2 |= ϕ implies π1 |= ϕ.
Exercise 7.15.
Indicate for each of the following claims whether it is a correct statement for
ﬁnite transition systems:
(a) ∀CTL equivalence is ﬁner than LTL equivalence.
(b) LTL equivalence is ﬁner than ∀CTL equivalence.
(c) ∃CTL equivalence is ﬁner than ∀CTL equivalence.
(d) ∃CTL equivalence is ﬁner than LTL equivalence.
(e) ∃CTL∗equivalence is ﬁner than CTL equivalence.
Justify your answers.

588
Equivalences and Abstraction
{a}
s1
∅
s2
s3
u1
u2
v1
t1
t2
{a}
{a}
{a, b}
{b}
{b}
∅
Figure 7.58: Transition system TS over AP = {a, b} for Exercise 7.16.
Exercise 7.16.
Consider the transition system TS as depicted in Figure 7.58. The initial states
are irrelevant and have been omitted. Apply Algorithm 36 (page 526) to compute the simulation
order ⪯TS.
Exercise 7.17.
Which of the transition systems in Figure 7.52 on page 583 are stutter trace
equivalent?
Exercise 7.18.
Consider the transition systems depicted below, where the gray ﬁlling of a state
indicates the propositions that hold in that state.
s1
s5
s2
t3
t2
t1
u1
u2
u5
u3
u4
TS1
TS2
TS3
{a}
{b}
s3
s4
For each i, j ∈{ 1 . . . 3 }×{ 1 . . .3 }, i ̸= j, determine whether TSi ∼= TSj, TSi ⊑TSj or TSi ̸⊑TSj.
Justify your answer.
Exercise 7.19.
Consider the transition systems depicted below, where the gray ﬁlling of a state
indicates the propositions that are hold in that state.

Exercises
589
s2
s3
s4
TS1
s6
s6
s5
s1
s10
s9
s9
s8
s7
s7
s11
TS3
t1
t4
t2
t7
t7
t5
t6
t8
t3
t3
TS2
v1
v1
v4
v3
v8
v8
v7
v7
v9
v2
v2
v5
{ a, b }
{ a }
{ b }
{ c }
For each i, j ∈{ 1 . . .3 } × { 1 . . . 3 }, i ̸= j, determine whether TSi ≈TSj or TSi ̸≈TSj. Justify
your answer.
Exercise 7.20.
Let ϕ be an LTL formula such that Words(ϕ) is stutter-insensitive. Show that
ϕ is equivalent to some LTL\⃝formula ψ.
Exercise 7.21.
Which of the transition systems in Figure 7.52 on page 583 are stutter bisimu-
lation equivalent?
Exercise 7.22.
Observational equivalence ≈obs is a slight variant of stutter bisimulation equiv-
alence where state s2 is allowed to perform a path fragment
s2 u1 . . . um



stutter steps
v1 . . . vk s′
2



stutter steps
with arbitrary stutter steps at the beginning and at the end and s′
1 ≈obs s′
2 to simulate a transition
s1 →s′
1 of an observational equivalent state s1. I.e., it is not required that s2 and states ui are
observationally equivalent, or that s′
2 and vi are observationally equivalent. For the special case
where s1 →s′
1 is a stutter step the path fragment of length 0 (consisting of state s2 = s′
2) can be
used to simulate s1 →s′
1.
The formal deﬁnition of observational equivalence is as follows. Let TS1 and TS2 be two transition
systems over AP with state spaces S1 and S2, respectively. A binary relation R ⊆S1 × S2 is an
observational bisimulation for (TS1, TS2) iﬀthe following conditions are satisﬁed:
(A) Every initial state of TS1 is related to an initial state of TS2, and vice versa. That is,
∀s1 ∈I1 ∃s2 ∈I2. (s1, s2) ∈R
and ∀s2 ∈I2 ∃s1 ∈I1. (s1, s2) ∈R

590
Equivalences and Abstraction
(B) For all (s1, s2) ∈R the following conditions (1), (2) and (3) hold:
(1) If (s1, s2) ∈R then L1(s1) = L2(s2)
(2) If (s1, s2) ∈R and s′
1 ∈Post(s1) then there exists a path fragment u0 u1 . . . un such that
n ⩾0 and u0 = s2, (s′
1, un) ∈R and, for some m ⩽n, L2(u0) = L2(u1) = . . . = L2(um)
and L2(um+1) = L2(um+2) = . . . = L2(un).
(3) If (s1, s2) ∈R and s′
2 ∈Post(s1) then there exists a path fragment u0 u1 . . . un such that
n ⩾0 and u0 = s2, (un, s′
2) ∈R and, for some m ⩽n, L1(u0) = L1(u1) = . . . = L1(um)
and L1(um+1) = L1(um+2) = . . . = L1(un).
TS1 and TS2 are called observational-equivalent, denoted TS1 ≈obs TS2, if there exists an obser-
vational bisimulation for (TS1, TS2).
(a) Which of the transition systems in Figure 7.52 on page 583 are observational-equivalent?
(b) Show that TS1 ≈TS2 implies TS1 ≈obs TS2.
(c) Consider the two transition system TS1 (left) and TS2 (right) shown in Figure 7.59 where
the colors stand for the state labels, e.g., we may deal with L1(si) = L2(tj) = {a} for i ∈
{1, 2, 3, 4} and j ∈{1, 2, 4} and L1(s6) = L2(t6) = ∅and L1(s7) = L1(s5) = L2(t7) = {b}.
s1
s2
s3
s4
s5
s6
s7
t1
t2
t3
t4
t5
TS1
TS2
{a}
{b}
∅
Figure 7.59: Transition systems TS1 (left) and TS2 (right) for Exercise 7.22.
Show that TS1 ̸≈TS2 and TS1 ≈obs TS2.

Exercises
591
Exercise 7.23.
Consider the transition system TS shown in Figure 7.54 on page 585.
(a) Which states of TS are stutter-bisimilar (according to ≈TS)? Depict the stutter bisimulation
quotient system TS/ ≈.
(b) Which states of TS are divergence stutter bisimilar? Justify the equivalence of states (ac-
cording to ≈div
TS ) by providing a step-dependent norm function. Depict the quotient system
TS/ ≈div under stutter bisimulation equivalence with divergence.
(c) Depict the divergence-sensitive expansion TS and apply Algorithm 37 to compute the diver-
gence stutter bisimulation equivalence classes.
(d) Provide CTL\⃝master formulae for the divergence stutter bisimulation equivalence classes.
Exercise 7.24.
Let TS be a transition system with state space S. Deﬁne functions ν∗
1, ν∗
2 :
S × S →IN such that (≈n
TS, ν∗
1, ν∗
2) is a normed bisimulation for TS.
Exercise 7.25.
Provide an example for a transition system TS where ≈n
TS (normed bisimulation
equivalence) is strictly ﬁner than ≈div
TS .
Exercise 7.26.
Provide the proof for Lemma 7.96 (page 537).
Exercise 7.27.
Let CTL\ U be the sublogic of CTL that does not permit the until operator.
Similarly, CTL∗
\ U means CTL without U . Which of the following statements are correct for ﬁnite
transition systems?
(a) CTL\ U equivalence is ﬁner than CTL\⃝equivalence.
(b) CTL\ U equivalence is ﬁner than divergence-sensitive stutter trace equivalence.
(c) CTL\⃝equivalence is ﬁner than LTL\⃝equivalence.
(d) Divergence-sensitive stutter bisimulation equivalence is ﬁner than CTL\ U equivalence.
(e) Stutter trace equivalence is ﬁner than CTL\ U equivalence.
(f) For AP-deterministic transition systems, stutter trace equivalence is ﬁner than trace-equivalence.
(g) For AP-deterministic transition systems, trace equivalence is ﬁner than CTL∗
\ U equivalence.
Exercise 7.28.
Check the correctness of the following statement. If TS1 and TS2 are stutter-
bisimilar transition systems over AP that are divergence-sensitive then TS1 ≈div TS2. Provide
either a proof or a counterexample.

592
Equivalences and Abstraction
Exercise 7.29. Let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, 2, be two transition systems. A stutter
simulation for (TS1, TS2) is a relation R ⊆S1 × S2 such that
(A) Each initial state of TS1 is R-related to an initial state of TS2, that is, ∀s1 ∈I1 ∃s2 ∈
I2. (s1, s2) ∈R.
(B) For all (s1, s2) ∈R the following conditions (1) and (2) hold:
(1) L1(s1) = L2(s2).
(2) If s′
1 ∈Post(s1) with (s1, s′
1) ̸∈R, then there exists a ﬁnite path fragment s2 u1 . . . un s′
2
with n ⩾0 and (s1, ui) ∈R, i = 1, . . . , n and (s′
1, s′
2) ∈R.
TS1 is said to be stutter-simulated by TS2, denoted TS1⪯stTS2, iﬀthere exists a stutter simulation
for (TS1, TS2).
(a) Provide an example for transition systems TS1, TS2 such that TS1 is not simulated by TS2,
but TS1⪯stTS2.
(b) Provide an example for transition systems TS1, TS2 such that TS1 ⊴TS2 and TS1 ̸⪯st TS2.
(c) Provide an example for transition systems TS1, TS2 such that TS1¬ ⊴TS2 and TS1⪯stTS2.
(d) Provide an example for transition systems TS1, TS2 such that TS1 ̸≈TS2, while TS1⪯stTS2
and TS2⪯stTS1.
A stutter simulation R for (TS1, TS2) is called divergence-sensitive if for all pairs (s1, s2) ∈R and
each inﬁnite path fragment π1 = s0,1 s1,1 s2,1 . . . in TS1 with s0,1 = s1 and (si,1, s2) ∈R for all
i ⩾0 there exists a transition s′
2 ∈Post(s2) with (sj,1, s′
2) ∈R for some j ⩾1. We write
TS1 ⪯div
st
TS2
iﬀthere exists a divergence-sensitive stutter simulation R for (TS1, TS2).
(e) Provide an example for transition systems TS1, TS2 such that TS1 ̸≈div TS2, while TS1⪯div
st TS2
and TS2⪯div
st TS1.
(f) Show that TS1 ≈div TS2 if and only if there exists a divergence-sensitive stutter simulation
R for (TS1, TS2) such that R−1 = { (s2, s1) | (s1, s2) ∈R } is a divergence-sensitive stutter
simulation for (TS2, TS1).
(g) Show that TS1 ≈div TS2 implies divergence stutter simulation equivalence of TS1 and TS2,
i.e., TS1 ⪯div
st
TS2 and TS2 ⪯div
st
TS1.
Show that the universal fragment of CTL∗
\⃝yields a logical characterization of the stutter simula-
tion order with divergence. For this, provide proofs for the following statements (h) and (i) where
TS1 and TS2 are supposed to be ﬁnite transition systems without terminal states.

Exercises
593
(h) If TS1 ⪯div
st
TS2 and Φ is a ∀CTL∗
\⃝formula with TS2 |= Φ, then TS1 |= Φ.
(i) Assume that for all ∀CTL∗
\⃝formulae Φ we have TS2 |= ¬Φ or TS1 |= Φ.
Show that
TS1 ⪯div
st
TS2.
Exercise 7.30.
Consider the following transition system TS:
s1
s2
s3
s4
s5
s6
s7
s8
u1
u2
u3
u4
u5
v1
v2
{ a }
{ b }
{ c }
Questions:
(a) Give the divergence-sensitive expansion TS.
(b) Determine the divergence stutter bisimulation quotient (TS)/ ≈. Give for each iteration the
partition of the state space.
(c) Give TS/≈div.
(d) Provide CTL\⃝master formulae for each divergence stutter bisimulation equivalence class.


Chapter 8
Partial Order Reduction
Consider the parallel composition of a number of processes P1 through Pn. The size of
the state space of P1∥P2∥. . . ∥Pn, where ∥denotes some parallel composition operator, is
exponential in the number n of processes. To check the validity of a linear-time property
of this system requires an inspection of all states in the underlying transition system. In
the simple setting where there are no synchronizations between the individual processes—
neither through shared variables nor via communication channels or the like—there are n!
diﬀerent orderings of the interleaved execution of n local actions. The eﬀect of concurrent
actions, however, is often independent of their ordering. Consider, e.g., the assignments
_
`
s
t
u
v
_
`
Figure 8.1: Interleaving diamond for α ||| β.
x := x+1 and y := y−3 in the concurrent system P1 ||| P2, where x is a local variable of P1,
say, and y of P2, and ||| denotes the interleaving operator. It is evident that regardless of
the ordering of these assignments, the result will be the same. This is illustrated in Figure
595

596
Partial Order Reduction
8.1, where actions α and β denote the assignments of P1 and P2, respectively. Instead of
analyzing the 2! orderings of x := x+1 and y := y−3 it may suﬃce to check just a single
ordering. This is correct as long as the intermediate states reached after the execution
of either α or β (see states t and u in Figure 8.1), are irrelevant for the properties to
be proved. Extending the simple example with a third process P3 that, e.g., resets its
variable z to 0, yields following an analogous reasoning that it suﬃces to consider just
one of the 3! possible orderings. This approach can be generalized for action sequences
α1 α2 . . . αn and β1 β2 . . . βm that are executed independently by processes P1 and P2. The
transition system of P1 ||| P2 represents all interleavings of these action sequences, whereas
a single path fragment respecting the ordering in these sequences suﬃces, provided the
intermediate states are irrelevant.
Put in a nutshell, the aim of partial order reduction, the technique that is treated in
this chapter, is to reduce the number of possible orderings that need to be analyzed for
checking formulae stated in a temporal logic such as LTL or CTL∗. This main concept is
to reduce the state space of the transition system that needs to be analyzed. Thus, the
idea is to replace the full transition system for P1 ||| P2 ||| . . . ||| Pn by a small fragment.
Figure 8.2 illustrates this for two processes that execute the action sequences α1 α2 and
β1 β2, respectively. The transition system on the left contains all possible interleavings,
while the reduced transition system on the right just consists a single path that might serve
as a representative for all possible interleavings. On increasing the number of concurrent
processes, this eﬀect becomes even more drastic—the size of the full transition system
grows exponentially in the number of processes, whereas the reduced system consists of a
single path that grows linear in n.
_1
_1
_1
`1
`1
`1
_2
_2
_2
`2
`2
`2
_1
`1
_2
`2
Figure 8.2: Parallel execution (α1 ; α2) ||| (β1 ; β2).
To avoid peak memory requirements, such a reduced transition system is obtained without

Partial Order Reduction
597
the necessity of ever generating the entire transition system that incorporates all possible
orderings. This is typically done by a static analysis of the high-level description of the
concurrent system, e.g., the channel systems as introduced in Chapter 2.
Clearly, the reduction technique crucially relies on the assumption that all processes are
fully autonomous, i.e., no synchronizations are involved via, e.g., shared variables or com-
munication channels. Moreover, it is assumed that the property of interest does not depend
on the intermediate states. To treat realistic systems where the processes may communi-
cate and thus depend on one another, the partial order reduction approach attempts to
identify path fragments of the full transition system which only diﬀer in the order of the
concurrently executed activities. Since such path fragments represent the same behavior,
it seems obvious to restrict the analysis of state space to one (or a few) representatives of
every possible interleaving.
Central for the partial order reduction approach is the notion of independent actions which
will be introduced in Section 8.1. Section 8.2 treats the partial order reduction approach
for model-checking LT properties that are speciﬁed by LTL\⃝formulae. Section 8.3 deals
with partial order reduction for CTL\⃝and CTL∗
\⃝. The intuition behind the omission of
the next step operator is that we have to abstract away from certain intermediate states,
as we sketched for the reduction in Figure 8.2.
Throughout this chapter TS = (S, Act, →, I, AP, L) is a ﬁnite transition system without
terminal states. As partial order reduction is most eﬀective for concurrent systems that
are “loosely” coupled, it is implicitly assumed that TS models an asynchronous concurrent
system where processes interact, e.g., either by shared variables or channel communication.
In a synchronous setting where concurrent processes evolve in a lockstep fashion, each
global transition involves all processes and thus cannot be considered as independent.
This assumption is not relevant for the theoretical considerations in this chapter, but is
important when considering static analysis of concurrent programs to enable the detection
of independent actions syntactically.
It is assumed that TS is action-deterministic. This entails that for any state s ∈S and
any action α ∈Act, s has at most one outgoing transition with action label α. Formally,
s
α
−−→s′ and s
α
−−→s′′ implies s′ = s′′. (The reader should not confuse this notion with AP-
determinism.) The assumption that TS is action-deterministic is not a severe restriction,
since actions can always be renamed such that an action-deterministic transition system
results. When, e.g., TS results from the parallel composition of several action-deterministic
processes, indices may be used for the actions to indicate which process performs the
action.

598
Partial Order Reduction
8.1
Independence of Actions
Let us ﬁrst introduce some notations that are used throughout the remainder of this
chapter.
Notation 8.1.
The Set of Actions Act(s)
For state s in transition system TS with action set Act, let Act(s) = { α ∈Act |
∃s′. s
α
−−→s′ }.
Thus, Act(s) denotes the set of actions that are enabled in state s.
Since an action-
deterministic transition system is assumed, for any α ∈Act(s) there is a unique α-successor
of s, denoted by α(s).
Notation 8.2.
The States α(s)
For action-deterministic transition system TS, s a state in TS and α ∈Act(s), let α(s)
denote the unique α-successor of s, i.e., s
α
−−→α(s). For action sequence α1 . . . αn with
α1 ∈Act(s) and αi+1 ∈Act(si) where si = αi(si−1) for 1 < i ⩽n, (α1 . . . αn)(s) denotes
sn, the state that is reached from s by performing α1 . . . αn.
In Figure 8.1, e.g., Act(s) = { α, β }, t = β(s) and u = α(s). Moreover, v = (β α)(s) and
v = (α β)(s).
The notion of independence of actions plays a central role in partial order reduction. As
we will describe later, the transition system TS is reduced by omitting the redundancies
in TS that are caused by the diﬀerent orderings of independent actions. Intuitively, the
pair of actions α and β with α ̸= β is independent when these actions access disjoint
variables. In this case, the eﬀect of executing α β or β α is the same. Actions α and
β are also independent when they represent actions of diﬀerent processes such that one
of these actions only operates on local variables. Actions within a process may also be
independent, viz. when their order of execution is irrelevant.
The characteristic feature of the independence of actions α and β is their commutativity
which asserts that the eﬀect of the execution orders α β and β α is the same. This means
that if α and β are enabled in state s,
• the execution of action α cannot disable β, and vice versa, and
• the action sequences α β and β α executed in s yield the same state.

Independence of Actions
599
These properties are characteristic for the interleaving diamond (see Figure 8.1 on page
595).
Deﬁnition 8.3.
Independence of Actions
Let TS = (S, Act, →, I, AP, L) be an action-deterministic transition system with α, β ∈
Act, α ̸= β.
1. α and β are independent (in TS) if for any s ∈S with α, β ∈Act(s):
β ∈Act(α(s))
and
α ∈Act(β(s))
and
α(β(s)) = β(α(s)).
2. α and β are dependent (in TS) if α and β are not independent in TS.
As in most cases the transition system TS is ﬁxed, the part (in TS) is often omitted. The
notions of dependence and independence can be lifted to relations between actions and
sets of actions as follows. For A ⊆Act and β ∈Act \ A, β is independent of A (in TS) if
for any α ∈A, β is independent of α (in TS). β is dependent on A in TS if β ∈Act \ A
and β and α are dependent in TS for some α ∈A.
Example 8.4.
Independence of Actions (Parallel Operator ∥H)
Let TS1, TS2 be two action-deterministic transition systems with action sets Act1 and
Act2, respectively, and H = Act1 ∩Act2. The actions α ∈Act1 \ H and β ∈Act2 \ H are
independent in TS1∥HTS2. (The handshaking operator ∥H has been deﬁned on page 48.)
When H = ∅, all actions of TS1 are independent of the actions of TS2.
Example 8.5.
Independence of Actions (Program Graphs)
Consider the program graphs PG1 and PG2 and assume they do not communicate over
channels.
The actions α and β, by means of which at least one of the two processes
accesses local variables only, are independent in TS(PG1 ||| PG2), the transition system
underlying the parallel composition of PG1 and PG2.
More precisely, we impose the
following condition.
Let α be an action only appearing in PG1 such that for variable
valuation η:
• Eﬀect(α, η)(x) = η(x) for all variables x accessed by PG2, and

600
Partial Order Reduction
• for any edge ℓ
g:α

→ℓ′ in PG1, guard g does not refer to the variables that appear in
PG2.
Under these conditions, α is independent of every action β in PG2.
⟨n1, n2, y=1⟩
⟨w1, n2, y=1⟩
⟨n1, w2, y=1⟩
⟨c1, n2, y=0⟩
⟨w1, w2, y=1⟩
⟨n1, c2, y=0⟩
⟨c1, w2, y=0⟩
⟨w1, c2, y=0⟩
req1
req2
enter1
req2
req1
enter2
req2
enter1
enter2
req1
rel
rel
rel
rel
Figure 8.3: The semaphore-based mutual exclusion algorithm.
Let us illustrate this by means of the semaphore-based mutual exclusion program, see the
transition system in Figure 8.3. The actions α = request1 and β = request2 only appear
in the following edges of the program graph:
noncriti
requesti

→waiti.
In fact, α and β satisfy the above-mentioned conditions, and therefore are independent.
This reﬂects the fact that the request operations—as well as all activities in the noncritical
section—can be concurrently executed. On the other hand, the actions enteri that are
executed on entering the critical section,
waiti
y > 0: enteri

→criti,
access the shared variable y (the semaphore). Note that
Eﬀect(enteri, η)(y) = η(y) −1
but
Eﬀect(requesti, η)(y) = η(y).
Therefore, the actions enter1 and enter2 are dependent, since e.g., for state s = ⟨w1, w2, y =
1⟩, we have
enter1, enter2 ∈Act(s)
and
enter2 /∈Act(enter1(s)) = Act(⟨c1, w2, y = 0⟩).

Independence of Actions
601
The pairs of actions (request1, enter2), (enter1, request2), (rel, request1) and (rel, request2)
are independent. For instance, the only state in which both actions rel and request1 are
enabled is s′ = ⟨n1, c2, y=0⟩. We have
request1 ∈Act(rel(s′))
rel ∈Act(request1(s′))
and
rel(request1(s′)) = request1(rel(s′)) = ⟨w1, n2, y=1⟩.
A similar reasoning applies to the other pairs of independent actions.
The following lemma is a central result for the partial order reduction approach. It relies on
the successive exchange of independent actions βi and α in the action sequence β1 . . . βnα.
Lemma 8.6.
Permuting Independent Actions
Let TS be an action-deterministic transition system, s a state in TS, and let
s = s0
β1
−−→s1
β2
−−→s2
β3
−−→. . .
βn
−−→sn
be an execution fragment from s with the action sequence β1 . . . βn. Then, for any α ∈
Act(s) which is independent of { β1, . . . , βn } we have α ∈Act(si), and
s = s0
α
−−→t0
β1
−−→t1
β2
−−→. . .
βn−1
−−−−→tn−1
βn
−−→tn
is an execution fragment in TS with the action sequence α β1 . . . βn such that ti = α(si)
for 0 ⩽i ⩽n.
Proof: Let TS be action-deterministic transition system. By induction on i ⩾1 it is shown
that
• α and βi+1 are enabled in state si = (β1 . . . βi)(s),
• βi is enabled in state ti−1 = (α β1 . . . βi−1)(s), and
• α(si) = βi(ti−1).
Base: (i = 1). Let α, β1 ∈Act(s) and s1 = β1(s) and t0 = α(s). Since α and β1 are
independent, α ∈Act(s1) and β1 ∈Act(t0), and α(β1(s)) = β1(α(s)), i.e., α(s1) = β1(t0).
Induction step: (i−1 =⇒i for 1 < i ⩽n). Assume α and βi are enabled in state si−1 =
(β1 . . . βi−1)(s), βi−1 is enabled in state ti−2 = (α β1 . . . βi−2)(s), and the α-successor of
si−1 and the βi−1-successor of ti−2 agree, i.e.:
ti−1 = α(si−1) = βi−1(ti−2).

602
Partial Order Reduction
s = s0
`1
s1
`2
s2
`3
...
`n−1
sn−1
`n
sn
can be extended to
s = s0
`1
s1
`2
s2
`3
...
`n−1
sn−1
`n
sn
tn = t
_
t0
`1
t1
`2
t2
`3
...
`n−1
tn−1
`n
_
_
_
_
t0
_
Figure 8.4: Permuting α with the independent actions β1 through βn.
The independence of α and βi yields that α is enabled in state βi(si−1) = si, βi is enabled
in state α(si−1) = βi−1(ti−2) = ti−1, and α(si) = βi(ti−1) = ti.
Lemma 8.6 is illustrated in Figure 8.4.
Consider the inﬁnite execution fragment ρ starting in s with the action sequence β1 β2 β3 . . .
and an action α ∈Act(s) that is independent on all βj’s (in particular, α ̸= βj for all
j > 0). Then Lemma 8.6 applied to the ﬁnite preﬁxes of ρ yields the existence of ﬁnite
execution fragments from s with the action sequences α β1 β2 . . . βn for all n > 0. Since
TS is action-deterministic, we obtain an inﬁnite execution fragment which ﬁrst executes
action α and then the inﬁnite action sequence β1 β2 β3 . . .. More precisely, we have:
Lemma 8.7.
Adding an Independent Action
Let TS be an action-deterministic transition system, s a state in TS, and let
s = s0
β1
−−→s1
β2
−−→s2
β3
−−→. . .
be an inﬁnite execution fragment from s with the action sequence β1 β2 . . .. Then, for
α ∈Act(s) which is independent of { β1, β2, . . . } we have α ∈Act(si) for all i ⩾0 and
s = s0
α
−−→t0
β1
−−→t1
β2
−−→t2
β3
−−→. . .

Independence of Actions
603
is an inﬁnite execution fragment in TS with the action sequence α β1 β2 . . . and ti = α(si)
for i ⩾0.
If no further assumptions are made, the traces induced by the execution fragments
s0
β1
−−→
s1
β2
−−→
. . .
βn
−−−→
sn
α
−−→
t,
and
s0
α
−−→
t0
β1
−−→
. . .
βn−1
−−−−→
tn−1
βn
−−→
t
will be distinct and not related via any form of (stutter) trace equivalence or (stutter)
trace inclusion. However, if the action α which is moved from the “right” to the “left”
(by successive swapping the order βi α into α βi) does not aﬀect the state labeling, then
the execution fragments are stutter-equivalent. Recall that execution fragments ϱ, ϱ′ are
stutter-equivalent, denoted ϱ ≜ϱ′, if their traces only diﬀer in the number of repetitions of
state labels; see Section 7.7.1. These actions are called stutter actions or invisible actions.
Deﬁnition 8.8.
Stutter Action
The action α ∈Act is a stutter action if for each transition s
α
−−→s′ in transition system
TS we have L(s) = L(s′).
Since action-deterministic transition systems are considered, α is a stutter action in TS
if and only if L(s) = L(α(s)) for all states s in TS with α ∈Act(s). For example, the
actions β and γ in the transition system in Figure 8.5 are stutter actions, while α is not
a stutter action.
s0
{ a }
s1
{ a }
s2
∅
s3
∅
α
α
β
β
γ
Figure 8.5: Actions β and γ are stutter actions.
Remark 8.9.
Stutter Steps vs. Stutter Actions
Let us brieﬂy explain the diﬀerence between stutter steps and stutter actions. Recall that

604
Partial Order Reduction
a stutter step is a transition s →t such that L(s) = L(t). The fact whether or not an
α-labeled transition is a stutter step depends on the state in which α is executed. For
example, let α be the action corresponding to the assignment x := 2 ∗x for some integer
variable x. In all states in which x evaluates to 0, α does not aﬀect the value of x. If the
atomic propositions only consider the values of x (and other program variables), but not
the program locations, then the transitions
⟨. . . , x = 0⟩
x:=2∗x
−−−−−→⟨. . . , x = 0⟩
are stutter steps, whereas the transitions
⟨. . . , x = v⟩
x:=2∗x
−−−−−→⟨. . . , x = 2v⟩
for v ̸= 0 are not. Action α is a stutter action whenever all transitions s
α
−−→s′ are stutter
steps.
Lemma 8.10.
Permuting Independent Stutter Actions
Let TS be an action-deterministic transition system, s a state in TS, and ϱ and ϱ′ be
ﬁnite execution fragments starting in s with action sequences β1 . . . βn α and α β1 . . . βn,
respectively, such that α is a stutter action which is independent of { β1, . . . , βn }. Then
ϱ ≜ϱ′.
Proof: Let
ϱ = s0
β1
−−→
s1
β2
−−→
s2
β3
−−→
. . .
βn
−−→
sn
α
−−→
v
ϱ′ = s0
α
−−→
t0
β1
−−→
t1
β2
−−→
. . .
βn−1
−−−−→
tn−1
βn
−−→
tn,
where s = s0. By Lemma 8.6, ϱ and ϱ′ end in the same state, i.e., tn = v, and α(si) = ti
for 0 ⩽i ⩽n. Since α is a stutter action:
L(si) = L(α(si)) = L(ti)
for
0 ⩽i ⩽n.
Let Ai = L(si), 0 ⩽i ⩽n. Then:
trace(ϱ)
=
L(s0) L(s1) . . . L(sn) L(tn)
=
A0 A1 . . . An An and
trace(ϱ′)
=
L(s0) L(t0) L(t1) . . . L(tn)
=
A0 A0 A1 . . . An.
Thus, both traces have the form A+
0 A1 . . . An−1A+
n . Hence, ϱ ≜ϱ′.
The following lemma describes a transformation of an inﬁnite execution fragment with the
action sequence β1 β2 β3 . . . into a stutter-equivalent execution fragment with the action
sequence α β1 β2 β3 . . . where α is a stutter action that is independent of any βi.

The Linear-Time Ample Set Approach
605
Lemma 8.11.
Adding an Independent Stutter Action
Let TS be an action-deterministic transition system, s a state in TS, and ρ and ρ′
be inﬁnite execution fragments starting in s with the action sequences β1 β2 β3 . . . and
α β1 β2 β3 . . ., respectively, such that α is a stutter action which is independent of { β1, β2, β3, . . . }.
Then ρ ≜ρ′.
Proof: Let ρ = s0
β1
−−→s1
β2
−−→s2
β3
−−→. . . and ρ′ = s0
α
−−→t0
β1
−−→t1
β2
−−→t2
β3
−−→. . . where
s = s0. Then, si = α(ti) for all i ⩾0. Since α is a stutter action we have L(si) = L(ti)
for all i ⩾0. With Ai = L(si) we get
trace(ρ)
=
L(s0) L(s1) L(s2) . . .
=
A0 A1 A2 . . .
trace(ρ′)
=
L(s0) L(t0) L(t1) L(t2) . . .
=
A0 A0 A1 A2 . . .
Thus, both traces have the form A+
0 A1A2 . . . which yields ρ ≜ρ′.
Lemmas 8.10 and 8.11 yield the basis of the partial order reduction approach. During
partial order reduction, any stutter equivalence class of executions in the full system TS
is represented by at least one execution in the reduced system ˆ
TS. (One might say that
partial order reduction amounts to model checking using representative executions.) The
representatives in ˆ
TS of TS’s stutter equivalence classes arise by permuting independent
actions and adding independent stutter actions.
8.2
The Linear-Time Ample Set Approach
We consider partial order reduction for LTL using so-called ample sets. The basic idea
is the following. Consider a high-level speciﬁcation of an asynchronous system. Using
traditional state space generation, for each encountered states all direct successors are
explored. That is, for each action α ∈Act(s), the successor state α(s) is determined, and
when encountered for the ﬁrst time, generated. With partial order reduction using ample
sets, the set ample(s) ⊆Act(s) will be explored instead of the entire set Act(s). That
is, all direct successors in Act(s) \ ample(s) are not explored, and possibly not generated
at all. By choosing appropriate action sets ample(·), this approach yields a—hopefully
small—fragment of the full transition system TS = (S, Act, →, I, AP, L). As TS will never
be generated, the peak memory requirements are determined by the size of the fragment
ˆ
TS rather than by TS.
The reduced transition system
ˆ
TS results from the transition
relation
⇒which is deﬁned by
s
α
−−→s′ ∧α ∈ample(s)
s
α⇒s′
.

606
Partial Order Reduction
More precisely,
ˆ
TS = ( ˆS, Act, ⇒, I, AP, L) where the state space ˆS consists of those
states that are reachable (under ⇒) from some initial state s0 ∈I and L(s) = L(s) for
any s ∈ˆS.
Thus, ˆS might be a proper subset of the original state space S. The following
correctness criterion needs to be established:
(1)
ˆ
TS and TS are equivalent with respect to the formulae to be checked.
It turns out that stutter trace equivalence is an appropriate notion of equivalence for partial
order reduction when checking LT properties; for branching-time properties, divergence-
sensitive stutter bisimulation is convenient. Besides this formal soundness criterion, the
following more informal requirements are of importance:
(2)
ˆ
TS should be considerably smaller (and therefore more eﬃcient to analyze) than TS.
(3) The eﬀort to generate
ˆ
TS should be relatively low compared to the veriﬁcation of
TS.
To fulﬁll the last constraint, we aim at an algorithm to generate ˆ
TS with a time complexity
that is linear in the size of ˆ
TS. Typically, ˆ
TS is obtained by a static analysis of a high-
level description of TS, e.g., as a channel system or sequential program graph. If ˆ
TS is
signiﬁcantly smaller than TS, then such an approach can be viewed as eﬃcient.
The following subsections treat the ample-set method for verifying LT properties speciﬁed
as LTL formulae.
It is assumed that the original transition system TS = (S, Act, →
, I, AP, L) is ﬁnite, action-deterministic, and does not have terminal states. The aim is
to replace the veriﬁcation whether TS |= ϕ, for ϕ an LTL formula over AP, by checking
whether ˆ
TS |= ϕ.
ˆ
TS is obtained from TS by choosing appropriate ample sets. We ﬁrst
deal with LT properties; in Section 8.3, this approach will be extended to the veriﬁcation
of branching-time properties stated in CTL∗.
8.2.1
Ample Set Constraints
To ensure that TS and
ˆ
TS are equivalent, the ample sets have to fulﬁll a number of
conditions. As we will see, these constraints ensure that TS ≜ˆ
TS, i.e., TS and ˆ
TS are
stutter trace equivalent (see Section 7.7.1, see page 530 and further). Since stutter trace
equivalence preserves all stutter-insensitive LT properties, the reduction of TS to ˆ
TS is
sound for such LT properties. The fragment of LTL that does not contain the next step

The Linear-Time Ample Set Approach
607
operator, LTL\⃝, is an appropriate logical formalism to specify stutter-insensitive LT
properties, and thus
ˆ
TS |= ϕ
if and only if
TS |= ϕ
for any LTL\⃝-formulae ϕ, see Corollary 7.93 (page 535). (As the next step operator is
not very useful for asynchronous systems, the kind of systems that partial order reduction
is aimed at, the absence of the ⃝operator is not a severe restriction.)
Given a technique to generate the ample sets, such that TS ≜ˆ
TS, standard LTL model-
checking techniques may be applied to check ˆ
TS |= ϕ (and thus TS |= ϕ). There are two
main approaches to the computation of the ample sets, i.e., for determining ˆ
TS: static vs.
dynamic partial order reduction. In dynamic (or on-the-ﬂy) partial order reduction, the
reduced transition system
ˆ
TS is generated during the LTL model checking of
ˆ
TS. The
main advantage of this approach is that ˆ
TS ̸|= ϕ might be established without the need for
generating the entire transition system ˆ
TS—only the relevant part of the product ˆ
TS⊗A¬ϕ,
where A¬ϕ is the B¨uchi automaton for ¬ϕ, is needed to show the refutation of ϕ. This
approach is treated in Section 8.2.3. In the static approach, a symbolic representation (e.g.,
in terms of program graphs) of ˆ
TS is generated prior to the veriﬁcation. The reduction
of the transition system may be viewed as a preprocessing phase of model checking. The
static approach is treated in Section 8.2.4.
In the remainder of this section, conditions for the ample sets are established that en-
sure TS ≜ˆ
TS. Subsequently, techniques will be discussed to algorithmically determine
appropriate ample sets.
Since every execution in ˆ
TS is an execution in TS, we establish suﬃcient conditions to
assign to each execution ρ0 in TS a stutter-equivalent execution ˆρ in ˆ
TS. In order to avoid
any confusion, we stress that this assignment of executions in TS to executions in ˆ
TS is
not part of the algorithm for generating ˆ
TS, but is only needed to prove the stutter trace
equivalence of TS and ˆ
TS. The basic idea for the transformation
“execution ρ0 in TS →ˆρ0 in ˆ
TS with ρ0 ≜ˆρ0 ”
is the following. Let ρ0 be an inﬁnite execution in TS that is not an execution in ˆ
TS. A
stutter-equivalent execution ˆρ0 in ˆ
TS will be obtained from ρ0 by successively permuting
the order of independent actions and possibly adding stutter steps, according to the trans-
formations described in cases 1 and 2 (see below). The correctness of these transformations
is ensured by Lemmas 8.10 and 8.11. These transformations allow the replacement of ρ0
through a possibly inﬁnite series of transformations:
ρ0 →ρ1 →ρ2 →. . . →ˆρ0
where ρi ≜ρ0 for all i ⩾0
such that at least the ﬁrst i steps in ρi are transitions (i.e., according to ⇒) in ˆ
TS and

608
Partial Order Reduction
agree with the ﬁrst i transitions of ρj for all j > i. That is, ρi[..i] = ρj[..i] for all j > i.
In this way, an execution ˆρ0 in ˆ
TS is obtained which, for any i ⩾0, agrees with ρi for the
ﬁrst i transitions. It can be regarded as the “limit” of the sequence ρ0, ρ1, ρ2, and so on.
Let us consider the transformation of ρi to ρi+1 in more detail. For simplicity consider
the case i=0. Let m be the minimal index in ρ0 such that s = ρ0[m]
α
−−→ρ0[m+1] for
α ̸∈ample(s). Execution ρ0 thus consists of a ﬁnite preﬁx ϱ0 containing transitions in
ˆ
TS that ends in state s, and the inﬁnite execution fragment ρ starting in s with action
sequence β1 β2 . . ., say, such that β1 ̸∈ample(s):
ρ0 = u
γ1⇒. . .
γm⇒s



preﬁx ϱ0
s
β1
−−→s1
β2
−−→s2 . . .



suﬃx ρ with β1 ̸∈ample(s)
for m ⩾0.
Execution ρ1 then starts with the preﬁx ϱ0 and continues with the inﬁnite execution
fragment ρ′ that is obtained from ρ according to one of the transformations described
below.
Case 1: There exists n > 0 such that α = βn+1 ∈ample(s) and β1, . . . , βn /∈ample(s),
i.e., some action of the suﬃx ρ = s
β1
−−→s1
β2
−−→. . . of ρ0 belongs to ample(s). The
conditions imposed on the ample sets will ensure that α is a stutter action that
is independent of { β1, . . . , βn }. The execution fragment ρ′ (i.e., the suﬃx of ρ1)
results from ρ by replacing the action sequence β1 . . . βn α with α β1 . . . βn. That is,
the action α is shifted to occur prior to any βi (0 < i ⩽n). This transformation is
described by Lemma 8.6 (page 601). Pictorially this amounts to
ρ0 =
u
γ1⇒. . .
γm⇒
s
β1
−−→. . .
βn
−−→sn
α
−−→
t
βn+2
−−−−→sn+2
βn+3
−−−−→. . .
ρ1 =
u
γ1⇒. . .
γm⇒
s
α⇒t0
β1
−−→. . .
βn
−−→
t
βn+2
−−−−→sn+2
βn+3
−−−−→. . .









common preﬁx ϱ0
stutter-equivalent
common suﬃx
execution fragments
Since α is a stutter action, ρ ≜ρ′ (see Lemma 8.10 on page 604), and thus ρ0 ≜ρ1.
Case 2: For all i > 0, βi /∈ample(s), i.e., none of the actions occurring in the suﬃx ρ
belongs to ample(s). The conditions on the ample sets will ensure the independence
of βi and ample(s) for any i, and that any α ∈ample(s) is a stutter action. The
execution fragment ρ′ then results by replacing ρ by the execution fragment that
starts in s and successively executes the actions α β1 β2 β3 . . ., for some α ∈ample(s).

The Linear-Time Ample Set Approach
609
Schematically:
ρ0
=
u
γ1⇒. . .
γm⇒s
β1
−−→s1
β2
−−→s2
β3
−−→. . .
ρ1
=
u
γ1⇒. . .
γm⇒s
α⇒t0
β1
−−→t1
β2
−−→t2
β3
−−→. . .






common preﬁx ϱ0
stutter-equivalent execution fragments
Since α is a stutter action, Lemma 8.11 yields ρ ≜ρ′ and thus ρ0 ≜ρ1.
In both cases, an execution fragment ρ1 is obtained that starts in the same state as ρ0
such that the ﬁrst transition that is not a transition in ˆ
TS occurs at some position ⩾2.
This recipe is applied iteratively to ρj →ρj+1 for j ⩾1. This yields a stutter-equivalent
execution fragment ρj+1 such that the ﬁrst transition that is not a transition in ˆ
TS (i.e., not
an ample transition) occurs at some position > j and ρj[..j+1] = ρj+1[..j+1]. Continuing
in this way, we ﬁnally obtain an execution fragment in ˆ
TS.
To ensure that the above-described transformations (i.e., cases 1 and 2) are applicable and
yield an execution ˆρ0 in ˆ
TS such that ρ0 ≜ˆρ0 with ρ0 in TS, four conditions are imposed on
ample sets referred to as (A1) through (A4). Conditions (A1) through (A3) are imposed
on each state s in ˆS; no restrictions are imposed on states that are unreachable via
⇒.
Condition (A4) is imposed on all cycles in ˆ
TS.
Let us consider the constraints in more detail.
(A1) Nonemptiness condition
∅̸= ample(s) ⊆Act(s)
The ﬁrst condition asserts that if a state has at least one direct successor in TS, then it
has least one direct successor in ˆ
TS. As TS does not have terminal states, condition (A1)
ensures that ˆ
TS does not have any terminal states.
(A2) Dependency condition
Let s
β1
−−→s1
β2
−−→. . .
βn
−−→sn
α
−−→t be a ﬁnite execution fragment in TS.
If α depends on ample(s), then βi ∈ample(s) for some 0 < i ⩽n.
The key condition for the correctness is the dependency condition (A2). It asserts that in
every (!) ﬁnite execution fragment of TS, an action depending on ample(s) cannot occur
before some action from ample(s) is occurring ﬁrst. Note that this condition is imposed

610
Partial Order Reduction
on every (ﬁnite) execution of the original transition system TS. We will see later that this
condition ensures that for any state s which is not fully expanded (i.e., ample(s) is a proper
subset of Act(s)), all ample actions α ∈ample(s) are independent of Act(s) \ ample(s).
Note that for n=0, condition (A2) is false, as the existential quantiﬁcation (over i) ranges
over an empty domain.
Condition (A2) guarantees that any ﬁnite execution in TS is of the form
ϱ = s
β1
−−→s1
β2
−−→. . .
βn
−−→sn
α
−−→t
with
α ∈ample(s)
and βi independent of ample(s) for 0 < i ⩽n. If α is a stutter action—which will be
guaranteed by constraint (A3)—the execution obtained by shifting α to the beginning is
also an execution of TS; see the transformation as described under case 1 above. That is
to say, if ϱ is pruned in TS, i.e., does not occur in ˆ
TS as β1 ̸∈ample(s), then a stutter-
equivalent execution can be constructed by performing α in s. Inﬁnite executions in TS
are of the form
s1
β1
−−→s2
β2
−−→. . .
with βi independent of ample(s) for 0 < i ⩽n.
For stutter action α ∈ample(s), inserting the action α at the beginning of this execution
yields another execution of TS; see the transformation as described under case 2 above.
(A3) Stutter condition
If ample(s) ̸= Act(s) then any α ∈ample(s) is a stutter action.
Stutter condition (A3) ensures that the transformations (cases 1 and 2) generate stutter-
equivalent executions; see Lemma 8.10 (page 604) and Lemma 8.11 (page 604). To be
more precise, condition (A3) ensures that the switch from action sequence β1 . . . βn α to
α β1 . . . βn, and from β1 β2 β3 . . . to α β1 β2 β3 . . . in state s with α ∈ample(s) yields
stutter-equivalent executions. Ample actions may thus be executed ﬁrst.
(A4) Cycle condition
For any cycle s0 s1 . . . sn in ˆ
TS and α ∈Act(si), for some 0 < i ⩽n,
there exists j ∈{ 1, . . . , n } such that α ∈ample(sj).
The cycle condition (A4) is the ﬁnal condition that is needed to ensure that TS and ˆ
TS
are stutter-equivalent. The justiﬁcation of this condition is provided later.
The conditions imposed on ample sets are summarized in Figure 8.6.

The Linear-Time Ample Set Approach
611
(A1) Nonemptiness condition
∅̸= ample(s) ⊆Act(s)
(A2) Dependency condition
Let s
β1
−−→. . .
βn
−−→sn
α
−−→t be a ﬁnite execution fragment in TS.
If α depends on ample(s), then βi ∈ample(s) for some 0 < i ⩽n.
(A3) Stutter condition
If ample(s) ̸= Act(s) then any α ∈ample(s) is a stutter action.
(A4) Cycle condition
For any cycle s0 s1 . . . sn in ˆ
TS and α ∈Act(si), for some 0 < i ⩽n,
there exists j ∈{ 1, . . . , n } such that α ∈ample(sj).
Figure 8.6: Requirements on the ample set of state s.
Example 8.12.
Ample Set Conditions
Consider the transition system TS in Figure 8.7 (left part) over AP = { a }. Action β is a
stutter action, and is independent of { α, γ, δ }. Let ample(s0) = { β }. This choice satisﬁes
constraints (A1) through (A3).
Consider now state s2. The choice ample(s2) = { α }
violates (A3), as α is not a stutter action. ample(s2) = { δ } violates the cycle condition
(A4): the reduced transition system ˆ
TS would contain the cycle s0 s2 s2 with α ∈Act(s2),
but α ̸∈ample(s2). Thus, we select ample(s2) = { α, δ }. The nonemptiness condition
(A1) then leaves no freedom for s3: ample(s3) = { γ }. The resulting reduced transition
system ˆ
TS is depicted in Figure 8.7 (right part).
The traces of TS and ˆ
TS are either of the form (∅+{ a }+)ω or (∅+{ a }+)∗∅ω. Hence,
TS ≜ˆ
TS.
We now state the main result of this section. The proof of this result is provided by a
series of lemmas, presented in the remainder of this section.
Theorem 8.13.
Correctness of the Ample Set Approach
Let TS be an action-deterministic, ﬁnite transition system without terminal states. Then
if conditions (A1) through (A4) are satisﬁed, then ˆ
TS ≜TS.
This theorem asserts that whenever
ˆ
TS is constructed from TS using ample sets that

612
Partial Order Reduction
s1
{ a }
s0
∅
s3
{ a }
s2
∅
β
β
α
γ
α
γ
δ
δ
s0
∅
s3
{ a }
s2
∅
β
α
γ
δ
Figure 8.7: Transition sytem TS (left) and ˆ
TS (right)
satisfy all constraints (A1) through (A4), then ˆ
TS and TS are stutter trace equivalent.
Since stutter trace equivalence is ﬁner than LTL\⃝equivalence, conditions (A1) through
(A4) guarantee that
ˆ
TS and TS satisfy the same LTL\⃝formulae.
The remainder of
this subsection is devoted to the proof of Theorem 8.13. Since ˆ
TS is a fragment of TS,
every execution of
ˆ
TS is an execution of TS. It remains to show that, conversely, for
every execution in TS there exists a stutter-equivalent execution in ˆ
TS. The proof for this
statement proceeds in a number of steps, and results from Lemmas 8.14 through 8.21.
The ﬁrst two lemmas follow from simple observations that are based on the dependency
condition (A2).
Lemma 8.14.
Independence of Ample and Other Enabled Actions
Let s ∈Reach(TS) and α ∈ample(s). Then
(A2) implies that α is independent of Act(s) \ ample(s).
Proof: Let s ∈Reach(TS), α ∈ample(s), and β ∈Act(s)\ample(s). Then there exists an
execution fragment starting in s which begins with action β:
ρ = s
β
−−→s1
γ1
−−→s2
γ2
−−→s3
γ3
−−→. . .
Assume ample(s) satisﬁes (A2) and assume α and β are dependent. The existence of
the execution ρ, however, violates condition (A2) since β is not preceded by an action in
ample(s). Contradiction.
(In Remark 8.19 (page 614) it is shown that just imposing that any α ∈ample(s) is
independent of Act(s) \ ample(s) is too weak to establish that TS ≜ˆ
TS.)

The Linear-Time Ample Set Approach
613
The following lemma asserts that for any execution fragment that starts in s it holds that
any action in ample(s) remains enabled as long as no action in ample(s) has been executed.
Lemma 8.15.
Enabledness of Ample Actions
Let s ∈Reach(TS) and s = s0
β1
−−→. . .
βn
−−→sn be a ﬁnite execution fragment in TS. If
ample(s) satisﬁes (A2) and { β1, . . . , βn }∩ample(s) = ∅, then for all actions α ∈ample(s)
are independent of { β1, . . . , βn }. In adddition, we have α ∈Act(si) for 0 < i ⩽n.
Proof: Let s ∈Reach(TS) and s = s0
β1
−−→. . .
βn
−−→sn be a ﬁnite execution fragment, ρ
say, in TS. Consider α ∈ample(s) and assume ample(s) satisﬁes constraints (A1) and
(A2). The proof is by induction on i.
Basis: (i=1). By Lemma 8.14, α and β1 are independent. But then also, α ∈Act(β(s0)) =
Act(s1).
Induction step: Suppose the claim holds for 0 < i < n. Consider the execution frag-
ment ρi = s0
β1
−−→. . .
βi
−−→si. As ρ is an execution fragment in TS, βi+1 ∈Act(si). So,
ρi+1 = s0
β1
−−→. . .
βi
−−→si
βi+1
−−−→si+1 is an execution fragment in TS. Then α and βi+1
are independent, as otherwise ρi+1 would violate (A2). The induction hypothesis yields
α ∈Act(si). As α and βi+1 are independent, we get α ∈Act(βi+1(si)) = Act(si+1).
Notation 8.16.
Fully Expanded State
A state s of TS is fully expanded if ample(s) = Act(s).
The following two lemmas show that the conditions (A1) through (A3) are necessary
conditions to guarantee that for each execution in TS a stutter-equivalent execution in ˆ
TS
can be determined.
Lemma 8.17.
Constructing Stutter-Equivalent Executions (Case 1)
Let ϱ be a ﬁnite execution fragment in Reach(TS) of the form
s
β1
−−→s1
β2
−−→. . .
βn
−−→sn
α
−−→t
where βi /∈ample(s), for 0 < i ⩽n, and α ∈ample(s). If ample(s) satisﬁes (A1) through
(A3), then there exists an execution fragment ϱ′ of the form
s
α⇒t0
β1
−−→t1
β2
−−→. . .
βn−1
−−−−→tn−1
βn
−−→t
and ϱ ≜ϱ′.

614
Partial Order Reduction
Proof: Let ϱ = s
β1
−−→s1
β2
−−→. . .
βn
−−→sn
α
−−→t be a ﬁnite execution fragment in Reach(TS)
where βi /∈ample(s), for 0 < i ⩽n, and α ∈ample(s). By Lemma 8.15, α is independent
of { β1, . . . , βn }. State s is not fully expanded, since β1 ∈Act(s) \ ample(s). By condition
(A3), α is a stutter action. The claim now follows from Lemma 8.10 (page 604).
Provided β1, . . . , βn /∈ample(s) and α ∈ample(s), replacing the action sequence β1 . . . βn α
in TS by α β1 . . . βn (as described in case 1) results in a stutter-equivalent execution frag-
ment. The following lemma is similar in ﬂavor but deals with inﬁnitely many actions that
are independent of α ∈ample(s).
Lemma 8.18.
Constructing Stutter-Equivalent Executions (Case 2)
Let ρ = s
β1
−−→s1
β2
−−→s2
β3
−−→. . . be an inﬁnite execution fragment in Reach(TS) where
βi /∈ample(s), for i > 0. If ample(s) satisﬁes (A1) through (A3), then there exists an
execution fragment ρ′ of the form
s
α⇒t0
β1
−−→t1
β2
−−→t2
β3
−−→. . .
where α ∈ample(s) and ρ ≜ρ′.
Proof: Let ρ = s
β1
−−→s1
β2
−−→s2
β3
−−→. . . be an inﬁnite execution fragment in Reach(TS)
where βi /∈ample(s), for i > 0. As β1 ∈Act(s) \ ample(s), state s is not fully expanded.
By condition (A3), all actions α ∈ample(s) are stutter actions. Condition (A1) yields
the existence of an action α ∈ample(s). The claim now follows directly from Lemma 8.7
(page 602) and Lemma 8.11 (page 605).
Remark 8.19.
An Alternative Dependency Condition (A2′)
Consider the following variant of (A2): for any s ∈ˆS with ample(s) ̸= Act(s), any
α ∈ample(s) is independent of Act(s) \ ample(s). This variant, referred to as (A2′) in
the sequel, seems—at ﬁrst sight—a reasonable variant of (A2). It simply requires that
any ample action of a nonfully expanded state s is independent of all enabled actions in s
that are not in its ample set. The following example shows, however, that (A2′) does not
guarantee that TS ≜ˆ
TS.
Consider the transition system depicted in Figure 8.8 (left part). Actions α and β are in-
dependent and α and δ are stutter actions. The following ample sets satisfy the conditions
(A1), (A2′), (A3) and (A4):
ample(s0) = { α }
and
ample(s2) = { β }
and
ample(s3) = { δ }.
The resulting reduced transition system ˆ
TS is depicted in Figure 8.8 (right part). Condi-
tions (A1) and (A3) are obvious. Note that s1 ̸∈ˆS, and thus no requirements are imposed

The Linear-Time Ample Set Approach
615
on ample(s1). Cycle condition (A4) is fulﬁlled, as there is only one cycle (the self-loop
at s3), and ample(s3) = Act(s3). As state s0 is the only nonfully expanded state in ˆ
TS,
condition (A2′) has only to be checked for s0. It holds as α and β are independent.
s1
∅
s0
∅
s3
∅
s2
∅
α
α
β
β
δ
s4
{ a }
δ
γ
s0
∅
s3
∅
s2
∅
α
β
δ
Figure 8.8: A possible, though unsound reduction that satisﬁes (A2′) but not (A2).
However, TS ̸≜ˆ
TS since, e.g.,
ˆ
TS |= □¬a (as it does not contain any a-state), while
TS ̸|= □¬a. Thus, condition (A2′) does not guarantee TS ≜ˆ
TS. The ample sets deﬁned
above violate condition (A2). This can be seen as follows. Action γ depends on α, since
both actions are enabled in state s1, but α is not enabled in γ(s1) = s4.
Thus, the
execution fragment s0
β
−−→s1
γ
−→s4 violates (A2) as α should occur before γ. So, (A2)
does not allow the reduction from TS to ˆ
TS as depicted in Figure 8.8.
Now consider the cycle condition (A4).
The results we established so far ensure that
the series of transformations ρ0 →ρ1 →ρ2 →. . . (according to case 1 and 2) generate
executions ρi that are stutter-equivalent to the execution ρ0 in TS. Moreover, at least the
ﬁrst i transitions in ρi are transitions in ˆ
TS and agree with the ﬁrst i transitions in ρj for
all j ⩾i. The idea is now to consider the “limit” ˆρ0 of the executions (ρi)i⩾0. That is, for
all i > 0, the ith transition in ˆρ0 is the ith transition in ρi (and ρj for all j ⩾i). Thus,
ˆρ0 is an execution in ˆ
TS. Unfortunately, without the cycle condition (A4) it cannot be
guaranteed that ρi ≜ˆρ0. The intuitive reason is that some (nonstutter) action β might
be delayed ad inﬁnitum in the successive construction of ˆρ0.
Let us consider this eﬀect more in detail. Assume α and β are independent, enabled in
all states, and α is a stutter action while β is not. The ample sets ample(s) = { α } for
any state s fulﬁll conditions (A1) through (A3). Let ρ0 be an execution with the action
sequence β αω. Then the above transformation ρ0 →ρ1 →ρ2 →. . . yields the executions
ρi with the action sequence αi β αω (see case 1). Their limit is the execution ˆρ0 with the
action sequence αω β ≡αω. However, it is not guaranteed that ˆρ0 ≜ρi as action β is

616
Partial Order Reduction
ignored forever in ˆρ0.
In a similar way, in absence of condition (A4), the transformation according to case 2 may
generate an execution in
ˆ
TS that is not stutter-equivalent to the original execution ρ0.
Let, e.g., ρ0 have the action sequence β1 β2 . . .. Then case 2 might generate a series of
executions ρ1 →ρ2 →. . . with action sequences
α
β1
β2
β3
β4
β5
. . .
α
α
β1
β2
β3
β4
. . .
α
α
α
β1
β2
β3
. . .
...
such that in the limit, action β1 is never performed.
The following example illustrates the necessity of cycle condition (A4).
s0
∅
s1 { a }
β
γ
t0
∅
t1
∅
t2
∅
α2
α3
α1
Figure 8.9: Transition systems TS1 (left) and TS2 (right).
Example 8.20.
Necessity of Cycle Condition (A4)
Consider the transition systems TS1 and TS2 depicted in Figure 8.9. The transition system
TS = TS1 ||| TS2 is depicted in the left part of Figure 8.10. The reduced transition system
ˆ
TS, depicted on the right of Figure 8.10, results from choosing ample(⟨s0, ti⟩) = { αi+1 },
for i=1, 2, 3.
Conditions (A1), (A2), and (A3) are fulﬁlled since β is independent of
{ α1, α2, α3 }. Consider the action sequence β (α1 α2 α3)ω and the associated execution ρ
in TS. The associated trace is
trace(ρ) = ∅{ a } { a } { a } . . . = ∅{ a }ω ∈Traces(TS).
In ˆ
TS, however, there does not exist an execution that is stutter-equivalent to ρ, since ˆ
TS
has no states labeled with a. In fact, Traces( ˆ
TS) = { ∅ω }. Hence, TS ̸≜ˆ
TS. (This can
also be seen by considering the LTL\⃝formula □¬a. Hence TS ̸|= □¬a and ˆ
TS |= □¬a.)
Let us explain why the above-mentioned replacement process, which should transform the
executions of TS into a stutter-equivalent execution of ˆ
TS, fails. In this example, case 1

The Linear-Time Ample Set Approach
617
⟨s0, t0⟩∅
⟨s0, t1⟩
∅
⟨s0, t2⟩∅
α2
α3
α1
⟨s1, t0⟩{ a }
⟨s1, t1⟩
{ a }
⟨s1, t2⟩{ a }
α2
α3
α1
β
β
β
γ
γ
γ
⟨s0, t0⟩∅
⟨s0, t1⟩
∅
⟨s0, t2⟩∅
α2
α3
α1
Figure 8.10: Transition system TS (left) and unsound reduced transition system ˆ
TS (right).
continuously applies, and ρ0 is successively replaced with executions that are associated
to the action sequences:
α1 β α2 α3 α1 α2 α3 . . .
α1 α2 β α3 α1 α2 α3 . . .
α1 α2 α3 β α1 α2 α3 . . .
α1 α2 α3 α1 β α2 α3 . . .
...
But the action β is never performed, since β does not occur in ˆ
TS. Actually, the cycle con-
`
_3
_1
s0t0
s0t1
s0t2
_2
`
`
Figure 8.11: Cycle condition (A4) is violated.
dition (A4) is violated, since β is continuously enabled on the cycle ⟨s0, t0⟩⟨s0, t1⟩⟨s0, t2⟩
⟨s0, t0⟩, see Figure 8.11, but not in any ample sets of these states.
The above considerations demonstrate that conditions (A1) through (A3) cannot guaran-
tee TS ≜ˆ
TS. The goal is now to show that (A1), (A2), and (A3) together with the cycle

618
Partial Order Reduction
condition (A4) suﬃce. In fact, with the cycle condition (A4) a situation described above
is impossible.
Lemma 8.21.
Stutter-Trace Inclusion of TS in
ˆ
TS
If (A1) through (A4) are satisﬁed, then TS ⊴ˆ
TS.
Proof: Let ρ0 be an execution in TS which starts in state s and is induced by the action
sequence β1 β2 β3 . . . where β1 /∈ample(s).
The execution ρ0 is successively replaced
with stutter-equivalent executions ρm, m = 1, 2, 3, . . ., by means of the transformations
indicated in Lemmas 8.17 and 8.18. Each of these executions ρm starts in state s and is
based on an action sequence of the form
α1 . . . αm β1 γ1 γ2 γ3 . . .
The action sequence α1 α2 . . . αm contains the actions of the ample sets, which are newly
inserted according to Lemma 8.18, and all actions βn, which were shifted forward according
to Lemma 8.17. γ1 γ2 γ3 . . . denotes the remaining subsequence of β1, β2, β3 . . .. Thus, ρm
is of the form
s
α1
=⇒t1
α2
=⇒. . . αm
=⇒tm
β1
−→tm
0
γ1
−→tm
1
γ2
−→tm
2
γ3
−→. . .
where α1, . . . , αm are stutter actions.
Actually, the case β1 ̸∈ample(tm) for all m ∈IN is impossible, since—due to the ﬁniteness
of TS—the path fragment s t1 t2 . . . tm contains a cycle for suﬃciently large m. Moreover,
β1 ∈Act(tm) for all m by Lemma 8.15 on page 613. This contradicts condition (A4).
Hence, β1 ∈ample(tm) for some m ⩾1. But then
s
α1
=⇒t1
α2
=⇒. . . αm
=⇒tm
β1
=⇒tm
0
is an execution fragment in ˆ
TS which is a preﬁx of ρm+1 and all executions ρj for j > m.
According to the outlined recipe, we obtain an execution ˆρ0 in ˆ
TS (as the “limit” of ρm,
ρm+1 . . .), where the induced action sequence contains all actions that occur in ρ0 (in TS).
Let us assume that ρ0 has the form s0
β1
−−→s1
β2
−−→. . . and let 0 = k0 < k1 < k2 < . . . such
that βk1 βk2 . . . results from β1 β2 . . . by omitting all stutter actions in β1 β2, . . .. (Note that
the subsequence βk1 βk2 . . . may be ﬁnite.) Then, trace(ρ0) has the form A+
0 A+
1 A+
2 . . .,
where Ai is the label L(sk) of all states sk with ki ⩽k < ki+1. Since each of the nonstutter
actions βki is eventually “processed” when generating the executions ρ1, ρ2, ρ3, . . ., for each
index ki there is some ﬁnite word wi of the form A+
0 A+
1 . . . A+
i and some index ℓi such
that the traces of the executions ρj for all j ⩾ℓi start with wi.
In particular, wi is
a proper preﬁx of wi+1 and the words wi are preﬁxes of the trace associated with the
“limit” execution ˆρ0. Hence, trace(ˆρ0) has the form A+
0 A+
1 A+
2 . . ., and ρ0 ≜ˆρ0.

The Linear-Time Ample Set Approach
619
As Traces( ˆ
TS) ⊆Traces(TS), the above lemma yields that TS ≜ˆ
TS. This completes the
proof of Theorem 8.13 (page 611).
Remark 8.22.
Nonemptiness Condition (A1) and Terminal States
Throughout this chapter, we assume a transition system without terminal states. This
assumption has been made to be consistent with Chapter 5 where LTL formulae are
interpreted as languages over inﬁnite words. However, all concepts presented here (as well
as those in Chapter 5) can also be applied to transition systems that have terminal states.
The only diﬀerence from the approach presented here is that the nonemptiness condition
has to be replaced with the following requirements (A1.1) and (A1.2):
(A1.1) ample(s) ⊆Act(s).
(A1.2) ample(s) = ∅if and only if Act(s) = ∅.
Condition (A1.1) ensures that ˆ
TS is a subtransition system of TS, while (A2.1) guarantees
that any terminal state in ˆ
TS is a terminal state in TS. Theorem 8.13 holds for transition
systems with terminal states, i.e., conditions (A1.1), (A1.2), and (A2) through (A4) yield
TS ≜ˆ
TS
8.2.2
Dynamic Partial Order Reduction
We now consider the integration of partial order reduction as part of LTL model checking.
The basic strategy is to generate ˆ
TS during model checking. This is in contrast to static
partial order reduction in which ˆ
TS is constructed prior to the veriﬁcation. To simplify
matters, we ﬁrst treat on-the-ﬂy, or dynamic, partial order reduction during invariant
checking. As invariants can be checked by a depth-ﬁrst search (DFS) technique, this boils
down to integrating the ample set technique in a depth-ﬁrst search. Subsequently, we show
how nested depth-ﬁrst search—the algorithm to ﬁnd cycles containing an accept state in
ˆ
TS ⊗A¬ϕ—can be adapted such that partial order reduction is employed.
Partial Order Reduction in Depth-First Search
Consider the invariant □Φ where
Φ is a propositional formula (i.e., not an LTL formula). In order to check whether TS |=
□Φ, a depth-ﬁrst search algorithm can be applied, as explained in Chapter 3, that checks
in every state of TS whether Φ holds. This is done during the state-space generation.
On exploring a state s, all outgoing transitions of s are considered, i.e., all actions in
Act(s) are considered. When integrating partial order reduction into this procedure, only

620
Partial Order Reduction
the α-successor states of s are considered for which α ∈ample(s). The resulting depth-
ﬁrst search algorithm is provided in Algorithm 38 on page 622. It generates the ample
sets for any fresh encountered state of
ˆ
TS and explores the successor states under
⇒
according to a depth-ﬁrst search strategy.
The set mark(s) keeps track of the actions
in ample(s) that have been considered during the search.
As soon as this set equals
ample(s), all ample successors of s are considered, state s is popped from the stack, and
Φ is checked. In case an action α is considered whose successor has not been encountered
before, the state is marked as being reachable (under ⇒) and pushed on the stack. For
any freshly encountered state, an approximation of its ample set is generated that satisﬁes
(A1) through (A3), but possibly not (A4). Later on, we will see that establishing these
constraints can be done by means of local criteria. Roughly speaking, it is ﬁrst attempted
to determine ample(s) as the set of actions of a single process that are enabled in state s.
To ensure the cycle condition (A4), the ample set is enlarged on demand. This is indicated
by the statement ample(s′) := Act(s′).
This technique relies on replacing (A4) by the
stronger condition:
(A4′) Strong cycle condition
Any cycle in ˆ
TS contains at least one state s with ample(s) = Act(s).
It is not diﬃcult to assess that (A4′) is a suﬃcient criterion for (A4), provided the other
ample set conditions (A1) through (A3) hold. This is shown in the following lemma.
Lemma 8.23.
Strong Cycle Condition
If (A1) through (A3) hold, then condition (A4′) implies (A4).
Proof: By contraposition. Assume s0 . . . sn (with n > 0) is a cycle in ˆ
TS with Act(sj) =
ample(sj) for some 0 < j ⩽n, i.e., state sj is fully expanded. Assume (A4) is violated,
i.e., for some i̸=j it holds that β ∈Act(si) and β ̸∈ample(sk) for all 0 < k ⩽n. Consider
the transition si
αi
−−→si+1 that is part of the cycle s0 . . . sn. (Here, i+1 should be read
as (i+1) mod n.) As s0 . . . sn is a cycle in ˆ
TS, it follows αi ∈ample(si). Condition (A2)
yields that all actions in ample(si) are independent of those in Act(si) \ ample(si). In
particular, αi is independent of β ̸∈ample(si). But then, β ∈Act(αi(si)) = Act(si+1).
As β ̸∈ample(si+1), it follows by a similar reasoning that β ∈Act(si+2). Continuing this
reasoning, we obtain β ∈Act(sj)\ample(sj). This, however, contradicts that ample(sj) =
Act(sj).
The advantage of (A4′) is that it can easily be integrated in the depth-ﬁrst search algo-
rithm. If the depth-ﬁrst search ﬁnds a backward edge s′
α
−−→s′′, i.e., s′ is the current state
and s′′ = α(s′) for the current action α ∈ample(s′) and s′′ is on the stack U, then a cycle

The Linear-Time Ample Set Approach
621
s′′ . . . s′ . . . s′′ has been found that contains s′. Thus, we may simply enlarge ample(s′) by
adding all actions β ∈Act(s′) that are not in the current ample set of s. This turns s′
into a fully expanded state and ensures (A4′). Alternatively, we may fully expand α(s′),
as it suﬃces to fully expand an arbitrary state on the cycle. (The check whether a state
is on the stack U can be realized in constant time by, e.g., organizing R by a hash table
where each entry is equipped with a bit indicating whether the state is in U or not.)
Example 8.24.
POR (Reachability Analysis)
Consider the following concurrent program consisting of two parallel processes:
Process 0:
while true
{
ℓ0 :
skip;
m0 :
wait until (¬b) {
n0 :
. . . critical section . . .}
b := true;
}
Process 1:
while true
{
ℓ1 :
skip;
m1 :
wait until (b) {
n1 :
. . . critical section . . .}
b := false;
}
The atomic proposition a holds in the states of TS(PG0 ||| PG1), see Figure 8.12, for which
at least one of the processes is in location n0 or n1. Action δi denotes the execution of the
skip statement by process i, αi denotes the action that corresponds to waiting at program
location mi; βi is the action denoting the exit of the busy-wait cycle by process i, and γi
the action to return to the beginning of the loop. The initial value of the shared boolean
variable b is unspeciﬁed.
We apply Algorithm 38 with Φ = true—just a state-space generation—to TS(PG0 ||| PG1).
We start with state s0 = ⟨ℓ0, ℓ1, ¬b⟩. The actions δ0 and δ1 ∈Act(s0) are stutter actions
and independent. The possibilities are
ample(s0) = { δ0 },
ample(s0) = { δ1 } or ample(s0) = { δ0, δ1 }.
The ﬁrst two alternatives are equivalent and lead to a better reduction than the last
alternative. Let
ample(s0) = { δ0 }.
Intuitively, this corresponds to assigning a higher priority to process zero.
The next
encountered state is δ0(s0) = s1 = ⟨m0, ℓ1, ¬b⟩. Actions δ1 and β0 belong to Act(s1) and
are independent. β0 (and β1) are not stutter actions. Let
ample(s1) = { δ1 }.
The next encountered state δ1(s1) = s2 = ⟨m0, m1, ¬b⟩. We have Act(s2) = { α1, β0 }. The
choice ample(s2) = { α1 } violates condition (A4) as it closes the cycle s1 s1 on which the

622
Partial Order Reduction
Algorithm 38 Invariant checking using partial order reduction
Input: ﬁnite transition system TS and propositional formula Φ
Output: “yes” if TS |= □Φ”, otherwise “no” plus a counterexample
set of states R := ∅;
(* the set of reachable states *)
stack of states U := ε;
(* the empty stack *)
bool b := true;
(* all states in R satisfy Φ *)
while (I \ R ̸= ∅∧b) do
let s ∈I \ R;
(* choose an arbitrary initial state not in R *)
visit(s);
(* perform a DFS for each unvisited initial state *)
od
if b then
return(”yes”)
(* TS |= ”always Φ” *)
else
return(”no”, reverse(U))
(* counterexample arises from the stack content *)
ﬁ
procedure visit (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
(* mark s as reachable *)
compute ample(s) satisfying (A1)–(A3);
(* see Section 8.2.3 *)
mark(s) := ∅;
(* taken actions in s *)
repeat
s′ := top(U);
if ample(s′) = mark(s′) then
pop(U);
(* all ample actions have been taken *)
b := b ∧(s′ |= Φ);
(* check validity of Φ in s′ *)
else
let α ∈ample(s′) \ mark(s′);
mark(s′) := mark(s′) ∪{ α };
(* mark α as taken *)
if α(s′) ̸∈R then
push(α(s′), U);
R := R ∪{ α(s′) };
(* α(s′) is a new reachable state *)
compute ample(α(s′)) satisfying (A1)–(A3);
(* see Section 8.2.3 *)
mark(α(s′)) := ∅;
else
if α(s′) ∈U then ample(s′) := Act(s′); ﬁ
(* establish (A4′) *)
ﬁ
ﬁ
until ((U = ε) ∨¬ b)
endproc

The Linear-Time Ample Set Approach
623
⟨ℓ0, ℓ1, ¬b⟩
⟨ℓ0, m1, ¬b⟩
⟨m0, ℓ1, ¬b⟩
⟨m0, m1, ¬b⟩
⟨n0, ℓ1, ¬b⟩
{ a }
⟨n0, m1, ¬b⟩
{ a }
⟨ℓ0, ℓ1, b⟩
⟨m0, ℓ1, b⟩
⟨ℓ0, m1, b⟩
⟨m0, m1, b⟩
⟨ℓ0, n1, b⟩
{ a }
⟨m0, n1, b⟩
{ a }
α1
α1
α1
δ1
δ0
δ0
δ1
β0
δ1
β0
α0
α0
α0
δ0
δ1
δ1
δ0
β1
δ0
β1
γ0
γ1
γ1
γ0
Figure 8.12: Transition system for the program PG1 ||| PG2.
action β0 is enabled but is never chosen. As β0 is not a stutter action, the only reasonable
choice is
ample(s2) = { α1, β0 }.
By continuing such arguments the reduced transition system ˆ
TS depicted in Figure 8.13
is obtained. Thus, eight of the reachable 12 states in TS are obtained by partial order
reduction, provided the ample sets are chosen as indicated above.
Partial Order Reduction in Nested Depth-First Search
The next issue is to
integrate partial order reduction in the LTL\⃝model-checking procedure. Rather than
checking TS |= ϕ it is veriﬁed whether ˆ
TS |= ϕ. The rough idea for verifying ˆ
TS |= ϕ is
as follows. As usual, a B¨uchi automaton A¬ϕ is constructed for the LTL\⃝formula ϕ.
The reachable states of the product transition system ˆ
TS⊗A¬ϕ are generated and during
this state-space generation phase, the persistence property “eventually forever no accept
state” is checked by means of the nested depth-ﬁrst search described in Section 5.2. In
the outer depth-ﬁrst search, a reachable accept state is searched for, whereas in the inner
depth-ﬁrst search, it is checked whether a reachable accept state lies on a cycle. In order
to obtain correct results it is evident that in both depth-ﬁrst searches, the same ample
sets need to be used. Otherwise, diﬀerent transition systems are considered.
As described in Section 5.2, a cycle with an accept state in A¬ϕ is found if the cycle
check—the inner DFS which attempts to ﬁnd a backward edge to an accept state—is
started for state s once the outer DFS for s is completed, i.e., when all successors of s
have been explored. When adopting the same approach as in Algorithm 38 for the nested

624
Partial Order Reduction
⟨ℓ0, ℓ1, ¬b⟩
⟨m0, ℓ1, ¬b⟩
⟨m0, m1, ¬b⟩
⟨n0, m1, ¬b⟩
{ a }
⟨ℓ0, ℓ1, b⟩
⟨ℓ0, m1, b⟩
⟨m0, m1, b⟩
⟨m0, n1, b⟩
{ a }
α1
α1
δ0
δ1
β0
α0
α0
δ1
δ0
β1
γ0
γ1
Figure 8.13: The reduced transition system ˆ
TS for PG1 ||| PG2.
depth-ﬁrst search, the inner and outer depth-ﬁrst search may dynamically change the
ample set. This is due to the extension of the ample set to accomplish (A4′). Hence, we
have to ensure that the inner DFS is started only if ample(s) cannot change anymore. To
that end, a slightly modiﬁed version of the nested DFS procedure (indicated at the end of
Section 5.2) is exploited. In this variant, the nested DFS is aborted as soon as the inner
DFS visits a state t which is on the stack U for the outer DFS.
The main steps are outlined in Algorithm 39. The procedure cycle check por is a slight
variant of the cycle check as given in Algorithm 7 (see page 210). This algorithm aborts
as soon as a state t is visited which is on the stack U for the outer DFS. That is, this
variant seeks an arbitrary backward edge rather than a backward edge from s′ to s (as
is done in Algorithm 40 on page 626). The test whether the current state t of the inner
DFS is on the stack U for the outer DFS can be performed in (expected) constant time
if the elements in R (organized as a hash table) are augmented with a bit that yields the
information whether or not a state is in U.
To ensure that the inner DFS uses the same ample sets ample(s) as the outer DFS (and
to avoid the recomputation of ample(s) in the inner DFS) one might use one bit for any
enabled action α which indicates whether α belongs to ample(s). A simple solution is to
use hashing for representing T and R, bits for U as well as the action bits. Thus, the
entries in this hash table are tuples ⟨s, bT , bU, ⟨α1, b1⟩, . . . , ⟨αn, bn⟩⟩consisting of a state
s ∈R, bit bT indicating whether s ∈T, bit bU indicating whether s ∈U, and a list
⟨α1, b1⟩, . . . , ⟨αn, bn⟩for all actions αi ∈Act(s) where bit bi equals one iﬀαi ∈ample(s).

The Linear-Time Ample Set Approach
625
Algorithm 39 Nested depth-ﬁrst search with partial order reduction
Input: ﬁnite transition system TS and propositional formula Φ
Output: ”yes” if TS |= □Φ”, otherwise ”no” plus a counterexample
set of states R := ∅;
(* set of visited states in the outer DFS *)
stack of states U := ε;
(* stack for the outer DFS *)
set of states T := ∅;
(* set of visited states in the inner DFS *)
stack of states V := ε;
(* stack for the inner DFS *)
boolean cycle found := false;
while (I \ R ̸= ∅∧¬cycle found) do
let s ∈I \ R;
reachable cycle(s);
od
if ¬cycle found then
return (”yes”)
(* TS |= ”eventually for ever Φ” *)
else
return (”no”, reverse(V.U))
(* stack contents yield a counterexample *)
ﬁ
procedure reachable cycle (state s)
push(s, U);
(* push s on the stack *)
R := R ∪{ s };
(* mark s as reachable *)
compute ample(s) satisfying (A1)–(A3);
(* see Section 8.2.3 *)
mark(s) := ∅;
(* taken actions in s *)
repeat
s′ := top(U);
if ample(s′) = mark(s′) then
if s ̸|= Φ then
cycle found := cycle check por(s′);
(* start the inner DFS in s′ *)
ﬁ
pop(U);
else
let α ∈mark(s′) \ ample(s′);
mark(s′) := mark(s′) ∪{ α };
(* mark α as taken *)
if α(s′) ̸∈R then
push(α(s′), U);
R := R ∪{ α(s′) };
(* α(s′) is a new reachable state *)
compute ample(α(s′)) satisfying (A1)–(A3);
(* see Section 8.2.3 *)
mark(α(s′)) := ∅;
else
if α(s′) ∈U then ample(s′) := Act(s′); ﬁ
(* establish (A4′) *)
ﬁ
ﬁ
until ((U = ε) ∨¬ b)
endproc

626
Partial Order Reduction
Algorithm 40 Cycle detection (inner DFS) using ample sets
Input: state s in ˆ
TS with s ̸|= Φ
Output: true if s belongs to a cycle in ˆ
TS; otherwise false
(* T organizes the set of states that have been visited in previous calls of
*)
(* cycle check por(·). V serves as DFS stack for cycle check por(·),
*)
(* U as DFS stack for the outer DFS (Algorithm 39).
*)
procedure boolean cycle check por(state s)
boolean cycle found := false;
(* no cycle found yet *)
push(s, V );
T := T ∪{ s };
repeat
t := top(V );
(* check whether t is still on the stack of the outer DFS *)
if t ∈U then
cycle found := true;
(* there is a cycle t . . . s . . . t *)
push(t, V );
else
if ample(t) = mark(t) then
pop(V );
(* all successors of t in ˆ
TS have been explored *)
else
let α ∈ample(t) \ mark(t);
mark(t) := mark(t) ∪{ α };
push(α(t), V );
T := T ∪{ α(t) };
ﬁ
ﬁ
until ((V = ε) ∨cycle found)
return cycle found
endproc

The Linear-Time Ample Set Approach
627
8.2.3
Computing Ample Sets
This section is devoted to techniques to determine the ample sets by means of a static
analysis of channel systems. The aim is to ﬁnd criteria for selecting ample sets that can
be checked eﬃciently by a syntactic analysis of the high-level formal description of the
system provided as a channel system. As the cycle condition (A4) can be established in
the way described before, the focus is on satisfying conditions (A1) through (A3). Recall
that a channel system CS consists of a number of concurrent processes, P1 through Pn
say, given as program graphs PG1 through PGn that may have shared variables and may
communicate with each other via channels, i.e., ﬁrst-in-ﬁrst-out buﬀers that can store
messages.
Communication via a channel of capacity zero corresponds to handshaking
plus the exchange of some data.
The transition system of CS is denoted as TS, i.e.,
TS = TS(CS) where CS = [PG1 | . . . | PGn]. A detailed introduction and formalization
of channel systems is given in Chapter 2.
When considering channel c as buﬀer, the
communication action c!v puts value v (at the rear of) the buﬀer whereas c?x retrieves an
element from (the front of) the buﬀer while assigning it to x.
Let Acti and Loci denote the action set and set of locations of PGi, respectively. Assume
that any action α ∈Acti occurs in exactly one edge ℓ
g:α

→ℓ′ in program graph PGi and
that the action sets Act1, . . . , Actn are pairwise disjoint. (This can always be ensured
by renaming of actions.)
In order to treat all edges in a uniform manner, we assume
communication actions to be preceded by guards that equal true, e.g., ℓ
c?x

→ℓ′ is written
as ℓ
g:c?x

→ℓ′ where g equals true.
Let us ﬁrst introduce some notations. For action α, let Var(α) denote the set of variables
occurring in α, and Modify(α) ⊆Var(α) the set of variables that are modiﬁed by α. For
example:
• Var(x := x + y) = { x, y } and Modify(x := x + y) = { x },
• Var(c?x) = Modify(c?x) = { x }, and
• Var(c!v) = Modify(c!v) = ∅if v is a value (in the domain of channel c).
Variable x is local to process Pi if no other process refers to x, i.e., if x /∈Var(α) for any
α ∈
1⩽j⩽n
j̸=i
Actj.
Let Acti(s) = Act(s) ∩Acti denote the set of actions of process Pi which are enabled in
(global) state s in TS = TS(CS). State s has the form ⟨ℓ1, . . . , ℓn, η, ξ⟩where ℓi denotes

628
Partial Order Reduction
the current location (control point) of PGi, η is the variable evaluation, and ξ the channel
evaluation. As before, TS is assumed to have no terminal states, i.e., Acti(s) ̸= ∅for
some process Pi, for any state s.1
As a ﬁrst step, we partition the set of processes P1 through Pn into two blocks. The ﬁrst
block contains processes Pi1 through Pik; the remaining processes constitute the other
block. A possible criterion to obtain such partitioning is to exploit the communication
pattern of the processes, e.g., no process Pij (0 < j ⩽k) is able to communicate to
processes outside this set. The intuition is to let ample(s) = Acti1(s) ∪. . . ∪Actik(s), for
(global) state s in TS(CS). This guarantees that by executing actions not in ample(s), it
is impossible that an action β that depends on ample(s) will become enabled in a global
state, and therefore would possibly be executed before an action in ample(s)—violating
(A2). For simplicity, suppose k=1 and let ample(s) = Acti(s), for some i. If no other
process Pj with j ̸= i can perform an action in s, then Acti(s) = Act(s), and s is fully
expanded (and evidently satisfying (A1) through (A3)).
Consider that Acti(s) is a proper subset of Act(s). Checking the nonemptiness condition
(A1) is trivial; it just amounts checking whether process Pi can perform an action in state
s, i.e., Acti(s) ̸= ∅. Checking the stutter condition (A3) amounts to check whether all
actions in Acti(s) are stutter actions. This step can be facilitated by determining the
stutter actions by a static analysis—α is a stutter action if the atomic propositions in
TS(CS) refer neither to a variable in Modify(α) nor to the source or target location of
edges of the form ℓ
g:α

→ℓ′ nor to the content of channel c if α is a receive or send action on
c.
Conditions (A1) and (A3) are thus relatively easy to deal with. This does not hold for
condition (A2) as this imposes a requirement on any execution in the full transition system
TS(CS). (The cycle condition (A4) is also a global property, but refers to the reduced
transition system ˆ
TS that needs to be analyzed anyway. For this reason the cycle condition
is easier to handle.) It turns out that checking (A2) is as hard as checking a reachability
property in the full transition system TS.
Theorem 8.25.
Algorithmic Diﬃculty of Checking (A2)
The worst-case time complexity of checking (A2) in ﬁnite, action-deterministic transition
system TS equals that of checking TS′ |= ∃♦a, for some a ∈AP, where TS′ is a ﬁnite,
action-deterministic transition system of the same size as TS.
Proof: Let TS = (S, Act, →, I, AP, L) be a ﬁnite, action-deterministic transition system
1In case TS = TS(CS) has terminal states, condition (A1) has to be replaced by (A1.1) and (A1.2), see
Remark 8.22 on page 619.

The Linear-Time Ample Set Approach
629
and a ∈AP. Without loss of generality, assume I = { s0 }. (In case there is more than one
initial state, a new state s0 can be introduced such that s0 has no incoming transitions,
and s0
α
−−→s′, if s
α
−−→s′ for initial state s.) Assume there is some (possibly unreachable)
state t ∈S with t |= a. (If such a state does not occur in TS, then this state t may just
be added.)
The idea of the proof is to deﬁne transition system TS′ and ample sets for the states in
TS′ such that t ∈Reach(TS) if and only if the ample sets deﬁned for TS′ violate condition
(A2). TS′ results from TS by adding the dependent actions α and β to the actions of TS,
such that β is enabled in any state of TS and independent of Act while α is only enabled
in the a-states (and results in the new state trap). Formally:
TS′ = (S ∪{ trap }, Act′, →′, { s0 }, AP, L′)
where trap /∈S, Act′ = Act ∪{ α, β, τ } for α, β, τ /∈Act. The labeling function L′ is
irrelevant. The transition relation →′ is deﬁned by
s
γ
−→s′ γ ∈Act
s
γ
−→′ s′
and
s |= a
s
α
−−→′ trap
and
s ∈S
s
β
−−→′ s
and
trap
τ
−→′ trap
Accordingly, the transitions in TS are extended such that α ∈Act(s) if s |= a, β ∈Act(s)
for all s ∈S, and trap is equipped with a self-loop labeled with the special action τ.
Let the ample sets for TS′ be deﬁned by
ample(s) = Act′(s) for all s ∈(S ∪{ trap }) \ { s0 } and ample(s0) = { β }.
That is, all states are fully expanded except for the initial state s0. Actions α and β
are dependent in TS′, since α and β are both enabled in any a-state s, but β cannot
be executed in state α(s) = trap. Due to the β-loops inserted at all states s ∈S, β is
independent of Act.
Claim: TS |= ∃♦a if and only if the ample sets in TS′ violate (A2).
1. (⇒) Let t ∈Reach(TS) for some t ∈S with t |= a. Then there exists an initial
execution fragment in TS′ of the form
ϱ = s0 −→. . . −→t



initial execution
fragment in TS
α
−−→trap.
Since β ∈Act(s0) and α and β are dependent in TS′, action α depends on ample(s0) =
{ β } in TS′. But since α is only enabled in state t and not in any state visited in
ϱ prior to t, ϱ violates (A2). (Note that β cannot occur in the execution fragment
s0 −→. . . −→t, as β is not an action of TS.)

630
Partial Order Reduction
2. (⇐) Assume (A2) is violated in TS′. Then there exists a state v ∈Reach(TS′) and
an execution fragment
v
γ1
−−→s1
γ2
−−→. . .
γn
−−→sn
γ
−→s′
in TS′ such that (i) γ depends on ample(v) and (ii) γ1, . . . , γn /∈ample(v). Since s0
is the only state that is not fully expanded, it follows from (ii) that v = s0. Due to
ample(s0) = { β } and since β is independent of all actions in TS, (i) yields γ = α.
Since α is only enabled in the a-states, it follows sn |= a. Thus, TS′ |= ∃♦a. By
construction of TS′, we get v, s1, . . . , sn ∈Reach(TS)—the only state in TS′ that is
not in TS is the state trap that has no outgoing transitions. Hence, TS |= ∃♦a.
Remark 8.26.
A Technical Remark on the Proof of Theorem 8.25
The above proof suggests that TS′ needs to be explicitly generated. This is, however, not
true. Suppose TS = TS(PG1 ||| . . . ||| PGn) for program graphs PG1, . . . , PGn and a is
the atomic proposition stating that variable y evaluates to 0. Introduce a new Boolean
variable x with initial value 0, strengthen all guards in any edge in PG1, . . . , PGn with the
conjunct x=0, and introduce the program graphs PGα, PGβ and PGτ that are deﬁned by
• the command “if x = 0 then skip

β
ﬁ” in an inﬁnite loop (PGβ),
• the command “if y = 0
  
a
then x := 1
  
α
ﬁ” (PGα),
• the skip-command in an inﬁnite loop (PGτ).
Program graphs PGβ and PGτ consist of a single location with a self-loop (labeled with
β and τ, respectively), while PGα consists of two locations connected by an edge with the
guard y = 0 and the action α for modeling the assignment x := 1. We then consider
TS′ = TS(PG1 ||| . . . ||| PGn



original program
||| PGα ||| PGβ ||| PGτ



extension
).
In this way, a representation of TS′ is obtained from the representation of TS in constant
time.
As a result of Theorem 8.25, (A2) is not checked for an arbitrary set of transitions, but
the structure of the program graph will be exploited to determine ample sets for which

The Linear-Time Ample Set Approach
631
condition (A2) is guaranteed to hold. In fact, by means of a static analysis of the program
graphs it will be determined which actions will be dependent. Let us consider determining
these dependencies in more detail.
Overapproximating Dependencies
Let D ⊆Act × Act be a binary relation on ac-
tions, that is intended to be an overapproximation of the dependency relation. That is, if
(α, β) ∈D, α and β are considered to be dependent. As D is an overapproximation, it
follows that if (α, β) ̸∈D, then α and β are independent; on the other hand, (α, β) ∈D
does not exclude that α and β might be independent. It is evident that if (A2) holds
for D, then it also holds for the proper dependency relation. Why do we not consider
the proper dependency relation, i.e., the complement of the independence relation? The
problem is that the notion of independency is a global property. For instance, it might
seem reasonable to consider the actions x := z + y and x := z to be dependent as they
modify the same variable. This is a local criterion. However, if there is no state in TS with
y ̸= 0 in which both actions are enabled, then they could be considered to be independent.
The latter is, however, a global property. Since the aim is to avoid the construction of
TS, and to determine ample sets prior to the state-space generation, we have to rely on
criteria that can be considered during a static analysis of the program graphs.
Let us brieﬂy sketch which simple syntactic criteria can be employed to determine D. It
seems reasonable that all pairs of actions belonging to the same process are dependent.
A simple, though rather conservative strategy would be to consider all pairs of actions
that refer to the same variable to be dependent. This is somewhat restrictive as, e.g., the
assignments x := y + 1 and z := y + z are in fact independent since they do not modify
the shared variable y. A more reﬁned strategy would consider the modiﬁed variables. A
simple, conservative strategy could be to consider all communication actions acting on the
same channel to be dependent (i.e., in D). This is somewhat restrictive as, e.g., actions
c!v and c?x for channel c with capacity one can never be enabled in the same global state:
either the channel is full or empty. Any action involving a synchronous channel (a channel
with capacity zero) is a joint action of two processes, and may thus be considered to be
dependent on all actions in both involved processes.
Local Criteria for (A2)
Local criteria which ensure that the choice ample(s) = Acti(s)
satisﬁes condition (A2) can be obtained as follows. (Recall that Acti(s) = Act(s) ∩Acti.)
As before, we assume all actions for the processes P1, . . . , Pn to be pairwise disjoint.
To ensure condition (A2), we check whether the following two (somewhat conservative)
conditions hold in global state s:
(A2.1) Any β ∈Actj is independent of Acti(s) for i ̸= j.

632
Partial Order Reduction
(A2.2) Any β ∈Acti\Act(s) may not become enabled through the activities of some process
Pj with i ̸= j.
Condition (A2.1) can be established by inspecting the program graphs of all processes Pj
and checking whether for any α ∈Acti and β ∈Actj, (α, β) ̸∈D. Note that all actions
local to process Pi are considered to be dependent by (A2.1). Condition (A2.2) considers
a global state s = ⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩and action β of process Pi that might be enabled
in ℓi, i.e., ℓi
g:β

→ℓ′
i occurs in PGi, but is disabled in s. This may be due to the fact that
the guard g does not hold, or the action β might be blocked (e.g., a send action to a full
channel). In order to ensure that β will not become enabled by activities of some other
process Pj, it should be the case that neither:
• the guard g is violated in s (as g may refer to shared variables that can be modiﬁed
by other processes), nor that
• β is a disabled communication action for a channel of nonzero capacity (which may
become enabled as another process either enters or removes a message from the
channel), nor that
• β is a disabled handshaking action (which may become enabled due to an activity
of another process),
nor that for some i ̸= j, there is an edge ℓ′
j
h:γ

→ℓ′′
j in PGj such that
• ℓ′
j is reachable (via 
→∗) from the current location ℓj (in state s) in PGj, and action
γ modiﬁes some variable that occurs in the guard g, or γ and β are complementary
communication actions, i.e., send and receive actions on the same channel.
Thus, (A2.2) ensures that for global state s = ⟨ℓ1, . . . , ℓi, . . . , ℓn, η, ξ⟩there do not exist
actions β ∈Acti \ Act(s) and γ ∈
j̸=i Actj and states
s′ = ⟨. . . , ℓ′
j, . . . , ℓi, . . . , η′, ξ′⟩, and s′′ = ⟨. . . , ℓ′′
j , . . . , ℓi, . . . , η′′, ξ′′⟩
where process Pi resides in location ℓi (as in state s) such that:
β /∈Act(s′) and
s −→. . . −→s′



β is not enabled
γ
−→s′′
β
−−→. . .
Let us consider a small example. Condition (A2.2) is violated in state s = ⟨. . . , ℓi, . . . , x =
0⟩if there are edges
ℓi
x>0:β

→ℓ′
i
and
ℓ′
j
x:=1

→ℓ′′
j

The Linear-Time Ample Set Approach
633
in PGi and PGj with i ̸= j such that ℓ′
j is reachable (via 
→∗) from ℓj. Note that the
action pairs (β, γ) referred to in (A2.2), as well as the reachability relation 
→∗in the
program graphs PG1, . . . , PGn, can be determined by a static analysis. The same applies
to (A2.1). As the size of program graphs is relatively small compared to their underlying
transition system, the cost of analyzing the program graphs for checking (A2.1) and (A2.2)
is negligible compared to the analysis of their transition systems.
The following lemma shows that conditions (A2.1) and (A2.2) are suﬃcient (though not
necessary) for (A2):
Lemma 8.27.
Suﬃcient Local Criteria for (A2)
If (A2.1) and (A2.2) hold, then ample(s) = Acti(s) satisﬁes (A2) for all execution frag-
ments in TS that start in state s.
Proof: By contraposition. Suppose that (A2.1) and (A2.2) hold for ample(s). Assume
(A2) does not hold and global state s is of the form ⟨. . . , ℓi, . . .⟩, i.e., process Pi is at
location ℓi. Then, there exists a ﬁnite execution fragment
s
β1
−−→s1
β2
−−→. . .
βn
−−→sn
βn+1
−−−−→. . .
where β1, . . . , βn /∈Acti(s) and βn+1 depends on ample(s) = Acti(s). Since (A2.1) holds,
actions depending on Acti(s) are actions of process i:
βn+1 ∈Acti \ Acti(s).
Let m be the largest index in { 1, . . . , n } such that β1, . . . , βm−1 are actions of other
processes, i.e.:
β1, . . . , βm−1 ∈

j̸=i
Actj \ Acti
and
βm ∈Acti
Since the actions β1, . . . , βm−1 cannot aﬀect the location of process Pi, location ℓi does not
change in the ﬁrst m−1 steps, i.e., states s1, . . . , sm−1 are also of the form ⟨. . . , ℓi, . . .⟩. As
βm /∈Acti(s) and βm ∈Acti(sm−1), action βm becomes enabled in location ℓi by executing
one of the actions in the set { β1, . . . , βm−1 }. Since β1, . . . , βm−1 are actions of processes
diﬀerent from Pi, this contradicts (A2.2).
Algorithm 41 on page 634 summarizes the main steps for computing the ample set of a
given state s such that conditions (A1), (A2), and (A3) are fulﬁlled. We consider here
the case where the candidates are the action sets Acti(s), i.e., the actions of Pi that are
enabled in s.

634
Partial Order Reduction
Algorithm 41 Computation of ample(s)
Input: state s = ⟨ℓ1, . . . , ℓn, η, ξ⟩in ˆ
TS
Output: ample(s) ⊆Act(s) such that (A1)-(A3) are fulﬁlled
(* let D ⊆Act × Act such that (α, β) ∈D if α and β are dependent *)
determine Acti(s) for all 0 < i ⩽n;
if (∃i. Acti(s) = Act(s)) then return Act(s) ﬁ;
for i = 1 to n do
(* check whether ample(s) = Acti(s) is possible *)
if (Acti ̸= ∅and Acti(s) only contains stutter actions) then
if (∃j ̸= i. Acti(s) × Actj(s) ∩D = ∅) then
b := true;
(* (A2.1) holds *)
if ∃ℓi
g:β

→ℓ′
i in PGi where β is a handshaking action then
b := false;
(* (A2.2) violated *)
else
for all ℓi
g:β

→ℓ′
i in PGi and ℓ′
j
h:γ

→ℓ′′
j in PGj with j ̸= i and ℓj 
→∗ℓ′
j do
if (η ̸|= g and γ modiﬁes some variable that occurs in g) or
(β and γ are complementary communication actions) then
b := false;
(* (A2.2) violated *)
ﬁ
od
ﬁ
if (b) then return Acti(s) ﬁ
(* (A1)-(A3) hold *)
ﬁ
ﬁ
od
(* ample(s) cannot be deﬁned as the action set of one process *)
return Act(s)
(* ample(s) := Act(s) *)

The Linear-Time Ample Set Approach
635
8.2.4
Static Partial Order Reduction
Rather than realizing the partial order reduction criteria during the model-checking pro-
cess, in static partial order reduction the reduced transition system ˆ
TS, or preferably, a
high-level formal description of ˆ
TS, is constructed prior to the veriﬁcation. The advantage
of this approach is that it may be combined with other state-space reduction techniques
such as symbolic approaches using binary decision diagrams, or bisimulation minimization.
This section treats static partial order reduction starting from the high-level description
PG1 ||| . . . ||| PGn, where, for the sake of simplicity, it is assumed that the program graphs
have shared variables but do not communicate via channels.
The main quest for static partial order reduction is to determine ample sets that satisfy
the conditions (A1) through (A4). As described in Section 8.2.3, the conditions (A1),
(A2), and (A3) can be established by means of local criteria of transition systems. It
turns out that these criteria can also be easily reformulated for program graphs and thus
can be checked prior to model checking. In contrast to on-the-ﬂy partial order reduction,
however, (A4) cannot be checked by establishing the strong cycle condition (A4′), as this
condition is tailored to the state space generation by means of a depth-ﬁrst search, a step
that is absent in the static approach. Instead, (A4) is established by inspection of the
program graphs PG1 through PGn by ﬁxing a set Asticky of sticky actions:
Asticky ⊆Act
The purpose of actions in Asticky is to serve to “break” any cycle in ˆ
TS. For state s, action
α ∈Asticky ∩ample(s) “sticks”, so to speak, all other enabled actions in s and forces their
exploration.
Notation 8.28.
Visible Action
An action α ∈Act is visible if α is not a stutter action, i.e., if there exists a state s in TS
with α ∈Act(s) and L(s) ̸= L(α(s)). Let Vis denote the set of visible actions.
The following requirements are imposed on Asticky.
(S1) Visibility condition
Vis ⊆Asticky
The visibility condition (S1) asserts that all visible actions are sticky, or equivalently, that
all actions in Act \ Asticky are stutter actions.

636
Partial Order Reduction
(S2) Cycle-breaking condition
For any cycle s0
β1⇒. . .
βn⇒sn in ˆ
TS, Asticky ∩{ β1, . . . , βn } ̸= ∅.
Condition (S2) thus asserts that any cycle in ˆ
TS contains at least one sticky action.
Consider now the following new condition on ample sets:
(A3/4) Sticky condition
If ample(s) ̸= Act(s), then ample(s) ∩Asticky = ∅.
Condition (A3/4) asserts that ample actions of nonfully expanded states are not sticky.
The condition (A3/4) implies both the stutter condition (A3) and the strong cycle condi-
tion (A4′). This is stated by the following lemma.
Lemma 8.29.
Sticky vs. Stutter and Cycle Condition
Let TS = (S, Act, →, I, AP, L) be a ﬁnite, action-deterministic transition system and
Asticky ⊆Act satisfying (S1) and (S2). If the ample sets for s ∈S satisfy (A3/4), then
(A3) and (A4′) hold.
Proof: Let s ∈S with ample(s) ̸= Act(s) and suppose (A3/4) holds.
1. The sticky condition (A3/4) ensures that ample(s) ∩Asticky = ∅. By the visibility
condition (S1), any α ∈ample(s) is a stutter action. Thus, (A3) holds.
2. Consider the cycle s0
β1⇒s1 . . .
βn⇒sn in ˆ
TS. By the cycle-breaking condition (S2),
we have βi ∈Asticky for some 0 < i ⩽n. So βi ∈ample(si−1) ∩Asticky. The sticky
condition (A3/4) yields that si−1 is fully expanded, i.e., ample(si−1) = Act(si−1).
Hence, (A4′) holds.
As a consequence we have the following result. If Asticky satisﬁes (S1) and (S2), and the
ample sets satisfy (A1), (A2), and (A3/4), then TS ≜ˆ
TS. In the sequel of this section, we
will discuss in detail how to check that all conditions (S1), (S2), (A1), (A2) and (A3/4)
are fulﬁlled by inspecting the program graphs of the concurrent processes involved.

The Linear-Time Ample Set Approach
637
Program Graph Reduction.
First, we discuss how to establish the ample set condi-
tions by a static analysis of the program graphs. It is assumed that Asticky satisﬁes (S1)
and (S2); later on it is explained how this can be guaranteed. For the sake of simplicity,
processes cannot communicate via channels (but may have shared variables). That is, the
full transition system TS has the form TS = TS(PG) where PG = PG1 ||| . . . ||| PGn for
program graphs PG1, . . . , PGn that do not contain any communication actions on chan-
nels. As before, Acti denotes the action set of PGi and Acti ∩Actj = ∅if i ̸= j, and
that no α ∈Acti occurs on more than one edge in PGi.
Thus, there is a one-to-one
correspondence between the actions in PGi and the edges in PGi. It is assumed that
an overapproximation D of the dependency relation has been computed (see page 631).
Finally, we assume that PGi has a single starting location, denoted ℓ0,i, and an initial
condition g0,i.
The idea is to transform PG = PG1 ||| . . . ||| PGn into ,
PG = ,
PG1 ||| . . . ||| ,
PGn such that
TS(PG) ≜TS(,
PG). The transformation of each program graph PGi proceeds in a number
of steps. First, the edges in PGi are marked with the labels good and sticky and locations
with the label ample in the following way:
1. For any action α ∈Asticky ∩Acti, the (unique) edge ℓ
g:α

→ℓ′ in PGi is marked as
sticky.
2. An edge ℓ
g:α

→ℓ′ in PGi is marked good if and only if for any action β in some
program graph PGj, i̸=j, (α, β) /∈D and variables modiﬁed by β do not occur in
guard g.
3. Location ℓof PGi is marked as ample if all its outgoing edges ℓ
→ℓ′ are marked
good, but not sticky, and the disjunction of the guards of all outgoing edges of ℓis
equivalent to true.
After this (partial) labeling phase, the program graphs PGi are modiﬁed as follows. Let
ample1, . . . , amplen be new Boolean variables. These variables are set to true on edges
that lead to locations that are marked as ample, and are set to false on all other edges:
4. Edge ℓ
g:α

→ℓ′ in PGi is replaced by ℓ
g:ˆα

→ℓ′, where ˆα is the atomic execution of
α followed by amplei := true whenever ℓ′ is marked as ample, and α followed by
amplei := false (atomically) otherwise.
In the next step, the guards of the edges in program graph PGi are strengthened with
propositions about the amplei boolean variables. Let

638
Partial Order Reduction
hi
=

1⩽j<i
¬amplej ∧amplei,
i = 1, . . . , n and
f
=

1⩽j⩽n
¬amplej.
The intuitive meaning of proposition hi is that the enabled actions of process Pi will serve
as an ample set, while f indicates that the state corresponding to the current location is
fully expanded. The guards in PGi are adapted in the following way:
5. Any edge ℓ
g:α

→ℓ′ in PGi is replaced with the edge ℓ
bg:ˆα

→ℓ′ where g = g ∧hi if the
source location ℓis marked as ample, and g = g ∧f otherwise.
The initial condition of
ˆ
PGi is deﬁned as follows:
6. ˆg0,i
=
g0,i ∧amplei if the starting location ℓ0,i in PGi is marked as ample, and
ˆg0,i = g0,i ∧¬amplei, otherwise.
These transformations of PGi yield the program graph ˆ
PGi. The reduced transition system
ˆ
TS is obtained as follows:
ˆ
TS = TS( ˆ
PG)
where
ˆ
PG = ˆ
PG1 ||| . . . ||| ˆ
PGn.
Some remarks are in order.
First, observe that
ˆ
PGi is not a reduced variant of PGi,
i.e., it contains the locations of PGi and extends its variables with the auxiliary variables
amplei.
State ˆs in
ˆ
TS has the form ⟨ℓ1, . . . , ℓn, η⟩where ℓi is a location in
ˆ
PGi (and
PGi) and η is a variable evaluation for the variables in PG1, . . . , PGn and the auxiliary
variables ample1, . . . , amplen. In contrast, state s in TS has the form ⟨ℓ1, . . . , ℓn, η⟩where
η assigns values to the variables in PG1, . . . , PGn. Nevertheless, ˆ
TS can be considered as
a subsystem of TS that results from the transition relation
⇒deﬁned by the ample sets:
on entering state ⟨ℓ1, . . . , ℓn, η⟩in ˆ
TS it holds η(amplei) = true if and only if location ℓi of
PGi is marked as ample. This also applies to the initial state. In particular, the reachable
fragment in ˆ
TS will not be larger than the reachable fragment in TS.
Lemma 8.30.
Invariant for
ˆ
TS
For any state ⟨ℓ1, . . . , ℓn, η⟩in Reach( ˆ
TS) and 0 < i ⩽n:
η |= amplei if and only if ℓi is marked as ample.
The above lemma allows us to identify state ˆs = ⟨ℓ1, . . . , ℓn, η⟩in
ˆ
TS with state s =
⟨ℓ1, . . . , ℓn, η⟩in TS where η results from η by ignoring the vaulation of the auxiliary

The Linear-Time Ample Set Approach
639
variables ample1, . . . , amplen. The action ˆα in ˆ
TS can be identiﬁed with action α in TS.
Due to the transformation of PGi, ample(s) for global state s in TS consists of actions α
for α ∈Act(s). This permits treating ample(ˆs) as a subset of Act(s).
Example 8.31.
Program Graph Transformation
Consider the program graphs PG1 and PG2 in Figure 8.14. Intuitively, PG1 and PG2
both describe a process which counts iteratively from 0 to N where N is a ﬁxed positive
integer. Initially, x = y = 0 and b = c = false, where these variables are all local.
n1
ℓ1
true:
x := 0;b := ¬b



action a1
x = N:
skip

action `1
x < N:
x := x+1



action _1
n2
ℓ2
true:
y := 0;c := ¬c



action a2
y = N:
skip

action `2
y < N:
y := y+1



action _2
Figure 8.14: Two counting processes as program graph PG1 (left) and PG2 (right).
Let AP = { b, c }, i.e., the only observable part of the program graphs is the value of b and
c. It follows that the actions α1, β1, α2, and β2 are stutter actions, whereas γ1 and γ2 are
visible. As all visible actions need to be sticky actions, a ﬁrst choice for Asticky is:
Asticky = { γ1, γ2 }.
This choice also satisﬁes (S2), since any cycle in ˆ
TS contains γ1 or γ2—a cycle can only
occur if both x and y have the same value, and this can only occur by ﬁrst counting
until N and resetting to zero (via a γ action). Actions α1 and β1 are independent of
Act2 = { α2, β2, γ2 }, and symmetrically, α2 and β2 are independent of Act1 = { α1, β1, γ1 }.
Consider the transformation from PG1 and PG2 into
ˆ
PG1 and
ˆ
PG2, respectively. This
goes along the steps described before. We start by marking the αi- and βi-edges as good as
these actions are independent. The γi-edges are marked as sticky. Accordingly, the initial
locations n1 and n2 are marked as ample (they only have edges marked as ample), while
locations ℓ1 and ℓ2 are not. Completing steps (4) through (6) yields the program graphs
ˆ
PG1 and
ˆ
PG2 in Figure 8.15. The initial condition for the modiﬁed program graphs is
x = y = 0 ∧b = c = false ∧ample1 = ample2 = true.

640
Partial Order Reduction
n1
ℓ1
¬ample1 ∧¬ample2:
x := 0;b := ¬b;ample1 := true



action ˆa1
(x = N)∧ample1:
ample1 := false



action ˆ`1
(x < N)∧ample1:
x := x+1;ample1 := true



action ˆ_1
n2
ℓ2
¬ample1 ∧¬ample2:
y := 0;c := ¬c;ample2 := true



action ˆa2
(y = N)∧¬ample1 ∧ample2:
ample2 := false



action ˆ`2
(y < N)∧¬ample1 ∧ample2:
y := y+1;ample2 := true



action ˆ_2
Figure 8.15: Transformed program graphs
ˆ
PG1 (top) and
ˆ
PG2 (bottom).
We now consider the reduced transition system ˆ
TS = TS( ˆ
PG1 ||| ˆ
PG2). Observe that ˆ
TS is
smaller than TS = TS(PG1 ||| PG2) since it avoids the interleavings of the action sequences
αN
1 and αN
2 . Instead, if both processes are in their initial location ni, then the auxiliary
variables ample1 and ample2 evaluate to true. The added conjuncts h1 = ample1 on the
edge n1 
→n1 and h2 = ¬ample1 ∧ample2 on the edge n2 
→n2 give a higher priority to
ˆ
PG1 and thus enforce performing the action sequence αN
1 β1 prior to performing αN
2 . This
can be seen as follows.
For the initial state of ˆ
TS,
ˆs = ⟨n1, n2, x = y = 0, b = c = false, ample1 = ample2 = true⟩,
we have
Act(ˆs) = { α1 }
while
Act(s) = { α1, α2 }
where s = ⟨n1, n2, x = y = 0, b = c = false⟩is the state corresponding to ˆs in TS. The
same applies to all reachable states s of TS where both processes are in their initial location
and x < N and y < N. Thus, in all these states, a signiﬁcant reduction results. Consider

The Linear-Time Ample Set Approach
641
now a state t of the form
t = ⟨n1, n2, x = N, y = k, b = . . . , c = . . .⟩
where 0 ⩽k < N.
in TS. The corresponding state in ˆ
TS is
ˆt = ⟨n1, n2, x = N, y = k, b = . . . , c = . . . , ample1 = ample2 = true⟩.
We have Act(ˆt) = { β1 } which is a proper subset of Act(t) = { β1, α2 }. By symmetry,
similar observations apply to the state where both program graphs are in their initial
location, y=N and x < N. State
u = ⟨ℓ1, n2, x = N, y = k, b = . . . , c = . . .⟩
with
Act(u) = { γ1, α2 }
in TS where 0 ⩽k < N corresponds to the following state in ˆ
TS:
ˆu = ⟨ℓ1, n2, x = N, y = k, b = . . . , c = . . . , ample1 = false, ample2 = true⟩
with Act(ˆu) = { α2 } ⊂Act(u). The only fully expanded states are the states of the form
v = ⟨ℓ1, ℓ2, x = y = N, b = . . . , c = . . .⟩
that correspond to
ˆv = ⟨ℓ1, ℓ2, x = y = N, b = . . . , c = . . . , ample1 = ample2 = false⟩.
Hence Act(ˆv) = Act(v) = { γ1, γ2 }.
Theorem 8.32.
Correctness of the Sticky Set Approach
Let PG = PG1 ||| . . . ||| PGn, and
ˆ
PG =
ˆ
PG1 ||| . . . ||| ˆ
PGn, TS = TS(PG) and
ˆ
TS =
TS( ˆ
PG). Then
if Asticky satisﬁes (S1) and (S2). then ˆ
TS ≜TS.
Proof: Let PG = PG1 ||| . . . ||| PGn and
ˆ
PG = ˆ
PG1 ||| . . . ||| ˆ
PGn. Assume Asticky satisﬁes
(S1) and (S2). We prove that conditions (A1), (A2), and (A3/4) hold for all states in
Reach( ˆ
TS). Since (A3/4) implies (A3) and (A4′), and (A4′) implies (A4), it follows by
Theorem 8.13 that TS ≜ˆ
TS.
Let ˆs = ⟨ℓ1, . . . , ℓn, η⟩be a reachable state in ˆ
TS with corresponding state s = ⟨ℓ1, . . . , ℓn, η⟩
in TS. Consider two cases.

642
Partial Order Reduction
1. None of the locations ℓi is marked as ample.
Then PG and
ˆ
PG have the same
outgoing edges in (global) location ⟨ℓ1, . . . , ℓn⟩. Moreover, η |= g if and only if η |= g
for any guard g that occurs in PG. (Recall that η and η agree on the original program
variables.) Hence, state ˆs is fully expanded, i.e.,
Act(ˆs) = { α | α ∈Act(s) }.
It follows that conditions (A1), (A2), and (A3/4) are then fulﬁlled.
2. ℓi is marked as ample and ℓ1, . . . , ℓi−1 are not marked as ample. By Lemma 8.30,
η |= hi. For 1 ⩽j < i, any outgoing edge from ℓj in
ˆ
PGj is either guarded by hj
or f. As η(amplej) = true, we get η ̸|= hj. Similarly, as η(amplei) = true, we have
η ̸|= f. Thus, for 1 ⩽j < i, none of the outgoing edges from ℓj in
ˆ
PGj is enabled
in state ˆs. Similarly, for i < j ⩽n none of the outgoing edges from ℓj in PGj is
enabled since these edges are guarded by hj or f as both require amplei to be false.
Thus:
ample(ˆs) ⊆{ α | α ∈Acti(s) }.
Since ℓi is marked as ample, any action α of an edge ℓi
g:α

→ℓ′
i in PGi is marked as
good, but not marked as sticky. In particular, Acti(s) ∩Asticky = ∅which yields:
ample(ˆs) ∩Asticky = ∅
(where we identify α and α). Thus, condition (A3/4) is fulﬁlled. Since all actions in
ample(ˆs) are marked as good, conditions (A2.1) and (A2.2) are fulﬁlled. By Lemma
8.27 (page 633) it follows that the dependency condition (A2) holds. The nonempti-
ness condition (A1) is fulﬁlled since the mark ample ensures that the disjunction of
the guards of all outgoing edges of ℓi is true.
Computing Sticky Sets
It remains to explain how a set Asticky satisfying the conditions
(S1) and (S2) can be determined by a static analysis of the program graph. The obvious
choice Asticky = Act would evidently suﬃce, but then (A3/4) would not allow for any
reduction of the state space. The goal is to obtain a set Asticky satisfying (S1) and (S2)
that is as small as possible. Initially, we set Asticky = Vis, the set of visible actions. This
ensures the visibility condition (S1). In order to establish (S2), actions are added until any
cycle in ˆ
TS contains an action in Asticky. This is done by a static analysis of the program
graph, attempting to keep the cardinality of Asticky minimal.
Notation 8.33.
Control Path and Control Cycle
A control path of PGi is a sequence of edges in PGi of the form

The Linear-Time Ample Set Approach
643
ℓ0
g1:α1

→ℓ1
g2:α2

→. . .
gk:αk

→ℓk.
A control path in PGi is a control cycle if ℓk = ℓ0 and k > 0.
Notation 8.34.
PGi-Projection
Let ϱ = s0
α1
−−→. . .
αk
−−→sk be an execution fragment in TS where sj = ⟨ℓj
1, . . . , ℓj
n, ηj⟩
for 0 ⩽j ⩽k. The PGi-projection of ϱ is the control path of PGi resulting from ϱ by
(1) removing all transitions sj−1
αj
−−→sj where αj /∈Acti and (2) replacing the transitions
si−1
αi
−−→si where αj ∈Acti with the corresponding edge ℓj−1
i
gj:αj

→ℓj
i.
The PGi-projection of an execution fragment in TS is the control path in PGi that has
been taken in ϱ. Vice versa, any execution fragment in TS arises by the combination of
control paths in some of the program graphs PG1, . . . , PGn, possibly in an interleaved
way.
Example 8.35.
Projections
Consider TS = TS(PG1 ||| PG2) where PG1, PG2 are depicted in Figure 8.14 (page 639).
For N = 2, the execution fragment
⟨n1, n2, x = 0, y = 0, b = c = false⟩
α1
−−→
⟨n1, n2, x = 1, y = 0, b = c = false⟩
α1
−−→
⟨n1, n2, x = 2, y = 0, b = c = false⟩
α2
−−→
⟨n1, n2, x = 2, y = 1, b = c = false⟩
β1
−−→
⟨ℓ1, n2, x = 2, y = 0, b = c = false⟩
yields the PG1-projection n1
x<2:α1

→n1
x<2:α1

→n1
x=2:β1

→ℓ1 and the PG2-
projection n2
y<2:α1

→n2. Note that the PGi-projection of ϱ might have length 0 (i.e.,
solely consists of the location ℓ0
i ) in which case ϱ does not take any edge of PGi.
The following lemma is obvious:
Lemma 8.36.
Global Cycles vs. Control Cycle
For each cycle s0
α1
−−→. . .
αm
−−−→sm in TS and for any 0 < j ⩽n:
if { α1, . . . , αm } ∩Actj ̸= ∅, then the PGj-projection is a control cycle.

644
Partial Order Reduction
The converse of Lemma 8.36 does not hold, since, e.g., the control cycle n1
x<N:α1

→n1
in the program graph PG1 of Figure 8.14 does not induce a cycle in TS since the value of
x is strictly increasing in each iteration.
By Lemma 8.36, the cycle-breaking condition (S2) is obviously fulﬁlled if Asticky contains
at least one action of any control cycle in PG1, . . . , PGn. This is guaranteed as follows.
Let Asticky = Vis, the set of visible actions. This ensures (S1). As each visible action is
in Asticky, it suﬃces for establishing (S2) that any cycle that does not contain a visible
action is considered. To that end, all edges from PGi with a visible action are removed.
By means of a depth-ﬁrst search of the resulting program graph PG′
i, say, control cycles
are determined. Whenever a backward edge ℓ
g:α

→ℓ′ is found, α is added to the sticky
set. Applying this DFS-based approach to each program graph PGi yields Asticky. From
Lemma 8.36 together with the fact that for any control cycle in PG′
i the depth-ﬁrst search
will ﬁnd a backward edge on this cycle, it follows that Asticky satisﬁes (S2). Hence, Asticky
contains at least one action of each control cycle in PG′
i. The remaining control cycles in
PGi contain at least one visible action, and thus, an action in Vis ⊆Asticky.
This strategy often generates a rather large Asticky set.
For instance, for the program
graphs in Figure 8.14, the set
Asticky = { γ1, γ2 }



=Vis
∪{ α1, α2 }
is obtained because of the control cycles n1
x<N:α1

→n1 and n2
y<N:α2

→n2. However,
these control cycles do not correspond to cycles in TS since each execution of α1 strictly
increases the value of x. The same applies to α2 and variable y. In order to ﬁnd control
cycles that do not correspond to a global cycle, i.e., a cycle in TS, we impose for each
program variable x:
a transitive, irreﬂexive relation ≺x on the domain of x.
For example, for integer variable x, the relation ≺x could be the natural order < or
the reverse natural order >. For Boolean variable x, the order with false ≺x true and
true ̸≺x false is appropriate. The relation ≺x should be chosen such that the classiﬁcation
of the actions into incrementing, decrementing, neutral, or complex actions (see below) is
algorithmically simple. For variable x and order ≺x, the eﬀect of action α ∈Act is said
to be
• incrementing on x if η(x) ≺x Eﬀect(η, α)(x) for each valuation η,
• decrementing on x if Eﬀect(η, α)(x) ≺x η(x) for each valuation η,

The Linear-Time Ample Set Approach
645
• neutral on x if Eﬀect(η, α)(x) ̸≺x η(x) and η(x) ̸≺x Eﬀect(η, α)(x), for each valuation
η.
• complex in all other cases.
For instance, for integer variable x where ≺x is the natural order < we have: x := x+2 has
an incrementing eﬀect on x, action x := x −5 has a decrementing eﬀect on x, y := y −5
is neutral on x, and x := y has a complex eﬀect on x.
A control path ℓ0
g1:α1

→. . .
gk:αk

→ℓk has incrementing eﬀect on x if (1) the eﬀect
of αj on x is incrementing for some j ∈{ 1, . . . , k } and (2) for each j ∈{ 1, . . . , r }, j ̸= k,
the eﬀect of αj on x is either incrementing or neutral. Control paths with a decrementing
eﬀect on x are deﬁned analogously. For an execution fragment
s0
β1
−−→s1
β2
−−→. . .
βm
−−−→sm
such that for some i ∈{ 1, . . . , n }
• the PGi-projection is a control path ℓ0
g1:α1

→ℓ1 . . .
gr:αr

→ℓr which has an
incrementing eﬀect on x, and
• the PGj-projection for j ̸= i does not contain an action which has either a decre-
menting or complex eﬀect on x,
the value of x is strictly increasing with respect to the order ≺x. The transitivity of ≺x
yields v0 ≺x vm, where v0 and vm are the value of x in the state s0 and sm, respectively.
Since ≺x is irreﬂexive, v0 ̸= vm. Thus, the given execution fragment cannot be a cycle
in TS, i.e., s0 ̸= sm. A similar observation holds for control cycles with a decrementing
eﬀect on x.
Example 8.37.
Control Cycles vs. Global Cycles
Consider the program graphs in Figure 8.16 where N > 1 is a ﬁxed integer, x and y are
nonnegative integer variables, and b, c Boolean variables. Program graph PG1 has the
control cycle
n1
x<N:x:=x+1

→
ℓ1
b:=¬b

→n1.
For ≺x = <, this control cycle has an incrementing eﬀect on x.
None of the actions
α2, β2, γ2 in PG2 modify the value of x, i.e., these actions have a neutral eﬀect on x. Thus,
there is no cycle in TS for which the PG1-projection coincides with the above control
cycle.

646
Partial Order Reduction
n1
ℓ1
b := ¬b
  
action `1
x < N:
x := x+1



action _1
n2
ℓ2
c := b∧¬c



action `2
y = N:
skip

action `2
x < y:
y := y−1



action _2
Figure 8.16: Program graphs PG1 (left) and PG2 (right).
n1
ℓ1
b := ¬b
  
action `1
x < N:
x := x+1



action _1
n2
ℓ2
c := b∧¬c



action `2
x > 5:
x := x−2



action _2
Figure 8.17: Program graphs PG1 (left) and PG2 (right).
Now consider the program graphs in Figure 8.17. The control cycle
n1
x<N:x:=x+1

→
ℓ1
b:=¬b

→n1
in PG1 has an incrementing eﬀect on x. However, action α2 in PG2 has a decreasing eﬀect
on x. In fact, there is a global cycle in TS(PG1 ||| PG2) of the form
s
=
⟨n1, n2, x = 0, y = 0, b = false, c = false⟩
α1
−−→
⟨ℓ1, n2, x = 1, y = 0, b = false, c = false⟩
β1
−−→
⟨n1, n2, x = 1, y = 0, b = true, c = false⟩
α1
−−→
⟨ℓ1, n2, x = 2, y = 0, b = true, c = false⟩
β1
−−→
⟨n1, n2, x = 2, y = 0, b = false, c = false⟩
α2
−−→
⟨n1, ℓ2, x = 0, y = 0, b = false, c = false⟩
β2
−−→
⟨n1, n2, x = 0, y = 0, b = false, c = false⟩
= s
where the PG1-projection yields the (duplication of the) above control cycle.

The Linear-Time Ample Set Approach
647
The goal is now to compute Asticky by starting with A = Vis (as before) and adding further
actions to break any control cycle of program graph PGi, say, that only contains stutter
actions, except for actions that have an incrementing or a decrementing eﬀect on some
variable x and for which there is no action in PGj, i ̸= j with an opposite eﬀect on x.
Notation 8.38.
Opposite Actions
Actions α and β ∈Act are opposite if there exists a variable x such that α has either an
incrementing or complex eﬀect on x and β has either a decrementing or complex eﬀect on
x, or vice versa. Let
Opp(α) = { β ∈Act | α and β are opposite }.
Note that any action α with complex eﬀect on some variable is opposite to itself, in which
case α ∈Opp(α).
The computation of Asticky proceeds as outlined in Algorithm 42 on page 648. Here, an
action α is called monotonic on x if it has either an incrementing or decrementing eﬀect
on x.
Example 8.39.
Computing Asticky
Reconsider the program graphs PG1 and PG2 in Figure 8.16 (page 646). Let ≺x=<=≺y
and false ≺true for the Boolean variables b and c. Moreover, we assume that AP only
refers to variable y, but not to x, b, or c. Then, action α2 is visible and all other actions
are stutter actions. Hence, Algorithm 42 starts with Asticky = Vis = { α2 }. Removal of all
visible edges yields the program graphs in Figure 8.18.
n1
ℓ1
b := ¬b
  
action `1
x < N:
x := x+1



action _1
n2
ℓ2
c := b∧¬c



action `2
y = N:
skip

action `2
Figure 8.18: Program graphs PG1 (left) and PG2 (right) after removal of visible edges.
The algorithm obtains M1 = { α1 } since α1 has an incrementing eﬀect on x, but there

648
Partial Order Reduction
Algorithm 42 Computation of Asticky
Input: program graphs PG1, . . . PGn
Output: Asticky ⊆Act satisfying (S1) and (S2)
Asticky := Vis;
(* establish (S1) *)
for i = 1 to n do
PGi := PGi where any edge ℓ
g:α

→ℓ′ with α ∈Vis is removed;
od
for i = 1 to n do
Mi := { α ∈Acti | α is monotonic ∧Opp(α) ⊆

j<k⩽n
Actk };
PGi := PGi where any edge ℓ
g:α

→ℓ′ with α ∈Mj is removed;
od
for i = 1 to n do
perform a DFS on PGi;
Asticky := Asticky ∪{ α | ℓ
g:α

→ℓ′is a backward edge in PGi };
od
return Asticky
(* Asticky fulﬁlls (S1) and (S2) *)

The Linear-Time Ample Set Approach
649
is no opposite action. Hence, the α1-edge from n1 is ℓ1 will be removed. The resulting
program graph is acyclic; no backward edge is found.
We obtain M2 = ∅as there is no monotonic action in the modiﬁed PG2. Hence, one of the
actions β2 or γ2 becomes sticky (i.e., is added to Asticky), depending on the starting location
for the depth-ﬁrst search. The result of Algorithm 42 is thus either Asticky = { α2, β2 } or
Asticky = { α2, γ2 }.
Lemma 8.40.
Soundness of Algorithm 42
The set Asticky ⊆Act returned by Algorithm 42 satisﬁes (S1) and (S2).
Proof: The visibility condition (S1) obviously holds since initially Asticky = Vis, and no
actions are removed from Asticky. Now consider (S2). Let ϱ be a global cycle of the form
s0
β1
−−→s1
β1
−−→. . .
βm
−−−→sm = s0.
If some of the actions β1, . . . , βm are visible, then the cycle-breaking condition (S2) holds
since Vis ⊆Asticky. Assume β1, . . . , βm are stutter actions. We prove that there exists
some j such that (some of) the actions in ({β1, . . . , βm} ∩Actj) \ Mi yield a control cycle
ϑ in PG′′
j (the variant of PGj obtained after removing all edges with action in Mj). From
this result, it follows that the depth-ﬁrst search in PG′′
j will classify one of the edges in ϑ
as a backward edge, and hence, adds at least one of the actions in {β1, . . . , βm} ∩Actj to
Asticky. This yields Asticky ∩{β1, . . . , βm} ̸= ∅.
Let J be the set of indices j ∈{ 1, . . . , n } with { β1, . . . , βm } ∩Actj ̸= ∅. Clearly, J ̸= ∅.
Let j = max J and assume there is no control cycle in PG′′
j where the underlying action
set is contained in
({β1, . . . , βm} ∩Actj) \ Mj.
Since the PGj-projection of the given global cycle ϱ is a control cycle ϑ in PG′
j (Lemma
8.36 on page 643), the control cycle ϑ in PG′
j must contain an action βi ∈Mj. Otherwise,
ϑ is a control cycle in PG′′
j built by actions in ({β1, . . . , βm} ∩Actj) \ Mj.
By deﬁnition of Mj, action βi is monotonic. Since β1, . . . , βm forms a global cycle in TS,
there must be another action βh, h ̸= i, on this cycle with an opposite eﬀect:
βh ∈Opp(βi).
Again, by deﬁnition of Mj, the actions that are opposite to βi belong to Actk for some
k > j. Thus, βh ∈Actk for some k > j. But then, k ∈J and k > j, which contradicts
j = max J.

650
Partial Order Reduction
8.3
The Branching-Time Ample Set Approach
The previous section presented conditions for the ample sets that ensure the stutter trace
equivalence of TS and ˆ
TS. Hence, these conditions are sound for verifying LTL\⃝. This
section treats partial order reduction for the branching-time temporal logics CTL\⃝and
CTL∗
\⃝.
The aim is to adopt the ample set approach, and adapt it such that rather
than establishing TS ≜ˆ
TS we obtain that TS ≈div
ˆ
TS.
As ≈div coincides with the
logical equivalence of CTL\⃝and CTL∗
\⃝(see Section 7.8.3 on page 560), this yields a
sound approach for verifying these logics. We ﬁrst argue by means of an example that the
conditions (A1) through (A4) do not suﬃce for CTL\⃝.
Example 8.41.
Conditions (A1)-(A4) Are Insuﬃcient for CTL\⃝
Consider the transition system TS in Figure 8.19 (left) over AP = { a, b, c }. Actions α and
δ are independent of { β, γ } and β, γ are stutter actions. Let ample(s0) = { β, γ }, and
ample(s) = Act(s) for all states s ̸= s0; see the reduced transition system ˆ
TS in Figure
8.19 (right).
s0
u
{ a }
{ a }
{ a }
{ c }
{ b }
γ
α
β
α
α
δ
γ
β
δ
δ
γ
β
τ
τ
τ
τ
s0
{ a }
{ a }
{ c }
{ b }
γ
β
α
α
δ
δ
τ
τ
τ
τ
Figure 8.19: Reduction satisﬁes (A1)-(A4), but TS ̸≡CTL\⃝
ˆ
TS.

The Branching-Time Ample Set Approach
651
Consider the CTL\⃝formula:
Φ = ∀□

a →(∀♦b ∨∀♦c)

.
Formula Φ asserts that for each reachable a-state s either any path from s eventually
reaches a b-state or any path from s eventually reaches a c-state. Hence ˆ
TS |= Φ as any
a-state in TS has either a direct b- or c-successor, but TS ̸|= Φ as state u ̸|= ∀♦b ∨∀♦c.
The latter follows from the fact that
TracesTS(u) = { {a}{a}{b}ω, {a}{a}{c}ω }.
As ˆ
TS |= Φ and TS ̸|= Φ, we get TS ̸≈div
ˆ
TS. In fact, we have
β(s0) ̸≈div γ(s0) ̸≈div α(s0)
as β(s0) can reach a b-state, while γ(s0) cannot, and vice versa γ(s0) can reach a c-state,
while β(s0) cannot. Moreover, α(s0) (and s0) can reach both a b- and a c-state. The same
holds for the α-successor s1 of s0. Since ˆ
TS does not contain s (or any equivalent state),
TS ̸≈div
ˆ
TS.
Since s0 ≈div α(s0), the reduction obtained by ample(s0) = { α }, and ample(s) = Act(s)
for any state s ̸= s0 yields the reduced transition system ˆ
TS in Figure 8.20). Now we have
ˆ
TS ≈div TS.
s0
u
{ a }
{ a }
{ a }
{ c }
{ b }
α
δ
γ
β
δ
δ
γ
β
τ
τ
τ
τ
Figure 8.20: A sound partial order reduction for CTL∗
\⃝.
The task is now to provide suﬃcient ample set conditions that ensure TS ≈div ˆ
TS. Since
≜is strictly coarser than ≈div, the conditions (A1) though (A4) are extended with a
condition ensuring that the branching structure of TS is preserved.

652
Partial Order Reduction
In Example 8.41, ample(s0) = { α } resulted in a correct reduction. The soundness of
this reduction follows from the fact that s0 ≈div α(s0). The γ- and β-transitions in state
s0 can be mimicked in the reduced transition system by ﬁrst performing the stutter step
s0 −→α(s0) followed by γ or β, respectively. It turns out that this strategy is generally
applicable. Whenever (A1)-(A4) allow for choosing a singleton action set ample(s) = { α },
then state s ≈div α(s).
A formal proof of this statement will be provided later.
An
intuitive explanation is that all other enabled actions in s (i.e., all actions in Act(s)\{ α })
are enabled in α(s) and lead to states that are equivalent to the corresponding successors
of α. This suggests extending conditions (A1) through (A4) by
(A5) Branching condition
If ample(s) ̸= Act(s), then |ample(s)| = 1.
Example 8.42.
Consider again the transition system TS in Figure 8.19 (left). The reduction shown in
Figure 8.20 fulﬁlls conditions (A1) through (A5). The nonemptiness condition (A1) and
the branching condition (A5) are obviously fulﬁlled, since ample(s0) = { α } is a singleton
and all other states are fully expanded. The stutter condition (A3) holds since α is a
stutter action. The cycle condition (A4) is obvious since all states on a cycle (the states
equipped with a self-loop) are fully expanded. Finally, the dependency condition (A2) is
satisﬁed since α is independent of { β, γ }.
s0
u
{ a }
{ a }
{ a }
{ c }
{ b }
α
δ
γ
β
τ
τ
τ
τ
Figure 8.21: Partial order reduction that violates (A3).
Now consider the alternative selection of ample sets: ample(s0) = { α } and ample(α(s0)) =
{ δ }, while all other states are fully expanded. These ample sets yield the reduced system
ˆ
TS shown in Figure 8.21. Observe that TS ̸≈div
ˆ
TS since ˆ
TS does not contain a state
that is equivalent to β(s0)—there is no state labeled with ∅that can reach a c-state but

The Branching-Time Ample Set Approach
653
(A1) Nonemptiness condition
∅̸= ample(s) ⊆Act(s)
(A2) Dependency condition
Let s
β1
−−→. . .
βn
−−→sn
α
−−→t be a ﬁnite execution fragment in TS.
If α depends on ample(s), then βi ∈ample(s) for some 0 < i ⩽n.
(A3) Stutter condition
If ample(s) ̸= Act(s), then any α ∈ample(s) is a stutter action.
(A4) Cycle condition
For any cycle s0 s1 . . . sn in ˆ
TS and α ∈Act(si), for some 0 < i ⩽n,
there exists j ∈{ 1, . . . , n } such that α ∈ample(sj).
(A5) Branching condition
If ample(s) ̸= Act(s), then |ample(s)| = 1.
Figure 8.22: Requirements on the ample set of state s for CTL∗
\⃝.
not a b-state. The same applies to γ(s0). In fact, TS and ˆ
TS can be distinguished by the
CTL\⃝formula
Φ = ∀♦(a ∧∃♦b ∧∃♦c)
which holds for ˆ
TS, but not for TS. In fact, stutter condition (A3) is violated since the
chosen action δ in state α(s0) is not a stutter action.
The ample set conditions are summarized in Figure 8.22. The remainder of this section is
concerned with the proof of the correctness theorem:
Theorem 8.43.
Correctness of the Ample Set Approach for CTL∗
\⃝
For action-deterministic, ﬁnite transition system TS without terminal states:
If conditions (A1) through (A5) are satisﬁed, then TS ≈div
ˆ
TS.
Since ≈div coincides with CTL∗
\⃝equivalence (see Theorem 7.128, page 561), TS and ˆ
TS
are CTL∗
\⃝-equivalent, provided that (A1)-(A5) hold.

654
Partial Order Reduction
For the remainder of this section, let TS = (S, Act, −→, I, AP, L) be an action-deterministic,
ﬁnite transition system without terminal states and assume that the ample sets satisfy
(A1)-(A5).
As before,
ˆ
TS denotes the reduced transition system that arises from the
reachable fragment of TS under the transition relation ⇒given by
s
α
−−→s′ ∧α ∈ample(s)
s
α⇒s′
.
The initial states of ˆ
TS are the initial states in TS. ˆS denotes the state space of ˆ
TS, i.e.,
all states in S that are reachable (via ⇒) from some initial state s0 ∈I.
It will be shown that (A1) through (A5) ensure that there exists a normed bisimulation
that relates TS and
ˆ
TS. The concept of normed bisimulations has been introduced in
Deﬁnition 7.120 (page 552).
The correctness theorem then follows from the fact that
normed bisimulation is strictly ﬁner than ≈div.
Let us brieﬂy recall the main concepts of normed bisimulations. A normed bisimulation
for (TS, ˆ
TS) is a triple (R, ν1, ν2) where R ⊆S × ˆS and ν1, ν2 : S × ˆS →IN are functions
such that for all pairs (s1, s2) ∈R the following conditions are fulﬁlled:
(NI) L(s1) = L(s2), and
(NII) For all s′
1 ∈Post(s1), at least one of the following three conditions holds:
(N1) there exists s′
2 ∈Post(s2) with (s′
1, s′
2) ∈R, or
(N2) (s′
1, s2) ∈R and ν1(s′
1, s2) < ν1(s1, s2), or
(N3) there exists s′
2 ∈Post(s2) with (s1, s′
2) ∈R and ν2(s1, s′
2) < ν2(s1, s2),
and the analogous conditions for all s′
2 ∈Post(s2) with the “swapped” norm func-
tions ν−
2 (instead of ν1 in (N2)) and ν−
1 (instead of ν2 in (N3)) given by ν−
i (u, v) =
νi(v, u) for all u ∈ˆS and v ∈S.
In addition, it is required that each initial state of TS is related by R to some initial state
of ˆ
TS, and vice versa. Intuitively, ν1(s, ˆs) is an upper bound on the “allowed” number of
stutter steps from s that cannot be mimicked by transitions of ˆs, Natural ν2(s, ˆs) serves
as a counter for the number of stutter steps that ˆs may perform to reach a state where
the visible (nonstutter) steps of s can be simulated.
To deﬁne R and the norm functions ν1, ν2 we need some further notations.

The Branching-Time Ample Set Approach
655
Deﬁnition 8.44.
Forming Path, Relation ◁
Let TS be a ﬁnite, action-deterministic transition system and s, s′ ∈S. A forming path
from s to s′ is a ﬁnite execution fragment ϱ in TS of the form s0
β1
−−→s1
β2
−−→. . .
βn
−−→sn
where
• s = s0 and sn = s′,
• β1, . . . , βn are stutter actions, and
• for 1 ⩽i < n, the singleton action set {βi+1} fulﬁlls the dependence condition (A2)
for state si. That is, for any ﬁnite execution fragment si
α1
−−→t1
α2
−−→. . .
αm
−−−→tm
γ
−→. . .
where γ is dependent on βi+1, there exists j ∈{1, . . . , m} such that αj = βi+1.
We write s ◁s′ iﬀthere exists a forming path from s to s′.
The following simple properties of forming paths and the relation ◁will be used quite
often in the following argumentation. First, the relation ◁is transitive and reﬂexive (even
though, in general, nonsymmetric). The reﬂexivity is clear as each execution fragment of
length 0 yields a forming path. The transitivity follows from the fact that forming paths
from s to s′ and from s′ to s′′ can be concatenated resulting in a forming path from s
to s′′. Secondly, if s0
β1
−−→s1
β2
−−→. . .
βn
−−→sn is a forming path from s = s0 to s′ = sn of
length n, then si ◁sj for 0 ⩽i ⩽j ⩽n.
Lemma 8.45.
Properties of Forming Paths (Part 1)
Let s0
β1
−−→s1
β2
−−→. . .
βn
−−→sn be a forming path from s = s0 to s′ = sn and α be a stutter
action such that s
α
−−→t is a transition in TS. Then, we have:
(a) If α /∈{β1, . . . , βn}, then α is independent of {β1, . . . , βn} and there exists a forming
path t0
β1
−−→t1
β2
−−→. . .
βn
−−→tn from t = t0 to tn such that si
α
−−→ti for all indices
i ∈{1, . . . , n}.
(b) If α = βj and α /∈{β1, . . . , βj−1} for some j ∈{1, . . . , n}, then t◁s′ and there exists
a forming path from t to s′ with the action sequence β1 . . . βj−1 βj+1 . . . βn.
Proof: We ﬁrst prove (a). The independency of α from {β1, . . . , βn} is immediate from
the deﬁnition of forming paths that require (A2) to hold on all states of a forming path.
Lemma 8.15 (page 613) yields the existence of an execution fragment
t0
β1
−−→t1
β2
−−→. . .
βn
−−→tn

656
Partial Order Reduction
from t = t0 to tn such that si
α
−−→ti for all indices i ∈{1, . . . , n}. It remains to show
that this execution fragment is a forming path. Obviously, β1, . . . , βn are stutter actions.
We now have to show that the dependency condition (A2) holds for all states ti and the
singleton action sets {βi+1}. This is obvious since whenever
ti
γ1
−−→v1
γ2
−−→. . .
γk
−−→vk
γ
−→v
is an execution fragment where γ depends on βi, then
si
α
−−→ti
γ1
−−→v1
γ2
−−→. . .
γk
−−→vk
γ
−→v
is an execution fragment from si. Since (A2) holds for si and the singleton set {βi+1} and γ
depends on βi+1, one of the actions α, γ1, . . . , γk agrees with βi+1. Since α /∈{β1, . . . , βn},
we have γj = βi+1 for some j ∈{1, . . . , k}. Hence, (A2) holds for ti and the action set
{βi+1}.
We now consider (b) and suppose that α = βj and α /∈{β1, . . . , βj−1}. Applying (a) to
the forming path
s = s0
β1
−−→s1
β2
−−→. . .
βj−1
−−−−→sj−1
yields the existence of a forming path
t0
β1
−−→t1
β2
−−→. . .
βj−1
−−−−→tj−1
from t = t0 to some state tj−1 such that si
α
−−→ti is a stutter step for i = 1, . . . , j −1. Since
α = βj we have
tj−1 = α(sj−1) = βj(sj−1) = sj.
Thus, by adding the forming path sj
βj+1
−−−−→sj+1
βj+2
−−−−→. . .
βn
−−→sn from sj to sn = s′ a
forming path
t = t0
β1
−−→t1
β2
−−→. . .
βj−1
−−−−→tj−1 = sj
βj+1
−−−−→sj+1
βj+2
−−−−→. . .
βn
−−→sn = s′
from t to s′ with the action sequence β1 . . . βj−1 βj+1 . . . βn is obtained.
Lemma 8.46.
Properties of Forming Paths (Part 2)
Let s, s′ be two states in TS such that s ◁s′ and let α ∈Act(s).
(a) If there is a forming path from s to s′ in which α does not occur, then α ∈Act(s′)
and α(s) ◁α(s′).
(b) If α is a stutter action with s
α
−−→t and ¬(t◁s′), then α ∈Act(s′) and s′
α
−−→t′ where
t ◁t′.

The Branching-Time Ample Set Approach
657
Proof: The proof for (a) can be provided using induction on the length n of a forming
path from s to s′ where α does not occur. The basis of induction n = 0 is obvious as we
then have s = s′. In the induction step n −1 =⇒n(n ⩾1) we assume that
s = s0
β1
−−→s1
β1
−−→. . .
βn−1
−−−−→sn−1
βn
−−→sn = s′
is a forming path from s to s′ such that α /∈{β1, . . . , βn}. By induction hypothesis we
have α ∈Act(sn−1) and
α(s) ◁t
where t = α(sn−1).
As the dependence condition (A2) holds for state sn−1 and the
singleton action set {βn}, actions α and βn are independent. Thus, α ∈Act(sn) and
βn ∈Act(t) and, with u = βn(t),
α(s′) = α(sn) = α(βn(sn−1)) = βn(α(sn−1)) = βn(t) = u.
Condition (A2) also holds for α(s) = t and the singleton action set {βn}, since α and βn
are independent and (A2) holds for state sn−1 and the singleton action set {βn}. We get
t ◁u.
Hence, α(s) ◁t ◁u = α(s′) which yields α(s) ◁α(s′).
The proof for part (b) can be provided with similar arguments, also using induction of the
length of a forming path from s to s′. See Exercise 8.15.
Note that part (a) of Lemma 8.46 applies to all actions α ∈Act(s) which are nonstutter
actions, since they cannot occur on a forming path.
In addition, there might also be
stutter actions α enabled in s that do not occur on at least one forming path from s to
the given state s′.
Notation 8.47.
Relation Rfp
The relation Rfp is given by Rfp = {(s, ˆs) ∈S × ˆS | s ◁ˆs} where, as before, S is the state
space of TS and ˆS the state space of ˆ
TS.
Notation 8.48.
Forming Path in ˆ
TS
A forming path in ˆ
TS means a forming path ˆs0
β1⇒ˆs1
β2⇒. . .
βn⇒ˆsn as in Deﬁnition
8.44 consisting of transitions in ˆ
TS. (Thus, ˆs0, ˆs1, . . . , ˆsn ∈ˆS and βi+1 ∈ample(ˆsi) for
0 ⩽i < n.)

658
Partial Order Reduction
Lemma 8.49.
Properties of Forming Paths in
ˆ
TS
Let ˆs be a state in ˆ
TS.
(a) If ˆϱ is a forming path in ˆ
TS starting in state ˆs and (s, ˆs) ∈Rfp, then (s, ˆu) ∈Rfp for
all states ˆu in ˆϱ.
(b) There exists a forming path from ˆs in ˆ
TS to some fully expanded state.
Proof: Part (a) is immediate by the transitivity of ◁. The statement in (b) follows from
the fact that any execution fragment
ˆs0
β1⇒ˆs1
β2⇒. . .
βn⇒ˆsn
in ˆ
TS where none of the states ˆsi is fully expanded is a forming path in ˆ
TS, because of the
dependency condition (A2), the stutter condition (A3), and the branching condition (A5).
As ˆ
TS is ﬁnite, the nonemptiness condition (A1) and the cycle condition (A4) ensure the
existence of a forming path from ˆs to a fully expanded state.
Notation 8.50.
Length of Shortest Forming Paths
For s, s′ ∈S with s ◁s′ the length of a shortest forming path from s to s′ is denoted
|s ◁s′|. For ˆs ∈ˆS, we deﬁne dist(ˆs) as the length of a shortest forming path in ˆ
TS from
ˆs to some fully expanded state.
Note that dist(ˆs) refers to the forming paths in ˆ
TS. Thus, dist(ˆs) might be larger than
minˆv |ˆs ◁ˆv| where ˆv ranges over all fully expanded states in ˆ
TS.
Notation 8.51.
Norm Functions ν1, ν2
The functions ν1, ν2 : S × ˆS →IN are deﬁned as follows. For all s ∈S and ˆs ∈ˆS we put
ν1(s, ˆs) =
	 |s ◁ˆs|
:
if (s, ˆs) ∈Rfp
0
:
otherwise.
and ν2(s, ˆs) = dist(ˆs).
Note that part (b) of Lemma 8.49 ensures that every state ˆs ∈ˆS has a forming path to
some fully expanded state. Thus, ν2 is well-deﬁned.

The Branching-Time Ample Set Approach
659
Lemma 8.52.
Normed Bisimulation Equivalence of TS and
ˆ
TS
(Rfp, ν1, ν2) is a normed bisimulation for (TS, ˆ
TS).
Proof: We have (s0, s0) ∈Rfp for all initial states s0 ∈I, since we may consider a forming
path of length 0.
We show that for any pair (s, ˆs) ∈Rfp conditions (NI) and (NII) hold for (s, ˆs) and for
(ˆs, s) when ν1 and ν2 and their arguments are exchanged. The labeling condition (NI) is
obvious as all actions on a forming path are stutter actions. Thus, all states on a forming
path have the same labeling.
We now consider a pair (s, ˆs) ∈Rfp and an action α ∈Act(s).
Case 1. α does not occur on some forming path from s to ˆs.
Then, α ∈Act(ˆs) and α(s) ◁α(ˆs) by part (a) of Lemma 8.46. Hence, if α ∈ample(ˆs),
then case (N1) applies. If α /∈ample(ˆs), then we choose the ﬁrst action β of a shortest
forming path in ˆ
TS from ˆs to some fully expanded state (see part (b) of Lemma 8.49 on
page 658). Then,
ˆs
β⇒β(ˆs)
is a forming path in ˆ
TS of length 1. Moreover, we have (s, β(ˆs)) ∈Rfp and
ν2(s, β(ˆs)) = dist(β(ˆs)) = dist(ˆs) −1 = ν2(s, ˆs) −1 < ν2(s, ˆs).
Hence, case (N3) applies.
Case 2. α occurs in some shortest forming path from s to ˆs.
Since α occurs is some forming path, α is a stutter action. Let
s0
β1
−−→s1 . . .
βj−1
−−−−→sj−1
α
−−→sj
βj+1
−−−−→. . .
βn
−−→sn
be a shortest forming path from s = s0 to ˆs = sn with α /∈{β1, . . . , βj−1}. By part (b) of
Lemma 8.45 on page 655 there exists a forming path from t = α(s) to ˆs with the action
sequence β1 . . . βj−1 βj+1 . . . βn. Thus, (t, ˆs) ∈Rfp and
ν1(t, ˆs) = |t ◁ˆs| ⩽n −1 < n = |s ◁ˆs| = ν1(s, ˆs).
Hence, case (N2) applies for the transition s
α
−−→t.
It remains to show that (NII) holds for (ˆs, s) ∈R−1 with exchanged roles of ν1 and ν2.
Let α ∈ample(s). If s = ˆs, then case (N1) applies. If s ̸= ˆs then we take the ﬁrst action

660
Partial Order Reduction
β of a shortest forming path from s to ˆs. We then have (ˆs, β(s)) ∈R−1
fp
and
ν1(β(s), ˆs) = |β(s) ◁ˆs| = |s ◁ˆs| −1 = ν1(s, ˆs) −1 < ν1(s, ˆs).
This yields condition (N3).
Example 8.53.
Normed Bisimulation Equivalence of TS and ˆ
TS
We regard again the transition system TS in Figure 8.19 (page 650) and the ample sets
ample(s0) = {α}, while all other states are fully expanded. This yields the reduced system
shown in Figure 8.20 (page 651). We saw before that conditions (A1)-(A5) are fulﬁlled.
The goal is now to provide a normed bisimulation for (TS, ˆ
TS). Besides the trivial forming
paths of length 0, we have forming paths s0
α⇒s1 in ˆ
TS, and forming paths sβ
α
−−→tβ and
sγ
α
−−→tγ in TS. Thus, according to Notation 8.47 we deal with the relation
Rfp = id ∪{(s0, s1), (sγ, tγ), (sβ, tβ)}
where id denotes the set of all pairs (ˆs, ˆs) with ˆs a state in ˆ
TS. The norm functions ν1 and
ν2 are deﬁned as follows. For the pairs (ˆs, ˆs) ∈id we have ν1(ˆs, ˆs) = |ˆs◁ˆs| = 0. Moreover,
ν1(sγ, tγ) = ν1(sβ, tβ) = ν1(s0, s1) = 1
and
ν2(s0, s1) = ν2(s0, s0) = dist(s0) = 1,
while νi(·) = 0 in all remaining cases. Let us check that (Rfp, ν1, ν2) is a normed bisimula-
tion. Condition (NI) is obviously fulﬁlled. Moreover, (NII) is clear for the pairs (ˆs, ˆs) ∈Rfp.
Let us regard the pair (s0, s1) ∈Rfp. For the transitions sγ
γ
−→tγ in TS, we take the tran-
sition s0
α⇒s1 in ˆ
TS where (N3) applies as we have ν2(s0, s1) = 0 < 1 = ν2(s0, s0). An
analogy holds for sβ
β
−−→tβ. For the transition s0
α
−−→s1 in TS the conditions of (N1) are
fulﬁlled since s0
α⇒s1 in ˆ
TS and (s1, s1) ∈Rfp. Similarly, the transition s0
α⇒s1 in ˆ
TS
is matched by s0
α
−−→s1 in TS according to (N1). For the others pairs in Rfp, condition
(NII) can be checked with similar arguments.
Lemma 8.52, together with Lemma 7.123 on page 555, yields that TS and ˆ
TS are equivalent
under stutter bisimulation equivalence with divergence.
This completes the proof for
Theorem 8.43.
Clearly, the DFS-based technique explained in Sections 8.2.2 and 8.2.3 to generate the
reduced system is also applicable to ensure conditions (A1)-(A5). The additional require-
ment (A5) is local and simply amounts checking whether the candidate action set Acti(s)
for ample(s) of the chosen process Pi is a singleton set. The static partial order approach
is also applicable, but requires extending the obtained ample sets for all states where
|ample(s)| ⩾2.

Summary
661
8.4
Summary
• Partial order reduction attempts to analyze only a fragment ˆ
TS of the full transition
system TS by ignoring several interleavings of independent actions.
• Swapping independent actions in an execution fragment yields an execution fragment
that starts and ends in the same state.
• The ample set method relies on choosing ample(s) ⊆Act(s) in state s. If the ample
sets satisfy two local conditions (the nonemptiness condition (A1) and the stutter
condition (A3)), a global condition for TS (the dependency condition (A2)), and for
ˆ
TS (the cycle condition (A4)), then TS and
ˆ
TS are stutter trace equivalent, and
thus, LTL\⃝-equivalent.
• Conditions (A1) and (A2) ensure that any execution ρ in TS can be turned into an
execution ρ′ in
ˆ
TS by successive permutations of independent actions and adding
independent stutter actions. The stutter and the cycle conditions (A3) and (A4)
ensure that ρ is stutter-equivalent to ρ′.
• In on-the-ﬂy partial order reduction, the reduced transition system ˆ
TS is generated
during (nested) depth-ﬁrst search. To ensure the cycle condition (A4), states that
yield a backward edge to a state on the stack are fully expanded.
• Checking the dependency condition (A2) has the same worst case time complexity as
solving a reachability problem. Instead of ensuring (A2), some stronger conditions
are imposed that can easily be checked by a static analysis and are stronger than
(A2).
• Static partial order reduction generates the reduced transition system prior to the
veriﬁcation.
To establish the cycle condition (A4), the static approach relies on
determining a set of sticky actions. If the set of sticky actions fulﬁlls the visibility
condition (S1) and the cycle-breaking condition (S2), the reduction yields a stutter-
equivalent transition system.
• If the ample sets satisfy conditions (A1) through (A4) and the branching condition
(A5), then TS and ˆ
TS are divergent-sensitive stutter-bisimilar, and thus, CTL∗
\⃝-
equivalent.
8.5
Bibliographic Notes
Independence of actions. Partial order reduction has been inspired by earlier work on
the commutativity of concurrent activities by Lipton [276] and Mazurkiewicz [287]. They

662
Partial Order Reduction
considered action sequences that are equivalent up to permuting independent actions.
Equivalence classes of action sequences are called Mazurkiewicz traces. (Exercise 8.5 deals
with a variant of Mazurkiewcz traces as in [253, 357, 125].) Other partial order models
for concurrent systems that have been inﬂuential on partial order reduction are, among
others, pomsets [343], partial orders [258], branching processes of Petri nets [144], and
event structures [423]. The notion of independent actions (see Deﬁnition 8.3) has been
introduced by Katz and Peled [234]. Deductive proof techniques for concurrent systems
that are based on a partial order view have been proposed in the early eigthies by Apt,
Francez, and de Roever [16], and Elrad and Francez [137]. These techniques have been
extended and reﬁned by several others; see e.g., [339, 225, 235, 380].
Partial order reduction. The concepts of partial order reduction for the algorithmic veriﬁ-
cation of concurrent asynchronous systems have been developed independently by Gode-
froid, Peled, and Valmari in the beginning of the nineties.
This chapter is based on
the ample set approach by Peled for LTL\⃝[324, 211, 325]. Ample sets are similar to
Godefroid’s persistent sets [168, 171, 169] and Valmari’s stubborn sets [398, 399, 400].
The ample set approach for branching-time properties presented in Section 8.3 originates
from Gerth, Kuiper, Peled, and Penczek [165, 326]. Alternative partial order reduction
approaches for branching-time properties have been provided by Willems and Wolper
[422], and Ramakrishna and Smolka [352]. Alternative criteria for preserving linear and
branching-time properties as well as sound criteria for the universal fragment of CTL∗
\⃝
have been presented by Penczek, Gerth, Kuiper, and Szreter [330] (see also Exercises
8.16–8.18). Partial order reduction techniques for equivalence checking under various im-
plementation relations have been discussed, e.g., in [401, 218].
Computing the reduced model. A detailed discussion of nested depth-ﬁrst search in combi-
nation with partial order reduction is given by Holzmann, Peled, and Yannakakis [212, 325].
For further reading on partial order reduction and its implementation in the model checker
SPIN we refer to [169], [92, Chapter 10], and the monograph by Holzmann on SPIN [209].
In the last years, several variants have been discussed, see e.g. [169, 402, 310, 413, 135,
64, 328]. Static partial order reduction (see Section 8.2.4) has been developed by Kur-
shan, Levin, Minea, Peled and Yenig¨un [251]. Other applications of partial order reduc-
tion include: integration with symbolic techniques (by Abdulla, Jonsson, Kindahl and
Peled [3]), inﬁnite-state systems (by Alur, Brayton, Henzinger, Qadeer and Rajamani [8]),
and breadth-ﬁrst search strategies (by Bosnacki and Holzmann [59]).
Related approaches. The concept of sleep sets [168, 172, 169] is orthogonal to the ample,
persistent, or stubborn sets. Sleep sets are aimed at decreasing the number of transitions
rather than the number of states and are based on the (dynamic) knowledge of the graph
structure that is obtained during the depth-ﬁrst search traversal of the (possibly reduced)
transition system. The concept of τ-conﬂuence, proposed by Groote and van de Pol [177],

Exercises
663
is aimed at symbolic state-space reduction and obtains branching bisimilar transition
systems. Rather than perform a partial order reduction of an interleaving representation
of a concurrent system, one can attempt to directly perform model checking on partial
orders. McMillan [289] has presented an algorithm to obtain an initial part of the (inﬁnite)
branching process of a 1-safe Petri net. The so-called complete ﬁnite preﬁx of the branching
process contains all information on reachable states and transitions, and can be used as
the basis for model-checking algorithms, see, e.g., [145, 416].
8.6
Exercises
Exercise 8.1.
Let TS be the transition system depicted in Figure8.23 with the action set
Act = { α, β, γ, δ, τ }. Determine the pairs of independent actions in TS.
s
t
v
u
w
r
τ
α
τ
δ
δ
α
β
γ
β
γ
Figure 8.23: Transition system TS for Exercise 8.1.
Exercise 8.2.
Let TS be a transition system and let I be the set of action pairs (α, β) such that
α and β are independent of TS. Is I transitive? reﬂexive? symmetric?
Exercise 8.3. Consider the transition system TS(PG1 ||| PG2) for the program graphs PG1 (left)
and PG2 (right) in Figure 8.24. Determine the pairs of independent actions.
Exercise 8.4.
Consider the transition system TSSem for mutual exclusion with a semaphore (see
Figure 2.8 on page 45). We deal with the action set Act = {requesti, reli, enteri : i = 1, 2} and
the proposition set AP = {crit1, crit2}.

664
Partial Order Reduction
n1
ℓ1
x > 0:
x := x+y



action `
y ̸= 0:
y := y+1



action _
n2
ℓ2
x > 0:
z := x+z



action b
z := z−1



action o
z := 2∗z



action a
Figure 8.24: Program graphs PG1 (left) and PG2 (right) for Exercise 8.3.
(a) Consider the ﬁnite execution fragment ϱ
⟨noncrit1, noncrit2, y = 1⟩
request1
−−−−−−−→
⟨wait1, noncrit2, y = 1⟩
enter1
−−−−−→
⟨crit1, noncrit2, y = 0⟩
rel1
−−−→
⟨noncrit1, noncrit2, y = 1⟩
request2
−−−−−−−→
⟨noncrit1, wait2, y = 1⟩
Verify the statement of Lemma 8.10 (page 604) by investigating the three action sequences
request1 enter1 request2 rel1,
request1 request2 enter1 rel1,
request2 request1 enter1 rel1,
and checking that they lead from s = ⟨noncrit1, noncrit2, y = 1⟩to state t = ⟨noncrit1, wait2, y =
1⟩and are stutter-equivalent to ϱ.
(b) Consider the inﬁnite execution ρ
⟨noncrit1, noncrit2, y = 1⟩
request1
−−−−−−−→
⟨wait1, noncrit2, y = 1⟩
enter1
−−−−−→
⟨crit1, noncrit2, y = 0⟩
rel1
−−−→
⟨noncrit1, noncrit2, y = 1⟩
request1
−−−−−−−→
. . .
where process P1 continuously passes through its three phases, while P2 does nothing. Verify
Lemma 8.11 (page 605) by investigating the action sequence request2 (request1 enter1 rel1)ω
and checking that it yields an inﬁnite execution that is stuttering equivalent to ρ.
Exercise 8.5.
Let TS = (S, Act, →, I, AP, L) be an action-deterministic transition system. and
let Ist be the set of all pairs (α, β) ∈Act × Act of independent actions α and β where α or β (or

Exercises
665
both) is a stutter action. Let stutter permutation equivalence ⇋perm be the coarsest equivalence
on Act∗such that
γ α β δ ⇋perm γ β α δ
if γ, δ ∈Act∗and (α, β) ∈Ist.
(a) Let ϱ and ϱ′ be two ﬁnite execution fragments in TS that start in the same state and that
rely on stutter permutation equivalent action sequences. Show that ϱ ≜ϱ′.
(b) Let ϱ = s0
α1
−−→s1
α2
−−→. . .
αk
−−→sk be a ﬁnite execution fragment in TS and let β1 . . . βk ∈
Act∗such that α1 . . . αk ⇋perm β1 . . . βk. Show that there exists a a ﬁnite execution fragment
in TS which starts in s0 and relies on the action sequence β1 . . . βk.
The extension of ⇋perm to an equivalence for inﬁnite action sequences is deﬁned as follows. If
-α = α1 α2 α3 . . . and -β = β1 β2 β3 . . . are action sequences in Actω then -α ⊴perm -β if for all ﬁnite
preﬁxes α1 . . . αn of -α there exists a ﬁnite preﬁx β1 . . . βm of -β with m ⩾n and a ﬁnite word
γ ∈Act∗such that
α1 . . . αn γ
⇋perm
β1 . . . βm.
We then deﬁne the binary relation ⇋perm ω on Actω by
-α ⇋perm ω -β
iﬀ
-α ⊴perm -β and -β ⊴perm -α.
(a) Show that ⇋perm ω is an equivalence.
(b) Let ρ and ρ′ be two inﬁnite execution fragments in TS starting in the same state s with the
action sequences -α and -β, respectively. Show that if -α ⇋perm ω -β, then ρ ≜ρ′.
(c) Let ρ = s0
α1
−−→s1
α2
−−→. . . be a inﬁnite execution fragment in TS with the action sequence
-α = α1 α2 . . . ∈Actω and let -β = β1 β2 . . . ∈Actω such that -α ⇋perm ω -β.
Show that
there exists an inﬁnite execution fragment in TS which starts in s0 and relies on the action
sequence -β.
(d) Let -α = α1 α2 α3 . . . ∈Actω and let (-αi)i⩾1 be a sequence of inﬁnite action sequences of the
form
-αi = α1 . . . αi



as in eα
-βi
where -βi is an element of Actω such that
-α1 ⇋perm
ω -α2 ⇋perm
ω -α3 ⇋perm
ω . . .
Can we conclude that -αi ⇋perm ω -α for all i ⩾1? Provide a proof or a counterexample.

666
Partial Order Reduction
Exercise 8.6.
s7
s6
s8
s9
s2
s1
s3
s4
η
η
η
η
β
α
β
α
α
β
α
β
γ
γ
γ
γ
s10
s5
δ
δ
η
γ
γ
The state labeling is as follows:
• L(s10) = ∅
• L(s6) = L(s7) = { a }
• L(s3) = L(s4) = L(s5) = L(s8) = L(s9) = { b }
• L(s1) = L(s2) = { a, b }
Indicate for each of the following ample sets whether they satisfy the requirements (A1) through
(A3). Also check whether the requirement (A4) holds
• ample(s6) = { γ, α }
• ample(s7) = { β }
• ample(s8) = { α }
• ample(s9) = { α, β, δ }
• ample(s10) = { γ, η }
If the conditions (A1) through (A4) do not hold, provide a minimal extension of the ample sets to
ﬁx it. Clarify your adaptations.

Exercises
667
Exercise 8.7. Consider the transition system TSPet for the Peterson mutual exclusion algorithm
(see page 45).
(a) Which actions are independent?
(b) Apply the partial order reduction approach to TSPet with small ample sets according to
(i) Algorithm 38 (page 622) for checking the invariant □¬(crit1 ∧crit2).
Take AP =
{ crit1, crit2 }.
(ii) Algorithm 39 (page 625) for checking the liveness property □♦crit1.
Take AP =
{ crit1 }.
Exercise 8.8.
Consider the transition system TS = BCR∥BP∥Printer for the booking system
considered in Example 2.29 on page 50.
(a) Which actions are independent?
(b) Apply the partial order reduction approach to TS with minimal ample sets according to
Algorithm 38 (page 622) for checking the liveness property ϕ = □♦“printer in location 1”
where the printer’s locations serve as atomic propositions.
_
`
s
t
u
v
_
`
a
a
_
s
u
v
`
a
Figure 8.25: Transition system TS (left) and ˆ
TS (right) for Exercise 8.9.
Exercise 8.9.
Figure 8.25 shows on its left a transition system TS and on its right a reduced
system ˆ
TS that results from choosing ample(s) = { α }. Check whether TS and ˆ
TS are stutter
trace equivalent. If they are not, indicate which of the conditions (A1)-(A4) is (are) violated.
Answer the same question for the transition system in the reduction shown in Figures 8.26 and
8.27, where diﬀerent colors indicate diﬀerent state labels.
Exercise 8.10.
Consider the transition system TS depicted below. Show that conditions (A1)-
(A4) do not allow for any state reduction, although there is a smaller subsystem ˆ
TS that is stutter
trace equivalent to TS.

668
Partial Order Reduction
_
`
s
t
u
v
_
`
a
a
_
s
u
v
`
a
_
w
`
Figure 8.26: Transition system TS (left) and ˆ
TS (right) for Exercise 8.9.
_
`
s
t
u
v
_
`
a
a
w
_
`
t
a
w
_
s
Figure 8.27: Transition system TS (left) and ˆ
TS (right) for Exercise 8.9.
τ
τ
τ
τ
δ0
δ
γ0
γ
γ
γ0
δ0
δ
α
β
α
β
Exercise 8.11.
Let TSi = (Si, Acti, →i, Ii, AP, Li), i = 1, . . . , n, be action-deterministic tran-
sition systems such that Acti ∩Actj ∩Actk = ∅if 1 ⩽i < j < k ⩽n. We consider the parallel
composition with synchronization over common actions (see page 49), i.e., the transition system
TS = TS1∥TS2∥. . . ∥TSn.
For each state s = ⟨s1, . . . , sn⟩of TS, let Acti(s) = Acti ∩Act(s) be the set of actions of TSi that

Exercises
669
are enabled in s.
Show that the dependency condition (A2) holds if for each state s of TS the following conditions
(i) and (ii) hold:
(i) If ample(s) ̸= Act(s), then ample(s) = Acti(s) for some i ∈{1, . . . , n}.
(ii) If ample(s) = Acti(s) ̸= Act(s), then ample(s) ∩
 
1⩽j⩽n
j̸=i
Actj

= ∅.
n1
ℓ1
y := y−1;b := c



action a1
x = N:
skip

action `1
x < N:
x := x+1



action _1
n2
ℓ2
c := b∧¬c



action a2
y = N:
skip

action `2
y < N < z:
z := z−2



action _2
m1
c := ¬b
  
action b1
y = 0:
y := 5
  
action e1
z ≤N:
skip

action e2
n3
ℓ3
b := false



action a3
y ≤x:
skip

action `3
z ≤N:
z := N +2



action _3
Figure 8.28: Program graphs PG1, PG2, PG3 for Exercise 8.12.
Exercise 8.12.
Apply the static partial order reduction approach to generate the action set
Asticky by means of Algorithm 42 (page 648) and the modiﬁed program graphs
ˆ
PG1,
ˆ
PG2, and
ˆ
PG3 for the three program graphs shown in Figure 8.28.
Exercise 8.13.
Explain which modiﬁcations of the presented static partial order reduction
approach are necessary to treat program graphs with channel-based message passing.
Exercise 8.14.
Consider the transition system TS shown on the left of Figure 8.29 where the
three black states are labeled by {a}, while the white states are labeled by ∅. Let ample(·) be the
ample sets that yield the reduced system ˆ
TS shown on the right of Figure 8.29.
(a) Show that (A1)-(A5) are fulﬁlled.
(b) Provide a normed bisimulation for (TS, ˆ
TS).

670
Partial Order Reduction
_1
_1
_1
`1
`1
`1
_2
_2
_2
`2
`2
`2
a
_1
`1
_2
`2
a
Figure 8.29: Transition system TS (left) and ˆ
TS (right) for Exercise 8.14.
Exercise 8.15.
Provide the proof for part (b) of Lemma 8.46 on page 656.
Exercise 8.16.
Let TS = (S, Act, →, I, AP, L) be a ﬁnite, action-deterministic transition system
without terminal states and let I be a binary relation on Act × Act such that (α, β) /∈I if α and
β are dependent actions. Let Vis be the set of visible actions, i.e., Vis is the set of all actions
α ∈Act that are not stutter actions. Furthermore, let ample sets ample(s) ⊆Act(s) be given such
that the following conditions (A2I), (A6), (A7) and (A8) hold for all states s ∈S:
(A2I) If s
β1
−−→s1
β2
−−→s2
β3
−−→. . .
βm
−−−→sm
γ
−−→t is a ﬁnite execution fragment in TS such that
γ /∈ample(s) and (α, γ) /∈I for all α ∈ample(s). then there exists an index n ∈{1, . . . , m}
such that βn ∈ample(s).
(A6) (Vis × Vis) ∩I = ∅.
(A7) If s is not fully expanded, then ample(s) contains at least one visible action, i.e., ample(s)∩
Vis ̸= ∅and ample(s) \ Vis ̸= ∅.
(A8) If s is not fully expanded, then ample(s) contains at least one stutter action, i.e., ample(s)\
Vis ̸= ∅.
Show that TS and ˆ
TS are LTL\⃝-equivalent.
Exercise 8.17.
Let TS, I, and conditions (A2I), (A6), (A7) be as in Exercise 8.16 and let ample
sets be given such that (A2I), (A6), (A7) hold. As before, let ˆS be the state space of ˆ
TS and let
R
=

(s, ˆs) ∈S × ˆS
|
there exists an execution fragment
s
α1
−−→s1
α2
−−→. . .
αn
−−−→ˆs
such that α1, . . . , αn are stutter actions

.
Show that R is a stutter simulation for (TS, ˆ
TS), deﬁned as in Exercise 7.29 on page 592.

Exercises
671
Exercise 8.18.
Let TS, I, and conditions (A2I), (A6), (A7) be as in Exercise 8.16. Show
that if conditions (A2I), (A6), (A7), and the branching condition (A5) hold then TS and ˆ
TS are
∀CTL∗
\⃝-equivalent.
(Hint: Show that the relation R as in Exercise 8.17 is a divergence-sensitive stutter simulation as
in Exercise 7.29 (page 592) and apply the statement (h) of Exercise 7.29 and Theorem 7.76 (page
517)).


Chapter 9
Timed Automata
The logics we have encountered so far are interpreted over transition systems that describe
how a reactive system may evolve from one state to another. Timing aspects are, however,
not covered. That is, indications are given neither about the residence time of a state nor
about the possibility of taking a transition within a particular time interval. However,
reactive systems such as device drivers, coﬀee machines, communication protocols, and
automatic teller machines, to mention a few, must react in time—they are time-critical.
The behavior of time-critical systems is typically subject to rather stringent timing con-
straints. For a train crossing it is essential that on detecting the approach of a train, the
gate is closed within a certain time bound in order to halt car and pedestrian traﬃc before
the train reaches the crossing. For a radiation machine the time period during which a
cancer patient is subjected to a high dose of radiation is extremely important; a small
extension of this period is dangerous and can cause the patient’s death.
To put it in a nutshell:
Correctness in time-critical systems not only depends on the logical result
of the computation but also on the time at which the results are produced.
As timeliness is of vital importance to reactive systems, it is essential that the timing
constraints of the system are guaranteed to be met. Checking whether timing constraints
are met is the subject of this chapter. In order to express such timing constraints, the
strategy will be to extend logical formalisms that allow expression of the ordering of events,
with a notion of quantitative time. Such extensions allow expression of timing constraints
such as:
“The traﬃc light will turn green within the next 30 seconds.”
673

674
Timed Automata
A ﬁrst choice to be made is the time domain: is it discrete or continuous? A discrete
time domain is conceptually simple. Transition systems are used to model timed systems
where each action is assumed to last for a single time unit. More general delays can be
modeled by using a dedicated unobservable action, τ (for tick), say. The fact that action
α lasts k > 1 time units may be modeled by k−1 tick actions followed (or preceded)
by α. This approach typically leads to very large transition systems. Note that in such
models the minimal time diﬀerence between any pair of actions is a multiple of an a
priori, ﬁxed, time unit.
For synchronous systems, for instance, in which the involved
processes proceed in a lockstep fashion, discrete time domains are appropriate: one time
unit corresponds to one clock pulse. In this setting, traditional temporal logics can be
used to express timing constraints. The next-step operator can be used to “measure” the
discrete elapse of time, i.e., ⃝Φ means that Φ holds after exactly one time unit. By
deﬁning ⃝k+1 Φ = ⃝k (⃝Φ) and ⃝0 Φ = Φ, general timing constraints can be speciﬁed.
Using the shorthand ♦⩽k Φ = ⃝0 Φ ∨⃝Φ ∨. . . ∨⃝k Φ, the above informally stated
timing constraint on the traﬃc light may be expressed as
□(red ⇒♦⩽30 green).
For synchronous systems, transition systems and logics such as LTL or CTL can be used
to express timing constraints, and traditional model checking algorithms suﬃce.
In this monograph we do not want to restrict ourselves to synchronous systems, and will
consider—as in Newtonian physics—time of a continuous nature. That is to say, the non-
negative real numbers (the set R⩾0) will be used as time domain. A main advantage is
that there is no need to ﬁx a minimal time unit in advance as a continuous time model
is invariant against changes of the time scale. This is more adequate for asynchronous
systems, such as distributed systems, in which components may proceed at distinct speeds,
and is more an intuitive than a discrete time model. Transition system representations of
asynchronous systems without additional timing information are indeed too abstract to
adequately model timing constraints, as illustrated by the following example.
Example 9.1.
A Railroad Crossing
Consider a railroad crossing, as discussed in Example 2.30 (page 51), see the schematic
representation in Figure 9.1.
For this railroad crossing a control system needs to be
developed that closes the gate on receipt of a signal indicating that a train is approaching
and only opens the gate once the train has signaled that it entirely crossed the road. The
safety property that should be established by the control system is that the gates are
always closed when the train is crossing the road. The complete system consists of the
three components: Train, Gate, and Controller:
Train ∥Gate ∥Controller.

Timed Automata
675
Figure 9.1: Railroad crossing (time abstract).
far
near
in
approach
enter
exit
0
1
3
2
approach
lower
exit
raise
up
down
lower
raise
Train
Controller
Gate
Figure 9.2: Transition systems for processes Train (left), Controller (middle), and Gate
(right).
Recall that actions common to a pair of processes need to be performed jointly, while
other actions are performed autonomously. The transition systems of these processes are
depicted in Figure 9.2. It follows that the composite system Train ∥Gate ∥Controller
does not guarantee that the gate is closed when the train is passing the crossing. This can
easily be seen by inspecting an initial fragment of the composite transition system; see
Figure 9.3—it cannot be deduced from the transition system whether, after sending the
“approach” signal, the train reaches the road before or after the gate has been closed.
Under the assumption, though, that the train does not exceed a certain maximum speed, a
lower bound for the duration between the signal “approach” and the time instant at which
the train has reached the crossing can be indicated, see Figure 9.4. Let us assume that the
train needs more than 2 minutes to reach the crossing after emission of the “approach”
signal. Accordingly, timing assumptions are made for the controller and the gate. On
receiving the “approach” signal, after exactly 1 minute the controller will signal the gate
to be lowered. The actual closing of the gate is assumed not to exceed a minute. The
branching in global state ⟨near, 1, up⟩can now be labeled with timing information:

676
Timed Automata
⟨far, 0, up⟩
⟨near, 1, up⟩
⟨in, 1, up⟩
⟨near, 2, down⟩
approach
enter
lower
Figure 9.3: Initial fragment of the transition system Train ∥Controller ∥Gate.
far
near
in
approach
enter
exit
0
1
3
2
approach
lower
exit
raise
up
down
lower
raise
after
delay of
execution time
> 2 minutes
1 minute
of ⩽1 minute
Figure 9.4: The Train (left), Controller (middle), and Gate (right) with timing assump-
tions.

Timed Automata
677
far 0 up
near 1 up
near 2 down
in 1 up
approach
lower
enter
2min
2min
...
The train can only execute the local state change near
enter
−−−−→in after more than 2 minutes.
On the other hand, the gate is closed at most 2 minutes after receiving the “approach”
signal. Therefore, the global state change
⟨near, 1, up⟩
enter
−−−−→⟨in, 1, up⟩
never occurs. Thus, the gate is always closed before the train reaches the crossing. The
fact that the gate remains closed as long as the train is on the crossing is ensured by the
fact that action raise can only happen after the train has indicated exit.
As a modeling formalism for time-critical systems, the notion of timed automata has been
developed, an extension of transition systems (in fact, program graphs) with clock variables
that measure the elapse of time. This model includes means to impose constraints on the
residence times of states, and on the timing of actions.
9.1
Timed Automata
Timed automata model the behavior of time-critical systems. A timed automaton is in
fact a program graph that is equipped with a ﬁnite set of real-valued clock variables,
called clocks for short. In the sequel we assume that the set of clocks is denumerable,
and we will use x, y, and z as clocks. Clocks are diﬀerent from the usual variables, as
their access is limited: clocks may only be inspected, and reset to zero. Clocks can be
reset to zero after which they start increasing their value implicitly as time progresses.
All clocks proceed at rate one, i.e., after the elapse of d time units, all clocks advance by
d. The value of a clock thus denotes the amount of time that has been elapsed since its
last reset. Clocks can intuitively be considered as stopwatches that can be started and
checked independently of one another. Conditions on the values of the clocks are used as
enabling conditions (i.e., guards) of actions: only if the condition is fulﬁlled is the action
enabled and capable of being taken; otherwise, the action is disabled. Conditions which
depend on clock values are called clock constraints. For the sake of simplicity, it is assumed
that enabling conditions only depend on clocks and not on other data variables. Clock

678
Timed Automata
constrains are also used to limit the amount of time that may be spent in a location. The
following deﬁnition prescribes how constraints over clocks are to be deﬁned.
Deﬁnition 9.2.
Clock Constraint
A clock constraint over set C of clocks is formed according to the grammar
g ::=
x < c
   x ⩽c
   x > c
   x ⩾c
   g ∧g
where c ∈N and x ∈C. Let CC(C) denote the set of clock constraints over C.
Clock constraints that do not contain any conjunctions are atomic. Let ACC(C) denote
the set of all atomic clock constraints over C.
Clock constraints are often written in abbreviated form, e.g., (x ⩾c1) ∧(x < c2) may be
abbreviated by x ∈[c1, c2) or c1 ⩽x < c2. Clock diﬀerence constraints such as x−y < c
can be added at the expense of a slightly more involved theory. For simplicity, they are
omitted here and we restrict the discussion to atomic clock constraints that compare a
clock with a constant c ∈N. The decidability of the model-checking problem is not aﬀected
if c is allowed to be rational. In this case the rationals in each formula can be converted
into natural numbers by suitable scaling. In general, we can multiply each constant by the
least common multiple of denominators of all constants appearing in all clock constraints.
Intuitively, a timed automaton is a (slightly modiﬁed) program graph, whose variables are
clocks. The clocks are used to formulate the real-time assumptions on system behavior.
An edge in a timed automaton is labeled with a guard (when is it allowed to take an
edge?), an action (what is performed when taking the edge?), and a set of clocks (which
clocks are to be reset?).
A location is equipped with an invariant that constrains the
amount of time that may be spent in that location. The formal deﬁnition is:
Deﬁnition 9.3.
Timed Automaton
A timed automaton is a tuple TA = (Loc, Act, C, 
→, Loc0, Inv, AP, L) where
• Loc is a ﬁnite set of locations, ,
• Loc0 ⊆Loc is a set of initial locations,
• Act is a ﬁnite set of actions,
• C is a ﬁnite set of clocks,

Timed Automata
679
• 
→⊆Loc × CC(C) × Act × 2C × Loc is a transition relation,
• Inv : Loc →CC(C) is an invariant-assignment function,
• AP is a ﬁnite set of atomic propositions, and
• L : Loc →2AP is a labeling function for the locations.
ACC(TA) denotes the set of atomic clock constraints that occur in either a guard or a
location invariant of TA.
A timed automaton is a program graph with a ﬁnite set C of clocks. Edges are labeled
with tuples (g, α, D) where g is a clock constraint on the clocks of the timed automaton,
α is an action, and D ⊆C is a set of clocks. The intuitive interpretation of ℓ
g:α,D

→ℓ′ is
that the timed automaton can move from location ℓto location ℓ′ when clock constraint
g holds. Besides, when moving from location ℓto ℓ′, any clock in D will be reset to zero
and action α is performed. Function Inv assigns to each location a location invariant that
speciﬁes how long the timed automaton may stay there. For location l, Inv(ℓ) constrains
the amount of time that may be spent in ℓ. That is to say, the location ℓshould be
left before the invariant Inv(ℓ) becomes invalid. If this is not possible—as there is no
outgoing transition enabled—no further progress is possible. In the formal semantics of
timed automata (see Deﬁnition 9.11) this situation causes time progress to halt. As time
progress is no longer possible, this situation is also known as a timelock. This phenomenon
will be discussed in more detail later. The function L has the same role as for transition
systems and associates to any location the set of atomic propositions that are valid in that
location.
Before considering the precise interpretation of timed automata, we give some simple
examples.
For depicting timed automata we adopt the drawing conventions for program graphs.
Invariants are indicated inside locations and are omitted when they equal true. Edges
are labeled with the guard, the action, and the set of clocks to be reset. Empty sets of
clocks are often omitted. The same applies to clock constraints that are constantly true.
The resetting of set D of clocks is sometimes indicated by reset(D). If the actions are
irrelevant, they are omitted.
Example 9.4.
Guards vs. Location Invariants
Figure 9.5(a) depicts a simple timed automaton with one clock x and one location ℓ
equipped with a self-loop. The self-loop can be taken if clock x has at least the value
2, and when being taken, clock x is reset. Initially, by default clock x has the value 0.

680
Timed Automata
2
4
time
2
4
6
8
10
value
of x
2
4
time
2
4
6
8
10
value
of x
(c)
(d)
(e)
(f)
3
3
2
4
time
2
4
6
8
10
value
(a)
(b)
of x
ℓ
ℓ
x ⩾2 : τ
reset(x)
2 ⩽x ⩽3 : τ
reset(x)
x ⩾2 : τ
reset(x)
ℓ
x ⩽3
Figure 9.5: Some timed automata with a single clock and one of their evolutions.
Figure 9.5(b) gives an example of an execution of this timed automaton, by depicting the
value of clock x vs. the elapsed time since the start of the automaton. Each time the clock
is reset to 0, the automaton traverses the self-loop at location ℓ. As Inv(ℓ) = true, time
can progress without any restriction while residing in ℓ. In particular, a legal behavior of
this automaton is to stay in location ℓad inﬁnitum. Formally,
Loc = Loc0 = { ℓ}, C = { x }, ℓ
true:x⩾2,{ x }

→ℓ, and Inv(ℓ) = true.
Labelings and actions are omitted.

Timed Automata
681
up
coming down
going up
down
{up}
∅
∅
{down}
lower
raise
x ⩾1
reset(x)
reset(x)
true
true
x ⩽1
x ⩽2
Figure 9.6: Timed automaton for the Gate.
Changing the timed automaton of Figure 9.5(a) slightly by incorporating a location invari-
ant x ⩽3 in location ℓleads to the eﬀect that x cannot progress unboundedly anymore.
Rather, if x ⩾2 (guard) and x ⩽3 (invariant) the outgoing transition must be taken.
Note that it is not speciﬁed at which time instant in the interval [2, 3] the transition is
taken, i.e., this is determined nondeterministically. The timed automaton and an example
of its behavior are illustrated in Figure 9.5(c) and (d), respectively.
Observe that the same eﬀect is not obtained when strengthening the guard in Figure 9.5(a)
into 2 ⩽x ⩽3 while keeping Inv(ℓ) = true. In that case, the outgoing transition can only
be taken when 2 ⩽x ⩽3—as in the previous scenario—but is not forced to be taken,
i.e., it can simply be ignored by letting time pass while staying in ℓ. This is illustrated in
Figure 9.5(e) and (f).
Put in a nutshell, invariants are the only means to force transitions to be taken.
Example 9.5.
Timed Automaton for the Gate
Consider the gate for the railroad crossing (see Example 9.1, page 674). Assuming that
lowering the gate takes at most a single time unit, and raising the gate takes at least one
and at most two time units, the timed automaton for process Gate is given as in Figure 9.6.
We have Act = { lower, raise } and
Loc = { up, comingdown, down, goingup }
with Loc0 = { up }. The transitions of the timed automaton are
up
true: lower, { x }

→comingdown
comingdown
true: τ, ∅

→down
down
true: raise, { x }

→goingup
goingup
x ⩾1: τ, ∅

→up
The location coming down with invariant x ⩽1 has been added to model that the maximal
delay between the occurrence of action lower and the change to location down is at most

682
Timed Automata
0
1
2
3
4
5
6
7
up
coming down
down
going up
time inst.
5.0971
time inst.
3.7
time inst.
2.172
time inst.
1.318
lower
raise
lower
Figure 9.7: Location diagram for the timed automaton Gate.
a single time unit.
Clock x is set to zero on the occurrence of action lower and thus
“measures” the elapse of time since that occurrence. By restricting the residence time of
coming down to x ⩽1, the switch to down must be made within one time unit. Note that
this would not have been established by having a direct edge between locations up and
down with guard x ⩽1, as the value of x would not refer to the time of occurrence of lower.
In a similar way, the purpose of location goingup with invariant x ⩽2 is to model that
raising the gate takes at most two time units. In the initial location up, no constraints are
imposed on the residence time, i.e., Inv(up) = true. The same applies to location down.
Let AP = {up, down} with the labeling function L(up) = { up }, L(down) = { down }, and
L(comingdown) = L(goingup) = ∅.
Remark 9.6.
Location Diagram
Every ﬁnite behavior of a timed automaton can be represented by a location diagram. This
depicts for every time instant up to some a priori ﬁxed upper bound, the location of the
timed automaton during that behavior. For the timed automaton of the Gate a possible
real-time behavior is indicated by the location diagram in Figure 9.7.
Parallel Composition of Timed Automata
For modeling complex systems it is con-
venient to allow parallel composition of timed automata. This allows for the modeling
of time-critical systems in a compositional manner. We consider a parallel composition
operator, denoted ||H, that is parameterized with a set of handshaking actions H. This
operator is similar in spirit to the corresponding operator on transition systems; see Def-
inition 2.26, page 48: actions in H need to be performed jointly by both involved timed

Timed Automata
683
automata, whereas actions outside H are performed autonomously in an interleaved fash-
ion.
Deﬁnition 9.7.
Handshaking for Timed Automata
Let TAi
=
(Loci, Acti, Ci, 
→i, Loc0,i, Invi, APi, Li), i = 1, 2 be timed automata with
H ⊆Act1 ∩Act2, C1 ∩C2 = ∅and AP1 ∩AP2 = ∅. The timed automaton TA1 ∥H TA2
is deﬁned as
(Loc1 × Loc2, Act1 ∪Act2, C1 ∪C2, 
→, Loc0,1 × Loc0,2, Inv, AP1 ∪AP2, L)
where L(⟨ℓ1, ℓ2⟩) = L1(ℓ1)∪L2(ℓ2) and Inv(⟨ℓ1, ℓ2⟩) = Inv1(ℓ1)∧Inv2(ℓ2). The transition
relation 
→is deﬁned by the following rules:
• for α ∈H:
ℓ1
g1:α,D1

→1 ℓ′
1 ∧ℓ2
g2:α,D2

→2 ℓ′
2
⟨ℓ1, ℓ2⟩
g1∧g2:α,D1∪D2

→⟨ℓ′
1, ℓ′
2⟩
• for α ̸∈H:
ℓ1
g:α,D

→1 ℓ′
1
⟨ℓ1, ℓ2⟩
g:α,D

→⟨ℓ′
1, ℓ2⟩
and
ℓ2
g:α,D

→2 ℓ′
2
⟨ℓ1, ℓ2⟩
g:α,D

→⟨ℓ1, ℓ′
2⟩
The location invariant of a composite location is simply the conjunction of the location
invariants of its constituents. For α ∈H, the transition in the resulting timed automaton
is guarded by the conjunction of the guards of the individual timed automata. This entails
that an action in H can only be taken when it is enabled in both timed automata. Besides,
the clocks that are reset in the individual automata are all reset. As for transition systems,
the operator ∥H is associative for a ﬁxed set H. Let TA1 ∥H TA2 ∥H . . . ∥TAn denote the
parallel composition of timed automata TA1 through TAn where H ⊆Act1 ∩. . . ∩Actn,
assuming that all timed automata are compatible, i.e., each pair of TAi and TAj, i ̸= j
have disjoint sets of atomic propositions and disjoint clocks.
Example 9.8.
Railroad Crossing
Consider again the railroad crossing example. We extend the timed automaton for the
gate (see Example 9.5) with timed automata for the controller and the train. The complete
system is then given by
(Train∥H1Controller)∥H2Gate

684
Timed Automata
far
near
in
approach
y> 2 :
exit
reset(y)
enter
y ⩽5
y ⩽5
0
3
1
2
approach
exit
raise
z = 1
lower
reset(z)
reset(z)
z ⩽1
z ⩽1
Train
Controller
Figure 9.8: Timed automata for the train and the controller .
where H1 = { approach, exit } and H2 = { lower, raise }.
Let us assume that the train signals its approaching of the gate at least two time units
before it enters the railroad crossing. Besides, it is assumed that the train has suﬃcient
speed such that it leaves the crossing ﬁve time units after approaching it, at the latest.
The timed automaton for the Train is depicted in Figure 9.8 (left). On approaching the
gate, clock y is set to zero, and only if y > 2 is the train allowed to enter the crossing.
The Controller is depicted in Figure 9.8 (right) and is forced to send the signal “lower”
(to the Gate) exactly after one time unit after the Train has signaled its approaching.
Figure 9.9 shows the composite timed automaton. The preﬁx of a possible behavior of the
complete system is sketched in the location diagram in Figure 9.10.
Note that this timed automaton contains the location ⟨in, 1, up⟩. In this location, the
train is at the crossing while the gate it still open. However, this location turns out to be
unreachable. It can only be reached when y > 2, but as y and z are reset at the same
time (on entrance of the preceding location), y > 2 implies z > 2, which is impossible due
to the location invariant z ⩽1.
9.1.1
Semantics
The previous examples suggest that the state of a timed automaton is determined by its
current location and the current values of all its clocks. In fact, any timed automaton can—
like program graphs—be interpreted as a transition system. Due to the continuous time
domain, these underlying transition systems have inﬁnitely many states (even uncountably

Timed Automata
685
⟨far, 0, up⟩
⟨near,1,up⟩
⟨in,1,up⟩
⟨far,3,com.down⟩
⟨near,2,com.down⟩
⟨in,2,com.down⟩
⟨far,3,down⟩
⟨near,2,down⟩
⟨in,2,down⟩
⟨far,0,going up⟩
⟨near,1,going up⟩
⟨in,1,going up⟩
enter
enter
enter
enter
approach
approach
exit
exit
lower
lower
raise
y ⩽5 ∧z ⩽1
y ⩽5 ∧z ⩽1
y ⩽5 ∧x ⩽1
y ⩽5 ∧x ⩽1
y ⩽5
z ⩽1 ∧x ⩽1
y ⩽5
z ⩽1
x ⩽2
y ⩽5 ∧x ⩽2 ∧z ⩽1
y ⩽5 ∧x ⩽2 ∧z ⩽1
reset(x, y)
y > 2
z = 1 :
z = 1 :
y > 2
reset(z)
y > 2
reset(z)
reset(x)
reset(y, z)
y > 2
x ⩾1
x ⩾1
x ⩾1
reset(x)
reset(x)
Figure 9.9: The timed automaton (Train∥H1Controller)∥H2Gate.

686
Timed Automata
0
1
2
3
4
5
6
7
up
coming down
down
going up
in
near
far
0
1
2
3
Figure 9.10: Location diagram for a behavior of (Train∥H1Controller)∥H2Gate.
many), and are inﬁnitely branching. Timed automata can thus be considered as ﬁnite
descriptions of inﬁnite transition systems. The underlying transition system of a timed
automaton results from unfolding. Its states consist of a control component, i.e., a location
ℓof the timed automaton, together with a valuation η of the clocks. States are thus pairs
of the form ⟨ℓ, η⟩. Let us ﬁrst consider clock valuations.
Deﬁnition 9.9.
Clock Valuation
A clock valuation η for a set C of clocks is a function η : C →R⩾0, assigning to each clock
x ∈C its current value η(x).
Let Eval(C) denote the set of all clock valuations over C. In the following, we often use
notations like [x = v, y = v′] to denote the clock evaluation η ∈Eval({ x, y }) with η(x) = v
and η(y) = v′.
We can now formally deﬁne what it means for a clock constraint to hold for a clock
valuation or not. This is done in a similar way as characterizing the semantics of a temporal
logic, namely by deﬁning a satisfaction relation. In this case the satisfaction relation |=
is a relation between clock valuations (over a set of clocks C) and clock constraints (over
C).

Timed Automata
687
Deﬁnition 9.10.
Satisfaction Relation for Clock Constraints
For set C of clocks, x ∈C, η ∈Eval(C), c ∈N, and g, g′ ∈CC(C), let |=⊆Eval(C)×CC(C)
be deﬁned by
η |= true
η |= x < c
iﬀη(x) < c
η |= x ⩽c
iﬀη(x) ⩽c
η |= ¬ g
iﬀη ̸|= g
η |= g ∧g′
iﬀη |= g ∧η |= g′
Let η be a clock valuation on C. For positive real d, η+d denotes the clock valuation
where all clocks of η are increased by d. Formally, (η+d)(x) = η(x) + d for all clocks
x ∈C. reset x in η denotes the clock valuation which is equal to η except that clock x
reset. Formally:
(reset x in η)(y) =
	 η(y)
if y ̸= x
0
if y = x.
For the clock valuation η = [x = π, y = 4], valuation η+9 = [x = π+9, y = 13], and
reset x in (η+9) = [x = 0, y = 13]. Nested occurrences of reset are typically abbreviated.
For instance, reset x in (reset y in η) is denoted reset x, y in η.
There are two possible ways in which a timed automaton can proceed: by taking a tran-
sition in the timed automaton, or by letting time progress while staying in a location. In
the underlying transition system, the former is represented by a discrete transition and
the latter by a delay transition. In the former case, the corresponding transition of the
underlying transition system is labeled with the action of the transition in the timed au-
tomaton, in the latter case, it is labeled with a positive real number indicating the amount
of time that has elapsed.
Deﬁnition 9.11.
Transition System Semantics of a Timed Automaton
Let TA = (Loc, Act, C, 
→, Loc0, Inv, AP, L) be a timed automaton. The transition system
TS(TA) = (S, Act′, →, I, AP′, L) with:
• S = Loc × Eval(C)
• Act′ = Act ∪R⩾0
• I = { ⟨ℓ0, η⟩| ℓ0 ∈Loc0 ∧η(x) = 0 for all x ∈C }
• AP′ = AP ∪ACC(C)

688
Timed Automata
• L′(⟨ℓ, η⟩) = L(ℓ) ∪{ g ∈ACC(C) | η |= g }
• the transition relation −→is deﬁned by the following two rules:
– discrete transition: ⟨ℓ, η⟩
α
−−→⟨ℓ′, η′⟩if the following conditions hold:
(a) there is a transition ℓ
g:α,D

→ℓ′ in TA
(b) η |= g
(c) η′ = reset D in η
(d) η′ |= Inv(ℓ′)
– delay transition: ⟨ℓ, η⟩
d
−→⟨ℓ, η+d⟩for d ∈R⩾0
(e) if η+d |= Inv(ℓ)
For a transition that corresponds to (a) traversing a transition ℓ
g:α,D

→
ℓ′ in the timed
automaton TA it must hold that (b) η satisﬁes the clock constraint g (ensuring the tran-
sition is enabled), and (c) the new clock valuation η′ is obtained by resetting all clocks
D in η should (d) satisfy the location invariant of ℓ′ (otherwise it is not allowed to be in
ℓ′). Idling in a location (second clause) for some non-negative amount of time is allowed
(e) if the location invariant remains true while time progresses. For state ⟨ℓ, η⟩such that
η |= Inv(ℓ), there are typically uncountably many outgoing delay transitions of the form
⟨ℓ, η⟩
d
−→as d can be selected from a continuous domain.
Example 9.12.
Light Switch
The timed automaton Switch in Figure 9.11 models a switch that controls a light. When
oﬀ, the switch may be turned on at any time instant. The user may switch oﬀthe light at
least one time unit after the most recent time the light was switched on. After two time
units the light automatically switches oﬀ. Clock x is used to keep track of the delay since
the last time the light has been switched on. (The timed automaton does not distinguish
between the switch oﬀaction activated by the user and by the light. This could be made
explicit by adding an edge from location on to oﬀ, with guard x = 2 and action τ.) The
following location diagram indicates a possible behavior:
0
0 3
1
1 39
2 2
2
3
4
3 783
off
on

Timed Automata
689
oﬀ
on
switch on
switch oﬀ
x ⩽2
reset(x)
x ⩾1
Figure 9.11: A simple light switch.
The transition system TS(Switch) has the state space
S = {⟨oﬀ, t⟩| t ∈IR⩾0} ∪{⟨on, t⟩| t ∈IR⩾0}
where t is a shorthand for the clock evaluation η with η(x) = t.
Uncountably many
transitions emanate from the initial state ⟨oﬀ, 0⟩. TS(Switch) has the following transitions
for reals d and t:
⟨oﬀ, t⟩
d
−→
⟨oﬀ, t + d⟩
for all t ⩾0 and d ⩾0
⟨oﬀ, t⟩
switch on
−−−−−→
⟨on, 0⟩
for all t ⩾0
⟨on, t⟩
d
−→
⟨on, t + d⟩
for all t ⩾0 and d ⩾0 with t + d ⩽2
⟨on, t⟩
switch oﬀ
−−−−−−→
⟨oﬀ, t⟩
for all 1 ⩽t ⩽2.
The set of reachable states in TS(Switch) from state ⟨oﬀ, 0⟩is
{⟨oﬀ, t⟩| t ∈IR⩾0} ∪{⟨on, t⟩| 0 ⩽t ⩽2}
as the location invariant x ⩽2 is violated in any state ⟨on, t⟩with t > 2. A preﬁx of an
example path of TS(Switch) is
⟨oﬀ, 0⟩
0.57
−−−→⟨oﬀ, 0.57⟩
switch on
−−−−−−−→⟨on, 0⟩
√
2
−−−→⟨on,
√
2⟩
0.2
−−→
⟨on,
√
2+0.2⟩
switch oﬀ
−−−−−−−→⟨oﬀ,
√
2+0.2⟩
switch on
−−−−−−−→⟨on, 0⟩
1.7
−−→⟨on, 1.7⟩. . .
Remark 9.13.
Parallel Composition
For timed automata we have
TS(TA1) ∥H∪IR>0 TS(TA2) = TS(TA1 ∥H TA2)
up to isomorphism. This is due to the fact that TA1 and TA2 do not have any shared
variables. Synchronization over time passage actions reﬂects the natural fact that time
proceeds equally fast in both components.

690
Timed Automata
The paths in TS(TA) are discrete representations of the continuous-time “behavior” of
TA. They indicate at least the states immediately before and after the execution of an
action α ∈Act. However, due to the fact that, e.g., interval delays may be realized in
uncountably many ways, diﬀerent paths may describe the same behavior (i.e., location
diagram). Consider, e.g., the behavior of the light switch of Example 9.12 where the light
alternates between oﬀand on while being oﬀfor exactly one time unit and on for two
time units, i.e., a return to oﬀtakes place after exactly three time units. The following
three example paths correspond to this continuous-time behavior:
π1
=
⟨oﬀ, 0⟩
⟨oﬀ, 1⟩
⟨on, 0⟩
⟨on, 2⟩
⟨oﬀ, 2⟩
. . .
π2
=
⟨oﬀ, 0⟩
⟨oﬀ, 0.5⟩
⟨oﬀ, 1⟩
⟨on, 0⟩
⟨on, 1⟩
⟨on, 2⟩
⟨oﬀ, 2⟩
. . .
π3
=
⟨oﬀ, 0⟩
⟨oﬀ, 0.1⟩
⟨oﬀ, 1⟩
⟨on, 0⟩
⟨on, 0.53⟩
⟨on, 1.3⟩
⟨on, 2⟩
⟨oﬀ, 2⟩
. . .
The only diﬀerence between these paths is the delay transitions.
In path π1, the one
time unit residence in the initial state ⟨oﬀ, 0⟩is realized by means of the delay transition
⟨oﬀ, 0⟩
1
−→⟨oﬀ, 1⟩. In contrast, the paths π2 and π3 realize this single time unit by two
delay transitions:
⟨oﬀ, 0⟩
0.5
−−→
⟨oﬀ, 0.5⟩
0.5
−−→
⟨oﬀ, 1⟩
and
⟨oﬀ, 0⟩
0.1
−−→
⟨oﬀ, 0.1⟩
0.9
−−→
⟨oﬀ, 1⟩.
But the eﬀect of the transition ⟨ℓ, η⟩
d1+d2
−−−−−→⟨ℓ, η+d1+d2⟩corresponds to the eﬀect of
the sequence of transitions:
⟨ℓ, η⟩
d1
−−→⟨ℓ, η+d1⟩
d2
−−→⟨ℓ, η+d1+d2⟩.
In both cases, d1+d2 time units pass without executing an action α ∈Act. Thereby,
uncountably many states of the form ⟨ℓ, η+t⟩with 0 ⩽t ⩽d1+d2 are passed through.
Remark 9.14.
Multiple Actions in Zero Time
The elapse of time in timed automata only takes place in locations. Actions α ∈Act take
place instantaneously, i.e., they have a duration of zero time units. As a result, at a single
time instant, several actions take place.
9.1.2
Time Divergence, Timelock, and Zenoness
The semantics of a timed automaton is given by a transition system with uncountably
many states (and transitions). Paths through this transition system correspond to possible

Timed Automata
691
behaviors of the timed automaton. However, not every such path represents a realistic
behavior. This subsection treats three essential phenomena for timed automata: time
divergence, timelock, and zenoness.
Time Divergence
Consider a location ℓsuch that for any t < d, for ﬁxed constant
d ∈IR>0, clock valuation η+t |= Inv(ℓ). A possible execution fragment starting from this
location is
⟨ℓ, η⟩
d1
−−→⟨ℓ, η+d1⟩
d2
−−→⟨ℓ, η+d1+d2⟩
d3
−−→⟨ℓ, η+d1+d2+d3⟩
d4
−−→. . .
where di > 0 and the inﬁnite sequence d1 + d2 + . . . converges toward d. Such inﬁnite
path fragments are called time-convergent. A time-convergent path is counterintuitive as
time advances only up to a certain value whereas by nature time always progresses. For
example, the transition system of the timed automaton for the light switch (see Figure
9.11 on page 689) exhibits the time-convergent execution fragment
⟨oﬀ, 0⟩
2−1
−−−→⟨oﬀ, 1−2−1⟩
2−2
−−−→⟨oﬀ, 1−2−2⟩
2−3
−−−→⟨oﬀ, 1−2−3⟩. . . . . .
which visits inﬁnitely many states in the interval [ 1
2, 1]. Time never proceeds beyond one.
The corresponding path is time-convergent. As time-convergent paths are not realistic,
they are not considered. That is to say, the analysis of timed automata is focused on
time-divergent paths, i.e., paths in which time always progresses.
In order to formally deﬁne time-divergent paths, let us ﬁrst deﬁne the elapsed time of a
path. Intuitively, the elapsed time of a path is the total time that elapses along a path.
The duration of an action α ∈Act is zero; the duration of a delay action d is d.
Deﬁnition 9.15.
Elapsed Time on a Path
Let TA be a timed automaton with the set Act of actions.
The function ExecTime :
Act ∪IR>0 →IR⩾0 is deﬁned as
ExecTime(τ) =
	 0
if τ ∈Act
d
if τ = d ∈IR>0.
For inﬁnite execution fragment ρ = s0
τ0
−−→s1
τ1
−−→s2 . . . in TS(TA) with τi ∈Act ∪IR>0
let
ExecTime(ρ) =
∞

i=0
ExecTime(τi).
The execution time of ﬁnite execution fragments is deﬁned analogously.
For the path
fragment π in TS(TA) induced by ρ, ExecTime(π) = ExecTime(ρ).

692
Timed Automata
Note that path fragment π may be induced by several execution fragments. However,
every pair of execution fragments with the same path fragment are only distinguished by
discrete transitions and not by delay transitions. Hence, ExecTime(π) is well-deﬁned.
Deﬁnition 9.16.
Time Divergence and Time Convergence
The inﬁnite path fragment π is time-divergent if ExecTime(π) = ∞; otherwise, π is
time-convergent.
Example 9.17.
Light Switch
For the light switch described in Example 9.12 (page 688), the path π in TS(Switch) in
which on and oﬀperiods of 1 minute alternate:
π = ⟨oﬀ, 0⟩⟨oﬀ, 1⟩⟨on, 0⟩⟨on, 1⟩⟨oﬀ, 1⟩⟨oﬀ, 2⟩⟨on, 0⟩⟨on, 1⟩⟨oﬀ, 1⟩. . .
is time-divergent as ExecTime(π) = 1 + 1 + 1 + . . . = ∞. The path
π′ = ⟨oﬀ, 0⟩⟨oﬀ, 1/2⟩⟨oﬀ, 3/4⟩⟨oﬀ, 7/8⟩⟨oﬀ, 15/16⟩. . .
in TS(Switch) is time-convergent, as ExecTime(π′) =
∞

i=0
 1
2
i+1 = 1 < ∞.
Deﬁnition 9.18.
Time-Divergent Set of Paths
For state s in TS(TA) let: Pathsdiv(s) = { π ∈Paths(s) | π is time-divergent }.
That is, Pathsdiv(s) denotes the set of time-divergent paths in TS(TA) that start in s.
Although time-convergent paths are not realistic, their existence cannot be avoided. For
the analysis of timed automata, time-convergent paths are simply ignored, e.g., a timed
automaton satisﬁes an invariant when along all its time-divergent paths the invariant is
satisﬁed.
Timelock.
State s in TS(TA) contains a timelock if there is no time-divergent path
starting in s.
Such states are unrealistic as time cannot progress for ever from these
states. Timelocks are considered as undesired and need to be avoided when modeling a
time-critical system by means of a timed automaton.
Deﬁnition 9.19.
Timelock
Let TA be a timed automaton. State s in TS(TA) contains a timelock if Pathsdiv(s) = ∅.
TA is timelock-free if no state in Reach(TS(TA)) contains a timelock.

Timed Automata
693
oﬀ
on
switch on
switch oﬀ
x ⩽2
reset(x)
1 ⩽x < 2
Figure 9.12: Timed automaton Switch1.
oﬀ
on
switch on
switch oﬀ
x < 3
reset(x)
1 ⩽x < 2
Figure 9.13: Timed automaton Switch2.
Example 9.20.
Modiﬁed Light Switch
We modify the light switch such that the light is on for a period with duration t ∈[1, 2),
i.e., the light is always switched oﬀwithin 2 minutes; see the timed automaton Switch1 in
Figure 9.12. The state ⟨on, 2⟩is reachable in transition system TS(Switch1), e.g., via the
execution fragment:
⟨oﬀ, 0⟩
switch on
−−−−−−−→⟨on, 0⟩
2
−→⟨on, 2⟩.
As ⟨on, 2⟩is a terminal state, Pathsdiv(⟨on, 2⟩) = ∅, and the state contains a timelock.
Timed automaton Switch1 is thus not timelock-free.
Any terminal state of a transition system that results from a timed automaton contains a
timelock. Terminal states should not be confused with terminal locations, i.e., locations
that have no outgoing edges. A terminal location ℓwith Inv(ℓ) = true, e.g., does not
result in a terminal state in the underlying transition system, as time may progress in ℓ
for ever. Terminal locations thus do not necessarily yield states with timelocks.
Not only terminal states may contain timelocks. Consider, e.g., another variant of the
light switch where Inv(on) = x < 3, see timed automaton Switch2 in Figure 9.13. The
reachable state ⟨on, 2⟩is not terminal, , e.g., the time-convergent path in TS(Switch2):
⟨on, 2⟩⟨on, 2.9⟩⟨on, 2.99⟩⟨on, 2.999⟩⟨on, 2.9999⟩. . .
emanates from it. However, Pathsdiv(⟨on, 2⟩) = ∅as the state ⟨on, 2⟩has no outgoing
discrete transitions (as the guard 1 ⩽x < 2 is violated), and time cannot progress beyond
three (due to Inv(on) = x < 3). State ⟨on, 2⟩in TS(Switch2) contains a timelock. Timed
automaton Switch2 is thus not timelock-free.

694
Timed Automata
Zenoness
As opposed to the presence of time-convergent paths, timelocks are considered
as modeling ﬂaws that should be avoided. The latter also applies to zenoness. Recall that
the execution of actions α ∈Act is instantaneous, i.e., actions take no time. Without
further restrictions, a timed automaton may perform inﬁnitely many actions in a ﬁnite
time interval. This phenomenon is also called zeno and represents nonrealizable behavior,
since it would require inﬁnitely fast processors.
Deﬁnition 9.21.
Zeno Paths
Let TA be a timed automaton. The inﬁnite path fragment π in TS(TA) is zeno (or: a
zeno path) if it is time-convergent and inﬁnitely many actions α ∈Act are executed along
π.
Deﬁnition 9.22.
Nonzenoness
A timed automaton TA is non-zeno if there does not exist an initial zeno path in TS(TA).
Timed automaton TA is thus non-zeno if and only if for every path π in TS(TA), either
π is time-divergent or π is time-convergent with almost only (i.e., all except for ﬁnitely
many) delay transitions.
Note that non-zenoness, as well as timelock freedom, only refers to the reachable fragment
of the transition system TS(TA). A non-zeno timed automaton may possess zeno paths
starting in an unreachable state. Similarly, a timelock-free timed automaton may contain
unreachable timelock states.
Example 9.23.
Zeno Paths of a Light Switch
Consider yet another variant of the light switch, in which the user has the possibility
to push the on button while the light is on. While doing so, clock x is reset, and the
light stays on for at most two units, unless the user pushes the on button again; see
timed automaton Switch3 in Figure 9.14. The paths induced by the following execution
fragments of TS(Switch3)
⟨oﬀ, 0⟩
switch on
−−−−−→⟨on, 0⟩
switch on
−−−−−→⟨on, 0⟩
switch on
−−−−−→⟨on, 0⟩
switch on
−−−−−→. . .
⟨oﬀ, 0⟩
switch on
−−−−−→⟨on, 0⟩
0.5
−−→⟨on, 0.5⟩
switch on
−−−−−→⟨on, 0⟩
0.25
−−−→⟨on, 0.25⟩
switch on
−−−−−→. . . ,
are zeno paths during which the user presses the on button inﬁnitely fast, or faster and
faster, respectively.
This unrealizable behavior can be avoided by imposing a minimal non-zero delay, c, say,
between successive button pushings by the user. This is established by imposing Inv(on) =

Timed Automata
695
oﬀ
on
switch on
x ⩽2
reset(x)
x ⩾1 : switch oﬀ
switch on
reset(x)
Figure 9.14: Timed automaton Switch3.
oﬀ
on
switch on
x ⩽200
reset(x)
x ⩾100 : switch oﬀ
x ⩾1 : switch on
reset(x)
Figure 9.15: Timed automaton Switch4.
x ⩾c for c > 0. Note that c should be a natural number. In order to model a minimal
response 0 < c < 1 where c is rational, say c =
1
100, all time constraints in the timed
automaton Switch3 need to be rescaled (see Figure 9.15). Essentially, the timed automaton
Switch4 computes with a modiﬁed time unit: one time unit for x in Switch4 corresponds
to
1
100 minutes.
To check whether or not a timed automaton is non-zeno is algorithmically diﬃcult. In-
stead, suﬃcient conditions are considered that are simple to check, e.g., by a static analysis
of the timed automaton. The following criterion is based on the intuition that a timed
automaton is non-zeno if on any of its control cycles, time advances with at least some
constant amount (larger than zero). This yields:
Lemma 9.24.
Suﬃcient Criterion for Nonzenoness
Let TA be a timed automaton with set C of clocks such that for every control cycle in TA
ℓ0
g1:α1,C1

→ℓ1
g2:α2,C2

→. . .
gn:αn,Cn

→ℓn with ℓ0 = ℓn,
there exists a clock x ∈C such that
1. x ∈Ci for some 0 < i ⩽n, and

696
Timed Automata
2. for all clock evaluations η there exists c ∈N>0 such that
η(x) < c
implies
(η ̸|= gj or Inv(ℓj)), for some 0 < j ⩽n.
Then: TA is non-zeno.
Proof: Let TA be a timed automaton over C with x ∈C satisfying the two constraints
stated in the claim and i, j the corresponding indices. Let π be a path in TS(TA) that
performs inﬁnitely many actions α ∈Act. As TA contains ﬁnitely many states, π traverses
some control cycle ℓ0 
→ℓ1 
→. . . 
→ℓn = ℓ0. Assume that i ⩽j. (As locations on cycles
can be renumbered, this is not a restriction.) Consider the path fragment in TS(TA) that
starts and ends in location ℓ0:
⟨ℓ0, η0⟩. . . ⟨ℓi−1, ηi−1⟩⟨ℓi, ηi⟩. . . ⟨ℓj−1, ηj−1⟩⟨ℓj, ηj⟩. . . ⟨ℓ0, η′
0⟩.
By the constraints satisﬁed by TA, clock x is reset on the transition ℓi−1 
→ℓi, and
the transition ℓj−1 
→ℓj is only possible when ηi−1(x) ⩾c (as for ηi−1(x) < c, either the
guard or the location invariant of ℓj are violated). This implies that by traversing the cycle
ℓ0 
→. . . 
→ℓ0 time advances with at least c > 0 time units. Hence, π is time-divergent
and TA is non-zeno.
The condition in Lemma 9.24 is compositional, i.e., if TA and TA′ both satisfy the con-
straints, then the parallel composed timed automaton TA ∥TA′ also satisﬁes the con-
straints. This follows directly from the fact that a control cycle in TA ∥TA′ consists of a
control cycle in TA, or TA′, or both. If each control cycle in TA and in TA′ satisﬁes the
constraint that time should advance with at least some positive amount, then this thus
also applies to each control cycle in TA ∥TA′. This property signiﬁcantly simpliﬁes to
checking whether a composite timed automaton is non-zeno. In case a timed automaton is
in fact untimed (as no clocks are used or all guards and invariants are vacuously true), it
can be considered as non-zeno, and thus not aﬀect the control cycles of other component
timed automata in a composite system.
Example 9.25.
Suﬃcient Condition for Nonzenoness
The timed automaton in Figure 9.15 (page 695) satisﬁes the constraints in Lemma 9.24.
In the control cycle oﬀ
→on 
→oﬀ, clock x is reset on oﬀ
→on, and the guard x ⩾100
ensures that when going from location oﬀto on, time has advanced with at least 100 time
units. On the control cycle on 
→on, clock x is reset, and the guard x ⩾1 ensures that
at least one time unit elapses on traversing this control cycle.
The timed automata Train, Gate, and Controller of Example 9.8 (page 683) all satisfy
for any control cycle the constraints in Lemma 9.24. This can be seen as follows. Timed

Timed Automata
697
automaton Gate has one control cycle: up 
→. . . 
→up. In that cycle, clock x is reset
when moving from location down to going up. Furthermore, for η(x) < 1, location up is
not reachable due to the guard x ⩾1 on going up 
→up. This ensures that on traversing
the control cycle up 
→. . . 
→up, time advances with at least one time unit. The timed
automaton Train contains the control cycle far 
→. . . 
→far. However, clock y is reset on
that cycle before reaching location near, and the guard y > 2 on near 
→in guarantees
that on traversing the control cycle at least one (in fact, more than two) time unit has
elapsed. For Controller, the resetting of clock z and guard z=1 ensure that also this timed
automaton fulﬁlls the constraints of Lemma 9.24. The timed automata Train, Gate and
Controller are thus non-zeno. As the control cycles in the composed timed automaton
(Train ∥H1 Gate) ∥H2 Controller are comprised of the constituting timed automata, this
composed timed automaton is non-zeno.
The previous considerations indicate that a timed automaton is adequately modeling a
time-critical system whenever it is non-zeno and does not contain any timelock. Timelock-
free, non-zeno timed automata induce transition systems without terminal states such that
along any path only ﬁnitely many actions are executed in ﬁnite time. In contrast to zeno
paths and timelocks, time-convergent paths will be treated akin to unfair paths (in fair
CTL) and are explicitly excluded for analysis purposes.
A delay of d > 0 time units can be realized in diﬀerent ways, in general by n > 0 delay
transitions of size d1 through dn with di > 0 such that d = d1+ . . . +dn. As we are only
interested in the amount of time advancing, a sequence of delay transitions labeled with d1
through dn and a sequence labeled with d′
1 through d′
k, say, such that n
i=1 di = k
i=1 d′
i =
d, are considered equivalent and denoted by
d⇒. This relation is used later for deﬁning
the semantics of timed CTL.
Notation 9.26.
Sets of Path Fragments
Let TA be a timed automaton. For path fragments in TS(TA) along which inﬁnitely many
actions are performed, let
s0
d0⇒s1
d1⇒s2
d2⇒. . .
with d0, d1, d2 . . . ⩾0
denote the equivalence class containing all inﬁnite path fragments induced by execution
fragments in TS(TA) of the form
s0
d1
0
→. . .
dk0
0→



time passage of
d0 time-units
s0 + d0
α0
−→s1
d1
1
→. . .
dk1
1→



time passage of
d1 time-units
s1 + d1
α1
−→s2
d1
2
→. . .
dk2
2→



time passage of
d2 time-units
s2 + d2
α2
−→
. . .

698
Timed Automata
where ki ∈IN, di ∈IR⩾0 and αi ∈Act such that ki
j=1 dj
i = di. Note that in the
⇒
notations, actions are abstracted away.
For inﬁnite path fragment π ∈s0
d0⇒s1
d1⇒. . . that performs inﬁnitely many actions,
we have ExecTime(π) = 
i⩾0 di. Path fragments in s0
d0⇒s1
d1⇒. . . are time-divergent
if and only if 
i di diverges.
Time-divergent path fragments that perform ﬁnitely many actions α ∈Act (but contain
inﬁnitely many delay transitions) are represented in a similar way, except that after the
execution of the last action α ∈Act the advance of time is represented by inﬁnitely many
1⇒transitions. That is, the set
s0
d0⇒s1
d1⇒. . .
dn−1⇒sn
1⇒sn+1
1⇒sn+2
1⇒. . .
contains all inﬁnite path fragments induced by the execution fragment of the form
s0 →. . . →



time passage of
d0 time-units
α0
−−→. . .
αn−2
−−−−→sn−1 →. . . →



time passage of
dn−1 time-units
αn−1
−−−−→sn
1→sn+1 1→sn+2 1→
. . .



inﬁnite time passage
Hence, s0
d0⇒s1
d1⇒. . . is a uniform notation for all inﬁnite time-divergent path frag-
ments.
9.2
Timed Computation Tree Logic
Timed CTL (TCTL, for short) is a real-time variant of CTL aimed to express properties of
timed automata. In TCTL, the until modality is equipped with a time interval such that
Φ U J Ψ asserts that a Ψ-state is reached within t ∈J time units while only visiting Φ-states
before reaching the Ψ-state. The fact that a deadlock may be reached within thirty time
units via legal states only, say, can be expressed as legal U [0,30] deadlock, where the atomic
propositions legal and deadlock have their obvious meaning. Timed CTL is suﬃciently
expressive to allow for the formulation of an important set of real-time system properties.
Deﬁnition 9.27.
Syntax of Timed CTL
Formulae in TCTL are either state or path formulae. TCTL state formulae over the
set AP of atomic propositions and set C of clocks are formed according to the following
grammar:
Φ ::= true
   a
   g
   Φ ∧Φ
   
¬Φ
   ∃ϕ
   ∀ϕ

Timed Computation Tree Logic
699
where a ∈AP, g ∈ACC(C) and ϕ is a path formula deﬁned by:
ϕ ::= Φ U J Φ
where J ⊆IR⩾0 is an interval whose bounds are natural numbers.
Timed CTL extends CTL with atomic clock constraints over the clocks in C, typically
the set of clocks in the timed automaton under consideration. The propositional logic
operators ∨, →, true, etc. are obtained in the usual way. The until operator is equipped
with an interval J of real numbers. Timed variants of the modal operators ♦and □are
obtained as follows: ♦J Φ = true U J Φ and
∃□J Φ = ¬∀♦J ¬Φ
and
∀□J Φ = ¬∃♦J ¬Φ.
The formula ∃□J Φ asserts that there exists a path for which during the interval J, Φ
holds; ∀□J Φ requires this to hold for all paths. As we will see later on when deﬁning
the formal semantics of TCTL, the path quantiﬁers quantify over time-divergent paths
only. Accordingly, a state in TS(TA) satisﬁes ∀♦JΦ whenever all time-divergent paths
starting in s satisfy ♦JΦ. The next-step operator is absent in TCTL. As the time domain
is continuous there is no unique next time instant which makes it impossible to provide a
suitable meaning to the next-step operator. Note that J ⊆IR⩾0 has natural bounds, i.e.,
the interval J is either of the form [n, m], (n, m], [n, m) or (n, m) for n, m ∈N and n ⩽m.
For right-open intervals, m = ∞is allowed.
In the sequel, intervals are often denoted by shorthand, e.g., ♦⩽2 denotes ♦[0,2] and □>8
denotes □(8,∞).
For the special case J = [0, ∞), the timing requirements are in fact
trivially fulﬁlled. That is:
Φ U [0,∞) Ψ = Φ U Ψ
and
♦Φ = ♦[0,∞) Φ
and
□Φ = □[0,∞) Φ.
The following examples illustrate the kind of timing properties that can be expressed in
TCTL.
Example 9.28.
Light Switch
Consider the light switch of Example 9.12 (page 688). The property
“the light cannot be continuously switched on for more than 2 minutes”
is expressed by the TCTL formula:
∀□(on −→∀♦>2 ¬on).
The property
“the light will stay on for at least 1 time unit and then switch oﬀ”

700
Timed Automata
is expressed by the TCTL formula:
∀□

(on ∧(x = 0)) −→(∀□⩽1on ∧∀♦>1oﬀ)

.
The clock x that occurs in the formula is used to specify the time instant at which the
light is switched on.
Example 9.29.
Railroad Crossing
Consider the railroad crossing example. The safety property
“the gate is always closed when the train is at the crossing”
does not contain any timing aspects, and can be described as in CTL by the formula
∀□(in −→down), where in and down are locations in the timed automata Train and
Gate, respectively. The (timed liveness) property
“once the train is far, within 1 minute the gate is up for at least 1 minute”
is expressed by the TCTL formula:
∀□(far −→∀♦⩽1 ∀□⩽1 up).
The fact that the train needs at least 2 minutes to reach the crossing after transmitting
the “approach” signal is expressed by
∀□

(near ∧(y = 0)) −→∀□⩽2 ¬in

where the atomic clock constraint y=0 indicates the time instant at which the train signals
its approach. Finally, the property that the train needs at most ﬁve minutes to pass the
crossing since its approach is expressed by:
∀□

(near ∧(y = 0)) −→∀♦⩽5far

.
The semantics of TCTL formulae is deﬁned for states of the form ⟨ℓ, η⟩. The state formulae
∀ϕ and ∃ϕ are interpreted over all time-divergent paths. That is to say, time-convergent
paths are not of any importance for the satisfaction of TCTL state formulae. This is
similar to the treatment of unfair paths in the semantics of fair CTL; see Deﬁnition 6.33
on page 360.

Timed Computation Tree Logic
701
Deﬁnition 9.30.
Satisfaction Relation for TCTL
Let TA = (Loc, Act, C, 
→, Loc0, Inv, AP, L) be a timed automaton, a ∈AP, g ∈ACC(C),
and J ⊆IR⩾0. For state s = ⟨ℓ, η⟩in TS(TA) and TCTL state formulae Φ and Ψ, and
TCTL path formula ϕ, the satisfaction relation |= is deﬁned for state formulae by
s |= true
s |= a
iﬀ
a ∈L(ℓ)
s |= g
iﬀ
η |= g
s |= ¬ Φ
iﬀ
not s |= Φ
s |= Φ ∧Ψ
iﬀ
(s |= Φ) and (s |= Ψ)
s |= ∃ϕ
iﬀ
π |= ϕ for some π ∈Pathsdiv(s)
s |= ∀ϕ
iﬀ
π |= ϕ for all π ∈Pathsdiv(s).
For time-divergent path π ∈s0
d0⇒s1
d1⇒. . ., the satisfaction relation |= for path for-
mulae is deﬁned by
π |= Φ U J Ψ
iﬀ
∃i ⩾0. si+d |= Ψ for some d ∈[0, di] with
i−1

k=0
dk + d ∈J
and
∀j ⩽i. sj+d′ |= Φ ∨Ψ for any d′ ∈[0, dj] with
j−1

k=0
dk + d′ ⩽
i−1

k=0
dk + d
where for si = ⟨ℓi, ηi⟩and d ⩾0 we have si+d = ⟨ℓi, ηi+d⟩.
The interpretations for atomic propositions, negation, and conjunction are as usual. Clock
constraint g holds in ⟨ℓ, η⟩whenever the values of the clocks in η satisfy g. State formula
∃ϕ is true in state s if and only if there exists some time-divergent path starting in s
that satisﬁes ϕ.
∀ϕ holds in s whenever all time-divergent paths starting in s satisfy
ϕ.
As stated before, path quantiﬁcation is over time-divergent paths.
Truth of ϕ on
time-convergent paths of s is irrelevant. Let us now consider the semantics of the until
operator. Time-divergent path π ∈s0
d0⇒s1
d1⇒. . . satisﬁes Φ U J Ψ whenever at some
time point in J, a state is reached satisfying Ψ and at all previous time instants Φ ∨Ψ
holds. The reader might wonder why it is not required—as in the temporal logics CTL
and LTL before—that just Φ holds at all preceding time instants. This is justiﬁed by the
following example.

702
Timed Automata
ℓ
ℓ′
x > 3 : reset(x)
x < 1
{ a }
{ b }
Figure 9.16: An example of a timed automaton .
Example 9.31.
Semantics of Until
Consider the timed automaton TA in Figure 9.16 and let Φ = ∀(a U >1b). Intuitively, we
expect TA |= Φ, since Inv(ℓ) = x < 1, and location ℓ′ cannot be left before three time units
have elapsed. At time instant t = 1.5, e.g., TA always resides in location ℓ′. Consider now
the path
π = ⟨ℓ, 0⟩⟨ℓ, 0.5⟩⟨ℓ′, 0.5⟩⟨ℓ′, 3⟩⟨ℓ, 0⟩. . . .
It follows that:
π ∈⟨ℓ, 0⟩
  
s0
0.5⇒⟨ℓ′, 0.5⟩
  
s1
2.5⇒⟨ℓ, 0⟩
  
s2
. . . .
According to the TCTL semantics, π |= a U >1b since
s1+d |= b for some d ∈[0, 2.5] such that 0.5+d > 1
and
s0+d′ |= a for all d′ ∈[0, 0.5]
and
s1+d′ |= a ∨b for all d′ ∈[0, d].
A semantics along the lines of CTL would require s1+d′ |= a for all d′ ∈[0, d] with d > 0.5.
The event ¬a ∧b, however, occurs at a time instant that is before the required time bound
]1, ∞) is reached. As a result, the statement s1+d′ |= a for all d′ ∈[0, d] with d > 0.5 does
not hold.
Note that in CTL (and LTL) it holds that Φ U Ψ is equivalent to (Φ ∨Ψ) U Ψ.
From the TCTLsemantics it follows for time-divergent path π ∈s0
d0⇒s1
d1⇒. . . that:
π |= ♦JΦ iﬀ∃i ⩾0. si+d |= Φ for some d ∈[0, di] with
i−1

k=0
dk + d ∈J.
As expected, a time-divergent path fragment satisﬁes ♦J Φ whenever a Φ-state is reached
at some time instant t ∈J. For the □J operator we obtain that
π |= □JΦ iﬀ∀i ⩾0. si+d |= Φ for any d ∈[0, di] with
i−1

k=0
dk + d ∈J.

Timed Computation Tree Logic
703
oﬀ
on
switch on
x ⩽2
reset(x)
x ⩾1 : switch oﬀ
switch on
reset(x)
Figure 9.17: Timed automaton Switch3 (again).
Thus, π |= □JΦ iﬀall states visited by π in the time interval J satisfy Φ.
Timed automaton TA satisﬁes TCTL state formula Φ whenever all its initial states satisfy
Φ.
Deﬁnition 9.32.
TCTL Semantics for Timed Automata
Let TA be a timed automaton with clocks C and locations Loc. For TCTL state formula
Φ, the satisfaction set Sat(Φ) is deﬁned by:
Sat(Φ) = { s ∈Loc × Eval(C) | s |= Φ }.
The timed automaton TA satisﬁes TCTL state formula Φ if and only if Φ holds in all
initial states of TA:
TA |= Φ
if and only if
∀ℓ0 ∈Loc0. ⟨ℓ0, η0⟩|= Φ
where η0(x) = 0 for all x ∈C.
Example 9.33.
TCTL Semantics
Consider the timed automaton Switch3 depicted in Figure 9.17.
For the sake of convenience we only consider the reachable states in TS(Switch3). We then
have:
Sat(∀♦<1oﬀ)
=
{ ⟨oﬀ, t⟩| t ⩾0 } ∪{ ⟨on, t⟩| 1 < t ⩽2 }
Sat(∃♦<1oﬀ)
=
{ ⟨oﬀ, t⟩| t ⩾0 } ∪{ ⟨on, t⟩| 0 < t ⩽2 }
Sat(∀♦(on ∧(x = 1)))
=
{ ⟨on, t⟩| 0 ⩽t ⩽1 }
Sat(∀♦(on ∧(x = 0)))
=
{ ⟨on, 0⟩}
Sat(∀♦(on ∧(x ⩾3)))
=
∅
Since Switch3 |= Φ if and only if the initial state ⟨oﬀ, 0⟩of TS(Switch3) is in Sat(Φ), we
have
Switch3 |= ∀♦<1oﬀ
and Switch3 |= ∃♦<1oﬀ
and Switch3 ̸|= ∀♦(on ∧(x ∈J))

704
Timed Automata
for any interval J ⊆IR⩾0. Consider
Φ = ∀□

(on ∧(x = 0)) −→∀♦(on ∧(x = 1))

.
It follows that Switch3 |= Φ. It is, however, essential that universal path quantiﬁcation
only consider time-divergent paths. For example, the time-convergent path
⟨oﬀ, 0⟩⟨on, 0⟩⟨on, 1
2⟩⟨on, 3
4⟩⟨on, 7
8⟩⟨on, 15
16⟩. . .
does not visit a state satisfying on ∧(x = 1).
Note that a (time-divergent) path does not have to explicitly visit a state satisfying on ∧
(x = 1) to satisfy Φ, e.g., the path ⟨oﬀ, 0⟩⟨on, 0⟩⟨on, 2⟩⟨oﬀ, 2⟩⟨on, 0⟩, . . . satisﬁes ♦on ∧
(x = 1) although a state with x=1 does not appear in its representation. The state ⟨on, 1⟩
is passed during the delay transition ⟨on, 0⟩
2
−→⟨on, 2⟩.
Finally, note that Switch3 ̸|= ∀♦on, as Inv(oﬀ) = true, i.e., the timed automaton has a
time-divergent path that resides in location oﬀfor ever.
Remark 9.34.
TCTL vs. CTL
Any TCTL formula Φ in which all intervals are of the form [0, ∞) may be considered as a
CTL formula over the set of propositions AP and the atomic clock constraints in Φ. Due
to time-divergent paths, though, there is a subtle diﬀerence between the interpretation
of TCTL and CTL formulae. As a result, TS(TA) |=TCTL ∀ϕ and TS(TA) ̸|=CTL ∀ϕ is
possible: whereas |=TCTL ranges over all time-divergent paths, |=CTL considers all paths,
in particular also the time-convergent paths. Consider, e.g., the light switch described in
Example 9.33 and the TCTL formula:
Φ = ∀□(on −→∀♦oﬀ).
It follows that
TS(TA) |=TCTL Φ



TCTL semantics
and
TS(TA) ̸|=CTL Φ



CTL semantics
.
The fact that TS(TA) ̸|=CTL Φ results from the existence of time-convergent paths in which
the location on is never left.
The semantics for TCTL is well-deﬁned for timed automata that contain a timelock. Recall
that timed automaton TA contains a timelock whenever there exists a state in TS(TA)
from which no time-divergent path emanates. A state is timelock-free if and only if it

TCTL Model Checking
705
satisﬁes ∃□true. The formula ∃□true holds in state s whenever some time-divergent path
satisﬁes □true, i.e., whenever there is at least one time-divergent path. Note that for fair
CTL, the states in which a fair path starts are also characterized by the formula ∃□true.
This yields the following characterization of timelock freeness:
Lemma 9.35.
Characterizing Timelock
Timed automaton TA is timelock-free iﬀ∀s ∈Reach(TS(TA)). s |=TCTL ∃□true.
TA |= ∀□Φ if and only if all reachable states on all time-divergent paths satisfy Φ. In
general, from TA |= ∀□Φ it may not be concluded that all reachable states in TS(TA)
satisfy Φ. This holds for timelock-free timed automata, but not for others. In particular,
the TCTL formula
∀□∃□true
is a tautology in TCTL (and not characteristic of timelock-free timed automata).
9.3
TCTL Model Checking
The TCTL model-checking problem is to check for a given timed automaton TA and
TCTL formula Φ whether TA |= Φ. It is assumed that TA is non-zeno. The possible
presence of timelocks is not relevant, as timelock freedom can be checked by a TCTL
formula, see Remark 9.35. The main diﬃculty of the TCTL model-checking problem is
that a transition system with uncountably many states has to be analyzed, since
TA |= Φ



timed automaton
iﬀ
TS(TA) |= Φ



inﬁnite transition system
.
A naive graph analysis in the state graph of TS(TA) is therefore not feasible. Instead,
the basic idea is to consider a ﬁnite quotient of this transition system, the so-called region
transition system, which is obtained from the timed automaton TA and the TCTL formula
Φ.1 In essence, the region transition system RTS(TA, Φ) is the quotient of TS(TA) with
respect to a bisimulation relation. The states in the region transition system are equiva-
lence classes of states in TS(TA) that all satisfy the same atomic clock constraints, and
from which “similar” time-divergent paths emanate, i.e., such states are TCTL equivalent.
As the number of equivalence classes is ﬁnite, this provides a basis for TCTL model check-
ing. In fact, rather than checking the TCTL formula Φ, it is checked whether a derived
CTL formula holds in RTS(TA, Φ).
1In fact, the region transition system depends on the maximal constants with which clocks are compared
in TA and the maximal timing constants in Φ.

706
Timed Automata
To check whether a timed automaton satisﬁes a TCTL formula thus amounts to model-
check its region transition system against a corresponding CTL formula. For the latter,
traditional CTL model-checking algorithms can be exploited. Summarizing:
TA |=TCTL Φ
iﬀ
RTS(TA, Φ)



ﬁnite transition system
|=CTL Φ
where Φ is a CTL formula that is obtained from the TCTL formula Φ using the translation
explained next. In summary, we obtain the scheme in Algorithm 43 where ∼= denotes the
equivalence used to obtain the quotient RTS(TA, Φ).
Algorithm 43 Basic recipe of TCTL model checking
Input: timed automaton TA and TCTL formula Φ (both over AP and C)
Output: TA |= Φ
Φ := eliminate the timing parameters from Φ;
determine the equivalence classes under ∼=;
construct the region transition system TS = RTS(TA);
apply the CTL model-checking algorithm to check TS |= Φ;
TA |= Φ if and only if TS |= Φ.
9.3.1
Eliminating Timing Parameters
We ﬁrst explain how intervals J ̸= [0, ∞) that may appear in TCTL formulae as time
bounds for path formulae are replaced by equivalent atomic clock constraints. Let TCTL♦
denote the set of TCTL formulae in which all intervals J are equal to [0, ∞). That is, the
only timing aspects that occur in TCTL♦formulae are atomic clock constraints. As such
constraints can be considered as atomic propositions, in fact, TCTL♦is a subset of CTL.
The resulting formulae provide the basis for the CTL formulae that are checked on the
region transition system.
The basic idea of eliminating J ̸= [0, ∞) from TCTL formula Φ is to introduce a fresh
clock, z, say, that neither occurs in Φ nor in the timed automaton under investigation,

TCTL Model Checking
707
and to enrich the formula Φ with atomic clock constraints that may refer to z. The clock
z is used to measure the elapse of time until a certain property, i.e., sub formula of Φ,
holds. For instance, to check the TCTL formula ∃♦JΦ in state s, clock z is reset in state
s and Φ is checked whenever the current value of clock z lies in the interval J. In order
to formalize this idea, the following auxiliary notations are helpful.
Notation 9.36.
Clock Evaluation η{. . .}
For clock evaluation η ∈Eval(C), z ̸∈C and d ∈IR⩾0, let η{z := d} denote the clock
valuation for C ∪{ z } that extends η by setting z to d while keeping the value of all other
clocks unchanged:
η{z := d}(x) =
	 η(x)
if x ∈C
d
if x = z.
Let TA be a timed automaton over C. For state s = ⟨ℓ, η⟩in TS(TA) let s{z := d} denote
the state ⟨ℓ, η{z := d}⟩. Note that s{z := d} is a state in TS(TA ⊕z) where TA ⊕z is the
timed automaton TA with the set of clocks C ∪{ z }.
The following theorem provides a recipe to transform any TCTL formula into a timing
parameter-free TCTL formula.
Theorem 9.37.
Elimination of Timing Parameters
Let TA be timed automaton (Loc, Act, C, 
→, Loc0, Inv, AP, L), and Φ U J Ψ a TCTL for-
mula over C and AP. For clock z ̸∈C, let
TA ⊕z = (Loc, Act, C ∪{ z }, 
→, Loc0, Inv, AP, L).
For any state s of TS(TA) it holds that
1. s |=TCTL ∃(Φ U JΨ)
iﬀ
s{z := 0}



state in TS(TA ⊕z)
|=TCTL ∃

(Φ ∨Ψ) U ((z ∈J) ∧Ψ)

.
2. s |=TCTL ∀(Φ U JΨ)
iﬀ
s{z := 0}



state in TS(TA ⊕z)
|=TCTL ∀

(Φ ∨Ψ) U ((z ∈J) ∧Ψ)

.
Proof: Since TA ⊕z just extends TA with a fresh clock z (which is not used in TA), it
follows that any path π in TS(TA) uniquely corresponds to a path π′ in TS(TA ⊕z) such
that
π ∈s0
d0⇒s1
d1⇒s2
d2⇒

708
Timed Automata
if and only if
π′ ∈s0{z := 0}
d0⇒s1{z := d0}
d1⇒s2{z := d0+d1}
d2⇒. . .
It is easy to see that π is time-divergent if and only if π′ is time-divergent. We now prove
that π |= Φ U J Ψ iﬀπ′ |= (Φ ∨Ψ) U ((z ∈J) ∧Ψ). We only consider the direction ⇒; the
proof for the other direction is similar. Assume π |= Φ U J Ψ. From the TCTL semantics
this is equivalent to
∃i ⩾0. si+d |= Ψ for some d ∈[0, di] with i−1
k=0 dk + d ∈J and
∀j ⩽i. sj+d′ |= Φ ∨Ψ for any d′ ∈[0, dj] with j−1
k=0 dk + d′ ⩽i−1
k=0 dk + d.
As z is a fresh clock, this is equivalent to
∃i ⩾0. s′
i+d |= Ψ for some d ∈[0, di] with i−1
k=0 dk + d ∈J and
∀j ⩽i. s′
j+d′ |= Φ ∨Ψ for any d′ ∈[0, dj] with j−1
k=0 dk + d′ ⩽i−1
k=0 dk + d.
where s′
i = si{z := i−1
k=0 dk} and s′
j = sj{z := j−1
k=0 dk}. As clock z is never reset, the
value of z in state s′
i+d equals i−1
k=0 dk + d. As this sum lies in J, in the ﬁrst conjunct Ψ
may be strengthened by the atomic clock constraint z ∈J. This yields
∃i ⩾0. s′
i+d |= (z ∈J) ∧Ψ for some d ∈[0, di] with
i−1

k=0
dk + d



=z
∈J and
∀j ⩽i. s′
j+d′ |= Φ ∨Ψ for any d′ ∈[0, dj] with j−1
k=0 dk + d′ ⩽
i−1

k=0
dk + d



=z
.
The constraint i−1
k=0 dk +d ∈J can now be omitted (as it is equivalent to z ∈J), whereas
in the second part, we may weaken Φ∨Ψ into (Φ∨Ψ)∨(Ψ ∧(z ∈J)) as for d′ = d and i=j,
Ψ ∧(z ∈J) holds. Applying the TCTL semantics yields that π′ |= (Φ∨Ψ) U ((z ∈J) ∧Ψ).
Example 9.38.
Eliminating Timing Parameters
Let Φ be a TCTL formula. According to the above mapping, the TCTL formula ∃♦⩽2 Φ
is replaced by ∃♦((z ⩽2) ∧Φ). In a similar way, we replace: ∃□⩽2 Φ = ¬∀♦⩽2 ¬Φ by
¬∀♦((z ⩽2) ∧¬Φ)
≡
∃□(¬(z ⩽2) ∨Φ)
=
∃□((z ⩽2) →Φ) .

TCTL Model Checking
709
Note that the resulting formulae are CTL formulae (or could be understood as such)
provided Φ does not contain intervals diﬀerent from [0, ∞).
In order to verify whether TA |= Φ for TCTL formula Φ, the above result suggests equip-
ping TA with a clock for each subformula of Φ of the form Ψ U JΨ′ while replacing this
subformula as indicated in Theorem 9.37.
This yields TCTL♦formula Φ.
As Φ does
not contain timing parameters, and any clock constraint can be considered as an atomic
proposition, in fact, Φ is a CTL formula! Verifying a timed CTL formula on a timed
automaton TA thus reduces to checking a CTL formula on a TA extended with a clock
whose sole purpose is to measure the elapse of time that is referred to in the formula.
9.3.2
Region Transition Systems
Consider timed automaton TA and TCTL♦formula Φ. It is assumed that TA is equipped
with an additional clock as explained in the previous section.
The idea is impose an
appropriate equivalence, denoted ∼=, on the clock valuations—and implicitly on the states
of TS(TA) by letting ⟨ℓ′, η′⟩∼= ⟨ℓ, η′⟩if ℓ= ℓ′ and η ∼= η′—such that:
(A) Equivalent clock valuations should satisfy the same clock constraints that occur in
TA and Φ:
η ∼= η′ ⇒

η |= g
iﬀ
η′ |= g for all g ∈ACC(TA) ∪ACC(Φ)

where ACC(TA) and ACC(Φ) denote the set of atomic clock constraints that occur
in TA and Φ, respectively. These constraints are either of the form x ⩽c or x < c.
(B) Time-divergent paths emanating from equivalent states should be “equivalent”. This
property guarantees that equivalent states satisfy the same path formulae.
(C) The number of equivalence classes under ∼= is ﬁnite.
In the sequel we adopt the following notation for clock values.
Notation 9.39.
Integral and Fractional Part of Real Numbers
Let d ∈IR. The integral part of d is the largest integer that is at most d:
⌊d⌋= max{ c ∈IN | c ⩽d }.
The fractional part of d is deﬁned by frac(d) = d −⌊d⌋. For example, ⌊17.59267⌋= 17,
frac(17.59267) = 0.59267, ⌊85⌋= 85, and frac(85) = 0.

710
Timed Automata
The deﬁnition of clock equivalence is based on three observations that successively lead to
a reﬁned notion of equivalence. Let us discuss these observations in detail.
First observation. Consider atomic clock constraint g, and let η be a clock valuation (both
over the set C of clocks with x ∈C). As g is an atomic clock constraint, g is either of the
form x < c or x ⩽c for c ∈IN. We have that η |= x < c whenever η(x) < c, or equivalently,
⌊η(x)⌋< c. The fractional part of η(x) in this case is not relevant. Similarly, η |= x ⩽c
whenever either ⌊η(x)⌋< c, or ⌊η(x)⌋= c and frac(x) = 0. Therefore, η |= g only depends
on the integral part ⌊η(x)⌋, and the fact whether frac(η(x)) = 0. This leads to the initial
suggestion that clock valuations η and η′ are equivalent (denoted ∼=1) whenever
⌊η(x)⌋= ⌊η′(x)⌋
and
frac(η(x)) = 0 iﬀfrac(η′(x)) = 0.
(9.1)
This constraint ensures that equivalent clock valuations satisfy the clock constraint g
provided g only contains atomic clock constraints of the form x < c or x ⩽c. (In case one
would restrict all atomic clock constraints to be strict, i.e., of the form x < c, the fractional
parts would not be of importance and the second conjunct in the above equation may be
omitted.) Note that it is crucial for this observation that only natural number constants
are permitted in the clock constraints. This equivalence notion is rather simple, leads to
a denumerable (but still inﬁnite) number of equivalence classes, but is too coarse.
Example 9.40.
A First Partitioning for Two Clocks
To exemplify the kind of equivalence classes that one obtains, consider the set of clocks C =
{ x, y }. The quotient space for C obtained by suggestion (9.1) is depicted in Figure 9.18)
where the equivalence classes are
• the corner points (q, p)
• the line segments { (q, y) | p < y < p+1 } and { (x, p) | q < x < q+1 }, and
• the content of the squares { (x, y) | q < x < q+1 ∧p < y < p+1 }
where p, q ∈IN and { (x, p) | q < x < q+1 } is a shorthand for the set of all clock
evaluations η with η(x) ∈]q, q+1[ and η(y) = p.
Second observation. We demonstrate the fact that ∼=1 is too coarse by means of a small
example. Consider location ℓwhose two outgoing transitions are guarded with x ⩾2
(action α) and y > 1 (action β), respectively; see also Figure 9.19. Let state s = ⟨ℓ, η⟩
with 1 < η(x) < 2 and 0 < η(y) < 1. Both transitions are disabled, so the only possibility
is to let time advance. The transition that is enabled next depends on the ordering of the

TCTL Model Checking
711
y
x
1
2
3
1
2
x = 3 y = 2
2 < x < 3
1 < y < 2
x = 3, 0 < y < 1
countable index
Figure 9.18: Initial partitioning for two clocks .
x
y
1
2
3
1
2
4
l
l
l
x
2
y
1
...
...
...
...
Figure 9.19: Fragment of timed automaton and time passage of two clock valuations.
fractional parts of the clocks x and y: if frac(η(x)) < frac(η(y)), then β is enabled before
α; if frac(η(x)) ⩾frac(η(y)), action α is enabled ﬁrst. Time-divergent paths in s may
thus start with α if frac(η(x)) ⩾frac(η(y)), and with β otherwise. This is represented by
the fact that delaying leads to distinct successor classes depending on the ordering of the
fractional parts of clock, see Figure 9.19 (right part).
Thus, besides ⌊η(x)⌋and the fact whether frac(η(x)) = 0, apparently the order of the
fractional parts of η(x), x ∈C is important as well, i.e., whether for x, y ∈C:
frac(η(x)) < frac(η(y)) or frac(η(x)) > frac(η(y)) or frac(η(x)) = frac(η(y)).
This suggests extending the initial proposal (9.1) for all x, y ∈C by
frac(η(x)) ⩽frac(η(y))
if and only if
frac(η′(x)) ⩽frac(η′(y)),
(9.2)
i.e., η1 ∼=2 η2 iﬀη1 ∼=1 η2 and (9.2) holds. This strengthening will ensure that equivalent
states ⟨ℓ, η⟩and ⟨ℓ, η′⟩have similar time-divergent paths.

712
Timed Automata
y
x
1
2
3
1
2
4
3 < x < 4, 1 < y < 2, x −y < 2
3 < x < 4, 1 < y < 2, x −y = 2
3 < x < 4, 1 < y < 2, x −y > 2
Figure 9.20: Reﬁning the initial partitioning for two clocks.
Example 9.41.
A Second Partitioning for Two Clocks
This observation suggests to decompose the squares { (x, y) | q < x < q+1 ∧p < y <
p+1 } into a line segment, an upper and lower triangle, i.e., the following three parts:
{ (x, y) | q < x < q+1 ∧p < y < p+1 ∧x−y < q−p },
{ (x, y) | q < x < q+1 ∧p < y < p+1 ∧x−y > q−p }, and
{ (x, y) | q < x < q+1 ∧p < y < p+1 ∧x−y = q−p }.
Figure 9.20 illustrates the resulting partitioning for two clocks.
Final observation. The above constraints on clock equivalence yield a denumerable though
not ﬁnite quotient. To obtain an equivalence with a ﬁnite quotient, we exploit the fact
that in order to decide whether TA |= Φ only the clock constraints occurring in TA and Φ
are relevant. As there are only ﬁnitely many clock constraints, we can determine for each
clock x ∈C the maximal clock constraint, cx ∈IN, say, with which x is compared in some
clock constraint in either TA (as guard or location invariant) or Φ. Since cx is the largest
constant with which clock x is compared it follows that if η(x) > cx, the actual value of
x is irrelevant. (Clock x that occurs neither in TA nor in Φ is superﬂuous and can be
omitted; for these clocks we set cx = 0.) As a consequence, the constraints (9.1) are only
relevant if η(x) ⩽cx and η′(x) ⩽cx, while for (9.2) in addition η(y) ⩽cy and η′(y) ⩽cy.
The above considerations suggest the following notion of clock equivalence.

TCTL Model Checking
713
y
x
1
2
3
1
2
ﬁnite index
4
cy = 2 cx = 4
Figure 9.21: Third (and ﬁnal) partitioning for two clocks (for cx = 4 and cy = 2).
Deﬁnition 9.42.
Clock Equivalence ∼=
Let TA be a timed automaton, Φ a TCTL♦formula (both over set C of clocks), and cx the
largest constant with which x ∈C is compared with in either TA or Φ. Clock valuations
η, η′ ∈Eval(C) are clock-equivalent, denoted η ∼= η′ if and only if either
• for any x ∈C it holds that η(x) > cx and η′(x) > cx, or
• for any x, y ∈C with η(x), η′(x) ⩽cx and η(y), η′(y) ⩽cy all the following conditions
hold:
– ⌊η(x)⌋= ⌊η′(x)⌋
and
frac(η(x)) = 0 iﬀfrac(η′(x)) = 0,
– frac(η(x)) ⩽frac(η(y))
iﬀ
frac(η′(x)) ⩽frac(η′(y)).
As the clock equivalence ∼= depends on TA and Φ, strictly speaking one should write ∼=TA,Φ
instead of ∼=. The dependency of ∼= on TA and Φ is limited to the largest constants cx;
that is to say, neither the structure of TA nor that of Φ is of relevance to clock equivalence.
The equivalence ∼= is lifted to states of the transition system TS(TA) as follows. For states
si = ⟨ℓi, ηi⟩, i = 1, 2, in TS(TA):
s1 ∼= s2
iﬀ
ℓ1 = ℓ2
and
η1 ∼= η2.
Equivalence classes under ∼= are called clock regions.

714
Timed Automata
Deﬁnition 9.43.
Clock and State Region
Let ∼= be a clock equivalence on C. The clock region of η ∈Eval(C), denoted [η], is
deﬁned by
[η] = { η′ ∈Eval(C) | η ∼= η′ }.
The state region of s = ⟨ℓ, η⟩∈TS(TA), denoted [s], is deﬁned by
[s] = ⟨ℓ, [η]⟩= { ⟨ℓ, η′⟩| η′ ∈[η] }.
In the sequel, state and clock regions are often indicated as regions whenever it is clear
from the context what is meant. Clock regions will be denoted by r, r′, and so forth.
We often use casual notations to denote clock regions or clock valuations. For a timed
automaton with two clocks, x and y say,
{(x, y) | 1 < x < 2, 0 < y < 1, x −y < 1}
denotes the clock region of all clock valuations η ∈Eval({ x, y }) with
1 < η(x) < 2
and
0 < η(y) < 1
and
frac(η(x)) < frac(η(y)).
Example 9.44.
Light Switch
Consider the timed automaton over C = { x } for the light switch and the TCTL♦formula
Φ = true. It follows that the largest constant with which x is compared is cx = 2; this is
due to the location invariant x ⩽2.
oﬀ
on
switch on
switch oﬀ
x ⩽2
reset(x)
x ⩾1
We gradually construct the regions for this timed automaton by considering each of the
constraints in Deﬁnition 9.42 separately. Clock valuations η, η′ are equivalent if η(x) and
η′(x) belong to the same equivalence class along the real line. (In general, for n clocks
this amounts to considering an n-dimensional hyperspace on IR⩾0.)
1. The requirement that η(x) > 2 and η′(x) > 2 or η(x) ⩽2 and η′(x) ⩽2 yields the
partitioning into the intervals [0, 2] and (2, ∞).

TCTL Model Checking
715
1
2
0
region
region
region
region
region
0 < x < 1
1 < x < 2
x = 0
x = 1
x = 2
x > 2
unbounded region
Figure 9.22: Clock regions for the light switch timed automaton.
2. The requirement that whenever η(x) ⩽2 and η′(x) ⩽2, the integral parts of η(x)
and η′(x) agree and frac(η(x)) = 0 iﬀfrac(η′(x)) = 0 yields the partitioning into the
intervals
[0, 0], (0, 1), [1, 1], (1, 2), [2], (2, ∞).
3. As there is only a single clock, the third constraint of Deﬁnition 9.42 trivially holds.
We thus obtain six clock regions (see Figure 9.22), and as there are two locations, twelve
state regions.
Example 9.45.
Two Clocks
Consider the set of clocks C = { x, y } and assume cx = 2 and cy = 1. As in the previous
example, we gradually construct the clock regions. Clock valuations η, η′ ∈Eval({ x, y })
are equivalent if the real-valued pairs (η(x), η(y)) and (η′(x), η′(y)) are elements of the
same clock region.
1. The requirement that η(x) > cx and η′(x) > cx or η(x) ⩽cx and η′(x) ⩽cx for any
clock x ∈C yields four classes:
{ (x, y) | 0 ⩽x ⩽2, 0 ⩽y ⩽1 },
{ (x, y) | 0 ⩽x ⩽2, y > 1 },
{ (x, y) | x > 2, 0 ⩽y ⩽1 },
and { (x, y) | x > 2, y > 1 }
2. The second requirement of Deﬁnition 9.42 yields a reﬁnement of the ﬁrst three classes
obtained in the previous step. For instance, the rectangle [(0 ⩽x ⩽2), (0 ⩽y ⩽1)]
is decomposed into the six corner points:
(0, 0), (0, 1), (1, 0), (1, 1), (2, 0) and, (2, 1),

716
Timed Automata
the (open) line segments:
{ (0, y) | 0 < y < 1 },
{ (1, y) | 0 < y < 1 },
{ (2, y) | 0 < y < 1 },
{ (x, 0) | 0 < x < 1 },
{ (x, 0) | 1 < x < 2 },
{ (x, 1) | 0 < x < 1 },
{ (x, 1) | 1 < x < 2 },
and the (open) squares:
{ (x, y) | 0 < x < 1, 0 < y < 1 }
and
{ (x, y) | 1 < x < 2, 0 < y < 1 }.
Similarly, [(0 ⩽x ⩽2), (y > 1)] is decomposed into
{ (0, y) | y > 1 }
{ (1, y) | y > 1 }
{ (2, y) | y > 1 }
{ (x, y) | 0 < x < 1, y > 1 }
{ (x, y) | 1 < x < 2, y > 1 }
In a similar way { (x, y) | x > 2, 0 ⩽y ⩽1 } is decomposed into three classes.
3. Finally, we apply the ordering constraint, see the third constraint of Deﬁnition 9.42
to { (x, y) | 1 < x < 2, 0 < y < 1 }.
Since the ordering of clocks now becomes
important, this class is split into
{ (x, y) | 1 < x < 2, 0 < y < 1, frac(x) < frac(y) },
{ (x, y) | 1 < x < 2, 0 < y < 1, frac(x) > frac(y) },
{ (x, y) | 1 < x < 2, 0 < y < 1, x−y = 1 }.
A similar reasoning applies to { (x, y) | 0 < x < 1, 0 < y < 1 }. The other classes are
not further partitioned. For instance, { (x, y) | 1 < x < 2, y > 1 } is not further split
as y > cy.
Summarizing, we obtain twenty-eight clock regions: six corner points, fourteen open line
segments, four open triangles, and four open clock regions.
Even for apparently simple timed automata, a large number of regions can arise. For
this reason, we abstain from indicating the regions in more complex examples such as
the railroad crossing and real-time mutual exclusion examples. The number of clocks, as
well as the constants cx, are essential factors that determine the number of regions. The
number of clock regions and state regions is ﬁnite, i.e., consraint (C) holds. The following
theorem contains an estimate for the number of clock regions. The number of state regions
is a factor |Loc| larger.

TCTL Model Checking
717
Theorem 9.46.
Number of Regions
The number of clock regions is bounded from below and above as follows:
|C|! ∗

x∈C
cx
⩽
| Eval(C)/∼= | ⩽
|C|! ∗2|C|−1 ∗

x∈C
(2cx + 2)
where for the upper bound it is assumed that cx ⩾1 for all x ∈C.
Proof: The lower and upper bounds are determined by considering a representation of
clock regions such that there is a one-to-one relationship between the representation of
a clock region and the clock region itself. This representation allows derivation of the
bounds.
Let C be a set of clocks and η ∈Eval(C). Every clock region r can be represented by a
tuple ⟨J, ℘, D⟩where J is a family of intervals, ℘is a permutation of a subset of clocks in
C, and D ⊆C is a set of clocks such that
• J = (Jx)x∈C is a family of intervals with
Jx ∈

[0, 0], ]0, 1[, [1, 1], ]1, 2[, . . . , ]cx−1, cx[, [cx, cx], ]cx, ∞[

,
such that η(x) ∈Jx for all clocks x ∈C and clock evaluations η ∈r.
• Let Copen be the set of clocks x ∈C such that Jx is an open interval, i,e,
Copen =

x ∈C | Jx ∈{ ]0, 1[, ]1, 2[, . . . ,
]cx−1, cx[, ]cx, ∞[ }

.
℘= { xi1, . . . , xik } is a permutation of Copen = { x1, . . . , xk } such that for any η ∈r
the clocks are ordered according to their fractional parts, i.e.,
ih < ij
imples
frac(η(xih)) ⩽frac(η(xij)).
• D ⊆Copen contains all clocks in Copen such that for all clock evaluations η′ ∈[η]
the fractional part for clock xij corresponds to the fractional part for its predecessor
xij−1 in the permutation ℘:
xij ∈D implies frac(η(xij−1)) = frac(η(xij)).
There is a one-to-one relation between the clock regions and triples ⟨J, ℘, D⟩.
The indicated upper bound for the number of clock regions is obtained by the following
combinatorial observation that there are

718
Timed Automata
• exactly .
x∈C
(2cx + 2) diﬀerent interval families J,
• maximally |Copen|! ⩽|C|! diﬀerent permutations over Copen, and
• maximally 2|Copen|−1 ⩽2|C|−1 diﬀerent choices for D ⊆C \ { x1 }.
The indicated lower bound is obtained when all clocks have a value in an open interval
(though not the unbounded interval ]cx, ∞[), and all have diﬀerent fractional parts. In
this case D = ∅, and
Jx ∈

]0, 1[, ]1, 2[, . . . , ]cx−1, cx[

.
As there are exactly .
x∈C
cx possibilities for J and maximally |C|! diﬀerent permutations,
the lower bound follows.
Example 9.47.
Number of Regions
Let us illustrate the number of regions for a reasonable small timed automaton. Assume
|C| = n such that cx = 2 for all x ∈C. The lower bound for the number of clock regions
indicated in Theorem 9.46 is n! · 2n. The minimal number of clock regions for n=2 equals
8; for n=3 and n=4 this rises to 48 and 384 respectively. For n=5, there are at least 3840
clock regions.
Lemma 9.48.
Let TA be a timed automaton and Φ a TCTL♦formula both over the set C of clocks and
∼= the clock equivalence induced by TA and Φ. Then:
1. For η, η′ ∈Eval(C) such that η ∼= η′:
η |= g
if and only if
η′ |= g for all g ∈ACC(TA) ∪ACC(Φ)
2. For s, s′ ∈TS(TA) such that s ∼= s′:
s |= a
if and only if
s′ |= a for any a ∈AP′.
where AP′ = AP ∪ACC(TA) ∪ACC(Φ).
The ﬁrst part of this lemma follows directly from the observations that justiﬁed the deﬁ-
nition of clock equivalence. Using this result, the satisfaction relation of clock constraints

TCTL Model Checking
719
(see Deﬁnition 9.10) may now be used for clock regions; [η] |= g denotes that η′ |= g for
any η′ ∈[η]. As equivalent states have the same location, the second part of the lemma
follows directly from the ﬁrst part. All states of a state region thus satisfy the same clock
constraints that occur in TA and Φ. This proves constraint (A) mentioned before.
It has been argued before that atomic clock constraints can in fact be considered as
atomic propositions. Under this view, clock equivalence between states of TS(TA) is in
fact a bisimulation. In the following, again let AP′ = AP ∪ACC(TA) ∪ACC(Φ). We lift
the notion of clock reset to regions as follows.
Notation 9.49.
Region Reset Operator
For r ∈Eval(C)/∼= and D ⊆C let
reset D in r = { reset D in η | η ∈r }.
Since for η, η′ ∈Eval(C) we have
η ∼= η′ ∧D ⊆C ⇒reset D in η ∼= reset D in η′,
it follows that reset D in r ∈Eval(C)/∼=. That is to say, resetting the clocks D in region
r can be considered as a transition between state regions.
Theorem 9.50.
Clock Equivalence is a Bisimulation
Clock equivalence is a bisimulation equivalence over AP′.
Proof: We prove that ∼= is a bisimulation (over AP′) by checking the conditions of a
bisimulation (see Deﬁnition 7.1, page 451). Let s1, s2 ∈TS(TA) such that s1 ∼= s2, that
is, s1 = ⟨ℓ, η1⟩and s2 = ⟨ℓ, η2⟩such that η1 ∼= η2.
1. From the second part of Lemma 9.48 (page 718), it follows that s1 |= a if and only
if s2 |= a for any a ∈AP′.
2. To show that any transition emanating from s1 can be mimicked by s2, distinguish
between discrete and delay transitions.
(a) (Discrete transition). Assume ⟨ℓ, η1⟩= s1
α
−−→s′
1 = ⟨ℓ′, η′
1⟩. By the semantics of
timed automata, this means that there is a transition ℓ
g:α,D

→ℓ′ in TA such that
η1 |= g
and
η′
1 = reset D in η1 |= Inv(ℓ′).

720
Timed Automata
Since η1 ∼= η2 and η1 |= g, it follows from the ﬁrst part of Lemma 9.48 that
η2 |= g. Similarly, since η1 ∼= η2, it follows that reset D in η1 ∼= reset D in η2.
As reset D in η1 |= Inv(ℓ′) we have reset D in η2 |= Inv(ℓ′). Thus:
s2
α
−−→s′
2 = ⟨ℓ′, reset D in η2⟩.
As the states s′
1 and s′
2 are in the same state region, it follows that s′
1 ∼= s′
2.
(b) (Delay transition).
Assume s1
d
−→s′
1 = s1+d for some d ∈IR⩾0.
It is not
diﬃcult to see that for any d there exists d′ such that η1+d ∼= η2+d′. From
η1 |= Inv(ℓ) and η1+d |= Inv(ℓ), it follows by Lemma 9.48 (page 718) that
η2 |= Inv(ℓ) and η2+d′ |= Inv(ℓ). But then s2
d′
−−→s2+d′ = s′
2 and s′
1 ∼= s′
2.
For transitions emanating from s′
2 an analogous reasoning applies.
Note that in the delay transitions, the amount of delaying is ignored. Instead, only the
fact that some delay may take place is of importance. Such bisimulation is also called time
abstract.
Remark 9.51.
The Need for Ordering the Fractional Parts of Clocks
For η1 ∼= η2 it holds that whenever η1(x), η2(x) ⩽cx and η1(y), η2(y) ⩽cy then:
frac(η1(x)) ⩽frac(η1(y))
if and only if
frac(η2(x)) ⩽frac(η2(y)).
Let us explain by means of a timed automaton with C = { x, y } and cx = 3, cy = 1 that
without this constraint, ∼= would not be a bisimulation.
Assume for location ℓ, Inv(ℓ) = y < 1. Consider state s1 = ⟨ℓ, η1⟩with
1 < η1(x) < 2,
0 < η1(y) < 1,
η1(x) −η1(y) > 1
and state s2 = ⟨ℓ, η2⟩with
1 < η2(x) < 2,
0 < η2(y) < 1,
η2(x) −η2(y) < 1.
The only diﬀerence between s1 and s2 is the ordering of the clocks. According to the ﬁrst
two constraints of the deﬁnition of ∼= (see Deﬁnition 9.42 on page 713), s1 and s2 would
be equivalent. But the successor state regions of s1 and s2 after delaying are distinct.
There exists a delay transition from s1 to state s′
1 = ⟨ℓ, η′
1⟩with η′
1(x) = 2 and η′
1(y) < 1,
i.e., the state region ⟨ℓ, [x = 2, y < 1]⟩. As clocks proceed at the same rate, clocks x and

TCTL Model Checking
721
y both advanced by an equal amount. Due to Inv(ℓ) = y < 1, any delay transition from
state s2 yields a state in the state region:
⟨ℓ, { (x, y) | 1 < x < 2, 0 < y < 1, x−y < 1 }⟩.
The state region ⟨ℓ, [x = 2, y < 1]⟩cannot be reached. States s1 and s2 have no corre-
sponding delay transitions, and thus are not bisimilar.
Due to the constraint on the ordering of the fractional parts of the clocks (see the third
constraint in Deﬁnition 9.42), this is avoided and s1 ̸∼= s2.
Theorem 9.50 ensures that the partitioning given by the state regions represents a re-
ﬁnement of the bisimulation quotient and allows deﬁning a quotient transition system in
which any edge ⟨ℓ, [η]⟩→⟨ℓ′, [η′]⟩is mimicked by ⟨ℓ, η⟩→⟨ℓ′, η′⟩. States in the quotient
transition system are state regions. Transitions between state regions are either delay or
discrete transitions. The following example illustrates this by means of a small example.
Example 9.52.
Region Transition System
Consider the simple timed automaton in Figure 9.23 (left) and let Φ = true.
As the
largest constant with which x is compared is 2, cx = 2. The region transition system is
depicted in Figure 9.23 (lower part). Since there is only one location ℓ, in each state region
the location is ℓ. All τ-labeled transitions are delay transitions. There are two discrete
transitions in the region automaton, both labeled with α, that lead to the initial state.
The only state region equipped with a τ-self-loop is called an unbounded region, as time
may progress without bound while remaining in the same state region.
Let us now consider Φ = ♦(z ⩽2), i.e., cz = 2. The region transition system for Φ and the
timed automaton of Figure 9.23 (upper part) is depicted in Figure 9.24. Note that it is in
fact the region transition system before (see Figure 9.23 (lower part)) extended with two
“copies” of it. These “copies” are introduced for the constraints x−z = 2 and z−x > 2.
Note that the clock z is never reset. This is typical for clocks occurring in Φ as there is
no means in a formula to reset clocks.
To deﬁne the quotient transition system with respect to ∼=, some auxiliary notions will be
introduced. A clock region is unbounded whenever all the value of any clock exceeds its
maximum constant.
Deﬁnition 9.53.
Unbounded Clock Region
The clock region r∞= { η ∈Eval(C) | ∀x ∈C. η(x) > cx } is unbounded.

722
Timed Automata
ℓ
x ⩾2 : α
reset(x)
ℓ
ℓ
ℓ
ℓ
ℓ
ℓ
τ
τ
τ
τ
τ
τ
α
α
x=0
0<x<1
x=1
x>2
x=2
1<x<2
Figure 9.23: Region transition system for a simple timed automaton with Φ = true.
ℓ
x ⩾2 : α
reset(x)
ℓ
ℓ
ℓ
ℓ
ℓ
ℓ
τ
τ
τ
τ
τ
τ
x = 0
0<x<1
x = 1
x>2
x = 2
1<x<2
z−x = 0
z−x = 0
z−x = 0
z−x = 0
z−x = 0
z−x = 0
ℓ
ℓ
ℓ
ℓ
ℓ
ℓ
τ
τ
τ
τ
τ
τ
x = 0
0<x<1
x = 1
x > 2
x = 2
1<x<2
z−x = 2
z−x = 2
z−x = 2
z−x = 2
z−x = 2
z−x = 2
ℓ
ℓ
ℓ
ℓ
ℓ
ℓ
τ
τ
τ
τ
τ
τ
x = 0
0<x<1
x = 1
x > 2
x = 2
1<x<2
z−x>2
z−x>2
z−x>2
z−x>2
z−x>2
z−x>2
α
α
α
α
α
α
Figure 9.24: Region transition system for a simple timed automaton with Φ with cz = 2.

TCTL Model Checking
723
The following deﬁnition deﬁnes the successor region of a region that is obtained by delay-
ing.
Deﬁnition 9.54.
Successor Region
Let r, r′ ∈Eval(C)/∼=. r′ is the successor (clock) region of r, denoted r′ = succ(r), if
either
1. r = r∞and r = r′, or
2. r ̸= r∞, r ̸= r′ and for all η ∈r:
∃d ∈IR>0.

η+d ∈r′ and ∀0 ⩽d′ ⩽d. η+d′ ∈r ∪r′
.
The successor state region is deﬁned as succ(⟨ℓ, r⟩) = ⟨ℓ, succ(r)⟩.
Stated in words, the progress of time in the unbounded region yields the unbounded region.
The clock region r′ is the delay successor of r ̸= r∞if any clock valuation in r can delay
to a clock valuation in r′, without having the possibility of leaving the regions r and r′
at any earlier time instant. Observe that the delay successor of a region is unique; this
corresponds to the deterministic nature of progressing time. For any delay, the progress
of time in an unbounded region is possible. This is not applicable to the other regions:
after delaying suﬃciently long, the region is left. Therefore, succ(r) ̸= r for r ̸= r∞.
Note that succ(⟨ℓ, r⟩) just deﬁnes the possible successor regions of a state region, and does
not consider the location invariant of ℓ.
Example 9.55.
Successor Clock Regions
For C = { x } with cx = 2, the successor region are given by
succ({0})
=
]0, 1[,
succ(]0, 1[)
=
{1},
succ({1})
=
]1, 2[,
succ(]1, 2[)
=
{2},
succ({2})
=
]2, ∞[ = r∞, and
succ(]2, ∞[)
=
]2, ∞[.

724
Timed Automata
For C = { x, y } with cx = 2 and cy = 1, r∞= { (x, y) | x > 2, y > 1 }. The following
regions are unbounded with respect to y, but bounded for x:
r1
=
{ (x, y) | 0 < x < 1, y > 1 }
r2
=
{ (1, y) | y > 1 },
r3
=
{ (x, y) | 1 < x < 2, y > 1 }
r4
=
{ (2, y) | y > 1 }.
It follows that succ(ri) = ri+1 for 0 < i ⩽3 and succ(r4) = r∞. For the bounded clock
regions, the successor regions are deﬁned by
succ({(x, y) | 0 < x < 1, 0 < y < 1, x < y})
=
{(x, 1) | 0 < x < 1},
succ({(x, y) | 0 < x < 1, 0 < y < 1, x > y})
=
{(1, y) | 0 < y < 1},
succ({(x, y) | 0 < x < 1, 0 < y < 1, x = y})
=
{(1, 1)},
succ({(x, y) | 1 < x < 2, 0 < y < 1, x < y})
=
{(x, 1) | 1 < x < 2},
succ({(x, y) | 1 < x < 2, 0 < y < 1, x > y})
=
{(2, y) | 0 < y < 1},
succ({(x, y) | 1 < x < 2, 0 < y < 1, x = y})
=
{(2, 1)}.
Besides, succ({(0, 0)}) = {(x, y) | 0 < x < 1, 0 < y < 1, x = y}) and succ({(2, 1)}) = r∞.
Remark 9.56.
Time Passage
The successor region succ(r) denotes the region that is obtained from r by delaying for
some amount. Not any delay in r, however, results in succ(r). A delay within a region
or to some (not necessarily direct) successor region of succ(r) is possible too. Delaying
within a region is only possible if there is no clock that has a ﬁxed value. This applies to
regions like ]0, 1[ (for |C|=1) or { (x, y) | 0 < x < 1, 0 < y < 1, x−y = 0 } for C = { x, y }.
Delaying within e.g., the regions { 0 } or { (x, 1) | 0 < x < 1 } is impossible—any delay in
these regions implies changing region.
The passage of time over several regions implies a change from r to succn(r) for n > 1.
For example, the delay transition in a timed automaton
⟨oﬀ, 0⟩1.578
−→⟨oﬀ, 1.578⟩
can be decomposed into three transitions, in which any delay is made to a state of the
successor region
⟨oﬀ, 0⟩
  
region { 0 }
0.5
−−→⟨oﬀ, 0.5⟩



region ]0, 1[
0.5
−−→
⟨oﬀ, 1⟩
  
region { 1 }
0.578
−−−−→⟨oﬀ, 1.578⟩



region ]1, ∞[
.
These considerations show that any time passage can be described by successor regions.

TCTL Model Checking
725
Recall that the interpretation of TCTL formulae was provided by considering time-divergent
paths. The following result provides a characterization of time-convergent paths in a non-
zeno timed automaton in terms of state regions.
Given that the timed automaton is
non-zeno, any time-convergent path contains ﬁnitely many delay transitions. That is to
say, from some point on, a time-convergent path stays within a certain state region. Vice
versa, a path that from some point on does not change state region, is time-convergent
(except for paths that reside in the unbounded region r∞).
Lemma 9.57.
Time Convergence
For non-zeno TA and π = s0 s1 s2 . . . an initial, inﬁnite path fragment in TS(TA):
(a) if π is time-convergent, then there exists a state region ⟨ℓ, r⟩such that for some j
si ∈⟨ℓ, r⟩for all i ⩾j.
(b) if there exists a state region ⟨ℓ, r⟩with r ̸= r∞and an index j such that
si ∈⟨ℓ, r⟩for all i ⩾j,
then π is time-convergent.
Proof:
(a) Assume π = s0 s1 s2 . . . is a time-convergent path in TS(TA).
Since π is time-
convergent, ﬁnitely many actions occur in π, i.e., from some point, say from index k
on, only delays occur. Thus there exists a state ⟨ℓ, η⟩and a sequence of non-negative
real numbers dk+1, dk+2 . . . such that
sk = ⟨ℓ, η⟩
and
si ∈⟨ℓ, η+dk+1+dk+2+ . . . +di⟩for all i > k.
Recall that the number of clock regions is ﬁnite, and observe that apart from the
self-loop at r∞, cycles (of delay successors) of clocks, regions do not exist. Thus,
as π is inﬁnite, and from some point only delays occur in π, some region must be
visited continuously from some index on. That is, there exists a clock region r and
an index j ⩾k such that
si = ⟨ℓ, η+dk+1+dk+2+ . . . +di⟩∈⟨ℓ, r⟩
for all i ⩾j.
(b) Assume there exists a state region ⟨ℓ, r⟩with r ̸= r∞and some j such that si ∈⟨ℓ, r⟩
for all i ⩾j.
We show that π = s0 s1 . . . is time-convergent by contraposition.

726
Timed Automata
Assume π is time-divergent. That is, inﬁnitely many delay transitions di occur in π
and 
i di is not converging. In particular, inﬁnitely many delay transitions occur
in ⟨ℓ, r⟩. Thus, no evaluation η ∈r exists with η(x) = 0 for some x. Distinguish two
cases.
(i) Inﬁnitely many actions α ∈Act occur in π. We show that this is impossible.
Assume action α occurs inﬁnitely often in π.
Then π traverses some loop
ℓ
g:α,D

→ℓin TA inﬁnitely often. As no evaluation η ∈r exists with η(x) = 0 for
some x, it follows that D = ∅. As r |= g, the action α can be executed inﬁnitely
often in every state ⟨ℓ, η⟩of ⟨ℓ, r⟩, i.e., the transition system TS(TA) contains
a loop ⟨ℓ, η⟩
α
−−→⟨ℓ, η⟩for any state ⟨ℓ, η⟩of ⟨ℓ, r⟩. This, however, contradicts
the assumption that TA is non-zeno.
(ii) Finitely many actions α ∈Act are executed along π. Then there is an index
j such that only delay transitions dj+1, dj+2, . . . occur in the path fragment
sj sj+1 . . ..
Let sj = ⟨ℓ, η⟩.
Since π is time-divergent, ∞
i=j+1 di does not
converge. That is, there exists an index k ⩾j such that k
i=j+1 di + η ∈r∞.
This, however, contradicts the assumption that r ̸= r∞is not left.
Lemma 9.57 suggests that in order to indicate time-divergent paths it suﬃces to ignore
delay transitions within a region.
Deﬁnition 9.58.
Region Transition System
Let TA = (Loc, Act, C, 
→, Loc0, Inv, AP, L) be a non-zeno timed automaton and let Φ be
a TCTL♦formula. Then the region transition system of TA for Φ is deﬁned as follows.
RTS(TA, Φ) = (S′, Act ∪{ τ }, →′, I′, AP′, L′)
where
• if S is the set of all states in TS(TA), then the state space of RTS(TA, Φ) is
S′ = S/ ∼= = { [s] | s ∈S },
the set of all state regions,
• I′ = { [s] | s ∈I },
• AP′ = ACC(TA) ∪ACC(Φ) ∪AP,
• L′(⟨ℓ, r⟩) = L(ℓ) ∪{ g ∈AP′ \ AP | r |= g },

TCTL Model Checking
727
• the transition relation →′ is deﬁned by:
ℓ
g:α,D

→ℓ′
∧
r |= g
∧
reset D in r |= Inv(ℓ′)
⟨ℓ, r⟩
α
−−→′ ⟨ℓ′, reset D in r⟩
and
r |= Inv(ℓ)
∧
succ(r) |= Inv(ℓ)
⟨ℓ, r⟩
τ
−→′ ⟨ℓ, succ(r)⟩
.
The dependence on formula Φ is implicit; its maximal constants are of relevance to the
clock equivalence only.
In case the region transition system does not depend on (the
maximal constants occurring in) Φ, we simply write RTS(TA). This applies, e.g., when
Φ = true or the constants in Φ for clock x do not exceed the maximal constants for x in
TA, for any x.
Example 9.59.
Light Switch
Consider the timed automaton modeling a light switch:
oﬀ
on
switch on
x ⩽2
reset(x)
x = 2 : switch oﬀ
Let Φ = true. Then cx = 2, and the region transition system RTS(Switch) = RTS(Switch, true)
is as follows, where the τ action labels are omitted:
oﬀ
x=0
oﬀ
x=1
oﬀ
x=2
oﬀ
x > 2
on
x=0
on
x=1
on
x=2
on
x > 2
oﬀ
0 < x < 1
oﬀ
1 < x < 2
on
0 < x < 1
on
1 < x < 2
sw oﬀ
sw on
sw on
sw on
sw on
sw on
sw on

728
Timed Automata
Although there exists a timelock in state ⟨on, [x > 2]⟩, the timed automaton Switch is
timelock-free, since ⟨on, [x > 2]⟩is unreachable.
Any path in the (inﬁnite) transition system of timed automaton Switch has a corresponding
path in RTS(Switch). The following path in TS(Switch):
⟨oﬀ, 0⟩⟨oﬀ, 2.5⟩⟨oﬀ, 2.7⟩⟨on, 0⟩⟨on, 1.456⟩⟨on, 1.7⟩⟨on, 2⟩. . .
corresponds to the path in RTS(TA):
⟨oﬀ, [x = 0]⟩⟨oﬀ, [0 < x < 1]⟩⟨oﬀ, [x = 1]⟩⟨oﬀ, [1 < x < 2]⟩
⟨oﬀ, [x = 2]⟩⟨oﬀ, [x > 2]⟩⟨on, [x = 0]⟩⟨on, [0 < x < 1]⟩
⟨on, [x = 1]⟩⟨on, [1 < x < 2]⟩⟨on, [x = 2]⟩. . .
(In fact, both paths are stutter trace equivalent with respect to the set of propositions
AP′.) Conversely, every path in RTS(Switch) represents a set of paths in TS(Switch). For
example, the path fragment
⟨oﬀ, [x = 0]⟩⟨oﬀ, [0 < x < 1]⟩⟨on, [x = 0]⟩⟨on, [0 < x < 1]⟩. . .
in RTS(Switch) is representative for all path fragments in TS(Switch) which reside in
location oﬀfor t time units with 0 < t < 1 and then change to location on; e.g.,
⟨oﬀ, 0⟩
⟨oﬀ, 0.231⟩
⟨oﬀ, 0.5788⟩
⟨oﬀ, 0.98⟩
⟨on, 0⟩
. . . and
⟨oﬀ, 0⟩
⟨oﬀ, 0.001⟩
⟨on, 0⟩
⟨on, 0.789⟩
⟨on, 0.79⟩
. . .
Although these path fragments change from oﬀto on at diﬀerent time instants, they are
stutter trace equivalent with respect to the set AP′ of propositions.
The time-divergent path
π = ⟨oﬀ, 0⟩⟨oﬀ, 1⟩⟨oﬀ, 2⟩⟨oﬀ, 3⟩. . . ,
in which the light is never switched on, ﬁnally reaches the unbounded state region ⟨oﬀ, [x >
2]⟩, in which time passage is represented by the self-loop:
⟨oﬀ, [x > 2]⟩
τ
−→⟨oﬀ, [x > 2]⟩.
Thus, in the region transition system, π is represented by the path
⟨oﬀ, [x = 0]⟩
⟨oﬀ, [0 < x < 1]⟩
⟨oﬀ, [x = 1]⟩
⟨oﬀ, [1 < x < 2]⟩
⟨oﬀ, [x = 2]⟩
⟨oﬀ, [x > 2]⟩
⟨oﬀ, [x > 2]⟩. . .
Example 9.60.
Region Transition System with Two Clocks
Consider the timed automaton TA:

TCTL Model Checking
729
ℓ′
0<x<1
y=0
ℓ
x=0
z=0
ℓ
0<x<1
0<y<1
x=y
ℓ′
0<x<1
0<y<1
x>y
ℓ′
x=1
0<y<1
ℓ′
x>1
y=1
ℓ′
x>1
0<y<1
ℓ′
x>1
y>1
ℓ
x=0
0<y<1
ℓ
0<x<1
0<y<1
x<y
Figure 9.25: Region transition system for example of a example timed automaton.
l
x
1
y
1
l
y
1
x
1
reset(x)
reset(y)
x
0
where cx = cy = 1. The reachable part of RTS(TA) is indicated in Figure 9.25. It is not
diﬃcult to see that the region transition system exhibits a path satisfying □(y < 1). The
following result asserts that this yields TA |= ∃□(y < 1).
The following result establishes the correctness of the model-checking approach of timed
automata via region transition systems.
Theorem 9.61.
Correctness of TCTL Model Checking
For non-zeno timed automaton TA and TCTL♦formula Φ:
TA |= Φ



TCTL semantics
if and only if
RTS(TA, Φ) |= Φ



CTL semantics
.
Proof: Let TA be a non-zeno timed automaton. By structural induction over the structure
of Φ, it is proven that any state subformula Ψ (of Φ) and any state s of TS(TA):
s |=TCTL Ψ
if and only if
[s] |=CTL Ψ.
The base cases are straightforward. For the induction step, it is assumed that the maximal
state subformulae of Ψ have been replaced by atomic propositions. (This assumption is
justiﬁed by the fact that CTL model checking is a recursive descent procedure over the
parse tree of Ψ.) Consider the proof for Ψ = ∀(a U b) for a, b ∈AP′; the proof for the
existentially quantiﬁed until-operator goes along similar lines.

730
Timed Automata
• (⇒): Assume s |=TCTL ∀(a U b) and s ∈TS(TA).
Then π |=TCTL a U b for any
time-divergent path π ∈Pathsdiv(s). Let
π′ = ⟨ℓ0, r0⟩
  
[s]
⟨ℓ1, r1⟩⟨ℓ2, r2⟩. . .
be a path in RTS(TA, ∀♦a) starting in the state region [s].
Then there exists a
corresponding path π = s0 s1 s2 . . . in TS(TA) such that s0 = s and si = ⟨ℓi, ηi⟩
where ηi ∈ri for all i ⩾0. As none of the regions ri ̸= r∞is equipped with a self-
loop, π′ either traverses a cycle (of length at least two) in RTS(TA), or the self-loop
at r∞, inﬁnitely often. That is, there does not exist a state region ⟨ℓi, ri⟩such that
for some j:
si ∈⟨ℓi, ri⟩for all i ⩾j.
By Lemma 9.57(a) (page 725), it follows that π is time-divergent.
Since s |=TCTL ∀(a U b), it follows that π |= a U b. In particular, there exists a state
sj with sj |= b such that si |= a ∨b for all i ⩽j. As in π each visited region in π′ is
represented by a state, it follows that ⟨ℓj, rj⟩|= b and ⟨ℓi, ri⟩|= a ∨b for any i ⩽j.
Hence, π′ |=CTL a U b.
• (⇐): Assume [s] |=CTL ∀(a U b). Let π = s0 s1 s2 . . . be a time-divergent path in
TS(TA) with s = s0 and
si = ⟨ℓi, ηi⟩,
i = 0, 1, 2, . . .
We show that π |=TCTL ♦a. Assume w.l.o.g. that delay transitions in π are between
successor regions. (Any delay transition can be decomposed into delay transitions
between successor regions.) As π is time-convergent, it follows from Lemma 9.57(b)
(page 725), that delay transitions within a state region ⟨ℓ, r⟩with r ̸= r∞do not
occur in π. Then
π′ = [s0] [s1] [s2] . . . = ⟨ℓ0, [η0]⟩⟨ℓ1, [η1]⟩⟨ℓ2, [η2]⟩. . .
is a path in RTS(TA, Φ) starting in the state region [s0] = [s]. As [s] |=CTL ∀(a U b)
it follows that π′ |=CTL a U b. Thus, there exists an index j such that [sj] |= b and
[si] |= a for i ⩽j. Hence, sj |= b and si |= a ∨b for any i ⩽j, and π |=TCTL ♦a. It
follows that s |=TCTL ∀(a U b).
The region transition system RTS(TA) provides a simple and eﬀective criterion to check
whether non-zeno timed automaton TA is timelock-free.

TCTL Model Checking
731
Theorem 9.62.
Timelock Freedom
Non-zeno timed automaton TA is timelock-free iﬀRTS(TA) does not have any reachable
terminal states.
Proof: Essentially, the proposition follows from Lemma 9.57 (page 725).
Example 9.63.
Modiﬁed Light Switch (Timelock)
Consider the timed automaton Switchtimelock:
oﬀ
on
switch on
switch oﬀ
x ⩽2
reset(x)
1 ⩽x < 2
which has a timelock in state ⟨on, η⟩with η(x) > 1. The transition system RTS(Switchtimelock)
is of the following form.
oﬀ
x=0
oﬀ
x=1
oﬀ
x=2
oﬀ
x > 2
on
x=0
on
x=1
on
x=2
on
x > 2
oﬀ
0 < x < 1
oﬀ
1 < x < 2
on
0 < x < 1
on
1 < x < 2
sw oﬀ
sw oﬀ
sw on
sw on
sw on
sw on
sw on
sw on
The state region ⟨on, [x=2]⟩is reachable and does not have any outgoing transitions. Thus,
Switchtimelock is not timelock-free.
The light switch described in Example 9.12 (page 688) is timelock-free, since the associated
region transition system does not contain a reachable terminal state, see Example 9.59
(page 727).
Timelock freedom can thus be checked by reachability analysis of the region transition
system.

732
Timed Automata
Remark 9.64.
Bisimulation, Time Divergence, and Fairness
The region transition system RTS(TA) is not bisimilar to TS(TA), since neither delay
transitions within a state region nor delays over several regions are explicitly represented
in RTS(TA). RTS(TA) and TS(TA) are, however, stutter-equivalent for the set of atomic
propositions AP′.
This follows from the fact that delay transitions over several state
regions in TS(TA) can be simulated in RTS(TA) by a sequence of delay transitions between
successor regions, and that delay transitions in TS(TA) within a state region may be
considered as stutter steps.
Equivalent states satisfy the same a ∈AP′ (see Lemma
9.48, page 718) and every path π′ = r0 r1 r2 . . . in RTS(TA, Φ) can be lifted to a path
π = s0 s1 s2 . . . with si ∈ri for all i ⩾0.
The reader may wonder whether region transition systems can be enriched with self-loops
(for bounded regions), and by incorporating delay transitions that jump over successor
regions. Let us discuss both enrichments. Self-loops could be added to region transition
systems to mimic the delay within a region. In order to only consider time-divergent paths,
fairness assumptions need to be imposed, however, to rule out inﬁnite (time-convergent)
behaviors that take a self-loop of a bounded region inﬁnitely often. Incorporating delay
transitions is more problematic, though. This is due to the fact that in order to determine
the truth of a TCTL path formula in a given path, states that are not explicitly on
that path may be relevant (and thus should not be skipped).
For example, any path
corresponding to an execution fragment of the form
⟨ℓ, [x = 0]⟩
d1
−→. . .
d1
−→



delay of 2 time units
⟨ℓ, [x = 2]⟩−→. . .
satisﬁes ♦(x = 1), since the interim state ⟨ℓ, [x = 1]⟩(which does not explicitly occur in
the path representation) is passed and satisﬁes the clock constraint x=1. Delay transitions
that take over successor regions are therefore not represented in region transition systems.
9.3.3
The TCTL Model-Checking Algorithm
The previous sections have described a technique to reduce the model-checking problem
TA |= Φ for non-zeno timed automaton TA and TCTL formula Φ to a CTL model-checking
problem on the region transition system for the clocks and their maximal constants in TA
and Φ. TCTL formulae have been assumed to be of the form ∃(Φ UJ Ψ) with J ̸= [0, ∞)
and such that Φ and Ψ do not contain any until formulae equipped with intervals diﬀerent
from [0, ∞). Such formulae are transformed into CTL formulae using a fresh clock z, say.
Before explaining on how this approach can be generalized toward nested formulae of the
form UJ with J ̸= [0, ∞), we summarize the approach so far by means of a small example.

TCTL Model Checking
733
oﬀ
x=0
z=0
oﬀ
0<x<1
0<z<1
x=z
oﬀ
x=1
z=1
oﬀ
x>1
z>1
on
x=0
z=1
on
x=1
z>1
oﬀ
x=1
z>1
on
x=0
z>1
on
0<x<1
z>1
sw oﬀ
sw on
Figure 9.26: Region transition system for example of a light switch timed automaton.
Example 9.65.
Formulae with a Single Time Bound
Consider the following timed automaton TA and the TCTL formula Φ = ∃♦⩽1on.
oﬀ
on
x = 1 : switch on
x ⩽1
reset(x)
x = 1 : switch oﬀ
As a ﬁrst step, Φ is replaced by Φ
=
∃♦((z ⩽1) ∧on) and TA is equipped with an
additional clock z. The maximal constants for the clocks x and z are cx = 1 and cz = 1.
The region transition system TS = RTS(TA ⊕z, Φ) is depicted in Figure 9.26.
The state region ⟨on, [x=0, z=1]⟩|= (z ⩽1) ∧on and is reachable from the initial state
region. Therefore TS |=CTL ∃♦((z ⩽1) ∧on), and thus TA |= ∃♦⩽1on.
It remains to clarify how formulae with nested time bounds, such as, e.g.,
Φ = ∀□⩾3 ∃♦]1,2] on
are treated. As before, we assume a non-zeno timed automaton TA = (Loc, Act, C, 
→,
Loc0, Inv, AP, L). Without loss of generality, TA is assumed to be timelock-free. A simple
way of treating formulae with nested time bounds is to introduce a fresh clock for each

734
Timed Automata
subformula. This amounts to, e.g., transforming the example formula Φ just above into:
Φ = ∀□

(z1 ⩾3) →∃♦(z2 ∈]1, 2] ∧on)

.
To check whether TA |= Φ amounts to applying a CTL model checker to RTS(TA ⊕
{ z1, z2 }) and Φ. Although this is a straightforward approach, the number of clocks grows
linearly with the number of time bounds. As the size of the region automaton is exponential
in the number of clocks, it is beneﬁcial to keep the number of (additional) clocks minimal.
In the sequel it will be shown that a single additional clock suﬃces for TCTL formulae
with arbitrary many (nested) time bounds.
As before, the timed automaton TA is equipped with a single fresh clock z, say, that does
not occur in TA. The principle of the model-checking algorithm is similar in spirit to that
of CTL—a recursive descent procedure over the parse tree of TCTL formula Φ. The clock
z is of interest only for subformulae Ψ of Φ that contain a time bound. Once Sat(Ψ) is
determined, the clock z is available for checking another subformula of Φ which contains
a time bound.
Let TS = TS(TA ⊕z), the transition system of TA equipped with the additional clock z
which will be used to evaluate the time-constrained formulae. The state space of TS is
Sts = Loc × Eval(C ∪{ z }).
For state s = ⟨ℓ, η⟩∈Sts and d ∈IR⩾0, let state s{z := d} ∈Sts which originates from s
by assigning value d to clock z and leaving all other clocks unaﬀected:
s{z := d} = ⟨ℓ, η{z := d}⟩
where
η{z := d}(x) =
	 d
if z = x
η(x)
otherwise
Let R = RTS(TA⊕z, Φ) and let Srts be the state space of R. For state region [s] = ⟨ℓ, r⟩∈
Srts, let [s]{z := 0} denote the state region ⟨ℓ, r{z := 0}⟩in Srts where
r{z := 0} = { η{z := 0} | η ∈r }.
Example 9.66.
Regions in RTS(TA ⊕z, Φ)
The states in the region transition systems R = RTS(TA ⊕z, Φ) and RTS(TA, Φ) are
strongly related; in fact, their only diﬀerence is the clock evaluation for clock z.
Let
C = { x }. The state region ⟨ℓ, [0 < x < 1]⟩in RTS(TA, Φ) corresponds to the following
state regions in Srts:
• ⟨ℓ, [0 < x < 1, z = c]⟩for c = 0, 1, . . . , cz,

TCTL Model Checking
735
• ⟨ℓ, [0 < x < 1, z > cz]⟩,
• ⟨ℓ, [0 < x < 1, c < z < c+1, frac(x) ▷◁frac(z)]⟩
for c = 0, 1, . . . , cz and ▷◁∈{ <, >, = }.
In the sequel, we present an algorithm to check whether TA |= Φ for TCTL formula Φ
that may contain several (possibly nested) time bounds. The basic idea is to exploit the
CTL model-checking algorithm on the region transition system of TA ⊕z and the CTL
formula Φ. This algorithm computes the satisfaction sets:
SatR(Φ) = { [s] ∈Srts | [s] |= Φ }.
Due to the bottom-up nature of the CTL model-checking algorithm, on computing SatR(Ψ)
for subformula Ψ of Φ, the satisfaction sets SatR(Ψi) for any subformula Ψi of Ψ have
been determined and are at our disposal. Any subformula Ψi can thus be replaced by
(fresh) atomic propositions aΨi. Accordingly, states in the region transition system R are
either labeled with atomic propositions that occur in TA, atomic clock constraints in Φ, or
propositions aΨi for any subformula Ψi of Φ. States in R may, in addition, be labeled with
propositions of the form z ∈J in case Ψi UJ Ψj is a subformula of Φ. These propositions
are the atomic clock constraints of clock z. The following example illustrates this.
Example 9.67.
Propositions for the Region Transition System
Consider the TCTL formula:
Φ = ∀□⩽3 ( ∃♦[2,6]a
  
=Ψ1
∧∃□]2,5[ ∀♦⩾3 (b ∧(x = 9))



=Ψ2



=Ψ3



=Ψ4



=Ψ5
),
The set of propositions of R contains the propositions a and b, the clock constraint x=9,
and the propositions aΨ1 through aΨ5, and aΦ. In addition, the clock constraints z ⩽3,
z ∈[2, 6], z ∈]2, 5[ and z ⩾3 are included; these clock constraints correspond to the time
bounds of the subformulae of Φ.
As stated above, verifying whether TA |= Φ boils down to applying a CTL model checker
to the region transition system R and Φ. For subformula Ψ of Φ we have
s ∈Sat(Ψ)



satisfaction relation in TS(TA)
iﬀ
aΨ ∈Lrts([s])



label in RTS(TA, Φ)
.

736
Timed Automata
Algorithm 44 (page 737) summarizes the essential steps of the TCTL model-checking
algorithm. First, the region transition system for TA ⊕z and Φ is determined. By means
of a recursive descent procedure over the parse tree of Φ, the satisfaction set SatR(Ψ) =
{ [s] ∈Srts | [s] |= Ψ } is determined for each subformula Ψ of Φ. For propositional logical
formula Ψ, the treatment is straightforward. The interesting cases are the path formulae.
Let us explain the treatment for Ψ = ∃(a UJ b); for universally quantiﬁed formulae, the
procedure is similar. A CTL model checker is applied on the region transition system and
the CTL formula Ψ = ∃(a U ((z ∈J) ∧b)). Note that Ψ is a CTL formula over the set
of atomic propositions that occur in Φ, clock constraints in Φ, and clock constraints on z
(like z ∈J). Theorems 9.37 (page 707) and 9.61 (page 729) yield
s |=TCTL Ψ
iﬀ
s{z := 0} |=TCTL Ψ
iﬀ
[s{z := 0}] |=TCTL Ψ
where [s{z := 0}] is a state in the region transition system R. Accordingly, all states [s]
in R for which
[s{z := 0}] |=TCTL Ψ
are labeled with proposition aΨ once SatR(Ψ) has been determined. Once all subformulae
have been treated, TA |= Φ if and only if all initial states in the region transition system
R are labeled with aΦ.
In case TA refutes Φ, the path fragment that is returned as
a counterexample by the CTL model checker for the region transition system can be
returned. The same applies to the generation of witnesses.
Given the fact that TA |= Φ can be decided by means of a CTL-like model-checking
algorithm on the region transition system, we obtain:
Theorem 9.68.
Time Complexity of TCTL Model Checking
For timed automaton TA and TCTL formula Φ, the TCTL model-checking problem TA |=
Φ can be determined in time O ((N+K) · | Φ |), where N and K are the number of states
and transitions in the region transition system RTS(TA, Φ), respectively.
The worst-case time complexity of TCTL model checking is thus linear in the size of Φ—
due to the recursive descent over the parse tree of Φ—and in the size of the region transition
system. As the state-space size of the region transition system grows exponentially in
the number of clocks (and maximal constants cx) (see Theorem 9.46, page 717), the time
complexity of TCTL model checking is exponential in the number of clocks. Although this
does not aﬀect the worst-case time complexity, it provides ample means to signiﬁcantly
reduce the number of states in the transition system (like the region transition system)
that symbolically represent the behavior of the timed automaton.
We state here without proof that the veriﬁcation problem for real-time systems is compu-
tationally hard, as even for TCTL there is a PSPACE lower bound.

TCTL Model Checking
737
Algorithm 44 TCTL model checking (basic idea)
Input: non-zeno, timelock-free timed automaton TA and TCTL formula Φ
Output: “yes” if TA |= Φ, “no” otherwise.
R := RTS(TA ⊕z, Φ);
(* with state space Srts and labeling Lrts *)
for all i ⩽| Φ | do
for all Ψ ∈Sub(Φ) with | Ψ | = i do
switch(Ψ):
true
:
SatR(Ψ) := Srts;
a
:
SatR(Ψ) := { s ∈Srts | a ∈Lrts(s) };
Ψ1 ∧Ψ2
:
SatR(Ψ) := { s ∈Srts | {aΨ1, aΨ2} ⊆Lrts(s) };
¬Ψ′
:
SatR(Ψ) := { s ∈Srts | aΨ′ ̸∈Lrts(s) };
∃(Ψ1 UJΨ2)
:
SatR(Ψ) := SatCTL

∃( (aΨ1 ∨aΨ2) U ((z ∈J) ∧aΨ2) )

;
∀(Ψ1 UJΨ2)
:
SatR(Ψ) := SatCTL

∀( (aΨ1 ∨aΨ2) U ( (z ∈J) ∧aΨ2) )

;
end switch
(* add aΨ to the labeling of all state regions where Ψ holds *)
forall s ∈Srts with s{z := 0} ∈SatR(Ψ) do Lrts(s) := Lrts(s) ∪{ aΨ } od;
od
od
if Irts ⊆SatR(Φ) then return “yes” else return “no” ﬁ

738
Timed Automata
Theorem 9.69.
Complexity of TCTL Model Checking
The TCTL model-checking problem is PSPACE-complete.
The proof of the PSPACE-completeness is not provided here; it can be found in [9].
9.4
Summary
• Timed automata are program graphs in which clock variables are used to measure
the elapse of time. Guards on edges determine when an edge may be taken, whereas
(location) invariants describe how long the system may reside in a location.
• A timed automaton describes an inﬁnite transition system, and thus is a model to
ﬁnitely model a continuous-time system.
• A path of a timed automaton is time-divergent if time may pass without bound. A
timed automaton is timelock-free whenever, from all states in its transition system,
at least one time-divergent path can start.
That is, all its states satisfy ∃□true
(under the TCTL semantics).
• A path of a timed automaton is zeno if it is not time-divergent and inﬁnitely many
actions are performed on it. A non-zeno timed automaton does not have initial zeno
paths. A suﬃcient criterion for non-zenoness is that in all control cycles at least a
single time unit elapses.
• Timed CTL is a real-time variant of CTL in which clock constraints may act as
atomic propositions and the until operator is equipped with a time interval. The
semantics of universal and existential path formulae is deﬁned in terms of time-
divergent paths. This treatment is similar to fair CTL where only fair paths are
considered.
• Model-checking whether timed automaton TA satisﬁes TCTL formula Φ can be
reduced to checking a CTL formula derived from Φ on a ﬁnite transition system
(determined by both TA and Φ), the so-called region transition system. The key to
this concept is a clock equivalence relation, a bisimulation relation on propositions
and clock constraints.
• The size of the region transition system is exponential in the number of clocks and
the constants with which clocks are compared.
• A timed automaton is timelock-free whenever its region transition system does not
have reachable terminal states.

Bibliographic Notes
739
9.5
Bibliographic Notes
Timed automata. The distinction between instantaneous activities (like changing a state)
and delays originates from real-time process algebras such as timed CSP [366], timed
CCS [427], and ATP [315]. The resulting two-phase behavior in which discrete phases – a
state change due to some activity – and continuous phases – passage of time – alternate
has been adopted in timed automata. Timed automata have been introduced by Alur and
Dill [10] (the journal version is published as [11]), Dill [131] and H. R. Lewis [271]. Hen-
zinger et al. [200] introduced the idea of invariants and called this safety timed automata.
Extensions of timed automata include, e.g., timed automata with deadlines (as opposed
to invariants) by Bornot and Sifakis [58], timed automata with drifting clocks – associ-
ating an interval to each clock that speciﬁes the relative speed with respect to an exact
reference clock – by Olivero, Sifakis, and Yovine [316], and hybrid automata for describing
a mixture of discrete and continous behavior of a more general nature by Maler, Manna,
and Pnueli [281]. D’Argenio and Brinksma [111] deﬁned a process algebra for describing
safety timed automata.
Model-checking timed automata. The decidability of model-checking timed CTL has been
shown by Alur, Courcoubetis, and Dill [9], using clock equivalence and region transition
systems. The symbolic manipulation of timed automata by means of sets of linear in-
equations over pairs of clocks has been brought up by Henzinger et. al. [200]. Bouyer
has shown that symbolic backward reachability in the setting where timed automata are
equipped with clock diﬀerence constraints (i.e., x−y ≺c) calls for a special treatment [61].
Survey papers on model-checking timed automata have been provided by Bengtsson and
Yi [43] and Yovine [430]. Time-abstract bisimulation originates from Larsen and Yi [265]
who studied this equivalence in the context of a real-time process algebra. Decidability
of time-abstract bisimulation has been shown by Cerans [78]. Tripakis and Yovine [394]
introduced the use of time-abstract bisimulation for timed automata veriﬁcation. In the
journal paper [395], these authors describe linear-time (using timed B¨uchi automata) and
branching-time (timed CTL) veriﬁcation algorithms based on time-abstract bisimulation.
They also present a quotienting algorithm with respect to time-abstract bisimulation. Dif-
ference bound matrices have been proposed for timed automata by Dill [131]. Berthomieu
and Menasche [48] have used these data structures for the analysis of time Petri nets and
Bellman [40] exploited these structures for constraint graphs. Larsen et al. [263] intro-
duced a symbolic data structure akin to binary decision diagrams for dealing with zones
in a compact manner. The edited volume [294] contains an overview of techniques and
tools for the veriﬁcation of real-time systems.
Linear-time properties. Timed automata with ﬁnal locations accept timed languages, i.e.,
sets of inﬁnite sequences of pairs consisting of a symbol and a real value representing
its time of occurrence. Alur and Dill [11] proved that the class of languages accepted

740
Timed Automata
by timed automata is not closed under complementation, and hence no simple logical
characterization of this class exists. Alur and Dill [12] present an algorithm to check the
emptiness of the language accepted by a timed automaton. Alur, Fix, and Henzinger [13]
proposed event-recording automata which are closed under all Boolean operations, includ-
ing complementation. An event-recording automaton is a timed automaton that contains
for every event (i.e., action) a clock that records the time of the last occurrence of the
event. Asarin, Caspi, and Maler [20] deﬁned timed regular expressions and proved that,
`a la Kleene’s theorem for ﬁnite automata, its expressive power is equivalent to timed au-
tomata (without location invariants). Intersection and renaming are essential operators
for timed regular expressions to obtain this result. As in classical automata theory, the
construction of automata from expressions is rather straightforward, but the reverse di-
rection is much more involved. The authors extend their results also to timed ω-regular
expressions.
Model checkers for timed automata. Behrmann, Larsen, Petterson, and Yi and colleagues
have developed the model checker Uppaal [35] since the mid-nineties. It supports a safety
fragment of timed CTL, and allows bounded liveness properties to be checked using test
automata. Around the same time, Yovine et al. developed the model checker Kronos
[429] which supports timed CTL. During recent years, Uppaal has been extended with
branch-and-bound algorithms for dealing with priced timed automata where locations are
equipped with a cost rate [353]. Wang [417] has developed a timed automata model checker
using a symbolic data structure akin to binary decision diagrams.
9.6
Exercises
Exercise 9.1.
Consider the timed automaton LightSwitch illustrated below.
oﬀ
on
y ⩽3
x ⩾1 : switch on
reset(x)
reset(x, y)
y=3 : switch oﬀ
x ⩾2 : sw on, reset(x)
Questions:
(a) Determine the transition system TS(LightSwitch).
(b) Determine the region transition system RTS(LightSwitch, true).

Exercises
741
(c) Check whether LightSwitch is timelock-free and non-zeno.
Exercise 9.2.
Consider the following two timed automata:
(a)
(b)
y ⩽4 :
reset(y)
x ⩽4 :
reset(x)
y ⩽4 :
x ⩽4 :
reset(y)
reset(x)
As these timed automata have a single location only, the state of these timed automata
can be considered as just a point in the real plane. A point (d, e) (with d, e ⩾0) thus
represents that clock x has value d and clock y has value e. Determine the reachable state
space of each of these timed automata. Justify your answers.
Exercise 9.3.
(Modeling exercise). A control system must ensure the safe and correct
functioning of a set of traﬃc lights at a T-junction between a major and a minor road.
The lights will be set on green on the major road and red on the minor road unless a
vehicle is detected by a sensor in the road just before the lights on the minor road. In
this case the lights will be switchable in the standard manner and allow traﬃc to leave
the minor road. After a suitable interval the lights will revert to their default position to
allow traﬃc to ﬂow on the major road again. Once a vehicle is detected the sensor will
be disabled until the minor-road lights are set to red again. A sketch of the T-junction is
provided below.
Lights
Minor road
Major road

742
Timed Automata
Questions:
1. First we ignore all timing issues involved and concentrate on the qualitative aspects
of the behavior of the traﬃc lights. Model the above system as a network of (timed)
automata. For convenience, you may assume that the two major-road lights are fully
synchronized and can be modeled as a single light. Complement your system model
by adding a process that regulates the arrival of cars in the minor road.
2. Adapt your model so as to incorporate the following timing constraints. Deal with
each timing constraint separately so as reduce the complexity.
Indicate for each
timing constraint the necessary adaptations to your un-timed model:
(a) a minor-road light stays on green for 30 seconds,
(b) all interim lights stay on for 5 seconds,
(c) there is a 1 second delay between switching one light oﬀand another on (e.g.,
switching from red to yellow),
(d) the major-road lights must be on green for at least 30 seconds in each cycle,
(e) (more involved) but must respond to the sensor immediately after that.
3. We extend the T-junction in the following way. Suppose there is a pedestrian crossing
a short distance down the minor road but beyond the sensor. There is a button on
each side of the road for pedestrians to indicate they wish to cross. The crossing
should only allow people to cross when the “minor lights” are set to red in order to
minimize waiting times for traﬃc on the minor road. The new situation is sketched
below.
Major road
Sensor
Minor road
Crossing
Button
Extend your timed model of the previous question in order to cope with this new
situation.

Exercises
743
4. Does the crossing indeed only allow pedestrians to cross when the “minor lights” are
set to red?
(This exercise is inspired by [151].)
Exercise 9.4.
Consider the following six timed automata:
(a)
x ⩽2
y ⩽2
y ⩽2
(b)
x ⩽2
y ⩽2
(c)
y ⩽2
y ⩽2
(f)
x ⩽3
y ⩽3
y ⩽3
(e)
x ⩽2
y ⩽3
y ⩽3
(d)
y ⩽2
a
b
c
a
b
c
a
b
c
a
b
c
a
b
c
a
b
c
x ⩽2 :
reset(y)
x ⩽2 :
reset(y)
x ⩽2 :
reset(y)
x ⩽2 :
x ⩽2 :
reset(y)
reset(y)
x ⩽3 :
reset(y)
Give for each individual timed automaton a TCTL formula that distinguishes this timed
automaton from all other ones. It is allowed to use only the atomic propositions a, b, and
c and clock constraints in the TCTL formulae. Location identiﬁers are not allowed. (This
exercise is due to Pedro D’Argenio.)

744
Timed Automata
Exercise 9.5.
Given the following timed automaton TA:
ℓ0
x ⩽2
∅
ℓ1
x ⩽1
∅
ℓ2
x ⩽2
{ a }
x = 2
x = 1
1 ⩽x < 2
x > 1
reset(x)
reset(x)
reset(x)
Questions:
(a) Determine the transition system TS(TA).
(b) Determine the set of states Sat(∃♦<4 a).
(c) Determine the region transition system RTS(TA, true).

Chapter 10
Probabilistic Systems
Whereas model-checking techniques focus on the absolute guarantee of correctness —
“it is impossible that the system fails” — in practice such rigid notions are hard, or
even impossible, to guarantee. Instead, systems are subject to various phenomena of a
stochastic nature, such as message loss or garbling and the like, and correctness — “with
99% chance the system will not fail” — is becoming less absolute. This chapter considers
the automated veriﬁcation of probabilistic systems, i.e., systems that exhibit probabilistic
aspects1. Probabilistic aspects are essential for, among others:
• Randomized algorithms.
Typical examples are distributed algorithms like leader
election or consensus algorithms where coin-tossing experiments are used to break
the “symmetry” between the processes such that, e.g., consensus will eventually be
reached with probability 1.
• Modeling unreliable and unpredictable system behavior. Phenomena like message
loss, processor failure, and the like may be modeled by nondeterminism. This is
often appropriate in early system design phases where systems are considered at a
high level of abstraction and where information about the likelihood is (sometimes
deliberately) left unspeciﬁed.
In later design stages, though, where the internal
system characteristics become more dominant, probabilities are a useful vehicle to
quantify and thus reﬁne this information.
• Model-based performance evaluation. As performance evaluation is aimed at fore-
casting system performance and dependability, probabilistic information — what is
1Note: verifying probabilistic systems should not be confused with probabilistic veriﬁcation, a model-
checking technique that is based on a partial state-space exploration.
745

746
Probabilistic Systems
the distribution of the message transmission delay or what is the failure rate of a
processor? — needs to be present in order to evaluate quantitative properties like
waiting time, queue length, time between failure, and so on.
In order to model random phenomena, transition systems are enriched with probabilities.
This can be done in diﬀerent ways. In discrete-time Markov chains (MCs), all choices are
probabilistic. Markov chains are the most popular operational model for the evaluation
of performance and dependability of information-processing systems. Roughly speaking,
Markov chains are transition systems with probability distributions for the successors
of each state.
That is, instead of a nondeterministic choice, the next state is chosen
probabilistically. Markov chains are not appropriate for modeling randomized distributed
systems, since they cannot model the interleaving behavior of the concurrent processes in
an adequate manner. For this purpose, Markov decision processes (MDPs) are used. In
MDPs, both nondeterministic and probabilistic choices coexist. Put in a nutshell, MDPs
are transition systems in which in any state a nondeterministic choice between probability
distributions exists. Once a probability distribution has been chosen nondeterministically,
the next state is selected in a probabilistic manner—as in MCs. Any MC is thus an MDP
in which in any state the probability distribution is uniquely determined. Randomized
distributed algorithms are typically appropriately modeled by MDPs, as probabilities af-
fect just a small part of the algorithm and nondeterminism is used to model concurrency
between processes by means of interleaving.
The veriﬁcation of probabilistic systems can be focused on either quantitative properties or
qualitative properties (or both). Quantitative properties typically put constraints on the
probability or expectation of certain events. Instances of quantitative properties are, e.g.,
the requirement that the probability for delivering a message within the next t time units
is at least 0.98, or that the expected number of unsuccessful attempts to ﬁnd a leader in
a concurrent system is at most seven. Qualitative properties, on the other hand, typically
assert that a certain (good) event will happen almost surely, i.e., with probability 1, or
dually, that a certain (bad) event almost never occurs, i.e., with zero probability. Typical
qualitative properties for Markov models are reachability, persistence (does eventually an
event always hold?), and repeated reachability (can certain states be repeatedly reached?).
The purpose of this chapter is to present the main veriﬁcation principles for qualitative and
quantitative properties of MCs and MDPs. These range from techniques to analyze reach-
ability, persistence, and repeated reachability properties, to model-checking algorithms
for a probabilistic variant of CTL, called Probabilistic Computation Tree Logic, PCTL for
short. This logic is appropriate for expressing a large class of properties in a rather elegant
manner. For instance, the property “eventually a leader will be elected with probability
at least 4
5” for a randomized leader election protocol is expressed in PCTL by
P⩾0.8(♦leader).

Markov Chains
747
Alternatively,
P⩽0.015(¬c.empty U ⩽6c.full)
asserts that the probability of a channel c being fully occupied within the next six steps,
while in all intermediate conﬁgurations c is nonempty, is bounded above by 0.015.
Apart from branching-time properties in PCTL, this chapter also covers linear-time prop-
erties. As opposed to PCTL where probabilities are expressed syntactically by means of
the P operator, in the linear-time setting probabilistic concepts only appear on the seman-
tic level. That is, in the probabilistic linear time setting, LTL formulae serve to specify
the desired or bad behaviors and the aim is to establish the probability that a given LTL
formula holds. Thus, the satisfaction relation over states is no longer Boolean—a formula
holds for a state or not—but assigns probability values to states. This chapter deals with
the veriﬁcation of linear-time properties such as regular safety properties and ω-regular
safety properties.
In line with the rest of this monograph, we adopt a state-based view of probabilistic
models. This means that Markov chains and Markov decision processes are treated as
variants of directed graphs (read: transition systems) where the edges (i.e., transitions)
are augmented with randomness information. This is in contrast to many textbooks where
MCs are deﬁned as sequences of random variables. The state-based approach with atomic
propositions for the states appears to be more natural, when viewing MCs and MDPs
as operational models for reactive systems and structures for temporal logics (as we do).
As compositional approaches for Markov models are outside the scope of this monograph,
actions are irrelevant in this chapter and are therefore omitted.
10.1
Markov Chains
Markov chains behave as transition systems with the only diﬀerence that nondeterministic
choices among successor states are replaced by probabilistic ones.
That is to say, the
successor state of state s, say, is chosen according to a probability distribution.
This
probability distribution only depends on the current state s, and not on, e.g., the path
fragment that led to state s from some initial state. Accordingly, the system evolution
does not depend on the history (i.e., the path fragment that has been executed so far),
but only on the current state s. This is known as the memoryless property.
Deﬁnition 10.1.
(Discrete-Time) Markov Chain (MC)
A (discrete-time) Markov chain is a tuple M = (S, P, ιinit, AP, L) where

748
Probabilistic Systems
• S is a countable, nonempty set of states,
• P : S × S →[0, 1] is the transition probability function such that for all states s:

s′∈S
P(s, s′) = 1,
• ιinit : S →[0, 1] is the initial distribution, such that 
s∈S
ιinit(s) = 1, and
• AP is a set of atomic propositions and L : S →2AP a labeling function.
M is called ﬁnite if S and AP are ﬁnite. For ﬁnite M, the size of M, denoted size(M),
is the number of states plus the number of pairs (s, s′) ∈S × S with P(s, s′) > 0.
The transition probability function P speciﬁes for each state s the probability P(s, s′) of
moving from s to s′ in one step, i.e., by a single transition. The constraint imposed on P
ensures that P is a distribution. For the mathematical treatment of Markov chains, it is
irrelevant whether the nonzero transition probabilities are rational or not. However, for
algorithmic purposes the values P(s, s′) are supposed to be rational for all states s, s′ ∈S.
The value ιinit(s) speciﬁes the probability that the system evolution starts in state s. The
states s with ιinit(s) > 0 are considered as the initial states. In a similar way, the states s′
for which P(s, s′) > 0 are viewed as the possible successors of s. For state s and T ⊆S,
let P(s, T) denote the probability of moving from s to some state t ∈T in a single step.
That is,
P(s, T) = 
t∈T
P(s, t).
In the sequel, we often identify the transition probability function P : S × S →[0, 1]
with the matrix ( P(s, t) )s,t∈S. The row P(s, ·) for state s in this matrix contains the
probabilities of moving from s to its successors, while the column P(·, s) for state s speciﬁes
the probabilities of entering state s from any other state. Similarly, the initial distribution
ιinit is often viewed as a vector ( ιinit(s) )s∈S.
The use of atomic propositions and the labeling function L is the same as for transition
systems. In the remainder of this chapter, we will often treat the state names as atomic
propositions, i.e., AP = S and L(s) = { s }.
A Markov chain induces an underlying digraph where states act as vertices and there is
an edge from s to s′ if and only if P(s, s′) > 0. Paths in Markov chains are maximal (i.e.,

Markov Chains
749
inﬁnite) paths in the underlying digraph. They are deﬁned as inﬁnite state sequences
π = s0 s1 s2 · · · ∈Sω such that P(si, si+1) > 0 for all i ⩾0. For path π in M, inf(π)
denotes the set of states that are visited inﬁnitely often in π. For ﬁnite Markov chains,
inf(π) is nonempty for all paths π.
Markov chains are depicted by their underlying digraph where edges are equipped with
the transition probabilities in ]0,1]. If a state s has a unique successor s′, i.e., P(s, s′) = 1,
the transition probability may be omitted.
Example 10.2.
A Simple Communication Protocol
Consider a simple communication protocol operating with a channel. It is error-prone
in the sense that messages may be lost, see the Markov chain depicted in Figure 10.1.
Here, ιinit(start) = 1 and ιinit(s) = 0 for s ̸= start, i.e., start is the unique initial state.
In the state start, a message is generated that is senf oﬀalong the channel in its unique
successor state try. The message is lost with probability
1
10, in which case the message
will be sent oﬀagain, until it is eventually delivered. As soon as the message has been
delivered correctly, the system returns to its initial state.
start
try
lost
delivered
1
1
10
1
1
9
10
Figure 10.1: Markov chain for a simple communication protocol.
Using the enumeration start, try, lost, delivered for the states, the transition probability
function P viewed as a 4×4 matrix and the initial distribution viewed as a column vector
are
P =
⎛
⎜
⎜
⎝
0
1
0
0
0
0
1
10
9
10
0
1
0
0
1
0
0
0
⎞
⎟
⎟
⎠
ιinit =
⎛
⎜
⎜
⎝
1
0
0
0
⎞
⎟
⎟
⎠
An example of a path is
π = (start try lost try lost try delivered)ω.
Along this path each message has to be retransmitted two times before delivery. It follows
that inf(π) = S. For T = { lost, delivered }, we have P(try, T) = 1.

750
Probabilistic Systems
Example 10.3.
Simulating a Die by a Fair Coin
Consider simulating the behavior of a standard six-sided die by a fair coin, as originally
proposed by Knuth and Yao [242], see the Markov chain depicted in Figure 10.2.
s0
s1,2,3
s4,5,6
s′
1,2,3
s2,3
s4,5
s′
4,5,6
1
2
1
2
1
2
1
2
1
2
1
2
1
2
3
4
5
6
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
1
1
1
1
1
Figure 10.2: Markov chain for simulating a die by a fair coin.
The computation starts in the initial state s0, i.e., we have ιinit(s0) = 1 and ιinit(s) = 0 for
all states s ̸= s0. The states 1, 2, 3, 4, 5, and 6 at the bottom stand for the possible die
outcomes. Each inner node stands for tossing a fair coin. If the outcome is heads, the left
branch determines the next state; if the outcome is tails, the right branch determines the
next state.
If the coin-tossing experiment in state s0 yields heads, the system moves to state s1,2,3.
Tossing the coin again leads with equal probability to either state s2,3 (from which the
die-outcomes 2 or 3 are possible with equal probability) or to state s′
1,2,3. From the latter
state, a coin ﬂipping yields with probability 1
2 the outcome 1, or with probability 1
2 a
return to state s1,2,3. The behavior for outcome tails in the initial state is symmetric. We
will establish later that, in fact, this Markov chain indeed adequately models a die, i.e.,
the outcomes are equally likely.
Example 10.4.
The Craps Gambling Game
The game craps is based on betting on the outcome of the roll of two dice. The outcome
of the ﬁrst roll—the “come-out” roll—determines whether there is a need for any further
rolls. On outcome 7 or 11, the game is over and the player wins. The outcomes 2, 3, or 12,
however, are “craps”; the player loses. On any other outcome, the dice are rolled again,
but the outcome of the come-out roll is remembered (the “point”). If the next roll yields

Markov Chains
751
7 or the point, the game is over. On 7, the player loses, on point the player wins. In any
other case, the dice are rolled until eventually either 7 or the point is obtained. Figure 10.3
depicts the Markov chain that describes the behavior of the craps game. State start is
the unique initial state. We have P(start, won) = 2
9 as there are eight combinations of the
come-out roll that are successful: (1,6), (2,5), (3,4), (5,6) and all symmetric counterparts.
The other transition probabilities are determined in a similar way. The self-loops at the
states 4, 5, 6, 8, 9, and 10 model the rerolling of the dice. For T = { 4, 5, 6 }, we have
P(s0, T) = 1
3.
1
1
3
4
13
18
13
18
25
36
25
36
1
12
1
12
5
36
5
36
1
9
1
9
4
10
5
9
6
8
1
12
1
12
1
9
1
9
5
36
5
36
1
6
1
6
1
6
1
6
1
6
1
6
3
4
2
9
1
9
won
lost
start
Figure 10.3: Markov chain for the behavior of the craps game.
Example 10.5.
Zeroconf Protocol
The IPv4 zeroconf protocol is designed for a home local network of appliances (microwave
oven, laptop, VCR, DVD player, etc.) each of which is supplied with a network interface
to enable mutual communication. Such adhoc networks must be hot-pluggable and self-
conﬁguring. Among others, this means that when a new appliance (interface) is connected
to the network, it must be conﬁgured with a unique IP address automatically. The zeroconf
protocol solves this task in the following way. A host that needs to be conﬁgured randomly
selects an IP address, U say, out of the 65,024 available addresses and broadcasts a message
(called probe) saying “Who is using the address U?” If the probe is received by a host
that is already using the address U, it replies by a message indicating that U is in use.
After receiving this message the host to be conﬁgured will restart: it randomly selects a
new address, broadcasts a probe, etc.
Due to message loss or a busy host, a probe or a reply message may not arrive at some
(or all) other hosts. In order to increase the reliability of the protocol, a host is required

752
Probabilistic Systems
s0
s1
s2
s3
s4
start
p
p
p
1−p
1−p
1−p
1−p
q
ok
s8
s7
1
1−q
s5
s6
error
p
1
Figure 10.4: Markov chain of the IPv4 zeroconf protocol (for n=4 probes).
to send n probes, each followed by a listening period of r time units. Therefore, the host
can start using the selected IP address only after n probes have been sent and no reply
has been received during n·r time units. Note that after running the protocol a host may
still end up using an IP address already in use by another host, e.g., because all probes
were lost. This situation, called address collision, is highly undesirable since it may force
a host to kill active TCP/IP connections.
The protocol behavior of a single host is modeled by a Markov chain consisting of n+5
states (see Figure 10.4 for n = 4) where n is the maximal number of probes needed (as
above). The initial state is s0 (labeled start). In state sn+4 (labeled ok) the host ﬁnally
ends up with an unused IP address; in state sn+2 (labeled error) it ends up with an address
that is already in use, i.e., an address collision. State si (0 < i ⩽n) is reached after issuing
the ith probe. In state s0 the host randomly chooses an IP address. With probability
q = m/65024, where m is the number of hosts in the network when connecting the host
to the network, this address is already in use. With probability 1−q the host chooses an
unused address and ends up in state sn+3. Then it issues n−1 probes and waits n·r time
units before using this address. (The sending of these probes and the waiting time are
abstracted from in the MC.) If the chosen IP address is already in use, state s1 is reached.
Now two situations are possible. With probability p, no reply is received during r time
units (as either the probe or its reply has been lost), and a next probe is sent, resulting
in state s2. If, however, a reply has arrived in time, the host returns to the initial state
and restarts the protocol. The behavior in state si (2 ⩽i < n) is similar. If in state sn,
however, no reply has received within r time units after sending the nth probe, an address
collision occurs.
We adopt the notions of direct successor and direct predecessor from transition systems.
Let Paths(M) denote the set of paths in M, and Pathsﬁn(M) denote the set of ﬁnite

Markov Chains
753
path fragments s0 s1 . . . sn where n ⩾0 and P(si, si+1) > 0 for 0 ⩽i < n. Paths(s)
denotes the set of all paths in M that start in state s. Similarly, Pathsﬁn(s) denotes the
set of all path fragments s0 s1 . . . sn such that s0 = s. The set of direct successors and
direct predecessors are deﬁned as follows. Let Post(s) denote the set of successors of s,
i.e., Post(s) = { s′ ∈S | P(s, s′) > 0 }. Similarly, Pre(s) = { s′ ∈S | P(s′, s) > 0 }.
Post∗(s) denotes the set of all states that are reachable from s via a ﬁnite path fragment
and Pre∗(s) = { s′ ∈S | s ∈Post∗(s′) }. For B ⊆S, let
Post∗(B) = 
s∈B
Post∗(s) and Pre∗(B) = 
s∈B
Pre∗(s).
Notation 10.6.
Absorbing State
State s of MC M is called absorbing if Post∗(s) = { s }. Since P is a stochastic matrix, i.e.,
each row sum equals 1, s is an absorbing state if and only if P(s, s) = 1, and P(s, t) = 0
for all states t ̸= s.
Remark 10.7.
Discrete-Time Markov Chains
Markov chains as in Deﬁnition 10.1 are often called discrete-time Markov chains. This has
mainly historical reasons. In many cases, Markov chains are used as a time-abstract model,
like transition systems provide a time-abstract operational model for reactive systems. In
fact, as for transition systems, a timed interpretation of Markov chains is only adequate
when the underlying time domain is discrete and each transition is assumed to take a
single time unit.
The underlying graph of a Markov chain forms the basis for reasoning about quali-
tative properties, such as LTL or CTL formulae.
To that end, deﬁne for MC M =
(S, P, ιinit, AP, L) the transition system TS(M) = (S, { τ }, →, I, AP, L) where I = { s ∈
S | ιinit(s) > 0 } and s
τ
−→t iﬀP(s, t) > 0. LTL or CTL formulae abstract away from the
probabilities; e.g., the CTL formula ∃♦a may hold even if it is very unlikely that a state
where a holds will eventually be visited. For instance, for the communication protocol
of Example 10.2 (page 749), the event to reach state delivered within the next 100 steps,
formalized in LTL by ϕ = "
0⩽i⩽100 ⃝idelivered, does not hold for the starting state,
but gives no quantitative information about the fraction of paths for which ϕ is violated.
In fact, the chance that ϕ does not hold is extremely small (namely 10−50), and hence,
might be classiﬁed as negligible. It even holds that
start |= ∃□¬delivered,
although it seems to be impossible that a message never will be delivered. In fact, the
event □¬delivered holds with zero probability, as we will see later.

754
Probabilistic Systems
The goal is now to specify and check quantitative properties. Such properties may, e.g.,
assert that the probability of reaching a certain bad state is suﬃciently small, or that
the probability of achieving a certain desired system behavior is above a given threshold.
Qualitative properties arise as a special case of quantitative properties where the probabil-
ity bounds are the trivial bounds zero or 1. That is, typical qualitative properties require
that the probability of reaching a bad state is zero, or dually, that a certain desired system
behavior appears with probability 1.
Although Markov chains yield a rather intuitive probabilistic model, reasoning about
quantitative or qualitative properties requires a formalization of the probabilities for sets
of paths. This formalization is based on measure theory; in particular probability spaces
and σ-algebras. Readers familiar with the main concepts of this ﬁeld may skip the following
short summary of the main concepts. Further details can be found, e.g., in [21, 150, 319].
Excursus on Probability Spaces
A σ-algebra is a pair (Outc, E) where Outc is a
nonempty set and E ⊆2Outc a set consisting of subsets of Outc that contains the empty
set and is closed under complementation and countable unions, i.e.,
• ∅∈E,
• if E ∈E, then E = Outc \ E ∈E,
• if E1, E2, . . . ∈E, then 
n⩾1
En ∈E.
Note that the conditions of σ-algebras yield that Outc ∈E, as Outc = ∅, and that E is
closed under countable intersections, as
1
n⩾0
En =

n⩾0
En.
Occasionally, the set Outc is supposed to be ﬁxed and E is called a σ-algebra. The elements
of Outc are often called outcomes, while the elements of E are called events.
For any set Outc, the powerset E = 2Outc yields a σ-algebra over Outc. In this σ-algebra,
all subsets of Outc are events. The other extreme is the σ-algebra consisting of the empty
set and Outc, i.e., E = { ∅, Outc }. Here, no nonempty proper subset of Outc is an event.
A probability measure on (Outc, E) is a function Pr : E →[0, 1] such that Pr(Outc) = 1,
and if (En)n⩾1 is a family of pairwise disjoint events En ∈E, then:
Pr(

n⩾1
En ) =

n⩾1
Pr(En).

Markov Chains
755
A probability space is a σ-algebra equipped with a probability measure, i.e., it is a triple
(Outc, E, Pr) where (Outc, E) is a σ-algebra and Pr a probability measure on (Outc, E).
The value Pr(E) is called the probability measure of E, or simply the probability of E.
In the context of probability measures, the events (i.e., the elements of E) are often said
to be measurable. That is, measurability of a set E ⊆Outc means that E ∈E, and hence,
it makes sense to speak about the probability measure of E.
Example 10.8.
Tossing a Fair Coin
Consider the experiment in which a fair coin is tossed once. The possible outcomes are
heads and tails, i.e., Outc = { heads, tails }. For the events to be considered let us assume
the singleton events { heads } and { tails } suﬃce. The smallest σ-algebra that contains
these events is the powerset of { heads, tails }. So, let E = 2Outc. Since the coin is assumed
to be fair, the probability measure Pr is given by
Pr(∅) = 0,
Pr({ heads }) = Pr({ tails }) = 1
2,
Pr({ heads, tails }) = 1.
In general, whenever Outc is countable, then a probability measure on the powerset of
Outc can be obtained by ﬁxing a function μ : Outc →[0, 1] such that

e∈Outc
μ(e) = 1.
Such functions μ are called distributions on Outc. Any distribution μ induces a probability
measure on the σ-algebra E = 2Outc in the following way. For subset E of Outc, Prμ(E)
is deﬁned by 
e∈E μ(e). In fact, it is easy to check that μ satisﬁes the conditions of a
probability measure. In the sequel, Prμ(E) is often abbreviated by μ(E) and Distr(Outc)
is used to denote the set of distributions on Outc.
Let us summarize some fundamental properties of probability measures. Since E ∪E =
Outc and E and E are disjoint, the above conditions imply
Pr(E) = 1 −Pr(E).
In particular, Pr(∅) = Pr(Outc) = 1 −Pr(Outc) = 1 −1 = 0. Probability measures
are monotonic, i.e., for events E and E′ such that E ⊆E′ it holds that
Pr(E′) = Pr(E) + Pr(E′ \ E) ⩾Pr(E).
Furthermore, if (En)n⩾1 is a family of events, possibly not pairwise disjoint, then: 
n⩾1 En =

n⩾1 E′
n where E′
1 = E1 and E′
n = En \ ( E1 ∪. . . ∪En−1 ) for n ⩾2. Since E′
n ∩E′
m = ∅

756
Probabilistic Systems
if n ̸= m we get
Pr(

n⩾1
En) = Pr(

n⩾1
E′
n) =

n⩾1
Pr(E′
n).
If E1 ⊆E2 ⊆E3 ⊆. . . and E′
n is as above, then we have E′
n = En \ En−1 for n ⩾2, which
yields
Pr(

n⩾1
En)
=
= Pr(E′
1)
  
Pr(E1) +
∞

n=2
= Pr(E′
n)



(Pr(En) −Pr(En−1))
=
lim
N→∞
&
Pr(E1) +
N
n=2
(Pr(En) −Pr(En−1))
'
=
lim
N→∞Pr(EN).
Note that this limit exists and agrees with the supremum of { Pr(E1), Pr(E2), . . . }, as
the monotonicity of Pr yields Pr(E1) ⩽Pr(E2) ⩽. . . ⩽1. For countable intersections
analogous results apply. That is, if E1 ⊇E2 ⊇. . ., then
Pr(
1
n⩾1
En) =
lim
n→∞Pr(En) = inf
n⩾1 Pr(En).
This follows from the fact that the sequence ( En )n⩾1 of the complements En = Outc\En
is decreasing. Thus, the above yields
Pr( +
n⩾1
En )
=
Pr( 
n⩾1
En )
=
1 −Pr( 
n⩾1
En)
=
1 −lim
n→∞Pr(En)
=
1 −lim
n→∞(1 −Pr(En))
=
lim
n→∞Pr(En).
Any event E with Pr(E) = 1 is said to hold almost surely. Note that if E holds almost
surely, then Pr(D) = Pr(E ∩D) for all events D as Pr(D \ E) = 0 since D \ E is a subset
of E and Pr(E) = 1 −Pr(E) = 1 −1 = 0. This yields
Pr(D) = Pr(E ∩D) + Pr(D \ E)



=0
= Pr(E ∩D).

Markov Chains
757
In particular, the event E1 ∩E2 of events E1 and E2 that hold almost surely, holds almost
surely. As can be shown by induction, this carries over to any event that can be written as
a ﬁnite intersection +
1⩽i⩽n Ei of events E1, . . . , En that hold almost surely. By taking the
limit of such (ﬁnite) intersections, we obtain that +
i⩾1 Ei holds almost surely if Pr(Ei) = 1
for all i ⩾0.
To deﬁne an appropriate σ-algebra for a given Markov chain M (see below), we will use
the fact that for each set Outc and each subset Π of 2Outc there exists a smallest σ-algebra
that contains Π. This is due to the observations that
• the powerset 2Outc of Outc is a σ-algebra, and
• the intersection of σ-algebras is a σ-algebra.
Thus, the intersection EΠ
=
+
EE where E ranges over all σ-algebras on Outc that
contain Π is a σ-algebra and is contained in any σ-algebra E such that Π ⊆E. EΠ is called
the σ-algebra generated by Π, and Π the basis for EΠ.
Probability Measure of a Markov Chain
In order to be able to associate probabil-
ities to events in Markov chains, the intuitive notion of probabilities in the Markov chain
M is formalized by associating a probability space with M. The inﬁnite paths of M play
the role of the outcomes. That is, OutcM = Paths(M). Recall that Paths(M) denotes
the set of all inﬁnite sequences s0 s1 s2 . . . ∈Sω such that P(si, si+1) > 0 for all i ⩾0.
(The requirement that ιinit(s0) > 0 could be added, but is irrelevant here.) The σ-algebra
associated with M is generated by the cylinder sets spanned by the ﬁnite path fragments
in M.
Deﬁnition 10.9.
Cylinder Set
The cylinder set of π = s0 . . . sn ∈Pathsﬁn(M) is deﬁned as
Cyl(π) = { π ∈Paths(M) | π ∈pref(π) }.
The cylinder set spanned by the ﬁnite path π thus consists of all inﬁnite paths that start
with π. The cylinder sets serve as basis events of the σ-algebra EM associated with M.

758
Probabilistic Systems
Deﬁnition 10.10.
σ-Algebra of a Markov Chain
The σ-algebra EM associated with MC M is the smallest σ-algebra that contains all
cylinder sets Cyl(π) where π ranges over all ﬁnite path fragments in M.
From classical concepts of probability theory (see e.g. [21, 150]), it follows that there exists
a unique probability measure PrM (or, brieﬂy, Pr) on the σ-algebra EM associated with
M where the probabilities for the cylinder sets (i.e., the events) are given by
PrM(Cyl(s0 . . . sn)) = ιinit(s0) · P(s0 . . . sn)
where
P(s0 s1 . . . sn) =

0⩽i<n
P(si, si+1).
For path fragments of length zero, let P(s0) = 1.
For paths starting in a certain (possibly noninitial) state s, the same construction is applied
to the MC Ms that results from M by declaring s as the unique initial state. Formally,
for M = (S, P, ιinit, AP, L) and s ∈S, the MC Ms is deﬁned by Ms = (S, P, ι1
s, AP, L)
where
ι1
s(t) =
	 1
if s = t
0
otherwise.
We often write PrM
s
for PrMs. If M is clear from the context, then M is omitted and we
simply write Prs.
Example 10.11.
Cylinder Sets
Consider the Markov chain for the craps game, see Figure 10.3.
The state sequence
π = start 6 6 6 ∈Pathsﬁn(s0). Its probability is given by
ιs(start) · P(start, 6) · P(6, 6) · P(6, 6) =
5
36·
 25
36
2 .
The cylinder set of π is given by
{ start 6n wonω | n > 2 } ∪{ start 6n lostω | n > 2 } ∪{ start 6ω }.
Notation 10.12.
LTL-Style Notations for Events
In the remainder of this chapter, LTL-like notations are frequently used to describe events
in Markov chains. For example, for set B ⊆S of states, ♦B denotes the event to reach

Markov Chains
759
(some state in) B eventually, and □♦B describes the event that B should be visited
inﬁnitely often. For singleton sets, the set brackets are typically omitted; e.g., □♦t means
that { t } is visited inﬁnitely often. In line with the notations for LTL, we often write
π |= ϕ rather than π ∈ϕ if ϕ is an LTL-style notation for an event (i.e., an LTL formula
with sets of states as atomic propositions) and π a path in M. The probability for ϕ to
hold in state s is denoted by PrM(s |= ϕ), i.e.,
PrM(s |= ϕ) = PrM
s { π ∈Paths(s) | π |= ϕ }.
If M is clear from the context the superscript M is omitted.
10.1.1
Reachability Probabilities
One of the elementary questions for the quantitative analysis of systems modeled by
Markov chains is to compute the probability of reaching a certain set B of states. The set
B may represent a set of certain bad states which should be visited only with some small
probability, or dually, a set of good states which should rather be visited frequently.
In the sequel, let M = (S, P, ιinit, AP, L) be a Markov chain and B ⊆S a set of states.
The event of interest is denoted ♦B. In order to be able to reason about the probability
of this event, we need to characterize the event ♦B as a measurable set of paths.
In
fact, this is not diﬃcult because the event ♦B agrees with the union of all basic cylinders
Cyl(s0 . . . sn) where s0 . . . sn is an initial path fragment in M such that s0, . . . , sn−1 /∈B
and sn ∈B. The set of all such paths is given by Pathsﬁn(M) ∩(S \ B)∗B. As the
set of ﬁnite path fragments is countable, this set is measurable, i.e., it is an element of
the σ-algebra EM on M. Moreover, since these cylinder sets are pairwise disjoint, the
probability of eventually reaching B is given by
PrM(♦B)
=

s0...sn∈Pathsﬁn(M) ∩(S\B)∗B
PrM(Cyl(s0 . . . sn))
=

s0...sn∈Pathsﬁn(M) ∩(S\B)∗B
ιinit(s0) · P(s0 . . . sn).
Example 10.13.
Computing Reachability Probabilities by Inﬁnite Series
Consider the Markov chain in Figure 10.1 on page 749, and suppose our interest is to
compute the probability of reaching the state delivered. For this event, the ﬁnite initial
path fragments s0 . . . sn with si ̸= delivered for 0 ⩽i < n and sn = delivered are of

760
Probabilistic Systems
interest. These path fragments are of the form
πn = start try (lost try)n delivered
where n is an arbitrary natural number. The probability of the cylinder set spanned by
*
πn is
 1
10
n · 9
10. Hence,
PrM(♦delivered) =
∞

n=0
& 1
10
'n
· 9
10 =
9
10
1 −1
10
=
9
10
9
10
= 1.
The event ♦delivered thus holds almost surely. This is, in fact, rather intuitive since in
the absence of a bound on the number of (re)transmissions it is to be expected that any
message is delivered eventually. Let us now impose an upper bound, say three, for the
number of transmission of a message. In order to determine the probability of the event
to deliver the message within three trials, we sum the probabilities for the cylinder sets of
the path fragments π0, π1, and π2 which yields
9
10 +
1
10 · 9
10 +
1
10 · 1
10 · 9
10 = 0.999.
This example shows how the probability of reaching a certain set of states can be calculated
by means of inﬁnite sums. In general, this technique is rather involved and cumbersome.
For instance, the computation of the event ♦won in the craps game (see Figure 10.3, page
751) is much more involved. Let us now explain how probabilities of reaching a certain
set B of states in a ﬁnite MC can be computed in a more eﬃcient way, i.e., without
considering inﬁnite sums.
Let variable xs denote the probability of reaching B from s, for arbitrary s ∈S. The goal
is to compute xs = Pr(s |= ♦B) for all states s. Clearly, if B is not reachable from s in
the underlying directed graph of M, then xs = 0. Also the converse holds, i.e., if xs > 0,
then B is reachable from s. Moreover, xs = 1 if s ∈B. For the states s ∈S \ B for which
B is reachable, it holds that
xs =

t∈S\B
P(s, t) · xt +

u∈B
P(s, u).
This equation states that either B is reached within one step, i.e., by a ﬁnite path fragment
s u with u ∈B (second summand), or ﬁrst a state t ∈S \ B is reached from which B is
reached—this corresponds to the path fragments s t . . . u of length ⩾2 where all states
(except the last one) do not belong to B (ﬁrst summand). Let ˜S = Pre∗(B) \ B denote

Markov Chains
761
the set of states s ∈S \ B such that there is a path fragment s0 s1 . . . sn (n > 0) with
s0 = s and sn ∈B. For the vector x = (xs)s∈˜S, we have
x = Ax + b,
where the matrix A contains the transition probabilities for the states in ˜S, i.e., A =
( P(s, t) )s,t∈˜S, and the vector b = (bs)s∈˜S contains the probabilities of reaching B from
˜S within one step, i.e., bs = P(s, B) = 
u∈B P(s, u). The above equation system can
be rewritten into a (heterogeneous) linear equation system
(I −A)·x = b
where I is the identity matrix of cardinality | ˜S| × | ˜S|.
Example 10.14.
Simple Communication Protocol
Consider the simple communication protocol in Figure 10.1 on page 749 and the event ♦B
for B = { delivered }. Then xs > 0 for all states s, since delivered is reachable from all
states. In this case, ˜S = { start, try, lost } and we obtain the equations
xstart
=
xtry
xtry
=
1
10 · xlost +
9
10
xlost
=
xtry.
These equations can be rewritten as
⎛
⎝
1
−1
0
0
1
−1
10
0
−1
1
⎞
⎠· x =
⎛
⎝
0
9
10
0
⎞
⎠
which yields the (unique) solution xstart = xtry = xlost = 1. Thus, the event of eventually
reaching the state delivered is almost sure for any state.
The above technique yields the following two-phase algorithm to compute reachability
probabilities in ﬁnite Markov chains: ﬁrst, perform a graph analysis to compute the set
˜S of all states that can reach B (e.g., by a backward DFS- or BFS-based search from
B), then generate the matrix A and the vector b, and solve the linear equation system
(I −A)·x = b. However, (I −A)·x = b might have more than one solution. This is
the case if I −A is singular, i.e., does not have an inverse. This problem is addressed
below by characterizing the desired probability vector as the least solution in [0, 1] ˜S. This
characterization enables computing the probability vector by an iterative approximation
method. (To apply direct methods, like Gaussian elimination, several rows and columns
of the matrix I −A have to be removed such that the remaining linear equation system

762
Probabilistic Systems
has a unique solution.) In fact, we present a characterization for a slightly more general
problem, viz. constrained reachability (i.e., until properties). The obtained characterization
also partly applies to inﬁnite Markov chains.
Let M = (S, P, ιinit, AP, L) be a (possibly inﬁnite) MC and B, C ⊆S. Consider the event
of reaching B via a ﬁnite path fragment which ends in a state s ∈B, and visits only
states in C prior to reaching s. Using LTL-like notations, this event is denoted by C U B.
The event ♦B considered above agrees with S U B. For n ⩾0, the event C U ⩽nB has the
same meaning as C U B, except that it is required to reach B (via states in C) within n
steps. Formally, C U ⩽nB is the union of the basic cylinders spanned by path fragments
s0 s1 . . . sk such that k ⩽n and si ∈C for all 0 ⩽i < k and sk ∈B.
Let S=0, S=1, S? a partition of S such that
• B ⊆S=1 ⊆{ s ∈S | Pr(s |= C U B) = 1 },
• S \ (C ∪B) ⊆S=0 ⊆{ s ∈S | Pr(s |= C U B) = 0 }, and
• S? = S \ (S=1 ∪S=0).
For all states in the set S=1, the event C U B almost surely holds. All states in S? belong
to C \ B. Let the matrix A be a quadratic matrix with rows and columns for the states
in S?. This matrix is obtained from the transition probability matrix P by omitting the
rows and columns for the states s ∈S=0 ∪S=1 from P. That is
A = ( P(s, t) )s,t∈S?
Similarly, let vector b be deﬁned as ( bs )s∈S? where bs = P(s, S=1).
We now provide a least ﬁxed point characterization for the probability vector (Pr(s |=
C U B) )s∈S?. Note that the set [0, 1]S? consists of all vectors y = (ys)s∈S? with ys ∈[0, 1]
for all s ∈S?. To obtain the least ﬁxed point characterization, the set [0, 1]S? is equipped
with the partial order ⩽given by y ⩽y′ if and only if ys ⩽y′
s for all s ∈S?, where
y = (ys)s∈S? and y′ = (y′
s)s∈S?.
Theorem 10.15.
Least Fixed Point Characterization
The vector x = ( Pr(s |= C U B) )s∈S? is the least ﬁxed point of the operator Υ : [0, 1]S? →
[0, 1]S? which is given by
Υ(y) = A · y + b.
Furthermore, if x(0) = 0 is the vector consisting of zeros only, and x(n+1) = Υ(x(n)) for
n ⩾0, then

Markov Chains
763
• x(n) = (x(n)
s )s∈S? where x(n)
s
= Pr(s |= C U ⩽nS=1) for each state s ∈S?,
• x(0) ⩽x(1) ⩽x(2) ⩽. . . ⩽x, and
• x = lim
n→∞x(n).
Before proving Theorem 10.15, let us ﬁrst comment on the well-deﬁnedness of Υ as a
function from [0, 1]S? to [0, 1]S?. For y = (ys)s∈S?, the vector Υ(y) = (y′
s)s∈S? has the
entries
y′
s =

t∈S?
P(s, t) · yt + P(s, S=1).
Since 0 ⩽yt ⩽1 for all t ∈S?, P(s, s′) ⩾0 and 
s′∈S P(s, s′) = 1, this implies 0 ⩽y′
s ⩽1.
Therefore, Υ(y) ∈[0, 1]S?.
Proof: Let xs = Pr(s |= C U B) for each state s ∈S. Then, it follows from the deﬁnitions
of S=0 and S=1 that x = (xs)s∈S?, xs = 0 for s ∈S=0, and xs = 1 for s ∈S=1.
1. Let us ﬁrst show that x agrees with the limit of the vectors x(n) = (x(n)
s )s∈S?. By
induction on n, one can show that x(n)
s
= Pr( s |= C U ⩽nS=1 ). Since C U S=1 is the
countable union of the events C U ⩽nS=1, we obtain
lim
n→∞x(n)
s
= Pr(s |= C U S=1) = xs.
2. The ﬁxed point property x = Υ(x) is a consequence of the fact that xs = Pr(s |=
C U B) = 0 if s ∈S=0 and xs = Pr(s |= C U B) = 1 if s ∈S=1. For s ∈S? we derive
that
xs
=

t∈S
P(s, t) · xt
=

t∈S=0
P(s, t) · xt

=0
+

t∈S?
P(s, t) · xt +

t∈S=1
P(s, t) · xt

=1
=

t∈S?
P(s, t) · xt +

t∈S=1
P(s, t)



=bs
is the component for state s in the vector Υ(x).
3. It remains to show that x ⩽y for each ﬁxed point y of Υ. This follows from the
fact that x(n) ⩽y for all n, which can be shown by induction on n.
But then
x = lim
n→∞x(n) ⩽y.

764
Probabilistic Systems
This completes the proof.
Remark 10.16.
Expansion Law
The statement of the above theorem with S=1 = B and S=0 = S\(C∪B) can be considered
as the probabilistic counterpart to the characterization of the CTL formula ∃(C U B) as
the least solution of the expansion law:
∃(C U B) ≡B ∨(C ∧∃⃝∃(C U B)).
To make this clear, let us rewrite this expansion law in the following way. The set X =
Sat(∃(C U B)) is the least set such that
B ∪{ s ∈C \ B | Post(s) ∩X ̸= ∅} ⊆X.
In Theorem 10.15, this set-based least ﬁxed point characterization is phrased for the
quantitative setting where instead of truth values for “s ∈X” we deal with values xs
in [0, 1]. If s ∈B, then xs = 1. This corresponds to the statement that s ∈B implies
s ∈X. If s ∈C \B, then xs = 
t∈C\B P(s, t)·xt +
t∈B P(s, t). This corresponds to the
statement that s ∈C \ B and Post(s) ∩X ̸= ∅implies s ∈X. Finally, if s ∈S \ (C ∪B),
then xs = 0. This corresponds to the statement that s /∈X if s /∈C ∪B.
The last part of Theorem 10.15 in fact provides a recipe for computing an approximation
of the desired probability vector x. It suggests to use the following iterative approach:
x(0) = 0
and
x(n+1) = Ax(n) + b
for n ⩾0.
This method, often called power method, provides a simple iterative algorithm which com-
putes the vectors x(0), x(1), x(2), . . . by matrix-vector multiplication and vector addition.
It aborts as soon as maxs∈S? |x(n+1)
s
−x(n)
s | < ε for some small user-deﬁned tolerance ε.
Although the convergence of the power method is guaranteed, it is often less eﬃcient than
other iterative methods for solving linear equation systems of large dimensions, such as
the Jacobi or Gauss-Seidel method. Explanations of such numerical methods for linear
equation systems go beyond the scope of this monograph and can be found in textbooks
such as [196, 248, 344].
Remark 10.17.
Choosing S=0 and S=1
The constraints on S=0 and S=1
B ⊆S=1 ⊆{ s ∈S | Pr(s |= C U B) = 1 }
and
S \ (C ∪B) ⊆S=0 ⊆{ s ∈S | Pr(s |= C U B) = 0 },

Markov Chains
765
do not uniquely characterize S=0 and S=1. For instance, S=0 = S \ (C ∪B) and S=1 = B
would suﬃce. For eﬃciency reasons, it is advantageous to deal with the largest possible
sets. The larger the sets S=0 and S=1, the smaller is their complement S?, and the smaller
the linear equation system that needs to be solved—as there is a variable for each s ∈S?.
A reasonable choice is
S=0
=
{ s ∈S | Pr(s |= C U B) = 0 }
and
S=1
=
{ s ∈S | Pr(s |= C U B) = 1 }.
These sets can be computed by simple graph algorithms that have a linear-time complexity
in the size of the MC M, i.e., the number of states plus the number of nonzero entries in
the transition probability matrix. The computation of S=0 is straightforward since
Pr(s |= C U B) = 0 if and only if s ̸|= ∃(C U B)
where ∃(C U B) is viewed as a CTL formula. Thus, S=0 can be calculated by means of a
backward search starting from B in time O(size(M)). The computation of S=1 can also
be realized by means of simple graph traversal techniques, as will be explained in the next
section; see page 775ﬀ.
The results we have established so far permit computing approximations of the probability
Pr(s |= C U B) by iterative methods. In order to apply direct methods for a linear equation
system, like Gaussian elimination, the uniqueness of the linear equation system to be solved
is required. Without any additional assumptions on the choice of S=0, the uniqueness can,
however, not be guaranteed. This even applies to ﬁnite Markov chains as shown by the
following example.
Remark 10.18.
Several Fixed Points
Under the assumption that S=0 is a proper subset of { s ∈S | Pr(s |= C U B) = 0 }, the
operator Υ may have more than one ﬁxed point. Consider, e.g., the Markov chain:
s
t
1
1
Consider the event ♦s. A possible choice is S=0 = ∅and S=1 = { s }, i.e., S? = { t }.
Matrix A is the identity matrix of cardinality one and b is the vector with the single
entry 0 for state t. Thus, the equation system x = Ax + b represents the trivial equation
xt = xt and the operator Υ : [0, 1] →[0, 1] is given by Υ(yt) = yt. Clearly, Υ has inﬁnitely
many ﬁxed points, namely all values yt ∈[0, 1]. However, the probabilities for the event
♦s are given by the least ﬁxed point xt = 0 of Υ.

766
Probabilistic Systems
Unique ﬁxed points are guaranteed if M is ﬁnite and if S=0 covers all states s with
s ̸|= ∃(C U B). As mentioned before, these are exactly the states s for which Pr(s |=
C U B) = 0. This fact is captured by the following theorem:
Theorem 10.19.
Unique Solution
Let M be a ﬁnite Markov chain with state space S, and B, C ⊆S,
S=0 = Sat(¬∃(C U B)) and B ⊆S=1 ⊆{ s ∈S | Pr(s |= C U B) = 1 }
and S? = S \(S=0 ∪S=1). Then, the vector ( Pr(s |= C U B) )s∈S? is the unique solution of
the equation system x = Ax + b where A = ( P(s, t) )s,t∈S?, and b = ( P(s, S=1) )s∈S?.
Proof: Suppose there are two solutions of the equation system, say x = Ax + b and
y = Ay + b. Thus x −y = A(x −y). Assume Ax = x implies x = 0, where 0 is a vector
just consisting of zeros. Then x −y = A(x −y) yields x −y = 0, and therefore x = y.
We now prove that indeed Ax = x implies x = 0. This is proven by contraposition.
Assume x = (xs)s∈S? is a vector such that Ax = x and x ̸= 0. Since M is ﬁnite, the
maximum of the values |xs| is well-deﬁned. Let x be this maximum, and T the set of
states for which xs = x, i.e.:
x = max{ |xs| | s ∈S? }
and
T = { s ∈S? | |xs| = x }.
As x ̸= 0, it follows that x > 0.
Furthermore, T ̸= ∅.
Since the values P(s, t) are
non-negative and 
t∈S? P(s, t) ⩽1, we obtain for each s ∈T:
x = |xs| ⩽

t∈S?
P(s, t) · |xt|

⩽x
⩽x ·

t∈S?
P(s, t) ⩽x.
This yields
x = |xs| =

t∈S?
P(s, t) · |xt| = x ·

t∈S?
P(s, t).
As x > 0, this implies 
t∈S?
P(s, t) = 1 and |xt| = x for all states in Post(s) ∩S?. But
then for any s ∈T:
Post(s) = { t ∈S | P(s, t) > 0 } ⊆T.
We conclude that Post∗(s) ⊆T for all s ∈T. In particular, Post∗(s) ⊆S? and Post∗(s) ∩
B = ∅(recall that B ⊆S=1 and therefore B ∩S? = ∅). Thus, none of the states s ∈T
can reach B. Therefore,
T ⊆{ s ∈S | s ̸|= ∃(C U B) } ⊆S=0.

Markov Chains
767
But, as T ⊆S? and S=0 ∩S? = ∅, T must be empty. Contradiction.
Remark 10.20.
Nonsingularity of Matrix I −A
A short remark for readers familiar with matrix norms. By roughly the same arguments
as in the proof of Theorem 10.15 (page 762) it follows that the matrix A does not have
an Eigenvalue λ with |λ| ⩾1. Then, the spectral norm of A, deﬁned as
max{ |λ| | λ is a (complex) Eigenvalue of A },
is strictly less than 1. Thus, the inﬁnite series:
I + A + A2 + A3 + . . . =

n⩾0
An
converges and its limit is the inverse of I −A where I is the identity matrix (of the same
cardinality as A). Note that
(I −A) · (I + A + A2 + A3 + . . .)
=
(I + A + A2 + A3 + . . .) −(A + A2 + A3 + A4 + . . .)
=
I.
This yields another argument why x = (I −A)−1b is a unique solution of Ax + b = x.
As a result, Theorem 10.15 yields an iterative method for computing step-bounded con-
strained reachability probabilities.
The probabilities of the events C U ⩽nB can be com-
puted by the following iterative scheme: x(0) = 0 and x(i+1) = Ax(i) + b for 0 ⩽i < n.
The matrix A and the vector b are deﬁned based on S=0 = S \ (C ∪B), S=1 = B and
S? = C \ B. That is:
A = ( P(s, t) )s,t∈C\B
and
b = ( P(s, B) )s∈C\B.
For s ∈C \ B, entry x(n)(s) equals Pr(s |= C U ⩽nB).
Example 10.21.
Constrained Reachability in the Craps Game
Consider the Markov chain modeling the craps game, see Figure 10.3 (page 751). The event
of interest is C U⩽n B where B = { won }, C = { start, 4, 5, 6 }. The bounded constrained
reachability probability Pr(start |= C U⩽n B) is the likelihood of winning the game by
either throwing 7 or 11 (the player wins directly), or one or more times only 4, 5, or 6. It
follows that
S=0 = { 8, 9, 10, lost }
S=1 = { won }
S? = { start, 4, 5, 6 }.

768
Probabilistic Systems
Using the state order start < 4 < 5 < 6, the matrix A and the vector b are given by
A =
1
36
⎛
⎜
⎜
⎝
0
3
4
5
0
27
0
0
0
0
26
0
0
0
0
25
⎞
⎟
⎟
⎠
b =
1
36
⎛
⎜
⎜
⎝
8
3
4
5
⎞
⎟
⎟
⎠.
The least ﬁxed point characterization suggests the following iterative scheme:
x(0) = 0
and
x(i+1) = Ax(i) + b for 0 ⩽i < n.
where xi records for any states in S? the probability of the event C U⩽nB. Applying this
iterative scheme to the example yields x(1) = b and
x(2) = 1
36
⎛
⎜
⎜
⎝
0
3
4
5
0
27
0
0
0
0
26
0
0
0
0
25
⎞
⎟
⎟
⎠· 1
36
⎛
⎜
⎜
⎝
8
3
4
5
⎞
⎟
⎟
⎠+ 1
36
⎛
⎜
⎜
⎝
8
3
4
5
⎞
⎟
⎟
⎠=
& 1
36
'2
⎛
⎜
⎜
⎝
338
189
248
305
⎞
⎟
⎟
⎠
.
For instance, we have Pr(start |= C U⩽2B) = 338
362 . In a similar way, one obtains x(3), x(4),
and so forth.
Remark 10.22.
Transient State Probabilities
The nth power of A, i.e., the matrix An, contains the state probabilities after exactly n
steps (i.e., transitions) inside S?. More precisely, matrix entry An(s, t) equals the sum of
the probabilities P(s0 s1 . . . sn) of all path fragments s0 s1 . . . sn with s0 = s, sn = t and
si ∈S? for 0 ⩽i ⩽n. That is:
An(s, t) = Pr(s |= S? U=n t).
If B = ∅and C = S, then S=1 = S=0 = ∅and S? = S, yielding A = P. The entry
Pn(s, t) (of the nth power of P) thus equals the probability of being in state t after n
steps given that the computation starts in state s, i.e., Pn(s, t) = Pr(s |= S U=n t). The
probability of M being in state t after exactly n transitions
ΘM
n (t) =

s∈S
Pn(s, t) · ιinit(s),
is called the transient state probability for state t.
The function ΘM
n is the transient state
distribution. When considering ΘM
n as the vector ( ΘM
n (t) )t∈S, the above equation can be
rewritten as
ΘM
n
= P · P · . . . · P



n times
· ιinit = Pn · ιinit,

Markov Chains
769
where the initial distribution is viewed as a column vector. Due to the numerical instability
of computing the nth power of a matrix, using, e.g., iterative squaring, it is recommended
to compute ΘM
n
by successive matrix-vector multiplication:
ΘM
0
= ιinit
and
ΘM
n+1 = P · ΘM
n
for n ⩾0.
Transient state probabilities are thus special instances of constrained reachability proba-
bilities. In fact, constrained reachability probabilities in MC M coincide with transient
state probabilities in a slightly modiﬁed Markov chain. Let us ﬁrst illustrate this by means
of simple, i.e., unconstrained, step-bounded reachability probabilities in M, say the event
♦⩽nB. The MC M is modiﬁed such that all states s ∈B are made absorbing. That is, all
outgoing transitions of s ∈B are replaced by a self-loop. This yields the MC MB. The
intuition of this transformation is that once a path reaches a state in B, its subsequent
states are of no importance to PrM(s |= ♦⩽nB). Formally, MB = (S, PB, L) with S and L
as for M, and PB is deﬁned by PB(s, t) = P(s, t) if s /∈B, PB(s, s) = 1, and PB(s, t) = 0
for s ∈B and s ̸= t. It then follows for any s ∈S:
PrM(s |= ♦⩽nB) = PrMB(s |= ♦=nB).
The probability of reaching a B-state within n steps in M is now given by:
PrM(♦⩽nB) =

t∈B
ΘMB
n
(t).
The reachability probability PrM(♦⩽nB) in the MC M thus agrees with the cumulative
transient state probability for the B-states in the MC MB.
Using similar arguments, one can show that the computation of step-bounded constrained
reachability probabilities PrM(C U ⩽nB) can be reduced to the problem of computing tran-
sient state probabilities in a slightly modiﬁed Markov chain. As for the simple reachability
probabilities, all states in B are made absorbing. In addition, all states in S \ (C ∪B)
are made absorbing.
This is justiﬁed by the fact that paths that visit some state in
S \ (C ∪B) contribute probability zero to PrM(s |= C U ⩽nB). We thus consider the
MC M′ = MB∪(S\(C∪B)) that results from M by making all states in B ∪(S \ (C ∪B))
absorbing. It then follows that for any state s ∈S:
PrM(s |= C U⩽n B) = PrM′(s |= ♦=nB).
The probability of reaching a B-state within n steps in M via C-states only is now given
by
PrM(C U⩽n B) =

t∈B
ΘM′
n (t).

770
Probabilistic Systems
Example 10.23.
Reachability by Transient Probabilities
Consider again the Markov chain modeling the craps game (see Figure 10.3, page 751).
Let C U⩽n B be the event of interest where B = { won }, C = { start, 4, 5, 6 }. According
to the described procedure just above, all states in B and all states that are neither in B
nor in C are made absorbing. This yields the MC depicted in Figure 10.5. The constrained
1
1
1
1
25
36
1
5
36
1
9
1
9
4
10
5
9
6
8
3
4
2
9
won
lost
start
13
18
1
6
1
9
1
12
1
9
1
12
1
6
1
6
5
36
1
9
1
12
Figure 10.5: Markov chain for the craps game for C U⩽nB.
reachability probabilities for C U⩽n B are obtained as follows. As before, let ιinit(start) = 1
and ιinit(s) = 0 for any other state. For n=0, we have
Pr(start |= C U⩽0B) = Θ0(won) = ιinit(won) = 0.
For n=1, one obtains
Pr(start |= C U⩽1B) = ιinit(start)·P(start, won) = 2
9.
For n=2, one obtains Pr(start |= C U⩽2B) = ιinit(start)·P2(start, won) which equals 338
362 .
For other n, the probabilities are obtained in a similar way.
10.1.2
Qualitative Properties
In the previous section, we have shown diﬀerent ways to compute reachability probabilities
in Markov chains. This section is focused on qualitative properties of Markov chains. Such
properties typically require certain events to happen with probability 1, or more generally,
to compute all states where a certain event holds almost surely.
Dually, the problem

Markov Chains
771
to check whether an event occurs with zero probability is a qualitative property. This
section will show that qualitative properties for events such as reachability, constrained
reachability, repeated reachability—can a certain set of states be visited repeatedly?—and
persistence—can only a certain set of states be visited from some moment on?—can all
be veriﬁed using graph analysis, i.e., by just considering the underlying digraph of the
Markov chain and ignoring the transition probabilities.
This is due to a fundamental
result for ﬁnite Markov chains stating that almost surely the computations will enter a
bottom strongly connected component (an SCC that once entered cannot be left anymore)
and visit each of its states inﬁnitely often. This result will be proven in detail. Finally, it
will be shown that this result does not apply to inﬁnite Markov chains.
The ﬁrst thing to be settled is that the events to be considered, such as repeated reacha-
bility and persistence, are measurable.
Remark 10.24.
Measurability of Repeated Reachability and Persistence
Let B ⊆S be a set of states in a Markov chain M. The set of all paths that visit B
inﬁnitely often is measurable. This holds in arbitrary (possibly inﬁnite) Markov chains
and follows from the fact that the event □♦B can be written as the countable intersection
of countable unions of cylinder sets:
□♦B =
1
n⩾0

m⩾n
Cyl(“(m+1)st state is in B”)
where Cyl(“(m+1)st state is in B”) denotes the union of all cylinder sets Cyl(t0 t1 . . . tm)
spanned by a ﬁnite path fragment of length m that ends in a B-state. That is, t0 t1 . . . tm ∈
Pathsﬁn(M) and tm ∈B. Let us prove the equality in the above equation.
1. ⊆: Let π = s0 s1 s2 . . . be a path in M such that π |= □♦B. Thus, for all indices n
there exists some m ⩾n such that sm ∈B. But then s0 s1 . . . . . . sm is a ﬁnite path
fragment which ends in some state in T and whose cylinder set contains π. Thus,
for all n ⩾0 there exists m ⩾n such that
π ∈Cyl(s0 . . . sm) ⊆Cyl(“(m + 1)-st state is in B”).
This shows that π belongs to the set on the right.
2. ⊇: Let π = s0 s1 s2 . . . be a path in +
n⩾0

m⩾n Cyl(“(m+1)st state ∈B”). Thus,
for each n there exists some m ⩾n and a ﬁnite path fragment t0 t1 . . . tm such
that tm ∈B and π ∈Cyl(t0 t1 . . . tm).
But then t0 t1 . . . tm is a preﬁx of π and
sm = tm ∈B. As this holds for any n, it follows that π |= □♦B.
These arguments can be generalized to establish the measurability of events stating that
ﬁnite path fragments, like π, appear inﬁnitely often. This can be seen as follows. Let

772
Probabilistic Systems
π = t0 . . . tk be a ﬁnite path fragment in M and Cyl(“π is taken from the mth state”)
the union of all cylinder sets Cyl(s0 . . . sm−1 t0 . . . tk). Then, the set of paths satisfying
□♦π, i.e., the set of paths that contain inﬁnitely many occurrences of π is measurable,
since it is given by:
1
n⩾0

m⩾n
Cyl(“π is taken from the mth state”).
Now let Π be a set of ﬁnite path fragments. The above yields that the event 
bπ∈Π □♦π,
stating that each ﬁnite path fragment π ∈Π is taken inﬁnitely often, is measurable too.
Note that since the state space S of a Markov chain is countable (see Deﬁnition 10.1, page
747), Pathsﬁn(M) is countable.
Let us now consider persistence properties, i.e., events of the form ♦□B. Such events
consist of all paths π = s0 s1 s2 . . . such that, for some n ⩾0, the suﬃx sn sn+1 . . .
only contains states in B. The event ♦□B is measurable as it is the complement of the
measurable event □♦(S \ B).
While the inﬁnite repetition of a nondeterministic choice in a transition system does not
impose any restrictions on the sequence of selected alternatives, randomization (as in
Markov chains) somehow implies strong fairness for all transitions. This follows from the
following theorem which states that under the assumption that a certain state t, say, of
a Markov chain is visited inﬁnitely often, then almost surely all ﬁnite path fragments
t0 t1 . . . tn that start in t (i.e., t0 = t) will be taken inﬁnitely often too. Here, the notion
“almost surely” refers to the conditional probabilities, under the condition that t is visited
inﬁnitely often. Formally, an event E is said to hold almost surely under the condition of
another event D if Pr(D) = Pr(E ∩D).
Theorem 10.25.
Probabilistic Choice as Strong Fairness
For (possibly inﬁnite) Markov chain M and s, t states in M:
PrM(s |= □♦t) = PrM
s


bπ ∈Pathsﬁn(t)
□♦π

where 
bπ ∈Pathsﬁn(t) □♦π denotes the set of all paths π such that any path fragment π ∈
Pathsﬁn(t) occurs inﬁnitely often in π.
In particular, for each state t ∈S and u ∈Post(t) the event “transition t →u is taken
inﬁnitely often” holds almost surely given that t is visited inﬁnitely often. In this sense,
executions of Markov chains are strongly fair with respect to all probabilistic choices.
Proof: The proof is provided in three steps.

Markov Chains
773
1. We ﬁrst prove that for any π ∈Pathsﬁn(t) it holds that:
Pr(s |= □♦t) = Pr(s |= ♦π).
Let p = P(π). As π ∈Pathsﬁn(t), it follows that 0 < p ⩽1. Let En(π) be the
event “visit t at least n times, but never take the path fragment π”. Note that
E1(π) ⊇E2(π) ⊇. . .. Furthermore:
Prs(En(π)) ⩽(1 −p)n.
Let the event E(π) = +
n⩾1 En(π).
That is, E(π) is the event that t is visited
inﬁnitely often, but the path fragment π is never taken. As E1(π) ⊇E2(π) ⊇. . .
and
Prs(E(π)) =
lim
n→∞Prs(En(π)) ⩽
lim
n→∞(1 −p)n = 0,
we have that:
Pr(s |= □♦t ∧“path fragment π is never taken”) = 0
2. Now consider the event Fn(π), for n ⩾0, that represents the fact that state t is
visited inﬁnitely often, while the path fragment π will not be taken anymore from
the nth state on. The probability for the event Fn(π) is given by
Prs(Fn(π)) =

s′∈S
Pr(
s |= ⃝n s′



the n-th state is s′
) · Prs′(E(π))



=0
= 0.
Now consider the event
F(π) = □♦t ∧“from some moment on, the path fragment π is never taken”.
It follows that F(π) = 
n⩾1 Fn(π). Since F1 ⊆F2 ⊆. . . it follows that
Prs(F(π)) = lim
n→∞Prs(Fn(π)) = 0.
Hence:
Pr(s |= □♦t ∧□♦“path fragment π is taken”)
=
Pr(s |= □♦t) −Prs(F(π))
=
Pr(s |= □♦t).
3. We now generalize this result to all ﬁnite path fragments starting in state t. Let the
event
F =

bπ∈Pathsﬁn(t)
F(π).
As the set of ﬁnite path fragments is countable we have
Prs(F) ⩽

bπ
Prs(F(π)) = 0
where π ranges over all ﬁnite path fragments starting in t. Hence, Prs(F) = 0.

774
Probabilistic Systems
Thus, under the condition that state t is visited inﬁnitely often, almost surely any ﬁnite
path fragment starting in t will be taken inﬁnitely often.
As a direct consequence of Theorem 10.25, it follows that any successor of t is visited
inﬁnitely often:
PrM(s |= □♦t) = PrM(s |=

u ∈Post∗(t)
□♦u).
Hence, for any state s it holds that
Pr(s |=

t∈S

u∈Post∗(t)
(□♦t →□♦u)) = 1.
Notation 10.26.
Graph Notations for Markov Chains
Let M = (S, P, ιinit, AP, L) be a ﬁnite MC. In the sequel, we often use graph-theoretical
notations for MCs which refer to the underlying digraph of M. For example, a subset T
of S is called strongly connected if for each pair (s, t) of states in T there exists a path
fragment s0 s1 . . . sn such that si ∈T for 0 ⩽i ⩽n, s0 = s and sn = t. A strongly
connected component (SCC, for short) of M denotes a strongly connected set of states
such that no proper superset of T is strongly connected. A bottom SCC (BSCC, for short)
of M is an SCC T from which no state outside T is reachable, i.e., for each state t ∈T it
holds that P(t, T) = 1. (Recall that P(s, T) = 
t∈T P(s, t).) Let BSCC(M) denote the
set of all BSCCs of the underlying digraph of M.
Let us now apply Theorem 10.25 to ﬁnite MCs. They enjoy the property that at least
one state is visited inﬁnitely often on each inﬁnite path. The following result asserts that
the set of states that is visited inﬁnitely often on a path almost surely forms a BSCC.
Before presenting this result, we have to ensure that the event “being in a given BSCC” is
measurable. This can be seen as follows. Recall that inf(π) denotes the set of states that
are visited inﬁnitely often along π. The event inf(π) = T for some BSCC T is measurable
as it can be written as a ﬁnite intersection of measurable sets (cf. Remark 10.24 on page
771):

t∈T
□♦t ∧♦□T.
The set of paths for which inf(π) is a BSCC agrees with the measurable event
!
T∈BSCC(M)
(inf(π) = T).

Markov Chains
775
Theorem 10.27.
Limit Behavior of Markov Chains
For each state s of a ﬁnite Markov chain M:
PrM
s { π ∈Paths(s) | inf(π) ∈BSCC(M) } = 1.
Proof: For each path π, the set inf(π) is strongly connected, and thus contained in some
SCC of M. Hence, for each state s:

T
Prs{ π ∈Paths(s) | inf(π) = T } = 1
(∗)
where T ranges over all nonempty SCCs of M. Assume that Prs{ π ∈Paths(s) | inf(π) =
T } is positive. By Theorem 10.25, almost all paths π with inf(π) = T fulﬁll
Post∗(T) = Post∗(inf(π)) ⊆inf(π) = T.
Hence, T = Post∗(T), i.e., T is a BSCC. The claim now follows from (∗).
Stated in words, Theorem 10.27 states that almost surely any ﬁnite Markov chain even-
tually reaches a BSCC and visits all its states inﬁnitely often.
Example 10.28.
Zeroconf Protocol (Revisited)
Consider the Markov chain for the zeroconf protocol; see Example 10.5 (page 751). This
MC has two BSCCs, namely { s8 } and { s6 }. According to the previous theorem, any
inﬁnite path will almost surely lead to one of these BSCCs. This means in particular that
the probability of inﬁnitely often attempting to acquire a new address (after receiving no
response on a probe) equals zero.
The previous theorem is a central result for the analysis of many types of properties of ﬁnite
MCs. In the following, we consider three important almost sure properties: reachability,
repeated reachability, and persistence properties. The problem of almost sure reachability
amounts to determining the set of states that reach a certain given set of states B, say,
almost surely. The following result provides the foundations for such a computation.
Theorem 10.29.
Almost Sure Reachability
Let M be a ﬁnite Markov chain with state space S, s ∈S and B ⊆S a set of absorbing
states. Then, the following statements are equivalent:

776
Probabilistic Systems
(a) Pr(s |= ♦B) = 1.
(b) Post∗(t) ∩B ̸= ∅for each state t ∈Post∗(s).
(c) s ∈S \ Pre∗( S \ Pre∗(B) ).
In particular, { s ∈S | Pr(s |= ♦B) = 1 } = S \ Pre∗( S \ Pre∗(B) ).
Proof:
1. (a) =⇒(b): Let t ∈Post∗(s) such that Post∗(t) ∩B = ∅, i.e., t is a successor of s
from which B cannot be reached. Then: Pr(s |= ♦B) ⩽1 −Pr(s |= ♦t) < 1. This
shows that if (b) is violated, (a) is so too.
2. (b) ⇐⇒(c): By deﬁnition of Post and Pre it follows that for each u ∈S and C ⊆S,
Post∗(u) ∩C ̸= ∅if and only if u ∈Pre∗(C). Thus:
Post∗(t) ∩B ̸= ∅for any state t ∈Post∗(s)
iﬀ
Post∗(s) ⊆Pre∗(B)
iﬀ
Post∗(s) ∩(S \ Pre∗(B)) = ∅
iﬀ
s /∈Pre∗( S \ Pre∗(B) )
iﬀ
s ∈S \ Pre∗( S \ Pre∗(B) ).
3. (b) =⇒(a): Assume Post∗(t) ∩B ̸= ∅for any successor t of s. By Theorem 10.27,
almost all paths π ∈Paths(s) reach a BSCC. Since each state in B is absorbing, each
BSCC T of M is either of the form T = { t } with t ∈B or it satisﬁes T ∩B = ∅.
Let us show that the latter case cannot occur. Consider T ∩B = ∅for BSCC T.
As T is a BSCC, Post∗(u) ∩B = ∅for each u ∈T. However, as B is reachable from
any successor of s, there is no BSCC T with T ∩B = ∅that is reachable from s.
Hence, from state s almost surely a state in B will be reached.
Thus, if all states in a ﬁnite Markov chain can reach a set B of absorbing states, then
B will be reached almost surely from each state. This, however, also implies that almost
surely B will be visited inﬁnitely often, as stated by the following corollary:

Markov Chains
777
Corollary 10.30.
Global Almost Sure Reachability
Let M be a ﬁnite Markov chain with state space S, and B ⊆S. Then:
s |= ∃♦B for any s ∈S
implies Pr(s |= □♦B) = 1 for all s ∈S.
Theorem 10.29 suggests the following algorithm to determine the set of states that reach
a certain set B of states almost surely in a ﬁnite MC M:
1. Make all states in B absorbing. This yields MC MB.
2. Determine the set S \ Pre∗(S \ Pre∗(B)) by a graph analysis in MB. This can be
done by a backward search from B to compute Pre∗(B) followed by a backward
search from S \ Pre∗(B) to determine Pre∗(S \ Pre∗(B)). Both searches are carried
out on MB.
Thus, the time complexity of determining the set of states s for which Pr(s |= ♦B) = 1 is
linear in the size of M.
Now consider a constrained reachability condition C U B where C and B are subsets of
the state space of a ﬁnite MC M.
Corollary 10.31.
Qualitative Constrained Reachability
For ﬁnite Markov chain M with state space S and B, C ⊆S, the sets
S=0 = { s ∈S | Pr(s |= C U B) = 0 } and S=1 = { s ∈S | Pr(s |= C U B) = 1 }
can be computed in time O(size(M)).
Proof: Let M be a ﬁnite MC and B, C ⊆S.
1. The set S=0 = { s ∈S | Pr(s |= C U B) = 0 } agrees with the complement of the
satisfaction set of the CTL formula ∃(C U B). This set can be computed by means
of a backward analysis starting from the B-states in time linear in the size of M.
2. A linear-time algorithm for the computation of S=1 = { s ∈S | Pr(s |= C U B) = 1 }
is obtained as follows. In fact, the problem of calculating S=1 can be solved by a
reduction to the problem of computing the set of states that almost surely eventually

778
Probabilistic Systems
reach B in a slightly modiﬁed Markov chain.
The idea is to make all B-states
absorbing and do the same for all states in S \ (C ∪B). To that end, M is changed
into the Markov chain M′ with state space S and transition probability function P′
given by
P′(s, t) =
⎧
⎨
⎩
1
:
if s ∈B ∪S \ (C ∪B)
P(s, t)
:
otherwise.
The justiﬁcation for the transformation of M into M′ is given by
• PrM(s |= C U B) = PrM′(s |= ♦B) for all states s ∈C \ B,
• PrM(s |= C U B) = PrM′(s |= ♦B) = 1 for all states s ∈B,
• PrM(s |= C U B) = PrM′(s |= ♦B) = 0 for all states s ∈S \ (C ∪B).
Thus, the probabilities for the constrained reachability property C U B in M can be
determined by computing the reachability probabilities ♦B in M′. The latter can
be done in time linear in the size of M′ (see above), which is bounded from above
by that of M. (Recall that size(M) is the number of states and transitions in M.)
Example 10.32.
Qualitative Constrained Reachability
Consider again the craps game, see Example 10.4 (page 750). As before, let B = { won }
and C = { start, 4, 5, 6 } and consider the event C U B. We have
S=0 = S \ Sat(∃(C U B)) = { lost, 8, 9, 10 }.
To determine the set S=1 all states in B and in S \ (B ∪C) are made absorbing. This
yields the MC in Figure 10.5 (page 770). The states that almost surely reach the state
won in this MC are { 4, 5, 6, won }. These are the states in S=1.
Using the above result, the qualitative model-checking problem to determine whether
PrM(C U B) = 1 can be solved by a graph analysis in time linear in the size of M. In
fact, the same holds for repeated reachability events:
Corollary 10.33.
Qualitative Repeated Reachability
Let M be a ﬁnite Markov chain with state space S, B ⊆S, and s ∈S. Then, the following
statements are equivalent:
(a) Pr(s |= □♦B) = 1.
(b) T ∩B ̸= ∅for each BSCC T that is reachable from s.

Markov Chains
779
(c) s |= ∀□∃♦B.
Proof: The equivalence of (a) and (b) follows immediately from the fact that from state s
almost surely a BSCC T will be reached and all states of T will be visited inﬁnitely often
(see Theorem 10.27). The equivalence of (a)/(b) and (c) is left as an exercise to the reader
(see Exercise 10.5 on page 901).
As a consequence, to check whether PrM(□♦B) = 1, it suﬃces to analyze the BSCCs
in M, which can be done in linear time.
The following result asserts that repeated
reachability probabilities can be computed in time polynomial in the size of M. This
is achieved by a reduction to the problem of computing the probabilities for eventually
visiting certain BSCCs:
Corollary 10.34.
Quantitative Repeated Reachability
Let M be a ﬁnite Markov chain with state space S, B ⊆S, and s ∈S, and U be the union
of all BSCCs T (in M) with T ∩B ̸= ∅. Then:
Pr(s |= □♦B) = Pr(s |= ♦U).
In a similar way, by an analysis of the BSCCs it can also be checked whether a strong or
weak fairness constraint (or other ω-regular liveness property) holds almost surely. For
persistence property ♦□B with B ⊆S, for instance, we have
• Pr(s |= ♦□B) = 1 iﬀT ⊆B for each BSCC T that is reachable from s.
• Pr(s |= ♦□B) = Pr(s |= ♦V ) where V is the union of all BSCCs T with T ⊆B.
The conclusion of this section is that checking a qualitative property, such as reachability,
repeated reachability, and persistence on a ﬁnite Markov chain can be achieved by a graph
analysis. The transition probabilities thus are of no importance for this purpose! As the
following example indicates, this does not hold for inﬁnite Markov chains.
Remark 10.35.
Qualitative Properties in Inﬁnite Markov Chains
We state without proof that the above considerations on the limiting behavior of ﬁnite
Markov chains do not hold for inﬁnite Markov chains. In fact, even for strongly connected
inﬁnite Markov chains it is possible that the probability of visiting a certain state inﬁnitely

780
Probabilistic Systems
often is zero. Thus, it is possible that Pr(s |= ♦T) > 0 for all states s, while Pr(s |=
□♦T) = 0. Typical examples are so-called one-dimensional random walks. A concrete
example is the inﬁnite Markov chain Mp where p is a rational number in ]0, 1[.
The
state space of Mp is S = IN with L(0) = { 0 } and L(n) = ∅for n > 0. The transition
probabilities in Mp are given by (see Figure 10.6):
P(n, n+1) = p
and
P(n, n−1) = 1 −p
for all n > 0
P(0, 0) = 1 −p
and
P(0, 1) = p.
It can be shown that for p ⩽1
2, the leftmost state is almost surely eventually reached, and
almost surely inﬁnitely often visited, i.e.:
Pr(n |= ♦0) = Pr(n |= □♦0) = 1
for all n ⩾0.
However, for p > 1
2, it is more likely to move to the right (i.e., to move from state n to state
n+1) than to the left, and it can be shown that Pr(n |= ♦0) < 1 and Pr(n |= □♦0) = 0
for all n > 0. (Further details on inﬁnite Markov chains and random walks can be found
in most textbook on Markov chains; see e.g., [63, 238, 248].)
0
1
2
3
p
p
p
1 −p
1 −p
1 −p
{ 0 }
∅
∅
∅
1 −p
Figure 10.6: Inﬁnite Markov chain for a one-dimensional random walk.
10.2
Probabilistic Computation Tree Logic
Probabilistic computation tree logic (PCTL, for short) is a branching-time temporal logic,
based on the logic CTL (see Chapter 6). A PCTL formula formulates conditions on a
state of a Markov chain. The interpretation is Boolean, i.e., a state either satisﬁes or
violates a PCTL formula. The logic PCTL is deﬁned like CTL with one major diﬀerence.
Instead of universal and existential path quantiﬁcation, PCTL incorporates, besides the
standard propositional logic operators, the probabilistic operator PJ(ϕ) where ϕ is a path
formula and J is an interval of [0, 1]. The path formula ϕ imposes a condition on the set
of paths, whereas J indicates a lower bound and/or upper bound on the probability. The
intuitive meaning of the formula PJ(ϕ) in state s is: the probability for the set of paths
satisfying ϕ and starting in s meets the bounds given by J. The probabilistic operator can
be considered as the quantitative counterpart to the CTL path quantiﬁers ∃and ∀. The
CTL formulae ∃ϕ and ∀ϕ assert the existence of certain paths and the absence of paths
where a certain condition does not hold respectively. They, however, do not impose any

Probabilistic Computation Tree Logic
781
constraints on the likelihood of the paths that satisfy the condition ϕ. Later on in this
section, the relationship between the operator PJ(ϕ) and universal and existential path
quantiﬁcation is elaborated in detail.
The path formulae ϕ are deﬁned as for CTL, except that a bounded until operator is
additionally incorporated. The intuitive meaning of the path formula Φ U⩽nΨ for a natural
number n is that a Ψ state should be reached within n transitions, and that all states prior
to reaching the Ψ-state satisfy Φ.
Deﬁnition 10.36.
Syntax of PCTL
PCTL state formulae over the set AP of atomic propositions are formed according to the
following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   PJ(ϕ)
where a ∈AP, ϕ is a path formula and J ⊆[0, 1] is an interval with rational bounds.
PCTL path formulae are formed according to the following grammar:
ϕ ::= ⃝Φ
   Φ1 U Φ2
   Φ1 U⩽n Φ2
where Φ, Φ1, and Φ2 are state formulae and n ∈IN.
As in CTL, the linear temporal operators ⃝and U (and its bounded variant) are required
to be immediately preceded by P.
Rather than writing the intervals explicitly, often
abbreviations are used; e.g., P⩽0.5(ϕ) denotes P[0,0.5](ϕ), P=1(ϕ) stands for P[1,1](ϕ), and
P>0(ϕ) denotes P]0,1](ϕ).
The propositional logic fragment of PCTL, as well as the path formulae ⃝Φ and Φ1 U Φ2
has the same meaning as in CTL. Path formula Φ1 U ⩽nΦ2 is the step-bounded variant of
Φ1 U Φ2. It asserts that the event speciﬁed by Φ2 will hold within at most n steps, while
Φ1 holds in all states that are visited before a Φ2-state has been reached. Other Boolean
connectives are derived in the usual way, e.g., Φ1 ∨Φ2 is obtained by ¬(¬Φ1 ∧¬Φ2).
The eventually operator (♦) can be derived as usual: ♦Φ = true U Φ.
Similarly, for
step-bounded eventually we have:
♦⩽nΦ = true U ⩽nΦ.
A path satisﬁes ♦⩽nΦ if it reaches a Φ-state within n steps.
The always operator can be derived using the duality of eventually and always (as in CTL
and LTL) and the duality of lower and upper bounds. The latter means that an event E

782
Probabilistic Systems
holds with probability at most p if and only if the dual event ¯E = Paths(M) \ E holds
with probability at least 1−p. Thus, it is possible to deﬁne, e.g.,
P⩽p(□Φ) = P⩾1−p(♦¬Φ)
and
P]p,q](□⩽nΦ) = P[1−q,1−p[(♦⩽n¬Φ).
Other temporal operators, like weak until W or release R (see Section 5.1.5, page 252)
can be derived in an analogous way. This is left as an exercise to the reader; see Exercise
10.9 (page 902).
Example 10.37.
Specifying Properties in PCTL
Consider the simulation of a six-sided die by a fair coin as described in Example 10.3 (page
750). The PCTL formula

1⩽i⩽6
P= 1
6(♦i)
expresses that each of the six possible outcomes of the die should occur with equal prob-
ability.
Consider a communication protocol that uses an imperfect channel that might lose mes-
sages. The PCTL formula
P=1(♦delivered) ∧P=1

□( try to send →P⩾0.99(♦⩽3delivered) )

asserts that almost surely some message will be delivered (ﬁrst conjunct) and that almost
surely for any attempt to send a message, with probability at least 0.99, the message will
be delivered within three steps.
Consider the craps game, see Example 10.4. The property “the probability of winning
without ever rolling 8, 9, or 10 is at least 0.32” is expressed by the PCTL formula:
P⩾0.32(¬(8 ∨9 ∨10) U won).
Impatient players might be interested in this property but with a bounded number of rolls,
say, ﬁve. This is expressed by
P⩾0.32(¬(8 ∨9 ∨10) U⩽5 won).
Finally, the PCTL formula
P⩾0.32(¬(8 ∨9 ∨10) U⩽5 P=1(□won))
expresses in addition that almost surely the player will always win.
PCTL formulae are interpreted over the states and paths of a Markov chain M. For the
state formulae, the satisfaction relation |= is a relation between states in M and state

Probabilistic Computation Tree Logic
783
formulae. As usual, we write s |= Φ rather than (s, Φ) ∈|=. The interpretation is as usual,
e.g., s |= Φ if and only if Φ holds in s. For the path formulae, |= is a relation between
inﬁnite path fragments in M and path formulae.
Deﬁnition 10.38.
Satisfaction Relation for PCTL
Let a ∈AP be an atomic proposition, M = (S, P, ιinit, AP, L) be a Markov chain, state
s ∈S, Φ, Ψ be PCTL state formulae, and ϕ be a PCTL path formula. The satisfaction
relation |= is deﬁned for state formulae by
s |= a
iﬀ
a ∈L(s),
s |= ¬Φ
iﬀ
s ̸|= Φ,
s |= Φ ∧Ψ
iﬀ
s |= Φ and s |= Ψ,
s |= PJ(ϕ)
iﬀ
Pr(s |= ϕ) ∈J.
Here, Pr(s |= ϕ) = Prs{ π ∈Paths(s) | π |= ϕ }.
Given a path π in M, the satisfaction relation is deﬁned (as for CTL):
π |= ⃝Φ
iﬀ
π[1] |= Φ,
π |= Φ U Ψ
iﬀ
∃j ⩾0. (π[j] |= Ψ ∧(∀0 ⩽k < j. π[k] |= Φ)) ,
π |= Φ U⩽n Ψ
iﬀ
∃0 ⩽j ⩽n. (π[j] |= Ψ ∧(∀0 ⩽k < j. π[k] |= Φ))
where for path π = s0 s1 s2 . . . and integer i ⩾0, π[i] denotes the (i+1)-st state of π, i.e.,
π[i] = si.
Let SatM(Φ), or brieﬂy Sat(Φ), denote { s ∈S | s |= Φ }.
The semantics of the probability operator P refers to the probability for the sets of paths
for which a path formula holds. To ensure that this is well-deﬁned, we need to establish
that the events speciﬁed by PCTL path formulae are measurable, i.e., elements of the σ-
algebra EM (see Deﬁnition 10.10, page 758). As the set { π ∈Paths(s) | π |= ϕ } for PCTL
path formula ϕ can be considered as a countable union of cylinder sets, its measurability
is ensured. This follows from the following lemma.
Lemma 10.39.
Measurability of PCTL Events
For each PCTL path formula ϕ and state s of a Markov chain M, the set { π ∈Paths(s) |
π |= ϕ } is measurable.
Proof: For any PCTL path formula ϕ, it will be proven that the set Paths(s, ϕ) = { π ∈

784
Probabilistic Systems
Paths(s) | π |= ϕ } is measurable, i.e., belongs to the σ-algebra EM. This is done by
showing that this set can be considered as the countable union of cylinder sets in EM.
There are three possibilities for ϕ. If ϕ = ⃝Φ, then Paths(s, ϕ) agrees with the union of
the cylinder sets Cyl(s t) where t |= Φ. For ϕ = Φ U ⩽nΨ, the set Paths(s, ϕ) is obtained
by the union of all cylinder sets Cyl(s0 s1 . . . sk) where k ⩽n, sk |= Ψ, s0 = s, and si |= Φ
for 0 ⩽i < k. For unbounded until, i.e., ϕ = Φ U Ψ, we have:
Paths(s, ϕ) =

n⩾0
{ π ∈Paths(s) | π |= Φ U ⩽nΨ }.
The equivalence of PCTL formulae is deﬁned as for the other logics encountered so far:
two state formulae are equivalent whenever their semantics are equal. Formally, for PCTL
state formulae Φ and Ψ:
Φ ≡Ψ
iﬀ
for all Markov chains M and states s of M it holds that:
s |= Φ ⇐⇒s |= Ψ
iﬀ
SatM(Φ) = SatM(Ψ) for all Markov chains M.
In addition to the equivalence rules for propositional logic, we have, e.g.,
P<p(ϕ) ≡¬P⩾p(ϕ)
where p ∈]0, 1] is a rational number and ϕ an arbitrary PCTL path formula. This equiv-
alence follows directly from the PCTL semantics. Thus, the expressiveness of PCTL does
not change when only permitting the upper bounds on the path probabilities (< p and
⩽p) and one of the (qualitative) bounds = 0 or = 1. Note that, e.g.,
P]0.3,0.7](ϕ) ≡¬P⩽0.3(ϕ) ∧P⩽0.7(ϕ).
Another example is the following duality law:
P>0( ⃝P>0(♦Φ) ) ≡P>0( ♦P>0(⃝Φ) ).
This is proven as follows. First, consider ⇒. Let s be a state of Markov chain M with
s |= P>0( ⃝P>0(♦Φ) ). Then, for some direct successor t of s, it holds that t |= P>0(♦Φ) ).
This implies that there exists a ﬁnite path fragment t0 t1 . . . tn which starts in t0 = t and
ends in state tn ∈Sat(Φ). So, tn−1 |= P>0(⃝Φ). Since s t0 t1 . . . tn−1 is a path fragment
starting in s, it follows that s |= P>0(♦P>0(⃝Φ)).
Consider ⇐. Let s |= P>0(♦P>0(⃝Φ) ). From the PCTL semantics it follows that
Pr(s |= ♦Sat(P>0(⃝Φ))) > 0.

Probabilistic Computation Tree Logic
785
Thus, there exists a path fragment s0 s1 . . . sn starting in s0 = s and ending in a state
sn ∈Sat(P>0(⃝Φ)). Hence, sn has a successor t with t |= Φ. But then s1 . . . sn t is a
witness for s1 |= P>0(♦Φ). Since s1 ∈Post(s), it follows that s |= P>0( ⃝P>0(♦Φ) ).
10.2.1
PCTL Model Checking
The PCTL model-checking problem is the following decision problem.
Given a ﬁnite
Markov chain M, state s in M, and PCTL state formula Φ, determine whether s |= Φ.
As for CTL model checking, the basic procedure is to compute the satisfaction set Sat(Φ).
This is done recursively using a bottom-up traversal of the parse tree of Φ; see Algorithm
13 (page 342). The nodes of the parse tree represent the subformulae of Φ. For each node
of the parse tree, i.e., for each subformula Ψ of Φ, the set Sat(Ψ) is determined. For the
propositional logic fragment of PCTL this is performed in exactly the same way as for
CTL. The most interesting part is the treatment of subformulae of the form Ψ = PJ(ϕ). In
order to determine whether s ∈Sat(Ψ), the probability Pr(s |= ϕ) for the event speciﬁed
by ϕ needs to be established. Then
Sat(PJ(ϕ)) = {s ∈S | Pr(s |= ϕ) ∈J}.
For several path formulae ϕ, the computation of the probability Pr(s |= ϕ) has, in fact,
already been treated in previous sections.
Let us ﬁrst consider the next-step operator. For ϕ = ⃝Ψ, the following equality holds:
Pr(s |= ⃝Ψ) =

s′∈Sat(Ψ)
P(s, s′)
where P is the transition probability function of M. In matrix-vector notation we thus
have that the vector ( Pr(s |= ⃝Ψ) )s∈S can be computed by multiplying P with the char-
acteristic vector for Sat(Ψ), i.e., bit vector (bs)s∈S where bs = 1 if and only if s ∈Sat(Ψ).
Checking the next-step operator thus reduces to a single matrix-vector multiplication.
The probability Pr(s |= ϕ) for until formulae ϕ = Φ U ⩽nΨ or ϕ = Φ U Ψ can be obtained
using the techniques explained in Section 10.1.1 (see page 759ﬀ). The events C U ⩽nB or
C U B, respectively, should be taken with C = Sat(Φ) and B = Sat(Ψ). For the bounded
until operator U ⩽n, the vector ( Pr(s |= ϕ) )s∈S can be obtained by O(n) vector-matrix
multiplications. For the until operator, a linear equation system needs to be solved. In
both cases, the dimension of the involved matrix is bounded by N × N where N = |S| is
the number of states in M. This yields

786
Probabilistic Systems
Theorem 10.40.
Time Complexity of PCTL Model Checking for MCs
For ﬁnite Markov chain M and PCTL formula Φ, the PCTL model-checking problem
M |= Φ can be solved in time
O( poly(size(M)) · nmax · |Φ| )
where nmax is the maximal step bound that appears in a subpath formula Ψ1 U ⩽nΨ2 of Φ
(and nmax = 1 if Φ does not contain a step-bounded until operator).
For eﬃciency reasons, in order to check the qualitative PCTL properties, such as P=1(a U b)
or P>0(a U b), graph-based techniques are employed as described in the next subsection.
This avoids solving a system of linear equations.
For CTL, counterexamples and witnesses can be provided as an additional diagnostic feed-
back when checking a transition system against a CTL formula ∃ϕ or ∀ϕ. Alternatively, a
CTL model checker may provide an output ﬁle containing the information on which states
fulﬁll the subformulae. Recall that the satisfaction sets of all subformulae are computed
by the CTL model checker anyway. The probabilistic analogue is to provide the infor-
mation on the probabilities Pr(s |= ϕ) for all subformulae PJ(ϕ). Note that these values
Pr(s |= ϕ) have been computed by the PCTL model checker. Although this information
can be very helpful, for large state spaces it might be hard to extract any relevant informa-
tion. To provide more comprehensive diagnostic information, the PCTL model-checking
procedure can be extended to return sets of ﬁnite path fragments that constitute a witness
for the satisfaction or refutation of subformulae PJ(ϕ). Let us explain this by means of
(unconstrained) reachability properties. If s ̸|= P⩽p(♦Ψ), then Pr(s |= ♦Ψ) > p. A proof
for the latter is given by a ﬁnite set Π of ﬁnite path fragments s0 s1 . . . sn such that s0 = s,
si ̸|= Ψ for 0 ⩽i < n and sn |= Ψ and 
bπ∈Π P(π) > p. A witness of s ̸|= P⩽p(♦Ψ) thus is
a ﬁnite set of paths, all satisfying ♦Ψ, such that their total probability mass exceeds p.
Example 10.41.
Counterexample
Consider the (abstract) Markov chain depicted in Figure 10.7 and assume the PCTL
formula of interest is P⩽1
2(♦b). The fact that s0 ̸|= P⩽1
2(♦b) can be witnessed by, e.g., the
set of ﬁnite paths:
{
s0 s1 t1
  
probability 0.2
,
s0 s1 s2 t1



probability 0.2
,
s0 s2 t1
  
probability 0.15
}
whose total probability exceeds the probability bound 1
2. Note that counterexamples are
not unique; e.g., replacing the ﬁnite path s0 s2 t1 by s0 s1 s2 t1 in the above set of paths
also yields a counterexample.
An evidence of s ̸|= P⩾p(♦Ψ)—note that the only diﬀerence with the previous case is that

Probabilistic Computation Tree Logic
787
s0
s1
t1
{ b }
u
s2
t2
{ b }
0.6
1
3
2
3
0.3
0.1
0.3
0.7
0.5
0.3
1
1
0.2
Figure 10.7: An example of a Markov chain.
p is an upper bound rather than a lower bound—is obtained by considering the set of ﬁnite
paths that refute ♦Ψ and showing that these paths occur with a probability that exceeds
1−p. More precisely, consider the ﬁnite set Π of ﬁnite paths s0 s1 . . . sn such that s0 = s,
si ̸|= Ψ for 0 ⩽i < n and sn belongs to some BSCC C of M such that C ∩Sat(Ψ) = ∅.
Moreover, it is required that 
bπ∈Π P(π) > 1−p. Note that all paths that start with a
preﬁx s0s1 . . . sn ∈Π never visit a state for which Ψ holds. The cylinder sets Cyl(π) of all
path fragments π ∈Π are contained in { π ∈Paths(s) | π |= □¬Ψ }. Hence:
Pr(s |= ♦Ψ) = 1 −Pr(s |= □¬Ψ) ⩽1 −

bπ∈Π
P(π) < 1 −(1−p) = p.
Vice versa, Pr(s |= □¬Ψ) equals the probability of reaching a BSCC T via a path fragment
through ¬Ψ-states such that T ∩Sat(Ψ) = ∅. Hence, Pr(s |= ♦Ψ) < p if and only if there
exists such a ﬁnite set Π. Such a set Π can be obtained by successively increasing n and
collecting all ﬁnite path fragments s0 s1 . . . sk up to length k ⩽n that fulﬁll the above
conditions (i.e., s0, . . . , sk−1 ̸|= Ψ and sk ∈T for some BSCC T with T ∩Sat(Ψ) = ∅),
until the probabilities P(s0 s1 . . . sk) sum up to a value > 1 −p.
10.2.2
The Qualitative Fragment of PCTL
The logic PCTL has been introduced as a variant of CTL where the path quantiﬁers ∃
and ∀are replaced by the probabilistic operator PJ. It is the purpose of this section to
compare the expressiveness of CTL and PCTL in more detail. As PCTL provides the
possibility to specify lower (or upper) bounds in the likelihood that they diﬀer from zero
and 1, as in P⩾1
2 (ϕ), it is evident that there exist properties that can be deﬁned in PCTL
but not in CTL. It remains to investigate how the qualitative fragment of PCTL—only
allowing bounds with p=0 or p=1—relates to CTL. As we will see, these logics are not
equally expressive, but are incomparable (though their common fragment is large).

788
Probabilistic Systems
Deﬁnition 10.42.
Qualitative Fragment of PCTL
State formulae in the qualitative fragment of PCTL (over AP) are formed according to
the following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   P>0(ϕ)
   P=1(ϕ)
where a ∈AP, ϕ is a path formula formed according to the following grammar:
ϕ ::= ⃝Φ
   Φ1 U Φ2
where Φ, Φ1, and Φ2 are state formulae.
The formulae of the qualitative fragment of PCTL are referred to as qualitative PCTL
formulae. Although the only allowed probability bounds are > 0 and =1, the bounds = 0
and < 1 can be derived, as
P=0(ϕ) ≡¬P>0(ϕ)
and
P<1(ϕ) ≡¬P=1(ϕ).
Thus, e.g., P=1(♦P>0(⃝a)) and P<1(P>0(♦a) U b) are qualitative PCTL formulae, while
P<0.5(♦a) and P=1(a U ⩽5b) are not. Note that the bounded until operator is not part of
the qualitative fragment of PCTL.
In the sequel, let M be a Markov chain. PCTL formulae will be interpreted over M. CTL
formulae are interpreted over the induced transition system of M, i.e., TS(M) (see page
753). Recall that s
τ
−→s′ in this transition system if and only if P(s, s′) > 0; the exact
transition probabilities are thus abstracted away in TS(M).
Deﬁnition 10.43.
Equivalence of PCTL and CTL Formulae
The PCTL formula Φ is equivalent to the CTL formula Ψ, denoted Φ ≡Ψ, if SatM(Φ) =
SatTS(M)(Ψ) for each Markov chain M.
Consider ﬁrst the PCTL formula P=1(ϕ) and the CTL formula ∀ϕ. The former asserts ϕ
to hold almost surely. This allows for certain exceptional executions where ϕ is violated.
The formula ∀ϕ, however, requires ϕ to hold for all paths. No exceptions are allowed. In
fact, we have:
s |= ∀♦a
implies
s |= P=1(♦a).
The reverse direction, however, does not hold. For example, consider the following Markov
chain:
s
s′
1
2
1
1
2
∅
{ a }

Probabilistic Computation Tree Logic
789
Formula P=1(♦a) holds in state s as the probability of visiting state s inﬁnitely often is
zero. On the other hand, the path sω is possible and clearly violates ♦a. Thus:
s |= P=1(♦a)
but
s ̸|= ∀♦a.
However, for certain path formulae ϕ, the probability bounds > 0 and = 1 correspond to
existential and universal path quantiﬁcation in CTL. The simplest such cases are path
formulae involving the next-step operator:
s |= P=1(⃝a)
iﬀ
s |= ∀⃝a
s |= P>0(⃝a)
iﬀ
s |= ∃⃝a
where s is a state in an arbitrary (possibly inﬁnite) Markov chain. The same applies to
reachability conditions ♦a that hold with positive probability if and only if ♦a holds for
some path, and to invariants □a that hold on all paths if and only if they hold almost
surely:
s |= P>0(♦a)
iﬀ
s |= ∃♦a
s |= P=1(□a)
iﬀ
s |= ∀□a.
Let us illustrate how to conduct the formal proof of these statements. Consider the ﬁrst
statement. Assume s |= P>0(♦a). By the PCTL semantics, it follows that Pr(s |= ♦a) > 0.
Thus, { π ∈Paths(s) | π |= ♦a } ̸= ∅, and hence, s |= ∃♦a. Vice versa, assume s |= ∃♦a,
i.e., there exists a ﬁnite path fragment s0 s1 . . . sn with s0 = s and sn |= a. It follows that
all paths in the cylinder set Cyl(s0s1 . . . sn) fulﬁll ♦a. Thus:
Pr(s |= ♦a) ⩾Prs(Cyl(s0s1 . . . sn)) = P(s0s1 . . . sn) > 0.
Therefore, s |= P>0(♦a).
The second statement follows by duality. First, observe that
s |= P=1(□a) = P=0(♦¬a) ≡¬P>0(♦¬a).
We can now apply the equivalence of P>0(♦a) and ∃♦a as follows:
s |= ¬P>0(♦¬a) iﬀs ̸|= P>0(♦¬a) iﬀs ̸|= ∃♦¬a iﬀs |= ¬∃♦¬a
  
=∀□a
.
Thus, the equivalence of P>0(⃝P>0(♦Φ)) and P>0(♦P>0(⃝Φ)) (stated on page 784) is
the probabilistic analogue of the CTL duality law ∃⃝∃♦Φ ≡∃♦∃⃝Φ.
The arguments for the equivalence of P>0(♦a) and ∃♦a can be generalized toward con-
strained reachability:
s |= P>0(a U b)
iﬀ
s |= ∃(a U b).

790
Probabilistic Systems
A generalization that, however, does not work is swapping the probability bound > 0 and
=1 in the above two equivalences, as P=1(♦a) ̸≡∀♦a and P>0(□a) ̸≡∃□a. In fact, the
PCTL formula P=1(♦a) cannot be expressed in CTL.
Lemma 10.44.
1. There is no CTL formula that is equivalent to P=1(♦a).
2. There is no CTL formula that is equivalent to P>0(□a).
Proof: We provide the proof of the ﬁrst statement; the second statement follows by duality,
i.e., P=1(♦a) = ¬P>0(□¬a). The proof is by contraposition. Assume there exists a CTL
formula Φ such that Φ ≡P=1(♦a). Consider the inﬁnite Markov chain Mp modeling the
random walk; see Figure 10.6 (page 780). The state space of Mp is S = IN and there
are transitions from state n to state n−1 with probability 1−p and to state n+1 with
probability p for n ⩾1, while P(0, 0) = 1−p and P(0, 1) = p. Let the labeling function
L be such that a only holds in state 0. That is, 0 |= a and n ̸|= a for all n > 0. Recall
that for p < 1
2, it holds that for any state n almost surely state 0 will be visited, while
for p > 1
2, the Markov chain Mp drifts to the right and the probability of reaching state
0 from any other state n > 0 is strictly smaller than 1. Thus, e.g., in M 1
4 the formula
P=1(♦a) holds for all states, while in M 3
4 , the formula P=1(♦a) does not hold in, e.g.,
state n = 1. Hence:
1 ∈SatM 1
4 ( P=1(♦a) )
but
1 /∈SatM 3
4 ( P=1(♦a) ).
Since TS(M 1
4) = TS(M 3
4 ), it follows that
SatM 1
4 (Φ) = SatM 3
4 (Φ).
Hence, state 1 either fulﬁlls the CTL formula Φ in both structures or in none of them.
This, however, contradicts the assumption that P=1(♦a) and Φ are equivalent.
The proof relies on the fact that the satisfaction of P=1(♦a) for inﬁnite Markov chains
may depend on the precise value of the transition probabilities, while CTL just refers to
the underlying graph of a Markov chain. In case one is restricted to ﬁnite Markov chains,
the statement in Lemma 10.44 no longer holds. For each ﬁnite Markov chain M and state
s of M it holds that
s |= P=1(♦a)
iﬀ
s |= ∀( (∃♦a) W a )

Probabilistic Computation Tree Logic
791
where W is the weak until operator (see Remark 6.9 on page 327) deﬁned by Φ W Ψ =
Φ U Ψ ∨□Φ. The proof of (a slight generalization of) this statement is the subject of
Exercise 10.11 (page 903). For ﬁnite Markov chains, the qualitative fragment of PCTL
can be embedded into CTL.
Whereas the previous lemma stated that some qualitative PCTL cannot be expressed in
CTL, the following result states that for some CTL formulae no equivalent qualitative
PCTL exists. As a result, CTL and the qualitative fragment of PCTL are incomparable.
Lemma 10.45.
1. There is no qualitative PCTL formula that is equivalent to ∀♦a.
2. There is no qualitative PCTL formula that is equivalent to ∃□a.
Proof: We provide the proof of the ﬁrst claim; the second claim follows by duality, since
∀♦a = ¬∃□¬a. For n ⩾1, let the MCs Mn and M′
n be deﬁned as follows. The state
spaces of Mn and M′
n are Sn = { t0, t1, . . . , tn−1 } ∪{ sn } and S′
n = { t0, t1, . . . , tn },
respectively. Mn and M′
n agree on the fragment consisting of their common states, i.e.,
state t0 through tn−1. State sn in Mn has a self-loop and a transition to tn−1, both with
probability 1
2. In contrast, state tn in M′
n only has a transition tn →tn−1 with probability
1. Both Markov chains are depicted in Figure 10.8. The transition probabilities in M′
n
are given by:
P′
n(ti, ti−1) = 1 for 1 ⩽i ⩽n
and
P′
n(t0, t0) = 1
and P′
n(·) = 0 otherwise. The transition probabilities in Mn are given by
Pn(sn, tn−1) = Pn(sn, sn) = 1
2,
Pn(ti, ti−1) = 1 for 1 ⩽i < n,
Pn(t0, t0) = 1
and Pn(·) = 0 in the remaining cases. Let AP = { a } and labeling functions Ln for Mn
and L′
n for M′
n given by Ln(sn) = Ln(ti) = L′
n(tj) = ∅for 1 ⩽i < n and 1 ⩽j ⩽n and
Ln(t0) = L′
n(t0) = { a }.
It can now be shown that for any qualitative PCTL formula Φ of nesting depth smaller
than n:
sn |= Φ
iﬀ
tn |= Φ.

792
Probabilistic Systems
t0
t1
{ a }
∅
1
1
1
sn
tn−1
∅
1
2
1
2
1
∅
Mn
t0
t1
{ a }
∅
1
1
1
tn
tn−1
1
1
∅
M′
n
Figure 10.8: The Markov chains Mn and M′
n.
This can be proven by induction on the nesting depth of Φ. (The proof is omitted here
and left as an exercise.) The nesting depth of qualitative PCTL formulae is deﬁned by
nd(true)
=
0
nd(a)
=
0
nd(Φ ∧Ψ)
=
max{nd(Φ), nd(Ψ)}
nd(¬Φ)
=
nd(Φ)
nd(PJ(ϕ))
=
nd(ϕ) + 1
nd(⃝Φ)
=
nd(Φ)
nd(Φ U Ψ)
=
max{nd(Φ), nd(Ψ)}
Suppose now that there exists a qualitative PCTL formula Φ such that Φ ≡∀♦a. Let
n = nd(Φ) + 1. Since sn |= Φ iﬀtn |= Φ, states sn and tn either both fulﬁll Φ or none
of them. On the other hand, sn ̸|= ∀♦a (because sn sn sn . . . ̸|= ♦a), while tn |= ∀♦a.
Contradiction.
These results indicate that extending the syntax of PCTL by adding universal and exis-
tential path quantiﬁcation increases its expressiveness. An essential aspect in the proof
of Lemma 10.45 is the existence of a state s, say, that has a self-loop and (at least) one
outgoing transition to another state. (In the proof, the state of interest is sn.) As the
probability of taking this loop inﬁnitely often is zero, the validity of a qualitative PCTL
formula in s in unaﬀected by the self-loop. However, the (zero probable) path sω may be
decisive for the validity of CTL formulae. The path sω, however, can be considered as
unfair, as there are inﬁnitely many opportunities to take the other outgoing transition.
The existence of such unfair computations turns out to be vital for the validity of Lemma
10.45. In fact, under appropriate fairness constraints, the equivalence of P=1(♦a) and ∀♦a
can be established. This can be seen as follows. Assume M is a ﬁnite Markov chain and
that any state s in M is uniquely characterized by an atomic proposition, say s. We

Probabilistic Computation Tree Logic
793
regard the strong fairness constraint sfair deﬁned by
sfair =

s∈S

t ∈Post(s)
(□♦s →□♦t).
It asserts that when a state s is visited inﬁnitely often, then any of its direct successors is
visited inﬁnitely often too. Using Theorem 10.25 (page 772), we obtain (see Exercise 10.8
on page 902)
s |= P=1(a U b)
iﬀ
s |=sfair ∀(a U b) and
s |= P>0(□a)
iﬀ
s |=sfair ∃□a.
As sfair is a realizable fairness constraint—from every reachable state at least one fair
path starts—we obtain
s |=sfair ∃(a U b)
iﬀ
s |= ∃(a U b)
iﬀ
s |= P>0(a U b)
s |=sfair ∀⃝a
iﬀ
s |= ∀⃝a
iﬀ
s |= P=1(⃝a)
s |=sfair ∃⃝a
iﬀ
s |= ∃⃝a
iﬀ
s |= P>0(⃝a).
Thus, for ﬁnite Markov chains the qualitative fragment of PCTL can be viewed as a variant
of CTL with some kind of strong fairness. A similar result holds for inﬁnite Markov chains,
but then the outermost conjunction in sfair has an inﬁnite range. The same applies to
the innermost conjunction in case inﬁnite branching occurs.
Repeated Reachability and Persistence Properties.
We now show that two prop-
erties that cannot be expressed in CTL (but which can be in CTL∗) can be expressed in
the qualitative fragment of PCTL.
For CTL, universal repeated reachability properties can be formalized by the combination
of the modalities ∀□and ∀♦:
s |= ∀□∀♦a
iﬀ
π |= □♦a for all π ∈Paths(s).
More details can be found in Remark 6.8 on page 326. For ﬁnite Markov chains, a similar
result holds for (the qualitative fragment of) PCTL.
Lemma 10.46.
Almost Sure Repeated Reachability is PCTL-deﬁnable
Let M be a ﬁnite Markov chain and s a state of M. Then:
s |= P=1( □P=1(♦a) )
iﬀ
Prs{ π ∈Paths(s) | π |= □♦a } = 1.

794
Probabilistic Systems
Proof: “=⇒”: Assume s |= P=1( □P=1(♦a) ). As P=1(□a) is equivalent to ∀□a, we have
s |= ∀□Sat(P=1(♦a)). Hence, all states t that are reachable from s satisfy P=1(♦a)).
Consider a BSCC T ⊆S of M such that Pr(s |= ♦T) > 0. Then, each state t in T is
reachable from s and t |= P=1(♦a). As Post∗(t) = T, T ∩Sat(a) ̸= ∅. Hence, almost all
paths π ∈Paths(s) that fulﬁll ♦T satisfy □♦a. Theorem 10.27 (page 775) then yields the
claim.
“⇐=”: Assume Prs{ π ∈Paths(s) | π |= □♦a } = 1. Theorem 10.27 (page 775) yields

T ∈BSCC(M)
T ∩Sat(a) ̸= ∅
Prs{π ∈Paths(s) | π |= ♦T} = 1.
On the other hand, Pr(t |= ♦a) = 1 for each state t of a BSCC T in M with T ∩Sat(a) ̸= ∅.
Therefore, the union of all BSCCs T with T ∩Sat(a) ̸= ∅is a subset of Sat(P=1(♦a)).
This yields
Pr( s |= ♦Sat(P=1(♦a)) ) = 1
and s |= P=1( □P=1(♦a) ).
According to this result, the PCTL formula P=1( □P=1(♦a) ) denotes that almost surely
a state for which a holds is repeatedly reachable. In the sequel, let P=1(□♦a) abbreviate
this formula.
There is no CTL formula that is equivalent to the CTL∗formula ∃□♦a. This is diﬀerent
for PCTL, as the requirement that the probability for the event □♦a is positive can be
described in PCTL.
For ﬁnite Markov chains, even arbitrary rational lower or upper
bounds for the likelihood of □♦a are PCTL-deﬁnable. In fact, the argument given in the
proof of Lemma 10.46 can be generalized for arbitrary probability bounds. The crucial
point is that almost surely a BSCC T ∈M will be reached and each of its states will
be visited inﬁnitely often. Thus, the probabilities for □♦a agree with the probability of
reaching a BSCC T where a holds for some state in T. Hence, for ﬁnite Markov chain M
and probability interval J, the PCTL formula PJ(□♦a) deﬁned by
PJ(□♦a) = PJ( ♦P=1(□♦a)



=P=1(□P=1(♦a))
)
characterizes all states s in M for which Pr(s |= □♦a) ∈J. This is expressed by the
following theorem:

Probabilistic Computation Tree Logic
795
Theorem 10.47.
Repeated Reachability Probabilities Are PCTL-deﬁnable
Let M be a ﬁnite Markov chain, s a state of M and J ⊆[0, 1] an interval. Then:
s |= PJ(♦P=1(□P=1(♦a))



=PJ(□♦a)
iﬀ
Pr(s |= □♦a) ∈J.
Proof: As M is ﬁnite, Theorem 10.27 (page 775) permits computing the probability for
visiting an a-state inﬁnitely often, as follows:
Pr(s |= □♦a)
=
Prs{ π ∈Paths(s) | π |= □♦a }
=
Prs{ π ∈Paths(s) | inf(π) ∈BSCC(M) ∧inf(π) ∩Sat(a) ̸= ∅}
=
Prs{ π ∈Paths(s) | π |= ♦T for some T ∈BSCC(M) with T ∩Sat(a) ̸= ∅}
=
Pr( s |= ♦Sat(P=1(□♦a)) ).
Hence, Pr(s |= □♦a) ∈J if and only if Pr(s |= ♦Sat(P=1(□♦a)) ) ∈J if and only if
s |= PJ( ♦P=1(□♦a) ) = PJ(□♦a).
Recall that universal persistence properties cannot be expressed in CTL; see Lemma 6.19
(page 335). For ﬁnite Markov chains, PCTL allows specifying almost sure persistence and,
moreover, persistence properties with arbitrary lower or upper bounds on the probability.
This is stated by the following theorem.
Theorem 10.48.
Persistence Probabilities are PCTL-Deﬁnable
For ﬁnite Markov chain M, state s of M and interval J ⊆[0, 1]:
s |= PJ(♦P=1(□a))
iﬀ
Pr(s |= ♦□a) ∈J.
Proof: This result follows by Theorem 10.27 (page 775) and the observation that for each
BSCC T of M: (i) if T ⊆Sat(a), then Pr(t |= □a) = 1 for all states t ∈T, and (ii) if
T \ Sat(a) ̸= ∅, then Pr(t |= ♦□a) = 0 for all states t ∈T.
In particular, the requirement that a persistence property holds almost surely for a cer-
tain state s (i.e., Pr(s |= ♦□a) = 1) is given by the PCTL formula P=1(♦P=1(□a)).

796
Probabilistic Systems
Let PJ(♦□Φ) denote the PCTL formula to express a probability bound on persistence
properties.
10.3
Linear-Time Properties
The previous section has introduced the branching-time temporal logic PCTL, and has
presented a model-checking algorithm for this logic for ﬁnite Markov chains. This section
deals with linear-time properties; see Chapter 3. Recall that an LT property is a set of
inﬁnite traces. The quantitative model-checking problem that we are confronted with is:
given a ﬁnite Markov chain M and an ω-regular property P, compute the probability for
the set of paths in M for which P holds. Some special cases, like properties of the form
C U B or □♦B, where B and C are sets of states in M, have been discussed before. The
purpose of this section is to generalize these results toward arbitrary ω-regular properties.
Deﬁnition 10.49.
Probability of LT Properties
Let M be a Markov chain and P an ω-regular property (both over AP). The probability
for M to exhibit a trace in P, denoted PrM(P), is deﬁned by
PrM(P) = PrM{ π ∈Paths(M) | trace(π) ∈P }.
This deﬁnition, of course, requires the measurability of the set of paths π with trace(π) ∈
P; see Remark 10.57 on page 804. For state s in M let PrM(s |= P), or brieﬂy, Pr(s |= P),
for PrMs(P), i.e.,
Pr(s |= P) = Prs{ π ∈Paths(s) | trace(π) ∈P }.
Similarly, for the LTL formula ϕ we write PrM(ϕ) for PrM(Words(ϕ))
=
PrM{π ∈
Paths(M) | π |= ϕ}, where |= is the standard LTL satisfaction relation, i.e., π |= ϕ iﬀ
trace(π) ∈Words(ϕ). For state s of M, PrM(s |= ϕ) denotes PrMs(ϕ), i.e.,
Pr(s |= ϕ) = Prs{ π ∈Paths(s) | π |= ϕ }.
Given an ω-regular property P over AP and ﬁnite Markov chain M = (S, P, ιinit, AP, L),
the goal is to compute PrM(P).
As for verifying ω-regular properties, we adopt an
automata-based approach. The main steps of this approach are as follows. The (com-
plement of the) LT property P is represented by means of an automaton A, say. For

Linear-Time Properties
797
regular safety properties this is an automaton for the bad preﬁxes, whereas for ω-regular
properties this is a B¨uchi automaton for the complement of P. It then suﬃces to check a
reachability and persistence property, respectively, on the product M ⊗A.
In order to guarantee that M ⊗A is a Markov chain, however, the automaton A needs
to be deterministic. This is a main diﬀerence with the traditional setting of transition
systems where nondeterministic (ﬁnite-state or B¨uchi) automata do suﬃce. For regular
safety properties we therefore assume A to be a DFA for the bad preﬁxes. For the ω-regular
properties, A is assumed to be a deterministic Rabin automaton (DRA, for short). DRAs
are equally expressive as ω-regular languages. (Recall that deterministic B¨uchi automata
are strictly less expressive than NBAs and therefore do not suﬃce for our purpose).
Rather than checking a reachability or persistence property, determining PrM(P) is re-
duced to computing the probability of accepting runs in the product Markov chain M⊗A.
This is ﬁrst discussed in detail for regular safety properties, and subsequently for ω-regular
properties.
Regular Safety Properties
We ﬁrst consider regular safety properties. Recall that
a safety property is regular whenever all bad preﬁxes constitute a regular language. Let
A = (Q, 2AP, δ, q0, F) be a deterministic ﬁnite automaton (DFA) for the bad preﬁxes of a
regular safety property Psafe. That is,
Psafe = { A0 A1 A2 . . . ∈(2AP)ω | ∀n ⩾0. A0 A1 . . . An ̸∈L(A) }.
Without loss of generality, the transition function δ is assumed to be total, i.e., δ(q, A) is
deﬁned for each A ⊆AP and each state q ∈Q. Furthermore, let M = (S, P, ιinit, AP, L)
be a ﬁnite Markov chain. Our interest is to compute the probability
PrM(Psafe) = 1 −

s∈S
ιinit(s) · Pr(s |= A)
for M to generate a trace in Psafe, i.e., a trace such that none of its preﬁxes is accepted
by A. The probability Pr(s |= A) is given by
Pr(s |= A)
=
PrM
s { π ∈Paths(s) | pref(trace(π)) ∩L(A) ̸= ∅}
=
PrM
s { π ∈Paths(s) | trace(π) /∈Psafe }
where pref(A0 A1 . . .) denotes the set of all ﬁnite preﬁxes of the inﬁnite word A0 A1 . . . ∈
(2AP)ω. The value Pr(s |= A) can be written as the (possibly inﬁnite) sum:
Pr(s |= A) =

bπ
P(π)

798
Probabilistic Systems
where π ranges over all ﬁnite path fragments s0 s1 . . . sn starting in s0 = s such that (1)
trace(s0 s1 . . . sn) = L(s0) L(s1) . . . L(sn) ∈L(A), and (2) the length n of π is minimal
according to (1), i.e., trace(s0 s1 . . . si) /∈L(A) for all 0 ⩽i < n. Condition (2) is equivalent
to the requirement that trace(π) is a minimal bad preﬁx of Psafe.
Computing the values Pr(s |= A) by using these sums may be diﬃcult.
Instead, we
adapt the techniques for checking regular safety properties of transition systems to the
probabilistic case. This involves the product of M and A which is deﬁned as follows.
Deﬁnition 10.50.
Product Markov Chain
Let M = (S, P, ιinit, AP, L) be a Markov chain and A = (Q, 2AP, δ, q0, F) be a DFA. The
product M ⊗A is the Markov chain:
M ⊗A = (S × Q, P′, ι′
init, { accept }, L′)
where L′(⟨s, q⟩) = { accept } if q ∈F and L′(⟨s, q⟩) = ∅otherwise, and
ι′
init(⟨s, q⟩) =

ιinit(s)
if q = δ(q0, L(s))
0
otherwise.
The transition probabilities in M ⊗A are given by
P′(⟨s, q⟩, ⟨s′, q′⟩) =

P(s, s′)
if q′ = δ(q, L(s′))
0
otherwise.
Since A is deterministic, M⊗A can be viewed as the unfolding of M where the automaton
component q of the states ⟨s, q⟩in M⊗A records the current state in A for the path frag-
ment taken so far. More precisely, for each (ﬁnite or inﬁnite) path fragment π = s0 s1 s2 . . .
in M there exists a unique run q0 q1 q2 . . . in A for trace(π) = L(s0) L(s1) L(s2) . . . and
π+ = ⟨s0, q1⟩⟨s1, q2⟩⟨s2, q3⟩. . .
is a path fragment in M⊗A. Vice versa, every path fragment in M⊗A which starts in state
⟨s, δ(q0, L(s))⟩arises from the combination of a path fragment in M and a corresponding
run in A.
Note that the DFA A does not aﬀect the probabilities.
That is, for each
measurable set Π of paths in M and state s,
PrM
s (Π) = PrM⊗A
⟨s,δ(q0,L(s))⟩{ π+ | π ∈Π }



Π+

Linear-Time Properties
799
where the superscripts M and M ⊗A are used to indicate the underlying Markov chain.
In particular, if Π is the set of paths that start in s and refute Psafe, i.e.,
Π = { π ∈PathsM(s) | pref(trace(π)) ∩L(A) ̸= ∅},
the set Π+ is the set of paths in M ⊗A that start in ⟨s, δ(q0, L(s))⟩and eventually reach
an accept state of A:
Π+ = { π+ ∈PathsM⊗A(⟨s, δ(q0, L(s))⟩) | π+ |= ♦accept }.
Recall that the atomic proposition accept characterizes the set of states ⟨s, q⟩where q is
an accept state of A. Thus, the paths satisfying ♦accept agree with the event ♦B where
B = S × F. This shows that PrM(s |= Psafe) can be derived from the probability for the
event ♦accept in M ⊗A. This is formally stated in the following theorem.
Theorem 10.51.
Quantitative Analysis for Safety Properties
Let Psafe be a regular safety property, A a DFA for the set of bad preﬁxes of Psafe, M a
Markov chain, and s a state in M. Then:
PrM(s |= Psafe)
=
PrM⊗A(⟨s, qs⟩̸|= ♦accept)
=
1 −PrM⊗A(⟨s, qs⟩|= ♦accept)
where qs = δ(q0, L(s)).
Thus, the computation of the probability for a regular safety property in a Markov chain is
reducible to computing the reachability probability in a product Markov chain. For ﬁnite
Markov chains, the latter problem can be solved by means of the techniques discussed in
Section 10.1.1 (see page 759ﬀ).
For the special case of qualitative regular safety properties, i.e., whether Psafe almost
surely holds in (ﬁnite) M, a graph analysis suﬃces. By means of a DFS- or BFS-based
search algorithm we can check whether a state ⟨s, q⟩with q ∈F is reachable in M ⊗A.
That is, the CTL formula ∃♦accept is checked. For the dual qualitative constraint, i.e.,
whether Psafe holds for M with probability zero, the graph-based techniques suggested in
Corollary 10.29 (page 775) can be exploited to check whether ♦accept holds almost surely
in M ⊗A.
ω-Regular Properties
Let us now consider the wider class of LT properties, i.e., ω-
regular properties. Recall that P is ω-regular whenever P deﬁnes an ω-regular language.
Let P be an ω-regular property. In case the (complement of) P can be described by
a deterministic B¨uchi automaton A, say, the technique for regular safety properties can

800
Probabilistic Systems
be roughly adopted. Consider the product Markov chain M ⊗A (see Deﬁnition 10.50 on
page 798). It can now be shown, using similar arguments as for regular safety properties,
that the probability of the event □♦accept in the product MC M ⊗A coincides with the
probability of refuting P by M, i.e.,
PrM(s |= A) = PrM
s { π ∈Paths(s) | trace(π) ∈Lω(A) }.
The probability of □♦accept can be obtained in polynomial time in the following way.
First, determine the BSCCs of M ⊗A (by a standard graph analysis). For each BSCC B
that contains a state ⟨s, q⟩with q ∈F, determine the probability of eventually reaching
B. This goes as indicated in Corollary 10.34 on page 779. Thus:
Theorem 10.52.
Quantitative Analysis for DBA-Deﬁnable Properties
Let A be a DBA and M a Markov chain. Then, for all states s in M:
PrM(s |= A) = PrM⊗A(⟨s, qs⟩|= □♦accept)
where qs = δ(q0, L(s)).
Proof: The argument is similar as for regular safety properties. The connection between a
path π in M and the corresponding path π+ in M ⊗A (which arises by augmenting the
states si in π = s0 s1 s2 . . . with the automaton states of the unique run for trace(π) in A)
is as follows:
trace(π) ∈Lω(A)
iﬀ
π+ |= □♦accept.
Since A is deterministic, A does not aﬀect the probabilities in M⊗A. Thus, the probability
for path π in M with trace(π) ∈Lω(A) agrees with the probability of generating a path
π+ in M ⊗A which arises by the lifting of path π in M where trace(π) ∈Lω(A). The
latter agrees with the probability for the paths π+ in M ⊗A with π+ |= □♦accept.
Since DBAs do not have the full power of ω-regular languages (see Section 4.3.3 on page
188ﬀ), this approach is not capable of handling arbitrary ω-regular properties. To over-
come this deﬁciency, B¨uchi automata will be replaced by an alternative automaton model
for which their deterministic counterparts are as expressive as ω-regular languages. Such
automata have the same components as NBAs (ﬁnite set of states, and so on) except for
the acceptance condition. We consider Rabin automata. The acceptance condition of a
Rabin automaton is given by a set of pairs of states:
{ (Li, Ki) | 0 < i ⩽k }
with
Li, Ki ⊆Q.
A run of a Rabin automaton is accepting if for some pair (Li, Ki) the states in Li are
visited ﬁnitely often and the states in Ki inﬁnitely often. That is, an accepted run should

Linear-Time Properties
801
satisfy the following LTL formula:
!
1⩽i⩽k
(♦□¬Li ∧□♦Ki).
A deterministic Rabin automaton is deterministic in the usual sense: it has a single initial
state, and for each state and each input symbol, there is at most one successor state.
Deﬁnition 10.53.
Deterministic Rabin Automaton (DRA)
A deterministic Rabin automaton (DRA) is a tuple A = (Q, Σ, δ, q0, Acc) where Q is a
ﬁnite set of states, Σ an alphabet, δ : Q × Σ →Q the transition function, q0 ∈Q the
starting state, and
Acc ⊆2Q × 2Q.
A run for σ = A0A1A2 . . . ∈Σω denotes an inﬁnite sequence q0 q1 q2 . . . of states in A
such that qi
Ai
−−→qi+1 for i ⩾0.
The run q0 q1 q2 . . . is accepting if there exists a pair
(L, K) ∈Acc such that
(∃n ⩾0. ∀m ⩾n. qm /∈L) ∧
∞
∃n ⩾0. qn ∈K

.
The accepted language of A is
Lω(A) = { σ ∈Σω | the run for σ in A is accepting }.
Any DBA can be considered as an DRA in the following way. Assume a DBA is given
with accept set F, i.e., an accepting run should visit some state in F inﬁnitely often. The
DRA with the same states and transitions and with the singleton acceptance condition
Acc = { (∅, F) } is evidently equivalent to this DBA. DRAs are thus at least as expressive
as DBAs.
Example 10.54.
DRA for □♦a
Consider the DBA for the LTL formula □♦a; see Figure 10.9. The alphabet of this DBA
is 2{ a } = { { a }, ∅}. Each accepting run has to visit q1 inﬁnitely often. The DRA with
Acc = { (∅, { q1 }) } is equivalent to this DBA: a run is accepting if and only if state
q1 is visited inﬁnitely often. As the ﬁrst component of the accept condition is ∅, the
requirement that the ﬁrst set is only visited ﬁnitely many times is vacuously true.
Recall that some ω-regular properties cannot be expressed by a DBA. This applies, e.g.,
to persistence properties such as the LTL formula ♦□a. DRAs are more expressive than

802
Probabilistic Systems
q0
q1
a
¬a
¬a
a
Figure 10.9: A DBA for □♦a.
q0
q1
a
¬a
¬a
a
Figure 10.10: A deterministic Rabin automaton for ♦□a.
DBAs. For instance, consider the DRA in Figure 10.10 with the acceptance condition
Acc = { ({ q0 }, { q1 }) }. The accepted language of this DRA is the set of inﬁnite words
whose runs end with a suﬃx that never visits q0, and, thus stays forever in state q1. These
are exactly the words A0 A1 . . . in Words(♦□a). As ♦□a cannot be described by a DBA,
the class of languages accepted by a DRA is strictly larger than the class of languages that
are recognizable by a DBA. In fact, the following fundamental result asserts that DRAs
are as expressive as ω-regular properties.
Theorem 10.55.
DRAs and ω-Regular Languages
The class of languages accepted by DRAs agrees with the class of ω-regular languages.
Proof: The proof of this result is outside the scope of this monograph. The interested
reader is referred to [174] for more details.
Recall that NBAs are also as expressive as ω-regular properties, cf. Theorem 4.32, and
thus DRAs and NBAs are equally expressive. In fact, there exists an algorithm that takes
as input an NBA A and generates an equivalent DRA of size 2O(n log n) where n is the size
of A.
Let us now return to our original problem: the veriﬁcation of quantitative ω-regular
properties over Markov chains. Let M = (S, P, ιinit, AP, L) be a ﬁnite Markov chain and
let A = (Q, 2AP, δ, q0, Acc) be a DRA which accepts the complement of the ω-regular LT
property P. The probability of M to generate traces in Lω(A) can be computed—as for
regular safety properties—on the basis of a product construction. The product of M and
A is deﬁned as the product of a Markov chain and a DFA; see Deﬁnition 10.50 (page 798).

Linear-Time Properties
803
If the acceptance condition of A is
Acc = { (L1, K1), . . . , (Lk, Kk) },
then the sets Li, Ki serve as atomic propositions in M ⊗A. The labeling function is the
obvious one, i.e., if H ∈{L1, . . . , Lk, K1, . . . , Kk}, then H holds in state ⟨s, q⟩of M ⊗A
iﬀq ∈H.
According to the following result, the computation of probabilities for satisfying ω-regular
properties boils down to computing the reachability probabilities for certain bottom strongly
connected components (BSCCs) in M ⊗A. These BSCCs are called accepting. A BSCC
T in M ⊗A is accepting if it fulﬁlls the acceptance condition Acc. More precisely, T is
accepting if and only if there exists some index i ∈{ 1, . . . , k } such that
T ∩(S × Li) = ∅
and
T ∩(S × Ki) ̸= ∅.
Stated in words, there is no state ⟨s, q⟩∈T such that q ∈Li and for some state ⟨t, q′⟩∈T
it holds that q ∈Ki. Thus, once such an accepting BSCC T is reached in M ⊗A, the
acceptance criterion for the DRA A is fulﬁlled almost surely.
Theorem 10.56.
DRA-Based Analysis of Markov Chains
Let M be a ﬁnite Markov chain, s a state in M, A a DRA, and let U be the union of all
accepting BSCCs in M ⊗A. Then:
PrM(s |= A) = PrM⊗A( ⟨s, qs⟩|= ♦U )
where qs = δ(q0, L(s)).
Proof: Let Π be the set of paths π ∈Paths(s) in the Markov chain M such that trace(π) ∈
Lω(A), and Π+ be the set of paths in M ⊗A that are obtained by augmenting the paths
π ∈Π with their corresponding runs in A. Note that the automaton A is deterministic.
Hence, for any path π in M there is a unique run in A for trace(π). As the transition
probabilities in M ⊗A are not aﬀected by the DRA A, it follows that
PrM
s (Π) = PrM⊗A
⟨s,qs⟩(Π+)
with qs = δ(q0, L(s)).
Since the traces of the paths π ∈Π belong to Lω(A), their runs are accepting, i.e., for
some acceptance pair (Li, Ki) of A, Ki is visited inﬁnitely often, and from some moment
on, Li is not visited anymore. Vice versa, trace(π) ∈Lω(A) for any path π in M where

804
Probabilistic Systems
the extended path π+ in M ⊗A fulﬁlls ♦□¬Li ∧□♦Ki for some acceptance pair (Li, Ki)
of A. Hence:
PrM(s |= A) = PrM⊗A{ ⟨s, qs⟩|=
!
1⩽i⩽k
(♦□¬Li ∧□♦Ki) }.
Whether a run ⟨s0, q1⟩⟨s1, q2⟩. . . satisﬁes the acceptance condition of a DRA only depends
on the states that are visited inﬁnitely often. By Theorem 10.27 (page 775), such states
almost surely form a BSCC in M⊗A. Hence, the probability for "
1⩽i⩽k(♦□¬Li ∧□♦Ki)
in M ⊗A coincides with the probability of reaching an accepting BSCC in M ⊗A.
This theorem yields that the probability of M to generate a trace in Lω(A) is given by
PrM(A) =

s∈S
ιinit(s) · PrM⊗A(⟨s, δ(q0, L(s))⟩|= ♦U)
.
This result suggests determining the BSCCs in the product Markov chain M⊗A to check
which BSCC is accepting (i.e., determine U), and then to compute for each of the accepting
BSCCs the reachability probability. The ﬁrst stage of this algorithm can be performed by
a standard graph analysis. To check whether a BSCC is accepting amounts to checking
all pairs (Li, Ki) ∈Acc. Finally, reachability probabilities can be determined by solving
a set of linear equations, as indicated earlier in this chapter (see Section 10.1.1). The size
of this linear equation system is linear in the size of the Markov chain M and the DRA
A. The overall time complexity of this procedure is
O(poly(size(M), size(A))).
To check whether almost all traces of M are accepted by the DRA A, it suﬃces to check
whether all BSCCs of M ⊗A that are reachable from some initial state ⟨s, δ(q0, L(s))⟩in
M ⊗A for which ιinit(s) > 0 are accepting.
Remark 10.57.
Measurability of ω-Regular Properties
So far, we have implicitly assumed the measurability of ω-regular properties. The fact
that ω-regular properties are indeed measurable follows by the following argument.
Let M = (S, P, ιinit, AP, L) be a Markov chain and P an ω-regular property which is
represented by the DRA A = (Q, 2AP, δ, q0, Acc) with Acc = { (L1, K1), . . . , (Lk, Kk) }.
We need to prove that:
Π = { π ∈Paths(M) | trace(π) ∈Lω(A)
  
=P
}
is measurable. Each path π = s0 s1 . . . ∈Π is lifted to a path π+ in the product Markov
chain M⊗A such that π+ = ⟨s0, q1⟩⟨s1, q2⟩. . .. The path π+ results from π by “adding”
the states in A of the (unique) run q0 q1 q2 . . . in A for trace(π). Then:

Linear-Time Properties
805
π ∈Π, i.e., trace(π) ∈Lω(A)
iﬀ
the (unique) run q0 q1 q2 . . . for trace(π) in A is accepting
iﬀ
the path π+ = ⟨s0, q1⟩⟨s1, q2⟩. . . in M ⊗A satisﬁes
"
1⩽i⩽k
(♦□¬Li ∧□♦Ki).
Let ϕi = ♦□¬Li ∧□♦Ki, for 0 < i ⩽k, and Πi the set of all paths π in M such that
π+ |= ϕi. Clearly, Π = Π1 ∪. . . ∪Πk. To show the measurability of Π it thus suﬃces
to prove the measurability of Πi. Let us consider Πi in somewhat more detail. It follows
that Πi = Π♦□
i
∩Π□♦
i
where Π♦□
i
is the set of paths π in M such that π+ |= ♦□¬Li, and
Π□♦
i
is the set of paths π in M such that π+ |= □♦Ki. It remains to show that Π♦□
i
and
Π□♦
i
are measurable. The set Π♦□
i
can be written as

n⩾0
1
m⩾n

s0...sn...sm
Cyl(s0 . . . sn . . . sm)
where s0 . . . sn . . . sm ranges over all ﬁnite path fragments in M such that qj ̸∈Li for n <
j ⩽m+1 for the induced run q0 q1 . . . qn+1 . . . qm+1 in DRA A. Thus, Π♦□
i
is measurable.
Similarly, the set Π□♦
i
can be written as
1
n⩾0

m⩾n

s0...sn...sm
Cyl(s0 . . . sn . . . sm)
where s0 . . . sn . . . sm ranges over all ﬁnite path fragments in M such that qm+1 ∈Ki for
the induced run q0 q1 . . . qn+1 . . . qm+1 in A. Hence, both sets Π♦□
i
and Π□♦
i
arise through
countable unions and intersections of cylinder sets and are therefore measurable.
Although the approach with DRA is conceptually simple, it has the drawback of a double
exponential blowup when starting with an LTL formula for the LT property. We mention
without proof that there exist LTL formulae ϕn of size O(poly(n)) for which the small-
est DRA representation for ϕn has 22n states. Using alternative techniques, the double
exponential blowup can be reduced to a single exponential blowup. The details of these
advanced techniques fall outside the scope of this monograph. Algorithms with a better
asymptotic worst-case complexity cannot be expected, as the qualitative model-checking
problem for ﬁnite Markov chains “given a ﬁnite Markov chain M and an LTL formula ϕ,
does Pr(M |= ϕ) = 1 hold?” is PSPACE-complete. This result is due to Vardi [407] and
stated here without proof.
Theorem 10.58.
The qualitative model-checking problem for ﬁnite Markov chains is PSPACE-complete.

806
Probabilistic Systems
10.4
PCTL∗and Probabilistic Bisimulation
This section introduces probabilistic bisimulation for Markov chains, and shows that this
notion of bisimulation coincides with PCTL equivalence. That is to say, PCTL equivalence
serves as a logical characterization of probabilistic bisimulation. Vice versa, probabilistic
bisimulation serves as an operational characterization of PCTL equivalence. It is shown
that the same applies to PCTL∗, a logic that results from the state formulae in PCTL
and allowing LTL formulae as path formulae. These results may thus be considered as the
quantitative analogue to the result that bisimulation on transition systems coincides with
CTL and CTL∗equivalence; see Theorem 7.20 (page 469).
10.4.1
PCTL∗
The logic PCTL∗extends PCTL by dropping the requirement that any temporal operator
must be proceeded by a state formula. In addition, it allows for boolean combinations
of path formulae. Thus, the logic PCTL∗permits Boolean combinations of formulae of
the form PJ(ϕ) where the interval J speciﬁes a probability bound, whereas ϕ is an LTL
formula whose substate formulae are PCTL∗state formulae. The logic PCTL∗is strictly
more expressive than LTL (with probability bounds) and PCTL.
Deﬁnition 10.59.
Syntax of PCTL∗
PCTL∗state formulae over the set AP of atomic propositions are formed according to the
following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   PJ(ϕ)
where a ∈AP, ϕ is a path formula and J ⊆[0, 1] is an interval with rational bounds.
PCTL∗path formulae are formed according to the following grammar:
ϕ ::= Φ
   ϕ1 ∧ϕ2
   ¬ϕ
   
⃝ϕ
   ϕ1 U ϕ2
where Φ is a PCTL∗state formula.
Other Boolean operators and the temporal modalities ♦, □, W , and R can be derived as
in CTL∗. The step-bounded until operator has been omitted from the syntax of PCTL∗
path formulae for the sake of simplicity. It can be deﬁned in terms of the other operators
in the following way:
ϕ1 U ⩽nϕ2 =
!
0⩽i⩽n
ψi
where ψ0 = ϕ2 and ψi+1 = ϕ1 ∧⃝ψi for i ⩾0.

PCTL∗and Probabilistic Bisimulation
807
The logic PCTL can thus be regarded as a sublogic of PCTL∗.
For a given Markov chain M = (S, P, ιinit, AP, L), the satisfaction relation for PCTL∗
state- and path formulae is deﬁned as for PCTL and CTL∗, respectively. For example,
s |= PJ(ϕ)
iﬀ
Pr(s |= ϕ) ∈J
where Pr(s |= ϕ) = Prs{ π ∈Paths(s) | π |= ϕ }.
The satisfaction relation for the
path formulae is exactly as in CTL∗.
Let SatM(Φ), or brieﬂy Sat(Φ), denote the set
{ s ∈S | s |= Φ }. A PCTL∗state formula Φ is said to hold for M, denoted M |= Φ, if
s |= Φ for all states s ∈S with ιinit(s) > 0.
The equivalence of PCTL∗state formulae is deﬁned as for PCTL, i.e.,
Φ ≡Ψ
iﬀ
SatM(Φ) = SatM(Ψ) for all Markov chains M.
(It is assumed that the set AP of atomic propositions is ﬁxed.) In case we are restricted
to ﬁnite Markov chains, we write ≡f, i.e.,
Φ ≡f Ψ
iﬀ
SatM(Φ) = SatM(Ψ) for all ﬁnite Markov chains M.
The results established for repeated reachability and persistence properties (see Theorem
10.47, page 795 and Theorem 10.48, page 795, respectively, can now be rephrased by
PJ(□♦Φ)
≡f
PJ(♦P=1(□P=1(♦Φ))),
PJ(♦□Φ)
≡f
PJ(♦P=1(□Φ)).
Let us now consider the model-checking problem for PCTL∗, i.e., for a given ﬁnite Markov
chain M and PCTL formula Φ, does M |= Φ hold? This problem can be tackled by
combining the procedure for PCTL model checking and the techniques discussed before
for the quantitative analysis of LTL formulae. The main procedure goes along the lines of
the model-checking algorithm for CTL∗and relies on a bottom-up treatment of the parse
tree of Φ. For each inner node (corresponding to state subformula Ψ of Φ), the satisfac-
tion set Sat(Ψ) = { s ∈S | s |= Ψ } is computed. For the propositional logic fragment
this computation is obvious and is as for CTL. The interesting case is a state formula of
the form Ψ = PJ(ϕ). In order to treat such formulae, ﬁrst all maximal state subformu-
lae of ϕ are replaced by new atomic propositions. Intuitively, these atomic propositions
represent the satisfaction sets for these subformulae. Due to the bottom-up nature of
the model-checking algorithm, these satisfaction sets have been determined already, and
this replacement amounts to labeling the states in these sets. Applying this replacement
procedure to ϕ yields an LTL formula ϕ′. Using the techniques explained in Section 10.3,
one computes for each state s the probability Pr(s |= ϕ′) of satisfying ϕ′ (and thus ϕ).
The returned result is then:
Sat(Ψ) = { s ∈S | Pr(s |= ϕ) ∈J }
.

808
Probabilistic Systems
Due to the double-exponential transformation of an LTL formula ϕ′ into a deterministic
Rabin automaton, the time complexity of model-checking PCTL∗is double exponential
in |ϕ| and polynomial in the size of the Markov chain M. Using alternative techniques
may yield a single exponential time complexity in |ϕ|. A further improvement cannot be
expected due to the PSPACE-completeness of the qualitative model-checking problem for
LTL; see Theorem 10.58, page 805.
10.4.2
Probabilistic Bisimulation
To compare the behavior of transition systems, bisimulation and simulation relations have
been extensively treated in Chapter 7. Bisimulation relations are equivalences requiring
two bisimilar states to be equally labeled and exhibit identical stepwise behavior. It can
be lifted to transition systems by comparing their initial states. Bisimilar states thus need
to be able to mimic each individual step of each other. This section considers a notion of
bisimulation on Markov chains that takes the transition probabilities into account. They
can be viewed as a quantitative variant of bisimulation for transition systems. The crucial
idea is to require bisimulation-equivalent states to have the same transition probability
for each equivalence class (under bisimulation). As for transition systems, bisimulation-
equivalent states must be equally labeled.
Deﬁnition 10.60.
Bisimulation for Markov Chains
Let M = (S, P, ιinit, AP, L) be a Markov chain. A probabilistic bisimulation on M is an
equivalence relation R on S such that for all states (s1, s2) ∈R:
1. L(s1) = L(s2).
2. P(s1, T) = P(s2, T) for each equivalence class T ∈S/R.
States s1 and s2 are bisimulation-equivalent (or bisimilar), denoted s1 ∼M s2, if there
exists a bisimulation R on M such that (s1, s2) ∈R.
A probabilistic bisimulation is often referred to as bisimulation in the sequel. The ﬁrst
condition states that the states are equally labeled.
The last condition requires that
for bisimilar states the probability of moving by a single transition to some equivalence
class is equal. Recall that P(s, T) = 
t∈T
P(s, t) denotes the probability of moving from
state s directly to some state in T. As opposed to bisimulation on states in transition
systems (see Deﬁnition 7.7 on page 456), any probabilistic bisimulation is required to be

PCTL∗and Probabilistic Bisimulation
809
an equivalence—otherwise it would be senseless to refer to equivalence classes in the last
constraint. This is in contrast to the nonprobabilistic case where bisimulation relations for
a single transition system TS need not be symmetric (although the coarsest bisimulation
∼TS is, in fact, an equivalence).
As for transition systems, the above notion of (probabilistic) bisimulation equivalence for
the states of a single Markov chain can be extended to compare two Markov chains M1,
M2. Let M1, M2 be Markov chains over the same set of atomic propositions with initial
distributions ι1
init and ι2
init, respectively. Consider the Markov chain M = M1 ⊎M2 that
results from the disjoint union of M1 and M2. Then M1 and M2 are bisimilar if
ι1
init(T) = ι2
init(T)
for each bisimulation equivalence class T of M = M1 ⊎M2.
Here, ιinit(T) denotes

t∈T
ιinit(t).
Example 10.61.
Bisimulation for Markov Chains
Consider the Markov chain in Figure 10.11. (Note that it consists of two mutually un-
reachable parts.) The reﬂexive, symmetric, and transitive closure of the relation
R = { (s1, s2), (u1, u3), (u2, u3), (v1, v3), (v2, v3) }
is a probabilistic bisimulation. This can be seen as follows. The equivalence classes are
T1 = [s1]∼= { s1, s2 }, T2 = [u1]∼= { u1, u2, u3 } and T3 = [v1]∼= { v1, v2, v3 }. It follows
that
P(s1, T1) = P(s2, T1) = 0, P(s1, T2) = P(s2, T2) = 2
3, P(s1, T3) = P(s2, T3) = 1
3.
In a similar way, it can be established that for all states in T2 and T3 the probabilities of
transition to each of the equivalence classes are the same.
Deﬁnition 10.62.
Bisimulation Quotient
Let M = (S, P, ιinit, AP, L) be a Markov chain. The quotient Markov chain M/ ∼M is
deﬁned by
M/∼M= (S/∼M, P′, ι′
init, AP, L′)
where P′([s]∼, [t]∼) = P(s, [t]∼), ι′
init([s]∼) = 
s′∈[s] ιinit(s) and L′([s]∼) = L(s).
The state space of the quotient Markov chain M/ ∼M is the set of equivalence classes
under ∼M. The transition probability from equivalence class [s]∼to [t]∼equals P(s, [t]∼).

810
Probabilistic Systems
s1
∅
u1
{ a }
u2
{ a }
v1
{ b }
v2
{ b }
1
1
1
3
1
2
1
6
1
6
1
6
1
2
3
s2
∅
u3
{ a }
v3 { b }
2
3
1
3
1
1
Figure 10.11: Two examples of Markov chains for which s1 ∼M s2.
Note that this is well-deﬁned as P(s, T) = P(s′, T) for all s ∼s′ and all bisimulation
equivalence classes T.
Example 10.63.
The Craps Game
Consider the Markov chain modeling the craps game; see Figure 10.3 (page 751). Assume
all states are labeled with the empty set, except for L(won) = { won }. The equivalence
relation that induces the following partitioning of the state space
{ start }, { won }, { lost }, { 4, 10 }, { 5, 9 }, { 6, 8 }
is a probabilistic bisimulation. This can be seen as follows. The fact that state won is not
bisimilar to any other state is clear as it is labeled diﬀerently. State lost is not bisimilar to
any other state, as it is the only absorbing state labeled with ∅. As state start is the only
state that can move to { won } with probability 2
9, it is not bisimilar to any other state.
Consider now, e.g., states 5 and 9. Both states can move to won with the same probability.
The same applies to any equivalence class T. States 5 and 9 are thus bisimilar. A similar
reasoning applies to the other states. The quotient Markov chain is depicted in Figure
10.12.
The remainder of this section is focused on establishing that bisimulation-equivalent states
satisfy the same PCTL∗formulae. This means in particular that s and any state in [s]∼
satisfy the same PCTL∗formulae.
Checking whether M |= Φ for PCTL∗formula Φ
may thus be established by checking M/ ∼|= Φ. In fact, it will be shown that PCTL
equivalence, PCTL∗equivalence, and probabilistic bisimulation coincide.
This means
that in order to show that two states are not bisimilar it suﬃces to indicate a PCTL (or
PCTL∗) formula that distinguishes them.
The key to establishing that bisimulation-equivalent states satisfy the same PCTL∗for-
mula is the following observation. Let s ∼M s′ where s and s′ are states in the Markov

PCTL∗and Probabilistic Bisimulation
811
1
1
25
36
4,10
1
12
1
6
6,8
5,9
2
9
3
4
13
18
1
6
2
9
5
18
1
9
1
6
1
6
1
9
1
6
won
lost
start
5
36
1
6
Figure 10.12: Bisimulation quotient for the craps game.
chain M. Then, the probability measures PrM
s
and PrM
s′
agree for all measurable sets
of paths that are closed under statewise bisimulation equivalence. In order to formally
prove this property, we need some additional notations and some standard concepts from
measure theory. Let us ﬁrst lift the notion of bisimulation to paths.
Deﬁnition 10.64.
Bisimulation-Equivalent Paths
The inﬁnite paths π1 = s0,1 s1,1 s2,1 . . . and π2 = s0,2 s1,2 s2,2 . . . in a Markov chain M are
bisimulation equivalent, denoted π1 ∼M π2, if they are statewise bisimilar:
π1 ∼M π2
if and only if
si,1 ∼M si,2 for all i ⩾0
.
Deﬁnition 10.65.
Bisimulation-Closed σ-Algebra
Let M be a Markov chain with state space S and T0, T1, . . . , Tn ∈S/ ∼M be equiv-
alence classes of ∼M.
The bisimulation-closed σ-algebra EM
∼M denotes the σ-algebra
generated by the sets Cyl(T0 T1 . . . Tn) where Cyl(T0 T1 . . . Tn) is the set of all paths
t0 t1 . . . tn tn+1 tn+2 . . . with ti ∈Ti for 0 ⩽i ⩽n.
All sets in the bisimulation-closed σ-algebra EM
∼are measurable with respect to the stan-

812
Probabilistic Systems
dard σ-algebra EM associated with M (see Deﬁnition 10.10). That is to say:
EM
∼
⊆EM
.
This inclusion is due to the fact that the basic events Cyl(T0 T1 . . . Tn) of the σ-algebra EM
∼
are countable unions of basic elements—cylinder sets spanned by the ﬁnite path fragments
in M—of the σ-algebra EM. Formally:
Cyl(T0 T1 . . . Tn) =

t0 t1 . . . tn ∈Pathsﬁn(M)
ti∈Ti,0⩽i⩽n
Cyl(t0 t1 . . . tn)
where T0, T1, . . . , Tn ∈S/∼M are bisimulation-equivalence classes. Thus, the bisimulation-
closed σ-algebra EM
∼is a so-called sub-σ-algebra of the σ-algebra EM. We refer to the
elements of EM
∼as bisimulation-closed events.
In fact, the events in the bisimulation-closed σ-algebra EM
∼are bisimulation-closed mea-
surable sets of paths in EM.
Let Π ∈EM be a measurable set of paths.
Note that
measurability is understood with respect to the standard σ-algebra EM on the paths of
M. The set Π is bisimulation-closed if for any π1 ∈Π and π2 such that π1 ∼M π2 it holds
that π2 ∈Π. That is:
EM
∼
= { Π ∈EM | Π is bisimulation-closed }.
The following result asserts that the probability measure PrM
s
for bisimulation-closed sets
of paths agree for bisimilar states.
Lemma 10.66.
Preservation of Probabilities of Bisimulation-Closed Events
Let M be a Markov chain. For all states s1, s2 in M:
s1 ∼M s2
implies
PrM
s1 (Π) = PrM
s2 (Π)
for all bisimulation-closed events Π ⊆Paths(M).
Proof: Since the bisimulation-closed σ-algebra EM
∼is closed under intersection, by stan-
dard results of measure theory it holds that: for ﬁxed function f : (S/ ∼M)+ →[0, 1],
there exists at most one probability measure μ on the bisimulation-closed σ-algebra EM
∼
such that
μ(Cyl(T0 T1 . . . Tn)) = f(T0 T1 . . . Tn)
for all bisimulation equivalence classes Ti, 0 ⩽i ⩽n.

PCTL∗and Probabilistic Bisimulation
813
This result yields that it suﬃces to show that s1 ∼M s2 implies that PrM
s1 and PrM
s2 agree
on the basic events Cyl(T0 T1 . . . Tn) of EM
∼. For bisimulation equivalence classes T, U of
M, let P(T, U) denote the value P(t, U) for all (some) t ∈T. Then we have
PrM
s1 ( Cyl(T0T1 . . . Tn) )
=
P(T0, T1) · P(T1, T2) . . . · P(Tn−1, Tn)
=
PrM
s2 ( Cyl(T0T1 . . . Tn) )
provided that s1, s2 ∈T0. Otherwise, i.e., if s1, s2 /∈T0, then:
PrM
s1 ( Cyl(T0T1 . . . Tn) ) = 0 = PrM
s2 ( Cyl(T0T1 . . . Tn) ).
For ﬁnitely-branching transition systems, CTL-equivalence, CTL∗-equivalence, and bisim-
ulation equivalence all coincide. An analogous result holds for PCTL, PCTL∗, and prob-
abilistic bisimulation equivalence. In fact, the restriction to ﬁnitely-branching systems is
not necessary. That is, PCTL, PCTL∗, and probabilistic bisimulation equivalence coincide
for any arbitrary, possibly inﬁnite, Markov chain. In the probabilistic setting, nonbisimilar
states can even be distinguished by a formula of a (small) fragment of PCTL that just
consists of atomic propositions, conjunction, and the operator P⩽p(⃝·). As in the non-
probabilistic setting, the until operator is thus not necessary for logically characterizing
bisimulation. As opposed to the nonprobabilistic case where full propositional logic (con-
taining conjunction and negation) is necessary, negation is not needed in the probabilistic
setting.
Let PCTL−denote the following fragment of PCTL. State formulae in PCTL−are formed
according to
Φ
::=
a | Φ1 ∧Φ2 | P⩽p(⃝Φ)
where a ∈AP and p is a rational number in [0, 1]. Negation is present neither as an
operator in PCTL−nor can it be expressed. The results indicated above are summarized
in the following theorem:
Theorem 10.67.
PCTL/PCTL∗and Bisimulation Equivalence
Let M be a Markov chain and s1, s2 states in M. Then, the following statements are
equivalent:
(a) s1 ∼M s2.
(b) s1 and s2 are PCTL∗-equivalent, i.e., fulﬁll the same PCTL∗formulae.

814
Probabilistic Systems
(c) s1 and s2 are PCTL-equivalent, i.e., fulﬁll the same PCTL formulae.
(d) s1 and s2 are PCTL−-equivalent, i.e., fulﬁll the same PCTL−formulae.
Proof: (a) =⇒(b): Using Lemma 10.66 on page 812 it can be shown by structural induction
on the syntax of PCTL∗state formula Φ and PCTL∗path formula ϕ:
(1) For states s1, s2 in M, if s1 ∼M s2, then:
(1.1) s1 |= Φ if and only if s2 |= Φ.
(1.2) Pr(s1 |= ϕ) = Pr(s2 |= ϕ).
(2) For paths π1, π2 in M, if π1 ∼M π2, then π1 |= ϕ if and only if π2 |= ϕ.
The proof of the ﬁrst part is fairly similar to the nonprobabilistic case (see Theorem 7.20
on page 469). We only consider statement (1.2) and assume as an induction hypothesis
that (2) holds for ϕ. Let s1 ∼M s2 and Π be the set of paths in M satisfying ϕ, i.e.,
Π = { π ∈Paths(M) | π |= ϕ }. The induction hypothesis applied to ϕ (see item (2))
yields that Π is bisimulation-closed. Hence, by Lemma 10.66 it follows that
Pr(s1 |= ϕ) = PrM
s1 (Π) = PrM
s2 (Π) = Pr(s2 |= ϕ).
(b) =⇒(c) and (c) =⇒(d): Obvious, since PCTL is a sublogic of PCTL∗and PCTL−is
a sublogic of PCTL.
(c) =⇒(a): Prior to proving that (a) is a consequence of (d), we ﬁrst treat a simpler
case and prove that PCTL-equivalent states in a ﬁnite Markov chain are probabilistically
bisimilar. The aim of this step is to show that roughly the same arguments as in the
nonprobabilistic case can be applied. We have to show that the relation
R = { (s1, s2) ∈S × S | s1 ≡PCTL s2 }
is a probabilistic bisimulation. (Here, ≡PCTL denotes PCTL equivalence of states.) Let
(s1, s2) ∈R. As s1 and s2 fulﬁll the same atomic propositions, it follows that L(s1) =
L(s2). It remains to prove that P(s1, T) = P(s2, T) for each equivalence class T under
R. Let T, U be R-equivalence classes with T ̸= U, and PCTL formula ΦT,U be such that
Sat(ΦT,U) ⊆T and Sat(ΦT,U) ∩U = ∅. Deﬁne:
ΦT =

U∈S/∼M
U̸=T
ΦT,U.

PCTL∗and Probabilistic Bisimulation
815
It is evident that Sat(ΦT ) = T. That is to say, ΦT is a PCTL master formula for the
equivalence class T. Without loss of generality, assume P(s1, T) ⩽P(s2, T). Let s1 |=
P⩽p(ΦT ) where p = P(s1, T). As s1 ≡PCTL s2, it follows that s2 |= P⩽p(ΦT ). But then
P(s1, T) = p = P(s2, T). This yields condition (2) for R.
(d) =⇒(a): Assume M is an arbitrary (possibly inﬁnite) Markov chain. The goal is to
show that
R = { (s1, s2) ∈S × S | s1 ≡PCTL−s2 }
is a probabilistic bisimulation. Let (s1, s2) ∈R. The fact that s1 and s2 are equally
labeled is established as in the previous part of the proof (i.e., (c) implies (a)). However,
the above argument to prove that P(s1, T) = P(s2, T) for any R-equivalence class T is not
applicable in case there are inﬁnitely many bisimulation equivalence classes. (Note that
then ΦT would be deﬁned by an inﬁnite conjunction.) Let the satisfaction sets Sat(Φ)
for PCTL−state formula Φ be basic events on the state space S of M and ES be the
smallest σ-algebra on S that contains the sets Sat(Φ). Since the set of all PCTL−formulae
is countable, any PCTL−-equivalence class T ∈S/R can be written as the countable
intersection of the satisfaction sets Sat(Φ) where Φ is a PCTL−formula and T ⊆Sat(Φ).
Thus, all PCTL−-equivalence classes T ∈S/R belong to ES.
As PCTL−permits conjunction, the set of all satisfaction sets Sat(Φ) is closed under ﬁnite
intersections. By a standard result of measure theory, we have that for every probability
measure μ1, μ2 on ES:
μ1(Sat(Φ)) = μ2(Sat(Φ)) for any PCTL−formula Φ
implies
μ1 = μ2.
In the remainder of the proof, this result is exploited to show that Pr(s1, T) = Pr(s2, T)
for all states s1, s2 with (s1, s2) ∈R and all T ∈S/R.
For state s in M, let the probability measure μs on ES be deﬁned by
μs(T) = P(s, T) =

t∈T
P(s, t)
for T ∈ES.
Clearly, μs(Sat(Φ)) = P(s, Sat(Φ)) for any PCTL−formula Φ. The goal is now to show
that μs1 = μs2 for PCTL−-equivalent states s1 and s2. This is established as follows.
Let (s1, s2) ∈R and Φ be a PCTL−formula such that P(s1, Sat(Φ)) equals p, say, and
P(s2, Sat(Φ)) equals q. Without loss of generality, assume p ⩽q. Then:
s1 |= P⩽p(⃝Φ).
As P⩽p(⃝Φ) is a PCTL−formula and (s1, s2) ∈R, it follows that s2 |= P⩽p(⃝Φ). But
then q = P(s2, Sat(Φ)) ⩽p ⩽q, and hence:
μs1(Sat(Φ)) = p = q = μs2(Sat(Φ)).

816
Probabilistic Systems
The probability measures μs1 and μs2 on ES thus coincide for all basic events Sat(Φ) of
ES. As the set of basic events Sat(Φ) is closed under intersection, any measure on ES
is uniquely determined by its values on the basic events. Thus, μs1(T) = μs2(T) for all
T ∈ES. All PCTL−-equivalence classes T ∈S/R belong to ES, so:
P(s1, T) = μs1(T) = μs2(T) = P(s2, T).
Thus, R is a probabilistic bisimulation.
The importance of Theorem 10.67 is manifold. First, it states that bisimulation equiv-
alence preserves all quantitative PCTL∗-deﬁnable properties. This justiﬁes considering
bisimulation-equivalent states to be “equal”. Second, Theorem 10.67 asserts that bisimu-
lation equivalence is the coarsest equivalence enjoying this property. That is to say, any
strictly coarser equivalence identiﬁes states with diﬀerent probabilistic behavior in the
sense of PCTL∗-deﬁnable properties, and even some relatively simple properties that can
be stated in PCTL−. Moreover, Theorem 10.67 can be used to prove that two states are
not bisimulation equivalent. In order to do so, it suﬃces to provide a PCTL∗formula
(or PCTL−or PCTL formula) that distinguishes the given states. Finally, observe that
probabilistic bisimulation equivalence of states s1 and s2 in a Markov chain M implies
bisimulation equivalence of s1 and s2 (as considered in Chapter 7) in the transition system
associated with M.
Example 10.68.
Craps Game
Consider the probabilistic bisimulation quotient for the craps game, see Figure 10.12. It
follows that s4,10 ̸∼M s6,8, since there exists a PCTL formula, e.g., P< 1
6 (⃝won), which
holds in s4,10 but not in s6,8.
10.5
Markov Chains with Costs
In addition to the probability of certain events, it is natural to analyze the average be-
havior of executions in a Markov chain. For instance, for a communication system where
a sender and a receiver can transfer messages via an unreliable channel, an interesting
measure of interest is the expected number of attempts to send a message until correct
delivery. Another example is a multiprocessor system where one might be interested in
the average number of steps between two successive failures—the mean “time” between
failures. For a battery-powered embedded system, a measure of interest is the expected
power consumption during operation.

Markov Chains with Costs
817
The aim of this section is to consider an extension of Markov chains, called Markov reward
chains, and to consider expected measures. A Markov reward chain is a Markov chain
in which states (or transitions) are augmented with rewards, natural numbers that can
be interpreted as bonuses, or dually as costs. We consider equipping states with rewards.
The idea is that whenever a state s is left, the reward associated with s is earned.
Deﬁnition 10.69.
Markov Reward Model (MRM)
A Markov reward model (MRM) is a tuple (M, rew) with M a Markov chain with state
space S and rew : S →IN a reward function that assigns to each state s ∈S a non-negative
integer reward rew(s).
Intuitively, the value rew(s) stands for the reward earned on leaving state s. Formally,
the cumulative reward for a ﬁnite path π = s0 s1 . . . sn is deﬁned by
rew(π) = rew(s0) + rew(s1) + . . . + rew(sn−1).
Note that the reward of the last state sn in the path π is not considered.
Example 10.70.
Zeroconf Protocol
Consider the Markov chain modeling the behavior of a single station in the zeroconf
protocol 10.5 (page 751). For convenience, the Markov chain is depicted in Figure 10.13.
We consider three reward functions for this model:
s0
s1
s2
s3
s4
start
p
p
p
1−p
1−p
1−p
1−p
q
ok
s8
s7
1
1−q
s5
s6
error
p
1
Figure 10.13: Markov chain of the IPv4 zeroconf protocol (for n=4 probes).
• The ﬁrst reward assignment (denoted rew1) represents waiting time—recall that on
transmitting a probe, an acknowledgment is awaited for exactly r time units. It is
deﬁned by rew1(si) = r for 0 < i ⩽n, rew1(s0) = 0 assuming that the host randomly
selects an address promptly, rew1(sn+3) = n·r, rew1(sn+2) = rew1(sn+4) = 0, and

818
Probabilistic Systems
rew1(sn+1) = E, where E denotes some large number that represents the highly
undesirable situation of an address collision.
• The second reward assignment (denoted rew2) is used to keep track of the number
of probes that are sent in total.
It is deﬁned by rew2(si) = 1 for 0 < i ⩽n,
rew2(sn+3) = n and 0 otherwise.
• Finally, the third reward assignment (denoted rew3) is used to keep track of the
number of failed attempts to acquire an unused address. It is deﬁned by rew3(s1) = 1
and 0 otherwise.
Consider the ﬁnite path π = s0 s1 s0 s1 s2 s0 s7 s8. It follows that rew1(π) = 7r, rew2(π) = 7
and rew3(π) = 2.
10.5.1
Cost-Bounded Reachability
Several quantitative properties of Markov reward models can be deﬁned on the basis of
cumulative rewards for ﬁnite paths. This section considers cost-bounded reachability, i.e.,
the expected reward before reaching a given set of states, and the probability of reaching
these states within a given bound on the cumulative reward. Let us ﬁrst consider expected
rewards. Let (M, rew) be an MRM with state space S and B ⊆S the set of target states.
For an inﬁnite path π = s0 s1 s2 . . . in M let
rew(π, ♦B) =

rew(s0 s1 . . . sn)
if si /∈B for 0 ⩽i < n and sn ∈B
∞
if π ̸|= ♦B.
Stated in words, rew(π, ♦B) denotes the cumulative reward earned along an inﬁnite path
π until reaching a B-state for the ﬁrst time. The expected reward until reaching B is now
deﬁned as the expectation of the function rew(π, ♦B):
Deﬁnition 10.71.
Expected Reward for Reachability Properties
For state s and B ⊆S, the expected reward until reaching B from s is deﬁned as follows.
If Pr(s |= ♦B) < 1, then ExpRew(s |= ♦B) = ∞. Otherwise, i.e., if Pr(s |= ♦B) = 1,
then:
ExpRew(s |= ♦B) =
∞

r=0
r · Prs{ π ∈Paths(s) | π |= ♦B ∧rew(π, ♦B) = r }.

Markov Chains with Costs
819
The inﬁnite series for Pr(s |= ♦B) = 1 converges for any reward function rew. The intuitive
argument for this is that the rewards along paths are added, while the probabilities of the
transitions are multiplicated. The formal proof is left as an exercise to the reader; see
Exercise 10.18 (page 904).
If Pr(s |= ♦B) = 1, then an equivalent characterization of the expected reward earned
until B is reached can be provided by means of a weighted sum of the rewards earned
along minimal path fragments from s to B:
ExpRew(s |= ♦B) =

bπ
P(π) · rew(π)
where π ranges over all ﬁnite paths s0 . . . , sn with sn ∈B, s0 = s and s0, . . . , sn−1 /∈B.
Example 10.72.
Simulating a Die by a Coin (Revisited)
Consider again the Markov chain in Example 10.3 (page 750) which describes how a six-
sided die can be simulated by a fair coin. For convenience, the Markov chain is illustrated
again in Figure 10.14. In order to reason about the number of coin ﬂips that are required
s0
s1,2,3
s4,5,6
s′
1,2,3
s2,3
s4,5
s′
4,5,6
1
2
1
2
1
2
1
2
1
2
1
2
1
2
3
4
5
6
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
1
1
1
1
1
Figure 10.14: Markov chain for simulating a die by a fair coin.
to obtain a certain die outcome, the Markov chain is extended to an MRM. The set B
of target states is thus B = { 1, 2, 3, 4, 5, 6 }. The reward function assigns reward 1 to all
states except the states in B, and reward zero to the states in B. The cumulative reward
of the inﬁnite path π = s0 s1,2,3 s′
1,2,3 1ω is rew(π, ♦B) = 3. The cumulative reward of
π′ = s0 (s1,2,3 s′
1,2,3)ω is ∞.
In order to determine the number of rounds that are performed until a die outcome is
obtained, an alternative reward function is used. A round is a visit to either state s1,2,3 or

820
Probabilistic Systems
s4,5,6. To reason about the number of rounds, reward 1 is associated with the states s1,2,3
and s4,5,6. All other states are equipped with reward zero. Using this reward function, we
obtain for the expected number of rounds before reaching a target state in B:
ExpRew(s0 |= ♦B) =
∞

r=1
r · 3
4 ·
&1
4
'r−1
= 4
3
.
Note that in every round a target state is reached (in this round) with probability 3
4, while
the probability for yet another round is 1
4. Thus, the probability for exactly r rounds agrees
with the probability of reaching B from the initial state s0 while entering { s1,2,3, s3,4,5 }
exactly r times, i.e., 3
4 · (1
4)r−1. The average number of rounds that is performed until an
outcome is thus 4
3.
Just a brief comment on the computation of ∞
r=1 r · 3
4 ·
1
4
r−1. One possible way to
compute the value of this inﬁnite series is the observation that ∞
r=1 r · ( 1
4)r−1 can be
viewed as the value of the ﬁrst derivative of the function f : ] −1, 1[→IR:
f(x) =
∞

r=0
xr =
1
1 −x
for x = 1
4. Then, f ′(x) =
∞

r=1
r · xr−1 =
1
(1−x)2 . Hence,
∞

r=1
r ·
 1
4
r−1 = f ′(1
4) =
1
(1−1
4)
2 =
1
( 3
4)
2
Therefore:
∞

r=1
r · 3
4 ·
 1
4
r−1 =
3
4 · f ′(1
4) =
3
4 ·
1
( 3
4)
2 =
4
3.
Let us now discuss in detail how to compute the expected rewards ExpRew(s |= ♦B), for
ﬁnite MRMs. Using the graph-based techniques explained in Section 10.1.2 (page 770ﬀ),
we ﬁrst determine the set S=1 of states s that reach B almost surely, i.e.:
S=1 = { s ∈S | Pr(s |= ♦B) = 1 }.
The task is to compute xs = ExpRew(s |= ♦B) for each state s ∈S=1. For all states
s ∈S=1 \ B, i.e., s ∈S \ B for which Pr(s |= ♦B) = 1, we have Pr(u |= ♦B) = 1 for all
direct successors u of s. Hence, if s ∈S=1, then either s ∈B or Post(s) ⊆S=1. Moreover,
the values xs = ExpRew(s |= ♦B) provide a solution of the following equation system:
xs =
⎧
⎨
⎩
0
if s ∈B
rew(s) +

u ∈Post(s)
P(s, u) · xu
if s ∈S=1 \ B.

Markov Chains with Costs
821
In fact, the vector (xs)s∈S=1 is the unique solution of the above linear equation system.
This follows from the results established in the proof of Theorem 10.19 on page 766 for the
subchain consisting of the states in S=1. Notice that the proof of Theorem 10.19 yields
that
Ax = x
implies
x = 0
where A = ( P(s, u) )s,u∈S=1\B. Since A is a quadratic matrix, this implication is equiv-
alent to the nonsingularity of I −A.
That is, for any vector b, the linear equation
system x = Ax + b, which can be rewritten as (I −A)x = b, has a unique solution,
namely x = (I −A)−1b. In fact, the above equation system for the expected rewards
can be rewritten in the form x = Ax + b where x stands for the vector ( xs )s∈S=1\B and
b = ( bs )s∈S=1\B is the vector with the entries bs = rew(s).
Summarizing, computing the expected reward earned until a certain set of states will be
reached in a ﬁnite MRM has a polynomial time complexity of the size of M. The necessary
techniques are a graph analysis to determine S=1, and solving a linear equation system.
Example 10.73.
Simulating a Die by a Coin (Revisited)
Consider again Knuth and Yao’s example of simulating a die by a fair coin. As in Example
10.72, consider the MRM where rewards serve as counters for the number of rounds. That
is, rew(s1,2,3) = rew(s4,5,6) = 1, and rew(s) = 0 for all other states. Let us compute the
average number of rounds performed until an outcome is obtained, i.e., until a state in
B = { 1, 2, 3, 4, 5, 6 } is reached, by the above linear equation system. Clearly, Pr(s |=
♦B) = 1 for each state s. Hence, all states are contained in S=1. Let x1,2,3 denote xs1,2,3
and x′
1,2,3 denote xs′
1,2,3. The values xs = ExpRew(s |= ♦B) are a solution of the following
equation system:
x0
=
1
2 · x1,2,3 +
1
2 · x4,5,6
x1,2,3
=
1 +
1
2 · x′
1,2,3 +
1
2 · x2,3
x2,3
=
1
2 · x2 +
1
2 · x3
x′
1,2,3
=
1
2 · x1,2,3 +
1
2 · x1
x4,5,6
=
1 +
1
2 · x′
4,5,6 +
1
2 · x4,5
x4,5
=
1
2 · x4 +
1
2 · x5
x′
4,5,6
=
1
2 · x4,5,6 +
1
2 · x6
x1 = x2 = x3 = x4 = x5 = x6 = 0
Using the values xi = 0 for 0 < i ⩽6, we obtain x2,3 = x4,5 = 0. The equations for the

822
Probabilistic Systems
other states simplify to
x0
=
1
2 · x1,2,3 +
1
2 · x4,5,6
x1,2,3
=
1 +
1
2 · x′
1,2,3
x′
1,2,3
=
1
2 · x1,2,3
x4,5,6
=
1 +
1
2 · x′
4,5,6
x′
4,5,6
=
1
2 · x4,5,6
This yields the linear equation system:
⎛
⎜
⎜
⎜
⎜
⎝
1
−1
2
0
−1
2
0
0
1
−1
2
0
0
0
−1
2
1
0
0
0
0
0
1
−1
2
0
0
0
−1
2
1
⎞
⎟
⎟
⎟
⎟
⎠
·
⎛
⎜
⎜
⎜
⎜
⎝
x0
x1,2,3
x′
1,2,3
x4,5,6
x′
4,5,6
⎞
⎟
⎟
⎟
⎟
⎠
=
⎛
⎜
⎜
⎜
⎜
⎝
0
1
0
1
0
⎞
⎟
⎟
⎟
⎟
⎠
The unique solution of this linear equation system is x0 = x1,2,3 = x4,5,6 = 4
3 and x′
1,2,3 =
x′
4,5,6, = 2
3. Thus, we obtain—as before—ExpRew(x0 |= ♦B) = x0 = 4
3 for the average
number of rounds.
Remark 10.74.
Alternative Deﬁnitions of the Expected Reward
According to Deﬁnition 10.71 (page 818), ExpRew(s |= ♦B) = ∞if B is not almost surely
reached from s. This choice is consistent with the fact that rew(π, ♦B) = ∞whenever
π ̸|= ♦B for some path π. Let us discuss two variants of this deﬁnition.
For certain applications, it might be more reasonable to deﬁne the cumulative reward for
an inﬁnite path fragment which never visits B as zero (rather than ∞). In this case, the
expected reward ExpRew(s |= ♦B) is deﬁned as
∞

r=0
r · Prs{ π ∈Paths(s) | π |= ♦B ∧rew(π, ♦B) = r }
for all cases. (That is, no exceptional case for Pr(s |= ♦B) < 1.) The proposed algorithm
for computing ExpRew(s |= ♦B) can easily be adapted to deal with this adapted deﬁnition
by adding the constraint xs = 0 for Pr(s |= ♦B) = 0 to the linear equation system. The
equation xt = 0 for t ∈B remains unchanged. For all other states s, i.e., all states s where
s /∈B and Pr(s |= ♦B) > 0, we deal with the equation:
xs = rew(s) +

u ∈Post(s)
P(s, u) · xu.
Another way of treating the paths that never reach a B-state is to consider conditional
expectations. That is, we consider the expected reward to reach B under the condition

Markov Chains with Costs
823
that B is eventually reached. The corresponding deﬁnition of this conditional expectation,
denoted CExpRew(s |= ♦B), is as follows. If Pr(s |= ♦B) > 0, then
CExpRew(s |= ♦B) =
∞

r=0
r · Prs{ π ∈Paths(s) | π |= ♦B ∧rew(π, ♦B) = r }
Pr(s |= ♦B)
.
If Pr(s |= ♦B) = 0, i.e., B is not reachable from s, then CExpRew(s |= ♦B) can be deﬁned
as undeﬁned or some ﬁxed value. The computation of the conditional expected rewards
goes as follows. By means of a backward graph analysis starting from the B-states, the
set
Pre∗(B) = { s ∈S | Pr(s |= ♦B) > 0 }.
is determined. This is a standard backward reachability analysis. Let M′ be a new Markov
chain with state space Pre∗(B). The transition probabilities of M′ are deﬁned by
P′(s, s′) =
P(s, s′)
P(s, Pre∗(B)) if s ∈Pre∗(B) \ B and s′ ∈Pre∗(B).
For t ∈B let P′(t, t) = 1 and P′(t, s′) = 0 for all states s′ ∈Pre∗(B) \ { t }.
Then
PrM′(s |= ♦B) = 1 for all s in M′ and
CExpRewM(s |= ♦B) = ExpRewM′(s |= ♦B).
The conditional expected reward in M is thus equal to the expected reward in M′. Thus,
the problem of computing the conditional expected rewards CExpRew(s |= ♦B) is re-
ducible to the problem of computing (unconditional) expected rewards.
Other important quantitative measures for MRMs are cost-bounded reachability probabil-
ities, i.e., the probability of reaching a certain given set of states within a certain bound
on the cumulative reward. Paths that reach one of the target states whose cumulative
reward exceeds the bound are considered too costly. Let B ⊆S, r ∈IN and ♦⩽rB denote
the event of reaching the set B with cumulative reward at most r. Then:
Pr(s |= ♦⩽rB)
=
Prs{ π ∈Paths(s) | π |= ♦B ∧rew(π, ♦B) ⩽r }
denotes the probability of reaching B from s while the cumulative reward earned until B is
reached is at most r. For example, when B stands for the set of good states, Pr(s |= ♦⩽rB)
denotes the probability of reaching a good state with cost at most r. We have
Pr(s |= ♦⩽rB) =

bπ
P(π)
where π ranges over all ﬁnite paths s0 . . . sn with sn ∈B, s0 = s and s0, . . . , sn−1 /∈B
such that rew(π) ⩽r.
For ﬁnite MRMs, the values xs,r = Pr(s |= ♦⩽rB) can be computed via the following
equation system:

824
Probabilistic Systems
• if s ∈B, then xs,r = 1;
• if s /∈Pre∗(B) or s ∈Pre∗(B) \ B ∧(rew(s) > r); then xs,r = 0
• in all other cases, i.e., if s ∈Pre∗(B) \ B and rew(s) ⩽r:
xs,r =

u∈S
P(s, u) · xu, r −rew(s).
The above equation system can be regarded as a linear equation system with variables xs,ρ
where (s, ρ) ∈S × { 0, 1, . . . , r }. If all rewards are positive, i.e., rew(s) > 0 for any state
s, then xs,r is completely determined by the values xu,ρ for u ∈S and ρ < r. Hence, in
this case the above equation system can be solved by successively computing the vectors
(xs,ρ)s∈S for ρ = 0, 1, . . . , r. In the presence of zero-reward states, the above equation for
xs,r may contain some variables xu,r for the same reward bound r. However, xs,r only
depends on the values xu,ρ for ρ ⩽r. Thus, the vectors x0, x1, x2, . . . , xr can be determined
in this order, where the vector xρ = (xs,ρ)s∈S is obtained from xi for 0 ⩽i < ρ as follows.
If s ∈B or s /∈Pre∗(B), the value of xs,ρ is 1 or 0 (see the ﬁrst two items above). For
s ∈Pre∗(B)\B and rew(s) > 0, the value of xs,ρ is obtained from the previously computed
values xu, ρ −rew(s) (see the sum in the third item). For the remaining states, i.e., states in
S0 = { s ∈Pre∗(B) \ B | rew(s) = 0 }, the values xs,ρ are obtained as the unique solution
of the following linear equation system:
x = A0·x + b.
Vector x stands for ( xs,ρ )s∈S0. The matrix A0 contains the transition probabilities be-
tween the states in S0, i.e., A0 = ( P(s, u) )s,u∈S0. The entries of the vector b = ( bs,ρ )s∈S0
are given by
bs,ρ
=

u∈B
P(s, u) ·
=1

xu,ρ
+

u ∈S \ Pre∗(B)
P(s, u) ·
=0

xu,ρ
+

u ∈Pre∗(B) \ B
rew(u) > ρ
P(s, u) ·
=0

xu,ρ
+

u ∈Pre∗(B) \ B
ρ ⩾rew(u) > 0
P(s, u) · xu,ρ
=
P(s, B)
+

u ∈Pre∗(B) \ B
ρ ⩾rew(u) > 0
P(s, u) ·
xu,ρ

already
computed
The above equation system is linear and has a unique solution. Recall that P(s, B) stands
for the probability of moving from state s within one transition to a state t ∈B, i.e.,
P(s, B) = 
t∈B
P(s, t).

Markov Chains with Costs
825
Summarizing, the probabilities Pr(s |= ♦⩽rB) can be computed with a time complexity
which is polynomial in the size of M and linear in the reward bound r. To compute
Pr(s0 |= ♦⩽rB) for some designated state s0, in fact not all variables xs,ρ might be relevant.
The relevant variables are obtained by starting with the equation for xs0,r and then adding
only those equations xs,ρ that appeared in an already generated equation. This observation
has no inﬂuence on the worst-case time complexity, but may yield drastic speedups.
Example 10.75.
Simulation of a Die by a Coin (Revisited)
Consider again the MRM for the simulation of a die by a fair coin where the reward
function serves to count the number of rounds; see Examples 10.72 (page 819) and 10.73
(page 821).
Consider the probability of obtaining a die outcome within the ﬁrst two
rounds. This amounts to computing the values xs,ρ = Pr(s |= ♦⩽ρB) for ρ = 0, 1, 2 and
all states s, where B = { 1, 2, 3, 4, 5, 6 }. We have
xs0,0 = xs1,2,3,0 = xs4,5,6,0 = 0,
xs′
1,2,3,0 = xs′
4,5,6,0 = 1
2,
xs2,3,0 = xs4,5,0 = xi = 1,
i = 1, . . . , 6.
The probability of reaching a B-state from the initial state in the ﬁrst round is given by
xs0,1 where
xs0,1
=
1
2 · xs1,2,3,1 +
1
2 · xs4,5,6,1
xs1,2,3,1
=
1
2 · xs2,3,0
  
=1
+ 1
2 · xs′
1,2,3,0
  
= 1
2
=
3
4
xs4,5,6,1
=
1
2 · xs4,5,0
  
=1
+ 1
2 · xs′
4,5,6,0
  
= 1
2
=
3
4.
This yields xs0,1 =
3
4.
For the other states, we have xs2,3,1 = xs4,5,1 = xi = 1 for
1 ⩽i ⩽6 and
xs′
1,2,3,1 =
1
2 · xs1,2,3,1 + 1
2 · xs2,3,1 =
1
2 · 3
4 + 1
2 · 1 =
7
8,
and similarly xs′
4,5,6,1 = 7
8. The probability xs0,2 of reaching B from the initial state within
two rounds is given by
xs0,2
=
1
2 · xs1,2,3,2 +
1
2 · xs4,5,6,2
xs1,2,3,2
=
1
2 · xs2,3,1
  
=1
+ 1
2 · xs′
1,2,3,1
  
= 7
8
=
15
16
xs4,5,6,1
=
1
2 · xs4,5,1
  
=1
+ 1
2 · xs′
4,5,6,1
  
= 7
8
=
15
16.

826
Probabilistic Systems
Thus, xs0,2 = 15
16. In fact, we have xs0,r = 1−1
4r for all integers r ⩾0; see Exercise 10.19
(page 904).
The techniques discussed so far for cost-bounded reachability probabilities can be adapted
to cost-bounded constrained reachability probabilities in a fairly straightforward manner.
For C, B ⊆S, let
Pr(s |= C U ⩽rB) = Prs{ π ∈Paths(s) | π |= C U ⩽rB }
where s0 s1 s2 . . . |= C U ⩽rB if and only if there exists a ﬁnite preﬁx s0 . . . sn such that
si ∈C for 0 ⩽i < n, sn ∈B and rew(s0 s1 . . . sn) ⩽r. In fact, the values Pr(s |= C U ⩽rB)
are obtained by an analogous linear equation system as for Pr(s |= ♦⩽rB). The equations
are
• if s ∈B, then xs,r = 1;
• if s ̸|= ∃(C U B) or s /∈B ∧rew(s) > r, then xs,r = 0;
• in all other cases, i.e., if s ∈∃(C U B) and rew(s) ⩽r:
xs,r =

u∈S
P(s, u) · xu, r −rew(s).
The techniques discussed so far are key ingredients for the model-checking of a variant of
PCTL that incorporates rewards. This logic is called PRCTL, which is short for Proba-
bilistic Reward CTL. It is deﬁned as follows.
Deﬁnition 10.76.
Syntax of PRCTL
PRCTL state formulae over the set AP of atomic propositions are formed according to
the following grammar:
Φ ::= true
   a
   Φ1 ∧Φ2
   
¬Φ
   PJ(ϕ)
   ER(Φ)
where a ∈AP, ϕ is a path formula, J ⊆[0, 1] and R are intervals with rational bounds.
PCTL path formulae are formed according to the following grammar:
ϕ ::= ⃝Φ
   Φ1 U Φ2
   
Φ1 U ⩽nΦ2



step-bounded
until
   
Φ1 U ⩽rΦ2



reward-bounded
until
where Φ, Φ1, and Φ2 are state formulae and n, r ∈IN.

Markov Chains with Costs
827
The semantics of the propositional logic fragment and probability operator is deﬁned as
for PCTL. For the expectation operator ER(·), the semantics is deﬁned by:
s |= ER(Φ)
iﬀ
ExpRew(s |= ♦Sat(Φ)) ∈R.
Example 10.77.
The logic PRCTL may be used to specify the simulation of a die by a coin by the require-
ments
E⩽3
2 (outcome) ∧

1⩽i⩽6
P= 1
6 (♦i) ∧P⩾15
16 ( ♦⩽2 outcome )
where outcome is an atomic proposition that labels the six outcome states 1,2,3,4,5, and
6. The above PRCTL formula asserts that (1) the average number of rounds to obtain an
outcome is bounded by 3
2, (2) the correctness of the outcomes in the sense that each of the
six possible outcomes has probability 1
6, and (3) with probability at least 15
16 the outcome
is obtained within at most two rounds.
Example 10.78.
Zeroconf Protocol
Consider again the zeroconf protocol as introduced in Example 10.5 (page 751). Consider
the reward function that represents waiting times. The property “the probability of ending
up with an unused address within n steps exceeds p′” can be expressed as PRCTL formula
P>p′(♦⩽n ok)
where ok uniquely indicates the state in which an unused address has been selected.
Consider now the reward function that keeps track of the number of probes sent. The
property “the probability of ending up with an unused address after at most n probes
exceeds p′” is expressed by the PRCTL formula
P>p′(♦⩽n ok).
Although the formula is identical to the previous one, its interpretation is somewhat
diﬀerent due to the diﬀerent reward function.
10.5.2
Long-Run Properties
This section is concerned with a diﬀerent class of properties, viz. long-run averages. As
opposed to the measures considered in the previous section, long-run averages are based

828
Probabilistic Systems
on the limiting behavior of Markov chains. Before considering long-run averages, let us
ﬁrst consider the long-run distribution of a Markov chain.
The long-run distribution is a limit deﬁned on the basis of transient distributions. Recall
that the transient state distribution Θn = ΘM
n
is a function that assigns to each state
t ∈S the probability of being in state t after exactly n steps given the initial distribution
ιinit; see Remark 10.22 (page 768). The limiting behavior of M is obtained when n tends
to go to inﬁnity.
For a given Markov chain M and states s, t in M, let θM
n (s, t) (brieﬂy θn(s, t)) denote
the probability of being in state t after exactly n steps when starting in state s, i.e.:
θn(s, t) = Prs{ s0 s1 s2 . . . ∈Paths(s) | s0 = s ∧sn = t }.
The transient state distribution Θn arises by the values θn(s, t) by taking the initial dis-
tribution into account:
Θn(t) =

s∈S
ιinit(s) · θn(s, t).
For ﬁxed state s, the function t →θn(s, t) agrees with the transient state distribution
ΘMs
n
in the Markov chain Ms that is obtained from M by declaring s to be the unique
starting state.
Deﬁnition 10.79.
Long-Run Distributions
Let M = (S, P, ιinit, AP, L) be a ﬁnite Markov chain and s, t ∈S. The long-run average
probability θM(s, t) (brieﬂy θ(s, t)) is given by
θ(s, t) =
lim
n→∞
1
n ·
n

i=1
θi(s, t).
The function t →θ(s, t) is the long-run distribution for starting state s. The long-run
distribution for M is given by
ΘM(t) =

s∈S
ιinit(s) · θ(s, t).
The limit in the above deﬁnition exists in every ﬁnite Markov chain. We will not provide
a formal proof of this fact and refer to textbooks on Markov chains, e.g., [248]. Intuitively,
the long-run probability θ(s, t) is the fraction of (discrete) time to be in state t when
starting in state s. For example, in the following two-state Markov chain:

Markov Chains with Costs
829
s
t
1
1
When starting in s, then after any even number of steps the current state is s, while after
any odd number of steps the current state is t. Hence:
θ2k(s, s) = θ2k+1(s, t) = 1 for all k ⩾0
while θ2k(s, t) = θ2k+1(s, s) = 0. Therefore:
1
2k
2k

i=1
θi(s, t)
=
k
2k ,
1
2k+1
2k+1

i=1
θi(s, t)
=
k + 1
2k + 1.
Hence, lim
n→∞θn(s, t) does not exist, but
θ(s, t) =
lim
n→∞
1
n
n

i=1
θi(s, t) = 1
2.
This example illustrates that the sequence of the transient probabilities θn(s, t) may not
converge. Hence, the deﬁnition of long-run probabilities cannot be simpliﬁed by just taking
the limit of the transient probabilities θn(s, t).
However, if limn→∞θn(s, t) exists, then it agrees with θ(s, t). This is illustrated by the
Markov chain:
s
t
1
2
1
2
1
Whenever the current state is s, then both successors s and t are equally likely. If, however,
the current state is t, then almost surely the next state is s. This provides an intuitive
explanation that the fraction of the time being in state s is 2
3, and for state t is 1
3. For
this example, we have
θn+1(s, s) = 1
2θn(s, s) + θn(s, t)
and
θn+1(s, t) = 1
2θn(s, s).
The following table shows the values for 0 ⩽n ⩽4:

830
Probabilistic Systems
n
θn(s, s)
θn(s, t)
0
1
0
1
3
4
1
4
2
5
8
3
8
3
11
16
5
16
4
21
32
11
31
...
...
...
limit
2
3
1
3
In fact, lim
n→∞θn(s, s) = 2
3 = θ(s, s) and lim
n→∞θn(s, t) = 1
3 = θ(s, t).
Long-run probabilities provide the basis for several interesting measures. The following
deﬁnition considers the expected long-run reward that is earned between two successive
visits to a state in the set B.
Deﬁnition 10.80.
Expected Long-run Reward between B-States
Let M be a ﬁnite MRM with state space S, B ⊆S and s ∈S such that Pr(s |= □♦B) = 1.
The expected long-run reward between two B-states for s is given by
LongRunERs(B) =

t∈B
θ(s, t) · ExpRew(t |= ⃝♦B)
where ExpRew(t |= ⃝♦B) is deﬁned as ExpRew(t |= ♦B), except that only paths of
length ⩾1 are considered, i.e.,
ExpRew(t |= ⃝♦B) = rew(t) +

u∈S
P(t, u) · ExpRew(u |= ♦B).
The value ExpRew(t |= ⃝♦B) can be interpreted as the average reward earned by moving
from t to B within one or more steps. The intuitive meaning of LongRunERs(B) is the
average reward earned between two successive visits to a B-state, when considering the
Markov chain M on the long run. For example, if B characterizes certain failure states,
and the reward function is deﬁned to be one for all states outside B, then LongRunERs(B)
yields the average number of steps that are performed between two failures.
The computation of the expected long-run rewards LongRunERs(B) relies on techniques
for computing the long-run probabilities. We will discuss now how the values θ(s, t) can
be obtained—once again—by solving linear equation systems.

Markov Chains with Costs
831
In the sequel, let M be a ﬁnite Markov chain with state space S and s ∈S. Let us ﬁrst
establish that the function t →θ(s, t) is, in fact, a distribution over S. Indeed, we have
0 ⩽θ(s, t) ⩽1, since 0 ⩽θi(s, t) ⩽1 for all i and therefore 
1⩽i⩽n θi(s, t) ⩽n. Moreover,
for each i ⩾1:

t∈S
θi(s, t) = 1
Therefore:

t∈S
θ(s, t) = 1
n

t∈S
n

i=1
θi(s, t) = 1
n
n

i=1

t∈S
θi(s, t)



=1
= 1
n · n = 1
Furthermore, we have the following balance equation:
θ(s, u) =

t∈S
θ(s, t) · P(t, u).
This follows from

t∈S
θ(s, t) · P(t, u)
=
lim
n→∞
1
n

t∈S
n
i=1
θi(s, t) · P(t, u)
=
lim
n→∞
1
n
n
i=1

t∈S
θi(s, t) · P(t, u)
=
lim
n→∞
1
n
n
i=1
θi+1(s, u)
=
lim
n→∞
n + 1
n
  
tends to 1
·

1
n + 1 ·
n+1

j=1
θj(s, u)



tends to θ(s, u)
−
θ1(s, u)
n + 1



tends to 0

=
θ(s, u).
As almost surely a BSCC will be reached, θ(s, t) = 0 if t does not belong to a BSCC that is
reachable from s. Note that then θi(s, t) tends to zero if i tends to inﬁnity. In particular,
if s ∈T and T ∈BSCC(M), then:

t∈T
θ(s, t) = 1.
This and the balance equation (applied to the sub-Markov chain consisting of the states
in B) yields that the values xs,t = θ(s, t) for s, t ∈T and T ∈BSCC(M) yield a solution

832
Probabilistic Systems
of the equation system:

t∈T
xs,t = 1
and
xs,u =

t∈T
xs,t · P(t, u)
where s and u range over all states of T. In fact, the above equation system has a unique
solution. In particular:
θ(s, t) = xs,t = xs′,t = θ(s′, t)
for all states s, s′, t of a BSCC. Thus, the long-run distributions t →θ(s, t) for the states s
that are contained in some BSCC T can be solved by means of the linear equation system
with variables xt for t ∈T and the equations
• 
t∈T
xt = 1;
• 
t∈T
xt · P(t, u) = xu for all states u ∈T.
This equation system has a unique solution (xt)t∈T and xt = θ(s, t) for all states s, t ∈T.
Furthermore, θ(s, u) = 0 for all states s ∈T and u /∈T. For all states s which do not
belong to a BSCC, the long-run probabilities θ(s, ·) are obtained as follows:
• θ(s, t) = 0 if t is not contained in BSCC, and
• θ(s, t) = Pr(s |= ♦T)·xt if t ∈T and T ∈BSCC(M), where xt = θ(s, t) for all/some
s ∈T.
A corresponding operator to specify lower or upper bounds for the expected long-run
rewards, say LR(Φ) where R is a reward interval, may be added to the logic PRCTL with
the semantics:
s |= LR(Φ) if and only if LongRunERs(Sat(Φ)) ∈R.
The above-sketched technique can then be used to compute the satisfaction set of LR(Φ).
10.6
Markov Decision Processes
Nondeterminism is absent in Markov chains. Markov decision processes (MDPs, for short)
can be viewed as a variant of Markov chains that permits both probabilistic and nonde-
terministic choices. As in Markov chains, the probabilistic choices may serve to model and

Markov Decision Processes
833
quantify the possible outcomes of randomized actions such as tossing a coin or sending a
message over a lossy communication channel. Probabilistic choices may also be adequate
for modeling the interface of a system with its environment. For example, for a vending
machine it might be reasonable to assign probability
9
10 for the option chocolate bar, and
probability
1
10 for the option apple. This, however, requires statistical experiments to ob-
tain adequate distributions that model the average behavior of the environment, i.e., the
user of the vending machine. In cases where this information is not available, or where it
is needed to guarantee system properties which should hold for all potential environments,
a natural choice is to model the interface with the environment by nondeterminism.
Another important motivation for the incorporation of nondeterminism in probabilistic
models such as Markov chains is provided by the ﬁeld of randomized distributed algo-
rithms. Such algorithms are concurrent and hence nondeterministic in nature. This is due
to the interleaving of the behavior of the distributed processes involved, i.e., the nondeter-
ministic choice to determine which of the concurrent processes performs the next step (see
Chapter 2). Besides, they are probabilistic in the sense that typically a rather restricted
set of actions (like tossing a coin or selecting a number from a certain range) has a random
nature. A simple example is a two-process mutual exclusion protocol where access to the
critical section is governed by an arbiter that on the basis of tossing a coin decides which
process acquires access.
Finally, nondeterminism is crucial for abstraction techniques of Markov chains. Abstrac-
tion is typically based on the grouping of states. If this abstraction is based on probabilis-
tic bisimulation, then there is no need for nondeterminism, as the transition probabilities
between groups (i.e., equivalence classes) of states is uniquely determined. If, however,
a coarser abstraction is considered where e.g., states are grouped on the basis of their
atomic propositions, one obtains a range of probabilities for the transition probabilities—
nondeterminism, so to speak. In the case of data abstraction, e.g., one might replace
probabilistic branching by a nondeterministic choice.
Several operational models have been studied in the literature that all can be viewed as
variants of Markov chains with both nondeterministic choices and discrete probabilities
for the transition relation. We adopt the traditional notion of Markov decision processes
(see e.g., the textbook [346]), extended by atomic propositions:
Deﬁnition 10.81.
Markov Decision Process (MDP)
A Markov decision process is a tuple M = (S, Act, P, ιinit, AP, L) where
• S is a countable set of states,
• Act is a set of actions,

834
Probabilistic Systems
• P : S × Act × S →[0, 1] is the transition probability function such that for all states
s ∈S and actions α ∈Act:

s′∈S
P(s, α, s′) ∈{ 0, 1 },
• ιinit : S →[0, 1] is the initial distribution such that 
s∈S ιinit(s) = 1,
• AP is a set of atomic propositions and L : S →2AP a labeling function.
An action α is enabled in state s if and only if 
s′∈S P(s, α, s′) = 1. Let Act(s) denote
the set of enabled actions in s. For any state s ∈S, it is required that Act(s) ̸= ∅. Each
state s′ for which P(s, α, s′) > 0 is called an α-successor of s.
The transition probabilities P(s, α, t) can be arbitrary real numbers in [0, 1] (that sum up
to either zero or 1 for ﬁxed s and α). For algorithmic purposes, the transition probabilities
are supposed to be rational. Furthermore, the veriﬁcation algorithms are restricted to ﬁnite
MDPs. An MDP is ﬁnite whenever the state space S, the set Act of actions, and the set
AP of atomic propositions are ﬁnite.
An MDP has a unique initial distribution ιinit. In fact, this could be generalized by allowing
a set of initial distributions. A computation then starts by choosing one of these initial
distributions nondeterministically. For the sake of simplicity, we just consider a single
initial distribution.
The intuitive operational behavior of an MDP M is as follows. A stochastic experiment
according to the initial distribution ιinit, yields a starting state s0 such that ιinit(s0) > 0.
On entering state s, say, ﬁrst a nondeterministic choice between the enabled actions needs
to be resolved. That is to say, it needs to be determined which action in Act(s) is to be
performed next. In the absence of any information about the frequency of actions—given
actions α and β in Act(s) it is unknown how often α needs to be selected—this choice is
purely nondeterministic. Suppose action α ∈Act(s) has been selected. On performing α
in state s, one of the α-successors of s is selected randomly according to the distribution
P(s, α, ·). That is, with probability P(s, α, t) the next state is t. If t is the unique α-
successor of s, then almost surely t is the successor after selecting α, i.e., P(s, α, t) = 1.
In this case, P(s, α, u) = 0 for all states u ̸= t.
Any Markov chain is an MDP in which for any state s, Act(s) is just a singleton set.
Vice versa, any MDP with this property is a Markov chain. The action names are then
irrelevant and can be omitted. Markov chains are thus a proper subset of MDPs.

Markov Decision Processes
835
The direct successors and predecessors of a state are deﬁned as follows. For s ∈S, α ∈Act
and T ⊆S, let P(s, α, T) denote the probability of moving to a state in T via α, i.e.,
P(s, α, T) =

t∈T
P(s, α, t)
.
Post(s, α) denotes the set of α-successors of s, i.e.,
Post(s, α) = { t ∈S | P(s, α, t) > 0 }.
Note that Post(s, α) = ∅if and only if α /∈Act(s). Pre(t) denotes the set of pairs (s, α)
with s ∈S and α ∈Act(s) such that t ∈Post(s, α), i.e.,
Pre(t) = { (s, α) ∈S × Act | P(s, α, t) > 0 }.
Example 10.82.
An Example of an MDP
Consider the MDP M depicted below:
s
∅
β, 1
2
t
{ a }
u
{ b }
β, 1
2
γ, 1
α, 1
γ, 1
State s is the only initial state, i.e., ιinit(s) = 1 and ιinit(t) = ιinit(u) = 0. The sets of
enabled actions are
• Act(s) = { α, β } with P(s, α, t) = 1, P(s, β, u) = P(s, β, s) = 1
2, and
• Act(t) = Act(u) = { γ } with P(t, γ, s) = P(u, γ, s) = 1.
In state s, a nondeterministic choice between actions α and β exists. On selecting action
α, the next state is t; on selecting action β, the successor states s and u are equally
probable. Some successor and predecessor sets are Post(s, α) = { t }, Post(s, β) = { s, u },
and Pre(s) = { (s, β), (t, γ), (u, γ) }.
Example 10.83.
A Randomized Mutual Exclusion Protocol
Consider a simple randomized mutual exclusion protocol for two concurrent processes P1

836
Probabilistic Systems
and P2. The coordination of accessing their critical sections is provided by a randomized
arbiter which permits process Pi to enter its critical section if the other process is in its
noncritical section. If both processes acquire access to the critical section, the arbiter
tosses a fair coin to decide which of the two processes has to wait and which process may
enter the critical section.
⟨n1, n2⟩
⟨w1, n2⟩
⟨n1, w2⟩
⟨c1, n2⟩
⟨w1, w2⟩
⟨n1, c2⟩
⟨c1, w2⟩
⟨w1, c2⟩
req1
req2
req1
req2
enter2
enter1
req1
rel2
rel1
req2
rel1
rel2
1
2
1
2
enter1
enter2
Figure 10.15: MDP for a randomized mutual exclusion protocol.
The composite behavior of the two concurrent processes and the arbiter can be modeled
by the MDP depicted in Figure 10.15.
All states of the MDP where at least one of
the processes is in its noncritical location exhibit a nondeterministic choice between the
enabled actions of P1 and P2. The corresponding req, enter or rel action does not have a
proper probabilistic eﬀect, since it yields a unique successor. The transition probabilities
that equal 1 are omitted from the ﬁgure. Only in state ⟨wait1, wait2⟩is there a proper
probabilistic choice performed by the arbiter to select the next process to enter the critical
section.
Remark 10.84.
Actions in an MDP
The action names α ∈Act are needed here only for technical reason, viz. to group all
edges belonging to the same probabilistic choice. When using MDPs in a compositional
framework, where the MDP for a complex system arises through the parallel composition
of several other MDPs, then it is more appropriate to allow for sets of distributions per
action and state rather than just a single distribution. Note that, e.g., the interleaving of
two equally named actions performed by diﬀerent processes yields a global state that has
two outgoing transitions with the same action label. This more general approach can be
formalized by replacing P with a transition relation of the form
→⊆S × Act × Distr(S)

Markov Decision Processes
837
where Distr(S) denotes the set of distributions over S, i.e., functions μ : S →[0, 1] such
that 
s∈S μ(s) = 1. Labeled transition systems appear as special case of this type of
transition relation. This follows from the fact that any transition s
α
−−→t in a transition
system can be identiﬁed with the transition s
α
−−→μ1
t where μ1
t ∈Distr(S) denotes the
distribution with μ1
t(t) = 1 and μ1
t(u) = 0 for any u ̸= t. The notion of MDP in this
monograph (see Deﬁnition 10.81) is obtained by considering transitions s
α
−−→μs,α for the
actions α ∈Act(s), where μs,α denotes the distribution t →P(s, α, t). Since compositional
approaches for MDPs fall outside the scope of this monograph, the action names are
irrelevant. The actions may be assumed to be renamed such that per state and action
there is at most one distribution.
Remark 10.85.
Probmela
In a similar way as transition systems for nonprobabilistic (concurrent) programs can be
described by higher-level modeling languages such as (nano)Promela, (see Section 2.2.5
on page 63), probabilistic systems can be speciﬁed by various higher-level description
techniques. We consider the main features of a probabilistic variant of nanoPromela, called
Probmela.
As in nanoPromela, a Probmela model consists of ﬁnitely many concurrent
processes that may communicate via either shared variables or channels (or both). The
processes are described by statements of a probabilistic guarded command language.
The core of this language is as in nanoPromela and consists of assignments, conditional
commands (i.e., statements built by the keywords if–ﬁ), loops (i.e., statements built by
do–od), communication actions c?x (for input) and c!expr (for output), and atomic regions.
The language features three probabilistic features: randomized assignments, probabilistic
choice, and lossy channels. Let us discuss these features in somewhat more detail.
• A random assignment has the form x := random(V ) where x is a variable and V is
a ﬁnite nonempty subset of dom(x). On executing this assignment, a value v ∈V is
chosen probabilistically according to a uniform distribution over V and assigned to
x. The probability that value v ∈V is assigned to x is thus
1
|V |.
• The probabilistic choice operator is a probabilistic variant of if–ﬁ-statements where
the resolution of the choices is by probabilities rather than by guards. The syntax is
pif [p1] ⇒stmt1 . . . [pn] ⇒stmtn ﬁp
where pi is a non-negative real number such that 
i pi = 1. The above statement
models the probabilistic choice between the statements stmt1 through stmtn, where
stmti is selected with probability pi.
• Communication channels may either be perfect (as in nanoPromela) or lossy. This
is indicated upon declaring a channel.
A perfect channel never loses a message,

838
Probabilistic Systems
c := s0;
do
:: c = s0
⇒
pif
[1
2] ⇒
c := s1,2,3
[1
2] ⇒
c := s4,5,6
ﬁp
:: c = s1,2,3
⇒
pif
[1
2] ⇒
c := s′
1,2,3
[1
2] ⇒
c := s2,3
ﬁp
:: c = s2,3
⇒
pif
[1
2] ⇒
c := 2
[1
2] ⇒
c := 3
ﬁp
:: c = s′
1,2,3
⇒
pif
[1
2] ⇒
c := s1,2,3
[1
2] ⇒
c := 1
ﬁp
:: c = s4,5,6
⇒
pif
[1
2] ⇒
c := s′
4,5,6
[1
2] ⇒
c := s4,5
ﬁp
:: c = s4,5
⇒
pif
[1
2] ⇒
c := 4
[1
2] ⇒
c := 5
ﬁp
:: c = s′
4,5,6
⇒
pif
[1
2] ⇒
c := s4,5,6
[1
2] ⇒
c := 6
ﬁp
od
Figure 10.16: Probmela speciﬁcation of Knuth and Yao’s simulation of a die by a fair coin.
whereas via a lossy channel a message is lost with probability p, a ﬁxed probability
that is deﬁned on declaring the channel. The eﬀect of the communication action c!v
along lossy channel c is that v is written into the buﬀer for c with probability 1−p,
and it fails (i.e., the content of the buﬀer for c remains unchanged while performing
the action c!v) with probability p.
The stepwise behavior of a Probmela program can be formalized by means of an MDP.
The states are tuples ⟨ℓ1, . . . , ℓn, η, ξ⟩where ℓi is the location of process i, η is a variable
evaluation, and ξ is a channel evaluation. This is the same as for nanoPromela. The
transitions in the MDP specify a probability distribution over the successor states (i.e.,
an enabled action of a state and its probabilistic eﬀect). As Probmela is only used for the
examples, we refrain from presenting these inference rules here.
To illustrate the language Probmela, consider the simulation of a die by a coin; see Figure
10.2 on page 750.
The Probmela code is shown in Figure 10.16. Here, c is a variable
whose domain is the state space of the MC in Figure 10.2. The statements
pif [1
2] ⇒c := . . . [1
2] ⇒c := . . . ﬁp
represent the coin-tossing experiments that are performed in the inner nodes. The ﬁnal
value of c stands for the die outcome. Note that the Probmela model just consists of a
single process which does not behave nondeterministically. The semantics is thus a Markov
chain.
Example 10.86.
Alternating Bit Protocol with Lossy Channel
The alternating bit protocol (see Example 2.32 on page 57) can be modeled by an MDP,

Markov Decision Processes
839
assuming that the probability p for a channel to lose a message is known. An MDP of
the alternating bit protocol can be obtained by specifying the behavior of the sender, the
receiver, and the timer by Probmela statements. As in Example 2.32, the asynchronous
channels c and d are used for connecting the sender and the receiver. The synchronous
channel e is used for activating the timer and the timeout signal. Channel c is declared to
be lossy with failure probability p, while channel d is supposed to be perfect. The sender
is described by the following Probmela fragment:
x := 0
do :: true ⇒
c!x; e!on;
if
::
d!y
⇒
x := ¬x; e!timeroﬀ
::
e?y
⇒
c!x; e!on
ﬁ
od
The behavior of the receiver and the timer can be speciﬁed by analogous Probmela state-
ments. As c is a lossy channel with probability p, the statement c!x will not result in
inserting message x into c.
Example 10.87.
Randomized Dining Philosophers
Example 3.2 (page 90) treats the dining philosophers problem.
We have seen that a
naive symmetric protocol fails to ensure deadlock freedom as all philosophers might, e.g.,
pick up their left chopsticks simultaneously (or in any order). A deadlock-free solution is
obtained when using variables that control the sticks and make them available to a single
philosopher only. In order to break the symmetry, the initial values of these variables have
to be chosen in such a way that initially at least one philosopher can pick up both sticks.
In the probabilistic setting, there are simpler solutions which are fully symmetric and that
need neither global control nor additional shared variables. Consider, e.g., the proposal
by Lehmann and Rabin [268]. The idea of their algorithm is that the philosophers toss a
fair coin to decide which of the sticks they pick up ﬁrst. If they fail to take the chosen
stick, they then repeat the random choice. Otherwise they try to get the other stick. If
the missing stick is not available, they return the taken stick and repeat the coin-tossing
experiment. The Probmela code of philosopher i, shown in Figure 10.17 on page 840,
uses Boolean variables sticki for the sticks that indicate whether stick i is available, where
initially sticki = true for all sticks.
This randomized algorithm is deadlock-free as whenever a philosopher attempts to access
an occupied stick, then he does not wait but repeats the coin-tossing experiment. Star-
vation freedom is guaranteed in the sense that almost surely any hungry philosopher who
tries inﬁnitely often to get the sticks will eventually eat.

840
Probabilistic Systems
modei := think;
do
:: true ⇒
modei := try;
pif
[1
2]
⇒
if
:: sticki
⇒
sticki := false;
if
:: sticki+1 ⇒
sticki+1 := false;
modei := eat;
sticki := true;
sticki+1 := true;
modei := think;
:: ¬sticki+1 ⇒
sticki := true;
ﬁ
:: ¬sticki
⇒
skip
ﬁ
[1
2]
⇒
if
:: sticki+1
⇒
sticki+1 := false;
if
:: sticki ⇒
sticki := false;
modei := eat;
sticki := true;
sticki+1 := true;
modei := think;
:: ¬sticki ⇒
sticki+1 := true;
ﬁ
:: ¬sticki+1
⇒
skip
ﬁ
ﬁp
od
Figure 10.17: Probmela code for philosopher i.
The semantics of the Probmela speciﬁcation for n philosophers is an MDP. In each state,
each of the philosophers has an enabled action. Most of the actions are nonprobabilistic
in the sense that they yield a unique successor state. Only when the current location
of some philosopher is the pif–ﬁp-statement does its enabled action stand for the coin-
tossing experiment to decide which stick to pick up ﬁrst. This yields two equally likely
successors.
Notation 10.88.
Finiteness, Size, and Graph of an MDP
Let M be an MDP as in Deﬁnition 10.81 (page 833). M is called ﬁnite if the state space
S, the action set Act, and the set AP of atomic propositions are ﬁnite.
The size of M is

Markov Decision Processes
841
deﬁned as the number of edges in the underlying graph of M, i.e., the number of triples
(s, α, t) such that P(s, α, t) > 0. Here, the underlying graph of M denotes the directed
graph (S, E) where the states of M act as vertices and (s, t) ∈E if and only if there exists
an action α such that P(s, α, t) > 0.
Notation 10.89.
LTL/CTL-like Notations
As earlier in this chapter, we will often use LTL- or CTL-like notations with states or sets
of states as atomic propositions. The satisfaction relation then refers to the underlying
graph of the MDP, e.g., for s ∈S and B ⊆S, the statement s |= ∃♦B means that some
state in B is reachable from s in the underlying graph of the MDP M.
The paths in an MDP M describe the potential computations that arise by resolving both
the nondeterministic and probabilistic choices in M. They are obtained by traversing the
underlying graph via consecutive edges. Paths and path fragments in an MDP are deﬁned
as alternating sequences of states and actions.2 More precisely,
Deﬁnition 10.90.
Path in an MDP
An inﬁnite path fragment in an MDP M = (S, Act, P, ιinit, AP, L) is an inﬁnite sequence
s0 α1 s1 α2 s2 α3 . . . ∈(S × Act)ω, written as
π = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . . ,
such that P(si, αi+1, si+1) > 0 for all i ⩾0. Any ﬁnite preﬁx of π that ends in a state is a
ﬁnite path fragment. Paths(s) denotes the set of inﬁnite path fragments that start in state
s; Pathsﬁn(s) denotes the set of ﬁnite path fragments that start in s. Let Paths(M) =

s∈S
Paths(s) and Pathsﬁn(M) = 
s∈S
Pathsﬁn(s).
For Markov chains, the set of paths is equipped with a σ-algebra and a probability mea-
sure that reﬂects the intuitive notion of probabilities for (measurable sets of) paths. For
MDPs, this is slightly diﬀerent since no constraints are imposed on the resolution of the
nondeterministic choices. Let us explain this phenomenon by means of a simple example.
Suppose that M is an MDP with a single initial state s0 with two enabled actions α and β
both representing a coin-tossing experiment. The coin used for action α is supposed to be
fair and yields heads and tails with equal probability, while action β represents ﬂipping an
unfair coin that provides the outcome heads with probability 1
6 and tails with probability
5
6. What is the probability for obtaining the outcome tails for the initial state s0? This
question cannot be answered; in fact, it is senseless, as this probability depends on whether
2As opposed to transition systems, no distinction is made between an execution and a path. The action
names in the paths are used to keep track of the stepwise probabilities.

842
Probabilistic Systems
action α or action β will be chosen. This, however, is not speciﬁed! It is guaranteed that
heads will appear with probability at least 1
6 and at most 1
2.
Also under the assumption that after performing α and β we return to state s0 and repeat
the selection of one of the actions α or β ad inﬁnitum, the nondeterminism in s0 can be
resolved arbitrarily. Any sequence of the actions α and β constitutes a legal behavior of
the MDP. Thus, it might even be the case that action β is never taken, in which case the
probability of obtaining heads within the ﬁrst n coin tosses is 1 −(1
2)n. For the other
extreme, if β is chosen the ﬁrst n times, then the probability of obtaining the outcome
heads at least once in the ﬁrst n rounds is 1 −(5
6)n. However, several other values are
possible for the probability of the event “at least once outcome heads in the ﬁrst n rounds”.
For instance, the value 1 −
5k
6k·2n−k is obtained if during the ﬁrst k ⩽n steps, action β is
chosen and from the (k+1)st step on action α is selected.
This example illustrates that MDPs are not augmented with a unique probability measure.
Instead, reasoning about probabilities of sets of paths of an MDP relies on the resolution
of nondeterminism. This resolution is performed by a scheduler. A scheduler chooses in
any state s one of the enabled actions α ∈Act(s). (Recall that Act(s) is nonempty for
any state s.) It does not impose any constraint on the probabilistic choice that is resolved
once α has been chosen.
Deﬁnition 10.91.
Scheduler
Let M = (S, Act, P, ιinit, AP, L) be an MDP. A scheduler for M is a function S : S+ →Act
such that S(s0 s1 . . . sn) ∈Act(sn) for all s0 s1 . . . sn ∈S+.
The path (fragment)
π = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . .
is called a S-path (fragment) if αi = S(s0 . . . si−1) for all i > 0.
In the literature, a scheduler is sometimes referred to as adversary, policy, or strategy.
Note that for any scheduler, the actions are dropped from the history s0 s1 . . . sn. This is
not a restriction as for any sequence s0 s1 . . . sn the relevant actions αi are given by αi+1 =
S(s0 s1 . . . si). Hence, the scheduled action sequence can be constructed from preﬁxes of
the path at hand. Any path fragment s0
α1
−−→s1
α2
−−→. . .
αn
−−→sn where αi ̸= S(s0 s1 . . . si)
for some i does not describe a path fragment that can be obtained from S.
As a scheduler resolves all nondeterministic choices in an MDP, it induces a Markov
chain. That is to say, the behavior of an MDP M under the decisions of scheduler S can
be formalized by a Markov chain MS. Intuitively, this Markov chain arises by unfolding
M into a tree, or forest if there are two or more states s with ιinit(s) > 0. The paths in the

Markov Decision Processes
843
Markov chain represent the S-paths; the states in the Markov chain are state sequences
of the Markov decision process M. Formally:
Deﬁnition 10.92.
Markov Chain of an MDP Induced by a Scheduler
Let M = (S, Act, P, ιinit, AP, L) be an MDP and S a scheduler on M. The Markov chain
MS is given by
MS = (S+, PS, ιinit, AP, L′)
where for σ = s0s1 . . . sn:
PS( σ, σ sn+1 )
=
P( sn, S(σ), sn+1 )
and L′(σ) = L(sn).
Note that MS is inﬁnite, even if the MDP M is ﬁnite. Intuitively, state s0 s1 . . . sn of MS
represents the conﬁguration where the MDP M is in state sn and s0 s1 . . . sn−1 stands for
the history, i.e., the path fragment that leads from the starting state s0 to the current
state sn. Since S might select diﬀerent actions for path fragments that end in the same
state s, a scheduler as in Deﬁnition 10.91 is also referred to as history-dependent.
Example 10.93.
Markov Chain Induced by a Scheduler
Consider the MDP of Example 10.82 (page 835), illustrated again below:
s
∅
β, 1
2
t
{ a }
u
{ b }
β, 1
2
γ, 1
α, 1
γ, 1
Let us consider some examples of schedulers for this MDP. Scheduler Sα always selects
action α in state s. It is deﬁned by Sα(σ) = α if last(σ) = s, otherwise Sα(σ) = γ. In
a similar way, Sβ is deﬁned by Sβ(σ) = β if last(σ) = s, otherwise Sβ(σ) = γ. The
only Sα-path in M is s
α
−−→t
γ
−→s
α
−−→. . .. The path s
β
−−→s
β
−−→s
β
−−→u
γ
−→s
β
−−→u . . . is a
Sβ-path. Likewise s
β
−−→u
γ
−→s
β
−−→u . . ..
Finally, let S be a scheduler that selects α in s when just returning from u, and β otherwise.
Thus: S(s0 . . . sn s) = α if sn = u and S(s0 . . . sn s) = β otherwise. Let S(s) = α. Note
that this scheduler decides on the basis of the one-but-last visited state. In the states u
and t, the only enabled action γ is chosen.

844
Probabilistic Systems
The Markov chain MSα is the inﬁnite chain:
s
st
sts
stst
1
1
1
1
∅
{ a }
∅
{ a }
An initial fragment of the Markov chain MSβ is depicted in Figure 10.18 on page 844.
s
∅
ss
∅
su
{ b }
sss
∅
ssu
{ b }
sus
∅
ssss
∅
sssu
{ b }
ssus
suss
∅
susu
{ a }
1
2
1
2
1
2
1
2
1
1
2
1
2
1
1
2
1
2
Figure 10.18: Initial fragment of the Markov chain MSβ.
There is a one-to-one correspondence between the S-paths of the MDP M and the paths
in the Markov chain MS. For a S-path
π = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . . ,
the corresponding path in the Markov chain MS is given by
πS = π0 π1 π2 . . .
where πn
=
s0 s1 . . . sn. Vice versa, for a path π0 π1 π2 . . . in the Markov chain MS,
π0 = s0 for some state s0 such that ιinit(s0) > 0 and, for each n > 0, πn = πn−1 sn for
some state sn in the MDP M such that P(sn−1, S(πn−1), sn) > 0. Hence:
s0
S(bπ0)
−−−−→s1
S(bπ1)
−−−−→s2
S(bπ2)
−−−−→. . .
is a S-path in M. In the sequel, we often identify the paths in MS with the corresponding
S-paths in M.

Markov Decision Processes
845
When we consider an ordinary transition system as an MDP (where any action taken in a
state yields a unique successor), the concept of a scheduler is just another formalization of
a path. In the general setting, i.e., for MDPs with proper probabilistic actions, however,
any scheduler induces a set of paths.
As MS is a Markov chain, one can now reason about the probabilities for measurable sets
of S-paths. Let PrM
S , or simply PrS, denote the probability measure PrMS associated
with the Markov chain MS. This measure is the basis for associating probabilities with
events in the MDP M. Let, e.g., P ⊆(2AP)ω be an ω-regular property. Then PrS(P) is
deﬁned (see Notation 10.49, page 796) as the probability measure of the set of S-paths π
in the Markov chain MS such that trace(π) ∈P:
PrS(P) = PrMS(P) = PrMS{ π ∈Paths(MS) | trace(π) ∈P }.
Similarly, for ﬁxed state s of M, which is considered as the unique starting state,
PrS(s |= P) = PrMS
s
{ π ∈Paths(s) | trace(π) ∈P }
where we identify the paths in MS with the corresponding S-paths in M. This explains
the notation above where the paths π ∈Paths(s) in M are identiﬁed with the associated
paths πS in the Markov chain MS.
The quantitative analysis of an MDP M against ω-regular speciﬁcations amounts to es-
tablishing the best lower and/or upper probability bounds that can be guaranteed, when
ranging over all schedulers. This corresponds to computing
inf
S PrS(s |= P)
and
sup
S
PrS(s |= P)
where the inﬁmum and the supremum are taken over all schedulers S for M. Later in
this section, we will establish that the inﬁmum and supremum may be replaced by mini-
mum and maximum, respectively. Ranging over all schedulers and considering minimal or
maximal probabilities corresponds to a worst-case analysis. This is due to the fact that
the full class of schedulers covers all possible resolutions of the nondeterminism that is
present.
Example 10.94.
A Randomized Mutual Exclusion Protocol (Revisited)
Consider again the MDP modeling the mutual exclusion with a randomized arbiter; see
Example 10.83 (page 835). Consider the ω-regular property stating that the ﬁrst process
inﬁnitely often enters its critical section, i.e., □♦crit1. Let scheduler S1 be such that in
any state it only selects one of the enabled actions of the ﬁrst process, and never an action
of the second process. There is a single S1-path where the ﬁrst process successively passes

846
Probabilistic Systems
its three phases (noncritical, waiting, and critical), while the second process does nothing.
Hence,
PrS1(□♦crit1) = 1.
On the other extreme, for the scheduler S2 which always selects one of the actions of the
second process, but ignores the ﬁrst process, we have
PrS2(□♦crit1) = 0.
Let us now consider the probability for the event that the ﬁrst process enters its critical
section within at most three waiting rounds from state ⟨wait1, noncrit2⟩. A waiting round is
interpreted as any path fragment of length three where the ﬁrst process does nothing, while
the second process passes through all three phases. For scheduler S1, this event almost
surely holds. The maximal probability is thus 1. The minimal probability is 1 −
 1
2
3 and
is obtained by the scheduler S3 which selects the action of the second process whenever
entering state ⟨wait1, noncrit2⟩. For the states ⟨wait1, wait2⟩and ⟨wait1, crit2⟩, there is
no proper choice and S3 selects the uniquely enabled action. For the other states, the
decisions of S3 are irrelevant.
Example 10.95.
Randomized Leader Election
Many communication protocols rely on the presence of a certain node (process) that acts
as a leader. In order to select such a leader, a distributed algorithm is employed. We
consider here the symmetric leader election protocol proposed by Itai and Rodeh [223]. It
considers n processes in a unidirectional ring topology. Each node can act in either of two
modes: active or passive. Process i is connected to its neighbors by FIFO channels ci and
ci+1, each of capacity 1. Addition should be considered modulo the ring size n.
In the active mode, process i randomly chooses a bit and sends it via channel ci+1 to its
unique successor on the ring. Process i receives the randomly chosen bit by process i−1
along channel ci. If the bit of process i is 1, while the obtained bit is zero, then process i
switches to the passive mode. Otherwise, process i takes part in the next round.
In the passive mode, process i just acts as a relay node: it passes each bit obtained from
its predecessor i−1 to its successor i+1. The leader has been elected as soon as there is
only one active process left. The Probmela-speciﬁcation for process i is shown in Figure
10.19 on page 847.
The semantics of the composite Probmela program obtained by the speciﬁcations for the
n processes is an MDP. The correctness of the algorithm can formally be established by
showing that under each scheduler almost surely eventually the number of active processes
(as indicated by the variable #active) equals one.

Markov Decision Processes
847
modei := active;
do
:: modei = active ⇒
xi := random(0, 1);
ci+1!xi; ci?yi;
if
:: yi = 1 ∧xi = 0
⇒
modei := passive;
#active := #active −1
:: yi = 0 ∨xi = 1
⇒
skip
ﬁ
:: modei = passive ⇒ci?yi; ci+1!yi
od
Figure 10.19: Probmela code for the randomized leader election protocol.
Deﬁnition 10.91 provides a rather general notion of scheduler and does not impose any
restrictions on the decisions of a scheduler. The function from histories (i.e., ﬁnite path
fragments) to actions does not require any consistency in the decisions and even allows
for schedulers for which the decisions are not computable. For the veriﬁcation of a large
class of qualitative and quantitative properties of ﬁnite MDPs, however, a simple subclass
of schedulers suﬃces. This means, e.g., that the maximal and minimal reachability prob-
abilities (when ranging over the full class of schedulers) are obtained by schedulers of this
subclass. The full generality of schedulers, as in Deﬁnition 10.91, is thus not needed.
Deﬁnition 10.96.
Memoryless Scheduler
Let M be an MDP with state space S. Scheduler S on M is memoryless (or: simple) iﬀ
for each sequence s0 s1 . . . sn and t0 t1 . . . tm ∈S+ with sn = tm:
S(s0 s1 . . . sn) = S(t0 t1 . . . tm).
In this case, S can be viewed as a function S : S →Act.
Stated in words, scheduler S is memoryless if it always selects the same action in a given
state. This choice is independent of what has happened in the history, i.e., which path led
to the current state.
For instance, the schedulers S1, S2 and S3 described informally in Example 10.94 (page
845) are all memoryless. The schedulers Sα and Sβ in Example 10.93 (page 843) are also
memoryless. The scheduler S in Example 10.93 is not memoryless as it bases its decisions
on the one-but-last state.
Memoryless schedulers are somehow extreme as they simply select one alternative (i.e.,
action) per state while ignoring all others. For instance, for the mutual exclusion example,

848
Probabilistic Systems
memoryless schedulers always select the same process to proceed in the states where both
processes are enabled to perform an action. A variant of memoryless schedulers are so-
called ﬁnite-memory schedulers, brieﬂy fm-schedulers. The behavior of a fm-scheduler is
described by a deterministic ﬁnite automaton (DFA). The selection of the action to be
performed in the MDP M depends on the current state of M (as before) and the current
state (called mode) of the scheduler, i.e., the DFA.
Deﬁnition 10.97.
Finite-Memory Scheduler
Let M be an MDP with state space S and action set Act. A ﬁnite-memory scheduler S
for M is a tuple S = (Q, act, Δ, start) where
• Q is a ﬁnite set of modes,
• Δ : Q × S →Q is the transition function,
• act : Q × S →Act is a function that selects an action act(q, s) ∈Act(s) for any
mode q ∈Q and state s of M,
• start : S →Q is a function that selects a starting mode for state s of M.
The behavior of an MDP M under a ﬁnite-memory scheduler S = (Q, act, Δ, start) is
as follows. Initially, a starting state s0 is randomly determined according to the initial
distribution ιinit, i.e., ιinit(s0) > 0. The fm-scheduler S initializes its DFA to the mode
q0 = start(s0) ∈Q. Assume that M is in state s and the current mode of S is q. The
decision of S, i.e., the selected action, is now given by α = act(q, s) ∈Act(s).
The
scheduler subsequently changes to mode Δ(q, s), while M performs the selected action α
and randomly moves to the next state according to the distribution P(s, α, ·).
Let us brieﬂy explain how ﬁnite-memory schedulers are related to the (general) no-
tion of a scheduler, see Deﬁnition 10.91 (page 842).
A ﬁnite-memory scheduler S =
(Q, act, Δ, start) is identiﬁed with the function, i.e., scheduler, S′ : Pathsﬁn →Act which
is deﬁned as follows. For the starting state s0, let S′(s0) = act(start(s0), s0). For path
fragment π = s0 s1 . . . sn let
S′(π) = act(qn, sn)
where q0 = start(s0) and qi+1 = Δ(qi, si) for 0 ⩽i ⩽n.
Finite-memory schedulers enjoy the property that the Markov chain MS can be identiﬁed
with a Markov chain where the states are just pairs ⟨s, q⟩where s is a state in the MDP

Markov Decision Processes
849
M and q a mode of S. Formally, M′
S is the Markov chain with state space S ×Q, labeling
L′(⟨s, q⟩) = L(s), the starting distribution ιinit, and the transition probabilities:
P′
S(⟨s, q⟩, ⟨t, p⟩) = P(s, act(q, s), t).
It can be shown that the inﬁnite Markov chain MS is probabilistic bisimulation-equivalent
to M′
S. This justiﬁes to identifying MS with M′
S. Hence, if M is a ﬁnite MDP, then we
consider MS as a ﬁnite MC.
Memoryless schedulers can be considered as ﬁnite-memory schedulers with just a single
mode. That is, the Markov chain MS induced by the memoryless scheduler S can be
viewed as a Markov chain with state space S. In particular, for ﬁnite M, MS can be
viewed as a ﬁnite Markov chain which results by selecting a single enabled action per state
(and discarding the other enabled actions). For ﬁnite MDP M the number of memoryless
schedulers is ﬁnite, albeit sometimes very large. Assuming, e.g., there are exactly two
enabled actions per state, then the total number of memoryless schedulers is 2n where
n = |S|.
Example 10.98.
Memoryless vs. Finite-Memory Schedulers
Consider the MDP M depicted below:
s0
∅
t
{ a }
u
{ b }
β
γ
α
γ
We have
• Act(s0) = { α, β }, P(s0, α, t) = P(s0, β, u) = 1, and
• Act(t) = Act(u) = { γ } with P(t, γ, s0) = P(u, γ, s0) = 1.
The MDP is deterministic apart from state s0 where a nondeterministic choice between
actions α and β exists. There are only two memoryless schedulers for M: scheduler Sα,
which always chooses α in s0, and scheduler Sβ, which always chooses β for s0.
The β-successor u of s0 is not reachable from s0 in the Markov chain MSα while by
symmetry the α-successor t of s0 is not accessible from s0 under scheduler Sβ. For both
memoryless schedulers, the probability of satisfying the ω-regular property ♦a ∧♦b is thus
zero:
PrSα(s0 |= ♦a ∧♦b) = PrSβ(s0 |= ♦a ∧♦b) = 0.

850
Probabilistic Systems
However, for the—nonmemoryless—scheduler Sαβ, which alternates between selecting α
and β (starting with α, say) on visiting s0, the event ♦a ∧♦b holds almost surely. In
fact, since M does not contain a proper probabilistic choice there is exactly one Sαβ-path
starting in s0:
π = s0
α
−−→t
γ
−→s0
β
−−→u
γ
−→s0
α
−−→t
γ
−→s0
β
−−→. . . ,
and π |= ♦a ∧♦b. Thus: although the event ♦a ∧♦b holds with probability zero under
all memoryless schedulers, there is a nonmemoryless scheduler for which this event almost
surely holds. This shows that the class of memoryless schedulers is insuﬃciently powerful
to characterize the minimal (or, dually, maximal) probability for ω-regular events.
The precise deﬁnition of the ﬁnite-memory scheduler Sαβ = (Q, act, Δ, start) is as follows.
It has two modes: one in which it is only able to select α, while in the other mode only
β can be selected. The scheduler switches mode whenever visiting s0. Formally, the state
space is Q = { qα, qβ }. The action function is given by
act(qβ, s0) = β
and
act(qα, s0) = α,
and act(q, t) = act(q, u) = γ for q ∈Q. Swapping modes is formalized by Δ(qβ, s0) = qα
and Δ(qα, s0) = qβ. If M is in state t or u, then S stays in its current mode. This is
formalized by Δ(qβ, t) = Δ(qβ, u) = qβ and Δ(qα, t) = Δ(qα, u) = qα. As we assume that
on the ﬁrst visit of s0, the action α is selected, the starting mode is deﬁned by start(s) = qα
for all s ∈S.
Remark 10.99.
Randomized Schedulers
Schedulers, as in Deﬁnition 10.91 (page 842), are deterministic since they select a unique
action for the current state.
This can be generalized by allowing schedulers to select
enabled actions probabilistically. That is, given a history a randomized scheduler returns a
probability for each action. (The reader should not confuse this aspect of randomness with
the random selection of the successor state within an MDP.) Mathematically, this means
that randomized schedulers are functions S : S+ →Distr(Act), where Distr(Act) is a
distribution over the set Act. It is required that any action α for which S(s0 . . . sn)(α) > 0
is enabled in the state sn. We do not consider randomized schedulers any further and
just mention that they can be approximated by deterministic schedulers and yield the
same extreme probabilities for ω-regular properties as deterministic schedulers.
Thus,
although they are more general, randomized schedulers do not yield any extra power for
our purposes. This justiﬁes not treating them any further here.

Markov Decision Processes
851
10.6.1
Reachability Probabilities
This section treats the computation of (constrained) reachability probabilities in MDPs.
That is, we are concerned with the following problem. Let M = (S, Act, P, ιinit, AP, L) be
a ﬁnite MDP and B ⊆S a set of target states. The measure of interest is the maximal,
or dually, the minimal probability of reaching a state in B when starting in state s ∈S.
For maximal probabilities this amounts to determining
Prmax(s |= ♦B)
=
sup
S
PrS(s |= ♦B).
Note that the supremum ranges over all, potentially inﬁnitely many, schedulers for M.
This section will show that these maximal probabilities can be computed by solving a linear
program. (Recall that reachability probabilities in MCs can be determined by solving
a linear equation system.) Furthermore, it will be shown that rather than considering
all schedulers—including history-dependent, ﬁnite-memory schedulers, and so forth—it
suﬃces to only consider the subclass of memoryless schedulers. That is, there exists a
memoryless scheduler that maximizes the probabilities to reach B. This holds for any
state s. The supremum can thus be replaced by a maximum.
Reasoning about the maximal probabilities for ♦B is needed, e.g., for showing that
PrS(s |= ♦B) ⩽ε for all schedulers S and some small upper bound 0 < ε ⩽1. Then:
PrS(s |= □¬B) ⩾1 −ε
for all schedulers S.
The task to compute Prmax(s |= ♦B) can thus be understood as showing that a safety
property (namely □¬B) holds with suﬃciently large probability, viz. 1 −ε, regardless of
the resolution of nondeterminism.
Theorem 10.100.
Equation System for Max Reachability Probabilities
Let M be a ﬁnite MDP with state space S, s ∈S and B ⊆S. The vector (xs)s∈S with
xs = Prmax(s |= ♦B) yields the unique solution of the following equation system:
• If s ∈B, then xs = 1.
• If s ̸|= ∃♦B, then xs = 0.
• If s /∈B and s |= ∃♦B, then
xs = max
 
t∈S
P(s, α, t) · xt | α ∈Act(s)

.

852
Probabilistic Systems
The CTL-like notations in the last two items refer to the underlying digraph of the MDP
M. That is, s |= ∃♦B asserts that B is reachable from s. Obviously, xs = Prmax(s |= ♦B)
is a solution of the above equation system. The proof of its uniqueness is rather technical
and omitted here. It uses similar arguments as for Markov chains, see Theorem 10.19 on
page 766. As for Markov chains, the second item could be omitted and replaced by the
requirement that the equations for xs in the third item hold for all states s ∈S \ B. The
uniqueness of xs = Prmax(s |= ♦B) is then, however, no longer guaranteed. As for Markov
chains, one can prove that (xs)s∈S is the least solution in [0, 1]S.
Example 10.101.
Equation System for Max Reachability Probabilities
Consider the MDP M depicted in Figure 10.20 on page 852. Assume we are interested in
Prmax(s |= ♦B) with B = { s2 }. The vector (xs)s∈S with xs = Prmax(s |= ♦B) yields the
unique solution of the following equation system: x3 = 0, x2 = 1 and
x0 = max{ 3
4x2 + 1
4x3, 1
2x2 + 1
2x1 }
and
x1 = 1
2x0 + 1
2x3 = 1
2x0
where xi denotes xsi. The unique solution of this set of linear equations is: (xs)s∈S =
(3
4, 3
8, 1, 0).
s0
s1
s2
α, 3
4
α, 1
2
s3
α, 1
4
β, 1
2
α, 1
2
β, 1
2
α, 1
α, 1
Figure 10.20: Example MDP for max reachability.
The following result asserts that there exists a memoryless scheduler that maximizes the
probabilities of reaching B eventually. This holds for any state s in MDP M.
Lemma 10.102.
Existence of Optimal Memoryless Schedulers
Let M be a ﬁnite MDP with state space S, and B ⊆S.
There exists a memoryless
scheduler S such that for any s ∈S
PrS(s |= ♦B) = Prmax(s |= ♦B).

Markov Decision Processes
853
Proof: Let xs = Prmax(s |= ♦B). The proof is by constructing a memoryless scheduler S
such that PrS(s |= ♦B) = Prmax(s |= ♦B). This goes as follows. For any state s, let
Actmax(s) be the set of actions α ∈Act(s) such that
xs =

t∈S
P(s, α, t) · xt
.
We ﬁrst observe that it does not suﬃce to select arbitrary actions from the set Actmax(s).
For example, consider a state with Actmax(s) = { α, β } where P(s, β, t) = 1 for some
t ∈B, while via α the set B cannot be reached, e.g., since P(s, α, s) = 1. A selection of
actions is thus needed that ensures reachability of B in the induced Markov chain under
S.
Consider the MDP Mmax that results from M by removing the actions β ∈Act(s) \
Actmax(s) from Act(s) for any state s for which B ∩Post∗(s) ̸= ∅. This simpliﬁcation of
M does not change the maximal probabilities to reach B. For s |= ∃♦B, let ∥s∥be the
length of a shortest path fragment from s to B in the MDP Mmax. It follows that ∥s∥= 0
if and only if s ∈B. By induction on n ⩾1 we deﬁne actions S(s) for the states s with
s |= ∃♦B and ∥s∥= n. If ∥s∥= n ⩾1, then choose an action S(s) ∈Actmax(s) such that
P(s, S(s), t) > 0 for some state t with t |= ∃♦B and ∥t∥= n−1. For the states s that
cannot reach B, we select an arbitrary action S(s) ∈Act(s). This yields a memoryless
scheduler S. The induced Markov chain MS is ﬁnite with state space S. Moreover, the
probabilities for ♦B provide the unique solution of the linear equation system:
• If s ∈B, then ys = 1.
• If s ̸|= ∃♦B, then ys = 0.
• If s /∈B and s |= ∃♦B, then ys = 
t∈S
P(s, S(s), t) · yt.
Since the vector (xs)s∈S also solves the above equation system we obtain:
PrS(s |= ♦B) = ys = xs = Prmax(s |= ♦B).
An optimal memoryless scheduler for the MDP in Figure 10.20 and the event ♦B is the
scheduler that selects α in any state.

854
Probabilistic Systems
Theorem 10.100 suggests an iterative approximation technique, called value iteration, to
calculate the values xs = Prmax(s |= ♦B). By means of a backward reachability analysis,
the set of states s is determined such that s |= ∃♦B. These are precisely the states for
which xs > 0. For the states s ∈Pre∗(B) \ B we have
xs =
lim
n→∞x(n)
s
where
x(0)
s
= 0
and
x(n+1)
s
=
max
 
t∈S
P(s, α, t) · x(n)
t
| α ∈Act(s)

.
In the above equation also states in B ∪(S \ Pre∗(B)) might appear. For these states we
have
x(n)
s
= 1 if s ∈B
and
x(n)
s
= 0 if s /∈Pre∗(B).
Note that x(0)
s
⩽x(1)
s
⩽x(2)
s
⩽. . .. Thus, the values Prmax(s |= ♦B) can be approximated
by successively computing the vectors
( x(0)
s
), ( x(1)
s
), ( x(2)
s
), . . .,
until maxs∈S |x(n+1)
s
−x(n)
s | is below a certain (typically very small) threshold.
Example 10.103.
Value Iteration
To illustrate the value iteration, we consider the MDP depicted in Figure 10.21 on page
855. As the atomic propositions are irrelevant, they have been omitted. Let B = { s3 }.
It follows that x(i)
3
= 1 and x(i)
2
= 0 for any i.
The latter follows from the fact that
s2 ̸|= ∃♦B. For the remaining states we obtain
x(i+1)
0
=
max{ 2
3x(i)
4 , x(i)
1 }
x(i+1)
5
=
max{ 2
3x(i)
7 , x(i)
6 }
x(i+1)
1
=
1
2x(i)
1 + 1
9
x(i+1)
6
=
3
5x(i)
6 + 2
5x(i)
5
x(i+1)
4
=
1
4x(i)
5 + 3
4x(i)
6
x(i+1)
7
=
1
2.
The successive computation of the vectors (xs)s∈S yields
(x(0)) = (0, 0, 0, 1, 0, 0, 0, 0)
and
(x(1)) = (0, 1
9, 0, 1, 0, 0, 0, 1
2)
and
(x(2)) = (1
9, 1
6, 0, 1, 0, 1
3, 0, 1
2)
and
(x(3)) = (1
6, 7
36, 0, 1, 1
12, 1
3, 2
15, 1
2) . . .

Markov Decision Processes
855
s4
s0
s1
s2
s6
s7
s3
s5
α, 1
β, 2
3
α, 1
4
β, 1
3
β, 1
3
α, 1
9
β, 2
3
α, 1
2
α, 1
2
α, 1
α, 2
5
α, 3
4
α, 1
2
α, 1
α, 1
α, 3
5
α, 7
18
Figure 10.21: Example of an MDP.
Remark 10.104.
Value Iteration for Step-Bounded Reachability Properties
The value iteration approach also yields a method to compute the maximal probabilities
for the event ♦⩽nB. In fact, we have
x(n)
s
= sup
S
PrS(s |= ♦⩽nB)
where S ranges over all schedulers. Furthermore, there exists a ﬁnite-memory scheduler
S that maximizes the probabilities for ♦⩽nB. (Thus, the supremum can be replaced by
maximum.) Such an optimal fm-scheduler can be composed by using modes 0, 1, . . . , n.
The starting mode is 0 for each state in M. The next-mode function changes from mode
i−1 to i for 1 ⩽i ⩽n. As soon as mode n has been reached, S stays forever in mode n.
For mode i ∈{ 0, 1, . . . , n−1 } and current state s in M, S selects an action α ∈Act(s)
that maximizes the value 
t∈S P(s, α, t)·x(i−1)
t
. The actions S(n, s) are arbitrary. Then,
PrS(s |= ♦⩽nB) = x(n)
s .
An alternative method to compute Prmax(s |= ♦B) is obtained by rewriting the equation
system in Theorem 10.100 into a linear program.

856
Probabilistic Systems
Theorem 10.105.
Linear Program for Max Reachability Probabilities
Let M be a ﬁnite MDP with state space S, and B ⊆S. The vector (xs)s∈S with xs =
Prmax(s |= ♦B) yields the unique solution of the following linear program:
• If s ∈B, then xs = 1.
• If s ̸|= ∃♦B, then xs = 0.
• If s /∈B and s |= ∃♦B, then 0 ⩽xs ⩽1 and for all actions α ∈Act(s):
xs ⩾

t∈S
P(s, α, t) · xt
where 
s∈S
xs is minimal.
Proof: It is not diﬃcult to see that the vector (xs)s∈S with xs = Prmax(s |= ♦B) is a
solution to the equations in the ﬁrst two items, and satisﬁes the inequalities in the last
item. Hence, there exists a solution (ys)s∈S of the above linear program. Since the sum of
the elements of ys is minimal under all vectors that satisfy the linear program, it follows
that 
s xs ⩾
s ys.
It remains to show the uniqueness of the solution. In fact, any solution (ys)s∈S of the linear
program is also a solution of the equation system in Theorem 10.100. Due to the minimality
of 
s∈S ys, the value ys in the third item agrees with max{ 
t P(s, α, t)·yt | α ∈Act(s) }.
This can be seen as follows. If this would not hold, then we could apply the value iteration
process starting with x(0)
s
= ys for all s. This yields a decreasing sequence of vectors
(x(n)
s )n⩾0. The limit (y′
s)s∈S solves both the ﬁrst three items of the linear program and
the equations in Theorem 10.100. As y′
s = limn→∞x(n)
s
⩽ys, the minimality of 
s∈S ys
as a solution of the inequalities in Theorem 10.105 yields y′
s = ys.
Thus, Theorem 10.100 yields that ys = xs = Prmax(s |= ♦B) for all states s.
Example 10.106.
Linear Program
Consider again the MDP in Figure 10.21 and let B = { s3 }. The equations of the linear

Markov Decision Processes
857
program for Prmax(s |= ♦B) are:
x0
⩾
2
3x4
x0
⩾
x1
x1
⩾
1
2x1 + 1
9
x2
=
0
x3
=
1
x4
⩾
1
4x5 + 3
4x6
x5
⩾
2
3x7
x5
⩾
x6
x6
⩾
3
5x6 + 2
5x5
x7
⩾
1
2
Note that the third item in Theorem 10.105 can be rewritten into

t∈S?\{ s }
P(s, α, t) · xt + (1 −P(s, α, s)) · xs
⩾
P(s, α, B)
where P(s, α, B) = 
t∈B P(s, α, t). The set S? contains all states such that the value
xs = Prmax(s |= ♦B) is not ﬁxed to 0 or 1 by the ﬁrst two items, i.e., S? = { s ∈S \ B |
s |= ∃♦B }. Hence:
s ∈S?
if and only if
s /∈B and Prmax(s |= ♦B) > 0.
Thus, the third item in the above theorem can be read as a linear inequality A · x ⩾b
where x is the vector (xs)s∈S? and A is a matrix with a row for each pair (s, α) with
s ∈S? and α ∈Act(s), and two extra rows for each state s ∈S? and a column for each
state t ∈S?. The entry of A in the row for (s, α) and column for state t equals P(s, α, t)
provided s ̸= t.
For s = t the entry of A equals 1 −P(s, α, s).
The two extra rows
represent the inequality 0 ⩽xs ⩽1, which can be split into the two constraints xs ⩾0
and −xs ⩾−1. Similarly, b is a vector with a component for each pair (s, α) where s ∈S?
and α ∈Act(s) and two extra components per state s ∈S?. The value of b for (s, α) is
the probability of moving from s via action α to a state in B (i.e., the value P(s, α, B)).
In this sense, Theorem 10.105 yields a characterization of the values Pr(s |= ♦B) as the
linear optimization problem which asks for the unique solution of A·x ⩾b under the side
condition that 
s∈S xs is minimal under all solutions of Ax ⩾b. The precise values for
Prmax(s |= ♦B) can thus be computed by standard algorithms to solve linear programs,
e.g., the simplex algorithm or polytime methods [367].
Corollary 10.107.
Complexity of Computing Max Reachability Probabilities
For ﬁnite MDP M with state space S, B ⊆S and s ∈S, the values Prmax(s |= ♦B) can
be computed in time polynomial in the size of M.
As a consequence, the question whether PrS(s |= ♦B) ⩽p for some upper bound p ∈[0, 1[
is decidable in polynomial time.
This result, however, is more of theoretical interest

858
Probabilistic Systems
than of practical relevance. In practice, the simplex method often outperforms polytime
algorithms for linear programs, although its worst-case time complexity is exponential.
Experiments with randomized distributed algorithms (modeled as MDPs) indicates that
the value iteration method is often faster than the simplex method.
The value iteration or linear program approach can be improved by ﬁrst computing the
set of states s with Prmax(s |= ♦B) = 1. This can be eﬃciently done by standard graph
algorithms. For these states, the corresponding equation and inequalities, respectively,
for xs in the third item of Theorem 10.100 and 10.105 respectively can be omitted. This
simpliﬁes the value iteration procedure and decreases the size of the linear program.
Let us now consider the qualitative reachability analysis of a ﬁnite MDP M. The goal
is to compute the set of states s for which Prmax(s |= ♦B) = 1.
Similar to the case
with Markov chains, the states in B are ﬁrst made absorbing. This means that any state
s ∈B is equipped with a single enabled action αs with P(s, αs, s) = 1. Since there exists
a memoryless scheduler that maximizes the probabilities for the event ♦B, it suﬃces to
compute the set of states s such that PrS(s |= ♦B) = 1 for some memoryless scheduler S,
say. The latter is equivalent to the requirement that no state t ̸|= ∃♦B is reachable from
s in the Markov chain MS via a path fragment in S \ B. As the number of memoryless
schedulers may be exponential (in the size of M), considering all such schedulers is not
an adequate solution.
However, the analysis of the underlying graph of M suﬃces to determine all states s where
Prmax(s |= ♦B) = 1. This approach is iterative and successively removes all vertices u
with Prmax(u |= ♦B) < 1.
Initially, each vertex u ∈U0 with U0 = S \ Sat(∃♦B) is
removed. The set U0 can simply be determined by a graph analysis. Then, for all states
t, all actions α are deleted from Act(t) that satisfy Post(t, α) ∩U0 ̸= ∅. If after deleting
these actions, Act(t) = ∅, then t will be removed. This procedure is repeated as long as
possible, and yields the MDP M1. Then, we restart the whole procedure with M1 rather
than M, etc., until all states in the obtained MDP Mi can reach B.
This approach is outlined in Algorithm 45. This algorithm treats the MDP as a directed
graph where the successors of any vertex t ∈S are the pairs (t, α) with α ∈Act(t). The
outgoing edges of the auxiliary vertices (t, α) lead to the vertices u ∈Post(t, α) = { u ∈
S | P(t, α, u) > 0 }. For u ∈S, Pre(u) denotes the set of state action pairs (t, α) ∈S ×Act
such that P(t, α, u) > 0. Removing α from Act(t) means removing the auxiliary vertex
(t, α), the edge from vertex t to vertex (t, α), and the outgoing edges from (t, α).

Markov Decision Processes
859
Algorithm 45 Computing the set of states s with Prmax(s |= ♦B) = 1
Input: MDP M with ﬁnite state space S, B ⊆S for s ∈B : Act(s) = { αs } and P(s, αs, s) = 1
(i.e., B is absorbing)
Output: { s ∈S | Prmax(s |= ♦B) = 1 }
U := { s ∈S | s ̸|= ∃♦B };
repeat
R := U;
while R ̸= ∅do
let u ∈R;
R := R \ { u };
for all (t, α) ∈Pre(u) such that t /∈U do
remove α from Act(t);
if Act(t) = ∅then
R := R ∪{ t };
U := U ∪{ t };
ﬁ
od
(* all incoming edges of u have been removed *)
remove u and its outgoing edges from M
od
(* determine the states s that cannot reach B in the modiﬁed MDP *)
U := {s ∈S \ U | s ̸|= ∃♦B};
until U = ∅
(* all states can reach B in the generated sub-MDP of M *)
return all states in the remaining MDP

860
Probabilistic Systems
Lemma 10.108.
Correctness of Algorithm 45
For ﬁnite MDP M and B, a set of states in M, Algorithm 45 returns the set of all states
s in M such that Prmax(s |= ♦B) = 1.
Proof: The correctness of Algorithm 45 relies on the following two facts: (i) for any state
t which is removed, Prmax(t |= ♦B) < 1, and (ii) for any action α removed from Act(t)
there is no memoryless scheduler S with S(t) = α and PrS(t |= ♦B) = 1.
Now let M0 = M, M1, M2, . . . , Mi be the sequence of MDPs that are generated by
Algorithm 45. More precisely, Mj is the MDP obtained by the ﬁrst j iterations of the
repeat loop. The ﬁnal MDP Mi still contains all states s where Prmax(s |= ♦B) = 1 and
all actions α ∈Act(s) that can be used by an optimal (memoryless) scheduler for ♦B.
Let S be a ﬁnite-memory scheduler for Mi that treats all enabled actions in a fair way
(i.e., if t is visited inﬁnitely often, then any action that is enabled in t is taken inﬁnitely
often). Then the (ﬁnite) Markov chain MS
i
induced by S enjoys the property that all
states can reach B. Corollary 10.30 on page 777 then yields that PrS(s |= ♦B) = 1 for
all states s in Mi. Thus, the set of states in Mi agrees with the set of states where
Prmax(s |= ♦B) = 1.
The worst-case complexity of Algorithm 45 is quadratic in the size of M. This can be
seen as follows. The maximal number of iterations of the outermost loop is N = |S|, as in
each iteration at least one state is eliminated. In each iteration, the set of states that can
reach B needs to be computed. This takes O(size(M)) time. The other operations cause
the overall cost O(size(M)), since any state t and state action pair (t, α) can be removed
at most once.
So far, this section has addressed the problem of computing the maximal probabilities for
reaching a certain set B of states in an MDP. Typically, B represents a set of bad states
and the aim is to show that, regardless of the scheduling policy, the probability of entering
a B-state is suﬃciently small. We will now show that similar techniques are applicable
to compute the minimal probabilities for reaching a certain set of states. When, e.g., B
stands for a set of good states then
Prmin(s |= ♦B) = inf
S PrS(s |= ♦B)
yields the best lower bound that can be guaranteed for the probability of eventually
reaching B. In analogy to Theorem 10.100, the minimal probabilities can be characterized
by an equation system. To ensure the uniqueness of the solution of this equation system
it is required that all states s such that Prmin(s |= ♦B) = 0 have the value xs = 0.

Markov Decision Processes
861
Theorem 10.109.
Equation System for Min Reachability Probabilities
Let M be a ﬁnite MDP with state space S and B ⊆S. The vector (xs)s∈S with xs =
Prmin(s |= ♦B) yields the unique solution of the following equation system:
• If s ∈B, then xs = 1.
• If Prmin(s |= ♦B) = 0, then xs = 0.
• If Prmin(s |= ♦B) > 0 and s /∈B, then:
xs = min
 
t∈S
P(s, α, t) · xt | α ∈Act(s)

.
Theorem 10.109 suggests that we ﬁrst compute the set containing all states s satisfying
Prmin(s |= ♦B) = 0, followed by a value iteration method to obtain an approximation of
the values xs = Prmin(s |= ♦B) for the states with xs > 0 and s /∈B. For this, we put
x(i)
s
= 0 if Prmin(s |= ♦B) = 0, and x(i)
s
= 1 if s ∈B, for all i. For the remaining states,
the iteration is started with x(0)
s
= 0. For successive iterations, let
x(n+1)
s
= min
 
t∈S
P(s, α, t) · x(n)
t
| α ∈Act(s)

.
Then: x(0)
s
⩽x(1)
s
⩽x(2)
s
⩽. . . and
lim
n→∞x(n)
s
= Prmin(s |= ♦B).
Moreover, x(n)
s
agrees with the minimal probability of reaching B within at most n steps,
where the minimum is taken over all schedulers. That is:
x(n)
s
= min
S PrS(s |= ♦⩽nB).
In fact, this minimum always exists and can be established by a ﬁnite-memory scheduler.
This scheduler has n modes, 0 through n−1.
The starting mode is 0, the next-mode
function switches from mode i−1 to mode i for 0 < i ⩽n and stays forever in mode n
after the nth step. S(i, s) is an action α ∈Act(s) that minimizes the value 
t∈S P(s, α, t)·
x(i−1)
t
. The actions S(n, s) ∈Act(s) are irrelevant.
The preprocessing required to compute the set
Smin
=0
= { s ∈S | Prmin(s |= ♦B) } = 0

862
Probabilistic Systems
can be performed by graph algorithms. The set Smin
=0 is given by S \ T where
T =

n⩾0
Tn
and T0 = B and, for n ⩾0:
Tn+1 = Tn ∪{ s ∈S | ∀α ∈Act(s) ∃t ∈Tn. P(s, α, t) > 0 }.
As T0 ⊆T1 ⊆T2 ⊆. . . ⊆S and S is ﬁnite, the sequence (Tn)n⩾0 eventually stabilizes,
i.e.,there exists some n ⩾0 such that Tn = Tn+1 = . . . = T.
Lemma 10.110.
Characterization of Smin
=0
Let M and T be as above. Then, Smin
=0
= S \ T, i.e., for all states s ∈S:
Prmin(s |= ♦B) > 0
iﬀ
s ∈T.
Proof: We show by induction on n that Prmin(s |= ♦B) > 0 for all s ∈Tn. Base case:
For n=0 the claim trivially holds as T0 = B and PrS(s |= ♦B) = 1 for each scheduler S
and state s ∈B. Induction step: Assume the claim holds for 0 through n−1. Let n ⩾1.
Consider s ∈Tn\Tn−1 and let S be a scheduler. Let α = S(s) be the action selected by S
when M starts in s. By deﬁnition of Tn, Tn−1 ∩Post(s, α) ̸= ∅. Let t ∈Tn−1 ∩Post(s, α).
By induction hypothesis, it holds that Prmin(t |= ♦B) > 0. For s ∈Tn, it then holds that
PrS(s |= ♦B) ⩾P(s, α, t) · Prmin(t |= ♦B) > 0.
Therefore, Prmin(s |= ♦B) > 0.
Vice versa, if s ∈S \ T, then Post(s, α) ∩T = ∅for some action α ∈Act(s). Hence, we
may consider a memoryless scheduler S which selects for each state s ∈S \ T such action
α ∈Act(s). Then, in the Markov chain MS the states in S \ T cannot reach any state
in T. Therefore, PrS(s |= ♦B) = 0 for all s ∈S \ T. This yields Prmin(s |= ♦B) = 0 for
s ∈S \ T.
The computation of S \ Smin
=0
= T = 
n⩾0 Tn can be performed in time linear in the size
of M. The main steps of such a linear-time algorithm are summarized in Algorithm 46.
To speed up the convergence of the value iteration process, one might also compute
Smin
=1
= { s ∈S | Prmin(s |= ♦B) = 1 } using graph analysis techniques. Note that the
computation of Smin
=1 also solves the qualitative veriﬁcation problem which asks whether
♦B almost surely holds under all schedulers.

Markov Decision Processes
863
Algorithm 46 Computing the set of states s with Prmin(s |= ♦B) = 0
Input: ﬁnite MDP M with state space S and B ⊆S
Output: { s ∈S | Prmin(s |= ♦B) = 0 }
T := B;
R := B;
while R ̸= ∅do
let t ∈R;
R := R \ { t };
for all (s, α) ∈Pre(t) with s /∈T do
remove α from Act(s)
if Act(s) = ∅then
add s to R and T
ﬁ
od
od
return T
Lemma 10.111.
Characterization of Smin
=1
Let M be a ﬁnite MDP with state space S, B ⊆S and s ∈S. The following statements
are equivalent:
(a) Prmin(s |= ♦B) < 1.
(b) There exists a memoryless scheduler S such that PrS(s |= □¬B) > 0.
(c) s |= ∃((¬B) U t) for some state t such that PrS(t |= □¬B) = 1 for some memoryless
scheduler S.
Proof: (a) =⇒(b): If Prmin(s |= ♦B) < 1 then, by Lemma 10.113 (page 865), PrS(s |=
♦B) < 1 for some memoryless scheduler S. But then
PrS(s |= □¬B) = 1 −PrS(s |= ♦B) > 0.
(b) =⇒(c): Let S be a memoryless scheduler such that PrS(s |= □¬B) > 0. Consider the
Markov chain MS. As S is memoryless, MS is ﬁnite. By Theorem 10.27 on page 775,
almost all paths in MS eventually enter a BSCC and visit all its states inﬁnitely often.
Hence, there is a BSCC C of MS such that C ∩B = ∅and
PrS(s |= ∃((¬B) U C)) > 0.
Furthermore, PrS(t |= □¬B) = 1 for all states t ∈C.

864
Probabilistic Systems
(c) =⇒(a): Assume s |= ∃((¬B) U t) for some state t such that PrS(t |= □¬B) = 1 for
some memoryless scheduler S. Let
π = s0
α1
−−→s1
α2
−−→. . .
αn
−−→sn
such that s0 = s, si /∈B for 0 ⩽i < n and sn = t. Let scheduler S′ generate this path
fragment with positive probability, i.e., S′(s0s1 . . . si) = αi+1 for 0 ⩽i < n. Moreover, S′
behaves as S for all state sequences that extend s0s1 . . . sn. Then:
PrS′(s |= □¬B) ⩾

1⩽i⩽n
P(si−1, αi, si) > 0
and therefore PrS′(s |= ♦B) < 1.
Lemma 10.111 suggests computing the set Smin
=1
as the complement of the set of states
that can reach T with
T = { s ∈S | Prmax(t |= □¬B) = 1 }
via a path fragment through S \ B. The set T can be obtained as follows. Initially, let
A(s) = Act(s) for any s ∈S \ B and A(t) = ∅for t ∈B. Any state t ∈B is removed
from T. This entails that for all state action pairs (s, α) ∈Pre(t) such that α ∈A(s) and
α is removed from A(s). If in this way A(s) becomes empty for some state s ∈T, then s
is removed from T by the same procedure. That is, all state action pairs (u, β) ∈Pre(s)
with β ∈A(u) are considered and β is removed from Act(u). This elimination process is
repeated as long as there are states s with A(s) = ∅. This results in a sub-MDP with
state space T ⊆S \ B and nonempty action sets A(t) ⊆Act(t) such that Post(t, α) ⊆T
for all t ∈T and α ∈A(t).
Clearly, PrS(t |= □¬B) = 1 for any state t ∈T and any scheduler S which only selects
actions from A(t) for state sequences t0t1 . . . tn with tn = t. Vice versa, by induction on
the number of iterations, it can be shown that Prmax(s |= □¬B) < 1 for all states s that
have been removed during the elimination process. Hence, indeed:
T = { s ∈S | Prmax(t |= □¬B) = 1 }.
We conclude that
Smin
=1
= { s ∈S | s ̸|= ∃(¬B) U T } = S \ Sat(∃((¬B) U T))
and obtain the following theorem:

Markov Decision Processes
865
Theorem 10.112.
Qualitative Analysis for Min Reachability Problems
The sets Smin
=0 and Smin
=1 can be computed using graph-based algorithms in time O(size(M)).
Using similar techniques as in Lemma 10.102 (page 852), the above equation system can be
used to show the existence of a memoryless scheduler S that minimizes the probabilities
of reaching B for all states.
Lemma 10.113.
Existence of Optimal Memoryless Schedulers
Let M be a ﬁnite MDP, B ⊆S, and s ∈S. There exists a memoryless scheduler S that
minimizes the probabilities of eventually reaching B, i.e., for all states s:
PrS(s |= ♦B) = Prmin(s |= ♦B).
Furthermore, similar to the case for maximal reachability probabilities, the above equation
system can be rewritten into a linear program. This linear program is deﬁned by
• If Prmin(s |= ♦B) = 1, then xs = 1.
• If Prmin(s |= ♦B) = 0, then xs = 0.
• If 0 < Pr(s |= ♦B) < 1, then 0 < xs < 1 and for all actions α ∈Act(s):
xs ⩽

t∈S
P(s, α, t) · xt
where 
s∈S
xs is maximal.
Remark 10.114.
Constrained Reachability
The techniques for the events ♦B or ♦⩽nB are also applicable to treat the constrained
reachability properties C U B or C U ⩽nB. This works as follows. As a ﬁrst step, all states
in s ∈S \ (C ∪B) are made absorbing. That is, their enabled actions are replaced by a
single action, αs, say, with P(s, αs, s) = 1. In the thus obtained MDP, Pr∗(s |= ♦B) or
Pr∗(s |= ♦⩽nB), respectively, are determined in the described manner. (Here, ∗is either
max or min.)
By Lemmas 10.102 and 10.113, there exists a memoryless scheduler that optimizes (i.e.,
maximizes or minimizes) the unbounded constrained reachability probabilities C U B. For

866
Probabilistic Systems
the step-bounded event C U ⩽nB, ﬁnite-memory schedulers exist that yield the extreme
probabilities.
In fact, the techniques sketched in this section provide the key ingredients for PCTL model
checking of ﬁnite MDPs.
10.6.2
PCTL Model Checking
In Section 10.2, the probabilistic computation tree logic (PCTL) has been introduced
as a CTL-like branching time logic for Markov chains.
Without changing the syntax,
PCTL can also serve as a temporal logic to specify important properties of ﬁnite MDPs.
The main (and only) diﬀerence with the setting for Markov chains is that the probabilistic
operator PJ(·) ranges over all schedulers. Thus, PJ(ϕ) asserts that the probability bounds
given by J for the event speciﬁed by ϕ are satisﬁed, regardless of the resolution of the
nondeterminism.
The syntax of PCTL as a logic for MDPs is the same as for Markov chains, see Deﬁnition
10.36 on page 781. For an MDP M = (S, Act, P, ιinit, AP, L), the satisfaction relation for
PCTL state- and path formulae is deﬁned as follows:
s |= true
s |= a
iﬀ
a ∈L(s)
s |= ¬Φ
iﬀ
s ̸|= Φ
s |= Φ1 ∧Φ2
iﬀ
s |= Φ1 and s |= Φ2
s |= PJ(ϕ)
iﬀ
for all schedulers S for M : PrS(s |= ϕ) ∈J.
Here, PrS(s |= ϕ) is a shorthand for PrS
s { π ∈Paths(s) | π |= ϕ }. We write SatM(Φ), or
brieﬂy Sat(Φ), for the satisfaction set of Φ in M, i.e.,
SatM(Φ) = { s ∈S | s |= Φ }.
The semantics of path formulae is exactly the same as for PCTL interpreted over Markov
chains. Thus, the probabilistic operator PJ(·) imposes probability bounds for all sched-
ulers. In particular, we have
• s |= P⩽p(ϕ) if and only if Prmax(s |= ϕ) ⩽p, and
• s |= P⩾p(ϕ) if and only if Prmin(s |= ϕ) ⩾p

Markov Decision Processes
867
where Prmax(s |= ϕ) = supSPrS(s |= ϕ) with S ranging over all possible schedulers for
M. Similarly, Prmin(s |= ϕ) denotes the inﬁmum of the probability for the event speciﬁed
by ϕ under all schedulers. For ﬁnite MDPs, the same holds for strict lower and upper
probability bounds (i.e., < p and > p), since for any PCTL path formula ϕ there exists a
ﬁnite-memory scheduler that maximizes or minimizes the probabilities for ϕ (see Remark
10.114 on page 865). Thus for ﬁnite MDPs:
Prmax(s |= ϕ) = max
S PrS(s |= ϕ) and Prmin(s |= ϕ) = min
S PrS(s |= ϕ).
The always operator can be derived as in the setting of Markov chains. For instance,
P⩽p(□Φ) can be deﬁned as P⩾1−p(♦¬Φ). Then:
s |= P⩽p(□Φ)
iﬀ
PrS(s |= □Sat(Φ)) ⩽p for all schedulers S.
For example, for the mutual exclusion protocol with a randomized arbiter, the PCTL
speciﬁcation
P=1(□(¬crit1 ∨¬crit2)) ∧

i=1,2
P=1( □( waiti →P⩾7
8 (♦⩽9criti) ) )
asserts the mutual exclusion property (ﬁrst conjunct) and that every waiting process will
enter its critical section within the next nine steps with at least probability 7
8 (regardless
of the scheduling policy).
Equivalence of PCTL Formulae
To distinguish the equivalence relations on PCTL
state formulae that result from the Markov chain semantics and the MDP semantics, we
use the notations ≡MDP and ≡MC, respectively. The relation ≡MDP denotes the equivalence
of PCTL formulae when interpreted over Markov decision processes. That is, Φ ≡MDP Ψ
if and only if for all MDPs M, it holds that SatM(Φ) = SatM(Ψ). Similarly, Φ ≡MC Ψ if
and only if for all Markov chains M, SatM(Φ) = SatM(Ψ). Since any Markov chain can
be viewed as an MDP where each state has a single enabled action, ≡MDP is ﬁner than
≡MC. That is:
Φ ≡MDP Ψ
implies
Φ ≡MC Ψ.
The converse, however, does not hold. This can be shown as follows. Consider a formula
of the form P⩽p(ϕ) with 0 ⩽p < 1 and assume ϕ is a satisﬁable, but not valid, path
formula such as ⃝a or a U b. Then:
P⩽p(ϕ) ≡MC ¬P>p(ϕ).
This equivalence is trivial since the probability for an event E in a Markov chain is ⩽p if
and only if the probability for E is not > p. An analogous argument is not applicable to
Markov decision processes, as universal quantiﬁcation is inherent in the semantics of the
probabilistic operator PJ(·):

868
Probabilistic Systems
s |= P⩽p(ϕ)
iﬀ
PrS(s |= ϕ) ⩽p for all schedulers S
s |= ¬P>p(ϕ)
iﬀ
not

PrS(s |= ϕ) > p for all schedulers S

iﬀ
PrS(s |= ϕ) ⩽p for some scheduler S
Hence, P⩽p(ϕ) ̸≡MDP ¬P>p(ϕ). Nonetheless, several equivalences established for MCs also
hold for MDPs, such as, e.g.,
P]p,q](ϕ) ≡MDP P>p(ϕ) ∧P⩽q(ϕ).
Let us brieﬂy consider the relationship between the qualitative fragment of PCTL and
CTL. The qualitative fragment for MDPs contains four qualitative properties built by the
probabilistic operators:
P=1(ϕ) and P>0(ϕ) and P<1(ϕ) and P=0(ϕ).
As opposed to the setting for Markov chains, these operators cannot be derived from each
other. Thus, the syntax of the qualitative fragment of PCTL has to be extended with
P<1(ϕ) and P=0(ϕ). As for Markov chains, the formulae P=1(□a) and ∀□a are equivalent.
The same applies to P>0(a U b) and ∃(a U b). The qualitative PCTL formulae P>0(□a)
and P=1(♦a) are not deﬁnable in CTL and, vice versa, the CTL formulae ∃□a and ∀♦a
cannot be speciﬁed by a qualitative PCTL formula.
PCTL Model Checking
Given a ﬁnite MDP M and a PCTL state formula Φ, to check
whether all initial states s satisfy Φ, an adapted version of the PCTL model-checking
algorithm for Markov chains can be employed. That is, as for other CTL-like branching
time logics, one successively computes the satisfaction sets Sat(Ψ) for the state subformulae
of Φ. The only diﬀerence from PCTL model checking for MCs is the treatment of the
probabilistic operator. Consider, e.g., Ψ = P⩽p(⃝Ψ′). The model checker determines the
values
xs = Prmax(s |= ⃝Ψ′) = max{

t ∈Sat(Ψ′)
P(s, α, t) | α ∈Act(s)}
and returns Sat(Ψ) = { s ∈S | xs ⩽p }. For until formulae Ψ = P⩽p(Ψ1 U Ψ2) and Ψ =
P⩽p(Ψ1 U⩽n Ψ2), we apply the techniques explained in the previous section to compute
xs = Prmax(s |= C U B) or xs = Prmax(s |= C U ⩽nB).
This can be done by either
solving a linear program or by means of value iteration.
The model checker returns
Sat(Ψ) = { s ∈S | xs ⩽p }. The treatment of strict upper probability bounds < p or
lower probability bounds (⩾p or > p) is similar. Formulae PJ(·) with probability intervals
J ⊆[0, 1] diﬀerent from [0, p[, [0, p], ]p, 1], [p, 1] can be treated by splitting PJ(·) into a
conjunction of a formula with an upper bound and a formula with a lower probability
bound.

Markov Decision Processes
869
The overall time complexity of this approach is linear in the length of the formula Φ and
the maximal step-bound nmax of a subformula PJ(Ψ1 U ⩽nΨ2) of Φ and polynomial in the
size of M, provided that a linear program solver with polynomial worst-case running time
is used.
Theorem 10.115.
Time Complexity of PCTL Model Checking for MDPs
For ﬁnite MDP M and PCTL formula Φ, the PCTL model-checking problem M |= Φ can
be determined in time
O( poly(size(M)) · nmax · |Φ| )
where nmax is the maximal step bound that appears in a sub-path formula Ψ1 U ⩽nΨ2 of Φ
(and nmax = 1 if Φ does not contain a step-bounded until operator).
For CTL we explained the concept of witnesses and counterexamples for state formulae ∃ϕ
and ∀ϕ; see Section 6.6 (page 373). Witnesses and counterexamples have been deﬁned as
“suﬃciently long” initial ﬁnite path fragments π that can be extended to a path π where
π |= ϕ (witness) and π ̸|= ϕ (counterexample). In the probabilistic case, the situation is
analogous, but now memoryless (or ﬁnite-memory) schedulers play the role of the ﬁnite
path fragments. If, e.g., s ̸|= P⩽p(Ψ1 U Ψ2), then Prmax(s |= Ψ1 U Ψ2) > p and there exists
a memoryless scheduler S such that PrS(s |= Ψ1 U Ψ2) > p. Note that such a memoryless
scheduler is computed implicitely by the algorithms presented for the computation of
Prmax(s |= Ψ1 U Ψ2) > p.
This scheduler S can be viewed as a counterexample for
s ̸|= P⩽p(Ψ1 U Ψ2). Of course, it suﬃces to represent only some information on S, e.g.,
S’s decisions on states where Ψ1 ∧¬Ψ2 holds. Counterexamples for other probability
bounds (⩾p, > p or < p) and other path formulae can be obtained in an analogous
way. Memoryless schedulers are suﬃcient as long as the step-bounded until operator is
not used. For s ̸|= PJ(Ψ1 U ⩽nΨ2) a counterexample can be obtained by a ﬁnite-memory
scheduler S where PrS(s |= Ψ1 U ⩽nΨ2) /∈J. The concept of witnesses can be realized
for formulae of the form ¬PJ(ϕ), since they require the existence of a scheduler where the
probability for ϕ is not in J. In fact, any memoryless (or ﬁnite-memory) scheduler S with
PrS(s |= ϕ) /∈J constitutes a proof for s |= ¬PJ(ϕ). Again, memoryless schedulers are
suﬃcient for PCTL without the step-bounded until operator.
10.6.3
Limiting Properties
Recall that for analyzing ﬁnite MCs against liveness properties, the key observation is
that almost surely a BSCC will be reached whose states are visited inﬁnitely often; see
Theorem 10.27 (page 775). An analogous result can be established for ﬁnite MDPs by
means of so-called end components. An end component is a sub-MDP that is closed under
probabilistic choices and that is strongly connected.

870
Probabilistic Systems
Deﬁnition 10.116.
Sub-MDP
Let M = (S, Act, P, ιinit, AP, L) be a Markov decision process. A sub-MDP of M is a pair
(T, A) where ∅̸= T ⊆S and A : T →2Act is a function such that:
• ∅̸= A(s) ⊆Act(s) for all states s ∈T,
• s ∈T and α ∈A(s) implies Post(s, α) = { t ∈S | P(s, α, t) > 0 } ⊆T.
A sub-MDP (T ′, A′) is said to be contained in a sub-MDP (T, A) if T ′ ⊆T and A′(t) ⊆A(t)
for all states t ∈T.
The digraph G(T,A) induced by a sub-MDP (T, A) is the directed graph with the vertex
set
T ∪{ ⟨s, α⟩∈T × Act | α ∈A(s) }
and the edges s →⟨s, α⟩for s ∈S and α ∈A(s) and ⟨s, α⟩→t for all t ∈Post(s, α).
Deﬁnition 10.117.
End Component
An end component of MDP M is a sub-MDP (T, A) such that the digraph G(T,A) induced
by (T, A) is strongly connected.
Let EC(M) denote the set of end components of M.
Example 10.118.
End Component
Consider the MDP M of Figure 10.21.
The sub-MDP (T, A) with T = { s5, s6 } and
A(s6) = A(s5) = { α } is an end component of M. The digraph G(T,A) = (V, E) where
V = { s5, ⟨s5, α⟩, s6, ⟨s6, α⟩} where s5 →⟨s5, α⟩, ⟨s5, α⟩→s6, s6 →⟨s6, α⟩and ⟨s6, α⟩→
s6 and ⟨s6, α⟩→s5.
For each end component (T, A) there is a scheduler, even a ﬁnite-memory one, that almost
surely enforces staying forever in T while visiting all states in T inﬁnitely often.
Lemma 10.119.
Recurrence Property of End Components
For end component (T, A) of ﬁnite MDP M, there exists a ﬁnite-memory scheduler S
such that for any s ∈S:
PrS( s |= □T ∧

t∈T
□♦t ) = 1.

Markov Decision Processes
871
Proof: The goal is to deﬁne an fm-scheduler S that schedules all actions α ∈A(s) inﬁnitely
often, but never an action β /∈A(s). For s ∈T let
A(s) = { αs
0, . . . , αs
ks−1 }.
The modes of S are the functions q : T →IN such that 0 ⩽q(s) < ks. The scheduler S
selects the action in the current state s according to a round-robin policy. That is, if αi
is the last selected action in state s, the next action to be selected is αi+1 (modulo ks).
Formally:
act(q, s) = αi
where
i = q(s) mod ks.
The next mode function is given by Δ(q, s) = p where p(t) = q(t) for t ∈T \ { s } and
p(s) = (q(s)+1) mod ks. The starting modes are given by start(·) = q0 where q0(s) = 0
for all s ∈T.
The decisions of S for states outside T are irrelevant.
For instance,
act(q, s) = αs, Δ(q, s) = q for all modes q and states s /∈T.
Since S only selects actions in A(s) for s ∈T, all S-paths that start in a state s ∈T
never visit a state outside T. As the digraph induced by (T, A) is strongly connected, the
(ﬁnite) MC induced by S consists of a single BSCC. By Theorem 10.27 (page 775), almost
surely any state in MS will be visited inﬁnitely often.
For an inﬁnite path
π = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . .
in a ﬁnite MDP M, the limit of π, denoted Limit(π), is deﬁned as the pair (T, A) where
T is the set of states that are visited inﬁnitely often in π:
T = inf(s0 s1 s2 . . .) = { s ∈S |
∞
∃n ⩾0. sn = s }
and A : T →Act, the function that assigns to each state s ∈T the set of actions that are
taken inﬁnitely often in s, i.e., for s ∈T:
A(s) = { α ∈Act(s) |
∞
∃n ⩾0. sn = s ∧αn+1 = α }.
The following theorem is the MDP analogue to Theorem 10.27 (page 775). It states that
under each scheduler the limit of almost all paths constitutes an end component.
Theorem 10.120.
Limiting Behavior of MDPs
For each state s of a ﬁnite MDP M and scheduler S for M:
PrS
s { π ∈Paths(s) | Limit(π) ∈EC(M) } = 1.

872
Probabilistic Systems
Proof: Let M be a ﬁnite MDP and π an inﬁnite path starting in s. Given that M is
ﬁnite, there is a state t, say, and an action α, say, such that π visits t and leaves it via
α inﬁnitely often. That is, the event □♦(t, α) holds. Consider an α-successor u of t, i.e.,
p = P(t, α, u) > 0. Given □♦(t, α), the probability of entering u ﬁnitely often is zero. This
follows from the fact that the probability of not taking the transition t
α
−−→u from some
moment on is bounded by limn→∞(1−p)n = 0. Thus, almost surely, u is entered inﬁnitely
often via the edge t
α
−−→u. Thus, for each scheduler S and almost all S-paths π it holds
that: if Limit(π) = (T, A), t ∈T, α ∈A(t) and P(t, α, u) > 0, then u ∈T. The claim now
follows from the fact that the underlying graph of Limit(π) is strongly connected.
Let M be a ﬁnite MDP and P ⊆(2AP)ω an LT property which only depends on the
labelings that are repeated inﬁnitely often. For example, P could stand for a repeated
reachability property □♦a, or Boolean combinations of repeated reachability properties,
such as a persistence property ♦□b, a strong fairness condition 
1⩽i⩽k(□♦ai →□♦bi), or
a Rabin condition "
1⩽i⩽k(♦□ai ∧□♦bi) where a, ai, b, and bi are atomic propositions. LT
properties P for which the satisfaction only depends on the labelings that appear inﬁnitely
often, but not on their order, are called limit LT properties. Let inf(A0A1A2 . . .) = { A ⊆
AP | ∀i ⩾0.∃j ⩾i. Ai = A } denote the set of labelings that appear inﬁnitely often in the
word A0A1A2 . . . ∈(2AP)ω.
Notation 10.121.
Limit LT Property
LT property P over AP is a limit LT property if for all words σ, σ′ ∈(2AP)ω:
σ ∈P and inf(σ) = inf(σ′)
implies
σ′ ∈P.
For limit LT properties, the satisfaction relation for the paths in a ﬁnite MDP M can be
expressed by conditions on sets of states. Let S be the state space of M and T ⊆S. Let
T |= P
iﬀ
∀σ ∈(2AP)ω. inf(σ) = L(T) implies σ ∈P
where L(T) = { L(t) ∈2AP | t ∈T }. If P is given by an LTL formula ϕ, i.e., P =
Words(ϕ), then we write T |= ϕ instead of T |= P.
Note that
T |= P
implies
for all paths π: inf(π) = T implies trace(π) ∈P.
By Theorem 10.120, only the sets inf(π) = T where T is the state set of an end component
of M are relevant when analyzing the probabilities for a limit LT property P.
An end
components (T, A) is said to be accepting (for P) iﬀT |= P.

Markov Decision Processes
873
This permits establishing a reduction from the probabilistic reachability problem to the
problem of computing extreme probabilities for limit LT properties. Let UP denote the
union of the sets T of all end components (T, A) of M such that T |= P. The set UP is
also called the success set of P in M. Similarly, let VP be the union of the sets T of all
end components (T, A) of M such that ¬(T |= P).
Theorem 10.122.
Verifying Limit LT Properties
Let M be a ﬁnite MDP and P a limit LT property. For any state s of M:
(a) Prmax(s |= P) = Prmax(s |= ♦UP), and
(b) Prmin(s |= P) = 1 −Prmax(s |= ♦VP).
Furthermore, there exist ﬁnite-memory schedulers Smax and Smin such that for any state
s of M:
(c) Prmax(s |= P) = PrSmax(s |= P) and (d) Prmin(s |= P) = PrSmin(s |= P).
Proof: First consider the statement for maximal probabilities. For each scheduler S we
have PrS(s |= P) ⩽PrS(s |= ♦UP ). By Theorem 10.120 it holds that
PrS(s |= P) = PrS{ π ∈Paths(s) | Limit(π) ∈EC(M) ∧inf(π) |= P }.
By deﬁnition of UP , π |= ♦UP for each path π with Limit(π) is an end component and
inf(π) |= P.
Vice versa, there exists a ﬁnite-memory scheduler such that PrS(s |= P) = Prmax(s |=
♦UP). To see this, consider a memoryless scheduler S0 that maximizes the probabilities
of reaching UP for all states s in M. In addition, for each end component (T, A) let the
fm-scheduler S(T,A) be such that it ensures staying forever in T while visiting all states
t ∈T inﬁnitely often, once started in some state in T. By Lemma 10.119 (page 870), such
an fm-scheduler does exist. Furthermore, for each state u ∈UP , select an end component
EC(u) = (T, A) with u ∈T and T |= P.
Let S be the scheduler which ﬁrst mimics S0 until a state u in UP has been reached.
From this moment on, S behaves as SEC(u). For this scheduler S, almost all paths that
eventually enter UP will visit all states of an end component (T, A) with T |= P inﬁnitely

874
Probabilistic Systems
often. In particular, the condition inf(π) |= P holds for almost all S-paths, provided they
eventually reach UP . This yields
PrS(s |= P)
=

u∈UP
PrS1(s |= (¬UP ) U u) · PrS2(u |= P)



=1
=
Prmax(s |= ♦UP).
Since Prmax(s |= ♦UP ) is an upper bound for the probabilities for P and starting state s
under all schedulers, this yields the claim.
Statement (b) for minimal probabilities can be derived from (a) using the fact that the
class of limit LT properties is closed under negation (i.e., with P also P = (2AP)ω \ P is
a limit property) and that PrS(s |= P) = 1 −PrS(s |= P) for all schedulers S. Hence:
Prmin(s |= P) = 1 −Prmax(s |= P)
and any fm-scheduler S that maximizes the probabilities for P minimizes the probabilities
for P. For T ⊆S we have T |= P iﬀ¬(T |= P). Hence, the set VP of all states t that
are contained in some end component (T, A) with ¬(T |= P) agrees with the set UP that
arises by the union of all end components (T, A) where T |= P. But then, (a) applied to
P yields
Prmax(s |= P) = Prmax(s |= ♦UP) = Prmax(s |= ♦VP).
Hence, for ﬁnite MDPs the PCTL formula P=1(□P=1(♦a)) asserts that under all schedulers
the event □♦a holds almost surely. This follows from the fact that
s |= P=1(□P=1(♦a))
iﬀ
for all end components (T, A) reachable from s, it holds that T ∩Sat(a) ̸= ∅
iﬀ
s ̸|= ∃♦VP with P = □♦a
iﬀ
Prmin(s |= □♦a) = 1.
Hence, almost sure repeated reachability is PCTL-deﬁnable for ﬁnite MDPs.
For certain limit LT properties, memoryless schedulers suﬃce to provide extreme prob-
abilities. This holds, e.g., for repeated reachability properties □♦B; see Exercise 10.23
(page 905).
As for reachability properties, graph-based methods suﬃce to check qualitative limit LT
properties. The simplest case is the question whether a limit LT property can be fulﬁlled
with positive probability under some scheduler.

Markov Decision Processes
875
Corollary 10.123.
Qualitative Limit LT Properties (Positive Probability)
Let P be a limit LT property and M a ﬁnite MDP and s a state in M. Then, the following
statements are equivalent:
(a) PrS(s |= P) > 0 for some scheduler S,
(b) Prmax(s |= P) > 0, and
(c) s |= ∃♦UP.
Checking whether PrS(s |= P) = 1 for some scheduler S (i.e., Prmax(s |= P) = 1) amounts
to verifying whether Prmax(s |= ♦UP ) = 1. This can be done using the techniques in
Section 10.6.1 (see Algorithm 45 on page 859), provided UP is given. The same holds for
qualitative limit LT properties that refer to Prmin(s |= P). They can be treated either by
algorithms to compute VP in combination with the algorithms for minimal reachability
probabilities, or—as shown in the proof of Theorem 10.122 (page 873)—by using the
duality of maximal and minimal probabilities for limit LT properties.
The remainder of this section is focused on the computation of the success set UP for limit
LT property P in a ﬁnite MDP M. Recall that UP is the union of the sets T of all end
components (T, A) such that T |= P. Clearly, UP results from an analysis of the set of
all end components of M. However, the number of end components can be exponential in
the size of M. This is due to the fact that end components may overlap, i.e., it is possible
to have two end components (T1, A1) and (T2, A2), say, such that (T1, A1) ̸= (T2, A2) and
T1∩T2 ̸= ∅. However, for certain limit LT properties P, the set UP can be characterized by
means of maximal end components, i.e., end components that are not properly contained
in any other end component:
Notation 10.124.
Maximal end components
An end component (T, A) of a ﬁnite MDP M is called maximal if there is no end component
(T ′, A′) such that (T, A) ̸= (T ′, A′) and T ⊆T ′ and A(s) ⊆A′(s) for all s ∈T.
Let MEC(M) denote the set of all maximal end components in M.
Any end component is contained in exactly one maximal end component. This follows from
the fact that the union of end components (T1, A1) and (T2, A2) with (T1, A1) ̸= (T2, A2)
and T1 ∩T2 ̸= ∅is an end component. Here, the union of sub-MDPs (T1, A1) and (T2, A2)
is the sub-MDP (T1 ∪T2, A1 ∪A2) where A1 ∪A2 denotes the function T1 ∪T2 →2Act
such that t →A1(t) ∪A2(t) if t ∈T1 ∩T2 and t →A1(t) if t ∈T1 \ T2 and t →A2(t)

876
Probabilistic Systems
if t ∈T2 \ T1. Furthermore, maximal end components are pairwise disjoint. Hence, the
number of maximal end components is bounded above by the number of states in M.
The set UP for the limit LT property P results from the end components (T, A) where
T |= P. In case P is a repeated reachability property, say □♦B for some B ⊆S, then
T |= P is equivalent to the requirement that T contains a B-state. If (T ′, A′) is an end
component with T ′ |= □♦B, then T |= □♦B, where (T, A) is the unique maximal end
component that contains (T ′, A′). Therefore, the success set UP for the event P = □♦B
arises by the union of all maximal end components (T, A) that contain at least one B-state.
Formally:
U□♦B =

(T, A) ∈MEC(M)
T ∩B ̸= ∅
T.
Note that an analogous result does not hold for persistence properties ♦□B, since a
non-maximal end component (T ′, A′) with T ′ ⊆B may be contained in a maximal end
component which also contains some states not in B. However, U♦□P agrees with the
union of all maximal end components (T, A) where T ⊆B in a slightly modiﬁed MDP
M□B. The MDP M□B results from M by removing all states s /∈B. More precisely,
M□B has the state space B ∪{ no }. The fresh state no is added as a trap state. The
transition probabilities are deﬁned by
P□B(s, α, t) = P(s, α, t) if α ∈Act, s ∈B and Post(s, α) ⊆B.
Let P□B(s, α, ·) = 0 for α ∈Act(s) such that Post(s, α) \ B ̸= ∅.
If state s in M
only has transitions to S \ B, it has no enabled actions left over. For such states s, let
P□B(s, τ, no) = 1. Furthermore, P□B(no, τ, no) = 1. Here, τ is a pseudo action that has
no further importance. The maximal end components of M□B which do not contain no
are end components (T, A) of M with T ⊆B. And vice versa, any end component (T, A)
of M with T ⊆B is contained in a maximal end component of M□B.
In fact, a similar technique is applicable for Rabin acceptance conditions:
Lemma 10.125.
Success Set for Rabin Conditions
Let M be a ﬁnite MDP with state space S, Bi, Ci ⊆S.
For a limit LT property P
which—when interpreted on M—is given by
!
1⩽i⩽k
(♦□Bi ∧□♦Ci),
it holds that
UP =

1⩽i⩽k
U
M□Bi
□♦Ci

Markov Decision Processes
877
where U
M□Bi
□♦Ci
is the success set of the event □♦Ci in the MDP M□Bi, i.e., the set of all
states t ∈S that are contained in some maximal end component (T, A) of M□Bi such that
no /∈T and T ∩Ci ̸= ∅.
The computation of the maximal end components of a ﬁnite MDP M can be performed
by means of iterative computations of SCCs. The idea is to successively remove all states
and actions that are not contained in some end component. In the ﬁrst iteration, the
nontrivial SCCs T1, . . . , Tk are determined in the underlying graph of M. (A nontrivial
SCC is an SCC which contains at least one edge, i.e., a cycle.)
Then, for each state
s ∈Ti, any action α ∈Act(s) for which Post(s, α) \ Ti ̸= ∅, is removed from Act(s). If
Act(s) becomes empty, state s is removed together with the actions β from Act(t) with
(t, β) ∈Pre(s). This yields a sub-MDP M1, say, of M where the action set Act(s) of each
state s solely consists of actions α such that all α-successors of s belong to the SCC Ti of
M with s ∈Ti.
Due to the removal of actions, however, the strong connectivity of Ti as a vertex set of the
underlying graph of M1 might be lost. We therefore have to repeat the whole procedure.
That is, we compute the nontrivial SCCs T 1
1 , . . . , T 1
k1 of M1 and repeat the procedure
described above for these SCCs. This yields a sub-MDP M2, say of M1. This procedure
is repeated until a sub-MDP Mi = M′ of M is obtained for which nontrivial SCCs agree
with the maximal end components of M.
These steps are summarized in Algorithm 47. Here, if T ⊆S and A : S →2Act is a
function, then A|T denotes the restriction of A to T, i.e., A|T : T →2Act is given by
A|T (t) = A(t) for all t ∈T.
Lemma 10.126.
Correctness of Algorithm 47
For ﬁnite MDP M with state space S, Algorithm 47 returns MEC(M) and requires at
most |S| (outermost) iterations.
Proof: The termination of Algorithm 47 follows from the fact that in each iteration (except
the last) of the repeat-loop, the partition induced by MEC is reﬁned and covers at most
the elements of the previous iteration. More precisely, let MEC0 = { S } and let MECi be
the set MEC immediately after the ith iteration of the repeat loop. For ﬁxed i, the sets
in MECi are nonempty and pairwise disjoint. They constitute a partition of some subset
Si of S. The sets Si are decreasing, i.e., S0 ⊇S1 ⊇S2 ⊇. . ., as for each i ⩾1 and
T ∈MECi there exists U ∈MECi−1 such that T ⊆U. Furthermore, if T = U, then in the
ith iteration no action α ∈A(t) has been removed from the action-sets of any state t ∈T.
This follows from the fact that the pairs (T, A|T ) for T ∈MECi are sub-MDPs of M, i.e.,
Post(t, α) ⊆T for all α ∈A(t) and t ∈T. Since the repeat loop terminates as soon as

878
Probabilistic Systems
Algorithm 47 Computing the maximal end components of a ﬁnite MDP
Input: ﬁnite MDP M with state space S
Output: the set MEC(M)
for all s ∈S do A(s) := Act(s); od
MEC := ∅;
MECnew := { S };
repeat
MEC := MECnew;
MECnew := ∅;
for all T ∈MEC do
R := ∅;
(* set of states to be removed *)
compute the nontrivial SCCs T1, . . . , Tk of the digraph G(T,A|T );
for i = 1, . . . , k do
for all states s ∈Ti do
A(s) := { α ∈A(s) | Post(s, α) ⊆Ti };
if A(s) = ∅then
R := R ∪{ s };
ﬁ
od
od
while R ̸= ∅do
let s ∈R
remove s from R and from T ;
for all (t, β) ∈Pre(s) with t ∈T do
A(t) := A(t) \ { β };
if A(t) = ∅then
R := R ∪{ t };
ﬁ
od
od
for i = 1, . . . , k do
if T ∩Ti ̸= ∅then
MECnew := MECnew ∪{T ∩Ti}
(* (T ∩Ti, A|T ∩Ti) is a sub-MDP of M *)
ﬁ
od
od
until (MEC = MECnew)
return { (T, A|T ) | T ∈MEC }

Markov Decision Processes
879
MEC = MECnew, for all iterations (except the last) there is at least one set U ∈MECi−1
such that some u ∈U is removed in the ith iteration.
After |S| iterations, MEC|S| would consist of singleton sets only and no further reﬁnements
would be possible. Hence, the maximal number of iterations of the repeat loop equals |S|.
For the (partial) correctness of Algorithm 47, let us ﬁrst observe that Algorithm 47 never
removes states or actions that belong to some end component. That is, whenever (T ′, A′) is
an end component of M then in each iteration of Algorithm 47, there exists T ∈MEC such
that (T ′, A′) is contained in (T, A|T ). This is a consequence of the following observation.
Whenever (T, A) is a sub-MDP such that each end component (T ′, A′) of M with T ∩T ′ ̸=
∅is contained in (T, A), then:
• For SCC C in G(T,A) it holds that for any state s ∈T and α ∈A(s) such that
Post(s, α) \ C ̸= ∅, there is no end component (T ′, A′) of M such that s ∈T ′ and
α ∈A′(s). In particular, any end component (T ′, A′) of M with T ′ ∩T ̸= ∅is
contained in the sub-MDP that results from (T, A) by removing α from A(s).
• If s ∈T and A(s) becomes empty by removing all actions, then there is no end
component of M containing s. In particular, any end component (T ′, A′) of M with
T ′ ∩T ̸= ∅is contained in the sub-MDP that results from (T, A) by removing state
s and all actions β from A(t) where t ∈T and P(t, β, s) > 0.
Hence, the output of Algorithm 47 is the set of sub-MDPs (T1, A1), . . . , (Tk, Ak) of M
where each end component (T ′, A′) is contained in some (Ti, Ai).
On the other hand, since any (Ti, Ai) remains unchanged in the last iteration of the repeat
loop, the graph G(Ti,Ai) is strongly connected. Thus, (Ti, Ai) is an end component of M,
and therefore a maximal end component of M. Hence, Algorithm 47 returns MEC(M).
Let us now consider the worst-case time complexity of Algorithm 47.
The SCCs of a
digraph with N vertices and M edges can be computed in time O(N+M).
The cost
of each iteration of the outermost loop is thus linear in the size of M. The number of
iterations is bounded by |S| as shown above. Hence, the worst-case time complexity of
Algorithm 47 is quadratic in the size of the MDP. More precisely, it is bounded above by
O( |S| · (|S| + M) )
where M is the number of triples (s, α, t) such that P(s, α, t) > 0. This shows that the
success set UP of a limit LT property P which is given by a Rabin acceptance condi-

880
Probabilistic Systems
tion "
1⩽i⩽k(♦□Bi ∧□♦Ci) (as in Lemma 10.125 on page 876) can be computed in time
O( size(M)2 · k ). Thus:
Theorem 10.127.
Time Complexity of Verifying Limit Rabin Properties
Let M be a ﬁnite MDP and P a limit LT property speciﬁed by a Rabin condition:
!
0<i⩽k
( ♦□Bi ∧□♦Ci ).
Then: the values Prmax(s |= P) can be computed in time O( poly( size(M) ) · k ).
By duality, the same holds for limit LT properties P which are given by a strong fairness
condition

1⩽i⩽k
( □♦Ci →□♦Di )
≡
¬
!
1⩽i⩽k
( ♦□¬Di ∧□♦Ci )
and the values Prmin(s |= P). Recall that by part (b) of Theorem 10.122 (page 873), we
have:
Prmin(s |= P) = 1 −Prmax(s |= ♦VP )
where VP is the union of the sets T of all end components (T, A) such that ¬(T |= P).
For a strong fairness condition as above we have ¬(T |= P) if and only if there exists i
such that T ∩Ci ̸= ∅and T ∩Bi = ∅. Hence, VP arises as the union of the maximal end
components (T, A) of M□¬Bi where T ∩Ci ̸= ∅. Here, M□¬Bi is the MDP obtained from
M by removing the states s ∈S \ Bi (see page 876 for the precise deﬁnition).
10.6.4
Linear-Time Properties and PCTL∗
This section treats the quantitative veriﬁcation of ω-regular property P against an MDP
M. This entails the computation of the values Prmin(s |= P) or, dually, Prmax(s |= P)
for state s in M. For example, let P describe the “good” behaviors and assume it is
required to establish whether P holds in M under all schedulers with some suﬃciently
large probability 1 −ε, say. More precisely, the requirement is to show that

s∈S
ιinit(s) · Prmin(s |= P) ⩾1 −ε.
Similarly, if P describes the bad behaviors, then a reasonable requirement is to verify
whether P holds with some suﬃciently small probability at most ε under all schedulers.
That is:

s∈S
ιinit(s) · Prmax(s |= P) ⩽ε.

Markov Decision Processes
881
The previous sections covered special cases of this setting such as reachability properties.
For limit LT property P given by a Rabin condition, the values Prmax(s |= P) can be
obtained by computing the values Prmax(s |= ♦UP).
The set UP is determined using
graph algorithms, and the reachability probabilities Prmax(s |= ♦UP ) are obtained by
(again) graph analysis followed by solving linear programs. This technique for limit LT
properties can be generalized toward arbitrary ω-regular properties in the following way.
Let P be an arbitrary ω-regular property. As a ﬁrst step, a deterministic Rabin automaton
A for P is constructed. Likewise as for Markov chains, the idea is to reduce the problem
of computing Prmin(s |= P) (or its dual) to determining reachability probabilities in a
product MDP. To that end, the product MDP M ⊗A is considered (deﬁned just below)
and the maximal probabilities of reaching the success set UA in M ⊗A are computed.
The success set UA depends on the Rabin acceptance condition in A.
Notation 10.128.
Product MDP
For ﬁnite MDP M = (S, Act, P, ιinit, AP, L) and DRA A = (Q, 2AP, δ, q0, Acc) with Acc =
{ (L1, K1), . . . , (Lk, Kk) }, the product M ⊗A is an MDP
M′ = (S × Q, Act, P′, ι′
init, Q, L′)
with
• P′(⟨s, q⟩, α, ⟨s′, q′⟩) =

P(s, α, s′)
if q′ = δ(q, L(s′))
0
otherwise.
• ι′
init(⟨s, q⟩) =

ιinit(s)
if q = δ(q0, L(s))
0
otherwise.
• L′(⟨s, q⟩) = { q }.
As for the product construction of a Markov chain and a DRA, there is a one-to-one
correspondence between the path
π = s0
α1
−−→s1
α2
−−→s2
α3
−−→. . .
in the MDP M and the path
π+ = ⟨s0, q1⟩
α1
−−→⟨s1, q2⟩
α2
−−→⟨s2, q3⟩
α3
−−→. . .

882
Probabilistic Systems
in M ⊗A that starts in state ⟨s0, q1⟩where q1 = δ(q0, L(s0)). Given a path π+ in M ⊗A
the corresponding path in M is simply obtained by omitting all automata states qi. Vice
versa, given a path π as above, the corresponding path π+ is obtained by adding the
automata states qi+1 = δ(qi, L(si)) to π. Thus, π+ arises by combining π with the unique
run for trace(π) in the DRA A. In particular:
trace(π) ∈P = Lω(A)
iﬀ
the run q0 q1 q2 q3 . . . for trace(π) in A is accepting
iﬀ
π+ |=
"
0<i⩽k
( ♦□¬Li ∧□♦Ki ).
In fact, this one-to-one correspondence on the path level induces a one-to-one correspon-
dence for schedulers on M and M⊗A. That is, any scheduler S for M induces a scheduler
S′ for M ⊗A such that for any S-path π in M the corresponding path π+ in M ⊗A is
a S′-path, and vice versa. The scheduler S′ is obtained by simply ignoring the automata
states, i.e.:
S′(⟨s0, q1⟩⟨s1, q2⟩. . . ⟨sn, qn+1⟩) =
S(s0 s1 . . . sn).
We then have
PrS(s |= P) = PrS′
⟨s, δ(q0, L(s))⟩|=
!
0<i⩽k
( ♦□¬Li ∧□♦Ki )

.
Vice versa, for a given scheduler S′ for M ⊗A, the corresponding scheduler S for M is
obtained as follows. For history s0 s1 . . . sn in M, scheduler S chooses the same action
as S′ selects for the history ⟨s0, q1⟩. . . ⟨sn, qn+1⟩in M ⊗A (where qi+1 = δ(qi, L(si)) for
0 ⩽i ⩽n).
Thus, there is a one-to-one-correspondence between the schedulers for M and M ⊗A.
This correspondence preserves the ﬁnite-memory property—if S is ﬁnite memory, then S′
is also. In addition, the probabilities for P (in M) under S agree with the probabilities
for A’s acceptance condition "
1⩽i⩽k ( ♦□¬Li ∧□♦Ki ) under S′. But then, for all states
s in M:
Prmax
M (s |= P)
=
Prmax
M⊗A( ⟨s, δ(q0, L(s))⟩|=
"
1⩽i⩽k
( ♦□¬Li ∧□♦Ki ) )
=
Prmax
M⊗A( ⟨s, δ(q0, L(s))⟩|= ♦UA )
where UA denotes the success set of A’s acceptance condition "
1⩽i⩽k ( ♦□¬Li ∧□♦Ki ).
Hence, the techniques presented in the previous section can be applied to compute Prmax(s |=
P). For the special case where the aim is to check whether Prmax(s |= P) > 0, a graph
analysis in M ⊗A suﬃces that checks whether ⟨s, δ(q0, L(s))⟩can reach the success set
UA in M ⊗A.

Markov Decision Processes
883
The same techniques can be used to determine Prmin(s |= P) by constructing a DRA for
the complement P of P, i.e., P = (2AP)ω \P. As the class of ω-regular properties is closed
under complementation, P is an ω-regular property. Then:
Prmin(s |= P) = 1 −Prmax(s |= P).
In case the ω-regular property P is given as LTL formula ϕ, the worst-case time complexity
of this technique to compute Prmax(s |= ϕ) or Prmin(s |= ϕ) is polynomial in the size of
M, but double exponential in the length of ϕ. (The double-exponential blowup is caused
by the transformation from LTL to DRA.) From the complexity-theoretic point of view
this algorithm is optimal, since the qualitative model-checking problem for MDPs—given
a ﬁnite MDP M and an LTL formula ϕ is Prmax(s |= ϕ) = 1—is in 2EXPTIME. This
result is due to Courcoubetis and Yannakakis and stated here without proof [104].
Theorem 10.129.
The qualitative model-checking problem for ﬁnite MDPs is in 2EXPTIME.
Recall that in the setting of Markov chains, this problem is PSPACE-complete.
As for Markov chains, the PCTL model-checking algorithm can be extended to treat the
logic PCTL∗by using the above techniques for computing extreme probabilities for LTL
formulae. For PCTL∗state formulae P⩽p(ϕ), one ﬁrst recursively computes the satisfaction
sets of the maximal state subformulae of ϕ. These maximal state subformulae are replaced
by new atomic propositions. This yields an LTL formula ϕ′, say. Subsequently, construct a
DRA for ϕ′ and apply a quantitative analysis to compute Prmax(s |= ϕ′) for all states s in
the MDP M. Then, Sat( P⩽p(ϕ) ) is the set of all states s in M where Prmax(s |= ϕ′) ⩽p.
The treatment of strict upper bounds < p is similar. For lower bounds ⩾p or > p, we
have to compute Prmin(s |= ϕ′) for all states s in M. This yields a PCTL∗model checking
procedure that runs in time polynomial in the size of the MDP and double exponential in
the length of the input PCTL∗state formula.
10.6.5
Fairness
This chapter is completed by discussing fairness assumptions in MDPs. Let us ﬁrst remark
that for each scheduler S, almost all paths that visit state s inﬁnitely often and take action
α in s inﬁnitely often will visit each α-successor of s inﬁnitely often. This is similar to the
setting of Markov chains, cf. Theorem 10.25 (page 772). (This fact has been already used
in the proof of Theorem 10.120.) Thus, probabilistic choices are almost surely strongly
fair. However, this does not address the resolution of the nondeterministic choices. As for

884
Probabilistic Systems
transition systems, fairness assumptions for the resolution of the nondeterministic choices
are often necessary to establish liveness properties. This typically applies to distributed
systems modeled by an MDP that relies on an interleaving semantics, and where (process)
fairness simply serves to rule out unrealistic behaviors where certain processes eventually
stop their execution without having reached a terminal state.
Consider, e.g., the simple mutual exclusion protocol with a randomized arbiter (cf. Ex-
ample 10.83, page 835). In the absence of any fairness assumption, this protocol cannot
guarantee that each process eventually enters its critical section almost surely. For in-
stance, a scheduler which only selects the actions of the second process while completely
ignoring the ﬁrst one, is not excluded. Similarly, for the randomized dining philosophers
algorithm (Example 10.87 on page 839), one cannot guarantee that each philosopher eats
inﬁnitely often almost surely, as there exist schedulers which only select the actions of one
of the philosophers and never an action from one of the other philosophers.
For MDPs, fairness assumptions on the resolution of the nondeterministic choices are
constraints on the schedulers. Instead of ranging over all schedulers, only the schedulers
that generate fair paths are considered and are taken into account for the analysis. The
underlying notion of fairness for paths is as for transition systems. In the sequel, it is
assumed that fairness constraints are given as LTL fairness assumptions, i.e., conjunctions
of unconditional fairness assumptions □♦Ψ, strong fairness assumptions □♦Φ →□♦Ψ,
and weak fairness assumptions ♦□Φ →□♦Ψ.
Here, Φ and Ψ are propositional logic
formulae. A scheduler is fair if it almost surely generates fair paths.
Deﬁnition 10.130.
Fair Scheduler
Let M be a Markov decision process and fair an LTL fairness assumption. A scheduler F
for M is fair (with respect to fair) if for each state s of M
PrF
s{ π ∈Paths(s) | π |= fair } = 1.
The fairness assumption fair is realizable in M if there exists some fair scheduler for M.
Without any additional assumptions, fair schedulers need not exist. This is evident when
there are no paths satisfying fair. But even if each ﬁnite path fragment can be extended
to a path satisfying fair, the existence of fair schedulers is not guaranteed. For example,
consider the following Markov chain:

Markov Decision Processes
885
s
{ a }
t
∅
1
2
1
2
1
2
1
2
Let the strong fairness assumption fair be deﬁned as □♦a →□♦b. Each path fragment
can be extended to a fair path, since there is always the possibility of eventually entering
state t and staying there forever (and violating □♦a).
On the other hand, when M
is considered as an MDP (labeling each transition with α, say), then M has just one
(memoryless) scheduler S, viz. one that in each state always selects α. But S is not fair
since almost surely both states s and t will be visited inﬁnitely often. Hence, □♦a ∧□¬b
holds almost surely.
In the sequel, we require the realizability of fair in the MDP M under consideration. As
LTL fairness assumptions constitute limit LT properties, for ﬁnite MDPs realizability is
equivalent to the existence of a ﬁnite-memory fair scheduler (see Exercise 10.28, page 907).
The ﬁrst observation is that realizable fairness assumptions are irrelevant for maximal
reachability probabilities:
Lemma 10.131.
Fairness and Max Reachability Probabilities
Let M be a ﬁnite MDP with state space S, B, C ⊆S and fair a realizable fairness
assumption for M. For each state s of M:
sup
F fair
scheduler for M
PrF(s |= C U B) = Prmax(s |= C U B).
Furthermore, there exists a ﬁnite-memory fair scheduler that maximizes the probabilities
for C U B.
Proof: Let M be a ﬁnite MDP with state space S, B, C ⊆S and fair a realizable fairness
assumption for M. For s ∈S, it holds that
sup
F fair
scheduler for M
PrF(s |= C U B) ⩽
sup
S arbitrary
scheduler for M
PrS(s |= C U B) = Prmax(s |= C U B)
since fair schedulers are more restrictive than arbitrary ones.
The basic idea is now to construct a fair ﬁnite-memory scheduler G that maximizes the
probabilities for the event C U B on the basis of a memoryless (possibly unfair) scheduler
S that maximizes the probabilities for that event (cf. Lemma 10.102 on page 852).

886
Probabilistic Systems
Let Π be the set of all ﬁnite path fragments s0 s1 . . . sn in the Markov chain MS such that
sn ∈B and si ∈C \B for 0 ⩽i < n. Furthermore, since fair is realizable and M is ﬁnite,
there exists a fair ﬁnite-memory scheduler F for M.
The fair scheduler G that maximizes the probabilities for C U B is now deﬁned as follows
on the basis of S and F.
G behaves as the memoryless scheduler S for all histories
s0 s1 . . . sn that are proper preﬁxes of some π ∈Π. As soon as G has generated the path
fragment s0 s1 . . . sn ∈Π then G continues in a fair way by mimicking the ﬁnite-memory
scheduler F for M. Similarly, once a path fragment s0 . . . sn is generated that is not a
preﬁx of some π ∈Π, G behaves as F.
Since the S-path fragments in Π are path fragments that are also generated by G, we
have
PrG(s |= C U B) = PrS(s |= C U B) = Prmax(s |= C U B).
Furthermore,
PrS
s { π ∈Paths(s) | pref(π) ⊆pref(Π) } = 0
where pref(π) denotes the set of all ﬁnite preﬁxes of π and pref(Π) the set of all ﬁnite
preﬁxes of the path fragments in Π. The event “pref(π) ⊆pref(Π)” means that G never
stops to mimic S, and thus might behave unfairly along those paths.
The latter statement follows from the following reasoning. Since the Markov chain MS
is ﬁnite (as S is memoryless), almost surely one of its BSCCs is reached and all its states
visited inﬁnitely often. But there is no S-path π that reaches a BSCC T of MS and
visits all states of T inﬁnitely often while fulﬁlling pref(π) ⊆pref(Π). This can be seen as
follows. Let π = s0 s1 s2 . . . be a S-path such that inf(π) = T and pref(π) ⊆pref(Π). We
show that B ∩T = ∅. This goes by contraposition. Assume B ∩T ̸= ∅. Select a ﬁnite
preﬁx π = s0 s1 . . . sn of π that ends in a state sn ∈B ∩T. Then, by deﬁnition of Π and
since π ∈pref(π) ⊆pref(Π), it follows that s0 s1 . . . sn ∈Π. But then none of the preﬁxes
πm = s0 s1 . . . sn sn+1 . . . sm of π of length m > n can be extended to a path fragment in
Π. That is, πm ∈pref(π) \ pref(Π) for all m > n. This contradicts the assumption that
pref(π) ⊆pref(Π).
This ensures that almost surely the scheduler G will stop to mimic the memoryless sched-
uler S and will behave in a fairly manner from some moment on by simulating F. This
yields that the ﬁnite-memory scheduler G is fair.
As Lemma 10.131 asserts the existence of a fair scheduler that maximizes the probabilities
for C U B, the supremum in Lemma 10.131 can be replaced with a maximum.
The above result can be understood as the probabilistic counterpart to the fact that

Markov Decision Processes
887
realizable fairness assumptions are irrelevant for verifying safety properties; see Theorem
3.55 (page 140). Recall that a typical usage of Prmax(s |= C U B) is to show that a safety
property a1 W a2 holds with some suﬃciently large probability 1 −ε under all schedulers.
(Then C characterizes the states where a1 ∧¬a2 holds, while B represents the states
satisfying ¬a1 ∧¬a2.) In this sense, computing Prmax(s |= C U B) can be understood as
quantitative reasoning about safety properties.
Due to the previous result, maximal probabilities can be computed without taking fairness
assumptions into account. This, however, does not apply to minimal probabilities. Fair-
ness assumptions may be essential when considering the minimal probabilities of reaching
a certain set of states B. This is a typical task to show that the liveness property ♦b holds
with probability ⩾1 −ε under all schedulers, for some small ε. For instance, consider the
following MDP:
s
∅
u
{ a }
t
{ b }
α, 1
γ, 1
β, 1
γ, 1
Consider the strong fairness assumption:
fair = □♦a →□♦b,
which can be read as fair = □♦u →□♦t. All fair schedulers have to take action α in
state s inﬁnitely often, and thus, ♦t almost surely holds for all fair schedulers. On the
other hand, the memoryless scheduler S that selects action β for state s never visits t.
Hence:
Prmin(s |= ♦b) = 0 < 1 =
inf
F fair
scheduler for M
PrF(s |= ♦b).
We now show that the problem of computing the minimal probabilities of reaching B under
fair schedulers is reducible to the problem of computing maximal reachability probabilities.
Let M = (S, Act, P, ιinit, AP, L) be a ﬁnite MDP, B ⊆S and fair a fairness assumption
that is realizable in M, i.e., M is fair with respect to fair. Let F min
=0
be the set of all
states t ∈S such that B will never be reached from t for some fair scheduler F:
F min
=0
= { t ∈S | PrF(t |= ♦B) = 0 for some fair scheduler F }.
By the following result, the set F min
=0
can be characterized by the end components (T, A)
of M such that T |= fair. Notice that the fairness assumption fair is a limit LT property
(see Notation 10.121 on page 872). Recall that T |= fair means that all paths π with
inf(π) = T fulﬁll fair.

888
Probabilistic Systems
Lemma 10.132.
Characterization of the Set F min
=0
Let M be a ﬁnite MDP, B ⊆S, fair and
F min
=0
= { t ∈S | PrF(t |= ♦B) = 0 for some fair scheduler F }.
For any state s ∈S, the following statements are equivalent:
(a) s ∈F min
=0 , i.e., PrF(s |= ♦B) = 0 for some fair scheduler F.
(b) PrF(s |= ♦B) = 0 for some fair, ﬁnite-memory scheduler F.
(c) Prmax(s |= (¬B) U V ) = 1 where V is the union of the state sets T of all end
components (T, A) of M such that T ∩B = ∅and T |= fair.
Proof: (a) =⇒(c): Suppose s ∈F min
=0 and consider a fair scheduler F with PrF(s |= ♦B) =
0. The limit of almost all F-paths is an end component. Let (T, A) be an end component
of M such that PrF
s(Π(T,A)) > 0 where Π(T,A) = { π ∈Paths(s) | Limit(π) = (T, A) }.
Then, T ∩B = ∅and T |= fair, and therefore T ⊆V . Moreover, all paths π ∈Π(T,A)
fulﬁll □¬B, and hence also (¬B) U V . Hence:
PrF(s |= (¬B) U V ) = 1.
In particular, Prmax(s |= (¬B) U V ) = 1.
(c) =⇒(b): Let Prmax(s |= (¬B) U V )
=
1.
Consider a ﬁnite-memory scheduler S
with PrG(s |= (¬B) U V ) = 1. By deﬁnition of V , there exists a fair ﬁnite-memoryless
scheduler H, say, such that PrH(t |= ♦B) = 0 for any state t ∈V . (The scheduler H can
be constructed using the same technique as used in the proof of Theorem 10.122, page
873.) We now compose G and H to obtain a fair ﬁnite-memory scheduler F which ensures
that B will not be reached from s. For starting state s, scheduler F ﬁrst acts as G. As
soon as V has been reached (which happens almost surely), F behaves as H. It is now
clear that F is fair (almost surely, eventually F simulates the fair scheduler H) and has the
ﬁnite-memory property (the union of the modes of G and H suﬃces). Moreover:
PrF(s |= ♦B) = 1 −PrG(s |= (¬B) U V ) = 0.
(b) =⇒(a): obvious.
The characterization of the set F min
=0
enables characterizing the minimal probabilities for
the event ♦B under fair schedulers by means of maximal probabilities for a constrained
reachability property:

Markov Decision Processes
889
Theorem 10.133.
Fair Min Reachability Probabilities
Let M be a ﬁnite MDP with state space S, B ⊆S, fair a strong fairness constraint, and
F min
=0
as above. Then, for any state s ∈S:
inf
F fair
scheduler for M
PrF(s |= ♦B) = 1 −Prmax(s |= (¬B) U F min
=0 ).
Furthermore, there exists a fair ﬁnite-memory scheduler F with
PrF(s |= ♦B) = 1 −Prmax(s |= (¬B) U F min
=0 ).
Proof: We ﬁrst prove the second statement. The proof is by constructing a ﬁnite-memory
fair scheduler G such that for any state s
PrG(s |= ♦B) ⩽1 −Prmax(s |= (¬B) U F min
=0 ).
Let S be a memoryless scheduler maximizing the probabilities for (¬B) U F min
=0 ; see Lemma
10.102 (page 852). From the proof of Lemma 10.132, it follows that there exists a fair
ﬁnite-memory scheduler H such that PrH(t |= ♦B) = 0 for each state t ∈F min
=0 . We now
combine S and H to obtain a ﬁnite-memory scheduler G with the desired properties. In
its starting mode, G simulates S until a path fragment s0 s1 . . . sn has been generated such
that si ∈S \ (B ∪F min
=0 ) for 0 ⩽i < n and either sn ∈F min
=0 or sn ∈B. In the former case,
G switches mode and simulates H from now on. In the latter case, G behaves from now
on as an arbitrary ﬁnite-memory fair scheduler. Obviously, G is fair and is ﬁnite memory,
and
PrG(s |= (¬B) U F min
=0 ) = Prmax(s |= (¬B) U F min
=0 ).
All G-paths π with π |= (¬B) U F min
=0
fulﬁll π |= □(¬B). Hence:
PrG(s |= ♦B)
=
1 −PrG(s |= □(¬B))
⩽
1 −PrF(s |= (¬B) U F min
=0 )
=
1 −Prmax(s |= (¬B) U F min
=0 ).
This shows the second claim. It remains to show that for each state s of M:
inf
F fair
scheduler for M
PrF(s |= ♦B) ⩾1 −Prmax(s |= (¬B) U F min
=0 ).
As for each fair scheduler F we have PrF(s |= ♦B) = 1 −PrF(s |= □(¬B)), it suﬃces to
show that
PrF(s |= □(¬B)) ⩽PrF(s |= (¬B) U F min
=0 ).

890
Probabilistic Systems
By Theorem 10.120 on page 871, we have
PrF(s |= □(¬B))
=

(T, A) end comp.
T ∩B = ∅
PrF
s{ π ∈Paths(s) | Limit(π) = (T, A) ∧π |= □(¬B) }
⩽

(T, A) end comp.
T ∩B = ∅
PrF
s{ π ∈Paths(s) | Limit(π) = (T, A) ∧π |= (¬B) U T }.
Furthermore, since F is fair, for each end component (T, A) such that PrF
s{ π ∈Paths(s) |
Limit(π) = (T, A) } > 0, we have T |= fair. Lemma 10.132 asserts that the end compo-
nents (T, A) with T |= fair and T ∩B = ∅belong to F min
=0 . Hence:
PrF(s |= □(¬B))
⩽

(T, A) end comp.
T ∩B = ∅, T |= fair
PrF
s{ π ∈Paths(s) | Limit(π) = (T, A) ∧π |= (¬B) U T }
⩽

(T, A) end comp.
T ∩B = ∅, T |= fair
PrF
s{ π ∈Paths(s) | Limit(π) = (T, A) ∧π |= (¬B) U F min
=0 }
⩽

(T, A) end comp.
PrF
s{ π ∈Paths(s) | Limit(π) = (T, A) ∧π |= (¬B) U F min
=0 }
=
PrF(s |= (¬B) U F min
=0 ).
Since PrF(s |= (¬B) U F min
=0 ) is bounded above by Prmax(s |= (¬B) U F min
=0 ), this yields the
ﬁrst claim.
Theorem 10.133 suggests the following recipe to determine the minimal probabilities for
reachability properties ♦B (for all fair schedulers) of a ﬁnite MDP: (1) determine the set
F min
=0 and (2) solve the linear program for the maximal probabilities for (¬B) U F min
=0 . The
computation of F min
=0
relies on a graph analysis of the end components of the MDP.
In case fair consists of weak fairness constraints ♦□Φj →□♦Ψj, j = 1, . . . , k, the
maximal end component may be exploited. In this case, V is the union of the sets T of
all maximal end components (T, A) such that, for each 1 ⩽j ⩽k, T ∩Sat(Ψj) ̸= ∅or
T \ Φj ̸= ∅. For strong fairness constraints, the analysis of maximal end components
might not be suﬃcient. However, the algorithm for computing maximal end components
(Algorithm 47) can be reformulated to compute all end components (T, A) such that
T |= fair and (T, A) is not contained in another end component (T ′, A′) where T ′ |= fair.
See Exercise 10.29 (page 907).

Markov Decision Processes
891
Constrained reachability properties C U B can be treated as simple reachability properties
by making all states s ∈S \ (C ∪B) in the MDP absorbing. Let M′ be the thus obtained
MDP. The paths in M satisfying C U B agree with the paths in M′ satisfying ♦B. Thus:
inf
F fair
scheduler for M
PrF
M(s |= C U B) =
inf
F′ fair
scheduler for M′
PrF′
M′(s |= ♦B).
The ingredients to treat (constrained) reachability properties under fairness assumptions
can be combined with the standard approach to compute satisfaction sets of CTL-like
logics to obtain a model-checking algorithm for PCTL under fairness assumptions and
ﬁnite MDPs. Let M be a ﬁnite MDP and fair an LTL fairness assumption that is realizable
in M. The satisfaction relation |=fair for PCTL state- and path formulae is deﬁned as the
standard satisfaction relation |=, except that the probabilistic operator ranges over all fair
schedulers (instead of all schedulers). That is:
s |=fair PJ(ϕ)
iﬀ
PrF(s |= ϕ) ∈J for all fair schedulers F.
The satisfaction set
Satfair(PJ(ϕ)) = { s ∈S | s |=fair PJ(ϕ) }
is obtained as follows. For path formulae with the next-step operator, the fairness con-
straints are irrelevant due to the realizability of fair. Thus,
Satfair(PJ(⃝a)) = Sat(PJ(⃝a))
for a ∈AP. For path formulae with the until operator we apply the techniques explained
above.
As a next veriﬁcation problem, we consider the quantitative analysis of ﬁnite MDPs against
an ω-regular property P in the presence of fairness assumptions. As for the case without
fairness assumptions, we adopt the automata-based approach and ﬁrst construct a deter-
ministic Rabin automaton A for P. Subsequently, the product-MDP M⊗A is considered;
see Notation 10.128 on page 881. Let us ﬁrst assume that we are interested in the maximal
probabilities for P, when ranging over all fair schedulers. By a graph analysis (similar to
the technique sketched above), we determine the union V of all end components (T, A)
in M ⊗A that satisfy the fairness assumption of M and the acceptance condition of A.
Then:
sup
F fair
scheduler for M
PrF
M(s |= P) = Prmax
M⊗A(⟨s, qs⟩|= ♦V )
where qs = δ(q0, L(s)). In fact, there is a ﬁnite-memory fair scheduler for M that max-
imizes the probabilities for P. Hence, the supremum can be replaced by a maximum.
Such a ﬁnite-memory fair scheduler can be derived from (i) a memoryless scheduler S for

892
Probabilistic Systems
M ⊗A that maximizes the probabilities of reaching V , and (ii) a ﬁnite-memory scheduler
F for M ⊗A which ensures that whenever an end component (T, A) of M ⊗A is reached
such that T |= fair and T satisﬁes the acceptance condition of A, then T will never be
left and all actions in T are visited inﬁnitely often. These two ﬁnite-memory schedulers S
and F for M ⊗A can be combined to obtain a ﬁnite-memory fair scheduler G for M ⊗A
that maximizes the probabilities for P. A corresponding ﬁnite-memory scheduler G is
obtained by encoding the states in A in the modes of G.
To compute minimal probabilities for P under all fair schedulers, we consider the comple-
ment property P and compute the maximal probabilities for P under all fair schedulers.
This is suﬃcient, since
min
F fair
scheduler for M
PrF(s |= P) =
1 −max
F fair
scheduler for M
PrF(s |= P).
Combining the techniques for model checking PCTL and those for checking ω-regular
properties yields a model-checking procedure for PCTL∗and ﬁnite MDPs under fairness
assumptions.
The worst-case time complexity is roughly the same for PCTL∗model
checking of MDPs without fairness. The main diﬀerence is that the graph analysis for
determining the end components is more advanced and can cause an additional factor
|fair| in the cost function.
In LTL and CTL∗, fairness assumptions can be encoded syntactically into the formula to
be checked. This allows one to reduce the fair satisfaction relation |=fair to the standard
satisfaction relation |=. In CTL∗, e.g., it holds that
s |=fair ∃ϕ
if and only if
s |= ∃(fair ∧ϕ)
and
s |=fair ∀ϕ
if and only if
s |= fair →ϕ.
To conclude this section, we show that an analogous result can also be established for the
logic PCTL∗. Clearly,
s |= P⩾p(fair →ϕ)
implies
s |=fair P⩾p(ϕ)
and
s |= P⩽p(fair ∧ϕ)
implies
s |=fair P⩽p(ϕ).
The question is whether the reverse implications also hold. At ﬁrst glance this does not
seem to be the case since, e.g., s |=fair P⩾p(ϕ) only concerns the fair schedulers, while
s |= P⩾p(fair →ϕ) considers all schedulers, including the unfair ones. While schedulers S
with 0 < PrS(s |= fair) < 1 are ignored by the fair satisfaction relation |=fair, satisfaction
s |= P⩾p(fair →ϕ) under the standard relation |= without fairness requires
PrS(s ̸|= fair) + PrS(s |= fair ∧ϕ) ⩾p

Markov Decision Processes
893
for all schedulers. In fact, when dropping the realizability assumption, then s |=fair P⩾p(ϕ)
and s ̸|= P⩾p(fair →ϕ) is possible. A simple example is a Markov chain M (viewed as
an MDP) with Pr(s |= fair) = 1
2 and Pr(s |= ϕ) = 0. Since there is no fair scheduler,
s |=fair P=1(ϕ), but s ̸|= P=1(fair →ϕ). However, the realizability assumption permits an
encoding of the fair satisfaction relation by means of the standard satisfaction relation for
ﬁnite MDPs. This is stated by the following theorem:
Theorem 10.134.
Reduction of |=fair to |=
Let M be a ﬁnite MDP and fair an LTL fairness assumption that is realizable for M.
Then, for each LTL formula ϕ and state s of M:
min
F fair
scheduler for M
PrF(s |= ϕ)
=
Prmin(s |= fair →ϕ)
max
F fair
scheduler for M
PrF(s |= ϕ)
=
Prmax(s |= fair ∧ϕ)
In particular, s |=fair P⩾p(ϕ) iﬀs |= P⩾p(fair →ϕ) and s |=fair P⩽p(ϕ) iﬀs |= P⩽p(fair ∧
ϕ). The same holds for strict probability bounds < p and > p.
Proof: We ﬁrst prove the statement about minimal probabilities. For any fair scheduler
F, it holds that PrF(s |= ϕ)
=
PrF(s |= fair →ϕ). Hence, the minimal probability
for ϕ under all fair schedulers is at least the minimal probability for fair →ϕ under all
schedulers.
We now show that there exists a fair (ﬁnite-memory) scheduler such that the probability
for ϕ equals the minimum for fair →ϕ under all schedulers. For the sake of simplicity,
assume that ϕ describes a limit LT property. (This is not a restriction, as ϕ can be replaced
by the acceptance condition of the DRA for ϕ.)
Let S be a ﬁnite-memory (possibly
unfair) scheduler that minimizes the probabilities for fair →ϕ. Thus, S maximizes the
probabilities for fair ∧¬ϕ and:
Prmax(s |= fair ∧¬ϕ)
=
PrS(s |= fair ∧¬ϕ)
=

(T,A)
PrS
s { π ∈Paths(s) | Limit(π) = (T, A) }
where (T, A) ranges over all end components of M such that T |= fair ∧¬(T |= ϕ).
Since S has the ﬁnite-memory property, the induced Markov chain MS is ﬁnite, and the
above sum can be rewritten as

T
PrS
s { π ∈Paths(s) | inf(π) = T }

894
Probabilistic Systems
where T ranges over all BSCCs of MS such that T |= fair ∧¬(T
|= ϕ).
We now
consider the ﬁnite-memory scheduler F that ﬁrst mimics S until S reaches a BSCC T. If
T |= fair ∧¬(T |= ϕ), then F behaves forever as S. If ¬(T |= fair) or T |= ϕ, then F
behaves from now on in an arbitrary but fair way (by acting like some fair ﬁnite-memory
scheduler). F is, in fact, a fair scheduler (because S reaches almost surely some BSCC).
Furthermore:
PrF(s |= ¬ϕ)
⩾

T
PrS
s { π ∈Paths(s) | inf(π) = T }
=
Prmax(s |= fair ∧¬ϕ)
where T ranges over all BSCCs with T |= fair ∧¬(T |= ϕ). As PrF(s |= ¬ϕ) = PrF(s |=
fair ∧¬ϕ), the inequality ⩾in the above formula can be replaced with an equality =. This
yields
PrF(s |= ϕ)
=
1 −PrF(s |= ¬ϕ)
=
1 −PrF(s |= fair ∧¬ϕ)
=
Prmin(s |= fair →ϕ).
The statement for maximal probabilities follows by duality.
Let F range over all fair
schedulers and S over all schedulers. Then:
max
F
PrF(s |= ϕ)
=
1 −min
F
PrF(s |= ¬ϕ)
=
1 −Prmin(s |= fair ∧¬ϕ)
=
Prmax(s |= fair →ϕ).
As a consequence:
s |=fair P=1(ϕ)
if and only if
s |= P=1(fair →ϕ)
and
s |=fair P=0(ϕ)
if and only if
s |= P=0(fair ∧ϕ).
That is to say, there exists a fair scheduler F with PrF(ϕ) > 0 if and only if there exists
a scheduler S with PrS(fair ∧ϕ) > 0. These reductions emphasize the expressiveness of
PCTL∗as a logic for reasoning about ﬁnite MDPs. However, for eﬃciency reasons it is
recommended to perform a quantitative analysis of ﬁnite MDPs with fairness assumptions
using the techniques described before.
10.7
Summary
• Markov chains are transition systems with ﬁxed probability distributions over the
successors of each state.

Summary
895
• A qualitative property is an event that either holds with probability one or zero.
Checking a qualitative property in ﬁnite Markov chains can be done by graph algo-
rithms. This does not hold for inﬁnite Markov chains.
• (Constrained) Reachability probabilities can be computed by a graph analysis and
solving a linear equation system.
• Almost surely, the long-run behavior of a ﬁnite Markov chain ends in a bottom
strongly connected component (BSCC). Quantitative (and qualitative) properties
about the long-run behavior—such as repeated reachability, persistence, or Boolean
combinations thereof—of a ﬁnite Markov chain M can be checked by computing the
probability of reaching an accepting BSCC in M.
• Probabilistic Computation Tree Logic (PCTL) is a quantitative variant of CTL
where the path quantiﬁers ∃and ∀are replaced by a probabilistic operator PJ(ϕ)
that speciﬁes lower and/or upper probability bounds (given by J) for the event ϕ.
• PCTL model checking for ﬁnite Markov chains relies on the standard CTL model-
checking procedure in combination with methods for computing constrained reach-
ability probabilities.
• The qualitative fragment of PCTL is obtained by only allowing bounds > 0 and =1.
For ﬁnite Markov chains, CTL is at least as expressive as the qualitative fragment
of PCTL. For inﬁnite Markov chains, the expressivity of the qualitative fragment
of PCTL and CTL is incomparable. As opposed to CTL, persistence properties can
be expressed in PCTL (both qualitative and quantitative).
• Computing the probability for an LT property P on a ﬁnite Markov chain M can
be reduced to computing the acceptance probability in the product of M and a
deterministic Rabin automaton (DRA) for the complement of P.
• A probabilistic bisimulation equivalence only relates states that are equally labeled
and whose cumulative probability of moving to the equivalence classes coincides.
• Probabilistic bisimulation on Markov chains coincides with PCTL and PCTL∗equiv-
alence. (The logic PCTL∗is obtained by combining PCTL and LTL.) This holds
for any arbitrary Markov chain—the restriction to ﬁnitely-branching models (as for
the logical characterization of bisimulation on transition systems) is not required.
• Long-run averages and expected cost-bounded reachability in Markov reward chains
can be determined using graph algorithms and solving linear equation systems.
• Markov decision processes (MDPs) are transition systems in which in any state a
nondeterministic choice between probability distributions exists. A Markov chain is
an MDP in which for any state the set of probability distributions is a singleton.
MDPs are adequate for modeling randomized distributed algorithms.

896
Probabilistic Systems
• Reasoning about probabilities in MDPs requires the concept of schedulers. Sched-
ulers resolve the nondeterminism and yield a stochastic process. Computing extreme
(i.e., minimal or maximal) probabilities for constrained reachability properties relies
on graph algorithms and linear programs. The latter can be solved by means of an
iterative approximation algorithm (called value iteration).
• When interpreting PCTL on MDPs, the formula PJ(ϕ) ranges over all schedulers.
The PCTL model-checking problem for MDPs is reducible to the reachability prob-
lem.
• Almost surely, the long-run behavior of a ﬁnite MDP ends in one of its end compo-
nents. Quantitative (and qualitative) properties about the long-run behavior—such
as repeated reachability, persistence, or Boolean combinations thereof—of a ﬁnite
MDP M can be checked by computing the extreme probability of reaching an “ac-
cepting” end component in M.
• Model-checking a ﬁnite MDP against an ω-regular property can be solved by an
automata-based approach, analogous to ﬁnite Markov chains.
• A scheduler is fair if it almost surely generates only fair paths. For maximal reach-
ability properties, fairness is irrelevant. Minimal reachability probabilities under all
fair schedulers can be computed by graph-based techniques and determining max-
imal probabilities for a constrained reachability property. Model checking a ﬁnite
MDP with fairness assumptions against an ω-regular property can be performed by
an automata-based approach similar to that for MDPs without fairness assumptions.
10.8
Bibliographic Notes
Markov chains and Markov decision processes.
The main principles of Markov chains
as a mathematical model for stochastic processes goes back to Markov in 1906. Since
then a variety of diﬀerent aspects of Markov chains has been studied in the literature
such as queuing theory [55], numerical algorithms [63, 378], reliability and performance
analysis [196], and lumping [72, 237]. Markov chains have been applied in various areas
ranging from systems biology, social sciences, and psychology, to electrical engineering
and operations research. Important textbooks on Markov chains are, e.g., [237, 238, 248].
The reader should bear in mind that this monograph treats Markov chains from the state-
based view as a graph (transition system) with probabilities, rather than—the more usual
interpretation—as a sequence of random variables. Markov reward models are extensively
described in the monograph by Howard [216]. The zeroconf protocol example has been
adopted from Bohnenkamp et al. [54].

Bibliographic Notes
897
Markov decision processes (MDPs) have their roots in operations research and stochastic
control theory.
They are useful for studying a wide range of optimization problems.
MDPs were known at least as early as in the ﬁfties; see the seminal work by Bellman
[38, 39]. MDPs are used in a variety of application areas, including robotics, automated
control, economics and in manufacturing. Vardi [407] proposed using MDPs as models
for concurrent probabilistic systems. Major textbooks on MDPs are by Puterman [346],
Howard [215], and Bertsekas [49]. The randomized philosophers example originates from
Lehmann and Rabin [268] and the randomized leader election algorithm of Itai and Rodeh
[223]. Other randomized algorithms can be found in, e.g., Rabin [349] or the textbooks
by Motwani and Raghavan [306], and Lynch [280].
Verifying qualitative properties. Veriﬁcation techniques for probabilistic models date back
to the early eighties and were focused on qualitative LT properties. Hart, Sharir, and
Pnueli [191] observed that graph-based algorithms are suﬃcient for proving almost sure
termination for ﬁnite-state concurrent probabilistic programs. The veriﬁcation of qualita-
tive ω-regular properties for ﬁnite MCs and ﬁnite MDPs has ﬁrst been addressed by Vardi
and Wolper [407, 409, 411, 412]. They represent ω-regular properties by means of NBAs
that are deterministic in the limit. Vardi and Wolper also showed that the qualitative LTL
model-checking problem for ﬁnite Markov chains is PSPACE-complete. Courcoubetis and
Yannakakis [104] extended these results by techniques for the quantitative analysis of
MCs against LTL and NBA speciﬁcations (see below). They also established a double-
exponential lower bound for the problem of verifying whether an LTL formula holds almost
surely for a ﬁnite MDP. Pnueli and Zuck have developed a tableau-based veriﬁcation tech-
nique for MDPs and qualitative LTL formulae [340] as well as proof methods for MDPs
that rely on the connection between probabilistic choice and fairness; see e.g., [341]. A
generalization of some of these concepts has been discussed by Baier and Kwiatkowska
[32]. Fairness assumptions that impose restrictions on the resolution of nondeterminism
in MDPs have been ﬁrst addressed by Hart, Sharir, and Pnueli [191] and Vardi [407]. The
role of fairness in the context of PCTL (and PCTL∗) model checking has been discussed
by Baier and Kwiatkowska [31].
Verifying quantitative properties. The presented algorithm for the quantitative analysis
of MCs against ω-regular speciﬁcations exploits deterministic Rabin automata (DRAs).
This approach is conceptually simple as the DRA does not aﬀect the transition proba-
bilities in the product Markov chain. Although for many ω-regular properties DRA exist
whose size is of the same order as NBA [241], in the worst case the smallest DRA can
be exponentially larger than the smallest equivalent NBA. Several alternative algorithms
have been presented in the literature that have a time complexity which is polynomial in
the size of the Markov chain and exponential in the length of the LTL formula ϕ. Such
algorithms have been proposed in the seminal paper by Courcoubetis and Yannakakis
[104], and more recently (using diﬀerent techniques) by Couvreur, Saheb, and Sutre [108],

898
Probabilistic Systems
and Bustan, Rubin, and Vardi [77]. The observation that the quantitative analysis of
MDPs can be solved by linear programs goes back to an earlier paper by Courcoubetis
and Yannakakis [103].
Branching-time properties. A branching-time logic for reasoning about probabilistic sys-
tems has been originally proposed by Hart and Sharir [190]. Their focus was on qualitative
properties and deductive proof rules. Hansson and Jonsson introduced Probabilistic Com-
putation Tree Logic (PCTL) and the PCTL model-checking procedure for ﬁnite Markov
chains [187]. Variants of PCTL have been proposed for MDPs (or similar models). Hans-
son [186] and Segala and Lynch [370] presented action-based variants of PCTL.
The
(state-based) variant of PCTL and PCTL∗for MDPs is due to Bianco and de Alfaro [51].
The concept of end components was introduced by Courcoubetis and Yannakakis [104]
and has been studied in more detail by de Alfaro [115, 116]. Eﬃcient counterexample gen-
eration algorithms for PCTL have recently been proposed by Han and Katoen [185]. A
detailed account of (among others) PCTL model checking has been given by Kwiatkowska,
Norman, and Parker [254]. Extensions of PCTL-like logics for MDPs (e.g., long-run prop-
erties) have been studied by de Alfaro; see e.g., [114, 115, 117]. The logic PCRTL (PCTL
with rewards) which, amongst others, supports long-run averages and expected cumulative
rewards has been proposed by Andova, Hermanns, and Katoen [14]. They also provide
model-checking algorithms for this logic.
Probabilistic bisimulation. Bisimulation for Markov chains and an action-based model ´a
la MDPs has been introduced in the seminal paper by Larsen and Skou [264]. Aziz et
al. [23] have shown that bisimulation equivalence on Markov chains preserves the validity
of PCTL∗formulae. The observation that PCTL−-equivalence agrees with bisimulation
equivalence goes back to Desharnais et al. [121]. These authors study this for labeled
Markov processes, a probabilistic model with continuous state spaces. Jonsson and Larsen
[227] deﬁned simulation relations for probabilistic models. Simulation and bisimulation
relations, as well as the use of MDP-like models as semantical model for process algebras,
can be found in the survey paper by Jonsson, Yi, and Larsen [228].
Further results
on the connection between PCTL/PCTL∗and bisimulation and simulation relations for
Markov chains have been recently established by Baier et al. [30]. For MDPs (and the
like) we refer to the works by Hansson [186], Segala and Lynch [370], and Desharnais
and her colleagues [122, 123, 124]. Bisimulation minimization algorithms for MCs have
been considered by Huynh and Tian [220], Baier, Engelen, and Majster-Cederbaum [27],
and Derisavi, Hermanns, and Sanders [120]. Recently, Katoen et al. [232] have shown
experimentally that substantial reductions in both memory and time can be obtained by
exploiting bisimulation minimization for PCTL model checking and reward properties.
Probabilistic model checkers.
One of the ﬁrst prototypical PCTL model checkers has
been reported by Fredlund [156]. More recent PCTL model checkers are PRISM [255]

Exercises
899
and ETMCC [201] (and its successor, MRMC [233]).
The former supports both MCs
and MDPs, the latter only MCs.
PRISM uses a variant of BDDs [26, 181] to enable
the compact representation of transition matrices [254, 323]. MRMC is based on a sparse
matrix representation and supports minimization techniques for probabilistic bisimulation.
Both MRMC/ETMCC and PRISM also support CSL model checking, a continuous-time
variant of PCTL proposed by Aziz et al. [22] and Baier et al. [29], and expected measures
for Markov reward chains. Other model checkers for Markov chains are ProbVerus [192]
and FMurϕ [331]. Alternative model checkers for Markov decision processes are LiQuor
[82] and Rapture [112, 226]. The latter tool focuses on reachability properties and exploits
abstraction-reﬁnement techniques. LiQuor supports the veriﬁcation of quantitative and
qualitative ω-regular properties of MDPs that are modeled using a probabilistic variant of
Promela, the input language of the LTL model checker SPIN. This variant [25] is based
on the probabilistic guarded command language by Morgan and McIver [304]. LiQuor uses
partial order reduction techniques to combat the state-space explosion problem [28, 113].
10.9
Exercises
Exercise 10.1.
Consider the Markov chain M shown in Figure 10.22. Let C = { s0, s1, s4, s6 }
s0
s1
s2
s3
s4
s5
s6
1
3
2
3
1
4
1
3
1
2
4
5
8
9
1
1
4
2
4
2
3
1
9
1
5
1
2
Figure 10.22: Markov chain M for Exercise 10.1.
and B = { s2, s3 }.
(a)
Compute the probability measure of the union of the following cylinder sets:
Cyl(s0 s1), Cyl(s0 s5 s6), Cyl(s0 s5 s4 s3), Cyl(s0 s1 s6)
given that the initial distribution is given by iinit(s0) = 1.

900
Probabilistic Systems
(b) Compute Pr(s0 |= ♦B) using the least ﬁxed point characterization.
(c) Compute Pr(s0 |= C U⩽5 B) using:
(i) the least ﬁxed point characterization;
(ii) transient state probabilities.
(d) Determine Pr(s0 |= ♦□D) with D = { s3, s4 }.
Exercise 10.2. Consider the Markov chain of Figure 10.23. Let B1 = { s1, s7 }, B2 = { s6, s7, s8 },
s0
s1
s4
s2
s8
s5
s3
s7
s6
s9
0.3
0.2
1
1
1
0.3
0.1
0.4
0.4
0.6
1
1
1
0.8
0.2
0.7
Figure 10.23: Markov chain M for Exercise 10.2.
B3 = { s1, s3, s7, s9 } and B4 = { s2, s3, s4, s5, s6, s7, s8, s9 }. Determine whether:
(a) Pr(s0 |= ♦B1) = 1,
(b) Pr(s7, ♦B2) = 1,
(c) Pr(s0, □♦Bi) = 1, for i ∈{ 1, 2, 3 },
(d) Pr(s0, ♦□B2) = 1, and
(e) Pr(s0, ♦□B4) = 1.
Exercise 10.3.
Let M = (S, P, ιinit, AP, L) be a ﬁnite Markov chain, s ∈S and C, B ⊆S,
n ∈IN, n ⩾1. Let C U=n B denote the event that a B-state will be entered after exactly n steps
and all states that are visited before belong to C. That is, s0 s1 s2 . . . |= C U=n B if and only if

Exercises
901
sn ∈B and si ∈C for 0 ⩽i < n. The event C U⩾nB denotes the union of the events C U=k B
where k ranges over all natural numbers ⩾n.
Question: Provide an algorithm to compute
(a) the values Pr(s |= C U=n B), and
(b) an algorithm for computing Pr(s |= C U⩾n B).
Exercise 10.4.
Let M = (S, P, ιinit, AP, L) be a ﬁnite Markov chain and s ∈S, a, b ∈AP.
Prove or disprove the following statements:
(a) Pr(s |= □a) = 1 iﬀs |= ∀□a
(b) Pr(s |= ♦a) < 1 iﬀs ̸|= ∀♦a
(c) Pr(s |= □a) > 0 iﬀs |= ∃□a
(d) Pr(s |= ♦□a) = 1 iﬀPr(s |= ♦B) = 1 where B = { t ∈S | t |= ∀□a }
(e) Pr(s |= a U b) = 1 iﬀs |= ∀(a U b)
(f) Pr(s |= a U b) = 0 iﬀs ̸|= ∃(a U b)
Exercise 10.5.
Complete the proof of Corollary 10.33 on page 778 and provide the proof for the
following statement:
Pr(s |= □♦B) = 1
iﬀ
s |= ∀□∃♦B
provided that s is a state of a ﬁnite Markov chain M and B a set of states in M.
Exercise 10.6.
Consider the following MC:
0
1
2
3
4
5
6
7
1
2
1
2
1
2
1
1
1
8
1
8
1
1
2
1
2
1
2
1
3
1
3
1
3
1
4
1
4
1
4
{b, r}
∅
∅
c
r
b
b
b

902
Probabilistic Systems
Question: Determine the set of states for which the PCTL formula P⩾p(b U c) holds for p = 17
19.
Exercise 10.7.
Prove or disprove the following PCTL equivalences:
(a) P=1( ⃝P=1(□a) ) ≡P=1( □P=1(⃝a) )
(b) P>0.5( ⃝P>0.5(♦a) ) ≡P>0.5( ♦P>0.5(⃝a) )
(c) P=1( ⃝P=1(♦a) ) ≡P=1( ♦P=1(⃝a) )
Exercise 10.8.
Let M = (S, P, ιinit, AP, L) be a ﬁnite Markov chain such that S ⊆AP and
L(s) ∩AP = { s } for each state s ∈S. Let sfair be the following CTL fairness assumption:
sfair =

s∈S

t ∈Post(s)
(□♦s →□♦t).
Show that for a, b ∈AP:
(a) s |= P=1(a U b)
iﬀ
s |=sfair ∀(a U b).
(b) s |= P>0(□a)
iﬀ
s |=sfair ∃□a.
Exercise 10.9.
Provide deﬁnitions of the weak until operator and the release operator in PCTL.
That is, deﬁne PCTL formulae PJ(Φ W Ψ) and PJ(Φ R Ψ) such that for each Markov chain M and
each state s in M:
s |= PJ(Φ W Ψ)
iﬀ
Pr(s |= Φ W Ψ) ∈J,
s |= PJ(Φ R Ψ)
iﬀ
Pr(s |= Φ R Ψ) ∈J,
where
Pr(s |= Φ W Ψ)
=
PrM
s { π ∈Paths(s) | π |= Φ U Ψ ∨π |= □Φ },
Pr(s |= Φ R Ψ)
=
PrM
s { π ∈Paths(s) | π ̸|= ¬Φ U ¬Ψ }.
Exercise 10.10.
As for CTL and LTL, PCTL in positive normal form (PNF) can be deﬁned
as a fragment of PCTL where negation is only allowed adjacent to atomic propositions. To avoid
a decrease in expressiveness, the syntax of PCTL formulae in PNF contains for each operator of
the base syntax of PCTL a dual operator (e.g., disjunction as the dual for conjunction, release as
the dual for until, etc.).
Questions:
(a) Provide the precise deﬁnition of the syntax of PCTL formulae, and

Exercises
903
(b) Prove that for any PCTL formula there exists an equivalent PCTL formula in PNF.
Exercise 10.11.
Let M be a ﬁnite Markov chain over AP, s a state of M and a, b ∈AP: Show
that
s |= P=1(a U b)
iﬀ
s |= ∀( (∃(a U b)) W b ).
Exercise 10.12.
Provide deterministic Rabin automata for the following LTL formulae: □(a →
♦b), ¬□(a →♦b), and a U (□b).
Exercise 10.13. Let A1 and A2 be DRA over the same alphabet. Deﬁne the DRA A = A1∪A2
such that
Lω(A) = Lω(A1) ∪Lω(A2)
and size(A) = O

poly(size(A1), size(A2))

.
Exercise 10.14.
Consider the Markov chain M in Figure 10.22 (page 899), and let the labeling
be given by L(s2) = L(s3) = L(s4) = { a } and L(s) = ∅for the remaining states. Question:
Compute the probability PrM(ϕ) for the LTL formula ϕ = □♦a. (Hint: Construct a DRA A
for ϕ and perform a quantitative analysis in M ⊗A.)
Exercise 10.15.
Prove the following statement. For ﬁnite Markov chain M = (S, P, ιinit, AP, L)
and ω-regular property P over AP such that PrM(P) > 0, there exists a ﬁnite path fragment
π = s0 s1 . . . sn in M with ιinit(s0) > 0 such that almost all paths in the cylinder set Cyl(π) fulﬁll
P, i.e.,
PrM{π ∈Cyl(π) | trace(π) ∈P} = P(π).
Exercise 10.16.
Show that there is no PCTL formula that is equivalent to the PCTL∗formula
P⩾0.5(⃝⃝a) where a is an atomic proposition.
Exercise 10.17.
Consider the Markov chain M, which is given by

904
Probabilistic Systems
1
2
3
4
5
6
0.1
1
0.3
0.2
0.7
0.2
0.7
0.8
0.3
1
0.5
0.2
Questions:
(a) Determine the bisimulation quotient M/∼M
(b) For each pair of equivalence classes C and D under ∼M, give a PCTL formula Φ such that
C |= Φ and D ̸|= Φ.
Exercise 10.18.
Let (M, rew) be a ﬁnite Markov reward model and s a state in M, T a set of
states in M such that Pr(s |= ♦T ) = 1. Show that the inﬁnite series
ExpRew(s |= ♦T ) =
∞

r=0
r · Prs{ π ∈Paths(s) | rew(π, ♦B) = r }
converges.
Exercise 10.19.
Consider the Markov reward model for the simulation of a die by coin-tossing
actions as in Example 10.75 on page 825. Show that for each r ∈IN, r ⩾0:
Pr(s0 |= ♦{ 1, 2, 3, 4, 5, 6 }) = 1 −1
4r
Exercise 10.20.
In Section 10.5, we only considered rewards for the states. Let us now study
reward models that rely on a ﬁnite Markov chain where the edges are augmented by rewards. I.e.,
we deal with reward functions rew : S × S →IN such that rew(s, s′) = 0 if P(s, s′) = 0. The
cumulative reward of a ﬁnite path fragment s0 s1 . . . sn is now deﬁned as the sum of the reward
earned by traversing the edges (s0, s1), (s1, s2), . . . , (sn−1, sn). That is,
rew(s0 s1 . . . sn) =

1⩽i⩽n
rew(si−1, si)
Expected rewards ExpRew(s |= ♦T ) and reward-bounded reachability events ♦⩽rT are deﬁned
as in Section 10.5.
Provide algorithms to compute expected rewards ExpRew(s |= ♦T ), and

Exercises
905
probabilities for reward-bounded reachability properties Pr(s |= ♦⩽rT ) for ﬁnite Markov chains
with reward structures that attach rewards to the edges.
Exercise 10.21.
Provide a deﬁnition of bisimulation equivalence on Markov reward models
such that bisimulation equivalence agrees with PRCTL-equivalence. Prove the correctness of your
notion of bisimulation equivalence.
Exercise 10.22.
Consider the MDP M shown in Figure 10.24. Let B = { s6 }. Compute the
values xs = Prmax(s |= ♦B) where s is a state in the MDP M. Take the following approach:
ﬁrst determine the states for which Prmax(s |= ♦B) ∈{ 0, 1 }; then solve the corresponding linear
program for the remaining states.
s6
s1
s2
s5
s4
s3
γ, 1
γ, 1
α, 1
β, 1
α, 1
2
α, 1
2
α, 1
2
α, 1
2
α, 1
2
β, 1
β, 1
α, 1
2
Figure 10.24: Markov decision process M for Exercise 10.22.
Exercise 10.23.
Given a ﬁnite Markov decision process M with state space S and a subset B
of S, show that there exists a memoryless scheduler S such that
Prmax(s |= □♦B) = PrS(s |= □♦B).
For which other types of limit LT properties P exist memoryless schedulers that maximize the
probabilities for P? Consider
(a) persistence properties ♦□B,
1. Rabin conditions
"
1⩽i⩽k
(♦□Bi ∧□♦Ci),
(b) strong fairness assumptions

1⩽i⩽k
(□♦Bi →□♦Ci).

906
Probabilistic Systems
Exercise 10.24.
Show or disprove that the class of limit LT properties is closed under intersec-
tion. Do the same for union and complementation.
Exercise 10.25.
Determine the maximal end components of the following MDP:
s4
s0
s1
s2
s6
s7
s3
s5
α, 1
β, 2
3
α, 1
4
β, 1
3
β, 1
3
α, 1
9
β, 2
3
α, 1
2
α, 1
2
α, 1
α, 2
5
α, 3
4
α, 1
2
α, 1
α, 1
α, 3
5
α, 7
18
Exercise 10.26.
Let M be a ﬁnite MDP over AP and A a DRA over the alphabet 2AP. On
page 882 we described a transformation “scheduler S for M ⇝scheduler S′ for M⊗A”, and vice
versa. Questions:
(a) Is it true that if S is memoryless, then so is S′?
(b) Is it true that if S′ is memoryless, then so is S?
(c) Assume that S′ is a ﬁnite-memory scheduler for M ⊗A. Describe the corresponding ﬁnite-
memoryless scheduler S by its modes.
Exercise 10.27.
Let M = (S, Act, P, ιinit, AP, L) be a Markov decision process. A bisimulation
on M is an equivalence R on S such that for all (s1, s2) ∈R:
(a) L(s1) = L(s2)
(b) for all α ∈Act(s1) there exists β ∈Act(s2) such that for all R-equivalence classes T ∈S/R:
P(s1, α, T) = P(s2, β, T).

Exercises
907
States s1, s2 of M are called bisimulation equivalent iﬀthere exists a bisimulation R with (s1, s2) ∈
R.
(a) Show that bisimulation-equivalent states satisfy the same PCTL∗formulae over AP.
(b) Suppose that M is ﬁnite. Show that PCTL-equivalent states are bisimulation equivalent.
In (b), PCTL-equivalence of two states s1, s2 of M means that s1 and s2 fulﬁll the same PCTL
formulae over AP.
Exercise 10.28. Let M be a ﬁnite Markov decision process and fair an LTL fairness assumption.
Prove the equivalence of the following statements:
(a) There exists a fair scheduler for M.
(b) There exists a fair ﬁnite-memory scheduler for M.
(c) There exists a scheduler S for M such that, for all states s of M, Prmax(s |= ♦Ufair) = 1,
where Ufair denotes the success set of fair, i.e., the union of the sets T of all end components
(T, A) of M such that T |= fair.
Here, fairness of a scheduler F for M means that for all states s of M it holds that
PrF
s

π ∈Paths(s) | π |= fair

= 1.
Exercise 10.29.
Let M be a ﬁnite Markov decision process and
sfair =

1⩽i⩽k
(□♦ai →□♦bi)
a strong fairness assumption. Questions:
(a) Design an algorithm that runs in time O

poly(size(M)) · k ) and computes all end compo-
nents (T, A) of M such that T |= sfair and such that (T, A) is not contained in another end
component (T ′, A′) with T ′ |= sfair.
(b) Design an algorithm that takes as input a ﬁnite MDP M and an LTL fairness assumption
sfair and checks in time O( poly(size(M)) · |ϕ| ) whether ϕ is realizable for M.
(Hint for part (a): combine the ideas of the algorithm to compute the maximal end components
(Algorithm 47) with the ideas of model checking CTL with fairness.)


Appendix A
Appendix: Preliminaries
A.1
Frequently Used Symbols and Notations
The symbol
only serves readability. It indicates the end of a deﬁnition, of a remark, or
of other numbered text fragments. The abbreviation “iﬀ” stands for “if and only if”. We
also often use logical symbols, such as ∧for “and”, ∨for “or” and the following quantiﬁers:
∃
“there exists . . .”
∀
“for all”
∞
∃
“there exist inﬁnitely many”
∞
∀
“for almost all, i.e., for all except for ﬁnitely many”.
The Greek Alphabet At various places, Latin and Greek letters serve as symbols for
certain mathematical objects. Although not all Greek letters will be used in this mono-
graph, Figure A.1 shows the complete Greek alphabet. The symbols Γ, Δ, Θ, Λ, Ξ, Σ, Υ,
Φ, Ψ, and Ω are capital letters. All other symbols in Figure A.1 are lowercase letters.
Natural and Real Numbers The symbol IN denotes the set { 0, 1, 2, . . . } of natural
numbers.
The set of real numbers is denoted IR. Subsets of IN and IR are often denoted
by subscripts.
For instance, IR⩾0 denotes the set of non-negative reals, while IR>5 denotes
the interval ]5, ∞[.
909

910
Appendix: Preliminaries
α
alpha
β
beta
γ, Γ
gamma
δ, Δ
delta
ϵ, ε
epsilon
ζ
zeta
η
eta
θ, ϑ, Θ
theta
ι
iota
κ
kappa
λ, Λ
lambda
μ
mu
ν
nu
ξ, Ξ
xi
o
omicron
π, ϖ, Π
pi
ρ, ϱ
rho
σ, ς, Σ
sigma
τ
tau
υ, Υ
upsilon
φ, ϕ, Φ
phi
χ
chi
ψ, Ψ
psi
ω, Ω
omega
Figure A.1: The Greek alphabet.
Asymptotic operators O, Ω, and Θ To specify the asymptotic growth of (cost) func-
tions, the Landau symbols O, Ω, and Θ are used (see, e.g., [100]):
O : asymptotic upper bound
Ω : asymptotic lower bound
Θ : asymptotic upper and lower bound
The precise meaning is as follows. If f : IN →IN is a function, then O(f) denotes the set
of all functions g : IN →IN such that there exists a constant C > 0 and natural number
N with g(n) ⩽C · f(n) for all n ∈IN where n ⩾N. The function class Ω(f) consists of
all functions g : IN →IN such that there exists a constant C > 0 and a natural number
N with g(n) ⩾C · f(n) for all n ⩾N. The class Θ(f) is given by Θ(f) = O(f) ∩Ω(f).
It is common to use the equality symbol instead of the element symbol “∈” and to write,
e.g., g = O(f) or g(n) = O(f(n)) rather than g ∈O(f). Thus, “equations” with the
asymptotic operators have to be read from the left to the right.
We write O(poly(n)) to denote the class of all functions g : IN →IN that are polynomially
bounded, i.e., g(n) = O(nk) for some natural number k.
Similarly, O(exp(n)) denotes
the class of all functions g : IN →IN that are exponentially bounded, i.e., g(n) = O(ank)
where a > 1 is a real constant and k a natural number.
Notation for Sets Let X be a set. The symbol 2X stands for the powerset of X, i.e., the
set consisting of all subsets of X. We write |X| to denote the cardinality of X, i.e., the
number of elements of X. (If X is inﬁnite, then |X| = ω.) Besides the standard symbols
∪for union, ∩for intersection, and \ for “set-minus”, i.e., X \ Y = {x ∈X | x /∈Y }, the
symbol ⊎will be used which denotes disjoint union. Formally, for sets X, Y , X ⊎Y is
deﬁned by {(x, 1) | x ∈X} ∪{(y, 2) | y ∈Y }. Additionally, we mention special cases for
union and intersection. For x ∈X, let Yx be subset of a set Y . Then,

x∈∅
Yx = ∅,
1
x∈∅
Yx = Y.
Thus, +
x∈∅. . . depends on the chosen universal set Y .

Frequently Used Symbols and Notations
911
Relations A relation denotes any set of tuples of ﬁxed length.
More precisely, let
X1, . . . , Xk be sets where k ∈IN with k ⩾1. Subsets of the Cartesian products X1×. . .×Xk
are also called relations or predicates. The number k denotes the arity. If X1 = X2 =
. . . = Xk = X, then the subsets of
Xk = X1 × . . . × Xk
are called k-ary relations on X. Very often we have to deal with binary (2-ary) relations R
over a set X. For these relations the inﬁx notation xRy is often used instead of (x, y) ∈R.
If X is a set and R a binary relation on X, then R is called
• transitive if for all x, y, z ∈X, xRy, and yRz implies xRz;
• reﬂexive if for all x ∈X, xRx;
• symmetric if for all x, y ∈X, xRy implies yRx;
• antisymmetric if for all x, y ∈X, xRy, and yRx implies x = y.
Equivalences An equivalence relation (or brieﬂy equivalence) on X is a transitive, re-
ﬂexive, and symmetric binary relation on X. Symmetric symbols (like ∼, ≡, or similar
symbols) are often used to denote an equivalence relation. If x ∈X, then [x]R = { y ∈
X | xRy } is called the equivalence class of x with respect to R. If R follows from the
context, [x] is often written for short instead of [x]R. The quotient space of X with respect
to R is the set of all equivalence classes with respect to R and is denoted X/R. Then,
X/R = {[x]R | x ∈X}. If R is an equivalence relation on X, then for all x, y ∈X:
xRy iﬀ[x]R = [y]R iﬀ[x]R ∩[y]R ̸= ∅.
So the quotient space consists of pairwise disjoint nonempty subsets of X whose union
just results in X. For each element x ∈X, there is always exactly one element A of the
quotient space with x ∈A (i.e. A = [x]R). The index of an equivalence relation R denotes
the number of equivalence classes, i.e., the cardinality of X/R. It is usual to use spellings
like “R is of ﬁnite index” if the index of R is ﬁnite (a natural number).
Let R and R′ be two equivalence relations on X. Relation R is a reﬁnement of R′ if
R ⊆R′, i.e., R “distinguishes” more elements than R′. In this case, it is also said that R
is ﬁner than R′ and that R′ is coarser than R.
It is referred to as a proper reﬁnement if R
is a reﬁnement of R′ with R ̸= R′. If R is a reﬁnement of R′, then every equivalence class
with respect to R is contained in exactly one equivalence class with respect to R′, because
we have [x]R ⊆[x]R′. This observation can be enforced as follows. Each equivalence class
with respect to R′ can be written as a disjoint union of equivalence classes with respect

912
Appendix: Preliminaries
to R. Thus, if R is a reﬁnement of R′, then |X/R′| ⩽|X/R|. Therefore, the index of R′
is at most the index of R.
Transitive and Reﬂexive Closure
Let R be a binary relation over X. The transi-
tive and reﬂexive closure of R is the smallest transitive, reﬂexive binary relation on X
containing R. Usually, this is denoted by R∗. Thus,
R∗=

n⩾0
Rn
where R0 = {(x, x) | x ∈X} and Rn+1 = { (x, y) ∈X × X | ∃z ∈X.(x, z) ∈R ∧(z, y) ∈
Rn }. If R is symmetric, then R∗is an equivalence relation.
Partitions A partition (or partitioning) of a set X is a set B ⊆2X consisting of pairwise
disjoint, nonempty subsets of X such that 
B∈B B = X. Elements of B are called blocks,
as well. In particular, each element x ∈X is included in exactly one block B ∈B. There
is a close connection between equivalence relations on X and partitions of X. If R is an
equivalence relation on X, then the quotient space X/R is a partition of X. Vice versa,
if B is a partition of X, then
{(x, y) | x and y are in the same block B ∈B}
is an equivalence relation with quotient space B.
Preorder A preorder R on X denotes a reﬂexive, transitive relation on X. Any preorder
induces an equivalence, the so-called kernel of R, which is given by R ∩R−1, i.e., the
relation {(x, y) | xRy and yRx}.
A.2
Formal Languages
This section summarizes the main concepts of regular languages. Further details and the
proofs of the results mentioned here can be found in any text book on formal language
theory, see e.g., [214, 272, 363, 383].
Words over an Alphabet An alphabet is an arbitrary nonempty and ﬁnite set Σ.
The
elements of Σ are typically called symbols or letters.
A word over Σ denotes a ﬁnite or
inﬁnite sequence of symbols in Σ, i.e., words have the form w = A1 A2 . . . An where n ∈IN
or σ = A1 A2A3 . . . and where the Ai’s are symbols in Σ.
1 The special case n = 0 is
1Formally, inﬁnite words can be deﬁned as functions σ : IN →Σ and the notation σ = A1 A2A3 . . .
means that σ(i) = Ai for all i ∈IN. Similarly, ﬁnite words are obtained by functions w : {1, . . . , n} →Σ.

Formal Languages
913
allowed, in which case the so-called empty word, denoted ε, is obtained.
The length of a
word is the number of symbols in the given word. Thus, for w = A1 A2 . . . An, the length
is n, while each inﬁnite word has the length ω. (The Greek letter ω (omega) is typically
used to denote “inﬁnity”.) Σ∗denotes the set consisting of all ﬁnite words over Σ, while
Σω denotes the set of all inﬁnite words over Σ. Note that ε ∈Σ∗. Thus, the set of all
nonempty ﬁnite words, denoted Σ+, is Σ∗\{ε}. A set of ﬁnite words over the alphabet Σ is
called a language, and is ranged over by L (and primed and subscripted versions thereof).
A preﬁx of a ﬁnite word w = A1 A2 . . . An, is a word v of the form A1A2 . . . Ai for some
i where 0 ⩽i ⩽n. A suﬃx of w is a word v of the form Ai Ai+1 . . . An where 1 ⩽i ⩽
n+1. (In particular, ε is a preﬁx and suﬃx of any ﬁnite word.) The words of the form
AiAi+1 . . . Aj with 1 ⩽i ⩽j ⩽n are called subwords of w. The deﬁnition of preﬁxes,
suﬃxes, and subwords of inﬁnite words are similar. For inﬁnite word σ = A0 A1 A2 . . .,
the suﬃx Aj Aj+1 Aj+2 . . . is denoted σ[j..]. For technical reasons, we start with the index
0. Thus, σ = σ[0..].
Operations on Words Important operations on words are concatenation and ﬁnite rep-
etition. Concatenation takes two words and “glues them together” to construct a new
word. It is denoted by juxtaposition. For instance, the concatenation of the words BA
and AAB yields the word BA.AAB = BAAAB. The concatenation of a word with itself
is denoted by squaring, e.g., (AB)2 equals ABAB; this is generalized in a straightforward
manner for arbitrary n. In the special cases n = 0 and n = 1, we have w0 = ε (the empty
word) and w1 = w.
Finite repetition, also called Kleene star and denoted by ∗, of a ﬁnite word w yields the
language
consisting of all ﬁnite words that arise by zero or more (but ﬁnitely many)
repetitions of w.
Formally, for w ∈Σ∗we have w∗= {wi | i ∈IN}.
For instance,
(AB)∗= { ε, AB, ABAB, ABABAB, . . . }. Note that the empty word ε is included in w∗
for each ﬁnite word w. This is precisely the diﬀerence with the slight variant of the Kleene
star, denoted +, deﬁned by w+ = {wi | i ∈IN, i ⩾1}, or, equivalently, w+ = w∗\ { ε }.
For instance, (AB)+ denotes the set { AB, ABAB, ABABAB, . . . }.
Operations on Languages Concatenation is lifted to languages in a natural way as
a pointwise extension of concatenation on words. The same applies to repetition. For
languages L, L1, L2 ⊆Σ∗we have
L1.L2 = { w1.w2 | w1 ∈L1, w2 ∈L2 }
and
L∗=
∞

i=0
Li,
and
L+ =
∞

i=1
Li,
where Li denotes the concatenation of i times L. Note that the star and plus notation for

914
Appendix: Preliminaries
languages over ﬁnite words is consistent with the standard notations Σ∗and Σ+ for the
set of all ﬁnite words over Σ with or without the empty word, respectively. For instance,
for L1 = { A, AB } and L2 = { ε, BBB } we have that
L1.L2
=
{ A, AB, ABBB, ABBBB }, and
L2
1
=
{ AA, AAB, ABAB, ABA }.
There are several equivalent formalisms to describe regular languages. In this monograph
we only use regular expressions and ﬁnite automata. We start with the former and intro-
duce the automata approach later.
Regular Expressions Regular expressions (denoted E or F) are built from the symbols
∅(to denote the empty language), ε (to denote the language { ε } consisting of the empty
word), the symbols A for A ∈Σ (for the singleton sets { A }), and the language opera-
tors ”+” (union), ”∗” (Kleene star, ﬁnite repetition), and ”.” (concatenation). Formally,
regular expressions can be deﬁned inductively:
1. ∅and ε are regular expressions over Σ.
2. If A ∈Σ, then A is a regular expression over Σ.
3. If E, E1 and E2 are regular expressions over Σ, then so are E1 + E2, E1.E2, and E∗.
4. Nothing else is a regular expression over Σ.
E+ is an abbreviation for the regular expression E.E∗. The semantics of a regular expression
E is a language L(E) ⊆Σ∗that is deﬁned as follows:
L(∅) = ∅,
L(ε) = { ε },
L(A) = { A }
and
L(E1 + E2) = L(E1) ∪L(E2),
L(E1.E2) = L(E1).L(E2),
L(E∗) = L(E)∗.
From this deﬁnition, we derive L(E+) = L(E)+.
A language L ⊆Σ∗is called regular if there is some regular expression E over Σ such that
L(E) = L. For instance, E = (A+B)∗.B.B.(A+B) is a regular expression over Σ = { A, B }
representing the language
L(E) = {wBBA | w ∈Σ∗} ∪{wB3 | w ∈Σ∗},
consisting of all ﬁnite words that end with three B’s or with the word BBA. The regular
expression E′ = (A + B)∗.B.B.(A + B)∗represents the regular language consisting of all
ﬁnite words over Σ = { A, B } that contain the subword BB.

Propositional Logic
915
It is standard to use a simpliﬁed syntax for regular expressions that does not distinguish
between the atomic expression x and the symbol x for x ∈{∅, ε}∪Σ and skips the operator
symbol ”. ” for concatenation. For example,
(A + B)∗BB(A + B)
stands for the regular expression (A + B)∗.B.B.(A + B).
A.3
Propositional Logic
This section summarizes the basic principles of propositional logic. For more elaborate
treatments we refer to the textbook [342].
Given is a ﬁnite set AP of atomic propositions, sometimes also called propositional symbols.
In the following, Latin letters like a, b, and c (with or without subscripts) are used to denote
elements of AP. The set of propositional logic formulae over AP, formulae for short, is
inductively deﬁned by the following four rules:
1. true is a formula.
2. Any atomic proposition a ∈AP is a formula.
3. If Φ1, Φ2 and Φ are formulae, then so are (¬Φ) and (Φ1 ∧Φ2).
4. Nothing else is a formula.
Any formula stands for a proposition that might hold or not, depending on which of
the atomic propositions are assumed to hold. Intuitively, the formula a stands for the
propositions stating that a holds. The intuitive meaning of the symbol ∧is conjunction
(“and”), i.e., Φ1 ∧Φ2 holds if and only if both propositions Φ1 and Φ2 hold. The symbol ¬
denotes negation, i.e., ¬Φ holds if and only if Φ does not hold. Thus, e.g., a ∧¬b holds if
and only if a holds and b does not hold. The constant true stands for a proposition which
holds in any context, independent of the interpretation of the atomic propositions a.
It is standard to use simpliﬁed notations for formulae with the help of derived operators
and by declaring a precedence order on the basic and derived operators, which often allows
skipping brackets. The standard precedence order assigns a higher priority to the unary
negation operator ¬ than the binary conjunction operator ∧. Thus, ¬a ∧b is short for

916
Appendix: Preliminaries
((¬a) ∧b). Moreover, conjunction ∧binds stronger than the derived binary operators,
such as
Φ1 ∨Φ2
def
=
¬(¬Φ1 ∧¬Φ2)
disjunction (“or”)
Φ1 →Φ2
def
=
¬Φ1 ∨Φ2
implication
Φ1 ↔Φ2
def
=
(¬Φ1 ∧¬Φ2) ∨(Φ1 ∧Φ2)
equivalence
Φ1 ⊕Φ2
def
=
(¬Φ1 ∧Φ2) ∨(Φ1 ∧¬Φ2)
parity (xor)
For example, ¬a ∨¬b ∧c is a short-form notation for (¬a) ∨((¬b) ∧c) which – by the
deﬁnition of ∨– stands for the formula Φ = (¬(¬a) ∧¬((¬b)) ∧c)).
Abstract Syntax Throughout this monograph, we provide the deﬁnition of the syntax
of logics in a more relaxed way. Skipping the syntactic rules for brackets (which can be
derived from the precedence order of the operators that will be declared in words), the
above inductive deﬁnition of propositional formulae over AP can be rewritten as
Φ
::= true
   a
   Φ1 ∧Φ2
   ¬Φ
where a ∈AP. The above can be understood as a casual notation for the Backus-Naur
form of a context-free grammar over the alphabet Σ = {true} ∪AP ∪{¬, ∧}. In this
short-form notation, the symbol Φ serves simultaneously for (1) a nonterminal symbol
(variable) of the grammar and (2) its derived words over Σ∗(i.e., propositional formulae).
The latter explains the indices in the term Φ1 ∧Φ2, which is correct on the formula level,
although the correct notation would be Φ ∧Φ (without indices) in the grammar.
Length of a Formula The length of a formula Φ is deﬁned by the number of operators
in Φ and is denoted by |Φ|. For instance, the formula Φ = (¬b) ∧c has the length 2.
Since in most cases we are only interested in the asymptotic length of formulae in formula
sequences (Φn), we may also assign one cost unit to the derived operators ∨and →. In
fact, the asymptotic formula length does not depend on whether ∨and →are treated as
a basic operator (with one cost unit per occurrence in a formula) or a derived one (using
conjunction and negation).
Semantics of Propositional Logic To formalize the intuitive meaning of propositional
formulae, we ﬁrst need a precise deﬁnition of the “context” that declares which atomic
propositions hold and which do not hold. This is done by means of an evaluation which
assigns a truth value 0 (“false”) or 1 (“true”) to each atomic proposition.
Formally,
an evaluation for AP is a function μ : AP →{ 0, 1 }. Eval(AP) denotes the set of all
evaluations for AP.
The semantics of propositional logic is speciﬁed by a satisfaction
relation |= indicating the evaluations μ for which a formula Φ is true. Formally, |= is a set
of pairs (μ, Φ) where μ is an evaluation and Φ is a formula. It is written

Propositional Logic
917
μ |= true
μ |= a
iﬀ
μ(a) = 1
μ |= ¬Φ
iﬀ
μ ̸|= Φ
μ |= Φ ∧Ψ
iﬀ
μ |= Φ and μ |= Ψ.
Figure A.2: The satisfaction relation |= of propositional logic.
μ |= Φ instead of (μ, Φ) ∈|=.
Accordingly, μ ̸|= Φ stands for (μ, Φ)
/∈|=. Intuitively, μ |= Φ stands for the fact that
Φ is true under evaluation μ. The satisfaction relation |= is inductively deﬁned by the
conditions indicated in Figure A.2. If μ |= Φ, then μ is called a satisﬁed condition for Φ.
In literature, the notation μ(Φ) = 1 if μ |= Φ, and μ(Φ) = 0, if μ ̸|= Φ, is used, too. The
value μ(Φ) ∈{0, 1} is called the truth-value of Φ under μ.
Formulae with derived operators like disjunction ∨or implication →have the expected
semantics. Thus,
μ |= Φ ∨Ψ
iﬀ
μ |= Φ or μ |= Ψ
μ |= Φ →Ψ
iﬀ
μ ̸|= Φ or μ |= Ψ
iﬀ
μ |= Φ implies μ |= Ψ.
Set Notation for Evaluations An alternative representation of evaluations for AP
is based upon representation of sets. Each evaluation μ can be represented by the set
Aμ = {a ∈AP | μ(a) = 1}. And conversely, an evaluation μ = μA with A = Aμ can be
assigned to each subset A of AP. Evaluation μA is the characteristic function of Aμ, that
is, μA(a) = 1 if a ∈A and μA(a) = 0 if a /∈A. This observation suggests extending the
satisfaction relation |= to subsets of AP by
A |= Φ
iﬀ
μA |= Φ.
As an example, we look at Φ = (a ∧¬b) ∨c. Given an evaluation μ with μ(a) = 0 and
μ(b) = μ(c) = 1, then μ ̸|= a ∧¬b and μ |= c, and thus, μ |= Φ. The accompanying set
Aμ is Aμ
= {b, c}. Hence, {b, c} |= Φ. The empty set induces an evaluation μ∅with
μ∅(a) = μ∅(b) = μ∅(c) = 0. Due to μ∅̸|= Φ (where Φ = (a ∧¬b) ∨c as above), we get
∅̸|= Φ. However, we have ∅|= ¬a∧¬b since ¬a and ¬b hold for the associated evaluation
μ∅.
Semantic Equivalence Two propositional logic formulae Φ, Ψ are called (semantically)
equivalent if they have the same truth-value for each evaluation. That is, for all evaluations
μ:

918
Appendix: Preliminaries
rule for double negation
idempotency law
¬¬Φ ≡Φ
Φ ∨Φ
≡
Φ
Φ ∧Φ
≡
Φ
absorption law
commutativity law
Φ ∧(Ψ ∨Φ)
≡
Φ
Φ ∧Ψ
≡
Ψ ∧Φ
Φ ∨(Ψ ∧Φ)
≡
Φ
Φ ∨Ψ
≡
Ψ ∨Φ
associativity law
de Morgan’s law
Φ ∧(Ψ ∧Ξ)
≡
(Φ ∧Ψ) ∧Ξ
¬(Φ ∧Ψ)
≡
¬Φ ∨¬Ψ
Φ ∨(Ψ ∨Ξ)
≡
(Φ ∨Ψ) ∨Ξ
¬(Φ ∨Ψ)
≡
¬Φ ∧¬Ψ
distributivity law
Φ ∨(Ψ1 ∧Ψ2)
≡
(Φ ∨Ψ1) ∧(Φ ∨Ψ2)
Φ ∧(Ψ1 ∨Ψ2)
≡
(Φ ∧Ψ1) ∨(Φ ∧Ψ2)
Figure A.3: Some equivalence rules for propositional logic.
μ |= Φ iﬀμ |= Ψ.
In this case we write Φ ≡Ψ.
For example, the formulae a∧¬¬b and a∧b are semantically
equivalent.
A few of the most important equivalence rules for propositional logic and
the operators ¬, ∧and ∨are shown in Figure A.3. Here, the Greek capital letters Φ, Ψ,
Ξ (with or without subscripts) serve as metasymbols for formulae of propositional logic.
The associativity and commutativity law for disjunction ∨and conjunction ∧justify the
omission of brackets and notations like

1⩽i⩽n
Φi or Φ1 ∧. . . ∧Φn
.
Note that the length of a formula of type 
1⩽i⩽n Φi is equal to n −1 (and not to 1).
Furthermore, notations like 
i∈I Φi or {Φi | i ∈I} are often used where I is an arbitrary
ﬁnite index set. If I is nonempty, then Φ stands for one of the formulae Φi1 ∧. . . ∧Φik
where I = {i1, . . . , ik} and i1, . . . , ik are pairwise diﬀerent. For I = ∅, the convention is

i∈∅
Φi
def
= true,
while
!
i∈∅
Φi
def
= false.
Satisﬁability and Validity Propositional formula Φ is called satisﬁable if there is an
evaluation μ with μ |= Φ. Φ is called valid (or a tautology) if μ |= Φ for each evaluation
μ. Φ is unsatisﬁable if Φ is not satisﬁable. For example, a ∧¬a is unsatisﬁable, while

Propositional Logic
919
a ∨¬(a ∧b) is a tautology.
The formulae a ∨¬b and a ∧¬b are satisﬁable, but not
tautologies. Obviously:
Φ is unsatisﬁable
iﬀ
μ ̸|= Φ for all evaluations μ
iﬀ
μ |= ¬Φ for all evaluations μ
iﬀ
¬Φ is valid.
Thus, Φ is unsatisﬁable if and only if ¬Φ is a tautology.
Literals and Positive Normal Form (PNF) A literal means a formula of the form a or
¬a where a ∈AP is an atomic proposition. Propositional formulae in positive normal form
(PNF for short, also sometimes called negation normal form) use the negation operator
only on the level of literals. To ensure that the class of PNF formulae is as expressive as
full propositional logic, both the conjunction and the disjunction operator serve as basic
operators. Thus, the abstract syntax of PNF formulae is
Φ
::=
true
   false
   a
   ¬a
   Φ1 ∧Φ2
   Φ1 ∨Φ2
where a ∈AP. Given a (non-PNF) formula Φ, de Morgan’s laws and the rule for double
negation allow for “pushing the negation inside” until an equivalent formula in PNF arises.
That is, successive application of the transformations
¬(Φ1 ∧Φ2)
⇝
¬Φ1 ∨¬Φ2
¬(Φ1 ∨Φ2)
⇝
¬Φ1 ∧¬Φ2
¬¬Ψ
⇝
Ψ
to Φ’s subformulae yields an equivalent formula in PNF of the same asymptotic length.
Conjunctive and Disjunctive Normal Form Special cases of PNF are the conjunctive
normal form (CNF) and disjunctive normal form (DNF). A CNF formula has the form

i∈I
"
j∈Ji
liti,j
where I and Ji are arbitrary ﬁnite index sets and liti,j for i ∈I and j ∈Ji are literals. The
subformulae "
j∈Ji liti,j are called clauses. For instance, (a1∨¬a3∨a4)∧(¬a2∨¬a3∨a4)∧a4
is a CNF formula with three clauses. Note that, e.g., true and false are also representable
by CNF formulae: true is obtained by I = ∅, while false is equivalent to a ∧¬a, a CNF
with two clauses consisting of one literal each. Given a PNF formula Φ, an equivalent CNF
formula is obtained (on the basis of the distributivity laws) by applying the transformation
rules:
Φ0 ∨(Ψ1 ∧Ψ2)
⇝
(Φ0 ∨Ψ1) ∧(Φ0 ∨Ψ2)
(Ψ1 ∧Ψ2) ∨Φ0
⇝
(Ψ1 ∨Φ0) ∧(Ψ2 ∨Φ0)

920
Appendix: Preliminaries
to Φ’s subformulae as long as possible. Thus, for each propositional formula Φ there exists
an equivalent CNF formula Φ′. Similarly, DNF formulae are formulae of the form
"
i∈I

j∈Ji
liti,j
where I and Ji are arbitrary ﬁnite index sets and liti,j for i ∈I and j ∈Ji are literals.
E.g., (a1 ∧¬a2) ∨(¬a2 ∧¬a3 ∧a4) ∨(¬a1 ∧¬a3) is a DNF formula. A transformation
similar to the one for CNF can be applied to prove that any propositional formula Φ has
an equivalent DNF formula Φ′.
A.4
Graphs
In most chapters of this monograph, the reader is supposed to be familiar with the basic
principles of graph theory and elementary graph algorithms. These are supposed to be
known from basic courses. This section is a brief summary of the terms and concepts that
are central to this monograph. The details can be found in any elementary textbook on al-
gorithms and data structures; see, e.g. [24, 100], or textbooks that provide an introduction
to graph theory, see, e.g. [396].
Digraphs (Graphs, for short) A digraph (or directed graph, in the following called
graph) is a pair G = (V, E) consisting of a set V of vertices and an edge relation E ⊆V ×V .
The elements of E are called edges. G is called ﬁnite if the set V (and hence also E) is
ﬁnite.
The basic models considered in this monograph will rely on graphs where the
vertices and edges are augmented with certain information.
E.g., instead of deﬁning
E as a set of vertex pairs, we may also deal with labeled edges, in which case E is a
subset of V × Σ × V for a certain alphabet Σ. If this additional information is irrelevant,
the edge labels may be omitted and rather than considering E ⊆V × Σ × V we use
E′ = { (v, w) | there exists an edge (v, σ, w) ∈E } to obtain a digraph in the above sense.
The following explanations refer to the case of a digraph G = (V, E) where E is a binary
relation over the vertices. For v ∈V , let PostG(v), or brieﬂy Post(v), denote the set of
direct successors of v; that is, Post(v) = { w ∈V | (v, w) ∈E }. Similarly, PreG(v),
or brieﬂy Pre(v), stands for the set of direct predecessors of v, i.e., Pre(v) = { w ∈V |
(w, v) ∈E }. A vertex v is called terminal if Post(v) = ∅. Edges of the form (v, v) are
called self-loops.
Paths in Graphs A path in G denotes a (ﬁnite or inﬁnite) non-empty sequence of vertices
ˆπ = v0 v1 . . . vr with r ⩾0 or π = v0 v1 v2 . . . such that vi+1 ∈Post(vi), i = 0, 1, 2, . . .. (In

Graphs
921
the context of transition systems, the term path is used in the sense of a maximal path,
that is, a path is either inﬁnite or ending in a terminal state.) A path is called simple if
its vertices are pairwise distinct, e.g., the ﬁnite path v0 v1 . . . vn is simple if vi ̸= vj for all
0 ⩽i < j ⩽n. The length of a path deﬁnes the number of traversed edges along the path
and is denoted by | · |. If ˆπ and π are as above, then |ˆπ| = r and |π| = ω. The set Post∗(v)
or Reach(v) denotes the set of all vertices reachable from v; that is, the set of all vertices
w ∈V with a ﬁnite path v0 v1 . . . vr with v = v0 and w = vr. A ﬁnite path v0, v1, . . . , vr is
called a cycle if v0 = vr and r > 0. Graph G is called acyclic (or cycle-free) if G does not
contain any cycle; otherwise G is called cyclic.
A popular representation of ﬁnite digraphs is by adjacency lists. This entails a list rep-
resentation for the sets Post(v) for each vertex v. To support direct access from vertex v
to its direct successors, an array for the vertices (in arbitrary order) can be used which
contains pointers to the heads of the adjacency lists.
Depth- and Breadth-First Search (DFS, BFS)
Depth-ﬁrst search (DFS) and
breadth-ﬁrst search (BFS) are important graph traversal strategies. They are both based
on the skeleton given in Algorithm 48 which deterimines each vertex v that is reachable
from the vertex v0. R is the set of vertices that have been already visited, while U keeps
track of all vertices that still have to be explored (provided they are not contained in R).
The procedure terminates since each edge is tagged as taken at most once. Any vertex u
can thus be added to U (and taken from U) at most |Pre(u)| times. Hence, Algorithm 48
terminates after at most O(M) iterations where M = |E| is the number of edges. (Note
that M = 
v∈V |Post(v)| = 
u∈V |Pre(u)|.) On termination, R contains all vertices that
are reachable from v0.
In case all vertices v ∈V have to be visited, the algorithm can be started with some
arbitrary vertex v0 and restarted with a new vertex v′
0, say, that has not yet been visited,
i.e., v′
0 /∈R. This can be repeated until all vertices belong to R. Given an adjacency
list representation of the sets Post(v), the time complexity is Θ(N + M) where N = |V |
is the number of vertices and M = 
v∈V |Post(v)| = |E| the number of edges. Here, it
is assumed that R and U are represented such that access to the elements of R and U,
as well as the insertion and deletion into U, takes constant time. For moderately sized
graphs, the set R can be represented by a bit-vector. In the context of model checking, R
is typically represented by a hash table. Using this data structure, the expected time to
insert an element into R and to check membership in R is constant.
Depth-ﬁrst and breadth-ﬁrst search diﬀer in the realization of the multiset U. The DFS
approach organizes U as a stack, while BFS relies on a queue implementation for U.
Accordingly, a stack obeys the LIFO principle (last-in, ﬁrst-out), while the insertion and
deletion of elements from a queue relies on the FIFO principle (ﬁrst-in, ﬁrst-out).

922
Appendix: Preliminaries
Algorithm 48 Reachability analysis
Input: ﬁnite digraph G = (V, E), vertex v0 ∈V
Output: Reach(v0)
set of vertex R := ∅;
(* the set of explored vertices *)
multiset of vertex U := {v0};
(* vertices still to be explored *)
(* initially none of the edges is tagged as taken *)
while U ̸= ∅do
let v ∈U;
(* choose some vertex still to be explored *)
if ∃u ∈Post(v) such that (v, u) is not tagged as taken then
let u ∈Post(v) be such a vertex;
tag the edge (v, u) as taken;
if u /∈R then
U := U ∪{u};
(* ensure that all successors *)
R := R ∪{ u }
(* of v will be explored *)
ﬁ
else
U := U \ { v }
ﬁ
od
return R.
(* R = Reach(v0) *)

Graphs
923
Let us brieﬂy summarize some details of the DFS approach. As mentioned above, DFS-
based graph traversal organizes the multiset of vertices that are still to be explored by
a stack. Stacks support the operations top(U) (which returns the ﬁrst element of U),
pop(U) (which deletes the ﬁrst element of U), and push(U, v) (which inserts v into U as
the ﬁrst element). The empty stack will be denoted with ε. Using an appropriate array
or list implementation of U, each of these operations, as well as checking emptiness, can
be executed in constant time.
DFSs provide the basis for many algorithms that analyze the topological structure of a
graph. An important algorithm in this monograph is a DFS-based cycle check, i.e., the
problem of deciding whether a given ﬁnite digraph contains a cycle. Such an algorithm
exploits the concept of backward edges.
The edge (v, u) is a backward edge whenever
vertex u is on the DFS stack U on tagging (v, u) as taken; see Algorithm 49.
Algorithm 49 Depth-ﬁrst search
Input: ﬁnite digraph G = (V, E), vertex v0 ∈V
Output: Reach(v0)
set of vertex R := ∅;
(* the set of explored vertices *)
stack of vertex U := ε;
(* initialize stack U as empty *)
for all vertices v0 ∈V do
if v0 /∈R then
push(U, v0);
(* U represents the singleton (multi-)set {v0} *)
while U ̸= ε do
v := top(U);
(* choose some vertex still to be explored *)
if ∃u ∈Post(v) such that (v, u) is not tagged as taken then
let u ∈Post(v) be such a vertex;
tag the edge (v, u) as taken;
if u /∈R then
push(U, u);
R := R ∪{ u }
(* u is visited *)
else
if u is contained in U then
tag (v, u) as backward edge
(* cycle found *)
ﬁ
ﬁ
else
U := U \ { v }
ﬁ
od
ﬁ
od
(* any vertex v in G has been visited *)

924
Appendix: Preliminaries
Any vertex w which is visited (i.e., inserted into R) when u is on the stack U is reachable
from u. Thus, any backward edge “closes” a cycle. Vice versa, if v0 v1 . . . vn is a cycle in G
and v0 is visited during the DFS after visiting v1, . . . , vn−1, then—on removing v0 as top
element from U tagging the edge (v0, v1) as taken—the vertices v2 through vn−1 are on the
stack U (since v0 is reachable from each of these vertices). As v1 has been visited before
v0, the edge (v0, v1) is a backward edge. Hence, for any cycle v0 v1 . . . vn in G, the DFS
classiﬁes at least one edge (vi−1, vi) as a backward edge. This yields that G has a cycle
if and only if the DFS detects a backward edge. Moreover, if we consider a ﬁxed starting
vertex v0 and apply the DFS approach to visit (exactly) the vertices that are reachable
from v0, then v0 belongs to a cycle in G if and only if the DFS ﬁnds a backward edge of
the form (w, v0) for some vertex w.
Strongly Connected Components (SCCs) Let G = (V, E) be a ﬁnite digraph and
C ⊆V . C is strongly connected if for every pair of vertices v, w ∈C, the vertices v
and w are mutually reachable, i.e., v ∈Post∗(w) and w ∈Post∗(v). A strongly connected
component (SCC, for short) of G is a maximally strongly connected set of vertices. That
is, C is an SCC if C is strongly connected and C is not contained in another strongly
connected vertex set D ⊆V with C ̸= D.
SCC C is called trivial if C = { v } and
(v, v) /∈E. SCC C is called terminal if there is no SCC D ̸= C such that (v, w) ∈E for
some v ∈C and w ∈D. Finite digraph G is cyclic if and only if G contains a nontrivial
SCC. The time complexity of determining the SCCs in ﬁnite digraph G is Θ(N + M)
where N = |V | and M = |E|. This complexity is obtained using a variant of DFS.
Trees The digraph T = (V, E) is a (directed) tree if there exists a vertex v0 with Pre(v0) =
∅such that each vertex v ∈V is reachable from v0 via a unique path. The vertex v0 is
the unique vertex with this property and is called the root of T.
Any vertex v with
Post(v) = ∅is called a leaf. Any vertex v ∈V \ { v0 } has exactly one direct predecessor,
i.e., |Pre(v)| = 1. This unique direct predecessor w of v is the father of v; v is called a
son of w.
Tree T is called ﬁnitely branching if the maximal outdegree of all its vertices is
ﬁnite, i.e., supv∈V |Post(v)| ∈IN. A binary tree is a tree with |Post(v)| ⩽2 for each vertex
v.
Hamiltonian Paths A Hamiltonian path in a ﬁnite digraph G = (V, E) is a path
v1 v2 . . . vn where each vertex v ∈V appears exactly once, i.e., V = { v1, . . . , vn } and
i ̸= j implies vi ̸= vj. The (directed) Hamiltonian path problem questions whether a
given ﬁnite digraph G has a Hamiltonian path.
Undirected Graphs An undirected graph is a digraph in which the orientation of the
edges is ignored. Formally, an undirected graph is a pair (V, E) where V is a set of vertices
and E a set consisting of subsets of V with exactly two elements. Then, { v, w } ∈E means
that there is an edge connecting v and w. Paths in undirected graphs are deﬁned as in

Computational Complexity
925
the directed case. For cycles it is required that they are composed of simple paths, i.e.,
paths v0 v1 . . . vn where n > 1 and v0, . . . , vn are pairwise distinct. (This constraint avoids
that a path of the form v w v with { v, w } ∈E is classiﬁed as cycle.)
A.5
Computational Complexity
In this monograph, some lower bounds on the time complexity of veriﬁcation problems are
presented. These lower bounds are based on showing the hardness for a certain complexity
class. This section summarizes the main basic concepts at a rather intuitive level. For the
precise deﬁnitions and technical details we refer to textbooks on complexity theory, such
as [160, 320].
The complexity class we consider here refers to decision problems, i.e., problems that take
a certain (ﬁnite) input and are required to return either “yes” or “no”. Example decision
problems are:
SAT (satisﬁability problem for propositional logic)
Given a propositional formula Φ. Is Φ satisﬁable?
(Directed) Hamiltonion path problem
Given a ﬁnite digraph G. Does G have a Hamiltonion path?
Cycle problem
Given a ﬁnite digraph G. Is G cyclic?
Pattern matching
Given ﬁnite words w = A1 . . . An (a text), v = B1 . . . Bm (a pattern) over some
alphabet. Is v a subword of w?
Complexity classes are classes of decision problems, classiﬁed by the resources (i.e., time
and space) that are required to solve them algorithmically.
Deterministic and Nondeterministic Algorithms The precise deﬁnition of the com-
plexity classes uses Turing machines as a formalization of algorithms. The input is encoded
by a ﬁnite word of the input alphabet of the Turing machine. The answers “yes” and “no”
correspond to the requirement that the Turing machine halts in an accept state (”yes”)
or in a nonaccept state (“no”). These details are omitted here. We describe informally
the complexity classes by means of an intuitive notion of what an algorithm is. For the
purpose of this monograph we need both deterministic and nondeterministic algorithms.
Although one typically aims at a deterministic algorithm to solve a certain problem (since

926
Appendix: Preliminaries
real programs do not work nondeterministically) the concept of nondeterministism plays
a crucial role in various theoretical considerations.
A deterministic algorithm is an algorithm where for any conﬁguration it is uniquely deter-
mined whether the algorithm halts or not, which output (if any) is provided, or what the
next step (and the successor conﬁguration) is. A deterministic algorithm solves a given
decision problem P if for each input w (1) the unique computation of the algorithm started
with w terminates, and (2) returns the correct answer. An input w (for P), of course,
needs to satisfy all criteria as given by the decision problem P, e.g., for the SAT prob-
lem, the input w is a propositional formula Φ. A deterministic algorithm solves the SAT
problem if it provides the answer “yes” if Φ is satisﬁable and “no” if Φ is not satisﬁable.
The time complexity of a deterministic algorithm A is typically measured by a function
TA : IN →IN where TA(n) is the maximal number of “steps” that A performs on an
input of size n. As the maximal number of steps is considered, TA reﬂects the worst-case
running time. Similarly, the space complexity is formalized by a function SA : IN →IN
where SA(n) is the maximal number of atomic memory units that are used for inputs of
length n.2
Nondeterministic algorithms diﬀer from deterministic algorithms in the sense that they
may provide ﬁnitely many alternatives for the next step of a conﬁguration. Thus, there
might be several possible computations of a nondeterministic algorithm on a given input
w. A nondeterministic algorithm is said to solve a decision problem P if for each input w:
(1) all computations for w terminate,
(2a) if the correct answer for w is “yes”, then there is at least one computation for w
that returns the answer “yes”, and
(2b) if the correct answer for w is “no”, then all computations for w return the answer
“no”.
An example of a nondeterministic algorithm for SAT is shown in Algorithm 50. Here,
sat(μ, Φ) is a subprocedure which computes deterministically the truth value of Φ under
the evaluation μ (in time Θ(|Φ|)). It returns the Boolean value true if μ |= Φ and false
otherwise. The details of this algorithm sat are not of importance here. Algorithm 50 relies
on the so-called “guess and check” principle which is the basis for many nondeterministic
algorithms. After nondeterministically guessing an evaluation μ it is checked whether or
not μ |= Φ. If the guess is correct, the evaluation is a witness for “μ |= Φ”, and the answer
2For some complexity classes, SA(n) only takes into account the memory requirement that is needed
in addition to the memory units for storing the input. As these complexity classes are not used in this
monograph, this detail is ignored here.

Computational Complexity
927
Algorithm 50 Nondeterministic algorithm for SAT
Input: propositional logic formula Φ over AP = {a1, . . . , an}
Output: ”yes” or ”no”
(* Guess an evalution μ for AP *)
for i = 1, . . . , n do
choose nondeterministically a truth value t ∈{0, 1};
μ(ai) := t
od
(* Check whether μ |= Φ *)
if sat(μ, Φ) then
return“yes”
(* Φ is satisﬁable *)
else
return “no”
(* Φ might or might not be satisﬁable *)
ﬁ
“yes” is correct. If, however, μ ̸|= Φ, then the given answer “no” might be wrong, as there
might be another evaluation μ′ with μ′ |= Φ. However, Algorithm 50 solves SAT since (1)
it terminates for all input formulae Φ. The fact that it also fulﬁlls conditions (2a) and
(2b) can be seen as follows. Condition (2a) holds since whenever Φ is satisﬁable, then
there exists a computation which chooses an evalution under which Φ holds, and hence,
the algorithm returns “yes”. Condition (2b) holds since whenever Φ is not satisﬁable, then
for each choice of μ in the guess phase we have μ ̸|= Φ and the returned answer is “no”.
The time complexity of a nondeterministic algorithm A that solves a decision problem
(i.e., all computations terminate) is given by the function TA : IN →IN where TA(n) is
the maximum number of steps that A may perform for inputs of length n. Similarly, the
space complexity of A is given by the function SA : IN →IN where SA(n) is the maximum
number of memory units that A may access on an input of length n.
Algorithm A (deterministic or nondeterministic) is called polynomially time-bounded (or
brieﬂy, a polytime algorithm) if TA(n) = O(poly(n)). Similarly, algorithm A is a polyspace
algorithm if SA(n) = O(poly(n)).
Complexity Classes Using the above intuitive explanations of deterministic and non-
deterministic algorithms, we are in a position to introduce the complexity classes used in
this monograph:
PTIME (or brieﬂy P) denotes the class of all decision problems that can be solved by a
deterministic polytime algorithm.

928
Appendix: Preliminaries
NP denotes the class of all decision problems that can be solved by a nondeterministic
polytime algorithm.
PSPACE denotes the class of all decision problems that can be solved by a deterministic
polyspace algorithm.
The complexity class NPSPACE is the class of all decision problems that can be solved by
a nondeterministic polyspace algorithm. It is known that PSPACE = NPSPACE. Since
any deterministic algorithm can be viewed as a nondeterministic algorithm (where the
number of alternative steps per conﬁguration is at most one) and since in N steps at most
N memory units can be used, it follows that:
PTIME ⊆NP ⊆PSPACE = NPSPACE.
One of the most important open questions in theoretical computer science is whether
PTIME agrees with NP. It is also unknown so far whether NP agrees with PSPACE.
The next complexity class considered is coNP which is somehow “complementary” to
NP.
Let P be a decision problem.
Then, the complementary problem of P, denoted
P, is the problem which takes the same inputs as P but requires the answer “no” if P
requires the answer “yes”, and vice versa. For example, the complementary problem of
SAT takes as input a propositional logic formula Φ and asks whether Φ is not satisﬁable.
The complementary problem of the (directed) Hamiltonian path problem asks whether a
given ﬁnite digraph G does not have a Hamiltonian path.
coNP denotes the class of all decision problems P where the complementary problem P
belongs to NP.
coNP subsumes PTIME and is contained in PSPACE, while it is unknown whether these
inclusions are strict. The complexity classes coPTIME and coPSPACE can be deﬁned
as the classes of the complementary problems of PTIME and PSPACE, respectively.
However, the symmetry of the treatment of “yes” and “no” by deterministic algorithms
allows swapping the outputs of a deterministic polytime (or polyspace) algorithm that
solves problem P to obtain a deterministic polytime (polyspace) algorithm for P. Hence,
PTIME = coPTIME and PSPACE = coPSPACE. Note that this argument does not apply
to nondeterministic complexity classes due to the asymmetry of “yes” and “no” answers
according to (2a) and (2b). The question whether NP and coNP agree is an open problem.
Further complexity classes that will be needed in this monograph are EXPTIME and
2EXPTIME. EXPTIME denotes the class of decision problems P that are solvable by a
deterministic algorithm where the worst-case time complexity is exponentially bounded,
i.e., bounded above by a function n →2p(n) where p is a polynomial. The complexity

Computational Complexity
929
class 2EXPTIME consists of all decision problems that can be solved by a deterministic
algorithm for which the worst-case time complexity is bounded by some function n →22p(n)
where p is a polynomial. It holds that
PSPACE ⊆EXPTIME ⊆2EXPTIME.
Completeness To specify the “hardest” problem in NP, Cook [99] introduced in the early
seventies the notion of NP-completeness. Decision problem P ∈NP is NP-complete if the
existence of a deterministic polytime algorithm A for P, implies that any other problem
Q ∈NP can be solved deterministically with the help of A plus a polytime transformation
from Q’s inputs to P’s inputs. (The transformation of Q’s inputs into P’s inputs relies
on the reduction principle.) Thus, if one NP-complete problem is shown to be in PTIME,
then NP = PTIME.
Let us brieﬂy consider these concepts in more detail. Let P and Q be decision problems.
Problem Q is called polynomially reducible to P if there exists a polytime deterministic
algorithm which transforms a given input wQ for Q into an input wP for P such that
the correct answer for Q on wQ is “yes” if and only if the correct answer for P on wP is
“yes”. Decision problem P is said to be NP-hard if each problem Q ∈NP is polynomially
reducible to P. P is called NP-complete if (1) P belongs to NP and (2) P is NP-hard.
There is a wide range of NP-complete problems. For many cases, the proof of membership
of P in NP is quite simple—one provides a polytime nondeterministic algorithm for P on
the basis of the guess-and-check paradigm. The NP-hardness is often harder to prove. The
ﬁrst NP-completeness result was by Cook [99] who showed that the SAT problem is NP-
complete. His proof for the NP-hardness of SAT is generic: it starts with a formalization
of a polytime nondeterministic algorithm for some NP-problem Q by a nondeterministic
Turing machine M and constructs for a given input word w for M a propositional formula
ΦM,w such that ΦM,w is satisﬁable if and only if M has an accepting computation for w.
For proving the NP-hardness of a given problem P, it is often simpler to use the reduction
principle:
if Q is NP-hard and Q is polynomially reducible to P, then P is NP-hard.
For instance, a polynomial reduction from SAT to 3SAT (a variant of SAT which takes as
input a CNF formula Φ with at most three literals per clause and asks for the satisﬁability
of Φ) is not very involved and yields the NP-hardness of 3SAT. The NP-hardness of the
Hamiltonian path problem can be proven by a polynomial reduction from 3SAT to the
Hamiltonian path problem. The latter problem is again polynomially reducible to the
three-coloring problem, a decision problem on ﬁnite undirected graphs that asks whether
the vertices can be colored with three colors such that for no edge { v, w } the vertices v
and w are equally colored. Hence, the three-coloring problem is NP-hard too. In this way,
a wide range of NP-hardness results have been obtained.

930
Appendix: Preliminaries
Hardness or completeness can be deﬁned in an analogous way for other complexity classes
such as PSPACE and coNP. P is called PSPACE-complete if (1) P belongs to PSPACE
and (2) P is PSPACE-hard, i.e., all problems in PSPACE are polynomially reducible to
P.
An example of a PSPACE-complete problem is the universality problem: does the
language described by a regular expression over the alphabet Σ equal Σ∗? Similarly, P is
called coNP-complete if (1) P belongs to coNP and (2) P is coNP-hard, i.e., all problems
in coNP are polynomially reducible to P.
The symmetry of NP and coNP yields that a
problem P is NP-hard if and only if its complementary problem P is coNP-hard. Thus,
P is NP-complete if and only if P is coNP-complete. For instance, the problem whether
a given propositional logic formula Φ is valid is coNP-complete, since Φ →¬Φ yields a
polynomial reduction from SAT to the validity problem—recall that Φ is not satisﬁable
if and only if ¬Φ is valid (see page 919)—and SAT is coNP-complete (as SAT is NP-
complete). Since coNP and NP are contained in PSPACE, any problem that is hard for
PSPACE is also coNP- and NP-hard.

Bibliography
[1] M. Abadi and L. Lamport. The existence of reﬁnement mappings. Theoretical
Computer Science, 82(2):253–284, 1991.
[2] Y. Abarbanel-Vinov and N. Aizenbud-Reshef and I. Beer and C. Eis-
ner and D. Geist and T. Heyman and I. Reuveni and E. Rippel and I.
Shitsevalov and Y. Wolfsthal and T. Yatzkar-Haham. On the eﬀective
deployment of functional formal veriﬁcation.
Formal Methods in System Design,
19:35–44, 2001.
[3] P. A. Abdulla and B. Jonsson and M. Kindahl and D. Peled. A general
approach to partial order reductions in symbolic veriﬁcation (extended abstract). In
10th International Conference on Computer Aided Veriﬁcation (CAV), volume 1427
of Lecture Notes in Computer Science, pages 379–390. Springer-Verlag, 1998.
[4] S. Abramsky. A domain equation for bisimulation. Information and Computation,
92(2):161–218, 1991.
[5] B. Alpern and F. Schneider. Deﬁning liveness. Information Processing Letters,
21(4):181–185, 1985.
[6] B. Alpern and F. Schneider. Recognizing safety and liveness. Distributed Com-
puting, 2(3):117–126, 1987.
[7] B. Alpern and F. Schneider. Verifying temporal properties without temporal
logic. ACM Transactions on Programming Languages and Systems, 11(1):147–167,
1989.
[8] R. Alur and R. K. Brayton and T. Henzinger and S. Qadeer and S. K.
Rajamani. Partial order reduction in symbolic state-space exploration.
Formal
Methods in System Design, 18(2):97–116, 2001.
[9] R. Alur and C. Courcoubetis and D. Dill. Model-checking in dense real time.
Information and Computation, 104(2):2–34, 1993.
931

932
BIBLIOGRAPHY
[10] R. Alur and D. Dill. Automata for modeling real-time systems. In 17th Inter-
national Colloquium on Automata, Languages and Programming (ICALP), volume
443 of Lecture Notes in Computer Science, pages 322–335. Springer-Verlag, 1990.
[11] R. Alur and D. Dill. A theory of timed automata. Theoretical Computer Science,
126(2):183–235, 1994.
[12] R. Alur and D. Dill. Automata-theoretic veriﬁcation of real-time systems. In
C. Heitmeyer and D. Mandrioli, editors, Formal Methods for Real-Time Computing,
pages 55–82. John Wiley & Sons, 1996.
[13] R. Alur and L. Fix and T. A. Henzinger. Event-clock automata: a determiniz-
able class of timed automata.
Theoretical Computer Science, 211(1–2):253–273,
1999.
[14] S. Andova and H. Hermanns and J.-P. Katoen. Discrete-time rewards model
checked. In 1st International Workshop on Formal Modeling and Analysis of Timed
Systems (FORMATS), volume 2791 of Lecture Notes in Computer Science, pages
88–104. Springer-Verlag, 2003.
[15] K. R. Apt. Correctness proofs of distributed termination algorithms. ACM Trans-
actions on Programming Languages and Systems, 8(3):388–405, 1986.
[16] K. R. Apt and N. Francez and W.-P. de Roever. A proof system for commu-
nicating sequential processes. ACM Transactions on Programming Languages and
Systems, 2(3):359–385, 1980.
[17] K. R. Apt and D. Kozen. Limits for the automatic veriﬁcation of ﬁnite-state
concurrent systems. Information Processing Letters, 22(6):307–309, 1986.
[18] K. R. Apt and E.-R. Olderog. Veriﬁcation of Sequential and Concurrent Pro-
grams. Springer-Verlag, 1997.
[19] A. Arnold. Finite Transition Systems. Prentice-Hall, 1994.
[20] E. Asarin and P. Caspi and O. Maler. Timed regular expressions. Journal of
the ACM, 49(2):172–206, 2002.
[21] R. B. Ash and C. A. Dol´eans-Dade. Probability and Measure Theory. Academic
Press, 2000.
[22] A. Aziz and K. Sanwal and V. Singhal and R. K. Brayton. Model-checking
continous-time Markov chains. ACM Transactions on Computer Logic, 1(1):162–
170, 2000.

BIBLIOGRAPHY
933
[23] A. Aziz and V. Singhal and F. Balarin and R. K. Brayton and A. L.
Sangiovanni-Vincentelli.
It usually works: The temporal logic of stochastic
systems. In 7th International Conference on Computer Aided Veriﬁcation (CAV),
volume 939 of Lecture Notes in Computer Science, pages 155–165. Springer-Verlag,
1995.
[24] S. Baase and A. van Gelder. Computer Algorithms: Introduction to Design and
Analysis. Addison-Wesley, 2000.
[25] C. Baier and F. Ciesinski and M. Gr¨oßer. Probmela: a modeling language for
communicating probabilistic systems. In 2nd ACM-IEEE International Conference
on Formal Methods and Models for Codesign (MEMOCODE), pages 57–66. IEEE
Computer Society Press, 2004.
[26] C.
Baier
and
E.
Clarke
and
V.
Hartonas-Garmhausen
and
M.
Kwiatkowska and M. Ryan.
Symbolic model checking for probabilistic pro-
cesses.
In 24th International Colloqium on Automata, Languages and Program-
ming (ICALP), volume 1256 of Lecture Notes in Computer Science, pages 430–440.
Springer-Verlag, 1997.
[27] C. Baier and B. Engelen and M. E. Majster-Cederbaum. Deciding bisim-
ilarity and similarity for probabilistic processes. Journal of Computer and System
Sciences, 60(1):187–231, 2000.
[28] C. Baier and M. Gr¨oßer and F. Ciesinski. Partial order reduction for prob-
abilistic systems.
In 1st International Conference on Quantitative Evaluation of
Systems (QEST), pages 230–239. IEEE Computer Society Press, 2004.
[29] C. Baier and B. R. Haverkort and H. Hermanns and J.-P. Katoen. Model
checking algorithms for continuous time Markov chains.
IEEE Transactions on
Software Engineering, 29(6):524–541, 2003.
[30] C. Baier and J.-P. Katoen and H. Hermanns and V. Wolf.
Compara-
tive branching time semantics for Markov chains. Information and Computation,
200(2):149–214, 2005.
[31] C. Baier and M. Kwiatkowska. Model checking for a probabilistic branching
time logic with fairness. Distributed Computing, 11(3):125–155, 1998.
[32] C. Baier and M. Kwiatkowska. On the veriﬁcation of qualitative properties of
probabilistic processes under fairness constraints. Information Processing Letters,
66(2):71–79, 1998.
[33] T. Ball and A. Podelski and S. Rajamani. Boolean and Cartesian abstrac-
tion for model checking C programs. In 7th International Conference on Tools and

934
BIBLIOGRAPHY
Algorithms for the Construction and Analysis of Systems (TACAS), volume 2031 of
Lecture Notes in Computer Science, pages 268–283. Springer-Verlag, 2001.
[34] K. A. Bartlett and R. A. Scantlebury and P. T. Wilkinson. A note on
reliable full duplex transmission over half duplex links. Communications of the ACM,
12(5):260–261, 1969.
[35] G. Behrmann and A. David and K. G. Larsen. A tutorial on Uppaal. In For-
mal Methods for the Design of Real-Time Systems, International School on Formal
Methods for the Design of Computer, Communication and Software Systems, volume
3185 of Lecture Notes in Computer Science, pages 200–236. Springer-Verlag, 2004.
[36] B. Beizer. Software Testing Techniques. Van Nostrand Reinhold, 1990.
[37] F. Belina and D. Hogrefe and A. Sarma. SDL with Applications from Protocol
Speciﬁcation. Prentice-Hall, 1991.
[38] R. Bellman. A Markovian decision process. Journal of Mathematics and Mechan-
ics, 38:679–684, 1957.
[39] R. Bellman. Markovian decision processes. Journal of Mathematics and Mechanics,
38:716–719, 1957.
[40] R. Bellman. On a routing problem. Quarterly of Applied Mathematics, 16(1):87–
90, 1958.
[41] M. Ben-Ari. Algorithms for on-the-ﬂy garbage collection. ACM Transactions on
Programming Languages and Systems, 6(3):333–344, 1984.
[42] M. Ben-Ari and Z. Manna and A. Pnueli. The temporal logic of branching
time. Acta Informatica, 20:207–226, 1983.
[43] J. Bengtsson and W. Yi. Timed automata: semantics, algorithms and tools. In
Lectures on Concurrency and Petri Nets, volume 3098 of Lecture Notes in Computer
Science, pages 87–124. Springer-Verlag, 2003.
[44] B. B´erard and M. Bidoit and A. Finkel and F. Laroussinie and A. Petit
and L. Petrucci and Ph. Schnoebelen. Systems and Software Veriﬁcation:
Model-Checking Techniques and Tools. Springer-Verlag, 2001.
[45] J. A. Bergstra and J. W. Klop.
Algebra of communicating processes with
abstraction. Theoretical Computer Science, 37:77–121, 1985.
[46] J. A. Bergstra and A. Ponse and S. A. Smolka (editors). Handbook of
Process Algebra. Elsevier Publishers B.V., 2001.

BIBLIOGRAPHY
935
[47] P. Berman and J. A. Garay.
Asymptotically optimal distributed consensus
(extended abstract). In Automata, Languages and Programming (ICALP), volume
372 of Lecture Notes in Computer Science, pages 80–94. Springer-Verlag, 1989.
[48] B. Berthomieu and M. Menasche. An enumerative approach for analyzing time
Petri nets. In IFIP 9th World Computer Congress, pages 41–46. North Holland,
1983.
[49] D. P. Bertsekas. Dynamic Programming: Deterministic and Stochastic Models.
Prentice-Hall, 1987.
[50] G. Bhat and R. Cleaveland and O. Grumberg. Eﬃcient on-the-ﬂy model
checking for CTL∗. In 10th Annual IEEE Symposium on Logic in Computer Science
(LICS), pages 388–397. IEEE Computer Society Press, 1995.
[51] A. Bianco and L. de Alfaro. Model checking of probabilistic and nondetermin-
istic systems. In 15th International Conference on Foundations of Software Tech-
nology and Theoretical Computer Science (FSTTCS), volume 1026 of Lecture Notes
in Computer Science, pages 499–513. Springer-Verlag, 1995.
[52] B. W. Boehm. Software Engineering Economics. Prentice-Hall, 1981.
[53] B. W. Boehm and V. R. Basili. Software defect reduction top 10 list. IEEE
Computer, 34(1):135–137, 2001.
[54] H. Bohnenkamp and P. van der Stok and H. Hermanns and F.W. Vaan-
drager. Cost optimisation of the ipv4 zeroconf protocol. In International Confer-
ence on Dependable Systems and Networks (DSN), pages 626–638. IEEE Computer
Society Press, 2003.
[55] G. Bolch and S. Greiner and H. de Meer and K. S. Trivedi. Queueing Net-
works and Markov Chains: Modeling and Performance Evaluation with Computer
Science Applications. John Wiley & Sons, 2006.
[56] B. Bollig and I. Wegener. Improving the variable ordering of OBDDs is NP-
complete. IEEE Transactions on Computers, 45(9):993–1002, 1996.
[57] T. Bolognesi and E. Brinksma. Introduction to the ISO speciﬁcation language
LOTOS. Computer Networks and ISDN Systems, 14(1):25–59, 1987.
[58] S. Bornot and J. Sifakis. An algebraic framework for urgency. Information and
Computation, 163(1):172–202, 2000.
[59] D. Bosnacki and G. Holzmann. Improving SPIN’s partial-order reduction for
breadth-ﬁrst search.
In 12th International SPIN Workshop on Model Checking
of Software, volume 3639 of Lecture Notes in Computer Science, pages 91–105.
Springer-Verlag, 2005.

936
BIBLIOGRAPHY
[60] A. Bouajjani and J.-C. Fernandez and N. Halbwachs. Minimal model gen-
eration.
In 2nd International Workshop on Computer-Aided Veriﬁcation (CAV),
volume 531 of Lecture Notes in Computer Science, pages 197–203. Springer-Verlag,
1990.
[61] P. Bouyer. Untameable timed automata!
In 20th Annual Symposium on The-
oretical Aspects of Computer Science (STACS), volume 2607 of Lecture Notes in
Computer Science, pages 620–631. Springer-Verlag, 2003.
[62] R. K. Brayton and G. D. Hachtel and A. L. Sangiovanni-Vincentelli
and F. Somenzi and A. Aziz and S.-T. Cheng and S. A. Edwards and S. P.
Khatri and Y. Kukimoto and A. Pardo and S. Qadeer and R. K. Ranjan
and S. Sarwary and T. R. Shiple and G. Swamy and T. Villa.
VIS: a
system for veriﬁcation and synthesis. In 8th International Conference on Computer
Aided Veriﬁcation (CAV), volume 1102 of Lecture Notes in Computer Science, pages
428–432. Springer-Verlag, 1996.
[63] P. Bremaud. Markov Chains, Gibbs Fields, Monte Carlo Simulation and Queues.
Springer-Verlag, 1999.
[64] L. Brim and I. ˇCern´a and M. Neˇcesal. Randomization helps in LTL model
checking. In 1st Joint International Workshop on Process Algebra and Probabilistic
Methods, Performance Modeling and Veriﬁcation (PAPM-PROBMIV), volume 2165
of Lecture Notes in Computer Science, pages 105–119. Springer-Verlag, 2001.
[65] S. D. Brookes and C. A. R. Hoare and A. W. Roscoe. A theory of commu-
nicating sequential processes. Journal of the ACM, 31(3):560–599, 1984.
[66] M. C. Browne and E. M. Clarke and D. L. Dill and B. Mishra. Auto-
matic veriﬁcation of sequential circuits using temporal logic. IEEE Transactions on
Computers, 35(12):1035–1044, 1986.
[67] M. C. Browne and E. M. Clarke and O. Grumberg. Characterizing ﬁnite
Kripke structures in propositional temporal logic. Theoretical Computer Science,
59(1–2):115–131, 1988.
[68] S. D. Bruda. Preorder relations. In M. Broy, B. Jonsson, J.-P. Katoen, M. Leucker,
and A. Pretschner, editors, Model-Based Testing of Reactive Systems, volume 3472
of Lecture Notes in Computer Science, chapter 5, pages 115–148. Springer-Verlag,
2005.
[69] J. Brunekreef and J.-P. Katoen and R. Koymans and S. Mauw. Design
and analysis of dynamic leader election protocols in broadcast networks. Distributed
Computing, 9(4):157–171, 1996.

BIBLIOGRAPHY
937
[70] R. Bryant.
Graph-based algorithms for boolean function manipulation.
IEEE
Transactions on Computers, 35(8):677–691, 1986.
[71] R. Bryant. On the complexity of VLSI implementations and graph representations
of boolean functions with application to integer multiplication. IEEE Transactions
on Computers, 40(2):205–213, 1991.
[72] P. Buchholz. Exact and ordinary lumpability in Markov chains. Journal of Applied
Probability, 31:59–75, 1994.
[73] J. R. B¨uchi.
On a decision method in restricted second order arithmetic.
In
International Congress on Logic, Methodology and Philosophy of Science, pages 1–
11. Stanford University Press, 1962.
[74] J. Burch and E. Clarke and K. L. McMillan and D. L. Dill and L.
Hwang. Symbolic model checking 1020 states and beyond. Information and Com-
putation, 98(2):142–170, 1992.
[75] J. Burch and E. M. Clarke and K. L. McMillan and D. L. Dill. Sequential
circuit veriﬁcation using symbolic model checking. In 27th ACM/IEEE Conference
on Design Automation (DAC), pages 46–51. IEEE Computer Society Press, 1990.
[76] D. Bustan and O. Grumberg. Simulation-based minimization. ACM Transac-
tions on Computational Logic, 4(2):181–206, 2003.
[77] D. Bustan and S. Rubin and M. Y. Vardi. Verifying ω-regular properties of
Markov chains. In 16th International Conference on Computer Aided Veriﬁcation
(CAV), volume 3114 of Lecture Notes in Computer Science, pages 189–201. Springer-
Verlag, 2004.
[78] K. Cerans. Decidability of bisimulation equivalences for parallel timer processes.
In 4th International Workshop on Computer Aided Veriﬁcation (CAV), volume 663
of Lecture Notes in Computer Science, pages 302–315. Springer-Verlag, 1992.
[79] W. Chan and R. J. Anderson and P. Beame and S. Burns and F. Modugno
and D. Notkin and J. D. Reese. Model checking large software speciﬁcations.
IEEE Transactions on Software Engineering, 24(7):498–520, 1998.
[80] E. Chang and Z. Manna and A. Pnueli.
The safety-progress classiﬁcation.
In F. L. Bauer, W. Brauer, and H. Schwichtenberg, editors, Logic and Algebra of
Speciﬁcation, volume 94 of NATO ASI Series F: Computer and Systems Sciences,
pages 143–202. Springer-Verlag, 1992.
[81] Y. Choueka. Theories of automata on ω-tapes. Journal of Computer and System
Sciences, 8:117–141, 1974.

938
BIBLIOGRAPHY
[82] F. Ciesinski and C. Baier. LiQuor: a tool for qualititative and quantitative linear
time analysis of reactive systems. In 3rd Conference on Quantitative Evaluation of
Systems (QEST), pages 131–132. IEEE Computer Society Press, 2006.
[83] A. Cimatti and E. M. Clarke and F. Giunchiglia and M. Roveri. NuSMV: a
new symbolic model checker. International Journal on Software Tools for Technology
Transfer, 2(4):410–425, 2000.
[84] E. M. Clarke and A. Biere and R. Raimi and Y. Zhu.
Bounded model
checking using satisﬁability solving. Formal Methods in System Design, 19(1):7–34,
2001.
[85] E. M. Clarke and I. A. Draghicescu. Expressibility results for linear time and
branching time logics. In J. W. de Bakker, W.-P. de Roever, and G. Rozenberg,
editors, Linear Time, Branching Time, and Partial Order in Logics and Model for
Concurrency, volume 354 of Lecture Notes in Computer Science, pages 428–437.
Springer-Verlag, 1988.
[86] E. M. Clarke and E. A. Emerson. Design and synthesis of synchronization
skeletons using branching time temporal logic. In Logic of Programs, volume 131 of
Lecture Notes in Computer Science, pages 52–71. Springer-Verlag, 1981.
[87] E. M. Clarke and E. A. Emerson and A. P. Sistla. Automatic veriﬁcation
of ﬁnite-state concurrent systems using temporal logic speciﬁcations. ACM Trans-
actions on Programming Languages and Systems, 8(2):244–263, 1986.
[88] E. M. Clarke and O. Grumberg and K. Hamaguchi. Another look at LTL
model checking. In 6th International Conference on Computer Aided Veriﬁcation
(CAV), volume 818 of Lecture Notes in Computer Science, pages 415–427. Springer-
Verlag, 1994.
[89] E. M. Clarke and O. Grumberg and H. Hiraishi and S. Jha and D. E.
Long and K. L. McMillan and L. A. Ness. Veriﬁcation of the Futurebus+
cache coherence protocol.
In 11th International Symposium on Computer Hard-
ware Description Languages and their Applications, pages 5–20. Kluwer Academic
Publishers, 1993.
[90] E. M. Clarke and O. Grumberg and D. E. Long. Model checking and abstrac-
tion. ACM Transactions on Programming Languages and Systems, 16(5):1512–1542,
1994.
[91] E. M. Clarke and O. Grumberg and K. L. McMillan and X. Zhao. Eﬃ-
cient generation of counterexamples and witnesses in symbolic model checking. In
32nd ACM/IEEE Conference on Design Automation (DAC), pages 427–432. IEEE
Computer Society Press, 1995.

BIBLIOGRAPHY
939
[92] E. M. Clarke and O. Grumberg and D. Peled. Model Checking. MIT Press,
1999.
[93] E. M. Clarke and S. Jha and Y. Lu and H. Veith. Tree-like counterexamples
in model checking. In 17th Annual IEEE Symposium on Logic in Computer Science
(LICS), pages 19–29. IEEE Computer Society Press, 2002.
[94] E. M. Clarke and R. Kurshan. Computer-aided veriﬁcation. IEEE Spectrum,
33(6):61–67, 1996.
[95] E. M. Clarke and H. Schlingloff. Model checking. In A. Robinson and A.
Voronkov, editors, Handbook of Automated Reasoning (Volume II), chapter 24, pages
1635–1790. Elsevier Publishers B.V., 2000.
[96] E. M. Clarke and J. Wing. Formal methods: state of the art and future direc-
tions. ACM Computing Surveys, 28(4):626–643, 1996.
[97] R. Cleaveland and J. Parrow and B. Steffen. The concurrency workbench:
a semantics-based tool for the veriﬁcation of concurrent systems. ACM Transactions
on Programming Languages and Systems, 15(1):36–72, 1993.
[98] R. Cleaveland and O. Sokolsky. Equivalence and preorder checking for ﬁnite-
state systems.
In J. Bergstra, A. Ponse, and S.A. Smolka, editors, Handbook of
Process Algebra, chapter 6, pages 391–424. Elsevier Publishers B.V., 2001.
[99] S. Cook.
The complexity of theorem-proving procedures. In 3rd Annual ACM
Symposium on Theory of Computing, pages 151–158. ACM Press, 1971.
[100] T. H. Cormen and C. E. Leiserson and R. L. Rivest and C. Stein. Intro-
duction to Algorithms. MIT Press, 2001.
[101] F. Corradini and R. De Nicola and A. Labella. An equational axiomati-
zation of bisimulation over regular expressions. Journal of Logic and Computation,
12(2):301–320, 2002.
[102] C. Courcoubetis and M. Y. Vardi and P. Wolper and M. Yannakakis.
Memory-eﬃcient algorithms for the veriﬁcation of temporal properties.
Formal
Methods in System Design, 1(2–3):275–288, 1992.
[103] C. Courcoubetis and M. Yannakakis.
Markov decision processes and reg-
ular events (extended abstract). In 17th International Colloquium on Automata,
Languages and Programming (ICALP), volume 443 of Lecture Notes in Computer
Science, pages 336–349. Springer-Verlag, 1990.
[104] C. Courcoubetis and M. Yannakakis. The complexity of probabilistic veriﬁca-
tion. Journal of the ACM, 42(4):857–907, 1995.

940
BIBLIOGRAPHY
[105] P. Cousot and R. Cousot.
On abstraction in software veriﬁcation.
In 14th
International Conference on Computer Aided Veriﬁcation (CAV), volume 2404 of
Lecture Notes in Computer Science, pages 37–56. Springer-Verlag, 2002.
[106] J.-M. Couvreur.
On-the-ﬂy veriﬁcation of linear temporal logic.
In World
Congress on Formal Methods (FM), volume 1708 of Lecture Notes in Computer
Science, pages 253–271. Springer-Verlag, 1999.
[107] J.-M. Couvreur and A. Duret-Lutz and D. Poitrenaud. On-the-ﬂy empti-
ness checks for generalized B¨uchi automata. In 12th International SPIN Workshop
on Model Checking of Software, volume 3639 of Lecture Notes in Computer Science,
pages 143–158. Springer-Verlag, 2005.
[108] J.-M. Couvreur and N. Saheb and G. Sutre. An optimal automata approach
to LTL model checking of probabilistic systems. In 10th International Conference
on Logic for Programming, Artiﬁcial Intelligence, and Reasoning (LPAR), volume
2850 of Lecture Notes in Computer Science, pages 361–375. Springer-Verlag, 2003.
[109] D. Dams and R. Gerth and O. Grumberg. Abstract interpretation of reactive
systems. ACM Transactions on Programming Languages and Systems, 19(2):253–
291, 1997.
[110] M. Daniele and F. Giunchiglia and M. Y. Vardi. Improved automata genera-
tion for linear temporal logic. In 11th International Conference on Computer Aided
Veriﬁcation (CAV), volume 1633 of Lecture Notes in Computer Science, pages 249–
260. Springer-Verlag, 1999.
[111] P. R. D’Argenio and E. Brinksma. A calculus for timed automata.
In 4th
International Symposium on Formal Techniques in Real-Time and Fault-Tolerant
Systems (FTRTFT), volume 1135 of Lecture Notes in Computer Science, pages 110–
129. Springer-Verlag, 1996.
[112] P. R. D’Argenio and B. Jeannet and H. Jensen and K. Larsen. Reacha-
bility analysis of probabilistic systems by successive renements. In Proc. 1st Joint
Int. Workshop Process Algebra and Probabilistic Methods, Performance Modeling
and Veriﬁcation (PAPM-PROBMIV), volume 2399 of Lecture Notes in Computer
Science, pages 39–56, 2001.
[113] P. R. D’Argenio and P. Niebert. Partial order reduction on concurrent prob-
abilistic programs. In 1st International Conference on Quantitative Evaluation of
Systems (QEST), pages 240–249. IEEE Computer Society Press, 2004.
[114] L. de Alfaro. Temporal logics for the speciﬁcation of performance and reliability.
In 14th Annual Symposium on Theoretical Aspects of Computer Science (STACS),
volume 1200 of Lecture Notes in Computer Science, pages 165–176. Springer-Verlag,
1997.

BIBLIOGRAPHY
941
[115] L. de Alfaro. Formal Veriﬁcation of Probabilistic Systems. PhD thesis, Stanford
University, Department of Computer Science, 1998.
[116] L. de Alfaro. How to specify and verify the long-run average behavior of prob-
abilistic systems. In Thirteenth Annual IEEE Symposium on Logic in Computer
Science (LICS), pages 454–465. IEEE Computer Society Press, 1998.
[117] L. de Alfaro. Computing minimum and maximum reachability times in proba-
bilistic systems. In 10th Conference on Concurrency Theory (CONCUR), volume
1664 of Lecture Notes in Computer Science, pages 66–81. Springer-Verlag, 1999.
[118] W.-P. de Roever and F. S. de Boer and U. Hannemann and J. Hooman
and Y. Lakhnech and M. Poel and J. Zwiers.
Concurrency Veriﬁcation:
Introduction to Compositional and Noncompositional Methods. Number 54 in Cam-
bridge Tracts in Theoretical Computer Science. Cambridge University Press, 2001.
[119] F. Dederichs and R. Weber. Safety and liveness from a methodological point
of view. Information Processing Letters, 36(1):25–30, 1990.
[120] S. Derisavi and H. Hermanns and W. H. Sanders. Optimal state-space lump-
ing in Markov chains. Information Processing Letters, 87(6):309–315, 2003.
[121] J. Desharnais and A. Edalat and P. Panangaden. Bisimulation for labelled
Markov processes. Information and Computation, 179(2):163–193, 2002.
[122] J. Desharnais and V. Gupta and R. Jagadeesan and P. Panangaden. Weak
bisimulation is sound and complete for PCTL∗. In Thirteenth International Confer-
ence on Concurrency Theory (CONCUR), volume 2421 of Lecture Notes in Com-
puter Science, pages 355–370. Springer-Verlag, 2002.
[123] J. Desharnais and V. Gupta and R. Jagadeesan and P. Panangaden. Ap-
proximating labelled Markov processes. Information and Computation, 184(1):160–
200, 2003.
[124] J. Desharnais and P. Panangaden. Continuous stochastic logic characterizes
bisimulation of continuous-time Markov processes. Journal of Algebraic and Logic
Programming, 56(1–2):99–115, 2003.
[125] V. Diekert and Y. M´etivier. Partial commutation and traces. In G. Rozenberg
and A. Salomaa, editors, Handbook of Formal Languages, volume 3, pages 457–533.
Springer-Verlag, 1997.
[126] E. W. Dijkstra. Solutions of a problem in concurrent programming control. Com-
munications of the ACM, 8(9):569, 1965.
[127] E. W. Dijkstra. Cooperating sequential processes. In F. Genuys, editor, Program-
ming Languages, pages 43–112. Academic Press, 1968.

942
BIBLIOGRAPHY
[128] E. W. Dijkstra. Hierarchical ordering of sequential processes. Acta Informatica,
1:115–138, 1971.
[129] E. W. Dijkstra. Information streams sharing a ﬁnite buﬀer. Information Process-
ing Letters, 1(5):179–180, 1972.
[130] E. W. Dijkstra. A Discipline of Programming. Prentice-Hall, 1976.
[131] D. L. Dill. Timing assumptions and veriﬁcation of ﬁnite-state concurrent systems.
In International Workshop on Automatic Veriﬁcation Methods for Finite-State Sys-
tems, volume 407 of Lecture Notes in Computer Science, pages 197–212. Springer-
Verlag, 1989.
[132] D. L. Dill. The Murϕ veriﬁer. In 8th International Conference on Computer Aided
Veriﬁcation (CAV), volume 1102 of Lecture Notes in Computer Science, pages 390–
393. Springer-Verlag, 1996.
[133] J. Dingel and T. Filkorn. Model checking for inﬁnite state systems using data
abstraction, assumption commitment style reasoning and theorem proving. In 7th
International Conference on Computer Aided Veriﬁcation (CAV), volume 939 of
Lecture Notes in Computer Science, pages 54–69. Springer-Verlag, 1995.
[134] R. Drechsler and B. Becker. Binary Decision Diagrams: Theory and Imple-
mentation. Kluwer Academic Publishers, 1998.
[135] S. Edelkamp and A. Lluch Lafuente and S. Leue. Directed explicit model
checking with HSF-SPIN. In 8th International SPIN Workshop on Model Checking of
Software, volume 2057 of Lecture Notes in Computer Science, pages 57–79. Springer-
Verlag, 2001.
[136] C. Eisner and D. Fisman. A Practical Introduction to PSL. Series on Integrated
Circuits and Systems. Springer, 2006.
[137] T. Elrad and N. Francez.
Decomposition of distributed programs into
communication-closed layers.
Science of Computer Programming, 2(3):155–173,
1982.
[138] E. A. Emerson. Temporal and modal logic. In J. van Leeuwen, editor, Handbook
of Theoretical Computer Science, vol B: Formal Models and Semantics. Elsevier
Publishers B.V., 1990.
[139] E. A. Emerson and J. Y. Halpern. Decision procedures and expressiveness in
the temporal logic of branching time. Journal of Computer and System Sciences,
30(1):1–24, 1985.

BIBLIOGRAPHY
943
[140] E. A. Emerson and J. Y. Halpern. “Sometimes” and “not never” revisited: on
branching versus linear time temporal logic. Journal of the ACM, 33(1):151–178,
1986.
[141] E. A. Emerson and C. S. Jutla. The complexity of tree automata and logics
of programs (extended abstract).
In 29th Annual Symposium on Foundations of
Computer Science (FOCS), pages 328–337. IEEE Computer Society Press, 1988.
[142] E. A. Emerson and C.-L. Lei. Temporal reasoning under generalized fairness
constraints. In 3rd Annual Symposium on Theoretical Aspects of Computer Science
(STACS), volume 210 of Lecture Notes in Computer Science, pages 21–36. Springer-
Verlag, 1986.
[143] E. A. Emerson and C.-L. Lei. Modalities for model checking: branching time
logic strikes back. Science of Computer Programming, 8(3):275–306, 1987.
[144] J. Engelfriet. Branching processes of Petri nets. Acta Informatica, 28(6):575–591,
1991.
[145] J. Esparza. Model checking using net unfoldings. Science of Computer Program-
ming, 23(2–3):151–195, 1994.
[146] K. Etessami. Stutter-invariant languages, omega-automata, and temporal logic. In
11th International Conference on Computer Aided Veriﬁcation (CAV), volume 1633
of Lecture Notes in Computer Science, pages 236–248. Springer-Verlag, 1999.
[147] K. Etessami. A note on a question of Peled and Wilke regarding stutter-invariant
LTL. Information Processing Letters, 75(6):261–263, 2000.
[148] K. Etessami and G. Holzmann. Optimizing B¨uchi automata. In 11th Inter-
national Conference on Concurrency Theory (CONCUR), volume 1877 of Lecture
Notes in Computer Science, pages 153–165. Springer-Verlag, 2000.
[149] K. Etessami and T. Wilke and R. Schuller. Fair simulation relations, parity
games, and state space reduction for B¨uchi automata. SIAM Journal of Computing,
34(5):1159–1175, 2005.
[150] W. Feller. An Introduction to Probability Theory and Its Applications, volumes 1
and 2. John Wiley & Sons, 2001.
[151] C. Fencott. Formal Methods for Concurrency. Thomson Computer Press, 1995.
[152] K. Fisler and M. Y. Vardi. Bisimulation minimization in an automata-theoretic
veriﬁcation framework.
In 2nd International Conference on Formal Methods in
Computer-Aided Design (FMCAD), volume 1522 of Lecture Notes in Computer Sci-
ence, pages 115–132. Springer-Verlag, 1998.

944
BIBLIOGRAPHY
[153] K. Fisler and M. Y. Vardi. Bisimulation and model checking. In 10th IFIP WG
10.5 Advanced Research Working Conference on Correct Hardware Design and Ver-
iﬁcation Methods (CHARME), volume 1703 of Lecture Notes in Computer Science,
pages 338–341. Springer-Verlag, 1999.
[154] K. Fisler and M. Y. Vardi.
Bisimulation minimization and symbolic model
checking. Formal Methods in System Design, 21(1):39–78, 2002.
[155] N. Francez. Fairness. Springer-Verlag, 1986.
[156] L.-A. Fredlund.
The timing and probability workbench: a tool for analysing
timed processes. Technical Report 49, Uppsala University, 1994.
[157] C. Fritz and T. Wilke. State space reductions for alternating B¨uchi automata. In
22th Conference on Foundations of Software Technology and Theoretical Computer
Science (FSTTCS), volume 2556 of Lecture Notes in Computer Science, pages 157–
168. Springer-Verlag, 2002.
[158] D. Gabbay and I. Hodkinson and M. Reynolds. Temporal Logic: Mathematical
Foundations and Computational Aspects, volume 1. Oxford University Press, 1994.
[159] D. Gabbay and A. Pnueli and S. Shelah and J. Stavi. On the temporal basis
of fairness. In 7th Symposium on Principles of Programming Languages (POPL),
pages 163–173. ACM Press, 1980.
[160] M. Garey and D. Johnson. Computers and Intractability: A Guide to the Theory
of NP-Completeness. W. H. Freeman and Company, 1979.
[161] P. Gastin and P. Moro and M. Zeitoun. Minimization of counterexamples in
SPIN. In 11th International SPIN Workshop on Model Checking of Software, volume
2989 of Lecture Notes in Computer Science, pages 92–108. Springer-Verlag, 2004.
[162] P. Gastin and D. Oddoux. Fast LTL to B¨uchi automata translation. In Thir-
teenth International Conference on Computer Aided Veriﬁcation (CAV), volume
2102 of Lecture Notes in Computer Science, pages 53–65. Springer-Verlag, 2001.
[163] J. Geldenhuys and A. Valmari. More eﬃcient on-the-ﬂy LTL veriﬁcation with
Tarjan’s algorithm. Theoretical Computer Science, 345(1):60–82, 2005.
[164] R. Gerth. Transition logic: how to reason about temporal properties in a compo-
sitional way. In 16th Annual ACM Symposium on Theory of Computing (STOC),
pages 39–50. ACM Press, 1984.
[165] R. Gerth and R. Kuiper and D. Peled and W. Penczek. A partial order
approach to branching time logic model checking. In 3rd Israel Symposium on the
Theory of Computing Systems (ISTCS), pages 130–139. IEEE Computer Society
Press, 1995.

BIBLIOGRAPHY
945
[166] R. Gerth and D. Peled and M. Y. Vardi and P. Wolper. Simple on-the-ﬂy
automatic veriﬁcation of linear temporal logic. In Protocol Speciﬁcation Testing and
Veriﬁcation, pages 3–18. Chapman & Hall, 1995.
[167] D. Giannakopoulou and F. Lerda. From states to transitions: improving trans-
lation of LTL formulae to B¨uchi automata. In 22nd IFIP International Conference
on Formal Techniques for Networked and Distributed Systems, volume 2529 of Lec-
ture Notes in Computer Science, pages 308–326. Springer-Verlag, 2002.
[168] P. Godefroid. Using partial orders to improve automatic veriﬁcation methods. In
2nd International Workshop on Computer Aided Veriﬁcation (CAV), volume 531 of
Lecture Notes in Computer Science, pages 176–185. Springer-Verlag, 1990.
[169] P. Godefroid. Partial Order Methods for the Veriﬁcation of Concurrent Systems:
An Approach to the State Explosion Problem, volume 1032 of Lecture Notes in Com-
puter Science. Springer-Verlag, 1996.
[170] P. Godefroid.
Model checking for programming languages using Verisoft.
In
24th Annual Symposium on Principles of Programming Languages (POPL), pages
174–186. ACM Press, 1997.
[171] P. Godefroid and D. Pirottin. Reﬁning dependencies improves partial-order
veriﬁcation methods. In 5nd International Workshop on Computer Aided Veriﬁ-
cation (CAV), volume 697 of Lecture Notes in Computer Science, pages 438–449.
Springer-Verlag, 1993.
[172] P. Godefroid and P. Wolper. Using partial orders for the eﬃcient veriﬁcation
of deadlock freedom and safety properties.
Formal Methods in Systems Design,
2(2):149–164, 1993.
[173] R. Gotzhein. Temporal logic and applications: a tutorial. Computer Networks and
ISDN Systems, 24(3):203–218, 1992.
[174] E. Gr¨adel and W. Thomas and T. Wilke (editors). Automata Logics, and
Inﬁnite Games: A Guide to Current Research, volume 2500 of Lecture Notes in
Computer Science. Springer-Verlag, 2002.
[175] W. D. Griffioen and F. Vaandrager. A theory of normed simulations. ACM
Transactions on Computational Logic, 5(4):577–610, 2004.
[176] J. F. Groote and F. Vaandrager. An eﬃcient algorithm for branching bisim-
ulation and stuttering equivalence. In 17th International Colloquium on Automata,
Languages and Programming (ICALP), volume 443 of Lecture Notes in Computer
Science, pages 531–540. Springer-Verlag, 1990.

946
BIBLIOGRAPHY
[177] J. F. Groote and J. van de Pol.
State space reduction using partial tau-
conﬂuence. In 25th International Symposium on Mathematical Foundations of Com-
puter Science (MFCS), volume 1893 of Lecture Notes in Computer Science, pages
383–393. Springer-Verlag, 2000.
[178] H. Gumm. Another glance at the Alpern-Schneider characterization of safety and
liveness in concurrent executions. Information Processing Letters, 47(6):291–294,
1993.
[179] A. Gupta. Formal hardware veriﬁcation methods: a survey. Formal Methods in
System Design, 1(2–3):151–238, 1992.
[180] G. Hachtel and F. Somenzi. Logic Synthesis and Veriﬁcation Algorithms. Kluwer
Academic Publishers, 1996.
[181] G. D. Hachtel and E. Macii and A. Pardo and F. Somenzi. Markovian
analysis of large ﬁnite-state machines. IEEE Transactions on CAD of Integrated
Circuits and Systems, 15(12):1479–1493, 1996.
[182] J. Hajek.
Automatically veriﬁed data transfer protocols.
In 4th International
Conference on Computer Communication (ICCC), pages 749–756. IEEE Computer
Society Press, 1978.
[183] N. Halbwachs. Synchronous Programming of Reactive Systems. Kluwer Academic
Publishers, 1992.
[184] M. Hammer and A. Knapp and S. Merz. Truly on-the-ﬂy LTL model checking.
In 11th International Conference on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS), volume 3440 of Lecture Notes in Computer Science,
pages 191–205. Springer-Verlag, 2005.
[185] T. Han and J.-P. Katoen. Counterexamples in probabilistic model checking.
In Thirteenth International Conference on Tools and Algorithms for the Construc-
tion and Analysis of Systems (TACAS), volume 4424 of Lecture Notes in Computer
Science, pages 72–86. Springer-Verlag, 2007.
[186] H. Hansson. Time and Probability in Formal Design of Distributed Systems. Series
in Real-Time Safety Critical Systems. Elsevier Publishers B.V., 1994.
[187] H. Hansson and B. Jonsson. A logic for reasoning about time and reliability.
Formal Aspects of Computing, 6(5):512–535, 1994.
[188] F. Harary. Graph Theory. Addison-Wesley, 1969.
[189] D. Harel. Statecharts: a visual formalism for complex systems. Science of Com-
puter Programming, 8(3):231–274, 1987.

BIBLIOGRAPHY
947
[190] S. Hart and M. Sharir. Probabilistic propositional temporal logics. Information
and Control, 70(2–3):97–155, 1986.
[191] S. Hart and M. Sharir and A. Pnueli. Termination of probabilistic concurrent
programs. ACM Transactions on Programming Languages and Systems, 5(3):356–
380, 1983.
[192] V. Hartonas-Garmhausen and S. Campos and E. M. Clarke. ProbVerus:
probabilistic symbolic model checking. In 5th International AMAST Workshop on
Formal Methods for Real-Time and Probabilistic Systems (ARTS), volume 1601 of
Lecture Notes in Computer Science, pages 96–110. Springer-Verlag, 1999.
[193] J. Hatcliff and M. Dwyer. Using the Bandera tool set to model-check properties
of concurrent Java software. In 12th International Conference on Concurrency The-
ory (CONCUR), volume 2154 of Lecture Notes in Computer Science, pages 39–58.
Springer-Verlag, 2001.
[194] K. Havelund and M. Lowry and J. Penix. Formal analysis of a space-craft
controller using SPIN. IEEE Transactions on Software Engineering, 27(8):749–765,
2001.
[195] K. Havelund and T. Pressburger.
Model checking Java programs using
Java Pathﬁnder. International Journal on Software Tools for Technology Transfer,
2(4):366–381, 2000.
[196] B. R. Haverkort. Performance of Computer Communication Systems: A Model-
Based Approach. John Wiley & Sons, 1998.
[197] M. Hennessy and R. Milner. Algebraic laws for nondeterminism and concur-
rency. Journal of the ACM, 32(1):137–161, 1985.
[198] M. R. Henzinger and T. A. Henzinger and P. W. Kopke. Computing simu-
lations on ﬁnite and inﬁnite graphs. In 36th Annual Symposium on Foundations of
Computer Science (FOCS), pages 453–462. IEEE Computer Society Press, 1995.
[199] T. Henzinger and R. Majumdar and J.-F. Raskin. A classiﬁcation of symbolic
transition systems. ACM Transactions on Computational Logic, 6(1):1–32, 2005.
[200] T. A. Henzinger and X. Nicollin and J. Sifakis and S. Yovine. Symbolic
model checking for real-time systems. Information and Computation, 111(2):193–
244, 1994.
[201] H. Hermanns and J.-P. Katoen and J. Meyer-Kayser and M. Siegle. A
tool for model-checking Markov chains. International Journal on Software Tools for
Technology Transfer, 4(2):153–172, 2003.

948
BIBLIOGRAPHY
[202] C. A. R. Hoare. Communicating sequential processes. Communications of the
ACM, 21(8):666–677, 1978.
[203] C. A. R. Hoare. Communicating Sequential Processes. Prentice-Hall, 1985.
[204] R. Hojati and R. K. Brayton and R. P. Kurshan. BDD-based debugging of
designs using language containment and fair CTL. In 5th International Conference
on Computer Aided Veriﬁcation (CAV), volume 697 of Lecture Notes in Computer
Science, pages 41–58. Springer-Verlag, 1993.
[205] G. J. Holzmann. Design and Validation of Computer Protocols. Prentice-Hall,
1990.
[206] G. J. Holzmann. Design and validation of protocols: a tutorial. Computer Net-
works and ISDN Systems, 25(9):981–1017, 1993.
[207] G. J. Holzmann. The theory and practice of a formal method: NewCoRe. In IFIP
World Congress, pages 35–44. North Holland, 1994.
[208] G. J. Holzmann. The model checker SPIN. IEEE Transactions on Software En-
gineering, 23(5):279–295, 1997.
[209] G. J. Holzmann.
The SPIN Model Checker:
Primer and Reference Manual.
Addison-Wesley, 2003.
[210] G. J. Holzmann and E. Najm and A. Serhrouchini. SPIN model checking:
an introduction. International Journal on Software Tools for Technology Transfer,
2(4):321–327, 2000.
[211] G. J. Holzmann and D. Peled. An improvement in formal veriﬁcation. In 7th
IFIP WG6.1 International Conference on Formal Description Techniques (FORTE),
pages 197–211. Chapman & Hall, 1994.
[212] G. J. Holzmann and D. Peled and M. Yannakakis. On nested depth-ﬁrst
search. In 2nd International SPIN workshop on Model Checking of Software, pages
23–32. AMS Press, 1996.
[213] J. E. Hopcroft. An n log n algorithm for minimizing the states in a ﬁnite au-
tomaton. In Z. Kohavi, editor, The Theory of Machines and Computations, pages
189–196. Academic Press, 1971.
[214] J. E. Hopcroft and R. Motwani and J. Ullman. Introduction to Automata
Theory, Languages and Computation. Addison-Wesley, 2001.
[215] R. A. Howard. Dynamic Programming and Markov Processes. MIT Press, 1960.

BIBLIOGRAPHY
949
[216] R. A. Howard. Dynamic Probabilistic Systems, volume 2: Semi-Markov and De-
cision Processes. John Wiley & Sons, 1972.
[217] D. A. Huffman. The synthesis of sequential switching circuits. Journal of the
Franklin Institute, 257(3–4):161–190, 275–303, 1954.
[218] M. Huhn and P. Niebert and H. Wehrheim. Partial order reductions for bisim-
ulation checking. In 18th Conference on Foundations of Software Technology and
Theoretical Computer Science (FSTTCS), volume 1530 of Lecture Notes in Com-
puter Science, pages 271–282. Springer-Verlag, 1998.
[219] M. Huth and M. D. Ryan. Logic in Computer Science – Modelling and Reasoning
about Systems. Cambridge University Press, 1999.
[220] T. Huynh and L. Tian. On some equivalence relations for probabilistic processes.
Fundamenta Informaticae, 17(3):211–234, 1992.
[221] H. Hyman. Comments on a problem in concurrent programming control. Commu-
nications of the ACM, 9(1):45, 1966.
[222] ISO/ITU-T. Formal Methods in Conformance Testing. International Standard,
1996.
[223] A. Itai and M. Rodeh. Symmetry breaking in distributed networks. Information
and Computation, 88(1):60–87, 1990.
[224] H. Iwashita and T. Nakata and F. Hirose. CTL model checking based on
forward state traversal.
In International Conference on Computer-Aided Design
(ICCAD), pages 82–87. IEEE Computer Society Press, 1996.
[225] W. Janssen and J. Zwiers. Specifying and proving communication closedness in
protocols. In Thirteenth IFIP WG6.1 International Symposium on Protocol Speciﬁ-
cation, Testing and Veriﬁcation, pages 323–339. North Holland, 1993.
[226] B. Jeannet and P. R. D’Argenio and K. G. Larsen.
RAPTURE: a tool
for verifying Markov decision processes. In Tools Day, International Conference on
Concurrency Theory (CONCUR), 2002.
[227] B. Jonsson and K. G. Larsen.
Speciﬁcation and reﬁnement of probabilistic
processes. In 6th Annual IEEE Symposium on Logic in Computer Science (LICS),
pages 266–277. IEEE Computer Society Press, 1991.
[228] B. Jonsson and W. Yi and K. G. Larsen. Probabilistic extensions of process
algebras. In J. Bergstra, A. Ponse, and S.A. Smolka, editors, Handbook of Process
Algebra, chapter 11, pages 685–711. Elsevier Publishers B.V., 2001.

950
BIBLIOGRAPHY
[229] M. Kaminski. A classiﬁcation of omega-regular languages. Theoretical Computer
Science, 36:217–229, 1985.
[230] J. A. W. Kamp. Tense Logic and the Theory of Linear Order. PhD thesis, Univer-
sity of California, Los Angeles, 1968.
[231] P. Kanellakis and S. Smolka. CCS expressions, ﬁnite state processes, and three
problems of equivalence. Information and Computation, 86(1):43–68, 1990.
[232] J.-P. Katoen and T. Kemna and I. S. Zapreev and D. N. Jansen. Bisim-
ulation minimisation mostly speeds up probabilistic model checking. In Thirteenth
International Conference on Tools and Algorithms for the Construction and Analy-
sis of Systems (TACAS), volume 4424 of Lecture Notes in Computer Science, pages
87–102. Springer-Verlag, 2007.
[233] J.-P. Katoen and M. Khattri and I. S. Zapreev. A Markov reward model
checker.
In 2nd International Conference on Quantitative Evaluation of Systems
(QEST), pages 243–244. IEEE Computer Society Press, 2005.
[234] S. Katz and D. Peled. Deﬁning conditional independence using collapses. Theo-
retical Computer Science, 101(2):337–359, 1992.
[235] S. Katz and D. Peled. Veriﬁcation of distributed programs using representative
interleaving sequences. Distributed Computing, 6(2):107–120, 1992.
[236] R. M. Keller. Formal veriﬁcation of parallel programs. Communications of the
ACM, 19(7):371–384, 1976.
[237] J. Kemeny and J. Snell. Finite Markov Chains. D. Van Nostrand, 1960.
[238] J. Kemeny and J. Snell. Denumerable Markov Chains. D. Van Nostrand, 1976.
[239] E. Kindler. Safety and liveness properties: a survey. Bulletin of the European
Association for Theoretical Computer Science, 53:268–272, 1994.
[240] S. C. Kleene. Representation of events in nerve nets and ﬁnite automata.
In
C. Shannon and J. McCarthy, editors, Automata Studies, pages 3–42. Princeton
University Press, 1956.
[241] J. Klein and C. Baier. Experiments with deterministic ω-automata for formulas
of linear temporal logic. Theoretical Computer Science, 363(2):182–195, 2006.
[242] D. E. Knuth and A. C. Yao. The complexity of nonuniform random number
generation. In J.E. Traub, editor, Algorithms and Complexity: New Directions and
Recent Results, pages 357–428. Academic Press, New York, 1976.

BIBLIOGRAPHY
951
[243] D. Kozen. Results on the propositional μ-calculus. Theoretical Computer Science,
27:333–354, 1983.
[244] S. A. Kripke. Semantical considerations on modal logic. Acta Philosophica Fennica,
16:83–94, 1963.
[245] F. Kr¨oger. Temporal Logic of Programs, volume 8 of Springer Monographs on
Theoretical Computer Science. Springer-Verlag, 1987.
[246] T. Kropf. Introduction to Formal Hardware Veriﬁcation. Springer-Verlag, 1999.
[247] A. Kucera and P. Schnoebelen. A general approach to comparing inﬁnite-
state systems with their ﬁnite-state speciﬁcations. Theoretical Computer Science,
358(2-3):315–333, 2006.
[248] V. Kulkarni. Modeling and Analysis of Stochastic Systems. Chapman & Hall,
1995.
[249] O. Kupferman and M.Y. Vardi. Model checking of safety properties. Formal
Methods in System Design, 19(3):291–314, 2001.
[250] R. Kurshan.
Computer-aided Veriﬁcation of Coordinating Processes:
The
Automata-Theoretic Approach. Princeton University Press, 1994.
[251] R. Kurshan and V. Levin and M. Minea and D. Peled and H. Yenig¨un.
Combining software and hardware veriﬁcation techniques. Formal Methods in System
Design, 21(3):251–280, 2002.
[252] M. Kwiatkowska. Survey of fairness notions. Information and Software Technol-
ogy, 31(7):371–386, 1989.
[253] M. Kwiatkowska. A metric for traces. Information Processing Letters, 35(3):129–
135, 1990.
[254] M. Kwiatkowska and G. Norman and D. Parker. Modelling and veriﬁcation
of probabilistic systems.
In P. Panangaden and F. van Breugel, editors, Part 2
of Mathematical Techniques for Analyzing Concurrent and Probabilistic Systems,
volume 23 of CRM Monograph Series. AMS Press, 2004.
[255] M. Kwiatkowska and G. Norman and D. Parker.
Probabilistic symbolic
model checking with PRISM: A hybrid approach. International Journal on Software
Tools for Technology Transfer, 6(2):128–142, 2004.
[256] L. Lamport. A new solution of Dijkstra’s concurrent programming problem. Com-
munications of the ACM, 17(8):453–455, 1974.

952
BIBLIOGRAPHY
[257] L. Lamport. Proving the correctness of multiprocess programs. IEEE Transactions
on Software Engineering, 3(2):125–143, 1977.
[258] L. Lamport. Time, clocks and the ordering of events in distributed systems. Com-
munication of the ACM, 21(7):558–565, 1978.
[259] L. Lamport. “Sometime” is sometimes “not never” – on the temporal logic of pro-
grams. In 7th Annual Symposium on Principles of Programming Languages (POPL),
pages 174–185. ACM Press, 1980.
[260] L. Lamport. The temporal logic of actions. ACM Transactions on Programming
Languages and Systems, 16(3):872–923, 1994.
[261] L. H. Landweber. Decision problems for omega-automata. Mathematical Systems
Theory, 3(4):376–384, 1969.
[262] F. Laroussinie and N. Markay and Ph. Schnoebelen. Temporal logic with
forgettable past. In 17th IEEE Symposium on Logic in Computer Science (LICS),
pages 383–392. IEEE Computer Society Press, 2002.
[263] K. G. Larsen and J. Pearson and C. Weise and W. Yi. Clock diﬀerence
diagrams. Nordic Journal of Computing, 6(3):271–298, 1999.
[264] K. G. Larsen and A. Skou. Bisimulation through probabilistic testing. Informa-
tion and Computation, 94(1):1–28, 1991.
[265] K. G. Larsen and W. Yi. Time-abstracted bisimulation: implicit speciﬁcation and
decidability. In 9th International Conference on the Mathematical Foundations of
Programming Semantics (MFPS), volume 802 of Lecture Notes in Computer Science,
pages 160–176. Springer-Verlag, 1993.
[266] D. Lee and M. Yannakakis. Online minimization of transition systems. In 24th
Annual ACM Symposium on Theory of Computing (STOC), pages 264–274. ACM
Press, 1992.
[267] D. Lehmann and A. Pnueli and J. Stavi. Impartiality, justice and fairness: the
ethics of concurrent termination. In 8th Colloquium on Automata, Languages and
Programming (ICALP), volume 115 of Lecture Notes in Computer Science, pages
264–277. Springer-Verlag, 1981.
[268] D. Lehmann and M. Rabin.
On the advantages of free choice: a symmetric
and fully distributed solution to the dining philosophers problem.
In 8th ACM
Symposium on Principles of Programming Languages (POPL), pages 133–138. ACM
Press, 1981.
[269] N. Leveson. Safeware: System Safety and Computers. ACM Press, 1995.

BIBLIOGRAPHY
953
[270] C. Lewis. Implication and the algebra of logic. Mind, N. S., 12(84):522–531, 1912.
[271] H. R. Lewis. A logic of concrete time intervals (extended abstract). In 5th An-
nual IEEE Symposium on Logic in Computer Science (LICS), pages 380–389. IEEE
Computer Society Press, 1990.
[272] H. R. Lewis and C. H. Papadimitriou. Elements of the Theory of Computation.
Prentice-Hall, 1997.
[273] O. Lichtenstein and A. Pnueli. Checking that ﬁnite-state concurrent programs
satisfy their linear speciﬁcation. In 12th Annual ACM Symposium on Principles of
Programming Languages (POPL), pages 97–107. ACM Press, 1985.
[274] O. Lichtenstein and A. Pnueli and L. Zuck.
The glory of the past.
In
Conference on Logic of Programs, volume 193 of Lecture Notes in Computer Science,
pages 196–218. Springer-Verlag, 1985.
[275] P. Liggesmeyer and M. Rothfelder and M. Rettelbach and T. Ack-
ermann.
Qualit¨atssicherung Software-basierter technischer Systeme.
Informatik
Spektrum, 21(5):249–258, 1998.
[276] R. Lipton. Reduction: a method of proving properties of parallel programs. Com-
munications of the ACM, 18(12):717–721, 1975.
[277] C. Loiseaux and S. Graf and J. Sifakis and A. Bouajjani and S. Bensalem.
Property preserving abstractions for the veriﬁcation of concurrent systems. Formal
Methods in System Design, 6(1):11–44, 1995.
[278] G. Lowe. Breaking and ﬁxing the Needham-Schroeder public-key protocol using
FDR. Software Concepts and Tools, 17(3):93–102, 1996.
[279] N. Lynch and F. Vaandrager.
Forward and backward simulations – part I:
untimed systems. Information and Computation, 121(2):214–233, 1993.
[280] N. A. Lynch. Distributed Algorithms. Morgan Kaufmann Publishers, 1996.
[281] O. Maler and Z. Manna and A. Pnueli. From timed to hybrid systems. In
Real-Time: Theory in Practice, REX Workshop, volume 600 of Lecture Notes in
Computer Science, pages 447–484. Springer-Verlag, 1992.
[282] Z. Manna and A. Pnueli. Completing the temporal picture. Theoretical Computer
Science, 83(1):97–130, 1991.
[283] Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Sys-
tems: Speciﬁcation. Springer-Verlag, 1992.

954
BIBLIOGRAPHY
[284] Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Sys-
tems: Safety. Springer-Verlag, 1995.
[285] P. Manolios and R. Trefler. Safety and liveness in branching time. In 16th
Annual IEEE Symposium on Logic in Computer Science (LICS), pages 366–372.
IEEE Computer Society Press, 2001.
[286] P. Manolios and R. J. Trefler. A lattice-theoretic characterization of safety
and liveness. In 22nd Annual Symposium on Principles of Distributed Computing
(PODC), pages 325–333. IEEE Computer Society Press, 2003.
[287] A. Mazurkiewicz. Trace theory. In Advances in Petri Nets, volume 255 of Lecture
Notes in Computer Science, pages 279–324. Springer-Verlag, 1987.
[288] K. L. McMillan. Symbolic Model Checking. Kluwer Academic Publishers, 1993.
[289] K. L. McMillan. A technique of state space search based on unfoldings. Formal
Methods in System Design, 6(1):45–65, 1995.
[290] R. McNaughton. Testing and generating inﬁnite sequences by a ﬁnite automaton.
Information and Control, 9(5):521–530, 1966.
[291] G. H. Mealy. A method for synthesizing sequential circuits. Bell System Technical
Journal, 34:1045–1079, 1955.
[292] C. Meinel and T. Theobald. Algorithms and Data Structures in VLSI Design.
Springer-Verlag, 1998.
[293] S. Merz. Model checking: a tutorial. In F. Cassez, C. Jard, B. Rozoy, and M.D.
Ryan, editors, Modelling and Veriﬁcation of Parallel Processes, volume 2067 of Lec-
ture Notes in Computer Science, pages 3–38. Springer-Verlag, 2001.
[294] S. Merz and N. Navet (editors). Modeling and Veriﬁcation of Real-Time Sys-
tems: Formalisms and Software Tools. ISTE Ltd, 2008.
[295] R. Milner. An algebraic deﬁnition of simulation between programs. In 2nd Interna-
tional Joint Conference on Artiﬁcial Intelligence, pages 481–489. William Kaufmann,
1971.
[296] R. Milner. A Calculus of Communicating Systems, volume 92 of Lecture Notes in
Computer Science. Springer-Verlag, 1980.
[297] R. Milner. Calculi for synchrony and asynchrony. Theoretical Computer Science,
25(3):267–310, 1983.
[298] R. Milner. Communication and Concurrency. Prentice-Hall, 1989.

BIBLIOGRAPHY
955
[299] R. Milner. Communicating and Mobile Systems: The Pi-Calculus. Cambridge
University Press, 1999.
[300] S. Minato. Binary Decision Diagrams and Applications for VLSI CAD. Kluwer
Academic Publishers, 1996.
[301] S. Minato and N. Ishiura and S. Yajima. Shared binary decision diagram with
attributed edges for eﬃcient boolean function manipulation. In 27th ACM/IEEE
Conference on Design Automation (DAC), pages 52–57. ACM Press, 1991.
[302] F. Moller and S. A. Smolka. On the computational complexity of bisimulation.
ACM Computing Surveys, 27(2):287–289, 1995.
[303] E. F. Moore. Gedanken-experiments on sequential machines. Automata Studies,
34:129–153, 1956.
[304] C. Morgan and A. McIver. pGCL: Formal reasoning for random algorithms.
South African Computer Journal, 22:14–27, 1999.
[305] A. W. Mostowski. Regular expressions for inﬁnite trees and a standard form
of automata. In 5th Symposium on Computational Theory, volume 208 of Lecture
Notes in Computer Science, pages 157–168. Springer-Verlag, 1984.
[306] R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge University
Press, 1995.
[307] D. E. Muller. Inﬁnite sequences and ﬁnite machines. In 4th IEEE Symposium on
Switching Circuit Theory and Logical Design, pages 3–16. IEEE, 1963.
[308] G. J. Myers. The Art of Software Testing. John Wiley & Sons, 1979.
[309] J. Myhill. Finite automata and the representation of events. Technical Report
WADD TR-57-624, Wright Patterson Air Force Base, OH, 1957.
[310] R. Nalumasu and G. Gopalakrishnan. A new partial order reduction algorithm
for concurrent systems. In Thirteenth IFIP International Conference on Hardware
Description Languages and their Applications (CHDL), pages 305–314. Chapman &
Hall, 1997.
[311] K. S. Namjoshi.
A simple characterization of stuttering bisimulation.
In 17th
Conference on Foundations of Software Technology and Theoretical Computer Sci-
ence (FSTTCS), volume 1346 of Lecture Notes in Computer Science, pages 284–296.
Springer-Verlag, 1997.
[312] G. Naumovich and L. A. Clarke.
Classifying properties: an alternative to
the safety-liveness classiﬁcation.
ACM SIGSOFT Software Engineering Notes,
25(6):159–168, 2000.

956
BIBLIOGRAPHY
[313] A. Nerode. Linear automaton transformations. In Proceedings of the American
Mathematical Society, volume 9, pages 541–544, 1958.
[314] R. De Nicola and F. Vaandrager.
Three logics for branching bisimulation
(extended abstract). In 5th Annual IEEE Symposium on Logic in Computer Science
(LICS), pages 118–129. IEEE Computer Society Press, Springer-Verlag, 1990.
[315] X. Nicollin and J.-L. Richier and J. Sifakis and J. Voiron. ATP: an algebra
for timed processes. In IFIP TC2 Working Conference on Programming Concepts
and Methods, pages 402–427. North Holland, 1990.
[316] A. Olivero and J. Sifakis and S. Yovine. Using abstractions for the veriﬁca-
tion of linear hybrid systems. In 6th International Conference on Computer Aided
Veriﬁcation (CAV), volume 818 of Lecture Notes in Computer Science, pages 81–94.
Springer-Verlag, 1994.
[317] S. Owicki. Verifying concurrent programs with shared data classes. In IFIP Work-
ing Conference on Formal Description of Programming Concepts, pages 279–298.
North Holland, 1978.
[318] R. Paige and R. E. Tarjan. Three partition reﬁnement algorithms. SIAM Journal
on Computing, 16(6):973–989, 1987.
[319] P. Panangaden. Measure and probability for concurrency theorists. Theoretical
Computer Science, 253(2):287–309, 2001.
[320] C. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[321] D. Park. On the semantics of fair parallelism. In Abstract Software Speciﬁcation,
volume 86 of Lecture Notes in Computer Science, pages 504–526. Springer-Verlag,
1979.
[322] D. Park. Concurrency and automata on inﬁnite sequences. In 5th GI-Conference
on Theoretical Computer Science, volume 104 of Lecture Notes in Computer Science,
pages 167–183. Springer-Verlag, 1981.
[323] D. Parker. Implementation of Symbolic Model Checking for Probabilistic Systems.
PhD thesis, University of Birmingham, UK, 2002.
[324] D. Peled. All from one, one for all: On model checking using representatives. In
5th International Conference on Computer Aided Veriﬁcation (CAV), volume 697 of
Lecture Notes in Computer Science, pages 409–423. Springer-Verlag, 1993.
[325] D. Peled.
Combining partial order reductions with on-the-ﬂy model checking.
Formal Methods in System Design, 8(1):39–64, 1996.

BIBLIOGRAPHY
957
[326] D. Peled.
Partial order reduction: Linear and branching temporal logics and
process algebras. In Partial Order Methods in Veriﬁcation [328], pages 79–88.
[327] D. Peled. Software Reliability Methods. Springer-Verlag, 2001.
[328] D. Peled and V. Pratt and G. J. Holzmann (editors). Partial Order Methods
in Veriﬁcation, volume 29 (10) of DIMACS Series in Discrete Mathematics and
Theoretical Computer Science. AMS Press, 1997.
[329] D. Peled and T. Wilke. Stutter-invariant temporal properties are expressible
without the next-time operator.
Information Processing Letters, 63(5):243–246,
1997.
[330] W. Penczek and R. Gerth and R. Kuiper and M. Szreter. Partial order
reductions preserving simulations. In 8th Workshop on Concurrency, Speciﬁcation
and Programming (CS&P), pages 153–172. Warsaw University Press, 1999.
[331] G. Della Penna and B. Intrigila and I. Melatti and E. Tronci and M.
Venturini Zilli. Finite horizon analysis of Markov chains with the Murphi veriﬁer.
Journal on Software Tools and Technology Transfer, 8(4-5):397–409, 2006.
[332] G. L. Peterson. Myths about the mutual exclusion problem. Information Pro-
cessing Letters, 12(3):15–116, 1981.
[333] J. L. Peterson. Petri Net Theory and the Modeling of Systems. Prentice-Hall,
1981.
[334] G. D. Plotkin. A structural approach to operational semantics. Technical Report
DAIMI FN-19, Aarhus University, 1981.
[335] G. D. Plotkin. The origins of structural operational semantics. Journal of Logic
and Algebraic Programming, 60–61:3–15, 2005.
[336] G. D. Plotkin. A structural approach to operational semantics. Journal of Logic
and Algebraic Programming, 60–61:17–139, 2005.
[337] A. Pnueli. The temporal logic of programs. In 18th IEEE Symposium on Foun-
dations of Computer Science (FOCS), pages 46–67. IEEE Computer Society Press,
1977.
[338] A. Pnueli. Linear and branching structures in the semantics and logics of reactive
systems. In 12th International Colloquium on Automata, Languages and Program-
ming (ICALP), volume 194 of Lecture Notes in Computer Science, pages 15–32.
Springer-Verlag, 1985.

958
BIBLIOGRAPHY
[339] A. Pnueli. Applications of temporal logic to the speciﬁcation and veriﬁcation of
reactive systems: a survey of current trends. In Advanced School on Current Trends
in Concurrency Theorey, volume 244 of Lecture Notes in Computer Science, pages
510–584. Springer-Verlag, 1986.
[340] A. Pnueli and L. Zuck. Probabilistic veriﬁcation by tableaux. In 1st Annual
Symposium on Logic in Computer Science (LICS), pages 322–331. IEEE Computer
Society Press, 1986.
[341] A. Pnueli and L. Zuck. Probabilistic veriﬁcation. Information and Computation,
103(1):1–29, 1993.
[342] H. Pospesel. Introduction to Logic: Propositional Logic. Prentice-Hall, 1979.
[343] V. Pratt. Modelling concurrency with partial orders. International Journal of
Parallel Programming, 15(1):33–71, 1986.
[344] W. Press and S. A. Teukolsky and W. T. Vetterling and B. P. Flannery.
Numerical Recipes in C++. The Art of Scientiﬁc Computing. Cambridge University
Press, 2002.
[345] A. Prior. Time and Modality. Oxford University Press, 1957.
[346] M. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Program-
ming. John Wiley & Sons, 1994.
[347] J.-P. Queille and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent systems
in CESAR. In 5th International Symposium on Programming, volume 137 of Lecture
Notes in Computer Science, pages 337–351. Springer-Verlag, 1982.
[348] J.-P. Queille and J. Sifakis. Fairness and related properties in transition sys-
tems. a temporal logic to deal with fairness. Acta Informatica, 19(3):195–220, 1983.
[349] M. O. Rabin. Probabilistic algorithms. In J. F. Traub, editor, Algorithms and
Complexity: New Directions and Recent Results, pages 21–39. Academic Press, 1976.
[350] M. O. Rabin and D. Scott. Finite automata and their decision problems. IBM
Journal of Research and Development, 3(2):114–125, 1959.
[351] M.O. Rabin. Decidability of second order theories and automata on inﬁnite trees.
Transactions of the AMS, 141:1–35, 1969.
[352] Y. Ramakrishna and S. Smolka. Partial-order reduction in the weak modal
mu-calculus. In 8th International Conference on Concurrency Theory (CONCUR),
volume 1243 of Lecture Notes in Computer Science, pages 5–24. Springer-Verlag,
1997.

BIBLIOGRAPHY
959
[353] J. I. Rasmussen and K. G. Larsen and K. Subramani.
On using priced
timed automata to achieve optimal scheduling. Formal Methods in System Design,
29(1):97–114, 2006.
[354] M. Rem. Trace theory and systolic computations. In Parallel Architectures and
Languages Europe (PARLE), volume 1, volume 258 of Lecture Notes in Computer
Science, pages 14–33. Springer-Verlag, 1987.
[355] M. Rem. A personal perspective of the Alpern-Schneider characterization of safety
and liveness. In W. H. J. Feijen, A. J. M. van Gasteren, D. Gries, and J. Misra, edi-
tors, Beauty is Our Business: A Birthday Salute to Edsger W. Dijkstra, chapter 43,
pages 365–372. Springer-Verlag, 1990.
[356] A. W. Roscoe. Model-checking CSP. In A. W. Roscoe, editor, A Classical Mind:
Essays in Honour of C. A. R. Hoare, pages 353–378. Prentice-Hall, 1994.
[357] G. Rozenberg and V. Diekert. The Book of Traces. World Scientiﬁc Publishing
Co., Inc., 1995.
[358] R. Rudell. Dynamic variable ordering for ordered binary decision diagrams. In
International Conference on Computer-Aided Design (ICCAD), pages 42–47. IEEE
Computer Society Press, 1993.
[359] J. Rushby. Formal methods and the certiﬁcation of critical systems. Technical
Report SRI-CSL-93-7, SRI International, 1993. (also issued as Formal Methods and
Digital System Validation, NASA CR 4551).
[360] T. C. Ruys and E. Brinksma. Managing the veriﬁcation trajectory. International
Journal on Software Tools for Technology Transfer, 4(2):246–259, 2003.
[361] S. Safra. On the complexity of ω-automata. In 29th Annual Symposium on Foun-
dations of Computer Science (FOCS), pages 319–327. IEEE Computer Society Press,
1988.
[362] A. L. Sangiovanni-Vincentelli and P. C. McGeer and A. Saldanha. Ver-
iﬁcation of electronic systems. In 33rd Annual Conference on Design Automation
(DAC), pages 106–111. ACM Press, 1996.
[363] J. E. Savage. Models of Computation: Exploring the Power of Computing. Addison-
Wesley, 1998.
[364] T. Schlipf and T. Buechner and R. Fritz and M. Helms and J. Koehl.
Formal veriﬁcation made easy. IBM Journal of Research and Development, 41(4–
5):567–576, 1997.
[365] K. Schneider. Veriﬁcation of Reactive Systems: Formal Methods and Algorithms.
Springer-Verlag, 2004.

960
BIBLIOGRAPHY
[366] S. Schneider. Specifying Real-Time Systems in Timed CSP. Prentice-Hall, 2000.
[367] A. Schrijver. Combinatorial Optimization: Polyhedra and Eﬃciency. Springer,
2003.
[368] S. Schwoon and J. Esparza. A note on on-the-ﬂy veriﬁcation algorithms. In
11th International Conference on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS), volume 3440 of Lecture Notes in Computer Science,
pages 174–190. Springer-Verlag, 2005.
[369] R. Sebastiani and S. Tonetta. “More deterministic” vs. “smaller” B¨uchi au-
tomata for eﬃcient LTL model checking. In 12th Advanced Research Working Con-
ference on Correct Hardware Design and Veriﬁcation Methods (CHARME), volume
2860 of Lecture Notes in Computer Science, pages 126–140. Springer-Verlag, 2003.
[370] R. Segala and N. Lynch. Probabilistic simulations for probabilistic processes.
Nordic Journal of Computing, 2(2):250–273, 1995.
[371] A. P. Sistla. Safety, liveness and fairness in temporal logic. Formal Aspects of
Computing, 6(5):495–512, 1994.
[372] A. P. Sistla and E. M. Clarke. The complexity of propositional linear temporal
logic. Journal of the ACM, 32(3):733–749, 1985.
[373] A. P. Sistla and M. Y. Vardi and P. Wolper. The complementation prob-
lem for B¨uchi automata with applications to temporal logic. Theoretical Computer
Science, 49:217–237, 1987.
[374] F. Somenzi. Binary decision diagrams. In M. Broy and R. Steinbruggen, editors,
Calculational System Design, volume 173 of NATO Science Series F: Computer and
Systems Sciences, pages 303–366. IOS Press, 1999.
[375] F. Somenzi and R. Bloem. Eﬃcient B¨uchi automata from LTL formulae. In 12th
International Conference on Computer Aided Veriﬁcation (CAV), volume 1855 of
Lecture Notes in Computer Science, pages 248–263. Springer-Verlag, 2000.
[376] L. Staiger. Research in the theory of omega-languages. Elektronische Informa-
tionsverarbeitung und Kybernetik, 23(8–9):415–439, 1987.
[377] J. Staunstrup and H. R. Andersen and H. Hulgaard and J. Lind-Nielsen
and K. G. Larsen and G. Behrmann and K. Kristoffersen and A. Skou
and H. Leerberg and N. B. Theilgaard. Practical veriﬁcation of embedded
software. IEEE Computer, 33(5):68–75, 2000.
[378] W. J. Stewart. Introduction to the Numerical Solution of Markov Chains. Prince-
ton University Press, 1994.

BIBLIOGRAPHY
961
[379] C. Stirling.
Modal and Temporal Properties of Processes.
Texts in Computer
Science. Springer-Verlag, New York, 2001.
[380] F. A. Stomp and W.-P. de Roever. A principle for sequential reasoning about
distributed algorithms. Formal Aspects of Computing, 6(6):716–737, 1994.
[381] N. Storey. Safety-Critical Computer Systems. Addison-Wesley, 1996.
[382] R. S. Streett. Propositional dynamic logic of looping and converse is elementarily
decidable. Information and Control, 54(1–2):121–141, 1982.
[383] T. A. Sudkamp. Languages and Machines, 3rd edition. Addison-Wesley, 2005.
[384] B.K. Szymanski. A simple solution to Lamport’s concurrent programming problem
with linear wait. In International Conference on Supercomputing Systems, pages
621–626, 1988.
[385] L. Tan and R. Cleaveland. Simulation revisited. In 7th International Conference
on Tools and Algorithms for the Construction and Analysis of Systems (TACAS),
volume 2031 of Lecture Notes in Computer Science, pages 480–495. Springer-Verlag,
2001.
[386] S. Tani and K. Hamaguchi and S. Yajima.
The complexity of the optimal
variable ordering problems of shared binary decision diagrams. In 4th International
Symposium on Algorithms and Computation, volume 762 of Lecture Notes in Com-
puter Science, pages 389–398. Springer-Verlag, 1993.
[387] R. Tarjan.
Depth-ﬁrst search and linear graph algorithms.
SIAM Journal on
Computing, 1(2):146–160, 1972.
[388] H. Tauriainen.
Nested emptiness search for generalized B¨uchi automata.
Re-
search Report A79, Helsinki University of Technology, Laboratory for Theoretical
Computer Science, 2003.
[389] X. Thirioux.
Simple and eﬃcient translation from LTL formulas to B¨uchi au-
tomata. Electronic Notes in Theoretical Computer Science, 66(2), 2002.
[390] W. Thomas. Automata on inﬁnite objects. In J. van Leeuwen, editor, Handbook of
Theoretical Computer Science, volume B: Formal Models and Semantics, chapter 4,
pages 133–191. Elsevier Publishers B.V., 1990.
[391] W. Thomas. Languages, automata, and logic. In G. Rozenberg and A. Salomaa,
editors, Handbook of Formal Languages, volume 3, pages 389–455. Springer-Verlag,
1997.
[392] B. A. Trakhtenbrot.
Finite automata and the logic of one-place predicates.
Siberian Mathematical Journal, 3:103–131, 1962.

962
BIBLIOGRAPHY
[393] G. J. Tretmans and K. Wijbrans and M. Chaudron. Software engineering
with formal methods: the development of a storm surge barrier control system.
Formal Methods in System Design, 19(2):195–215, 2001.
[394] S. Tripakis and S. Yovine. Analysis of timed systems based on time-abstracting
bisimulations.
In 8th International Conference on Computer Aided Veriﬁcation
(CAV), volume 1102 of Lecture Notes in Computer Science, pages 232–243. Springer-
Verlag, 1996.
[395] S. Tripakis and S. Yovine. Analysis of timed systems using time-abstracting
bisimulations. Formal Methods in System Design, 18(1):25–68, 2001.
[396] R. Trudeau. Introduction to Graph Theory. Dover Publications Inc., 1994.
[397] D. Turi and J. J. M. M. Rutten. On the foundations of ﬁnal coalgebra semantics.
Mathematical Structures in Computer Science, 8(5):481–540, 1998.
[398] A. Valmari. Stubborn sets for reduced state space generation. In 10th International
Conference on Applications and Theory of Petri Nets (ICATPN), volume 483 of
Lecture Notes in Computer Science, pages 491–515. Springer-Verlag, 1989.
[399] A. Valmari. A stubborn attack on state explosion. Formal Methods in System
Design, 1(4):297–322, 1992.
[400] A. Valmari. On-the-ﬂy veriﬁcation with stubborn sets. In 5th International Con-
ference on Computer Aided Veriﬁcation (CAV), volume 697 of Lecture Notes in
Computer Science, pages 397–408. Springer-Verlag, 1993.
[401] A. Valmari. Stubborn set methods for process algebras. In Partial Order Methods
in Veriﬁcation [328], pages 213–231.
[402] H. van der Schoot and H. Ural. An improvement of partial order veriﬁcation.
Software Testing, Veriﬁcation and Reliability, 8(2):83–102, 1998.
[403] J.L.A. van der Snepscheut.
Trace Theory and VLSI Design, volume 200 of
Lecture Notes in Computer Science. Springer-Verlag, 1985.
[404] R. J. van Glabbeek. The linear time – branching time spectrum (extended ab-
stract). In 1st International Conference on Concurrency Theory (CONCUR), volume
458 of Lecture Notes in Computer Science, pages 278–297. Springer-Verlag, 1990.
[405] R. J. van Glabbeek. The linear time – branching time spectrum II. In 4th In-
ternational Conference on Concurrency Theory (CONCUR), volume 715 of Lecture
Notes in Computer Science, pages 66–81. Springer-Verlag, 1993.
[406] R. J. van Glabbeek and W. P. Weijland. Branching time and abstraction in
bisimulation semantics. Journal of the ACM, 43(3):555–600, 1996.

BIBLIOGRAPHY
963
[407] M. Y. Vardi. Automatic veriﬁcation of probabilistic concurrent ﬁnite-state pro-
grams. In 26th IEEE Symposium on Foundations of Computer Science (FOCS),
pages 327–338. IEEE Computer Society Press, 1985.
[408] M. Y. Vardi. An automata-theoretic approach to linear temporal logic. In 8th
BanﬀHigher Order Workshop Conference on Logics for Concurrency: Structure
versus Automata, volume 1043 of Lecture Notes in Computer Science, pages 238–
266. Springer-Verlag, 1996.
[409] M. Y. Vardi.
Probabilistic linear-time model checking:
An overview of the
automata-theoretic approach. In 5th International AMAST Workshop on Formal
Methods for Real-Time and Probabilistic Systems (ARTS), volume 1601, pages 265–
276. Springer-Verlag, 1999.
[410] M. Y. Vardi. Branching versus linear time: Final showdown. In 7th International
Conference on Tools and Algorithms for the Construction and Analysis of Systems
(TACAS), volume 2031 of Lecture Notes in Computer Science, pages 1–22. Springer-
Verlag, 2001.
[411] M. Y. Vardi and P. Wolper. An automata-theoretic approach to automatic
program veriﬁcation (preliminary report). In 1st Annual Symposium on Logic in
Computer Science (LICS), pages 332–344. IEEE Computer Society Press, 1986.
[412] M. Y. Vardi and P. Wolper. Reasoning about inﬁnite computations. Information
and Computation, 115(1):1–37, 1994.
[413] K. Varpaaniemi.
On stubborn sets in the veriﬁcation of linear time temporal
properties. In 19th International Conference on Application and Theory of Petri
Nets (ICATPN), volume 1420 of Lecture Notes in Computer Science, pages 124–
143. Springer-Verlag, 1998.
[414] W. Visser and H. Barringer. Practical CTL∗model checking: should SPIN
be extended?
International Journal on Software Tools for Technology Transfer,
2(4):350–365, 2000.
[415] H. V¨olzer and D. Varacca and E. Kindler. Deﬁning fairness. In 16th Inter-
national Conference on Concurrency Theory (CONCUR), volume 3653 of Lecture
Notes in Computer Science, pages 458–472. Springer-Verlag, 2005.
[416] F. Wallner.
Model checking LTL using net unfoldings.
In 10th International
Conference on Computer Aided Veriﬁcation (CAV), volume 1427 of Lecture Notes
in Computer Science, pages 207–218. Springer-Verlag, 1998.
[417] F. Wang. Eﬃcient veriﬁcation of timed automata with BDD-like data structures.
Journal on Software Tools and Technology Transfer, 6(1):77–97, 2004.

964
BIBLIOGRAPHY
[418] I. Wegener.
Branching Programs and Binary Decision Diagrams: Theory and
Applications. SIAM Monographs on Discrete Mathematics and Applications. Society
for Industrial and Applied Mathematics, 2000.
[419] C. H. West.
An automated technique for communications protocol validation.
IEEE Transactions on Communications, 26(8):1271–1275, 1978.
[420] C. H. West. Protocol validation in complex systems. In Symposium on Commu-
nications Architectures and Protocols, pages 303–312. ACM Press, 1989.
[421] J. A. Whittaker. What is software testing? Why is it so hard? IEEE Software,
17(1):70–79, 2000.
[422] B. Willems and P. Wolper. Partial-order methods for model checking: from
linear time to branching time.
In 11th IEEE Symposium on Logic in Computer
Science (LICS), page 294. IEEE Computer Society Press, 1996.
[423] G. Winskel. Event structures. In Petri Nets: Central Models and Their Properties,
Advances in Petri Nets, volume 255 of Lecture Notes in Computer Science, pages
325–392. Springer-Verlag, 1986.
[424] P. Wolper. Speciﬁcation and synthesis of communicating processes using an ex-
tended temporal logic. In 9th Symposium on Principles of Programming Languages
(POPL), pages 20–33. ACM Press, 1982.
[425] P. Wolper. Temporal logic can be more expressive.
Information and Control,
56(1–2):72–99, 1983.
[426] P. Wolper.
An introduction to model checking.
Position statement for panel
discussion at the Software Quality workshop, 1995.
[427] W. Yi. CCS + time = an interleaving model for real-time systems. In 18th Inter-
national Colloquium on Automata, Languages and Programming (ICALP), volume
510 of Lecture Notes in Computer Science, pages 217–228. Springer-Verlag, 1991.
[428] M. Yoeli. Formal Veriﬁcation of Hardware Design. IEEE Computer Society Press,
1990.
[429] S. Yovine.
KRONOS: A veriﬁcation tool for real-time systems.
International
Journal on Software Tools for Technology Transfer, 1(1-2):123–133, 1997.
[430] S. Yovine. Model checking timed automata. In G. Rozenberg and F. Vaandrager,
editors, Lectures on Embedded Systems, volume 1494 of Lecture Notes in Computer
Science, pages 114–152. Springer-Verlag, 1998.

Index
A
absorbing state, 753, 769
absorption law, 248, 918
abstract
syntax, 916
transition system, 500
abstraction
function, 499
accept state, 152, 174
acceptance set, 174, 193, 274
accepting
bottom strongly component, 803
end component, 872
run, 154, 174, 193, 801
Act set of actions, 20
action-based bisimulation, 465
action-deterministic, 24, 597
adjacency lists, 921
almost surely, 756
alphabet, 912
alternating bit protocol, 57, 60, 545, 564,
838
always, 230, 319
ample set, 605
anti-symmetric relation, 911
AP set of atomic propositions, 20
AP-determinism, 24, 512, 582
AP-partition, 478
arbiter, 50, 259, 362, 835
arity, 911
assignment, 65
random, 837
associativity law, 918
atomic
clock constraint, 678
proposition, 20, 915
region, 65, 74
statement, 42, 72
B
B¨uchi automaton, 174, 229, 607, 623, 800
backward edge, 207, 208, 213, 620, 623, 624,
644, 923
bad preﬁx, 112, 159, 161, 199, 797
bakery algorithm, 461, 471
balance equation, 831
basis, 757
BFS, 921
-based reachability, 108, 390
binary decision diagram, 381, 395
one successor succ1(·), 395
ordered, 395
reduced, 398
semantics, 396
shared, 408
zero successor succ0(·), 395
binary decision tree, 385
bisimulation, 451, 456, 732
action-based, 465
normed, 552
on a Markov chain, 808
quotient TS/ ∼, 459
step-dependent normed, 556
stutter, 536
stutter with divergence, 546
bisimulation equivalence, 451
965

966
INDEX
≈n, 552
≈, 536
≈s, 556
≈div, 546
∼, 451
∼M, 808
∼TS, 456
∼bisimulation equivalence, 451
bisimulation-closed σ-algebra, 811
block, 476
bottom strongly connected component, 774
branching condition (A5), 652
breadth-ﬁrst search, 921
BSCC, 774, 787
C
cardinality, 910
channel, 53
capacity, 55
cap(·) channel capacity, 55
lossy, 837
Chan set of channels, 53
channel system, 55, 63, 68, 79, 627, 837
closed, 63
open, 63
transition system, 59
characteristic function, 386
circuit, 77, 82, 87, 240, 301
clause, 919
clock constraint, 678
clock equivalence, 713
∼= clock equivalence, 713
clock region, 714
unbounded, 721
r∞unbounded clock region, 721
closed channel system, 63
closure
of formula, 276
of LT property, 114
transitive, reﬂexive, 912
CNF, 407, 919
coarser, 911
cofactor, 383
order-consistent, 397
communication action, 53, 70
Comm set of communication actions, 53
communication channel, 53, 241
commutativity law, 918
complex eﬀect, 645
computation tree logic, see CTL
computed table, 409, 414
concatenation, 913
concurrency, 36
Cond(·) set of Boolean conditions, 30
conjunctive normal form, 919
coNP, 928
-complete, 930
-hard, 930
consistent, 276
constrained reachability, 762, 777
step-bounded, 767
control
cycle, 642
path, 642
counterexample, 8, 168, 199, 271, 374, 786
CTL
equivalence, 468
existential fragment, 520
fairness assumption, 359
path formula, 317
semantics, 320, 360
state formula, 317
syntax, 317
universal fragment, 516
CTL∗
equivalence, 468
existential fragment, 520
semantics, 423
syntax, 422
universal fragment, 516
CTL+, 426
cumulative reward, 817
cycle, 921

INDEX
967
breaking condition (S2), 635
condition (A4), 610, 620
cylinder set, 757
D
DBA, 188, 799
de Morgan’s law, 918
deadlock, 89
decrementing eﬀect, 644
dependence of actions, 599
dependency condition (A2), 609, 628
depth-ﬁrst search, 921
nested, 203, 623
deterministic
algorithm, 926
B¨uchi automaton, 188, 799
ﬁnite automaton, 156, 797
Rabin automaton, 801, 881
transition system, 24
DFA, 156
DFS, 921
digraph, 920
Dijkstra’s dining philosophers, 90
dining philosophers, 90, 234, 839
discrete-time Markov chain, 753
disjoint union ⊎, 910
disjunctive normal form, 919
distribution, 755
distributive law, 249, 918
divergence
-sensitive expansion TS, 575
sensitivity, 544
stutter bisimulation, 546
divergent state, 544
DNF, 407, 919
dom(·) domain of message, 55
double negation, 918
DRA, 801
accepting run, 801
language, 801
run, 801
drain, 395
duality rules, 248, 329
dynamic leader election, 242
E
edge, 920
eﬀect, 644
complex, 645
decrementing, 644
incrementing, 644
of an action, 32
Eﬀect(·), 32
elementary sets, 276
elimination rule, 400
emptiness problem, 155, 184, 296
empty word ε, 913
end component, 870
accepting, 872
graph, 870
maximal, 875
ENF, 332
equivalence
class, 911
of NBA, 185
of NFA, 155
relation, 911
equivalence ≡
of CTL formulae, 329
of CTL∗formulae, 425
of CTL- and LTL formulae, 334
of LTL formulae, 248
propositional logic, 917
equivalence checking
bisimulation equivalence, 493
ﬁnite trace equivalence, 494
simulation equivalence, 528
stutter-bisimilarity, 567
with divergence, 574
trace equivalence, 494
essential variable, 383
evaluation, 27, 30, 382, 916

968
INDEX
Eval(·) variable evaluation, 27, 30, 382, 916
event, 754
measurable, 755
E set of events, 754
eventually, 121, 230, 318
execution, 25
execution fragment, 24
existential fragment, 520
existential normal form, 332
CTL, 332
existential quantiﬁcation, 317, 418, 909
exit states, 571
Bottom(·) set of exit states, 571
expansion law
CTL, 329
LTL, 248, 249, 275
CTL, 330
PCTL, 764
expected
long-run reward, 830
reward, 818
exp(n) exponential complexity, 910
expressiveness, 337
F
fair
satisfaction relation, 135, 259, 363, 892
scheduler, 884
FairPaths(·) set of fair paths, 134, 259, 360
fair satisfaction relation |=
CTL, 360
LTL, 259
fair satisfaction relation |=
CTL, 361
LT property, 135
LTL, 358
PCTL, 891
FairTraces(·) set of fair traces, 134, 259
fairness, 126, 258, 359, 732, 883
fairness assumption, 133
CTL, 359
CTL∗, 425
LTL, 258
MDP, 883
realizable, 139, 793, 884
fairness constraint, 129
LTL, 258
strong, 130, 258, 359
unconditional, 130, 258, 359
weak, 130, 258, 359
father, 924
ﬁnal state, 152, 174
ﬁnd or add, 409
ﬁner, 911
ﬁnite trace
equivalence, 117, 494
inclusion, 116
ﬁnite transition system, 20
ﬁnite word, 912
ﬁnite-memory scheduler, 848
ﬁnitely branching, 472, 924
ﬁrst(·), 95
fm-scheduler, 848
forming path, 655
frac(·) fractional part of real, 709
fully expanded, 613
G
garbage collection, 265
generalized NBA, 193, 274
global cycle, 644
GNBA, 193, 274, 278
accepting run, 193
language, 193, 274
run, 193
graph, 920
end component, 870
of a Markov chain, 748
of a transition system, 95
of an MDP, 840
program, 30
guard, 33, 65

INDEX
969
guarded command language, 63, 837
guess-and-check, 926
H
Hamiltonian path problem, 288, 356
vet, 924
handshaking, 47, 48, 56, 466, 599, 683
H set of handshaking actions, 48, 683
hardware circuits, 26
hardware veriﬁcation, 5
I
idempotency rules, 248, 329, 918
iﬀ, 909
image-ﬁnite, 119
implementation relation, 449
weak, 529
incrementing eﬀect, 644
independence of actions, 37, 599
index of an equivalence, 911
inf(π), 749
inﬁnite word, 100, 170, 912
initial
execution fragment, 25
path fragment, 96
initial distribution ιinit, 748
initial state, 20
inner node, 395
integral part ⌊d⌋of real d, 709
interleaving, 36, 38, 40, 49
invariant, 107
condition, 107
isomorphism rule, 400, 409
ITE, 410
iterated cofactor, 383
K
Kleene star, 913
Knuth and Yao’s die simulation, 750
Knuth’s die simulation, 819, 821, 838
L
labeling function, 20
language
of a regular expression, 914
of an ω-regular expression, 171
of DRA, 801
of GNBA, 193, 274
of LT property, 100
of NBA, 174
of NFA, 154
language L, 170, 913
language equivalence
GNBA, 193
NBA, 185
NFA, 155
leader election, 87, 242, 846
leaf, 924
length
of a formula, 916
of a word, 913
letter, 912
light switch, 688, 692–694, 699, 714, 727
limit, 871
limit LT property, 872, 887
linear temporal logic, see LTL
linear-time property, see LT property
literal, 919
liveness property, 121
locally consistent, 276
location, 32, 678
diagram, 682
Loc set of locations, 32, 678
long-run reward, 830
LT property, 100, 456, 796
ω-regular, 172, 796
limit, 872
satisfaction, 100
stutter-insensitive, 535
LTL
elementary sets, 276
equivalence, 468

970
INDEX
fairness assumption, 258
semantics, 235, 237
syntax, 231
LTL\⃝, 534
M
Markov chain, 747
Markov decision process, 833
Markov reward model, 817
master formula, 471, 562, 815
maximal
end component, 875
execution fragment, 25
path fragment, 96
set of formulae, 276
maximal proper state subformula, 427
MDP, 833
measurable event, 755
memoryless scheduler, 847
message passing, 47, 56
minimal bad preﬁx, 112, 161
mode, 848
model checking, 11
process, 11
strengths and weaknesses, 14
Modify(·) set of modiﬁed variables, 627
modiﬁed variable, 627
modulo-4 counter, 240
monotonic, 647
MRM, 817
mutex-property, 102
mutual exclusion, 43, 45, 50, 98, 102, 161,
173, 259, 542
semaphore, 73
N
nanoPromela, 64, 837
IN natural numbers, 909
NBA, 174
accepting run, 174
language, 174
nonblocking, 187
run, 174
union operator, 179
negative cofactor, 383
nested depth-ﬁrst search, 203, 623
nesting depth, 792
neutral, 645
NFA, 151
accepting run, 154
language, 154
run, 153
non-zeno, 694
nonblocking
GNBA, 195
NBA, 187
nondeterminism, 22
nondeterministic
algorithm, 926
B¨uchi automaton, 174
ﬁnite automaton, 151
nonemptiness
condition (A1), 609
problem, 155, 184
norm function, 552
normal form
existential, 332
positive, 252, 333, 902
normed bisimulation, 552, 654
NP, 928
-complete, 929
-hard, 929
O
O(exp(n)), 910
O(poly(n)), 910
OBDD, 392
reduced, 398
observational equivalence, 589
ω-regular
expression, 171
language, 172

INDEX
971
property, 172, 272, 796, 799
open channel system, 63
operational semantics, 68
opposite actions, 647
ordered binary decision diagram, 395
outcome, 754
Outc set of outcomes, 754
P
P (complexity class), 927
partition, 476, 912
path, 96
-lifting, 454, 504, 549
existential quantiﬁcation, 317
fair, 134
formula, 422, 698
fragment, 95
in a digraph, 920
in a Markov chain, 749
in transition system, 96
limit, 871
quantiﬁer, 314, 330
universal quantiﬁcation, 317
Paths(·) set of paths, 96
Pathsﬁn(·) set of ﬁnite paths, 96
PCTL, 780, 806, 866, 883
semantics, 783
PCTL∗, 806, 883
persistence condition, 199
persistence property, 199, 623, 795, 876
Peterson’s algorithm, 45, 67, 84, 161, 538,
667
PGi-projection, 643
PNF, 252, 255, 257, 333, 902, 919
poly-time algorithm, 927
poly(n) polynomial complexity, 910
polynomial time-bounded, 927
positive cofactor, 383
positive normal form, 252, 516, 902
CTL, 333
LTL, 255, 257
PCTL, 902
propositional logic, 919
release, 257
weak until, 255
Post(s), 23, 753, 835, 920
power method, 764
powerset, 910
construction, 157
Pre(s), 23, 753, 835, 920
pref(P), 115
preﬁx, 913
of a path fragment, 96
pref(·), 114
preorder, 498, 912
probabilistic choice, 837
probabilistic computation tree logic, see PCTL
probabilistic CTL, see PCTL
probability measure, 754
probability space, 755
Probmela, 837
process fairness, 126
producer-consumer system, 565
product automaton, 156
product transition system, 165, 200, 623
program
nanoPromela, 64
program graph, 32, 34, 55, 68, 77
independence of actions, 599
interleaving, 40
partial order reduction, 627
static partial order reduction, 635
transition system, 34
projection, 643
function, 383
Promela, 63, 837
proper reﬁnement, 911
propositional
logic, 915
symbol, 915
PSPACE, 928
-complete, 930
-hard, 930

972
INDEX
PTIME, 927
Q
qualitative
fragment of PCTL, 788
property, 746
quantiﬁer, 909
path-, 314
quantitative property, 746
quotient
transition system, 521
space, 458, 911
transition system TS/ ≈, 541
transition system TS/ ≈div, 546
transition system TS/ ∼, 459
transition system TS/ ≃, 508
R
Rabin automaton, 801
railroad crossing, 51, 683, 700
random assignment, 837
randomized
dining philosopher, 839
leader election, 846
scheduler, 850
reachability probability, 759
reachable states, 26
IR real numbers, 909
real-time, 246, 673
realizable, 884
reduced OBDD, 398
reduced state space ˆS, 606
reduced transition relation ⇒, 606
reduction rules, 400
reﬁnement, 911
reﬂexive relation, 911
region, 714
reset operator, 719
region transition system, 709, 726
regular
expression, 171, 914
language, 172, 914
property, 172
safety property, 159, 797
relational product, 416, 419
release operator, 256, 902
R release operator, 256
release PNF, 257
rename operator, 386, 416
repeated eventually, 121
repetition
ﬁnite, 913
inﬁnite, 171
reward function, 817
ROBDD, 398
ROBDD-size, 400
root, 395, 924
rule for double negation, 918
run
in DRA, 801
in GNBA, 193
in NBA, 174
in NFA, 153
S
safety property, 112, 116, 117, 140, 159,
177, 797, 886
SAT problem, 925
Sat(Φ), 423
satisfaction relation |=
CTL, 320
CTL∗, 423
fair CTL, 360
LT property, 100
PCTL, 783
satisfaction relation |=
CTL, 321
CTL∗, 423
LTL, 235, 237
PCTL, 782, 866
propositional logic, 916
TCTL, 701

INDEX
973
satisfaction set, 321, 343, 423, 703
fair, 361
satisﬁability, 296, 918, 925
SCC, 774, 924
scheduler, 842
fair, 884
ﬁnite-memory, 848
memoryless, 847
randomized, 850
simple, 847
self-loop, 920
semantic equivalence ≡
propositional logic, 917
semaphore, 43, 73, 98, 537, 542, 600, 663
set of
actions, 20
atomic propositions, 20
bad preﬁxes, 112, 161
minimal bad preﬁxes, 112, 161
natural numbers IN, 909
predecessor states, 23
real numbers IR, 909
successor states, 23
Shannon expansion, 384, 397
B shared OBDD, 408
shared OBDD, 408
shared variable, 39
Σ alphabet, 912
σ-algebra, 754
bisimulation-closed, 811
σ-algebra, 758
simple scheduler, 847
simulation, 497, 506
equivalence, 506
equivalence ≃, 505
⪯simulation order, 497
order ⪯, 506
quotient system, 508
≃simulation equivalence, 505
simulator set, 506
size
of an MDP, 840
of an OBDD, 395
of an ROBDD, 400
skip, 65
software veriﬁcation, 3
son, 924
splitter, 483, 568
stability, 483
stable, 568
stack, 923
standard triple, 415
starvation freedom, 103, 121, 127, 173
state formula, 422, 698
state graph, 95
G(TS) state graph of TS, 95
state region, 714
state space explosion, 77, 381
statement
skip, 65
atomic{. . .}, 66
nanoPromela, 65
exit, 68
sub, 69
static partial order reduction, 635
step-bounded
constrained reachability, 767
until, 781
step-dependent normed bisimulation ≈s, 556
sticky
action, 635
condition (A3/4), 636
strong cycle condition (A4′), 620
strong fairness, 130, 259, 359, 772
strongly connected, 774
strongly connected component, 774, 924
bottom, 774
structural induction, 281
structured operational semantics, 34, 70
stutter
action, 603
bisimulation
≈, 536
bisimulation with divergence, 546

974
INDEX
condition (A3), 610
equivalence, 530
equivalence with divergence ≈div, 549
implementation relation, 540
insensitive, 535
step, 530, 603
trace equivalence, 532, 606
trace inclusion, 532
≜stutter trace equivalence, 532
⊴stutter trace inclusion, 532
sub-MDP, 870
sub-OBDD, 396
subset construction, 157
substatement, 69
subword, 913
succb(v), 395
success set, 873
successor function, 395
successor region, 723
succ(·) successor region, 723
suﬃx, 913
of a path fragment, 96
superblock, 476
switching function, 383
symbol, 912
symbolic, 381
symmetric function, 406
symmetric relation, 911
synchronous product ⊗, 75, 156
T
tautology, 918
TCTL, 698
model checking, 705
semantics, 701
syntax, 698
terminal
node, 395
state, 23, 89
test-and-set semantics, 66, 72
time divergence, 700
time-convergent, 692
time-divergent, 692
timed automaton, 678
timed computation tree logic, see TCTL
timed CTL
seeTCTL, 698
timelock, 692, 705, 731
total DBA, 188
total DFA, 156
trace, 98
fair, 134
trace equivalence, 105, 106, 514
checking, 494
trace fragment, 98
trace inclusion, 104
ﬁnite, 116
Traces(·) set of traces, 98
Tracesﬁn(·) set of ﬁnite traces, 98
transient state distribution, 768, 828
transient state probabilities, 768
transition probability function, 748, 834
transition probability matrix
Markov chain, 748
Markov decision process, 834
transition relation →, 20
transition system, 20
graph, 95
image-ﬁnite, 119
interleaving, 38
of a channel system, 59
of a program graph, 34
of a timed automaton, 687
of hardware circuit, 28
transitive relation, 911
transitive, reﬂexive closure, 912
tree, 924
two-step-semantics, 72
U
unconditional fairness, 130, 259, 359
unique table, 409

INDEX
975
universal fragment, 516
universal quantiﬁcation, 317, 909
V
val(v), 395
validity, 296, 918
validity problem, 930
value function, 395
value iteration, 854, 861
variable
nanoPromela, 64
essential, 383
labeling function, 395
ordering ℘, 395
ordering problem, 403
typed, 30
Var set of variables, 30
Var(·) variables in an expression, 627
variable labeling function var(v), 395
vertex, 920
Vis, 635
visibility condition (S1), 635
visible action, 635
W
weak fairness, 130, 259, 359
weak implementation relation, 529
weak until, 252, 318, 327, 902
W weak until, 252
weak-until PNF, 255
witness, 374, 786
word, 97, 912
empty, 913
inﬁnite, 100, 170
Z
zeno path, 694

